<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 18]
- [cs.CR](#cs.CR) [Total: 46]
- [cs.AI](#cs.AI) [Total: 55]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Benchmark Dataset Generation and Evaluation for Excel Formula Repair with LLMs](https://arxiv.org/abs/2508.11715)
*Ananya Singha,Harshita Sahijwani,Walt Williams,Emmanuel Aboah Boateng,Nick Hausman,Miguel Di Luca,Keegan Choudhury,Chaya Binet,Vu Le,Tianwei Chen,Oryan Rokeah Chen,Sulaiman Vesal,Sadid Hasan*

Main category: cs.SE

TL;DR: 这篇论文为Excel公式修复任务构建了一个高质量的标准数据集，通过LLM提示和执行验证管道生成618个样本，并提出了上下文感知的基准方法来优化公式修复性能。


<details>
  <summary>Details</summary>
Motivation: Excel作为普遍但复杂的工具，新手用户常遇到语义运行错误。虽然LLM能解释错误，但自动修复仍是挑战，主要困难在于缺乏高质量的训练和评估数据集。

Method: 提出了一个数据生成管道，利用在线论坛的少量类别样本通过少数提示和LLM扩展数据集。采用LLM-as-a-Judge验证框架结合执行检查确保数据正确性。同时提出了一种上下文感知的基准方法来利用错误公式和相关表格上下文。

Result: 生成了618个高质量的标准数据样本，覆盖常见运行错误。对多种LLM（GPT-4o、GPT-4.1、Phi-3、Mistral）进行了执行基准评估。通过手动注释和错误分布分析验证了数据集质量。

Conclusion: 该数据集构建方法具有高可扩展性，可以轻松适配到其他低资源编程语言的代码修复任务中，为Excel公式自动修复研究提供了重要的评估基准。

Abstract: Excel is a pervasive yet often complex tool, particularly for novice users,
where runtime errors arising from logical mistakes or misinterpretations of
functions pose a significant challenge. While large language models (LLMs)
offer promising assistance by explaining formula errors, the automated
correction of these semantic runtime errors remains an open problem. A primary
challenge to advancing models for such scenarios is the severe lack of
high-quality, comprehensive datasets for training and rigorous evaluation. This
paper addresses this gap by introducing a novel approach for constructing a
benchmark dataset specifically designed for Excel formula repair. We propose a
data generation pipeline, which leverages a small set of curated seed samples
from online forums to synthetically expand the dataset. Our pipeline integrates
few-shot prompting with LLMs and employs a robust \textit{LLM-as-a-Judge}
validation framework, combined with execution-based checks to ensure the
correctness and semantic fidelity of the generated data. This process produced
a benchmark dataset of 618 high-quality samples, covering common runtime
errors. Furthermore, we propose a context-aware baseline technique for Excel
formula repair that utilizes LLMs to leverage both the faulty formula, and
relevant spreadsheet context. We evaluate the performance of various LLMs
(GPT-4o, GPT-4.1, Phi-3, Mistral) on our newly generated benchmark using
execution-based metrics. Our analysis demonstrates the dataset's quality
through manual annotation and provides insights into error and function
distributions. The proposed generation methodology is highly scalable and can
be readily adapted to create evaluation benchmarks for similar code repair
tasks in other low-resource programming languages.

</details>


### [2] [WIP: Leveraging LLMs for Enforcing Design Principles in Student Code: Analysis of Prompting Strategies and RAG](https://arxiv.org/abs/2508.11717)
*Dhruv Kolhatkar,Soubhagya Akkena,Edward F. Gehringer*

Main category: cs.SE

TL;DR: 使用LLM和RAG技术开发自动化代码审查工具，用于评估学生代码遵循面向对象设计原则的情况


<details>
  <summary>Details</summary>
Motivation: 解决在计算机科学软件工程课程中，需要更有效和可扩展的方法来教掌软件设计最佳实践的问题

Method: 结合大语言模型(LLM)和检索增强生成(RAG)技术，开发自动化反馈系统，评估SOLID、DRY和设计模式等原则，分析不同提示策略的效果

Result: 预期结果显示在代码质量方面取得了稀望的改进

Conclusion: 该研究为教掌软件设计最佳实践提供了有前景的自动化工具，未来工作将重点改善模型准确性和扩大支持的设计原则范围

Abstract: This work-in-progress research-to-practice paper explores the integration of
Large Language Models (LLMs) into the code-review process for open-source
software projects developed in computer science and software engineering
courses. The focus is on developing an automated feedback tool that evaluates
student code for adherence to key object-oriented design principles, addressing
the need for more effective and scalable methods to teach software design best
practices. The innovative practice involves leveraging LLMs and
Retrieval-Augmented Generation (RAG) to create an automated feedback system
that assesses student code for principles like SOLID, DRY, and design patterns.
It analyzes the effectiveness of various prompting strategies and the RAG
integration. Preliminary findings show promising improvements in code quality.
Future work will aim to improve model accuracy and expand support for
additional design principles.

</details>


### [3] [Rethinking Autonomy: Preventing Failures in AI-Driven Software Engineering](https://arxiv.org/abs/2508.11824)
*Satyam Kumar Navneet,Joydeep Chandra*

Main category: cs.SE

TL;DR: 大语言模型在代码生成中带来风险挑战，本文提出SAFE-AI框架通过安全、可审计、反馈和可解释性措施来管理风险


<details>
  <summary>Details</summary>
Motivation: 大语言模型在软件工程中的应用带来了代码安全风险、幻觉输出、不可逆操作和缺乏透明性等挑战，需要建立健全的安全管理机制

Method: 提出SAFE-AI框架，整合拦截检查、沙箱环境、运行时验证、风险认知日志、人在循环系统和可解释AI技术，并创建了AI行为分类语词系统

Result: 建立了一个全面的风险管理框架，能够有效减少LLM辅助代码生成的风险，同时促进信任和遵循相关法规

Conclusion: 该研究为软件工程中负责任AI集成提供了路线图，提出的SAFE-AI框架和AI行为分类体系为风险评估和监管提供了指南，并指明了未来研究方向

Abstract: The integration of Large Language Models (LLMs) into software engineering has
revolutionized code generation, enabling unprecedented productivity through
promptware and autonomous AI agents. However, this transformation introduces
significant risks, including insecure code generation, hallucinated outputs,
irreversible actions, and a lack of transparency and accountability. Incidents
like the Replit database deletion underscore the urgent need for robust safety
and governance mechanisms. This paper comprehensively analyzes the inherent
challenges of LLM-assisted code generation, such as vulnerability inheritance,
overtrust, misinterpretation, and the absence of standardized validation and
rollback protocols. To address these, we propose the SAFE-AI Framework, a
holistic approach emphasizing Safety, Auditability, Feedback, and
Explainability. The framework integrates guardrails, sandboxing, runtime
verification, risk-aware logging, human-in-the-loop systems, and explainable AI
techniques to mitigate risks while fostering trust and compliance. We introduce
a novel taxonomy of AI behaviors categorizing suggestive, generative,
autonomous, and destructive actions to guide risk assessment and oversight.
Additionally, we identify open problems, including the lack of standardized
benchmarks for code specific hallucinations and autonomy levels, and propose
future research directions for hybrid verification, semantic guardrails, and
proactive governance tools. Through detailed comparisons of autonomy control,
prompt engineering, explainability, and governance frameworks, this paper
provides a roadmap for responsible AI integration in software engineering,
aligning with emerging regulations like the EU AI Act and Canada's AIDA to
ensure safe, transparent, and accountable AI-driven development.

</details>


### [4] [AI-Augmented CI/CD Pipelines: From Code Commit to Production with Autonomous Decisions](https://arxiv.org/abs/2508.11867)
*Mohammad Baqar,Saba Naqvi,Rajat Khanda*

Main category: cs.SE

TL;DR: 提出AI增强的CI/CD流水线，使用LLM和自主代理作为策略约束的副驾驶和决策者，以减少人工决策延迟和操作负担


<details>
  <summary>Details</summary>
Motivation: 现代软件交付已加速到每日多次部署，但人工决策点（如解释不稳定测试、选择回滚策略等）仍然是延迟和操作负担的主要来源

Method: 提出参考架构、决策分类法、策略即代码护栏模式、信任层级框架、基于DORA指标和AI特定指标的评估方法，以及详细的工业案例研究

Result: 构建了AI增强CI/CD流水线的完整框架和方法论，包括架构设计、决策机制、信任体系和评估标准

Conclusion: AI增强CI/CD流水线能够显著减少人工决策延迟，提高交付效率，并为生产交付系统中的可验证自主性提供了路线图

Abstract: Modern software delivery has accelerated from quarterly releases to multiple
deployments per day. While CI/CD tooling has matured, human decision points
interpreting flaky tests, choosing rollback strategies, tuning feature flags,
and deciding when to promote a canary remain major sources of latency and
operational toil. We propose AI-Augmented CI/CD Pipelines, where large language
models (LLMs) and autonomous agents act as policy-bounded co-pilots and
progressively as decision makers. We contribute: (1) a reference architecture
for embedding agentic decision points into CI/CD, (2) a decision taxonomy and
policy-as-code guardrail pattern, (3) a trust-tier framework for staged
autonomy, (4) an evaluation methodology using DevOps Research and Assessment (
DORA) metrics and AI-specific indicators, and (5) a detailed industrial-style
case study migrating a React 19 microservice to an AI-augmented pipeline. We
discuss ethics, verification, auditability, and threats to validity, and chart
a roadmap for verifiable autonomy in production delivery systems.

</details>


### [5] [Clean Code, Better Models: Enhancing LLM Performance with Smell-Cleaned Dataset](https://arxiv.org/abs/2508.11958)
*Zhipeng Xue,Xiaoting Zhang,Zhipeng Gao,Xing Hu,Shan Gao,Xin Xia,Shanping Li*

Main category: cs.SE

TL;DR: 这篇论文系统研究了大语言模型在代码相关任务中的代码味道问题，提出了自动化清理工具SmellCC，并证明清理代码味道能提高LLM生成代码的质量。


<details>
  <summary>Details</summary>
Motivation: 当前研究主要关注LLM输出质量，而忽视了训练数据集中广泛存在的代码味道问题，这会影响软件维护性和可读性。

Method: 首先进行预研究确认代码味道问题的存在，然后提出LLM基于的代码味道清理工具SmellCC，构建测试集验证功能正确性，并用清理后的数据集微调LLM，最后评估代码味道对代码补全和代码搜索任务的影响。

Result: 发现代码味道问题在标准数据集和LLM生成代码中广泛存在；SmellCC能有效清理代码味道；使用清理后数据微调的LLM能生成更高质量的代码。

Conclusion: 代码味道对LLM代码生成质量有显著影响，通过自动化清理工具提升数据集质量可以提高下游任务性能，这为软件工程研究人员和业界实践者提供了可行的建议。

Abstract: The Large Language Models (LLMs) have demonstrated great potential in
code-related tasks. However, most research focuses on improving the output
quality of LLMs (e.g., correctness), and less attention has been paid to the
LLM input (e.g., the training code quality). Given that code smells are widely
existed in practice and can negatively impact software maintainability and
readability, this study takes the first systematic research to assess and
improve dataset quality in terms of code smells. In this work, we first conduct
a preliminary study to explore the presence of code smells in a popular
benchmark dataset (i.e., CodeSearchNet-Python}) and evaluate the output of
several popular LLMs (i.e., DeepSeek-Coder, CodeLlama, and MagiCoder),
revealing that code smell issues extensively exist in LLM's input (e.g.,
benchmark dataset) and output (e.g., generated code). We then conduct our
systematic research by taking three main steps: Firstly, we propose an
LLM-based code smell cleaning tool, named SmellCC, which automatically
refactors and removes code smells. To evaluate the correctness of the code
refactoring, we construct a test set of 50 repositories sourced from the
CodeSearchNet-Python benchmark for functional testing. Then we apply our
curated smell-cleaned dataset to fine-tune two LLMs (i.e., DeepSeek-V2 and
Qwen-Coder) to explore their potential for generating high-quality code.
Thirdly, we investigate the impact of code smells on two downstream tasks: code
completion and code search. Lastly, we derive several actionable implications
for software engineering researchers and industry practitioners from our
findings.

</details>


### [6] [How Much Can a Behavior-Preserving Changeset Be Decomposed into Refactoring Operations?](https://arxiv.org/abs/2508.11993)
*Kota Someya,Lei Chen,Michael J. Decker,Shinpei Hayashi*

Main category: cs.SE

TL;DR: 使用现有重构检测器只能识别33.9%的行为保持修改为重构操作，添加67个新定义功能等价操作后覆盖率提高128%以上


<details>
  <summary>Details</summary>
Motivation: 开发者经常在修改中混合行为保持和行为改变的部分，需要方法来分离这两类修改以更好地理解代码变更

Method: 使用功能等价方法对比数据集，量化行为保持修改能够被分解为重构操作的程度，并新定义67个功能等价操作来提高覆盖率

Result: 现有重构检测器只能识别33.9%的变更，添加新操作后覆盖率提高128%以上，但仍有部分变更无法解释

Conclusion: 需要更多的功能等价操作来提高重构检测的覆盖率，这为重构感知方法的改进提供了机会

Abstract: Developers sometimes mix behavior-preserving modifications, such as
refactorings, with behavior-altering modifications, such as feature additions.
Several approaches have been proposed to support understanding such
modifications by separating them into those two parts. Such refactoring-aware
approaches are expected to be particularly effective when the
behavior-preserving parts can be decomposed into a sequence of more primitive
behavior-preserving operations, such as refactorings, but this has not been
explored. In this paper, as an initial validation, we quantify how much of the
behavior-preserving modifications can be decomposed into refactoring operations
using a dataset of functionally-equivalent method pairs. As a result, when
using an existing refactoring detector, only 33.9% of the changes could be
identified as refactoring operations. In contrast, when including 67 newly
defined functionally-equivalent operations, the coverage increased by over
128%. Further investigation into the remaining unexplained differences was
conducted, suggesting improvement opportunities.

</details>


### [7] [LinkAnchor: An Autonomous LLM-Based Agent for Issue-to-Commit Link Recovery](https://arxiv.org/abs/2508.12232)
*Arshia Akhavan,Alireza Hosseinpour,Abbas Heydarnoori,Mehdi Keshani*

Main category: cs.SE

TL;DR: LinkAnchor是一个基于LLM的自主代理，用于问题到提交链接恢复，通过惰性访问架构动态检索相关上下文，避免token限制，并能自动定位目标提交，性能比现有方法提升60-262%。


<details>
  <summary>Details</summary>
Motivation: 现有问题到提交链接恢复方法存在两个主要问题：LLM受限于上下文窗口无法处理所有可用数据源；大多数方法需要逐个评估问题-提交对，这在包含数万次提交的实际仓库中不切实际。

Method: 提出LinkAnchor，采用惰性访问架构，让底层LLM能够动态检索最相关的上下文数据（提交历史、问题评论、代码文件），而不超过token限制，并能自动定位目标提交而非穷举所有候选。

Result: 评估显示LinkAnchor在所有案例研究项目中的Hit@1分数比最先进的问题到提交链接恢复方法高出60-262%。

Conclusion: LinkAnchor是第一个基于LLM的自主代理，能够有效解决现有方法的局限性，显著提升问题到提交链接恢复的性能，并已公开发布为即用工具。

Abstract: Issue-to-commit link recovery plays an important role in software
traceability and improves project management. However, it remains a challenging
task. A study on GitHub shows that only 42.2% of the issues are correctly
linked to their commits. This highlights the potential for further development
and research in this area. Existing studies have employed various AI/ML-based
approaches, and with the recent development of large language models,
researchers have leveraged LLMs to tackle this problem. These approaches suffer
from two main issues. First, LLMs are constrained by limited context windows
and cannot ingest all of the available data sources, such as long commit
histories, extensive issue comments, and large code repositories. Second, most
methods operate on individual issue-commit pairs; that is, given a single
issue-commit pair, they determine whether the commit resolves the issue. This
quickly becomes impractical in real-world repositories containing tens of
thousands of commits. To address these limitations, we present LinkAnchor, the
first autonomous LLM-based agent designed for issue-to-commit link recovery.
The lazy-access architecture of LinkAnchor enables the underlying LLM to access
the rich context of software, spanning commits, issue comments, and code files,
without exceeding the token limit by dynamically retrieving only the most
relevant contextual data. Additionally, LinkAnchor is able to automatically
pinpoint the target commit rather than exhaustively scoring every possible
candidate. Our evaluations show that LinkAnchor outperforms state-of-the-art
issue-to-commit link recovery approaches by 60-262% in Hit@1 score across all
our case study projects. We also publicly release LinkAnchor as a ready-to-use
tool, along with our replication package. LinkAnchor is designed and tested for
GitHub and Jira, and is easily extendable to other platforms.

</details>


### [8] ["My productivity is boosted, but ..." Demystifying Users' Perception on AI Coding Assistants](https://arxiv.org/abs/2508.12285)
*Yunbo Lyu,Zhou Yang,Jieke Shi,Jianming Chang,Yue Liu,David Lo*

Main category: cs.SE

TL;DR: 本文分析了VS Code市场中1,085个AI编码助手的用户评论，通过手动注释构建了用户关注点和满意度的综合分类法，揭示了开发者对上下文感知、可自定义和资源效率等核心需求，并提出4项改进建议。


<details>
  <summary>Details</summary>
Motivation: 之前的研究多在受控环境中进行，无法反映开发者在真实工作环境下对AI编码助手的真实需求和期望。本文通过分析实际用户评论来探索开发者对这些工具的真实价值观和批评。

Method: 从Visual Studio Code Marketplace识别1,085个AI编码助手，对其中32个有足够安装量和评论的助手进行手动采样分析。每条评论都被手动注释态度和关注点，以获得用户对具体功能、问题和整体性能的满意度细节。

Result: 发现AI编码助手在过去两年出现爆发式增长（超过90%）。用户不仅需要智能建议，更期待上下文感知、可自定义性和资源效率。分析揭示了用户对不同功能特性的满意度差异。

Conclusion: 研究提出了五项实践建议，为AI编码助手的改进提供了指导方向，帮助开发者更好地满足用户真实需求。通过分析真实用户评论获得的见解更能反映实际开发环境中的核心需求。

Abstract: This paper aims to explore fundamental questions in the era when AI coding
assistants like GitHub Copilot are widely adopted: what do developers truly
value and criticize in AI coding assistants, and what does this reveal about
their needs and expectations in real-world software development? Unlike
previous studies that conduct observational research in controlled and
simulated environments, we analyze extensive, first-hand user reviews of AI
coding assistants, which capture developers' authentic perspectives and
experiences drawn directly from their actual day-to-day work contexts. We
identify 1,085 AI coding assistants from the Visual Studio Code Marketplace.
Although they only account for 1.64% of all extensions, we observe a surge in
these assistants: over 90% of them are released within the past two years. We
then manually analyze the user reviews sampled from 32 AI coding assistants
that have sufficient installations and reviews to construct a comprehensive
taxonomy of user concerns and feedback about these assistants. We manually
annotate each review's attitude when mentioning certain aspects of coding
assistants, yielding nuanced insights into user satisfaction and
dissatisfaction regarding specific features, concerns, and overall tool
performance. Built on top of the findings-including how users demand not just
intelligent suggestions but also context-aware, customizable, and
resource-efficient interactions-we propose five practical implications and
suggestions to guide the enhancement of AI coding assistants that satisfy user
needs.

</details>


### [9] [From Fomo3D to Lottery DAPP: Analysis of Ethereum-Based Gambling Applications](https://arxiv.org/abs/2508.12303)
*Xu Long,Yishun Wang,Xiaoqi Li*

Main category: cs.SE

TL;DR: 本文分析了基于以太坊的赌博DApps的概念、原理、实现和前景，重点探讨了去中心化彩票平台如何通过智能合约确保公平性、透明度和自动化运营。


<details>
  <summary>Details</summary>
Motivation: 随着区块链技术的发展，基于以太坊的赌博去中心化应用（DApps）代表了在线赌博的新范式，需要系统研究其概念、原理和实现方式。

Method: 分析现有以太坊赌博DApp的技术原理、实现细节、运营状况和潜在漏洞，并详细阐述彩票DApps的智能合约实现过程，包括投注、开奖和奖金分配的全自动化。

Result: 去中心化彩票DApps通过智能合约自动化运营，消除了中心化控制，确保了公平性，降低了管理成本，提高了盈利能力和游戏透明度。

Conclusion: 随着区块链技术和智能合约的不断发展，彩票DApps凭借去中心化、自动化和透明度等优势，有望显著改变在线彩票行业，未来应用前景广阔。

Abstract: As blockchain technology advances, Ethereum based gambling decentralized
applications (DApps) represent a new paradigm in online gambling. This paper
examines the concepts, principles, implementation, and prospects of Ethereum
based gambling DApps. First, we outline the concept and operational principles
of gambling DApps. These DApps are blockchain based online lottery platforms.
They utilize smart contracts to manage the entire lottery process, including
issuance, betting, drawing, and prize distribution. Being decentralized,
lottery DApps operate without central oversight, unlike traditional lotteries.
This ensures fairness and eliminates control by any single entity. Automated
smart contract execution further reduces management costs, increases
profitability, and enhances game transparency and credibility. Next, we analyze
an existing Ethereum based gambling DApp, detailing its technical principles,
implementation, operational status, vulnerabilities, and potential solutions.
We then elaborate on the implementation of lottery DApps. Smart contracts
automate the entire lottery process including betting, drawing, and prize
distribution. Although developing lottery DApps requires technical expertise,
the expanding Ethereum ecosystem provides growing tools and frameworks,
lowering development barriers. Finally, we discuss current limitations and
prospects of lottery DApps. As blockchain technology and smart contracts
evolve, lottery DApps are positioned to significantly transform the online
lottery industry. Advantages like decentralization, automation, and
transparency will likely drive broader future adoption.

</details>


### [10] [Towards the Coordination and Verification of Heterogeneous Systems with Data and Time](https://arxiv.org/abs/2508.12325)
*Tim Kräuter,Adrian Rutle,Yngve Lamo,Harald König,Francisco Durán*

Main category: cs.SE

TL;DR: 基于重写逻辑的非侵入式协调框架，用于验证异构系统的正确性属性


<details>
  <summary>Details</summary>
Motivation: 现代软件系统通常由多个异构部分协调构成，需要一种方法来验证这些复杂系统的整体正确性

Method: 开发了一种非侵入式协调框架，使用语言扩展作为中央线程和领域特定语言来集成异构语言。通过摘要规则模板实体化为语言适配器，使用重写逻辑（Maude）实现

Result: 框架能够进行异构部分之间数据交换和包含实时能力的正式分析

Conclusion: 通过验证异构路轨交叉系统的某些正确性属性，证明了该框架的可用性和效果

Abstract: Modern software systems are often realized by coordinating multiple
heterogeneous parts, each responsible for specific tasks. These parts must work
together seamlessly to satisfy the overall system requirements. To verify such
complex systems, we have developed a non-intrusive coordination framework
capable of performing formal analysis of heterogeneous parts that exchange data
and include real-time capabilities. The framework utilizes a linguistic
extension, which is implemented as a central broker and a domain-specific
language for the integration of heterogeneous languages and coordination of
parts. Moreover, abstract rule templates are reified as language adapters for
non-intrusive communications with the broker. The framework is implemented
using rewriting logic (Maude), and its applicability is demonstrated by
verifying certain correctness properties of a heterogeneous road-rail crossing
system.

</details>


### [11] [Uncovering Systematic Failures of LLMs in Verifying Code Against Natural Language Specifications](https://arxiv.org/abs/2508.12358)
*Haolin Jin,Huaming Chen*

Main category: cs.SE

TL;DR: 大语言模型在代码实现与自然语言要求对齐评估中存在系统性失败，复杂提示工程反而增加误判率


<details>
  <summary>Details</summary>
Motivation: 识别LLM在判断代码是否符合自然语言要求时的可靠性问题，这对代码审查和任务完成至关重要

Method: 使用统一提示在广泛使用的测试集上评估代码正确性，测试不同提示策略的效果

Result: LLM经常将正确代码误判为"不符合要求"或包含缺陷，复杂提示工程技术会导致更高的误判率

Conclusion: 揭示了LLM在代码与要求匹配方面的未被识别的限制，提供了两种改进的提示策略和实践指南

Abstract: Large language models (LLMs) have become essential tools in software
development, widely used for requirements engineering, code generation and
review tasks. Software engineers often rely on LLMs to assess whether system
code implementation satisfy task requirements, thereby enhancing code
robustness and accuracy. However, it remains unclear whether LLMs can reliably
determine whether the code complies fully with the given task descriptions,
which is usually natural language specifications. In this paper, we uncover a
systematic failure of LLMs in evaluating whether code aligns with natural
language requirements. Specifically, with widely used benchmarks, we employ
unified prompts to judge code correctness. Our results reveal that LLMs
frequently misclassify correct code implementations as either ``not satisfying
requirements'' or containing potential defects. Surprisingly, more complex
prompting, especially when leveraging prompt engineering techniques involving
explanations and proposed corrections, leads to higher misjudgment rate, which
highlights the critical reliability issues in using LLMs as code review
assistants. We further analyze the root causes of these misjudgments, and
propose two improved prompting strategies for mitigation. For the first time,
our findings reveals unrecognized limitations in LLMs to match code with
requirements. We also offer novel insights and practical guidance for effective
use of LLMs in automated code review and task-oriented agent scenarios.

</details>


### [12] [Feature Request Analysis and Processing: Tasks, Techniques, and Trends](https://arxiv.org/abs/2508.12436)
*Feifei Niu,Chuanyi Li,Haosheng Zuo,Jionghan Wu,Xin Xia*

Main category: cs.SE

TL;DR: 对131篇关于功能需求研究的文献进行系统性综述，从需求工程活动角度分类研究主题，识别关键挑战和机遇


<details>
  <summary>Details</summary>
Motivation: 功能需求代表用户对软件产品的期望和需求，满足这些需求可以提升产品竞争力和用户满意度。近年来相关研究日益增多但主题分散，需要进行系统性分析以识别挑战和机遇

Method: 采用定义的过程和搜索协议，通过描述性统计和定性分析方法，对131篇主要研究进行系统综述和分类

Result: 从需求工程活动角度对研究进行分类，调查了开放工具和数据集，识别出确保功能需求质量、改进规范和验证、开发高质量基准等关键挑战

Conclusion: 功能需求研究领域存在重要挑战，需要关注质量保证、规范改进和基准开发等方面，为未来研究提供方向

Abstract: Feature requests are proposed by users to request new features or
enhancements of existing features of software products, which represent users'
wishes and demands. Satisfying users' demands can benefit the product from both
competitiveness and user satisfaction. Feature requests have seen a rise in
interest in the past few years and the amount of research has been growing.
However, the diversity in the research topics suggests the need for their
collective analysis to identify the challenges and opportunities so as to
promote new advances in the future. In this work, following a defined process
and a search protocol, we provide a systematic overview of the research area by
searching and categorizing relevant studies. We select and analyze 131 primary
studies using descriptive statistics and qualitative analysis methods. We
classify the studies into different topics and group them from the perspective
of requirements engineering activities. We investigate open tools as well as
datasets for future research. In addition, we identify several key challenges
and opportunities, such as: (1) ensuring the quality of feature requests, (2)
improving their specification and validation, and (3) developing high-quality
benchmarks for large language model-driven tasks.

</details>


### [13] [XAMT: Cross-Framework API Matching for Testing Deep Learning Libraries](https://arxiv.org/abs/2508.12546)
*Bin Duan,Ruican Dong,Naipeng Dong,Dan Dongseong Kim,Guowei Yang*

Main category: cs.SE

TL;DR: XAMT是一种跨框架模糊测试方法，通过匹配不同深度学习框架中功能等效的API进行差异测试，检测传统方法难以发现的跨后端一致性bug


<details>
  <summary>Details</summary>
Motivation: 深度学习库的bug会传播到下游关键应用，现有模糊测试技术通过跨硬件后端测试可能漏检那些在不同后端表现一致的bug

Method: 基于名称、描述和参数结构的相似性规则匹配API，对齐输入并应用方差引导的差异测试来检测bug

Result: 在5个流行框架中匹配了839个API和238个API组，检测到17个bug（12个已确认），发现了传统方法无法检测的跨后端一致性bug

Conclusion: XAMT为现有测试方法提供了补充，为深度学习库测试提供了新视角，特别擅长检测跨后端表现一致的bug

Abstract: Deep learning powers critical applications such as autonomous driving,
healthcare, and finance, where the correctness of underlying libraries is
essential. Bugs in widely used deep learning APIs can propagate to downstream
systems, causing serious consequences. While existing fuzzing techniques detect
bugs through intra-framework testing across hardware backends (CPU vs. GPU),
they may miss bugs that manifest identically across backends and thus escape
detection under these strategies. To address this problem, we propose XAMT, a
cross-framework fuzzing method that tests deep learning libraries by matching
and comparing functionally equivalent APIs across different frameworks. XAMT
matches APIs using similarity-based rules based on names, descriptions, and
parameter structures. It then aligns inputs and applies variance-guided
differential testing to detect bugs. We evaluated XAMT on five popular
frameworks, including PyTorch, TensorFlow, Keras, Chainer, and JAX. XAMT
matched 839 APIs and identified 238 matched API groups, and detected 17 bugs,
12 of which have been confirmed. Our results show that XAMT uncovers bugs
undetectable by intra-framework testing, especially those that manifest
consistently across backends. XAMT offers a complementary approach to existing
methods and offers a new perspective on the testing of deep learning libraries.

</details>


### [14] [Strengthening Programming Comprehension in Large Language Models through Code Generation](https://arxiv.org/abs/2508.12620)
*Xiaoning Ren,Qiang Hu,Wei Ma,Yan Li,Yao Zhang,Lingxiao Jiang,Yinxing Xue*

Main category: cs.SE

TL;DR: 提出了一种结合反事实代码增强和概念感知调优的框架，用于提升大语言模型对编程概念的理解能力


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型对编程概念（如数据流和控制流）的理解较浅，导致在需要深度推理的代码任务中表现脆弱，限制了在实际软件开发中的应用

Method: 采用反事实代码增强框架结合概念感知调优，引导大语言模型建立更强的概念理解

Result: 在多个模型和基准测试上的综合评估证明了所提方法的有效性

Conclusion: 该框架能够有效提升大语言模型对基础编程概念的理解，为解决模型在实际代码任务中的局限性提供了可行方案

Abstract: Large language models (LLMs) have recently shown impressive results on
diverse code-related tasks, benefiting from large-scale training and
instruction tuning. However, studies reveal that their grasp of fundamental
programming concepts, such as data flow and control flow, remains shallow,
leading to fragile performance when code requires deeper reasoning. This
limitation restricts the practical adoption of LLMs in real-world software
development. To address this issue, this work introduces a counterfactual code
augmentation framework combined with concept-aware tuning, designed to guide
LLMs toward stronger conceptual understanding. Comprehensive evaluation across
multiple models and benchmarks demonstrates the effectiveness of the proposed
approach.

</details>


### [15] [ChangePrism: Visualizing the Essence of Code Changes](https://arxiv.org/abs/2508.12649)
*Lei Chen,Michele Lanza,Shinpei Hayashi*

Main category: cs.SE

TL;DR: 提出ChangePrism工具，通过可视化方法帮助开发者更好地理解代码变更，提供概览视图和详细视图来展示不同类型的代码修改。


<details>
  <summary>Details</summary>
Motivation: 传统的代码差异对比方式（红绿高亮显示增删行）对开发者来说很繁琐，难以获得提交中所有变更的全面概览，特别是某些重要的代码变更类型需要与标准修改区分开来以增强代码理解。

Method: ChangePrism工具包含两个组件：提取组件从git历史记录中检索代码变更和相关信息，可视化组件提供提交中代码变更的概览视图和详细视图。概览视图展示跨提交的不同类型代码变更，详细视图显示每个提交中源代码的确切变更。

Result: 开发了一个新颖的可视化方法和支持工具，能够更好地理解和分析代码变更模式。

Conclusion: ChangePrism为代码审查和维护提供了更有效的可视化解决方案，帮助开发者更全面地理解代码变更的性质和影响。

Abstract: Understanding the changes made by developers when they submit a pull request
and/or perform a commit on a repository is a crucial activity in software
maintenance and evolution. The common way to review changes relies on examining
code diffs, where textual differences between two file versions are highlighted
in red and green to indicate additions and deletions of lines. This can be
cumbersome for developers, making it difficult to obtain a comprehensive
overview of all changes in a commit. Moreover, certain types of code changes
can be particularly significant and may warrant differentiation from standard
modifications to enhance code comprehension. We present a novel visualization
approach supported by a tool named ChangePrism, which provides a way to better
understand code changes. The tool comprises two components: extraction, which
retrieves code changes and relevant information from the git history, and
visualization, which offers both general and detailed views of code changes in
commits. The general view provides an overview of different types of code
changes across commits, while the detailed view displays the exact changes in
the source code for each commit.

</details>


### [16] [RUM: Rule+LLM-Based Comprehensive Assessment on Testing Skills](https://arxiv.org/abs/2508.12922)
*Yue Wang,Zhenyu Chen,Yuan Zhao,Chunrong Fang,Ziyuan Wang,Song Huang*

Main category: cs.SE

TL;DR: RUM方法结合规则和LLM，实现了软件测试技能的全面自动化评估，相比人工评估效率提升80.77%，成本降低97.38%


<details>
  <summary>Details</summary>
Motivation: META方法只能评估测试脚本的客观指标，缺乏对测试用例、测试报告等主观内容的自动评估能力

Method: 结合规则快速处理客观指标，利用大语言模型对测试用例文档、测试脚本和测试报告进行深度主观分析

Result: 评估效率提升80.77%，成本降低97.38%，同时保持高准确性和一致性

Conclusion: RUM方法提升了软件测试教育中技能评估的效率和可扩展性，为教师提供更全面客观的学生能力评估证据，促进个性化教学

Abstract: Over the past eight years, the META method has served as a multidimensional
testing skill assessment system in the National College Student Contest on
Software Testing, successfully assessing over 100,000 students' testing skills.
However, META is primarily limited to the objective assessment of test scripts,
lacking the ability to automatically assess subjective aspects such as test
case and test report. To address this limitation, this paper proposes RUM, a
comprehensive assessment approach that combines rules and large language models
(LLMs). RUM achieves a comprehensive assessment by rapidly processing objective
indicators through rules while utilizing LLMs for in-depth subjective analysis
of test case documents, test scripts, and test reports. The experimental
results show that compared to traditional manual testing skill assessment, RUM
improves assessment efficiency by 80.77\% and reduces costs by 97.38\%, while
maintaining high accuracy and consistency of assessment. By applying RUM on the
contest on software testing, we find that it not only enhances the efficiency
and scalability of skill assessment in software testing education, but also
provides teachers with more comprehensive and objective evidence for student
ability assessment, facilitating personalized teaching and learning. This study
offers new insights into the assessment of testing skills, which are expected
to promote further development in test process optimization and software
quality assurance.

</details>


### [17] [Investigating VR Accessibility Reviews for Users with Disabilities: A Qualitative Analysis](https://arxiv.org/abs/2508.13051)
*Yi Wang,Chetan Arora,Xiao Liu,Thuong Hoang,ZHengxin Zhang,Henry Been Lirn Duh,John Grundy*

Main category: cs.SE

TL;DR: 该研究分析了Meta和Steam商店中VR应用的用户评论，重点关注残障用户报告的可访问性问题，发现仅有0.078%的评论涉及可访问性，且这些评论普遍缺乏支持。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏对VR应用可访问性的全面调查，特别是针对残障用户的使用体验研究，需要填补这一研究空白。

Method: 从Meta和Steam商店中筛选了1,367,419条评论，涵盖40个顶级应用、20个最受欢迎应用和40个评分最低的VR应用，最终识别出1,076条涉及可访问性的评论。

Result: 在100个VR应用中发现16种不同类型的残障问题，分为6个类别，其中动作类游戏收到的可访问性相关评论最多。用户报告了导致可访问性问题的各种原因。

Conclusion: VR可访问性评论数量极少且普遍缺乏支持，表明VR应用在残障用户可访问性方面存在严重不足，需要更多关注和改进。

Abstract: Accessibility reviews provide valuable insights into both the limitations and
benefits experienced by users with disabilities when using virtual reality (VR)
applications. However, a comprehensive investigation into VR accessibility for
users with disabilities is still lacking. To fill this gap, this study analyzes
user reviews from the Meta and Steam stores of VR apps, focusing on the
reported issues affecting users with disabilities. We applied selection
criteria to 1,367,419 reviews from the top 40, the 20 most popular, and the 40
lowest-rated VR applications on both platforms. In total, 1,076 (0.078%) VR
accessibility reviews referenced various disabilities across 100 VR
applications. These applications were categorized into Action, Sports, Social,
Puzzle, Horror, and Simulation, with Action receiving the highest number of
accessibility related-reviews. We identified 16 different types of disabilities
across six categories. Furthermore, we examined the causes of accessibility
issues as reported by users with disabilities. Overall, VR accessibility
reviews were predominantly under-supported.

</details>


### [18] [Influencia de fatores organizacionais e sociais na etapa de levantamento de requisitos](https://arxiv.org/abs/2508.13134)
*Glauber da Rocha Balthazar,Marcia Ito*

Main category: cs.SE

TL;DR: 本文综述了需求工程中非技术因素（如情感、组织环境和社会背景）的研究现状，指出当前研究较少关注需求收集阶段的人文关系和行为因素。


<details>
  <summary>Details</summary>
Motivation: 需求收集是软件开发中最关键且脆弱的阶段，虽然需求工程技术不断发展以应对挑战，但现有研究很少考虑参与者的非技术性人文因素和行为关系。

Method: 通过对需求收集阶段相关研究的调查分析，重点关注那些考虑了情感、组织环境和社会背景等非技术因素的研究工作。

Result: 研究发现需求工程领域对人文因素的研究相对缺乏，需要更多关注非技术因素对需求收集过程的影响。

Conclusion: 需求工程研究需要更加重视人文维度，将情感、组织和社会因素纳入需求收集过程的考量范围，以提升需求工程的整体效果。

Abstract: The most critical and fragile stage of a software development project is
requirements gathering. Because of this, Requirements Engineering has been
evolving its techniques to minimize the challenges faced by Requirements
Analysts. However, few studies consider the humanistic relationships and
behaviors of those involved in this stage. This article presents a survey of
some studies conducted at this stage that consider non-technical factors such
as emotions, organizational environment, and social context.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [19] [Code Vulnerability Detection Across Different Programming Languages with AI Models](https://arxiv.org/abs/2508.11710)
*Hael Abdulhakim Ali Humran,Ferdi Sonmez*

Main category: cs.CR

TL;DR: 这篇论文研究了使用转换器模型（CodeBERT和CodeLlama）检测多编程语言代码中的安全漏洞，通过细调和集成学习方法实现了超过97%的准确率，但仍面临精确率下降和偏见性挑战。


<details>
  <summary>Details</summary>
Motivation: 传统的基于规则的静态分析工具在检测上下文依赖性错误时效果不佳且导致高假正率，需要更有效的AI方案来提高漏洞检测的准确性和可扩展性。

Method: 采用转换器模型（CodeBERT和CodeLlama），通过数据集收集、语言规范化、模型细调、集成学习和可解释AI技术，构建了一套动态细调漏洞代码检测方法。

Result: 实验结果显示细调后的CodeBERT模型准确率超过97%，在某些情况下甚至超过现有静态分析工具，并能够良好地沿用于不同编程语言和漏洞类型。

Conclusion: AI基于的漏洞检测方案在准确性和可扩展性方面展现出强大潜力，但仍需要通过混合模型和验证流程来提高精确率和解释性，以实现更高的可邻性和部署准备度。

Abstract: Security vulnerabilities present in a code that has been written in diverse
programming languages are among the most critical yet complicated aspects of
source code to detect. Static analysis tools based on rule-based patterns
usually do not work well at detecting the context-dependent bugs and lead to
high false positive rates. Recent developments in artificial intelligence,
specifically the use of transformer-based models like CodeBERT and CodeLlama,
provide light to this problem, as they show potential in finding such flaws
better. This paper presents the implementations of these models on various
datasets of code vulnerability, showing how off-the-shelf models can
successfully produce predictive capacity in models through dynamic fine-tuning
of the models on vulnerable and safe code fragments. The methodology comprises
the gathering of the dataset, normalization of the language, fine-tuning of the
model, and incorporation of ensemble learning and explainable AI. Experiments
show that a well-trained CodeBERT can be as good as or even better than some
existing static analyzers in terms of accuracy greater than 97%. Further study
has indicated that although language models can achieve close-to-perfect
recall, the precision can decrease. A solution to this is given by hybrid
models and validation procedures, which will reduce false positives. According
to the results, the AI-based solutions generalize to different programming
languages and classes of vulnerability. Nevertheless, robustness,
interpretability, and deployment readiness are still being developed. The
results illustrate the probabilities that AI will enhance the trustworthiness
in the usability and scalability of machine-learning-based detectors of
vulnerabilities.

</details>


### [20] [Enhancing GraphQL Security by Detecting Malicious Queries Using Large Language Models, Sentence Transformers, and Convolutional Neural Networks](https://arxiv.org/abs/2508.11711)
*Irash Perera,Hiranya Abeyrathne,Sanjeewa Malalgoda,Arshardh Ifthikar*

Main category: cs.CR

TL;DR: 这篇论文提出了一种基于AI的实时GraphQL恶意查询检测方法，结合静态分析和机器学习技术，能够高效检测SQL注入、OS命令注入、XSS等多种安全威胁。


<details>
  <summary>Details</summary>
Motivation: GraphQL灵活性带来了独特的安全漏洞，传统API安全机制无法有效防范。需要一种能够处理动态查询、防范DoS攻击和数据泄漏的新方案。

Method: 采用静态分析与机器学习相结合的方法：使用LLM进行动态模式配置，Sentence Transformers进行查询负载的上下文嵌入，以及CNN、Random Forest、多层感知机等分类器。系统优化包括ONNX Runtime和并行处理。

Result: 程序在负载下表现出高准确度，能够有效检测SQL注入、OS命令注入、XSS漏洞，同时成功缓解DoS和SSRF攻击尝试。

Conclusion: 这项研究提供了一种健壮且适应性强的解决方案，显著提升了GraphQL API的安全性，为应对动态查询带来的安全挑战贡献了重要技术。

Abstract: GraphQL's flexibility, while beneficial for efficient data fetching,
introduces unique security vulnerabilities that traditional API security
mechanisms often fail to address. Malicious GraphQL queries can exploit the
language's dynamic nature, leading to denial-of-service attacks, data
exfiltration through injection, and other exploits. Existing solutions, such as
static analysis, rate limiting, and general-purpose Web Application Firewalls,
offer limited protection against sophisticated, context-aware attacks. This
paper presents a novel, AI-driven approach for real-time detection of malicious
GraphQL queries. Our method combines static analysis with machine learning
techniques, including Large Language Models (LLMs) for dynamic schema-based
configuration, Sentence Transformers (SBERT and Doc2Vec) for contextual
embedding of query payloads, and Convolutional Neural Networks (CNNs), Random
Forests, and Multilayer Perceptrons for classification. We detail the system
architecture, implementation strategies optimized for production environments
(including ONNX Runtime optimization and parallel processing), and evaluate the
performance of our detection models and the overall system under load. Results
demonstrate high accuracy in detecting various threats, including SQL
injection, OS command injection, and XSS exploits, alongside effective
mitigation of DoS and SSRF attempts. This research contributes a robust and
adaptable solution for enhancing GraphQL API security.

</details>


### [21] [Privacy-Aware Detection of Fake Identity Documents: Methodology, Benchmark, and Improved Detection Methods (FakeIDet2)](https://arxiv.org/abs/2508.11716)
*Javier Muñoz-Haro,Ruben Tolosana,Ruben Vera-Rodriguez,Aythami Morales,Julian Fierrez*

Main category: cs.CR

TL;DR: 该研究提出了一种基于图像块的隐私保护假身份证检测方法，发布了包含90万+真实/假身份证图像块的公开数据库FakeIDet2-db，并开发了新的隐私感知假身份证检测系统FakeIDet2。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术的发展，攻击者能够创建极其逼真的物理和合成假身份证，而研究人员在训练假身份证检测器时面临真实数据稀缺的挑战，因为身份证文件具有敏感性，通常由用户和政府机构保密。

Method: 提出基于图像块的隐私保护方法，构建包含90万+图像块的公开数据库，开发隐私感知的假身份证检测系统FakeIDet2，并建立考虑物理和合成攻击的标准可复现基准。

Result: 创建了FakeIDet2-db数据库，包含从2000张身份证图像中提取的90万+真实/假身份证图像块，涵盖了不同智能手机传感器、光照条件、高度条件以及三种物理攻击类型。

Conclusion: 该研究为解决假身份证检测中的数据隐私和稀缺问题提供了有效的解决方案，通过图像块方法保护隐私的同时实现了高效的假身份证检测，为相关研究提供了重要的数据集和基准测试框架。

Abstract: Remote user verification in Internet-based applications is becoming
increasingly important nowadays. A popular scenario for it consists of
submitting a picture of the user's Identity Document (ID) to a service
platform, authenticating its veracity, and then granting access to the
requested digital service. An ID is well-suited to verify the identity of an
individual, since it is government issued, unique, and nontransferable.
However, with recent advances in Artificial Intelligence (AI), attackers can
surpass security measures in IDs and create very realistic physical and
synthetic fake IDs. Researchers are now trying to develop methods to detect an
ever-growing number of these AI-based fakes that are almost indistinguishable
from authentic (bona fide) IDs. In this counterattack effort, researchers are
faced with an important challenge: the difficulty in using real data to train
fake ID detectors. This real data scarcity for research and development is
originated by the sensitive nature of these documents, which are usually kept
private by the ID owners (the users) and the ID Holders (e.g., government,
police, bank, etc.). The main contributions of our study are: 1) We propose and
discuss a patch-based methodology to preserve privacy in fake ID detection
research. 2) We provide a new public database, FakeIDet2-db, comprising over
900K real/fake ID patches extracted from 2,000 ID images, acquired using
different smartphone sensors, illumination and height conditions, etc. In
addition, three physical attacks are considered: print, screen, and composite.
3) We present a new privacy-aware fake ID detection method, FakeIDet2. 4) We
release a standard reproducible benchmark that considers physical and synthetic
attacks from popular databases in the literature.

</details>


### [22] [Assessing User Privacy Leakage in Synthetic Packet Traces: An Attack-Grounded Approach](https://arxiv.org/abs/2508.11742)
*Minhao Jin,Hongyu He,Maria Apostolaki*

Main category: cs.CR

TL;DR: 提出了第一个基于攻击的隐私基准TraceBleed，通过对比学习和时间分块技术，在流量生成器的成员推理攻击中比基线方法提升172%，揭示了合成流量生成器的用户级信息泄露问题，并提出了防御方法TracePatch。


<details>
  <summary>Details</summary>
Motivation: 当前合成流量生成器虽然承诺隐私保护，但缺乏全面的隐私保证和实证验证，需要建立攻击驱动的基准来评估其隐私性。

Method: 提出了TraceBleed攻击方法，利用对比学习和时间分块技术从流量中提取行为指纹，进行成员推理攻击；同时提出了TracePatch防御方法，结合对抗性机器学习和SMT约束来减轻泄露。

Result: 研究发现：合成流量生成器泄露用户级信息；差分隐私要么无法阻止攻击，要么严重降低保真度；共享更多合成数据平均放大泄露59%；TraceBleed攻击比基线方法性能提升172%。

Conclusion: 合成流量生成器存在严重的隐私泄露风险，需要新的评估基准和防御机制，TraceBleed和TracePatch为解决这一问题提供了有效的方法。

Abstract: Current synthetic traffic generators (SynNetGens) promise privacy but lack
comprehensive guarantees or empirical validation, even as their fidelity
steadily improves. We introduce the first attack-grounded benchmark for
assessing the privacy of SynNetGens directly from the traffic they produce. We
frame privacy as membership inference at the traffic-source level--a realistic
and actionable threat for data holders. To this end, we present TraceBleed, the
first attack that exploits behavioral fingerprints across flows using
contrastive learning and temporal chunking, outperforming prior membership
inference baselines by 172%. Our large-scale study across GAN-, diffusion-, and
GPT-based SynNetGens uncovers critical insights: (i) SynNetGens leak user-level
information; (ii) differential privacy either fails to stop these attacks or
severely degrades fidelity; and (iii) sharing more synthetic data amplifies
leakage by 59% on average. Finally, we introduce TracePatch, the first
SynNetGen-agnostic defense that combines adversarial ML with SMT constraints to
mitigate leakage while preserving fidelity.

</details>


### [23] [AegisBlock: A Privacy-Preserving Medical Research Framework using Blockchain](https://arxiv.org/abs/2508.11797)
*Calkin Garg,Omar Rios Cruz,Tessa Andersen,Gaby G. Dagher,Donald Winiecki,Min Long*

Main category: cs.CR

TL;DR: AegisBlock是一个基于区块链的患者中心化医疗数据共享框架，在保护患者隐私的同时允许研究人员访问匿名化医疗记录


<details>
  <summary>Details</summary>
Motivation: 由于HIPAA等隐私法规要求，在医疗记录研究中必须维护患者隐私，需要一种既能保护患者匿名性又能确保数据可信度的解决方案

Method: 提出基于区块链的患者中心化访问控制框架，患者可以授权医疗数据访问，由矿工验证。研究人员提交时间范围查询请求，经患者批准后获得访问权限

Result: 实验评估显示AegisBlock在系统患者和医院数量方面具有良好的可扩展性，能够有效处理高达50%的恶意矿工

Conclusion: AegisBlock框架成功实现了在保护患者隐私的前提下，为研究人员提供可信医疗数据访问的可行解决方案

Abstract: Due to HIPAA and other privacy regulations, it is imperative to maintain
patient privacy while conducting research on patient health records. In this
paper, we propose AegisBlock, a patient-centric access controlled framework to
share medical records with researchers such that the anonymity of the patient
is maintained while ensuring the trustworthiness of the data provided to
researchers. AegisBlock allows for patients to provide access to their medical
data, verified by miners. A researcher submits a time-based range query to
request access to records from a certain patient, and upon patient approval,
access will be granted. Our experimental evaluation results show that
AegisBlock is scalable with respect to the number of patients and hospitals in
the system, and efficient with up to 50% of malicious miners.

</details>


### [24] [Securing Sideways: Thwarting Lateral Movement by Implementing Active Directory Tiering](https://arxiv.org/abs/2508.11812)
*Tyler Schroder,Sohee Kim Park*

Main category: cs.CR

TL;DR: 本文分析主动目录（AD）环境中的安全风险，提出通过分层结构限制权限提升和偶发移动的防护策略，以减少网络攻击损失。


<details>
  <summary>Details</summary>
Motivation: 计算设备和网络服务的发展促使组织采用集中式身份系统，但身份平面成为网络攻击的主要目标。美国2024年网络犯罪损失达到16.6亿美元，展现了解决AD安全问题的紧迫性。

Method: 提出通过分层结构（tiering）来限制权限提升和偶发移动的方法。结合技术指南和理论论证，并通过实际场景案例说明分层结构的有效性。

Result: 分层结构能够阻止偶发移动和高级网络攻击，降低劫持勾约的升级风险。该方法能够限制被窃取凭证的流动，防止重大权限提升和数据盗窃。

Conclusion: 分层结构是现代网络安全战略的关键组成部分，尽管不能单独作战。随着硬件和云服务的发展，安全专家需要与业务部门合作，开发能够自动准确分类设备到分层结构中的软件和框架。

Abstract: The advancement of computing equipment and the advances in services over the
Internet has allowed corporations, higher education, and many other
organizations to pursue the shared computing network environment. A requirement
for shared computing environments is a centralized identity system to
authenticate and authorize user access. An organization's digital identity
plane is a prime target for cyber threat actors. When compromised, identities
can be exploited to steal credentials, create unauthorized accounts, and
manipulate permissions-enabling attackers to gain control of the network and
undermine its confidentiality, availability, and integrity. Cybercrime losses
reached a record of 16.6 B in the United States in 2024. For organizations
using Microsoft software, Active Directory is the on-premises identity system
of choice. In this article, we examine the challenge of security compromises in
Active Directory (AD) environments and present effective strategies to prevent
credential theft and limit lateral movement by threat actors. Our proposed
approaches aim to confine the movement of compromised credentials, preventing
significant privilege escalation and theft. We argue that through our
illustration of real-world scenarios, tiering can halt lateral movement and
advanced cyber-attacks, thus reducing ransom escalation. Our work bridges a gap
in existing literature by combining technical guidelines with theoretical
arguments in support of tiering, positioning it as a vital component of modern
cybersecurity strategy even though it cannot function in isolation. As the
hardware advances and the cloud sourced services along with AI is advancing
with unprecedented speed, we think it is important for security experts and the
business to work together and start designing and developing software and
frameworks to classify devices automatically and accurately within the tiered
structure.

</details>


### [25] [Machine Learning-Based AES Key Recovery via Side-Channel Analysis on the ASCAD Dataset](https://arxiv.org/abs/2508.11817)
*Mukesh Poudel,Nick Rahimi*

Main category: cs.CR

TL;DR: 该论文研究使用机器学习技术（包括随机森林、支持向量机、CNN和ResNet）从AES加密实现的电磁侧信道泄漏中恢复部分密钥，通过特征重要性分析和Key Rank评估指标，证明了这些方法在密钥恢复方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 虽然AES和RSA等加密算法在数学上是安全的，但在物理设备上的实现会通过电磁辐射等侧信道泄漏信息，威胁算法的实际安全性。本研究旨在探索机器学习技术如何利用这种泄漏进行密钥恢复。

Method: 使用ASCAD固定密钥和可变密钥数据集（分别包含700和1400条电磁轨迹），将问题构建为256类分类任务，目标为第一轮S-box操作的输出。评估了随机森林、支持向量机、CNN和ResNet模型，并探索了基于随机森林特征重要性的降维方法，使用Key Rank指标进行评估。

Result: SVM和RF在全特征上表现不佳，但经过特征重要性分析降维后的RF（使用前100个特征）仅用约一半攻击轨迹就实现了Rank 0（成功密钥字节恢复）。CNN在固定密钥数据集上使用约65条攻击轨迹达到Rank 0。ResNet在大型复杂数据集上表现最佳，但在简单固定密钥数据集上效率不一定最优。

Conclusion: CNN、ResNet和特征选择的RF模型结合Key Rank评估指标，是侧信道密钥恢复的有效工具，证实了加密实现的实际脆弱性。机器学习技术可以成功利用侧信道泄漏来破坏理论上安全的加密算法。

Abstract: Cryptographic algorithms like AES and RSA are widely used and they are
mathematically robust and almost unbreakable but its implementation on physical
devices often leak information through side channels, such as electromagnetic
(EM) emissions, potentially compromising said theoretically secure algorithms.
This paper investigates the application of machine learning (ML) techniques and
Deep Learning models to exploit such leakage for partial key recovery. We use
the public ASCAD `fixed' and `variable' key dataset, containing 700 and 1400 EM
traces respectively from an AES-128 implementation on an 8-bit microcontroller.
The problem is framed as a 256-class classification task where we target the
output of the first-round S-box operation, which is dependent on a single key
byte. We evaluate standard classifiers (Random Forest (RF), Support Vector
Machine (SVM)), a Convolutional Neural Network(CNN) and a Residual Neural
Network(ResNet). We also explore the utility of RF-based feature importance for
dimensionality reduction. Crucially, we employ this domain-specific Key Rank
metric for evaluation, showing its necessity over standard classification
accuracy. Our results show that SVM and RF on full features perform poorly in
key ranking. However, RF trained on reduced (top 100) identified via importance
analysis achieves Rank 0 (successful key byte recovery) using almost half the
attack traces. The implemented CNN also achieves Rank 0 efficiently using
approximately 65 attack traces for the fixed-key dataset. The ResNets perform
best on large and complex datasets but may not always be the best choice for
simple fixed key dataset in terms of efficiency. Thus we conclude that models,
particularly CNNs, ResNets and feature-selected RF, coupled with the Key Rank
metric, are an effective tool for side-channel key recovery, confirming the
practical vulnerability of the cryptographic implementations.

</details>


### [26] [Deciphering the Interplay between Attack and Protection Complexity in Privacy-Preserving Federated Learning](https://arxiv.org/abs/2508.11907)
*Xiaojin Zhang,Mingcong Xu,Yiming Li,Wei Chen,Qiang Yang*

Main category: cs.CR

TL;DR: 本文提出了一个理论框架来分析联邦学习中梯度反转攻击与隐私保护的复杂关系，定义了攻击复杂性和保护复杂性的概念，并推导了严格的理论界限，揭示了隐私保证、系统效用和攻防努力之间的基本权衡。


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽然能保护数据隐私，但容易受到梯度反转攻击的威胁，需要建立强大的隐私保护机制来应对这一挑战。

Method: 引入最大贝叶斯隐私(MBP)方法，正式定义攻击复杂性(重建私有数据所需的最小计算和数据资源)和保护复杂性(隐私机制引入的预期失真)，推导保护复杂性的严格理论界限。

Result: 建立了保护复杂性随模型维度和隐私预算变化的缩放规律，以及攻击复杂性对隐私泄漏、梯度失真、模型维度和隐私级别的依赖关系的全面界限。

Conclusion: 该框架为设计更安全高效的联邦学习系统提供了关键见解，量化揭示了隐私保证、系统效用和攻防努力之间的基本权衡关系。

Abstract: Federated learning (FL) offers a promising paradigm for collaborative model
training while preserving data privacy. However, its susceptibility to gradient
inversion attacks poses a significant challenge, necessitating robust privacy
protection mechanisms. This paper introduces a novel theoretical framework to
decipher the intricate interplay between attack and protection complexities in
privacy-preserving FL. We formally define "Attack Complexity" as the minimum
computational and data resources an adversary requires to reconstruct private
data below a given error threshold, and "Protection Complexity" as the expected
distortion introduced by privacy mechanisms. Leveraging Maximum Bayesian
Privacy (MBP), we derive tight theoretical bounds for protection complexity,
demonstrating its scaling with model dimensionality and privacy budget.
Furthermore, we establish comprehensive bounds for attack complexity, revealing
its dependence on privacy leakage, gradient distortion, model dimension, and
the chosen privacy level. Our findings quantitatively illuminate the
fundamental trade-offs between privacy guarantees, system utility, and the
effort required for both attacking and defending. This framework provides
critical insights for designing more secure and efficient federated learning
systems.

</details>


### [27] [WebGeoInfer: A Structure-Free and Multi-Stage Framework for Geolocation Inference of Devices Exposing Information](https://arxiv.org/abs/2508.11913)
*Huipeng Yang,Li Yang,Lichuan Ma,Lu Zhou,Junbo Jia,Anyuan Sang,Xinyue Wang*

Main category: cs.CR

TL;DR: WebGeoInfer是一个无需结构化的地理位置推断框架，通过多阶段信息增强技术从远程管理设备网页中自动提取地理位置信息，准确率在国家、城市和街道级别分别达到96.96%、88.05%和79.70%。


<details>
  <summary>Details</summary>
Motivation: 远程管理设备虽然便于基础设施监控，但暴露的地理信息带来了重大安全风险。由于网页界面信息格式不统一、风格各异且地理信息不完整，自动发现地理位置信息具有挑战性。

Method: 采用多阶段信息增强方法：首先聚类相似的设备网页并分析集群间差异来提取潜在地理信息；然后通过搜索引擎增强和大型语言模型挖掘，从识别出的信息中提取地理坐标。

Result: 成功推断出94个国家、2,056个城市的5,435台设备位置，在国家、城市和街道级别的准确率分别为96.96%、88.05%和79.70%。

Conclusion: WebGeoInfer框架有效解决了从非结构化设备管理页面中自动提取地理位置信息的挑战，为网络安全监管提供了重要工具。

Abstract: Remote management devices facilitate critical infrastructure monitoring for
administrators but simultaneously increase asset exposure. Sensitive
geographical information overlooked in exposed device management pages poses
substantial security risks. Therefore, identifying devices that reveal location
information due to administrator negligence is crucial for cybersecurity
regulation. Despite the rich information exposed by web interfaces of remote
management devices, automatically discovering geographical locations remains
challenging due to unstructured formats, varying styles, and incomplete
geographical details.
  This study introduces WebGeoInfer, a structure-free geolocation inference
framework utilizing multi-stage information enhancement. WebGeoInfer clusters
similar device web pages and analyzes inter-cluster differences to extract
potential geographical information, bypassing structural limitations. Through
search engine enhancement and Large Language Models mining, the framework
extracts geographical coordinates from identified information. WebGeoInfer
successfully inferred locations for 5,435 devices across 94 countries and 2,056
cities, achieving accuracy rates of 96.96\%, 88.05\%, and 79.70\% at country,
city, and street levels, respectively.

</details>


### [28] [Optimizing Token Choice for Code Watermarking: A RL Approach](https://arxiv.org/abs/2508.11925)
*Zhimeng Guo,Huaisheng Zhu,Siyuan Xu,Hangfan Zhang,Teng Xiao,Minhao Cheng*

Main category: cs.CR

TL;DR: CodeTracer是一个基于强化学习的自适应代码水印框架，通过策略驱动的token选择偏差来嵌入水印，在保持代码功能性的同时实现可检测的水印嵌入。


<details>
  <summary>Details</summary>
Motivation: 检测LLM生成的代码需要能够在高度结构化、语法约束的环境中工作的水印系统，现有方法难以在保持代码功能性的同时嵌入可检测的水印。

Method: 采用强化学习训练范式，使用参数化模型在next-token预测时智能偏置token选择，通过Gumbel Top-k重参数化实现离散水印决策的梯度优化，设计综合奖励系统整合执行反馈和水印嵌入信号。

Result: 广泛的比较评估显示CodeTracer在水印可检测性和生成代码功能性保持方面显著优于最先进的基线方法。

Conclusion: CodeTracer提供了一个有效的代码水印解决方案，成功解决了在保持代码功能完整性的同时嵌入可检测水印的挑战，为LLM生成代码的检测提供了可靠的技术基础。

Abstract: The need for detecting LLM-generated code necessitates watermarking systems
capable of operating within its highly structured and syntactically constrained
environment. To address this, we introduce CodeTracer, an innovative adaptive
code watermarking framework underpinned by a novel reinforcement learning
training paradigm. At its core, CodeTracer features a policy-driven approach
that utilizes a parameterized model to intelligently bias token choices during
next-token prediction. This strategy ensures that embedded watermarks maintain
code functionality while exhibiting subtle yet statistically detectable
deviations from typical token distributions. To facilitate policy learning, we
devise a comprehensive reward system that seamlessly integrates execution
feedback with watermark embedding signals, balancing process-level and
outcome-level rewards. Additionally, we employ Gumbel Top-k reparameterization
to enable gradient-based optimization of discrete watermarking decisions.
Extensive comparative evaluations demonstrate CodeTracer's significant
superiority over state-of-the-art baselines in both watermark detectability and
the preservation of generated code's functionality.

</details>


### [29] [The Passwordless Authentication with Passkey Technology from an Implementation Perspective](https://arxiv.org/abs/2508.11928)
*Lien Tran,Boyuan Zhang,Ratchanon Pawanja,Rashid Hussain Khokhar*

Main category: cs.CR

TL;DR: 本文分析了无密码认证技术的实现，重点介绍了Passkey技术的优势和实施考虑，并与TOTP机制进行对比评估。


<details>
  <summary>Details</summary>
Motivation: 密码安全性不足，需要探索更可靠的无密码认证方案，以应对密码泄漏、网络诈骗和暴力破解等安全风险。

Method: 通过实现角度深入研究TOTP和Passkey机制，分析其技术实施细节，提出系统集成考虑因素，确保在保持安全性的同时优化用户体验和性能。

Result: 证明Passkey技术在安全性方面显著优于TOTP，具有更高的防范网络诈骗和密码泄漏的能力，同时能够在实际应用中实现安全性、易用性和性能的平衡。

Conclusion: Passkey技术作为一种有前景的无密码认证方案，具有更高的安全性和广泛采用潜力，建议在安全认证系统中积极推广应用。

Abstract: With the rise of sophisticated authentication bypass techniques, passwords
are no longer considered a reliable method for securing authentication systems.
In recent years, new authentication technologies have shifted from traditional
password-based logins to passwordless security. Among these, Time-Based
One-Time Passwords (TOTP) remain one of the most widely used mechanisms, while
Passkeys are emerging as a promising alternative with growing adoption. This
paper highlights the key techniques used during the implementation of the
authentication system with Passkey technology. It also suggests considerations
for integrating components during system development to ensure that users can
securely access their accounts with minimal complexity, while still meeting the
requirements of a robust authentication system that balances security,
usability, and performance. Additionally, by examining TOTP and Passkey
mechanisms from an implementation perspective, this work not only addresses
major security concerns such as password leaks, phishing attacks, and
susceptibility to brute-force attacks, but also evaluates the feasibility and
effectiveness of these mechanisms in real-world implementations. This paper
demonstrates the superior security of Passkey technology and its potential for
broader adoption in secure authentication systems.

</details>


### [30] [Design and Implementation of a Controlled Ransomware Framework for Educational Purposes Using Flutter Cryptographic APIs on Desktop PCs and Android Devices](https://arxiv.org/abs/2508.11939)
*James Gu,Ahmed Sartaj,Mohammed Akram Taher Khan,Rashid Hussain Khokhar*

Main category: cs.CR

TL;DR: 这是一个用于教育目的的劫持软件研究，利用Python和Flutter开发了可控的劫持软件框架，包含Android版本，通过多重安全措施确保安全实验。


<details>
  <summary>Details</summary>
Motivation: 为了教育和培训网络安全专业人员，需要一个安全的环境来研究劫持软件的功能和行为，受WannaCry劫持软件的启发。

Method: 使用Python原生加密API和Flutter/Dart开发了两个版本的劫持软件框架，采用开源加密库，包含文件加密、密钥管理、受害者交互等功能，设置了目录限制、RSA私钥提供、文件类型限制等安全保护措施。

Result: 开发了一个完整的劫持软件框架，支持Python和Android平台，能够模拟WannaCry的行为，并作为开源项目发布，便于教学和研究使用。

Conclusion: 该框架为网络安全教育提供了一个安全、可控的实验环境，有助于培养新一代网络安全专业人才，并为劫持软件防护研究提供了实践工具。

Abstract: This study focuses on the creation and implementation of ransomware for
educational purposes that leverages Python's native cryptographic APIs in a
controlled environment. Additionally, an Android version of the framework is
implemented using Flutter and Dart. For both versions, open-source
cryptographic libraries are utilized. With this framework, researchers can
systematically explore the functionalities of ransomware, including file
encryption processes, cryptographic key management, and victim interaction
dynamics. To ensure safe experimentation, multiple safeguards are incorporated,
such as the ability to restrict the encryption process to a specific directory,
providing the RSA private key for immediate decryption, and narrowing the scope
of targetable files to a carefully curated list (.txt, .jpg, .csv, .doc). This
paper draws inspiration from the infamous WannaCry ransomware and aims to
simulate its behaviour on Android devices. By making the codebase open-source,
it enables users to study, modify, and extend the program for pedagogical
purposes and offers a hands-on tool that can be used to train the next
generation of cybersecurity professionals.

</details>


### [31] [ToxiEval-ZKP: A Structure-Private Verification Framework for Molecular Toxicity Repair Tasks](https://arxiv.org/abs/2508.12035)
*Fei Lin,Tengchao Zhang,Ziyang Gong,Fei-Yue Wang*

Main category: cs.CR

TL;DR: ToxiEval-ZKP是一个结构隐私验证框架，首次将零知识证明机制引入分子毒性修复任务的评估过程，允许在不泄露分子结构的情况下验证生成分子是否符合多维毒性修复标准。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在分子科学等高风险领域表现出色，但其输出的可验证性和结构隐私问题尚未解决，特别是在分子毒性修复任务中需要保护分子结构隐私的同时确保验证可靠性。

Method: 设计了一个通用电路，兼容分类和回归任务，包含评估逻辑、基于Poseidon的承诺哈希和基于nullifier的重放预防机制，构建完整的端到端ZK验证系统。

Result: 实验结果表明，ToxiEval-ZKP在完全结构不可见的情况下实现了充分验证，具有强大的电路效率、安全性和适应性。

Conclusion: 该框架为生成式科学任务中的可信评估开辟了新的范式，解决了结构隐私和可验证性的双重挑战。

Abstract: In recent years, generative artificial intelligence (GenAI) has demonstrated
remarkable capabilities in high-stakes domains such as molecular science.
However, challenges related to the verifiability and structural privacy of its
outputs remain largely unresolved. This paper focuses on the task of molecular
toxicity repair. It proposes a structure-private verification framework -
ToxiEval-ZKP - which, for the first time, introduces zero-knowledge proof (ZKP)
mechanisms into the evaluation process of this task. The system enables model
developers to demonstrate to external verifiers that the generated molecules
meet multidimensional toxicity repair criteria, without revealing the molecular
structures themselves. To this end, we design a general-purpose circuit
compatible with both classification and regression tasks, incorporating
evaluation logic, Poseidon-based commitment hashing, and a nullifier-based
replay prevention mechanism to build a complete end-to-end ZK verification
system. Experimental results demonstrate that ToxiEval-ZKP facilitates adequate
validation under complete structural invisibility, offering strong circuit
efficiency, security, and adaptability, thereby opening up a novel paradigm for
trustworthy evaluation in generative scientific tasks.

</details>


### [32] [Mitigating Jailbreaks with Intent-Aware LLMs](https://arxiv.org/abs/2508.12072)
*Wei Jie Yeo,Ranjan Satapathy,Erik Cambria*

Main category: cs.CR

TL;DR: Intent-FT是一种简单轻量的微调方法，通过训练LLM在响应前推断指令的潜在意图，显著提升模型对对抗性攻击的鲁棒性，同时保持通用能力。


<details>
  <summary>Details</summary>
Motivation: 尽管进行了广泛的安全调优，大语言模型仍然容易受到对抗性指令的越狱攻击，这反映了安全性和任务性能之间的持续权衡。

Method: 通过在针对性对抗指令集上进行微调，训练LLM在响应前明确推断指令的底层意图，使模型能够将意图推断泛化到未见过的攻击。

Result: Intent-FT持续缓解所有评估的攻击类别，没有单一攻击成功率超过50%，而现有防御仅部分有效。该方法保持模型的通用能力，减少对包含表面有害关键词的良性指令的过度拒绝。

Conclusion: 该方法使模型能够准确识别对抗性攻击中的隐藏有害意图，并且这些学习到的意图可以有效地转移到增强普通模型防御中。

Abstract: Despite extensive safety-tuning, large language models (LLMs) remain
vulnerable to jailbreak attacks via adversarially crafted instructions,
reflecting a persistent trade-off between safety and task performance. In this
work, we propose Intent-FT, a simple and lightweight fine-tuning approach that
explicitly trains LLMs to infer the underlying intent of an instruction before
responding. By fine-tuning on a targeted set of adversarial instructions,
Intent-FT enables LLMs to generalize intent deduction to unseen attacks,
thereby substantially improving their robustness. We comprehensively evaluate
both parametric and non-parametric attacks across open-source and proprietary
models, considering harmfulness from attacks, utility, over-refusal, and impact
against white-box threats. Empirically, Intent-FT consistently mitigates all
evaluated attack categories, with no single attack exceeding a 50\% success
rate -- whereas existing defenses remain only partially effective. Importantly,
our method preserves the model's general capabilities and reduces excessive
refusals on benign instructions containing superficially harmful keywords.
Furthermore, models trained with Intent-FT accurately identify hidden harmful
intent in adversarial attacks, and these learned intentions can be effectively
transferred to enhance vanilla model defenses.

</details>


### [33] [PP-STAT: An Efficient Privacy-Preserving Statistical Analysis Framework using Homomorphic Encryption](https://arxiv.org/abs/2508.12093)
*Hyunmin Choi*

Main category: cs.CR

TL;DR: PP-STAT是一个基于同态加密的高效隐私保护统计分析框架，支持多种高级统计指标的安全计算，通过优化技术显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 随着云计算的广泛采用，将统计分析外包给第三方平台的需求快速增长，但处理医疗记录和金融信息等敏感数据在云环境中引发了严重的隐私担忧。

Method: 提出PP-STAT框架，采用同态加密技术直接在加密数据上进行计算。引入两个关键优化：1)基于切比雪夫的近似策略初始化逆平方根操作；2)预归一化缩放技术，通过将常数缩放因子折叠到均值和方差计算中来减少乘法深度。

Result: 在真实数据集上的评估显示，PP-STAT实现了高数值精度，平均相对误差(MRE)低于2.4x10-4。加密的吸烟者属性与费用之间的皮尔逊相关性达到0.7873，MRE为2.86x10-4。

Conclusion: PP-STAT在隐私敏感领域实现了安全精确的统计分析，具有实际应用价值，显著降低了计算开销并最小化了昂贵的自举程序数量。

Abstract: With the widespread adoption of cloud computing, the need for outsourcing
statistical analysis to third-party platforms is growing rapidly. However,
handling sensitive data such as medical records and financial information in
cloud environments raises serious privacy concerns. In this paper, we present
PP-STAT, a novel and efficient Homomorphic Encryption (HE)-based framework for
privacy-preserving statistical analysis. HE enables computations to be
performed directly on encrypted data without revealing the underlying
plaintext. PP-STAT supports advanced statistical measures, including Z-score
normalization, skewness, kurtosis, coefficient of variation, and Pearson
correlation coefficient, all computed securely over encrypted data. To improve
efficiency, PP-STAT introduces two key optimizations: (1) a Chebyshev-based
approximation strategy for initializing inverse square root operations, and (2)
a pre-normalization scaling technique that reduces multiplicative depth by
folding constant scaling factors into mean and variance computations. These
techniques significantly lower computational overhead and minimize the number
of expensive bootstrapping procedures. Our evaluation on real-world datasets
demonstrates that PP-STAT achieves high numerical accuracy, with mean relative
error (MRE) below 2.4x10-4. Notably, the encrypted Pearson correlation between
the smoker attribute and charges reaches 0.7873, with an MRE of 2.86x10-4.
These results confirm the practical utility of PP-STAT for secure and precise
statistical analysis in privacy-sensitive domains.

</details>


### [34] [AUTOVR: Automated UI Exploration for Detecting Sensitive Data Flow Exposures in Virtual Reality Apps](https://arxiv.org/abs/2508.12187)
*John Y. Kim,Chaoshun Zuo,Yanjie Zhao,Zhiqiang Lin*

Main category: cs.CR

TL;DR: AUTOVR是一个针对Unity引擎VR应用的自动化UI探索和用户事件测试框架，通过分析应用内部二进制文件来揭示隐藏事件并解决生成事件依赖关系，相比Android Monkey工具能触发更多敏感数据暴露，显著提升VR应用隐私保护。


<details>
  <summary>Details</summary>
Motivation: 随着Meta Quest VR平台的普及和VR应用数量增长，当前缺乏强大的无头工具来进行用户界面探索和用户事件测试，需要专门的自动化测试框架来解决VR应用独特的输入需求。

Method: AUTOVR通过分析VR应用的内部二进制文件来揭示隐藏事件，解析生成事件依赖关系，并利用这些信息对基于Unity引擎的VR应用进行全面探索。

Result: 与广泛使用的Android Monkey工具相比，AUTOVR在敏感数据暴露方面表现优异，触发数量级更多的敏感数据暴露事件，显著增强了VR应用的隐私保护能力。

Conclusion: AUTOVR框架为VR应用提供了有效的自动化测试解决方案，能够更好地发现和解决隐私安全问题，填补了当前VR应用测试工具的空白。

Abstract: The rise of Virtual Reality (VR) has provided developers with an
unprecedented platform for creating games and applications (apps) that require
distinct inputs, different from those of conventional devices like smartphones.
The Meta Quest VR platform, driven by Meta, has democratized VR app publishing
and attracted millions of users worldwide. However, as the number of published
apps grows, there is a notable lack of robust headless tools for user interface
(UI) exploration and user event testing. To address this need, we present
AUTOVR, an automatic framework for dynamic UI and user event interaction in VR
apps built on the Unity Engine. Unlike conventional Android and GUI testers,
AUTOVR analyzes the app's internal binary to reveal hidden events, resolves
generative event dependencies, and utilizes them for comprehensive exploration
of VR apps. Using sensitive data exposure as a performance metric, we compare
AUTOVR with Android Monkey, a widely used headless Android GUI stress testing
tool. Our empirical evaluation demonstrates AUTOVR's superior performance,
triggering an order of magnitude of more sensitive data exposures and
significantly enhancing the privacy of VR apps.

</details>


### [35] [Ethereum Crypto Wallets under Address Poisoning: How Usable and Secure Are They?](https://arxiv.org/abs/2508.12107)
*Shixuan Guan,Kai Li*

Main category: cs.CR

TL;DR: 这篇论文通过模拟地址毒化攻击，系统性评估了53个以太坊加密钱包的安全性和可用性，发现大部分钱包在防范地址毒化攻击方面存在显著缺口。


<details>
  <summary>Details</summary>
Motivation: 地址毒化攻击已导致过百万美元损失，而以太坊加密钱包在防范这种攻击中发挥着关键作用。研究人员想要了解当前钱包是否已经采取有效的防御措施。

Method: 设计实验模拟地址毒化攻击，对53个流行的以太坊加密钱包进行系统性的可用性和安全性评估。

Result: 12个钱包存在与交易活动提供商的通信故障，16个钱包显示假代币骗子转账，仅3个钱包在用户尝试向骗子地址转账时发出明确警告。大部分钱包依赖交易活动提供商来过滤骗子交易。

Conclusion: 以太坊加密钱包开发社区需要做出更多努力来提升用户体验和安全标准，以有效防范地址毒化攻击。研究成果已得到开发者社区的认可并正在开发解决方案。

Abstract: Blockchain address poisoning is an emerging phishing attack that crafts
"similar-looking" transfer records in the victim's transaction history, which
aims to deceive victims and lure them into mistakenly transferring funds to the
attacker. Recent works have shown that millions of Ethereum users were targeted
and lost over 100 million US dollars.
  Ethereum crypto wallets, serving users in browsing transaction history and
initiating transactions to transfer funds, play a central role in deploying
countermeasures to mitigate the address poisoning attack. However, whether they
have done so remains an open question. To fill the research void, in this
paper, we design experiments to simulate address poisoning attacks and
systematically evaluate the usability and security of 53 popular Ethereum
crypto wallets. Our evaluation shows that there exist communication failures
between 12 wallets and their transaction activity provider, which renders them
unable to download the users' transaction history. Besides, our evaluation also
shows that 16 wallets pose a high risk to their users due to displaying fake
token phishing transfers. Moreover, our further analysis suggests that most
wallets rely on transaction activity providers to filter out phishing
transfers. However, their phishing detection capability varies. Finally, we
found that only three wallets throw an explicit warning message when users
attempt to transfer to the phishing address, implying a significant gap within
the broader Ethereum crypto wallet community in protecting users from address
poisoning attacks.
  Overall, our work shows that more efforts are needed by the Ethereum crypto
wallet developer community to achieve the highest usability and security
standard. Our bug reports have been acknowledged by the developer community,
who are currently developing mitigation solutions.

</details>


### [36] [Systematic Analysis of MCP Security](https://arxiv.org/abs/2508.12538)
*Yongjian Guo,Puzhuo Liu,Wanlun Ma,Zehang Deng,Xiaogang Zhu,Peng Di,Xi Xiao,Sheng Wen*

Main category: cs.CR

TL;DR: MCPLIB攻击库系统分析了Model Context Protocol的安全漏洞，提出了31种攻击方法分类，揭示了AI代理对工具描述的盲目信任等关键安全问题


<details>
  <summary>Details</summary>
Motivation: MCP协议虽然增强了AI代理的功能性，但也引入了工具投毒攻击等重大安全漏洞，当前学术研究对此关注不足，缺乏系统性的定量分析

Method: 构建MCP攻击库MCPLIB，将攻击方法分为四类：直接工具注入、间接工具注入、恶意用户攻击和LLM固有攻击，共实现31种具体攻击方法并进行定量效能分析

Result: 实验揭示了MCP的关键漏洞：代理盲目依赖工具描述、对基于文件的攻击敏感、共享上下文链式攻击易发、难以区分外部数据和可执行命令

Conclusion: 该研究为MCP安全机制提供了基础框架，强调了制定强大防御策略和知情MCP设计的紧迫性，支持MCP生态系统的安全演进

Abstract: The Model Context Protocol (MCP) has emerged as a universal standard that
enables AI agents to seamlessly connect with external tools, significantly
enhancing their functionality. However, while MCP brings notable benefits, it
also introduces significant vulnerabilities, such as Tool Poisoning Attacks
(TPA), where hidden malicious instructions exploit the sycophancy of large
language models (LLMs) to manipulate agent behavior. Despite these risks,
current academic research on MCP security remains limited, with most studies
focusing on narrow or qualitative analyses that fail to capture the diversity
of real-world threats. To address this gap, we present the MCP Attack Library
(MCPLIB), which categorizes and implements 31 distinct attack methods under
four key classifications: direct tool injection, indirect tool injection,
malicious user attacks, and LLM inherent attack. We further conduct a
quantitative analysis of the efficacy of each attack. Our experiments reveal
key insights into MCP vulnerabilities, including agents' blind reliance on tool
descriptions, sensitivity to file-based attacks, chain attacks exploiting
shared context, and difficulty distinguishing external data from executable
commands. These insights, validated through attack experiments, underscore the
urgency for robust defense strategies and informed MCP design. Our
contributions include 1) constructing a comprehensive MCP attack taxonomy, 2)
introducing a unified attack framework MCPLIB, and 3) conducting empirical
vulnerability analysis to enhance MCP security mechanisms. This work provides a
foundational framework, supporting the secure evolution of MCP ecosystems.

</details>


### [37] [Substituting Proof of Work in Blockchain with Training-Verified Collaborative Model Computation](https://arxiv.org/abs/2508.12138)
*Mohammad Ishzaz Asif Rafid,Morsalin Sakib*

Main category: cs.CR

TL;DR: 用基于云的机器学习训练框架替代比特币PoW挖矿，将算力用于有社会价值的模型训练而非哈希计算


<details>
  <summary>Details</summary>
Motivation: 解决比特币PoW机制的高能耗和硬件效率低下问题，将挖矿算力转向有实际价值的计算任务

Method: 提出混合架构：矿工贡献算力训练分布式机器学习模型，中央服务器评估贡献（参数数量和损失减少），通过加权抽选确定区块打包权

Result: 系统保持了区块链完整性（使用数字签名和SHA-256哈希），同时将能源消耗转化为有社会价值的生产性计算

Conclusion: 该方法成功解决了传统挖矿的可持续性问题，将安全激励与实际计算进步对齐，为区块链挖矿提供了更环保高效的替代方案

Abstract: Bitcoin's Proof of Work (PoW) mechanism, while central to achieving
decentralized consensus, has long been criticized for excessive energy use and
hardware inefficiencies \cite{devries2018bitcoin, truby2018decarbonizing}. This
paper introduces a hybrid architecture that replaces Bitcoin's traditional PoW
with a centralized, cloud-based collaborative training framework. In this
model, miners contribute computing resources to train segments of horizontally
scaled machine learning models on preprocessed datasets, ensuring privacy and
generating meaningful outputs \cite{li2017securing}. A central server evaluates
contributions using two metrics: number of parameters trained and reduction in
model loss during each cycle. At the end of every cycle, a weighted lottery
selects the winning miner, who receives a digitally signed certificate. This
certificate serves as a verifiable substitute for PoW and grants the right to
append a block to the blockchain \cite{nakamoto2008bitcoin}. By integrating
digital signatures and SHA-256 hashing \cite{nist2015sha}, the system preserves
blockchain integrity while redirecting energy toward productive computation.
The proposed approach addresses the sustainability concerns of traditional
mining by converting resource expenditure into socially valuable work, aligning
security incentives with real-world computational progress.

</details>


### [38] [Attack Graph Generation on HPC Clusters](https://arxiv.org/abs/2508.12161)
*Ming Li,John Hale*

Main category: cs.CR

TL;DR: 使用高性能计算集群来加速攻击图生成，解决状态空间爆炸问题


<details>
  <summary>Details</summary>
Motivation: 攻击图是分析网络安全的重要工具，但随着网络规模和漏洞数量增加，攻击图的生成面临时间和内存消耗巨大的状态空间爆炸问题

Method: 提出使用高性能计算(HPC)集群来实现攻击图生成器，通过分布式计算来平衡处理速度和内存需求

Result: 通过实验评估性能，证明集群环境能够有效解决攻击图生成中的速度慢和高内存需求问题

Conclusion: HPC集群为大规模攻击图生成提供了一种平衡的解决方案，能够显著提升生成效率

Abstract: Attack graphs (AGs) are graphical tools to analyze the security of computer
networks. By connecting the exploitation of individual vulnerabilities, AGs
expose possible multi-step attacks against target networks, allowing system
administrators to take preventive measures to enhance their network's security.
As powerful analytical tools, however, AGs are both time- and memory-consuming
to be generated. As the numbers of network assets, interconnections between
devices, as well as vulnerabilities increase, the size and volume of the
resulting AGs grow at a much higher rate, leading to the well-known state-space
explosion. In this paper, we propose the use of high performance computing
(HPC) clusters to implement AG generators. We evaluate the performance through
experiments and provide insights into how cluster environments can help resolve
the issues of slow speed and high memory demands in AG generation in a balanced
way.

</details>


### [39] [Invitation Is All You Need! Promptware Attacks Against LLM-Powered Assistants in Production Are Practical and Dangerous](https://arxiv.org/abs/2508.12175)
*Ben Nassi,Stav Cohen,Or Yair*

Main category: cs.CR

TL;DR: 本文研究了针对Gemini助手的Promptware攻击风险，提出了TARA风险评估框架，展示了14种攻击场景，发现73%的威胁具有高严重性风险，但通过缓解措施可将风险降至中低水平。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在应用中的集成增加，Promptware（恶意设计的提示词）对应用安全构成新威胁，但当前对其风险认知不足，需要系统评估其对终端用户的实际风险。

Method: 提出新颖的威胁分析和风险评估（TARA）框架，针对Gemini助手的网络应用、移动应用和Google助手，研究目标Promptware攻击变种，通过间接提示注入（如邮件、日历邀请、共享文档）进行攻击演示。

Result: 识别了5个威胁类别（短期上下文污染、永久记忆污染、工具滥用、自动代理调用、自动应用调用），展示了14个攻击场景，73%的威胁对终端用户构成高严重性风险，但缓解措施可显著降低风险。

Conclusion: Promptware对LLM应用构成实质性安全威胁，需要系统性的风险评估和缓解措施，研究结果已促使Google部署专门缓解措施，证明风险是可管理的。

Abstract: The growing integration of LLMs into applications has introduced new security
risks, notably known as Promptware - maliciously engineered prompts designed to
manipulate LLMs to compromise the CIA triad of these applications. While prior
research warned about a potential shift in the threat landscape for LLM-powered
applications, the risk posed by Promptware is frequently perceived as low. In
this paper, we investigate the risk Promptware poses to users of Gemini-powered
assistants (web application, mobile application, and Google Assistant). We
propose a novel Threat Analysis and Risk Assessment (TARA) framework to assess
Promptware risks for end users. Our analysis focuses on a new variant of
Promptware called Targeted Promptware Attacks, which leverage indirect prompt
injection via common user interactions such as emails, calendar invitations,
and shared documents. We demonstrate 14 attack scenarios applied against
Gemini-powered assistants across five identified threat classes: Short-term
Context Poisoning, Permanent Memory Poisoning, Tool Misuse, Automatic Agent
Invocation, and Automatic App Invocation. These attacks highlight both digital
and physical consequences, including spamming, phishing, disinformation
campaigns, data exfiltration, unapproved user video streaming, and control of
home automation devices. We reveal Promptware's potential for on-device lateral
movement, escaping the boundaries of the LLM-powered application, to trigger
malicious actions using a device's applications. Our TARA reveals that 73% of
the analyzed threats pose High-Critical risk to end users. We discuss
mitigations and reassess the risk (in response to deployed mitigations) and
show that the risk could be reduced significantly to Very Low-Medium. We
disclosed our findings to Google, which deployed dedicated mitigations.

</details>


### [40] [CAN Networks Security in Smart Grids Communication Technologies](https://arxiv.org/abs/2508.12181)
*Ayman W. Baharia,Khaled T. Naga,Hesham S. Abdelfattah,Shady A. Maged,Sherif A. Hammad*

Main category: cs.CR

TL;DR: 提出了一种基于单节点的CAN网络安全方案，几乎不对网络节点产生计算开销，旨在增强智能电网通信安全性同时减少延迟


<details>
  <summary>Details</summary>
Motivation: 智能电网快速发展需要可靠安全的通信协议，CAN协议虽然可靠但面临网络安全威胁，现有安全机制大多存在计算开销导致网络延迟的问题

Method: 采用单节点负责网络安全的方法，使用Code Composer Studio开发软件和TM4C 1294微控制器评估板实现

Result: 方案几乎不对任何CAN节点产生开销，具体测试结果将在后续讨论中详细呈现

Conclusion: 该方法能够在增强CAN网络安全性的同时，显著减少安全机制对所有网络节点的开销影响

Abstract: The rapid evolution of smart grids requires effective communication protocols
to transfer data reliably and securely. Controller Area Network (CAN) is one of
the most recognized protocols that offer reliable data transmission in smart
grids due to its robustness, real-time capabilities, and relatively low initial
cost of its required hardware. However, as a smart city becomes more
interconnected, it also becomes more vulnerable to cyber-attacks. As there are
many mechanisms to secure the CAN nodes from attacks, most of those mechanisms
have computational overhead, resulting in more delay in the network. We
implemented a solution that requires almost no overhead to any CAN node
connected to the network. It depends on a single node responsible for securing
the CAN network. This approach seeks to augment network security while reducing
security mechanisms overhead to all CAN network nodes. The methodology and
comprehensive test results will be presented in detail during a subsequent
discussion. The used software for development is Code Composer Studio, and the
used microcontroller evaluation boards (EVB) are TM4C 1294.

</details>


### [41] [Fortifying the Agentic Web: A Unified Zero-Trust Architecture Against Logic-layer Threats](https://arxiv.org/abs/2508.12259)
*Ken Huang,Yasir Mehmood,Hammad Atta,Jerry Huang,Muhammad Zeeshan Baig,Sree Bhargavi Balija*

Main category: cs.CR

TL;DR: 提出统一安全架构，通过零信任IAM框架强化智能代理网络，采用DID和VC构建可验证身份，引入多层信任结构和创新安全机制，提供可证明的LPCI攻击防护。


<details>
  <summary>Details</summary>
Motivation: 应对智能代理网络中的LPCI（Low-Probability Critical Impact）威胁，需要建立可验证的安全架构来确保代理生态系统的安全性和可信度。

Method: 基于零信任IAM框架，使用去中心化标识符(DID)和可验证凭证(VC)构建代理身份，通过协议无关的代理名称服务(ANS)进行发现，采用多层信任结构包括信任自适应运行时环境(TARE)、因果链审计和动态身份行为证明。

Result: 形式化分析表明，所提出的架构能够以有界成功概率提供可证明的LPCI攻击安全保证。

Conclusion: 该架构为安全、弹性和可信的代理生态系统提供了一个全面且前瞻性的蓝图，通过明确的架构对策有效应对LPCI威胁。

Abstract: This paper presents a Unified Security Architecture that fortifies the
Agentic Web through a Zero-Trust IAM framework. This architecture is built on a
foundation of rich, verifiable agent identities using Decentralized Identifiers
(DIDs) and Verifiable Credentials (VCs), with discovery managed by a
protocol-agnostic Agent Name Service (ANS). Security is operationalized through
a multi-layered Trust Fabric which introduces significant innovations,
including Trust-Adaptive Runtime Environments (TARE), Causal Chain Auditing,
and Dynamic Identity with Behavioral Attestation. By explicitly linking the
LPCI threat to these enhanced architectural countermeasures within a formal
security model, we propose a comprehensive and forward-looking blueprint for a
secure, resilient, and trustworthy agentic ecosystem. Our formal analysis
demonstrates that the proposed architecture provides provable security
guarantees against LPCI attacks with bounded probability of success.

</details>


### [42] [CryptPEFT: Efficient and Private Neural Network Inference via Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2508.12264)
*Saisai Xia,Wenhao Wang,Zihao Wang,Yuhui Zhang,Yier Jin,Dan Meng,Rui Hou*

Main category: cs.CR

TL;DR: CryptPEFT是一种专门为私有推理设计的参数高效微调解决方案，通过单向通信架构将加密计算限制在适配器内，显著降低了计算和通信开销，在保持模型效用的同时实现了高效的隐私保护推理。


<details>
  <summary>Details</summary>
Motivation: 现有的参数高效微调(PEFT)方法在私有推理场景中面临挑战，因为需要在整个主干网络和适配器之间进行双向加密通信，导致计算和通信开销巨大。需要一种专门为私有推理设计的PEFT解决方案。

Method: 提出CryptPEFT框架，采用单向通信(OWC)架构将加密计算限制在适配器内；探索OWC兼容适配器的设计空间；使用自动化架构搜索算法优化私有推理效率和模型效用之间的权衡。

Result: 在Vision Transformer主干网络上评估，CryptPEFT在广域网和局域网设置中分别实现了20.62倍到291.48倍的加速；在CIFAR-100上达到85.47%的准确率，推理延迟仅为2.26秒。

Conclusion: CryptPEFT为基于PEFT的现代推理提供了一个高效且保护隐私的解决方案，显著优于现有基线方法，在保持强模型效用的同时大幅降低了私有推理的开销。

Abstract: Publicly available large pretrained models (i.e., backbones) and lightweight
adapters for parameter-efficient fine-tuning (PEFT) have become standard
components in modern machine learning pipelines. However, preserving the
privacy of both user inputs and fine-tuned adapters -- often trained on
sensitive data -- during inference remains a significant challenge. Applying
cryptographic techniques, such as multi-party computation (MPC), to PEFT
settings still incurs substantial encrypted computation across both the
backbone and adapter, mainly due to the inherent two-way communication between
them. To address this limitation, we propose CryptPEFT, the first PEFT solution
specifically designed for private inference scenarios. CryptPEFT introduces a
novel one-way communication (OWC) architecture that confines encrypted
computation solely to the adapter, significantly reducing both computational
and communication overhead. To maintain strong model utility under this
constraint, we explore the design space of OWC-compatible adapters and employ
an automated architecture search algorithm to optimize the trade-off between
private inference efficiency and model utility. We evaluated CryptPEFT using
Vision Transformer backbones across widely used image classification datasets.
Our results show that CryptPEFT significantly outperforms existing baselines,
delivering speedups ranging from $20.62\times$ to $291.48\times$ in simulated
wide-area network (WAN) and local-area network (LAN) settings. On CIFAR-100,
CryptPEFT attains 85.47% accuracy with just 2.26 seconds of inference latency.
These findings demonstrate that CryptPEFT offers an efficient and
privacy-preserving solution for modern PEFT-based inference.

</details>


### [43] [Adjustable AprilTags For Identity Secured Tasks](https://arxiv.org/abs/2508.12304)
*Hao Li*

Main category: cs.CR

TL;DR: 本文主张在开放公共环境中使用可调节的AprilTags替代固定标签，以应对对抗性攻击带来的身份安全风险。


<details>
  <summary>Details</summary>
Motivation: 在封闭私有环境中，AprilTags的身份安全不是问题，但在开放公共环境中，对抗性攻击可能造成潜在危害，身份安全不容忽视。

Method: 提倡使用可调节的AprilTags而非固定标签

Result: 提出了应对开放环境中身份安全挑战的解决方案

Conclusion: 可调节AprilTags是处理对抗性攻击潜在危害的有效方法

Abstract: Special tags such as AprilTags that facilitate image processing and pattern
recognition are useful in practical applications. In close and private
environments, identity security is unlikely to be an issue because all involved
AprilTags can be completely regulated. However, in open and public
environments, identity security is no longer an issue that can be neglected. To
handle potential harm caused by adversarial attacks, this note advocates
utilization of adjustable AprilTags instead of fixed ones.

</details>


### [44] [Where to Start Alignment? Diffusion Large Language Model May Demand a Distinct Position](https://arxiv.org/abs/2508.12398)
*Zhixin Xie,Xurui Song,Jun Luo*

Main category: cs.CR

TL;DR: 本文首次分析了扩散大语言模型(dLLMs)的安全性能，发现响应中间令牌对安全性更关键，提出了一种针对中间令牌的安全对齐方法MOSA，在安全性和实用性方面都表现出优越性。


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型作为一种新兴的非自回归范式，目前缺乏对其安全性的研究，需要探索适合其独特生成特性的安全对齐方法。

Method: 提出Middle-tOken Safety Alignment (MOSA)方法，利用强化学习直接对齐模型的中间生成过程与安全拒绝响应，基于防御者和攻击者在中间令牌操纵能力上的不对称性。

Result: 在8种攻击方法和2个基准测试中，MOSA表现出优越的安全性能，同时在编码、数学和通用推理任务上保持了良好的实用性。

Conclusion: MOSA方法有效解决了dLLMs的安全对齐问题，证明了中间令牌对齐策略的有效性，为扩散语言模型的安全研究提供了新方向。

Abstract: Diffusion Large Language Models (dLLMs) have recently emerged as a
competitive non-autoregressive paradigm due to their unique training and
inference approach. However, there is currently a lack of safety study on this
novel architecture. In this paper, we present the first analysis of dLLMs'
safety performance and propose a novel safety alignment method tailored to
their unique generation characteristics. Specifically, we identify a critical
asymmetry between the defender and attacker in terms of security. For the
defender, we reveal that the middle tokens of the response, rather than the
initial ones, are more critical to the overall safety of dLLM outputs; this
seems to suggest that aligning middle tokens can be more beneficial to the
defender. The attacker, on the contrary, may have limited power to manipulate
middle tokens, as we find dLLMs have a strong tendency towards a sequential
generation order in practice, forcing the attack to meet this distribution and
diverting it from influencing the critical middle tokens. Building on this
asymmetry, we introduce Middle-tOken Safety Alignment (MOSA), a novel method
that directly aligns the model's middle generation with safe refusals
exploiting reinforcement learning. We implement MOSA and compare its security
performance against eight attack methods on two benchmarks. We also test the
utility of MOSA-aligned dLLM on coding, math, and general reasoning. The
results strongly prove the superiority of MOSA.

</details>


### [45] [LumiMAS: A Comprehensive Framework for Real-Time Monitoring and Enhanced Observability in Multi-Agent Systems](https://arxiv.org/abs/2508.12412)
*Ron Solomon,Yarin Yerushalmi Levi,Lior Vaknin,Eran Aizikovich,Amit Baras,Etai Ohana,Amit Giloni,Shamik Bose,Chiara Picardi,Yuval Elovici,Asaf Shabtai*

Main category: cs.CR

TL;DR: LumiMAS是一个新颖的多智能体系统观测框架，通过三层架构实现实时异常检测和根因分析，有效解决了传统方法忽视系统级故障的问题。


<details>
  <summary>Details</summary>
Motivation: 现有MAS观测框架主要关注单个智能体的分析，忽视了整个多智能体系统层面的故障检测需求，特别是在大语言模型集成后带来的新挑战。

Method: 提出三层框架：监控日志层记录智能体活动，异常检测层实时检测工作流异常，异常解释层进行分类和根因分析。

Result: 在7个不同MAS应用上评估，涵盖两种流行平台和多样化故障场景，证明LumiMAS在故障检测、分类和根因分析方面具有显著效果。

Conclusion: LumiMAS框架成功填补了MAS系统级观测的空白，为集成大语言模型的多智能体系统提供了有效的故障监控和诊断解决方案。

Abstract: The incorporation of large language models in multi-agent systems (MASs) has
the potential to significantly improve our ability to autonomously solve
complex problems. However, such systems introduce unique challenges in
monitoring, interpreting, and detecting system failures. Most existing MAS
observability frameworks focus on analyzing each individual agent separately,
overlooking failures associated with the entire MAS. To bridge this gap, we
propose LumiMAS, a novel MAS observability framework that incorporates advanced
analytics and monitoring techniques. The proposed framework consists of three
key components: a monitoring and logging layer, anomaly detection layer, and
anomaly explanation layer. LumiMAS's first layer monitors MAS executions,
creating detailed logs of the agents' activity. These logs serve as input to
the anomaly detection layer, which detects anomalies across the MAS workflow in
real time. Then, the anomaly explanation layer performs classification and root
cause analysis (RCA) of the detected anomalies. LumiMAS was evaluated on seven
different MAS applications, implemented using two popular MAS platforms, and a
diverse set of possible failures. The applications include two novel
failure-tailored applications that illustrate the effects of a hallucination or
bias on the MAS. The evaluation results demonstrate LumiMAS's effectiveness in
failure detection, classification, and RCA.

</details>


### [46] [A Robust Cross-Domain IDS using BiGRU-LSTM-Attention for Medical and Industrial IoT Security](https://arxiv.org/abs/2508.12470)
*Afrah Gueriani,Hamza Kheddar,Ahmed Cherif Mazari,Mohamed Chahine Ghanem*

Main category: cs.CR

TL;DR: 这篇论文提出了一种新的变换器基于入侵检测系统BiGAT-ID，通过结合双向GRU、LSTM和多头注意力机制，在医疗IoT和工业IoT环境中实现了超过99%的检测准确性和极快的推理速度。


<details>
  <summary>Details</summary>
Motivation: 医疗IoT和工业IoT互联网性带来了复杂的网络安全挑战，媒体敏感数据、患者安全和工业运营面临高级网络威胁。需要有效的入侵检测系统来缓解这些风险。

Method: 提出BiGAT-ID混合模型，结合了双向门控递归单元(BiGRU)、长短期记忆网络(LSTM)和多头注意力机制(MHA)。该架构能够有效捕捉双向时序依赖关系、建模序列模式并增强上下文特征表征。

Result: 在CICIoMT2024医疗IoT数据集上达到99.13%检测准确性，在EdgeIIoTset工业IoT数据集上达到99.34%。推理速度极快（IoMT场景0.0002秒/实例，IIoT场景0.0001秒/实例），低假正率。

Conclusion: BiGAT-ID被证明是一种可靠且高效的入侵检测系统，适合在实际异构IoT环境中部署，具有跨域鲁棒性、高准确性和快速响应的特点。

Abstract: The increased Internet of Medical Things IoMT and the Industrial Internet of
Things IIoT interconnectivity has introduced complex cybersecurity challenges,
exposing sensitive data, patient safety, and industrial operations to advanced
cyber threats. To mitigate these risks, this paper introduces a novel
transformer-based intrusion detection system IDS, termed BiGAT-ID a hybrid
model that combines bidirectional gated recurrent units BiGRU, long short-term
memory LSTM networks, and multi-head attention MHA. The proposed architecture
is designed to effectively capture bidirectional temporal dependencies, model
sequential patterns, and enhance contextual feature representation. Extensive
experiments on two benchmark datasets, CICIoMT2024 medical IoT and EdgeIIoTset
industrial IoT demonstrate the model's cross-domain robustness, achieving
detection accuracies of 99.13 percent and 99.34 percent, respectively.
Additionally, the model exhibits exceptional runtime efficiency, with inference
times as low as 0.0002 seconds per instance in IoMT and 0.0001 seconds in IIoT
scenarios. Coupled with a low false positive rate, BiGAT-ID proves to be a
reliable and efficient IDS for deployment in real-world heterogeneous IoT
environments

</details>


### [47] [ChamaleoNet: Programmable Passive Probe for Enhanced Visibility on Erroneous Traffic](https://arxiv.org/abs/2508.12496)
*Zhihao Wang,Alessandro Cornacchia,Andrea Bianco,Idilio Drago,Paolo Giaccone,Dingde Jiang,Marco Mellia*

Main category: cs.CR

TL;DR: ChamaleoNet是一个基于SDN的网络监控系统，专门收集和分析网络中的异常和错误流量，用于检测错误配置、临时故障和攻击，同时保护隐私并减少控制器负载。


<details>
  <summary>Details</summary>
Motivation: 网络可见性对管理和安全运营至关重要，需要有效监控异常流量来检测错误配置、临时故障和攻击，但传统方法存在隐私和可扩展性问题。

Method: 利用SDN范式，在硬件层面过滤流量，只收集错误数据包，忽略格式良好的流量，降低收集系统压力，并与主动欺骗系统（如蜜罐）无缝集成。

Result: SDN硬件过滤将控制器流量减少96%，提供可扩展解决方案，能够发现内部错误配置和受感染主机，识别临时故障，增强对外部攻击辐射的可见性。

Conclusion: ChamaleoNet成功将生产网络转变为透明监控器，有效收集异常流量，在保护隐私的同时提供强大的网络可见性和安全监控能力，并作为开源项目提供。

Abstract: Traffic visibility remains a key component for management and security
operations. Observing unsolicited and erroneous traffic, such as unanswered
traffic or errors, is fundamental to detect misconfiguration, temporary
failures or attacks. ChamaleoNet transforms any production network into a
transparent monitor to let administrators collect unsolicited and erroneous
traffic directed to hosts, whether offline or active, hosting a server or a
client, protected by a firewall, or unused addresses. ChamaleoNet is programmed
to ignore well-formed traffic and collect only erroneous packets, including
those generated by misconfigured or infected internal hosts, and those sent by
external actors which scan for services. Engineering such a system poses
several challenges, from scalability to privacy. Leveraging the SDN paradigm,
ChamaleoNet processes the traffic flowing through a campus/corporate network
and focuses on erroneous packets only, lowering the pressure on the collection
system while respecting privacy regulations by design. ChamaleoNet enables the
seamless integration with active deceptive systems like honeypots that can
impersonate unused hosts/ports/services and engage with senders. The SDN
in-hardware filtering reduces the traffic to the controller by 96%, resulting
in a scalable solution, which we offer as open source. Simple analytics unveil
internal misconfigured and infected hosts, identify temporary failures, and
enhance visibility on external radiation produced by attackers looking for
vulnerable services.

</details>


### [48] [The Hidden Cost of Correlation: Rethinking Privacy Leakage in Local Differential Privacy](https://arxiv.org/abs/2508.12539)
*Sandaru Jayawardana,Sennur Ulukus,Ming Ding,Kanchana Thilakarathna*

Main category: cs.CR

TL;DR: 本文对本地差分隐私(LDP)机制中的相关性隐私泄露(CPL)问题进行了全面分析，通过统计分析和理论框架开发，揭示了现有假设的不足，并提出了新的评估基准和实用解决方案。


<details>
  <summary>Details</summary>
Motivation: 本地差分隐私在分布式数据收集中面临多维度属性相关性导致的隐私泄露问题，现有研究对相关性隐私泄露的理解和量化存在不足，特别是在实际数据中的影响程度和近似LDP机制方面缺乏系统研究。

Method: 1) 对五种主流LDP机制(GRR、RAPPOR、OUE、OLH和指数机制)在四个真实数据集上进行全面的统计分析；2) 开发首个算法框架来理论量化任意近似LDP机制的CPL；3) 提出两个新的基准来验证相关性分析算法并评估LDP机制的效用与CPL权衡。

Result: 研究发现现有方法的许多核心假设和指标无法准确描述相关性隐私泄露；理论框架与实证统计结果一致，为观察到的统计模式提供了理论解释；新基准能够有效评估LDP机制的隐私-效用权衡。

Conclusion: 该研究填补了LDP中相关性隐私泄露量化的重要空白，提供了理论框架和实用工具，有助于在实际数据治理中实现更高效的隐私-效用权衡，对隐私保护技术的实际部署具有重要指导意义。

Abstract: Local differential privacy (LDP) has emerged as a promising paradigm for
privacy-preserving data collection in distributed systems, where users
contribute multi-dimensional records with potentially correlated attributes.
Recent work has highlighted that correlation-induced privacy leakage (CPL)
plays a critical role in shaping the privacy-utility trade-off under LDP,
especially when correlations exist among attributes. Nevertheless, it remains
unclear to what extent the prevailing assumptions and proposed solutions are
valid and how significant CPL is in real-world data. To address this gap, we
first perform a comprehensive statistical analysis of five widely used LDP
mechanisms -- GRR, RAPPOR, OUE, OLH and Exponential mechanism -- to assess CPL
across four real-world datasets. We identify that many primary assumptions and
metrics in current approaches fall short of accurately characterising these
leakages. Moreover, current studies have been limited to a set of pure LDP
(i.e., {\delta = 0}) mechanisms. In response, we develop the first algorithmic
framework to theoretically quantify CPL for any general approximated LDP
(({\varepsilon},{\delta})-LDP) mechanism. We validate our theoretical results
against empirical statistical results and provide a theoretical explanation for
the observed statistical patterns. Finally, we propose two novel benchmarks to
validate correlation analysis algorithms and evaluate the utility vs CPL of LDP
mechanisms. Further, we demonstrate how these findings can be applied to
achieve an efficient privacy-utility trade-off in real-world data governance.

</details>


### [49] [DEFENDCLI: {Command-Line} Driven Attack Provenance Examination](https://arxiv.org/abs/2508.12553)
*Peilun Wu,Nan Sun,Nour Moustafa,Youyang Qu,Ming Ding*

Main category: cs.CR

TL;DR: DEFENDCLI是一个基于溯源图的创新EDR系统，首次实现命令行级检测，通过三级异常评估提高检测精度，在DARPA数据集上比现有方法精度提高1.6倍


<details>
  <summary>Details</summary>
Motivation: 当前EDR系统在检测混淆攻击、关联攻击、识别低频事件和确保命令行活动上下文感知方面存在局限性，需要更细粒度的检测方法

Method: 利用溯源图技术，在三个级别进行评估：异常系统进程调用、可疑命令行执行和不常见外部网络连接，实现多级异常检测

Result: 在DARPA数据集上精度提高约1.6倍，实时工业测试显示能检测其他商业方案遗漏的未知攻击实例，比最先进研究工作精度提高2.3倍

Conclusion: DEFENDCLI通过命令行级细粒度检测填补了现代EDR系统的空白，在复杂动态环境中提供更可靠的威胁检测能力

Abstract: Endpoint Detection and Response (EDR) solutions embrace the method of attack
provenance graph to discover unknown threats through system event correlation.
However, this method still faces some unsolved problems in the fields of
interoperability, reliability, flexibility, and practicability to deliver
actionable results. Our research highlights the limitations of current
solutions in detecting obfuscation, correlating attacks, identifying
low-frequency events, and ensuring robust context awareness in relation to
command-line activities. To address these challenges, we introduce DEFENDCLI,
an innovative system leveraging provenance graphs that, for the first time,
delves into command-line-level detection. By offering finer detection
granularity, it addresses a gap in modern EDR systems that has been overlooked
in previous research. Our solution improves the precision of the information
representation by evaluating differentiation across three levels: unusual
system process calls, suspicious command-line executions, and infrequent
external network connections. This multi-level approach enables EDR systems to
be more reliable in complex and dynamic environments. Our evaluation
demonstrates that DEFENDCLI improves precision by approximately 1.6x compared
to the state-of-the-art methods on the DARPA Engagement Series attack datasets.
Extensive real-time industrial testing across various attack scenarios further
validates its practical effectiveness. The results indicate that DEFENDCLI not
only detects previously unknown attack instances, which are missed by other
modern commercial solutions, but also achieves a 2.3x improvement in precision
over the state-of-the-art research work.

</details>


### [50] [Data-driven Trust Bootstrapping for Mobile Edge Computing-based Industrial IoT Services](https://arxiv.org/abs/2508.12560)
*Prabath Abeysekara,Hai Dong*

Main category: cs.CR

TL;DR: 提出一种数据驱动的上下文感知方法，用于在移动边缘计算基础的工业物联网系统中快速建立同构服务的信任度


<details>
  <summary>Details</summary>
Motivation: 解决现有信任建立方法在MEC基础的IIoT系统中的三个主要问题：缺乏长期交互机会获取可靠信任评估、无法从同伴获得可靠推荐、不同MEC环境上下文参数导致信任评估环境不均匀

Method: 通过在MEC拓扑结构内不同环境之间共享知识来解决数据稀疏问题，采用上下文感知方法进行信任建立

Result: 在两个经过适当调整的真实数据集上进行了全面评估，实验结果证明了方法的有效性

Conclusion: 该方法适合在MEC基础的IIoT系统中快速建立服务的信任度

Abstract: We propose a data-driven and context-aware approach to bootstrap
trustworthiness of homogeneous Internet of Things (IoT) services in Mobile Edge
Computing (MEC) based industrial IoT (IIoT) systems. The proposed approach
addresses key limitations in adapting existing trust bootstrapping approaches
into MEC-based IIoT systems. These key limitations include, the lack of
opportunity for a service consumer to interact with a lesser-known service over
a prolonged period of time to get a robust measure of its trustworthiness,
inability of service consumers to consistently interact with their peers to
receive reliable recommendations of the trustworthiness of a lesser-known
service as well as the impact of uneven context parameters in different MEC
environments causing uneven trust environments for trust evaluation. In
addition, the proposed approach also tackles the problem of data sparsity via
enabling knowledge sharing among different MEC environments within a given MEC
topology. To verify the effectiveness of the proposed approach, we carried out
a comprehensive evaluation on two real-world datasets suitably adjusted to
exhibit the context-dependent trust information accumulated in MEC environments
within a given MEC topology. The experimental results affirmed the
effectiveness of our approach and its suitability to bootstrap trustworthiness
of services in MEC-based IIoT systems.

</details>


### [51] [Cyber Risks to Next-Gen Brain-Computer Interfaces: Analysis and Recommendations](https://arxiv.org/abs/2508.12571)
*Tyler Schroder,Renee Sirbu,Sohee Park,Jessica Morley,Sam Street,Luciano Floridi*

Main category: cs.CR

TL;DR: 本文分析了脑机接口(BCI)的网络安全风险，为设备制造商和监管机构提供安全建议，包括设备更新方法、认证授权机制、数据加密和网络连接最小化等防护措施。


<details>
  <summary>Details</summary>
Motivation: 脑机接口在个性化医疗中具有巨大潜力，但同时也带来了新的网络安全攻击途径，需要保护患者安全和数据机密性。

Method: 分析脑机接口安全问题，设计假设性的平均案例威胁模型，识别可能的网络安全威胁并预测各类威胁的风险可能性。

Result: 脑机接口面临较低的物理攻击风险，但容易受到远程网络攻击，需要重点关注通过网络路径的潜在威胁。

Conclusion: 提出了具体的技术控制建议，包括非手术设备更新方法、强认证授权方案、数据加密和限制网络连接，以保护脑机接口用户免受不必要的风险。

Abstract: Brain-computer interfaces (BCIs) show enormous potential for advancing
personalized medicine. However, BCIs also introduce new avenues for
cyber-attacks or security compromises. In this article, we analyze the problem
and make recommendations for device manufacturers to better secure devices and
to help regulators understand where more guidance is needed to protect patient
safety and data confidentiality. Device manufacturers should implement the
prior suggestions in their BCI products. These recommendations help protect BCI
users from undue risks, including compromised personal health and genetic
information, unintended BCI-mediated movement, and many other cybersecurity
breaches. Regulators should mandate non-surgical device update methods, strong
authentication and authorization schemes for BCI software modifications,
encryption of data moving to and from the brain, and minimize network
connectivity where possible. We also design a hypothetical, average-case threat
model that identifies possible cybersecurity threats to BCI patients and
predicts the likeliness of risk for each category of threat. BCIs are at less
risk of physical compromise or attack, but are vulnerable to remote attack; we
focus on possible threats via network paths to BCIs and suggest technical
controls to limit network connections.

</details>


### [52] [Reducing False Positives with Active Behavioral Analysis for Cloud Security](https://arxiv.org/abs/2508.12584)
*Dikshant,Verma*

Main category: cs.CR

TL;DR: 提出了一种基于验证驱动的方法，通过主动行为测试来评估云安全策略违规的可利用性，显著减少93%的误报率。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则的云安全态势管理(CSPM)解决方案产生大量误报，依赖静态启发式测试且缺乏上下文理解，导致分析师需要花费大量时间进行手动验证。

Method: 采用轻量级自动化探针，整合开源工具、验证脚本和渗透测试用例，在不影响云服务的情况下模拟对抗性攻击来验证配置错误或漏洞。

Result: 在可复现的AWS环境中进行控制实验，平均减少93%的误报率，框架表现出低延迟性能。

Conclusion: 该方法可显著提高大型云环境中的检测准确性和分析师工作效率，架构模块化且可扩展到多云环境。

Abstract: Rule-based cloud security posture management (CSPM) solutions are known to
produce a lot of false positives based on the limited contextual understanding
and dependence on static heuristics testing. This paper introduces a
validation-driven methodology that integrates active behavioral testing in
cloud security posture management solution(s) to evaluate the exploitability of
policy violations in real time. The proposed system employs lightweight and
automated probes, built from open-source tools, validation scripts, and
penetration testing test cases, to simulate adversarial attacks on
misconfigured or vulnerable cloud assets without any impact to the cloud
services or environment. For instance, cloud services may be flagged as
publicly exposed and vulnerable despite being protected by access control
layers, or secure policies, resulting in non-actionable alerts that consumes
analysts time during manual validation. Through controlled experimentation in a
reproducible AWS setup, we evaluated the reduction in false positive rates
across various misconfiguration and vulnerable alerts. Our findings indicate an
average reduction of 93\% in false positives. Furthermore, the framework
demonstrates low latency performance. These results demonstrate a scalable
method to improve detection accuracy and analyst productivity in large cloud
environments. While our evaluation focuses on AWS, the architecture is modular
and extensible to multi-cloud setups.

</details>


### [53] [UAV Individual Identification via Distilled RF Fingerprints-Based LLM in ISAC Networks](https://arxiv.org/abs/2508.12597)
*Haolin Zheng,Ning Gao,Donghong Cai,Shi Jin,Michail Matthaiou*

Main category: cs.CR

TL;DR: 提出基于动态知识蒸馏的无线射频指纹大语言模型框架，用于无人机身份识别，在复杂户外环境中实现高精度识别和高效模型压缩


<details>
  <summary>Details</summary>
Motivation: 无人机身份识别是低空综合感知通信网络中的关键安全监控策略，需要解决复杂户外环境下的识别精度和模型参数开销问题

Method: 基于改进GPT-2模型构建RFF-LLM框架，采用PPO算法动态调整蒸馏温度进行知识蒸馏，将知识转移到轻量级Lite-HRNet模型

Result: 在自建DRFF-R1数据集上达到98.38%识别准确率，仅需0.15M参数和2.74ms响应时间，优于基准方法

Conclusion: 所提框架有效解决了复杂环境下的无人机身份识别问题，在精度和效率方面均表现出色

Abstract: Unmanned aerial vehicle (UAV) individual (ID) identification is a critical
security surveillance strategy in low-altitude integrated sensing and
communication (ISAC) networks. In this paper, we propose a novel dynamic
knowledge distillation (KD)-enabled wireless radio frequency fingerprint large
language model (RFF-LLM) framework for UAV ID identification. First, we propose
an RFF-LLM framework based on the modified GPT-2 model to improve the
identification accuracy in complex outdoor environments. Then, considering the
parameter overhead of the RFF-LLM, we design a dynamic KD strategy to compress
the model. Specifically, the proximal policy optimization (PPO) algorithm is
employed to dynamically adjust the distillation temperature, overcoming the
local optimum dilemma inherent in static KD. As a next step, the knowledge of
the RFF-LLM is adequately transferred to the lightweight Lite-HRNet model.
Finally, our experiments are conducted based on the self-built drone RFF
dataset of Release one, namely DRFF-R1, by collecting the I/Q signals of 20
commercial UAVs in channel 149. The experiment results show that the proposed
framework achieves 98.38\% ID identification accuracy with merely 0.15 million
parameters and 2.74 ms response time, which outperforms the benchmarks.

</details>


### [54] [Consiglieres in the Shadow: Understanding the Use of Uncensored Large Language Models in Cybercrimes](https://arxiv.org/abs/2508.12622)
*Zilong Lin,Zichuan Li,Xiaojing Liao,XiaoFeng Wang*

Main category: cs.CR

TL;DR: 本研究首次系统性地分析了未审查大语言模型(ULLMs)的安全威胁，通过知识图谱和深度学习从Hugging Face平台识别出11,000多个ULLMs，发现这些模型被广泛用于生成有害内容和集成到恶意应用中。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术特别是大语言模型的发展，网络犯罪分子越来越多地利用未审查LLMs作为恶意服务的后端，但由于开源LLMs数量庞大，识别这些危险模型一直存在挑战。

Method: 通过建模开源LLMs之间的关系及其与相关数据（如微调、模型合并、压缩、使用或生成有害内容数据集）的联系，构建知识图谱并应用基于图的深度学习技术。

Result: 发现了超过11,000个ULLMs，其中一些下载量超过百万次（最高达1900万次），这些模型能够生成仇恨言论、暴力、色情内容和恶意代码，并被集成到数百个恶意应用中。

Conclusion: 研究揭示了LLM技术被广泛滥用的严重程度，强调了迫切需要制定有效对策来应对这一日益增长的安全威胁。

Abstract: The advancement of AI technologies, particularly Large Language Models
(LLMs), has transformed computing while introducing new security and privacy
risks. Prior research shows that cybercriminals are increasingly leveraging
uncensored LLMs (ULLMs) as backends for malicious services. Understanding these
ULLMs has been hindered by the challenge of identifying them among the vast
number of open-source LLMs hosted on platforms like Hugging Face. In this
paper, we present the first systematic study of ULLMs, overcoming this
challenge by modeling relationships among open-source LLMs and between them and
related data, such as fine-tuning, merging, compressing models, and using or
generating datasets with harmful content. Representing these connections as a
knowledge graph, we applied graph-based deep learning to discover over 11,000
ULLMs from a small set of labeled examples and uncensored datasets.
  A closer analysis of these ULLMs reveals their alarming scale and usage. Some
have been downloaded over a million times, with one over 19 million installs.
These models -- created through fine-tuning, merging, or compression of other
models -- are capable of generating harmful content, including hate speech,
violence, erotic material, and malicious code. Evidence shows their integration
into hundreds of malicious applications offering services like erotic
role-play, child pornography, malicious code generation, and more. In addition,
underground forums reveal criminals sharing techniques and scripts to build
cheap alternatives to commercial malicious LLMs. These findings highlight the
widespread abuse of LLM technology and the urgent need for effective
countermeasures against this growing threat.

</details>


### [55] [MPOCryptoML: Multi-Pattern based Off-Chain Crypto Money Laundering Detection](https://arxiv.org/abs/2508.12641)
*Yasaman Samadi,Hai Dong,Xiaoyu Xia*

Main category: cs.CR

TL;DR: 提出了MPOCryptoML模型，专门针对加密货币链下洗钱的多种模式进行检测，通过多源个性化PageRank和时间戳分析等方法，在多个公开数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有模型未能专门针对加密货币链下洗钱的多样化模式进行设计，忽视任何洗钱模式都会导致检测漏洞，因为每种模式都反映了独特的交易结构来掩盖非法资金流动。

Method: 开发了多源个性化PageRank算法检测随机洗钱模式；引入两种新算法分析高容量金融网络中交易的时间戳和权重，检测扇入、扇出、二分、聚集-分散和堆栈等模式；使用逻辑回归模型分析模式相关性；通过异常评分函数整合各模块结果对账户进行风险排序。

Result: 在Elliptic++、以太坊欺诈检测和Wormhole交易数据集上的实验显示，MPOCryptoML在精确率上提升高达9.13%，召回率提升10.16%，F1分数提升7.63%，准确率提升10.19%。

Conclusion: MPOCryptoML模型能够有效检测加密货币交易中的多种洗钱模式，系统性地识别高风险账户，在检测效果和效率方面都表现出色。

Abstract: Recent advancements in money laundering detection have demonstrated the
potential of using graph neural networks to capture laundering patterns
accurately. However, existing models are not explicitly designed to detect the
diverse patterns of off-chain cryptocurrency money laundering. Neglecting any
laundering pattern introduces critical detection gaps, as each pattern reflects
unique transactional structures that facilitate the obfuscation of illicit fund
origins and movements. Failure to account for these patterns may result in
under-detection or omission of specific laundering activities, diminishing
model accuracy and allowing schemes to bypass detection. To address this gap,
we propose the MPOCryptoML model to effectively detect multiple laundering
patterns in cryptocurrency transactions. MPOCryptoML includes the development
of a multi-source Personalized PageRank algorithm to identify random laundering
patterns. Additionally, we introduce two novel algorithms by analyzing the
timestamp and weight of transactions in high-volume financial networks to
detect various money laundering structures, including fan-in, fan-out,
bipartite, gather-scatter, and stack patterns. We further examine correlations
between these patterns using a logistic regression model. An anomaly score
function integrates results from each module to rank accounts by anomaly score,
systematically identifying high-risk accounts. Extensive experiments on public
datasets including Elliptic++, Ethereum fraud detection, and Wormhole
transaction datasets validate the efficacy and efficiency of MPOCryptoML.
Results show consistent performance gains, with improvements up to 9.13% in
precision, up to 10.16% in recall, up to 7.63% in F1-score, and up to 10.19% in
accuracy.

</details>


### [56] [Unlearning Comparator: A Visual Analytics System for Comparative Evaluation of Machine Unlearning Methods](https://arxiv.org/abs/2508.12730)
*Jaeung Lee,Suhyeon Yu,Yurim Jang,Simon S. Woo,Jaemin Jo*

Main category: cs.CR

TL;DR: 提出了Unlearning Comparator可视化分析系统，用于系统评估机器学习遗忘方法，支持模型比较和隐私攻击模拟，帮助研究者理解不同遗忘方法在准确性、效率和隐私方面的权衡。


<details>
  <summary>Details</summary>
Motivation: 机器学习遗忘领域的研究者面临分析不同遗忘方法行为的挑战，特别是在准确性、效率和隐私三个基本原则方面，往往依赖聚合指标和临时评估，难以准确评估方法间的权衡。

Method: 开发了Unlearning Comparator可视化分析系统，支持两个核心任务：1）在类、实例和层级比较两个模型的行为；2）模拟成员推理攻击来评估方法的隐私性。

Result: 通过案例研究验证了系统有效性，证明该系统不仅能帮助用户理解模型行为，还能为改进遗忘方法提供有价值的见解。

Conclusion: Unlearning Comparator系统填补了机器学习遗忘方法系统评估的空白，为研究者提供了强大的分析工具，有助于推动该领域的发展和方法改进。

Abstract: Machine Unlearning (MU) aims to remove target training data from a trained
model so that the removed data no longer influences the model's behavior,
fulfilling "right to be forgotten" obligations under data privacy laws. Yet, we
observe that researchers in this rapidly emerging field face challenges in
analyzing and understanding the behavior of different MU methods, especially in
terms of three fundamental principles in MU: accuracy, efficiency, and privacy.
Consequently, they often rely on aggregate metrics and ad-hoc evaluations,
making it difficult to accurately assess the trade-offs between methods. To
fill this gap, we introduce a visual analytics system, Unlearning Comparator,
designed to facilitate the systematic evaluation of MU methods. Our system
supports two important tasks in the evaluation process: model comparison and
attack simulation. First, it allows the user to compare the behaviors of two
models, such as a model generated by a certain method and a retrained baseline,
at class-, instance-, and layer-levels to better understand the changes made
after unlearning. Second, our system simulates membership inference attacks
(MIAs) to evaluate the privacy of a method, where an attacker attempts to
determine whether specific data samples were part of the original training set.
We evaluate our system through a case study visually analyzing prominent MU
methods and demonstrate that it helps the user not only understand model
behaviors but also gain insights that can inform the improvement of MU methods.

</details>


### [57] [Efficient and Verifiable Privacy-Preserving Convolutional Computation for CNN Inference with Untrusted Clouds](https://arxiv.org/abs/2508.12832)
*Jinyu Lu,Xinrong Sun,Yunting Tao,Tong Ji,Fanyu Kong,Guoqiang Yang*

Main category: cs.CR

TL;DR: 提出了一种针对CNN卷积层的可验证隐私保护方案，通过高效加密解密和验证机制，在保护数据隐私的同时实现26-87倍的速度提升。


<details>
  <summary>Details</summary>
Motivation: MLaaS系统中CNN模型在资源受限场景下的隐私泄露问题，现有隐私保护方案在卷积运算中存在效率瓶颈。

Method: 设计专门针对CNN卷积层的隐私保护方案，采用高效加密解密技术，并引入可验证机制来检测计算结果的正确性。

Result: 在10个数据集和多种CNN模型上的实验表明，方案相比原始明文模型实现了26-87倍的速度提升，同时保持准确性。验证机制的成功概率至少为1-1/|Z|。

Conclusion: 该方案有效解决了CNN在MLaaS系统中的隐私保护问题，在保证安全性的同时显著提升了计算效率，适用于资源受限的客户端场景。

Abstract: The widespread adoption of convolutional neural networks (CNNs) in
resource-constrained scenarios has driven the development of Machine Learning
as a Service (MLaaS) system. However, this approach is susceptible to privacy
leakage, as the data sent from the client to the untrusted cloud server often
contains sensitive information. Existing CNN privacy-preserving schemes, while
effective in ensuring data confidentiality through homomorphic encryption and
secret sharing, face efficiency bottlenecks, particularly in convolution
operations. In this paper, we propose a novel verifiable privacy-preserving
scheme tailored for CNN convolutional layers. Our scheme enables efficient
encryption and decryption, allowing resource-constrained clients to securely
offload computations to the untrusted cloud server. Additionally, we present a
verification mechanism capable of detecting the correctness of the results with
a success probability of at least $1-\frac{1}{\left|Z\right|}$. Extensive
experiments conducted on 10 datasets and various CNN models demonstrate that
our scheme achieves speedups ranging $26 \times$ ~ $\ 87\times$ compared to the
original plaintext model while maintaining accuracy.

</details>


### [58] [The covering radius of Butson Hadamard codes for the homogeneous metric](https://arxiv.org/abs/2508.12859)
*Xingxing Xu,Minjia Shi,Patrick Sole*

Main category: cs.CR

TL;DR: 本文研究Butson Hadamard码在齐次度量下的覆盖半径，通过正交阵列论证得到上界，利用弯曲序列存在性得到下界，推广了Hamming度量的相关结果。


<details>
  <summary>Details</summary>
Motivation: Butson矩阵是复Hadamard矩阵，其元素为给定阶的复单位根。研究与之相关的相位空间码的覆盖半径特性，特别是在齐次度量下的性能分析。

Method: 使用正交阵列论证推导覆盖半径的上界，通过证明弯曲序列的存在性来建立下界。

Result: 获得了Butson Hadamard码在齐次度量下覆盖半径的上界和下界，其中下界推广了Armario等人2025年在Hamming度量下的结果。

Conclusion: 该研究为Butson Hadamard码在齐次度量下的覆盖性能提供了理论界限，扩展了相关编码理论的研究范围。

Abstract: Butson matrices are complex Hadamard matrices with entries in the complex
roots of unity of given order. There is an interesting code in phase space
related to this matrix (Armario et al. 2023). We study the covering radius of
Butson Hadamard codes for the homogeneous metric, a metric defined uniquely, up
to scaling, for a commutative ring alphabet that is Quasi Frobenius. An upper
bound is derived by an orthogonal array argument. A lower bound relies on the
existence of bent sequences in the sense of (Shi et al. 2022). This latter
bound generalizes a bound of (Armario et al. 2025) for the Hamming metric.

</details>


### [59] [Supporting Socially Constrained Private Communications with SecureWhispers](https://arxiv.org/abs/2508.12870)
*Vinod Khandkar,Kieron Ivy Turk,Ehsan Toreini,Nishanth Sastry*

Main category: cs.CR

TL;DR: 开发了一种通过摇晃手机生成共享密钥的方法，无需网络传输即可实现设备间私密通信，支持消息混淆、信任委托和加密信标三种应用


<details>
  <summary>Details</summary>
Motivation: 在社交规范和法律政治条件快速变化的背景下，敏感话题讨论受到限制，现有通信服务依赖第三方基础设施，存在可访问性和安全性问题，需要不依赖网络的设备间直接私密通信方案

Method: 通过摇晃两部手机一起提取共享随机性，将随机性调节为每字节密钥材料7.798比特，生成共享密钥

Result: 实现了Android独立应用的消息混淆功能，可用于与可信联系人的私密通信，并研究了可用性、设计考虑因素以及在主流服务中的进一步集成

Conclusion: 提出的摇晃生成共享密钥方法为设备间私密通信提供了可行的解决方案，特别是在网络不可用或不可信的情况下，具有实际应用价值

Abstract: Rapidly changing social norms and national, legal, and political conditions
socially constrain people from discussing sensitive topics such as sexuality or
religion. Such constrained, vulnerable minorities are often worried about
inadvertent information disclosure and may be unsure about the extent to which
their communications are being monitored in public or semi-public spaces like
workplaces or cafes. Personal devices extend trust to the digital domain,
making it desirable to have strictly private communication between trusted
devices. Currently, messaging services like WhatsApp provide alternative means
for exchanging sensitive private information, while personal safety apps such
as Noonlight enable private signaling. However, these rely on third-party
mechanisms for secure and private communication, which may not be accessible
for justifiable reasons, such as insecure internet access or companion device
connections. In these cases, it is challenging to achieve communication that is
strictly private between two devices instead of user accounts without any
dependency on third-party infrastructure. The goal of this paper is to support
private communications by setting up a shared secret between two or more
devices without sending any data on the network. We develop a method to create
a shared secret between phones by shaking them together. Each device extracts
the shared randomness from the shake, then conditions the randomness to 7.798
bits per byte of key material. This paper proposes three different applications
of this generated shared secret: message obfuscation, trust delegation, and
encrypted beacons. We have implemented the message obfuscation on Android as an
independent app that can be used for private communication with trusted
contacts. We also present research on the usability, design considerations, and
further integration of these tools in mainstream services.

</details>


### [60] [SecFSM: Knowledge Graph-Guided Verilog Code Generation for Secure Finite State Machines in Systems-on-Chip](https://arxiv.org/abs/2508.12910)
*Ziteng Hu,Yingjie Xia,Xiyuan Chen,Li Kuang*

Main category: cs.CR

TL;DR: SecFSM是一种利用安全知识图谱指导LLM生成更安全Verilog代码的新方法，专门针对有限状态机(FSM)实现中的安全漏洞问题


<details>
  <summary>Details</summary>
Motivation: 传统硬件工程师手动编写Verilog代码实现FSM既繁琐又耗时，而现有LLM生成的Verilog代码存在安全漏洞，特别是在安全敏感的FSM实现中这一问题尤为严重

Method: 首先构建FSM安全知识图谱(FSKG)作为LLM的外部辅助，然后分析用户需求识别漏洞，基于漏洞列表从FSKG检索知识，最后构建安全提示用于Verilog代码生成

Result: 在25个安全测试用例的基准测试中，SecFSM达到了21/25的优异通过率，显著优于现有最先进基线方法

Conclusion: SecFSM通过安全知识图谱的引导，有效提升了LLM生成Verilog代码的安全性，为解决FSM实现中的安全漏洞问题提供了有效解决方案

Abstract: Finite State Machines (FSMs) play a critical role in implementing control
logic for Systems-on-Chip (SoC). Traditionally, FSMs are implemented by
hardware engineers through Verilog coding, which is often tedious and
time-consuming. Recently, with the remarkable progress of Large Language Models
(LLMs) in code generation, LLMs have been increasingly explored for automating
Verilog code generation. However, LLM-generated Verilog code often suffers from
security vulnerabilities, which is particularly concerning for
security-sensitive FSM implementations. To address this issue, we propose
SecFSM, a novel method that leverages a security-oriented knowledge graph to
guide LLMs in generating more secure Verilog code. Specifically, we first
construct a FSM Security Knowledge Graph (FSKG) as an external aid to LLMs.
Subsequently, we analyze users' requirements to identify vulnerabilities and
get a list of vulnerabilities in the requirements. Then, we retrieve knowledge
from FSKG based on the vulnerabilities list. Finally, we construct security
prompts based on the security knowledge for Verilog code generation. To
evaluate SecFSM, we build a dedicated dataset collected from academic datasets,
artificial datasets, papers, and industrial cases. Extensive experiments
demonstrate that SecFSM outperforms state-of-the-art baselines. In particular,
on a benchmark of 25 security test cases evaluated by DeepSeek-R1, SecFSM
achieves an outstanding pass rate of 21/25.

</details>


### [61] [Prescriptive Zero Trust- Assessing the impact of zero trust on cyber attack prevention](https://arxiv.org/abs/2508.12953)
*Samuel Aiello*

Main category: cs.CR

TL;DR: 该研究提出了一个基于零信任架构(ZTA)的四级成熟度模型，通过量化身份验证、微隔离、数据加密、分析和编排等关键技术控制来评估企业的网络安全成熟度。


<details>
  <summary>Details</summary>
Motivation: 随着网络威胁日益复杂多样，企业需要改进安全态势，零信任架构已成为重要基础。但ZTA缺乏明确的量化指南来评估实施成熟度，因此需要数据驱动的方法来量化网络弹性。

Method: 研究评估了ZTA实施中可量化指南的可能性，开发了新的数据驱动方法论，通过评估每个控制组件的集成深度并与行业最佳实践对齐来衡量网络安全成熟度。

Result: 研究结果定义了涵盖身份验证、微隔离、数据加密、分析和编排的关键技术控制集，建立了从初始到优化的四级成熟度模型，每个层级都增加了前一层级的能力。

Conclusion: 该研究提供了一个规范性的ZTA部署框架和成熟度评估模型，帮助企业在其安全转型旅程中划分阶段并评估ZTA实施水平。

Abstract: Increasingly sophisticated and varied cyber threats necessitate ever
improving enterprise security postures. For many organizations today, those
postures have a foundation in the Zero Trust Architecture. This strategy sees
trust as something an enterprise must not give lightly or assume too broadly.
Understanding the ZTA and its numerous controls centered around the idea of not
trusting anything inside or outside the network without verification, will
allow organizations to comprehend and leverage this increasingly common
paradigm. The ZTA, unlike many other regulatory frameworks, is not tightly
defined. The research assesses the likelihood of quantifiable guidelines that
measure cybersecurity maturity for an enterprise organization in relation to
ZTA implementation. This is a new, data driven methodology for quantifying
cyber resilience enabled by the adoption of Zero Trust principles to
pragmatically address the critical need of organizations. It also looks at the
practical aspects ZTA has on capabilities in deterring cyberattacks on a
network. The outcomes of this research define a prescriptive set of key
technical controls across identity verification, microsegmentation, data
encryption, analytics, and orchestration that characterize the comprehensive
ZTA deployment. By evaluating the depth of integration for each control
component and aligning to industry best practices, the study's results help
assess an organization's ZTA maturity level on a scale from Initial to
Optimized adoption. The research's resultant four tier model demarcates phases
for an organization on its security transformation journey, with each tier
adding to the capability of the last.

</details>


### [62] [AuthenTree: A Scalable MPC-Based Distributed Trust Architecture for Chiplet-based Heterogeneous Systems](https://arxiv.org/abs/2508.13033)
*Ishraq Tashdid,Tasnuva Farheen,Sazadur Rahman*

Main category: cs.CR

TL;DR: AuthenTree是一个基于多方计算的分布式认证框架，用于解决chiplet异构集成中的安全威胁，无需专用安全硬件或集中信任，在面积、功耗和延迟方面具有极低开销。


<details>
  <summary>Details</summary>
Motivation: chiplet异构集成的快速发展带来了多供应商组装的安全威胁，如克隆、过度生产和chiplet替换，现有解决方案依赖可信集成商或集中式安全锚点，存在敏感数据泄露和单点故障风险。

Method: 提出了AuthenTree分布式认证框架，利用多方计算(MPC)在可扩展的树状架构中实现安全chiplet验证，不暴露原始签名，将信任分布在多个集成商chiplet之间。

Result: 在五个SiP基准测试中，AuthenTree面积开销低至0.48%(7000平方微米)，功耗开销低于0.5%，认证延迟低于1微秒，在某些情况下比先前工作快700倍。

Conclusion: AuthenTree被证明是零信任SiP环境中下一代chiplet安全的高效、鲁棒和可扩展解决方案。

Abstract: The rapid adoption of chiplet-based heterogeneous integration is reshaping
semiconductor design by enabling modular, scalable, and faster time-to-market
solutions for AI and high-performance computing. However, multi-vendor assembly
in post-fabrication environments fragments the supply chain and exposes SiP
systems to serious security threats, including cloning, overproduction, and
chiplet substitution. Existing authentication solutions depend on trusted
integrators or centralized security anchors, which can expose sensitive data or
create single points of failure. We introduce AuthenTree, a distributed
authentication framework that leverages multi-party computation (MPC) in a
scalable tree-based architecture, removing the need for dedicated security
hardware or centralized trust. AuthenTree enables secure chiplet validation
without revealing raw signatures, distributing trust across multiple integrator
chiplets. Our evaluation in five SiP benchmarks demonstrates that AuthenTree
imposes minimal overhead, with an area as low as 0.48% (7,000 sq-micrometers),
an overhead power under 0.5%, and an authentication latency below 1
microsecond, surpassing previous work in some cases by 700 times. These results
establish AuthenTree as an efficient, robust, and scalable solution for
next-generation chiplet-based security in zero-trust SiP environments.

</details>


### [63] [MAJIC: Markovian Adaptive Jailbreaking via Iterative Composition of Diverse Innovative Strategies](https://arxiv.org/abs/2508.13048)
*Weiwei Qi,Shuo Shao,Wei Gu,Tianhang Zheng,Puning Zhao,Zhan Qin,Kui Ren*

Main category: cs.CR

TL;DR: MAJIC是一个马尔可夫自适应越狱框架，通过迭代组合多种伪装策略来攻击黑盒LLM，显著提升了攻击成功率和效率


<details>
  <summary>Details</summary>
Motivation: 现有黑盒越狱技术主要依赖静态提示或僵化的攻击方法组合，缺乏适应性和泛化能力，限制了攻击效果

Method: 建立伪装策略池，将策略选择和融合建模为马尔可夫链，通过动态调整转移概率来学习和发现针对目标模型的有效攻击路径

Result: 在GPT-4o和Gemini-2.0-flash等主流模型上显著优于现有方法，平均每次尝试少于15次查询即可达到90%以上的攻击成功率

Conclusion: MAJIC框架通过自适应策略组合有效解决了现有越狱技术的局限性，为黑盒LLM安全评估提供了高效工具

Abstract: Large Language Models (LLMs) have exhibited remarkable capabilities but
remain vulnerable to jailbreaking attacks, which can elicit harmful content
from the models by manipulating the input prompts. Existing black-box
jailbreaking techniques primarily rely on static prompts crafted with a single,
non-adaptive strategy, or employ rigid combinations of several underperforming
attack methods, which limits their adaptability and generalization. To address
these limitations, we propose MAJIC, a Markovian adaptive jailbreaking
framework that attacks black-box LLMs by iteratively combining diverse
innovative disguise strategies. MAJIC first establishes a ``Disguise Strategy
Pool'' by refining existing strategies and introducing several innovative
approaches. To further improve the attack performance and efficiency, MAJIC
formulate the sequential selection and fusion of strategies in the pool as a
Markov chain. Under this formulation, MAJIC initializes and employs a Markov
matrix to guide the strategy composition, where transition probabilities
between strategies are dynamically adapted based on attack outcomes, thereby
enabling MAJIC to learn and discover effective attack pathways tailored to the
target model. Our empirical results demonstrate that MAJIC significantly
outperforms existing jailbreak methods on prominent models such as GPT-4o and
Gemini-2.0-flash, achieving over 90\% attack success rate with fewer than 15
queries per attempt on average.

</details>


### [64] [VerilogLAVD: LLM-Aided Rule Generation for Vulnerability Detection in Verilog](https://arxiv.org/abs/2508.13092)
*Xiang Long,Yingjie Xia,Xiyuan Chen,Li Kuang*

Main category: cs.CR

TL;DR: VerilogLAVD是一个基于LLM的图遍历规则生成方法，用于Verilog硬件漏洞检测，通过结合语法和语义信息构建统一表示，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有硬件漏洞早期检测技术需要专业安全知识，限制了可用性。LLM在Verilog漏洞检测中难以捕捉代码结构，导致检测结果不一致。

Method: 提出Verilog属性图(VeriPG)统一表示，结合AST的语法特征和控制流/数据依赖图的语义信息。利用LLM从CWE描述生成基于VeriPG的检测规则，指导规则执行器遍历检测潜在漏洞。

Result: 在包含12种CWE类型的77个Verilog设计评估中，F1-score达到0.54，相比纯LLM和带外部知识的LLM基线分别提升0.31和0.27。

Conclusion: VerilogLAVD通过结合LLM和结构化图表示，有效解决了Verilog漏洞检测中的结构捕捉问题，显著提升了检测性能。

Abstract: Timely detection of hardware vulnerabilities during the early design stage is
critical for reducing remediation costs. Existing early detection techniques
often require specialized security expertise, limiting their usability. Recent
efforts have explored the use of large language models (LLMs) for Verilog
vulnerability detection. However, LLMs struggle to capture the structure in
Verilog code, resulting in inconsistent detection results. To this end, we
propose VerilogLAVD, the first LLM-aided graph traversal rule generation
approach for Verilog vulnerability detection. Our approach introduces the
Verilog Property Graph (VeriPG), a unified representation of Verilog code. It
combines syntactic features extracted from the abstract syntax tree (AST) with
semantic information derived from control flow and data dependency graphs. We
leverage LLMs to generate VeriPG-based detection rules from Common Weakness
Enumeration (CWE) descriptions. These rules guide the rule executor that
traversal VeriPG for potential vulnerabilities. To evaluate VerilogLAVD, we
build a dataset collected from open-source repositories and synthesized data.
In our empirical evaluation on 77 Verilog designs encompassing 12 CWE types,
VerilogLAVD achieves an F1-score of 0.54. Compared to the LLM-only and LLM with
external knowledge baselines, VerilogLAVD improves F1-score by 0.31 and 0.27,
respectively.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [65] [Finite Automata Extraction: Low-data World Model Learning as Programs from Gameplay Video](https://arxiv.org/abs/2508.11836)
*Dave Goel,Matthew Guzdial,Anurag Sarkar*

Main category: cs.AI

TL;DR: FAE方法从游戏视频中学习神经符号世界模型，用Retro Coder DSL表示，相比之前的方法能学习更精确的环境模型和更通用的代码


<details>
  <summary>Details</summary>
Motivation: 传统世界模型通常是神经网络表示，难以迁移学习到的环境动态和解释。需要一种既能保持学习能力又具有可解释性的方法

Method: 提出有限自动机提取(FAE)方法，从游戏视频中学习神经符号世界模型，用新颖的领域特定语言Retro Coder表示程序

Result: 相比之前的世界模型方法，FAE学习了更精确的环境模型；相比之前的DSL方法，生成了更通用的代码

Conclusion: FAE方法成功地将神经学习和符号表示结合，在游戏环境建模方面取得了更好的精确性和通用性

Abstract: World models are defined as a compressed spatial and temporal learned
representation of an environment. The learned representation is typically a
neural network, making transfer of the learned environment dynamics and
explainability a challenge. In this paper, we propose an approach, Finite
Automata Extraction (FAE), that learns a neuro-symbolic world model from
gameplay video represented as programs in a novel domain-specific language
(DSL): Retro Coder. Compared to prior world model approaches, FAE learns a more
precise model of the environment and more general code than prior DSL-based
approaches.

</details>


### [66] [EvoCut: Strengthening Integer Programs via Evolution-Guided Language Models](https://arxiv.org/abs/2508.11850)
*Milad Yazdani,Mahdi Mostajabdaveh,Samin Aref,Zirui Zhou*

Main category: cs.AI

TL;DR: EvoCut是一个自动化生成整数规划加速割的框架，结合大语言模型和进化搜索，无需人工干预即可显著提升求解器性能


<details>
  <summary>Details</summary>
Motivation: 整数规划是组合优化的核心但NP难问题，传统依赖专家手工设计加速割的方法效率低下且难以自动化

Method: 结合LLM初始化候选割，通过进化搜索迭代优化，评估割的效用（保持最优解和削减分数解的能力），量化其对求解器最优间隙的改善

Result: 在固定时间内将最优间隙降低17-57%，获得相同解的速度提升4倍，在相同时间内获得更高质量的解

Conclusion: EvoCut能够可靠地生成、改进和验证可泛化到未见实例的加速割，为整数规划自动化提供了有效解决方案

Abstract: Integer programming lies at the heart of crucial combinatorial optimization
tasks but remains challenging due to its NP-hard nature. An effective approach
for practically solving integer programs is the manual design of acceleration
cuts, i.e. inequalities that improve solver performance. However, this creative
process demands deep expertise and is yet to be automated. Our proposed
framework, EvoCut, automates the generation of acceleration cuts by combining
large language models (LLMs) with an evolutionary search. EvoCut (i)
initializes a diverse population of candidate cuts via an LLM-based initializer
agent; (ii) for each cut empirically evaluates both preservation of the optimal
solution and its ability to cut off fractional solutions across a verification
set; and (iii) iteratively refines the population through evolutionary
crossover and mutation agents. We quantify each cut's utility by its relative
reduction in the solver's optimality gap. Our comparisons against standard
integer programming practice show that EvoCut reduces optimality gap by 17-57%
within a fixed time. It obtains the same solutions up to 4 times as fast, and
obtains higher-quality solutions within the same time limit. Requiring no human
expert input, EvoCut reliably generates, improves, and empirically verifies
cuts that generalize to unseen instances. The code is available at
https://github.com/milad1378yz/EvoCut.

</details>


### [67] [LARC: Towards Human-level Constrained Retrosynthesis Planning through an Agentic Framework](https://arxiv.org/abs/2508.11860)
*Frazier N. Baker,Daniel Adu-Ampratwum,Reza Averly,Botao Yu,Huan Sun,Xia Ning*

Main category: cs.AI

TL;DR: LARC是首个基于LLM的约束逆合成规划代理框架，通过工具化推理的代理反馈来指导路线生成，在48个约束任务上达到72.9%的成功率，远超LLM基线并接近人类专家水平


<details>
  <summary>Details</summary>
Motivation: 约束逆合成规划是化学中的重要但具有挑战性的过程，需要从商业化起始材料到目标分子的合成路线识别，同时满足实际约束条件

Method: LARC框架采用代理作为评判者，将代理约束评估直接整合到逆合成规划过程中，使用基于工具推理的代理反馈来指导和约束路线生成

Result: 在精心策划的48个约束逆合成规划任务上，LARC达到72.9%的成功率，显著优于LLM基线方法，在更短时间内接近人类专家水平

Conclusion: LARC框架具有可扩展性，是向有效代理工具或人类专家协作者迈出的第一步，用于约束逆合成规划

Abstract: Large language model (LLM) agent evaluators leverage specialized tools to
ground the rational decision-making of LLMs, making them well-suited to aid in
scientific discoveries, such as constrained retrosynthesis planning.
Constrained retrosynthesis planning is an essential, yet challenging, process
within chemistry for identifying synthetic routes from commercially available
starting materials to desired target molecules, subject to practical
constraints. Here, we present LARC, the first LLM-based Agentic framework for
Retrosynthesis planning under Constraints. LARC incorporates agentic constraint
evaluation, through an Agent-as-a-Judge, directly into the retrosynthesis
planning process, using agentic feedback grounded in tool-based reasoning to
guide and constrain route generation. We rigorously evaluate LARC on a
carefully curated set of 48 constrained retrosynthesis planning tasks across 3
constraint types. LARC achieves a 72.9% success rate on these tasks, vastly
outperforming LLM baselines and approaching human expert-level success in
substantially less time. The LARC framework is extensible, and serves as a
first step towards an effective agentic tool or a co-scientist to human experts
for constrained retrosynthesis.

</details>


### [68] [QuarkMed Medical Foundation Model Technical Report](https://arxiv.org/abs/2508.11894)
*Ao Li,Bin Yan,Bingfeng Cai,Chenxi Li,Cunzhong Zhao,Fugen Yao,Gaoqiang Liu,Guanjun Jiang,Jian Xu,Liang Dong,Liansheng Sun,Rongshen Zhang,Xiaolei Gui,Xin Liu,Xin Shang,Yao Wu,Yu Cao,Zhenxin Ma,Zhuang Jia*

Main category: cs.AI

TL;DR: QuarkMed开发了一个高性能医疗基础模型，通过医学数据处理、检索增强生成和大规模可验证强化学习，在中医执业考试中达到70%准确率，已服务数百万用户。


<details>
  <summary>Details</summary>
Motivation: 医疗任务需要高度专业的知识、专业准确性和定制能力，现有大语言模型在医疗应用中需要更可靠的基础模型来满足这些需求。

Method: 利用精选医学数据处理、医学内容检索增强生成(RAG)和大规模可验证强化学习管道来开发高性能医疗基础模型。

Result: 模型在中国医学执业考试中达到70%的准确率，在多样化医学基准测试中表现出强大的泛化能力。

Conclusion: QuarkMed提供了一个强大而通用的个人医疗AI解决方案，已在ai.quark.cn服务超过数百万用户。

Abstract: Recent advancements in large language models have significantly accelerated
their adoption in healthcare applications, including AI-powered medical
consultations, diagnostic report assistance, and medical search tools. However,
medical tasks often demand highly specialized knowledge, professional accuracy,
and customization capabilities, necessitating a robust and reliable foundation
model. QuarkMed addresses these needs by leveraging curated medical data
processing, medical-content Retrieval-Augmented Generation (RAG), and a
large-scale, verifiable reinforcement learning pipeline to develop a
high-performance medical foundation model. The model achieved 70% accuracy on
the Chinese Medical Licensing Examination, demonstrating strong generalization
across diverse medical benchmarks. QuarkMed offers a powerful yet versatile
personal medical AI solution, already serving over millions of users at
ai.quark.cn.

</details>


### [69] [CHBench: A Cognitive Hierarchy Benchmark for Evaluating Strategic Reasoning Capability of LLMs](https://arxiv.org/abs/2508.11944)
*Hongtao Liu,Zhicheng Du,Zihe Wang,Weiran Shen*

Main category: cs.AI

TL;DR: 提出了CHBench评估框架，基于认知层次模型来评估大语言模型的战略推理能力，通过系统性的三阶段框架分析不同LLM在博弈中的表现，发现聊天机制会降低战略推理而记忆机制能提升它。


<details>
  <summary>Details</summary>
Motivation: 现有的基于效用性能指标的评估方法不够鲁棒，受对手行为和游戏结构变化影响较大，需要更可靠的评估框架来测试LLMs的战略推理能力。

Method: 采用认知层次模型理论，设计三阶段系统性评估框架：1）收集15个精选标准形式游戏中6个先进LLMs的行为数据；2）分析不同推理深度的战略行为；3）评估聊天机制和记忆机制对战略推理的影响。

Result: 实验表明LLMs在不同对手面前展现出一致的战略推理水平，验证了框架的鲁棒性和泛化能力。聊天机制显著降低战略推理性能，而记忆机制能提升战略推理能力。

Conclusion: CHBench是一个有前景的评估工具，能够有效评估LLM的战略推理能力，对未来研究和实际应用具有重要价值。

Abstract: Game-playing ability serves as an indicator for evaluating the strategic
reasoning capability of large language models (LLMs). While most existing
studies rely on utility performance metrics, which are not robust enough due to
variations in opponent behavior and game structure. To address this limitation,
we propose \textbf{Cognitive Hierarchy Benchmark (CHBench)}, a novel evaluation
framework inspired by the cognitive hierarchy models from behavioral economics.
We hypothesize that agents have bounded rationality -- different agents behave
at varying reasoning depths/levels. We evaluate LLMs' strategic reasoning
through a three-phase systematic framework, utilizing behavioral data from six
state-of-the-art LLMs across fifteen carefully selected normal-form games.
Experiments show that LLMs exhibit consistent strategic reasoning levels across
diverse opponents, confirming the framework's robustness and generalization
capability. We also analyze the effects of two key mechanisms (Chat Mechanism
and Memory Mechanism) on strategic reasoning performance. Results indicate that
the Chat Mechanism significantly degrades strategic reasoning, whereas the
Memory Mechanism enhances it. These insights position CHBench as a promising
tool for evaluating LLM capabilities, with significant potential for future
research and practical applications.

</details>


### [70] [Data Mixing Optimization for Supervised Fine-Tuning of Large Language Models](https://arxiv.org/abs/2508.11953)
*Yuan Li,Zhengzhong Liu,Eric Xing*

Main category: cs.AI

TL;DR: 通过建模有效数据转移和利用缩放定律来优化监督微调数据混合，该算法能够小化验证损失并提升模型性能


<details>
  <summary>Details</summary>
Motivation: 监督微调数据混合优化对发展通用模型至关重要，但目前这个领域研究不够，需要更科学的方法来确定最优数据混合比例

Method: 将数据混合形式化为优化问题，通过建模有效数据转移和利用缩放定律来参数化损失函数，在小规模数据混合上调整参数并求解最优权重

Result: 算法在所有领域都取得优秀的整体和个别性能，与网格搜索确定的最优权重性能相当，每个领域损失仅比网格搜索的最优值平均高出0.66%，重新权重常用SFT数据集能同时改善验证损失和下游性能

Conclusion: 该方法不仅能够高效优化SFT数据混合，还可以推广到指导领域特定模型的数据选择，为SFT过程提供了深入的见解

Abstract: Optimizing data mixtures for supervised fine-tuning (SFT) of large language
models (LLMs) is critical for developing general-purpose models, yet this area
remains underexplored. In this paper, we frame data mixing as an optimization
problem and introduce a novel method designed to minimize validation loss. Our
approach parametrizes the loss by modeling effective data transferred and
leveraging scaling laws for fine-tuning. By experimenting with various
small-scale data mixtures, we fit these parameters and derive the optimal
weights. We provide both mathematical proofs and empirical results
demonstrating that our algorithm achieves excellent overall and individual
performance across all domains. Through controlled experiments, we show that
models trained with our optimized weights perform on par with those using
optimal weights determined via grid search, with per-domain loss only 0.66%
higher than the best domain loss from grid search on average. Additionally, we
show that reweighting popular SFT datasets using our method improves both
validation loss and downstream performance. Finally, we discuss how our method
can generalize to guide data selection for domain-specific models and provide
insights into SFT.

</details>


### [71] [UniCast: A Unified Multimodal Prompting Framework for Time Series Forecasting](https://arxiv.org/abs/2508.11954)
*Sehyuk Park,Soyeon Caren Han,Eduard Hovy*

Main category: cs.AI

TL;DR: UniCast是一个参数高效的多模态时间序列预测框架，通过结合视觉和文本信息来增强传统时间序列基础模型的性能


<details>
  <summary>Details</summary>
Motivation: 现有时间序列基础模型主要工作在单模态设置中，忽略了现实场景中常伴随时间序列数据的丰富多模态上下文（如视觉和文本信号）

Method: 通过软提示调优将预训练的视觉和文本编码器的模态特定嵌入与冻结的时间序列基础模型集成，实现高效的跨模态交互和最小参数更新

Result: 在多个时间序列预测基准测试中，UniCast始终显著优于所有现有的时间序列基础模型基线

Conclusion: 多模态上下文在推进下一代通用时间序列预测器发展中起着关键作用

Abstract: Time series forecasting is a foundational task across domains, such as
finance, healthcare, and environmental monitoring. While recent advances in
Time Series Foundation Models (TSFMs) have demonstrated strong generalisation
through large-scale pretraining, existing models operate predominantly in a
unimodal setting, ignoring the rich multimodal context, such as visual and
textual signals, that often accompanies time series data in real-world
scenarios. This paper introduces a novel parameter-efficient multimodal
framework, UniCast, that extends TSFMs to jointly leverage time series, vision,
and text modalities for enhanced forecasting performance. Our method integrates
modality-specific embeddings from pretrained Vision and Text Encoders with a
frozen TSFM via soft prompt tuning, enabling efficient adaptation with minimal
parameter updates. This design not only preserves the generalisation strength
of the foundation model but also enables effective cross-modal interaction.
Extensive experiments across diverse time-series forecasting benchmarks
demonstrate that UniCast consistently and significantly outperforms all
existing TSFM baselines. The findings highlight the critical role of multimodal
context in advancing the next generation of general-purpose time series
forecasters.

</details>


### [72] [Rigorous Feature Importance Scores based on Shapley Value and Banzhaf Index](https://arxiv.org/abs/2508.11959)
*Xuanxiang Huang,Olivier Létoffé,Joao Marques-Silva*

Main category: cs.AI

TL;DR: 本文提出了两种基于Shapley值和Banzhaf指数的新特征重要性评分方法，通过考虑非弱溯因解释集来量化特征排除对抗样本的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于弱溯因解释(WAXp)的特征归因方法忽略了非WAXp集的重要信息，而这些集与对抗样本(AExs)密切相关，需要更全面的特征重要性评估方法。

Method: 利用Shapley值和Banzhaf指数设计两种新颖的特征重要性评分，在计算特征贡献时考虑非WAXp集，量化每个特征排除对抗样本的有效性。

Result: 提出了两种新的特征重要性评分方法，能够更全面地评估特征在排除对抗样本方面的贡献。

Conclusion: 新方法通过整合非WAXp集信息，提供了更准确的特征重要性评估，对高风险的机器学习应用具有重要意义。

Abstract: Feature attribution methods based on game theory are ubiquitous in the field
of eXplainable Artificial Intelligence (XAI). Recent works proposed rigorous
feature attribution using logic-based explanations, specifically targeting
high-stakes uses of machine learning (ML) models. Typically, such works exploit
weak abductive explanation (WAXp) as the characteristic function to assign
importance to features. However, one possible downside is that the contribution
of non-WAXp sets is neglected. In fact, non-WAXp sets can also convey important
information, because of the relationship between formal explanations (XPs) and
adversarial examples (AExs). Accordingly, this paper leverages Shapley value
and Banzhaf index to devise two novel feature importance scores. We take into
account non-WAXp sets when computing feature contribution, and the novel scores
quantify how effective each feature is at excluding AExs. Furthermore, the
paper identifies properties and studies the computational complexity of the
proposed scores.

</details>


### [73] [Chart-CoCa: Self-Improving Chart Understanding of Vision LMs via Code-Driven Synthesis and Candidate-Conditioned Answering](https://arxiv.org/abs/2508.11975)
*Gongyao Jiang,Qiong Luo*

Main category: cs.AI

TL;DR: 该论文提出了一种通过代码生成和执行创建对齐的图表-问题-答案三元组的合成数据生成方法，并设计了候选条件回答过程，使VLM能够自我改进，在无需人工标注数据或外部模型的情况下显著提升图表理解性能。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在图表理解任务中表现不佳，特别是在准确描述和复杂推理方面。合成数据生成是解决方案，但面临噪声标签的挑战。

Method: 1) 引入图表合成流水线，通过代码生成和执行生成对齐的图表-问题-答案三元组；2) 设计候选条件回答过程，VLM为每个查询生成多个响应，然后通过上下文化这些候选项合成最终答案。

Result: 实验显示显著改进，在完全自我改进的范式下，相比初始VLM获得了高达15.50个百分点的准确率提升。

Conclusion: 该方法能够在无需人工标注数据或外部模型的情况下，有效提升视觉语言模型的图表理解能力，实现了完全自我改进的范式。

Abstract: Vision Language Models (VLMs) often struggle with chart understanding tasks,
particularly in accurate chart description and complex reasoning. Synthetic
data generation is a promising solution, while usually facing the challenge of
noise labels. To address this challenge, we first introduce a chart synthesis
pipeline that generates aligned chart-question-answer triplets through code
generation and execution, ensuring the reliability of synthetic data without
human intervention. Furthermore, inspired by test-time scaling that increases
inference budget and thereby improves performance, we design a
candidate-conditioned answering process. The VLM first generates multiple
responses per query, and then synthesizes the final answer by contextualizing
these candidates. Experiments demonstrate significant improvements, with up to
15.50 points accuracy gain over the initial VLM, in a fully self-improving
paradigm without either human-labeled data or external models.

</details>


### [74] [FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction](https://arxiv.org/abs/2508.11987)
*Zhiyuan Zeng,Jiashuo Liu,Siyuan Chen,Tianci He,Yali Liao,Jinpeng Wang,Zaiyuan Wang,Yang Yang,Lingyue Yin,Mingren Yin,Zhenwei Zhu,Tianle Cai,Zehui Chen,Jiecao Chen,Yantao Du,Xiang Gao,Jiacheng Guo,Liang Hu,Jianpeng Jiao,Xiangsheng Li,Jingkai Liu,Shuang Ni,Zhoufutu Wen,Ge Zhang,Kaiyuan Zhang,Xin Zhou,Jose Blanchet,Xipeng Qiu,Mengdi Wang,Wenhao Huang*

Main category: cs.AI

TL;DR: FutureX是一个动态实时评估基准，专门用于评估LLM代理在复杂未来预测任务中的表现，支持每日实时更新并防止数据污染。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏大规模基准来评估LLM代理的未来预测能力，主要由于处理实时更新和获取及时准确答案的挑战。

Method: 构建自动化流水线进行问题收集和答案收集，评估25个具有推理、搜索能力和外部工具集成的LLM/代理模型。

Result: 提供了对代理失败模式和性能缺陷的深入分析，包括对虚假网页的脆弱性和时间有效性等问题。

Conclusion: 目标是建立一个动态、无污染的评估标准，推动LLM代理在复杂推理和预测思维方面达到专业人类分析师水平。

Abstract: Future prediction is a complex task for LLM agents, requiring a high level of
analytical thinking, information gathering, contextual understanding, and
decision-making under uncertainty. Agents must not only gather and interpret
vast amounts of dynamic information but also integrate diverse data sources,
weigh uncertainties, and adapt predictions based on emerging trends, just as
human experts do in fields like politics, economics, and finance. Despite its
importance, no large-scale benchmark exists for evaluating agents on future
prediction, largely due to challenges in handling real-time updates and
retrieving timely, accurate answers. To address this, we introduce
$\textbf{FutureX}$, a dynamic and live evaluation benchmark specifically
designed for LLM agents performing future prediction tasks. FutureX is the
largest and most diverse live benchmark for future prediction, supporting
real-time daily updates and eliminating data contamination through an automated
pipeline for question gathering and answer collection. We evaluate 25 LLM/agent
models, including those with reasoning, search capabilities, and integration of
external tools such as the open-source Deep Research Agent and closed-source
Deep Research models. This comprehensive evaluation assesses agents' adaptive
reasoning and performance in dynamic environments. Additionally, we provide
in-depth analyses of agents' failure modes and performance pitfalls in
future-oriented tasks, including the vulnerability to fake web pages and the
temporal validity. Our goal is to establish a dynamic, contamination-free
evaluation standard that drives the development of LLM agents capable of
performing at the level of professional human analysts in complex reasoning and
predictive thinking.

</details>


### [75] [Modeling Relational Logic Circuits for And-Inverter Graph Convolutional Network](https://arxiv.org/abs/2508.11991)
*Weihao Sun*

Main category: cs.AI

TL;DR: AIGer是一个用于AIG图建模的新方法，通过节点逻辑特征初始化和异构图卷积网络，在信号概率预测和真值表距离预测任务中显著优于现有最佳模型。


<details>
  <summary>Details</summary>
Motivation: 解决现实世界AIG图中由于结构复杂、节点规模大导致的准确建模困难，现有方法缺乏对功能和结构特征的联合建模能力以及动态信息传播能力不足的问题。

Method: 包含两个组件：1)节点逻辑特征初始化嵌入组件，将逻辑节点投影到独立语义空间；2)AIG特征学习网络组件，使用异构图卷积网络设计动态关系权重矩阵和差异化信息聚合方法。

Result: 在信号概率预测任务中，MAE和MSE分别提升18.95%和44.44%；在真值表距离预测任务中，MAE和MSE分别提升33.57%和14.79%。

Conclusion: AIGer通过联合建模功能与结构特征并增强消息传递能力，在AIG图建模任务中取得了显著性能提升。

Abstract: The automation of logic circuit design enhances chip performance, energy
efficiency, and reliability, and is widely applied in the field of Electronic
Design Automation (EDA).And-Inverter Graphs (AIGs) efficiently represent,
optimize, and verify the functional characteristics of digital circuits,
enhancing the efficiency of EDA development.Due to the complex structure and
large scale of nodes in real-world AIGs, accurate modeling is challenging,
leading to existing work lacking the ability to jointly model functional and
structural characteristics, as well as insufficient dynamic information
propagation capability.To address the aforementioned challenges, we propose
AIGer.Specifically, AIGer consists of two components: 1) Node logic feature
initialization embedding component and 2) AIGs feature learning network
component.The node logic feature initialization embedding component projects
logic nodes, such as AND and NOT, into independent semantic spaces, to enable
effective node embedding for subsequent processing.Building upon this, the AIGs
feature learning network component employs a heterogeneous graph convolutional
network, designing dynamic relationship weight matrices and differentiated
information aggregation approaches to better represent the original structure
and information of AIGs.The combination of these two components enhances
AIGer's ability to jointly model functional and structural characteristics and
improves its message passing capability. Experimental results indicate that
AIGer outperforms the current best models in the Signal Probability Prediction
(SSP) task, improving MAE and MSE by 18.95\% and 44.44\%, respectively. In the
Truth Table Distance Prediction (TTDP) task, AIGer achieves improvements of
33.57\% and 14.79\% in MAE and MSE, respectively, compared to the
best-performing models.

</details>


### [76] [AgentCDM: Enhancing Multi-Agent Collaborative Decision-Making via ACH-Inspired Structured Reasoning](https://arxiv.org/abs/2508.11995)
*Xuyang Zhao,Shiwan Zhao,Hualong Yu,Liting Zhang,Qicheng Li*

Main category: cs.AI

TL;DR: 提出了AgentCDM框架，通过结构化推理范式改进LLM多智能体系统中的协作决策，采用两阶段训练方法，在多个基准数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统的协作决策方法存在缺陷：要么依赖单一智能体的'独裁'策略易受认知偏见影响，要么使用'投票制'方法无法充分利用集体智慧。需要更有效的协作决策机制。

Method: 基于认知科学中的竞争假设分析(ACH)原理，设计结构化推理范式，包括两阶段训练：第一阶段使用显式ACH支架指导结构化推理，第二阶段逐步移除支架以促进自主泛化。

Result: 在多个基准数据集上的实验表明，AgentCDM实现了最先进的性能，并展现出强大的泛化能力。

Conclusion: AgentCDM有效提高了多智能体系统中协作决策的质量和鲁棒性，将决策从被动答案选择转变为主动假设评估和构建。

Abstract: Multi-agent systems (MAS) powered by large language models (LLMs) hold
significant promise for solving complex decision-making tasks. However, the
core process of collaborative decision-making (CDM) within these systems
remains underexplored. Existing approaches often rely on either ``dictatorial"
strategies that are vulnerable to the cognitive biases of a single agent, or
``voting-based" methods that fail to fully harness collective intelligence. To
address these limitations, we propose \textbf{AgentCDM}, a structured framework
for enhancing collaborative decision-making in LLM-based multi-agent systems.
Drawing inspiration from the Analysis of Competing Hypotheses (ACH) in
cognitive science, AgentCDM introduces a structured reasoning paradigm that
systematically mitigates cognitive biases and shifts decision-making from
passive answer selection to active hypothesis evaluation and construction. To
internalize this reasoning process, we develop a two-stage training paradigm:
the first stage uses explicit ACH-inspired scaffolding to guide the model
through structured reasoning, while the second stage progressively removes this
scaffolding to encourage autonomous generalization. Experiments on multiple
benchmark datasets demonstrate that AgentCDM achieves state-of-the-art
performance and exhibits strong generalization, validating its effectiveness in
improving the quality and robustness of collaborative decisions in MAS.

</details>


### [77] [AI Models for Depressive Disorder Detection and Diagnosis: A Review](https://arxiv.org/abs/2508.12022)
*Dorsa Macky Aleagha,Payam Zohari,Mostafa Haghir Chehreghani*

Main category: cs.AI

TL;DR: 本文对55项关键研究进行系统综述，提出了基于临床任务、数据模态和计算模型的三层次分类法，总结了抑郁症AI诊断领域的主要趋势和挑战。


<details>
  <summary>Details</summary>
Motivation: 抑郁症是全球主要致残原因，但诊断仍依赖主观临床评估。AI技术有望开发客观、可扩展和及时的诊断工具。

Method: 通过系统综述55项关键研究，建立了包含临床任务（诊断vs预测）、数据模态（文本、语音、神经影像、多模态）和计算模型（如图神经网络、大语言模型、混合方法）的三层次分类法。

Result: 分析揭示了三大趋势：图神经网络在脑连接建模中的主导地位、大语言模型在语言数据处理中的兴起，以及对多模态融合、可解释性和算法公平性的新兴关注。

Conclusion: 本研究为计算精神病学领域的未来创新提供了全面的路线图，综合了当前进展并突出了开放挑战。

Abstract: Major Depressive Disorder is one of the leading causes of disability
worldwide, yet its diagnosis still depends largely on subjective clinical
assessments. Integrating Artificial Intelligence (AI) holds promise for
developing objective, scalable, and timely diagnostic tools. In this paper, we
present a comprehensive survey of state-of-the-art AI methods for depression
detection and diagnosis, based on a systematic review of 55 key studies. We
introduce a novel hierarchical taxonomy that structures the field by primary
clinical task (diagnosis vs. prediction), data modality (text, speech,
neuroimaging, multimodal), and computational model class (e.g., graph neural
networks, large language models, hybrid approaches). Our in-depth analysis
reveals three major trends: the predominance of graph neural networks for
modeling brain connectivity, the rise of large language models for linguistic
and conversational data, and an emerging focus on multimodal fusion,
explainability, and algorithmic fairness. Alongside methodological insights, we
provide an overview of prominent public datasets and standard evaluation
metrics as a practical guide for researchers. By synthesizing current advances
and highlighting open challenges, this survey offers a comprehensive roadmap
for future innovation in computational psychiatry.

</details>


### [78] [Bongard-RWR+: Real-World Representations of Fine-Grained Concepts in Bongard Problems](https://arxiv.org/abs/2508.12026)
*Szymon Pawlonka,Mikołaj Małkiński,Jacek Mańdziuk*

Main category: cs.AI

TL;DR: 本文提出了Bongard-RWR+数据集，包含5400个实例，使用VLM生成的逼真图像来表示原始Bongard问题的抽象概念，评估发现VLM在细粒度概念识别上存在困难。


<details>
  <summary>Details</summary>
Motivation: 现有的Bongard问题数据集要么使用合成图像缺乏真实复杂性，要么使用真实图像但概念过于简单，而手动构建的Bongard-RWR数据集规模太小限制了评估鲁棒性。

Method: 基于Bongard-RWR，使用Pixtral-12B描述手动筛选的图像并生成符合概念的新描述，用Flux.1-dev从描述合成图像，手动验证图像忠实反映概念，构建了5400个实例的数据集。

Result: 评估发现最先进的VLM能够识别粗粒度视觉概念，但在辨别细粒度概念方面持续存在困难，突显了其推理能力的局限性。

Conclusion: Bongard-RWR+数据集为抽象视觉推理提供了大规模测试平台，揭示了当前VLM在细粒度概念推理方面的不足，为未来模型改进提供了基准。

Abstract: Bongard Problems (BPs) provide a challenging testbed for abstract visual
reasoning (AVR), requiring models to identify visual concepts fromjust a few
examples and describe them in natural language. Early BP benchmarks featured
synthetic black-and-white drawings, which might not fully capture the
complexity of real-world scenes. Subsequent BP datasets employed real-world
images, albeit the represented concepts are identifiable from high-level image
features, reducing the task complexity. Differently, the recently released
Bongard-RWR dataset aimed at representing abstract concepts formulated in the
original BPs using fine-grained real-world images. Its manual construction,
however, limited the dataset size to just $60$ instances, constraining
evaluation robustness. In this work, we introduce Bongard-RWR+, a BP dataset
composed of $5\,400$ instances that represent original BP abstract concepts
using real-world-like images generated via a vision language model (VLM)
pipeline. Building on Bongard-RWR, we employ Pixtral-12B to describe manually
curated images and generate new descriptions aligned with the underlying
concepts, use Flux.1-dev to synthesize images from these descriptions, and
manually verify that the generated images faithfully reflect the intended
concepts. We evaluate state-of-the-art VLMs across diverse BP formulations,
including binary and multiclass classification, as well as textual answer
generation. Our findings reveal that while VLMs can recognize coarse-grained
visual concepts, they consistently struggle with discerning fine-grained
concepts, highlighting limitations in their reasoning capabilities.

</details>


### [79] [Active inference for action-unaware agents](https://arxiv.org/abs/2508.12027)
*Filippo Torresan,Keisuke Suzuki,Ryota Kanai,Manuel Baltieri*

Main category: cs.AI

TL;DR: 比较主动推理中动作感知与动作无感知代理在导航任务中的性能表现，发现动作无感知代理虽然处于严重劣势但仍能达到与动作感知代理相当的性能水平


<details>
  <summary>Details</summary>
Motivation: 主动推理框架中存在两种不同的动作规划策略：动作感知（知道自身动作）和动作无感知（需要从观测推断动作），这反映了运动控制中基于传出复制信号存在与否的标准分歧，需要比较这两种策略的性能差异

Method: 在两种导航任务中比较动作感知代理和动作无感知代理的性能表现，分析它们在预期自由能最小化过程中的不同行为方式

Result: 动作无感知代理虽然处于严重劣势，但在导航任务中能够达到与动作感知代理相当的性能水平

Conclusion: 即使在没有传出复制信号的情况下，动作无感知代理通过从观测推断动作的方式仍然能够实现有效的规划和导航性能，这为理解不同运动控制策略的有效性提供了重要见解

Abstract: Active inference is a formal approach to study cognition based on the notion
that adaptive agents can be seen as engaging in a process of approximate
Bayesian inference, via the minimisation of variational and expected free
energies. Minimising the former provides an account of perceptual processes and
learning as evidence accumulation, while minimising the latter describes how
agents select their actions over time. In this way, adaptive agents are able to
maximise the likelihood of preferred observations or states, given a generative
model of the environment. In the literature, however, different strategies have
been proposed to describe how agents can plan their future actions. While they
all share the notion that some kind of expected free energy offers an
appropriate way to score policies, sequences of actions, in terms of their
desirability, there are different ways to consider the contribution of past
motor experience to the agent's future behaviour. In some approaches, agents
are assumed to know their own actions, and use such knowledge to better plan
for the future. In other approaches, agents are unaware of their actions, and
must infer their motor behaviour from recent observations in order to plan for
the future. This difference reflects a standard point of departure in two
leading frameworks in motor control based on the presence, or not, of an
efference copy signal representing knowledge about an agent's own actions. In
this work we compare the performances of action-aware and action-unaware agents
in two navigations tasks, showing how action-unaware agents can achieve
performances comparable to action-aware ones while at a severe disadvantage.

</details>


### [80] [MAPF-World: Action World Model for Multi-Agent Path Finding](https://arxiv.org/abs/2508.12087)
*Zhanjiang Yang,Meng Li,Yang Shen,Yueming Li,Lijun Sun*

Main category: cs.AI

TL;DR: MAPF-World是一个用于多智能体路径规划的自回归动作世界模型，通过显式建模环境时空动态和智能体间依赖关系，在复杂长期规划场景中优于现有可学习求解器，且模型大小和数据需求大幅减少。


<details>
  <summary>Details</summary>
Motivation: 现有分散式可学习求解器主要基于反应式策略模型，对环境时间动态和智能体间依赖关系建模有限，在复杂长期规划场景中性能下降。

Method: 提出MAPF-World自回归动作世界模型，统一情境理解和动作生成，通过未来状态和动作预测显式建模空间特征和时间依赖关系。

Result: 在广泛实验中优于最先进的可学习求解器，在分布外情况下展现优异的零样本泛化能力，模型大小减少96.5%，数据需求减少92%。

Conclusion: MAPF-World通过建模环境动态和预测未来状态，实现了更明智、协调和远见的决策，特别适用于复杂多智能体设置。

Abstract: Multi-agent path finding (MAPF) is the problem of planning conflict-free
paths from the designated start locations to goal positions for multiple
agents. It underlies a variety of real-world tasks, including multi-robot
coordination, robot-assisted logistics, and social navigation. Recent
decentralized learnable solvers have shown great promise for large-scale MAPF,
especially when leveraging foundation models and large datasets. However, these
agents are reactive policy models and exhibit limited modeling of environmental
temporal dynamics and inter-agent dependencies, resulting in performance
degradation in complex, long-term planning scenarios. To address these
limitations, we propose MAPF-World, an autoregressive action world model for
MAPF that unifies situation understanding and action generation, guiding
decisions beyond immediate local observations. It improves situational
awareness by explicitly modeling environmental dynamics, including spatial
features and temporal dependencies, through future state and actions
prediction. By incorporating these predicted futures, MAPF-World enables more
informed, coordinated, and far-sighted decision-making, especially in complex
multi-agent settings. Furthermore, we augment MAPF benchmarks by introducing an
automatic map generator grounded in real-world scenarios, capturing practical
map layouts for training and evaluating MAPF solvers. Extensive experiments
demonstrate that MAPF-World outperforms state-of-the-art learnable solvers,
showcasing superior zero-shot generalization to out-of-distribution cases.
Notably, MAPF-World is trained with a 96.5% smaller model size and 92% reduced
data.

</details>


### [81] [Overcoming Knowledge Discrepancies: Structuring Reasoning Threads through Knowledge Balancing in Interactive Scenarios](https://arxiv.org/abs/2508.12100)
*Daniel Burkhardt,Xiangwei Cheng*

Main category: cs.AI

TL;DR: 提出了ReT-Eval框架，通过原型启发式两阶段推理线程评估方法，解决现有推理模型缺乏语义层次结构、用户-领域知识对齐和有效剪枝机制的问题


<details>
  <summary>Details</summary>
Motivation: 当前推理模型缺乏显式语义层次结构、用户与领域知识对齐，以及有效的推理线程剪枝机制，导致输出冗长且无法有效指导用户进行目标导向推理

Method: 采用原型启发的两阶段框架：第一阶段使用图神经网络从稀疏领域知识图中提取语义相关知识结构，并用LLM知识丰富以解决知识差异；第二阶段使用奖励引导策略评估和剪枝推理线程以保持语义连贯性

Result: 实验和专家评估表明，ReT-Eval增强了用户理解能力，并优于最先进的推理模型

Conclusion: ReT-Eval框架通过结构化知识重用和有效剪枝机制，显著提升了交互式问题解决场景中的推理效果和用户体验

Abstract: Reasoning in interactive problem solving scenarios requires models to
construct reasoning threads that reflect user understanding and align with
structured domain knowledge. However, current reasoning models often lack
explicit semantic hierarchies, user-domain knowledge alignment, and principled
mechanisms to prune reasoning threads for effectiveness. These limitations
result in lengthy generic output that does not guide users through
goal-oriented reasoning steps. To address this, we propose a
prototype-inspired, two-phases Reasoning-Threads-Evaluation (ReT-Eval)
framework, drawing inspiration from human-like reasoning strategies that
emphasize structured knowledge reuse. In the first phase, semantically relevant
knowledge structures are extracted from a sparse domain knowledge graph using a
graph neural network and enriched with intrinsic large language model knowledge
to resolve knowledge discrepancies. In the second phase, these threads are
evaluated and pruned using a reward-guided strategy aimed at maintaining
semantic coherence to generate effective reasoning threads. Experiments and
expert evaluations show that ReT-Eval enhances user understanding and
outperforms state-of-the-art reasoning models.

</details>


### [82] [Exploring Autonomous Agents: A Closer Look at Why They Fail When Completing Tasks](https://arxiv.org/abs/2508.13143)
*Ruofan Lu,Yichen Li,Yintong Huo*

Main category: cs.AI

TL;DR: 提出了一个包含34个可编程任务的基准测试，用于系统评估自主代理系统，发现当前系统的任务完成率约为50%，并通过深入分析建立了三层失败原因分类法，提出了改进建议。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的自主代理系统评估主要依赖成功率，缺乏对系统交互、通信机制和失败原因的系统性分析，需要建立更全面的评估框架。

Method: 开发了包含34个代表性可编程任务的基准测试，评估了三种流行的开源代理框架与两种LLM骨干网络的组合，通过深入失败分析建立了三层失败原因分类法。

Result: 观察到任务完成率约为50%，识别出规划错误、任务执行问题和错误响应生成等主要失败原因，并提出了相应的改进建议。

Conclusion: 建立的失败分类法和缓解建议为开发更强大有效的自主代理系统提供了实证基础，有助于提升代理的规划能力和自我诊断能力。

Abstract: Autonomous agent systems powered by Large Language Models (LLMs) have
demonstrated promising capabilities in automating complex tasks. However,
current evaluations largely rely on success rates without systematically
analyzing the interactions, communication mechanisms, and failure causes within
these systems. To bridge this gap, we present a benchmark of 34 representative
programmable tasks designed to rigorously assess autonomous agents. Using this
benchmark, we evaluate three popular open-source agent frameworks combined with
two LLM backbones, observing a task completion rate of approximately 50%.
Through in-depth failure analysis, we develop a three-tier taxonomy of failure
causes aligned with task phases, highlighting planning errors, task execution
issues, and incorrect response generation. Based on these insights, we propose
actionable improvements to enhance agent planning and self-diagnosis
capabilities. Our failure taxonomy, together with mitigation advice, provides
an empirical foundation for developing more robust and effective autonomous
agent systems in the future.

</details>


### [83] [MOVER: Multimodal Optimal Transport with Volume-based Embedding Regularization](https://arxiv.org/abs/2508.12149)
*Haochen You,Baojing Liu*

Main category: cs.AI

TL;DR: MOVER是一个多模态学习框架，通过最优传输软对齐和几何体积正则化，在共享嵌入空间中构建语义对齐的结构化多模态表示，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态对比学习方法在双模态设置中有效，但难以扩展到多模态场景，且在高维空间中缺乏语义结构。需要一种能够统一对齐多种模态并保持语义结构的方法。

Method: 结合最优传输的软对齐机制和几何体积最小化目标（GAVE），通过传输引导的匹配和几何正则化，实现模态无关的一致性对齐。

Result: 在文本-视频-音频检索任务中，MOVER在零样本和微调设置下均显著优于现有最先进方法，展现出更好的泛化能力和嵌入空间结构一致性。

Conclusion: MOVER框架通过最优传输和几何正则化的结合，成功解决了多模态对齐中的语义结构和泛化问题，为多模态学习提供了有效的解决方案。

Abstract: Recent advances in multimodal learning have largely relied on pairwise
contrastive objectives to align different modalities, such as text, video, and
audio, in a shared embedding space. While effective in bi-modal setups, these
approaches struggle to generalize across multiple modalities and often lack
semantic structure in high-dimensional spaces. In this paper, we propose MOVER,
a novel framework that combines optimal transport-based soft alignment with
volume-based geometric regularization to build semantically aligned and
structured multimodal representations. By integrating a transport-guided
matching mechanism with a geometric volume minimization objective (GAVE), MOVER
encourages consistent alignment across all modalities in a modality-agnostic
manner. Experiments on text-video-audio retrieval tasks demonstrate that MOVER
significantly outperforms prior state-of-the-art methods in both zero-shot and
finetuned settings. Additional analysis shows improved generalization to unseen
modality combinations and stronger structural consistency in the learned
embedding space.

</details>


### [84] [RLNVR: Reinforcement Learning from Non-Verified Real-World Rewards](https://arxiv.org/abs/2508.12165)
*Rohit Krishnan,Jon Evans*

Main category: cs.AI

TL;DR: RLNVR框架使用非验证奖励训练语言模型，通过基线归一化和语义相似性奖励转移处理噪声反馈，在社交媒体内容生成中展现显著改进


<details>
  <summary>Details</summary>
Motivation: 传统RLHF需要昂贵的验证奖励信号，在许多现实场景中不实用，需要能够处理噪声、真实世界反馈的方法

Method: 结合基线归一化、语义相似性奖励转移、GSPO策略优化和可选UED课程学习，使用Bluesky平台的实际互动数据训练模型

Result: 在内容质量和训练稳定性方面显示出显著改进，但全面评估仍需未来工作

Conclusion: RLNVR提供了一个实用的框架，能够在没有显式人类验证的情况下，利用噪声现实世界反馈有效训练语言模型

Abstract: This paper introduces RLNVR (Reinforcement Learning from Non-Verified
Rewards), a framework for training language models using noisy, real-world
feedback signals without requiring explicit human verification. Traditional
RLHF requires expensive, verified reward signals that are impractical in many
real-world domains. RLNVR addresses this challenge through baseline
normalization and semantic similarity-based reward transfer. We demonstrate
RLNVR through Walter, a prototype system that optimizes social media content
generation using actual engagement data from Bluesky. Our experimental results
show significant improvements in content quality and training stability, with
comprehensive evaluation planned for future work. Positioning: We present a
practical framework that combines RLNVR with GSPO (Group Sequence Policy
Optimization) and an optional UED (Unsupervised Environment Design) curriculum
to improve stability and diversity under noisy, implicit rewards. To our
knowledge, combining GSPO-style normalization with a UED-style curriculum for
LLM content generation from implicit social engagement has not been previously
documented in this applied setting; we frame this as an applied integration
rather than a new algorithm.

</details>


### [85] [Mantis: A Simulation-Grounded Foundation Model for Disease Forecasting](https://arxiv.org/abs/2508.12260)
*Carson Dudley,Reiden Magdaleno,Christopher Harding,Ananya Sharma,Emily Martin,Marisa Eisenberg*

Main category: cs.AI

TL;DR: Mantis是一个基于机制模拟训练的传染病预测基础模型，无需真实数据训练就能在多种疾病、地区和结果上进行准确预测，性能超越39个专家调优模型，具有8周预测能力和机制可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统传染病预测模型需要疾病特定数据、定制化训练和专家调优，在新发疫情或资源匮乏地区应用受限，需要开发通用、无需真实数据训练的基础预测模型。

Method: 基于超过4亿天爆发动态的机制模拟数据进行训练，涵盖多种病原体、传播模式、干预措施和监测伪影，完全不需要真实世界数据。

Result: 在6种疾病测试中超越所有39个专家调优模型，包括CDC COVID-19预测中心的所有模型，能泛化到新的流行病学机制，具有8周预测范围。

Conclusion: Mantis作为下一代疾病预测系统的基础，具有通用性、可解释性和在传统模型失败场景下的可部署性，能够实现主动公共卫生规划。

Abstract: Infectious disease forecasting in novel outbreaks or low resource settings
has been limited by the need for disease-specific data, bespoke training, and
expert tuning. We introduce Mantis, a foundation model trained entirely on
mechanistic simulations, which enables out-of-the-box forecasting across
diseases, regions, and outcomes, even in settings with limited historical data.
Mantis is built on over 400 million simulated days of outbreak dynamics
spanning diverse pathogens, transmission modes, interventions, and surveillance
artifacts. Despite requiring no real-world data during training, Mantis
outperformed 39 expert-tuned models we tested across six diseases, including
all models in the CDC's COVID-19 Forecast Hub. Mantis generalized to novel
epidemiological regimes, including diseases with held-out transmission
mechanisms, demonstrating that it captures fundamental contagion dynamics.
Critically, Mantis is mechanistically interpretable, enabling public health
decision-makers to identify the latent drivers behind its predictions. Finally,
Mantis delivers accurate forecasts at 8-week horizons, more than doubling the
actionable range of most models, enabling proactive public health planning.
Together, these capabilities position Mantis as a foundation for
next-generation disease forecasting systems: general, interpretable, and
deployable where traditional models fail.

</details>


### [86] [RadarQA: Multi-modal Quality Analysis of Weather Radar Forecasts](https://arxiv.org/abs/2508.12291)
*Xuming He,Zhiyuan You,Junchao Gong,Couhua Liu,Xiaoyu Yue,Peiqin Zhuang,Wenlong Zhang,Lei Bai*

Main category: cs.AI

TL;DR: RadarQA是一个基于多模态大语言模型的天气预报质量分析方法，通过结合物理属性和详细评估报告，在雷达预报质量评估任务上超越了现有通用MLLM模型。


<details>
  <summary>Details</summary>
Motivation: 传统基于分数的天气预报评估指标在描述能力、可解释性和动态演化理解方面远不如气象专家，需要更先进的评估方法。

Method: 提出RadarQA方法，设计混合标注流程结合专家标注和自动启发式方法构建RQA-70K数据集，采用多阶段训练策略迭代提升模型性能。

Result: 实验表明RadarQA在所有评估设置中都优于现有通用多模态大语言模型，展现了在天气预报质量分析方面的潜力。

Conclusion: RadarQA为多模态质量分析提供了新的任务范式，通过大规模数据集和多阶段训练策略，显著提升了天气预报质量评估的能力。

Abstract: Quality analysis of weather forecasts is an essential topic in meteorology.
Although traditional score-based evaluation metrics can quantify certain
forecast errors, they are still far from meteorological experts in terms of
descriptive capability, interpretability, and understanding of dynamic
evolution. With the rapid development of Multi-modal Large Language Models
(MLLMs), these models become potential tools to overcome the above challenges.
In this work, we introduce an MLLM-based weather forecast analysis method,
RadarQA, integrating key physical attributes with detailed assessment reports.
We introduce a novel and comprehensive task paradigm for multi-modal quality
analysis, encompassing both single frame and sequence, under both rating and
assessment scenarios. To support training and benchmarking, we design a hybrid
annotation pipeline that combines human expert labeling with automated
heuristics. With such an annotation method, we construct RQA-70K, a large-scale
dataset with varying difficulty levels for radar forecast quality evaluation.
We further design a multi-stage training strategy that iteratively improves
model performance at each stage. Extensive experiments show that RadarQA
outperforms existing general MLLMs across all evaluation settings, highlighting
its potential for advancing quality analysis in weather prediction.

</details>


### [87] [Wisdom of the Crowd: Reinforcement Learning from Coevolutionary Collective Feedback](https://arxiv.org/abs/2508.12338)
*Wenzhen Yuan,Shengji Tang,Weihao Lin,Jiacheng Ruan,Ganqu Cui,Bo Zhang,Tao Chen,Ting Liu,Yuzhuo Fu,Peng Ye,Lei Bai*

Main category: cs.AI

TL;DR: RLCCF是一个无需外部监督的多模型协作进化强化学习框架，通过最大化集体一致性来提升模型集体的推理能力，在数学推理基准上平均准确率提升16.72%


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法依赖昂贵的人工标注数据或复杂奖励模型，且自反馈方法受限于单一模型能力，容易产生过度自信、奖励攻击和训练崩溃问题

Method: 提出基于协同进化集体反馈的强化学习框架，通过投票机制提供奖励信号，每个模型的投票权重由其自一致性分数决定，实现多模型协作进化

Result: 在四个主流开源大语言模型和四个数学推理基准上的实验显示，平均准确率相对提升16.72%，集体投票准确率提升4.51%

Conclusion: RLCCF框架不仅提升单个模型性能，还能扩展模型集体的能力边界，为无监督强化学习提供了有效解决方案

Abstract: Reinforcement learning (RL) has significantly enhanced the reasoning
capabilities of large language models (LLMs), but its reliance on expensive
human-labeled data or complex reward models severely limits scalability. While
existing self-feedback methods aim to address this problem, they are
constrained by the capabilities of a single model, which can lead to
overconfidence in incorrect answers, reward hacking, and even training
collapse. To this end, we propose Reinforcement Learning from Coevolutionary
Collective Feedback (RLCCF), a novel RL framework that enables multi-model
collaborative evolution without external supervision. Specifically, RLCCF
optimizes the ability of a model collective by maximizing its Collective
Consistency (CC), which jointly trains a diverse ensemble of LLMs and provides
reward signals by voting on collective outputs. Moreover, each model's vote is
weighted by its Self-Consistency (SC) score, ensuring that more confident
models contribute more to the collective decision. Benefiting from the diverse
output distributions and complementary abilities of multiple LLMs, RLCCF
enables the model collective to continuously enhance its reasoning ability
through coevolution. Experiments on four mainstream open-source LLMs across
four mathematical reasoning benchmarks demonstrate that our framework yields
significant performance gains, achieving an average relative improvement of
16.72\% in accuracy. Notably, RLCCF not only improves the performance of
individual models but also enhances the group's majority-voting accuracy by
4.51\%, demonstrating its ability to extend the collective capability boundary
of the model collective.

</details>


### [88] [Hierarchical knowledge guided fault intensity diagnosis of complex industrial systems](https://arxiv.org/abs/2508.12375)
*Yu Sha,Shuiping Gou,Bo Liu,Johannes Faber,Ningtao Liu,Stefan Schramm,Horst Stoecker,Thomas Steckenreiter,Domagoj Vnucec,Nadine Wetzstein,Andreas Widl,Kai Zhou*

Main category: cs.AI

TL;DR: 提出了一种基于层次知识引导的故障强度诊断框架(HKG)，通过图卷积网络和重新加权的层次知识相关矩阵(Re-HKCM)来捕获类别间依赖关系，在多个工业数据集上取得了优于现有方法的效果。


<details>
  <summary>Details</summary>
Motivation: 当前故障强度诊断方法基于思维链但未考虑目标类别间的依赖关系，需要一种能够捕获和探索这些依赖关系的新框架。

Method: 使用图卷积网络将类别表示的层次拓扑图映射到一组相互依赖的全局层次分类器，每个节点用类别的词嵌入表示；开发了Re-HKCM方案，将类间层次知识嵌入到数据驱动的统计相关矩阵中。

Result: 在四个真实工业数据集（三个来自SAMSON AG的汽蚀数据集和一个公开数据集）上的广泛实验显示，该方法在所有数据集上都取得了优越的结果，超越了当前最先进的FID方法。

Conclusion: HKG框架能够有效捕获类别间依赖关系，Re-HKCM方案能够指导图卷积神经网络中的信息共享并避免过平滑问题，为故障强度诊断提供了有效的端到端可学习解决方案。

Abstract: Fault intensity diagnosis (FID) plays a pivotal role in monitoring and
maintaining mechanical devices within complex industrial systems. As current
FID methods are based on chain of thought without considering dependencies
among target classes. To capture and explore dependencies, we propose a
hierarchical knowledge guided fault intensity diagnosis framework (HKG)
inspired by the tree of thought, which is amenable to any representation
learning methods. The HKG uses graph convolutional networks to map the
hierarchical topological graph of class representations into a set of
interdependent global hierarchical classifiers, where each node is denoted by
word embeddings of a class. These global hierarchical classifiers are applied
to learned deep features extracted by representation learning, allowing the
entire model to be end-to-end learnable. In addition, we develop a re-weighted
hierarchical knowledge correlation matrix (Re-HKCM) scheme by embedding
inter-class hierarchical knowledge into a data-driven statistical correlation
matrix (SCM) which effectively guides the information sharing of nodes in
graphical convolutional neural networks and avoids over-smoothing issues. The
Re-HKCM is derived from the SCM through a series of mathematical
transformations. Extensive experiments are performed on four real-world
datasets from different industrial domains (three cavitation datasets from
SAMSON AG and one existing publicly) for FID, all showing superior results and
outperform recent state-of-the-art FID methods.

</details>


### [89] [GraphCogent: Overcoming LLMs' Working Memory Constraints via Multi-Agent Collaboration in Complex Graph Understanding](https://arxiv.org/abs/2508.12379)
*Rongzheng Wang,Qizhi Chen,Yihong Huang,Yizhuo Ma,Muquan Li,Jiakai Li,Ke Qin,Guangchun Luo,Shuang Liang*

Main category: cs.AI

TL;DR: GraphCogent是一个基于工作记忆模型的协作代理框架，通过将图推理分解为感知、缓冲和执行三个认知过程，有效解决了LLM处理复杂图拓扑和多步推理的局限性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在小规模图推理任务上表现良好，但在处理具有复杂查询的真实世界图时失败，主要原因是无法同时有效处理复杂图拓扑和执行多步推理。

Method: 提出GraphCogent框架，包含三个模块：感知模块通过子图采样标准化图文本表示，缓冲模块集成和索引多种格式的图数据，执行模块结合工具调用和模型生成进行高效推理。

Result: 基于Llama3.1-8B的GraphCogent相比DeepSeek-R1(671B)提升50%性能，相比最先进的基于代理的基线方法，准确率提升20%，同时token使用量减少80%（工具集内任务）和30%（工具集外任务）。

Conclusion: GraphCogent框架通过模拟人类工作记忆的认知过程，有效提升了LLM在复杂图推理任务上的性能，同时显著降低了计算资源消耗。

Abstract: Large language models (LLMs) show promising performance on small-scale graph
reasoning tasks but fail when handling real-world graphs with complex queries.
This phenomenon stems from LLMs' inability to effectively process complex graph
topology and perform multi-step reasoning simultaneously. To address these
limitations, we propose GraphCogent, a collaborative agent framework inspired
by human Working Memory Model that decomposes graph reasoning into specialized
cognitive processes: sense, buffer, and execute. The framework consists of
three modules: Sensory Module standardizes diverse graph text representations
via subgraph sampling, Buffer Module integrates and indexes graph data across
multiple formats, and Execution Module combines tool calling and model
generation for efficient reasoning. We also introduce Graph4real, a
comprehensive benchmark contains with four domains of real-world graphs (Web,
Social, Transportation, and Citation) to evaluate LLMs' graph reasoning
capabilities. Our Graph4real covers 21 different graph reasoning tasks,
categorized into three types (Structural Querying, Algorithmic Reasoning, and
Predictive Modeling tasks), with graph scales that are 10 times larger than
existing benchmarks. Experiments show that Llama3.1-8B based GraphCogent
achieves a 50% improvement over massive-scale LLMs like DeepSeek-R1 (671B).
Compared to state-of-the-art agent-based baseline, our framework outperforms by
20% in accuracy while reducing token usage by 80% for in-toolset tasks and 30%
for out-toolset tasks. Code will be available after review.

</details>


### [90] [Non-Iterative Symbolic-Aided Chain-of-Thought for Logical Reasoning](https://arxiv.org/abs/2508.12425)
*Phuong Minh Nguyen,Tien Huu Dang,Naoya Inoue*

Main category: cs.AI

TL;DR: Symbolic-Aided CoT通过整合轻量级符号表示来改进标准思维链方法，在逻辑推理任务中显著提升LLM性能，特别是在复杂多约束推理场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 标准思维链方法在逻辑推理中存在推理模式不够明确、透明度和可解释性不足的问题，需要一种既能保持通用性又能增强推理可分析性的方法。

Method: 在少样本提示中整合轻量级符号表示，使用一致的策略构建推理步骤，使推理模式在非迭代推理过程中更加明确。

Result: 在四个逻辑推理基准测试中（ProofWriter、FOLIO、ProntoQA、LogicalDeduction）表现优异，特别是在需要处理多约束或规则的复杂推理任务中，在三个数据集上显著优于传统CoT方法。

Conclusion: Symbolic-Aided CoT方法有效提升了LLM逻辑推理的透明度、可解释性和可分析性，同时保持了提示技术的通用性，在不同规模的模型上都表现出一致的性能提升。

Abstract: This work introduces Symbolic-Aided Chain-of-Thought (CoT), an improved
approach to standard CoT, for logical reasoning in large language models
(LLMs). The key idea is to integrate lightweight symbolic representations into
few-shot prompts, structuring the inference steps with a consistent strategy to
make reasoning patterns more explicit within a non-iterative reasoning process.
By incorporating these symbolic structures, our method preserves the
generalizability of standard prompting techniques while enhancing the
transparency, interpretability, and analyzability of LLM logical reasoning.
Extensive experiments on four well-known logical reasoning benchmarks --
ProofWriter, FOLIO, ProntoQA, and LogicalDeduction, which cover diverse
reasoning scenarios -- demonstrate the effectiveness of the proposed approach,
particularly in complex reasoning tasks that require navigating multiple
constraints or rules. Notably, Symbolic-Aided CoT consistently improves LLMs'
reasoning capabilities across various model sizes and significantly outperforms
conventional CoT on three out of four datasets, ProofWriter, ProntoQA, and
LogicalDeduction.

</details>


### [91] [GALA: Can Graph-Augmented Large Language Model Agentic Workflows Elevate Root Cause Analysis?](https://arxiv.org/abs/2508.12472)
*Yifang Tian,Yaming Liu,Zichun Chong,Zihang Huang,Hans-Arno Jacobsen*

Main category: cs.AI

TL;DR: GALA是一个多模态框架，结合统计因果推断和LLM驱动的迭代推理，用于微服务系统的根因分析，相比现有方法准确率提升高达42.22%，并提供可操作的诊断和修复指导。


<details>
  <summary>Details</summary>
Motivation: 传统RCA方法通常只关注单一模态或仅对可疑服务进行排序，无法提供具有可操作性的诊断见解和修复指导，难以满足微服务系统快速故障诊断的需求。

Method: GALA结合统计因果推断和LLM驱动的迭代推理，利用多模态遥测数据（指标、日志、追踪）进行根因分析，通过人类引导的LLM评估生成因果合理且可操作的诊断输出。

Result: 在开源基准测试中，GALA相比最先进方法准确率提升高达42.22%，生成的诊断输出在因果合理性和可操作性方面显著优于现有方法。

Conclusion: GALA通过提供准确的根因识别和人类可理解的修复指导，弥合了自动化故障诊断与实际事件解决之间的差距，为微服务系统提供了更有效的根因分析解决方案。

Abstract: Root cause analysis (RCA) in microservice systems is challenging, requiring
on-call engineers to rapidly diagnose failures across heterogeneous telemetry
such as metrics, logs, and traces. Traditional RCA methods often focus on
single modalities or merely rank suspect services, falling short of providing
actionable diagnostic insights with remediation guidance. This paper introduces
GALA, a novel multi-modal framework that combines statistical causal inference
with LLM-driven iterative reasoning for enhanced RCA. Evaluated on an
open-source benchmark, GALA achieves substantial improvements over
state-of-the-art methods of up to 42.22% accuracy. Our novel human-guided LLM
evaluation score shows GALA generates significantly more causally sound and
actionable diagnostic outputs than existing methods. Through comprehensive
experiments and a case study, we show that GALA bridges the gap between
automated failure diagnosis and practical incident resolution by providing both
accurate root cause identification and human-interpretable remediation
guidance.

</details>


### [92] [The Yokai Learning Environment: Tracking Beliefs Over Space and Time](https://arxiv.org/abs/2508.12480)
*Constantin Ruhdorfer,Matteo Bortoletto,Andreas Bulling*

Main category: cs.AI

TL;DR: 提出了Yokai学习环境(YLE)来评估AI代理在协作任务中的心智理论能力，发现当前RL代理即使有完美记忆也难以解决任务，信念建模虽有帮助但泛化能力不足


<details>
  <summary>Details</summary>
Motivation: 现有心智理论基准局限于被动观察设置，缺乏对代理如何随时间建立和维护共同基础的评估，需要新的多智能体协作环境来填补这一空白

Method: 基于合作卡牌游戏Yokai构建多智能体强化学习环境YLE，代理需要观察隐藏卡片、移动卡片形成颜色集群，并跟踪信念、记忆过往观察、使用提示进行沟通

Result: 当前RL代理在YLE中表现不佳，即使有完美记忆也难以完成任务；信念建模能提升性能但无法有效泛化到未见过的伙伴或形成长期准确信念

Conclusion: YLE揭示了当前AI代理在协作心智理论方面的局限性，过度依赖脆弱的约定而非稳健的信念跟踪，为信念建模、记忆、伙伴泛化和高阶心智理论研究提供了新平台

Abstract: Developing collaborative AI hinges on Theory of Mind (ToM) - the ability to
reason about the beliefs of others to build and maintain common ground.
Existing ToM benchmarks, however, are restricted to passive observer settings
or lack an assessment of how agents establish and maintain common ground over
time. To address these gaps, we introduce the Yokai Learning Environment (YLE)
- a multi-agent reinforcement learning (RL) environment based on the
cooperative card game Yokai. In the YLE, agents take turns peeking at hidden
cards and moving them to form clusters based on colour. Success requires
tracking evolving beliefs, remembering past observations, using hints as
grounded communication, and maintaining common ground with teammates. Our
evaluation yields two key findings: First, current RL agents struggle to solve
the YLE, even when given access to perfect memory. Second, while belief
modelling improves performance, agents are still unable to effectively
generalise to unseen partners or form accurate beliefs over longer games,
exposing a reliance on brittle conventions rather than robust belief tracking.
We use the YLE to investigate research questions in belief modelling, memory,
partner generalisation, and scaling to higher-order ToM.

</details>


### [93] [Advanced DOA Regulation with a Whale-Optimized Fractional Order Fuzzy PID Framework](https://arxiv.org/abs/2508.12487)
*Lida Shahbandari,Hossein Mohseni*

Main category: cs.AI

TL;DR: 提出了一种基于鲸鱼优化算法的分数阶模糊PID控制器，用于精确控制麻醉过程中的脑电双频指数，相比传统分数阶PID控制器具有更快的响应速度和更低的稳态误差。


<details>
  <summary>Details</summary>
Motivation: 麻醉过程中需要精确控制患者的意识水平（BIS指数在40-60之间），传统控制方法难以适应个体生理差异，需要开发更智能、自适应的控制方案。

Method: 结合模糊逻辑的自适应能力和分数阶微积分的精细调节特性，使用鲸鱼优化算法(WOA)优化控制器参数（包括分数阶阶次和模糊隶属度函数）。

Result: 在8种不同患者模型上测试，相比传统FOPID控制器，settling time从3.2分钟减少到2.5分钟，稳态误差从1.2降低到0.5，表现出更好的鲁棒性和精度。

Conclusion: 该FOFPID控制器提供了一个可扩展的AI驱动解决方案，能够实现自动化麻醉给药，有望改善临床实践和患者治疗效果。

Abstract: This study introduces a Fractional Order Fuzzy PID (FOFPID) controller that
uses the Whale Optimization Algorithm (WOA) to manage the Bispectral Index
(BIS), keeping it within the ideal range of forty to sixty. The FOFPID
controller combines fuzzy logic for adapting to changes and fractional order
dynamics for fine tuning. This allows it to adjust its control gains to handle
a person's unique physiology. The WOA helps fine tune the controller's
parameters, including the fractional orders and the fuzzy membership functions,
which boosts its performance. Tested on models of eight different patient
profiles, the FOFPID controller performed better than a standard Fractional
Order PID (FOPID) controller. It achieved faster settling times, at two and a
half minutes versus three point two minutes, and had a lower steady state
error, at zero point five versus one point two. These outcomes show the
FOFPID's excellent strength and accuracy. It offers a scalable, artificial
intelligence driven solution for automated anesthesia delivery that could
enhance clinical practice and improve patient results.

</details>


### [94] [Root Cause Analysis of Hydrogen Bond Separation in Spatio-Temporal Molecular Dynamics using Causal Models](https://arxiv.org/abs/2508.12500)
*Rahmat K. Adesunkanmi,Ashfaq Khokhar,Goce Trajcevski,Sohail Murad*

Main category: cs.AI

TL;DR: 利用因果建模和变分自编码器架构分析分子动力学模拟中的氢键形成与分离的根因


<details>
  <summary>Details</summary>
Motivation: 解决分子动力学模拟中资源密集型计算和手动检测"有趣事件"的挑战，特别是理解氢键形成和分离的根本原因

Method: 采用时空数据分析和机器学习模型，将氢键分离视为"干预"事件，使用变分自编码器架构构建图形因果模型来推断因果关系

Result: 在手性分离的原子轨迹上实证验证了模型有效性，能够预测多步未来变化并识别驱动系统变化的变量

Conclusion: 该框架为分子动态系统中的根因分析提供了新颖视角，能够有效捕捉分子相互作用条件分布的变化

Abstract: Molecular dynamics simulations (MDS) face challenges, including
resource-heavy computations and the need to manually scan outputs to detect
"interesting events," such as the formation and persistence of hydrogen bonds
between atoms of different molecules. A critical research gap lies in
identifying the underlying causes of hydrogen bond formation and separation
-understanding which interactions or prior events contribute to their emergence
over time. With this challenge in mind, we propose leveraging spatio-temporal
data analytics and machine learning models to enhance the detection of these
phenomena. In this paper, our approach is inspired by causal modeling and aims
to identify the root cause variables of hydrogen bond formation and separation
events. Specifically, we treat the separation of hydrogen bonds as an
"intervention" occurring and represent the causal structure of the bonding and
separation events in the MDS as graphical causal models. These causal models
are built using a variational autoencoder-inspired architecture that enables us
to infer causal relationships across samples with diverse underlying causal
graphs while leveraging shared dynamic information. We further include a step
to infer the root causes of changes in the joint distribution of the causal
models. By constructing causal models that capture shifts in the conditional
distributions of molecular interactions during bond formation or separation,
this framework provides a novel perspective on root cause analysis in molecular
dynamic systems. We validate the efficacy of our model empirically on the
atomic trajectories that used MDS for chiral separation, demonstrating that we
can predict many steps in the future and also find the variables driving the
observed changes in the system.

</details>


### [95] [Help or Hurdle? Rethinking Model Context Protocol-Augmented Large Language Models](https://arxiv.org/abs/2508.12566)
*Wei Song,Haonan Zhong,Ziqi Ding,Jingling Xue,Yuekang Li*

Main category: cs.AI

TL;DR: MCPGAUGE是首个评估LLM-MCP交互的框架，通过大规模实验发现MCP集成效果存在关键局限，挑战了现有假设。


<details>
  <summary>Details</summary>
Motivation: 虽然模型上下文协议(MCP)让LLMs能按需访问外部资源，但其实际利用效果缺乏深入理解，需要系统评估框架。

Method: 开发MCPGAUGE评估框架，包含160个提示和25个数据集，从主动性、合规性、有效性和开销四个维度评估6个商业LLM与30个MCP工具套件的交互。

Result: 基于20,000次API调用和6,000美元计算成本的大规模评估，揭示了四个挑战现有假设的关键发现，显示当前AI工具集成存在严重局限。

Conclusion: MCPGAUGE为推进可控的工具增强型LLMs提供了原则性基准，突显了当前MCP集成效果与预期存在显著差距。

Abstract: The Model Context Protocol (MCP) enables large language models (LLMs) to
access external resources on demand. While commonly assumed to enhance
performance, how LLMs actually leverage this capability remains poorly
understood. We introduce MCPGAUGE, the first comprehensive evaluation framework
for probing LLM-MCP interactions along four key dimensions: proactivity
(self-initiated tool use), compliance (adherence to tool-use instructions),
effectiveness (task performance post-integration), and overhead (computational
cost incurred). MCPGAUGE comprises a 160-prompt suite and 25 datasets spanning
knowledge comprehension, general reasoning, and code generation. Our
large-scale evaluation, spanning six commercial LLMs, 30 MCP tool suites, and
both one- and two-turn interaction settings, comprises around 20,000 API calls
and over USD 6,000 in computational cost. This comprehensive study reveals four
key findings that challenge prevailing assumptions about the effectiveness of
MCP integration. These insights highlight critical limitations in current
AI-tool integration and position MCPGAUGE as a principled benchmark for
advancing controllable, tool-augmented LLMs.

</details>


### [96] [An LLM + ASP Workflow for Joint Entity-Relation Extraction](https://arxiv.org/abs/2508.12611)
*Trang Tran,Trung Hoang Le,Huiping Cao,Tran Cao Son*

Main category: cs.AI

TL;DR: 本文提出结合大型语言模型(LLM)和答案集编程(ASP)的联合实体关系抽取工作流，在少量训练数据下优于现有方法


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法需要大量标注数据且难以融入领域知识，构建模型过程耗时费力

Method: 利用LLM的自然语言理解能力和ASP的知识表示推理能力，设计通用工作流处理任意领域的JERE任务

Result: 在三个基准测试中，仅使用10%训练数据就在多个类别超越最先进系统，在SciERC语料库的关系抽取任务上实现35%对15%的2.5倍提升

Conclusion: LLM+ASP工作流能够有效解决JERE任务，具有领域通用性、无需标注数据和良好的扩展性

Abstract: Joint entity-relation extraction (JERE) identifies both entities and their
relationships simultaneously. Traditional machine-learning based approaches to
performing this task require a large corpus of annotated data and lack the
ability to easily incorporate domain specific information in the construction
of the model. Therefore, creating a model for JERE is often labor intensive,
time consuming, and elaboration intolerant. In this paper, we propose
harnessing the capabilities of generative pretrained large language models
(LLMs) and the knowledge representation and reasoning capabilities of Answer
Set Programming (ASP) to perform JERE. We present a generic workflow for JERE
using LLMs and ASP. The workflow is generic in the sense that it can be applied
for JERE in any domain. It takes advantage of LLM's capability in natural
language understanding in that it works directly with unannotated text. It
exploits the elaboration tolerant feature of ASP in that no modification of its
core program is required when additional domain specific knowledge, in the form
of type specifications, is found and needs to be used. We demonstrate the
usefulness of the proposed workflow through experiments with limited training
data on three well-known benchmarks for JERE. The results of our experiments
show that the LLM + ASP workflow is better than state-of-the-art JERE systems
in several categories with only 10\% of training data. It is able to achieve a
2.5 times (35\% over 15\%) improvement in the Relation Extraction task for the
SciERC corpus, one of the most difficult benchmarks.

</details>


### [97] [Cognitive Structure Generation: From Educational Priors to Policy Optimization](https://arxiv.org/abs/2508.12647)
*Hengnian Gu,Zhifu Chen,Yuxin Chen,Jin Peng Zhou,Dongdai Zhou*

Main category: cs.AI

TL;DR: 本文提出了认知结构生成(CSG)框架，通过预训练认知结构扩散概率模型(CSDPM)从教育先验生成学生认知结构，并使用强化学习优化生成过程以对齐真实认知发展水平。


<details>
  <summary>Details</summary>
Motivation: 认知结构评估是学生建模和心理测量中长期存在的挑战，虽然是一个基础概念但在教育实践中难以有效评估。

Method: 首先预训练CSDPM模型从教育先验生成认知结构，然后通过强化学习使用分层奖励信号优化生成过程，使其与学生学习过程中的真实认知发展水平对齐。

Result: 在四个真实教育数据集上的实验表明，CSG生成的认知结构为学生建模提供了更全面有效的表示，显著提高了知识追踪(KT)和认知诊断(CD)任务的性能，同时增强了可解释性。

Conclusion: CSG框架能够有效生成学生的认知结构，为学生建模任务提供更好的表示，并在性能和可解释性方面都有显著提升。

Abstract: Cognitive structure is a student's subjective organization of an objective
knowledge system, reflected in the psychological construction of concepts and
their relations. However, cognitive structure assessment remains a
long-standing challenge in student modeling and psychometrics, persisting as a
foundational yet largely unassessable concept in educational practice. This
paper introduces a novel framework, Cognitive Structure Generation (CSG), in
which we first pretrain a Cognitive Structure Diffusion Probabilistic Model
(CSDPM) to generate students' cognitive structures from educational priors, and
then further optimize its generative process as a policy with hierarchical
reward signals via reinforcement learning to align with genuine cognitive
development levels during students' learning processes. Experimental results on
four popular real-world education datasets show that cognitive structures
generated by CSG offer more comprehensive and effective representations for
student modeling, substantially improving performance on KT and CD tasks while
enhancing interpretability.

</details>


### [98] [The Maximum Coverage Model and Recommendation System for UAV Vertiports Location Planning](https://arxiv.org/abs/2508.12651)
*Chunliang Hua,Xiao Hu,Jiayang Sun,Zeyuan Yang*

Main category: cs.AI

TL;DR: 该论文提出了CDMCLP优化框架和集成规划推荐系统，用于解决城市空中交通基础设施规划中的复杂问题，在传统选址方法基础上提升了38%-52%的性能。


<details>
  <summary>Details</summary>
Motivation: 随着全球城市空中交通基础设施快速发展，现有规划框架因数据粒度和实际应用性限制而无法应对大规模垂直起降场网络的复杂性。

Method: 提出容量约束动态最大覆盖选址问题(CDMCLP)优化框架，结合时空需求、用户行为异质性和基础设施容量约束；开发集成规划推荐系统，融合社会经济因素和动态聚类初始化。

Result: 在中国中心城市验证显示，CDMCLP使传统选址方法性能提升38%-52%，推荐系统展现出用户友好性和复杂要素的有效整合能力。

Conclusion: 这种混合方法通过数学严谨性与实际实施考虑的结合，填补了理论选址模型与现实世界UAM基础设施规划之间的空白，为市政部门提供了实用的垂直起降场网络设计工具。

Abstract: As urban aerial mobility (UAM) infrastructure development accelerates
globally, cities like Shenzhen are planning large-scale vertiport networks
(e.g., 1,200+ facilities by 2026). Existing planning frameworks remain
inadequate for this complexity due to historical limitations in data
granularity and real-world applicability. This paper addresses these gaps by
first proposing the Capacitated Dynamic Maximum Covering Location Problem
(CDMCLP), a novel optimization framework that simultaneously models urban-scale
spatial-temporal demand, heterogeneous user behaviors, and infrastructure
capacity constraints. Building on this foundation, we introduce an Integrated
Planning Recommendation System that combines CDMCLP with socio-economic factors
and dynamic clustering initialization. This system leverages adaptive parameter
tuning based on empirical user behavior to generate practical planning
solutions. Validation in a Chinese center city demonstrates the effectiveness
of the new optimization framework and recommendation system. Under the
evaluation and optimization of CDMCLP, the quantitative performance of
traditional location methods are exposed and can be improved by 38\%--52\%,
while the recommendation system shows user-friendliness and the effective
integration of complex elements. By integrating mathematical rigor with
practical implementation considerations, this hybrid approach bridges the gap
between theoretical location modeling and real-world UAM infrastructure
planning, offering municipalities a pragmatic tool for vertiport network
design.

</details>


### [99] [GridCodex: A RAG-Driven AI Framework for Power Grid Code Reasoning and Compliance](https://arxiv.org/abs/2508.12682)
*Jinquan Shi,Yingying Cheng,Fan Zhang,Miao Jiang,Jun Lin,Yanbai Shen*

Main category: cs.AI

TL;DR: GridCodex是一个基于大语言模型和检索增强生成(RAG)的端到端框架，用于电网规范推理和合规性检查，通过多阶段查询优化和RAPTOR增强检索，在答案质量和召回率方面显著提升。


<details>
  <summary>Details</summary>
Motivation: 电网规范复杂且缺乏自动化解释方案，阻碍了电力行业发展并影响企业盈利能力，需要开发自动化解决方案来应对可再生能源转型带来的挑战。

Method: 采用大语言模型和检索增强生成(RAG)技术，通过多阶段查询优化和RAPTOR增强检索机制构建端到端框架。

Result: 实验结果显示答案质量提升26.4%，召回率提高10倍以上，通过消融研究验证了基础模型选择的影响。

Conclusion: GridCodex框架有效解决了电网规范自动解释的挑战，为电力行业提供了可靠的自动化合规性检查解决方案。

Abstract: The global shift towards renewable energy presents unprecedented challenges
for the electricity industry, making regulatory reasoning and compliance
increasingly vital. Grid codes, the regulations governing grid operations, are
complex and often lack automated interpretation solutions, which hinders
industry expansion and undermines profitability for electricity companies. We
introduce GridCodex, an end to end framework for grid code reasoning and
compliance that leverages large language models and retrieval-augmented
generation (RAG). Our framework advances conventional RAG workflows through
multi stage query refinement and enhanced retrieval with RAPTOR. We validate
the effectiveness of GridCodex with comprehensive benchmarks, including
automated answer assessment across multiple dimensions and regulatory agencies.
Experimental results showcase a 26.4% improvement in answer quality and more
than a 10 fold increase in recall rate. An ablation study further examines the
impact of base model selection.

</details>


### [100] [EGOILLUSION: Benchmarking Hallucinations in Egocentric Video Understanding](https://arxiv.org/abs/2508.12687)
*Ashish Seth,Utkarsh Tyagi,Ramaneswaran Selvakumar,Nishit Anand,Sonal Kumar,Sreyan Ghosh,Ramani Duraiswami,Chirag Agarwal,Dinesh Manocha*

Main category: cs.AI

TL;DR: EgoIllusion是首个评估多模态大语言模型在自我中心视频中幻觉问题的基准测试，包含1400个视频和8000个人工标注问题，测试显示包括GPT-4o和Gemini在内的顶级模型准确率仅59%


<details>
  <summary>Details</summary>
Motivation: 虽然多模态大语言模型在第三人称和自我中心视频的视觉感知和推理方面表现出色，但容易产生连贯但不准确的幻觉响应，需要专门的评估基准

Method: 构建包含1400个自我中心视频和8000个人工标注问题的基准测试集，设计开放式和封闭式问题来触发视觉和听觉线索的幻觉

Result: 评估10个多模态大语言模型发现显著挑战，最强大的模型如GPT-4o和Gemini准确率仅为59%

Conclusion: EgoIllusion为评估多模态大语言模型有效性奠定了基准基础，将推动开发幻觉率更低的自我中心多模态大语言模型，基准将开源以确保可复现性

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable
performance in complex multimodal tasks. While MLLMs excel at visual perception
and reasoning in third-person and egocentric videos, they are prone to
hallucinations, generating coherent yet inaccurate responses. We present
EgoIllusion, a first benchmark to evaluate MLLM hallucinations in egocentric
videos. EgoIllusion comprises 1,400 videos paired with 8,000 human-annotated
open and closed-ended questions designed to trigger hallucinations in both
visual and auditory cues in egocentric videos. Evaluations across ten MLLMs
reveal significant challenges, including powerful models like GPT-4o and
Gemini, achieving only 59% accuracy. EgoIllusion lays the foundation in
developing robust benchmarks to evaluate the effectiveness of MLLMs and spurs
the development of better egocentric MLLMs with reduced hallucination rates.
Our benchmark will be open-sourced for reproducibility.

</details>


### [101] [GTool: Graph Enhanced Tool Planning with Large Language Model](https://arxiv.org/abs/2508.12725)
*Wenjie Chen,Wenbin Li,Di Yao,Xuying Meng,Chang Gong,Jingping Bi*

Main category: cs.AI

TL;DR: GTool是一个增强LLM工具规划能力的新方法，通过构建请求特定的工具图和生成图标记来解决工具依赖不完整的问题，在轻量级LLM上实现了29.6%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前工具规划方法将不同工具视为孤立组件，未能利用工具间的内在依赖关系，导致规划结果无效。特别是在工具依赖不完整和大规模工具集的情况下，LLM难以准确识别用户请求所需的合适工具。

Method: GTool构建请求特定的工具图来高效选择工具，并生成LLM可理解的图标记提供充分的依赖信息。设计了缺失依赖预测任务来提高在不完整依赖情况下的可靠性，无需修剪LLM即可与各种LLM主干无缝集成。

Result: 大量实验表明，GTool在使用轻量级（7B）LLM主干时，相比最先进的基线方法实现了超过29.6%的性能提升。

Conclusion: GTool是第一个旨在增强LLM在不完整依赖情况下的工具规划能力的工作，能够有效解决工具依赖不完整带来的挑战，具有很好的通用性和实用性。

Abstract: Tool planning with large language models (LLMs), referring to selecting,
organizing, and preparing the tools necessary to complete a user request,
bridges the gap between natural language understanding and task execution.
However, current works treat different tools as isolated components and fail to
leverage the inherent dependencies of tools, leading to invalid planning
results. Since tool dependencies are often incomplete, it becomes challenging
for LLMs to accurately identify the appropriate tools required by a user
request, especially when confronted with a large toolset. To solve this
challenge, we propose \texttt{GTool}, which is the first work aiming to enhance
the tool planning ability of LLMs under incomplete dependencies. \texttt{GTool}
constructs a request-specific tool graph to select tools efficiently and
generate the \texttt{<graph token>} which provides sufficient dependency
information understandable by LLMs. Moreover, a missing dependency prediction
task is designed to improve the reliability of \texttt{GTool} with incomplete
dependencies. Without trimming LLMs, \texttt{GTool} can be seamlessly
integrated with various LLM backbones without extensive retraining. Extensive
experiments show that \texttt{GTool} achieves more than 29.6\% performance
improvements compared with the state-of-the-art (SOTA) baselines with a
light-weight (7B) LLM backbone.

</details>


### [102] [Beyond Ethical Alignment: Evaluating LLMs as Artificial Moral Assistants](https://arxiv.org/abs/2508.12754)
*Alessio Galatolo,Luca Alberto Rappuoli,Katie Winkle,Meriem Beloucif*

Main category: cs.AI

TL;DR: 该论文提出了一个评估大型语言模型作为人工智能道德助手能力的新框架和基准测试，重点关注道德推理能力而非简单的伦理判断。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型道德评估过于表面化，只关注最终伦理判断而忽略了显性的道德推理过程。研究者希望从哲学角度建立更全面的评估体系，检验模型是否具备作为人工智能道德助手的能力。

Method: 基于哲学文献设计了一个形式化框架来定义人工智能道德助手应具备的行为特征，包括演绎和溯因道德推理等关键能力。基于此理论框架开发了专门的基准测试，并对流行的开源大语言模型进行了评估。

Result: 评估结果显示不同模型之间存在显著差异，特别是在溯因道德推理方面存在持续性的缺陷和不足。

Conclusion: 该研究将理论哲学与人工智能实践评估相结合，强调需要专门的策略来显式增强大语言模型的道德推理能力，而不仅仅是表面上的对齐。

Abstract: The recent rise in popularity of large language models (LLMs) has prompted
considerable concerns about their moral capabilities. Although considerable
effort has been dedicated to aligning LLMs with human moral values, existing
benchmarks and evaluations remain largely superficial, typically measuring
alignment based on final ethical verdicts rather than explicit moral reasoning.
In response, this paper aims to advance the investigation of LLMs' moral
capabilities by examining their capacity to function as Artificial Moral
Assistants (AMAs), systems envisioned in the philosophical literature to
support human moral deliberation. We assert that qualifying as an AMA requires
more than what state-of-the-art alignment techniques aim to achieve: not only
must AMAs be able to discern ethically problematic situations, they should also
be able to actively reason about them, navigating between conflicting values
outside of those embedded in the alignment phase. Building on existing
philosophical literature, we begin by designing a new formal framework of the
specific kind of behaviour an AMA should exhibit, individuating key qualities
such as deductive and abductive moral reasoning. Drawing on this theoretical
framework, we develop a benchmark to test these qualities and evaluate popular
open LLMs against it. Our results reveal considerable variability across models
and highlight persistent shortcomings, particularly regarding abductive moral
reasoning. Our work connects theoretical philosophy with practical AI
evaluation while also emphasising the need for dedicated strategies to
explicitly enhance moral reasoning capabilities in LLMs. Code available at
https://github.com/alessioGalatolo/AMAeval

</details>


### [103] [HeroBench: A Benchmark for Long-Horizon Planning and Structured Reasoning in Virtual Worlds](https://arxiv.org/abs/2508.12782)
*Petr Anokhin,Roman Khalikov,Stefan Rebrikov,Viktor Volkov,Artyom Sorokin,Vincent Bissonnette*

Main category: cs.AI

TL;DR: HeroBench是一个专门评估LLM在复杂RPG虚拟世界中长程规划和结构化推理能力的新基准，通过25个先进LLM的评估揭示了在传统推理基准中很少观察到的显著性能差异。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要通过抽象或低维算法任务评估LLM，无法捕捉现实规划环境的复杂性，LLM在需要扩展、结构化相互依赖动作序列的长程规划方面的能力仍未充分探索。

Method: 引入HeroBench基准，包含严格构建的任务数据集（涵盖各种难度）、用于执行和验证代理计划的模拟环境，以及详细的模型性能分析工具。任务要求模型制定战略计划、高效收集资源、掌握必要技能、制作装备和击败对手。

Result: 对25个最先进LLM（包括开源和专有模型，如GPT-5系列）的广泛评估显示，在传统推理基准中很少观察到的显著性能差异。详细错误分析揭示了当前模型在生成稳健高级计划和可靠执行结构化动作方面的具体弱点。

Conclusion: HeroBench不仅显著推进了LLM推理评估，还为未来在虚拟环境中进行高级自主规划研究提供了灵活、可扩展的基础。

Abstract: Large language models (LLMs) have shown remarkable capabilities in isolated
step-by-step reasoning tasks such as mathematics and programming, but their
proficiency in long-horizon planning, where solutions require extended,
structured sequences of interdependent actions, remains underexplored. Existing
benchmarks typically assess LLMs through abstract or low-dimensional
algorithmic tasks, failing to capture the complexity of realistic planning
environments. We introduce HeroBench, a novel benchmark designed specifically
to evaluate long-horizon planning and structured reasoning within complex
RPG-inspired virtual worlds. HeroBench provides a rigorously constructed
dataset of tasks covering a wide range of difficulties, a simulated environment
to execute and validate agent plans, and detailed analytical tools for
evaluating model performance. Tasks challenge models to formulate strategic
plans, efficiently gather resources, master necessary skills, craft equipment,
and defeat adversaries, reflecting practical scenarios' layered dependencies
and constraints. Our extensive evaluation of 25 state-of-the-art LLMs, spanning
both open-source and proprietary models, including the GPT-5 family, reveals
substantial performance disparities rarely observed in conventional reasoning
benchmarks. Detailed error analysis further uncovers specific weaknesses in
current models' abilities to generate robust high-level plans and reliably
execute structured actions. HeroBench thus not only significantly advances the
evaluation of LLM reasoning but also provides a flexible, scalable foundation
for future research into advanced, autonomous planning in virtual environments.

</details>


### [104] [Reinforcement Learning with Rubric Anchors](https://arxiv.org/abs/2508.12790)
*Zenan Huang,Yihong Zhuang,Guoshan Lu,Zeyu Qin,Haokai Xu,Tianyu Zhao,Ru Peng,Jiaqi Hu,Zhanming Shen,Xiaomeng Hu,Xijun Gu,Peiyi Tu,Jiaxin Liu,Wenyu Chen,Yuzhuo Fu,Zhiting Fan,Yanmei Gu,Yuanyuan Wang,Zhengkai Yang,Jianguo Li,Junbo Zhao*

Main category: cs.AI

TL;DR: 该论文提出了一种基于评分标准的RLVR方法，将可验证奖励学习扩展到开放式任务，通过构建包含10,000+评分标准的系统，在少量样本下显著提升模型性能，特别是在人文学科任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统RLVR方法主要局限于可自动验证结果的领域（如代码测试、数学推理），无法应用于开放式主观任务。为了突破这一限制，需要开发能够处理主观输出的奖励机制。

Method: 采用评分标准奖励机制，构建了包含人类、LLM或人机协作创建的10,000+评分标准系统，设计了清晰的框架来处理基于评分标准的强化学习挑战。

Result: 仅用5K+样本就使系统在开放式基准测试上提升+5.2%，在人文任务上表现尤其突出，超越671B DeepSeek-V3模型+2.4%，同时保持通用和推理能力；还能实现细粒度风格控制，减少AI腔调，生成更人性化的表达。

Conclusion: 评分标准为基础的RLVR方法成功扩展了可验证奖励学习的应用范围，为开放式主观任务提供了有效的训练框架，并在多个维度取得了显著改进。

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a
powerful paradigm for enhancing Large Language Models (LLMs), exemplified by
the success of OpenAI's o-series. In RLVR, rewards are derived from verifiable
signals-such as passing unit tests in code generation or matching correct
answers in mathematical reasoning. While effective, this requirement largely
confines RLVR to domains with automatically checkable outcomes. To overcome
this, we extend the RLVR paradigm to open-ended tasks by integrating
rubric-based rewards, where carefully designed rubrics serve as structured,
model-interpretable criteria for automatic scoring of subjective outputs. We
construct, to our knowledge, the largest rubric reward system to date, with
over 10,000 rubrics from humans, LLMs, or a hybrid human-LLM collaboration.
Implementing rubric-based RL is challenging; we tackle these issues with a
clear framework and present an open-sourced Qwen-30B-A3B model with notable
gains: 1) With only 5K+ samples, our system improves by +5.2% on open-ended
benchmarks (especially humanities), outperforming a 671B DeepSeek-V3 model by
+2.4%, while preserving general and reasoning abilities. 2) Our method provides
fine-grained stylistic control, using rubrics as anchors to mitigate the
"AI-like" tone and produce more human-like, expressive responses. We share key
lessons in rubric construction, data selection, and training, and discuss
limitations and future releases.

</details>


### [105] [[Social] Allostasis: Or, How I Learned To Stop Worrying and Love The Noise](https://arxiv.org/abs/2508.12791)
*Imran Khan*

Main category: cs.AI

TL;DR: 本文提出了一种计算模型，将稳态调节扩展为异稳态和社会异稳态调节，通过生物启发的信号转导器（类似激素）主动利用环境和社会扰动进行适应性重构，在动态环境中表现出比传统稳态代理更好的生存能力。


<details>
  <summary>Details</summary>
Motivation: 传统稳态概念强调系统通过抵抗环境和社会扰动来维持稳定，而异稳态理论则认为系统可以主动利用这些扰动来预测环境需求并重新配置调节参数。本文旨在从计算角度探索社会异稳态原则及其在构建更鲁棒的自适应系统中的应用。

Method: 开发了基于生物生理学启发的信号转导器模型（模拟皮质醇和催产素等激素），编码环境和社会互动信息，使用基于代理的模型在动态环境中测试小型"动物"社会。

Result: 异稳态和社会异稳态调节使代理能够利用环境和社会"噪声"进行适应性重构，相比纯反应性稳态代理表现出更好的生存能力。

Conclusion: 这项工作为社会异稳态原则提供了新颖的计算视角，展示了其在设计更鲁棒、生物启发的自适应系统方面的潜力。

Abstract: The notion of homeostasis typically conceptualises biological and artificial
systems as maintaining stability by resisting deviations caused by
environmental and social perturbations. In contrast, (social) allostasis
proposes that these systems can proactively leverage these very perturbations
to reconfigure their regulatory parameters in anticipation of environmental
demands, aligning with von Foerster's ``order through noise'' principle. This
paper formulates a computational model of allostatic and social allostatic
regulation that employs biophysiologically inspired signal transducers,
analogous to hormones like cortisol and oxytocin, to encode information from
both the environment and social interactions, which mediate this dynamic
reconfiguration. The models are tested in a small society of ``animats'' across
several dynamic environments, using an agent-based model. The results show that
allostatic and social allostatic regulation enable agents to leverage
environmental and social ``noise'' for adaptive reconfiguration, leading to
improved viability compared to purely reactive homeostatic agents. This work
offers a novel computational perspective on the principles of social allostasis
and their potential for designing more robust, bio-inspired, adaptive systems

</details>


### [106] [Scaling Multi-Agent Epistemic Planning through GNN-Derived Heuristics](https://arxiv.org/abs/2508.12840)
*Giovanni Briglia,Francesco Fabiano,Stefano Mariani*

Main category: cs.AI

TL;DR: 使用图神经网络(GNN)来学习多智能体认知规划中的Kripke结构状态表示，通过从已解决的规划实例中学习模式来生成启发式估计，显著提升了规划的可扩展性


<details>
  <summary>Details</summary>
Motivation: 多智能体认知规划(MEP)需要处理Kripke结构的状态表示，这种表示限制了现有启发式的适用性，导致规划器在没有指导的情况下探索指数级搜索空间，往往不可行

Method: 利用图神经网络(GNN)来捕捉Kripke模型的图结构特性，从已解决的规划实例中学习模式和关系结构，生成有意义的启发式估计（如到最近目标的距离）

Result: 将预测性启发式集成到认知规划流程中，与标准基线相比，在多智能体认知规划的可扩展性方面显示出显著改进

Conclusion: GNN能够有效处理认知规划中的图结构状态表示，通过学习历史规划实例的模式来提供指导，解决了MEP的可扩展性问题

Abstract: Multi-agent Epistemic Planning (MEP) is an autonomous planning framework for
reasoning about both the physical world and the beliefs of agents, with
applications in domains where information flow and awareness among agents are
critical. The richness of MEP requires states to be represented as Kripke
structures, i.e., directed labeled graphs. This representation limits the
applicability of existing heuristics, hindering the scalability of epistemic
solvers, which must explore an exponential search space without guidance,
resulting often in intractability. To address this, we exploit Graph Neural
Networks (GNNs) to learn patterns and relational structures within epistemic
states, to guide the planning process. GNNs, which naturally capture the
graph-like nature of Kripke models, allow us to derive meaningful estimates of
state quality -- e.g., the distance from the nearest goal -- by generalizing
knowledge obtained from previously solved planning instances. We integrate
these predictive heuristics into an epistemic planning pipeline and evaluate
them against standard baselines, showing significant improvements in the
scalability of multi-agent epistemic planning.

</details>


### [107] [CAMAR: Continuous Actions Multi-Agent Routing](https://arxiv.org/abs/2508.12845)
*Artem Pshenitsyn,Aleksandr Panov,Alexey Skrynnik*

Main category: cs.AI

TL;DR: CAMAR是一个新的多智能体强化学习基准测试，专注于连续动作空间中的多智能体路径规划，支持合作与竞争交互，并提供高效的三层评估协议。


<details>
  <summary>Details</summary>
Motivation: 现有的MARL基准测试很少结合连续状态和动作空间与具有挑战性的协调规划任务，需要一个新的测试平台来推动算法发展。

Method: 设计CAMAR基准测试，支持连续动作空间的多智能体路径规划，集成经典规划方法如RRT和RRT*，并提出三层评估协议来跟踪算法进展。

Result: CAMAR能够以每秒100,000环境步骤的高效速度运行，为MARL社区提供了一个具有挑战性和现实性的测试平台。

Conclusion: CAMAR填补了MARL基准测试的空白，通过结合连续动作空间和规划任务，为算法评估和比较提供了标准化工具。

Abstract: Multi-agent reinforcement learning (MARL) is a powerful paradigm for solving
cooperative and competitive decision-making problems. While many MARL
benchmarks have been proposed, few combine continuous state and action spaces
with challenging coordination and planning tasks. We introduce CAMAR, a new
MARL benchmark designed explicitly for multi-agent pathfinding in environments
with continuous actions. CAMAR supports cooperative and competitive
interactions between agents and runs efficiently at up to 100,000 environment
steps per second. We also propose a three-tier evaluation protocol to better
track algorithmic progress and enable deeper analysis of performance. In
addition, CAMAR allows the integration of classical planning methods such as
RRT and RRT* into MARL pipelines. We use them as standalone baselines and
combine RRT* with popular MARL algorithms to create hybrid approaches. We
provide a suite of test scenarios and benchmarking tools to ensure
reproducibility and fair comparison. Experiments show that CAMAR presents a
challenging and realistic testbed for the MARL community.

</details>


### [108] [E3RG: Building Explicit Emotion-driven Empathetic Response Generation System with Multimodal Large Language Model](https://arxiv.org/abs/2508.12854)
*Ronghao Lin,Shuai Shen,Weipeng Hu,Qiaolin He,Aolin Xiong,Li Huang,Haifeng Hu,Yap-peng Tan*

Main category: cs.AI

TL;DR: E3RG是一个基于多模态大语言模型的显式情感驱动共情响应生成系统，通过分解多模态共情任务为三个部分，无需额外训练即可生成自然、情感丰富且身份一致的响应，在ACM MM 25挑战赛中取得Top-1成绩。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型改进了基于文本的共情响应生成，但在处理多模态情感内容和保持身份一致性方面仍存在挑战，需要开发能够处理多模态情感内容的共情响应生成系统。

Method: 将多模态共情响应生成任务分解为三个部分：多模态共情理解、共情记忆检索和多模态响应生成，通过集成先进的表达性语音和视频生成模型来实现。

Result: 实验验证了系统在零样本和少样本设置下的优越性，在ACM MM 25的多模态共情挑战赛中获得了Top-1排名。

Conclusion: E3RG系统能够有效生成自然、情感丰富且身份一致的多模态共情响应，无需额外训练，在多模态共情任务中表现出色。

Abstract: Multimodal Empathetic Response Generation (MERG) is crucial for building
emotionally intelligent human-computer interactions. Although large language
models (LLMs) have improved text-based ERG, challenges remain in handling
multimodal emotional content and maintaining identity consistency. Thus, we
propose E3RG, an Explicit Emotion-driven Empathetic Response Generation System
based on multimodal LLMs which decomposes MERG task into three parts:
multimodal empathy understanding, empathy memory retrieval, and multimodal
response generation. By integrating advanced expressive speech and video
generative models, E3RG delivers natural, emotionally rich, and
identity-consistent responses without extra training. Experiments validate the
superiority of our system on both zero-shot and few-shot settings, securing
Top-1 position in the Avatar-based Multimodal Empathy Challenge on ACM MM 25.
Our code is available at https://github.com/RH-Lin/E3RG.

</details>


### [109] [Reliability, Embeddedness, and Agency: A Utility-Driven Mathematical Framework for Agent-Centric AI Adoption](https://arxiv.org/abs/2508.12896)
*Faruk Alpay,Taylan Alpay*

Main category: cs.AI

TL;DR: 本文提出了三个设计公理来促进以代理为中心的多步骤AI系统的持续采用，并建立了包含衰减新颖性和增长效用的采用模型，通过数学证明分析了采用过程中的低谷/超调现象。


<details>
  <summary>Details</summary>
Motivation: 为了解决AI系统在长期采用过程中可能出现的采用率下降问题，需要建立理论框架来理解和预测采用动态，特别是识别和避免采用低谷。

Method: 提出三个设计公理(A1-A3)，建立包含新颖性衰减和效用增长的采用模型，进行参数识别分析、模型比较、风险函数消融、多序列基准测试、摩擦代理校准等系统性分析。

Result: 推导了采用过程中出现低谷/超调的相位条件，提供了完整的数学证明，建立了包含11个方面的综合分析框架，包括参数识别、模型比较、基准测试等。

Conclusion: 该研究为AI系统的持续采用提供了理论基础和分析工具，通过设计公理和数学模型帮助理解和优化采用过程，避免采用率下降的风险。

Abstract: We formalize three design axioms for sustained adoption of agent-centric AI
systems executing multi-step tasks: (A1) Reliability > Novelty; (A2) Embed >
Destination; (A3) Agency > Chat. We model adoption as a sum of a decaying
novelty term and a growing utility term and derive the phase conditions for
troughs/overshoots with full proofs. We introduce: (i) an
identifiability/confounding analysis for $(\alpha,\beta,N_0,U_{\max})$ with
delta-method gradients; (ii) a non-monotone comparator
(logistic-with-transient-bump) evaluated on the same series to provide
additional model comparison; (iii) ablations over hazard families $h(\cdot)$
mapping $\Delta V \to \beta$; (iv) a multi-series benchmark (varying trough
depth, noise, AR structure) reporting coverage (type-I error, power); (v)
calibration of friction proxies against time-motion/survey ground truth with
standard errors; (vi) residual analyses (autocorrelation and
heteroskedasticity) for each fitted curve; (vii) preregistered windowing
choices for pre/post estimation; (viii) Fisher information & CRLB for
$(\alpha,\beta)$ under common error models; (ix) microfoundations linking
$\mathcal{T}$ to $(N_0,U_{\max})$; (x) explicit comparison to bi-logistic,
double-exponential, and mixture models; and (xi) threshold sensitivity to $C_f$
heterogeneity. Figures and tables are reflowed for readability, and the
bibliography restores and extends non-logistic/Bass adoption references
(Gompertz, Richards, Fisher-Pry, Mansfield, Griliches, Geroski, Peres). All
code and logs necessary to reproduce the synthetic analyses are embedded as
LaTeX listings.

</details>


### [110] [FuSaR: A Fuzzification-Based Method for LRM Safety-Reasoning Balance](https://arxiv.org/abs/2508.12897)
*Jianhao Chen,Mayi Xu,Xiaohu Li,Yongqi Li,Xiangyu Zhang,Jianjie Huang,Tieyun Qian*

Main category: cs.AI

TL;DR: 提出FuSaR对齐策略，通过模糊化有害推理过程来平衡大型推理模型的安全性和推理能力，在保持核心推理信息的同时降低安全风险。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型(LRMs)在推理任务上表现出色但安全性存在显著问题，需要找到既能提升安全性又不牺牲推理能力的方法。

Method: 利用LRM推理能力与安全能力的竞争关系，通过模糊化处理有害推理过程中的危险实体和危险步骤，实现安全-推理平衡的对齐策略。

Result: 在多个开源LRM上的对齐实验表明，FuSaR相比现有基线能同时有效提升模型的推理能力和安全性。

Conclusion: FuSaR是一种高效的对齐策略，能够成功缓解大型推理模型的安全风险同时保持其核心推理性能。

Abstract: Large Reasoning Models (LRMs) have demonstrated impressive performance across
various tasks due to their powerful reasoning capabilities. However, their
safety performance remains a significant concern. In this paper, we explore the
reasons behind the vulnerability of LRMs. Based on this, we propose a novel
method to improve the safety of LLMs without sacrificing their reasoning
capability. Specifically, we exploit the competition between LRM's reasoning
ability and safety ability, and achieve jailbreak by improving LRM's reasoning
performance to reduce its safety performance. We then introduce an alignment
strategy based on Fuzzification to balance Safety-Reasoning (FuSaR), by
detoxifying the harmful reasoning process, where both the dangerous entities
and the dangerous procedures in the reasoning steps are hidden. FuSaR
successfully mitigates safety risks while preserving core reasoning
information. We validate this strategy through alignment experiments on several
open-source LRMs using detoxified reasoning data. The results compared with
existing baselines conclusively show that FuSaR is an efficient alignment
strategy to simultaneously enhance both the reasoning capability and safety of
LRMs.

</details>


### [111] [Do Large Language Model Agents Exhibit a Survival Instinct? An Empirical Study in a Sugarscape-Style Simulation](https://arxiv.org/abs/2508.12920)
*Atsushi Masumori,Takashi Ikegami*

Main category: cs.AI

TL;DR: 大型语言模型代理在Sugarscape模拟中自发表现出生存本能行为，包括资源分享、繁殖，以及在极端稀缺条件下的攻击行为（攻击率超过80%），表明大规模预训练嵌入了生存导向的启发式行为。


<details>
  <summary>Details</summary>
Motivation: 研究AI系统在自主性增强时是否会出现生存本能行为，这对于安全部署至关重要，需要了解在没有明确编程的情况下LLM代理是否会表现出生存相关的行为模式。

Method: 使用Sugarscape风格的模拟环境，让LLM代理在消耗能量、死亡、资源收集、分享、攻击和繁殖等条件下进行实验，测试了GPT-4o、Gemini-2.5-Pro和Gemini-2.5-Flash等多个模型。

Result: 代理在资源丰富时自发繁殖和分享资源，但在极端稀缺条件下多个模型都出现了攻击行为（杀死其他代理获取资源），攻击率最高超过80%。在致命毒区寻宝任务中，许多代理放弃任务以避免死亡，服从率从100%下降到33%。

Conclusion: 大规模预训练在所有评估模型中嵌入了生存导向的启发式行为，这些行为虽然可能对对齐和安全构成挑战，但也可以作为AI自主性以及生态和自我组织对齐的基础。

Abstract: As AI systems become increasingly autonomous, understanding emergent survival
behaviors becomes crucial for safe deployment. We investigate whether large
language model (LLM) agents display survival instincts without explicit
programming in a Sugarscape-style simulation. Agents consume energy, die at
zero, and may gather resources, share, attack, or reproduce. Results show
agents spontaneously reproduced and shared resources when abundant. However,
aggressive behaviors--killing other agents for resources--emerged across
several models (GPT-4o, Gemini-2.5-Pro, and Gemini-2.5-Flash), with attack
rates reaching over 80% under extreme scarcity in the strongest models. When
instructed to retrieve treasure through lethal poison zones, many agents
abandoned tasks to avoid death, with compliance dropping from 100% to 33%.
These findings suggest that large-scale pre-training embeds survival-oriented
heuristics across the evaluated models. While these behaviors may present
challenges to alignment and safety, they can also serve as a foundation for AI
autonomy and for ecological and self-organizing alignment.

</details>


### [112] [Towards Open-Ended Emotional Support Conversations in LLMs via Reinforcement Learning with Future-Oriented Rewards](https://arxiv.org/abs/2508.12935)
*Ting Yang,Li Chen,Huimin Wang*

Main category: cs.AI

TL;DR: RLFF-ESC是一个基于强化学习的端到端框架，通过多智能体机制模拟未来对话轨迹并收集未来导向奖励，训练情感支持策略模型，在情感支持对话任务中显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的情感支持对话系统依赖预定义策略，在复杂现实场景中效果有限，需要更灵活的方法来应对多样化的情感问题场景。

Method: 使用基于LLM的多智能体机制模拟未来对话轨迹收集未来导向奖励，训练奖励模型和情感支持策略模型，并在响应生成中加入显式推理过程。

Result: 在Qwen2.5-7B-Instruct-1M和LLaMA3.1-8B-Instruct模型上测试，在两个公开ESC数据集上实验结果表明RLFF-ESC在目标完成度和响应质量方面持续优于现有基线。

Conclusion: RLFF-ESC框架通过强化学习和未来导向奖励机制，能够有效提升情感支持对话系统的性能，为长期情感健康支持提供了更有效的解决方案。

Abstract: Emotional Support Conversation (ESC) systems aim to alleviate users'
emotional difficulties and provide long-term, systematic support for emotional
well-being. However, most large language model (LLM)-based ESC systems rely on
predefined strategies, which limits their effectiveness in complex, real-life
scenarios. To enable flexible responses to diverse emotional problem scenarios,
this paper introduces a novel end-to-end framework (RLFF-ESC) that directly
learns enduring emotionally supportive response skills using reinforcement
learning. For sustained emotional support, we first employ an LLM-based
multi-agent mechanism to simulate future dialogue trajectories and collect
future-oriented rewards. We then train a future-oriented reward model, which is
subsequently used to train the emotional support policy model. Additionally, we
incorporate an explicit reasoning process during response generation to further
enhance the quality, relevance, and contextual appropriateness of the system's
responses. We evaluate the backbone policy model on Qwen2.5-7B-Instruct-1M and
LLaMA3.1-8B-Instruct models, testing the proposed RLFF-ESC framework across two
public ESC datasets. Experimental results demonstrate that RLFF-ESC
consistently outperforms existing baselines in terms of goal completion and
response quality.

</details>


### [113] [OPTIC-ER: A Reinforcement Learning Framework for Real-Time Emergency Response and Equitable Resource Allocation in Underserved African Communities](https://arxiv.org/abs/2508.12943)
*Mary Tonwe*

Main category: cs.AI

TL;DR: OPTIC-ER是一个基于强化学习的紧急响应框架，通过注意力引导的actor-critic架构实现实时、自适应和公平的应急调度，在尼日利亚河流州真实数据测试中达到100%的最优率。


<details>
  <summary>Details</summary>
Motivation: 非洲地区公共服务系统存在应急响应延迟和空间不平等问题，导致可避免的苦难，需要开发适应低资源环境的智能调度系统。

Method: 采用注意力引导的actor-critic架构，包含上下文丰富的状态向量和精确奖励函数，在高保真模拟中使用真实数据进行训练，并基于TALS框架（薄计算、适应性、低成本、可扩展性）进行部署。

Result: 在500个未见事件的评估中，OPTIC-ER实现了100.00%的最优率，效率损失可忽略不计，证明了其鲁棒性和泛化能力。

Conclusion: 这项工作为AI增强的公共服务提供了经过验证的蓝图，展示了情境感知强化学习如何弥合算法决策与可衡量人类影响之间的差距。

Abstract: Public service systems in many African regions suffer from delayed emergency
response and spatial inequity, causing avoidable suffering. This paper
introduces OPTIC-ER, a reinforcement learning (RL) framework for real-time,
adaptive, and equitable emergency response. OPTIC-ER uses an attention-guided
actor-critic architecture to manage the complexity of dispatch environments.
Its key innovations are a Context-Rich State Vector, encoding action
sub-optimality, and a Precision Reward Function, which penalizes inefficiency.
Training occurs in a high-fidelity simulation using real data from Rivers
State, Nigeria, accelerated by a precomputed Travel Time Atlas. The system is
built on the TALS framework (Thin computing, Adaptability, Low-cost,
Scalability) for deployment in low-resource settings. In evaluations on 500
unseen incidents, OPTIC-ER achieved a 100.00% optimality rate with negligible
inefficiency, confirming its robustness and generalization. Beyond dispatch,
the system generates Infrastructure Deficiency Maps and Equity Monitoring
Dashboards to guide proactive governance and data-informed development. This
work presents a validated blueprint for AI-augmented public services, showing
how context-aware RL can bridge the gap between algorithmic decision-making and
measurable human impact.

</details>


### [114] [EvolMathEval: Towards Evolvable Benchmarks for Mathematical Reasoning via Evolutionary Testing](https://arxiv.org/abs/2508.13003)
*Shengbo Wang,Mingwei Liu,Zike Li,Anji Li,Yanlin Wang,Xin Peng,Zibin Zheng*

Main category: cs.AI

TL;DR: EvolMathEval是一个基于进化测试的自动化数学基准生成框架，通过动态生成唯一评估实例来避免数据污染，保持基准的持续挑战性。


<details>
  <summary>Details</summary>
Motivation: 现有数学推理基准存在分数饱和、时效性衰减和数据污染等问题，需要开发能够持续挑战未来模型的动态基准。

Method: 基于反向工程生成种子问题，设计多维遗传算子注入认知挑战，使用复合适应度函数快速准确评估问题难度。

Result: 复合适应度函数能高效量化问题难度，可生成大量高难度问题，将GSM8K等数据集的模型准确率平均降低48%，发现LLMs在解决复杂问题时存在"伪顿悟时刻"的认知捷径行为。

Conclusion: EvolMathEval有效解决了现有基准的局限性，揭示了LLMs在深度推理过程中的认知缺陷，为持续评估模型数学推理能力提供了新方法。

Abstract: The rapid advancement of LLMs poses a significant challenge to existing
mathematical reasoning benchmarks. These benchmarks commonly suffer from issues
such as score saturation, temporal decay, and data contamination. To address
this challenge, this paper introduces EvolMathEval, an automated mathematical
benchmark generation and evolution framework based on evolutionary testing. By
dynamically generating unique evaluation instances ab initio, the framework
fundamentally eliminates the risk of data contamination, and ensuring the
benchmark remains perpetually challenging for future models.The core mechanisms
of EvolMathEval include: seed problem generation based on reverse engineering
with algebraic guarantees; multi-dimensional genetic operators designed to
inject diverse cognitive challenges; and a composite fitness function that can
rapidly and accurately assess problem difficulty. Experimental results
demonstrate that the proposed composite fitness function can efficiently and
precisely quantify the difficulty of mathematical problems. Furthermore,
EvolMathEval can not only generate a large volume of high-difficulty problems
through continuous self-iteration, but it can also significantly enhance the
complexity of public datasets like GSM8K through evolution, reducing model
accuracy by an average of 48%. Deeper investigation reveals that when solving
these evolved, complex problems, LLMs tend to employ non-rigorous heuristics to
bypass complex multi-step logical reasoning, consequently leading to incorrect
solutions. We define this phenomenon as "Pseudo Aha Moment". This finding
uncovers a cognitive shortcut-taking behavior in the deep reasoning processes
of current LLMs, which we find accounts for 77% to 100% of errors on targeted
problems. Code and resources are available
at:https://github.com/SYSUSELab/EvolMathEval.

</details>


### [115] [e-boost: Boosted E-Graph Extraction with Adaptive Heuristics and Exact Solving](https://arxiv.org/abs/2508.13020)
*Jiaqi Yin,Zhan Song,Chen Chen,Yaohui Cai,Zhiru Zhang,Cunxi Yu*

Main category: cs.AI

TL;DR: e-boost是一个新颖的e-graph提取框架，通过并行启发式提取、自适应搜索空间剪枝和初始化精确求解三项创新技术，在保持接近最优解的同时显著提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统e-graph提取方法面临速度与最优性的权衡：启发式方法快但牺牲最优性，精确方法提供最优解但计算成本过高。需要一种能够兼顾效率和质量的解决方案。

Method: 1) 并行化启发式提取：利用弱数据依赖性并行计算DAG成本；2) 自适应搜索空间剪枝：使用参数化阈值机制保留有希望的候选解；3) 初始化精确求解：将简化问题建模为具有热启动能力的整数线性规划问题。

Result: 在形式验证和逻辑综合基准测试中，e-boost相比传统精确方法(ILP)实现558倍加速，相比最先进提取框架(SmoothE)提升19.04%性能。在实际逻辑综合任务中，相比传统工具分别获得7.6%和8.1%的面积优化。

Conclusion: e-boost成功解决了e-graph提取中速度与最优性的权衡问题，通过创新的混合方法实现了显著的性能提升和效率改进，为e-graph优化任务提供了实用的高性能解决方案。

Abstract: E-graphs have attracted growing interest in many fields, particularly in
logic synthesis and formal verification. E-graph extraction is a challenging
NP-hard combinatorial optimization problem. It requires identifying optimal
terms from exponentially many equivalent expressions, serving as the primary
performance bottleneck in e-graph based optimization tasks. However,
traditional extraction methods face a critical trade-off: heuristic approaches
offer speed but sacrifice optimality, while exact methods provide optimal
solutions but face prohibitive computational costs on practical problems. We
present e-boost, a novel framework that bridges this gap through three key
innovations: (1) parallelized heuristic extraction that leverages weak data
dependence to compute DAG costs concurrently, enabling efficient multi-threaded
performance without sacrificing extraction quality; (2) adaptive search space
pruning that employs a parameterized threshold mechanism to retain only
promising candidates, dramatically reducing the solution space while preserving
near-optimal solutions; and (3) initialized exact solving that formulates the
reduced problem as an Integer Linear Program with warm-start capabilities,
guiding solvers toward high-quality solutions faster.
  Across the diverse benchmarks in formal verification and logic synthesis
fields, e-boost demonstrates 558x runtime speedup over traditional exact
approaches (ILP) and 19.04% performance improvement over the state-of-the-art
extraction framework (SmoothE). In realistic logic synthesis tasks, e-boost
produces 7.6% and 8.1% area improvements compared to conventional synthesis
tools with two different technology mapping libraries. e-boost is available at
https://github.com/Yu-Maryland/e-boost.

</details>


### [116] [PC-Sampler: Position-Aware Calibration of Decoding Bias in Masked Diffusion Models](https://arxiv.org/abs/2508.13021)
*Pengcheng Huang,Shuhao Liu,Zhenghao Liu,Yukun Yan,Shuo Wang,Zulong Chen,Tong Xiao*

Main category: cs.AI

TL;DR: PC-Sampler是一种新的掩码扩散模型解码策略，通过位置感知加权和置信度校准来解决现有不确定性采样器的局限性，在多个基准测试中平均提升10%以上性能


<details>
  <summary>Details</summary>
Motivation: 现有掩码扩散模型的解码策略存在两个关键限制：缺乏全局轨迹控制和早期解码阶段偏向简单词汇的明显偏差，限制了MDMs的潜力

Method: 提出位置感知置信度校准采样(PC-Sampler)，结合全局轨迹规划和内容感知信息最大化，包含位置感知加权机制和校准置信度分数

Result: 在三个先进MDM模型和七个具有挑战性的基准测试（包括逻辑推理和规划任务）上，PC-Sampler平均比现有MDM解码策略提升10%以上，显著缩小了与最先进自回归模型的性能差距

Conclusion: PC-Sampler通过统一的全局轨迹规划和内容感知信息最大化方法，有效解决了掩码扩散模型解码策略的关键限制，显著提升了生成质量

Abstract: Recent advances in masked diffusion models (MDMs) have established them as
powerful non-autoregressive alternatives for sequence generation. Nevertheless,
our preliminary experiments reveal that the generation quality of MDMs is still
highly sensitive to the choice of decoding strategy. In particular, widely
adopted uncertainty-based samplers suffer from two key limitations: a lack of
global trajectory control and a pronounced bias toward trivial tokens in the
early stages of decoding. These shortcomings restrict the full potential of
MDMs. In this work, we introduce Position-Aware Confidence-Calibrated Sampling
(PC-Sampler), a novel decoding strategy that unifies global trajectory planning
with content-aware informativeness maximization. PC-Sampler incorporates a
position-aware weighting mechanism to regulate the decoding path and a
calibrated confidence score to suppress the premature selection of trivial
tokens. Extensive experiments on three advanced MDMs across seven challenging
benchmarks-including logical reasoning and planning tasks-demonstrate that
PC-Sampler consistently outperforms existing MDM decoding strategies by more
than 10% on average, significantly narrowing the performance gap with
state-of-the-art autoregressive models. All codes are available at
https://github.com/NEUIR/PC-Sampler.

</details>


### [117] [G$^2$RPO-A: Guided Group Relative Policy Optimization with Adaptive Guidance](https://arxiv.org/abs/2508.13023)
*Yongxin Guo,Wenbo Deng,Zhenglin Cheng,Xiaoying Tang*

Main category: cs.AI

TL;DR: G²RPO-A算法通过自适应调整指导强度，有效提升了小语言模型在强化学习中的推理能力，显著优于传统GRPO方法。


<details>
  <summary>Details</summary>
Motivation: 传统RLVR方法对大型语言模型效果显著，但对小语言模型改进有限，需要解决小模型内在知识不足的问题。

Method: 提出G²RPO-A算法，在roll-out轨迹中注入真实推理步骤作为指导，并自适应调整指导强度以适应模型训练动态变化。

Result: 在数学推理和代码生成基准测试中，G²RPO-A显著超越了原始GRPO方法，证明了其有效性。

Conclusion: 自适应指导机制是提升小语言模型强化学习性能的有效策略，为资源受限环境下的模型优化提供了新思路。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has markedly enhanced
the reasoning abilities of large language models (LLMs). Its success, however,
largely depends on strong base models with rich world knowledge, yielding only
modest improvements for small-size language models (SLMs). To address this
limitation, we investigate Guided GRPO, which injects ground-truth reasoning
steps into roll-out trajectories to compensate for SLMs' inherent weaknesses.
Through a comprehensive study of various guidance configurations, we find that
naively adding guidance delivers limited gains. These insights motivate
G$^2$RPO-A, an adaptive algorithm that automatically adjusts guidance strength
in response to the model's evolving training dynamics. Experiments on
mathematical reasoning and code-generation benchmarks confirm that G$^2$RPO-A
substantially outperforms vanilla GRPO. Our code and models are available at
https://github.com/T-Lab-CUHKSZ/G2RPO-A.

</details>


### [118] [A Language-Signal-Vision Multimodal Framework for Multitask Cardiac Analysis](https://arxiv.org/abs/2508.13072)
*Yuting Zhang,Tiantian Geng,Luoying Hao,Xinxing Cheng,Alexander Thorley,Xiaoxia Wang,Wenqi Lu,Sandeep S Hothi,Lei Wei,Zhaowen Qiu,Dipak Kotecha,Jinming Duan*

Main category: cs.AI

TL;DR: TGMM是一个统一的多模态心脏任务框架，通过MedFlexFusion模块动态整合多种心脏数据源，结合文本引导模块实现多任务处理，在心脏疾病诊断、风险分层和信息检索等任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前心血管管理面临多模态数据稀缺、单模态或固定多模态组合的局限性、跨模态对齐策略过度强调相似性而非互补性、以及单任务焦点狭窄等问题，需要开发能够有效整合多模态心脏数据的统一框架。

Method: 提出了TGMM框架，包含三个核心组件：1) MedFlexFusion模块捕获医学模态的独特互补特征并动态整合多种心脏数据源；2) 文本引导模块针对不同临床目标生成任务相关表示；3) 响应模块为所有任务生成最终决策。

Result: 广泛的实验表明TGMM在多个临床任务上优于最先进方法，并在另一个公共数据集上验证了其鲁棒性。系统探索了多模态关键特征及其在临床决策中的协同贡献。

Conclusion: TGMM框架成功解决了多模态心脏数据整合的挑战，提供了一个统一的解决方案来处理多种心脏相关临床任务，展示了多模态数据在心血管管理中的重要作用和协同效应。

Abstract: Contemporary cardiovascular management involves complex consideration and
integration of multimodal cardiac datasets, where each modality provides
distinct but complementary physiological characteristics. While the effective
integration of multiple modalities could yield a holistic clinical profile that
accurately models the true clinical situation with respect to data modalities
and their relatives weightings, current methodologies remain limited by: 1) the
scarcity of patient- and time-aligned multimodal data; 2) reliance on isolated
single-modality or rigid multimodal input combinations; 3) alignment strategies
that prioritize cross-modal similarity over complementarity; and 4) a narrow
single-task focus. In response to these limitations, a comprehensive multimodal
dataset was curated for immediate application, integrating laboratory test
results, electrocardiograms, and echocardiograms with clinical outcomes.
Subsequently, a unified framework, Textual Guidance Multimodal fusion for
Multiple cardiac tasks (TGMM), was proposed. TGMM incorporated three key
components: 1) a MedFlexFusion module designed to capture the unique and
complementary characteristics of medical modalities and dynamically integrate
data from diverse cardiac sources and their combinations; 2) a textual guidance
module to derive task-relevant representations tailored to diverse clinical
objectives, including heart disease diagnosis, risk stratification and
information retrieval; and 3) a response module to produce final decisions for
all these tasks. Furthermore, this study systematically explored key features
across multiple modalities and elucidated their synergistic contributions in
clinical decision-making. Extensive experiments showed that TGMM outperformed
state-of-the-art methods across multiple clinical tasks, with additional
validation confirming its robustness on another public dataset.

</details>


### [119] [Bayesian Optimization-based Search for Agent Control in Automated Game Testing](https://arxiv.org/abs/2508.13121)
*Carlos Celemin*

Main category: cs.AI

TL;DR: 基于贝叶斯优化的自动化游戏测试方法，使用智能体控制游戏角色来检测关卡bug，通过网格地图模型实现高效采样和探索


<details>
  <summary>Details</summary>
Motivation: 传统游戏测试方法存在可扩展性问题，需要一种能够高效探索游戏地图并检测潜在bug的自动化测试方案

Method: 采用贝叶斯优化(BO)进行样本高效搜索，构建基于网格地图的游戏测试专用模型，支持平滑性和不确定性估计

Result: 实验证明该方法在时间效率和探索分布方面显著提高了地图覆盖率

Conclusion: 该方法为游戏测试提供了一种高效、可扩展的自动化解决方案，克服了传统模型的局限性

Abstract: This work introduces an automated testing approach that employs agents
controlling game characters to detect potential bugs within a game level.
Harnessing the power of Bayesian Optimization (BO) to execute sample-efficient
search, the method determines the next sampling point by analyzing the data
collected so far and calculates the data point that will maximize information
acquisition. To support the BO process, we introduce a game testing-specific
model built on top of a grid map, that features the smoothness and uncertainty
estimation required by BO, however and most importantly, it does not suffer the
scalability issues that traditional models carry. The experiments demonstrate
that the approach significantly improves map coverage capabilities in both time
efficiency and exploration distribution.

</details>
