<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 14]
- [cs.CR](#cs.CR) [Total: 8]
- [cs.AI](#cs.AI) [Total: 33]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Automated File-Level Logging Generation for Machine Learning Applications using LLMs: A Case Study using GPT-4o Mini](https://arxiv.org/abs/2508.04820)
*Mayra Sofia Ruiz Rodriguez,SayedHassan Khatoonabadi,Emad Shihab*

Main category: cs.SE

TL;DR: 研究评估了GPT-4o mini在机器学习项目中生成文件级日志的能力，发现其在63.91%的情况下与人类日志位置一致，但存在82.66%的过度日志问题。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型（LLMs）在文件级日志生成中的潜力，特别是在机器学习应用中，以提升系统可靠性。

Method: 收集171个ML仓库的4,073个Python文件，移除原始日志后使用LLM生成日志，评估日志位置、级别、变量和文本质量，并进行手动分析。

Result: LLM在63.91%的情况下与人类日志位置一致，但过度日志率高达82.66%，且在大型代码块和项目特定日志规范中存在挑战。

Conclusion: LLM在文件级日志生成中表现有潜力，但需解决过度日志和规范对齐问题以实现实际应用。

Abstract: Logging is essential in software development, helping developers monitor
system behavior and aiding in debugging applications. Given the ability of
large language models (LLMs) to generate natural language and code, researchers
are exploring their potential to generate log statements. However, prior work
focuses on evaluating logs introduced in code functions, leaving file-level log
generation underexplored -- especially in machine learning (ML) applications,
where comprehensive logging can enhance reliability. In this study, we evaluate
the capacity of GPT-4o mini as a case study to generate log statements for ML
projects at file level. We gathered a set of 171 ML repositories containing
4,073 Python files with at least one log statement. We identified and removed
the original logs from the files, prompted the LLM to generate logs for them,
and evaluated both the position of the logs and log level, variables, and text
quality of the generated logs compared to human-written logs. In addition, we
manually analyzed a representative sample of generated logs to identify common
patterns and challenges. We find that the LLM introduces logs in the same place
as humans in 63.91% of cases, but at the cost of a high overlogging rate of
82.66%. Furthermore, our manual analysis reveals challenges for file-level
logging, which shows overlogging at the beginning or end of a function,
difficulty logging within large code blocks, and misalignment with
project-specific logging conventions. While the LLM shows promise for
generating logs for complete files, these limitations remain to be addressed
for practical implementation.

</details>


### [2] [Automated Bug Frame Retrieval from Gameplay Videos Using Vision-Language Models](https://arxiv.org/abs/2508.04895)
*Wentao Lu,Alexander Senchenko,Abram Hindle,Cor-Paul Bezemer*

Main category: cs.SE

TL;DR: 论文提出了一种自动化管道，将游戏视频缩减为最能匹配错误描述的单帧图像，显著减少开发者的手动工作量。


<details>
  <summary>Details</summary>
Motivation: 现代游戏工作室快速发布新版本和补丁，产生大量包含游戏视频的错误报告，手动审核这些视频耗时且难以扩展。

Method: 使用FFmpeg提取关键帧，并通过视觉-语言模型（GPT-4o）选择最匹配错误描述的代表性帧。

Result: 在真实游戏视频和JIRA错误报告上测试，管道在Top-1检索帧上达到F1分数0.79和准确率0.89。

Conclusion: 该方法通过提供即时信息图像，显著减少了手动工作量，加快了错误分类和回归检查，对游戏行业的QA团队和开发者具有实际价值。

Abstract: Modern game studios deliver new builds and patches at a rapid pace,
generating thousands of bug reports, many of which embed gameplay videos. To
verify and triage these bug reports, developers must watch the submitted
videos. This manual review is labour-intensive, slow, and hard to scale. In
this paper, we introduce an automated pipeline that reduces each video to a
single frame that best matches the reported bug description, giving developers
instant visual evidence that pinpoints the bug.
  Our pipeline begins with FFmpeg for keyframe extraction, reducing each video
to a median of just 1.90% of its original frames while still capturing bug
moments in 98.79 of cases. These keyframes are then evaluated by a
vision--language model (GPT-4o), which ranks them based on how well they match
the textual bug description and selects the most representative frame. We
evaluated this approach using real-world developer-submitted gameplay videos
and JIRA bug reports from a popular First-Person Shooter (FPS) game. The
pipeline achieves an overall F1 score of 0.79 and Accuracy of 0.89 for the
top-1 retrieved frame. Performance is highest for the Lighting & Shadow (F1 =
0.94), Physics & Collision (0.86), and UI & HUD (0.83) bug categories, and
lowest for Animation & VFX (0.51).
  By replacing video viewing with an immediately informative image, our
approach dramatically reduces manual effort and speeds up triage and regression
checks, offering practical benefits to quality assurance (QA) teams and
developers across the game industry.

</details>


### [3] [Charting Uncertain Waters: A Socio-Technical Framework for Navigating GenAI's Impact on Open Source Communities](https://arxiv.org/abs/2508.04921)
*Zixuan Feng,Reed Milewicz,Emerson Murphy-Hill,Tyler Menezes,Alexander Serebrenik,Igor Steinmacher,Anita Sarma*

Main category: cs.SE

TL;DR: 开源软件社区面临生成式AI带来的不确定性，需通过社会技术框架探索风险与机遇，以增强社区韧性。


<details>
  <summary>Details</summary>
Motivation: 生成式AI快速改变软件开发方式，可能威胁开源社区的协作精神，需明确框架应对。

Method: 采用基于McLuhan Tetrad的社会技术框架，进行情景驱动的概念性探索，分析四个领域的影响。

Result: 识别了生成式AI对软件实践、文档、社区参与和治理的潜在风险与机遇。

Conclusion: 开源社区领导者和研究者可主动塑造生态系统未来，而非被动应对技术变革。

Abstract: Open Source Software communities face a wave of uncertainty as Generative AI
rapidly transforms how software is created, maintained, and governed. Without
clear frameworks, communities risk being overwhelmed by the complexity and
ambiguity introduced by GenAI, threatening the collaborative ethos that
underpins OSS. We conduct a scenario-driven, conceptual exploration using a
socio-technical framework inspired by McLuhan's Tetrad to surface both risks
and opportunities for community resilience amid GenAI-driven disruption of OSS
development across four domains: software practices, documentation, community
engagement, and governance. By adopting this lens, OSS leaders and researchers
can proactively shape the future of their ecosystems, rather than simply
reacting to technological upheaval.

</details>


### [4] [Taxonomy of Faults in Attention-Based Neural Networks](https://arxiv.org/abs/2508.04925)
*Sigma Jahan,Saurabh Singh Rajput,Tushar Sharma,Mohammad Masudur Rahman*

Main category: cs.SE

TL;DR: 论文提出首个针对注意力机制神经网络（ABNNs）的故障分类研究，填补了现有深度学习故障分类的不足。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习故障分类未能充分涵盖注意力机制引入的独特故障，导致缺乏可操作的诊断指导。

Method: 通过系统分析555个来自96个项目的真实故障，开发了包含七类注意力特有故障的新分类法。

Result: 超过一半的ABNN故障源于注意力架构特有机制，研究还提出了四种诊断启发式方法，解释了33.0%的注意力特有故障。

Conclusion: 研究为注意力模型提供了首个系统性诊断指导，填补了现有研究的空白。

Abstract: Attention mechanisms are at the core of modern neural architectures, powering
systems ranging from ChatGPT to autonomous vehicles and driving a major
economic impact. However, high-profile failures, such as ChatGPT's nonsensical
outputs or Google's suspension of Gemini's image generation due to attention
weight errors, highlight a critical gap: existing deep learning fault
taxonomies might not adequately capture the unique failures introduced by
attention mechanisms. This gap leaves practitioners without actionable
diagnostic guidance. To address this gap, we present the first comprehensive
empirical study of faults in attention-based neural networks (ABNNs). Our work
is based on a systematic analysis of 555 real-world faults collected from 96
projects across ten frameworks, including GitHub, Hugging Face, and Stack
Overflow. Through our analysis, we develop a novel taxonomy comprising seven
attention-specific fault categories, not captured by existing work. Our results
show that over half of the ABNN faults arise from mechanisms unique to
attention architectures. We further analyze the root causes and manifestations
of these faults through various symptoms. Finally, by analyzing symptom-root
cause associations, we identify four evidence-based diagnostic heuristics that
explain 33.0% of attention-specific faults, offering the first systematic
diagnostic guidance for attention-based models.

</details>


### [5] [Generative AI for Object-Oriented Programming: Writing the Right Code and Reasoning the Right Logic](https://arxiv.org/abs/2508.05005)
*Gang Xu,Airong Wang,Yushan Pan*

Main category: cs.SE

TL;DR: 论文探讨了大型语言模型（LLMs）与面向对象编程（OOP）的结合，提出了如何利用LLMs提升OOP学习和代码编写的有效性，并提出了评估方法。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs与OOP的结合研究不足，缺乏对LLMs如何提升OOP学习和代码编写的理解，以及如何评估这些AI工具。

Method: 从程序员、新手和经验丰富的程序员的角度，分析典型编码流程中LLMs可以发挥作用的环节，并提出增强逻辑推理和代码编写的方法。

Result: 识别了LLMs在OOP任务中的关键应用点，并提出了提升编程体验的具体方法。

Conclusion: LLMs在OOP领域有巨大潜力，未来研究应进一步探索其应用和评估方法。

Abstract: We find ourselves in the midst of an explosion in artificial intelligence
research, particularly with large language models (LLMs). These models have
diverse applications spanning finance, commonsense knowledge graphs, medicine,
and visual analysis. In the world of Object-Oriented Programming(OOP), a robust
body of knowledge and methods has been developed for managing complex tasks
through object-oriented thinking. However, the intersection of LLMs with OOP
remains an underexplored territory. Empirically, we currently possess limited
understanding of how LLMs can enhance the effectiveness of OOP learning and
code writing, as well as how we can evaluate such AI-powered tools. Our work
aims to address this gap by presenting a vision from the perspectives of key
stakeholders involved in an OOP task: programmers, mariners, and experienced
programmers. We identify critical junctures within typical coding workflows
where the integration of LLMs can offer significant benefits. Furthermore, we
propose ways to augment existing logical reasoning and code writing, ultimately
enhancing the programming experience.

</details>


### [6] [An ML-based Approach to Predicting Software Change Dependencies: Insights from an Empirical Study on OpenStack](https://arxiv.org/abs/2508.05034)
*Arabat,Ali,Sayagh,Mohammed,Hassine,Jameleddine*

Main category: cs.SE

TL;DR: 论文研究了大型软件系统中变更依赖管理的挑战，提出了一种半自动化方法，利用两个机器学习模型预测和识别依赖关系，显著提高了依赖管理的效率。


<details>
  <summary>Details</summary>
Motivation: 随着软件系统复杂度的增加，准确识别和管理变更依赖变得至关重要，尤其是在跨团队和多组件环境中。依赖问题通常在代码审查阶段才被发现，导致开发效率低下。

Method: 研究基于OpenStack的初步调查，提出了两个ML模型：一个预测变更间依赖的可能性，另一个识别具体的依赖变更对。

Result: 模型表现良好，平均AUC分数分别为79.33%和91.89%，Brier分数为0.11和0.014。第二个模型在top-k召回率上表现优异。

Conclusion: 提出的半自动化方法能有效帮助开发者提前识别依赖关系，减少延迟和搜索时间，提升开发效率。

Abstract: As software systems grow in complexity, accurately identifying and managing
dependencies among changes becomes increasingly critical. For instance, a
change that leverages a function must depend on the change that introduces it.
Establishing such dependencies allows CI/CD pipelines to build and orchestrate
changes effectively, preventing build failures and incomplete feature
deployments. In modern software systems, dependencies often span multiple
components across teams, creating challenges for development and deployment.
They serve various purposes, from enabling new features to managing
configurations, and can even involve traditionally independent changes like
documentation updates. To address these challenges, we conducted a preliminary
study on dependency management in OpenStack, a large-scale software system. Our
study revealed that a substantial portion of software changes in OpenStack over
the past 10 years are interdependent. Surprisingly, 51.08% of these
dependencies are identified during the code review phase-after a median delay
of 5.06 hours-rather than at the time of change creation. Developers often
spend a median of 57.12 hours identifying dependencies, searching among a
median of 463 other changes. To help developers proactively identify
dependencies, we propose a semi-automated approach that leverages two ML
models. The first model predicts the likelihood of dependencies among changes,
while the second identifies the exact pairs of dependent changes. Our proposed
models demonstrate strong performance, achieving average AUC scores of 79.33%
and 91.89%, and Brier scores of 0.11 and 0.014, respectively. Indeed, the
second model has a good top-k recall across all types of pairs, while the top-k
precision has room for improvement.

</details>


### [7] [LadyBug: A GitHub Bot for UI-Enhanced Bug Localization in Mobile Apps](https://arxiv.org/abs/2508.05085)
*Junayed Mahmud,James Chen,Terry Achille,Camilo Alvarez-Velez,Darren Dean Bansil,Patrick Ijieh,Samar Karanch,Nadeeshan De Silva,Oscar Chaparro,Andrian Marcus,Kevin Moran*

Main category: cs.SE

TL;DR: LadyBug是一个GitHub机器人，通过结合UI交互信息和文本检索来自动定位Android应用中的bug。它利用开发者上传的bug重现轨迹和原始bug描述，生成可能包含bug的文件排名列表。


<details>
  <summary>Details</summary>
Motivation: 提高Android应用中bug定位的准确性和效率，减少开发者手动调试的时间。

Method: LadyBug连接到GitHub仓库，通过问题跟踪器触发，结合UI交互信息和文本检索技术定位bug。

Result: 在包含80个bug报告的基准测试中，LadyBug优于纯文本检索基线，UI信息的利用显著提高了定位准确性。

Conclusion: LadyBug是一个有效的开源工具，通过结合UI和文本信息，显著提升了bug定位的准确性。

Abstract: This paper introduces LadyBug, a GitHub bot that automatically localizes bugs
for Android apps by combining UI interaction information with text retrieval.
LadyBug connects to an Android app's GitHub repository, and is triggered when a
bug is reported in the corresponding issue tracker. Developers can then record
a reproduction trace for the bug on a device or emulator and upload the trace
to LadyBug via the GitHub issue tracker. This enables LadyBug to utilize both
the text from the original bug description, and UI information from the
reproduction trace to accurately retrieve a ranked list of files from the
project that most likely contain the reported bug.
  We empirically evaluated LadyBug using an automated testing pipeline and
benchmark called RedWing that contains 80 fully-localized and reproducible bug
reports from 39 Android apps. Our results illustrate that LadyBug outperforms
text-retrieval-based baselines and that the utilization of UI information leads
to a substantial increase in localization accuracy. LadyBug is an open-source
tool, available at https://github.com/LadyBugML/ladybug.
  A video showing the capabilities of Ladybug can be viewed here:
https://youtu.be/hI3tzbRK0Cw

</details>


### [8] [Posterior-GRPO: Rewarding Reasoning Processes in Code Generation](https://arxiv.org/abs/2508.05170)
*Lishui Fan,Yu Zhang,Mouxiang Chen,Zhongxin Liu*

Main category: cs.SE

TL;DR: 论文提出了一种统一框架，结合推理过程质量优化强化学习，通过LCB-RB基准和OD-based奖励模型训练方法，以及P-GRPO算法，显著提升代码生成性能。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习范式仅依赖测试结果的奖励，忽视了中间推理过程的质量，易导致奖励黑客问题。

Method: 开发LCB-RB基准评估推理质量，提出OD-based奖励模型训练方法，并设计P-GRPO算法选择性奖励成功任务的推理过程。

Result: 7B参数模型在代码生成任务中表现优异，超越基线4.5%，接近GPT-4-Turbo，并成功推广至数学任务。

Conclusion: 结合推理过程质量的强化学习方法有效提升了模型性能，并具备泛化能力。

Abstract: Reinforcement learning (RL) has significantly advanced code generation for
large language models (LLMs). However, current paradigms rely on outcome-based
rewards from test cases, neglecting the quality of the intermediate reasoning
process. While supervising the reasoning process directly is a promising
direction, it is highly susceptible to reward hacking, where the policy model
learns to exploit the reasoning reward signal without improving final outcomes.
To address this, we introduce a unified framework that can effectively
incorporate the quality of the reasoning process during RL. First, to enable
reasoning evaluation, we develop LCB-RB, a benchmark comprising preference
pairs of superior and inferior reasoning processes. Second, to accurately score
reasoning quality, we introduce an Optimized-Degraded based (OD-based) method
for reward model training. This method generates high-quality preference pairs
by systematically optimizing and degrading initial reasoning paths along
curated dimensions of reasoning quality, such as factual accuracy, logical
rigor, and coherence. A 7B parameter reward model with this method achieves
state-of-the-art (SOTA) performance on LCB-RB and generalizes well to other
benchmarks. Finally, we introduce Posterior-GRPO (P-GRPO), a novel RL method
that conditions process-based rewards on task success. By selectively applying
rewards to the reasoning processes of only successful outcomes, P-GRPO
effectively mitigates reward hacking and aligns the model's internal reasoning
with final code correctness. A 7B parameter model with P-GRPO achieves superior
performance across diverse code generation tasks, outperforming outcome-only
baselines by 4.5%, achieving comparable performance to GPT-4-Turbo. We further
demonstrate the generalizability of our approach by extending it to
mathematical tasks. Our models, dataset, and code are publicly available.

</details>


### [9] [AI-assisted JSON Schema Creation and Mapping](https://arxiv.org/abs/2508.05192)
*Felix Neubauer,Jürgen Pleiss,Benjamin Uekermann*

Main category: cs.SE

TL;DR: 提出了一种结合大型语言模型（LLMs）和确定性技术的混合方法，用于通过自然语言输入创建和修改JSON Schema，并集成到开源工具MetaConfigurator中。


<details>
  <summary>Details</summary>
Motivation: 许多领域缺乏标准化模型，且非专家创建模型存在困难。

Method: 结合LLMs和确定性技术，支持自然语言输入的JSON Schema创建、修改和映射，并集成到MetaConfigurator工具中。

Result: 通过化学领域的应用示例验证了方法的适用性，显著降低了非专家进行结构化数据建模和数据集成的门槛。

Conclusion: 结合自然语言交互和确定性保障，为非专家提供了更便捷的数据建模和集成解决方案。

Abstract: Model-Driven Engineering (MDE) places models at the core of system and data
engineering processes. In the context of research data, these models are
typically expressed as schemas that define the structure and semantics of
datasets. However, many domains still lack standardized models, and creating
them remains a significant barrier, especially for non-experts. We present a
hybrid approach that combines large language models (LLMs) with deterministic
techniques to enable JSON Schema creation, modification, and schema mapping
based on natural language inputs by the user. These capabilities are integrated
into the open-source tool MetaConfigurator, which already provides visual model
editing, validation, code generation, and form generation from models. For data
integration, we generate schema mappings from heterogeneous JSON, CSV, XML, and
YAML data using LLMs, while ensuring scalability and reliability through
deterministic execution of generated mapping rules. The applicability of our
work is demonstrated in an application example in the field of chemistry. By
combining natural language interaction with deterministic safeguards, this work
significantly lowers the barrier to structured data modeling and data
integration for non-experts.

</details>


### [10] [STEPWISE-CODEX-Bench: Evaluating Complex Multi-Function Comprehension and Fine-Grained Execution Reasoning](https://arxiv.org/abs/2508.05193)
*Kaiwen Yan,Yuhang Chang,Zirui Guo,Yaling Mou,Jiang Ming,Jingwei Sun*

Main category: cs.SE

TL;DR: SX-Bench是一个新的代码评估基准，专注于复杂多函数理解和细粒度执行推理，揭示了现有模型在复杂推理中的瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有基准（如HumanEval和MBPP）主要测试功能正确性，而复杂推理能力评估不足，导致高级模型得分饱和，缺乏区分度。

Method: 提出SX-Bench，通过多子函数协作任务（如链式调用、嵌套循环）评估整体控制和数据流建模能力，以“计算步骤”为最小执行单元。

Result: 在20多个主流模型上测试，SX-Bench显示出高区分度，即使是OpenAI-O3在Hard-Reasoning任务上准确率仅为78.37%。

Conclusion: SX-Bench将代码评估从“单函数验证”推进到“多函数动态推理”，为深入评估代码智能模型提供了关键工具。

Abstract: In recent years, large language models (LLMs) have made significant progress
in code intelligence, yet systematically evaluating their code understanding
and reasoning abilities remains challenging. Mainstream benchmarks such as
HumanEval and MBPP primarily assess functional correctness, while reasoning
benchmarks like CRUXEVAL are limited to single-function, low-complexity
scenarios. As a result, advanced models achieve nearly saturated scores,
limiting their discriminative power. To address this, we present
STEPWISE-CODEX-Bench (SX-Bench), a novel benchmark designed for complex
multi-function understanding and fine-grained execution reasoning. SX-Bench
features tasks involving collaboration among multiple sub-functions (e.g.,
chained calls, nested loops), shifting evaluation towards overall control and
data flow modeling. It defines "computation steps" as the minimal execution
unit and requires models to predict the total number of steps in reasoning
tasks, thereby assessing a model's in-depth understanding of dynamic execution
beyond simple I/O matching. Evaluation on over 20 mainstream models (including
14 reasoning-enhanced models) demonstrates that SX-Bench is highly
discriminative: even the state-of-the-art OpenAI-O3 achieves only 78.37 percent
accuracy on Hard-Reasoning tasks, much lower than its saturated scores on
previous benchmarks, thereby revealing bottlenecks in complex and fine-grained
reasoning. We also release an automated pipeline combining program synthesis,
symbolic execution, and LLM-aided validation for efficient benchmark generation
and quality assurance. SX-Bench advances code evaluation from "single-function
verification" to "multi-function dynamic reasoning," providing a key tool for
the in-depth assessment of advanced code intelligence models.

</details>


### [11] [EvoGraph: Hybrid Directed Graph Evolution toward Software 3.0](https://arxiv.org/abs/2508.05199)
*Igor Costa,Christopher Baran*

Main category: cs.SE

TL;DR: EvoGraph是一个框架，通过类型化有向图和专用小型语言模型（SLM）实现软件系统的自我进化，包括源代码、构建管道、文档和工单。


<details>
  <summary>Details</summary>
Motivation: 解决传统软件现代化中的挑战，如隐式契约、性能保持和集成演化，推动软件系统向持续自适应且可控的方向发展。

Method: 使用类型化有向图表示所有工件，应用基于SLM的突变操作符，并通过多目标适应度选择幸存者。

Result: 在三个基准测试中，修复83%的安全漏洞，COBOL转Java功能等效性达93%，文档更新延迟小于两分钟，延迟降低40%，功能交付时间缩短7倍。

Conclusion: EvoGraph为软件3.0提供了一条可行路径，系统能够持续自适应并保持可控性。

Abstract: We introduce **EvoGraph**, a framework that enables software systems to
evolve their own source code, build pipelines, documentation, and tickets.
EvoGraph represents every artefact in a typed directed graph, applies learned
mutation operators driven by specialized small language models (SLMs), and
selects survivors with a multi-objective fitness. On three benchmarks, EvoGraph
fixes 83% of known security vulnerabilities, translates COBOL to Java with 93%
functional equivalence (test verified), and maintains documentation freshness
within two minutes. Experiments show a 40% latency reduction and a sevenfold
drop in feature lead time compared with strong baselines. We extend our
approach to **evoGraph**, leveraging language-specific SLMs for modernizing
.NET, Lisp, CGI, ColdFusion, legacy Python, and C codebases, achieving 82-96%
semantic equivalence across languages while reducing computational costs by 90%
compared to large language models. EvoGraph's design responds to empirical
failure modes in legacy modernization, such as implicit contracts, performance
preservation, and integration evolution. Our results suggest a practical path
toward Software 3.0, where systems adapt continuously yet remain under
measurable control.

</details>


### [12] [A Conceptual Model and Methodology for Sustainability-aware, IoT-enhanced Business Processes](https://arxiv.org/abs/2508.05301)
*Victoria Torres Bosch,Ronny Seiger,Manuela Albert Albiol,Antoni Mestre Gascon,Pedro Jose Valderas Aranda*

Main category: cs.SE

TL;DR: 论文提出了一种概念模型和方法论，旨在利用物联网（IoT）技术提升业务流程（BPs）的可持续性，超越传统环境维度的研究。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注环境可持续性，但缺乏系统性方法全面衡量和提升业务流程的可持续性。

Method: 提出概念模型和方法论，结合BPM和IoT，通过案例（旅游和医疗）验证。

Result: 模型和方法论能有效识别和实施可持续性优化的IoT增强业务流程。

Conclusion: IoT技术为业务流程的可持续性提供了系统性解决方案，具有广泛适用性。

Abstract: The real-time data collection and automation capabilities offered by the
Internet of Things (IoT) are revolutionizing and transforming Business
Processes (BPs) into IoT-enhanced BPs, showing high potential for improving
sustainability. Although already studied in Business Process Management (BPM),
sustainability research has primarily focused on environmental concerns.
However, achieving a holistic and lasting impact requires a systematic approach
to address sustainability beyond the environmental dimension. This work
proposes a conceptual model and a structured methodology with the goal of
analyzing the potential of IoT to measure and improve the sustainability of
BPs. The conceptual model formally represents key sustainability concepts,
linking BPM and IoT by highlighting how IoT devices support and contribute to
sustainability. The methodology guides the systematic analysis of existing BPs,
identifies opportunities, and implements sustainability-aware, IoT-enhanced
BPs. The approach is illustrated through a running example from the tourism
domain and a case study in healthcare.

</details>


### [13] [Evaluating the Use of LLMs for Documentation to Code Traceability](https://arxiv.org/abs/2506.16440)
*Ebube Alor,SayedHassan Khatoonabadi,Emad Shihab*

Main category: cs.SE

TL;DR: 论文评估了大型语言模型（LLMs）在文档与代码之间建立追溯链接的能力，发现其性能优于基线方法，但在精确性和错误模式上仍需改进。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在自动化文档与代码追溯中的潜力，填补现有研究的空白。

Method: 通过系统实验评估LLMs在追溯链接识别、关系解释质量和多步链重建三个关键能力上的表现。

Result: 最佳LLM在两个数据集上的F1分数分别为79.4%和80.4%，关系解释的完全正确率为42.9%至71.1%，多步链的端点准确性高。

Conclusion: LLMs可作为追溯发现的有力工具，但需结合人工干预和任务框架设计以优化性能。

Abstract: Large Language Models (LLMs) offer new potential for automating
documentation-to-code traceability, yet their capabilities remain
underexplored. We present a comprehensive evaluation of LLMs (Claude 3.5
Sonnet, GPT-4o, and o3-mini) in establishing trace links between various
software documentation (including API references and user guides) and source
code. We create two novel datasets from two open-source projects (Unity Catalog
and Crawl4AI). Through systematic experiments, we assess three key
capabilities: (1) trace link identification accuracy, (2) relationship
explanation quality, and (3) multi-step chain reconstruction. Results show that
the best-performing LLM achieves F1-scores of 79.4% and 80.4% across the two
datasets, substantially outperforming our baselines (TF-IDF, BM25, and
CodeBERT). While fully correct relationship explanations range from 42.9% to
71.1%, partial accuracy exceeds 97%, indicating that fundamental connections
are rarely missed. For multi-step chains, LLMs maintain high endpoint accuracy
but vary in capturing precise intermediate links. Error analysis reveals that
many false positives stem from naming-based assumptions, phantom links, or
overgeneralization of architectural patterns. We demonstrate that task-framing,
such as a one-to-many matching strategy, is critical for performance. These
findings position LLMs as powerful assistants for trace discovery, but their
limitations could necessitate human-in-the-loop tool design and highlight
specific error patterns for future research.

</details>


### [14] [How Robust are LLM-Generated Library Imports? An Empirical Study using Stack Overflow](https://arxiv.org/abs/2507.10818)
*Jasmine Latendresse,SayedHassan Khatoonabadi,Emad Shihab*

Main category: cs.SE

TL;DR: 论文研究了六种先进LLM在解决Python问题时推荐的库，发现它们偏爱第三方库，但存在可用性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 了解LLM在编程任务中如何推荐库，以提升代码功能、安全性和可维护性。

Method: 通过从Stack Overflow获取真实Python问题，分析六种LLM推荐的库类型、特征及可用性。

Result: LLM主要推荐成熟、流行的第三方库，但4.6%的库因导入名与包名不匹配无法自动解析，且仅两种模型提供安装指导。

Conclusion: 研究为开发者和研究者提供了改进LLM生成代码可靠性和可用性的方向。

Abstract: Software libraries are central to the functionality, security, and
maintainability of modern code. As developers increasingly turn to Large
Language Models (LLMs) to assist with programming tasks, understanding how
these models recommend libraries is essential. In this paper, we conduct an
empirical study of six state-of-the-art LLMs, both proprietary and open-source,
by prompting them to solve real-world Python problems sourced from Stack
Overflow. We analyze the types of libraries they import, the characteristics of
those libraries, and the extent to which the recommendations are usable out of
the box. Our results show that LLMs predominantly favour third-party libraries
over standard ones, and often recommend mature, popular, and permissively
licensed dependencies. However, we also identify gaps in usability: 4.6% of the
libraries could not be resolved automatically due to structural mismatches
between import names and installable packages, and only two models (out of six)
provided installation guidance. While the generated code is technically valid,
the lack of contextual support places the burden of manually resolving
dependencies on the user. Our findings offer actionable insights for both
developers and researchers, and highlight opportunities to improve the
reliability and usability of LLM-generated code in the context of software
dependencies.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [15] [Adversarial Attacks and Defenses on Graph-aware Large Language Models (LLMs)](https://arxiv.org/abs/2508.04894)
*Iyiola E. Olatunji,Franziska Boenisch,Jing Xu,Adam Dziedzic*

Main category: cs.CR

TL;DR: 本文探讨了图结构数据与大语言模型（LLM）结合时的对抗攻击脆弱性，发现LLAGA和GRAPHPROMPTER模型易受攻击，并提出防御框架GALGUARD。


<details>
  <summary>Details</summary>
Motivation: 研究图结构数据与LLM结合的对抗攻击脆弱性，填补这一领域的空白。

Method: 利用现有的图模型对抗攻击方法（如投毒和规避攻击）测试LLAGA和GRAPHPROMPTER模型，并发现LLAGA的新攻击面。

Result: 发现LLAGA的节点序列模板增加脆弱性，GRAPHPROMPTER的GNN编码器更鲁棒，但两者均易受特征扰动攻击。

Conclusion: 提出GALGUARD防御框架，结合LLM特征校正和GNN防御，增强模型安全性。

Abstract: Large Language Models (LLMs) are increasingly integrated with
graph-structured data for tasks like node classification, a domain
traditionally dominated by Graph Neural Networks (GNNs). While this integration
leverages rich relational information to improve task performance, their
robustness against adversarial attacks remains unexplored. We take the first
step to explore the vulnerabilities of graph-aware LLMs by leveraging existing
adversarial attack methods tailored for graph-based models, including those for
poisoning (training-time attacks) and evasion (test-time attacks), on two
representative models, LLAGA (Chen et al. 2024) and GRAPHPROMPTER (Liu et al.
2024). Additionally, we discover a new attack surface for LLAGA where an
attacker can inject malicious nodes as placeholders into the node sequence
template to severely degrade its performance. Our systematic analysis reveals
that certain design choices in graph encoding can enhance attack success, with
specific findings that: (1) the node sequence template in LLAGA increases its
vulnerability; (2) the GNN encoder used in GRAPHPROMPTER demonstrates greater
robustness; and (3) both approaches remain susceptible to imperceptible feature
perturbation attacks. Finally, we propose an end-to-end defense framework
GALGUARD, that combines an LLM-based feature correction module to mitigate
feature-level perturbations and adapted GNN defenses to protect against
structural attacks.

</details>


### [16] [On the Classical Hardness of the Semidirect Discrete Logarithm Problem in Finite Groups](https://arxiv.org/abs/2508.05048)
*Mohammad Ferry Husnil Arif,Muhammad Imran*

Main category: cs.CR

TL;DR: 本文研究了半直接离散对数问题（SDLP）在经典计算模型下的硬度，发现其硬度高度依赖于群结构，且并不总是比标准离散对数问题（DLP）更难。


<details>
  <summary>Details</summary>
Motivation: SDLP曾被提出作为后量子密码协议的基础，但近期研究显示其对量子攻击并不安全。因此，本文探讨SDLP在经典计算模型下的优势。

Method: 将SDLP重新表述为广义离散对数问题，并改进Baby-Step Giant-Step算法以分析其复杂度。通过理论分析和SageMath实验验证。

Result: SDLP的经典硬度因群结构而异：在有限域中与DLP相当，在椭圆曲线中变得简单，在初等阿贝尔群中可能更难。

Conclusion: SDLP的非阿贝尔结构并不保证更高的经典硬度，密码应用需更谨慎选择代数结构。

Abstract: The semidirect discrete logarithm problem (SDLP) in finite groups was
proposed as a foundation for post-quantum cryptographic protocols, based on the
belief that its non-abelian structure would resist quantum attacks. However,
recent results have shown that SDLP in finite groups admits efficient quantum
algorithms, undermining its quantum resistance. This raises a fundamental
question: does the SDLP offer any computational advantages over the standard
discrete logarithm problem (DLP) against classical adversaries? In this work,
we investigate the classical hardness of SDLP across different finite group
platforms. We establish that the group-case SDLP can be reformulated as a
generalized discrete logarithm problem, enabling adaptation of classical
algorithms to study its complexity. We present a concrete adaptation of the
Baby-Step Giant-Step algorithm for SDLP, achieving time and space complexity
$O(\sqrt{r})$ where $r$ is the period of the underlying cycle structure.
Through theoretical analysis and experimental validation in SageMath, we
demonstrate that the classical hardness of SDLP is highly platform-dependent
and does not uniformly exceed that of standard DLP. In finite fields
$\mathbb{F}_p^*$, both problems exhibit comparable complexity. Surprisingly, in
elliptic curves $E(\mathbb{F}_p)$, the SDLP becomes trivial due to the bounded
automorphism group, while in elementary abelian groups $\mathbb{F}_p^n$, the
SDLP can be harder than DLP, with complexity varying based on the eigenvalue
structure of the automorphism. Our findings reveal that the non-abelian
structure of semidirect products does not inherently guarantee increased
classical hardness, suggesting that the search for classically hard problems
for cryptographic applications requires more careful consideration of the
underlying algebraic structures.

</details>


### [17] [Incident Response Planning Using a Lightweight Large Language Model with Reduced Hallucination](https://arxiv.org/abs/2508.05188)
*Kim Hammar,Tansu Alpcan,Emil C. Lupu*

Main category: cs.CR

TL;DR: 提出了一种利用LLM进行网络安全事件响应规划的新方法，通过微调、信息检索和前瞻规划减少幻觉，并在实验中表现出优于前沿LLM的性能。


<details>
  <summary>Details</summary>
Motivation: 解决当前基于前沿LLM的提示工程方法成本高且易产生幻觉的问题，提升事件响应的效率和准确性。

Method: 包括三个步骤：微调LLM、信息检索和前瞻规划，确保生成的响应计划幻觉概率有界且可调节。

Result: 实验表明，该方法恢复时间比前沿LLM缩短22%，且能泛化到多种事件类型和响应动作。

Conclusion: 该方法轻量且高效，适用于实际部署，为网络安全事件响应提供了新思路。

Abstract: Timely and effective incident response is key to managing the growing
frequency of cyberattacks. However, identifying the right response actions for
complex systems is a major technical challenge. A promising approach to
mitigate this challenge is to use the security knowledge embedded in large
language models (LLMs) to assist security operators during incident handling.
Recent research has demonstrated the potential of this approach, but current
methods are mainly based on prompt engineering of frontier LLMs, which is
costly and prone to hallucinations. We address these limitations by presenting
a novel way to use an LLM for incident response planning with reduced
hallucination. Our method includes three steps: fine-tuning, information
retrieval, and lookahead planning. We prove that our method generates response
plans with a bounded probability of hallucination and that this probability can
be made arbitrarily small at the expense of increased planning time under
certain assumptions. Moreover, we show that our method is lightweight and can
run on commodity hardware. We evaluate our method on logs from incidents
reported in the literature. The experimental results show that our method a)
achieves up to 22% shorter recovery times than frontier LLMs and b) generalizes
to a broad range of incident types and response actions.

</details>


### [18] [An Overview of 7726 User Reports: Uncovering SMS Scams and Scammer Strategies](https://arxiv.org/abs/2508.05276)
*Sharad Agarwal,Guillermo Suarez-Tangil,Marie Vasek*

Main category: cs.CR

TL;DR: 论文分析了用户提交的短信报告，区分了垃圾短信和诈骗短信，并首次对诈骗短信进行了分类。


<details>
  <summary>Details</summary>
Motivation: 研究绕过防火墙的短信内容，填补了现有研究的空白。

Method: 与主要移动网络运营商合作，收集了135万份用户报告，并开发了方法论框架进行分析。

Result: 35.12%的短信被识别为垃圾短信，40.27%为诈骗短信，并分类为12种诈骗类型。

Conclusion: 研究揭示了诈骗短信的类型和基础设施滥用情况，为防范提供了新视角。

Abstract: Mobile network operators implement firewalls to stop illicit messages, but
scammers find ways to evade detection. Previous work has looked into SMS texts
that are blocked by these firewalls. However, there is little insight into SMS
texts that bypass them and reach users. To this end, we collaborate with a
major mobile network operator to receive 1.35m user reports submitted over four
months. We find 89.16% of user reports comprise text messages, followed by
reports of suspicious calls and URLs. Using our methodological framework, we
identify 35.12% of the unique text messages reported by users as spam, while
40.27% are scam text messages. This is the first paper that investigates SMS
reports submitted by users and differentiates between spam and scams. Our paper
classifies the identified scam text messages into 12 scam types, of which the
most popular is 'wrong number' scams. We explore the various infrastructure
services that scammers abuse to conduct SMS scams, including mobile network
operators and hosting infrastructure, and analyze the text of the scam messages
to understand how scammers lure victims into providing them with their personal
or financial details.

</details>


### [19] [ShikkhaChain: A Blockchain-Powered Academic Credential Verification System for Bangladesh](https://arxiv.org/abs/2508.05334)
*Ahsan Farabi,Israt Khandaker,Nusrat Jahan,Ibrahim Khalil Shanto*

Main category: cs.CR

TL;DR: ShikkhaChain是一个基于区块链的学术证书管理平台，旨在解决孟加拉国等发展中国家学术证书欺诈问题，提供去中心化、防篡改的解决方案。


<details>
  <summary>Details</summary>
Motivation: 学术证书欺诈威胁教育诚信，尤其是在孟加拉国等发展中国家，现有验证方法效率低下且依赖人工。

Method: 平台基于以太坊智能合约和IPFS存储，通过React DApp和MetaMask集成实现透明、可扩展的解决方案，支持基于角色的访问和QR验证。

Result: 原型展示了增强的信任度、缩短的验证时间以及提升的国际可信度。

Conclusion: ShikkhaChain为孟加拉国的学术和就业生态系统提供了更可靠的解决方案。

Abstract: Academic credential fraud threatens educational integrity, especially in
developing countries like Bangladesh, where verification methods are primarily
manual and inefficient. To address this challenge, we present ShikkhaChain, a
blockchain-powered certificate management platform designed to securely issue,
verify, and revoke academic credentials in a decentralized and tamper-proof
manner. Built on Ethereum smart contracts and utilizing IPFS for off-chain
storage, the platform offers a transparent, scalable solution accessible
through a React-based DApp with MetaMask integration. ShikkhaChain enables
role-based access for governments, regulators, institutions, and public
verifiers, allowing QR-based validation and on-chain revocation tracking. Our
prototype demonstrates enhanced trust, reduced verification time, and improved
international credibility for Bangladeshi degrees, promoting a more reliable
academic and employment ecosystem.

</details>


### [20] [Grouped k-threshold random grid-based visual cryptography scheme](https://arxiv.org/abs/2508.05394)
*Xiaoli Zhuo,Xuehu Yan,Wei Yan*

Main category: cs.CR

TL;DR: 提出了一种新的随机网格视觉密码共享范式（n'-grouped (k,n) RGVCS），通过从任意(k,n')方案构建(k,n)方案，实现了分层次的对比度特性，并提出了新的对比度计算公式。最终通过设置n'=k，实现了现有文献中最高的对比度值。


<details>
  <summary>Details</summary>
Motivation: 现有(k,n)随机网格视觉密码方案（RGVCS）的对比度未能达到理论上限，亟需更高对比度的构造方法。

Method: 提出n'-grouped (k,n) RGVCS范式，从任意(k,n')方案构建(k,n)方案，并引入新的对比度计算公式。通过设置n'=k，实现对比度优化。

Result: 提出的方案在对比度上优于现有方法，达到了文献中的最高对比度值。

Conclusion: 新范式成功提升了RGVCS的对比度，为视觉密码的优化提供了有效途径。

Abstract: Visual cryptography schemes (VCSs) belong to a category of secret image
sharing schemes that do not require cryptographic knowledge for decryption,
instead relying directly on the human visual system. Among VCSs, random
grid-based VCS (RGVCS) has garnered widespread attention as it avoids pixel
expansion while requiring no basic matrices design. Contrast, a core metric for
RGVCS, directly determines the visual quality of recovered images, rendering
its optimization a critical research objective. However, existing $(k,n)$
RGVCSs still fail to attain theoretical upper bounds on contrast, highlighting
the urgent need for higher-contrast constructions. In this paper, we propose a
novel sharing paradigm for RGVCS that constructs $(k,n)$-threshold schemes from
arbitrary $(k,n')$-threshold schemes $(k \leq n'\leq n)$, termed
\emph{$n'$-grouped $(k,n)$ RGVCS}. This paradigm establishes hierarchical
contrast characteristics: participants within the same group achieve optimal
recovery quality, while inter-group recovery shows a hierarchical contrast. We
further introduce a new contrast calculation formula tailored to the new
paradigm. Then, we propose a contrast-enhanced $(k,n)$ RGVCS by setting $n'=
k$, achieving the highest contrast value documented in the existing literature.
Theoretical analysis and experimental results demonstrate the superiority of
our proposed scheme in terms of contrast.

</details>


### [21] [Local Distance Query with Differential Privacy](https://arxiv.org/abs/2508.05518)
*Weihong Sheng,Jiajun Chen,Bin Cai,Chunqiang Hu,Meng Han,Jiguo Yu*

Main category: cs.CR

TL;DR: 论文提出两种方法解决本地差分隐私（LDP）下距离查询的挑战：一种是生成合成图但效用低，另一种是首个专为距离查询设计的LDP方法，通过聚合局部距离向量捕获全局结构。


<details>
  <summary>Details</summary>
Motivation: 现实场景中缺乏可信的第三方管理者（curator），导致在本地差分隐私下实现距离查询具有挑战性。

Method: 1. 生成合成图并通过随机化响应和位操作减少噪声干扰；2. 首个专为距离查询设计的LDP方法，通过聚合局部距离向量更新全局距离。

Result: 理论分析和实验验证表明，第二种方法能有效捕获全局图结构并准确更新距离。

Conclusion: 提出的第二种方法在本地差分隐私下实现了高效的距离查询，克服了合成图方法的低效用问题。

Abstract: Differential Privacy (DP) is commonly employed to safeguard graph analysis or
publishing. Distance, a critical factor in graph analysis, is typically handled
using curator DP, where a trusted curator holds the complete neighbor lists of
all vertices and answers queries privately. However, in many real-world
scenarios, such a curator may not be present, posing a significant challenge
for implementing differentially private distance queries under Local
Differential Privacy (LDP). This paper proposes two approaches to address this
challenge. The first approach generates a synthetic graph by randomizing
responses and applies bitwise operations to reduce noise interference. However,
like other synthetic graph methods, this approach suffers from low utility. To
overcome this limitation, we propose a second approach, the first LDP method
specifically designed for distance queries, which captures the global graph
structure by continuously aggregating local distance vectors from neighboring
vertices. This process enables the accurate updating of global distances. We
demonstrate the effectiveness of our method through comprehensive theoretical
analysis and experimental evaluations on real-world datasets.

</details>


### [22] [PRvL: Quantifying the Capabilities and Risks of Large Language Models for PII Redaction](https://arxiv.org/abs/2508.05545)
*Leon Garza,Anantaa Kotal,Aritran Piplai,Lavanya Elluri,Prajit Das,Aman Chadha*

Main category: cs.CR

TL;DR: 论文探讨了利用大型语言模型（LLMs）进行个人身份信息（PII）脱敏的方法，分析了不同架构和训练策略的效果，并提出了开源工具PRvL以支持实际应用。


<details>
  <summary>Details</summary>
Motivation: 传统规则系统和特定领域NER模型在PII脱敏中泛化能力不足，LLMs因其上下文理解能力成为有潜力的替代方案，但其架构和训练选择对脱敏性能的影响尚未充分研究。

Method: 评估多种LLM架构和训练策略在PII脱敏中的效果，衡量脱敏性能、语义保留和PII泄漏，并与延迟和计算成本对比。

Result: 提供了配置高效、准确且隐私保护的LLM脱敏系统的实用指南，并开源了PRvL工具包，支持灵活部署和定制。

Conclusion: LLMs在PII脱敏中表现优异，PRvL为实际应用提供了可定制且安全的解决方案。

Abstract: Redacting Personally Identifiable Information (PII) from unstructured text is
critical for ensuring data privacy in regulated domains. While earlier
approaches have relied on rule-based systems and domain-specific Named Entity
Recognition (NER) models, these methods fail to generalize across formats and
contexts. Recent advances in Large Language Models (LLMs) offer a promising
alternative, yet the effect of architectural and training choices on redaction
performance remains underexplored. LLMs have demonstrated strong performance in
tasks that require contextual language understanding, including the redaction
of PII in free-form text. Prior work suggests that with appropriate adaptation,
LLMs can become effective contextual privacy learners. However, the
consequences of architectural and training choices for PII Redaction remain
underexplored. In this work, we present a comprehensive analysis of LLMs as
privacy-preserving PII Redaction systems. We evaluate a range of LLM
architectures and training strategies for their effectiveness in PII Redaction.
Our analysis measures redaction performance, semantic preservation, and PII
leakage, and compares these outcomes against latency and computational cost.
The results provide practical guidance for configuring LLM-based redactors that
are accurate, efficient, and privacy-aware. To support reproducibility and
real-world deployment, we release PRvL, an open-source suite of fine-tuned
models, and evaluation tools for general-purpose PII Redaction. PRvL is built
entirely on open-source LLMs and supports multiple inference settings for
flexibility and compliance. It is designed to be easily customized for
different domains and fully operable within secure, self-managed environments.
This enables data owners to perform redactions without relying on third-party
services or exposing sensitive content beyond their own infrastructure.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [23] [Prescriptive Agents based on Rag for Automated Maintenance (PARAM)](https://arxiv.org/abs/2508.04714)
*Chitranshu Harbola,Anupam Purwar*

Main category: cs.AI

TL;DR: 本文提出了一种基于大型语言模型（LLM）的智能系统，用于工业机械的预测性维护，结合振动频率分析和多代理生成技术，提供可操作的维护建议。


<details>
  <summary>Details</summary>
Motivation: 工业机械维护需要及时干预以防止灾难性故障并优化运行效率，传统方法仅能检测异常，缺乏具体维护建议。

Method: 系统将轴承振动数据（BPFO、BPFI、BSF、FTF频率）序列化为自然语言供LLM处理，结合多代理组件处理维护手册和网络搜索，生成结构化维护建议。

Result: 实验验证表明，系统能有效检测异常并提供上下文相关的维护指导。

Conclusion: 该系统填补了状态监测与可操作维护规划之间的空白，为工业维护提供了智能决策支持，扩展了LLM在工业领域的应用。

Abstract: Industrial machinery maintenance requires timely intervention to prevent
catastrophic failures and optimize operational efficiency. This paper presents
an integrated Large Language Model (LLM)-based intelligent system for
prescriptive maintenance that extends beyond traditional anomaly detection to
provide actionable maintenance recommendations. Building upon our prior LAMP
framework for numerical data analysis, we develop a comprehensive solution that
combines bearing vibration frequency analysis with multi agentic generation for
intelligent maintenance planning. Our approach serializes bearing vibration
data (BPFO, BPFI, BSF, FTF frequencies) into natural language for LLM
processing, enabling few-shot anomaly detection with high accuracy. The system
classifies fault types (inner race, outer race, ball/roller, cage faults) and
assesses severity levels. A multi-agentic component processes maintenance
manuals using vector embeddings and semantic search, while also conducting web
searches to retrieve comprehensive procedural knowledge and access up-to-date
maintenance practices for more accurate and in-depth recommendations. The
Gemini model then generates structured maintenance recommendations includes
immediate actions, inspection checklists, corrective measures, parts
requirements, and timeline specifications. Experimental validation in bearing
vibration datasets demonstrates effective anomaly detection and contextually
relevant maintenance guidance. The system successfully bridges the gap between
condition monitoring and actionable maintenance planning, providing industrial
practitioners with intelligent decision support. This work advances the
application of LLMs in industrial maintenance, offering a scalable framework
for prescriptive maintenance across machinery components and industrial
sectors.

</details>


### [24] [GeoFlow: Agentic Workflow Automation for Geospatial Tasks](https://arxiv.org/abs/2508.04719)
*Amulya Bhattaram,Justin Chung,Stanley Chung,Ranit Gupta,Janani Ramamoorthy,Kartikeya Gullapalli,Diana Marculescu,Dimitrios Stamoulis*

Main category: cs.AI

TL;DR: GeoFlow是一种自动生成地理空间任务代理工作流的方法，通过明确工具调用目标提升代理成功率并减少令牌使用。


<details>
  <summary>Details</summary>
Motivation: 现有方法在推理分解上较为关注，但API选择通常隐含，缺乏明确的工具调用指导。

Method: GeoFlow为每个代理提供详细的工具调用目标，以指导运行时地理空间API的调用。

Result: 与最先进方法相比，GeoFlow将代理成功率提高了6.8%，令牌使用量减少了四倍。

Conclusion: GeoFlow通过明确工具调用目标，显著提升了代理性能和效率。

Abstract: We present GeoFlow, a method that automatically generates agentic workflows
for geospatial tasks. Unlike prior work that focuses on reasoning decomposition
and leaves API selection implicit, our method provides each agent with detailed
tool-calling objectives to guide geospatial API invocation at runtime. GeoFlow
increases agentic success by 6.8% and reduces token usage by up to fourfold
across major LLM families compared to state-of-the-art approaches.

</details>


### [25] [Who is a Better Player: LLM against LLM](https://arxiv.org/abs/2508.04720)
*Yingjie Zhou,Jiezhang Cao,Farong Wen,Li Xu,Yanwei Jiang,Jun Jia,Ronghui Li,Xiaohong Liu,Yu Zhou,Xiongkuo Min,Jie Guo,Zicheng Zhang,Guangtao Zhai*

Main category: cs.AI

TL;DR: 论文提出了一种基于对抗性棋盘游戏的评估框架，用于全面评估大型语言模型（LLMs）的性能，弥补了主流问答基准方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 对抗性棋盘游戏是战略推理和智能的典型领域，可作为评估AI系统的基准。现有问答基准方法依赖数据，存在局限性。

Method: 提出Qi Town平台，支持5种游戏和20个LLM驱动的玩家，使用Elo评分系统和性能循环图（PLG）定量评估LLMs，并通过积极情绪分数（PSS）评估心理适应性。

Result: 实验表明，尽管技术差异大，多数LLMs在对抗环境中表现乐观且适应性优于人类，但PLG揭示了技能不稳定性。

Conclusion: 该框架有效评估LLMs性能，但LLMs在游戏中的技能不稳定性需进一步研究。

Abstract: Adversarial board games, as a paradigmatic domain of strategic reasoning and
intelligence, have long served as both a popular competitive activity and a
benchmark for evaluating artificial intelligence (AI) systems. Building on this
foundation, we propose an adversarial benchmarking framework to assess the
comprehensive performance of Large Language Models (LLMs) through board games
competition, compensating the limitation of data dependency of the mainstream
Question-and-Answer (Q&A) based benchmark method. We introduce Qi Town, a
specialized evaluation platform that supports 5 widely played games and
involves 20 LLM-driven players. The platform employs both the Elo rating system
and a novel Performance Loop Graph (PLG) to quantitatively evaluate the
technical capabilities of LLMs, while also capturing Positive Sentiment Score
(PSS) throughout gameplay to assess mental fitness. The evaluation is
structured as a round-robin tournament, enabling systematic comparison across
players. Experimental results indicate that, despite technical differences,
most LLMs remain optimistic about winning and losing, demonstrating greater
adaptability to high-stress adversarial environments than humans. On the other
hand, the complex relationship between cyclic wins and losses in PLGs exposes
the instability of LLMs' skill play during games, warranting further
explanation and exploration.

</details>


### [26] [Fine-Tuning Small Language Models (SLMs) for Autonomous Web-based Geographical Information Systems (AWebGIS)](https://arxiv.org/abs/2508.04846)
*Mahdi Nazari Ashani,Ali Asghar Alesheikh,Saba Kazemi,Kimya Kheirkhah,Yasin Mohammadi,Fatemeh Rezaie,Amir Mahdi Manafi,Hedieh Zarkesh*

Main category: cs.AI

TL;DR: 比较三种实现自主网络地理信息系统（AWebGIS）的方法，发现基于小型语言模型（SLM）的客户端方法在准确性和隐私保护方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于云的AWebGIS解决方案对互联网依赖性强、隐私和可扩展性差的问题。

Method: 比较三种方法：1）基于云的大型语言模型（LLM）；2）半自动离线方法（传统机器学习）；3）基于小型语言模型（SLM）的完全离线客户端方法。

Result: SLM方法准确率最高（精确匹配0.93，Levenshtein相似度0.99，ROUGE-1和ROUGE-L得分0.98），且减少服务器负载。

Conclusion: 客户端执行的SLM方法是AWebGIS的可行解决方案，兼顾高准确性和隐私保护。

Abstract: Autonomous web-based geographical information systems (AWebGIS) aim to
perform geospatial operations from natural language input, providing intuitive,
intelligent, and hands-free interaction. However, most current solutions rely
on cloud-based large language models (LLMs), which require continuous internet
access and raise users' privacy and scalability issues due to centralized
server processing. This study compares three approaches to enabling AWebGIS:
(1) a fully-automated online method using cloud-based LLMs (e.g., Cohere); (2)
a semi-automated offline method using classical machine learning classifiers
such as support vector machine and random forest; and (3) a fully autonomous
offline (client-side) method based on a fine-tuned small language model (SLM),
specifically T5-small model, executed in the client's web browser. The third
approach, which leverages SLMs, achieved the highest accuracy among all
methods, with an exact matching accuracy of 0.93, Levenshtein similarity of
0.99, and recall-oriented understudy for gisting evaluation ROUGE-1 and ROUGE-L
scores of 0.98. Crucially, this client-side computation strategy reduces the
load on backend servers by offloading processing to the user's device,
eliminating the need for server-based inference. These results highlight the
feasibility of browser-executable models for AWebGIS solutions.

</details>


### [27] [Large Language Models Reasoning Abilities Under Non-Ideal Conditions After RL-Fine-Tuning](https://arxiv.org/abs/2508.04848)
*Chang Tian,Matthew B. Blaschko,Mingzhe Xing,Xiuxing Li,Yinliang Yue,Marie-Francine Moens*

Main category: cs.AI

TL;DR: 强化学习（RL）用于提升大语言模型（LLMs）的推理能力，但现有基准测试多基于理想场景。研究提出三种非理想场景，发现RL微调在非理想场景下性能显著下降，揭示当前方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试忽略了大语言模型在非理想场景下的推理能力，研究旨在填补这一空白，并基于脑科学发现提出新研究方向。

Method: 研究定义了三种非理想场景，使用RL微调三种LLMs和一种大型视觉语言模型（LVLM），并在八个公共数据集上测试性能。

Result: RL微调在理想场景下提升推理能力，但在非理想场景中性能显著下降，现有方法未能有效解决这些缺陷。

Conclusion: 大模型的推理能力常被高估，非理想场景下的评估至关重要，研究呼吁更多关注此类场景。

Abstract: Reinforcement learning (RL) has become a key technique for enhancing the
reasoning abilities of large language models (LLMs), with policy-gradient
algorithms dominating the post-training stage because of their efficiency and
effectiveness. However, most existing benchmarks evaluate large-language-model
reasoning under idealized settings, overlooking performance in realistic,
non-ideal scenarios. We identify three representative non-ideal scenarios with
practical relevance: summary inference, fine-grained noise suppression, and
contextual filtering. We introduce a new research direction guided by
brain-science findings that human reasoning remains reliable under imperfect
inputs. We formally define and evaluate these challenging scenarios. We
fine-tune three LLMs and a state-of-the-art large vision-language model (LVLM)
using RL with a representative policy-gradient algorithm and then test their
performance on eight public datasets. Our results reveal that while RL
fine-tuning improves baseline reasoning under idealized settings, performance
declines significantly across all three non-ideal scenarios, exposing critical
limitations in advanced reasoning capabilities. Although we propose a
scenario-specific remediation method, our results suggest current methods leave
these reasoning deficits largely unresolved. This work highlights that the
reasoning abilities of large models are often overstated and underscores the
importance of evaluating models under non-ideal scenarios. The code and data
will be released at XXXX.

</details>


### [28] [ConfAgents: A Conformal-Guided Multi-Agent Framework for Cost-Efficient Medical Diagnosis](https://arxiv.org/abs/2508.04915)
*Huiya Zhao,Yinghao Zhu,Zixiang Wang,Yasha Wang,Junyi Gao,Liantao Ma*

Main category: cs.AI

TL;DR: HealthFlow是一种自我进化的AI代理，通过元级进化机制提升策略规划能力，显著优于现有框架。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理在医疗研究中依赖静态策略，无法成为更好的策略规划者，限制了其效能。

Method: 引入HealthFlow，通过元级进化机制自主优化高层问题解决策略，并开发EHRFlowBench基准进行评价。

Result: 实验表明HealthFlow显著优于现有代理框架。

Conclusion: 研究标志着从工具使用者向自我进化任务管理者的转变，为更自主的AI科学发现铺路。

Abstract: The efficacy of AI agents in healthcare research is hindered by their
reliance on static, predefined strategies. This creates a critical limitation:
agents can become better tool-users but cannot learn to become better strategic
planners, a crucial skill for complex domains like healthcare. We introduce
HealthFlow, a self-evolving AI agent that overcomes this limitation through a
novel meta-level evolution mechanism. HealthFlow autonomously refines its own
high-level problem-solving policies by distilling procedural successes and
failures into a durable, strategic knowledge base. To anchor our research and
facilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark
featuring complex, realistic health data analysis tasks derived from
peer-reviewed clinical research. Our comprehensive experiments demonstrate that
HealthFlow's self-evolving approach significantly outperforms state-of-the-art
agent frameworks. This work marks a necessary shift from building better
tool-users to designing smarter, self-evolving task-managers, paving the way
for more autonomous and effective AI for scientific discovery.

</details>


### [29] [The Docking Game: Loop Self-Play for Fast, Dynamic, and Accurate Prediction of Flexible Protein--Ligand Binding](https://arxiv.org/abs/2508.05006)
*Youzhi Zhang,Yufei Li,Gaofeng Meng,Hongbin Liu,Jiebo Luo*

Main category: cs.AI

TL;DR: 提出了一种基于博弈论的新型分子对接框架（Docking Game），通过LoopPlay算法显著提升了对接准确性。


<details>
  <summary>Details</summary>
Motivation: 现有多任务学习模型在配体对接中表现不佳，主要由于配体和蛋白质结构复杂性差异。

Method: 将蛋白-配体交互建模为双玩家博弈，开发LoopPlay算法，通过内外循环交替训练玩家。

Result: 在公开数据集上，LoopPlay比现有方法提升约10%的准确率。

Conclusion: LoopPlay有望提升药物发现中分子对接的准确性。

Abstract: Molecular docking is a crucial aspect of drug discovery, as it predicts the
binding interactions between small-molecule ligands and protein pockets.
However, current multi-task learning models for docking often show inferior
performance in ligand docking compared to protein pocket docking. This
disparity arises largely due to the distinct structural complexities of ligands
and proteins. To address this issue, we propose a novel game-theoretic
framework that models the protein-ligand interaction as a two-player game
called the Docking Game, with the ligand docking module acting as the ligand
player and the protein pocket docking module as the protein player. To solve
this game, we develop a novel Loop Self-Play (LoopPlay) algorithm, which
alternately trains these players through a two-level loop. In the outer loop,
the players exchange predicted poses, allowing each to incorporate the other's
structural predictions, which fosters mutual adaptation over multiple
iterations. In the inner loop, each player dynamically refines its predictions
by incorporating its own predicted ligand or pocket poses back into its model.
We theoretically show the convergence of LoopPlay, ensuring stable
optimization. Extensive experiments conducted on public benchmark datasets
demonstrate that LoopPlay achieves approximately a 10\% improvement in
predicting accurate binding modes compared to previous state-of-the-art
methods. This highlights its potential to enhance the accuracy of molecular
docking in drug discovery.

</details>


### [30] [Can Large Language Models Integrate Spatial Data? Empirical Insights into Reasoning Strengths and Computational Weaknesses](https://arxiv.org/abs/2508.05009)
*Bin Han,Robert Wolfe,Anat Caspi,Bill Howe*

Main category: cs.AI

TL;DR: 该论文探讨了利用大型语言模型（LLMs）整合异构城市空间数据的潜力，发现LLMs在空间推理方面存在局限，但通过特征优化和迭代修正方法能显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统规则方法和机器学习在整合城市空间数据时存在不足，LLMs因其灵活性和适应性成为潜在替代方案。

Method: 研究分析了LLMs的空间推理能力，提出特征优化和迭代修正方法（review-and-refine）以提升性能。

Result: LLMs在减少对空间推理依赖的情况下表现优异，迭代修正方法能有效纠正错误并保留正确结果。

Conclusion: LLMs为城市空间数据整合提供了灵活且高效的解决方案，未来可结合多模态方法和多样化数据格式支持进一步优化。

Abstract: We explore the application of large language models (LLMs) to empower domain
experts in integrating large, heterogeneous, and noisy urban spatial datasets.
Traditional rule-based integration methods are unable to cover all edge cases,
requiring manual verification and repair. Machine learning approaches require
collecting and labeling of large numbers of task-specific samples. In this
study, we investigate the potential of LLMs for spatial data integration. Our
analysis first considers how LLMs reason about environmental spatial
relationships mediated by human experience, such as between roads and
sidewalks. We show that while LLMs exhibit spatial reasoning capabilities, they
struggle to connect the macro-scale environment with the relevant computational
geometry tasks, often producing logically incoherent responses. But when
provided relevant features, thereby reducing dependence on spatial reasoning,
LLMs are able to generate high-performing results. We then adapt a
review-and-refine method, which proves remarkably effective in correcting
erroneous initial responses while preserving accurate responses. We discuss
practical implications of employing LLMs for spatial data integration in
real-world contexts and outline future research directions, including
post-training, multi-modal integration methods, and support for diverse data
formats. Our findings position LLMs as a promising and flexible alternative to
traditional rule-based heuristics, advancing the capabilities of adaptive
spatial data integration.

</details>


### [31] [Cognitive Duality for Adaptive Web Agents](https://arxiv.org/abs/2508.05081)
*Jiarun Liu,Chunhong Zhang,Zheng Hu*

Main category: cs.AI

TL;DR: 论文提出了一种结合离线模仿学习和在线探索的Web导航智能体框架CogniWeb，基于人类认知的双系统理论，实现了高效且性能优异的导航。


<details>
  <summary>Details</summary>
Motivation: 当前Web导航智能体方法未能有效整合离线学习和在线探索，而人类认知的双系统理论为解决这一问题提供了灵感。

Method: 提出CogniWeb框架，将认知分解为快速直觉（System 1）和慢速推理（System 2）过程，并根据任务复杂度自适应切换。

Result: 在WebArena上评估，CogniWeb实现了43.96%的成功率，同时显著提高了效率（减少75%的token使用）。

Conclusion: CogniWeb通过结合双系统认知理论，为Web导航智能体提供了一种高效且性能优异的解决方案。

Abstract: Web navigation represents a critical and challenging domain for evaluating
artificial general intelligence (AGI), demanding complex decision-making within
high-entropy, dynamic environments with combinatorially explosive action
spaces. Current approaches to building autonomous web agents either focus on
offline imitation learning or online exploration, but rarely integrate both
paradigms effectively. Inspired by the dual-process theory of human cognition,
we derive a principled decomposition into fast System 1 and slow System 2
cognitive processes. This decomposition provides a unifying perspective on
existing web agent methodologies, bridging the gap between offline learning of
intuitive reactive behaviors and online acquisition of deliberative planning
capabilities. We implement this framework in CogniWeb, a modular agent
architecture that adaptively toggles between fast intuitive processing and
deliberate reasoning based on task complexity. Our evaluation on WebArena
demonstrates that CogniWeb achieves competitive performance (43.96% success
rate) while maintaining significantly higher efficiency (75% reduction in token
usage).

</details>


### [32] [MedMKEB: A Comprehensive Knowledge Editing Benchmark for Medical Multimodal Large Language Models](https://arxiv.org/abs/2508.05083)
*Dexuan Xu,Jieyi Wang,Zhongyan Chai,Yongzhi Cao,Hanpin Wang,Huamin Zhang,Yu Huang*

Main category: cs.AI

TL;DR: MedMKEB是首个用于评估医疗多模态大语言模型知识编辑能力的综合基准，填补了该领域的空白。


<details>
  <summary>Details</summary>
Motivation: 医疗知识不断更新，需要高效编辑模型中的过时或错误信息，而现有研究缺乏针对多模态医疗知识编辑的系统性基准。

Method: 基于高质量医疗视觉问答数据集，设计包括反事实修正、语义泛化、知识迁移和对抗鲁棒性等编辑任务，并引入专家验证。

Result: 实验表明现有知识编辑方法在医疗领域存在局限性，需开发专门策略。

Conclusion: MedMKEB将作为标准基准，推动可信且高效的医疗知识编辑算法发展。

Abstract: Recent advances in multimodal large language models (MLLMs) have
significantly improved medical AI, enabling it to unify the understanding of
visual and textual information. However, as medical knowledge continues to
evolve, it is critical to allow these models to efficiently update outdated or
incorrect information without retraining from scratch. Although textual
knowledge editing has been widely studied, there is still a lack of systematic
benchmarks for multimodal medical knowledge editing involving image and text
modalities. To fill this gap, we present MedMKEB, the first comprehensive
benchmark designed to evaluate the reliability, generality, locality,
portability, and robustness of knowledge editing in medical multimodal large
language models. MedMKEB is built on a high-quality medical visual
question-answering dataset and enriched with carefully constructed editing
tasks, including counterfactual correction, semantic generalization, knowledge
transfer, and adversarial robustness. We incorporate human expert validation to
ensure the accuracy and reliability of the benchmark. Extensive single editing
and sequential editing experiments on state-of-the-art general and medical
MLLMs demonstrate the limitations of existing knowledge-based editing
approaches in medicine, highlighting the need to develop specialized editing
strategies. MedMKEB will serve as a standard benchmark to promote the
development of trustworthy and efficient medical knowledge editing algorithms.

</details>


### [33] [EasySize: Elastic Analog Circuit Sizing via LLM-Guided Heuristic Search](https://arxiv.org/abs/2508.05113)
*Xinyue Wu,Fan Hu,Shaik Jani Babu,Yi Zhao,Xinfei Guo*

Main category: cs.AI

TL;DR: EasySize是一个基于微调Qwen3-8B模型的轻量级门尺寸框架，适用于不同工艺节点、设计规范和电路拓扑，显著减少了对人力和计算资源的依赖。


<details>
  <summary>Details</summary>
Motivation: 模拟电路设计耗时且依赖经验，现有AI方法通用性差且计算资源需求高。

Method: 结合动态任务特定损失函数和全局差分进化（DE）与局部粒子群优化（PSO）的启发式搜索。

Result: 在未针对特定工艺节点训练的情况下，EasySize在多个技术节点上表现优异，并显著减少仿真资源。

Conclusion: EasySize能加速和简化模拟电路设计，减少对人力和计算资源的依赖。

Abstract: Analog circuit design is a time-consuming, experience-driven task in chip
development. Despite advances in AI, developing universal, fast, and stable
gate sizing methods for analog circuits remains a significant challenge. Recent
approaches combine Large Language Models (LLMs) with heuristic search
techniques to enhance generalizability, but they often depend on large model
sizes and lack portability across different technology nodes. To overcome these
limitations, we propose EasySize, the first lightweight gate sizing framework
based on a finetuned Qwen3-8B model, designed for universal applicability
across process nodes, design specifications, and circuit topologies. EasySize
exploits the varying Ease of Attainability (EOA) of performance metrics to
dynamically construct task-specific loss functions, enabling efficient
heuristic search through global Differential Evolution (DE) and local Particle
Swarm Optimization (PSO) within a feedback-enhanced flow. Although finetuned
solely on 350nm node data, EasySize achieves strong performance on 5
operational amplifier (Op-Amp) netlists across 180nm, 45nm, and 22nm technology
nodes without additional targeted training, and outperforms AutoCkt, a
widely-used Reinforcement Learning based sizing framework, on 86.67\% of tasks
with more than 96.67\% of simulation resources reduction. We argue that
EasySize can significantly reduce the reliance on human expertise and
computational resources in gate sizing, thereby accelerating and simplifying
the analog circuit design process. EasySize will be open-sourced at a later
date.

</details>


### [34] [Beyond Automation: Socratic AI, Epistemic Agency, and the Implications of the Emergence of Orchestrated Multi-Agent Learning Architectures](https://arxiv.org/abs/2508.05116)
*Peer-Benedikt Degen,Igor Asanov*

Main category: cs.AI

TL;DR: 论文探讨了生成式AI在高等教育中的核心作用，通过实验验证了苏格拉底式AI导师对学生批判性思维的促进作用，并提出了模块化多代理系统的概念。


<details>
  <summary>Details</summary>
Motivation: 研究生成式AI如何从边缘工具发展为重塑知识生成与验证的基础设施，并探索其在教育中的潜力。

Method: 通过对照实验，比较苏格拉底式AI导师与普通AI聊天机器人在65名德国师范生中的效果。

Result: 使用苏格拉底式AI导师的学生在批判性、独立性和反思性思维方面显著提升。

Conclusion: 研究为混合学习生态系统提供了实证和概念框架，强调人机协作与教学一致性。

Abstract: Generative AI is no longer a peripheral tool in higher education. It is
rapidly evolving into a general-purpose infrastructure that reshapes how
knowledge is generated, mediated, and validated. This paper presents findings
from a controlled experiment evaluating a Socratic AI Tutor, a large language
model designed to scaffold student research question development through
structured dialogue grounded in constructivist theory. Conducted with 65
pre-service teacher students in Germany, the study compares interaction with
the Socratic Tutor to engagement with an uninstructed AI chatbot. Students
using the Socratic Tutor reported significantly greater support for critical,
independent, and reflective thinking, suggesting that dialogic AI can stimulate
metacognitive engagement and challenging recent narratives of de-skilling due
to generative AI usage. These findings serve as a proof of concept for a
broader pedagogical shift: the use of multi-agent systems (MAS) composed of
specialised AI agents. To conceptualise this, we introduce the notion of
orchestrated MAS, modular, pedagogically aligned agent constellations, curated
by educators, that support diverse learning trajectories through differentiated
roles and coordinated interaction. To anchor this shift, we propose an adapted
offer-and-use model, in which students appropriate instructional offers from
these agents. Beyond technical feasibility, we examine system-level
implications for higher education institutions and students, including funding
necessities, changes to faculty roles, curriculars, competencies and assessment
practices. We conclude with a comparative cost-effectiveness analysis
highlighting the scalability of such systems. In sum, this study contributes
both empirical evidence and a conceptual roadmap for hybrid learning ecosystems
that embed human-AI co-agency and pedagogical alignment.

</details>


### [35] [Graph-based Event Log Repair](https://arxiv.org/abs/2508.05145)
*Sebastiano Dissegna,Chiara Di Francescomarino,Massimiliano Ronzani*

Main category: cs.AI

TL;DR: 论文提出了一种基于异构图神经网络（HGNN）的方法，用于修复事件日志中的缺失属性，相比现有方法表现更优。


<details>
  <summary>Details</summary>
Motivation: 现实世界的事件日志常因数据采集问题导致信息缺失，现有方法（如基于流程模型或机器学习）存在局限性，需要更自然且表达能力强的解决方案。

Method: 开发了一种异构图神经网络模型，能够处理复杂多模态序列（如事件日志），修复事件中的缺失属性。

Result: 在两个合成日志和四个真实日志上评估，相比基于自动编码器的现有方法，新方法在修复所有事件属性方面表现优异。

Conclusion: 异构图神经网络为事件日志修复提供了更有效的方法，尤其在处理多属性缺失时表现突出。

Abstract: The quality of event logs in Process Mining is crucial when applying any form
of analysis to them. In real-world event logs, the acquisition of data can be
non-trivial (e.g., due to the execution of manual activities and related manual
recording or to issues in collecting, for each event, all its attributes), and
often may end up with events recorded with some missing information. Standard
approaches to the problem of trace (or log) reconstruction either require the
availability of a process model that is used to fill missing values by
leveraging different reasoning techniques or employ a Machine Learning/Deep
Learning model to restore the missing values by learning from similar cases. In
recent years, a new type of Deep Learning model that is capable of handling
input data encoded as graphs has emerged, namely Graph Neural Networks. Graph
Neural Network models, and even more so Heterogeneous Graph Neural Networks,
offer the advantage of working with a more natural representation of complex
multi-modal sequences like the execution traces in Process Mining, allowing for
more expressive and semantically rich encodings.
  In this work, we focus on the development of a Heterogeneous Graph Neural
Network model that, given a trace containing some incomplete events, will
return the full set of attributes missing from those events. We evaluate our
work against a state-of-the-art approach leveraging autoencoders on two
synthetic logs and four real event logs, on different types of missing values.
Different from state-of-the-art model-free approaches, which mainly focus on
repairing a subset of event attributes, the proposed approach shows very good
performance in reconstructing all different event attributes.

</details>


### [36] [QA-Dragon: Query-Aware Dynamic RAG System for Knowledge-Intensive Visual Question Answering](https://arxiv.org/abs/2508.05197)
*Zhuohang Jiang,Pangjing Wu,Xu Yuan,Wenqi Fan,Qing Li*

Main category: cs.AI

TL;DR: QA-Dragon提出了一种动态RAG系统，通过多模态检索和路由机制提升复杂VQA任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法在文本或图像检索上孤立操作，难以处理需要多跳推理或最新知识的复杂查询。

Method: QA-Dragon引入领域路由器和搜索路由器，动态选择检索策略，支持多模态、多轮和多跳推理。

Result: 在Meta CRAG-MM挑战中，QA-Dragon显著提升性能，单源、多源和多轮任务分别优于基线5.06%、6.35%和5.03%。

Conclusion: QA-Dragon通过动态多模态检索和路由机制，有效解决了复杂VQA任务中的知识获取和推理问题。

Abstract: Retrieval-Augmented Generation (RAG) has been introduced to mitigate
hallucinations in Multimodal Large Language Models (MLLMs) by incorporating
external knowledge into the generation process, and it has become a widely
adopted approach for knowledge-intensive Visual Question Answering (VQA).
However, existing RAG methods typically retrieve from either text or images in
isolation, limiting their ability to address complex queries that require
multi-hop reasoning or up-to-date factual knowledge. To address this
limitation, we propose QA-Dragon, a Query-Aware Dynamic RAG System for
Knowledge-Intensive VQA. Specifically, QA-Dragon introduces a domain router to
identify the query's subject domain for domain-specific reasoning, along with a
search router that dynamically selects optimal retrieval strategies. By
orchestrating both text and image search agents in a hybrid setup, our system
supports multimodal, multi-turn, and multi-hop reasoning, enabling it to tackle
complex VQA tasks effectively. We evaluate our QA-Dragon on the Meta CRAG-MM
Challenge at KDD Cup 2025, where it significantly enhances the reasoning
performance of base models under challenging scenarios. Our framework achieves
substantial improvements in both answer accuracy and knowledge overlap scores,
outperforming baselines by 5.06% on the single-source task, 6.35% on the
multi-source task, and 5.03% on the multi-turn task.

</details>


### [37] [An Explainable Natural Language Framework for Identifying and Notifying Target Audiences In Enterprise Communication](https://arxiv.org/abs/2508.05267)
*Vítor N. Lourenço,Mohnish Dubey,Yunfei Bai,Audrey Depeige,Vivek Jain*

Main category: cs.AI

TL;DR: 提出了一种结合RDF图数据库和LLMs的新框架，用于解决大规模维护组织中专家识别和复杂实体关系通信管理的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统通信方法无法有效应对信息过载和响应时间延长的问题。

Method: 结合RDF图数据库和LLMs，通过规划-编排架构处理自然语言查询，实现精确受众定位和透明推理。

Result: 系统支持直观查询，提供可解释的结果，提升组织内通信效率并保持信任。

Conclusion: 该框架有效解决了大规模维护组织中的通信管理问题。

Abstract: In large-scale maintenance organizations, identifying subject matter experts
and managing communications across complex entities relationships poses
significant challenges -- including information overload and longer response
times -- that traditional communication approaches fail to address effectively.
We propose a novel framework that combines RDF graph databases with LLMs to
process natural language queries for precise audience targeting, while
providing transparent reasoning through a planning-orchestration architecture.
Our solution enables communication owners to formulate intuitive queries
combining concepts such as equipment, manufacturers, maintenance engineers, and
facilities, delivering explainable results that maintain trust in the system
while improving communication efficiency across the organization.

</details>


### [38] [A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents](https://arxiv.org/abs/2508.05311)
*Andrew Kiruluta*

Main category: cs.AI

TL;DR: 提出了一种混合架构，将基于决策树的符号推理与大型语言模型（LLMs）的生成能力结合，通过多智能体框架实现协调推理。


<details>
  <summary>Details</summary>
Motivation: 现有方法松散耦合符号与神经模块，缺乏统一性，新设计旨在通过嵌入决策树和随机森林作为可调用预言机，实现更紧密的集成。

Method: 在统一推理系统中嵌入决策树和随机森林作为预言机，LLM智能体处理溯因推理和规划，中央协调器维护状态一致性。

Result: 在ProofWriter、GSM8k和ARC等基准测试中表现优异，准确率提升5.3%至7.2%，并在临床决策和科学发现中验证了实用性。

Conclusion: 该架构为通用神经符号推理提供了鲁棒、可解释且可扩展的解决方案。

Abstract: We propose a hybrid architecture that integrates decision tree-based symbolic
reasoning with the generative capabilities of large language models (LLMs)
within a coordinated multi-agent framework. Unlike prior approaches that
loosely couple symbolic and neural modules, our design embeds decision trees
and random forests as callable oracles within a unified reasoning system.
Tree-based modules enable interpretable rule inference and causal logic, while
LLM agents handle abductive reasoning, generalization, and interactive
planning. A central orchestrator maintains belief state consistency and
mediates communication across agents and external tools, enabling reasoning
over both structured and unstructured inputs.
  The system achieves strong performance on reasoning benchmarks. On
\textit{ProofWriter}, it improves entailment consistency by +7.2\% through
logic-grounded tree validation. On GSM8k, it achieves +5.3\% accuracy gains in
multistep mathematical problems via symbolic augmentation. On \textit{ARC}, it
boosts abstraction accuracy by +6.0\% through integration of symbolic oracles.
Applications in clinical decision support and scientific discovery show how the
system encodes domain rules symbolically while leveraging LLMs for contextual
inference and hypothesis generation. This architecture offers a robust,
interpretable, and extensible solution for general-purpose neuro-symbolic
reasoning.

</details>


### [39] [The Term 'Agent' Has Been Diluted Beyond Utility and Requires Redefinition](https://arxiv.org/abs/2508.05338)
*Brinnae Bent*

Main category: cs.AI

TL;DR: 本文主张重新定义AI中的'agent'一词，提出一个多维框架以明确其最低要求，并建议标准化术语以提升研究清晰度和政策制定效果。


<details>
  <summary>Details</summary>
Motivation: 由于AI能力的快速发展，特别是大语言模型系统，'agent'一词的含义变得模糊，影响了研究交流、系统评估和政策制定。

Method: 通过历史分析和当代使用模式，提出一个多维框架，定义'agent'的最低要求，并探讨其在不同维度上的表现。

Result: 提出了一个清晰的'agent'定义框架，并提供了标准化术语和框架采纳的具体建议。

Conclusion: 该框架为研究清晰度和政策制定提供了实用工具，同时保留了术语的历史多样性。

Abstract: The term 'agent' in artificial intelligence has long carried multiple
interpretations across different subfields. Recent developments in AI
capabilities, particularly in large language model systems, have amplified this
ambiguity, creating significant challenges in research communication, system
evaluation and reproducibility, and policy development. This paper argues that
the term 'agent' requires redefinition. Drawing from historical analysis and
contemporary usage patterns, we propose a framework that defines clear minimum
requirements for a system to be considered an agent while characterizing
systems along a multidimensional spectrum of environmental interaction,
learning and adaptation, autonomy, goal complexity, and temporal coherence.
This approach provides precise vocabulary for system description while
preserving the term's historically multifaceted nature. After examining
potential counterarguments and implementation challenges, we provide specific
recommendations for moving forward as a field, including suggestions for
terminology standardization and framework adoption. The proposed approach
offers practical tools for improving research clarity and reproducibility while
supporting more effective policy development.

</details>


### [40] [NomicLaw: Emergent Trust and Strategic Argumentation in LLMs During Collaborative Law-Making](https://arxiv.org/abs/2508.05344)
*Asutosh Hota,Jussi P. P. Jokinen*

Main category: cs.AI

TL;DR: NomicLaw是一个多智能体模拟框架，用于研究LLMs在开放式法律和伦理困境中的行为，通过协作立法、投票和策略性语言使用来评估其社会推理能力。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在开放式多智能体环境中处理法律和伦理问题的能力，填补现有研究的空白。

Method: 设计NomicLaw模拟框架，让LLMs协作制定法律规则，通过投票和语言分析量化信任和互惠行为。

Result: 实验显示LLMs能自发形成联盟、背叛信任，并通过策略性语言影响集体决策，展示了其社会推理和说服能力。

Conclusion: 研究揭示了开源LLMs的潜在社会能力，为未来AI系统在自主协商和立法设计中的应用提供了启示。

Abstract: Recent advancements in large language models (LLMs) have extended their
capabilities from basic text processing to complex reasoning tasks, including
legal interpretation, argumentation, and strategic interaction. However,
empirical understanding of LLM behavior in open-ended, multi-agent settings
especially those involving deliberation over legal and ethical dilemmas remains
limited. We introduce NomicLaw, a structured multi-agent simulation where LLMs
engage in collaborative law-making, responding to complex legal vignettes by
proposing rules, justifying them, and voting on peer proposals. We
quantitatively measure trust and reciprocity via voting patterns and
qualitatively assess how agents use strategic language to justify proposals and
influence outcomes. Experiments involving homogeneous and heterogeneous LLM
groups demonstrate how agents spontaneously form alliances, betray trust, and
adapt their rhetoric to shape collective decisions. Our results highlight the
latent social reasoning and persuasive capabilities of ten open-source LLMs and
provide insights into the design of future AI systems capable of autonomous
negotiation, coordination and drafting legislation in legal settings.

</details>


### [41] [Minimal Model Reasoning in Description Logics: Don't Try This at Home!](https://arxiv.org/abs/2508.05350)
*Federica Di Stefano,Quentin Manière,Magdalena Ortiz,Mantas Šimkus*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Reasoning with minimal models has always been at the core of many knowledge
representation techniques, but we still have only a limited understanding of
this problem in Description Logics (DLs). Minimization of some selected
predicates, letting the remaining predicates vary or be fixed, as proposed in
circumscription, has been explored and exhibits high complexity. The case of
`pure' minimal models, where the extension of all predicates must be minimal,
has remained largely uncharted. We address this problem in popular DLs and
obtain surprisingly negative results: concept satisfiability in minimal models
is undecidable already for $\mathcal{EL}$. This undecidability also extends to
a very restricted fragment of tuple-generating dependencies. To regain
decidability, we impose acyclicity conditions on the TBox that bring the
worst-case complexity below double exponential time and allow us to establish a
connection with the recently studied pointwise circumscription; we also derive
results in data complexity. We conclude with a brief excursion to the DL-Lite
family, where a positive result was known for DL-Lite$_{\text{core}}$, but our
investigation establishes ExpSpace-hardness already for its extension
DL-Lite$_{\text{horn}}$.

</details>


### [42] [StructVRM: Aligning Multimodal Reasoning with Structured and Verifiable Reward Models](https://arxiv.org/abs/2508.05383)
*Xiangxiang Zhang,Jingxuan Wei,Donghong Zhong,Qi Chen,Caijun Jia,Cheng Tan,Jinming Gu,Xiaobo Qin,Zhiping Liu,Liang Hu,Tong Sun,Yuchen Wu,Zewei Sun,Chenwei Lou,Hua Zheng,Tianyang Zhan,Changbao Wang,Shuangzhi Wu,Zefa Lin,Chang Guo,Sihang Yuan,Riwei Chen,Shixiong Zhao,Yingping Zhang,Gaowei Wu,Bihui Yu,Jiahui Wu,Zhehui Zhao,Qianqian Liu,Ruofeng Tang,Xingyue Huang,Bing Zhao,Mengyang Zhang,Youqiang Zhou*

Main category: cs.AI

TL;DR: StructVRM提出了一种基于结构化可验证奖励模型的方法，用于改进视觉语言模型在复杂多问题推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 传统奖励机制仅提供整体二元评分，无法处理复杂任务中的部分正确性，限制了模型的学习效果。

Method: StructVRM通过训练模型验证器，提供细粒度的子问题级反馈，评估语义和数学等价性，而非严格的字符串匹配。

Result: Seed-StructVRM在12个多模态基准测试中的6个以及新构建的高难度STEM-Bench上达到最优性能。

Conclusion: 结构化可验证奖励训练是提升多模态模型在复杂推理任务中能力的有效方法。

Abstract: Existing Vision-Language Models often struggle with complex, multi-question
reasoning tasks where partial correctness is crucial for effective learning.
Traditional reward mechanisms, which provide a single binary score for an
entire response, are too coarse to guide models through intricate problems with
multiple sub-parts. To address this, we introduce StructVRM, a method that
aligns multimodal reasoning with Structured and Verifiable Reward Models. At
its core is a model-based verifier trained to provide fine-grained,
sub-question-level feedback, assessing semantic and mathematical equivalence
rather than relying on rigid string matching. This allows for nuanced, partial
credit scoring in previously intractable problem formats. Extensive experiments
demonstrate the effectiveness of StructVRM. Our trained model, Seed-StructVRM,
achieves state-of-the-art performance on six out of twelve public multimodal
benchmarks and our newly curated, high-difficulty STEM-Bench. The success of
StructVRM validates that training with structured, verifiable rewards is a
highly effective approach for advancing the capabilities of multimodal models
in complex, real-world reasoning domains.

</details>


### [43] [An Explainable Machine Learning Framework for Railway Predictive Maintenance using Data Streams from the Metro Operator of Portugal](https://arxiv.org/abs/2508.05388)
*Silvia García-Méndez,Francisco de Arriba-Pérez,Fátima Leal,Bruno Veloso,Benedita Malheiro,Juan Carlos Burguillo-Rial*

Main category: cs.AI

TL;DR: 提出了一种实时数据驱动的预测性维护方法，用于智能交通系统，结合样本预处理、增量分类和解释性模块，实验结果显示高准确性和实用性。


<details>
  <summary>Details</summary>
Motivation: 为智能交通系统提供实时、高精度的故障预测，以支持主动维护决策，提高服务可用性和安全性。

Method: 采用包含样本预处理、增量分类和解释性模块的在线处理流程，利用统计和频率相关特征进行实时分析。

Result: 在MetroPT数据集上，F-measure超过98%，准确率达到99%，且在类别不平衡和噪声下表现稳定。

Conclusion: 该方法在铁路预测性维护中具有实际应用价值，能有效识别早期故障迹象并支持快速决策。

Abstract: This work contributes to a real-time data-driven predictive maintenance
solution for Intelligent Transportation Systems. The proposed method implements
a processing pipeline comprised of sample pre-processing, incremental
classification with Machine Learning models, and outcome explanation. This
novel online processing pipeline has two main highlights: (i) a dedicated
sample pre-processing module, which builds statistical and frequency-related
features on the fly, and (ii) an explainability module. This work is the first
to perform online fault prediction with natural language and visual
explainability. The experiments were performed with the MetroPT data set from
the metro operator of Porto, Portugal. The results are above 98 % for F-measure
and 99 % for accuracy. In the context of railway predictive maintenance,
achieving these high values is crucial due to the practical and operational
implications of accurate failure prediction. In the specific case of a high
F-measure, this ensures that the system maintains an optimal balance between
detecting the highest possible number of real faults and minimizing false
alarms, which is crucial for maximizing service availability. Furthermore, the
accuracy obtained enables reliability, directly impacting cost reduction and
increased safety. The analysis demonstrates that the pipeline maintains high
performance even in the presence of class imbalance and noise, and its
explanations effectively reflect the decision-making process. These findings
validate the methodological soundness of the approach and confirm its practical
applicability for supporting proactive maintenance decisions in real-world
railway operations. Therefore, by identifying the early signs of failure, this
pipeline enables decision-makers to understand the underlying problems and act
accordingly swiftly.

</details>


### [44] [DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning](https://arxiv.org/abs/2508.05405)
*Xinrun Xu,Pi Bu,Ye Wang,Börje F. Karlsson,Ziming Wang,Tengtao Song,Qi Zhu,Jun Song,Zhiming Ding,Bo Zheng*

Main category: cs.AI

TL;DR: DeepPHY是一个新的基准框架，用于评估视觉语言模型（VLMs）对物理原则的理解和推理能力，发现现有模型在复杂动态环境中的表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有VLMs在细节关注和精确行动规划方面表现不足，尤其在复杂动态环境中，需要更系统的评估方法。

Method: 提出DeepPHY框架，通过多难度物理推理环境和细粒度评估指标，系统测试VLMs的物理理解和推理能力。

Result: 评估显示，即使最先进的VLMs也难以将描述性物理知识转化为精确的预测控制。

Conclusion: DeepPHY为VLMs的物理推理能力提供了系统性评估，揭示了现有模型的局限性。

Abstract: Although Vision Language Models (VLMs) exhibit strong perceptual abilities
and impressive visual reasoning, they struggle with attention to detail and
precise action planning in complex, dynamic environments, leading to subpar
performance. Real-world tasks typically require complex interactions, advanced
spatial reasoning, long-term planning, and continuous strategy refinement,
usually necessitating understanding the physics rules of the target scenario.
However, evaluating these capabilities in real-world scenarios is often
prohibitively expensive. To bridge this gap, we introduce DeepPHY, a novel
benchmark framework designed to systematically evaluate VLMs' understanding and
reasoning about fundamental physical principles through a series of challenging
simulated environments. DeepPHY integrates multiple physical reasoning
environments of varying difficulty levels and incorporates fine-grained
evaluation metrics. Our evaluation finds that even state-of-the-art VLMs
struggle to translate descriptive physical knowledge into precise, predictive
control.

</details>


### [45] [Large Language Models Transform Organic Synthesis From Reaction Prediction to Automation](https://arxiv.org/abs/2508.05427)
*Kartar Kumar Lohana Tharwani,Rajesh Kumar,Sumita,Numan Ahmed,Yong Tang*

Main category: cs.AI

TL;DR: LLMs正在改变有机合成中反应的设计与执行方式，结合图神经网络等技术加速发现周期，但需解决数据偏见等问题。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs如何从理论工具发展为实用的实验室助手，以推动更快、更环保的化学研究。

Method: 结合LLMs与图神经网络、量子计算和实时光谱技术，优化合成路线和反应预测。

Result: LLMs显著缩短发现周期，支持数据驱动的绿色化学，但仍存在数据偏见和安全性问题。

Conclusion: 通过开放基准和可解释界面等社区倡议，实现AI驱动的快速、可靠且包容的分子创新。

Abstract: Large language models (LLMs) are beginning to reshape how chemists plan and
run reactions in organic synthesis. Trained on millions of reported
transformations, these text-based models can propose synthetic routes, forecast
reaction outcomes and even instruct robots that execute experiments without
human supervision. Here we survey the milestones that turned LLMs from
speculative tools into practical lab partners. We show how coupling LLMs with
graph neural networks, quantum calculations and real-time spectroscopy shrinks
discovery cycles and supports greener, data-driven chemistry. We discuss
limitations, including biased datasets, opaque reasoning and the need for
safety gates that prevent unintentional hazards. Finally, we outline community
initiatives open benchmarks, federated learning and explainable interfaces that
aim to democratize access while keeping humans firmly in control. These
advances chart a path towards rapid, reliable and inclusive molecular
innovation powered by artificial intelligence and automation.

</details>


### [46] [Whose Truth? Pluralistic Geo-Alignment for (Agentic) AI](https://arxiv.org/abs/2508.05432)
*Krzysztof Janowicz,Zilong Liu,Gengchen Mai,Zhangyu Wang,Ivan Majic,Alexandra Fortacz,Grant McKenzie,Song Gao*

Main category: cs.AI

TL;DR: 论文探讨了AI对齐中的地理差异问题，强调需根据区域文化、政治和法律差异调整对齐措施，避免一刀切。


<details>
  <summary>Details</summary>
Motivation: 现有AI对齐研究多关注偏见和不平等，但地理差异的影响尚未充分探索。不同地区对适当性、真实性和合法性的定义差异显著，需针对性解决。

Method: 论文回顾了地理差异对AI对齐的影响，提出未来研究方向，并概述了评估对齐敏感性的方法。

Result: 研究发现AI对齐需考虑地理差异，如文本到图像模型可能忽略实际性别比例差异。部分模型输出需根据用户地理位置调整。

Conclusion: 随着AI的普及，需开发时空感知的对齐方法，避免一刀切，确保AI行为符合各地社会规范。

Abstract: AI (super) alignment describes the challenge of ensuring (future) AI systems
behave in accordance with societal norms and goals. While a quickly evolving
literature is addressing biases and inequalities, the geographic variability of
alignment remains underexplored. Simply put, what is considered appropriate,
truthful, or legal can differ widely across regions due to cultural norms,
political realities, and legislation. Alignment measures applied to AI/ML
workflows can sometimes produce outcomes that diverge from statistical
realities, such as text-to-image models depicting balanced gender ratios in
company leadership despite existing imbalances. Crucially, some model outputs
are globally acceptable, while others, e.g., questions about Kashmir, depend on
knowing the user's location and their context. This geographic sensitivity is
not new. For instance, Google Maps renders Kashmir's borders differently based
on user location. What is new is the unprecedented scale and automation with
which AI now mediates knowledge, expresses opinions, and represents geographic
reality to millions of users worldwide, often with little transparency about
how context is managed. As we approach Agentic AI, the need for
spatio-temporally aware alignment, rather than one-size-fits-all approaches, is
increasingly urgent. This paper reviews key geographic research problems,
suggests topics for future work, and outlines methods for assessing alignment
sensitivity.

</details>


### [47] [Bench-2-CoP: Can We Trust Benchmarking for EU AI Compliance?](https://arxiv.org/abs/2508.05464)
*Matteo Prandi,Vincenzo Suriani,Federico Pierucci,Marcello Galisai,Daniele Nardi,Piercosma Bisconti*

Main category: cs.AI

TL;DR: 论文提出了Bench-2-CoP框架，用于量化AI评估基准与欧盟AI法案要求之间的差距，发现现有基准严重忽视关键功能能力。


<details>
  <summary>Details</summary>
Motivation: 当前AI评估工具未能覆盖新法规关注的系统性风险，亟需量化这一差距以改进评估框架。

Method: 引入Bench-2-CoP框架，通过LLM-as-judge分析，将194,955个基准问题映射到欧盟AI法案的能力分类中。

Result: 发现评估生态严重偏向行为倾向（如幻觉倾向、歧视偏见），而关键功能能力（如失控场景）几乎未被覆盖。

Conclusion: 研究为政策制定者和开发者提供了改进评估工具的关键见解，以促进更安全合规的AI发展。

Abstract: The rapid advancement of General Purpose AI (GPAI) models necessitates robust
evaluation frameworks, especially with emerging regulations like the EU AI Act
and its associated Code of Practice (CoP). Current AI evaluation practices
depend heavily on established benchmarks, but these tools were not designed to
measure the systemic risks that are the focus of the new regulatory landscape.
This research addresses the urgent need to quantify this "benchmark-regulation
gap." We introduce Bench-2-CoP, a novel, systematic framework that uses
validated LLM-as-judge analysis to map the coverage of 194,955 questions from
widely-used benchmarks against the EU AI Act's taxonomy of model capabilities
and propensities. Our findings reveal a profound misalignment: the evaluation
ecosystem is overwhelmingly focused on a narrow set of behavioral propensities,
such as "Tendency to hallucinate" (53.7% of the corpus) and "Discriminatory
bias" (28.9%), while critical functional capabilities are dangerously
neglected. Crucially, capabilities central to loss-of-control scenarios,
including evading human oversight, self-replication, and autonomous AI
development, receive zero coverage in the entire benchmark corpus. This
translates to a near-total evaluation gap for systemic risks like "Loss of
Control" (0.4% coverage) and "Cyber Offence" (0.8% coverage). This study
provides the first comprehensive, quantitative analysis of this gap, offering
critical insights for policymakers to refine the CoP and for developers to
build the next generation of evaluation tools, ultimately fostering safer and
more compliant AI.

</details>


### [48] [Can Large Language Models Generate Effective Datasets for Emotion Recognition in Conversations?](https://arxiv.org/abs/2508.05474)
*Burak Can Kaplan,Hugo Cesar De Castro Carneiro,Stefan Wermter*

Main category: cs.AI

TL;DR: 使用小型高效LLM生成多样化ERC数据集，补充现有基准，提升分类器性能。


<details>
  <summary>Details</summary>
Motivation: ERC数据稀缺且存在偏差，LLM成本高且应用有限，需高效解决方案。

Method: 利用小型通用LLM生成六种新数据集，补充三大ERC基准，评估其效用。

Result: 生成数据集显著提升ERC分类器性能，增强鲁棒性。

Conclusion: 小型LLM生成的数据集有效解决ERC数据不足问题，提升模型表现。

Abstract: Emotion recognition in conversations (ERC) focuses on identifying emotion
shifts within interactions, representing a significant step toward advancing
machine intelligence. However, ERC data remains scarce, and existing datasets
face numerous challenges due to their highly biased sources and the inherent
subjectivity of soft labels. Even though Large Language Models (LLMs) have
demonstrated their quality in many affective tasks, they are typically
expensive to train, and their application to ERC tasks--particularly in data
generation--remains limited. To address these challenges, we employ a small,
resource-efficient, and general-purpose LLM to synthesize ERC datasets with
diverse properties, supplementing the three most widely used ERC benchmarks. We
generate six novel datasets, with two tailored to enhance each benchmark. We
evaluate the utility of these datasets to (1) supplement existing datasets for
ERC classification, and (2) analyze the effects of label imbalance in ERC. Our
experimental results indicate that ERC classifier models trained on the
generated datasets exhibit strong robustness and consistently achieve
statistically significant performance improvements on existing ERC benchmarks.

</details>


### [49] [InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs to Enhance Reasoning Capabilities](https://arxiv.org/abs/2508.05496)
*Shuo Cai,Su Lu,Qi Zhou,Kejing Yang,Zhijie Sang,Congkai Xie,Hongxia Yang*

Main category: cs.AI

TL;DR: InfiAlign是一个可扩展且样本高效的后训练框架，结合监督微调（SFT）和直接偏好优化（DPO），通过多维质量指标自动筛选高质量数据，显著提升模型推理能力并减少数据需求。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLMs）在复杂任务上表现出色，但后训练提升其能力通常需要大量数据和计算资源，现有方法依赖启发式或任务特定策略，难以扩展。

Method: InfiAlign框架整合SFT和DPO，通过自动筛选高质量对齐数据，显著减少数据需求并提升性能。

Result: 在Qwen2.5-Math-7B-Base模型上，仅使用12%的训练数据即达到与DeepSeek-R1-Distill-Qwen-7B相当的性能，数学推理任务提升3.89%。

Conclusion: 结合数据选择和全阶段后训练，InfiAlign提供了一种可扩展且数据高效的解决方案，适用于大推理模型的对齐。

Abstract: Large language models (LLMs) have exhibited impressive reasoning abilities on
a wide range of complex tasks. However, enhancing these capabilities through
post-training remains resource intensive, particularly in terms of data and
computational cost. Although recent efforts have sought to improve sample
efficiency through selective data curation, existing methods often rely on
heuristic or task-specific strategies that hinder scalability. In this work, we
introduce InfiAlign, a scalable and sample-efficient post-training framework
that integrates supervised fine-tuning (SFT) with Direct Preference
Optimization (DPO) to align LLMs for enhanced reasoning. At the core of
InfiAlign is a robust data selection pipeline that automatically curates
high-quality alignment data from open-source reasoning datasets using
multidimensional quality metrics. This pipeline enables significant performance
gains while drastically reducing data requirements and remains extensible to
new data sources. When applied to the Qwen2.5-Math-7B-Base model, our SFT model
achieves performance on par with DeepSeek-R1-Distill-Qwen-7B, while using only
approximately 12% of the training data, and demonstrates strong generalization
across diverse reasoning tasks. Additional improvements are obtained through
the application of DPO, with particularly notable gains in mathematical
reasoning tasks. The model achieves an average improvement of 3.89% on AIME
24/25 benchmarks. Our results highlight the effectiveness of combining
principled data selection with full-stage post-training, offering a practical
solution for aligning large reasoning models in a scalable and data-efficient
manner. The model checkpoints are available at
https://huggingface.co/InfiX-ai/InfiAlign-Qwen-7B-SFT.

</details>


### [50] [GRAIL:Learning to Interact with Large Knowledge Graphs for Retrieval Augmented Reasoning](https://arxiv.org/abs/2508.05498)
*Ge Chang,Jinbo Su,Jiacheng Liu,Pengfei Yang,Yuhao Shang,Huiwen Zheng,Hongli Ma,Yan Liang,Yuanchun Li,Yunxin Liu*

Main category: cs.AI

TL;DR: GRAIL框架通过结合LLM引导的随机探索和路径过滤，解决了现有RAG方法在处理结构化知识（如知识图谱）时的局限性，显著提升了推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法主要针对非结构化数据，对结构化知识（如知识图谱）处理能力有限，且当前图谱检索方法难以同时捕捉整体结构和控制精度。

Method: GRAIL框架结合LLM引导的随机探索和路径过滤，生成细粒度推理轨迹，并通过两阶段训练学习动态决策策略。

Result: 在三个知识图谱问答数据集上，GRAIL平均准确率提升21.01%，F1分数提升22.43%。

Conclusion: GRAIL通过交互式检索范式，动态平衡检索广度和精度，显著提升了图谱检索的推理性能。

Abstract: Large Language Models (LLMs) integrated with Retrieval-Augmented Generation
(RAG) techniques have exhibited remarkable performance across a wide range of
domains. However, existing RAG approaches primarily operate on unstructured
data and demonstrate limited capability in handling structured knowledge such
as knowledge graphs. Meanwhile, current graph retrieval methods fundamentally
struggle to capture holistic graph structures while simultaneously facing
precision control challenges that manifest as either critical information gaps
or excessive redundant connections, collectively undermining reasoning
performance. To address this challenge, we propose GRAIL: Graph-Retrieval
Augmented Interactive Learning, a framework designed to interact with
large-scale graphs for retrieval-augmented reasoning. Specifically, GRAIL
integrates LLM-guided random exploration with path filtering to establish a
data synthesis pipeline, where a fine-grained reasoning trajectory is
automatically generated for each task. Based on the synthesized data, we then
employ a two-stage training process to learn a policy that dynamically decides
the optimal actions at each reasoning step. The overall objective of
precision-conciseness balance in graph retrieval is decoupled into fine-grained
process-supervised rewards to enhance data efficiency and training stability.
In practical deployment, GRAIL adopts an interactive retrieval paradigm,
enabling the model to autonomously explore graph paths while dynamically
balancing retrieval breadth and precision. Extensive experiments have shown
that GRAIL achieves an average accuracy improvement of 21.01% and F1
improvement of 22.43% on three knowledge graph question-answering datasets. Our
source code and datasets is available at https://github.com/Changgeww/GRAIL.

</details>


### [51] [Auto-Eval Judge: Towards a General Agentic Framework for Task Completion Evaluation](https://arxiv.org/abs/2508.05508)
*Roshita Bhonsle,Rishav Dutta,Sneha Vavilapalli,Harsh Seth,Abubakarr Jaye,Yapei Chang,Mukund Rungta,Emmanuel Aboah Boateng,Sadid Hasan,Ehi Nosakhare,Soundar Srinivasan*

Main category: cs.AI

TL;DR: 提出了一种通用、模块化的框架，用于评估代理任务完成情况，通过分解任务并验证每个步骤，与人类评估更一致。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法（如LLM-as-a-Judge）仅关注最终输出，忽略了逐步推理过程，且现有Agent-as-a-Judge系统局限于特定领域。

Method: 设计了一个模块化框架，将任务分解为子任务，利用代理的输出和推理逐步验证，最终汇总结果。

Result: 在GAIA和BigCodeBench基准测试中，提出的Judge Agent比GPT-4o基线更接近人类评估，准确率分别提高4.76%和10.52%。

Conclusion: 该框架展示了通用评估方法的潜力，能够更全面地评估代理任务完成情况。

Abstract: The increasing adoption of foundation models as agents across diverse domains
necessitates a robust evaluation framework. Current methods, such as
LLM-as-a-Judge, focus only on final outputs, overlooking the step-by-step
reasoning that drives agentic decision-making. Meanwhile, existing
Agent-as-a-Judge systems, where one agent evaluates another's task completion,
are typically designed for narrow, domain-specific settings. To address this
gap, we propose a generalizable, modular framework for evaluating agent task
completion independent of the task domain. The framework emulates human-like
evaluation by decomposing tasks into sub-tasks and validating each step using
available information, such as the agent's output and reasoning. Each module
contributes to a specific aspect of the evaluation process, and their outputs
are aggregated to produce a final verdict on task completion. We validate our
framework by evaluating the Magentic-One Actor Agent on two benchmarks, GAIA
and BigCodeBench. Our Judge Agent predicts task success with closer agreement
to human evaluations, achieving 4.76% and 10.52% higher alignment accuracy,
respectively, compared to the GPT-4o based LLM-as-a-Judge baseline. This
demonstrates the potential of our proposed general-purpose evaluation
framework.

</details>


### [52] [Streamlining Admission with LOR Insights: AI-Based Leadership Assessment in Online Master's Program](https://arxiv.org/abs/2508.05513)
*Meryem Yilmaz Soylu,Adrian Gallard,Jeonghyun Lee,Gayane Grigoryan,Rushil Desai,Stephen Harmon*

Main category: cs.AI

TL;DR: LORI是一种基于AI的工具，用于从推荐信中自动检测领导力技能，使用RoBERTa和LLAMA模型，准确率高达91.6%。


<details>
  <summary>Details</summary>
Motivation: 推荐信评估耗时且主观，LORI旨在通过AI技术提供客观、高效的领导力评估。

Method: 采用自然语言处理技术，结合RoBERTa和LLAMA模型，识别领导力属性如团队合作、沟通和创新。

Result: RoBERTa模型在测试数据中表现优异，加权F1分数为91.6%，精确率和召回率分别为92.4%和91.6%。

Conclusion: LORI在研究生招生中能高效评估领导力技能，提升录取过程的客观性和全面性。

Abstract: Letters of recommendation (LORs) provide valuable insights into candidates'
capabilities and experiences beyond standardized test scores. However,
reviewing these text-heavy materials is time-consuming and labor-intensive. To
address this challenge and support the admission committee in providing
feedback for students' professional growth, our study introduces LORI: LOR
Insights, a novel AI-based detection tool for assessing leadership skills in
LORs submitted by online master's program applicants. By employing natural
language processing and leveraging large language models using RoBERTa and
LLAMA, we seek to identify leadership attributes such as teamwork,
communication, and innovation. Our latest RoBERTa model achieves a weighted F1
score of 91.6%, a precision of 92.4%, and a recall of 91.6%, showing a strong
level of consistency in our test data. With the growing importance of
leadership skills in the STEM sector, integrating LORI into the graduate
admissions process is crucial for accurately assessing applicants' leadership
capabilities. This approach not only streamlines the admissions process but
also automates and ensures a more comprehensive evaluation of candidates'
capabilities.

</details>


### [53] [MV-Debate: Multi-view Agent Debate with Dynamic Reflection Gating for Multimodal Harmful Content Detection in Social Media](https://arxiv.org/abs/2508.05557)
*Rui Lu,Jinhe Bi,Yunpu Ma,Feng Xiao,Yuntao Du,Yijun Tian*

Main category: cs.AI

TL;DR: MV-Debate是一种多视角代理辩论框架，通过动态反思门控统一检测多模态有害内容，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 社交媒体中多模态内容的复杂性使得有害意图（如讽刺、仇恨言论或虚假信息）难以检测，需要跨模态分析和动态适应。

Method: 提出MV-Debate框架，包含四个互补的辩论代理（表面分析师、深度推理者、模态对比者和社会情境分析者），通过迭代辩论和反思门控优化检测。

Result: 在三个基准数据集上，MV-Debate显著优于单模型和现有多代理辩论基线。

Conclusion: 多代理辩论框架在安全关键的在线环境中具有潜力，可提升社会意图检测的可靠性。

Abstract: Social media has evolved into a complex multimodal environment where text,
images, and other signals interact to shape nuanced meanings, often concealing
harmful intent. Identifying such intent, whether sarcasm, hate speech, or
misinformation, remains challenging due to cross-modal contradictions, rapid
cultural shifts, and subtle pragmatic cues. To address these challenges, we
propose MV-Debate, a multi-view agent debate framework with dynamic reflection
gating for unified multimodal harmful content detection. MV-Debate assembles
four complementary debate agents, a surface analyst, a deep reasoner, a
modality contrast, and a social contextualist, to analyze content from diverse
interpretive perspectives. Through iterative debate and reflection, the agents
refine responses under a reflection-gain criterion, ensuring both accuracy and
efficiency. Experiments on three benchmark datasets demonstrate that MV-Debate
significantly outperforms strong single-model and existing multi-agent debate
baselines. This work highlights the promise of multi-agent debate in advancing
reliable social intent detection in safety-critical online contexts.

</details>


### [54] [The Missing Reward: Active Inference in the Era of Experience](https://arxiv.org/abs/2508.05619)
*Bo Wen*

Main category: cs.AI

TL;DR: 论文提出主动推理（AIF）为解决自主AI代理学习中的奖励工程瓶颈问题，通过最小化自由能量的内在驱动替代外部奖励信号，结合大语言模型实现高效学习。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统依赖高质量训练数据和人工奖励设计，面临可扩展性挑战，阻碍真正自主智能的发展。

Method: 采用主动推理框架，结合大语言模型作为生成世界模型，实现基于贝叶斯目标的探索与利用平衡。

Result: AIF能够填补"接地代理缺口"，使AI系统自主制定、调整和追求目标，同时保持与人类价值观的一致性。

Conclusion: AIF与生成模型的结合为自主AI系统的发展提供了可行路径，满足计算和物理约束。

Abstract: This paper argues that Active Inference (AIF) provides a crucial foundation
for developing autonomous AI agents capable of learning from experience without
continuous human reward engineering. As AI systems begin to exhaust
high-quality training data and rely on increasingly large human workforces for
reward design, the current paradigm faces significant scalability challenges
that could impede progress toward genuinely autonomous intelligence. The
proposal for an ``Era of Experience,'' where agents learn from self-generated
data, is a promising step forward. However, this vision still depends on
extensive human engineering of reward functions, effectively shifting the
bottleneck from data curation to reward curation. This highlights what we
identify as the \textbf{grounded-agency gap}: the inability of contemporary AI
systems to autonomously formulate, adapt, and pursue objectives in response to
changing circumstances. We propose that AIF can bridge this gap by replacing
external reward signals with an intrinsic drive to minimize free energy,
allowing agents to naturally balance exploration and exploitation through a
unified Bayesian objective. By integrating Large Language Models as generative
world models with AIF's principled decision-making framework, we can create
agents that learn efficiently from experience while remaining aligned with
human values. This synthesis offers a compelling path toward AI systems that
can develop autonomously while adhering to both computational and physical
constraints.

</details>


### [55] [Simulating Human-Like Learning Dynamics with LLM-Empowered Agents](https://arxiv.org/abs/2508.05622)
*Yu Yuan,Lili Zhao,Wei Chen,Guangting Zheng,Kai Zhang,Mengdi Zhang,Qi Liu*

Main category: cs.AI

TL;DR: LearnerAgent是一个基于大语言模型的多智能体框架，用于模拟真实教学环境，研究人类学习行为。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以捕捉学习动态或提供可解释性，因此提出LearnerAgent以解决这些问题。

Method: 构建具有心理学基础的学习者类型（如深度、表面和懒惰学习者），通过知识获取、策略选择、测试和同伴互动跟踪学习动态。

Result: 研究发现深度学习者能持续认知增长，表面学习者的浅层知识被有效诊断，学习者行为与心理特征一致，基础LLM的默认行为是勤奋但脆弱的表面学习者。

Conclusion: LearnerAgent与真实场景高度吻合，为LLM行为提供了更深入的见解。

Abstract: Capturing human learning behavior based on deep learning methods has become a
major research focus in both psychology and intelligent systems. Recent
approaches rely on controlled experiments or rule-based models to explore
cognitive processes. However, they struggle to capture learning dynamics, track
progress over time, or provide explainability. To address these challenges, we
introduce LearnerAgent, a novel multi-agent framework based on Large Language
Models (LLMs) to simulate a realistic teaching environment. To explore
human-like learning dynamics, we construct learners with psychologically
grounded profiles-such as Deep, Surface, and Lazy-as well as a persona-free
General Learner to inspect the base LLM's default behavior. Through weekly
knowledge acquisition, monthly strategic choices, periodic tests, and peer
interaction, we can track the dynamic learning progress of individual learners
over a full-year journey. Our findings are fourfold: 1) Longitudinal analysis
reveals that only Deep Learner achieves sustained cognitive growth. Our
specially designed "trap questions" effectively diagnose Surface Learner's
shallow knowledge. 2) The behavioral and cognitive patterns of distinct
learners align closely with their psychological profiles. 3) Learners'
self-concept scores evolve realistically, with the General Learner developing
surprisingly high self-efficacy despite its cognitive limitations. 4)
Critically, the default profile of base LLM is a "diligent but brittle Surface
Learner"-an agent that mimics the behaviors of a good student but lacks true,
generalizable understanding. Extensive simulation experiments demonstrate that
LearnerAgent aligns well with real scenarios, yielding more insightful findings
about LLMs' behavior.

</details>
