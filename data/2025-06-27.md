<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 11]
- [cs.CR](#cs.CR) [Total: 12]
- [cs.AI](#cs.AI) [Total: 13]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Domain Knowledge in Requirements Engineering: A Systematic Mapping Study](https://arxiv.org/abs/2506.20754)
*Marina Araújo,Júlia Araújo,Romeu Oliveira,Lucas Romao,Marcos Kalinowski*

Main category: cs.SE

TL;DR: 本文通过系统映射研究，总结了领域知识在需求工程中的应用现状，包括方法、技术和工具，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 领域知识对需求工程至关重要，但目前缺乏系统性的总结和操作化方法。

Method: 采用混合搜索策略（数据库搜索与迭代式雪球法）进行系统映射研究。

Result: 分析了75篇论文，总结了需求类型、质量属性和领域知识在形式化、获取及维护中的挑战。

Conclusion: 研究为知识驱动的需求工程提供了概念和方法基础，并指出了未来研究方向。

Abstract: [Context] Domain knowledge is recognized as a key component for the success
of Requirements Engineering (RE), as it provides the conceptual support needed
to understand the system context, ensure alignment with stakeholder needs, and
reduce ambiguity in requirements specification. Despite its relevance, the
scientific literature still lacks a systematic consolidation of how domain
knowledge can be effectively used and operationalized in RE. [Goal] This paper
addresses this gap by offering a comprehensive overview of existing
contributions, including methods, techniques, and tools to incorporate domain
knowledge into RE practices. [Method] We conducted a systematic mapping study
using a hybrid search strategy that combines database searches with iterative
backward and forward snowballing. [Results] In total, we found 75 papers that
met our inclusion criteria. The analysis highlights the main types of
requirements addressed, the most frequently considered quality attributes, and
recurring challenges in the formalization, acquisition, and long-term
maintenance of domain knowledge. The results provide support for researchers
and practitioners in identifying established approaches and unresolved issues.
The study also outlines promising directions for future research, emphasizing
the development of scalable, automated, and sustainable solutions to integrate
domain knowledge into RE processes. [Conclusion] The study contributes by
providing a comprehensive overview that helps to build a conceptual and
methodological foundation for knowledge-driven requirements engineering.

</details>


### [2] [Agile Management for Machine Learning: A Systematic Mapping Study](https://arxiv.org/abs/2506.20759)
*Lucas Romao,Hugo Villamizar,Romeu Oliveira,Silvio Alonso,Marcos Kalinowski*

Main category: cs.SE

TL;DR: 本文通过系统映射研究总结了敏捷管理在机器学习（ML）驱动系统中的现状，识别了8个关键主题和主要挑战。


<details>
  <summary>Details</summary>
Motivation: 机器学习系统的动态性和传统项目管理方法的局限性促使研究如何有效应用敏捷方法。

Method: 采用混合搜索策略（数据库搜索与雪球迭代）进行系统映射研究，分析了27篇论文。

Result: 研究识别了8个框架，并将建议和实践分为8个主题，主要挑战是ML任务的工作量估算。

Conclusion: 研究总结了现状并指出需更多实证评估来验证现有成果。

Abstract: [Context] Machine learning (ML)-enabled systems are present in our society,
driving significant digital transformations. The dynamic nature of ML
development, characterized by experimental cycles and rapid changes in data,
poses challenges to traditional project management. Agile methods, with their
flexibility and incremental delivery, seem well-suited to address this
dynamism. However, it is unclear how to effectively apply these methods in the
context of ML-enabled systems, where challenges require tailored approaches.
[Goal] Our goal is to outline the state of the art in agile management for
ML-enabled systems. [Method] We conducted a systematic mapping study using a
hybrid search strategy that combines database searches with backward and
forward snowballing iterations. [Results] Our study identified 27 papers
published between 2008 and 2024. From these, we identified eight frameworks and
categorized recommendations and practices into eight key themes, such as
Iteration Flexibility, Innovative ML-specific Artifacts, and the Minimal Viable
Model. The main challenge identified across studies was accurate effort
estimation for ML-related tasks. [Conclusion] This study contributes by mapping
the state of the art and identifying open gaps in the field. While relevant
work exists, more robust empirical evaluation is still needed to validate these
contributions.

</details>


### [3] [Generating Reliable Adverse event Profiles for Health through Automated Integrated Data (GRAPH-AID): A Semi-Automated Ontology Building Approach](https://arxiv.org/abs/2506.20851)
*Srikar Reddy Gadusu,Larry Callahan,Samir Lababidi,Arunasri Nishtala,Sophia Healey,Hande McGinty*

Main category: cs.SE

TL;DR: 本文提出了一种用户友好的方法，利用Python和rdflib库支持本体开发，解决了Neo4j数据库与OWL无缝集成的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着数据和知识的迅速扩展，采用系统化的本体生成方法变得至关重要。现有方法需要理解描述逻辑（DL）语法，这对许多用户来说不友好，因此需要更易用的方法。

Method: 使用Python和rdflib库开发了一种方法，通过自动生成类和公理，实现Neo4j数据库与OWL的集成。

Result: 通过整合FDA的FAERS数据库数据，开发了一个Python脚本，展示了该方法的有效性。

Conclusion: 该方法为快速增长的药物不良事件数据集的本体生成提供了实用解决方案，支持药物安全监测和公共卫生决策。

Abstract: As data and knowledge expand rapidly, adopting systematic methodologies for
ontology generation has become crucial. With the daily increases in data
volumes and frequent content changes, the demand for databases to store and
retrieve information for the creation of knowledge graphs has become
increasingly urgent. The previously established Knowledge Acquisition and
Representation Methodology (KNARM) outlines a systematic approach to address
these challenges and create knowledge graphs. However, following this
methodology highlights the existing challenge of seamlessly integrating Neo4j
databases with the Web Ontology Language (OWL). Previous attempts to integrate
data from Neo4j into an ontology have been discussed, but these approaches
often require an understanding of description logics (DL) syntax, which may not
be familiar to many users. Thus, a more accessible method is necessary to
bridge this gap. This paper presents a user-friendly approach that utilizes
Python and its rdflib library to support ontology development. We showcase our
novel approach through a Neo4j database we created by integrating data from the
Food and Drug Administration (FDA) Adverse Event Reporting System (FAERS)
database. Using this dataset, we developed a Python script that automatically
generates the required classes and their axioms, facilitating a smoother
integration process. This approach offers a practical solution to the
challenges of ontology generation in the context of rapidly growing adverse
drug event datasets, supporting improved drug safety monitoring and public
health decision-making.

</details>


### [4] [Engineering RAG Systems for Real-World Applications: Design, Development, and Evaluation](https://arxiv.org/abs/2506.20869)
*Md Toufique Hasan,Muhammad Waseem,Kai-Kristian Kemell,Ayman Asad Khan,Mika Saari,Pekka Abrahamsson*

Main category: cs.SE

TL;DR: 本文介绍了五个基于检索增强生成（RAG）的实际应用案例，并通过用户评估总结了十二个关键经验教训。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs）在事实准确性和上下文相关性方面的不足，并填补实际应用中缺乏实证研究的空白。

Method: 开发了五个领域的RAG系统，结合多语言OCR、语义检索和领域适应的LLMs，并通过100名用户的网络评估。

Result: 用户评估了六个维度，总结了影响RAG系统可靠性和可用性的技术、操作和伦理挑战。

Conclusion: RAG系统在实际应用中具有潜力，但仍需解决技术、操作和伦理问题。

Abstract: Retrieval-Augmented Generation (RAG) systems are emerging as a key approach
for grounding Large Language Models (LLMs) in external knowledge, addressing
limitations in factual accuracy and contextual relevance. However, there is a
lack of empirical studies that report on the development of RAG-based
implementations grounded in real-world use cases, evaluated through general
user involvement, and accompanied by systematic documentation of lessons
learned. This paper presents five domain-specific RAG applications developed
for real-world scenarios across governance, cybersecurity, agriculture,
industrial research, and medical diagnostics. Each system incorporates
multilingual OCR, semantic retrieval via vector embeddings, and domain-adapted
LLMs, deployed through local servers or cloud APIs to meet distinct user needs.
A web-based evaluation involving a total of 100 participants assessed the
systems across six dimensions: (i) Ease of Use, (ii) Relevance, (iii)
Transparency, (iv) Responsiveness, (v) Accuracy, and (vi) Likelihood of
Recommendation. Based on user feedback and our development experience, we
documented twelve key lessons learned, highlighting technical, operational, and
ethical challenges affecting the reliability and usability of RAG systems in
practice.

</details>


### [5] [Complex Model Transformations by Reinforcement Learning with Uncertain Human Guidance](https://arxiv.org/abs/2506.20883)
*Kyanna Dagenais,Istvan David*

Main category: cs.SE

TL;DR: 论文提出了一种结合人类指导的强化学习方法，用于开发复杂的模型转换序列，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 手动开发复杂的模型转换（MT）序列易出错且不可行，强化学习（RL）虽能缓解问题，但在复杂场景中性能不足，人类指导可弥补这一缺陷。

Method: 提出了一种框架，将用户定义的MT映射到RL原语中，并通过RL程序执行以寻找最优MT序列，同时整合不确定的人类建议。

Result: 评估表明，即使人类建议不确定，也能显著提升RL性能，并更高效地开发复杂MT序列。

Conclusion: 该方法通过权衡人类建议的确定性和及时性，为RL驱动的人机协同工程方法迈出了一步。

Abstract: Model-driven engineering problems often require complex model transformations
(MTs), i.e., MTs that are chained in extensive sequences. Pertinent examples of
such problems include model synchronization, automated model repair, and design
space exploration. Manually developing complex MTs is an error-prone and often
infeasible process. Reinforcement learning (RL) is an apt way to alleviate
these issues. In RL, an autonomous agent explores the state space through trial
and error to identify beneficial sequences of actions, such as MTs. However, RL
methods exhibit performance issues in complex problems. In these situations,
human guidance can be of high utility. In this paper, we present an approach
and technical framework for developing complex MT sequences through RL, guided
by potentially uncertain human advice. Our framework allows user-defined MTs to
be mapped onto RL primitives, and executes them as RL programs to find optimal
MT sequences. Our evaluation shows that human guidance, even if uncertain,
substantially improves RL performance, and results in more efficient
development of complex MTs. Through a trade-off between the certainty and
timeliness of human advice, our method takes a step towards RL-driven
human-in-the-loop engineering methods.

</details>


### [6] [Boosting Vulnerability Detection with Inter-function Multilateral Association Insights](https://arxiv.org/abs/2506.21014)
*Shaojian Qiu,Mengyang Huang,Jiahao Cheng*

Main category: cs.SE

TL;DR: IFMA-VD是一个基于超图卷积的漏洞检测框架，通过分析函数间的多边关联提升检测效果。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法忽视函数间复杂关联，导致漏洞检测不全面。

Method: 构建代码行为超图，利用超边卷积提取多边关联特征。

Result: 在三个数据集上F-measure和Recall优于基线方法。

Conclusion: 多边关联特征能增强代码表示，IFMA-VD在实际数据中有效。

Abstract: Vulnerability detection is a crucial yet challenging technique for ensuring
the security of software systems. Currently, most deep learning-based
vulnerability detection methods focus on stand-alone functions, neglecting the
complex inter-function interrelations, particularly the multilateral
associations. This oversight can fail to detect vulnerabilities in these
interrelations. To address this gap, we present an Inter-Function Multilateral
Association analysis framework for Vulnerability Detection (IFMA-VD). The
cornerstone of the IFMA-VD lies in constructing a code behavior hypergraph and
utilizing hyperedge convolution to extract multilateral association features.
Specifically, we first parse functions into a code property graph to generate
intra-function features. Following this, we construct a code behavior
hypergraph by segmenting the program dependency graph to isolate and encode
behavioral features into hyperedges. Finally, we utilize a hypergraph network
to capture the multilateral association knowledge for augmenting vulnerability
detection. We evaluate IFMA-VD on three widely used vulnerability datasets and
demonstrate improvements in F-measure and Recall compared to baseline methods.
Additionally, we illustrate that multilateral association features can boost
code feature representation and validate the effectiveness of IFMA-VD on
real-world datasets.

</details>


### [7] [How Good Are Synthetic Requirements ? Evaluating LLM-Generated Datasets for AI4RE](https://arxiv.org/abs/2506.21138)
*Abdelkarim El-Hajjami,Camille Salinesi*

Main category: cs.SE

TL;DR: 论文提出Synthline v1，通过改进的生成策略和优化技术生成高质量合成需求数据，解决AI4RE领域数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 公开标注的需求数据集稀缺阻碍了AI4RE的发展，需要系统化方法优化合成数据的质量。

Method: 采用多样本提示、自动提示优化（PACE）和后生成筛选技术，评估四种分类任务下的数据质量。

Result: 多样本提示显著提升数据质量和多样性；PACE优化效果因任务而异；合成数据在某些任务上优于人工数据。

Conclusion: 合成需求数据可有效缓解数据集稀缺问题，为AI4RE提供实用解决方案。

Abstract: The shortage of publicly available, labeled requirements datasets remains a
major barrier to advancing Artificial Intelligence for Requirements Engineering
(AI4RE). While Large Language Models offer promising capabilities for synthetic
data generation, systematic approaches to control and optimize the quality of
generated requirements remain underexplored. This paper presents Synthline v1,
an enhanced Product Line approach for generating synthetic requirements data
that extends our earlier v0 version with advanced generation strategies and
curation techniques. We investigate four research questions assessing how
prompting strategies, automated prompt optimization, and post-generation
curation affect data quality across four classification tasks: defect
detection, functional vs. non-functional, quality vs. non-quality, and security
vs. non-security. Our evaluation shows that multi-sample prompting
significantly boosts both utility and diversity over single-sample generation,
with F1-score gains from 6 to 44 points. The use of PACE (Prompt Actor-Critic
Editing) for automated prompt optimization yields task-dependent results,
greatly improving functional classification (+32.5 points) but reducing
performance on others. Interestingly, similarity-based curation improves
diversity but often harms classification performance, indicating that some
redundancy may help ML models. Most importantly, our results show that
synthetic requirements can match or outperform human-authored ones for specific
tasks, with synthetic data surpassing human data for security (+7.8 points) and
defect classification (+15.4 points). These findings offer practical insights
for AI4RE and chart a viable path to mitigating dataset scarcity through
systematic synthetic generation.

</details>


### [8] [$T^3$: Multi-level Tree-based Automatic Program Repair with Large Language Models](https://arxiv.org/abs/2506.21211)
*Quanming Liu,Xupeng Bu,Zhichao Yan,Ru Li*

Main category: cs.SE

TL;DR: 该论文提出了一种名为$T^3$的创新框架，结合大型语言模型（LLMs）的强大推理能力和树搜索技术，提升了自动程序修复（APR）任务的精度。


<details>
  <summary>Details</summary>
Motivation: 由于自动程序修复（APR）需要复杂的逻辑和多步推理能力，而现有的链式思考（CoT）技术在该领域的应用不足，因此需要一种更有效的方法来提升APR的性能。

Method: 研究系统评估了几种常见的CoT技术在APR任务中的表现，并提出了$T^3$框架，结合LLMs的推理能力和树搜索技术，优化候选修复方案的生成。

Result: $T^3$框架显著提高了生成候选修复方案的精度，并为APR任务中的样本选择和修复策略优化提供了有价值的指导。

Conclusion: $T^3$框架为高效自动化调试建立了坚实的基础，展示了在APR任务中结合LLMs和树搜索技术的潜力。

Abstract: Automatic Program Repair (APR) is a core technology in software development
and maintenance, with aims to enable automated defect repair with minimal human
intervention. In recent years, the substantial advancements in Large Language
Models (LLMs) and the Chain-of-Thought (CoT) techniques have significantly
enhanced the reasoning capabilities of these models. However, due to the
complex logic and multi-step reasoning ability needed, the application of CoT
techniques in the APR domain remains insufficient. This study systematically
evaluates the performance of several common CoT techniques in APR tasks and
proposes an innovative framework $T^3$, which integrates the powerful reasoning
capabilities of LLMs with tree search, effectively improving the precision of
generating candidate repair solutions. Furthermore, $T^3$ provides valuable
guidance for optimizing sample selection and repair strategies in APR tasks,
establishing a robust framework for achieving efficient automated debugging.

</details>


### [9] [KOALA: a Configurable Tool for Collecting IDE Data When Solving Programming Tasks](https://arxiv.org/abs/2506.21266)
*Daniil Karol,Elizaveta Artser,Ilya Vlasov,Yaroslav Golubev,Hieke Keuning,Anastasiia Birillo*

Main category: cs.SE

TL;DR: KOALA是一个可配置的工具，用于收集学生在JetBrains IDE中解决编程任务时的代码快照和功能使用数据，解决了现有工具的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有数据收集工具在代码粒度控制、编程环境事件收集和配置灵活性方面存在不足，限制了研究和教育的效果。

Method: 开发KOALA插件，安装在JetBrains IDE中，配置任务、IDE功能开关和调查，收集代码快照、IDE操作和其他未记录的数据，并转换为ProgSnap2格式。

Result: 从28名学生中收集了数据，展示了工具的实际应用效果和部分数据洞察。

Conclusion: KOALA提供了一个灵活且功能强大的解决方案，显著改进了编程教育中的数据收集能力。

Abstract: Collecting data of students solving programming tasks is incredibly valuable
for researchers and educators. It allows verifying that the students correctly
apply the features and concepts they are taught, or finding students'
misconceptions. However, existing data collection tools have limitations, e.g.,
no control over the granularity of the collected code, not collecting the
specific events of the programming environment used, and overall being hard to
configure.
  To overcome these limitations, we propose KOALA, a convenient and highly
configurable tool for collecting code snapshots and feature usage from students
solving programming tasks in JetBrains IDEs. The plugin can be installed in
IDEs and configured to provide the students with the necessary tasks, enable or
disable certain IDE features like code completion, and run surveys. During
problem solving, the plugin collects code snapshots at the configured
granularity, all IDE actions like running and debugging, as well as some data
not collected in prior works, like employed hotkeys and switching focus between
files. The collected data is sent to the server that comes with the tool, where
it is stored and can be converted to the standardized ProgSnap2 format. To
showcase the tool, we collected data from 28 students solving tasks in two
courses within the IDE, highlighting some insights from this data.

</details>


### [10] [Exploring Micro Frontends: A Case Study Application in E-Commerce](https://arxiv.org/abs/2506.21297)
*Ricardo Hideki Hangai Kojo,Luiz Fernando Corte Real,Renato Cordeiro Ferreira,Thatiane de Oliveira Rosa,Alfredo Goldman*

Main category: cs.SE

TL;DR: 本文探讨了微前端架构在工业场景中的适用性，通过案例研究发现其虽能提升可扩展性和团队独立性，但并非总是必要选择。


<details>
  <summary>Details</summary>
Motivation: 研究微前端架构的适用性，特别是在已有微服务架构的企业中，以解决紧耦合和开发体验差的问题。

Method: 结合学术与灰色文献调研，并在一个手工艺品市场平台实施微前端架构，通过开发者问卷评估效果。

Result: 微前端成功实施但非必需，其他方案如单体前端也能达到类似效果；其优势在于与现有微服务架构的协同。

Conclusion: 微前端在特定场景（如已有微服务架构）中更具优势，但需权衡复杂性和基础设施成本。

Abstract: In the micro frontends architectural style, the frontend is divided into
smaller components, which can range from a simple button to an entire page. The
goal is to improve scalability, resilience, and team independence, albeit at
the cost of increased complexity and infrastructure demands. This paper seeks
to understand when it is worth adopting micro frontends, particularly in the
context of industry. To achieve this, we conducted an investigation into the
state of the art of micro frontends, based on both academic and gray
literature. We then implemented this architectural style in a marketplace for
handcrafted products, which already used microservices. Finally, we evaluated
the implementation through a semi-open questionnaire with the developers. At
the studied marketplace company, the need for architectural change arose due to
the tight coupling between their main system (a Java monolith) and a dedicated
frontend system. Additionally, there were deprecated technologies and poor
developer experience. To address these issues, the micro frontends architecture
was adopted, along with the API Gateway and Backend for Frontend patterns, and
technologies such as Svelte and Fastify. Although the adoption of Micro
Frontends was successful, it was not strictly necessary to meet the company's
needs. According to the analysis of the mixed questionnaire responses, other
alternatives, such as a monolithic frontend, could have achieved comparable
results. What made adopting micro frontends the most convenient choice in the
company's context was the monolith strangulation and microservices adoption,
which facilitated implementation through infrastructure reuse and knowledge
sharing between teams.

</details>


### [11] [An object-centric core metamodel for IoT-enhanced event logs](https://arxiv.org/abs/2506.21300)
*Yannis Bertrand,Christian Imenkamp,Lukas Malburg,Matthias Ehrendorfer,Marco Franceschetti,Joscha Grüger,Francesco Leotta,Jürgen Mangler,Ronny Seiger,Agnes Koschmider,Stefanie Rinderle-Ma,Barbara Weber,Estefania Serral*

Main category: cs.SE

TL;DR: 论文提出了一种核心模型，整合了现有物联网（IoT）数据与业务流程数据集成模型的关键特征，以促进数据共享和协作。


<details>
  <summary>Details</summary>
Motivation: 物联网设备的普及生成了大量数据，但与传统业务流程数据的集成存在挑战，现有模型碎片化阻碍了协作。

Method: 提出一个基于共同需求的核心模型，并通过Python原型实现验证其满足这些需求。

Result: 核心模型成功整合了现有模型的关键特征，并通过用例验证了其有效性。

Conclusion: 该模型为物联网与业务流程数据的集成提供了统一框架，促进了数据共享和协作。

Abstract: Advances in Internet-of-Things (IoT) technologies have prompted the
integration of IoT devices with business processes (BPs) in many organizations
across various sectors, such as manufacturing, healthcare and smart spaces. The
proliferation of IoT devices leads to the generation of large amounts of IoT
data providing a window on the physical context of BPs, which facilitates the
discovery of new insights about BPs using process mining (PM) techniques.
However, to achieve these benefits, IoT data need to be combined with
traditional process (event) data, which is challenging due to the very
different characteristics of IoT and process data, for instance in terms of
granularity levels. Recently, several data models were proposed to integrate
IoT data with process data, each focusing on different aspects of data
integration based on different assumptions and requirements. This fragmentation
hampers data exchange and collaboration in the field of PM, e.g., making it
tedious for researchers to share data. In this paper, we present a core model
synthesizing the most important features of existing data models. As the core
model is based on common requirements, it greatly facilitates data sharing and
collaboration in the field. A prototypical Python implementation is used to
evaluate the model against various use cases and demonstrate that it satisfies
these common requirements.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [12] [Perry: A High-level Framework for Accelerating Cyber Deception Experimentation](https://arxiv.org/abs/2506.20770)
*Brian Singer,Yusuf Saquib,Lujo Bauer,Vyas Sekar*

Main category: cs.CR

TL;DR: Perry是一个高级框架，旨在简化网络欺骗的设计和探索，通过抽象层和实验模块支持多种欺骗场景的快速实现和评估。


<details>
  <summary>Details</summary>
Motivation: 现有的网络欺骗工具复杂且难以扩展，阻碍了操作员对欺骗策略的实验和评估。

Method: Perry框架包含抽象层和实验模块，通过四个关键模块（动作规划器、可观测性模块、环境状态服务和攻击图服务）实现高级到低级的转换。

Result: Perry减少了实现多样化欺骗防御的复杂性，并通过55个独特场景展示了其价值。

Conclusion: Perry为操作员提供了高效的工具，帮助探索欺骗策略的微妙权衡。

Abstract: Cyber deception aims to distract, delay, and detect network attackers with
fake assets such as honeypots, decoy credentials, or decoy files. However,
today, it is difficult for operators to experiment, explore, and evaluate
deception approaches. Existing tools and platforms have non-portable and
complex implementations that are difficult to modify and extend. We address
this pain point by introducing Perry, a high-level framework that accelerates
the design and exploration of deception what-if scenarios. Perry has two
components: a high-level abstraction layer for security operators to specify
attackers and deception strategies, and an experimentation module to run these
attackers and defenders in realistic emulated networks. To translate these
high-level specifications we design four key modules for Perry: 1) an action
planner that translates high-level actions into low-level implementations, 2)
an observability module to translate low-level telemetry into high-level
observations, 3) an environment state service that enables environment agnostic
strategies, and 4) an attack graph service to reason about how attackers could
explore an environment. We illustrate that Perry's abstractions reduce the
implementation effort of exploring a wide variety of deception defenses,
attackers, and environments. We demonstrate the value of Perry by emulating 55
unique deception what-if scenarios and illustrate how these experiments enable
operators to shed light on subtle tradeoffs.

</details>


### [13] [SIMulator: SIM Tracing on a (Pico-)Budget](https://arxiv.org/abs/2506.20800)
*Gabriel K. Gegenhuber,Philipp É. Frenzel,Adrian Dabrowski*

Main category: cs.CR

TL;DR: 论文提出了一种低成本实现SIM追踪功能的方法，仅需常见组件如UART接口和GPIO端口，降低了硬件复杂性和成本。


<details>
  <summary>Details</summary>
Motivation: 传统SIM追踪依赖昂贵专用硬件，限制了研究人员特别是新手的参与。

Method: 利用低成本微控制器（如Raspberry Pi Pico）实现SIM追踪，通过电气隔离SIM与调制解调器，仅在APDU级别传输数据。

Result: 成功实现了完整的SIM追踪功能，硬件成本低至4美元。

Conclusion: 该方法显著降低了SIM追踪的门槛，有助于推动蜂窝网络研究的广泛探索。

Abstract: SIM tracing -- the ability to inspect, modify, and relay communication
between a SIM card and modem -- has become a significant technique in cellular
network research. It enables essential security- and development-related
applications such as fuzzing communication interfaces, extracting session keys,
monitoring hidden SIM activity (e.g., proactive SIM commands or over-the-air
updates), and facilitating scalable, distributed measurement platforms through
SIM reuse. Traditionally, achieving these capabilities has relied on
specialized hardware, which can pose financial and logistical burdens for
researchers, particularly those new to the field. In this work, we show that
full SIM tracing functionality can be achieved using only simple, widely
available components, such as UART interfaces and GPIO ports. We port these
capabilities to low-cost microcontrollers, exemplified by the Raspberry Pi Pico
(4~USD). Unlike other approaches, it dramatically reduces hardware complexity
by electrically decoupling the SIM and the modem and only transferring on APDU
level. By significantly reducing hardware requirements and associated costs, we
aim to make SIM tracing techniques accessible to a broader community of
researchers and hobbyists, fostering wider exploration and experimentation in
cellular network research.

</details>


### [14] [Poster: Enhancing GNN Robustness for Network Intrusion Detection via Agent-based Analysis](https://arxiv.org/abs/2506.20806)
*Zhonghao Zhan,Huichi Zhou,Hamed Haddadi*

Main category: cs.CR

TL;DR: 该论文提出了一种利用大型语言模型（LLMs）增强图神经网络（GNNs）在入侵检测系统中鲁棒性和泛化能力的新方法。


<details>
  <summary>Details</summary>
Motivation: GNNs在网络入侵检测系统（NIDS）中表现优异，但在分布漂移和对抗攻击下性能下降，现有评估方法不够全面。

Method: 通过LLMs模拟网络安全专家，分析网络流数据生成的图结构，识别并缓解对抗性扰动。

Result: 实验表明，LLM分析显著提升了GNNs在对抗攻击下的鲁棒性。

Conclusion: LLMs可作为入侵检测架构的补充层，提升系统整体性能。

Abstract: Graph Neural Networks (GNNs) show great promise for Network Intrusion
Detection Systems (NIDS), particularly in IoT environments, but suffer
performance degradation due to distribution drift and lack robustness against
realistic adversarial attacks. Current robustness evaluations often rely on
unrealistic synthetic perturbations and lack demonstrations on systematic
analysis of different kinds of adversarial attack, which encompass both
black-box and white-box scenarios. This work proposes a novel approach to
enhance GNN robustness and generalization by employing Large Language Models
(LLMs) in an agentic pipeline as simulated cybersecurity expert agents. These
agents scrutinize graph structures derived from network flow data, identifying
and potentially mitigating suspicious or adversarially perturbed elements
before GNN processing. Our experiments, using a framework designed for
realistic evaluation and testing with a variety of adversarial attacks
including a dataset collected from physical testbed experiments, demonstrate
that integrating LLM analysis can significantly improve the resilience of
GNN-based NIDS against challenges, showcasing the potential of LLM agent as a
complementary layer in intrusion detection architectures.

</details>


### [15] [Empowering Digital Agriculture: A Privacy-Preserving Framework for Data Sharing and Collaborative Research](https://arxiv.org/abs/2506.20872)
*Osama Zafar,Rosemarie Santa González,Mina Namazi,Alfonso Morales,Erman Ayday*

Main category: cs.CR

TL;DR: 提出了一种隐私保护框架，结合降维技术和差分隐私，支持农民安全共享数据，促进农业研究合作。


<details>
  <summary>Details</summary>
Motivation: 解决农民因隐私问题不愿共享数据的问题，推动数据驱动农业的发展。

Method: 结合主成分分析（PCA）和拉普拉斯噪声的差分隐私技术，支持联邦学习和隐私保护数据聚合。

Result: 在真实数据集上验证了框架的隐私保护效果和实用性，性能接近集中式系统。

Conclusion: 该框架有助于农民和研究者的合作，推动农业数据的安全整合与创新。

Abstract: Data-driven agriculture, which integrates technology and data into
agricultural practices, has the potential to improve crop yield, disease
resilience, and long-term soil health. However, privacy concerns, such as
adverse pricing, discrimination, and resource manipulation, deter farmers from
sharing data, as it can be used against them. To address this barrier, we
propose a privacy-preserving framework that enables secure data sharing and
collaboration for research and development while mitigating privacy risks. The
framework combines dimensionality reduction techniques (like Principal
Component Analysis (PCA)) and differential privacy by introducing Laplacian
noise to protect sensitive information. The proposed framework allows
researchers to identify potential collaborators for a target farmer and train
personalized machine learning models either on the data of identified
collaborators via federated learning or directly on the aggregated
privacy-protected data. It also allows farmers to identify potential
collaborators based on similarities. We have validated this on real-life
datasets, demonstrating robust privacy protection against adversarial attacks
and utility performance comparable to a centralized system. We demonstrate how
this framework can facilitate collaboration among farmers and help researchers
pursue broader research objectives. The adoption of the framework can empower
researchers and policymakers to leverage agricultural data responsibly, paving
the way for transformative advances in data-driven agriculture. By addressing
critical privacy challenges, this work supports secure data integration,
fostering innovation and sustainability in agricultural systems.

</details>


### [16] [ZKPROV: A Zero-Knowledge Approach to Dataset Provenance for Large Language Models](https://arxiv.org/abs/2506.20915)
*Mina Namazi,Alexander Nemecek,Erman Ayday*

Main category: cs.CR

TL;DR: ZKPROV是一种新型加密框架，通过零知识证明验证大型语言模型的数据来源，确保模型训练数据的可靠性而不泄露敏感信息。


<details>
  <summary>Details</summary>
Motivation: 在敏感领域（如医疗）部署大型语言模型时，确保其计算来源的完整性至关重要，尤其是在数据使用受严格监管的情况下。

Method: ZKPROV通过零知识证明将训练模型与其授权数据集绑定，避免验证每一步训练过程，利用数据集签名元数据和紧凑模型参数承诺。

Result: 实验证明ZKPROV在生成和验证证明时高效且可扩展，适用于实际部署，同时提供形式化安全保障。

Conclusion: ZKPROV在保护数据集机密性的同时，确保了可信的数据来源，为实际应用提供了实用解决方案。

Abstract: As the deployment of large language models (LLMs) grows in sensitive domains,
ensuring the integrity of their computational provenance becomes a critical
challenge, particularly in regulated sectors such as healthcare, where strict
requirements are applied in dataset usage. We introduce ZKPROV, a novel
cryptographic framework that enables zero-knowledge proofs of LLM provenance.
It allows users to verify that a model is trained on a reliable dataset without
revealing sensitive information about it or its parameters. Unlike prior
approaches that focus on complete verification of the training process
(incurring significant computational cost) or depend on trusted execution
environments, ZKPROV offers a distinct balance. Our method cryptographically
binds a trained model to its authorized training dataset(s) through
zero-knowledge proofs while avoiding proof of every training step. By
leveraging dataset-signed metadata and compact model parameter commitments,
ZKPROV provides sound and privacy-preserving assurances that the result of the
LLM is derived from a model trained on the claimed authorized and relevant
dataset. Experimental results demonstrate the efficiency and scalability of the
ZKPROV in generating this proof and verifying it, achieving a practical
solution for real-world deployments. We also provide formal security
guarantees, proving that our approach preserves dataset confidentiality while
ensuring trustworthy dataset provenance.

</details>


### [17] [CodeGuard: A Generalized and Stealthy Backdoor Watermarking for Generative Code Models](https://arxiv.org/abs/2506.20926)
*Haoxuan Li,Jiale Zhang,Xiaobing Sun,Xiapu Luo*

Main category: cs.CR

TL;DR: CodeGuard是一种结合注意力机制和分布式触发嵌入策略的新型水印方法，解决了现有技术在泛化性和隐蔽性上的不足，验证率高达100%，且不影响主要任务性能。


<details>
  <summary>Details</summary>
Motivation: 生成代码模型（GCMs）需要有效的数字版权保护以防止未经授权的泄露和滥用，但现有水印技术存在泛化性差和隐蔽性不足的问题。

Method: CodeGuard通过注意力机制确定水印嵌入位置，并使用同态字符替换和分布式触发嵌入策略，提高隐蔽性和泛化性。

Result: 实验显示，CodeGuard在代码摘要和代码生成任务中验证率达100%，且对主要任务性能无影响，隐蔽性显著优于基线方法。

Conclusion: CodeGuard为生成代码模型提供了一种高效、隐蔽且泛化性强的版权保护解决方案。

Abstract: Generative code models (GCMs) significantly enhance development efficiency
through automated code generation and code summarization. However, building and
training these models require computational resources and time, necessitating
effective digital copyright protection to prevent unauthorized leaks and
misuse. Backdoor watermarking, by embedding hidden identifiers, simplifies
copyright verification by breaking the model's black-box nature. Current
backdoor watermarking techniques face two main challenges: first, limited
generalization across different tasks and datasets, causing fluctuating
verification rates; second, insufficient stealthiness, as watermarks are easily
detected and removed by automated methods. To address these issues, we propose
CodeGuard, a novel watermarking method combining attention mechanisms with
distributed trigger embedding strategies. Specifically, CodeGuard employs
attention mechanisms to identify watermark embedding positions, ensuring
verifiability. Moreover, by using homomorphic character replacement, it avoids
manual detection, while distributed trigger embedding reduces the likelihood of
automated detection. Experimental results demonstrate that CodeGuard achieves
up to 100% watermark verification rates in both code summarization and code
generation tasks, with no impact on the primary task performance. In terms of
stealthiness, CodeGuard performs exceptionally, with a maximum detection rate
of only 0.078 against ONION detection methods, significantly lower than
baseline methods.

</details>


### [18] [SPA: Towards More Stealth and Persistent Backdoor Attacks in Federated Learning](https://arxiv.org/abs/2506.20931)
*Chengcheng Zhu,Ye Li,Bosen Rao,Jiale Zhang,Yunlong Mao,Sheng Zhong*

Main category: cs.CR

TL;DR: 本文提出了一种名为SPA的新型隐蔽后门攻击框架，通过特征空间对齐而非直接触发标签关联，显著提高了攻击的隐蔽性和持久性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）中的后门攻击通常依赖端到端标签监督，导致特征解耦和持久性有限。SPA旨在解决这些问题，提供更隐蔽和持久的攻击方式。

Method: SPA通过减少后门触发特征与目标类特征之间的表示距离，实现高隐蔽性和持久性的攻击。此外，引入自适应对抗触发优化机制，增强攻击效果。

Result: 实验表明，SPA在各种FL基准测试中均能实现高攻击成功率，且对模型效用影响最小，同时在非IID数据分布和防御性FL场景下表现稳健。

Conclusion: SPA展示了后门攻击在FL中的日益复杂化，强调了开发特征级防御技术的紧迫性。

Abstract: Federated Learning (FL) has emerged as a leading paradigm for
privacy-preserving distributed machine learning, yet the distributed nature of
FL introduces unique security challenges, notably the threat of backdoor
attacks. Existing backdoor strategies predominantly rely on end-to-end label
supervision, which, despite their efficacy, often results in detectable feature
disentanglement and limited persistence. In this work, we propose a novel and
stealthy backdoor attack framework, named SPA, which fundamentally departs from
traditional approaches by leveraging feature-space alignment rather than direct
trigger-label association. Specifically, SPA reduces representational distances
between backdoor trigger features and target class features, enabling the
global model to misclassify trigger-embedded inputs with high stealth and
persistence. We further introduce an adaptive, adversarial trigger optimization
mechanism, utilizing boundary-search in the feature space to enhance attack
longevity and effectiveness, even against defensive FL scenarios and non-IID
data distributions. Extensive experiments on various FL benchmarks demonstrate
that SPA consistently achieves high attack success rates with minimal impact on
model utility, maintains robustness under challenging participation and data
heterogeneity conditions, and exhibits persistent backdoor effects far
exceeding those of conventional techniques. Our results call urgent attention
to the evolving sophistication of backdoor threats in FL and emphasize the
pressing need for advanced, feature-level defense techniques.

</details>


### [19] [PrivacyGo: Privacy-Preserving Ad Measurement with Multidimensional Intersection](https://arxiv.org/abs/2506.20981)
*Jian Du,Haohao Qian,Shikun Zhang,Wen-jie Lu,Donghang Lu,Yongchuan Niu,Bo Jiang,Yongjun Zhao,Qiang Yan*

Main category: cs.CR

TL;DR: 本文提出了一种基于反向OPRF和盲密钥旋转技术的隐私保护广告测量框架，支持多标识符安全匹配，防止交叉标识符关联，并引入差分隐私机制。


<details>
  <summary>Details</summary>
Motivation: 解决多标识符隐私用户配置文件匹配的挑战性问题，为现代广告分析提供隐私保护基础。

Method: 采用反向OPRF和盲密钥旋转技术，结合差分隐私机制，设计高效且安全的协议。

Result: 协议具有强隐私保证和高效率，适用于大规模数据集，为广告行业提供隐私保护解决方案。

Conclusion: 本文为隐私保护广告测量设定了新标准，结合密码学与差分隐私，满足行业关键需求。

Abstract: This paper tackles the challenging and practical problem of multi-identifier
private user profile matching for privacy-preserving ad measurement, a
cornerstone of modern advertising analytics. We introduce a comprehensive
cryptographic framework leveraging reversed Oblivious Pseudorandom Functions
(OPRF) and novel blind key rotation techniques to support secure matching
across multiple identifiers. Our design prevents cross-identifier linkages and
includes a differentially private mechanism to obfuscate intersection sizes,
mitigating risks such as membership inference attacks.
  We present a concrete construction of our protocol that achieves both strong
privacy guarantees and high efficiency. It scales to large datasets, offering a
practical and scalable solution for privacy-centric applications like secure ad
conversion tracking. By combining rigorous cryptographic principles with
differential privacy, our work addresses a critical need in the advertising
industry, setting a new standard for privacy-preserving ad measurement
frameworks.

</details>


### [20] [TEMPEST-LoRa: Cross-Technology Covert Communication](https://arxiv.org/abs/2506.21069)
*Xieyang Sun,Yuanqing Zheng,Wei Xi,Zuhao Chen,Zhizhen Chen,Han Hao,Zhiping Jiang,Sheng Zhong*

Main category: cs.CR

TL;DR: 论文提出了一种新型电磁隐蔽信道TEMPEST-LoRa，利用视频电缆的电磁泄漏，通过LoRa接收器远距离传输敏感数据，最大距离87.5米，速率21.6 kbps。


<details>
  <summary>Details</summary>
Motivation: 电磁隐蔽信道对隔离网络的安全构成威胁，现有方法需要近距离部署专用接收器，限制了实际影响。本文旨在探索一种更隐蔽、远距离的传输方式。

Method: 利用视频电缆的电磁泄漏，通过Cross-Technology Covert Communication (CTCC)技术调制数据，使用商业LoRa节点/网关接收。

Result: 实验证明，攻击者可在87.5米距离内以21.6 kbps速率可靠解码数据，且显示器关闭时仍可传输。

Conclusion: TEMPEST-LoRa展示了电磁隐蔽信道的潜在风险，需引起安全社区的重视。

Abstract: Electromagnetic (EM) covert channels pose significant threats to computer and
communications security in air-gapped networks. Previous works exploit EM
radiation from various components (e.g., video cables, memory buses, CPUs) to
secretly send sensitive information. These approaches typically require the
attacker to deploy highly specialized receivers near the victim, which limits
their real-world impact. This paper reports a new EM covert channel,
TEMPEST-LoRa, that builds on Cross-Technology Covert Communication (CTCC),
which could allow attackers to covertly transmit EM-modulated secret data from
air-gapped networks to widely deployed operational LoRa receivers from afar. We
reveal the potential risk and demonstrate the feasibility of CTCC by tackling
practical challenges involved in manipulating video cables to precisely
generate the EM leakage that could readily be received by third-party
commercial LoRa nodes/gateways. Experiment results show that attackers can
reliably decode secret data modulated by the EM leakage from a video cable at a
maximum distance of 87.5m or a rate of 21.6 kbps. We note that the secret data
transmission can be performed with monitors turned off (therefore covertly).

</details>


### [21] [PhishKey: A Novel Centroid-Based Approach for Enhanced Phishing Detection Using Adaptive HTML Component Extraction](https://arxiv.org/abs/2506.21106)
*Felipe Castaño,Eduardo Fidalgo,Enrique Alegre,Rocio Alaiz-Rodríguez,Raul Orduna,Francesco Zola*

Main category: cs.CR

TL;DR: PhishKey是一种新型钓鱼检测方法，结合了URL分类和HTML内容分析，通过软投票集成实现高准确率。


<details>
  <summary>Details</summary>
Motivation: 钓鱼攻击快速演变，绕过检测机制并利用人类弱点，需要一种适应性、鲁棒性和高效性的解决方案。

Method: PhishKey使用自动特征提取，结合字符级CNN处理URL和CAPE处理HTML内容，通过软投票集成结果。

Result: 在四个数据集上测试，F1分数高达98.70%，对抗性攻击表现优异。

Conclusion: PhishKey在钓鱼检测中表现出高效性和鲁棒性，适用于实际应用。

Abstract: Phishing attacks pose a significant cybersecurity threat, evolving rapidly to
bypass detection mechanisms and exploit human vulnerabilities. This paper
introduces PhishKey to address the challenges of adaptability, robustness, and
efficiency. PhishKey is a novel phishing detection method using automatic
feature extraction from hybrid sources. PhishKey combines character-level
processing with Convolutional Neural Networks (CNN) for URL classification, and
a Centroid-Based Key Component Phishing Extractor (CAPE) for HTML content at
the word level. CAPE reduces noise and ensures complete sample processing
avoiding crop operations on the input data. The predictions from both modules
are integrated using a soft-voting ensemble to achieve more accurate and
reliable classifications. Experimental evaluations on four state-of-the-art
datasets demonstrate the effectiveness of PhishKey. It achieves up to 98.70% F1
Score and shows strong resistance to adversarial manipulations such as
injection attacks with minimal performance degradation.

</details>


### [22] [Inside Job: Defending Kubernetes Clusters Against Network Misconfigurations](https://arxiv.org/abs/2506.21134)
*Jacopo Bufalino,Jose Luis Martin-Navarro,Mario Di Francesco,Tuomas Aura*

Main category: cs.CR

TL;DR: 该论文分析了Kubernetes集群中网络配置对安全性的影响，重点关注横向移动问题，并评估了287个开源应用，发现了634个配置错误。


<details>
  <summary>Details</summary>
Motivation: Kubernetes的普及使其成为恶意攻击的目标，但网络配置对安全的影响研究不足。

Method: 对287个开源应用进行网络配置分析，重点关注横向移动问题。

Result: 发现634个配置错误，远超现有解决方案的发现能力，部分问题已修复。

Conclusion: 网络配置对Kubernetes安全至关重要，需更多关注和改进。

Abstract: Kubernetes has emerged as the de facto standard for container orchestration.
Unfortunately, its increasing popularity has also made it an attractive target
for malicious actors. Despite extensive research on securing Kubernetes, little
attention has been paid to the impact of network configuration on the security
of application deployments. This paper addresses this gap by conducting a
comprehensive analysis of network misconfigurations in a Kubernetes cluster
with specific reference to lateral movement. Accordingly, we carried out an
extensive evaluation of 287 open-source applications belonging to six different
organizations, ranging from IT companies and public entities to non-profits. As
a result, we identified 634 misconfigurations, well beyond what could be found
by solutions in the state of the art. We responsibly disclosed our findings to
the concerned organizations and engaged in a discussion to assess their
severity. As of now, misconfigurations affecting more than thirty applications
have been fixed with the mitigations we proposed.

</details>


### [23] [Balancing Privacy and Utility in Correlated Data: A Study of Bayesian Differential Privacy](https://arxiv.org/abs/2506.21308)
*Martin Lange,Patricia Guerra-Balboa,Javier Parra-Arnau,Thorsten Strufe*

Main category: cs.CR

TL;DR: 研究探讨了贝叶斯差分隐私（BDP）在现实数据中的实用性，提出了一种新方法以在相关性数据中保持隐私和实用性。


<details>
  <summary>Details</summary>
Motivation: 标准差分隐私（DP）在数据相关时低估隐私泄露风险，BDP虽能解决此问题但实用性不足，限制了其应用。

Method: 通过分析高斯多元分布和马尔可夫链等模型，提出理论联系和新方法，将DP机制适配为BDP。

Result: 在真实数据上验证了新定理的有效性，设计的BDP机制在保持隐私的同时实用性良好。

Conclusion: 研究为相关性数据中的隐私保护提供了实用解决方案，推动了BDP的实际应用。

Abstract: Privacy risks in differentially private (DP) systems increase significantly
when data is correlated, as standard DP metrics often underestimate the
resulting privacy leakage, leaving sensitive information vulnerable. Given the
ubiquity of dependencies in real-world databases, this oversight poses a
critical challenge for privacy protections. Bayesian differential privacy (BDP)
extends DP to account for these correlations, yet current BDP mechanisms
indicate notable utility loss, limiting its adoption.
  In this work, we address whether BDP can be realistically implemented in
common data structures without sacrificing utility -- a key factor for its
applicability. By analyzing arbitrary and structured correlation models,
including Gaussian multivariate distributions and Markov chains, we derive
practical utility guarantees for BDP. Our contributions include theoretical
links between DP and BDP and a novel methodology for adapting DP mechanisms to
meet the BDP requirements. Through evaluations on real-world databases, we
demonstrate that our novel theorems enable the design of BDP mechanisms that
maintain competitive utility, paving the way for practical privacy-preserving
data practices in correlated settings.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [24] [The Singapore Consensus on Global AI Safety Research Priorities](https://arxiv.org/abs/2506.20702)
*Yoshua Bengio,Tegan Maharaj,Luke Ong,Stuart Russell,Dawn Song,Max Tegmark,Lan Xue,Ya-Qin Zhang,Stephen Casper,Wan Sie Lee,Sören Mindermann,Vanessa Wilfred,Vidhisha Balachandran,Fazl Barez,Michael Belinsky,Imane Bello,Malo Bourgon,Mark Brakel,Siméon Campos,Duncan Cass-Beggs,Jiahao Chen,Rumman Chowdhury,Kuan Chua Seah,Jeff Clune,Juntao Dai,Agnes Delaborde,Nouha Dziri,Francisco Eiras,Joshua Engels,Jinyu Fan,Adam Gleave,Noah Goodman,Fynn Heide,Dan Hendrycks,Cyrus Hodes,Bryan Low Kian Hsiang,Minlie Huang,Sami Jawhar,Wang Jingyu,Adam Tauman Kalai,Meindert Kamphuis,Mohan Kankanhalli,Subhash Kantamneni,Mathias Bonde Kirk,Thomas Kwa,Jeffrey Ladish,Kwok-Yan Lam,Wan Lee Sie,Taewhi Lee,Xiaojian Li,Jiajun Liu,Chaochao Lu,Yifan Mai,Richard Mallah,Julian Michael,Nick Moës,Simon Möller,Kihyuk Nam,Kwan Yee Ng,Mark Nitzberg,Besmira Nushi,Seán O hÉigeartaigh,Alejandro Ortega,Pierre Peigné,James Petrie,Benjamin Prud'Homme,Reihaneh Rabbany,Nayat Sanchez-Pi,Sarah Schwettmann,Buck Shlegeris,Saad Siddiqui,Aradhana Sinha,Martín Soto,Cheston Tan,Dong Ting,Robert Trager,Brian Tse,Anthony Tung K. H.,Vanessa Wilfred,John Willes,Denise Wong,Wei Xu,Rongwu Xu,Yi Zeng,HongJiang Zhang,Djordje Žikelić*

Main category: cs.AI

TL;DR: 新加坡2025年AI会议（SCAI）旨在通过国际合作推动AI安全研究，提出开发、评估和控制三大领域的挑战。


<details>
  <summary>Details</summary>
Motivation: AI的快速发展和自主性带来了巨大潜力，但也引发了如何确保AI安全、可靠和可信的讨论。

Method: 采用深度防御模型，将AI安全研究分为开发、评估和控制三大领域。

Result: 报告基于国际AI安全报告，提出了AI安全研究的优先方向。

Conclusion: 构建可信的AI生态系统对促进创新和避免反弹至关重要。

Abstract: Rapidly improving AI capabilities and autonomy hold significant promise of
transformation, but are also driving vigorous debate on how to ensure that AI
is safe, i.e., trustworthy, reliable, and secure. Building a trusted ecosystem
is therefore essential -- it helps people embrace AI with confidence and gives
maximal space for innovation while avoiding backlash.
  The "2025 Singapore Conference on AI (SCAI): International Scientific
Exchange on AI Safety" aimed to support research in this space by bringing
together AI scientists across geographies to identify and synthesise research
priorities in AI safety. This resulting report builds on the International AI
Safety Report chaired by Yoshua Bengio and backed by 33 governments. By
adopting a defence-in-depth model, this report organises AI safety research
domains into three types: challenges with creating trustworthy AI systems
(Development), challenges with evaluating their risks (Assessment), and
challenges with monitoring and intervening after deployment (Control).

</details>


### [25] [MAGPIE: A dataset for Multi-AGent contextual PrIvacy Evaluation](https://arxiv.org/abs/2506.20737)
*Gurusha Juneja,Alon Albalak,Wenyue Hua,William Yang Wang*

Main category: cs.AI

TL;DR: 论文研究了基于LLM的代理在协作任务中是否理解上下文隐私，并评估了现有模型在保护隐私方面的表现。结果表明，当前模型在隐私保护和任务完成方面存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 随着LLM代理的广泛应用，隐私保护成为关键问题，尤其是在多代理协作任务中。现有基准测试仅针对简单任务，缺乏对复杂场景下隐私保护的评估。

Method: 提出了一个名为MAGPIE的基准测试，包含158个高风险场景，评估模型对上下文隐私的理解和协作能力。

Result: 实验显示，当前模型（如GPT-4o和Claude-2.7-Sonnet）在隐私分类和多轮对话中泄露隐私的比例较高，且多代理系统在71%的场景中无法完成任务。

Conclusion: 当前模型在上下文隐私保护和协作任务解决方面尚未达到理想水平，亟需改进。

Abstract: The proliferation of LLM-based agents has led to increasing deployment of
inter-agent collaboration for tasks like scheduling, negotiation, resource
allocation etc. In such systems, privacy is critical, as agents often access
proprietary tools and domain-specific databases requiring strict
confidentiality. This paper examines whether LLM-based agents demonstrate an
understanding of contextual privacy. And, if instructed, do these systems
preserve inference time user privacy in non-adversarial multi-turn
conversation. Existing benchmarks to evaluate contextual privacy in LLM-agents
primarily assess single-turn, low-complexity tasks where private information
can be easily excluded. We first present a benchmark - MAGPIE comprising 158
real-life high-stakes scenarios across 15 domains. These scenarios are designed
such that complete exclusion of private data impedes task completion yet
unrestricted information sharing could lead to substantial losses. We then
evaluate the current state-of-the-art LLMs on (a) their understanding of
contextually private data and (b) their ability to collaborate without
violating user privacy. Empirical experiments demonstrate that current models,
including GPT-4o and Claude-2.7-Sonnet, lack robust understanding of contextual
privacy, misclassifying private data as shareable 25.2\% and 43.6\% of the
time. In multi-turn conversations, these models disclose private information in
59.9\% and 50.5\% of cases even under explicit privacy instructions.
Furthermore, multi-agent systems fail to complete tasks in 71\% of scenarios.
These results underscore that current models are not aligned towards both
contextual privacy preservation and collaborative task-solving.

</details>


### [26] [Dynamic Context-Aware Prompt Recommendation for Domain-Specific AI Applications](https://arxiv.org/abs/2506.20815)
*Xinye Tang,Haijun Zhai,Chaitanya Belwal,Vineeth Thayanithi,Philip Baumann,Yogesh K Roy*

Main category: cs.AI

TL;DR: 提出了一种动态上下文感知提示推荐系统，用于领域特定AI应用，通过多阶段推理和模板生成高质量提示。


<details>
  <summary>Details</summary>
Motivation: LLM应用对用户提示质量敏感，领域特定应用中高质量提示难以设计。

Method: 结合上下文查询分析、检索增强知识基础、分层技能组织和自适应技能排名。

Result: 实验显示方法在实用性和相关性上表现优异，通过自动和专家评估验证。

Conclusion: 系统能有效生成高质量提示，提升领域特定AI应用的用户体验。

Abstract: LLM-powered applications are highly susceptible to the quality of user
prompts, and crafting high-quality prompts can often be challenging especially
for domain-specific applications. This paper presents a novel dynamic
context-aware prompt recommendation system for domain-specific AI applications.
Our solution combines contextual query analysis, retrieval-augmented knowledge
grounding, hierarchical skill organization, and adaptive skill ranking to
generate relevant and actionable prompt suggestions.
  The system leverages behavioral telemetry and a two-stage hierarchical
reasoning process to dynamically select and rank relevant skills, and
synthesizes prompts using both predefined and adaptive templates enhanced with
few-shot learning. Experiments on real-world datasets demonstrate that our
approach achieves high usefulness and relevance, as validated by both automated
and expert evaluations.

</details>


### [27] [Beyond Reactive Safety: Risk-Aware LLM Alignment via Long-Horizon Simulation](https://arxiv.org/abs/2506.20949)
*Chenkai Sun,Denghui Zhang,ChengXiang Zhai,Heng Ji*

Main category: cs.AI

TL;DR: 论文提出了一种框架，用于评估语言模型建议的宏观社会影响，并引入了一个间接危害场景数据集，以提高模型的安全意识。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型在高风险社会决策中的影响力增加，需要理解其建议的深远影响以确保其有益性。

Method: 提出了一个概念验证框架，用于模拟模型建议在宏观社会系统中的传播，并引入了一个包含100个间接危害场景的数据集。

Result: 新数据集上性能提升超过20%，在现有安全基准上平均胜率超过70%。

Conclusion: 该方法为提高语言模型安全性提供了有前景的方向。

Abstract: Given the growing influence of language model-based agents on high-stakes
societal decisions, from public policy to healthcare, ensuring their beneficial
impact requires understanding the far-reaching implications of their
suggestions. We propose a proof-of-concept framework that projects how
model-generated advice could propagate through societal systems on a
macroscopic scale over time, enabling more robust alignment. To assess the
long-term safety awareness of language models, we also introduce a dataset of
100 indirect harm scenarios, testing models' ability to foresee adverse,
non-obvious outcomes from seemingly harmless user prompts. Our approach
achieves not only over 20% improvement on the new dataset but also an average
win rate exceeding 70% against strong baselines on existing safety benchmarks
(AdvBench, SafeRLHF, WildGuardMix), suggesting a promising direction for safer
agents.

</details>


### [28] [Unveiling Causal Reasoning in Large Language Models: Reality or Mirage?](https://arxiv.org/abs/2506.21215)
*Haoang Chi,He Li,Wenjing Yang,Feng Liu,Long Lan,Xiaoguang Ren,Tongliang Liu,Bo Han*

Main category: cs.AI

TL;DR: 论文探讨了大型语言模型（LLMs）的因果推理能力，发现其仅能进行浅层（level-1）推理，缺乏人类般的深层（level-2）能力。作者提出G^2-Reasoner方法，结合通用知识和目标导向提示，显著提升了LLMs的因果推理能力。


<details>
  <summary>Details</summary>
Motivation: 研究动机是评估LLMs是否具备类似人类的真实因果推理能力，并探索提升其能力的途径。

Method: 通过分析LLMs的自回归机制，并引入新基准CausalProbe-2024进行实证检验。提出G^2-Reasoner方法，整合通用知识和目标导向提示。

Result: LLMs在CausalProbe-2024上表现显著下降，证实其仅能进行level-1推理。G^2-Reasoner显著提升了LLMs在新鲜和反事实情境中的推理能力。

Conclusion: LLMs当前仅具备浅层因果推理能力，但通过结合通用知识和目标导向提示，有望迈向level-2推理。G^2-Reasoner为这一目标提供了新路径。

Abstract: Causal reasoning capability is critical in advancing large language models
(LLMs) toward strong artificial intelligence. While versatile LLMs appear to
have demonstrated capabilities in understanding contextual causality and
providing responses that obey the laws of causality, it remains unclear whether
they perform genuine causal reasoning akin to humans. However, current evidence
indicates the contrary. Specifically, LLMs are only capable of performing
shallow (level-1) causal reasoning, primarily attributed to the causal
knowledge embedded in their parameters, but they lack the capacity for genuine
human-like (level-2) causal reasoning. To support this hypothesis,
methodologically, we delve into the autoregression mechanism of
transformer-based LLMs, revealing that it is not inherently causal.
Empirically, we introduce a new causal Q&A benchmark called CausalProbe-2024,
whose corpora are fresh and nearly unseen for the studied LLMs. The LLMs
exhibit a significant performance drop on CausalProbe-2024 compared to earlier
benchmarks, indicating the fact that they primarily engage in level-1 causal
reasoning. To bridge the gap towards level-2 causal reasoning, we draw
inspiration from the fact that human reasoning is usually facilitated by
general knowledge and intended goals. We propose G^2-Reasoner, a method that
incorporates general knowledge and goal-oriented prompts into LLMs' causal
reasoning processes. Experiments demonstrate that G^2-Reasoner significantly
enhances LLMs' causal reasoning capability, particularly in fresh and
counterfactual contexts. This work sheds light on a new path for LLMs to
advance towards genuine causal reasoning, going beyond level-1 and making
strides towards level-2.

</details>


### [29] [World-aware Planning Narratives Enhance Large Vision-Language Model Planner](https://arxiv.org/abs/2506.21230)
*Junhao Shi,Zhaoye Fei,Siyin Wang,Qipeng Guo,Jingjing Gong,Xipeng QIu*

Main category: cs.AI

TL;DR: WAP框架通过四种认知能力增强LVLMs的环境理解能力，显著提升了任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有LVLMs在复杂场景中表现不佳，缺乏环境感知能力。

Method: 提出WAP框架，结合视觉外观建模、空间推理等功能，通过课程学习训练模型。

Result: 在EB-ALFRED基准上，任务成功率显著提升，超越GPT-4o等专有系统。

Conclusion: WAP框架有效提升了LVLMs在复杂任务中的表现。

Abstract: Large Vision-Language Models (LVLMs) show promise for embodied planning tasks
but struggle with complex scenarios involving unfamiliar environments and
multi-step goals. Current approaches rely on environment-agnostic imitation
learning that disconnects instructions from environmental contexts, causing
models to struggle with context-sensitive instructions and rely on
supplementary cues rather than visual reasoning during long-horizon
interactions. In this work, we propose World-Aware Planning Narrative
Enhancement (WAP), a framework that infuses LVLMs with comprehensive
environmental understanding through four cognitive capabilities (visual
appearance modeling, spatial reasoning, functional abstraction, and syntactic
grounding) while developing and evaluating models using only raw visual
observations through curriculum learning. Evaluations on the EB-ALFRED
benchmark demonstrate substantial improvements, with Qwen2.5-VL achieving a
60.7 absolute improvement in task success rates, particularly in commonsense
reasoning (+60.0) and long-horizon planning (+70.0). Notably, our enhanced
open-source models outperform proprietary systems like GPT-4o and
Claude-3.5-Sonnet by a large margin.

</details>


### [30] [IXAII: An Interactive Explainable Artificial Intelligence Interface for Decision Support Systems](https://arxiv.org/abs/2506.21310)
*Pauline Speckmann,Mario Nadj,Christian Janiesch*

Main category: cs.AI

TL;DR: IXAII是一个交互式可解释AI系统，整合了LIME、SHAP、Anchors和DiCE四种方法，提供定制化解释视图，用户可控制解释内容和格式。


<details>
  <summary>Details</summary>
Motivation: 现有可解释AI方法多为静态且忽视用户视角，限制了其实际效果。

Method: 开发IXAII系统，支持四种解释方法，并为五类用户群体提供定制视图。通过专家和普通用户访谈评估。

Result: IXAII通过多解释方法和可视化选项提高了透明度，用户认为其有帮助。

Conclusion: IXAII在可解释AI方法、交互性和实际应用间架起桥梁，为AI解释实践和人机交互提供了新视角。

Abstract: Although several post-hoc methods for explainable AI have been developed,
most are static and neglect the user perspective, limiting their effectiveness
for the target audience. In response, we developed the interactive explainable
intelligent system called IXAII that offers explanations from four explainable
AI methods: LIME, SHAP, Anchors, and DiCE. Our prototype provides tailored
views for five user groups and gives users agency over the explanations'
content and their format. We evaluated IXAII through interviews with experts
and lay users. Our results indicate that IXAII, which provides different
explanations with multiple visualization options, is perceived as helpful to
increase transparency. By bridging the gaps between explainable AI methods,
interactivity, and practical implementation, we provide a novel perspective on
AI explanation practices and human-AI interaction.

</details>


### [31] [Active Inference AI Systems for Scientific Discovery](https://arxiv.org/abs/2506.21329)
*Karthik Duraisamy*

Main category: cs.AI

TL;DR: 论文提出AI驱动的科学发现需解决抽象、推理和现实三大差距，而非依赖模型规模或数据。通过主动推理系统结合因果模型、贝叶斯规划和知识图谱，实现闭环验证与人类判断的结合。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统在科学发现中存在架构限制和推理脆弱性，需通过解决三大差距推动进步。

Method: 提出主动推理AI系统，结合因果自监督模型、贝叶斯规划、知识图谱及闭环实验验证。

Result: 系统通过内部模型与外部验证的交互实现科学发现，强调人类判断的不可或缺性。

Conclusion: 科学发现的未来依赖于结合AI推理与人类判断的闭环系统，而非单纯扩大模型规模。

Abstract: The rapid evolution of artificial intelligence has led to expectations of
transformative scientific discovery, yet current systems remain fundamentally
limited by their operational architectures, brittle reasoning mechanisms, and
their separation from experimental reality. Building on earlier work, we
contend that progress in AI-driven science now depends on closing three
fundamental gaps -- the abstraction gap, the reasoning gap, and the reality gap
-- rather than on model size/data/test time compute. Scientific reasoning
demands internal representations that support simulation of actions and
response, causal structures that distinguish correlation from mechanism, and
continuous calibration. We define active inference AI systems for scientific
discovery as those that (i) maintain long-lived research memories grounded in
causal self-supervised foundation models, (ii) symbolic or neuro-symbolic
planners equipped with Bayesian guardrails, (iii) grow persistent knowledge
graphs where thinking generates novel conceptual nodes, reasoning establishes
causal edges, and real-world interaction prunes false connections while
strengthening verified pathways, and (iv) refine their internal representations
through closed-loop interaction with both high-fidelity simulators and
automated laboratories - an operational loop where mental simulation guides
action and empirical surprise reshapes understanding. In essence, we outline an
architecture where discovery arises from the interplay between internal models
that enable counterfactual reasoning and external validation that grounds
hypotheses in reality. It is also argued that the inherent ambiguity in
feedback from simulations and experiments, and underlying uncertainties makes
human judgment indispensable, not as a temporary scaffold but as a permanent
architectural component.

</details>


### [32] [TableMoE: Neuro-Symbolic Routing for Structured Expert Reasoning in Multimodal Table Understanding](https://arxiv.org/abs/2506.21393)
*Junwen Zhang,Pu Chen,Yin Zhang*

Main category: cs.AI

TL;DR: TableMoE提出了一种神经符号混合专家架构，用于处理复杂多模态表格数据，显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 解决现有多模态大语言模型在复杂表格数据（如模糊、倾斜、嵌套布局等）中表现不佳的问题。

Method: 采用神经符号路由机制，动态分配表格元素到专用专家模块，并结合大规模预训练数据集TableMoE-Align。

Result: TableMoE在多个WildStruct基准测试中显著优于现有模型，验证了神经符号路由和专家对齐的有效性。

Conclusion: TableMoE通过神经符号推理提升了多模态表格理解的鲁棒性和可解释性。

Abstract: Multimodal understanding of tables in real-world contexts is challenging due
to the complexity of structure, symbolic density, and visual degradation (blur,
skew, watermarking, incomplete structures or fonts, multi-span or
hierarchically nested layouts). Existing multimodal large language models
(MLLMs) struggle with such WildStruct conditions, resulting in limited
performance and poor generalization. To address these challenges, we propose
TableMoE, a neuro-symbolic Mixture-of-Connector-Experts (MoCE) architecture
specifically designed for robust, structured reasoning over multimodal table
data. TableMoE features an innovative Neuro-Symbolic Routing mechanism, which
predicts latent semantic token roles (e.g., header, data cell, axis, formula)
and dynamically routes table elements to specialized experts (Table-to-HTML,
Table-to-JSON, Table-to-Code) using a confidence-aware gating strategy informed
by symbolic reasoning graphs. To facilitate effective alignment-driven
pretraining, we introduce the large-scale TableMoE-Align dataset, consisting of
1.2M table-HTML-JSON-code quadruples across finance, science, biomedicine and
industry, utilized exclusively for model pretraining. For evaluation, we curate
and release four challenging WildStruct benchmarks: WMMFinQA, WMMTatQA,
WMMTabDialog, and WMMFinanceMath, designed specifically to stress-test models
under real-world multimodal degradation and structural complexity. Experimental
results demonstrate that TableMoE significantly surpasses existing
state-of-the-art models. Extensive ablation studies validate each core
component, emphasizing the critical role of Neuro-Symbolic Routing and
structured expert alignment. Through qualitative analyses, we further showcase
TableMoE's interpretability and enhanced robustness, underscoring the
effectiveness of integrating neuro-symbolic reasoning for multimodal table
understanding.

</details>


### [33] [Spatial Mental Modeling from Limited Views](https://arxiv.org/abs/2506.21458)
*Baiqiao Yin,Qineng Wang,Pingyue Zhang,Jianshu Zhang,Kangrui Wang,Zihan Wang,Jieyu Zhang,Keshigeyan Chandrasegaran,Han Liu,Ranjay Krishna,Saining Xie,Manling Li,Jiajun Wu,Li Fei-Fei*

Main category: cs.AI

TL;DR: MindCube基准测试揭示了现有视觉语言模型（VLMs）在构建空间心理模型方面的不足，通过“map-then-reason”方法显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 探索视觉语言模型是否能像人类一样从少量视角构建完整的空间心理模型。

Method: 使用MindCube基准测试评估VLMs的空间心理模型能力，并提出三种改进方法，最终采用“map-then-reason”联合训练策略。

Result: 通过“map-then-reason”方法，准确率从37.8%提升至60.8%，结合强化学习后达到70.7%。

Conclusion: 构建和利用内部结构化空间表示能显著提升对不可观察空间的理解。

Abstract: Can Vision Language Models (VLMs) imagine the full scene from just a few
views, like humans do? Humans form spatial mental models, internal
representations of unseen space, to reason about layout, perspective, and
motion. Our new MindCube benchmark with 21,154 questions across 3,268 images
exposes this critical gap, where existing VLMs exhibit near-random performance.
Using MindCube, we systematically evaluate how well VLMs build robust spatial
mental models through representing positions (cognitive mapping), orientations
(perspective-taking), and dynamics (mental simulation for "what-if" movements).
We then explore three approaches to help VLMs approximate spatial mental
models, including unseen intermediate views, natural language reasoning chains,
and cognitive maps. The significant improvement comes from a synergistic
approach, "map-then-reason", that jointly trains the model to first generate a
cognitive map and then reason upon it. By training models to reason over these
internal maps, we boosted accuracy from 37.8% to 60.8% (+23.0%). Adding
reinforcement learning pushed performance even further to 70.7% (+32.9%). Our
key insight is that such scaffolding of spatial mental models, actively
constructing and utilizing internal structured spatial representations with
flexible reasoning processes, significantly improves understanding of
unobservable space.

</details>


### [34] [Ad-Hoc Human-AI Coordination Challenge](https://arxiv.org/abs/2506.21490)
*Tin Dizdarević,Ravi Hammond,Tobias Gessler,Anisoara Calinescu,Jonathan Cook,Matteo Gallici,Andrei Lupu,Jakob Nicolaus Foerster*

Main category: cs.AI

TL;DR: 论文提出了Ad-Hoc Human-AI Coordination Challenge (AH2AC2)，通过开发人类代理代理解决人类评估的高成本和难以复现问题，并开源了一个有限的人类游戏数据集。


<details>
  <summary>Details</summary>
Motivation: 实现AI代理与人类的无缝协调是现实应用中的关键挑战，但人类评估的高成本和难以复现限制了Hanabi游戏在人类-AI交互中的应用。

Method: 开发了基于大规模人类数据集的“人类代理代理”，作为廉价、可复现的评估伙伴，并开源了3,079局游戏的有限数据集。

Result: 提出了AH2AC2挑战，并展示了双人和三人Hanabi场景的基线结果。

Conclusion: 通过人类代理代理和有限数据集，AH2AC2为人类-AI协调研究提供了廉价且可复现的评估方法。

Abstract: Achieving seamless coordination between AI agents and humans is crucial for
real-world applications, yet it remains a significant open challenge. Hanabi is
a cooperative card game featuring imperfect information, constrained
communication, theory of mind requirements, and coordinated action -- making it
an ideal testbed for human-AI coordination. However, its use for human-AI
interaction has been limited by the challenges of human evaluation. In this
work, we introduce the Ad-Hoc Human-AI Coordination Challenge (AH2AC2) to
overcome the constraints of costly and difficult-to-reproduce human
evaluations. We develop \textit{human proxy agents} on a large-scale human
dataset that serve as robust, cheap, and reproducible human-like evaluation
partners in AH2AC2. To encourage the development of data-efficient methods, we
open-source a dataset of 3,079 games, deliberately limiting the amount of
available human gameplay data. We present baseline results for both two- and
three- player Hanabi scenarios. To ensure fair evaluation, we host the proxy
agents through a controlled evaluation system rather than releasing them
publicly. The code is available at
\href{https://github.com/FLAIROx/ah2ac2}{https://github.com/FLAIROx/ah2ac2}.

</details>


### [35] [Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge](https://arxiv.org/abs/2506.21506)
*Boyu Gou,Zanming Huang,Yuting Ning,Yu Gu,Michael Lin,Weijian Qi,Andrei Kopanev,Botao Yu,Bernal Jiménez Gutiérrez,Yiheng Shu,Chan Hee Song,Jiaman Wu,Shijie Chen,Hanane Nour Moussa,Tianshu Zhang,Jian Xie,Yifei Li,Tianci Xue,Zeyi Liao,Kai Zhang,Boyuan Zheng,Zhaowei Cai,Viktor Rozgic,Morteza Ziyadi,Huan Sun,Yu Su*

Main category: cs.AI

TL;DR: Mind2Web 2是一个包含130个长时任务的新基准，用于评估自主网络搜索系统的性能，并提出了一种基于树形评分的自动评估框架。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法无法应对自主搜索系统的复杂性和开放性，需要更全面的基准和方法。

Method: 提出Mind2Web 2基准和Agent-as-a-Judge框架，通过任务特定评分代理自动评估答案正确性和来源引用。

Result: OpenAI Deep Research系统表现最佳，达到人类性能的50-70%，且耗时减半。

Conclusion: Mind2Web 2为下一代自主搜索系统的开发和评估提供了坚实基础。

Abstract: Agentic search such as Deep Research systems, where large language models
autonomously browse the web, synthesize information, and return comprehensive
citation-backed answers, represents a major shift in how users interact with
web-scale information. While promising greater efficiency and cognitive
offloading, the growing complexity and open-endedness of agentic search have
outpaced existing evaluation benchmarks and methodologies, which largely assume
short search horizons and static answers. In this paper, we introduce Mind2Web
2, a benchmark of 130 realistic, high-quality, and long-horizon tasks that
require real-time web browsing and extensive information synthesis, constructed
with over 1,000 hours of human labor. To address the challenge of evaluating
time-varying and complex answers, we propose a novel Agent-as-a-Judge
framework. Our method constructs task-specific judge agents based on a
tree-structured rubric design to automatically assess both answer correctness
and source attribution. We conduct a comprehensive evaluation of nine frontier
agentic search systems and human performance, along with a detailed error
analysis to draw insights for future development. The best-performing system,
OpenAI Deep Research, can already achieve 50-70% of human performance while
spending half the time, showing a great potential. Altogether, Mind2Web 2
provides a rigorous foundation for developing and benchmarking the next
generation of agentic search systems.

</details>


### [36] [PsyLite Technical Report](https://arxiv.org/abs/2506.21536)
*Fangjun Ding,Renyu Zhang,Xinyu Feng,Chengye Xie,Zheng Zhang,Yanting Zhang*

Main category: cs.AI

TL;DR: PsyLite是一个基于InternLM2.5-7B-chat的轻量级心理咨询大语言模型，通过两阶段训练策略提升推理能力、心理咨询能力和对话安全性，并在资源受限环境中实现低硬件部署。


<details>
  <summary>Details</summary>
Motivation: 现有AI心理咨询模型在对话安全、场景处理和轻量化部署方面存在不足，需要改进。

Method: 采用混合蒸馏数据微调和ORPO偏好优化的两阶段训练策略，结合条件RAG引入幽默元素并拒绝危险请求。

Result: 在CEval、CPsyCounE和SafeDialBench评估中表现优异，心理咨询专业性提升47.6%，对话安全性提升2.4%，且仅需5GB内存。

Conclusion: PsyLite为资源受限环境提供了可行的心理咨询解决方案，显著提升了模型性能和安全性。

Abstract: With the rapid development of digital technology, AI-driven psychological
counseling has gradually become an important research direction in the field of
mental health. However, existing models still have deficiencies in dialogue
safety, detailed scenario handling, and lightweight deployment. To address
these issues, this study proposes PsyLite, a lightweight psychological
counseling large language model agent developed based on the base model
InternLM2.5-7B-chat. Through a two-stage training strategy (hybrid distillation
data fine-tuning and ORPO preference optimization), PsyLite enhances the
model's deep-reasoning ability, psychological counseling ability, and safe
dialogue ability. After deployment using Ollama and Open WebUI, a custom
workflow is created with Pipelines. An innovative conditional RAG is designed
to introduce crosstalk humor elements at appropriate times during psychological
counseling to enhance user experience and decline dangerous requests to
strengthen dialogue safety. Evaluations show that PsyLite outperforms the
baseline models in the Chinese general evaluation (CEval), psychological
counseling professional evaluation (CPsyCounE), and dialogue safety evaluation
(SafeDialBench), particularly in psychological counseling professionalism
(CPsyCounE score improvement of 47.6\%) and dialogue safety (\safe{} score
improvement of 2.4\%). Additionally, the model uses quantization technology
(GGUF q4\_k\_m) to achieve low hardware deployment (5GB memory is sufficient
for operation), providing a feasible solution for psychological counseling
applications in resource-constrained environments.

</details>
