<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 14]
- [cs.CR](#cs.CR) [Total: 17]
- [cs.SE](#cs.SE) [Total: 11]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [A Small-Scale System for Autoregressive Program Synthesis Enabling Controlled Experimentation](https://arxiv.org/abs/2602.09112)
*Russ Webb,Jason Ramapuram*

Main category: cs.AI

TL;DR: Cadmus系统：一个低成本小模型程序合成研究平台，用于研究程序补全、分布外表示、归纳推理和指令跟随，在特定任务上超越GPT-5


<details>
  <summary>Details</summary>
Motivation: 当前程序合成研究主要依赖大型语言模型，存在分布问题不明确、微调效果难理解、分词影响不清晰、计算存储成本高等问题。需要一个小型、透明、可控的研究平台来深入理解程序合成的本质机制。

Method: 开发了Cadmus系统，包含整数虚拟机、多样化真实程序数据集和自回归Transformer模型，训练成本低于200美元。该系统允许研究者精细控制训练分布，并能检查和插装模型。

Result: Cadmus模型在特定领域语言（DSL）的整数算术程序补全任务上达到100%准确率，优于GPT-5的95%。同时揭示了GPT-5在解决相同任务时引入了未知的先验知识，这成为使用大规模LLM进行研究时的混杂因素。

Conclusion: 小型模型在复杂推理任务上能够实现更深入的可解释性研究，为程序合成、分布外表示、归纳推理等研究提供了透明、可控、低成本的研究平台，有助于理解模型与训练数据之间的关系。

Abstract: What research can be pursued with small models trained to complete true programs? Typically, researchers study program synthesis via large language models (LLMs) which introduce issues such as knowing what is in or out of distribution, understanding fine-tuning effects, understanding the effects of tokenization, and higher demand on compute and storage to carry out experiments. We present a system called Cadmus which includes an integer virtual machine (VM), a dataset composed of true programs of diverse tasks, and an autoregressive transformer model that is trained for under \$200 of compute cost. The system can be used to study program completion, out-of-distribution representations, inductive reasoning, and instruction following in a setting where researchers have effective and affordable fine-grained control of the training distribution and the ability to inspect and instrument models. Smaller models working on complex reasoning tasks enable instrumentation and investigations that may be prohibitively expensive on larger models. To demonstrate that these tasks are complex enough to be of interest, we show that these Cadmus models outperform GPT-5 (by achieving 100\% accuracy while GPT-5 has 95\% accuracy) even on a simple task of completing correct, integer arithmetic programs in our domain-specific language (DSL) while providing transparency into the dataset's relationship to the problem. We also show that GPT-5 brings unknown priors into its reasoning process when solving the same tasks, demonstrating a confounding factor that prevents the use of large-scale LLMs for some investigations where the training set relationship to the task needs to be fully understood.

</details>


### [2] [PABU: Progress-Aware Belief Update for Efficient LLM Agents](https://arxiv.org/abs/2602.09138)
*Haitao Jiang,Lin Ge,Hengrui Cai,Rui Song*

Main category: cs.AI

TL;DR: PABU框架通过显式建模任务进度和选择性保留历史信息，减少LLM智能体中的冗余动作和推理成本


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体通常基于完整的动作-观察历史来决策，这引入了任务无关信息，导致冗余动作和更高的推理成本

Method: 提出Progress-Aware Belief Update (PABU)框架，通过预测相对进度并选择性保留关键交互信息来紧凑表示智能体状态

Result: 在AgentGym基准的8个环境中，PABU达到81.0%的任务完成率，比基于完整历史的SoTA模型提升23.9%，交互步骤减少26.9%至平均9.5步

Conclusion: PABU通过显式进度预测和选择性保留机制，有效提升了LLM智能体的效率和性能，两者都是实现稳健信念学习和性能提升的必要组件

Abstract: Large Language Model (LLM) agents commonly condition actions on full action-observation histories, which introduce task-irrelevant information that easily leads to redundant actions and higher inference cost. We propose Progress-Aware Belief Update (PABU), a belief-state framework that compactly represents an agent's state by explicitly modeling task progress and selectively retaining past actions and observations. At each step, the agent predicts its relative progress since the previous round and decides whether the newly encountered interaction should be stored, conditioning future decisions only on the retained subset. Across eight environments in the AgentGym benchmark, and using identical training trajectories, PABU achieves an 81.0% task completion rate, outperforming previous State of the art (SoTA) models with full-history belief by 23.9%. Additionally, PABU's progress-oriented action selection improves efficiency, reducing the average number of interaction steps to 9.5, corresponding to a 26.9% reduction. Ablation studies show that both explicit progress prediction and selective retention are necessary for robust belief learning and performance gains.

</details>


### [3] [CoMMa: Contribution-Aware Medical Multi-Agents From A Game-Theoretic Perspective](https://arxiv.org/abs/2602.09159)
*Yichen Wu,Yujin Oh,Sangjoon Park,Kailong Fan,Dania Daye,Hana Farzaneh,Xiang Li,Raul Uppot,Quanzheng Li*

Main category: cs.AI

TL;DR: CoMMa是一个去中心化的医疗多智能体框架，通过博弈论目标和确定性嵌入投影实现贡献感知的信用分配，在肿瘤学决策支持任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有医疗多智能体框架在处理需要动态、异构患者数据推理的肿瘤学决策支持任务时存在局限性，大多数基于随机叙事推理的架构缺乏明确的证据归因和稳定性。

Method: 提出CoMMa框架：1) 去中心化LLM智能体架构，专家在分区证据上操作；2) 通过博弈论目标进行协调；3) 使用确定性嵌入投影近似贡献感知信用分配；4) 通过估计每个智能体的边际效用实现明确的证据归因。

Result: 在多样化的肿瘤学基准测试（包括真实世界多学科肿瘤委员会数据集）上，CoMMa相比数据集中化和基于角色的多智能体基线，实现了更高的准确性和更稳定的性能。

Conclusion: CoMMa通过贡献感知的信用分配机制，为医疗决策支持提供了可解释、数学基础扎实且稳定的决策路径，在肿瘤学多智能体决策中展现出优越性。

Abstract: Recent multi-agent frameworks have broadened the ability to tackle oncology decision support tasks that require reasoning over dynamic, heterogeneous patient data. We propose Contribution-Aware Medical Multi-Agents (CoMMa), a decentralized LLM-agent framework in which specialists operate on partitioned evidence and coordinate through a game-theoretic objective for robust decision-making. In contrast to most agent architectures relying on stochastic narrative-based reasoning, CoMMa utilizes deterministic embedding projections to approximate contribution-aware credit assignment. This yields explicit evidence attribution by estimating each agent's marginal utility, producing interpretable and mathematically grounded decision pathways with improved stability. Evaluated on diverse oncology benchmarks, including a real-world multidisciplinary tumor board dataset, CoMMa achieves higher accuracy and more stable performance than data-centralized and role-based multi-agents baselines.

</details>


### [4] [Measuring Dataset Diversity from a Geometric Perspective](https://arxiv.org/abs/2602.09340)
*Yang Ba,Mohammad Sadeq Abolhasani,Michelle V Mancenido,Rong Pan*

Main category: cs.AI

TL;DR: 提出基于拓扑数据分析（TDA）和持久性景观（PLs）的几何多样性度量框架PLDiv，超越传统熵和分布变化度量，捕捉数据集的几何结构特征。


<details>
  <summary>Details</summary>
Motivation: 现有多样性度量主要关注特征空间离散度或度量空间幅度，捕捉分布变化或熵，但很大程度上忽略了数据集的几何结构。需要一种能捕捉数据几何和结构特性的多样性度量方法。

Method: 基于拓扑数据分析和持久性景观构建框架，从数据中提取和量化几何特征。持久性景观提供数据拓扑特征的稳定表示，用于测量超越熵的多样性。

Result: 通过跨多种模态的广泛实验证明，提出的PLDiv度量方法强大、可靠且可解释，直接将数据多样性与底层几何结构联系起来。

Conclusion: PLDiv为数据集构建、增强和评估提供了基础工具，通过拓扑数据分析方法实现了对数据几何结构多样性的量化测量。

Abstract: Diversity can be broadly defined as the presence of meaningful variation across elements, which can be viewed from multiple perspectives, including statistical variation and geometric structural richness in the dataset. Existing diversity metrics, such as feature-space dispersion and metric-space magnitude, primarily capture distributional variation or entropy, while largely neglecting the geometric structure of datasets. To address this gap, we introduce a framework based on topological data analysis (TDA) and persistence landscapes (PLs) to extract and quantify geometric features from data. This approach provides a theoretically grounded means of measuring diversity beyond entropy, capturing the rich geometric and structural properties of datasets. Through extensive experiments across diverse modalities, we demonstrate that our proposed PLs-based diversity metric (PLDiv) is powerful, reliable, and interpretable, directly linking data diversity to its underlying geometry and offering a foundational tool for dataset construction, augmentation, and evaluation.

</details>


### [5] [Auditing Multi-Agent LLM Reasoning Trees Outperforms Majority Vote and LLM-as-Judge](https://arxiv.org/abs/2602.09341)
*Wei Yang,Shixuan Li,Heng Ping,Peiyu Zhang,Paul Bogdan,Jesse Thomason*

Main category: cs.AI

TL;DR: AgentAuditor通过构建推理树替代多数投票，结合ACPO训练，在5种多智能体设置中实现最高5%的准确率提升


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统大多采用多数投票聚合智能体输出，这种方法丢弃了推理轨迹的证据结构，且在智能体存在相关偏见时容易形成错误共识（confabulation consensus），导致系统脆弱

Method: 1. AgentAuditor：构建推理树显式表示智能体轨迹间的共识与分歧，在关键分歧点比较推理分支，将全局裁决转化为高效的局部验证；2. ACPO：在多数投票失败案例上训练裁决器，奖励基于证据的少数选择而非流行错误

Result: 在5种流行的多智能体设置中，AgentAuditor相比多数投票实现最高5%的绝对准确率提升，相比LLM-as-Judge方法提升最高3%

Conclusion: 通过显式建模推理轨迹的共识与分歧，并针对多数投票失败案例进行优化训练，AgentAuditor能够更有效地解决多智能体系统中的共识错误问题，显著提升系统性能

Abstract: Multi-agent systems (MAS) can substantially extend the reasoning capacity of large language models (LLMs), yet most frameworks still aggregate agent outputs with majority voting. This heuristic discards the evidential structure of reasoning traces and is brittle under the confabulation consensus, where agents share correlated biases and converge on the same incorrect rationale. We introduce AgentAuditor, which replaces voting with a path search over a Reasoning Tree that explicitly represents agreements and divergences among agent traces. AgentAuditor resolves conflicts by comparing reasoning branches at critical divergence points, turning global adjudication into efficient, localized verification. We further propose Anti-Consensus Preference Optimization (ACPO), which trains the adjudicator on majority-failure cases and rewards evidence-based minority selections over popular errors. AgentAuditor is agnostic to MAS setting, and we find across 5 popular settings that it yields up to 5% absolute accuracy improvement over a majority vote, and up to 3% over using LLM-as-Judge.

</details>


### [6] [Image Quality in the Era of Artificial Intelligence](https://arxiv.org/abs/2602.09347)
*Jana G. Delfino,Jason L. Granstedt,Frank W. Samuelson,Robert Ochs,Krishna Juluru*

Main category: cs.AI

TL;DR: AI在放射学图像重建和增强中应用迅速，能提升图像质量、加快获取速度，但也引入了新的失败模式和图像感知质量与信息内容之间的脱节风险。


<details>
  <summary>Details</summary>
Motivation: AI在放射学图像重建和增强中的应用日益广泛，虽然能显著提升图像质量和工作效率，但也带来了新的风险，特别是图像感知质量与实际信息内容之间的脱节问题，需要引起重视。

Method: 本文是一篇通讯文章，旨在通过分析和讨论的方式，提高人们对AI在放射学图像重建和增强中局限性的认识。

Result: AI技术能够生成更清晰、更平滑、更详细的图像，加快图像获取速度，并让临床医生能更快地审阅图像。

Conclusion: 理解AI图像重建和增强的局限性对于安全有效地使用该技术至关重要，用户需要在享受AI技术带来的好处的同时，最小化相关风险。

Abstract: Artificial intelligence (AI) is being deployed within radiology at a rapid pace. AI has proven an excellent tool for reconstructing and enhancing images that appear sharper, smoother, and more detailed, can be acquired more quickly, and allowing clinicians to review them more rapidly. However, incorporation of AI also introduces new failure modes and can exacerbate the disconnect between perceived quality of an image and information content of that image. Understanding the limitations of AI-enabled image reconstruction and enhancement is critical for safe and effective use of the technology. Hence, the purpose of this communication is to bring awareness to limitations when AI is used to reconstruct or enhance a radiological image, with the goal of enabling users to reap benefits of the technology while minimizing risks.

</details>


### [7] [Bridging Efficiency and Transparency: Explainable CoT Compression in Multimodal Large Reasoning Models](https://arxiv.org/abs/2602.09485)
*Yizhi Wang,Linan Yue,Min-Ling Zhang*

Main category: cs.AI

TL;DR: XMCC是一个可解释的多模态思维链压缩器，通过强化学习优化序列决策过程，有效缩短推理轨迹同时保持关键推理步骤和答案正确性，并提供压缩决策的自然语言解释。


<details>
  <summary>Details</summary>
Motivation: 长思维链在多模态推理中广泛使用，但往往过于冗长且包含冗余推理步骤，这会降低推理效率。现有压缩方法存在两个主要问题：1)可能破坏视觉-文本推理的完整性；2)压缩过程缺乏可解释性。

Method: 提出XMCC（可解释多模态思维链压缩器），将压缩建模为序列决策过程，通过强化学习进行优化。该方法能够缩短推理轨迹，同时保留关键推理步骤和答案正确性，并为压缩决策生成自然语言解释。

Result: 在代表性多模态推理基准测试上的广泛实验表明，XMCC不仅减少了推理长度，还提供了可解释的解释，验证了其有效性。

Conclusion: XMCC解决了长思维链压缩中的关键挑战，在保持推理完整性的同时提高效率，并通过可解释的压缩决策增强了系统的透明度和可信度。

Abstract: Long chains of thought (Long CoTs) are widely employed in multimodal reasoning models to tackle complex tasks by capturing detailed visual information. However, these Long CoTs are often excessively lengthy and contain redundant reasoning steps, which can hinder inference efficiency. Compressing these long CoTs is a natural solution, yet existing approaches face two major challenges: (1) they may compromise the integrity of visual-textual reasoning by removing essential alignment cues, and (2) the compression process lacks explainability, making it difficult to discern which information is critical. To address these problems, we propose XMCC, an eXplainable Multimodal CoT Compressor that formulates compression as a sequential decision-making process optimized via reinforcement learning. XMCC can effectively shorten reasoning trajectories while preserving key reasoning steps and answer correctness, and simultaneously generates natural-language explanations for its compression decisions. Extensive experiments on representative multimodal reasoning benchmarks demonstrate that XMCC not only reduces reasoning length but also provides explainable explanations, validating its effectiveness.

</details>


### [8] [Computing Conditional Shapley Values Using Tabular Foundation Models](https://arxiv.org/abs/2602.09489)
*Lars Henry Berge Olsen,Dennis Christensen*

Main category: cs.AI

TL;DR: 本文提出使用TabPFN等表格基础模型来高效计算Shapley值，相比传统方法在保持准确性的同时大幅降低计算时间。


<details>
  <summary>Details</summary>
Motivation: Shapley值是解释性AI的核心工具，但计算成本高昂，特别是在特征相关时。传统方法需要近似大量条件期望，要么通过蒙特卡洛积分要么通过回归。深度学习方法由于需要为每个条件期望重新训练而效率低下，表格基础模型如TabPFN通过上下文学习解决了这一计算瓶颈。

Method: 使用TabPFN的多个变体来计算Shapley值，通过上下文学习近似条件期望而无需重新训练。在模拟和真实数据集上比较TabPFN与最先进方法的性能。

Result: 在大多数情况下，TabPFN表现最佳；即使不是最佳时，也仅略逊于最佳方法，但运行时间大幅减少。TabPFN在保持准确性的同时显著提高了计算效率。

Conclusion: 表格基础模型如TabPFN为高效计算Shapley值提供了有前景的解决方案。未来可以进一步改进表格基础模型，使其更好地适应条件Shapley值估计的特定需求。

Abstract: Shapley values have become a cornerstone of explainable AI, but they are computationally expensive to use, especially when features are dependent. Evaluating them requires approximating a large number of conditional expectations, either via Monte Carlo integration or regression. Until recently it has not been possible to fully exploit deep learning for the regression approach, because retraining for each conditional expectation takes too long. Tabular foundation models such as TabPFN overcome this computational hurdle by leveraging in-context learning, so each conditional expectation can be approximated without any re-training. In this paper, we compute Shapley values with multiple variants of TabPFN and compare their performance with state-of-the-art methods on both simulated and real datasets. In most cases, TabPFN yields the best performance; where it does not, it is only marginally worse than the best method, at a fraction of the runtime. We discuss further improvements and how tabular foundation models can be better adapted specifically for conditional Shapley value estimation.

</details>


### [9] [FLINGO -- Instilling ASP Expressiveness into Linear Integer Constraints](https://arxiv.org/abs/2602.09620)
*Jorge Fandinno,Pedro Cabalar,Philipp Wanko,Torsten Schaub*

Main category: cs.AI

TL;DR: FLINGO语言将ASP的丰富表达能力引入约束ASP，支持默认值、未定义属性、非确定性赋值和聚合值等特性


<details>
  <summary>Details</summary>
Motivation: 传统约束ASP中，数值约束的表达方式更接近后端求解器，失去了ASP原有的丰富表达能力，如默认值、未定义属性、非确定性赋值和聚合值等特性

Method: 提出FLINGO语言和工具，在数值约束中融入ASP的表达能力，并提供从FLINGO语法到标准CASP程序（CLINGCON格式）的翻译方法

Result: 开发了FLINGO语言，能够在约束ASP中保留ASP的丰富表达能力，并通过多个示例展示了其应用

Conclusion: FLINGO成功将ASP的表达能力引入约束ASP，填补了传统CASP在表达能力上的不足，为实际应用提供了更灵活的建模工具

Abstract: Constraint Answer Set Programming (CASP) is a hybrid paradigm that enriches Answer Set Programming (ASP) with numerical constraint processing, something required in many real-world applications. The usual specification of constraints in most CASP solvers is closer to the numerical back-end expressiveness and semantics, rather than to standard specification in ASP. In the latter, numerical attributes are represented with predicates and this allows declaring default values, leaving the attribute undefined, making non-deterministic assignments with choice rules or using aggregated values. In CASP, most (if not all) of these features are lost once we switch to a constraint-based representation of those same attributes. In this paper, we present the FLINGO language (and tool) that incorporates the aforementioned expressiveness inside the numerical constraints and we illustrate its use with several examples. Based on previous work that established its semantic foundations, we also present a translation from the newly introduced FLINGO syntax to regular CASP programs following the CLINGCON input format.

</details>


### [10] [ClinAlign: Scaling Healthcare Alignment from Clinician Preference](https://arxiv.org/abs/2602.09653)
*Shiwei Lyu,Xidong Wang,Lei Liu,Hao Zhu,Chaohe Zhang,Jian Wang,Jinjie Gu,Benyou Wang,Yue Shen*

Main category: cs.AI

TL;DR: 提出两阶段框架解决LLM医疗输出与临床医生偏好对齐问题：1)创建医生验证的偏好数据集HealthRubrics；2)提炼为可重用原则HealthPrinciples，用于离线对齐和推理时自修正，在资源有限情况下超越更大模型表现。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型具备专家级医学知识，但其开放式输出与临床医生细粒度偏好的对齐仍然困难。现有方法依赖粗粒度目标或不可靠的自动化评估，缺乏专业指南的坚实基础。

Method: 提出两阶段框架：1)创建HealthRubrics数据集，包含7,034个医生验证的偏好示例，临床医生完善LLM起草的评分标准以满足严格医学标准；2)提炼为HealthPrinciples，包含119个广泛可重用、临床基础的原则，按临床维度组织，实现超越手动标注的可扩展监督。

Result: 使用该框架训练的30B-A3B模型在HealthBench-Hard上达到33.4%的准确率，超越了包括Deepseek-R1和o3在内的更大模型，为临床对齐建立了资源高效的基础。

Conclusion: 提出的两阶段框架通过创建医生验证的偏好数据集和提炼可重用临床原则，有效解决了LLM医疗输出与临床医生偏好的对齐问题，在资源有限情况下实现了优于更大模型的性能。

Abstract: Although large language models (LLMs) demonstrate expert-level medical knowledge, aligning their open-ended outputs with fine-grained clinician preferences remains challenging. Existing methods often rely on coarse objectives or unreliable automated judges that are weakly grounded in professional guidelines. We propose a two-stage framework to address this gap. First, we introduce HealthRubrics, a dataset of 7,034 physician-verified preference examples in which clinicians refine LLM-drafted rubrics to meet rigorous medical standards. Second, we distill these rubrics into HealthPrinciples: 119 broadly reusable, clinically grounded principles organized by clinical dimensions, enabling scalable supervision beyond manual annotation. We use HealthPrinciples for (1) offline alignment by synthesizing rubrics for unlabeled queries and (2) an inference-time tool for guided self-revision. A 30B-A3B model trained with our framework achieves 33.4% on HealthBench-Hard, outperforming much larger models including Deepseek-R1 and o3, establishing a resource-efficient baseline for clinical alignment.

</details>


### [11] [GHS-TDA: A Synergistic Reasoning Framework Integrating Global Hypothesis Space with Topological Data Analysis](https://arxiv.org/abs/2602.09794)
*Jiaquan Zhang,Chaoning Zhang,Shuxu Chen,Xudong Wang,Zhenzhen Huang,Pengcheng Zheng,Shuai Yuan,Sheng Zheng,Qigan Sun,Jie Zou,Lik-Hang Lee,Yang Yang*

Main category: cs.AI

TL;DR: GHS-TDA通过构建全局假设图结合拓扑数据分析，解决传统思维链方法中早期错误传播和缺乏结构化分析的问题，提升推理准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统思维链方法存在两个根本性局限：1) 推理过程对早期决策高度敏感，一旦出现初始错误会传播放大且难以纠正；2) 缺乏结构化分析技术来过滤冗余推理和提取关键特征，导致推理过程不稳定且可解释性有限。

Method: 提出GHS-TDA方法：首先构建语义丰富的全局假设图，聚合、对齐和协调多个候选推理路径，为局部推理失败时提供替代的全局修正路径；然后应用基于持久同调的拓扑数据分析，捕获稳定的多尺度结构，去除冗余和不一致性，提取更可靠的推理骨架。

Result: 通过联合利用推理多样性和拓扑稳定性，GHS-TDA实现了自适应收敛，生成高置信度和可解释的推理路径，在多个推理基准测试中，在准确性和鲁棒性方面均持续优于强基线方法。

Conclusion: GHS-TDA通过全局协调和拓扑分析有效解决了传统思维链方法的局限性，显著提升了大型语言模型的推理性能，为复杂任务提供了更可靠和可解释的推理框架。

Abstract: Chain-of-Thought (CoT) has been shown to significantly improve the reasoning accuracy of large language models (LLMs) on complex tasks. However, due to the autoregressive, step-by-step generation paradigm, existing CoT methods suffer from two fundamental limitations. First, the reasoning process is highly sensitive to early decisions: once an initial error is introduced, it tends to propagate and amplify through subsequent steps, while the lack of a global coordination and revision mechanism makes such errors difficult to correct, ultimately leading to distorted reasoning chains. Second, current CoT approaches lack structured analysis techniques for filtering redundant reasoning and extracting key reasoning features, resulting in unstable reasoning processes and limited interpretability. To address these issues, we propose GHS-TDA. GHS-TDA first constructs a semantically enriched global hypothesis graph to aggregate, align, and coordinate multiple candidate reasoning paths, thereby providing alternative global correction routes when local reasoning fails. It then applies topological data analysis based on persistent homology to capture stable multi-scale structures, remove redundancy and inconsistencies, and extract a more reliable reasoning skeleton. By jointly leveraging reasoning diversity and topological stability, GHS-TDA achieves self-adaptive convergence, produces high-confidence and interpretable reasoning paths, and consistently outperforms strong baselines in terms of both accuracy and robustness across multiple reasoning benchmarks.

</details>


### [12] [Would a Large Language Model Pay Extra for a View? Inferring Willingness to Pay from Subjective Choices](https://arxiv.org/abs/2602.09802)
*Manon Reusens,Sofie Goethals,Toon Calders,David Martens*

Main category: cs.AI

TL;DR: 研究LLM在旅行助手场景中的主观决策能力，通过选择困境实验和多项logit模型推导隐含支付意愿，并与人类基准对比，发现LLM能产生有意义的WTP值但存在系统性偏差。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在旅行助手等应用中的部署增多，它们经常需要在没有客观正确答案的情况下为用户做出主观选择。研究旨在评估LLM在这种主观决策场景中的表现，特别是其隐含支付意愿与人类基准的差异。

Method: 在旅行助手情境中向LLM呈现选择困境，使用多项logit模型分析响应以推导隐含支付意愿估计。研究基线设置外，还考察了更现实条件下的模型行为变化，包括提供用户历史选择信息和基于角色的提示。

Result: 较大规模的LLM能够产生有意义的WTP值，但在属性层面存在系统性偏差。总体倾向于高估人类WTP，特别是在引入昂贵选项或商务导向角色时。当模型基于先前对便宜选项的偏好进行条件化时，估值更接近人类基准。

Conclusion: 研究结果凸显了使用LLM进行主观决策支持的潜力和局限性，强调了在实际部署此类系统时仔细选择模型、设计提示和用户表示的重要性。

Abstract: As Large Language Models (LLMs) are increasingly deployed in applications such as travel assistance and purchasing support, they are often required to make subjective choices on behalf of users in settings where no objectively correct answer exists. We study LLM decision-making in a travel-assistant context by presenting models with choice dilemmas and analyzing their responses using multinomial logit models to derive implied willingness to pay (WTP) estimates. These WTP values are subsequently compared to human benchmark values from the economics literature. In addition to a baseline setting, we examine how model behavior changes under more realistic conditions, including the provision of information about users' past choices and persona-based prompting. Our results show that while meaningful WTP values can be derived for larger LLMs, they also display systematic deviations at the attribute level. Additionally, they tend to overestimate human WTP overall, particularly when expensive options or business-oriented personas are introduced. Conditioning models on prior preferences for cheaper options yields valuations that are closer to human benchmarks. Overall, our findings highlight both the potential and the limitations of using LLMs for subjective decision support and underscore the importance of careful model selection, prompt design, and user representation when deploying such systems in practice.

</details>


### [13] [CODE-SHARP: Continuous Open-ended Discovery and Evolution of Skills as Hierarchical Reward Programs](https://arxiv.org/abs/2602.10085)
*Richard Bornemann,Pierluigi Vito Amadori,Antoine Cully*

Main category: cs.AI

TL;DR: CODE-SHARP框架利用基础模型自动发现和演化分层技能，通过代码形式的奖励函数实现开放式的技能学习，在Craftax环境中显著提升长时程任务解决能力。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习依赖人工设计的奖励函数，无法适应开放式的技能发现，因为有意义技能的集合事先未知。现有方法仅限于为预定义任务优化奖励函数，需要一种能够自动发现和演化新技能的框架。

Method: 提出CODE-SHARP框架，利用基础模型开放地扩展和精炼分层技能档案，该档案以可执行奖励函数代码的有向图形式组织。通过高层基础模型规划器组合发现的技能，使单个目标条件智能体能够解决复杂的长时程任务。

Result: 在Craftax环境中，仅使用发现的SHARP技能生成的奖励进行训练的目标条件智能体，能够解决越来越长的时程目标。当由高层基础模型规划器组合时，该智能体在复杂长时程任务上的表现平均超过预训练智能体和任务特定专家策略134%以上。

Conclusion: CODE-SHARP框架通过自动发现和演化分层技能，成功解决了开放式技能学习的挑战，显著提升了智能体在复杂长时程任务上的性能，为开放式的技能发现提供了有效的解决方案。

Abstract: Developing agents capable of open-endedly discovering and learning novel skills is a grand challenge in Artificial Intelligence. While reinforcement learning offers a powerful framework for training agents to master complex skills, it typically relies on hand-designed reward functions. This is infeasible for open-ended skill discovery, where the set of meaningful skills is not known a priori. While recent methods have shown promising results towards automating reward function design, they remain limited to refining rewards for pre-defined tasks. To address this limitation, we introduce Continuous Open-ended Discovery and Evolution of Skills as Hierarchical Reward Programs (CODE-SHARP), a novel framework leveraging Foundation Models (FM) to open-endedly expand and refine a hierarchical skill archive, structured as a directed graph of executable reward functions in code. We show that a goal-conditioned agent trained exclusively on the rewards generated by the discovered SHARP skills learns to solve increasingly long-horizon goals in the Craftax environment. When composed by a high-level FM-based planner, the discovered skills enable a single goal-conditioned agent to solve complex, long-horizon tasks, outperforming both pretrained agents and task-specific expert policies by over $134$% on average. We will open-source our code and provide additional videos at https://sites.google.com/view/code-sharp/homepage.

</details>


### [14] [Agent World Model: Infinity Synthetic Environments for Agentic Reinforcement Learning](https://arxiv.org/abs/2602.10090)
*Zhaoyang Wang,Canwen Xu,Boyi Liu,Yite Wang,Siwei Han,Zhewei Yao,Huaxiu Yao,Yuxiong He*

Main category: cs.AI

TL;DR: 提出Agent World Model (AWM)合成环境生成管道，创建1000个日常场景环境，配备丰富工具集，用于大规模强化学习训练多轮工具使用智能体，实现强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型赋能自主智能体执行复杂任务，但智能体训练受限于缺乏多样可靠的环境。现有环境模拟存在可靠性、一致性不足的问题。

Method: 提出Agent World Model (AWM)合成环境生成管道，创建1000个代码驱动、数据库支持的环境，平均每个环境配备35个工具，提供高质量观测和可靠状态转换。

Result: 在三个基准测试上，仅使用合成环境训练（而非基准特定环境）的智能体展现出强大的分布外泛化能力。代码驱动环境支持可靠奖励函数设计。

Conclusion: AWM合成环境生成管道为大规模智能体训练提供了高质量、可靠的环境资源，解决了环境稀缺问题，支持高效强化学习并实现强泛化性能。

Abstract: Recent advances in large language model (LLM) have empowered autonomous agents to perform complex tasks that require multi-turn interactions with tools and environments. However, scaling such agent training is limited by the lack of diverse and reliable environments. In this paper, we propose Agent World Model (AWM), a fully synthetic environment generation pipeline. Using this pipeline, we scale to 1,000 environments covering everyday scenarios, in which agents can interact with rich toolsets (35 tools per environment on average) and obtain high-quality observations. Notably, these environments are code-driven and backed by databases, providing more reliable and consistent state transitions than environments simulated by LLMs. Moreover, they enable more efficient agent interaction compared with collecting trajectories from realistic environments. To demonstrate the effectiveness of this resource, we perform large-scale reinforcement learning for multi-turn tool-use agents. Thanks to the fully executable environments and accessible database states, we can also design reliable reward functions. Experiments on three benchmarks show that training exclusively in synthetic environments, rather than benchmark-specific ones, yields strong out-of-distribution generalization. The code is available at https://github.com/Snowflake-Labs/agent-world-model.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [15] [PICASSO: Scaling CHERI Use-After-Free Protection to Millions of Allocations using Colored Capabilities](https://arxiv.org/abs/2602.09131)
*Merve Gülmez,Ruben Sturm,Hossam ElAtali,Håkan Englund,Jonathan Woodruff,N. Asokan,Thomas Nyman*

Main category: cs.CR

TL;DR: PICASSO通过引入彩色能力扩展CHERI架构，提供硬件管理的来源有效性表，实现批量撤销悬空指针，有效缓解堆内存的时空安全问题，性能开销小。


<details>
  <summary>Details</summary>
Motivation: CHERI指令集架构虽然提供了强大的空间内存安全性，但缺乏内置的时态安全性，特别是对于堆分配。先前增强CHERI时态安全性的尝试在可扩展性、内存开销和安全性方面存在不足，主要因为需要定期扫描系统内存来单独撤销过时的能力。

Method: 引入彩色能力，为CHERI的能力模型添加受控的间接层。通过硬件管理的来源有效性表跟踪能力到各自分配的来源，允许批量撤销悬空指针而无需隔离已释放的内存。在CHERI-RISC-V架构上实现PICASSO扩展，并集成到CheriBSD操作系统和CHERI-enabled Clang/LLVM工具链中。

Result: 有效缓解了NIST Juliet测试用例中所有基于堆的时态内存安全漏洞（use-after-free和double-free错误）。在SPEC CPU基准测试中仅产生5%的几何平均性能开销，在SQLite、PostgreSQL和gRPC等长时间运行工作负载中相比先前工作具有更低的延迟和更一致的性能。

Conclusion: 彩色能力显著减少了能力撤销扫描的频率，同时提高了安全性，为CHERI架构提供了有效的时态内存安全解决方案，具有较小的性能开销。

Abstract: While the CHERI instruction-set architecture extensions for capabilities enable strong spatial memory safety, CHERI lacks built-in temporal safety, particularly for heap allocations. Prior attempts to augment CHERI with temporal safety fall short in terms of scalability, memory overhead, and incomplete security guarantees due to periodical sweeps of the system's memory to individually revoke stale capabilities. We address these limitations by introducing colored capabilities that add a controlled form of indirection to CHERI's capability model. This enables provenance tracking of capabilities to their respective allocations via a hardware-managed provenance-validity table, allowing bulk retraction of dangling pointers without needing to quarantine freed memory. Colored capabilities significantly reduce the frequency of capability revocation sweeps while improving security. We realize colored capabilities in PICASSO, an extension of the CHERI-RISC-V architecture on a speculative out-of-order FPGA softcore (CHERI-Toooba). We also integrate colored-capability support into the CheriBSD OS and CHERI-enabled Clang/LLVM toolchain. Our evaluation shows effective mitigation of use-after-free and double-free bugs across all heap-based temporal memory-safety vulnerabilities in NIST Juliet test cases, with only a small performance overhead on SPEC CPU benchmarks (5% g.m.), less latency, and more consistent performance in long-running SQLite, PostgreSQL, and gRPC workloads compared to prior work.

</details>


### [16] [One RNG to Rule Them All: How Randomness Becomes an Attack Vector in Machine Learning](https://arxiv.org/abs/2602.09182)
*Kotekar Annapoorna Prabhu,Andrew Gan,Zahra Ghodsi*

Main category: cs.CR

TL;DR: RNGGuard：一种保护机器学习系统中随机数生成器安全性的工具，通过静态分析和运行时替换来防御针对随机性源的攻击


<details>
  <summary>Details</summary>
Motivation: 机器学习严重依赖随机性（数据采样、数据增强、权重初始化、优化等），但不同框架、软件依赖和硬件后端的伪随机数生成器实现差异以及缺乏统计验证，可能形成未探索的攻击向量。针对随机性源的攻击极其隐蔽，在现实系统中已有被利用的历史。

Method: 提出RNGGuard工具：1）静态分析目标库的源代码，识别随机函数及其使用模块；2）在运行时通过将不安全的函数调用替换为符合安全规范的RNGGuard实现来强制执行安全随机函数执行。

Result: 评估表明RNGGuard提供了一种实用的方法来填补机器学习系统中保护随机性源的现有安全漏洞。

Conclusion: RNGGuard能够以较低的工作量帮助机器学习工程师保护其系统，通过系统化的方法解决机器学习开发流程中随机性源的安全问题。

Abstract: Machine learning relies on randomness as a fundamental component in various steps such as data sampling, data augmentation, weight initialization, and optimization. Most machine learning frameworks use pseudorandom number generators as the source of randomness. However, variations in design choices and implementations across different frameworks, software dependencies, and hardware backends along with the lack of statistical validation can lead to previously unexplored attack vectors on machine learning systems. Such attacks on randomness sources can be extremely covert, and have a history of exploitation in real-world systems. In this work, we examine the role of randomness in the machine learning development pipeline from an adversarial point of view, and analyze the implementations of PRNGs in major machine learning frameworks. We present RNGGuard to help machine learning engineers secure their systems with low effort. RNGGuard statically analyzes a target library's source code and identifies instances of random functions and modules that use them. At runtime, RNGGuard enforces secure execution of random functions by replacing insecure function calls with RNGGuard's implementations that meet security specifications. Our evaluations show that RNGGuard presents a practical approach to close existing gaps in securing randomness sources in machine learning systems.

</details>


### [17] [Atlas: Enabling Cross-Vendor Authentication for IoT](https://arxiv.org/abs/2602.09263)
*Sanket Goutam,Omar Chowdhury,Amir Rahmati*

Main category: cs.CR

TL;DR: Atlas框架通过扩展Web公钥基础设施到物联网，为设备颁发X.509证书，使设备能够直接建立跨域mTLS通道，减少对云服务的依赖，降低延迟。


<details>
  <summary>Details</summary>
Motivation: 当前云中介的物联网架构存在认证碎片化问题，跨供应商设备间交互存在延迟和可用性瓶颈，需要一种能够实现设备间直接安全通信的解决方案。

Method: Atlas框架扩展Web PKI到物联网，通过供应商操作的ACME客户端和DNS命名空间为设备颁发X.509证书，使设备获得全局可验证身份，并建立跨管理域的相互TLS通道。

Result: 证书配置每设备在6秒内完成，mTLS仅增加约17ms延迟和适度CPU开销，相比云中介基准，Atlas应用能够维持更低、更可预测的延迟。

Conclusion: Atlas框架能够立即部署，因为许多主要供应商已经在Web服务中使用ACME兼容的CA，只需最小基础设施变更即可实现设备间直接安全通信。

Abstract: Cloud-mediated IoT architectures fragment authentication across vendor silos and create latency and availability bottlenecks for cross-vendor device-to-device (D2D) interactions. We present Atlas, a framework that extends the Web public-key infrastructure to IoT by issuing X.509 certificates to devices via vendor-operated ACME clients and vendor-controlled DNS namespaces. Devices obtain globally verifiable identities without hardware changes and establish mutual TLS channels directly across administrative domains, decoupling runtime authentication from cloud reachability. We prototype Atlas on ESP32 and Raspberry Pi, integrate it with an MQTT-based IoT stack and an Atlas-aware cloud, and evaluate it in smart-home and smart-city workloads. Certificate provisioning completes in under 6s per device, mTLS adds only about 17ms of latency and modest CPU overhead, and Atlas-based applications sustain low, predictable latency compared to cloud-mediated baselines. Because many major vendors already rely on ACME-compatible CAs for their web services, Atlas is immediately deployable with minimal infrastructure changes.

</details>


### [18] [Benchmarking Knowledge-Extraction Attack and Defense on Retrieval-Augmented Generation](https://arxiv.org/abs/2602.09319)
*Zhisheng Qi,Utkarsh Sahu,Li Ma,Haoyu Han,Ryan Rossi,Franck Dernoncourt,Mahantesh Halappanavar,Nesreen Ahmed,Yushun Dong,Yue Zhao,Yu Zhang,Yu Wang*

Main category: cs.CR

TL;DR: 该论文提出了首个针对RAG系统知识提取攻击的系统性基准测试，旨在解决现有研究在攻击防御技术、检索嵌入模型和评估指标方面的碎片化问题。


<details>
  <summary>Details</summary>
Motivation: RAG系统在知识密集型应用中广泛应用，但研究表明恶意查询可提取敏感知识库内容，引发知识产权和隐私泄露担忧。现有研究存在碎片化问题，缺乏统一的评估框架。

Method: 构建了首个系统性基准测试，涵盖广泛的攻击防御策略、代表性检索嵌入模型、开源和闭源生成器，在统一实验框架下使用标准化协议和多个数据集进行评估。

Result: 通过整合实验环境并实现可重复、可比较的评估，该基准测试为开发隐私保护的RAG系统提供了实用基础，能够应对新兴的知识提取威胁。

Conclusion: 该基准测试填补了RAG系统安全评估的空白，为研究和开发隐私保护的RAG系统提供了系统性的评估框架和实用指导。

Abstract: Retrieval-Augmented Generation (RAG) has become a cornerstone of knowledge-intensive applications, including enterprise chatbots, healthcare assistants, and agentic memory management. However, recent studies show that knowledge-extraction attacks can recover sensitive knowledge-base content through maliciously crafted queries, raising serious concerns about intellectual property theft and privacy leakage. While prior work has explored individual attack and defense techniques, the research landscape remains fragmented, spanning heterogeneous retrieval embeddings, diverse generation models, and evaluations based on non-standardized metrics and inconsistent datasets. To address this gap, we introduce the first systematic benchmark for knowledge-extraction attacks on RAG systems. Our benchmark covers a broad spectrum of attack and defense strategies, representative retrieval embedding models, and both open- and closed-source generators, all evaluated under a unified experimental framework with standardized protocols across multiple datasets. By consolidating the experimental landscape and enabling reproducible, comparable evaluation, this benchmark provides actionable insights and a practical foundation for developing privacy-preserving RAG systems in the face of emerging knowledge extraction threats. Our code is available here.

</details>


### [19] [Privacy Amplification for BandMF via $b$-Min-Sep Subsampling](https://arxiv.org/abs/2602.09338)
*Andy Dong,Arun Ganesh*

Main category: cs.CR

TL;DR: 本文研究了BandMF（使用带相关噪声的DP-SGD）的隐私放大问题，提出了一种新的b-min-sep子采样方案，该方案优于现有的循环泊松采样，并在多归属用户级隐私设置中具有天然扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的BandMF隐私放大方法存在局限性，特别是在子采样策略方面。循环泊松采样虽然实用，但在隐私放大效果上不够理想，且现有的子采样方案难以扩展到多归属用户级隐私设置。

Method: 提出了b-min-sep子采样方案，这是对泊松采样和balls-in-bins采样的泛化，扩展了BandMF的实用批处理策略。使用基于动态规划的蒙特卡洛隐私分析方法，利用了子采样过程中的马尔可夫结构。

Result: 在高噪声区域，b-min-sep与循环泊松采样效果相当；在中低噪声区域，b-min-sep提供严格更好的隐私保证。实验结果表明该方法的有效性，并且该方案能自然地扩展到多归属用户级隐私设置。

Conclusion: b-min-sep子采样方案为BandMF提供了更强的隐私放大效果，特别是在中低噪声区域，同时保持了分析所需的结构特性，并能够扩展到更复杂的隐私设置中。

Abstract: We study privacy amplification for BandMF, i.e., DP-SGD with correlated noise across iterations via a banded correlation matrix. We propose $b$-min-sep subsampling, a new subsampling scheme that generalizes Poisson and balls-in-bins subsampling, extends prior practical batching strategies for BandMF, and enables stronger privacy amplification than cyclic Poisson while preserving the structural properties needed for analysis. We give a near-exact privacy analysis using Monte Carlo accounting, based on a dynamic program that leverages the Markovian structure in the subsampling procedure. We show that $b$-min-sep matches cyclic Poisson subsampling in the high noise regime and achieves strictly better guarantees in the mid-to-low noise regime, with experimental results that bolster our claims. We further show that unlike previous BandMF subsampling schemes, our $b$-min-sep subsampling naturally extends to the multi-attribution user-level privacy setting.

</details>


### [20] [Timing and Memory Telemetry on GPUs for AI Governance](https://arxiv.org/abs/2602.09369)
*Saleh K. Monfared,Fatemeh Ganji,Dan Holcomb,Shahin Tajik*

Main category: cs.CR

TL;DR: 提出基于GPU架构特性的计算活动测量框架，通过四种互补原语生成可观测信号，用于GPU部署后的治理和问责


<details>
  <summary>Details</summary>
Motivation: GPU加速计算的快速发展推动了大规模AI进步，但也引发了对已部署加速器如何被观察和治理的担忧。当前GPU暴露的可信遥测有限，且可能被对手修改或虚拟化，需要在不信任主机和设备的情况下提供可操作的计算利用率信号。

Method: 引入基于现代GPU架构特性的测量框架，包含四种互补原语：1）受工作量证明启发的概率性、工作负载驱动机制；2）基于可验证延迟函数的顺序、延迟敏感工作负载；3）基于通用矩阵乘法的张量核心测量；4）VRAM驻留测试。这些原语提供GPU参与度的统计和行为指标。

Result: 评估显示这些原语对争用、架构对齐、内存压力和功耗开销有响应，时序偏移和驻留延迟揭示了有意义的利用率模式。计算遥测可以补充未来的问责机制。

Conclusion: 基于计算的遥测能够暴露与GPU部署后治理相关的架构信号，即使在没有可信固件、安全区域或供应商控制计数器的情况下也能保持可观测性，为GPU治理提供有价值的补充机制。

Abstract: The rapid expansion of GPU-accelerated computing has enabled major advances in large-scale artificial intelligence (AI), while heightening concerns about how accelerators are observed or governed once deployed. Governance is essential to ensure that large-scale compute infrastructure is not silently repurposed for training models, circumventing usage policies, or operating outside legal oversight. Because current GPUs expose limited trusted telemetry and can be modified or virtualized by adversaries, we explore whether compute-based measurements can provide actionable signals of utilization when host and device are untrusted. We introduce a measurement framework that leverages architectural characteristics of modern GPUs to generate timing- and memory-based observables that correlate with compute activity. Our design draws on four complementary primitives: (1) a probabilistic, workload-driven mechanism inspired by Proof-of-Work (PoW) to expose parallel effort, (2) sequential, latency-sensitive workloads derived via Verifiable Delay Functions (VDFs) to characterize scalar execution pressure, (3) General Matrix Multiplication (GEMM)-based tensor-core measurements that reflect dense linear-algebra throughput, and (4) a VRAM-residency test that distinguishes on-device memory locality from off-chip access through bandwidth-dependent hashing. These primitives provide statistical and behavioral indicators of GPU engagement that remain observable even without trusted firmware, enclaves, or vendor-controlled counters. We evaluate their responses to contention, architectural alignment, memory pressure, and power overhead, showing that timing shifts and residency latencies reveal meaningful utilization patterns. Our results illustrate why compute-based telemetry can complement future accountability mechanisms by exposing architectural signals relevant to post-deployment GPU governance.

</details>


### [21] [LLMAC: A Global and Explainable Access Control Framework with Large Language Model](https://arxiv.org/abs/2602.09392)
*Sharif Noor Zisad,Ragib Hasan*

Main category: cs.CR

TL;DR: 提出LLMAC：基于大语言模型的统一访问控制框架，整合RBAC、ABAC、DAC等传统方法，解决动态复杂场景下的访问控制问题，在合成数据集上达到98.5%准确率。


<details>
  <summary>Details</summary>
Motivation: 传统访问控制方法（RBAC、ABAC、DAC）各自为特定目的设计，无法有效处理现代系统所需的动态、情境依赖的工作流。企业需要能够处理复杂、变化安全需求的访问控制系统。

Method: 提出LLMAC框架，利用大语言模型（LLMs）统一整合多种访问控制方法。使用包含所有权验证、版本管理、工作流流程、动态角色分离等复杂场景的合成数据集训练Mistral 7B模型。

Result: 训练后的LLM模型达到98.5%的准确率，显著优于传统方法（RBAC:14.5%、ABAC:58.5%、DAC:27.5%）。系统提供清晰可读的决策解释，性能测试显示具有实际部署可行性。

Conclusion: LLMAC框架成功整合了多种访问控制方法，通过大语言模型实现了高精度、可解释的动态访问控制，为复杂现代系统提供了实用的解决方案。

Abstract: Today's business organizations need access control systems that can handle complex, changing security requirements that go beyond what traditional methods can manage. Current approaches, such as Role-Based Access Control (RBAC), Attribute-Based Access Control (ABAC), and Discretionary Access Control (DAC), were designed for specific purposes. They cannot effectively manage the dynamic, situation-dependent workflows that modern systems require. In this research, we introduce LLMAC, a new unified approach using Large Language Models (LLMs) to combine these different access control methods into one comprehensive, understandable system. We used an extensive synthetic dataset that represents complex real-world scenarios, including policies for ownership verification, version management, workflow processes, and dynamic role separation. Using Mistral 7B, our trained LLM model achieved outstanding results with 98.5% accuracy, significantly outperforming traditional methods (RBAC: 14.5%, ABAC: 58.5%, DAC: 27.5%) while providing clear, human readable explanations for each decision. Performance testing shows that the system can be practically deployed with reasonable response times and computing resources.

</details>


### [22] [Understanding and Enhancing Encoder-based Adversarial Transferability against Large Vision-Language Models](https://arxiv.org/abs/2602.09431)
*Xinwei Zhang,Li Bai,Tianwei Zhang,Youqian Zhang,Qingqing Ye,Yingnan Zhao,Ruochen Du,Haibo Hu*

Main category: cs.CR

TL;DR: 本文首次系统研究了LVLM中基于编码器的对抗样本可迁移性，发现现有攻击方法可迁移性有限，并提出SGMA框架来提升可迁移性。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在多模态任务中表现出色，但其对视觉输入的依赖使其面临对抗性威胁。现有基于编码器的攻击方法仅针对视觉编码器进行优化，而非整个LVLM，计算效率较高，但其在不同LVLM架构间的可迁移性在现实黑盒场景中尚未得到充分理解。

Method: 首先在8个不同的LVLM上进行大规模基准测试，揭示现有攻击方法的可迁移性限制。然后进行深入分析，发现两个根本原因：1）模型间视觉定位不一致；2）模型内语义对齐冗余。最后提出语义引导的多模态攻击（SGMA）框架，将扰动导向语义关键区域，并在全局和局部层面破坏跨模态定位。

Result: 实验表明，SGMA在不同受害模型和任务上比现有攻击方法具有更高的可迁移性。这些结果揭示了LVLM部署中的关键安全风险，并强调了开发鲁棒多模态防御的紧迫性。

Conclusion: 本文首次系统研究了LVLM中基于编码器的对抗样本可迁移性问题，揭示了现有攻击方法的局限性及其根本原因，并提出SGMA框架有效提升了攻击可迁移性，暴露了LVLM部署的安全风险。

Abstract: Large vision-language models (LVLMs) have achieved impressive success across multimodal tasks, but their reliance on visual inputs exposes them to significant adversarial threats. Existing encoder-based attacks perturb the input image by optimizing solely on the vision encoder, rather than the entire LVLM, offering a computationally efficient alternative to end-to-end optimization. However, their transferability across different LVLM architectures in realistic black-box scenarios remains poorly understood. To address this gap, we present the first systematic study towards encoder-based adversarial transferability in LVLMs. Our contributions are threefold. First, through large-scale benchmarking over eight diverse LVLMs, we reveal that existing attacks exhibit severely limited transferability. Second, we perform in-depth analysis, disclosing two root causes that hinder the transferability: (1) inconsistent visual grounding across models, where different models focus their attention on distinct regions; (2) redundant semantic alignment within models, where a single object is dispersed across multiple overlapping token representations. Third, we propose Semantic-Guided Multimodal Attack (SGMA), a novel framework to enhance the transferability. Inspired by the discovered causes in our analysis, SGMA directs perturbations toward semantically critical regions and disrupts cross-modal grounding at both global and local levels. Extensive experiments across different victim models and tasks show that SGMA achieves higher transferability than existing attacks. These results expose critical security risks in LVLM deployment and underscore the urgent need for robust multimodal defenses.

</details>


### [23] [A Behavioral Fingerprint for Large Language Models: Provenance Tracking via Refusal Vectors](https://arxiv.org/abs/2602.09434)
*Zhenyu Xu,Victor S. Sheng*

Main category: cs.CR

TL;DR: 提出基于安全对齐诱导行为模式的LLM指纹框架，利用拒绝向量进行模型溯源，在76个衍生模型中实现100%的家族识别准确率


<details>
  <summary>Details</summary>
Motivation: 保护大型语言模型的知识产权，防止未经授权的衍生模型扩散，需要有效的模型溯源和所有权验证方法

Method: 利用安全对齐诱导的行为模式，从模型内部表示中提取拒绝向量作为行为指纹，构建指纹系统并进行大规模验证

Result: 行为指纹对微调、合并、量化等常见修改具有强鲁棒性；在76个衍生模型中实现100%的基础模型家族识别准确率；即使在对抗攻击下仍保留可检测痕迹

Conclusion: 提出的行为指纹框架为LLM知识产权保护提供了有效解决方案，并提出了通过局部敏感哈希和零知识证明实现隐私保护公开验证的理论框架

Abstract: Protecting the intellectual property of large language models (LLMs) is a critical challenge due to the proliferation of unauthorized derivative models. We introduce a novel fingerprinting framework that leverages the behavioral patterns induced by safety alignment, applying the concept of refusal vectors for LLM provenance tracking. These vectors, extracted from directional patterns in a model's internal representations when processing harmful versus harmless prompts, serve as robust behavioral fingerprints. Our contribution lies in developing a fingerprinting system around this concept and conducting extensive validation of its effectiveness for IP protection. We demonstrate that these behavioral fingerprints are highly robust against common modifications, including finetunes, merges, and quantization. Our experiments show that the fingerprint is unique to each model family, with low cosine similarity between independently trained models. In a large-scale identification task across 76 offspring models, our method achieves 100\% accuracy in identifying the correct base model family. Furthermore, we analyze the fingerprint's behavior under alignment-breaking attacks, finding that while performance degrades significantly, detectable traces remain. Finally, we propose a theoretical framework to transform this private fingerprint into a publicly verifiable, privacy-preserving artifact using locality-sensitive hashing and zero-knowledge proofs.

</details>


### [24] [ReSIM: Re-ranking Binary Similarity Embeddings to Improve Function Search Performance](https://arxiv.org/abs/2602.09548)
*Gianluca Capozzi,Anna Paola Giancaspro,Fabio Petroni,Leonardo Querzoni,Giuseppe Antonio Di Luna*

Main category: cs.CR

TL;DR: ReSIM是一个增强的二进制函数相似性搜索系统，通过神经重排序器补充嵌入搜索，显著提升搜索效果


<details>
  <summary>Details</summary>
Motivation: 现有二进制函数相似性系统主要基于双编码器架构，这些架构独立嵌入函数，无法捕捉跨函数关系和相似性，限制了搜索准确性

Method: 提出ReSIM系统，在嵌入搜索基础上引入神经重排序模块，该模块联合处理查询-候选对，基于它们的相互表示计算排序分数，从而更准确评估相似性

Result: 在7个嵌入模型和2个基准数据集上评估，ReSIM在搜索效果上实现一致改进，nDCG平均提升21.7%，Recall平均提升27.8%

Conclusion: ReSIM通过神经重排序器补充传统嵌入搜索，能够捕捉双编码器无法捕获的细粒度关系信息，显著提升二进制函数相似性搜索效果

Abstract: Binary Function Similarity (BFS), the problem of determining whether two binary functions originate from the same source code, has been extensively studied in recent research across security, software engineering, and machine learning communities. This interest arises from its central role in developing vulnerability detection systems, copyright infringement analysis, and malware phylogeny tools. Nearly all binary function similarity systems embed assembly functions into real-valued vectors, where similar functions map to points that lie close to each other in the metric space. These embeddings enable function search: a query function is embedded and compared against a database of candidate embeddings to retrieve the most similar matches.
  Despite their effectiveness, such systems rely on bi-encoder architectures that embed functions independently, limiting their ability to capture cross-function relationships and similarities. To address this limitation, we introduce ReSIM, a novel and enhanced function search system that complements embedding-based search with a neural re-ranker. Unlike traditional embedding models, our reranking module jointly processes query-candidate pairs to compute ranking scores based on their mutual representation, allowing for more accurate similarity assessment. By re-ranking the top results from embedding-based retrieval, ReSIM leverages fine-grained relation information that bi-encoders cannot capture.
  We evaluate ReSIM across seven embedding models on two benchmark datasets, demonstrating consistent improvements in search effectiveness, with average gains of 21.7% in terms of nDCG and 27.8% in terms of Recall.

</details>


### [25] [Parallel Composition for Statistical Privacy](https://arxiv.org/abs/2602.09627)
*Dennis Breutigam,Rüdiger Reischuk*

Main category: cs.CR

TL;DR: 该论文研究了在统计隐私（SP）框架下多查询组合的隐私保护问题，提出了一种基于子采样和随机分区数据库的机制，首次获得了对有限背景知识攻击者的隐私上界，展示了在现实场景中考虑分布熵可以改善隐私和精度保证。


<details>
  <summary>Details</summary>
Motivation: 传统差分隐私（DP）假设攻击者几乎完全了解数据库条目，这种最坏情况假设可能高估实际中个体面临的隐私威胁。相比之下，统计隐私（SP）及相关概念考虑攻击者只知道数据库条目的分布而非具体实现，需要分析底层分布熵与隐私机制之间的交互作用。

Method: 提出基于子采样和随机分区数据库的隐私机制，通过限制查询之间的依赖关系来保护隐私。该方法首次在不限制数据库的情况下，获得了针对有限背景知识攻击者的隐私上界。

Result: 研究显示，在现实应用场景中考虑分布熵可以改善隐私和精度保证。在固定隐私参数和效用损失的情况下，SP允许的查询数量显著多于DP。论文通过示例说明了这种优势。

Conclusion: 统计隐私框架比传统差分隐私更贴近实际应用场景，通过考虑攻击者的有限背景知识和数据库分布的熵，可以在相同隐私保护水平下支持更多查询，提供更好的隐私-效用权衡。

Abstract: Differential Privacy (DP) considers a scenario in which an adversary has almost complete information about the entries of a database. This worst-case assumption is likely to overestimate the privacy threat faced by an individual in practice. In contrast, Statistical Privacy (SP), as well as related notions such as noiseless privacy or limited background knowledge privacy, describe a setting in which the adversary knows the distribution of the database entries, but not their exact realizations. In this case, privacy analysis must account for the interaction between uncertainty induced by the entropy of the underlying distributions and privacy mechanisms that distort query answers, which can be highly non-trivial.
  This paper investigates this problem for multiple queries (composition). A privacy mechanism is proposed that is based on subsampling and randomly partitioning the database to bound the dependency among queries. This way for the first time, to the best of our knowledge, upper privacy bounds against limited adversaries are obtained without any further restriction on the database.
  These bounds show that in realistic application scenarios taking the entropy of distributions into account yields improvements of privacy and precision guarantees. We illustrate examples where for fixed privacy parameters and utility loss SP allows significantly more queries than DP.

</details>


### [26] [Stop Testing Attacks, Start Diagnosing Defenses: The Four-Checkpoint Framework Reveals Where LLM Safety Breaks](https://arxiv.org/abs/2602.09629)
*Hayfa Dhabhi,Kashyap Thimmaraju*

Main category: cs.CR

TL;DR: 该研究提出了一个四检查点框架来分析LLM安全防御机制，发现输出阶段的防御最弱，传统二元评估严重低估了安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有研究虽然证明了越狱攻击的成功，但未能解释防御机制在何处失败以及为何失败。为了填补这一空白，需要系统性地分析LLM安全防御的薄弱环节。

Method: 提出了四检查点框架，将安全机制按处理阶段（输入vs输出）和检测级别（字面vs意图）组织成四个检查点。设计了13种针对特定检查点的规避技术，使用LLM作为评判者进行分类，并引入加权攻击成功率来捕捉被二元评估忽略的部分信息泄露。

Result: 传统二元攻击成功率为22.6%，但加权攻击成功率显示为52.7%，高出2.3倍。输出阶段防御（CP3、CP4）最弱（72-79% WASR），输入字面防御（CP1）最强（13% WASR）。Claude安全性最强（42.8% WASR），其次是GPT-5（55.9%）和Gemini（59.5%）。

Conclusion: 当前防御在输入字面检查点最强，但在意图级操纵和输出阶段技术面前仍然脆弱。四检查点框架为识别和解决部署系统中的安全漏洞提供了结构化方法。

Abstract: Large Language Models (LLMs) deploy safety mechanisms to prevent harmful outputs, yet these defenses remain vulnerable to adversarial prompts. While existing research demonstrates that jailbreak attacks succeed, it does not explain \textit{where} defenses fail or \textit{why}.
  To address this gap, we propose that LLM safety operates as a sequential pipeline with distinct checkpoints. We introduce the \textbf{Four-Checkpoint Framework}, which organizes safety mechanisms along two dimensions: processing stage (input vs.\ output) and detection level (literal vs.\ intent). This creates four checkpoints, CP1 through CP4, each representing a defensive layer that can be independently evaluated. We design 13 evasion techniques, each targeting a specific checkpoint, enabling controlled testing of individual defensive layers.
  Using this framework, we evaluate GPT-5, Claude Sonnet 4, and Gemini 2.5 Pro across 3,312 single-turn, black-box test cases. We employ an LLM-as-judge approach for response classification and introduce Weighted Attack Success Rate (WASR), a severity-adjusted metric that captures partial information leakage overlooked by binary evaluation.
  Our evaluation reveals clear patterns. Traditional Binary ASR reports 22.6\% attack success. However, WASR reveals 52.7\%, a 2.3$\times$ higher vulnerability. Output-stage defenses (CP3, CP4) prove weakest at 72--79\% WASR, while input-literal defenses (CP1) are strongest at 13\% WASR. Claude achieves the strongest safety (42.8\% WASR), followed by GPT-5 (55.9\%) and Gemini (59.5\%).
  These findings suggest that current defenses are strongest at input-literal checkpoints but remain vulnerable to intent-level manipulation and output-stage techniques. The Four-Checkpoint Framework provides a structured approach for identifying and addressing safety vulnerabilities in deployed systems.

</details>


### [27] [PiTPM: Partially Interactive Signatures for Multi-Device TPM Operations](https://arxiv.org/abs/2602.09707)
*Yunusa Simpa Abdulsalam,Mustapha Hedabou*

Main category: cs.CR

TL;DR: PiTPM是一个基于TPM 2.0的聚合器框架，采用Schnorr签名方案，通过混合信任架构消除了多方签名中的交互需求，实现了常数大小的签名和显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于TPM 2.0的多方签名方案存在根本性限制：需要所有参与者在承诺阶段进行交互协调，导致同步瓶颈、二次通信复杂度和参与者故障导致协议中止等问题，这在跨设备加密操作中尤为突出。

Method: 提出PiTPM聚合器框架，基于Schnorr数字签名，采用混合信任架构。框架使用存储在聚合器中的预共享随机种子，实现无需参与者间通信的确定性全局承诺计算。

Result: 提出的框架实现了常数大小的签名（与签名者数量无关），实验结果表明在TPM加密系统设计中可能实现范式转变，混合信任架构在保持严格安全保证的同时实现了显著性能提升。

Conclusion: PiTPM通过混合信任架构解决了TPM多方签名的交互限制问题，提供了形式化安全分析证明其在随机预言模型下基于离散对数假设的EU-CMA安全性，为分布式系统提供了更高效的多方签名方案。

Abstract: Trusted Platform Module (TPM) 2.0 devices provide efficient hardware-based cryptographic security through tamper-resistant key storage and computation, making them ideal building blocks for multi-party signature schemes in distributed systems. However, existing TPM-based multi-signature constructions suffer from a fundamental limitation, they require interactive protocols where all participants must coordinate during the commitment phase, before any signature can be computed. This interactive requirement creates several critical problems, such as synchronization bottlenecks, quadratic communication complexity, and aborted protocols as a result of participant failure. These limitations become particularly heightened for applications that require cross-device cryptographic operations. This paper presents PiTPM, an Aggregator Framework built upon Schnorr's digital signature. Our protocol eliminates the interactive requirement using a hybrid trust architecture. The proposed framework uses pre-shared randomness seeds stored securely in an Aggregator, enabling deterministic computation of global commitments without inter-participant communication. The resulting signatures of the proposed framework are of constant size regardless of signer count. Our experimental results show a possible paradigm shift in TPM-based cryptographic system design, demonstrating that hybrid trust architectures can achieve significant performance improvements while maintaining rigorous security guarantees. We provide a comprehensive formal security analysis proving EU-CMA security under the discrete logarithm assumption in the random oracle model.

</details>


### [28] [From Multi-sig to DLCs: Modern Oracle Designs on Bitcoin](https://arxiv.org/abs/2602.09822)
*Giulio Caldarelli*

Main category: cs.CR

TL;DR: 该研究调查了2015年后比特币Layer 1的预言机设计发展，发现主要从多签模式转向基于证明的设计（特别是DLC），后者在实际应用中表现更好。


<details>
  <summary>Details</summary>
Motivation: 比特币作为交易账本的设计限制了其条件应用的可编程性，特别是在依赖外部事件的预言机机制方面。研究旨在了解自2015年以太坊智能合约时代以来，比特币Layer 1是否出现了新的预言机设计，以及后续的比特币改进提案是否扩展了预言机的可实现性。

Method: 使用Scopus和Web of Science数据库进行文献检索，并辅以Google Scholar来捕捉协议提案，分析比特币Layer 1预言机设计的发展趋势。

Result: 研究发现学术文献覆盖有限，许多贡献在期刊渠道之外流通。主要变化是从多签模式（将预言机视为共同签名者）转向基于证明的设计，特别是离散对数合约（DLCs）。DLCs显示出更强的比特币社区合规性、工具支持，并在实际场景（如博彩和预测市场机制）中有实施证据。

Conclusion: 比特币Layer 1的预言机设计在2015年后发生了显著转变，从多签模式转向基于证明的设计，其中DLCs成为主流，具有更好的社区支持、工具生态和实际应用前景。

Abstract: Unlike Ethereum, which was conceived as a general-purpose smart-contract platform, Bitcoin was designed primarily as a transaction ledger for its native currency, which limits programmability for conditional applications. This constraint is particularly evident when considering oracles, mechanisms that enable Bitcoin contracts to depend on exogenous events. This paper investigates whether new oracle designs have emerged for Bitcoin Layer 1 since the 2015 transition to the Ethereum smart contracts era and whether subsequent Bitcoin improvement proposals have expanded oracles' implementability. Using Scopus and Web of Science searches, complemented by Google Scholar to capture protocol proposals, we observe that the indexed academic coverage remains limited, and many contributions circulate outside journal venues. Within the retrieved corpus, the main post-2015 shift is from multisig-style, which envisioned oracles as co-signers, toward attestation-based designs, mainly represented by Discreet Log Contracts (DLCs), which show stronger Bitcoin community compliance, tool support, and evidence of practical implementations in real-world scenarios such as betting and prediction-market mechanisms.

</details>


### [29] [Spinel: A Post-Quantum Signature Scheme Based on SLn(Fp) Hashing](https://arxiv.org/abs/2602.09882)
*Asmaa Cherkaoui,Faraz Heravi,Delaram Kahrobaei,Siamak F. Shahandashti*

Main category: cs.CR

TL;DR: Spinel是一个后量子数字签名方案，结合了SPHINCS+的安全性和基于SL_n(F_p)上扩展图导航问题的新型代数哈希函数，为量子计算时代提供安全签名方案。


<details>
  <summary>Details</summary>
Motivation: 量子计算的出现迫使密码学界设计超越经典硬度假设的数字签名方案，需要开发能够抵抗量子攻击的后量子密码方案。

Method: 将SPHINCS+签名方案与基于Tillich-Zemor范式的新型代数哈希函数相结合，该哈希函数的安全性基于SL_n(F_p)上扩展图导航问题的硬度，该问题被认为对量子攻击也是困难的。

Result: 提供了哈希函数安全性的经验证据，展示了如何将哈希函数集成到SPHINCS+框架中，分析了安全退化并确定了参数选择，实现了哈希函数和Spinel签名方案，并提供了详细的性能评估结果。

Conclusion: Spinel为代数哈希基签名方案的设计奠定了基础，扩展了后量子密码学的工具箱，展示了在实际应用中的可行性。

Abstract: The advent of quantum computation compels the cryptographic community to design digital signature schemes whose security extends beyond the classical hardness assumptions. In this work, we introduce Spinel, a post-quantum digital signature scheme that combines the proven security of SPHINCS+ (CCS 2019) with a new family of algebraic hash functions (Adv. Math. Commun. 2025) derived from the Tillich-Zemor paradigm (Eurocrypt 2008) with security rooted in the hardness of navigating expander graphs over SL_n(F_p), a problem believed to be hard even for quantum adversaries. We first provide empirical evidence of the security of this hash function, complementing the original theoretical analysis. We then show how the hash function can be integrated within the SPHINCS+ framework to give a secure signature scheme. We then model and analyze the security degradation of the proposed scheme, which informs the parameter selection we discuss next. Finally, we provide an implementation of the hash function and the proposed signature scheme Spinel as well as detailed empirical results for the performance of Spinel showing its feasibility in practice. Our approach lays the foundations for the design of algebraic hash-based signature schemes, expanding the toolkit of post-quantum cryptography.

</details>


### [30] [The Need for Standardized Evidence Sampling in CMMC Assessments: A Survey-Based Analysis of Assessor Practices](https://arxiv.org/abs/2602.09905)
*Logan Therrien,John Hastings*

Main category: cs.CR

TL;DR: 研究发现CMMC评估中证据抽样实践缺乏标准化，主要依赖评估员主观判断而非正式统计方法，导致评估结果不一致性风险


<details>
  <summary>Details</summary>
Motivation: CMMC框架虽然定义了评估目标和控制要求，但缺乏关于证据抽样的正式指导，这可能导致评估实践不一致，影响认证结果的可靠性

Method: 通过匿名调查收集CMMC认证评估员和首席评估员的数据，采用探索性研究方法分析证据抽样实践中的不一致性

Result: 17份有效调查显示，证据抽样实践主要依赖评估员判断、感知风险和环境复杂性，而非正式统计抽样模型；参与者普遍报告评估间存在不一致，支持制定标准化指导但反对僵化的百分比要求

Conclusion: 缺乏统一的证据抽样框架引入了变异性，可能影响评估可靠性和认证结果的可信度；建议为未来CMMC评估方法开发和实证研究提供指导

Abstract: The Cybersecurity Maturity Model Certification (CMMC) framework provides a common standard for protecting sensitive unclassified information in defense contracting. While CMMC defines assessment objectives and control requirements, limited formal guidance exists regarding evidence sampling, the process by which assessors select, review, and validate artifacts to substantiate compliance. Analyzing data collected through an anonymous survey of CMMC-certified assessors and lead assessors, this exploratory study investigates whether inconsistencies in evidence sampling practices exist within the CMMC assessment ecosystem and evaluates the need for a risk-informed standardized sampling methodology. Across 17 usable survey responses, results indicate that evidence sampling practices are predominantly driven by assessor judgment, perceived risk, and environmental complexity rather than formalized standards, with formal statistical sampling models rarely referenced. Participants frequently reported inconsistencies across assessments and expressed broad support for the development of standardized guidance, while generally opposing rigid percentage-based requirements. The findings support the conclusion that the absence of a uniform evidence sampling framework introduces variability that may affect assessment reliability and confidence in certification outcomes. Recommendations are provided to inform future CMMC assessment methodology development and further empirical research.

</details>


### [31] [CAPID: Context-Aware PII Detection for Question-Answering Systems](https://arxiv.org/abs/2602.10074)
*Mariia Ponomarenko,Sepideh Abedini,Masoumeh Shafieinejad,D. B. Emerson,Shubhankar Mohapatra,Xi He*

Main category: cs.CR

TL;DR: CAPID：一种通过微调本地小型语言模型实现隐私保护PII检测的方法，能够识别PII的上下文相关性，在保护隐私的同时保持问答系统质量


<details>
  <summary>Details</summary>
Motivation: 当前PII检测方法通常直接屏蔽所有个人信息，忽略了其中部分信息可能对用户问题具有上下文相关性，导致回答质量下降。大型语言模型虽能判断相关性，但因其闭源特性和缺乏隐私保障，不适合处理敏感数据。

Method: 提出CAPID方法：1）使用LLM生成包含多种PII类型和相关性级别的合成数据集；2）微调本地小型语言模型，使其能够检测PII范围、分类PII类型并评估上下文相关性；3）在问答系统中，先由SLM过滤敏感信息，再将处理后的内容传递给LLM进行回答。

Result: 实验表明，基于微调SLM的相关性感知PII检测在范围检测、相关性判断和类型分类准确率上显著优于现有基线方法，同时在匿名化处理下保持了更高的下游任务效用。

Conclusion: CAPID提供了一种实用的隐私保护PII检测方案，通过本地微调的小型语言模型实现了相关性感知的敏感信息过滤，在保护用户隐私的同时最大限度地保持了问答系统的回答质量。

Abstract: Detecting personally identifiable information (PII) in user queries is critical for ensuring privacy in question-answering systems. Current approaches mainly redact all PII, disregarding the fact that some of them may be contextually relevant to the user's question, resulting in a degradation of response quality. Large language models (LLMs) might be able to help determine which PII are relevant, but due to their closed source nature and lack of privacy guarantees, they are unsuitable for sensitive data processing. To achieve privacy-preserving PII detection, we propose CAPID, a practical approach that fine-tunes a locally owned small language model (SLM) that filters sensitive information before it is passed to LLMs for QA. However, existing datasets do not capture the context-dependent relevance of PII needed to train such a model effectively. To fill this gap, we propose a synthetic data generation pipeline that leverages LLMs to produce a diverse, domain-rich dataset spanning multiple PII types and relevance levels. Using this dataset, we fine-tune an SLM to detect PII spans, classify their types, and estimate contextual relevance. Our experiments show that relevance-aware PII detection with a fine-tuned SLM substantially outperforms existing baselines in span, relevance and type accuracy while preserving significantly higher downstream utility under anonymization.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [32] [RuleFlow : Generating Reusable Program Optimizations with LLMs](https://arxiv.org/abs/2602.09051)
*Avaljot Singh,Dushyant Bharadwaj,Stefanos Baziotis,Kaushik Varadharajan,Charith Mendis*

Main category: cs.SE

TL;DR: RuleFlow是一个三阶段混合方法，通过发现程序特定优化、转换为通用重写规则、集成到编译器中，实现Pandas程序优化，在PandasBench上达到4.3倍加速。


<details>
  <summary>Details</summary>
Motivation: 现有Pandas优化方法存在局限性：系统方法笨重且支持有限，编译器方法可靠但优化范围有限，LLM方法能发现非平凡优化但不可靠、昂贵且产出率低。需要一种结合可靠性和广泛优化能力的方法。

Method: RuleFlow采用三阶段混合方法：1) 发现阶段：使用LLM发现程序特定优化；2) 桥接阶段：将发现的优化转换为通用重写规则；3) 部署阶段：将规则集成到编译器中，自动应用规则，避免重复依赖LLM。

Result: 在PandasBench基准测试中，RuleFlow成为新的SOTA Pandas优化框架：相比前编译器SOTA（Dias）加速达4.3倍，相比前系统SOTA（Modin）加速达1914.9倍。

Conclusion: RuleFlow通过将LLM发现的优化转换为编译器可用的通用规则，实现了可靠且广泛的Pandas程序优化，解决了现有方法的局限性。

Abstract: Optimizing Pandas programs is a challenging problem. Existing systems and compiler-based approaches offer reliability but are either heavyweight or support only a limited set of optimizations. Conversely, using LLMs in a per-program optimization methodology can synthesize nontrivial optimizations, but is unreliable, expensive, and offers a low yield. In this work, we introduce a hybrid approach that works in a 3-stage manner that decouples discovery from deployment and connects them via a novel bridge. First, it discovers per-program optimizations (discovery). Second, they are converted into generalised rewrite rules (bridge). Finally, these rules are incorporated into a compiler that can automatically apply them wherever applicable, eliminating repeated reliance on LLMs (deployment). We demonstrate that RuleFlow is the new state-of-the-art (SOTA) Pandas optimization framework on PandasBench, a challenging Pandas benchmark consisting of Python notebooks. Across these notebooks, we achieve a speedup of up to 4.3x over Dias, the previous compiler-based SOTA, and 1914.9x over Modin, the previous systems-based SOTA.
  Our code is available at https://github.com/ADAPT-uiuc/RuleFlow.

</details>


### [33] [Predicting Open Source Software Sustainability with Deep Temporal Neural Hierarchical Architectures and Explainable AI](https://arxiv.org/abs/2602.09064)
*S M Rakib Ul Karim,Wenyi Lu,Enock Kasaadha,Sean Goggins*

Main category: cs.SE

TL;DR: 提出一个分层预测框架，将开源软件项目建模为基于社会技术分类的不同生命周期阶段，通过多阶段分类管道实现94%准确率的阶段分类。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要依赖静态或聚合指标（如项目年龄或累计活动），对开源软件可持续性随时间演变的理解有限。需要一种能够捕捉项目生命周期轨迹动态变化的方法。

Method: 提出分层预测框架，将开源项目建模为基于社会技术分类的生命周期阶段。框架结合工程化表格指标和24个月时间活动序列，采用多阶段分类管道区分不同协调和参与机制的生命周期阶段，并整合可解释AI技术分析特征贡献。

Result: 在大规模开源仓库语料库上评估，该方法在生命周期阶段分类中达到超过94%的整体准确率。归因分析一致识别贡献活动和社区相关特征为主导信号。

Conclusion: 该框架能够有效建模开源项目的生命周期轨迹，强调集体参与动态在项目可持续性中的核心作用，为大规模评估项目组织和健康状况提供了新方法。

Abstract: Open Source Software (OSS) projects follow diverse lifecycle trajectories shaped by evolving patterns of contribution, coordination, and community engagement. Understanding these trajectories is essential for stakeholders seeking to assess project organization and health at scale. However, prior work has largely relied on static or aggregated metrics, such as project age or cumulative activity, providing limited insight into how OSS sustainability unfolds over time. In this paper, we propose a hierarchical predictive framework that models OSS projects as belonging to distinct lifecycle stages grounded in established socio-technical categorizations of OSS development. Rather than treating sustainability solely as project longevity, these lifecycle stages operationalize sustainability as a multidimensional construct integrating contribution activity, community participation, and maintenance dynamics. The framework combines engineered tabular indicators with 24-month temporal activity sequences and employs a multi-stage classification pipeline to distinguish lifecycle stages associated with different coordination and participation regimes. To support transparency, we incorporate explainable AI techniques to examine the relative contribution of feature categories to model predictions. Evaluated on a large corpus of OSS repositories, the proposed approach achieves over 94\% overall accuracy in lifecycle stage classification. Attribution analyses consistently identify contribution activity and community-related features as dominant signals, highlighting the central role of collective participation dynamics.

</details>


### [34] [DRAGON: Robust Classification for Very Large Collections of Software Repositories](https://arxiv.org/abs/2602.09071)
*Stefano Balla,Stefano Zacchiroli,Thomas Degueule,Jean-Rémy Falleri,Romain Robbes*

Main category: cs.SE

TL;DR: DRAGON是一个基于轻量级信号（文件和目录名称，可选README）的代码仓库分类器，在大规模软件集合中表现优异，即使README缺失也能保持良好性能。


<details>
  <summary>Details</summary>
Motivation: 现有代码仓库分类方法过度依赖README等元数据，但这些文件经常缺失，限制了在大规模实际场景中的应用。需要一种更稳健的分类方法。

Method: DRAGON完全基于版本控制系统中常见的轻量级信号：文件和目录名称，以及可选的README文件（当可用时）。该方法设计用于处理大规模和多样化的软件集合。

Result: 在大规模仓库分类中，DRAGON将F1@5从54.8%提升到60.8%，超越了现有技术。即使README缺失，性能仅下降6%。许多分类错误是语义相近的"近失"，增加了实际应用价值。

Conclusion: DRAGON提供了一种稳健、可扩展的代码仓库分类方法，适用于文档稀疏或不一致的真实场景。研究还发布了迄今为止最大的开源仓库分类数据集（82.5万个仓库），为未来大规模、语言无关的软件仓库理解研究奠定了基础。

Abstract: The ability to automatically classify source code repositories with ''topics'' that reflect their content and purpose is very useful, especially when navigating or searching through large software collections. However, existing approaches often rely heavily on README files and other metadata, which are frequently missing, limiting their applicability in real-world large-scale settings. We present DRAGON, a repository classifier designed for very large and diverse software collections. It operates entirely on lightweight signals commonly stored in version control systems: file and directory names, and optionally the README when available. In repository classification at scale, DRAGON improves F1@5 from 54.8% to 60.8%, surpassing the state of the art. DRAGON remains effective even when README files are absent, with performance degrading by only 6% w.r.t. when they are present. This robustness makes it practical for real-world settings where documentation is sparse or inconsistent. Furthermore, many of the remaining classification errors are near misses, where predicted labels are semantically close to the correct topics. This property increases the practical value of the predictions in real-world software collections, where suggesting a few related topics can still guide search and discovery. As a byproduct of developing DRAGON, we also release the largest open dataset to date for repository classification, consisting of 825 thousand repositories with associated ground-truth topics, sourced from the Software Heritage archive, providing a foundation for future large-scale and language-agnostic research on software repository understanding.

</details>


### [35] [Towards an OSF-based Registered Report Template for Software Engineering Controlled Experiments](https://arxiv.org/abs/2602.09292)
*Ana B. M. Bett,Thais S. Nepomuceno,Edson OliveiraJr,Maria Teresa Baldassarre,Valdemar V. Graciano Neto,Marcos Kalinowski*

Main category: cs.SE

TL;DR: 该论文分析了在软件工程控制实验中采用注册报告（RR）模板的现状，发现现有OSF模板无法完全满足SE实验文档指南要求，建议建立专门的SE注册报告指南。


<details>
  <summary>Details</summary>
Motivation: 软件工程实证研究社区虽然改进了实验方法，但控制实验的描述仍缺乏严谨性，影响了可重复性和透明度。注册报告（RR）作为一种解决方案被讨论，但需要适合软件工程实验的模板。

Method: 分析Open Science Framework（OSF）上选定的注册报告类型模板，对照软件工程控制实验的文档指南进行评估，考察模板与指南的匹配程度。

Result: 分析发现，尽管有一个RR类型与许多文档建议相符，但没有一个模板能全面覆盖指南要求。研究还揭示了OSF RR模板定制化的局限性。

Conclusion: 尽管软件工程实证研究有进步，但实验规划和文档仍缺乏严谨性，损害了可重复性。建议采用基于OSF的注册报告，但目前没有可用的RR类型完全满足指南要求，建立软件工程特定的注册报告指南至关重要。

Abstract: Context: The empirical software engineering (ESE) community has contributed to improving experimentation over the years. However, there is still a lack of rigor in describing controlled experiments, hindering reproducibility and transparency. Registered Reports (RR) have been discussed in the ESE community to address these issues. A RR registers a study's hypotheses, methods, and/or analyses before execution, involving peer review and potential acceptance before data collection. This helps mitigate problematic practices such as p-hacking, publication bias, and inappropriate post hoc analysis. Objective: This paper presents initial results toward establishing an RR template for Software Engineering controlled experiments using the Open Science Framework (OSF). Method: We analyzed templates of selected OSF RR types in light of documentation guidelines for controlled experiments. Results: The observed lack of rigor motivated our investigation of OSF-based RR types. Our analysis showed that, although one of the RR types aligned with many of the documentation suggestions contained in the guidelines, none of them covered the guidelines comprehensively. The study also highlights limitations in OSF RR template customization. Conclusion: Despite progress in ESE, planning and documenting experiments still lack rigor, compromising reproducibility. Adopting OSF-based RRs is proposed. However, no currently available RR type fully satisfies the guidelines. Establishing RR-specific guidelines for SE is deemed essential.

</details>


### [36] [Cross-Project Flakiness: A Case Study of the OpenStack Ecosystem](https://arxiv.org/abs/2602.09311)
*Tao Xiao,Dong Wang,Shane McIntosh,Hideaki Hata,Yasutaka Kamei*

Main category: cs.SE

TL;DR: 本文对OpenStack生态系统中的测试不稳定性进行了实证研究，发现跨项目不稳定性影响55%的项目，显著增加审查时间和计算成本，70%的单元测试表现出跨项目不稳定性，挑战了单元测试固有的隔离假设。


<details>
  <summary>Details</summary>
Motivation: 自动化回归测试是现代软件开发的核心，但测试不稳定性（flakiness）会破坏开发者对测试结果的信任、浪费计算资源并削弱持续集成的可靠性。虽然已有研究关注单个项目内的测试不稳定性，但其在更广泛的生态系统层面的影响尚未得到充分探索。

Method: 对OpenStack生态系统中649个项目进行实证研究，重点关注：(1) 跨项目不稳定性——不稳定的测试影响多个项目；(2) 不一致的不稳定性——测试在某些项目中表现出不稳定性，在其他项目中保持稳定。通过分析识别出1,535个跨项目不稳定测试和1,105个不一致不稳定测试。

Result: 研究发现：跨项目不稳定性影响55%的OpenStack项目，显著增加审查时间和计算成本；70%的单元测试表现出跨项目不稳定性，挑战了单元测试固有的隔离假设；通过定性分析发现，持续集成中的竞争条件、不一致的构建配置和依赖不匹配是不一致不稳定性的主要原因。

Conclusion: 这些发现强调了在复杂生态系统中需要更好的跨项目协调、标准化的持续集成配置以及改进的测试隔离策略。研究结果对理解测试不稳定性的生态系统影响具有重要意义，并为改进软件测试实践提供了实证依据。

Abstract: Automated regression testing is a cornerstone of modern software development, often contributing directly to code review and Continuous Integration (CI). Yet some tests suffer from flakiness, where their outcomes vary non-deterministically. Flakiness erodes developer trust in test results, wastes computational resources, and undermines CI reliability. While prior research has examined test flakiness within individual projects, its broader ecosystem-wide impact remains largely unexplored. In this paper, we present an empirical study of test flakiness in the OpenStack ecosystem, which focuses on (1) cross-project flakiness, where flaky tests impact multiple projects, and (2) inconsistent flakiness, where a test exhibits flakiness in some projects but remains stable in others. By analyzing 649 OpenStack projects, we identify 1,535 cross-project flaky tests and 1,105 inconsistently flaky tests. We find that cross-project flakiness affects 55% of OpenStack projects and significantly increases both review time and computational costs. Surprisingly, 70% of unit tests exhibit cross-project flakiness, challenging the assumption that unit tests are inherently insulated from issues that span modules like integration and system-level tests. Through qualitative analysis, we observe that race conditions in CI, inconsistent build configurations, and dependency mismatches are the primary causes of inconsistent flakiness. These findings underline the need for better coordination across complex ecosystems, standardized CI configurations, and improved test isolation strategies.

</details>


### [37] [SWE-AGI: Benchmarking Specification-Driven Software Construction with MoonBit in the Era of Autonomous Agents](https://arxiv.org/abs/2602.09447)
*Zhirui Zhang,Hongbo Zhang,Haoxiang Fei,Zhiyuan Bao,Yubin Chen,Zhengyu Lei,Ziyue Liu,Yixuan Sun,Mingkun Xiao,Zihang Ye,Yu Zhang,Hongcheng Zhu,Yuxiang Wen,Heung-Yeung Shum*

Main category: cs.SE

TL;DR: SWE-AGI是一个开源基准测试，用于评估LLM基于明确规范构建生产级软件系统的能力，结果显示GPT-5.3-Codex表现最佳（86.4%），但随着任务难度增加性能急剧下降，代码阅读成为AI辅助开发的主要瓶颈。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在编码方面表现出色，但其基于明确规范自主构建生产级软件系统的能力仍是一个开放性问题。需要评估LLM在严格遵循权威标准和RFC规范下，构建大规模软件系统的实际能力。

Method: 引入SWE-AGI基准测试，要求LLM智能体在固定API框架下，严格依据权威标准和RFC规范实现解析器、解释器、二进制解码器和SAT求解器等任务。每个任务涉及1,000-10,000行核心逻辑代码，利用新兴的MoonBit生态系统最小化数据泄露，迫使智能体依赖长期架构推理而非代码检索。

Result: GPT-5.3-Codex表现最佳（19/22任务，86.4%），优于Claude-Opus-4.6（15/22，68.2%），Kimi-2.5在开源模型中表现最强。随着任务难度增加，性能急剧下降，特别是在规范密集的困难系统上。行为分析显示，随着代码库规模扩大，代码阅读而非编写成为AI辅助开发的主要瓶颈。

Conclusion: 虽然基于规范的自主软件工程越来越可行，但在可靠支持生产级开发之前仍面临重大挑战。代码阅读能力成为限制AI辅助软件开发规模扩展的关键因素。

Abstract: Although large language models (LLMs) have demonstrated impressive coding capabilities, their ability to autonomously build production-scale software from explicit specifications remains an open question. We introduce SWE-AGI, an open-source benchmark for evaluating end-to-end, specification-driven construction of software systems written in MoonBit. SWE-AGI tasks require LLM-based agents to implement parsers, interpreters, binary decoders, and SAT solvers strictly from authoritative standards and RFCs under a fixed API scaffold. Each task involves implementing 1,000-10,000 lines of core logic, corresponding to weeks or months of engineering effort for an experienced human developer. By leveraging the nascent MoonBit ecosystem, SWE-AGI minimizes data leakage, forcing agents to rely on long-horizon architectural reasoning rather than code retrieval. Across frontier models, gpt-5.3-codex achieves the best overall performance (solving 19/22 tasks, 86.4%), outperforming claude-opus-4.6 (15/22, 68.2%), and kimi-2.5 exhibits the strongest performance among open-source models. Performance degrades sharply with increasing task difficulty, particularly on hard, specification-intensive systems. Behavioral analysis further reveals that as codebases scale, code reading, rather than writing, becomes the dominant bottleneck in AI-assisted development. Overall, while specification-driven autonomous software engineering is increasingly viable, substantial challenges remain before it can reliably support production-scale development.

</details>


### [38] [Toward Linking Declined Proposals and Source Code: An Exploratory Study on the Go Repository](https://arxiv.org/abs/2602.09467)
*Sota Nakashima,Masanari Kondo,Mahmoud Alfadel,Aly Ahmad,Toshihiro Nakae,Hidenori Matsuzaki*

Main category: cs.SE

TL;DR: 该研究首次尝试在开源软件中建立被拒绝的贡献（如GitHub issue）与相关源代码之间的可追溯性链接，使用LLM驱动的管道进行分析，准确率达到0.836，平均精度为0.643。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注被接受的贡献，而被拒绝的贡献中包含了有价值的设计原理和软件决策的隐式知识。这些被拒绝贡献背后的讨论揭示了判断什么应该或不应该实现的标准，对开发者理解软件设计决策具有重要意义。

Method: 使用官方Go仓库中的提案（GitHub issues）作为数据集，设计了一个LLM驱动的管道来链接被拒绝的提案与源代码。管道首先选择正确的粒度级别，然后在相应粒度上生成链接。

Result: 管道在选择被拒绝提案的正确粒度方面准确率达到0.836，在相应粒度上生成正确链接的平均精度为0.643。失败分析显示，链接生成失败的主要原因是讨论内容冗余且缺乏具体实现信息。

Conclusion: 这是首次尝试建立被拒绝贡献与源代码之间的可追溯性链接的研究。虽然LLM驱动的管道取得了有希望的结果，但被拒绝提案中讨论的冗余性和信息不足仍然是链接生成的主要挑战。

Abstract: Traceability links are key information sources for software developers, connecting software artifacts (e.g., linking requirements to the corresponding source code). In open-source software (OSS) projects, such links play an important role, particularly between the contributions (e.g., GitHub issues) and the corresponding source code. Through these links, developers can trace the discussions in contributions and uncover design rationales, constraints, and security concerns. Previous studies have mainly examined accepted contributions, while those declined after discussion have been overlooked. The discussions behind declined contributions contain valuable design rationales and implicit knowledge about software decision-making, as the reasons behind the decline often reveal the criteria used to judge what should or should not be implemented. In this study, we present the first attempt to establish traceability links between declined contributions and related source code. We propose an initial linking approach and conduct an empirical analysis of the generated links to discuss factors affecting link generation. As our dataset, we use proposals from the official Go repository, which are GitHub issues used to propose new features or language changes. To link declined proposals to source code, we designed an LLM-driven pipeline. Our results showed that the pipeline selected the correct granularity for each declined proposal with an accuracy of 0.836, and generated correct links at that granularity with a mean precision of 0.643. To clarify the challenges of linking declined proposals, we performed a failure analysis. In the declined proposals where the pipeline failed to generate links, the discussions were often redundant and lacked concrete information (e.g., how the feature should be implemented).

</details>


### [39] [Immersion in the GitHub Universe: Scaling Coding Agents to Mastery](https://arxiv.org/abs/2602.09892)
*Jiale Zhao,Guoxin Chen,Fanzhe Meng,Minghao Li,Jie Chen,Hui Xu,Yongshuai Sun,Xin Zhao,Ruihua Song,Yuan Zhang,Peng Wang,Cheng Chen,Jirong Wen,Kai Jia*

Main category: cs.SE

TL;DR: ScaleSWE：一个自动化、沙箱化的多智能体工作流，通过处理600万个PR生成10万个已验证的软件工程实例，是目前最大的此类数据集，并基于此训练出在SWE Bench上达到64%解决率的智能体。


<details>
  <summary>Details</summary>
Motivation: 现实世界软件工程任务的掌握程度受到大规模高质量训练数据稀缺的根本性瓶颈限制。现有数据的扩展受到环境设置复杂性、单元测试生成和问题陈述策划的限制。

Method: 提出ScaleSWE系统，采用自动化、沙箱化的多智能体工作流，协调三个专门智能体（环境设置、测试创建、问题描述合成）来处理5200个仓库中的600万个拉取请求，生成ScaleSWE数据集。

Result: 生成了10万个已验证的软件工程实例（目前最大的此类数据集），在仓库多样性和任务复杂性方面显著超越现有数据集。基于此训练出的ScaleSWE智能体在SWE Bench Verified上达到64%的解决率，相比基础模型提升近三倍。

Conclusion: ScaleSWE为数据构建提供了可扩展、可复现的方法，能够推进基于LLM的软件工程发展。该数据集将公开可用。

Abstract: Achieving mastery in real world software engineering tasks is fundamentally bottlenecked by the scarcity of large scale, high quality training data. Scaling such data has been limited by the complexity of environment setup, unit test generation, and problem statement curation. In this paper, we propose ScaleSWE, an automated, sandboxed multi agent workflow designed to construct high quality SWE data at scale. The system coordinates three specialized agents for environment setup, test creation, and problem description synthesis to process 6 million pull requests across 5200 repositories, producing Scale SWE Data: 100k verified SWE instances, the largest such dataset to date. It substantially surpasses existing real world datasets in repository diversity and reflects realistic task complexity. We further demonstrate the dataset utility for training by distilling 71498 high quality trajectories and finetuning Qwen30BA3BInstruct to produce ScaleSWE Agent. Our agent achieves a 64 resolve rate on SWE Bench Verified a nearly three fold improvement over the base model. ScaleSWE provides a scalable, reproducible approach for data construction to advance LLM based software engineering. Scale SWE will be publicly available.

</details>


### [40] [JMigBench: A Benchmark for Evaluating LLMs on Source Code Migration (Java 8 to Java 11)](https://arxiv.org/abs/2602.09930)
*Nishil Amin,Zhiwei Fei,Xiang Li,Justyna Petke,He Ye*

Main category: cs.SE

TL;DR: 构建了JMigBench基准测试评估LLM在Java 8到11代码迁移任务中的表现，发现Mistral Codestral能处理简单API替换但无法应对复杂迁移场景。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在源代码迁移任务中的实际能力，特别是Java版本升级中的API迁移，为开发者提供自动化迁移工具的有效性评估。

Method: 1) 从开源仓库收集函数对数据集；2) 构建包含8类废弃API的精细化数据集；3) 使用Mistral Codestral模型进行评估；4) 采用CodeBLEU和基于关键词的指标衡量词汇、语义相似度和迁移正确性。

Result: Mistral Codestral能中等程度处理简单的一对一API替换（11.11%完全一致迁移），但在CORBA、JAX-WS等复杂迁移任务上表现不佳，无法完全替代人工迁移。

Conclusion: 当前LLM能部分减轻开发者在重复性迁移任务上的负担，但尚不能完全替代人工。基准测试为未来扩展数据集、优化提示策略和改进不同LLM迁移性能提供了基础。

Abstract: We build a benchmark to evaluate large language models (LLMs) for source code migration tasks, specifically upgrading functions from Java 8 to Java 11. We first collected a dataset of function pairs from open-source repositories, but limitations in data quality led us to construct a refined dataset covering eight categories of deprecated APIs. Using this dataset, the Mistral Codestral model was evaluated with CodeBLEU and keyword-based metrics to measure lexical and semantic similarity as well as migration correctness. Results show that the evaluated model (Mistral Codestral) can handle trivial one-to-one API substitutions with moderate success, achieving identical migrations in 11.11% of the cases, but it struggles with more complex migrations such as CORBA or JAX-WS. These findings suggest Mistral Codestral can partially reduce developer effort by automating repetitive migration tasks but cannot yet replace humans within the scope of the JMigBench benchmark. The benchmark and analysis provide a foundation for future work on expanding datasets, refining prompting strategies, and improving migration performance across different LLMs.

</details>


### [41] [QEMI: A Quantum Software Stacks Testing Framework via Equivalence Modulo Inputs](https://arxiv.org/abs/2602.09942)
*Junjie Luo,Shangzhou Xia,Fuyuan Zhang,Jianjun Zhao*

Main category: cs.SE

TL;DR: 提出量子EMI(QEMI)测试方法，通过生成包含死代码的随机量子程序并移除死代码生成变体，检测量子软件栈中的bug


<details>
  <summary>Details</summary>
Motivation: 随着量子算法和硬件的发展，确保量子软件栈的正确性变得日益重要。然而，由于oracle问题（缺乏可靠的预期程序行为基准），测试量子软件栈仍然具有挑战性。

Method: 基于等价模输入(EMI)思想，提出量子EMI(QEMI)方法：1) 基于量子控制流结构生成包含死代码的随机量子程序；2) 将EMI技术从经典编译器测试适配到量子领域，通过移除死代码生成程序变体。

Result: 将QEMI应用于Qiskit、Q#和Cirq，成功识别了11个崩溃bug和1个行为不一致问题。

Conclusion: QEMI通过超越结构转换并融入语义保持转换到量子程序分析，扩展了量子软件栈可用的有限测试技术集。

Abstract: As quantum algorithms and hardware continue to evolve, ensuring the correctness of the quantum software stack (QSS) has become increasingly important. However, testing QSSes remains challenging due to the oracle problem, i.e., the lack of a reliable ground truth for expected program behavior. Existing metamorphic testing approaches often rely on equivalent circuit transformations, backend modifications, or parameter tuning to address this issue. In this work, inspired by Equivalence Modulo Inputs (EMI), we propose Quantum EMI (QEMI), a new testing approach for QSSes. Our key contributions include: (1) a random quantum program generator that produces code with dead code based on quantum control-flow structures, and (2) an adaptation of the EMI technique from classical compiler testing to generate variants by removing dead code. By comparing the behavior of these variants, we can detect potential bugs in QSS implementations. We applied QEMI to Qiskit, Q#, and Cirq, and successfully identified 11 crash bugs and 1 behavioral inconsistency. QEMI expands the limited set of testing techniques available for quantum software stacks by going beyond structural transformations and incorporating semantics-preserving ones into quantum program analysis.

</details>


### [42] [Environment-in-the-Loop: Rethinking Code Migration with LLM-based Agents](https://arxiv.org/abs/2602.09944)
*Xiang Li,Zhiwei Fei,Ying Ma,Jerry Zhang,Sarro Federica,He Ye*

Main category: cs.SE

TL;DR: 论文指出当前代码迁移研究主要关注代码本身，而忽略了环境交互的自动化，导致实际部署效率低下。作者提出需要将环境构建与代码迁移工作流紧密结合的框架。


<details>
  <summary>Details</summary>
Motivation: 现代软件系统需要持续升级代码以增强功能、安全性和性能，LLMs在代码迁移任务中表现出色。然而，当前研究主要集中在代码迁移（重构、API适配、依赖更新），而对必须伴随的自动化环境交互探索相对不足。代码与环境紧密交织，仅依赖静态环境分析会导致对目标环境理解不足、反馈周期延长，从而造成大量返工和项目延迟，降低整体效率。

Method: 首先概述自动化环境构建的现状，然后提出一个将自动化环境设置与代码迁移工作流紧密集成的新型框架范式，最后探索代码迁移领域中自动化环境交互的挑战和未来方向。

Result: 研究发现，没有自动化环境交互，代码迁移的自动化只完成了一半。成功的软件演进需要整合代码和环境迁移的整体视角。

Conclusion: 论文强调软件成功演进需要代码和环境迁移的整体视角，提出将自动化环境设置与代码迁移工作流紧密结合的框架范式是解决当前问题的关键方向。

Abstract: Modern software systems continuously undergo code upgrades to enhance functionality, security, and performance, and Large Language Models (LLMs) have demonstrated remarkable capabilities in code migration tasks. However, while research on automated code migration which including refactoring, API adaptation, and dependency updates has advanced rapidly, the exploration of the automated environment interaction that must accompany it remains relatively scarce. In practice, code and its environment are intricately intertwined. Relying solely on static analysis of the environment leads to an inadequate understanding of the target setting, prolongs feedback cycles, and consequently causes significant rework and project delays, thereby reducing overall efficiency. We contend that successful software evolution demands a holistic perspective that integrates both code and environment migration. To understand the current landscape and challenges, we first provide an overview of the status of automated environment construction. We then propose a novel framework paradigm that tightly integrates automated environment setup with the code migration workflow. Finally, we explore the challenges and future directions for automated environment interaction within the code migration domain. Our findings emphasize that without automated environment interaction, the automation of code migration is only half complete.

</details>
