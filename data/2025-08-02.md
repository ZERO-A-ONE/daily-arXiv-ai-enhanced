<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 12]
- [cs.CR](#cs.CR) [Total: 4]
- [cs.AI](#cs.AI) [Total: 23]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [On LLM-Assisted Generation of Smart Contracts from Business Processes](https://arxiv.org/abs/2507.23087)
*Fabian Stiehle,Hans Weytjens,Ingo Weber*

Main category: cs.SE

TL;DR: 研究探讨了使用大型语言模型（LLM）从业务流程描述生成智能合约代码的可行性，并提出了一种自动化评估框架。结果表明，LLM在智能合约开发中的可靠性不足。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则的代码生成方法存在局限性，LLM被认为是一种潜在解决方案，但现有研究缺乏对生成代码执行正确性的系统评估。

Method: 通过自动化评估框架，测试不同类型和大小的LLM在生成智能合约代码时的表现，重点关注流程执行的关键属性。

Result: LLM在智能合约开发中的表现未能达到所需的完美可靠性。

Conclusion: 建议未来研究探索如何将LLM负责任地集成到现有代码生成工具中，以提高可靠性。提出的评估框架可作为开发此类集成的基础。

Abstract: Large language models (LLMs) have changed the reality of how software is
produced. Within the wider software engineering community, among many other
purposes, they are explored for code generation use cases from different types
of input. In this work, we present an exploratory study to investigate the use
of LLMs for generating smart contract code from business process descriptions,
an idea that has emerged in recent literature to overcome the limitations of
traditional rule-based code generation approaches. However, current LLM-based
work evaluates generated code on small samples, relying on manual inspection,
or testing whether code compiles but ignoring correct execution. With this
work, we introduce an automated evaluation framework and provide empirical data
from larger data sets of process models. We test LLMs of different types and
sizes in their capabilities of achieving important properties of process
execution, including enforcing process flow, resource allocation, and
data-based conditions. Our results show that LLM performance falls short of the
perfect reliability required for smart contract development. We suggest future
work to explore responsible LLM integrations in existing tools for code
generation to ensure more reliable output. Our benchmarking framework can serve
as a foundation for developing and evaluating such integrations.

</details>


### [2] [FlowETL: An Autonomous Example-Driven Pipeline for Data Engineering](https://arxiv.org/abs/2507.23118)
*Mattia Di Profio,Mingjun Zhong,Yaji Sripada,Marcel Jaspars*

Main category: cs.SE

TL;DR: FlowETL是一种基于示例的自主ETL管道架构，旨在自动标准化和准备输入数据集，减少人工干预。


<details>
  <summary>Details</summary>
Motivation: 现代ETL解决方案需要大量人工设计特定上下文且不可通用的转换，缺乏自动化能力。

Method: FlowETL通过规划引擎和ETL工作器构建并应用转换计划，结合监控和日志功能。

Result: 在14个不同领域、文件结构和大小的数据集上表现出良好的泛化能力。

Conclusion: FlowETL为ETL自动化提供了有效解决方案，减少了人工干预需求。

Abstract: The Extract, Transform, Load (ETL) workflow is fundamental for populating and
maintaining data warehouses and other data stores accessed by analysts for
downstream tasks. A major shortcoming of modern ETL solutions is the extensive
need for a human-in-the-loop, required to design and implement
context-specific, and often non-generalisable transformations. While related
work in the field of ETL automation shows promising progress, there is a lack
of solutions capable of automatically designing and applying these
transformations. We present FlowETL, a novel example-based autonomous ETL
pipeline architecture designed to automatically standardise and prepare input
datasets according to a concise, user-defined target dataset. FlowETL is an
ecosystem of components which interact together to achieve the desired outcome.
A Planning Engine uses a paired input-output datasets sample to construct a
transformation plan, which is then applied by an ETL worker to the source
dataset. Monitoring and logging provide observability throughout the entire
pipeline. The results show promising generalisation capabilities across 14
datasets of various domains, file structures, and file sizes.

</details>


### [3] [Vibe Modeling: Challenges and Opportunities](https://arxiv.org/abs/2507.23120)
*Jordi Cabot*

Main category: cs.SE

TL;DR: 论文提出了一种名为“vibe modeling”的新方法，旨在结合AI和MDE的优势，以加速开发可靠复杂系统。


<details>
  <summary>Details</summary>
Motivation: 随着软件系统需求的增长和复杂性的提升，现有开发方法和工具面临挑战，如用户界面多样化、智能组件需求和可持续性问题。MDE虽提升了开发质量和效率，但模型复杂度增加；而基于LLM的vibe coding方法虽快速生成代码，却存在漏洞和可维护性问题。

Method: 提出vibe modeling概念，整合AI（如LLM）和MDE的优势，以自然语言描述生成可靠模型。

Result: 论文概述了vibe modeling的关键概念，并探讨了其在未来建模中的机遇与挑战。

Conclusion: vibe modeling为结合AI与MDE提供了新思路，有望提升复杂系统开发的效率和可靠性，但仍需解决相关挑战。

Abstract: There is a pressing need for better development methods and tools to keep up
with the growing demand and increasing complexity of new software systems. New
types of user interfaces, the need for intelligent components, sustainability
concerns, ... bring new challenges that we need to handle. In the last years,
model-driven engineering (MDE) has been key to improving the quality and
productivity of software development, but models themselves are becoming
increasingly complex to specify and manage. At the same time, we are witnessing
the growing popularity of vibe coding approaches that rely on Large Language
Models (LLMs) to transform natural language descriptions into running code at
the expenses of code vulnerabilities, scalability issues and maintainability
concerns. In this paper, we introduce the concept of \textit{vibe modeling} as
a novel approach to integrate the best of both worlds (AI and MDE) to speed up
the development of reliable complex systems. We outline the key concepts of
vibe modeling and highlight the opportunities and open challenges it presents
for the future of modeling.

</details>


### [4] [Extension Decisions in Open Source Software Ecosystem](https://arxiv.org/abs/2507.23168)
*Elmira Onagh,Maleknaz Nayebi*

Main category: cs.SE

TL;DR: GitHub Marketplace的CI工具中，约65%的新功能是重复的，通常在六个月内出现。研究通过图模型分析功能发布和冗余工具，帮助开发者选择最佳发布时机。


<details>
  <summary>Details</summary>
Motivation: 研究GitHub Marketplace中CI工具的冗余现象，以帮助开发者和维护者优化工具选择和发布策略。

Method: 通过链接6,983个CI Actions到3,869个提供商，并挖掘其版本历史，构建图模型跟踪功能发布和冗余工具。

Result: 约65%的新CI Actions功能是重复的，且通常在六个月内出现；少数先行者工具主导了后续的分支和扩展。

Conclusion: 研究提供了数据驱动的工具选择和策略指导，并公开数据集以促进软件生态系统的创新和竞争研究。

Abstract: GitHub Marketplace is expanding by approximately 41% annually, with new
tools; however, many additions replicate existing functionality. We study this
phenomenon in the platform's largest segment, Continuous Integration (CI), by
linking 6,983 CI Actions to 3,869 providers and mining their version histories.
Our graph model timestamps every functionality's debut, tracks its adoption,
and clusters redundant tools. We find that approximately 65% of new CI Actions
replicate existing capabilities, typically within six months, and that a small
set of first-mover Actions accounts for most subsequent forks and extensions.
These insights enable developers to choose the optimal moment to launch, target
unmet functionality, and help maintainers eliminate redundant tools. We publish
the complete graph and dataset to encourage longitudinal research on innovation
and competition in software ecosystems, and to provide practitioners with a
data-driven roadmap for identifying emerging trends and guiding product
strategy.

</details>


### [5] [AutoBridge: Automating Smart Device Integration with Centralized Platform](https://arxiv.org/abs/2507.23178)
*Siyuan Liu,Zhice Yang,Huangxun Chen*

Main category: cs.SE

TL;DR: AutoBridge自动化生成IoT集成代码，通过分阶段调试确保正确性，成功率和功能覆盖率分别达93.87%和94.87%，用户反馈后可达100%。


<details>
  <summary>Details</summary>
Motivation: 减少人工编程复杂IoT集成代码的需求，提升效率和准确性。

Method: 采用分而治之策略：首先生成设备控制逻辑，再合成平台兼容代码，并通过多阶段调试确保正确性。

Result: 在34个IoT设备上测试，平均成功率和功能覆盖率分别为93.87%和94.87%，用户反馈后可达100%。

Conclusion: AutoBridge显著优于人工编程，提升代码准确性50%至80%。

Abstract: Multimodal IoT systems coordinate diverse IoT devices to deliver
human-centered services. The ability to incorporate new IoT devices under the
management of a centralized platform is an essential requirement. However, it
requires significant human expertise and effort to program the complex IoT
integration code that enables the platform to understand and control the device
functions. Therefore, we propose AutoBridge to automate IoT integration code
generation. Specifically, AutoBridge adopts a divide-and-conquer strategy: it
first generates device control logic by progressively retrieving
device-specific knowledge, then synthesizes platformcompliant integration code
using platform-specific knowledge. To ensure correctness, AutoBridge features a
multi-stage debugging pipeline, including an automated debugger for virtual IoT
device testing and an interactive hardware-in-the-loop debugger that requires
only binary user feedback (yes and no) for real-device verification. We
evaluate AutoBridge on a benchmark of 34 IoT devices across two open-source IoT
platforms. The results demonstrate that AutoBridge can achieves an average
success rate of 93.87% and an average function coverage of 94.87%, without any
human involvement. With minimal binary yes and no feedback from users, the code
is then revised to reach 100% function coverage. A user study with 15
participants further shows that AutoBridge outperforms expert programmers by
50% to 80% in code accuracy, even when the programmers are allowed to use
commercial code LLMs.

</details>


### [6] [XABPs: Towards eXplainable Autonomous Business Processes](https://arxiv.org/abs/2507.23269)
*Peter Fettke,Fabiana Fournier,Lior Limonad,Andreas Metzger,Stefanie Rinderle-Ma,Barbara Weber*

Main category: cs.SE

TL;DR: 论文提出可解释的自主业务流程（XABPs）以解决AI/ML驱动的自主业务流程（ABPs）带来的信任、调试、责任等问题。


<details>
  <summary>Details</summary>
Motivation: ABPs虽能提升效率和降低成本，但也带来信任、调试、责任等新问题，需通过可解释性解决。

Method: 提出XABPs概念，系统化其形式、构建可解释性框架，并识别关键研究挑战。

Result: XABPs能通过解释系统决策逻辑，增强信任并解决ABPs的潜在问题。

Conclusion: XABPs是解决ABPs问题的可行方向，需进一步研究其实现与应用。

Abstract: Autonomous business processes (ABPs), i.e., self-executing workflows
leveraging AI/ML, have the potential to improve operational efficiency, reduce
errors, lower costs, improve response times, and free human workers for more
strategic and creative work. However, ABPs may raise specific concerns
including decreased stakeholder trust, difficulties in debugging, hindered
accountability, risk of bias, and issues with regulatory compliance. We argue
for eXplainable ABPs (XABPs) to address these concerns by enabling systems to
articulate their rationale. The paper outlines a systematic approach to XABPs,
characterizing their forms, structuring explainability, and identifying key BPM
research challenges towards XABPs.

</details>


### [7] [SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution](https://arxiv.org/abs/2507.23348)
*Han Li,Yuling Shi,Shaoxin Lin,Xiaodong Gu,Heng Lian,Xin Wang,Yantao Jia,Tao Huang,Qianxiang Wang*

Main category: cs.SE

TL;DR: SWE-Debate是一个竞争性多代理辩论框架，通过多样化的推理路径和代码依赖图遍历，提升问题定位能力，并在SWE-bench基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于代理的问题解决方法通常局限于局部解决方案，难以识别跨代码库的问题模式。

Method: SWE-Debate通过创建多个故障传播路径作为定位提案，组织三轮辩论，由具有不同推理视角的代理协作达成一致的修复计划，最后通过MCTS代码修改代理生成补丁。

Result: 在SWE-bench基准测试中，SWE-Debate实现了开源代理框架的最新最优结果，显著优于基线方法。

Conclusion: SWE-Debate通过多代理辩论框架有效解决了现有方法的局限性，提升了问题定位和修复的准确性。

Abstract: Issue resolution has made remarkable progress thanks to the advanced
reasoning capabilities of large language models (LLMs). Recently, agent-based
frameworks such as SWE-agent have further advanced this progress by enabling
autonomous, tool-using agents to tackle complex software engineering tasks.
While existing agent-based issue resolution approaches are primarily based on
agents' independent explorations, they often get stuck in local solutions and
fail to identify issue patterns that span across different parts of the
codebase. To address this limitation, we propose SWE-Debate, a competitive
multi-agent debate framework that encourages diverse reasoning paths and
achieves more consolidated issue localization. SWE-Debate first creates
multiple fault propagation traces as localization proposals by traversing a
code dependency graph. Then, it organizes a three-round debate among
specialized agents, each embodying distinct reasoning perspectives along the
fault propagation trace. This structured competition enables agents to
collaboratively converge on a consolidated fix plan. Finally, this consolidated
fix plan is integrated into an MCTS-based code modification agent for patch
generation. Experiments on the SWE-bench benchmark show that SWE-Debate
achieves new state-of-the-art results in open-source agent frameworks and
outperforms baselines by a large margin.

</details>


### [8] [Quality Evaluation of COBOL to Java Code Transformation](https://arxiv.org/abs/2507.23356)
*Shmulik Froimovich,Raviv Gal,Wesam Ibraheem,Avi Ziv*

Main category: cs.SE

TL;DR: IBM开发了一个自动化评估系统，用于评估COBOL到Java的代码翻译，结合分析检查器和LLM作为评判技术，支持持续集成和大规模基准测试。


<details>
  <summary>Details</summary>
Motivation: 解决基于LLM的翻译器评估中的模型不透明性和翻译质量评估复杂性。

Method: 结合分析检查器和LLM-as-a-judge技术，提供可扩展的多方面评估。

Result: 系统支持持续集成、大规模基准测试，减少对人工审核的依赖。

Conclusion: 该系统为开发者和项目经理提供可操作的见解，促进高质量代码库的现代化演进。

Abstract: We present an automated evaluation system for assessing COBOL-to-Java code
translation within IBM's watsonx Code Assistant for Z (WCA4Z). The system
addresses key challenges in evaluating LLM-based translators, including model
opacity and the complexity of translation quality assessment. Our approach
combines analytic checkers with LLM-as-a-judge (LaaJ) techniques to deliver
scalable, multi-faceted evaluations. The system supports continuous integration
workflows, enables large-scale benchmarking, and reduces reliance on manual
review. We describe the system architecture, evaluation strategies, and
reporting mechanisms that provide actionable insights for developers and
project managers, facilitating the evolution of high-quality, modernized
codebases.

</details>


### [9] [SWE-Exp: Experience-Driven Software Issue Resolution](https://arxiv.org/abs/2507.23361)
*Silin Chen,Shaoxin Lin,Xiaodong Gu,Yuling Shi,Heng Lian,Longfei Yun,Dong Chen,Weiguo Sun,Lin Cao,Qianxiang Wang*

Main category: cs.SE

TL;DR: SWE-Exp通过从先前的代理轨迹中提取可操作的经验，实现跨问题的持续学习，显著提高了软件问题的解决率。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代理在解决软件问题时缺乏记忆能力，无法复用先前经验，导致效率低下。

Method: 引入多面经验库，捕获成功和失败的修复尝试，提取可复用的知识。

Result: 在SWE-bench-Verified上达到41.6%的Pass@1解决率，优于现有方法。

Conclusion: SWE-Exp为自动化软件工程代理提供了经验驱动的战略解决方案，显著提升了效率。

Abstract: Recent advances in large language model (LLM) agents have shown remarkable
progress in software issue resolution, leveraging advanced techniques such as
multi-agent collaboration and Monte Carlo Tree Search (MCTS). However, current
agents act as memoryless explorers - treating each problem separately without
retaining or reusing knowledge from previous repair experiences. This leads to
redundant exploration of failed trajectories and missed chances to adapt
successful issue resolution methods to similar problems. To address this
problem, we introduce SWE-Exp, an experience - enhanced approach that distills
concise and actionable experience from prior agent trajectories, enabling
continuous learning across issues. Our method introduces a multi-faceted
experience bank that captures both successful and failed repair attempts.
Specifically, it extracts reusable issue resolution knowledge at different
levels - from high-level problem comprehension to specific code changes.
Experiments show that SWE-Exp achieves state-of-the-art resolution rate (41.6%
Pass@1) on SWE-bench-Verified under open-source agent frameworks. Our approach
establishes a new paradigm in which automated software engineering agents
systematically accumulate and leverage repair expertise, fundamentally shifting
from trial-and-error exploration to strategic, experience-driven issue
resolution.

</details>


### [10] [Trae Agent: An LLM-based Agent for Software Engineering with Test-time Scaling](https://arxiv.org/abs/2507.23370)
*Trae Research Team,Pengfei Gao,Zhao Tian,Xiangxin Meng,Xinchen Wang,Ruida Hu,Yuanan Xiao,Yizhou Liu,Zhao Zhang,Junjie Chen,Cuiyun Gao,Yun Lin,Yingfei Xiong,Chao Peng,Xia Liu*

Main category: cs.SE

TL;DR: 本文提出了Trae Agent，一种基于代理的集成推理方法，用于解决软件仓库级别的问题。通过模块化代理处理生成、剪枝和选择，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示的方法在探索大型集成空间和仓库级理解方面存在局限性，影响了整体效果。

Method: Trae Agent将目标建模为最优解搜索问题，通过生成、剪枝和选择模块化代理解决两大挑战。

Result: 在SWE-bench基准测试中，Trae Agent平均Pass@1提升10.22%，并以75.20%的成绩领先排行榜。

Conclusion: Trae Agent在软件问题解决中表现出色，已开源以支持研究社区。

Abstract: Software issue resolution is a critical challenge in software engineering and
has garnered increasing attention in recent years. With the rapid advancement
of large language models (LLMs), substantial progress has been made in
addressing real-world software engineering tasks. Recent studies have
introduced ensemble reasoning techniques to enhance the performance of
LLM-based issue resolution. However, existing prompting-based methods still
face limitations in effectively exploring large ensemble spaces and lack the
capacity for repository-level understanding, both of which constrain their
overall effectiveness. In this paper, we propose Trae Agent, the first
agent-based ensemble reasoning approach for repository-level issue resolution.
Trae Agent formulates our goal as an optimal solution search problem and
addresses two key challenges, i.e., large ensemble spaces and repository-level
understanding, through modular agents for generation, pruning, and selection.
We conduct extensive experiments using three leading LLMs on the widely-adopted
SWE-bench benchmark, comparing Trae Agent against four state-of-the-art
ensemble reasoning techniques. Experimental results demonstrate that Trae Agent
consistently achieves superior performance, with an average improvement of
10.22% over all baselines in terms of Pass@1. Trae Agent has achieved first
place on the SWE-bench Verified leaderboard, with a notable Pass@1 score of
75.20%. We are pleased to release Trae Agent as an open-source project to
support the research community, with all resources available at
https://github.com/bytedance/trae-agent.

</details>


### [11] [Dynamic and Static Analysis of Python Software with Kieker Including Reconstructed Architectures](https://arxiv.org/abs/2507.23425)
*Daphné Larrivain,Shinhyung Yang,Wilhelm Hasselbring*

Main category: cs.SE

TL;DR: Kieker框架扩展支持Python，结合静态和动态分析，提供系统全面洞察。


<details>
  <summary>Details</summary>
Motivation: Python的流行使得对其应用的结构洞察变得重要，扩展Kieker支持Python具有价值。

Method: 结合静态和动态分析构建Python应用的完整视图。

Result: 实现了对Python应用的结构化分析能力。

Conclusion: Kieker框架的Python支持为开发者提供了更全面的系统观察工具。

Abstract: The Kieker observability framework is a tool that provides users with the
means to design a custom observability pipeline for their application.
Originally tailored for Java, supporting Python with Kieker is worthwhile.
Python's popularity has exploded over the years, thus making structural
insights of Python applications highly valuable. Our Python analysis pipeline
combines static and dynamic analysis in order to build a complete picture of a
given system.

</details>


### [12] [An Empirical Study on the Amount of Changes Required for Merge Request Acceptance](https://arxiv.org/abs/2507.23640)
*Samah Kansab,Mohammed Sayagh,Francis Bordeleau,Ali Tizghadam*

Main category: cs.SE

TL;DR: 论文研究了GitLab合并请求（MRs）中代码审查（CR）的工作量，定义为提交后修改的代码量。研究发现71%的MRs需要调整，28%涉及200行以上代码修改，且工作量与审查时间或参与者数量无关。通过机器学习模型预测，发现复杂度、开发者经验和文本特征是关键预测因素。


<details>
  <summary>Details</summary>
Motivation: 代码审查是软件开发的重要环节，但现有研究较少关注基于代码修改量的工作量，尤其是在GitLab MRs背景下。本文旨在填补这一空白。

Method: 使用来自四个GitLab项目的23,600多个MRs数据集，定义并测量CR工作量。训练可解释的机器学习模型，结合文本特征、代码复杂度、开发者经验等多维度指标。

Result: 71%的MRs需要调整，28%涉及200行以上代码修改。模型性能优异（AUC 0.84-0.88），复杂度、经验和文本特征是主要预测因素。

Conclusion: 研究表明机器学习可有效解释和预测代码审查工作量，复杂度、经验和历史项目特征是关键影响因素。

Abstract: Code review (CR) is essential to software development, helping ensure that
new code is properly integrated. However, the CR process often involves
significant effort, including code adjustments, responses to reviewers, and
continued implementation. While past studies have examined CR delays and
iteration counts, few have investigated the effort based on the volume of code
changes required, especially in the context of GitLab Merge Requests (MRs),
which remains underexplored. In this paper, we define and measure CR effort as
the amount of code modified after submission, using a dataset of over 23,600
MRs from four GitLab projects. We find that up to 71% of MRs require
adjustments after submission, and 28% of these involve changes to more than 200
lines of code. Surprisingly, this effort is not correlated with review time or
the number of participants. To better understand and predict CR effort, we
train an interpretable machine learning model using metrics across multiple
dimensions: text features, code complexity, developer experience, review
history, and branching. Our model achieves strong performance (AUC 0.84-0.88)
and reveals that complexity, experience, and text features are key predictors.
Historical project characteristics also influence current review effort. Our
findings highlight the feasibility of using machine learning to explain and
anticipate the effort needed to integrate code changes during review.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [13] [Fine-Grained Privacy Extraction from Retrieval-Augmented Generation Systems via Knowledge Asymmetry Exploitation](https://arxiv.org/abs/2507.23229)
*Yufei Chen,Yao Wang,Haibin Zhang,Tao Gu*

Main category: cs.CR

TL;DR: 本文提出了一种新的黑盒攻击框架，通过利用RAG系统与标准LLM之间的知识不对称性，实现了跨异构知识领域的细粒度隐私提取。


<details>
  <summary>Details</summary>
Motivation: 现有的隐私攻击方法在RAG系统中存在数据泄漏问题，但无法准确识别知识库来源的句子，且在多领域应用中缺乏鲁棒性。

Method: 采用链式思维推理策略，通过分解对抗性查询和语义关系评分，训练神经网络以精确识别包含隐私信息的句子。

Result: 实验结果显示，在单领域和多领域场景中分别实现了91%和83%的隐私提取率，敏感句子暴露减少了65%。

Conclusion: 该研究填补了RAG系统中攻击与防御之间的空白，为自适应缓解提供了基础。

Abstract: Retrieval-augmented generation (RAG) systems enhance large language models
(LLMs) by integrating external knowledge bases, but this advancement introduces
significant privacy risks. Existing privacy attacks on RAG systems can trigger
data leakage but often fail to accurately isolate knowledge-base-derived
sentences within mixed responses. They also lack robustness when applied across
multiple domains. This paper addresses these challenges by presenting a novel
black-box attack framework that exploits knowledge asymmetry between RAG and
standard LLMs to achieve fine-grained privacy extraction across heterogeneous
knowledge landscapes. We propose a chain-of-thought reasoning strategy that
creates adaptive prompts to steer RAG systems away from sensitive content.
Specifically, we first decompose adversarial queries to maximize information
disparity and then apply a semantic relationship scoring to resolve lexical and
syntactic ambiguities. We finally train a neural network on these feature
scores to precisely identify sentences containing private information. Unlike
prior work, our framework generalizes to unseen domains through iterative
refinement without pre-defined knowledge. Experimental results show that we
achieve over 91% privacy extraction rate in single-domain and 83% in
multi-domain scenarios, reducing sensitive sentence exposure by over 65% in
case studies. This work bridges the gap between attack and defense in RAG
systems, enabling precise extraction of private information while providing a
foundation for adaptive mitigation.

</details>


### [14] [Counterfactual Evaluation for Blind Attack Detection in LLM-based Evaluation Systems](https://arxiv.org/abs/2507.23453)
*Lijia Liu,Takumi Kondo,Kyohei Atarashi,Koh Takeuchi,Jiyi Li,Shigeru Saito,Hisashi Kashima*

Main category: cs.CR

TL;DR: 论文研究了针对LLM评估系统的提示注入防御方法，提出了一种对抗盲攻击的框架SE+CFE，显著提升了安全性。


<details>
  <summary>Details</summary>
Motivation: LLM评估系统易受盲攻击威胁，需开发有效防御方法。

Method: 提出SE+CFE框架，结合标准评估和反事实评估以检测攻击。

Result: 实验表明SE+CFE显著提升攻击检测率，性能损失极小。

Conclusion: SE+CFE框架能有效防御盲攻击，提升评估系统的安全性。

Abstract: This paper investigates defenses for LLM-based evaluation systems against
prompt injection. We formalize a class of threats called blind attacks, where a
candidate answer is crafted independently of the true answer to deceive the
evaluator. To counter such attacks, we propose a framework that augments
Standard Evaluation (SE) with Counterfactual Evaluation (CFE), which
re-evaluates the submission against a deliberately false ground-truth answer.
An attack is detected if the system validates an answer under both standard and
counterfactual conditions. Experiments show that while standard evaluation is
highly vulnerable, our SE+CFE framework significantly improves security by
boosting attack detection with minimal performance trade-offs.

</details>


### [15] [LLM-Based Identification of Infostealer Infection Vectors from Screenshots: The Case of Aurora](https://arxiv.org/abs/2507.23611)
*Estelle Ruellan,Eric Clay,Nicholas Ascoli*

Main category: cs.CR

TL;DR: 论文提出了一种利用LLM（如gpt-4o-mini）分析感染截图以提取潜在IoC、追踪恶意活动的新方法，展示了从1000张截图中提取337个可操作URL和246个相关文件的能力。


<details>
  <summary>Details</summary>
Motivation: 当前研究主要集中在主动检测恶意软件，而忽略了感染截图等反应性分析，导致对恶意活动追踪的不足。

Method: 利用LLM分析感染截图，提取URL、文件和感染主题，并关联数据以识别恶意活动和分发方法。

Result: 从1000张截图中提取了337个URL和246个文件，识别出3个恶意活动，揭示了分发方法和社会工程策略。

Conclusion: 通过LLM驱动的分析，研究提供了一种可扩展的方法，用于识别感染向量并增强威胁情报。

Abstract: Infostealers exfiltrate credentials, session cookies, and sensitive data from
infected systems. With over 29 million stealer logs reported in 2024, manual
analysis and mitigation at scale are virtually unfeasible/unpractical. While
most research focuses on proactive malware detection, a significant gap remains
in leveraging reactive analysis of stealer logs and their associated artifacts.
Specifically, infection artifacts such as screenshots, image captured at the
point of compromise, are largely overlooked by the current literature. This
paper introduces a novel approach leveraging Large Language Models (LLMs), more
specifically gpt-4o-mini, to analyze infection screenshots to extract potential
Indicators of Compromise (IoCs), map infection vectors, and track campaigns.
Focusing on the Aurora infostealer, we demonstrate how LLMs can process
screenshots to identify infection vectors, such as malicious URLs, installer
files, and exploited software themes. Our method extracted 337 actionable URLs
and 246 relevant files from 1000 screenshots, revealing key malware
distribution methods and social engineering tactics. By correlating extracted
filenames, URLs, and infection themes, we identified three distinct malware
campaigns, demonstrating the potential of LLM-driven analysis for uncovering
infection workflows and enhancing threat intelligence. By shifting malware
analysis from traditional log-based detection methods to a reactive,
artifact-driven approach that leverages infection screenshots, this research
presents a scalable method for identifying infection vectors and enabling early
intervention.

</details>


### [16] [Polynomial Lattices for the BIKE Cryptosystem](https://arxiv.org/abs/2507.23641)
*Michael Schaller*

Main category: cs.CR

TL;DR: 本文研究了BIKE密码系统中基于多项式环的秩2格，分析了其性质并推广了弱密钥恢复方法，展示了如何通过构造格解决最短向量问题并获取简化基。


<details>
  <summary>Details</summary>
Motivation: 研究BIKE密码系统中的格结构及其性质，以推广弱密钥恢复方法并提升安全性分析。

Method: 构造多项式环上的秩2格，分析其性质，并通过解决最短向量问题获取格的简化基。

Result: 展示了如何通过构造格解决最短向量问题，并获取简化基以检测更多弱密钥。

Conclusion: 通过格的简化基，可以更全面地检测弱密钥，为BIKE密码系统的安全性分析提供了新方法。

Abstract: In this paper we introduce a rank $2$ lattice over a polynomial ring arising
from the public key of the BIKE cryptosystem \cite{aragon2022bike}. The secret
key is a sparse vector in this lattice. We study properties of this lattice and
generalize the recovery of weak keys from \cite{BardetDLO16}. In particular, we
show that they implicitly solved a shortest vector problem in the lattice we
constructed. Rather than finding only a shortest vector, we obtain a reduced
basis of the lattice which makes it possible to check for more weak keys.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [17] [Unifying Post-hoc Explanations of Knowledge Graph Completions](https://arxiv.org/abs/2507.22951)
*Alessandro Lonardi,Samy Badreddine,Tarek R. Besold,Pablo Sanchez Martin*

Main category: cs.AI

TL;DR: 本文提出了一种统一的知识图谱补全（KGC）后验解释方法，通过多目标优化框架平衡解释的有效性和简洁性，并改进评估协议。


<details>
  <summary>Details</summary>
Motivation: 当前KGC后验解释缺乏形式化和一致的评估，影响可重复性和跨研究比较。

Method: 提出多目标优化框架统一现有解释算法，并改进评估协议（如使用Mean Reciprocal Rank和Hits@k）。

Result: 通过统一方法和改进评估标准，提升KGC解释研究的可重复性和影响力。

Conclusion: 强调解释的实用性，为KGC解释研究提供更统一和可操作的框架。

Abstract: Post-hoc explainability for Knowledge Graph Completion (KGC) lacks
formalization and consistent evaluations, hindering reproducibility and
cross-study comparisons. This paper argues for a unified approach to post-hoc
explainability in KGC. First, we propose a general framework to characterize
post-hoc explanations via multi-objective optimization, balancing their
effectiveness and conciseness. This unifies existing post-hoc explainability
algorithms in KGC and the explanations they produce. Next, we suggest and
empirically support improved evaluation protocols using popular metrics like
Mean Reciprocal Rank and Hits@$k$. Finally, we stress the importance of
interpretability as the ability of explanations to address queries meaningful
to end-users. By unifying methods and refining evaluation standards, this work
aims to make research in KGC explainability more reproducible and impactful.

</details>


### [18] [Data Readiness for Scientific AI at Scale](https://arxiv.org/abs/2507.23018)
*Wesley Brewer,Patrick Widener,Valentine Anantharaj,Feiyi Wang,Tom Beck,Arjun Shankar,Sarp Oral*

Main category: cs.AI

TL;DR: 本文探讨了数据准备原则（DRAI）在领导级科学数据集中的应用，分析了四个领域的典型工作流程，提出了一个针对高性能计算环境的二维准备框架。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决科学数据在AI训练中的预处理挑战，特别是针对生成模型的可扩展性和可重复性。

Method: 方法包括分析四个代表性领域的工作流程，提出一个结合数据准备级别和处理阶段的两维框架。

Result: 结果是一个概念成熟度矩阵，用于指导科学数据准备和基础设施开发。

Conclusion: 结论是该框架为跨领域标准化支持可扩展和可重复的科学AI提供了指导。

Abstract: This paper examines how Data Readiness for AI (DRAI) principles apply to
leadership-scale scientific datasets used to train foundation models. We
analyze archetypal workflows across four representative domains - climate,
nuclear fusion, bio/health, and materials - to identify common preprocessing
patterns and domain-specific constraints. We introduce a two-dimensional
readiness framework composed of Data Readiness Levels (raw to AI-ready) and
Data Processing Stages (ingest to shard), both tailored to high performance
computing (HPC) environments. This framework outlines key challenges in
transforming scientific data for scalable AI training, emphasizing
transformer-based generative models. Together, these dimensions form a
conceptual maturity matrix that characterizes scientific data readiness and
guides infrastructure development toward standardized, cross-domain support for
scalable and reproducible AI for science.

</details>


### [19] [FairReason: Balancing Reasoning and Social Bias in MLLMs](https://arxiv.org/abs/2507.23067)
*Zhenyu Pan,Yutong Zhang,Jianshu Zhang,Haoran Lu,Haozheng Luo,Yuwei Han,Philip S. Yu,Manling Li,Han Liu*

Main category: cs.AI

TL;DR: 研究发现，在MLLMs中，通过强化学习的1:4混合训练可以在减少10%偏见的同时保留88%的推理准确性。


<details>
  <summary>Details</summary>
Motivation: 探索推理能力提升与偏见缓解之间的交互作用，明确两者是否存在固有权衡。

Method: 比较三种偏见缓解策略（SFT、KD、RL），并在不同样本比例下分析推理与偏见的权衡。

Result: 强化学习的1:4混合训练显著减少偏见（10%）且保留高推理准确性（88%）。

Conclusion: 提供了一种平衡MLLMs公平性与能力的具体方法。

Abstract: Multimodal Large Language Models (MLLMs) already achieve state-of-the-art
results across a wide range of tasks and modalities. To push their reasoning
ability further, recent studies explore advanced prompting schemes and
post-training fine-tuning. Although these techniques improve logical accuracy,
they frequently leave the models' outputs burdened with pronounced social
biases. Clarifying how reasoning gains interact with bias mitigation-and
whether the two objectives inherently trade off-therefore remains an open and
pressing research problem. Our study begins by benchmarking three
bias-mitigation strategies-supervised fine-uning (SFT), knowledge distillation
(KD), and rule-based reinforcement learning (RL)-under identical conditions,
establishing their baseline strengths and weaknesses. Building on these
results, we vary the proportion of debias-focused and reasoning-centric samples
within each paradigm to chart the reasoning-versus-bias trade-off. Our sweeps
reveal a consistent sweet spot: a roughly 1:4 mix trained with reinforcement
learning cuts stereotype scores by 10% while retaining 88% of the model's
original reasoning accuracy, offering concrete guidance for balancing fairness
and capability in MLLMs.

</details>


### [20] [Moravec's Paradox: Towards an Auditory Turing Test](https://arxiv.org/abs/2507.23091)
*David Noever,Forrest McKee*

Main category: cs.AI

TL;DR: 当前AI系统在人类轻松完成的听觉任务上表现极差，失败率超过93%。研究通过听觉图灵测试揭示了AI在选择性注意力、噪声鲁棒性和上下文适应方面的不足。


<details>
  <summary>Details</summary>
Motivation: 受Moravec悖论启发，研究旨在量化AI与人类在听觉任务上的差距，并探索失败原因。

Method: 设计了包含917个挑战的听觉图灵测试，涵盖七类任务，评估了GPT-4和Whisper等先进模型。

Result: AI模型最高准确率仅6.9%，远低于人类的52%，暴露了其在复杂听觉场景处理中的缺陷。

Conclusion: 研究提出了诊断框架，强调需整合选择性注意力、基于物理的音频理解和上下文感知的新方法。

Abstract: This research work demonstrates that current AI systems fail catastrophically
on auditory tasks that humans perform effortlessly. Drawing inspiration from
Moravec's paradox (i.e., tasks simple for humans often prove difficult for
machines, and vice versa), we introduce an auditory Turing test comprising 917
challenges across seven categories: overlapping speech, speech in noise,
temporal distortion, spatial audio, coffee-shop noise, phone distortion, and
perceptual illusions. Our evaluation of state-of-the-art audio models including
GPT-4's audio capabilities and OpenAI's Whisper reveals a striking failure rate
exceeding 93%, with even the best-performing model achieving only 6.9% accuracy
on tasks that humans solved at 7.5 times higher success (52%). These results
expose focusing failures in how AI systems process complex auditory scenes,
particularly in selective attention, noise robustness, and contextual
adaptation. Our benchmark not only quantifies the human-machine auditory gap
but also provides insights into why these failures occur, suggesting that
current architectures lack fundamental mechanisms for human-like auditory scene
analysis. The traditional design of audio CAPTCHAs highlights common filters
that humans evolved but machines fail to select in multimodal language models.
This work establishes a diagnostic framework for measuring progress toward
human-level machine listening and highlights the need for novel approaches
integrating selective attention, physics-based audio understanding, and
context-aware perception into multimodal AI systems.

</details>


### [21] [Argumentatively Coherent Judgmental Forecasting](https://arxiv.org/abs/2507.23163)
*Deniz Gorur,Antonio Rago,Francesca Toni*

Main category: cs.AI

TL;DR: 论文提出并形式化定义了‘论证一致性’属性，要求预测者的推理与预测一致。通过实验证明，过滤不一致预测能提高人类和LLM预测的准确性，但用户实验显示用户通常不遵循这一属性。


<details>
  <summary>Details</summary>
Motivation: 研究人类和LLM预测中论证一致性的作用，以提高预测准确性。

Method: 定义论证一致性，并通过人类和LLM预测实验及用户实验验证其效果。

Result: 过滤不一致预测显著提高准确性，但用户通常不遵循一致性。

Conclusion: 论证一致性对预测准确性有实际价值，需在群体预测中过滤不一致意见。

Abstract: Judgmental forecasting employs human opinions to make predictions about
future events, rather than exclusively historical data as in quantitative
forecasting. When these opinions form an argumentative structure around
forecasts, it is useful to study the properties of the forecasts from an
argumentative perspective. In this paper, we advocate and formally define a
property of argumentative coherence, which, in essence, requires that a
forecaster's reasoning is coherent with their forecast. We then conduct three
evaluations with our notion of coherence. First, we assess the impact of
enforcing coherence on human forecasters as well as on Large Language Model
(LLM)-based forecasters, given that they have recently shown to be competitive
with human forecasters. In both cases, we show that filtering out incoherent
predictions improves forecasting accuracy consistently, supporting the
practical value of coherence in both human and LLM-based forecasting. Then, via
crowd-sourced user experiments, we show that, despite its apparent
intuitiveness and usefulness, users do not generally align with this coherence
property. This points to the need to integrate, within argumentation-based
judgmental forecasting, mechanisms to filter out incoherent opinions before
obtaining group forecasting predictions.

</details>


### [22] [Tractable Responsibility Measures for Ontology-Mediated Query Answering](https://arxiv.org/abs/2507.23191)
*Meghyn Bienvenu,Diego Figueira,Pierre Lafourcade*

Main category: cs.AI

TL;DR: 论文研究了基于Shapley值的责任评分在ontology-mediated查询中的计算复杂性，发现其在某些查询类中具有多项式数据复杂性，而在其他情况下则变得困难。


<details>
  <summary>Details</summary>
Motivation: 探讨如何量化事实对查询答案的贡献，特别是在ontology-mediated查询中，理解责任评分的计算复杂性。

Method: 利用数据库设置的结果，分析Shapley值责任评分的计算复杂性，包括数据复杂性和组合复杂性。

Result: 对于first-order-rewritable查询类，责任评分具有多项式数据复杂性；但在某些情况下（如支持合取的查询），计算变得困难。DL-Lite方言中的某些查询类仍可高效计算。

Conclusion: 研究揭示了责任评分计算复杂性的边界，为实际应用提供了指导。

Abstract: Recent work on quantitative approaches to explaining query answers employs
responsibility measures to assign scores to facts in order to quantify their
respective contributions to obtaining a given answer. In this paper, we study
the complexity of computing such responsibility scores in the setting of
ontology-mediated query answering, focusing on a very recently introduced
family of Shapley-value-based responsibility measures defined in terms of
weighted sums of minimal supports (WSMS). By exploiting results from the
database setting, we can show that such measures enjoy polynomial data
complexity for classes of ontology-mediated queries that are
first-order-rewritable, whereas the problem becomes "shP"-hard when the
ontology language can encode reachability queries (via axioms like $\exists R.
A \sqsubseteq A$). To better understand the tractability frontier, we next
explore the combined complexity of WSMS computation. We prove that
intractability applies already to atomic queries if the ontology language
supports conjunction, as well as to unions of `well-behaved' conjunctive
queries, even in the absence of an ontology. By contrast, our study yields
positive results for common DL-Lite dialects: by means of careful analysis, we
identify classes of structurally restricted conjunctive queries (which
intuitively disallow undesirable interactions between query atoms) that admit
tractable WSMS computation.

</details>


### [23] [Solution-aware vs global ReLU selection: partial MILP strikes back for DNN verification](https://arxiv.org/abs/2507.23197)
*Yuke Liao,Blaise Genest,Kuldeep Meel,Shaan Aryaman*

Main category: cs.AI

TL;DR: 论文提出了一种基于分治法的混合MILP方法，通过SAS评分选择关键ReLU变量，显著减少了二进制变量数量，提升了验证效率。


<details>
  <summary>Details</summary>
Motivation: 处理复杂实例时，传统方法在ReLU变量选择上效率不足，需要更优的评分机制来减少计算成本。

Method: 结合分治法，提出SAS评分和全局评分（GS），通过混合MILP和α,β-CROWN验证，优化ReLU变量选择。

Result: SAS评分将二进制变量减少约6倍，验证效率提升40%，未解决实例降至8-15%，平均运行时间46s-417s。

Conclusion: SAS评分和混合MILP方法显著提升了验证效率和准确性，适用于大规模神经网络。

Abstract: To handle complex instances, we revisit a divide-and-conquer approach to
break down the complexity: instead of few complex BaB calls, we rely on many
small {\em partial} MILP calls. The crucial step is to select very few but very
important ReLUs to treat using (costly) binary variables. The previous attempts
were suboptimal in that respect. To select these important ReLU variables, we
propose a novel {\em solution-aware} ReLU scoring ({\sf SAS}), as well as adapt
the BaB-SR and BaB-FSB branching functions as {\em global} ReLU scoring ({\sf
GS}) functions. We compare them theoretically as well as experimentally, and
{\sf SAS} is more efficient at selecting a set of variables to open using
binary variables. Compared with previous attempts, SAS reduces the number of
binary variables by around 6 times, while maintaining the same level of
accuracy. Implemented in {\em Hybrid MILP}, calling first $\alpha,\beta$-CROWN
with a short time-out to solve easier instances, and then partial MILP,
produces a very accurate yet efficient verifier, reducing by up to $40\%$ the
number of undecided instances to low levels ($8-15\%$), while keeping a
reasonable runtime ($46s-417s$ on average per instance), even for fairly large
CNNs with 2 million parameters.

</details>


### [24] [How Far Are AI Scientists from Changing the World?](https://arxiv.org/abs/2507.23276)
*Qiujie Xie,Yixuan Weng,Minjun Zhu,Fuchen Shen,Shulin Huang,Zhen Lin,Jiahui Zhou,Zilan Mao,Zijie Yang,Linyi Yang,Jian Wu,Yue Zhang*

Main category: cs.AI

TL;DR: 本文综述了基于大语言模型（LLM）的AI科学家系统的现状，探讨了其改变科学研究的潜力、当前瓶颈及未来目标。


<details>
  <summary>Details</summary>
Motivation: 探索AI科学家系统如何推动科学发现，并评估其距离实现突破性科学发现的能力。

Method: 通过前瞻性综述，全面分析AI科学家系统的现有成就，识别关键瓶颈和必要组件。

Result: 指出AI科学家系统已取得进展，但仍需解决关键问题以实现突破性发现。

Conclusion: 本文旨在明确当前AI科学家系统的局限性，并为其未来发展提供方向。

Abstract: The emergence of large language models (LLMs) is propelling automated
scientific discovery to the next level, with LLM-based Artificial Intelligence
(AI) Scientist systems now taking the lead in scientific research. Several
influential works have already appeared in the field of AI Scientist systems,
with AI-generated research papers having been accepted at the ICLR 2025
workshop, suggesting that a human-level AI Scientist capable of uncovering
phenomena previously unknown to humans, may soon become a reality. In this
survey, we focus on the central question: How far are AI scientists from
changing the world and reshaping the scientific research paradigm? To answer
this question, we provide a prospect-driven review that comprehensively
analyzes the current achievements of AI Scientist systems, identifying key
bottlenecks and the critical components required for the emergence of a
scientific agent capable of producing ground-breaking discoveries that solve
grand challenges. We hope this survey will contribute to a clearer
understanding of limitations of current AI Scientist systems, showing where we
are, what is missing, and what the ultimate goals for scientific AI should be.

</details>


### [25] [AI Must not be Fully Autonomous](https://arxiv.org/abs/2507.23330)
*Tosin Adewumi,Lama Alkhaled,Florent Imbert,Hui Han,Nudrat Habib,Karl Löwenmark*

Main category: cs.AI

TL;DR: 论文讨论了自主AI的三个级别，主张AI不应完全自主，并提出12个论点和6个反驳论点。


<details>
  <summary>Details</summary>
Motivation: 探讨自主AI的风险，尤其是超级智能（ASI）可能带来的威胁。

Method: 通过理论分析、论点和反驳，结合15个AI价值错位的案例。

Result: 强调人类监督对降低AI风险的重要性。

Conclusion: 完全自主的AI（级别3）风险过高，需保持人类监督。

Abstract: Autonomous Artificial Intelligence (AI) has many benefits. It also has many
risks. In this work, we identify the 3 levels of autonomous AI. We are of the
position that AI must not be fully autonomous because of the many risks,
especially as artificial superintelligence (ASI) is speculated to be just
decades away. Fully autonomous AI, which can develop its own objectives, is at
level 3 and without responsible human oversight. However, responsible human
oversight is crucial for mitigating the risks. To ague for our position, we
discuss theories of autonomy, AI and agents. Then, we offer 12 distinct
arguments and 6 counterarguments with rebuttals to the counterarguments. We
also present 15 pieces of recent evidence of AI misaligned values and other
risks in the appendix.

</details>


### [26] [DSBC : Data Science task Benchmarking with Context engineering](https://arxiv.org/abs/2507.23336)
*Ram Mohan Rao Kadiyala,Siddhant Gupta,Jebish Purbey,Giulio Martini,Suman Debnath,Hamza Farooq*

Main category: cs.AI

TL;DR: 论文提出了一种针对数据科学代理的全面基准测试，评估了三种大型语言模型在不同方法下的表现，揭示了性能差异和关键影响因素。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏系统性评估数据科学代理的基准，研究旨在填补这一空白，为实际部署提供指导。

Method: 通过商业应用观察用户交互，设计了包含八类任务的基准，测试了三种模型（Claude-4.0-Sonnet、Gemini-2.5-Flash、OpenAI-o4-Mini）在零样本、多步和SmolAgent方法下的表现。

Result: 研究发现不同模型和方法之间存在显著性能差异，并探讨了温度参数对结果的影响。

Conclusion: 提出的基准和评估框架为未来研究更鲁棒和高效的数据科学代理奠定了基础。

Abstract: Recent advances in large language models (LLMs) have significantly impacted
data science workflows, giving rise to specialized data science agents designed
to automate analytical tasks. Despite rapid adoption, systematic benchmarks
evaluating the efficacy and limitations of these agents remain scarce. In this
paper, we introduce a comprehensive benchmark specifically crafted to reflect
real-world user interactions with data science agents by observing usage of our
commercial applications. We evaluate three LLMs: Claude-4.0-Sonnet,
Gemini-2.5-Flash, and OpenAI-o4-Mini across three approaches: zero-shot with
context engineering, multi-step with context engineering, and with SmolAgent.
Our benchmark assesses performance across a diverse set of eight data science
task categories, additionally exploring the sensitivity of models to common
prompting issues, such as data leakage and slightly ambiguous instructions. We
further investigate the influence of temperature parameters on overall and
task-specific outcomes for each model and approach. Our findings reveal
distinct performance disparities among the evaluated models and methodologies,
highlighting critical factors that affect practical deployment. The benchmark
dataset and evaluation framework introduced herein aim to provide a foundation
for future research of more robust and effective data science agents.

</details>


### [27] [LLM4Rail: An LLM-Augmented Railway Service Consulting Platform](https://arxiv.org/abs/2507.23377)
*Zhuo Li,Xianghuai Deng,Chiwei Feng,Hanmeng Li,Shenjie Wang,Haichao Zhang,Teng Jia,Conlin Chen,Louis Linchun Wu,Jia Wang*

Main category: cs.AI

TL;DR: LLM4Rail是一个基于大语言模型（LLM）的铁路服务平台，通过QTAO提示框架整合推理与任务导向行动，提供个性化铁路服务。


<details>
  <summary>Details</summary>
Motivation: 满足日益增长的个性化铁路服务需求，提升铁路服务的智能化和定制化水平。

Method: 提出QTAO提示框架，整合推理与任务导向行动；构建CRFD-25数据集，并开发基于LLM的零样本对话推荐系统。

Result: LLM4Rail能提供准确的个性化铁路服务，包括票务、餐饮推荐等；CRFD-25数据集支持个性化餐饮服务。

Conclusion: LLM4Rail通过QTAO框架和CRFD-25数据集，有效提升了铁路服务的个性化和智能化水平。

Abstract: Large language models (LLMs) have significantly reshaped different walks of
business. To meet the increasing demands for individualized railway service, we
develop LLM4Rail - a novel LLM-augmented railway service consulting platform.
Empowered by LLM, LLM4Rail can provide custom modules for ticketing, railway
food & drink recommendations, weather information, and chitchat. In LLM4Rail,
we propose the iterative "Question-Thought-Action-Observation (QTAO)" prompting
framework. It meticulously integrates verbal reasoning with task-oriented
actions, that is, reasoning to guide action selection, to effectively retrieve
external observations relevant to railway operation and service to generate
accurate responses. To provide personalized onboard dining services, we first
construct the Chinese Railway Food and Drink (CRFD-25) - a publicly accessible
takeout dataset tailored for railway services. CRFD-25 covers a wide range of
signature dishes categorized by cities, cuisines, age groups, and spiciness
levels. We further introduce an LLM-based zero-shot conversational recommender
for railway catering. To address the unconstrained nature of open
recommendations, the feature similarity-based post-processing step is
introduced to ensure all the recommended items are aligned with CRFD-25
dataset.

</details>


### [28] [Chatting with your ERP: A Recipe](https://arxiv.org/abs/2507.23429)
*Jorge Ruiz Gómez,Lidia Andrés Susinos,Jorge Alamo Olivé,Sonia Rey Osorno,Manuel Luis Gonzalez Hernández*

Main category: cs.AI

TL;DR: 论文介绍了一种基于大型语言模型（LLM）的代理，用于与工业级ERP系统交互，通过自然语言查询生成可执行的SQL语句，并提出了一种双代理架构以提高可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决工业级ERP系统中自然语言查询转换为SQL语句的挑战，提高查询生成的准确性和可靠性。

Method: 采用双代理架构，结合推理和批判阶段，利用开源权重LLM实现自然语言到SQL的转换。

Result: 提出的双代理架构显著提高了查询生成的可靠性。

Conclusion: 该研究为工业级ERP系统的自然语言交互提供了可行的解决方案，双代理架构是提升可靠性的有效方法。

Abstract: This paper presents the design, implementation, and evaluation behind a Large
Language Model (LLM) agent that chats with an industrial production-grade ERP
system. The agent is capable of interpreting natural language queries and
translating them into executable SQL statements, leveraging open-weight LLMs. A
novel dual-agent architecture combining reasoning and critique stages was
proposed to improve query generation reliability.

</details>


### [29] [Self-Foveate: Enhancing Diversity and Difficulty of Synthesized Instructions from Unsupervised Text via Multi-Level Foveation](https://arxiv.org/abs/2507.23440)
*Mingzhe Li,Xin Lu,Yanyan Zhao*

Main category: cs.AI

TL;DR: 论文提出了一种名为Self-Foveate的创新方法，通过多级注视技术增强LLM生成指令的多样性和难度。


<details>
  <summary>Details</summary>
Motivation: 现有自动合成指令的方法在多样性和难度上存在不足，需要减少人工标注依赖并提升生成质量。

Method: 采用“Micro-Scatter-Macro”多级注视方法，指导LLM从无监督文本中挖掘细粒度信息。

Result: 在多个无监督语料库和模型架构上的实验验证了方法的有效性和优越性。

Conclusion: Self-Foveate显著提升了指令合成的多样性和难度，代码和数据已公开。

Abstract: Large language models (LLMs) with instruction following capabilities have
demonstrated impressive problem-solving abilities. While synthesizing
instructional data from unsupervised text has become a common approach for
training such models, conventional methods rely heavily on human effort for
data annotation. Although existing automated synthesis paradigms have
alleviated this constraint, they still exhibit significant limitations in
ensuring adequate diversity and difficulty of synthesized instructions. To
address these challenges, we propose Self-Foveate, an innovative LLM-driven
method for instruction synthesis. This approach introduces a
"Micro-Scatter-Macro" multi-level foveation methodology that effectively guides
the LLM to deeply excavate fine-grained information embedded in unsupervised
text, thereby enhancing both the diversity and difficulty of synthesized
instructions. Comprehensive experiments across multiple unsupervised corpora
and diverse model architectures validate the effectiveness and superiority of
our proposed method. We publicly release our data and codes:
https://github.com/Mubuky/Self-Foveate

</details>


### [30] [Causal Reasoning in Pieces: Modular In-Context Learning for Causal Discovery](https://arxiv.org/abs/2507.23488)
*Kacper Kadziolka,Saber Salehkaleybar*

Main category: cs.AI

TL;DR: 论文研究了大型语言模型在因果发现任务中的表现，提出了一种基于Tree-of-Thoughts和Chain-of-Thoughts的模块化流程，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 因果推理是大型语言模型的核心挑战，传统模型在数据扰动下表现不佳，因此探索先进推理模型在因果发现中的潜力。

Method: 使用OpenAI的o系列和DeepSeek-R模型，结合Tree-of-Thoughts和Chain-of-Thoughts方法，设计模块化流程进行因果发现。

Result: 新方法在Corr2Cause基准测试中表现显著优于传统方法，性能提升近三倍。

Conclusion: 先进推理模型结合结构化流程可显著提升因果发现能力，为跨领域应用提供通用框架。

Abstract: Causal inference remains a fundamental challenge for large language models.
Recent advances in internal reasoning with large language models have sparked
interest in whether state-of-the-art reasoning models can robustly perform
causal discovery-a task where conventional models often suffer from severe
overfitting and near-random performance under data perturbations. We study
causal discovery on the Corr2Cause benchmark using the emergent OpenAI's
o-series and DeepSeek-R model families and find that these reasoning-first
architectures achieve significantly greater native gains than prior approaches.
To capitalize on these strengths, we introduce a modular in-context pipeline
inspired by the Tree-of-Thoughts and Chain-of-Thoughts methodologies, yielding
nearly three-fold improvements over conventional baselines. We further probe
the pipeline's impact by analyzing reasoning chain length, complexity, and
conducting qualitative and quantitative comparisons between conventional and
reasoning models. Our findings suggest that while advanced reasoning models
represent a substantial leap forward, carefully structured in-context
frameworks are essential to maximize their capabilities and offer a
generalizable blueprint for causal discovery across diverse domains.

</details>


### [31] [Causal Identification of Sufficient, Contrastive and Complete Feature Sets in Image Classification](https://arxiv.org/abs/2507.23497)
*David A Kelly,Hana Chockler*

Main category: cs.AI

TL;DR: 论文提出了一种基于因果关系的图像分类器解释方法，兼具形式严谨性和实用性，适用于黑盒算法。


<details>
  <summary>Details</summary>
Motivation: 现有图像分类器解释方法缺乏形式严谨性，而逻辑解释虽严谨但假设严格，不适用于图像分类器。

Method: 提出因果解释方法，证明其形式性质，并引入对比性和置信度感知的完整因果解释。

Result: 实验表明不同模型在充分性、对比性和完整性上有不同表现，算法高效且完全黑盒。

Conclusion: 因果解释兼具形式严谨性和实用性，适用于图像分类器，且计算高效。

Abstract: Existing algorithms for explaining the outputs of image classifiers are based
on a variety of approaches and produce explanations that lack formal rigor. On
the other hand, logic-based explanations are formally and rigorously defined
but their computability relies on strict assumptions about the model that do
not hold on image classifiers.
  In this paper, we show that causal explanations, in addition to being
formally and rigorously defined, enjoy the same formal properties as
logic-based ones, while still lending themselves to black-box algorithms and
being a natural fit for image classifiers. We prove formal properties of causal
explanations and introduce contrastive causal explanations for image
classifiers. Moreover, we augment the definition of explanation with confidence
awareness and introduce complete causal explanations: explanations that are
classified with exactly the same confidence as the original image.
  We implement our definitions, and our experimental results demonstrate that
different models have different patterns of sufficiency, contrastiveness, and
completeness. Our algorithms are efficiently computable, taking on average 6s
per image on a ResNet50 model to compute all types of explanations, and are
totally black-box, needing no knowledge of the model, no access to model
internals, no access to gradient, nor requiring any properties, such as
monotonicity, of the model.

</details>


### [32] [DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer](https://arxiv.org/abs/2507.23554)
*Ruoyu Wang,Junda Wu,Yu Xia,Tong Yu,Ryan A. Rossi,Julian McAuley,Lina Yao*

Main category: cs.AI

TL;DR: 论文提出DICE框架，通过动态选择上下文示例提升大语言模型代理的性能，解决了现有方法依赖启发式或任务特定设计的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于上下文学习的代理性能对示例选择高度敏感，缺乏通用的理论依据，亟需一种普适且理论支持的方法。

Method: 提出DICE框架，通过因果视角分解示例知识，提出逐步选择标准，确保性能提升。

Result: 实验证明DICE在多样领域有效且通用，显著提升代理性能。

Conclusion: DICE为上下文示例选择提供了理论支持，无需额外训练成本，可集成到现有框架中。

Abstract: Large language model-based agents, empowered by in-context learning (ICL),
have demonstrated strong capabilities in complex reasoning and tool-use tasks.
However, existing works have shown that the effectiveness of ICL is highly
sensitive to the choice of demonstrations, with suboptimal examples often
leading to unstable or degraded performance. While prior work has explored
example selection, including in some agentic or multi-step settings, existing
approaches typically rely on heuristics or task-specific designs and lack a
general, theoretically grounded criterion for what constitutes an effective
demonstration across reasoning steps. Therefore, it is non-trivial to develop a
principled, general-purpose method for selecting demonstrations that
consistently benefit agent performance. In this paper, we address this
challenge with DICE, Dynamic In-Context Example Selection for LLM Agents, a
theoretically grounded ICL framework for agentic tasks that selects the most
relevant demonstrations at each step of reasoning. Our approach decomposes
demonstration knowledge into transferable and non-transferable components
through a causal lens, showing how the latter can introduce spurious
dependencies that impair generalization. We further propose a stepwise
selection criterion with a formal guarantee of improved agent performance.
Importantly, DICE is a general, framework-agnostic solution that can be
integrated as a plug-in module into existing agentic frameworks without any
additional training cost. Extensive experiments across diverse domains
demonstrate our method's effectiveness and generality, highlighting the
importance of principled, context-aware demo selection for robust and efficient
LLM agents.

</details>


### [33] [Semantic Chain-of-Trust: Autonomous Trust Orchestration for Collaborator Selection via Hypergraph-Aided Agentic AI](https://arxiv.org/abs/2507.23565)
*Botao Zhu,Xianbin Wang,Dusit Niyato*

Main category: cs.AI

TL;DR: 提出了一种基于语义信任链的自主信任编排方法，利用智能代理和超图技术优化分布式协作中的信任评估。


<details>
  <summary>Details</summary>
Motivation: 解决分布式协作中信任评估的复杂性和资源消耗问题，避免因评估时机不当或频率过高而影响资源利用率和任务执行效率。

Method: 采用智能代理和超图技术，通过自主感知设备状态、任务分解和语义推理，仅在设备空闲期进行信任评估，并利用信任超图实现分层管理和多跳协作。

Result: 实验结果表明，该方法实现了资源高效的信任评估。

Conclusion: 提出的方法有效平衡了信任评估的开销与准确性，适用于大规模分布式协作系统。

Abstract: In collaborative systems, the effective completion of tasks hinges on
task-specific trust evaluations of potential devices for distributed
collaboration. However, the complexity of tasks, the spatiotemporal dynamism of
distributed device resources, and the inevitable assessment overhead
dramatically increase the complexity and resource consumption of the trust
evaluation process. As a result, ill-timed or overly frequent trust evaluations
can reduce utilization rate of constrained resources, negatively affecting
collaborative task execution. To address this challenge, this paper proposes an
autonomous trust orchestration method based on a new concept of semantic
chain-of-trust. Our technique employs agentic AI and hypergraph to establish
and maintain trust relationships among devices. By leveraging its strengths in
autonomous perception, task decomposition, and semantic reasoning, we propose
agentic AI to perceive device states and autonomously perform trust evaluations
of collaborators based on historical performance data only during device idle
periods, thereby enabling efficient utilization of distributed resources. In
addition, agentic AI performs task-specific trust evaluations on collaborator
resources by analyzing the alignment between resource capabilities and task
requirements. Moreover, by maintaining a trust hypergraph embedded with trust
semantics for each device, agentic AI enables hierarchical management of
collaborators and identifies collaborators requiring trust evaluation based on
trust semantics, thereby achieving a balance between overhead and trust
accuracy. Furthermore, local trust hypergraphs from multiple devices can be
chained together to support multi-hop collaboration, enabling efficient
coordination in large-scale systems. Experimental results demonstrate that the
proposed method achieves resource-efficient trust evaluation.

</details>


### [34] [MemoCue: Empowering LLM-Based Agents for Human Memory Recall via Strategy-Guided Querying](https://arxiv.org/abs/2507.23633)
*Qian Zhao,Zhuo Sun,Bin Guo,Zhiwen Yu*

Main category: cs.AI

TL;DR: 论文提出了一种基于策略引导的代理辅助记忆回忆方法，通过设计策略将原始查询转化为线索丰富的查询，以帮助用户回忆记忆。该方法通过5W回忆地图分类记忆查询，并结合蒙特卡洛树搜索算法优化策略选择和响应生成，实验表明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统代理辅助记忆回忆方法受限于内存模块大小，无法完整获取记忆。受记忆理论启发，研究旨在通过有效线索主动激活用户的相关记忆。

Method: 提出Recall Router框架，包括5W回忆地图分类记忆查询，定义15种回忆策略模式，并结合蒙特卡洛树搜索算法优化策略选择和响应生成。使用指令调优数据集微调开源大语言模型开发MemoCue代理。

Result: 在三个代表性数据集上，MemoCue在回忆启发方面优于基于大语言模型的方法17.74%，人类评估也显示其在记忆回忆应用中的优势。

Conclusion: 策略引导的代理辅助记忆回忆方法通过优化策略选择和响应生成，显著提升了记忆回忆效果，具有实际应用潜力。

Abstract: Agent-assisted memory recall is one critical research problem in the field of
human-computer interaction. In conventional methods, the agent can retrieve
information from its equipped memory module to help the person recall
incomplete or vague memories. The limited size of memory module hinders the
acquisition of complete memories and impacts the memory recall performance in
practice. Memory theories suggest that the person's relevant memory can be
proactively activated through some effective cues. Inspired by this, we propose
a novel strategy-guided agent-assisted memory recall method, allowing the agent
to transform an original query into a cue-rich one via the judiciously designed
strategy to help the person recall memories. To this end, there are two key
challenges. (1) How to choose the appropriate recall strategy for diverse
forgetting scenarios with distinct memory-recall characteristics? (2) How to
obtain the high-quality responses leveraging recall strategies, given only
abstract and sparsely annotated strategy patterns? To address the challenges,
we propose a Recall Router framework. Specifically, we design a 5W Recall Map
to classify memory queries into five typical scenarios and define fifteen
recall strategy patterns across the corresponding scenarios. We then propose a
hierarchical recall tree combined with the Monte Carlo Tree Search algorithm to
optimize the selection of strategy and the generation of strategy responses. We
construct an instruction tuning dataset and fine-tune multiple open-source
large language models (LLMs) to develop MemoCue, an agent that excels in
providing memory-inspired responses. Experiments on three representative
datasets show that MemoCue surpasses LLM-based methods by 17.74% in recall
inspiration. Further human evaluation highlights its advantages in
memory-recall applications.

</details>


### [35] [Personalized Education with Ranking Alignment Recommendation](https://arxiv.org/abs/2507.23664)
*Haipeng Liu,Yuxuan Liu,Ting Long*

Main category: cs.AI

TL;DR: 论文提出了一种名为RAR的个性化问题推荐方法，通过将协作思想融入探索机制，解决了传统强化学习方法在训练中探索效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 个性化问题推荐旨在帮助学生掌握学习目标，但现有强化学习方法在探索效率上表现不佳。

Method: 提出Ranking Alignment Recommendation (RAR)，将协作思想融入探索机制，优化训练过程。

Result: 实验表明RAR显著提升了推荐性能，且框架适用于任何基于强化学习的推荐系统。

Conclusion: RAR通过改进探索机制，有效提升了问题推荐的效率与性能。

Abstract: Personalized question recommendation aims to guide individual students
through questions to enhance their mastery of learning targets. Most previous
methods model this task as a Markov Decision Process and use reinforcement
learning to solve, but they struggle with efficient exploration, failing to
identify the best questions for each student during training. To address this,
we propose Ranking Alignment Recommendation (RAR), which incorporates
collaborative ideas into the exploration mechanism, enabling more efficient
exploration within limited training episodes. Experiments show that RAR
effectively improves recommendation performance, and our framework can be
applied to any RL-based question recommender. Our code is available in
https://github.com/wuming29/RAR.git.

</details>


### [36] [TextQuests: How Good are LLMs at Text-Based Video Games?](https://arxiv.org/abs/2507.23701)
*Long Phan,Mantas Mazeika,Andy Zou,Dan Hendrycks*

Main category: cs.AI

TL;DR: TextQuests是一个基于交互式小说的基准测试，用于评估AI代理在长上下文推理和自主问题解决中的能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试未能充分评估AI代理在探索性环境中的自主推理能力，因此需要更全面的测试工具。

Method: 利用Infocom交互式小说游戏作为基准，设计TextQuests，禁止外部工具使用，专注于长上下文推理和自主问题解决。

Result: TextQuests提供了一个评估AI代理在长时程、探索性环境中推理能力的有效工具。

Conclusion: TextQuests填补了现有基准测试的空白，推动了AI代理在复杂、自主推理能力上的发展。

Abstract: Evaluating AI agents within complex, interactive environments that mirror
real-world challenges is critical for understanding their practical
capabilities. While existing agent benchmarks effectively assess skills like
tool use or performance on structured tasks, they often do not fully capture an
agent's ability to operate autonomously in exploratory environments that demand
sustained, self-directed reasoning over a long and growing context. To spur the
development of agents capable of more robust intrinsic reasoning over long
horizons, we introduce TextQuests, a benchmark based on the Infocom suite of
interactive fiction games. These text-based adventures, which can take human
players over 30 hours and require hundreds of precise actions to solve, serve
as an effective proxy for evaluating AI agents on focused, stateful tasks. The
benchmark is specifically designed to assess an LLM agent's capacity for
self-contained problem-solving by precluding the use of external tools, thereby
focusing on intrinsic long-context reasoning capabilities in an exploratory
environment characterized by the need for trial-and-error learning and
sustained problem-solving within a single interactive session. We release
TextQuests at https://textquests.ai.

</details>


### [37] [Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving](https://arxiv.org/abs/2507.23726)
*Luoxin Chen,Jinming Gu,Liankai Huang,Wenhao Huang,Zhicheng Jiang,Allan Jie,Xiaoran Jin,Xing Jin,Chenggang Li,Kaijing Ma,Cheng Ren,Jiawei Shen,Wenlei Shi,Tong Sun,He Sun,Jiahui Wang,Siran Wang,Zhihong Wang,Chenrui Wei,Shufa Wei,Yonghui Wu,Yuchen Wu,Yihang Xia,Huajian Xin,Fan Yang,Huaiyuan Ying,Hongyi Yuan,Zheng Yuan,Tianyang Zhan,Chi Zhang,Yue Zhang,Ge Zhang,Tianyun Zhao,Jianqiu Zhao,Yichi Zhou,Thomas Hanwen Zhu*

Main category: cs.AI

TL;DR: Seed-Prover 是一种基于强化学习和形式化验证的定理证明模型，通过迭代优化证明过程，显著提升了数学推理能力，尤其在 IMO 级别问题上表现优异。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在数学推理中表现良好，但在定理证明上因缺乏明确的监督信号而受限。形式化语言（如 Lean）提供了清晰的验证信号，为模型训练提供了有效途径。

Method: 提出 Seed-Prover 模型，通过 Lean 反馈、已证明引理和自我总结迭代优化证明。设计了三种推理策略以支持深度和广度推理。同时开发 Seed-Geometry 引擎解决几何问题。

Result: Seed-Prover 在 IMO 问题上达到 78.1% 的证明率，显著优于之前的方法。Seed-Geometry 在几何问题上表现优异。两者在 IMO 2025 中成功证明了 5/6 的问题。

Conclusion: Seed-Prover 和 Seed-Geometry 展示了形式化验证与长链推理结合的有效性，推动了自动数学推理的进步。

Abstract: LLMs have demonstrated strong mathematical reasoning abilities by leveraging
reinforcement learning with long chain-of-thought, yet they continue to
struggle with theorem proving due to the lack of clear supervision signals when
solely using natural language. Dedicated domain-specific languages like Lean
provide clear supervision via formal verification of proofs, enabling effective
training through reinforcement learning. In this work, we propose
\textbf{Seed-Prover}, a lemma-style whole-proof reasoning model. Seed-Prover
can iteratively refine its proof based on Lean feedback, proved lemmas, and
self-summarization. To solve IMO-level contest problems, we design three
test-time inference strategies that enable both deep and broad reasoning.
Seed-Prover proves $78.1\%$ of formalized past IMO problems, saturates MiniF2F,
and achieves over 50\% on PutnamBench, outperforming the previous
state-of-the-art by a large margin. To address the lack of geometry support in
Lean, we introduce a geometry reasoning engine \textbf{Seed-Geometry}, which
outperforms previous formal geometry engines. We use these two systems to
participate in IMO 2025 and fully prove 5 out of 6 problems. This work
represents a significant advancement in automated mathematical reasoning,
demonstrating the effectiveness of formal verification with long
chain-of-thought reasoning.

</details>


### [38] [CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning and non-reasoning tasks](https://arxiv.org/abs/2507.23751)
*Ping Yu,Jack Lanchantin,Tianlu Wang,Weizhe Yuan,Olga Golovneva,Ilia Kulikov,Sainbayar Sukhbaatar,Jason Weston,Jing Xu*

Main category: cs.AI

TL;DR: CoT-Self-Instruct是一种合成数据生成方法，通过链式思维（CoT）指导LLMs生成高质量合成提示，显著优于现有数据集。


<details>
  <summary>Details</summary>
Motivation: 提升LLM在可验证推理和非可验证指令任务中的性能。

Method: 基于种子任务，利用CoT生成合成提示，并通过自动指标过滤高质量数据。

Result: 在MATH500等可验证推理任务和AlpacaEval 2.0等指令任务中表现优异。

Conclusion: CoT-Self-Instruct为LLM训练提供了高效的数据生成方法。

Abstract: We propose CoT-Self-Instruct, a synthetic data generation method that
instructs LLMs to first reason and plan via Chain-of-Thought (CoT) based on the
given seed tasks, and then to generate a new synthetic prompt of similar
quality and complexity for use in LLM training, followed by filtering for
high-quality data with automatic metrics. In verifiable reasoning, our
synthetic data significantly outperforms existing training datasets, such as
s1k and OpenMathReasoning, across MATH500, AMC23, AIME24 and GPQA-Diamond. For
non-verifiable instruction-following tasks, our method surpasses the
performance of human or standard self-instruct prompts on both AlpacaEval 2.0
and Arena-Hard.

</details>


### [39] [SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model](https://arxiv.org/abs/2507.23773)
*Mingkai Deng,Jinyu Hou,Yilin Shen,Hongxia Jin,Graham Neubig,Zhiting Hu,Eric Xing*

Main category: cs.AI

TL;DR: SimuRA是一种基于世界模型的通用AI代理架构，通过模拟规划克服自回归LLM的限制，在复杂任务中表现显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理局限于单一任务，缺乏通用性和扩展性，而人类通过模拟行动结果进行推理。SimuRA旨在实现更通用的智能代理。

Method: SimuRA基于环境中的最优代理原则，利用LLM实现世界模型，通过自然语言的潜在空间进行灵活规划。

Result: 在网页浏览任务中，SimuRA将航班搜索成功率从0%提升至32.2%，世界模型规划比自回归规划优势高达124%。

Conclusion: SimuRA展示了世界模型模拟作为推理范式的优势，为训练单一通用代理模型提供了可能性。

Abstract: AI agents built on large language models (LLMs) hold enormous promise, but
current practice focuses on a one-task-one-agent approach, which not only falls
short of scalability and generality, but also suffers from the fundamental
limitations of autoregressive LLMs. On the other hand, humans are general
agents who reason by mentally simulating the outcomes of their actions and
plans. Moving towards a more general and powerful AI agent, we introduce
SimuRA, a goal-oriented architecture for generalized agentic reasoning. Based
on a principled formulation of optimal agent in any environment, \modelname
overcomes the limitations of autoregressive reasoning by introducing a world
model for planning via simulation. The generalized world model is implemented
using LLM, which can flexibly plan in a wide range of environments using the
concept-rich latent space of natural language. Experiments on difficult web
browsing tasks show that \modelname improves the success of flight search from
0\% to 32.2\%. World-model-based planning, in particular, shows consistent
advantage of up to 124\% over autoregressive planning, demonstrating the
advantage of world model simulation as a reasoning paradigm. We are excited
about the possibility for training a single, general agent model based on LLMs
that can act superintelligently in all environments. To start, we make SimuRA,
a web-browsing agent built on \modelname with pretrained LLMs, available as a
research demo for public testing.

</details>
