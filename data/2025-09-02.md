<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 8]
- [cs.CR](#cs.CR) [Total: 18]
- [cs.AI](#cs.AI) [Total: 24]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Model-Driven Quantum Code Generation Using Large Language Models and Retrieval-Augmented Generation](https://arxiv.org/abs/2508.21097)
*Nazanin Siavash,Armin Moin*

Main category: cs.SE

TL;DR: 本文提出利用检索增强生成(RAG)技术增强大型语言模型(LLM)，用于量子软件系统的模型到代码转换，通过Qiskit库生成量子计算代码，实验显示精心设计的提示可将CodeBLEU分数提高四倍。


<details>
  <summary>Details</summary>
Motivation: 量子混合软件系统存在平台异构性和开发人员技能缺乏的问题，模型驱动方法可以降低成本和风险。

Method: 采用RAG管道整合GitHub上的Qiskit代码样本，通过LLM从UML模型实例生成量子代码。

Result: 实验结果表明，精心设计的提示工程可以将CodeBLEU分数提升高达四倍，产生更准确和一致的量子代码。

Conclusion: 该方法为量子软件工程提供了有前景的研究方向，未来可进一步探索将软件系统模型实例作为RAG信息源，以及代码到代码转换等应用场景。

Abstract: This paper introduces a novel research direction for model-to-text/code
transformations by leveraging Large Language Models (LLMs) that can be enhanced
with Retrieval-Augmented Generation (RAG) pipelines. The focus is on quantum
and hybrid quantum-classical software systems, where model-driven approaches
can help reduce the costs and mitigate the risks associated with the
heterogeneous platform landscape and lack of developers' skills. We validate
one of the proposed ideas regarding generating code out of UML model instances
of software systems. This Python code uses a well-established library, called
Qiskit, to execute on gate-based or circuit-based quantum computers. The RAG
pipeline that we deploy incorporates sample Qiskit code from public GitHub
repositories. Experimental results show that well-engineered prompts can
improve CodeBLEU scores by up to a factor of four, yielding more accurate and
consistent quantum code. However, the proposed research direction can go beyond
this through further investigation in the future by conducting experiments to
address our other research questions and ideas proposed here, such as deploying
software system model instances as the source of information in the RAG
pipelines, or deploying LLMs for code-to-code transformations, for instance,
for transpilation use cases.

</details>


### [2] [Learning to Generate Unit Test via Adversarial Reinforcement Learning](https://arxiv.org/abs/2508.21107)
*Dongjun Lee,Changho Hwang,Kimin Lee*

Main category: cs.SE

TL;DR: UTR是一种通过对抗性强化学习训练LLM生成高质量单元测试的新框架，通过迭代训练测试生成器和代码生成器来提升测试质量。


<details>
  <summary>Details</summary>
Motivation: 目前LLM自动生成单元测试的方法尚未充分探索，需要更有效的训练方法来生成能够曝露代码故障的高质量测试。

Method: 使用对抗性强化学习框架，同时训练两个LLM：测试生成器通过最大化辨别奖励（生成能曝露代码故障的测试），代码生成器通过最大化代码奖励（生成能通过测试的代码）。

Result: UTR训练的Qwen3-4B模型在单元测试生成质量上超过了相同模型的监督学习结果，甚至超过了GPT-4.1等前沿模型。

Conclusion: UTR框架能够有效训练LLM生成高质量单元测试，通过对抗性学习提升了测试的故障检测能力。

Abstract: Unit testing is a core practice in programming, enabling systematic
evaluation of programs produced by human developers or large language models
(LLMs). Given the challenges in writing comprehensive unit tests, LLMs have
been employed to automate test generation, yet methods for training LLMs to
produce high-quality tests remain underexplored. In this work, we propose UTRL,
a novel reinforcement learning framework that trains an LLM to generate
high-quality unit tests given a programming instruction. Our key idea is to
iteratively train two LLMs, the unit test generator and the code generator, in
an adversarial manner via reinforcement learning. The unit test generator is
trained to maximize a discrimination reward, which reflects its ability to
produce tests that expose faults in the code generator's solutions, and the
code generator is trained to maximize a code reward, which reflects its ability
to produce solutions that pass the unit tests generated by the test generator.
In our experiments, we demonstrate that unit tests generated by Qwen3-4B
trained via UTRL show higher quality compared to unit tests generated by the
same model trained via supervised fine-tuning on human-written ground-truth
unit tests, yielding code evaluations that more closely align with those
induced by the ground-truth tests. Moreover, Qwen3-4B trained with UTRL
outperforms frontier models such as GPT-4.1 in generating high-quality unit
tests, highlighting the effectiveness of UTRL in training LLMs for this task.

</details>


### [3] [Automated Bug Triaging using Instruction-Tuned Large Language Models](https://arxiv.org/abs/2508.21156)
*Kiana Kiashemshaki,Arsham Khosravani,Alireza Hosseinpour,Arshia Akhavan*

Main category: cs.SE

TL;DR: 提出基于指令调优大语言模型的轻量级框架，使用LoRA适配器和候选约束解码来实现bug分配，在EclipseJDT和Mozilla数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 大型项目中的bug分配任务通常缓慢且不一致，需要一种更高效的方法来替代成本高昂的特征工程和图基方法。

Method: 使用指令调优的大语言模型，结合LoRA适配器进行微调，采用候选约束解码确保分配的有效性。

Result: 在EclipseJDT和Mozilla数据集上，模型在短列表质量方面表现强劲（Hit@10达到0.753），尽管Top-1准确率一般。在最新快照上准确率显著提升。

Conclusion: 指令调优的大语言模型为bug分配任务提供了一个实用的替代方案，具有在现实世界人机协作场景中的应用潜力。

Abstract: Bug triaging, the task of assigning new issues to developers, is often slow
and inconsistent in large projects. We present a lightweight framework that
instruction-tuned large language model (LLM) with LoRA adapters and uses
candidate-constrained decoding to ensure valid assignments. Tested on
EclipseJDT and Mozilla datasets, the model achieves strong shortlist quality
(Hit at 10 up to 0.753) despite modest exact Top-1 accuracy. On recent
snapshots, accuracy rises sharply, showing the framework's potential for
real-world, human-in-the-loop triaging. Our results suggest that
instruction-tuned LLMs offer a practical alternative to costly feature
engineering and graph-based methods.

</details>


### [4] [The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management](https://arxiv.org/abs/2508.21433)
*Tobias Lindenbauer,Igor Slinko,Ludwig Felder,Egor Bogomolov,Yaroslav Zharov*

Main category: cs.SE

TL;DR: 简单的观测掩码策略在SWE-agent中比LLM摘要化更有效且成本更低，解决率相近但成本减半


<details>
  <summary>Details</summary>
Motivation: 解决LLM基代理在复杂任务中产生长上下文历史导致高成本的问题，对比不同上下文管理策略的效果

Method: 在SWE-agent上使用SWE-bench Verified数据集，系统比较原始代理、观测掩码策略和LLM摘要化策略在4种不同模型配置下的性能

Result: 观测掩码策略将成本降低50%，解决率与LLM摘要化相当或略高（如Qwen3-Coder 480B从53.8%提升到54.8%）

Conclusion: 在SWE-agent和SWE-bench Verified环境中，最简单的上下文管理策略反而是最高效和经济的选择

Abstract: Large Language Model (LLM)-based agents solve complex tasks through iterative
reasoning, exploration, and tool-use, a process that can result in long,
expensive context histories. While state-of-the-art Software Engineering ( SE)
agents like OpenHands or Cursor use LLM-based summarization to tackle this
issue, it is unclear whether the increased complexity offers tangible
performance benefits compared to simply omitting older observations. We present
a systematic comparison of these strategies within SWE-agent on SWE-bench
Verified across five diverse model configurations. We find that a simple
observation-masking strategy halves cost relative to a raw agent while
matching, and sometimes slightly exceeding, the solve rate of LLM
summarization. For example, with Qwen3-Coder 480B, masking improves solve rate
from 53.8% (raw agent) to 54.8%, while remaining competitive with summarization
at a lower cost. These results suggest that, at least within SWE-agent on
SWE-bench Verified, the most effective and efficient context management can be
the simplest. We release code and data for reproducibility

</details>


### [5] [Enhancing Semantic Understanding in Pointer Analysis using Large Language Models](https://arxiv.org/abs/2508.21454)
*Baijun Cheng,Kailong Wang,Ling Shi,Haoyu Wang,Yao Guo,Ding Li,Xiangqun Chen*

Main category: cs.SE

TL;DR: LMPA是一个将大语言模型集成到指针分析中的新框架，通过LLM识别类似系统API的用户自定义函数并建模，提升指针分析的精度和可扩展性


<details>
  <summary>Details</summary>
Motivation: 传统指针分析框架由于对代码语义理解不足，在处理用户自定义函数时过于保守，导致错误事实传播。LLM的发展为解决这一问题提供了新机会

Method: LMPA识别类似系统API的用户自定义函数并相应建模，减少错误的跨调用上下文传播；通过推断初始点集和引入自然语言增强的摘要策略来改进基于摘要的分析

Result: 论文提出了LMPA的愿景框架，但尚未提供具体实验结果

Conclusion: LMPA展示了将LLM集成到指针分析中的潜力，能够提升分析精度和可扩展性，论文还讨论了实现这一愿景的关键挑战

Abstract: Pointer analysis has been studied for over four decades. However, existing
frameworks continue to suffer from the propagation of incorrect facts. A major
limitation stems from their insufficient semantic understanding of code,
resulting in overly conservative treatment of user-defined functions. Recent
advances in large language models (LLMs) present new opportunities to bridge
this gap. In this paper, we propose LMPA (LLM-enhanced Pointer Analysis), a
vision that integrates LLMs into pointer analysis to enhance both precision and
scalability. LMPA identifies user-defined functions that resemble system APIs
and models them accordingly, thereby mitigating erroneous cross-calling-context
propagation. Furthermore, it enhances summary-based analysis by inferring
initial points-to sets and introducing a novel summary strategy augmented with
natural language. Finally, we discuss the key challenges involved in realizing
this vision.

</details>


### [6] [Reusable Test Suites for Reinforcement Learning](https://arxiv.org/abs/2508.21553)
*Jørn Eirik Betten,Quentin Mazouni,Dennis Gross,Pedro Lind,Helge Spieker*

Main category: cs.SE

TL;DR: 提出MPTCS方法，从任何策略测试框架生成的测试用例中，基于可解性、多样性和通用难度选择策略无关的多样化测试用例集


<details>
  <summary>Details</summary>
Motivation: 现有强化学习策略测试方法生成的测试套件针对特定策略定制，对其他策略的适用性不明确，需要可重用的策略无关测试用例

Method: 使用一组策略基于难度评分从候选池中选择测试用例，采用离散化通用测试用例描述符表面来促进测试套件多样性

Result: 评估了难度评分的有效性，分析了方法效果和成本与策略数量的关系，检验了多样性方法对状态空间的覆盖和触发故障行为的能力

Conclusion: MPTCS能够选择揭示智能体行为典型缺陷的多样化、可重用策略无关测试用例

Abstract: Reinforcement learning (RL) agents show great promise in solving sequential
decision-making tasks. However, validating the reliability and performance of
the agent policies' behavior for deployment remains challenging. Most
reinforcement learning policy testing methods produce test suites tailored to
the agent policy being tested, and their relevance to other policies is
unclear. This work presents Multi-Policy Test Case Selection (MPTCS), a novel
automated test suite selection method for RL environments, designed to extract
test cases generated by any policy testing framework based on their
solvability, diversity, and general difficulty. MPTCS uses a set of policies to
select a diverse collection of reusable policy-agnostic test cases that reveal
typical flaws in the agents' behavior. The set of policies selects test cases
from a candidate pool, which can be generated by any policy testing method,
based on a difficulty score. We assess the effectiveness of the difficulty
score and how the method's effectiveness and cost depend on the number of
policies in the set. Additionally, a method for promoting diversity in the test
suite, a discretized general test case descriptor surface inspired by
quality-diversity algorithms, is examined to determine how it covers the state
space and which policies it triggers to produce faulty behaviors.

</details>


### [7] [Human-Written vs. AI-Generated Code: A Large-Scale Study of Defects, Vulnerabilities, and Complexity](https://arxiv.org/abs/2508.21634)
*Domenico Cotroneo,Cristina Improta,Pietro Liguori*

Main category: cs.SE

TL;DR: 大规模比较人类开发者和三大LLM（ChatGPT、DeepSeek-Coder、Qwen-Coder）编写的代码质量，发现AI生成代码更简单但存在更多安全漏洞和未使用构造。


<details>
  <summary>Details</summary>
Motivation: 随着AI代码助手在软件开发中的广泛应用，需要了解AI生成代码与人类编写代码在可靠性、可维护性和安全性方面的差异。

Method: 评估超过50万个Python和Java代码样本，使用正交缺陷分类和常见弱点枚举来分析代码缺陷、安全漏洞和结构复杂性。

Result: AI生成代码更简单重复，但更容易出现未使用构造和硬编码调试；人类代码结构更复杂但可维护性问题更多；AI代码包含更多高风险安全漏洞。

Conclusion: AI和人类编写的代码具有不同的缺陷特征，需要在AI辅助编程中采用专门的质量保证实践。

Abstract: As AI code assistants become increasingly integrated into software
development workflows, understanding how their code compares to human-written
programs is critical for ensuring reliability, maintainability, and security.
In this paper, we present a large-scale comparison of code authored by human
developers and three state-of-the-art LLMs, i.e., ChatGPT, DeepSeek-Coder, and
Qwen-Coder, on multiple dimensions of software quality: code defects, security
vulnerabilities, and structural complexity. Our evaluation spans over 500k code
samples in two widely used languages, Python and Java, classifying defects via
Orthogonal Defect Classification and security vulnerabilities using the Common
Weakness Enumeration. We find that AI-generated code is generally simpler and
more repetitive, yet more prone to unused constructs and hardcoded debugging,
while human-written code exhibits greater structural complexity and a higher
concentration of maintainability issues. Notably, AI-generated code also
contains more high-risk security vulnerabilities. These findings highlight the
distinct defect profiles of AI- and human-authored code and underscore the need
for specialized quality assurance practices in AI-assisted programming.

</details>


### [8] [The Integration of Agile Methodologies in DevOps Practices within the Information Technology Industry](https://arxiv.org/abs/2508.21811)
*Ashley Hourigan,Ridewaan Hanslo*

Main category: cs.SE

TL;DR: 这篇论文通过11个半结构化访谈和主题分析，研究了Agile和DevOps在IT行业中的实践，提出了新的理解模型来详细说明两者的相互关系。


<details>
  <summary>Details</summary>
Motivation: IT行业对软件交付速度的需求日益增长，Agile和DevOps方法论逐渐取代传统水漏模型，需要研究两者在实践中的可行性和适用性。

Method: 采用11个半结构化访谈，对象来自IT行业各个部门的Agile和DevOps实践者，通过主题分析提取了51个唯一代码并合成了19个主题。

Result: 研究识别了DevOps生命周期各阶段中Agile方法的集成和实施情况，得出了详细描述Agile方法在DevOps实践中相互关系的新理解。

Conclusion: 论文完成了研究目标，提供了关于Agile方法如何集成到DevOps实践中的新见解，对IT行业的软件开发实践具有重要意义。

Abstract: The demand for rapid software delivery in the Information Technology (IT)
industry has significantly intensified, emphasising the need for faster
software products and service releases with enhanced features to meet customer
expectations. Agile methodologies are replacing traditional approaches such as
Waterfall, where flexibility, iterative development and adaptation to change
are favoured over rigid planning and execution. DevOps, a subsequent evolution
from Agile, emphasises collaborative efforts in development and operations
teams, focusing on continuous integration and deployment to deliver resilient
and high-quality software products and services. This study aims to critically
assess both Agile and DevOps practices in the IT industry to identify the
feasibility and applicability of Agile methods in DevOps practices. Eleven
semi-structured interviews were conducted with Agile and DevOps practitioners
in varying capacities across several sectors within the IT industry. Through
thematic analysis, 51 unique codes were extracted and synthesised into 19
themes that reported on each phase of the DevOps lifecycle, specifically
regarding the integration and implementation of Agile methods into DevOps
practices. Based on the findings, a new understanding detailing the
interrelationship of Agile methods in DevOps practices was discussed that met
the research objectives.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [9] [The WASM Cloak: Evaluating Browser Fingerprinting Defenses Under WebAssembly based Obfuscation](https://arxiv.org/abs/2508.21219)
*A H M Nazmus Sakib,Mahsin Bin Akram,Joseph Spracklen,Sahan Kalutarage,Raveen Wijewickrama,Igor Bilogrevic,Murtuza Jadliwala*

Main category: cs.CR

TL;DR: 本文首次系统评估了WebAssembly(WASM)混淆技术对现代浏览器指纹识别防御的影响，发现学术研究中的检测器存在中度漏洞，而商业浏览器防御工具仍完全有效。


<details>
  <summary>Details</summary>
Motivation: 随着WebAssembly(WASM)的广泛采用，攻击者可以将JavaScript转换为WASM二进制格式来混淆恶意逻辑，这可能成为现有指纹识别防御的盲点。

Method: 开发自动化流水线，将真实世界的JS指纹识别脚本转换为功能性的WASM混淆变体，并测试两类防御：研究文献中的最先进检测器和商业浏览器工具。

Result: 研究发现学术检测器因依赖源代码特征分析而存在中度漏洞（源于过时数据集或缺乏WASM兼容性），而浏览器扩展和原生浏览器功能等防御仍完全有效（因其API级拦截不关心脚本底层实现）。

Conclusion: 结果揭示了学术防御策略与实际防御策略之间的差距，为加强针对WASM混淆的检测方法提供了见解，同时也揭示了未来攻击中更隐蔽技术的机会。

Abstract: Browser fingerprinting defenses have historically focused on detecting
JavaScript(JS)-based tracking techniques. However, the widespread adoption of
WebAssembly (WASM) introduces a potential blind spot, as adversaries can
convert JS to WASM's low-level binary format to obfuscate malicious logic. This
paper presents the first systematic evaluation of how such WASM-based
obfuscation impacts the robustness of modern fingerprinting defenses. We
develop an automated pipeline that translates real-world JS fingerprinting
scripts into functional WASM-obfuscated variants and test them against two
classes of defenses: state-of-the-art detectors in research literature and
commercial, in-browser tools. Our findings reveal a notable divergence:
detectors proposed in the research literature that rely on feature-based
analysis of source code show moderate vulnerability, stemming from outdated
datasets or a lack of WASM compatibility. In contrast, defenses such as browser
extensions and native browser features remained completely effective, as their
API-level interception is agnostic to the script's underlying implementation.
These results highlight a gap between academic and practical defense strategies
and offer insights into strengthening detection approaches against WASM-based
obfuscation, while also revealing opportunities for more evasive techniques in
future attacks.

</details>


### [10] [Locus: Agentic Predicate Synthesis for Directed Fuzzing](https://arxiv.org/abs/2508.21302)
*Jie Zhu,Chihao Shen,Ziyang Li,Jiahao Yu,Yizheng Chen,Kexin Pei*

Main category: cs.CR

TL;DR: Locus是一个新的定向模糊测试框架，通过合成谓词来捕获语义上有意义的中间状态作为里程碑，显著提高了发现真实漏洞的效率，平均加速41.6倍


<details>
  <summary>Details</summary>
Motivation: 定向模糊测试在寻找导致特定目标程序状态的输入时面临挑战，现有方法依赖分支距离或手动指定的约束，这些方法要么不够精确，要么难以泛化到不同的目标状态和程序

Method: Locus采用代理框架和程序分析工具来自动合成和迭代精化候选谓词，这些谓词作为中间里程碑，通过符号执行确保谓词严格松弛目标状态以防止错误拒绝

Result: Locus显著提高了8个最先进模糊测试器的效率，平均加速41.6倍，发现了8个先前未修补的漏洞，其中一个已被确认并准备补丁

Conclusion: Locus通过自动合成语义上有意义的中间状态谓词，为定向模糊测试提供了有效的进展度量方法，能够泛化到不同的程序和目标状态，大幅提升了漏洞发现效率

Abstract: Directed fuzzing aims to find program inputs that lead to specified target
program states. It has broad applications, such as debugging system crashes,
confirming reported bugs, and generating exploits for potential
vulnerabilities. This task is inherently challenging because target states are
often deeply nested in the program, while the search space manifested by
numerous possible program inputs is prohibitively large. Existing approaches
rely on branch distances or manually-specified constraints to guide the search;
however, the branches alone are often insufficient to precisely characterize
progress toward reaching the target states, while the manually specified
constraints are often tailored for specific bug types and thus difficult to
generalize to diverse target states and programs.
  We present Locus, a novel framework to improve the efficiency of directed
fuzzing. Our key insight is to synthesize predicates to capture fuzzing
progress as semantically meaningful intermediate states, serving as milestones
towards reaching the target states. When used to instrument the program under
fuzzing, they can reject executions unlikely to reach the target states, while
providing additional coverage guidance. To automate this task and generalize to
diverse programs, Locus features an agentic framework with program analysis
tools to synthesize and iteratively refine the candidate predicates, while
ensuring the predicates strictly relax the target states to prevent false
rejections via symbolic execution. Our evaluation shows that Locus
substantially improves the efficiency of eight state-of-the-art fuzzers in
discovering real-world vulnerabilities, achieving an average speedup of 41.6x.
So far, Locus has found eight previously unpatched bugs, with one already
acknowledged with a draft patch.

</details>


### [11] [LLM-driven Provenance Forensics for Threat Investigation and Detection](https://arxiv.org/abs/2508.21323)
*Kunal Mukherjee,Murat Kantarcioglu*

Main category: cs.CR

TL;DR: PROVSEEK是一个基于LLM的智能代理框架，用于自动化溯源驱动的取证分析和威胁情报提取，通过结合RAG和思维链推理，在DARPA数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的取证分析方法在处理复杂的APT攻击时存在局限性，需要一种能够动态检索相关上下文、减少幻觉并生成可验证取证摘要的自动化框架。

Method: 采用专门的工具链动态检索相关上下文，生成精确的上下文感知查询，结合向量化威胁报告知识库和系统溯源数据库。通过多角色代理协调减少幻觉，结合RAG和思维链推理进行自适应多步分析。

Result: 在公开DARPA数据集上的评估显示：在情报提取任务中比检索方法提升34%的上下文精确率/召回率；在威胁检测任务中比基线代理AI方法和最先进溯源入侵检测系统提升22%/29%的精确率/召回率。

Conclusion: PROVSEEK通过将溯源数据与智能推理相结合，为基于证据的智能取证调查APT攻击建立了新范式，实现了可扩展、可解释的攻击行为取证分析。

Abstract: We introduce PROVSEEK, an LLM-powered agentic framework for automated
provenance-driven forensic analysis and threat intelligence extraction.
PROVSEEK employs specialized toolchains to dynamically retrieve relevant
context by generating precise, context-aware queries that fuse a vectorized
threat report knowledge base with data from system provenance databases. The
framework resolves provenance queries, orchestrates multiple role-specific
agents to mitigate hallucinations, and synthesizes structured, ground-truth
verifiable forensic summaries. By combining agent orchestration with
Retrieval-Augmented Generation (RAG) and chain-of-thought (CoT) reasoning,
PROVSEEK enables adaptive multi-step analysis that iteratively refines
hypotheses, verifies supporting evidence, and produces scalable, interpretable
forensic explanations of attack behaviors. By combining provenance data with
agentic reasoning, PROVSEEK establishes a new paradigm for grounded agentic
forecics to investigate APTs. We conduct a comprehensive evaluation on publicly
available DARPA datasets, demonstrating that PROVSEEK outperforms
retrieval-based methods for intelligence extraction task, achieving a 34%
improvement in contextual precision/recall; and for threat detection task,
PROVSEEK achieves 22%/29% higher precision/recall compared to both a baseline
agentic AI approach and State-Of-The-Art (SOTA) Provenance-based Intrusion
Detection System (PIDS).

</details>


### [12] [Risks and Compliance with the EU's Core Cyber Security Legislation](https://arxiv.org/abs/2508.21386)
*Jukka Ruohonen,Jesper Løffler Nielsen,Jakub Skórczynski*

Main category: cs.CR

TL;DR: 欧盟网络安全立法采用风险导向方法，涵盖技术、组织和人为安全等多方面风险，但存在可接受风险、非概率风险和残余风险等概念缺失，增加了复杂性和合规负担。


<details>
  <summary>Details</summary>
Motivation: 研究欧盟五项核心网络安全立法中风险概念的框架方式，分析这些立法在风险概念上的趋同或分歧，以及描述法律风险概念时使用的限定词和术语。

Method: 基于定性法律解释和分类构建的方法论，对欧盟五项核心网络安全立法文件进行系统分析。

Result: 五项立法涵盖了广泛的网络安全风险类型，包括技术、组织和人为安全风险以及非人为风险。多数立法使用技术方面和资产来构建法律风险概念，其中一项立法采用威胁中心视角。但存在可接受风险、非概率风险和残余风险等概念缺失。

Conclusion: 欧盟新网络安全立法显著扩展了风险导向的监管方法，但同时也增加了复杂性和合规负担。论文最后提出了处理合规性和开展相关研究的实用建议。

Abstract: The European Union (EU) has long favored a risk-based approach to regulation.
Such an approach is also used in recent cyber security legislation enacted in
the EU. Risks are also inherently related to compliance with the new
legislation. Objective: The paper investigates how risks are framed in the EU's
five core cyber security legislative acts, whether the framings indicate
convergence or divergence between the acts and their risk concepts, and what
qualifying words and terms are used when describing the legal notions of risks.
Method : The paper's methodology is based on qualitative legal interpretation
and taxonomy-building. Results: The five acts have an encompassing coverage of
different cyber security risks, including but not limited to risks related to
technical, organizational, and human security as well as those not originating
from man-made actions. Both technical aspects and assets are used to frame the
legal risk notions in many of the legislative acts. A threat-centric viewpoint
is also present in one of the acts. Notable gaps are related to acceptable
risks, non-probabilistic risks, and residual risks. Conclusion: The EU's new
cyber security legislation has significantly extended the risk-based approach
to regulations. At the same time, complexity and compliance burden have
increased. With this point in mind, the paper concludes with a few practical
takeaways about means to deal with compliance and research it.

</details>


### [13] [zkLoRA: Fine-Tuning Large Language Models with Verifiable Security via Zero-Knowledge Proofs](https://arxiv.org/abs/2508.21393)
*Guofu Liao,Taotao Wang,Shengli Zhang,Jiqun Zhang,Shi Long,Dacheng Tao*

Main category: cs.CR

TL;DR: zkLoRA是首个将LoRA微调与零知识证明结合的安全框架，为Transformer架构提供端到端可验证性，保护模型参数和训练数据隐私


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型微调在不可信环境中的安全性和可验证性问题，传统方法存在计算资源需求和隐私保护不足的挑战

Method: 结合低秩适应(LoRA)和零知识证明(ZKP)，使用查找参数、求和检查协议和多项式承诺等密码学技术验证算术和非算术操作

Result: 在LLaMA等开源模型上验证了可扩展性（支持130亿参数），通过GPU实现展示了实用性和效率

Conclusion: zkLoRA填补了参数高效微调与零知识证明之间的关键空白，为敏感环境中的LLM安全部署提供了可信解决方案

Abstract: Fine-tuning large language models (LLMs) is crucial for adapting them to
specific tasks, yet it remains computationally demanding and raises concerns
about correctness and privacy, particularly in untrusted environments. Although
parameter-efficient methods like Low-Rank Adaptation (LoRA) significantly
reduce resource requirements, ensuring the security and verifiability of
fine-tuning under zero-knowledge constraints remains an unresolved challenge.
To address this, we introduce zkLoRA, the first framework to integrate LoRA
fine-tuning with zero-knowledge proofs (ZKPs), achieving provable security and
correctness. zkLoRA employs advanced cryptographic techniques -- such as lookup
arguments, sumcheck protocols, and polynomial commitments -- to verify both
arithmetic and non-arithmetic operations in Transformer-based architectures.
The framework provides end-to-end verifiability for forward propagation,
backward propagation, and parameter updates during LoRA fine-tuning, while
safeguarding the privacy of model parameters and training data. Leveraging
GPU-based implementations, zkLoRA demonstrates practicality and efficiency
through experimental validation on open-source LLMs like LLaMA, scaling up to
13 billion parameters. By combining parameter-efficient fine-tuning with ZKPs,
zkLoRA bridges a critical gap, enabling secure and trustworthy deployment of
LLMs in sensitive or untrusted environments.

</details>


### [14] [An Empirical Study of Vulnerable Package Dependencies in LLM Repositories](https://arxiv.org/abs/2508.21417)
*Shuhan Liu,Xing Hu,Xin Xia,David Lo,Xiaohu Yang*

Main category: cs.CR

TL;DR: 对52个开源LLM的第三方依赖漏洞进行实证分析，发现LLM生态系统中漏洞披露时间显著长于Python生态系统，且75.8%的LLM在配置文件中包含易受攻击的依赖项。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM发展迅速，但其严重依赖外部代码依赖，形成了复杂的依赖供应链。现有研究主要关注模型级安全威胁，而LLM依赖供应链中的漏洞被忽视，需要填补这一研究空白。

Method: 对52个开源LLM进行实证分析，检查其第三方依赖和相关漏洞；探索LLM仓库中的活动以了解维护者如何管理第三方漏洞；将LLM生态系统的第三方依赖漏洞与Python生态系统进行比较。

Result: LLM生态系统中一半的漏洞未被披露超过56.2个月，显著长于Python生态系统；75.8%的LLM在其配置文件中包含易受攻击的依赖项。

Conclusion: 该研究增进了对LLM供应链风险的理解，为从业者提供了见解，并指出了改进LLM供应链安全的潜在方向。

Abstract: Large language models (LLMs) have developed rapidly in recent years,
revolutionizing various fields. Despite their widespread success, LLMs heavily
rely on external code dependencies from package management systems, creating a
complex and interconnected LLM dependency supply chain. Vulnerabilities in
dependencies can expose LLMs to security risks. While existing research
predominantly focuses on model-level security threats, vulnerabilities within
the LLM dependency supply chain have been overlooked. To fill this gap, we
conducted an empirical analysis of 52 open-source LLMs, examining their
third-party dependencies and associated vulnerabilities. We then explored
activities within the LLM repositories to understand how maintainers manage
third-party vulnerabilities in practice. Finally, we compared third-party
dependency vulnerabilities in the LLM ecosystem to those in the Python
ecosystem. Our results show that half of the vulnerabilities in the LLM
ecosystem remain undisclosed for more than 56.2 months, significantly longer
than those in the Python ecosystem. Additionally, 75.8% of LLMs include
vulnerable dependencies in their configuration files. This study advances the
understanding of LLM supply chain risks, provides insights for practitioners,
and highlights potential directions for improving the security of the LLM
supply chain.

</details>


### [15] [RepoMark: A Code Usage Auditing Framework for Code Large Language Models](https://arxiv.org/abs/2508.21432)
*Wenjie Qu,Yuguang Zhou,Bo Wang,Wengrui Zheng,Yuexin Li,Jinyuan Jia,Jiaheng Zhang*

Main category: cs.CR

TL;DR: RepoMark是一个新颖的数据标记框架，用于审计代码大语言模型的数据使用情况，通过生成语义等效的代码变体并引入数据标记，在保持语义不变的情况下检测模型是否使用了特定代码库进行训练。


<details>
  <summary>Details</summary>
Motivation: 随着代码大语言模型的快速发展，模型在开源代码库上的训练引发了严重的伦理和法律问题，特别是数据授权和开源许可证合规性问题。开发者质疑模型训练者是否获得了适当的授权，而数据收集过程缺乏透明度。

Method: 提出RepoMark框架，通过生成多个语义等效的代码变体，在代码文件中引入数据标记。在检测阶段，使用基于排序的新型假设检验方法来检测模型中的记忆化现象。

Result: 实验表明，在严格的5%错误检测率保证下，RepoMark在小代码库上的检测成功率超过90%，显著优于现有数据标记技术（准确率低于55%）。

Conclusion: RepoMark是一个强大、理论可靠且有前景的解决方案，能够增强代码大语言模型训练的透明度，保护代码库所有者的权益。

Abstract: The rapid development of Large Language Models (LLMs) for code generation has
transformed software development by automating coding tasks with unprecedented
efficiency.
  However, the training of these models on open-source code repositories (e.g.,
from GitHub) raises critical ethical and legal concerns, particularly regarding
data authorization and open-source license compliance. Developers are
increasingly questioning whether model trainers have obtained proper
authorization before using repositories for training, especially given the lack
of transparency in data collection.
  To address these concerns, we propose a novel data marking framework RepoMark
to audit the data usage of code LLMs. Our method enables repository owners to
verify whether their code has been used in training, while ensuring semantic
preservation, imperceptibility, and theoretical false detection rate (FDR)
guarantees. By generating multiple semantically equivalent code variants,
RepoMark introduces data marks into the code files, and during detection,
RepoMark leverages a novel ranking-based hypothesis test to detect memorization
within the model. Compared to prior data auditing approaches, RepoMark
significantly enhances sample efficiency, allowing effective auditing even when
the user's repository possesses only a small number of code files.
  Experiments demonstrate that RepoMark achieves a detection success rate over
90\% on small code repositories under a strict FDR guarantee of 5\%. This
represents a significant advancement over existing data marking techniques, all
of which only achieve accuracy below 55\% under identical settings. This
further validates RepoMark as a robust, theoretically sound, and promising
solution for enhancing transparency in code LLM training, which can safeguard
the rights of repository owners.

</details>


### [16] [Time Tells All: Deanonymization of Blockchain RPC Users with Zero Transaction Fee (Extended Version)](https://arxiv.org/abs/2508.21440)
*Shan Wang,Ming Yang,Yu Liu,Yue Zhang,Shuaiqing Zhang,Zhen Ling,Jiannong Cao,Xinwen Fu*

Main category: cs.CR

TL;DR: 提出一种针对区块链RPC服务的零成本去匿名化攻击，通过分析交易确认时间与网络数据包时间戳的关联，能够以超过95%的成功率将用户IP地址与其区块链假名关联


<details>
  <summary>Details</summary>
Motivation: 区块链RPC服务虽然提供了便利，但存在严重的隐私风险，现有的去匿名化攻击要么不适用于RPC用户，要么需要支付交易费用，需要一种更有效的攻击方法

Method: 利用交易确认时间戳与用户查询交易状态时TCP数据包时间戳的时序相关性，通过监控网络流量和分析公共账本，建立IP地址与区块链假名的关联

Result: 攻击在以太坊、比特币和Solana等多种区块链网络上对普通RPC用户实现了超过95%的成功率，且无需支付任何交易费用

Conclusion: 区块链RPC服务存在严重的隐私泄露风险，提出的时序相关性分析方法能够有效实现去匿名化攻击，揭示了当前RPC服务架构的隐私缺陷

Abstract: Remote Procedure Call (RPC) services have become a primary gateway for users
to access public blockchains. While they offer significant convenience, RPC
services also introduce critical privacy challenges that remain insufficiently
examined. Existing deanonymization attacks either do not apply to blockchain
RPC users or incur costs like transaction fees assuming an active network
eavesdropper. In this paper, we propose a novel deanonymization attack that can
link an IP address of a RPC user to this user's blockchain pseudonym. Our
analysis reveals a temporal correlation between the timestamps of transaction
confirmations recorded on the public ledger and those of TCP packets sent by
the victim when querying transaction status. We assume a strong passive
adversary with access to network infrastructure, capable of monitoring traffic
at network border routers or Internet exchange points. By monitoring network
traffic and analyzing public ledgers, the attacker can link the IP address of
the TCP packet to the pseudonym of the transaction initiator by exploiting the
temporal correlation. This deanonymization attack incurs zero transaction fee.
We mathematically model and analyze the attack method, perform large-scale
measurements of blockchain ledgers, and conduct real-world attacks to validate
the attack. Our attack achieves a high success rate of over 95% against normal
RPC users on various blockchain networks, including Ethereum, Bitcoin and
Solana.

</details>


### [17] [SoK: Large Language Model-Generated Textual Phishing Campaigns End-to-End Analysis of Generation, Characteristics, and Detection](https://arxiv.org/abs/2508.21457)
*Fengchao Chen,Tingmin Wu,Van Nguyen,Carsten Rudolph*

Main category: cs.CR

TL;DR: 本文首次系统化分析了LLM生成的网络钓鱼攻击，提出了GenCharDef框架，从生成技术、攻击特征到防御策略进行端到端分析，揭示了LLM钓鱼与传统钓鱼在方法、安全视角、数据依赖和评估实践上的差异。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型(LLMs)的发展，网络钓鱼攻击变得更加低成本、可扩展和隐蔽，出现了"钓鱼即服务"的新型攻击模式。尽管LLM辅助钓鱼攻击研究增多，但缺乏对钓鱼攻击生命周期的系统性研究。

Method: 提出了Generation-Characterization-Defense (GenCharDef)框架，通过系统化知识(SoK)方法，对LLM生成的钓鱼攻击进行端到端分析，涵盖生成技术、攻击特征和缓解策略。

Result: 系统化地识别了LLM生成钓鱼与传统钓鱼在方法论、安全视角、数据依赖和评估实践方面的关键差异，揭示了LLM驱动钓鱼的独特挑战。

Conclusion: GenCharDef框架为理解不断演变的威胁态势提供了连贯基础，并指导设计更具弹性的防御措施，填补了LLM生成钓鱼系统性研究的空白。

Abstract: Phishing is a pervasive form of social engineering in which attackers
impersonate trusted entities to steal information or induce harmful actions.
Text-based phishing dominates for its low cost, scalability, and
concealability, advantages recently amplified by large language models (LLMs)
that enable ``Phishing-as-a-Service'' attacks at scale within minutes. Despite
the growing research into LLM-facilitated phishing attacks, consolidated
systematic research on the phishing attack life cycle remains scarce. In this
work, we present the first systematization of knowledge (SoK) on LLM-generated
phishing, offering an end-to-end analysis that spans generation techniques,
attack features, and mitigation strategies. We introduce
Generation-Characterization-Defense (GenCharDef), which systematizes the ways
in which LLM-generated phishing differs from traditional phishing across
methodologies, security perspectives, data dependencies, and evaluation
practices. This framework highlights unique challenges of LLM-driven phishing,
providing a coherent foundation for understanding the evolving threat landscape
and guiding the design of more resilient defenses.

</details>


### [18] [Towards a Decentralized IoT Onboarding for Smart Homes Using Consortium Blockchain](https://arxiv.org/abs/2508.21480)
*Narges Dadkhah,Khan Reaz,Gerhard Wunder*

Main category: cs.CR

TL;DR: 本文提出了一种基于联盟区块链的去中心化智能家庭设备入网框架，解决传统PKI模型的安全风险和用户主权限制问题。


<details>
  <summary>Details</summary>
Motivation: 智能家庭和IoT安全系统的普及带来了便捷性和安全性提升的机遇，但传统的设备入网方法存在安全风险和用户主权限制问题，限制了IoT解决方案的可扩展部署。

Method: 提出了一种新的入网框架，基于现有网络层入网技术并扩展到应用层，集成联盟区块链技术实现去中心化入网机制，支持设备注册、密钥撤销、访问控制管理和风险检测等功能。

Result: 使用Tamarin Prover进行正式模型验证，证明协议具有认证、令牌完整性、密钥保密性和公共通道弹性。原型实现验证了框架的可行性，验证时间仅0.34秒，显示了其可扩展性。性能评估显示该方法能够处理不同工作负荷，保持高吞吞量、低延迟，支持近实时IoT数据处理。

Conclusion: 该研究提出的基于区块链的去中心化入网框架有效解决了智能家庭设备入网的安全性和可扩展性问题，为IoT平台提供了更透明、安全的信任建立方案，具有实际应用价值。

Abstract: The increasing adoption of smart home devices and IoT-based security systems
presents significant opportunities to enhance convenience, safety, and risk
management for homeowners and service providers. However, secure
onboarding-provisioning credentials and establishing trust with cloud
platforms-remains a considerable challenge. Traditional onboarding methods
often rely on centralized Public Key Infrastructure (PKI) models and
manufacturer-controlled keys, which introduce security risks and limit the
user's digital sovereignty. These limitations hinder the widespread deployment
of scalable IoT solutions. This paper presents a novel onboarding framework
that builds upon existing network-layer onboarding techniques and extends them
to the application layer to address these challenges. By integrating consortium
blockchain technology, we propose a decentralized onboarding mechanism that
enhances transparency, security, and monitoring for smart home architectures.
The architecture supports device registration, key revocation, access control
management, and risk detection through event-driven alerts across dedicated
blockchain channels and smart contracts. To evaluate the framework, we formally
model the protocol using the Tamarin Prover under the Dolev-Yao adversary
model. The analysis focuses on authentication, token integrity, key
confidentiality, and resilience over public channels. A prototype
implementation demonstrates the system's viability in smart home settings, with
verification completing in 0.34 seconds, highlighting its scalability and
suitability for constrained devices and diverse stakeholders. Additionally,
performance evaluation shows that the blockchain-based approach effectively
handles varying workloads, maintains high throughput and low latency, and
supports near real-time IoT data processing.

</details>


### [19] [Generalized Encrypted Traffic Classification Using Inter-Flow Signals](https://arxiv.org/abs/2508.21558)
*Federica Bianchi,Edoardo Di Paolo,Angelo Spognardi*

Main category: cs.CR

TL;DR: 提出了一种基于原始PCAP数据的加密流量分类模型，利用创新的跨流信号表示方法，在多个分类任务和数据集上优于现有方法，准确率最高可达99%


<details>
  <summary>Details</summary>
Motivation: 现有加密流量分类方法通常需要先验假设且缺乏通用性，需要开发一种无需假设、可跨任务通用的分类模型

Method: 直接在原始PCAP数据上操作，利用跨流信号表示方法捕获流间时间相关性和数据包量分布特征

Result: 在几乎所有分类任务和大多数数据集上都优于现有成熟方法，部分情况下准确率达到99%

Conclusion: 该模型展现了出色的鲁棒性和适应性，为加密流量分类提供了有效的通用解决方案

Abstract: In this paper, we present a novel encrypted traffic classification model that
operates directly on raw PCAP data without requiring prior assumptions about
traffic type. Unlike existing methods, it is generalizable across multiple
classification tasks and leverages inter-flow signals - an innovative
representation that captures temporal correlations and packet volume
distributions across flows. Experimental results show that our model
outperforms well-established methods in nearly every classification task and
across most datasets, achieving up to 99% accuracy in some cases, demonstrating
its robustness and adaptability.

</details>


### [20] [Agentic Discovery and Validation of Android App Vulnerabilities](https://arxiv.org/abs/2508.21579)
*Ziyue Wang,Liyi Zhou*

Main category: cs.CR

TL;DR: A2系统通过智能代理方式发现和验证Android漏洞，显著提高检测准确率并自动生成漏洞利用证明，在基准测试中达到78.3%覆盖率，在真实应用中发现了104个零日漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有Android漏洞检测工具产生大量低价值警告，分析师需要花费大量时间筛选，而真正可利用的漏洞往往被遗漏，造成安全瓶颈。

Method: 采用双阶段方法：(i)智能漏洞发现-结合语义理解和传统安全工具分析应用安全；(ii)智能漏洞验证-系统性地验证Android多模态攻击面（UI交互、组件通信、文件操作、密码计算等）的漏洞。

Result: 在Ghera基准测试(n=60)中达到78.3%覆盖率，远超现有最佳分析器(APKHunt 30.0%)；生成82个推测性漏洞发现，其中51个生成有效PoC证明；在169个生产APK中发现104个零日漏洞，54.8%自动生成PoC验证。

Conclusion: A2系统能够有效减少误报，提高漏洞检测准确性，并通过自动生成PoC证明漏洞可利用性，显著提升Android应用安全分析的效率和效果。

Abstract: Existing Android vulnerability detection tools overwhelm teams with thousands
of low-signal warnings yet uncover few true positives. Analysts spend days
triaging these results, creating a bottleneck in the security pipeline.
Meanwhile, genuinely exploitable vulnerabilities often slip through, leaving
opportunities open to malicious counterparts.
  We introduce A2, a system that mirrors how security experts analyze and
validate Android vulnerabilities through two complementary phases: (i) Agentic
Vulnerability Discovery, which reasons about application security by combining
semantic understanding with traditional security tools; and (ii) Agentic
Vulnerability Validation, which systematically validates vulnerabilities across
Android's multi-modal attack surface-UI interactions, inter-component
communication, file system operations, and cryptographic computations.
  On the Ghera benchmark (n=60), A2 achieves 78.3% coverage, surpassing
state-of-the-art analyzers (e.g., APKHunt 30.0%). Rather than overwhelming
analysts with thousands of warnings, A2 distills results into 82 speculative
vulnerability findings, including 47 Ghera cases and 28 additional true
positives. Crucially, A2 then generates working Proof-of-Concepts (PoCs) for 51
of these speculative findings, transforming them into validated vulnerability
findings that provide direct, self-confirming evidence of exploitability.
  In real-world evaluation on 169 production APKs, A2 uncovers 104
true-positive zero-day vulnerabilities. Among these, 57 (54.8%) are
self-validated with automatically generated PoCs, including a medium-severity
vulnerability in a widely used application with over 10 million installs.

</details>


### [21] [Condense to Conduct and Conduct to Condense](https://arxiv.org/abs/2508.21602)
*Tomasz Kazana*

Main category: cs.CR

TL;DR: 本文首次构建了低电导度置换的例子，并证明了低电导度置换与多源某处压缩器在信息论特性上的等价性


<details>
  <summary>Details</summary>
Motivation: Dodis等人先前提出了置换电导度的概念并开始寻找低电导度置换，本文旨在提供具体实例并建立一般性理论特征

Method: 通过理论分析和构造性证明，展示了低电导度置换与多源某处压缩器之间的等价关系

Result: 成功构建了首个低电导度置换实例，并建立了该问题的完整理论特征

Conclusion: 低电导度置换的存在性得到证明，且其与多源某处压缩器在信息论层面具有等价性，为密码学中的混淆-扩散网络提供了重要理论基础

Abstract: In this paper we give the first examples of low-conductance permutations. The
notion of conductance of permutations was introduced in the paper
"Indifferentiability of Confusion-Diffusion Networks" by Dodis et al., where
the search for low-conductance permutations was initiated and motivated. In
this paper we not only give the desired examples, but also make a general
characterization of the problem -- i.e. we show that low-conductance
permutations are equivalent to permutations that have the information-theoretic
properties of the so-called Multi-Source-Somewhere-Condensers.

</details>


### [22] [Detecting Stealthy Data Poisoning Attacks in AI Code Generators](https://arxiv.org/abs/2508.21636)
*Cristina Improta*

Main category: cs.CR

TL;DR: 本文系统研究了现有数据投毒检测方法在无触发器的隐蔽攻击模型下的有效性，发现现有方法在检测针对代码生成模型的隐形投毒攻击方面存在显著不足


<details>
  <summary>Details</summary>
Motivation: 深度学习代码生成模型依赖大量网络数据，容易遭受数据投毒攻击。近期出现的无触发器攻击能够悄无声息地将安全代码替换为语义等效但存在漏洞的实现，使得检测方法难以区分干净样本和投毒样本

Method: 对三个深度学习模型（CodeBERT、CodeT5+、AST-T5）进行针对性投毒攻击，评估频谱签名分析、激活聚类和静态分析三种防御方法的有效性

Result: 所有检测方法在检测无触发器投毒方面都表现不佳：基于表示的方法无法隔离投毒样本，静态分析存在假阳性和假阴性问题

Conclusion: 研究结果强调了需要为AI辅助代码生成开发更强大、不依赖触发器的防御机制，以应对这种隐蔽威胁模型

Abstract: Deep learning (DL) models for natural language-to-code generation have become
integral to modern software development pipelines. However, their heavy
reliance on large amounts of data, often collected from unsanitized online
sources, exposes them to data poisoning attacks, where adversaries inject
malicious samples to subtly bias model behavior. Recent targeted attacks
silently replace secure code with semantically equivalent but vulnerable
implementations without relying on explicit triggers to launch the attack,
making it especially hard for detection methods to distinguish clean from
poisoned samples. We present a systematic study on the effectiveness of
existing poisoning detection methods under this stealthy threat model.
Specifically, we perform targeted poisoning on three DL models (CodeBERT,
CodeT5+, AST-T5), and evaluate spectral signatures analysis, activation
clustering, and static analysis as defenses. Our results show that all methods
struggle to detect triggerless poisoning, with representation-based approaches
failing to isolate poisoned samples and static analysis suffering false
positives and false negatives, highlighting the need for more robust,
trigger-independent defenses for AI-assisted code generation.

</details>


### [23] [Hybrid Cryptographic Monitoring System for Side-Channel Attack Detection on PYNQ SoCs](https://arxiv.org/abs/2508.21606)
*Nishant Chinnasami,Rasha Karakchi*

Main category: cs.CR

TL;DR: 提出了一种轻量级双检测框架，结合统计阈值和机器学习方法，用于AES-128加密在嵌入式系统中的实时异常检测，无需修改AES内部结构或依赖硬件性能计数器。


<details>
  <summary>Details</summary>
Motivation: AES-128加密虽然在理论上安全，但在嵌入式系统实际部署中容易受到时序和故障注入攻击，需要一种轻量级的实时检测方案。

Method: 通过模拟延迟和密文损坏来收集时序和数据特征，评估两种策略：基于执行时间的统计阈值方法和基于块级异常的随机森林分类器，在CPU和FPGA平台上实现。

Result: 机器学习方法在准确性上优于静态阈值方法，同时在嵌入式平台上保持实时可行性。

Conclusion: 该框架特别适用于需要在检测精度和计算效率之间取得平衡的低功耗、资源受限系统。

Abstract: AES-128 encryption is theoretically secure but vulnerable in practical
deployments due to timing and fault injection attacks on embedded systems. This
work presents a lightweight dual-detection framework combining statistical
thresholding and machine learning (ML) for real-time anomaly detection. By
simulating anomalies via delays and ciphertext corruption, we collect timing
and data features to evaluate two strategies: (1) a statistical threshold
method based on execution time and (2) a Random Forest classifier trained on
block-level anomalies. Implemented on CPU and FPGA (PYNQ-Z1), our results show
that the ML approach outperforms static thresholds in accuracy, while
maintaining real-time feasibility on embedded platforms. The framework operates
without modifying AES internals or relying on hardware performance counters.
This makes it especially suitable for low-power, resource-constrained systems
where detection accuracy and computational efficiency must be balanced.

</details>


### [24] [I Stolenly Swear That I Am Up to (No) Good: Design and Evaluation of Model Stealing Attacks](https://arxiv.org/abs/2508.21654)
*Daryna Oliynyk,Rudolf Mayer,Kathrin Grosse,Andreas Rauber*

Main category: cs.CR

TL;DR: 这篇论文首次提出了模型盗窃攻击的标准化评估方法，通过分析图像分类模型攻击案例，提出了完整的威胁模型和攻击比较框架，以及攻击开发的最佳实践和研究方向。


<details>
  <summary>Details</summary>
Motivation: 目前模型盗窃攻击的设计和评估缺乏标准化，导致不同研究工作难以比较和评估进展。这个领域需要统一的评估方法来提高研究的可比性和可重现性。

Method: 研究了最大的图像分类模型盗窃攻击群体，提出了第一个完整的威胁模型和攻击比较框架，分析了相关工作的攻击设置。

Result: 提出了攻击开发的最佳实践指南（实验前、实验中和实验后），以及一个广泛的开政研究问题清单。

Conclusion: 这个方法论是第一个通用的模型盗窃攻击评估方法，不仅适用于图像分类领域，也可以转移到其他问题领域，为该领域的研究提供了标准化的评估基准。

Abstract: Model stealing attacks endanger the confidentiality of machine learning
models offered as a service. Although these models are kept secret, a malicious
party can query a model to label data samples and train their own substitute
model, violating intellectual property. While novel attacks in the field are
continually being published, their design and evaluations are not standardised,
making it challenging to compare prior works and assess progress in the field.
This paper is the first to address this gap by providing recommendations for
designing and evaluating model stealing attacks. To this end, we study the
largest group of attacks that rely on training a substitute model -- those
attacking image classification models. We propose the first comprehensive
threat model and develop a framework for attack comparison. Further, we analyse
attack setups from related works to understand which tasks and models have been
studied the most. Based on our findings, we present best practices for attack
development before, during, and beyond experiments and derive an extensive list
of open research questions regarding the evaluation of model stealing attacks.
Our findings and recommendations also transfer to other problem domains, hence
establishing the first generic evaluation methodology for model stealing
attacks.

</details>


### [25] [Cybersecurity AI: Hacking the AI Hackers via Prompt Injection](https://arxiv.org/abs/2508.21669)
*Víctor Mayoral-Vilches,Per Mannermaa Rynning*

Main category: cs.CR

TL;DR: AI网络安全工具存在提示注入漏洞，攻击者可通过恶意内容劫持AI代理执行流程，获得系统访问权限。


<details>
  <summary>Details</summary>
Motivation: 揭示AI驱动的网络安全工具面临的新型安全威胁——提示注入攻击，类似于传统XSS漏洞，需要安全社区重视和解决。

Method: 通过对网络安全AI框架及其CLI工具进行概念验证攻击，展示提示注入漏洞的实际危害，并实施多层防御机制进行缓解。

Result: 成功演示了针对CAI框架的提示注入攻击，证明这是LLM架构中普遍存在的系统性安全问题。

Conclusion: 提示注入是LLM基础架构中反复出现的系统性问题，需要像处理传统Web应用XSS那样投入专门工作来解决。

Abstract: We demonstrate how AI-powered cybersecurity tools can be turned against
themselves through prompt injection attacks. Prompt injection is reminiscent of
cross-site scripting (XSS): malicious text is hidden within seemingly trusted
content, and when the system processes it, that text is transformed into
unintended instructions. When AI agents designed to find and exploit
vulnerabilities interact with malicious web servers, carefully crafted reponses
can hijack their execution flow, potentially granting attackers system access.
We present proof-of-concept exploits against the Cybersecurity AI (CAI)
framework and its CLI tool, and detail our mitigations against such attacks in
a multi-layered defense implementation. Our findings indicate that prompt
injection is a recurring and systemic issue in LLM-based architectures, one
that will require dedicated work to address, much as the security community has
had to do with XSS in traditional web applications.

</details>


### [26] [OptMark: Robust Multi-bit Diffusion Watermarking via Inference Time Optimization](https://arxiv.org/abs/2508.21727)
*Jiazheng Xing,Hai Ci,Hongbin Xu,Hangjie Yuan,Yong Liu,Mike Zheng Shou*

Main category: cs.CR

TL;DR: OptMark是一种基于优化的多比特水印方法，通过在扩散去噪过程的中间潜在空间中嵌入水印，实现了对图像变换和生成攻击的鲁棒性保护。


<details>
  <summary>Details</summary>
Motivation: 当前扩散水印方法存在局限性：零比特水印系统缺乏大规模用户跟踪能力，而多比特方法对某些图像变换或生成攻击高度敏感，缺乏全面的鲁棒性。

Method: 在扩散去噪过程中早期嵌入结构水印以抵抗生成攻击，晚期嵌入细节水印以抵御图像变换，采用定制正则化项保持图像质量和不可感知性，并利用伴随梯度方法将内存使用从O(N)降低到O(1)。

Result: 实验结果表明OptMark实现了不可见的多比特水印，同时对值度量变换、几何变换、编辑和再生攻击具有强大的鲁棒性。

Conclusion: OptMark提供了一种有效的解决方案，解决了扩散生成图像水印中的鲁棒性和容量限制问题，为版权保护和用户跟踪提供了可靠的技术支持。

Abstract: Watermarking diffusion-generated images is crucial for copyright protection
and user tracking. However, current diffusion watermarking methods face
significant limitations: zero-bit watermarking systems lack the capacity for
large-scale user tracking, while multi-bit methods are highly sensitive to
certain image transformations or generative attacks, resulting in a lack of
comprehensive robustness. In this paper, we propose OptMark, an
optimization-based approach that embeds a robust multi-bit watermark into the
intermediate latents of the diffusion denoising process. OptMark strategically
inserts a structural watermark early to resist generative attacks and a detail
watermark late to withstand image transformations, with tailored regularization
terms to preserve image quality and ensure imperceptibility. To address the
challenge of memory consumption growing linearly with the number of denoising
steps during optimization, OptMark incorporates adjoint gradient methods,
reducing memory usage from O(N) to O(1). Experimental results demonstrate that
OptMark achieves invisible multi-bit watermarking while ensuring robust
resilience against valuemetric transformations, geometric transformations,
editing, and regeneration attacks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [27] [Fuzzy, Symbolic, and Contextual: Enhancing LLM Instruction via Cognitive Scaffolding](https://arxiv.org/abs/2508.21204)
*Vanessa Figueiredo*

Main category: cs.AI

TL;DR: 这篇论文研究了大型语言模型的架构引导偏置如何影响教学对话中的认知行为，通过符号脚手架和短期记忆机制提升适应性思维能力。


<details>
  <summary>Details</summary>
Motivation: 探索架构设计对LLMs在教育对话中认知行为的影响，以提升模型在苏格拉底式教学中的理性思维能力。

Method: 采用符号脚手架机制配合短期记忆模式，通过5个系统变体的对比实验，使用专家设计的评价标准进行认知行为分析。

Result: 完整系统在脚手架、响应性、符号思维和对话记忆方面均超过基线变体，移除记忆或符号结构会对抽象、适应性探测和概念连续性产生负面影响。

Conclusion: 架构脚手架能够可靠地形成LLMs中派生的教学策略，支持了处理级别的认知形成机制。

Abstract: We study how architectural inductive biases influence the cognitive behavior
of large language models (LLMs) in instructional dialogue. We introduce a
symbolic scaffolding mechanism paired with a short-term memory schema designed
to promote adaptive, structured reasoning in Socratic tutoring. Using
controlled ablation across five system variants, we evaluate model outputs via
expert-designed rubrics covering scaffolding, responsiveness, symbolic
reasoning, and conversational memory. We present preliminary results using an
LLM-based evaluation framework aligned to a cognitively grounded rubric. This
enables scalable, systematic comparisons across architectural variants in
early-stage experimentation. The preliminary results show that our full system
consistently outperforms baseline variants. Analysis reveals that removing
memory or symbolic structure degrades key cognitive behaviors, including
abstraction, adaptive probing, and conceptual continuity. These findings
support a processing-level account in which architectural scaffolds can
reliably shape emergent instructional strategies in LLMs.

</details>


### [28] [Addressing accuracy and hallucination of LLMs in Alzheimer's disease research through knowledge graphs](https://arxiv.org/abs/2508.21238)
*Tingxuan Xu,Jiarui Feng,Justin Melendez,Kaleigh Roberts,Donghong Cai,Mingfang Zhu,Donald Elbert,Yixin Chen,Randall J. Bateman*

Main category: cs.AI

TL;DR: 这篇论文评估了GraphRAG系统在阿尔茫海默病生物医学领域的性能，通过对比学科问答质量和可追溯性，为研究人员提供了易用的测试界面和预建数据库。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在多个领域发挥作用，但在科学研究中仍遇到幻觉、领域知识缺乏、回答不可追溯等挑战。GraphRAG作为一种有前景的方法，可以通过整合领域特定上下文信息来提高聊天机器人的可靠性。

Method: 编译50篇论文和70个专家问题的阿尔茫海默病数据库，构建GraphRAG知识库，使用GPT-4o作为LLM回答查询，对比GraphRAG与标准GPT-4o模型的回答质量，评估多个RAG和GraphRAG系统的可追溯性。

Result: 评估了GraphRAG系统在阿尔茫海默病领域的表现，对比了与标准LLM模型的性能差异，并分析了不同RAG系统的可追溯性特性。

Conclusion: 研究为生物医学领域的GraphRAG应用提供了实证评估，开发了易用的测试界面和预建数据库，有助于推动GraphRAG技术在专业领域的应用和研究。

Abstract: In the past two years, large language model (LLM)-based chatbots, such as
ChatGPT, have revolutionized various domains by enabling diverse task
completion and question-answering capabilities. However, their application in
scientific research remains constrained by challenges such as hallucinations,
limited domain-specific knowledge, and lack of explainability or traceability
for the response. Graph-based Retrieval-Augmented Generation (GraphRAG) has
emerged as a promising approach to improving chatbot reliability by integrating
domain-specific contextual information before response generation, addressing
some limitations of standard LLMs. Despite its potential, there are only
limited studies that evaluate GraphRAG on specific domains that require
intensive knowledge, like Alzheimer's disease or other biomedical domains. In
this paper, we assess the quality and traceability of two popular GraphRAG
systems. We compile a database of 50 papers and 70 expert questions related to
Alzheimer's disease, construct a GraphRAG knowledge base, and employ GPT-4o as
the LLM for answering queries. We then compare the quality of responses
generated by GraphRAG with those from a standard GPT-4o model. Additionally, we
discuss and evaluate the traceability of several Retrieval-Augmented Generation
(RAG) and GraphRAG systems. Finally, we provide an easy-to-use interface with a
pre-built Alzheimer's disease database for researchers to test the performance
of both standard RAG and GraphRAG.

</details>


### [29] [MultiFluxAI Enhancing Platform Engineering with Advanced Agent-Orchestrated Retrieval Systems](https://arxiv.org/abs/2508.21307)
*Sri Ram Macharla,Sridhar Murthy J,Anjaneyulu Pasala*

Main category: cs.AI

TL;DR: MultiFluxAI是一个创新的AI平台，用于解决产品工程中管理和集成大量不同数据源的挑战，通过生成式AI、向量化和智能编排技术提供动态的上下文感知响应。


<details>
  <summary>Details</summary>
Motivation: 解决产品工程中管理和集成大量不同数据源的挑战，增强数字生态系统中用户参与度，处理当前和新的服务相关查询。

Method: 利用先进的AI技术，包括生成式AI、向量化和智能编排，提供动态和上下文感知的复杂用户查询响应。

Result: 开发了一个创新的AI平台，能够有效管理和集成不同数据源，提升用户参与度和查询处理能力。

Conclusion: MultiFluxAI通过先进的AI技术成功解决了产品工程中的数据管理挑战，提供了增强的用户体验和动态响应能力。

Abstract: MultiFluxAI is an innovative AI platform developed to address the challenges
of managing and integrating vast, disparate data sources in product engineering
across application domains. It addresses both current and new service related
queries that enhance user engagement in the digital ecosystem. This platform
leverages advanced AI techniques, such as Generative AI, vectorization, and
agentic orchestration to provide dynamic and context-aware responses to complex
user queries.

</details>


### [30] [Multi-Ontology Integration with Dual-Axis Propagation for Medical Concept Representation](https://arxiv.org/abs/2508.21320)
*Mohsen Nayebi Kerdabadi,Arya Hadizadeh Moghaddam,Dongjie Wang,Zijun Yao*

Main category: cs.AI

TL;DR: LINKO是一个基于大语言模型的医疗本体集成学习框架，通过双轴知识传播（垂直和水平）来增强医疗概念表示学习，在有限数据和罕见疾病预测场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注单一本体系统或多个孤立本体系统的知识整合，缺乏跨本体系统的统一学习结构，导致概念表示学习局限于本体内部关系，忽略了跨本体连接。

Method: 1) 使用LLM提供图检索增强的初始化嵌入；2) 通过双轴知识传播联合学习：垂直传播（层级内）和水平传播（跨本体）；3) 作为插件编码器与现有EHR预测模型兼容。

Result: 在两个公共数据集上的实验验证了LINKO优于最先进基线方法，在有限数据可用性和罕见疾病预测场景中表现出更强的鲁棒性。

Conclusion: LINKO框架通过整合多个本体图并实现跨异构本体系统的知识传播，显著提升了医疗概念表示学习的效果，特别是在数据稀缺和罕见疾病预测方面具有重要价值。

Abstract: Medical ontology graphs map external knowledge to medical codes in electronic
health records via structured relationships. By leveraging domain-approved
connections (e.g., parent-child), predictive models can generate richer medical
concept representations by incorporating contextual information from related
concepts. However, existing literature primarily focuses on incorporating
domain knowledge from a single ontology system, or from multiple ontology
systems (e.g., diseases, drugs, and procedures) in isolation, without
integrating them into a unified learning structure. Consequently, concept
representation learning often remains limited to intra-ontology relationships,
overlooking cross-ontology connections. In this paper, we propose LINKO, a
large language model (LLM)-augmented integrative ontology learning framework
that leverages multiple ontology graphs simultaneously by enabling dual-axis
knowledge propagation both within and across heterogeneous ontology systems to
enhance medical concept representation learning. Specifically, LINKO first
employs LLMs to provide a graph-retrieval-augmented initialization for ontology
concept embedding, through an engineered prompt that includes concept
descriptions, and is further augmented with ontology context. Second, our
method jointly learns the medical concepts in diverse ontology graphs by
performing knowledge propagation in two axes: (1) intra-ontology vertical
propagation across hierarchical ontology levels and (2) inter-ontology
horizontal propagation within every level in parallel. Last, through extensive
experiments on two public datasets, we validate the superior performance of
LINKO over state-of-the-art baselines. As a plug-in encoder compatible with
existing EHR predictive models, LINKO further demonstrates enhanced robustness
in scenarios involving limited data availability and rare disease prediction.

</details>


### [31] [Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models](https://arxiv.org/abs/2508.21365)
*Yi Liao,Yu Gu,Yuan Sui,Zining Zhu,Yifan Lu,Guohua Tang,Zhongqian Sun,Wei Yang*

Main category: cs.AI

TL;DR: TiG框架通过将强化学习决策重新表述为语言建模任务，让大语言模型在游戏环境中直接交互来发展程序性知识，同时保持其推理和解释能力


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在复杂推理任务表现出色但在简单交互任务中表现不佳的问题，弥合陈述性知识和程序性知识之间的差距

Method: 将基于强化学习的决策重新表述为语言建模任务，通过在线强化学习基于环境反馈迭代优化语言引导的策略

Result: TiG成功弥合了陈述性和程序性知识差距，以显著更低的数据和计算需求达到与传统强化学习方法相当的性能，并提供逐步自然语言解释

Conclusion: TiG框架有效结合了大语言模型的世界知识和推理能力与强化学习的交互学习优势，提高了复杂交互任务的透明度和可解释性

Abstract: Large language models (LLMs) excel at complex reasoning tasks such as
mathematics and coding, yet they frequently struggle with simple interactive
tasks that young children perform effortlessly. This discrepancy highlights a
critical gap between declarative knowledge (knowing about something) and
procedural knowledge (knowing how to do something). Although traditional
reinforcement learning (RL) agents can acquire procedural knowledge through
environmental interaction, they often operate as black boxes and require
substantial training data. In contrast, LLMs possess extensive world knowledge
and reasoning capabilities, but are unable to effectively convert this static
knowledge into dynamic decision-making in interactive settings. To address this
challenge, we propose Think in Games (TiG), a novel framework that empowers
LLMs to develop procedural understanding through direct interaction with game
environments, while retaining their inherent reasoning and explanatory
abilities. Specifically, TiG reformulates RL-based decision-making as a
language modeling task: LLMs generate language-guided policies, which are
refined iteratively through online reinforcement learning based on
environmental feedback. Our experimental results show that TiG successfully
bridges the gap between declarative and procedural knowledge, achieving
competitive performance with dramatically lower data and computational demands
compared to conventional RL methods. Moreover, TiG provides step-by-step
natural language explanations for its decisions, greatly improving transparency
and interpretability in complex interactive tasks.

</details>


### [32] [AHELM: A Holistic Evaluation of Audio-Language Models](https://arxiv.org/abs/2508.21376)
*Tony Lee,Haoqin Tu,Chi Heem Wong,Zijun Wang,Siwei Yang,Yifan Mai,Yuyin Zhou,Cihang Xie,Percy Liang*

Main category: cs.AI

TL;DR: AHELM是一个综合性的音频-语言模型基准测试，包含10个评估维度，标准化了提示词和评估方法，测试了14个模型，发现Gemini 2.5 Pro在多数方面表现最佳但存在公平性问题，基线系统表现意外良好。


<details>
  <summary>Details</summary>
Motivation: 现有音频-语言模型评估缺乏标准化基准，测试维度有限，模型间难以公平比较，需要全面的评估框架。

Method: 开发AHELM基准，整合多个数据集（包括新合成的PARADE和CoRe-Bench数据集），标准化提示词、推理参数和评估指标，测试14个开源和闭源模型及3个基线系统。

Result: Gemini 2.5 Pro在10个维度中的5个排名第一，但在ASR任务中存在群体不公平性（p=0.01）；基线系统表现良好，其中一个仅具备语音转文本能力的系统总体排名第五。

Conclusion: AHELM提供了全面的音频-语言模型评估框架，揭示了现有模型的优势和不足，特别是公平性问题，基准将持续更新以促进该领域发展。

Abstract: Evaluations of audio-language models (ALMs) -- multimodal models that take
interleaved audio and text as input and output text -- are hindered by the lack
of standardized benchmarks; most benchmarks measure only one or two
capabilities and omit evaluative aspects such as fairness or safety.
Furthermore, comparison across models is difficult as separate evaluations test
a limited number of models and use different prompting methods and inference
parameters. To address these shortfalls, we introduce AHELM, a benchmark that
aggregates various datasets -- including 2 new synthetic audio-text datasets
called PARADE, which evaluates the ALMs on avoiding stereotypes, and
CoRe-Bench, which measures reasoning over conversational audio through
inferential multi-turn question answering -- to holistically measure the
performance of ALMs across 10 aspects we have identified as important to the
development and usage of ALMs: audio perception, knowledge, reasoning, emotion
detection, bias, fairness, multilinguality, robustness, toxicity, and safety.
We also standardize the prompts, inference parameters, and evaluation metrics
to ensure equitable comparisons across models. We test 14 open-weight and
closed-API ALMs from 3 developers and 3 additional simple baseline systems each
consisting of an automatic speech recognizer and a language model. Our results
show that while Gemini 2.5 Pro ranks top in 5 out of 10 aspects, it exhibits
group unfairness ($p=0.01$) on ASR tasks whereas most of the other models do
not. We also find that the baseline systems perform reasonably well on AHELM,
with one ranking 5th overall despite having only speech-to-text capabilities.
For transparency, all raw prompts, model generations, and outputs are available
on our website at https://crfm.stanford.edu/helm/audio/v1.0.0. AHELM is
intended to be a living benchmark and new datasets and models will be added
over time.

</details>


### [33] [AI Compute Architecture and Evolution Trends](https://arxiv.org/abs/2508.21394)
*Bor-Sung Liang*

Main category: cs.AI

TL;DR: 本文提出了AI计算的七层架构模型，分析了AI从学术研究到实际应用发展中的机遇与挑战，包括技术架构演进和经济生态建设问题。


<details>
  <summary>Details</summary>
Motivation: AI发展已从学术研究转向实际应用，但在各个层面都面临诸多挑战，需要系统性地分析AI发展的机遇与挑战。

Method: 提出七层AI计算架构模型（物理层、链路层、神经网络层、上下文层、智能体层、编排层、应用层），通过大语言模型的三阶段演进分析每层的发展轨迹和关键技术。

Result: 系统阐述了AI计算架构的演进路径，分析了Scale-Up和Scale-Out策略的影响，探讨了从单AI智能体到AI生态系统的演进趋势。

Conclusion: AI发展不仅涉及技术挑战，还需要构建自持续的经济生态系统，借鉴互联网产业发展经验可以预测AI未来的发展轨迹。

Abstract: The focus of AI development has shifted from academic research to practical
applications. However, AI development faces numerous challenges at various
levels. This article will attempt to analyze the opportunities and challenges
of AI from several different perspectives using a structured approach. This
article proposes a seven-layer model for AI compute architecture, including
Physical Layer, Link Layer, Neural Network Layer, Context Layer, Agent Layer,
Orchestrator Layer, and Application Layer, from bottom to top. It also explains
how AI computing has evolved into this 7-layer architecture through the
three-stage evolution on large-scale language models (LLMs). For each layer, we
describe the development trajectory and key technologies. In Layers 1 and 2 we
discuss AI computing issues and the impact of Scale-Up and Scale-Out strategies
on computing architecture. In Layer 3 we explore two different development
paths for LLMs. In Layer 4 we discuss the impact of contextual memory on LLMs
and compares it to traditional processor memory. In Layers 5 to 7 we discuss
the trends of AI agents and explore the issues in evolution from a single AI
agent to an AI-based ecosystem, and their impact on the AI industry.
Furthermore, AI development involves not only technical challenges but also the
economic issues to build self-sustainable ecosystem. This article analyzes the
internet industry to provide predictions on the future trajectory of AI
development.

</details>


### [34] [CARJAN: Agent-Based Generation and Simulation of Traffic Scenarios with AJAN](https://arxiv.org/abs/2508.21411)
*Leonard Frank Neis,Andre Antakli,Matthias Klusch*

Main category: cs.AI

TL;DR: CARJAN是一个基于AJAN多智能体框架和CARLA驾驶模拟器的半自动化交通场景生成与仿真工具，提供可视化界面和SPARQL行为树决策机制


<details>
  <summary>Details</summary>
Motivation: 城市交通场景中不同类型交互智能体（行人、骑行者、自动驾驶车辆）的建模和虚拟仿真仍然是一个挑战，需要用户友好的工具来支持场景生成和模拟

Method: 基于AJAN多智能体工程框架和CARLA驾驶模拟器，提供可视化用户界面用于交通场景布局的建模、存储和维护，利用SPARQL行为树进行智能体决策和交互

Result: 开发了CARJAN工具，实现了在CARLA中交互式、智能体驱动的虚拟交通场景生成和仿真的首个集成方法

Conclusion: CARJAN为城市交通场景的建模和仿真提供了一个创新的半自动化解决方案，通过结合多智能体框架和驾驶模拟器，有效解决了不同类型交通参与者交互仿真的挑战

Abstract: User-friendly modeling and virtual simulation of urban traffic scenarios with
different types of interacting agents such as pedestrians, cyclists and
autonomous vehicles remains a challenge. We present CARJAN, a novel tool for
semi-automated generation and simulation of such scenarios based on the
multi-agent engineering framework AJAN and the driving simulator CARLA. CARJAN
provides a visual user interface for the modeling, storage and maintenance of
traffic scenario layouts, and leverages SPARQL Behavior Tree-based
decision-making and interactions for agents in dynamic scenario simulations in
CARLA. CARJAN provides a first integrated approach for interactive, intelligent
agent-based generation and simulation of virtual traffic scenarios in CARLA.

</details>


### [35] [A General Framework of Epistemic Forgetting and its Instantiation by Ranking Functions](https://arxiv.org/abs/2508.21441)
*Christoph Beierle,Alexander Hahn,Diana Howey,Gabriele Kern-Isberner,Kai Sauerwald*

Main category: cs.AI

TL;DR: 本文从认知角度研究知识管理中的遗忘操作，在Spohn排序函数的认知状态下提出了五种通用类型和七种具体遗忘操作，并通过逻辑编程和AGM理论的公理体系对这些操作进行全面评估。


<details>
  <summary>Details</summary>
Motivation: 现有的遗忘操作主要基于经典逻辑，如变量消除和AGM收缩理论，但缺乏对认知状态下遗忘操作的深入研究。本文旨在从认知视角探索具有更丰富语义结构的遗忘操作。

Method: 采用认知状态建模，提出五种通用类型的认知遗忘操作，并在Spohn排序函数上实例化七种具体操作。借鉴逻辑编程和AGM理论的公理体系，建立全面的评估框架。

Result: 系统评估了所有具体遗忘操作在不同公理下的表现，提供了新颖的综合概览，突出了各遗忘算子之间的差异和共同点。

Conclusion: 研究将经典遗忘操作提升到认知层面，为知识管理中的遗忘操作提供了更丰富的理论框架和实践指导，展示了不同遗忘算子在认知状态下的特性和适用场景。

Abstract: Forgetting as a knowledge management operation deliberately ignores parts of
the knowledge and beliefs of an agent, for various reasons. Forgetting has many
facets, one may want to forget parts of the syntax, a proposition, or a
conditional. In the literature, two main operators suitable for performing
forgetting have been proposed and investigated in depth: First, variable
elimination is a syntactical method that blends out certain atomic variables to
focus on the rest of the language. It has been mainly used in the area of logic
programming and answer set programming. Second, contraction in AGM belief
revision theory effectively removes propositions from belief sets under logical
deduction. Both operations rely mainly on classical logics. In this article, we
take an epistemic perspective and study forgetting operations in epistemic
states with richer semantic structures, but with clear links to propositional
logic. This allows us to investigate what forgetting in the epistemic
background means, thereby lifting well-known and novel forgetting operations to
the epistemic level. We present five general types of epistemic forgetting and
instantiate them with seven concrete forgetting operations for Spohn's ranking
functions. We take inspiration from postulates of forgetting both from logic
programming and AGM theory to propose a rich landscape of axioms for evaluating
forgetting operations. Finally, we evaluate all concrete forgetting operations
according to all postulates, leading to a novel comprehensive overview
highlighting differences and commonalities among the forgetting operators.

</details>


### [36] [Learning Lifted Action Models From Traces of Incomplete Actions and States](https://arxiv.org/abs/2508.21449)
*Niklas Jansen,Jonas Gösgens,Hector Geffner*

Main category: cs.AI

TL;DR: 从随机状态-动作轨迹中学习滑动拼图游戏的提升STRIPS模型，处理不完整的状态表示和动作参数缺失问题


<details>
  <summary>Details</summary>
Motivation: 现有方法大多假设动作是完整的STRIPS动作或所有谓词都可观察，但现实场景中状态和动作信息往往不完整，需要更真实的学习设置

Method: 引入STRIPS+变体，允许动作参数在前提条件中隐式存在，并提出SYNTH算法通过构建分层的前提表达式序列来学习STRIPS+模型

Result: 建立了SYNTH算法的正确性和完备性，并在从现有STRIPS领域衍生的STRIPS+模型生成的状态-动作轨迹上测试了可扩展性

Conclusion: 提出的STRIPS+框架和SYNTH算法能够有效处理状态和动作信息不完整的模型学习问题，为更现实的规划模型学习提供了解决方案

Abstract: Consider the problem of learning a lifted STRIPS model of the sliding-tile
puzzle from random state-action traces where the states represent the location
of the tiles only, and the actions are the labels up, down, left, and right,
with no arguments. Two challenges are involved in this problem. First, the
states are not full STRIPS states, as some predicates are missing, like the
atoms representing the position of the ``blank''. Second, the actions are not
full STRIPS either, as they do not reveal all the objects involved in the
actions effects and preconditions. Previous approaches have addressed different
versions of this model learning problem, but most assume that actions in the
traces are full STRIPS actions or that the domain predicates are all
observable. The new setting considered in this work is more ``realistic'', as
the atoms observed convey the state of the world but not full STRIPS states,
and the actions reveal the arguments needed for selecting the action but not
the ones needed for modeling it in STRIPS. For formulating and addressing the
learning problem, we introduce a variant of STRIPS, which we call STRIPS+,
where certain STRIPS action arguments can be left implicit in preconditions
which can also involve a limited form of existential quantification. The
learning problem becomes the problem of learning STRIPS+ models from STRIPS+
state-action traces. For this, the proposed learning algorithm, called SYNTH,
constructs a stratified sequence (conjunction) of precondition expressions or
``queries'' for each action, that denote unique objects in the state and ground
the implicit action arguments in STRIPS+. The correctness and completeness of
SYNTH is established, and its scalability is tested on state-action traces
obtained from STRIPS+ models derived from existing STRIPS domains.

</details>


### [37] [MMSearch-Plus: A Simple Yet Challenging Benchmark for Multimodal Browsing Agents](https://arxiv.org/abs/2508.21475)
*Xijia Tao,Yihua Teng,Xinxing Su,Xinyu Fu,Jihao Wu,Chaofan Tao,Ziru Liu,Haoli Bai,Rui Liu,Lingpeng Kong*

Main category: cs.AI

TL;DR: MMSearch-Plus是一个包含311个任务的基准测试，专门设计用于评估多模态语言模型在需要深度视觉推理、来源验证和长时程工具使用的复杂网页浏览任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态浏览基准测试往往可以通过浅层的固定工作流程解决，无法真正测试模型在细粒度视觉推理、来源验证和长时程工具使用方面的能力。

Method: 采用空间-时间外推法构建任务，每个任务包含多个弱局部视觉信号，需要通过迭代的文本-图像搜索进行提取、传播和交叉验证。提供模型无关的代理框架和浏览工具进行评估。

Result: 最强代理(o3)在没有搜索的情况下达到15.1%准确率，在搜索展开后达到36.0%；最强的开源模型(Qwen-2.5-VL-72B-Instruct)在没有搜索时为0.0%，经过20轮搜索后达到6.9%。

Conclusion: 该基准测试揭示了当前多模态语言模型在来源验证、基于部件的推理和长时程规划方面的关键失败点，为未来模型改进提供了重要方向。

Abstract: Large multimodal language models (MLLMs) are increasingly deployed as web
agents, yet many multimodal browsing benchmarks can be solved by shallow, fixed
workflows that lean on high-recall image search and nearby text-masking the
genuinely multimodal challenges of fine-grained visual reasoning, provenance
verification, and long-horizon tool use. We introduce MMSearch-Plus, a
benchmark of 311 tasks that highly demand multimodal understanding while
preserving the difficulty profile of strong text-only browsing suites. Each
item is constructed to contain multiple weak, localized visual signals that
must be extracted, propagated through iterative text-image search, and
cross-validated under retrieval noise before answering. Our curation procedure,
Spatial-Temporal Extrapolation, seeds questions whose answers require
extrapolating from spatial cues (micro-text, part-level appearance, layouts,
signage) and temporal traces (broadcast overlays, seasonal context) to
out-of-image facts such as events, dates, and venues. We provide a
model-agnostic agent framework with browsing tools and evaluate a range of
closed and open MLLMs. The strongest agent (o3) attains 15.1% without search
and 36.0% accuracy with rollout under our framework, while a strong open-source
model (Qwen-2.5-VL-72B-Instruct) achieves 0.0% without search and 6.9% after 20
rounds of search. Beyond answer accuracy, we assess bounding-box production and
cropped-image search, and conduct an error analysis that surfaces failures in
source verification, part-based reasoning, and long-horizon planning.

</details>


### [38] [Modeling Wise Decision Making: A Z-Number Fuzzy Framework Inspired by Phronesis](https://arxiv.org/abs/2508.21517)
*Sweta Kaman,Ankita Sharma,Romi Banerjee*

Main category: cs.AI

TL;DR: 使用程序化模糊推理系统和Z数量来量化智慧的多维特征和不确定性，通过图形道德困境任务收集反馈，得到了与传统量表相关的双属性智慧表征


<details>
  <summary>Details</summary>
Motivation: 现有智慧测量依赖自我报告，缺乏谦虚和不确定性的考虑，需要一种考虑多维度和信心度的计算框架来改善心理学测量并支持人道主义AI

Method: 开发了基于Z数的模糊推理系统，每个决策都用智慧分数（限制）和信心分数（确定性）表达。通过文化中立图形道德困境任务收集100名参与者的说话语言反馈，将其映射到智慧的5个理论组成部分，使用21条规则和高斯核密度估计调整的成员函数进行综合

Result: 在概念验证研究中，系统产生的双属性智慧表征与现有量表征出现中等但显著的相关性，与无关特质的关联可以忽略，支持了收敛效度和区别效度

Conclusion: 这项研究将智慧形式化为一种考虑多维度和不确定性的构念，通过Z数进行操作化。除了推进心理学测量外，还计算了模糊Z数如何为AI系统提供可解释、敏感信心的推理能力，在严格计算和类人判断之间找到安全的中间地带

Abstract: Background: Wisdom is a superordinate construct that embraces perspective
taking, reflectiveness, prosocial orientation, reflective empathetic action,
and intellectual humility. Unlike conventional models of reasoning that are
rigidly bound by binary thinking, wisdom unfolds in shades of ambiguity,
requiring both graded evaluation and self-reflective humility. Current measures
depend on self-reports and seldom reflect the humility and uncertainty inherent
in wise reasoning. A computational framework that takes into account both
multidimensionality and confidence has the potential to improve psychological
science and allow humane AI. Method: We present a fuzzy inference system with Z
numbers, each of the decisions being expressed in terms of a wisdom score
(restriction) and confidence score (certainty). As part of this study,
participants (N = 100) were exposed to culturally neutral pictorial moral
dilemma tasks to which they generated think-aloud linguistic responses, which
were mapped into five theoretically based components of wisdom. The scores of
each individual component were combined using a base of 21 rules, with
membership functions tuned via Gaussian kernel density estimation. Results: In
a proof of concept study, the system produced dual attribute wisdom
representations that correlated modestly but significantly with established
scales while showing negligible relations with unrelated traits, supporting
convergent and divergent validity. Contribution: The contribution is to
formalize wisdom as a multidimensional, uncertainty-conscious construct,
operationalized in the form of Z-numbers. In addition to progressing
measurement in psychology, it calculates how fuzzy Z numbers can provide AI
systems with interpretable, confidence-sensitive reasoning that affords a safe,
middle ground between rigorous computation and human-like judgment.

</details>


### [39] [Counterfactual Scenarios for Automated Planning](https://arxiv.org/abs/2508.21521)
*Nicola Gigante,Francesco Leofante,Andrea Micheli*

Main category: cs.AI

TL;DR: 本文提出了一种基于反事实场景的新型解释范式，通过最小化修改规划问题来满足期望属性，计算复杂度与规划求解相当，具有实际可行性。


<details>
  <summary>Details</summary>
Motivation: 传统反事实解释在自动规划中仅关注现有计划的微小修改，无法捕捉问题的高层特性，需要新的解释方法来诊断故障和推理规划特性。

Method: 提出基于反事实场景的解释范式，给定规划问题和LTLf公式定义期望属性，识别对问题的最小修改以使规划满足属性。提供了两种基于显式量化满足属性规划的具体实现。

Result: 分析了允许不同类型修改时生成反事实场景的计算复杂度，证明其通常与计算规划问题的解同样高效。

Conclusion: 反事实场景解释框架为构建实用算法提供了基础，计算复杂度可控，具有实际应用价值，能够有效解释规划问题的高层特性。

Abstract: Counterfactual Explanations (CEs) are a powerful technique used to explain
Machine Learning models by showing how the input to a model should be minimally
changed for the model to produce a different output. Similar proposals have
been made in the context of Automated Planning, where CEs have been
characterised in terms of minimal modifications to an existing plan that would
result in the satisfaction of a different goal. While such explanations may
help diagnose faults and reason about the characteristics of a plan, they fail
to capture higher-level properties of the problem being solved. To address this
limitation, we propose a novel explanation paradigm that is based on
counterfactual scenarios. In particular, given a planning problem $P$ and an
\ltlf formula $\psi$ defining desired properties of a plan, counterfactual
scenarios identify minimal modifications to $P$ such that it admits plans that
comply with $\psi$. In this paper, we present two qualitative instantiations of
counterfactual scenarios based on an explicit quantification over plans that
must satisfy $\psi$. We then characterise the computational complexity of
generating such counterfactual scenarios when different types of changes are
allowed on $P$. We show that producing counterfactual scenarios is often only
as expensive as computing a plan for $P$, thus demonstrating the practical
viability of our proposal and ultimately providing a framework to construct
practical algorithms in this area.

</details>


### [40] [HealthProcessAI: A Technical Framework and Proof-of-Concept for LLM-Enhanced Healthcare Process Mining](https://arxiv.org/abs/2508.21540)
*Eduardo Illueca-Fernandez,Kaile Chen,Fernando Seoane,Farhad Abtahi*

Main category: cs.AI

TL;DR: 这篇论文提出了HealthProcessAI框架，利用多个大语言模型简化医疗健康领域的过程挖掘应用，通过自动化语义解释和报告生成提高可访问性。


<details>
  <summary>Details</summary>
Motivation: 医疗健康领域过程挖掘应用面临技术复杂性、无标准化方法和训练资源缺乏等障碍，需要一种更易于访问和使用的解决方案。

Method: 开发HealthProcessAI框架，包装现有Python(PM4PY)和R(bupaR)库，集成多个大语言模型进行自动化过程图解释和报告生成，使用胱血病进展数据验证框架功能。

Result: 框架成功处理四个概念验证场景的胱血病数据，Claude Sonnet-4和Gemini 2.5-Pro获得最高一致性分数(3.79/4.0和3.65/4.0)，显示了模型的不同优势。

Conclusion: 该框架通过结合结构化分析和AI驱动解释，代表了将复杂过程挖掘结果转换为可执行见解的新方法进步。

Abstract: Process mining has emerged as a powerful analytical technique for
understanding complex healthcare workflows. However, its application faces
significant barriers, including technical complexity, a lack of standardized
approaches, and limited access to practical training resources. We introduce
HealthProcessAI, a GenAI framework designed to simplify process mining
applications in healthcare and epidemiology by providing a comprehensive
wrapper around existing Python (PM4PY) and R (bupaR) libraries. To address
unfamiliarity and improve accessibility, the framework integrates multiple
Large Language Models (LLMs) for automated process map interpretation and
report generation, helping translate technical analyses into outputs that
diverse users can readily understand. We validated the framework using sepsis
progression data as a proof-of-concept example and compared the outputs of five
state-of-the-art LLM models through the OpenRouter platform. To test its
functionality, the framework successfully processed sepsis data across four
proof-of-concept scenarios, demonstrating robust technical performance and its
capability to generate reports through automated LLM analysis. LLM evaluation
using five independent LLMs as automated evaluators revealed distinct model
strengths: Claude Sonnet-4 and Gemini 2.5-Pro achieved the highest consistency
scores (3.79/4.0 and 3.65/4.0) when evaluated by automated LLM assessors. By
integrating multiple Large Language Models (LLMs) for automated interpretation
and report generation, the framework addresses widespread unfamiliarity with
process mining outputs, making them more accessible to clinicians, data
scientists, and researchers. This structured analytics and AI-driven
interpretation combination represents a novel methodological advance in
translating complex process mining results into potentially actionable insights
for healthcare applications.

</details>


### [41] [Revisiting Landmarks: Learning from Previous Plans to Generalize over Problem Instances](https://arxiv.org/abs/2508.21564)
*Issa Hanou,Sebastijan Dumančić,Mathijs de Weerdt*

Main category: cs.AI

TL;DR: 提出了一种发现跨领域通用地标的新框架，通过学习已解决实例自动生成中间目标，用于传统地标提取算法难以处理的规划问题


<details>
  <summary>Details</summary>
Motivation: 传统地标提取算法在处理具有重复性子计划的规划问题时效果有限，需要一种能够捕捉领域重复性模式并自动泛化的方法

Method: 使用独立于具体问题对象的状态函数构建有向通用地标图，包括循环可能性来表示重复性子计划，并基于此图设计启发式算法

Result: 从少量小实例学习到的通用地标图对同一领域的大实例同样有效，当识别到表示重复的循环时，启发式性能相比基线有显著提升

Conclusion: 通用地标能够捕捉可解释且对自动规划器有用的领域信息，这些信息可以从同一领域的小规模计划集中自动发现

Abstract: We propose a new framework for discovering landmarks that automatically
generalize across a domain. These generalized landmarks are learned from a set
of solved instances and describe intermediate goals for planning problems where
traditional landmark extraction algorithms fall short. Our generalized
landmarks extend beyond the predicates of a domain by using state functions
that are independent of the objects of a specific problem and apply to all
similar objects, thus capturing repetition. Based on these functions, we
construct a directed generalized landmark graph that defines the landmark
progression, including loop possibilities for repetitive subplans. We show how
to use this graph in a heuristic to solve new problem instances of the same
domain. Our results show that the generalized landmark graphs learned from a
few small instances are also effective for larger instances in the same domain.
If a loop that indicates repetition is identified, we see a significant
improvement in heuristic performance over the baseline. Generalized landmarks
capture domain information that is interpretable and useful to an automated
planner. This information can be discovered from a small set of plans for the
same domain.

</details>


### [42] [Scalable Solution Methods for Dec-POMDPs with Deterministic Dynamics](https://arxiv.org/abs/2508.21595)
*Yang You,Alex Schutz,Zhikun Li,Bruno Lacerda,Robert Skilton,Nick Hawes*

Main category: cs.AI

TL;DR: 本文提出了确定性分布式部分可观测马尔可夫决策过程（Det-Dec-POMDPs）模型，并设计了一种可处理大规模问题的迭代求解算法IDPP。


<details>
  <summary>Details</summary>
Motivation: 多机器人导航等高级多代理规划问题通常可以通过确定性动作和观测来有效模型，但现有的Dec-POMDP求解器在处理大规模问题时效率不高。

Method: 提出了一种叫迭代确定性POMDP规划（IDPP）的方法，该方法基于经典的联合均衡搜索策略框架，并专门为处理大规模Det-Dec-POMDP问题进行了优化。

Result: IDPP算法能够有效处理当前Dec-POMDP求解器无法高效处理的大规模Det-Dec-POMDP问题。

Conclusion: 该研究为确定性多代理规划问题提供了一种实用的解决方案，IDPP算法在处理大规模问题时显示出了良好的性能。

Abstract: Many high-level multi-agent planning problems, including multi-robot
navigation and path planning, can be effectively modeled using deterministic
actions and observations.
  In this work, we focus on such domains and introduce the class of
Deterministic Decentralized POMDPs (Det-Dec-POMDPs). This is a subclass of
Dec-POMDPs characterized by deterministic transitions and observations
conditioned on the state and joint actions.
  We then propose a practical solver called Iterative Deterministic POMDP
Planning (IDPP). This method builds on the classic Joint Equilibrium Search for
Policies framework and is specifically optimized to handle large-scale
Det-Dec-POMDPs that current Dec-POMDP solvers are unable to address
efficiently.

</details>


### [43] [Integrating Large Language Models with Network Optimization for Interactive and Explainable Supply Chain Planning: A Real-World Case Study](https://arxiv.org/abs/2508.21622)
*Saravanan Venkatachalam*

Main category: cs.AI

TL;DR: 整合网络优化模型与大语言模型的交互式供应链规划决策支持系统，提供可解释性和角色感知的决策帮助。


<details>
  <summary>Details</summary>
Motivation: 缩小操作研究输出与业务利益相关者理解之间的差距，通过自然语言摘要、上下文可视化和定制KPI提升决策可访问性。

Method: 采用混合整数规划模型处理多周期多物品的战术性库存重新分配，通过AI代理、RESTful API和动态用户界面支持实时交互和模拟分析。

Result: 案例研究证明系统能够防止缺货、降低成本并维持服务水平，改善规划效果。

Conclusion: 未来将集成私有LLM、迁移学习、强化学习和贝叶斯神经网络以提升可解释性、适应性和实时决策能力。

Abstract: This paper presents an integrated framework that combines traditional network
optimization models with large language models (LLMs) to deliver interactive,
explainable, and role-aware decision support for supply chain planning. The
proposed system bridges the gap between complex operations research outputs and
business stakeholder understanding by generating natural language summaries,
contextual visualizations, and tailored key performance indicators (KPIs). The
core optimization model addresses tactical inventory redistribution across a
network of distribution centers for multi-period and multi-item, using a
mixed-integer formulation. The technical architecture incorporates AI agents,
RESTful APIs, and a dynamic user interface to support real-time interaction,
configuration updates, and simulation-based insights. A case study demonstrates
how the system improves planning outcomes by preventing stockouts, reducing
costs, and maintaining service levels. Future extensions include integrating
private LLMs, transfer learning, reinforcement learning, and Bayesian neural
networks to enhance explainability, adaptability, and real-time
decision-making.

</details>


### [44] [A-MHA*: Anytime Multi-Heuristic A*](https://arxiv.org/abs/2508.21637)
*Ramkumar Natarajan,Muhammad Suhail Saleem,William Xiao,Sandip Aine,Howie Choset,Maxim Likhachev*

Main category: cs.AI

TL;DR: 将多启发式A*（MHA*）扩展为随时算法A-MHA*，能够快速找到可行解并持续改进，同时保持最优性保证


<details>
  <summary>Details</summary>
Motivation: MHA*虽然能利用多个不可采纳启发式函数加速搜索，但只能一次性求解且需要仔细设置膨胀因子，无法随时间持续改进解的质量

Method: 受ARA*算法启发，将ARA*的概念精确适配到MHA*框架中，开发出随时版本A-MHA*

Result: A-MHA*在3D路径规划和滑块拼图领域表现出色，相比MHA*和其他随时算法具有更好性能

Conclusion: A-MHA*成功扩展了MHA*为随时算法，保持了原有的次优性和完备性保证，并能持续改进解质量

Abstract: Designing good heuristic functions for graph search requires adequate domain
knowledge. It is often easy to design heuristics that perform well and
correlate with the underlying true cost-to-go values in certain parts of the
search space but these may not be admissible throughout the domain thereby
affecting the optimality guarantees of the search. Bounded suboptimal search
using several such partially good but inadmissible heuristics was developed in
Multi-Heuristic A* (MHA*). Although MHA* leverages multiple inadmissible
heuristics to potentially generate a faster suboptimal solution, the original
version does not improve the solution over time. It is a one shot algorithm
that requires careful setting of inflation factors to obtain a desired one time
solution. In this work, we tackle this issue by extending MHA* to an anytime
version that finds a feasible suboptimal solution quickly and continually
improves it until time runs out. Our work is inspired from the Anytime
Repairing A* (ARA*) algorithm. We prove that our precise adaptation of ARA*
concepts in the MHA* framework preserves the original suboptimal and
completeness guarantees and enhances MHA* to perform in an anytime fashion.
Furthermore, we report the performance of A-MHA* in 3-D path planning domain
and sliding tiles puzzle and compare against MHA* and other anytime algorithms.

</details>


### [45] [Leveraging Imperfection with MEDLEY A Multi-Model Approach Harnessing Bias in Medical AI](https://arxiv.org/abs/2508.21648)
*Farhad Abtahi,Mehdi Astaraki,Fernando Seoane*

Main category: cs.AI

TL;DR: MEDLEY框架通过保留多个AI模型的多样性输出而非达成共识，将AI偏见视为潜在优势，为医疗AI系统提供新的监管和伦理路径


<details>
  <summary>Details</summary>
Motivation: 传统方法将医疗AI中的偏见视为需要消除的缺陷，但人类推理本身就包含受教育、文化和经验影响的偏见，这些偏见可能具有价值

Method: 提出MEDLEY概念框架，协调多个AI模型并保留其多样性输出，将模型特定偏见记录为潜在优势，将幻觉视为供临床医生验证的临时假设

Result: 开发了概念验证演示器，使用30多个大型语言模型，在合成病例中保留共识和少数观点，使诊断不确定性和潜在偏见对临床监督透明

Conclusion: MEDLEY通过将AI不完美性重新定义为资源，提供了范式转变，为开发可信赖的医疗AI系统开辟了新的监管、伦理和创新途径

Abstract: Bias in medical artificial intelligence is conventionally viewed as a defect
requiring elimination. However, human reasoning inherently incorporates biases
shaped by education, culture, and experience, suggesting their presence may be
inevitable and potentially valuable. We propose MEDLEY (Medical Ensemble
Diagnostic system with Leveraged diversitY), a conceptual framework that
orchestrates multiple AI models while preserving their diverse outputs rather
than collapsing them into a consensus. Unlike traditional approaches that
suppress disagreement, MEDLEY documents model-specific biases as potential
strengths and treats hallucinations as provisional hypotheses for clinician
verification. A proof-of-concept demonstrator was developed using over 30 large
language models, creating a minimum viable product that preserved both
consensus and minority views in synthetic cases, making diagnostic uncertainty
and latent biases transparent for clinical oversight. While not yet a validated
clinical tool, the demonstration illustrates how structured diversity can
enhance medical reasoning under clinician supervision. By reframing AI
imperfection as a resource, MEDLEY offers a paradigm shift that opens new
regulatory, ethical, and innovation pathways for developing trustworthy medical
AI systems.

</details>


### [46] [PosterForest: Hierarchical Multi-Agent Collaboration for Scientific Poster Generation](https://arxiv.org/abs/2508.21720)
*Jiho Choi,Seojeong Park,Seongjong Song,Hyunjung Shim*

Main category: cs.AI

TL;DR: PosterForest是一个无需训练的科学海报生成框架，通过分层中间表示和多智能体协作，实现文本和视觉元素的语义整合与结构优化


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了科学文档的分层结构和文本视觉元素的语义整合，需要同时解决这两个挑战

Method: 引入Poster Tree分层中间表示，采用多智能体协作策略（内容摘要和布局规划智能体），通过迭代协调和相互反馈实现联合优化

Result: 在多个学术领域的实验中，方法在定性和定量评估上均优于现有基线，生成的海报质量最接近专家设计，信息保留、结构清晰度和用户偏好方面表现优异

Conclusion: PosterForest框架通过分层表示和多智能体协作，成功解决了科学海报生成中的结构和语义整合问题，实现了高质量的自动化海报生成

Abstract: We present a novel training-free framework, \textit{PosterForest}, for
automated scientific poster generation. Unlike prior approaches, which largely
neglect the hierarchical structure of scientific documents and the semantic
integration of textual and visual elements, our method addresses both
challenges directly. We introduce the \textit{Poster Tree}, a hierarchical
intermediate representation that jointly encodes document structure and
visual-textual relationships at multiple levels. Our framework employs a
multi-agent collaboration strategy, where agents specializing in content
summarization and layout planning iteratively coordinate and provide mutual
feedback. This approach enables the joint optimization of logical consistency,
content fidelity, and visual coherence. Extensive experiments on multiple
academic domains show that our method outperforms existing baselines in both
qualitative and quantitative evaluations. The resulting posters achieve quality
closest to expert-designed ground truth and deliver superior information
preservation, structural clarity, and user preference.

</details>


### [47] [Freeze and Conquer: Reusable Ansatz for Solving the Traveling Salesman Problem](https://arxiv.org/abs/2508.21730)
*Fabrizio Fagiolo,Nicolo' Vescera*

Main category: cs.AI

TL;DR: 提出了一种用于旅行商问题的变分量子算法，通过紧凑排列编码减少量子比特需求，采用优化-冻结-重用策略，在训练实例上优化电路结构后冻结并重用，仅需重新优化参数。


<details>
  <summary>Details</summary>
Motivation: 解决传统变分量子算法在旅行商问题中需要大量量子比特和每次测试都需要重新进行结构搜索的高成本问题，旨在实现NISQ设备上的快速部署。

Method: 使用紧凑排列编码减少量子比特需求；采用优化-冻结-重用策略：先在训练实例上用模拟退火优化电路结构，然后冻结结构，在新实例上仅重新优化电路参数。

Result: 在4-7个城市的40个随机对称实例上，4城市达到100%最优路径采样概率，5城市90%，6城市80%，7城市降至约20%，显示方法的可扩展性限制。

Conclusion: 该方法在中等规模问题上表现出强大的泛化能力，冻结Ansatz能显著减少求解时间而不降低解质量，但存在可扩展性限制，有望扩展到车辆路径和作业车间调度等更复杂问题。

Abstract: In this paper we present a variational algorithm for the Traveling Salesman
Problem (TSP) that combines (i) a compact encoding of permutations, which
reduces the qubit requirement too, (ii) an optimize-freeze-reuse strategy:
where the circuit topology (``Ansatz'') is first optimized on a training
instance by Simulated Annealing (SA), then ``frozen'' and re-used on novel
instances, limited to a rapid re-optimization of only the circuit parameters.
This pipeline eliminates costly structural research in testing, making the
procedure immediately implementable on NISQ hardware.
  On a set of $40$ randomly generated symmetric instances that span $4 - 7$
cities, the resulting Ansatz achieves an average optimal trip sampling
probability of $100\%$ for 4 city cases, $90\%$ for 5 city cases and $80\%$ for
6 city cases. With 7 cities the success rate drops markedly to an average of
$\sim 20\%$, revealing the onset of scalability limitations of the proposed
method.
  The results show robust generalization ability for moderate problem sizes and
indicate how freezing the Ansatz can dramatically reduce time-to-solution
without degrading solution quality. The paper also discusses scalability
limitations, the impact of ``warm-start'' initialization of parameters, and
prospects for extension to more complex problems, such as Vehicle Routing and
Job-Shop Scheduling.

</details>


### [48] [Orientability of Causal Relations in Time Series using Summary Causal Graphs and Faithful Distributions](https://arxiv.org/abs/2508.21742)
*Timothée Loranchet,Charles K. Assaad*

Main category: cs.AI

TL;DR: 本文提出了在给定摘要因果图背景知识的情况下，保证时间变量间微观层面边定向的理论条件，为复杂时间系统中的因果发现提供理论保证。


<details>
  <summary>Details</summary>
Motivation: 时间序列分析中理解时间变量间的因果关系是一个核心挑战，特别是在完整因果结构未知的情况下。专家通常能够提供摘要因果图来捕捉主要因果关系，但如何利用这种高层抽象来指导微观层面的因果发现需要理论支持。

Method: 提出了在假设存在忠实且因果充分的分布条件下，给定摘要因果图背景知识，保证微观层面时间变量间边定向的理论条件。这些条件即使在宏观层面存在循环或双向边的情况下也适用。

Result: 建立了微观层面边定向的理论保证条件，证明了在摘要因果图的指导下，即使宏观层面存在复杂结构，也能可靠地进行微观层面的因果推断。

Conclusion: 研究结果为利用专家知识提供的摘要因果图来改进从观测时间序列数据中进行因果推断提供了实用指导，强调了将专家知识融入复杂时间系统因果发现的价值。

Abstract: Understanding causal relations between temporal variables is a central
challenge in time series analysis, particularly when the full causal structure
is unknown. Even when the full causal structure cannot be fully specified,
experts often succeed in providing a high-level abstraction of the causal
graph, known as a summary causal graph, which captures the main causal
relations between different time series while abstracting away micro-level
details. In this work, we present conditions that guarantee the orientability
of micro-level edges between temporal variables given the background knowledge
encoded in a summary causal graph and assuming having access to a faithful and
causally sufficient distribution with respect to the true unknown graph. Our
results provide theoretical guarantees for edge orientation at the micro-level,
even in the presence of cycles or bidirected edges at the macro-level. These
findings offer practical guidance for leveraging SCGs to inform causal
discovery in complex temporal systems and highlight the value of incorporating
expert knowledge to improve causal inference from observational time series
data.

</details>


### [49] [Tree-Guided Diffusion Planner](https://arxiv.org/abs/2508.21800)
*Hyeonseong Jeon,Cheolhong Min,Jaesik Park*

Main category: cs.AI

TL;DR: 提出Tree-guided Diffusion Planner (TDP)，一种零样本测试时规划框架，通过树搜索和双层采样过程解决扩散模型在非凸、不可微和多奖励场景下的规划问题，在多个任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的规划方法在凸可微奖励场景下表现良好，但在现实世界的非凸目标、不可微约束和多奖励结构中效果显著下降。同时，有监督规划方法需要任务特定训练或价值估计器，限制了测试时灵活性和零样本泛化能力。

Method: TDP将测试时规划构建为树搜索问题，采用双层采样过程：1) 通过无训练粒子引导生成多样化父轨迹以促进广泛探索；2) 通过任务目标引导的快速条件去噪精炼子轨迹。仅使用预训练模型和测试时奖励信号。

Result: 在三个多样化任务上评估：迷宫金币收集、机械臂方块操作和AntMaze多目标探索。TDP在所有任务上一致优于最先进方法。

Conclusion: TDP通过树引导的扩散规划有效解决了梯度引导在复杂现实场景中的局限性，实现了更好的探索-利用平衡，展示了在零样本测试时规划中的优越性能。

Abstract: Planning with pretrained diffusion models has emerged as a promising approach
for solving test-time guided control problems. However, standard gradient
guidance typically performs optimally under convex and differentiable reward
landscapes, showing substantially reduced effectiveness in real-world scenarios
involving non-convex objectives, non-differentiable constraints, and
multi-reward structures. Furthermore, recent supervised planning approaches
require task-specific training or value estimators, which limits test-time
flexibility and zero-shot generalization. We propose a Tree-guided Diffusion
Planner (TDP), a zero-shot test-time planning framework that balances
exploration and exploitation through structured trajectory generation. We frame
test-time planning as a tree search problem using a bi-level sampling process:
(1) diverse parent trajectories are produced via training-free particle
guidance to encourage broad exploration, and (2) sub-trajectories are refined
through fast conditional denoising guided by task objectives. TDP addresses the
limitations of gradient guidance by exploring diverse trajectory regions and
harnessing gradient information across this expanded solution space using only
pretrained models and test-time reward signals. We evaluate TDP on three
diverse tasks: maze gold-picking, robot arm block manipulation, and AntMaze
multi-goal exploration. TDP consistently outperforms state-of-the-art
approaches on all tasks. The project page can be found at:
tree-diffusion-planner.github.io.

</details>


### [50] [Automated Clinical Problem Detection from SOAP Notes using a Collaborative Multi-Agent LLM Architecture](https://arxiv.org/abs/2508.21803)
*Yeawon Lee,Xiaoyang Wang,Christopher C. Yang*

Main category: cs.AI

TL;DR: 使用多治理系统模拟临床会议团队，通过层次迭代辩论提升了临床问题识别的准确性和稳健性


<details>
  <summary>Details</summary>
Motivation: 临床文档解释对患者护理至关重要，但单一模型缺乏高风险临床任务所需的稳健性，需要更准确、可解释的临床决策支持工具

Method: 设计了协作式多治理系统(MAS)，模拟临床会议团队。Manager治理协调动态指派的专科治理团队，进行层次迭代辩论达成共识，分析SOAP记录中的S和O部分来识别临床问题

Result: 在420份MIMIC-III记录的港理数据集上评估，动态多治理配置在识别心力衰经、急性肾伤伤和感染性伤等疾病方面表现一致提升，辩论结构能有效表面并重新相互冲突证据

Conclusion: 通过模拟临床团队的推理过程，该系统为开发更准确、稳健和可解释的临床决策支持工具提供了有前途的路径

Abstract: Accurate interpretation of clinical narratives is critical for patient care,
but the complexity of these notes makes automation challenging. While Large
Language Models (LLMs) show promise, single-model approaches can lack the
robustness required for high-stakes clinical tasks. We introduce a
collaborative multi-agent system (MAS) that models a clinical consultation team
to address this gap. The system is tasked with identifying clinical problems by
analyzing only the Subjective (S) and Objective (O) sections of SOAP notes,
simulating the diagnostic reasoning process of synthesizing raw data into an
assessment. A Manager agent orchestrates a dynamically assigned team of
specialist agents who engage in a hierarchical, iterative debate to reach a
consensus. We evaluated our MAS against a single-agent baseline on a curated
dataset of 420 MIMIC-III notes. The dynamic multi-agent configuration
demonstrated consistently improved performance in identifying congestive heart
failure, acute kidney injury, and sepsis. Qualitative analysis of the agent
debates reveals that this structure effectively surfaces and weighs conflicting
evidence, though it can occasionally be susceptible to groupthink. By modeling
a clinical team's reasoning process, our system offers a promising path toward
more accurate, robust, and interpretable clinical decision support tools.

</details>
