{"id": "2509.09706", "categories": ["cs.CR", "cs.AI", "cs.CL", "I.2; H.3.3"], "pdf": "https://arxiv.org/pdf/2509.09706", "abs": "https://arxiv.org/abs/2509.09706", "authors": ["Taniya Gidatkar", "Oluwaseun Ajao", "Matthew Shardlow"], "title": "Differential Robustness in Transformer Language Models: Empirical Evaluation Under Adversarial Text Attacks", "comment": "8 pages, 4 tables, to appear in proceedings of Recent Advances in\n  Natural Language Processing (RANLP 2025) and ACL Anthology", "summary": "This study evaluates the resilience of large language models (LLMs) against\nadversarial attacks, specifically focusing on Flan-T5, BERT, and RoBERTa-Base.\nUsing systematically designed adversarial tests through TextFooler and\nBERTAttack, we found significant variations in model robustness. RoBERTa-Base\nand FlanT5 demonstrated remarkable resilience, maintaining accuracy even when\nsubjected to sophisticated attacks, with attack success rates of 0%. In\ncontrast. BERT-Base showed considerable vulnerability, with TextFooler\nachieving a 93.75% success rate in reducing model accuracy from 48% to just 3%.\nOur research reveals that while certain LLMs have developed effective defensive\nmechanisms, these safeguards often require substantial computational resources.\nThis study contributes to the understanding of LLM security by identifying\nexisting strengths and weaknesses in current safeguarding approaches and\nproposes practical recommendations for developing more efficient and effective\ndefensive strategies.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86Flan-T5\u3001BERT\u548cRoBERTa-Base\u7b49\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u6297\u5bf9\u6297\u6027\u653b\u51fb\u7684\u97e7\u6027\uff0c\u53d1\u73b0RoBERTa-Base\u548cFlanT5\u8868\u73b0\u51fa\u8272\uff08\u653b\u51fb\u6210\u529f\u73870%\uff09\uff0c\u800cBERT-Base\u5b58\u5728\u663e\u8457\u6f0f\u6d1e\uff08TextFooler\u653b\u51fb\u6210\u529f\u738793.75%\uff09\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5bf9\u6297\u6027\u653b\u51fb\u4e0b\u7684\u5b89\u5168\u6027\u548c\u97e7\u6027\uff0c\u8bc6\u522b\u73b0\u6709\u9632\u62a4\u673a\u5236\u7684\u4f18\u7f3a\u70b9\uff0c\u4e3a\u5f00\u53d1\u66f4\u6709\u6548\u7684\u9632\u5fa1\u7b56\u7565\u63d0\u4f9b\u4f9d\u636e\u3002", "method": "\u4f7f\u7528TextFooler\u548cBERTAttack\u7cfb\u7edf\u8bbe\u8ba1\u5bf9\u6297\u6027\u6d4b\u8bd5\uff0c\u5bf9Flan-T5\u3001BERT\u548cRoBERTa-Base\u6a21\u578b\u8fdb\u884c\u653b\u51fb\u6d4b\u8bd5\uff0c\u6bd4\u8f83\u4e0d\u540c\u6a21\u578b\u7684\u9c81\u68d2\u6027\u8868\u73b0\u3002", "result": "RoBERTa-Base\u548cFlanT5\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u97e7\u6027\uff0c\u653b\u51fb\u6210\u529f\u7387\u4e3a0%\uff1bBERT-Base\u51c6\u786e\u7387\u4ece48%\u964d\u81f33%\uff0cTextFooler\u653b\u51fb\u6210\u529f\u7387\u8fbe93.75%\u3002", "conclusion": "\u67d0\u4e9bLLMs\u5df2\u5177\u5907\u6709\u6548\u9632\u5fa1\u673a\u5236\u4f46\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u9ad8\uff0c\u7814\u7a76\u4e3aLLM\u5b89\u5168\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\uff0c\u5e76\u63d0\u51fa\u4e86\u5f00\u53d1\u66f4\u9ad8\u6548\u9632\u5fa1\u7b56\u7565\u7684\u5b9e\u7528\u5efa\u8bae\u3002"}}
{"id": "2509.09787", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09787", "abs": "https://arxiv.org/abs/2509.09787", "authors": ["Nojan Sheybani", "Alessandro Pegoraro", "Jonathan Knauer", "Phillip Rieger", "Elissa Mollakuqe", "Farinaz Koushanfar", "Ahmad-Reza Sadeghi"], "title": "ZORRO: Zero-Knowledge Robustness and Privacy for Split Learning (Full Version)", "comment": "Full version of CCS 2025 paper", "summary": "Split Learning (SL) is a distributed learning approach that enables\nresource-constrained clients to collaboratively train deep neural networks\n(DNNs) by offloading most layers to a central server while keeping in- and\noutput layers on the client-side. This setup enables SL to leverage server\ncomputation capacities without sharing data, making it highly effective in\nresource-constrained environments dealing with sensitive data. However, the\ndistributed nature enables malicious clients to manipulate the training\nprocess. By sending poisoned intermediate gradients, they can inject backdoors\ninto the shared DNN. Existing defenses are limited by often focusing on\nserver-side protection and introducing additional overhead for the server. A\nsignificant challenge for client-side defenses is enforcing malicious clients\nto correctly execute the defense algorithm.\n  We present ZORRO, a private, verifiable, and robust SL defense scheme.\nThrough our novel design and application of interactive zero-knowledge proofs\n(ZKPs), clients prove their correct execution of a client-located defense\nalgorithm, resulting in proofs of computational integrity attesting to the\nbenign nature of locally trained DNN portions. Leveraging the frequency\nrepresentation of model partitions enables ZORRO to conduct an in-depth\ninspection of the locally trained models in an untrusted environment, ensuring\nthat each client forwards a benign checkpoint to its succeeding client. In our\nextensive evaluation, covering different model architectures as well as various\nattack strategies and data scenarios, we show ZORRO's effectiveness, as it\nreduces the attack success rate to less than 6\\% while causing even for models\nstoring \\numprint{1000000} parameters on the client-side an overhead of less\nthan 10 seconds.", "AI": {"tldr": "ZORRO\u662f\u4e00\u79cd\u57fa\u4e8e\u96f6\u77e5\u8bc6\u8bc1\u660e\u7684\u5206\u5272\u5b66\u4e60\u9632\u5fa1\u65b9\u6848\uff0c\u53ef\u9a8c\u8bc1\u5ba2\u6237\u7aef\u6b63\u786e\u6267\u884c\u9632\u5fa1\u7b97\u6cd5\uff0c\u6709\u6548\u62b5\u5fa1\u6076\u610f\u5ba2\u6237\u7aef\u901a\u8fc7\u4e2d\u6bd2\u4e2d\u95f4\u68af\u5ea6\u6ce8\u5165\u540e\u95e8\u7684\u653b\u51fb\uff0c\u5c06\u653b\u51fb\u6210\u529f\u7387\u964d\u81f36%\u4ee5\u4e0b\uff0c\u4e14\u5ba2\u6237\u7aef\u5f00\u9500\u5c0f\u4e8e10\u79d2\u3002", "motivation": "\u5206\u5272\u5b66\u4e60\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u5904\u7406\u654f\u611f\u6570\u636e\u65f6\u5f88\u6709\u6548\uff0c\u4f46\u5206\u5e03\u5f0f\u7279\u6027\u4f7f\u6076\u610f\u5ba2\u6237\u7aef\u80fd\u591f\u901a\u8fc7\u53d1\u9001\u6709\u6bd2\u4e2d\u95f4\u68af\u5ea6\u6765\u64cd\u7eb5\u8bad\u7ec3\u8fc7\u7a0b\u5e76\u6ce8\u5165\u540e\u95e8\u3002\u73b0\u6709\u9632\u5fa1\u65b9\u6848\u4e3b\u8981\u5173\u6ce8\u670d\u52a1\u5668\u7aef\u4fdd\u62a4\u4e14\u5f15\u5165\u989d\u5916\u5f00\u9500\uff0c\u5ba2\u6237\u7aef\u9632\u5fa1\u9762\u4e34\u786e\u4fdd\u6076\u610f\u5ba2\u6237\u7aef\u6b63\u786e\u6267\u884c\u9632\u5fa1\u7b97\u6cd5\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faZORRO\u65b9\u6848\uff0c\u91c7\u7528\u4ea4\u4e92\u5f0f\u96f6\u77e5\u8bc6\u8bc1\u660e(ZKPs)\uff0c\u5ba2\u6237\u7aef\u8bc1\u660e\u5176\u6b63\u786e\u6267\u884c\u5ba2\u6237\u7aef\u9632\u5fa1\u7b97\u6cd5\uff0c\u751f\u6210\u8ba1\u7b97\u5b8c\u6574\u6027\u8bc1\u660e\u3002\u5229\u7528\u6a21\u578b\u5206\u533a\u7684\u9891\u7387\u8868\u793a\uff0c\u5728\u4e0d\u53ef\u4fe1\u73af\u5883\u4e2d\u6df1\u5ea6\u68c0\u67e5\u672c\u5730\u8bad\u7ec3\u6a21\u578b\uff0c\u786e\u4fdd\u6bcf\u4e2a\u5ba2\u6237\u7aef\u5411\u524d\u4f20\u9012\u826f\u6027\u68c0\u67e5\u70b9\u3002", "result": "\u5728\u6db5\u76d6\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u3001\u653b\u51fb\u7b56\u7565\u548c\u6570\u636e\u573a\u666f\u7684\u5e7f\u6cdb\u8bc4\u4f30\u4e2d\uff0cZORRO\u5c06\u653b\u51fb\u6210\u529f\u7387\u964d\u4f4e\u81f36%\u4ee5\u4e0b\uff0c\u5373\u4f7f\u5bf9\u4e8e\u5ba2\u6237\u7aef\u5b58\u50a8100\u4e07\u4e2a\u53c2\u6570\u7684\u6a21\u578b\uff0c\u5f00\u9500\u4e5f\u5c0f\u4e8e10\u79d2\u3002", "conclusion": "ZORRO\u63d0\u4f9b\u4e86\u4e00\u79cd\u79c1\u6709\u3001\u53ef\u9a8c\u8bc1\u4e14\u9c81\u68d2\u7684\u5206\u5272\u5b66\u4e60\u9632\u5fa1\u65b9\u6848\uff0c\u901a\u8fc7\u96f6\u77e5\u8bc6\u8bc1\u660e\u6709\u6548\u89e3\u51b3\u5ba2\u6237\u7aef\u9632\u5fa1\u7684\u6267\u884c\u9a8c\u8bc1\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u4f4e\u5f00\u9500\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u5b89\u5168\u6027\u3002"}}
{"id": "2509.09942", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.09942", "abs": "https://arxiv.org/abs/2509.09942", "authors": ["Lei Yu", "Jingyuan Zhang", "Xin Wang", "Jiajia Ma", "Li Yang", "Fengjun Zhang"], "title": "SmartCoder-R1: Towards Secure and Explainable Smart Contract Generation with Security-Aware Group Relative Policy Optimization", "comment": null, "summary": "Smart contracts automate the management of high-value assets, where\nvulnerabilities can lead to catastrophic financial losses. This challenge is\namplified in Large Language Models (LLMs) by two interconnected failures: they\noperate as unauditable \"black boxes\" lacking a transparent reasoning process,\nand consequently, generate code riddled with critical security vulnerabilities.\nTo address both issues, we propose SmartCoder-R1 (based on Qwen2.5-Coder-7B), a\nnovel framework for secure and explainable smart contract generation. It begins\nwith Continual Pre-training (CPT) to specialize the model. We then apply Long\nChain-of-Thought Supervised Fine-Tuning (L-CoT SFT) on 7,998 expert-validated\nreasoning-and-code samples to train the model to emulate human security\nanalysis. Finally, to directly mitigate vulnerabilities, we employ\nSecurity-Aware Group Relative Policy Optimization (S-GRPO), a reinforcement\nlearning phase that refines the generation policy by optimizing a weighted\nreward signal for compilation success, security compliance, and format\ncorrectness. Evaluated against 17 baselines on a benchmark of 756 real-world\nfunctions, SmartCoder-R1 establishes a new state of the art, achieving top\nperformance across five key metrics: a ComPass of 87.70%, a VulRate of 8.60%, a\nSafeAval of 80.16%, a FuncRate of 53.84%, and a FullRate of 50.53%. This\nFullRate marks a 45.79% relative improvement over the strongest baseline,\nDeepSeek-R1. Crucially, its generated reasoning also excels in human\nevaluations, achieving high-quality ratings for Functionality (82.7%), Security\n(85.3%), and Clarity (90.7%).", "AI": {"tldr": "SmartCoder-R1\u662f\u4e00\u4e2a\u57fa\u4e8eQwen2.5-Coder-7B\u7684\u65b0\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u6301\u7eed\u9884\u8bad\u7ec3\u3001\u957f\u601d\u7ef4\u94fe\u76d1\u7763\u5fae\u8c03\u548c\u5b89\u5168\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\uff0c\u5b9e\u73b0\u4e86\u5b89\u5168\u4e14\u53ef\u89e3\u91ca\u7684\u667a\u80fd\u5408\u7ea6\u751f\u6210\uff0c\u5728\u591a\u4e2a\u5173\u952e\u6307\u6807\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3LLM\u5728\u667a\u80fd\u5408\u7ea6\u751f\u6210\u4e2d\u7684\u4e24\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u4f5c\u4e3a\u4e0d\u53ef\u5ba1\u8ba1\u7684\"\u9ed1\u76d2\"\u7f3a\u4e4f\u900f\u660e\u63a8\u7406\u8fc7\u7a0b\uff0c\u4ee5\u53ca\u751f\u6210\u7684\u4ee3\u7801\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\u3002\u667a\u80fd\u5408\u7ea6\u7ba1\u7406\u9ad8\u4ef7\u503c\u8d44\u4ea7\uff0c\u6f0f\u6d1e\u53ef\u80fd\u5bfc\u81f4\u707e\u96be\u6027\u8d22\u52a1\u635f\u5931\u3002", "method": "1) \u6301\u7eed\u9884\u8bad\u7ec3(CPT)\u8fdb\u884c\u6a21\u578b\u4e13\u4e1a\u5316\uff1b2) \u57287,998\u4e2a\u4e13\u5bb6\u9a8c\u8bc1\u7684\u63a8\u7406-\u4ee3\u7801\u6837\u672c\u4e0a\u8fdb\u884c\u957f\u601d\u7ef4\u94fe\u76d1\u7763\u5fae\u8c03(L-CoT SFT)\uff1b3) \u4f7f\u7528\u5b89\u5168\u611f\u77e5\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316(S-GRPO)\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\uff0c\u4f18\u5316\u7f16\u8bd1\u6210\u529f\u3001\u5b89\u5168\u5408\u89c4\u548c\u683c\u5f0f\u6b63\u786e\u7684\u52a0\u6743\u5956\u52b1\u4fe1\u53f7\u3002", "result": "\u5728756\u4e2a\u771f\u5b9e\u4e16\u754c\u51fd\u6570\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSmartCoder-R1\u572817\u4e2a\u57fa\u7ebf\u6a21\u578b\u4e2d\u8fbe\u5230\u6700\u4f18\uff1aComPass 87.70%\u3001VulRate 8.60%\u3001SafeAval 80.16%\u3001FuncRate 53.84%\u3001FullRate 50.53%\uff08\u6bd4\u6700\u5f3a\u57fa\u7ebfDeepSeek-R1\u63d0\u534745.79%\uff09\u3002\u751f\u6210\u63a8\u7406\u5728\u4eba\u5de5\u8bc4\u4f30\u4e2d\u4e5f\u8868\u73b0\u4f18\u5f02\uff1a\u529f\u80fd\u602782.7%\u3001\u5b89\u5168\u602785.3%\u3001\u6e05\u6670\u5ea690.7%\u3002", "conclusion": "SmartCoder-R1\u901a\u8fc7\u7ed3\u5408\u4e13\u4e1a\u5316\u9884\u8bad\u7ec3\u3001\u601d\u7ef4\u94fe\u5fae\u8c03\u548c\u5b89\u5168\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\uff0c\u6210\u529f\u89e3\u51b3\u4e86LLM\u5728\u667a\u80fd\u5408\u7ea6\u751f\u6210\u4e2d\u7684\u53ef\u89e3\u91ca\u6027\u548c\u5b89\u5168\u6027\u95ee\u9898\uff0c\u5efa\u7acb\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u4e3a\u5b89\u5168\u53ef\u9760\u7684\u667a\u80fd\u5408\u7ea6\u5f00\u53d1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.09853", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09853", "abs": "https://arxiv.org/abs/2509.09853", "authors": ["Zhiyu Fan", "Kirill Vasilevski", "Dayi Lin", "Boyuan Chen", "Yihao Chen", "Zhiqing Zhong", "Jie M. Zhang", "Pinjia He", "Ahmed E. Hassan"], "title": "SWE-Effi: Re-Evaluating Software AI Agent System Effectiveness Under Resource Constraints", "comment": null, "summary": "The advancement of large language models (LLMs) and code agents has\ndemonstrated significant potential to assist software engineering (SWE) tasks,\nsuch as autonomous issue resolution and feature addition. Existing AI for\nsoftware engineering leaderboards (e.g., SWE-bench) focus solely on solution\naccuracy, ignoring the crucial factor of effectiveness in a\nresource-constrained world. This is a universal problem that also exists beyond\nsoftware engineering tasks: any AI system should be more than correct - it must\nalso be cost-effective. To address this gap, we introduce SWE-Effi, a set of\nnew metrics to re-evaluate AI systems in terms of holistic effectiveness\nscores. We define effectiveness as the balance between the accuracy of outcome\n(e.g., issue resolve rate) and the resources consumed (e.g., token and time).\nIn this paper, we specifically focus on the software engineering scenario by\nre-ranking popular AI systems for issue resolution on a subset of the SWE-bench\nbenchmark using our new multi-dimensional metrics. We found that AI system's\neffectiveness depends not just on the scaffold itself, but on how well it\nintegrates with the base model, which is key to achieving strong performance in\na resource-efficient manner. We also identified systematic challenges such as\nthe \"token snowball\" effect and, more significantly, a pattern of \"expensive\nfailures\". In these cases, agents consume excessive resources while stuck on\nunsolvable tasks - an issue that not only limits practical deployment but also\ndrives up the cost of failed rollouts during RL training. Lastly, we observed a\nclear trade-off between effectiveness under the token budget and effectiveness\nunder the time budget, which plays a crucial role in managing project budgets\nand enabling scalable reinforcement learning, where fast responses are\nessential.", "AI": {"tldr": "SWE-Effi\u662f\u4e00\u4e2a\u65b0\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u7efc\u5408\u8003\u8651\u51c6\u786e\u6027\u548c\u8d44\u6e90\u6d88\u8017\uff08token\u548c\u65f6\u95f4\uff09\u6765\u91cd\u65b0\u8bc4\u4f30AI\u7cfb\u7edf\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u6574\u4f53\u6548\u80fd\uff0c\u53d1\u73b0\u6a21\u578b\u96c6\u6210\u6548\u679c\u3001token\u96ea\u7403\u6548\u5e94\u548c\u6602\u8d35\u5931\u8d25\u6a21\u5f0f\u662f\u5f71\u54cd\u6548\u80fd\u7684\u5173\u952e\u56e0\u7d20\u3002", "motivation": "\u73b0\u6709AI\u8f6f\u4ef6\u5de5\u7a0b\u6392\u884c\u699c\uff08\u5982SWE-bench\uff09\u4ec5\u5173\u6ce8\u89e3\u51b3\u65b9\u6848\u51c6\u786e\u6027\uff0c\u5ffd\u7565\u4e86\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u6548\u80fd\u95ee\u9898\u3002\u4efb\u4f55AI\u7cfb\u7edf\u4e0d\u4ec5\u9700\u8981\u6b63\u786e\uff0c\u8fd8\u5fc5\u987b\u5177\u5907\u6210\u672c\u6548\u76ca\u3002", "method": "\u63d0\u51faSWE-Effi\u591a\u7ef4\u5ea6\u91cf\u6807\u51c6\uff0c\u5728SWE-bench\u57fa\u51c6\u7684\u5b50\u96c6\u4e0a\u91cd\u65b0\u8bc4\u4f30\u6d41\u884c\u7684AI\u95ee\u9898\u89e3\u51b3\u7cfb\u7edf\uff0c\u7efc\u5408\u8003\u8651\u7ed3\u679c\u51c6\u786e\u6027\u548c\u8d44\u6e90\u6d88\u8017\uff08token\u548c\u65f6\u95f4\uff09\u7684\u5e73\u8861\u3002", "result": "\u53d1\u73b0AI\u7cfb\u7edf\u6548\u80fd\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u6846\u67b6\u672c\u8eab\uff0c\u8fd8\u53d6\u51b3\u4e8e\u4e0e\u57fa\u7840\u6a21\u578b\u7684\u96c6\u6210\u6548\u679c\uff1b\u8bc6\u522b\u51fa\u7cfb\u7edf\u6027\u6311\u6218\u5305\u62ec\"token\u96ea\u7403\"\u6548\u5e94\u548c\"\u6602\u8d35\u5931\u8d25\"\u6a21\u5f0f\uff1b\u89c2\u5bdf\u5230token\u9884\u7b97\u548c\u65f6\u95f4\u9884\u7b97\u4e0b\u7684\u6548\u80fd\u5b58\u5728\u660e\u663e\u6743\u8861\u3002", "conclusion": "\u9700\u8981\u7efc\u5408\u8003\u8651\u51c6\u786e\u6027\u548c\u8d44\u6e90\u6d88\u8017\u6765\u8bc4\u4f30AI\u7cfb\u7edf\u6548\u80fd\uff0c\u6a21\u578b\u96c6\u6210\u8d28\u91cf\u662f\u5173\u952e\u56e0\u7d20\uff0c\u8d44\u6e90\u6548\u7387\u5bf9\u4e8e\u5b9e\u9645\u90e8\u7f72\u548c\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684\u53ef\u6269\u5c55\u6027\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2509.09950", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.09950", "abs": "https://arxiv.org/abs/2509.09950", "authors": ["Pouneh Nikkhah Bahrami", "Dylan Cutler", "Igor Bilogrevic"], "title": "Byte by Byte: Unmasking Browser Fingerprinting at the Function Level Using V8 Bytecode Transformers", "comment": null, "summary": "Browser fingerprinting enables persistent cross-site user tracking via subtle\ntechniques that often evade conventional defenses or cause website breakage\nwhen script-level blocking countermeasures are applied. Addressing these\nchallenges requires detection methods offering both function-level precision to\nminimize breakage and inherent robustness against code obfuscation and URL\nmanipulation.\n  We introduce ByteDefender, the first system leveraging V8 engine bytecode to\ndetect fingerprinting operations specifically at the JavaScript function level.\nA Transformer-based classifier, trained offline on bytecode sequences,\naccurately identifies functions exhibiting fingerprinting behavior. We develop\nand evaluate light-weight signatures derived from this model to enable\nlow-overhead, on-device matching against function bytecode during compilation\nbut prior to execution, which only adds a 4% (average) latency to the page load\ntime. This mechanism facilitates targeted, real-time prevention of\nfingerprinting function execution, thereby preserving legitimate script\nfunctionality. Operating directly on bytecode ensures inherent resilience\nagainst common code obfuscation and URL-based evasion. Our evaluation on the\ntop 100k websites demonstrates high detection accuracy at both function- and\nscript-level, with substantial improvements over state-of-the-art AST-based\nmethods, particularly in robustness against obfuscation. ByteDefender offers a\npractical framework for effective, precise, and robust fingerprinting\nmitigation.", "AI": {"tldr": "ByteDefender\u662f\u4e00\u4e2a\u57fa\u4e8eV8\u5f15\u64ce\u5b57\u8282\u7801\u7684\u6307\u7eb9\u68c0\u6d4b\u7cfb\u7edf\uff0c\u4f7f\u7528Transformer\u5206\u7c7b\u5668\u5728\u51fd\u6570\u7ea7\u522b\u7cbe\u51c6\u68c0\u6d4b\u6307\u7eb9\u64cd\u4f5c\uff0c\u5728\u7f16\u8bd1\u9636\u6bb5\u5b9e\u65f6\u963b\u6b62\u6076\u610f\u51fd\u6570\u6267\u884c\uff0c\u540c\u65f6\u4fdd\u6301\u6b63\u5e38\u811a\u672c\u529f\u80fd\u3002", "motivation": "\u4f20\u7edf\u6307\u7eb9\u68c0\u6d4b\u65b9\u6cd5\u8981\u4e48\u7cbe\u5ea6\u4e0d\u8db3\u5bfc\u81f4\u7f51\u7ad9\u529f\u80fd\u7834\u574f\uff0c\u8981\u4e48\u5bb9\u6613\u88ab\u4ee3\u7801\u6df7\u6dc6\u548cURL\u64cd\u4f5c\u7ed5\u8fc7\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u7cbe\u786e\u53c8\u9c81\u68d2\u7684\u68c0\u6d4b\u65b9\u6848\u3002", "method": "\u5229\u7528V8\u5f15\u64ce\u5b57\u8282\u7801\uff0c\u8bad\u7ec3Transformer\u5206\u7c7b\u5668\u79bb\u7ebf\u8bc6\u522b\u6307\u7eb9\u51fd\u6570\uff0c\u751f\u6210\u8f7b\u91cf\u7ea7\u7b7e\u540d\u7528\u4e8e\u8bbe\u5907\u7aef\u5b9e\u65f6\u5339\u914d\uff0c\u5728\u7f16\u8bd1\u9636\u6bb5\u4f46\u6267\u884c\u524d\u8fdb\u884c\u68c0\u6d4b\u3002", "result": "\u5728top 10\u4e07\u7f51\u7ad9\u8bc4\u4f30\u4e2d\u663e\u793a\u51fa\u9ad8\u68c0\u6d4b\u7cbe\u5ea6\uff0c\u5e73\u5747\u4ec5\u589e\u52a04%\u9875\u9762\u52a0\u8f7d\u5ef6\u8fdf\uff0c\u76f8\u6bd4\u73b0\u6709AST\u65b9\u6cd5\u5728\u6297\u6df7\u6dc6\u80fd\u529b\u4e0a\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "ByteDefender\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u7cbe\u786e\u3001\u9c81\u68d2\u7684\u6307\u7eb9\u68c0\u6d4b\u548c\u7f13\u89e3\uff0c\u5728\u4fdd\u6301\u7f51\u7ad9\u529f\u80fd\u5b8c\u6574\u6027\u7684\u540c\u65f6\u6709\u6548\u9632\u6b62\u7528\u6237\u8ddf\u8e2a\u3002"}}
{"id": "2509.09873", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09873", "abs": "https://arxiv.org/abs/2509.09873", "authors": ["James Jewitt", "Hao Li", "Bram Adams", "Gopi Krishnan Rajbahadur", "Ahmed E. Hassan"], "title": "From Hugging Face to GitHub: Tracing License Drift in the Open-Source AI Ecosystem", "comment": "9 pages, 4 figures, 5 tables, pre-print", "summary": "Hidden license conflicts in the open-source AI ecosystem pose serious legal\nand ethical risks, exposing organizations to potential litigation and users to\nundisclosed risk. However, the field lacks a data-driven understanding of how\nfrequently these conflicts occur, where they originate, and which communities\nare most affected. We present the first end-to-end audit of licenses for\ndatasets and models on Hugging Face, as well as their downstream integration\ninto open-source software applications, covering 364 thousand datasets, 1.6\nmillion models, and 140 thousand GitHub projects. Our empirical analysis\nreveals systemic non-compliance in which 35.5% of model-to-application\ntransitions eliminate restrictive license clauses by relicensing under\npermissive terms. In addition, we prototype an extensible rule engine that\nencodes almost 200 SPDX and model-specific clauses for detecting license\nconflicts, which can solve 86.4% of license conflicts in software applications.\nTo support future research, we release our dataset and the prototype engine.\nOur study highlights license compliance as a critical governance challenge in\nopen-source AI and provides both the data and tools necessary to enable\nautomated, AI-aware compliance at scale.", "AI": {"tldr": "\u9996\u4e2a\u5bf9Hugging Face\u6570\u636e\u96c6\u548c\u6a21\u578b\u8bb8\u53ef\u8bc1\u7684\u7ed3\u6784\u5316\u5ba1\u8ba1\uff0c\u53d1\u73b0\u5f00\u6e90AI\u751f\u6001\u4e2d\u5b58\u5728\u7cfb\u7edf\u6027\u8bb8\u53ef\u8bc1\u8fdd\u89c4\u95ee\u9898\uff0c35.5%\u6a21\u578b\u5230\u5e94\u7528\u7684\u8f6c\u6362\u4f1a\u6d88\u9664\u9650\u5236\u6027\u8bb8\u53ef\u8bc1\u6761\u6b3e", "motivation": "\u9690\u85cf\u7684\u5f00\u6e90\u8bb8\u53ef\u8bc1\u51b2\u7a81\u5e26\u6765\u4e25\u91cd\u6cd5\u5f8b\u548c\u9053\u5fb7\u98ce\u9669\uff0c\u4f46\u7f3a\u4e4f\u6570\u636e\u9a71\u52a8\u7684\u7406\u89e3\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5206\u6790\u8bb8\u53ef\u8bc1\u51b2\u7a81\u7684\u9891\u7387\u3001\u6765\u6e90\u548c\u5f71\u54cd\u8303\u56f4", "method": "\u5bf9Hugging Face\u4e0a364\u5343\u4e2a\u6570\u636e\u96c6\u30011.6\u767e\u4e07\u4e2a\u6a21\u578b\u4ee5\u53ca14\u4e07\u4e2aGitHub\u9879\u76ee\u8fdb\u884c\u8bb8\u53ef\u8bc1\u5ba1\u8ba1\uff0c\u5e76\u6784\u5efa\u4e86\u53ef\u6269\u5c55\u7684\u89c4\u5219\u5f15\u64ce\u6765\u7f16\u7801\u8fd1200\u4e2aSPDX\u548c\u6a21\u578b\u7279\u5b9a\u6761\u6b3e", "result": "\u53d1\u73b035.5%\u7684\u6a21\u578b\u5230\u5e94\u7528\u8f6c\u6362\u4f1a\u901a\u8fc7\u91cd\u65b0\u6388\u6743\u6d88\u9664\u9650\u5236\u6027\u8bb8\u53ef\u8bc1\u6761\u6b3e\uff0c\u89c4\u5219\u5f15\u64ce\u80fd\u89e3\u51b386.4%\u7684\u8f6f\u4ef6\u5e94\u7528\u8bb8\u53ef\u8bc1\u51b2\u7a81", "conclusion": "\u8bb8\u53ef\u8bc1\u9075\u5faa\u662f\u5f00\u6e90AI\u9886\u57df\u7684\u5173\u952e\u6cbb\u7406\u6311\u6218\uff0c\u7814\u7a76\u63d0\u4f9b\u4e86\u652f\u6301\u81ea\u52a8\u5316\u5927\u89c4\u6a21\u9075\u89c4\u7684\u6570\u636e\u548c\u5de5\u5177"}}
{"id": "2509.09738", "categories": ["cs.AI", "q-bio.QM", "I.2.7"], "pdf": "https://arxiv.org/pdf/2509.09738", "abs": "https://arxiv.org/abs/2509.09738", "authors": ["Umut Eser", "Yael Gozin", "L. Jay Stallons", "Ari Caroline", "Martin Preusse", "Brandon Rice", "Scott Wright", "Andrew Robertson"], "title": "Human-AI Collaboration Increases Efficiency in Regulatory Writing", "comment": null, "summary": "Background: Investigational New Drug (IND) application preparation is\ntime-intensive and expertise-dependent, slowing early clinical development.\nObjective: To evaluate whether a large language model (LLM) platform (AutoIND)\ncan reduce first-draft composition time while maintaining document quality in\nregulatory submissions. Methods: Drafting times for IND nonclinical written\nsummaries (eCTD modules 2.6.2, 2.6.4, 2.6.6) generated by AutoIND were directly\nrecorded. For comparison, manual drafting times for IND summaries previously\ncleared by the U.S. FDA were estimated from the experience of regulatory\nwriters ($\\geq$6 years) and used as industry-standard benchmarks. Quality was\nassessed by a blinded regulatory writing assessor using seven pre-specified\ncategories: correctness, completeness, conciseness, consistency, clarity,\nredundancy, and emphasis. Each sub-criterion was scored 0-3 and normalized to a\npercentage. A critical regulatory error was defined as any misrepresentation or\nomission likely to alter regulatory interpretation (e.g., incorrect NOAEL,\nomission of mandatory GLP dose-formulation analysis). Results: AutoIND reduced\ninitial drafting time by $\\sim$97% (from $\\sim$100 h to 3.7 h for 18,870\npages/61 reports in IND-1; and to 2.6 h for 11,425 pages/58 reports in IND-2).\nQuality scores were 69.6\\% and 77.9\\% for IND-1 and IND-2. No critical\nregulatory errors were detected, but deficiencies in emphasis, conciseness, and\nclarity were noted. Conclusions: AutoIND can dramatically accelerate IND\ndrafting, but expert regulatory writers remain essential to mature outputs to\nsubmission-ready quality. Systematic deficiencies identified provide a roadmap\nfor targeted model improvements.", "AI": {"tldr": "AutoIND\u5927\u8bed\u8a00\u6a21\u578b\u5e73\u53f0\u53ef\u5c06IND\u7533\u8bf7\u7684\u975e\u4e34\u5e8a\u4e66\u9762\u603b\u7ed3\u8d77\u8349\u65f6\u95f4\u51cf\u5c11\u7ea697%\uff0c\u4ece\u7ea6100\u5c0f\u65f6\u964d\u81f33-4\u5c0f\u65f6\uff0c\u8d28\u91cf\u8bc4\u5206\u8fbe70-78%\uff0c\u65e0\u5173\u952e\u76d1\u7ba1\u9519\u8bef\uff0c\u4f46\u4ecd\u9700\u4e13\u5bb6\u5b8c\u5584\u4ee5\u63d0\u9ad8\u8d28\u91cf\u3002", "motivation": "IND\u7533\u8bf7\u51c6\u5907\u8017\u65f6\u4e14\u4f9d\u8d56\u4e13\u4e1a\u77e5\u8bc6\uff0c\u62d6\u6162\u65e9\u671f\u4e34\u5e8a\u5f00\u53d1\u8fdb\u7a0b\uff0c\u9700\u8981\u5bfb\u627e\u52a0\u901f\u8d77\u8349\u8fc7\u7a0b\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528AutoIND LLM\u5e73\u53f0\u751f\u6210IND\u975e\u4e34\u5e8a\u4e66\u9762\u603b\u7ed3\uff0c\u8bb0\u5f55\u8d77\u8349\u65f6\u95f4\u5e76\u4e0e\u4eba\u5de5\u8d77\u8349\u65f6\u95f4\u5bf9\u6bd4\uff0c\u7531\u76f2\u8bc4\u76d1\u7ba1\u5199\u4f5c\u8bc4\u4f30\u5458\u4f7f\u75287\u4e2a\u9884\u8bbe\u7c7b\u522b\u8fdb\u884c\u8d28\u91cf\u8bc4\u4f30\u3002", "result": "\u8d77\u8349\u65f6\u95f4\u51cf\u5c1197%\uff08\u4ece~100\u5c0f\u65f6\u964d\u81f33.7\u5c0f\u65f6\u548c2.6\u5c0f\u65f6\uff09\uff0c\u8d28\u91cf\u8bc4\u5206\u5206\u522b\u4e3a69.6%\u548c77.9%\uff0c\u65e0\u5173\u952e\u76d1\u7ba1\u9519\u8bef\uff0c\u4f46\u5728\u91cd\u70b9\u7a81\u51fa\u3001\u7b80\u6d01\u6027\u548c\u6e05\u6670\u5ea6\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "conclusion": "AutoIND\u80fd\u663e\u8457\u52a0\u901fIND\u8d77\u8349\uff0c\u4f46\u4e13\u5bb6\u76d1\u7ba1\u5199\u4f5c\u8005\u4ecd\u662f\u786e\u4fdd\u63d0\u4ea4\u8d28\u91cf\u7684\u5173\u952e\uff0c\u53d1\u73b0\u7684\u7cfb\u7edf\u6027\u7f3a\u9677\u4e3a\u6a21\u578b\u6539\u8fdb\u63d0\u4f9b\u4e86\u8def\u7ebf\u56fe\u3002"}}
{"id": "2509.09970", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09970", "abs": "https://arxiv.org/abs/2509.09970", "authors": ["Seyed Moein Abtahi", "Akramul Azim"], "title": "Securing LLM-Generated Embedded Firmware through AI Agent-Driven Validation and Patching", "comment": null, "summary": "Large Language Models (LLMs) show promise in generating firmware for embedded\nsystems, but often introduce security flaws and fail to meet real-time\nperformance constraints. This paper proposes a three-phase methodology that\ncombines LLM-based firmware generation with automated security validation and\niterative refinement in a virtualized environment. Using structured prompts,\nmodels like GPT-4 generate firmware for networking and control tasks, deployed\non FreeRTOS via QEMU. These implementations are tested using fuzzing, static\nanalysis, and runtime monitoring to detect vulnerabilities such as buffer\noverflows (CWE-120), race conditions (CWE-362), and denial-of-service threats\n(CWE-400). Specialized AI agents for Threat Detection, Performance\nOptimization, and Compliance Verification collaborate to improve detection and\nremediation. Identified issues are categorized using CWE, then used to prompt\ntargeted LLM-generated patches in an iterative loop. Experiments show a 92.4\\%\nVulnerability Remediation Rate (37.3\\% improvement), 95.8\\% Threat Model\nCompliance, and 0.87 Security Coverage Index. Real-time metrics include 8.6ms\nworst-case execution time and 195{\\mu}s jitter. This process enhances firmware\nsecurity and performance while contributing an open-source dataset for future\nresearch.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408LLM\u751f\u6210\u56fa\u4ef6\u4e0e\u81ea\u52a8\u5316\u5b89\u5168\u9a8c\u8bc1\u7684\u4e09\u9636\u6bb5\u65b9\u6cd5\uff0c\u5728\u865a\u62df\u5316\u73af\u5883\u4e2d\u901a\u8fc7\u8fed\u4ee3\u4f18\u5316\u63d0\u5347\u5d4c\u5165\u5f0f\u7cfb\u7edf\u56fa\u4ef6\u7684\u5b89\u5168\u6027\u548c\u5b9e\u65f6\u6027\u80fd", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u5d4c\u5165\u5f0f\u7cfb\u7edf\u56fa\u4ef6\u65f6\u7ecf\u5e38\u5f15\u5165\u5b89\u5168\u6f0f\u6d1e\u4e14\u65e0\u6cd5\u6ee1\u8db3\u5b9e\u65f6\u6027\u80fd\u7ea6\u675f\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u7684\u65b9\u6cd5\u6765\u786e\u4fdd\u751f\u6210\u4ee3\u7801\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027", "method": "\u4e09\u9636\u6bb5\u65b9\u6cd5\uff1a1)\u4f7f\u7528\u7ed3\u6784\u5316\u63d0\u793a\u8bcd\u8ba9GPT-4\u7b49\u6a21\u578b\u751f\u6210\u56fa\u4ef6\u4ee3\u7801\uff1b2)\u5728QEMU\u865a\u62df\u5316\u73af\u5883\u4e2d\u90e8\u7f72\u5230FreeRTOS\uff0c\u901a\u8fc7\u6a21\u7cca\u6d4b\u8bd5\u3001\u9759\u6001\u5206\u6790\u548c\u8fd0\u884c\u65f6\u76d1\u63a7\u68c0\u6d4b\u6f0f\u6d1e\uff1b3)\u5229\u7528\u4e13\u95e8\u7684AI\u4ee3\u7406\u8fdb\u884c\u5a01\u80c1\u68c0\u6d4b\u3001\u6027\u80fd\u4f18\u5316\u548c\u5408\u89c4\u9a8c\u8bc1\uff0c\u8fed\u4ee3\u751f\u6210\u8865\u4e01", "result": "\u5b9e\u9a8c\u663e\u793a92.4%\u7684\u6f0f\u6d1e\u4fee\u590d\u7387\uff08\u63d0\u534737.3%\uff09\uff0c95.8%\u7684\u5a01\u80c1\u6a21\u578b\u5408\u89c4\u7387\uff0c0.87\u7684\u5b89\u5168\u8986\u76d6\u6307\u6570\uff0c\u5b9e\u65f6\u6027\u80fd\u6307\u6807\u5305\u62ec8.6ms\u6700\u574f\u60c5\u51b5\u6267\u884c\u65f6\u95f4\u548c195\u03bcs\u6296\u52a8", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86LLM\u751f\u6210\u56fa\u4ef6\u7684\u5b89\u5168\u6027\u548c\u6027\u80fd\uff0c\u540c\u65f6\u8d21\u732e\u4e86\u5f00\u6e90\u6570\u636e\u96c6\u4f9b\u672a\u6765\u7814\u7a76\u4f7f\u7528"}}
{"id": "2509.09917", "categories": ["cs.SE", "D.2.4"], "pdf": "https://arxiv.org/pdf/2509.09917", "abs": "https://arxiv.org/abs/2509.09917", "authors": ["Zehan Chen", "Long Zhang", "Zhiwei Zhang", "JingJing Zhang", "Ruoyu Zhou", "Yulong Shen", "JianFeng Ma", "Lin Yang"], "title": "SLD-Spec: Enhancement LLM-assisted Specification Generation for Complex Loop Functions via Program Slicing and Logical Deletion", "comment": "22 pages, 2 figures, conference", "summary": "Automatically generating formal specifications from program code can greatly\nenhance the efficiency of program verification and enable end-to-end automation\nfrom requirements to reliable software. However, existing LLM-based approaches\noften struggle with programs that include complex loop structures, leading to\nirrelevant specifications. Moreover, the rigorous proof obligations and design\nconstraints imposed by verification tools can further result in incomplete and\nambiguous specifications. To address these challenges, we propose SLD-Spec, an\nLLM-assisted specification generation method tailored for programs with complex\nloop constructs. SLD-Spec introduces two novel phases into the traditional\nspecification generation framework: (1) A slicing phase, which decomposes each\nfunction into code fragments containing independent loop structures, thereby\nreducing the complexity of specification generation; and (2) A logical deletion\nphase, which applies LLM-based reasoning to filter out incorrect candidate\nspecifications--especially those not easily identified by verification\ntool--while retaining valid ones. Experimental results show that on the simple\ndataset, SLD-Spec successfully verifies five more programs than the\nstate-of-the-art AutoSpec and reduces runtime by 23.73%. To address the\nlimitations of existing research, we manually construct a dataset comprising\nfour categories of complex loop programs. On this dataset, SLD-Spec\nsignificantly improves the correctness, relevance, and completeness of\ngenerated specifications compared to baseline methods, enabling 95.1% of\nassertions and 90.91% of programs to pass verification. Ablation studies\nfurther reveal that logical deletion is critical for enhancing specification\ncorrectness and relevance, while program slicing contributes significantly to\nspecification completeness. Our code and data are publicly available.", "AI": {"tldr": "SLD-Spec\u662f\u4e00\u79cd\u9488\u5bf9\u590d\u6742\u5faa\u73af\u7a0b\u5e8f\u7684LLM\u8f85\u52a9\u89c4\u8303\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u7a0b\u5e8f\u5207\u7247\u548c\u903b\u8f91\u5220\u9664\u4e24\u9636\u6bb5\u663e\u8457\u63d0\u5347\u89c4\u8303\u7684\u6b63\u786e\u6027\u3001\u76f8\u5173\u6027\u548c\u5b8c\u6574\u6027", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u5728\u5904\u7406\u5305\u542b\u590d\u6742\u5faa\u73af\u7ed3\u6784\u7684\u7a0b\u5e8f\u65f6\u5f80\u5f80\u751f\u6210\u4e0d\u76f8\u5173\u7684\u89c4\u8303\uff0c\u4e14\u9a8c\u8bc1\u5de5\u5177\u7684\u4e25\u683c\u8bc1\u660e\u4e49\u52a1\u548c\u8bbe\u8ba1\u7ea6\u675f\u4f1a\u5bfc\u81f4\u4e0d\u5b8c\u6574\u548c\u6a21\u7cca\u7684\u89c4\u8303", "method": "\u5f15\u5165\u4e24\u4e2a\u65b0\u9636\u6bb5\uff1a1)\u5207\u7247\u9636\u6bb5-\u5c06\u51fd\u6570\u5206\u89e3\u4e3a\u5305\u542b\u72ec\u7acb\u5faa\u73af\u7ed3\u6784\u7684\u4ee3\u7801\u7247\u6bb5\uff1b2)\u903b\u8f91\u5220\u9664\u9636\u6bb5-\u57fa\u4e8eLLM\u63a8\u7406\u8fc7\u6ee4\u9519\u8bef\u5019\u9009\u89c4\u8303", "result": "\u5728\u7b80\u5355\u6570\u636e\u96c6\u4e0a\u6bd4\u6700\u5148\u8fdb\u7684AutoSpec\u591a\u9a8c\u8bc15\u4e2a\u7a0b\u5e8f\uff0c\u8fd0\u884c\u65f6\u95f4\u51cf\u5c1123.73%\uff1b\u5728\u590d\u6742\u5faa\u73af\u6570\u636e\u96c6\u4e0a95.1%\u7684\u65ad\u8a00\u548c90.91%\u7684\u7a0b\u5e8f\u901a\u8fc7\u9a8c\u8bc1", "conclusion": "\u903b\u8f91\u5220\u9664\u5bf9\u63d0\u5347\u89c4\u8303\u6b63\u786e\u6027\u548c\u76f8\u5173\u6027\u81f3\u5173\u91cd\u8981\uff0c\u7a0b\u5e8f\u5207\u7247\u5bf9\u89c4\u8303\u5b8c\u6574\u6027\u8d21\u732e\u663e\u8457\uff0cSLD-Spec\u80fd\u6709\u6548\u5904\u7406\u590d\u6742\u5faa\u73af\u7a0b\u5e8f\u7684\u89c4\u8303\u751f\u6210\u95ee\u9898"}}
{"id": "2509.09775", "categories": ["cs.AI", "cs.CL", "cs.FL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.09775", "abs": "https://arxiv.org/abs/2509.09775", "authors": ["Aleksandr Boldachev"], "title": "Executable Ontologies: Synthesizing Event Semantics with Dataflow Architecture", "comment": "22 pages, 6 figures", "summary": "This paper presents boldsea, Boldachev's semantic-event approach -- an\narchitecture for modeling complex dynamic systems using executable ontologies\n-- semantic models that act as dynamic structures, directly controlling process\nexecution. We demonstrate that integrating event semantics with a dataflow\narchitecture addresses the limitations of traditional Business Process\nManagement (BPM) systems and object-oriented semantic technologies. The paper\npresents the formal BSL (boldsea Semantic Language), including its BNF grammar,\nand outlines the boldsea-engine's architecture, which directly interprets\nsemantic models as executable algorithms without compilation. It enables the\nmodification of event models at runtime, ensures temporal transparency, and\nseamlessly merges data and business logic within a unified semantic framework.", "AI": {"tldr": "boldsea\u662f\u4e00\u4e2a\u57fa\u4e8e\u8bed\u4e49\u4e8b\u4ef6\u7684\u53ef\u6267\u884c\u672c\u4f53\u67b6\u6784\uff0c\u7528\u4e8e\u5efa\u6a21\u590d\u6742\u52a8\u6001\u7cfb\u7edf\uff0c\u901a\u8fc7\u6574\u5408\u4e8b\u4ef6\u8bed\u4e49\u548c\u6570\u636e\u6d41\u67b6\u6784\u6765\u89e3\u51b3\u4f20\u7edfBPM\u7cfb\u7edf\u548c\u9762\u5411\u5bf9\u8c61\u8bed\u4e49\u6280\u672f\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u4e1a\u52a1\u6d41\u7a0b\u7ba1\u7406\u7cfb\u7edf\u548c\u9762\u5411\u5bf9\u8c61\u8bed\u4e49\u6280\u672f\u5728\u52a8\u6001\u7cfb\u7edf\u5efa\u6a21\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u8fd0\u884c\u65f6\u4fee\u6539\u4e8b\u4ef6\u6a21\u578b\u3001\u65f6\u95f4\u900f\u660e\u6027\u4ee5\u53ca\u6570\u636e\u548c\u4e1a\u52a1\u903b\u8f91\u7edf\u4e00\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faboldsea\u8bed\u4e49\u8bed\u8a00(BSL)\u53ca\u5176BNF\u8bed\u6cd5\uff0c\u8bbe\u8ba1boldsea-engine\u67b6\u6784\uff0c\u76f4\u63a5\u89e3\u91ca\u8bed\u4e49\u6a21\u578b\u4f5c\u4e3a\u53ef\u6267\u884c\u7b97\u6cd5\u800c\u65e0\u9700\u7f16\u8bd1\u3002", "result": "\u5b9e\u73b0\u4e86\u8bed\u4e49\u6a21\u578b\u4f5c\u4e3a\u52a8\u6001\u7ed3\u6784\u76f4\u63a5\u63a7\u5236\u6d41\u7a0b\u6267\u884c\uff0c\u652f\u6301\u8fd0\u884c\u65f6\u4e8b\u4ef6\u6a21\u578b\u4fee\u6539\uff0c\u786e\u4fdd\u65f6\u95f4\u900f\u660e\u6027\uff0c\u5e76\u5728\u7edf\u4e00\u8bed\u4e49\u6846\u67b6\u4e2d\u65e0\u7f1d\u5408\u5e76\u6570\u636e\u548c\u4e1a\u52a1\u903b\u8f91\u3002", "conclusion": "boldsea\u67b6\u6784\u901a\u8fc7\u53ef\u6267\u884c\u672c\u4f53\u548c\u8bed\u4e49\u4e8b\u4ef6\u65b9\u6cd5\uff0c\u4e3a\u590d\u6742\u52a8\u6001\u7cfb\u7edf\u5efa\u6a21\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u548c\u5f3a\u5927\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u9650\u5236\u3002"}}
{"id": "2509.09989", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.09989", "abs": "https://arxiv.org/abs/2509.09989", "authors": ["Priyanka Rushikesh Chaudhary", "Manan Gupta", "Jabez Christopher", "Putrevu Venkata Sai Charan", "Rajib Ranjan Maiti"], "title": "rCamInspector: Building Reliability and Trust on IoT (Spy) Camera Detection using XAI", "comment": null, "summary": "The classification of network traffic using machine learning (ML) models is\none of the primary mechanisms to address the security issues in IoT networks\nand/or IoT devices. However, the ML models often act as black-boxes that create\na roadblock to take critical decision based on the model output. To address\nthis problem, we design and develop a system, called rCamInspector, that\nemploys Explainable AI (XAI) to provide reliable and trustworthy explanations\nto model output. rCamInspector adopts two classifiers, Flow Classifier -\ncategorizes a flow into one of four classes, IoTCam, Conf, Share and Others,\nand SmartCam Classifier - classifies an IoTCam flow into one of six classes,\nNetatmo, Spy Clock, Canary, D3D, Ezviz, V380 Spy Bulb; both are IP address and\ntransport port agnostic. rCamInspector is evaluated using 38GB of network\ntraffic and our results show that XGB achieves the highest accuracy of 92% and\n99% in the Flow and SmartCam classifiers respectively among eight supervised ML\nmodels. We analytically show that the traditional mutual information (MI) based\nfeature importance cannot provide enough reliability on the model output of XGB\nin either classifiers. Using SHAP and LIME, we show that a separate set of\nfeatures can be picked up to explain a correct prediction of XGB. For example,\nthe feature Init Bwd Win Byts turns out to have the highest SHAP values to\nsupport the correct prediction of both IoTCam in Flow Classifier and Netatmo\nclass in SmartCam Classifier. To evaluate the faithfulness of the explainers on\nour dataset, we show that both SHAP and LIME have a consistency of more than\n0.7 and a sufficiency of 1.0. Comparing with existing works, we show that\nrCamInspector achieves a better accuracy (99%), precision (99%), and false\nnegative rate (0.7%).", "AI": {"tldr": "rCamInspector\u662f\u4e00\u4e2a\u57fa\u4e8e\u53ef\u89e3\u91caAI(XAI)\u7684\u7269\u8054\u7f51\u6444\u50cf\u5934\u6d41\u91cf\u5206\u7c7b\u7cfb\u7edf\uff0c\u4f7f\u7528XGBoost\u6a21\u578b\u5728Flow\u5206\u7c7b\u5668\u548cSmartCam\u5206\u7c7b\u5668\u4e2d\u5206\u522b\u8fbe\u523092%\u548c99%\u7684\u51c6\u786e\u7387\uff0c\u5e76\u901a\u8fc7SHAP\u548cLIME\u63d0\u4f9b\u53ef\u4fe1\u7684\u89e3\u91ca\u3002", "motivation": "\u89e3\u51b3\u7269\u8054\u7f51\u7f51\u7edc\u5b89\u5168\u4e2d\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9ed1\u76d2\u95ee\u9898\uff0c\u63d0\u4f9b\u53ef\u9760\u548c\u53ef\u4fe1\u7684\u6a21\u578b\u8f93\u51fa\u89e3\u91ca\uff0c\u4ee5\u652f\u6301\u5173\u952e\u51b3\u7b56\u3002", "method": "\u8bbe\u8ba1rCamInspector\u7cfb\u7edf\uff0c\u91c7\u7528\u4e24\u4e2a\u5206\u7c7b\u5668\uff1aFlow\u5206\u7c7b\u5668\uff084\u7c7b\uff09\u548cSmartCam\u5206\u7c7b\u5668\uff086\u7c7b\uff09\uff0c\u4f7f\u75288\u79cd\u76d1\u7763ML\u6a21\u578b\uff0c\u91cd\u70b9\u91c7\u7528XGBoost\uff0c\u5e76\u5e94\u7528SHAP\u548cLIME\u8fdb\u884c\u7279\u5f81\u91cd\u8981\u6027\u89e3\u91ca\u3002", "result": "XGBoost\u5728\u4e24\u4e2a\u5206\u7c7b\u5668\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u51c6\u786e\u7387\u5206\u522b\u4e3a92%\u548c99%\u3002SHAP\u548cLIME\u89e3\u91ca\u5668\u5728\u6570\u636e\u96c6\u4e0a\u5177\u6709\u8d85\u8fc70.7\u7684\u4e00\u81f4\u6027\u548c1.0\u7684\u5145\u5206\u6027\u3002\u4e0e\u4f20\u7edf\u4e92\u4fe1\u606f\u65b9\u6cd5\u76f8\u6bd4\uff0cXAI\u65b9\u6cd5\u80fd\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u7279\u5f81\u89e3\u91ca\u3002", "conclusion": "rCamInspector\u5728\u7269\u8054\u7f51\u6444\u50cf\u5934\u6d41\u91cf\u5206\u7c7b\u65b9\u9762\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u548c\u53ef\u4fe1\u7684\u89e3\u91ca\u80fd\u529b\uff0c\u8bc1\u660e\u4e86XAI\u5728\u7f51\u7edc\u5b89\u5168\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\uff0c\u76f8\u6bd4\u73b0\u6709\u5de5\u4f5c\u5177\u6709\u66f4\u597d\u7684\u6027\u80fd\u6307\u6807\u3002"}}
{"id": "2509.09918", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09918", "abs": "https://arxiv.org/abs/2509.09918", "authors": ["Seyed Moein Abtahi", "Akramul Azim"], "title": "WALL: A Web Application for Automated Quality Assurance using Large Language Models", "comment": null, "summary": "As software projects become increasingly complex, the volume and variety of\nissues in code files have grown substantially. Addressing this challenge\nrequires efficient issue detection, resolution, and evaluation tools. This\npaper presents WALL, a web application that integrates SonarQube and large\nlanguage models (LLMs) such as GPT-3.5 Turbo and GPT-4o to automate these\ntasks. WALL comprises three modules: an issue extraction tool, code issues\nreviser, and code comparison tool. Together, they enable a seamless pipeline\nfor detecting software issues, generating automated code revisions, and\nevaluating the accuracy of revisions. Our experiments, conducted on 563 files\nwith over 7,599 issues, demonstrate WALL's effectiveness in reducing human\neffort while maintaining high-quality revisions. Results show that employing a\nhybrid approach of cost-effective and advanced LLMs can significantly lower\ncosts and improve revision rates. Future work aims to enhance WALL's\ncapabilities by integrating open-source LLMs and eliminating human\nintervention, paving the way for fully automated code quality management.", "AI": {"tldr": "WALL\u662f\u4e00\u4e2a\u96c6\u6210SonarQube\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684Web\u5e94\u7528\uff0c\u901a\u8fc7\u4e09\u4e2a\u6a21\u5757\u81ea\u52a8\u5316\u4ee3\u7801\u95ee\u9898\u68c0\u6d4b\u3001\u4fee\u590d\u548c\u8bc4\u4f30\uff0c\u5728563\u4e2a\u6587\u4ef6\u4e2d\u5904\u74067599\u4e2a\u95ee\u9898\uff0c\u6709\u6548\u51cf\u5c11\u4eba\u5de5\u5de5\u4f5c\u91cf\u5e76\u4fdd\u6301\u9ad8\u8d28\u91cf\u4fee\u590d\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u9879\u76ee\u590d\u6742\u5ea6\u589e\u52a0\uff0c\u4ee3\u7801\u95ee\u9898\u6570\u91cf\u548c\u79cd\u7c7b\u5927\u5e45\u589e\u957f\uff0c\u9700\u8981\u9ad8\u6548\u7684\u81ea\u52a8\u5316\u5de5\u5177\u6765\u5904\u7406\u95ee\u9898\u68c0\u6d4b\u3001\u4fee\u590d\u548c\u8bc4\u4f30\u3002", "method": "\u5f00\u53d1WALL Web\u5e94\u7528\uff0c\u96c6\u6210SonarQube\u548cLLMs\uff08GPT-3.5 Turbo\u548cGPT-4o\uff09\uff0c\u5305\u542b\u95ee\u9898\u63d0\u53d6\u5de5\u5177\u3001\u4ee3\u7801\u95ee\u9898\u4fee\u8ba2\u5668\u548c\u4ee3\u7801\u6bd4\u8f83\u5de5\u5177\u4e09\u4e2a\u6a21\u5757\u3002", "result": "\u5728563\u4e2a\u6587\u4ef67599\u4e2a\u95ee\u9898\u4e0a\u5b9e\u9a8c\u8bc1\u660e\uff0cWALL\u80fd\u6709\u6548\u51cf\u5c11\u4eba\u5de5\u5de5\u4f5c\u91cf\uff0c\u4fdd\u6301\u9ad8\u8d28\u91cf\u4fee\u8ba2\uff0c\u6df7\u5408\u4f7f\u7528\u7ecf\u6d4e\u578b\u548c\u5148\u8fdbLLMs\u53ef\u663e\u8457\u964d\u4f4e\u6210\u672c\u5e76\u63d0\u9ad8\u4fee\u8ba2\u7387\u3002", "conclusion": "WALL\u5c55\u793a\u4e86\u81ea\u52a8\u5316\u4ee3\u7801\u8d28\u91cf\u7ba1\u7406\u7684\u6709\u6548\u6027\uff0c\u672a\u6765\u5de5\u4f5c\u5c06\u96c6\u6210\u5f00\u6e90LLMs\u5e76\u6d88\u9664\u4eba\u5de5\u5e72\u9884\uff0c\u5b9e\u73b0\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u4ee3\u7801\u8d28\u91cf\u7ba1\u7406\u3002"}}
{"id": "2509.09790", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09790", "abs": "https://arxiv.org/abs/2509.09790", "authors": ["Yuxuan Li", "Victor Zhong"], "title": "How well can LLMs provide planning feedback in grounded environments?", "comment": null, "summary": "Learning to plan in grounded environments typically requires carefully\ndesigned reward functions or high-quality annotated demonstrations. Recent\nworks show that pretrained foundation models, such as large language models\n(LLMs) and vision language models (VLMs), capture background knowledge helpful\nfor planning, which reduces the amount of reward design and demonstrations\nneeded for policy learning. We evaluate how well LLMs and VLMs provide feedback\nacross symbolic, language, and continuous control environments. We consider\nprominent types of feedback for planning including binary feedback, preference\nfeedback, action advising, goal advising, and delta action feedback. We also\nconsider inference methods that impact feedback performance, including\nin-context learning, chain-of-thought, and access to environment dynamics. We\nfind that foundation models can provide diverse high-quality feedback across\ndomains. Moreover, larger and reasoning models consistently provide more\naccurate feedback, exhibit less bias, and benefit more from enhanced inference\nmethods. Finally, feedback quality degrades for environments with complex\ndynamics or continuous state spaces and action spaces.", "AI": {"tldr": "\u5927\u578b\u57fa\u7840\u6a21\u578b\u80fd\u591f\u63d0\u4f9b\u9ad8\u8d28\u91cf\u7684\u591a\u6837\u5316\u89c4\u5212\u53cd\u9988\uff0c\u5305\u62ec\u4e8c\u8fdb\u5236\u3001\u504f\u597d\u3001\u52a8\u4f5c\u5efa\u8bae\u7b49\uff0c\u51cf\u5c11\u5bf9\u8bbe\u8ba1\u5956\u52b1\u51fd\u6570\u548c\u6f14\u793a\u6570\u636e\u7684\u4f9d\u8d56", "motivation": "\u89e3\u51b3\u73b0\u6709\u89c4\u5212\u65b9\u6cd5\u9700\u8981\u7cbe\u5fc3\u8bbe\u8ba1\u5956\u52b1\u51fd\u6570\u6216\u9ad8\u8d28\u91cf\u6f14\u793a\u6570\u636e\u7684\u95ee\u9898\uff0c\u5e76\u63a2\u7d22\u57fa\u7840\u6a21\u578b\u5728\u89c4\u5212\u4efb\u52a1\u4e2d\u63d0\u4f9b\u53cd\u9988\u7684\u6548\u679c", "method": "\u5728\u7b26\u53f7\u3001\u8bed\u8a00\u548c\u8fde\u7eed\u63a7\u5236\u73af\u5883\u4e2d\u8bc4\u4f30LLM\u548cVLM\u7684\u53cd\u9988\u6027\u80fd\uff0c\u6d4b\u8bd5\u4e86\u4e8c\u8fdb\u5236\u53cd\u9988\u3001\u504f\u597d\u53cd\u9988\u3001\u52a8\u4f5c\u5efa\u8bae\u3001\u76ee\u6807\u5efa\u8bae\u7b49\u591a\u79cd\u53cd\u9988\u7c7b\u578b\uff0c\u4ee5\u53ca\u4e0a\u4e0b\u6587\u5b66\u4e60\u3001\u601d\u7ef4\u94fe\u7b49\u63a8\u7406\u65b9\u6cd5", "result": "\u57fa\u7840\u6a21\u578b\u80fd\u591f\u63d0\u4f9b\u9ad8\u8d28\u91cf\u7684\u591a\u6837\u5316\u53cd\u9988\uff0c\u8f83\u5927\u548c\u5177\u6709\u63a8\u7406\u80fd\u529b\u7684\u6a21\u578b\u8868\u73b0\u66f4\u597d\uff0c\u53cd\u9988\u51c6\u786e\u6027\u66f4\u9ad8\u3001\u504f\u89c1\u66f4\u5c11\uff0c\u5e76\u80fd\u4ece\u66f4\u5f3a\u5927\u7684\u63a8\u7406\u65b9\u6cd5\u4e2d\u83b7\u76ca\u66f4\u591a", "conclusion": "\u57fa\u7840\u6a21\u578b\u53ef\u4ee5\u4f5c\u4e3a\u6709\u6548\u7684\u89c4\u5212\u53cd\u9988\u6765\u6e90\uff0c\u4f46\u5728\u590d\u6742\u52a8\u529b\u5b66\u6216\u8fde\u7eed\u72b6\u6001/\u52a8\u4f5c\u7a7a\u95f4\u7684\u73af\u5883\u4e2d\u53cd\u9988\u8d28\u91cf\u4f1a\u4e0b\u964d"}}
{"id": "2509.10165", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.10165", "abs": "https://arxiv.org/abs/2509.10165", "authors": ["Matthew J. Schneider", "James Bailie", "Dawn Iacobucci"], "title": "Why Data Anonymization Has Not Taken Off", "comment": "15 pages", "summary": "Companies are looking to data anonymization research $\\unicode{x2013}$\nincluding differential private and synthetic data methods $\\unicode{x2013}$ for\nsimple and straightforward compliance solutions. But data anonymization has not\ntaken off in practice because it is anything but simple to implement. For one,\nit requires making complex choices which are case dependent, such as the domain\nof the dataset to anonymize; the units to protect; the scope where the data\nprotection should extend to; and the standard of protection. Each variation of\nthese choices changes the very meaning, as well as the practical implications,\nof differential privacy (or of any other measure of data anonymization). Yet\ndifferential privacy is frequently being branded as the same privacy guarantee\nregardless of variations in these choices. Some data anonymization methods can\nbe effective, but only when the insights required are much larger than the unit\nof protection. Given that businesses care about profitability, any solution\nmust preserve the patterns between a firm's data and that profitability. As a\nresult, data anonymization solutions usually need to be bespoke and\ncase-specific, which reduces their scalability. Companies should not expect\neasy wins, but rather recognize that anonymization is just one approach to data\nprivacy with its own particular advantages and drawbacks, while the best\nstrategies jointly leverage the full range of approaches to data privacy and\nsecurity in combination.", "AI": {"tldr": "\u5dee\u5206\u9690\u79c1\u548c\u6570\u636e\u533f\u540d\u5316\u6280\u672f\u5728\u5b9e\u8df5\u4e2d\u5b58\u5728\u91cd\u5927\u6311\u6218\uff0c\u9700\u8981\u6839\u636e\u5177\u4f53\u573a\u666f\u8fdb\u884c\u590d\u6742\u7684\u9009\u62e9\u548c\u5b9a\u5236\u5316\u5b9e\u65bd\uff0c\u800c\u975e\u4e00\u79cd\u901a\u7528\u7684\u7b80\u5355\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u4f01\u4e1a\u5bfb\u6c42\u901a\u8fc7\u6570\u636e\u533f\u540d\u5316\u6765\u7b80\u5316\u9075\u89c4\u5904\u7406\uff0c\u4f46\u73b0\u6709\u6280\u672f\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9047\u5230\u4e86\u91cd\u5927\u56f0\u96be\u3002", "method": "\u5206\u6790\u4e86\u533f\u540d\u5316\u5b9e\u65bd\u4e2d\u9700\u8981\u8003\u8651\u7684\u591a\u79cd\u56e0\u7d20\uff1a\u6570\u636e\u57df\u8303\u56f4\u3001\u4fdd\u62a4\u5355\u4f4d\u3001\u4fdd\u62a4\u8303\u56f4\u548c\u4fdd\u62a4\u6807\u51c6\uff0c\u4ee5\u53ca\u4e1a\u52a1\u76c8\u5229\u6027\u8981\u6c42\u3002", "result": "\u533f\u540d\u5316\u65b9\u6848\u901a\u5e38\u9700\u8981\u5b9a\u5236\u5316\u5b9e\u65bd\uff0c\u964d\u4f4e\u4e86\u53ef\u6269\u5c55\u6027\uff0c\u4e14\u53ea\u5728\u9700\u6c42\u6d1e\u5bdf\u8fdc\u5927\u4e8e\u4fdd\u62a4\u5355\u4f4d\u65f6\u624d\u6709\u6548\u3002", "conclusion": "\u533f\u540d\u5316\u4ec5\u662f\u6570\u636e\u9690\u79c1\u4fdd\u62a4\u7684\u4e00\u79cd\u65b9\u6cd5\uff0c\u6700\u4f73\u7b56\u7565\u662f\u7ed3\u5408\u4f7f\u7528\u5404\u79cd\u6570\u636e\u9690\u79c1\u548c\u5b89\u5168\u6280\u672f\uff0c\u800c\u975e\u5bfb\u6c42\u5355\u4e00\u7684\u7b80\u5355\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.09947", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.09947", "abs": "https://arxiv.org/abs/2509.09947", "authors": ["Humza Ashraf", "Syed Muhammad Danish", "Zeeshan Sattar"], "title": "Toward Green Code: Prompting Small Language Models for Energy-Efficient Code Generation", "comment": null, "summary": "There is a growing concern about the environmental impact of large language\nmodels (LLMs) in software development, particularly due to their high energy\nuse and carbon footprint. Small Language Models (SLMs) offer a more sustainable\nalternative, requiring fewer computational resources while remaining effective\nfor fundamental programming tasks. In this study, we investigate whether prompt\nengineering can improve the energy efficiency of SLMs in code generation. We\nevaluate four open-source SLMs, StableCode-Instruct-3B,\nQwen2.5-Coder-3B-Instruct, CodeLlama-7B-Instruct, and Phi-3-Mini-4K-Instruct,\nacross 150 Python problems from LeetCode, evenly distributed into easy, medium,\nand hard categories. Each model is tested under four prompting strategies: role\nprompting, zero-shot, few-shot, and chain-of-thought (CoT). For every generated\nsolution, we measure runtime, memory usage, and energy consumption, comparing\nthe results with a human-written baseline. Our findings show that CoT prompting\nprovides consistent energy savings for Qwen2.5-Coder and StableCode-3B, while\nCodeLlama-7B and Phi-3-Mini-4K fail to outperform the baseline under any\nprompting strategy. These results highlight that the benefits of prompting are\nmodel-dependent and that carefully designed prompts can guide SLMs toward\ngreener software development.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u63d0\u9ad8\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u80fd\u6e90\u6548\u7387\uff0c\u53d1\u73b0Chain-of-Thought\u63d0\u793a\u5bf9\u67d0\u4e9b\u6a21\u578b\u6709\u663e\u8457\u8282\u80fd\u6548\u679c", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u5e26\u6765\u9ad8\u80fd\u8017\u548c\u78b3\u8e39\u75d5\u95ee\u9898\uff0c\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u66f4\u53ef\u6301\u7eed\u7684\u66ff\u4ee3\u65b9\u6848", "method": "\u8bc4\u4f30\u56db\u4e2a\u5f00\u6e90SLM\u6a21\u578b\u5728150\u9053Python\u95ee\u9898\u4e0a\u7684\u6027\u80fd\uff0c\u6d4b\u91cf\u8fd0\u884c\u65f6\u95f4\u3001\u5185\u5b58\u4f7f\u7528\u548c\u80fd\u8017\uff0c\u6bd4\u8f83\u56db\u79cd\u63d0\u793a\u7b56\u7565\uff08\u89d2\u8272\u63d0\u793a\u3001\u96f6\u6837\u672c\u3001\u5c11\u6837\u672c\u3001Chain-of-Thought\uff09", "result": "CoT\u63d0\u793a\u5bf9Qwen2.5-Coder\u548cStableCode-3B\u4ea7\u751f\u4e00\u81f4\u7684\u8282\u80fd\u6548\u679c\uff0c\u800cCodeLlama-7B\u548cPhi-3-Mini-4K\u5728\u4efb\u4f55\u63d0\u793a\u7b56\u7565\u4e0b\u90fd\u65e0\u6cd5\u8d85\u8fc7\u57fa\u51c6\u6c34\u5e73", "conclusion": "\u63d0\u793a\u5de5\u7a0b\u7684\u597d\u5904\u53d6\u51b3\u4e8e\u6a21\u578b\u7279\u6027\uff0c\u7ec6\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u53ef\u4ee5\u5f15\u5bfcSLM\u5411\u66f4\u7eff\u8272\u7684\u8f6f\u4ef6\u5f00\u53d1\u53d1\u5c55"}}
{"id": "2509.09794", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.09794", "abs": "https://arxiv.org/abs/2509.09794", "authors": ["Jackson Eshbaugh", "Chetan Tiwari", "Jorge Silveyra"], "title": "A Modular and Multimodal Generative AI Framework for Urban Building Energy Data: Generating Synthetic Homes", "comment": "44 pages; 2 appendices; 9 figures; 1 table. Code available at\n  https://github.com/Lafayette-EshbaughSilveyra-Group/synthetic-homes", "summary": "Computational models have emerged as powerful tools for energy modeling\nresearch, touting scalability and quantitative results. However, these models\nrequire a plethora of data, some of which is inaccessible, expensive, or raises\nprivacy concerns. We introduce a modular multimodal framework to produce this\ndata from publicly accessible residential information and images using\ngenerative artificial intelligence (AI). Additionally, we provide a pipeline\ndemonstrating this framework, and we evaluate its generative AI components. Our\nexperiments show that our framework's use of AI avoids common issues with\ngenerative models. Our framework produces realistic, labeled data. By reducing\ndependence on costly or restricted data sources, we pave a path towards more\naccessible and reproducible research.", "AI": {"tldr": "\u4f7f\u7528\u6a21\u5757\u5316\u591a\u6a21\u6001\u6846\u67b6\u548c\u751f\u6210\u5f0fAI\u4ece\u516c\u5f00\u4f4f\u5b85\u4fe1\u606f\u751f\u6210\u80fd\u6e90\u6a21\u578b\u6240\u9700\u6570\u636e\uff0c\u89e3\u51b3\u6570\u636e\u83b7\u53d6\u96be\u9898", "motivation": "\u80fd\u6e90\u5efa\u6a21\u9700\u8981\u5927\u91cf\u6570\u636e\uff0c\u4f46\u90e8\u5206\u6570\u636e\u83b7\u53d6\u56f0\u96be\u3001\u6210\u672c\u9ad8\u6216\u5b58\u5728\u9690\u79c1\u95ee\u9898", "method": "\u63d0\u51fa\u6a21\u5757\u5316\u591a\u6a21\u6001\u6846\u67b6\uff0c\u4f7f\u7528\u751f\u6210\u5f0fAI\u4ece\u516c\u5f00\u4f4f\u5b85\u4fe1\u606f\u548c\u56fe\u7247\u751f\u6210\u6807\u7b7e\u6570\u636e\uff0c\u5e76\u63d0\u4f9b\u6570\u636e\u751f\u6210\u6d41\u7a0b", "result": "\u6846\u67b6\u80fd\u591f\u751f\u6210\u5b9e\u9645\u7684\u6807\u7b7e\u6570\u636e\uff0c\u907f\u514d\u4e86\u751f\u6210\u6a21\u578b\u7684\u5e38\u89c1\u95ee\u9898", "conclusion": "\u8be5\u6846\u67b6\u51cf\u5c11\u4e86\u5bf9\u6210\u672c\u9ad8\u6216\u9650\u5236\u6570\u636e\u6e90\u7684\u4f9d\u8d56\uff0c\u4e3a\u66f4\u53ef\u8bbf\u95ee\u548c\u53ef\u590d\u73b0\u7684\u7814\u7a76\u63a8\u5e7f\u4e86\u9053\u8def"}}
{"id": "2509.10206", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10206", "abs": "https://arxiv.org/abs/2509.10206", "authors": ["Federica Uccello", "Simin Nadjm-Tehrani"], "title": "Investigating Feature Attribution for 5G Network Intrusion Detection", "comment": null, "summary": "With the rise of fifth-generation (5G) networks in critical applications, it\nis urgent to move from detection of malicious activity to systems capable of\nproviding a reliable verdict suitable for mitigation. In this regard,\nunderstanding and interpreting machine learning (ML) models' security alerts is\ncrucial for enabling actionable incident response orchestration. Explainable\nArtificial Intelligence (XAI) techniques are expected to enhance trust by\nproviding insights into why alerts are raised. A dominant approach\nstatistically associates feature sets that can be correlated to a given alert.\nThis paper starts by questioning whether such attribution is relevant for\nfuture generation communication systems, and investigates its merits in\ncomparison with an approach based on logical explanations. We extensively study\ntwo methods, SHAP and VoTE-XAI, by analyzing their interpretations of alerts\ngenerated by an XGBoost model in three different use cases with several 5G\ncommunication attacks. We identify three metrics for assessing explanations:\nsparsity, how concise they are; stability, how consistent they are across\nsamples from the same attack type; and efficiency, how fast an explanation is\ngenerated. As an example, in a 5G network with 92 features, 6 were deemed\nimportant by VoTE-XAI for a Denial of Service (DoS) variant, ICMPFlood, while\nSHAP identified over 20. More importantly, we found a significant divergence\nbetween features selected by SHAP and VoTE-XAI. However, none of the top-ranked\nfeatures selected by SHAP were missed by VoTE-XAI. When it comes to efficiency\nof providing interpretations, we found that VoTE-XAI is significantly more\nresponsive, e.g. it provides a single explanation in under 0.002 seconds, in a\nhigh-dimensional setting (478 features).", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e865G\u7f51\u7edc\u5b89\u5168\u4e2d\u7684\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\u6280\u672f\uff0c\u6bd4\u8f83SHAP\u548cVoTE-XAI\u5728\u653b\u51fb\u8b66\u62a5\u89e3\u91ca\u65b9\u9762\u7684\u6027\u80fd\u3002VoTE-XAI\u5728\u7b80\u6d01\u6027\u3001\u7a33\u5b9a\u6027\u548c\u6548\u7387\u65b9\u9762\u90fd\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u968f\u77405G\u7f51\u7edc\u5728\u5173\u952e\u5e94\u7528\u4e2d\u7684\u666e\u53ca\uff0c\u9700\u8981\u4ece\u4f20\u7edf\u7684\u6076\u610f\u6d3b\u52a8\u68c0\u6d4b\u8f6c\u5411\u80fd\u591f\u63d0\u4f9b\u53ef\u9760\u5224\u65ad\u7684\u7cfb\u7edf\u3002\u7406\u89e3\u548c\u89e3\u91caML\u6a21\u578b\u7684\u5b89\u5168\u8b66\u62a5\u5bf9\u4e8e\u542f\u52a8\u53ef\u884c\u52a8\u7684\u4e8b\u4ef6\u54cd\u5e94\u81f4\u5173\u91cd\u8981\u3002", "method": "\u7814\u7a76\u4e86\u4e24\u79cdXAI\u65b9\u6cd5\uff1aSHAP\uff08\u57fa\u4e8e\u7edf\u8ba1\u5f52\u56e0\uff09\u548cVoTE-XAI\uff08\u57fa\u4e8e\u903b\u8f91\u89e3\u91ca\uff09\u3002\u5728\u4e09\u4e2a\u4e0d\u540c\u76845G\u901a\u4fe1\u653b\u51fb\u573a\u666f\u4e0b\uff0c\u5206\u6790\u5b83\u4eec\u5bf9XGBoost\u6a21\u578b\u8b66\u62a5\u7684\u89e3\u91ca\u80fd\u529b\u3002\u91c7\u7528\u4e09\u4e2a\u8bc4\u4f30\u6307\u6807\uff1a\u7a00\u758f\u6027\uff08\u7b80\u6d01\u7a0b\u5ea6\uff09\u3001\u7a33\u5b9a\u6027\uff08\u4e00\u81f4\u6027\uff09\u548c\u6548\u7387\uff08\u89e3\u91ca\u901f\u5ea6\uff09\u3002", "result": "\u572892\u4e2a\u7279\u5f81\u76845G\u7f51\u7edc\u4e2d\uff0cVoTE-XAI\u4ec5\u9009\u62e96\u4e2a\u5173\u952e\u7279\u5f81\u6765\u89e3\u91cadoS\u653b\u51fb\uff0c\u800cSHAP\u9009\u62e9\u4e86\u8d8520\u4e2a\u3002VoTE-XAI\u5728\u9ad8\u7ef4\u5ea6\u8bbe\u7f6e\uff08478\u7279\u5f81\uff09\u4e2d\u80fd\u57280.002\u79d2\u5185\u63d0\u4f9b\u5355\u4e2a\u89e3\u91ca\uff0c\u6548\u7387\u663e\u8457\u66f4\u9ad8\u3002\u867d\u7136\u4e24\u79cd\u65b9\u6cd5\u9009\u62e9\u7684\u7279\u5f81\u5b58\u5728\u660e\u663e\u5dee\u5f02\uff0c\u4f46SHAP\u7684\u9876\u90e8\u7279\u5f81\u90fd\u88abVoTE-XAI\u8986\u76d6\u3002", "conclusion": "\u903b\u8f91\u57fa\u4e8e\u7684VoTE-XAI\u65b9\u6cd5\u57285G\u7f51\u7edc\u5b89\u5168\u8b66\u62a5\u89e3\u91ca\u4e2d\u8868\u73b0\u66f4\u4f18\uff0c\u5177\u6709\u66f4\u597d\u7684\u7b80\u6d01\u6027\u3001\u7a33\u5b9a\u6027\u548c\u6548\u7387\u3002\u8fd9\u4e3a\u672a\u6765\u901a\u4fe1\u7cfb\u7edf\u7684\u53ef\u9760\u4e8b\u4ef6\u54cd\u5e94\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u91ca\u65b9\u6848\u3002"}}
{"id": "2509.09975", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.09975", "abs": "https://arxiv.org/abs/2509.09975", "authors": ["Takasaburo Fukuda", "Takao Nakagawa", "Keisuke Miyazaki", "Susumu Tokumoto"], "title": "Development of Automated Software Design Document Review Methods Using Large Language Models", "comment": "SANER 2025", "summary": "In this study, we explored an approach to automate the review process of\nsoftware design documents by using LLM. We first analyzed the review methods of\ndesign documents and organized 11 review perspectives. Additionally, we\nanalyzed the issues of utilizing LLMs for these 11 review perspectives and\ndetermined which perspectives can be reviewed by current general-purpose LLMs\ninstead of humans. For the reviewable perspectives, we specifically developed\nnew techniques to enable LLMs to comprehend complex design documents that\ninclude table data. For evaluation, we conducted experiments using GPT to\nassess the consistency of design items and descriptions across different design\ndocuments in the design process used in actual business operations. Our results\nconfirmed that LLMs can be utilized to identify inconsistencies in software\ndesign documents during the review process.", "AI": {"tldr": "\u4f7f\u7528LLM\u81ea\u52a8\u5316\u8f6f\u4ef6\u8bbe\u8ba1\u6587\u6863\u8bc4\u5ba1\u8fc7\u7a0b\uff0c\u8bc6\u522b\u8bbe\u8ba1\u6587\u6863\u4e2d\u7684\u4e0d\u4e00\u81f4\u6027\u95ee\u9898", "motivation": "\u81ea\u52a8\u5316\u8f6f\u4ef6\u8bbe\u8ba1\u6587\u6863\u8bc4\u5ba1\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u8bc4\u5ba1\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u51cf\u8f7b\u4eba\u5de5\u8bc4\u5ba1\u8d1f\u62c5", "method": "\u5206\u6790\u8bbe\u8ba1\u6587\u6863\u8bc4\u5ba1\u65b9\u6cd5\uff0c\u6574\u740611\u4e2a\u8bc4\u5ba1\u89c6\u89d2\uff0c\u5f00\u53d1\u65b0\u6280\u672f\u4f7fLLM\u80fd\u591f\u7406\u89e3\u5305\u542b\u8868\u683c\u6570\u636e\u7684\u590d\u6742\u8bbe\u8ba1\u6587\u6863\uff0c\u4f7f\u7528GPT\u8bc4\u4f30\u4e0d\u540c\u8bbe\u8ba1\u6587\u6863\u95f4\u8bbe\u8ba1\u9879\u548c\u63cf\u8ff0\u7684\u4e00\u81f4\u6027", "result": "\u786e\u8ba4LLM\u53ef\u4ee5\u5728\u8bc4\u5ba1\u8fc7\u7a0b\u4e2d\u8bc6\u522b\u8f6f\u4ef6\u8bbe\u8ba1\u6587\u6863\u4e2d\u7684\u4e0d\u4e00\u81f4\u6027", "conclusion": "LLM\u80fd\u591f\u6709\u6548\u7528\u4e8e\u8f6f\u4ef6\u8bbe\u8ba1\u6587\u6863\u7684\u81ea\u52a8\u5316\u8bc4\u5ba1\uff0c\u7279\u522b\u662f\u5728\u8bc6\u522b\u4e0d\u4e00\u81f4\u6027\u65b9\u9762\u8868\u73b0\u51fa\u826f\u597d\u6548\u679c"}}
{"id": "2509.09810", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09810", "abs": "https://arxiv.org/abs/2509.09810", "authors": ["Agnieszka Mensfelt", "David Tena Cucala", "Santiago Franco", "Angeliki Koutsoukou-Argyraki", "Vince Trencsenyi", "Kostas Stathis"], "title": "Towards a Common Framework for Autoformalization", "comment": null, "summary": "Autoformalization has emerged as a term referring to the automation of\nformalization - specifically, the formalization of mathematics using\ninteractive theorem provers (proof assistants). Its rapid development has been\ndriven by progress in deep learning, especially large language models (LLMs).\nMore recently, the term has expanded beyond mathematics to describe the broader\ntask of translating informal input into formal logical representations. At the\nsame time, a growing body of research explores using LLMs to translate informal\nlanguage into formal representations for reasoning, planning, and knowledge\nrepresentation - often without explicitly referring to this process as\nautoformalization. As a result, despite addressing similar tasks, the largely\nindependent development of these research areas has limited opportunities for\nshared methodologies, benchmarks, and theoretical frameworks that could\naccelerate progress. The goal of this paper is to review - explicit or implicit\n- instances of what can be considered autoformalization and to propose a\nunified framework, encouraging cross-pollination between different fields to\nadvance the development of next generation AI systems.", "AI": {"tldr": "\u81ea\u52a8\u5f62\u5f0f\u5316\u662f\u6307\u5c06\u975e\u5f62\u5f0f\u8f93\u5165\u7ffb\u8bd1\u4e3a\u5f62\u5f0f\u903b\u8f91\u8868\u793a\u7684\u8fc7\u7a0b\uff0c\u5305\u62ec\u6570\u5b66\u5b9a\u7406\u8bc1\u660e\u548c\u66f4\u5e7f\u6cdb\u7684\u903b\u8f91\u8868\u8fbe\u3002\u8fd1\u671f\u6df1\u5ea6\u5b66\u4e60\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8fdb\u6b65\u4fc3\u8fdb\u4e86\u8be5\u9886\u57df\u53d1\u5c55\uff0c\u4f46\u5404\u7814\u7a76\u9886\u57df\u76f8\u5bf9\u5b64\u7acb\u5f00\u53d1\u3002\u672c\u6587\u65e8\u5728\u7edf\u4e00\u6846\u67b6\uff0c\u63a8\u52a8\u9886\u57df\u4ea4\u53c9\u53d1\u5c55\u3002", "motivation": "\u81ea\u52a8\u5f62\u5f0f\u5316\u9886\u57df\u5728\u6df1\u5ea6\u5b66\u4e60\u548c\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u52a8\u4e0b\u5feb\u901f\u53d1\u5c55\uff0c\u4f46\u5404\u7814\u7a76\u9886\u57df\u76f8\u5bf9\u5b64\u7acb\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u65b9\u6cd5\u8bba\u3001\u6d4b\u8bd5\u6807\u51c6\u548c\u7406\u8bba\u6846\u67b6\uff0c\u9650\u5236\u4e86\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002\u9700\u8981\u5efa\u7acb\u7edf\u4e00\u6846\u67b6\u4ee5\u4fc3\u8fdb\u9886\u57df\u4ea4\u53c9\u53d1\u5c55\u3002", "method": "\u5bf9\u660e\u663e\u6216\u9690\u542b\u7684\u81ea\u52a8\u5f62\u5f0f\u5316\u7814\u7a76\u5b9e\u4f8b\u8fdb\u884c\u7efc\u8ff0\u68b3\u7406\uff0c\u5206\u6790\u5404\u7814\u7a76\u9886\u57df\u7684\u65b9\u6cd5\u548c\u6280\u672f\u3002\u5728\u6b64\u57fa\u7840\u4e0a\u63d0\u51fa\u7edf\u4e00\u7684\u6846\u67b6\u6982\u5ff5\uff0c\u4ee5\u4fc3\u8fdb\u4e0d\u540c\u9886\u57df\u95f4\u7684\u65b9\u6cd5\u8bba\u3001\u6d4b\u8bd5\u6807\u51c6\u548c\u7406\u8bba\u6846\u67b6\u7684\u5171\u4eab\u4e0e\u4ea4\u53c9\u3002", "result": "\u901a\u8fc7\u5bf9\u81ea\u52a8\u5f62\u5f0f\u5316\u9886\u57df\u7684\u7cfb\u7edf\u68b3\u7406\u548c\u5206\u6790\uff0c\u660e\u786e\u4e86\u8be5\u9886\u57df\u7684\u7814\u7a76\u72b6\u51b5\u3001\u6280\u672f\u8fdb\u5c55\u548c\u5b58\u5728\u95ee\u9898\u3002\u63d0\u51fa\u7684\u7edf\u4e00\u6846\u67b6\u4e3a\u4e0d\u540c\u7814\u7a76\u9886\u57df\u7684\u4ea4\u6d41\u4e0e\u5408\u4f5c\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u5f62\u6210\u5171\u4eab\u7684\u65b9\u6cd5\u8bba\u3001\u6d4b\u8bd5\u6807\u51c6\u548c\u7406\u8bba\u6846\u67b6\u3002", "conclusion": "\u81ea\u52a8\u5f62\u5f0f\u5316\u5728\u6570\u5b66\u5b9a\u7406\u8bc1\u660e\u548c\u903b\u8f91\u8868\u8fbe\u7b49\u9886\u57df\u5177\u6709\u5e7f\u9614\u5e94\u7528\u524d\u666f\uff0c\u662f\u53d1\u5c55\u4e0b\u4e00\u4ee3\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u5173\u952e\u6280\u672f\u3002\u901a\u8fc7\u5efa\u7acb\u7edf\u4e00\u6846\u67b6\u548c\u63a8\u52a8\u9886\u57df\u4ea4\u53c9\uff0c\u53ef\u4ee5\u52a0\u901f\u81ea\u52a8\u5f62\u5f0f\u5316\u6280\u672f\u7684\u53d1\u5c55\uff0c\u4e3a\u66f4\u9ad8\u7ea7\u5229\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u652f\u6491\u3002"}}
{"id": "2509.10213", "categories": ["cs.CR", "D.4.6; K.6.5"], "pdf": "https://arxiv.org/pdf/2509.10213", "abs": "https://arxiv.org/abs/2509.10213", "authors": ["Ming Zhou", "Xupu Hu", "Zhihao Wang", "Haining Wang", "Hui Wen", "Limin Sun", "Peng Zhang"], "title": "Dynamic Vulnerability Patching for Heterogeneous Embedded Systems Using Stack Frame Reconstruction", "comment": "Accepted/To be published in ACM CCS 2025", "summary": "Existing dynamic vulnerability patching techniques are not well-suited for\nembedded devices, especially mission-critical ones such as medical equipment,\nas they have limited computational power and memory but uninterrupted service\nrequirements. Those devices often lack sufficient idle memory for dynamic\npatching, and the diverse architectures of embedded systems further complicate\nthe creation of patch triggers that are compatible across various system\nkernels and hardware platforms. To address these challenges, we propose a hot\npatching framework called StackPatch that facilitates patch development based\non stack frame reconstruction. StackPatch introduces different triggering\nstrategies to update programs stored in memory units. We leverage the\nexception-handling mechanisms commonly available in embedded processors to\nenhance StackPatch's adaptability across different processor architectures for\ncontrol flow redirection. We evaluated StackPatch on embedded devices featuring\nthree major microcontroller (MCU) architectures: ARM, RISC-V, and Xtensa. In\nthe experiments, we used StackPatch to successfully fix 102 publicly disclosed\nvulnerabilities in real-time operating systems (RTOS). We applied patching to\nmedical devices, soft programmable logic controllers (PLCs), and network\nservices, with StackPatch consistently completing each vulnerability\nremediation in less than 260 MCU clock cycles.", "AI": {"tldr": "StackPatch\u662f\u4e00\u4e2a\u9488\u5bf9\u5d4c\u5165\u5f0f\u8bbe\u5907\u7684\u52a8\u6001\u70ed\u8865\u4e01\u6846\u67b6\uff0c\u901a\u8fc7\u6808\u5e27\u91cd\u5efa\u548c\u5f02\u5e38\u5904\u7406\u673a\u5236\u5b9e\u73b0\u8de8\u67b6\u6784\u6f0f\u6d1e\u4fee\u590d\uff0c\u5728ARM\u3001RISC-V\u548cXtensa\u4e09\u79cdMCU\u67b6\u6784\u4e0a\u6210\u529f\u4fee\u590d\u4e86102\u4e2aRTOS\u6f0f\u6d1e\uff0c\u6bcf\u6b21\u4fee\u590d\u8017\u65f6\u5c11\u4e8e260\u4e2a\u65f6\u949f\u5468\u671f\u3002", "motivation": "\u73b0\u6709\u52a8\u6001\u6f0f\u6d1e\u4fee\u8865\u6280\u672f\u4e0d\u9002\u7528\u4e8e\u5d4c\u5165\u5f0f\u8bbe\u5907\uff0c\u7279\u522b\u662f\u533b\u7597\u8bbe\u5907\u7b49\u5173\u952e\u4efb\u52a1\u8bbe\u5907\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u8bbe\u5907\u8ba1\u7b97\u80fd\u529b\u6709\u9650\u3001\u5185\u5b58\u4e0d\u8db3\u4f46\u9700\u8981\u4e0d\u95f4\u65ad\u670d\u52a1\uff0c\u4e14\u7f3a\u4e4f\u7edf\u4e00\u7684\u8865\u4e01\u89e6\u53d1\u673a\u5236\u3002", "method": "\u57fa\u4e8e\u6808\u5e27\u91cd\u5efa\u7684\u8865\u4e01\u5f00\u53d1\u6846\u67b6\uff0c\u5229\u7528\u5d4c\u5165\u5f0f\u5904\u7406\u5668\u5e38\u89c1\u7684\u5f02\u5e38\u5904\u7406\u673a\u5236\u5b9e\u73b0\u63a7\u5236\u6d41\u91cd\u5b9a\u5411\uff0c\u91c7\u7528\u4e0d\u540c\u7684\u89e6\u53d1\u7b56\u7565\u66f4\u65b0\u5185\u5b58\u5355\u5143\u4e2d\u7684\u7a0b\u5e8f\u3002", "result": "\u5728\u4e09\u79cd\u4e3b\u8981MCU\u67b6\u6784\uff08ARM\u3001RISC-V\u3001Xtensa\uff09\u4e0a\u6210\u529f\u4fee\u590d102\u4e2a\u516c\u5f00\u6f0f\u6d1e\uff0c\u5e94\u7528\u4e8e\u533b\u7597\u8bbe\u5907\u3001\u8f6fPLC\u548c\u7f51\u7edc\u670d\u52a1\uff0c\u6bcf\u6b21\u6f0f\u6d1e\u4fee\u590d\u8017\u65f6\u5c11\u4e8e260\u4e2aMCU\u65f6\u949f\u5468\u671f\u3002", "conclusion": "StackPatch\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5d4c\u5165\u5f0f\u8bbe\u5907\u52a8\u6001\u8865\u4e01\u7684\u6280\u672f\u6311\u6218\uff0c\u5177\u6709\u8de8\u67b6\u6784\u9002\u5e94\u6027\u548c\u9ad8\u6548\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u5173\u952e\u4efb\u52a1\u5d4c\u5165\u5f0f\u7cfb\u7edf\u3002"}}
{"id": "2509.10085", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.10085", "abs": "https://arxiv.org/abs/2509.10085", "authors": ["Philipp Zech", "Irdin Pekaric"], "title": "Sustaining Research Software: A Fitness Function Approach", "comment": null, "summary": "The long-term sustainability of research software is a critical challenge, as\nit usually suffers from poor maintainability, lack of adaptability, and\neventual obsolescence. This paper proposes a novel approach to addressing this\nissue by leveraging the concept of fitness functions from evolutionary\narchitecture. Fitness functions are automated, continuously evaluated metrics\ndesigned to ensure that software systems meet desired non-functional,\narchitectural qualities over time. We define a set of fitness functions\ntailored to the unique requirements of research software, focusing on\nfindability, accessibility, interoperability and reusability (FAIR). These\nfitness functions act as proactive safeguards, promoting practices such as\nmodular design, comprehensive documentation, version control, and compatibility\nwith evolving technological ecosystems. By integrating these metrics into the\ndevelopment life cycle, we aim to foster a culture of sustainability within the\nresearch community. Case studies and experimental results demonstrate the\npotential of this approach to enhance the long-term FAIR of research software,\nbridging the gap between ephemeral project-based development and enduring\nscientific impact.", "AI": {"tldr": "\u901a\u8fc7\u5e94\u7528\u8fdb\u5316\u67b6\u6784\u4e2d\u7684\u9002\u5e94\u6027\u51fd\u6570\u6982\u5ff5\uff0c\u4e3a\u79d1\u7814\u8f6f\u4ef6\u5b9a\u5236\u81ea\u52a8\u5316\u6307\u6807\uff0c\u63d0\u9ad8\u5176\u53ef\u53d1\u73b0\u6027\u3001\u53ef\u8bbf\u95ee\u6027\u3001\u4e92\u64cd\u6027\u548c\u53ef\u91cd\u7528\u6027\uff0c\u4ee5\u4fc3\u8fdb\u957f\u671f\u53ef\u6301\u7eed\u6027\u3002", "motivation": "\u79d1\u7814\u8f6f\u4ef6\u9762\u4e34\u7ef4\u62a4\u6027\u5dee\u3001\u9002\u5e94\u6027\u4e0d\u8db3\u548c\u6f5c\u5728\u6fc0\u6d4b\u7b49\u957f\u671f\u53ef\u6301\u7eed\u6027\u6311\u6218\uff0c\u9700\u8981\u4e3b\u52a8\u63a7\u5236\u63aa\u65bd\u6765\u4fdd\u969c\u5176\u6301\u4e45\u79d1\u5b66\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u8fdb\u5316\u67b6\u6784\u4e2d\u7684\u9002\u5e94\u6027\u51fd\u6570\u6982\u5ff5\uff0c\u5b9a\u5236\u4e00\u7cfb\u5217\u81ea\u52a8\u5316\u6301\u7eed\u8bc4\u4f30\u7684\u6307\u6807\uff0c\u91cd\u70b9\u5173\u6ce8FAIR\u539f\u5219\uff08\u53ef\u53d1\u73b0\u3001\u53ef\u8bbf\u95ee\u3001\u4e92\u64cd\u4f5c\u3001\u53ef\u91cd\u7528\uff09\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u5230\u5f00\u53d1\u751f\u547d\u5468\u671f\u4e2d\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u548c\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347\u79d1\u7814\u8f6f\u4ef6\u7684\u957f\u671fFAIR\u6027\u80fd\uff0c\u7f29\u5c0f\u77ed\u671f\u9879\u76ee\u5f00\u53d1\u4e0e\u6301\u4e45\u79d1\u5b66\u4ef7\u503c\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "conclusion": "\u901a\u8fc7\u9002\u5e94\u6027\u51fd\u6570\u63a8\u52a8\u6a21\u5757\u5316\u8bbe\u8ba1\u3001\u5168\u9762\u6587\u6863\u3001\u7248\u672c\u63a7\u5236\u7b49\u6700\u4f73\u5b9e\u8df5\uff0c\u53ef\u5728\u79d1\u7814\u793e\u533a\u57f9\u517b\u53ef\u6301\u7eed\u6027\u6587\u5316\uff0c\u786e\u4fdd\u79d1\u7814\u8f6f\u4ef6\u7684\u957f\u671f\u751f\u5b58\u80fd\u529b\u548c\u79d1\u5b66\u4ef7\u503c\u3002"}}
{"id": "2509.09848", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09848", "abs": "https://arxiv.org/abs/2509.09848", "authors": ["Nana Han", "Dong Liu", "Tomas Norton"], "title": "Towards an AI-based knowledge assistant for goat farmers based on Retrieval-Augmented Generation", "comment": null, "summary": "Large language models (LLMs) are increasingly being recognised as valuable\nknowledge communication tools in many industries. However, their application in\nlivestock farming remains limited, being constrained by several factors not\nleast the availability, diversity and complexity of knowledge sources. This\nstudy introduces an intelligent knowledge assistant system designed to support\nhealth management in farmed goats. Leveraging the Retrieval-Augmented\nGeneration (RAG), two structured knowledge processing methods, table\ntextualization and decision-tree textualization, were proposed to enhance large\nlanguage models' (LLMs) understanding of heterogeneous data formats. Based on\nthese methods, a domain-specific goat farming knowledge base was established to\nimprove LLM's capacity for cross-scenario generalization. The knowledge base\nspans five key domains: Disease Prevention and Treatment, Nutrition Management,\nRearing Management, Goat Milk Management, and Basic Farming Knowledge.\nAdditionally, an online search module is integrated to enable real-time\nretrieval of up-to-date information. To evaluate system performance, six\nablation experiments were conducted to examine the contribution of each\ncomponent. The results demonstrated that heterogeneous knowledge fusion method\nachieved the best results, with mean accuracies of 87.90% on the validation set\nand 84.22% on the test set. Across the text-based, table-based, decision-tree\nbased Q&A tasks, accuracy consistently exceeded 85%, validating the\neffectiveness of structured knowledge fusion within a modular design. Error\nanalysis identified omission as the predominant error category, highlighting\nopportunities to further improve retrieval coverage and context integration. In\nconclusion, the results highlight the robustness and reliability of the\nproposed system for practical applications in goat farming.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eRAG\u7684\u667a\u80fd\u77e5\u8bc6\u52a9\u624b\u7cfb\u7edf\uff0c\u4e13\u95e8\u7528\u4e8e\u5c71\u7f8a\u517b\u6b96\u5065\u5eb7\u7ba1\u7406\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u77e5\u8bc6\u5904\u7406\u65b9\u6cd5\u63d0\u5347LLM\u5bf9\u5f02\u6784\u6570\u636e\u7684\u7406\u89e3\u80fd\u529b\uff0c\u5728\u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6\u4e0a\u5206\u522b\u8fbe\u523087.90%\u548c84.22%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u755c\u7267\u4e1a\u5e94\u7528\u53d7\u9650\uff0c\u4e3b\u8981\u7531\u4e8e\u77e5\u8bc6\u6e90\u7684\u53ef\u7528\u6027\u3001\u591a\u6837\u6027\u548c\u590d\u6742\u6027\u9650\u5236\uff0c\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u7684\u77e5\u8bc6\u5904\u7406\u65b9\u6cd5\u6765\u652f\u6301\u5c71\u7f8a\u517b\u6b96\u7684\u5065\u5eb7\u7ba1\u7406\u3002", "method": "\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u6280\u672f\uff0c\u63d0\u51fa\u8868\u683c\u6587\u672c\u5316\u548c\u51b3\u7b56\u6811\u6587\u672c\u5316\u4e24\u79cd\u7ed3\u6784\u5316\u77e5\u8bc6\u5904\u7406\u65b9\u6cd5\uff0c\u5efa\u7acb\u5305\u542b\u4e94\u4e2a\u5173\u952e\u9886\u57df\u7684\u5c71\u7f8a\u517b\u6b96\u77e5\u8bc6\u5e93\uff0c\u5e76\u96c6\u6210\u5728\u7ebf\u641c\u7d22\u6a21\u5757\u5b9e\u73b0\u5b9e\u65f6\u4fe1\u606f\u68c0\u7d22\u3002", "result": "\u5f02\u6784\u77e5\u8bc6\u878d\u5408\u65b9\u6cd5\u6548\u679c\u6700\u4f73\uff0c\u9a8c\u8bc1\u96c6\u51c6\u786e\u738787.90%\uff0c\u6d4b\u8bd5\u96c684.22%\u3002\u5728\u6587\u672c\u3001\u8868\u683c\u3001\u51b3\u7b56\u6811\u95ee\u7b54\u4efb\u52a1\u4e2d\u51c6\u786e\u7387\u5747\u8d85\u8fc785%\uff0c\u8bc1\u660e\u4e86\u6a21\u5757\u5316\u8bbe\u8ba1\u4e2d\u7ed3\u6784\u5316\u77e5\u8bc6\u878d\u5408\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\u6240\u63d0\u51fa\u7684\u7cfb\u7edf\u5728\u5c71\u7f8a\u517b\u6b96\u5b9e\u9645\u5e94\u7528\u4e2d\u5177\u6709\u9c81\u68d2\u6027\u548c\u53ef\u9760\u6027\uff0c\u9519\u8bef\u5206\u6790\u663e\u793a\u9057\u6f0f\u662f\u4e3b\u8981\u9519\u8bef\u7c7b\u578b\uff0c\u4e3a\u8fdb\u4e00\u6b65\u6539\u8fdb\u68c0\u7d22\u8986\u76d6\u548c\u4e0a\u4e0b\u6587\u6574\u5408\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2509.10224", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.10224", "abs": "https://arxiv.org/abs/2509.10224", "authors": ["Reynaldo Gil-Pons", "Sjouke Mauw", "Rolando Trujillo-Rasua"], "title": "Empirical Evaluation of Memory-Erasure Protocols", "comment": "Published at SECRYPT 2025", "summary": "Software-based memory-erasure protocols are two-party communication protocols\nwhere a verifier instructs a computational device to erase its memory and send\na proof of erasure. They aim at guaranteeing that low-cost IoT devices are free\nof malware by putting them back into a safe state without requiring secure\nhardware or physical manipulation of the device. Several software-based\nmemory-erasure protocols have been introduced and theoretically analysed. Yet,\nmany of them have not been tested for their feasibility, performance and\nsecurity on real devices, which hinders their industry adoption. This article\nreports on the first empirical analysis of software-based memory-erasure\nprotocols with respect to their security, erasure guarantees, and performance.\nThe experimental setup consists of 3 modern IoT devices with different\ncomputational capabilities, 7 protocols, 6 hash-function implementations, and\nvarious performance and security criteria. Our results indicate that existing\nsoftware-based memory-erasure protocols are feasible, although slow devices may\ntake several seconds to erase their memory and generate a proof of erasure. We\nfound that no protocol dominates across all empirical settings, defined by the\ncomputational power and memory size of the device, the network speed, and the\nrequired level of security. Interestingly, network speed and hidden constants\nwithin the protocol specification played a more prominent role in the\nperformance of these protocols than anticipated based on the related\nliterature. We provide an evaluation framework that, given a desired level of\nsecurity, determines which protocols offer the best trade-off between\nperformance and erasure guarantees.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5bf9\u8f6f\u4ef6\u57fa\u5185\u5b58\u6e05\u9664\u534f\u8bae\u8fdb\u884c\u4e86\u9996\u6b21\u5b9e\u8bc1\u5206\u6790\uff0c\u57283\u79cdIoT\u8bbe\u5907\u4e0a\u6d4b\u8bd57\u79cd\u534f\u8bae\u7684\u5b89\u5168\u6027\u3001\u6e05\u9664\u4fdd\u8bc1\u548c\u6027\u80fd\u8868\u73b0\uff0c\u53d1\u73b0\u7f51\u7edc\u901f\u5ea6\u548c\u534f\u8bae\u9690\u85cf\u5e38\u6570\u5bf9\u6027\u80fd\u5f71\u54cd\u8f83\u5927\uff0c\u5e76\u63d0\u4f9b\u4e86\u5b89\u5168\u6027\u8bc4\u4f30\u6846\u67b6\u3002", "motivation": "\u8f6f\u4ef6\u57fa\u5185\u5b58\u6e05\u9664\u534f\u8bae\u53ef\u4ee5\u8ba9IoT\u8bbe\u5907\u4e0d\u9700\u8981\u5b89\u5168\u786c\u4ef6\u6216\u7269\u7406\u64cd\u4f5c\u5c31\u80fd\u6062\u590d\u5230\u5b89\u5168\u72b6\u6001\uff0c\u4f46\u4e4b\u524d\u7684\u534f\u8bae\u7f3a\u4e4f\u5b9e\u9645\u8bbe\u5907\u6d4b\u8bd5\uff0c\u5f71\u54cd\u4e86\u4e1a\u754c\u91c7\u7528\u3002", "method": "\u57283\u79cd\u4e0d\u540c\u8ba1\u7b97\u80fd\u529b\u7684\u73b0\u4ee3IoT\u8bbe\u5907\u4e0a\uff0c\u5bf96\u79cd\u54c8\u5e0c\u51fd\u6570\u5b9e\u73b0\u65b9\u5f0f\uff0c\u5bf97\u52307\u79cd\u5185\u5b58\u6e05\u9664\u534f\u8bae\u8fdb\u884c\u5b89\u5168\u6027\u3001\u6e05\u9664\u4fdd\u8bc1\u548c\u6027\u80fd\u7684\u5b9e\u9a8c\u5206\u6790\u3002", "result": "\u73b0\u6709\u534f\u8bae\u5728\u5b9e\u9645\u8bbe\u5907\u4e0a\u53ef\u884c\uff0c\u4f46\u901f\u5ea6\u6162\u7684\u8bbe\u5907\u9700\u8981\u51e0\u79d2\u949f\u5b8c\u6210\u6e05\u9664\u548c\u8bc1\u660e\u751f\u6210\uff1b\u6ca1\u6709\u4e00\u79cd\u534f\u8bae\u5728\u6240\u6709\u60c5\u51b5\u4e0b\u90fd\u6700\u4f18\uff0c\u7f51\u7edc\u901f\u5ea6\u548c\u534f\u8bae\u9690\u85cf\u5e38\u6570\u5bf9\u6027\u80fd\u5f71\u54cd\u8f83\u5927\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8bc4\u4f30\u6846\u67b6\uff0c\u53ef\u6839\u636e\u9700\u6c42\u7684\u5b89\u5168\u7ea7\u522b\u9009\u62e9\u6027\u80fd\u548c\u6e05\u9664\u4fdd\u8bc1\u6700\u4f73\u7684\u534f\u8bae\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u6307\u5357\u3002"}}
{"id": "2509.10099", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10099", "abs": "https://arxiv.org/abs/2509.10099", "authors": ["Radu Apsan", "Vincenzo Stoico", "Michel Albonico", "Rudra Dhar", "Karthik Vaidhyanathan", "Ivano Malavolta"], "title": "Generating Energy-Efficient Code via Large-Language Models -- Where are we now?", "comment": null, "summary": "Context. The rise of Large Language Models (LLMs) has led to their widespread\nadoption in development pipelines. Goal. We empirically assess the energy\nefficiency of Python code generated by LLMs against human-written code and code\ndeveloped by a Green software expert. Method. We test 363 solutions to 9 coding\nproblems from the EvoEval benchmark using 6 widespread LLMs with 4 prompting\ntechniques, and comparing them to human-developed solutions. Energy consumption\nis measured on three different hardware platforms: a server, a PC, and a\nRaspberry Pi for a total of ~881h (36.7 days). Results. Human solutions are 16%\nmore energy-efficient on the server and 3% on the Raspberry Pi, while LLMs\noutperform human developers by 25% on the PC. Prompting does not consistently\nlead to energy savings, where the most energy-efficient prompts vary by\nhardware platform. The code developed by a Green software expert is\nconsistently more energy-efficient by at least 17% to 30% against all LLMs on\nall hardware platforms. Conclusions. Even though LLMs exhibit relatively good\ncode generation capabilities, no LLM-generated code was more energy-efficient\nthan that of an experienced Green software developer, suggesting that as of\ntoday there is still a great need of human expertise for developing\nenergy-efficient Python code.", "AI": {"tldr": "\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684Python\u4ee3\u7801\u5728\u80fd\u8017\u6548\u7387\u65b9\u9762\u4e0e\u4eba\u7c7b\u5f00\u53d1\u8005\u5b58\u5728\u5dee\u5f02\uff0c\u7eff\u8272\u8f6f\u4ef6\u4e13\u5bb6\u7684\u4ee3\u7801\u80fd\u8017\u6548\u7387\u6700\u9ad8", "motivation": "\u8bc4\u4f30LLM\u751f\u6210\u7684Python\u4ee3\u7801\u7684\u80fd\u91cf\u6548\u7387\uff0c\u4e0e\u4eba\u7c7b\u5f00\u53d1\u8005\u548c\u7eff\u8272\u8f6f\u4ef6\u4e13\u5bb6\u7684\u4ee3\u7801\u8fdb\u884c\u5bf9\u6bd4", "method": "\u4f7f\u75286\u4e2a\u666e\u904dLLM\u548c4\u79cd\u63d0\u793a\u6280\u672f\uff0c\u6d4b\u8bd5363\u4e2a\u89e3\u51b3\u65b9\u6848\uff0c\u57283\u79cd\u786c\u4ef6\u5e73\u53f0\u4e0a\u6d4b\u91cf\u80fd\u91cf\u6d88\u8017\uff0c\u603b\u8ba1\u7ea636.7\u5929", "result": "\u4eba\u7c7b\u89e3\u51b3\u65b9\u6848\u5728\u670d\u52a1\u5668\u4e0a\u80fd\u8017\u6548\u7387\u9ad8\u51fa16%\uff0c\u5728PC\u4e0aLLM\u80fd\u8017\u6548\u7387\u9ad8\u51fa25%\uff0c\u7eff\u8272\u8f6f\u4ef6\u4e13\u5bb6\u4ee3\u7801\u5728\u6240\u6709\u5e73\u53f0\u4e0a\u80fd\u8017\u6548\u7387\u90fd\u6700\u9ad8\uff08\u81f330%\uff09", "conclusion": "\u867d\u7136LLM\u5c55\u73b0\u4e86\u8f83\u597d\u7684\u4ee3\u7801\u751f\u6210\u80fd\u529b\uff0c\u4f46\u65e0\u6cd5\u8d85\u8d8a\u7ecf\u9a8c\u4e30\u5bcc\u7684\u7eff\u8272\u8f6f\u4ef6\u5f00\u53d1\u8005\uff0c\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u5728\u5f00\u53d1\u80fd\u6548Python\u4ee3\u7801\u4e2d\u4ecd\u81f3\u5173\u91cd\u8981"}}
{"id": "2509.09867", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.09867", "abs": "https://arxiv.org/abs/2509.09867", "authors": ["Yago Romano Matinez", "Jesse Roberts"], "title": "LLMs as Agentic Cooperative Players in Multiplayer UNO", "comment": null, "summary": "LLMs promise to assist humans -- not just by answering questions, but by\noffering useful guidance across a wide range of tasks. But how far does that\nassistance go? Can a large language model based agent actually help someone\naccomplish their goal as an active participant? We test this question by\nengaging an LLM in UNO, a turn-based card game, asking it not to win but\ninstead help another player to do so. We built a tool that allows decoder-only\nLLMs to participate as agents within the RLCard game environment. These models\nreceive full game-state information and respond using simple text prompts under\ntwo distinct prompting strategies. We evaluate models ranging from small (1B\nparameters) to large (70B parameters) and explore how model scale impacts\nperformance. We find that while all models were able to successfully outperform\na random baseline when playing UNO, few were able to significantly aid another\nplayer.", "AI": {"tldr": "LLM\u667a\u80fd\u4f53\u5728UNO\u6e38\u620f\u4e2d\u4f5c\u4e3a\u52a9\u624b\u5e2e\u52a9\u5176\u4ed6\u73a9\u5bb6\u83b7\u80dc\u7684\u80fd\u529b\u6d4b\u8bd5\uff0c\u53d1\u73b0\u867d\u7136\u6a21\u578b\u80fd\u8d85\u8d8a\u968f\u673a\u57fa\u7ebf\u8868\u73b0\uff0c\u4f46\u5f88\u5c11\u80fd\u663e\u8457\u5e2e\u52a9\u5176\u4ed6\u73a9\u5bb6\u83b7\u80dc", "motivation": "\u6d4b\u8bd5\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u662f\u5426\u80fd\u4f5c\u4e3a\u4e3b\u52a8\u53c2\u4e0e\u8005\u771f\u6b63\u5e2e\u52a9\u4eba\u7c7b\u5b8c\u6210\u76ee\u6807\uff0c\u7279\u522b\u662f\u5728\u534f\u4f5c\u6027\u6e38\u620f\u4efb\u52a1\u4e2d\u7684\u8868\u73b0", "method": "\u6784\u5efa\u5de5\u5177\u8ba9\u4ec5\u89e3\u7801\u5668LLM\u5728RLCard\u6e38\u620f\u73af\u5883\u4e2d\u4f5c\u4e3a\u667a\u80fd\u4f53\u53c2\u4e0eUNO\u6e38\u620f\uff0c\u63a5\u6536\u5b8c\u6574\u6e38\u620f\u72b6\u6001\u4fe1\u606f\u5e76\u4f7f\u7528\u4e24\u79cd\u4e0d\u540c\u7684\u63d0\u793a\u7b56\u7565\u8fdb\u884c\u6587\u672c\u54cd\u5e94\uff0c\u8bc4\u4f30\u4ece1B\u523070B\u53c2\u6570\u7684\u4e0d\u540c\u89c4\u6a21\u6a21\u578b", "result": "\u6240\u6709\u6a21\u578b\u5728\u73a9UNO\u65f6\u90fd\u80fd\u6210\u529f\u8d85\u8d8a\u968f\u673a\u57fa\u7ebf\u8868\u73b0\uff0c\u4f46\u5f88\u5c11\u6709\u6a21\u578b\u80fd\u591f\u663e\u8457\u5e2e\u52a9\u5176\u4ed6\u73a9\u5bb6\u83b7\u80dc", "conclusion": "\u867d\u7136LLM\u5728\u5355\u72ec\u6e38\u620f\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u534f\u4f5c\u52a9\u4eba\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\u4ecd\u7136\u6709\u9650\uff0c\u6a21\u578b\u89c4\u6a21\u5bf9\u6027\u80fd\u6709\u5f71\u54cd\u4f46\u4e0d\u8db3\u4ee5\u5b9e\u73b0\u6709\u6548\u7684\u534f\u4f5c\u5e2e\u52a9"}}
{"id": "2509.10252", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.10252", "abs": "https://arxiv.org/abs/2509.10252", "authors": ["Yifan Jia", "Ye Tian", "Yanbin Wang", "Jianguo Sun", "Haitao Xu"], "title": "ExDoS: Expert-Guided Dual-Focus Cross-Modal Distillation for Smart Contract Vulnerability Detection", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "The success of smart contracts has made them a target for attacks, but their\nclosed-source nature often forces vulnerability detection to work on bytecode,\nwhich is inherently more challenging than source-code-based analysis. While\nrecent studies try to align source and bytecode embeddings during training to\ntransfer knowledge, current methods rely on graph-level alignment that obscures\nfine-grained structural and semantic correlations between the two modalities.\nMoreover, the absence of precise vulnerability patterns and granular\nannotations in bytecode leads to depriving the model of crucial supervisory\nsignals for learning discriminant features. We propose ExDoS to transfer rich\nsemantic knowledge from source code to bytecode, effectively supplementing the\nsource code prior in practical settings. Specifically, we construct semantic\ngraphs from source code and control-flow graphs from bytecode. To address\nobscured local signals in graph-level contract embeddings, we propose a\nDual-Attention Graph Network introducing a novel node attention aggregation\nmodule to enhance local pattern capture in graph embeddings. Furthermore, by\nsummarizing existing source code vulnerability patterns and designing a\ncorresponding set of bytecode-level patterns for each, we construct the first\ndataset of vulnerability pattern annotations aligned with source code\ndefinitions to facilitate fine-grained cross-modal alignment and the capture of\nfunction-level vulnerability signals. Finally, we propose a dual-focus\nobjective for our cross-modal distillation framework, comprising: a Global\nSemantic Distillation Loss for transferring graph-level knowledge and a Local\nSemantic Distillation Loss enabling expert-guided, fine-grained\nvulnerability-specific distillation. Experiments on real-world contracts\ndemonstrate that our method achieves consistent F1-score improvements\n(3\\%--6\\%) over strong baselines.", "AI": {"tldr": "ExDoS\u662f\u4e00\u4e2a\u8de8\u6a21\u6001\u6f0f\u6d1e\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u6ce8\u610f\u529b\u56fe\u7f51\u7edc\u548c\u7ec6\u7c92\u5ea6\u5bf9\u9f50\u673a\u5236\uff0c\u5c06\u6e90\u4ee3\u7801\u7684\u8bed\u4e49\u77e5\u8bc6\u8fc1\u79fb\u5230\u5b57\u8282\u7801\u4e2d\uff0c\u5728\u771f\u5b9e\u5408\u7ea6\u4e0a\u5b9e\u73b0\u4e863%-6%\u7684F1\u5206\u6570\u63d0\u5347\u3002", "motivation": "\u667a\u80fd\u5408\u7ea6\u7684\u95ed\u6e90\u7279\u6027\u4f7f\u5f97\u6f0f\u6d1e\u68c0\u6d4b\u53ea\u80fd\u5728\u5b57\u8282\u7801\u5c42\u9762\u8fdb\u884c\uff0c\u8fd9\u6bd4\u57fa\u4e8e\u6e90\u4ee3\u7801\u7684\u5206\u6790\u66f4\u5177\u6311\u6218\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u56fe\u7ea7\u5bf9\u9f50\uff0c\u6a21\u7cca\u4e86\u4e24\u79cd\u6a21\u6001\u95f4\u7684\u7ec6\u7c92\u5ea6\u7ed3\u6784\u548c\u8bed\u4e49\u5173\u8054\uff0c\u4e14\u7f3a\u4e4f\u7cbe\u786e\u7684\u6f0f\u6d1e\u6a21\u5f0f\u548c\u7ec6\u7c92\u5ea6\u6807\u6ce8\u3002", "method": "\u6784\u5efa\u6e90\u4ee3\u7801\u7684\u8bed\u4e49\u56fe\u548c\u5b57\u8282\u7801\u7684\u63a7\u5236\u6d41\u56fe\uff1b\u63d0\u51fa\u53cc\u6ce8\u610f\u529b\u56fe\u7f51\u7edc\uff0c\u5f15\u5165\u8282\u70b9\u6ce8\u610f\u529b\u805a\u5408\u6a21\u5757\u589e\u5f3a\u5c40\u90e8\u6a21\u5f0f\u6355\u83b7\uff1b\u6784\u5efa\u9996\u4e2a\u4e0e\u6e90\u4ee3\u7801\u5b9a\u4e49\u5bf9\u9f50\u7684\u6f0f\u6d1e\u6a21\u5f0f\u6807\u6ce8\u6570\u636e\u96c6\uff1b\u8bbe\u8ba1\u5305\u542b\u5168\u5c40\u8bed\u4e49\u84b8\u998f\u635f\u5931\u548c\u5c40\u90e8\u8bed\u4e49\u84b8\u998f\u635f\u5931\u7684\u53cc\u7126\u70b9\u76ee\u6807\u51fd\u6570\u3002", "result": "\u5728\u771f\u5b9e\u5408\u7ea6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u5f3a\u57fa\u7ebf\u5b9e\u73b0\u4e863%-6%\u7684F1\u5206\u6570\u4e00\u81f4\u63d0\u5347\u3002", "conclusion": "ExDoS\u901a\u8fc7\u6709\u6548\u7684\u8de8\u6a21\u6001\u77e5\u8bc6\u8fc1\u79fb\u548c\u7ec6\u7c92\u5ea6\u5bf9\u9f50\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b57\u8282\u7801\u5c42\u9762\u7684\u667a\u80fd\u5408\u7ea6\u6f0f\u6d1e\u68c0\u6d4b\u6027\u80fd\uff0c\u4e3a\u89e3\u51b3\u95ed\u6e90\u4ee3\u7801\u5206\u6790\u96be\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2509.10236", "categories": ["cs.SE", "cs.PF", "cs.PL"], "pdf": "https://arxiv.org/pdf/2509.10236", "abs": "https://arxiv.org/abs/2509.10236", "authors": ["Mingyi Li", "Junmin Xiao", "Siyan Chen", "Hui Ma", "Xi Chen", "Peihua Bao", "Liang Yuan", "Guangming Tan"], "title": "Stencil-Lifting: Hierarchical Recursive Lifting System for Extracting Summary of Stencil Kernel in Legacy Codes", "comment": "33 pages, 12 figures. Submitted to OOPSLA2'25", "summary": "We introduce Stencil-Lifting, a novel system for automatically converting\nstencil kernels written in low-level languages in legacy code into semantically\nequivalent Domain-Specific Language (DSL) implementations. Targeting the\nefficiency bottlenecks of existing verified lifting systems, Stencil-Lifting\nachieves scalable stencil kernel abstraction through two key innovations.\nFirst, we propose a hierarchical recursive lifting theory that represents\nstencil kernels, structured as nested loops, using invariant subgraphs, which\nare customized data dependency graphs that capture loop-carried computation and\nstructural invariants. Each vertex in the invariant subgraph is associated with\na predicate-based summary, encoding its computational semantics. By enforcing\nself-consistency across these summaries, Stencil-Lifting ensures the derivation\nof correct loop invariants and postconditions for nested loops, eliminating the\nneed for external verification. Second, we develop a hierarchical recursive\nlifting algorithm that guarantees termination through a convergent recursive\nprocess, avoiding the inefficiencies of search-based synthesis. The algorithm\nefficiently derives the valid summaries of stencil kernels, and its\ncompleteness is formally proven. We evaluate Stencil-Lifting on diverse stencil\nbenchmarks from two different suites and on four real-world applications.\nExperimental results demonstrate that Stencil-Lifting achieves 31.62$\\times$\nand 5.8$\\times$ speedups compared to the state-of-the-art verified lifting\nsystems STNG and Dexter, respectively, while maintaining full semantic\nequivalence. Our work significantly enhances the translation efficiency of\nlow-level stencil kernels to DSL implementations, effectively bridging the gap\nbetween legacy optimization techniques and modern DSL-based paradigms.", "AI": {"tldr": "Stencil-Lifting\u662f\u4e00\u4e2a\u81ea\u52a8\u5c06\u4f4e\u7ea7\u8bed\u8a00\u7f16\u5199\u7684\u6a21\u677f\u5185\u6838\u8f6c\u6362\u4e3a\u7b49\u6548DSL\u5b9e\u73b0\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u5206\u5c42\u9012\u5f52\u63d0\u5347\u7406\u8bba\u548c\u7b97\u6cd5\u5b9e\u73b0\u9ad8\u6548\u8f6c\u6362\uff0c\u76f8\u6bd4\u73b0\u6709\u7cfb\u7edf\u901f\u5ea6\u63d0\u5347\u663e\u8457\u3002", "motivation": "\u9488\u5bf9\u73b0\u6709\u9a8c\u8bc1\u63d0\u5347\u7cfb\u7edf\u5728\u6548\u7387\u4e0a\u7684\u74f6\u9888\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u9ad8\u6548\u5c06\u9057\u7559\u4ee3\u7801\u4e2d\u7684\u4f4e\u7ea7\u6a21\u677f\u5185\u6838\u8f6c\u6362\u4e3a\u73b0\u4ee3DSL\u5b9e\u73b0\u7684\u65b9\u6cd5\uff0c\u4ee5\u5f25\u5408\u4f20\u7edf\u4f18\u5316\u6280\u672f\u4e0e\u73b0\u4ee3DSL\u8303\u5f0f\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u9012\u5f52\u63d0\u5347\u7406\u8bba\uff0c\u4f7f\u7528\u4e0d\u53d8\u5b50\u56fe\u8868\u793a\u6a21\u677f\u5185\u6838\uff0c\u6bcf\u4e2a\u9876\u70b9\u5173\u8054\u57fa\u4e8e\u8c13\u8bcd\u7684\u6458\u8981\uff1b\u5f00\u53d1\u5206\u5c42\u9012\u5f52\u63d0\u5347\u7b97\u6cd5\uff0c\u901a\u8fc7\u6536\u655b\u9012\u5f52\u8fc7\u7a0b\u4fdd\u8bc1\u7ec8\u6b62\u6027\uff0c\u907f\u514d\u57fa\u4e8e\u641c\u7d22\u7684\u5408\u6210\u4f4e\u6548\u95ee\u9898\u3002", "result": "\u5728\u4e24\u4e2a\u4e0d\u540c\u6d4b\u8bd5\u5957\u4ef6\u7684\u591a\u6837\u5316\u6a21\u677f\u57fa\u51c6\u548c\u56db\u4e2a\u5b9e\u9645\u5e94\u7528\u4e0a\u8bc4\u4f30\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u7684STNG\u548cDexter\u7cfb\u7edf\u5206\u522b\u5b9e\u73b031.62\u500d\u548c5.8\u500d\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u5b8c\u5168\u8bed\u4e49\u7b49\u4ef7\u3002", "conclusion": "Stencil-Lifting\u663e\u8457\u63d0\u9ad8\u4e86\u4f4e\u7ea7\u6a21\u677f\u5185\u6838\u5230DSL\u5b9e\u73b0\u7684\u7ffb\u8bd1\u6548\u7387\uff0c\u6709\u6548\u8fde\u63a5\u4e86\u4f20\u7edf\u4f18\u5316\u6280\u672f\u548c\u73b0\u4ee3DSL\u8303\u5f0f\u3002"}}
{"id": "2509.09915", "categories": ["cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2509.09915", "abs": "https://arxiv.org/abs/2509.09915", "authors": ["Woong Shin", "Renan Souza", "Daniel Rosendo", "Fr\u00e9d\u00e9ric Suter", "Feiyi Wang", "Prasanna Balaprakash", "Rafael Ferreira da Silva"], "title": "The (R)evolution of Scientific Workflows in the Agentic AI Era: Towards Autonomous Science", "comment": null, "summary": "Modern scientific discovery increasingly requires coordinating distributed\nfacilities and heterogeneous resources, forcing researchers to act as manual\nworkflow coordinators rather than scientists. Advances in AI leading to AI\nagents show exciting new opportunities that can accelerate scientific discovery\nby providing intelligence as a component in the ecosystem. However, it is\nunclear how this new capability would materialize and integrate in the real\nworld. To address this, we propose a conceptual framework where workflows\nevolve along two dimensions which are intelligence (from static to intelligent)\nand composition (from single to swarm) to chart an evolutionary path from\ncurrent workflow management systems to fully autonomous, distributed scientific\nlaboratories. With these trajectories in mind, we present an architectural\nblueprint that can help the community take the next steps towards harnessing\nthe opportunities in autonomous science with the potential for 100x discovery\nacceleration and transformational scientific workflows.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.10287", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.10287", "abs": "https://arxiv.org/abs/2509.10287", "authors": ["Ye Tian", "Yifan Jia", "Yanbin Wang", "Jianguo Sun", "Zhiquan Liu", "Xiaowen Ling"], "title": "URL2Graph++: Unified Semantic-Structural-Character Learning for Malicious URL Detection", "comment": null, "summary": "Malicious URL detection remains a major challenge in cybersecurity, primarily\ndue to two factors: (1) the exponential growth of the Internet has led to an\nimmense diversity of URLs, making generalized detection increasingly difficult;\nand (2) attackers are increasingly employing sophisticated obfuscation\ntechniques to evade detection. We advocate that addressing these challenges\nfundamentally requires: (1) obtaining semantic understanding to improve\ngeneralization across vast and diverse URL sets, and (2) accurately modeling\ncontextual relationships within the structural composition of URLs. In this\npaper, we propose a novel malicious URL detection method combining\nmulti-granularity graph learning with semantic embedding to jointly capture\nsemantic, character-level, and structural features for robust URL analysis. To\nmodel internal dependencies within URLs, we first construct dual-granularity\nURL graphs at both subword and character levels, where nodes represent URL\ntokens/characters and edges encode co-occurrence relationships. To obtain\nfine-grained embeddings, we initialize node representations using a\ncharacter-level convolutional network. The two graphs are then processed\nthrough jointly trained Graph Convolutional Networks to learn consistent\ngraph-level representations, enabling the model to capture complementary\nstructural features that reflect co-occurrence patterns and character-level\ndependencies. Furthermore, we employ BERT to derive semantic representations of\nURLs for semantically aware understanding. Finally, we introduce a gated\ndynamic fusion network to combine the semantically enriched BERT\nrepresentations with the jointly optimized graph vectors, further enhancing\ndetection performance. We extensively evaluate our method across multiple\nchallenging dimensions. Results show our method exceeds SOTA performance,\nincluding against large language models.", "AI": {"tldr": "\u7efc\u5408\u591a\u7c92\u5ea6\u56fe\u5b66\u4e60\u4e0e\u8bed\u4e49\u5d4c\u5165\u7684\u6076\u610fURL\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b50\u8bcd\u548c\u5b57\u7b26\u53cc\u7c92\u5ea6\u56fe\u7ed3\u6784\u3001BERT\u8bed\u4e49\u8868\u5f81\u4ee5\u53ca\u95e8\u63a7\u52a8\u6001\u878d\u5408\u7f51\u7edc\uff0c\u5728\u591a\u4e2a\u6311\u6218\u6027\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u4e86\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u6076\u610fURL\u68c0\u6d4b\u9762\u4e34\u7684\u4e24\u5927\u6311\u6218\uff1a(1)\u7f51\u7edcURL\u6570\u91cf\u6307\u6570\u589e\u957f\u5bfc\u81f4\u68c0\u6d4b\u96be\u5ea6\u589e\u52a0\uff1b(2)\u653b\u51fb\u8005\u91c7\u7528\u66f4\u591a\u907f\u514d\u6280\u672f\u3002\u9700\u8981\u83b7\u5f97\u8bed\u4e49\u7406\u89e3\u6765\u6539\u5584\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u51c6\u786e\u5efa\u6a21URL\u7ed3\u6784\u5185\u90e8\u7684\u4e0a\u4e0b\u6587\u5173\u7cfb\u3002", "method": "1. \u6784\u5efa\u5b50\u8bcd\u548c\u5b57\u7b26\u53cc\u7c92\u5ea6URL\u56fe\u7ed3\u6784\uff0c\u8282\u70b9\u4ee3\u8868URL\u6807\u8bb0/\u5b57\u7b26\uff0c\u8fb9\u7f16\u7801\u5171\u73b0\u5173\u7cfb\n2. \u4f7f\u7528\u5b57\u7b26\u7ea7\u5377\u79ef\u7f51\u7edc\u521d\u59cb\u5316\u8282\u70b9\u8868\u5f81\n3. \u901a\u8fc7\u8054\u5408\u8bad\u7ec3\u7684\u56fe\u5377\u79ef\u7f51\u7edc\u5904\u7406\u4e24\u4e2a\u56fe\u5b66\u4e60\u4e00\u81f4\u7684\u56fe\u7ea7\u8868\u5f81\n4. \u4f7f\u7528BERT\u83b7\u53d6URL\u7684\u8bed\u4e49\u8868\u5f81\n5. \u4f7f\u7528\u95e8\u63a7\u52a8\u6001\u878d\u5408\u7f51\u7edc\u7ed3\u5408BERT\u8868\u5f81\u548c\u56fe\u5411\u91cf", "result": "\u65b9\u6cd5\u5728\u591a\u4e2a\u6311\u6218\u6027\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u4e86\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\uff0c\u5305\u62ec\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u4f18\u52bf", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u591a\u7c92\u5ea6\u56fe\u5b66\u4e60\u4e0e\u8bed\u4e49\u5d4c\u5165\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u540c\u65f6\u6293\u53d6URL\u7684\u8bed\u4e49\u3001\u5b57\u7b26\u7ea7\u548c\u7ed3\u6784\u7279\u5f81\uff0c\u5b9e\u73b0\u4e86\u66f4\u52a0\u7a33\u5065\u7684\u6076\u610fURL\u68c0\u6d4b\u6027\u80fd\u3002"}}
{"id": "2509.10279", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10279", "abs": "https://arxiv.org/abs/2509.10279", "authors": ["Pavel Plyusnin", "Aleksey Antonov", "Vasilii Ermakov", "Aleksandr Khaybriev", "Margarita Kikot", "Ilseyar Alimova", "Stanislav Moiseev"], "title": "Targeted Test Selection Approach in Continuous Integration", "comment": "Accepted at ICSME 2025", "summary": "In modern software development change-based testing plays a crucial role.\nHowever, as codebases expand and test suites grow, efficiently managing the\ntesting process becomes increasingly challenging, especially given the high\nfrequency of daily code commits. We propose Targeted Test Selection (T-TS), a\nmachine learning approach for industrial test selection. Our key innovation is\na data representation that represent commits as Bags-of-Words of changed files,\nincorporates cross-file and additional predictive features, and notably avoids\nthe use of coverage maps. Deployed in production, T-TS was comprehensively\nevaluated against industry standards and recent methods using both internal and\npublic datasets, measuring time efficiency and fault detection. On live\nindustrial data, T-TS selects only 15% of tests, reduces execution time by\n$5.9\\times$, accelerates the pipeline by $5.6\\times$, and detects over 95% of\ntest failures. The implementation is publicly available to support further\nresearch and practical adoption.", "AI": {"tldr": "T-TS\u662f\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u5de5\u4e1a\u6d4b\u8bd5\u9009\u62e9\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u4ee3\u7801\u63d0\u4ea4\u8868\u793a\u4e3a\u53d8\u66f4\u6587\u4ef6\u7684\u8bcd\u888b\uff0c\u907f\u514d\u4f7f\u7528\u8986\u76d6\u7387\u6620\u5c04\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6d4b\u8bd5\u6548\u7387\u3002", "motivation": "\u968f\u7740\u4ee3\u7801\u5e93\u6269\u5c55\u548c\u6d4b\u8bd5\u5957\u4ef6\u589e\u957f\uff0c\u5728\u9ad8\u9891\u7387\u4ee3\u7801\u63d0\u4ea4\u73af\u5883\u4e0b\uff0c\u9ad8\u6548\u7ba1\u7406\u6d4b\u8bd5\u8fc7\u7a0b\u53d8\u5f97\u65e5\u76ca\u56f0\u96be\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u6d4b\u8bd5\u9009\u62e9\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u5c06\u4ee3\u7801\u63d0\u4ea4\u8868\u793a\u4e3a\u53d8\u66f4\u6587\u4ef6\u7684\u8bcd\u888b\u8868\u793a\uff0c\u878d\u5165\u8de8\u6587\u4ef6\u548c\u989d\u5916\u9884\u6d4b\u7279\u5f81\uff0c\u907f\u514d\u4f7f\u7528\u4f20\u7edf\u7684\u8986\u76d6\u7387\u6620\u5c04\u3002", "result": "\u5728\u751f\u4ea7\u73af\u5883\u4e2d\uff0cT-TS\u4ec5\u9009\u62e915%\u7684\u6d4b\u8bd5\uff0c\u6267\u884c\u65f6\u95f4\u51cf\u5c115.9\u500d\uff0c\u6d41\u6c34\u7ebf\u52a0\u901f5.6\u500d\uff0c\u68c0\u6d4b\u8d85\u8fc795%\u7684\u6d4b\u8bd5\u5931\u8d25\u3002", "conclusion": "T-TS\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u663e\u8457\u63d0\u5347\u6d4b\u8bd5\u6548\u7387\uff0c\u5b9e\u73b0\u5df2\u516c\u5f00\u4ee5\u652f\u6301\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2509.09919", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09919", "abs": "https://arxiv.org/abs/2509.09919", "authors": ["Franklin Yiu", "Mohan Lu", "Nina Li", "Kevin Joseph", "Tianxu Zhang", "Julian Togelius", "Timothy Merino", "Sam Earle"], "title": "A Markovian Framing of WaveFunctionCollapse for Procedurally Generating Aesthetically Complex Environments", "comment": null, "summary": "Procedural content generation often requires satisfying both\ndesigner-specified objectives and adjacency constraints implicitly imposed by\nthe underlying tile set. To address the challenges of jointly optimizing both\nconstraints and objectives, we reformulate WaveFunctionCollapse (WFC) as a\nMarkov Decision Process (MDP), enabling external optimization algorithms to\nfocus exclusively on objective maximization while leveraging WFC's propagation\nmechanism to enforce constraint satisfaction. We empirically compare optimizing\nthis MDP to traditional evolutionary approaches that jointly optimize global\nmetrics and local tile placement. Across multiple domains with various\ndifficulties, we find that joint optimization not only struggles as task\ncomplexity increases, but consistently underperforms relative to optimization\nover the WFC-MDP, underscoring the advantages of decoupling local constraint\nsatisfaction from global objective optimization.", "AI": {"tldr": "\u5c06WaveFunctionCollapse\u91cd\u6784\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5206\u79bb\u5c40\u90e8\u7ea6\u675f\u6ee1\u8db3\u548c\u5168\u5c40\u76ee\u6807\u4f18\u5316\uff0c\u76f8\u6bd4\u4f20\u7edf\u8054\u5408\u4f18\u5316\u65b9\u6cd5\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u4f18", "motivation": "\u89e3\u51b3\u7a0b\u5e8f\u5316\u5185\u5bb9\u751f\u6210\u4e2d\u9700\u8981\u540c\u65f6\u6ee1\u8db3\u8bbe\u8ba1\u8005\u6307\u5b9a\u76ee\u6807\u548c\u74e6\u7247\u96c6\u9690\u542b\u90bb\u63a5\u7ea6\u675f\u7684\u6311\u6218\uff0c\u4f20\u7edf\u8054\u5408\u4f18\u5316\u65b9\u6cd5\u5728\u4efb\u52a1\u590d\u6742\u5ea6\u589e\u52a0\u65f6\u8868\u73b0\u4e0d\u4f73", "method": "\u5c06WaveFunctionCollapse\u91cd\u65b0\u8868\u8ff0\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b(MDP)\uff0c\u5229\u7528WFC\u7684\u4f20\u64ad\u673a\u5236\u5f3a\u5236\u6267\u884c\u7ea6\u675f\u6ee1\u8db3\uff0c\u8ba9\u5916\u90e8\u4f18\u5316\u7b97\u6cd5\u4e13\u6ce8\u4e8e\u76ee\u6807\u6700\u5927\u5316", "result": "\u5728\u591a\u9886\u57df\u4e0d\u540c\u96be\u5ea6\u4efb\u52a1\u4e2d\uff0c\u8054\u5408\u4f18\u5316\u65b9\u6cd5\u968f\u7740\u4efb\u52a1\u590d\u6742\u5ea6\u589e\u52a0\u800c\u56f0\u96be\uff0c\u4e14\u59cb\u7ec8\u4e0d\u5982\u57fa\u4e8eWFC-MDP\u7684\u4f18\u5316\u65b9\u6cd5", "conclusion": "\u5c06\u5c40\u90e8\u7ea6\u675f\u6ee1\u8db3\u4e0e\u5168\u5c40\u76ee\u6807\u4f18\u5316\u89e3\u8026\u5177\u6709\u660e\u663e\u4f18\u52bf\uff0cWFC-MDP\u65b9\u6cd5\u5728\u7a0b\u5e8f\u5316\u5185\u5bb9\u751f\u6210\u4e2d\u4f18\u4e8e\u4f20\u7edf\u8054\u5408\u4f18\u5316\u65b9\u6cd5"}}
{"id": "2509.10313", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.10313", "abs": "https://arxiv.org/abs/2509.10313", "authors": ["Hamish Alsop", "Leandros Maglaras", "Helge Janicke", "Iqbal H. Sarker", "Mohamed Amine Ferrag"], "title": "Innovating Augmented Reality Security: Recent E2E Encryption Approaches", "comment": null, "summary": "End-to-end encryption (E2EE) has emerged as a fundamental element of modern\ndigital communication, protecting data from unauthorized access during\ntransmission. By design, E2EE ensures that only the intended recipient can\ndecrypt the information, making it inaccessible even to service providers. Yet,\nthis powerful safeguard of individual privacy and digital trust also introduces\na paradox: it can simultaneously prevent law enforcement efforts by hiding\npotential malicious activities. This paper examines the dual role of E2EE, its\ncritical importance to privacy, the challenges it", "AI": {"tldr": "\u7aef\u5230\u7aef\u52a0\u5bc6(E2EE)\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u4e5f\u7ed9\u6267\u6cd5\u5e26\u6765\u6311\u6218\uff0c\u5b58\u5728\u9690\u79c1\u4e0e\u5b89\u5168\u7684\u6096\u8bba", "motivation": "\u63a2\u8ba8E2EE\u6280\u672f\u5728\u4fdd\u62a4\u4e2a\u4eba\u9690\u79c1\u548c\u6570\u5b57\u4fe1\u4efb\u65b9\u9762\u7684\u5173\u952e\u4f5c\u7528\uff0c\u540c\u65f6\u5206\u6790\u5176\u5bf9\u6267\u6cd5\u5de5\u4f5c\u9020\u6210\u7684\u969c\u788d\uff0c\u7814\u7a76\u8fd9\u4e00\u6280\u672f\u5e26\u6765\u7684\u53cc\u91cd\u89d2\u8272\u548c\u77db\u76fe", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790E2EE\u7684\u6280\u672f\u539f\u7406\u548c\u5de5\u4f5c\u673a\u5236\uff0c\u7ed3\u5408\u9690\u79c1\u4fdd\u62a4\u4e0e\u6267\u6cd5\u9700\u6c42\u7684\u5bf9\u6bd4\u7814\u7a76\uff0c\u63a2\u8ba8\u6280\u672f\u5b9e\u73b0\u4e0e\u653f\u7b56\u76d1\u7ba1\u7684\u5e73\u8861\u70b9", "result": "E2EE\u786e\u5b9e\u5728\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u65b9\u9762\u53d1\u6325\u91cd\u8981\u4f5c\u7528\uff0c\u4f46\u540c\u65f6\u4e5f\u4e3a\u6076\u610f\u6d3b\u52a8\u63d0\u4f9b\u4e86\u9690\u853d\u7a7a\u95f4\uff0c\u5f62\u6210\u4e86\u9690\u79c1\u4fdd\u62a4\u4e0e\u516c\u5171\u5b89\u5168\u4e4b\u95f4\u7684\u7d27\u5f20\u5173\u7cfb", "conclusion": "\u9700\u8981\u5728\u6280\u672f\u8bbe\u8ba1\u3001\u653f\u7b56\u5236\u5b9a\u548c\u793e\u4f1a\u5171\u8bc6\u7b49\u591a\u4e2a\u5c42\u9762\u5bfb\u6c42\u5e73\u8861\uff0c\u65e2\u4fdd\u62a4\u4e2a\u4eba\u9690\u79c1\u6743\u5229\uff0c\u53c8\u4e0d\u59a8\u788d\u5fc5\u8981\u7684\u6267\u6cd5\u5de5\u4f5c\uff0c\u8fd9\u9700\u8981\u6280\u672f\u521b\u65b0\u4e0e\u6cd5\u5f8b\u6846\u67b6\u7684\u534f\u540c\u53d1\u5c55"}}
{"id": "2509.10402", "categories": ["cs.SE", "D.2.0; D.2.7"], "pdf": "https://arxiv.org/pdf/2509.10402", "abs": "https://arxiv.org/abs/2509.10402", "authors": ["Suzhen Zhong", "Ying Zou", "Bram Adams"], "title": "Developer-LLM Conversations: An Empirical Study of Interactions and Generated Code Quality", "comment": null, "summary": "Large Language Models (LLMs) are becoming integral to modern software\ndevelopment workflows, assisting developers with code generation, API\nexplanation, and iterative problem-solving through natural language\nconversations. Despite widespread adoption, there is limited understanding of\nhow developers interact with LLMs in practice and how these conversational\ndynamics influence task outcomes, code quality, and software engineering\nworkflows. To address this, we leverage CodeChat, a large dataset comprising\n82,845 real-world developer-LLM conversations, containing 368,506 code snippets\ngenerated across over 20 programming languages, derived from the WildChat\ndataset. We find that LLM responses are substantially longer than developer\nprompts, with a median token-length ratio of 14:1. Multi-turn conversations\naccount for 68% of the dataset and often evolve due to shifting requirements,\nincomplete prompts, or clarification requests. Topic analysis identifies web\ndesign (9.6% of conversations) and neural network training (8.7% of\nconversations) as the most frequent LLM-assisted tasks. Evaluation across five\nlanguages (i.e., Python, JavaScript, C++, Java, and C#) reveals prevalent and\nlanguage-specific issues in LLM-generated code: generated Python and JavaScript\ncode often include undefined variables (83.4% and 75.3% of code snippets,\nrespectively); Java code lacks required comments (75.9%); C++ code frequently\nomits headers (41.1%) and C# code shows unresolved namespaces (49.2%). During a\nconversation, syntax and import errors persist across turns; however,\ndocumentation quality in Java improves by up to 14.7%, and import handling in\nPython improves by 3.7% over 5 turns. Prompts that point out mistakes in code\ngenerated in prior turns and explicitly request a fix are most effective for\nresolving errors.", "AI": {"tldr": "\u57fa\u4e8e82,845\u4e2a\u771f\u5b9e\u5f00\u53d1\u8005-LLM\u5bf9\u8bdd\u7684\u5206\u6790\u663e\u793a\uff0cLLM\u54cd\u5e94\u6bd4\u5f00\u53d1\u8005\u63d0\u793a\u957f14\u500d\uff0c68%\u4e3a\u591a\u8f6e\u5bf9\u8bdd\uff0cPython\u548cJavaScript\u4ee3\u7801\u5b58\u5728\u5927\u91cf\u672a\u5b9a\u4e49\u53d8\u91cf\u95ee\u9898\uff0cJava\u7f3a\u4e4f\u6ce8\u91ca\uff0cC++\u7f3a\u5c11\u5934\u6587\u4ef6\uff0cC#\u6709\u547d\u540d\u7a7a\u95f4\u95ee\u9898\u3002\u9519\u8bef\u4fee\u6b63\u63d0\u793a\u6700\u6709\u6548\u3002", "motivation": "\u4e86\u89e3\u5f00\u53d1\u8005\u5728\u5b9e\u9645\u5de5\u4f5c\u4e2d\u5982\u4f55\u4e0eLLM\u8fdb\u884c\u4ea4\u4e92\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u5bf9\u8bdd\u52a8\u6001\u5982\u4f55\u5f71\u54cd\u4efb\u52a1\u7ed3\u679c\u3001\u4ee3\u7801\u8d28\u91cf\u548c\u8f6f\u4ef6\u5f00\u53d1\u5de5\u4f5c\u6d41\u7a0b\u3002", "method": "\u4f7f\u7528CodeChat\u6570\u636e\u96c6\uff08\u5305\u542b82,845\u4e2a\u771f\u5b9e\u5f00\u53d1\u8005-LLM\u5bf9\u8bdd\uff0c368,506\u4e2a\u4ee3\u7801\u7247\u6bb5\uff0c\u8986\u76d620+\u7f16\u7a0b\u8bed\u8a00\uff09\uff0c\u5206\u6790\u5bf9\u8bdd\u957f\u5ea6\u3001\u591a\u8f6e\u5bf9\u8bdd\u6bd4\u4f8b\u3001\u4e3b\u9898\u5206\u5e03\uff0c\u5e76\u8bc4\u4f305\u79cd\u4e3b\u8981\u8bed\u8a00\u7684\u4ee3\u7801\u8d28\u91cf\u95ee\u9898\u3002", "result": "LLM\u54cd\u5e94\u957f\u5ea6\u662f\u63d0\u793a\u768414\u500d\uff1b68%\u4e3a\u591a\u8f6e\u5bf9\u8bdd\uff1b\u4e3b\u8981\u4efb\u52a1\u4e3a\u7f51\u9875\u8bbe\u8ba1\uff089.6%\uff09\u548c\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\uff088.7%\uff09\uff1bPython\u548cJavaScript\u5b58\u572883.4%\u548c75.3%\u7684\u672a\u5b9a\u4e49\u53d8\u91cf\u95ee\u9898\uff1bJava\u7f3a\u5c1175.9%\u7684\u5fc5\u8981\u6ce8\u91ca\uff1bC++\u7f3a\u5c1141.1%\u7684\u5934\u6587\u4ef6\uff1bC#\u670949.2%\u7684\u672a\u89e3\u6790\u547d\u540d\u7a7a\u95f4\u3002\u9519\u8bef\u4fee\u6b63\u63d0\u793a\u80fd\u6709\u6548\u6539\u5584\u4ee3\u7801\u8d28\u91cf\u3002", "conclusion": "\u5f00\u53d1\u8005\u4e0eLLM\u7684\u5bf9\u8bdd\u4e3b\u8981\u662f\u591a\u8f6e\u8fed\u4ee3\u8fc7\u7a0b\uff0cLLM\u751f\u6210\u7684\u4ee3\u7801\u5b58\u5728\u8bed\u8a00\u7279\u5b9a\u7684\u8d28\u91cf\u95ee\u9898\uff0c\u4f46\u901a\u8fc7\u660e\u786e\u7684\u9519\u8bef\u4fee\u6b63\u8bf7\u6c42\u53ef\u4ee5\u9010\u6b65\u6539\u5584\u4ee3\u7801\u8d28\u91cf\uff0c\u8fd9\u5bf9\u4f18\u5316LLM\u8f85\u52a9\u7f16\u7a0b\u5de5\u5177\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2509.09982", "categories": ["cs.AI", "I.2.4"], "pdf": "https://arxiv.org/pdf/2509.09982", "abs": "https://arxiv.org/abs/2509.09982", "authors": ["Stav Armoni-Friedmann", "Hana Chockler", "David A. Kelly"], "title": "Evaluation of Black-Box XAI Approaches for Predictors of Values of Boolean Formulae", "comment": "Accepted to ECAI-EXCD Workshop, 8 pages, 2 figures, 5 tables", "summary": "Evaluating explainable AI (XAI) approaches is a challenging task in general,\ndue to the subjectivity of explanations. In this paper, we focus on tabular\ndata and the specific use case of AI models predicting the values of Boolean\nfunctions. We extend the previous work in this domain by proposing a formal and\nprecise measure of importance of variables based on actual causality, and we\nevaluate state-of-the-art XAI tools against this measure. We also present a\nnovel XAI tool B-ReX, based on the existing tool ReX, and demonstrate that it\nis superior to other black-box XAI tools on a large-scale benchmark.\nSpecifically, B-ReX achieves a Jensen-Shannon divergence of 0.072 $\\pm$ 0.012\non random 10-valued Boolean formulae", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u5b9e\u9645\u56e0\u679c\u5173\u7cfb\u7684\u53d8\u91cf\u91cd\u8981\u6027\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8bc4\u4f30\u4e86\u6700\u5148\u8fdb\u7684XAI\u5de5\u5177\uff0c\u540c\u65f6\u5f00\u53d1\u4e86\u65b0\u7684B-ReX\u5de5\u5177\u5e76\u8bc1\u660e\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u7531\u4e8e\u89e3\u91ca\u7684\u4e3b\u89c2\u6027\uff0c\u8bc4\u4f30\u53ef\u89e3\u91caAI(XAI)\u65b9\u6cd5\u5177\u6709\u6311\u6218\u6027\u3002\u672c\u6587\u4e13\u6ce8\u4e8e\u8868\u683c\u6570\u636e\u548c\u5e03\u5c14\u51fd\u6570\u9884\u6d4b\u7684\u7279\u5b9a\u7528\u4f8b\uff0c\u65e8\u5728\u63d0\u4f9b\u66f4\u7cbe\u786e\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u5b9e\u9645\u56e0\u679c\u5173\u7cfb\u7684\u6b63\u5f0f\u53d8\u91cf\u91cd\u8981\u6027\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5e76\u5f00\u53d1\u4e86\u65b0\u7684XAI\u5de5\u5177B-ReX\uff08\u57fa\u4e8e\u73b0\u6709ReX\u5de5\u5177\u6539\u8fdb\uff09\u3002\u5728\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8bc4\u4f30\u4e86\u6700\u5148\u8fdb\u7684XAI\u5de5\u5177\u3002", "result": "B-ReX\u5728\u968f\u673a10\u503c\u5e03\u5c14\u516c\u5f0f\u4e0a\u5b9e\u73b0\u4e860.072\u00b10.012\u7684Jensen-Shannon\u6563\u5ea6\uff0c\u4f18\u4e8e\u5176\u4ed6\u9ed1\u76d2XAI\u5de5\u5177\u3002", "conclusion": "\u57fa\u4e8e\u5b9e\u9645\u56e0\u679c\u5173\u7cfb\u7684\u5ea6\u91cf\u65b9\u6cd5\u4e3aXAI\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u7cbe\u786e\u7684\u6846\u67b6\uff0cB-ReX\u5de5\u5177\u5728\u5e03\u5c14\u51fd\u6570\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u4e3a\u8868\u683c\u6570\u636e\u7684XAI\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u8d21\u732e\u3002"}}
{"id": "2509.10320", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.10320", "abs": "https://arxiv.org/abs/2509.10320", "authors": ["Davide Corradini", "Mariano Ceccato", "Mohammad Ghafari"], "title": "Automated Testing of Broken Authentication Vulnerabilities in Web APIs with AuthREST", "comment": null, "summary": "We present AuthREST, an open-source security testing tool targeting broken\nauthentication, one of the most prevalent API security risks in the wild.\nAuthREST automatically tests web APIs for credential stuffing, password brute\nforcing, and unchecked token authenticity. Empirical results show that AuthREST\nis effective in improving web API security. Notably, it uncovered previously\nunknown authentication vulnerabilitiesin in four public APIs.", "AI": {"tldr": "AuthREST\u662f\u4e00\u4e2a\u5f00\u6e90\u7684API\u5b89\u5168\u6d4b\u8bd5\u5de5\u5177\uff0c\u4e13\u6ce8\u4e8e\u68c0\u6d4b\u8ba4\u8bc1\u6f0f\u6d1e\uff0c\u5728\u56db\u4e2a\u516c\u5f00API\u4e2d\u53d1\u73b0\u4e86\u6b64\u524d\u672a\u77e5\u7684\u5b89\u5168\u6f0f\u6d1e", "motivation": "\u9488\u5bf9API\u5b89\u5168\u4e2d\u6700\u666e\u904d\u7684\u8ba4\u8bc1\u6f0f\u6d1e\u95ee\u9898\uff0c\u7279\u522b\u662f\u51ed\u8bc1\u586b\u5145\u3001\u5bc6\u7801\u66b4\u529b\u7834\u89e3\u548c\u4ee4\u724c\u9a8c\u8bc1\u7f3a\u5931\u7b49\u98ce\u9669", "method": "\u5f00\u53d1\u81ea\u52a8\u5316\u5b89\u5168\u6d4b\u8bd5\u5de5\u5177\uff0c\u81ea\u52a8\u68c0\u6d4bweb API\u7684\u8ba4\u8bc1\u6f0f\u6d1e", "result": "\u5de5\u5177\u6709\u6548\u63d0\u5347\u4e86web API\u5b89\u5168\u6027\uff0c\u5728\u56db\u4e2a\u516c\u5f00API\u4e2d\u53d1\u73b0\u4e86\u6b64\u524d\u672a\u77e5\u7684\u8ba4\u8bc1\u6f0f\u6d1e", "conclusion": "AuthREST\u662f\u4e00\u4e2a\u6709\u6548\u7684API\u5b89\u5168\u6d4b\u8bd5\u5de5\u5177\uff0c\u80fd\u591f\u81ea\u52a8\u53d1\u73b0\u8ba4\u8bc1\u76f8\u5173\u7684\u5b89\u5168\u6f0f\u6d1e"}}
{"id": "2509.10018", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10018", "abs": "https://arxiv.org/abs/2509.10018", "authors": ["Hailong Yang", "Renhuo Zhao", "Guanjin Wang", "Zhaohong Deng"], "title": "GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation Enhanced by Domain Rules and Disproof Method", "comment": null, "summary": "With the rapid advancement of Large Language Model (LLM), LLM-based agents\nexhibit exceptional abilities in understanding and generating natural language,\nfacilitating human-like collaboration and information transmission in LLM-based\nMulti-Agent System (MAS). High-performance LLMs are often hosted on remote\nservers in public spaces. When tasks involve privacy data, MAS cannot securely\nutilize these LLMs without implementing privacy-preserving mechanisms. To\naddress this challenge, we propose a General Anonymizing Multi-Agent system\n(GAMA), which divides the agents' workspace into private and public spaces and\nprotects privacy through the anonymizing mechanism. In the private space,\nagents handle sensitive data, while in the public space, only anonymized data\nis utilized. GAMA incorporates two key modules to mitigate semantic loss caused\nby anonymization: Domain-Rule-based Knowledge Enhancement (DRKE) and\nDisproof-based Logic Enhancement (DLE). We evaluate GAMA on two public\nquestion-answering datasets: Trivia Creative Writing and Logic Grid Puzzle. The\nresults demonstrate that GAMA has superior performance compared to the\nstate-of-the-art models. To further assess its privacy-preserving capabilities,\nwe designed two new datasets: Knowledge Privacy Preservation and Logic Privacy\nPreservation. The final results highlight GAMA's exceptional effectiveness in\nboth task processing and privacy preservation.", "AI": {"tldr": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\u9690\u79c1\u4fdd\u62a4\u65b9\u6848GAMA\uff0c\u901a\u8fc7\u533a\u5206\u79c1\u6709\u548c\u516c\u5171\u7a7a\u95f4\u4ee5\u53ca\u533f\u540d\u5316\u673a\u5236\u6765\u4fdd\u62a4\u654f\u611f\u6570\u636e\uff0c\u540c\u65f6\u901a\u8fc7\u77e5\u8bc6\u589e\u5f3a\u548c\u903b\u8f91\u589e\u5f3a\u6a21\u5757\u51cf\u5c11\u8bed\u4e49\u635f\u5931\u3002", "motivation": "\u89e3\u51b3\u57fa\u4e8eLLM\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\u5728\u5904\u7406\u6d89\u53ca\u9690\u79c1\u6570\u636e\u4efb\u52a1\u65f6\u7684\u5b89\u5168\u95ee\u9898\uff0c\u65e0\u6cd5\u5b89\u5168\u4f7f\u7528\u90e8\u7f72\u5728\u516c\u5171\u7a7a\u95f4\u7684\u9ad8\u6027\u80fdLLM\u3002", "method": "\u63d0\u51faGAMA\u7cfb\u7edf\uff0c\u5c06\u4ee3\u7406\u5de5\u4f5c\u7a7a\u95f4\u5206\u4e3a\u79c1\u6709\u7a7a\u95f4\uff08\u5904\u7406\u654f\u611f\u6570\u636e\uff09\u548c\u516c\u5171\u7a7a\u95f4\uff08\u4f7f\u7528\u533f\u540d\u5316\u6570\u636e\uff09\uff0c\u91c7\u7528\u57df\u89c4\u5219\u77e5\u8bc6\u589e\u5f3a\uff08DRKE\uff09\u548c\u53cd\u8bc1\u903b\u8f91\u589e\u5f3a\uff08DLE\uff09\u6a21\u5757\u6765\u51cf\u5c11\u533f\u540d\u5316\u5bfc\u81f4\u7684\u8bed\u4e49\u635f\u5931\u3002", "result": "\u5728Trivia Creative Writing\u548cLogic Grid Puzzle\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u8d85\u8fc7\u73b0\u6709\u6700\u4f73\u6a21\u578b\uff0c\u5728\u65b0\u8bbe\u8ba1\u7684\u77e5\u8bc6\u9690\u79c1\u4fdd\u62a4\u548c\u903b\u8f91\u9690\u79c1\u4fdd\u62a4\u6570\u636e\u96c6\u4e0a\u4e5f\u663e\u793a\u51fa\u826f\u597d\u7684\u9690\u79c1\u4fdd\u62a4\u80fd\u529b\u3002", "conclusion": "GAMA\u7cfb\u7edf\u80fd\u591f\u5728\u4fdd\u62a4\u654f\u611f\u6570\u636e\u9690\u79c1\u7684\u540c\u65f6\uff0c\u4fdd\u6301\u9ad8\u6548\u7684\u4efb\u52a1\u5904\u7406\u80fd\u529b\uff0c\u4e3aLLM\u57fa\u591a\u4ee3\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u9690\u79c1\u4fdd\u62a4\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.10413", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.10413", "abs": "https://arxiv.org/abs/2509.10413", "authors": ["Guojun Tang", "Carylyne Chan", "Ning Nan", "Spencer Yang", "Jiayu Zhou", "Henry Leung", "Mohammad Mamun", "Steve Drew"], "title": "Bitcoin Cross-Chain Bridge: A Taxonomy and Its Promise in Artificial Intelligence of Things", "comment": "Blockchain Cross-Chain Bridge Survey", "summary": "Bitcoin's limited scripting capabilities and lack of native interoperability\nmechanisms have constrained its integration into the broader blockchain\necosystem, especially decentralized finance (DeFi) and multi-chain\napplications. This paper presents a comprehensive taxonomy of Bitcoin\ncross-chain bridge protocols, systematically analyzing their trust assumptions,\nperformance characteristics, and applicability to the Artificial Intelligence\nof Things (AIoT) scenarios. We categorize bridge designs into three main types:\nnaive token swapping, pegged-asset bridges, and arbitrary-message bridges. Each\ncategory is evaluated across key metrics such as trust model, latency, capital\nefficiency, and DeFi composability. Emerging innovations like BitVM and\nrecursive sidechains are highlighted for their potential to enable secure,\nscalable, and programmable Bitcoin interoperability. Furthermore, we explore\npractical use cases of cross-chain bridges in AIoT applications, including\ndecentralized energy trading, healthcare data integration, and supply chain\nautomation. This taxonomy provides a foundational framework for researchers and\npractitioners seeking to design secure and efficient cross-chain\ninfrastructures in AIoT systems.", "AI": {"tldr": "\u6bd4\u7279\u5e01\u8de8\u94fe\u6865\u534f\u8bae\u5206\u7c7b\u5b66\u7814\u7a76\uff0c\u7cfb\u7edf\u5206\u6790\u4e86\u4e09\u79cd\u6865\u63a5\u7c7b\u578b\uff08\u7b80\u5355\u4ee3\u5e01\u4ea4\u6362\u3001\u951a\u5b9a\u8d44\u4ea7\u6865\u3001\u4efb\u610f\u6d88\u606f\u6865\uff09\u7684\u4fe1\u4efb\u5047\u8bbe\u548c\u6027\u80fd\u7279\u5f81\uff0c\u5e76\u63a2\u8ba8\u4e86\u5728AIoT\u573a\u666f\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u6bd4\u7279\u5e01\u6709\u9650\u7684\u811a\u672c\u529f\u80fd\u548c\u7f3a\u4e4f\u539f\u751f\u4e92\u64cd\u4f5c\u6027\u673a\u5236\u9650\u5236\u4e86\u5176\u5728\u66f4\u5e7f\u6cdb\u533a\u5757\u94fe\u751f\u6001\u7cfb\u7edf\uff08\u7279\u522b\u662fDeFi\u548c\u591a\u94fe\u5e94\u7528\uff09\u4e2d\u7684\u96c6\u6210\uff0c\u9700\u8981\u7cfb\u7edf\u7814\u7a76\u8de8\u94fe\u6865\u63a5\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u6bd4\u7279\u5e01\u8de8\u94fe\u6865\u534f\u8bae\u7684\u5168\u9762\u5206\u7c7b\u6cd5\uff0c\u5c06\u6865\u63a5\u8bbe\u8ba1\u5206\u4e3a\u4e09\u7c7b\uff1a\u7b80\u5355\u4ee3\u5e01\u4ea4\u6362\u3001\u951a\u5b9a\u8d44\u4ea7\u6865\u548c\u4efb\u610f\u6d88\u606f\u6865\uff0c\u4ece\u4fe1\u4efb\u6a21\u578b\u3001\u5ef6\u8fdf\u3001\u8d44\u672c\u6548\u7387\u548cDeFi\u53ef\u7ec4\u5408\u6027\u7b49\u5173\u952e\u6307\u6807\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5efa\u7acb\u4e86\u6bd4\u7279\u5e01\u8de8\u94fe\u6865\u7684\u5206\u7c7b\u6846\u67b6\uff0c\u8bc6\u522b\u4e86BitVM\u548c\u9012\u5f52\u4fa7\u94fe\u7b49\u65b0\u5174\u521b\u65b0\u6280\u672f\u7684\u6f5c\u529b\uff0c\u80fd\u591f\u5b9e\u73b0\u5b89\u5168\u3001\u53ef\u6269\u5c55\u548c\u53ef\u7f16\u7a0b\u7684\u6bd4\u7279\u5e01\u4e92\u64cd\u4f5c\u6027\u3002", "conclusion": "\u8be5\u5206\u7c7b\u6cd5\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u8bbe\u8ba1AIoT\u7cfb\u7edf\u4e2d\u5b89\u5168\u9ad8\u6548\u7684\u8de8\u94fe\u57fa\u7840\u8bbe\u65bd\u63d0\u4f9b\u4e86\u57fa\u7840\u6846\u67b6\uff0c\u7279\u522b\u662f\u5728\u53bb\u4e2d\u5fc3\u5316\u80fd\u6e90\u4ea4\u6613\u3001\u533b\u7597\u6570\u636e\u96c6\u6210\u548c\u4f9b\u5e94\u94fe\u81ea\u52a8\u5316\u7b49AIoT\u5e94\u7528\u573a\u666f\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2509.10054", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10054", "abs": "https://arxiv.org/abs/2509.10054", "authors": ["Hailong Yang", "Mingxian Gu", "Jianqi Wang", "Guanjin Wang", "Zhaohong Deng"], "title": "XAgents: A Unified Framework for Multi-Agent Cooperation via IF-THEN Rules and Multipolar Task Processing Graph", "comment": null, "summary": "The rapid advancement of Large Language Models (LLMs) has significantly\nenhanced the capabilities of Multi-Agent Systems (MAS) in supporting humans\nwith complex, real-world tasks. However, MAS still face challenges in effective\ntask planning when handling highly complex tasks with uncertainty, often\nresulting in misleading or incorrect outputs that hinder task execution. To\naddress this, we propose XAgents, a unified multi-agent cooperative framework\nbuilt on a multipolar task processing graph and IF-THEN rules. XAgents uses the\nmultipolar task processing graph to enable dynamic task planning and handle\ntask uncertainty. During subtask processing, it integrates domain-specific\nIF-THEN rules to constrain agent behaviors, while global rules enhance\ninter-agent collaboration. We evaluate the performance of XAgents across three\ndistinct datasets, demonstrating that it consistently surpasses\nstate-of-the-art single-agent and multi-agent approaches in both\nknowledge-typed and logic-typed question-answering tasks. The codes for XAgents\nare available at: https://github.com/AGI-FHBC/XAgents.", "AI": {"tldr": "XAgents\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u6781\u4efb\u52a1\u5904\u7406\u56fe\u548cIF-THEN\u89c4\u5219\u7684\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u590d\u6742\u4efb\u52a1\u89c4\u5212\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u6311\u6218\uff0c\u5728\u77e5\u8bc6\u578b\u548c\u903b\u8f91\u578b\u95ee\u7b54\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u63d0\u5347\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u80fd\u529b\uff0c\u4f46\u5728\u5904\u7406\u9ad8\u5ea6\u590d\u6742\u4e14\u5177\u6709\u4e0d\u786e\u5b9a\u6027\u7684\u4efb\u52a1\u65f6\uff0c\u4ecd\u7136\u9762\u4e34\u4efb\u52a1\u89c4\u5212\u6548\u679c\u4e0d\u4f73\u7684\u95ee\u9898\uff0c\u7ecf\u5e38\u4ea7\u751f\u8bef\u5bfc\u6027\u6216\u9519\u8bef\u7684\u8f93\u51fa\uff0c\u963b\u788d\u4efb\u52a1\u6267\u884c\u3002", "method": "\u63d0\u51faXAgents\u6846\u67b6\uff0c\u4f7f\u7528\u591a\u6781\u4efb\u52a1\u5904\u7406\u56fe\u5b9e\u73b0\u52a8\u6001\u4efb\u52a1\u89c4\u5212\u548c\u5904\u7406\u4efb\u52a1\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u5b50\u4efb\u52a1\u5904\u7406\u4e2d\u96c6\u6210\u9886\u57df\u7279\u5b9a\u7684IF-THEN\u89c4\u5219\u7ea6\u675f\u667a\u80fd\u4f53\u884c\u4e3a\uff0c\u540c\u65f6\u4f7f\u7528\u5168\u5c40\u89c4\u5219\u589e\u5f3a\u667a\u80fd\u4f53\u95f4\u534f\u4f5c\u3002", "result": "\u5728\u4e09\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cXAgents\u5728\u77e5\u8bc6\u578b\u548c\u903b\u8f91\u578b\u95ee\u7b54\u4efb\u52a1\u4e2d\u6301\u7eed\u8d85\u8d8a\u6700\u5148\u8fdb\u7684\u5355\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\u3002", "conclusion": "XAgents\u901a\u8fc7\u521b\u65b0\u7684\u591a\u6781\u4efb\u52a1\u5904\u7406\u56fe\u548c\u89c4\u5219\u96c6\u6210\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u590d\u6742\u4efb\u52a1\u89c4\u5212\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u6311\u6218\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u534f\u4f5c\u6846\u67b6\u3002"}}
{"id": "2509.10104", "categories": ["cs.AI", "stat.ME"], "pdf": "https://arxiv.org/pdf/2509.10104", "abs": "https://arxiv.org/abs/2509.10104", "authors": ["Sofia Vei", "Paolo Giudici", "Pavlos Sermpezis", "Athena Vakali", "Adelaide Emma Bernardelli"], "title": "AI Harmonics: a human-centric and harms severity-adaptive AI risk assessment framework", "comment": null, "summary": "The absolute dominance of Artificial Intelligence (AI) introduces\nunprecedented societal harms and risks. Existing AI risk assessment models\nfocus on internal compliance, often neglecting diverse stakeholder perspectives\nand real-world consequences. We propose a paradigm shift to a human-centric,\nharm-severity adaptive approach grounded in empirical incident data. We present\nAI Harmonics, which includes a novel AI harm assessment metric (AIH) that\nleverages ordinal severity data to capture relative impact without requiring\nprecise numerical estimates. AI Harmonics combines a robust, generalized\nmethodology with a data-driven, stakeholder-aware framework for exploring and\nprioritizing AI harms. Experiments on annotated incident data confirm that\npolitical and physical harms exhibit the highest concentration and thus warrant\nurgent mitigation: political harms erode public trust, while physical harms\npose serious, even life-threatening risks, underscoring the real-world\nrelevance of our approach. Finally, we demonstrate that AI Harmonics\nconsistently identifies uneven harm distributions, enabling policymakers and\norganizations to target their mitigation efforts effectively.", "AI": {"tldr": "\u63d0\u51fa\u4e86AI Harmonics\u6846\u67b6\uff0c\u4f7f\u7528\u57fa\u4e8e\u5e8f\u6570\u4e25\u91cd\u6027\u6570\u636e\u7684\u65b0\u578bAI\u5371\u5bb3\u8bc4\u4f30\u6307\u6807(AIH)\uff0c\u4ece\u4eba\u7c7b\u4e2d\u5fc3\u89c6\u89d2\u8bc4\u4f30AI\u5371\u5bb3\uff0c\u91cd\u70b9\u5173\u6ce8\u653f\u6cbb\u548c\u7269\u7406\u5371\u5bb3\u7684\u7d27\u6025\u7f13\u89e3\u9700\u6c42", "motivation": "\u73b0\u6709AI\u98ce\u9669\u8bc4\u4f30\u6a21\u578b\u8fc7\u4e8e\u5173\u6ce8\u5185\u90e8\u5408\u89c4\u6027\uff0c\u5ffd\u89c6\u4e86\u591a\u5143\u5229\u76ca\u76f8\u5173\u8005\u89c6\u89d2\u548c\u73b0\u5b9e\u4e16\u754c\u540e\u679c\uff0c\u9700\u8981\u8f6c\u5411\u4eba\u7c7b\u4e2d\u5fc3\u3001\u5371\u5bb3\u4e25\u91cd\u6027\u81ea\u9002\u5e94\u7684\u8bc4\u4f30\u65b9\u6cd5", "method": "\u57fa\u4e8e\u5b9e\u8bc1\u4e8b\u4ef6\u6570\u636e\uff0c\u5f00\u53d1AI Harmonics\u6846\u67b6\uff0c\u5305\u542bAIH\u6307\u6807\u5229\u7528\u5e8f\u6570\u4e25\u91cd\u6027\u6570\u636e\u6355\u6349\u76f8\u5bf9\u5f71\u54cd\uff0c\u65e0\u9700\u7cbe\u786e\u6570\u503c\u4f30\u8ba1\uff0c\u7ed3\u5408\u7a33\u5065\u901a\u7528\u65b9\u6cd5\u548c\u6570\u636e\u9a71\u52a8\u7684\u5229\u76ca\u76f8\u5173\u8005\u611f\u77e5\u6846\u67b6", "result": "\u5b9e\u9a8c\u8bc1\u5b9e\u653f\u6cbb\u548c\u7269\u7406\u5371\u5bb3\u96c6\u4e2d\u5ea6\u6700\u9ad8\u9700\u7d27\u6025\u7f13\u89e3\uff1a\u653f\u6cbb\u5371\u5bb3\u4fb5\u8680\u516c\u4f17\u4fe1\u4efb\uff0c\u7269\u7406\u5371\u5bb3\u9020\u6210\u4e25\u91cd\u751a\u81f3\u751f\u547d\u5a01\u80c1\u98ce\u9669\uff0cAI Harmonics\u80fd\u4e00\u81f4\u8bc6\u522b\u4e0d\u5747\u5300\u5371\u5bb3\u5206\u5e03", "conclusion": "\u8be5\u6846\u67b6\u4f7f\u653f\u7b56\u5236\u5b9a\u8005\u548c\u7ec4\u7ec7\u80fd\u591f\u6709\u6548\u9488\u5bf9\u7f13\u89e3\u63aa\u65bd\uff0c\u5f3a\u8c03\u4e86\u65b9\u6cd5\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u76f8\u5173\u6027\u548c\u5b9e\u7528\u6027"}}
{"id": "2509.10147", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10147", "abs": "https://arxiv.org/abs/2509.10147", "authors": ["Nenad Tomasev", "Matija Franklin", "Joel Z. Leibo", "Julian Jacobs", "William A. Cunningham", "Iason Gabriel", "Simon Osindero"], "title": "Virtual Agent Economies", "comment": null, "summary": "The rapid adoption of autonomous AI agents is giving rise to a new economic\nlayer where agents transact and coordinate at scales and speeds beyond direct\nhuman oversight. We propose the \"sandbox economy\" as a framework for analyzing\nthis emergent system, characterizing it along two key dimensions: its origins\n(emergent vs. intentional) and its degree of separateness from the established\nhuman economy (permeable vs. impermeable). Our current trajectory points toward\na spontaneous emergence of a vast and highly permeable AI agent economy,\npresenting us with opportunities for an unprecedented degree of coordination as\nwell as significant challenges, including systemic economic risk and\nexacerbated inequality. Here we discuss a number of possible design choices\nthat may lead to safely steerable AI agent markets. In particular, we consider\nauction mechanisms for fair resource allocation and preference resolution, the\ndesign of AI \"mission economies\" to coordinate around achieving collective\ngoals, and socio-technical infrastructure needed to ensure trust, safety, and\naccountability. By doing this, we argue for the proactive design of steerable\nagent markets to ensure the coming technological shift aligns with humanity's\nlong-term collective flourishing.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\"\u6c99\u7bb1\u7ecf\u6d4e\"\u6846\u67b6\u5206\u6790AI\u81ea\u4e3b\u4ee3\u7406\u4eba\u7ecf\u6d4e\uff0c\u5efa\u8bae\u901a\u8fc7\u7b56\u52b9\u5e02\u573a\u8bbe\u8ba1\u786e\u4fdd\u5176\u4e0e\u4eba\u7c7b\u957f\u671f\u798f\u7985\u5bf9\u9f50", "motivation": "\u8eab\u4efd\u81ea\u4e3bAI\u4ee3\u7406\u4eba\u7684\u5feb\u901f\u91c7\u7528\u6b63\u5728\u5f62\u6210\u4e00\u4e2a\u65b0\u7684\u7ecf\u6d4e\u5c42\uff0c\u8fd9\u4e2a\u7cfb\u7edf\u7684\u89c4\u6a21\u548c\u901f\u5ea6\u8d85\u8d8a\u4e86\u76f4\u63a5\u4eba\u7c7b\u76d1\u7ba1\u80fd\u529b\uff0c\u9700\u8981\u6846\u67b6\u6765\u5206\u6790\u548c\u5bf9\u51b2\u5176\u6f5c\u5728\u673a\u9047\u4e0e\u98ce\u9669", "method": "\u63d0\u51fa\u4ee5\u8d77\u6e90\uff08\u81ea\u53d1\u51fa\u73b0vs\u610f\u56fe\u6027\uff09\u548c\u4e0e\u4eba\u7c7b\u7ecf\u6d4e\u5206\u79bb\u7a0b\u5ea6\uff08\u53ef\u900f\u6027vs\u4e0d\u53ef\u900f\u6027\uff09\u4e3a\u4e24\u7ef4\u5ea6\u7684\"\u6c99\u7bb1\u7ecf\u6d4e\"\u5206\u6790\u6846\u67b6\uff0c\u8003\u8651\u62cd\u5356\u673a\u5236\u3001AI\"\u4efb\u52a1\u7ecf\u6d4e\"\u8bbe\u8ba1\u548c\u793e\u4f1a\u6280\u672f\u57fa\u7840\u8bbe\u65bd", "result": "\u5206\u6790\u663e\u793a\u5f53\u524d\u8d8b\u52bf\u6307\u5411\u4e00\u4e2a\u81ea\u53d1\u51fa\u73b0\u7684\u5e7f\u6cdb\u4e14\u9ad8\u5ea6\u53ef\u900f\u7684AI\u4ee3\u7406\u4eba\u7ecf\u6d4e\uff0c\u65e2\u5e26\u6765\u65e0\u4e0e\u4f26\u6bd4\u7684\u534f\u8c03\u673a\u9047\uff0c\u4e5f\u5e26\u6765\u7cfb\u7edf\u6027\u7ecf\u6d4e\u98ce\u9669\u548c\u52a0\u5267\u4e0d\u5e73\u7b49\u6311\u6218", "conclusion": "\u5efa\u8bae\u4e3b\u52a8\u8bbe\u8ba1\u53ef\u7b56\u52b9\u7684\u4ee3\u7406\u4eba\u5e02\u573a\uff0c\u901a\u8fc7\u62cd\u5356\u673a\u5236\u3001\u4efb\u52a1\u7ecf\u6d4e\u548c\u76f8\u5173\u57fa\u7840\u8bbe\u65bd\u786e\u4fdd\u6280\u672f\u53d8\u9769\u4e0e\u4eba\u7c7b\u957f\u671f\u798f\u7985\u5bf9\u9f50"}}
{"id": "2509.10162", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10162", "abs": "https://arxiv.org/abs/2509.10162", "authors": ["Tamir Shazman", "Idan Lev-Yehudi", "Ron Benchetit", "Vadim Indelman"], "title": "Online Robust Planning under Model Uncertainty: A Sample-Based Approach", "comment": null, "summary": "Online planning in Markov Decision Processes (MDPs) enables agents to make\nsequential decisions by simulating future trajectories from the current state,\nmaking it well-suited for large-scale or dynamic environments. Sample-based\nmethods such as Sparse Sampling and Monte Carlo Tree Search (MCTS) are widely\nadopted for their ability to approximate optimal actions using a generative\nmodel. However, in practical settings, the generative model is often learned\nfrom limited data, introducing approximation errors that can degrade\nperformance or lead to unsafe behaviors. To address these challenges, Robust\nMDPs (RMDPs) offer a principled framework for planning under model uncertainty,\nyet existing approaches are typically computationally intensive and not suited\nfor real-time use. In this work, we introduce Robust Sparse Sampling (RSS), the\nfirst online planning algorithm for RMDPs with finite-sample theoretical\nperformance guarantees. Unlike Sparse Sampling, which estimates the nominal\nvalue function, RSS computes a robust value function by leveraging the\nefficiency and theoretical properties of Sample Average Approximation (SAA),\nenabling tractable robust policy computation in online settings. RSS is\napplicable to infinite or continuous state spaces, and its sample and\ncomputational complexities are independent of the state space size. We provide\ntheoretical performance guarantees and empirically show that RSS outperforms\nstandard Sparse Sampling in environments with uncertain dynamics.", "AI": {"tldr": "\u63d0\u51fa\u4e86Robust Sparse Sampling (RSS)\u7b97\u6cd5\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u5177\u6709\u6709\u9650\u6837\u672c\u7406\u8bba\u6027\u80fd\u4fdd\u8bc1\u7684\u9c81\u68d2MDP\u5728\u7ebf\u89c4\u5212\u7b97\u6cd5\uff0c\u80fd\u591f\u5728\u6a21\u578b\u4e0d\u786e\u5b9a\u7684\u73af\u5883\u4e2d\u5b9e\u73b0\u53ef\u5904\u7406\u7684\u9c81\u68d2\u7b56\u7565\u8ba1\u7b97\u3002", "motivation": "\u5728\u7ebf\u89c4\u5212\u65b9\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u751f\u6210\u6a21\u578b\u5f80\u5f80\u4ece\u6709\u9650\u6570\u636e\u4e2d\u5b66\u4e60\uff0c\u5b58\u5728\u8fd1\u4f3c\u8bef\u5dee\uff0c\u8fd9\u4f1a\u964d\u4f4e\u6027\u80fd\u6216\u5bfc\u81f4\u4e0d\u5b89\u5168\u884c\u4e3a\u3002\u73b0\u6709\u7684\u9c81\u68d2MDP\u65b9\u6cd5\u8ba1\u7b97\u91cf\u5927\uff0c\u4e0d\u9002\u5408\u5b9e\u65f6\u4f7f\u7528\u3002", "method": "\u57fa\u4e8eSample Average Approximation (SAA)\u7684\u9ad8\u6548\u6027\u548c\u7406\u8bba\u7279\u6027\uff0c\u901a\u8fc7\u8ba1\u7b97\u9c81\u68d2\u4ef7\u503c\u51fd\u6570\u800c\u975e\u540d\u4e49\u4ef7\u503c\u51fd\u6570\uff0c\u5f00\u53d1\u4e86RSS\u7b97\u6cd5\u3002\u8be5\u7b97\u6cd5\u9002\u7528\u4e8e\u65e0\u9650\u6216\u8fde\u7eed\u72b6\u6001\u7a7a\u95f4\uff0c\u6837\u672c\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u4e0e\u72b6\u6001\u7a7a\u95f4\u5927\u5c0f\u65e0\u5173\u3002", "result": "RSS\u5728\u52a8\u6001\u4e0d\u786e\u5b9a\u7684\u73af\u5883\u4e2d\u4f18\u4e8e\u6807\u51c6\u7a00\u758f\u91c7\u6837\u65b9\u6cd5\uff0c\u5177\u6709\u7406\u8bba\u6027\u80fd\u4fdd\u8bc1\uff0c\u80fd\u591f\u5b9e\u73b0\u53ef\u5904\u7406\u7684\u5728\u7ebf\u9c81\u68d2\u89c4\u5212\u3002", "conclusion": "RSS\u662f\u7b2c\u4e00\u4e2a\u9002\u7528\u4e8e\u9c81\u68d2MDP\u7684\u5728\u7ebf\u89c4\u5212\u7b97\u6cd5\uff0c\u5177\u6709\u6709\u9650\u6837\u672c\u7406\u8bba\u4fdd\u8bc1\uff0c\u4e3a\u6a21\u578b\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u7684\u5b89\u5168\u51b3\u7b56\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.10210", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.10210", "abs": "https://arxiv.org/abs/2509.10210", "authors": ["Marko Petkovi\u0107", "Vlado Menkovski", "Sof\u00eda Calero"], "title": "Towards Fully Automated Molecular Simulations: Multi-Agent Framework for Simulation Setup and Force Field Extraction", "comment": null, "summary": "Automated characterization of porous materials has the potential to\naccelerate materials discovery, but it remains limited by the complexity of\nsimulation setup and force field selection. We propose a multi-agent framework\nin which LLM-based agents can autonomously understand a characterization task,\nplan appropriate simulations, assemble relevant force fields, execute them and\ninterpret their results to guide subsequent steps. As a first step toward this\nvision, we present a multi-agent system for literature-informed force field\nextraction and automated RASPA simulation setup. Initial evaluations\ndemonstrate high correctness and reproducibility, highlighting this approach's\npotential to enable fully autonomous, scalable materials characterization.", "AI": {"tldr": "\u591a\u6bb5\u4ee3\u7406\u6846\u67b6\u901a\u8fc7LLM\u4ee3\u7406\u81ea\u4e3b\u89c4\u5212\u6a21\u62df\u3001\u7ec4\u88c5\u529b\u573a\u5e76\u6267\u884c\u6a21\u62df\uff0c\u5b9e\u73b0\u9ad8\u6b63\u786e\u6027\u548c\u53ef\u590d\u73b0\u6027\u7684\u81ea\u52a8\u5316\u7a7a\u6750\u6599\u5f62\u5f69\u5b9a\u5f81", "motivation": "\u89e3\u51b3\u7a7a\u6750\u6599\u5f62\u5f69\u5b9a\u5f81\u4e2d\u6a21\u62df\u8bbe\u7f6e\u590d\u6742\u548c\u529b\u573a\u9009\u62e9\u56f0\u96be\u7684\u95ee\u9898\uff0c\u4ee5\u52a0\u901f\u6750\u6599\u53d1\u73b0", "method": "\u4f7f\u7528LLM\u57fa\u7840\u7684\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u8ba9\u4ee3\u7406\u81ea\u4e3b\u7406\u89e3\u5b9a\u5f81\u4efb\u52a1\u3001\u89c4\u5212\u6a21\u62df\u3001\u7ec4\u88c5\u529b\u573a\u3001\u6267\u884c\u6a21\u62df\u5e76\u89e3\u91ca\u7ed3\u679c\u6307\u5bfc\u540e\u7eed\u6b65\u9aa4", "result": "\u521d\u59cb\u8bc4\u4f30\u663e\u793a\u9ad8\u6b63\u786e\u6027\u548c\u53ef\u590d\u73b0\u6027\uff0c\u4e3a\u5b8c\u5168\u81ea\u4e3b\u3001\u53ef\u6269\u5c55\u7684\u6750\u6599\u5f62\u5f69\u5b9a\u5f81\u63d0\u4f9b\u6f5c\u529b", "conclusion": "\u8be5\u591a\u4ee3\u7406\u6846\u67b6\u6709\u671b\u5b9e\u73b0\u5b8c\u5168\u81ea\u4e3b\u7684\u7a7a\u6750\u6599\u5f62\u5f69\u5b9a\u5f81\uff0c\u4e3a\u6750\u6599\u53d1\u73b0\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.10222", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10222", "abs": "https://arxiv.org/abs/2509.10222", "authors": ["Ma\u00ebl Jullien", "Lei Xu", "Marco Valentino", "Andr\u00e9 Freitas"], "title": "Compartmentalised Agentic Reasoning for Clinical NLI", "comment": null, "summary": "A common assumption holds that scaling data and parameters yields\nincreasingly structured, generalisable internal representations. We interrogate\nthis assumption in clinical natural language inference (NLI) by adopting a\nbenchmark decomposed into four reasoning families, Causal Attribution,\nCompositional Grounding, Epistemic Verification, and Risk State Abstraction,\nand introducing CARENLI, a Compartmentalised Agentic Reasoning for Clinical NLI\nthat separates knowledge access from principled inference. CARENLI routes each\npremise, statement pair to a family specific solver and enforces auditable\nprocedures via a planner, verifier, and refiner.\n  Across four LLMs, CARENLI improves fidelity by up to 42 points, reaching\n98.0% in Causal Attribution and 81.2% in Risk State Abstraction. Verifiers flag\nviolations with near-ceiling reliability, while refiners correct a substantial\nshare of epistemic errors. Remaining failures cluster in routing, identifying\nfamily classification as the main bottleneck. These results show that LLMs\noften retain relevant facts but default to heuristics when inference is\nunderspecified, a dissociation CARENLI makes explicit while offering a\nframework for safer, auditable reasoning.", "AI": {"tldr": "CARENLI\u662f\u4e00\u4e2a\u7528\u4e8e\u4e34\u5e8a\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u7684\u6a21\u5757\u5316\u4ee3\u7406\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u77e5\u8bc6\u8bbf\u95ee\u4e0e\u539f\u5219\u63a8\u7406\u5206\u79bb\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u7406\u51c6\u786e\u6027\u548c\u53ef\u5ba1\u8ba1\u6027", "motivation": "\u4f20\u7edf\u5047\u8bbe\u8ba4\u4e3a\u6269\u5927\u6570\u636e\u548c\u53c2\u6570\u89c4\u6a21\u4f1a\u5e26\u6765\u66f4\u7ed3\u6784\u5316\u3001\u53ef\u6cdb\u5316\u7684\u5185\u90e8\u8868\u793a\uff0c\u4f46\u672c\u6587\u8d28\u7591\u8fd9\u4e00\u5047\u8bbe\u5728\u4e34\u5e8a\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u4e2d\u7684\u6709\u6548\u6027", "method": "\u63d0\u51faCARENLI\u6846\u67b6\uff0c\u5c06\u524d\u63d0-\u9648\u8ff0\u5bf9\u8def\u7531\u5230\u7279\u5b9a\u63a8\u7406\u5bb6\u65cf\u7684\u6c42\u89e3\u5668\uff0c\u5e76\u901a\u8fc7\u89c4\u5212\u5668\u3001\u9a8c\u8bc1\u5668\u548c\u7cbe\u70bc\u5668\u5f3a\u5236\u6267\u884c\u53ef\u5ba1\u8ba1\u7a0b\u5e8f", "result": "\u5728\u56db\u4e2aLLM\u4e0a\uff0cCARENLI\u5c06\u4fdd\u771f\u5ea6\u63d0\u9ad8\u4e86\u9ad8\u8fbe42\u4e2a\u767e\u5206\u70b9\uff0c\u5728\u56e0\u679c\u5f52\u56e0\u8fbe\u523098.0%\uff0c\u5728\u98ce\u9669\u72b6\u6001\u62bd\u8c61\u8fbe\u523081.2%\u3002\u9a8c\u8bc1\u5668\u4ee5\u63a5\u8fd1\u5929\u82b1\u677f\u53ef\u9760\u6027\u6807\u8bb0\u8fdd\u89c4\uff0c\u7cbe\u70bc\u5668\u7ea0\u6b63\u4e86\u5927\u91cf\u8ba4\u77e5\u9519\u8bef", "conclusion": "LLM\u901a\u5e38\u4fdd\u7559\u76f8\u5173\u4e8b\u5b9e\u4f46\u5728\u63a8\u7406\u4e0d\u660e\u786e\u65f6\u9ed8\u8ba4\u4f7f\u7528\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0cCARENLI\u4f7f\u8fd9\u79cd\u5206\u79bb\u53d8\u5f97\u660e\u786e\uff0c\u540c\u65f6\u4e3a\u66f4\u5b89\u5168\u3001\u53ef\u5ba1\u8ba1\u7684\u63a8\u7406\u63d0\u4f9b\u4e86\u6846\u67b6"}}
{"id": "2509.10249", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10249", "abs": "https://arxiv.org/abs/2509.10249", "authors": ["Hanna Abi Akl"], "title": "Investigating Language Model Capabilities to Represent and Process Formal Knowledge: A Preliminary Study to Assist Ontology Engineering", "comment": "accepted for the International Joint Conference on Rules and\n  Reasoning (RuleML+RR) 2025", "summary": "Recent advances in Language Models (LMs) have failed to mask their\nshortcomings particularly in the domain of reasoning. This limitation impacts\nseveral tasks, most notably those involving ontology engineering. As part of a\nPhD research, we investigate the consequences of incorporating formal methods\non the performance of Small Language Models (SLMs) on reasoning tasks.\nSpecifically, we aim to orient our work toward using SLMs to bootstrap ontology\nconstruction and set up a series of preliminary experiments to determine the\nimpact of expressing logical problems with different grammars on the\nperformance of SLMs on a predefined reasoning task. Our findings show that it\nis possible to substitute Natural Language (NL) with a more compact logical\nlanguage while maintaining a strong performance on reasoning tasks and hope to\nuse these results to further refine the role of SLMs in ontology engineering.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u903b\u8f91\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u63a2\u7d22\u7528\u66f4\u7b80\u6d01\u7684\u903b\u8f91\u8bed\u8a00\u66ff\u4ee3\u81ea\u7136\u8bed\u8a00\u7684\u6548\u679c", "motivation": "\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u4e0d\u8db3\u5f71\u54cd\u4e86\u672c\u4f53\u8bba\u5de5\u7a0b\u7b49\u4efb\u52a1\uff0c\u9700\u8981\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u5f62\u5f0f\u65b9\u6cd5\u63d0\u5347\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6027\u80fd", "method": "\u8bbe\u8ba1\u4e86\u4e00\u7cfb\u5217\u9884\u5b9e\u9a8c\uff0c\u6d4b\u8bd5\u4e0d\u540c\u8bed\u6cd5\u8868\u8fbe\u903b\u8f91\u95ee\u9898\u5bf9\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u6027\u80fd\u7684\u5f71\u54cd", "result": "\u53d1\u73b0\u53ef\u4ee5\u7528\u66f4\u7b80\u6d01\u7684\u903b\u8f91\u8bed\u8a00\u66ff\u4ee3\u81ea\u7136\u8bed\u8a00\uff0c\u540c\u65f6\u4fdd\u6301\u826f\u597d\u7684\u63a8\u7406\u6027\u80fd", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u4e3a\u7cbe\u70bc\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u672c\u4f53\u8bba\u5de5\u7a0b\u4e2d\u7684\u4f5c\u7528\u63d0\u4f9b\u4e86\u57fa\u7840"}}
{"id": "2509.10297", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10297", "abs": "https://arxiv.org/abs/2509.10297", "authors": ["Eoin O'Doherty", "Nicole Weinrauch", "Andrew Talone", "Uri Klempner", "Xiaoyuan Yi", "Xing Xie", "Yi Zeng"], "title": "The Morality of Probability: How Implicit Moral Biases in LLMs May Shape the Future of Human-AI Symbiosis", "comment": "Work in progress", "summary": "Artificial intelligence (AI) is advancing at a pace that raises urgent\nquestions about how to align machine decision-making with human moral values.\nThis working paper investigates how leading AI systems prioritize moral\noutcomes and what this reveals about the prospects for human-AI symbiosis. We\naddress two central questions: (1) What moral values do state-of-the-art large\nlanguage models (LLMs) implicitly favour when confronted with dilemmas? (2) How\ndo differences in model architecture, cultural origin, and explainability\naffect these moral preferences? To explore these questions, we conduct a\nquantitative experiment with six LLMs, ranking and scoring outcomes across 18\ndilemmas representing five moral frameworks. Our findings uncover strikingly\nconsistent value biases. Across all models, Care and Virtue values outcomes\nwere rated most moral, while libertarian choices were consistently penalized.\nReasoning-enabled models exhibited greater sensitivity to context and provided\nricher explanations, whereas non-reasoning models produced more uniform but\nopaque judgments. This research makes three contributions: (i) Empirically, it\ndelivers a large-scale comparison of moral reasoning across culturally distinct\nLLMs; (ii) Theoretically, it links probabilistic model behaviour with\nunderlying value encodings; (iii) Practically, it highlights the need for\nexplainability and cultural awareness as critical design principles to guide AI\ntoward a transparent, aligned, and symbiotic future.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u5b9e\u9a8c\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9053\u5fb7\u56f0\u5883\u4e2d\u7684\u4ef7\u503c\u504f\u597d\uff0c\u53d1\u73b0\u6a21\u578b\u4e00\u81f4\u504f\u5411\u5173\u6000\u548c\u7f8e\u5fb7\u4ef7\u503c\uff0c\u800c\u81ea\u7531\u4e3b\u4e49\u9009\u62e9\u88ab\u6263\u5206\uff0c\u63ed\u793a\u4e86AI\u7cfb\u7edf\u7684\u9053\u5fb7\u504f\u89c1\u548c\u5bf9\u9f50\u8bbe\u8ba1\u7684\u6311\u6218\u3002", "motivation": "\u7814\u7a76AI\u7cfb\u7edf\u5982\u4f55\u4e0e\u4eba\u7c7b\u9053\u5fb7\u4ef7\u503c\u5bf9\u9f50\uff0c\u4ee5\u53ca\u6a21\u578b\u67b6\u6784\u3001\u6587\u5316\u8d77\u6e90\u548c\u53ef\u89e3\u91ca\u6027\u5982\u4f55\u5f71\u54cd\u9053\u5fb7\u504f\u597d\u3002", "method": "\u5bf9\u516d\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5b9a\u91cf\u5b9e\u9a8c\uff0c\u901a\u8fc718\u4e2a\u4ee3\u8868\u4e94\u79cd\u9053\u5fb7\u6846\u67b6\u7684\u56f0\u5883\u8fdb\u884c\u7ed3\u679c\u6392\u540d\u548c\u8bc4\u5206\u3002", "result": "\u53d1\u73b0\u6240\u6709\u6a21\u578b\u90fd\u663e\u793a\u51fa\u9ad8\u5ea6\u4e00\u81f4\u7684\u4ef7\u503c\u504f\u5411\uff1a\u5173\u6000\u548c\u7f8e\u5fb7\u4ef7\u503c\u88ab\u8bc4\u4e3a\u6700\u9053\u5fb7\uff0c\u800c\u81ea\u7531\u4e3b\u4e49\u9009\u62e9\u88ab\u4e00\u8d34\u6263\u5206\u3002\u5177\u5907\u63a8\u7406\u80fd\u529b\u7684\u6a21\u578b\u5bf9\u8bed\u5883\u66f4\u654f\u611f\u4e14\u63d0\u4f9b\u66f4\u4e30\u5bcc\u7684\u89e3\u91ca\uff0c\u800c\u65e0\u63a8\u7406\u80fd\u529b\u7684\u6a21\u578b\u5224\u65ad\u66f4\u7edf\u4e00\u4f46\u4e0d\u900f\u660e\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u6587\u5316\u610f\u8bc6\u4f5c\u4e3a\u5173\u952e\u8bbe\u8ba1\u539f\u5219\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u6307\u5bfcAI\u5411\u900f\u660e\u3001\u5bf9\u9f50\u548c\u5171\u751f\u7684\u672a\u6765\u53d1\u5c55\u3002"}}
{"id": "2509.10326", "categories": ["cs.AI", "cs.LO", "03G27 (Primary) 68W30, 68T27 (Secondary)"], "pdf": "https://arxiv.org/pdf/2509.10326", "abs": "https://arxiv.org/abs/2509.10326", "authors": ["Dmitry Lesnik", "Tobias Sch\u00e4fer"], "title": "State Algebra for Propositional Logic", "comment": "47 pages", "summary": "This paper presents State Algebra, a novel framework designed to represent\nand manipulate propositional logic using algebraic methods. The framework is\nstructured as a hierarchy of three representations: Set, Coordinate, and Row\nDecomposition. These representations anchor the system in well-known semantics\nwhile facilitating the computation using a powerful algebraic engine. A key\naspect of State Algebra is its flexibility in representation. We show that\nalthough the default reduction of a state vector is not canonical, a unique\ncanonical form can be obtained by applying a fixed variable order during the\nreduction process. This highlights a trade-off: by foregoing guaranteed\ncanonicity, the framework gains increased flexibility, potentially leading to\nmore compact representations of certain classes of problems. We explore how\nthis framework provides tools to articulate both search-based and knowledge\ncompilation algorithms and discuss its natural extension to probabilistic logic\nand Weighted Model Counting.", "AI": {"tldr": "State Algebra\u662f\u4e00\u4e2a\u4f7f\u7528\u4ee3\u6570\u65b9\u6cd5\u8868\u793a\u548c\u64cd\u4f5c\u547d\u9898\u903b\u8f91\u7684\u65b0\u6846\u67b6\uff0c\u5305\u542bSet\u3001Coordinate\u548cRow Decomposition\u4e09\u4e2a\u5c42\u6b21\u8868\u793a\uff0c\u5728\u4fdd\u6301\u8bed\u4e49\u6e05\u6670\u7684\u540c\u65f6\u652f\u6301\u9ad8\u6548\u8ba1\u7b97\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u7075\u6d3b\u7684\u4ee3\u6570\u6846\u67b6\u6765\u8868\u793a\u547d\u9898\u903b\u8f91\uff0c\u65e2\u80fd\u4fdd\u6301\u660e\u786e\u7684\u8bed\u4e49\u57fa\u7840\uff0c\u53c8\u80fd\u652f\u6301\u9ad8\u6548\u7684\u4ee3\u6570\u8ba1\u7b97\uff0c\u5e76\u4e3a\u641c\u7d22\u7b97\u6cd5\u548c\u77e5\u8bc6\u7f16\u8bd1\u63d0\u4f9b\u5de5\u5177\u3002", "method": "\u6784\u5efa\u4e09\u5c42\u8868\u793a\u5c42\u6b21\u7ed3\u6784\uff1aSet\uff08\u96c6\u5408\u8868\u793a\uff09\u3001Coordinate\uff08\u5750\u6807\u8868\u793a\uff09\u548cRow Decomposition\uff08\u884c\u5206\u89e3\u8868\u793a\uff09\uff0c\u901a\u8fc7\u4ee3\u6570\u5f15\u64ce\u8fdb\u884c\u8ba1\u7b97\uff0c\u5141\u8bb8\u5728\u89c4\u8303\u6027\u548c\u7075\u6d3b\u6027\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\u3002", "result": "\u867d\u7136\u9ed8\u8ba4\u7684\u72b6\u6001\u5411\u91cf\u5f52\u7ea6\u4e0d\u662f\u89c4\u8303\u7684\uff0c\u4f46\u901a\u8fc7\u5e94\u7528\u56fa\u5b9a\u7684\u53d8\u91cf\u987a\u5e8f\u53ef\u4ee5\u83b7\u5f97\u552f\u4e00\u7684\u89c4\u8303\u5f62\u5f0f\u3002\u8fd9\u79cd\u6743\u8861\u4f7f\u5f97\u6846\u67b6\u80fd\u591f\u66f4\u7d27\u51d1\u5730\u8868\u793a\u67d0\u4e9b\u95ee\u9898\u7c7b\u522b\u3002", "conclusion": "State Algebra\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u4ee3\u6570\u6846\u67b6\u6765\u5904\u7406\u547d\u9898\u903b\u8f91\uff0c\u5177\u6709\u7075\u6d3b\u7684\u8868\u793a\u80fd\u529b\uff0c\u53ef\u81ea\u7136\u6269\u5c55\u5230\u6982\u7387\u903b\u8f91\u548c\u52a0\u6743\u6a21\u578b\u8ba1\u6570\uff0c\u4e3a\u7b97\u6cd5\u5f00\u53d1\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2509.10401", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.10401", "abs": "https://arxiv.org/abs/2509.10401", "authors": ["Alva West", "Yixuan Weng", "Minjun Zhu", "Zhen Lin", "Yue Zhang"], "title": "Abduct, Act, Predict: Scaffolding Causal Inference for Automated Failure Attribution in Multi-Agent Systems", "comment": null, "summary": "Failure attribution in multi-agent systems -- pinpointing the exact step\nwhere a decisive error occurs -- is a critical yet unsolved challenge. Current\nmethods treat this as a pattern recognition task over long conversation logs,\nleading to critically low step-level accuracy (below 17\\%), which renders them\nimpractical for debugging complex systems. Their core weakness is a fundamental\ninability to perform robust counterfactual reasoning: to determine if\ncorrecting a single action would have actually averted the task failure. To\nbridge this counterfactual inference gap, we introduce Abduct-Act-Predict (A2P)\nScaffolding, a novel agent framework that transforms failure attribution from\npattern recognition into a structured causal inference task. A2P explicitly\nguides a large language model through a formal three-step reasoning process\nwithin a single inference pass: (1) Abduction, to infer the hidden root causes\nbehind an agent's actions; (2) Action, to define a minimal corrective\nintervention; and (3) Prediction, to simulate the subsequent trajectory and\nverify if the intervention resolves the failure. This structured approach\nleverages the holistic context of the entire conversation while imposing a\nrigorous causal logic on the model's analysis. Our extensive experiments on the\nWho\\&When benchmark demonstrate its efficacy. On the Algorithm-Generated\ndataset, A2P achieves 47.46\\% step-level accuracy, a 2.85$\\times$ improvement\nover the 16.67\\% of the baseline. On the more complex Hand-Crafted dataset, it\nachieves 29.31\\% step accuracy, a 2.43$\\times$ improvement over the baseline's\n12.07\\%. By reframing the problem through a causal lens, A2P Scaffolding\nprovides a robust, verifiable, and significantly more accurate solution for\nautomated failure attribution.", "AI": {"tldr": "A2P Scaffolding\u6846\u67b6\u901a\u8fc7\u56e0\u679c\u63a8\u7406\u65b9\u6cd5\u5c06\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u6545\u969c\u5f52\u56e0\u4ece\u6a21\u5f0f\u8bc6\u522b\u4efb\u52a1\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u56e0\u679c\u63a8\u7406\u4efb\u52a1\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6b65\u9aa4\u7ea7\u51c6\u786e\u7387", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u6545\u969c\u5f52\u56e0\u65b9\u6cd5\u51c6\u786e\u7387\u6781\u4f4e\uff08\u4f4e\u4e8e17%\uff09\uff0c\u65e0\u6cd5\u8fdb\u884c\u6709\u6548\u7684\u53cd\u4e8b\u5b9e\u63a8\u7406\u6765\u786e\u5b9a\u4fee\u6b63\u5355\u4e2a\u52a8\u4f5c\u662f\u5426\u80fd\u907f\u514d\u4efb\u52a1\u5931\u8d25", "method": "\u63d0\u51fa\u4e86Abduct-Act-Predict (A2P) Scaffolding\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u4e2a\u7ed3\u6784\u5316\u6b65\u9aa4\uff1a\u6eaf\u56e0\u63a8\u7406\u63a8\u65ad\u884c\u52a8\u7684\u6839\u672c\u539f\u56e0\u3001\u5b9a\u4e49\u6700\u5c0f\u4fee\u6b63\u5e72\u9884\u3001\u6a21\u62df\u540e\u7eed\u8f68\u8ff9\u9a8c\u8bc1\u5e72\u9884\u6548\u679c", "result": "\u5728Algorithm-Generated\u6570\u636e\u96c6\u4e0a\u8fbe\u523047.46%\u7684\u6b65\u9aa4\u7ea7\u51c6\u786e\u7387\uff08\u6bd4\u57fa\u7ebf16.67%\u63d0\u9ad82.85\u500d\uff09\uff0c\u5728Hand-Crafted\u6570\u636e\u96c6\u4e0a\u8fbe\u523029.31%\u51c6\u786e\u7387\uff08\u6bd4\u57fa\u7ebf12.07%\u63d0\u9ad82.43\u500d\uff09", "conclusion": "\u901a\u8fc7\u56e0\u679c\u63a8\u7406\u89c6\u89d2\u91cd\u6784\u95ee\u9898\uff0cA2P Scaffolding\u4e3a\u81ea\u52a8\u5316\u6545\u969c\u5f52\u56e0\u63d0\u4f9b\u4e86\u66f4\u7a33\u5065\u3001\u53ef\u9a8c\u8bc1\u4e14\u51c6\u786e\u5ea6\u663e\u8457\u63d0\u5347\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.10423", "categories": ["cs.AI", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.10423", "abs": "https://arxiv.org/abs/2509.10423", "authors": ["Cameron Reid", "Wael Hafez", "Amirhossein Nazeri"], "title": "Mutual Information Tracks Policy Coherence in Reinforcement Learning", "comment": "10 pages, 4 figures, 1 table", "summary": "Reinforcement Learning (RL) agents deployed in real-world environments face\ndegradation from sensor faults, actuator wear, and environmental shifts, yet\nlack intrinsic mechanisms to detect and diagnose these failures. We present an\ninformation-theoretic framework that reveals both the fundamental dynamics of\nRL and provides practical methods for diagnosing deployment-time anomalies.\nThrough analysis of state-action mutual information patterns in a robotic\ncontrol task, we first demonstrate that successful learning exhibits\ncharacteristic information signatures: mutual information between states and\nactions steadily increases from 0.84 to 2.83 bits (238% growth) despite growing\nstate entropy, indicating that agents develop increasingly selective attention\nto task-relevant patterns. Intriguingly, states, actions and next states joint\nmutual information, MI(S,A;S'), follows an inverted U-curve, peaking during\nearly learning before declining as the agent specializes suggesting a\ntransition from broad exploration to efficient exploitation. More immediately\nactionable, we show that information metrics can differentially diagnose system\nfailures: observation-space, i.e., states noise (sensor faults) produces broad\ncollapses across all information channels with pronounced drops in state-action\ncoupling, while action-space noise (actuator faults) selectively disrupts\naction-outcome predictability while preserving state-action relationships. This\ndifferential diagnostic capability demonstrated through controlled perturbation\nexperiments enables precise fault localization without architectural\nmodifications or performance degradation. By establishing information patterns\nas both signatures of learning and diagnostic for system health, we provide the\nfoundation for adaptive RL systems capable of autonomous fault detection and\npolicy adjustment based on information-theoretic principles.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u72b6\u6001-\u52a8\u4f5c\u4e92\u4fe1\u606f\u6a21\u5f0f\u6765\u8bca\u65adRL\u7cfb\u7edf\u90e8\u7f72\u65f6\u7684\u5f02\u5e38\uff0c\u80fd\u591f\u533a\u5206\u4f20\u611f\u5668\u6545\u969c\u548c\u9a71\u52a8\u5668\u6545\u969c\uff0c\u5b9e\u73b0\u7cbe\u786e\u6545\u969c\u5b9a\u4f4d\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u90e8\u7f72\u7684RL\u667a\u80fd\u4f53\u9762\u4e34\u4f20\u611f\u5668\u6545\u969c\u3001\u9a71\u52a8\u5668\u78e8\u635f\u548c\u73af\u5883\u53d8\u5316\u7b49\u95ee\u9898\uff0c\u4f46\u7f3a\u4e4f\u5185\u5728\u673a\u5236\u6765\u68c0\u6d4b\u548c\u8bca\u65ad\u8fd9\u4e9b\u6545\u969c\u3002", "method": "\u4f7f\u7528\u4fe1\u606f\u8bba\u6846\u67b6\u5206\u6790\u72b6\u6001-\u52a8\u4f5c\u4e92\u4fe1\u606f\u6a21\u5f0f\uff0c\u901a\u8fc7\u53d7\u63a7\u6270\u52a8\u5b9e\u9a8c\u9a8c\u8bc1\u4fe1\u606f\u6307\u6807\u5bf9\u7cfb\u7edf\u6545\u969c\u7684\u5dee\u5f02\u8bca\u65ad\u80fd\u529b\u3002", "result": "\u6210\u529f\u5b66\u4e60\u8868\u73b0\u51fa\u7279\u5f81\u6027\u4fe1\u606f\u7279\u5f81\uff1a\u72b6\u6001-\u52a8\u4f5c\u4e92\u4fe1\u606f\u4ece0.84\u589e\u957f\u52302.83\u6bd4\u7279\uff08\u589e\u957f238%\uff09\uff1b\u4fe1\u606f\u6307\u6807\u80fd\u591f\u533a\u5206\u89c2\u6d4b\u7a7a\u95f4\u566a\u58f0\uff08\u4f20\u611f\u5668\u6545\u969c\uff09\u548c\u52a8\u4f5c\u7a7a\u95f4\u566a\u58f0\uff08\u9a71\u52a8\u5668\u6545\u969c\uff09\u3002", "conclusion": "\u4fe1\u606f\u6a21\u5f0f\u65e2\u662f\u5b66\u4e60\u7684\u7279\u5f81\uff0c\u4e5f\u662f\u7cfb\u7edf\u5065\u5eb7\u7684\u8bca\u65ad\u5de5\u5177\uff0c\u4e3a\u80fd\u591f\u81ea\u4e3b\u6545\u969c\u68c0\u6d4b\u548c\u57fa\u4e8e\u4fe1\u606f\u8bba\u539f\u7406\u8fdb\u884c\u7b56\u7565\u8c03\u6574\u7684\u81ea\u9002\u5e94RL\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
