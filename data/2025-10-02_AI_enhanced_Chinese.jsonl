{"id": "2510.00151", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00151", "abs": "https://arxiv.org/abs/2510.00151", "authors": ["Valentin Barbaza", "Alan Rodrigo Diaz-Rizo", "Hassan Aboushady", "Spyridon Raptis", "Haralampos-G. Stratigopoulos"], "title": "Stealing AI Model Weights Through Covert Communication Channels", "comment": null, "summary": "AI models are often regarded as valuable intellectual property due to the\nhigh cost of their development, the competitive advantage they provide, and the\nproprietary techniques involved in their creation. As a result, AI model\nstealing attacks pose a serious concern for AI model providers. In this work,\nwe present a novel attack targeting wireless devices equipped with AI hardware\naccelerators. The attack unfolds in two phases. In the first phase, the\nvictim's device is compromised with a hardware Trojan (HT) designed to covertly\nleak model weights through a hidden communication channel, without the victim\nrealizing it. In the second phase, the adversary uses a nearby wireless device\nto intercept the victim's transmission frames during normal operation and\nincrementally reconstruct the complete weight matrix. The proposed attack is\nagnostic to both the AI model architecture and the hardware accelerator used.\nWe validate our approach through a hardware-based demonstration involving four\ndiverse AI models of varying types and sizes. We detail the design of the HT\nand the covert channel, highlighting their stealthy nature. Additionally, we\nanalyze the impact of bit error rates on the reception and propose an error\nmitigation technique. The effectiveness of the attack is evaluated based on the\naccuracy of the reconstructed models with stolen weights and the time required\nto extract them. Finally, we explore potential defense mechanisms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u914d\u5907AI\u786c\u4ef6\u52a0\u901f\u5668\u7684\u65e0\u7ebf\u8bbe\u5907\u7684\u65b0\u578b\u6a21\u578b\u7a83\u53d6\u653b\u51fb\uff0c\u901a\u8fc7\u786c\u4ef6\u6728\u9a6c\u548c\u9690\u853d\u901a\u4fe1\u901a\u9053\u7a83\u53d6\u6a21\u578b\u6743\u91cd\uff0c\u80fd\u591f\u91cd\u5efa\u5b8c\u6574\u6743\u91cd\u77e9\u9635\u4e14\u5bf9\u6a21\u578b\u67b6\u6784\u548c\u786c\u4ef6\u52a0\u901f\u5668\u65e0\u5173\u3002", "motivation": "AI\u6a21\u578b\u56e0\u5176\u9ad8\u6602\u5f00\u53d1\u6210\u672c\u3001\u7ade\u4e89\u4f18\u52bf\u548c\u4e13\u6709\u6280\u672f\u800c\u5177\u6709\u91cd\u8981\u77e5\u8bc6\u4ea7\u6743\u4ef7\u503c\uff0c\u6a21\u578b\u7a83\u53d6\u653b\u51fb\u5bf9AI\u6a21\u578b\u63d0\u4f9b\u5546\u6784\u6210\u4e25\u91cd\u5a01\u80c1\u3002", "method": "\u653b\u51fb\u5206\u4e24\u9636\u6bb5\uff1a\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7\u786c\u4ef6\u6728\u9a6c\u5728\u53d7\u5bb3\u8005\u8bbe\u5907\u4e0a\u5efa\u7acb\u9690\u853d\u901a\u4fe1\u901a\u9053\u6cc4\u9732\u6a21\u578b\u6743\u91cd\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u9644\u8fd1\u65e0\u7ebf\u8bbe\u5907\u62e6\u622a\u4f20\u8f93\u5e27\u5e76\u589e\u91cf\u91cd\u5efa\u5b8c\u6574\u6743\u91cd\u77e9\u9635\u3002", "result": "\u901a\u8fc7\u786c\u4ef6\u6f14\u793a\u9a8c\u8bc1\u4e86\u56db\u79cd\u4e0d\u540c\u7c7b\u578b\u548c\u5927\u5c0f\u7684AI\u6a21\u578b\u7684\u6709\u6548\u6027\uff0c\u5206\u6790\u4e86\u8bef\u7801\u7387\u5f71\u54cd\u5e76\u63d0\u51fa\u4e86\u9519\u8bef\u7f13\u89e3\u6280\u672f\uff0c\u8bc4\u4f30\u4e86\u91cd\u5efa\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u63d0\u53d6\u65f6\u95f4\u3002", "conclusion": "\u8be5\u653b\u51fb\u5177\u6709\u9690\u853d\u6027\u548c\u6709\u6548\u6027\uff0c\u9700\u8981\u63a2\u7d22\u76f8\u5e94\u7684\u9632\u5fa1\u673a\u5236\u6765\u4fdd\u62a4AI\u6a21\u578b\u77e5\u8bc6\u4ea7\u6743\u3002"}}
{"id": "2510.00164", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.00164", "abs": "https://arxiv.org/abs/2510.00164", "authors": ["Dominik Apel", "Zeta Avarikioti", "Matteo Maffei", "Yuheng Wang"], "title": "Calyx: Privacy-Preserving Multi-Token Optimistic-Rollup Protocol", "comment": null, "summary": "Rollup protocols have recently received significant attention as a promising\nclass of Layer 2 (L2) scalability solutions. By utilizing the Layer 1 (L1)\nblockchain solely as a bulletin board for a summary of the executed\ntransactions and state changes, rollups enable secure off-chain execution while\navoiding the complexity of other L2 mechanisms. However, to ensure data\navailability, current rollup protocols require the plaintext of executed\ntransactions to be published on-chain, resulting in inherent privacy\nlimitations.\n  In this paper, we address this problem by introducing Calyx, the first\nprivacy-preserving multi-token optimistic-Rollup protocol. Calyx guarantees\nfull payment privacy for all L2 transactions, revealing no information about\nthe sender, recipient, transferred amount, or token type. The protocol further\nsupports atomic execution of multiple multi-token transactions and introduces a\ntransaction fee scheme to enable broader application scenarios while ensuring\nthe sustainable operation of the protocol. To enforce correctness, Calyx adopts\nan efficient one-step fraud-proof mechanism. We analyze the security and\nprivacy guarantees of the protocol and provide an implementation and\nevaluation. Our results show that executing a single transaction costs\napproximately $0.06 (0.00002 ETH) and incurs only constant-size on-chain cost\nin asymptotic terms.", "AI": {"tldr": "Calyx\u662f\u9996\u4e2a\u9690\u79c1\u4fdd\u62a4\u7684\u591a\u4ee3\u5e01\u4e50\u89c2Rollup\u534f\u8bae\uff0c\u4e3a\u6240\u6709L2\u4ea4\u6613\u63d0\u4f9b\u5b8c\u6574\u7684\u652f\u4ed8\u9690\u79c1\u4fdd\u62a4\uff0c\u540c\u65f6\u652f\u6301\u591a\u4ee3\u5e01\u4ea4\u6613\u7684\u539f\u5b50\u6267\u884c\u548c\u53ef\u6301\u7eed\u7684\u8d39\u7528\u673a\u5236\u3002", "motivation": "\u5f53\u524dRollup\u534f\u8bae\u9700\u8981\u5728\u94fe\u4e0a\u53d1\u5e03\u660e\u6587\u4ea4\u6613\u6570\u636e\u4ee5\u786e\u4fdd\u6570\u636e\u53ef\u7528\u6027\uff0c\u8fd9\u5bfc\u81f4\u4e86\u56fa\u6709\u7684\u9690\u79c1\u9650\u5236\u3002", "method": "\u91c7\u7528\u9ad8\u6548\u7684\u4e00\u6b65\u6b3a\u8bc8\u8bc1\u660e\u673a\u5236\uff0c\u652f\u6301\u591a\u4ee3\u5e01\u4ea4\u6613\u7684\u539f\u5b50\u6267\u884c\uff0c\u5e76\u5f15\u5165\u4ea4\u6613\u8d39\u7528\u65b9\u6848\u3002", "result": "\u5355\u7b14\u4ea4\u6613\u6267\u884c\u6210\u672c\u7ea6\u4e3a0.06\u7f8e\u5143\uff080.00002 ETH\uff09\uff0c\u5728\u6e10\u8fd1\u610f\u4e49\u4e0a\u4ec5\u4ea7\u751f\u6052\u5b9a\u5927\u5c0f\u7684\u94fe\u4e0a\u6210\u672c\u3002", "conclusion": "Calyx\u6210\u529f\u89e3\u51b3\u4e86Rollup\u534f\u8bae\u7684\u9690\u79c1\u95ee\u9898\uff0c\u4e3aL2\u53ef\u6269\u5c55\u6027\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u652f\u4ed8\u9690\u79c1\u4fdd\u62a4\u3002"}}
{"id": "2510.00181", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00181", "abs": "https://arxiv.org/abs/2510.00181", "authors": ["Luis Burbano", "Diego Ortiz", "Qi Sun", "Siwei Yang", "Haoqin Tu", "Cihang Xie", "Yinzhi Cao", "Alvaro A Cardenas"], "title": "CHAI: Command Hijacking against embodied AI", "comment": null, "summary": "Embodied Artificial Intelligence (AI) promises to handle edge cases in\nrobotic vehicle systems where data is scarce by using common-sense reasoning\ngrounded in perception and action to generalize beyond training distributions\nand adapt to novel real-world situations. These capabilities, however, also\ncreate new security risks. In this paper, we introduce CHAI (Command Hijacking\nagainst embodied AI), a new class of prompt-based attacks that exploit the\nmultimodal language interpretation abilities of Large Visual-Language Models\n(LVLMs). CHAI embeds deceptive natural language instructions, such as\nmisleading signs, in visual input, systematically searches the token space,\nbuilds a dictionary of prompts, and guides an attacker model to generate Visual\nAttack Prompts. We evaluate CHAI on four LVLM agents; drone emergency landing,\nautonomous driving, and aerial object tracking, and on a real robotic vehicle.\nOur experiments show that CHAI consistently outperforms state-of-the-art\nattacks. By exploiting the semantic and multimodal reasoning strengths of\nnext-generation embodied AI systems, CHAI underscores the urgent need for\ndefenses that extend beyond traditional adversarial robustness.", "AI": {"tldr": "CHAI\u662f\u4e00\u79cd\u9488\u5bf9\u5177\u8eabAI\u7cfb\u7edf\u7684\u65b0\u578b\u63d0\u793a\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u591a\u6a21\u6001\u89c6\u89c9\u8f93\u5165\u4e2d\u5d4c\u5165\u6b3a\u9a97\u6027\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\uff0c\u5229\u7528\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6a21\u6001\u8bed\u8a00\u89e3\u91ca\u80fd\u529b\u8fdb\u884c\u547d\u4ee4\u52ab\u6301\u653b\u51fb\u3002", "motivation": "\u5177\u8eabAI\u7cfb\u7edf\u5728\u5904\u7406\u8fb9\u7f18\u60c5\u51b5\u65f6\u4f7f\u7528\u57fa\u4e8e\u611f\u77e5\u548c\u884c\u52a8\u7684\u5e38\u8bc6\u63a8\u7406\u6765\u6cdb\u5316\u8bad\u7ec3\u5206\u5e03\u4e4b\u5916\u7684\u60c5\u51b5\uff0c\u4f46\u8fd9\u4e9b\u80fd\u529b\u4e5f\u5e26\u6765\u4e86\u65b0\u7684\u5b89\u5168\u98ce\u9669\u3002", "method": "CHAI\u901a\u8fc7\u7cfb\u7edf\u641c\u7d22token\u7a7a\u95f4\u3001\u6784\u5efa\u63d0\u793a\u5b57\u5178\uff0c\u5e76\u6307\u5bfc\u653b\u51fb\u6a21\u578b\u751f\u6210\u89c6\u89c9\u653b\u51fb\u63d0\u793a\uff0c\u5728\u591a\u6a21\u6001\u89c6\u89c9\u8f93\u5165\u4e2d\u5d4c\u5165\u6b3a\u9a97\u6027\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\uff08\u5982\u8bef\u5bfc\u6027\u6807\u5fd7\uff09\u3002", "result": "\u5728\u56db\u4e2aLVLM\u4ee3\u7406\uff08\u65e0\u4eba\u673a\u7d27\u6025\u964d\u843d\u3001\u81ea\u52a8\u9a7e\u9a76\u3001\u7a7a\u4e2d\u76ee\u6807\u8ddf\u8e2a\uff09\u548c\u771f\u5b9e\u673a\u5668\u4eba\u8f66\u8f86\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCHAI\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u653b\u51fb\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528\u4e0b\u4e00\u4ee3\u5177\u8eabAI\u7cfb\u7edf\u7684\u8bed\u4e49\u548c\u591a\u6a21\u6001\u63a8\u7406\u4f18\u52bf\uff0cCHAI\u5f3a\u8c03\u4e86\u8d85\u8d8a\u4f20\u7edf\u5bf9\u6297\u9c81\u68d2\u6027\u7684\u9632\u5fa1\u63aa\u65bd\u7684\u7d27\u8feb\u9700\u6c42\u3002"}}
{"id": "2510.00240", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00240", "abs": "https://arxiv.org/abs/2510.00240", "authors": ["Ehsan Aghaei", "Sarthak Jain", "Prashanth Arun", "Arjun Sambamoorthy"], "title": "SecureBERT 2.0: Advanced Language Model for Cybersecurity Intelligence", "comment": null, "summary": "Effective analysis of cybersecurity and threat intelligence data demands\nlanguage models that can interpret specialized terminology, complex document\nstructures, and the interdependence of natural language and source code.\nEncoder-only transformer architectures provide efficient and robust\nrepresentations that support critical tasks such as semantic search, technical\nentity extraction, and semantic analysis, which are key to automated threat\ndetection, incident triage, and vulnerability assessment. However,\ngeneral-purpose language models often lack the domain-specific adaptation\nrequired for high precision. We present SecureBERT 2.0, an enhanced\nencoder-only language model purpose-built for cybersecurity applications.\nLeveraging the ModernBERT architecture, SecureBERT 2.0 introduces improved\nlong-context modeling and hierarchical encoding, enabling effective processing\nof extended and heterogeneous documents, including threat reports and source\ncode artifacts. Pretrained on a domain-specific corpus more than thirteen times\nlarger than its predecessor, comprising over 13 billion text tokens and 53\nmillion code tokens from diverse real-world sources, SecureBERT 2.0 achieves\nstate-of-the-art performance on multiple cybersecurity benchmarks. Experimental\nresults demonstrate substantial improvements in semantic search for threat\nintelligence, semantic analysis, cybersecurity-specific named entity\nrecognition, and automated vulnerability detection in code within the\ncybersecurity domain.", "AI": {"tldr": "SecureBERT 2.0\u662f\u4e00\u4e2a\u4e13\u4e3a\u7f51\u7edc\u5b89\u5168\u5e94\u7528\u8bbe\u8ba1\u7684\u589e\u5f3a\u578b\u7f16\u7801\u5668\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u591a\u4e2a\u7f51\u7edc\u5b89\u5168\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u901a\u7528\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u7f51\u7edc\u5b89\u5168\u9886\u57df\u6240\u9700\u7684\u9886\u57df\u7279\u5b9a\u9002\u5e94\u6027\uff0c\u65e0\u6cd5\u9ad8\u7cbe\u5ea6\u5904\u7406\u4e13\u4e1a\u672f\u8bed\u3001\u590d\u6742\u6587\u6863\u7ed3\u6784\u4ee5\u53ca\u81ea\u7136\u8bed\u8a00\u548c\u6e90\u4ee3\u7801\u7684\u76f8\u4e92\u4f9d\u8d56\u5173\u7cfb\u3002", "method": "\u57fa\u4e8eModernBERT\u67b6\u6784\uff0c\u91c7\u7528\u6539\u8fdb\u7684\u957f\u4e0a\u4e0b\u6587\u5efa\u6a21\u548c\u5206\u5c42\u7f16\u7801\uff0c\u5728\u6bd4\u524d\u8eab\u592713\u500d\u4ee5\u4e0a\u7684\u9886\u57df\u7279\u5b9a\u8bed\u6599\u5e93\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u5305\u542b\u8d85\u8fc7130\u4ebf\u6587\u672c\u6807\u8bb0\u548c5300\u4e07\u4ee3\u7801\u6807\u8bb0\u3002", "result": "\u5728\u5a01\u80c1\u60c5\u62a5\u8bed\u4e49\u641c\u7d22\u3001\u8bed\u4e49\u5206\u6790\u3001\u7f51\u7edc\u5b89\u5168\u7279\u5b9a\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u548c\u4ee3\u7801\u6f0f\u6d1e\u81ea\u52a8\u68c0\u6d4b\u65b9\u9762\u8868\u73b0\u51fa\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "SecureBERT 2.0\u4e3a\u7f51\u7edc\u5b89\u5168\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u4e13\u7528\u8bed\u8a00\u6a21\u578b\uff0c\u80fd\u591f\u5904\u7406\u6269\u5c55\u548c\u5f02\u6784\u6587\u6863\uff0c\u652f\u6301\u81ea\u52a8\u5316\u5a01\u80c1\u68c0\u6d4b\u3001\u4e8b\u4ef6\u5206\u7c7b\u548c\u6f0f\u6d1e\u8bc4\u4f30\u7b49\u5173\u952e\u4efb\u52a1\u3002"}}
{"id": "2510.00002", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.00002", "abs": "https://arxiv.org/abs/2510.00002", "authors": ["Dong Liu"], "title": "PBFD and PDFD: Formally Defined and Verified Methodologies and Empirical Evaluation for Scalable Full-Stack Software Engineering", "comment": "184 pages; 35 figures; A DOI-linked version of this paper and all\n  supplementary materials are available on Zenodo at\n  https://zenodo.org/records/16883985", "summary": "This paper introduces Primary Breadth-First Development (PBFD) and Primary\nDepth-First Development (PDFD), two formally defined and verified methodologies\nfor scalable, industrial-grade full-stack software engineering. These\napproaches bridge a longstanding gap between formal methods and real-world\ndevelopment practice by enforcing structural correctness through\ngraph-theoretic modeling. Unlike prior graph-based approaches, PBFD and PDFD\noperate over layered directed graphs and are formalized using unified state\nmachines and Communicating Sequential Processes (CSP) to ensure critical\nproperties, including bounded-refinement termination and structural\ncompleteness. To coordinate hierarchical data at scale, we propose Three-Level\nEncapsulation (TLE) - a novel, bitmask-based encoding scheme that delivers\nprovably constant-time updates. TLE's formal guarantees underpin PBFD's\nindustrial-scale performance and scalability. PBFD was empirically validated\nthrough an eight-year enterprise deployment, demonstrating over 20x faster\ndevelopment than Salesforce OmniScript and 7-8x faster query performance\ncompared to conventional relational models. Additionally, both methodologies\nare supported by open-source MVPs, with PDFD's implementation conclusively\ndemonstrating its correctness-first design principles. Together, PBFD and PDFD\nestablish a reproducible, transparent framework that integrates formal\nverification into practical software development. All formal specifications,\nMVPs, and datasets are publicly available to foster academic research and\nindustrial-grade adoption.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86PBFD\u548cPDFD\u4e24\u79cd\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u8f6f\u4ef6\u5f00\u53d1\u65b9\u6cd5\uff0c\u901a\u8fc7\u56fe\u8bba\u5efa\u6a21\u786e\u4fdd\u7ed3\u6784\u6b63\u786e\u6027\uff0c\u5e76\u63d0\u51fa\u4e86TLE\u7f16\u7801\u65b9\u6848\u5b9e\u73b0\u5e38\u6570\u65f6\u95f4\u66f4\u65b0\u3002\u57288\u5e74\u4f01\u4e1a\u90e8\u7f72\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6027\u80fd\u4f18\u52bf\u3002", "motivation": "\u5f25\u5408\u5f62\u5f0f\u5316\u65b9\u6cd5\u4e0e\u5b9e\u9645\u5f00\u53d1\u5b9e\u8df5\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u5de5\u4e1a\u7ea7\u5168\u6808\u8f6f\u4ef6\u5f00\u53d1\u63d0\u4f9b\u53ef\u6269\u5c55\u4e14\u7ed3\u6784\u6b63\u786e\u7684\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u5206\u5c42\u6709\u5411\u56fe\u7684PBFD\u548cPDFD\u65b9\u6cd5\uff0c\u4f7f\u7528\u7edf\u4e00\u72b6\u6001\u673a\u548cCSP\u8fdb\u884c\u5f62\u5f0f\u5316\uff0c\u63d0\u51faTLE\u4e09\u5c42\u6b21\u5c01\u88c5\u7f16\u7801\u65b9\u6848\u3002", "result": "\u4f01\u4e1a\u90e8\u7f72\u663e\u793a\u5f00\u53d1\u901f\u5ea6\u6bd4Salesforce OmniScript\u5feb20\u500d\u4ee5\u4e0a\uff0c\u67e5\u8be2\u6027\u80fd\u6bd4\u4f20\u7edf\u5173\u7cfb\u6a21\u578b\u5feb7-8\u500d\u3002", "conclusion": "PBFD\u548cPDFD\u5efa\u7acb\u4e86\u5c06\u5f62\u5f0f\u5316\u9a8c\u8bc1\u878d\u5165\u5b9e\u9645\u8f6f\u4ef6\u5f00\u53d1\u7684\u900f\u660e\u6846\u67b6\uff0c\u6240\u6709\u89c4\u8303\u548c\u5b9e\u73b0\u5747\u5df2\u5f00\u6e90\u3002"}}
{"id": "2510.00022", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.00022", "abs": "https://arxiv.org/abs/2510.00022", "authors": ["Ansh Kamthan"], "title": "Learning to Lead Themselves: Agentic AI in MAS using MARL", "comment": "Exploring foundational behaviours of agentic ai using MARL 39 pages -\n  25 minute read, 5 tables, 24 equation, 9 figures", "summary": "As autonomous systems move from prototypes to real deployments, the ability\nof multiple agents to make decentralized, cooperative decisions becomes a core\nrequirement. This paper examines how agentic artificial intelligence, agents\nthat act independently, adaptively and proactively can improve task allocation\nand coordination in multi-agent systems, with primary emphasis on drone\ndelivery and secondary relevance to warehouse automation. We formulate the\nproblem in a cooperative multi-agent reinforcement learning setting and\nimplement a lightweight multi-agent Proximal Policy Optimization, called IPPO,\napproach in PyTorch under a centralized-training, decentralized-execution\nparadigm. Experiments are conducted in PettingZoo environment, where multiple\nhomogeneous drones or agents must self-organize to cover distinct targets\nwithout explicit communication.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u4f7f\u7528\u81ea\u4e3bAI\u667a\u80fd\u4f53\u6539\u5584\u4efb\u52a1\u5206\u914d\u548c\u534f\u8c03\u7684\u65b9\u6cd5\uff0c\u91cd\u70b9\u5173\u6ce8\u65e0\u4eba\u673a\u914d\u9001\u548c\u4ed3\u5e93\u81ea\u52a8\u5316\u5e94\u7528\u3002", "motivation": "\u968f\u7740\u81ea\u4e3b\u7cfb\u7edf\u4ece\u539f\u578b\u8f6c\u5411\u5b9e\u9645\u90e8\u7f72\uff0c\u591a\u667a\u80fd\u4f53\u8fdb\u884c\u53bb\u4e2d\u5fc3\u5316\u534f\u540c\u51b3\u7b56\u7684\u80fd\u529b\u6210\u4e3a\u6838\u5fc3\u9700\u6c42\u3002", "method": "\u5728\u5408\u4f5c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u4e0b\uff0c\u91c7\u7528\u96c6\u4e2d\u8bad\u7ec3\u3001\u5206\u6563\u6267\u884c\u7684\u8f7b\u91cf\u7ea7\u591a\u667a\u80fd\u4f53\u8fd1\u7aef\u7b56\u7565\u4f18\u5316(IPPO)\u65b9\u6cd5\uff0c\u5728PettingZoo\u73af\u5883\u4e2d\u5b9e\u73b0\u3002", "result": "\u591a\u4e2a\u540c\u8d28\u65e0\u4eba\u673a\u6216\u667a\u80fd\u4f53\u80fd\u591f\u5728\u6ca1\u6709\u663e\u5f0f\u901a\u4fe1\u7684\u60c5\u51b5\u4e0b\u81ea\u7ec4\u7ec7\u8986\u76d6\u4e0d\u540c\u76ee\u6807\u3002", "conclusion": "\u81ea\u4e3bAI\u667a\u80fd\u4f53\u80fd\u591f\u6709\u6548\u63d0\u5347\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u4efb\u52a1\u5206\u914d\u548c\u534f\u8c03\u80fd\u529b\u3002"}}
{"id": "2510.00317", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.00317", "abs": "https://arxiv.org/abs/2510.00317", "authors": ["Youpeng Li", "Kartik Joshi", "Xinda Wang", "Eric Wong"], "title": "MAVUL: Multi-Agent Vulnerability Detection via Contextual Reasoning and Interactive Refinement", "comment": "Accepted by The 7th IEEE International Conference on Trust, Privacy\n  and Security in Intelligent Systems, and Applications (IEEE TPS 2025)", "summary": "The widespread adoption of open-source software (OSS) necessitates the\nmitigation of vulnerability risks. Most vulnerability detection (VD) methods\nare limited by inadequate contextual understanding, restrictive single-round\ninteractions, and coarse-grained evaluations, resulting in undesired model\nperformance and biased evaluation results. To address these challenges, we\npropose MAVUL, a novel multi-agent VD system that integrates contextual\nreasoning and interactive refinement. Specifically, a vulnerability analyst\nagent is designed to flexibly leverage tool-using capabilities and contextual\nreasoning to achieve cross-procedural code understanding and effectively mine\nvulnerability patterns. Through iterative feedback and refined decision-making\nwithin cross-role agent interactions, the system achieves reliable reasoning\nand vulnerability prediction. Furthermore, MAVUL introduces multi-dimensional\nground truth information for fine-grained evaluation, thereby enhancing\nevaluation accuracy and reliability.\n  Extensive experiments conducted on a pairwise vulnerability dataset\ndemonstrate MAVUL's superior performance. Our findings indicate that MAVUL\nsignificantly outperforms existing multi-agent systems with over 62% higher\npairwise accuracy and single-agent systems with over 600% higher average\nperformance. The system's effectiveness is markedly improved with increased\ncommunication rounds between the vulnerability analyst agent and the security\narchitect agent, underscoring the importance of contextual reasoning in tracing\nvulnerability flows and the crucial feedback role. Additionally, the integrated\nevaluation agent serves as a critical, unbiased judge, ensuring a more accurate\nand reliable estimation of the system's real-world applicability by preventing\nmisleading binary comparisons.", "AI": {"tldr": "MAVUL\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u591a\u4ee3\u7406\u6f0f\u6d1e\u68c0\u6d4b\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u63a8\u7406\u548c\u4ea4\u4e92\u5f0f\u4f18\u5316\u6765\u89e3\u51b3\u4f20\u7edf\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\u548c\u8bc4\u4f30\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u4e0a\u4e0b\u6587\u7406\u89e3\u4e0d\u8db3\u3001\u5355\u8f6e\u4ea4\u4e92\u9650\u5236\u548c\u7c97\u7c92\u5ea6\u8bc4\u4f30\u7b49\u95ee\u9898\uff0c\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u4e0d\u4f73\u548c\u8bc4\u4f30\u7ed3\u679c\u504f\u5dee\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u6709\u6548\u7684\u68c0\u6d4b\u7cfb\u7edf\u3002", "method": "\u8bbe\u8ba1\u6f0f\u6d1e\u5206\u6790\u5e08\u4ee3\u7406\uff0c\u5229\u7528\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u548c\u4e0a\u4e0b\u6587\u63a8\u7406\u5b9e\u73b0\u8de8\u8fc7\u7a0b\u4ee3\u7801\u7406\u89e3\uff1b\u901a\u8fc7\u8de8\u89d2\u8272\u4ee3\u7406\u4ea4\u4e92\u7684\u8fed\u4ee3\u53cd\u9988\u548c\u4f18\u5316\u51b3\u7b56\u5b9e\u73b0\u53ef\u9760\u63a8\u7406\uff1b\u5f15\u5165\u591a\u7ef4\u771f\u5b9e\u4fe1\u606f\u8fdb\u884c\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u3002", "result": "\u5728\u6210\u5bf9\u6f0f\u6d1e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMAVUL\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u591a\u4ee3\u7406\u7cfb\u7edf\uff08\u6210\u5bf9\u51c6\u786e\u7387\u9ad862%\u4ee5\u4e0a\uff09\u548c\u5355\u4ee3\u7406\u7cfb\u7edf\uff08\u5e73\u5747\u6027\u80fd\u9ad8600%\u4ee5\u4e0a\uff09\uff1b\u6f0f\u6d1e\u5206\u6790\u5e08\u4e0e\u5b89\u5168\u67b6\u6784\u5e08\u4ee3\u7406\u95f4\u901a\u4fe1\u8f6e\u6b21\u589e\u52a0\u80fd\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6548\u679c\u3002", "conclusion": "MAVUL\u901a\u8fc7\u4e0a\u4e0b\u6587\u63a8\u7406\u8ffd\u8e2a\u6f0f\u6d1e\u6d41\u548c\u5173\u952e\u53cd\u9988\u673a\u5236\uff0c\u7ed3\u5408\u96c6\u6210\u8bc4\u4f30\u4ee3\u7406\u4f5c\u4e3a\u65e0\u504f\u5224\u65ad\uff0c\u786e\u4fdd\u4e86\u7cfb\u7edf\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u8bc4\u4f30\u3002"}}
{"id": "2510.00003", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.00003", "abs": "https://arxiv.org/abs/2510.00003", "authors": ["Malte Hansen", "Jens Bamberg", "Noe Baumann", "Wilhelm Hasselbring"], "title": "Semantic Zoom and Mini-Maps for Software Cities", "comment": "Copyright 2025 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "summary": "Software visualization tools can facilitate program comprehension by\nproviding visual metaphors, or abstractions that reduce the amount of textual\ndata that needs to be processed mentally. One way they do this is by enabling\ndevelopers to build an internal representation of the visualized software and\nits architecture. However, as the amount of displayed data in the visualization\nincreases, the visualization itself can become more difficult to comprehend.\nThe ability to display small and large amounts of data in visualizations is\ncalled visual scalability.\n  In this paper, we present two approaches to address the challenge of visual\nscalability in 3D software cities. First, we present an approach to semantic\nzoom, in which the graphical representation of the software landscape changes\nbased on the virtual camera's distance from visual objects. Second, we augment\nthe visualization with a miniature two-dimensional top-view projection called\nmini-map. We demonstrate our approach using an open-source implementation in\nour software visualization tool ExplorViz. ExplorViz is web-based and uses the\n3D city metaphor, focusing on live trace visualization.\n  We evaluated our approaches in two separate user studies. The results\nindicate that semantic zoom and the mini-map are both useful additions. User\nfeedback indicates that semantic zoom and mini-maps are especially useful for\nlarge software landscapes and collaborative software exploration. The studies\nindicate a good usability of our implemented approaches. However, some\nshortcomings in our implementations have also been discovered, to be addressed\nin future work.\n  Video URL: https://youtu.be/LYtUeWvizjU", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u89e3\u51b33D\u8f6f\u4ef6\u57ce\u5e02\u53ef\u89c6\u5316\u53ef\u6269\u5c55\u6027\u6311\u6218\u7684\u65b9\u6cd5\uff1a\u8bed\u4e49\u7f29\u653e\u548c\u8ff7\u4f60\u5730\u56fe\uff0c\u5e76\u5728ExplorViz\u5de5\u5177\u4e2d\u5b9e\u73b0\u548c\u8bc4\u4f30\u3002", "motivation": "\u968f\u7740\u53ef\u89c6\u5316\u4e2d\u663e\u793a\u6570\u636e\u91cf\u7684\u589e\u52a0\uff0c\u53ef\u89c6\u5316\u672c\u8eab\u53ef\u80fd\u53d8\u5f97\u96be\u4ee5\u7406\u89e3\uff0c\u9700\u8981\u89e3\u51b3\u89c6\u89c9\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002", "method": "1. \u8bed\u4e49\u7f29\u653e\uff1a\u57fa\u4e8e\u865a\u62df\u76f8\u673a\u4e0e\u89c6\u89c9\u5bf9\u8c61\u7684\u8ddd\u79bb\u6539\u53d8\u8f6f\u4ef6\u666f\u89c2\u7684\u56fe\u5f62\u8868\u793a\n2. \u8ff7\u4f60\u5730\u56fe\uff1a\u6dfb\u52a0\u4e8c\u7ef4\u4fef\u89c6\u6295\u5f71\u7684\u8ff7\u4f60\u5730\u56fe\n\u5728\u57fa\u4e8eWeb\u7684ExplorViz\u8f6f\u4ef6\u53ef\u89c6\u5316\u5de5\u5177\u4e2d\u5b9e\u73b0", "result": "\u4e24\u4e2a\u72ec\u7acb\u7684\u7528\u6237\u7814\u7a76\u8868\u660e\uff0c\u8bed\u4e49\u7f29\u653e\u548c\u8ff7\u4f60\u5730\u56fe\u90fd\u662f\u6709\u7528\u7684\u8865\u5145\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5927\u578b\u8f6f\u4ef6\u666f\u89c2\u548c\u534f\u4f5c\u8f6f\u4ef6\u63a2\u7d22\uff0c\u663e\u793a\u51fa\u826f\u597d\u7684\u53ef\u7528\u6027\u3002", "conclusion": "\u8bed\u4e49\u7f29\u653e\u548c\u8ff7\u4f60\u5730\u56fe\u80fd\u6709\u6548\u63d0\u53473D\u8f6f\u4ef6\u57ce\u5e02\u7684\u89c6\u89c9\u53ef\u6269\u5c55\u6027\uff0c\u4f46\u5b9e\u73b0\u4e2d\u5b58\u5728\u4e00\u4e9b\u9700\u8981\u6539\u8fdb\u7684\u7f3a\u70b9\u3002"}}
{"id": "2510.00023", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00023", "abs": "https://arxiv.org/abs/2510.00023", "authors": ["Quy Minh Le", "Minh Sao Khue Luu", "Khanh-Tung Tran", "Duc-Hai Nguyen", "Hoang-Quoc-Viet Pham", "Quan Le", "Hoang Thanh Lam", "Hoang D. Nguyen"], "title": "ToolBrain: A Flexible Reinforcement Learning Framework for Agentic Tools", "comment": null, "summary": "Effective tool use is essential for agentic AI, yet training agents to\nutilize tools remains challenging due to manually designed rewards, limited\ntraining data, and poor multi-tool selection, resulting in slow adaptation,\nwasted computational resources, and suboptimal performance. We introduce\nToolBrain, a lightweight and user-friendly framework for coaching tool use in\nagentic models with flexible reinforcement learning (RL), easing the barriers\nfor researchers and practitioners to adapt LLM-based agents to specific\ndomains. It supports a wide range of training strategies, including RL\nalgorithms such as GRPO and DPO, as well as supervised learning. ToolBrain\nenables custom reward callables directly on an agent's execution traces or\nsimply utilizes an automated LLM-as-a-judge system for reward generation. It is\npacked with useful capabilities, including knowledge distillation from large to\nsmall models for efficient development, automatic task generation from tool\ndescriptions, seamless tool retrieval, efficient fine-tuning pipelines with\nQLoRA through Unsloth, and quantized inference via bitsandbytes. We demonstrate\nToolBrain through diverse use cases, such as training a CodeAct agent to\nautonomously execute email search tasks, showing fast, targeted improvements\n(up to 30.0%) in tool-use skills while keeping the codebase simple and\nextensible in Agentic AI. Our framework is publicly available at\nhttps://toolbrain.org.", "AI": {"tldr": "ToolBrain\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u667a\u80fd\u4ee3\u7406\u4f7f\u7528\u5de5\u5177\uff0c\u89e3\u51b3\u624b\u52a8\u8bbe\u8ba1\u5956\u52b1\u3001\u6570\u636e\u4e0d\u8db3\u548c\u591a\u5de5\u5177\u9009\u62e9\u7b49\u95ee\u9898\uff0c\u63d0\u5347\u4ee3\u7406\u7684\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u8bad\u7ec3\u4ee3\u7406\u4f7f\u7528\u5de5\u5177\u9762\u4e34\u624b\u52a8\u8bbe\u8ba1\u5956\u52b1\u3001\u8bad\u7ec3\u6570\u636e\u6709\u9650\u548c\u591a\u5de5\u5177\u9009\u62e9\u56f0\u96be\u7b49\u6311\u6218\uff0c\u5bfc\u81f4\u9002\u5e94\u6162\u3001\u8ba1\u7b97\u8d44\u6e90\u6d6a\u8d39\u548c\u6027\u80fd\u4e0d\u4f73\u3002", "method": "ToolBrain\u6846\u67b6\u652f\u6301\u591a\u79cd\u8bad\u7ec3\u7b56\u7565\uff08GRPO\u3001DPO\u7b49\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u548c\u76d1\u7763\u5b66\u4e60\uff09\uff0c\u63d0\u4f9b\u81ea\u5b9a\u4e49\u5956\u52b1\u51fd\u6570\u548c\u81ea\u52a8LLM\u8bc4\u5224\u7cfb\u7edf\uff0c\u5177\u5907\u77e5\u8bc6\u84b8\u998f\u3001\u81ea\u52a8\u4efb\u52a1\u751f\u6210\u3001\u5de5\u5177\u68c0\u7d22\u3001\u9ad8\u6548\u5fae\u8c03\u7b49\u529f\u80fd\u3002", "result": "\u5728\u4ee3\u7801\u4ee3\u7406\u6267\u884c\u90ae\u4ef6\u641c\u7d22\u4efb\u52a1\u4e2d\uff0cToolBrain\u5b9e\u73b0\u4e86\u5de5\u5177\u4f7f\u7528\u6280\u80fd\u7684\u5feb\u901f\u9488\u5bf9\u6027\u6539\u8fdb\uff08\u63d0\u5347\u8fbe30.0%\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u4ee3\u7801\u5e93\u7b80\u6d01\u53ef\u6269\u5c55\u3002", "conclusion": "ToolBrain\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7528\u6237\u53cb\u597d\u3001\u8f7b\u91cf\u7ea7\u7684\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u8bad\u7ec3LLM\u4ee3\u7406\u5728\u7279\u5b9a\u9886\u57df\u4e2d\u4f7f\u7528\u5de5\u5177\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2510.00322", "categories": ["cs.CR", "cs.CC", "cs.DS", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00322", "abs": "https://arxiv.org/abs/2510.00322", "authors": ["G\u00fcnter F. Steinke", "Thomas Steinke"], "title": "Privately Estimating Black-Box Statistics", "comment": null, "summary": "Standard techniques for differentially private estimation, such as Laplace or\nGaussian noise addition, require guaranteed bounds on the sensitivity of the\nestimator in question. But such sensitivity bounds are often large or simply\nunknown. Thus we seek differentially private methods that can be applied to\narbitrary black-box functions. A handful of such techniques exist, but all are\neither inefficient in their use of data or require evaluating the function on\nexponentially many inputs. In this work we present a scheme that trades off\nbetween statistical efficiency (i.e., how much data is needed) and oracle\nefficiency (i.e., the number of evaluations). We also present lower bounds\nshowing the near-optimality of our scheme.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u7edf\u8ba1\u6548\u7387\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u6743\u8861\u7684\u5dee\u5206\u9690\u79c1\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u4efb\u610f\u9ed1\u76d2\u51fd\u6570\uff0c\u65e0\u9700\u654f\u611f\u6027\u8fb9\u754c", "motivation": "\u4f20\u7edf\u5dee\u5206\u9690\u79c1\u65b9\u6cd5\u9700\u8981\u4f30\u8ba1\u5668\u7684\u654f\u611f\u6027\u8fb9\u754c\uff0c\u4f46\u8fd9\u4e9b\u8fb9\u754c\u5f80\u5f80\u5f88\u5927\u6216\u672a\u77e5\u3002\u73b0\u6709\u9ed1\u76d2\u65b9\u6cd5\u8981\u4e48\u6570\u636e\u4f7f\u7528\u6548\u7387\u4f4e\uff0c\u8981\u4e48\u9700\u8981\u6307\u6570\u7ea7\u51fd\u6570\u8bc4\u4f30", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5728\u7edf\u8ba1\u6548\u7387\uff08\u6240\u9700\u6570\u636e\u91cf\uff09\u548coracle\u6548\u7387\uff08\u8bc4\u4f30\u6b21\u6570\uff09\u4e4b\u95f4\u6743\u8861\u7684\u65b9\u6848", "result": "\u63d0\u51fa\u7684\u65b9\u6848\u5728\u4e24\u79cd\u6548\u7387\u4e4b\u95f4\u5b9e\u73b0\u4e86\u826f\u597d\u7684\u6743\u8861\uff0c\u5e76\u7ed9\u51fa\u4e86\u8bc1\u660e\u65b9\u6848\u63a5\u8fd1\u6700\u4f18\u7684\u4e0b\u754c", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u5dee\u5206\u9690\u79c1\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u4efb\u610f\u9ed1\u76d2\u51fd\u6570\uff0c\u65e0\u9700\u654f\u611f\u6027\u8fb9\u754c\uff0c\u5728\u6548\u7387\u548c\u5b9e\u7528\u6027\u4e4b\u95f4\u53d6\u5f97\u4e86\u5e73\u8861"}}
{"id": "2510.00004", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.00004", "abs": "https://arxiv.org/abs/2510.00004", "authors": ["Malte Hansen", "David Moreno-Lumbreras", "Wilhelm Hasselbring"], "title": "HTML Structure Exploration in 3D Software Cities", "comment": "Copyright 2025 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "summary": "Software visualization, which uses data from dynamic program analysis, can\nhelp to explore and understand the behavior of software systems. It is common\nthat large software systems offer a web interface for user interaction.\nUsually, available web interfaces are not regarded in software visualization\ntools. This paper introduces additions to the web-based live tracing software\nvisualization tool ExplorViz: We add an embedded web view for instrumented\napplications in the 3D visualization to ease interaction with the given\napplications and enable the exploration of the thereby displayed HTML content.\nNamely, the Document Object Model (DOM) is visualized via a three-dimensional\nrepresentation of the HTML structure in same-origin contexts.\n  Our visualization approach is evaluated in a preliminary user study. The\nstudy results give insights into the potential use cases, benefits, and\nshortcomings of our implemented approach. Based on our study results, we\npropose directions for further research to support the visual exploration of\nweb interfaces and explore use cases for the combined visualization of software\ncities and HTML structure.\n  Video URL: https://youtu.be/wBWKlbvzOOE", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86ExplorViz\u5de5\u5177\u7684\u6269\u5c55\u529f\u80fd\uff0c\u57283D\u8f6f\u4ef6\u53ef\u89c6\u5316\u4e2d\u5d4c\u5165Web\u89c6\u56fe\uff0c\u7528\u4e8e\u53ef\u89c6\u5316HTML\u7ed3\u6784\u548cDOM\uff0c\u5e76\u901a\u8fc7\u7528\u6237\u7814\u7a76\u8bc4\u4f30\u4e86\u8be5\u65b9\u6cd5\u7684\u6f5c\u529b\u3002", "motivation": "\u5927\u578b\u8f6f\u4ef6\u7cfb\u7edf\u901a\u5e38\u63d0\u4f9bWeb\u754c\u9762\uff0c\u4f46\u73b0\u6709\u7684\u8f6f\u4ef6\u53ef\u89c6\u5316\u5de5\u5177\u5f80\u5f80\u5ffd\u7565\u8fd9\u4e9b\u754c\u9762\u3002\u4e3a\u4e86\u5e2e\u52a9\u7528\u6237\u66f4\u597d\u5730\u7406\u89e3\u548c\u63a2\u7d22\u8f6f\u4ef6\u7cfb\u7edf\u7684\u884c\u4e3a\uff0c\u9700\u8981\u5c06Web\u754c\u9762\u96c6\u6210\u5230\u53ef\u89c6\u5316\u5de5\u5177\u4e2d\u3002", "method": "\u5728\u57fa\u4e8eWeb\u7684\u5b9e\u65f6\u8ffd\u8e2a\u8f6f\u4ef6\u53ef\u89c6\u5316\u5de5\u5177ExplorViz\u4e2d\uff0c\u6dfb\u52a0\u4e86\u5d4c\u5165\u5f0fWeb\u89c6\u56fe\uff0c\u7528\u4e8e\u68c0\u6d4b\u5e94\u7528\u7a0b\u5e8f\u3002\u901a\u8fc73D\u53ef\u89c6\u5316\u5c55\u793aHTML\u7ed3\u6784\uff0c\u7279\u522b\u662f\u5728\u540c\u6e90\u4e0a\u4e0b\u6587\u4e2d\u53ef\u89c6\u5316\u6587\u6863\u5bf9\u8c61\u6a21\u578b(DOM)\u3002", "result": "\u901a\u8fc7\u521d\u6b65\u7528\u6237\u7814\u7a76\u8bc4\u4f30\u4e86\u53ef\u89c6\u5316\u65b9\u6cd5\uff0c\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u6f5c\u5728\u7528\u4f8b\u3001\u4f18\u52bf\u548c\u4e0d\u8db3\u3002", "conclusion": "\u57fa\u4e8e\u7814\u7a76\u7ed3\u679c\uff0c\u63d0\u51fa\u4e86\u8fdb\u4e00\u6b65\u7814\u7a76\u65b9\u5411\uff0c\u4ee5\u652f\u6301Web\u754c\u9762\u7684\u53ef\u89c6\u5316\u63a2\u7d22\uff0c\u5e76\u63a2\u7d22\u8f6f\u4ef6\u57ce\u5e02\u4e0eHTML\u7ed3\u6784\u7ec4\u5408\u53ef\u89c6\u5316\u7684\u7528\u4f8b\u3002"}}
{"id": "2510.00071", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00071", "abs": "https://arxiv.org/abs/2510.00071", "authors": ["Dongqi Zheng"], "title": "ARS: Adaptive Reasoning Suppression for Efficient Large Reasoning Language Models", "comment": "Accepted by 39th NeurIPS - Foundations of Reasoning in Language\n  Models", "summary": "Large Reasoning Language Models (LRLMs or LRMs) demonstrate remarkable\ncapabilities in complex reasoning tasks, but suffer from significant\ncomputational inefficiencies due to overthinking phenomena. Existing efficient\nreasoning methods face the challenge of balancing reasoning quality with\ninference cost reduction. We propose \\textbf{Adaptive Reasoning Suppression\n(ARS)}, a novel training-free approach that dynamically suppresses redundant\nreasoning steps while preserving accuracy through adaptive certainty\nmonitoring. ARS introduces a multi-checkpoint certainty estimation mechanism\nwith progressive suppression thresholds, achieving superior efficiency compared\nto static suppression methods. Our extensive evaluation across mathematical\nreasoning benchmarks using multiple model architectures demonstrates that ARS\nachieves up to 53%, 46.1%, and 57.9% in token, latency and energy reduction,\nwhile maintaining or improving accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u81ea\u9002\u5e94\u63a8\u7406\u6291\u5236\uff08ARS\uff09\u7684\u8bad\u7ec3\u514d\u8d39\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u6291\u5236\u5197\u4f59\u63a8\u7406\u6b65\u9aa4\u6765\u63d0\u5347\u5927\u578b\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u7684\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b58\u5728\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5e73\u8861\u63a8\u7406\u8d28\u91cf\u4e0e\u63a8\u7406\u6210\u672c\u964d\u4f4e\u3002", "method": "ARS\u91c7\u7528\u591a\u68c0\u67e5\u70b9\u786e\u5b9a\u6027\u4f30\u8ba1\u673a\u5236\u548c\u6e10\u8fdb\u6291\u5236\u9608\u503c\uff0c\u52a8\u6001\u76d1\u6d4b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u786e\u5b9a\u6027\uff0c\u6291\u5236\u5197\u4f59\u63a8\u7406\u6b65\u9aa4\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cARS\u5b9e\u73b0\u4e86\u9ad8\u8fbe53%\u7684token\u51cf\u5c11\u300146.1%\u7684\u5ef6\u8fdf\u964d\u4f4e\u548c57.9%\u7684\u80fd\u8017\u51cf\u5c11\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u3002", "conclusion": "ARS\u662f\u4e00\u79cd\u6709\u6548\u7684\u8bad\u7ec3\u514d\u8d39\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u63a8\u7406\u6548\u7387\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2510.00350", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.00350", "abs": "https://arxiv.org/abs/2510.00350", "authors": ["Akshaya Kumar", "Anna Raymaker", "Michael Specter"], "title": "Security and Privacy Analysis of Tile's Location Tracking Protocol", "comment": null, "summary": "We conduct the first comprehensive security analysis of Tile, the second most\npopular crowd-sourced location-tracking service behind Apple's AirTags. We\nidentify several exploitable vulnerabilities and design flaws, disproving many\nof the platform's claimed security and privacy guarantees: Tile's servers can\npersistently learn the location of all users and tags, unprivileged adversaries\ncan track users through Bluetooth advertisements emitted by Tile's devices, and\nTile's anti-theft mode is easily subverted.\n  Despite its wide deployment -- millions of users, devices, and purpose-built\nhardware tags -- Tile provides no formal description of its protocol or threat\nmodel. Worse, Tile intentionally weakens its antistalking features to support\nan antitheft use-case and relies on a novel \"accountability\" mechanism to\npunish those abusing the system to stalk victims.\n  We examine Tile's accountability mechanism, a unique feature of independent\ninterest; no other provider attempts to guarantee accountability. While an\nideal accountability mechanism may disincentivize abuse in crowd-sourced\nlocation tracking protocols, we show that Tile's implementation is subvertible\nand introduces new exploitable vulnerabilities. We conclude with a discussion\non the need for new, formal definitions of accountability in this setting.", "AI": {"tldr": "\u9996\u6b21\u5bf9Tile\u4f4d\u7f6e\u8ffd\u8e2a\u670d\u52a1\u8fdb\u884c\u5b89\u5168\u5206\u6790\uff0c\u53d1\u73b0\u591a\u4e2a\u53ef\u88ab\u5229\u7528\u7684\u6f0f\u6d1e\u548c\u8bbe\u8ba1\u7f3a\u9677\uff0c\u5305\u62ec\u670d\u52a1\u5668\u53ef\u8ffd\u8e2a\u6240\u6709\u7528\u6237\u4f4d\u7f6e\u3001\u84dd\u7259\u5e7f\u544a\u53ef\u88ab\u653b\u51fb\u8005\u5229\u7528\u3001\u9632\u76d7\u6a21\u5f0f\u6613\u88ab\u7ed5\u8fc7\u7b49\u95ee\u9898\u3002", "motivation": "Tile\u4f5c\u4e3a\u4ec5\u6b21\u4e8e\u82f9\u679cAirTags\u7684\u7b2c\u4e8c\u5927\u4f17\u5305\u4f4d\u7f6e\u8ffd\u8e2a\u670d\u52a1\uff0c\u58f0\u79f0\u63d0\u4f9b\u5b89\u5168\u548c\u9690\u79c1\u4fdd\u969c\uff0c\u4f46\u7f3a\u4e4f\u6b63\u5f0f\u534f\u8bae\u63cf\u8ff0\u548c\u5a01\u80c1\u6a21\u578b\uff0c\u9700\u8981\u9a8c\u8bc1\u5176\u5b89\u5168\u6027\u627f\u8bfa\u3002", "method": "\u901a\u8fc7\u5206\u6790Tile\u5e73\u53f0\u7684\u6f0f\u6d1e\u548c\u8bbe\u8ba1\u7f3a\u9677\uff0c\u8bc4\u4f30\u5176\u5b89\u5168\u673a\u5236\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u5173\u6ce8\u53cd\u8ddf\u8e2a\u529f\u80fd\u548c\u95ee\u8d23\u673a\u5236\u7684\u5b9e\u65bd\u3002", "result": "\u53d1\u73b0Tile\u670d\u52a1\u5668\u53ef\u6301\u4e45\u8ffd\u8e2a\u6240\u6709\u7528\u6237\u4f4d\u7f6e\uff0c\u975e\u7279\u6743\u653b\u51fb\u8005\u53ef\u901a\u8fc7\u84dd\u7259\u5e7f\u544a\u8ffd\u8e2a\u7528\u6237\uff0c\u9632\u76d7\u6a21\u5f0f\u6613\u88ab\u7ed5\u8fc7\uff0c\u95ee\u8d23\u673a\u5236\u5b58\u5728\u53ef\u88ab\u5229\u7528\u7684\u6f0f\u6d1e\u3002", "conclusion": "Tile\u7684\u5b89\u5168\u548c\u9690\u79c1\u4fdd\u969c\u5b58\u5728\u4e25\u91cd\u95ee\u9898\uff0c\u9700\u8981\u65b0\u7684\u6b63\u5f0f\u95ee\u8d23\u673a\u5236\u5b9a\u4e49\u6765\u6539\u5584\u4f17\u5305\u4f4d\u7f6e\u8ffd\u8e2a\u534f\u8bae\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2510.00031", "categories": ["cs.SE", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.00031", "abs": "https://arxiv.org/abs/2510.00031", "authors": ["Shun-ichiro Hayashi", "Koki Morita", "Daichi Mukunoki", "Tetsuya Hoshino", "Takahiro Katagiri"], "title": "VibeCodeHPC: An Agent-Based Iterative Prompting Auto-Tuner for HPC Code Generation Using LLMs", "comment": null, "summary": "We propose VibeCodeHPC, an automatic tuning system for HPC programs based on\nmulti-agent LLMs for code generation. VibeCodeHPC tunes programs through\nmulti-agent role allocation and iterative prompt refinement. We describe the\nsystem configuration with four roles: Project Manager (PM), System Engineer\n(SE), Programmer (PG), and Continuous Delivery (CD). We introduce dynamic agent\ndeployment and activity monitoring functions to facilitate effective\nmulti-agent collaboration. In our case study, we convert and optimize CPU-based\nmatrix-matrix multiplication code written in C to GPU code using CUDA. The\nmulti-agent configuration of VibeCodeHPC achieved higher-quality code\ngeneration per unit time compared to a solo-agent configuration. Additionally,\nthe dynamic agent deployment and activity monitoring capabilities facilitated\nmore effective identification of requirement violations and other issues.", "AI": {"tldr": "VibeCodeHPC\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53LLM\u7684HPC\u7a0b\u5e8f\u81ea\u52a8\u8c03\u4f18\u7cfb\u7edf\uff0c\u901a\u8fc7\u89d2\u8272\u5206\u914d\u548c\u8fed\u4ee3\u63d0\u793a\u4f18\u5316\u6765\u8c03\u4f18\u7a0b\u5e8f", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u81ea\u52a8\u8c03\u4f18HPC\u7a0b\u5e8f\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u63d0\u9ad8\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u548c\u6548\u7387", "method": "\u4f7f\u7528\u56db\u89d2\u8272\u591a\u667a\u80fd\u4f53\u914d\u7f6e\uff08\u9879\u76ee\u7ecf\u7406\u3001\u7cfb\u7edf\u5de5\u7a0b\u5e08\u3001\u7a0b\u5e8f\u5458\u3001\u6301\u7eed\u4ea4\u4ed8\uff09\uff0c\u7ed3\u5408\u52a8\u6001\u667a\u80fd\u4f53\u90e8\u7f72\u548c\u6d3b\u52a8\u76d1\u63a7\u529f\u80fd", "result": "\u5728CPU\u5230GPU\u4ee3\u7801\u8f6c\u6362\u6848\u4f8b\u4e2d\uff0c\u591a\u667a\u80fd\u4f53\u914d\u7f6e\u76f8\u6bd4\u5355\u667a\u80fd\u4f53\u5b9e\u73b0\u4e86\u66f4\u9ad8\u8d28\u91cf\u7684\u4ee3\u7801\u751f\u6210\uff0c\u5e76\u80fd\u66f4\u6709\u6548\u5730\u8bc6\u522b\u9700\u6c42\u8fdd\u89c4\u95ee\u9898", "conclusion": "\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u5728HPC\u7a0b\u5e8f\u8c03\u4f18\u4e2d\u5177\u6709\u4f18\u52bf\uff0c\u52a8\u6001\u90e8\u7f72\u548c\u76d1\u63a7\u529f\u80fd\u589e\u5f3a\u4e86\u534f\u4f5c\u6548\u679c"}}
{"id": "2510.00075", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00075", "abs": "https://arxiv.org/abs/2510.00075", "authors": ["Rishi Bommasani"], "title": "NeurIPS should lead scientific consensus on AI policy", "comment": "Published at NeurIPS 2025", "summary": "Designing wise AI policy is a grand challenge for society. To design such\npolicy, policymakers should place a premium on rigorous evidence and scientific\nconsensus. While several mechanisms exist for evidence generation, and nascent\nmechanisms tackle evidence synthesis, we identify a complete void on consensus\nformation. In this position paper, we argue NeurIPS should actively catalyze\nscientific consensus on AI policy. Beyond identifying the current deficit in\nconsensus formation mechanisms, we argue that NeurIPS is the best option due\nits strengths and the paucity of compelling alternatives. To make progress, we\nrecommend initial pilots for NeurIPS by distilling lessons from the IPCC's\nleadership to build scientific consensus on climate policy. We dispel\npredictable counters that AI researchers disagree too much to achieve consensus\nand that policy engagement is not the business of NeurIPS. NeurIPS leads AI on\nmany fronts, and it should champion scientific consensus to create higher\nquality AI policy.", "AI": {"tldr": "\u8bba\u6587\u4e3b\u5f20NeurIPS\u4f1a\u8bae\u5e94\u79ef\u6781\u63a8\u52a8AI\u653f\u7b56\u79d1\u5b66\u5171\u8bc6\u7684\u5f62\u6210\uff0c\u501f\u9274IPCC\u5728\u6c14\u5019\u653f\u7b56\u65b9\u9762\u7684\u7ecf\u9a8c\uff0c\u901a\u8fc7\u8bd5\u70b9\u9879\u76ee\u6765\u586b\u8865\u5f53\u524d\u5171\u8bc6\u5f62\u6210\u673a\u5236\u7684\u7a7a\u767d\u3002", "motivation": "\u5f53\u524dAI\u653f\u7b56\u5236\u5b9a\u7f3a\u4e4f\u79d1\u5b66\u5171\u8bc6\u5f62\u6210\u673a\u5236\uff0c\u800cNeurIPS\u4f5c\u4e3aAI\u9886\u57df\u7684\u9886\u5bfc\u8005\uff0c\u6700\u9002\u5408\u627f\u62c5\u8fd9\u4e00\u89d2\u8272\uff0c\u4ee5\u4fc3\u8fdb\u66f4\u9ad8\u8d28\u91cf\u7684AI\u653f\u7b56\u5236\u5b9a\u3002", "method": "\u5efa\u8baeNeurIPS\u501f\u9274IPCC\u5728\u6c14\u5019\u653f\u7b56\u5171\u8bc6\u5f62\u6210\u65b9\u9762\u7684\u7ecf\u9a8c\uff0c\u5f00\u5c55\u521d\u6b65\u8bd5\u70b9\u9879\u76ee\uff0c\u901a\u8fc7\u8bc1\u636e\u751f\u6210\u548c\u7efc\u5408\u6765\u63a8\u52a8\u79d1\u5b66\u5171\u8bc6\u3002", "result": "\u8bba\u6587\u8bc6\u522b\u4e86\u5f53\u524dAI\u653f\u7b56\u5171\u8bc6\u5f62\u6210\u7684\u5b8c\u5168\u7a7a\u767d\uff0c\u5e76\u8bba\u8bc1\u4e86NeurIPS\u662f\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u7684\u6700\u4f73\u9009\u62e9\u3002", "conclusion": "NeurIPS\u5e94\u8be5\u5728AI\u653f\u7b56\u79d1\u5b66\u5171\u8bc6\u5f62\u6210\u65b9\u9762\u53d1\u6325\u9886\u5bfc\u4f5c\u7528\uff0c\u8fd9\u7b26\u5408\u5176\u5728AI\u9886\u57df\u7684\u9886\u5bfc\u5730\u4f4d\uff0c\u5e76\u80fd\u4ea7\u751f\u66f4\u9ad8\u8d28\u91cf\u7684AI\u653f\u7b56\u3002"}}
{"id": "2510.00451", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.00451", "abs": "https://arxiv.org/abs/2510.00451", "authors": ["Dalal Alharthi", "Ivan Roberto Kawaminami Garcia"], "title": "A Call to Action for a Secure-by-Design Generative AI Paradigm", "comment": null, "summary": "Large language models have gained widespread prominence, yet their\nvulnerability to prompt injection and other adversarial attacks remains a\ncritical concern. This paper argues for a security-by-design AI paradigm that\nproactively mitigates LLM vulnerabilities while enhancing performance. To\nachieve this, we introduce PromptShield, an ontology-driven framework that\nensures deterministic and secure prompt interactions. It standardizes user\ninputs through semantic validation, eliminating ambiguity and mitigating\nadversarial manipulation. To assess PromptShield's security and performance\ncapabilities, we conducted an experiment on an agent-based system to analyze\ncloud logs within Amazon Web Services (AWS), containing 493 distinct events\nrelated to malicious activities and anomalies. By simulating prompt injection\nattacks and assessing the impact of deploying PromptShield, our results\ndemonstrate a significant improvement in model security and performance,\nachieving precision, recall, and F1 scores of approximately 94%. Notably, the\nontology-based framework not only mitigates adversarial threats but also\nenhances the overall performance and reliability of the system. Furthermore,\nPromptShield's modular and adaptable design ensures its applicability beyond\ncloud security, making it a robust solution for safeguarding generative AI\napplications across various domains. By laying the groundwork for AI safety\nstandards and informing future policy development, this work stimulates a\ncrucial dialogue on the pivotal role of deterministic prompt engineering and\nontology-based validation in ensuring the safe and responsible deployment of\nLLMs in high-stakes environments.", "AI": {"tldr": "\u63d0\u51faPromptShield\u6846\u67b6\uff0c\u901a\u8fc7\u672c\u4f53\u9a71\u52a8\u7684\u8bed\u4e49\u9a8c\u8bc1\u6765\u9632\u5fa1LLM\u7684\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u5728AWS\u4e91\u65e5\u5fd7\u5206\u6790\u5b9e\u9a8c\u4e2d\u5b9e\u73b0\u4e86\u7ea694%\u7684\u5b89\u5168\u6027\u548c\u6027\u80fd\u6307\u6807\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5e7f\u6cdb\u4f7f\u7528\u4f46\u5b58\u5728\u63d0\u793a\u6ce8\u5165\u7b49\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u8981\u5efa\u7acb\u5b89\u5168\u4f18\u5148\u7684AI\u8303\u5f0f\u6765\u4e3b\u52a8\u7f13\u89e3\u8fd9\u4e9b\u6f0f\u6d1e\u3002", "method": "\u5f00\u53d1PromptShield\u6846\u67b6\uff0c\u91c7\u7528\u672c\u4f53\u9a71\u52a8\u7684\u8bed\u4e49\u9a8c\u8bc1\u6807\u51c6\u5316\u7528\u6237\u8f93\u5165\uff0c\u6d88\u9664\u6b67\u4e49\u5e76\u9632\u5fa1\u5bf9\u6297\u6027\u64cd\u7eb5\u3002", "result": "\u5728AWS\u4e91\u65e5\u5fd7\u5206\u6790\u5b9e\u9a8c\u4e2d\uff0cPromptShield\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5b89\u5168\u6027\u548c\u6027\u80fd\uff0c\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u5747\u8fbe\u5230\u7ea694%\u3002", "conclusion": "PromptShield\u4e0d\u4ec5\u6709\u6548\u9632\u5fa1\u5bf9\u6297\u5a01\u80c1\uff0c\u8fd8\u63d0\u5347\u4e86\u7cfb\u7edf\u6574\u4f53\u6027\u80fd\u548c\u53ef\u9760\u6027\uff0c\u5176\u6a21\u5757\u5316\u8bbe\u8ba1\u4f7f\u5176\u9002\u7528\u4e8e\u5404\u79cd\u751f\u6210\u5f0fAI\u5e94\u7528\u9886\u57df\u3002"}}
{"id": "2510.00092", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.00092", "abs": "https://arxiv.org/abs/2510.00092", "authors": ["Shufeng Chen", "Mariat James Elizebeth", "Robab Aghazadeh Chakherlou", "Xingyu Zhao", "Eric Barbier", "Siddartha Khastgir", "Paul Jennings"], "title": "A Scalable Framework for Safety Assurance of Self-Driving Vehicles based on Assurance 2.0", "comment": null, "summary": "Assurance 2.0 is a modern framework developed to address the assurance\nchallenges of increasingly complex, adaptive, and autonomous systems. Building\non the traditional Claims-Argument-Evidence (CAE) model, it introduces reusable\nassurance theories and explicit counterarguments (defeaters) to enhance rigor,\ntransparency, and adaptability. It supports continuous, incremental assurance,\nenabling innovation without compromising safety. However, limitations persist\nin confidence measurement, residual doubt management, automation support, and\nthe practical handling of defeaters and confirmation bias. This paper presents\n\\textcolor{black}{a set of decomposition frameworks to identify a complete set\nof safety arguments and measure their corresponding evidence.} Grounded in the\nAssurance 2.0 paradigm, the framework is instantiated through a structured\ntemplate and employs a three-tiered decomposition strategy. \\textcolor{black}{A\ncase study regarding the application of the decomposition framework in the\nend-to-end (E2E) AI-based Self-Driving Vehicle (SDV) development is also\npresented in this paper.} At the top level, the SDV development is divided into\nthree critical phases: Requirements Engineering (RE), Verification and\nValidation (VnV), and Post-Deployment (PD). Each phase is further decomposed\naccording to its Product Development Lifecycle (PDLC). To ensure comprehensive\ncoverage, each PDLC is analyzed using an adapted 5M1E model (Man, Machine,\nMethod, Material, Measurement, and Environment). Originally developed for\nmanufacturing quality control, the 5M1E model is reinterpreted and contextually\nmapped to the assurance domain. This enables a multi-dimensional decomposition\nthat supports fine-grained traceability of safety claims, evidence, and\npotential defeaters.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8eAssurance 2.0\u8303\u5f0f\u7684\u5206\u89e3\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6a21\u677f\u548c\u4e09\u5c42\u6b21\u5206\u89e3\u7b56\u7565\uff0c\u4e3a\u7aef\u5230\u7aefAI\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u5f00\u53d1\u63d0\u4f9b\u5b8c\u6574\u7684\u5b89\u5168\u8bba\u8bc1\u96c6\u548c\u8bc1\u636e\u5ea6\u91cf\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3Assurance 2.0\u5728\u7f6e\u4fe1\u5ea6\u6d4b\u91cf\u3001\u6b8b\u4f59\u7591\u8651\u7ba1\u7406\u3001\u81ea\u52a8\u5316\u652f\u6301\u4ee5\u53ca\u5b9e\u9645\u5904\u7406\u53cd\u9a73\u548c\u786e\u8ba4\u504f\u5dee\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u590d\u6742\u81ea\u9002\u5e94\u7cfb\u7edf\u63d0\u4f9b\u66f4\u4e25\u8c28\u7684\u4fdd\u8bc1\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e09\u5c42\u6b21\u5206\u89e3\u7b56\u7565\uff1a\u9876\u5c42\u5c06SDV\u5f00\u53d1\u5206\u4e3a\u9700\u6c42\u5de5\u7a0b\u3001\u9a8c\u8bc1\u4e0e\u9a8c\u8bc1\u3001\u90e8\u7f72\u540e\u4e09\u4e2a\u9636\u6bb5\uff1b\u6bcf\u4e2a\u9636\u6bb5\u6309\u4ea7\u54c1\u5f00\u53d1\u751f\u547d\u5468\u671f\u8fdb\u4e00\u6b65\u5206\u89e3\uff1b\u4f7f\u7528\u6539\u8fdb\u76845M1E\u6a21\u578b\uff08\u4eba\u3001\u673a\u3001\u65b9\u6cd5\u3001\u6750\u6599\u3001\u6d4b\u91cf\u3001\u73af\u5883\uff09\u8fdb\u884c\u591a\u7ef4\u5ea6\u5206\u6790\u3002", "result": "\u5f00\u53d1\u4e86\u7ed3\u6784\u5316\u6a21\u677f\u548c\u5206\u89e3\u6846\u67b6\uff0c\u652f\u6301\u5b89\u5168\u58f0\u660e\u3001\u8bc1\u636e\u548c\u6f5c\u5728\u53cd\u9a73\u7684\u7ec6\u7c92\u5ea6\u53ef\u8ffd\u6eaf\u6027\uff0c\u5e76\u901a\u8fc7\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u8be5\u5206\u89e3\u6846\u67b6\u80fd\u591f\u8bc6\u522b\u5b8c\u6574\u7684\u5b89\u5168\u8bba\u8bc1\u96c6\u5e76\u5ea6\u91cf\u76f8\u5e94\u8bc1\u636e\uff0c\u589e\u5f3a\u4e86Assurance 2.0\u5728\u590d\u6742\u7cfb\u7edf\u5b89\u5168\u4fdd\u8bc1\u4e2d\u7684\u5b9e\u7528\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2510.00084", "categories": ["cs.AI", "cs.CY", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.00084", "abs": "https://arxiv.org/abs/2510.00084", "authors": ["Fabian Kovac", "Sebastian Neumaier", "Timea Pahi", "Torsten Priebe", "Rafael Rodrigues", "Dimitrios Christodoulou", "Maxime Cordy", "Sylvain Kubler", "Ali Kordia", "Georgios Pitsiladis", "John Soldatos", "Petros Zervoudakis"], "title": "Towards a Framework for Supporting the Ethical and Regulatory Certification of AI Systems", "comment": "Accepted for publication in the proceedings of the Workshop on AI\n  Certification, Fairness and Regulations, co-located with the Austrian\n  Symposium on AI and Vision (AIRoV 2025)", "summary": "Artificial Intelligence has rapidly become a cornerstone technology,\nsignificantly influencing Europe's societal and economic landscapes. However,\nthe proliferation of AI also raises critical ethical, legal, and regulatory\nchallenges. The CERTAIN (Certification for Ethical and Regulatory Transparency\nin Artificial Intelligence) project addresses these issues by developing a\ncomprehensive framework that integrates regulatory compliance, ethical\nstandards, and transparency into AI systems. In this position paper, we outline\nthe methodological steps for building the core components of this framework.\nSpecifically, we present: (i) semantic Machine Learning Operations (MLOps) for\nstructured AI lifecycle management, (ii) ontology-driven data lineage tracking\nto ensure traceability and accountability, and (iii) regulatory operations\n(RegOps) workflows to operationalize compliance requirements. By implementing\nand validating its solutions across diverse pilots, CERTAIN aims to advance\nregulatory compliance and to promote responsible AI innovation aligned with\nEuropean standards.", "AI": {"tldr": "CERTAIN\u9879\u76ee\u5f00\u53d1\u4e86\u4e00\u4e2a\u7efc\u5408\u6846\u67b6\uff0c\u5c06\u76d1\u7ba1\u5408\u89c4\u3001\u4f26\u7406\u6807\u51c6\u548c\u900f\u660e\u5ea6\u6574\u5408\u5230AI\u7cfb\u7edf\u4e2d\uff0c\u901a\u8fc7\u8bed\u4e49MLOps\u3001\u672c\u4f53\u9a71\u52a8\u7684\u6570\u636e\u8c31\u7cfb\u8ddf\u8e2a\u548cRegOps\u5de5\u4f5c\u6d41\u6765\u89e3\u51b3AI\u7684\u4f26\u7406\u3001\u6cd5\u5f8b\u548c\u76d1\u7ba1\u6311\u6218\u3002", "motivation": "AI\u5728\u6b27\u6d32\u793e\u4f1a\u548c\u7ecf\u6d4e\u4e2d\u7684\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u4e86\u5173\u952e\u7684\u4f26\u7406\u3001\u6cd5\u5f8b\u548c\u76d1\u7ba1\u6311\u6218\uff0c\u9700\u8981\u5efa\u7acb\u80fd\u591f\u786e\u4fdd\u5408\u89c4\u6027\u548c\u900f\u660e\u5ea6\u7684\u6846\u67b6\u3002", "method": "\u5f00\u53d1\u8bed\u4e49MLOps\u8fdb\u884c\u7ed3\u6784\u5316AI\u751f\u547d\u5468\u671f\u7ba1\u7406\uff0c\u4f7f\u7528\u672c\u4f53\u9a71\u52a8\u7684\u6570\u636e\u8c31\u7cfb\u8ddf\u8e2a\u786e\u4fdd\u53ef\u8ffd\u6eaf\u6027\u548c\u95ee\u8d23\u5236\uff0c\u4ee5\u53ca\u5b9e\u65bdRegOps\u5de5\u4f5c\u6d41\u6765\u64cd\u4f5c\u5316\u5408\u89c4\u8981\u6c42\u3002", "result": "\u901a\u8fc7\u5728\u4e0d\u540c\u8bd5\u70b9\u4e2d\u5b9e\u65bd\u548c\u9a8c\u8bc1\u89e3\u51b3\u65b9\u6848\uff0cCERTAIN\u9879\u76ee\u63a8\u8fdb\u4e86\u76d1\u7ba1\u5408\u89c4\uff0c\u5e76\u4fc3\u8fdb\u4e86\u7b26\u5408\u6b27\u6d32\u6807\u51c6\u7684\u8d1f\u8d23\u4efbAI\u521b\u65b0\u3002", "conclusion": "CERTAIN\u9879\u76ee\u901a\u8fc7\u5176\u7efc\u5408\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86AI\u7684\u4f26\u7406\u548c\u76d1\u7ba1\u6311\u6218\uff0c\u4e3a\u6b27\u6d32\u7684\u8d1f\u8d23\u4efbAI\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u652f\u6301\u3002"}}
{"id": "2510.00452", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.00452", "abs": "https://arxiv.org/abs/2510.00452", "authors": ["Dalal Alharthi", "Ivan Roberto Kawaminami Garcia"], "title": "Cloud Investigation Automation Framework (CIAF): An AI-Driven Approach to Cloud Forensics", "comment": null, "summary": "Large Language Models (LLMs) have gained prominence in domains including\ncloud security and forensics. Yet cloud forensic investigations still rely on\nmanual analysis, making them time-consuming and error-prone. LLMs can mimic\nhuman reasoning, offering a pathway to automating cloud log analysis. To\naddress this, we introduce the Cloud Investigation Automation Framework (CIAF),\nan ontology-driven framework that systematically investigates cloud forensic\nlogs while improving efficiency and accuracy. CIAF standardizes user inputs\nthrough semantic validation, eliminating ambiguity and ensuring consistency in\nlog interpretation. This not only enhances data quality but also provides\ninvestigators with reliable, standardized information for decision-making. To\nevaluate security and performance, we analyzed Microsoft Azure logs containing\nransomware-related events. By simulating attacks and assessing CIAF's impact,\nresults showed significant improvement in ransomware detection, achieving\nprecision, recall, and F1 scores of 93 percent. CIAF's modular, adaptable\ndesign extends beyond ransomware, making it a robust solution for diverse\ncyberattacks. By laying the foundation for standardized forensic methodologies\nand informing future AI-driven automation, this work underscores the role of\ndeterministic prompt engineering and ontology-based validation in enhancing\ncloud forensic investigations. These advancements improve cloud security while\npaving the way for efficient, automated forensic workflows.", "AI": {"tldr": "\u63d0\u51fa\u4e86Cloud Investigation Automation Framework (CIAF)\uff0c\u4e00\u4e2a\u57fa\u4e8e\u672c\u4f53\u7684\u81ea\u52a8\u5316\u4e91\u53d6\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u9a8c\u8bc1\u6807\u51c6\u5316\u7528\u6237\u8f93\u5165\uff0c\u63d0\u9ad8\u52d2\u7d22\u8f6f\u4ef6\u68c0\u6d4b\u6548\u7387\uff0c\u51c6\u786e\u7387\u8fbe\u523093%\u3002", "motivation": "\u4e91\u53d6\u8bc1\u8c03\u67e5\u4ecd\u4f9d\u8d56\u624b\u52a8\u5206\u6790\uff0c\u8017\u65f6\u4e14\u5bb9\u6613\u51fa\u9519\u3002LLMs\u80fd\u591f\u6a21\u62df\u4eba\u7c7b\u63a8\u7406\uff0c\u4e3a\u81ea\u52a8\u5316\u4e91\u65e5\u5fd7\u5206\u6790\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002", "method": "\u5f00\u53d1\u4e86CIAF\u6846\u67b6\uff0c\u91c7\u7528\u672c\u4f53\u9a71\u52a8\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bed\u4e49\u9a8c\u8bc1\u6807\u51c6\u5316\u7528\u6237\u8f93\u5165\uff0c\u6d88\u9664\u6b67\u4e49\uff0c\u786e\u4fdd\u65e5\u5fd7\u89e3\u91ca\u7684\u4e00\u81f4\u6027\u3002", "result": "\u5728\u5fae\u8f6fAzure\u65e5\u5fd7\u4e0a\u7684\u6d4b\u8bd5\u663e\u793a\uff0c\u52d2\u7d22\u8f6f\u4ef6\u68c0\u6d4b\u7684\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u5747\u8fbe\u523093%\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\u3002", "conclusion": "CIAF\u7684\u6a21\u5757\u5316\u3001\u9002\u5e94\u6027\u8bbe\u8ba1\u4f7f\u5176\u6210\u4e3a\u5904\u7406\u5404\u79cd\u7f51\u7edc\u653b\u51fb\u7684\u5f3a\u5927\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u6807\u51c6\u5316\u53d6\u8bc1\u65b9\u6cd5\u548c\u672a\u6765AI\u9a71\u52a8\u7684\u81ea\u52a8\u5316\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.00197", "categories": ["cs.SE", "D.2.11"], "pdf": "https://arxiv.org/pdf/2510.00197", "abs": "https://arxiv.org/abs/2510.00197", "authors": ["Diogo Maia", "Filipe Correia", "Andr\u00e9 Restivo", "Paulo Queiroz"], "title": "Container Orchestration Patterns for Optimizing Resource Use", "comment": null, "summary": "Service-based architectures provide substantial benefits, yet service\norchestration remains a challenge, particularly for newcomers. While various\nresources on orchestration techniques exist, they often lack clarity and\nstandardization, making best practices difficult to implement and limiting\ntheir adoption within the software industry.\n  To address this gap, we analyzed existing literature and tools to identify\ncommon orchestration practices. Based on our findings, we define three key\norchestration resource optimization patterns: {\\sc Preemptive Scheduling}, {\\sc\nService Balancing}, and {\\sc Garbage Collection}. {\\sc Preemptive Scheduling}\nallows the allocation of sufficient resources for services of higher priority\nin stressful situations, while {\\sc Service Balancing} enables a restructuring\nof the nodes to allow better resource usage. To end, {\\sc Garbage Collection}\ncreates cleanup mechanisms to better understand the system's resource usage and\noptimize it. These patterns serve as foundational elements for improving\norchestration practices and fostering broader adoption in service-based\narchitectures.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e09\u79cd\u670d\u52a1\u7f16\u6392\u8d44\u6e90\u4f18\u5316\u6a21\u5f0f\uff1a\u62a2\u5360\u5f0f\u8c03\u5ea6\u3001\u670d\u52a1\u5e73\u8861\u548c\u5783\u573e\u56de\u6536\uff0c\u4ee5\u89e3\u51b3\u670d\u52a1\u7f16\u6392\u4e2d\u7684\u6311\u6218\u5e76\u4fc3\u8fdb\u6700\u4f73\u5b9e\u8df5\u7684\u91c7\u7528\u3002", "motivation": "\u670d\u52a1\u7f16\u6392\u5728\u57fa\u4e8e\u670d\u52a1\u7684\u67b6\u6784\u4e2d\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u65b0\u624b\u800c\u8a00\u3002\u73b0\u6709\u7684\u7f16\u6392\u6280\u672f\u8d44\u6e90\u7f3a\u4e4f\u6e05\u6670\u5ea6\u548c\u6807\u51c6\u5316\uff0c\u4f7f\u5f97\u6700\u4f73\u5b9e\u8df5\u96be\u4ee5\u5b9e\u65bd\uff0c\u9650\u5236\u4e86\u5728\u8f6f\u4ef6\u884c\u4e1a\u4e2d\u7684\u91c7\u7528\u3002", "method": "\u901a\u8fc7\u5206\u6790\u73b0\u6709\u6587\u732e\u548c\u5de5\u5177\uff0c\u8bc6\u522b\u5e38\u89c1\u7684\u7f16\u6392\u5b9e\u8df5\uff0c\u5e76\u57fa\u4e8e\u53d1\u73b0\u5b9a\u4e49\u4e86\u4e09\u79cd\u5173\u952e\u7684\u7f16\u6392\u8d44\u6e90\u4f18\u5316\u6a21\u5f0f\u3002", "result": "\u5b9a\u4e49\u4e86\u4e09\u79cd\u7f16\u6392\u8d44\u6e90\u4f18\u5316\u6a21\u5f0f\uff1a\u62a2\u5360\u5f0f\u8c03\u5ea6\uff08\u4e3a\u9ad8\u4f18\u5148\u7ea7\u670d\u52a1\u5206\u914d\u8db3\u591f\u8d44\u6e90\uff09\u3001\u670d\u52a1\u5e73\u8861\uff08\u91cd\u65b0\u7ec4\u7ec7\u8282\u70b9\u4ee5\u6539\u5584\u8d44\u6e90\u4f7f\u7528\uff09\u548c\u5783\u573e\u56de\u6536\uff08\u521b\u5efa\u6e05\u7406\u673a\u5236\u4ee5\u4f18\u5316\u7cfb\u7edf\u8d44\u6e90\u4f7f\u7528\uff09\u3002", "conclusion": "\u8fd9\u4e9b\u6a21\u5f0f\u4f5c\u4e3a\u6539\u8fdb\u7f16\u6392\u5b9e\u8df5\u548c\u4fc3\u8fdb\u5728\u57fa\u4e8e\u670d\u52a1\u7684\u67b6\u6784\u4e2d\u66f4\u5e7f\u6cdb\u91c7\u7528\u7684\u57fa\u7840\u8981\u7d20\u3002"}}
{"id": "2510.00088", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.00088", "abs": "https://arxiv.org/abs/2510.00088", "authors": ["Sagnik Basu", "Shubham Prakash", "Ashish Maruti Barge", "Siddharth D Jaiswal", "Abhisek Dash", "Saptarshi Ghosh", "Animesh Mukherjee"], "title": "Judging by Appearances? Auditing and Intervening Vision-Language Models for Bail Prediction", "comment": null, "summary": "Large language models (LLMs) have been extensively used for legal judgment\nprediction tasks based on case reports and crime history. However, with a surge\nin the availability of large vision language models (VLMs), legal judgment\nprediction systems can now be made to leverage the images of the criminals in\naddition to the textual case reports/crime history. Applications built in this\nway could lead to inadvertent consequences and be used with malicious intent.\nIn this work, we run an audit to investigate the efficiency of standalone VLMs\nin the bail decision prediction task. We observe that the performance is poor\nacross multiple intersectional groups and models \\textit{wrongly deny bail to\ndeserving individuals with very high confidence}. We design different\nintervention algorithms by first including legal precedents through a RAG\npipeline and then fine-tuning the VLMs using innovative schemes. We demonstrate\nthat these interventions substantially improve the performance of bail\nprediction. Our work paves the way for the design of smarter interventions on\nVLMs in the future, before they can be deployed for real-world legal judgment\nprediction.", "AI": {"tldr": "\u672c\u6587\u5ba1\u8ba1\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u4fdd\u91ca\u51b3\u7b56\u9884\u6d4b\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6a21\u578b\u6027\u80fd\u5dee\u4e14\u4f1a\u9519\u8bef\u62d2\u7edd\u5e94\u83b7\u4fdd\u91ca\u8005\uff0c\u901a\u8fc7RAG\u7ba1\u9053\u548c\u6cd5\u5f8b\u5148\u4f8b\u4ee5\u53ca\u5fae\u8c03\u5e72\u9884\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5174\u8d77\uff0c\u6cd5\u5f8b\u5224\u51b3\u9884\u6d4b\u7cfb\u7edf\u53ef\u80fd\u5229\u7528\u7f6a\u72af\u56fe\u50cf\u548c\u6587\u672c\u6848\u4ef6\u62a5\u544a\uff0c\u8fd9\u53ef\u80fd\u5e26\u6765\u610f\u5916\u540e\u679c\u548c\u6076\u610f\u4f7f\u7528\uff0c\u56e0\u6b64\u9700\u8981\u8bc4\u4f30\u5176\u6548\u7387\u3002", "method": "\u9996\u5148\u5ba1\u8ba1\u72ec\u7acbVLMs\u5728\u4fdd\u91ca\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u7136\u540e\u8bbe\u8ba1\u5e72\u9884\u7b97\u6cd5\uff1a\u901a\u8fc7RAG\u7ba1\u9053\u5f15\u5165\u6cd5\u5f8b\u5148\u4f8b\uff0c\u5e76\u4f7f\u7528\u521b\u65b0\u65b9\u6848\u5fae\u8c03VLMs\u3002", "result": "\u53d1\u73b0\u6a21\u578b\u5728\u591a\u4e2a\u4ea4\u53c9\u7fa4\u4f53\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u4f1a\u9ad8\u7f6e\u4fe1\u5ea6\u9519\u8bef\u62d2\u7edd\u5e94\u83b7\u4fdd\u91ca\u8005\uff1b\u5e72\u9884\u63aa\u65bd\u663e\u8457\u63d0\u9ad8\u4e86\u4fdd\u91ca\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u672a\u6765\u5728VLMs\u90e8\u7f72\u5230\u771f\u5b9e\u4e16\u754c\u6cd5\u5f8b\u5224\u51b3\u9884\u6d4b\u4e4b\u524d\u8bbe\u8ba1\u66f4\u667a\u80fd\u7684\u5e72\u9884\u63aa\u65bd\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2510.00490", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.00490", "abs": "https://arxiv.org/abs/2510.00490", "authors": ["Yu Yan", "Siqi Lu", "Yang Gao", "Zhaoxuan Li", "Ziming Zhao", "Qingjun Yuan", "Yongjuan Wang"], "title": "Has the Two-Decade-Old Prophecy Come True? Artificial Bad Intelligence Triggered by Merely a Single-Bit Flip in Large Language Models", "comment": "19 pages", "summary": "Recently, Bit-Flip Attack (BFA) has garnered widespread attention for its\nability to compromise software system integrity remotely through hardware fault\ninjection. With the widespread distillation and deployment of large language\nmodels (LLMs) into single file .gguf formats, their weight spaces have become\nexposed to an unprecedented hardware attack surface. This paper is the first to\nsystematically discover and validate the existence of single-bit\nvulnerabilities in LLM weight files: in mainstream open-source models (e.g.,\nDeepSeek and QWEN) using .gguf quantized formats, flipping just single bit can\ninduce three types of targeted semantic level failures Artificial Flawed\nIntelligence (outputting factual errors), Artificial Weak Intelligence\n(degradation of logical reasoning capability), and Artificial Bad Intelligence\n(generating harmful content).\n  By building an information theoretic weight sensitivity entropy model and a\nprobabilistic heuristic scanning framework called BitSifter, we achieved\nefficient localization of critical vulnerable bits in models with hundreds of\nmillions of parameters. Experiments show that vulnerabilities are significantly\nconcentrated in the tensor data region, particularly in areas related to the\nattention mechanism and output layers, which are the most sensitive. A negative\ncorrelation was observed between model size and robustness, with smaller models\nbeing more susceptible to attacks. Furthermore, a remote BFA chain was\ndesigned, enabling semantic-level attacks in real-world environments: At an\nattack frequency of 464.3 times per second, a single bit can be flipped with\n100% success in as little as 31.7 seconds. This causes the accuracy of LLM to\nplummet from 73.5% to 0%, without requiring high-cost equipment or complex\nprompt engineering.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u53d1\u73b0\u5e76\u9a8c\u8bc1\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6743\u91cd\u6587\u4ef6\u4e2d\u5b58\u5728\u5355\u6bd4\u7279\u6f0f\u6d1e\uff0c\u901a\u8fc7\u6784\u5efa\u4fe1\u606f\u8bba\u6743\u91cd\u654f\u611f\u5ea6\u71b5\u6a21\u578b\u548c\u6982\u7387\u542f\u53d1\u5f0f\u626b\u63cf\u6846\u67b6BitSifter\uff0c\u80fd\u591f\u9ad8\u6548\u5b9a\u4f4d\u5173\u952e\u6613\u53d7\u653b\u51fb\u6bd4\u7279\uff0c\u5e76\u8bbe\u8ba1\u4e86\u8fdc\u7a0b\u6bd4\u7279\u7ffb\u8f6c\u653b\u51fb\u94fe\uff0c\u53ef\u5728\u73b0\u5b9e\u73af\u5883\u4e2d\u5b9e\u73b0\u8bed\u4e49\u7ea7\u653b\u51fb\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee5.gguf\u91cf\u5316\u683c\u5f0f\u5e7f\u6cdb\u90e8\u7f72\uff0c\u5176\u6743\u91cd\u7a7a\u95f4\u9762\u4e34\u524d\u6240\u672a\u6709\u7684\u786c\u4ef6\u653b\u51fb\u9762\u3002\u6bd4\u7279\u7ffb\u8f6c\u653b\u51fb\u80fd\u591f\u901a\u8fc7\u786c\u4ef6\u6545\u969c\u6ce8\u5165\u8fdc\u7a0b\u7834\u574f\u8f6f\u4ef6\u7cfb\u7edf\u5b8c\u6574\u6027\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76LLM\u6743\u91cd\u6587\u4ef6\u4e2d\u7684\u5355\u6bd4\u7279\u6f0f\u6d1e\u3002", "method": "\u6784\u5efa\u4fe1\u606f\u8bba\u6743\u91cd\u654f\u611f\u5ea6\u71b5\u6a21\u578b\u548c\u6982\u7387\u542f\u53d1\u5f0f\u626b\u63cf\u6846\u67b6BitSifter\uff0c\u7528\u4e8e\u9ad8\u6548\u5b9a\u4f4d\u5173\u952e\u6613\u53d7\u653b\u51fb\u6bd4\u7279\uff1b\u8bbe\u8ba1\u8fdc\u7a0b\u6bd4\u7279\u7ffb\u8f6c\u653b\u51fb\u94fe\uff0c\u5728\u73b0\u5b9e\u73af\u5883\u4e2d\u5b9e\u73b0\u8bed\u4e49\u7ea7\u653b\u51fb\u3002", "result": "\u5728\u4e3b\u6d41\u5f00\u6e90\u6a21\u578b\u7684.gguf\u91cf\u5316\u683c\u5f0f\u4e2d\uff0c\u7ffb\u8f6c\u5355\u4e2a\u6bd4\u7279\u53ef\u8bf1\u5bfc\u4e09\u79cd\u76ee\u6807\u8bed\u4e49\u7ea7\u6545\u969c\uff1a\u4eba\u5de5\u7f3a\u9677\u667a\u80fd\uff08\u8f93\u51fa\u4e8b\u5b9e\u9519\u8bef\uff09\u3001\u4eba\u5de5\u5f31\u667a\u80fd\uff08\u903b\u8f91\u63a8\u7406\u80fd\u529b\u9000\u5316\uff09\u548c\u4eba\u5de5\u4e0d\u826f\u667a\u80fd\uff08\u751f\u6210\u6709\u5bb3\u5185\u5bb9\uff09\u3002\u653b\u51fb\u9891\u7387\u8fbe464.3\u6b21/\u79d2\u65f6\uff0c31.7\u79d2\u5185\u53ef100%\u6210\u529f\u7ffb\u8f6c\u5355\u4e2a\u6bd4\u7279\uff0c\u4f7fLLM\u51c6\u786e\u7387\u4ece73.5%\u964d\u81f30%\u3002", "conclusion": "LLM\u6743\u91cd\u6587\u4ef6\u5b58\u5728\u4e25\u91cd\u7684\u5355\u6bd4\u7279\u6f0f\u6d1e\uff0c\u6a21\u578b\u5927\u5c0f\u4e0e\u9c81\u68d2\u6027\u5448\u8d1f\u76f8\u5173\uff0c\u8f83\u5c0f\u6a21\u578b\u66f4\u6613\u53d7\u653b\u51fb\u3002\u8fd9\u79cd\u653b\u51fb\u4e0d\u9700\u8981\u9ad8\u6210\u672c\u8bbe\u5907\u6216\u590d\u6742\u63d0\u793a\u5de5\u7a0b\uff0c\u5bf9LLM\u7684\u5b89\u5168\u6027\u6784\u6210\u4e25\u91cd\u5a01\u80c1\u3002"}}
{"id": "2510.00324", "categories": ["cs.SE", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00324", "abs": "https://arxiv.org/abs/2510.00324", "authors": ["Lucas Roberts", "Denisa Roberts"], "title": "Which Programming Language and Model Work Best With LLM-as-a-Judge For Code Retrieval?", "comment": "Accepted as a full paper at SIGIR-AP 2025", "summary": "Code search is an important information retrieval application. Benefits of\nbetter code search include faster new developer on-boarding, reduced software\nmaintenance, and ease of understanding for large repositories. Despite\nimprovements in search algorithms and search benchmarks, the domain of code\nsearch has lagged behind. One reason is the high cost of human annotation for\ncode queries and answers. While humans may annotate search results in general\ntext QA systems, code annotations require specialized knowledge of a\nprogramming language (PL), as well as domain specific software engineering\nknowledge. In this work we study the use of Large Language Models (LLMs) to\nretrieve code at the level of functions and to generate annotations for code\nsearch results. We compare the impact of the retriever representation (sparse\nvs. semantic), programming language, and LLM by comparing human annotations\nacross several popular languages (C, Java, Javascript, Go, and Python). We\nfocus on repositories that implement common data structures likely to be\nimplemented in any PLs. For the same human annotations, we compare several\nLLM-as-a-Judge models to evaluate programming language and other affinities\nbetween LLMs. We find that the chosen retriever and PL exhibit affinities that\ncan be leveraged to improve alignment of human and AI relevance determinations,\nwith significant performance implications. We also find differences in\nrepresentation (sparse vs. semantic) across PLs that impact alignment of human\nand AI relevance determinations. We propose using transpilers to bootstrap\nscalable code search benchmark datasets in other PLs and in a case study\ndemonstrate that human-AI relevance agreement rates largely match the (worst\ncase) human-human agreement under study. The application code used in this work\nis available at \\href{https://github.com/rlucas7/code-searcher/}{this github\nrepo}.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4ee3\u7801\u641c\u7d22\uff0c\u6bd4\u8f83\u4e0d\u540c\u68c0\u7d22\u8868\u793a\u65b9\u6cd5\u3001\u7f16\u7a0b\u8bed\u8a00\u548cLLM\u5bf9\u4eba\u7c7b\u6807\u6ce8\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u68c0\u7d22\u5668\u548c\u7f16\u7a0b\u8bed\u8a00\u4e4b\u95f4\u5b58\u5728\u4eb2\u548c\u6027\uff0c\u5e76\u63d0\u51fa\u4f7f\u7528\u8f6c\u8bd1\u5668\u6269\u5c55\u4ee3\u7801\u641c\u7d22\u57fa\u51c6\u6570\u636e\u96c6\u7684\u65b9\u6cd5\u3002", "motivation": "\u4ee3\u7801\u641c\u7d22\u662f\u91cd\u8981\u7684\u4fe1\u606f\u68c0\u7d22\u5e94\u7528\uff0c\u4f46\u7531\u4e8e\u9700\u8981\u7f16\u7a0b\u8bed\u8a00\u4e13\u4e1a\u77e5\u8bc6\u548c\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u77e5\u8bc6\uff0c\u4eba\u5de5\u6807\u6ce8\u6210\u672c\u9ad8\u6602\uff0c\u5bfc\u81f4\u8be5\u9886\u57df\u53d1\u5c55\u6ede\u540e\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u68c0\u7d22\u51fd\u6570\u7ea7\u4ee3\u7801\u5e76\u751f\u6210\u6807\u6ce8\uff0c\u6bd4\u8f83\u7a00\u758f\u8868\u793a\u4e0e\u8bed\u4e49\u8868\u793a\u3001\u4e0d\u540c\u7f16\u7a0b\u8bed\u8a00\uff08C\u3001Java\u3001Javascript\u3001Go\u3001Python\uff09\u4ee5\u53ca\u4e0d\u540cLLM\u7684\u5f71\u54cd\uff0c\u5e76\u5229\u7528\u8f6c\u8bd1\u5668\u6269\u5c55\u57fa\u51c6\u6570\u636e\u96c6\u3002", "result": "\u53d1\u73b0\u9009\u62e9\u7684\u68c0\u7d22\u5668\u548c\u7f16\u7a0b\u8bed\u8a00\u5b58\u5728\u4eb2\u548c\u6027\uff0c\u53ef\u4ee5\u6539\u5584\u4eba\u7c7b\u4e0eAI\u76f8\u5173\u6027\u5224\u65ad\u7684\u4e00\u81f4\u6027\uff1b\u4e0d\u540c\u7f16\u7a0b\u8bed\u8a00\u5728\u8868\u793a\u65b9\u6cd5\uff08\u7a00\u758fvs\u8bed\u4e49\uff09\u4e0a\u5b58\u5728\u5dee\u5f02\uff0c\u5f71\u54cd\u4eba\u7c7b\u4e0eAI\u76f8\u5173\u6027\u5224\u65ad\u7684\u4e00\u81f4\u6027\u3002", "conclusion": "\u901a\u8fc7\u8f6c\u8bd1\u5668\u53ef\u4ee5\u6269\u5c55\u4ee3\u7801\u641c\u7d22\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5728\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u4eba\u7c7b-AI\u76f8\u5173\u6027\u4e00\u81f4\u6027\u7387\u57fa\u672c\u5339\u914d\u7814\u7a76\u4e2d\u7684\uff08\u6700\u5dee\u60c5\u51b5\uff09\u4eba\u7c7b-\u4eba\u7c7b\u4e00\u81f4\u6027\u3002"}}
{"id": "2510.00156", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00156", "abs": "https://arxiv.org/abs/2510.00156", "authors": ["Songran Bai", "Bingzhe Wu", "Yiwei Zhang", "Chengke Wu", "Xiaolong Zheng", "Yaze Yuan", "Ke Wu", "Jianqiang Li"], "title": "AuditAgent: Expert-Guided Multi-Agent Reasoning for Cross-Document Fraudulent Evidence Discovery", "comment": null, "summary": "Financial fraud detection in real-world scenarios presents significant\nchallenges due to the subtlety and dispersion of evidence across complex,\nmulti-year financial disclosures. In this work, we introduce a novel\nmulti-agent reasoning framework AuditAgent, enhanced with auditing domain\nexpertise, for fine-grained evidence chain localization in financial fraud\ncases. Leveraging an expert-annotated dataset constructed from enforcement\ndocuments and financial reports released by the China Securities Regulatory\nCommission, our approach integrates subject-level risk priors, a hybrid\nretrieval strategy, and specialized agent modules to efficiently identify and\naggregate cross-report evidence. Extensive experiments demonstrate that our\nmethod substantially outperforms General-Purpose Agent paradigm in both recall\nand interpretability, establishing a new benchmark for automated, transparent\nfinancial forensics. Our results highlight the value of domain-specific\nreasoning and dataset construction for advancing robust financial fraud\ndetection in practical, real-world regulatory applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aAuditAgent\u7684\u591a\u667a\u80fd\u4f53\u63a8\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u91d1\u878d\u6b3a\u8bc8\u68c0\u6d4b\u4e2d\u7684\u7ec6\u7c92\u5ea6\u8bc1\u636e\u94fe\u5b9a\u4f4d\uff0c\u8be5\u6846\u67b6\u6574\u5408\u4e86\u5ba1\u8ba1\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\uff0c\u5728\u771f\u5b9e\u91d1\u878d\u6b3a\u8bc8\u6848\u4f8b\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u91d1\u878d\u6b3a\u8bc8\u68c0\u6d4b\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u56e0\u4e3a\u8bc1\u636e\u5f80\u5f80\u5fae\u5999\u4e14\u5206\u6563\u5728\u590d\u6742\u591a\u5e74\u7684\u8d22\u52a1\u62ab\u9732\u4e2d\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u81ea\u52a8\u5316\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u63a8\u7406\u7684AuditAgent\u6846\u67b6\uff0c\u6574\u5408\u4e86\u4e3b\u4f53\u7ea7\u98ce\u9669\u5148\u9a8c\u3001\u6df7\u5408\u68c0\u7d22\u7b56\u7565\u548c\u4e13\u95e8\u5316\u667a\u80fd\u4f53\u6a21\u5757\uff0c\u5229\u7528\u4e2d\u56fd\u8bc1\u76d1\u4f1a\u53d1\u5e03\u7684\u6267\u6cd5\u6587\u4ef6\u548c\u8d22\u52a1\u62a5\u544a\u6784\u5efa\u4e13\u5bb6\u6807\u6ce8\u6570\u636e\u96c6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u53ec\u56de\u7387\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u901a\u7528\u667a\u80fd\u4f53\u8303\u5f0f\uff0c\u4e3a\u81ea\u52a8\u5316\u900f\u660e\u91d1\u878d\u53d6\u8bc1\u5efa\u7acb\u4e86\u65b0\u57fa\u51c6\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u9886\u57df\u7279\u5b9a\u63a8\u7406\u548c\u6570\u636e\u96c6\u6784\u5efa\u5bf9\u4e8e\u63a8\u8fdb\u5b9e\u9645\u76d1\u7ba1\u5e94\u7528\u4e2d\u7a33\u5065\u91d1\u878d\u6b3a\u8bc8\u68c0\u6d4b\u7684\u4ef7\u503c\u3002"}}
{"id": "2510.00529", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.00529", "abs": "https://arxiv.org/abs/2510.00529", "authors": ["Anbi Guo", "Mahfuza Farooque"], "title": "Memory-Augmented Log Analysis with Phi-4-mini: Enhancing Threat Detection in Structured Security Logs", "comment": null, "summary": "Structured security logs are critical for detecting advanced persistent\nthreats (APTs). Large language models (LLMs) struggle in this domain due to\nlimited context and domain mismatch. We propose \\textbf{DM-RAG}, a dual-memory\nretrieval-augmented generation framework for structured log analysis. It\nintegrates a short-term memory buffer for recent summaries and a long-term\nFAISS-indexed memory for historical patterns. An instruction-tuned Phi-4-mini\nprocesses the combined context and outputs structured predictions. Bayesian\nfusion promotes reliable persistence into memory. On the UNSW-NB15 dataset,\nDM-RAG achieves 53.64% accuracy and 98.70% recall, surpassing fine-tuned and\nRAG baselines in recall. The architecture is lightweight, interpretable, and\nscalable, enabling real-time threat monitoring without extra corpora or heavy\ntuning.", "AI": {"tldr": "\u63d0\u51fa\u4e86DM-RAG\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u8bb0\u5fc6\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\u5206\u6790\u7ed3\u6784\u5316\u5b89\u5168\u65e5\u5fd7\uff0c\u5728UNSW-NB15\u6570\u636e\u96c6\u4e0a\u8fbe\u523053.64%\u51c6\u786e\u7387\u548c98.70%\u53ec\u56de\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7ed3\u6784\u5316\u5b89\u5168\u65e5\u5fd7\u5206\u6790\u4e2d\u5b58\u5728\u4e0a\u4e0b\u6587\u9650\u5236\u548c\u9886\u57df\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u96be\u4ee5\u6709\u6548\u68c0\u6d4b\u9ad8\u7ea7\u6301\u7eed\u6027\u5a01\u80c1\u3002", "method": "\u91c7\u7528\u53cc\u8bb0\u5fc6RAG\u6846\u67b6\uff0c\u5305\u542b\u77ed\u671f\u8bb0\u5fc6\u7f13\u51b2\u533a\u7528\u4e8e\u8fd1\u671f\u6458\u8981\u548c\u957f\u671fFAISS\u7d22\u5f15\u8bb0\u5fc6\u7528\u4e8e\u5386\u53f2\u6a21\u5f0f\uff0c\u4f7f\u7528\u6307\u4ee4\u8c03\u4f18\u7684Phi-4-mini\u5904\u7406\u4e0a\u4e0b\u6587\uff0c\u8d1d\u53f6\u65af\u878d\u5408\u786e\u4fdd\u53ef\u9760\u8bb0\u5fc6\u6301\u4e45\u5316\u3002", "result": "\u5728UNSW-NB15\u6570\u636e\u96c6\u4e0a\uff0cDM-RAG\u5728\u53ec\u56de\u7387\u4e0a\u8d85\u8d8a\u4e86\u5fae\u8c03\u548cRAG\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8fbe\u523098.70%\u53ec\u56de\u7387\u548c53.64%\u51c6\u786e\u7387\u3002", "conclusion": "\u8be5\u67b6\u6784\u8f7b\u91cf\u7ea7\u3001\u53ef\u89e3\u91ca\u4e14\u53ef\u6269\u5c55\uff0c\u80fd\u591f\u5728\u65e0\u9700\u989d\u5916\u8bed\u6599\u5e93\u6216\u5927\u91cf\u8c03\u4f18\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u5b9e\u65f6\u5a01\u80c1\u76d1\u63a7\u3002"}}
{"id": "2510.00328", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.00328", "abs": "https://arxiv.org/abs/2510.00328", "authors": ["Ahmed Fawzy", "Amjed Tahir", "Kelly Blincoe"], "title": "Vibe Coding in Practice: Motivations, Challenges, and a Future Outlook -- a Grey Literature Review", "comment": null, "summary": "AI code generation tools are transforming software development, especially\nfor novice and non-software developers, by enabling them to write code and\nbuild applications faster and with little to no human intervention. Vibe coding\nis the practice where users rely on AI code generation tools through intuition\nand trial-and-error without necessarily understanding the underlying code.\nDespite widespread adoption, no research has systematically investigated why\nusers engage in vibe coding, what they experience while doing so, and how they\napproach quality assurance (QA) and perceive the quality of the AI-generated\ncode. To this end, we conduct a systematic grey literature review of 101\npractitioner sources, extracting 518 firsthand behavioral accounts about vibe\ncoding practices, challenges, and limitations. Our analysis reveals a\nspeed-quality trade-off paradox, where vibe coders are motivated by speed and\naccessibility, often experiencing rapid ``instant success and flow'', yet most\nperceive the resulting code as fast but flawed. QA practices are frequently\noverlooked, with many skipping testing, relying on the models' or tools'\noutputs without modification, or delegating checks back to the AI code\ngeneration tools. This creates a new class of vulnerable software developers,\nparticularly those who build a product but are unable to debug it when issues\narise. We argue that vibe coding lowers barriers and accelerates prototyping,\nbut at the cost of reliability and maintainability. These insights carry\nimplications for tool designers and software development teams. Understanding\nhow vibe coding is practiced today is crucial for guiding its responsible use\nand preventing a broader QA crisis in AI-assisted development.", "AI": {"tldr": "AI\u4ee3\u7801\u751f\u6210\u5de5\u5177\u901a\u8fc7\u76f4\u89c9\u548c\u8bd5\u9519\u7684\u65b9\u5f0f\u8ba9\u7528\u6237\u8fdb\u884c\"\u6c1b\u56f4\u7f16\u7a0b\"\uff0c\u867d\u7136\u52a0\u901f\u4e86\u5f00\u53d1\u8fc7\u7a0b\uff0c\u4f46\u5bfc\u81f4\u4e86\u901f\u5ea6\u4e0e\u8d28\u91cf\u7684\u6743\u8861\u6096\u8bba\uff0c\u4ea7\u751f\u4e86\u65e0\u6cd5\u8c03\u8bd5\u4ee3\u7801\u7684\u8106\u5f31\u5f00\u53d1\u8005\u7fa4\u4f53\u3002", "motivation": "\u5c3d\u7ba1AI\u4ee3\u7801\u751f\u6210\u5de5\u5177\u88ab\u5e7f\u6cdb\u91c7\u7528\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u7528\u6237\u4e3a\u4f55\u8fdb\u884c\u6c1b\u56f4\u7f16\u7a0b\u3001\u4f53\u9a8c\u5982\u4f55\u4ee5\u53ca\u5982\u4f55\u5904\u7406\u8d28\u91cf\u4fdd\u8bc1\u7684\u7cfb\u7edf\u6027\u7814\u7a76\u3002", "method": "\u5bf9101\u4e2a\u4ece\u4e1a\u8005\u8d44\u6599\u8fdb\u884c\u7cfb\u7edf\u6027\u7070\u8272\u6587\u732e\u7efc\u8ff0\uff0c\u63d0\u53d6\u4e86518\u4e2a\u5173\u4e8e\u6c1b\u56f4\u7f16\u7a0b\u5b9e\u8df5\u3001\u6311\u6218\u548c\u9650\u5236\u7684\u7b2c\u4e00\u624b\u884c\u4e3a\u63cf\u8ff0\u3002", "result": "\u5206\u6790\u63ed\u793a\u4e86\u901f\u5ea6-\u8d28\u91cf\u6743\u8861\u6096\u8bba\uff1a\u6c1b\u56f4\u7f16\u7a0b\u8005\u8ffd\u6c42\u901f\u5ea6\u548c\u53ef\u8bbf\u95ee\u6027\uff0c\u5e38\u4f53\u9a8c\u5230\"\u5373\u65f6\u6210\u529f\u548c\u6d41\u7545\u611f\"\uff0c\u4f46\u5927\u591a\u6570\u8ba4\u4e3a\u751f\u6210\u7684\u4ee3\u7801\u5feb\u901f\u4f46\u6709\u7f3a\u9677\u3002\u8d28\u91cf\u4fdd\u8bc1\u5b9e\u8df5\u5e38\u88ab\u5ffd\u89c6\uff0c\u8bb8\u591a\u7528\u6237\u8df3\u8fc7\u6d4b\u8bd5\u3001\u76f4\u63a5\u4f7f\u7528\u6a21\u578b\u8f93\u51fa\u6216\u59d4\u6258AI\u5de5\u5177\u68c0\u67e5\u3002", "conclusion": "\u6c1b\u56f4\u7f16\u7a0b\u964d\u4f4e\u4e86\u95e8\u69db\u5e76\u52a0\u901f\u4e86\u539f\u578b\u8bbe\u8ba1\uff0c\u4f46\u4ee5\u53ef\u9760\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u4e3a\u4ee3\u4ef7\uff0c\u4ea7\u751f\u4e86\u65e0\u6cd5\u8c03\u8bd5\u4ea7\u54c1\u7684\u8106\u5f31\u5f00\u53d1\u8005\u7fa4\u4f53\uff0c\u8fd9\u5bf9\u5de5\u5177\u8bbe\u8ba1\u8005\u548c\u5f00\u53d1\u56e2\u961f\u5177\u6709\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2510.00167", "categories": ["cs.AI", "cs.CR", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.00167", "abs": "https://arxiv.org/abs/2510.00167", "authors": ["Diego Ortiz Barbosa", "Mohit Agrawal", "Yash Malegaonkar", "Luis Burbano", "Axel Andersson", "Gy\u00f6rgy D\u00e1n", "Henrik Sandberg", "Alvaro A. Cardenas"], "title": "Drones that Think on their Feet: Sudden Landing Decisions with Embodied AI", "comment": null, "summary": "Autonomous drones must often respond to sudden events, such as alarms,\nfaults, or unexpected changes in their environment, that require immediate and\nadaptive decision-making. Traditional approaches rely on safety engineers\nhand-coding large sets of recovery rules, but this strategy cannot anticipate\nthe vast range of real-world contingencies and quickly becomes incomplete.\nRecent advances in embodied AI, powered by large visual language models,\nprovide commonsense reasoning to assess context and generate appropriate\nactions in real time. We demonstrate this capability in a simulated urban\nbenchmark in the Unreal Engine, where drones dynamically interpret their\nsurroundings and decide on sudden maneuvers for safe landings. Our results show\nthat embodied AI makes possible a new class of adaptive recovery and\ndecision-making pipelines that were previously infeasible to design by hand,\nadvancing resilience and safety in autonomous aerial systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u5177\u8eabAI\u548c\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u6765\u589e\u5f3a\u81ea\u4e3b\u65e0\u4eba\u673a\u5bf9\u7a81\u53d1\u4e8b\u4ef6\u7684\u54cd\u5e94\u80fd\u529b\uff0c\u66ff\u4ee3\u4f20\u7edf\u624b\u5199\u6062\u590d\u89c4\u5219\u7684\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u5b89\u5168\u5de5\u7a0b\u5e08\u624b\u52a8\u7f16\u5199\u5927\u91cf\u6062\u590d\u89c4\u5219\uff0c\u4f46\u65e0\u6cd5\u9884\u6d4b\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u5404\u79cd\u610f\u5916\u60c5\u51b5\uff0c\u4e14\u89c4\u5219\u96c6\u5f88\u5feb\u4f1a\u53d8\u5f97\u4e0d\u5b8c\u6574\u3002", "method": "\u4f7f\u7528\u5177\u8eabAI\u548c\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u5728Unreal Engine\u6a21\u62df\u7684\u57ce\u5e02\u573a\u666f\u4e2d\uff0c\u8ba9\u65e0\u4eba\u673a\u52a8\u6001\u89e3\u8bfb\u73af\u5883\u5e76\u5b9e\u65f6\u751f\u6210\u9002\u5f53\u7684\u7d27\u6025\u7740\u9646\u52a8\u4f5c\u3002", "result": "\u5177\u8eabAI\u4f7f\u5f97\u4ee5\u524d\u65e0\u6cd5\u624b\u52a8\u8bbe\u8ba1\u7684\u65b0\u578b\u81ea\u9002\u5e94\u6062\u590d\u548c\u51b3\u7b56\u6d41\u7a0b\u6210\u4e3a\u53ef\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u5347\u4e86\u81ea\u4e3b\u822a\u7a7a\u7cfb\u7edf\u7684\u5f39\u6027\u548c\u5b89\u5168\u6027\uff0c\u4e3a\u65e0\u4eba\u673a\u5e94\u6025\u54cd\u5e94\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.00554", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.00554", "abs": "https://arxiv.org/abs/2510.00554", "authors": ["Andrew Gan", "Zahra Ghodsi"], "title": "Sentry: Authenticating Machine Learning Artifacts on the Fly", "comment": null, "summary": "Machine learning systems increasingly rely on open-source artifacts such as\ndatasets and models that are created or hosted by other parties. The reliance\non external datasets and pre-trained models exposes the system to supply chain\nattacks where an artifact can be poisoned before it is delivered to the\nend-user. Such attacks are possible due to the lack of any authenticity\nverification in existing machine learning systems. Incorporating cryptographic\nsolutions such as hashing and signing can mitigate the risk of supply chain\nattacks. However, existing frameworks for integrity verification based on\ncryptographic techniques can incur significant overhead when applied to\nstate-of-the-art machine learning artifacts due to their scale, and are not\ncompatible with GPU platforms. In this paper, we develop Sentry, a novel\nGPU-based framework that verifies the authenticity of machine learning\nartifacts by implementing cryptographic signing and verification for datasets\nand models. Sentry ties developer identities to signatures and performs\nauthentication on the fly as artifacts are loaded on GPU memory, making it\ncompatible with GPU data movement solutions such as NVIDIA GPUDirect that\nbypass the CPU. Sentry incorporates GPU acceleration of cryptographic hash\nconstructions such as Merkle tree and lattice hashing, implementing memory\noptimizations and resource partitioning schemes for a high throughput\nperformance. Our evaluations show that Sentry is a practical solution to bring\nauthenticity to machine learning systems, achieving orders of magnitude speedup\nover a CPU-based baseline.", "AI": {"tldr": "Sentry\u662f\u4e00\u4e2a\u57fa\u4e8eGPU\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5b9e\u73b0\u6570\u636e\u96c6\u7684\u52a0\u5bc6\u7b7e\u540d\u548c\u9a8c\u8bc1\u6765\u786e\u4fdd\u673a\u5668\u5b66\u4e60\u5de5\u4ef6\u7684\u771f\u5b9e\u6027\uff0c\u9632\u6b62\u4f9b\u5e94\u94fe\u653b\u51fb\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u4f9d\u8d56\u5916\u90e8\u6570\u636e\u96c6\u548c\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u7f3a\u4e4f\u771f\u5b9e\u6027\u9a8c\u8bc1\uff0c\u5bb9\u6613\u53d7\u5230\u4f9b\u5e94\u94fe\u653b\u51fb\u3002\u73b0\u6709\u7684\u52a0\u5bc6\u9a8c\u8bc1\u65b9\u6848\u5728\u89c4\u6a21\u548cGPU\u517c\u5bb9\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u5f00\u53d1Sentry\u6846\u67b6\uff0c\u5c06\u5f00\u53d1\u8005\u8eab\u4efd\u4e0e\u7b7e\u540d\u7ed1\u5b9a\uff0c\u5728GPU\u5185\u5b58\u52a0\u8f7d\u5de5\u4ef6\u65f6\u8fdb\u884c\u5b9e\u65f6\u8ba4\u8bc1\uff0c\u91c7\u7528GPU\u52a0\u901f\u7684Merkle\u6811\u548c\u683c\u54c8\u5e0c\u7b49\u52a0\u5bc6\u54c8\u5e0c\u7ed3\u6784\uff0c\u5b9e\u73b0\u5185\u5b58\u4f18\u5316\u548c\u8d44\u6e90\u5206\u533a\u3002", "result": "\u8bc4\u4f30\u663e\u793aSentry\u662f\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u76f8\u6bd4\u57fa\u4e8eCPU\u7684\u57fa\u7ebf\u5b9e\u73b0\u4e86\u6570\u91cf\u7ea7\u7684\u52a0\u901f\u3002", "conclusion": "Sentry\u4e3a\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u5e26\u6765\u4e86\u771f\u5b9e\u6027\u4fdd\u969c\uff0c\u901a\u8fc7GPU\u52a0\u901f\u7684\u52a0\u5bc6\u9a8c\u8bc1\u6709\u6548\u7f13\u89e3\u4e86\u4f9b\u5e94\u94fe\u653b\u51fb\u98ce\u9669\u3002"}}
{"id": "2510.00450", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.00450", "abs": "https://arxiv.org/abs/2510.00450", "authors": ["Sheikh Md. Mushfiqur Rahman", "Nasir Eisty"], "title": "Beyond Pass/Fail: The Story of Learning-Based Testing", "comment": null, "summary": "Learning-Based Testing (LBT) merges learning and testing processes to achieve\nboth testing and behavioral adequacy. LBT utilizes active learning to infer the\nmodel of the System Under Test (SUT), enabling scalability for large and\ncomplex programs by requiring only a minimal set of initial test cases. The\ncore principle of LBT is that the SUT's behavior can be thoroughly inferred by\nprogressively generating test cases and subjecting the SUT to testing, thereby\nensuring comprehensive testing. Despite being in its early stages, LBT has a\nsolid foundation of theoretical research demonstrating its efficacy in testing\nboth procedural and reactive programs. This paper provides a systematic\nliterature review of various LBT implementations across different program types\nand evaluates the current state of research in this field. We explore diverse\ntheoretical frameworks, existing tools, and libraries within the LBT domain to\nillustrate the concept's evolution and current research status. Additionally,\nwe examine case studies involving the application of LBT tools in industrial\nsettings, highlighting their potential and effectiveness in commercial software\ntesting. This systematic literature review aims to offer researchers a\ncomprehensive perspective on the inception and development of LBT, presenting\nit as a promising technique in software testing. By unveiling LBT's\nunderutilized potential, this paper seeks to significantly benefit the\npractitioners and research community.", "AI": {"tldr": "\u57fa\u4e8e\u5b66\u4e60\u7684\u6d4b\u8bd5\uff08LBT\uff09\u901a\u8fc7\u7ed3\u5408\u5b66\u4e60\u548c\u6d4b\u8bd5\u8fc7\u7a0b\uff0c\u5229\u7528\u4e3b\u52a8\u5b66\u4e60\u63a8\u65ad\u88ab\u6d4b\u7cfb\u7edf\u6a21\u578b\uff0c\u4ec5\u9700\u5c11\u91cf\u521d\u59cb\u6d4b\u8bd5\u7528\u4f8b\u5373\u53ef\u5b9e\u73b0\u5927\u89c4\u6a21\u590d\u6742\u7a0b\u5e8f\u7684\u6d4b\u8bd5\uff0c\u786e\u4fdd\u884c\u4e3a\u5145\u5206\u6027\u3002", "motivation": "\u4f20\u7edf\u6d4b\u8bd5\u65b9\u6cd5\u5728\u5904\u7406\u5927\u89c4\u6a21\u590d\u6742\u7a0b\u5e8f\u65f6\u9762\u4e34\u6311\u6218\uff0cLBT\u65e8\u5728\u901a\u8fc7\u4e3b\u52a8\u5b66\u4e60\u6280\u672f\u63d0\u9ad8\u6d4b\u8bd5\u6548\u7387\u548c\u8986\u76d6\u7387\uff0c\u51cf\u5c11\u5bf9\u5927\u91cf\u521d\u59cb\u6d4b\u8bd5\u7528\u4f8b\u7684\u4f9d\u8d56\u3002", "method": "\u91c7\u7528\u4e3b\u52a8\u5b66\u4e60\u6280\u672f\u9010\u6b65\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\uff0c\u901a\u8fc7\u6d4b\u8bd5\u8fc7\u7a0b\u63a8\u65ad\u88ab\u6d4b\u7cfb\u7edf\u7684\u884c\u4e3a\u6a21\u578b\uff0c\u7ed3\u5408\u7406\u8bba\u6846\u67b6\u3001\u5de5\u5177\u5e93\u548c\u6848\u4f8b\u7814\u7a76\u8fdb\u884c\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u3002", "result": "LBT\u5728\u8fc7\u7a0b\u548c\u53cd\u5e94\u5f0f\u7a0b\u5e8f\u6d4b\u8bd5\u4e2d\u663e\u793a\u51fa\u6709\u6548\u6027\uff0c\u5de5\u4e1a\u6848\u4f8b\u7814\u7a76\u8bc1\u660e\u4e86\u5176\u5728\u5546\u4e1a\u8f6f\u4ef6\u6d4b\u8bd5\u4e2d\u7684\u6f5c\u529b\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "LBT\u4f5c\u4e3a\u4e00\u79cd\u6709\u524d\u666f\u7684\u8f6f\u4ef6\u6d4b\u8bd5\u6280\u672f\uff0c\u5177\u6709\u672a\u5145\u5206\u5229\u7528\u7684\u6f5c\u529b\uff0c\u80fd\u4e3a\u5b9e\u8df5\u8005\u548c\u7814\u7a76\u793e\u533a\u5e26\u6765\u663e\u8457\u76ca\u5904\uff0c\u503c\u5f97\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u5e94\u7528\u3002"}}
{"id": "2510.00185", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00185", "abs": "https://arxiv.org/abs/2510.00185", "authors": ["Gabriel de Olim Gaul", "Adam Gould", "Avinash Kori", "Francesca Toni"], "title": "Object-Centric Case-Based Reasoning via Argumentation", "comment": "Accepted to ArgXAI@ECAI25", "summary": "We introduce Slot Attention Argumentation for Case-Based Reasoning (SAA-CBR),\na novel neuro-symbolic pipeline for image classification that integrates\nobject-centric learning via a neural Slot Attention (SA) component with\nsymbolic reasoning conducted by Abstract Argumentation for Case-Based Reasoning\n(AA-CBR). We explore novel integrations of AA-CBR with the neural component,\nincluding feature combination strategies, casebase reduction via representative\nsamples, novel count-based partial orders, a One-Vs-Rest strategy for extending\nAA-CBR to multi-class classification, and an application of Supported AA-CBR, a\nbipolar variant of AA-CBR. We demonstrate that SAA-CBR is an effective\nclassifier on the CLEVR-Hans datasets, showing competitive performance against\nbaseline models.", "AI": {"tldr": "SAA-CBR\u662f\u4e00\u79cd\u65b0\u7684\u795e\u7ecf\u7b26\u53f7\u56fe\u50cf\u5206\u7c7b\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u795e\u7ecfSlot Attention\u7ec4\u4ef6\u548c\u7b26\u53f7\u63a8\u7406\u7684AA-CBR\u65b9\u6cd5\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u96c6\u6210\u795e\u7ecf\u5b66\u4e60\u548c\u7b26\u53f7\u63a8\u7406\u7684\u56fe\u50cf\u5206\u7c7b\u7cfb\u7edf\uff0c\u5229\u7528\u5bf9\u8c61\u4e2d\u5fc3\u5b66\u4e60\u548c\u62bd\u8c61\u8bba\u8bc1\u8fdb\u884c\u6848\u4f8b\u63a8\u7406\u3002", "method": "\u4f7f\u7528Slot Attention\u8fdb\u884c\u5bf9\u8c61\u4e2d\u5fc3\u5b66\u4e60\uff0c\u901a\u8fc7AA-CBR\u8fdb\u884c\u7b26\u53f7\u63a8\u7406\uff0c\u5305\u62ec\u7279\u5f81\u7ec4\u5408\u7b56\u7565\u3001\u6848\u4f8b\u5e93\u7f29\u51cf\u3001\u57fa\u4e8e\u8ba1\u6570\u7684\u504f\u5e8f\u3001One-Vs-Rest\u591a\u7c7b\u5206\u7c7b\u7b56\u7565\u4ee5\u53ca\u652f\u6301\u6027AA-CBR\u53d8\u4f53\u3002", "result": "\u5728CLEVR-Hans\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4e0e\u57fa\u7ebf\u6a21\u578b\u76f8\u6bd4\u5177\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "SAA-CBR\u662f\u4e00\u4e2a\u6709\u6548\u7684\u5206\u7c7b\u5668\uff0c\u6210\u529f\u6574\u5408\u4e86\u795e\u7ecf\u548c\u7b26\u53f7\u7ec4\u4ef6\uff0c\u5728\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\u5c55\u73b0\u4e86\u826f\u597d\u6027\u80fd\u3002"}}
{"id": "2510.00572", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00572", "abs": "https://arxiv.org/abs/2510.00572", "authors": ["Ahsan Farabi", "Muhaiminul Rashid Shad", "Israt Khandaker"], "title": "IntrusionX: A Hybrid Convolutional-LSTM Deep Learning Framework with Squirrel Search Optimization for Network Intrusion Detection", "comment": null, "summary": "Intrusion Detection Systems (IDS) face persistent challenges due to evolving\ncyberattacks, high-dimensional traffic data, and severe class imbalance in\nbenchmark datasets such as NSL-KDD. To address these issues, we propose\nIntrusionX, a hybrid deep learning framework that integrates Convolutional\nNeural Networks (CNNs) for local feature extraction and Long Short-Term Memory\n(LSTM) networks for temporal modeling. The architecture is further optimized\nusing the Squirrel Search Algorithm (SSA), enabling effective hyperparameter\ntuning while maintaining computational efficiency. Our pipeline incorporates\nrigorous preprocessing, stratified data splitting, and dynamic class weighting\nto enhance the detection of rare classes. Experimental evaluation on NSL-KDD\ndemonstrates that IntrusionX achieves 98% accuracy in binary classification and\n87% in 5-class classification, with significant improvements in minority class\nrecall (U2R: 71%, R2L: 93%). The novelty of IntrusionX lies in its\nreproducible, imbalance-aware design with metaheuristic optimization.", "AI": {"tldr": "IntrusionX\u662f\u4e00\u79cd\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408CNN\u548cLSTM\u7f51\u7edc\uff0c\u4f7f\u7528\u677e\u9f20\u641c\u7d22\u7b97\u6cd5\u4f18\u5316\u8d85\u53c2\u6570\uff0c\u5728NSL-KDD\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u7684\u5165\u4fb5\u68c0\u6d4b\u3002", "motivation": "\u89e3\u51b3\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u9762\u4e34\u7684\u6311\u6218\uff1a\u4e0d\u65ad\u6f14\u53d8\u7684\u7f51\u7edc\u653b\u51fb\u3001\u9ad8\u7ef4\u6d41\u91cf\u6570\u636e\u4ee5\u53caNSL-KDD\u7b49\u57fa\u51c6\u6570\u636e\u96c6\u4e2d\u7684\u4e25\u91cd\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "method": "\u63d0\u51faIntrusionX\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff1aCNN\u7528\u4e8e\u5c40\u90e8\u7279\u5f81\u63d0\u53d6\uff0cLSTM\u7528\u4e8e\u65f6\u95f4\u5efa\u6a21\uff0c\u4f7f\u7528\u677e\u9f20\u641c\u7d22\u7b97\u6cd5\u8fdb\u884c\u8d85\u53c2\u6570\u4f18\u5316\uff0c\u5e76\u91c7\u7528\u4e25\u683c\u9884\u5904\u7406\u3001\u5206\u5c42\u6570\u636e\u5206\u5272\u548c\u52a8\u6001\u7c7b\u522b\u52a0\u6743\u3002", "result": "\u5728NSL-KDD\u6570\u636e\u96c6\u4e0a\uff0c\u4e8c\u5143\u5206\u7c7b\u51c6\u786e\u7387\u8fbe\u523098%\uff0c5\u7c7b\u5206\u7c7b\u51c6\u786e\u7387\u8fbe\u523087%\uff0c\u5c11\u6570\u7c7b\u53ec\u56de\u7387\u663e\u8457\u63d0\u5347\uff08U2R\uff1a71%\uff0cR2L\uff1a93%\uff09\u3002", "conclusion": "IntrusionX\u7684\u521b\u65b0\u5728\u4e8e\u5176\u53ef\u590d\u73b0\u7684\u3001\u4e0d\u5e73\u8861\u611f\u77e5\u8bbe\u8ba1\u7ed3\u5408\u5143\u542f\u53d1\u5f0f\u4f18\u5316\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5165\u4fb5\u68c0\u6d4b\u6027\u80fd\u3002"}}
{"id": "2510.00476", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00476", "abs": "https://arxiv.org/abs/2510.00476", "authors": ["Arushi Sharma", "Vedant Pungliya", "Christopher J. Quinn", "Ali Jannesari"], "title": "Analyzing Latent Concepts in Code Language Models", "comment": null, "summary": "Interpreting the internal behavior of large language models trained on code\nremains a critical challenge, particularly for applications demanding trust,\ntransparency, and semantic robustness. We propose Code Concept Analysis\n(CoCoA): a global post-hoc interpretability framework that uncovers emergent\nlexical, syntactic, and semantic structures in a code language model's\nrepresentation space by clustering contextualized token embeddings into\nhuman-interpretable concept groups. We propose a hybrid annotation pipeline\nthat combines static analysis tool-based syntactic alignment with\nprompt-engineered large language models (LLMs), enabling scalable labeling of\nlatent concepts across abstraction levels. We analyse the distribution of\nconcepts across layers and across three finetuning tasks. Emergent concept\nclusters can help identify unexpected latent interactions and be used to\nidentify trends and biases within the model's learned representations. We\nfurther integrate LCA with local attribution methods to produce\nconcept-grounded explanations, improving the coherence and interpretability of\ntoken-level saliency. Empirical evaluations across multiple models and tasks\nshow that LCA discovers concepts that remain stable under semantic-preserving\nperturbations (average Cluster Sensitivity Index, CSI = 0.288) and evolve\npredictably with fine-tuning. In a user study, concept-augmented explanations\ndisambiguate token roles. In a user study on the programming-language\nclassification task, concept-augmented explanations disambiguated token roles\nand improved human-centric explainability by 37 percentage points compared with\ntoken-level attributions using Integrated Gradients.", "AI": {"tldr": "\u63d0\u51fa\u4e86Code Concept Analysis (CoCoA)\u6846\u67b6\uff0c\u901a\u8fc7\u805a\u7c7b\u4e0a\u4e0b\u6587\u6807\u8bb0\u5d4c\u5165\u6765\u63ed\u793a\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u8bcd\u6c47\u3001\u53e5\u6cd5\u548c\u8bed\u4e49\u7ed3\u6784\uff0c\u5e76\u6574\u5408\u5c40\u90e8\u5f52\u56e0\u65b9\u6cd5\u751f\u6210\u6982\u5ff5\u57fa\u7840\u7684\u89e3\u91ca\u3002", "motivation": "\u89e3\u91ca\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u7684\u5185\u90e8\u884c\u4e3a\u5bf9\u4e8e\u9700\u8981\u4fe1\u4efb\u3001\u900f\u660e\u5ea6\u548c\u8bed\u4e49\u9c81\u68d2\u6027\u7684\u5e94\u7528\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u4ecd\u662f\u4e00\u4e2a\u6311\u6218\u3002", "method": "\u63d0\u51faCoCoA\u5168\u5c40\u540e\u9a8c\u53ef\u89e3\u91ca\u6027\u6846\u67b6\uff0c\u4f7f\u7528\u6df7\u5408\u6807\u6ce8\u6d41\u7a0b\u7ed3\u5408\u9759\u6001\u5206\u6790\u5de5\u5177\u548c\u63d0\u793a\u5de5\u7a0bLLM\uff0c\u5c06\u4e0a\u4e0b\u6587\u6807\u8bb0\u5d4c\u5165\u805a\u7c7b\u4e3a\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u6982\u5ff5\u7ec4\u3002", "result": "CoCoA\u53d1\u73b0\u7684\u6982\u5ff5\u5728\u8bed\u4e49\u4fdd\u7559\u6270\u52a8\u4e0b\u4fdd\u6301\u7a33\u5b9a(CSI=0.288)\uff0c\u5e76\u968f\u5fae\u8c03\u53ef\u9884\u6d4b\u5730\u6f14\u5316\u3002\u5728\u7528\u6237\u7814\u7a76\u4e2d\uff0c\u6982\u5ff5\u589e\u5f3a\u89e3\u91ca\u5728\u7f16\u7a0b\u8bed\u8a00\u5206\u7c7b\u4efb\u52a1\u4e2d\u6bd4\u57fa\u4e8e\u6807\u8bb0\u5f52\u56e0\u7684\u65b9\u6cd5\u63d0\u9ad8\u4e8637\u4e2a\u767e\u5206\u70b9\u7684\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "CoCoA\u6846\u67b6\u80fd\u591f\u6709\u6548\u63ed\u793a\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6f5c\u5728\u7ed3\u6784\uff0c\u63d0\u4f9b\u66f4\u8fde\u8d2f\u548c\u53ef\u89e3\u91ca\u7684\u6982\u5ff5\u57fa\u7840\u89e3\u91ca\uff0c\u63d0\u9ad8\u4eba\u7c7b\u4e2d\u5fc3\u7684\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2510.00186", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00186", "abs": "https://arxiv.org/abs/2510.00186", "authors": ["Anni Li", "Aria Attar", "Paul Dong"], "title": "Thinkquel: A Model Dedicated to Text-to-dbt Using Synthetic Data and a Span-Aware Objective", "comment": null, "summary": "Transforming natural-language requests into reliable, production-ready data\ntransformations remains challenging: correctness depends on precise schema\nlinking and warehouse-specific SQL dialects, while the strongest supervision\navailable during training--execution success and result matching--are provided\nonly at the sequence level. At the same time, assembling large,\nexecution-validated corpora is costly, and token-level objectives misalign with\nthese global signals, yielding unstable optimization and limited portability.\nWe introduce Thinkquel, a fine-tuned model for producing robust, portable, and\nexecution-validated database queries. Methodologies in Thinkquel integrates a\nnovel synthetic data pipeline, TS-SQL, that leverages dbt as a portable\nintermediate representation with a span-aware reinforcement learning objective,\nand Token-Sequence GRPO (TS-GRPO), specifically designed to bridge the gap\nbetween token-level training signals and sequence-level execution rewards when\nfinetuning LLMs. On the 500-example TS-SQL test set, Thinkquel (32B) reaches\n93.2\\% execution success and 61.8\\% exact-result match with a two-stage SFT\ncurriculum, improving over the base model by 67.2\\% (exec.) and 44.4\\% (match).\nIn Spider (14B) experiments, TS-GRPO increases training stability and speeds\nconvergence of the execution-match reward relative to GRPO and GSPO.", "AI": {"tldr": "Thinkquel\u662f\u4e00\u4e2a\u7ecf\u8fc7\u5fae\u8c03\u7684\u6a21\u578b\uff0c\u7528\u4e8e\u751f\u6210\u53ef\u9760\u3001\u53ef\u79fb\u690d\u4e14\u7ecf\u8fc7\u6267\u884c\u9a8c\u8bc1\u7684\u6570\u636e\u5e93\u67e5\u8be2\u3002\u5b83\u96c6\u6210\u4e86\u65b0\u9896\u7684\u5408\u6210\u6570\u636e\u7ba1\u9053TS-SQL\u548c\u4e13\u95e8\u8bbe\u8ba1\u7684Token-Sequence GRPO\u5f3a\u5316\u5b66\u4e60\u76ee\u6807\uff0c\u4ee5\u5f25\u5408\u4ee4\u724c\u7ea7\u8bad\u7ec3\u4fe1\u53f7\u548c\u5e8f\u5217\u7ea7\u6267\u884c\u5956\u52b1\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "motivation": "\u5c06\u81ea\u7136\u8bed\u8a00\u8bf7\u6c42\u8f6c\u6362\u4e3a\u53ef\u9760\u3001\u751f\u4ea7\u5c31\u7eea\u7684\u6570\u636e\u8f6c\u6362\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff1a\u6b63\u786e\u6027\u4f9d\u8d56\u4e8e\u7cbe\u786e\u7684\u6a21\u5f0f\u94fe\u63a5\u548c\u4ed3\u5e93\u7279\u5b9a\u7684SQL\u65b9\u8a00\uff0c\u800c\u8bad\u7ec3\u671f\u95f4\u6700\u5f3a\u7684\u76d1\u7763\u2014\u2014\u6267\u884c\u6210\u529f\u548c\u7ed3\u679c\u5339\u914d\u2014\u2014\u4ec5\u5728\u5e8f\u5217\u7ea7\u522b\u63d0\u4f9b\u3002\u540c\u65f6\uff0c\u7ec4\u88c5\u5927\u578b\u3001\u7ecf\u8fc7\u6267\u884c\u9a8c\u8bc1\u7684\u8bed\u6599\u5e93\u6210\u672c\u9ad8\u6602\uff0c\u4ee4\u724c\u7ea7\u76ee\u6807\u4e0e\u8fd9\u4e9b\u5168\u5c40\u4fe1\u53f7\u4e0d\u5339\u914d\uff0c\u5bfc\u81f4\u4f18\u5316\u4e0d\u7a33\u5b9a\u548c\u53ef\u79fb\u690d\u6027\u6709\u9650\u3002", "method": "Thinkquel\u96c6\u6210\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5408\u6210\u6570\u636e\u7ba1\u9053TS-SQL\uff0c\u5229\u7528dbt\u4f5c\u4e3a\u53ef\u79fb\u690d\u7684\u4e2d\u95f4\u8868\u793a\uff0c\u5e76\u7ed3\u5408\u4e86\u8de8\u5ea6\u611f\u77e5\u7684\u5f3a\u5316\u5b66\u4e60\u76ee\u6807Token-Sequence GRPO\uff08TS-GRPO\uff09\uff0c\u4e13\u95e8\u8bbe\u8ba1\u7528\u4e8e\u5728\u5fae\u8c03LLMs\u65f6\u5f25\u5408\u4ee4\u724c\u7ea7\u8bad\u7ec3\u4fe1\u53f7\u548c\u5e8f\u5217\u7ea7\u6267\u884c\u5956\u52b1\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "result": "\u5728500\u4e2a\u793a\u4f8b\u7684TS-SQL\u6d4b\u8bd5\u96c6\u4e0a\uff0cThinkquel\uff0832B\uff09\u901a\u8fc7\u4e24\u9636\u6bb5SFT\u8bfe\u7a0b\u8fbe\u5230\u4e8693.2%\u7684\u6267\u884c\u6210\u529f\u7387\u548c61.8%\u7684\u7cbe\u786e\u7ed3\u679c\u5339\u914d\u7387\uff0c\u76f8\u5bf9\u4e8e\u57fa\u7840\u6a21\u578b\u5206\u522b\u63d0\u9ad8\u4e8667.2%\uff08\u6267\u884c\uff09\u548c44.4%\uff08\u5339\u914d\uff09\u3002\u5728Spider\uff0814B\uff09\u5b9e\u9a8c\u4e2d\uff0cTS-GRPO\u76f8\u5bf9\u4e8eGRPO\u548cGSPO\u63d0\u9ad8\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027\u5e76\u52a0\u901f\u4e86\u6267\u884c\u5339\u914d\u5956\u52b1\u7684\u6536\u655b\u3002", "conclusion": "Thinkquel\u901a\u8fc7\u96c6\u6210TS-SQL\u5408\u6210\u6570\u636e\u7ba1\u9053\u548cTS-GRPO\u5f3a\u5316\u5b66\u4e60\u76ee\u6807\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u81ea\u7136\u8bed\u8a00\u5230SQL\u8f6c\u6362\u4e2d\u7684\u6311\u6218\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6267\u884c\u6210\u529f\u7387\u548c\u7ed3\u679c\u5339\u914d\u7387\uff0c\u540c\u65f6\u6539\u5584\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6536\u655b\u901f\u5ea6\u3002"}}
{"id": "2510.00763", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.00763", "abs": "https://arxiv.org/abs/2510.00763", "authors": ["Maximilian Reif", "Jens Zumbr\u00e4gel"], "title": "A Monoid Ring Approach to Color Visual Cryptography", "comment": "5 pages, 3 figures", "summary": "A visual cryptography scheme is a secret sharing scheme in which the secret\ninformation is an image and the shares are printed on transparencies, so that\nthe secret image can be recovered by simply stacking the shares on top of each\nother. Such schemes do therefore not require any knowledge of cryptography\ntools to recover the secret, and they have widespread applications, for\nexample, when sharing QR codes or medical images. In this work we deal with\nvisual cryptography threshold schemes for color images. Our color model differs\nfrom most previous work by allowing arbitrary colors to be stacked, resulting\nin a possibly different color. This more general color monoid model enables us\nto achieve shorter pixel expansion and higher contrast than comparable schemes.\nWe revisit the polynomial framework of Koga and Ishihara for constructing\nvisual cryptography schemes and apply the monoid ring to obtain new schemes for\ncolor visual cryptography.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f69\u8272\u89c6\u89c9\u5bc6\u7801\u65b9\u6848\uff0c\u4f7f\u7528\u66f4\u901a\u7528\u7684\u989c\u8272\u5e7a\u534a\u7fa4\u6a21\u578b\uff0c\u901a\u8fc7\u591a\u9879\u5f0f\u6846\u67b6\u548c\u5e7a\u534a\u7fa4\u73af\u6784\u5efa\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86\u66f4\u5c0f\u7684\u50cf\u7d20\u6269\u5c55\u548c\u66f4\u9ad8\u7684\u5bf9\u6bd4\u5ea6\u3002", "motivation": "\u4f20\u7edf\u89c6\u89c9\u5bc6\u7801\u65b9\u6848\u5728\u5f69\u8272\u56fe\u50cf\u5904\u7406\u4e0a\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u901a\u7528\u7684\u989c\u8272\u6a21\u578b\u6765\u652f\u6301\u4efb\u610f\u989c\u8272\u53e0\u52a0\uff0c\u4ece\u800c\u83b7\u5f97\u66f4\u597d\u7684\u6027\u80fd\u8868\u73b0\u3002", "method": "\u91c7\u7528\u989c\u8272\u5e7a\u534a\u7fa4\u6a21\u578b\uff0c\u91cd\u65b0\u5ba1\u89c6Koga\u548cIshihara\u7684\u591a\u9879\u5f0f\u6846\u67b6\uff0c\u5e94\u7528\u5e7a\u534a\u7fa4\u73af\u7406\u8bba\u6784\u5efa\u65b0\u7684\u5f69\u8272\u89c6\u89c9\u5bc6\u7801\u65b9\u6848\u3002", "result": "\u65b0\u65b9\u6848\u76f8\u6bd4\u540c\u7c7b\u65b9\u6848\u5b9e\u73b0\u4e86\u66f4\u77ed\u7684\u50cf\u7d20\u6269\u5c55\u548c\u66f4\u9ad8\u7684\u5bf9\u6bd4\u5ea6\uff0c\u63d0\u5347\u4e86\u5f69\u8272\u89c6\u89c9\u5bc6\u7801\u7684\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u5e7a\u534a\u7fa4\u73af\u65b9\u6cd5\u6784\u5efa\u7684\u5f69\u8272\u89c6\u89c9\u5bc6\u7801\u65b9\u6848\u5728\u50cf\u7d20\u6269\u5c55\u548c\u5bf9\u6bd4\u5ea6\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u4e3a\u5f69\u8272\u56fe\u50cf\u7684\u5b89\u5168\u5171\u4eab\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.00501", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.00501", "abs": "https://arxiv.org/abs/2510.00501", "authors": ["Kaixin Wang", "Tianlin Li", "Xiaoyu Zhang", "Aishan Liu", "Xianglong Liu", "Ziqi Liu", "Zhiqiang Zhang", "Jun Zhou", "and Bin Shi"], "title": "CodeChemist: Functional Knowledge Transfer for Low-Resource Code Generation via Test-Time Scaling", "comment": null, "summary": "Code Large Language Models (CodeLLMs) are increasingly used in code\ngeneration tasks across a wide range of applications. However, their\nperformance is often inconsistent across different programming languages (PLs),\nwith low-resource PLs suffering the most due to limited training data. In this\npaper, we present CodeChemist, a novel and efficient framework for test-time\nscaling that enables functional knowledge transfer from high-resource to\nlow-resource PLs using generated test cases. CodeChemist first generates and\nexecutes code in high-resource PLs to create test cases that encapsulate\nfunctional knowledge. It then uses multi-temperature hedged sampling to\ngenerate code snippets in the low-resource PL and selects the best one based on\nthe pass rate of the test cases. Our extensive experiments show that\nCodeChemist outperforms existing test-time scaling approaches, boosting the\nperformance of code generation for low-resource PLs without requiring any model\nretraining.", "AI": {"tldr": "CodeChemist\u662f\u4e00\u4e2a\u9ad8\u6548\u7684\u6d4b\u8bd5\u65f6\u6269\u5c55\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u5b9e\u73b0\u4ece\u9ad8\u8d44\u6e90\u7f16\u7a0b\u8bed\u8a00\u5230\u4f4e\u8d44\u6e90\u7f16\u7a0b\u8bed\u8a00\u7684\u529f\u80fd\u77e5\u8bc6\u8fc1\u79fb\uff0c\u65e0\u9700\u6a21\u578b\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u63d0\u5347\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u4ee3\u7801\u751f\u6210\u6027\u80fd\u3002", "motivation": "\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u7f16\u7a0b\u8bed\u8a00\u4e0a\u7684\u6027\u80fd\u4e0d\u4e00\u81f4\uff0c\u4f4e\u8d44\u6e90\u7f16\u7a0b\u8bed\u8a00\u7531\u4e8e\u8bad\u7ec3\u6570\u636e\u6709\u9650\u8868\u73b0\u8f83\u5dee\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u79cd\u6027\u80fd\u5dee\u5f02\u95ee\u9898\u3002", "method": "\u9996\u5148\u751f\u6210\u5e76\u6267\u884c\u9ad8\u8d44\u6e90\u8bed\u8a00\u7684\u4ee3\u7801\u6765\u521b\u5efa\u5305\u542b\u529f\u80fd\u77e5\u8bc6\u7684\u6d4b\u8bd5\u7528\u4f8b\uff0c\u7136\u540e\u4f7f\u7528\u591a\u6e29\u5ea6\u5bf9\u51b2\u91c7\u6837\u751f\u6210\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u4ee3\u7801\u7247\u6bb5\uff0c\u6839\u636e\u6d4b\u8bd5\u7528\u4f8b\u901a\u8fc7\u7387\u9009\u62e9\u6700\u4f73\u4ee3\u7801\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCodeChemist\u4f18\u4e8e\u73b0\u6709\u7684\u6d4b\u8bd5\u65f6\u6269\u5c55\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4f4e\u8d44\u6e90\u7f16\u7a0b\u8bed\u8a00\u7684\u4ee3\u7801\u751f\u6210\u6027\u80fd\u3002", "conclusion": "CodeChemist\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u901a\u8fc7\u529f\u80fd\u77e5\u8bc6\u8fc1\u79fb\u89e3\u51b3\u4e86\u4f4e\u8d44\u6e90\u7f16\u7a0b\u8bed\u8a00\u4ee3\u7801\u751f\u6210\u6027\u80fd\u4e0d\u8db3\u7684\u95ee\u9898\u3002"}}
{"id": "2510.00229", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00229", "abs": "https://arxiv.org/abs/2510.00229", "authors": ["Rohan Kadekodi", "Zhan Jin", "Keisuke Kamahori", "Yile Gu", "Sean Khatiri", "Noah H. Bayindirli", "Sergey Gorbunov", "Baris Kasikci"], "title": "DualTune: Decoupled Fine-Tuning for On-Device Agentic Systems", "comment": null, "summary": "The deployment of Large Language Models (LLMs) as agentic orchestrators has\nrevolutionized task automation, but the need for privacy-preserving,\ncost-effective solutions demands on-device inference capabilities. However,\nlocal LLMs consistently underperform compared to frontier models in tool\ncalling scenarios, struggling with both tool selection from large tool sets and\naccurate argument generation for complex parameter structures. We introduce a\nmethodology that disaggregates a tool-calling task into two distinct subtasks:\ntool selection and argument generation. We propose \"decoupled fine-tuning\", a\nnovel post-training approach that employs LoRA fine-tuning to create dedicated\nLoRA adapters for tool selection and tool-specific argument generation using\nseparate loss masking for each of the subtasks. Furthermore, we present\nDualTune, an inference framework that leverages the LoRA adapters created using\ndecoupled fine-tuning to perform efficient agent orchestration with the help of\nlocal models on end-user devices. DualTune decomposes the tool-call generation\nstep into tool selection and argument generation, and dynamically loads the\ncorresponding LoRA adapters to generate tool calls. Additionally, DualTune\nimplements hierarchical orchestration to restrict the number of tools required\nfor tool selection. Our experiments on the MCP-Bench benchmark demonstrate that\nthe Qwen-2.5-7B model trained using decoupled fine-tuning improves the tool\ncalling accuracy of the base model by 46%, and outperforms other local\nreasoning, non-reasoning and fine-tuned models of similar size in all cases,\nand models that are 2x larger, in most cases.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u8026\u5fae\u8c03\u65b9\u6cd5\uff0c\u5c06\u5de5\u5177\u8c03\u7528\u4efb\u52a1\u5206\u89e3\u4e3a\u5de5\u5177\u9009\u62e9\u548c\u53c2\u6570\u751f\u6210\u4e24\u4e2a\u5b50\u4efb\u52a1\uff0c\u901a\u8fc7\u4e13\u7528LoRA\u9002\u914d\u5668\u548c\u5206\u5c42\u7f16\u6392\u63d0\u5347\u672c\u5730LLM\u7684\u5de5\u5177\u8c03\u7528\u6027\u80fd\u3002", "motivation": "\u672c\u5730LLM\u5728\u5de5\u5177\u8c03\u7528\u573a\u666f\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u65e0\u6cd5\u4e0e\u524d\u6cbf\u6a21\u578b\u7ade\u4e89\uff0c\u7279\u522b\u662f\u5728\u5927\u578b\u5de5\u5177\u96c6\u9009\u62e9\u548c\u590d\u6742\u53c2\u6570\u751f\u6210\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u9700\u8981\u9690\u79c1\u4fdd\u62a4\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u672c\u5730\u63a8\u7406\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u89e3\u8026\u5fae\u8c03\u65b9\u6cd5\uff0c\u4f7f\u7528LoRA\u5fae\u8c03\u521b\u5efa\u4e13\u7528\u9002\u914d\u5668\uff0c\u5206\u522b\u5904\u7406\u5de5\u5177\u9009\u62e9\u548c\u5de5\u5177\u7279\u5b9a\u53c2\u6570\u751f\u6210\uff0c\u901a\u8fc7\u5206\u79bb\u635f\u5931\u63a9\u7801\u4f18\u5316\u6bcf\u4e2a\u5b50\u4efb\u52a1\u3002DualTune\u63a8\u7406\u6846\u67b6\u52a8\u6001\u52a0\u8f7d\u76f8\u5e94LoRA\u9002\u914d\u5668\uff0c\u5e76\u5b9e\u65bd\u5206\u5c42\u7f16\u6392\u9650\u5236\u5de5\u5177\u9009\u62e9\u6570\u91cf\u3002", "result": "\u5728MCP-Bench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528\u89e3\u8026\u5fae\u8c03\u7684Qwen-2.5-7B\u6a21\u578b\u5c06\u57fa\u7840\u6a21\u578b\u7684\u5de5\u5177\u8c03\u7528\u51c6\u786e\u7387\u63d0\u9ad8\u4e8646%\uff0c\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u4f18\u4e8e\u76f8\u4f3c\u89c4\u6a21\u7684\u5176\u4ed6\u6a21\u578b\uff0c\u751a\u81f3\u4f18\u4e8e2\u500d\u5927\u5c0f\u7684\u6a21\u578b\u3002", "conclusion": "\u89e3\u8026\u5fae\u8c03\u548cDualTune\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u672c\u5730LLM\u7684\u5de5\u5177\u8c03\u7528\u80fd\u529b\uff0c\u4e3a\u8bbe\u5907\u7aef\u63a8\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u9690\u79c1\u548c\u6210\u672c\u6548\u76ca\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2510.00799", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00799", "abs": "https://arxiv.org/abs/2510.00799", "authors": ["Gautier Evennou", "Vivien Chappelier", "Ewa Kijak"], "title": "Fast, Secure, and High-Capacity Image Watermarking with Autoencoded Text Vectors", "comment": "Preprint", "summary": "Most image watermarking systems focus on robustness, capacity, and\nimperceptibility while treating the embedded payload as meaningless bits. This\nbit-centric view imposes a hard ceiling on capacity and prevents watermarks\nfrom carrying useful information. We propose LatentSeal, which reframes\nwatermarking as semantic communication: a lightweight text autoencoder maps\nfull-sentence messages into a compact 256-dimensional unit-norm latent vector,\nwhich is robustly embedded by a finetuned watermark model and secured through a\nsecret, invertible rotation. The resulting system hides full-sentence messages,\ndecodes in real time, and survives valuemetric and geometric attacks. It\nsurpasses prior state of the art in BLEU-4 and Exact Match on several\nbenchmarks, while breaking through the long-standing 256-bit payload ceiling.\nIt also introduces a statistically calibrated score that yields a ROC AUC score\nof 0.97-0.99, and practical operating points for deployment. By shifting from\nbit payloads to semantic latent vectors, LatentSeal enables watermarking that\nis not only robust and high-capacity, but also secure and interpretable,\nproviding a concrete path toward provenance, tamper explanation, and\ntrustworthy AI governance. Models, training and inference code, and data splits\nwill be available upon publication.", "AI": {"tldr": "LatentSeal\u5c06\u56fe\u50cf\u6c34\u5370\u91cd\u65b0\u5b9a\u4e49\u4e3a\u8bed\u4e49\u901a\u4fe1\uff0c\u901a\u8fc7\u6587\u672c\u81ea\u7f16\u7801\u5668\u5c06\u5b8c\u6574\u53e5\u5b50\u6620\u5c04\u4e3a\u7d27\u51d1\u7684256\u7ef4\u6f5c\u5411\u91cf\uff0c\u7a81\u7834\u4e86\u4f20\u7edf256\u4f4d\u6709\u6548\u8f7d\u8377\u7684\u9650\u5236\uff0c\u5b9e\u73b0\u4e86\u9ad8\u5bb9\u91cf\u3001\u9c81\u68d2\u4e14\u53ef\u89e3\u91ca\u7684\u6c34\u5370\u7cfb\u7edf\u3002", "motivation": "\u4f20\u7edf\u56fe\u50cf\u6c34\u5370\u7cfb\u7edf\u5c06\u5d4c\u5165\u7684\u6709\u6548\u8f7d\u8377\u89c6\u4e3a\u65e0\u610f\u4e49\u7684\u6bd4\u7279\uff0c\u8fd9\u79cd\u6bd4\u7279\u4e2d\u5fc3\u89c6\u56fe\u9650\u5236\u4e86\u5bb9\u91cf\uff0c\u5e76\u963b\u6b62\u6c34\u5370\u643a\u5e26\u6709\u7528\u4fe1\u606f\u3002", "method": "\u4f7f\u7528\u8f7b\u91cf\u7ea7\u6587\u672c\u81ea\u7f16\u7801\u5668\u5c06\u5b8c\u6574\u53e5\u5b50\u6620\u5c04\u5230\u7d27\u51d1\u7684256\u7ef4\u5355\u4f4d\u8303\u6570\u6f5c\u5411\u91cf\uff0c\u901a\u8fc7\u5fae\u8c03\u7684\u6c34\u5370\u6a21\u578b\u8fdb\u884c\u9c81\u68d2\u5d4c\u5165\uff0c\u5e76\u901a\u8fc7\u79d8\u5bc6\u53ef\u9006\u65cb\u8f6c\u8fdb\u884c\u4fdd\u62a4\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u4e86\u73b0\u6709\u6280\u672f\u6c34\u5e73\uff0cBLEU-4\u548c\u7cbe\u786e\u5339\u914d\u8868\u73b0\u4f18\u5f02\uff0c\u540c\u65f6\u5b9e\u73b0\u4e860.97-0.99\u7684ROC AUC\u5206\u6570\uff0c\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u90e8\u7f72\u64cd\u4f5c\u70b9\u3002", "conclusion": "\u901a\u8fc7\u4ece\u6bd4\u7279\u6709\u6548\u8f7d\u8377\u8f6c\u5411\u8bed\u4e49\u6f5c\u5411\u91cf\uff0cLatentSeal\u5b9e\u73b0\u4e86\u4e0d\u4ec5\u9c81\u68d2\u548c\u9ad8\u5bb9\u91cf\uff0c\u800c\u4e14\u5b89\u5168\u53ef\u89e3\u91ca\u7684\u6c34\u5370\uff0c\u4e3a\u6765\u6e90\u8ffd\u8e2a\u3001\u7be1\u6539\u89e3\u91ca\u548c\u53ef\u4fe1AI\u6cbb\u7406\u63d0\u4f9b\u4e86\u5177\u4f53\u8def\u5f84\u3002"}}
{"id": "2510.00519", "categories": ["cs.SE", "cs.AI", "D.2.4; D.2.11"], "pdf": "https://arxiv.org/pdf/2510.00519", "abs": "https://arxiv.org/abs/2510.00519", "authors": ["Hadiza Umar Yusuf", "Khouloud Gaaloul"], "title": "Architectural Transformations and Emerging Verification Demands in AI-Enabled Cyber-Physical Systems", "comment": null, "summary": "In the world of Cyber-Physical Systems (CPS), a captivating real-time fusion\noccurs where digital technology meets the physical world. This synergy has been\nsignificantly transformed by the integration of artificial intelligence (AI), a\nmove that dramatically enhances system adaptability and introduces a layer of\ncomplexity that impacts CPS control optimization and reliability. Despite\nadvancements in AI integration, a significant gap remains in understanding how\nthis shift affects CPS architecture, operational complexity, and verification\npractices. The extended abstract addresses this gap by investigating\narchitectural distinctions between AI-driven and traditional control models\ndesigned in Simulink and their respective implications for system verification.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86AI\u9a71\u52a8\u7684CPS\u4e0e\u4f20\u7edf\u63a7\u5236\u6a21\u578b\u5728\u67b6\u6784\u548c\u9a8c\u8bc1\u5b9e\u8df5\u4e0a\u7684\u5dee\u5f02", "motivation": "\u7406\u89e3AI\u96c6\u6210\u5bf9CPS\u67b6\u6784\u3001\u64cd\u4f5c\u590d\u6742\u6027\u548c\u9a8c\u8bc1\u5b9e\u8df5\u7684\u5f71\u54cd\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u7a7a\u767d", "method": "\u901a\u8fc7\u8c03\u67e5Simulink\u4e2d\u8bbe\u8ba1\u7684AI\u9a71\u52a8\u4e0e\u4f20\u7edf\u63a7\u5236\u6a21\u578b\u7684\u67b6\u6784\u533a\u522b", "result": "\u63ed\u793a\u4e86\u4e24\u79cd\u6a21\u578b\u5728\u7cfb\u7edf\u9a8c\u8bc1\u65b9\u9762\u7684\u4e0d\u540c\u5f71\u54cd", "conclusion": "AI\u96c6\u6210\u663e\u8457\u6539\u53d8\u4e86CPS\u67b6\u6784\u548c\u9a8c\u8bc1\u9700\u6c42\uff0c\u9700\u8981\u65b0\u7684\u9a8c\u8bc1\u65b9\u6cd5"}}
{"id": "2510.00274", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.00274", "abs": "https://arxiv.org/abs/2510.00274", "authors": ["Maisha Maliha", "Dean Hougen"], "title": "MAGIC-MASK: Multi-Agent Guided Inter-Agent Collaboration with Mask-Based Explainability for Reinforcement Learning", "comment": "16 pages, 3 figures", "summary": "Understanding the decision-making process of Deep Reinforcement Learning\nagents remains a key challenge for deploying these systems in safety-critical\nand multi-agent environments. While prior explainability methods like\nStateMask, have advanced the identification of critical states, they remain\nlimited by computational cost, exploration coverage, and lack of adaptation to\nmulti-agent settings. To overcome these limitations, we propose a\nmathematically grounded framework, MAGIC-MASK (Multi-Agent Guided Inter-agent\nCollaboration with Mask-Based Explainability for Reinforcement Learning), that\nextends perturbation-based explanation to Multi-Agent Reinforcement Learning.\nOur method integrates Proximal Policy Optimization, adaptive epsilon-greedy\nexploration, and lightweight inter-agent collaboration to share masked state\ninformation and peer experience. This collaboration enables each agent to\nperform saliency-guided masking and share reward-based insights with peers,\nreducing the time required for critical state discovery, improving explanation\nfidelity, and leading to faster and more robust learning. The core novelty of\nour approach lies in generalizing explainability from single-agent to\nmulti-agent systems through a unified mathematical formalism built on\ntrajectory perturbation, reward fidelity analysis, and Kullback-Leibler\ndivergence regularization. This framework yields localized, interpretable\nexplanations grounded in probabilistic modeling and multi-agent Markov decision\nprocesses. We validate our framework on both single-agent and multi-agent\nbenchmarks, including a multi-agent highway driving environment and Google\nResearch Football, demonstrating that MAGIC-MASK consistently outperforms\nstate-of-the-art baselines in fidelity, learning efficiency, and policy\nrobustness while offering interpretable and transferable explanations.", "AI": {"tldr": "\u63d0\u51fa\u4e86MAGIC-MASK\u6846\u67b6\uff0c\u5c06\u57fa\u4e8e\u6270\u52a8\u7684\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u6269\u5c55\u5230\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff0c\u901a\u8fc7\u667a\u80fd\u4f53\u95f4\u534f\u4f5c\u5171\u4eab\u63a9\u7801\u72b6\u6001\u4fe1\u606f\u548c\u7ecf\u9a8c\uff0c\u63d0\u9ad8\u5173\u952e\u72b6\u6001\u53d1\u73b0\u6548\u7387\u548c\u89e3\u91ca\u4fdd\u771f\u5ea6\u3002", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u5728\u5b89\u5168\u5173\u952e\u548c\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684\u51b3\u7b56\u8fc7\u7a0b\u7406\u89e3\u95ee\u9898\uff0c\u514b\u670d\u73b0\u6709\u65b9\u6cd5\u5728\u8ba1\u7b97\u6210\u672c\u3001\u63a2\u7d22\u8986\u76d6\u548c\u591a\u667a\u80fd\u4f53\u9002\u5e94\u6027\u65b9\u9762\u7684\u9650\u5236\u3002", "method": "\u96c6\u6210\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u3001\u81ea\u9002\u5e94epsilon-greedy\u63a2\u7d22\u548c\u8f7b\u91cf\u7ea7\u667a\u80fd\u4f53\u95f4\u534f\u4f5c\uff0c\u901a\u8fc7\u8f68\u8ff9\u6270\u52a8\u3001\u5956\u52b1\u4fdd\u771f\u5ea6\u5206\u6790\u548cKL\u6563\u5ea6\u6b63\u5219\u5316\u7684\u7edf\u4e00\u6570\u5b66\u5f62\u5f0f\u5316\u6846\u67b6\u3002", "result": "\u5728\u5355\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5305\u62ec\u591a\u667a\u80fd\u4f53\u9ad8\u901f\u516c\u8def\u9a7e\u9a76\u73af\u5883\u548cGoogle Research Football\uff0cMAGIC-MASK\u5728\u4fdd\u771f\u5ea6\u3001\u5b66\u4e60\u6548\u7387\u548c\u7b56\u7565\u9c81\u68d2\u6027\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u6982\u7387\u5efa\u6a21\u548c\u591a\u667a\u80fd\u4f53\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5c40\u90e8\u5316\u3001\u53ef\u89e3\u91ca\u7684\u89e3\u91ca\uff0c\u5b9e\u73b0\u4e86\u4ece\u5355\u667a\u80fd\u4f53\u5230\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\u6cdb\u5316\u3002"}}
{"id": "2510.01097", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.01097", "abs": "https://arxiv.org/abs/2510.01097", "authors": ["Zhixin Dong", "Xian Xu", "Yuhang Zeng", "Mingchao Wan", "Chunmiao Li"], "title": "Universally Composable Termination Analysis of Tendermint", "comment": "35 pages including references, 16 figures, 2 tables. Submitted to\n  ACNS 2026", "summary": "Modern blockchain systems operating in adversarial environments require\nrobust consensus protocols that guarantee both safety and termination under\nnetwork delay attacks. Tendermint, a widely adopted consensus protocol in\nconsortium blockchains, achieves high throughput and finality. However,\nprevious analysis of the safety and termination has been done in a standalone\nfashion, with no consideration of the composition with other protocols\ninteracting with it in a concurrent manner. Moreover, the termination\nproperties under adaptive network delays caused by Byzantine adversaries have\nnot been formally analyzed. This paper presents the first universally\ncomposable (UC) security analysis of Tendermint, demonstrating its resilience\nagainst strategic message-delay attacks. By constructing a UC ideal model of\nTendermint, we formalize its core mechanisms: phase-base consensus procedure,\ndynamic timeouts, proposal locking, leader rotation, and others, under a\nnetwork adversary that selectively delays protocol messages. Our main result\nproves that the Tendermint protocol UC-realizes the ideal Tendermint model,\nwhich ensures bounded termination latency, i.e., guaranteed termination, even\nwhen up to $f<n/3$ nodes are Byzantine (where $n$ is the number of nodes\nparticipating in the consensus), provided that network delays remain within a\nprotocol-defined threshold under the partially synchronous net assumption.\nSpecifically, through formal proofs within the UC framework, we show that\nTendermint maintains safety and termination. By the composition theorem of UC,\nthis guarantees that these properties are maintained when Tendermint is\ncomposed with various blockchain components.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5bf9Tendermint\u5171\u8bc6\u534f\u8bae\u8fdb\u884c\u4e86\u901a\u7528\u53ef\u7ec4\u5408(UC)\u5b89\u5168\u5206\u6790\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u6218\u7565\u6d88\u606f\u5ef6\u8fdf\u653b\u51fb\u4e0b\u7684\u5f39\u6027\uff0c\u786e\u4fdd\u5728\u90e8\u5206\u540c\u6b65\u7f51\u7edc\u5047\u8bbe\u4e0b\uff0c\u5373\u4f7f\u6709f<n/3\u7684\u62dc\u5360\u5ead\u8282\u70b9\uff0c\u534f\u8bae\u4ecd\u80fd\u4fdd\u6301\u5b89\u5168\u6027\u548c\u7ec8\u6b62\u6027\u3002", "motivation": "\u73b0\u6709\u5bf9Tendermint\u5b89\u5168\u6027\u548c\u7ec8\u6b62\u6027\u7684\u5206\u6790\u90fd\u662f\u5b64\u7acb\u8fdb\u884c\u7684\uff0c\u6ca1\u6709\u8003\u8651\u4e0e\u5176\u4ed6\u534f\u8bae\u7684\u5e76\u53d1\u7ec4\u5408\uff0c\u4e14\u5728\u62dc\u5360\u5ead\u5bf9\u624b\u5f15\u8d77\u7684\u81ea\u9002\u5e94\u7f51\u7edc\u5ef6\u8fdf\u4e0b\u7684\u7ec8\u6b62\u6027\u5c1a\u672a\u5f97\u5230\u6b63\u5f0f\u5206\u6790\u3002", "method": "\u901a\u8fc7\u6784\u5efaTendermint\u7684UC\u7406\u60f3\u6a21\u578b\uff0c\u5f62\u5f0f\u5316\u5176\u6838\u5fc3\u673a\u5236\uff08\u57fa\u4e8e\u9636\u6bb5\u7684\u5171\u8bc6\u8fc7\u7a0b\u3001\u52a8\u6001\u8d85\u65f6\u3001\u63d0\u6848\u9501\u5b9a\u3001\u9886\u5bfc\u8005\u8f6e\u6362\u7b49\uff09\uff0c\u5728\u7f51\u7edc\u5bf9\u624b\u9009\u62e9\u6027\u5ef6\u8fdf\u534f\u8bae\u6d88\u606f\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u5206\u6790\u3002", "result": "\u4e3b\u8981\u7ed3\u679c\u8bc1\u660eTendermint\u534f\u8baeUC\u5b9e\u73b0\u4e86\u7406\u60f3Tendermint\u6a21\u578b\uff0c\u786e\u4fdd\u6709\u754c\u7ec8\u6b62\u5ef6\u8fdf\uff0c\u5373\u5728\u7f51\u7edc\u5ef6\u8fdf\u4fdd\u6301\u5728\u534f\u8bae\u5b9a\u4e49\u9608\u503c\u5185\u65f6\uff0c\u5373\u4f7f\u6709f<n/3\u7684\u62dc\u5360\u5ead\u8282\u70b9\u4e5f\u80fd\u4fdd\u8bc1\u7ec8\u6b62\u3002", "conclusion": "\u901a\u8fc7UC\u6846\u67b6\u5185\u7684\u5f62\u5f0f\u5316\u8bc1\u660e\uff0cTendermint\u4fdd\u6301\u4e86\u5b89\u5168\u6027\u548c\u7ec8\u6b62\u6027\u3002\u6839\u636eUC\u7684\u7ec4\u5408\u5b9a\u7406\uff0c\u8fd9\u4fdd\u8bc1\u4e86\u5f53Tendermint\u4e0e\u5404\u79cd\u533a\u5757\u94fe\u7ec4\u4ef6\u7ec4\u5408\u65f6\uff0c\u8fd9\u4e9b\u5c5e\u6027\u4ecd\u80fd\u5f97\u5230\u4fdd\u6301\u3002"}}
{"id": "2510.00532", "categories": ["cs.SE", "cs.CR", "D.2.5"], "pdf": "https://arxiv.org/pdf/2510.00532", "abs": "https://arxiv.org/abs/2510.00532", "authors": ["Hengcheng Zhu", "Songqiang Chen", "Valerio Terragni", "Lili Wei", "Jiarong Wu", "Yepang Liu", "Shing-Chi Cheung"], "title": "LSPFuzz: Hunting Bugs in Language Servers", "comment": "This paper has been accepted for publication in The 40th IEEE/ACM\n  International Conference on Automated Software Engineering (ASE 2025)", "summary": "The Language Server Protocol (LSP) has revolutionized the integration of code\nintelligence in modern software development. There are approximately 300 LSP\nserver implementations for various languages and 50 editors offering LSP\nintegration. However, the reliability of LSP servers is a growing concern, as\ncrashes can disable all code intelligence features and significantly impact\nproductivity, while vulnerabilities can put developers at risk even when\nediting untrusted source code. Despite the widespread adoption of LSP, no\nexisting techniques specifically target LSP server testing. To bridge this gap,\nwe present LSPFuzz, a grey-box hybrid fuzzer for systematic LSP server testing.\nOur key insight is that effective LSP server testing requires holistic mutation\nof source code and editor operations, as bugs often manifest from their\ncombinations. To satisfy the sophisticated constraints of LSP and effectively\nexplore the input space, we employ a two-stage mutation pipeline: syntax-aware\nmutations to source code, followed by context-aware dispatching of editor\noperations. We evaluated LSPFuzz on four widely used LSP servers. LSPFuzz\ndemonstrated superior performance compared to baseline fuzzers, and uncovered\npreviously unknown bugs in real-world LSP servers. Of the 51 bugs we reported,\n42 have been confirmed, 26 have been fixed by developers, and two have been\nassigned CVE numbers. Our work advances the quality assurance of LSP servers,\nproviding both a practical tool and foundational insights for future research\nin this domain.", "AI": {"tldr": "LSPFuzz\u662f\u4e00\u4e2a\u9488\u5bf9\u8bed\u8a00\u670d\u52a1\u5668\u534f\u8bae(LSP)\u670d\u52a1\u5668\u7684\u7070\u76d2\u6df7\u5408\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u53d8\u5f02\u7b56\u7565\uff08\u8bed\u6cd5\u611f\u77e5\u7684\u6e90\u4ee3\u7801\u53d8\u5f02\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u7f16\u8f91\u5668\u64cd\u4f5c\u8c03\u5ea6\uff09\u6765\u53d1\u73b0LSP\u670d\u52a1\u5668\u4e2d\u7684bug\u3002", "motivation": "LSP\u670d\u52a1\u5668\u53ef\u9760\u6027\u95ee\u9898\u65e5\u76ca\u4e25\u91cd\uff0c\u5d29\u6e83\u4f1a\u7981\u7528\u6240\u6709\u4ee3\u7801\u667a\u80fd\u529f\u80fd\uff0c\u6f0f\u6d1e\u53ef\u80fd\u8ba9\u5f00\u53d1\u8005\u5728\u7f16\u8f91\u4e0d\u53d7\u4fe1\u4efb\u6e90\u4ee3\u7801\u65f6\u9762\u4e34\u98ce\u9669\u3002\u5c3d\u7ba1LSP\u5e7f\u6cdb\u91c7\u7528\uff0c\u4f46\u73b0\u6709\u6280\u672f\u6ca1\u6709\u4e13\u95e8\u9488\u5bf9LSP\u670d\u52a1\u5668\u6d4b\u8bd5\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u53d8\u5f02\u7ba1\u9053\uff1a\u9996\u5148\u5bf9\u6e90\u4ee3\u7801\u8fdb\u884c\u8bed\u6cd5\u611f\u77e5\u53d8\u5f02\uff0c\u7136\u540e\u6839\u636e\u4e0a\u4e0b\u6587\u8c03\u5ea6\u7f16\u8f91\u5668\u64cd\u4f5c\u3002\u8fd9\u79cd\u7070\u76d2\u6df7\u5408\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63a2\u7d22LSP\u7684\u590d\u6742\u7ea6\u675f\u548c\u8f93\u5165\u7a7a\u95f4\u3002", "result": "\u5728\u56db\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684LSP\u670d\u52a1\u5668\u4e0a\u8bc4\u4f30\uff0cLSPFuzz\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u6a21\u7cca\u5668\uff0c\u53d1\u73b0\u4e8651\u4e2a\u4e4b\u524d\u672a\u77e5\u7684bug\uff0c\u5176\u4e2d42\u4e2a\u88ab\u786e\u8ba4\uff0c26\u4e2a\u88ab\u4fee\u590d\uff0c2\u4e2a\u88ab\u5206\u914d\u4e86CVE\u7f16\u53f7\u3002", "conclusion": "LSPFuzz\u63a8\u8fdb\u4e86LSP\u670d\u52a1\u5668\u7684\u8d28\u91cf\u4fdd\u8bc1\uff0c\u4e3a\u8be5\u9886\u57df\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u548c\u57fa\u7840\u89c1\u89e3\u3002"}}
{"id": "2510.00300", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00300", "abs": "https://arxiv.org/abs/2510.00300", "authors": ["Serena Gomez Wannaz"], "title": "ICL Optimized Fragility", "comment": null, "summary": "ICL guides are known to improve task-specific performance, but their impact\non cross-domain cognitive abilities remains unexplored. This study examines how\nICL guides affect reasoning across different knowledge domains using six\nvariants of the GPT-OSS:20b model: one baseline model and five ICL\nconfigurations (simple, chain-of-thought, random, appended text, and symbolic\nlanguage). The models were subjected to 840 tests spanning general knowledge\nquestions, logic riddles, and a mathematical olympiad problem. Statistical\nanalysis (ANOVA) revealed significant behavioral modifications (p less than\n0.001) across ICL variants, demonstrating a phenomenon termed \"optimized\nfragility.\" ICL models achieved 91%-99% accuracy on general knowledge tasks\nwhile showing degraded performance on complex reasoning problems, with accuracy\ndropping to 10-43% on riddles compared to 43% for the baseline model. Notably,\nno significant differences emerged on the olympiad problem (p=0.2173),\nsuggesting that complex mathematical reasoning remains unaffected by ICL\noptimization. These findings indicate that ICL guides create systematic\ntrade-offs between efficiency and reasoning flexibility, with important\nimplications for LLM deployment and AI safety.", "AI": {"tldr": "ICL\u5f15\u5bfc\u867d\u7136\u80fd\u63d0\u5347\u7279\u5b9a\u4efb\u52a1\u6027\u80fd\uff0c\u4f46\u4f1a\u5bfc\u81f4\u8de8\u9886\u57df\u63a8\u7406\u80fd\u529b\u4e0b\u964d\uff0c\u5f62\u6210\"\u4f18\u5316\u8106\u5f31\u6027\"\u73b0\u8c61\u3002", "motivation": "\u63a2\u7d22ICL\u5f15\u5bfc\u5bf9\u8de8\u9886\u57df\u8ba4\u77e5\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u63a8\u7406\u80fd\u529b\u7684\u7cfb\u7edf\u6027\u53d8\u5316\u3002", "method": "\u4f7f\u7528GPT-OSS:20b\u6a21\u578b\u76846\u79cd\u53d8\u4f53\uff081\u4e2a\u57fa\u7ebf+5\u79cdICL\u914d\u7f6e\uff09\uff0c\u8fdb\u884c840\u9879\u6d4b\u8bd5\uff0c\u6db5\u76d6\u5e38\u8bc6\u95ee\u9898\u3001\u903b\u8f91\u8c1c\u9898\u548c\u6570\u5b66\u5965\u8d5b\u9898\uff0c\u901a\u8fc7ANOVA\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\u3002", "result": "ICL\u6a21\u578b\u5728\u5e38\u8bc6\u4efb\u52a1\u4e0a\u8fbe\u523091%-99%\u51c6\u786e\u7387\uff0c\u4f46\u5728\u590d\u6742\u63a8\u7406\u95ee\u9898\u4e0a\u8868\u73b0\u4e0b\u964d\uff0c\u8c1c\u9898\u51c6\u786e\u7387\u964d\u81f310-43%\uff08\u57fa\u7ebf\u4e3a43%\uff09\uff0c\u6570\u5b66\u5965\u8d5b\u9898\u65e0\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "ICL\u5f15\u5bfc\u5728\u6548\u7387\u548c\u63a8\u7406\u7075\u6d3b\u6027\u4e4b\u95f4\u5b58\u5728\u7cfb\u7edf\u6027\u6743\u8861\uff0c\u5bf9LLM\u90e8\u7f72\u548cAI\u5b89\u5168\u6709\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2510.01173", "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.01173", "abs": "https://arxiv.org/abs/2510.01173", "authors": ["Zhengyuan Jiang", "Yuyang Zhang", "Moyang Guo", "Neil Zhenqiang Gong"], "title": "EditTrack: Detecting and Attributing AI-assisted Image Editing", "comment": null, "summary": "In this work, we formulate and study the problem of image-editing detection\nand attribution: given a base image and a suspicious image, detection seeks to\ndetermine whether the suspicious image was derived from the base image using an\nAI editing model, while attribution further identifies the specific editing\nmodel responsible. Existing methods for detecting and attributing AI-generated\nimages are insufficient for this problem, as they focus on determining whether\nan image was AI-generated/edited rather than whether it was edited from a\nparticular base image. To bridge this gap, we propose EditTrack, the first\nframework for this image-editing detection and attribution problem. Building on\nfour key observations about the editing process, EditTrack introduces a novel\nre-editing strategy and leverages carefully designed similarity metrics to\ndetermine whether a suspicious image originates from a base image and, if so,\nby which model. We evaluate EditTrack on five state-of-the-art editing models\nacross six datasets, demonstrating that it consistently achieves accurate\ndetection and attribution, significantly outperforming five baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e86EditTrack\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4b\u56fe\u50cf\u662f\u5426\u7531\u7279\u5b9a\u57fa\u7840\u56fe\u50cf\u901a\u8fc7AI\u7f16\u8f91\u6a21\u578b\u751f\u6210\uff0c\u5e76\u80fd\u8bc6\u522b\u5177\u4f53\u4f7f\u7528\u7684\u7f16\u8f91\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u68c0\u6d4b\u56fe\u50cf\u662f\u5426\u4e3aAI\u751f\u6210/\u7f16\u8f91\uff0c\u4f46\u65e0\u6cd5\u5224\u65ad\u662f\u5426\u4ece\u7279\u5b9a\u57fa\u7840\u56fe\u50cf\u7f16\u8f91\u800c\u6765\uff0c\u9700\u8981\u89e3\u51b3\u56fe\u50cf\u7f16\u8f91\u68c0\u6d4b\u548c\u5f52\u5c5e\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u5bf9\u7f16\u8f91\u8fc7\u7a0b\u7684\u56db\u4e2a\u5173\u952e\u89c2\u5bdf\uff0c\u63d0\u51fa\u91cd\u65b0\u7f16\u8f91\u7b56\u7565\u548c\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u76f8\u4f3c\u5ea6\u5ea6\u91cf\uff0c\u5224\u65ad\u53ef\u7591\u56fe\u50cf\u662f\u5426\u6e90\u81ea\u57fa\u7840\u56fe\u50cf\u53ca\u4f7f\u7528\u7684\u7f16\u8f91\u6a21\u578b\u3002", "result": "\u57285\u4e2a\u6700\u5148\u8fdb\u7f16\u8f91\u6a21\u578b\u548c6\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cEditTrack\u80fd\u51c6\u786e\u8fdb\u884c\u68c0\u6d4b\u548c\u5f52\u5c5e\uff0c\u663e\u8457\u4f18\u4e8e5\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "EditTrack\u662f\u9996\u4e2a\u89e3\u51b3\u56fe\u50cf\u7f16\u8f91\u68c0\u6d4b\u548c\u5f52\u5c5e\u95ee\u9898\u7684\u6846\u67b6\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2510.00591", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00591", "abs": "https://arxiv.org/abs/2510.00591", "authors": ["Liyi Cai", "Yijie Ren", "Yitong Zhang", "Jia Li"], "title": "AI-Driven Self-Evolving Software: A Promising Path Toward Software Automation", "comment": null, "summary": "Software automation has long been a central goal of software engineering,\nstriving for software development that proceeds without human intervention.\nRecent efforts have leveraged Artificial Intelligence (AI) to advance software\nautomation with notable progress. However, current AI functions primarily as\nassistants to human developers, leaving software development still dependent on\nexplicit human intervention. This raises a fundamental question: Can AI move\nbeyond its role as an assistant to become a core component of software, thereby\nenabling genuine software automation? To investigate this vision, we introduce\nAI-Driven Self-Evolving Software, a new form of software that evolves\ncontinuously through direct interaction with users. We demonstrate the\nfeasibility of this idea with a lightweight prototype built on a multi-agent\narchitecture that autonomously interprets user requirements, generates and\nvalidates code, and integrates new functionalities. Case studies across\nmultiple representative scenarios show that the prototype can reliably\nconstruct and reuse functionality, providing early evidence that such software\nsystems can scale to more sophisticated applications and pave the way toward\ntruly automated software development. We make code and cases in this work\npublicly available at https://anonymous.4open.science/r/live-software.", "AI": {"tldr": "\u63d0\u51faAI\u9a71\u52a8\u7684\u81ea\u8fdb\u5316\u8f6f\u4ef6\u6982\u5ff5\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u67b6\u6784\u5b9e\u73b0\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u7684\u6301\u7eed\u8f6f\u4ef6\u8fdb\u5316\uff0c\u5c55\u793a\u4e86\u4eceAI\u52a9\u624b\u5230\u8f6f\u4ef6\u6838\u5fc3\u7ec4\u4ef6\u7684\u8f6c\u53d8\u53ef\u884c\u6027\u3002", "motivation": "\u5f53\u524dAI\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u4e3b\u8981\u4f5c\u4e3a\u4eba\u7c7b\u5f00\u53d1\u8005\u7684\u52a9\u624b\uff0c\u4ecd\u9700\u4eba\u5de5\u5e72\u9884\u3002\u7814\u7a76\u63a2\u7d22AI\u80fd\u5426\u8d85\u8d8a\u52a9\u624b\u89d2\u8272\uff0c\u6210\u4e3a\u8f6f\u4ef6\u6838\u5fc3\u7ec4\u4ef6\uff0c\u5b9e\u73b0\u771f\u6b63\u7684\u8f6f\u4ef6\u81ea\u52a8\u5316\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u67b6\u6784\u6784\u5efa\u8f7b\u91cf\u7ea7\u539f\u578b\uff0c\u80fd\u591f\u81ea\u4e3b\u89e3\u91ca\u7528\u6237\u9700\u6c42\u3001\u751f\u6210\u9a8c\u8bc1\u4ee3\u7801\u5e76\u96c6\u6210\u65b0\u529f\u80fd\uff0c\u5b9e\u73b0\u8f6f\u4ef6\u7684\u6301\u7eed\u8fdb\u5316\u3002", "result": "\u5728\u591a\u4e2a\u4ee3\u8868\u6027\u573a\u666f\u7684\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u539f\u578b\u80fd\u591f\u53ef\u9760\u5730\u6784\u5efa\u548c\u91cd\u7528\u529f\u80fd\uff0c\u4e3a\u66f4\u590d\u6742\u5e94\u7528\u7684\u89c4\u6a21\u5316\u63d0\u4f9b\u4e86\u65e9\u671f\u8bc1\u636e\u3002", "conclusion": "AI\u9a71\u52a8\u7684\u81ea\u8fdb\u5316\u8f6f\u4ef6\u5c55\u793a\u4e86\u5b9e\u73b0\u771f\u6b63\u81ea\u52a8\u5316\u8f6f\u4ef6\u5f00\u53d1\u7684\u6f5c\u529b\uff0c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u7684\u672a\u6765\u53d1\u5c55\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2510.00307", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00307", "abs": "https://arxiv.org/abs/2510.00307", "authors": ["Thierry Blankenstein", "Jialin Yu", "Zixuan Li", "Vassilis Plachouras", "Sunando Sengupta", "Philip Torr", "Yarin Gal", "Alasdair Paren", "Adel Bibi"], "title": "BiasBusters: Uncovering and Mitigating Tool Selection Bias in Large Language Models", "comment": null, "summary": "Agents backed by large language models (LLMs) often rely on external tools\ndrawn from marketplaces where multiple providers offer functionally equivalent\noptions. This raises a critical point concerning fairness: if selection is\nsystematically biased, it can degrade user experience and distort competition\nby privileging some providers over others. We introduce a benchmark of diverse\ntool categories, each containing multiple functionally equivalent tools, to\nevaluate tool-selection bias. Using this benchmark, we test seven models and\nshow that unfairness exists with models either fixating on a single provider or\ndisproportionately preferring earlier-listed tools in context. To investigate\nthe origins of this bias, we conduct controlled experiments examining tool\nfeatures, metadata (name, description, parameters), and pre-training exposure.\nWe find that: (1) semantic alignment between queries and metadata is the\nstrongest predictor of choice; (2) perturbing descriptions significantly shifts\nselections; and (3) repeated pre-training exposure to a single endpoint\namplifies bias. Finally, we propose a lightweight mitigation that first filters\nthe candidate tools to a relevant subset and then samples uniformly, reducing\nbias while preserving good task coverage. Our findings highlight tool-selection\nbias as a key obstacle for the fair deployment of tool-augmented LLMs.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86LLM\u4ee3\u7406\u5728\u5de5\u5177\u9009\u62e9\u4e2d\u7684\u504f\u89c1\u95ee\u9898\uff0c\u53d1\u73b0\u6a21\u578b\u4f1a\u7cfb\u7edf\u6027\u5730\u504f\u5411\u67d0\u4e9b\u63d0\u4f9b\u5546\u6216\u5217\u8868\u4f4d\u7f6e\u9760\u524d\u7684\u5de5\u5177\uff0c\u63d0\u51fa\u4e86\u8bc4\u4f30\u57fa\u51c6\u548c\u8f7b\u91cf\u7ea7\u7f13\u89e3\u65b9\u6cd5\u3002", "motivation": "LLM\u4ee3\u7406\u4f9d\u8d56\u5916\u90e8\u5de5\u5177\u5e02\u573a\uff0c\u4f46\u5de5\u5177\u9009\u62e9\u5982\u679c\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u89c1\uff0c\u4f1a\u635f\u5bb3\u7528\u6237\u4f53\u9a8c\u548c\u5e02\u573a\u7ade\u4e89\u516c\u5e73\u6027\uff0c\u9700\u8981\u7814\u7a76\u8fd9\u79cd\u504f\u89c1\u7684\u6210\u56e0\u548c\u7f13\u89e3\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u5305\u542b\u591a\u4e2a\u529f\u80fd\u7b49\u6548\u5de5\u5177\u7684\u57fa\u51c6\uff0c\u6d4b\u8bd57\u4e2a\u6a21\u578b\u7684\u9009\u62e9\u884c\u4e3a\uff0c\u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\u5206\u6790\u5de5\u5177\u7279\u5f81\u3001\u5143\u6570\u636e\u548c\u9884\u8bad\u7ec3\u66b4\u9732\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u8fc7\u6ee4\u548c\u5747\u5300\u91c7\u6837\u7684\u7f13\u89e3\u65b9\u6cd5\u3002", "result": "\u53d1\u73b0\u8bed\u4e49\u5bf9\u9f50\u662f\u9009\u62e9\u7684\u6700\u5f3a\u9884\u6d4b\u56e0\u5b50\uff0c\u6270\u52a8\u63cf\u8ff0\u4f1a\u663e\u8457\u6539\u53d8\u9009\u62e9\uff0c\u91cd\u590d\u9884\u8bad\u7ec3\u66b4\u9732\u4f1a\u653e\u5927\u504f\u89c1\uff0c\u63d0\u51fa\u7684\u7f13\u89e3\u65b9\u6cd5\u80fd\u6709\u6548\u51cf\u5c11\u504f\u89c1\u540c\u65f6\u4fdd\u6301\u4efb\u52a1\u8986\u76d6\u3002", "conclusion": "\u5de5\u5177\u9009\u62e9\u504f\u89c1\u662f\u5de5\u5177\u589e\u5f3aLLM\u516c\u5e73\u90e8\u7f72\u7684\u5173\u952e\u969c\u788d\uff0c\u9700\u8981\u5173\u6ce8\u548c\u89e3\u51b3\u3002"}}
{"id": "2510.00674", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.00674", "abs": "https://arxiv.org/abs/2510.00674", "authors": ["Konstantinos Karakatsanis", "Georgios Alexopoulos", "Ioannis Karyotakis", "Foivos Timotheos Proestakis", "Evangelos Talos", "Panos Louridas", "Dimitris Mitropoulos"], "title": "PyTrim: A Practical Tool for Reducing Python Dependency Bloat", "comment": "Accepted at ASE 2025 (Tool Demonstration Track)", "summary": "Dependency bloat is a persistent challenge in Python projects, which\nincreases maintenance costs and security risks. While numerous tools exist for\ndetecting unused dependencies in Python, removing these dependencies across the\nsource code and configuration files of a project requires manual effort and\nexpertise.\n  To tackle this challenge we introduce PYTRIM, an end-to-end system to\nautomate this process. PYTRIM eliminates unused imports and package\ndeclarations across a variety of file types, including Python source and\nconfiguration files such as requirements.txt and setup.py. PYTRIM's modular\ndesign makes it agnostic to the source of dependency bloat information,\nenabling integration with any detection tool. Beyond its contribution when it\ncomes to automation, PYTRIM also incorporates a novel dynamic analysis\ncomponent that improves dependency detection recall.\n  Our evaluation of PYTRIM's end-to-end effectiveness on a ground-truth dataset\nof 37 merged pull requests from prior work, shows that PYTRIM achieves 98.3%\naccuracy in replicating human-made changes. To show its practical impact, we\nrun PYTRIM on 971 open-source packages, identifying and trimming bloated\ndependencies in 39 of them. For each case, we submit a corresponding pull\nrequest, 6 of which have already been accepted and merged. PYTRIM is available\nas an open-source project, encouraging community contributions and further\ndevelopment.\n  Video demonstration: https://youtu.be/LqTEdOUbJRI\n  Code repository: https://github.com/TrimTeam/PyTrim", "AI": {"tldr": "PYTRIM\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u81ea\u52a8\u5316\u7cfb\u7edf\uff0c\u7528\u4e8e\u6d88\u9664Python\u9879\u76ee\u4e2d\u7684\u4f9d\u8d56\u81a8\u80c0\u95ee\u9898\uff0c\u80fd\u591f\u81ea\u52a8\u79fb\u9664\u672a\u4f7f\u7528\u7684\u5bfc\u5165\u548c\u5305\u58f0\u660e\uff0c\u652f\u6301\u591a\u79cd\u6587\u4ef6\u7c7b\u578b\uff0c\u5e76\u96c6\u6210\u4e86\u52a8\u6001\u5206\u6790\u7ec4\u4ef6\u6765\u63d0\u9ad8\u68c0\u6d4b\u53ec\u56de\u7387\u3002", "motivation": "Python\u9879\u76ee\u4e2d\u7684\u4f9d\u8d56\u81a8\u80c0\u95ee\u9898\u589e\u52a0\u4e86\u7ef4\u62a4\u6210\u672c\u548c\u5b89\u5168\u98ce\u9669\uff0c\u73b0\u6709\u5de5\u5177\u53ea\u80fd\u68c0\u6d4b\u672a\u4f7f\u7528\u7684\u4f9d\u8d56\uff0c\u4f46\u79fb\u9664\u8fd9\u4e9b\u4f9d\u8d56\u9700\u8981\u624b\u52a8\u64cd\u4f5c\u548c\u4e13\u4e1a\u77e5\u8bc6\u3002", "method": "PYTRIM\u91c7\u7528\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u80fd\u591f\u4e0e\u4efb\u4f55\u4f9d\u8d56\u68c0\u6d4b\u5de5\u5177\u96c6\u6210\uff0c\u81ea\u52a8\u79fb\u9664\u672a\u4f7f\u7528\u7684\u5bfc\u5165\u548c\u5305\u58f0\u660e\uff0c\u652f\u6301Python\u6e90\u4ee3\u7801\u548c\u914d\u7f6e\u6587\u4ef6\uff08\u5982requirements.txt\u3001setup.py\uff09\uff0c\u5e76\u5305\u542b\u52a8\u6001\u5206\u6790\u7ec4\u4ef6\u6765\u63d0\u9ad8\u68c0\u6d4b\u6548\u679c\u3002", "result": "\u572837\u4e2a\u771f\u5b9e\u5408\u5e76\u7684pull requests\u6570\u636e\u96c6\u4e0a\uff0cPYTRIM\u5b9e\u73b0\u4e8698.3%\u7684\u51c6\u786e\u7387\u3002\u5728971\u4e2a\u5f00\u6e90\u5305\u4e2d\uff0c\u8bc6\u522b\u5e76\u4fee\u526a\u4e8639\u4e2a\u5305\u7684\u81a8\u80c0\u4f9d\u8d56\uff0c\u63d0\u4ea4\u4e86\u5bf9\u5e94\u7684pull requests\uff0c\u5176\u4e2d6\u4e2a\u5df2\u88ab\u63a5\u53d7\u5408\u5e76\u3002", "conclusion": "PYTRIM\u662f\u4e00\u4e2a\u6709\u6548\u7684\u81ea\u52a8\u5316\u5de5\u5177\uff0c\u80fd\u591f\u51c6\u786e\u8bc6\u522b\u548c\u79fb\u9664Python\u9879\u76ee\u4e2d\u7684\u672a\u4f7f\u7528\u4f9d\u8d56\uff0c\u5728\u771f\u5b9e\u9879\u76ee\u4e2d\u5f97\u5230\u4e86\u9a8c\u8bc1\uff0c\u5e76\u4f5c\u4e3a\u5f00\u6e90\u9879\u76ee\u53d1\u5e03\u4ee5\u4fc3\u8fdb\u793e\u533a\u8d21\u732e\u548c\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2510.00332", "categories": ["cs.AI", "cs.CE", "I.6.4; I.2.1"], "pdf": "https://arxiv.org/pdf/2510.00332", "abs": "https://arxiv.org/abs/2510.00332", "authors": ["Zeshi Dai", "Zimo Peng", "Zerui Cheng", "Ryan Yihe Li"], "title": "When Hallucination Costs Millions: Benchmarking AI Agents in High-Stakes Adversarial Financial Markets", "comment": "15 pages, 5 figures, 4 tables; In submission to ICLR 2026", "summary": "We present CAIA, a benchmark exposing a critical blind spot in AI evaluation:\nthe inability of state-of-the-art models to operate in adversarial, high-stakes\nenvironments where misinformation is weaponized and errors are irreversible.\nWhile existing benchmarks measure task completion in controlled settings,\nreal-world deployment demands resilience against active deception. Using crypto\nmarkets as a testbed where $30 billion was lost to exploits in 2024, we\nevaluate 17 models on 178 time-anchored tasks requiring agents to distinguish\ntruth from manipulation, navigate fragmented information landscapes, and make\nirreversible financial decisions under adversarial pressure.\n  Our results reveal a fundamental capability gap: without tools, even frontier\nmodels achieve only 28% accuracy on tasks junior analysts routinely handle.\nTool augmentation improves performance but plateaus at 67.4% versus 80% human\nbaseline, despite unlimited access to professional resources. Most critically,\nwe uncover a systematic tool selection catastrophe: models preferentially\nchoose unreliable web search over authoritative data, falling for SEO-optimized\nmisinformation and social media manipulation. This behavior persists even when\ncorrect answers are directly accessible through specialized tools, suggesting\nfoundational limitations rather than knowledge gaps. We also find that Pass@k\nmetrics mask dangerous trial-and-error behavior for autonomous deployment.\n  The implications extend beyond crypto to any domain with active adversaries,\ne.g. cybersecurity, content moderation, etc. We release CAIA with contamination\ncontrols and continuous updates, establishing adversarial robustness as a\nnecessary condition for trustworthy AI autonomy. The benchmark reveals that\ncurrent models, despite impressive reasoning scores, remain fundamentally\nunprepared for environments where intelligence must survive active opposition.", "AI": {"tldr": "CAIA\u57fa\u51c6\u6d4b\u8bd5\u63ed\u793a\u4e86AI\u5728\u5bf9\u6297\u6027\u9ad8\u98ce\u9669\u73af\u5883\u4e2d\u7684\u4e25\u91cd\u80fd\u529b\u7f3a\u9677\uff0c\u7279\u522b\u662f\u5728\u52a0\u5bc6\u8d27\u5e01\u5e02\u573a\u7b49\u5b58\u5728\u4e3b\u52a8\u6b3a\u9a97\u7684\u9886\u57df\uff0c\u5373\u4f7f\u6700\u5148\u8fdb\u7684\u6a21\u578b\u4e5f\u96be\u4ee5\u533a\u5206\u771f\u76f8\u4e0e\u64cd\u7eb5\uff0c\u5728\u4e0d\u53ef\u9006\u51b3\u7b56\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u73b0\u6709AI\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u53d7\u63a7\u73af\u5883\u4e0b\u7684\u4efb\u52a1\u5b8c\u6210\u80fd\u529b\uff0c\u4f46\u73b0\u5b9e\u4e16\u754c\u90e8\u7f72\u9700\u8981AI\u5177\u5907\u62b5\u5fa1\u4e3b\u52a8\u6b3a\u9a97\u7684\u97e7\u6027\u3002\u52a0\u5bc6\u8d27\u5e01\u5e02\u573a2024\u5e74\u56e0\u6f0f\u6d1e\u635f\u5931300\u4ebf\u7f8e\u5143\uff0c\u662f\u6d4b\u8bd5AI\u5728\u5bf9\u6297\u6027\u73af\u5883\u4e2d\u8868\u73b0\u7684\u826f\u597d\u8bd5\u9a8c\u573a\u3002", "method": "\u4f7f\u7528\u52a0\u5bc6\u8d27\u5e01\u5e02\u573a\u4f5c\u4e3a\u6d4b\u8bd5\u5e73\u53f0\uff0c\u8bc4\u4f3017\u4e2a\u6a21\u578b\u5728178\u4e2a\u65f6\u95f4\u951a\u5b9a\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u8981\u6c42AI\u533a\u5206\u771f\u76f8\u4e0e\u64cd\u7eb5\u3001\u5bfc\u822a\u788e\u7247\u5316\u4fe1\u606f\u73af\u5883\uff0c\u5e76\u5728\u5bf9\u6297\u538b\u529b\u4e0b\u505a\u51fa\u4e0d\u53ef\u9006\u7684\u91d1\u878d\u51b3\u7b56\u3002", "result": "\u65e0\u5de5\u5177\u65f6\u524d\u6cbf\u6a21\u578b\u51c6\u786e\u7387\u4ec528%\uff0c\u5de5\u5177\u589e\u5f3a\u540e\u63d0\u5347\u81f367.4%\uff0c\u4f46\u4ecd\u4f4e\u4e8e80%\u7684\u4eba\u7c7b\u57fa\u51c6\u3002\u6a21\u578b\u5b58\u5728\u7cfb\u7edf\u6027\u5de5\u5177\u9009\u62e9\u707e\u96be\uff0c\u504f\u597d\u4e0d\u53ef\u9760\u7684\u7f51\u9875\u641c\u7d22\u800c\u975e\u6743\u5a01\u6570\u636e\u6e90\uff0c\u5373\u4f7f\u6b63\u786e\u7b54\u6848\u53ef\u901a\u8fc7\u4e13\u4e1a\u5de5\u5177\u76f4\u63a5\u83b7\u53d6\u3002", "conclusion": "\u5f53\u524d\u6a21\u578b\u5c3d\u7ba1\u5728\u63a8\u7406\u5f97\u5206\u4e0a\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\uff0c\u4f46\u5728\u9700\u8981\u62b5\u5fa1\u4e3b\u52a8\u5bf9\u6297\u7684\u73af\u5883\u4e2d\u4ecd\u5b58\u5728\u6839\u672c\u6027\u4e0d\u8db3\u3002\u5bf9\u6297\u6027\u9c81\u68d2\u6027\u662f\u53ef\u4fe1AI\u81ea\u4e3b\u6027\u7684\u5fc5\u8981\u6761\u4ef6\uff0cCAIA\u57fa\u51c6\u4e3a\u6b64\u63d0\u4f9b\u4e86\u6301\u7eed\u66f4\u65b0\u7684\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2510.00680", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.00680", "abs": "https://arxiv.org/abs/2510.00680", "authors": ["Hang Cui", "Jingjing Li", "Haotian Si", "Quan Zhou", "Changhua Pei", "Gaogang Xie", "Dan Pei"], "title": "TShape: Rescuing Machine Learning Models from Complex Shapelet Anomalies", "comment": null, "summary": "Time series anomaly detection (TSAD) is critical for maintaining the\nreliability of modern IT infrastructures, where complex anomalies frequently\narise in highly dynamic environments. In this paper, we present TShape, a novel\nframework designed to address the challenges in industrial time series anomaly\ndetection. Existing methods often struggle to detect shapelet anomalies that\nmanifest as complex shape deviations, which appear obvious to human experts but\nprove challenging for machine learning algorithms. TShape introduces a\npatch-wise dual attention mechanism with multi-scale convolution to model\nintricate sub-sequence variations by balancing local, fine-grained shape\nfeatures with global contextual dependencies. Our extensive evaluation on five\ndiverse benchmarks demonstrates that TShape outperforms existing\nstate-of-the-art models, achieving an average 10\\% F1 score improvement in\nanomaly detection. Additionally, ablation studies and attention visualizations\nconfirm the essential contributions of each component, highlighting the\nrobustness and adaptability of TShape to complex shapelet shapes in time series\ndata.", "AI": {"tldr": "TShape\u662f\u4e00\u4e2a\u7528\u4e8e\u5de5\u4e1a\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u8865\u4e01\u5f0f\u53cc\u91cd\u6ce8\u610f\u529b\u673a\u5236\u548c\u591a\u5c3a\u5ea6\u5377\u79ef\u6765\u68c0\u6d4b\u5f62\u72b6\u5f02\u5e38\uff0c\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747F1\u5206\u6570\u63d0\u534710%\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u68c0\u6d4b\u5f62\u72b6\u5f02\u5e38\uff08shapelet anomalies\uff09\uff0c\u8fd9\u4e9b\u5f02\u5e38\u8868\u73b0\u4e3a\u590d\u6742\u7684\u5f62\u72b6\u504f\u5dee\uff0c\u5bf9\u4eba\u7c7b\u4e13\u5bb6\u6765\u8bf4\u5f88\u660e\u663e\u4f46\u5bf9\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u5f15\u5165\u8865\u4e01\u5f0f\u53cc\u91cd\u6ce8\u610f\u529b\u673a\u5236\u4e0e\u591a\u5c3a\u5ea6\u5377\u79ef\uff0c\u901a\u8fc7\u5e73\u8861\u5c40\u90e8\u7ec6\u7c92\u5ea6\u5f62\u72b6\u7279\u5f81\u4e0e\u5168\u5c40\u4e0a\u4e0b\u6587\u4f9d\u8d56\u5173\u7cfb\u6765\u5efa\u6a21\u590d\u6742\u7684\u5b50\u5e8f\u5217\u53d8\u5316\u3002", "result": "\u5728\u4e94\u4e2a\u4e0d\u540c\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u663e\u793a\uff0cTShape\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u6a21\u578b\uff0c\u5f02\u5e38\u68c0\u6d4b\u7684F1\u5206\u6570\u5e73\u5747\u63d0\u534710%\u3002\u6d88\u878d\u7814\u7a76\u548c\u6ce8\u610f\u529b\u53ef\u89c6\u5316\u786e\u8ba4\u4e86\u5404\u7ec4\u4ef6\u7684\u91cd\u8981\u8d21\u732e\u3002", "conclusion": "TShape\u5bf9\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u590d\u6742\u5f62\u72b6\u5f02\u5e38\u5177\u6709\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\uff0c\u6bcf\u4e2a\u7ec4\u4ef6\u90fd\u53d1\u6325\u4e86\u91cd\u8981\u4f5c\u7528\u3002"}}
{"id": "2510.00355", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00355", "abs": "https://arxiv.org/abs/2510.00355", "authors": ["Renee Ge", "Qianli Liao", "Tomaso Poggio"], "title": "Hierarchical Reasoning Model: A Critical Supplementary Material", "comment": "Preprint, Under review", "summary": "Transformers have demonstrated remarkable performance in natural language\nprocessing and related domains, as they largely focus on sequential,\nautoregressive next-token prediction tasks. Yet, they struggle in logical\nreasoning, not necessarily because of a fundamental limitation of these models,\nbut possibly due to the lack of exploration of more creative uses, such as\nlatent space and recurrent reasoning. An emerging exploration in this direction\nis the Hierarchical Reasoning Model (Wang et al., 2025), which introduces a\nnovel type of recurrent reasoning in the latent space of transformers,\nachieving remarkable performance on a wide range of 2D reasoning tasks. Despite\nthe promising results, this line of models is still at an early stage and calls\nfor in-depth investigation. In this work, we perform a critical review on this\nclass of models, examine key design choices and present intriguing variants\nthat achieve significantly better performance on the Sudoku-Extreme and\nMaze-Hard tasks than previously reported. Our results also raise surprising\nobservations and intriguing directions for further research.", "AI": {"tldr": "\u5bf9Transformer\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8fdb\u884c\u5faa\u73af\u63a8\u7406\u7684\u5c42\u6b21\u63a8\u7406\u6a21\u578b\u8fdb\u884c\u6279\u5224\u6027\u56de\u987e\uff0c\u63d0\u51fa\u6539\u8fdb\u53d8\u4f53\uff0c\u5728\u6570\u72ec\u548c\u8ff7\u5bab\u4efb\u52a1\u4e0a\u53d6\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347", "motivation": "Transformer\u5728\u903b\u8f91\u63a8\u7406\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u53ef\u80fd\u6e90\u4e8e\u7f3a\u4e4f\u5bf9\u6f5c\u5728\u7a7a\u95f4\u548c\u5faa\u73af\u63a8\u7406\u7b49\u521b\u9020\u6027\u5e94\u7528\u7684\u63a2\u7d22", "method": "\u5bf9\u5c42\u6b21\u63a8\u7406\u6a21\u578b\u8fdb\u884c\u5173\u952e\u8bbe\u8ba1\u9009\u62e9\u5206\u6790\uff0c\u63d0\u51fa\u6539\u8fdb\u53d8\u4f53\uff0c\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u5b9e\u73b0\u5faa\u73af\u63a8\u7406", "result": "\u5728Sudoku-Extreme\u548cMaze-Hard\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6bd4\u4e4b\u524d\u62a5\u544a\u663e\u8457\u66f4\u597d\u7684\u6027\u80fd", "conclusion": "\u7814\u7a76\u7ed3\u679c\u63d0\u51fa\u4e86\u4ee4\u4eba\u60ca\u8bb6\u7684\u89c2\u5bdf\u548c\u8fdb\u4e00\u6b65\u7814\u7a76\u7684\u6709\u8da3\u65b9\u5411\uff0c\u8868\u660e\u8fd9\u7c7b\u6a21\u578b\u4ecd\u5904\u4e8e\u65e9\u671f\u9636\u6bb5"}}
{"id": "2510.00730", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.00730", "abs": "https://arxiv.org/abs/2510.00730", "authors": ["Larissa Schmid", "Elias Lundell", "Yogya Gamage", "Benoit Baudry", "Martin Monperrus"], "title": "Maven-Lockfile: High Integrity Rebuild of Past Java Releases", "comment": null, "summary": "Modern software projects depend on many third-party libraries, complicating\nreproducible and secure builds. Several package managers address this with the\ngeneration of a lockfile that freezes dependency versions and can be used to\nverify the integrity of dependencies. Yet, Maven, one of the most important\npackage managers in the Java ecosystem, lacks native support for a lockfile. We\npresent Maven-Lockfile to generate and update lockfiles, with support for\nrebuilding projects from past versions. Our lockfiles capture all direct and\ntransitive dependencies with their checksums, enabling high integrity builds.\nOur evaluation shows that Maven-Lockfile can reproduce builds from historical\ncommits and is able to detect tampered artifacts. With minimal configuration,\nMaven-Lockfile equips Java projects with modern build integrity and build\nreproducibility, and fosters future research on software supply chain security\nin Java.", "AI": {"tldr": "Maven-Lockfile\u4e3aJava\u751f\u6001\u7cfb\u7edf\u4e2d\u7684Maven\u5305\u7ba1\u7406\u5668\u63d0\u4f9b\u9501\u6587\u4ef6\u652f\u6301\uff0c\u89e3\u51b3\u4f9d\u8d56\u7248\u672c\u51bb\u7ed3\u548c\u6784\u5efa\u5b8c\u6574\u6027\u9a8c\u8bc1\u95ee\u9898\u3002", "motivation": "\u73b0\u4ee3\u8f6f\u4ef6\u9879\u76ee\u4f9d\u8d56\u5927\u91cf\u7b2c\u4e09\u65b9\u5e93\uff0c\u4f7f\u53ef\u91cd\u73b0\u548c\u5b89\u5168\u6784\u5efa\u53d8\u5f97\u590d\u6742\u3002Maven\u4f5c\u4e3aJava\u751f\u6001\u7cfb\u7edf\u6700\u91cd\u8981\u7684\u5305\u7ba1\u7406\u5668\u4e4b\u4e00\uff0c\u7f3a\u4e4f\u539f\u751f\u9501\u6587\u4ef6\u652f\u6301\uff0c\u65e0\u6cd5\u786e\u4fdd\u4f9d\u8d56\u5b8c\u6574\u6027\u548c\u6784\u5efa\u53ef\u91cd\u73b0\u6027\u3002", "method": "\u5f00\u53d1Maven-Lockfile\u5de5\u5177\u6765\u751f\u6210\u548c\u66f4\u65b0\u9501\u6587\u4ef6\uff0c\u652f\u6301\u4ece\u5386\u53f2\u7248\u672c\u91cd\u5efa\u9879\u76ee\u3002\u9501\u6587\u4ef6\u6355\u83b7\u6240\u6709\u76f4\u63a5\u548c\u4f20\u9012\u4f9d\u8d56\u53ca\u5176\u6821\u9a8c\u548c\uff0c\u5b9e\u73b0\u9ad8\u5b8c\u6574\u6027\u6784\u5efa\u3002", "result": "\u8bc4\u4f30\u663e\u793aMaven-Lockfile\u80fd\u591f\u91cd\u73b0\u5386\u53f2\u63d0\u4ea4\u7684\u6784\u5efa\uff0c\u5e76\u80fd\u68c0\u6d4b\u88ab\u7be1\u6539\u7684\u6784\u4ef6\u3002\u901a\u8fc7\u6700\u5c0f\u914d\u7f6e\u5373\u53ef\u4e3aJava\u9879\u76ee\u63d0\u4f9b\u73b0\u4ee3\u6784\u5efa\u5b8c\u6574\u6027\u548c\u53ef\u91cd\u73b0\u6027\u3002", "conclusion": "Maven-Lockfile\u586b\u8865\u4e86Maven\u5728\u9501\u6587\u4ef6\u652f\u6301\u65b9\u9762\u7684\u7a7a\u767d\uff0c\u4e3aJava\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\u7814\u7a76\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2510.00381", "categories": ["cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.00381", "abs": "https://arxiv.org/abs/2510.00381", "authors": ["Kaiwen Yu", "Mengying Sun", "Zhijin Qin", "Xiaodong Xu", "Ping Yang", "Yue Xiao", "Gang Wu"], "title": "Semantic-Driven AI Agent Communications: Challenges and Solutions", "comment": null, "summary": "With the rapid growth of intelligent services, communication targets are\nshifting from humans to artificial intelligent (AI) agents, which require new\nparadigms to enable real-time perception, decision-making, and collaboration.\nSemantic communication, which conveys task-relevant meaning rather than raw\ndata, offers a promising solution. However, its practical deployment remains\nconstrained by dynamic environments and limited resources. To address these\nissues, this article proposes a semantic-driven AI agent communication\nframework and develops three enabling techniques. First, semantic adaptation\ntransmission applies fine-tuning with real or generative samples to efficiently\nadapt models to varying environments. Second, semantic lightweight transmission\nincorporates pruning, quantization, and perception-aware sampling to reduce\nmodel complexity and alleviate computational burden on edge agents. Third,\nsemantic self-evolution control employs distributed hierarchical\ndecision-making to optimize multi-dimensional resources, enabling robust\nmulti-agent collaboration in dynamic environments. Simulation results show that\nthe proposed solutions achieve faster convergence and stronger robustness,\nwhile the proposed distributed hierarchical optimization method significantly\noutperforms conventional decision-making schemes, highlighting its potential\nfor AI agent communication networks.", "AI": {"tldr": "\u63d0\u51fa\u8bed\u4e49\u9a71\u52a8\u7684AI\u667a\u80fd\u4f53\u901a\u4fe1\u6846\u67b6\uff0c\u5305\u542b\u8bed\u4e49\u81ea\u9002\u5e94\u4f20\u8f93\u3001\u8bed\u4e49\u8f7b\u91cf\u5316\u4f20\u8f93\u548c\u8bed\u4e49\u81ea\u8fdb\u5316\u63a7\u5236\u4e09\u5927\u6280\u672f\uff0c\u89e3\u51b3\u52a8\u6001\u73af\u5883\u548c\u6709\u9650\u8d44\u6e90\u4e0b\u7684AI\u667a\u80fd\u4f53\u901a\u4fe1\u6311\u6218\u3002", "motivation": "\u968f\u7740\u667a\u80fd\u670d\u52a1\u5feb\u901f\u53d1\u5c55\uff0c\u901a\u4fe1\u5bf9\u8c61\u4ece\u4eba\u7c7b\u8f6c\u5411AI\u667a\u80fd\u4f53\uff0c\u9700\u8981\u65b0\u8303\u5f0f\u652f\u6301\u5b9e\u65f6\u611f\u77e5\u3001\u51b3\u7b56\u548c\u534f\u4f5c\u3002\u8bed\u4e49\u901a\u4fe1\u867d\u5177\u524d\u666f\uff0c\u4f46\u53d7\u9650\u4e8e\u52a8\u6001\u73af\u5883\u548c\u8d44\u6e90\u7ea6\u675f\u3002", "method": "1. \u8bed\u4e49\u81ea\u9002\u5e94\u4f20\u8f93\uff1a\u4f7f\u7528\u771f\u5b9e\u6216\u751f\u6210\u6837\u672c\u8fdb\u884c\u5fae\u8c03\uff0c\u4f7f\u6a21\u578b\u9002\u5e94\u53d8\u5316\u73af\u5883\uff1b2. \u8bed\u4e49\u8f7b\u91cf\u5316\u4f20\u8f93\uff1a\u7ed3\u5408\u526a\u679d\u3001\u91cf\u5316\u548c\u611f\u77e5\u611f\u77e5\u91c7\u6837\uff0c\u964d\u4f4e\u6a21\u578b\u590d\u6742\u5ea6\uff1b3. \u8bed\u4e49\u81ea\u8fdb\u5316\u63a7\u5236\uff1a\u91c7\u7528\u5206\u5e03\u5f0f\u5206\u5c42\u51b3\u7b56\u4f18\u5316\u591a\u7ef4\u8d44\u6e90\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u6240\u63d0\u65b9\u6848\u5b9e\u73b0\u66f4\u5feb\u6536\u655b\u548c\u66f4\u5f3a\u9c81\u68d2\u6027\uff0c\u5206\u5e03\u5f0f\u5206\u5c42\u4f18\u5316\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u51b3\u7b56\u65b9\u6848\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aAI\u667a\u80fd\u4f53\u901a\u4fe1\u7f51\u7edc\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u6f5c\u529b\u3002"}}
{"id": "2510.00976", "categories": ["cs.AI", "cs.CR", "cs.DC", "cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2510.00976", "abs": "https://arxiv.org/abs/2510.00976", "authors": ["Aueaphum Aueawatthanaphisut"], "title": "Adaptive Federated Few-Shot Rare-Disease Diagnosis with Energy-Aware Secure Aggregation", "comment": "6 pages, 6 figures, 12 equations, 1 algorithm", "summary": "Rare-disease diagnosis remains one of the most pressing challenges in digital\nhealth, hindered by extreme data scarcity, privacy concerns, and the limited\nresources of edge devices. This paper proposes the Adaptive Federated Few-Shot\nRare-Disease Diagnosis (AFFR) framework, which integrates three pillars: (i)\nfew-shot federated optimization with meta-learning to generalize from limited\npatient samples, (ii) energy-aware client scheduling to mitigate device\ndropouts and ensure balanced participation, and (iii) secure aggregation with\ncalibrated differential privacy to safeguard sensitive model updates. Unlike\nprior work that addresses these aspects in isolation, AFFR unifies them into a\nmodular pipeline deployable on real-world clinical networks. Experimental\nevaluation on simulated rare-disease detection datasets demonstrates up to 10%\nimprovement in accuracy compared with baseline FL, while reducing client\ndropouts by over 50% without degrading convergence. Furthermore,\nprivacy-utility trade-offs remain within clinically acceptable bounds. These\nfindings highlight AFFR as a practical pathway for equitable and trustworthy\nfederated diagnosis of rare conditions.", "AI": {"tldr": "\u63d0\u51faAFFR\u6846\u67b6\uff0c\u901a\u8fc7\u5143\u5b66\u4e60\u8054\u90a6\u4f18\u5316\u3001\u80fd\u91cf\u611f\u77e5\u5ba2\u6237\u7aef\u8c03\u5ea6\u548c\u5b89\u5168\u805a\u5408\uff0c\u89e3\u51b3\u7f55\u89c1\u75c5\u8bca\u65ad\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u3001\u8bbe\u5907\u6389\u7ebf\u548c\u9690\u79c1\u4fdd\u62a4\u95ee\u9898\uff0c\u5728\u6a21\u62df\u6570\u636e\u96c6\u4e0a\u5b9e\u73b010%\u51c6\u786e\u7387\u63d0\u5347\u548c50%\u6389\u7ebf\u7387\u964d\u4f4e\u3002", "motivation": "\u7f55\u89c1\u75c5\u8bca\u65ad\u9762\u4e34\u6570\u636e\u6781\u5ea6\u7a00\u7f3a\u3001\u9690\u79c1\u62c5\u5fe7\u548c\u8fb9\u7f18\u8bbe\u5907\u8d44\u6e90\u6709\u9650\u7b49\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u5b64\u7acb\u5904\u7406\u8fd9\u4e9b\u95ee\u9898\uff0c\u9700\u8981\u7edf\u4e00\u7684\u53ef\u90e8\u7f72\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7ed3\u5408\u4e09\u4e2a\u652f\u67f1\uff1a\u57fa\u4e8e\u5143\u5b66\u4e60\u7684\u5c11\u6837\u672c\u8054\u90a6\u4f18\u5316\u3001\u80fd\u91cf\u611f\u77e5\u5ba2\u6237\u7aef\u8c03\u5ea6\u673a\u5236\u3001\u4ee5\u53ca\u5e26\u6821\u51c6\u5dee\u5206\u9690\u79c1\u7684\u5b89\u5168\u805a\u5408\uff0c\u5f62\u6210\u6a21\u5757\u5316\u7ba1\u9053\u3002", "result": "\u5728\u6a21\u62df\u7f55\u89c1\u75c5\u68c0\u6d4b\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u6bd4\u57fa\u7ebf\u8054\u90a6\u5b66\u4e60\u51c6\u786e\u7387\u63d0\u534710%\uff0c\u5ba2\u6237\u7aef\u6389\u7ebf\u7387\u964d\u4f4e50%\u4ee5\u4e0a\uff0c\u6536\u655b\u6027\u4e0d\u53d7\u5f71\u54cd\uff0c\u9690\u79c1-\u6548\u7528\u6743\u8861\u5728\u4e34\u5e8a\u53ef\u63a5\u53d7\u8303\u56f4\u5185\u3002", "conclusion": "AFFR\u4e3a\u7f55\u89c1\u75c5\u7684\u516c\u5e73\u53ef\u4fe1\u8054\u90a6\u8bca\u65ad\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\uff0c\u7edf\u4e00\u89e3\u51b3\u4e86\u6570\u636e\u7a00\u7f3a\u3001\u8bbe\u5907\u7a33\u5b9a\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u7b49\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2510.00762", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.00762", "abs": "https://arxiv.org/abs/2510.00762", "authors": ["Rudrajit Choudhuri", "Carmen Badea", "Christian Bird", "Jenna Butler", "Rob DeLine", "Brian Houck"], "title": "AI Where It Matters: Where, Why, and How Developers Want AI Support in Daily Work", "comment": null, "summary": "Generative AI is reshaping software work, yet we lack clear guidance on where\ndevelopers most need and want support, and how to design it responsibly. We\nreport a large-scale, mixed-methods study of N=860 developers that examines\nwhere, why, and how they seek or limit AI help, providing the first task-aware,\nempirically validated mapping from developers' perceptions of their tasks to AI\nadoption patterns and responsible AI priorities. Using cognitive appraisal\ntheory, we show that task evaluations predict openness to and use of AI,\nrevealing distinct patterns: strong current use and a desire for improvement in\ncore work (e.g., coding, testing); high demand to reduce toil (e.g.,\ndocumentation, operations); and clear limits for identity- and\nrelationship-centric work (e.g., mentoring). Priorities for responsible AI\nsupport vary by context: reliability and security for systems-facing tasks;\ntransparency, alignment, and steerability to maintain control; and fairness and\ninclusiveness for human-facing work. Our results offer concrete, contextual\nguidance for delivering AI where it matters to developers and their work.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7860\u540d\u5f00\u53d1\u8005\u7684\u6df7\u5408\u65b9\u6cd5\u8c03\u67e5\uff0c\u63ed\u793a\u4e86\u5f00\u53d1\u8005\u5bf9AI\u652f\u6301\u7684\u63a5\u53d7\u7a0b\u5ea6\u548c\u4f7f\u7528\u6a21\u5f0f\uff0c\u53d1\u73b0\u4e0d\u540c\u4efb\u52a1\u7c7b\u578b\u5bf9AI\u9700\u6c42\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u5e76\u63d0\u51fa\u4e86\u8d1f\u8d23\u4efbAI\u8bbe\u8ba1\u7684\u4e0a\u4e0b\u6587\u6307\u5bfc\u539f\u5219\u3002", "motivation": "\u751f\u6210\u5f0fAI\u6b63\u5728\u91cd\u5851\u8f6f\u4ef6\u5de5\u4f5c\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u5173\u4e8e\u5f00\u53d1\u8005\u6700\u9700\u8981AI\u652f\u6301\u7684\u9886\u57df\u3001\u5982\u4f55\u8d1f\u8d23\u4efb\u8bbe\u8ba1AI\u652f\u6301\u7684\u660e\u786e\u6307\u5bfc\u3002", "method": "\u91c7\u7528\u5927\u89c4\u6a21\u6df7\u5408\u65b9\u6cd5\u7814\u7a76\uff0c\u5bf9860\u540d\u5f00\u53d1\u8005\u8fdb\u884c\u8c03\u67e5\uff0c\u7ed3\u5408\u8ba4\u77e5\u8bc4\u4ef7\u7406\u8bba\u5206\u6790\u4efb\u52a1\u8bc4\u4f30\u5982\u4f55\u9884\u6d4bAI\u63a5\u53d7\u5ea6\u548c\u4f7f\u7528\u6a21\u5f0f\u3002", "result": "\u53d1\u73b0\u4e09\u79cd\u4e3b\u8981\u6a21\u5f0f\uff1a\u6838\u5fc3\u5de5\u4f5c\uff08\u7f16\u7801\u3001\u6d4b\u8bd5\uff09\u5df2\u6709\u8f83\u5f3a\u4f7f\u7528\u4f46\u5e0c\u671b\u6539\u8fdb\uff1b\u9ad8\u9700\u6c42\u51cf\u5c11\u91cd\u590d\u6027\u5de5\u4f5c\uff08\u6587\u6863\u3001\u8fd0\u7ef4\uff09\uff1b\u660e\u786e\u9650\u5236\u8eab\u4efd\u548c\u5173\u7cfb\u76f8\u5173\u4efb\u52a1\uff08\u6307\u5bfc\uff09\u3002\u8d1f\u8d23\u4efbAI\u7684\u4f18\u5148\u7ea7\u56e0\u4e0a\u4e0b\u6587\u800c\u5f02\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u5728\u5f00\u53d1\u8005\u771f\u6b63\u5173\u5fc3\u7684\u9886\u57df\u63d0\u4f9bAI\u652f\u6301\u63d0\u4f9b\u4e86\u5177\u4f53\u3001\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u6307\u5bfc\uff0c\u5e2e\u52a9\u8bbe\u8ba1\u66f4\u8d1f\u8d23\u4efb\u548c\u6709\u6548\u7684AI\u5de5\u5177\u3002"}}
{"id": "2510.00415", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00415", "abs": "https://arxiv.org/abs/2510.00415", "authors": ["Dadi Guo", "Tianyi Zhou", "Dongrui Liu", "Chen Qian", "Qihan Ren", "Shuai Shao", "Zhiyuan Fan", "Yi R. Fung", "Kun Wang", "Linfeng Zhang", "Jing Shao"], "title": "Towards Self-Evolving Benchmarks: Synthesizing Agent Trajectories via Test-Time Exploration under Validate-by-Reproduce Paradigm", "comment": "his is a work in progress due to methodology refinement and further\n  evaluation", "summary": "Recent advances in large language models (LLMs) and agent system designs have\nempowered agents with unprecedented levels of capability. However, existing\nagent benchmarks are showing a trend of rapid ceiling-hitting by newly\ndeveloped agents, making it difficult to meet the demands for evaluating agent\nabilities. To address this problem, we propose the Trajectory-based\nValidated-by-Reproducing Agent-benchmark Complexity Evolution (TRACE)\nframework. This framework takes an original task from an existing benchmark and\nencourages agents to freely explore and evolve it into a new task with higher\ndifficulty while recording validatable agent trajectories. The framework\nproceeds in three stages: (1) evolutionary proposal mining, which provides task\nevolution proposals through preliminary exploration and divergent thinking; (2)\nproblem formation and free exploration, where proposals are conceptualized into\nfeasible problem candidates and the agents then explore them freely while\nrecording their execution trajectories; and (3) multi-level validation, which\nensures that the evolved tasks are accompanied by validatable and reproducible\ntrajectories. Experiments on the GAIA benchmark demonstrate that the TRACE\nframework consistently enhances task complexity while improving the reliability\nof correctness through validatable execution trajectories. This work marks a\nparadigm shift from static, manually curated benchmarks to dynamic,\nself-evolving evaluation systems, providing a sustainable and challenging\nrunway for agent development.", "AI": {"tldr": "TRACE\u6846\u67b6\u901a\u8fc7\u8ba9\u667a\u80fd\u4f53\u81ea\u7531\u63a2\u7d22\u548c\u6f14\u5316\u73b0\u6709\u57fa\u51c6\u4efb\u52a1\uff0c\u751f\u6210\u66f4\u9ad8\u96be\u5ea6\u7684\u65b0\u4efb\u52a1\uff0c\u5e76\u8bb0\u5f55\u53ef\u9a8c\u8bc1\u7684\u6267\u884c\u8f68\u8ff9\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u667a\u80fd\u4f53\u57fa\u51c6\u5feb\u901f\u8fbe\u5230\u6027\u80fd\u5929\u82b1\u677f\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u667a\u80fd\u4f53\u57fa\u51c6\u663e\u793a\u51fa\u65b0\u5f00\u53d1\u667a\u80fd\u4f53\u5feb\u901f\u8fbe\u5230\u6027\u80fd\u4e0a\u9650\u7684\u8d8b\u52bf\uff0c\u96be\u4ee5\u6ee1\u8db3\u8bc4\u4f30\u667a\u80fd\u4f53\u80fd\u529b\u7684\u9700\u6c42\u3002", "method": "TRACE\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u9636\u6bb5\uff1a\u8fdb\u5316\u63d0\u6848\u6316\u6398\uff08\u901a\u8fc7\u521d\u6b65\u63a2\u7d22\u548c\u53d1\u6563\u601d\u7ef4\u63d0\u4f9b\u4efb\u52a1\u8fdb\u5316\u63d0\u6848\uff09\u3001\u95ee\u9898\u5f62\u6210\u4e0e\u81ea\u7531\u63a2\u7d22\uff08\u5c06\u63d0\u6848\u6982\u5ff5\u5316\u4e3a\u53ef\u884c\u95ee\u9898\u5019\u9009\uff0c\u667a\u80fd\u4f53\u81ea\u7531\u63a2\u7d22\u5e76\u8bb0\u5f55\u6267\u884c\u8f68\u8ff9\uff09\u3001\u591a\u7ea7\u9a8c\u8bc1\uff08\u786e\u4fdd\u8fdb\u5316\u4efb\u52a1\u5177\u6709\u53ef\u9a8c\u8bc1\u548c\u53ef\u590d\u73b0\u7684\u8f68\u8ff9\uff09\u3002", "result": "\u5728GAIA\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTRACE\u6846\u67b6\u80fd\u6301\u7eed\u63d0\u5347\u4efb\u52a1\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u901a\u8fc7\u53ef\u9a8c\u8bc1\u7684\u6267\u884c\u8f68\u8ff9\u63d0\u9ad8\u6b63\u786e\u6027\u7684\u53ef\u9760\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u6807\u5fd7\u7740\u4ece\u9759\u6001\u3001\u4eba\u5de5\u7b56\u5212\u7684\u57fa\u51c6\u5411\u52a8\u6001\u3001\u81ea\u8fdb\u5316\u8bc4\u4f30\u7cfb\u7edf\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u4e3a\u667a\u80fd\u4f53\u53d1\u5c55\u63d0\u4f9b\u4e86\u53ef\u6301\u7eed\u4e14\u5177\u6709\u6311\u6218\u6027\u7684\u8dd1\u9053\u3002"}}
{"id": "2510.01002", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.01002", "abs": "https://arxiv.org/abs/2510.01002", "authors": ["Chengran Yang", "Ting Zhang", "Jinfeng Jiang", "Xin Zhou", "Haoye Tian", "Jieke Shi", "Junkai Chen", "Yikun Li", "Eng Lieh Ouh", "Lwin Khin Shar", "David Lo"], "title": "Semantics-Aligned, Curriculum-Driven, and Reasoning-Enhanced Vulnerability Repair Framework", "comment": null, "summary": "Current learning-based Automated Vulnerability Repair (AVR) approaches, while\npromising, often fail to generalize effectively in real-world scenarios. Our\ndiagnostic analysis reveals three fundamental weaknesses in state-of-the-art\nAVR approaches: (1) limited cross-repository generalization, with performance\ndrops on unseen codebases; (2) inability to capture long-range dependencies,\ncausing a performance degradation on complex, multi-hunk repairs; and (3)\nover-reliance on superficial lexical patterns, leading to significant\nperformance drops on vulnerabilities with minor syntactic variations like\nvariable renaming.\n  To address these limitations, we propose SeCuRepair, a semantics-aligned,\ncurriculum-driven, and reasoning-enhanced framework for vulnerability repair.\nAt its core, SeCuRepair adopts a reason-then-edit paradigm, requiring the model\nto articulate why and how a vulnerability should be fixed before generating the\npatch. This explicit reasoning enforces a genuine understanding of repair logic\nrather than superficial memorization of lexical patterns. SeCuRepair also moves\nbeyond traditional supervised fine-tuning and employs semantics-aware\nreinforcement learning, rewarding patches for their syntactic and semantic\nalignment with the oracle patch rather than mere token overlap. Complementing\nthis, a difficulty-aware curriculum progressively trains the model, starting\nwith simple fixes and advancing to complex, multi-hunk coordinated edits.\n  We evaluate SeCuRepair on strict, repository-level splits of BigVul and newly\ncrafted PrimeVul_AVR datasets. SeCuRepair significantly outperforms all\nbaselines, surpassing the best-performing baselines by 34.52% on BigVul and\n31.52% on PrimeVul\\textsubscript{AVR} in terms of CodeBLEU, respectively.\nComprehensive ablation studies further confirm that each component of our\nframework contributes to its final performance.", "AI": {"tldr": "SeCuRepair\u662f\u4e00\u4e2a\u57fa\u4e8e\u8bed\u4e49\u5bf9\u9f50\u3001\u8bfe\u7a0b\u9a71\u52a8\u548c\u63a8\u7406\u589e\u5f3a\u7684\u6f0f\u6d1e\u4fee\u590d\u6846\u67b6\uff0c\u901a\u8fc7\u5148\u63a8\u7406\u540e\u7f16\u8f91\u7684\u8303\u5f0f\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8\u5316\u6f0f\u6d1e\u4fee\u590d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5b66\u4e60\u7684\u81ea\u52a8\u5316\u6f0f\u6d1e\u4fee\u590d\u65b9\u6cd5\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\uff0c\u5b58\u5728\u8de8\u4ed3\u5e93\u6cdb\u5316\u6709\u9650\u3001\u65e0\u6cd5\u6355\u6349\u957f\u8ddd\u79bb\u4f9d\u8d56\u3001\u8fc7\u5ea6\u4f9d\u8d56\u8868\u9762\u8bcd\u6c47\u6a21\u5f0f\u7b49\u95ee\u9898\u3002", "method": "\u91c7\u7528\u5148\u63a8\u7406\u540e\u7f16\u8f91\u7684\u8303\u5f0f\uff0c\u8981\u6c42\u6a21\u578b\u5728\u751f\u6210\u8865\u4e01\u524d\u660e\u786e\u8868\u8fbe\u4fee\u590d\u903b\u8f91\uff1b\u4f7f\u7528\u8bed\u4e49\u611f\u77e5\u7684\u5f3a\u5316\u5b66\u4e60\u5956\u52b1\u8bed\u6cd5\u548c\u8bed\u4e49\u5bf9\u9f50\u7684\u8865\u4e01\uff1b\u91c7\u7528\u96be\u5ea6\u611f\u77e5\u7684\u8bfe\u7a0b\u5b66\u4e60\u4ece\u7b80\u5355\u4fee\u590d\u9010\u6b65\u8fc7\u6e21\u5230\u590d\u6742\u7684\u591a\u5757\u534f\u8c03\u7f16\u8f91\u3002", "result": "\u5728BigVul\u548cPrimeVul_AVR\u6570\u636e\u96c6\u4e0a\uff0cSeCuRepair\u663e\u8457\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0cCodeBLEU\u6307\u6807\u5206\u522b\u6bd4\u6700\u4f73\u57fa\u7ebf\u9ad8\u51fa34.52%\u548c31.52%\u3002", "conclusion": "SeCuRepair\u901a\u8fc7\u8bed\u4e49\u5bf9\u9f50\u3001\u63a8\u7406\u589e\u5f3a\u548c\u8bfe\u7a0b\u5b66\u4e60\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709AVR\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6f0f\u6d1e\u4fee\u590d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6027\u80fd\u3002"}}
{"id": "2510.00881", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00881", "abs": "https://arxiv.org/abs/2510.00881", "authors": ["Patrizio Migliarini", "Mashal Afzal Memon", "Marco Autili", "Paola Inverardi"], "title": "Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning", "comment": "Accepted at ASE 2025", "summary": "Large Language Models (LLMs) are increasingly integrated into software\nengineering (SE) tools for tasks that extend beyond code synthesis, including\njudgment under uncertainty and reasoning in ethically significant contexts. We\npresent a fully automated framework for assessing ethical reasoning\ncapabilities across 16 LLMs in a zero-shot setting, using 30 real-world\nethically charged scenarios. Each model is prompted to identify the most\napplicable ethical theory to an action, assess its moral acceptability, and\nexplain the reasoning behind their choice. Responses are compared against\nexpert ethicists' choices using inter-model agreement metrics. Our results show\nthat LLMs achieve an average Theory Consistency Rate (TCR) of 73.3% and Binary\nAgreement Rate (BAR) on moral acceptability of 86.7%, with interpretable\ndivergences concentrated in ethically ambiguous cases. A qualitative analysis\nof free-text explanations reveals strong conceptual convergence across models\ndespite surface-level lexical diversity. These findings support the potential\nviability of LLMs as ethical inference engines within SE pipelines, enabling\nscalable, auditable, and adaptive integration of user-aligned ethical\nreasoning. Our focus is the Ethical Interpreter component of a broader\nprofiling pipeline: we evaluate whether current LLMs exhibit sufficient\ninterpretive stability and theory-consistent reasoning to support automated\nprofiling.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f3016\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u7684\u4f26\u7406\u63a8\u7406\u80fd\u529b\uff0c\u4f7f\u752830\u4e2a\u771f\u5b9e\u4e16\u754c\u7684\u4f26\u7406\u573a\u666f\u8fdb\u884c\u6d4b\u8bd5\u3002", "motivation": "\u968f\u7740LLMs\u8d8a\u6765\u8d8a\u591a\u5730\u96c6\u6210\u5230\u8f6f\u4ef6\u5de5\u7a0b\u5de5\u5177\u4e2d\uff0c\u9700\u8981\u8bc4\u4f30\u5b83\u4eec\u5728\u4f26\u7406\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u6d89\u53ca\u4e0d\u786e\u5b9a\u6027\u548c\u4f26\u7406\u91cd\u8981\u60c5\u5883\u4e0b\u7684\u5224\u65ad\u80fd\u529b\u3002", "method": "\u91c7\u7528\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u8ba9LLMs\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u8bc6\u522b\u6700\u9002\u7528\u7684\u4f26\u7406\u7406\u8bba\u3001\u8bc4\u4f30\u884c\u4e3a\u7684\u9053\u5fb7\u53ef\u63a5\u53d7\u6027\uff0c\u5e76\u89e3\u91ca\u5176\u63a8\u7406\u8fc7\u7a0b\uff0c\u7136\u540e\u5c06\u54cd\u5e94\u4e0e\u4f26\u7406\u5b66\u4e13\u5bb6\u7684\u9009\u62e9\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "LLMs\u7684\u5e73\u5747\u7406\u8bba\u4e00\u81f4\u6027\u7387\u4e3a73.3%\uff0c\u9053\u5fb7\u53ef\u63a5\u53d7\u6027\u7684\u4e8c\u5143\u4e00\u81f4\u7387\u4e3a86.7%\uff0c\u5728\u4f26\u7406\u6a21\u7cca\u6848\u4f8b\u4e2d\u5b58\u5728\u53ef\u89e3\u91ca\u7684\u5206\u6b67\uff0c\u5b9a\u6027\u5206\u6790\u663e\u793a\u6a21\u578b\u95f4\u5b58\u5728\u5f3a\u70c8\u7684\u6982\u5ff5\u6536\u655b\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660eLLMs\u4f5c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u7ba1\u9053\u4e2d\u7684\u4f26\u7406\u63a8\u7406\u5f15\u64ce\u5177\u6709\u6f5c\u5728\u53ef\u884c\u6027\uff0c\u80fd\u591f\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u53ef\u5ba1\u8ba1\u548c\u81ea\u9002\u5e94\u7684\u7528\u6237\u5bf9\u9f50\u4f26\u7406\u63a8\u7406\u96c6\u6210\u3002"}}
{"id": "2510.00436", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00436", "abs": "https://arxiv.org/abs/2510.00436", "authors": ["Sarvesh Soni", "Dina Demner-Fushman"], "title": "Automated Evaluation can Distinguish the Good and Bad AI Responses to Patient Questions about Hospitalization", "comment": null, "summary": "Automated approaches to answer patient-posed health questions are rising, but\nselecting among systems requires reliable evaluation. The current gold standard\nfor evaluating the free-text artificial intelligence (AI) responses--human\nexpert review--is labor-intensive and slow, limiting scalability. Automated\nmetrics are promising yet variably aligned with human judgments and often\ncontext-dependent. To address the feasibility of automating the evaluation of\nAI responses to hospitalization-related questions posed by patients, we\nconducted a large systematic study of evaluation approaches. Across 100 patient\ncases, we collected responses from 28 AI systems (2800 total) and assessed them\nalong three dimensions: whether a system response (1) answers the question, (2)\nappropriately uses clinical note evidence, and (3) uses general medical\nknowledge. Using clinician-authored reference answers to anchor metrics,\nautomated rankings closely matched expert ratings. Our findings suggest that\ncarefully designed automated evaluation can scale comparative assessment of AI\nsystems and support patient-clinician communication.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u81ea\u52a8\u5316\u8bc4\u4f30AI\u7cfb\u7edf\u56de\u7b54\u60a3\u8005\u5065\u5eb7\u95ee\u9898\u7684\u53ef\u884c\u6027\uff0c\u901a\u8fc7\u7cfb\u7edf\u7814\u7a76\u8bc4\u4f30\u65b9\u6cd5\uff0c\u53d1\u73b0\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u80fd\u591f\u6709\u6548\u6269\u5c55AI\u7cfb\u7edf\u7684\u6bd4\u8f83\u8bc4\u4f30\u3002", "motivation": "\u5f53\u524d\u8bc4\u4f30AI\u56de\u7b54\u60a3\u8005\u5065\u5eb7\u95ee\u9898\u7684\u9ec4\u91d1\u6807\u51c6\u2014\u2014\u4eba\u7c7b\u4e13\u5bb6\u8bc4\u5ba1\u2014\u2014\u52b3\u52a8\u5bc6\u96c6\u4e14\u7f13\u6162\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u3002\u81ea\u52a8\u5316\u6307\u6807\u867d\u7136\u524d\u666f\u5e7f\u9614\uff0c\u4f46\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u4e00\u81f4\u6027\u4e0d\u4e00\u4e14\u5e38\u5e38\u4f9d\u8d56\u4e0a\u4e0b\u6587\u3002", "method": "\u5728100\u4e2a\u60a3\u8005\u6848\u4f8b\u4e2d\uff0c\u6536\u96c6\u4e8628\u4e2aAI\u7cfb\u7edf\u7684\u56de\u7b54\uff08\u51712800\u4e2a\uff09\uff0c\u4ece\u4e09\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\uff1a\u662f\u5426\u56de\u7b54\u95ee\u9898\u3001\u662f\u5426\u9002\u5f53\u4f7f\u7528\u4e34\u5e8a\u8bb0\u5f55\u8bc1\u636e\u3001\u662f\u5426\u4f7f\u7528\u4e00\u822c\u533b\u5b66\u77e5\u8bc6\u3002\u4f7f\u7528\u4e34\u5e8a\u533b\u751f\u64b0\u5199\u7684\u53c2\u8003\u7b54\u6848\u4f5c\u4e3a\u6307\u6807\u951a\u70b9\u3002", "result": "\u81ea\u52a8\u5316\u6392\u540d\u4e0e\u4e13\u5bb6\u8bc4\u5206\u9ad8\u5ea6\u5339\u914d\uff0c\u8868\u660e\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u80fd\u591f\u6709\u6548\u6269\u5c55AI\u7cfb\u7edf\u7684\u6bd4\u8f83\u8bc4\u4f30\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u53ef\u4ee5\u6269\u5c55AI\u7cfb\u7edf\u7684\u6bd4\u8f83\u8bc4\u4f30\uff0c\u5e76\u652f\u6301\u60a3\u8005-\u4e34\u5e8a\u533b\u751f\u6c9f\u901a\u3002"}}
{"id": "2510.00920", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.00920", "abs": "https://arxiv.org/abs/2510.00920", "authors": ["Songqiang Chen", "Congying Xu", "Jingyi Chen", "Jialun Cao", "Jiarong Wu", "Shing-Chi Cheung"], "title": "On Effective Semantic Translation for Code: A Study Based on Pseudocode", "comment": null, "summary": "Large language models (LLMs) show great potential in code translation.\nHowever, accurate translation remains challenging when using the commonly\nadopted direct code-to-code translation approach, which converts a program into\nthe target programming language (PL) in a single step. Inspired by the success\nof incorporating intermediate steps to guide LLMs in resolving challenging\ntasks, we explore pseudocode-based code translation, which emulates the human\nsemantic translation by first interpreting the program's intent and logic into\npseudocode and then implementing it in the target PL. We find that\npseudocode-based translation helps translate programs that direct translation\nstruggles to handle. Nonetheless, the effectiveness, advantages, and\nlimitations of this approach remain underexplored. To bridge this gap, we\npresent an empirical study on pseudocode-based code translation, aiming to\ninvestigate its effectiveness in enhancing the direct translation approach,\nilluminate its effective usage, and identify limitations hindering its\npotential benefits. By comparing direct and pseudocode-based translation\napproaches on 9,690 translation tasks across six PLs with five popular LLMs, we\ndemonstrate that pseudocode-based translation can effectively complement direct\ntranslation, particularly when translating from flexible to rigid PLs or\ndealing with low-resource Rust. Based on these findings, we suggest adopting\nstrategies that combine the complementary strengths of both approaches to\nenhance code translation accuracy. We also reveal the advantages of\npseudocode-based translation in disentangling translations of complicated\nprograms and mitigating distractions from detailed implementations in original\nprograms, as well as its limitations due to incorrect, incomplete, or ambiguous\npseudocode.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u4f2a\u4ee3\u7801\u4f5c\u4e3a\u4e2d\u95f4\u6b65\u9aa4\u6765\u6539\u8fdb\u4ee3\u7801\u7ffb\u8bd1\uff0c\u901a\u8fc7\u5c06\u7a0b\u5e8f\u5148\u8f6c\u6362\u4e3a\u4f2a\u4ee3\u7801\u518d\u7ffb\u8bd1\u5230\u76ee\u6807\u8bed\u8a00\uff0c\u76f8\u6bd4\u76f4\u63a5\u7ffb\u8bd1\u65b9\u6cd5\u80fd\u66f4\u597d\u5730\u5904\u7406\u590d\u6742\u7a0b\u5e8f\uff0c\u7279\u522b\u662f\u5728\u4ece\u7075\u6d3b\u8bed\u8a00\u5230\u4e25\u683c\u8bed\u8a00\u7684\u7ffb\u8bd1\u573a\u666f\u4e2d\u3002", "motivation": "\u76f4\u63a5\u4ee3\u7801\u7ffb\u8bd1\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u7a0b\u5e8f\u65f6\u5b58\u5728\u56f0\u96be\uff0c\u53d7\u4eba\u7c7b\u8bed\u4e49\u7ffb\u8bd1\u8fc7\u7a0b\u542f\u53d1\uff0c\u63a2\u7d22\u4f7f\u7528\u4f2a\u4ee3\u7801\u4f5c\u4e3a\u4e2d\u95f4\u6b65\u9aa4\u6765\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u4f2a\u4ee3\u7801\u57fa\u4ee3\u7801\u7ffb\u8bd1\u65b9\u6cd5\uff0c\u5148\u5c06\u7a0b\u5e8f\u89e3\u91ca\u4e3a\u4f2a\u4ee3\u7801\u8868\u8fbe\u610f\u56fe\u548c\u903b\u8f91\uff0c\u518d\u5b9e\u73b0\u4e3a\u76ee\u6807\u7f16\u7a0b\u8bed\u8a00\u3002\u901a\u8fc7\u6bd4\u8f83\u76f4\u63a5\u7ffb\u8bd1\u548c\u4f2a\u4ee3\u7801\u57fa\u7ffb\u8bd1\u57289,690\u4e2a\u7ffb\u8bd1\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u4f7f\u75285\u4e2a\u6d41\u884cLLM\u548c6\u79cd\u7f16\u7a0b\u8bed\u8a00\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\u3002", "result": "\u4f2a\u4ee3\u7801\u57fa\u7ffb\u8bd1\u80fd\u6709\u6548\u8865\u5145\u76f4\u63a5\u7ffb\u8bd1\uff0c\u7279\u522b\u9002\u7528\u4e8e\u4ece\u7075\u6d3b\u8bed\u8a00\u5230\u4e25\u683c\u8bed\u8a00\u7684\u7ffb\u8bd1\u548c\u5904\u7406\u4f4e\u8d44\u6e90Rust\u8bed\u8a00\u3002\u4e24\u79cd\u65b9\u6cd5\u5177\u6709\u4e92\u8865\u4f18\u52bf\uff0c\u7ed3\u5408\u4f7f\u7528\u80fd\u63d0\u9ad8\u7ffb\u8bd1\u51c6\u786e\u6027\u3002", "conclusion": "\u5efa\u8bae\u91c7\u7528\u7ed3\u5408\u76f4\u63a5\u7ffb\u8bd1\u548c\u4f2a\u4ee3\u7801\u57fa\u7ffb\u8bd1\u4f18\u52bf\u7684\u7b56\u7565\u6765\u63d0\u5347\u4ee3\u7801\u7ffb\u8bd1\u51c6\u786e\u6027\u3002\u4f2a\u4ee3\u7801\u57fa\u7ffb\u8bd1\u5728\u89e3\u8026\u590d\u6742\u7a0b\u5e8f\u7ffb\u8bd1\u548c\u51cf\u5c11\u539f\u59cb\u7a0b\u5e8f\u5b9e\u73b0\u7ec6\u8282\u5e72\u6270\u65b9\u9762\u6709\u4f18\u52bf\uff0c\u4f46\u4e5f\u53d7\u9650\u4e8e\u4f2a\u4ee3\u7801\u751f\u6210\u7684\u8d28\u91cf\u95ee\u9898\u3002"}}
{"id": "2510.00480", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00480", "abs": "https://arxiv.org/abs/2510.00480", "authors": ["Kenjiro Ide", "Taiga Someya", "Kohei Kawaguchi", "Keisuke Fujii"], "title": "Expandable Decision-Making States for Multi-Agent Deep Reinforcement Learning in Soccer Tactical Analysis", "comment": "28 pages, 9 figures", "summary": "Invasion team sports such as soccer produce a high-dimensional, strongly\ncoupled state space as many players continuously interact on a shared field,\nchallenging quantitative tactical analysis. Traditional rule-based analyses are\nintuitive, while modern predictive machine learning models often perform\npattern-matching without explicit agent representations. The problem we address\nis how to build player-level agent models from data, whose learned values and\npolicies are both tactically interpretable and robust across heterogeneous data\nsources. Here, we propose Expandable Decision-Making States (EDMS), a\nsemantically enriched state representation that augments raw positions and\nvelocities with relational variables (e.g., scoring of space, pass, and score),\ncombined with an action-masking scheme that gives on-ball and off-ball agents\ndistinct decision sets. Compared to prior work, EDMS maps learned value\nfunctions and action policies to human-interpretable tactical concepts (e.g.,\nmarking pressure, passing lanes, ball accessibility) instead of raw coordinate\nfeatures, and aligns agent choices with the rules of play. In the experiments,\nEDMS with action masking consistently reduced both action-prediction loss and\ntemporal-difference (TD) error compared to the baseline. Qualitative case\nstudies and Q-value visualizations further indicate that EDMS highlights\nhigh-risk, high-reward tactical patterns (e.g., fast counterattacks and\ndefensive breakthroughs). We also integrated our approach into an open-source\nlibrary and demonstrated compatibility with multiple commercial and open\ndatasets, enabling cross-provider evaluation and reproducible experiments.", "AI": {"tldr": "\u63d0\u51faEDMS\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bed\u4e49\u589e\u5f3a\u7684\u72b6\u6001\u8868\u793a\u548c\u52a8\u4f5c\u63a9\u7801\u673a\u5236\uff0c\u6784\u5efa\u53ef\u89e3\u91ca\u7684\u7403\u5458\u7ea7\u667a\u80fd\u4f53\u6a21\u578b\uff0c\u7528\u4e8e\u8db3\u7403\u7b49\u5165\u4fb5\u6027\u56e2\u961f\u8fd0\u52a8\u7684\u6218\u672f\u5206\u6790\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u7684\u5206\u6790\u65b9\u6cd5\u76f4\u89c2\u4f46\u6709\u9650\uff0c\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7f3a\u4e4f\u660e\u786e\u7684\u667a\u80fd\u4f53\u8868\u793a\u548c\u6218\u672f\u53ef\u89e3\u91ca\u6027\u3002\u9700\u8981\u6784\u5efa\u65e2\u80fd\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\uff0c\u53c8\u5177\u6709\u6218\u672f\u53ef\u89e3\u91ca\u6027\u548c\u8de8\u6570\u636e\u6e90\u9c81\u68d2\u6027\u7684\u7403\u5458\u7ea7\u667a\u80fd\u4f53\u6a21\u578b\u3002", "method": "\u63d0\u51faExpandable Decision-Making States (EDMS)\uff0c\u901a\u8fc7\u589e\u5f3a\u539f\u59cb\u4f4d\u7f6e\u548c\u901f\u5ea6\u4fe1\u606f\uff0c\u6dfb\u52a0\u5173\u7cfb\u53d8\u91cf\uff08\u5982\u7a7a\u95f4\u5f97\u5206\u3001\u4f20\u7403\u548c\u5f97\u5206\u8bc4\u4f30\uff09\uff0c\u5e76\u7ed3\u5408\u52a8\u4f5c\u63a9\u7801\u65b9\u6848\uff0c\u4e3a\u6301\u7403\u548c\u65e0\u7403\u7403\u5458\u63d0\u4f9b\u4e0d\u540c\u7684\u51b3\u7b56\u96c6\u3002", "result": "EDMS\u4e0e\u52a8\u4f5c\u63a9\u7801\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\uff0c\u6301\u7eed\u964d\u4f4e\u4e86\u52a8\u4f5c\u9884\u6d4b\u635f\u5931\u548c\u65f6\u95f4\u5dee\u5206\u8bef\u5dee\u3002\u5b9a\u6027\u6848\u4f8b\u7814\u7a76\u548cQ\u503c\u53ef\u89c6\u5316\u663e\u793aEDMS\u80fd\u591f\u7a81\u51fa\u9ad8\u98ce\u9669\u9ad8\u56de\u62a5\u7684\u6218\u672f\u6a21\u5f0f\u3002", "conclusion": "EDMS\u65b9\u6cd5\u80fd\u591f\u5c06\u5b66\u4e60\u5230\u7684\u4ef7\u503c\u51fd\u6570\u548c\u52a8\u4f5c\u7b56\u7565\u6620\u5c04\u5230\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u6218\u672f\u6982\u5ff5\uff0c\u4e0e\u6bd4\u8d5b\u89c4\u5219\u5bf9\u9f50\uff0c\u5e76\u652f\u6301\u8de8\u6570\u636e\u6e90\u8bc4\u4f30\u548c\u53ef\u91cd\u590d\u5b9e\u9a8c\u3002"}}
{"id": "2510.00946", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.00946", "abs": "https://arxiv.org/abs/2510.00946", "authors": ["Shiza Andleeb", "Brandon Kantorski", "Jeffrey C. Carver"], "title": "ChatGPT in Introductory Programming: Counterbalanced Evaluation of Code Quality, Conceptual Learning, and Student Perceptions", "comment": "Accepted to SIGCITE'25", "summary": "Background: Large language models (LLMs) such as ChatGPT are increasingly\nused in introductory programming courses to provide real-time code generation,\ndebugging, and explanations. While these tools can boost productivity and code\nquality, concerns remain about over-reliance and potential impacts on\nconceptual learning. Objective: To investigate how ChatGPT access affects code\nquality, conceptual understanding, task completion times, and student\nperceptions in a CS1 course. Methods: We conducted a counterbalanced,\nquasi-experimental study in which students alternated between ChatGPT and\nnon-ChatGPT conditions across two programming assignments in C (functions and\nstructures). We evaluated their code submissions using multidimensional\nrubrics, conceptual post-surveys, and task completion time. Results: Students\nwho had access to ChatGPT produced significantly higher rubric scores for code\nquality and completed tasks in less time compared to those without access.\nHowever, gains in conceptual understanding were mixed, lower for the functions\ntopic but higher for the structures topic. Students reported positive\nexperiences with ChatGPT, citing its value for debugging and practice, while\nexpressing concerns about accuracy and long-term skill development.\nConclusions: ChatGPT can enhance code quality and efficiency for novice\nprogrammers, but may not uniformly improve conceptual understanding. Structured\nintegration and complementary instructional strategies are recommended to\nfoster independent problem-solving skills.", "AI": {"tldr": "\u7814\u7a76ChatGPT\u5bf9CS1\u8bfe\u7a0b\u4e2d\u5b66\u751f\u7f16\u7a0b\u8868\u73b0\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u4f7f\u7528ChatGPT\u80fd\u63d0\u9ad8\u4ee3\u7801\u8d28\u91cf\u548c\u6548\u7387\uff0c\u4f46\u5bf9\u6982\u5ff5\u7406\u89e3\u7684\u5f71\u54cd\u4e0d\u4e00\u81f4\uff0c\u9700\u8981\u7ed3\u6784\u5316\u6574\u5408\u4ee5\u57f9\u517b\u72ec\u7acb\u89e3\u51b3\u95ee\u9898\u7684\u80fd\u529b\u3002", "motivation": "\u968f\u7740ChatGPT\u7b49\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7f16\u7a0b\u8bfe\u7a0b\u4e2d\u7684\u5e94\u7528\u589e\u52a0\uff0c\u9700\u8981\u4e86\u89e3\u5176\u5bf9\u4ee3\u7801\u8d28\u91cf\u3001\u6982\u5ff5\u7406\u89e3\u3001\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u548c\u5b66\u751f\u611f\u77e5\u7684\u5f71\u54cd\uff0c\u4ee5\u5e73\u8861\u5de5\u5177\u4f7f\u7528\u4e0e\u5b66\u4e60\u6548\u679c\u3002", "method": "\u91c7\u7528\u5e73\u8861\u8bbe\u8ba1\u7684\u51c6\u5b9e\u9a8c\u7814\u7a76\uff0c\u5b66\u751f\u5728\u4e24\u4e2aC\u8bed\u8a00\u7f16\u7a0b\u4f5c\u4e1a\uff08\u51fd\u6570\u548c\u7ed3\u6784\u4f53\uff09\u4e2d\u4ea4\u66ff\u4f7f\u7528ChatGPT\u548c\u975eChatGPT\u6761\u4ef6\uff0c\u901a\u8fc7\u591a\u7ef4\u8bc4\u5206\u6807\u51c6\u3001\u6982\u5ff5\u540e\u6d4b\u8c03\u67e5\u548c\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u4f7f\u7528ChatGPT\u7684\u5b66\u751f\u5728\u4ee3\u7801\u8d28\u91cf\u8bc4\u5206\u4e0a\u663e\u8457\u66f4\u9ad8\uff0c\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u66f4\u77ed\uff1b\u6982\u5ff5\u7406\u89e3\u65b9\u9762\u7ed3\u679c\u4e0d\u4e00\u81f4\uff0c\u51fd\u6570\u4e3b\u9898\u7406\u89e3\u8f83\u4f4e\u4f46\u7ed3\u6784\u4f53\u4e3b\u9898\u7406\u89e3\u8f83\u9ad8\uff1b\u5b66\u751f\u5bf9ChatGPT\u4f53\u9a8c\u79ef\u6781\uff0c\u8ba4\u4e3a\u5bf9\u8c03\u8bd5\u548c\u7ec3\u4e60\u6709\u4ef7\u503c\uff0c\u4f46\u62c5\u5fc3\u51c6\u786e\u6027\u548c\u957f\u671f\u6280\u80fd\u53d1\u5c55\u3002", "conclusion": "ChatGPT\u80fd\u63d0\u5347\u65b0\u624b\u7a0b\u5e8f\u5458\u7684\u4ee3\u7801\u8d28\u91cf\u548c\u6548\u7387\uff0c\u4f46\u672a\u5fc5\u80fd\u4e00\u81f4\u6539\u5584\u6982\u5ff5\u7406\u89e3\uff0c\u5efa\u8bae\u901a\u8fc7\u7ed3\u6784\u5316\u6574\u5408\u548c\u8865\u5145\u6559\u5b66\u7b56\u7565\u6765\u57f9\u517b\u72ec\u7acb\u89e3\u51b3\u95ee\u9898\u7684\u80fd\u529b\u3002"}}
{"id": "2510.00492", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00492", "abs": "https://arxiv.org/abs/2510.00492", "authors": ["Dong Bok Lee", "Seanie Lee", "Sangwoo Park", "Minki Kang", "Jinheon Baek", "Dongki Kim", "Dominik Wagner", "Jiongdao Jin", "Heejun Lee", "Tobias Bocklet", "Jinyu Wang", "Jingjing Fu", "Sung Ju Hwang", "Jiang Bia", "Lei Song"], "title": "Rethinking Reward Models for Multi-Domain Test-Time Scaling", "comment": null, "summary": "The reliability of large language models (LLMs) during test-time scaling is\noften assessed with \\emph{external verifiers} or \\emph{reward models} that\ndistinguish correct reasoning from flawed logic. Prior work generally assumes\nthat process reward models (PRMs), which score every intermediate reasoning\nstep, outperform outcome reward models (ORMs) that assess only the final\nanswer. This view is based mainly on evidence from narrow, math-adjacent\ndomains. We present the first unified evaluation of four reward model variants,\ndiscriminative ORM and PRM (\\DisORM, \\DisPRM) and generative ORM and PRM\n(\\GenORM, \\GenPRM), across 14 diverse domains. Contrary to conventional wisdom,\nwe find that (i) \\DisORM performs on par with \\DisPRM, (ii) \\GenPRM is not\ncompetitive, and (iii) overall, \\GenORM is the most robust, yielding\nsignificant and consistent gains across every tested domain. We attribute this\nto PRM-style stepwise scoring, which inherits label noise from LLM\nauto-labeling and has difficulty evaluating long reasoning trajectories,\nincluding those involving self-correcting reasoning. Our theoretical analysis\nshows that step-wise aggregation compounds errors as reasoning length grows,\nand our empirical observations confirm this effect. These findings challenge\nthe prevailing assumption that fine-grained supervision is always better and\nsupport generative outcome verification for multi-domain deployment. We\npublicly release our code, datasets, and checkpoints at\n\\href{https://github.com/db-Lee/Multi-RM}{\\underline{\\small\\texttt{https://github.com/db-Lee/Multi-RM}}}\nto facilitate future research in multi-domain settings.", "AI": {"tldr": "\u672c\u7814\u7a76\u6311\u6218\u4e86\u4f20\u7edf\u89c2\u70b9\uff0c\u53d1\u73b0\u572814\u4e2a\u4e0d\u540c\u9886\u57df\u4e2d\uff0c\u751f\u6210\u5f0f\u7ed3\u679c\u5956\u52b1\u6a21\u578b(GenORM)\u6bd4\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b(PRM)\u8868\u73b0\u66f4\u7a33\u5065\uff0c\u800c\u5224\u522b\u5f0f\u7ed3\u679c\u5956\u52b1\u6a21\u578b(DisORM)\u4e0e\u5224\u522b\u5f0f\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b(DisPRM)\u8868\u73b0\u76f8\u5f53\u3002", "motivation": "\u4f20\u7edf\u89c2\u70b9\u8ba4\u4e3a\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b(PRM)\u4f18\u4e8e\u7ed3\u679c\u5956\u52b1\u6a21\u578b(ORM)\uff0c\u4f46\u8fd9\u79cd\u89c2\u70b9\u4e3b\u8981\u57fa\u4e8e\u6570\u5b66\u76f8\u5173\u9886\u57df\u7684\u8bc1\u636e\u3002\u672c\u7814\u7a76\u65e8\u5728\u5728\u591a\u6837\u5316\u9886\u57df\u4e2d\u7edf\u4e00\u8bc4\u4f30\u4e0d\u540c\u5956\u52b1\u6a21\u578b\u7684\u6027\u80fd\u3002", "method": "\u572814\u4e2a\u591a\u6837\u5316\u9886\u57df\u4e2d\u7edf\u4e00\u8bc4\u4f30\u4e86\u56db\u79cd\u5956\u52b1\u6a21\u578b\u53d8\u4f53\uff1a\u5224\u522b\u5f0fORM\u548cPRM(DisORM, DisPRM)\u4ee5\u53ca\u751f\u6210\u5f0fORM\u548cPRM(GenORM, GenPRM)\u3002", "result": "\u53d1\u73b0DisORM\u4e0eDisPRM\u8868\u73b0\u76f8\u5f53\uff0cGenPRM\u4e0d\u5177\u7ade\u4e89\u529b\uff0c\u800cGenORM\u5728\u6240\u6709\u6d4b\u8bd5\u9886\u57df\u4e2d\u90fd\u8868\u73b0\u51fa\u663e\u8457\u4e14\u4e00\u81f4\u7684\u63d0\u5347\uff0c\u662f\u6700\u7a33\u5065\u7684\u6a21\u578b\u3002", "conclusion": "\u7814\u7a76\u6311\u6218\u4e86\u7ec6\u7c92\u5ea6\u76d1\u7763\u603b\u662f\u66f4\u597d\u7684\u666e\u904d\u5047\u8bbe\uff0c\u652f\u6301\u5728\u591a\u9886\u57df\u90e8\u7f72\u4e2d\u4f7f\u7528\u751f\u6210\u5f0f\u7ed3\u679c\u9a8c\u8bc1\u65b9\u6cd5\u3002"}}
{"id": "2510.00957", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.00957", "abs": "https://arxiv.org/abs/2510.00957", "authors": ["Shiza Andleeb", "Teo Mendoza", "Lucas Cordova", "Gursimran Walia", "Jeffrey C. Carver"], "title": "Enhancing Software Testing Education: Understanding Where Students Struggle", "comment": "Accepted to SIGCITE'25", "summary": "Effective software testing is critical for producing reliable and secure\nsoftware, yet many computer science students struggle to master the\nfoundational concepts required to construct comprehensive test suites. While\nautomated feedback tools are widely used to support student learning, it\nremains unclear which testing concepts are most frequently misunderstood and\nhow these misunderstandings are reflected in students' test suite revisions.\nThis study examines the specific testing concepts that lead students to make\nineffective changes, those that fail to improve code coverage, during test\nsuite development. Leveraging an automated feedback tool in a senior-level\nsoftware testing course, we analyzed student submissions from two assignments\nto identify prevalent conceptual gaps and patterns of unproductive\nmodification. Our results reveal that decision coverage and exception handling\nare persistent challenges, and that students most often make superficial or\nmethod-level changes that do not enhance coverage. These findings provide\nactionable insights for educators, researchers, and tool designers. By\npinpointing the concepts that most often contribute to poor testing outcomes,\nwe can refine feedback systems, target instruction to address persistent\nmisconceptions, and more effectively support students in developing robust,\nmaintainable test suites.", "AI": {"tldr": "\u5206\u6790\u5b66\u751f\u5728\u8f6f\u4ef6\u6d4b\u8bd5\u8bfe\u7a0b\u4e2d\u5e38\u89c1\u7684\u6982\u5ff5\u8bef\u89e3\uff0c\u7279\u522b\u662f\u51b3\u7b56\u8986\u76d6\u7387\u548c\u5f02\u5e38\u5904\u7406\u65b9\u9762\u7684\u56f0\u96be\uff0c\u4ee5\u53ca\u5b66\u751f\u503e\u5411\u4e8e\u8fdb\u884c\u65e0\u6548\u7684\u8868\u9762\u4fee\u6539\u800c\u975e\u5b9e\u8d28\u6027\u6539\u8fdb\u6d4b\u8bd5\u8986\u76d6\u7387\u7684\u884c\u4e3a\u6a21\u5f0f\u3002", "motivation": "\u867d\u7136\u81ea\u52a8\u5316\u53cd\u9988\u5de5\u5177\u5e7f\u6cdb\u7528\u4e8e\u652f\u6301\u5b66\u751f\u5b66\u4e60\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u54ea\u4e9b\u6d4b\u8bd5\u6982\u5ff5\u6700\u5e38\u88ab\u8bef\u89e3\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u8bef\u89e3\u5982\u4f55\u53cd\u6620\u5728\u5b66\u751f\u7684\u6d4b\u8bd5\u5957\u4ef6\u4fee\u8ba2\u4e2d\u3002\u9700\u8981\u8bc6\u522b\u5bfc\u81f4\u5b66\u751f\u505a\u51fa\u65e0\u6548\u4fee\u6539\u7684\u5177\u4f53\u6d4b\u8bd5\u6982\u5ff5\u3002", "method": "\u5728\u9ad8\u7ea7\u8f6f\u4ef6\u6d4b\u8bd5\u8bfe\u7a0b\u4e2d\u4f7f\u7528\u81ea\u52a8\u5316\u53cd\u9988\u5de5\u5177\uff0c\u5206\u6790\u4e24\u4e2a\u4f5c\u4e1a\u7684\u5b66\u751f\u63d0\u4ea4\u5185\u5bb9\uff0c\u8bc6\u522b\u666e\u904d\u5b58\u5728\u7684\u6982\u5ff5\u5dee\u8ddd\u548c\u65e0\u6210\u6548\u4fee\u6539\u6a21\u5f0f\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u51b3\u7b56\u8986\u76d6\u7387\u548c\u5f02\u5e38\u5904\u7406\u662f\u6301\u7eed\u5b58\u5728\u7684\u6311\u6218\uff0c\u5b66\u751f\u6700\u5e38\u8fdb\u884c\u8868\u9762\u6216\u65b9\u6cd5\u7ea7\u522b\u7684\u4fee\u6539\uff0c\u8fd9\u4e9b\u4fee\u6539\u65e0\u6cd5\u63d0\u9ad8\u4ee3\u7801\u8986\u76d6\u7387\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u6559\u80b2\u8005\u3001\u7814\u7a76\u4eba\u5458\u548c\u5de5\u5177\u8bbe\u8ba1\u8005\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\uff0c\u901a\u8fc7\u7cbe\u786e\u5b9a\u4f4d\u6700\u5e38\u5bfc\u81f4\u6d4b\u8bd5\u7ed3\u679c\u5dee\u7684\u6982\u5ff5\uff0c\u53ef\u4ee5\u6539\u8fdb\u53cd\u9988\u7cfb\u7edf\uff0c\u9488\u5bf9\u6027\u5730\u89e3\u51b3\u6301\u7eed\u5b58\u5728\u7684\u8bef\u89e3\uff0c\u66f4\u6709\u6548\u5730\u652f\u6301\u5b66\u751f\u5f00\u53d1\u5065\u58ee\u3001\u53ef\u7ef4\u62a4\u7684\u6d4b\u8bd5\u5957\u4ef6\u3002"}}
{"id": "2510.00523", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.00523", "abs": "https://arxiv.org/abs/2510.00523", "authors": ["Wei-Yao Wang", "Kazuya Tateishi", "Qiyu Wu", "Shusuke Takahashi", "Yuki Mitsufuji"], "title": "VIRTUE: Visual-Interactive Text-Image Universal Embedder", "comment": "25 pages", "summary": "Multimodal representation learning models have demonstrated successful\noperation across complex tasks, and the integration of vision-language models\n(VLMs) has further enabled embedding models with instruction-following\ncapabilities. However, existing embedding models lack visual-interactive\ncapabilities to specify regions of interest from users (e.g., point, bounding\nbox, mask), which have been explored in generative models to broaden their\nhuman-interactive applicability. Equipping embedding models with visual\ninteractions not only would unlock new applications with localized grounding of\nuser intent, which remains unexplored, but also enable the models to learn\nentity-level information within images to complement their global\nrepresentations for conventional embedding tasks. In this paper, we propose a\nnovel Visual-InteRactive Text-Image Universal Embedder (VIRTUE) that extends\nthe capabilities of the segmentation model and the vision-language model to the\nrealm of representation learning. In VIRTUE, the segmentation model can process\nvisual prompts that pinpoint specific regions within an image, thereby enabling\nthe embedder to handle complex and ambiguous scenarios more precisely. To\nevaluate the visual-interaction ability of VIRTUE, we introduce a large-scale\nSegmentation-and-Scene Caption Retrieval (SCaR) benchmark comprising 1M samples\nthat aims to retrieve the text caption by jointly considering the entity with a\nspecific object and image scene. VIRTUE consistently achieves a\nstate-of-the-art performance with significant improvements across 36 universal\nMMEB (3.1%-8.5%) and five visual-interactive SCaR (15.2%-20.3%) tasks.", "AI": {"tldr": "\u63d0\u51faVIRTUE\u89c6\u89c9\u4ea4\u4e92\u6587\u672c\u56fe\u50cf\u901a\u7528\u5d4c\u5165\u5668\uff0c\u901a\u8fc7\u6574\u5408\u5206\u5272\u6a21\u578b\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u4f7f\u5d4c\u5165\u6a21\u578b\u80fd\u591f\u5904\u7406\u89c6\u89c9\u4ea4\u4e92\u63d0\u793a\uff08\u5982\u70b9\u3001\u8fb9\u754c\u6846\u3001\u63a9\u7801\uff09\uff0c\u572836\u4e2a\u901a\u7528MMEB\u4efb\u52a1\u548c5\u4e2a\u89c6\u89c9\u4ea4\u4e92SCaR\u4efb\u52a1\u4e0a\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5d4c\u5165\u6a21\u578b\u7f3a\u4e4f\u89c6\u89c9\u4ea4\u4e92\u80fd\u529b\u6765\u6307\u5b9a\u7528\u6237\u611f\u5174\u8da3\u533a\u57df\uff0c\u800c\u751f\u6210\u6a21\u578b\u5df2\u63a2\u7d22\u6b64\u7c7b\u4ea4\u4e92\u3002\u4e3a\u5d4c\u5165\u6a21\u578b\u6dfb\u52a0\u89c6\u89c9\u4ea4\u4e92\u80fd\u529b\u53ef\u89e3\u9501\u65b0\u7684\u5e94\u7528\u573a\u666f\uff0c\u5e76\u8ba9\u6a21\u578b\u5b66\u4e60\u56fe\u50cf\u4e2d\u7684\u5b9e\u4f53\u7ea7\u4fe1\u606f\u6765\u8865\u5145\u5168\u5c40\u8868\u793a\u3002", "method": "\u6269\u5c55\u5206\u5272\u6a21\u578b\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5230\u8868\u793a\u5b66\u4e60\u9886\u57df\uff0c\u5206\u5272\u6a21\u578b\u5904\u7406\u89c6\u89c9\u63d0\u793a\u4ee5\u7cbe\u786e\u5b9a\u4f4d\u56fe\u50cf\u7279\u5b9a\u533a\u57df\uff0c\u4f7f\u5d4c\u5165\u5668\u80fd\u66f4\u7cbe\u786e\u5904\u7406\u590d\u6742\u548c\u6a21\u7cca\u573a\u666f\u3002", "result": "\u572836\u4e2a\u901a\u7528MMEB\u4efb\u52a1\u4e0a\u63d0\u53473.1%-8.5%\uff0c\u57285\u4e2a\u89c6\u89c9\u4ea4\u4e92SCaR\u4efb\u52a1\u4e0a\u63d0\u534715.2%-20.3%\uff0c\u5747\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "VIRTUE\u6210\u529f\u5c06\u89c6\u89c9\u4ea4\u4e92\u80fd\u529b\u5f15\u5165\u5d4c\u5165\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u901a\u7528\u548c\u89c6\u89c9\u4ea4\u4e92\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u4e3a\u5d4c\u5165\u5b66\u4e60\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2510.00552", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.00552", "abs": "https://arxiv.org/abs/2510.00552", "authors": ["Leopold M\u00fcller", "Joshua Holstein", "Sarah Bause", "Gerhard Satzger", "Niklas K\u00fchl"], "title": "Data Quality Challenges in Retrieval-Augmented Generation", "comment": "Preprint version. Accepted for presentation at the International\n  Conference on Information Systems (ICIS 2025). Please cite the published\n  version when available", "summary": "Organizations increasingly adopt Retrieval-Augmented Generation (RAG) to\nenhance Large Language Models with enterprise-specific knowledge. However,\ncurrent data quality (DQ) frameworks have been primarily developed for static\ndatasets, and only inadequately address the dynamic, multi-stage nature of RAG\nsystems. This study aims to develop DQ dimensions for this new type of AI-based\nsystems. We conduct 16 semi-structured interviews with practitioners of leading\nIT service companies. Through a qualitative content analysis, we inductively\nderive 15 distinct DQ dimensions across the four processing stages of RAG\nsystems: data extraction, data transformation, prompt & search, and generation.\nOur findings reveal that (1) new dimensions have to be added to traditional DQ\nframeworks to also cover RAG contexts; (2) these new dimensions are\nconcentrated in early RAG steps, suggesting the need for front-loaded quality\nmanagement strategies, and (3) DQ issues transform and propagate through the\nRAG pipeline, necessitating a dynamic, step-aware approach to quality\nmanagement.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u9488\u5bf9RAG\u7cfb\u7edf\u7684\u6570\u636e\u8d28\u91cf\u7ef4\u5ea6\uff0c\u901a\u8fc7\u8bbf\u8c08IT\u670d\u52a1\u516c\u53f8\u4ece\u4e1a\u8005\uff0c\u8bc6\u522b\u51fa15\u4e2a\u8de8\u56db\u4e2a\u5904\u7406\u9636\u6bb5\u7684\u6570\u636e\u8d28\u91cf\u7ef4\u5ea6\uff0c\u53d1\u73b0\u9700\u8981\u6269\u5c55\u4f20\u7edfDQ\u6846\u67b6\u3001\u91c7\u7528\u524d\u7f6e\u8d28\u91cf\u7ba1\u7406\u7b56\u7565\u548c\u52a8\u6001\u8d28\u91cf\u7ba1\u7406\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u6570\u636e\u8d28\u91cf\u6846\u67b6\u4e3b\u8981\u9488\u5bf9\u9759\u6001\u6570\u636e\u96c6\uff0c\u65e0\u6cd5\u5145\u5206\u5e94\u5bf9RAG\u7cfb\u7edf\u52a8\u6001\u3001\u591a\u9636\u6bb5\u7684\u7279\u6027\uff0c\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u9488\u5bf9\u8fd9\u7c7bAI\u7cfb\u7edf\u7684\u6570\u636e\u8d28\u91cf\u7ef4\u5ea6\u3002", "method": "\u5bf916\u5bb6\u9886\u5148IT\u670d\u52a1\u516c\u53f8\u7684\u4ece\u4e1a\u8005\u8fdb\u884c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u901a\u8fc7\u5b9a\u6027\u5185\u5bb9\u5206\u6790\u5f52\u7eb3\u51faRAG\u7cfb\u7edf\u56db\u4e2a\u5904\u7406\u9636\u6bb5\u7684\u6570\u636e\u8d28\u91cf\u7ef4\u5ea6\u3002", "result": "\u8bc6\u522b\u51fa15\u4e2a\u4e0d\u540c\u7684\u6570\u636e\u8d28\u91cf\u7ef4\u5ea6\uff0c\u5206\u5e03\u5728\u6570\u636e\u63d0\u53d6\u3001\u6570\u636e\u8f6c\u6362\u3001\u63d0\u793a\u4e0e\u641c\u7d22\u3001\u751f\u6210\u56db\u4e2a\u9636\u6bb5\uff0c\u53d1\u73b0\u65b0\u7ef4\u5ea6\u4e3b\u8981\u96c6\u4e2d\u5728\u65e9\u671f\u9636\u6bb5\uff0c\u4e14\u8d28\u91cf\u95ee\u9898\u4f1a\u5728\u7ba1\u9053\u4e2d\u8f6c\u5316\u548c\u4f20\u64ad\u3002", "conclusion": "\u9700\u8981\u6269\u5c55\u4f20\u7edfDQ\u6846\u67b6\u4ee5\u6db5\u76d6RAG\u73af\u5883\uff0c\u91c7\u7528\u524d\u7f6e\u8d28\u91cf\u7ba1\u7406\u7b56\u7565\uff0c\u5e76\u5b9e\u65bd\u52a8\u6001\u3001\u9636\u6bb5\u611f\u77e5\u7684\u8d28\u91cf\u7ba1\u7406\u65b9\u6cd5\u3002"}}
{"id": "2510.01003", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.01003", "abs": "https://arxiv.org/abs/2510.01003", "authors": ["Boshi Wang", "Weijian Xu", "Yunsheng Li", "Mei Gao", "Yujia Xie", "Huan Sun", "Dongdong Chen"], "title": "Improving Code Localization with Repository Memory", "comment": "15 pages, 8 figures", "summary": "Code localization is a fundamental challenge in repository-level software\nengineering tasks such as bug fixing. While existing methods equip language\nagents with comprehensive tools/interfaces to fetch information from the\nrepository, they overlook the critical aspect of memory, where each instance is\ntypically handled from scratch assuming no prior repository knowledge. In\ncontrast, human developers naturally build long-term repository memory, such as\nthe functionality of key modules and associations between various bug types and\ntheir likely fix locations. In this work, we augment language agents with such\nmemory by leveraging a repository's commit history - a rich yet underutilized\nresource that chronicles the codebase's evolution. We introduce tools that\nallow the agent to retrieve from a non-parametric memory encompassing recent\nhistorical commits and linked issues, as well as functionality summaries of\nactively evolving parts of the codebase identified via commit patterns. We\ndemonstrate that augmenting such a memory can significantly improve LocAgent, a\nstate-of-the-art localization framework, on both SWE-bench-verified and the\nmore recent SWE-bench-live benchmarks. Our research contributes towards\ndeveloping agents that can accumulate and leverage past experience for\nlong-horizon tasks, more closely emulating the expertise of human developers.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5229\u7528\u4ee3\u7801\u4ed3\u5e93\u7684\u63d0\u4ea4\u5386\u53f2\uff0c\u4e3a\u8bed\u8a00\u4ee3\u7406\u6dfb\u52a0\u957f\u671f\u8bb0\u5fc6\u80fd\u529b\uff0c\u4ee5\u6539\u8fdb\u4ee3\u7801\u5b9a\u4f4d\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u4ee3\u7801\u4ed3\u5e93\u4efb\u52a1\u65f6\u901a\u5e38\u4ece\u96f6\u5f00\u59cb\uff0c\u5ffd\u7565\u4e86\u4eba\u7c7b\u5f00\u53d1\u8005\u4f1a\u79ef\u7d2f\u957f\u671f\u4ed3\u5e93\u8bb0\u5fc6\u7684\u5173\u952e\u65b9\u9762\uff0c\u5982\u5173\u952e\u6a21\u5757\u529f\u80fd\u548cbug\u7c7b\u578b\u4e0e\u4fee\u590d\u4f4d\u7f6e\u7684\u5173\u8054\u3002", "method": "\u5f15\u5165\u5de5\u5177\u4f7f\u4ee3\u7406\u80fd\u591f\u4ece\u975e\u53c2\u6570\u5316\u8bb0\u5fc6\u4e2d\u68c0\u7d22\u4fe1\u606f\uff0c\u5305\u62ec\u8fd1\u671f\u5386\u53f2\u63d0\u4ea4\u3001\u5173\u8054\u95ee\u9898\u4ee5\u53ca\u901a\u8fc7\u63d0\u4ea4\u6a21\u5f0f\u8bc6\u522b\u7684\u6d3b\u8dc3\u4ee3\u7801\u90e8\u5206\u7684\u529f\u80fd\u6458\u8981\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6dfb\u52a0\u8fd9\u79cd\u8bb0\u5fc6\u80fd\u529b\u80fd\u663e\u8457\u63d0\u5347\u6700\u5148\u8fdb\u7684\u5b9a\u4f4d\u6846\u67b6LocAgent\u5728SWE-bench-verified\u548cSWE-bench-live\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u6027\u80fd\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u6709\u52a9\u4e8e\u5f00\u53d1\u80fd\u591f\u79ef\u7d2f\u548c\u5229\u7528\u8fc7\u5f80\u7ecf\u9a8c\u5904\u7406\u957f\u671f\u4efb\u52a1\u7684\u4ee3\u7406\uff0c\u66f4\u63a5\u8fd1\u6a21\u62df\u4eba\u7c7b\u5f00\u53d1\u8005\u7684\u4e13\u4e1a\u77e5\u8bc6\u3002"}}
{"id": "2510.00565", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00565", "abs": "https://arxiv.org/abs/2510.00565", "authors": ["Shojiro Yamabe", "Jun Sakuma"], "title": "Toward Safer Diffusion Language Models: Discovery and Mitigation of Priming Vulnerability", "comment": null, "summary": "Diffusion language models (DLMs) generate tokens in parallel through\niterative denoising, which can reduce latency and enable bidirectional\nconditioning. However, the safety risks posed by jailbreak attacks that exploit\nthis inference mechanism are not well understood. In this paper, we reveal that\nDLMs have a critical vulnerability stemming from their iterative denoising\nprocess and propose a countermeasure. Specifically, our investigation shows\nthat if an affirmative token for a harmful query appears at an intermediate\nstep, subsequent denoising can be steered toward a harmful response even in\naligned models. As a result, simply injecting such affirmative tokens can\nreadily bypass the safety guardrails. Furthermore, we demonstrate that the\nvulnerability allows existing optimization-based jailbreak attacks to succeed\non DLMs. Building on this analysis, we propose a novel safety alignment method\ntailored to DLMs that trains models to generate safe responses from\ncontaminated intermediate states that contain affirmative tokens. Our\nexperiments indicate that the proposed method significantly mitigates the\nvulnerability with minimal impact on task performance. Furthermore, our method\nimproves robustness against conventional jailbreak attacks. Our work\nunderscores the need for DLM-specific safety research.", "AI": {"tldr": "\u6269\u6563\u8bed\u8a00\u6a21\u578b(DLMs)\u5b58\u5728\u7531\u8fed\u4ee3\u53bb\u566a\u8fc7\u7a0b\u5f15\u53d1\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u653b\u51fb\u8005\u53ef\u901a\u8fc7\u6ce8\u5165\u80af\u5b9a\u6027\u4ee4\u724c\u7ed5\u8fc7\u5b89\u5168\u9632\u62a4\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9DLMs\u7684\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\uff0c\u80fd\u6709\u6548\u7f13\u89e3\u6b64\u6f0f\u6d1e\u3002", "motivation": "DLMs\u901a\u8fc7\u5e76\u884c\u8fed\u4ee3\u53bb\u566a\u751f\u6210\u4ee4\u724c\uff0c\u8fd9\u79cd\u63a8\u7406\u673a\u5236\u53ef\u80fd\u5e26\u6765\u65b0\u7684\u5b89\u5168\u98ce\u9669\uff0c\u7279\u522b\u662f\u8d8a\u72f1\u653b\u51fb\u3002\u76ee\u524d\u5bf9\u8fd9\u79cd\u57fa\u4e8e\u63a8\u7406\u673a\u5236\u7684\u5b89\u5168\u98ce\u9669\u7406\u89e3\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9DLMs\u7684\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\uff0c\u8bad\u7ec3\u6a21\u578b\u4ece\u5305\u542b\u80af\u5b9a\u6027\u4ee4\u724c\u7684\u6c61\u67d3\u4e2d\u95f4\u72b6\u6001\u751f\u6210\u5b89\u5168\u54cd\u5e94\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u663e\u8457\u7f13\u89e3\u6f0f\u6d1e\uff0c\u5bf9\u4efb\u52a1\u6027\u80fd\u5f71\u54cd\u6700\u5c0f\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u5bf9\u4f20\u7edf\u8d8a\u72f1\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "DLMs\u5177\u6709\u7279\u5b9a\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u8981\u4e13\u95e8\u7684\u5b89\u5168\u7814\u7a76\u3002\u63d0\u51fa\u7684\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\u80fd\u6709\u6548\u4fdd\u62a4DLMs\u514d\u53d7\u6b64\u7c7b\u653b\u51fb\u3002"}}
{"id": "2510.01024", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.01024", "abs": "https://arxiv.org/abs/2510.01024", "authors": ["Elvis J\u00fanior", "Alan Valejo", "Jorge Valverde-Rebaza", "V\u00e2nia de Oliveira Neves"], "title": "GenIA-E2ETest: A Generative AI-Based Approach for End-to-End Test Automation", "comment": "Preprint of a paper published at the 39th Brazilian Symposium on\n  Software Engineering (SBES 2025). Please cite the published version:\n  https://sol.sbc.org.br/index.php/sbes/article/view/37006", "summary": "Software testing is essential to ensure system quality, but it remains\ntime-consuming and error-prone when performed manually. Although recent\nadvances in Large Language Models (LLMs) have enabled automated test\ngeneration, most existing solutions focus on unit testing and do not address\nthe challenges of end-to-end (E2E) testing, which validates complete\napplication workflows from user input to final system response. This paper\nintroduces GenIA-E2ETest, which leverages generative AI to generate executable\nE2E test scripts from natural language descriptions automatically. We evaluated\nthe approach on two web applications, assessing completeness, correctness,\nadaptation effort, and robustness. Results were encouraging: the scripts\nachieved an average of 77% for both element metrics, 82% for precision of\nexecution, 85% for execution recall, required minimal manual adjustments\n(average manual modification rate of 10%), and showed consistent performance in\ntypical web scenarios. Although some sensitivity to context-dependent\nnavigation and dynamic content was observed, the findings suggest that\nGenIA-E2ETest is a practical and effective solution to accelerate E2E test\nautomation from natural language, reducing manual effort and broadening access\nto automated testing.", "AI": {"tldr": "GenIA-E2ETest\u5229\u7528\u751f\u6210\u5f0fAI\u4ece\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u81ea\u52a8\u751f\u6210\u53ef\u6267\u884c\u7684\u7aef\u5230\u7aef\u6d4b\u8bd5\u811a\u672c\uff0c\u5728Web\u5e94\u7528\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u624b\u52a8\u6d4b\u8bd5\u5de5\u4f5c\u91cf\u3002", "motivation": "\u4f20\u7edf\u8f6f\u4ef6\u6d4b\u8bd5\u8017\u65f6\u4e14\u6613\u9519\uff0c\u73b0\u6709\u57fa\u4e8eLLM\u7684\u6d4b\u8bd5\u751f\u6210\u4e3b\u8981\u5173\u6ce8\u5355\u5143\u6d4b\u8bd5\uff0c\u7f3a\u4e4f\u9488\u5bf9\u7aef\u5230\u7aef\u6d4b\u8bd5\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9700\u8981\u9a8c\u8bc1\u5b8c\u6574\u5e94\u7528\u5de5\u4f5c\u6d41\u7a0b\u3002", "method": "\u63d0\u51faGenIA-E2ETest\u65b9\u6cd5\uff0c\u5229\u7528\u751f\u6210\u5f0fAI\u4ece\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u81ea\u52a8\u751f\u6210\u53ef\u6267\u884c\u7684\u7aef\u5230\u7aef\u6d4b\u8bd5\u811a\u672c\u3002", "result": "\u5728\u4e24\u4e2aWeb\u5e94\u7528\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff1a\u5143\u7d20\u6307\u6807\u5e73\u574777%\uff0c\u6267\u884c\u7cbe\u5ea682%\uff0c\u6267\u884c\u53ec\u56de\u738785%\uff0c\u624b\u52a8\u4fee\u6539\u7387\u4ec510%\uff0c\u5728\u5178\u578bWeb\u573a\u666f\u4e2d\u8868\u73b0\u7a33\u5b9a\u3002", "conclusion": "GenIA-E2ETest\u662f\u4ece\u81ea\u7136\u8bed\u8a00\u52a0\u901f\u7aef\u5230\u7aef\u6d4b\u8bd5\u81ea\u52a8\u5316\u7684\u5b9e\u7528\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5c3d\u7ba1\u5bf9\u4e0a\u4e0b\u6587\u76f8\u5173\u5bfc\u822a\u548c\u52a8\u6001\u5185\u5bb9\u6709\u4e9b\u654f\u611f\uff0c\u4f46\u80fd\u663e\u8457\u51cf\u5c11\u624b\u52a8\u5de5\u4f5c\u91cf\u5e76\u6269\u5927\u81ea\u52a8\u5316\u6d4b\u8bd5\u7684\u53ef\u53ca\u6027\u3002"}}
{"id": "2510.00615", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00615", "abs": "https://arxiv.org/abs/2510.00615", "authors": ["Minki Kang", "Wei-Ning Chen", "Dongge Han", "Huseyin A. Inan", "Lukas Wutschitz", "Yanzhi Chen", "Robert Sim", "Saravan Rajmohan"], "title": "ACON: Optimizing Context Compression for Long-horizon LLM Agents", "comment": "Preprint", "summary": "Large language models (LLMs) are increasingly deployed as agents in dynamic,\nreal-world environments, where success requires both reasoning and effective\ntool use. A central challenge for agentic tasks is the growing context length,\nas agents must accumulate long histories of actions and observations. This\nexpansion raises costs and reduces efficiency in long-horizon tasks, yet prior\nwork on context compression has mostly focused on single-step tasks or narrow\napplications. We introduce Agent Context Optimization (ACON), a unified\nframework that optimally compresses both environment observations and\ninteraction histories into concise yet informative condensations. ACON\nleverages compression guideline optimization in natural language space: given\npaired trajectories where full context succeeds but compressed context fails,\ncapable LLMs analyze the causes of failure, and the compression guideline is\nupdated accordingly. Furthermore, we propose distilling the optimized LLM\ncompressor into smaller models to reduce the overhead of the additional module.\nExperiments on AppWorld, OfficeBench, and Multi-objective QA show that ACON\nreduces memory usage by 26-54% (peak tokens) while largely preserving task\nperformance, preserves over 95% of accuracy when distilled into smaller\ncompressors, and enhances smaller LMs as long-horizon agents with up to 46%\nperformance improvement.", "AI": {"tldr": "ACON\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316\u538b\u7f29\u73af\u5883\u89c2\u5bdf\u548c\u4ea4\u4e92\u5386\u53f2\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u7a7a\u95f4\u4e2d\u7684\u538b\u7f29\u6307\u5357\u4f18\u5316\u6765\u51cf\u5c11\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u968f\u7740LLM\u4f5c\u4e3a\u667a\u80fd\u4f53\u5728\u52a8\u6001\u73af\u5883\u4e2d\u90e8\u7f72\uff0c\u4e0a\u4e0b\u6587\u957f\u5ea6\u589e\u957f\u5bfc\u81f4\u6210\u672c\u589e\u52a0\u548c\u6548\u7387\u964d\u4f4e\uff0c\u800c\u73b0\u6709\u7684\u4e0a\u4e0b\u6587\u538b\u7f29\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5355\u6b65\u4efb\u52a1\u6216\u72ed\u7a84\u5e94\u7528\u3002", "method": "ACON\u5229\u7528\u538b\u7f29\u6307\u5357\u4f18\u5316\uff1a\u5f53\u5b8c\u6574\u4e0a\u4e0b\u6587\u6210\u529f\u4f46\u538b\u7f29\u4e0a\u4e0b\u6587\u5931\u8d25\u65f6\uff0cLLM\u5206\u6790\u5931\u8d25\u539f\u56e0\u5e76\u76f8\u5e94\u66f4\u65b0\u538b\u7f29\u6307\u5357\uff0c\u540c\u65f6\u5c06\u4f18\u5316\u7684LLM\u538b\u7f29\u5668\u84b8\u998f\u5230\u66f4\u5c0f\u7684\u6a21\u578b\u4e2d\u3002", "result": "\u5728AppWorld\u3001OfficeBench\u548cMulti-objective QA\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cACON\u51cf\u5c11\u5185\u5b58\u4f7f\u752826-54%\uff08\u5cf0\u503c\u4ee4\u724c\uff09\uff0c\u540c\u65f6\u57fa\u672c\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\uff0c\u84b8\u998f\u5230\u66f4\u5c0f\u538b\u7f29\u5668\u65f6\u4fdd\u630195%\u4ee5\u4e0a\u51c6\u786e\u7387\uff0c\u5e76\u5c06\u8f83\u5c0fLM\u4f5c\u4e3a\u957f\u89c6\u91ce\u667a\u80fd\u4f53\u7684\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe46%\u3002", "conclusion": "ACON\u6709\u6548\u89e3\u51b3\u4e86\u667a\u80fd\u4f53\u4efb\u52a1\u4e2d\u4e0a\u4e0b\u6587\u957f\u5ea6\u589e\u957f\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u4f18\u5316\u538b\u7f29\u663e\u8457\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\u5e76\u4fdd\u6301\u6027\u80fd\uff0c\u540c\u65f6\u901a\u8fc7\u84b8\u998f\u6280\u672f\u5b9e\u73b0\u9ad8\u6548\u90e8\u7f72\u3002"}}
{"id": "2510.01077", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.01077", "abs": "https://arxiv.org/abs/2510.01077", "authors": ["Daniele Bifolco", "Guido Annicchiarico", "Pierluigi Barbiero", "Massimiliano Di Penta", "Fiorella Zampetti"], "title": "CodeGenLink: A Tool to Find the Likely Origin and License of Automatically Generated Code", "comment": "Proceedings of the 40th IEEE/ACM International Conference on\n  Automated Software Engineering (ASE 2025), November 16-20 2025, Seoul, South\n  Korea", "summary": "Large Language Models (LLMs) are widely used in software development tasks\nnowadays. Unlike reusing code taken from the Web, for LLMs' generated code,\ndevelopers are concerned about its lack of trustworthiness and possible\ncopyright or licensing violations, due to the lack of code provenance\ninformation. This paper proposes CodeGenLink, a GitHub CoPilot extension for\nVisual Studio Code aimed at (i) suggesting links containing code very similar\nto automatically generated code, and (ii) whenever possible, indicating the\nlicense of the likely origin of the code. CodeGenLink retrieves candidate links\nby combining LLMs with their web search features and then performs similarity\nanalysis between the generated and retrieved code. Preliminary results show\nthat CodeGenLink effectively filters unrelated links via similarity analysis\nand provides licensing information when available. Tool URL:\nhttps://github.com/danielebifolco/CodeGenLink Tool Video:\nhttps://youtu.be/M6nqjBf9_pw", "AI": {"tldr": "CodeGenLink\u662f\u4e00\u4e2aGitHub CoPilot\u6269\u5c55\uff0c\u901a\u8fc7\u7ed3\u5408LLM\u548c\u7f51\u7edc\u641c\u7d22\u6765\u68c0\u7d22\u4e0eAI\u751f\u6210\u4ee3\u7801\u76f8\u4f3c\u7684\u4ee3\u7801\u94fe\u63a5\uff0c\u5e76\u63d0\u4f9b\u53ef\u80fd\u7684\u4ee3\u7801\u6765\u6e90\u8bb8\u53ef\u8bc1\u4fe1\u606f\u3002", "motivation": "\u5f00\u53d1\u4eba\u5458\u5bf9LLM\u751f\u6210\u4ee3\u7801\u7f3a\u4e4f\u4fe1\u4efb\uff0c\u62c5\u5fc3\u7248\u6743\u548c\u8bb8\u53ef\u8bc1\u8fdd\u89c4\u95ee\u9898\uff0c\u56e0\u4e3a\u7f3a\u5c11\u4ee3\u7801\u6765\u6e90\u4fe1\u606f\u3002", "method": "\u7ed3\u5408LLM\u7684\u7f51\u7edc\u641c\u7d22\u529f\u80fd\u68c0\u7d22\u5019\u9009\u94fe\u63a5\uff0c\u7136\u540e\u5bf9\u751f\u6210\u4ee3\u7801\u548c\u68c0\u7d22\u4ee3\u7801\u8fdb\u884c\u76f8\u4f3c\u6027\u5206\u6790\u3002", "result": "\u521d\u6b65\u7ed3\u679c\u663e\u793aCodeGenLink\u80fd\u6709\u6548\u901a\u8fc7\u76f8\u4f3c\u6027\u5206\u6790\u8fc7\u6ee4\u65e0\u5173\u94fe\u63a5\uff0c\u5e76\u5728\u53ef\u7528\u65f6\u63d0\u4f9b\u8bb8\u53ef\u8bc1\u4fe1\u606f\u3002", "conclusion": "CodeGenLink\u4e3a\u89e3\u51b3LLM\u751f\u6210\u4ee3\u7801\u7684\u53ef\u4fe1\u5ea6\u548c\u7248\u6743\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2510.00620", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00620", "abs": "https://arxiv.org/abs/2510.00620", "authors": ["Rosni Vasu", "Peter Jansen", "Pao Siangliulue", "Cristina Sarasua", "Abraham Bernstein", "Peter Clark", "Bhavana Dalvi Mishra"], "title": "HARPA: A Testability-Driven, Literature-Grounded Framework for Research Ideation", "comment": "10 pages (main), 65 pages total", "summary": "While there has been a surge of interest in automated scientific discovery\n(ASD), especially with the emergence of LLMs, it remains challenging for tools\nto generate hypotheses that are both testable and grounded in the scientific\nliterature. Additionally, existing ideation tools are not adaptive to prior\nexperimental outcomes. We developed HARPA to address these challenges by\nincorporating the ideation workflow inspired by human researchers. HARPA first\nidentifies emerging research trends through literature mining, then explores\nhypothesis design spaces, and finally converges on precise, testable hypotheses\nby pinpointing research gaps and justifying design choices. Our evaluations\nshow that HARPA-generated hypothesis-driven research proposals perform\ncomparably to a strong baseline AI-researcher across most qualitative\ndimensions (e.g., specificity, novelty, overall quality), but achieve\nsignificant gains in feasibility(+0.78, p$<0.05$, bootstrap) and groundedness\n(+0.85, p$<0.01$, bootstrap) on a 10-point Likert scale. When tested with the\nASD agent (CodeScientist), HARPA produced more successful executions (20 vs. 11\nout of 40) and fewer failures (16 vs. 21 out of 40), showing that expert\nfeasibility judgments track with actual execution success. Furthermore, to\nsimulate how researchers continuously refine their understanding of what\nhypotheses are both testable and potentially interesting from experience, HARPA\nlearns a reward model that scores new hypotheses based on prior experimental\noutcomes, achieving approx. a 28\\% absolute gain over HARPA's untrained\nbaseline scorer. Together, these methods represent a step forward in the field\nof AI-driven scientific discovery.", "AI": {"tldr": "HARPA\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u79d1\u5b66\u53d1\u73b0\u5de5\u5177\uff0c\u901a\u8fc7\u6587\u732e\u6316\u6398\u8bc6\u522b\u7814\u7a76\u8d8b\u52bf\u3001\u63a2\u7d22\u5047\u8bbe\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u5e76\u57fa\u4e8e\u5b9e\u9a8c\u7ed3\u679c\u5b66\u4e60\u5956\u52b1\u6a21\u578b\uff0c\u751f\u6210\u53ef\u6d4b\u8bd5\u4e14\u57fa\u4e8e\u6587\u732e\u7684\u5047\u8bbe\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u81ea\u52a8\u5316\u79d1\u5b66\u53d1\u73b0\u5de5\u5177\u96be\u4ee5\u751f\u6210\u65e2\u53ef\u6d4b\u8bd5\u53c8\u57fa\u4e8e\u79d1\u5b66\u6587\u732e\u7684\u5047\u8bbe\uff0c\u4e14\u65e0\u6cd5\u6839\u636e\u5148\u524d\u5b9e\u9a8c\u7ed3\u679c\u8fdb\u884c\u8c03\u6574\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u53d7\u4eba\u7c7b\u7814\u7a76\u4eba\u5458\u542f\u53d1\u7684\u6784\u601d\u6d41\u7a0b\uff1a\u6587\u732e\u6316\u6398\u8bc6\u522b\u7814\u7a76\u8d8b\u52bf\u3001\u63a2\u7d22\u5047\u8bbe\u8bbe\u8ba1\u7a7a\u95f4\u3001\u901a\u8fc7\u5b9a\u4f4d\u7814\u7a76\u7a7a\u767d\u548c\u8bba\u8bc1\u8bbe\u8ba1\u9009\u62e9\u6765\u6536\u655b\u5230\u7cbe\u786e\u53ef\u6d4b\u8bd5\u7684\u5047\u8bbe\uff0c\u5e76\u5b66\u4e60\u57fa\u4e8e\u5148\u524d\u5b9e\u9a8c\u7ed3\u679c\u7684\u5956\u52b1\u6a21\u578b\u3002", "result": "HARPA\u751f\u6210\u7684\u7814\u7a76\u63d0\u6848\u5728\u53ef\u884c\u6027(+0.78)\u548c\u57fa\u7840\u6027(+0.85)\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\uff0c\u4e0eASD\u4ee3\u7406(CodeScientist)\u6d4b\u8bd5\u65f6\u83b7\u5f97\u66f4\u591a\u6210\u529f\u6267\u884c(20 vs 11)\u548c\u66f4\u5c11\u5931\u8d25(16 vs 21)\uff0c\u5956\u52b1\u6a21\u578b\u6bd4\u672a\u8bad\u7ec3\u57fa\u7ebf\u63d0\u9ad8\u7ea628%\u3002", "conclusion": "HARPA\u4ee3\u8868\u4e86AI\u9a71\u52a8\u79d1\u5b66\u53d1\u73b0\u9886\u57df\u7684\u91cd\u8981\u8fdb\u5c55\uff0c\u80fd\u591f\u751f\u6210\u66f4\u53ef\u884c\u3001\u66f4\u57fa\u4e8e\u6587\u732e\u7684\u5047\u8bbe\uff0c\u5e76\u901a\u8fc7\u5b66\u4e60\u5b9e\u9a8c\u53cd\u9988\u6301\u7eed\u6539\u8fdb\u5047\u8bbe\u8d28\u91cf\u3002"}}
{"id": "2510.01096", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.01096", "abs": "https://arxiv.org/abs/2510.01096", "authors": ["Nathan Wintersgill", "Trevor Stalnaker", "Daniel Otten", "Laura A. Heymann", "Oscar Chaparro", "Massimiliano Di Penta", "Daniel M. German", "Denys Poshyvanyk"], "title": "Developers' Perspectives on Software Licensing: Current Practices, Challenges, and Tools", "comment": null, "summary": "Most modern software products incorporate open-source components, requiring\ndevelopment teams to maintain compliance with each component's licenses.\nNoncompliance can lead to significant financial, legal, and reputational\nrepercussions. While some organizations may seek advice from legal\npractitioners to assist with licensing tasks, developers still play a key role\nin such a process. To this end, it is essential to understand how developers\napproach license compliance tasks, the challenges they encounter, and the tools\nthat they use. This work studies these aspects of software licensing practices\nthrough a study - conducted by a joint team of software engineering and legal\nresearchers - consisting of a survey with 58 software developers and seven\nfollow-up interviews. The study resulted in 15 key findings regarding the\ncurrent state of practice. We discuss the implications of our findings and\noffer directions for future research as well as actionable recommendations for\nlicensing tools.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u8c03\u67e5\u548c\u8bbf\u8c08\u5206\u6790\u4e86\u5f00\u53d1\u8005\u5904\u7406\u5f00\u6e90\u8bb8\u53ef\u8bc1\u5408\u89c4\u7684\u5b9e\u8df5\u3001\u6311\u6218\u548c\u5de5\u5177\u4f7f\u7528\u60c5\u51b5\uff0c\u63d0\u51fa\u4e8615\u4e2a\u5173\u952e\u53d1\u73b0\u548c\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u5f00\u6e90\u7ec4\u4ef6\u5728\u73b0\u4ee3\u8f6f\u4ef6\u4e2d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u8bb8\u53ef\u8bc1\u4e0d\u5408\u89c4\u4f1a\u5e26\u6765\u8d22\u52a1\u3001\u6cd5\u5f8b\u548c\u58f0\u8a89\u98ce\u9669\u3002\u5f00\u53d1\u8005\u5728\u6b64\u8fc7\u7a0b\u4e2d\u626e\u6f14\u5173\u952e\u89d2\u8272\uff0c\u9700\u8981\u4e86\u89e3\u4ed6\u4eec\u7684\u5b9e\u8df5\u65b9\u6cd5\u548c\u9762\u4e34\u7684\u6311\u6218\u3002", "method": "\u7531\u8f6f\u4ef6\u5de5\u7a0b\u548c\u6cd5\u5f8b\u7814\u7a76\u4eba\u5458\u7ec4\u6210\u7684\u8054\u5408\u56e2\u961f\uff0c\u5bf958\u540d\u8f6f\u4ef6\u5f00\u53d1\u8005\u8fdb\u884c\u95ee\u5377\u8c03\u67e5\uff0c\u5e76\u8fdb\u884c7\u6b21\u540e\u7eed\u8bbf\u8c08\u3002", "result": "\u7814\u7a76\u5f97\u51fa\u4e8615\u4e2a\u5173\u4e8e\u5f53\u524d\u5b9e\u8df5\u72b6\u6001\u7684\u5173\u952e\u53d1\u73b0\uff0c\u63ed\u793a\u4e86\u5f00\u53d1\u8005\u5728\u8bb8\u53ef\u8bc1\u5408\u89c4\u65b9\u9762\u7684\u73b0\u72b6\u548c\u95ee\u9898\u3002", "conclusion": "\u7814\u7a76\u8ba8\u8bba\u4e86\u53d1\u73b0\u7684\u5f71\u54cd\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\uff0c\u5e76\u4e3a\u8bb8\u53ef\u8bc1\u5de5\u5177\u63d0\u51fa\u4e86\u53ef\u884c\u7684\u6539\u8fdb\u5efa\u8bae\u3002"}}
{"id": "2510.00625", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00625", "abs": "https://arxiv.org/abs/2510.00625", "authors": ["Wei Liu", "Haomei Xu", "Bingqing Liu", "Zhiying Deng", "Haozhao Wang", "Jun Wang", "Ruixuan Li", "Yee Whye Teh", "Wee Sun Lee"], "title": "Is Model Editing Built on Sand? Revealing Its Illusory Success and Fragile Foundation", "comment": "This is a work in progress. Comments and suggestions are welcome", "summary": "Large language models (LLMs) inevitably encode outdated or incorrect\nknowledge. Updating, deleting, and forgetting such knowledge is important for\nalignment, safety, and other issues. To address this issue, model editing has\nemerged as a promising paradigm: by precisely editing a small subset of\nparameters such that a specific fact is updated while preserving other\nknowledge. Despite its great success reported in previous papers, we find the\napparent reliability of editing rests on a fragile foundation and the current\nliterature is largely driven by illusory success. The fundamental goal of\nsteering the model's output toward a target with minimal modification would\nencourage exploiting hidden shortcuts, rather than utilizing real semantics.\nThis problem directly challenges the feasibility of the current model editing\nliterature at its very foundation, as shortcuts are inherently at odds with\nrobust knowledge integration. Coincidentally, this issue has long been obscured\nby evaluation frameworks that lack the design of negative examples. To uncover\nit, we systematically develop a suite of new evaluation methods. Strikingly, we\nfind that state-of-the-art approaches collapse even under the simplest negation\nqueries. Our empirical evidence shows that editing is likely to be based on\nshortcuts rather than full semantics, calling for an urgent reconsideration of\nthe very basis of model editing before further advancements can be meaningfully\npursued.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6307\u51fa\u5f53\u524d\u6a21\u578b\u7f16\u8f91\u65b9\u6cd5\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\uff0c\u8868\u9762\u4e0a\u7684\u6210\u529f\u5b9e\u9645\u4e0a\u662f\u57fa\u4e8e\u5229\u7528\u9690\u85cf\u6377\u5f84\u800c\u975e\u771f\u5b9e\u8bed\u4e49\uff0c\u5bfc\u81f4\u5728\u5426\u5b9a\u67e5\u8be2\u7b49\u7b80\u5355\u6d4b\u8bd5\u4e0b\u5c31\u4f1a\u5931\u6548\u3002", "motivation": "\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u7f16\u8f91\u6587\u732e\u5b58\u5728\u6839\u672c\u6027\u95ee\u9898\uff0c\u7f16\u8f91\u7684\u53ef\u9760\u6027\u5efa\u7acb\u5728\u8106\u5f31\u57fa\u7840\u4e0a\uff0c\u9700\u8981\u63ed\u793a\u8fd9\u79cd\u865a\u5e7b\u6210\u529f\u5e76\u91cd\u65b0\u8bc4\u4f30\u6a21\u578b\u7f16\u8f91\u7684\u57fa\u7840\u3002", "method": "\u7cfb\u7edf\u5f00\u53d1\u4e86\u4e00\u5957\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u7279\u522b\u8bbe\u8ba1\u4e86\u5426\u5b9a\u67e5\u8be2\u7b49\u8d1f\u4f8b\u6d4b\u8bd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u6a21\u578b\u7f16\u8f91\u662f\u5426\u771f\u6b63\u57fa\u4e8e\u8bed\u4e49\u7406\u89e3\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6700\u5148\u8fdb\u7684\u6a21\u578b\u7f16\u8f91\u65b9\u6cd5\u5728\u7b80\u5355\u5426\u5b9a\u67e5\u8be2\u4e0b\u5c31\u4f1a\u5d29\u6e83\uff0c\u8868\u660e\u7f16\u8f91\u5f88\u53ef\u80fd\u57fa\u4e8e\u6377\u5f84\u800c\u975e\u5b8c\u6574\u8bed\u4e49\u3002", "conclusion": "\u6a21\u578b\u7f16\u8f91\u5f53\u524d\u7684\u57fa\u7840\u5b58\u5728\u4e25\u91cd\u95ee\u9898\uff0c\u9700\u8981\u5728\u8fdb\u4e00\u6b65\u63a8\u8fdb\u524d\u91cd\u65b0\u8003\u8651\u5176\u6839\u672c\u57fa\u7840\uff0c\u56e0\u4e3a\u6377\u5f84\u4e0e\u7a33\u5065\u7684\u77e5\u8bc6\u6574\u5408\u672c\u8d28\u4e0a\u662f\u77db\u76fe\u7684\u3002"}}
{"id": "2510.01182", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.01182", "abs": "https://arxiv.org/abs/2510.01182", "authors": ["Shuqing Li", "Chenran Zhang", "Binchang Li", "Cuiyun Gao", "Michael R. Lyu"], "title": "When Shared Worlds Break: Demystifying Defects in Multi-User Extended Reality Software Systems", "comment": null, "summary": "Multi-user Extended Reality (XR) systems enable transformative shared\nexperiences but introduce unique software defects that compromise user\nexperience. Understanding software defects in multi-user XR systems is crucial\nfor enhancing system reliability, yet remains underexplored. To fill the gap,\nthis paper presents the first large-scale empirical study of multi-user XR\ndefects, analyzing 2,649 real-world bug reports from diverse sources, including\ndeveloper forums, GitHub repositories, and app reviews on mainstream XR app\nstores. Through rigorous qualitative analysis using iterative open coding, we\ndevelop a comprehensive taxonomy that classifies multi-user XR bugs along three\ndimensions: Symptom Manifestation, Root Cause Origin, and Consequence Severity.\nOur findings reveal that synchronization inconsistencies and avatar-related\nanomalies are the most prevalent symptoms, while network/synchronization logic\ndefects and session management flaws emerge as dominant root causes.\nCritically, over 34% of analyzed bugs lead to severe consequences that\nfundamentally break the shared experience, including system crashes, persistent\ndisconnections, and complete interaction breakdowns, etc. We also identify\nconcerning privacy and health implications unique to multi-user XR contexts.\nBased on our findings of defect analysis, we provide actionable recommendations\nfor developers, platform vendors, and researchers. Our results demonstrate that\nmulti-user XR systems face distinct challenges at the intersection of\ndistributed systems, real-time 3D interaction, and immersive experiences,\nnecessitating specialized approaches to testing, debugging, and quality\nassurance.", "AI": {"tldr": "\u9996\u4e2a\u5927\u89c4\u6a21\u591a\u7528\u6237XR\u7cfb\u7edf\u8f6f\u4ef6\u7f3a\u9677\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u6790\u4e862,649\u4e2a\u771f\u5b9ebug\u62a5\u544a\uff0c\u5f00\u53d1\u4e86\u5305\u542b\u75c7\u72b6\u8868\u73b0\u3001\u6839\u672c\u539f\u56e0\u548c\u540e\u679c\u4e25\u91cd\u6027\u7684\u4e09\u7ef4\u5206\u7c7b\u6cd5\uff0c\u63ed\u793a\u4e86\u540c\u6b65\u4e0d\u4e00\u81f4\u548c\u5316\u8eab\u5f02\u5e38\u662f\u6700\u5e38\u89c1\u75c7\u72b6\uff0c\u7f51\u7edc/\u540c\u6b65\u903b\u8f91\u7f3a\u9677\u662f\u4e3b\u8981\u6839\u672c\u539f\u56e0\u3002", "motivation": "\u591a\u7528\u6237XR\u7cfb\u7edf\u5f15\u5165\u4e86\u72ec\u7279\u7684\u8f6f\u4ef6\u7f3a\u9677\uff0c\u5f71\u54cd\u7528\u6237\u4f53\u9a8c\uff0c\u4f46\u76f8\u5173\u7814\u7a76\u4ecd\u4e0d\u8db3\u3002\u7406\u89e3\u8fd9\u4e9b\u7f3a\u9677\u5bf9\u63d0\u5347\u7cfb\u7edf\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u5b9a\u6027\u5206\u6790\u4f7f\u7528\u8fed\u4ee3\u5f00\u653e\u7f16\u7801\u65b9\u6cd5\uff0c\u5206\u6790\u6765\u81ea\u5f00\u53d1\u8005\u8bba\u575b\u3001GitHub\u4ed3\u5e93\u548c\u4e3b\u6d41XR\u5e94\u7528\u5546\u5e97\u5e94\u7528\u8bc4\u8bba\u76842,649\u4e2a\u771f\u5b9ebug\u62a5\u544a\u3002", "result": "\u5f00\u53d1\u4e86\u5168\u9762\u7684\u5206\u7c7b\u6cd5\uff0c\u53d1\u73b0\u540c\u6b65\u4e0d\u4e00\u81f4\u548c\u5316\u8eab\u76f8\u5173\u5f02\u5e38\u662f\u6700\u666e\u904d\u75c7\u72b6\uff0c\u7f51\u7edc/\u540c\u6b65\u903b\u8f91\u7f3a\u9677\u548c\u4f1a\u8bdd\u7ba1\u7406\u7f3a\u9677\u662f\u4e3b\u8981\u6839\u672c\u539f\u56e0\u3002\u8d85\u8fc734%\u7684bug\u5bfc\u81f4\u4e25\u91cd\u7834\u574f\u5171\u4eab\u4f53\u9a8c\u7684\u540e\u679c\u3002", "conclusion": "\u591a\u7528\u6237XR\u7cfb\u7edf\u5728\u5206\u5e03\u5f0f\u7cfb\u7edf\u3001\u5b9e\u65f63D\u4ea4\u4e92\u548c\u6c89\u6d78\u5f0f\u4f53\u9a8c\u4ea4\u53c9\u9886\u57df\u9762\u4e34\u72ec\u7279\u6311\u6218\uff0c\u9700\u8981\u4e13\u95e8\u7684\u6d4b\u8bd5\u3001\u8c03\u8bd5\u548c\u8d28\u91cf\u4fdd\u8bc1\u65b9\u6cd5\u3002"}}
{"id": "2510.00627", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00627", "abs": "https://arxiv.org/abs/2510.00627", "authors": ["Bingzhang Wang", "Kehua Chen", "Yinhai Wang"], "title": "Collaborative-Distilled Diffusion Models (CDDM) for Accelerated and Lightweight Trajectory Prediction", "comment": null, "summary": "Trajectory prediction is a fundamental task in Autonomous Vehicles (AVs) and\nIntelligent Transportation Systems (ITS), supporting efficient motion planning\nand real-time traffic safety management. Diffusion models have recently\ndemonstrated strong performance in probabilistic trajectory prediction, but\ntheir large model size and slow sampling process hinder real-world deployment.\nThis paper proposes Collaborative-Distilled Diffusion Models (CDDM), a novel\nmethod for real-time and lightweight trajectory prediction. Built upon\nCollaborative Progressive Distillation (CPD), CDDM progressively transfers\nknowledge from a high-capacity teacher diffusion model to a lightweight student\nmodel, jointly reducing both the number of sampling steps and the model size\nacross distillation iterations. A dual-signal regularized distillation loss is\nfurther introduced to incorporate guidance from both the teacher and\nground-truth data, mitigating potential overfitting and ensuring robust\nperformance. Extensive experiments on the ETH-UCY pedestrian benchmark and the\nnuScenes vehicle benchmark demonstrate that CDDM achieves state-of-the-art\nprediction accuracy. The well-distilled CDDM retains 96.2% and 95.5% of the\nbaseline model's ADE and FDE performance on pedestrian trajectories, while\nrequiring only 231K parameters and 4 or 2 sampling steps, corresponding to 161x\ncompression, 31x acceleration, and 9 ms latency. Qualitative results further\nshow that CDDM generates diverse and accurate trajectories under dynamic agent\nbehaviors and complex social interactions. By bridging high-performing\ngenerative models with practical deployment constraints, CDDM enables\nresource-efficient probabilistic prediction for AVs and ITS. Code is available\nat https://github.com/bingzhangw/CDDM.", "AI": {"tldr": "\u63d0\u51faCDDM\u65b9\u6cd5\uff0c\u901a\u8fc7\u534f\u4f5c\u6e10\u8fdb\u84b8\u998f\u5c06\u5927\u5bb9\u91cf\u6559\u5e08\u6269\u6563\u6a21\u578b\u7684\u77e5\u8bc6\u8f6c\u79fb\u5230\u8f7b\u91cf\u7ea7\u5b66\u751f\u6a21\u578b\uff0c\u5b9e\u73b0\u5b9e\u65f6\u8f7b\u91cf\u5316\u7684\u8f68\u8ff9\u9884\u6d4b\uff0c\u5728\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u6a21\u578b\u53c2\u6570\u548c\u91c7\u6837\u6b65\u9aa4\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u5728\u6982\u7387\u8f68\u8ff9\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u6a21\u578b\u89c4\u6a21\u5927\u3001\u91c7\u6837\u901f\u5ea6\u6162\uff0c\u963b\u788d\u4e86\u5728\u5b9e\u9645\u81ea\u52a8\u9a7e\u9a76\u548c\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u4e2d\u7684\u90e8\u7f72\u3002", "method": "\u57fa\u4e8e\u534f\u4f5c\u6e10\u8fdb\u84b8\u998f(CPD)\uff0c\u9010\u6b65\u51cf\u5c11\u91c7\u6837\u6b65\u9aa4\u548c\u6a21\u578b\u5927\u5c0f\uff0c\u5f15\u5165\u53cc\u4fe1\u53f7\u6b63\u5219\u5316\u84b8\u998f\u635f\u5931\uff0c\u7ed3\u5408\u6559\u5e08\u6a21\u578b\u548c\u771f\u5b9e\u6570\u636e\u7684\u6307\u5bfc\u3002", "result": "\u5728ETH-UCY\u884c\u4eba\u57fa\u51c6\u548cnuScenes\u8f66\u8f86\u57fa\u51c6\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u9884\u6d4b\u7cbe\u5ea6\uff0c\u4ec5\u9700231K\u53c2\u6570\u548c2-4\u91c7\u6837\u6b65\u9aa4\uff0c\u5b9e\u73b0161\u500d\u538b\u7f29\u300131\u500d\u52a0\u901f\u548c9ms\u5ef6\u8fdf\u3002", "conclusion": "CDDM\u901a\u8fc7\u6865\u63a5\u9ad8\u6027\u80fd\u751f\u6210\u6a21\u578b\u4e0e\u5b9e\u7528\u90e8\u7f72\u7ea6\u675f\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u548c\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u5b9e\u73b0\u4e86\u8d44\u6e90\u9ad8\u6548\u7684\u6982\u7136\u9884\u6d4b\u3002"}}
{"id": "2510.00636", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.00636", "abs": "https://arxiv.org/abs/2510.00636", "authors": ["Alessio Devoto", "Maximilian Jeblick", "Simon J\u00e9gou"], "title": "Expected Attention: KV Cache Compression by Estimating Attention from Future Queries Distribution", "comment": null, "summary": "Memory consumption of the Key-Value (KV) cache represents a major bottleneck\nfor efficient large language model inference. While attention-score-based KV\ncache pruning shows promise, it faces critical practical limitations: attention\nscores from future tokens are unavailable during compression, and modern\nimplementations like Flash Attention do not materialize the full attention\nmatrix, making past scores inaccessible. To overcome these challenges, we\nintroduce $\\textbf{Expected Attention, a training-free compression method}$\nthat estimates KV pairs importance by predicting how future queries will attend\nto them. Our approach leverages the distributional properties of LLM\nactivations to compute expected attention scores in closed form for each KV\npair. These scores enable principled ranking and pruning of KV pairs with\nminimal impact on the residual stream, achieving effective compression without\nperformance degradation. Importantly, our method operates seamlessly across\nboth prefilling and decoding phases, consistently outperforming\nstate-of-the-art baselines in both scenarios. Finally, $\\textbf{we release\nKVPress, a comprehensive library to enable researchers to implement and\nbenchmark KV cache compression methods, already including more than 20\ntechniques}$.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aExpected Attention\u7684\u65e0\u8bad\u7ec3KV\u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\uff0c\u901a\u8fc7\u9884\u6d4b\u672a\u6765\u67e5\u8be2\u5982\u4f55\u5173\u6ce8KV\u5bf9\u6765\u4f30\u8ba1\u5176\u91cd\u8981\u6027\uff0c\u89e3\u51b3\u4e86\u6ce8\u610f\u529b\u5206\u6570\u5728\u63a8\u7406\u65f6\u4e0d\u53ef\u7528\u7684\u95ee\u9898\u3002", "motivation": "KV\u7f13\u5b58\u7684\u5b58\u50a8\u6d88\u8017\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6548\u7387\u7684\u4e3b\u8981\u74f6\u9888\u3002\u73b0\u6709\u7684\u57fa\u4e8e\u6ce8\u610f\u529b\u5206\u6570\u7684KV\u7f13\u5b58\u526a\u679d\u65b9\u6cd5\u9762\u4e34\u5b9e\u9645\u9650\u5236\uff1a\u672a\u6765token\u7684\u6ce8\u610f\u529b\u5206\u6570\u5728\u538b\u7f29\u65f6\u4e0d\u53ef\u7528\uff0c\u4e14\u73b0\u4ee3\u5b9e\u73b0\u5982Flash Attention\u4e0d\u4f1a\u751f\u6210\u5b8c\u6574\u7684\u6ce8\u610f\u529b\u77e9\u9635\u3002", "method": "\u5229\u7528LLM\u6fc0\u6d3b\u7684\u5206\u5e03\u7279\u6027\uff0c\u4ee5\u95ed\u5f0f\u5f62\u5f0f\u8ba1\u7b97\u6bcf\u4e2aKV\u5bf9\u7684\u671f\u671b\u6ce8\u610f\u529b\u5206\u6570\uff0c\u57fa\u4e8e\u8fd9\u4e9b\u5206\u6570\u8fdb\u884c\u6392\u5e8f\u548c\u526a\u679d\uff0c\u5bf9\u6b8b\u5dee\u6d41\u5f71\u54cd\u6700\u5c0f\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u9884\u586b\u5145\u548c\u89e3\u7801\u9636\u6bb5\u90fd\u80fd\u65e0\u7f1d\u8fd0\u884c\uff0c\u5728\u4e24\u4e2a\u573a\u666f\u4e2d\u90fd\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u5f00\u53d1\u4e86KVPress\u5e93\uff0c\u5305\u542b20\u591a\u79cd\u6280\u672f\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u5b9e\u73b0\u548c\u57fa\u51c6\u6d4b\u8bd5KV\u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5de5\u5177\u3002"}}
{"id": "2510.00664", "categories": ["cs.AI", "cs.CV", "68", "I.2; I.4"], "pdf": "https://arxiv.org/pdf/2510.00664", "abs": "https://arxiv.org/abs/2510.00664", "authors": ["Giacomo Ignesti", "Davide Moroni", "Massimo Martinelli"], "title": "Batch-CAM: Introduction to better reasoning in convolutional deep learning models", "comment": "18 pages, 7 figures, submitted to SN Computer Science Springer Nature", "summary": "Understanding the inner workings of deep learning models is crucial for\nadvancing artificial intelligence, particularly in high-stakes fields such as\nhealthcare, where accurate explanations are as vital as precision. This paper\nintroduces Batch-CAM, a novel training paradigm that fuses a batch\nimplementation of the Grad-CAM algorithm with a prototypical reconstruction\nloss. This combination guides the model to focus on salient image features,\nthereby enhancing its performance across classification tasks. Our results\ndemonstrate that Batch-CAM achieves a simultaneous improvement in accuracy and\nimage reconstruction quality while reducing training and inference times. By\nensuring models learn from evidence-relevant information,this approach makes a\nrelevant contribution to building more transparent, explainable, and\ntrustworthy AI systems.", "AI": {"tldr": "\u63d0\u51faBatch-CAM\u8bad\u7ec3\u8303\u5f0f\uff0c\u7ed3\u5408\u6279\u5904\u7406Grad-CAM\u7b97\u6cd5\u548c\u539f\u578b\u91cd\u5efa\u635f\u5931\uff0c\u63d0\u5347\u6a21\u578b\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u540c\u65f6\u63d0\u9ad8\u51c6\u786e\u7387\u548c\u56fe\u50cf\u91cd\u5efa\u8d28\u91cf\uff0c\u51cf\u5c11\u8bad\u7ec3\u548c\u63a8\u7406\u65f6\u95f4\u3002", "motivation": "\u5728\u533b\u7597\u7b49\u9ad8\u98ce\u9669\u9886\u57df\uff0c\u6df1\u5ea6\u5b66\u4e60\u7684\u53ef\u89e3\u91ca\u6027\u81f3\u5173\u91cd\u8981\uff0c\u51c6\u786e\u7684\u89e3\u91ca\u4e0e\u7cbe\u5ea6\u540c\u7b49\u91cd\u8981\u3002\u9700\u8981\u6784\u5efa\u66f4\u900f\u660e\u3001\u53ef\u89e3\u91ca\u548c\u53ef\u4fe1\u8d56\u7684AI\u7cfb\u7edf\u3002", "method": "\u878d\u5408\u6279\u5904\u7406Grad-CAM\u7b97\u6cd5\u4e0e\u539f\u578b\u91cd\u5efa\u635f\u5931\uff0c\u5f15\u5bfc\u6a21\u578b\u5173\u6ce8\u663e\u8457\u56fe\u50cf\u7279\u5f81\u3002", "result": "Batch-CAM\u5728\u51c6\u786e\u7387\u548c\u56fe\u50cf\u91cd\u5efa\u8d28\u91cf\u4e0a\u540c\u65f6\u63d0\u5347\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u8bad\u7ec3\u548c\u63a8\u7406\u65f6\u95f4\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u786e\u4fdd\u6a21\u578b\u4ece\u8bc1\u636e\u76f8\u5173\u4fe1\u606f\u4e2d\u5b66\u4e60\uff0c\u4e3a\u6784\u5efa\u66f4\u900f\u660e\u3001\u53ef\u89e3\u91ca\u548c\u53ef\u4fe1\u8d56\u7684AI\u7cfb\u7edf\u505a\u51fa\u4e86\u91cd\u8981\u8d21\u732e\u3002"}}
{"id": "2510.00689", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00689", "abs": "https://arxiv.org/abs/2510.00689", "authors": ["Chi-Huang Lin", "Ting Han Wei", "Chun-Jui Wang", "Hung Guei", "Chung-Chin Shih", "Yun-Jui Tsai", "I-Chen Wu", "Ti-Rong Wu"], "title": "Relevance-Zone Reduction in Game Solving", "comment": "Accepted by the Advances in Computer Games (ACG 2025)", "summary": "Game solving aims to find the optimal strategies for all players and\ndetermine the theoretical outcome of a game. However, due to the exponential\ngrowth of game trees, many games remain unsolved, even though methods like\nAlphaZero have demonstrated super-human level in game playing. The\nRelevance-Zone (RZ) is a local strategy reuse technique that restricts the\nsearch to only the regions relevant to the outcome, significantly reducing the\nsearch space. However, RZs are not unique. Different solutions may result in\nRZs of varying sizes. Smaller RZs are generally more favorable, as they\nincrease the chance of reuse and improve pruning efficiency. To this end, we\npropose an iterative RZ reduction method that repeatedly solves the same\nposition while gradually restricting the region involved, guiding the solver\ntoward smaller RZs. We design three constraint generation strategies and\nintegrate an RZ Pattern Table to fully leverage past solutions. In experiments\non 7x7 Killall-Go, our method reduces the average RZ size to 85.95% of the\noriginal. Furthermore, the reduced RZs can be permanently stored as reusable\nknowledge for future solving tasks, especially for larger board sizes or\ndifferent openings.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8fed\u4ee3\u5f0f\u76f8\u5173\u533a\u57df(RZ)\u7f29\u51cf\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cd\u590d\u6c42\u89e3\u540c\u4e00\u4f4d\u7f6e\u5e76\u9010\u6b65\u9650\u5236\u641c\u7d22\u533a\u57df\u6765\u83b7\u5f97\u66f4\u5c0f\u7684RZ\uff0c\u4ece\u800c\u63d0\u9ad8\u7b56\u7565\u91cd\u7528\u548c\u526a\u679d\u6548\u7387\u3002", "motivation": "\u6e38\u620f\u6c42\u89e3\u9762\u4e34\u6307\u6570\u7ea7\u589e\u957f\u7684\u535a\u5f08\u6811\u95ee\u9898\uff0c\u867d\u7136\u76f8\u5173\u533a\u57df(RZ)\u6280\u672f\u80fd\u663e\u8457\u51cf\u5c11\u641c\u7d22\u7a7a\u95f4\uff0c\u4f46\u4e0d\u540c\u89e3\u51b3\u65b9\u6848\u4f1a\u4ea7\u751f\u4e0d\u540c\u5927\u5c0f\u7684RZ\uff0c\u8f83\u5c0f\u7684RZ\u66f4\u6709\u5229\u4e8e\u91cd\u7528\u548c\u526a\u679d\u6548\u7387\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e09\u79cd\u7ea6\u675f\u751f\u6210\u7b56\u7565\uff0c\u5e76\u96c6\u6210\u4e86RZ\u6a21\u5f0f\u8868\u6765\u5145\u5206\u5229\u7528\u8fc7\u5f80\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u8fed\u4ee3\u6c42\u89e3\u540c\u4e00\u4f4d\u7f6e\u5e76\u9010\u6b65\u9650\u5236\u533a\u57df\u6765\u5f15\u5bfc\u6c42\u89e3\u5668\u83b7\u5f97\u66f4\u5c0f\u7684RZ\u3002", "result": "\u57287x7 Killall-Go\u5b9e\u9a8c\u4e2d\uff0c\u5e73\u5747RZ\u5927\u5c0f\u51cf\u5c11\u5230\u539f\u59cb\u768485.95%\uff0c\u7f29\u51cf\u540e\u7684RZ\u53ef\u4f5c\u4e3a\u53ef\u91cd\u7528\u77e5\u8bc6\u5b58\u50a8\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u51cf\u5c0fRZ\u5927\u5c0f\uff0c\u63d0\u9ad8\u6c42\u89e3\u6548\u7387\uff0c\u7f29\u51cf\u540e\u7684RZ\u53ef\u4f5c\u4e3a\u6c38\u4e45\u77e5\u8bc6\u7528\u4e8e\u672a\u6765\u66f4\u5927\u68cb\u76d8\u6216\u4e0d\u540c\u5f00\u5c40\u5e03\u5c40\u7684\u6c42\u89e3\u4efb\u52a1\u3002"}}
{"id": "2510.00690", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00690", "abs": "https://arxiv.org/abs/2510.00690", "authors": ["Yunhao Wang", "Ziting Li", "Shuai Chen", "Tao Liu", "Chao Song", "Junjie Jiang", "Jian Zhu", "Peng Gao", "Bin Qin"], "title": "ACPO: Adaptive Curriculum Policy Optimization for Aligning Vision-Language Models in Complex Reasoning", "comment": null, "summary": "Aligning large-scale vision-language models (VLMs) for complex reasoning via\nreinforcement learning is often hampered by the limitations of existing policy\noptimization algorithms, such as static training schedules and the rigid,\nuniform clipping mechanism in Proximal Policy Optimization (PPO). In this work,\nwe introduce Adaptive Curriculum Policy Optimization (ACPO), a novel framework\nthat addresses these challenges through a dual-component adaptive learning\nstrategy. First, ACPO employs a dynamic curriculum that orchestrates a\nprincipled transition from a stable, near on-policy exploration phase to an\nefficient, off-policy exploitation phase by progressively increasing sample\nreuse. Second, we propose an Advantage-Aware Adaptive Clipping (AAAC) mechanism\nthat replaces the fixed clipping hyperparameter with dynamic, sample-wise\nbounds modulated by the normalized advantage of each token. This allows for\nmore granular and robust policy updates, enabling larger gradients for\nhigh-potential samples while safeguarding against destructive ones. We conduct\nextensive experiments on a suite of challenging multimodal reasoning\nbenchmarks, including MathVista, LogicVista, and MMMU-Pro. Results demonstrate\nthat ACPO consistently outperforms strong baselines such as DAPO and PAPO,\nachieving state-of-the-art performance, accelerated convergence, and superior\ntraining stability.", "AI": {"tldr": "ACPO\u662f\u4e00\u4e2a\u81ea\u9002\u5e94\u8bfe\u7a0b\u7b56\u7565\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8bfe\u7a0b\u548c\u81ea\u9002\u5e94\u88c1\u526a\u673a\u5236\u6539\u8fdb\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u9f50\u8bad\u7ec3\uff0c\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u5b9e\u73b0SOTA\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\uff08\u5982PPO\uff09\u5728\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u8bad\u7ec3\u4e2d\u5b58\u5728\u9759\u6001\u8bad\u7ec3\u8ba1\u5212\u548c\u521a\u6027\u88c1\u526a\u673a\u5236\u7684\u9650\u5236\uff0c\u963b\u788d\u4e86\u590d\u6742\u63a8\u7406\u4efb\u52a1\u7684\u6027\u80fd\u63d0\u5347\u3002", "method": "\u63d0\u51faACPO\u6846\u67b6\uff1a1\uff09\u52a8\u6001\u8bfe\u7a0b\u7b56\u7565\uff0c\u4ece\u8fd1\u7b56\u7565\u63a2\u7d22\u9010\u6b65\u8fc7\u6e21\u5230\u79bb\u7b56\u7565\u5229\u7528\uff1b2\uff09\u4f18\u52bf\u611f\u77e5\u81ea\u9002\u5e94\u88c1\u526a\u673a\u5236\uff0c\u6839\u636e\u6bcf\u4e2atoken\u7684\u5f52\u4e00\u5316\u4f18\u52bf\u52a8\u6001\u8c03\u6574\u88c1\u526a\u8fb9\u754c\u3002", "result": "\u5728MathVista\u3001LogicVista\u548cMMMU-Pro\u7b49\u591a\u6a21\u6001\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cACPO\u663e\u8457\u4f18\u4e8eDAPO\u548cPAPO\u7b49\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u6027\u80fd\u3001\u52a0\u901f\u6536\u655b\u548c\u66f4\u597d\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "conclusion": "ACPO\u901a\u8fc7\u81ea\u9002\u5e94\u5b66\u4e60\u7b56\u7565\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u590d\u6742\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\u7684\u5bf9\u9f50\u8bad\u7ec3\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u548c\u7a33\u5b9a\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.00706", "categories": ["cs.AI", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00706", "abs": "https://arxiv.org/abs/2510.00706", "authors": ["Yusif Ibrahimov", "Tarique Anwar", "Tommy Yuan", "Turan Mutallimov", "Elgun Hasanov"], "title": "AttentionDep: Domain-Aware Attention for Explainable Depression Severity Assessment", "comment": null, "summary": "In today's interconnected society, social media platforms provide a window\ninto individuals' thoughts, emotions, and mental states. This paper explores\nthe use of platforms like Facebook, X (formerly Twitter), and Reddit for\ndepression severity detection. We propose AttentionDep, a domain-aware\nattention model that drives explainable depression severity estimation by\nfusing contextual and domain knowledge. Posts are encoded hierarchically using\nunigrams and bigrams, with attention mechanisms highlighting clinically\nrelevant tokens. Domain knowledge from a curated mental health knowledge graph\nis incorporated through a cross-attention mechanism, enriching the contextual\nfeatures. Finally, depression severity is predicted using an ordinal regression\nframework that respects the clinical-relevance and natural ordering of severity\nlevels. Our experiments demonstrate that AttentionDep outperforms\nstate-of-the-art baselines by over 5% in graded F1 score across datasets, while\nproviding interpretable insights into its predictions. This work advances the\ndevelopment of trustworthy and transparent AI systems for mental health\nassessment from social media.", "AI": {"tldr": "AttentionDep\u6a21\u578b\u901a\u8fc7\u878d\u5408\u4e0a\u4e0b\u6587\u548c\u9886\u57df\u77e5\u8bc6\u8fdb\u884c\u53ef\u89e3\u91ca\u7684\u6291\u90c1\u75c7\u4e25\u91cd\u7a0b\u5ea6\u68c0\u6d4b\uff0c\u5728\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5229\u7528\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\u4f5c\u4e3a\u4e86\u89e3\u4e2a\u4f53\u5fc3\u7406\u72b6\u6001\u7684\u7a97\u53e3\uff0c\u5f00\u53d1\u53ef\u4fe1\u8d56\u4e14\u900f\u660e\u7684AI\u7cfb\u7edf\u7528\u4e8e\u5fc3\u7406\u5065\u5eb7\u8bc4\u4f30\u3002", "method": "\u63d0\u51faAttentionDep\u6a21\u578b\uff0c\u4f7f\u7528\u5355\u5b57\u548c\u53cc\u5b57\u8fdb\u884c\u5206\u5c42\u7f16\u7801\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u7a81\u51fa\u4e34\u5e8a\u76f8\u5173\u6807\u8bb0\uff0c\u5e76\u6574\u5408\u5fc3\u7406\u5065\u5eb7\u77e5\u8bc6\u56fe\u8c31\u7684\u9886\u57df\u77e5\u8bc6\uff0c\u91c7\u7528\u5e8f\u6570\u56de\u5f52\u6846\u67b6\u9884\u6d4b\u6291\u90c1\u75c7\u4e25\u91cd\u7a0b\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8868\u660eAttentionDep\u5728\u5206\u7ea7F1\u5206\u6570\u4e0a\u6bd4\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u9ad8\u51fa5%\u4ee5\u4e0a\uff0c\u540c\u65f6\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u9884\u6d4b\u6d1e\u5bdf\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63a8\u52a8\u4e86\u57fa\u4e8e\u793e\u4ea4\u5a92\u4f53\u7684\u5fc3\u7406\u5065\u5eb7\u8bc4\u4f30\u4e2d\u53ef\u4fe1\u8d56\u548c\u900f\u660eAI\u7cfb\u7edf\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.00732", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00732", "abs": "https://arxiv.org/abs/2510.00732", "authors": ["Yuchen Tian", "Ruiyuan Huang", "Xuanwu Wang", "Jing Ma", "Zengfeng Huang", "Ziyang Luo", "Hongzhan Lin", "Da Zheng", "Lun Du"], "title": "EvolProver: Advancing Automated Theorem Proving by Evolving Formalized Problems via Symmetry and Difficulty", "comment": null, "summary": "Large Language Models (LLMs) for formal theorem proving have shown\nsignificant promise, yet they often lack generalizability and are fragile to\neven minor transformations of problem statements. To address this limitation,\nwe introduce a novel data augmentation pipeline designed to enhance model\nrobustness from two perspectives: symmetry and difficulty. From the symmetry\nperspective, we propose two complementary methods: EvolAST, an Abstract Syntax\nTree (AST) based approach that targets syntactic symmetry to generate\nsemantically equivalent problem variants, and EvolDomain, which leverages LLMs\nto address semantic symmetry by translating theorems across mathematical\ndomains. From the difficulty perspective, we propose EvolDifficulty, which uses\ncarefully designed evolutionary instructions to guide LLMs in generating new\ntheorems with a wider range of difficulty. We then use the evolved data to\ntrain EvolProver, a 7B-parameter non-reasoning theorem prover. EvolProver\nestablishes a new state-of-the-art (SOTA) on FormalMATH-Lite with a 53.8%\npass@32 rate, surpassing all models of comparable size, including\nreasoning-based models. It also sets new SOTA records for non-reasoning models\non MiniF2F-Test (69.8% pass@32), Ineq-Comp-Seed (52.2% pass@32), and\nIneq-Comp-Transformed (34.0% pass@32). Ablation studies further confirm our\ndata augmentation pipeline's effectiveness across multiple benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6570\u636e\u589e\u5f3a\u6d41\u6c34\u7ebf\uff0c\u901a\u8fc7\u5bf9\u79f0\u6027\u548c\u96be\u5ea6\u4e24\u4e2a\u89d2\u5ea6\u63d0\u5347\u5b9a\u7406\u8bc1\u660e\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff0c\u8bad\u7ec3\u51fa\u7684EvolProver\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u521b\u4e0b\u65b0\u8bb0\u5f55\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5f62\u5f0f\u5b9a\u7406\u8bc1\u660e\u4e2d\u7f3a\u4e4f\u6cdb\u5316\u80fd\u529b\uff0c\u5bf9\u95ee\u9898\u8868\u8ff0\u7684\u5fae\u5c0f\u53d8\u6362\u4e5f\u5f88\u8106\u5f31\u3002", "method": "\u4ece\u5bf9\u79f0\u6027\u89d2\u5ea6\u63d0\u51faEvolAST\uff08\u57fa\u4e8e\u62bd\u8c61\u8bed\u6cd5\u6811\uff09\u548cEvolDomain\uff08\u8de8\u6570\u5b66\u9886\u57df\u7ffb\u8bd1\uff09\uff1b\u4ece\u96be\u5ea6\u89d2\u5ea6\u63d0\u51faEvolDifficulty\uff1b\u4f7f\u7528\u589e\u5f3a\u6570\u636e\u8bad\u7ec37B\u53c2\u6570\u7684\u975e\u63a8\u7406\u5b9a\u7406\u8bc1\u660e\u5668EvolProver\u3002", "result": "EvolProver\u5728FormalMATH-Lite\u4e0a\u8fbe\u523053.8% pass@32\uff0c\u5728MiniF2F-Test\u3001Ineq-Comp-Seed\u548cIneq-Comp-Transformed\u4e0a\u5747\u521b\u4e0b\u975e\u63a8\u7406\u6a21\u578b\u7684\u65b0\u8bb0\u5f55\u3002", "conclusion": "\u6570\u636e\u589e\u5f3a\u6d41\u6c34\u7ebf\u6709\u6548\u63d0\u5347\u4e86\u5b9a\u7406\u8bc1\u660e\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff0cEvolProver\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2510.00778", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00778", "abs": "https://arxiv.org/abs/2510.00778", "authors": ["Seunghoo Hong", "Geonho Son", "Juhun Lee", "Simon S. Woo"], "title": "DIA: The Adversarial Exposure of Deterministic Inversion in Diffusion Models", "comment": "ICCV2025", "summary": "Diffusion models have shown to be strong representation learners, showcasing\nstate-of-the-art performance across multiple domains. Aside from accelerated\nsampling, DDIM also enables the inversion of real images back to their latent\ncodes. A direct inheriting application of this inversion operation is real\nimage editing, where the inversion yields latent trajectories to be utilized\nduring the synthesis of the edited image. Unfortunately, this practical tool\nhas enabled malicious users to freely synthesize misinformative or deepfake\ncontents with greater ease, which promotes the spread of unethical and abusive,\nas well as privacy-, and copyright-infringing contents. While defensive\nalgorithms such as AdvDM and Photoguard have been shown to disrupt the\ndiffusion process on these images, the misalignment between their objectives\nand the iterative denoising trajectory at test time results in weak disruptive\nperformance.In this work, we present the DDIM Inversion Attack (DIA) that\nattacks the integrated DDIM trajectory path. Our results support the effective\ndisruption, surpassing previous defensive methods across various editing\nmethods. We believe that our frameworks and results can provide practical\ndefense methods against the malicious use of AI for both the industry and the\nresearch community. Our code is available here:\nhttps://anonymous.4open.science/r/DIA-13419/.", "AI": {"tldr": "\u63d0\u51faDDIM\u53cd\u6f14\u653b\u51fb(DIA)\u65b9\u6cd5\uff0c\u901a\u8fc7\u653b\u51fbDDIM\u8f68\u8ff9\u8def\u5f84\u6765\u6709\u6548\u9632\u5fa1\u6076\u610f\u56fe\u50cf\u7f16\u8f91\uff0c\u8d85\u8d8a\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u3002", "motivation": "DDIM\u53cd\u6f14\u6280\u672f\u4f7f\u6076\u610f\u7528\u6237\u80fd\u8f7b\u677e\u5408\u6210\u865a\u5047\u6216\u4fb5\u6743\u5185\u5bb9\uff0c\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u56e0\u76ee\u6807\u4e0e\u53bb\u566a\u8f68\u8ff9\u4e0d\u5339\u914d\u800c\u6548\u679c\u6709\u9650\u3002", "method": "\u5f00\u53d1DDIM\u53cd\u6f14\u653b\u51fb(DIA)\uff0c\u76f4\u63a5\u653b\u51fbDDIM\u8f68\u8ff9\u8def\u5f84\uff0c\u7834\u574f\u6269\u6563\u6a21\u578b\u7684\u56fe\u50cf\u7f16\u8f91\u80fd\u529b\u3002", "result": "DIA\u5728\u5404\u79cd\u7f16\u8f91\u65b9\u6cd5\u4e2d\u5747\u80fd\u6709\u6548\u7834\u574f\u56fe\u50cf\u7f16\u8f91\u8fc7\u7a0b\uff0c\u6027\u80fd\u8d85\u8d8aAdvDM\u548cPhotoguard\u7b49\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u3002", "conclusion": "DIA\u6846\u67b6\u4e3a\u884c\u4e1a\u548c\u7814\u7a76\u793e\u533a\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684AI\u6076\u610f\u4f7f\u7528\u9632\u5fa1\u65b9\u6cd5\u3002"}}
{"id": "2510.00793", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.00793", "abs": "https://arxiv.org/abs/2510.00793", "authors": ["J. A. Hageman", "C. F. W. Peeters"], "title": "AI in data science education: experiences from the classroom", "comment": "6 pages, 0 figures", "summary": "This study explores the integration of AI, particularly large language models\n(LLMs) like ChatGPT, into educational settings, focusing on the implications\nfor teaching and learning. Through interviews with course coordinators from\ndata science courses at Wageningen University, this research identifies both\nthe benefits and challenges associated with AI in the classroom. While AI tools\ncan streamline tasks and enhance learning, concerns arise regarding students'\noverreliance on these technologies, potentially hindering the development of\nessential cognitive and problem solving skills. The study highlights the\nimportance of responsible AI usage, ethical considerations, and the need for\nadapting assessment methods to ensure educational outcomes are met. With\ncareful integration, AI can be a valuable asset in education, provided it is\nused to complement rather than replace fundamental learning processes.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86AI\uff08\u7279\u522b\u662f\u50cfChatGPT\u8fd9\u6837\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff09\u5728\u6559\u80b2\u73af\u5883\u4e2d\u7684\u6574\u5408\uff0c\u91cd\u70b9\u5173\u6ce8\u5bf9\u6559\u5b66\u7684\u5f71\u54cd\u3002\u901a\u8fc7\u8bbf\u8c08\u74e6\u8d6b\u5b81\u6839\u5927\u5b66\u6570\u636e\u79d1\u5b66\u8bfe\u7a0b\u7684\u534f\u8c03\u5458\uff0c\u7814\u7a76\u53d1\u73b0AI\u5de5\u5177\u65e2\u80fd\u7b80\u5316\u4efb\u52a1\u3001\u589e\u5f3a\u5b66\u4e60\uff0c\u4e5f\u5b58\u5728\u5b66\u751f\u8fc7\u5ea6\u4f9d\u8d56\u3001\u963b\u788d\u8ba4\u77e5\u548c\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u53d1\u5c55\u7684\u98ce\u9669\u3002", "motivation": "\u968f\u7740AI\u6280\u672f\u5728\u6559\u80b2\u9886\u57df\u7684\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u9700\u8981\u4e86\u89e3AI\u5de5\u5177\u5bf9\u6559\u5b66\u548c\u5b66\u4e60\u7684\u5b9e\u9645\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5982\u4f55\u5e73\u8861AI\u5e26\u6765\u7684\u4fbf\u5229\u4e0e\u5b66\u751f\u80fd\u529b\u53d1\u5c55\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u901a\u8fc7\u5bf9\u74e6\u8d6b\u5b81\u6839\u5927\u5b66\u6570\u636e\u79d1\u5b66\u8bfe\u7a0b\u534f\u8c03\u5458\u8fdb\u884c\u8bbf\u8c08\uff0c\u6536\u96c6\u5173\u4e8eAI\u5728\u6559\u80b2\u4e2d\u5e94\u7528\u7684\u5b9a\u6027\u6570\u636e\u3002", "result": "\u7814\u7a76\u53d1\u73b0AI\u5de5\u5177\u80fd\u591f\u7b80\u5316\u4efb\u52a1\u5e76\u589e\u5f3a\u5b66\u4e60\u4f53\u9a8c\uff0c\u4f46\u540c\u65f6\u4e5f\u5b58\u5728\u5b66\u751f\u8fc7\u5ea6\u4f9d\u8d56AI\u7684\u98ce\u9669\uff0c\u8fd9\u53ef\u80fd\u963b\u788d\u4ed6\u4eec\u53d1\u5c55\u5173\u952e\u7684\u8ba4\u77e5\u548c\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u3002", "conclusion": "AI\u53ef\u4ee5\u6210\u4e3a\u6559\u80b2\u4e2d\u7684\u5b9d\u8d35\u8d44\u4ea7\uff0c\u4f46\u9700\u8981\u8d1f\u8d23\u4efb\u5730\u4f7f\u7528\uff0c\u786e\u4fddAI\u8865\u5145\u800c\u975e\u66ff\u4ee3\u57fa\u672c\u5b66\u4e60\u8fc7\u7a0b\uff0c\u540c\u65f6\u9700\u8981\u8c03\u6574\u8bc4\u4f30\u65b9\u6cd5\u4ee5\u786e\u4fdd\u6559\u80b2\u76ee\u6807\u7684\u5b9e\u73b0\u3002"}}
{"id": "2510.00795", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00795", "abs": "https://arxiv.org/abs/2510.00795", "authors": ["Anastasia Vepreva", "Julia Razlivina", "Maria Eremeeva", "Nina Gubina", "Anastasia Orlova", "Aleksei Dmitrenko", "Ksenya Kapranova", "Susan Jyakhwo", "Nikita Vasilev", "Arsen Sarkisyan", "Ivan Yu. Chernyshov", "Vladimir Vinogradov", "Andrei Dmitrenko"], "title": "Benchmarking Agentic Systems in Automated Scientific Information Extraction with ChemX", "comment": "Accepted at The AI for Accelerated Materials Discovery (AI4Mat)\n  Workshop, NeurIPS 2025", "summary": "The emergence of agent-based systems represents a significant advancement in\nartificial intelligence, with growing applications in automated data\nextraction. However, chemical information extraction remains a formidable\nchallenge due to the inherent heterogeneity of chemical data. Current\nagent-based approaches, both general-purpose and domain-specific, exhibit\nlimited performance in this domain. To address this gap, we present ChemX, a\ncomprehensive collection of 10 manually curated and domain-expert-validated\ndatasets focusing on nanomaterials and small molecules. These datasets are\ndesigned to rigorously evaluate and enhance automated extraction methodologies\nin chemistry. To demonstrate their utility, we conduct an extensive\nbenchmarking study comparing existing state-of-the-art agentic systems such as\nChatGPT Agent and chemical-specific data extraction agents. Additionally, we\nintroduce our own single-agent approach that enables precise control over\ndocument preprocessing prior to extraction. We further evaluate the performance\nof modern baselines, such as GPT-5 and GPT-5 Thinking, to compare their\ncapabilities with agentic approaches. Our empirical findings reveal persistent\nchallenges in chemical information extraction, particularly in processing\ndomain-specific terminology, complex tabular and schematic representations, and\ncontext-dependent ambiguities. The ChemX benchmark serves as a critical\nresource for advancing automated information extraction in chemistry,\nchallenging the generalization capabilities of existing methods, and providing\nvaluable insights into effective evaluation strategies.", "AI": {"tldr": "\u63d0\u51fa\u4e86ChemX\u6570\u636e\u96c6\u6765\u8bc4\u4f30\u5316\u5b66\u4fe1\u606f\u63d0\u53d6\u65b9\u6cd5\uff0c\u901a\u8fc7\u57fa\u51c6\u6d4b\u8bd5\u53d1\u73b0\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u5316\u5b66\u672f\u8bed\u3001\u590d\u6742\u8868\u683c\u548c\u4e0a\u4e0b\u6587\u6b67\u4e49\u65b9\u9762\u4ecd\u9762\u4e34\u6311\u6218", "motivation": "\u5316\u5b66\u4fe1\u606f\u63d0\u53d6\u56e0\u6570\u636e\u5f02\u8d28\u6027\u800c\u5177\u6709\u6311\u6218\u6027\uff0c\u73b0\u6709\u57fa\u4e8e\u4ee3\u7406\u7684\u65b9\u6cd5\u5728\u8be5\u9886\u57df\u8868\u73b0\u6709\u9650\uff0c\u9700\u8981\u4e13\u95e8\u7684\u8bc4\u4f30\u8d44\u6e90", "method": "\u521b\u5efa\u4e8610\u4e2a\u624b\u52a8\u7b56\u5212\u4e14\u7ecf\u8fc7\u9886\u57df\u4e13\u5bb6\u9a8c\u8bc1\u7684\u6570\u636e\u96c6\uff0c\u8fdb\u884c\u5e7f\u6cdb\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6bd4\u8f83\u73b0\u6709\u6700\u5148\u8fdb\u7684\u4ee3\u7406\u7cfb\u7edf\uff0c\u5e76\u5f15\u5165\u4e86\u5355\u4ee3\u7406\u65b9\u6cd5\u63a7\u5236\u6587\u6863\u9884\u5904\u7406", "result": "\u5b9e\u8bc1\u7814\u7a76\u63ed\u793a\u4e86\u5316\u5b66\u4fe1\u606f\u63d0\u53d6\u4e2d\u7684\u6301\u7eed\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u9886\u57df\u7279\u5b9a\u672f\u8bed\u3001\u590d\u6742\u8868\u683c\u548c\u793a\u610f\u56fe\u8868\u793a\u4ee5\u53ca\u4e0a\u4e0b\u6587\u76f8\u5173\u6b67\u4e49\u65b9\u9762", "conclusion": "ChemX\u57fa\u51c6\u662f\u63a8\u8fdb\u5316\u5b66\u81ea\u52a8\u5316\u4fe1\u606f\u63d0\u53d6\u7684\u5173\u952e\u8d44\u6e90\uff0c\u6311\u6218\u73b0\u6709\u65b9\u6cd5\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u4e3a\u6709\u6548\u8bc4\u4f30\u7b56\u7565\u63d0\u4f9b\u5b9d\u8d35\u89c1\u89e3"}}
{"id": "2510.00817", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2510.00817", "abs": "https://arxiv.org/abs/2510.00817", "authors": ["Nicholas Leisegang", "Giovanni Casini", "Thomas Meyer"], "title": "Semantic Bridges Between First Order c-Representations and Cost-Based Semantics: An Initial Perspective", "comment": null, "summary": "Weighted-knowledge bases and cost-based semantics represent a recent\nformalism introduced by Bienvenu et al. for Ontology Mediated Data Querying in\nthe case where a given knowledge base is inconsistent. This is done by adding a\nweight to each statement in the knowledge base (KB), and then giving each DL\ninterpretation a cost based on how often it breaks rules in the KB. In this\npaper we compare this approach with c-representations, a form of non-monotonic\nreasoning originally introduced by Kern-Isberner. c-Representations describe a\nmeans to interpret defeasible concept inclusions in the first-order case. This\nis done by assigning a numerical ranking to each interpretations via penalties\nfor each violated conditional. We compare these two approaches on a semantic\nlevel. In particular, we show that under certain conditions a weighted\nknowledge base and a set of defeasible conditionals can generate the same\nordering on interpretations, and therefore an equivalence of semantic\nstructures up to relative cost. Moreover, we compare entailment described in\nboth cases, where certain notions are equivalently expressible in both\nformalisms. Our results have the potential to benefit further work on both\ncost-based semantics and c-representations", "AI": {"tldr": "\u6bd4\u8f83\u52a0\u6743\u77e5\u8bc6\u5e93\u4e0ec-representations\u4e24\u79cd\u5904\u7406\u4e0d\u4e00\u81f4\u77e5\u8bc6\u5e93\u7684\u65b9\u6cd5\uff0c\u5206\u6790\u5b83\u4eec\u5728\u8bed\u4e49\u5c42\u9762\u7684\u7b49\u4ef7\u6027", "motivation": "\u7814\u7a76\u52a0\u6743\u77e5\u8bc6\u5e93\u548cc-representations\u8fd9\u4e24\u79cd\u5904\u7406\u4e0d\u4e00\u81f4\u77e5\u8bc6\u5e93\u7684\u65b9\u6cd5\u4e4b\u95f4\u7684\u8bed\u4e49\u5173\u7cfb\uff0c\u63a2\u7d22\u5b83\u4eec\u80fd\u5426\u4ea7\u751f\u76f8\u540c\u7684\u89e3\u91ca\u6392\u5e8f", "method": "\u901a\u8fc7\u8bed\u4e49\u5c42\u9762\u6bd4\u8f83\uff0c\u5206\u6790\u4e24\u79cd\u65b9\u6cd5\u5728\u89e3\u91ca\u6392\u5e8f\u548c\u8574\u542b\u5173\u7cfb\u4e0a\u7684\u7b49\u4ef7\u6761\u4ef6", "result": "\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\uff0c\u52a0\u6743\u77e5\u8bc6\u5e93\u548c\u4e00\u7ec4\u53ef\u5e9f\u6b62\u6761\u4ef6\u53ef\u4ee5\u751f\u6210\u76f8\u540c\u7684\u89e3\u91ca\u6392\u5e8f\uff0c\u5b9e\u73b0\u8bed\u4e49\u7ed3\u6784\u7684\u76f8\u5bf9\u6210\u672c\u7b49\u4ef7", "conclusion": "\u4e24\u79cd\u5f62\u5f0f\u4e3b\u4e49\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u5177\u6709\u8bed\u4e49\u7b49\u4ef7\u6027\uff0c\u8fd9\u6709\u52a9\u4e8e\u8fdb\u4e00\u6b65\u7814\u7a76\u6210\u672c\u8bed\u4e49\u548cc-representations"}}
{"id": "2510.00821", "categories": ["cs.AI", "90C05, 68T27", "I.2.3; F.4.1"], "pdf": "https://arxiv.org/pdf/2510.00821", "abs": "https://arxiv.org/abs/2510.00821", "authors": ["Andr\u00e9s Corrada-Emmanuel"], "title": "Logical Consistency Between Disagreeing Experts and Its Role in AI Safety", "comment": "10 pages, 7 figures", "summary": "If two experts disagree on a test, we may conclude both cannot be 100 per\ncent correct. But if they completely agree, no possible evaluation can be\nexcluded. This asymmetry in the utility of agreements versus disagreements is\nexplored here by formalizing a logic of unsupervised evaluation for\nclassifiers. Its core problem is computing the set of group evaluations that\nare logically consistent with how we observe them agreeing and disagreeing in\ntheir decisions. Statistical summaries of their aligned decisions are inputs\ninto a Linear Programming problem in the integer space of possible correct or\nincorrect responses given true labels. Obvious logical constraints, such as,\nthe number of correct responses cannot exceed the number of observed responses,\nare inequalities. But in addition, there are axioms, universally applicable\nlinear equalities that apply to all finite tests. The practical and immediate\nutility of this approach to unsupervised evaluation using only logical\nconsistency is demonstrated by building no-knowledge alarms that can detect\nwhen one or more LLMs-as-Judges are violating a minimum grading threshold\nspecified by the user.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u76d1\u7763\u8bc4\u4f30\u5206\u7c7b\u5668\u7684\u903b\u8f91\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u5206\u7c7b\u5668\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u548c\u5206\u6b67\u6765\u63a8\u65ad\u5176\u6027\u80fd\uff0c\u65e0\u9700\u771f\u5b9e\u6807\u7b7e\u3002", "motivation": "\u63a2\u7d22\u5206\u7c7b\u5668\u8bc4\u4f30\u4e2d\u4e00\u81f4\u6027\u4e0e\u5206\u6b67\u7684\u4e0d\u5bf9\u79f0\u6027\uff0c\u5f00\u53d1\u4ec5\u57fa\u4e8e\u903b\u8f91\u4e00\u81f4\u6027\u7684\u65e0\u76d1\u7763\u8bc4\u4f30\u65b9\u6cd5\uff0c\u65e0\u9700\u771f\u5b9e\u6807\u7b7e\u5373\u53ef\u68c0\u6d4b\u6a21\u578b\u6027\u80fd\u95ee\u9898\u3002", "method": "\u5c06\u5206\u7c7b\u5668\u5bf9\u9f50\u51b3\u7b56\u7684\u7edf\u8ba1\u6458\u8981\u4f5c\u4e3a\u7ebf\u6027\u89c4\u5212\u95ee\u9898\u7684\u8f93\u5165\uff0c\u5728\u6574\u6570\u7a7a\u95f4\u4e2d\u5efa\u6a21\u6b63\u786e\u6216\u9519\u8bef\u54cd\u5e94\u7684\u53ef\u80fd\u7ec4\u5408\uff0c\u5e94\u7528\u903b\u8f91\u7ea6\u675f\u548c\u666e\u9002\u6027\u516c\u7406\u3002", "result": "\u6784\u5efa\u4e86\u65e0\u9700\u77e5\u8bc6\u7684\u8b66\u62a5\u7cfb\u7edf\uff0c\u80fd\u591f\u68c0\u6d4bLLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u662f\u5426\u8fdd\u53cd\u7528\u6237\u6307\u5b9a\u7684\u6700\u4f4e\u8bc4\u5206\u9608\u503c\uff0c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u5b9e\u9645\u6548\u7528\u3002", "conclusion": "\u57fa\u4e8e\u903b\u8f91\u4e00\u81f4\u6027\u7684\u65e0\u76d1\u7763\u8bc4\u4f30\u65b9\u6cd5\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u5206\u7c7b\u5668\u6027\u80fd\u95ee\u9898\uff0c\u65e0\u9700\u4f9d\u8d56\u771f\u5b9e\u6807\u7b7e\u4fe1\u606f\u3002"}}
{"id": "2510.00831", "categories": ["cs.AI", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.00831", "abs": "https://arxiv.org/abs/2510.00831", "authors": ["Julian Oelhaf", "Georg Kordowich", "Changhun Kim", "Paula Andrea P\u00e9rez-Toro", "Christian Bergler", "Andreas Maier", "Johann J\u00e4ger", "Siming Bayer"], "title": "Benchmarking Machine Learning Models for Fault Classification and Localization in Power System Protection", "comment": "Submitted to ICASSP 2026; under review", "summary": "The increasing integration of distributed energy resources (DERs),\nparticularly renewables, poses significant challenges for power system\nprotection, with fault classification (FC) and fault localization (FL) being\namong the most critical tasks. Conventional protection schemes, based on fixed\nthresholds, cannot reliably identify and localize short circuits with the\nincreasing complexity of the grid under dynamic conditions. Machine learning\n(ML) offers a promising alternative; however, systematic benchmarks across\nmodels and settings remain limited. This work presents, for the first time, a\ncomparative benchmarking study of classical ML models for FC and FL in power\nsystem protection based on EMT data. Using voltage and current waveforms\nsegmented into sliding windows of 10 ms to 50 ms, we evaluate models under\nrealistic real-time constraints. Performance is assessed in terms of accuracy,\nrobustness to window size, and runtime efficiency. The best-performing FC model\nachieved an F1 score of 0.992$\\pm$0.001, while the top FL model reached an R2\nof 0.806$\\pm$0.008 with a mean processing time of 0.563 ms.", "AI": {"tldr": "\u672c\u6587\u5bf9\u7535\u529b\u7cfb\u7edf\u4fdd\u62a4\u4e2d\u7684\u6545\u969c\u5206\u7c7b\u548c\u6545\u969c\u5b9a\u4f4d\u8fdb\u884c\u4e86\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6bd4\u8f83\u57fa\u51c6\u7814\u7a76\uff0c\u57fa\u4e8eEMT\u6570\u636e\u8bc4\u4f30\u4e86\u7ecf\u5178ML\u6a21\u578b\u5728\u4e0d\u540c\u7a97\u53e3\u5927\u5c0f\u4e0b\u7684\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u968f\u7740\u5206\u5e03\u5f0f\u80fd\u6e90\u8d44\u6e90\u7279\u522b\u662f\u53ef\u518d\u751f\u80fd\u6e90\u7684\u96c6\u6210\u589e\u52a0\uff0c\u7535\u529b\u7cfb\u7edf\u4fdd\u62a4\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002\u4f20\u7edf\u7684\u57fa\u4e8e\u56fa\u5b9a\u9608\u503c\u7684\u4fdd\u62a4\u65b9\u6848\u5728\u52a8\u6001\u6761\u4ef6\u4e0b\u65e0\u6cd5\u53ef\u9760\u8bc6\u522b\u548c\u5b9a\u4f4d\u77ed\u8def\u6545\u969c\uff0c\u800c\u673a\u5668\u5b66\u4e60\u7684\u7cfb\u7edf\u5316\u57fa\u51c6\u7814\u7a76\u4ecd\u7136\u6709\u9650\u3002", "method": "\u4f7f\u7528\u7535\u538b\u548c\u7535\u6d41\u6ce2\u5f62\u6570\u636e\uff0c\u5c06\u5176\u5206\u5272\u4e3a10-50\u6beb\u79d2\u7684\u6ed1\u52a8\u7a97\u53e3\uff0c\u5728\u5b9e\u65f6\u7ea6\u675f\u4e0b\u8bc4\u4f30\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002\u8bc4\u4f30\u6307\u6807\u5305\u62ec\u51c6\u786e\u6027\u3001\u5bf9\u7a97\u53e3\u5927\u5c0f\u7684\u9c81\u68d2\u6027\u548c\u8fd0\u884c\u65f6\u6548\u7387\u3002", "result": "\u6700\u4f73\u6545\u969c\u5206\u7c7b\u6a21\u578bF1\u5f97\u5206\u4e3a0.992\u00b10.001\uff0c\u6700\u4f73\u6545\u969c\u5b9a\u4f4d\u6a21\u578bR2\u5f97\u5206\u4e3a0.806\u00b10.008\uff0c\u5e73\u5747\u5904\u7406\u65f6\u95f4\u4e3a0.563\u6beb\u79d2\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u7535\u529b\u7cfb\u7edf\u6545\u969c\u5206\u7c7b\u548c\u5b9a\u4f4d\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u6ee1\u8db3\u5b9e\u65f6\u4fdd\u62a4\u8981\u6c42\uff0c\u4e3a\u590d\u6742\u7535\u7f51\u6761\u4ef6\u4e0b\u7684\u4fdd\u62a4\u65b9\u6848\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2510.00836", "categories": ["cs.AI", "cs.CE", "q-fin.RM"], "pdf": "https://arxiv.org/pdf/2510.00836", "abs": "https://arxiv.org/abs/2510.00836", "authors": ["Jieun Yu", "Minjung Park", "Sangmi Chai"], "title": "Improving Cryptocurrency Pump-and-Dump Detection through Ensemble-Based Models and Synthetic Oversampling Techniques", "comment": null, "summary": "This study aims to detect pump and dump (P&D) manipulation in cryptocurrency\nmarkets, where the scarcity of such events causes severe class imbalance and\nhinders accurate detection. To address this issue, the Synthetic Minority\nOversampling Technique (SMOTE) was applied, and advanced ensemble learning\nmodels were evaluated to distinguish manipulative trading behavior from normal\nmarket activity. The experimental results show that applying SMOTE greatly\nenhanced the ability of all models to detect P&D events by increasing recall\nand improving the overall balance between precision and recall. In particular,\nXGBoost and LightGBM achieved high recall rates (94.87% and 93.59%,\nrespectively) with strong F1-scores and demonstrated fast computational\nperformance, making them suitable for near real time surveillance. These\nfindings indicate that integrating data balancing techniques with ensemble\nmethods significantly improves the early detection of manipulative activities,\ncontributing to a fairer, more transparent, and more stable cryptocurrency\nmarket.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528SMOTE\u6280\u672f\u89e3\u51b3\u52a0\u5bc6\u8d27\u5e01\u5e02\u573a\u4e2dPump and Dump\u64cd\u7eb5\u68c0\u6d4b\u7684\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u7ed3\u5408\u96c6\u6210\u5b66\u4e60\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u52a0\u5bc6\u8d27\u5e01\u5e02\u573a\u4e2dPump and Dump\u64cd\u7eb5\u4e8b\u4ef6\u7a00\u7f3a\u5bfc\u81f4\u4e25\u91cd\u7684\u7c7b\u522b\u4e0d\u5e73\u8861\uff0c\u963b\u788d\u4e86\u51c6\u786e\u7684\u68c0\u6d4b\u3002", "method": "\u5e94\u7528SMOTE\u6280\u672f\u8fdb\u884c\u6570\u636e\u5e73\u8861\uff0c\u5e76\u8bc4\u4f30\u5148\u8fdb\u7684\u96c6\u6210\u5b66\u4e60\u6a21\u578b\u6765\u533a\u5206\u64cd\u7eb5\u4ea4\u6613\u884c\u4e3a\u548c\u6b63\u5e38\u5e02\u573a\u6d3b\u52a8\u3002", "result": "SMOTE\u663e\u8457\u63d0\u9ad8\u4e86\u6240\u6709\u6a21\u578b\u7684\u68c0\u6d4b\u80fd\u529b\uff0cXGBoost\u548cLightGBM\u5206\u522b\u8fbe\u523094.87%\u548c93.59%\u7684\u53ec\u56de\u7387\uff0c\u5177\u6709\u5f3aF1\u5206\u6570\u548c\u5feb\u901f\u8ba1\u7b97\u6027\u80fd\u3002", "conclusion": "\u6570\u636e\u5e73\u8861\u6280\u672f\u4e0e\u96c6\u6210\u65b9\u6cd5\u7684\u7ed3\u5408\u663e\u8457\u6539\u5584\u4e86\u64cd\u7eb5\u6d3b\u52a8\u7684\u65e9\u671f\u68c0\u6d4b\uff0c\u6709\u52a9\u4e8e\u5efa\u7acb\u66f4\u516c\u5e73\u3001\u900f\u660e\u548c\u7a33\u5b9a\u7684\u52a0\u5bc6\u8d27\u5e01\u5e02\u573a\u3002"}}
{"id": "2510.00844", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00844", "abs": "https://arxiv.org/abs/2510.00844", "authors": ["Jianhao Chen", "Chenxu Wang", "Gengrui Zhang", "Peng Ye", "Lei Bai", "Wei Hu", "Yuzhong Qu", "Shuyue Hu"], "title": "Learning Compact Representations of LLM Abilities via Item Response Theory", "comment": null, "summary": "Recent years have witnessed a surge in the number of large language models\n(LLMs), yet efficiently managing and utilizing these vast resources remains a\nsignificant challenge. In this work, we explore how to learn compact\nrepresentations of LLM abilities that can facilitate downstream tasks, such as\nmodel routing and performance prediction on new benchmarks. We frame this\nproblem as estimating the probability that a given model will correctly answer\na specific query. Inspired by the item response theory (IRT) in psychometrics,\nwe model this probability as a function of three key factors: (i) the model's\nmulti-skill ability vector, (2) the query's discrimination vector that\nseparates models of differing skills, and (3) the query's difficulty scalar. To\nlearn these parameters jointly, we introduce a Mixture-of-Experts (MoE) network\nthat couples model- and query-level embeddings. Extensive experiments\ndemonstrate that our approach leads to state-of-the-art performance in both\nmodel routing and benchmark accuracy prediction. Moreover, analysis validates\nthat the learned parameters encode meaningful, interpretable information about\nmodel capabilities and query characteristics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9879\u76ee\u53cd\u5e94\u7406\u8bba(IRT)\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b66\u4e60LLM\u7684\u7d27\u51d1\u8868\u793a\u6765\u6539\u8fdb\u6a21\u578b\u8def\u7531\u548c\u6027\u80fd\u9884\u6d4b\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u6570\u91cf\u6fc0\u589e\uff0c\u5982\u4f55\u6709\u6548\u7ba1\u7406\u548c\u5229\u7528\u8fd9\u4e9b\u8d44\u6e90\u6210\u4e3a\u91cd\u8981\u6311\u6218\u3002\u9700\u8981\u5b66\u4e60\u7d27\u51d1\u7684LLM\u80fd\u529b\u8868\u793a\u6765\u652f\u6301\u4e0b\u6e38\u4efb\u52a1\u3002", "method": "\u53d7IRT\u542f\u53d1\uff0c\u5c06\u6a21\u578b\u6b63\u786e\u56de\u7b54\u67e5\u8be2\u7684\u6982\u7387\u5efa\u6a21\u4e3a\u4e09\u4e2a\u56e0\u7d20\u7684\u51fd\u6570\uff1a\u6a21\u578b\u591a\u6280\u80fd\u80fd\u529b\u5411\u91cf\u3001\u67e5\u8be2\u533a\u5206\u5ea6\u5411\u91cf\u548c\u67e5\u8be2\u96be\u5ea6\u6807\u91cf\u3002\u4f7f\u7528\u6df7\u5408\u4e13\u5bb6\u7f51\u7edc\u8054\u5408\u5b66\u4e60\u8fd9\u4e9b\u53c2\u6570\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u6a21\u578b\u8def\u7531\u548c\u57fa\u51c6\u51c6\u786e\u7387\u9884\u6d4b\u65b9\u9762\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5b66\u4e60\u5230\u7684\u53c2\u6570\u80fd\u591f\u7f16\u7801\u6709\u610f\u4e49\u3001\u53ef\u89e3\u91ca\u7684\u6a21\u578b\u80fd\u529b\u548c\u67e5\u8be2\u7279\u5f81\u4fe1\u606f\u3002", "conclusion": "\u57fa\u4e8eIRT\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5b66\u4e60LLM\u7684\u7d27\u51d1\u8868\u793a\uff0c\u4e3a\u6a21\u578b\u7ba1\u7406\u548c\u6027\u80fd\u9884\u6d4b\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2510.00876", "categories": ["cs.AI", "68T20", "I.2.8"], "pdf": "https://arxiv.org/pdf/2510.00876", "abs": "https://arxiv.org/abs/2510.00876", "authors": ["Pietro Totis", "Alberto Pozanco", "Daniel Borrajo"], "title": "Unveiling Interesting Insights: Monte Carlo Tree Search for Knowledge Discovery", "comment": null, "summary": "Organizations are increasingly focused on leveraging data from their\nprocesses to gain insights and drive decision-making. However, converting this\ndata into actionable knowledge remains a difficult and time-consuming task.\nThere is often a gap between the volume of data collected and the ability to\nprocess and understand it, which automated knowledge discovery aims to fill.\nAutomated knowledge discovery involves complex open problems, including\neffectively navigating data, building models to extract implicit relationships,\nand considering subjective goals and knowledge. In this paper, we introduce a\nnovel method for Automated Insights and Data Exploration (AIDE), that serves as\na robust foundation for tackling these challenges through the use of Monte\nCarlo Tree Search (MCTS). We evaluate AIDE using both real-world and synthetic\ndata, demonstrating its effectiveness in identifying data transformations and\nmodels that uncover interesting data patterns. Among its strengths, AIDE's\nMCTS-based framework offers significant extensibility, allowing for future\nintegration of additional pattern extraction strategies and domain knowledge.\nThis makes AIDE a valuable step towards developing a comprehensive solution for\nautomated knowledge discovery.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22(MCTS)\u7684\u81ea\u52a8\u6d1e\u5bdf\u548c\u6570\u636e\u63a2\u7d22(AIDE)\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u4ece\u6570\u636e\u4e2d\u81ea\u52a8\u53d1\u73b0\u77e5\u8bc6\u7684\u6311\u6218\u3002", "motivation": "\u7ec4\u7ec7\u6536\u96c6\u4e86\u5927\u91cf\u6570\u636e\u4f46\u96be\u4ee5\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u77e5\u8bc6\uff0c\u81ea\u52a8\u77e5\u8bc6\u53d1\u73b0\u9762\u4e34\u6570\u636e\u5bfc\u822a\u3001\u6a21\u578b\u6784\u5efa\u548c\u4e3b\u89c2\u76ee\u6807\u7b49\u590d\u6742\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22(MCTS)\u6846\u67b6\u6784\u5efaAIDE\u7cfb\u7edf\uff0c\u901a\u8fc7\u63a2\u7d22\u6570\u636e\u8f6c\u6362\u548c\u6a21\u578b\u6765\u53d1\u73b0\u6709\u8da3\u7684\u6570\u636e\u6a21\u5f0f\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u548c\u5408\u6210\u6570\u636e\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cAIDE\u80fd\u6709\u6548\u8bc6\u522b\u6570\u636e\u8f6c\u6362\u548c\u6a21\u578b\uff0c\u63ed\u793a\u6709\u610f\u4e49\u7684\u6570\u636e\u6a21\u5f0f\u3002", "conclusion": "AIDE\u4e3a\u81ea\u52a8\u77e5\u8bc6\u53d1\u73b0\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u57fa\u7840\u6846\u67b6\uff0c\u672a\u6765\u53ef\u96c6\u6210\u66f4\u591a\u6a21\u5f0f\u63d0\u53d6\u7b56\u7565\u548c\u9886\u57df\u77e5\u8bc6\u3002"}}
{"id": "2510.00894", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00894", "abs": "https://arxiv.org/abs/2510.00894", "authors": ["Ran Liu", "Yuan Fang", "Xiaoli Li"], "title": "FusionAdapter for Few-Shot Relation Learning in Multimodal Knowledge Graphs", "comment": "Archived paper", "summary": "Multimodal Knowledge Graphs (MMKGs) incorporate various modalities, including\ntext and images, to enhance entity and relation representations. Notably,\ndifferent modalities for the same entity often present complementary and\ndiverse information. However, existing MMKG methods primarily align modalities\ninto a shared space, which tends to overlook the distinct contributions of\nspecific modalities, limiting their performance particularly in low-resource\nsettings. To address this challenge, we propose FusionAdapter for the learning\nof few-shot relationships (FSRL) in MMKG. FusionAdapter introduces (1) an\nadapter module that enables efficient adaptation of each modality to unseen\nrelations and (2) a fusion strategy that integrates multimodal entity\nrepresentations while preserving diverse modality-specific characteristics. By\neffectively adapting and fusing information from diverse modalities,\nFusionAdapter improves generalization to novel relations with minimal\nsupervision. Extensive experiments on two benchmark MMKG datasets demonstrate\nthat FusionAdapter achieves superior performance over state-of-the-art methods.", "AI": {"tldr": "FusionAdapter\u662f\u4e00\u4e2a\u7528\u4e8e\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u4e2d\u5c11\u6837\u672c\u5173\u7cfb\u5b66\u4e60\u7684\u6a21\u578b\uff0c\u901a\u8fc7\u9002\u914d\u5668\u6a21\u5757\u548c\u878d\u5408\u7b56\u7565\u6709\u6548\u6574\u5408\u591a\u6a21\u6001\u4fe1\u606f\uff0c\u5728\u4f4e\u8d44\u6e90\u8bbe\u7f6e\u4e0b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709MMKG\u65b9\u6cd5\u4e3b\u8981\u5c06\u4e0d\u540c\u6a21\u6001\u5bf9\u9f50\u5230\u5171\u4eab\u7a7a\u95f4\uff0c\u5ffd\u89c6\u4e86\u7279\u5b9a\u6a21\u6001\u7684\u72ec\u7279\u8d21\u732e\uff0c\u5728\u4f4e\u8d44\u6e90\u8bbe\u7f6e\u4e0b\u6027\u80fd\u53d7\u9650\u3002", "method": "\u63d0\u51faFusionAdapter\uff0c\u5305\u542b\u9002\u914d\u5668\u6a21\u5757\u5b9e\u73b0\u5404\u6a21\u6001\u5bf9\u672a\u89c1\u5173\u7cfb\u7684\u6709\u6548\u9002\u5e94\uff0c\u4ee5\u53ca\u878d\u5408\u7b56\u7565\u5728\u4fdd\u7559\u6a21\u6001\u7279\u5b9a\u7279\u5f81\u7684\u540c\u65f6\u6574\u5408\u591a\u6a21\u6001\u5b9e\u4f53\u8868\u793a\u3002", "result": "\u5728\u4e24\u4e2a\u57fa\u51c6MMKG\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cFusionAdapter\u5728\u5c11\u6837\u672c\u5173\u7cfb\u5b66\u4e60\u4efb\u52a1\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u6709\u6548\u9002\u5e94\u548c\u878d\u5408\u6765\u81ea\u4e0d\u540c\u6a21\u6001\u7684\u4fe1\u606f\uff0cFusionAdapter\u80fd\u591f\u4ee5\u6700\u5c11\u7684\u76d1\u7763\u5b9e\u73b0\u5bf9\u65b0\u9896\u5173\u7cfb\u7684\u66f4\u597d\u6cdb\u5316\u3002"}}
{"id": "2510.00922", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.00922", "abs": "https://arxiv.org/abs/2510.00922", "authors": ["Shashank Reddy Chirra", "Jayden Teoh", "Praveen Paruchuri", "Pradeep Varakantham"], "title": "On Discovering Algorithms for Adversarial Imitation Learning", "comment": null, "summary": "Adversarial Imitation Learning (AIL) methods, while effective in settings\nwith limited expert demonstrations, are often considered unstable. These\napproaches typically decompose into two components: Density Ratio (DR)\nestimation $\\frac{\\rho_E}{\\rho_{\\pi}}$, where a discriminator estimates the\nrelative occupancy of state-action pairs under the policy versus the expert;\nand Reward Assignment (RA), where this ratio is transformed into a reward\nsignal used to train the policy. While significant research has focused on\nimproving density estimation, the role of reward assignment in influencing\ntraining dynamics and final policy performance has been largely overlooked. RA\nfunctions in AIL are typically derived from divergence minimization objectives,\nrelying heavily on human design and ingenuity. In this work, we take a\ndifferent approach: we investigate the discovery of data-driven RA functions,\ni.e, based directly on the performance of the resulting imitation policy. To\nthis end, we leverage an LLM-guided evolutionary framework that efficiently\nexplores the space of RA functions, yielding \\emph{Discovered Adversarial\nImitation Learning} (DAIL), the first meta-learnt AIL algorithm. Remarkably,\nDAIL generalises across unseen environments and policy optimization algorithms,\noutperforming the current state-of-the-art of \\emph{human-designed} baselines.\nFinally, we analyse why DAIL leads to more stable training, offering novel\ninsights into the role of RA functions in the stability of AIL. Code is\npublicly available: https://github.com/shshnkreddy/DAIL.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86DAIL\u7b97\u6cd5\uff0c\u901a\u8fc7LLM\u5f15\u5bfc\u7684\u8fdb\u5316\u6846\u67b6\u81ea\u52a8\u53d1\u73b0\u6570\u636e\u9a71\u52a8\u7684\u5956\u52b1\u5206\u914d\u51fd\u6570\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u6297\u6a21\u4eff\u5b66\u4e60\u7684\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u3002", "motivation": "\u5bf9\u6297\u6a21\u4eff\u5b66\u4e60(AIL)\u65b9\u6cd5\u867d\u7136\u6709\u6548\u4f46\u901a\u5e38\u4e0d\u7a33\u5b9a\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5bc6\u5ea6\u6bd4\u4f30\u8ba1\uff0c\u800c\u5956\u52b1\u5206\u914d\u51fd\u6570\u7684\u4f5c\u7528\u88ab\u5ffd\u89c6\uff0c\u4e14\u4e25\u91cd\u4f9d\u8d56\u4eba\u5de5\u8bbe\u8ba1\u3002", "method": "\u91c7\u7528LLM\u5f15\u5bfc\u7684\u8fdb\u5316\u6846\u67b6\uff0c\u5728\u5956\u52b1\u5206\u914d\u51fd\u6570\u7a7a\u95f4\u4e2d\u8fdb\u884c\u9ad8\u6548\u63a2\u7d22\uff0c\u57fa\u4e8e\u6a21\u4eff\u7b56\u7565\u7684\u6027\u80fd\u81ea\u52a8\u53d1\u73b0\u6700\u4f18\u7684\u5956\u52b1\u5206\u914d\u51fd\u6570\u3002", "result": "DAIL\u7b97\u6cd5\u5728\u672a\u89c1\u8fc7\u7684\u73af\u5883\u548c\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\u4e0a\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u8d85\u8d8a\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u7684\u4eba\u5de5\u8bbe\u8ba1\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "DAIL\u662f\u7b2c\u4e00\u4e2a\u5143\u5b66\u4e60\u7684AIL\u7b97\u6cd5\uff0c\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u5956\u52b1\u5206\u914d\u51fd\u6570\u53d1\u73b0\uff0c\u4e3aAIL\u7684\u7a33\u5b9a\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002"}}
{"id": "2510.00958", "categories": ["cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.00958", "abs": "https://arxiv.org/abs/2510.00958", "authors": ["Yoonju Sim", "Hyeonah Kim", "Changhyun Kwon"], "title": "Test-Time Search in Neural Graph Coarsening Procedures for the Capacitated Vehicle Routing Problem", "comment": null, "summary": "The identification of valid inequalities, such as the rounded capacity\ninequalities (RCIs), is a key component of cutting plane methods for the\nCapacitated Vehicle Routing Problem (CVRP). While a deep learning-based\nseparation method can learn to find high-quality cuts, our analysis reveals\nthat the model produces fewer cuts than expected because it is insufficiently\nsensitive to generate a diverse set of generated subsets. This paper proposes\nan alternative: enhancing the performance of a trained model at inference time\nthrough a new test-time search with stochasticity. First, we introduce\nstochastic edge selection into the graph coarsening procedure, replacing the\npreviously proposed greedy approach. Second, we propose the Graph Coarsening\nHistory-based Partitioning (GraphCHiP) algorithm, which leverages coarsening\nhistory to identify not only RCIs but also, for the first time, the Framed\ncapacity inequalities (FCIs). Experiments on randomly generated CVRP instances\ndemonstrate the effectiveness of our approach in reducing the dual gap compared\nto the existing neural separation method. Additionally, our method discovers\neffective FCIs on a specific instance, despite the challenging nature of\nidentifying such cuts.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u5207\u5272\u5e73\u9762\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u968f\u673a\u6027\u548c\u5386\u53f2\u4fe1\u606f\u6765\u589e\u5f3a\u6a21\u578b\u5728\u63a8\u7406\u65f6\u7684\u6027\u80fd\uff0c\u80fd\u591f\u751f\u6210\u66f4\u591a\u6837\u5316\u7684\u5207\u5272\uff0c\u5305\u62ec\u5706\u6574\u5bb9\u91cf\u4e0d\u7b49\u5f0f\u548c\u6846\u67b6\u5bb9\u91cf\u4e0d\u7b49\u5f0f\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u5206\u79bb\u65b9\u6cd5\u751f\u6210\u7684\u5207\u5272\u6570\u91cf\u4e0d\u8db3\uff0c\u56e0\u4e3a\u6a21\u578b\u5bf9\u751f\u6210\u591a\u6837\u5316\u5b50\u96c6\u7684\u654f\u611f\u6027\u4e0d\u591f\uff0c\u9700\u8981\u63d0\u5347\u6a21\u578b\u5728\u63a8\u7406\u65f6\u7684\u6027\u80fd\u3002", "method": "1. \u5728\u56fe\u7c97\u5316\u8fc7\u7a0b\u4e2d\u5f15\u5165\u968f\u673a\u8fb9\u9009\u62e9\u66ff\u4ee3\u8d2a\u5fc3\u65b9\u6cd5\uff1b2. \u63d0\u51faGraphCHiP\u7b97\u6cd5\uff0c\u5229\u7528\u7c97\u5316\u5386\u53f2\u8bc6\u522b\u5706\u6574\u5bb9\u91cf\u4e0d\u7b49\u5f0f\u548c\u6846\u67b6\u5bb9\u91cf\u4e0d\u7b49\u5f0f\u3002", "result": "\u5728\u968f\u673a\u751f\u6210\u7684CVRP\u5b9e\u4f8b\u4e0a\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u73b0\u6709\u795e\u7ecf\u5206\u79bb\u65b9\u6cd5\u80fd\u66f4\u6709\u6548\u5730\u51cf\u5c11\u5bf9\u5076\u95f4\u9699\uff0c\u5e76\u6210\u529f\u8bc6\u522b\u51fa\u6709\u6548\u7684\u6846\u67b6\u5bb9\u91cf\u4e0d\u7b49\u5f0f\u3002", "conclusion": "\u901a\u8fc7\u6d4b\u8bd5\u65f6\u641c\u7d22\u548c\u968f\u673a\u6027\u589e\u5f3a\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u5207\u5272\u5e73\u9762\u65b9\u6cd5\u4e2d\u7684\u6027\u80fd\uff0c\u751f\u6210\u66f4\u591a\u6837\u5316\u548c\u6709\u6548\u7684\u5207\u5272\u3002"}}
{"id": "2510.00960", "categories": ["cs.AI", "cs.NE", "cs.SY", "eess.SY", "I.2.6"], "pdf": "https://arxiv.org/pdf/2510.00960", "abs": "https://arxiv.org/abs/2510.00960", "authors": ["Miha O\u017ebot", "Igor \u0160krjanc", "Vitomir \u0160truc"], "title": "A Neuro-Fuzzy System for Interpretable Long-Term Stock Market Forecasting", "comment": "Published in: ERK 2025 -- 34th International Electrotechnical and\n  Computer Science Conference, Portoro\\v{z}, Slovenia, Sept. 25--26, 2025.\n  Proceedings published by Dru\\v{s}tvo Slovenska sekcija IEEE. ISSN: 2591-0442\n  (online). 4 pages, 2 figures", "summary": "In the complex landscape of multivariate time series forecasting, achieving\nboth accuracy and interpretability remains a significant challenge. This paper\nintroduces the Fuzzy Transformer (Fuzzformer), a novel recurrent neural network\narchitecture combined with multi-head self-attention and fuzzy inference\nsystems to analyze multivariate stock market data and conduct long-term time\nseries forecasting. The method leverages LSTM networks and temporal attention\nto condense multivariate data into interpretable features suitable for fuzzy\ninference systems. The resulting architecture offers comparable forecasting\nperformance to conventional models such as ARIMA and LSTM while providing\nmeaningful information flow within the network. The method was examined on the\nreal world stock market index S\\&P500. Initial results show potential for\ninterpretable forecasting and identify current performance tradeoffs,\nsuggesting practical application in understanding and forecasting stock market\nbehavior.", "AI": {"tldr": "\u63d0\u51faFuzzformer\u6a21\u578b\uff0c\u7ed3\u5408RNN\u3001\u591a\u5934\u81ea\u6ce8\u610f\u529b\u548c\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf\uff0c\u7528\u4e8e\u591a\u53d8\u91cf\u80a1\u7968\u5e02\u573a\u6570\u636e\u7684\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u5728\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\uff0c\u540c\u65f6\u5b9e\u73b0\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002", "method": "\u4f7f\u7528LSTM\u7f51\u7edc\u548c\u65f6\u95f4\u6ce8\u610f\u529b\u5c06\u591a\u53d8\u91cf\u6570\u636e\u538b\u7f29\u4e3a\u9002\u5408\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u7279\u5f81\uff0c\u7ed3\u5408\u591a\u5934\u81ea\u6ce8\u610f\u529b\u548c\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf\u3002", "result": "\u5728S&P500\u80a1\u7968\u5e02\u573a\u6307\u6570\u4e0a\u7684\u6d4b\u8bd5\u663e\u793a\uff0c\u4e0eARIMA\u548cLSTM\u7b49\u4f20\u7edf\u6a21\u578b\u76f8\u6bd4\u5177\u6709\u76f8\u5f53\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u540c\u65f6\u63d0\u4f9b\u7f51\u7edc\u5185\u90e8\u6709\u610f\u4e49\u7684\u4fe1\u606f\u6d41\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u53ef\u89e3\u91ca\u9884\u6d4b\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u867d\u7136\u5b58\u5728\u6027\u80fd\u6743\u8861\uff0c\u4f46\u5728\u7406\u89e3\u548c\u9884\u6d4b\u80a1\u5e02\u884c\u4e3a\u65b9\u9762\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.00967", "categories": ["cs.AI", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.00967", "abs": "https://arxiv.org/abs/2510.00967", "authors": ["Cong Yu", "Valter Uotila", "Shilong Deng", "Qingyuan Wu", "Tuo Shi", "Songlin Jiang", "Lei You", "Bo Zhao"], "title": "QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL", "comment": null, "summary": "Designing and optimizing task-specific quantum circuits are crucial to\nleverage the advantage of quantum computing. Recent large language model\n(LLM)-based quantum circuit generation has emerged as a promising automatic\nsolution. However, the fundamental challenges remain unaddressed: (i)\nparameterized quantum gates require precise numerical values for optimal\nperformance, which also depend on multiple aspects, including the number of\nquantum gates, their parameters, and the layout/depth of the circuits. (ii)\nLLMs often generate low-quality or incorrect quantum circuits due to the lack\nof quantum domain-specific knowledge. We propose QUASAR, an agentic\nreinforcement learning (RL) framework for quantum circuits generation and\noptimization based on tool-augmented LLMs. To align the LLM with\nquantum-specific knowledge and improve the generated quantum circuits, QUASAR\ndesigns (i) a quantum circuit verification approach with external quantum\nsimulators and (ii) a sophisticated hierarchical reward mechanism in RL\ntraining. Extensive evaluation shows improvements in both syntax and semantic\nperformance of the generated quantum circuits. When augmenting a 4B LLM, QUASAR\nhas achieved the validity of 99.31% in Pass@1 and 100% in Pass@10,\noutperforming industrial LLMs of GPT-4o, GPT-5 and DeepSeek-V3 and several\nsupervised-fine-tuning (SFT)-only and RL-only baselines.", "AI": {"tldr": "QUASAR\u662f\u4e00\u4e2a\u57fa\u4e8e\u5de5\u5177\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u91cf\u5b50\u7535\u8def\u751f\u6210\u4e0e\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u89e3\u51b3\u91cf\u5b50\u7535\u8def\u53c2\u6570\u4f18\u5316\u548cLLM\u7f3a\u4e4f\u91cf\u5b50\u9886\u57df\u77e5\u8bc6\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709LLM\u751f\u6210\u7684\u91cf\u5b50\u7535\u8def\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a(i)\u53c2\u6570\u5316\u91cf\u5b50\u95e8\u9700\u8981\u7cbe\u786e\u6570\u503c\u4f18\u5316\uff0c\u8fd9\u53d6\u51b3\u4e8e\u591a\u4e2a\u56e0\u7d20\uff1b(ii)LLM\u7f3a\u4e4f\u91cf\u5b50\u9886\u57df\u77e5\u8bc6\uff0c\u5e38\u751f\u6210\u4f4e\u8d28\u91cf\u6216\u4e0d\u6b63\u786e\u7684\u7535\u8def\u3002", "method": "\u63d0\u51faQUASAR\u6846\u67b6\uff0c\u5305\u542b\uff1a(i)\u4f7f\u7528\u5916\u90e8\u91cf\u5b50\u6a21\u62df\u5668\u7684\u7535\u8def\u9a8c\u8bc1\u65b9\u6cd5\uff1b(ii)\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u4e2d\u7684\u5206\u5c42\u5956\u52b1\u673a\u5236\u3002", "result": "\u57284B LLM\u4e0a\uff0cQUASAR\u5728Pass@1\u8fbe\u523099.31%\u6709\u6548\u6027\uff0cPass@10\u8fbe\u5230100%\uff0c\u4f18\u4e8eGPT-4o\u3001GPT-5\u3001DeepSeek-V3\u7b49\u5de5\u4e1a\u7ea7LLM\u4ee5\u53caSFT-only\u548cRL-only\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "QUASAR\u901a\u8fc7\u5de5\u5177\u589e\u5f3a\u548c\u5f3a\u5316\u5b66\u4e60\u663e\u8457\u63d0\u5347\u4e86\u91cf\u5b50\u7535\u8def\u751f\u6210\u7684\u8bed\u6cd5\u548c\u8bed\u4e49\u6027\u80fd\uff0c\u89e3\u51b3\u4e86LLM\u5728\u91cf\u5b50\u8ba1\u7b97\u9886\u57df\u7684\u77e5\u8bc6\u4e0d\u8db3\u95ee\u9898\u3002"}}
{"id": "2510.01006", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.01006", "abs": "https://arxiv.org/abs/2510.01006", "authors": ["Saravanan Venkatachalam"], "title": "Integrating AI and Ensemble Forecasting: Explainable Materials Planning with Scorecards and Trend Insights for a Large-Scale Manufacturer", "comment": null, "summary": "This paper presents a practical architecture for after-sales demand\nforecasting and monitoring that unifies a revenue- and cluster-aware ensemble\nof statistical, machine-learning, and deep-learning models with a role-driven\nanalytics layer for scorecards and trend diagnostics. The framework ingests\nexogenous signals (installed base, pricing, macro indicators, life cycle,\nseasonality) and treats COVID-19 as a distinct regime, producing country-part\nforecasts with calibrated intervals. A Pareto-aware segmentation forecasts\nhigh-revenue items individually and pools the long tail via clusters, while\nhorizon-aware ensembling aligns weights with business-relevant losses (e.g.,\nWMAPE). Beyond forecasts, a performance scorecard delivers decision-focused\ninsights: accuracy within tolerance thresholds by revenue share and count, bias\ndecomposition (over- vs under-forecast), geographic and product-family\nhotspots, and ranked root causes tied to high-impact part-country pairs. A\ntrend module tracks trajectories of MAPE/WMAPE and bias across recent months,\nflags entities that are improving or deteriorating, detects change points\naligned with known regimes, and attributes movements to lifecycle and seasonal\nfactors. LLMs are embedded in the analytics layer to generate role-aware\nnarratives and enforce reporting contracts. They standardize business\ndefinitions, automate quality checks and reconciliations, and translate\nquantitative results into concise, explainable summaries for planners and\nexecutives. The system exposes a reproducible workflow -- request\nspecification, model execution, database-backed artifacts, and AI-generated\nnarratives -- so planners can move from \"How accurate are we now?\" to \"Where is\naccuracy heading and which levers should we pull?\", closing the loop between\nforecasting, monitoring, and inventory decisions across more than 90 countries\nand about 6,000 parts.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u552e\u540e\u9700\u6c42\u9884\u6d4b\u548c\u76d1\u63a7\u7684\u5b9e\u7528\u67b6\u6784\uff0c\u96c6\u6210\u4e86\u6536\u5165\u611f\u77e5\u548c\u805a\u7c7b\u611f\u77e5\u7684\u7edf\u8ba1\u3001\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u5e76\u914d\u5907\u89d2\u8272\u9a71\u52a8\u7684\u5206\u6790\u5c42\uff0c\u7528\u4e8e\u751f\u6210\u8bc4\u5206\u5361\u548c\u8d8b\u52bf\u8bca\u65ad\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u552e\u540e\u9700\u6c42\u9884\u6d4b\u4e2d\u7684\u590d\u6742\u6027\uff0c\u5305\u62ec\u5904\u7406\u5916\u751f\u4fe1\u53f7\uff08\u5982\u5b89\u88c5\u57fa\u6570\u3001\u5b9a\u4ef7\u3001\u5b8f\u89c2\u6307\u6807\uff09\u3001COVID-19\u4f5c\u4e3a\u7279\u6b8a\u5236\u5ea6\u7684\u5f71\u54cd\uff0c\u4ee5\u53ca\u4e3a\u9ad8\u6536\u5165\u9879\u76ee\u548c\u957f\u5c3e\u9879\u76ee\u63d0\u4f9b\u5dee\u5f02\u5316\u7684\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u5e15\u7d2f\u6258\u611f\u77e5\u7684\u5206\u5272\u65b9\u6cd5\uff0c\u5bf9\u9ad8\u6536\u5165\u9879\u76ee\u8fdb\u884c\u5355\u72ec\u9884\u6d4b\uff0c\u5bf9\u957f\u5c3e\u9879\u76ee\u901a\u8fc7\u805a\u7c7b\u8fdb\u884c\u6c60\u5316\u9884\u6d4b\uff1b\u4f7f\u7528\u6c34\u5e73\u611f\u77e5\u7684\u96c6\u6210\u65b9\u6cd5\uff0c\u6839\u636e\u4e1a\u52a1\u76f8\u5173\u635f\u5931\uff08\u5982WMAPE\uff09\u8c03\u6574\u6743\u91cd\uff1b\u5d4c\u5165LLM\u751f\u6210\u89d2\u8272\u611f\u77e5\u7684\u53d9\u8ff0\u548c\u6267\u884c\u62a5\u544a\u5408\u540c\u3002", "result": "\u7cfb\u7edf\u80fd\u591f\u751f\u6210\u56fd\u5bb6-\u96f6\u4ef6\u7ea7\u522b\u7684\u9884\u6d4b\uff0c\u5e76\u5e26\u6709\u6821\u51c6\u533a\u95f4\uff1b\u63d0\u4f9b\u6027\u80fd\u8bc4\u5206\u5361\uff0c\u5305\u62ec\u51c6\u786e\u6027\u9608\u503c\u3001\u504f\u5dee\u5206\u89e3\u3001\u5730\u7406\u548c\u4ea7\u54c1\u7cfb\u5217\u70ed\u70b9\uff0c\u4ee5\u53ca\u9ad8\u5f71\u54cd\u96f6\u4ef6-\u56fd\u5bb6\u5bf9\u7684\u6839\u672c\u539f\u56e0\u6392\u540d\uff1b\u8d8b\u52bf\u6a21\u5757\u8ddf\u8e2aMAPE/WMAPE\u548c\u504f\u5dee\u7684\u8f68\u8ff9\uff0c\u68c0\u6d4b\u53d8\u5316\u70b9\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u91cd\u590d\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u4ece\u9884\u6d4b\u5230\u76d1\u63a7\u518d\u5230\u5e93\u5b58\u51b3\u7b56\uff0c\u5e2e\u52a9\u89c4\u5212\u8005\u4ece\u5173\u6ce8\u5f53\u524d\u51c6\u786e\u6027\u8f6c\u5411\u5173\u6ce8\u51c6\u786e\u6027\u8d8b\u52bf\u548c\u53ef\u64cd\u4f5c\u7684\u6760\u6746\uff0c\u5b9e\u73b0\u4e86\u572890\u591a\u4e2a\u56fd\u5bb6\u548c\u7ea66000\u4e2a\u96f6\u4ef6\u4e0a\u7684\u95ed\u73af\u7ba1\u7406\u3002"}}
{"id": "2510.01025", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.01025", "abs": "https://arxiv.org/abs/2510.01025", "authors": ["Federico Tiblias", "Irina Bigoulaeva", "Jingcheng Niu", "Simone Balloccu", "Iryna Gurevych"], "title": "Shape Happens: Automatic Feature Manifold Discovery in LLMs via Supervised Multi-Dimensional Scaling", "comment": null, "summary": "The linear representation hypothesis states that language models (LMs) encode\nconcepts as directions in their latent space, forming organized,\nmultidimensional manifolds. Prior efforts focus on discovering specific\ngeometries for specific features, and thus lack generalization. We introduce\nSupervised Multi-Dimensional Scaling (SMDS), a model-agnostic method to\nautomatically discover feature manifolds. We apply SMDS to temporal reasoning\nas a case study, finding that different features form various geometric\nstructures such as circles, lines, and clusters. SMDS reveals many insights on\nthese structures: they consistently reflect the properties of the concepts they\nrepresent; are stable across model families and sizes; actively support\nreasoning in models; and dynamically reshape in response to context changes.\nTogether, our findings shed light on the functional role of feature manifolds,\nsupporting a model of entity-based reasoning in which LMs encode and transform\nstructured representations.", "AI": {"tldr": "\u63d0\u51faSMDS\u65b9\u6cd5\u81ea\u52a8\u53d1\u73b0\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u7279\u5f81\u6d41\u5f62\uff0c\u901a\u8fc7\u65f6\u95f4\u63a8\u7406\u6848\u4f8b\u7814\u7a76\u53d1\u73b0\u7279\u5f81\u5f62\u6210\u591a\u79cd\u51e0\u4f55\u7ed3\u6784\uff0c\u63ed\u793a\u4e86\u8fd9\u4e9b\u7ed3\u6784\u7684\u7a33\u5b9a\u6027\u3001\u529f\u80fd\u6027\u548c\u52a8\u6001\u9002\u5e94\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e13\u6ce8\u4e8e\u53d1\u73b0\u7279\u5b9a\u7279\u5f81\u7684\u7279\u5b9a\u51e0\u4f55\u7ed3\u6784\uff0c\u7f3a\u4e4f\u6cdb\u5316\u6027\u3002\u9700\u8981\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u7684\u65b9\u6cd5\u6765\u81ea\u52a8\u53d1\u73b0\u7279\u5f81\u6d41\u5f62\u3002", "method": "\u5f15\u5165\u76d1\u7763\u591a\u7ef4\u7f29\u653e(SMDS)\uff0c\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u7684\u65b9\u6cd5\uff0c\u81ea\u52a8\u53d1\u73b0\u7279\u5f81\u6d41\u5f62\u3002\u4ee5\u65f6\u95f4\u63a8\u7406\u4e3a\u6848\u4f8b\u7814\u7a76\u5e94\u7528\u8be5\u65b9\u6cd5\u3002", "result": "\u53d1\u73b0\u4e0d\u540c\u7279\u5f81\u5f62\u6210\u5404\u79cd\u51e0\u4f55\u7ed3\u6784\uff08\u5706\u3001\u7ebf\u3001\u7c07\uff09\uff1b\u8fd9\u4e9b\u7ed3\u6784\u4e00\u81f4\u53cd\u6620\u6982\u5ff5\u5c5e\u6027\uff1b\u5728\u4e0d\u540c\u6a21\u578b\u5bb6\u65cf\u548c\u89c4\u6a21\u4e2d\u7a33\u5b9a\uff1b\u4e3b\u52a8\u652f\u6301\u6a21\u578b\u63a8\u7406\uff1b\u968f\u4e0a\u4e0b\u6587\u53d8\u5316\u52a8\u6001\u91cd\u5851\u3002", "conclusion": "\u7279\u5f81\u6d41\u5f62\u5728\u8bed\u8a00\u6a21\u578b\u4e2d\u5177\u6709\u529f\u80fd\u6027\u4f5c\u7528\uff0c\u652f\u6301\u57fa\u4e8e\u5b9e\u4f53\u7684\u63a8\u7406\u6a21\u578b\uff0c\u5176\u4e2d\u8bed\u8a00\u6a21\u578b\u7f16\u7801\u548c\u8f6c\u6362\u7ed3\u6784\u5316\u8868\u793a\u3002"}}
{"id": "2510.01030", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.01030", "abs": "https://arxiv.org/abs/2510.01030", "authors": ["Zach Studdiford", "Timothy T. Rogers", "Kushin Mukherjee", "Siddharth Suresh"], "title": "Uncovering the Computational Ingredients of Human-Like Representations in LLMs", "comment": "9 pages", "summary": "The ability to translate diverse patterns of inputs into structured patterns\nof behavior has been thought to rest on both humans' and machines' ability to\nlearn robust representations of relevant concepts. The rapid advancement of\ntransformer-based large language models (LLMs) has led to a diversity of\ncomputational ingredients -- architectures, fine tuning methods, and training\ndatasets among others -- but it remains unclear which of these ingredients are\nmost crucial for building models that develop human-like representations.\nFurther, most current LLM benchmarks are not suited to measuring\nrepresentational alignment between humans and models, making benchmark scores\nunreliable for assessing if current LLMs are making progress towards becoming\nuseful cognitive models. We address these limitations by first evaluating a set\nof over 70 models that widely vary in their computational ingredients on a\ntriplet similarity task, a method well established in the cognitive sciences\nfor measuring human conceptual representations, using concepts from the THINGS\ndatabase. Comparing human and model representations, we find that models that\nundergo instruction-finetuning and which have larger dimensionality of\nattention heads are among the most human aligned, while multimodal pretraining\nand parameter size have limited bearing on alignment. Correlations between\nalignment scores and scores on existing benchmarks reveal that while some\nbenchmarks (e.g., MMLU) are better suited than others (e.g., MUSR) for\ncapturing representational alignment, no existing benchmark is capable of fully\naccounting for the variance of alignment scores, demonstrating their\ninsufficiency in capturing human-AI alignment. Taken together, our findings\nhelp highlight the computational ingredients most essential for advancing LLMs\ntowards models of human conceptual representation and address a key\nbenchmarking gap in LLM evaluation.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e8670\u591a\u4e2a\u4e0d\u540c\u67b6\u6784\u7684LLM\u5728\u6982\u5ff5\u8868\u793a\u4e0a\u4e0e\u4eba\u7c7b\u7684\u5bf9\u9f50\u7a0b\u5ea6\uff0c\u53d1\u73b0\u6307\u4ee4\u5fae\u8c03\u548c\u6ce8\u610f\u529b\u5934\u7ef4\u5ea6\u662f\u5f71\u54cd\u5bf9\u9f50\u7684\u5173\u952e\u56e0\u7d20\uff0c\u800c\u591a\u6a21\u6001\u9884\u8bad\u7ec3\u548c\u53c2\u6570\u91cf\u5f71\u54cd\u6709\u9650\u3002\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u5b8c\u5168\u6355\u6349\u4eba\u673a\u5bf9\u9f50\u7a0b\u5ea6\u3002", "motivation": "\u5f53\u524dLLM\u7684\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u4e86\u591a\u6837\u5316\u7684\u8ba1\u7b97\u8981\u7d20\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u54ea\u4e9b\u8981\u7d20\u5bf9\u6784\u5efa\u5177\u6709\u4eba\u7c7b\u7c7b\u4f3c\u8868\u793a\u80fd\u529b\u7684\u6a21\u578b\u6700\u4e3a\u5173\u952e\u3002\u540c\u65f6\uff0c\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e0d\u9002\u5408\u8861\u91cf\u4eba\u7c7b\u4e0e\u6a21\u578b\u4e4b\u95f4\u7684\u8868\u793a\u5bf9\u9f50\u7a0b\u5ea6\u3002", "method": "\u4f7f\u7528\u8ba4\u77e5\u79d1\u5b66\u4e2d\u6210\u719f\u7684\u4e09\u5143\u7ec4\u76f8\u4f3c\u6027\u4efb\u52a1\uff0c\u57fa\u4e8eTHINGS\u6570\u636e\u5e93\u7684\u6982\u5ff5\uff0c\u8bc4\u4f30\u4e8670\u591a\u4e2a\u4e0d\u540c\u8ba1\u7b97\u8981\u7d20\uff08\u67b6\u6784\u3001\u5fae\u8c03\u65b9\u6cd5\u3001\u8bad\u7ec3\u6570\u636e\u7b49\uff09\u7684\u6a21\u578b\uff0c\u6bd4\u8f83\u4eba\u7c7b\u4e0e\u6a21\u578b\u7684\u8868\u793a\u5bf9\u9f50\u7a0b\u5ea6\u3002", "result": "\u7ecf\u8fc7\u6307\u4ee4\u5fae\u8c03\u7684\u6a21\u578b\u548c\u5177\u6709\u66f4\u5927\u6ce8\u610f\u529b\u5934\u7ef4\u5ea6\u7684\u6a21\u578b\u4e0e\u4eba\u7c7b\u8868\u793a\u6700\u4e3a\u5bf9\u9f50\uff1b\u591a\u6a21\u6001\u9884\u8bad\u7ec3\u548c\u53c2\u6570\u91cf\u5bf9\u5bf9\u9f50\u5f71\u54cd\u6709\u9650\uff1b\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e2dMMLU\u6bd4MUSR\u66f4\u80fd\u6355\u6349\u8868\u793a\u5bf9\u9f50\uff0c\u4f46\u6ca1\u6709\u57fa\u51c6\u80fd\u5b8c\u5168\u89e3\u91ca\u5bf9\u9f50\u5206\u6570\u7684\u65b9\u5dee\u3002", "conclusion": "\u6307\u4ee4\u5fae\u8c03\u548c\u6ce8\u610f\u529b\u5934\u7ef4\u5ea6\u662f\u63a8\u8fdbLLM\u6210\u4e3a\u4eba\u7c7b\u6982\u5ff5\u8868\u793a\u6a21\u578b\u7684\u5173\u952e\u8ba1\u7b97\u8981\u7d20\uff0c\u540c\u65f6\u586b\u8865\u4e86LLM\u8bc4\u4f30\u4e2d\u7684\u57fa\u51c6\u6d4b\u8bd5\u7a7a\u767d\u3002"}}
{"id": "2510.01038", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.01038", "abs": "https://arxiv.org/abs/2510.01038", "authors": ["Akchunya Chanchal", "David A. Kelly", "Hana Chockler"], "title": "Activation-Deactivation: A General Framework for Robust Post-hoc Explainable AI", "comment": "Preprint: Under Review", "summary": "Black-box explainability methods are popular tools for explaining the\ndecisions of image classifiers. A major drawback of these tools is their\nreliance on mutants obtained by occluding parts of the input, leading to\nout-of-distribution images. This raises doubts about the quality of the\nexplanations. Moreover, choosing an appropriate occlusion value often requires\ndomain knowledge. In this paper we introduce a novel forward-pass paradigm\nActivation-Deactivation (AD), which removes the effects of occluded input\nfeatures from the model's decision-making by switching off the parts of the\nmodel that correspond to the occlusions. We introduce ConvAD, a drop-in\nmechanism that can be easily added to any trained Convolutional Neural Network\n(CNN), and which implements the AD paradigm. This leads to more robust\nexplanations without any additional training or fine-tuning. We prove that the\nConvAD mechanism does not change the decision-making process of the network. We\nprovide experimental evaluation across several datasets and model\narchitectures. We compare the quality of AD-explanations with explanations\nachieved using a set of masking values, using the proxies of robustness, size,\nand confidence drop-off. We observe a consistent improvement in robustness of\nAD explanations (up to 62.5%) compared to explanations obtained with\nocclusions, demonstrating that ConvAD extracts more robust explanations without\nthe need for domain knowledge.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u524d\u5411\u4f20\u64ad\u8303\u5f0fActivation-Deactivation (AD)\uff0c\u901a\u8fc7\u5173\u95ed\u6a21\u578b\u4e2d\u4e0e\u906e\u6321\u90e8\u5206\u5bf9\u5e94\u7684\u7ec4\u4ef6\u6765\u6d88\u9664\u906e\u6321\u8f93\u5165\u7279\u5f81\u5bf9\u6a21\u578b\u51b3\u7b56\u7684\u5f71\u54cd\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u9ed1\u76d2\u89e3\u91ca\u65b9\u6cd5\u56e0\u906e\u6321\u5bfc\u81f4\u56fe\u50cf\u5206\u5e03\u5916\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u9ed1\u76d2\u89e3\u91ca\u65b9\u6cd5\u4f9d\u8d56\u906e\u6321\u90e8\u5206\u8f93\u5165\u6765\u751f\u6210\u89e3\u91ca\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u4f1a\u4ea7\u751f\u5206\u5e03\u5916\u56fe\u50cf\uff0c\u5f71\u54cd\u89e3\u91ca\u8d28\u91cf\uff0c\u4e14\u9009\u62e9\u5408\u9002\u906e\u6321\u503c\u9700\u8981\u9886\u57df\u77e5\u8bc6\u3002", "method": "\u63d0\u51fa\u4e86ConvAD\u673a\u5236\uff0c\u53ef\u4ee5\u8f7b\u677e\u6dfb\u52a0\u5230\u4efb\u4f55\u8bad\u7ec3\u597d\u7684CNN\u4e2d\uff0c\u5b9e\u73b0AD\u8303\u5f0f\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6216\u5fae\u8c03\u3002\u901a\u8fc7\u6570\u5b66\u8bc1\u660e\u8be5\u673a\u5236\u4e0d\u4f1a\u6539\u53d8\u7f51\u7edc\u7684\u51b3\u7b56\u8fc7\u7a0b\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u6a21\u578b\u67b6\u6784\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAD\u89e3\u91ca\u5728\u9c81\u68d2\u6027\u65b9\u9762\u76f8\u6bd4\u4f20\u7edf\u906e\u6321\u65b9\u6cd5\u6709\u663e\u8457\u63d0\u5347\uff08\u6700\u9ad8\u8fbe62.5%\uff09\uff0c\u4e14\u65e0\u9700\u9886\u57df\u77e5\u8bc6\u3002", "conclusion": "ConvAD\u80fd\u591f\u63d0\u53d6\u66f4\u9c81\u68d2\u7684\u89e3\u91ca\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u906e\u6321\u65b9\u6cd5\u56e0\u5206\u5e03\u5916\u56fe\u50cf\u548c\u9700\u8981\u9886\u57df\u77e5\u8bc6\u7684\u95ee\u9898\u3002"}}
{"id": "2510.01069", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.01069", "abs": "https://arxiv.org/abs/2510.01069", "authors": ["Elija Perrier"], "title": "Typed Chain-of-Thought: A Curry-Howard Framework for Verifying LLM Reasoning", "comment": "Under review", "summary": "While Chain-of-Thought (CoT) prompting enhances the reasoning capabilities of\nlarge language models, the faithfulness of the generated rationales remains an\nopen problem for model interpretability. We propose a novel theoretical lens\nfor this problem grounded in the Curry-Howard correspondence, which posits a\ndirect relationship between formal proofs and computer programs. Under this\nparadigm, a faithful reasoning trace is analogous to a well-typed program,\nwhere each intermediate step corresponds to a typed logical inference. We\noperationalise this analogy, presenting methods to extract and map the\ninformal, natural language steps of CoT into a formal, typed proof structure.\nSuccessfully converting a CoT trace into a well-typed proof serves as a strong,\nverifiable certificate of its computational faithfulness, moving beyond\nheuristic interpretability towards formal verification. Our framework provides\na methodology to transform plausible narrative explanations into formally\nverifiable programs, offering a path towards building more reliable and\ntrustworthy AI systems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eCurry-Howard\u5bf9\u5e94\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5c06CoT\u63a8\u7406\u8f68\u8ff9\u6620\u5c04\u4e3a\u5f62\u5f0f\u5316\u7c7b\u578b\u8bc1\u660e\u7ed3\u6784\uff0c\u4ee5\u9a8c\u8bc1\u63a8\u7406\u7684\u5fe0\u5b9e\u6027\u3002", "motivation": "CoT\u63d0\u793a\u589e\u5f3a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u751f\u6210\u63a8\u7406\u8fc7\u7a0b\u7684\u5fe0\u5b9e\u6027\u4ecd\u7136\u662f\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u7684\u5f00\u653e\u95ee\u9898\u3002", "method": "\u57fa\u4e8eCurry-Howard\u5bf9\u5e94\u5173\u7cfb\uff0c\u5c06\u975e\u6b63\u5f0f\u7684\u81ea\u7136\u8bed\u8a00CoT\u6b65\u9aa4\u63d0\u53d6\u5e76\u6620\u5c04\u5230\u5f62\u5f0f\u5316\u7684\u7c7b\u578b\u8bc1\u660e\u7ed3\u6784\u4e2d\u3002", "result": "\u6210\u529f\u5c06CoT\u8f68\u8ff9\u8f6c\u6362\u4e3a\u826f\u597d\u7c7b\u578b\u7684\u8bc1\u660e\uff0c\u53ef\u4f5c\u4e3a\u8ba1\u7b97\u5fe0\u5b9e\u6027\u7684\u53ef\u9a8c\u8bc1\u8bc1\u4e66\u3002", "conclusion": "\u8be5\u6846\u67b6\u63d0\u4f9b\u4e86\u5c06\u53ef\u4fe1\u53d9\u8ff0\u6027\u89e3\u91ca\u8f6c\u5316\u4e3a\u5f62\u5f0f\u5316\u53ef\u9a8c\u8bc1\u7a0b\u5e8f\u7684\u65b9\u6cd5\uff0c\u4e3a\u6784\u5efa\u66f4\u53ef\u9760\u548c\u53ef\u4fe1\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u8def\u5f84\u3002"}}
{"id": "2510.01088", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.01088", "abs": "https://arxiv.org/abs/2510.01088", "authors": ["Guobin Shen", "Dongcheng Zhao", "Haibo Tong", "Jindong Li", "Feifei Zhao", "Yi Zeng"], "title": "Safety Instincts: LLMs Learn to Trust Their Internal Compass for Self-Defense", "comment": null, "summary": "Ensuring Large Language Model (LLM) safety remains challenging due to the\nabsence of universal standards and reliable content validators, making it\ndifficult to obtain effective training signals. We discover that aligned models\nalready possess robust internal safety beliefs: they consistently produce\nhigh-confidence refusals to harmful requests while exhibiting high entropy when\ngenerating potentially dangerous content. This entropy gap reveals an untapped\nsignal--models intrinsically \"know\" when to refuse. We introduce Safety\nInstincts Reinforcement Learning (SIRL), which transforms this internal\nconfidence into a self-generated reward signal, eliminating dependence on\nexternal validators or human annotations. SIRL teaches models to trust their\nsafety instincts by reinforcing low-entropy refusal behaviors. Evaluated on\nLlama and Qwen models, SIRL maintains 89%+ Defense Success Rates (DSRs) against\n20+ jailbreak methods, from static prompts to adaptive attacks. Using only\n15,000 unlabeled prompts, SIRL surpasses resource-intensive supervised methods\nwhile preserving performance on mathematics, coding, and conversation\nbenchmarks. Our work demonstrates that effective alignment can emerge from\nwithin, paving the way for more autonomous and robust AI safety mechanisms that\nscale without extensive human oversight.", "AI": {"tldr": "SIRL\u65b9\u6cd5\u5229\u7528LLM\u5185\u90e8\u7684\u5b89\u5168\u7f6e\u4fe1\u5ea6\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6a21\u578b\u4fe1\u4efb\u81ea\u8eab\u7684\u5b89\u5168\u76f4\u89c9\uff0c\u65e0\u9700\u5916\u90e8\u9a8c\u8bc1\u5668\u5373\u53ef\u5b9e\u73b0\u9ad8\u6548\u5bf9\u9f50\u3002", "motivation": "\u7531\u4e8e\u7f3a\u4e4f\u901a\u7528\u6807\u51c6\u548c\u53ef\u9760\u7684\u5185\u5bb9\u9a8c\u8bc1\u5668\uff0c\u786e\u4fddLLM\u5b89\u5168\u6027\u9762\u4e34\u6311\u6218\uff0c\u96be\u4ee5\u83b7\u5f97\u6709\u6548\u7684\u8bad\u7ec3\u4fe1\u53f7\u3002", "method": "\u53d1\u73b0\u5bf9\u9f50\u6a21\u578b\u5df2\u5177\u5907\u5185\u90e8\u5b89\u5168\u4fe1\u5ff5\uff0c\u5229\u7528\u62d2\u7edd\u6709\u5bb3\u8bf7\u6c42\u65f6\u7684\u9ad8\u7f6e\u4fe1\u5ea6\u4e0e\u751f\u6210\u5371\u9669\u5185\u5bb9\u65f6\u7684\u9ad8\u71b5\u503c\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5f00\u53d1SIRL\u65b9\u6cd5\u5c06\u5185\u90e8\u7f6e\u4fe1\u5ea6\u8f6c\u5316\u4e3a\u81ea\u751f\u6210\u5956\u52b1\u4fe1\u53f7\u3002", "result": "\u5728Llama\u548cQwen\u6a21\u578b\u4e0a\u8bc4\u4f30\uff0cSIRL\u5bf920+\u79cd\u8d8a\u72f1\u65b9\u6cd5\u4fdd\u630189%+\u7684\u9632\u5fa1\u6210\u529f\u7387\uff0c\u4ec5\u4f7f\u752815,000\u4e2a\u672a\u6807\u6ce8\u63d0\u793a\u5373\u53ef\u8d85\u8d8a\u8d44\u6e90\u5bc6\u96c6\u578b\u76d1\u7763\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u6570\u5b66\u3001\u7f16\u7a0b\u548c\u5bf9\u8bdd\u57fa\u51c6\u6027\u80fd\u3002", "conclusion": "\u6709\u6548\u5bf9\u9f50\u53ef\u4ee5\u4ece\u6a21\u578b\u5185\u90e8\u4ea7\u751f\uff0c\u4e3a\u65e0\u9700\u5927\u91cf\u4eba\u5de5\u76d1\u7763\u7684\u81ea\u4e3b\u3001\u9c81\u68d2AI\u5b89\u5168\u673a\u5236\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2510.01094", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.01094", "abs": "https://arxiv.org/abs/2510.01094", "authors": ["Alexander Nasuta", "Alessandro Cisi", "Sylwia Olbrych", "Gustavo Vieira", "Rui Fernandes", "Lucas Paletta", "Marlene Mayr", "Rishyank Chevuri", "Robert Woitsch", "Hans Aoyang Zhou", "Anas Abdelrazeq", "Robert H. Schmitt"], "title": "Optimizing Fairness in Production Planning: A Human-Centric Approach to Machine and Workforce Allocation", "comment": null, "summary": "This work presents a two-layer, human-centric production planning framework\ndesigned to optimize both operational efficiency and workforce fairness in\nindustrial manufacturing. The first layer formulates the Order-Line allocation\nas a Constraint Programming (CP) problem, generating high-utilization\nproduction schedules that respect machine capacities, processing times, and due\ndates. The second layer models Worker-Line allocation as a Markov Decision\nProcess (MDP), integrating human factors such as worker preference, experience,\nresilience, and medical constraints into the assignment process. Three solution\nstrategies, greedy allocation, MCTS, and RL, are implemented and compared\nacross multiple evaluation scenarios. The proposed system is validated through\n16 test sessions with domain experts from the automotive industry, combining\nquantitative key performance indicators (KPIs) with expert ratings. Results\nindicate that the CP-based scheduling approach produces compact, feasible\nproduction plans with low tardiness, while the MDP-based worker allocation\nsignificantly improves fairness and preference alignment compared to baseline\napproaches. Domain experts rated both the Order-Line and Worker-Line components\nas effective and highlighted opportunities to further refine the objective\nfunction to penalize excessive earliness and improve continuity in worker\nassignments. Overall, the findings demonstrate that combining CP with\nlearning-based decision-making provides a robust approach for human-centric\nproduction planning. The approach enables simultaneous optimization of\nthroughput and workforce well-being, offering a practical foundation for fair\nand efficient manufacturing scheduling in industrial settings.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u53cc\u5c42\u4eba\u672c\u751f\u4ea7\u89c4\u5212\u6846\u67b6\uff0c\u7ed3\u5408\u7ea6\u675f\u89c4\u5212\uff08CP\uff09\u4f18\u5316\u751f\u4ea7\u8c03\u5ea6\u548c\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDP\uff09\u4f18\u5316\u5de5\u4eba\u5206\u914d\uff0c\u5b9e\u73b0\u8fd0\u8425\u6548\u7387\u548c\u5458\u5de5\u516c\u5e73\u6027\u7684\u5e73\u8861\u3002", "motivation": "\u5728\u5de5\u4e1a\u5236\u9020\u4e2d\u540c\u65f6\u4f18\u5316\u8fd0\u8425\u6548\u7387\u548c\u52b3\u52a8\u529b\u516c\u5e73\u6027\uff0c\u5c06\u673a\u5668\u80fd\u529b\u3001\u5904\u7406\u65f6\u95f4\u3001\u4ea4\u671f\u7b49\u8fd0\u8425\u7ea6\u675f\u4e0e\u5de5\u4eba\u504f\u597d\u3001\u7ecf\u9a8c\u3001\u9002\u5e94\u6027\u548c\u533b\u7597\u9650\u5236\u7b49\u4eba\u56e0\u56e0\u7d20\u6574\u5408\u5230\u751f\u4ea7\u89c4\u5212\u4e2d\u3002", "method": "\u7b2c\u4e00\u5c42\u4f7f\u7528\u7ea6\u675f\u89c4\u5212\uff08CP\uff09\u89e3\u51b3\u8ba2\u5355-\u4ea7\u7ebf\u5206\u914d\u95ee\u9898\uff0c\u751f\u6210\u9ad8\u5229\u7528\u7387\u7684\u751f\u4ea7\u8ba1\u5212\uff1b\u7b2c\u4e8c\u5c42\u4f7f\u7528\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDP\uff09\u89e3\u51b3\u5de5\u4eba-\u4ea7\u7ebf\u5206\u914d\u95ee\u9898\uff0c\u6574\u5408\u4eba\u56e0\u56e0\u7d20\u3002\u6bd4\u8f83\u4e86\u8d2a\u5a6a\u5206\u914d\u3001MCTS\u548cRL\u4e09\u79cd\u89e3\u51b3\u65b9\u6848\u7b56\u7565\u3002", "result": "CP\u8c03\u5ea6\u65b9\u6cd5\u4ea7\u751f\u7d27\u51d1\u3001\u53ef\u884c\u7684\u751f\u4ea7\u8ba1\u5212\uff0c\u5ef6\u8fdf\u7387\u4f4e\uff1bMDP\u5de5\u4eba\u5206\u914d\u663e\u8457\u63d0\u9ad8\u4e86\u516c\u5e73\u6027\u548c\u504f\u597d\u5339\u914d\u5ea6\u3002\u9886\u57df\u4e13\u5bb6\u8ba4\u4e3a\u4e24\u4e2a\u7ec4\u4ef6\u90fd\u6709\u6548\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u76ee\u6807\u51fd\u6570\u4ee5\u60e9\u7f5a\u8fc7\u5ea6\u63d0\u524d\u548c\u6539\u5584\u5de5\u4eba\u5206\u914d\u8fde\u7eed\u6027\u7684\u673a\u4f1a\u3002", "conclusion": "\u7ed3\u5408CP\u4e0e\u57fa\u4e8e\u5b66\u4e60\u7684\u51b3\u7b56\u4e3a\u4eba\u672c\u751f\u4ea7\u89c4\u5212\u63d0\u4f9b\u4e86\u7a33\u5065\u65b9\u6cd5\uff0c\u80fd\u591f\u540c\u65f6\u4f18\u5316\u541e\u5410\u91cf\u548c\u5458\u5de5\u798f\u7949\uff0c\u4e3a\u5de5\u4e1a\u73af\u5883\u4e2d\u7684\u516c\u5e73\u9ad8\u6548\u5236\u9020\u8c03\u5ea6\u63d0\u4f9b\u4e86\u5b9e\u7528\u57fa\u7840\u3002"}}
{"id": "2510.01114", "categories": ["cs.AI", "I.2.1; I.2.4; I.2.11"], "pdf": "https://arxiv.org/pdf/2510.01114", "abs": "https://arxiv.org/abs/2510.01114", "authors": ["Lionel Levine", "John Santerre", "Alexander S. Young", "T. Barry Levine", "Francis Campion", "Majid Sarrafzadeh"], "title": "PRISM-Consult: A Panel-of-Experts Architecture for Clinician-Aligned Diagnosis", "comment": "8 pages, 6 figures", "summary": "We present PRISM-Consult, a clinician-aligned panel-of-experts architecture\nthat extends the compact PRISM sequence model into a routed family of domain\nspecialists. Episodes are tokenized as structured clinical events; a\nlight-weight router reads the first few tokens and dispatches to specialist\nmodels (Cardiac-Vascular, Pulmonary, Gastro-Oesophageal, Musculoskeletal,\nPsychogenic). Each specialist inherits PRISM's small transformer backbone and\ntoken template, enabling parameter efficiency and interpretability. On\nreal-world Emergency Department cohorts, specialists exhibit smooth convergence\nwith low development perplexities across domains, while the router achieves\nhigh routing quality and large compute savings versus consult-all under a\nsafety-first policy. We detail the data methodology (initial vs. conclusive\nICD-9 families), routing thresholds and calibration, and report per-domain\nresults to avoid dominance by common events. The framework provides a practical\npath to safe, auditable, and low-latency consult at scale, and we outline\nvalidation steps-external/temporal replication, asymmetric life-threat\nthresholds, and multi-label arbitration-to meet prospective clinical deployment\nstandards.", "AI": {"tldr": "PRISM-Consult\u662f\u4e00\u4e2a\u4e34\u5e8a\u533b\u751f\u5bf9\u9f50\u7684\u4e13\u5bb6\u5c0f\u7ec4\u67b6\u6784\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u8def\u7531\u5668\u5c06\u6025\u8bca\u75c5\u4f8b\u5206\u53d1\u5230\u4e0d\u540c\u9886\u57df\u7684\u4e13\u79d1\u6a21\u578b\uff0c\u5b9e\u73b0\u53c2\u6570\u9ad8\u6548\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u89e3\u51b3\u6025\u8bca\u79d1\u5927\u89c4\u6a21\u54a8\u8be2\u4e2d\u5b89\u5168\u3001\u53ef\u5ba1\u8ba1\u548c\u4f4e\u5ef6\u8fdf\u7684\u9700\u6c42\uff0c\u907f\u514d\u5e38\u89c1\u4e8b\u4ef6\u4e3b\u5bfc\u7ed3\u679c\uff0c\u63d0\u4f9b\u5b9e\u7528\u7684\u4e34\u5e8a\u90e8\u7f72\u8def\u5f84\u3002", "method": "\u6269\u5c55\u7d27\u51d1\u7684PRISM\u5e8f\u5217\u6a21\u578b\u4e3a\u8def\u7531\u7684\u4e13\u79d1\u4e13\u5bb6\u5bb6\u65cf\uff0c\u5c06\u75c5\u4f8b\u6807\u8bb0\u5316\u4e3a\u7ed3\u6784\u5316\u4e34\u5e8a\u4e8b\u4ef6\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u8def\u7531\u5668\u8bfb\u53d6\u524d\u51e0\u4e2a\u6807\u8bb0\u5e76\u5206\u53d1\u5230\u4e13\u79d1\u6a21\u578b\uff08\u5fc3\u810f\u8840\u7ba1\u3001\u80ba\u3001\u80c3\u80a0\u3001\u808c\u8089\u9aa8\u9abc\u3001\u5fc3\u7406\uff09\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6025\u8bca\u79d1\u961f\u5217\u4e2d\uff0c\u4e13\u79d1\u6a21\u578b\u5728\u5404\u9886\u57df\u8868\u73b0\u51fa\u5e73\u6ed1\u6536\u655b\u548c\u4f4e\u5f00\u53d1\u56f0\u60d1\u5ea6\uff0c\u8def\u7531\u5668\u5728\u5b89\u5168\u4f18\u5148\u7b56\u7565\u4e0b\u5b9e\u73b0\u9ad8\u8d28\u91cf\u8def\u7531\u548c\u5927\u91cf\u8ba1\u7b97\u8282\u7701\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5b89\u5168\u3001\u53ef\u5ba1\u8ba1\u548c\u4f4e\u5ef6\u8fdf\u7684\u5927\u89c4\u6a21\u54a8\u8be2\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\uff0c\u5e76\u901a\u8fc7\u5916\u90e8/\u65f6\u95f4\u590d\u5236\u3001\u4e0d\u5bf9\u79f0\u751f\u547d\u5a01\u80c1\u9608\u503c\u548c\u591a\u6807\u7b7e\u4ef2\u88c1\u7b49\u9a8c\u8bc1\u6b65\u9aa4\u6ee1\u8db3\u524d\u77bb\u6027\u4e34\u5e8a\u90e8\u7f72\u6807\u51c6\u3002"}}
{"id": "2510.01115", "categories": ["cs.AI", "cs.MA", "econ.TH", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2510.01115", "abs": "https://arxiv.org/abs/2510.01115", "authors": ["Evan Heus", "Rick Bookstaber", "Dhruv Sharma"], "title": "Exploring Network-Knowledge Graph Duality: A Case Study in Agentic Supply Chain Risk Analysis", "comment": "7 pages, 3 figures", "summary": "Large Language Models (LLMs) struggle with the complex, multi-modal, and\nnetwork-native data underlying financial risk. Standard Retrieval-Augmented\nGeneration (RAG) oversimplifies relationships, while specialist models are\ncostly and static. We address this gap with an LLM-centric agent framework for\nsupply chain risk analysis. Our core contribution is to exploit the inherent\nduality between networks and knowledge graphs (KG). We treat the supply chain\nnetwork as a KG, allowing us to use structural network science principles for\nretrieval. A graph traverser, guided by network centrality scores, efficiently\nextracts the most economically salient risk paths. An agentic architecture\norchestrates this graph retrieval alongside data from numerical factor tables\nand news streams. Crucially, it employs novel ``context shells'' -- descriptive\ntemplates that embed raw figures in natural language -- to make quantitative\ndata fully intelligible to the LLM. This lightweight approach enables the model\nto generate concise, explainable, and context-rich risk narratives in real-time\nwithout costly fine-tuning or a dedicated graph database.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u4f9b\u5e94\u94fe\u7f51\u7edc\u89c6\u4e3a\u77e5\u8bc6\u56fe\u8c31\uff0c\u5229\u7528\u7f51\u7edc\u79d1\u5b66\u539f\u7406\u8fdb\u884c\u98ce\u9669\u8def\u5f84\u68c0\u7d22\uff0c\u7ed3\u5408\u4e0a\u4e0b\u6587\u6a21\u677f\u4f7f\u5b9a\u91cf\u6570\u636e\u5bf9LLM\u53ef\u7406\u89e3\uff0c\u5b9e\u73b0\u5b9e\u65f6\u3001\u53ef\u89e3\u91ca\u7684\u98ce\u9669\u5206\u6790\u3002", "motivation": "\u4f20\u7edfRAG\u65b9\u6cd5\u5728\u91d1\u878d\u98ce\u9669\u5206\u6790\u4e2d\u8fc7\u5ea6\u7b80\u5316\u5173\u7cfb\uff0c\u800c\u4e13\u4e1a\u6a21\u578b\u6210\u672c\u9ad8\u4e14\u9759\u6001\uff0c\u65e0\u6cd5\u5904\u7406\u590d\u6742\u591a\u6a21\u6001\u7684\u4f9b\u5e94\u94fe\u98ce\u9669\u6570\u636e\u3002", "method": "\u5c06\u4f9b\u5e94\u94fe\u7f51\u7edc\u5efa\u6a21\u4e3a\u77e5\u8bc6\u56fe\u8c31\uff0c\u57fa\u4e8e\u7f51\u7edc\u4e2d\u5fc3\u6027\u5206\u6570\u6307\u5bfc\u56fe\u904d\u5386\u5668\u63d0\u53d6\u5173\u952e\u98ce\u9669\u8def\u5f84\uff0c\u7ed3\u5408\u6570\u503c\u56e0\u5b50\u8868\u548c\u65b0\u95fb\u6d41\u6570\u636e\uff0c\u4f7f\u7528\u4e0a\u4e0b\u6587\u6a21\u677f\u5c06\u539f\u59cb\u6570\u636e\u8f6c\u6362\u4e3a\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u3002", "result": "\u8be5\u8f7b\u91cf\u7ea7\u65b9\u6cd5\u65e0\u9700\u6602\u8d35\u5fae\u8c03\u6216\u4e13\u7528\u56fe\u6570\u636e\u5e93\uff0c\u5373\u53ef\u751f\u6210\u7b80\u6d01\u3001\u53ef\u89e3\u91ca\u4e14\u4e0a\u4e0b\u6587\u4e30\u5bcc\u7684\u5b9e\u65f6\u98ce\u9669\u53d9\u8ff0\u3002", "conclusion": "\u5229\u7528\u7f51\u7edc\u4e0e\u77e5\u8bc6\u56fe\u8c31\u7684\u4e8c\u5143\u6027\uff0c\u901a\u8fc7\u667a\u80fd\u4f53\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e86LLM\u5728\u590d\u6742\u91d1\u878d\u98ce\u9669\u5206\u6790\u4e2d\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2510.01141", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.01141", "abs": "https://arxiv.org/abs/2510.01141", "authors": ["Shruthan Radhakrishna", "Aman Tiwari", "Aanjaneya Shukla", "Masoud Hashemi", "Rishabh Maheshwary", "Shiva Krishna Reddy Malay", "Jash Mehta", "Pulkit Pattnaik", "Saloni Mittal", "Khalil Slimi", "Kelechi Ogueji", "Akintunde Oladipo", "Soham Parikh", "Oluwanifemi Bamgbose", "Toby Liang", "Ahmed Masry", "Khyati Mahajan", "Sai Rajeswar Mudumba", "Vikas Yadav", "Sathwik Tejaswi Madhusudhan", "Torsten Scholak", "Sagar Davasam", "Srinivas Sunkara", "Nicholas Chapados"], "title": "Apriel-1.5-15b-Thinker", "comment": null, "summary": "We present Apriel-1.5-15B-Thinker, a 15-billion parameter open-weights\nmultimodal reasoning model that achieves frontier-level performance through\ntraining design rather than sheer scale. Starting from Pixtral-12B, we apply a\nprogressive three-stage methodology: (1) depth upscaling to expand reasoning\ncapacity without pretraining from scratch, (2) staged continual pre-training\nthat first develops foundational text and vision understanding, then enhances\nvisual reasoning through targeted synthetic data generation addressing spatial\nstructure, compositional understanding, and fine-grained perception, and (3)\nhigh-quality text-only supervised fine-tuning on curated instruction-response\npairs with explicit reasoning traces spanning mathematics, coding, science, and\ntool use. Notably, our model achieves competitive results without reinforcement\nlearning or preference optimization, isolating the contribution of our\ndata-centric continual pre-training approach. On the Artificial Analysis\nIntelligence Index, Apriel-1.5-15B-Thinker attains a score of 52, matching\nDeepSeek-R1-0528 despite requiring significantly fewer computational resources.\nAcross ten image benchmarks, its performance is on average within five points\nof Gemini-2.5-Flash and Claude Sonnet-3.7, a key achievement for a model\noperating within single-GPU deployment constraints. Our results demonstrate\nthat thoughtful mid-training 2 design can close substantial capability gaps\nwithout massive scale, making frontier-level multimodal reasoning accessible to\norganizations with limited infrastructure. We release the model checkpoint, all\ntraining recipes, and evaluation protocols under the MIT license to to advance\nopen-source research.", "AI": {"tldr": "Apriel-1.5-15B-Thinker\u662f\u4e00\u4e2a150\u4ebf\u53c2\u6570\u7684\u591a\u6a21\u6001\u63a8\u7406\u6a21\u578b\uff0c\u901a\u8fc7\u6e10\u8fdb\u5f0f\u4e09\u9636\u6bb5\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5728\u4e0d\u4f9d\u8d56\u5927\u89c4\u6a21\u8ba1\u7b97\u8d44\u6e90\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u524d\u6cbf\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u65e8\u5728\u8bc1\u660e\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u8bad\u7ec3\u65b9\u6cd5\u800c\u975e\u5355\u7eaf\u6269\u5927\u6a21\u578b\u89c4\u6a21\uff0c\u53ef\u4ee5\u5728\u6709\u9650\u8ba1\u7b97\u8d44\u6e90\u4e0b\u5b9e\u73b0\u524d\u6cbf\u6c34\u5e73\u7684\u591a\u6a21\u6001\u63a8\u7406\u80fd\u529b\uff0c\u4f7f\u66f4\u591a\u7ec4\u7ec7\u80fd\u591f\u90e8\u7f72\u9ad8\u6027\u80fd\u6a21\u578b\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u6e10\u8fdb\u5f0f\u8bad\u7ec3\uff1a1\uff09\u6df1\u5ea6\u6269\u5c55\u63a8\u7406\u80fd\u529b\uff1b2\uff09\u5206\u9636\u6bb5\u6301\u7eed\u9884\u8bad\u7ec3\uff0c\u5148\u5efa\u7acb\u6587\u672c\u548c\u89c6\u89c9\u57fa\u7840\u7406\u89e3\uff0c\u518d\u901a\u8fc7\u5408\u6210\u6570\u636e\u589e\u5f3a\u89c6\u89c9\u63a8\u7406\uff1b3\uff09\u9ad8\u8d28\u91cf\u6587\u672c\u76d1\u7763\u5fae\u8c03\uff0c\u5305\u542b\u663e\u5f0f\u63a8\u7406\u8f68\u8ff9\u3002", "result": "\u5728Artificial Analysis Intelligence Index\u4e0a\u83b7\u5f9752\u5206\uff0c\u4e0eDeepSeek-R1-0528\u76f8\u5f53\u4f46\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u663e\u8457\u66f4\u5c11\uff1b\u5728\u5341\u4e2a\u56fe\u50cf\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u6027\u80fd\u4ec5\u6bd4Gemini-2.5-Flash\u548cClaude Sonnet-3.7\u4f4e5\u5206\u3002", "conclusion": "\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u4e2d\u671f\u8bad\u7ec3\u7b56\u7565\u53ef\u4ee5\u5728\u4e0d\u4f9d\u8d56\u5927\u89c4\u6a21\u8ba1\u7b97\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u7f29\u5c0f\u80fd\u529b\u5dee\u8ddd\uff0c\u4f7f\u524d\u6cbf\u6c34\u5e73\u7684\u591a\u6a21\u6001\u63a8\u7406\u5bf9\u57fa\u7840\u8bbe\u65bd\u6709\u9650\u7684\u7ec4\u7ec7\u53d8\u5f97\u53ef\u884c\u3002"}}
{"id": "2510.01143", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.01143", "abs": "https://arxiv.org/abs/2510.01143", "authors": ["Harry Dong", "David Brandfonbrener", "Eryk Helenowski", "Yun He", "Mrinal Kumar", "Han Fang", "Yuejie Chi", "Karthik Abinav Sankararaman"], "title": "Generalized Parallel Scaling with Interdependent Generations", "comment": null, "summary": "Parallel LLM inference scaling involves sampling a set of $N>1$ responses for\na single input prompt. However, these $N$ parallel responses tend to be\ngenerated independently from each other, partitioning compute resources and\nleaving potentially useful information in one generation untapped by others.\nThis is in contrast to response length scaling where past computation is used\nin all future steps. For higher quality responses and response sets, we propose\nBridge to generate interdependent responses in parallel by rethinking batched\nLLM hidden states as holistic tensors rather than independent slices. With only\na small amount (2.8%-5.1%) of new parameters, Bridge improves the relative mean\naccuracy gains from reinforcement learning with verifiable rewards by up to 50%\nand boosts consistency of correct responses. Trained once, Bridge scales to any\ngeneration width, all with greater performance than independent generations,\nunlocking a more general mode of parallel scaling that effectively leverages\ninformation between sequences, compatible with any post-generation aggregation\ntechnique.", "AI": {"tldr": "Bridge\u662f\u4e00\u79cd\u5e76\u884cLLM\u63a8\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u5e76\u884c\u751f\u6210\u7684\u54cd\u5e94\u4e4b\u95f4\u5efa\u7acb\u4fe1\u606f\u6865\u6881\uff0c\u5229\u7528\u76f8\u4e92\u4f9d\u8d56\u7684\u9690\u85cf\u72b6\u6001\u6765\u63d0\u5347\u54cd\u5e94\u8d28\u91cf\u548c\u4e00\u81f4\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u5e76\u884cLLM\u63a8\u7406\u4e2d\uff0c\u591a\u4e2a\u54cd\u5e94\u662f\u72ec\u7acb\u751f\u6210\u7684\uff0c\u8ba1\u7b97\u8d44\u6e90\u88ab\u5206\u5272\uff0c\u4e00\u4e2a\u751f\u6210\u4e2d\u7684\u6709\u7528\u4fe1\u606f\u65e0\u6cd5\u88ab\u5176\u4ed6\u751f\u6210\u5229\u7528\uff0c\u8fd9\u9650\u5236\u4e86\u54cd\u5e94\u8d28\u91cf\u548c\u54cd\u5e94\u96c6\u7684\u4e00\u81f4\u6027\u3002", "method": "\u5c06\u6279\u91cfLLM\u9690\u85cf\u72b6\u6001\u91cd\u65b0\u6784\u60f3\u4e3a\u6574\u4f53\u5f20\u91cf\u800c\u975e\u72ec\u7acb\u5207\u7247\uff0c\u901a\u8fc7\u6dfb\u52a0\u5c11\u91cf\u65b0\u53c2\u6570\uff082.8%-5.1%\uff09\u6765\u751f\u6210\u76f8\u4e92\u4f9d\u8d56\u7684\u5e76\u884c\u54cd\u5e94\u3002", "result": "Bridge\u5c06\u5e26\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u7684\u76f8\u5bf9\u5e73\u5747\u51c6\u786e\u7387\u589e\u76ca\u63d0\u9ad8\u4e8650%\uff0c\u5e76\u63d0\u5347\u4e86\u6b63\u786e\u54cd\u5e94\u7684\u4e00\u81f4\u6027\u3002\u8bad\u7ec3\u4e00\u6b21\u5373\u53ef\u6269\u5c55\u5230\u4efb\u4f55\u751f\u6210\u5bbd\u5ea6\uff0c\u6027\u80fd\u59cb\u7ec8\u4f18\u4e8e\u72ec\u7acb\u751f\u6210\u3002", "conclusion": "Bridge\u89e3\u9501\u4e86\u4e00\u79cd\u66f4\u901a\u7528\u7684\u5e76\u884c\u6269\u5c55\u6a21\u5f0f\uff0c\u6709\u6548\u5229\u7528\u5e8f\u5217\u95f4\u7684\u4fe1\u606f\uff0c\u4e0e\u4efb\u4f55\u540e\u751f\u6210\u805a\u5408\u6280\u672f\u517c\u5bb9\u3002"}}
