<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 11]
- [cs.AI](#cs.AI) [Total: 6]
- [cs.SE](#cs.SE) [Total: 8]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [The Birthmark Standard: Privacy-Preserving Photo Authentication via Hardware Roots of Trust and Consortium Blockchain](https://arxiv.org/abs/2602.04933)
*Sam Ryan*

Main category: cs.CR

TL;DR: 提出Birthmark标准，利用相机传感器固有噪声特征生成硬件根密钥，通过联盟区块链存储认证记录，解决AI生成图像破坏照片证据可信度的问题。


<details>
  <summary>Details</summary>
Motivation: 生成式AI系统快速发展破坏了摄影证据的可信度，现有认证方法（如C2PA）存在技术脆弱性（元数据易被剥离）和结构性依赖（企业控制验证基础设施），商业利益可能与公共利益冲突。

Method: 利用制造独特的传感器熵（非均匀性校正图和PRNU模式）生成硬件根认证密钥；拍摄时创建匿名化认证证书，通过密钥表架构保持设备匿名性（超过1000台设备）；认证记录存储在由新闻组织运营的联盟区块链上。

Result: 使用ProVerif形式化验证隐私属性，证明在Dolev-Yao对手假设下实现制造商非相关性和区块链观察者非识别性；原型验证显示相机开销低于100ms，百万级每日认证下验证延迟低于500ms。

Conclusion: Birthmark标准提供了一种硬件根认证架构，能在所有元数据丢失情况下生存，解决了现有认证方法的技术和结构缺陷，为新闻和公共话语提供可靠的图像证据基础。

Abstract: The rapid advancement of generative AI systems has collapsed the credibility landscape for photographic evidence. Modern image generation models produce photorealistic images undermining the evidentiary foundation upon which journalism and public discourse depend. Existing authentication approaches, such as the Coalition for Content Provenance and Authenticity (C2PA), embed cryptographically signed metadata directly into image files but suffer from two critical failures: technical vulnerability to metadata stripping during social media reprocessing, and structural dependency on corporate-controlled verification infrastructure where commercial incentives may conflict with public interest. We present the Birthmark Standard, an authentication architecture leveraging manufacturing-unique sensor entropy from non-uniformity correction (NUC) maps and PRNU patterns to generate hardware-rooted authentication keys. During capture, cameras create anonymized authentication certificates proving sensor authenticity without exposing device identity via a key table architecture maintaining anonymity sets exceeding 1,000 devices. Authentication records are stored on a consortium blockchain operated by journalism organizations rather than commercial platforms, enabling verification that survives all metadata loss. We formally verify privacy properties using ProVerif, proving observational equivalence for Manufacturer Non-Correlation and Blockchain Observer Non-Identification under Dolev-Yao adversary assumptions. The architecture is validated through prototype implementation using Raspberry Pi 4 hardware, demonstrating the complete cryptographic pipeline. Performance analysis projects camera overhead below 100ms and verification latency below 500ms at scale of one million daily authentications.

</details>


### [2] [SynthForensics: A Multi-Generator Benchmark for Detecting Synthetic Video Deepfakes](https://arxiv.org/abs/2602.04939)
*Roberto Leotta,Salvatore Alfio Sambataro,Claudio Vittorio Ragaglia,Mirko Casu,Yuri Petralia,Francesco Guarnera,Luca Guarnera,Sebastiano Battiato*

Main category: cs.CR

TL;DR: SynthForensics是首个以人为中心的合成视频深度伪造检测基准，包含6,815个来自5个开源T2V模型的视频，现有检测器在该基准上性能显著下降，训练于该基准可提升泛化能力但会降低对传统篡改型深度伪造的兼容性。


<details>
  <summary>Details</summary>
Motivation: 随着开源文本到视频模型在消费级硬件上的普及，现有基于人脸和篡改的检测基准已过时，迫切需要新的基准来应对完全合成的视频深度伪造威胁。

Method: 构建包含6,815个视频的SynthForensics基准，来自5个架构不同的开源T2V模型，采用两阶段人工验证确保质量，提供四种压缩版本（原始、无损、轻度、重度压缩）进行鲁棒性测试。

Result: 现有最先进的检测器在该基准上表现脆弱且泛化能力有限：平均AUC下降29.19%，部分方法性能低于随机猜测，顶级模型在重度压缩下损失超过30个点。使用SynthForensics训练可实现对未见生成器的鲁棒泛化（93.81% AUC），但会降低与传统篡改型深度伪造的向后兼容性。

Conclusion: SynthForensics基准揭示了现有检测器对完全合成视频深度伪造的脆弱性，训练于该基准可提升泛化能力但需权衡与传统检测任务的兼容性，为未来检测器开发提供了重要基准。

Abstract: The landscape of synthetic media has been irrevocably altered by text-to-video (T2V) models, whose outputs are rapidly approaching indistinguishability from reality. Critically, this technology is no longer confined to large-scale labs; the proliferation of efficient, open-source generators is democratizing the ability to create high-fidelity synthetic content on consumer-grade hardware. This makes existing face-centric and manipulation-based benchmarks obsolete. To address this urgent threat, we introduce SynthForensics, to the best of our knowledge the first human-centric benchmark for detecting purely synthetic video deepfakes. The benchmark comprises 6,815 unique videos from five architecturally distinct, state-of-the-art open-source T2V models. Its construction was underpinned by a meticulous two-stage, human-in-the-loop validation to ensure high semantic and visual quality. Each video is provided in four versions (raw, lossless, light, and heavy compression) to enable real-world robustness testing. Experiments demonstrate that state-of-the-art detectors are both fragile and exhibit limited generalization when evaluated on this new domain: we observe a mean performance drop of $29.19\%$ AUC, with some methods performing worse than random chance, and top models losing over 30 points under heavy compression. The paper further investigates the efficacy of training on SynthForensics as a means to mitigate these observed performance gaps, achieving robust generalization to unseen generators ($93.81\%$ AUC), though at the cost of reduced backward compatibility with traditional manipulation-based deepfakes. The complete dataset and all generation metadata, including the specific prompts and inference parameters for every video, will be made publicly available at [link anonymized for review].

</details>


### [3] [System-Level Isolation for Mixed-Criticality RISC-V SoCs: A "World" Reality Check](https://arxiv.org/abs/2602.05002)
*Luis Cunha,Jose Martins,Manuel Rodriguez,Tiago Gomes,Sandro Pinto,Uwe Moslehner,Kai Dieffenbach,Glenn Farrall,Kajetan Nuernberger,Thomas Roecker*

Main category: cs.CR

TL;DR: 本文对RISC-V硬件隔离原语（IOPMP、World-based checker等）在异构SoC中的实际应用进行了比较分析，评估了它们在安全性、性能、面积等方面的权衡，提出了改进方案以减少SoC面积约5%。


<details>
  <summary>Details</summary>
Motivation: 随着RISC-V在汽车、物联网和工业控制等领域的加速采用，这些领域受到严格的SWaP-C约束，推动了异构SoC的发展。然而，这种集成带来了混合关键性环境中的系统级隔离挑战，现有RISC-V硬件隔离原语的互操作性、可扩展性和实时系统适用性尚未得到充分理解。

Method: 对RISC-V Worlds、IOPMP和SmMTT等硬件隔离原语进行比较分析，实现了IOPMP、基于World的检查器，以及改进的RISC-V World检查器以解决基线规范的关键限制，评估它们在安全保证和功耗-性能-面积（PPA）方面的权衡。

Result: 基于World的检查器引入了固定且与配置无关的访问延迟，实现了比评估替代方案更低的worst-case延迟，并能随系统规模可预测地扩展。在宏观层面，提出的修改相比基线设计可减少SoC面积约5%。

Conclusion: 研究结果将直接贡献于RISC-V规范的演进和标准化，以及未来RISC-V SoC的设计。所有工作成果将作为开源发布，为异构SoC中的系统级隔离提供实用指导。

Abstract: As RISC-V adoption accelerates, domains such as automotive, the Internet of Things (IoT), and industrial control are attracting growing attention. These domains are subject to stringent Size, Weight, Power, and Cost (SWaP-C) constraints, which have driven a shift toward heterogeneous Systems-on-Chip (SoCs) integrating general-purpose CPUs, tightly coupled accelerators, and diverse I/O devices with different integrity levels. While such integration improves cost efficiency and performance, it introduces a fundamental safety and security challenge: enforcing system-level isolation in mixed-criticality environments. Although RISC-V International has proposed several hardware isolation primitives, including RISC-V Worlds, IOPMP, and SmMTT, their interoperability, scalability, and suitability for real-time systems remain insufficiently understood. In this paper, we present a comparative analysis of these primitives from the perspective of practical heterogeneous SoC designs. We implement an IOPMP, a World-based checker, and a modified RISC-V World checker that addresses key limitations of the baseline specification, and evaluate their trade-offs in terms of security guarantees and power-performance-area (PPA). Our results show that the World-based checker introduces a fixed, configuration-independent access latency, achieving lower worst-case delay than the evaluated alternatives while scaling predictably with system size. At the macro level, we estimate that the proposed modifications reduce SoC area by up to approximately 5% compared to a baseline design. All artifacts will be released as open source, and we expect these findings to directly contribute to the evolution and ratification of RISC-V specifications, as well as to the design of future RISC-V SoCs.

</details>


### [4] [VEXA: Evidence-Grounded and Persona-Adaptive Explanations for Scam Risk Sensemaking](https://arxiv.org/abs/2602.05056)
*Heajun An,Connor Ng,Sandesh Sharma Dulal,Junghwan Kim,Jin-Hee Cho*

Main category: cs.CR

TL;DR: VEXA框架通过结合梯度SHAP归因和理论驱动的人物角色，为在线诈骗检测生成面向学习者的、证据基础的解释，提高语义可靠性而不增加语言复杂性。


<details>
  <summary>Details</summary>
Motivation: 生成式AI使得在线诈骗更加流畅和情境感知，给日常风险评估带来挑战。虽然基于Transformer的检测器有很强的预测性能，但其解释对非专家不透明或与模型决策不一致。

Method: 提出VEXA框架，整合基于GradientSHAP的归因和理论驱动的人物角色，生成面向学习者的诈骗解释。该方法在多渠道数据集上进行评估。

Result: 基于检测器证据的解释提高了语义可靠性而不增加语言复杂性，人物角色调节引入了可解释的风格变化而不破坏证据对齐。证据基础控制语义正确性，人物角色适应在忠实性约束下操作于呈现层面。

Conclusion: VEXA展示了人物角色适应、证据基础解释的可行性，为非正式情境中面向学习者的可信安全解释提供了设计指导。

Abstract: Online scams across email, short message services, and social media increasingly challenge everyday risk assessment, particularly as generative AI enables more fluent and context-aware deception. Although transformer-based detectors achieve strong predictive performance, their explanations are often opaque to non-experts or misaligned with model decisions. We propose VEXA, an evidence-grounded and persona-adaptive framework for generating learner-facing scam explanations by integrating GradientSHAP-based attribution with theory-informed vulnerability personas. Evaluation across multi-channel datasets shows that grounding explanations in detector-derived evidence improves semantic reliability without increasing linguistic complexity, while persona conditioning introduces interpretable stylistic variation without disrupting evidential alignment. These results reveal a key design insight: evidential grounding governs semantic correctness, whereas persona-based adaptation operates at the level of presentation under constraints of faithfulness. Together, VEXA demonstrates the feasibility of persona-adaptive, evidence-grounded explanations and provides design guidance for trustworthy, learner-facing security explanations in non-formal contexts.

</details>


### [5] [Crypto-asset Taxonomy for Investors and Regulators](https://arxiv.org/abs/2602.05098)
*Xiao Zhang,Juan Ignacio Ibañez,Jiahua Xu*

Main category: cs.CR

TL;DR: 该论文为加密资产开发了一个多维分类框架，将技术设计与市场结构和监管联系起来，填补了该领域缺乏统一分类体系的空白。


<details>
  <summary>Details</summary>
Motivation: 加密资产已成为电子市场的主要组成部分，交易量和市场份额不断增长，但目前缺乏统一全面的资产级别分类框架。需要建立一个能够连接技术设计、市场结构和监管的分类体系。

Method: 基于既定的分类指南和现有模型，从理论、监管框架和案例研究中推导维度，然后在前100种资产中应用该结构，并提供多个详细案例研究。

Result: 分类框架涵盖技术标准、关键资源集中度、资产功能、法律分类以及铸造、收益、赎回等机制设计。资产映射和案例研究揭示了重复的设计模式，捕捉了现有分类边界上的边缘案例特征，并记录了名义去中心化资产中的集中控制现象。

Conclusion: 该论文为加密市场的系统研究提供了框架，支持监管机构评估代币风险，并为投资者和数字平台设计者在构建或参与电子市场时提供了比较资产的工具。

Abstract: Crypto-assets are a main segment of electronic markets, with growing trade volume and market share, yet there's no unified and comprehensive asset level taxonomy framework. This paper develops a multidimensional taxonomy for crypto-assets that connects technical design to market structure and regulation. Building on established taxonomy guideline and existing models, we derive dimensions from theory, regulatory frameworks, and case studies. We then map top 100 assets within the structure and provide several detailed case studies. The taxonomy covers technology standard, centralisation of critical resources, asset function, legal classification and mechanism designs of minting, yield, redemption. The asset mapping and case studies reveal recurring design patterns, capture features of edge cases that sit on boundaries of current categorisations, and document centralised control of nominal decentralised assets. This paper provides framework for systematic study for crypto markets, supports regulators in assessing token risks, and offers investors and digital platform designers a tool to compare assets when building or participate in electronic markets.

</details>


### [6] [LTRAS: A Linkable Threshold Ring Adaptor Signature Scheme for Efficient and Private Cross-Chain Transactions](https://arxiv.org/abs/2602.05431)
*Yi Liang,Jinguang Han*

Main category: cs.CR

TL;DR: 提出了一种可链接阈值环适配器签名方案(LTRAS)，结合了适配器签名的条件绑定、阈值环签名的多账户支付和可链接性防止双花，显著降低了大规模环和多账户支付场景下的计算和通信开销。


<details>
  <summary>Details</summary>
Motivation: 区块链技术面临可扩展性和吞吐量限制，支付通道等链下解决方案受到关注。适配器签名因其支持原子性而被视为构建支付通道的有前景原语，但标准适配器签名可能泄露签名者身份，存在隐私问题。环签名可以提供匿名性但带来高通信开销，特别是在UTXO区块链（如Monero）常用的多账户支付场景中。

Method: 提出了可链接阈值环适配器签名(LTRAS)方案，整合了适配器签名的条件绑定特性、阈值环签名的多账户支付能力以及防止双花的可链接性。提供了LTRAS的形式化定义、安全模型和具体构造，并通过理论分析和实验实现评估其性能。

Result: 实验结果表明，在大规模环和多账户支付场景下，该方案相比现有方案显著降低了计算和通信开销。方案在跨链原子交换中的应用展示了其在增强区块链交易隐私和效率方面的潜力。

Conclusion: LTRAS方案有效解决了适配器签名的隐私泄露问题和环签名的高通信开销问题，特别适用于UTXO区块链的多账户支付场景。该方案在保持安全性的同时提高了效率，为区块链交易的隐私保护和性能优化提供了新思路。

Abstract: Despite the advantages of decentralization and immutability, blockchain technology faces significant scalability and throughput limitations, which has prompted the exploration of off-chain solutions like payment channels. Adaptor signatures have been considered a promising primitive for constructing such channels due to their support for atomicity, offering an alternative to traditional hash-timelock contracts. However, standard adaptor signatures may reveal signer identity, raising potential privacy concerns. While ring signatures can mitigate this issue by providing anonymity, they often introduce high communication overhead, particularly in multi-account payment settings commonly used in UTXO-based blockchains like Monero. To address these limitations, we propose a Linkable Threshold Ring Adaptor Signature (LTRAS) scheme, which integrates the conditional binding of adaptor signatures, the multi-account payment of threshold ring signatures, and the linkability for preventing double-spending. The formal definition, security model and concrete construction of LTRAS are provided. We also analyze its security and evaluate its performance through theoretical analysis and experimental implementation. Experimental results demonstrate that our scheme achieve significantly lower computation and communication overhead compared to existing schemes in large ring sizes and multi-account payment scenarios. Finally, we discuss its application in cross-chain atomic swaps, demonstrating its potential for enhancing privacy and efficiency in blockchain transactions.

</details>


### [7] [GNSS SpAmming: a spoofing-based GNSS denial-of-service attack](https://arxiv.org/abs/2602.05517)
*Sergio Angulo Cosín,Javier Junquera-Sánchez,Carlos Hernando-Ramiro,José-Antonio Gómez-Sánchez*

Main category: cs.CR

TL;DR: 论文提出了一种新型GNSS攻击"SpAmming"，结合了干扰和欺骗两种攻击方式，通过CDMA多路复用技术使接收器失去对合法卫星信号的访问，现有反制措施难以应对。


<details>
  <summary>Details</summary>
Motivation: 现有GNSS系统主要面临干扰（拒绝信号访问）和欺骗（冒充合法卫星）两种攻击，虽然已有大量反制措施，但缺乏对结合这两种攻击方式的新型攻击的研究。论文旨在揭示这种更隐蔽的混合攻击模式。

Method: 利用大多数GNSS中存在的CDMA多路复用技术，通过欺骗攻击使接收器失去对合法卫星信号的访问。使用SDR（软件定义无线电）系统开发实验原型，针对冷启动、温启动和已获取PVT解算的导航接收器进行攻击测试，评估不同攻击配置（原始虚假信号发射、多普勒效应配置、码偏移等）的效果。

Result: 实验证明SpAmming攻击特别对冷启动接收器有效，但在其他场景下也表现出攻击效果，尤其是与其他攻击结合时。攻击效果随接收器先前状态的不同而变化。

Conclusion: SpAmming是一种新型混合攻击，现有反干扰和反欺骗措施难以应对。论文提出了可能的检测和反制措施，并建议进一步研究其在OSNMA等认证服务中的影响，以及通过特征化改进对类似攻击的响应。

Abstract: GNSSs are vulnerable to attacks of two kinds: jamming (i.e. denying access to the signal) and spoofing (i.e. impersonating a legitimate satellite). These attacks have been extensively studied, and we have a myriad of countermeasures to mitigate them. In this paper we expose a new type of attack: SpAmming, which combines both approaches to achieve the same effects in a more subtle way.
  Exploiting the CDMA multiplexing present in most GNSSs, and through a spoofing attack, this approach leads the receiver to lose access to the signal of a legitimate satellite, which would be equivalent to a denial of service; but in this case the existing countermeasures against jamming or spoofing would not allow safeguarding its effectiveness, as it is neither of them.
  An experimental proof-of-concept is presented in which its impact is evaluated as a function of the previous state of the receiver. Using an SDR-based system developed at the Space Security Centre, the attack is executed against a cold-started receiver, a warm-started receiver, and a receiver that has already acquired the PVT solution and is navigating. Different attack configurations are also tested, starting from a raw emission of the false signal, to surgical Doppler effect configuration, code offset, etc. Although it is shown to be particularly successful against cold-started receivers, the results show that it is also effective in other scenarios, especially if accompanied by other attacks. We will conclude the article by outlining possible countermeasures to detect and, eventually, counteract it; and possible avenues of research to better understand its impact, especially for authenticated services such as OSNMA, and to characterize it in order to improve the response to similar attacks.

</details>


### [8] [ADCA: Attention-Driven Multi-Party Collusion Attack in Federated Self-Supervised Learning](https://arxiv.org/abs/2602.05612)
*Jiayao Wang,Yiping Zhang,Jiale Zhang,Wenliang Yuan,Qilin Wu,Junwu Zhu,Dongfang Zhao*

Main category: cs.CR

TL;DR: 本文提出了一种针对联邦自监督学习的注意力驱动多方合谋攻击（ADCA），通过分解全局触发器、恶意客户端合谋以及注意力机制动态聚合，显著提高了攻击成功率和持久性。


<details>
  <summary>Details</summary>
Motivation: 联邦自监督学习结合了分布式训练的隐私优势和自监督学习利用未标记数据的能力，但现有研究表明其易受后门攻击。现有攻击方法受限于触发器设计，通常使用全局统一触发器，容易被检测、在聚合过程中被稀释，且在异构客户端环境中缺乏鲁棒性。

Method: 提出注意力驱动多方合谋攻击（ADCA）：1）在本地预训练期间，恶意客户端分解全局触发器以找到最优本地模式；2）恶意客户端合谋形成恶意联盟，建立协作优化机制；3）在机制中，每个客户端提交模型更新，注意力机制动态聚合这些更新以探索最佳协作策略；4）聚合参数作为联盟内下一轮训练的初始状态，有效减轻良性更新对后门信息的稀释。

Result: 在多个联邦自监督学习场景和四个数据集上的实验表明，ADCA在攻击成功率（ASR）和持久性方面显著优于现有方法，证明了其有效性和鲁棒性。

Conclusion: ADCA通过创新的注意力驱动多方合谋机制，解决了现有联邦自监督学习后门攻击的局限性，实现了更高效、更持久的攻击效果，揭示了联邦自监督学习安全性的新挑战。

Abstract: Federated Self-Supervised Learning (FSSL) integrates the privacy advantages of distributed training with the capability of self-supervised learning to leverage unlabeled data, showing strong potential across applications. However, recent studies have shown that FSSL is also vulnerable to backdoor attacks. Existing attacks are limited by their trigger design, which typically employs a global, uniform trigger that is easily detected, gets diluted during aggregation, and lacks robustness in heterogeneous client environments. To address these challenges, we propose the Attention-Driven multi-party Collusion Attack (ADCA). During local pre-training, malicious clients decompose the global trigger to find optimal local patterns. Subsequently, these malicious clients collude to form a malicious coalition and establish a collaborative optimization mechanism within it. In this mechanism, each submits its model updates, and an attention mechanism dynamically aggregates them to explore the best cooperative strategy. The resulting aggregated parameters serve as the initial state for the next round of training within the coalition, thereby effectively mitigating the dilution of backdoor information by benign updates. Experiments on multiple FSSL scenarios and four datasets show that ADCA significantly outperforms existing methods in Attack Success Rate (ASR) and persistence, proving its effectiveness and robustness.

</details>


### [9] [Time-Complexity Characterization of NIST Lightweight Cryptography Finalists](https://arxiv.org/abs/2602.05641)
*Najmul Hasan,Prashanth BusiReddyGari*

Main category: cs.CR

TL;DR: 该研究提出了一个符号模型来分析NIST轻量级密码学项目中十个决赛算法的理论时间复杂度，为受限设备上的密码选择提供指导。


<details>
  <summary>Details</summary>
Motivation: 随着数字身份系统和物联网验证等新兴技术的发展，在计算能力、内存和能源资源有限的设备上需要轻量级密码学。虽然NIST的轻量级密码学项目对十个决赛算法进行了实证评估，但缺乏对其时间复杂度的统一理论理解。

Method: 引入一个符号模型，将每个密码方案分解为初始化、数据处理和最终化三个阶段，从而能够对所有十个决赛算法进行形式化的时间复杂度推导。

Result: 结果阐明了设计参数如何在受限的移动和嵌入式环境中影响计算扩展性，为区分算法效率提供了基础。

Conclusion: 该框架为区分算法效率提供了必要基础，并指导在受限环境中选择能够支持安全系统的密码原语。

Abstract: Lightweight cryptography is becoming essential as emerging technologies in digital identity systems and Internet of Things verification continue to demand strong cryptographic assurance on devices with limited processing power, memory, and energy resources. As these technologies move into routine use, they demand cryptographic primitives that maintain strong security and deliver predictable performance through clear theoretical models of time complexity. Although NIST's lightweight cryptography project provides empirical evaluations of the ten finalist algorithms, a unified theoretical understanding of their time-complexity behavior remains absent. This work introduces a symbolic model that decomposes each scheme into initialization, data-processing, and finalization phases, enabling formal time-complexity derivation for all ten finalists. The results clarify how design parameters shape computational scaling on constrained mobile and embedded environments. The framework provides a foundation needed to distinguish algorithmic efficiency and guides the choice of primitives capable of supporting security systems in constrained environments.

</details>


### [10] [Persistent Human Feedback, LLMs, and Static Analyzers for Secure Code Generation and Vulnerability Detection](https://arxiv.org/abs/2602.05868)
*Ehsan Firouzi,Mohammad Ghafari*

Main category: cs.CR

TL;DR: 论文通过分析1080个LLM生成的代码样本，发现静态分析工具（CodeQL和Semgrep）在评估代码安全性时存在显著不一致性，仅61-65%的报告与人工验证的真实情况相符，质疑了这些工具作为唯一评估标准的可靠性，并提出基于人类反馈的动态检索增强生成框架。


<details>
  <summary>Details</summary>
Motivation: 现有文献过度依赖静态分析工具来评估LLM的代码安全生成和漏洞检测能力，但这些工具的可靠性尚未得到充分验证。研究者希望通过系统比较静态分析工具输出与人工验证的真实情况，揭示这些工具在实际评估中的局限性。

Method: 1. 收集1080个LLM生成的代码样本；2. 构建人工验证的真实基准数据集；3. 使用两个广泛使用的静态安全工具（CodeQL和Semgrep）分析这些代码；4. 比较工具输出与真实基准的匹配程度；5. 基于分析结果提出动态检索增强生成框架，持续存储人类反馈供LLM重用。

Result: 1. 61%的样本实际是安全的；2. Semgrep和CodeQL分别将60%和80%的样本分类为安全；3. 虽然总体统计看似一致，但逐样本分析显示显著差异：Semgrep仅65%的报告正确匹配真实情况，CodeQL仅61%；4. 静态分析工具作为代码安全唯一评估者的可靠性受到质疑。

Conclusion: 静态分析工具不能作为评估代码安全的唯一标准，需要专家反馈的补充。提出的动态检索增强生成框架通过持续存储和重用人类反馈，能够提升LLM在安全代码生成和漏洞检测方面的能力，为更可靠的代码安全评估提供新思路。

Abstract: Existing literature heavily relies on static analysis tools to evaluate LLMs for secure code generation and vulnerability detection. We reviewed 1,080 LLM-generated code samples, built a human-validated ground-truth, and compared the outputs of two widely used static security tools, CodeQL and Semgrep, against this corpus. While 61% of the samples were genuinely secure, Semgrep and CodeQL classified 60% and 80% as secure, respectively. Despite the apparent agreement in aggregate statistics, per-sample analysis reveals substantial discrepancies: only 65% of Semgrep's and 61% of CodeQL's reports correctly matched the ground truth. These results question the reliability of static analysis tools as sole evaluators of code security and underscore the need for expert feedback. Building on this insight, we propose a conceptual framework that persistently stores human feedback in a dynamic retrieval-augmented generation pipeline, enabling LLMs to reuse past feedback for secure code generation and vulnerability detection.

</details>


### [11] [Characterizing and Modeling the GitHub Security Advisories Review Pipeline](https://arxiv.org/abs/2602.06009)
*Claudio Segal,Paulo Segal,Carlos Eduardo de Schuller Banjar,Felipe Paixão,Hudson Silva Borges,Paulo Silveira Neto,Eduardo Santana de Almeida,Joanna C. S. Santos,Anton Kocheturov,Gaurav Kumar Srivastava,Daniel Sadoc Menasché*

Main category: cs.CR

TL;DR: 对GitHub安全公告（GHSA）审查流程的大规模实证研究，分析了28.8万条公告，发现审查延迟存在两种不同机制：快速路径（GitHub仓库公告主导）和慢速路径（NVD优先公告主导）。


<details>
  <summary>Details</summary>
Motivation: GitHub安全公告已成为开源漏洞披露的核心组成部分，但只有部分公告经过GitHub审查，且审查机制缺乏深入理解。需要研究哪些公告更可能被审查、审查延迟情况以及审查流程的结构特征。

Method: 对2019-2025年超过288,000条安全公告进行大规模实证研究，分析审查模式、量化审查延迟，识别不同的审查延迟机制，并基于公告处理管道结构开发排队模型。

Result: 研究发现审查延迟存在两种明显不同的机制：快速路径主要由GitHub仓库公告（GRAs）主导，慢速路径主要由NVD优先公告主导。研究还量化了审查延迟，并确定了哪些类型的公告更可能被审查。

Conclusion: GitHub安全公告审查流程存在结构性的双重机制，这种理解有助于改进漏洞披露流程，并为开发者和安全工具提供更准确的预期。

Abstract: GitHub Security Advisories (GHSA) have become a central component of open-source vulnerability disclosure and are widely used by developers and security tools. A distinctive feature of GHSA is that only a fraction of advisories are reviewed by GitHub, while the mechanisms associated with this review process remain poorly understood. In this paper, we conduct a large-scale empirical study of GHSA review processes, analyzing over 288,000 advisories spanning 2019--2025. We characterize which advisories are more likely to be reviewed, quantify review delays, and identify two distinct review-latency regimes: a fast path dominated by GitHub Repository Advisories (GRAs) and a slow path dominated by NVD-first advisories. We further develop a queueing model that accounts for this dichotomy based on the structure of the advisory processing pipeline.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [12] [Beyond Cosine Similarity](https://arxiv.org/abs/2602.05266)
*Xinbo Ai*

Main category: cs.AI

TL;DR: 本文提出了一种新的相似度度量方法recos，它通过推导比经典柯西-施瓦茨不等式更紧的上界，用排序向量分量归一化点积，在11种嵌入模型上超越了传统余弦相似度。


<details>
  <summary>Details</summary>
Motivation: 余弦相似度基于柯西-施瓦茨不等式，只能捕捉线性关系，无法建模真实世界语义空间的复杂非线性结构。需要一种数学原理更严谨、能捕捉更广泛关系的相似度度量方法。

Method: 推导出比经典柯西-施瓦茨界更紧的点积上界，基于此提出recos度量：通过排序向量分量归一化点积，将完美相似的条件从严格线性依赖放宽为序数一致性。

Result: 在11种嵌入模型（静态、上下文化、通用类型）上的广泛实验表明，recos在标准语义文本相似度基准测试中，与传统余弦相似度相比，始终获得与人类判断更高的相关性。

Conclusion: recos作为一种数学原理严谨且经验上优越的替代方案，为复杂嵌入空间中的语义分析提供了更高的准确性。

Abstract: Cosine similarity, the standard metric for measuring semantic similarity in vector spaces, is mathematically grounded in the Cauchy-Schwarz inequality, which inherently limits it to capturing linear relationships--a constraint that fails to model the complex, nonlinear structures of real-world semantic spaces. We advance this theoretical underpinning by deriving a tighter upper bound for the dot product than the classical Cauchy-Schwarz bound. This new bound leads directly to recos, a similarity metric that normalizes the dot product by the sorted vector components. recos relaxes the condition for perfect similarity from strict linear dependence to ordinal concordance, thereby capturing a broader class of relationships. Extensive experiments across 11 embedding models--spanning static, contextualized, and universal types--demonstrate that recos consistently outperforms traditional cosine similarity, achieving higher correlation with human judgments on standard Semantic Textual Similarity (STS) benchmarks. Our work establishes recos as a mathematically principled and empirically superior alternative, offering enhanced accuracy for semantic analysis in complex embedding spaces.

</details>


### [13] [Hallucination-Resistant Security Planning with a Large Language Model](https://arxiv.org/abs/2602.05279)
*Kim Hammar,Tansu Alpcan,Emil Lupu*

Main category: cs.AI

TL;DR: 提出一个原则性框架，将LLM集成到安全管理的迭代循环中，通过一致性检查和外部反馈控制幻觉风险，在事件响应用例中可将恢复时间减少30%


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在支持安全管理任务（如事件响应规划）方面具有潜力，但其不可靠性和幻觉倾向仍然是重大挑战，需要解决这些问题以实现可靠的决策支持

Method: 提出一个原则性框架，将LLM集成到迭代循环中：LLM生成候选行动，检查其与系统约束和前瞻预测的一致性；当一致性低时，通过数字孪生等外部反馈收集信息，然后通过上下文学习细化候选行动

Result: 证明该设计可通过调整一致性阈值控制幻觉风险，并在特定假设下建立了上下文学习的遗憾界限；在四个公共数据集上的实验表明，该框架相比前沿LLM可将恢复时间减少30%

Conclusion: 该框架为在安全管理中使用LLM作为决策支持提供了一种原则性方法，通过一致性检查和外部反馈机制有效控制幻觉风险，在事件响应用例中显著提升了性能

Abstract: Large language models (LLMs) are promising tools for supporting security management tasks, such as incident response planning. However, their unreliability and tendency to hallucinate remain significant challenges. In this paper, we address these challenges by introducing a principled framework for using an LLM as decision support in security management. Our framework integrates the LLM in an iterative loop where it generates candidate actions that are checked for consistency with system constraints and lookahead predictions. When consistency is low, we abstain from the generated actions and instead collect external feedback, e.g., by evaluating actions in a digital twin. This feedback is then used to refine the candidate actions through in-context learning (ICL). We prove that this design allows to control the hallucination risk by tuning the consistency threshold. Moreover, we establish a bound on the regret of ICL under certain assumptions. To evaluate our framework, we apply it to an incident response use case where the goal is to generate a response and recovery plan based on system logs. Experiments on four public datasets show that our framework reduces recovery times by up to 30% compared to frontier LLMs.

</details>


### [14] [Graph-based Agent Memory: Taxonomy, Techniques, and Applications](https://arxiv.org/abs/2602.05665)
*Chang Yang,Chuang Zhou,Yilin Xiao,Su Dong,Luyao Zhuang,Yujing Zhang,Zhu Wang,Zijin Hong,Zheng Yuan,Zhishang Xiang,Shengyuan Chen,Huachi Zhou,Qinggang Zhang,Ninghao Liu,Jinsong Su,Xinrun Wang,Yi Chang,Xiao Huang*

Main category: cs.AI

TL;DR: 本文对基于图结构的智能体记忆系统进行了全面综述，涵盖了记忆分类、生命周期技术、开源资源、应用场景以及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 在大型语言模型智能体中，记忆是实现长期复杂任务（如多轮对话、游戏、科学发现）的核心模块。图结构因其建模关系依赖、组织层次信息和支持高效检索的内在能力，成为智能体记忆的强大结构。本文旨在为开发更高效可靠的图基智能体记忆系统提供可操作的见解。

Method: 1. 提出智能体记忆的分类法：短期vs长期记忆、知识vs经验记忆、非结构vs结构记忆，并从图基实现视角进行阐述。
2. 按照智能体记忆的生命周期，系统分析图基智能体记忆的关键技术：记忆提取（数据转换）、存储（高效组织）、检索（支持推理的相关内容检索）、演化（内容更新）。
3. 总结支持自演化智能体记忆开发和评估的开源库和基准测试。
4. 探索多样化的应用场景。
5. 识别关键挑战和未来研究方向。

Result: 1. 建立了全面的图基智能体记忆分类框架。
2. 系统化分析了记忆生命周期的关键技术环节。
3. 收集整理了相关研究论文、开源数据和项目资源（https://github.com/DEEP-PolyU/Awesome-GraphMemory）。
4. 识别了该领域的关键挑战和未来发展方向。

Conclusion: 图结构为智能体记忆提供了强大的组织框架，能够有效支持知识积累、迭代推理和自我演化。本文的综述为开发更高效可靠的图基智能体记忆系统提供了系统性的指导，通过分类法、技术分析和资源整理，推动了该领域的研究进展。未来需要在记忆效率、可靠性、可解释性等方面进一步探索。

Abstract: Memory emerges as the core module in the Large Language Model (LLM)-based agents for long-horizon complex tasks (e.g., multi-turn dialogue, game playing, scientific discovery), where memory can enable knowledge accumulation, iterative reasoning and self-evolution. Among diverse paradigms, graph stands out as a powerful structure for agent memory due to the intrinsic capabilities to model relational dependencies, organize hierarchical information, and support efficient retrieval. This survey presents a comprehensive review of agent memory from the graph-based perspective. First, we introduce a taxonomy of agent memory, including short-term vs. long-term memory, knowledge vs. experience memory, non-structural vs. structural memory, with an implementation view of graph-based memory. Second, according to the life cycle of agent memory, we systematically analyze the key techniques in graph-based agent memory, covering memory extraction for transforming the data into the contents, storage for organizing the data efficiently, retrieval for retrieving the relevant contents from memory to support reasoning, and evolution for updating the contents in the memory. Third, we summarize the open-sourced libraries and benchmarks that support the development and evaluation of self-evolving agent memory. We also explore diverse application scenarios. Finally, we identify critical challenges and future research directions. This survey aims to offer actionable insights to advance the development of more efficient and reliable graph-based agent memory systems. All the related resources, including research papers, open-source data, and projects, are collected for the community in https://github.com/DEEP-PolyU/Awesome-GraphMemory.

</details>


### [15] [RL-VLA$^3$: Reinforcement Learning VLA Accelerating via Full Asynchronism](https://arxiv.org/abs/2602.05765)
*Zhong Guan,Haoran Sun,Yongjian Guo,Shuai Di,Xiaodong Bai,Jing Long,Tianyun Zhao,Mingxi Luo,Chen Zhou,Yucheng Guo,Qiming Yang,Wanting Xu,Wen Huang,Yunxuan Ma,Hongke Zhao,Likang Wu,Xiaotie Deng,Xi Xiao,Sheng Wen,Yicheng Gong,Junwu Xiong*

Main category: cs.AI

TL;DR: 本文提出首个完全异步的VLA模型训练框架，通过环境交互、策略生成和模型更新的全流程异步化，显著提升训练效率，在LIBERO基准上实现最高126.67%的吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型的RL训练框架（如RLinf）虽然能提升模型泛化能力，但仍采用同步执行方式，导致环境交互、策略生成和模型更新阶段的资源利用率低下和吞吐量受限，成为训练效率的主要瓶颈。

Method: 提出完全异步策略训练框架，采用多级解耦架构：1）环境交互和轨迹收集的异步并行化；2）策略生成的流式执行；3）训练更新的解耦调度。借鉴大模型RL中的异步优化思想，实现从环境交互到模型更新的全流程异步化。

Result: 在LIBERO基准上，相比现有同步策略，框架实现最高59.25%的吞吐量提升；通过深度优化分离策略，吞吐量最高可提升126.67%。消融实验验证了各异步组件的有效性，8到256个GPU的扩展性验证显示方法在多数条件下具有优秀可扩展性。

Conclusion: 提出的完全异步训练框架有效解决了VLA模型训练中的效率瓶颈问题，通过全流程异步化显著提升了训练吞吐量和资源利用率，为大规模VLA模型的高效训练提供了可行方案。

Abstract: In recent years, Vision-Language-Action (VLA) models have emerged as a crucial pathway towards general embodied intelligence, yet their training efficiency has become a key bottleneck. Although existing reinforcement learning (RL)-based training frameworks like RLinf can enhance model generalization, they still rely on synchronous execution, leading to severe resource underutilization and throughput limitations during environment interaction, policy generation (rollout), and model update phases (actor). To overcome this challenge, this paper, for the first time, proposes and implements a fully-asynchronous policy training framework encompassing the entire pipeline from environment interaction, rollout generation, to actor policy updates. Systematically drawing inspiration from asynchronous optimization ideas in large model RL, our framework designs a multi-level decoupled architecture. This includes asynchronous parallelization of environment interaction and trajectory collection, streaming execution for policy generation, and decoupled scheduling for training updates. We validated the effectiveness of our method across diverse VLA models and environments. On the LIBERO benchmark, the framework achieves throughput improvements of up to 59.25\% compared to existing synchronous strategies. When deeply optimizing separation strategies, throughput can be increased by as much as 126.67\%. We verified the effectiveness of each asynchronous component via ablation studies. Scaling law validation across 8 to 256 GPUs demonstrates our method's excellent scalability under most conditions.

</details>


### [16] [OmniVideo-R1: Reinforcing Audio-visual Reasoning with Query Intention and Modality Attention](https://arxiv.org/abs/2602.05847)
*Zhangquan Chen,Jiale Tao,Ruihuang Li,Yihao Hu,Ruitao Chen,Zhantao Yang,Xinlei Yu,Haodong Jing,Manyuan Zhang,Shuai Shao,Biao Wang,Qinglin Lu,Ruqi Huang*

Main category: cs.AI

TL;DR: OmniVideo-R1是一个通过强化学习框架改进多模态视频理解的模型，采用查询密集定位和模态注意力融合策略，在多个基准测试中表现优异


<details>
  <summary>Details</summary>
Motivation: 人类通过多种模态协同感知世界，但现有的全视频模型在视听理解任务上仍面临挑战，需要改进混合模态推理能力

Method: 提出OmniVideo-R1强化框架，采用两种关键策略：1）基于自监督学习的查询密集定位；2）基于对比学习的模态注意力融合

Result: 在多个基准测试上的广泛实验表明，OmniVideo-R1始终优于强基线模型，显示出其有效性和强大的泛化能力

Conclusion: OmniVideo-R1通过"全模态线索思考"的强化框架，显著提升了多模态视频理解能力，为视听理解任务提供了有效解决方案

Abstract: While humans perceive the world through diverse modalities that operate synergistically to support a holistic understanding of their surroundings, existing omnivideo models still face substantial challenges on audio-visual understanding tasks. In this paper, we propose OmniVideo-R1, a novel reinforced framework that improves mixed-modality reasoning. OmniVideo-R1 empowers models to "think with omnimodal cues" by two key strategies: (1) query-intensive grounding based on self-supervised learning paradigms; and (2) modality-attentive fusion built upon contrastive learning paradigms. Extensive experiments on multiple benchmarks demonstrate that OmniVideo-R1 consistently outperforms strong baselines, highlighting its effectiveness and robust generalization capabilities.

</details>


### [17] [Learning Event-Based Shooter Models from Virtual Reality Experiments](https://arxiv.org/abs/2602.06023)
*Christopher A. McClurg,Alan R. Wagner*

Main category: cs.AI

TL;DR: 开发数据驱动的离散事件模拟器，用于评估学校安全干预措施，特别是机器人干预策略，以解决VR研究中招募参与者的限制问题。


<details>
  <summary>Details</summary>
Motivation: VR虽然能有效评估学校安全措施，但每次实验都需要招募新参与者，难以进行大规模或迭代评估，特别是在需要大量训练场景的学习有效干预策略时。

Method: 开发数据驱动的离散事件模拟器，将枪手移动和区域内行为建模为从VR研究中参与者行为学习的随机过程，用于评估机器人干预策略。

Result: 模拟器能够重现关键经验模式，使得大规模评估和学习干预策略成为可能，这些策略直接使用人类受试者训练是不可行的。

Conclusion: 这项工作展示了一个高到中等保真度的模拟工作流程，为开发和评估自主学校安全干预措施提供了可扩展的替代方案。

Abstract: Virtual reality (VR) has emerged as a powerful tool for evaluating school security measures in high-risk scenarios such as school shootings, offering experimental control and high behavioral fidelity. However, assessing new interventions in VR requires recruiting new participant cohorts for each condition, making large-scale or iterative evaluation difficult. These limitations are especially restrictive when attempting to learn effective intervention strategies, which typically require many training episodes. To address this challenge, we develop a data-driven discrete-event simulator (DES) that models shooter movement and in-region actions as stochastic processes learned from participant behavior in VR studies. We use the simulator to examine the impact of a robot-based shooter intervention strategy. Once shown to reproduce key empirical patterns, the DES enables scalable evaluation and learning of intervention strategies that are infeasible to train directly with human subjects. Overall, this work demonstrates a high-to-mid fidelity simulation workflow that provides a scalable surrogate for developing and evaluating autonomous school-security interventions.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [18] [Large Language Models in Software Documentation and Modeling: A Literature Review and Findings](https://arxiv.org/abs/2602.04938)
*Lukas Radosky,Ivan Polasek*

Main category: cs.SE

TL;DR: 本文对大型语言模型在软件工程文档和建模任务中的应用进行了系统性文献综述，分析了相关研究的方法、评估指标和数据集。


<details>
  <summary>Details</summary>
Motivation: 生成式人工智能特别是大型语言模型在软件工程领域受到广泛关注，它们能够理解自然语言和结构化语言，具有处理软件文档和模型的潜力。然而，目前缺乏对这一特定应用领域的系统性综述。

Method: 对四个主要软件工程会议/期刊的文献进行系统性综述，按任务类型组织分析，涵盖使用的提示技术、评估指标、人工评估方法和主要数据集。

Result: 提供了大型语言模型在软件工程文档和建模任务应用的综合分析框架，总结了当前的研究现状、技术方法和评估实践。

Conclusion: 大型语言模型在软件工程文档和建模任务中具有重要应用价值，本文的系统性综述为该领域的研究提供了全面的参考框架和未来研究方向。

Abstract: Generative artificial intelligence attracts significant attention, especially with the introduction of large language models. Its capabilities are being exploited to solve various software engineering tasks. Thanks to their ability to understand natural language and generate natural language responses, large language models are great for processing various software documentation artifacts. At the same time, large language models excel at understanding structured languages, having the potential for working with software programs and models. We conduct a literature review on the usage of large language models for software engineering tasks related to documentation and modeling. We analyze articles from four major venues in the area, organize them per tasks they solve, and provide an overview of used prompt techniques, metrics, approaches to human-based evaluation, and major datasets.

</details>


### [19] [TestMigrationsInPy: A Dataset of Test Migrations from Unittest to Pytest](https://arxiv.org/abs/2602.05122)
*Altino Alves,Andre Hora*

Main category: cs.SE

TL;DR: TestMigrationsInPy是一个包含923个真实世界unittest到pytest迁移的数据集，用于支持Python测试框架迁移的自动化研究。


<details>
  <summary>Details</summary>
Motivation: 虽然pytest相比unittest有优势（如更简单的断言、fixture重用和互操作性），但手动迁移过程耗时且漫长。Python生态中的多个项目已从unittest迁移到pytest，但缺乏自动化工具支持这一过程。

Method: 作者创建了TestMigrationsInPy数据集，收集了开发者实际执行的923个真实迁移案例。数据集包含迁移类型信息（如断言或fixture的变更），为未来研究提供基准。

Result: TestMigrationsInPy数据集已公开可用，包含详细的迁移类型分类，能够有效验证从简单断言迁移到复杂fixture迁移的各种解决方案。

Conclusion: 该数据集为Python测试框架迁移研究提供了真实世界的基准，支持开发自动化迁移工具，并可通过迁移类型分类验证不同复杂度的解决方案。

Abstract: Unittest and pytest are the most popular testing frameworks in Python. Overall, pytest provides some advantages, including simpler assertion, reuse of fixtures, and interoperability. Due to such benefits, multiple projects in the Python ecosystem have migrated from unittest to pytest. To facilitate the migration, pytest can also run unittest tests, thus, the migration can happen gradually over time. However, the migration can be time-consuming and take a long time to conclude. In this context, projects would benefit from automated solutions to support the migration process. In this paper, we propose TestMigrationsInPy, a dataset of test migrations from unittest to pytest. TestMigrationsInPy contains 923 real-world migrations performed by developers. Future research proposing novel solutions to migrate frameworks in Python can rely on TestMigrationsInPy as a ground truth. Moreover, as TestMigrationsInPy includes information about the migration type (e.g., changes in assertions or fixtures), our dataset enables novel solutions to be verified effectively, for instance, from simpler assertion migrations to more complex fixture migrations. TestMigrationsInPy is publicly available at: https://github.com/altinoalvesjunior/TestMigrationsInPy.

</details>


### [20] [Exceptional Behaviors: How Frequently Are They Tested?](https://arxiv.org/abs/2602.05123)
*Andre Hora,Gordon Fraser*

Main category: cs.SE

TL;DR: 该研究通过实证分析发现，在真实Python系统中，21.4%的执行方法会在运行时抛出异常，其中约20%的方法频繁抛出异常，挑战了"异常行为罕见"的传统假设。


<details>
  <summary>Details</summary>
Motivation: 当前研究主要关注传播到测试的异常，而忽略了未到达测试的其他异常。为了全面了解真实系统中异常行为的测试覆盖情况，需要同时研究这两类异常。

Method: 对25个Python系统的测试套件进行仪器化运行，监控执行过程，收集运行时抛出的异常信息。覆盖5,372个执行方法、1,790万次调用和140万次抛出的异常。

Result: 21.4%的执行方法会在运行时抛出异常；在抛出异常的方法中，中位数显示每10次调用就有1次触发异常行为；约80%的方法异常抛出频率较低，但约20%的方法频繁抛出异常。

Conclusion: 异常抛出行为不一定是"异常"或罕见的。建议开发新工具支持异常行为的测试和昂贵的try/except块重构，提醒研究者和实践者重新思考异常行为的本质。

Abstract: Exceptions allow developers to handle error cases expected to occur infrequently. Ideally, good test suites should test both normal and exceptional behaviors to catch more bugs and avoid regressions. While current research analyzes exceptions that propagate to tests, it does not explore other exceptions that do not reach the tests. In this paper, we provide an empirical study to explore how frequently exceptional behaviors are tested in real-world systems. We consider both exceptions that propagate to tests and the ones that do not reach the tests. For this purpose, we run an instrumented version of test suites, monitor their execution, and collect information about the exceptions raised at runtime. We analyze the test suites of 25 Python systems, covering 5,372 executed methods, 17.9M calls, and 1.4M raised exceptions. We find that 21.4% of the executed methods do raise exceptions at runtime. In methods that raise exceptions, on the median, 1 in 10 calls exercise exceptional behaviors. Close to 80% of the methods that raise exceptions do so infrequently, but about 20% raise exceptions more frequently. Finally, we provide implications for researchers and practitioners. We suggest developing novel tools to support exercising exceptional behaviors and refactoring expensive try/except blocks. We also call attention to the fact that exception-raising behaviors are not necessarily "abnormal" or rare.

</details>


### [21] [The Necessity of a Holistic Safety Evaluation Framework for AI-Based Automation Features](https://arxiv.org/abs/2602.05157)
*Alireza Abbaspour,Shabin Mahadevan,Kilian Zwirglmaier,Jeff Stafford*

Main category: cs.SE

TL;DR: 传统安全分析通常排除质量管理(QM)组件，但AI集成显示这些组件可能引入SOTIF相关风险，需要重新评估安全框架以应对AI带来的新挑战。


<details>
  <summary>Details</summary>
Motivation: 传统驾驶自动化功能的安全分析将质量管理(QM)组件排除在严格的安全影响评估之外，但随着AI集成的发展，这些非安全相关组件可能引入SOTIF相关危险风险，且新兴AI安全标准(如ISO/PAS 8800)要求重新评估这些组件的安全考虑。

Method: 通过案例研究展示AI驱动的感知系统即使在QM分类组件中也可能出现缺陷，导致具有关键安全影响的意外功能行为。结合理论分析与实际示例，论证采用全面的FuSa、SOTIF和AI标准驱动方法来识别和缓解AI组件风险的必要性。

Result: 研究表明AI驱动的感知系统缺陷可能在QM分类组件中出现，导致意外功能行为并违反风险接受标准。需要修订现有安全框架以应对AI带来的演变挑战。

Conclusion: 需要采用全面的FuSa、SOTIF和AI标准驱动方法对AI组件进行整体安全分析和风险评估，修订现有安全框架以应对AI带来的新挑战，确保跨所有组件分类的全面安全保证。

Abstract: The intersection of Safety of Intended Functionality (SOTIF) and Functional Safety (FuSa) analysis of driving automation features has traditionally excluded Quality Management (QM) components from rigorous safety impact evaluations. While QM components are not typically classified as safety-relevant, recent developments in artificial intelligence (AI) integration reveal that such components can contribute to SOTIF-related hazardous risks. Compliance with emerging AI safety standards, such as ISO/PAS 8800, necessitates re-evaluating safety considerations for these components. This paper examines the necessity of conducting holistic safety analysis and risk assessment on AI components, emphasizing their potential to introduce hazards with the capacity to violate risk acceptance criteria when deployed in safety-critical driving systems, particularly in perception algorithms. Using case studies, we demonstrate how deficiencies in AI-driven perception systems can emerge even in QM-classified components, leading to unintended functional behaviors with critical safety implications. By bridging theoretical analysis with practical examples, this paper argues for the adoption of comprehensive FuSa, SOTIF, and AI standards-driven methodologies to identify and mitigate risks in AI components. The findings demonstrate the importance of revising existing safety frameworks to address the evolving challenges posed by AI, ensuring comprehensive safety assurance across all component classifications spanning multiple safety standards.

</details>


### [22] [PatchGuru: Patch Oracle Inference from Natural Language Artifacts with Large Language Models](https://arxiv.org/abs/2602.05270)
*Thanh Le-Cong,Bach Le,Toby Murray,Michael Pradel,Cristian Cadar*

Main category: cs.SE

TL;DR: PatchGuru：首个从真实PR中自动推断可执行补丁规范的技术，使用LLM从自然语言描述中提取开发者意图，合成运行时断言，自动验证补丁行为，发现未知bug


<details>
  <summary>Details</summary>
Motivation: 软件系统演化中，补丁可能无意改变程序行为。由于不完整的回归测试和非正式的自然语言描述，验证补丁是否符合预期语义很困难

Method: 给定PR，使用LLM从自然语言工件中提取开发者意图，合成补丁预言（patch oracles）——以运行时断言形式表达的比较程序规范。通过迭代精炼、比较前后版本行为、识别违规、自审过滤不一致性来生成bug报告

Result: 在4个广泛使用的Python项目的400个PR上评估，报告39个警告，精度0.62，确认24个真阳性，包括12个先前未知的bug（其中11个被开发者修复）。相比最先进技术Testora，多发现17个bug（24 vs 7），精度从0.32提升到0.62。每个PR平均成本8.9分钟和0.07美元

Conclusion: PatchGuru通过提供可执行文档和自动验证补丁意图，补充了代码审查和回归测试，展示了从自然语言描述中自动推断可执行规范的可行性

Abstract: As software systems evolve, patches may unintentionally alter program behavior. Validating patches against their intended semantics is difficult due to incomplete regression tests and informal, non-executable natural language (NL) descriptions of patch intent. We present PatchGuru, the first automated technique that infers executable patch specifications from real-world pull requests (PRs). Given a PR, PatchGuru uses large language models (LLMs) to extract developer intent from NL artifacts and synthesizes patch oracles: under-approximate yet practical specifications expressed as runtime assertions in comparison programs that integrate pre- and post-patch versions. Patch oracles focus on patch-relevant behaviors, enable automated validation, and support cross-version properties. PatchGuru iteratively refines inferred oracles by comparing pre- and post-patch behaviors, identifies violations, filters inconsistencies via self-review, and generates bug reports. We evaluate PatchGuru on 400 recent PRs from four widely used open-source Python projects. PatchGuru reports 39 warnings with a precision of 0.62, yielding 24 confirmed true positives, including 12 previously unknown bugs, 11 of which were subsequently fixed by developers. Compared to the state-of-the-art technique Testora, PatchGuru detects 17 more bugs (24 vs. 7) while improving precision from 0.32 to 0.62. PatchGuru incurs an average cost of 8.9 minutes and USD 0.07 per PR. These results suggest that PatchGuru complements code review and regression testing by providing executable documentation and automated validation of patch intent.

</details>


### [23] [Does Programming Language Matter? An Empirical Study of Fuzzing Bug Detection](https://arxiv.org/abs/2602.05312)
*Tatsuya Shirai,Olivier Nourry,Yutaro Kashiwa,Kenji Fujiwara,Hajimu Iida*

Main category: cs.SE

TL;DR: 该研究通过大规模跨语言分析发现，不同编程语言在模糊测试的bug检测频率、漏洞比例、崩溃类型和修复时间等方面存在显著差异，表明模糊测试效果受语言设计影响很大。


<details>
  <summary>Details</summary>
Motivation: 尽管模糊测试已广泛应用于持续集成工作流（持续模糊测试），但先前研究未探讨模糊测试效果是否因编程语言而异。本研究旨在填补这一空白，分析不同编程语言下模糊测试bug特征和检测效率的差异。

Method: 研究对61,444个模糊测试bug和999,248次构建进行分析，涵盖559个OSS-Fuzz项目，按主要编程语言（C++、Rust、Python、Go等）进行分类，进行大规模跨语言比较分析。

Result: 研究发现：(1) C++和Rust的模糊测试bug检测频率更高；(2) Rust和Python的漏洞比例较低但倾向于暴露更关键漏洞；(3) 崩溃类型因语言而异，Go中不可复现bug更常见而Rust中罕见；(4) Python的补丁覆盖率更高但检测时间更长。

Conclusion: 模糊测试行为和效果受语言设计影响显著，这一发现为开发语言感知的模糊测试策略和工具提供了重要见解，有助于针对不同编程语言优化模糊测试实践。

Abstract: Fuzzing has become a popular technique for automatically detecting vulnerabilities and bugs by generating unexpected inputs. In recent years, the fuzzing process has been integrated into continuous integration workflows (i.e., continuous fuzzing), enabling short and frequent testing cycles. Despite its widespread adoption, prior research has not examined whether the effectiveness of continuous fuzzing varies across programming languages. This study conducts a large-scale cross-language analysis to examine how fuzzing bug characteristics and detection efficiency differ among languages. We analyze 61,444 fuzzing bugs and 999,248 builds from 559 OSS-Fuzz projects categorized by primary language. Our findings reveal that (i) C++ and Rust exhibit higher fuzzing bug detection frequencies, (ii) Rust and Python show low vulnerability ratios but tend to expose more critical vulnerabilities, (iii) crash types vary across languages and unreproducible bugs are more frequent in Go but rare in Rust, and (iv) Python attains higher patch coverage but suffers from longer time-to-detection. These results demonstrate that fuzzing behavior and effectiveness are strongly shaped by language design, providing insights for language-aware fuzzing strategies and tool development.

</details>


### [24] [ArkTS-CodeSearch: A Open-Source ArkTS Dataset for Code Retrieval](https://arxiv.org/abs/2602.05550)
*Yulong He,Artem Ermakov,Sergey Kovalchuk,Artem Aliev,Dmitry Shalymov*

Main category: cs.SE

TL;DR: 构建首个ArkTS代码智能数据集与评估基准，包含代码检索任务，评估现有代码嵌入模型并进行微调，发布数据集和模型


<details>
  <summary>Details</summary>
Motivation: OpenHarmony生态中的ArkTS语言缺乏公开数据集和评估基准，阻碍了代码智能研究的发展

Method: 从GitHub和Gitee爬取ArkTS仓库，使用tree-sitter-arkts提取注释-函数对，进行跨平台去重和统计分析，设计单搜索任务评估代码嵌入模型，使用ArkTS和TypeScript数据集进行微调

Result: 构建了大规模ArkTS数据集，评估了现有开源代码嵌入模型，通过微调获得了高性能的ArkTS代码理解模型，建立了首个系统性的ArkTS代码检索基准

Conclusion: 该工作填补了ArkTS代码智能研究的空白，提供了公开的数据集和模型，为ArkTS代码检索建立了首个系统性基准

Abstract: ArkTS is a core programming language in the OpenHarmony ecosystem, yet research on ArkTS code intelligence is hindered by the lack of public datasets and evaluation benchmarks. This paper presents a large-scale ArkTS dataset constructed from open-source repositories, targeting code retrieval and code evaluation tasks. We design a single-search task, where natural language comments are used to retrieve corresponding ArkTS functions. ArkTS repositories are crawled from GitHub and Gitee, and comment-function pairs are extracted using tree-sitter-arkts, followed by cross-platform deduplication and statistical analysis of ArkTS function types. We further evaluate all existing open-source code embedding models on the single-search task and perform fine-tuning using both ArkTS and TypeScript training datasets, resulting in a high-performing model for ArkTS code understanding. This work establishes the first systematic benchmark for ArkTS code retrieval. Both the dataset and our fine-tuned model will be released publicly and are available at https://huggingface.co/hreyulog/embedinggemma_arkts and https://huggingface.co/datasets/hreyulog/arkts-code-docstring,establishing the first systematic benchmark for ArkTS code retrieval.

</details>


### [25] [A Bayesian Optimization-Based AutoML Framework for Non-Intrusive Load Monitoring](https://arxiv.org/abs/2602.05739)
*Nazanin Siavash,Armin Moin*

Main category: cs.SE

TL;DR: 提出将AutoML应用于非侵入式负荷监测(NILM)的新框架，通过贝叶斯优化自动选择模型和调参，并开发了开源工具包AutoML4NILM


<details>
  <summary>Details</summary>
Motivation: NILM通过分析家庭总用电量来估算单个电器功耗，相比为每个电器安装智能电表更经济。但应用机器学习技术需要专业数据科学知识，限制了领域从业者的使用。

Method: 提出将自动化机器学习(AutoML)引入NILM领域的新框架，利用贝叶斯优化进行自动模型选择和超参数调优。开发了灵活可扩展的开源工具包AutoML4NILM，目前支持11种算法及其不同超参数。

Result: 该框架使领域从业者无需高级数据科学或机器学习专业知识就能有效应用机器学习技术。AutoML4NILM工具包旨在简化和促进能源分解中AutoML解决方案的部署。

Conclusion: 将AutoML引入NILM领域可以降低技术门槛，促进研究和工业应用。提出的框架和开源工具包为能源分解提供了灵活、可扩展的解决方案。

Abstract: Non-Intrusive Load Monitoring (NILM), commonly known as energy disaggregation, aims to estimate the power consumption of individual appliances by analyzing a home's total electricity usage. This method provides a cost-effective alternative to installing dedicated smart meters for each appliance. In this paper, we introduce a novel framework that incorporates Automated Machine Learning (AutoML) into the NILM domain, utilizing Bayesian Optimization for automated model selection and hyperparameter tuning. This framework empowers domain practitioners to effectively apply machine learning techniques without requiring advanced expertise in data science or machine learning. To support further research and industry adoption, we present AutoML4NILM, a flexible and extensible open-source toolkit designed to streamline the deployment of AutoML solutions for energy disaggregation. Currently, this framework supports 11 algorithms, each with different hyperparameters; however, its flexible design allows for the extension of both the algorithms and their hyperparameters.

</details>
