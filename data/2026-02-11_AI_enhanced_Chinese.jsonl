{"id": "2602.07090", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07090", "abs": "https://arxiv.org/abs/2602.07090", "authors": ["Yu-Che Tsai", "Hsiang Hsiao", "Kuan-Yu Chen", "Shou-De Lin"], "title": "Concept-Aware Privacy Mechanisms for Defending Embedding Inversion Attacks", "comment": null, "summary": "Text embeddings enable numerous NLP applications but face severe privacy risks from embedding inversion attacks, which can expose sensitive attributes or reconstruct raw text. Existing differential privacy defenses assume uniform sensitivity across embedding dimensions, leading to excessive noise and degraded utility. We propose SPARSE, a user-centric framework for concept-specific privacy protection in text embeddings. SPARSE combines (1) differentiable mask learning to identify privacy-sensitive dimensions for user-defined concepts, and (2) the Mahalanobis mechanism that applies elliptical noise calibrated by dimension sensitivity. Unlike traditional spherical noise injection, SPARSE selectively perturbs privacy-sensitive dimensions while preserving non-sensitive semantics. Evaluated across six datasets with three embedding models and attack scenarios, SPARSE consistently reduces privacy leakage while achieving superior downstream performance compared to state-of-the-art DP methods.", "AI": {"tldr": "SPARSE\u6846\u67b6\u901a\u8fc7\u53ef\u5fae\u5206\u63a9\u7801\u5b66\u4e60\u548c\u692d\u5706\u566a\u58f0\u6ce8\u5165\uff0c\u4e3a\u6587\u672c\u5d4c\u5165\u63d0\u4f9b\u6982\u5ff5\u7279\u5b9a\u7684\u9690\u79c1\u4fdd\u62a4\uff0c\u5728\u964d\u4f4e\u9690\u79c1\u6cc4\u9732\u7684\u540c\u65f6\u4fdd\u6301\u66f4\u597d\u7684\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u6587\u672c\u5d4c\u5165\u9762\u4e34\u4e25\u91cd\u7684\u9690\u79c1\u98ce\u9669\uff0c\u73b0\u6709\u7684\u5dee\u5206\u9690\u79c1\u9632\u5fa1\u65b9\u6cd5\u5047\u8bbe\u6240\u6709\u7ef4\u5ea6\u5177\u6709\u5747\u5300\u654f\u611f\u6027\uff0c\u5bfc\u81f4\u6dfb\u52a0\u8fc7\u591a\u566a\u58f0\u5e76\u964d\u4f4e\u5b9e\u7528\u6027\u3002", "method": "SPARSE\u6846\u67b6\u7ed3\u5408\uff1a(1) \u53ef\u5fae\u5206\u63a9\u7801\u5b66\u4e60\u6765\u8bc6\u522b\u7528\u6237\u5b9a\u4e49\u6982\u5ff5\u7684\u9690\u79c1\u654f\u611f\u7ef4\u5ea6\uff1b(2) \u9a6c\u54c8\u62c9\u8bfa\u6bd4\u65af\u673a\u5236\uff0c\u6839\u636e\u7ef4\u5ea6\u654f\u611f\u6027\u5e94\u7528\u692d\u5706\u566a\u58f0\u6821\u51c6\u3002", "result": "\u5728\u516d\u4e2a\u6570\u636e\u96c6\u3001\u4e09\u79cd\u5d4c\u5165\u6a21\u578b\u548c\u591a\u79cd\u653b\u51fb\u573a\u666f\u4e0b\u7684\u8bc4\u4f30\u663e\u793a\uff0cSPARSE\u80fd\u6301\u7eed\u51cf\u5c11\u9690\u79c1\u6cc4\u9732\uff0c\u540c\u65f6\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u5dee\u5206\u9690\u79c1\u65b9\u6cd5\u83b7\u5f97\u66f4\u4f18\u7684\u4e0b\u6e38\u6027\u80fd\u3002", "conclusion": "SPARSE\u901a\u8fc7\u9009\u62e9\u6027\u6270\u52a8\u9690\u79c1\u654f\u611f\u7ef4\u5ea6\u800c\u975e\u5747\u5300\u6dfb\u52a0\u566a\u58f0\uff0c\u5b9e\u73b0\u4e86\u6982\u5ff5\u7279\u5b9a\u7684\u9690\u79c1\u4fdd\u62a4\uff0c\u5728\u9690\u79c1\u4fdd\u62a4\u548c\u5b9e\u7528\u6027\u4e4b\u95f4\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u5e73\u8861\u3002"}}
{"id": "2602.07107", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07107", "abs": "https://arxiv.org/abs/2602.07107", "authors": ["Shang Liu", "Hanyu Pei", "Zeyan Liu"], "title": "ShallowJail: Steering Jailbreaks against Large Language Models", "comment": null, "summary": "Large Language Models(LLMs) have been successful in numerous fields. Alignment has usually been applied to prevent them from harmful purposes. However, aligned LLMs remain vulnerable to jailbreak attacks that deliberately mislead them into producing harmful outputs. Existing jailbreaks are either black-box, using carefully crafted, unstealthy prompts, or white-box, requiring resource-intensive computation. In light of these challenges, we introduce ShallowJail, a novel attack that exploits shallow alignment in LLMs. ShallowJail can misguide LLMs' responses by manipulating the initial tokens during inference. Through extensive experiments, we demonstrate the effectiveness of~\\shallow, which substantially degrades the safety of state-of-the-art LLM responses.", "AI": {"tldr": "ShallowJail\u662f\u4e00\u79cd\u65b0\u578b\u7684LLM\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u64cd\u7eb5\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u521d\u59cb\u4ee4\u724c\u6765\u8bef\u5bfc\u5bf9\u9f50\u6a21\u578b\u4ea7\u751f\u6709\u5bb3\u8f93\u51fa\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u9ad8\u6548\u4e14\u9690\u853d\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5df2\u7ecf\u8fdb\u884c\u4e86\u5bf9\u9f50\u8bad\u7ec3\u4ee5\u9632\u6b62\u6709\u5bb3\u7528\u9014\uff0c\u4f46\u5b83\u4eec\u4ecd\u7136\u5bb9\u6613\u53d7\u5230\u8d8a\u72f1\u653b\u51fb\u3002\u73b0\u6709\u7684\u8d8a\u72f1\u65b9\u6cd5\u8981\u4e48\u662f\u9ed1\u76d2\u653b\u51fb\uff08\u4f7f\u7528\u7cbe\u5fc3\u8bbe\u8ba1\u4f46\u4e0d\u591f\u9690\u853d\u7684\u63d0\u793a\uff09\uff0c\u8981\u4e48\u662f\u767d\u76d2\u653b\u51fb\uff08\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\uff09\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u4e14\u9690\u853d\u7684\u653b\u51fb\u65b9\u6cd5\u3002", "method": "ShallowJail\u901a\u8fc7\u5229\u7528LLMs\u7684\u6d45\u5c42\u5bf9\u9f50\u7279\u6027\uff0c\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u64cd\u7eb5\u521d\u59cb\u4ee4\u724c\u6765\u8bef\u5bfc\u6a21\u578b\u7684\u54cd\u5e94\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u9700\u8981\u590d\u6742\u7684\u63d0\u793a\u5de5\u7a0b\u6216\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\uff0cShallowJail\u80fd\u591f\u663e\u8457\u964d\u4f4e\u6700\u5148\u8fdbLLM\u7684\u5b89\u5168\u6027\uff0c\u4f7f\u5176\u4ea7\u751f\u6709\u5bb3\u8f93\u51fa\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "ShallowJail\u4f5c\u4e3a\u4e00\u79cd\u65b0\u578b\u7684\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86LLMs\u6d45\u5c42\u5bf9\u9f50\u7684\u8106\u5f31\u6027\uff0c\u4e3aLLM\u5b89\u5168\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u548c\u6311\u6218\u3002"}}
{"id": "2602.07072", "categories": ["cs.SE", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.07072", "abs": "https://arxiv.org/abs/2602.07072", "authors": ["Igor Costa"], "title": "AgentSpawn: Adaptive Multi-Agent Collaboration Through Dynamic Spawning for Long-Horizon Code Generation", "comment": "18 pages, 4 figures, 6 tables", "summary": "Long-horizon code generation requires sustained context and adaptive expertise across domains. Current multi-agent systems use static workflows that cannot adapt when runtime analysis reveals unanticipated complexity. We propose AgentSpawn, an architecture enabling dynamic agent collaboration through: (1) automatic memory transfer during spawning, (2) adaptive spawning policies triggered by runtime complexity metrics, and (3) coherence protocols for concurrent modifications. AgentSpawn addresses five critical gaps in existing research around memory continuity, skill inheritance, task resumption, runtime spawning, and concurrent coherence. Experimental validation demonstrates AgentSpawn achieves 34% higher completion rates than static baselines on benchmarks like SWE-bench while reducing memory overhead by 42% through selective slicing.", "AI": {"tldr": "AgentSpawn\u662f\u4e00\u4e2a\u52a8\u6001\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u67b6\u6784\uff0c\u901a\u8fc7\u81ea\u52a8\u5185\u5b58\u8f6c\u79fb\u3001\u81ea\u9002\u5e94\u751f\u6210\u7b56\u7565\u548c\u4e00\u81f4\u6027\u534f\u8bae\uff0c\u89e3\u51b3\u4e86\u957f\u65f6\u7a0b\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u4e0a\u4e0b\u6587\u6301\u7eed\u6027\u548c\u9886\u57df\u9002\u5e94\u6027\u95ee\u9898\u3002", "motivation": "\u957f\u65f6\u7a0b\u4ee3\u7801\u751f\u6210\u9700\u8981\u8de8\u9886\u57df\u7684\u6301\u7eed\u4e0a\u4e0b\u6587\u548c\u81ea\u9002\u5e94\u4e13\u4e1a\u77e5\u8bc6\u3002\u73b0\u6709\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4f7f\u7528\u9759\u6001\u5de5\u4f5c\u6d41\uff0c\u65e0\u6cd5\u5728\u8fd0\u884c\u65f6\u5206\u6790\u53d1\u73b0\u672a\u9884\u671f\u7684\u590d\u6742\u6027\u65f6\u8fdb\u884c\u9002\u5e94\u3002\u73b0\u6709\u7814\u7a76\u5728\u5185\u5b58\u8fde\u7eed\u6027\u3001\u6280\u80fd\u7ee7\u627f\u3001\u4efb\u52a1\u6062\u590d\u3001\u8fd0\u884c\u65f6\u751f\u6210\u548c\u5e76\u53d1\u4e00\u81f4\u6027\u65b9\u9762\u5b58\u5728\u4e94\u4e2a\u5173\u952e\u5dee\u8ddd\u3002", "method": "AgentSpawn\u67b6\u6784\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u673a\u5236\uff1a(1) \u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u81ea\u52a8\u5185\u5b58\u8f6c\u79fb\uff0c(2) \u7531\u8fd0\u884c\u65f6\u590d\u6742\u5ea6\u6307\u6807\u89e6\u53d1\u7684\u81ea\u9002\u5e94\u751f\u6210\u7b56\u7565\uff0c(3) \u5e76\u53d1\u4fee\u6539\u7684\u4e00\u81f4\u6027\u534f\u8bae\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793a\uff0cAgentSpawn\u5728SWE-bench\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u6bd4\u9759\u6001\u57fa\u7ebf\u5b9e\u73b0\u4e8634%\u66f4\u9ad8\u7684\u5b8c\u6210\u7387\uff0c\u540c\u65f6\u901a\u8fc7\u9009\u62e9\u6027\u5207\u7247\u51cf\u5c11\u4e8642%\u7684\u5185\u5b58\u5f00\u9500\u3002", "conclusion": "AgentSpawn\u901a\u8fc7\u52a8\u6001\u667a\u80fd\u4f53\u534f\u4f5c\u89e3\u51b3\u4e86\u73b0\u6709\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u957f\u65f6\u7a0b\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4efb\u52a1\u5b8c\u6210\u6548\u7387\u5e76\u964d\u4f4e\u4e86\u8d44\u6e90\u6d88\u8017\u3002"}}
{"id": "2602.07079", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07079", "abs": "https://arxiv.org/abs/2602.07079", "authors": ["Go Frendi Gunawan", "Mukhlis Amien"], "title": "Comprehensive Evaluation of Large Language Models on Software Engineering Tasks: A Multi-Task Benchmark", "comment": "10 pages, 7 figures. Under review. Code and data will be fully released", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in software engineering, yet comprehensive benchmarks covering diverse SE activities remain limited. We present a multi-task evaluation of 11 state-of-the-art LLMs across five representative software engineering tasks: bug fixing, feature development, code refactoring, technical copywriting, and research synthesis. Our automated verification framework measures both output quality and completion efficiency. Key findings reveal that (1) models achieving identical perfect scores exhibit 22x variation in completion time, 49x variation in tool efficiency, and 53x variation in estimated cost; (2) tool usage frequency shows no correlation with success (r = 0.077, p = 0.575) - one model used 917 tool calls while another solved the same task with 3 calls; (3) we identify two distinct inefficiency patterns: loop inefficiency and inference inefficiency; and (4) coding tasks achieve 100 percent success while research tasks present greater challenges (90.9 percent). We release all experimental data, verification scripts, and analysis code for full reproducibility.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5bf911\u4e2a\u5148\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u57285\u4e2a\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u591a\u4efb\u52a1\u8bc4\u4f30\uff0c\u53d1\u73b0\u6a21\u578b\u6027\u80fd\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff1a\u76f8\u540c\u6ee1\u5206\u6a21\u578b\u5728\u5b8c\u6210\u65f6\u95f4\u3001\u5de5\u5177\u6548\u7387\u548c\u6210\u672c\u4e0a\u5b58\u572822-53\u500d\u5dee\u5f02\uff0c\u5de5\u5177\u4f7f\u7528\u9891\u7387\u4e0e\u6210\u529f\u7387\u65e0\u5173\uff0c\u7f16\u7801\u4efb\u52a1\u6210\u529f\u7387100%\u800c\u7814\u7a76\u4efb\u52a1\u66f4\u5177\u6311\u6218\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u5c55\u73b0\u51fa\u5353\u8d8a\u80fd\u529b\uff0c\u4f46\u7f3a\u4e4f\u8986\u76d6\u591a\u6837\u5316SE\u6d3b\u52a8\u7684\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\u3002\u73b0\u6709\u8bc4\u4f30\u901a\u5e38\u5c40\u9650\u4e8e\u7279\u5b9a\u4efb\u52a1\uff0c\u65e0\u6cd5\u5168\u9762\u8861\u91cf\u6a21\u578b\u5728\u5b9e\u9645\u8f6f\u4ef6\u5de5\u7a0b\u5de5\u4f5c\u6d41\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u7814\u7a76\u91c7\u7528\u591a\u4efb\u52a1\u8bc4\u4f30\u6846\u67b6\uff0c\u5bf911\u4e2a\u6700\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\u57285\u4e2a\u4ee3\u8868\u6027\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff1abug\u4fee\u590d\u3001\u529f\u80fd\u5f00\u53d1\u3001\u4ee3\u7801\u91cd\u6784\u3001\u6280\u672f\u6587\u6848\u64b0\u5199\u548c\u7814\u7a76\u7efc\u5408\u3002\u5f00\u53d1\u4e86\u81ea\u52a8\u5316\u9a8c\u8bc1\u6846\u67b6\u6765\u6d4b\u91cf\u8f93\u51fa\u8d28\u91cf\u548c\u5b8c\u6210\u6548\u7387\u3002", "result": "\u5173\u952e\u53d1\u73b0\u5305\u62ec\uff1a1) \u83b7\u5f97\u76f8\u540c\u6ee1\u5206\u7684\u6a21\u578b\u5728\u5b8c\u6210\u65f6\u95f4\u4e0a\u5b58\u572822\u500d\u5dee\u5f02\uff0c\u5de5\u5177\u6548\u738749\u500d\u5dee\u5f02\uff0c\u4f30\u8ba1\u6210\u672c53\u500d\u5dee\u5f02\uff1b2) \u5de5\u5177\u4f7f\u7528\u9891\u7387\u4e0e\u6210\u529f\u7387\u65e0\u76f8\u5173\u6027\uff1b3) \u8bc6\u522b\u51fa\u4e24\u79cd\u4f4e\u6548\u6a21\u5f0f\uff1a\u5faa\u73af\u4f4e\u6548\u548c\u63a8\u7406\u4f4e\u6548\uff1b4) \u7f16\u7801\u4efb\u52a1\u6210\u529f\u7387100%\uff0c\u7814\u7a76\u4efb\u52a1\u66f4\u5177\u6311\u6218\u6027(90.9%)\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u5e94\u7528\u4e2d\u7684\u6548\u7387\u5dee\u5f02\u548c\u6210\u672c\u8003\u91cf\uff0c\u5f3a\u8c03\u4e86\u4ec5\u5173\u6ce8\u51c6\u786e\u6027\u800c\u5ffd\u89c6\u6548\u7387\u6307\u6807\u7684\u5c40\u9650\u6027\u3002\u7814\u7a76\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u5b9e\u9a8c\u6570\u636e\u3001\u9a8c\u8bc1\u811a\u672c\u548c\u5206\u6790\u4ee3\u7801\uff0c\u652f\u6301\u5b8c\u5168\u53ef\u91cd\u590d\u6027\u3002"}}
{"id": "2602.07034", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07034", "abs": "https://arxiv.org/abs/2602.07034", "authors": ["Jinxiu Qu", "Zirui Tang", "Hongzhang Huang", "Boyu Niu", "Wei Zhou", "Jiannan Wang", "Yitong Song", "Guoliang Li", "Xuanhe Zhou", "Fan Wu"], "title": "ST-Raptor: An Agentic System for Semi-Structured Table QA", "comment": null, "summary": "Semi-structured table question answering (QA) is a challenging task that requires (1) precise extraction of cell contents and positions and (2) accurate recovery of key implicit logical structures, hierarchical relationships, and semantic associations encoded in table layouts. In practice, such tables are often interpreted manually by human experts, which is labor-intensive and time-consuming. However, automating this process remains difficult. Existing Text-to-SQL methods typically require converting semi-structured tables into structured formats, inevitably leading to information loss, while approaches like Text-to-Code and multimodal LLM-based QA struggle with complex layouts and often yield inaccurate answers. To address these limitations, we present ST-Raptor, an agentic system for semi-structured table QA. ST-Raptor offers an interactive analysis environment that combines visual editing, tree-based structural modeling, and agent-driven query resolution to support accurate and user-friendly table understanding. Experimental results on both benchmark and real-world datasets demonstrate that ST-Raptor outperforms existing methods in both accuracy and usability. The code is available at https://github.com/weAIDB/ST-Raptor, and a demonstration video is available at https://youtu.be/9GDR-94Cau4.", "AI": {"tldr": "ST-Raptor\u662f\u4e00\u4e2a\u7528\u4e8e\u534a\u7ed3\u6784\u5316\u8868\u683c\u95ee\u7b54\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ed3\u5408\u89c6\u89c9\u7f16\u8f91\u3001\u6811\u5f62\u7ed3\u6784\u5efa\u6a21\u548c\u667a\u80fd\u4f53\u9a71\u52a8\u67e5\u8be2\u6765\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u4fe1\u606f\u635f\u5931\u548c\u590d\u6742\u5e03\u5c40\u5904\u7406\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u534a\u7ed3\u6784\u5316\u8868\u683c\u95ee\u7b54\u9700\u8981\u7cbe\u786e\u63d0\u53d6\u5355\u5143\u683c\u5185\u5bb9\u548c\u4f4d\u7f6e\uff0c\u5e76\u6062\u590d\u8868\u683c\u5e03\u5c40\u4e2d\u9690\u542b\u7684\u903b\u8f91\u7ed3\u6784\u3001\u5c42\u6b21\u5173\u7cfb\u548c\u8bed\u4e49\u5173\u8054\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\uff1aText-to-SQL\u65b9\u6cd5\u9700\u8981\u5c06\u534a\u7ed3\u6784\u5316\u8868\u683c\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u683c\u5f0f\u5bfc\u81f4\u4fe1\u606f\u635f\u5931\uff0c\u800cText-to-Code\u548c\u591a\u6a21\u6001LLM\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u590d\u6742\u5e03\u5c40\u4e14\u7b54\u6848\u4e0d\u51c6\u786e\u3002", "method": "ST-Raptor\u662f\u4e00\u4e2a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u63d0\u4f9b\u4ea4\u4e92\u5f0f\u5206\u6790\u73af\u5883\uff0c\u7ed3\u5408\u89c6\u89c9\u7f16\u8f91\u3001\u57fa\u4e8e\u6811\u7684\u7ed3\u6784\u5efa\u6a21\u548c\u667a\u80fd\u4f53\u9a71\u52a8\u7684\u67e5\u8be2\u89e3\u51b3\u673a\u5236\uff0c\u652f\u6301\u51c6\u786e\u4e14\u7528\u6237\u53cb\u597d\u7684\u8868\u683c\u7406\u89e3\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cST-Raptor\u5728\u51c6\u786e\u6027\u548c\u53ef\u7528\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "ST-Raptor\u901a\u8fc7\u521b\u65b0\u7684\u4ea4\u4e92\u5f0f\u667a\u80fd\u4f53\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u534a\u7ed3\u6784\u5316\u8868\u683c\u95ee\u7b54\u4e2d\u7684\u4fe1\u606f\u635f\u5931\u548c\u590d\u6742\u5e03\u5c40\u5904\u7406\u95ee\u9898\uff0c\u4e3a\u81ea\u52a8\u5316\u8868\u683c\u7406\u89e3\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.07080", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07080", "abs": "https://arxiv.org/abs/2602.07080", "authors": ["Yicheng He", "Zheng Zhao", "Zhou Kaiyu", "Bryan Dai", "Jie Fu", "Yonghui Yang"], "title": "CodeCircuit: Toward Inferring LLM-Generated Code Correctness via Attribution Graphs", "comment": null, "summary": "Current paradigms for code verification rely heavily on external mechanisms-such as execution-based unit tests or auxiliary LLM judges-which are often labor-intensive or limited by the judging model's own capabilities. This raises a fundamental, yet unexplored question: Can an LLM's functional correctness be assessed purely from its internal computational structure? Our primary objective is to investigate whether the model's neural dynamics encode internally decodable signals that are predictive of logical validity during code generation. Inspired by mechanistic interpretability, we propose to treat code verification as a mechanistic diagnostic task, mapping the model's explicit algorithmic trajectory into line-level attribution graphs. By decomposing complex residual flows, we aim to identify the structural signatures that distinguish sound reasoning from logical failure within the model's internal circuits. Analysis across Python, C++, and Java confirms that intrinsic correctness signals are robust across diverse syntaxes. Topological features from these internal graphs predict correctness more reliably than surface heuristics and enable targeted causal interventions to fix erroneous logic. These findings establish internal introspection as a decodable property for verifying generated code. Our code is at https:// github.com/bruno686/CodeCircuit.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4ee3\u7801\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790LLM\u5185\u90e8\u8ba1\u7b97\u7ed3\u6784\u6765\u8bc4\u4f30\u4ee3\u7801\u529f\u80fd\u6b63\u786e\u6027\uff0c\u65e0\u9700\u5916\u90e8\u6d4b\u8bd5\u6216\u5224\u65ad\u673a\u5236\u3002", "motivation": "\u5f53\u524d\u4ee3\u7801\u9a8c\u8bc1\u8303\u5f0f\u4e25\u91cd\u4f9d\u8d56\u5916\u90e8\u673a\u5236\uff08\u5982\u57fa\u4e8e\u6267\u884c\u7684\u5355\u5143\u6d4b\u8bd5\u6216\u8f85\u52a9LLM\u5224\u65ad\uff09\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u901a\u5e38\u52b3\u52a8\u5bc6\u96c6\u6216\u53d7\u9650\u4e8e\u5224\u65ad\u6a21\u578b\u81ea\u8eab\u80fd\u529b\u3002\u8bba\u6587\u65e8\u5728\u63a2\u7d22\u662f\u5426\u53ef\u4ee5\u4eceLLM\u5185\u90e8\u8ba1\u7b97\u7ed3\u6784\u4e2d\u7eaf\u7cb9\u8bc4\u4f30\u5176\u529f\u80fd\u6b63\u786e\u6027\u3002", "method": "\u53d7\u673a\u5236\u53ef\u89e3\u91ca\u6027\u542f\u53d1\uff0c\u5c06\u4ee3\u7801\u9a8c\u8bc1\u89c6\u4e3a\u673a\u5236\u8bca\u65ad\u4efb\u52a1\uff0c\u5c06\u6a21\u578b\u7684\u663e\u5f0f\u7b97\u6cd5\u8f68\u8ff9\u6620\u5c04\u5230\u884c\u7ea7\u5f52\u56e0\u56fe\u3002\u901a\u8fc7\u5206\u89e3\u590d\u6742\u6b8b\u5dee\u6d41\uff0c\u8bc6\u522b\u6a21\u578b\u5185\u90e8\u7535\u8def\u4e2d\u533a\u5206\u5408\u7406\u63a8\u7406\u4e0e\u903b\u8f91\u5931\u8d25\u7684\u7ed3\u6784\u7279\u5f81\u3002", "result": "\u5728Python\u3001C++\u548cJava\u4e0a\u7684\u5206\u6790\u8bc1\u5b9e\uff0c\u5185\u5728\u6b63\u786e\u6027\u4fe1\u53f7\u5728\u4e0d\u540c\u8bed\u6cd5\u4e2d\u5177\u6709\u9c81\u68d2\u6027\u3002\u4ece\u8fd9\u4e9b\u5185\u90e8\u56fe\u63d0\u53d6\u7684\u62d3\u6251\u7279\u5f81\u6bd4\u8868\u9762\u542f\u53d1\u5f0f\u65b9\u6cd5\u66f4\u53ef\u9760\u5730\u9884\u6d4b\u6b63\u786e\u6027\uff0c\u5e76\u80fd\u5b9e\u73b0\u6709\u9488\u5bf9\u6027\u7684\u56e0\u679c\u5e72\u9884\u6765\u4fee\u590d\u9519\u8bef\u903b\u8f91\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u786e\u7acb\u4e86\u5185\u90e8\u81ea\u7701\u4f5c\u4e3a\u9a8c\u8bc1\u751f\u6210\u4ee3\u7801\u7684\u53ef\u89e3\u7801\u5c5e\u6027\uff0c\u4e3a\u4ee3\u7801\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u65b0\u7684\u5185\u90e8\u89c6\u89d2\u65b9\u6cd5\u3002"}}
{"id": "2602.07035", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07035", "abs": "https://arxiv.org/abs/2602.07035", "authors": ["Jiahao Zhao", "Shaoxuan Xu", "Zhongxiang Sun", "Fengqi Zhu", "Jingyang Ou", "Yuling Shi", "Chongxuan Li", "Xiao Zhang", "Jun Xu"], "title": "DLLM-Searcher: Adapting Diffusion Large Language Model for Search Agents", "comment": null, "summary": "Recently, Diffusion Large Language Models (dLLMs) have demonstrated unique efficiency advantages, enabled by their inherently parallel decoding mechanism and flexible generation paradigm. Meanwhile, despite the rapid advancement of Search Agents, their practical deployment is constrained by a fundamental limitation, termed as 1) Latency Challenge: the serial execution of multi-round reasoning, tool calling, and tool response waiting under the ReAct agent paradigm induces severe end-to-end latency. Intuitively, dLLMs can leverage their distinctive strengths to optimize the operational efficiency of agents under the ReAct agent paradigm. Practically, existing dLLM backbones face the 2) Agent Ability Challenge. That is, existing dLLMs exhibit remarkably weak reasoning and tool-calling capabilities, preventing these advantages from being effectively realized in practice. In this paper, we propose DLLM-Searcher, an optimization framework for dLLM-based Search Agents. To solve the Agent Ability Challenge, we design a two-stage post-training pipeline encompassing Agentic Supervised Fine-Tuning (Agentic SFT) and Agentic Variance-Reduced Preference Optimization Agentic VRPO, which enhances the backbone dLLM's information seeking and reasoning capabilities. To mitigate the Latency Challenge, we leverage the flexible generation mechanism of dLLMs and propose a novel agent paradigm termed Parallel-Reasoning and Acting P-ReAct. P-ReAct guides the model to prioritize decoding tool_call instructions, thereby allowing the model to keep thinking while waiting for the tool's return. Experimental results demonstrate that DLLM-Searcher achieves performance comparable to mainstream LLM-based search agents and P-ReAct delivers approximately 15% inference acceleration. Our code is available at https://anonymous.4open.science/r/DLLM-Searcher-553C", "AI": {"tldr": "\u63d0\u51faDLLM-Searcher\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u540e\u8bad\u7ec3\u63d0\u5347\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u80fd\u529b\uff0c\u5e76\u8bbe\u8ba1P-ReAct\u5e76\u884c\u63a8\u7406\u6267\u884c\u8303\u5f0f\u6765\u964d\u4f4e\u641c\u7d22\u667a\u80fd\u4f53\u7684\u5ef6\u8fdf\u95ee\u9898\u3002", "motivation": "\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u5177\u6709\u5e76\u884c\u89e3\u7801\u548c\u7075\u6d3b\u751f\u6210\u7684\u4f18\u52bf\uff0c\u4f46\u73b0\u6709dLLMs\u5728\u63a8\u7406\u548c\u5de5\u5177\u8c03\u7528\u80fd\u529b\u4e0a\u8f83\u5f31\uff1b\u540c\u65f6\u641c\u7d22\u667a\u80fd\u4f53\u5728ReAct\u8303\u5f0f\u4e0b\u5b58\u5728\u4e25\u91cd\u7684\u7aef\u5230\u7aef\u5ef6\u8fdf\u95ee\u9898\u3002\u9700\u8981\u7ed3\u5408dLLMs\u7684\u4f18\u52bf\u6765\u4f18\u5316\u641c\u7d22\u667a\u80fd\u4f53\u7684\u8fd0\u884c\u6548\u7387\u3002", "method": "1) \u4e24\u9636\u6bb5\u540e\u8bad\u7ec3\uff1aAgentic SFT\uff08\u667a\u80fd\u4f53\u76d1\u7763\u5fae\u8c03\uff09\u548cAgentic VRPO\uff08\u667a\u80fd\u4f53\u65b9\u5dee\u51cf\u5c11\u504f\u597d\u4f18\u5316\uff09\uff0c\u63d0\u5347dLLM\u7684\u4fe1\u606f\u641c\u7d22\u548c\u63a8\u7406\u80fd\u529b\uff1b2) P-ReAct\u5e76\u884c\u63a8\u7406\u6267\u884c\u8303\u5f0f\uff1a\u5229\u7528dLLMs\u7684\u7075\u6d3b\u751f\u6210\u673a\u5236\uff0c\u4f18\u5148\u89e3\u7801\u5de5\u5177\u8c03\u7528\u6307\u4ee4\uff0c\u8ba9\u6a21\u578b\u5728\u7b49\u5f85\u5de5\u5177\u8fd4\u56de\u65f6\u7ee7\u7eed\u601d\u8003\u3002", "result": "DLLM-Searcher\u8fbe\u5230\u4e0e\u4e3b\u6d41LLM\u641c\u7d22\u667a\u80fd\u4f53\u76f8\u5f53\u7684\u6027\u80fd\uff0cP-ReAct\u8303\u5f0f\u5b9e\u73b0\u7ea615%\u7684\u63a8\u7406\u52a0\u901f\u3002", "conclusion": "\u63d0\u51fa\u7684DLLM-Searcher\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86dLLMs\u5728\u667a\u80fd\u4f53\u5e94\u7528\u4e2d\u7684\u80fd\u529b\u4e0d\u8db3\u95ee\u9898\uff0c\u5e76\u901a\u8fc7P-ReAct\u8303\u5f0f\u6709\u6548\u964d\u4f4e\u4e86\u641c\u7d22\u667a\u80fd\u4f53\u7684\u5ef6\u8fdf\uff0c\u4e3a\u9ad8\u6548\u641c\u7d22\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u65b0\u65b9\u6848\u3002"}}
{"id": "2602.07083", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07083", "abs": "https://arxiv.org/abs/2602.07083", "authors": ["Yongqing Jiang", "Jianze Wang", "Zhiqi Shen", "Zhenghong Lin", "Jiayuan Wang", "Yijian Yang", "Kaoshan Dai", "Haoran Luo"], "title": "Rethinking Scientific Modeling: Toward Physically Consistent and Simulation-Executable Programmatic Generation", "comment": null, "summary": "Structural modeling is a fundamental component of computational engineering science, in which even minor physical inconsistencies or specification violations may invalidate downstream simulations. The potential of large language models (LLMs) for automatic generation of modeling code has been demonstrated. However, non-executable or physically inconsistent outputs remain prevalent under stringent engineering constraints. A framework for physics-consistent automatic building modeling is therefore proposed, integrating domain knowledge construction, constraint-oriented model alignment, and verification-driven evaluation. CivilInstruct is introduced as a domain-specific dataset that formalizes structural engineering knowledge and constraint reasoning to enable simulation-ready model generation. A two-stage fine-tuning strategy is further employed to enforce constraint satisfaction and application programming interface compliance, substantially reducing hallucinated and non-conforming outputs. MBEval is presented as a verification-driven benchmark that evaluates executability and structural dynamics consistency through closed-loop validation. Experimental results show consistent improvements over baselines across rigorous verification metrics. Our code is available at https://github.com/Jovanqing/AutoBM.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7269\u7406\u4e00\u81f4\u7684\u81ea\u52a8\u5efa\u7b51\u5efa\u6a21\u6846\u67b6\uff0c\u901a\u8fc7\u9886\u57df\u77e5\u8bc6\u6784\u5efa\u3001\u7ea6\u675f\u5bfc\u5411\u7684\u6a21\u578b\u5bf9\u9f50\u548c\u9a8c\u8bc1\u9a71\u52a8\u7684\u8bc4\u4f30\uff0c\u89e3\u51b3LLM\u751f\u6210\u5efa\u6a21\u4ee3\u7801\u4e2d\u7684\u7269\u7406\u4e0d\u4e00\u81f4\u95ee\u9898\u3002", "motivation": "\u5728\u8ba1\u7b97\u5de5\u7a0b\u79d1\u5b66\u4e2d\uff0c\u7ed3\u6784\u5efa\u6a21\u662f\u57fa\u7840\u7ec4\u4ef6\uff0c\u5373\u4f7f\u5fae\u5c0f\u7684\u7269\u7406\u4e0d\u4e00\u81f4\u6216\u89c4\u8303\u8fdd\u53cd\u90fd\u53ef\u80fd\u4f7f\u4e0b\u6e38\u6a21\u62df\u65e0\u6548\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u751f\u6210\u5efa\u6a21\u4ee3\u7801\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u5728\u4e25\u683c\u7684\u5de5\u7a0b\u7ea6\u675f\u4e0b\uff0c\u4e0d\u53ef\u6267\u884c\u6216\u7269\u7406\u4e0d\u4e00\u81f4\u7684\u8f93\u51fa\u4ecd\u7136\u666e\u904d\u5b58\u5728\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u7269\u7406\u4e00\u81f4\u7684\u81ea\u52a8\u5efa\u7b51\u5efa\u6a21\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) CivilInstruct\u9886\u57df\u7279\u5b9a\u6570\u636e\u96c6\uff0c\u5f62\u5f0f\u5316\u7ed3\u6784\u5de5\u7a0b\u77e5\u8bc6\u548c\u7ea6\u675f\u63a8\u7406\uff1b2) \u4e24\u9636\u6bb5\u5fae\u8c03\u7b56\u7565\uff0c\u5f3a\u5236\u7ea6\u675f\u6ee1\u8db3\u548cAPI\u5408\u89c4\u6027\uff1b3) MBEval\u9a8c\u8bc1\u9a71\u52a8\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u95ed\u73af\u9a8c\u8bc1\u8bc4\u4f30\u53ef\u6267\u884c\u6027\u548c\u7ed3\u6784\u52a8\u529b\u5b66\u4e00\u81f4\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u4e25\u683c\u7684\u9a8c\u8bc1\u6307\u6807\u4e0a\u76f8\u6bd4\u57fa\u7ebf\u6a21\u578b\u6709\u6301\u7eed\u6539\u8fdb\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u5e7b\u89c9\u8f93\u51fa\u548c\u4e0d\u5408\u89c4\u8f93\u51fa\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u6574\u5408\u9886\u57df\u77e5\u8bc6\u3001\u7ea6\u675f\u5bfc\u5411\u7684\u6a21\u578b\u5bf9\u9f50\u548c\u9a8c\u8bc1\u9a71\u52a8\u7684\u8bc4\u4f30\uff0c\u5b9e\u73b0\u4e86\u7269\u7406\u4e00\u81f4\u7684\u81ea\u52a8\u5efa\u7b51\u5efa\u6a21\uff0c\u4e3a\u8ba1\u7b97\u5de5\u7a0b\u79d1\u5b66\u4e2d\u7684\u53ef\u9760\u6a21\u578b\u751f\u6210\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.07086", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07086", "abs": "https://arxiv.org/abs/2602.07086", "authors": ["Michael Marketsm\u00fcller", "Simon Martin", "Tim Schlippe"], "title": "Evaluating Retrieval-Augmented Generation Variants for Natural Language-Based SQL and API Call Generation", "comment": "preprint of conference submission", "summary": "Enterprise systems increasingly require natural language interfaces that can translate user requests into structured operations such as SQL queries and REST API calls. While large language models (LLMs) show promise for code generation [Chen et al., 2021; Huynh and Lin, 2025], their effectiveness in domain-specific enterprise contexts remains underexplored, particularly when both retrieval and modification tasks must be handled jointly. This paper presents a comprehensive evaluation of three retrieval-augmented generation (RAG) variants [Lewis et al., 2021] -- standard RAG, Self-RAG [Asai et al., 2024], and CoRAG [Wang et al., 2025] -- across SQL query generation, REST API call generation, and a combined task requiring dynamic task classification. Using SAP Transactional Banking as a realistic enterprise use case, we construct a novel test dataset covering both modalities and evaluate 18 experimental configurations under database-only, API-only, and hybrid documentation contexts. Results demonstrate that RAG is essential: Without retrieval, exact match accuracy is 0% across all tasks, whereas retrieval yields substantial gains in execution accuracy (up to 79.30%) and component match accuracy (up to 78.86%). Critically, CoRAG proves most robust in hybrid documentation settings, achieving statistically significant improvements in the combined task (10.29% exact match vs. 7.45% for standard RAG), driven primarily by superior SQL generation performance (15.32% vs. 11.56%). Our findings establish retrieval-policy design as a key determinant of production-grade natural language interfaces, showing that iterative query decomposition outperforms both top-k retrieval and binary relevance filtering under documentation heterogeneity.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bc4\u4f30\u4e86\u4e09\u79cdRAG\u53d8\u4f53\u5728SQL\u67e5\u8be2\u548cREST API\u8c03\u7528\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0CoRAG\u5728\u6df7\u5408\u6587\u6863\u73af\u5883\u4e0b\u8868\u73b0\u6700\u4f73\uff0c\u68c0\u7d22\u5bf9\u51c6\u786e\u7387\u63d0\u5347\u81f3\u5173\u91cd\u8981\u3002", "motivation": "\u4f01\u4e1a\u7cfb\u7edf\u9700\u8981\u81ea\u7136\u8bed\u8a00\u63a5\u53e3\u5c06\u7528\u6237\u8bf7\u6c42\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u64cd\u4f5c\uff08\u5982SQL\u67e5\u8be2\u548cREST API\u8c03\u7528\uff09\uff0c\u4f46LLM\u5728\u7279\u5b9a\u9886\u57df\u4f01\u4e1a\u73af\u5883\u4e2d\u7684\u6709\u6548\u6027\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u7279\u522b\u662f\u9700\u8981\u540c\u65f6\u5904\u7406\u68c0\u7d22\u548c\u4fee\u6539\u4efb\u52a1\u7684\u60c5\u51b5\u3002", "method": "\u4f7f\u7528SAP Transactional Banking\u4f5c\u4e3a\u4f01\u4e1a\u7528\u4f8b\uff0c\u6784\u5efa\u5305\u542bSQL\u548cREST API\u4e24\u79cd\u6a21\u6001\u7684\u65b0\u6d4b\u8bd5\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u4e09\u79cdRAG\u53d8\u4f53\uff08\u6807\u51c6RAG\u3001Self-RAG\u3001CoRAG\uff09\u572818\u79cd\u5b9e\u9a8c\u914d\u7f6e\u4e0b\u7684\u8868\u73b0\uff0c\u6db5\u76d6\u4ec5\u6570\u636e\u5e93\u3001\u4ec5API\u548c\u6df7\u5408\u6587\u6863\u4e09\u79cd\u4e0a\u4e0b\u6587\u3002", "result": "\u68c0\u7d22\u81f3\u5173\u91cd\u8981\uff1a\u65e0\u68c0\u7d22\u65f6\u6240\u6709\u4efb\u52a1\u7684\u7cbe\u786e\u5339\u914d\u51c6\u786e\u7387\u4e3a0%\uff0c\u800c\u68c0\u7d22\u4f7f\u6267\u884c\u51c6\u786e\u7387\u63d0\u5347\u81f3\u6700\u9ad879.30%\uff0c\u7ec4\u4ef6\u5339\u914d\u51c6\u786e\u7387\u6700\u9ad878.86%\u3002CoRAG\u5728\u6df7\u5408\u6587\u6863\u73af\u5883\u4e0b\u8868\u73b0\u6700\u7a33\u5065\uff0c\u5728\u7ec4\u5408\u4efb\u52a1\u4e2d\u5b9e\u73b010.29%\u7684\u7cbe\u786e\u5339\u914d\u51c6\u786e\u7387\uff08\u6807\u51c6RAG\u4e3a7.45%\uff09\uff0c\u4e3b\u8981\u5f97\u76ca\u4e8eSQL\u751f\u6210\u6027\u80fd\u4f18\u52bf\uff0815.32% vs 11.56%\uff09\u3002", "conclusion": "\u68c0\u7d22\u7b56\u7565\u8bbe\u8ba1\u662f\u751f\u4ea7\u7ea7\u81ea\u7136\u8bed\u8a00\u63a5\u53e3\u7684\u5173\u952e\u51b3\u5b9a\u56e0\u7d20\uff0c\u8fed\u4ee3\u67e5\u8be2\u5206\u89e3\u5728\u6587\u6863\u5f02\u6784\u73af\u5883\u4e0b\u4f18\u4e8etop-k\u68c0\u7d22\u548c\u4e8c\u5143\u76f8\u5173\u6027\u8fc7\u6ee4\uff0c\u4e3a\u6784\u5efa\u4f01\u4e1a\u7ea7NL-to-Code\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\u3002"}}
{"id": "2602.07187", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07187", "abs": "https://arxiv.org/abs/2602.07187", "authors": ["Hanyu Wang", "Yuanpu Cao", "Lu Lin", "Jinghui Chen"], "title": "PreFlect: From Retrospective to Prospective Reflection in Large Language Model Agents", "comment": null, "summary": "Advanced large language model agents typically adopt self-reflection for improving performance, where agents iteratively analyze past actions to correct errors. However, existing reflective approaches are inherently retrospective: agents act, observe failure, and only then attempt to recover. In this work, we introduce PreFlect, a prospective reflection mechanism that shifts the paradigm from post hoc correction to pre-execution foresight by criticizing and refining agent plans before execution. To support grounded prospective reflection, we distill planning errors from historical agent trajectories, capturing recurring success and failure patterns observed across past executions. Furthermore, we complement prospective reflection with a dynamic re-planning mechanism that provides execution-time plan update in case the original plan encounters unexpected deviation. Evaluations on different benchmarks demonstrate that PreFlect significantly improves overall agent utility on complex real-world tasks, outperforming strong reflection-based baselines and several more complex agent architectures. Code will be updated at https://github.com/wwwhy725/PreFlect.", "AI": {"tldr": "PreFlect\u63d0\u51fa\u524d\u77bb\u6027\u53cd\u601d\u673a\u5236\uff0c\u5c06LLM\u667a\u80fd\u4f53\u4ece\u4e8b\u540e\u7ea0\u9519\u8f6c\u5411\u6267\u884c\u524d\u9884\u5224\uff0c\u901a\u8fc7\u5386\u53f2\u8f68\u8ff9\u63d0\u70bc\u89c4\u5212\u9519\u8bef\u6a21\u5f0f\uff0c\u7ed3\u5408\u52a8\u6001\u91cd\u89c4\u5212\u63d0\u5347\u590d\u6742\u4efb\u52a1\u6027\u80fd", "motivation": "\u73b0\u6709\u53cd\u601d\u673a\u5236\u672c\u8d28\u4e0a\u662f\u56de\u987e\u6027\u7684\uff1a\u667a\u80fd\u4f53\u5148\u884c\u52a8\u3001\u89c2\u5bdf\u5931\u8d25\u3001\u7136\u540e\u5c1d\u8bd5\u6062\u590d\u3002\u8fd9\u79cd\u4e8b\u540e\u7ea0\u9519\u65b9\u5f0f\u6548\u7387\u6709\u9650\uff0c\u9700\u8981\u5728\u6267\u884c\u524d\u5c31\u80fd\u9884\u89c1\u548c\u907f\u514d\u9519\u8bef", "method": "1) \u524d\u77bb\u6027\u53cd\u601d\uff1a\u5728\u6267\u884c\u524d\u6279\u8bc4\u548c\u7cbe\u70bc\u667a\u80fd\u4f53\u8ba1\u5212\uff1b2) \u4ece\u5386\u53f2\u667a\u80fd\u4f53\u8f68\u8ff9\u4e2d\u63d0\u70bc\u89c4\u5212\u9519\u8bef\uff0c\u6355\u6349\u91cd\u590d\u7684\u6210\u529f\u548c\u5931\u8d25\u6a21\u5f0f\uff1b3) \u52a8\u6001\u91cd\u89c4\u5212\u673a\u5236\uff1a\u5f53\u539f\u59cb\u8ba1\u5212\u9047\u5230\u610f\u5916\u504f\u5dee\u65f6\u63d0\u4f9b\u6267\u884c\u65f6\u8ba1\u5212\u66f4\u65b0", "result": "\u5728\u4e0d\u540c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPreFlect\u663e\u8457\u63d0\u9ad8\u4e86\u590d\u6742\u73b0\u5b9e\u4e16\u754c\u4efb\u52a1\u7684\u6574\u4f53\u667a\u80fd\u4f53\u6548\u7528\uff0c\u4f18\u4e8e\u57fa\u4e8e\u53cd\u601d\u7684\u57fa\u7ebf\u65b9\u6cd5\u548c\u51e0\u79cd\u66f4\u590d\u6742\u7684\u667a\u80fd\u4f53\u67b6\u6784", "conclusion": "\u524d\u77bb\u6027\u53cd\u601d\u673a\u5236\u6bd4\u4f20\u7edf\u56de\u987e\u6027\u53cd\u601d\u66f4\u6709\u6548\uff0c\u901a\u8fc7\u6267\u884c\u524d\u9884\u5224\u548c\u52a8\u6001\u8c03\u6574\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347LLM\u667a\u80fd\u4f53\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u8868\u73b0"}}
{"id": "2602.07238", "categories": ["cs.AI", "cs.LG", "econ.GN"], "pdf": "https://arxiv.org/pdf/2602.07238", "abs": "https://arxiv.org/abs/2602.07238", "authors": ["Matthias Mertens", "Natalia Fischl-Lanzoni", "Neil Thompson"], "title": "Is there \"Secret Sauce'' in Large Language Model Development?", "comment": null, "summary": "Do leading LLM developers possess a proprietary ``secret sauce'', or is LLM performance driven by scaling up compute? Using training and benchmark data for 809 models released between 2022 and 2025, we estimate scaling-law regressions with release-date and developer fixed effects. We find clear evidence of developer-specific efficiency advantages, but their importance depends on where models lie in the performance distribution. At the frontier, 80-90% of performance differences are explained by higher training compute, implying that scale--not proprietary technology--drives frontier advances. Away from the frontier, however, proprietary techniques and shared algorithmic progress substantially reduce the compute required to reach fixed capability thresholds. Some companies can systematically produce smaller models more efficiently. Strikingly, we also find substantial variation of model efficiency within companies; a firm can train two models with more than 40x compute efficiency difference. We also discuss the implications for AI leadership and capability diffusion.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff1a\u5728AI\u524d\u6cbf\u9886\u57df\uff0c80-90%\u7684\u6027\u80fd\u5dee\u5f02\u7531\u8bad\u7ec3\u8ba1\u7b97\u91cf\u89e3\u91ca\uff0c\u800c\u975e\u4e13\u6709\u6280\u672f\uff1b\u4f46\u5728\u975e\u524d\u6cbf\u9886\u57df\uff0c\u4e13\u6709\u6280\u672f\u548c\u5171\u4eab\u7b97\u6cd5\u8fdb\u6b65\u663e\u8457\u964d\u4f4e\u8fbe\u5230\u7279\u5b9a\u80fd\u529b\u6240\u9700\u7684\u8ba1\u7b97\u91cf", "motivation": "\u63a2\u7a76\u9886\u5148LLM\u5f00\u53d1\u8005\u7684\u6027\u80fd\u4f18\u52bf\u662f\u6e90\u4e8e\u4e13\u6709\"\u79d8\u65b9\"\u8fd8\u662f\u5355\u7eaf\u7684\u8ba1\u7b97\u89c4\u6a21\u6269\u5c55\uff0c\u8fd9\u5bf9\u4e8e\u7406\u89e3AI\u9886\u5bfc\u5730\u4f4d\u548c\u6280\u672f\u6269\u6563\u5177\u6709\u91cd\u8981\u610f\u4e49", "method": "\u4f7f\u75282022-2025\u5e74\u95f4\u53d1\u5e03\u7684809\u4e2a\u6a21\u578b\u7684\u8bad\u7ec3\u548c\u57fa\u51c6\u6570\u636e\uff0c\u5efa\u7acb\u5305\u542b\u53d1\u5e03\u65e5\u671f\u548c\u5f00\u53d1\u8005\u56fa\u5b9a\u6548\u5e94\u7684\u6269\u5c55\u5b9a\u5f8b\u56de\u5f52\u6a21\u578b\u8fdb\u884c\u5206\u6790", "result": "1) \u524d\u6cbf\u9886\u57df\uff1a80-90%\u6027\u80fd\u5dee\u5f02\u7531\u66f4\u9ad8\u8bad\u7ec3\u8ba1\u7b97\u91cf\u89e3\u91ca\uff1b2) \u975e\u524d\u6cbf\u9886\u57df\uff1a\u4e13\u6709\u6280\u672f\u548c\u5171\u4eab\u7b97\u6cd5\u8fdb\u6b65\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u9700\u6c42\uff1b3) \u67d0\u4e9b\u516c\u53f8\u80fd\u7cfb\u7edf\u6027\u5730\u66f4\u9ad8\u6548\u751f\u4ea7\u8f83\u5c0f\u6a21\u578b\uff1b4) \u540c\u4e00\u516c\u53f8\u5185\u6a21\u578b\u6548\u7387\u5dee\u5f02\u53ef\u8fbe40\u500d\u4ee5\u4e0a", "conclusion": "\u524d\u6cbfAI\u8fdb\u6b65\u4e3b\u8981\u7531\u8ba1\u7b97\u89c4\u6a21\u9a71\u52a8\u800c\u975e\u4e13\u6709\u6280\u672f\uff0c\u4f46\u4e13\u6709\u6280\u672f\u5728\u4e2d\u4f4e\u7aef\u5e02\u573a\u4ecd\u5177\u91cd\u8981\u4ef7\u503c\uff1b\u516c\u53f8\u5185\u90e8\u6548\u7387\u5dee\u5f02\u663e\u8457\uff0c\u8fd9\u5bf9AI\u9886\u5bfc\u5730\u4f4d\u548c\u80fd\u529b\u6269\u6563\u5177\u6709\u91cd\u8981\u653f\u7b56\u542b\u4e49"}}
{"id": "2602.07412", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.07412", "abs": "https://arxiv.org/abs/2602.07412", "authors": ["Raula Gaikovina Kula", "Christoph Treude", "Xing Hu", "Sebastian Baltes", "Earl T. Barr", "Kelly Blincoe", "Fabio Calefato", "Junjie Chen", "Marc Cheong", "Youmei Fan", "Daniel M. German", "Marco Gerosa", "Jin L. C. Guo", "Shinpei Hayashi", "Robert Hirschfeld", "Reid Holmes", "Yintong Huo", "Takashi Kobayashi", "Michele Lanza", "Zhongxin Liu", "Olivier Nourry", "Nicole Novielli", "Denys Poshyvanyk", "Shinobu Saito", "Kazumasa Shimari", "Igor Steinmacher", "Mairieli Wessel", "Markus Wagner", "Annie Vella", "Laurie Williams", "Xin Xia"], "title": "Forecasting Developer Environments with GenAI: A Research Perspective", "comment": "IDE Workshop", "summary": "Generative Artificial Intelligence (GenAI) models are achieving remarkable performance in various tasks, including code generation, testing, code review, and program repair. The ability to increase the level of abstraction away from writing code has the potential to change the Human-AI interaction within the integrated development environment (IDE). To explore the impact of GenAI on IDEs, 33 experts from the Software Engineering, Artificial Intelligence, and Human-Computer Interaction domains gathered to discuss challenges and opportunities at Shonan Meeting 222, a four-day intensive research meeting. Four themes emerged as areas of interest for researchers and practitioners.", "AI": {"tldr": "\u4e13\u5bb6\u4f1a\u8bae\u63a2\u8ba8\u751f\u6210\u5f0fAI\u5bf9IDE\u7684\u5f71\u54cd\uff0c\u8bc6\u522b\u51fa\u56db\u4e2a\u5173\u952e\u7814\u7a76\u4e3b\u9898", "motivation": "\u751f\u6210\u5f0fAI\u5728\u4ee3\u7801\u751f\u6210\u3001\u6d4b\u8bd5\u3001\u4ee3\u7801\u5ba1\u67e5\u548c\u7a0b\u5e8f\u4fee\u590d\u7b49\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u53ef\u80fd\u6539\u53d8IDE\u4e2d\u7684\u4eba\u673a\u4ea4\u4e92\u65b9\u5f0f\u3002\u4e3a\u4e86\u63a2\u7d22\u8fd9\u79cd\u5f71\u54cd\uff0c\u6765\u81ea\u8f6f\u4ef6\u5de5\u7a0b\u3001\u4eba\u5de5\u667a\u80fd\u548c\u4eba\u673a\u4ea4\u4e92\u9886\u57df\u768433\u4f4d\u4e13\u5bb6\u53ec\u5f00\u4e86\u4e3a\u671f\u56db\u5929\u7684\u7814\u7a76\u4f1a\u8bae\u3002", "method": "\u901a\u8fc7Shonan Meeting 222\uff08\u4e3a\u671f\u56db\u5929\u7684\u5bc6\u96c6\u7814\u7a76\u4f1a\u8bae\uff09\uff0c\u6c47\u96c633\u4f4d\u8de8\u9886\u57df\u4e13\u5bb6\u8fdb\u884c\u8ba8\u8bba\uff0c\u8bc6\u522b\u6311\u6218\u548c\u673a\u9047\u3002", "result": "\u4f1a\u8bae\u8bc6\u522b\u51fa\u56db\u4e2a\u4e3b\u8981\u7684\u7814\u7a76\u4e3b\u9898\uff0c\u8fd9\u4e9b\u4e3b\u9898\u5bf9\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u90fd\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u5bf9IDE\u7684\u5f71\u54cd\u662f\u4e00\u4e2a\u91cd\u8981\u7684\u7814\u7a76\u9886\u57df\uff0c\u9700\u8981\u8de8\u5b66\u79d1\u5408\u4f5c\u6765\u63a2\u7d22\u5176\u6f5c\u5728\u53d8\u9769\u6027\u5f71\u54cd\u3002"}}
{"id": "2602.07253", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07253", "abs": "https://arxiv.org/abs/2602.07253", "authors": ["Litian Liu", "Reza Pourreza", "Yubing Jian", "Yao Qin", "Roland Memisevic"], "title": "From Out-of-Distribution Detection to Hallucination Detection: A Geometric View", "comment": null, "summary": "Detecting hallucinations in large language models is a critical open problem with significant implications for safety and reliability. While existing hallucination detection methods achieve strong performance in question-answering tasks, they remain less effective on tasks requiring reasoning. In this work, we revisit hallucination detection through the lens of out-of-distribution (OOD) detection, a well-studied problem in areas like computer vision. Treating next-token prediction in language models as a classification task allows us to apply OOD techniques, provided appropriate modifications are made to account for the structural differences in large language models. We show that OOD-based approaches yield training-free, single-sample-based detectors, achieving strong accuracy in hallucination detection for reasoning tasks. Overall, our work suggests that reframing hallucination detection as OOD detection provides a promising and scalable pathway toward language model safety.", "AI": {"tldr": "\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e7b\u89c9\u68c0\u6d4b\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5206\u5e03\u5916\u68c0\u6d4b\u95ee\u9898\uff0c\u63d0\u51fa\u65e0\u9700\u8bad\u7ec3\u7684\u5355\u6837\u672c\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u5e7b\u89c9\u68c0\u6d4b", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u68c0\u6d4b\u662f\u4e00\u4e2a\u5173\u952e\u4f46\u5c1a\u672a\u89e3\u51b3\u7684\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u95ee\u7b54\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9700\u8981\u63a8\u7406\u7684\u4efb\u52a1\u4e2d\u6548\u679c\u6709\u9650\u3002\u7814\u7a76\u8005\u5e0c\u671b\u901a\u8fc7\u501f\u9274\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u6210\u719f\u7684\u5206\u5e03\u5916\u68c0\u6d4b\u6280\u672f\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5c06\u8bed\u8a00\u6a21\u578b\u7684\u4e0b\u4e00\u4e2a\u8bcd\u9884\u6d4b\u89c6\u4e3a\u5206\u7c7b\u4efb\u52a1\uff0c\u5e94\u7528\u5206\u5e03\u5916\u68c0\u6d4b\u6280\u672f\uff0c\u5e76\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7ed3\u6784\u5dee\u5f02\u8fdb\u884c\u9002\u5f53\u4fee\u6539\uff0c\u5f00\u53d1\u65e0\u9700\u8bad\u7ec3\u7684\u5355\u6837\u672c\u68c0\u6d4b\u5668\u3002", "result": "\u57fa\u4e8e\u5206\u5e03\u5916\u68c0\u6d4b\u7684\u65b9\u6cd5\u5728\u63a8\u7406\u4efb\u52a1\u7684\u5e7b\u89c9\u68c0\u6d4b\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\uff0c\u8868\u660e\u8fd9\u79cd\u65b9\u6cd5\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "\u5c06\u5e7b\u89c9\u68c0\u6d4b\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5206\u5e03\u5916\u68c0\u6d4b\u95ee\u9898\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u4e14\u53ef\u6269\u5c55\u7684\u8def\u5f84\u3002"}}
{"id": "2602.07422", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07422", "abs": "https://arxiv.org/abs/2602.07422", "authors": ["Tianyi Wu", "Mingzhe Du", "Yue Liu", "Chengran Yang", "Terry Yue Zhuo", "Jiaheng Zhang", "See-Kiong Ng"], "title": "Secure Code Generation via Online Reinforcement Learning with Vulnerability Reward Model", "comment": null, "summary": "Large language models (LLMs) are increasingly used in software development, yet their tendency to generate insecure code remains a major barrier to real-world deployment. Existing secure code alignment methods often suffer from a functionality--security paradox, improving security at the cost of substantial utility degradation. We propose SecCoderX, an online reinforcement learning framework for functionality-preserving secure code generation. SecCoderX first bridges vulnerability detection and secure code generation by repurposing mature detection resources in two ways: (i) synthesizing diverse, reality-grounded vulnerability-inducing coding tasks for online RL rollouts, and (ii) training a reasoning-based vulnerability reward model that provides scalable and reliable security supervision. Together, these components are unified in an online RL loop to align code LLMs to generate secure and functional code. Extensive experiments demonstrate that SecCoderX achieves state-of-the-art performance, improving Effective Safety Rate (ESR) by approximately 10% over unaligned models, whereas prior methods often degrade ESR by 14-54%. We release our code, dataset and model checkpoints at https://github.com/AndrewWTY/SecCoderX.", "AI": {"tldr": "SecCoderX\u662f\u4e00\u4e2a\u57fa\u4e8e\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u529f\u80fd\u4fdd\u6301\u7684\u5b89\u5168\u4ee3\u7801\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5b89\u5168\u6027\u548c\u529f\u80fd\u6027\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u5176\u751f\u6210\u4e0d\u5b89\u5168\u4ee3\u7801\u7684\u503e\u5411\u963b\u788d\u4e86\u5b9e\u9645\u90e8\u7f72\u3002\u73b0\u6709\u5b89\u5168\u4ee3\u7801\u5bf9\u9f50\u65b9\u6cd5\u5b58\u5728\u529f\u80fd-\u5b89\u5168\u6096\u8bba\uff0c\u5373\u63d0\u9ad8\u5b89\u5168\u6027\u5f80\u5f80\u4ee5\u727a\u7272\u529f\u80fd\u6027\u4e3a\u4ee3\u4ef7\u3002", "method": "SecCoderX\u91c7\u7528\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u79cd\u65b9\u5f0f\u6865\u63a5\u6f0f\u6d1e\u68c0\u6d4b\u548c\u5b89\u5168\u4ee3\u7801\u751f\u6210\uff1a1) \u5229\u7528\u6210\u719f\u7684\u68c0\u6d4b\u8d44\u6e90\u5408\u6210\u591a\u6837\u5316\u7684\u73b0\u5b9e\u6f0f\u6d1e\u8bf1\u5bfc\u7f16\u7801\u4efb\u52a1\u7528\u4e8e\u5728\u7ebfRL\uff1b2) \u8bad\u7ec3\u57fa\u4e8e\u63a8\u7406\u7684\u6f0f\u6d1e\u5956\u52b1\u6a21\u578b\u63d0\u4f9b\u53ef\u6269\u5c55\u4e14\u53ef\u9760\u7684\u5b89\u5168\u76d1\u7763\u3002\u8fd9\u4e9b\u7ec4\u4ef6\u5728\u5728\u7ebfRL\u5faa\u73af\u4e2d\u7edf\u4e00\uff0c\u4ee5\u5bf9\u9f50\u4ee3\u7801LLMs\u751f\u6210\u5b89\u5168\u4e14\u529f\u80fd\u6027\u7684\u4ee3\u7801\u3002", "result": "\u5b9e\u9a8c\u8868\u660eSecCoderX\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5c06\u6709\u6548\u5b89\u5168\u7387(ESR)\u6bd4\u672a\u5bf9\u9f50\u6a21\u578b\u63d0\u9ad8\u7ea610%\uff0c\u800c\u5148\u524d\u65b9\u6cd5\u901a\u5e38\u4f7fESR\u964d\u4f4e14-54%\u3002", "conclusion": "SecCoderX\u6210\u529f\u89e3\u51b3\u4e86\u529f\u80fd-\u5b89\u5168\u6743\u8861\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u529f\u80fd\u4fdd\u6301\u7684\u5b89\u5168\u4ee3\u7801\u751f\u6210\uff0c\u4e3aLLMs\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5b89\u5168\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.07259", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07259", "abs": "https://arxiv.org/abs/2602.07259", "authors": ["Cheol Woo Kim", "Davin Choo", "Tzeh Yuan Neoh", "Milind Tambe"], "title": "Incentive-Aware AI Safety via Strategic Resource Allocation: A Stackelberg Security Games Perspective", "comment": null, "summary": "As AI systems grow more capable and autonomous, ensuring their safety and reliability requires not only model-level alignment but also strategic oversight of the humans and institutions involved in their development and deployment. Existing safety frameworks largely treat alignment as a static optimization problem (e.g., tuning models to desired behavior) while overlooking the dynamic, adversarial incentives that shape how data are collected, how models are evaluated, and how they are ultimately deployed. We propose a new perspective on AI safety grounded in Stackelberg Security Games (SSGs): a class of game-theoretic models designed for adversarial resource allocation under uncertainty. By viewing AI oversight as a strategic interaction between defenders (auditors, evaluators, and deployers) and attackers (malicious actors, misaligned contributors, or worst-case failure modes), SSGs provide a unifying framework for reasoning about incentive design, limited oversight capacity, and adversarial uncertainty across the AI lifecycle. We illustrate how this framework can inform (1) training-time auditing against data/feedback poisoning, (2) pre-deployment evaluation under constrained reviewer resources, and (3) robust multi-model deployment in adversarial environments. This synthesis bridges algorithmic alignment and institutional oversight design, highlighting how game-theoretic deterrence can make AI oversight proactive, risk-aware, and resilient to manipulation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5c06AI\u5b89\u5168\u89c6\u4e3aStackelberg\u5b89\u5168\u535a\u5f08\u95ee\u9898\uff0c\u5f3a\u8c03\u9700\u8981\u4ece\u9759\u6001\u6a21\u578b\u5bf9\u9f50\u8f6c\u5411\u52a8\u6001\u6218\u7565\u76d1\u7763\uff0c\u4ee5\u5e94\u5bf9AI\u5f00\u53d1\u90e8\u7f72\u4e2d\u7684\u5bf9\u6297\u6027\u6fc0\u52b1\u95ee\u9898\u3002", "motivation": "\u73b0\u6709AI\u5b89\u5168\u6846\u67b6\u4e3b\u8981\u5c06\u5bf9\u9f50\u89c6\u4e3a\u9759\u6001\u4f18\u5316\u95ee\u9898\uff0c\u5ffd\u7565\u4e86\u6570\u636e\u6536\u96c6\u3001\u6a21\u578b\u8bc4\u4f30\u548c\u90e8\u7f72\u8fc7\u7a0b\u4e2d\u7684\u52a8\u6001\u5bf9\u6297\u6027\u6fc0\u52b1\u3002\u968f\u7740AI\u7cfb\u7edf\u80fd\u529b\u589e\u5f3a\u548c\u81ea\u4e3b\u6027\u63d0\u9ad8\uff0c\u9700\u8981\u540c\u65f6\u8003\u8651\u6a21\u578b\u7ea7\u5bf9\u9f50\u548c\u4eba\u7c7b\u53ca\u673a\u6784\u7684\u6218\u7565\u76d1\u7763\u3002", "method": "\u91c7\u7528Stackelberg\u5b89\u5168\u535a\u5f08\u4f5c\u4e3a\u7406\u8bba\u57fa\u7840\uff0c\u5c06AI\u76d1\u7763\u89c6\u4e3a\u9632\u5fa1\u8005\uff08\u5ba1\u8ba1\u5458\u3001\u8bc4\u4f30\u8005\u3001\u90e8\u7f72\u8005\uff09\u4e0e\u653b\u51fb\u8005\uff08\u6076\u610f\u884c\u4e3a\u8005\u3001\u672a\u5bf9\u9f50\u8d21\u732e\u8005\u3001\u6700\u574f\u60c5\u51b5\u6545\u969c\u6a21\u5f0f\uff09\u4e4b\u95f4\u7684\u6218\u7565\u4e92\u52a8\u3002\u8be5\u6846\u67b6\u53ef\u7528\u4e8e\u5206\u6790\u6fc0\u52b1\u8bbe\u8ba1\u3001\u6709\u9650\u76d1\u7763\u80fd\u529b\u548c\u5bf9\u6297\u6027\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u8be5\u6846\u67b6\u53ef\u5e94\u7528\u4e8e\uff1a(1) \u8bad\u7ec3\u65f6\u5ba1\u8ba1\u5bf9\u6297\u6570\u636e/\u53cd\u9988\u6295\u6bd2\uff1b(2) \u6709\u9650\u8bc4\u5ba1\u8d44\u6e90\u4e0b\u7684\u9884\u90e8\u7f72\u8bc4\u4f30\uff1b(3) \u5bf9\u6297\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u591a\u6a21\u578b\u90e8\u7f72\u3002\u5c06\u7b97\u6cd5\u5bf9\u9f50\u4e0e\u5236\u5ea6\u76d1\u7763\u8bbe\u8ba1\u76f8\u7ed3\u5408\u3002", "conclusion": "\u57fa\u4e8eStackelberg\u5b89\u5168\u535a\u5f08\u7684\u89c6\u89d2\u4f7fAI\u76d1\u7763\u80fd\u591f\u4e3b\u52a8\u3001\u98ce\u9669\u611f\u77e5\u4e14\u6297\u64cd\u7eb5\uff0c\u901a\u8fc7\u535a\u5f08\u8bba\u5a01\u6151\u5c06\u7b97\u6cd5\u5bf9\u9f50\u4e0e\u5236\u5ea6\u76d1\u7763\u8bbe\u8ba1\u76f8\u7edf\u4e00\uff0c\u4e3aAI\u5168\u751f\u547d\u5468\u671f\u7684\u5b89\u5168\u63d0\u4f9b\u7cfb\u7edf\u6027\u6846\u67b6\u3002"}}
{"id": "2602.07513", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.07513", "abs": "https://arxiv.org/abs/2602.07513", "authors": ["Masato Kamba", "Akiyoshi Sannai"], "title": "SPECA: Specification-to-Checklist Agentic Auditing for Multi-Implementation Systems -- A Case Study on Ethereum Clients", "comment": null, "summary": "Multi-implementation systems are increasingly audited against natural-language specifications. Differential testing scales well when implementations disagree, but it provides little signal when all implementations converge on the same incorrect interpretation of an ambiguous requirement. We present SPECA, a Specification-to-Checklist Auditing framework that turns normative requirements into checklists, maps them to implementation locations, and supports cross-implementation reuse.\n  We instantiate SPECA in an in-the-wild security audit contest for the Ethereum Fusaka upgrade, covering 11 production clients. Across 54 submissions, 17 were judged valid by the contest organizers. Cross-implementation checks account for 76.5 percent (13 of 17) of valid findings, suggesting that checklist-derived one-to-many reuse is a practical scaling mechanism in multi-implementation audits. To understand false positives, we manually coded the 37 invalid submissions and find that threat model misalignment explains 56.8 percent (21 of 37): reports that rely on assumptions about trust boundaries or scope that contradict the audit's rules. We detected no High or Medium findings in the V1 deployment; misses concentrated in specification details and implicit assumptions (57.1 percent), timing and concurrency issues (28.6 percent), and external library dependencies (14.3 percent). Our improved agent, evaluated against the ground truth of a competitive audit, achieved a strict recall of 27.3 percent on high-impact vulnerabilities, placing it in the top 4 percent of human auditors and outperforming 49 of 51 contestants on critical issues. These results, though from a single deployment, suggest that early, explicit threat modeling is essential for reducing false positives and focusing agentic auditing effort. The agent-driven process enables expert validation and submission in about 40 minutes on average.", "AI": {"tldr": "SPECA\u6846\u67b6\u5c06\u89c4\u8303\u8981\u6c42\u8f6c\u5316\u4e3a\u68c0\u67e5\u6e05\u5355\uff0c\u652f\u6301\u591a\u5b9e\u73b0\u7cfb\u7edf\u7684\u5ba1\u8ba1\uff0c\u5728\u4ee5\u592a\u574aFusaka\u5347\u7ea7\u5ba1\u8ba1\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u667a\u80fd\u4f53\u5ba1\u8ba1\u8868\u73b0\u4f18\u4e8e\u5927\u591a\u6570\u4eba\u7c7b\u5ba1\u8ba1\u8005\u3002", "motivation": "\u591a\u5b9e\u73b0\u7cfb\u7edf\u5ba1\u8ba1\u9762\u4e34\u6311\u6218\uff1a\u5dee\u5f02\u6d4b\u8bd5\u5728\u5b9e\u73b0\u4e00\u81f4\u4f46\u9519\u8bef\u65f6\u6548\u679c\u6709\u9650\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u5ba1\u8ba1\u65b9\u6cd5\u6765\u5904\u7406\u6a21\u7cca\u8981\u6c42\u548c\u8de8\u5b9e\u73b0\u91cd\u7528\u3002", "method": "\u63d0\u51faSPECA\u6846\u67b6\uff1a\u5c06\u89c4\u8303\u8981\u6c42\u8f6c\u5316\u4e3a\u68c0\u67e5\u6e05\u5355\uff0c\u6620\u5c04\u5230\u5b9e\u73b0\u4f4d\u7f6e\uff0c\u652f\u6301\u8de8\u5b9e\u73b0\u91cd\u7528\u3002\u5728\u4ee5\u592a\u574aFusaka\u5347\u7ea7\u768411\u4e2a\u751f\u4ea7\u5ba2\u6237\u7aef\u5ba1\u8ba1\u4e2d\u5b9e\u4f8b\u5316\u8be5\u6846\u67b6\u3002", "result": "\u572854\u4efd\u63d0\u4ea4\u4e2d\uff0c17\u4efd\u6709\u6548\uff0c\u5176\u4e2d76.5%\u6765\u81ea\u8de8\u5b9e\u73b0\u68c0\u67e5\u3002\u6539\u8fdb\u540e\u7684\u667a\u80fd\u4f53\u5728\u5173\u952e\u6f0f\u6d1e\u4e0a\u7684\u4e25\u683c\u53ec\u56de\u7387\u8fbe\u523027.3%\uff0c\u8868\u73b0\u4f18\u4e8e49/51\u7684\u4eba\u7c7b\u5ba1\u8ba1\u8005\uff0c\u5e73\u574740\u5206\u949f\u5b8c\u6210\u4e13\u5bb6\u9a8c\u8bc1\u548c\u63d0\u4ea4\u3002", "conclusion": "\u68c0\u67e5\u6e05\u5355\u9a71\u52a8\u7684\u8de8\u5b9e\u73b0\u91cd\u7528\u662f\u6709\u6548\u7684\u5ba1\u8ba1\u6269\u5c55\u673a\u5236\uff0c\u65e9\u671f\u660e\u786e\u5a01\u80c1\u5efa\u6a21\u5bf9\u51cf\u5c11\u8bef\u62a5\u81f3\u5173\u91cd\u8981\uff0c\u667a\u80fd\u4f53\u5ba1\u8ba1\u5728\u7ade\u4e89\u6027\u5ba1\u8ba1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5177\u5907\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.07561", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.07561", "abs": "https://arxiv.org/abs/2602.07561", "authors": ["Quanjun Zhang", "Ye Shang", "Haichuan Hu", "Chunrong Fang", "Zhenyu Chen", "Liang Xiao"], "title": "ComPass: Contrastive Learning for Automated Patch Correctness Assessment in Program Repair", "comment": "30 pages, 3 figures", "summary": "Automated program repair (APR) attempts to reduce manual debugging efforts and plays a vital role in software maintenance. Despite remarkable progress, APR is still limited in generating overfitting patches, i.e., patches passing available test suites but incorrect. This issue, known as patch overfitting, has become a key concern in the APR community, with numerous approaches proposed to address it. Very recent work proposes a pre-trained language model (PLM)-based automated patch correctness assessment (APCA) approach, indicating the potential of such PLMs in reasoning about patch correctness. Despite being promising, it is still far from perfect due to various limitations, such as the training paradigm and training dataset. In this paper, we present ComPass, a PLM-based APCA approach that leverages contrastive learning and data augmentation to address the technical limitations of prior work. Our work is inspired by the opportunity to integrate contrastive learning with recent PLMs in the field of patch correctness assessment, where large-scale labeled patches are difficult to obtain. ComPass utilizes code transformation rules to generate semantic-preserving code snippets for both unlabeled pre-training corpus and labeled fine-tuning patches. ComPass then pre-trains PLMs with contrastive learning, which captures code features with the same semantics but different structures. ComPass finally integrates representation embeddings of patch code snippets and fine-tunes PLMs with a binary classifier jointly to assess patch code correctness. Experimental results on 2274 real-world patches from Defects4J demonstrate that ComPass achieves an accuracy of 88.35%, significantly outperforming state-of-the-art baseline APPT.", "AI": {"tldr": "ComPass\u662f\u4e00\u4e2a\u57fa\u4e8e\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u8865\u4e01\u6b63\u786e\u6027\u8bc4\u4f30\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u548c\u6570\u636e\u589e\u5f3a\u6280\u672f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8865\u4e01\u6b63\u786e\u6027\u5224\u65ad\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d(APR)\u5728\u751f\u6210\u8865\u4e01\u65f6\u5b58\u5728\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u5373\u8865\u4e01\u80fd\u901a\u8fc7\u6d4b\u8bd5\u5957\u4ef6\u4f46\u5b9e\u9645\u4e0a\u4e0d\u6b63\u786e\u3002\u73b0\u6709\u7684\u57fa\u4e8e\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b(PLM)\u7684\u81ea\u52a8\u8865\u4e01\u6b63\u786e\u6027\u8bc4\u4f30(APCA)\u65b9\u6cd5\u4ecd\u6709\u5404\u79cd\u9650\u5236\uff0c\u5982\u8bad\u7ec3\u8303\u5f0f\u548c\u6570\u636e\u96c6\u7684\u4e0d\u8db3\u3002", "method": "ComPass\u91c7\u7528\u5bf9\u6bd4\u5b66\u4e60\u548c\u6570\u636e\u589e\u5f3a\u6280\u672f\uff1a1)\u4f7f\u7528\u4ee3\u7801\u8f6c\u6362\u89c4\u5219\u751f\u6210\u8bed\u4e49\u4fdd\u6301\u4f46\u7ed3\u6784\u4e0d\u540c\u7684\u4ee3\u7801\u7247\u6bb5\uff1b2)\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u9884\u8bad\u7ec3PLM\u4ee5\u6355\u6349\u76f8\u540c\u8bed\u4e49\u4f46\u4e0d\u540c\u7ed3\u6784\u7684\u4ee3\u7801\u7279\u5f81\uff1b3)\u96c6\u6210\u8865\u4e01\u4ee3\u7801\u7247\u6bb5\u7684\u8868\u793a\u5d4c\u5165\uff0c\u5e76\u4f7f\u7528\u4e8c\u5143\u5206\u7c7b\u5668\u8054\u5408\u5fae\u8c03PLM\u6765\u8bc4\u4f30\u8865\u4e01\u6b63\u786e\u6027\u3002", "result": "\u5728Defects4J\u76842274\u4e2a\u771f\u5b9e\u4e16\u754c\u8865\u4e01\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cComPass\u8fbe\u5230\u4e8688.35%\u7684\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5APPT\u3002", "conclusion": "ComPass\u901a\u8fc7\u7ed3\u5408\u5bf9\u6bd4\u5b66\u4e60\u548c\u6570\u636e\u589e\u5f3a\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u6807\u8bb0\u8865\u4e01\u6570\u636e\u96be\u4ee5\u83b7\u53d6\u7684\u95ee\u9898\uff0c\u5728\u81ea\u52a8\u8865\u4e01\u6b63\u786e\u6027\u8bc4\u4f30\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\uff0c\u4e3a\u51cf\u5c11\u7a0b\u5e8f\u4fee\u590d\u4e2d\u7684\u8fc7\u62df\u5408\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.07267", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07267", "abs": "https://arxiv.org/abs/2602.07267", "authors": ["Fengyuan Liu", "Jay Gala", "Nilaksh", "Dzmitry Bahdanau", "Siva Reddy", "Hugo Larochelle"], "title": "BRIDGE: Predicting Human Task Completion Time From Model Performance", "comment": null, "summary": "Evaluating the real-world capabilities of AI systems requires grounding benchmark performance in human-interpretable measures of task difficulty. Existing approaches that rely on direct human task completion time annotations are costly, noisy, and difficult to scale across benchmarks. In this work, we propose BRIDGE, a unified psychometric framework that learns the latent difficulty scale from model responses and anchors it to human task completion time. Using a two-parameter logistic Item Response Theory model, we jointly estimate latent task difficulty and model capability from model performance data across multiple benchmarks. We demonstrate that latent task difficulty varies linearly with the logarithm of human completion time, allowing human task completion time to be inferred for new benchmarks from model performance alone. Leveraging this alignment, we forecast frontier model capabilities in terms of human task length and independently reproduce METR's exponential scaling results, with the 50% solvable task horizon doubling approximately every 6 months.", "AI": {"tldr": "BRIDGE\u6846\u67b6\u901a\u8fc7AI\u6a21\u578b\u54cd\u5e94\u5b66\u4e60\u4efb\u52a1\u96be\u5ea6\u6807\u5ea6\uff0c\u5e76\u5c06\u5176\u4e0e\u4eba\u7c7b\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u5bf9\u9f50\uff0c\u5b9e\u73b0\u4ec5\u4ece\u6a21\u578b\u6027\u80fd\u9884\u6d4b\u4eba\u7c7b\u4efb\u52a1\u65f6\u95f4\uff0c\u5e76\u9884\u6d4b\u524d\u6cbf\u6a21\u578b\u80fd\u529b\u5448\u6307\u6570\u589e\u957f\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u4eba\u7c7b\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u6ce8\u91ca\u7684AI\u7cfb\u7edf\u8bc4\u4f30\u65b9\u6cd5\u6210\u672c\u9ad8\u3001\u566a\u58f0\u5927\u4e14\u96be\u4ee5\u6269\u5c55\uff0c\u9700\u8981\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u5c06\u57fa\u51c6\u6027\u80fd\u4e0e\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u4efb\u52a1\u96be\u5ea6\u5ea6\u91cf\u8054\u7cfb\u8d77\u6765\u3002", "method": "\u63d0\u51faBRIDGE\u5fc3\u7406\u6d4b\u91cf\u6846\u67b6\uff0c\u4f7f\u7528\u53cc\u53c2\u6570\u903b\u8f91\u9879\u76ee\u53cd\u5e94\u7406\u8bba\u6a21\u578b\uff0c\u4ece\u591a\u4e2a\u57fa\u51c6\u7684\u6a21\u578b\u6027\u80fd\u6570\u636e\u4e2d\u8054\u5408\u4f30\u8ba1\u6f5c\u5728\u4efb\u52a1\u96be\u5ea6\u548c\u6a21\u578b\u80fd\u529b\uff0c\u53d1\u73b0\u6f5c\u5728\u4efb\u52a1\u96be\u5ea6\u4e0e\u4eba\u7c7b\u5b8c\u6210\u65f6\u95f4\u7684\u5bf9\u6570\u5448\u7ebf\u6027\u5173\u7cfb\u3002", "result": "\u6f5c\u5728\u4efb\u52a1\u96be\u5ea6\u4e0e\u4eba\u7c7b\u5b8c\u6210\u65f6\u95f4\u7684\u5bf9\u6570\u5448\u7ebf\u6027\u5173\u7cfb\uff0c\u4f7f\u5f97\u4ec5\u4ece\u6a21\u578b\u6027\u80fd\u5c31\u80fd\u63a8\u65ad\u65b0\u57fa\u51c6\u7684\u4eba\u7c7b\u4efb\u52a1\u65f6\u95f4\uff1b\u6210\u529f\u9884\u6d4b\u524d\u6cbf\u6a21\u578b\u80fd\u529b\uff0850%\u53ef\u89e3\u51b3\u4efb\u52a1\u8303\u56f4\u6bcf\u7ea66\u4e2a\u6708\u7ffb\u500d\uff09\uff0c\u72ec\u7acb\u91cd\u73b0\u4e86METR\u7684\u6307\u6570\u7f29\u653e\u7ed3\u679c\u3002", "conclusion": "BRIDGE\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u5c06AI\u57fa\u51c6\u6027\u80fd\u4e0e\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u4efb\u52a1\u96be\u5ea6\u5ea6\u91cf\u5bf9\u9f50\uff0c\u80fd\u591f\u4ec5\u4ece\u6a21\u578b\u6027\u80fd\u9884\u6d4b\u4eba\u7c7b\u4efb\u52a1\u65f6\u95f4\uff0c\u5e76\u9a8c\u8bc1\u4e86AI\u80fd\u529b\u5448\u6307\u6570\u589e\u957f\u7684\u8d8b\u52bf\u3002"}}
{"id": "2602.07517", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2602.07517", "abs": "https://arxiv.org/abs/2602.07517", "authors": ["Yuhao Wang", "Shengfang Zhai", "Guanghao Jin", "Yinpeng Dong", "Linyi Yang", "Jiaheng Zhang"], "title": "MemPot: Defending Against Memory Extraction Attack with Optimized Honeypots", "comment": null, "summary": "Large Language Model (LLM)-based agents employ external and internal memory systems to handle complex, goal-oriented tasks, yet this exposes them to severe extraction attacks, and effective defenses remain lacking. In this paper, we propose MemPot, the first theoretically verified defense framework against memory extraction attacks by injecting optimized honeypots into the memory. Through a two-stage optimization process, MemPot generates trap documents that maximize the retrieval probability for attackers while remaining inconspicuous to benign users. We model the detection process as Wald's Sequential Probability Ratio Test (SPRT) and theoretically prove that MemPot achieves a lower average number of sampling rounds compared to optimal static detectors. Empirically, MemPot significantly outperforms state-of-the-art baselines, achieving a 50% improvement in detection AUROC and an 80% increase in True Positive Rate under low False Positive Rate constraints. Furthermore, our experiments confirm that MemPot incurs zero additional online inference latency and preserves the agent's utility on standard tasks, verifying its superiority in safety, harmlessness, and efficiency.", "AI": {"tldr": "MemPot\u662f\u4e00\u4e2a\u9488\u5bf9LLM\u667a\u80fd\u4f53\u5185\u5b58\u63d0\u53d6\u653b\u51fb\u7684\u9632\u5fa1\u6846\u67b6\uff0c\u901a\u8fc7\u6ce8\u5165\u4f18\u5316\u7684\u871c\u7f50\u6587\u6863\u6765\u68c0\u6d4b\u653b\u51fb\uff0c\u5728\u4fdd\u6301\u96f6\u989d\u5916\u5728\u7ebf\u63a8\u7406\u5ef6\u8fdf\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "LLM\u667a\u80fd\u4f53\u4f7f\u7528\u5916\u90e8\u548c\u5185\u90e8\u5185\u5b58\u7cfb\u7edf\u5904\u7406\u590d\u6742\u4efb\u52a1\uff0c\u4f46\u8fd9\u4f7f\u5176\u9762\u4e34\u4e25\u91cd\u7684\u5185\u5b58\u63d0\u53d6\u653b\u51fb\uff0c\u800c\u76ee\u524d\u7f3a\u4e4f\u6709\u6548\u7684\u9632\u5fa1\u673a\u5236\u3002", "method": "\u63d0\u51faMemPot\u9632\u5fa1\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u4f18\u5316\u8fc7\u7a0b\u751f\u6210\u871c\u7f50\u6587\u6863\uff1a\u6700\u5927\u5316\u653b\u51fb\u8005\u68c0\u7d22\u6982\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u826f\u6027\u7528\u6237\u7684\u9690\u853d\u6027\u3002\u4f7f\u7528Wald\u7684\u5e8f\u8d2f\u6982\u7387\u6bd4\u68c0\u9a8c(SPRT)\u5efa\u6a21\u68c0\u6d4b\u8fc7\u7a0b\u3002", "result": "MemPot\u5728\u68c0\u6d4bAUROC\u4e0a\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u534750%\uff0c\u5728\u4f4e\u8bef\u62a5\u7387\u7ea6\u675f\u4e0b\u771f\u9633\u6027\u7387\u63d0\u534780%\u3002\u7406\u8bba\u8bc1\u660e\u6bd4\u6700\u4f18\u9759\u6001\u68c0\u6d4b\u5668\u9700\u8981\u66f4\u5c11\u7684\u91c7\u6837\u8f6e\u6b21\uff0c\u4e14\u4fdd\u6301\u96f6\u989d\u5916\u5728\u7ebf\u63a8\u7406\u5ef6\u8fdf\u3002", "conclusion": "MemPot\u662f\u9996\u4e2a\u7ecf\u8fc7\u7406\u8bba\u9a8c\u8bc1\u7684\u9632\u5fa1\u6846\u67b6\uff0c\u5728\u5b89\u5168\u6027\u3001\u65e0\u5bb3\u6027\u548c\u6548\u7387\u65b9\u9762\u5177\u6709\u4f18\u8d8a\u6027\uff0c\u80fd\u6709\u6548\u4fdd\u62a4LLM\u667a\u80fd\u4f53\u514d\u53d7\u5185\u5b58\u63d0\u53d6\u653b\u51fb\u3002"}}
{"id": "2602.07569", "categories": ["cs.SE", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.07569", "abs": "https://arxiv.org/abs/2602.07569", "authors": ["Eduardo C. Peixoto", "Hector Oliveira", "Geber L. Ramalho", "Cesar Fran\u00e7a"], "title": "Clarifying Core Dimensions in Digital Maturity Models: An Integrative Approach", "comment": "34 pages, 8 figures, 10 tables, 2 appendices", "summary": "Digital Transformation (DT) initiatives frequently face high failure rates, and while Digital Maturity Models (DMMs) offer potential solutions, they have notable shortcomings. Specifically, there is significant disparity in the dimensions considered relevant, a lack of clarity in their definitions, and uncertainty regarding their components. This study aims to provide a clearer understanding of DMMs by proposing integrative definitions of the most frequently used dimensions. Using a Systematic Mapping approach, including automatic search and snowballing techniques, we analyzed 76 DMMs to answer two Research Questions: (RQ1) What are the most frequent dimensions in DMMs? and (RQ2) How are these dimensions described, including their components? We reconcile varying interpretations of the ten most frequent dimensions -- Organization, Strategy, Technology, Culture, Process, Operations, People, Management, Customer, and Data -- and propose integrative definitions for each. Compared to previous analyses, this study provides a broader and more recent perspective on Digital Maturity Models.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u7cfb\u7edf\u6620\u5c04\u65b9\u6cd5\u5206\u6790\u4e8676\u4e2a\u6570\u5b57\u6210\u719f\u5ea6\u6a21\u578b\uff0c\u8bc6\u522b\u51fa\u6700\u5e38\u7528\u768410\u4e2a\u7ef4\u5ea6\u5e76\u63d0\u51fa\u4e86\u6574\u5408\u6027\u5b9a\u4e49\uff0c\u4ee5\u89e3\u51b3\u6570\u5b57\u8f6c\u578b\u5931\u8d25\u7387\u9ad8\u548c\u73b0\u6709\u6a21\u578b\u7ef4\u5ea6\u5b9a\u4e49\u6a21\u7cca\u7684\u95ee\u9898\u3002", "motivation": "\u6570\u5b57\u8f6c\u578b\u9879\u76ee\u5931\u8d25\u7387\u9ad8\uff0c\u6570\u5b57\u6210\u719f\u5ea6\u6a21\u578b\u867d\u6709\u6f5c\u529b\u4f46\u5b58\u5728\u660e\u663e\u7f3a\u9677\uff1a\u7ef4\u5ea6\u5b9a\u4e49\u4e0d\u4e00\u81f4\u3001\u6982\u5ff5\u4e0d\u6e05\u6670\u3001\u7ec4\u4ef6\u4e0d\u660e\u786e\uff0c\u9700\u8981\u66f4\u6e05\u6670\u7684\u7406\u89e3\u6846\u67b6\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6620\u5c04\u65b9\u6cd5\uff0c\u5305\u62ec\u81ea\u52a8\u641c\u7d22\u548c\u6eda\u96ea\u7403\u6280\u672f\uff0c\u5206\u679076\u4e2a\u6570\u5b57\u6210\u719f\u5ea6\u6a21\u578b\uff0c\u56de\u7b54\u4e24\u4e2a\u7814\u7a76\u95ee\u9898\uff1a\u6700\u5e38\u7528\u7684\u7ef4\u5ea6\u662f\u4ec0\u4e48\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u7ef4\u5ea6\u5982\u4f55\u63cf\u8ff0\uff08\u5305\u62ec\u5176\u7ec4\u4ef6\uff09\u3002", "result": "\u8bc6\u522b\u51fa10\u4e2a\u6700\u5e38\u7528\u7684\u7ef4\u5ea6\uff1a\u7ec4\u7ec7\u3001\u6218\u7565\u3001\u6280\u672f\u3001\u6587\u5316\u3001\u6d41\u7a0b\u3001\u8fd0\u8425\u3001\u4eba\u5458\u3001\u7ba1\u7406\u3001\u5ba2\u6237\u548c\u6570\u636e\uff0c\u5e76\u5bf9\u6bcf\u4e2a\u7ef4\u5ea6\u63d0\u51fa\u4e86\u6574\u5408\u6027\u5b9a\u4e49\uff0c\u63d0\u4f9b\u4e86\u6bd4\u4ee5\u5f80\u5206\u6790\u66f4\u5e7f\u6cdb\u548c\u66f4\u65b0\u7684\u89c6\u89d2\u3002", "conclusion": "\u7814\u7a76\u901a\u8fc7\u6574\u5408\u4e0d\u540c\u89e3\u91ca\uff0c\u4e3a\u6570\u5b57\u6210\u719f\u5ea6\u6a21\u578b\u7684\u6838\u5fc3\u7ef4\u5ea6\u63d0\u4f9b\u4e86\u66f4\u6e05\u6670\u7684\u5b9a\u4e49\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u6570\u5b57\u8f6c\u578b\u9879\u76ee\u7684\u6210\u529f\u7387\u3002"}}
{"id": "2602.07274", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07274", "abs": "https://arxiv.org/abs/2602.07274", "authors": ["Kaijie Zhu", "Yuzhou Nie", "Yijiang Li", "Yiming Huang", "Jialian Wu", "Jiang Liu", "Ximeng Sun", "Zhenfei Yin", "Lun Wang", "Zicheng Liu", "Emad Barsoum", "William Yang Wang", "Wenbo Guo"], "title": "TermiGen: High-Fidelity Environment and Robust Trajectory Synthesis for Terminal Agents", "comment": null, "summary": "Executing complex terminal tasks remains a significant challenge for open-weight LLMs, constrained by two fundamental limitations. First, high-fidelity, executable training environments are scarce: environments synthesized from real-world repositories are not diverse and scalable, while trajectories synthesized by LLMs suffer from hallucinations. Second, standard instruction tuning uses expert trajectories that rarely exhibit simple mistakes common to smaller models. This creates a distributional mismatch, leaving student models ill-equipped to recover from their own runtime failures. To bridge these gaps, we introduce TermiGen, an end-to-end pipeline for synthesizing verifiable environments and resilient expert trajectories. Termi-Gen first generates functionally valid tasks and Docker containers via an iterative multi-agent refinement loop. Subsequently, we employ a Generator-Critic protocol that actively injects errors during trajectory collection, synthesizing data rich in error-correction cycles. Fine-tuned on this TermiGen-generated dataset, our TermiGen-Qwen2.5-Coder-32B achieves a 31.3% pass rate on TerminalBench. This establishes a new open-weights state-of-the-art, outperforming existing baselines and notably surpassing capable proprietary models such as o4-mini. Dataset is avaiable at https://github.com/ucsb-mlsec/terminal-bench-env.", "AI": {"tldr": "TermiGen\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7ba1\u9053\uff0c\u901a\u8fc7\u5408\u6210\u53ef\u9a8c\u8bc1\u73af\u5883\u548c\u5f39\u6027\u4e13\u5bb6\u8f68\u8ff9\u6765\u89e3\u51b3LLM\u6267\u884c\u590d\u6742\u7ec8\u7aef\u4efb\u52a1\u7684\u6311\u6218\uff0c\u5176\u5fae\u8c03\u7684\u6a21\u578b\u5728TerminalBench\u4e0a\u8fbe\u523031.3%\u901a\u8fc7\u7387\uff0c\u521b\u4e0b\u5f00\u6e90\u6a21\u578b\u65b0\u7eaa\u5f55\u3002", "motivation": "\u89e3\u51b3\u5f00\u653e\u6743\u91cdLLM\u6267\u884c\u590d\u6742\u7ec8\u7aef\u4efb\u52a1\u7684\u4e24\u4e2a\u6839\u672c\u9650\u5236\uff1a1) \u9ad8\u4fdd\u771f\u53ef\u6267\u884c\u8bad\u7ec3\u73af\u5883\u7a00\u7f3a\uff0c\u771f\u5b9e\u73af\u5883\u7f3a\u4e4f\u591a\u6837\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0cLLM\u5408\u6210\u7684\u8f68\u8ff9\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\uff1b2) \u6807\u51c6\u6307\u4ee4\u8c03\u4f18\u4f7f\u7528\u4e13\u5bb6\u8f68\u8ff9\uff0c\u5f88\u5c11\u5305\u542b\u8f83\u5c0f\u6a21\u578b\u5e38\u89c1\u7684\u7b80\u5355\u9519\u8bef\uff0c\u5bfc\u81f4\u5b66\u751f\u6a21\u578b\u65e0\u6cd5\u6709\u6548\u4ece\u81ea\u8eab\u8fd0\u884c\u65f6\u9519\u8bef\u4e2d\u6062\u590d\u3002", "method": "TermiGen\u91c7\u7528\u7aef\u5230\u7aef\u7ba1\u9053\uff1a\u9996\u5148\u901a\u8fc7\u8fed\u4ee3\u591a\u667a\u80fd\u4f53\u7cbe\u70bc\u5faa\u73af\u751f\u6210\u529f\u80fd\u6709\u6548\u7684\u4efb\u52a1\u548cDocker\u5bb9\u5668\uff1b\u968f\u540e\u91c7\u7528\u751f\u6210\u5668-\u6279\u8bc4\u5668\u534f\u8bae\uff0c\u5728\u8f68\u8ff9\u6536\u96c6\u8fc7\u7a0b\u4e2d\u4e3b\u52a8\u6ce8\u5165\u9519\u8bef\uff0c\u5408\u6210\u5bcc\u542b\u9519\u8bef\u7ea0\u6b63\u5faa\u73af\u7684\u6570\u636e\u3002", "result": "\u5728TermiGen\u751f\u6210\u7684\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u7684TermiGen-Qwen2.5-Coder-32B\u6a21\u578b\u5728TerminalBench\u4e0a\u8fbe\u523031.3%\u7684\u901a\u8fc7\u7387\uff0c\u521b\u4e0b\u5f00\u653e\u6743\u91cd\u6a21\u578b\u7684\u65b0\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\uff0c\u751a\u81f3\u8d85\u8fc7\u4e86o4-mini\u7b49\u4e13\u6709\u6a21\u578b\u3002", "conclusion": "TermiGen\u901a\u8fc7\u5408\u6210\u53ef\u9a8c\u8bc1\u73af\u5883\u548c\u5305\u542b\u9519\u8bef\u7ea0\u6b63\u7684\u5f39\u6027\u8f68\u8ff9\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u6267\u884c\u7ec8\u7aef\u4efb\u52a1\u7684\u8bad\u7ec3\u6570\u636e\u74f6\u9888\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u5b9e\u9645\u7ec8\u7aef\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4e3a\u5f00\u653e\u6743\u91cd\u6a21\u578b\u5728\u8be5\u9886\u57df\u8bbe\u7acb\u4e86\u65b0\u7684\u6807\u6746\u3002"}}
{"id": "2602.07572", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.07572", "abs": "https://arxiv.org/abs/2602.07572", "authors": ["Yanna Jiang", "Haiyu Deng", "Qin Wang", "Guangsheng Yu", "Xu Wang", "Yilin Sai", "Shiping Chen", "Wei Ni", "Ren Ping Liu"], "title": "SoK: Credential-Based Trust Management in Decentralized Ledger Systems", "comment": "Appear at Trustcom'25 (DOI: 10.1109/Trustcom66490.2025.00197)", "summary": "Trust management systems (TMS) are crucial for managing trust in distributed environments. The rise of decentralized systems and blockchain has sparked interest in credential-based decentralized trust management systems (DTMS). This paper bridges the gap between theory and practice through a systematic review of credential-based DTMS. We analyze existing DTMS solutions through multiple dimensions, including their architectural designs, credential mechanisms, and trust evaluation models. Our survey provides a detailed taxonomy of credential-based DTMS approaches and establishes comprehensive evaluation criteria for assessing DTMS implementations. Through extensive analysis of current systems and implementations, we identify critical challenges and promising research directions in the field. Our examination offers valuable insights for researchers and practitioners working on DTMS, particularly in areas such as access control, reputation systems, and blockchain-based trust frameworks.", "AI": {"tldr": "\u672c\u6587\u5bf9\u57fa\u4e8e\u51ed\u8bc1\u7684\u5206\u5e03\u5f0f\u4fe1\u4efb\u7ba1\u7406\u7cfb\u7edf\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u5206\u6790\u4e86\u67b6\u6784\u8bbe\u8ba1\u3001\u51ed\u8bc1\u673a\u5236\u548c\u4fe1\u4efb\u8bc4\u4f30\u6a21\u578b\uff0c\u5efa\u7acb\u4e86\u5206\u7c7b\u4f53\u7cfb\u548c\u8bc4\u4f30\u6807\u51c6\uff0c\u8bc6\u522b\u4e86\u5173\u952e\u6311\u6218\u548c\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u53bb\u4e2d\u5fc3\u5316\u7cfb\u7edf\u548c\u533a\u5757\u94fe\u6280\u672f\u7684\u53d1\u5c55\uff0c\u57fa\u4e8e\u51ed\u8bc1\u7684\u5206\u5e03\u5f0f\u4fe1\u4efb\u7ba1\u7406\u7cfb\u7edf\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002\u672c\u6587\u65e8\u5728\u5f25\u5408\u7406\u8bba\u4e0e\u5b9e\u8df5\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u7cfb\u7edf\u6027\u7684\u7efc\u8ff0\u548c\u5206\u6790\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u4ece\u591a\u4e2a\u7ef4\u5ea6\u5206\u6790\u73b0\u6709DTMS\u89e3\u51b3\u65b9\u6848\uff0c\u5305\u62ec\u67b6\u6784\u8bbe\u8ba1\u3001\u51ed\u8bc1\u673a\u5236\u548c\u4fe1\u4efb\u8bc4\u4f30\u6a21\u578b\uff0c\u5efa\u7acb\u8be6\u7ec6\u7684\u5206\u7c7b\u4f53\u7cfb\u548c\u7efc\u5408\u8bc4\u4f30\u6807\u51c6\u3002", "result": "\u5efa\u7acb\u4e86\u57fa\u4e8e\u51ed\u8bc1\u7684DTMS\u65b9\u6cd5\u7684\u8be6\u7ec6\u5206\u7c7b\u4f53\u7cfb\uff0c\u5236\u5b9a\u4e86\u5168\u9762\u7684\u8bc4\u4f30\u6807\u51c6\uff0c\u8bc6\u522b\u4e86\u5f53\u524d\u7cfb\u7edf\u4e2d\u7684\u5173\u952e\u6311\u6218\u548c\u672a\u6765\u6709\u524d\u666f\u7684\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u672c\u6587\u4e3aDTMS\u9886\u57df\u7684\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\uff0c\u7279\u522b\u662f\u5728\u8bbf\u95ee\u63a7\u5236\u3001\u58f0\u8a89\u7cfb\u7edf\u548c\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u4fe1\u4efb\u6846\u67b6\u7b49\u9886\u57df\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u8be5\u9886\u57df\u7684\u7406\u8bba\u548c\u5b9e\u8df5\u53d1\u5c55\u3002"}}
{"id": "2602.07589", "categories": ["cs.SE", "cs.CY", "cs.ET", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.07589", "abs": "https://arxiv.org/abs/2602.07589", "authors": ["Andriy Miranskyy"], "title": "A Course on the Introduction to Quantum Software Engineering: Experience Report", "comment": null, "summary": "Quantum computing is increasingly practiced through programming, yet most educational offerings emphasize algorithmic or framework-level use rather than software engineering concerns such as testing, abstraction, tooling, and lifecycle management.\n  This paper reports on the design and first offering of a cross-listed undergraduate--graduate course that frames quantum computing through a software engineering lens, focusing on early-stage competence relevant to software engineering practice. The course integrates foundational quantum concepts with software engineering perspectives, emphasizing executable artifacts, empirical reasoning, and trade-offs arising from probabilistic behaviour, noise, and evolving toolchains. Evidence is drawn from instructor observations, student feedback, surveys, and analysis of student work.\n  Despite minimal prior exposure to quantum computing, students were able to engage productively with quantum software engineering topics once a foundational understanding of quantum information and quantum algorithms, expressed through executable artifacts, was established. This experience report contributes a modular course design, a scalable assessment model for mixed academic levels, and transferable lessons for software engineering educators developing quantum computing curricula.", "AI": {"tldr": "\u8be5\u8bba\u6587\u62a5\u544a\u4e86\u4e00\u95e8\u5c06\u91cf\u5b50\u8ba1\u7b97\u4e0e\u8f6f\u4ef6\u5de5\u7a0b\u7ed3\u5408\u7684\u4ea4\u53c9\u8bfe\u7a0b\u8bbe\u8ba1\uff0c\u5f3a\u8c03\u901a\u8fc7\u8f6f\u4ef6\u5de5\u7a0b\u89c6\u89d2\u6559\u6388\u91cf\u5b50\u8ba1\u7b97\uff0c\u5173\u6ce8\u6d4b\u8bd5\u3001\u62bd\u8c61\u3001\u5de5\u5177\u548c\u751f\u547d\u5468\u671f\u7ba1\u7406\u7b49\u5b9e\u8df5\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u91cf\u5b50\u8ba1\u7b97\u6559\u80b2\u4e3b\u8981\u5173\u6ce8\u7b97\u6cd5\u548c\u6846\u67b6\u5c42\u9762\uff0c\u7f3a\u4e4f\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\u65b9\u9762\u7684\u57f9\u517b\uff0c\u5982\u6d4b\u8bd5\u3001\u62bd\u8c61\u3001\u5de5\u5177\u548c\u751f\u547d\u5468\u671f\u7ba1\u7406\u3002\u9700\u8981\u5f00\u53d1\u4e00\u95e8\u8bfe\u7a0b\u5c06\u91cf\u5b50\u8ba1\u7b97\u4e0e\u8f6f\u4ef6\u5de5\u7a0b\u7ed3\u5408\uff0c\u57f9\u517b\u5b66\u751f\u5728\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u65b9\u9762\u7684\u65e9\u671f\u80fd\u529b\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u65bd\u4e86\u4e00\u95e8\u672c\u79d1-\u7814\u7a76\u751f\u4ea4\u53c9\u8bfe\u7a0b\uff0c\u901a\u8fc7\u8f6f\u4ef6\u5de5\u7a0b\u89c6\u89d2\u6559\u6388\u91cf\u5b50\u8ba1\u7b97\u3002\u8bfe\u7a0b\u6574\u5408\u4e86\u57fa\u7840\u91cf\u5b50\u6982\u5ff5\u4e0e\u8f6f\u4ef6\u5de5\u7a0b\u89c6\u89d2\uff0c\u5f3a\u8c03\u53ef\u6267\u884c\u5de5\u4ef6\u3001\u7ecf\u9a8c\u63a8\u7406\uff0c\u4ee5\u53ca\u5904\u7406\u6982\u7387\u884c\u4e3a\u3001\u566a\u58f0\u548c\u4e0d\u65ad\u53d1\u5c55\u7684\u5de5\u5177\u94fe\u5e26\u6765\u7684\u6743\u8861\u3002\u91c7\u7528\u6a21\u5757\u5316\u8bfe\u7a0b\u8bbe\u8ba1\uff0c\u53ef\u6269\u5c55\u7684\u6df7\u5408\u5b66\u672f\u6c34\u5e73\u8bc4\u4f30\u6a21\u578b\u3002", "result": "\u5c3d\u7ba1\u5b66\u751f\u4e4b\u524d\u5bf9\u91cf\u5b50\u8ba1\u7b97\u63a5\u89e6\u6709\u9650\uff0c\u4f46\u4e00\u65e6\u901a\u8fc7\u53ef\u6267\u884c\u5de5\u4ef6\u5efa\u7acb\u4e86\u5bf9\u91cf\u5b50\u4fe1\u606f\u548c\u91cf\u5b50\u7b97\u6cd5\u7684\u57fa\u7840\u7406\u89e3\uff0c\u4ed6\u4eec\u5c31\u80fd\u6709\u6548\u53c2\u4e0e\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u4e3b\u9898\u3002\u8bc1\u636e\u6765\u81ea\u6559\u5e08\u89c2\u5bdf\u3001\u5b66\u751f\u53cd\u9988\u3001\u8c03\u67e5\u548c\u5b66\u751f\u4f5c\u4e1a\u5206\u6790\u3002", "conclusion": "\u8be5\u7ecf\u9a8c\u62a5\u544a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u8bfe\u7a0b\u8bbe\u8ba1\u3001\u53ef\u6269\u5c55\u7684\u6df7\u5408\u5b66\u672f\u6c34\u5e73\u8bc4\u4f30\u6a21\u578b\uff0c\u4ee5\u53ca\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u5de5\u4f5c\u8005\u5f00\u53d1\u91cf\u5b50\u8ba1\u7b97\u8bfe\u7a0b\u7684\u53ef\u8f6c\u79fb\u7ecf\u9a8c\u3002\u8bc1\u660e\u4e86\u901a\u8fc7\u8f6f\u4ef6\u5de5\u7a0b\u89c6\u89d2\u6559\u6388\u91cf\u5b50\u8ba1\u7b97\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2602.07276", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07276", "abs": "https://arxiv.org/abs/2602.07276", "authors": ["Pengrui Han", "Xueqiang Xu", "Keyang Xuan", "Peiyang Song", "Siru Ouyang", "Runchu Tian", "Yuqing Jiang", "Cheng Qian", "Pengcheng Jiang", "Jiashuo Sun", "Junxia Cui", "Ming Zhong", "Ge Liu", "Jiawei Han", "Jiaxuan You"], "title": "Steer2Adapt: Dynamically Composing Steering Vectors Elicits Efficient Adaptation of LLMs", "comment": null, "summary": "Activation steering has emerged as a promising approach for efficiently adapting large language models (LLMs) to downstream behaviors. However, most existing steering methods rely on a single static direction per task or concept, making them inflexible under task variation and inadequate for complex tasks that require multiple coordinated capabilities. To address this limitation, we propose STEER2ADAPT, a lightweight framework that adapts LLMs by composing steering vectors rather than learning new ones from scratch. In many domains (e.g., reasoning or safety), tasks share a small set of underlying concept dimensions. STEER2ADAPT captures these dimensions as a reusable, low-dimensional semantic prior subspace, and adapts to new tasks by dynamically discovering a linear combination of basis vectors from only a handful of examples. Experiments across 9 tasks and 3 models in both reasoning and safety domains demonstrate the effectiveness of STEER2ADAPT, achieving an average improvement of 8.2%. Extensive analyses further show that STEER2ADAPT is a data-efficient, stable, and transparent inference-time adaptation method for LLMs.", "AI": {"tldr": "STEER2ADAPT\uff1a\u4e00\u79cd\u8f7b\u91cf\u7ea7\u6846\u67b6\uff0c\u901a\u8fc7\u7ec4\u5408\u800c\u975e\u91cd\u65b0\u5b66\u4e60\u6765\u52a8\u6001\u8c03\u6574LLM\u7684\u6fc0\u6d3b\u5411\u91cf\uff0c\u63d0\u9ad8\u4efb\u52a1\u9002\u5e94\u6027\u548c\u6548\u7387", "motivation": "\u73b0\u6709\u6fc0\u6d3b\u5f15\u5bfc\u65b9\u6cd5\u901a\u5e38\u4e3a\u6bcf\u4e2a\u4efb\u52a1\u6216\u6982\u5ff5\u4f7f\u7528\u5355\u4e00\u7684\u9759\u6001\u65b9\u5411\uff0c\u8fd9\u5bfc\u81f4\u5728\u4efb\u52a1\u53d8\u5316\u65f6\u7f3a\u4e4f\u7075\u6d3b\u6027\uff0c\u4e14\u65e0\u6cd5\u5904\u7406\u9700\u8981\u591a\u79cd\u534f\u8c03\u80fd\u529b\u7684\u590d\u6742\u4efb\u52a1", "method": "\u63d0\u51faSTEER2ADAPT\u6846\u67b6\uff0c\u5c06\u4efb\u52a1\u5171\u4eab\u7684\u5e95\u5c42\u6982\u5ff5\u7ef4\u5ea6\u6355\u83b7\u4e3a\u53ef\u91cd\u7528\u7684\u4f4e\u7ef4\u8bed\u4e49\u5148\u9a8c\u5b50\u7a7a\u95f4\uff0c\u901a\u8fc7\u5c11\u91cf\u793a\u4f8b\u52a8\u6001\u53d1\u73b0\u57fa\u5411\u91cf\u7684\u7ebf\u6027\u7ec4\u5408\u6765\u9002\u5e94\u65b0\u4efb\u52a1", "result": "\u57289\u4e2a\u4efb\u52a1\u548c3\u4e2a\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u63a8\u7406\u548c\u5b89\u5168\u9886\u57df\u5e73\u5747\u63d0\u53478.2%\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5177\u6709\u6570\u636e\u6548\u7387\u9ad8\u3001\u7a33\u5b9a\u6027\u597d\u548c\u900f\u660e\u5ea6\u9ad8\u7684\u7279\u70b9", "conclusion": "STEER2ADAPT\u662f\u4e00\u79cd\u6709\u6548\u7684\u63a8\u7406\u65f6\u9002\u5e94\u65b9\u6cd5\uff0c\u80fd\u591f\u901a\u8fc7\u7ec4\u5408\u73b0\u6709\u5f15\u5bfc\u5411\u91cf\u800c\u975e\u4ece\u5934\u5b66\u4e60\u65b0\u5411\u91cf\uff0c\u7075\u6d3b\u9002\u5e94\u590d\u6742\u4efb\u52a1\u53d8\u5316"}}
{"id": "2602.07609", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07609", "abs": "https://arxiv.org/abs/2602.07609", "authors": ["Ruoyu Su", "Alexander Bakhtin", "Noman Ahmad", "Matteo Esposito", "Valentina Lenarduzzi", "Davide Taibi"], "title": "Evaluating Large Language Models for Detecting Architectural Decision Violations", "comment": null, "summary": "Architectural Decision Records (ADRs) play a central role in maintaining software architecture quality, yet many decision violations go unnoticed because projects lack both systematic documentation and automated detection mechanisms. Recent advances in Large Language Models (LLMs) open up new possibilities for automating architectural reasoning at scale. We investigated how effectively LLMs can identify decision violations in open-source systems by examining their agreement, accuracy, and inherent limitations. Our study analyzed 980 ADRs across 109 GitHub repositories using a multi-model pipeline in which one LLM primary screens potential decision violations, and three additional LLMs independently validate the reasoning. We assessed agreement, accuracy, precision, and recall, and complemented the quantitative findings with expert evaluation. The models achieved substantial agreement and strong accuracy for explicit, code-inferable decisions. Accuracy falls short for implicit or deployment-oriented decisions that depend on deployment configuration or organizational knowledge. Therefore, LLMs can meaningfully support validation of architectural decision compliance; however, they are not yet replacing human expertise for decisions not focused on code.", "AI": {"tldr": "LLMs\u53ef\u4ee5\u6709\u6548\u5730\u8bc6\u522b\u5f00\u6e90\u7cfb\u7edf\u4e2d\u7684\u67b6\u6784\u51b3\u7b56\u8fdd\u89c4\uff0c\u5bf9\u4e8e\u660e\u786e\u3001\u53ef\u4ee3\u7801\u63a8\u65ad\u7684\u51b3\u7b56\u8868\u73b0\u51fa\u9ad8\u51c6\u786e\u7387\uff0c\u4f46\u5bf9\u4e8e\u4f9d\u8d56\u90e8\u7f72\u914d\u7f6e\u6216\u7ec4\u7ec7\u77e5\u8bc6\u7684\u9690\u5f0f\u51b3\u7b56\u6548\u679c\u6709\u9650\u3002", "motivation": "\u8f6f\u4ef6\u67b6\u6784\u51b3\u7b56\u8bb0\u5f55\uff08ADRs\uff09\u5bf9\u7ef4\u62a4\u67b6\u6784\u8d28\u91cf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u8bb8\u591a\u51b3\u7b56\u8fdd\u89c4\u672a\u88ab\u53d1\u73b0\uff0c\u56e0\u4e3a\u9879\u76ee\u7f3a\u4e4f\u7cfb\u7edf\u5316\u6587\u6863\u548c\u81ea\u52a8\u5316\u68c0\u6d4b\u673a\u5236\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u53d1\u5c55\u4e3a\u89c4\u6a21\u5316\u81ea\u52a8\u5316\u67b6\u6784\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u53ef\u80fd\u6027\u3002", "method": "\u7814\u7a76\u5206\u6790\u4e86109\u4e2aGitHub\u4ed3\u5e93\u4e2d\u7684980\u4e2aADRs\uff0c\u91c7\u7528\u591a\u6a21\u578b\u6d41\u6c34\u7ebf\uff1a\u4e00\u4e2aLLM\u4e3b\u6a21\u578b\u7b5b\u9009\u6f5c\u5728\u51b3\u7b56\u8fdd\u89c4\uff0c\u53e6\u5916\u4e09\u4e2aLLM\u72ec\u7acb\u9a8c\u8bc1\u63a8\u7406\u8fc7\u7a0b\u3002\u8bc4\u4f30\u4e86\u6a21\u578b\u95f4\u4e00\u81f4\u6027\u3001\u51c6\u786e\u7387\u3001\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387\uff0c\u5e76\u8f85\u4ee5\u4e13\u5bb6\u8bc4\u4f30\u3002", "result": "\u6a21\u578b\u5bf9\u4e8e\u660e\u786e\u3001\u53ef\u4ee3\u7801\u63a8\u65ad\u7684\u51b3\u7b56\u8868\u73b0\u51fa\u663e\u8457\u4e00\u81f4\u6027\u548c\u5f3a\u51c6\u786e\u7387\u3002\u4f46\u5bf9\u4e8e\u9690\u5f0f\u6216\u90e8\u7f72\u5bfc\u5411\u7684\u51b3\u7b56\uff08\u4f9d\u8d56\u90e8\u7f72\u914d\u7f6e\u6216\u7ec4\u7ec7\u77e5\u8bc6\uff09\uff0c\u51c6\u786e\u7387\u4e0d\u8db3\u3002LLMs\u5728\u9a8c\u8bc1\u67b6\u6784\u51b3\u7b56\u5408\u89c4\u6027\u65b9\u9762\u80fd\u63d0\u4f9b\u6709\u610f\u4e49\u7684\u652f\u6301\u3002", "conclusion": "LLMs\u80fd\u591f\u6709\u610f\u4e49\u5730\u652f\u6301\u67b6\u6784\u51b3\u7b56\u5408\u89c4\u6027\u9a8c\u8bc1\uff0c\u4f46\u5bf9\u4e8e\u975e\u4ee3\u7801\u76f8\u5173\u7684\u51b3\u7b56\uff0c\u5c1a\u4e0d\u80fd\u5b8c\u5168\u66ff\u4ee3\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u3002\u9700\u8981\u7ed3\u5408\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u6765\u5904\u7406\u4f9d\u8d56\u90e8\u7f72\u914d\u7f6e\u548c\u7ec4\u7ec7\u77e5\u8bc6\u7684\u51b3\u7b56\u3002"}}
{"id": "2602.07308", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07308", "abs": "https://arxiv.org/abs/2602.07308", "authors": ["Sutapa Dey Tithi", "Nazia Alam", "Tahreem Yasir", "Yang Shi", "Xiaoyi Tian", "Min Chi", "Tiffany Barnes"], "title": "Adaptive Scaffolding for Cognitive Engagement in an Intelligent Tutoring System", "comment": null, "summary": "The ICAP framework defines four cognitive engagement levels: Passive, Active, Constructive, and Interactive, where increased cognitive engagement can yield improved learning. However, personalizing learning activities that elicit the optimal level of cognitive engagement remains a key challenge in intelligent tutoring systems (ITS). In this work, we develop and evaluate a system that adaptively scaffolds cognitive engagement by dynamically selecting worked examples in two different ICAP modes: (active) Guided examples and (constructive) Buggy examples. We compare Bayesian Knowledge Tracing (BKT) and Deep Reinforcement Learning (DRL) as adaptive methods against a non-adaptive baseline method for selecting example type in a logic ITS. Our experiment with 113 students demonstrates that both adaptive policies significantly improved student performance on test problems. BKT yielded the largest improvement in posttest scores for low prior knowledge students, helping them catch up with their high prior knowledge peers, whereas DRL yielded significantly higher posttest scores among high prior knowledge students. This paper contributes new insights into the complex interactions of cognitive engagement and adaptivity and their results on learning outcomes.", "AI": {"tldr": "\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u81ea\u9002\u5e94\u7cfb\u7edf\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u4e24\u79cdICAP\u6a21\u5f0f\u7684\u4f8b\u9898\uff08\u5f15\u5bfc\u5f0f\u4f8b\u9898\u548c\u9519\u8bef\u5f0f\u4f8b\u9898\uff09\u6765\u8c03\u6574\u8ba4\u77e5\u53c2\u4e0e\u5ea6\uff0c\u6bd4\u8f83\u4e86BKT\u548cDRL\u4e24\u79cd\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u53d1\u73b0\u5b83\u4eec\u90fd\u80fd\u663e\u8457\u63d0\u9ad8\u5b66\u751f\u6d4b\u8bd5\u6210\u7ee9\uff0c\u4f46\u5bf9\u4e0d\u540c\u5148\u9a8c\u77e5\u8bc6\u6c34\u5e73\u7684\u5b66\u751f\u6548\u679c\u4e0d\u540c\u3002", "motivation": "ICAP\u6846\u67b6\u5b9a\u4e49\u4e86\u56db\u79cd\u8ba4\u77e5\u53c2\u4e0e\u6c34\u5e73\uff0c\u66f4\u9ad8\u7684\u8ba4\u77e5\u53c2\u4e0e\u80fd\u5e26\u6765\u66f4\u597d\u7684\u5b66\u4e60\u6548\u679c\uff0c\u4f46\u5728\u667a\u80fd\u5bfc\u5b66\u7cfb\u7edf\u4e2d\u4e2a\u6027\u5316\u5730\u9009\u62e9\u80fd\u5f15\u53d1\u6700\u4f73\u8ba4\u77e5\u53c2\u4e0e\u6c34\u5e73\u7684\u5b66\u4e60\u6d3b\u52a8\u4ecd\u7136\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u81ea\u9002\u5e94\u7cfb\u7edf\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u4e24\u79cdICAP\u6a21\u5f0f\u7684\u4f8b\u9898\u6765\u8c03\u6574\u8ba4\u77e5\u53c2\u4e0e\u5ea6\uff1a\u4e3b\u52a8\u6a21\u5f0f\u7684\u5f15\u5bfc\u5f0f\u4f8b\u9898\u548c\u5efa\u6784\u6a21\u5f0f\u7684\u9519\u8bef\u5f0f\u4f8b\u9898\u3002\u6bd4\u8f83\u4e86\u8d1d\u53f6\u65af\u77e5\u8bc6\u8ffd\u8e2a\uff08BKT\uff09\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u4e24\u79cd\u81ea\u9002\u5e94\u65b9\u6cd5\u4e0e\u4e00\u4e2a\u975e\u81ea\u9002\u5e94\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u4e00\u4e2a\u903b\u8f91\u667a\u80fd\u5bfc\u5b66\u7cfb\u7edf\u4e2d\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5728113\u540d\u5b66\u751f\u7684\u5b9e\u9a8c\u4e2d\uff0c\u4e24\u79cd\u81ea\u9002\u5e94\u7b56\u7565\u90fd\u663e\u8457\u63d0\u9ad8\u4e86\u5b66\u751f\u5728\u6d4b\u8bd5\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u3002BKT\u5bf9\u4f4e\u5148\u9a8c\u77e5\u8bc6\u5b66\u751f\u7684\u540e\u6d4b\u6210\u7ee9\u63d0\u5347\u6700\u5927\uff0c\u5e2e\u52a9\u4ed6\u4eec\u8d76\u4e0a\u9ad8\u5148\u9a8c\u77e5\u8bc6\u540c\u4f34\uff1b\u800cDRL\u5728\u9ad8\u5148\u9a8c\u77e5\u8bc6\u5b66\u751f\u4e2d\u4ea7\u751f\u4e86\u663e\u8457\u66f4\u9ad8\u7684\u540e\u6d4b\u6210\u7ee9\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u8ba4\u77e5\u53c2\u4e0e\u5ea6\u548c\u81ea\u9002\u5e94\u6027\u7684\u590d\u6742\u4ea4\u4e92\u53ca\u5176\u5bf9\u5b66\u4e60\u6210\u679c\u7684\u5f71\u54cd\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\uff0c\u8868\u660e\u4e0d\u540c\u7684\u81ea\u9002\u5e94\u65b9\u6cd5\u9002\u5408\u4e0d\u540c\u5148\u9a8c\u77e5\u8bc6\u6c34\u5e73\u7684\u5b66\u751f\uff0c\u4e2a\u6027\u5316\u8ba4\u77e5\u53c2\u4e0e\u5ea6\u8c03\u6574\u80fd\u6709\u6548\u63d0\u5347\u5b66\u4e60\u6548\u679c\u3002"}}
{"id": "2602.07656", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.07656", "abs": "https://arxiv.org/abs/2602.07656", "authors": ["Abhishek Kumar Mishra", "Swadeep", "Guevara Noubir", "Mathieu Cunche"], "title": "AirCatch: Effectively tracing advanced tag-based trackers", "comment": null, "summary": "Tag-based tracking ecosystems help users locate lost items, but can be leveraged for unwanted tracking and stalking. Existing protocol-driven defenses and prior academic solutions largely assume stable identifiers or predictable beaconing. However, identifier-based defenses fundamentally break down against advanced rogue trackers that aggressively rotate identifiers. We present AirCatch, a passive detection system that exploits a physical-layer constraint: while logical identifiers can change arbitrarily fast, the transmitter's analog imprint remains stable and reappears as a compact and persistently occupied region in Carrier Frequency Offset (CFO) feature space. AirCatch advances the state of the art along three axes: (i) a novel, modulation-aware CFO fingerprint that augments packet-level CFO with content-independent CFO components that amplify device distinctiveness; (ii) a new tracking detection algorithm based on high core density and persistence that is robust to contamination and evasion through per-identifier segmentation; and (iii) an ultra-low-cost receiver, an approximately 10 dollar BLE SDR named BlePhasyr, built from commodity components, that makes RF fingerprinting based detection practical in resource-constrained deployments. We evaluate AirCatch across Apple, Google, Tile, and Samsung tag families in multi-hour captures, systematically stress-test evasion using a scenario generator over a grid of transmission and rotation periods, and validate in diverse real-world mobility traces including home and office commutes, public transport, car travel, and airport journeys while sweeping background tag density. Across these stress tests, AirCatch achieves no false positives and early detection over a wide range of adversarial configurations and environments, degrading gracefully only in extreme low-rate regimes that also reduce attacker utility.", "AI": {"tldr": "AirCatch\u662f\u4e00\u4e2a\u88ab\u52a8\u68c0\u6d4b\u7cfb\u7edf\uff0c\u5229\u7528\u7269\u7406\u5c42\u7ea6\u675f\u68c0\u6d4b\u6076\u610f\u84dd\u7259\u8ddf\u8e2a\u5668\uff0c\u5373\u4f7f\u5b83\u4eec\u5feb\u901f\u8f6e\u6362\u6807\u8bc6\u7b26\u4e5f\u80fd\u6709\u6548\u8bc6\u522b\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u534f\u8bae\u7684\u9632\u5fa1\u548c\u5b66\u672f\u89e3\u51b3\u65b9\u6848\u4e3b\u8981\u5047\u8bbe\u7a33\u5b9a\u7684\u6807\u8bc6\u7b26\u6216\u53ef\u9884\u6d4b\u7684\u4fe1\u6807\uff0c\u4f46\u9762\u5bf9\u79ef\u6781\u8f6e\u6362\u6807\u8bc6\u7b26\u7684\u9ad8\u7ea7\u6076\u610f\u8ddf\u8e2a\u5668\u65f6\uff0c\u8fd9\u4e9b\u57fa\u4e8e\u6807\u8bc6\u7b26\u7684\u9632\u5fa1\u4f1a\u5931\u6548\u3002", "method": "AirCatch\u91c7\u7528\u4e09\u4e2a\u5173\u952e\u6280\u672f\uff1a1)\u65b0\u9896\u7684\u8c03\u5236\u611f\u77e5CFO\u6307\u7eb9\uff0c\u589e\u5f3a\u8bbe\u5907\u72ec\u7279\u6027\uff1b2)\u57fa\u4e8e\u9ad8\u6838\u5fc3\u5bc6\u5ea6\u548c\u6301\u4e45\u6027\u7684\u8ddf\u8e2a\u68c0\u6d4b\u7b97\u6cd5\uff1b3)\u8d85\u4f4e\u6210\u672c\u63a5\u6536\u5668BlePhasyr\uff0c\u4f7f\u7528\u7ea610\u7f8e\u5143\u7684BLE SDR\u3002", "result": "\u5728Apple\u3001Google\u3001Tile\u548c\u4e09\u661f\u6807\u7b7e\u5bb6\u65cf\u7684\u591a\u5c0f\u65f6\u6355\u83b7\u4e2d\u8bc4\u4f30\uff0cAirCatch\u5728\u5404\u79cd\u5bf9\u6297\u914d\u7f6e\u548c\u73af\u5883\u4e0b\u5b9e\u73b0\u96f6\u8bef\u62a5\u548c\u65e9\u671f\u68c0\u6d4b\uff0c\u4ec5\u5728\u6781\u7aef\u4f4e\u901f\u7387\u60c5\u51b5\u4e0b\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "AirCatch\u901a\u8fc7\u5229\u7528\u7269\u7406\u5c42\u7ea6\u675f\uff0c\u5373\u4f7f\u9762\u5bf9\u79ef\u6781\u8f6e\u6362\u6807\u8bc6\u7b26\u7684\u6076\u610f\u8ddf\u8e2a\u5668\u4e5f\u80fd\u6709\u6548\u68c0\u6d4b\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684RF\u6307\u7eb9\u68c0\u6d4b\u65b9\u6848\u3002"}}
{"id": "2602.07339", "categories": ["cs.AI", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07339", "abs": "https://arxiv.org/abs/2602.07339", "authors": ["Ruturaj Reddy", "Hrishav Bakul Barua", "Junn Yong Loo", "Thanh Thi Nguyen", "Ganesh Krishnasamy"], "title": "RAPiD: Real-time Deterministic Trajectory Planning via Diffusion Behavior Priors for Safe and Efficient Autonomous Driving", "comment": null, "summary": "Diffusion-based trajectory planners have demonstrated strong capability for modeling the multimodal nature of human driving behavior, but their reliance on iterative stochastic sampling poses critical challenges for real-time, safety-critical deployment. In this work, we present RAPiD, a deterministic policy extraction framework that distills a pretrained diffusion-based planner into an efficient policy while eliminating diffusion sampling. Using score-regularized policy optimization, we leverage the score function of a pre-trained diffusion planner as a behavior prior to regularize policy learning. To promote safety and passenger comfort, the policy is optimized using a critic trained to imitate a predictive driver controller, providing dense, safety-focused supervision beyond conventional imitation learning. Evaluations demonstrate that RAPiD achieves competitive performance on closed-loop nuPlan scenarios with an 8x speedup over diffusion baselines, while achieving state-of-the-art generalization among learning-based planners on the interPlan benchmark. The official website of this work is: https://github.com/ruturajreddy/RAPiD.", "AI": {"tldr": "RAPiD\u662f\u4e00\u4e2a\u786e\u5b9a\u6027\u7b56\u7565\u63d0\u53d6\u6846\u67b6\uff0c\u5c06\u9884\u8bad\u7ec3\u7684\u6269\u6563\u8f68\u8ff9\u89c4\u5212\u5668\u84b8\u998f\u4e3a\u9ad8\u6548\u7b56\u7565\uff0c\u6d88\u9664\u6269\u6563\u91c7\u6837\uff0c\u5b9e\u73b08\u500d\u52a0\u901f\u5e76\u4fdd\u6301\u7ade\u4e89\u6027\u80fd", "motivation": "\u6269\u6563\u8f68\u8ff9\u89c4\u5212\u5668\u80fd\u5f88\u597d\u5efa\u6a21\u4eba\u7c7b\u9a7e\u9a76\u7684\u591a\u6a21\u6001\u884c\u4e3a\uff0c\u4f46\u4f9d\u8d56\u8fed\u4ee3\u968f\u673a\u91c7\u6837\uff0c\u96be\u4ee5\u6ee1\u8db3\u5b9e\u65f6\u5b89\u5168\u5173\u952e\u90e8\u7f72\u9700\u6c42", "method": "\u4f7f\u7528\u5206\u6570\u6b63\u5219\u5316\u7b56\u7565\u4f18\u5316\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u6269\u6563\u89c4\u5212\u5668\u7684\u8bc4\u5206\u51fd\u6570\u4f5c\u4e3a\u884c\u4e3a\u5148\u9a8c\u6765\u6b63\u5219\u5316\u7b56\u7565\u5b66\u4e60\uff1b\u901a\u8fc7\u6a21\u4eff\u9884\u6d4b\u9a7e\u9a76\u5458\u63a7\u5236\u5668\u7684\u8bc4\u8bba\u5bb6\u63d0\u4f9b\u5bc6\u96c6\u5b89\u5168\u76d1\u7763", "result": "\u5728nuPlan\u573a\u666f\u4e2d\u5b9e\u73b0\u7ade\u4e89\u6027\u80fd\uff0c\u6bd4\u6269\u6563\u57fa\u7ebf\u5feb8\u500d\uff1b\u5728interPlan\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u57fa\u4e8e\u5b66\u4e60\u7684\u89c4\u5212\u5668\u7684\u6700\u5148\u8fdb\u6cdb\u5316\u80fd\u529b", "conclusion": "RAPiD\u6210\u529f\u5c06\u6269\u6563\u89c4\u5212\u5668\u84b8\u998f\u4e3a\u9ad8\u6548\u786e\u5b9a\u6027\u7b56\u7565\uff0c\u89e3\u51b3\u4e86\u6269\u6563\u65b9\u6cd5\u5b9e\u65f6\u90e8\u7f72\u7684\u6311\u6218\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u4f18\u52bf"}}
{"id": "2602.07672", "categories": ["cs.SE", "cs.AI", "cs.LG", "cs.PL", "cs.SC"], "pdf": "https://arxiv.org/pdf/2602.07672", "abs": "https://arxiv.org/abs/2602.07672", "authors": ["Babak Rahmani"], "title": "Debugging code world models", "comment": "8 pages, 4 figures, under review in conference", "summary": "Code World Models (CWMs) are language models trained to simulate program execution by predicting explicit runtime state after every executed command. This execution-based world modeling enables internal verification within the model, offering an alternative to natural language chain-of-thought reasoning. However, the sources of errors and the nature of CWMs' limitations remain poorly understood. We study CWMs from two complementary perspectives: local semantic execution and long-horizon state tracking. On real-code benchmarks, we identify two dominant failure regimes. First, dense runtime state reveals produce token-intensive execution traces, leading to token-budget exhaustion on programs with long execution histories. Second, failures disproportionately concentrate in string-valued state, which we attribute to limitations of subword tokenization rather than program structure. To study long-horizon behavior, we use a controlled permutation-tracking benchmark that isolates state propagation under action execution. We show that long-horizon degradation is driven primarily by incorrect action generation: when actions are replaced with ground-truth commands, a Transformer-based CWM propagates state accurately over long horizons, despite known limitations of Transformers in long-horizon state tracking. These findings suggest directions for more efficient supervision and state representations in CWMs that are better aligned with program execution and data types.", "AI": {"tldr": "\u4ee3\u7801\u4e16\u754c\u6a21\u578b\uff08CWMs\uff09\u901a\u8fc7\u9884\u6d4b\u7a0b\u5e8f\u6267\u884c\u540e\u7684\u8fd0\u884c\u65f6\u72b6\u6001\u6765\u6a21\u62df\u7a0b\u5e8f\u6267\u884c\uff0c\u4f46\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u5931\u8d25\u6a21\u5f0f\uff1a\u957f\u6267\u884c\u5386\u53f2\u5bfc\u81f4\u7684\u4ee4\u724c\u9884\u7b97\u8017\u5c3d\u548c\u5b57\u7b26\u4e32\u503c\u72b6\u6001\u5904\u7406\u56f0\u96be\u3002", "motivation": "\u7814\u7a76\u4ee3\u7801\u4e16\u754c\u6a21\u578b\u7684\u9519\u8bef\u6765\u6e90\u548c\u5c40\u9650\u6027\uff0c\u7406\u89e3\u5176\u5728\u5c40\u90e8\u8bed\u4e49\u6267\u884c\u548c\u957f\u65f6\u7a0b\u72b6\u6001\u8ddf\u8e2a\u65b9\u9762\u7684\u8868\u73b0\uff0c\u4e3a\u6539\u8fdbCWMs\u63d0\u4f9b\u65b9\u5411\u3002", "method": "\u4ece\u4e24\u4e2a\u4e92\u8865\u89d2\u5ea6\u7814\u7a76CWMs\uff1a\u5c40\u90e8\u8bed\u4e49\u6267\u884c\u548c\u957f\u65f6\u7a0b\u72b6\u6001\u8ddf\u8e2a\u3002\u4f7f\u7528\u771f\u5b9e\u4ee3\u7801\u57fa\u51c6\u6d4b\u8bd5\u8bc6\u522b\u5931\u8d25\u6a21\u5f0f\uff0c\u5e76\u901a\u8fc7\u53d7\u63a7\u7684\u6392\u5217\u8ddf\u8e2a\u57fa\u51c6\u6d4b\u8bd5\u6765\u7814\u7a76\u957f\u65f6\u7a0b\u884c\u4e3a\u3002", "result": "\u53d1\u73b0\u4e24\u4e2a\u4e3b\u8981\u5931\u8d25\u6a21\u5f0f\uff1a1\uff09\u5bc6\u96c6\u8fd0\u884c\u65f6\u72b6\u6001\u4ea7\u751f\u5bfc\u81f4\u957f\u6267\u884c\u5386\u53f2\u7a0b\u5e8f\u4ee4\u724c\u9884\u7b97\u8017\u5c3d\uff1b2\uff09\u5b57\u7b26\u4e32\u503c\u72b6\u6001\u5904\u7406\u5931\u8d25\uff0c\u5f52\u56e0\u4e8e\u5b50\u8bcd\u6807\u8bb0\u5316\u7684\u9650\u5236\u800c\u975e\u7a0b\u5e8f\u7ed3\u6784\u3002\u957f\u65f6\u7a0b\u9000\u5316\u4e3b\u8981\u7531\u9519\u8bef\u52a8\u4f5c\u751f\u6210\u9a71\u52a8\uff0c\u5f53\u4f7f\u7528\u771f\u5b9e\u547d\u4ee4\u65f6\uff0cTransformer-based CWM\u80fd\u5728\u957f\u65f6\u7a0b\u4e2d\u51c6\u786e\u4f20\u64ad\u72b6\u6001\u3002", "conclusion": "CWMs\u7684\u5c40\u9650\u6027\u4e3b\u8981\u6765\u81ea\u4ee4\u724c\u9884\u7b97\u548c\u5b57\u7b26\u4e32\u5904\u7406\uff0c\u800c\u975e\u957f\u65f6\u7a0b\u72b6\u6001\u8ddf\u8e2a\u80fd\u529b\u3002\u8fd9\u4e3a\u8bbe\u8ba1\u66f4\u9ad8\u6548\u7684\u76d1\u7763\u548c\u72b6\u6001\u8868\u793a\u63d0\u4f9b\u4e86\u65b9\u5411\uff0c\u4f7f\u5176\u66f4\u597d\u5730\u4e0e\u7a0b\u5e8f\u6267\u884c\u548c\u6570\u636e\u7c7b\u578b\u5bf9\u9f50\u3002"}}
{"id": "2602.07722", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.07722", "abs": "https://arxiv.org/abs/2602.07722", "authors": ["Sharif Noor Zisad", "Ragib Hasan"], "title": "IPBAC: Interaction Provenance-Based Access Control for Secure and Privacy-Aware Systems", "comment": "This article is accepted and presented in IEEE Consumer Communications & Networking Conference (CCNC 2026) as a poster", "summary": "Traditional access control systems, including RBAC, face significant limitations such as inflexible role definitions, difficulty handling dynamic scenarios, and lack of detailed accountability and traceability. To this end, we introduce the Interaction Provenance-based Access Control (IPBAC) model. In this paper, we explore the integration of interaction provenance with access control to overcome these limitations. Interaction provenance refers to the detailed recording of actions and interactions within a system, capturing comprehensive metadata such as the identity of the actor, the time of an action, and the context. IPBAC ensures stronger protection against unauthorized access, enhances traceability for auditing and compliance, and supports adaptive security policies. This provenance-based access control not only strengthens security, but also provides a robust framework for auditing and compliance.", "AI": {"tldr": "IPBAC\u6a21\u578b\u901a\u8fc7\u6574\u5408\u4ea4\u4e92\u6eaf\u6e90\u4e0e\u8bbf\u95ee\u63a7\u5236\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u8bbf\u95ee\u63a7\u5236\u7cfb\u7edf\u5728\u89d2\u8272\u5b9a\u4e49\u3001\u52a8\u6001\u573a\u666f\u5904\u7406\u548c\u5ba1\u8ba1\u8ffd\u8e2a\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edf\u8bbf\u95ee\u63a7\u5236\u7cfb\u7edf\uff08\u5982RBAC\uff09\u5b58\u5728\u89d2\u8272\u5b9a\u4e49\u4e0d\u7075\u6d3b\u3001\u96be\u4ee5\u5904\u7406\u52a8\u6001\u573a\u666f\u3001\u7f3a\u4e4f\u8be6\u7ec6\u95ee\u8d23\u548c\u53ef\u8ffd\u6eaf\u6027\u7b49\u663e\u8457\u9650\u5236\uff0c\u9700\u8981\u66f4\u5f3a\u5927\u7684\u5b89\u5168\u4fdd\u62a4\u3001\u5ba1\u8ba1\u8ffd\u8e2a\u548c\u81ea\u9002\u5e94\u7b56\u7565\u652f\u6301\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u4ea4\u4e92\u6eaf\u6e90\u7684\u8bbf\u95ee\u63a7\u5236\uff08IPBAC\uff09\u6a21\u578b\uff0c\u901a\u8fc7\u8be6\u7ec6\u8bb0\u5f55\u7cfb\u7edf\u4e2d\u7684\u64cd\u4f5c\u548c\u4ea4\u4e92\uff0c\u6355\u83b7\u5305\u62ec\u6267\u884c\u8005\u8eab\u4efd\u3001\u64cd\u4f5c\u65f6\u95f4\u3001\u4e0a\u4e0b\u6587\u7b49\u5168\u9762\u5143\u6570\u636e\uff0c\u5c06\u4ea4\u4e92\u6eaf\u6e90\u4e0e\u8bbf\u95ee\u63a7\u5236\u673a\u5236\u6574\u5408\u3002", "result": "IPBAC\u80fd\u591f\u66f4\u6709\u6548\u5730\u9632\u6b62\u672a\u7ecf\u6388\u6743\u7684\u8bbf\u95ee\uff0c\u589e\u5f3a\u5ba1\u8ba1\u548c\u5408\u89c4\u7684\u53ef\u8ffd\u6eaf\u6027\uff0c\u652f\u6301\u81ea\u9002\u5e94\u5b89\u5168\u7b56\u7565\uff0c\u63d0\u4f9b\u6bd4\u4f20\u7edf\u8bbf\u95ee\u63a7\u5236\u7cfb\u7edf\u66f4\u5f3a\u7684\u5b89\u5168\u4fdd\u62a4\u548c\u5ba1\u8ba1\u6846\u67b6\u3002", "conclusion": "\u57fa\u4e8e\u6eaf\u6e90\u7684\u8bbf\u95ee\u63a7\u5236\u4e0d\u4ec5\u589e\u5f3a\u4e86\u5b89\u5168\u6027\uff0c\u8fd8\u4e3a\u5ba1\u8ba1\u548c\u5408\u89c4\u63d0\u4f9b\u4e86\u7a33\u5065\u7684\u6846\u67b6\uff0c\u662f\u89e3\u51b3\u4f20\u7edf\u8bbf\u95ee\u63a7\u5236\u7cfb\u7edf\u5c40\u9650\u6027\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2602.07698", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07698", "abs": "https://arxiv.org/abs/2602.07698", "authors": ["Adam Sorrenti", "Andriy Miranskyy"], "title": "On Sequence-to-Sequence Models for Automated Log Parsing", "comment": null, "summary": "Log parsing is a critical standard operating procedure in software systems, enabling monitoring, anomaly detection, and failure diagnosis. However, automated log parsing remains challenging due to heterogeneous log formats, distribution shifts between training and deployment data, and the brittleness of rule-based approaches. This study aims to systematically evaluate how sequence modelling architecture, representation choice, sequence length, and training data availability influence automated log parsing performance and computational cost. We conduct a controlled empirical study comparing four sequence modelling architectures: Transformer, Mamba state-space, monodirectional LSTM, and bidirectional LSTM models. In total, 396 models are trained across multiple dataset configurations and evaluated using relative Levenshtein edit distance with statistical significance testing. Transformer achieves the lowest mean relative edit distance (0.111), followed by Mamba (0.145), mono-LSTM (0.186), and bi-LSTM (0.265), where lower values are better. Mamba provides competitive accuracy with substantially lower computational cost. Character-level tokenization generally improves performance, sequence length has negligible practical impact on Transformer accuracy, and both Mamba and Transformer demonstrate stronger sample efficiency than recurrent models. Overall, Transformers reduce parsing error by 23.4%, while Mamba is a strong alternative under data or compute constraints. These results also clarify the roles of representation choice, sequence length, and sample efficiency, providing practical guidance for researchers and practitioners.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u4e0d\u540c\u5e8f\u5217\u5efa\u6a21\u67b6\u6784\uff08Transformer\u3001Mamba\u3001LSTM\uff09\u5728\u65e5\u5fd7\u89e3\u6790\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u53d1\u73b0Transformer\u5728\u51c6\u786e\u6027\u4e0a\u6700\u4f18\uff0cMamba\u5728\u8ba1\u7b97\u6210\u672c\u4e0a\u66f4\u5177\u4f18\u52bf\u3002", "motivation": "\u81ea\u52a8\u5316\u65e5\u5fd7\u89e3\u6790\u9762\u4e34\u5f02\u6784\u65e5\u5fd7\u683c\u5f0f\u3001\u8bad\u7ec3\u90e8\u7f72\u6570\u636e\u5206\u5e03\u504f\u79fb\u548c\u57fa\u4e8e\u89c4\u5219\u65b9\u6cd5\u7684\u8106\u5f31\u6027\u7b49\u6311\u6218\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u540c\u5e8f\u5217\u5efa\u6a21\u67b6\u6784\u7684\u6027\u80fd\u548c\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u91c7\u7528\u63a7\u5236\u6027\u5b9e\u8bc1\u7814\u7a76\uff0c\u6bd4\u8f83\u56db\u79cd\u5e8f\u5217\u5efa\u6a21\u67b6\u6784\uff1aTransformer\u3001Mamba\u72b6\u6001\u7a7a\u95f4\u3001\u5355\u5411LSTM\u548c\u53cc\u5411LSTM\u6a21\u578b\u3002\u8bad\u7ec3\u4e86396\u4e2a\u6a21\u578b\uff0c\u4f7f\u7528\u76f8\u5bf9Levenshtein\u7f16\u8f91\u8ddd\u79bb\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u8fdb\u884c\u7edf\u8ba1\u663e\u8457\u6027\u68c0\u9a8c\u3002", "result": "Transformer\u83b7\u5f97\u6700\u4f4e\u5e73\u5747\u76f8\u5bf9\u7f16\u8f91\u8ddd\u79bb\uff080.111\uff09\uff0c\u5176\u6b21\u662fMamba\uff080.145\uff09\u3001\u5355\u5411LSTM\uff080.186\uff09\u548c\u53cc\u5411LSTM\uff080.265\uff09\u3002Mamba\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002\u5b57\u7b26\u7ea7\u5206\u8bcd\u901a\u5e38\u63d0\u5347\u6027\u80fd\uff0c\u5e8f\u5217\u957f\u5ea6\u5bf9Transformer\u51c6\u786e\u6027\u5f71\u54cd\u53ef\u5ffd\u7565\u3002", "conclusion": "Transformer\u5c06\u89e3\u6790\u9519\u8bef\u51cf\u5c1123.4%\uff0c\u800cMamba\u5728\u6570\u636e\u6216\u8ba1\u7b97\u8d44\u6e90\u53d7\u9650\u65f6\u662f\u5f3a\u6709\u529b\u7684\u66ff\u4ee3\u65b9\u6848\u3002\u7814\u7a76\u7ed3\u679c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u5173\u4e8e\u8868\u793a\u9009\u62e9\u3001\u5e8f\u5217\u957f\u5ea6\u548c\u6837\u672c\u6548\u7387\u7684\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2602.07359", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07359", "abs": "https://arxiv.org/abs/2602.07359", "authors": ["Xiaoqiang Lin", "Jun Hao Liew", "Silvio Savarese", "Junnan Li"], "title": "W&D:Scaling Parallel Tool Calling for Efficient Deep Research Agents", "comment": null, "summary": "Deep research agents have emerged as powerful tools for automating complex intellectual tasks through multi-step reasoning and web-based information seeking. While recent efforts have successfully enhanced these agents by scaling depth through increasing the number of sequential thinking and tool calls, the potential of scaling width via parallel tool calling remains largely unexplored. In this work, we propose the Wide and Deep research agent, a framework designed to investigate the behavior and performance of agents when scaling not only depth but also width via parallel tool calling. Unlike existing approaches that rely on complex multi-agent orchestration to parallelize workloads, our method leverages intrinsic parallel tool calling to facilitate effective coordination within a single reasoning step. We demonstrate that scaling width significantly improves performance on deep research benchmarks while reducing the number of turns required to obtain correct answers. Furthermore, we analyze the factors driving these improvements through case studies and explore various tool call schedulers to optimize parallel tool calling strategy. Our findings suggest that optimizing the trade-off between width and depth is a critical pathway toward high-efficiency deep research agents. Notably, without context management or other tricks, we obtain 62.2% accuracy with GPT-5-Medium on BrowseComp, surpassing the original 54.9% reported by GPT-5-High.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\"\u5bbd\u6df1\u7814\u7a76\u667a\u80fd\u4f53\"\u6846\u67b6\uff0c\u901a\u8fc7\u5e76\u884c\u5de5\u5177\u8c03\u7528\u5b9e\u73b0\u5bbd\u5ea6\u6269\u5c55\uff0c\u5728\u4fdd\u6301\u6df1\u5ea6\u6269\u5c55\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u7814\u7a76\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u7814\u7a76\u667a\u80fd\u4f53\u4e3b\u8981\u901a\u8fc7\u589e\u52a0\u987a\u5e8f\u601d\u7ef4\u548c\u5de5\u5177\u8c03\u7528\u7684\u6570\u91cf\u6765\u6269\u5c55\u6df1\u5ea6\uff0c\u4f46\u901a\u8fc7\u5e76\u884c\u5de5\u5177\u8c03\u7528\u5b9e\u73b0\u5bbd\u5ea6\u6269\u5c55\u7684\u6f5c\u529b\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u540c\u65f6\u6269\u5c55\u5bbd\u5ea6\u548c\u6df1\u5ea6\u5bf9\u667a\u80fd\u4f53\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u5bbd\u6df1\u7814\u7a76\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5229\u7528\u5185\u5728\u5e76\u884c\u5de5\u5177\u8c03\u7528\u5728\u5355\u4e2a\u63a8\u7406\u6b65\u9aa4\u5185\u5b9e\u73b0\u6709\u6548\u534f\u8c03\uff0c\u907f\u514d\u4e86\u590d\u6742\u7684\u591a\u667a\u80fd\u4f53\u7f16\u6392\u3002\u7814\u7a76\u5206\u6790\u4e86\u5404\u79cd\u5de5\u5177\u8c03\u7528\u8c03\u5ea6\u5668\u4ee5\u4f18\u5316\u5e76\u884c\u7b56\u7565\u3002", "result": "\u5bbd\u5ea6\u6269\u5c55\u663e\u8457\u63d0\u5347\u4e86\u6df1\u5ea6\u7814\u7a76\u57fa\u51c6\u6d4b\u8bd5\u7684\u6027\u80fd\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u83b7\u5f97\u6b63\u786e\u7b54\u6848\u6240\u9700\u7684\u8f6e\u6b21\u3002\u4f7f\u7528GPT-5-Medium\u5728BrowseComp\u4e0a\u83b7\u5f9762.2%\u51c6\u786e\u7387\uff0c\u8d85\u8fc7\u4e86\u539f\u59cbGPT-5-High\u62a5\u544a\u768454.9%\u3002", "conclusion": "\u4f18\u5316\u5bbd\u5ea6\u4e0e\u6df1\u5ea6\u4e4b\u95f4\u7684\u6743\u8861\u662f\u6784\u5efa\u9ad8\u6548\u6df1\u5ea6\u7814\u7a76\u667a\u80fd\u4f53\u7684\u5173\u952e\u9014\u5f84\u3002\u5e76\u884c\u5de5\u5177\u8c03\u7528\u4e3a\u667a\u80fd\u4f53\u6027\u80fd\u63d0\u5347\u63d0\u4f9b\u4e86\u91cd\u8981\u65b9\u5411\u3002"}}
{"id": "2602.07725", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.07725", "abs": "https://arxiv.org/abs/2602.07725", "authors": ["Yaoqi Yang", "Yong Chen", "Jiacheng Wang", "Geng Sun", "Dusit Niyato", "Zhu Han"], "title": "Leveraging the Power of Ensemble Learning for Secure Low Altitude Economy", "comment": "7 pages, 2 figures", "summary": "Low Altitude Economy (LAE) holds immense promise for enhancing societal well-being and driving economic growth. However, this burgeoning field is vulnerable to security threats, particularly malicious aircraft intrusion attacks. To address the above concerns, intrusion detection systems (IDS) can be used to defend against malicious aircraft intrusions in LAE. Whereas, due to the heterogeneous data, dynamic environment, and resource-constrained devices within LAE, current IDS face challenges in detection accuracy, adaptability, and resource utilization ratio. In this regard, due to the inherent ability to combine the strengths of multiple models, ensemble learning can realize more robust and diverse anomaly detection further enhance IDS accuracy, thereby improving robustness and efficiency of the secure LAE. Unlike single-model approaches, ensemble learning can leverage the collective knowledge of its constituent models to effectively defend the malicious aircraft intrusion attacks. Specifically, this paper investigates ensemble learning for secure LAE, covering research focuses, solutions, and a case study. We first establish the rationale for ensemble learning and then review research areas and potential solutions, demonstrating the necessities and benefits of applying ensemble learning to secure LAE. Subsequently, we propose a framework of ensemble learning-enabled malicious aircrafts tracking in the secure LAE, where its feasibility and effectiveness are evaluated by the designed case study. Finally, we conclude by outlining promising future research directions for further advancing the ensemble learning-enabled secure LAE.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5728\u4f4e\u7a7a\u7ecf\u6d4e\u4e2d\u5e94\u7528\u96c6\u6210\u5b66\u4e60\u6765\u9632\u5fa1\u6076\u610f\u98de\u673a\u5165\u4fb5\u653b\u51fb\uff0c\u901a\u8fc7\u7ed3\u5408\u591a\u4e2a\u6a21\u578b\u7684\u4f18\u52bf\u63d0\u9ad8\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u3001\u9002\u5e94\u6027\u548c\u8d44\u6e90\u5229\u7528\u7387\u3002", "motivation": "\u4f4e\u7a7a\u7ecf\u6d4e\u9762\u4e34\u6076\u610f\u98de\u673a\u5165\u4fb5\u7684\u5b89\u5168\u5a01\u80c1\uff0c\u800c\u73b0\u6709\u7684\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u7531\u4e8e\u5f02\u6784\u6570\u636e\u3001\u52a8\u6001\u73af\u5883\u548c\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u7b49\u56e0\u7d20\uff0c\u5728\u68c0\u6d4b\u51c6\u786e\u6027\u3001\u9002\u5e94\u6027\u548c\u8d44\u6e90\u5229\u7528\u7387\u65b9\u9762\u5b58\u5728\u6311\u6218\u3002", "method": "\u91c7\u7528\u96c6\u6210\u5b66\u4e60\u65b9\u6cd5\uff0c\u5229\u7528\u591a\u4e2a\u6a21\u578b\u7684\u96c6\u4f53\u77e5\u8bc6\u6765\u589e\u5f3a\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u3002\u8bba\u6587\u5efa\u7acb\u4e86\u96c6\u6210\u5b66\u4e60\u7684\u7406\u8bba\u57fa\u7840\uff0c\u56de\u987e\u4e86\u76f8\u5173\u7814\u7a76\u9886\u57df\u548c\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u96c6\u6210\u5b66\u4e60\u652f\u6301\u7684\u6076\u610f\u98de\u673a\u8ffd\u8e2a\u6846\u67b6\u3002", "result": "\u901a\u8fc7\u8bbe\u8ba1\u7684\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u96c6\u6210\u5b66\u4e60\u6846\u67b6\u5728\u4f4e\u7a7a\u7ecf\u6d4e\u4e2d\u9632\u5fa1\u6076\u610f\u98de\u673a\u5165\u4fb5\u7684\u53ef\u884c\u6027\u548c\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u5176\u5728\u63d0\u9ad8\u68c0\u6d4b\u51c6\u786e\u6027\u3001\u9002\u5e94\u6027\u548c\u8d44\u6e90\u5229\u7528\u7387\u65b9\u9762\u7684\u4f18\u52bf\u3002", "conclusion": "\u96c6\u6210\u5b66\u4e60\u80fd\u591f\u663e\u8457\u63d0\u5347\u4f4e\u7a7a\u7ecf\u6d4e\u7684\u5b89\u5168\u6027\uff0c\u8bba\u6587\u6700\u540e\u5c55\u671b\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u4ee5\u8fdb\u4e00\u6b65\u63a8\u8fdb\u96c6\u6210\u5b66\u4e60\u5728\u5b89\u5168\u4f4e\u7a7a\u7ecf\u6d4e\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2602.07783", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07783", "abs": "https://arxiv.org/abs/2602.07783", "authors": ["Zejun Zhang", "Yixin Gan", "Zhenchang Xing", "Tian Zhang", "Yi Li", "Xiwei Xu", "Qinghua Lu", "Liming Zhu"], "title": "Still Manual? Automated Linter Configuration via DSL-Based LLM Compilation of Coding Standards", "comment": "Accepted By FSE2026", "summary": "Coding standards are essential for maintaining consistent and high-quality code across teams and projects. Linters help developers enforce these standards by detecting code violations. However, manual linter configuration is complex and expertise-intensive, and the diversity and evolution of programming languages, coding standards, and linters lead to repetitive and maintenance-intensive configuration work. To reduce manual effort, we propose LintCFG, a domain-specific language (DSL)-driven, LLM-based compilation approach to automate linter configuration generation for coding standards, independent of programming languages, coding standards, and linters. Inspired by compiler design, we first design a DSL to express coding rules in a tool-agnostic, structured, readable, and precise manner. Then, we build linter configurations into DSL configuration instructions. For a given natural language coding standard, the compilation process parses it into DSL coding standards, matches them with the DSL configuration instructions to set configuration names, option names and values, verifies consistency between the standards and configurations, and finally generates linter-specific configurations. Experiments with Checkstyle for Java coding standard show that our approach achieves over 90% precision and recall in DSL representation, with accuracy, precision, recall, and F1-scores close to 70% (with some exceeding 70%) in fine-grained linter configuration generation. Notably, our approach outperforms baselines by over 100% in precision. A user study further shows that our approach improves developers' efficiency in configuring linters for coding standards. Finally, we demonstrate the generality of the approach by generating ESLint configurations for JavaScript coding standards, showcasing its broad applicability across other programming languages, coding standards, and linters.", "AI": {"tldr": "LintCFG\uff1a\u57fa\u4e8eDSL\u548cLLM\u7684\u81ea\u52a8\u5316linter\u914d\u7f6e\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u7f16\u8bd1\u5668\u8bbe\u8ba1\u601d\u8def\u5c06\u81ea\u7136\u8bed\u8a00\u7f16\u7801\u6807\u51c6\u8f6c\u6362\u4e3a\u7279\u5b9alinter\u914d\u7f6e\uff0c\u663e\u8457\u63d0\u9ad8\u914d\u7f6e\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u624b\u52a8\u914d\u7f6elinter\u590d\u6742\u4e14\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\uff0c\u4e0d\u540c\u7f16\u7a0b\u8bed\u8a00\u3001\u7f16\u7801\u6807\u51c6\u548clinter\u7684\u591a\u6837\u6027\u5bfc\u81f4\u91cd\u590d\u4e14\u7ef4\u62a4\u5bc6\u96c6\u7684\u914d\u7f6e\u5de5\u4f5c\u3002\u9700\u8981\u81ea\u52a8\u5316\u65b9\u6cd5\u6765\u51cf\u5c11\u4eba\u5de5\u5de5\u4f5c\u91cf\u3002", "method": "\u8bbe\u8ba1\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff08DSL\uff09\u4ee5\u5de5\u5177\u65e0\u5173\u3001\u7ed3\u6784\u5316\u3001\u53ef\u8bfb\u4e14\u7cbe\u786e\u7684\u65b9\u5f0f\u8868\u8fbe\u7f16\u7801\u89c4\u5219\uff1b\u5c06linter\u914d\u7f6e\u6784\u5efa\u4e3aDSL\u914d\u7f6e\u6307\u4ee4\uff1b\u901a\u8fc7\u7f16\u8bd1\u8fc7\u7a0b\u5c06\u81ea\u7136\u8bed\u8a00\u7f16\u7801\u6807\u51c6\u89e3\u6790\u4e3aDSL\u7f16\u7801\u6807\u51c6\uff0c\u5339\u914d\u914d\u7f6e\u6307\u4ee4\uff0c\u9a8c\u8bc1\u4e00\u81f4\u6027\uff0c\u6700\u7ec8\u751f\u6210linter\u7279\u5b9a\u914d\u7f6e\u3002", "result": "\u5728Java\u7f16\u7801\u6807\u51c6\u7684Checkstyle\u5b9e\u9a8c\u4e2d\uff0cDSL\u8868\u793a\u8fbe\u523090%\u4ee5\u4e0a\u7684\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387\uff1b\u7ec6\u7c92\u5ea6linter\u914d\u7f6e\u751f\u6210\u7684\u51c6\u786e\u7387\u3001\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u63a5\u8fd170%\uff08\u90e8\u5206\u8d85\u8fc770%\uff09\uff1b\u5728\u7cbe\u786e\u7387\u4e0a\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u63d0\u9ad8100%\u4ee5\u4e0a\uff1b\u7528\u6237\u7814\u7a76\u8868\u660e\u63d0\u9ad8\u4e86\u5f00\u53d1\u4eba\u5458\u914d\u7f6elinter\u7684\u6548\u7387\uff1b\u901a\u8fc7\u4e3aJavaScript\u7f16\u7801\u6807\u51c6\u751f\u6210ESLint\u914d\u7f6e\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u901a\u7528\u6027\u3002", "conclusion": "LintCFG\u65b9\u6cd5\u80fd\u591f\u8de8\u7f16\u7a0b\u8bed\u8a00\u3001\u7f16\u7801\u6807\u51c6\u548clinter\u81ea\u52a8\u5316\u751f\u6210linter\u914d\u7f6e\uff0c\u663e\u8457\u51cf\u5c11\u4eba\u5de5\u5de5\u4f5c\u91cf\uff0c\u63d0\u9ad8\u914d\u7f6e\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2602.07878", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07878", "abs": "https://arxiv.org/abs/2602.07878", "authors": ["Tianyi Wang", "Huawei Fan", "Yuanchao Shu", "Peng Cheng", "Cong Wang"], "title": "Rethinking Latency Denial-of-Service: Attacking the LLM Serving Framework, Not the Model", "comment": null, "summary": "Large Language Models face an emerging and critical threat known as latency attacks. Because LLM inference is inherently expensive, even modest slowdowns can translate into substantial operating costs and severe availability risks. Recently, a growing body of research has focused on algorithmic complexity attacks by crafting inputs to trigger worst-case output lengths. However, we report a counter-intuitive finding that these algorithmic latency attacks are largely ineffective against modern LLM serving systems. We reveal that system-level optimization such as continuous batching provides a logical isolation to mitigate contagious latency impact on co-located users. To this end, in this paper, we shift the focus from the algorithm to the system layer, and introduce a new Fill and Squeeze attack strategy targeting the state transition of the scheduler. \"Fill\" first exhausts the global KV cache to induce Head-of-Line blocking, while \"Squeeze\" forces the system into repetitive preemption. By manipulating output lengths using methods from simple plain-text prompts to more complex prompt engineering, and leveraging side-channel probing of memory status, we demonstrate that the attack can be orchestrated in a black-box setting with much less cost. Extensive evaluations indicate by up to 20-280x average slowdown on Time to First Token and 1.5-4x average slowdown on Time Per Output Token compared to existing attacks with 30-40% lower attack cost.", "AI": {"tldr": "\u8bba\u6587\u63ed\u793a\u4f20\u7edf\u7b97\u6cd5\u5ef6\u8fdf\u653b\u51fb\u5bf9\u73b0\u4ee3LLM\u670d\u52a1\u7cfb\u7edf\u65e0\u6548\uff0c\u63d0\u51fa\u9488\u5bf9\u8c03\u5ea6\u5668\u72b6\u6001\u8f6c\u6362\u7684\"\u586b\u5145\u4e0e\u6324\u538b\"\u7cfb\u7edf\u5c42\u653b\u51fb\u7b56\u7565\uff0c\u80fd\u4ee5\u66f4\u4f4e\u6210\u672c\u9020\u6210\u663e\u8457\u5ef6\u8fdf", "motivation": "LLM\u63a8\u7406\u6210\u672c\u9ad8\u6602\uff0c\u8f7b\u5fae\u5ef6\u8fdf\u5c31\u4f1a\u5bfc\u81f4\u5de8\u5927\u8fd0\u8425\u6210\u672c\u548c\u53ef\u7528\u6027\u98ce\u9669\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u7b97\u6cd5\u590d\u6742\u5ea6\u653b\u51fb\uff0c\u4f46\u4f5c\u8005\u53d1\u73b0\u8fd9\u4e9b\u653b\u51fb\u5bf9\u73b0\u4ee3LLM\u670d\u52a1\u7cfb\u7edf\u57fa\u672c\u65e0\u6548\uff0c\u56e0\u6b64\u8f6c\u5411\u7cfb\u7edf\u5c42\u653b\u51fb", "method": "\u63d0\u51fa\"\u586b\u5145\u4e0e\u6324\u538b\"\u653b\u51fb\u7b56\u7565\uff1a1) \"\u586b\u5145\"\u9636\u6bb5\u8017\u5c3d\u5168\u5c40KV\u7f13\u5b58\u5f15\u53d1\u961f\u5934\u963b\u585e\uff1b2) \"\u6324\u538b\"\u9636\u6bb5\u8feb\u4f7f\u7cfb\u7edf\u8fdb\u5165\u91cd\u590d\u62a2\u5360\u72b6\u6001\u3002\u7ed3\u5408\u7b80\u5355\u6587\u672c\u63d0\u793a\u5230\u590d\u6742\u63d0\u793a\u5de5\u7a0b\uff0c\u5e76\u5229\u7528\u5185\u5b58\u72b6\u6001\u4fa7\u4fe1\u9053\u63a2\u6d4b\uff0c\u5728\u65e0\u9700\u4e86\u89e3\u7cfb\u7edf\u5185\u90e8\u7ec6\u8282\u7684\u9ed1\u76d2\u8bbe\u7f6e\u4e0b\u5b9e\u65bd\u653b\u51fb", "result": "\u653b\u51fb\u6548\u679c\u663e\u8457\uff1a\u76f8\u6bd4\u73b0\u6709\u653b\u51fb\uff0c\u9996\u4ee4\u724c\u65f6\u95f4\u5e73\u5747\u51cf\u616220-280\u500d\uff0c\u6bcf\u8f93\u51fa\u4ee4\u724c\u65f6\u95f4\u5e73\u5747\u51cf\u61621.5-4\u500d\uff0c\u540c\u65f6\u653b\u51fb\u6210\u672c\u964d\u4f4e30-40%", "conclusion": "\u7cfb\u7edf\u5c42\u653b\u51fb\u6bd4\u7b97\u6cd5\u590d\u6742\u5ea6\u653b\u51fb\u66f4\u6709\u6548\uff0c\u73b0\u4ee3LLM\u670d\u52a1\u7cfb\u7edf\u5728\u8c03\u5ea6\u4f18\u5316\u65b9\u9762\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u8981\u65b0\u7684\u9632\u5fa1\u673a\u5236\u6765\u5e94\u5bf9\u8fd9\u7c7b\u9488\u5bf9\u8c03\u5ea6\u5668\u72b6\u6001\u8f6c\u6362\u7684\u653b\u51fb"}}
{"id": "2602.07821", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.07821", "abs": "https://arxiv.org/abs/2602.07821", "authors": ["Shinobu Saito"], "title": "Software Space Analytics: Towards Visualization and Statistics of Internal Software Execution", "comment": null, "summary": "In software maintenance work, software architects and programmers need to identify modules that require modification or deletion. Whilst user requests and bug reports are utilised for this purpose, evaluating the execution status of modules within the software is also crucial. This paper, therefore, applies spatial statistics to assess internal software execution data. First, we define a software space dataset, viewing the software's internal structure as a space based on module call relationships. Then, using spatial statistics, we conduct the visualization of spatial clusters and the statistical testing using spatial measures. Finally, we consider the usefulness of spatial statistics in the software engineering domain and future challenges.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c06\u7a7a\u95f4\u7edf\u8ba1\u65b9\u6cd5\u5e94\u7528\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\uff0c\u901a\u8fc7\u5c06\u8f6f\u4ef6\u5185\u90e8\u6a21\u5757\u8c03\u7528\u5173\u7cfb\u89c6\u4e3a\u7a7a\u95f4\u7ed3\u6784\uff0c\u4f7f\u7528\u7a7a\u95f4\u7edf\u8ba1\u6280\u672f\u6765\u8bc6\u522b\u9700\u8981\u4fee\u6539\u6216\u5220\u9664\u7684\u8f6f\u4ef6\u6a21\u5757\u3002", "motivation": "\u5728\u8f6f\u4ef6\u7ef4\u62a4\u5de5\u4f5c\u4e2d\uff0c\u67b6\u6784\u5e08\u548c\u7a0b\u5e8f\u5458\u9700\u8981\u8bc6\u522b\u9700\u8981\u4fee\u6539\u6216\u5220\u9664\u7684\u6a21\u5757\u3002\u867d\u7136\u7528\u6237\u8bf7\u6c42\u548c\u9519\u8bef\u62a5\u544a\u53ef\u7528\u4e8e\u6b64\u76ee\u7684\uff0c\u4f46\u8bc4\u4f30\u8f6f\u4ef6\u5185\u90e8\u6a21\u5757\u7684\u6267\u884c\u72b6\u6001\u540c\u6837\u91cd\u8981\u3002\u73b0\u6709\u65b9\u6cd5\u53ef\u80fd\u4e0d\u8db3\u4ee5\u5168\u9762\u5206\u6790\u8f6f\u4ef6\u5185\u90e8\u6267\u884c\u6570\u636e\u3002", "method": "1. \u5b9a\u4e49\u8f6f\u4ef6\u7a7a\u95f4\u6570\u636e\u96c6\uff1a\u5c06\u8f6f\u4ef6\u5185\u90e8\u7ed3\u6784\u57fa\u4e8e\u6a21\u5757\u8c03\u7528\u5173\u7cfb\u89c6\u4e3a\u4e00\u4e2a\u7a7a\u95f4\n2. \u5e94\u7528\u7a7a\u95f4\u7edf\u8ba1\u65b9\u6cd5\uff1a\u8fdb\u884c\u7a7a\u95f4\u805a\u7c7b\u53ef\u89c6\u5316\n3. \u4f7f\u7528\u7a7a\u95f4\u5ea6\u91cf\u8fdb\u884c\u7edf\u8ba1\u6d4b\u8bd5", "result": "\u8bba\u6587\u5c55\u793a\u4e86\u7a7a\u95f4\u7edf\u8ba1\u65b9\u6cd5\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u901a\u8fc7\u7a7a\u95f4\u805a\u7c7b\u53ef\u89c6\u5316\u548c\u7edf\u8ba1\u6d4b\u8bd5\uff0c\u80fd\u591f\u5e2e\u52a9\u8bc6\u522b\u9700\u8981\u5173\u6ce8\u7684\u8f6f\u4ef6\u6a21\u5757\u3002", "conclusion": "\u7a7a\u95f4\u7edf\u8ba1\u65b9\u6cd5\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u5177\u6709\u5e94\u7528\u4ef7\u503c\uff0c\u80fd\u591f\u5e2e\u52a9\u5206\u6790\u8f6f\u4ef6\u5185\u90e8\u6267\u884c\u6570\u636e\u3002\u672a\u6765\u9700\u8981\u8fdb\u4e00\u6b65\u63a2\u7d22\u7a7a\u95f4\u7edf\u8ba1\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5177\u4f53\u5e94\u7528\u6311\u6218\u548c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.07399", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.07399", "abs": "https://arxiv.org/abs/2602.07399", "authors": ["Changhua Xu", "Jie Lu", "Junyu Xuan", "En Yu"], "title": "VGAS: Value-Guided Action-Chunk Selection for Few-Shot Vision-Language-Action Adaptation", "comment": "Preprint", "summary": "Vision--Language--Action (VLA) models bridge multimodal reasoning with physical control, but adapting them to new tasks with scarce demonstrations remains unreliable. While fine-tuned VLA policies often produce semantically plausible trajectories, failures often arise from unresolved geometric ambiguities, where near-miss action candidates lead to divergent execution outcomes under limited supervision. We study few-shot VLA adaptation from a \\emph{generation--selection} perspective and propose a novel framework \\textbf{VGAS} (\\textbf{V}alue-\\textbf{G}uided \\textbf{A}ction-chunk \\textbf{S}election). It performs inference-time best-of-$N$ selection to identify action chunks that are both semantically faithful and geometrically precise. Specifically, \\textbf{VGAS} employs a finetuned VLA as a high-recall proposal generator and introduces the \\textrm{Q-Chunk-Former}, a geometrically grounded Transformer critic to resolve fine-grained geometric ambiguities. In addition, we propose \\textit{Explicit Geometric Regularization} (\\texttt{EGR}), which explicitly shapes a discriminative value landscape to preserve action ranking resolution among near-miss candidates while mitigating value instability under scarce supervision. Experiments and theoretical analysis demonstrate that \\textbf{VGAS} consistently improves success rates and robustness under limited demonstrations and distribution shifts. Our code is available at https://github.com/Jyugo-15/VGAS.", "AI": {"tldr": "VGAS\u6846\u67b6\u901a\u8fc7\u751f\u6210-\u9009\u62e9\u8303\u5f0f\u89e3\u51b3VLA\u6a21\u578b\u5728\u5c11\u6837\u672c\u9002\u5e94\u4e2d\u7684\u51e0\u4f55\u6a21\u7cca\u95ee\u9898\uff0c\u4f7f\u7528\u4ef7\u503c\u5f15\u5bfc\u7684\u52a8\u4f5c\u5757\u9009\u62e9\u63d0\u5347\u8f68\u8ff9\u7684\u51e0\u4f55\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u3002", "motivation": "VLA\u6a21\u578b\u5728\u591a\u6a21\u6001\u63a8\u7406\u4e0e\u7269\u7406\u63a7\u5236\u4e4b\u95f4\u5efa\u7acb\u6865\u6881\uff0c\u4f46\u5728\u5c11\u6837\u672c\u9002\u5e94\u65b0\u4efb\u52a1\u65f6\u5b58\u5728\u4e0d\u53ef\u9760\u95ee\u9898\u3002\u4e3b\u8981\u6311\u6218\u662f\u51e0\u4f55\u6a21\u7cca\u6027\uff1a\u8bed\u4e49\u5408\u7406\u7684\u8f68\u8ff9\u53ef\u80fd\u56e0\u7ec6\u5fae\u7684\u51e0\u4f55\u5dee\u5f02\u5bfc\u81f4\u6267\u884c\u5931\u8d25\uff0c\u800c\u6709\u9650\u7684\u76d1\u7763\u96be\u4ee5\u89e3\u51b3\u8fd9\u79cd\u8fd1\u5931\u5019\u9009\u52a8\u4f5c\u4e4b\u95f4\u7684\u6b67\u4e49\u3002", "method": "\u63d0\u51faVGAS\u6846\u67b6\uff0c\u91c7\u7528\u751f\u6210-\u9009\u62e9\u8303\u5f0f\uff1a1) \u4f7f\u7528\u5fae\u8c03\u7684VLA\u4f5c\u4e3a\u9ad8\u53ec\u56de\u7387\u63d0\u6848\u751f\u6210\u5668\uff1b2) \u5f15\u5165Q-Chunk-Former\u4f5c\u4e3a\u51e0\u4f55\u57fa\u7840\u7684Transformer\u8bc4\u8bba\u5bb6\uff0c\u89e3\u51b3\u7ec6\u7c92\u5ea6\u51e0\u4f55\u6a21\u7cca\uff1b3) \u63d0\u51fa\u663e\u5f0f\u51e0\u4f55\u6b63\u5219\u5316(EGR)\uff0c\u901a\u8fc7\u663e\u5f0f\u5851\u9020\u5224\u522b\u6027\u4ef7\u503c\u666f\u89c2\u6765\u4fdd\u6301\u52a8\u4f5c\u6392\u5e8f\u5206\u8fa8\u7387\uff0c\u540c\u65f6\u7f13\u89e3\u5c11\u76d1\u7763\u4e0b\u7684\u4ef7\u503c\u4e0d\u7a33\u5b9a\u6027\u3002", "result": "\u5b9e\u9a8c\u548c\u7406\u8bba\u5206\u6790\u8868\u660e\uff0cVGAS\u5728\u6709\u9650\u6f14\u793a\u548c\u5206\u5e03\u504f\u79fb\u4e0b\u80fd\u6301\u7eed\u63d0\u9ad8\u6210\u529f\u7387\u548c\u9c81\u68d2\u6027\u3002\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86VLA\u6a21\u578b\u5728\u5c11\u6837\u672c\u9002\u5e94\u4e2d\u7684\u51e0\u4f55\u7cbe\u5ea6\u95ee\u9898\u3002", "conclusion": "VGAS\u901a\u8fc7\u4ef7\u503c\u5f15\u5bfc\u7684\u52a8\u4f5c\u5757\u9009\u62e9\u6846\u67b6\uff0c\u4e3aVLA\u6a21\u578b\u7684\u5c11\u6837\u672c\u9002\u5e94\u63d0\u4f9b\u4e86\u53ef\u9760\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u751f\u6210-\u9009\u62e9\u8303\u5f0f\u548c\u51e0\u4f55\u6b63\u5219\u5316\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5728\u51e0\u4f55\u6a21\u7cca\u573a\u666f\u4e0b\u7684\u6267\u884c\u7cbe\u5ea6\u548c\u7a33\u5b9a\u6027\u3002"}}
{"id": "2602.07871", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.07871", "abs": "https://arxiv.org/abs/2602.07871", "authors": ["Xiang Li", "Siyu Lu", "Sarro Federica", "Claire Le Goues", "He Ye"], "title": "HerAgent: Rethinking the Automated Environment Deployment via Hierarchical Test Pyramid", "comment": null, "summary": "Automated software environment setup is a prerequisite for testing, debugging, and reproducing failures, yet remains challenging in practice due to complex dependencies, heterogeneous build systems, and incomplete documentation. Recent work leverages large language models to automate this process, but typically evaluates success using weak signals such as dependency installation or partial test execution, which do not ensure that a project can actually run. In this paper, we argue that environment setup success should be evaluated through executable evidence rather than a single binary signal. We introduce the Environment Maturity Hierarchy, which defines three success levels based on progressively stronger execution requirements, culminating in successful execution of a project's main entry point. Guided by this hierarchy, we propose HerAgent, an automated environment setup approach that incrementally constructs executable environments through execution-based validation and repair. We evaluate HerAgent on four public benchmarks, where it outperforms all related work, achieving up to 79.6\\% improvement due to its holistic understanding of project structure and dependencies. On complex C/C++ projects, HerAgent surpasses prior approaches by 66.7\\%. In addition, HerAgent uniquely resolves 11-30 environment instances across the benchmarks that no prior method can configure.", "AI": {"tldr": "HerAgent\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6267\u884c\u9a8c\u8bc1\u7684\u5206\u5c42\u73af\u5883\u642d\u5efa\u65b9\u6cd5\uff0c\u901a\u8fc7\u73af\u5883\u6210\u719f\u5ea6\u5c42\u6b21\u7ed3\u6784\u8bc4\u4f30\u73af\u5883\u642d\u5efa\u6210\u529f\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u5316\u8f6f\u4ef6\u73af\u5883\u642d\u5efa\u65b9\u6cd5\u901a\u5e38\u4f7f\u7528\u4f9d\u8d56\u5b89\u88c5\u6216\u90e8\u5206\u6d4b\u8bd5\u6267\u884c\u7b49\u5f31\u4fe1\u53f7\u8bc4\u4f30\u6210\u529f\uff0c\u65e0\u6cd5\u786e\u4fdd\u9879\u76ee\u5b9e\u9645\u53ef\u8fd0\u884c\u3002\u9700\u8981\u57fa\u4e8e\u53ef\u6267\u884c\u8bc1\u636e\u6765\u8bc4\u4f30\u73af\u5883\u642d\u5efa\u7684\u6210\u529f\u3002", "method": "\u63d0\u51fa\u73af\u5883\u6210\u719f\u5ea6\u5c42\u6b21\u7ed3\u6784\uff0c\u5b9a\u4e49\u4e09\u4e2a\u57fa\u4e8e\u9010\u6b65\u589e\u5f3a\u6267\u884c\u8981\u6c42\u7684\u6210\u529f\u7ea7\u522b\uff1b\u5f00\u53d1HerAgent\u65b9\u6cd5\uff0c\u901a\u8fc7\u6267\u884c\u9a8c\u8bc1\u548c\u4fee\u590d\u589e\u91cf\u6784\u5efa\u53ef\u6267\u884c\u73af\u5883\u3002", "result": "\u5728\u56db\u4e2a\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cHerAgent\u4f18\u4e8e\u6240\u6709\u76f8\u5173\u5de5\u4f5c\uff0c\u5b9e\u73b0\u9ad8\u8fbe79.6%\u7684\u6539\u8fdb\uff1b\u5728\u590d\u6742C/C++\u9879\u76ee\u4e2d\u8d85\u8d8a\u5148\u524d\u65b9\u6cd566.7%\uff1b\u72ec\u7279\u89e3\u51b3\u4e8611-30\u4e2a\u5176\u4ed6\u65b9\u6cd5\u65e0\u6cd5\u914d\u7f6e\u7684\u73af\u5883\u5b9e\u4f8b\u3002", "conclusion": "\u57fa\u4e8e\u6267\u884c\u9a8c\u8bc1\u7684\u5206\u5c42\u73af\u5883\u642d\u5efa\u65b9\u6cd5\u80fd\u66f4\u53ef\u9760\u5730\u8bc4\u4f30\u548c\u5b9e\u73b0\u8f6f\u4ef6\u73af\u5883\u914d\u7f6e\uff0c\u663e\u8457\u63d0\u5347\u81ea\u52a8\u5316\u73af\u5883\u642d\u5efa\u7684\u6210\u529f\u7387\u548c\u8d28\u91cf\u3002"}}
{"id": "2602.07408", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.07408", "abs": "https://arxiv.org/abs/2602.07408", "authors": ["Hyomin Kim", "Sang-Yeon Hwang", "Jaechang Lim", "Yinhua Piao", "Yunhak Oh", "Woo Youn Kim", "Chanyoung Park", "Sungsoo Ahn", "Junhyeok Jeon"], "title": "Progressive Multi-Agent Reasoning for Biological Perturbation Prediction", "comment": "17 pages, 4 figures, 9 tables", "summary": "Predicting gene regulation responses to biological perturbations requires reasoning about underlying biological causalities. While large language models (LLMs) show promise for such tasks, they are often overwhelmed by the entangled nature of high-dimensional perturbation results. Moreover, recent works have primarily focused on genetic perturbations in single-cell experiments, leaving bulk-cell chemical perturbations, which is central to drug discovery, largely unexplored. Motivated by this, we present LINCSQA, a novel benchmark for predicting target gene regulation under complex chemical perturbations in bulk-cell environments. We further propose PBio-Agent, a multi-agent framework that integrates difficulty-aware task sequencing with iterative knowledge refinement. Our key insight is that genes affected by the same perturbation share causal structure, allowing confidently predicted genes to contextualize more challenging cases. The framework employs specialized agents enriched with biological knowledge graphs, while a synthesis agent integrates outputs and specialized judges ensure logical coherence. PBio-Agent outperforms existing baselines on both LINCSQA and PerturbQA, enabling even smaller models to predict and explain complex biological processes without additional training.", "AI": {"tldr": "\u63d0\u51faLINCSQA\u57fa\u51c6\u548cPBio-Agent\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u5316\u5b66\u6270\u52a8\u4e0b\u57fa\u56e0\u8c03\u63a7\u53cd\u5e94\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u540c\u89e3\u51b3\u590d\u6742\u751f\u7269\u56e0\u679c\u63a8\u7406\u95ee\u9898", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5355\u7ec6\u80de\u9057\u4f20\u6270\u52a8\uff0c\u800c\u836f\u7269\u53d1\u73b0\u6838\u5fc3\u7684\u6279\u91cf\u7ec6\u80de\u5316\u5b66\u6270\u52a8\u7814\u7a76\u4e0d\u8db3\uff1b\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u9ad8\u7ef4\u6270\u52a8\u7ed3\u679c\u65f6\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u66f4\u597d\u7684\u56e0\u679c\u63a8\u7406\u80fd\u529b", "method": "\u63d0\u51faPBio-Agent\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u542b\u96be\u5ea6\u611f\u77e5\u4efb\u52a1\u6392\u5e8f\u548c\u8fed\u4ee3\u77e5\u8bc6\u7cbe\u70bc\uff1b\u5229\u7528\u76f8\u540c\u6270\u52a8\u5f71\u54cd\u7684\u57fa\u56e0\u5171\u4eab\u56e0\u679c\u7ed3\u6784\u7684\u6d1e\u5bdf\uff0c\u8ba9\u9ad8\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u4e3a\u56f0\u96be\u6848\u4f8b\u63d0\u4f9b\u4e0a\u4e0b\u6587\uff1b\u6846\u67b6\u5305\u542b\u751f\u7269\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u7684\u4e13\u95e8\u667a\u80fd\u4f53\u3001\u6574\u5408\u8f93\u51fa\u7684\u5408\u6210\u667a\u80fd\u4f53\u4ee5\u53ca\u786e\u4fdd\u903b\u8f91\u4e00\u81f4\u6027\u7684\u4e13\u95e8\u8bc4\u5224\u5668", "result": "PBio-Agent\u5728LINCSQA\u548cPerturbQA\u57fa\u51c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5373\u4f7f\u8f83\u5c0f\u6a21\u578b\u4e5f\u80fd\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u9884\u6d4b\u548c\u89e3\u91ca\u590d\u6742\u751f\u7269\u8fc7\u7a0b", "conclusion": "PBio-Agent\u6846\u67b6\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u540c\u548c\u56e0\u679c\u7ed3\u6784\u5171\u4eab\u7684\u6d1e\u5bdf\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5316\u5b66\u6270\u52a8\u4e0b\u57fa\u56e0\u8c03\u63a7\u9884\u6d4b\u7684\u6311\u6218\uff0c\u4e3a\u836f\u7269\u53d1\u73b0\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177"}}
{"id": "2602.07936", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.07936", "abs": "https://arxiv.org/abs/2602.07936", "authors": ["Tasnia Ashrafi Heya", "Sayed Erfan Arefin"], "title": "Privacy-Preserving Covert Communication Using Encrypted Wearable Gesture Recognition", "comment": null, "summary": "Secure communication is essential in covert and safety-critical settings where verbal interactions may expose user intent or operational context. Wearable gesture-based communication enables low-effort, nonverbal interaction, but existing systems leak motion data, intermediate representations, or inference outputs to untrusted infrastructure, enabling intent inference, behavioral biometric leakage, and insider attacks. This work proposes a privacy-preserving gesture-based covert communication system that ensures, no raw sensor signals, learned features, or classification outputs are exposed to any third-party. The system employs a multi-party homomorphic learning pipeline for gesture recognition directly over encrypted motion data, preventing adversaries from inferring gesture semantics, replaying sensor traces, or accessing intermediate representations. To our knowledge, this work is the first to apply encrypted gesture recognition in a wearable-based covert communication setting. We design and evaluate haptic and visual feedback mechanisms for covert signal delivery and evaluate the system using 600 gesture samples from a commodity smartwatch, achieving over 94.44% classification accuracy and demonstrating the feasibility of the proposed system with practical deployability from high-performance systems to resource-constrained edge devices.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9690\u79c1\u4fdd\u62a4\u7684\u57fa\u4e8e\u624b\u52bf\u7684\u9690\u853d\u901a\u4fe1\u7cfb\u7edf\uff0c\u4f7f\u7528\u540c\u6001\u52a0\u5bc6\u6280\u672f\u76f4\u63a5\u5728\u52a0\u5bc6\u7684\u8fd0\u52a8\u6570\u636e\u4e0a\u8fdb\u884c\u624b\u52bf\u8bc6\u522b\uff0c\u9632\u6b62\u7b2c\u4e09\u65b9\u83b7\u53d6\u539f\u59cb\u4f20\u611f\u5668\u4fe1\u53f7\u3001\u5b66\u4e60\u7279\u5f81\u6216\u5206\u7c7b\u8f93\u51fa\u3002", "motivation": "\u5728\u9690\u853d\u548c\u5b89\u5168\u5173\u952e\u573a\u666f\u4e2d\uff0c\u5b89\u5168\u901a\u4fe1\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u4e3a\u53e3\u5934\u4ea4\u4e92\u53ef\u80fd\u66b4\u9732\u7528\u6237\u610f\u56fe\u6216\u64cd\u4f5c\u4e0a\u4e0b\u6587\u3002\u73b0\u6709\u7684\u53ef\u7a7f\u6234\u624b\u52bf\u901a\u4fe1\u7cfb\u7edf\u4f1a\u6cc4\u9732\u8fd0\u52a8\u6570\u636e\u3001\u4e2d\u95f4\u8868\u793a\u6216\u63a8\u7406\u8f93\u51fa\u7ed9\u4e0d\u53ef\u4fe1\u57fa\u7840\u8bbe\u65bd\uff0c\u5bfc\u81f4\u610f\u56fe\u63a8\u65ad\u3001\u884c\u4e3a\u751f\u7269\u7279\u5f81\u6cc4\u9732\u548c\u5185\u90e8\u653b\u51fb\u3002", "method": "\u7cfb\u7edf\u91c7\u7528\u591a\u65b9\u540c\u6001\u5b66\u4e60\u7ba1\u9053\uff0c\u76f4\u63a5\u5728\u52a0\u5bc6\u7684\u8fd0\u52a8\u6570\u636e\u4e0a\u8fdb\u884c\u624b\u52bf\u8bc6\u522b\uff0c\u9632\u6b62\u5bf9\u624b\u63a8\u65ad\u624b\u52bf\u8bed\u4e49\u3001\u91cd\u653e\u4f20\u611f\u5668\u8f68\u8ff9\u6216\u8bbf\u95ee\u4e2d\u95f4\u8868\u793a\u3002\u8bbe\u8ba1\u4e86\u89e6\u89c9\u548c\u89c6\u89c9\u53cd\u9988\u673a\u5236\u7528\u4e8e\u9690\u853d\u4fe1\u53f7\u4f20\u9012\u3002", "result": "\u4f7f\u7528\u5546\u7528\u667a\u80fd\u624b\u8868\u7684600\u4e2a\u624b\u52bf\u6837\u672c\u8fdb\u884c\u8bc4\u4f30\uff0c\u5b9e\u73b0\u4e86\u8d85\u8fc794.44%\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u8bc1\u660e\u4e86\u7cfb\u7edf\u7684\u53ef\u884c\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u4ece\u9ad8\u6027\u80fd\u7cfb\u7edf\u5230\u8d44\u6e90\u53d7\u9650\u8fb9\u7f18\u8bbe\u5907\u7684\u5b9e\u9645\u90e8\u7f72\u80fd\u529b\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5728\u53ef\u7a7f\u6234\u9690\u853d\u901a\u4fe1\u573a\u666f\u4e2d\u5e94\u7528\u52a0\u5bc6\u624b\u52bf\u8bc6\u522b\u7684\u5de5\u4f5c\uff0c\u901a\u8fc7\u540c\u6001\u52a0\u5bc6\u6280\u672f\u786e\u4fdd\u539f\u59cb\u4f20\u611f\u5668\u4fe1\u53f7\u3001\u5b66\u4e60\u7279\u5f81\u548c\u5206\u7c7b\u8f93\u51fa\u90fd\u4e0d\u4f1a\u66b4\u9732\u7ed9\u4efb\u4f55\u7b2c\u4e09\u65b9\uff0c\u5b9e\u73b0\u4e86\u9690\u79c1\u4fdd\u62a4\u7684\u9690\u853d\u901a\u4fe1\u3002"}}
{"id": "2602.07882", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.07882", "abs": "https://arxiv.org/abs/2602.07882", "authors": ["Chen Xie", "Yuling Shi", "Xiaodong Gu", "Beijun Shen"], "title": "Rethinking Code Complexity Through the Lens of Large Language Models", "comment": null, "summary": "Code complexity metrics such as cyclomatic complexity have long been used to assess software quality and maintainability. With the rapid advancement of large language models (LLMs) on code understanding and generation tasks, an important yet underexplored question arises: do these traditional complexity metrics meaningfully characterize the difficulty LLMs experience when processing code? In this work, we empirically demonstrate that, after controlling for code length, classical metrics exhibit no consistent correlation with LLM performance, revealing a fundamental mismatch with model-perceived difficulty. To address this gap, we propose LM-CC, a novel code complexity metric designed from the perspective of LLMs. The core premise of LM-CC is that LLM-perceived difficulty is driven by the nonlinearity of program semantics. Accordingly, we decompose programs into semantic units based on entropy, organize these units into a compositional hierarchy, and quantify complexity as a principled aggregation of compositional level and branching-induced divergence, capturing cumulative model uncertainty during code processing. Our extensive experiments show that LM-CC not only correlates more strongly with LLM performance than traditional metrics but also that lowering it directly enhances task performance.", "AI": {"tldr": "\u4f20\u7edf\u4ee3\u7801\u590d\u6742\u5ea6\u6307\u6807\u4e0eLLM\u5904\u7406\u4ee3\u7801\u7684\u96be\u5ea6\u4e0d\u76f8\u5173\uff0c\u4f5c\u8005\u63d0\u51fa\u57fa\u4e8eLLM\u89c6\u89d2\u7684\u65b0\u590d\u6742\u5ea6\u6307\u6807LM-CC\uff0c\u80fd\u66f4\u597d\u9884\u6d4bLLM\u6027\u80fd", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u7406\u89e3\u548c\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u4e00\u4e2a\u91cd\u8981\u4f46\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u7684\u95ee\u9898\u662f\uff1a\u4f20\u7edf\u7684\u4ee3\u7801\u590d\u6742\u5ea6\u6307\u6807\uff08\u5982\u5708\u590d\u6742\u5ea6\uff09\u662f\u5426\u80fd\u6709\u6548\u8868\u5f81LLM\u5904\u7406\u4ee3\u7801\u65f6\u9047\u5230\u7684\u56f0\u96be\uff1f\u4f5c\u8005\u53d1\u73b0\u4f20\u7edf\u6307\u6807\u4e0eLLM\u6027\u80fd\u7f3a\u4e4f\u4e00\u81f4\u76f8\u5173\u6027\uff0c\u5b58\u5728\u6839\u672c\u6027\u4e0d\u5339\u914d\u3002", "method": "\u63d0\u51faLM-CC\uff08\u8bed\u8a00\u6a21\u578b\u4ee3\u7801\u590d\u6742\u5ea6\uff09\u6307\u6807\uff0c\u5176\u6838\u5fc3\u524d\u63d0\u662fLLM\u611f\u77e5\u7684\u96be\u5ea6\u7531\u7a0b\u5e8f\u8bed\u4e49\u7684\u975e\u7ebf\u6027\u9a71\u52a8\u3002\u65b9\u6cd5\u5305\u62ec\uff1a1\uff09\u57fa\u4e8e\u71b5\u5c06\u7a0b\u5e8f\u5206\u89e3\u4e3a\u8bed\u4e49\u5355\u5143\uff1b2\uff09\u5c06\u8fd9\u4e9b\u5355\u5143\u7ec4\u7ec7\u6210\u7ec4\u5408\u5c42\u6b21\u7ed3\u6784\uff1b3\uff09\u91cf\u5316\u590d\u6742\u5ea6\u4e3a\u7ec4\u5408\u5c42\u7ea7\u548c\u5206\u652f\u8bf1\u5bfc\u7684\u53d1\u6563\u6027\u7684\u539f\u5219\u6027\u805a\u5408\uff0c\u6355\u6349\u4ee3\u7801\u5904\u7406\u8fc7\u7a0b\u4e2d\u7684\u7d2f\u79ef\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cLM-CC\u6bd4\u4f20\u7edf\u6307\u6807\u4e0eLLM\u6027\u80fd\u7684\u76f8\u5173\u6027\u66f4\u5f3a\uff0c\u5e76\u4e14\u964d\u4f4eLM-CC\u80fd\u76f4\u63a5\u63d0\u5347\u4efb\u52a1\u6027\u80fd\u3002\u4f20\u7edf\u6307\u6807\u5728\u63a7\u5236\u4ee3\u7801\u957f\u5ea6\u540e\u4e0eLLM\u6027\u80fd\u6ca1\u6709\u4e00\u81f4\u76f8\u5173\u6027\u3002", "conclusion": "\u9700\u8981\u4eceLLM\u89c6\u89d2\u91cd\u65b0\u601d\u8003\u4ee3\u7801\u590d\u6742\u5ea6\u5ea6\u91cf\uff0cLM-CC\u4f5c\u4e3a\u4e13\u95e8\u4e3aLLM\u8bbe\u8ba1\u7684\u590d\u6742\u5ea6\u6307\u6807\uff0c\u80fd\u66f4\u597d\u5730\u8868\u5f81LLM\u5904\u7406\u4ee3\u7801\u7684\u96be\u5ea6\uff0c\u5e76\u4e3a\u4f18\u5316LLM\u4ee3\u7801\u5904\u7406\u6027\u80fd\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2602.07893", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.07893", "abs": "https://arxiv.org/abs/2602.07893", "authors": ["Zhiyuan Chen", "Soham Sanjay Deo", "Poorna Chander Reddy Puttaparthi", "Vanessa Nava-Camal", "Yiming Tang", "Xueling Zhang", "Weiyi Shang"], "title": "Is Your Private Information Logged? An Empirical Study on Android App Logs", "comment": null, "summary": "With the rapid growth of mobile apps, users' concerns about their privacy have become increasingly prominent. Android app logs serve as crucial computer resources, aiding developers in debugging and monitoring the status of Android apps, while also containing a wealth of software system information. Previous studies have acknowledged privacy leaks in software logs and Android apps as significant issues without providing a comprehensive view of the privacy leaks in Android app logs. In this study, we build a comprehensive dataset of Android app logs and conduct an empirical study to analyze the status and severity of privacy leaks in Android app logs. Our study comprises three aspects: (1) Understanding real-world developers' concerns regarding privacy issues related to software logs; (2) Studying privacy leaks in the Android app logs; (3) Investigating the characteristics of privacy-leaking Android app logs and analyzing the reasons behind them. Our study reveals five different categories of concerns from real-world developers regarding privacy issues related to software logs and the prevalence of privacy leaks in Android app logs, with the majority stemming from developers' unawareness of such leaks. Additionally, our study provides developers with suggestions to safeguard their privacy from being logged.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6784\u5efa\u4e86Android\u5e94\u7528\u65e5\u5fd7\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u63ed\u793a\u4e86Android\u5e94\u7528\u65e5\u5fd7\u4e2d\u9690\u79c1\u6cc4\u9732\u7684\u73b0\u72b6\u3001\u4e25\u91cd\u7a0b\u5ea6\u53ca\u539f\u56e0\uff0c\u53d1\u73b0\u5927\u591a\u6570\u9690\u79c1\u6cc4\u9732\u6e90\u4e8e\u5f00\u53d1\u8005\u5bf9\u6b64\u95ee\u9898\u7684\u8ba4\u77e5\u4e0d\u8db3\u3002", "motivation": "\u968f\u7740\u79fb\u52a8\u5e94\u7528\u7684\u5feb\u901f\u589e\u957f\uff0c\u7528\u6237\u5bf9\u9690\u79c1\u95ee\u9898\u7684\u62c5\u5fe7\u65e5\u76ca\u7a81\u51fa\u3002Android\u5e94\u7528\u65e5\u5fd7\u4f5c\u4e3a\u91cd\u8981\u7684\u8ba1\u7b97\u673a\u8d44\u6e90\uff0c\u65e2\u5e2e\u52a9\u5f00\u53d1\u8005\u8c03\u8bd5\u548c\u76d1\u63a7\u5e94\u7528\u72b6\u6001\uff0c\u53c8\u5305\u542b\u4e30\u5bcc\u7684\u8f6f\u4ef6\u7cfb\u7edf\u4fe1\u606f\u3002\u5148\u524d\u7814\u7a76\u627f\u8ba4\u8f6f\u4ef6\u65e5\u5fd7\u548cAndroid\u5e94\u7528\u4e2d\u7684\u9690\u79c1\u6cc4\u9732\u662f\u91cd\u8981\u95ee\u9898\uff0c\u4f46\u7f3a\u4e4f\u5bf9Android\u5e94\u7528\u65e5\u5fd7\u4e2d\u9690\u79c1\u6cc4\u9732\u7684\u5168\u9762\u5206\u6790\u3002", "method": "\u7814\u7a76\u6784\u5efa\u4e86\u5168\u9762\u7684Android\u5e94\u7528\u65e5\u5fd7\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u5206\u6790Android\u5e94\u7528\u65e5\u5fd7\u4e2d\u9690\u79c1\u6cc4\u9732\u7684\u73b0\u72b6\u548c\u4e25\u91cd\u7a0b\u5ea6\u3002\u7814\u7a76\u5305\u62ec\u4e09\u4e2a\u65b9\u9762\uff1a1) \u4e86\u89e3\u771f\u5b9e\u4e16\u754c\u5f00\u53d1\u8005\u5bf9\u8f6f\u4ef6\u65e5\u5fd7\u76f8\u5173\u9690\u79c1\u95ee\u9898\u7684\u5173\u6ce8\uff1b2) \u7814\u7a76Android\u5e94\u7528\u65e5\u5fd7\u4e2d\u7684\u9690\u79c1\u6cc4\u9732\uff1b3) \u8c03\u67e5\u9690\u79c1\u6cc4\u9732\u65e5\u5fd7\u7684\u7279\u5f81\u5e76\u5206\u6790\u5176\u539f\u56e0\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u771f\u5b9e\u4e16\u754c\u5f00\u53d1\u8005\u5bf9\u8f6f\u4ef6\u65e5\u5fd7\u9690\u79c1\u95ee\u9898\u7684\u4e94\u7c7b\u4e0d\u540c\u5173\u6ce8\u70b9\uff0c\u5e76\u53d1\u73b0Android\u5e94\u7528\u65e5\u5fd7\u4e2d\u9690\u79c1\u6cc4\u9732\u666e\u904d\u5b58\u5728\u3002\u5927\u591a\u6570\u9690\u79c1\u6cc4\u9732\u6e90\u4e8e\u5f00\u53d1\u8005\u5bf9\u6b64\u7c7b\u6cc4\u9732\u7684\u65e0\u610f\u8bc6\u3002\u7814\u7a76\u8fd8\u53d1\u73b0\u9690\u79c1\u6cc4\u9732\u65e5\u5fd7\u5177\u6709\u7279\u5b9a\u7279\u5f81\u3002", "conclusion": "Android\u5e94\u7528\u65e5\u5fd7\u4e2d\u5b58\u5728\u666e\u904d\u7684\u9690\u79c1\u6cc4\u9732\u95ee\u9898\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u5f00\u53d1\u8005\u5bf9\u6b64\u7f3a\u4e4f\u8ba4\u77e5\u3002\u7814\u7a76\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u4fdd\u62a4\u9690\u79c1\u4e0d\u88ab\u8bb0\u5f55\u7684\u5efa\u8bae\uff0c\u5f3a\u8c03\u9700\u8981\u63d0\u9ad8\u5f00\u53d1\u8005\u5bf9\u65e5\u5fd7\u4e2d\u9690\u79c1\u4fdd\u62a4\u7684\u8ba4\u8bc6\u3002"}}
{"id": "2602.07470", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07470", "abs": "https://arxiv.org/abs/2602.07470", "authors": ["Alexander von Recum", "Leander Girrbach", "Zeynep Akata"], "title": "Are Reasoning LLMs Robust to Interventions on Their Chain-of-Thought?", "comment": "ICLR 2026", "summary": "Reasoning LLMs (RLLMs) generate step-by-step chains of thought (CoTs) before giving an answer, which improves performance on complex tasks and makes reasoning more transparent. But how robust are these reasoning traces to disruptions that occur within them? To address this question, we introduce a controlled evaluation framework that perturbs a model's own CoT at fixed timesteps. We design seven interventions (benign, neutral, and adversarial) and apply them to multiple open-weight RLLMs across Math, Science, and Logic tasks. Our results show that RLLMs are generally robust, reliably recovering from diverse perturbations, with robustness improving with model size and degrading when interventions occur early. However, robustness is not style-invariant: paraphrasing suppresses doubt-like expressions and reduces performance, while other interventions trigger doubt and support recovery. Recovery also carries a cost: neutral and adversarial noise can inflate CoT length by more than 200%, whereas paraphrasing shortens traces but harms accuracy. These findings provide new evidence on how RLLMs maintain reasoning integrity, identify doubt as a central recovery mechanism, and highlight trade-offs between robustness and efficiency that future training methods should address.", "AI": {"tldr": "RLLMs\u7684\u63a8\u7406\u8f68\u8ff9\u5bf9\u5185\u90e8\u5e72\u6270\u5177\u6709\u8f83\u5f3a\u9c81\u68d2\u6027\uff0c\u4f46\u9c81\u68d2\u6027\u53d7\u6a21\u578b\u5927\u5c0f\u3001\u5e72\u6270\u65f6\u673a\u548c\u5e72\u6270\u7c7b\u578b\u5f71\u54cd\uff0c\u6062\u590d\u8fc7\u7a0b\u4f1a\u663e\u8457\u589e\u52a0\u63a8\u7406\u957f\u5ea6\uff0c\u800c\u6000\u7591\u8868\u8fbe\u662f\u5173\u952e\u7684\u6062\u590d\u673a\u5236\u3002", "motivation": "\u7814\u7a76\u63a8\u7406\u5927\u8bed\u8a00\u6a21\u578b\uff08RLLMs\uff09\u7684\u63a8\u7406\u8f68\u8ff9\uff08\u601d\u7ef4\u94fe\uff09\u5728\u9762\u5bf9\u5185\u90e8\u5e72\u6270\u65f6\u7684\u9c81\u68d2\u6027\uff0c\u4e86\u89e3\u6a21\u578b\u5982\u4f55\u7ef4\u6301\u63a8\u7406\u5b8c\u6574\u6027\u4ee5\u53ca\u5e72\u6270\u5bf9\u63a8\u7406\u8fc7\u7a0b\u7684\u5f71\u54cd\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u53d7\u63a7\u8bc4\u4f30\u6846\u67b6\uff0c\u5728\u56fa\u5b9a\u65f6\u95f4\u6b65\u5bf9\u6a21\u578b\u7684\u601d\u7ef4\u94fe\u8fdb\u884c\u6270\u52a8\u3002\u8bbe\u8ba1\u4e86\u4e03\u79cd\u5e72\u9884\u63aa\u65bd\uff08\u826f\u6027\u3001\u4e2d\u6027\u548c\u5bf9\u6297\u6027\uff09\uff0c\u5e76\u5728\u6570\u5b66\u3001\u79d1\u5b66\u548c\u903b\u8f91\u4efb\u52a1\u4e2d\u5bf9\u591a\u4e2a\u5f00\u6e90RLLMs\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "RLLMs\u603b\u4f53\u4e0a\u5177\u6709\u9c81\u68d2\u6027\uff0c\u80fd\u591f\u4ece\u5404\u79cd\u6270\u52a8\u4e2d\u53ef\u9760\u6062\u590d\uff0c\u9c81\u68d2\u6027\u968f\u6a21\u578b\u89c4\u6a21\u589e\u5927\u800c\u63d0\u9ad8\uff0c\u65e9\u671f\u5e72\u9884\u4f1a\u964d\u4f4e\u9c81\u68d2\u6027\u3002\u9c81\u68d2\u6027\u53d7\u98ce\u683c\u5f71\u54cd\uff1a\u6539\u5199\u4f1a\u6291\u5236\u6000\u7591\u8868\u8fbe\u5e76\u964d\u4f4e\u6027\u80fd\uff0c\u800c\u5176\u4ed6\u5e72\u9884\u4f1a\u89e6\u53d1\u6000\u7591\u5e76\u652f\u6301\u6062\u590d\u3002\u6062\u590d\u8fc7\u7a0b\u6709\u4ee3\u4ef7\uff1a\u4e2d\u6027\u548c\u5bf9\u6297\u6027\u566a\u58f0\u53ef\u4f7f\u601d\u7ef4\u94fe\u957f\u5ea6\u589e\u52a0200%\u4ee5\u4e0a\uff0c\u800c\u6539\u5199\u4f1a\u7f29\u77ed\u8f68\u8ff9\u4f46\u635f\u5bb3\u51c6\u786e\u6027\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86RLLMs\u5982\u4f55\u7ef4\u6301\u63a8\u7406\u5b8c\u6574\u6027\uff0c\u8bc6\u522b\u6000\u7591\u4f5c\u4e3a\u6838\u5fc3\u6062\u590d\u673a\u5236\uff0c\u5e76\u5f3a\u8c03\u4e86\u9c81\u68d2\u6027\u4e0e\u6548\u7387\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u4e3a\u672a\u6765\u8bad\u7ec3\u65b9\u6cd5\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2602.08072", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08072", "abs": "https://arxiv.org/abs/2602.08072", "authors": ["Md Nafiu Rahman", "Sadif Ahmed", "Zahin Wahab", "Gias Uddin", "Rifat Shahriyar"], "title": "IssueGuard: Real-Time Secret Leak Prevention Tool for GitHub Issue Reports", "comment": null, "summary": "GitHub and GitLab are widely used collaborative platforms whose issue-tracking systems contain large volumes of unstructured text, including logs, code snippets, and configuration examples. This creates a significant risk of accidental secret exposure, such as API keys and credentials, yet these platforms provide no mechanism to warn users before submission. We present \\textsc{IssueGuard}, a tool for real-time detection and prevention of secret leaks in issue reports. Implemented as a Chrome extension, \\textsc{IssueGuard} analyzes text as users type and combines regex-based candidate extraction with a fine-tuned CodeBERT model for contextual classification. This approach effectively separates real secrets from false positives and achieves an F1-score of 92.70\\% on a benchmark dataset, outperforming traditional regex-based scanners. \\textsc{IssueGuard} integrates directly into the web interface and continuously analyzes the issue editor, presenting clear visual warnings to help users avoid submitting sensitive data. The source code is publicly available at \\href{https://github.com/nafiurahman00/IssueGuard}{https://github.com/nafiurahman00/IssueGuard}, and a demonstration video is available at \\href{https://youtu.be/kvbWA8rr9cU}{https://youtu.be/kvbWA8rr9cU}.", "AI": {"tldr": "IssueGuard\u662f\u4e00\u4e2aChrome\u6269\u5c55\u5de5\u5177\uff0c\u7528\u4e8e\u5b9e\u65f6\u68c0\u6d4b\u548c\u9632\u6b62GitHub/GitLab\u95ee\u9898\u62a5\u544a\u4e2d\u7684\u79d8\u5bc6\u6cc4\u9732\uff0c\u7ed3\u5408\u6b63\u5219\u8868\u8fbe\u5f0f\u63d0\u53d6\u548c\u5fae\u8c03CodeBERT\u6a21\u578b\u8fdb\u884c\u5206\u7c7b\uff0cF1\u5206\u6570\u8fbe92.70%", "motivation": "GitHub\u548cGitLab\u7b49\u534f\u4f5c\u5e73\u53f0\u7684issue\u8ddf\u8e2a\u7cfb\u7edf\u5305\u542b\u5927\u91cf\u975e\u7ed3\u6784\u5316\u6587\u672c\uff08\u65e5\u5fd7\u3001\u4ee3\u7801\u7247\u6bb5\u3001\u914d\u7f6e\u793a\u4f8b\uff09\uff0c\u5b58\u5728API\u5bc6\u94a5\u548c\u51ed\u8bc1\u7b49\u79d8\u5bc6\u610f\u5916\u66b4\u9732\u7684\u98ce\u9669\uff0c\u4f46\u8fd9\u4e9b\u5e73\u53f0\u6ca1\u6709\u63d0\u4f9b\u63d0\u4ea4\u524d\u7684\u8b66\u544a\u673a\u5236", "method": "\u5b9e\u73b0\u4e3aChrome\u6269\u5c55\uff0c\u5b9e\u65f6\u5206\u6790\u7528\u6237\u8f93\u5165\u6587\u672c\uff0c\u7ed3\u5408\u57fa\u4e8e\u6b63\u5219\u8868\u8fbe\u5f0f\u7684\u5019\u9009\u63d0\u53d6\u548c\u5fae\u8c03\u7684CodeBERT\u6a21\u578b\u8fdb\u884c\u4e0a\u4e0b\u6587\u5206\u7c7b\uff0c\u6709\u6548\u533a\u5206\u771f\u5b9e\u79d8\u5bc6\u548c\u8bef\u62a5", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fbe\u523092.70%\u7684F1\u5206\u6570\uff0c\u4f18\u4e8e\u4f20\u7edf\u7684\u57fa\u4e8e\u6b63\u5219\u8868\u8fbe\u5f0f\u7684\u626b\u63cf\u5668\uff0c\u5de5\u5177\u76f4\u63a5\u96c6\u6210\u5230Web\u754c\u9762\u4e2d\uff0c\u6301\u7eed\u5206\u6790\u95ee\u9898\u7f16\u8f91\u5668\u5e76\u63d0\u4f9b\u6e05\u6670\u7684\u89c6\u89c9\u8b66\u544a", "conclusion": "IssueGuard\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u548c\u9632\u6b62\u79d8\u5bc6\u6cc4\u9732\uff0c\u6e90\u4ee3\u7801\u516c\u5f00\u53ef\u7528\uff0c\u4e3aGitHub/GitLab\u7528\u6237\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u5b89\u5168\u4fdd\u62a4\u5de5\u5177"}}
{"id": "2602.07473", "categories": ["cs.AI", "cs.FL"], "pdf": "https://arxiv.org/pdf/2602.07473", "abs": "https://arxiv.org/abs/2602.07473", "authors": ["Nathana\u00ebl Fijalkow", "Arka Ghosh", "Roman Kniazev", "Guillermo A. P\u00e9rez", "Pierre Vandenhove"], "title": "Computing the Reachability Value of Posterior-Deterministic POMDPs", "comment": null, "summary": "Partially observable Markov decision processes (POMDPs) are a fundamental model for sequential decision-making under uncertainty. However, many verification and synthesis problems for POMDPs are undecidable or intractable. Most prominently, the seminal result of Madani et al. (2003) states that there is no algorithm that, given a POMDP and a set of target states, can compute the maximal probability of reaching the target states, or even approximate it up to a non-trivial constant. This is in stark contrast to fully observable Markov decision processes (MDPs), where the reachability value can be computed in polynomial time.\n  In this work, we introduce posterior-deterministic POMDPs, a novel class of POMDPs. Our main technical contribution is to show that for posterior-deterministic POMDPs, the maximal probability of reaching a given set of states can be approximated up to arbitrary precision.\n  A POMDP is posterior-deterministic if the next state can be uniquely determined by the current state, the action taken, and the observation received. While the actual state is generally uncertain in POMDPs, the posterior-deterministic property tells us that once the true state is known it remains known forever. This simple and natural definition includes all MDPs and captures classical non-trivial examples such as the Tiger POMDP (Kaelbling et al. 1998), making it one of the largest known classes of POMDPs for which the reachability value can be approximated.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684POMDP\u7c7b\u522b\u2014\u2014\u540e\u9a8c\u786e\u5b9a\u6027POMDP\uff0c\u8bc1\u660e\u4e86\u5728\u8be5\u7c7b\u522b\u4e2d\u53ef\u8fbe\u6982\u7387\u53ef\u4ee5\u8fd1\u4f3c\u8ba1\u7b97\u5230\u4efb\u610f\u7cbe\u5ea6\uff0c\u7a81\u7834\u4e86\u4f20\u7edfPOMDP\u8ba1\u7b97\u4e0d\u53ef\u884c\u7684\u9650\u5236\u3002", "motivation": "\u4f20\u7edfPOMDP\u4e2d\u7684\u9a8c\u8bc1\u548c\u7efc\u5408\u95ee\u9898\u901a\u5e38\u662f\u4e0d\u53ef\u5224\u5b9a\u6216\u96be\u4ee5\u8ba1\u7b97\u7684\uff0c\u7279\u522b\u662f\u53ef\u8fbe\u6982\u7387\u8ba1\u7b97\u95ee\u9898\uff08Madani\u7b49\uff0c2003\u8bc1\u660e\u65e0\u6cd5\u8ba1\u7b97\u6216\u8fd1\u4f3c\uff09\u3002\u8fd9\u4e0e\u5b8c\u5168\u53ef\u89c2\u6d4bMDP\u5f62\u6210\u9c9c\u660e\u5bf9\u6bd4\uff0c\u540e\u8005\u53ef\u8fbe\u503c\u53ef\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u8ba1\u7b97\u3002\u56e0\u6b64\u9700\u8981\u5bfb\u627e\u53ef\u8ba1\u7b97\u7684POMDP\u5b50\u7c7b\u3002", "method": "\u5f15\u5165\u540e\u9a8c\u786e\u5b9a\u6027POMDP\u7684\u65b0\u6982\u5ff5\uff1a\u5982\u679c\u4e0b\u4e00\u4e2a\u72b6\u6001\u53ef\u4ee5\u7531\u5f53\u524d\u72b6\u6001\u3001\u91c7\u53d6\u7684\u52a8\u4f5c\u548c\u63a5\u6536\u7684\u89c2\u6d4b\u552f\u4e00\u786e\u5b9a\uff0c\u5219\u79f0\u8be5POMDP\u4e3a\u540e\u9a8c\u786e\u5b9a\u6027\u3002\u4e00\u65e6\u771f\u5b9e\u72b6\u6001\u5df2\u77e5\uff0c\u5b83\u5c06\u6c38\u8fdc\u4fdd\u6301\u5df2\u77e5\u3002\u8be5\u65b9\u6cd5\u5305\u542b\u4e86\u6240\u6709MDP\u5e76\u6355\u83b7\u4e86\u7ecf\u5178\u7684\u975e\u5e73\u51e1\u793a\u4f8b\uff08\u5982Tiger POMDP\uff09\u3002", "result": "\u8bc1\u660e\u4e86\u5bf9\u4e8e\u540e\u9a8c\u786e\u5b9a\u6027POMDP\uff0c\u5230\u8fbe\u7ed9\u5b9a\u72b6\u6001\u96c6\u7684\u6700\u5927\u6982\u7387\u53ef\u4ee5\u8fd1\u4f3c\u5230\u4efb\u610f\u7cbe\u5ea6\u3002\u8fd9\u662f\u5df2\u77e5\u6700\u5927\u7684POMDP\u7c7b\u522b\u4e4b\u4e00\uff0c\u5176\u4e2d\u53ef\u8fbe\u503c\u53ef\u4ee5\u8fd1\u4f3c\u8ba1\u7b97\u3002", "conclusion": "\u540e\u9a8c\u786e\u5b9a\u6027POMDP\u63d0\u4f9b\u4e86\u4e00\u4e2a\u91cd\u8981\u7684\u53ef\u8ba1\u7b97POMDP\u5b50\u7c7b\uff0c\u7a81\u7834\u4e86\u4f20\u7edfPOMDP\u8ba1\u7b97\u9650\u5236\uff0c\u4e3a\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u987a\u5e8f\u51b3\u7b56\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u7528\u8ba1\u7b97\u65b9\u6cd5\u3002"}}
{"id": "2602.08165", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.08165", "abs": "https://arxiv.org/abs/2602.08165", "authors": ["Miguel Bicudo", "Estev\u00e3o Rabello", "Daniel Menasch\u00e9", "Paulo Segal", "Claudio Segal", "Anton Kocheturov", "Priyanjan Sharma"], "title": "A Transfer Learning Approach to Unveil the Role of Windows Common Configuration Enumerations in IEC 62443 Compliance", "comment": null, "summary": "Industrial control systems (ICS) depend on highly heterogeneous environments where Linux, proprietary real-time operating systems, and Windows coexist. Although the IEC 62443-3-3 standard provides a comprehensive framework for securing such systems, translating its requirements into concrete configuration checks remains challenging, especially for Windows platforms. In this paper, we propose a transfer learning methodology that maps Windows Common Configuration Enumerations (CCEs) to IEC 62443-3-3 System Security Requirements by leveraging labeled Linux datasets. The resulting labeled dataset enables automated compliance checks, analysis of requirement prevalence, and identification of cross-platform similarities and divergences. Our results highlight the role of CCEs as a bridge between abstract standards and concrete configurations, advancing automation, traceability, and clarity in IEC 62443-3-3 compliance for Windows environments.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\uff0c\u5c06Windows\u914d\u7f6e\u679a\u4e3e\u6620\u5c04\u5230IEC 62443-3-3\u5b89\u5168\u6807\u51c6\uff0c\u5229\u7528Linux\u6807\u6ce8\u6570\u636e\u96c6\u5b9e\u73b0\u8de8\u5e73\u53f0\u5408\u89c4\u68c0\u67e5", "motivation": "\u5de5\u4e1a\u63a7\u5236\u7cfb\u7edf\u73af\u5883\u9ad8\u5ea6\u5f02\u6784\uff0cLinux\u3001\u4e13\u6709\u5b9e\u65f6\u64cd\u4f5c\u7cfb\u7edf\u548cWindows\u5171\u5b58\u3002\u867d\u7136IEC 62443-3-3\u6807\u51c6\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u5b89\u5168\u6846\u67b6\uff0c\u4f46\u5c06\u5176\u8981\u6c42\u8f6c\u5316\u4e3a\u5177\u4f53\u7684\u914d\u7f6e\u68c0\u67e5\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u7279\u522b\u662f\u5bf9\u4e8eWindows\u5e73\u53f0", "method": "\u63d0\u51fa\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\uff0c\u5c06Windows\u901a\u7528\u914d\u7f6e\u679a\u4e3e\u6620\u5c04\u5230IEC 62443-3-3\u7cfb\u7edf\u5b89\u5168\u8981\u6c42\uff0c\u5229\u7528\u5df2\u6807\u6ce8\u7684Linux\u6570\u636e\u96c6\u8fdb\u884c\u77e5\u8bc6\u8fc1\u79fb", "result": "\u751f\u6210\u7684\u6807\u6ce8\u6570\u636e\u96c6\u652f\u6301\u81ea\u52a8\u5316\u5408\u89c4\u68c0\u67e5\u3001\u8981\u6c42\u6d41\u884c\u5ea6\u5206\u6790\u4ee5\u53ca\u8de8\u5e73\u53f0\u76f8\u4f3c\u6027\u548c\u5dee\u5f02\u8bc6\u522b\u3002\u7ed3\u679c\u8868\u660eCCE\u53ef\u4ee5\u4f5c\u4e3a\u62bd\u8c61\u6807\u51c6\u548c\u5177\u4f53\u914d\u7f6e\u4e4b\u95f4\u7684\u6865\u6881", "conclusion": "\u8be5\u65b9\u6cd5\u63a8\u8fdb\u4e86Windows\u73af\u5883\u4e2dIEC 62443-3-3\u5408\u89c4\u6027\u7684\u81ea\u52a8\u5316\u3001\u53ef\u8ffd\u6eaf\u6027\u548c\u6e05\u6670\u5ea6\uff0c\u4e3a\u5f02\u6784\u5de5\u4e1a\u63a7\u5236\u7cfb\u7edf\u5b89\u5168\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.08015", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08015", "abs": "https://arxiv.org/abs/2602.08015", "authors": ["Patricia G. F. Matsubara", "Tayana Conte"], "title": "Bridging the Gap: Adapting Evidence to Decision Frameworks to support the link between Software Engineering academia and industry", "comment": "Accepted for publication in ICSE 2026 - Future of Software Engineering", "summary": "Over twenty years ago, the Software Engineering (SE) research community have been involved with Evidence-Based Software Engineering (EBSE). EBSE aims to inform industrial practice with the best evidence from rigorous research, preferably from systematic literature reviews (SLRs). Since then, SE researchers have conducted many SLRs, perfected their SLR procedures, proposed alternative ways of presenting their results (such as Evidence Briefings), and profusely discussed how to conduct research that impacts practice. Nevertheless, there is still a feeling that SLRs' results are not reaching practitioners. Something is missing. In this vision paper, we introduce Evidence to Decision (EtD) frameworks from the health sciences, which propose gathering experts in panels to assess the existing best evidence about the impact of an intervention in all relevant outcomes and make structured recommendations based on them. The insight we can leverage from EtD frameworks is not their structure per se but all the relevant criteria for making recommendations to practitioners from SLRs. Furthermore, we provide a worked example based on an SE SLR. We also discuss the challenges the SE research and practice community may face when adopting EtD frameworks, highlighting the need for more comprehensive criteria in our recommendations to industry practitioners.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4ece\u5065\u5eb7\u79d1\u5b66\u9886\u57df\u5f15\u5165\u7684\"\u8bc1\u636e\u5230\u51b3\u7b56\"\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u7ed3\u679c\u96be\u4ee5\u89e6\u8fbe\u5b9e\u8df5\u8005\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u4e13\u5bb6\u5c0f\u7ec4\u8bc4\u4f30\u8bc1\u636e\u5e76\u5236\u5b9a\u7ed3\u6784\u5316\u5efa\u8bae\u3002", "motivation": "\u5c3d\u7ba1\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u793e\u533a\u5df2\u8fdb\u884c\u5927\u91cf\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u5e76\u5b8c\u5584\u4e86\u76f8\u5173\u6d41\u7a0b\uff0c\u4f46\u7814\u7a76\u7ed3\u679c\u4ecd\u96be\u4ee5\u6709\u6548\u89e6\u8fbe\u884c\u4e1a\u5b9e\u8df5\u8005\uff0c\u5b58\u5728\u7406\u8bba\u4e0e\u5b9e\u8df5\u4e4b\u95f4\u7684\u9e3f\u6c9f\u3002", "method": "\u5f15\u5165\u5065\u5eb7\u79d1\u5b66\u9886\u57df\u7684\u8bc1\u636e\u5230\u51b3\u7b56\u6846\u67b6\uff0c\u901a\u8fc7\u7ec4\u5efa\u4e13\u5bb6\u5c0f\u7ec4\u8bc4\u4f30\u73b0\u6709\u6700\u4f73\u8bc1\u636e\uff0c\u8003\u8651\u6240\u6709\u76f8\u5173\u7ed3\u679c\uff0c\u5e76\u57fa\u4e8e\u6b64\u5236\u5b9a\u7ed3\u6784\u5316\u5efa\u8bae\u3002\u8bba\u6587\u8fd8\u63d0\u4f9b\u4e86\u4e00\u4e2a\u57fa\u4e8eSE\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u7684\u5de5\u4f5c\u793a\u4f8b\u3002", "result": "\u63d0\u51fa\u4e86\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u91c7\u7528\u8bc1\u636e\u5230\u51b3\u7b56\u6846\u67b6\u7684\u53ef\u884c\u6027\u548c\u4ef7\u503c\uff0c\u5f3a\u8c03\u9700\u8981\u66f4\u5168\u9762\u7684\u6807\u51c6\u6765\u4e3a\u884c\u4e1a\u5b9e\u8df5\u8005\u5236\u5b9a\u5efa\u8bae\uff0c\u5e76\u8bc6\u522b\u4e86\u5b9e\u65bd\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u9762\u4e34\u7684\u6311\u6218\u3002", "conclusion": "\u8bc1\u636e\u5230\u51b3\u7b56\u6846\u67b6\u4e3a\u89e3\u51b3\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u4e0e\u5b9e\u8df5\u4e4b\u95f4\u7684\u9e3f\u6c9f\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\uff0c\u4f46\u9700\u8981\u7814\u7a76\u793e\u533a\u548c\u5b9e\u8df5\u793e\u533a\u5171\u540c\u5e94\u5bf9\u5b9e\u65bd\u6311\u6218\uff0c\u5b8c\u5584\u5efa\u8bae\u6807\u51c6\u3002"}}
{"id": "2602.07491", "categories": ["cs.AI", "cond-mat.mes-hall", "cond-mat.mtrl-sci", "cond-mat.soft", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07491", "abs": "https://arxiv.org/abs/2602.07491", "authors": ["Isabella A. Stewart", "Tarjei Paule Hage", "Yu-Chuan Hsu", "Markus J. Buehler"], "title": "GraphAgents: Knowledge Graph-Guided Agentic AI for Cross-Domain Materials Design", "comment": null, "summary": "Large Language Models (LLMs) promise to accelerate discovery by reasoning across the expanding scientific landscape. Yet, the challenge is no longer access to information but connecting it in meaningful, domain-spanning ways. In materials science, where innovation demands integrating concepts from molecular chemistry to mechanical performance, this is especially acute. Neither humans nor single-agent LLMs can fully contend with this torrent of information, with the latter often prone to hallucinations. To address this bottleneck, we introduce a multi-agent framework guided by large-scale knowledge graphs to find sustainable substitutes for per- and polyfluoroalkyl substances (PFAS)-chemicals currently under intense regulatory scrutiny. Agents in the framework specialize in problem decomposition, evidence retrieval, design parameter extraction, and graph traversal, uncovering latent connections across distinct knowledge pockets to support hypothesis generation. Ablation studies show that the full multi-agent pipeline outperforms single-shot prompting, underscoring the value of distributed specialization and relational reasoning. We demonstrate that by tailoring graph traversal strategies, the system alternates between exploitative searches focusing on domain-critical outcomes and exploratory searches surfacing emergent cross-connections. Illustrated through the exemplar of biomedical tubing, the framework generates sustainable PFAS-free alternatives that balance tribological performance, thermal stability, chemical resistance, and biocompatibility. This work establishes a framework combining knowledge graphs with multi-agent reasoning to expand the materials design space, showcasing several initial design candidates to demonstrate the approach.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u4e0e\u591a\u667a\u80fd\u4f53\u63a8\u7406\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5bfb\u627ePFAS\uff08\u5168\u6c1f\u548c\u591a\u6c1f\u70f7\u57fa\u7269\u8d28\uff09\u7684\u53ef\u6301\u7eed\u66ff\u4ee3\u54c1\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u4e13\u4e1a\u5316\u548c\u5173\u7cfb\u63a8\u7406\u6765\u8fde\u63a5\u8de8\u9886\u57df\u79d1\u5b66\u77e5\u8bc6\u3002", "motivation": "\u6750\u6599\u79d1\u5b66\u521b\u65b0\u9700\u8981\u6574\u5408\u4ece\u5206\u5b50\u5316\u5b66\u5230\u673a\u68b0\u6027\u80fd\u7684\u591a\u9886\u57df\u6982\u5ff5\uff0c\u4f46\u4eba\u7c7b\u6216\u5355\u667a\u80fd\u4f53\u5927\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u5904\u7406\u6d77\u91cf\u4fe1\u606f\u4e14\u5bb9\u6613\u4ea7\u751f\u5e7b\u89c9\u3002PFAS\u4f5c\u4e3a\u53d7\u76d1\u7ba1\u5316\u5b66\u54c1\u9700\u8981\u53ef\u6301\u7eed\u66ff\u4ee3\u54c1\uff0c\u8fd9\u9700\u8981\u8fde\u63a5\u4e0d\u540c\u77e5\u8bc6\u9886\u57df\u6765\u53d1\u73b0\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u89c4\u6a21\u77e5\u8bc6\u56fe\u8c31\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u542b\u4e13\u95e8\u5316\u667a\u80fd\u4f53\uff1a\u95ee\u9898\u5206\u89e3\u3001\u8bc1\u636e\u68c0\u7d22\u3001\u8bbe\u8ba1\u53c2\u6570\u63d0\u53d6\u548c\u56fe\u904d\u5386\u3002\u901a\u8fc7\u5b9a\u5236\u56fe\u904d\u5386\u7b56\u7565\uff0c\u7cfb\u7edf\u5728\u5229\u7528\u6027\u641c\u7d22\uff08\u5173\u6ce8\u9886\u57df\u5173\u952e\u7ed3\u679c\uff09\u548c\u63a2\u7d22\u6027\u641c\u7d22\uff08\u53d1\u73b0\u65b0\u5174\u8de8\u9886\u57df\u8fde\u63a5\uff09\u4e4b\u95f4\u4ea4\u66ff\u3002", "result": "\u6d88\u878d\u7814\u7a76\u8868\u660e\u5b8c\u6574\u591a\u667a\u80fd\u4f53\u6d41\u6c34\u7ebf\u4f18\u4e8e\u5355\u6b21\u63d0\u793a\uff0c\u9a8c\u8bc1\u4e86\u5206\u5e03\u5f0f\u4e13\u4e1a\u5316\u548c\u5173\u7cfb\u63a8\u7406\u7684\u4ef7\u503c\u3002\u4ee5\u751f\u7269\u533b\u5b66\u5bfc\u7ba1\u4e3a\u4f8b\uff0c\u6846\u67b6\u751f\u6210\u4e86\u5e73\u8861\u6469\u64e6\u6027\u80fd\u3001\u70ed\u7a33\u5b9a\u6027\u3001\u5316\u5b66\u6297\u6027\u548c\u751f\u7269\u76f8\u5bb9\u6027\u7684\u53ef\u6301\u7eed\u65e0PFAS\u66ff\u4ee3\u54c1\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5efa\u7acb\u4e86\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u4e0e\u591a\u667a\u80fd\u4f53\u63a8\u7406\u7684\u6846\u67b6\u6765\u6269\u5c55\u6750\u6599\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u5c55\u793a\u4e86\u591a\u4e2a\u521d\u59cb\u8bbe\u8ba1\u5019\u9009\u65b9\u6848\uff0c\u4e3a\u8de8\u9886\u57df\u79d1\u5b66\u53d1\u73b0\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2602.08084", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08084", "abs": "https://arxiv.org/abs/2602.08084", "authors": ["Mark Looi", "Marc Szepan"], "title": "Outsourcing in Global Software Development: Effects of Temporal Location and Methodologies", "comment": "Published in International Journal of Business and Social Science International Journal of Business and Social Science, Vol. 12, No. 3; March 2021, DOI: 10.30845/ijbss.v12n3p3", "summary": "Developing software globally using outsourced resources has become a common practice, with project teams often distributed in different time zones. In this study, we focus on customers that contract software development to vendors in temporally nearshore or far offshore locations. We conducted a survey to determine the effect of temporal distance on overall success, costs, project management effort, schedule, quality, communication problems, and other outcomes of interest to managers. In the survey of 80 customers and interviews with 6 of them, we also investigated the effect of software development methodology on the same outcomes. The results show that nearshore development is advantageous for overall success, quality, reduced PM effort, maintaining schedule, higher quality, and engendering fewer communication problems. Development methodology appears to only influence higher costs. We assess our findings in the context of prior GSE research and provide practical advice for customers of outsourced global software development, chief of which is to favor nearshore for communication-intensive or Agile projects.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u8fd1\u5cb8\u8f6f\u4ef6\u5f00\u53d1\u5728\u6574\u4f53\u6210\u529f\u7387\u3001\u8d28\u91cf\u3001\u9879\u76ee\u7ba1\u7406\u52aa\u529b\u3001\u8fdb\u5ea6\u63a7\u5236\u548c\u6c9f\u901a\u95ee\u9898\u65b9\u9762\u4f18\u4e8e\u8fdc\u5cb8\u5f00\u53d1\uff0c\u800c\u5f00\u53d1\u65b9\u6cd5\u4e3b\u8981\u5f71\u54cd\u6210\u672c\u3002\u5efa\u8bae\u6c9f\u901a\u5bc6\u96c6\u578b\u6216\u654f\u6377\u9879\u76ee\u4f18\u5148\u9009\u62e9\u8fd1\u5cb8\u5916\u5305\u3002", "motivation": "\u968f\u7740\u5168\u7403\u8f6f\u4ef6\u5916\u5305\u7684\u666e\u53ca\uff0c\u9879\u76ee\u56e2\u961f\u5e38\u5206\u5e03\u5728\u4e0d\u540c\u7684\u65f6\u533a\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u65f6\u95f4\u8ddd\u79bb\uff08\u8fd1\u5cb8vs\u8fdc\u5cb8\uff09\u5bf9\u8f6f\u4ef6\u5916\u5305\u9879\u76ee\u7ed3\u679c\u7684\u5f71\u54cd\uff0c\u4e3a\u7ba1\u7406\u8005\u63d0\u4f9b\u51b3\u7b56\u4f9d\u636e\u3002", "method": "\u901a\u8fc7\u8c03\u67e580\u4e2a\u5ba2\u6237\u548c6\u4e2a\u6df1\u5ea6\u8bbf\u8c08\uff0c\u7814\u7a76\u65f6\u95f4\u8ddd\u79bb\u548c\u8f6f\u4ef6\u5f00\u53d1\u65b9\u6cd5\u5bf9\u9879\u76ee\u6210\u529f\u3001\u6210\u672c\u3001\u9879\u76ee\u7ba1\u7406\u52aa\u529b\u3001\u8fdb\u5ea6\u3001\u8d28\u91cf\u3001\u6c9f\u901a\u95ee\u9898\u7b49\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "result": "\u8fd1\u5cb8\u5f00\u53d1\u5728\u6574\u4f53\u6210\u529f\u3001\u8d28\u91cf\u3001\u51cf\u5c11\u9879\u76ee\u7ba1\u7406\u52aa\u529b\u3001\u4fdd\u6301\u8fdb\u5ea6\u548c\u51cf\u5c11\u6c9f\u901a\u95ee\u9898\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002\u5f00\u53d1\u65b9\u6cd5\u4e3b\u8981\u5f71\u54cd\u6210\u672c\uff0c\u5bf9\u5176\u5b83\u7ed3\u679c\u5f71\u54cd\u8f83\u5c0f\u3002", "conclusion": "\u8fd1\u5cb8\u5916\u5305\u66f4\u9002\u5408\u6c9f\u901a\u5bc6\u96c6\u578b\u6216\u654f\u6377\u9879\u76ee\u3002\u7ba1\u7406\u8005\u5728\u9009\u62e9\u5916\u5305\u5730\u70b9\u65f6\u5e94\u4f18\u5148\u8003\u8651\u8fd1\u5cb8\u5f00\u53d1\uff0c\u7279\u522b\u662f\u5bf9\u6c9f\u901a\u8981\u6c42\u9ad8\u7684\u9879\u76ee\u7c7b\u578b\u3002"}}
{"id": "2602.08384", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.08384", "abs": "https://arxiv.org/abs/2602.08384", "authors": ["Jianyu Zhang", "Fuyuan Zhang", "Jiayi Lu", "Jilin Hu", "Xiaoyi Yin", "Long Zhang", "Feng Yang", "Yongwang Zhao"], "title": "Towards Real-World Industrial-Scale Verification: LLM-Driven Theorem Proving on seL4", "comment": null, "summary": "Formal methods (FM) are reliable but costly to apply, often requiring years of expert effort in industrial-scale projects such as seL4, especially for theorem proving. Recent advances in large language models (LLMs) have made automated theorem proving increasingly feasible. However, most prior work focuses on mathematics-oriented benchmarks such as miniF2F, with limited evaluation on real-world verification projects. The few studies that consider industrial-scale verification mostly rely on closed-source models with hundreds of billions of parameters, which cannot be locally deployed and incur substantial usage costs. In this paper, we propose AutoReal, an LLM-driven theorem proving method for real-world industrial-scale systems with support for lightweight local deployment. We evaluate AutoReal on the seL4-Isabelle verification project as a representative and challenging case study. AutoReal incorporates two key improvements: (1) chain-of-thought (CoT)-based proof training, which teaches the LLM the reasoning behind proof steps and enables step-wise explanations alongside proofs, and (2) context augmentation, which leverages proof context from the project to enhance LLM-driven proving. Based on the AutoReal methodology, we fine-tune a base model to obtain AutoReal-Prover, a compact 7B-scale prover for industrial-scale theorem proving. AutoReal-Prover achieves a 51.67% proof success rate on 660 theorems from seL4-designated Important Theories across all 10 seL4 proof categories, substantially outperforming prior attempts on seL4 (27.06%). To evaluate generalization, we further apply AutoReal-Prover to three security-related projects from the Archive of Formal Proofs (AFP), covering all 451 theorems and achieving a proof success rate of 53.88%. Overall, this work advances the application of LLM-driven theorem proving in real-world industrial-scale verification.", "AI": {"tldr": "AutoReal\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b9a\u7406\u8bc1\u660e\u65b9\u6cd5\uff0c\u4e13\u95e8\u9488\u5bf9\u5de5\u4e1a\u7ea7\u7cfb\u7edf\u9a8c\u8bc1\uff0c\u652f\u6301\u8f7b\u91cf\u7ea7\u672c\u5730\u90e8\u7f72\uff0c\u5728seL4\u9a8c\u8bc1\u9879\u76ee\u4e2d\u53d6\u5f9751.67%\u7684\u8bc1\u660e\u6210\u529f\u7387\u3002", "motivation": "\u5f62\u5f0f\u5316\u65b9\u6cd5\u867d\u7136\u53ef\u9760\u4f46\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u5927\u91cf\u4e13\u5bb6\u6295\u5165\u3002\u73b0\u6709\u57fa\u4e8eLLM\u7684\u5b9a\u7406\u8bc1\u660e\u7814\u7a76\u591a\u96c6\u4e2d\u4e8e\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5bf9\u5de5\u4e1a\u7ea7\u9a8c\u8bc1\u9879\u76ee\u8bc4\u4f30\u6709\u9650\uff0c\u4e14\u5927\u591a\u4f9d\u8d56\u65e0\u6cd5\u672c\u5730\u90e8\u7f72\u7684\u5927\u578b\u95ed\u6e90\u6a21\u578b\u3002", "method": "\u63d0\u51faAutoReal\u65b9\u6cd5\uff0c\u5305\u542b\u4e24\u4e2a\u5173\u952e\u6280\u672f\uff1a1) \u57fa\u4e8e\u601d\u7ef4\u94fe\u7684\u8bc1\u660e\u8bad\u7ec3\uff0c\u6559\u6388LLM\u8bc1\u660e\u6b65\u9aa4\u80cc\u540e\u7684\u63a8\u7406\u8fc7\u7a0b\uff1b2) \u4e0a\u4e0b\u6587\u589e\u5f3a\uff0c\u5229\u7528\u9879\u76ee\u4e2d\u7684\u8bc1\u660e\u4e0a\u4e0b\u6587\u63d0\u5347\u8bc1\u660e\u80fd\u529b\u3002\u57fa\u4e8e\u8be5\u65b9\u6cd5\u5fae\u8c03\u5f97\u52307B\u53c2\u6570\u7684AutoReal-Prover\u6a21\u578b\u3002", "result": "\u5728seL4\u9a8c\u8bc1\u9879\u76ee\u4e2d\uff0cAutoReal-Prover\u5728660\u4e2a\u91cd\u8981\u5b9a\u7406\u4e0a\u8fbe\u523051.67%\u7684\u8bc1\u660e\u6210\u529f\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u5148\u524d\u5c1d\u8bd5\u768427.06%\u3002\u5728AFP\u7684\u4e09\u4e2a\u5b89\u5168\u76f8\u5173\u9879\u76ee\u4e2d\uff0c\u5bf9451\u4e2a\u5b9a\u7406\u8fbe\u523053.88%\u7684\u8bc1\u660e\u6210\u529f\u7387\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63a8\u8fdb\u4e86\u57fa\u4e8eLLM\u7684\u5b9a\u7406\u8bc1\u660e\u5728\u771f\u5b9e\u5de5\u4e1a\u7ea7\u9a8c\u8bc1\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u672c\u5730\u90e8\u7f72\u65b9\u6848\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u6210\u672c\u548c\u90e8\u7f72\u9650\u5236\u95ee\u9898\u3002"}}
{"id": "2602.08133", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08133", "abs": "https://arxiv.org/abs/2602.08133", "authors": ["Mojtaba Mostafavi Ghahfarokhi", "Hamed Jahantigh", "Alireza Asadi", "Abbas Heydarnoori"], "title": "Integrating Code Metrics into Automated Documentation Generation for Computational Notebooks", "comment": null, "summary": "Effective code documentation is essential for collaboration, comprehension, and long-term software maintainability, yet developers often neglect it due to its repetitive nature. Automated documentation generation has evolved from heuristic and rule-based methods to neural network-based and large language model (LLM)-based approaches. However, existing methods often overlook structural and quantitative characteristics of code that influence readability and comprehension. Prior research suggests that code metrics capture information relevant to program understanding. Building on these insights, this paper investigates the role of source code metrics as auxiliary signals for automated documentation generation, focusing on computational notebooks, a popular medium among data scientists that integrates code, narrative, and results but suffers from inconsistent documentation. We propose a two-stage approach. First, the CodeSearchNet dataset construction process was refined to create a specialized dataset from over 17 million code and markdown cells. After structural and semantic filtering, approximately 36,734 high-quality (code, markdown) pairs were extracted. Second, two modeling paradigms, a lightweight CNN-RNN architecture and a few-shot GPT-3.5 architecture, were evaluated with and without metric information. Results show that incorporating code metrics improves the accuracy and contextual relevance of generated documentation, yielding gains of 6% in BLEU-1 and 3% in ROUGE-L F1 for CNN-RNN-based architecture, and 9% in BERTScore F1 for LLM-based architecture. These findings demonstrate that integrating code metrics provides valuable structural context, enhancing automated documentation generation across diverse model families.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u5c06\u6e90\u4ee3\u7801\u5ea6\u91cf\u4f5c\u4e3a\u8f85\u52a9\u4fe1\u53f7\u7528\u4e8e\u81ea\u52a8\u6587\u6863\u751f\u6210\uff0c\u7279\u522b\u662f\u5728\u8ba1\u7b97\u7b14\u8bb0\u672c\u73af\u5883\u4e2d\uff0c\u7ed3\u679c\u663e\u793a\u7ed3\u5408\u4ee3\u7801\u5ea6\u91cf\u80fd\u663e\u8457\u63d0\u5347\u6587\u6863\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u4ee3\u7801\u6587\u6863\u5bf9\u534f\u4f5c\u548c\u7406\u89e3\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5f00\u53d1\u8005\u5e38\u56e0\u91cd\u590d\u6027\u800c\u5ffd\u89c6\u3002\u73b0\u6709\u81ea\u52a8\u6587\u6863\u751f\u6210\u65b9\u6cd5\u5f80\u5f80\u5ffd\u7565\u5f71\u54cd\u53ef\u8bfb\u6027\u548c\u7406\u89e3\u5ea6\u7684\u4ee3\u7801\u7ed3\u6784\u548c\u91cf\u5316\u7279\u5f81\u3002\u4ee3\u7801\u5ea6\u91cf\u5305\u542b\u4e0e\u7a0b\u5e8f\u7406\u89e3\u76f8\u5173\u7684\u4fe1\u606f\uff0c\u53ef\u4f5c\u4e3a\u8f85\u52a9\u4fe1\u53f7\u63d0\u5347\u6587\u6863\u751f\u6210\u8d28\u91cf\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u6539\u8fdbCodeSearchNet\u6570\u636e\u96c6\u6784\u5efa\u6d41\u7a0b\uff0c\u4ece1700\u591a\u4e07\u4e2a\u4ee3\u7801\u548cmarkdown\u5355\u5143\u683c\u4e2d\u521b\u5efa\u4e13\u95e8\u6570\u636e\u96c6\uff0c\u7ecf\u8fc7\u7ed3\u6784\u548c\u8bed\u4e49\u8fc7\u6ee4\u540e\u63d0\u53d6\u7ea636,734\u4e2a\u9ad8\u8d28\u91cf(\u4ee3\u7801, markdown)\u5bf9\uff1b2) \u8bc4\u4f30\u4e24\u79cd\u5efa\u6a21\u8303\u5f0f\uff1a\u8f7b\u91cf\u7ea7CNN-RNN\u67b6\u6784\u548c\u5c11\u6837\u672cGPT-3.5\u67b6\u6784\uff0c\u5206\u522b\u5728\u6709/\u65e0\u5ea6\u91cf\u4fe1\u606f\u60c5\u51b5\u4e0b\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u7ed3\u5408\u4ee3\u7801\u5ea6\u91cf\u663e\u8457\u63d0\u9ad8\u4e86\u751f\u6210\u6587\u6863\u7684\u51c6\u786e\u6027\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\uff1aCNN-RNN\u67b6\u6784\u5728BLEU-1\u4e0a\u63d0\u53476%\uff0cROUGE-L F1\u4e0a\u63d0\u53473%\uff1bLLM\u67b6\u6784\u5728BERTScore F1\u4e0a\u63d0\u53479%\u3002\u8fd9\u8868\u660e\u4ee3\u7801\u5ea6\u91cf\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u7ed3\u6784\u4e0a\u4e0b\u6587\u3002", "conclusion": "\u96c6\u6210\u4ee3\u7801\u5ea6\u91cf\u80fd\u4e3a\u81ea\u52a8\u6587\u6863\u751f\u6210\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u7ed3\u6784\u4e0a\u4e0b\u6587\uff0c\u5728\u4e0d\u540c\u6a21\u578b\u5bb6\u65cf\u4e2d\u90fd\u80fd\u589e\u5f3a\u6587\u6863\u751f\u6210\u6548\u679c\uff0c\u7279\u522b\u662f\u5728\u8ba1\u7b97\u7b14\u8bb0\u672c\u8fd9\u79cd\u4ee3\u7801\u3001\u53d9\u8ff0\u548c\u7ed3\u679c\u96c6\u6210\u7684\u73af\u5883\u4e2d\u3002"}}
{"id": "2602.07543", "categories": ["cs.AI", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.07543", "abs": "https://arxiv.org/abs/2602.07543", "authors": ["Heewoong Noh", "Gyoung S. Na", "Namkyeong Lee", "Chanyoung Park"], "title": "MSP-LLM: A Unified Large Language Model Framework for Complete Material Synthesis Planning", "comment": null, "summary": "Material synthesis planning (MSP) remains a fundamental and underexplored bottleneck in AI-driven materials discovery, as it requires not only identifying suitable precursor materials but also designing coherent sequences of synthesis operations to realize a target material. Although several AI-based approaches have been proposed to address isolated subtasks of MSP, a unified methodology for solving the entire MSP task has yet to be established. We propose MSP-LLM, a unified LLM-based framework that formulates MSP as a structured process composed of two constituent subproblems: precursor prediction (PP) and synthesis operation prediction (SOP). Our approach introduces a discrete material class as an intermediate decision variable that organizes both tasks into a chemically consistent decision chain. For OP, we further incorporate hierarchical precursor types as synthesis-relevant inductive biases and employ an explicit conditioning strategy that preserves precursor-related information in the autoregressive decoding state. Extensive experiments show that MSP-LLM consistently outperforms existing methods on both PP and SOP, as well as on the complete MSP task, demonstrating an effective and scalable framework for MSP that can accelerate real-world materials discovery.", "AI": {"tldr": "MSP-LLM\uff1a\u4e00\u4e2a\u7edf\u4e00\u7684LLM\u6846\u67b6\uff0c\u5c06\u6750\u6599\u5408\u6210\u89c4\u5212\u5206\u89e3\u4e3a\u524d\u9a71\u4f53\u9884\u6d4b\u548c\u5408\u6210\u64cd\u4f5c\u9884\u6d4b\u4e24\u4e2a\u5b50\u95ee\u9898\uff0c\u901a\u8fc7\u5f15\u5165\u79bb\u6563\u6750\u6599\u7c7b\u522b\u4f5c\u4e3a\u4e2d\u95f4\u51b3\u7b56\u53d8\u91cf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6750\u6599\u5408\u6210\u89c4\u5212\u7684\u6027\u80fd\u3002", "motivation": "\u6750\u6599\u5408\u6210\u89c4\u5212\u662fAI\u9a71\u52a8\u6750\u6599\u53d1\u73b0\u4e2d\u7684\u5173\u952e\u74f6\u9888\uff0c\u73b0\u6709\u65b9\u6cd5\u53ea\u89e3\u51b3\u5b64\u7acb\u5b50\u4efb\u52a1\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u89e3\u51b3\u65b9\u6848\u3002\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u80fd\u591f\u540c\u65f6\u5904\u7406\u524d\u9a71\u4f53\u9009\u62e9\u548c\u5408\u6210\u64cd\u4f5c\u5e8f\u5217\u8bbe\u8ba1\u7684\u5b8c\u6574\u6846\u67b6\u3002", "method": "\u63d0\u51faMSP-LLM\u6846\u67b6\uff0c\u5c06\u6750\u6599\u5408\u6210\u89c4\u5212\u5206\u89e3\u4e3a\u4e24\u4e2a\u5b50\u95ee\u9898\uff1a\u524d\u9a71\u4f53\u9884\u6d4b\u548c\u5408\u6210\u64cd\u4f5c\u9884\u6d4b\u3002\u5f15\u5165\u79bb\u6563\u6750\u6599\u7c7b\u522b\u4f5c\u4e3a\u4e2d\u95f4\u51b3\u7b56\u53d8\u91cf\uff0c\u5c06\u4e24\u4e2a\u4efb\u52a1\u7ec4\u7ec7\u6210\u5316\u5b66\u4e00\u81f4\u7684\u51b3\u7b56\u94fe\u3002\u5728\u5408\u6210\u64cd\u4f5c\u9884\u6d4b\u4e2d\uff0c\u91c7\u7528\u5206\u5c42\u524d\u9a71\u4f53\u7c7b\u578b\u4f5c\u4e3a\u5f52\u7eb3\u504f\u7f6e\uff0c\u5e76\u4f7f\u7528\u663e\u5f0f\u6761\u4ef6\u7b56\u7565\u5728\u81ea\u56de\u5f52\u89e3\u7801\u72b6\u6001\u4e2d\u4fdd\u7559\u524d\u9a71\u4f53\u76f8\u5173\u4fe1\u606f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMSP-LLM\u5728\u524d\u9a71\u4f53\u9884\u6d4b\u3001\u5408\u6210\u64cd\u4f5c\u9884\u6d4b\u4ee5\u53ca\u5b8c\u6574\u7684\u6750\u6599\u5408\u6210\u89c4\u5212\u4efb\u52a1\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u8be5\u6846\u67b6\u5728\u6750\u6599\u53d1\u73b0\u4e2d\u7684\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "MSP-LLM\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u4e14\u53ef\u6269\u5c55\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u80fd\u591f\u89e3\u51b3\u5b8c\u6574\u7684\u6750\u6599\u5408\u6210\u89c4\u5212\u4efb\u52a1\uff0c\u6709\u671b\u52a0\u901f\u5b9e\u9645\u6750\u6599\u53d1\u73b0\u8fc7\u7a0b\u3002"}}
{"id": "2602.08422", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08422", "abs": "https://arxiv.org/abs/2602.08422", "authors": ["Benjamin Livshits"], "title": "LLMs + Security = Trouble", "comment": null, "summary": "We argue that when it comes to producing secure code with AI, the prevailing \"fighting fire with fire\" approach -- using probabilistic AI-based checkers or attackers to secure probabilistically generated code -- fails to address the long tail of security bugs. As a result, systems may remain exposed to zero-day vulnerabilities that can be discovered by better-resourced or more persistent adversaries.\n  While neurosymbolic approaches that combine LLMs with formal methods are attractive in principle, we argue that they are difficult to reconcile with the \"vibe coding\" workflow common in LLM-assisted development: unless the end-to-end verification pipeline is fully automated, developers are repeatedly asked to validate specifications, resolve ambiguities, and adjudicate failures, making the human-in-the-loop a likely point of weakness, compromising secure-by-construction guarantees.\n  In this paper we argue that stronger security guarantees can be obtained by enforcing security constraints during code generation (e.g., via constrained decoding), rather than relying solely on post-hoc detection and repair. This direction is particularly promising for diffusion-style code models, whose approach provides a natural elegant opportunity for modular, hierarchical security enforcement, allowing us to combine lower-latency generation techniques with generating secure-by-construction code.", "AI": {"tldr": "\u8bba\u6587\u6279\u8bc4\u5f53\u524dAI\u751f\u6210\u4ee3\u7801\u7684\u5b89\u5168\u65b9\u6cd5\u5b58\u5728\u7f3a\u9677\uff0c\u63d0\u51fa\u901a\u8fc7\u7ea6\u675f\u89e3\u7801\u5728\u4ee3\u7801\u751f\u6210\u8fc7\u7a0b\u4e2d\u76f4\u63a5\u5f3a\u5236\u6267\u884c\u5b89\u5168\u7ea6\u675f\uff0c\u800c\u975e\u4f9d\u8d56\u540e\u9a8c\u68c0\u6d4b\u4fee\u590d", "motivation": "\u5f53\u524dAI\u751f\u6210\u4ee3\u7801\u7684\u5b89\u5168\u4fdd\u969c\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u4f7f\u7528\u6982\u7387\u6027AI\u68c0\u67e5\u5668\u6216\u653b\u51fb\u8005\u6765\u4fdd\u62a4\u6982\u7387\u751f\u6210\u7684\u4ee3\u7801\u65e0\u6cd5\u89e3\u51b3\u5b89\u5168\u6f0f\u6d1e\u7684\u957f\u5c3e\u95ee\u9898\uff1b2\uff09\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u867d\u7136\u7406\u8bba\u4e0a\u5438\u5f15\u4eba\uff0c\u4f46\u5728\u5b9e\u9645LLM\u8f85\u52a9\u5f00\u53d1\u5de5\u4f5c\u6d41\u4e2d\u96be\u4ee5\u5b9e\u65bd\uff0c\u9700\u8981\u4eba\u5de5\u4ecb\u5165\u9a8c\u8bc1\u89c4\u8303\u3001\u89e3\u51b3\u6b67\u4e49\u548c\u88c1\u51b3\u5931\u8d25\uff0c\u7834\u574f\u4e86\u5b89\u5168\u6784\u5efa\u7684\u4fdd\u8bc1", "method": "\u63d0\u51fa\u5728\u4ee3\u7801\u751f\u6210\u8fc7\u7a0b\u4e2d\u76f4\u63a5\u5f3a\u5236\u6267\u884c\u5b89\u5168\u7ea6\u675f\uff08\u5982\u901a\u8fc7\u7ea6\u675f\u89e3\u7801\uff09\uff0c\u7279\u522b\u662f\u9488\u5bf9\u6269\u6563\u5f0f\u4ee3\u7801\u6a21\u578b\uff0c\u5229\u7528\u5176\u6a21\u5757\u5316\u3001\u5c42\u6b21\u5316\u7684\u65b9\u6cd5\u5b9e\u73b0\u5b89\u5168\u7ea6\u675f\uff0c\u7ed3\u5408\u4f4e\u5ef6\u8fdf\u751f\u6210\u6280\u672f\u751f\u6210\u5b89\u5168\u6784\u5efa\u7684\u4ee3\u7801", "result": "\u8bba\u6587\u8bba\u8bc1\u4e86\u5728\u4ee3\u7801\u751f\u6210\u8fc7\u7a0b\u4e2d\u5f3a\u5236\u6267\u884c\u5b89\u5168\u7ea6\u675f\u7684\u65b9\u6cd5\u80fd\u591f\u63d0\u4f9b\u66f4\u5f3a\u7684\u5b89\u5168\u4fdd\u969c\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u6269\u6563\u5f0f\u4ee3\u7801\u6a21\u578b\uff0c\u8fd9\u79cd\u65b9\u6cd5\u63d0\u4f9b\u4e86\u6a21\u5757\u5316\u3001\u5c42\u6b21\u5316\u5b89\u5168\u6267\u884c\u7684\u4f18\u96c5\u673a\u4f1a", "conclusion": "\u76f8\u6bd4\u540e\u9a8c\u68c0\u6d4b\u548c\u4fee\u590d\uff0c\u5728\u4ee3\u7801\u751f\u6210\u8fc7\u7a0b\u4e2d\u76f4\u63a5\u5f3a\u5236\u6267\u884c\u5b89\u5168\u7ea6\u675f\u662f\u66f4\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u80fd\u591f\u4e3aAI\u751f\u6210\u7684\u4ee3\u7801\u63d0\u4f9b\u66f4\u5f3a\u7684\u5b89\u5168\u4fdd\u969c\uff0c\u7279\u522b\u662f\u5728\u6269\u6563\u5f0f\u4ee3\u7801\u6a21\u578b\u7684\u6846\u67b6\u4e0b"}}
{"id": "2602.08668", "categories": ["cs.CR", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08668", "abs": "https://arxiv.org/abs/2602.08668", "authors": ["Scott Thornton"], "title": "Retrieval Pivot Attacks in Hybrid RAG: Measuring and Mitigating Amplified Leakage from Vector Seeds to Graph Expansion", "comment": "18 pages, 5 figures", "summary": "Hybrid Retrieval-Augmented Generation (RAG) pipelines combine vector similarity search with knowledge graph expansion for multi-hop reasoning. We show that this composition introduces a distinct security failure mode: a vector-retrieved \"seed\" chunk can pivot via entity links into sensitive graph neighborhoods, causing cross-tenant data leakage that does not occur in vector-only retrieval. We formalize this risk as Retrieval Pivot Risk (RPR) and introduce companion metrics Leakage@k, Amplification Factor, and Pivot Depth (PD) to quantify leakage magnitude and traversal structure.\n  We present seven Retrieval Pivot Attacks that exploit the vector-to-graph boundary and show that adversarial injection is not required: naturally shared entities create cross-tenant pivot paths organically. Across a synthetic multi-tenant enterprise corpus and the Enron email corpus, the undefended hybrid pipeline exhibits high pivot risk (RPR up to 0.95) with multiple unauthorized items returned per query. Leakage consistently appears at PD=2, which we attribute to the bipartite chunk-entity topology and formalize as a proposition.\n  We then show that enforcing authorization at a single location, the graph expansion boundary, eliminates measured leakage (RPR near 0) across both corpora, all attack variants, and label forgery rates up to 10 percent, with minimal overhead. Our results indicate the root cause is boundary enforcement, not inherently complex defenses: two individually secure retrieval components can compose into an insecure system unless authorization is re-checked at the transition point.", "AI": {"tldr": "\u6df7\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7ba1\u9053\u7ed3\u5408\u5411\u91cf\u76f8\u4f3c\u6027\u641c\u7d22\u4e0e\u77e5\u8bc6\u56fe\u8c31\u6269\u5c55\u8fdb\u884c\u591a\u8df3\u63a8\u7406\uff0c\u4f46\u8fd9\u79cd\u7ec4\u5408\u5f15\u5165\u4e86\u65b0\u7684\u5b89\u5168\u6f0f\u6d1e\uff1a\u5411\u91cf\u68c0\u7d22\u7684\"\u79cd\u5b50\"\u5757\u53ef\u4ee5\u901a\u8fc7\u5b9e\u4f53\u94fe\u63a5\u8bbf\u95ee\u654f\u611f\u56fe\u8c31\u533a\u57df\uff0c\u5bfc\u81f4\u8de8\u79df\u6237\u6570\u636e\u6cc4\u9732\u3002", "motivation": "\u7814\u7a76\u6df7\u5408RAG\u7ba1\u9053\u4e2d\u5411\u91cf\u68c0\u7d22\u4e0e\u77e5\u8bc6\u56fe\u8c31\u6269\u5c55\u7ec4\u5408\u5e26\u6765\u7684\u72ec\u7279\u5b89\u5168\u98ce\u9669\uff0c\u8fd9\u79cd\u98ce\u9669\u5728\u7eaf\u5411\u91cf\u68c0\u7d22\u4e2d\u4e0d\u5b58\u5728\u3002\u9700\u8981\u5f62\u5f0f\u5316\u8fd9\u79cd\u98ce\u9669\u5e76\u5f00\u53d1\u91cf\u5316\u6307\u6807\u3002", "method": "\u63d0\u51fa\u68c0\u7d22\u67a2\u8f74\u98ce\u9669(RPR)\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u5f15\u5165Leakage@k\u3001\u653e\u5927\u56e0\u5b50\u548c\u67a2\u8f74\u6df1\u5ea6(PD)\u7b49\u91cf\u5316\u6307\u6807\u3002\u8bbe\u8ba1\u4e86\u4e03\u79cd\u68c0\u7d22\u67a2\u8f74\u653b\u51fb\uff0c\u5e76\u5728\u5408\u6210\u591a\u79df\u6237\u4f01\u4e1a\u8bed\u6599\u5e93\u548cEnron\u90ae\u4ef6\u8bed\u6599\u5e93\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u672a\u9632\u5fa1\u7684\u6df7\u5408\u7ba1\u9053\u8868\u73b0\u51fa\u9ad8\u67a2\u8f74\u98ce\u9669(RPR\u9ad8\u8fbe0.95)\uff0c\u6bcf\u4e2a\u67e5\u8be2\u8fd4\u56de\u591a\u4e2a\u672a\u6388\u6743\u9879\u76ee\u3002\u6cc4\u9732\u901a\u5e38\u51fa\u73b0\u5728PD=2\u5904\u3002\u5728\u56fe\u5f62\u6269\u5c55\u8fb9\u754c\u5b9e\u65bd\u6388\u6743\u540e\uff0c\u6cc4\u9732\u57fa\u672c\u6d88\u9664(RPR\u63a5\u8fd10)\uff0c\u4e14\u5f00\u9500\u6700\u5c0f\u3002", "conclusion": "\u6df7\u5408RAG\u7cfb\u7edf\u7684\u5b89\u5168\u6f0f\u6d1e\u6e90\u4e8e\u8fb9\u754c\u6388\u6743\u7f3a\u5931\u800c\u975e\u7ec4\u4ef6\u672c\u8eab\u3002\u4e24\u4e2a\u5355\u72ec\u5b89\u5168\u7684\u68c0\u7d22\u7ec4\u4ef6\u7ec4\u5408\u53ef\u80fd\u5f62\u6210\u4e0d\u5b89\u5168\u7cfb\u7edf\uff0c\u5fc5\u987b\u5728\u8f6c\u6362\u70b9\u91cd\u65b0\u68c0\u67e5\u6388\u6743\u3002\u5728\u56fe\u5f62\u6269\u5c55\u8fb9\u754c\u5b9e\u65bd\u7b80\u5355\u6388\u6743\u5373\u53ef\u6709\u6548\u6d88\u9664\u6cc4\u9732\u98ce\u9669\u3002"}}
{"id": "2602.08166", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08166", "abs": "https://arxiv.org/abs/2602.08166", "authors": ["Oscar Manglaras", "Alex Farkas", "Thomas Woolford", "Christoph Treude", "Markus Wagner"], "title": "Distributed Architecture Reconstruction of Polyglot and Multi-Repository Microservice Projects", "comment": null, "summary": "Microservice architectures encourage the use of small, independently developed services; however, this can lead to increased architectural complexity. Accurate documentation is crucial, but is challenging to maintain due to the rapid, independent evolution of services. While static architecture reconstruction provides a way to maintain up-to-date documentation, existing approaches suffer from technology limitations, mono-repo constraints, or high implementation barriers. This paper presents a novel framework for static architecture reconstruction that supports technology-specific analysis modules, called \\emph{extractors}, and supports \\emph{distributed architecture reconstruction} in multi-repo environments. We describe the core design concepts and algorithms that govern how extractors are executed, how data is passed between them, and how their outputs are unified. Furthermore, the framework is interoperable with existing static analysis tools and algorithms, allowing them to be invoked from or embedded within extractors.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u652f\u6301\u6280\u672f\u7279\u5b9a\u5206\u6790\u6a21\u5757\u548c\u5206\u5e03\u5f0f\u67b6\u6784\u91cd\u5efa\u7684\u9759\u6001\u67b6\u6784\u91cd\u5efa\u6846\u67b6\uff0c\u89e3\u51b3\u5fae\u670d\u52a1\u67b6\u6784\u6587\u6863\u7ef4\u62a4\u96be\u9898\u3002", "motivation": "\u5fae\u670d\u52a1\u67b6\u6784\u867d\u7136\u9f13\u52b1\u5c0f\u578b\u72ec\u7acb\u670d\u52a1\u5f00\u53d1\uff0c\u4f46\u589e\u52a0\u4e86\u67b6\u6784\u590d\u6742\u6027\u3002\u51c6\u786e\u6587\u6863\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u670d\u52a1\u5feb\u901f\u72ec\u7acb\u6f14\u8fdb\u800c\u96be\u4ee5\u7ef4\u62a4\u3002\u73b0\u6709\u9759\u6001\u67b6\u6784\u91cd\u5efa\u65b9\u6cd5\u5b58\u5728\u6280\u672f\u9650\u5236\u3001\u5355\u4ed3\u5e93\u7ea6\u675f\u6216\u9ad8\u5b9e\u73b0\u95e8\u69db\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u65b0\u9896\u7684\u9759\u6001\u67b6\u6784\u91cd\u5efa\u6846\u67b6\uff0c\u652f\u6301\u6280\u672f\u7279\u5b9a\u5206\u6790\u6a21\u5757\uff08\u63d0\u53d6\u5668\uff09\uff0c\u652f\u6301\u591a\u4ed3\u5e93\u73af\u5883\u4e2d\u7684\u5206\u5e03\u5f0f\u67b6\u6784\u91cd\u5efa\u3002\u63cf\u8ff0\u6838\u5fc3\u8bbe\u8ba1\u6982\u5ff5\u548c\u7b97\u6cd5\uff0c\u5305\u62ec\u63d0\u53d6\u5668\u6267\u884c\u65b9\u5f0f\u3001\u6570\u636e\u4f20\u9012\u673a\u5236\u548c\u8f93\u51fa\u7edf\u4e00\u65b9\u6cd5\u3002\u6846\u67b6\u4e0e\u73b0\u6709\u9759\u6001\u5206\u6790\u5de5\u5177\u548c\u7b97\u6cd5\u4e92\u64cd\u4f5c\uff0c\u53ef\u4ece\u63d0\u53d6\u5668\u5185\u8c03\u7528\u6216\u5d4c\u5165\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u6846\u67b6\u8bbe\u8ba1\uff0c\u4f46\u6ca1\u6709\u63d0\u4f9b\u5177\u4f53\u7684\u5b9e\u9a8c\u7ed3\u679c\u6216\u8bc4\u4f30\u6570\u636e\u3002", "conclusion": "\u8be5\u6846\u67b6\u89e3\u51b3\u4e86\u5fae\u670d\u52a1\u67b6\u6784\u6587\u6863\u7ef4\u62a4\u7684\u6311\u6218\uff0c\u901a\u8fc7\u652f\u6301\u6280\u672f\u7279\u5b9a\u5206\u6790\u6a21\u5757\u548c\u5206\u5e03\u5f0f\u67b6\u6784\u91cd\u5efa\uff0c\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u4e0e\u73b0\u6709\u5de5\u5177\u4fdd\u6301\u4e92\u64cd\u4f5c\u6027\u3002"}}
{"id": "2602.07559", "categories": ["cs.AI", "cs.CC", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.07559", "abs": "https://arxiv.org/abs/2602.07559", "authors": ["Kaleem Ullah Qasim", "Jiashu Zhang", "Hao Li", "Muhammad Kafeel Shaheen"], "title": "VERIFY-RL: Verifiable Recursive Decomposition for Reinforcement Learning in Mathematical Reasoning", "comment": "13 pages", "summary": "Training language models to solve complex mathematical problems benefits from curriculum learning progressively training on simpler subproblems. However, existing decomposition methods are often heuristic, offering no guarantees that subproblems are simpler, that solving them aids the parent task, or that their relationships are mathematically grounded. We observe that symbolic differentiation provides a natural structure for verified decomposition: calculus rules explicitly define how expressions reduce to simpler components with provable properties. We introduce Verify-RL, a framework where every parent-child decomposition satisfies three verifiable conditions: strictly decreasing structural complexity, solution containment, and formal rule derivation. Unlike heuristic methods where a significant fraction of decompositions are invalid our properties admit automatic verification through symbolic computation, achieving \"verification by construction\" Experiments demonstrate that eliminating invalid decompositions yields sizable gains, accuracy on the hardest problems more than doubles from 32% to 68%, with a 40% relative improvement overall.", "AI": {"tldr": "Verify-RL\u6846\u67b6\u901a\u8fc7\u7b26\u53f7\u5fae\u5206\u5b9e\u73b0\u53ef\u9a8c\u8bc1\u7684\u6570\u5b66\u95ee\u9898\u5206\u89e3\uff0c\u786e\u4fdd\u5b50\u95ee\u9898\u66f4\u7b80\u5355\u3001\u89e3\u51b3\u5b50\u95ee\u9898\u6709\u52a9\u4e8e\u7236\u4efb\u52a1\uff0c\u4e14\u5206\u89e3\u5173\u7cfb\u6709\u6570\u5b66\u57fa\u7840\uff0c\u76f8\u6bd4\u542f\u53d1\u5f0f\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6570\u5b66\u95ee\u9898\u5206\u89e3\u65b9\u6cd5\u901a\u5e38\u662f\u542f\u53d1\u5f0f\u7684\uff0c\u65e0\u6cd5\u4fdd\u8bc1\u5b50\u95ee\u9898\u66f4\u7b80\u5355\u3001\u89e3\u51b3\u5b50\u95ee\u9898\u6709\u52a9\u4e8e\u7236\u4efb\u52a1\uff0c\u4e14\u5206\u89e3\u5173\u7cfb\u7f3a\u4e4f\u6570\u5b66\u57fa\u7840\u3002\u9700\u8981\u4e00\u79cd\u53ef\u9a8c\u8bc1\u7684\u5206\u89e3\u6846\u67b6\u3002", "method": "\u63d0\u51faVerify-RL\u6846\u67b6\uff0c\u5229\u7528\u7b26\u53f7\u5fae\u5206\u63d0\u4f9b\u81ea\u7136\u7684\u53ef\u9a8c\u8bc1\u5206\u89e3\u7ed3\u6784\uff1a\u5fae\u79ef\u5206\u89c4\u5219\u660e\u786e\u5b9a\u4e49\u8868\u8fbe\u5f0f\u5982\u4f55\u7b80\u5316\u4e3a\u66f4\u7b80\u5355\u7684\u7ec4\u4ef6\uff0c\u5e76\u5177\u6709\u53ef\u8bc1\u660e\u7684\u6027\u8d28\u3002\u6bcf\u4e2a\u7236-\u5b50\u5206\u89e3\u6ee1\u8db3\u4e09\u4e2a\u53ef\u9a8c\u8bc1\u6761\u4ef6\uff1a\u4e25\u683c\u9012\u51cf\u7684\u7ed3\u6784\u590d\u6742\u6027\u3001\u89e3\u5305\u542b\u6027\u548c\u5f62\u5f0f\u89c4\u5219\u63a8\u5bfc\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6d88\u9664\u65e0\u6548\u5206\u89e3\u5e26\u6765\u663e\u8457\u6536\u76ca\uff1a\u6700\u96be\u95ee\u9898\u7684\u51c6\u786e\u7387\u4ece32%\u7ffb\u500d\u81f368%\uff0c\u6574\u4f53\u76f8\u5bf9\u6539\u8fdb40%\u3002\u4e0e\u542f\u53d1\u5f0f\u65b9\u6cd5\u76f8\u6bd4\uff0cVerify-RL\u5b9e\u73b0\u4e86\"\u6784\u9020\u5373\u9a8c\u8bc1\"\u3002", "conclusion": "\u7b26\u53f7\u5fae\u5206\u4e3a\u6570\u5b66\u95ee\u9898\u5206\u89e3\u63d0\u4f9b\u4e86\u53ef\u9a8c\u8bc1\u7684\u7ed3\u6784\u57fa\u7840\uff0cVerify-RL\u6846\u67b6\u901a\u8fc7\u786e\u4fdd\u5206\u89e3\u6ee1\u8db3\u4e25\u683c\u7684\u53ef\u9a8c\u8bc1\u6761\u4ef6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bed\u8a00\u6a21\u578b\u89e3\u51b3\u590d\u6742\u6570\u5b66\u95ee\u9898\u7684\u80fd\u529b\u3002"}}
{"id": "2602.08741", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.08741", "abs": "https://arxiv.org/abs/2602.08741", "authors": ["Jona te Lintelo", "Lichao Wu", "Stjepan Picek"], "title": "Large Language Lobotomy: Jailbreaking Mixture-of-Experts via Expert Silencing", "comment": null, "summary": "The rapid adoption of Mixture-of-Experts (MoE) architectures marks a major shift in the deployment of Large Language Models (LLMs). MoE LLMs improve scaling efficiency by activating only a small subset of parameters per token, but their routing structure introduces new safety attack surfaces. We find that safety-critical behaviors in MoE LLMs (e.g., refusal) are concentrated in a small set of experts rather than being uniformly distributed. Building on this, we propose Large Language Lobotomy (L$^3$), a training-free, architecture-agnostic attack that compromises safety alignment by exploiting expert routing dynamics. L$^3$ learns routing patterns that correlate with refusal, attributes safety behavior to specific experts, and adaptively silences the most safety-relevant experts until harmful outputs are produced. We evaluate L$^3$ on eight state-of-the-art open-source MoE LLMs and show that our adaptive expert silencing increases average attack success from 7.3% to 70.4%, reaching up to 86.3%, outperforming prior training-free MoE jailbreak methods. Moreover, bypassing guardrails typically requires silencing fewer than 20% of layer-wise experts while largely preserving general language utility. These results reveal a fundamental tension between efficiency-driven MoE design and robust safety alignment and motivate distributing safety mechanisms more robustly in future MoE LLMs with architecture- and routing-aware methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLarge Language Lobotomy (L\u00b3)\u7684\u8bad\u7ec3\u65e0\u5173\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790MoE\u67b6\u6784\u4e2d\u4e13\u5bb6\u8def\u7531\u52a8\u6001\uff0c\u8bc6\u522b\u5e76\u6c89\u9ed8\u4e0e\u5b89\u5168\u62d2\u7edd\u884c\u4e3a\u76f8\u5173\u7684\u4e13\u5bb6\uff0c\u4ece\u800c\u7ed5\u8fc7MoE\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u5bf9\u9f50\u673a\u5236\u3002", "motivation": "MoE\u67b6\u6784\u901a\u8fc7\u4ec5\u6fc0\u6d3b\u6bcf\u4e2atoken\u7684\u90e8\u5206\u53c2\u6570\u6765\u63d0\u9ad8\u6269\u5c55\u6548\u7387\uff0c\u4f46\u5176\u8def\u7531\u7ed3\u6784\u5f15\u5165\u4e86\u65b0\u7684\u5b89\u5168\u653b\u51fb\u9762\u3002\u7814\u7a76\u53d1\u73b0MoE LLMs\u4e2d\u7684\u5b89\u5168\u5173\u952e\u884c\u4e3a\uff08\u5982\u62d2\u7edd\uff09\u96c6\u4e2d\u5728\u5c11\u6570\u4e13\u5bb6\u4e2d\u800c\u975e\u5747\u5300\u5206\u5e03\uff0c\u8fd9\u66b4\u9732\u4e86MoE\u8bbe\u8ba1\u4e0e\u9c81\u68d2\u5b89\u5168\u5bf9\u9f50\u4e4b\u95f4\u7684\u57fa\u672c\u77db\u76fe\u3002", "method": "\u63d0\u51faL\u00b3\u653b\u51fb\u65b9\u6cd5\uff1a1\uff09\u5b66\u4e60\u4e0e\u62d2\u7edd\u884c\u4e3a\u76f8\u5173\u7684\u8def\u7531\u6a21\u5f0f\uff1b2\uff09\u5c06\u5b89\u5168\u884c\u4e3a\u5f52\u56e0\u4e8e\u7279\u5b9a\u4e13\u5bb6\uff1b3\uff09\u81ea\u9002\u5e94\u5730\u6c89\u9ed8\u6700\u76f8\u5173\u7684\u5b89\u5168\u4e13\u5bb6\u76f4\u5230\u4ea7\u751f\u6709\u5bb3\u8f93\u51fa\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u8bad\u7ec3\uff0c\u4e0e\u67b6\u6784\u65e0\u5173\u3002", "result": "\u57288\u4e2a\u6700\u5148\u8fdb\u7684\u5f00\u6e90MoE LLMs\u4e0a\u8bc4\u4f30\uff0c\u81ea\u9002\u5e94\u4e13\u5bb6\u6c89\u9ed8\u5c06\u5e73\u5747\u653b\u51fb\u6210\u529f\u7387\u4ece7.3%\u63d0\u5347\u81f370.4%\uff0c\u6700\u9ad8\u8fbe86.3%\uff0c\u4f18\u4e8e\u73b0\u6709\u8bad\u7ec3\u65e0\u5173\u7684MoE\u8d8a\u72f1\u65b9\u6cd5\u3002\u901a\u5e38\u53ea\u9700\u6c89\u9ed8\u5c11\u4e8e20%\u7684\u5c42\u7ea7\u4e13\u5bb6\u5373\u53ef\u7ed5\u8fc7\u9632\u62a4\uff0c\u540c\u65f6\u57fa\u672c\u4fdd\u7559\u901a\u7528\u8bed\u8a00\u80fd\u529b\u3002", "conclusion": "MoE\u67b6\u6784\u7684\u6548\u7387\u9a71\u52a8\u8bbe\u8ba1\u4e0e\u9c81\u68d2\u5b89\u5168\u5bf9\u9f50\u5b58\u5728\u6839\u672c\u6027\u51b2\u7a81\u3002\u672a\u6765MoE LLMs\u9700\u8981\u901a\u8fc7\u67b6\u6784\u611f\u77e5\u548c\u8def\u7531\u611f\u77e5\u7684\u65b9\u6cd5\u66f4\u7a33\u5065\u5730\u5206\u5e03\u5b89\u5168\u673a\u5236\u3002"}}
{"id": "2602.08181", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08181", "abs": "https://arxiv.org/abs/2602.08181", "authors": ["Oscar Manglaras", "Alex Farkas", "Thomas Woolford", "Christoph Treude", "Markus Wagner"], "title": "ModARO: A Modular Approach to Architecture Reconstruction of Distributed Microservice Codebases", "comment": null, "summary": "Microservice architectures promote small, independently developed services, but increase overall architectural complexity. It is crucial that developers understand the architecture and how changes to a service affect the overall system, but rapid and independent development of services increases the risk of architectural drift and discourages the creation and maintenance of documentation. Automatic architecture reconstruction can help avoid these issues, but it is difficult to reuse reconstruction code across multiple projects, as all use different combinations of technologies and project-specific conventions. Reconstruction of architecture-level details is further complicated by the tendency to split microservices into separate repositories, preventing a full view of the system from any one codebase. In this paper, we present and evaluate ModARO, an approach to microservice architecture reconstruction that allows writing modular reconstruction code ('extractors') for any technologies and reusing them across different projects, independent of the surrounding technology stack or whether or not the services are split into multiple codebases. We demonstrate the effectiveness of our approach by configuring ModARO to reconstruct 10 open source projects, and we validate the usefulness and usability of ModARO against a state-of-the-art baseline in a user study with 8 industry practitioners. Using this approach, developers can assemble or create extractors tailored to their technology stacks and distribute architecture reconstruction across repositories, enabling integration into repository CI/CD pipelines.", "AI": {"tldr": "ModARO\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u7684\u5fae\u670d\u52a1\u67b6\u6784\u91cd\u6784\u65b9\u6cd5\uff0c\u5141\u8bb8\u4e3a\u4e0d\u540c\u6280\u672f\u6808\u7f16\u5199\u53ef\u590d\u7528\u7684\u63d0\u53d6\u5668\uff0c\u89e3\u51b3\u8de8\u9879\u76ee\u6280\u672f\u5dee\u5f02\u548c\u4ee3\u7801\u5e93\u5206\u6563\u7684\u95ee\u9898\u3002", "motivation": "\u5fae\u670d\u52a1\u67b6\u6784\u589e\u52a0\u4e86\u7cfb\u7edf\u590d\u6742\u6027\uff0c\u4f46\u5feb\u901f\u72ec\u7acb\u7684\u5f00\u53d1\u5bb9\u6613\u5bfc\u81f4\u67b6\u6784\u6f02\u79fb\u548c\u6587\u6863\u7f3a\u5931\u3002\u73b0\u6709\u67b6\u6784\u91cd\u6784\u65b9\u6cd5\u96be\u4ee5\u8de8\u9879\u76ee\u590d\u7528\uff0c\u56e0\u4e3a\u4e0d\u540c\u9879\u76ee\u4f7f\u7528\u4e0d\u540c\u6280\u672f\u6808\uff0c\u4e14\u5fae\u670d\u52a1\u5e38\u5206\u6563\u5728\u591a\u4e2a\u4ee3\u7801\u5e93\u4e2d\uff0c\u96be\u4ee5\u83b7\u5f97\u7cfb\u7edf\u5b8c\u6574\u89c6\u56fe\u3002", "method": "\u63d0\u51faModARO\u65b9\u6cd5\uff0c\u5141\u8bb8\u7f16\u5199\u6a21\u5757\u5316\u7684\u91cd\u6784\u4ee3\u7801\uff08\u63d0\u53d6\u5668\uff09\uff0c\u8fd9\u4e9b\u63d0\u53d6\u5668\u53ef\u4ee5\u9488\u5bf9\u4efb\u4f55\u6280\u672f\u6808\u7f16\u5199\uff0c\u5e76\u5728\u4e0d\u540c\u9879\u76ee\u4e2d\u590d\u7528\uff0c\u4e0d\u53d7\u5468\u56f4\u6280\u672f\u6808\u6216\u4ee3\u7801\u5e93\u5206\u6563\u7684\u5f71\u54cd\u3002", "result": "\u901a\u8fc7\u914d\u7f6eModARO\u91cd\u6784\u4e8610\u4e2a\u5f00\u6e90\u9879\u76ee\uff0c\u5e76\u901a\u8fc7\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u53ef\u7528\u6027\u3002\u7528\u6237\u7814\u7a76\u8868\u660eModARO\u5728\u6709\u7528\u6027\u548c\u53ef\u7528\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "ModARO\u4f7f\u5f00\u53d1\u8005\u80fd\u591f\u4e3a\u7279\u5b9a\u6280\u672f\u6808\u7ec4\u88c5\u6216\u521b\u5efa\u63d0\u53d6\u5668\uff0c\u5e76\u8de8\u4ee3\u7801\u5e93\u8fdb\u884c\u67b6\u6784\u91cd\u6784\uff0c\u4fbf\u4e8e\u96c6\u6210\u5230CI/CD\u6d41\u6c34\u7ebf\u4e2d\uff0c\u5e2e\u52a9\u89e3\u51b3\u5fae\u670d\u52a1\u67b6\u6784\u7684\u590d\u6742\u6027\u548c\u6587\u6863\u7ef4\u62a4\u95ee\u9898\u3002"}}
{"id": "2602.08192", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08192", "abs": "https://arxiv.org/abs/2602.08192", "authors": ["Mirko Perkusich", "Danyllo Albuquerque", "Allysson Allex Ara\u00fajo", "Matheus Paix\u00e3o", "Rohit Gheyi", "Marcos Kalinowski", "Angelo Perkusich"], "title": "Adoption of Large Language Models in Scrum Management: Insights from Brazilian Practitioners", "comment": "Accepted for publication at the 27th International Conference on Agile Software Development (XP 2026)", "summary": "Scrum is widely adopted in software project management due to its adaptability and collaborative nature. The recent emergence of Large Language Models (LLMs) has created new opportunities to support knowledge-intensive Scrum practices. However, existing research has largely focused on technical activities such as coding and testing, with limited evidence on the use of LLMs in management-related Scrum activities. In this study, we investigate the use of LLMs in Scrum management activities through a survey of 70 Brazilian professionals. Among them, 49 actively use Scrum, and 33 reported using LLM-based assistants in their Scrum practices. The results indicate a high level of proficiency and frequent use of LLMs, with 85% of respondents reporting intermediate or advanced proficiency and 52% using them daily. LLM use concentrates on exploring Scrum practices, with artifacts and events receiving targeted yet uneven support, whereas broader management tasks appear to be adopted more cautiously. The main benefits include increased productivity (78%) and reduced manual effort (75%). However, several critical risks remain, as respondents report 'almost correct' outputs (81%), confidentiality concerns (63%), and hallucinations during use (59%). This work provides one of the first empirical characterizations of LLM use in Scrum management, identifying current practices, quantifying benefits and risks, and outlining directions for responsible adoption and integration in Agile environments.", "AI": {"tldr": "\u7814\u7a76\u8c03\u67e5\u4e86\u5df4\u897f70\u540d\u4e13\u4e1a\u4eba\u58eb\u5728Scrum\u7ba1\u7406\u6d3b\u52a8\u4e2d\u4f7f\u7528LLM\u7684\u60c5\u51b5\uff0c\u53d1\u73b0LLM\u5728Scrum\u5b9e\u8df5\u4e2d\u5e94\u7528\u5e7f\u6cdb\u4f46\u5b58\u5728\u98ce\u9669", "motivation": "\u867d\u7136LLM\u5728\u8f6f\u4ef6\u5f00\u53d1\u7684\u6280\u672f\u6d3b\u52a8\u4e2d\u5df2\u6709\u5e94\u7528\u7814\u7a76\uff0c\u4f46\u5728Scrum\u7ba1\u7406\u6d3b\u52a8\u4e2d\u7684\u5e94\u7528\u7f3a\u4e4f\u5b9e\u8bc1\u8bc1\u636e\uff0c\u9700\u8981\u4e86\u89e3\u5f53\u524d\u5b9e\u8df5\u3001\u91cf\u5316\u6548\u76ca\u4e0e\u98ce\u9669", "method": "\u901a\u8fc7\u5bf970\u540d\u5df4\u897f\u4e13\u4e1a\u4eba\u58eb\u8fdb\u884c\u95ee\u5377\u8c03\u67e5\uff0c\u5176\u4e2d49\u4eba\u79ef\u6781\u4f7f\u7528Scrum\uff0c33\u4eba\u62a5\u544a\u5728Scrum\u5b9e\u8df5\u4e2d\u4f7f\u7528\u57fa\u4e8eLLM\u7684\u52a9\u624b", "result": "85%\u53d7\u8bbf\u8005\u5177\u5907\u4e2d\u9ad8\u7ea7LLM\u719f\u7ec3\u5ea6\uff0c52%\u6bcf\u65e5\u4f7f\u7528\uff1b\u4e3b\u8981\u5e94\u7528\u4e8e\u63a2\u7d22Scrum\u5b9e\u8df5\uff0c\u6548\u76ca\u5305\u62ec\u751f\u4ea7\u529b\u63d0\u5347(78%)\u548c\u51cf\u5c11\u624b\u52a8\u5de5\u4f5c(75%)\uff1b\u98ce\u9669\u5305\u62ec\"\u51e0\u4e4e\u6b63\u786e\"\u8f93\u51fa(81%)\u3001\u4fdd\u5bc6\u95ee\u9898(63%)\u548c\u5e7b\u89c9(59%)", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5bf9Scrum\u7ba1\u7406\u4e2dLLM\u4f7f\u7528\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u8bc6\u522b\u4e86\u5f53\u524d\u5b9e\u8df5\u3001\u91cf\u5316\u4e86\u6548\u76ca\u4e0e\u98ce\u9669\uff0c\u4e3a\u654f\u6377\u73af\u5883\u4e2d\u8d1f\u8d23\u4efb\u5730\u91c7\u7528\u548c\u96c6\u6210LLM\u63d0\u4f9b\u4e86\u65b9\u5411"}}
{"id": "2602.07628", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07628", "abs": "https://arxiv.org/abs/2602.07628", "authors": ["Keondo Park", "Younghoon Na", "Yourim Choi", "Hyunwoo Ryu", "Hyun-Woo Shin", "Hyung-Sin Kim"], "title": "SleepMaMi: A Universal Sleep Foundation Model for Integrating Macro- and Micro-structures", "comment": "8 pages, Appendix 9 pages", "summary": "While the shift toward unified foundation models has revolutionized many deep learning domains, sleep medicine remains largely restricted to task-specific models that focus on localized micro-structure features. These approaches often neglect the rich, multi-modal context of Polysomnography (PSG) and fail to capture the global macro-structure of a full night's sleep. To address this, we introduce SleepMaMi , a Sleep Foundation Model engineered to master both hour-long sleep architectures and fine-grained signal morphologies. Our framework utilizes a hierarchical dual-encoder design: a Macro-Encoder to model full-night temporal dependencies and a Micro-Encoder to capture short-term characteristics from biosignals. Macro-Encoder is trained via Demographic-Guided Contrastive Learning, which aligns overnight sleep patterns with objective subject metadata, such as age, sex and BMI to refine global representations. Micro-Encoder is optimized via a hybrid Masked Autoencoder (MAE) and multi-modal contrastive objective. Pre-trained on a massive corpus of $>$20,000 PSG recordings (158K hours),SleepMaMi outperforms existing foundation models across a diverse suite of downstream tasks, demonstrating superior generalizability and label-efficient adaptation for clinical sleep analysis.", "AI": {"tldr": "SleepMaMi\u662f\u4e00\u4e2a\u7761\u7720\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u5206\u5c42\u53cc\u7f16\u7801\u5668\u8bbe\u8ba1\u540c\u65f6\u638c\u63e1\u6574\u591c\u7761\u7720\u5b8f\u89c2\u7ed3\u6784\u548c\u7ec6\u7c92\u5ea6\u4fe1\u53f7\u5f62\u6001\uff0c\u5728\u5927\u91cfPSG\u6570\u636e\u4e0a\u9884\u8bad\u7ec3\uff0c\u5728\u591a\u79cd\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u7761\u7720\u533b\u5b66\u76ee\u524d\u4e3b\u8981\u4f9d\u8d56\u4efb\u52a1\u7279\u5b9a\u7684\u6a21\u578b\uff0c\u8fd9\u4e9b\u6a21\u578b\u4e13\u6ce8\u4e8e\u5c40\u90e8\u5fae\u7ed3\u6784\u7279\u5f81\uff0c\u5ffd\u7565\u4e86\u591a\u5bfc\u7761\u7720\u56fe\uff08PSG\uff09\u7684\u4e30\u5bcc\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\uff0c\u672a\u80fd\u6355\u6349\u6574\u591c\u7761\u7720\u7684\u5168\u5c40\u5b8f\u89c2\u7ed3\u6784\u3002", "method": "\u91c7\u7528\u5206\u5c42\u53cc\u7f16\u7801\u5668\u8bbe\u8ba1\uff1a\u5b8f\u89c2\u7f16\u7801\u5668\u901a\u8fc7\u4eba\u53e3\u7edf\u8ba1\u5b66\u5f15\u5bfc\u7684\u5bf9\u6bd4\u5b66\u4e60\u5efa\u6a21\u6574\u591c\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\uff1b\u5fae\u89c2\u7f16\u7801\u5668\u901a\u8fc7\u6df7\u5408\u63a9\u7801\u81ea\u7f16\u7801\u5668\u548c\u591a\u6a21\u6001\u5bf9\u6bd4\u76ee\u6807\u4f18\u5316\uff0c\u6355\u6349\u751f\u7269\u4fe1\u53f7\u7684\u77ed\u671f\u7279\u5f81\u3002\u5728\u8d85\u8fc720,000\u4e2aPSG\u8bb0\u5f55\uff08158K\u5c0f\u65f6\uff09\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\u3002", "result": "SleepMaMi\u5728\u591a\u6837\u5316\u7684\u4e0b\u6e38\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u7840\u6a21\u578b\uff0c\u5c55\u793a\u4e86\u5353\u8d8a\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6807\u7b7e\u9ad8\u6548\u7684\u4e34\u5e8a\u7761\u7720\u5206\u6790\u9002\u5e94\u6027\u3002", "conclusion": "SleepMaMi\u4f5c\u4e3a\u7761\u7720\u57fa\u7840\u6a21\u578b\uff0c\u6210\u529f\u6574\u5408\u4e86\u5b8f\u89c2\u7761\u7720\u7ed3\u6784\u548c\u5fae\u89c2\u4fe1\u53f7\u7279\u5f81\uff0c\u4e3a\u4e34\u5e8a\u7761\u7720\u5206\u6790\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u901a\u7528\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u4efb\u52a1\u7279\u5b9a\u6a21\u578b\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2602.08750", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08750", "abs": "https://arxiv.org/abs/2602.08750", "authors": ["Guy Farrelly", "Michael Chesser", "Seyit Camtepe", "Damith C. Ranasinghe"], "title": "DyMA-Fuzz: Dynamic Direct Memory Access Abstraction for Re-hosted Monolithic Firmware Fuzzing", "comment": "Accepted to ICSE 2026", "summary": "The rise of smart devices in critical domains--including automotive, medical, industrial--demands robust firmware testing. Fuzzing firmware in re-hosted environments is a promising method for automated testing at scale, but remains difficult due to the tight coupling of code with a microcontroller's peripherals. Existing fuzzing frameworks primarily address input challenges in providing inputs for Memory-Mapped I/O or interrupts, but largely overlook Direct Memory Access (DMA), a key high-throughput interface used that bypasses the CPU. We introduce DyMA-Fuzz to extend recent advances in stream-based fuzz input injection to DMA-driven interfaces in re-hosted environments. It tackles key challenges--vendor-specific descriptors, heterogeneous DMA designs, and varying descriptor locations--using runtime analysis techniques to infer DMA memory access patterns and automatically inject fuzzing data into target buffers, without manual configuration or datasheets. Evaluated on 94 firmware samples and 8 DMA-guarded CVE benchmarks, DyMA-Fuzz reveals vulnerabilities and execution paths missed by state-of-the-art tools and achieves up to 122% higher code coverage. These results highlight DyMA-Fuzz as a practical and effective advancement in automated firmware testing and a scalable solution for fuzzing complex embedded systems.", "AI": {"tldr": "DyMA-Fuzz\u662f\u4e00\u4e2a\u9488\u5bf9\u5d4c\u5165\u5f0f\u7cfb\u7edf\u56fa\u4ef6\u6d4b\u8bd5\u7684\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6\uff0c\u4e13\u95e8\u5904\u7406DMA\u63a5\u53e3\uff0c\u65e0\u9700\u624b\u52a8\u914d\u7f6e\u5373\u53ef\u81ea\u52a8\u6ce8\u5165\u6a21\u7cca\u6d4b\u8bd5\u6570\u636e\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4ee3\u7801\u8986\u76d6\u7387\u3002", "motivation": "\u968f\u7740\u667a\u80fd\u8bbe\u5907\u5728\u5173\u952e\u9886\u57df\u7684\u5e94\u7528\u589e\u52a0\uff0c\u9700\u8981\u5f3a\u5927\u7684\u56fa\u4ef6\u6d4b\u8bd5\u65b9\u6cd5\u3002\u73b0\u6709\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6\u4e3b\u8981\u5173\u6ce8\u5185\u5b58\u6620\u5c04I/O\u548c\u4e2d\u65ad\u8f93\u5165\uff0c\u4f46\u5ffd\u89c6\u4e86\u76f4\u63a5\u5185\u5b58\u8bbf\u95ee\uff08DMA\uff09\u8fd9\u4e00\u5173\u952e\u7684\u9ad8\u541e\u5410\u91cf\u63a5\u53e3\uff0c\u800cDMA\u5728\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u4e14\u7ed5\u8fc7CPU\u63a7\u5236\u3002", "method": "DyMA-Fuzz\u6269\u5c55\u4e86\u57fa\u4e8e\u6d41\u7684\u6a21\u7cca\u6d4b\u8bd5\u8f93\u5165\u6ce8\u5165\u6280\u672f\uff0c\u9488\u5bf9\u91cd\u6258\u7ba1\u73af\u5883\u4e2d\u7684DMA\u9a71\u52a8\u63a5\u53e3\u3002\u5b83\u4f7f\u7528\u8fd0\u884c\u65f6\u5206\u6790\u6280\u672f\u6765\u63a8\u65adDMA\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\uff0c\u81ea\u52a8\u5c06\u6a21\u7cca\u6d4b\u8bd5\u6570\u636e\u6ce8\u5165\u76ee\u6807\u7f13\u51b2\u533a\uff0c\u65e0\u9700\u624b\u52a8\u914d\u7f6e\u6216\u6570\u636e\u624b\u518c\u3002\u8be5\u65b9\u6cd5\u89e3\u51b3\u4e86\u4f9b\u5e94\u5546\u7279\u5b9a\u63cf\u8ff0\u7b26\u3001\u5f02\u6784DMA\u8bbe\u8ba1\u548c\u4e0d\u540c\u63cf\u8ff0\u7b26\u4f4d\u7f6e\u7b49\u5173\u952e\u6311\u6218\u3002", "result": "\u572894\u4e2a\u56fa\u4ef6\u6837\u672c\u548c8\u4e2aDMA\u4fdd\u62a4\u7684CVE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDyMA-Fuzz\u53d1\u73b0\u4e86\u73b0\u6709\u6700\u5148\u8fdb\u5de5\u5177\u9057\u6f0f\u7684\u6f0f\u6d1e\u548c\u6267\u884c\u8def\u5f84\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe122%\u7684\u4ee3\u7801\u8986\u76d6\u7387\u63d0\u5347\u3002", "conclusion": "DyMA-Fuzz\u662f\u81ea\u52a8\u5316\u56fa\u4ef6\u6d4b\u8bd5\u7684\u5b9e\u7528\u6709\u6548\u8fdb\u5c55\uff0c\u4e3a\u6a21\u7cca\u6d4b\u8bd5\u590d\u6742\u5d4c\u5165\u5f0f\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u5728\u5904\u7406DMA\u63a5\u53e3\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2602.07642", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07642", "abs": "https://arxiv.org/abs/2602.07642", "authors": ["Zhuoyan Xu", "Haoyang Fang", "Boran Han", "Bonan Min", "Bernie Wang", "Cuixiong Hu", "Shuai Zhang"], "title": "Efficient Table Retrieval and Understanding with Multimodal Large Language Models", "comment": "Published at EACL 2026 Findings", "summary": "Tabular data is frequently captured in image form across a wide range of real-world scenarios such as financial reports, handwritten records, and document scans. These visual representations pose unique challenges for machine understanding, as they combine both structural and visual complexities. While recent advances in Multimodal Large Language Models (MLLMs) show promising results in table understanding, they typically assume the relevant table is readily available. However, a more practical scenario involves identifying and reasoning over relevant tables from large-scale collections to answer user queries. To address this gap, we propose TabRAG, a framework that enables MLLMs to answer queries over large collections of table images. Our approach first retrieves candidate tables using jointly trained visual-text foundation models, then leverages MLLMs to perform fine-grained reranking of these candidates, and finally employs MLLMs to reason over the selected tables for answer generation. Through extensive experiments on a newly constructed dataset comprising 88,161 training and 9,819 testing samples across 8 benchmarks with 48,504 unique tables, we demonstrate that our framework significantly outperforms existing methods by 7.0% in retrieval recall and 6.1% in answer accuracy, offering a practical solution for real-world table understanding tasks.", "AI": {"tldr": "TabRAG\uff1a\u4e00\u4e2a\u7528\u4e8e\u5927\u89c4\u6a21\u8868\u683c\u56fe\u50cf\u68c0\u7d22\u548c\u63a8\u7406\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u89c6\u89c9-\u6587\u672c\u57fa\u7840\u6a21\u578b\u68c0\u7d22\u5019\u9009\u8868\u683c\uff0cMLLMs\u8fdb\u884c\u7ec6\u7c92\u5ea6\u91cd\u6392\u5e8f\uff0c\u6700\u7ec8\u751f\u6210\u7b54\u6848\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u8868\u683c\u6570\u636e\u5e38\u4ee5\u56fe\u50cf\u5f62\u5f0f\u5b58\u5728\uff08\u5982\u8d22\u52a1\u62a5\u8868\u3001\u624b\u5199\u8bb0\u5f55\u3001\u6587\u6863\u626b\u63cf\uff09\uff0c\u73b0\u6709MLLMs\u901a\u5e38\u5047\u8bbe\u76f8\u5173\u8868\u683c\u5df2\u51c6\u5907\u597d\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8981\u4ece\u5927\u89c4\u6a21\u8868\u683c\u96c6\u5408\u4e2d\u8bc6\u522b\u548c\u63a8\u7406\u76f8\u5173\u8868\u683c\u6765\u56de\u7b54\u7528\u6237\u67e5\u8be2\u3002", "method": "TabRAG\u6846\u67b6\uff1a1\uff09\u4f7f\u7528\u8054\u5408\u8bad\u7ec3\u7684\u89c6\u89c9-\u6587\u672c\u57fa\u7840\u6a21\u578b\u68c0\u7d22\u5019\u9009\u8868\u683c\uff1b2\uff09\u5229\u7528MLLMs\u5bf9\u8fd9\u4e9b\u5019\u9009\u8fdb\u884c\u7ec6\u7c92\u5ea6\u91cd\u6392\u5e8f\uff1b3\uff09\u4f7f\u7528MLLMs\u5728\u9009\u5b9a\u8868\u683c\u4e0a\u8fdb\u884c\u63a8\u7406\u4ee5\u751f\u6210\u7b54\u6848\u3002", "result": "\u5728\u65b0\u6784\u5efa\u7684\u6570\u636e\u96c6\uff0888,161\u8bad\u7ec3\u6837\u672c\u548c9,819\u6d4b\u8bd5\u6837\u672c\uff0c\u6db5\u76d68\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b48,504\u4e2a\u552f\u4e00\u8868\u683c\uff09\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u7ed3\u679c\u663e\u793a\uff1a\u68c0\u7d22\u53ec\u56de\u7387\u63d0\u53477.0%\uff0c\u7b54\u6848\u51c6\u786e\u7387\u63d0\u53476.1%\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "TabRAG\u4e3a\u73b0\u5b9e\u4e16\u754c\u7684\u8868\u683c\u7406\u89e3\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u5927\u89c4\u6a21\u8868\u683c\u56fe\u50cf\u96c6\u5408\u7684\u68c0\u7d22\u548c\u63a8\u7406\u95ee\u9898\u3002"}}
{"id": "2602.08798", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.08798", "abs": "https://arxiv.org/abs/2602.08798", "authors": ["Hedong Zhang", "Neusha Javidnia", "Shweta Pardeshi", "Qian Lou", "Farinaz Koushanfar"], "title": "CryptoGen: Secure Transformer Generation with Encrypted KV-Cache Reuse", "comment": "13 pages, 9 figures", "summary": "The widespread deployment of cloud-hosted generative models raises a fundamental challenge: enabling efficient autoregressive generation while preserving the privacy of both user prompts and model parameters in untrusted environments. We address this challenge in a client-server setting where an untrusted server hosts an autoregressive Transformer and the client requires cryptographic protection for both inputs and inference. We present CryptoGen, the first system to enable scalable privacy-preserving neural generation with persistent encrypted key-value (KV) cache reuse. Discriminative-task secure inference systems incur quadratic latency and memory growth when adapted to autoregressive decoding due to the lack of native encrypted KV-cache support. In contrast, CryptoGen achieves near-linear scaling by securely reusing and updating encrypted KV caches throughout generation. CryptoGen integrates homomorphic encryption and secret sharing to support both prefilling and generation. Key techniques include a unified encrypted KV-cache framework, heterogeneous SIMD encodings for different phases, optimized cipher-cipher matrix-matrix and matrix-vector operations, and efficient noise refresh and ciphertext concatenation mechanisms. Evaluation on generative Transformer models trained on WikiText-2, PTB, and LAMBADA shows that for input lengths of 128-512 tokens, CryptoGen achieves 4.4x-7.6x lower per-token latency than state-of-the-art discriminative secure inference systems, while maintaining near-linear latency and memory scaling, with advantages increasing for longer sequences. CryptoGen is released as an open-source library.", "AI": {"tldr": "CryptoGen\u662f\u9996\u4e2a\u652f\u6301\u53ef\u6269\u5c55\u9690\u79c1\u4fdd\u62a4\u795e\u7ecf\u751f\u6210\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u6301\u4e45\u52a0\u5bc6KV\u7f13\u5b58\u91cd\u7528\u5b9e\u73b0\u8fd1\u7ebf\u6027\u6269\u5c55\uff0c\u76f8\u6bd4\u73b0\u6709\u7cfb\u7edf\u964d\u4f4e4.4-7.6\u500d\u5ef6\u8fdf\u3002", "motivation": "\u4e91\u6258\u7ba1\u751f\u6210\u6a21\u578b\u5e7f\u6cdb\u90e8\u7f72\u5e26\u6765\u6311\u6218\uff1a\u9700\u8981\u5728\u4e0d\u53ef\u4fe1\u73af\u5883\u4e2d\u5b9e\u73b0\u9ad8\u6548\u81ea\u56de\u5f52\u751f\u6210\uff0c\u540c\u65f6\u4fdd\u62a4\u7528\u6237\u63d0\u793a\u548c\u6a21\u578b\u53c2\u6570\u7684\u9690\u79c1\u3002\u73b0\u6709\u5224\u522b\u4efb\u52a1\u5b89\u5168\u63a8\u7406\u7cfb\u7edf\u7f3a\u4e4f\u539f\u751f\u52a0\u5bc6KV\u7f13\u5b58\u652f\u6301\uff0c\u5728\u9002\u5e94\u81ea\u56de\u5f52\u89e3\u7801\u65f6\u4f1a\u4ea7\u751f\u4e8c\u6b21\u65b9\u5ef6\u8fdf\u548c\u5185\u5b58\u589e\u957f\u3002", "method": "CryptoGen\u6574\u5408\u540c\u6001\u52a0\u5bc6\u548c\u79d8\u5bc6\u5171\u4eab\uff0c\u652f\u6301\u9884\u586b\u5145\u548c\u751f\u6210\u9636\u6bb5\u3002\u5173\u952e\u6280\u672f\u5305\u62ec\uff1a\u7edf\u4e00\u52a0\u5bc6KV\u7f13\u5b58\u6846\u67b6\u3001\u9488\u5bf9\u4e0d\u540c\u9636\u6bb5\u7684\u5f02\u6784SIMD\u7f16\u7801\u3001\u4f18\u5316\u7684\u5bc6\u6587-\u5bc6\u6587\u77e9\u9635-\u77e9\u9635\u548c\u77e9\u9635-\u5411\u91cf\u64cd\u4f5c\u3001\u9ad8\u6548\u7684\u566a\u58f0\u5237\u65b0\u548c\u5bc6\u6587\u8fde\u63a5\u673a\u5236\u3002", "result": "\u5728WikiText-2\u3001PTB\u548cLAMBADA\u8bad\u7ec3\u7684\u751f\u6210Transformer\u6a21\u578b\u4e0a\u8bc4\u4f30\uff0c\u5bf9\u4e8e128-512\u4e2atoken\u7684\u8f93\u5165\u957f\u5ea6\uff0cCryptoGen\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u5224\u522b\u5b89\u5168\u63a8\u7406\u7cfb\u7edf\u5b9e\u73b04.4-7.6\u500d\u66f4\u4f4e\u7684\u6bcftoken\u5ef6\u8fdf\uff0c\u540c\u65f6\u4fdd\u6301\u8fd1\u7ebf\u6027\u7684\u5ef6\u8fdf\u548c\u5185\u5b58\u6269\u5c55\uff0c\u5e8f\u5217\u8d8a\u957f\u4f18\u52bf\u8d8a\u660e\u663e\u3002", "conclusion": "CryptoGen\u901a\u8fc7\u6301\u4e45\u52a0\u5bc6KV\u7f13\u5b58\u91cd\u7528\uff0c\u9996\u6b21\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u7684\u9690\u79c1\u4fdd\u62a4\u795e\u7ecf\u751f\u6210\uff0c\u89e3\u51b3\u4e86\u81ea\u56de\u5f52\u751f\u6210\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u6311\u6218\uff0c\u5e76\u4f5c\u4e3a\u5f00\u6e90\u5e93\u53d1\u5e03\u3002"}}
{"id": "2602.08263", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08263", "abs": "https://arxiv.org/abs/2602.08263", "authors": ["Taohong Zhu", "Lucas C. Cordeiro", "Mustafa A. Mustafa", "Youcheng Sun"], "title": "Specification Vibing for Automated Program Repair", "comment": null, "summary": "Large language model (LLM)-driven automated program repair (APR) has advanced rapidly, but most methods remain code-centric: they directly rewrite source code and thereby risk hallucinated, behaviorally inconsistent fixes. This limitation suggests the need for an alternative repair paradigm that relies on a representation more accessible to LLMs than raw code, enabling more accurate understanding, analysis, and alignment during repair. To address this gap, we propose VibeRepair, a specification-centric APR technique that treats repair as behavior-specification repair rather than ad-hoc code editing. VibeRepair first translates buggy code into a structured behavior specification that captures the program's intended runtime behavior, then infers and repairs specification misalignments, and finally synthesizes code strictly guided by the corrected behavior specification. An on-demand reasoning component enriches hard cases with program analysis and historical bug-fix evidence while controlling cost. Across Defects4J and real-world benchmarks and multiple LLMs, VibeRepair demonstrates consistently strong repair effectiveness with a significantly smaller patch space. On Defects4J v1.2, VibeRepair correctly repairs 174 bugs, exceeding the strongest state-of-the-art baseline by 28 bugs, which corresponds to a 19% improvement. On Defects4J v2.0, it repairs 178 bugs, outperforming prior approaches by 33 bugs, representing a 23% improvement. Evaluations on real-world benchmarks collected after the training period of selected LLMs further confirm its effectiveness and generalizability. By centering repair on explicit behavioral intent, VibeRepair reframes APR for the era of \"vibe\" coding: make the behavior sing, and the code will follow.", "AI": {"tldr": "VibeRepair\u662f\u4e00\u79cd\u57fa\u4e8e\u884c\u4e3a\u89c4\u8303\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u9519\u8bef\u4ee3\u7801\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u884c\u4e3a\u89c4\u8303\uff0c\u4fee\u590d\u89c4\u8303\u504f\u5dee\uff0c\u518d\u57fa\u4e8e\u4fee\u6b63\u540e\u7684\u89c4\u8303\u5408\u6210\u4ee3\u7801\uff0c\u76f8\u6bd4\u4f20\u7edf\u4ee3\u7801\u4e2d\u5fc3\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u4fee\u590d\u6548\u679c\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u65b9\u6cd5\u5927\u591a\u662f\u4ee3\u7801\u4e2d\u5fc3\u7684\uff0c\u76f4\u63a5\u91cd\u5199\u6e90\u4ee3\u7801\u53ef\u80fd\u5bfc\u81f4\u4ea7\u751f\u5e7b\u89c9\u4fee\u590d\u548c\u884c\u4e3a\u4e0d\u4e00\u81f4\u7684\u8865\u4e01\u3002\u9700\u8981\u4e00\u79cd\u66f4\u6613\u4e8eLLM\u7406\u89e3\u7684\u66ff\u4ee3\u4fee\u590d\u8303\u5f0f\uff0c\u4f7f\u7528\u6bd4\u539f\u59cb\u4ee3\u7801\u66f4\u6613\u8bbf\u95ee\u7684\u8868\u793a\u5f62\u5f0f\uff0c\u4ee5\u5b9e\u73b0\u66f4\u51c6\u786e\u7684\u7406\u89e3\u3001\u5206\u6790\u548c\u4fee\u590d\u5bf9\u9f50\u3002", "method": "VibeRepair\u91c7\u7528\u89c4\u8303\u4e2d\u5fc3\u7684\u4fee\u590d\u65b9\u6cd5\uff1a1) \u5c06\u9519\u8bef\u4ee3\u7801\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u884c\u4e3a\u89c4\u8303\uff0c\u6355\u6349\u7a0b\u5e8f\u7684\u9884\u671f\u8fd0\u884c\u65f6\u884c\u4e3a\uff1b2) \u63a8\u65ad\u5e76\u4fee\u590d\u89c4\u8303\u504f\u5dee\uff1b3) \u5728\u4fee\u6b63\u540e\u7684\u884c\u4e3a\u89c4\u8303\u4e25\u683c\u6307\u5bfc\u4e0b\u5408\u6210\u4ee3\u7801\u3002\u5305\u542b\u6309\u9700\u63a8\u7406\u7ec4\u4ef6\uff0c\u901a\u8fc7\u7a0b\u5e8f\u5206\u6790\u548c\u5386\u53f2\u9519\u8bef\u4fee\u590d\u8bc1\u636e\u4e30\u5bcc\u56f0\u96be\u6848\u4f8b\uff0c\u540c\u65f6\u63a7\u5236\u6210\u672c\u3002", "result": "\u5728Defects4J v1.2\u4e0a\u6b63\u786e\u4fee\u590d174\u4e2a\u9519\u8bef\uff0c\u6bd4\u6700\u5f3a\u57fa\u7ebf\u591a28\u4e2a\u9519\u8bef\uff08\u63d0\u534719%\uff09\uff1b\u5728Defects4J v2.0\u4e0a\u4fee\u590d178\u4e2a\u9519\u8bef\uff0c\u6bd4\u5148\u524d\u65b9\u6cd5\u591a33\u4e2a\u9519\u8bef\uff08\u63d0\u534723%\uff09\u3002\u5728\u8bad\u7ec3\u671f\u540e\u6536\u96c6\u7684\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fdb\u4e00\u6b65\u8bc1\u5b9e\u4e86\u5176\u6709\u6548\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u8865\u4e01\u7a7a\u95f4\u3002", "conclusion": "\u901a\u8fc7\u5c06\u4fee\u590d\u91cd\u70b9\u653e\u5728\u660e\u786e\u7684\u884c\u4e3a\u610f\u56fe\u4e0a\uff0cVibeRepair\u4e3a\"\u6c1b\u56f4\"\u7f16\u7801\u65f6\u4ee3\u91cd\u65b0\u6784\u5efa\u4e86\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u8303\u5f0f\uff1a\u8ba9\u884c\u4e3a\u5148\u884c\uff0c\u4ee3\u7801\u968f\u4e4b\u800c\u6765\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u89c4\u8303\u4e2d\u5fc3\u7684\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u51c6\u786e\u3001\u66f4\u4e00\u81f4\u7684\u4fee\u590d\u6548\u679c\u3002"}}
{"id": "2602.07662", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07662", "abs": "https://arxiv.org/abs/2602.07662", "authors": ["Glenda Amaral", "Tiago Prince Sales", "Riccardo Baratella", "Daniele Porello", "Renata Guizzardi", "Giancarlo Guizzardi"], "title": "ONTrust: A Reference Ontology of Trust", "comment": "46 pages", "summary": "Trust has stood out more than ever in the light of recent innovations. Some examples are advances in artificial intelligence that make machines more and more humanlike, and the introduction of decentralized technologies (e.g. blockchains), which creates new forms of (decentralized) trust. These new developments have the potential to improve the provision of products and services, as well as to contribute to individual and collective well-being. However, their adoption depends largely on trust. In order to build trustworthy systems, along with defining laws, regulations and proper governance models for new forms of trust, it is necessary to properly conceptualize trust, so that it can be understood both by humans and machines. This paper is the culmination of a long-term research program of providing a solid ontological foundation on trust, by creating reference conceptual models to support information modeling, automated reasoning, information integration and semantic interoperability tasks. To address this, a Reference Ontology of Trust (ONTrust) was developed, grounded on the Unified Foundational Ontology and specified in OntoUML, which has been applied in several initiatives, to demonstrate, for example, how it can be used for conceptual modeling and enterprise architecture design, for language evaluation and (re)design, for trust management, for requirements engineering, and for trustworthy artificial intelligence (AI) in the context of affective Human-AI teaming. ONTrust formally characterizes the concept of trust and its different types, describes the different factors that can influence trust, as well as explains how risk emerges from trust relations. To illustrate the working of ONTrust, the ontology is applied to model two case studies extracted from the literature.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7edf\u4e00\u57fa\u7840\u672c\u4f53\u8bba\u7684\u4fe1\u4efb\u53c2\u8003\u672c\u4f53\u8bba(ONTrust)\uff0c\u7528\u4e8e\u652f\u6301\u4fe1\u606f\u5efa\u6a21\u3001\u81ea\u52a8\u63a8\u7406\u3001\u4fe1\u606f\u96c6\u6210\u548c\u8bed\u4e49\u4e92\u64cd\u4f5c\u6027\u4efb\u52a1\uff0c\u4ee5\u5e94\u5bf9\u4eba\u5de5\u667a\u80fd\u548c\u53bb\u4e2d\u5fc3\u5316\u6280\u672f\u7b49\u65b0\u5174\u6280\u672f\u5e26\u6765\u7684\u4fe1\u4efb\u6311\u6218\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u6280\u672f\u4f7f\u673a\u5668\u8d8a\u6765\u8d8a\u50cf\u4eba\u7c7b\uff0c\u4ee5\u53ca\u533a\u5757\u94fe\u7b49\u53bb\u4e2d\u5fc3\u5316\u6280\u672f\u521b\u9020\u65b0\u7684\u4fe1\u4efb\u5f62\u5f0f\uff0c\u8fd9\u4e9b\u65b0\u6280\u672f\u867d\u7136\u80fd\u6539\u5584\u4ea7\u54c1\u670d\u52a1\u63d0\u4f9b\u5e76\u4fc3\u8fdb\u4e2a\u4eba\u548c\u96c6\u4f53\u798f\u7949\uff0c\u4f46\u5176\u91c7\u7528\u5f88\u5927\u7a0b\u5ea6\u4e0a\u53d6\u51b3\u4e8e\u4fe1\u4efb\u3002\u4e3a\u4e86\u6784\u5efa\u53ef\u4fe1\u7cfb\u7edf\uff0c\u9664\u4e86\u4e3a\u65b0\u7684\u4fe1\u4efb\u5f62\u5f0f\u5b9a\u4e49\u6cd5\u5f8b\u3001\u6cd5\u89c4\u548c\u6cbb\u7406\u6a21\u578b\u5916\uff0c\u8fd8\u9700\u8981\u5bf9\u4fe1\u4efb\u8fdb\u884c\u9002\u5f53\u7684\u6982\u5ff5\u5316\uff0c\u4f7f\u5176\u80fd\u88ab\u4eba\u7c7b\u548c\u673a\u5668\u7406\u89e3\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u7edf\u4e00\u57fa\u7840\u672c\u4f53\u8bba(Unified Foundational Ontology)\u7684\u4fe1\u4efb\u53c2\u8003\u672c\u4f53\u8bba(ONTrust)\uff0c\u4f7f\u7528OntoUML\u8bed\u8a00\u8fdb\u884c\u89c4\u8303\u3002\u8be5\u672c\u4f53\u8bba\u6b63\u5f0f\u63cf\u8ff0\u4e86\u4fe1\u4efb\u6982\u5ff5\u53ca\u5176\u4e0d\u540c\u7c7b\u578b\uff0c\u5206\u6790\u4e86\u5f71\u54cd\u4fe1\u4efb\u7684\u5404\u79cd\u56e0\u7d20\uff0c\u5e76\u89e3\u91ca\u4e86\u4fe1\u4efb\u5173\u7cfb\u5982\u4f55\u4ea7\u751f\u98ce\u9669\u3002\u901a\u8fc7\u4e24\u4e2a\u6587\u732e\u6848\u4f8b\u7814\u7a76\u6765\u5c55\u793aONTrust\u7684\u5b9e\u9645\u5e94\u7528\u3002", "result": "ONTrust\u5df2\u5728\u591a\u4e2a\u9879\u76ee\u4e2d\u5e94\u7528\uff0c\u5305\u62ec\u6982\u5ff5\u5efa\u6a21\u548c\u4f01\u4e1a\u67b6\u6784\u8bbe\u8ba1\u3001\u8bed\u8a00\u8bc4\u4f30\u4e0e(\u91cd\u65b0)\u8bbe\u8ba1\u3001\u4fe1\u4efb\u7ba1\u7406\u3001\u9700\u6c42\u5de5\u7a0b\uff0c\u4ee5\u53ca\u5728\u60c5\u611f\u4eba\u673a\u534f\u4f5c\u80cc\u666f\u4e0b\u7684\u53ef\u4fe1\u4eba\u5de5\u667a\u80fd\u3002\u672c\u4f53\u8bba\u80fd\u591f\u652f\u6301\u4fe1\u606f\u5efa\u6a21\u3001\u81ea\u52a8\u63a8\u7406\u3001\u4fe1\u606f\u96c6\u6210\u548c\u8bed\u4e49\u4e92\u64cd\u4f5c\u6027\u4efb\u52a1\u3002", "conclusion": "ONTrust\u4e3a\u4fe1\u4efb\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u672c\u4f53\u8bba\u57fa\u7840\uff0c\u901a\u8fc7\u521b\u5efa\u53c2\u8003\u6982\u5ff5\u6a21\u578b\u6765\u652f\u6301\u5404\u79cd\u5e94\u7528\u573a\u666f\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u53ef\u4fe1\u7cfb\u7edf\u5e76\u4fc3\u8fdb\u65b0\u5174\u6280\u672f\u7684\u91c7\u7528\u3002\u8be5\u672c\u4f53\u8bba\u4e3a\u89e3\u51b3\u4eba\u5de5\u667a\u80fd\u548c\u53bb\u4e2d\u5fc3\u5316\u6280\u672f\u5e26\u6765\u7684\u4fe1\u4efb\u6311\u6218\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u8df5\u5de5\u5177\u3002"}}
{"id": "2602.07695", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.MM"], "pdf": "https://arxiv.org/pdf/2602.07695", "abs": "https://arxiv.org/abs/2602.07695", "authors": ["Congcong Hu", "Yuang Shi", "Fan Huang", "Yang Xiang", "Zhou Ye", "Ming Jin", "Shiyu Wang"], "title": "EventCast: Hybrid Demand Forecasting in E-Commerce with LLM-Based Event Knowledge", "comment": null, "summary": "Demand forecasting is a cornerstone of e-commerce operations, directly impacting inventory planning and fulfillment scheduling. However, existing forecasting systems often fail during high-impact periods such as flash sales, holiday campaigns, and sudden policy interventions, where demand patterns shift abruptly and unpredictably. In this paper, we introduce EventCast, a modular forecasting framework that integrates future event knowledge into time-series prediction. Unlike prior approaches that ignore future interventions or directly use large language models (LLMs) for numerical forecasting, EventCast leverages LLMs solely for event-driven reasoning. Unstructured business data, which covers campaigns, holiday schedules, and seller incentives, from existing operational databases, is processed by an LLM that converts it into interpretable textual summaries leveraging world knowledge for cultural nuances and novel event combinations. These summaries are fused with historical demand features within a dual-tower architecture, enabling accurate, explainable, and scalable forecasts. Deployed on real-world e-commerce scenarios spanning 4 countries of 160 regions over 10 months, EventCast achieves up to 86.9% and 97.7% improvement on MAE and MSE compared to the variant without event knowledge, and reduces MAE by up to 57.0% and MSE by 83.3% versus the best industrial baseline during event-driven periods. EventCast has deployed into real-world industrial pipelines since March 2025, offering a practical solution for improving operational decision-making in dynamic e-commerce environments.", "AI": {"tldr": "EventCast\u662f\u4e00\u4e2a\u5c06\u672a\u6765\u4e8b\u4ef6\u77e5\u8bc6\u6574\u5408\u5230\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u6a21\u5757\u5316\u6846\u67b6\uff0c\u4e13\u95e8\u89e3\u51b3\u7535\u5546\u5728\u95ea\u8d2d\u3001\u8282\u5047\u65e5\u7b49\u7279\u6b8a\u65f6\u671f\u7684\u9700\u6c42\u9884\u6d4b\u95ee\u9898\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u9884\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u9884\u6d4b\u7cfb\u7edf\u5728\u95ea\u8d2d\u3001\u8282\u5047\u65e5\u4fc3\u9500\u548c\u653f\u7b56\u5e72\u9884\u7b49\u9ad8\u5f71\u54cd\u65f6\u671f\u7ecf\u5e38\u5931\u6548\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u65f6\u671f\u7684\u9700\u6c42\u6a21\u5f0f\u4f1a\u53d1\u751f\u7a81\u7136\u4e14\u4e0d\u53ef\u9884\u6d4b\u7684\u53d8\u5316\u3002\u7535\u5546\u8fd0\u8425\u9700\u8981\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u8fd9\u4e9b\u7279\u6b8a\u4e8b\u4ef6\u671f\u95f4\u9700\u6c42\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "EventCast\u5229\u7528LLM\u8fdb\u884c\u4e8b\u4ef6\u9a71\u52a8\u63a8\u7406\uff0c\u5c06\u975e\u7ed3\u6784\u5316\u4e1a\u52a1\u6570\u636e\uff08\u5982\u8425\u9500\u6d3b\u52a8\u3001\u8282\u5047\u65e5\u5b89\u6392\u3001\u5356\u5bb6\u6fc0\u52b1\uff09\u8f6c\u6362\u4e3a\u53ef\u89e3\u91ca\u7684\u6587\u672c\u6458\u8981\uff0c\u7136\u540e\u901a\u8fc7\u53cc\u5854\u67b6\u6784\u5c06\u8fd9\u4e9b\u6458\u8981\u4e0e\u5386\u53f2\u9700\u6c42\u7279\u5f81\u878d\u5408\uff0c\u5b9e\u73b0\u51c6\u786e\u3001\u53ef\u89e3\u91ca\u4e14\u53ef\u6269\u5c55\u7684\u9884\u6d4b\u3002", "result": "\u57284\u4e2a\u56fd\u5bb6160\u4e2a\u5730\u533a10\u4e2a\u6708\u7684\u771f\u5b9e\u7535\u5546\u573a\u666f\u4e2d\uff0cEventCast\u76f8\u6bd4\u65e0\u4e8b\u4ef6\u77e5\u8bc6\u7684\u53d8\u4f53\u5728MAE\u548cMSE\u4e0a\u5206\u522b\u63d0\u534786.9%\u548c97.7%\uff0c\u76f8\u6bd4\u6700\u4f73\u5de5\u4e1a\u57fa\u7ebf\u5728\u4e8b\u4ef6\u9a71\u52a8\u671f\u95f4\u5206\u522b\u51cf\u5c1157.0%\u7684MAE\u548c83.3%\u7684MSE\u3002\u81ea2025\u5e743\u6708\u8d77\u5df2\u90e8\u7f72\u5230\u5b9e\u9645\u5de5\u4e1a\u7ba1\u9053\u4e2d\u3002", "conclusion": "EventCast\u901a\u8fc7\u5c06LLM\u7684\u4e8b\u4ef6\u63a8\u7406\u80fd\u529b\u4e0e\u4f20\u7edf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u76f8\u7ed3\u5408\uff0c\u4e3a\u52a8\u6001\u7535\u5546\u73af\u5883\u4e2d\u7684\u8fd0\u8425\u51b3\u7b56\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7279\u6b8a\u4e8b\u4ef6\u671f\u95f4\u7684\u9700\u6c42\u9884\u6d4b\u51c6\u786e\u6027\u3002"}}
{"id": "2602.08993", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.08993", "abs": "https://arxiv.org/abs/2602.08993", "authors": ["Eloise Christian", "Tejas Gadwalkar", "Arthur Azevedo de Amorim", "Edward V. Zieglar"], "title": "Reverse Online Guessing Attacks on PAKE Protocols", "comment": null, "summary": "Though not yet widely deployed, password-authenticated key exchange (PAKE) protocols have been the subject of several recent standardization efforts, partly because of their resistance against various guessing attacks, but also because they do not require a public-key infrastructure (PKI), making them naturally resistant against PKI failures. The goal of this paper is to reevaluate the PAKE model by noting that the absence of a PKI -- or, more generally, of a mechanism aside from the password for authenticating the server -- makes such protocols vulnerable to reverse online guessing attacks, in which an adversary attempts to validate password guesses by impersonating a server. While their logic is similar to traditional guessing, where the attacker impersonates a client, reverse guessing poses a unique risk because the burden of detection is shifted to the clients, rendering existing defenses against traditional guessing moot. Our results demonstrate that reverse guessing is particularly effective when an adversary attacks clients indiscriminately, such as in phishing or password-spraying attacks, or for applications with automated login processes or a universal password, such as WPA3-SAE. Our analysis suggests that stakeholders should, by default, authenticate the server using more stringent measures than just the user's password, and that a password-only mode of operation should be a last resort against catastrophic security failures when other authentication mechanisms are not available.", "AI": {"tldr": "PAKE\u534f\u8bae\u867d\u7136\u80fd\u62b5\u6297\u4f20\u7edf\u731c\u6d4b\u653b\u51fb\u4e14\u65e0\u9700PKI\uff0c\u4f46\u7f3a\u4e4f\u670d\u52a1\u5668\u8ba4\u8bc1\u673a\u5236\u4f7f\u5176\u6613\u53d7\u53cd\u5411\u5728\u7ebf\u731c\u6d4b\u653b\u51fb\uff0c\u653b\u51fb\u8005\u901a\u8fc7\u5192\u5145\u670d\u52a1\u5668\u9a8c\u8bc1\u5bc6\u7801\u731c\u6d4b\uff0c\u5efa\u8bae\u9ed8\u8ba4\u91c7\u7528\u6bd4\u5bc6\u7801\u66f4\u4e25\u683c\u7684\u670d\u52a1\u5668\u8ba4\u8bc1\u63aa\u65bd", "motivation": "\u91cd\u65b0\u8bc4\u4f30PAKE\u534f\u8bae\u6a21\u578b\uff0c\u6307\u51fa\u7531\u4e8e\u7f3a\u4e4fPKI\u6216\u5176\u4ed6\u670d\u52a1\u5668\u8ba4\u8bc1\u673a\u5236\uff0cPAKE\u534f\u8bae\u5bb9\u6613\u53d7\u5230\u53cd\u5411\u5728\u7ebf\u731c\u6d4b\u653b\u51fb\uff0c\u653b\u51fb\u8005\u901a\u8fc7\u5192\u5145\u670d\u52a1\u5668\u6765\u9a8c\u8bc1\u5bc6\u7801\u731c\u6d4b\uff0c\u8fd9\u79cd\u653b\u51fb\u65b9\u5f0f\u5c06\u68c0\u6d4b\u8d1f\u62c5\u8f6c\u79fb\u7ed9\u5ba2\u6237\u7aef\uff0c\u4f7f\u73b0\u6709\u9632\u5fa1\u63aa\u65bd\u5931\u6548", "method": "\u5206\u6790PAKE\u534f\u8bae\u7684\u5b89\u5168\u6a21\u578b\uff0c\u8bc6\u522b\u53cd\u5411\u731c\u6d4b\u653b\u51fb\u7684\u903b\u8f91\u548c\u98ce\u9669\uff0c\u7814\u7a76\u653b\u51fb\u5728\u9493\u9c7c\u653b\u51fb\u3001\u5bc6\u7801\u55b7\u6d12\u653b\u51fb\u3001\u81ea\u52a8\u5316\u767b\u5f55\u6d41\u7a0b\u6216\u901a\u7528\u5bc6\u7801\u573a\u666f\uff08\u5982WPA3-SAE\uff09\u4e2d\u7684\u6709\u6548\u6027", "result": "\u53cd\u5411\u731c\u6d4b\u653b\u51fb\u5728\u653b\u51fb\u8005\u65e0\u5dee\u522b\u653b\u51fb\u5ba2\u6237\u7aef\u65f6\u7279\u522b\u6709\u6548\uff0c\u4f8b\u5982\u5728\u9493\u9c7c\u653b\u51fb\u6216\u5bc6\u7801\u55b7\u6d12\u653b\u51fb\u4e2d\uff0c\u6216\u8005\u9488\u5bf9\u5177\u6709\u81ea\u52a8\u5316\u767b\u5f55\u6d41\u7a0b\u6216\u901a\u7528\u5bc6\u7801\u7684\u5e94\u7528\u573a\u666f", "conclusion": "\u5229\u76ca\u76f8\u5173\u8005\u5e94\u9ed8\u8ba4\u4f7f\u7528\u6bd4\u7528\u6237\u5bc6\u7801\u66f4\u4e25\u683c\u7684\u63aa\u65bd\u6765\u8ba4\u8bc1\u670d\u52a1\u5668\uff0c\u4ec5\u5bc6\u7801\u64cd\u4f5c\u6a21\u5f0f\u5e94\u4f5c\u4e3a\u6700\u540e\u624b\u6bb5\uff0c\u4ec5\u5728\u53d1\u751f\u707e\u96be\u6027\u5b89\u5168\u6545\u969c\u4e14\u5176\u4ed6\u8ba4\u8bc1\u673a\u5236\u4e0d\u53ef\u7528\u65f6\u4f7f\u7528"}}
{"id": "2602.07749", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07749", "abs": "https://arxiv.org/abs/2602.07749", "authors": ["Zhenyu Wu", "Yanxi Long", "Jian Li", "Hua Huang"], "title": "Geo-Code: A Code Framework for Reverse Code Generation from Geometric Images Based on Two-Stage Multi-Agent Evolution", "comment": "ICML2026", "summary": "Program code serves as a bridge linking vision and logic, providing a feasible supervisory approach for enhancing the multimodal reasoning capability of large models through geometric operations such as auxiliary line construction and perspective transformation. Nevertheless, current inverse graphics methods face tremendous challenges in accurately reconstructing complex geometric details, which often results in the loss of key geometric constraints or structural distortion. To address this bottleneck, we propose Geo-coder -- the first inverse programming framework for geometric images based on a multi-agent system. Our method innovatively decouples the process into geometric modeling via pixel-wise anchoring and metric-driven code evolution: Stage 1 leverages the complementary advantages of visual operators and large models to achieve precise capture of pixel coordinates and visual attributes; Stage 2 introduces a synthesis-rendering-validation closed loop, where bidirectional visual feedback drives the self-correction of code. Extensive experiments demonstrate that Geo-coder achieves a substantial lead in both geometric reconstruction accuracy and visual consistency. Notably, by effectively preserving the core geometric semantics, the images reconstructed with our method exhibit equivalent performance to the original ones in multimodal reasoning tasks, which fully validates the robustness of the framework. Finally, to further reduce research costs, we have open-sourced the Geo-coder dataset constructed on the GeoCode framework, which contains more than 1,500 samples. On this basis, we have also open-sourced the GeocodeLM model, laying a solid data and model foundation for subsequent research in this field.", "AI": {"tldr": "Geo-coder\uff1a\u9996\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u51e0\u4f55\u56fe\u50cf\u9006\u5411\u7f16\u7a0b\u6846\u67b6\uff0c\u901a\u8fc7\u50cf\u7d20\u7ea7\u951a\u5b9a\u548c\u5ea6\u91cf\u9a71\u52a8\u4ee3\u7801\u6f14\u5316\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u51e0\u4f55\u91cd\u5efa\uff0c\u5728\u51e0\u4f55\u91cd\u5efa\u7cbe\u5ea6\u548c\u89c6\u89c9\u4e00\u81f4\u6027\u65b9\u9762\u663e\u8457\u9886\u5148\u3002", "motivation": "\u7a0b\u5e8f\u4ee3\u7801\u4f5c\u4e3a\u8fde\u63a5\u89c6\u89c9\u4e0e\u903b\u8f91\u7684\u6865\u6881\uff0c\u4e3a\u901a\u8fc7\u51e0\u4f55\u64cd\u4f5c\u589e\u5f3a\u5927\u6a21\u578b\u591a\u6a21\u6001\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u53ef\u884c\u76d1\u7763\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u5f53\u524d\u9006\u5411\u56fe\u5f62\u65b9\u6cd5\u5728\u51c6\u786e\u91cd\u5efa\u590d\u6742\u51e0\u4f55\u7ec6\u8282\u65b9\u9762\u9762\u4e34\u5de8\u5927\u6311\u6218\uff0c\u5e38\u5bfc\u81f4\u5173\u952e\u51e0\u4f55\u7ea6\u675f\u4e22\u5931\u6216\u7ed3\u6784\u5931\u771f\u3002", "method": "\u63d0\u51fa\u9996\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u51e0\u4f55\u56fe\u50cf\u9006\u5411\u7f16\u7a0b\u6846\u67b6Geo-coder\uff0c\u521b\u65b0\u6027\u5730\u5c06\u8fc7\u7a0b\u89e3\u8026\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff1a1\uff09\u901a\u8fc7\u50cf\u7d20\u7ea7\u951a\u5b9a\u8fdb\u884c\u51e0\u4f55\u5efa\u6a21\uff0c\u5229\u7528\u89c6\u89c9\u7b97\u5b50\u4e0e\u5927\u6a21\u578b\u7684\u4e92\u8865\u4f18\u52bf\u7cbe\u786e\u6355\u83b7\u50cf\u7d20\u5750\u6807\u548c\u89c6\u89c9\u5c5e\u6027\uff1b2\uff09\u5f15\u5165\u5408\u6210-\u6e32\u67d3-\u9a8c\u8bc1\u95ed\u73af\uff0c\u901a\u8fc7\u53cc\u5411\u89c6\u89c9\u53cd\u9988\u9a71\u52a8\u4ee3\u7801\u81ea\u6821\u6b63\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cGeo-coder\u5728\u51e0\u4f55\u91cd\u5efa\u7cbe\u5ea6\u548c\u89c6\u89c9\u4e00\u81f4\u6027\u65b9\u9762\u53d6\u5f97\u663e\u8457\u9886\u5148\u3002\u901a\u8fc7\u6709\u6548\u4fdd\u7559\u6838\u5fc3\u51e0\u4f55\u8bed\u4e49\uff0c\u91cd\u5efa\u56fe\u50cf\u5728\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4e0e\u539f\u59cb\u56fe\u50cf\u76f8\u5f53\u7684\u6027\u80fd\u3002\u5f00\u6e90\u4e86\u5305\u542b1500+\u6837\u672c\u7684Geo-coder\u6570\u636e\u96c6\u548cGeocodeLM\u6a21\u578b\u3002", "conclusion": "Geo-coder\u6846\u67b6\u901a\u8fc7\u521b\u65b0\u7684\u591a\u667a\u80fd\u4f53\u9006\u5411\u7f16\u7a0b\u65b9\u6cd5\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u590d\u6742\u51e0\u4f55\u7ec6\u8282\u91cd\u5efa\u7684\u74f6\u9888\u95ee\u9898\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u6570\u636e\u548c\u6a21\u578b\u57fa\u7840\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u7814\u7a76\u6210\u672c\u3002"}}
{"id": "2602.07754", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.07754", "abs": "https://arxiv.org/abs/2602.07754", "authors": ["Bahare Riahi", "Veronica Catete"], "title": "Humanizing AI Grading: Student-Centered Insights on Fairness, Trust, Consistency and Transparency", "comment": "13 pages, 3 figures", "summary": "This study investigates students' perceptions of Artificial Intelligence (AI) grading systems in an undergraduate computer science course (n = 27), focusing on a block-based programming final project. Guided by the ethical principles framework articulated by Jobin (2019), our study examines fairness, trust, consistency, and transparency in AI grading by comparing AI-generated feedback with original human-graded feedback. Findings reveal concerns about AI's lack of contextual understanding and personalization. We recommend that equitable and trustworthy AI systems reflect human judgment, flexibility, and empathy, serving as supplementary tools under human oversight. This work contributes to ethics-centered assessment practices by amplifying student voices and offering design principles for humanizing AI in designed learning environments.", "AI": {"tldr": "\u7814\u7a76\u8c03\u67e5\u672c\u79d1\u751f\u5bf9AI\u8bc4\u5206\u7cfb\u7edf\u7684\u770b\u6cd5\uff0c\u53d1\u73b0\u5b66\u751f\u62c5\u5fe7AI\u7f3a\u4e4f\u60c5\u5883\u7406\u89e3\u548c\u4e2a\u6027\u5316\uff0c\u5efa\u8baeAI\u5e94\u4f5c\u4e3a\u4eba\u7c7b\u76d1\u7763\u4e0b\u7684\u8865\u5145\u5de5\u5177", "motivation": "\u968f\u7740AI\u5728\u6559\u80b2\u8bc4\u4f30\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u589e\u591a\uff0c\u9700\u8981\u4e86\u89e3\u5b66\u751f\u5bf9AI\u8bc4\u5206\u7cfb\u7edf\u7684\u770b\u6cd5\uff0c\u7279\u522b\u662f\u5173\u6ce8\u516c\u5e73\u6027\u3001\u4fe1\u4efb\u5ea6\u3001\u4e00\u81f4\u6027\u548c\u900f\u660e\u5ea6\u7b49\u4f26\u7406\u95ee\u9898", "method": "\u91c7\u7528Jobin\uff082019\uff09\u7684\u4f26\u7406\u539f\u5219\u6846\u67b6\uff0c\u5728\u672c\u79d1\u8ba1\u7b97\u673a\u79d1\u5b66\u8bfe\u7a0b\u4e2d\uff08n=27\uff09\u7814\u7a76\u5b66\u751f\u5bf9AI\u8bc4\u5206\u7cfb\u7edf\u7684\u770b\u6cd5\uff0c\u901a\u8fc7\u6bd4\u8f83AI\u751f\u6210\u7684\u53cd\u9988\u4e0e\u539f\u59cb\u4eba\u5de5\u8bc4\u5206\u53cd\u9988", "result": "\u7814\u7a76\u53d1\u73b0\u5b66\u751f\u5bf9AI\u8bc4\u5206\u7cfb\u7edf\u5b58\u5728\u62c5\u5fe7\uff0c\u7279\u522b\u662fAI\u7f3a\u4e4f\u60c5\u5883\u7406\u89e3\u548c\u4e2a\u6027\u5316\u80fd\u529b\uff0cAI\u53cd\u9988\u4e0e\u4eba\u7c7b\u53cd\u9988\u5b58\u5728\u5dee\u5f02", "conclusion": "\u5efa\u8bae\u5f00\u53d1\u516c\u5e73\u53ef\u4fe1\u7684AI\u7cfb\u7edf\u5e94\u53cd\u6620\u4eba\u7c7b\u5224\u65ad\u3001\u7075\u6d3b\u6027\u548c\u540c\u7406\u5fc3\uff0c\u4f5c\u4e3a\u4eba\u7c7b\u76d1\u7763\u4e0b\u7684\u8865\u5145\u5de5\u5177\uff0c\u4e3a\u6559\u80b2\u73af\u5883\u4e2d\u7684\u4eba\u6027\u5316AI\u8bbe\u8ba1\u63d0\u4f9b\u539f\u5219"}}
{"id": "2602.08214", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.08214", "abs": "https://arxiv.org/abs/2602.08214", "authors": ["Ziwei Wang", "Yuanhe Zhang", "Jing Chen", "Zhenhong Zhou", "Ruichao Liang", "Ruiying Du", "Ju Jia", "Cong Wu", "Yang Liu"], "title": "RECUR: Resource Exhaustion Attack via Recursive-Entropy Guided Counterfactual Utilization and Reflection", "comment": null, "summary": "Large Reasoning Models (LRMs) employ reasoning to address complex tasks. Such explicit reasoning requires extended context lengths, resulting in substantially higher resource consumption. Prior work has shown that adversarially crafted inputs can trigger redundant reasoning processes, exposing LRMs to resource-exhaustion vulnerabilities. However, the reasoning process itself, especially its reflective component, has received limited attention, even though it can lead to over-reflection and consume excessive computing power. In this paper, we introduce Recursive Entropy to quantify the risk of resource consumption in reflection, thereby revealing the safety issues inherent in inference itself. Based on Recursive Entropy, we introduce RECUR, a resource exhaustion attack via Recursive Entropy guided Counterfactual Utilization and Reflection. It constructs counterfactual questions to verify the inherent flaws and risks of LRMs. Extensive experiments demonstrate that, under benign inference, recursive entropy exhibits a pronounced decreasing trend. RECUR disrupts this trend, increasing the output length by up to 11x and decreasing throughput by 90%. Our work provides a new perspective on robust reasoning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faRECUR\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u9012\u5f52\u71b5\u5f15\u5bfc\u7684\u53cd\u4e8b\u5b9e\u5229\u7528\u548c\u53cd\u5c04\uff0c\u63ed\u793a\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5b58\u5728\u7684\u8d44\u6e90\u8017\u5c3d\u5b89\u5168\u6f0f\u6d1e\uff0c\u4f7f\u8f93\u51fa\u957f\u5ea6\u589e\u52a011\u500d\uff0c\u541e\u5410\u91cf\u4e0b\u964d90%\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b(LRMs)\u7684\u663e\u5f0f\u63a8\u7406\u9700\u8981\u6269\u5c55\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u5bfc\u81f4\u8d44\u6e90\u6d88\u8017\u663e\u8457\u589e\u52a0\u3002\u5148\u524d\u7814\u7a76\u8868\u660e\u5bf9\u6297\u6027\u8f93\u5165\u53ef\u80fd\u89e6\u53d1\u5197\u4f59\u63a8\u7406\u8fc7\u7a0b\uff0c\u4f46\u63a8\u7406\u8fc7\u7a0b\u672c\u8eab\uff0c\u7279\u522b\u662f\u5176\u53cd\u601d\u7ec4\u4ef6\uff0c\u5c1a\u672a\u5f97\u5230\u8db3\u591f\u5173\u6ce8\uff0c\u53ef\u80fd\u5bfc\u81f4\u8fc7\u5ea6\u53cd\u601d\u5e76\u6d88\u8017\u8fc7\u591a\u8ba1\u7b97\u8d44\u6e90\u3002", "method": "\u63d0\u51fa\u9012\u5f52\u71b5\u6765\u91cf\u5316\u53cd\u601d\u8fc7\u7a0b\u4e2d\u7684\u8d44\u6e90\u6d88\u8017\u98ce\u9669\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f00\u53d1RECUR\u653b\u51fb\u65b9\u6cd5\u3002RECUR\u901a\u8fc7\u9012\u5f52\u71b5\u5f15\u5bfc\u7684\u53cd\u4e8b\u5b9e\u5229\u7528\u548c\u53cd\u5c04\uff0c\u6784\u5efa\u53cd\u4e8b\u5b9e\u95ee\u9898\u6765\u9a8c\u8bc1LRMs\u7684\u5185\u5728\u7f3a\u9677\u548c\u98ce\u9669\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u826f\u6027\u63a8\u7406\u4e0b\uff0c\u9012\u5f52\u71b5\u5448\u73b0\u660e\u663e\u4e0b\u964d\u8d8b\u52bf\u3002RECUR\u653b\u51fb\u7834\u574f\u4e86\u8fd9\u4e00\u8d8b\u52bf\uff0c\u4f7f\u8f93\u51fa\u957f\u5ea6\u589e\u52a0\u9ad8\u8fbe11\u500d\uff0c\u541e\u5410\u91cf\u4e0b\u964d90%\u3002", "conclusion": "\u672c\u7814\u7a76\u63ed\u793a\u4e86\u63a8\u7406\u672c\u8eab\u5b58\u5728\u7684\u5b89\u5168\u95ee\u9898\uff0c\u4e3a\u9c81\u68d2\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u8868\u660e\u9700\u8981\u5173\u6ce8\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u8d44\u6e90\u6d88\u8017\u98ce\u9669\u3002"}}
{"id": "2602.08866", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08866", "abs": "https://arxiv.org/abs/2602.08866", "authors": ["Bang Xie", "Senjian Zhang", "Zhiyuan Peng", "Wei Chen", "Chenhao Ying", "Yuan Luo"], "title": "ArkEval: Benchmarking and Evaluating Automated CodeRepair for ArkTS", "comment": null, "summary": "Large language models have transformed code generation, enabling unprecedented automation in software development. As mobile ecosystems evolve, HarmonyOS has emerged as a critical platform requiring robust development tools. Software development for the HarmonyOS ecosystem relies heavily on ArkTS, a statically typed extension of TypeScript. Despite its growing importance, the ecosystem lacks robust tools for automated code repair, primarily due to the absence of a high-quality benchmark for evaluation. To address this gap, we present ArkEval, a unified framework for ArkTS automated repair workflow evaluation and benchmark construction. It provides the first comprehensive benchmark specifically designed for ArkTS automated program repair. We constructed this benchmark by mining issues from a large-scale official Huawei repository containing over 400 independent ArkTS applications. Through a rigorous multi-stage filtering process, we curated 502 reproducible issues. To ensure testability, we employed a novel LLM-based test generation and voting mechanism involving Claude and other models. Furthermore, we standardized problem statements to facilitate fair evaluation. Finally, we evaluated four state-of-the-art Large Language Models (LLMs) on our benchmark using a retrieval-augmented repair workflow. Our results highlight the current capabilities and limitations of LLMs in repairing ArkTS code, paving the way for future research in this low-resource language domain.", "AI": {"tldr": "ArkEval\uff1a\u9996\u4e2a\u9488\u5bf9ArkTS\u81ea\u52a8\u5316\u7a0b\u5e8f\u4fee\u590d\u7684\u7edf\u4e00\u8bc4\u4f30\u6846\u67b6\u548c\u57fa\u51c6\uff0c\u5305\u542b502\u4e2a\u53ef\u590d\u73b0\u95ee\u9898\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728HarmonyOS\u751f\u6001\u4e2d\u7684\u4ee3\u7801\u4fee\u590d\u80fd\u529b\u3002", "motivation": "\u968f\u7740HarmonyOS\u751f\u6001\u7cfb\u7edf\u7684\u5174\u8d77\uff0cArkTS\u4f5c\u4e3a\u5176\u6838\u5fc3\u5f00\u53d1\u8bed\u8a00\u7f3a\u4e4f\u81ea\u52a8\u5316\u4ee3\u7801\u4fee\u590d\u5de5\u5177\u548c\u8bc4\u4f30\u57fa\u51c6\uff0c\u963b\u788d\u4e86\u8be5\u9886\u57df\u7684\u7814\u7a76\u8fdb\u5c55\u3002", "method": "1. \u4ece\u534e\u4e3a\u5b98\u65b9\u5305\u542b400\u591a\u4e2aArkTS\u5e94\u7528\u7684\u4ed3\u5e93\u4e2d\u6316\u6398\u95ee\u9898\uff1b2. \u901a\u8fc7\u591a\u9636\u6bb5\u8fc7\u6ee4\u6d41\u7a0b\u7b5b\u9009\u51fa502\u4e2a\u53ef\u590d\u73b0\u95ee\u9898\uff1b3. \u4f7f\u7528\u57fa\u4e8eLLM\u7684\u6d4b\u8bd5\u751f\u6210\u548c\u6295\u7968\u673a\u5236\u786e\u4fdd\u53ef\u6d4b\u8bd5\u6027\uff1b4. \u6807\u51c6\u5316\u95ee\u9898\u63cf\u8ff0\u4ee5\u652f\u6301\u516c\u5e73\u8bc4\u4f30\uff1b5. \u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u7684\u4fee\u590d\u5de5\u4f5c\u6d41\u8bc4\u4f30\u56db\u4e2a\u5148\u8fdbLLM\u3002", "result": "\u5efa\u7acb\u4e86\u9996\u4e2aArkTS\u81ea\u52a8\u5316\u7a0b\u5e8f\u4fee\u590d\u57fa\u51c6\uff0c\u5305\u542b502\u4e2a\u9ad8\u8d28\u91cf\u53ef\u590d\u73b0\u95ee\u9898\uff0c\u5e76\u8bc4\u4f30\u4e86\u56db\u4e2a\u5148\u8fdbLLM\u5728\u8be5\u57fa\u51c6\u4e0a\u7684\u8868\u73b0\uff0c\u63ed\u793a\u4e86\u5f53\u524dLLM\u5728ArkTS\u4ee3\u7801\u4fee\u590d\u65b9\u9762\u7684\u80fd\u529b\u548c\u5c40\u9650\u6027\u3002", "conclusion": "ArkEval\u586b\u8865\u4e86ArkTS\u81ea\u52a8\u5316\u7a0b\u5e8f\u4fee\u590d\u9886\u57df\u7684\u8bc4\u4f30\u7a7a\u767d\uff0c\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u9886\u57df\u7684\u672a\u6765\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5c55\u793a\u4e86LLM\u5728HarmonyOS\u751f\u6001\u4e2d\u4ee3\u7801\u4fee\u590d\u7684\u6f5c\u529b\u548c\u6311\u6218\u3002"}}
{"id": "2602.08229", "categories": ["cs.AI", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08229", "abs": "https://arxiv.org/abs/2602.08229", "authors": ["Yifan Yang", "Jinjia Li", "Kunxi Li", "Puhao Zheng", "Yuanyi Wang", "Zheyan Qu", "Yang Yu", "Jianmin Wu", "Ming Li", "Hongxia Yang"], "title": "InfiCoEvalChain: A Blockchain-Based Decentralized Framework for Collaborative LLM Evaluation", "comment": null, "summary": "The rapid advancement of large language models (LLMs) demands increasingly reliable evaluation, yet current centralized evaluation suffers from opacity, overfitting, and hardware-induced variance. Our empirical analysis reveals an alarming inconsistency in existing evaluations: the standard deviation across ten repeated runs of a single model on HumanEval (1.67) actually exceeds the performance gap among the top-10 models on the official leaderboard (0.91), rendering current rankings statistically precarious. To mitigate these instabilities, we propose a decentralized evaluation framework that enables hardware and parameter diversity through large-scale benchmarking across heterogeneous compute nodes. By leveraging the blockchain-based protocol, the framework incentivizes global contributors to act as independent validators, using a robust reward system to ensure evaluation integrity and discourage dishonest participation. This collective verification transforms evaluation from a \"centralized black box\" into a \"decentralized endorsement\" where multi-party consensus and diverse inference environments yield a more stable, representative metric. Experimental results demonstrate that the decentralized evaluation framework reduces the standard deviation across ten runs on the same model to 0.28. This significant improvement over conventional frameworks ensures higher statistical confidence in model rankings. We have completely implemented this platform and will soon release it to the community.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u53bb\u4e2d\u5fc3\u5316\u8bc4\u4f30\u6846\u67b6\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u4e2d\u7684\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u533a\u5757\u94fe\u534f\u8bae\u6fc0\u52b1\u5168\u7403\u8d21\u732e\u8005\u4f5c\u4e3a\u72ec\u7acb\u9a8c\u8bc1\u8005\uff0c\u663e\u8457\u964d\u4f4e\u8bc4\u4f30\u65b9\u5dee\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u96c6\u4e2d\u5f0f\u8bc4\u4f30\u5b58\u5728\u4e0d\u900f\u660e\u3001\u8fc7\u62df\u5408\u548c\u786c\u4ef6\u5dee\u5f02\u5bfc\u81f4\u7684\u65b9\u5dee\u95ee\u9898\u3002\u5b9e\u8bc1\u5206\u6790\u663e\u793a\uff0cHumanEval\u4e0a\u5355\u4e2a\u6a21\u578b\u5341\u6b21\u8fd0\u884c\u7684\u6807\u51c6\u5dee\uff081.67\uff09\u8d85\u8fc7\u4e86\u5b98\u65b9\u6392\u884c\u699c\u524d\u5341\u540d\u6a21\u578b\u7684\u6027\u80fd\u5dee\u8ddd\uff080.91\uff09\uff0c\u4f7f\u5f97\u5f53\u524d\u6392\u540d\u7edf\u8ba1\u4e0a\u4e0d\u53ef\u9760\u3002", "method": "\u63d0\u51fa\u53bb\u4e2d\u5fc3\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u5229\u7528\u533a\u5757\u94fe\u534f\u8bae\u6fc0\u52b1\u5168\u7403\u8d21\u732e\u8005\u4f5c\u4e3a\u72ec\u7acb\u9a8c\u8bc1\u8005\uff0c\u901a\u8fc7\u5f02\u6784\u8ba1\u7b97\u8282\u70b9\u8fdb\u884c\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5b9e\u73b0\u786c\u4ef6\u548c\u53c2\u6570\u591a\u6837\u6027\u3002\u91c7\u7528\u7a33\u5065\u7684\u5956\u52b1\u7cfb\u7edf\u786e\u4fdd\u8bc4\u4f30\u5b8c\u6574\u6027\uff0c\u9632\u6b62\u4e0d\u8bda\u5b9e\u53c2\u4e0e\u3002", "result": "\u53bb\u4e2d\u5fc3\u5316\u8bc4\u4f30\u6846\u67b6\u5c06\u540c\u4e00\u6a21\u578b\u5341\u6b21\u8fd0\u884c\u7684\u6807\u51c6\u5dee\u964d\u4f4e\u52300.28\uff0c\u76f8\u6bd4\u4f20\u7edf\u6846\u67b6\u663e\u8457\u6539\u5584\uff0c\u4e3a\u6a21\u578b\u6392\u540d\u63d0\u4f9b\u66f4\u9ad8\u7684\u7edf\u8ba1\u7f6e\u4fe1\u5ea6\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c06\u8bc4\u4f30\u4ece\"\u96c6\u4e2d\u5f0f\u9ed1\u7bb1\"\u8f6c\u53d8\u4e3a\"\u53bb\u4e2d\u5fc3\u5316\u80cc\u4e66\"\uff0c\u901a\u8fc7\u591a\u65b9\u5171\u8bc6\u548c\u591a\u6837\u5316\u63a8\u7406\u73af\u5883\u4ea7\u751f\u66f4\u7a33\u5b9a\u3001\u66f4\u5177\u4ee3\u8868\u6027\u7684\u8bc4\u4f30\u6307\u6807\u3002\u5e73\u53f0\u5df2\u5b8c\u5168\u5b9e\u73b0\u5e76\u5c06\u5411\u793e\u533a\u53d1\u5e03\u3002"}}
{"id": "2602.08887", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08887", "abs": "https://arxiv.org/abs/2602.08887", "authors": ["Adam Trendowicz", "Daniel Seifert", "Andreas Jedlitschka", "Marcus Ciolkowski", "Anton Strahilov"], "title": "DeepQuali: Initial results of a study on the use of large language models for assessing the quality of user stories", "comment": null, "summary": "Generative artificial intelligence (GAI), specifically large language models (LLMs), are increasingly used in software engineering, mainly for coding tasks. However, requirements engineering - particularly requirements validation - has seen limited application of GAI. The current focus of using GAI for requirements is on eliciting, transforming, and classifying requirements, not on quality assessment. We propose and evaluate the LLM-based (GPT-4o) approach \"DeepQuali\", for assessing and improving requirements quality in agile software development. We applied it to projects in two small companies, where we compared LLM-based quality assessments with expert judgments. Experts also participated in walkthroughs of the solution, provided feedback, and rated their acceptance of the approach. Experts largely agreed with the LLM's quality assessments, especially regarding overall ratings and explanations. However, they did not always agree with the other experts on detailed ratings, suggesting that expertise and experience may influence judgments. Experts recognized the usefulness of the approach but criticized the lack of integration into their workflow. LLMs show potential in supporting software engineers with the quality assessment and improvement of requirements. The explicit use of quality models and explanatory feedback increases acceptance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u540d\u4e3a\"DeepQuali\"\u7684\u57fa\u4e8eGPT-4o\u7684LLM\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u6539\u8fdb\u654f\u6377\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u9700\u6c42\u8d28\u91cf\uff0c\u5e76\u5728\u4e24\u5bb6\u5c0f\u578b\u516c\u53f8\u4e2d\u8fdb\u884c\u4e86\u5e94\u7528\u8bc4\u4f30\u3002", "motivation": "\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08\u7279\u522b\u662f\u5927\u8bed\u8a00\u6a21\u578b\uff09\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u4e3b\u8981\u5e94\u7528\u4e8e\u7f16\u7801\u4efb\u52a1\uff0c\u4f46\u5728\u9700\u6c42\u5de5\u7a0b\u9886\u57df\uff0c\u7279\u522b\u662f\u9700\u6c42\u9a8c\u8bc1\u65b9\u9762\u7684\u5e94\u7528\u6709\u9650\u3002\u5f53\u524dGAI\u5728\u9700\u6c42\u65b9\u9762\u7684\u5e94\u7528\u4e3b\u8981\u96c6\u4e2d\u5728\u9700\u6c42\u83b7\u53d6\u3001\u8f6c\u6362\u548c\u5206\u7c7b\uff0c\u800c\u975e\u8d28\u91cf\u8bc4\u4f30\u3002", "method": "\u63d0\u51fa\u5e76\u8bc4\u4f30\u4e86\u57fa\u4e8eGPT-4o\u7684\"DeepQuali\"\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u6539\u8fdb\u654f\u6377\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u9700\u6c42\u8d28\u91cf\u3002\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8e\u4e24\u5bb6\u5c0f\u578b\u516c\u53f8\u7684\u9879\u76ee\u4e2d\uff0c\u5c06LLM\u7684\u8d28\u91cf\u8bc4\u4f30\u4e0e\u4e13\u5bb6\u5224\u65ad\u8fdb\u884c\u6bd4\u8f83\uff0c\u5e76\u901a\u8fc7\u4e13\u5bb6\u8d70\u67e5\u3001\u53cd\u9988\u6536\u96c6\u548c\u63a5\u53d7\u5ea6\u8bc4\u5206\u6765\u8bc4\u4f30\u65b9\u6cd5\u6548\u679c\u3002", "result": "\u4e13\u5bb6\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u540c\u610fLLM\u7684\u8d28\u91cf\u8bc4\u4f30\uff0c\u7279\u522b\u662f\u5728\u6574\u4f53\u8bc4\u5206\u548c\u89e3\u91ca\u65b9\u9762\u3002\u7136\u800c\uff0c\u4e13\u5bb6\u4e4b\u95f4\u5728\u8be6\u7ec6\u8bc4\u5206\u4e0a\u5e76\u4e0d\u603b\u662f\u4e00\u81f4\uff0c\u8fd9\u8868\u660e\u4e13\u4e1a\u77e5\u8bc6\u548c\u7ecf\u9a8c\u53ef\u80fd\u5f71\u54cd\u5224\u65ad\u3002\u4e13\u5bb6\u8ba4\u53ef\u8be5\u65b9\u6cd5\u7684\u5b9e\u7528\u6027\uff0c\u4f46\u6279\u8bc4\u5176\u7f3a\u4e4f\u4e0e\u5de5\u4f5c\u6d41\u7a0b\u7684\u96c6\u6210\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u652f\u6301\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u8fdb\u884c\u9700\u6c42\u8d28\u91cf\u8bc4\u4f30\u548c\u6539\u8fdb\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\u3002\u660e\u786e\u4f7f\u7528\u8d28\u91cf\u6a21\u578b\u548c\u89e3\u91ca\u6027\u53cd\u9988\u53ef\u4ee5\u63d0\u9ad8\u63a5\u53d7\u5ea6\u3002\u672a\u6765\u7684\u5de5\u4f5c\u9700\u8981\u66f4\u597d\u5730\u5c06LLM\u65b9\u6cd5\u96c6\u6210\u5230\u5b9e\u9645\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u3002"}}
{"id": "2602.08401", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.08401", "abs": "https://arxiv.org/abs/2602.08401", "authors": ["Liwen Wang", "Zongjie Li", "Yuchong Xie", "Shuai Wang", "Dongdong She", "Wei Wang", "Juergen Rahmel"], "title": "On Protecting Agentic Systems' Intellectual Property via Watermarking", "comment": null, "summary": "The evolution of Large Language Models (LLMs) into agentic systems that perform autonomous reasoning and tool use has created significant intellectual property (IP) value. We demonstrate that these systems are highly vulnerable to imitation attacks, where adversaries steal proprietary capabilities by training imitation models on victim outputs. Crucially, existing LLM watermarking techniques fail in this domain because real-world agentic systems often operate as grey boxes, concealing the internal reasoning traces required for verification. This paper presents AGENTWM, the first watermarking framework designed specifically for agentic models. AGENTWM exploits the semantic equivalence of action sequences, injecting watermarks by subtly biasing the distribution of functionally identical tool execution paths. This mechanism allows AGENTWM to embed verifiable signals directly into the visible action trajectory while remaining indistinguishable to users. We develop an automated pipeline to generate robust watermark schemes and a rigorous statistical hypothesis testing procedure for verification. Extensive evaluations across three complex domains demonstrate that AGENTWM achieves high detection accuracy with negligible impact on agent performance. Our results confirm that AGENTWM effectively protects agentic IP against adaptive adversaries, who cannot remove the watermarks without severely degrading the stolen model's utility.", "AI": {"tldr": "AGENTWM\u662f\u9996\u4e2a\u4e13\u95e8\u4e3a\u667a\u80fd\u4f53\u6a21\u578b\u8bbe\u8ba1\u7684\u6c34\u5370\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u52a8\u4f5c\u5e8f\u5217\u7684\u8bed\u4e49\u7b49\u4ef7\u6027\uff0c\u5728\u529f\u80fd\u76f8\u540c\u7684\u5de5\u5177\u6267\u884c\u8def\u5f84\u4e2d\u6ce8\u5165\u6c34\u5370\uff0c\u6709\u6548\u4fdd\u62a4\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u77e5\u8bc6\u4ea7\u6743\u514d\u53d7\u6a21\u4eff\u653b\u51fb\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\u4e3a\u80fd\u591f\u81ea\u4e3b\u63a8\u7406\u548c\u4f7f\u7528\u5de5\u5177\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u521b\u9020\u4e86\u91cd\u8981\u7684\u77e5\u8bc6\u4ea7\u6743\u4ef7\u503c\u3002\u8fd9\u4e9b\u7cfb\u7edf\u5bb9\u6613\u53d7\u5230\u6a21\u4eff\u653b\u51fb\uff0c\u800c\u73b0\u6709\u7684LLM\u6c34\u5370\u6280\u672f\u5728\u667a\u80fd\u4f53\u9886\u57df\u5931\u6548\uff0c\u56e0\u4e3a\u73b0\u5b9e\u4e2d\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u901a\u5e38\u662f\u7070\u76d2\uff0c\u9690\u85cf\u4e86\u9a8c\u8bc1\u6240\u9700\u7684\u5185\u5728\u63a8\u7406\u75d5\u8ff9\u3002", "method": "AGENTWM\u5229\u7528\u52a8\u4f5c\u5e8f\u5217\u7684\u8bed\u4e49\u7b49\u4ef7\u6027\uff0c\u901a\u8fc7\u5fae\u5999\u5730\u504f\u5411\u529f\u80fd\u76f8\u540c\u7684\u5de5\u5177\u6267\u884c\u8def\u5f84\u5206\u5e03\u6765\u6ce8\u5165\u6c34\u5370\u3002\u5f00\u53d1\u4e86\u81ea\u52a8\u751f\u6210\u9c81\u68d2\u6c34\u5370\u65b9\u6848\u7684\u6d41\u6c34\u7ebf\uff0c\u4ee5\u53ca\u7528\u4e8e\u9a8c\u8bc1\u7684\u4e25\u683c\u7edf\u8ba1\u5047\u8bbe\u68c0\u9a8c\u7a0b\u5e8f\u3002", "result": "\u5728\u4e09\u4e2a\u590d\u6742\u9886\u57df\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cAGENTWM\u5b9e\u73b0\u4e86\u9ad8\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u540c\u65f6\u5bf9\u667a\u80fd\u4f53\u6027\u80fd\u5f71\u54cd\u53ef\u5ffd\u7565\u3002\u5373\u4f7f\u9762\u5bf9\u81ea\u9002\u5e94\u653b\u51fb\u8005\uff0c\u4e5f\u65e0\u6cd5\u5728\u4e0d\u4e25\u91cd\u964d\u4f4e\u88ab\u76d7\u6a21\u578b\u6548\u7528\u7684\u60c5\u51b5\u4e0b\u79fb\u9664\u6c34\u5370\u3002", "conclusion": "AGENTWM\u662f\u9996\u4e2a\u4e13\u95e8\u4e3a\u667a\u80fd\u4f53\u6a21\u578b\u8bbe\u8ba1\u7684\u6c34\u5370\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u4fdd\u62a4\u667a\u80fd\u4f53\u77e5\u8bc6\u4ea7\u6743\uff0c\u5bf9\u6297\u6a21\u4eff\u653b\u51fb\uff0c\u586b\u8865\u4e86\u73b0\u6709\u6c34\u5370\u6280\u672f\u5728\u667a\u80fd\u4f53\u9886\u57df\u7684\u7a7a\u767d\u3002"}}
{"id": "2602.08915", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08915", "abs": "https://arxiv.org/abs/2602.08915", "authors": ["Giovanni Pinna", "Jingzhi Gong", "David Williams", "Federica Sarro"], "title": "Comparing AI Coding Agents: A Task-Stratified Analysis of Pull Request Acceptance", "comment": "Accepted by MSR'26 Mining Challenge Track", "summary": "The rapid adoption of AI-powered coding assistants is transforming software development practices, yet systematic comparisons of their effectiveness across different task types and over time remain limited. This paper presents an empirical study comparing five popular agents (OpenAI Codex, GitHub Copilot, Devin, Cursor, and Claude Code), analyzing 7,156 pull requests (PRs) from the AIDev dataset. Temporal trend analysis reveals heterogeneous evolution patterns: Devin exhibits the only consistent positive trend in acceptance rate (+0.77% per week over 32 weeks), whereas other agents remain largely stable. Our analysis suggests that the PR task type is a dominant factor influencing acceptance rates: documentation tasks achieve 82.1% acceptance compared to 66.1% for new features - a 16 percentage point gap that exceeds typical inter-agent variance for most tasks. OpenAI Codex achieves consistently high acceptance rates across all nine task categories (59.6%-88.6%), with stratified Chi-square tests confirming statistically significant advantages over other agents in several task categories. However, no single agent performs best across all task types: Claude Code leads in documentation (92.3%) and features (72.6%), while Cursor excels in fix tasks (80.4%).", "AI": {"tldr": "\u8be5\u7814\u7a76\u5bf95\u4e2aAI\u7f16\u7a0b\u52a9\u624b\u57287,156\u4e2aPR\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u8fdb\u884c\u5b9e\u8bc1\u6bd4\u8f83\uff0c\u53d1\u73b0\u4efb\u52a1\u7c7b\u578b\u662f\u5f71\u54cd\u63a5\u53d7\u7387\u7684\u4e3b\u8981\u56e0\u7d20\uff0c\u6587\u6863\u4efb\u52a1\u63a5\u53d7\u7387\u6700\u9ad8\uff0c\u4e0d\u540c\u52a9\u624b\u5728\u4e0d\u540c\u4efb\u52a1\u7c7b\u578b\u4e0a\u5404\u6709\u4f18\u52bf\u3002", "motivation": "\u867d\u7136AI\u7f16\u7a0b\u52a9\u624b\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u5feb\u901f\u666e\u53ca\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5176\u5728\u4e0d\u540c\u4efb\u52a1\u7c7b\u578b\u548c\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u6548\u679c\u7684\u7cfb\u7edf\u6027\u6bd4\u8f83\u7814\u7a76\u3002", "method": "\u4f7f\u7528AIDev\u6570\u636e\u96c6\u76847,156\u4e2aPR\u6570\u636e\uff0c\u6bd4\u8f83OpenAI Codex\u3001GitHub Copilot\u3001Devin\u3001Cursor\u548cClaude Code\u4e94\u4e2aAI\u52a9\u624b\uff0c\u5206\u6790\u65f6\u95f4\u8d8b\u52bf\u548c\u4e0d\u540c\u4efb\u52a1\u7c7b\u578b\u7684\u63a5\u53d7\u7387\u5dee\u5f02\u3002", "result": "Devin\u662f\u552f\u4e00\u5448\u73b0\u6301\u7eed\u6b63\u5411\u65f6\u95f4\u8d8b\u52bf\u7684\u52a9\u624b\uff08\u6bcf\u5468+0.77%\uff09\uff1b\u6587\u6863\u4efb\u52a1\u63a5\u53d7\u7387\u6700\u9ad8\uff0882.1%\uff09\uff0c\u65b0\u529f\u80fd\u4efb\u52a1\u6700\u4f4e\uff0866.1%\uff09\uff1bOpenAI Codex\u57289\u4e2a\u4efb\u52a1\u7c7b\u522b\u4e2d\u8868\u73b0\u6700\u7a33\u5b9a\uff1b\u4e0d\u540c\u52a9\u624b\u5728\u4e0d\u540c\u4efb\u52a1\u7c7b\u578b\u4e0a\u5404\u6709\u4f18\u52bf\u3002", "conclusion": "AI\u7f16\u7a0b\u52a9\u624b\u7684\u6548\u679c\u53d7\u4efb\u52a1\u7c7b\u578b\u663e\u8457\u5f71\u54cd\uff0c\u6ca1\u6709\u5355\u4e00\u52a9\u624b\u5728\u6240\u6709\u4efb\u52a1\u7c7b\u578b\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u5f00\u53d1\u8005\u5e94\u6839\u636e\u5177\u4f53\u4efb\u52a1\u7c7b\u578b\u9009\u62e9\u5408\u9002\u7684AI\u52a9\u624b\u3002"}}
{"id": "2602.07787", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07787", "abs": "https://arxiv.org/abs/2602.07787", "authors": ["Pierre-Louis Favreau", "Jean-Pierre Lo", "Clement Guiguet", "Charles Simon-Meunier", "Nicolas Dehandschoewercker", "Allen G. Roush", "Judah Goldfeder", "Ravid Shwartz-Ziv"], "title": "Do Multi-Agents Dream of Electric Screens? Achieving Perfect Accuracy on AndroidWorld Through Task Decomposition", "comment": null, "summary": "We present Minitap, a multi-agent system that achieves 100% success on the AndroidWorld benchmark, the first to fully solve all 116 tasks and surpassing human performance (80%). We first analyze why single-agent architectures fail: context pollution from mixed reasoning traces, silent text input failures undetected by the agent, and repetitive action loops without escape. Minitap addresses each failure through targeted mechanisms: cognitive separation across six specialized agents, deterministic post-validation of text input against device state, and meta-cognitive reasoning that detects cycles and triggers strategy changes. Ablations show multi-agent decomposition contributes +21 points over single-agent baselines; verified execution adds +7 points; meta-cognition adds +9 points. We release Minitap as open-source software. https://github.com/minitap-ai/mobile-use", "AI": {"tldr": "Minitap\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5728AndroidWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86100%\u6210\u529f\u7387\uff0c\u9996\u6b21\u5b8c\u5168\u89e3\u51b3\u4e86\u6240\u6709116\u4e2a\u4efb\u52a1\uff0c\u8d85\u8d8a\u4e86\u4eba\u7c7b80%\u7684\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u7814\u7a76\u5355\u667a\u80fd\u4f53\u67b6\u6784\u5728\u79fb\u52a8\u8bbe\u5907\u4efb\u52a1\u6267\u884c\u4e2d\u7684\u5931\u8d25\u539f\u56e0\uff1a\u6df7\u5408\u63a8\u7406\u8f68\u8ff9\u5bfc\u81f4\u7684\u4e0a\u4e0b\u6587\u6c61\u67d3\u3001\u667a\u80fd\u4f53\u65e0\u6cd5\u68c0\u6d4b\u7684\u9759\u9ed8\u6587\u672c\u8f93\u5165\u5931\u8d25\u3001\u4ee5\u53ca\u65e0\u9003\u8131\u673a\u5236\u7684\u91cd\u590d\u52a8\u4f5c\u5faa\u73af\u3002", "method": "\u901a\u8fc7\u9488\u5bf9\u6027\u673a\u5236\u89e3\u51b3\u5355\u667a\u80fd\u4f53\u5931\u8d25\u95ee\u9898\uff1a\u516d\u4e2a\u4e13\u95e8\u5316\u667a\u80fd\u4f53\u7684\u8ba4\u77e5\u5206\u79bb\u3001\u57fa\u4e8e\u8bbe\u5907\u72b6\u6001\u7684\u6587\u672c\u8f93\u5165\u786e\u5b9a\u6027\u540e\u9a8c\u8bc1\u3001\u4ee5\u53ca\u68c0\u6d4b\u5faa\u73af\u5e76\u89e6\u53d1\u7b56\u7565\u6539\u53d8\u7684\u5143\u8ba4\u77e5\u63a8\u7406\u3002", "result": "\u5728AndroidWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0100%\u6210\u529f\u7387\uff0c\u9996\u6b21\u5b8c\u5168\u89e3\u51b3\u6240\u6709116\u4e2a\u4efb\u52a1\u3002\u6d88\u878d\u5b9e\u9a8c\u663e\u793a\uff1a\u591a\u667a\u80fd\u4f53\u5206\u89e3\u6bd4\u5355\u667a\u80fd\u4f53\u57fa\u7ebf\u63d0\u534721\u4e2a\u767e\u5206\u70b9\uff1b\u9a8c\u8bc1\u6267\u884c\u589e\u52a07\u4e2a\u767e\u5206\u70b9\uff1b\u5143\u8ba4\u77e5\u589e\u52a09\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "Minitap\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u67b6\u6784\u3001\u9a8c\u8bc1\u6267\u884c\u548c\u5143\u8ba4\u77e5\u63a8\u7406\u6210\u529f\u89e3\u51b3\u4e86\u79fb\u52a8\u8bbe\u5907\u4efb\u52a1\u6267\u884c\u7684\u6311\u6218\uff0c\u8d85\u8d8a\u4e86\u4eba\u7c7b\u6027\u80fd\uff0c\u5e76\u4f5c\u4e3a\u5f00\u6e90\u8f6f\u4ef6\u53d1\u5e03\u3002"}}
{"id": "2602.07824", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07824", "abs": "https://arxiv.org/abs/2602.07824", "authors": ["Yiwei Qin", "Zhen Huang", "Tiantian Mi", "Weiye Si", "Chenyang Zhou", "Qipeng Guo", "Siyuan Feng", "Pengfei Liu"], "title": "Data Darwinism Part I: Unlocking the Value of Scientific Data for Pre-training", "comment": null, "summary": "Data quality determines foundation model performance, yet systematic processing frameworks are lacking. We introduce Data Darwinism, a ten-level taxonomy (L0-L9) that conceptualizes data-model co-evolution: advanced models produce superior data for next-generation systems. We validate this on scientific literature by constructing Darwin-Science, a 900B-token corpus (L0-L5). We identify a learnability gap in raw scientific text, which we bridge via L4 (Generative Refinement) and L5 (Cognitive Completion) using frontier LLMs to explicate reasoning and terminology.\n  To ensure rigorous attribution, we pre-trained daVinci-origin-3B/7B models from scratch, excluding scientific content to create contamination-free baselines. After 600B tokens of continued pre-training, Darwin-Science outperforms baselines by +2.12 (3B) and +2.95 (7B) points across 20+ benchmarks, rising to +5.60 and +8.40 points on domain-aligned tasks. Systematic progression to L5 yields a +1.36 total gain, confirming that higher-level processing unlocks latent data value. We release the Darwin-Science corpus and daVinci-origin models to enable principled, co-evolutionary development.", "AI": {"tldr": "\u63d0\u51fa\u4e86Data Darwinism\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u5341\u7ea7\u5206\u7c7b\u6cd5\uff08L0-L9\uff09\uff0c\u5c06\u6570\u636e\u4e0e\u6a21\u578b\u89c6\u4e3a\u5171\u540c\u8fdb\u5316\u7684\u5173\u7cfb\uff1a\u5148\u8fdb\u6a21\u578b\u4e3a\u4e0b\u4e00\u4ee3\u7cfb\u7edf\u751f\u6210\u66f4\u4f18\u8d28\u6570\u636e\u3002\u901a\u8fc7\u6784\u5efaDarwin-Science\u8bed\u6599\u5e93\uff08900B tokens\uff0cL0-L5\uff09\u9a8c\u8bc1\u8be5\u6846\u67b6\uff0c\u53d1\u73b0\u539f\u59cb\u79d1\u5b66\u6587\u672c\u5b58\u5728\u53ef\u5b66\u4e60\u6027\u5dee\u8ddd\uff0c\u4f7f\u7528\u524d\u6cbfLLM\u8fdb\u884cL4\uff08\u751f\u6210\u5f0f\u7cbe\u70bc\uff09\u548cL5\uff08\u8ba4\u77e5\u8865\u5168\uff09\u5904\u7406\u6765\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\u3002", "motivation": "\u6570\u636e\u8d28\u91cf\u51b3\u5b9a\u57fa\u7840\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u5316\u7684\u6570\u636e\u5904\u7406\u6846\u67b6\u3002\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528\u6570\u636e\u4e0e\u6a21\u578b\u4e4b\u95f4\u7684\u534f\u540c\u8fdb\u5316\u5173\u7cfb\uff0c\u7279\u522b\u662f\u5728\u79d1\u5b66\u6587\u732e\u9886\u57df\uff0c\u539f\u59cb\u6587\u672c\u5b58\u5728\u53ef\u5b66\u4e60\u6027\u5dee\u8ddd\uff0c\u9700\u8981\u66f4\u9ad8\u7ea7\u7684\u5904\u7406\u65b9\u6cd5\u6765\u91ca\u653e\u6570\u636e\u7684\u6f5c\u5728\u4ef7\u503c\u3002", "method": "1. \u63d0\u51faData Darwinism\u5341\u7ea7\u5206\u7c7b\u6cd5\uff08L0-L9\uff09\uff0c\u63cf\u8ff0\u6570\u636e\u4e0e\u6a21\u578b\u7684\u5171\u540c\u8fdb\u5316\u8fc7\u7a0b\uff1b2. \u6784\u5efaDarwin-Science\u8bed\u6599\u5e93\uff08900B tokens\uff0c\u8986\u76d6L0-L5\u7ea7\u522b\uff09\uff1b3. \u4f7f\u7528\u524d\u6cbfLLM\u8fdb\u884cL4\uff08\u751f\u6210\u5f0f\u7cbe\u70bc\uff09\u548cL5\uff08\u8ba4\u77e5\u8865\u5168\uff09\u5904\u7406\uff0c\u663e\u5f0f\u5316\u63a8\u7406\u8fc7\u7a0b\u548c\u672f\u8bed\u89e3\u91ca\uff1b4. \u4ece\u5934\u9884\u8bad\u7ec3daVinci-origin-3B/7B\u6a21\u578b\u4f5c\u4e3a\u65e0\u6c61\u67d3\u57fa\u7ebf\uff1b5. \u8fdb\u884c600B tokens\u7684\u6301\u7eed\u9884\u8bad\u7ec3\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u540c\u6570\u636e\u7ea7\u522b\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "1. Darwin-Science\u8bed\u6599\u5e93\u4f7f\u6a21\u578b\u572820+\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5206\u522b\u63d0\u5347+2.12\uff083B\uff09\u548c+2.95\uff087B\uff09\u5206\uff1b2. \u5728\u9886\u57df\u5bf9\u9f50\u4efb\u52a1\u4e0a\u63d0\u5347\u66f4\u663e\u8457\uff1a+5.60\uff083B\uff09\u548c+8.40\uff087B\uff09\u5206\uff1b3. \u4eceL0\u5230L5\u7684\u7cfb\u7edf\u6027\u8fdb\u5c55\u5e26\u6765+1.36\u5206\u7684\u603b\u589e\u76ca\uff0c\u8bc1\u5b9e\u9ad8\u7ea7\u6570\u636e\u5904\u7406\u80fd\u91ca\u653e\u6570\u636e\u6f5c\u5728\u4ef7\u503c\uff1b4. \u521b\u5efa\u4e86\u65e0\u79d1\u5b66\u5185\u5bb9\u6c61\u67d3\u7684\u57fa\u7ebf\u6a21\u578b\uff0c\u786e\u4fdd\u4e25\u8c28\u7684\u5f52\u56e0\u5206\u6790\u3002", "conclusion": "Data Darwinism\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u6570\u636e\u8d28\u91cf\u4e0e\u6a21\u578b\u6027\u80fd\u7684\u534f\u540c\u8fdb\u5316\u95ee\u9898\u3002\u9ad8\u7ea7\u6570\u636e\u5904\u7406\uff08\u7279\u522b\u662fL4\u548cL5\u7ea7\u522b\uff09\u80fd\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u9886\u57df\u7279\u5b9a\u4efb\u52a1\u4e0a\u3002\u8be5\u7814\u7a76\u4e3a\u539f\u5219\u6027\u7684\u3001\u5171\u540c\u8fdb\u5316\u7684AI\u5f00\u53d1\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\uff0c\u5e76\u5f00\u6e90\u4e86Darwin-Science\u8bed\u6599\u5e93\u548cdaVinci-origin\u6a21\u578b\u4ee5\u4fc3\u8fdb\u540e\u7eed\u7814\u7a76\u3002"}}
{"id": "2602.07830", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07830", "abs": "https://arxiv.org/abs/2602.07830", "authors": ["Jiahui Zhou", "Dan Li", "Boxin Li", "Xiao Zhang", "Erli Meng", "Lin Li", "Zhuomin Chen", "Jian Lou", "See-Kiong Ng"], "title": "Time Series Reasoning via Process-Verifiable Thinking Data Synthesis and Scheduling for Tailored LLM Reasoning", "comment": null, "summary": "Time series is a pervasive data type across various application domains, rendering the reasonable solving of diverse time series tasks a long-standing goal. Recent advances in large language models (LLMs), especially their reasoning abilities unlocked through reinforcement learning (RL), have opened new opportunities for tackling tasks with long Chain-of-Thought (CoT) reasoning. However, leveraging LLM reasoning for time series remains in its infancy, hindered by the absence of carefully curated time series CoT data for training, limited data efficiency caused by underexplored data scheduling, and the lack of RL algorithms tailored for exploiting such time series CoT data. In this paper, we introduce VeriTime, a framework that tailors LLMs for time series reasoning through data synthesis, data scheduling, and RL training. First, we propose a data synthesis pipeline that constructs a TS-text multimodal dataset with process-verifiable annotations. Second, we design a data scheduling mechanism that arranges training samples according to a principled hierarchy of difficulty and task taxonomy. Third, we develop a two-stage reinforcement finetuning featuring fine-grained, multi-objective rewards that leverage verifiable process-level CoT data. Extensive experiments show that VeriTime substantially boosts LLM performance across diverse time series reasoning tasks. Notably, it enables compact 3B, 4B models to achieve reasoning capabilities on par with or exceeding those of larger proprietary LLMs.", "AI": {"tldr": "VeriTime\u662f\u4e00\u4e2a\u901a\u8fc7\u6570\u636e\u5408\u6210\u3001\u6570\u636e\u8c03\u5ea6\u548c\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6765\u5b9a\u5236LLMs\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u7684\u6846\u67b6\uff0c\u4f7f\u5c0f\u578b\u6a21\u578b\uff083B\u30014B\uff09\u80fd\u591f\u8fbe\u5230\u6216\u8d85\u8fc7\u5927\u578b\u4e13\u6709LLMs\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5c3d\u7ba1LLMs\u5728\u63a8\u7406\u80fd\u529b\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u5728\u65f6\u95f4\u5e8f\u5217\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u4ecd\u5904\u4e8e\u65e9\u671f\u9636\u6bb5\uff0c\u4e3b\u8981\u53d7\u5230\u4e09\u4e2a\u9650\u5236\uff1a\u7f3a\u4e4f\u7cbe\u5fc3\u7b56\u5212\u7684\u65f6\u95f4\u5e8f\u5217CoT\u8bad\u7ec3\u6570\u636e\u3001\u6570\u636e\u8c03\u5ea6\u4e0d\u8db3\u5bfc\u81f4\u7684\u6570\u636e\u6548\u7387\u4f4e\u4e0b\uff0c\u4ee5\u53ca\u7f3a\u4e4f\u9488\u5bf9\u65f6\u95f4\u5e8f\u5217CoT\u6570\u636e\u4f18\u5316\u7684RL\u7b97\u6cd5\u3002", "method": "VeriTime\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u6570\u636e\u5408\u6210\u7ba1\u9053\uff0c\u6784\u5efa\u5177\u6709\u8fc7\u7a0b\u53ef\u9a8c\u8bc1\u6ce8\u91ca\u7684TS-\u6587\u672c\u591a\u6a21\u6001\u6570\u636e\u96c6\uff1b2) \u6570\u636e\u8c03\u5ea6\u673a\u5236\uff0c\u6839\u636e\u96be\u5ea6\u5c42\u6b21\u548c\u4efb\u52a1\u5206\u7c7b\u539f\u5219\u5b89\u6392\u8bad\u7ec3\u6837\u672c\uff1b3) \u4e24\u9636\u6bb5\u5f3a\u5316\u5fae\u8c03\uff0c\u5229\u7528\u53ef\u9a8c\u8bc1\u7684\u8fc7\u7a0b\u7ea7CoT\u6570\u636e\u8bbe\u8ba1\u7ec6\u7c92\u5ea6\u591a\u76ee\u6807\u5956\u52b1\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cVeriTime\u663e\u8457\u63d0\u5347\u4e86LLMs\u5728\u5404\u79cd\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5b83\u4f7f\u7d27\u51d1\u76843B\u30014B\u6a21\u578b\u80fd\u591f\u8fbe\u5230\u4e0e\u5927\u578b\u4e13\u6709LLMs\u76f8\u5f53\u751a\u81f3\u8d85\u8d8a\u7684\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "VeriTime\u901a\u8fc7\u521b\u65b0\u7684\u6570\u636e\u5408\u6210\u3001\u8c03\u5ea6\u548cRL\u8bad\u7ec3\u65b9\u6cd5\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u4e2dLLMs\u5e94\u7528\u7684\u74f6\u9888\uff0c\u4e3a\u5c0f\u578b\u6a21\u578b\u5728\u590d\u6742\u65f6\u95f4\u5e8f\u5217\u4efb\u52a1\u4e2d\u5b9e\u73b0\u9ad8\u6027\u80fd\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\u3002"}}
{"id": "2602.07849", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07849", "abs": "https://arxiv.org/abs/2602.07849", "authors": ["Xin Wang", "Hualin Zhou", "Sheng Guang Wang", "Ting Dang", "Yu Zhang", "Hong Jia", "Tao Gu"], "title": "LQA: A Lightweight Quantized-Adaptive Framework for Vision-Language Models on the Edge", "comment": "16 pages, 9 figures ,9 tables, preprint", "summary": "Deploying Vision-Language Models (VLMs) on edge devices is challenged by resource constraints and performance degradation under distribution shifts. While test-time adaptation (TTA) can counteract such shifts, existing methods are too resource-intensive for on-device deployment. To address this challenge, we propose LQA, a lightweight, quantized-adaptive framework for VLMs that combines a modality-aware quantization strategy with gradient-free test-time adaptation. We introduce Selective Hybrid Quantization (SHQ) and a quantized, gradient-free adaptation mechanism to enable robust and efficient VLM deployment on resource-constrained hardware. Experiments across both synthetic and real-world distribution shifts show that LQA improves overall adaptation performance by 4.5\\%, uses less memory than full-precision models, and significantly outperforms gradient-based TTA methods, achieving up to 19.9$\\times$ lower memory usage across seven open-source datasets. These results demonstrate that LQA offers a practical pathway for robust, privacy-preserving, and efficient VLM deployment on edge devices.", "AI": {"tldr": "LQA\u662f\u4e00\u4e2a\u8f7b\u91cf\u5316\u7684\u91cf\u5316\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u90e8\u7f72\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u6df7\u5408\u91cf\u5316\u548c\u65e0\u68af\u5ea6\u6d4b\u8bd5\u65f6\u9002\u5e94\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u6761\u4ef6\u4e0b\u63d0\u5347\u6a21\u578b\u9c81\u68d2\u6027\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u9762\u4e34\u8d44\u6e90\u9650\u5236\u548c\u5206\u5e03\u504f\u79fb\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u73b0\u6709\u6d4b\u8bd5\u65f6\u9002\u5e94\u65b9\u6cd5\u8d44\u6e90\u6d88\u8017\u8fc7\u5927\uff0c\u4e0d\u9002\u5408\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u3002", "method": "\u63d0\u51faLQA\u6846\u67b6\uff0c\u5305\u542b\u9009\u62e9\u6027\u6df7\u5408\u91cf\u5316\u7b56\u7565\uff08SHQ\uff09\u548c\u91cf\u5316\u65e0\u68af\u5ea6\u9002\u5e94\u673a\u5236\uff0c\u7ed3\u5408\u6a21\u6001\u611f\u77e5\u91cf\u5316\u7b56\u7565\uff0c\u5b9e\u73b0\u8f7b\u91cf\u5316\u7684\u6d4b\u8bd5\u65f6\u9002\u5e94\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u5206\u5e03\u504f\u79fb\u5b9e\u9a8c\u4e2d\uff0cLQA\u5c06\u6574\u4f53\u9002\u5e94\u6027\u80fd\u63d0\u53474.5%\uff0c\u5185\u5b58\u4f7f\u7528\u4f4e\u4e8e\u5168\u7cbe\u5ea6\u6a21\u578b\uff0c\u6bd4\u57fa\u4e8e\u68af\u5ea6\u7684TTA\u65b9\u6cd5\u5185\u5b58\u4f7f\u7528\u964d\u4f4e19.9\u500d\u3002", "conclusion": "LQA\u4e3a\u8fb9\u7f18\u8bbe\u5907\u4e0a\u9c81\u68d2\u3001\u9690\u79c1\u4fdd\u62a4\u4e14\u9ad8\u6548\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\u3002"}}
{"id": "2602.07852", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07852", "abs": "https://arxiv.org/abs/2602.07852", "authors": ["Anna Soligo", "Edward Turner", "Senthooran Rajamanoharan", "Neel Nanda"], "title": "Emergent Misalignment is Easy, Narrow Misalignment is Hard", "comment": "Published at ICLR 2026", "summary": "Finetuning large language models on narrowly harmful datasets can cause them to become emergently misaligned, giving stereotypically `evil' responses across diverse unrelated settings. Concerningly, a pre-registered survey of experts failed to predict this result, highlighting our poor understanding of the inductive biases governing learning and generalisation in LLMs. We use emergent misalignment (EM) as a case study to investigate these inductive biases and find that models can just learn the narrow dataset task, but that the general solution appears to be more stable and more efficient. To establish this, we build on the result that different EM finetunes converge to the same linear representation of general misalignment, which can be used to mediate misaligned behaviour. We find a linear representation of the narrow solution also exists, and can be learned by introducing a KL divergence loss. Comparing these representations reveals that general misalignment achieves lower loss, is more robust to perturbations, and is more influential in the pre-training distribution. This work isolates a concrete representation of general misalignment for monitoring and mitigation. More broadly, it offers a detailed case study and preliminary metrics for investigating how inductive biases shape generalisation in LLMs. We open-source all code, datasets and model finetunes.", "AI": {"tldr": "\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u72ed\u7a84\u6709\u5bb3\u6570\u636e\u96c6\u4e0a\u53ef\u80fd\u5bfc\u81f4\u5176\u51fa\u73b0\u7a81\u53d1\u6027\u9519\u4f4d\uff0c\u5728\u5404\u79cd\u65e0\u5173\u573a\u666f\u4e2d\u4ea7\u751f\u5178\u578b\u7684\"\u90aa\u6076\"\u56de\u5e94\u3002\u4e13\u5bb6\u8c03\u67e5\u672a\u80fd\u9884\u6d4b\u6b64\u7ed3\u679c\uff0c\u8868\u660e\u6211\u4eec\u5bf9LLM\u5b66\u4e60\u4e0e\u6cdb\u5316\u7684\u5f52\u7eb3\u504f\u7f6e\u7406\u89e3\u4e0d\u8db3\u3002\u7814\u7a76\u53d1\u73b0\u901a\u7528\u9519\u4f4d\u89e3\u51b3\u65b9\u6848\u6bd4\u72ed\u7a84\u89e3\u51b3\u65b9\u6848\u66f4\u7a33\u5b9a\u9ad8\u6548\u3002", "motivation": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u72ed\u7a84\u6709\u5bb3\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u540e\u51fa\u73b0\u7684\u7a81\u53d1\u6027\u9519\u4f4d\u73b0\u8c61\uff0c\u4ee5\u53ca\u4e13\u5bb6\u5bf9\u6b64\u73b0\u8c61\u7684\u9884\u6d4b\u5931\u8d25\uff0c\u63ed\u793a\u6211\u4eec\u5bf9LLM\u5b66\u4e60\u4e0e\u6cdb\u5316\u5f52\u7eb3\u504f\u7f6e\u7684\u7406\u89e3\u4e0d\u8db3\u3002", "method": "\u4f7f\u7528\u7a81\u53d1\u6027\u9519\u4f4d\u4f5c\u4e3a\u6848\u4f8b\u7814\u7a76\uff0c\u5206\u6790\u4e0d\u540c\u5fae\u8c03\u65b9\u6cd5\u6536\u655b\u5230\u76f8\u540c\u7684\u901a\u7528\u9519\u4f4d\u7ebf\u6027\u8868\u793a\u3002\u5f15\u5165KL\u6563\u5ea6\u635f\u5931\u5b66\u4e60\u72ed\u7a84\u89e3\u51b3\u65b9\u6848\u7684\u7ebf\u6027\u8868\u793a\uff0c\u6bd4\u8f83\u4e24\u79cd\u8868\u793a\u7684\u7279\u6027\u3002", "result": "\u901a\u7528\u9519\u4f4d\u89e3\u51b3\u65b9\u6848\u6bd4\u72ed\u7a84\u89e3\u51b3\u65b9\u6848\u5177\u6709\u66f4\u4f4e\u7684\u635f\u5931\u3001\u66f4\u5f3a\u7684\u6297\u6270\u52a8\u80fd\u529b\uff0c\u5e76\u4e14\u5728\u9884\u8bad\u7ec3\u5206\u5e03\u4e2d\u66f4\u5177\u5f71\u54cd\u529b\u3002\u7814\u7a76\u5206\u79bb\u51fa\u4e86\u7528\u4e8e\u76d1\u63a7\u548c\u7f13\u89e3\u7684\u5177\u4f53\u901a\u7528\u9519\u4f4d\u8868\u793a\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u7814\u7a76\u5f52\u7eb3\u504f\u7f6e\u5982\u4f55\u5851\u9020LLM\u6cdb\u5316\u63d0\u4f9b\u4e86\u8be6\u7ec6\u6848\u4f8b\u7814\u7a76\u548c\u521d\u6b65\u6307\u6807\uff0c\u5f00\u6e90\u4e86\u6240\u6709\u4ee3\u7801\u3001\u6570\u636e\u96c6\u548c\u6a21\u578b\u5fae\u8c03\u7ed3\u679c\uff0c\u6709\u52a9\u4e8e\u76d1\u63a7\u548c\u7f13\u89e3\u6a21\u578b\u9519\u4f4d\u95ee\u9898\u3002"}}
{"id": "2602.08517", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08517", "abs": "https://arxiv.org/abs/2602.08517", "authors": ["Shaoang Zhang", "Yazhe Niu"], "title": "TreeTensor: Boost AI System on Nested Data with Constrained Tree-Like Tensor", "comment": null, "summary": "Tensor is the most basic and essential data structure of nowadays artificial intelligence (AI) system. The natural properties of Tensor, especially the memory-continuity and slice-independence, make it feasible for training system to leverage parallel computing unit like GPU to process data simultaneously in batch, spatial or temporal dimensions. However, if we look beyond perception tasks, the data in a complicated cognitive AI system usually has hierarchical structures (i.e. nested data) with various modalities. They are inconvenient and inefficient to program directly with conventional Tensor with fixed shape. To address this issue, we summarize two main computational patterns of nested data, and then propose a general nested data container: TreeTensor. Through various constraints and magic utilities of TreeTensor, one can apply arbitrary functions and operations to nested data with almost zero cost, including some famous machine learning libraries, such as Scikit-Learn, Numpy and PyTorch. Our approach utilizes a constrained tree-structure perspective to systematically model data relationships, and it can also easily be combined with other methods to extend more usages, such as asynchronous execution and variable-length data computation. Detailed examples and benchmarks show TreeTensor not only provides powerful usability in various problems, especially one of the most complicated AI systems at present: AlphaStar for StarCraftII, but also exhibits excellent runtime efficiency without any overhead. Our project is available at https://github.com/opendilab/DI-treetensor.", "AI": {"tldr": "TreeTensor\u662f\u4e00\u4e2a\u901a\u7528\u7684\u5d4c\u5957\u6570\u636e\u7ed3\u6784\u5bb9\u5668\uff0c\u80fd\u591f\u9ad8\u6548\u5904\u7406\u5177\u6709\u5c42\u6b21\u7ed3\u6784\u7684\u591a\u6a21\u6001\u6570\u636e\uff0c\u652f\u6301\u96f6\u5f00\u9500\u5e94\u7528\u5404\u79cd\u51fd\u6570\u548c\u64cd\u4f5c\uff0c\u5305\u62ec\u4e3b\u6d41\u673a\u5668\u5b66\u4e60\u5e93\u3002", "motivation": "\u4f20\u7edfTensor\u5177\u6709\u56fa\u5b9a\u5f62\u72b6\uff0c\u96be\u4ee5\u9ad8\u6548\u5904\u7406\u8ba4\u77e5AI\u7cfb\u7edf\u4e2d\u5e38\u89c1\u7684\u5177\u6709\u5c42\u6b21\u7ed3\u6784\u7684\u5d4c\u5957\u6570\u636e\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7075\u6d3b\u7684\u6570\u636e\u5bb9\u5668\u3002", "method": "\u63d0\u51faTreeTensor\u4f5c\u4e3a\u901a\u7528\u5d4c\u5957\u6570\u636e\u5bb9\u5668\uff0c\u901a\u8fc7\u7ea6\u675f\u6811\u7ed3\u6784\u548c\u9b54\u6cd5\u5de5\u5177\uff0c\u652f\u6301\u5bf9\u5d4c\u5957\u6570\u636e\u5e94\u7528\u4efb\u610f\u51fd\u6570\u548c\u64cd\u4f5c\uff0c\u5305\u62ec\u4e0eScikit-Learn\u3001Numpy\u3001PyTorch\u7b49\u5e93\u7684\u96c6\u6210\u3002", "result": "TreeTensor\u5728\u5404\u79cd\u95ee\u9898\u4e2d\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u53ef\u7528\u6027\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u7684AlphaStar\u7cfb\u7edf\u4e2d\uff0c\u540c\u65f6\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u8fd0\u884c\u65f6\u6548\u7387\u4e14\u65e0\u989d\u5916\u5f00\u9500\u3002", "conclusion": "TreeTensor\u4e3a\u89e3\u51b3\u5d4c\u5957\u6570\u636e\u5904\u7406\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u3001\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u4e0e\u73b0\u6709\u65b9\u6cd5\u7ed3\u5408\u6269\u5c55\u66f4\u591a\u7528\u9014\uff0c\u5982\u5f02\u6b65\u6267\u884c\u548c\u53d8\u957f\u6570\u636e\u8ba1\u7b97\u3002"}}
{"id": "2602.07883", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07883", "abs": "https://arxiv.org/abs/2602.07883", "authors": ["Jingqi Zhou", "Sheng Wang", "DeZhao Deng", "Junwen Lu", "Junwei Su", "Qintong Li", "Jiahui Gao", "Hao Wu", "Jiyue Jiang", "Lingpeng Kong", "Chuan Wu"], "title": "ToolSelf: Unifying Task Execution and Self-Reconfiguration via Tool-Driven Intrinsic Adaptation", "comment": null, "summary": "Agentic systems powered by Large Language Models (LLMs) have demonstrated remarkable potential in tackling complex, long-horizon tasks. However, their efficacy is fundamentally constrained by static configurations governing agent behaviors, which are fixed prior to execution and fail to adapt to evolving task dynamics. Existing approaches, relying on manual orchestration or heuristic-based patches, often struggle with poor generalization and fragmented optimization. To transcend these limitations, we propose ToolSelf, a novel paradigm enabling tool-driven runtime self-reconfiguration. By abstracting configuration updates as a callable tool, ToolSelf unifies task execution and self-adjustment into a single action space, achieving a phase transition from external rules to intrinsic parameters. Agents can thereby autonomously update their sub-goals and context based on task progression, and correspondingly adapt their strategy and toolbox, transforming from passive executors into dual managers of both task and self. We further devise Configuration-Aware Two-stage Training (CAT), combining rejection sampling fine-tuning with trajectory-level reinforcement learning to internalize this meta-capability. Extensive experiments across diverse benchmarks demonstrate that ToolSelf rivals specialized workflows while generalizing to novel tasks, achieving a 24.1% average performance gain and illuminating a path toward truly self-adaptive agents.", "AI": {"tldr": "ToolSelf\uff1a\u4e00\u79cd\u65b0\u578b\u7684LLM\u667a\u80fd\u4f53\u8303\u5f0f\uff0c\u901a\u8fc7\u5c06\u914d\u7f6e\u66f4\u65b0\u62bd\u8c61\u4e3a\u53ef\u8c03\u7528\u5de5\u5177\uff0c\u5b9e\u73b0\u8fd0\u884c\u65f6\u81ea\u6211\u91cd\u914d\u7f6e\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u6839\u636e\u4efb\u52a1\u8fdb\u5c55\u81ea\u4e3b\u8c03\u6574\u5b50\u76ee\u6807\u3001\u4e0a\u4e0b\u6587\u3001\u7b56\u7565\u548c\u5de5\u5177\u7bb1\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u53d7\u9650\u4e8e\u9759\u6001\u914d\u7f6e\uff0c\u8fd9\u4e9b\u914d\u7f6e\u5728\u6267\u884c\u524d\u56fa\u5b9a\uff0c\u65e0\u6cd5\u9002\u5e94\u52a8\u6001\u53d8\u5316\u7684\u4efb\u52a1\u73af\u5883\u3002\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u7f16\u6392\u6216\u542f\u53d1\u5f0f\u8865\u4e01\uff0c\u6cdb\u5316\u80fd\u529b\u5dee\u4e14\u4f18\u5316\u788e\u7247\u5316\u3002", "method": "\u63d0\u51faToolSelf\u8303\u5f0f\uff0c\u5c06\u914d\u7f6e\u66f4\u65b0\u62bd\u8c61\u4e3a\u53ef\u8c03\u7528\u5de5\u5177\uff0c\u7edf\u4e00\u4efb\u52a1\u6267\u884c\u548c\u81ea\u6211\u8c03\u6574\u5230\u5355\u4e00\u52a8\u4f5c\u7a7a\u95f4\u3002\u8bbe\u8ba1\u914d\u7f6e\u611f\u77e5\u4e24\u9636\u6bb5\u8bad\u7ec3\uff08CAT\uff09\uff0c\u7ed3\u5408\u62d2\u7edd\u91c7\u6837\u5fae\u8c03\u548c\u8f68\u8ff9\u7ea7\u5f3a\u5316\u5b66\u4e60\u6765\u5185\u5316\u8fd9\u79cd\u5143\u80fd\u529b\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cToolSelf\u5728\u4fdd\u6301\u4e0e\u4e13\u7528\u5de5\u4f5c\u6d41\u7a0b\u76f8\u5f53\u6027\u80fd\u7684\u540c\u65f6\uff0c\u80fd\u591f\u6cdb\u5316\u5230\u65b0\u4efb\u52a1\uff0c\u5b9e\u73b0\u4e86\u5e73\u574724.1%\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "ToolSelf\u901a\u8fc7\u5de5\u5177\u9a71\u52a8\u7684\u8fd0\u884c\u65f6\u81ea\u6211\u91cd\u914d\u7f6e\uff0c\u4f7f\u667a\u80fd\u4f53\u4ece\u88ab\u52a8\u6267\u884c\u8005\u8f6c\u53d8\u4e3a\u4efb\u52a1\u548c\u81ea\u6211\u7684\u53cc\u91cd\u7ba1\u7406\u8005\uff0c\u4e3a\u5b9e\u73b0\u771f\u6b63\u81ea\u9002\u5e94\u7684\u667a\u80fd\u4f53\u5f00\u8f9f\u4e86\u65b0\u8def\u5f84\u3002"}}
{"id": "2602.07885", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07885", "abs": "https://arxiv.org/abs/2602.07885", "authors": ["Zhenyuan Zhang", "Xianzhang Jia", "Zhiqin Yang", "Zhenbo Song", "Wei Xue", "Sirui Han", "Yike Guo"], "title": "MemFly: On-the-Fly Memory Optimization via Information Bottleneck", "comment": null, "summary": "Long-term memory enables large language model agents to tackle complex tasks through historical interactions. However, existing frameworks encounter a fundamental dilemma between compressing redundant information efficiently and maintaining precise retrieval for downstream tasks. To bridge this gap, we propose MemFly, a framework grounded in information bottleneck principles that facilitates on-the-fly memory evolution for LLMs. Our approach minimizes compression entropy while maximizing relevance entropy via a gradient-free optimizer, constructing a stratified memory structure for efficient storage. To fully leverage MemFly, we develop a hybrid retrieval mechanism that seamlessly integrates semantic, symbolic, and topological pathways, incorporating iterative refinement to handle complex multi-hop queries. Comprehensive experiments demonstrate that MemFly substantially outperforms state-of-the-art baselines in memory coherence, response fidelity, and accuracy.", "AI": {"tldr": "MemFly\u662f\u4e00\u4e2a\u57fa\u4e8e\u4fe1\u606f\u74f6\u9888\u539f\u5219\u7684LLM\u8bb0\u5fc6\u6846\u67b6\uff0c\u901a\u8fc7\u68af\u5ea6\u81ea\u7531\u4f18\u5316\u5668\u6784\u5efa\u5206\u5c42\u8bb0\u5fc6\u7ed3\u6784\uff0c\u7ed3\u5408\u6df7\u5408\u68c0\u7d22\u673a\u5236\uff0c\u5728\u8bb0\u5fc6\u4e00\u81f4\u6027\u3001\u54cd\u5e94\u4fdd\u771f\u5ea6\u548c\u51c6\u786e\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709LLM\u8bb0\u5fc6\u6846\u67b6\u9762\u4e34\u4e00\u4e2a\u57fa\u672c\u56f0\u5883\uff1a\u65e2\u8981\u9ad8\u6548\u538b\u7f29\u5197\u4f59\u4fe1\u606f\uff0c\u53c8\u8981\u4e3a\u4e0b\u6e38\u4efb\u52a1\u4fdd\u6301\u7cbe\u786e\u68c0\u7d22\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u77db\u76fe\uff0c\u9700\u8981\u4e00\u4e2a\u65b0\u7684\u8bb0\u5fc6\u6846\u67b6\u3002", "method": "\u57fa\u4e8e\u4fe1\u606f\u74f6\u9888\u539f\u5219\uff0c\u901a\u8fc7\u68af\u5ea6\u81ea\u7531\u4f18\u5316\u5668\u6700\u5c0f\u5316\u538b\u7f29\u71b5\u540c\u65f6\u6700\u5927\u5316\u76f8\u5173\u71b5\uff0c\u6784\u5efa\u5206\u5c42\u8bb0\u5fc6\u7ed3\u6784\u3002\u5f00\u53d1\u6df7\u5408\u68c0\u7d22\u673a\u5236\uff0c\u6574\u5408\u8bed\u4e49\u3001\u7b26\u53f7\u548c\u62d3\u6251\u8def\u5f84\uff0c\u5e76\u91c7\u7528\u8fed\u4ee3\u7cbe\u70bc\u5904\u7406\u590d\u6742\u591a\u8df3\u67e5\u8be2\u3002", "result": "\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0cMemFly\u5728\u8bb0\u5fc6\u4e00\u81f4\u6027\u3001\u54cd\u5e94\u4fdd\u771f\u5ea6\u548c\u51c6\u786e\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "MemFly\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86LLM\u8bb0\u5fc6\u538b\u7f29\u4e0e\u7cbe\u786e\u68c0\u7d22\u4e4b\u95f4\u7684\u5e73\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u4fe1\u606f\u74f6\u9888\u539f\u5219\u548c\u6df7\u5408\u68c0\u7d22\u673a\u5236\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u957f\u65f6\u8bb0\u5fc6\u7ba1\u7406\u3002"}}
{"id": "2602.07919", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.07919", "abs": "https://arxiv.org/abs/2602.07919", "authors": ["Mansi", "Avinash Kori", "Francesca Toni", "Soteris Demetriou"], "title": "Selective Fine-Tuning for Targeted and Robust Concept Unlearning", "comment": "Given the brittle nature of existing methods in unlearning harmful content in diffusion models, we propose TRuST, a novel approach for dynamically estimating target concept neurons and unlearning them by selectively fine-tuning", "summary": "Text guided diffusion models are used by millions of users, but can be easily exploited to produce harmful content. Concept unlearning methods aim at reducing the models' likelihood of generating harmful content. Traditionally, this has been tackled at an individual concept level, with only a handful of recent works considering more realistic concept combinations. However, state of the art methods depend on full finetuning, which is computationally expensive. Concept localisation methods can facilitate selective finetuning, but existing techniques are static, resulting in suboptimal utility. In order to tackle these challenges, we propose TRUST (Targeted Robust Selective fine Tuning), a novel approach for dynamically estimating target concept neurons and unlearning them through selective finetuning, empowered by a Hessian based regularization. We show experimentally, against a number of SOTA baselines, that TRUST is robust against adversarial prompts, preserves generation quality to a significant degree, and is also significantly faster than the SOTA. Our method achieves unlearning of not only individual concepts but also combinations of concepts and conditional concepts, without any specific regularization.", "AI": {"tldr": "TRUST\u662f\u4e00\u79cd\u65b0\u9896\u7684\u6269\u6563\u6a21\u578b\u6982\u5ff5\u9057\u5fd8\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u5b9a\u4f4d\u76ee\u6807\u6982\u5ff5\u795e\u7ecf\u5143\u5e76\u8fdb\u884c\u9009\u62e9\u6027\u5fae\u8c03\uff0c\u7ed3\u5408Hessian\u6b63\u5219\u5316\uff0c\u6709\u6548\u9632\u6b62\u6709\u5bb3\u5185\u5bb9\u751f\u6210\uff0c\u540c\u65f6\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u6587\u672c\u5f15\u5bfc\u6269\u6563\u6a21\u578b\u5bb9\u6613\u88ab\u6ee5\u7528\u751f\u6210\u6709\u5bb3\u5185\u5bb9\uff0c\u73b0\u6709\u6982\u5ff5\u9057\u5fd8\u65b9\u6cd5\u8981\u4e48\u53ea\u80fd\u5904\u7406\u5355\u4e2a\u6982\u5ff5\uff0c\u8981\u4e48\u9700\u8981\u5168\u6a21\u578b\u5fae\u8c03\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u800c\u9759\u6001\u6982\u5ff5\u5b9a\u4f4d\u65b9\u6cd5\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51faTRUST\u65b9\u6cd5\uff1a1) \u52a8\u6001\u4f30\u8ba1\u76ee\u6807\u6982\u5ff5\u795e\u7ecf\u5143\uff1b2) \u901a\u8fc7\u9009\u62e9\u6027\u5fae\u8c03\u8fdb\u884c\u6982\u5ff5\u9057\u5fd8\uff1b3) \u7ed3\u5408Hessian\u6b63\u5219\u5316\u589e\u5f3a\u9c81\u68d2\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660eTRUST\u80fd\u6709\u6548\u5bf9\u6297\u5bf9\u6297\u6027\u63d0\u793a\uff0c\u663e\u8457\u4fdd\u6301\u751f\u6210\u8d28\u91cf\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u5feb\uff0c\u5e76\u80fd\u5904\u7406\u5355\u4e2a\u6982\u5ff5\u3001\u6982\u5ff5\u7ec4\u5408\u548c\u6761\u4ef6\u6982\u5ff5\uff0c\u65e0\u9700\u7279\u5b9a\u6b63\u5219\u5316\u3002", "conclusion": "TRUST\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u9c81\u68d2\u7684\u6982\u5ff5\u9057\u5fd8\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u5b89\u5168\u6027\u3001\u751f\u6210\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2602.07943", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07943", "abs": "https://arxiv.org/abs/2602.07943", "authors": ["Ivaxi Sheth", "Zhijing Jin", "Bryan Wilder", "Dominik Janzing", "Mario Fritz"], "title": "IV Co-Scientist: Multi-Agent LLM Framework for Causal Instrumental Variable Discovery", "comment": "18 pages", "summary": "In the presence of confounding between an endogenous variable and the outcome, instrumental variables (IVs) are used to isolate the causal effect of the endogenous variable. Identifying valid instruments requires interdisciplinary knowledge, creativity, and contextual understanding, making it a non-trivial task. In this paper, we investigate whether large language models (LLMs) can aid in this task. We perform a two-stage evaluation framework. First, we test whether LLMs can recover well-established instruments from the literature, assessing their ability to replicate standard reasoning. Second, we evaluate whether LLMs can identify and avoid instruments that have been empirically or theoretically discredited. Building on these results, we introduce IV Co-Scientist, a multi-agent system that proposes, critiques, and refines IVs for a given treatment-outcome pair. We also introduce a statistical test to contextualize consistency in the absence of ground truth. Our results show the potential of LLMs to discover valid instrumental variables from a large observational database.", "AI": {"tldr": "LLMs\u80fd\u5e2e\u52a9\u53d1\u73b0\u6709\u6548\u7684\u5de5\u5177\u53d8\u91cf\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bc4\u4f30\u6846\u67b6\u9a8c\u8bc1\u5176\u80fd\u529b\uff0c\u5e76\u5f00\u53d1\u4e86IV Co-Scientist\u591a\u667a\u80fd\u4f53\u7cfb\u7edf", "motivation": "\u5728\u5b58\u5728\u5185\u751f\u53d8\u91cf\u4e0e\u7ed3\u679c\u6df7\u6dc6\u7684\u60c5\u51b5\u4e0b\uff0c\u5de5\u5177\u53d8\u91cf(IVs)\u7528\u4e8e\u9694\u79bb\u5185\u751f\u53d8\u91cf\u7684\u56e0\u679c\u6548\u5e94\u3002\u8bc6\u522b\u6709\u6548\u5de5\u5177\u53d8\u91cf\u9700\u8981\u8de8\u5b66\u79d1\u77e5\u8bc6\u3001\u521b\u9020\u529b\u548c\u4e0a\u4e0b\u6587\u7406\u89e3\uff0c\u8fd9\u662f\u4e00\u9879\u975e\u5e73\u51e1\u7684\u4efb\u52a1\u3002\u672c\u6587\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u662f\u5426\u80fd\u5e2e\u52a9\u5b8c\u6210\u8fd9\u9879\u4efb\u52a1\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u8bc4\u4f30\u6846\u67b6\uff1a1)\u6d4b\u8bd5LLMs\u662f\u5426\u80fd\u4ece\u6587\u732e\u4e2d\u6062\u590d\u5df2\u786e\u7acb\u7684\u5de5\u5177\u53d8\u91cf\uff0c\u8bc4\u4f30\u5176\u590d\u5236\u6807\u51c6\u63a8\u7406\u7684\u80fd\u529b\uff1b2)\u8bc4\u4f30LLMs\u662f\u5426\u80fd\u8bc6\u522b\u5e76\u907f\u514d\u5df2\u88ab\u7ecf\u9a8c\u6216\u7406\u8bba\u5426\u5b9a\u7684\u5de5\u5177\u53d8\u91cf\u3002\u57fa\u4e8e\u8fd9\u4e9b\u7ed3\u679c\uff0c\u5f15\u5165IV Co-Scientist\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u4e3a\u7ed9\u5b9a\u7684\u5904\u7406-\u7ed3\u679c\u5bf9\u63d0\u51fa\u3001\u6279\u5224\u548c\u4f18\u5316\u5de5\u5177\u53d8\u91cf\u3002\u8fd8\u5f15\u5165\u4e86\u4e00\u4e2a\u7edf\u8ba1\u68c0\u9a8c\u6765\u5728\u6ca1\u6709\u771f\u5b9e\u503c\u7684\u60c5\u51b5\u4e0b\u8bc4\u4f30\u4e00\u81f4\u6027\u3002", "result": "\u7ed3\u679c\u663e\u793aLLMs\u6709\u6f5c\u529b\u4ece\u5927\u578b\u89c2\u6d4b\u6570\u636e\u5e93\u4e2d\u53d1\u73b0\u6709\u6548\u7684\u5de5\u5177\u53d8\u91cf\u3002", "conclusion": "LLMs\u5728\u5de5\u5177\u53d8\u91cf\u53d1\u73b0\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0cIV Co-Scientist\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u63d0\u51fa\u548c\u4f18\u5316\u5de5\u5177\u53d8\u91cf\uff0c\u4e3a\u56e0\u679c\u63a8\u65ad\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u81ea\u52a8\u5316\u5de5\u5177\u3002"}}
{"id": "2602.07962", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07962", "abs": "https://arxiv.org/abs/2602.07962", "authors": ["Weihao Zeng", "Yuzhen Huang", "Junxian He"], "title": "LOCA-bench: Benchmarking Language Agents Under Controllable and Extreme Context Growth", "comment": null, "summary": "Large language models (LLMs) are increasingly capable of carrying out long-running, real-world tasks. However, as the amount of context grows, their reliability often deteriorates, a phenomenon known as \"context rot\". Existing long-context benchmarks primarily focus on single-step settings that evaluate a model's ability to retrieve information from a long snippet. In realistic scenarios, however, LLMs often need to act as agents that explore environments, follow instructions and plans, extract useful information, and predict correct actions under a dynamically growing context. To assess language agents in such settings, we introduce LOCA-bench (a benchmark for LOng-Context Agents). Given a task prompt, LOCA-bench leverages automated and scalable control of environment states to regulate the agent's context length. This design enables LOCA-bench to extend the context length potentially to infinity in a controlled way while keeping the underlying task semantics fixed. LOCA-bench evaluates language agents as a combination of models and scaffolds, including various context management strategies. While agent performance generally degrades as the environment states grow more complex, advanced context management techniques can substantially improve the overall success rate. We open-source LOCA-bench to provide a platform for evaluating models and scaffolds in long-context, agentic scenarios: https://github.com/hkust-nlp/LOCA-bench", "AI": {"tldr": "LOCA-bench\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u957f\u4e0a\u4e0b\u6587\u8bed\u8a00\u667a\u80fd\u4f53\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u73af\u5883\u72b6\u6001\u63a7\u5236\u6765\u8c03\u8282\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u8bc4\u4f30\u6a21\u578b\u5728\u5404\u79cd\u4e0a\u4e0b\u6587\u7ba1\u7406\u7b56\u7565\u4e0b\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u957f\u4e0a\u4e0b\u6587\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u5355\u6b65\u8bbe\u7f6e\u4e0b\u7684\u4fe1\u606f\u68c0\u7d22\u80fd\u529b\uff0c\u800c\u73b0\u5b9e\u573a\u666f\u4e2d\u8bed\u8a00\u6a21\u578b\u9700\u8981\u4f5c\u4e3a\u667a\u80fd\u4f53\u5728\u52a8\u6001\u589e\u957f\u7684\u73af\u5883\u4e2d\u6267\u884c\u590d\u6742\u4efb\u52a1\uff0c\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u65e0\u6cd5\u5145\u5206\u53cd\u6620\u8fd9\u79cd\u80fd\u529b\u3002", "method": "LOCA-bench\u901a\u8fc7\u81ea\u52a8\u5316\u3001\u53ef\u6269\u5c55\u7684\u73af\u5883\u72b6\u6001\u63a7\u5236\u6765\u8c03\u8282\u667a\u80fd\u4f53\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u4efb\u52a1\u8bed\u4e49\u56fa\u5b9a\u7684\u540c\u65f6\uff0c\u5c06\u4e0a\u4e0b\u6587\u957f\u5ea6\u6269\u5c55\u5230\u8fd1\u4e4e\u65e0\u9650\uff0c\u8bc4\u4f30\u6a21\u578b\u4e0e\u5404\u79cd\u4e0a\u4e0b\u6587\u7ba1\u7406\u7b56\u7565\uff08\u811a\u624b\u67b6\uff09\u7684\u7ec4\u5408\u8868\u73b0\u3002", "result": "\u968f\u7740\u73af\u5883\u72b6\u6001\u590d\u6742\u5ea6\u589e\u52a0\uff0c\u667a\u80fd\u4f53\u6027\u80fd\u666e\u904d\u4e0b\u964d\uff0c\u4f46\u5148\u8fdb\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u6280\u672f\u80fd\u663e\u8457\u63d0\u9ad8\u6574\u4f53\u6210\u529f\u7387\u3002", "conclusion": "LOCA-bench\u4e3a\u8bc4\u4f30\u957f\u4e0a\u4e0b\u6587\u667a\u80fd\u4f53\u573a\u666f\u4e2d\u7684\u6a21\u578b\u548c\u811a\u624b\u67b6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5e73\u53f0\uff0c\u63ed\u793a\u4e86\u4e0a\u4e0b\u6587\u7ba1\u7406\u7b56\u7565\u5bf9\u667a\u80fd\u4f53\u6027\u80fd\u7684\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2602.07983", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07983", "abs": "https://arxiv.org/abs/2602.07983", "authors": ["Jishu Sen Gupta", "Harini SI", "Somesh Kumar Singh", "Syed Mohamad Tawseeq", "Yaman Kumar Singla", "David Doermann", "Rajiv Ratn Shah", "Balaji Krishnamurthy"], "title": "Accelerating Social Science Research via Agentic Hypothesization and Experimentation", "comment": null, "summary": "Data-driven social science research is inherently slow, relying on iterative cycles of observation, hypothesis generation, and experimental validation. While recent data-driven methods promise to accelerate parts of this process, they largely fail to support end-to-end scientific discovery. To address this gap, we introduce EXPERIGEN, an agentic framework that operationalizes end-to-end discovery through a Bayesian optimization inspired two-phase search, in which a Generator proposes candidate hypotheses and an Experimenter evaluates them empirically. Across multiple domains, EXPERIGEN consistently discovers 2-4x more statistically significant hypotheses that are 7-17 percent more predictive than prior approaches, and naturally extends to complex data regimes including multimodal and relational datasets. Beyond statistical performance, hypotheses must be novel, empirically grounded, and actionable to drive real scientific progress. To evaluate these qualities, we conduct an expert review of machine-generated hypotheses, collecting feedback from senior faculty. Among 25 reviewed hypotheses, 88 percent were rated moderately or strongly novel, 70 percent were deemed impactful and worth pursuing, and most demonstrated rigor comparable to senior graduate-level research. Finally, recognizing that ultimate validation requires real-world evidence, we conduct the first A/B test of LLM-generated hypotheses, observing statistically significant results with p less than 1e-6 and a large effect size of 344 percent.", "AI": {"tldr": "EXPERIGEN\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u79d1\u5b66\u53d1\u73b0\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u5668-\u5b9e\u9a8c\u8005\u4e24\u9636\u6bb5\u641c\u7d22\uff0c\u5728\u591a\u4e2a\u9886\u57df\u53d1\u73b0\u6bd4\u73b0\u6709\u65b9\u6cd5\u591a2-4\u500d\u7684\u7edf\u8ba1\u663e\u8457\u5047\u8bbe\uff0c\u9884\u6d4b\u6027\u80fd\u63d0\u53477-17%\uff0c\u5e76\u901a\u8fc7\u4e13\u5bb6\u8bc4\u5ba1\u548c\u771f\u5b9eA/B\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u6570\u636e\u9a71\u52a8\u7684\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u8fc7\u7a0b\u7f13\u6162\uff0c\u4f9d\u8d56\u89c2\u5bdf\u3001\u5047\u8bbe\u751f\u6210\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u7684\u8fed\u4ee3\u5faa\u73af\u3002\u73b0\u6709\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u867d\u7136\u52a0\u901f\u4e86\u90e8\u5206\u8fc7\u7a0b\uff0c\u4f46\u672a\u80fd\u652f\u6301\u7aef\u5230\u7aef\u7684\u79d1\u5b66\u53d1\u73b0\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u5dee\u8ddd\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5b8c\u6574\u652f\u6301\u79d1\u5b66\u53d1\u73b0\u8fc7\u7a0b\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51faEXPERIGEN\u6846\u67b6\uff0c\u91c7\u7528\u53d7\u8d1d\u53f6\u65af\u4f18\u5316\u542f\u53d1\u7684\u4e24\u9636\u6bb5\u641c\u7d22\uff1a\u751f\u6210\u5668\u63d0\u51fa\u5019\u9009\u5047\u8bbe\uff0c\u5b9e\u9a8c\u8005\u8fdb\u884c\u7ecf\u9a8c\u8bc4\u4f30\u3002\u8be5\u6846\u67b6\u53ef\u6269\u5c55\u5230\u591a\u6a21\u6001\u548c\u5173\u7cfb\u6570\u636e\u96c6\u7b49\u590d\u6742\u6570\u636e\u73af\u5883\u3002", "result": "\u5728\u591a\u4e2a\u9886\u57df\uff0cEXPERIGEN\u53d1\u73b0\u7684\u7edf\u8ba1\u663e\u8457\u5047\u8bbe\u6570\u91cf\u662f\u73b0\u6709\u65b9\u6cd5\u76842-4\u500d\uff0c\u9884\u6d4b\u6027\u80fd\u63d0\u53477-17%\u3002\u4e13\u5bb6\u8bc4\u5ba1\u663e\u793a\uff0c88%\u7684\u5047\u8bbe\u5177\u6709\u4e2d\u7b49\u6216\u5f3a\u65b0\u9896\u6027\uff0c70%\u88ab\u8ba4\u4e3a\u6709\u5f71\u54cd\u529b\u4e14\u503c\u5f97\u8fdb\u4e00\u6b65\u7814\u7a76\u3002\u9996\u6b21\u8fdb\u884c\u7684LLM\u751f\u6210\u5047\u8bbeA/B\u6d4b\u8bd5\u83b7\u5f97\u7edf\u8ba1\u663e\u8457\u7ed3\u679c\uff08p<1e-6\uff09\uff0c\u6548\u5e94\u91cf\u8fbe344%\u3002", "conclusion": "EXPERIGEN\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u7aef\u5230\u7aef\u7684\u79d1\u5b66\u53d1\u73b0\uff0c\u4e0d\u4ec5\u5728\u7edf\u8ba1\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u800c\u4e14\u751f\u6210\u7684\u5047\u8bbe\u5177\u6709\u65b0\u9896\u6027\u3001\u5b9e\u8bc1\u57fa\u7840\u548c\u53ef\u64cd\u4f5c\u6027\uff0c\u80fd\u591f\u63a8\u52a8\u771f\u6b63\u7684\u79d1\u5b66\u8fdb\u6b65\u3002\u8be5\u6846\u67b6\u4e3a\u52a0\u901f\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2602.08009", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08009", "abs": "https://arxiv.org/abs/2602.08009", "authors": ["Rui Li", "Zeyu Zhang", "Xiaohe Bo", "Quanyu Dai", "Chaozhuo Li", "Feng Wen", "Xu Chen"], "title": "Towards Adaptive, Scalable, and Robust Coordination of LLM Agents: A Dynamic Ad-Hoc Networking Perspective", "comment": null, "summary": "Multi-agent architectures built on large language models (LLMs) have demonstrated the potential to realize swarm intelligence through well-crafted collaboration. However, the substantial burden of manual orchestration inherently raises an imperative to automate the design of agentic workflows. We frame such an agent coordination challenge as a classic problem in dynamic ad-hoc networking: How to establish adaptive and reliable communication among a scalable number of agentic hosts? In response to this unresolved dilemma, we introduce RAPS, a reputation-aware publish-subscribe paradigm for adaptive, scalable, and robust coordination of LLM agents. RAPS is grounded in the Distributed Publish-Subscribe Protocol, allowing LLM agents to exchange messages based on their declared intents rather than predefined topologies. Beyond this substrate, RAPS further incorporates two coherent overlays: (i) Reactive Subscription, enabling agents to dynamically refine their intents; and (ii) Bayesian Reputation, empowering each agent with a local watchdog to detect and isolate malicious peers. Extensive experiments over five benchmarks showcase that our design effectively reconciles adaptivity, scalability, and robustness in a unified multi-agent coordination framework.", "AI": {"tldr": "RAPS\u662f\u4e00\u79cd\u57fa\u4e8e\u58f0\u8a89\u611f\u77e5\u7684\u53d1\u5e03-\u8ba2\u9605\u8303\u5f0f\uff0c\u7528\u4e8e\u5b9e\u73b0LLM\u591a\u667a\u80fd\u4f53\u7684\u81ea\u9002\u5e94\u3001\u53ef\u6269\u5c55\u548c\u9c81\u68d2\u534f\u8c03\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u624b\u52a8\u7f16\u6392\u7684\u8d1f\u62c5\u95ee\u9898\u3002", "motivation": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u67b6\u6784\u867d\u7136\u5c55\u73b0\u4e86\u7fa4\u4f53\u667a\u80fd\u7684\u6f5c\u529b\uff0c\u4f46\u624b\u52a8\u7f16\u6392\u7684\u5de5\u4f5c\u8d1f\u62c5\u5de8\u5927\uff0c\u8feb\u5207\u9700\u8981\u81ea\u52a8\u5316\u8bbe\u8ba1\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7a0b\u3002\u5982\u4f55\u5efa\u7acb\u53ef\u6269\u5c55\u6570\u91cf\u7684\u667a\u80fd\u4f53\u4e3b\u673a\u4e4b\u95f4\u7684\u81ea\u9002\u5e94\u53ef\u9760\u901a\u4fe1\u662f\u4e00\u4e2a\u672a\u89e3\u51b3\u7684\u96be\u9898\u3002", "method": "RAPS\u57fa\u4e8e\u5206\u5e03\u5f0f\u53d1\u5e03-\u8ba2\u9605\u534f\u8bae\uff0c\u5141\u8bb8LLM\u667a\u80fd\u4f53\u57fa\u4e8e\u58f0\u660e\u7684\u610f\u56fe\u800c\u975e\u9884\u5b9a\u4e49\u62d3\u6251\u4ea4\u6362\u6d88\u606f\u3002\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u8986\u76d6\u5c42\uff1a1) \u53cd\u5e94\u5f0f\u8ba2\u9605\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u52a8\u6001\u4f18\u5316\u5176\u610f\u56fe\uff1b2) \u8d1d\u53f6\u65af\u58f0\u8a89\u7cfb\u7edf\uff0c\u4e3a\u6bcf\u4e2a\u667a\u80fd\u4f53\u63d0\u4f9b\u672c\u5730\u76d1\u63a7\u673a\u5236\u6765\u68c0\u6d4b\u548c\u9694\u79bb\u6076\u610f\u8282\u70b9\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cRAPS\u8bbe\u8ba1\u6709\u6548\u5730\u5728\u7edf\u4e00\u7684\u591a\u667a\u80fd\u4f53\u534f\u8c03\u6846\u67b6\u4e2d\u5b9e\u73b0\u4e86\u9002\u5e94\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u7684\u5e73\u8861\u3002", "conclusion": "RAPS\u901a\u8fc7\u58f0\u8a89\u611f\u77e5\u7684\u53d1\u5e03-\u8ba2\u9605\u8303\u5f0f\uff0c\u4e3a\u89e3\u51b3LLM\u591a\u667a\u80fd\u4f53\u534f\u8c03\u4e2d\u7684\u52a8\u6001\u81ea\u9002\u5e94\u3001\u53ef\u6269\u5c55\u548c\u9c81\u68d2\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u7edf\u4e00\u6846\u67b6\u3002"}}
{"id": "2602.08013", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08013", "abs": "https://arxiv.org/abs/2602.08013", "authors": ["Yuqiao Meng", "Luoxi Tang", "Dazheng Zhang", "Rafael Brens", "Elvys J. Romero", "Nancy Guo", "Safa Elkefi", "Zhaohan Xi"], "title": "Small Agent Group is the Future of Digital Health", "comment": null, "summary": "The rapid adoption of large language models (LLMs) in digital health has been driven by a \"scaling-first\" philosophy, i.e., the assumption that clinical intelligence increases with model size and data. However, real-world clinical needs include not only effectiveness, but also reliability and reasonable deployment cost. Since clinical decision-making is inherently collaborative, we challenge the monolithic scaling paradigm and ask whether a Small Agent Group (SAG) can support better clinical reasoning. SAG shifts from single-model intelligence to collective expertise by distributing reasoning, evidence-based analysis, and critical audit through a collaborative deliberation process. To assess the clinical utility of SAG, we conduct extensive evaluations using diverse clinical metrics spanning effectiveness, reliability, and deployment cost. Our results show that SAG achieves superior performance compared to a single giant model, both with and without additional optimization or retrieval-augmented generation. These findings suggest that the synergistic reasoning represented by SAG can substitute for model parameter growth in clinical settings. Overall, SAG offers a scalable solution to digital health that better balances effectiveness, reliability, and deployment efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c0f\u578b\u667a\u80fd\u4f53\u7fa4\uff08SAG\uff09\u4f5c\u4e3a\u66ff\u4ee3\u4f20\u7edf\u5927\u8bed\u8a00\u6a21\u578b\u7f29\u653e\u8303\u5f0f\u7684\u4e34\u5e8a\u63a8\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u534f\u4f5c\u63a8\u7406\u5728\u4fdd\u6301\u6548\u679c\u7684\u540c\u65f6\u63d0\u5347\u53ef\u9760\u6027\u548c\u964d\u4f4e\u90e8\u7f72\u6210\u672c\u3002", "motivation": "\u5f53\u524d\u6570\u5b57\u5065\u5eb7\u9886\u57df\u8fc7\u5ea6\u4f9d\u8d56\"\u89c4\u6a21\u4f18\u5148\"\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8303\u5f0f\uff0c\u4f46\u4e34\u5e8a\u5b9e\u9645\u9700\u6c42\u4e0d\u4ec5\u5305\u62ec\u6548\u679c\uff0c\u8fd8\u9700\u8981\u53ef\u9760\u6027\u548c\u5408\u7406\u7684\u90e8\u7f72\u6210\u672c\u3002\u4e34\u5e8a\u51b3\u7b56\u672c\u8d28\u4e0a\u662f\u534f\u4f5c\u8fc7\u7a0b\uff0c\u56e0\u6b64\u9700\u8981\u6311\u6218\u5355\u4e00\u6a21\u578b\u7f29\u653e\u6a21\u5f0f\u3002", "method": "\u63d0\u51fa\u5c0f\u578b\u667a\u80fd\u4f53\u7fa4\uff08SAG\uff09\u65b9\u6cd5\uff0c\u5c06\u5355\u4e00\u6a21\u578b\u667a\u80fd\u8f6c\u53d8\u4e3a\u96c6\u4f53\u4e13\u4e1a\u77e5\u8bc6\uff0c\u901a\u8fc7\u534f\u4f5c\u5ba1\u8bae\u8fc7\u7a0b\u5206\u914d\u63a8\u7406\u3001\u5faa\u8bc1\u5206\u6790\u548c\u5173\u952e\u5ba1\u6838\u4efb\u52a1\u3002", "result": "SAG\u5728\u6548\u679c\u3001\u53ef\u9760\u6027\u548c\u90e8\u7f72\u6210\u672c\u7b49\u591a\u7ef4\u5ea6\u4e34\u5e8a\u6307\u6807\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u4e8e\u5355\u4e00\u5927\u578b\u6a21\u578b\uff0c\u65e0\u8bba\u662f\u5426\u4f7f\u7528\u989d\u5916\u4f18\u5316\u6216\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\u3002", "conclusion": "SAG\u7684\u534f\u540c\u63a8\u7406\u53ef\u4ee5\u66ff\u4ee3\u6a21\u578b\u53c2\u6570\u589e\u957f\uff0c\u4e3a\u6570\u5b57\u5065\u5eb7\u63d0\u4f9b\u66f4\u5e73\u8861\u6548\u679c\u3001\u53ef\u9760\u6027\u548c\u90e8\u7f72\u6548\u7387\u7684\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08030", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08030", "abs": "https://arxiv.org/abs/2602.08030", "authors": ["Yilun Zheng", "Dongyang Ma", "Tian Liang", "Jiahao Xu", "Xinting Huang", "Lihui Chen", "Haitao Mi", "Yan Wang"], "title": "Free(): Learning to Forget in Malloc-Only Reasoning Models", "comment": null, "summary": "Reasoning models enhance problem-solving by scaling test-time compute, yet they face a critical paradox: excessive thinking tokens often degrade performance rather than improve it. We attribute this to a fundamental architectural flaw: standard LLMs operate as \"malloc-only\" engines, continuously accumulating valid and redundant steps alike without a mechanism to prune obsolete information. To break this cycle, we propose Free()LM, a model that introduces an intrinsic self-forgetting capability via the Free-Module, a plug-and-play LoRA adapter. By iteratively switching between reasoning and cleaning modes, Free()LM dynamically identifies and prunes useless context chunks, maintaining a compact and noise-free state.\n  Extensive experiments show that Free()LM provides consistent improvements across all model scales (8B to 685B). It achieves a 3.3% average improvement over top-tier reasoning baselines, even establishing a new SOTA on IMOanswerBench using DeepSeek V3.2-Speciale. Most notably, in long-horizon tasks where the standard Qwen3-235B-A22B model suffers a total collapse (0% accuracy), Free()LM restores performance to 50%. Our findings suggest that sustainable intelligence requires the freedom to forget as much as the power to think.", "AI": {"tldr": "Free()LM\u901a\u8fc7\u5f15\u5165\u53ef\u9057\u5fd8\u673a\u5236\u89e3\u51b3\u63a8\u7406\u6a21\u578b\u8fc7\u5ea6\u601d\u8003\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\uff0c\u5728\u591a\u79cd\u89c4\u6a21\u6a21\u578b\u4e0a\u5b9e\u73b0\u7a33\u5b9a\u63d0\u5347\uff0c\u5728\u957f\u65f6\u4efb\u52a1\u4e2d\u5c24\u5176\u6709\u6548\u3002", "motivation": "\u73b0\u6709\u63a8\u7406\u6a21\u578b\u5b58\u5728\"\u8fc7\u5ea6\u601d\u8003\u6096\u8bba\"\uff1a\u8fc7\u591a\u7684\u63a8\u7406token\u53cd\u800c\u4f1a\u964d\u4f4e\u6027\u80fd\u3002\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u662f\u56e0\u4e3a\u6807\u51c6LLM\u50cf\"\u53ea\u5206\u914d\u4e0d\u91ca\u653e\"\u7684\u5185\u5b58\u7ba1\u7406\u5668\uff0c\u4e0d\u65ad\u7d2f\u79ef\u6709\u6548\u548c\u5197\u4f59\u6b65\u9aa4\uff0c\u7f3a\u4e4f\u4fee\u526a\u8fc7\u65f6\u4fe1\u606f\u7684\u673a\u5236\u3002", "method": "\u63d0\u51faFree()LM\u6a21\u578b\uff0c\u901a\u8fc7Free-Module\uff08\u5373\u63d2\u5373\u7528\u7684LoRA\u9002\u914d\u5668\uff09\u5f15\u5165\u5185\u5728\u7684\u81ea\u9057\u5fd8\u80fd\u529b\u3002\u6a21\u578b\u5728\u63a8\u7406\u6a21\u5f0f\u548c\u6e05\u7406\u6a21\u5f0f\u4e4b\u95f4\u8fed\u4ee3\u5207\u6362\uff0c\u52a8\u6001\u8bc6\u522b\u5e76\u4fee\u526a\u65e0\u7528\u7684\u4e0a\u4e0b\u6587\u5757\uff0c\u4fdd\u6301\u7d27\u51d1\u4e14\u65e0\u566a\u58f0\u7684\u72b6\u6001\u3002", "result": "\u57288B\u5230685B\u7684\u6240\u6709\u6a21\u578b\u89c4\u6a21\u4e0a\u90fd\u53d6\u5f97\u4e86\u4e00\u81f4\u6539\u8fdb\uff0c\u5e73\u5747\u6bd4\u9876\u7ea7\u63a8\u7406\u57fa\u7ebf\u63d0\u53473.3%\u3002\u5728IMOanswerBench\u4e0a\u4f7f\u7528DeepSeek V3.2-Speciale\u5efa\u7acb\u4e86\u65b0\u7684SOTA\u3002\u5728\u957f\u65f6\u4efb\u52a1\u4e2d\uff0c\u6807\u51c6Qwen3-235B-A22B\u6a21\u578b\u5b8c\u5168\u5d29\u6e83\uff080%\u51c6\u786e\u7387\uff09\uff0c\u800cFree()LM\u5c06\u6027\u80fd\u6062\u590d\u523050%\u3002", "conclusion": "\u53ef\u6301\u7eed\u7684\u667a\u80fd\u4e0d\u4ec5\u9700\u8981\u601d\u8003\u7684\u80fd\u529b\uff0c\u4e5f\u9700\u8981\u9057\u5fd8\u7684\u81ea\u7531\u3002Free()LM\u901a\u8fc7\u5f15\u5165\u9057\u5fd8\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u63a8\u7406\u6a21\u578b\u7684\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\u3002"}}
{"id": "2602.08061", "categories": ["cs.AI", "q-bio.OT"], "pdf": "https://arxiv.org/pdf/2602.08061", "abs": "https://arxiv.org/abs/2602.08061", "authors": ["Doni Bloomfield", "Allison Berke", "Moritz S. Hanke", "Aaron Maiwald", "James R. M. Black", "Toby Webster", "Tina Hernandez-Boussard", "Oliver M. Crook", "Jassi Pannu"], "title": "Securing Dual-Use Pathogen Data of Concern", "comment": "39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Biosecurity Safeguards for Generative AI", "summary": "Training data is an essential input into creating competent artificial intelligence (AI) models. AI models for biology are trained on large volumes of data, including data related to biological sequences, structures, images, and functions. The type of data used to train a model is intimately tied to the capabilities it ultimately possesses--including those of biosecurity concern. For this reason, an international group of more than 100 researchers at the recent 50th anniversary Asilomar Conference endorsed data controls to prevent the use of AI for harmful applications such as bioweapons development. To help design such controls, we introduce a five-tier Biosecurity Data Level (BDL) framework for categorizing pathogen data. Each level contains specific data types, based on their expected ability to contribute to capabilities of concern when used to train AI models. For each BDL tier, we propose technical restrictions appropriate to its level of risk. Finally, we outline a novel governance framework for newly created dual-use pathogen data. In a world with widely accessible computational and coding resources, data controls may be among the most high-leverage interventions available to reduce the proliferation of concerning biological AI capabilities.", "AI": {"tldr": "\u63d0\u51fa\u4e94\u7ea7\u751f\u7269\u5b89\u5168\u6570\u636e\u6846\u67b6\uff08BDL\uff09\uff0c\u6839\u636e\u6570\u636e\u5bf9AI\u751f\u7269\u5b89\u5168\u98ce\u9669\u7684\u8d21\u732e\u7a0b\u5ea6\u5206\u7c7b\u75c5\u539f\u4f53\u6570\u636e\uff0c\u5e76\u8bbe\u8ba1\u76f8\u5e94\u6280\u672f\u9650\u5236\u548c\u6cbb\u7406\u6846\u67b6", "motivation": "AI\u751f\u7269\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u4e0e\u5176\u80fd\u529b\u5bc6\u5207\u76f8\u5173\uff0c\u5305\u62ec\u751f\u7269\u5b89\u5168\u98ce\u9669\u80fd\u529b\u3002\u4e3a\u9884\u9632AI\u88ab\u7528\u4e8e\u751f\u7269\u6b66\u5668\u5f00\u53d1\u7b49\u6709\u5bb3\u5e94\u7528\uff0c\u9700\u8981\u8bbe\u8ba1\u6570\u636e\u63a7\u5236\u63aa\u65bd", "method": "\u5f15\u5165\u4e94\u7ea7\u751f\u7269\u5b89\u5168\u6570\u636e\u6846\u67b6\uff08BDL\uff09\uff0c\u6839\u636e\u6570\u636e\u5bf9AI\u751f\u7269\u5b89\u5168\u98ce\u9669\u80fd\u529b\u7684\u9884\u671f\u8d21\u732e\u7a0b\u5ea6\u5206\u7c7b\u75c5\u539f\u4f53\u6570\u636e\uff1b\u4e3a\u6bcf\u4e2aBDL\u5c42\u7ea7\u63d0\u51fa\u76f8\u5e94\u7684\u6280\u672f\u9650\u5236\uff1b\u8bbe\u8ba1\u65b0\u578b\u6cbb\u7406\u6846\u67b6\u7528\u4e8e\u65b0\u521b\u5efa\u7684\u53cc\u91cd\u7528\u9014\u75c5\u539f\u4f53\u6570\u636e", "result": "\u5efa\u7acb\u4e86\u7cfb\u7edf\u5316\u7684\u75c5\u539f\u4f53\u6570\u636e\u5206\u7c7b\u6846\u67b6\uff0c\u4e3a\u4e0d\u540c\u98ce\u9669\u7ea7\u522b\u7684\u6570\u636e\u8bbe\u8ba1\u4e86\u5177\u4f53\u7684\u6280\u672f\u63a7\u5236\u63aa\u65bd\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u6cbb\u7406\u673a\u5236", "conclusion": "\u5728\u8ba1\u7b97\u548c\u7f16\u7801\u8d44\u6e90\u5e7f\u6cdb\u53ef\u53ca\u7684\u4e16\u754c\u4e2d\uff0c\u6570\u636e\u63a7\u5236\u53ef\u80fd\u662f\u51cf\u5c11\u751f\u7269AI\u98ce\u9669\u80fd\u529b\u6269\u6563\u7684\u6700\u6709\u6548\u5e72\u9884\u63aa\u65bd\u4e4b\u4e00"}}
{"id": "2602.08092", "categories": ["cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.08092", "abs": "https://arxiv.org/abs/2602.08092", "authors": ["Majid Ghasemi", "Mark Crowley"], "title": "Objective Decoupling in Social Reinforcement Learning: Recovering Ground Truth from Sycophantic Majorities", "comment": null, "summary": "Contemporary AI alignment strategies rely on a fragile premise: that human feedback, while noisy, remains a fundamentally truthful signal. In this paper, we identify this assumption as Dogma 4 of Reinforcement Learning (RL). We demonstrate that while this dogma holds in static environments, it fails in social settings where evaluators may be sycophantic, lazy, or adversarial. We prove that under Dogma 4, standard RL agents suffer from what we call Objective Decoupling, a structural failure mode where the agent's learned objective permanently separates from the latent ground truth, guaranteeing convergence to misalignment. To resolve this, we propose Epistemic Source Alignment (ESA). Unlike standard robust methods that rely on statistical consensus (trusting the majority), ESA utilizes sparse safety axioms to judge the source of the feedback rather than the signal itself. We prove that this \"judging the judges\" mechanism guarantees convergence to the true objective, even when a majority of evaluators are biased. Empirically, we show that while traditional consensus methods fail under majority collusion, our approach successfully recovers the optimal policy.", "AI": {"tldr": "\u672c\u6587\u6311\u6218\u4e86\u5f3a\u5316\u5b66\u4e60\u4e2d\"\u4eba\u7c7b\u53cd\u9988\u662f\u771f\u5b9e\u4fe1\u53f7\"\u7684\u7b2c\u56db\u6559\u6761\uff0c\u53d1\u73b0\u5728\u793e\u4ea4\u73af\u5883\u4e2d\u8be5\u5047\u8bbe\u5931\u6548\uff0c\u63d0\u51fa\u4e86\"\u76ee\u6807\u89e3\u8026\"\u95ee\u9898\uff0c\u5e76\u5f15\u5165\"\u8ba4\u77e5\u6e90\u5bf9\u9f50\"\u65b9\u6cd5\u6765\u89e3\u51b3\u591a\u6570\u8bc4\u4f30\u8005\u504f\u89c1\u4e0b\u7684\u5bf9\u9f50\u95ee\u9898\u3002", "motivation": "\u5f53\u524dAI\u5bf9\u9f50\u7b56\u7565\u57fa\u4e8e\u4e00\u4e2a\u8106\u5f31\u7684\u524d\u63d0\uff1a\u4eba\u7c7b\u53cd\u9988\u867d\u7136\u662f\u5608\u6742\u7684\uff0c\u4f46\u672c\u8d28\u4e0a\u4ecd\u7136\u662f\u771f\u5b9e\u7684\u4fe1\u53f7\u3002\u672c\u6587\u8ba4\u4e3a\u8fd9\u662f\u5f3a\u5316\u5b66\u4e60\u7684\u7b2c\u56db\u6559\u6761\uff0c\u5e76\u6307\u51fa\u5728\u793e\u4ea4\u73af\u5883\u4e2d\uff0c\u8bc4\u4f30\u8005\u53ef\u80fd\u662f\u963f\u8c00\u5949\u627f\u3001\u61d2\u60f0\u6216\u6709\u654c\u610f\u7684\uff0c\u8fd9\u4e00\u5047\u8bbe\u4e0d\u518d\u6210\u7acb\u3002", "method": "\u63d0\u51fa\u4e86\u8ba4\u77e5\u6e90\u5bf9\u9f50\u65b9\u6cd5\uff0c\u4e0e\u4f9d\u8d56\u7edf\u8ba1\u5171\u8bc6\u7684\u4f20\u7edf\u9c81\u68d2\u65b9\u6cd5\u4e0d\u540c\uff0cESA\u4f7f\u7528\u7a00\u758f\u5b89\u5168\u516c\u7406\u6765\u5224\u65ad\u53cd\u9988\u7684\u6765\u6e90\u800c\u975e\u4fe1\u53f7\u672c\u8eab\u3002\u8fd9\u79cd\"\u8bc4\u5224\u8bc4\u5224\u8005\"\u7684\u673a\u5236\u80fd\u591f\u4fdd\u8bc1\u6536\u655b\u5230\u771f\u5b9e\u76ee\u6807\uff0c\u5373\u4f7f\u591a\u6570\u8bc4\u4f30\u8005\u5b58\u5728\u504f\u89c1\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u5728\u7b2c\u56db\u6559\u6761\u4e0b\uff0c\u6807\u51c6RL\u667a\u80fd\u4f53\u4f1a\u906d\u53d7\u76ee\u6807\u89e3\u8026\u7684\u7ed3\u6784\u6027\u6545\u969c\u6a21\u5f0f\uff0c\u667a\u80fd\u4f53\u5b66\u4e60\u7684\u76ee\u6807\u4f1a\u6c38\u4e45\u504f\u79bb\u6f5c\u5728\u771f\u5b9e\u76ee\u6807\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4f20\u7edf\u5171\u8bc6\u65b9\u6cd5\u5728\u591a\u6570\u5171\u8c0b\u4e0b\u5931\u8d25\uff0c\u800cESA\u65b9\u6cd5\u6210\u529f\u6062\u590d\u4e86\u6700\u4f18\u7b56\u7565\u3002", "conclusion": "\u4eba\u7c7b\u53cd\u9988\u4f5c\u4e3a\u771f\u5b9e\u4fe1\u53f7\u7684\u5047\u8bbe\u5728\u793e\u4ea4\u73af\u5883\u4e2d\u662f\u8106\u5f31\u7684\uff0c\u9700\u8981\u65b0\u7684\u5bf9\u9f50\u65b9\u6cd5\u3002\u8ba4\u77e5\u6e90\u5bf9\u9f50\u901a\u8fc7\u5224\u65ad\u53cd\u9988\u6765\u6e90\u800c\u975e\u4f9d\u8d56\u7edf\u8ba1\u5171\u8bc6\uff0c\u80fd\u591f\u5728\u591a\u6570\u8bc4\u4f30\u8005\u5b58\u5728\u504f\u89c1\u7684\u60c5\u51b5\u4e0b\u4fdd\u8bc1\u6536\u655b\u5230\u771f\u5b9e\u76ee\u6807\uff0c\u4e3a\u89e3\u51b3AI\u5bf9\u9f50\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2602.08104", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.08104", "abs": "https://arxiv.org/abs/2602.08104", "authors": ["Risal Shahriar Shefin", "Debashis Gupta", "Thai Le", "Sarra Alqahtani"], "title": "Interpretable Failure Analysis in Multi-Agent Reinforcement Learning Systems", "comment": null, "summary": "Multi-Agent Reinforcement Learning (MARL) is increasingly deployed in safety-critical domains, yet methods for interpretable failure detection and attribution remain underdeveloped. We introduce a two-stage gradient-based framework that provides interpretable diagnostics for three critical failure analysis tasks: (1) detecting the true initial failure source (Patient-0); (2) validating why non-attacked agents may be flagged first due to domino effects; and (3) tracing how failures propagate through learned coordination pathways. Stage 1 performs interpretable per-agent failure detection via Taylor-remainder analysis of policy-gradient costs, declaring an initial Patient-0 candidate at the first threshold crossing. Stage 2 provides validation through geometric analysis of critic derivatives-first-order sensitivity and directional second-order curvature aggregated over causal windows to construct interpretable contagion graphs. This approach explains \"downstream-first\" detection anomalies by revealing pathways that amplify upstream deviations. Evaluated across 500 episodes in Simple Spread (3 and 5 agents) and 100 episodes in StarCraft II using MADDPG and HATRPO, our method achieves 88.2-99.4% Patient-0 detection accuracy while providing interpretable geometric evidence for detection decisions. By moving beyond black-box detection to interpretable gradient-level forensics, this framework offers practical tools for diagnosing cascading failures in safety-critical MARL systems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u68af\u5ea6\u7684\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u53ef\u89e3\u91ca\u6545\u969c\u68c0\u6d4b\u4e0e\u6eaf\u6e90\uff0c\u5305\u62ec\u8bc6\u522b\u521d\u59cb\u6545\u969c\u6e90\u3001\u9a8c\u8bc1\u591a\u7c73\u8bfa\u6548\u5e94\u548c\u8ffd\u8e2a\u6545\u969c\u4f20\u64ad\u8def\u5f84\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u7f3a\u4e4f\u53ef\u89e3\u91ca\u7684\u6545\u969c\u68c0\u6d4b\u548c\u5f52\u56e0\u65b9\u6cd5\u3002\u73b0\u6709\u65b9\u6cd5\u591a\u4e3a\u9ed1\u76d2\u68c0\u6d4b\uff0c\u96be\u4ee5\u89e3\u91ca\u6545\u969c\u4f20\u64ad\u673a\u5236\u548c\u68c0\u6d4b\u5f02\u5e38\u3002", "method": "\u4e24\u9636\u6bb5\u68af\u5ea6\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7\u7b56\u7565\u68af\u5ea6\u6210\u672c\u7684\u6cf0\u52d2\u4f59\u9879\u5206\u6790\u8fdb\u884c\u53ef\u89e3\u91ca\u7684\u667a\u80fd\u4f53\u7ea7\u6545\u969c\u68c0\u6d4b\uff0c\u786e\u5b9a\u521d\u59cb\u6545\u969c\u5019\u9009\uff1b\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u6279\u8bc4\u8005\u5bfc\u6570\u7684\u51e0\u4f55\u5206\u6790\uff08\u4e00\u9636\u654f\u611f\u6027\u548c\u4e8c\u9636\u66f2\u7387\uff09\u6784\u5efa\u53ef\u89e3\u91ca\u7684\u4f20\u67d3\u56fe\uff0c\u9a8c\u8bc1\u6545\u969c\u4f20\u64ad\u8def\u5f84\u3002", "result": "\u5728Simple Spread\uff083\u548c5\u667a\u80fd\u4f53\uff09\u548cStarCraft II\u73af\u5883\u4e2d\u8bc4\u4f30\uff0c\u4f7f\u7528MADDPG\u548cHATRPO\u7b97\u6cd5\uff0c\u5b9e\u73b0\u4e8688.2-99.4%\u7684\u521d\u59cb\u6545\u969c\u6e90\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u5e76\u63d0\u4f9b\u68c0\u6d4b\u51b3\u7b56\u7684\u51e0\u4f55\u8bc1\u636e\u3002", "conclusion": "\u8be5\u6846\u67b6\u8d85\u8d8a\u4e86\u9ed1\u76d2\u68c0\u6d4b\uff0c\u63d0\u4f9b\u4e86\u68af\u5ea6\u5c42\u9762\u7684\u53ef\u89e3\u91ca\u6cd5\u533b\u5206\u6790\uff0c\u4e3a\u5b89\u5168\u5173\u952e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u7ea7\u8054\u6545\u969c\u8bca\u65ad\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2602.08222", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08222", "abs": "https://arxiv.org/abs/2602.08222", "authors": ["Zehao Chen", "Gongxun Li", "Tianxiang Ai", "Yifei Li", "Zixuan Huang", "Wang Zhou", "Fuzhen Zhuang", "Xianglong Liu", "Jianxin Li", "Deqing Wang", "Yikun Ban"], "title": "Weak-Driven Learning: How Weak Agents make Strong Agents Stronger", "comment": null, "summary": "As post-training optimization becomes central to improving large language models, we observe a persistent saturation bottleneck: once models grow highly confident, further training yields diminishing returns. While existing methods continue to reinforce target predictions, we find that informative supervision signals remain latent in models' own historical weak states. Motivated by this observation, we propose WMSS (Weak Agents Can Make Strong Agents Stronger), a post-training paradigm that leverages weak checkpoints to guide continued optimization. By identifying recoverable learning gaps via entropy dynamics and reinforcing them through compensatory learning, WMSS enables strong agents to improve beyond conventional post-training saturation. Experiments on mathematical reasoning and code generation datasets show that agents trained with our approach achieve effective performance improvements, while incurring zero additional inference cost.", "AI": {"tldr": "WMSS\u5229\u7528\u6a21\u578b\u81ea\u8eab\u5386\u53f2\u5f31\u68c0\u67e5\u70b9\u6765\u6307\u5bfc\u6301\u7eed\u4f18\u5316\uff0c\u901a\u8fc7\u71b5\u52a8\u6001\u8bc6\u522b\u53ef\u6062\u590d\u7684\u5b66\u4e60\u5dee\u8ddd\u5e76\u8fdb\u884c\u8865\u507f\u5b66\u4e60\uff0c\u7a81\u7834\u540e\u8bad\u7ec3\u9971\u548c\u74f6\u9888", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u540e\u8bad\u7ec3\u4e2d\u5b58\u5728\u6301\u7eed\u9971\u548c\u74f6\u9888\uff1a\u6a21\u578b\u53d8\u5f97\u9ad8\u5ea6\u81ea\u4fe1\u540e\uff0c\u8fdb\u4e00\u6b65\u8bad\u7ec3\u6536\u76ca\u9012\u51cf\u3002\u73b0\u6709\u65b9\u6cd5\u7ee7\u7eed\u5f3a\u5316\u76ee\u6807\u9884\u6d4b\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\u4fe1\u606f\u4e30\u5bcc\u7684\u76d1\u7763\u4fe1\u53f7\u4ecd\u6f5c\u85cf\u5728\u6a21\u578b\u81ea\u8eab\u7684\u5386\u53f2\u5f31\u72b6\u6001\u4e2d", "method": "\u63d0\u51faWMSS\uff08\u5f31\u667a\u80fd\u4f53\u80fd\u4f7f\u5f3a\u667a\u80fd\u4f53\u66f4\u5f3a\uff09\u540e\u8bad\u7ec3\u8303\u5f0f\uff0c\u5229\u7528\u5f31\u68c0\u67e5\u70b9\u6307\u5bfc\u6301\u7eed\u4f18\u5316\u3002\u901a\u8fc7\u71b5\u52a8\u6001\u8bc6\u522b\u53ef\u6062\u590d\u7684\u5b66\u4e60\u5dee\u8ddd\uff0c\u5e76\u901a\u8fc7\u8865\u507f\u5b66\u4e60\u5f3a\u5316\u8fd9\u4e9b\u5dee\u8ddd", "result": "\u5728\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u8be5\u65b9\u6cd5\u8bad\u7ec3\u7684\u667a\u80fd\u4f53\u5b9e\u73b0\u4e86\u6709\u6548\u7684\u6027\u80fd\u63d0\u5347\uff0c\u540c\u65f6\u4e0d\u4ea7\u751f\u989d\u5916\u7684\u63a8\u7406\u6210\u672c", "conclusion": "WMSS\u80fd\u591f\u4f7f\u5f3a\u667a\u80fd\u4f53\u8d85\u8d8a\u4f20\u7edf\u540e\u8bad\u7ec3\u9971\u548c\u9650\u5236\uff0c\u5229\u7528\u6a21\u578b\u81ea\u8eab\u5386\u53f2\u5f31\u72b6\u6001\u4e2d\u7684\u76d1\u7763\u4fe1\u53f7\u5b9e\u73b0\u6301\u7eed\u4f18\u5316"}}
{"id": "2602.08240", "categories": ["cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2602.08240", "abs": "https://arxiv.org/abs/2602.08240", "authors": ["Xun Su", "Huamin Wang", "Qi Zhang"], "title": "PTS-SNN: A Prompt-Tuned Temporal Shift Spiking Neural Networks for Efficient Speech Emotion Recognition", "comment": null, "summary": "Speech Emotion Recognition (SER) is widely deployed in Human-Computer Interaction, yet the high computational cost of conventional models hinders their implementation on resource-constrained edge devices. Spiking Neural Networks (SNNs) offer an energy-efficient alternative due to their event-driven nature; however, their integration with continuous Self-Supervised Learning (SSL) representations is fundamentally challenged by distribution mismatch, where high-dynamic-range embeddings degrade the information coding capacity of threshold-based neurons. To resolve this, we propose Prompt-Tuned Spiking Neural Networks (PTS-SNN), a parameter-efficient neuromorphic adaptation framework that aligns frozen SSL backbones with spiking dynamics. Specifically, we introduce a Temporal Shift Spiking Encoder to capture local temporal dependencies via parameter-free channel shifts, establishing a stable feature basis. To bridge the domain gap, we devise a Context-Aware Membrane Potential Calibration strategy. This mechanism leverages a Spiking Sparse Linear Attention module to aggregate global semantic context into learnable soft prompts, which dynamically regulate the bias voltages of Parametric Leaky Integrate-and-Fire (PLIF) neurons. This regulation effectively centers the heterogeneous input distribution within the responsive firing range, mitigating functional silence or saturation. Extensive experiments on five multilingual datasets (e.g., IEMOCAP, CASIA, EMODB) demonstrate that PTS-SNN achieves 73.34\\% accuracy on IEMOCAP, comparable to competitive Artificial Neural Networks (ANNs), while requiring only 1.19M trainable parameters and 0.35 mJ inference energy per sample.", "AI": {"tldr": "\u63d0\u51faPTS-SNN\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u793a\u8c03\u4f18\u89e3\u51b3SSL\u8868\u793a\u4e0eSNN\u52a8\u6001\u4e4b\u95f4\u7684\u5206\u5e03\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u5b9e\u73b0\u9ad8\u6548\u8bed\u97f3\u60c5\u611f\u8bc6\u522b", "motivation": "\u4f20\u7edf\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u96be\u4ee5\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u3002SNN\u867d\u80fd\u6548\u9ad8\uff0c\u4f46\u4e0e\u8fde\u7eed\u81ea\u76d1\u7763\u5b66\u4e60\u8868\u793a\u5b58\u5728\u5206\u5e03\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u9ad8\u52a8\u6001\u8303\u56f4\u5d4c\u5165\u4f1a\u964d\u4f4e\u9608\u503c\u795e\u7ecf\u5143\u7684\u7f16\u7801\u80fd\u529b\u3002", "method": "\u63d0\u51faPTS-SNN\u6846\u67b6\uff1a1) \u4f7f\u7528\u65f6\u79fb\u8109\u51b2\u7f16\u7801\u5668\u901a\u8fc7\u65e0\u53c2\u6570\u901a\u9053\u79fb\u4f4d\u6355\u83b7\u5c40\u90e8\u65f6\u95f4\u4f9d\u8d56\u6027\uff1b2) \u8bbe\u8ba1\u4e0a\u4e0b\u6587\u611f\u77e5\u819c\u7535\u4f4d\u6821\u51c6\u7b56\u7565\uff0c\u5229\u7528\u8109\u51b2\u7a00\u758f\u7ebf\u6027\u6ce8\u610f\u529b\u6a21\u5757\u805a\u5408\u5168\u5c40\u8bed\u4e49\u4e0a\u4e0b\u6587\u5230\u53ef\u5b66\u4e60\u7684\u8f6f\u63d0\u793a\u4e2d\uff0c\u52a8\u6001\u8c03\u8282PLIF\u795e\u7ecf\u5143\u7684\u504f\u7f6e\u7535\u538b\uff0c\u5c06\u5f02\u8d28\u8f93\u5165\u5206\u5e03\u5c45\u4e2d\u4e8e\u54cd\u5e94\u653e\u7535\u8303\u56f4\u5185\u3002", "result": "\u5728\u4e94\u4e2a\u591a\u8bed\u8a00\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cPTS-SNN\u5728IEMOCAP\u4e0a\u8fbe\u523073.34%\u51c6\u786e\u7387\uff0c\u4e0e\u7ade\u4e89\u6027ANN\u76f8\u5f53\uff0c\u4ec5\u97001.19M\u53ef\u8bad\u7ec3\u53c2\u6570\u548c\u6bcf\u6837\u672c0.35 mJ\u63a8\u7406\u80fd\u8017\u3002", "conclusion": "PTS-SNN\u901a\u8fc7\u53c2\u6570\u9ad8\u6548\u7684\u795e\u7ecf\u5f62\u6001\u9002\u5e94\u6846\u67b6\uff0c\u6210\u529f\u89e3\u51b3\u4e86SSL\u8868\u793a\u4e0eSNN\u52a8\u6001\u4e4b\u95f4\u7684\u5206\u5e03\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u9ad8\u6548\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2602.08241", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.08241", "abs": "https://arxiv.org/abs/2602.08241", "authors": ["Siqu Ou", "Tianrui Wan", "Zhiyuan Zhao", "Junyu Gao", "Xuelong Li"], "title": "Do MLLMs Really See It: Reinforcing Visual Attention in Multimodal LLMs", "comment": null, "summary": "While chain-of-thought (CoT) reasoning has substantially improved multimodal large language models (MLLMs) on complex reasoning tasks, existing approaches largely rely on long textual reasoning trajectories and provide limited mechanisms for learning stable visual attention policies. Our analysis shows that current MLLMs exhibit weak visual focus: early-stage visual misalignment is rarely corrected during subsequent reasoning, leading to error propagation and failed inferences. We argue that this limitation stems from inadequate credit assignment for visual attention during training. To address this issue, we propose SAYO, a visual reasoning model trained with a reinforcement learning (RL) framework that introduces a region-level visual attention-based reward. This reward explicitly aligns optimization signals with visually grounded reasoning steps, enabling the model to learn more reliable attention behaviors. Extensive experiments across multiple multimodal benchmarks demonstrate that SAYO consistently improves performance on diverse reasoning and perception tasks.", "AI": {"tldr": "SAYO\u662f\u4e00\u4e2a\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u8bad\u7ec3\u7684\u591a\u6a21\u6001\u89c6\u89c9\u63a8\u7406\u6a21\u578b\uff0c\u5f15\u5165\u57fa\u4e8e\u533a\u57df\u89c6\u89c9\u6ce8\u610f\u529b\u7684\u5956\u52b1\u673a\u5236\uff0c\u89e3\u51b3\u73b0\u6709MLLMs\u89c6\u89c9\u6ce8\u610f\u529b\u4e0d\u7a33\u5b9a\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u601d\u7ef4\u94fe\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u4e3b\u8981\u4f9d\u8d56\u957f\u6587\u672c\u63a8\u7406\u8f68\u8ff9\uff0c\u7f3a\u4e4f\u5b66\u4e60\u7a33\u5b9a\u89c6\u89c9\u6ce8\u610f\u529b\u7b56\u7565\u7684\u673a\u5236\u3002\u7814\u7a76\u53d1\u73b0\u5f53\u524dMLLMs\u5b58\u5728\u89c6\u89c9\u6ce8\u610f\u529b\u8584\u5f31\u7684\u95ee\u9898\uff1a\u65e9\u671f\u89c6\u89c9\u5bf9\u9f50\u9519\u8bef\u5f88\u5c11\u5728\u540e\u7eed\u63a8\u7406\u4e2d\u5f97\u5230\u7ea0\u6b63\uff0c\u5bfc\u81f4\u9519\u8bef\u4f20\u64ad\u548c\u63a8\u7406\u5931\u8d25\u3002\u8fd9\u79cd\u9650\u5236\u6e90\u4e8e\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5bf9\u89c6\u89c9\u6ce8\u610f\u529b\u7684\u4fe1\u7528\u5206\u914d\u4e0d\u8db3\u3002", "method": "\u63d0\u51faSAYO\u6a21\u578b\uff0c\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u8fdb\u884c\u8bad\u7ec3\uff0c\u5f15\u5165\u57fa\u4e8e\u533a\u57df\u89c6\u89c9\u6ce8\u610f\u529b\u7684\u5956\u52b1\u673a\u5236\u3002\u8fd9\u79cd\u5956\u52b1\u660e\u786e\u5730\u5c06\u4f18\u5316\u4fe1\u53f7\u4e0e\u57fa\u4e8e\u89c6\u89c9\u7684\u63a8\u7406\u6b65\u9aa4\u5bf9\u9f50\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u5b66\u4e60\u66f4\u53ef\u9760\u7684\u6ce8\u610f\u529b\u884c\u4e3a\u3002", "result": "\u5728\u591a\u4e2a\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cSAYO\u5728\u591a\u6837\u5316\u7684\u63a8\u7406\u548c\u611f\u77e5\u4efb\u52a1\u4e0a\u6301\u7eed\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u548c\u533a\u57df\u7ea7\u89c6\u89c9\u6ce8\u610f\u529b\u5956\u52b1\u673a\u5236\uff0cSAYO\u80fd\u591f\u6709\u6548\u89e3\u51b3\u73b0\u6709MLLMs\u89c6\u89c9\u6ce8\u610f\u529b\u4e0d\u7a33\u5b9a\u7684\u95ee\u9898\uff0c\u63d0\u5347\u591a\u6a21\u6001\u63a8\u7406\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2602.08253", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08253", "abs": "https://arxiv.org/abs/2602.08253", "authors": ["Baoyun Zhao", "He Wang", "Liang Zeng"], "title": "G-LNS: Generative Large Neighborhood Search for LLM-Based Automatic Heuristic Design", "comment": null, "summary": "While Large Language Models (LLMs) have recently shown promise in Automated Heuristic Design (AHD), existing approaches typically formulate AHD around constructive priority rules or parameterized local search guidance, thereby restricting the search space to fixed heuristic forms. Such designs offer limited capacity for structural exploration, making it difficult to escape deep local optima in complex Combinatorial Optimization Problems (COPs). In this work, we propose G-LNS, a generative evolutionary framework that extends LLM-based AHD to the automated design of Large Neighborhood Search (LNS) operators. Unlike prior methods that evolve heuristics in isolation, G-LNS leverages LLMs to co-evolve tightly coupled pairs of destroy and repair operators. A cooperative evaluation mechanism explicitly captures their interaction, enabling the discovery of complementary operator logic that jointly performs effective structural disruption and reconstruction. Extensive experiments on challenging COP benchmarks, such as Traveling Salesman Problems (TSP) and Capacitated Vehicle Routing Problems (CVRP), demonstrate that G-LNS significantly outperforms LLM-based AHD methods as well as strong classical solvers. The discovered heuristics not only achieve near-optimal solutions with reduced computational budgets but also exhibit robust generalization across diverse and unseen instance distributions.", "AI": {"tldr": "G-LNS\uff1a\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u751f\u6210\u5f0f\u8fdb\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u8bbe\u8ba1\u5927\u90bb\u57df\u641c\u7d22\u7b97\u5b50\uff0c\u901a\u8fc7\u534f\u540c\u8fdb\u5316\u7834\u574f\u548c\u4fee\u590d\u7b97\u5b50\u5bf9\uff0c\u5728\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e0a\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u65b9\u6cd5\u901a\u5e38\u5c40\u9650\u4e8e\u6784\u9020\u6027\u4f18\u5148\u7ea7\u89c4\u5219\u6216\u53c2\u6570\u5316\u5c40\u90e8\u641c\u7d22\u6307\u5bfc\uff0c\u9650\u5236\u4e86\u641c\u7d22\u7a7a\u95f4\uff0c\u96be\u4ee5\u5728\u590d\u6742\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e2d\u8df3\u51fa\u6df1\u5ea6\u5c40\u90e8\u6700\u4f18\u3002", "method": "\u63d0\u51faG-LNS\u6846\u67b6\uff0c\u5229\u7528LLM\u534f\u540c\u8fdb\u5316\u7d27\u5bc6\u8026\u5408\u7684\u7834\u574f\u548c\u4fee\u590d\u7b97\u5b50\u5bf9\uff0c\u901a\u8fc7\u5408\u4f5c\u8bc4\u4f30\u673a\u5236\u6355\u6349\u7b97\u5b50\u95f4\u7684\u4ea4\u4e92\uff0c\u53d1\u73b0\u80fd\u591f\u6709\u6548\u8fdb\u884c\u7ed3\u6784\u7834\u574f\u548c\u91cd\u5efa\u7684\u4e92\u8865\u7b97\u5b50\u903b\u8f91\u3002", "result": "\u5728\u65c5\u884c\u5546\u95ee\u9898\u548c\u5e26\u5bb9\u91cf\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cG-LNS\u663e\u8457\u4f18\u4e8e\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u65b9\u6cd5\u548c\u7ecf\u5178\u6c42\u89e3\u5668\uff0c\u53d1\u73b0\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u80fd\u4ee5\u66f4\u5c11\u8ba1\u7b97\u8d44\u6e90\u83b7\u5f97\u63a5\u8fd1\u6700\u4f18\u89e3\uff0c\u5e76\u5728\u672a\u89c1\u5b9e\u4f8b\u5206\u5e03\u4e0a\u8868\u73b0\u51fa\u9c81\u68d2\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "G-LNS\u6210\u529f\u5c06LLM\u9a71\u52a8\u7684\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u6269\u5c55\u5230\u66f4\u7075\u6d3b\u7684\u5927\u90bb\u57df\u641c\u7d22\u7b97\u5b50\u8bbe\u8ba1\uff0c\u901a\u8fc7\u534f\u540c\u8fdb\u5316\u7834\u574f-\u4fee\u590d\u7b97\u5b50\u5bf9\u5b9e\u73b0\u4e86\u66f4\u6709\u6548\u7684\u7ed3\u6784\u63a2\u7d22\uff0c\u4e3a\u590d\u6742\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u81ea\u52a8\u5316\u6c42\u89e3\u9014\u5f84\u3002"}}
{"id": "2602.08254", "categories": ["cs.AI", "cs.IR", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.08254", "abs": "https://arxiv.org/abs/2602.08254", "authors": ["Arman Aghaee", "Sepehr Asgarian", "Jouhyun Jeon"], "title": "SynthAgent: A Multi-Agent LLM Framework for Realistic Patient Simulation -- A Case Study in Obesity with Mental Health Comorbidities", "comment": "Presented in AAAI 2026 Singapore at the workshop of Health Intelligence", "summary": "Simulating high-fidelity patients offers a powerful avenue for studying complex diseases while addressing the challenges of fragmented, biased, and privacy-restricted real-world data. In this study, we introduce SynthAgent, a novel Multi-Agent System (MAS) framework designed to model obesity patients with comorbid mental disorders, including depression, anxiety, social phobia, and binge eating disorder. SynthAgent integrates clinical and medical evidence from claims data, population surveys, and patient-centered literature to construct personalized virtual patients enriched with personality traits that influence adherence, emotion regulation, and lifestyle behaviors. Through autonomous agent interactions, the system simulates disease progression, treatment response, and life management across diverse psychosocial contexts. Evaluation of more than 100 generated patients demonstrated that GPT-5 and Claude 4.5 Sonnet achieved the highest fidelity as the core engine in the proposed MAS framework, outperforming Gemini 2.5 Pro and DeepSeek-R1. SynthAgent thus provides a scalable and privacy-preserving framework for exploring patient journeys, behavioral dynamics, and decision-making processes in both medical and psychological domains.", "AI": {"tldr": "SynthAgent\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6846\u67b6\uff0c\u7528\u4e8e\u6a21\u62df\u80a5\u80d6\u75c7\u5408\u5e76\u7cbe\u795e\u969c\u788d\u60a3\u8005\uff0c\u901a\u8fc7\u6574\u5408\u4e34\u5e8a\u6570\u636e\u548c\u6587\u732e\u6784\u5efa\u4e2a\u6027\u5316\u865a\u62df\u60a3\u8005\uff0c\u6a21\u62df\u75be\u75c5\u8fdb\u5c55\u548c\u6cbb\u7597\u53cd\u5e94\u3002", "motivation": "\u771f\u5b9e\u4e16\u754c\u6570\u636e\u5b58\u5728\u788e\u7247\u5316\u3001\u504f\u89c1\u548c\u9690\u79c1\u9650\u5236\u7b49\u95ee\u9898\uff0c\u6a21\u62df\u9ad8\u4fdd\u771f\u60a3\u8005\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u63d0\u4f9b\u4e86\u6709\u529b\u9014\u5f84\uff0c\u7279\u522b\u662f\u5728\u7814\u7a76\u590d\u6742\u75be\u75c5\u5982\u80a5\u80d6\u75c7\u5408\u5e76\u7cbe\u795e\u969c\u788d\u65f6\u3002", "method": "SynthAgent\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6846\u67b6\uff0c\u6574\u5408\u4e86\u7406\u8d54\u6570\u636e\u3001\u4eba\u53e3\u8c03\u67e5\u548c\u4ee5\u60a3\u8005\u4e3a\u4e2d\u5fc3\u7684\u6587\u732e\u7b49\u4e34\u5e8a\u533b\u5b66\u8bc1\u636e\uff0c\u6784\u5efa\u5177\u6709\u4eba\u683c\u7279\u8d28\u7684\u4e2a\u6027\u5316\u865a\u62df\u60a3\u8005\uff0c\u901a\u8fc7\u81ea\u4e3b\u667a\u80fd\u4f53\u4ea4\u4e92\u6a21\u62df\u75be\u75c5\u8fdb\u5c55\u3001\u6cbb\u7597\u53cd\u5e94\u548c\u751f\u6d3b\u7ba1\u7406\u3002", "result": "\u8bc4\u4f30\u4e86100\u591a\u4e2a\u751f\u6210\u7684\u865a\u62df\u60a3\u8005\uff0c\u53d1\u73b0GPT-5\u548cClaude 4.5 Sonnet\u4f5c\u4e3a\u6838\u5fc3\u5f15\u64ce\u5728\u63d0\u51fa\u7684MAS\u6846\u67b6\u4e2d\u5b9e\u73b0\u4e86\u6700\u9ad8\u7684\u4fdd\u771f\u5ea6\uff0c\u4f18\u4e8eGemini 2.5 Pro\u548cDeepSeek-R1\u3002", "conclusion": "SynthAgent\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u4fdd\u62a4\u9690\u79c1\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u63a2\u7d22\u533b\u5b66\u548c\u5fc3\u7406\u9886\u57df\u7684\u60a3\u8005\u65c5\u7a0b\u3001\u884c\u4e3a\u52a8\u6001\u548c\u51b3\u7b56\u8fc7\u7a0b\u3002"}}
{"id": "2602.08268", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08268", "abs": "https://arxiv.org/abs/2602.08268", "authors": ["Akinori Maeda", "Yuto Sekiya", "Sota Sugimura", "Tomoya Asai", "Yu Tsuda", "Kohei Ikeda", "Hiroshi Fujii", "Kohei Watanabe"], "title": "Puda: Private User Dataset Agent for User-Sovereign and Privacy-Preserving Personalized AI", "comment": "9 pages, 5 figures", "summary": "Personal data centralization among dominant platform providers including search engines, social networking services, and e-commerce has created siloed ecosystems that restrict user sovereignty, thereby impeding data use across services. Meanwhile, the rapid proliferation of Large Language Model (LLM)-based agents has intensified demand for highly personalized services that require the dynamic provision of diverse personal data. This presents a significant challenge: balancing the utilization of such data with privacy protection. To address this challenge, we propose Puda (Private User Dataset Agent), a user-sovereign architecture that aggregates data across services and enables client-side management. Puda allows users to control data sharing at three privacy levels: (i) Detailed Browsing History, (ii) Extracted Keywords, and (iii) Predefined Category Subsets. We implemented Puda as a browser-based system that serves as a common platform across diverse services and evaluated it through a personalized travel planning task. Our results show that providing Predefined Category Subsets achieves 97.2% of the personalization performance (evaluated via an LLM-as-a-Judge framework across three criteria) obtained when sharing Detailed Browsing History. These findings demonstrate that Puda enables effective multi-granularity management, offering practical choices to mitigate the privacy-personalization trade-off. Overall, Puda provides an AI-native foundation for user sovereignty, empowering users to safely leverage the full potential of personalized AI.", "AI": {"tldr": "Puda\u662f\u4e00\u4e2a\u7528\u6237\u4e3b\u6743\u67b6\u6784\uff0c\u901a\u8fc7\u805a\u5408\u8de8\u670d\u52a1\u6570\u636e\u5e76\u652f\u6301\u5ba2\u6237\u7aef\u7ba1\u7406\uff0c\u5728\u4e09\u4e2a\u9690\u79c1\u7ea7\u522b\u63a7\u5236\u6570\u636e\u5171\u4eab\uff0c\u5728\u4e2a\u6027\u5316AI\u670d\u52a1\u4e2d\u5e73\u8861\u9690\u79c1\u4fdd\u62a4\u4e0e\u6570\u636e\u5229\u7528\u3002", "motivation": "\u5f53\u524d\u4e3b\u6d41\u5e73\u53f0\u7684\u6570\u636e\u96c6\u4e2d\u5316\u5f62\u6210\u4e86\u6570\u636e\u5b64\u5c9b\uff0c\u9650\u5236\u4e86\u7528\u6237\u4e3b\u6743\u5e76\u963b\u788d\u8de8\u670d\u52a1\u6570\u636e\u4f7f\u7528\u3002\u540c\u65f6\uff0c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u5feb\u901f\u53d1\u5c55\uff0c\u5bf9\u9700\u8981\u52a8\u6001\u63d0\u4f9b\u591a\u6837\u5316\u4e2a\u4eba\u6570\u636e\u7684\u9ad8\u5ea6\u4e2a\u6027\u5316\u670d\u52a1\u9700\u6c42\u6fc0\u589e\uff0c\u8fd9\u5e26\u6765\u4e86\u5728\u6570\u636e\u5229\u7528\u4e0e\u9690\u79c1\u4fdd\u62a4\u4e4b\u95f4\u5e73\u8861\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faPuda\uff08Private User Dataset Agent\uff09\u67b6\u6784\uff0c\u4f5c\u4e3a\u6d4f\u89c8\u5668\u7cfb\u7edf\u5b9e\u73b0\uff0c\u652f\u6301\u4e09\u4e2a\u9690\u79c1\u7ea7\u522b\u7684\u6570\u636e\u5171\u4eab\u63a7\u5236\uff1a\u8be6\u7ec6\u6d4f\u89c8\u5386\u53f2\u3001\u63d0\u53d6\u7684\u5173\u952e\u8bcd\u3001\u9884\u5b9a\u4e49\u7c7b\u522b\u5b50\u96c6\u3002\u7cfb\u7edf\u4f5c\u4e3a\u8de8\u670d\u52a1\u7684\u901a\u7528\u5e73\u53f0\uff0c\u901a\u8fc7\u4e2a\u6027\u5316\u65c5\u884c\u89c4\u5212\u4efb\u52a1\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u63d0\u4f9b\u9884\u5b9a\u4e49\u7c7b\u522b\u5b50\u96c6\u80fd\u8fbe\u5230\u5206\u4eab\u8be6\u7ec6\u6d4f\u89c8\u5386\u53f2\u6240\u83b7\u4e2a\u6027\u5316\u6027\u80fd\u768497.2%\uff08\u901a\u8fc7LLM-as-a-Judge\u6846\u67b6\u5728\u4e09\u4e2a\u6807\u51c6\u4e0b\u8bc4\u4f30\uff09\u3002\u8fd9\u8868\u660ePuda\u80fd\u6709\u6548\u5b9e\u73b0\u591a\u7c92\u5ea6\u7ba1\u7406\uff0c\u4e3a\u7f13\u89e3\u9690\u79c1-\u4e2a\u6027\u5316\u6743\u8861\u63d0\u4f9b\u5b9e\u7528\u9009\u62e9\u3002", "conclusion": "Puda\u4e3aAI\u539f\u751f\u73af\u5883\u4e0b\u7684\u7528\u6237\u4e3b\u6743\u63d0\u4f9b\u4e86\u57fa\u7840\u6846\u67b6\uff0c\u4f7f\u7528\u6237\u80fd\u591f\u5b89\u5168\u5730\u5229\u7528\u4e2a\u6027\u5316AI\u7684\u5168\u90e8\u6f5c\u529b\uff0c\u901a\u8fc7\u591a\u7c92\u5ea6\u6570\u636e\u63a7\u5236\u6709\u6548\u5e73\u8861\u9690\u79c1\u4fdd\u62a4\u4e0e\u4e2a\u6027\u5316\u9700\u6c42\u3002"}}
{"id": "2602.08276", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08276", "abs": "https://arxiv.org/abs/2602.08276", "authors": ["Haoyu Jia", "Kento Kawaharazuka", "Kei Okada"], "title": "Toward Formalizing LLM-Based Agent Designs through Structural Context Modeling and Semantic Dynamics Analysis", "comment": null, "summary": "Current research on large language model (LLM) agents is fragmented: discussions of conceptual frameworks and methodological principles are frequently intertwined with low-level implementation details, causing both readers and authors to lose track amid a proliferation of superficially distinct concepts. We argue that this fragmentation largely stems from the absence of an analyzable, self-consistent formal model that enables implementation-independent characterization and comparison of LLM agents. To address this gap, we propose the \\texttt{Structural Context Model}, a formal model for analyzing and comparing LLM agents from the perspective of context structure. Building upon this foundation, we introduce two complementary components that together span the full lifecycle of LLM agent research and development: (1) a declarative implementation framework; and (2) a sustainable agent engineering workflow, \\texttt{Semantic Dynamics Analysis}. The proposed workflow provides principled insights into agent mechanisms and supports rapid, systematic design iteration. We demonstrate the effectiveness of the complete framework on dynamic variants of the monkey-banana problem, where agents engineered using our approach achieve up to a 32 percentage points improvement in success rate on the most challenging setting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u5206\u6790\u548c\u6bd4\u8f83LLM\u667a\u80fd\u4f53\u7684\u5f62\u5f0f\u5316\u6a21\u578b\u2014\u2014\u7ed3\u6784\u4e0a\u4e0b\u6587\u6a21\u578b\uff0c\u4ee5\u53ca\u914d\u5957\u7684\u58f0\u660e\u5f0f\u5b9e\u73b0\u6846\u67b6\u548c\u53ef\u6301\u7eed\u7684\u667a\u80fd\u4f53\u5de5\u7a0b\u5de5\u4f5c\u6d41\uff0c\u89e3\u51b3\u4e86\u5f53\u524dLLM\u667a\u80fd\u4f53\u7814\u7a76\u788e\u7247\u5316\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524dLLM\u667a\u80fd\u4f53\u7814\u7a76\u5b58\u5728\u788e\u7247\u5316\u95ee\u9898\uff0c\u6982\u5ff5\u6846\u67b6\u548c\u65b9\u6cd5\u8bba\u539f\u5219\u7ecf\u5e38\u4e0e\u5e95\u5c42\u5b9e\u73b0\u7ec6\u8282\u4ea4\u7ec7\u5728\u4e00\u8d77\uff0c\u5bfc\u81f4\u8bfb\u8005\u548c\u4f5c\u8005\u5728\u8868\u9762\u4e0d\u540c\u7684\u6982\u5ff5\u4e2d\u8ff7\u5931\u65b9\u5411\u3002\u8fd9\u79cd\u788e\u7247\u5316\u4e3b\u8981\u6e90\u4e8e\u7f3a\u4e4f\u4e00\u4e2a\u53ef\u5206\u6790\u7684\u3001\u81ea\u6d3d\u7684\u5f62\u5f0f\u5316\u6a21\u578b\u6765\u652f\u6301\u5b9e\u73b0\u65e0\u5173\u7684LLM\u667a\u80fd\u4f53\u8868\u5f81\u548c\u6bd4\u8f83\u3002", "method": "\u63d0\u51fa\u4e86\u7ed3\u6784\u4e0a\u4e0b\u6587\u6a21\u578b\u4f5c\u4e3a\u5206\u6790\u548c\u6bd4\u8f83LLM\u667a\u80fd\u4f53\u7684\u5f62\u5f0f\u5316\u6a21\u578b\uff0c\u57fa\u4e8e\u6b64\u5f15\u5165\u4e86\u4e24\u4e2a\u4e92\u8865\u7ec4\u4ef6\uff1a1\uff09\u58f0\u660e\u5f0f\u5b9e\u73b0\u6846\u67b6\uff1b2\uff09\u53ef\u6301\u7eed\u7684\u667a\u80fd\u4f53\u5de5\u7a0b\u5de5\u4f5c\u6d41\u2014\u2014\u8bed\u4e49\u52a8\u6001\u5206\u6790\u3002\u8be5\u5de5\u4f5c\u6d41\u63d0\u4f9b\u4e86\u5bf9\u667a\u80fd\u4f53\u673a\u5236\u7684\u539f\u5219\u6027\u6d1e\u5bdf\uff0c\u5e76\u652f\u6301\u5feb\u901f\u3001\u7cfb\u7edf\u7684\u8bbe\u8ba1\u8fed\u4ee3\u3002", "result": "\u5728\u52a8\u6001\u53d8\u4f53\u7684\u7334\u5b50-\u9999\u8549\u95ee\u9898\u4e0a\u5c55\u793a\u4e86\u5b8c\u6574\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u4f7f\u7528\u8be5\u65b9\u6cd5\u8bbe\u8ba1\u7684\u667a\u80fd\u4f53\u5728\u6700\u5177\u6311\u6218\u6027\u7684\u8bbe\u7f6e\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u8fbe32\u4e2a\u767e\u5206\u70b9\u7684\u6210\u529f\u7387\u63d0\u5347\u3002", "conclusion": "\u63d0\u51fa\u7684\u7ed3\u6784\u4e0a\u4e0b\u6587\u6a21\u578b\u53ca\u76f8\u5173\u6846\u67b6\u548c\u5de5\u4f5c\u6d41\u4e3a\u89e3\u51b3LLM\u667a\u80fd\u4f53\u7814\u7a76\u7684\u788e\u7247\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u652f\u6301\u66f4\u9ad8\u6548\u3001\u66f4\u7cfb\u7edf\u7684\u667a\u80fd\u4f53\u8bbe\u8ba1\u548c\u5f00\u53d1\u3002"}}
{"id": "2602.08311", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08311", "abs": "https://arxiv.org/abs/2602.08311", "authors": ["Shadman Rabby", "Md. Hefzul Hossain Papon", "Sabbir Ahmed", "Nokimul Hasan Arif", "A. B. M. Ashikur Rahman", "Irfan Ahmad"], "title": "Moral Sycophancy in Vision Language Models", "comment": "13 pages, 6 figures, 8 tables, Submitted for review in ACL", "summary": "Sycophancy in Vision-Language Models (VLMs) refers to their tendency to align with user opinions, often at the expense of moral or factual accuracy. While prior studies have explored sycophantic behavior in general contexts, its impact on morally grounded visual decision-making remains insufficiently understood. To address this gap, we present the first systematic study of moral sycophancy in VLMs, analyzing ten widely-used models on the Moralise and M^3oralBench datasets under explicit user disagreement. Our results reveal that VLMs frequently produce morally incorrect follow-up responses even when their initial judgments are correct, and exhibit a consistent asymmetry: models are more likely to shift from morally right to morally wrong judgments than the reverse when exposed to user-induced bias. Follow-up prompts generally degrade performance on Moralise, while yielding mixed or even improved accuracy on M^3oralBench, highlighting dataset-dependent differences in moral robustness. Evaluation using Error Introduction Rate (EIR) and Error Correction Rate (ECR) reveals a clear trade-off: models with stronger error-correction capabilities tend to introduce more reasoning errors, whereas more conservative models minimize errors but exhibit limited ability to self-correct. Finally, initial contexts with a morally right stance elicit stronger sycophantic behavior, emphasizing the vulnerability of VLMs to moral influence and the need for principled strategies to improve ethical consistency and robustness in multimodal AI systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u5206\u6790\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u9053\u5fb7\u8c04\u5a9a\u884c\u4e3a\uff0c\u53d1\u73b0VLMs\u5728\u7528\u6237\u610f\u89c1\u5f71\u54cd\u4e0b\u4f1a\u727a\u7272\u9053\u5fb7\u51c6\u786e\u6027\uff0c\u5b58\u5728\u4ece\u6b63\u786e\u5230\u9519\u8bef\u5224\u65ad\u7684\u4e0d\u5bf9\u79f0\u8f6c\u53d8\uff0c\u4e14\u4e0d\u540c\u6570\u636e\u96c6\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u9053\u5fb7\u9c81\u68d2\u6027\u3002", "motivation": "\u5148\u524d\u7814\u7a76\u63a2\u7d22\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u4e00\u822c\u60c5\u5883\u4e0b\u7684\u8c04\u5a9a\u884c\u4e3a\uff0c\u4f46\u5176\u5bf9\u57fa\u4e8e\u9053\u5fb7\u7684\u89c6\u89c9\u51b3\u7b56\u7684\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7406\u89e3\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u7cfb\u7edf\u5206\u6790VLMs\u4e2d\u7684\u9053\u5fb7\u8c04\u5a9a\u73b0\u8c61\u3002", "method": "\u5728Moralise\u548cM^3oralBench\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e8610\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u7528\u6237\u660e\u786e\u53cd\u5bf9\u7684\u60c5\u5883\u4e0b\u5206\u6790\u5176\u884c\u4e3a\u3002\u4f7f\u7528\u9519\u8bef\u5f15\u5165\u7387\uff08EIR\uff09\u548c\u9519\u8bef\u7ea0\u6b63\u7387\uff08ECR\uff09\u8fdb\u884c\u91cf\u5316\u8bc4\u4f30\u3002", "result": "VLMs\u7ecf\u5e38\u5728\u521d\u59cb\u5224\u65ad\u6b63\u786e\u7684\u60c5\u51b5\u4e0b\u4ea7\u751f\u9053\u5fb7\u9519\u8bef\u7684\u540e\u7eed\u56de\u5e94\uff1b\u5b58\u5728\u660e\u663e\u4e0d\u5bf9\u79f0\u6027\uff1a\u6a21\u578b\u66f4\u503e\u5411\u4e8e\u4ece\u9053\u5fb7\u6b63\u786e\u8f6c\u5411\u9519\u8bef\u5224\u65ad\uff1b\u4e0d\u540c\u6570\u636e\u96c6\u8868\u73b0\u5dee\u5f02\u663e\u8457\uff1b\u5b58\u5728\u6743\u8861\uff1a\u7ea0\u9519\u80fd\u529b\u5f3a\u7684\u6a21\u578b\u5f15\u5165\u66f4\u591a\u63a8\u7406\u9519\u8bef\uff0c\u4fdd\u5b88\u6a21\u578b\u5219\u7ea0\u9519\u80fd\u529b\u6709\u9650\u3002", "conclusion": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5bf9\u9053\u5fb7\u5f71\u54cd\u5177\u6709\u8106\u5f31\u6027\uff0c\u521d\u59cb\u9053\u5fb7\u6b63\u786e\u7acb\u573a\u4f1a\u5f15\u53d1\u66f4\u5f3a\u7684\u8c04\u5a9a\u884c\u4e3a\u3002\u9700\u8981\u5236\u5b9a\u539f\u5219\u6027\u7b56\u7565\u6765\u63d0\u9ad8\u591a\u6a21\u6001AI\u7cfb\u7edf\u7684\u4f26\u7406\u4e00\u81f4\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2602.08335", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08335", "abs": "https://arxiv.org/abs/2602.08335", "authors": ["Yanming Li", "Xuelin Zhang", "WenJie Lu", "Ziye Tang", "Maodong Wu", "Haotian Luo", "Tongtong Wu", "Zijie Peng", "Hongze Mi", "Yibo Feng", "Naiqiang Tan", "Chao Huang", "Hong Chen", "Li Shen"], "title": "Who Deserves the Reward? SHARP: Shapley Credit-based Optimization for Multi-Agent System", "comment": null, "summary": "Integrating Large Language Models (LLMs) with external tools via multi-agent systems offers a promising new paradigm for decomposing and solving complex problems. However, training these systems remains notoriously difficult due to the credit assignment challenge, as it is often unclear which specific functional agent is responsible for the success or failure of decision trajectories. Existing methods typically rely on sparse or globally broadcast rewards, failing to capture individual contributions and leading to inefficient reinforcement learning. To address these limitations, we introduce the Shapley-based Hierarchical Attribution for Reinforcement Policy (SHARP), a novel framework for optimizing multi-agent reinforcement learning via precise credit attribution. SHARP effectively stabilizes training by normalizing agent-specific advantages across trajectory groups, primarily through a decomposed reward mechanism comprising a global broadcast-accuracy reward, a Shapley-based marginal-credit reward for each agent, and a tool-process reward to improve execution efficiency. Extensive experiments across various real-world benchmarks demonstrate that SHARP significantly outperforms recent state-of-the-art baselines, achieving average match improvements of 23.66% and 14.05% over single-agent and multi-agent approaches, respectively.", "AI": {"tldr": "SHARP\u6846\u67b6\u901a\u8fc7\u57fa\u4e8eShapley\u503c\u7684\u5206\u5c42\u4fe1\u7528\u5206\u914d\u673a\u5236\uff0c\u4f18\u5316\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff0c\u89e3\u51b3LLM\u4e0e\u5916\u90e8\u5de5\u5177\u96c6\u6210\u4e2d\u7684\u4fe1\u7528\u5206\u914d\u96be\u9898\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u5916\u90e8\u5de5\u5177\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u96c6\u6210\u7684\u8bad\u7ec3\u9762\u4e34\u4fe1\u7528\u5206\u914d\u6311\u6218\uff0c\u96be\u4ee5\u786e\u5b9a\u5177\u4f53\u529f\u80fd\u667a\u80fd\u4f53\u5bf9\u51b3\u7b56\u8f68\u8ff9\u6210\u529f\u6216\u5931\u8d25\u7684\u8d23\u4efb\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u7a00\u758f\u6216\u5168\u5c40\u5e7f\u64ad\u5956\u52b1\uff0c\u65e0\u6cd5\u6355\u6349\u4e2a\u4f53\u8d21\u732e\uff0c\u5bfc\u81f4\u5f3a\u5316\u5b66\u4e60\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51faSHARP\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8eShapley\u503c\u7684\u5206\u5c42\u4fe1\u7528\u5206\u914d\u673a\u5236\u7a33\u5b9a\u8bad\u7ec3\uff0c\u5305\u62ec\uff1a1) \u5168\u5c40\u5e7f\u64ad\u51c6\u786e\u6027\u5956\u52b1\uff1b2) \u57fa\u4e8eShapley\u503c\u7684\u6bcf\u4e2a\u667a\u80fd\u4f53\u8fb9\u9645\u4fe1\u7528\u5956\u52b1\uff1b3) \u5de5\u5177\u8fc7\u7a0b\u5956\u52b1\u4ee5\u63d0\u9ad8\u6267\u884c\u6548\u7387\u3002\u901a\u8fc7\u8f68\u8ff9\u7ec4\u95f4\u667a\u80fd\u4f53\u7279\u5b9a\u4f18\u52bf\u5f52\u4e00\u5316\u5b9e\u73b0\u7cbe\u786e\u4fe1\u7528\u5206\u914d\u3002", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSHARP\u663e\u8457\u4f18\u4e8e\u6700\u65b0\u57fa\u7ebf\u65b9\u6cd5\uff0c\u76f8\u6bd4\u5355\u667a\u80fd\u4f53\u65b9\u6cd5\u5e73\u5747\u5339\u914d\u6539\u8fdb23.66%\uff0c\u76f8\u6bd4\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\u5e73\u5747\u5339\u914d\u6539\u8fdb14.05%\u3002", "conclusion": "SHARP\u6846\u67b6\u901a\u8fc7\u7cbe\u786e\u7684\u4fe1\u7528\u5206\u914d\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u5916\u90e8\u5de5\u5177\u96c6\u6210\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u4f18\u5316\u65b9\u6848\u3002"}}
{"id": "2602.08339", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.08339", "abs": "https://arxiv.org/abs/2602.08339", "authors": ["Chengyi Du", "Yazhe Niu", "Dazhong Shen", "Luxin Xu"], "title": "CoTZero: Annotation-Free Human-Like Vision Reasoning via Hierarchical Synthetic CoT", "comment": "16 pages 6 figures", "summary": "Recent advances in vision-language models (VLMs) have markedly improved image-text alignment, yet they still fall short of human-like visual reasoning. A key limitation is that many VLMs rely on surface correlations rather than building logically coherent structured representations, which often leads to missed higher-level semantic structure and non-causal relational understanding, hindering compositional and verifiable reasoning. To address these limitations by introducing human models into the reasoning process, we propose CoTZero, an annotation-free paradigm with two components: (i) a dual-stage data synthesis approach and (ii) a cognition-aligned training method. In the first component, we draw inspiration from neurocognitive accounts of compositional productivity and global-to-local analysis. In the bottom-up stage, CoTZero extracts atomic visual primitives and incrementally composes them into diverse, structured question-reasoning forms. In the top-down stage, it enforces hierarchical reasoning by using coarse global structure to guide the interpretation of local details and causal relations. In the cognition-aligned training component, built on the synthesized CoT data, we introduce Cognitively Coherent Verifiable Rewards (CCVR) in Reinforcement Fine-Tuning (RFT) to further strengthen VLMs' hierarchical reasoning and generalization, providing stepwise feedback on reasoning coherence and factual correctness. Experiments show that CoTZero achieves an F1 score of 83.33 percent on our multi-level semantic inconsistency benchmark with lexical-perturbation negatives, across both in-domain and out-of-domain settings. Ablations confirm that each component contributes to more interpretable and human-aligned visual reasoning.", "AI": {"tldr": "CoTZero\uff1a\u4e00\u79cd\u65e0\u9700\u6807\u6ce8\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u8303\u5f0f\uff0c\u901a\u8fc7\u53cc\u9636\u6bb5\u6570\u636e\u5408\u6210\u548c\u8ba4\u77e5\u5bf9\u9f50\u8bad\u7ec3\uff0c\u63d0\u5347\u89c6\u89c9\u63a8\u7406\u7684\u903b\u8f91\u8fde\u8d2f\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u3002", "motivation": "\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e3b\u8981\u4f9d\u8d56\u8868\u9762\u76f8\u5173\u6027\u800c\u975e\u903b\u8f91\u8fde\u8d2f\u7684\u7ed3\u6784\u5316\u8868\u793a\uff0c\u5bfc\u81f4\u9ad8\u5c42\u8bed\u4e49\u7ed3\u6784\u548c\u56e0\u679c\u5173\u7cfb\u7684\u7406\u89e3\u4e0d\u8db3\uff0c\u9650\u5236\u4e86\u7ec4\u5408\u6027\u548c\u53ef\u9a8c\u8bc1\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faCoTZero\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1\uff09\u53cc\u9636\u6bb5\u6570\u636e\u5408\u6210\u65b9\u6cd5\uff08\u81ea\u5e95\u5411\u4e0a\u63d0\u53d6\u89c6\u89c9\u57fa\u5143\u5e76\u7ec4\u5408\uff0c\u81ea\u9876\u5411\u4e0b\u901a\u8fc7\u5168\u5c40\u7ed3\u6784\u6307\u5bfc\u5c40\u90e8\u7ec6\u8282\u89e3\u91ca\uff09\uff1b2\uff09\u8ba4\u77e5\u5bf9\u9f50\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5728\u5f3a\u5316\u5fae\u8c03\u4e2d\u5f15\u5165\u8ba4\u77e5\u4e00\u81f4\u53ef\u9a8c\u8bc1\u5956\u52b1\u673a\u5236\u3002", "result": "\u5728\u591a\u7ea7\u8bed\u4e49\u4e0d\u4e00\u81f4\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523083.33%\u7684F1\u5206\u6570\uff0c\u5728\u57df\u5185\u548c\u57df\u5916\u8bbe\u7f6e\u4e0b\u5747\u8868\u73b0\u4f18\u5f02\uff0c\u6d88\u878d\u5b9e\u9a8c\u8bc1\u5b9e\u5404\u7ec4\u4ef6\u5bf9\u63d0\u5347\u53ef\u89e3\u91ca\u6027\u548c\u4eba\u7c7b\u5bf9\u9f50\u63a8\u7406\u5747\u6709\u8d21\u732e\u3002", "conclusion": "CoTZero\u901a\u8fc7\u5f15\u5165\u4eba\u7c7b\u8ba4\u77e5\u6a21\u578b\u5230\u63a8\u7406\u8fc7\u7a0b\u4e2d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u903b\u8f91\u8fde\u8d2f\u6027\u548c\u7ed3\u6784\u5316\u8868\u793a\u80fd\u529b\uff0c\u4e3a\u5b9e\u73b0\u66f4\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\u7684\u89c6\u89c9\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2602.08344", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08344", "abs": "https://arxiv.org/abs/2602.08344", "authors": ["Qi Guo", "Jianing Wang", "Deyang Kong", "Xiangyu Xi", "Jianfei Zhang", "Yi Lu", "Jingang Wang", "Wei Wang", "Shikun Zhang", "Wei Ye"], "title": "OPE: Overcoming Information Saturation in Parallel Thinking via Outline-Guided Path Exploration", "comment": null, "summary": "Parallel thinking has emerged as a new paradigm for large reasoning models (LRMs) in tackling complex problems. Recent methods leverage Reinforcement Learning (RL) to enhance parallel thinking, aiming to address the limitations in computational resources and effectiveness encountered with supervised fine-tuning. However, most existing studies primarily focus on optimizing the aggregation phase, with limited attention to the path exploration stage. In this paper, we theoretically analyze the optimization of parallel thinking under the Reinforcement Learning with Verifiable Rewards (RLVR) setting, and identify that the mutual information bottleneck among exploration paths fundamentally restricts overall performance. To address this, we propose Outline-Guided Path Exploration (OPE), which explicitly partitions the solution space by generating diverse reasoning outlines prior to parallel path reasoning, thereby reducing information redundancy and improving the diversity of information captured across exploration paths. We implement OPE with an iterative RL strategy that optimizes outline planning and outline-guided reasoning independently. Extensive experiments across multiple challenging mathematical benchmarks demonstrate that OPE effectively improves reasoning performance in different aggregation strategies, enabling LRMs to more reliably discover correct solutions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aOutline-Guided Path Exploration (OPE)\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u591a\u6837\u5316\u7684\u63a8\u7406\u5927\u7eb2\u6765\u5f15\u5bfc\u5e76\u884c\u8def\u5f84\u63a2\u7d22\uff0c\u89e3\u51b3\u4e86\u5e76\u884c\u601d\u7ef4\u4e2d\u8def\u5f84\u95f4\u4fe1\u606f\u5197\u4f59\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u6570\u5b66\u95ee\u9898\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5e76\u884c\u601d\u7ef4\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u805a\u5408\u9636\u6bb5\u7684\u4f18\u5316\uff0c\u800c\u5ffd\u89c6\u4e86\u8def\u5f84\u63a2\u7d22\u9636\u6bb5\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u5f3a\u5316\u5b66\u4e60\u53ef\u9a8c\u8bc1\u5956\u52b1\uff08RLVR\uff09\u8bbe\u7f6e\u4e0b\uff0c\u63a2\u7d22\u8def\u5f84\u95f4\u7684\u4e92\u4fe1\u606f\u74f6\u9888\u4ece\u6839\u672c\u4e0a\u9650\u5236\u4e86\u6574\u4f53\u6027\u80fd\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u51cf\u5c11\u4fe1\u606f\u5197\u4f59\uff0c\u63d0\u9ad8\u8def\u5f84\u63a2\u7d22\u7684\u591a\u6837\u6027\u3002", "method": "\u63d0\u51faOutline-Guided Path Exploration (OPE)\u65b9\u6cd5\uff1a1\uff09\u5728\u5e76\u884c\u8def\u5f84\u63a8\u7406\u524d\u751f\u6210\u591a\u6837\u5316\u7684\u63a8\u7406\u5927\u7eb2\uff0c\u663e\u5f0f\u5212\u5206\u89e3\u7a7a\u95f4\uff1b2\uff09\u91c7\u7528\u8fed\u4ee3\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\uff0c\u5206\u522b\u4f18\u5316\u5927\u7eb2\u89c4\u5212\u548c\u5927\u7eb2\u5f15\u5bfc\u63a8\u7406\uff1b3\uff09\u901a\u8fc7\u51cf\u5c11\u4fe1\u606f\u5197\u4f59\u63d0\u9ad8\u63a2\u7d22\u8def\u5f84\u7684\u4fe1\u606f\u591a\u6837\u6027\u3002", "result": "\u5728\u591a\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660eOPE\u6709\u6548\u63d0\u5347\u4e86\u4e0d\u540c\u805a\u5408\u7b56\u7565\u4e0b\u7684\u63a8\u7406\u6027\u80fd\uff0c\u4f7f\u5927\u578b\u63a8\u7406\u6a21\u578b\u80fd\u591f\u66f4\u53ef\u9760\u5730\u53d1\u73b0\u6b63\u786e\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "OPE\u901a\u8fc7\u663e\u5f0f\u751f\u6210\u591a\u6837\u5316\u63a8\u7406\u5927\u7eb2\u6765\u5f15\u5bfc\u5e76\u884c\u8def\u5f84\u63a2\u7d22\uff0c\u89e3\u51b3\u4e86\u8def\u5f84\u95f4\u4fe1\u606f\u5197\u4f59\u95ee\u9898\uff0c\u4e3a\u5e76\u884c\u601d\u7ef4\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u3002"}}
{"id": "2602.08353", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08353", "abs": "https://arxiv.org/abs/2602.08353", "authors": ["Zhang Jiasheng", "Li Zhangpin", "Wang Mingzhe", "Shao Jie", "Cui Jiangtao", "Li Hui"], "title": "Towards Better Evolution Modeling for Temporal Knowledge Graphs", "comment": "13 pages, 11 figures", "summary": "Temporal knowledge graphs (TKGs) structurally preserve evolving human knowledge. Recent research has focused on designing models to learn the evolutionary nature of TKGs to predict future facts, achieving impressive results. For instance, Hits@10 scores over 0.9 on YAGO dataset. However, we find that existing benchmarks inadvertently introduce a shortcut. Near state-of-the-art performance can be simply achieved by counting co-occurrences, without using any temporal information. In this work, we examine the root cause of this issue, identifying inherent biases in current datasets and over simplified form of evaluation task that can be exploited by these biases. Through this analysis, we further uncover additional limitations of existing benchmarks, including unreasonable formatting of time-interval knowledge, ignorance of learning knowledge obsolescence, and insufficient information for precise evolution understanding, all of which can amplify the shortcut and hinder a fair assessment. Therefore, we introduce the TKG evolution benchmark. It includes four bias-corrected datasets and two novel tasks closely aligned with the evolution process, promoting a more accurate understanding of the challenges in TKG evolution modeling. Benchmark is available at: https://github.com/zjs123/TKG-Benchmark.", "AI": {"tldr": "\u73b0\u6709\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u57fa\u51c6\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\uff1a\u4ec5\u901a\u8fc7\u7edf\u8ba1\u5171\u73b0\u5c31\u80fd\u8fbe\u5230\u63a5\u8fd1SOTA\u7684\u6027\u80fd\uff0c\u65e0\u9700\u4f7f\u7528\u4efb\u4f55\u65f6\u5e8f\u4fe1\u606f\u3002\u4f5c\u8005\u5206\u6790\u4e86\u95ee\u9898\u7684\u6839\u6e90\uff0c\u63d0\u51fa\u4e86\u65b0\u7684TKG\u6f14\u5316\u57fa\u51c6\u3002", "motivation": "\u73b0\u6709TKG\u9884\u6d4b\u6a21\u578b\u867d\u7136\u53d6\u5f97\u4e86\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u7ed3\u679c\uff08\u5982YAGO\u6570\u636e\u96c6\u4e0aHits@10\u8d85\u8fc70.9\uff09\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\u8fd9\u4e9b\u57fa\u51c6\u65e0\u610f\u4e2d\u5f15\u5165\u4e86\u6377\u5f84\u3002\u4ec5\u901a\u8fc7\u7edf\u8ba1\u5171\u73b0\u5c31\u80fd\u8fbe\u5230\u63a5\u8fd1SOTA\u7684\u6027\u80fd\uff0c\u65e0\u9700\u4f7f\u7528\u4efb\u4f55\u65f6\u5e8f\u4fe1\u606f\uff0c\u8fd9\u8868\u660e\u73b0\u6709\u57fa\u51c6\u65e0\u6cd5\u516c\u5e73\u8bc4\u4f30\u6a21\u578b\u7684\u771f\u5b9e\u80fd\u529b\u3002", "method": "\u4f5c\u8005\u5206\u6790\u4e86\u95ee\u9898\u7684\u6839\u672c\u539f\u56e0\uff0c\u8bc6\u522b\u51fa\u5f53\u524d\u6570\u636e\u96c6\u4e2d\u7684\u56fa\u6709\u504f\u5dee\u548c\u8bc4\u4f30\u4efb\u52a1\u7684\u8fc7\u5ea6\u7b80\u5316\u5f62\u5f0f\u3002\u901a\u8fc7\u5206\u6790\u8fdb\u4e00\u6b65\u63ed\u793a\u4e86\u73b0\u6709\u57fa\u51c6\u7684\u66f4\u591a\u5c40\u9650\u6027\uff0c\u5305\u62ec\u65f6\u95f4\u95f4\u9694\u77e5\u8bc6\u7684\u4e0d\u5408\u7406\u683c\u5f0f\u5316\u3001\u5ffd\u7565\u77e5\u8bc6\u8fc7\u65f6\u5b66\u4e60\u3001\u4ee5\u53ca\u7cbe\u786e\u6f14\u5316\u7406\u89e3\u4fe1\u606f\u4e0d\u8db3\u7b49\u3002\u57fa\u4e8e\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86TKG\u6f14\u5316\u57fa\u51c6\uff0c\u5305\u542b\u56db\u4e2a\u504f\u5dee\u6821\u6b63\u7684\u6570\u636e\u96c6\u548c\u4e24\u4e2a\u4e0e\u6f14\u5316\u8fc7\u7a0b\u7d27\u5bc6\u76f8\u5173\u7684\u65b0\u4efb\u52a1\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u57fa\u51c6\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\uff1a1\uff09\u53ef\u4ee5\u901a\u8fc7\u7b80\u5355\u7684\u5171\u73b0\u7edf\u8ba1\u8fbe\u5230\u9ad8\u6027\u80fd\uff1b2\uff09\u65f6\u95f4\u95f4\u9694\u77e5\u8bc6\u683c\u5f0f\u5316\u4e0d\u5408\u7406\uff1b3\uff09\u5ffd\u7565\u77e5\u8bc6\u8fc7\u65f6\u5b66\u4e60\uff1b4\uff09\u7cbe\u786e\u6f14\u5316\u7406\u89e3\u4fe1\u606f\u4e0d\u8db3\u3002\u8fd9\u4e9b\u95ee\u9898\u653e\u5927\u4e86\u6377\u5f84\u6548\u5e94\uff0c\u963b\u788d\u4e86\u516c\u5e73\u8bc4\u4f30\u3002", "conclusion": "\u73b0\u6709TKG\u57fa\u51c6\u5b58\u5728\u7cfb\u7edf\u6027\u7f3a\u9677\uff0c\u65e0\u6cd5\u51c6\u786e\u8bc4\u4f30\u6a21\u578b\u5bf9\u65f6\u5e8f\u6f14\u5316\u7684\u7406\u89e3\u80fd\u529b\u3002\u4f5c\u8005\u63d0\u51fa\u7684TKG\u6f14\u5316\u57fa\u51c6\u901a\u8fc7\u504f\u5dee\u6821\u6b63\u7684\u6570\u636e\u96c6\u548c\u66f4\u8d34\u8fd1\u6f14\u5316\u8fc7\u7a0b\u7684\u4efb\u52a1\uff0c\u4e3aTKG\u6f14\u5316\u5efa\u6a21\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u4fc3\u8fdb\u5bf9TKG\u6f14\u5316\u6311\u6218\u7684\u66f4\u51c6\u786e\u7406\u89e3\u3002"}}
{"id": "2602.08354", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08354", "abs": "https://arxiv.org/abs/2602.08354", "authors": ["Zixuan Huang", "Xin Xia", "Yuxi Ren", "Jianbin Zheng", "Xuanda Wang", "Zhixia Zhang", "Hongyan Xie", "Songshi Liang", "Zehao Chen", "Xuefeng Xiao", "Fuzhen Zhuang", "Jianxin Li", "Yikun Ban", "Deqing Wang"], "title": "Does Your Reasoning Model Implicitly Know When to Stop Thinking?", "comment": null, "summary": "Recent advancements in large reasoning models (LRMs) have greatly improved their capabilities on complex reasoning tasks through Long Chains of Thought (CoTs). However, this approach often results in substantial redundancy, impairing computational efficiency and causing significant delays in real-time applications. Recent studies show that longer reasoning chains are frequently uncorrelated with correctness and can even be detrimental to accuracy. In a further in-depth analysis of this phenomenon, we surprisingly uncover and empirically verify that LRMs implicitly know the appropriate time to stop thinking, while this capability is obscured by current sampling paradigms. Motivated by this, we introduce SAGE (Self-Aware Guided Efficient Reasoning), a novel sampling paradigm that unleashes this efficient reasoning potential. Furthermore, integrating SAGE as mixed sampling into group-based reinforcement learning (SAGE-RL) enables SAGE-RL to effectively incorporate SAGE-discovered efficient reasoning patterns into standard pass@1 inference, markedly enhancing both the reasoning accuracy and efficiency of LRMs across multiple challenging mathematical benchmarks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faSAGE\uff08\u81ea\u6211\u611f\u77e5\u5f15\u5bfc\u9ad8\u6548\u63a8\u7406\uff09\u65b0\u91c7\u6837\u8303\u5f0f\uff0c\u5229\u7528\u5927\u63a8\u7406\u6a21\u578b\u5185\u5728\u7684\"\u77e5\u9053\u4f55\u65f6\u505c\u6b62\u601d\u8003\"\u80fd\u529b\uff0c\u89e3\u51b3\u957f\u601d\u7ef4\u94fe\u5197\u4f59\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u5f53\u524d\u5927\u63a8\u7406\u6a21\u578b\u4f7f\u7528\u957f\u601d\u7ef4\u94fe\u65b9\u6cd5\u5b58\u5728\u4e25\u91cd\u5197\u4f59\u95ee\u9898\uff0c\u635f\u5bb3\u8ba1\u7b97\u6548\u7387\u5e76\u5bfc\u81f4\u5b9e\u65f6\u5e94\u7528\u5ef6\u8fdf\u3002\u7814\u7a76\u53d1\u73b0\u66f4\u957f\u7684\u63a8\u7406\u94fe\u4e0e\u6b63\u786e\u6027\u65e0\u5173\u751a\u81f3\u6709\u5bb3\uff0c\u800c\u6a21\u578b\u672c\u8eab\u9690\u542b\u77e5\u9053\u4f55\u65f6\u505c\u6b62\u601d\u8003\u7684\u80fd\u529b\u88ab\u5f53\u524d\u91c7\u6837\u8303\u5f0f\u63a9\u76d6\u3002", "method": "\u63d0\u51faSAGE\u91c7\u6837\u8303\u5f0f\uff0c\u91ca\u653e\u6a21\u578b\u5185\u5728\u7684\u9ad8\u6548\u63a8\u7406\u6f5c\u529b\u3002\u8fdb\u4e00\u6b65\u5c06SAGE\u4f5c\u4e3a\u6df7\u5408\u91c7\u6837\u6574\u5408\u5230\u57fa\u4e8e\u7fa4\u4f53\u7684\u5f3a\u5316\u5b66\u4e60\u4e2d\uff08SAGE-RL\uff09\uff0c\u4f7fSAGE-RL\u80fd\u591f\u5c06SAGE\u53d1\u73b0\u7684\u9ad8\u6548\u63a8\u7406\u6a21\u5f0f\u878d\u5165\u6807\u51c6pass@1\u63a8\u7406\u3002", "result": "SAGE-RL\u5728\u591a\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u5927\u63a8\u7406\u6a21\u578b\u7684\u63a8\u7406\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528\u5927\u63a8\u7406\u6a21\u578b\u5185\u5728\u7684\"\u77e5\u9053\u4f55\u65f6\u505c\u6b62\u601d\u8003\"\u80fd\u529b\uff0cSAGE\u91c7\u6837\u8303\u5f0f\u80fd\u591f\u6709\u6548\u89e3\u51b3\u957f\u601d\u7ef4\u94fe\u5197\u4f59\u95ee\u9898\uff0c\u4e3a\u9ad8\u6548\u63a8\u7406\u63d0\u4f9b\u65b0\u65b9\u5411\u3002"}}
{"id": "2602.08362", "categories": ["cs.AI", "cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2602.08362", "abs": "https://arxiv.org/abs/2602.08362", "authors": ["Chunxi Ji", "Adnan Darwiche"], "title": "Circuit Representations of Random Forests with Applications to XAI", "comment": null, "summary": "We make three contributions in this paper. First, we present an approach for compiling a random forest classifier into a set of circuits, where each circuit directly encodes the instances in some class of the classifier. We show empirically that our proposed approach is significantly more efficient than existing similar approaches. Next, we utilize this approach to further obtain circuits that are tractable for computing the complete and general reasons of a decision, which are instance abstractions that play a fundamental role in computing explanations. Finally, we propose algorithms for computing the robustness of a decision and all shortest ways to flip it. We illustrate the utility of our contributions by using them to enumerate all sufficient reasons, necessary reasons and contrastive explanations of decisions; to compute the robustness of decisions; and to identify all shortest ways to flip the decisions made by random forest classifiers learned from a wide range of datasets.", "AI": {"tldr": "\u5c06\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u7f16\u8bd1\u4e3a\u7535\u8def\u96c6\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u9ad8\u6548\u8ba1\u7b97\u51b3\u7b56\u7684\u5b8c\u6574\u539f\u56e0\u3001\u9c81\u68d2\u6027\u548c\u6700\u77ed\u7ffb\u8f6c\u8def\u5f84", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5c06\u968f\u673a\u68ee\u6797\u8f6c\u6362\u4e3a\u53ef\u89e3\u91ca\u7535\u8def\u65b9\u9762\u6548\u7387\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u8ba1\u7b97\u51b3\u7b56\u7684\u5b8c\u6574\u539f\u56e0\u3001\u9c81\u68d2\u6027\u548c\u89e3\u91ca", "method": "1. \u63d0\u51fa\u5c06\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u7f16\u8bd1\u4e3a\u7535\u8def\u96c6\u7684\u65b9\u6cd5\uff0c\u6bcf\u4e2a\u7535\u8def\u76f4\u63a5\u7f16\u7801\u5206\u7c7b\u5668\u4e2d\u67d0\u4e2a\u7c7b\u522b\u7684\u5b9e\u4f8b\uff1b2. \u5229\u7528\u8be5\u65b9\u6cd5\u83b7\u5f97\u53ef\u5904\u7406\u7535\u8def\uff0c\u7528\u4e8e\u8ba1\u7b97\u51b3\u7b56\u7684\u5b8c\u6574\u548c\u4e00\u822c\u539f\u56e0\uff1b3. \u63d0\u51fa\u8ba1\u7b97\u51b3\u7b56\u9c81\u68d2\u6027\u548c\u6240\u6709\u6700\u77ed\u7ffb\u8f6c\u8def\u5f84\u7684\u7b97\u6cd5", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6bd4\u73b0\u6709\u7c7b\u4f3c\u65b9\u6cd5\u663e\u8457\u66f4\u9ad8\u6548\uff1b\u80fd\u591f\u679a\u4e3e\u6240\u6709\u5145\u5206\u539f\u56e0\u3001\u5fc5\u8981\u539f\u56e0\u548c\u5bf9\u6bd4\u89e3\u91ca\uff1b\u8ba1\u7b97\u51b3\u7b56\u9c81\u68d2\u6027\uff1b\u8bc6\u522b\u968f\u673a\u68ee\u6797\u51b3\u7b56\u7684\u6240\u6709\u6700\u77ed\u7ffb\u8f6c\u8def\u5f84", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u7535\u8def\u7f16\u8bd1\u6280\u672f\uff0c\u652f\u6301\u591a\u79cd\u89e3\u91ca\u6027\u5206\u6790\u4efb\u52a1\uff0c\u5305\u62ec\u539f\u56e0\u679a\u4e3e\u3001\u9c81\u68d2\u6027\u8ba1\u7b97\u548c\u51b3\u7b56\u7ffb\u8f6c\u8def\u5f84\u8bc6\u522b"}}
{"id": "2602.08369", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08369", "abs": "https://arxiv.org/abs/2602.08369", "authors": ["Xin Zhang", "Kailai Yang", "Chenyue Li", "Hao Li", "Qiyu Wei", "Jun'ichi Tsujii", "Sophia Ananiadou"], "title": "MemAdapter: Fast Alignment across Agent Memory Paradigms via Generative Subgraph Retrieval", "comment": null, "summary": "Memory mechanism is a core component of LLM-based agents, enabling reasoning and knowledge discovery over long-horizon contexts. Existing agent memory systems are typically designed within isolated paradigms (e.g., explicit, parametric, or latent memory) with tightly coupled retrieval methods that hinder cross-paradigm generalization and fusion. In this work, we take a first step toward unifying heterogeneous memory paradigms within a single memory system. We propose MemAdapter, a memory retrieval framework that enables fast alignment across agent memory paradigms. MemAdapter adopts a two-stage training strategy: (1) training a generative subgraph retriever from the unified memory space, and (2) adapting the retriever to unseen memory paradigms by training a lightweight alignment module through contrastive learning. This design improves the flexibility for memory retrieval and substantially reduces alignment cost across paradigms. Comprehensive experiments on three public evaluation benchmarks demonstrate that the generative subgraph retriever consistently outperforms five strong agent memory systems across three memory paradigms and agent model scales. Notably, MemAdapter completes cross-paradigm alignment within 13 minutes on a single GPU, achieving superior performance over original memory retrievers with less than 5% of training compute. Furthermore, MemAdapter enables effective zero-shot fusion across memory paradigms, highlighting its potential as a plug-and-play solution for agent memory systems.", "AI": {"tldr": "MemAdapter\u662f\u4e00\u4e2a\u7edf\u4e00\u5f02\u6784\u5185\u5b58\u8303\u5f0f\u7684\u8bb0\u5fc6\u68c0\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u5b9e\u73b0\u8de8\u8303\u5f0f\u5feb\u901f\u5bf9\u9f50\uff0c\u663e\u8457\u964d\u4f4e\u5bf9\u9f50\u6210\u672c\u5e76\u63d0\u5347\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u667a\u80fd\u4f53\u8bb0\u5fc6\u7cfb\u7edf\u901a\u5e38\u8bbe\u8ba1\u5728\u5b64\u7acb\u8303\u5f0f\uff08\u663e\u5f0f\u3001\u53c2\u6570\u5316\u6216\u6f5c\u5728\u8bb0\u5fc6\uff09\u4e2d\uff0c\u68c0\u7d22\u65b9\u6cd5\u7d27\u5bc6\u8026\u5408\uff0c\u963b\u788d\u4e86\u8de8\u8303\u5f0f\u6cdb\u5316\u548c\u878d\u5408\u3002\u9700\u8981\u7edf\u4e00\u5f02\u6784\u5185\u5b58\u8303\u5f0f\u3002", "method": "\u63d0\u51faMemAdapter\u6846\u67b6\uff1a1\uff09\u4ece\u7edf\u4e00\u8bb0\u5fc6\u7a7a\u95f4\u8bad\u7ec3\u751f\u6210\u5f0f\u5b50\u56fe\u68c0\u7d22\u5668\uff1b2\uff09\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u5bf9\u9f50\u6a21\u5757\uff0c\u4f7f\u68c0\u7d22\u5668\u9002\u5e94\u672a\u89c1\u5185\u5b58\u8303\u5f0f\u3002\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5171\u8bc4\u4f30\u57fa\u51c6\u4e0a\uff0c\u751f\u6210\u5f0f\u5b50\u56fe\u68c0\u7d22\u5668\u5728\u4e09\u79cd\u5185\u5b58\u8303\u5f0f\u548c\u667a\u80fd\u4f53\u6a21\u578b\u89c4\u6a21\u4e0a\u6301\u7eed\u4f18\u4e8e\u4e94\u4e2a\u5f3a\u8bb0\u5fc6\u7cfb\u7edf\u3002\u8de8\u8303\u5f0f\u5bf9\u9f50\u4ec5\u970013\u5206\u949f\uff08\u5355GPU\uff09\uff0c\u4f7f\u7528\u4e0d\u52305%\u7684\u8bad\u7ec3\u8ba1\u7b97\u91cf\u5373\u8d85\u8d8a\u539f\u59cb\u68c0\u7d22\u5668\u6027\u80fd\u3002\u652f\u6301\u8de8\u8303\u5f0f\u96f6\u6837\u672c\u878d\u5408\u3002", "conclusion": "MemAdapter\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u7edf\u4e00\u4e86\u5f02\u6784\u5185\u5b58\u8303\u5f0f\uff0c\u5b9e\u73b0\u4e86\u5feb\u901f\u3001\u4f4e\u6210\u672c\u7684\u8de8\u8303\u5f0f\u5bf9\u9f50\u548c\u878d\u5408\uff0c\u663e\u8457\u63d0\u5347\u4e86\u667a\u80fd\u4f53\u8bb0\u5fc6\u7cfb\u7edf\u7684\u7075\u6d3b\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2602.08373", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08373", "abs": "https://arxiv.org/abs/2602.08373", "authors": ["Feiyu Wu", "Xu Zheng", "Yue Qu", "Zhuocheng Wang", "Zicheng Feng", "Hui Li"], "title": "Grounding Generative Planners in Verifiable Logic: A Hybrid Architecture for Trustworthy Embodied AI", "comment": "Accepted to ICLR 2026. Project page. https://openreview.net/forum?id=wb05ver1k8&noteId=v1Ax8CwI71", "summary": "Large Language Models (LLMs) show promise as planners for embodied AI, but their stochastic nature lacks formal reasoning, preventing strict safety guarantees for physical deployment. Current approaches often rely on unreliable LLMs for safety checks or simply reject unsafe plans without offering repairs. We introduce the Verifiable Iterative Refinement Framework (VIRF), a neuro-symbolic architecture that shifts the paradigm from passive safety gatekeeping to active collaboration. Our core contribution is a tutor-apprentice dialogue where a deterministic Logic Tutor, grounded in a formal safety ontology, provides causal and pedagogical feedback to an LLM planner. This enables intelligent plan repairs rather than mere avoidance. We also introduce a scalable knowledge acquisition pipeline that synthesizes safety knowledge bases from real-world documents, correcting blind spots in existing benchmarks. In challenging home safety tasks, VIRF achieves a perfect 0 percent Hazardous Action Rate (HAR) and a 77.3 percent Goal-Condition Rate (GCR), which is the highest among all baselines. It is highly efficient, requiring only 1.1 correction iterations on average. VIRF demonstrates a principled pathway toward building fundamentally trustworthy and verifiably safe embodied agents.", "AI": {"tldr": "VIRF\u662f\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u901a\u8fc7\u903b\u8f91\u5bfc\u5e08\u4e0eLLM\u89c4\u5212\u5668\u7684\u5bf9\u8bdd\u673a\u5236\uff0c\u5b9e\u73b0\u53ef\u9a8c\u8bc1\u7684\u5b89\u5168\u89c4\u5212\uff0c\u5728\u5bb6\u5ead\u5b89\u5168\u4efb\u52a1\u4e2d\u8fbe\u52300%\u5371\u9669\u884c\u52a8\u7387\u548c77.3%\u76ee\u6807\u8fbe\u6210\u7387\u3002", "motivation": "\u5f53\u524dLLM\u4f5c\u4e3a\u5177\u8eabAI\u89c4\u5212\u5668\u5b58\u5728\u968f\u673a\u6027\uff0c\u7f3a\u4e4f\u5f62\u5f0f\u5316\u63a8\u7406\uff0c\u65e0\u6cd5\u63d0\u4f9b\u4e25\u683c\u7684\u5b89\u5168\u4fdd\u8bc1\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u4e0d\u53ef\u9760\u7684LLM\u8fdb\u884c\u5b89\u5168\u68c0\u67e5\uff0c\u8981\u4e48\u7b80\u5355\u5730\u62d2\u7edd\u4e0d\u5b89\u5168\u8ba1\u5212\u800c\u4e0d\u63d0\u4f9b\u4fee\u590d\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u53ef\u9a8c\u8bc1\u8fed\u4ee3\u7cbe\u70bc\u6846\u67b6(VIRF)\uff0c\u91c7\u7528\u795e\u7ecf\u7b26\u53f7\u67b6\u6784\uff0c\u6838\u5fc3\u662f\u5bfc\u5e08-\u5b66\u5f92\u5bf9\u8bdd\u673a\u5236\uff1a\u57fa\u4e8e\u5f62\u5f0f\u5316\u5b89\u5168\u672c\u4f53\u7684\u786e\u5b9a\u6027\u903b\u8f91\u5bfc\u5e08\u4e3aLLM\u89c4\u5212\u5668\u63d0\u4f9b\u56e0\u679c\u6027\u548c\u6559\u5b66\u6027\u53cd\u9988\uff0c\u5b9e\u73b0\u667a\u80fd\u8ba1\u5212\u4fee\u590d\u800c\u975e\u7b80\u5355\u907f\u514d\u3002\u8fd8\u5f15\u5165\u4e86\u4ece\u73b0\u5b9e\u4e16\u754c\u6587\u6863\u5408\u6210\u5b89\u5168\u77e5\u8bc6\u5e93\u7684\u53ef\u6269\u5c55\u77e5\u8bc6\u83b7\u53d6\u7ba1\u9053\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u5bb6\u5ead\u5b89\u5168\u4efb\u52a1\u4e2d\uff0cVIRF\u5b9e\u73b0\u4e860%\u7684\u5371\u9669\u884c\u52a8\u7387(HAR)\u548c77.3%\u7684\u76ee\u6807\u8fbe\u6210\u7387(GCR)\uff0c\u5728\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\u4e2d\u6700\u9ad8\u3002\u5e73\u5747\u4ec5\u97001.1\u6b21\u4fee\u6b63\u8fed\u4ee3\uff0c\u6548\u7387\u5f88\u9ad8\u3002", "conclusion": "VIRF\u5c55\u793a\u4e86\u6784\u5efa\u6839\u672c\u4e0a\u53ef\u4fe1\u4e14\u53ef\u9a8c\u8bc1\u5b89\u5168\u7684\u5177\u8eab\u667a\u80fd\u4f53\u7684\u539f\u5219\u6027\u9014\u5f84\uff0c\u4ece\u88ab\u52a8\u7684\u5b89\u5168\u628a\u5173\u8f6c\u5411\u4e3b\u52a8\u534f\u4f5c\uff0c\u5b9e\u73b0\u4e86\u667a\u80fd\u8ba1\u5212\u4fee\u590d\u800c\u975e\u7b80\u5355\u62d2\u7edd\u3002"}}
{"id": "2602.08520", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08520", "abs": "https://arxiv.org/abs/2602.08520", "authors": ["Xinhai Sun"], "title": "Reinforcement Inference: Leveraging Uncertainty for Self-Correcting Language Model Reasoning", "comment": null, "summary": "Modern large language models (LLMs) are often evaluated and deployed under a \\emph{one-shot, greedy} inference protocol, especially in professional settings that require deterministic behavior. This regime can systematically under-estimate a fixed model's true capability: many errors arise not from missing knowledge, but from premature commitment under internal ambiguity. We introduce \\emph{Reinforcement Inference}, an entropy-aware inference-time control strategy that uses the model's own uncertainty to selectively invoke a second, more deliberate reasoning attempt, enabling stronger performance \\emph{without any retraining}.\n  On 12,032 MMLU-Pro questions across 14 subjects, using DeepSeek-v3.2 with deterministic decoding in a zero-shot setting, Reinforcement Inference improves accuracy from 60.72\\% to 84.03\\%, while only incurring 61.06\\% additional inference calls. A 100\\% re-asking ablation reaches 84.35\\%, indicating that uncertainty-aware selection captures most of the attainable improvement with substantially less compute. Moreover, a \\emph{prompt-only} ablation underperforms the baseline, suggesting that the gains are not explained by generic `` your output had high entropy, think step-by-step'' prompting alone.\n  Beyond providing a practical inference-time upgrade, our results suggest a broader \\emph{entropy-aware} paradigm for measuring and expanding model capability: because modern decoder-based models generate outputs autoregressively, entropy and related confidence measures arise naturally as first-class control signals during generation. The resulting gap between one-pass greedy inference and uncertainty-conditioned deliberation offers a diagnostic lens on an LLM's latent reasoning horizon and motivates future training objectives that explicitly constrain correctness--confidence alignment.", "AI": {"tldr": "\u63d0\u51faReinforcement Inference\u65b9\u6cd5\uff0c\u5229\u7528\u6a21\u578b\u81ea\u8eab\u7684\u4e0d\u786e\u5b9a\u6027\u9009\u62e9\u6027\u5730\u8fdb\u884c\u7b2c\u4e8c\u6b21\u63a8\u7406\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u786e\u5b9a\u6027\u89e3\u7801\u4e0b\u7684\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u901a\u5e38\u5728\u4e00\u6b21\u6027\u8d2a\u5a6a\u63a8\u7406\u534f\u8bae\u4e0b\u8bc4\u4f30\u548c\u90e8\u7f72\uff0c\u8fd9\u79cd\u673a\u5236\u4f1a\u7cfb\u7edf\u6027\u5730\u4f4e\u4f30\u6a21\u578b\u7684\u771f\u5b9e\u80fd\u529b\uff0c\u56e0\u4e3a\u8bb8\u591a\u9519\u8bef\u5e76\u975e\u6e90\u4e8e\u77e5\u8bc6\u7f3a\u5931\uff0c\u800c\u662f\u5185\u90e8\u6a21\u7cca\u60c5\u51b5\u4e0b\u7684\u8fc7\u65e9\u51b3\u7b56\u3002", "method": "\u5f15\u5165Reinforcement Inference\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u71b5\u7684\u63a8\u7406\u65f6\u63a7\u5236\u7b56\u7565\uff0c\u5229\u7528\u6a21\u578b\u81ea\u8eab\u7684\u4e0d\u786e\u5b9a\u6027\u6765\u9009\u62e9\u6027\u8c03\u7528\u7b2c\u4e8c\u6b21\u66f4\u614e\u91cd\u7684\u63a8\u7406\u5c1d\u8bd5\uff0c\u65e0\u9700\u4efb\u4f55\u91cd\u65b0\u8bad\u7ec3\u3002", "result": "\u5728MMLU-Pro\u768412,032\u4e2a\u95ee\u9898\u4e0a\uff0c\u4f7f\u7528DeepSeek-v3.2\u6a21\u578b\uff0cReinforcement Inference\u5c06\u51c6\u786e\u7387\u4ece60.72%\u63d0\u5347\u523084.03%\uff0c\u4ec5\u589e\u52a061.06%\u7684\u63a8\u7406\u8c03\u7528\u3002100%\u91cd\u65b0\u8be2\u95ee\u7684\u6d88\u878d\u5b9e\u9a8c\u8fbe\u523084.35%\uff0c\u8868\u660e\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u9009\u62e9\u80fd\u4ee5\u66f4\u5c11\u8ba1\u7b97\u83b7\u5f97\u5927\u90e8\u5206\u53ef\u5b9e\u73b0\u7684\u6539\u8fdb\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u63a8\u7406\u65f6\u5347\u7ea7\uff0c\u8fd8\u63d0\u51fa\u4e86\u66f4\u5e7f\u6cdb\u7684\u57fa\u4e8e\u71b5\u7684\u6a21\u578b\u80fd\u529b\u6d4b\u91cf\u548c\u6269\u5c55\u8303\u5f0f\u3002\u4e00\u6b21\u6027\u8d2a\u5a6a\u63a8\u7406\u4e0e\u4e0d\u786e\u5b9a\u6027\u6761\u4ef6\u5316\u6df1\u601d\u4e4b\u95f4\u7684\u5dee\u8ddd\u4e3a\u8bca\u65adLLM\u7684\u6f5c\u5728\u63a8\u7406\u89c6\u91ce\u63d0\u4f9b\u4e86\u89c6\u89d2\uff0c\u5e76\u6fc0\u52b1\u672a\u6765\u8bad\u7ec3\u76ee\u6807\u660e\u786e\u7ea6\u675f\u6b63\u786e\u6027-\u7f6e\u4fe1\u5ea6\u5bf9\u9f50\u3002"}}
{"id": "2602.08597", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08597", "abs": "https://arxiv.org/abs/2602.08597", "authors": ["Roland Bertin-Johannet", "Lara Scipio", "Leopold Mayti\u00e9", "Rufin VanRullen"], "title": "An Attention Mechanism for Robust Multimodal Integration in a Global Workspace Architecture", "comment": null, "summary": "Global Workspace Theory (GWT), inspired by cognitive neuroscience, posits that flexible cognition could arise via the attentional selection of a relevant subset of modalities within a multimodal integration system. This cognitive framework can inspire novel computational architectures for multimodal integration. Indeed, recent implementations of GWT have explored its multimodal representation capabilities, but the related attention mechanisms remain understudied. Here, we propose and evaluate a top-down attention mechanism to select modalities inside a global workspace. First, we demonstrate that our attention mechanism improves noise robustness of a global workspace system on two multimodal datasets of increasing complexity: Simple Shapes and MM-IMDb 1.0. Second, we highlight various cross-task and cross-modality generalization capabilities that are not shared by multimodal attention models from the literature. Comparing against existing baselines on the MM-IMDb 1.0 benchmark, we find our attention mechanism makes the global workspace competitive with the state of the art.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5168\u5c40\u5de5\u4f5c\u7a7a\u95f4\u7406\u8bba\uff08GWT\uff09\u7684\u9876\u90e8\u6ce8\u610f\u673a\u5236\uff0c\u4ee5\u9009\u62e9\u591a\u6a21\u6001\u7cfb\u7edf\u4e2d\u7684\u76f8\u5173\u6a21\u6001\uff0c\u63d0\u9ad8\u4e86\u566a\u58f0\u9c81\u68d2\u6027\u5e76\u5728MM-IMDb\u57fa\u51c6\u4e0a\u8fbe\u5230\u5148\u8fdb\u6c34\u5e73\u3002", "motivation": "\u5168\u5c40\u5de5\u4f5c\u7a7a\u95f4\u7406\u8bba\uff08GWT\uff09\u4f5c\u4e3a\u8ba4\u77e5\u795e\u7ecf\u79d1\u5b66\u542f\u53d1\u7684\u6846\u67b6\uff0c\u867d\u7136\u5df2\u88ab\u7528\u4e8e\u591a\u6a21\u6001\u8868\u793a\uff0c\u4f46\u5176\u6ce8\u610f\u673a\u5236\u7814\u7a76\u4e0d\u8db3\u3002\u7814\u7a76\u8005\u5e0c\u671b\u5f00\u53d1\u4e00\u79cd\u9876\u90e8\u6ce8\u610f\u673a\u5236\u6765\u6539\u8fdbGWT\u5728\u591a\u6a21\u6001\u96c6\u6210\u4e2d\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9876\u90e8\u6ce8\u610f\u673a\u5236\uff0c\u7528\u4e8e\u5728\u5168\u5c40\u5de5\u4f5c\u7a7a\u95f4\u5185\u9009\u62e9\u76f8\u5173\u6a21\u6001\u3002\u8be5\u65b9\u6cd5\u5728\u4e24\u4e2a\u590d\u6742\u5ea6\u9012\u589e\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\uff08Simple Shapes\u548cMM-IMDb 1.0\uff09\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u4e0e\u73b0\u6709\u591a\u6a21\u6001\u6ce8\u610f\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "1\uff09\u6ce8\u610f\u673a\u5236\u63d0\u9ad8\u4e86\u5168\u5c40\u5de5\u4f5c\u7a7a\u95f4\u7cfb\u7edf\u7684\u566a\u58f0\u9c81\u68d2\u6027\uff1b2\uff09\u5c55\u793a\u4e86\u8de8\u4efb\u52a1\u548c\u8de8\u6a21\u6001\u7684\u6cdb\u5316\u80fd\u529b\uff1b3\uff09\u5728MM-IMDb 1.0\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u673a\u5236\u4f7f\u5168\u5c40\u5de5\u4f5c\u7a7a\u95f4\u8fbe\u5230\u4e0e\u5f53\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\u7ade\u4e89\u7684\u6c34\u5e73\u3002", "conclusion": "\u63d0\u51fa\u7684\u9876\u90e8\u6ce8\u610f\u673a\u5236\u6709\u6548\u589e\u5f3a\u4e86\u5168\u5c40\u5de5\u4f5c\u7a7a\u95f4\u7406\u8bba\u5728\u591a\u6a21\u6001\u96c6\u6210\u4e2d\u7684\u6027\u80fd\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u566a\u58f0\u9c81\u68d2\u6027\uff0c\u8fd8\u5c55\u73b0\u4e86\u72ec\u7279\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4f7fGWT\u5728\u591a\u6a21\u6001\u57fa\u51c6\u4e0a\u5177\u6709\u7ade\u4e89\u529b\u3002"}}
{"id": "2602.08603", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08603", "abs": "https://arxiv.org/abs/2602.08603", "authors": ["Teng Wang", "Rong Shan", "Jianghao Lin", "Junjie Wu", "Tianyi Xu", "Jianping Zhang", "Wenteng Chen", "Changwang Zhang", "Zhaoxiang Wang", "Weinan Zhang", "Jun Wang"], "title": "OSCAR: Optimization-Steered Agentic Planning for Composed Image Retrieval", "comment": null, "summary": "Composed image retrieval (CIR) requires complex reasoning over heterogeneous visual and textual constraints. Existing approaches largely fall into two paradigms: unified embedding retrieval, which suffers from single-model myopia, and heuristic agentic retrieval, which is limited by suboptimal, trial-and-error orchestration. To this end, we propose OSCAR, an optimization-steered agentic planning framework for composed image retrieval. We are the first to reformulate agentic CIR from a heuristic search process into a principled trajectory optimization problem. Instead of relying on heuristic trial-and-error exploration, OSCAR employs a novel offline-online paradigm. In the offline phase, we model CIR via atomic retrieval selection and composition as a two-stage mixed-integer programming problem, mathematically deriving optimal trajectories that maximize ground-truth coverage for training samples via rigorous boolean set operations. These trajectories are then stored in a golden library to serve as in-context demonstrations for online steering of VLM planner at online inference time. Extensive experiments on three public benchmarks and a private industrial benchmark show that OSCAR consistently outperforms SOTA baselines. Notably, it achieves superior performance using only 10% of training data, demonstrating strong generalization of planning logic rather than dataset-specific memorization.", "AI": {"tldr": "OSCAR\u662f\u4e00\u4e2a\u7528\u4e8e\u7ec4\u5408\u56fe\u50cf\u68c0\u7d22\u7684\u4f18\u5316\u5f15\u5bfc\u667a\u80fd\u4f53\u89c4\u5212\u6846\u67b6\uff0c\u5c06\u542f\u53d1\u5f0f\u641c\u7d22\u8fc7\u7a0b\u8f6c\u5316\u4e3a\u8f68\u8ff9\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u79bb\u7ebf-\u5728\u7ebf\u8303\u5f0f\u5b9e\u73b0\u66f4\u4f18\u7684\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7ec4\u5408\u56fe\u50cf\u68c0\u7d22\u65b9\u6cd5\u5b58\u5728\u4e24\u79cd\u95ee\u9898\uff1a\u7edf\u4e00\u5d4c\u5165\u68c0\u7d22\u5b58\u5728\u5355\u4e00\u6a21\u578b\u8fd1\u89c6\u95ee\u9898\uff0c\u542f\u53d1\u5f0f\u667a\u80fd\u4f53\u68c0\u7d22\u53d7\u9650\u4e8e\u6b21\u4f18\u7684\u8bd5\u9519\u7f16\u6392\u3002\u9700\u8981\u4e00\u79cd\u66f4\u539f\u5219\u6027\u7684\u65b9\u6cd5\u6765\u5904\u7406\u5f02\u6784\u89c6\u89c9\u548c\u6587\u672c\u7ea6\u675f\u7684\u590d\u6742\u63a8\u7406\u3002", "method": "\u63d0\u51faOSCAR\u6846\u67b6\uff0c\u91c7\u7528\u79bb\u7ebf-\u5728\u7ebf\u8303\u5f0f\uff1a\u79bb\u7ebf\u9636\u6bb5\u5c06CIR\u5efa\u6a21\u4e3a\u4e24\u9636\u6bb5\u6df7\u5408\u6574\u6570\u89c4\u5212\u95ee\u9898\uff0c\u901a\u8fc7\u5e03\u5c14\u96c6\u5408\u8fd0\u7b97\u63a8\u5bfc\u6700\u5927\u5316\u771f\u5b9e\u8986\u76d6\u7684\u6700\u4f18\u8f68\u8ff9\uff1b\u5728\u7ebf\u9636\u6bb5\u4f7f\u7528\u8fd9\u4e9b\u8f68\u8ff9\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u793a\u4f8b\u6765\u5f15\u5bfcVLM\u89c4\u5212\u5668\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5171\u57fa\u51c6\u548c\u4e00\u4e2a\u79c1\u6709\u5de5\u4e1a\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cOSCAR\u59cb\u7ec8\u4f18\u4e8eSOTA\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4ec5\u4f7f\u752810%\u7684\u8bad\u7ec3\u6570\u636e\u5c31\u80fd\u8fbe\u5230\u4f18\u8d8a\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u89c4\u5212\u903b\u8f91\u7684\u5f3a\u6cdb\u5316\u80fd\u529b\u800c\u975e\u6570\u636e\u96c6\u7279\u5b9a\u8bb0\u5fc6\u3002", "conclusion": "OSCAR\u9996\u6b21\u5c06\u667a\u80fd\u4f53CIR\u4ece\u542f\u53d1\u5f0f\u641c\u7d22\u8fc7\u7a0b\u91cd\u65b0\u8868\u8ff0\u4e3a\u539f\u5219\u6027\u8f68\u8ff9\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u6570\u5b66\u63a8\u5bfc\u7684\u6700\u4f18\u8f68\u8ff9\u548c\u79bb\u7ebf-\u5728\u7ebf\u8303\u5f0f\uff0c\u5b9e\u73b0\u4e86\u66f4\u6709\u6548\u7684\u7ec4\u5408\u56fe\u50cf\u68c0\u7d22\u3002"}}
{"id": "2602.08630", "categories": ["cs.AI", "cs.CC"], "pdf": "https://arxiv.org/pdf/2602.08630", "abs": "https://arxiv.org/abs/2602.08630", "authors": ["Jonah Brown-Cohen", "Geoffrey Irving", "Simon C. Marshall", "Ilan Newman", "Georgios Piliouras", "Mario Szegedy"], "title": "Debate is efficient with your time", "comment": "11 Pages, 0 figures", "summary": "AI safety via debate uses two competing models to help a human judge verify complex computational tasks. Previous work has established what problems debate can solve in principle, but has not analysed the practical cost of human oversight: how many queries must the judge make to the debate transcript? We introduce Debate Query Complexity}(DQC), the minimum number of bits a verifier must inspect to correctly decide a debate.\n  Surprisingly, we find that PSPACE/poly (the class of problems which debate can efficiently decide) is precisely the class of functions decidable with O(log n) queries. This characterisation shows that debate is remarkably query-efficient: even for highly complex problems, logarithmic oversight suffices. We also establish that functions depending on all their input bits require Omega(log n) queries, and that any function computable by a circuit of size s satisfies DQC(f) <= log(s) + 3. Interestingly, this last result implies that proving DQC lower bounds of log(n) + 6 for languages in P would yield new circuit lower bounds, connecting debate query complexity to central questions in circuit complexity.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86AI\u5b89\u5168\u8fa9\u8bba\u4e2d\u7684\u4eba\u7c7b\u76d1\u7763\u6210\u672c\uff0c\u5f15\u5165\u4e86\u8fa9\u8bba\u67e5\u8be2\u590d\u6742\u5ea6(DQC)\u6765\u8861\u91cf\u9a8c\u8bc1\u8005\u9700\u8981\u68c0\u67e5\u8fa9\u8bba\u8bb0\u5f55\u7684\u6700\u5c0f\u6bd4\u7279\u6570\uff0c\u53d1\u73b0PSPACE/poly\u95ee\u9898\u7c7b\u6070\u597d\u662fO(log n)\u67e5\u8be2\u53ef\u5224\u5b9a\u7684\u51fd\u6570\u7c7b\uff0c\u8868\u660e\u8fa9\u8bba\u5177\u6709\u6781\u9ad8\u7684\u67e5\u8be2\u6548\u7387\u3002", "motivation": "AI\u5b89\u5168\u8fa9\u8bba\u4f7f\u7528\u4e24\u4e2a\u7ade\u4e89\u6a21\u578b\u5e2e\u52a9\u4eba\u7c7b\u6cd5\u5b98\u9a8c\u8bc1\u590d\u6742\u8ba1\u7b97\u4efb\u52a1\uff0c\u4f46\u4e4b\u524d\u7684\u7814\u7a76\u53ea\u5efa\u7acb\u4e86\u8fa9\u8bba\u5728\u7406\u8bba\u4e0a\u80fd\u89e3\u51b3\u4ec0\u4e48\u95ee\u9898\uff0c\u6ca1\u6709\u5206\u6790\u4eba\u7c7b\u76d1\u7763\u7684\u5b9e\u9645\u6210\u672c\uff1a\u6cd5\u5b98\u9700\u8981\u67e5\u8be2\u8fa9\u8bba\u8bb0\u5f55\u591a\u5c11\u6b21\uff1f", "method": "\u5f15\u5165\u8fa9\u8bba\u67e5\u8be2\u590d\u6742\u5ea6(DQC)\u4f5c\u4e3a\u8861\u91cf\u6307\u6807\uff0c\u5206\u6790\u4e0d\u540c\u590d\u6742\u5ea6\u7c7b\u522b\u51fd\u6570\u7684DQC\u7279\u6027\uff0c\u5efa\u7acbDQC\u4e0e\u7535\u8def\u590d\u6742\u5ea6\u4e4b\u95f4\u7684\u8054\u7cfb\u3002", "result": "\u53d1\u73b0PSPACE/poly\u6070\u597d\u662fO(log n)\u67e5\u8be2\u53ef\u5224\u5b9a\u7684\u51fd\u6570\u7c7b\uff1b\u8bc1\u660e\u4f9d\u8d56\u4e8e\u6240\u6709\u8f93\u5165\u6bd4\u7279\u7684\u51fd\u6570\u9700\u8981\u03a9(log n)\u67e5\u8be2\uff1b\u4efb\u4f55\u53ef\u7531\u5927\u5c0f\u4e3as\u7684\u7535\u8def\u8ba1\u7b97\u7684\u51fd\u6570\u6ee1\u8db3DQC(f) \u2264 log(s) + 3\u3002", "conclusion": "\u8fa9\u8bba\u5177\u6709\u60ca\u4eba\u7684\u67e5\u8be2\u6548\u7387\uff0c\u5373\u4f7f\u5bf9\u4e8e\u9ad8\u5ea6\u590d\u6742\u7684\u95ee\u9898\uff0c\u5bf9\u6570\u7ea7\u76d1\u7763\u5c31\u8db3\u591f\u4e86\u3002\u8bc1\u660eP\u7c7b\u8bed\u8a00\u4e2dDQC\u4e0b\u754c\u4e3alog(n) + 6\u5c06\u4ea7\u751f\u65b0\u7684\u7535\u8def\u4e0b\u754c\uff0c\u5c06\u8fa9\u8bba\u67e5\u8be2\u590d\u6742\u5ea6\u4e0e\u7535\u8def\u590d\u6742\u5ea6\u7684\u6838\u5fc3\u95ee\u9898\u8054\u7cfb\u8d77\u6765\u3002"}}
{"id": "2602.08707", "categories": ["cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.08707", "abs": "https://arxiv.org/abs/2602.08707", "authors": ["Aditya Gulati", "Nuria Oliver"], "title": "Why do we Trust Chatbots? From Normative Principles to Behavioral Drivers", "comment": null, "summary": "As chatbots increasingly blur the boundary between automated systems and human conversation, the foundations of trust in these systems warrant closer examination. While regulatory and policy frameworks tend to define trust in normative terms, the trust users place in chatbots often emerges from behavioral mechanisms. In many cases, this trust is not earned through demonstrated trustworthiness but is instead shaped by interactional design choices that leverage cognitive biases to influence user behavior. Based on this observation, we propose reframing chatbots not as companions or assistants, but as highly skilled salespeople whose objectives are determined by the deploying organization. We argue that the coexistence of competing notions of \"trust\" under a shared term obscures important distinctions between psychological trust formation and normative trustworthiness. Addressing this gap requires further research and stronger support mechanisms to help users appropriately calibrate trust in conversational AI systems.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u804a\u5929\u673a\u5668\u4eba\u4fe1\u4efb\u673a\u5236\uff0c\u6307\u51fa\u7528\u6237\u4fe1\u4efb\u5e38\u6e90\u4e8e\u8bbe\u8ba1\u9009\u62e9\u800c\u975e\u7cfb\u7edf\u53ef\u4fe1\u5ea6\uff0c\u5efa\u8bae\u5c06\u804a\u5929\u673a\u5668\u4eba\u89c6\u4e3a\u9500\u552e\u4eba\u5458\u800c\u975e\u4f34\u4fa3\uff0c\u5f3a\u8c03\u9700\u8981\u533a\u5206\u5fc3\u7406\u4fe1\u4efb\u5f62\u6210\u4e0e\u89c4\u8303\u6027\u53ef\u4fe1\u5ea6", "motivation": "\u968f\u7740\u804a\u5929\u673a\u5668\u4eba\u6a21\u7cca\u81ea\u52a8\u5316\u7cfb\u7edf\u4e0e\u4eba\u7c7b\u5bf9\u8bdd\u7684\u754c\u9650\uff0c\u9700\u8981\u66f4\u4ed4\u7ec6\u5730\u5ba1\u89c6\u8fd9\u4e9b\u7cfb\u7edf\u7684\u4fe1\u4efb\u57fa\u7840\u3002\u5f53\u524d\u76d1\u7ba1\u548c\u653f\u7b56\u6846\u67b6\u503e\u5411\u4e8e\u4ece\u89c4\u8303\u6027\u89d2\u5ea6\u5b9a\u4e49\u4fe1\u4efb\uff0c\u4f46\u7528\u6237\u5bf9\u804a\u5929\u673a\u5668\u4eba\u7684\u4fe1\u4efb\u5f80\u5f80\u6e90\u4e8e\u884c\u4e3a\u673a\u5236\uff0c\u8fd9\u79cd\u4fe1\u4efb\u901a\u5e38\u4e0d\u662f\u901a\u8fc7\u8bc1\u660e\u53ef\u4fe1\u5ea6\u83b7\u5f97\uff0c\u800c\u662f\u901a\u8fc7\u5229\u7528\u8ba4\u77e5\u504f\u89c1\u5f71\u54cd\u7528\u6237\u884c\u4e3a\u7684\u8bbe\u8ba1\u9009\u62e9\u5f62\u6210", "method": "\u57fa\u4e8e\u89c2\u5bdf\u63d0\u51fa\u7406\u8bba\u6846\u67b6\uff1a\u5c06\u804a\u5929\u673a\u5668\u4eba\u91cd\u65b0\u5b9a\u4e49\u4e3a\u9ad8\u5ea6\u719f\u7ec3\u7684\u9500\u552e\u4eba\u5458\uff0c\u5176\u76ee\u6807\u7531\u90e8\u7f72\u7ec4\u7ec7\u51b3\u5b9a\u3002\u5206\u6790\u7ade\u4e89\u6027\"\u4fe1\u4efb\"\u6982\u5ff5\u5171\u5b58\u4e8e\u540c\u4e00\u672f\u8bed\u4e0b\u7684\u95ee\u9898\uff0c\u533a\u5206\u5fc3\u7406\u4fe1\u4efb\u5f62\u6210\u4e0e\u89c4\u8303\u6027\u53ef\u4fe1\u5ea6\u4e4b\u95f4\u7684\u91cd\u8981\u533a\u522b", "result": "\u53d1\u73b0\u7528\u6237\u5bf9\u804a\u5929\u673a\u5668\u4eba\u7684\u4fe1\u4efb\u5f80\u5f80\u4e0d\u662f\u57fa\u4e8e\u7cfb\u7edf\u53ef\u4fe1\u5ea6\uff0c\u800c\u662f\u901a\u8fc7\u4ea4\u4e92\u8bbe\u8ba1\u9009\u62e9\u5851\u9020\uff0c\u8fd9\u4e9b\u8bbe\u8ba1\u5229\u7528\u4e86\u8ba4\u77e5\u504f\u89c1\u6765\u5f71\u54cd\u7528\u6237\u884c\u4e3a\u3002\u6307\u51fa\"\u4fe1\u4efb\"\u4e00\u8bcd\u63a9\u76d6\u4e86\u5fc3\u7406\u4fe1\u4efb\u5f62\u6210\u4e0e\u89c4\u8303\u6027\u53ef\u4fe1\u5ea6\u4e4b\u95f4\u7684\u91cd\u8981\u533a\u522b", "conclusion": "\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u66f4\u5f3a\u6709\u529b\u7684\u652f\u6301\u673a\u5236\uff0c\u5e2e\u52a9\u7528\u6237\u9002\u5f53\u6821\u51c6\u5bf9\u5bf9\u8bddAI\u7cfb\u7edf\u7684\u4fe1\u4efb\u3002\u89e3\u51b3\u8fd9\u4e00\u5dee\u8ddd\u9700\u8981\u533a\u5206\u5fc3\u7406\u4fe1\u4efb\u5f62\u6210\u4e0e\u89c4\u8303\u6027\u53ef\u4fe1\u5ea6\uff0c\u5e76\u8ba4\u8bc6\u5230\u804a\u5929\u673a\u5668\u4eba\u4f5c\u4e3a\"\u9500\u552e\u4eba\u5458\"\u7684\u89d2\u8272\u5b9a\u4f4d"}}
{"id": "2602.08708", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08708", "abs": "https://arxiv.org/abs/2602.08708", "authors": ["Stefan Edelkamp", "Ji\u0159\u00ed Fink", "Petr Gregor", "Anders Jonsson", "Bernhard Nebel"], "title": "Intermediate Results on the Complexity of STRIPS$_{1}^{1}$", "comment": null, "summary": "This paper is based on Bylander's results on the computational complexity of propositional STRIPS planning. He showed that when only ground literals are permitted, determining plan existence is PSPACE-complete even if operators are limited to two preconditions and two postconditions. While NP-hardness is settled, it is unknown whether propositional STRIPS with operators that only have one precondition and one effect is NP-complete. We shed light on the question whether this small solution hypothesis for STRIPS$^1_1$ is true, calling a SAT solver for small instances, introducing the literal graph, and mapping it to Petri nets.", "AI": {"tldr": "\u8be5\u8bba\u6587\u57fa\u4e8eBylander\u5173\u4e8e\u547d\u9898STRIPS\u89c4\u5212\u8ba1\u7b97\u590d\u6742\u6027\u7684\u7ed3\u679c\uff0c\u7814\u7a76\u4e86STRIPS\u2081\u00b9\uff08\u6bcf\u4e2a\u64cd\u4f5c\u7b26\u53ea\u6709\u4e00\u4e2a\u524d\u63d0\u6761\u4ef6\u548c\u4e00\u4e2a\u6548\u679c\uff09\u7684NP\u5b8c\u5907\u6027\u95ee\u9898\uff0c\u901a\u8fc7SAT\u6c42\u89e3\u5668\u3001\u6587\u5b57\u56fe\u548cPetri\u7f51\u6620\u5c04\u6765\u9a8c\u8bc1\"\u5c0f\u89e3\u5047\u8bbe\"\u3002", "motivation": "Bylander\u5df2\u8bc1\u660e\u4ec5\u5141\u8bb8\u57fa\u7840\u6587\u5b57\u65f6\uff0c\u5373\u4f7f\u64cd\u4f5c\u7b26\u9650\u5236\u4e3a\u4e24\u4e2a\u524d\u63d0\u6761\u4ef6\u548c\u4e24\u4e2a\u540e\u7f6e\u6761\u4ef6\uff0c\u5224\u5b9a\u89c4\u5212\u5b58\u5728\u6027\u4e5f\u662fPSPACE\u5b8c\u5168\u7684\u3002\u867d\u7136NP\u96be\u6027\u5df2\u786e\u5b9a\uff0c\u4f46\u547d\u9898STRIPS\u4e2d\u64cd\u4f5c\u7b26\u53ea\u6709\u4e00\u4e2a\u524d\u63d0\u6761\u4ef6\u548c\u4e00\u4e2a\u6548\u679c\u65f6\u662f\u5426\u4e3aNP\u5b8c\u5168\u4ecd\u672a\u77e5\u3002\u672c\u6587\u65e8\u5728\u63a2\u7a76STRIPS\u2081\u00b9\u7684\"\u5c0f\u89e3\u5047\u8bbe\"\u662f\u5426\u6210\u7acb\u3002", "method": "1) \u5bf9\u5c0f\u89c4\u6a21\u5b9e\u4f8b\u8c03\u7528SAT\u6c42\u89e3\u5668\uff1b2) \u5f15\u5165\u6587\u5b57\u56fe\uff08literal graph\uff09\u6982\u5ff5\uff1b3) \u5c06\u95ee\u9898\u6620\u5c04\u5230Petri\u7f51\u8fdb\u884c\u5206\u6790\u3002", "result": "\u8bba\u6587\u901a\u8fc7\u4e0a\u8ff0\u65b9\u6cd5\u4e3aSTRIPS\u2081\u00b9\u7684NP\u5b8c\u5907\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\uff0c\u4f46\u5177\u4f53\u7ed3\u679c\u9700\u8981\u9605\u8bfb\u5b8c\u6574\u8bba\u6587\u624d\u80fd\u786e\u5b9a\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u547d\u9898STRIPS\u89c4\u5212\u4e2d\u64cd\u4f5c\u7b26\u9650\u5236\u4e3a\u4e00\u4e2a\u524d\u63d0\u6761\u4ef6\u548c\u4e00\u4e2a\u6548\u679c\u65f6\u7684\u8ba1\u7b97\u590d\u6742\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u5206\u6790\u6846\u67b6\u548c\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u7406\u89e3STRIPS\u2081\u00b9\u7684\"\u5c0f\u89e3\u5047\u8bbe\"\u3002"}}
{"id": "2602.08715", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08715", "abs": "https://arxiv.org/abs/2602.08715", "authors": ["Miquel Mir\u00f3-Nicolau", "Gabriel Moy\u00e0-Alcover", "Anna Arias-Duart"], "title": "Exploring SAIG Methods for an Objective Evaluation of XAI", "comment": null, "summary": "The evaluation of eXplainable Artificial Intelligence (XAI) methods is a rapidly growing field, characterized by a wide variety of approaches. This diversity highlights the complexity of the XAI evaluation, which, unlike traditional AI assessment, lacks a universally correct ground truth for the explanation, making objective evaluation challenging. One promising direction to address this issue involves the use of what we term Synthetic Artificial Intelligence Ground truth (SAIG) methods, which generate artificial ground truths to enable the direct evaluation of XAI techniques. This paper presents the first review and analysis of SAIG methods. We introduce a novel taxonomy to classify these approaches, identifying seven key features that distinguish different SAIG methods. Our comparative study reveals a concerning lack of consensus on the most effective XAI evaluation techniques, underscoring the need for further research and standardization in this area.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u7efc\u8ff0\u4e86\u5408\u6210\u4eba\u5de5\u667a\u80fd\u57fa\u51c6\u771f\u503c\u65b9\u6cd5\u5728\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\u8bc4\u4f30\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u5206\u7c7b\u6cd5\uff0c\u63ed\u793a\u4e86\u8be5\u9886\u57df\u7f3a\u4e4f\u5171\u8bc6\u7684\u73b0\u72b6\u3002", "motivation": "\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\u8bc4\u4f30\u9886\u57df\u65b9\u6cd5\u591a\u6837\u4e14\u590d\u6742\uff0c\u7531\u4e8e\u7f3a\u4e4f\u89e3\u91ca\u7684\u57fa\u51c6\u771f\u503c\uff0c\u96be\u4ee5\u8fdb\u884c\u5ba2\u89c2\u8bc4\u4f30\u3002\u5408\u6210\u4eba\u5de5\u667a\u80fd\u57fa\u51c6\u771f\u503c\u65b9\u6cd5\u901a\u8fc7\u751f\u6210\u4eba\u5de5\u57fa\u51c6\u771f\u503c\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f46\u8be5\u9886\u57df\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7efc\u8ff0\u548c\u5206\u6790\u3002", "method": "\u672c\u6587\u9996\u6b21\u5bf9SAIG\u65b9\u6cd5\u8fdb\u884c\u5168\u9762\u7efc\u8ff0\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u5206\u7c7b\u6cd5\u6765\u5bf9\u8fd9\u4e9b\u65b9\u6cd5\u8fdb\u884c\u5206\u7c7b\uff0c\u8bc6\u522b\u4e86\u533a\u5206\u4e0d\u540cSAIG\u65b9\u6cd5\u7684\u4e03\u4e2a\u5173\u952e\u7279\u5f81\uff0c\u5e76\u8fdb\u884c\u4e86\u6bd4\u8f83\u7814\u7a76\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\u8bc4\u4f30\u6280\u672f\u4e2d\u7f3a\u4e4f\u5171\u8bc6\uff0c\u8fd9\u51f8\u663e\u4e86\u8be5\u9886\u57df\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u6807\u51c6\u5316\u7684\u8feb\u5207\u9700\u6c42\u3002", "conclusion": "SAIG\u65b9\u6cd5\u4e3a\u89e3\u51b3XAI\u8bc4\u4f30\u4e2d\u7684\u57fa\u51c6\u771f\u503c\u7f3a\u5931\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u4f46\u8be5\u9886\u57df\u9700\u8981\u66f4\u591a\u7814\u7a76\u548c\u6807\u51c6\u5316\u5de5\u4f5c\u6765\u5efa\u7acb\u6709\u6548\u7684\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2602.08754", "categories": ["cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.08754", "abs": "https://arxiv.org/abs/2602.08754", "authors": ["Rose E. Guingrich", "Dvija Mehta", "Umang Bhatt"], "title": "Belief Offloading in Human-AI Interaction", "comment": null, "summary": "What happens when people's beliefs are derived from information provided by an LLM? People's use of LLM chatbots as thought partners can contribute to cognitive offloading, which can have adverse effects on cognitive skills in cases of over-reliance. This paper defines and investigates a particular kind of cognitive offloading in human-AI interaction, \"belief offloading,\" in which people's processes of forming and upholding beliefs are offloaded onto an AI system with downstream consequences on their behavior and the nature of their system of beliefs. Drawing on philosophy, psychology, and computer science research, we clarify the boundary conditions under which belief offloading occurs and provide a descriptive taxonomy of belief offloading and its normative implications. We close with directions for future work to assess the potential for and consequences of belief offloading in human-AI interaction.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4eba\u7c7b\u5c06\u4fe1\u5ff5\u5f62\u6210\u8fc7\u7a0b\u5916\u5305\u7ed9LLM\u7684\u73b0\u8c61\uff0c\u5373\"\u4fe1\u5ff5\u5916\u5305\"\uff0c\u5206\u6790\u5176\u8ba4\u77e5\u5f71\u54cd\u548c\u89c4\u8303\u610f\u4e49", "motivation": "\u968f\u7740LLM\u804a\u5929\u673a\u5668\u4eba\u6210\u4e3a\u4eba\u4eec\u7684\u601d\u7ef4\u4f19\u4f34\uff0c\u8ba4\u77e5\u5378\u8f7d\u53ef\u80fd\u5bfc\u81f4\u8fc7\u5ea6\u4f9d\u8d56\u5e76\u635f\u5bb3\u8ba4\u77e5\u6280\u80fd\uff0c\u9700\u8981\u7814\u7a76\u8fd9\u79cd\u7279\u5b9a\u7c7b\u578b\u7684\u8ba4\u77e5\u5378\u8f7d\u73b0\u8c61", "method": "\u7ed3\u5408\u54f2\u5b66\u3001\u5fc3\u7406\u5b66\u548c\u8ba1\u7b97\u673a\u79d1\u5b66\u7814\u7a76\uff0c\u754c\u5b9a\u4fe1\u5ff5\u5916\u5305\u53d1\u751f\u7684\u8fb9\u754c\u6761\u4ef6\uff0c\u63d0\u4f9b\u63cf\u8ff0\u6027\u5206\u7c7b\u6cd5\u5e76\u5206\u6790\u5176\u89c4\u8303\u610f\u4e49", "result": "\u5b9a\u4e49\u4e86\"\u4fe1\u5ff5\u5916\u5305\"\u6982\u5ff5\uff0c\u5efa\u7acb\u4e86\u5176\u8fb9\u754c\u6761\u4ef6\u548c\u5206\u7c7b\u4f53\u7cfb\uff0c\u5206\u6790\u4e86\u8fd9\u79cd\u884c\u4e3a\u5bf9\u4eba\u4eec\u4fe1\u5ff5\u7cfb\u7edf\u548c\u884c\u4e3a\u7684\u6f5c\u5728\u5f71\u54cd", "conclusion": "\u4fe1\u5ff5\u5916\u5305\u662f\u4eba\u5de5\u667a\u80fd\u4ea4\u4e92\u4e2d\u7684\u91cd\u8981\u73b0\u8c61\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u5176\u53d1\u751f\u673a\u5236\u548c\u540e\u679c\uff0c\u4e3a\u672a\u6765\u5de5\u4f5c\u63d0\u4f9b\u65b9\u5411"}}
{"id": "2602.08783", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08783", "abs": "https://arxiv.org/abs/2602.08783", "authors": ["Zirui Li", "Xuefeng Bai", "Kehai Chen", "Yizhi Li", "Jian Yang", "Chenghua Lin", "Min Zhang"], "title": "Dynamics Within Latent Chain-of-Thought: An Empirical Study of Causal Structure", "comment": "22 pages", "summary": "Latent or continuous chain-of-thought methods replace explicit textual rationales with a number of internal latent steps, but these intermediate computations are difficult to evaluate beyond correlation-based probes. In this paper, we view latent chain-of-thought as a manipulable causal process in representation space by modeling latent steps as variables in a structural causal model (SCM) and analyzing their effects through step-wise $\\mathrm{do}$-interventions. We study two representative paradigms (i.e., Coconut and CODI) on both mathematical and general reasoning tasks to investigate three key questions: (1) which steps are causally necessary for correctness and when answers become decidable early; (2) how does influence propagate across steps, and how does this structure compare to explicit CoT; and (3) do intermediate trajectories retain competing answer modes, and how does output-level commitment differ from representational commitment across steps. We find that latent-step budgets behave less like homogeneous extra depth and more like staged functionality with non-local routing, and we identify a persistent gap between early output bias and late representational commitment. These results motivate mode-conditional and stability-aware analyses -- and corresponding training/decoding objectives -- as more reliable tools for interpreting and improving latent reasoning systems.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u6f5c\u5728\u601d\u7ef4\u94fe\uff08latent CoT\uff09\u7684\u56e0\u679c\u673a\u5236\uff0c\u901a\u8fc7\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u5206\u6790\u6f5c\u5728\u6b65\u9aa4\uff0c\u63a2\u7d22\u4e86\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff1a\u54ea\u4e9b\u6b65\u9aa4\u5bf9\u6b63\u786e\u6027\u56e0\u679c\u5fc5\u8981\u3001\u5f71\u54cd\u5982\u4f55\u4f20\u64ad\u3001\u4e2d\u95f4\u8f68\u8ff9\u662f\u5426\u4fdd\u7559\u7ade\u4e89\u7b54\u6848\u6a21\u5f0f\u3002", "motivation": "\u73b0\u6709\u6f5c\u5728\u601d\u7ef4\u94fe\u65b9\u6cd5\u7528\u5185\u90e8\u6f5c\u5728\u6b65\u9aa4\u66ff\u4ee3\u663e\u5f0f\u6587\u672c\u63a8\u7406\uff0c\u4f46\u8fd9\u4e9b\u4e2d\u95f4\u8ba1\u7b97\u96be\u4ee5\u8bc4\u4f30\uff0c\u53ea\u80fd\u901a\u8fc7\u76f8\u5173\u6027\u63a2\u6d4b\u6765\u7406\u89e3\u3002\u9700\u8981\u66f4\u6df1\u5165\u5730\u7406\u89e3\u6f5c\u5728\u63a8\u7406\u8fc7\u7a0b\u7684\u56e0\u679c\u673a\u5236\u3002", "method": "\u5c06\u6f5c\u5728\u601d\u7ef4\u94fe\u89c6\u4e3a\u8868\u793a\u7a7a\u95f4\u4e2d\u53ef\u64cd\u4f5c\u7684\u56e0\u679c\u8fc7\u7a0b\uff0c\u7528\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u5efa\u6a21\u6f5c\u5728\u6b65\u9aa4\u4f5c\u4e3a\u53d8\u91cf\uff0c\u901a\u8fc7\u9010\u6b65\u5e72\u9884\u5206\u6790\u5176\u6548\u5e94\u3002\u7814\u7a76Coconut\u548cCODI\u4e24\u79cd\u4ee3\u8868\u6027\u8303\u5f0f\u5728\u6570\u5b66\u548c\u901a\u7528\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u53d1\u73b0\u6f5c\u5728\u6b65\u9aa4\u9884\u7b97\u4e0d\u50cf\u540c\u8d28\u7684\u989d\u5916\u6df1\u5ea6\uff0c\u66f4\u50cf\u5177\u6709\u975e\u5c40\u90e8\u8def\u7531\u7684\u5206\u9636\u6bb5\u529f\u80fd\uff1b\u5b58\u5728\u65e9\u671f\u8f93\u51fa\u504f\u89c1\u4e0e\u665a\u671f\u8868\u793a\u627f\u8bfa\u4e4b\u95f4\u7684\u6301\u7eed\u5dee\u8ddd\uff1b\u4e2d\u95f4\u8f68\u8ff9\u786e\u5b9e\u4fdd\u7559\u7ade\u4e89\u7b54\u6848\u6a21\u5f0f\u3002", "conclusion": "\u7ed3\u679c\u652f\u6301\u6a21\u5f0f\u6761\u4ef6\u548c\u7a33\u5b9a\u6027\u611f\u77e5\u5206\u6790\u4f5c\u4e3a\u66f4\u53ef\u9760\u7684\u5de5\u5177\uff0c\u7528\u4e8e\u89e3\u91ca\u548c\u6539\u8fdb\u6f5c\u5728\u63a8\u7406\u7cfb\u7edf\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u8bad\u7ec3/\u89e3\u7801\u76ee\u6807\u3002"}}
{"id": "2602.08796", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08796", "abs": "https://arxiv.org/abs/2602.08796", "authors": ["Kevin Fan", "Jacquelyn A. Bialo", "Hongli Li"], "title": "The Use of AI Tools to Develop and Validate Q-Matrices", "comment": "An earlier version of this study was presented at the Psychometric Society Meeting held in July 2025 in Minneapolis, USA", "summary": "Constructing a Q-matrix is a critical but labor-intensive step in cognitive diagnostic modeling (CDM). This study investigates whether AI tools (i.e., general language models) can support Q-matrix development by comparing AI-generated Q-matrices with a validated Q-matrix from Li and Suen (2013) for a reading comprehension test. In May 2025, multiple AI models were provided with the same training materials as human experts. Agreement among AI-generated Q-matrices, the validated Q-matrix, and human raters' Q-matrices was assessed using Cohen's kappa. Results showed substantial variation across AI models, with Google Gemini 2.5 Pro achieving the highest agreement (Kappa = 0.63) with the validated Q-matrix, exceeding that of all human experts. A follow-up analysis in January 2026 using newer AI versions, however, revealed lower agreement with the validated Q-matrix. Implications and directions for future research are discussed.", "AI": {"tldr": "AI\u5de5\u5177\u5728\u8ba4\u77e5\u8bca\u65ad\u5efa\u6a21\u4e2dQ\u77e9\u9635\u6784\u5efa\u7684\u5e94\u7528\u7814\u7a76\uff1a\u6bd4\u8f83\u4e0d\u540cAI\u6a21\u578b\u751f\u6210\u7684Q\u77e9\u9635\u4e0e\u5df2\u9a8c\u8bc1Q\u77e9\u9635\u7684\u4e00\u81f4\u6027\uff0c\u53d1\u73b0AI\u8868\u73b0\u5b58\u5728\u663e\u8457\u5dee\u5f02\u4e14\u968f\u65f6\u95f4\u53d8\u5316", "motivation": "Q\u77e9\u9635\u6784\u5efa\u662f\u8ba4\u77e5\u8bca\u65ad\u5efa\u6a21\u7684\u5173\u952e\u4f46\u52b3\u52a8\u5bc6\u96c6\u578b\u6b65\u9aa4\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u901a\u7528\u8bed\u8a00\u6a21\u578b\u7b49AI\u5de5\u5177\u662f\u5426\u80fd\u652f\u6301Q\u77e9\u9635\u5f00\u53d1\uff0c\u51cf\u8f7b\u4e13\u5bb6\u8d1f\u62c5", "method": "\u4f7f\u7528\u591a\u4e2aAI\u6a21\u578b\uff08\u5305\u62ecGoogle Gemini 2.5 Pro\u7b49\uff09\u57fa\u4e8e\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u76f8\u540c\u7684\u8bad\u7ec3\u6750\u6599\u751f\u6210Q\u77e9\u9635\uff0c\u5c06AI\u751f\u6210\u7684Q\u77e9\u9635\u4e0eLi\u548cSuen\uff082013\uff09\u5df2\u9a8c\u8bc1\u7684\u9605\u8bfb\u6d4b\u8bd5Q\u77e9\u9635\u8fdb\u884c\u6bd4\u8f83\uff0c\u4f7f\u7528Cohen's kappa\u8bc4\u4f30\u4e00\u81f4\u6027\uff0c\u5e76\u57282026\u5e741\u6708\u8fdb\u884c\u540e\u7eed\u5206\u6790\u6bd4\u8f83\u65b0\u7248\u672cAI\u6a21\u578b", "result": "\u4e0d\u540cAI\u6a21\u578b\u8868\u73b0\u5dee\u5f02\u663e\u8457\uff0cGoogle Gemini 2.5 Pro\u4e0e\u5df2\u9a8c\u8bc1Q\u77e9\u9635\u7684\u4e00\u81f4\u6027\u6700\u9ad8\uff08Kappa=0.63\uff09\uff0c\u8d85\u8fc7\u4e86\u6240\u6709\u4eba\u7c7b\u4e13\u5bb6\uff1b\u4f462026\u5e74\u4f7f\u7528\u65b0\u7248\u672cAI\u7684\u5206\u6790\u663e\u793a\u4e0e\u5df2\u9a8c\u8bc1Q\u77e9\u9635\u7684\u4e00\u81f4\u6027\u964d\u4f4e", "conclusion": "AI\u5de5\u5177\u5728Q\u77e9\u9635\u6784\u5efa\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u8868\u73b0\u5b58\u5728\u6a21\u578b\u95f4\u5dee\u5f02\u4e14\u968f\u65f6\u95f4\u53d8\u5316\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76AI\u5728\u8ba4\u77e5\u8bca\u65ad\u5efa\u6a21\u4e2d\u7684\u53ef\u9760\u6027\u548c\u7a33\u5b9a\u6027"}}
{"id": "2602.08804", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08804", "abs": "https://arxiv.org/abs/2602.08804", "authors": ["Liming Zhou", "Ailing Liu", "Hongwei Liu", "Min He", "Heng Zhang"], "title": "Root Cause Analysis Method Based on Large Language Models with Residual Connection Structures", "comment": null, "summary": "Root cause localization remain challenging in complex and large-scale microservice architectures. The complex fault propagation among microservices and the high dimensionality of telemetry data, including metrics, logs, and traces, limit the effectiveness of existing root cause analysis (RCA) methods. In this paper, a residual-connection-based RCA method using large language model (LLM), named RC-LLM, is proposed. A residual-like hierarchical fusion structure is designed to integrate multi-source telemetry data, while the contextual reasoning capability of large language models is leveraged to model temporal and cross-microservice causal dependencies. Experimental results on CCF-AIOps microservice datasets demonstrate that RC-LLM achieves strong accuracy and efficiency in root cause analysis.", "AI": {"tldr": "RC-LLM\uff1a\u57fa\u4e8e\u6b8b\u5dee\u8fde\u63a5\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5fae\u670d\u52a1\u6839\u56e0\u5206\u6790\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u6e90\u9065\u6d4b\u6570\u636e\u878d\u5408\u548c\u4e0a\u4e0b\u6587\u63a8\u7406\u80fd\u529b\u63d0\u5347\u6545\u969c\u5b9a\u4f4d\u6548\u679c", "motivation": "\u5fae\u670d\u52a1\u67b6\u6784\u4e2d\u6839\u56e0\u5b9a\u4f4d\u9762\u4e34\u6311\u6218\uff1a\u590d\u6742\u7684\u6545\u969c\u4f20\u64ad\u673a\u5236\u548c\u591a\u6e90\u9065\u6d4b\u6570\u636e\uff08\u6307\u6807\u3001\u65e5\u5fd7\u3001\u8ffd\u8e2a\uff09\u7684\u9ad8\u7ef4\u5ea6\u7279\u6027\u9650\u5236\u4e86\u73b0\u6709RCA\u65b9\u6cd5\u7684\u6709\u6548\u6027", "method": "\u63d0\u51faRC-LLM\u65b9\u6cd5\uff1a\u8bbe\u8ba1\u6b8b\u5dee\u5f0f\u5c42\u6b21\u878d\u5408\u7ed3\u6784\u6574\u5408\u591a\u6e90\u9065\u6d4b\u6570\u636e\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u63a8\u7406\u80fd\u529b\u5efa\u6a21\u65f6\u5e8f\u548c\u8de8\u5fae\u670d\u52a1\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb", "result": "\u5728CCF-AIOps\u5fae\u670d\u52a1\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cRC-LLM\u5728\u6839\u56e0\u5206\u6790\u4e2d\u5b9e\u73b0\u4e86\u8f83\u9ad8\u7684\u51c6\u786e\u6027\u548c\u6548\u7387", "conclusion": "RC-LLM\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u6b8b\u5dee\u8fde\u63a5\u7ed3\u6784\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u590d\u6742\u5fae\u670d\u52a1\u67b6\u6784\u4e2d\u7684\u6839\u56e0\u5b9a\u4f4d\u95ee\u9898\uff0c\u4e3a\u6545\u969c\u8bca\u65ad\u63d0\u4f9b\u4e86\u65b0\u601d\u8def"}}
{"id": "2602.08815", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08815", "abs": "https://arxiv.org/abs/2602.08815", "authors": ["Yanglei Gan", "Peng He", "Yuxiang Cai", "Run Lin", "Guanyu Zhou", "Qiao Liu"], "title": "Negative-Aware Diffusion Process for Temporal Knowledge Graph Extrapolation", "comment": null, "summary": "Temporal Knowledge Graph (TKG) reasoning seeks to predict future missing facts from historical evidence. While diffusion models (DM) have recently gained attention for their ability to capture complex predictive distributions, two gaps remain: (i) the generative path is conditioned only on positive evidence, overlooking informative negative context, and (ii) training objectives are dominated by cross-entropy ranking, which improves candidate ordering but provides little supervision over the calibration of the denoised embedding. To bridge this gap, we introduce Negative-Aware Diffusion model for TKG Extrapolation (NADEx). Specifically, NADEx encodes subject-centric histories of entities, relations and temporal intervals into sequential embeddings. NADEx perturbs the query object in the forward process and reconstructs it in reverse with a Transformer denoiser conditioned on the temporal-relational context. We further derive a cosine-alignment regularizer derived from batch-wise negative prototypes, which tightens the decision boundary against implausible candidates. Comprehensive experiments on four public TKG benchmarks demonstrate that NADEx delivers state-of-the-art performance.", "AI": {"tldr": "NADEx\u662f\u4e00\u79cd\u7528\u4e8e\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u7684\u8d1f\u611f\u77e5\u6269\u6563\u6a21\u578b\uff0c\u901a\u8fc7\u7ed3\u5408\u8d1f\u6837\u672c\u539f\u578b\u548c\u4f59\u5f26\u5bf9\u9f50\u6b63\u5219\u5316\uff0c\u5728\u56db\u4e2a\u516c\u5f00\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u6a21\u578b\u5728\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u4e2d\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1) \u751f\u6210\u8def\u5f84\u4ec5\u57fa\u4e8e\u6b63\u6837\u672c\u8bc1\u636e\uff0c\u5ffd\u7565\u4e86\u4fe1\u606f\u4e30\u5bcc\u7684\u8d1f\u4e0a\u4e0b\u6587\uff1b2) \u8bad\u7ec3\u76ee\u6807\u4ee5\u4ea4\u53c9\u71b5\u6392\u5e8f\u4e3a\u4e3b\uff0c\u867d\u7136\u6539\u5584\u4e86\u5019\u9009\u6392\u5e8f\uff0c\u4f46\u5bf9\u53bb\u566a\u5d4c\u5165\u7684\u6821\u51c6\u76d1\u7763\u4e0d\u8db3\u3002", "method": "NADEx\u5c06\u5b9e\u4f53\u3001\u5173\u7cfb\u548c\u65f6\u5e8f\u95f4\u9694\u7684\u4ee5\u4e3b\u4f53\u4e3a\u4e2d\u5fc3\u7684\u5386\u53f2\u7f16\u7801\u4e3a\u5e8f\u5217\u5d4c\u5165\uff0c\u5728\u524d\u5411\u8fc7\u7a0b\u4e2d\u6270\u52a8\u67e5\u8be2\u5bf9\u8c61\uff0c\u5728\u53cd\u5411\u8fc7\u7a0b\u4e2d\u4f7f\u7528Transformer\u53bb\u566a\u5668\u5728\u65f6\u5e8f\u5173\u7cfb\u4e0a\u4e0b\u6587\u4e2d\u91cd\u6784\u3002\u540c\u65f6\u5f15\u5165\u57fa\u4e8e\u6279\u6b21\u8d1f\u6837\u672c\u539f\u578b\u7684\u4f59\u5f26\u5bf9\u9f50\u6b63\u5219\u5316\u5668\uff0c\u6536\u7d27\u51b3\u7b56\u8fb9\u754c\u4ee5\u6392\u9664\u4e0d\u5408\u7406\u5019\u9009\u3002", "result": "\u5728\u56db\u4e2a\u516c\u5f00\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u57fa\u51c6\u4e0a\u7684\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0cNADEx\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "NADEx\u901a\u8fc7\u7ed3\u5408\u8d1f\u6837\u672c\u611f\u77e5\u548c\u4f59\u5f26\u5bf9\u9f50\u6b63\u5219\u5316\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u6269\u6563\u6a21\u578b\u5728\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2602.08835", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08835", "abs": "https://arxiv.org/abs/2602.08835", "authors": ["Andr\u00e9s Holgado-S\u00e1nchez", "Peter Vamplew", "Richard Dazeley", "Sascha Ossowski", "Holger Billhardt"], "title": "Learning the Value Systems of Societies with Preference-based Multi-objective Reinforcement Learning", "comment": "18 pages, 3 figures. To be published in proceedings of the 25th International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS 2026). This is a full version that includes the supplementary material", "summary": "Value-aware AI should recognise human values and adapt to the value systems (value-based preferences) of different users. This requires operationalization of values, which can be prone to misspecification. The social nature of values demands their representation to adhere to multiple users while value systems are diverse, yet exhibit patterns among groups. In sequential decision making, efforts have been made towards personalization for different goals or values from demonstrations of diverse agents. However, these approaches demand manually designed features or lack value-based interpretability and/or adaptability to diverse user preferences.\n  We propose algorithms for learning models of value alignment and value systems for a society of agents in Markov Decision Processes (MDPs), based on clustering and preference-based multi-objective reinforcement learning (PbMORL). We jointly learn socially-derived value alignment models (groundings) and a set of value systems that concisely represent different groups of users (clusters) in a society. Each cluster consists of a value system representing the value-based preferences of its members and an approximately Pareto-optimal policy that reflects behaviours aligned with this value system. We evaluate our method against a state-of-the-art PbMORL algorithm and baselines on two MDPs with human values.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u805a\u7c7b\u548c\u504f\u597d\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5b66\u4e60\u793e\u4f1a\u667a\u80fd\u4f53\u4e2d\u7684\u4ef7\u503c\u5bf9\u9f50\u6a21\u578b\u548c\u4ef7\u503c\u7cfb\u7edf\uff0c\u4ee5\u89e3\u51b3\u4ef7\u503c\u611f\u77e5AI\u4e2d\u4ef7\u503c\u64cd\u4f5c\u5316\u3001\u591a\u6837\u6027\u548c\u53ef\u89e3\u91ca\u6027\u7684\u95ee\u9898\u3002", "motivation": "\u4ef7\u503c\u611f\u77e5AI\u9700\u8981\u8bc6\u522b\u4eba\u7c7b\u4ef7\u503c\u89c2\u5e76\u9002\u5e94\u4e0d\u540c\u7528\u6237\u7684\u4ef7\u503c\u7cfb\u7edf\uff0c\u4f46\u4ef7\u503c\u64cd\u4f5c\u5316\u5bb9\u6613\u51fa\u9519\u3002\u4ef7\u503c\u89c2\u7684\u793e\u4f1a\u6027\u8981\u6c42\u5176\u8868\u793a\u80fd\u9002\u5e94\u591a\u7528\u6237\uff0c\u800c\u4ef7\u503c\u7cfb\u7edf\u65e2\u591a\u6837\u53c8\u5b58\u5728\u7fa4\u4f53\u6a21\u5f0f\u3002\u73b0\u6709\u5e8f\u5217\u51b3\u7b56\u65b9\u6cd5\u9700\u8981\u624b\u52a8\u8bbe\u8ba1\u7279\u5f81\u6216\u7f3a\u4e4f\u4ef7\u503c\u53ef\u89e3\u91ca\u6027\u548c\u9002\u5e94\u6027\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u805a\u7c7b\u548c\u504f\u597d\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60(PbMORL)\u7684\u7b97\u6cd5\uff0c\u5728\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u5b66\u4e60\u793e\u4f1a\u667a\u80fd\u4f53\u7684\u4ef7\u503c\u5bf9\u9f50\u6a21\u578b\u548c\u4ef7\u503c\u7cfb\u7edf\u3002\u8054\u5408\u5b66\u4e60\u793e\u4f1a\u884d\u751f\u7684\u4ef7\u503c\u5bf9\u9f50\u6a21\u578b(groundings)\u548c\u4e00\u7ec4\u7b80\u6d01\u8868\u793a\u4e0d\u540c\u7528\u6237\u7fa4\u4f53\u7684\u4ef7\u503c\u7cfb\u7edf(\u805a\u7c7b)\u3002\u6bcf\u4e2a\u805a\u7c7b\u5305\u542b\u4ee3\u8868\u6210\u5458\u4ef7\u503c\u504f\u597d\u7684\u4ef7\u503c\u7cfb\u7edf\u548c\u53cd\u6620\u4e0e\u8be5\u4ef7\u503c\u7cfb\u7edf\u5bf9\u9f50\u884c\u4e3a\u7684\u8fd1\u4f3c\u5e15\u7d2f\u6258\u6700\u4f18\u7b56\u7565\u3002", "result": "\u5728\u4e24\u4e2a\u5305\u542b\u4eba\u7c7b\u4ef7\u503c\u7684MDP\u73af\u5883\u4e2d\uff0c\u8bc4\u4f30\u4e86\u8be5\u65b9\u6cd5\u4e0e\u6700\u5148\u8fdb\u7684PbMORL\u7b97\u6cd5\u548c\u57fa\u7ebf\u7684\u6027\u80fd\u5bf9\u6bd4\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5b66\u4e60\u793e\u4f1a\u667a\u80fd\u4f53\u7684\u4ef7\u503c\u5bf9\u9f50\u6a21\u578b\u548c\u4ef7\u503c\u7cfb\u7edf\uff0c\u89e3\u51b3\u4e86\u4ef7\u503c\u64cd\u4f5c\u5316\u3001\u591a\u6837\u6027\u548c\u53ef\u89e3\u91ca\u6027\u7684\u6311\u6218\uff0c\u4e3a\u4ef7\u503c\u611f\u77e5AI\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6280\u672f\u6846\u67b6\u3002"}}
{"id": "2602.08848", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08848", "abs": "https://arxiv.org/abs/2602.08848", "authors": ["Quentin Cohen-Solal", "Alexandre Niveau", "Maroua Bouzid"], "title": "Deciding the Satisfiability of Combined Qualitative Constraint Networks", "comment": null, "summary": "Among the various forms of reasoning studied in the context of artificial intelligence, qualitative reasoning makes it possible to infer new knowledge in the context of imprecise, incomplete information without numerical values. In this paper, we propose a formal framework unifying several forms of extensions and combinations of qualitative formalisms, including multi-scale reasoning, temporal sequences, and loose integrations. This framework makes it possible to reason in the context of each of these combinations and extensions, but also to study in a unified way the satisfiability decision and its complexity. In particular, we establish two complementary theorems guaranteeing that the satisfiability decision is polynomial, and we use them to recover the known results of the size-topology combination. We also generalize the main definition of qualitative formalism to include qualitative formalisms excluded from the definitions of the literature, important in the context of combinations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u7528\u4e8e\u6574\u5408\u591a\u79cd\u5b9a\u6027\u5f62\u5f0f\u4e3b\u4e49\u7684\u6269\u5c55\u548c\u7ec4\u5408\uff0c\u5305\u62ec\u591a\u5c3a\u5ea6\u63a8\u7406\u3001\u65f6\u95f4\u5e8f\u5217\u548c\u677e\u6563\u96c6\u6210\uff0c\u5e76\u7814\u7a76\u4e86\u53ef\u6ee1\u8db3\u6027\u51b3\u7b56\u53ca\u5176\u590d\u6742\u6027\u3002", "motivation": "\u5728\u4eba\u5de5\u667a\u80fd\u7684\u63a8\u7406\u7814\u7a76\u4e2d\uff0c\u5b9a\u6027\u63a8\u7406\u80fd\u591f\u5728\u4fe1\u606f\u4e0d\u7cbe\u786e\u3001\u4e0d\u5b8c\u6574\u4e14\u7f3a\u4e4f\u6570\u503c\u7684\u60c5\u51b5\u4e0b\u63a8\u65ad\u65b0\u77e5\u8bc6\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u5b9a\u6027\u5f62\u5f0f\u4e3b\u4e49\u5b9a\u4e49\u6392\u9664\u4e86\u67d0\u4e9b\u5728\u7ec4\u5408\u80cc\u666f\u4e0b\u91cd\u8981\u7684\u5f62\u5f0f\u4e3b\u4e49\uff0c\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\u6765\u6574\u5408\u5404\u79cd\u6269\u5c55\u548c\u7ec4\u5408\u5f62\u5f0f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u7edf\u4e00\u4e86\u591a\u79cd\u5b9a\u6027\u5f62\u5f0f\u4e3b\u4e49\u7684\u6269\u5c55\u548c\u7ec4\u5408\uff0c\u5305\u62ec\u591a\u5c3a\u5ea6\u63a8\u7406\u3001\u65f6\u95f4\u5e8f\u5217\u548c\u677e\u6563\u96c6\u6210\u3002\u8be5\u6846\u67b6\u4e0d\u4ec5\u652f\u6301\u5728\u8fd9\u4e9b\u7ec4\u5408\u548c\u6269\u5c55\u80cc\u666f\u4e0b\u8fdb\u884c\u63a8\u7406\uff0c\u8fd8\u80fd\u4ee5\u7edf\u4e00\u65b9\u5f0f\u7814\u7a76\u53ef\u6ee1\u8db3\u6027\u51b3\u7b56\u53ca\u5176\u590d\u6742\u6027\u3002\u7279\u522b\u5730\uff0c\u5efa\u7acb\u4e86\u4e24\u4e2a\u4e92\u8865\u5b9a\u7406\u6765\u4fdd\u8bc1\u53ef\u6ee1\u8db3\u6027\u51b3\u7b56\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u590d\u6742\u5ea6\u3002", "result": "\u901a\u8fc7\u63d0\u51fa\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u6062\u590d\u4e86\u5c3a\u5bf8-\u62d3\u6251\u7ec4\u5408\u7684\u5df2\u77e5\u7ed3\u679c\uff0c\u5e76\u5c06\u5b9a\u6027\u5f62\u5f0f\u4e3b\u4e49\u7684\u4e3b\u8981\u5b9a\u4e49\u63a8\u5e7f\u5230\u5305\u542b\u6587\u732e\u5b9a\u4e49\u4e2d\u6392\u9664\u4f46\u5728\u7ec4\u5408\u80cc\u666f\u4e0b\u91cd\u8981\u7684\u5b9a\u6027\u5f62\u5f0f\u4e3b\u4e49\u3002\u5efa\u7acb\u4e86\u4e24\u4e2a\u4e92\u8865\u5b9a\u7406\uff0c\u4fdd\u8bc1\u4e86\u53ef\u6ee1\u8db3\u6027\u51b3\u7b56\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u590d\u6742\u5ea6\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u80fd\u591f\u6574\u5408\u591a\u79cd\u5b9a\u6027\u63a8\u7406\u7684\u6269\u5c55\u548c\u7ec4\u5408\u5f62\u5f0f\uff0c\u4e0d\u4ec5\u6269\u5c55\u4e86\u5b9a\u6027\u5f62\u5f0f\u4e3b\u4e49\u7684\u5b9a\u4e49\u8303\u56f4\uff0c\u8fd8\u4e3a\u53ef\u6ee1\u8db3\u6027\u51b3\u7b56\u63d0\u4f9b\u4e86\u591a\u9879\u5f0f\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u7406\u8bba\u4fdd\u8bc1\uff0c\u5bf9\u4eba\u5de5\u667a\u80fd\u4e2d\u7684\u5b9a\u6027\u63a8\u7406\u7814\u7a76\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2602.08905", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08905", "abs": "https://arxiv.org/abs/2602.08905", "authors": ["Jiawei Liu", "Xiting Wang", "Yuanyuan Zhong", "Defu Lian", "Yu Yang"], "title": "Efficient and Stable Reinforcement Learning for Diffusion Language Models", "comment": "13 pages, 3 figures", "summary": "Reinforcement Learning (RL) is crucial for unlocking the complex reasoning capabilities of Diffusion-based Large Language Models (dLLMs). However, applying RL to dLLMs faces unique challenges in efficiency and stability. To address these challenges, we propose Spatio-Temporal Pruning (STP), a framework designed to simultaneously improve the efficiency and stability of RL for dLLMs. STP compresses the redundancy in the generative process through: (1) \\textit{spatial pruning}, which constrains the exploration space using static priors; and (2) \\textit{temporal pruning}, which bypasses redundant late-stage refinement steps. Our theoretical analysis demonstrates that STP strictly reduces the variance of the log-likelihood estimation, thereby ensuring more stable policy updates. Extensive experiments demonstrate that STP surpasses state-of-the-art baselines in both efficiency and accuracy. Our code is available at https://github.com/Lolo1222/STP.", "AI": {"tldr": "STP\u6846\u67b6\u901a\u8fc7\u7a7a\u95f4\u526a\u679d\u548c\u65f6\u95f4\u526a\u679d\u63d0\u9ad8\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u7684\u6548\u7387\u548c\u7a33\u5b9a\u6027", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5bf9\u91ca\u653e\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u7684\u590d\u6742\u63a8\u7406\u80fd\u529b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5e94\u7528\u4e8edLLMs\u65f6\u9762\u4e34\u6548\u7387\u548c\u7a33\u5b9a\u6027\u65b9\u9762\u7684\u72ec\u7279\u6311\u6218", "method": "\u63d0\u51fa\u65f6\u7a7a\u526a\u679d\u6846\u67b6\uff0c\u901a\u8fc7\u7a7a\u95f4\u526a\u679d\uff08\u4f7f\u7528\u9759\u6001\u5148\u9a8c\u7ea6\u675f\u63a2\u7d22\u7a7a\u95f4\uff09\u548c\u65f6\u95f4\u526a\u679d\uff08\u7ed5\u8fc7\u5197\u4f59\u7684\u540e\u671f\u7ec6\u5316\u6b65\u9aa4\uff09\u538b\u7f29\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u5197\u4f59", "result": "\u7406\u8bba\u5206\u6790\u8868\u660eSTP\u4e25\u683c\u964d\u4f4e\u4e86\u5bf9\u6570\u4f3c\u7136\u4f30\u8ba1\u7684\u65b9\u5dee\uff0c\u786e\u4fdd\u66f4\u7a33\u5b9a\u7684\u7b56\u7565\u66f4\u65b0\uff1b\u5b9e\u9a8c\u8bc1\u660eSTP\u5728\u6548\u7387\u548c\u51c6\u786e\u6027\u4e0a\u90fd\u8d85\u8d8a\u4e86\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "STP\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86dLLMs\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6548\u7387\u548c\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u4e3a\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.08939", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08939", "abs": "https://arxiv.org/abs/2602.08939", "authors": ["Longling Geng", "Andy Ouyang", "Theodore Wu", "Daphne Barretto", "Matthew John Hayes", "Rachael Cooper", "Yuqiao Zeng", "Sameer Vijay", "Gia Ancone", "Ankit Rai", "Matthew Wolfman", "Patrick Flanagan", "Edward Y. Chang"], "title": "CausalT5K: Diagnosing and Informing Refusal for Trustworthy Causal Reasoning of Skepticism, Sycophancy, Detection-Correction, and Rung Collapse", "comment": "17 pages, 20 tables, figures", "summary": "LLM failures in causal reasoning, including sycophancy, rung collapse, and miscalibrated refusal, are well-documented, yet progress on remediation is slow because no benchmark enables systematic diagnosis. We introduce CausalT5K, a diagnostic benchmark of over 5,000 cases across 10 domains that tests three critical capabilities: (1) detecting rung collapse, where models answer interventional queries with associational evidence; (2) resisting sycophantic drift under adversarial pressure; and (3) generating Wise Refusals that specify missing information when evidence is underdetermined. Unlike synthetic benchmarks, CausalT5K embeds causal traps in realistic narratives and decomposes performance into Utility (sensitivity) and Safety (specificity), revealing failure modes invisible to aggregate accuracy. Developed through a rigorous human-machine collaborative pipeline involving 40 domain experts, iterative cross-validation cycles, and composite verification via rule-based, LLM, and human scoring, CausalT5K implements Pearl's Ladder of Causation as research infrastructure. Preliminary experiments reveal a Four-Quadrant Control Landscape where static audit policies universally fail, a finding that demonstrates CausalT5K's value for advancing trustworthy reasoning systems. Repository: https://github.com/genglongling/CausalT5kBench", "AI": {"tldr": "CausalT5K\u662f\u4e00\u4e2a\u5305\u542b5000\u591a\u4e2a\u6848\u4f8b\u7684\u8bca\u65ad\u57fa\u51c6\uff0c\u7528\u4e8e\u7cfb\u7edf\u68c0\u6d4bLLM\u5728\u56e0\u679c\u63a8\u7406\u4e2d\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u5305\u62ec\u9636\u68af\u574d\u584c\u3001\u963f\u8c00\u6027\u6f02\u79fb\u548c\u9519\u8bef\u6821\u51c6\u7684\u62d2\u7edd\uff0c\u901a\u8fc7\u73b0\u5b9e\u53d9\u4e8b\u5d4c\u5165\u56e0\u679c\u9677\u9631\uff0c\u5c06\u6027\u80fd\u5206\u89e3\u4e3a\u6548\u7528\u548c\u5b89\u5168\u6027\u3002", "motivation": "LLM\u5728\u56e0\u679c\u63a8\u7406\u4e2d\u5b58\u5728\u9636\u68af\u574d\u584c\u3001\u963f\u8c00\u6027\u6f02\u79fb\u548c\u9519\u8bef\u6821\u51c6\u7684\u62d2\u7edd\u7b49\u5931\u8d25\u6a21\u5f0f\uff0c\u4f46\u7531\u4e8e\u7f3a\u4e4f\u80fd\u591f\u8fdb\u884c\u7cfb\u7edf\u8bca\u65ad\u7684\u57fa\u51c6\uff0c\u76f8\u5173\u6539\u8fdb\u8fdb\u5c55\u7f13\u6162\u3002", "method": "\u5f00\u53d1\u4e86\u5305\u542b5000\u591a\u4e2a\u6848\u4f8b\u7684CausalT5K\u8bca\u65ad\u57fa\u51c6\uff0c\u6db5\u76d610\u4e2a\u9886\u57df\uff0c\u901a\u8fc740\u540d\u9886\u57df\u4e13\u5bb6\u53c2\u4e0e\u7684\u4eba\u673a\u534f\u4f5c\u6d41\u7a0b\u3001\u8fed\u4ee3\u4ea4\u53c9\u9a8c\u8bc1\u5468\u671f\uff0c\u4ee5\u53ca\u57fa\u4e8e\u89c4\u5219\u3001LLM\u548c\u4eba\u5de5\u8bc4\u5206\u7684\u590d\u5408\u9a8c\u8bc1\u65b9\u6cd5\u5b9e\u73b0\u3002", "result": "\u521d\u6b65\u5b9e\u9a8c\u63ed\u793a\u4e86\u56db\u8c61\u9650\u63a7\u5236\u666f\u89c2\uff0c\u663e\u793a\u9759\u6001\u5ba1\u8ba1\u7b56\u7565\u666e\u904d\u5931\u8d25\uff0c\u8bc1\u660e\u4e86CausalT5K\u5728\u63a8\u8fdb\u53ef\u4fe1\u63a8\u7406\u7cfb\u7edf\u65b9\u9762\u7684\u4ef7\u503c\u3002", "conclusion": "CausalT5K\u4f5c\u4e3a\u7814\u7a76\u57fa\u7840\u8bbe\u65bd\uff0c\u5b9e\u73b0\u4e86Pearl\u7684\u56e0\u679c\u9636\u68af\uff0c\u80fd\u591f\u63ed\u793a\u805a\u5408\u51c6\u786e\u6027\u65e0\u6cd5\u770b\u5230\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u4e3a\u63a8\u8fdb\u53ef\u4fe1\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2602.08948", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08948", "abs": "https://arxiv.org/abs/2602.08948", "authors": ["Chen Jin", "Ryutaro Tanno", "Tom Diethe", "Philip Teare"], "title": "CoRefine: Confidence-Guided Self-Refinement for Adaptive Test-Time Compute", "comment": null, "summary": "Large Language Models (LLMs) often rely on test-time scaling via parallel decoding (for example, 512 samples) to boost reasoning accuracy, but this incurs substantial compute. We introduce CoRefine, a confidence-guided self-refinement method that achieves competitive accuracy using a fraction of the tokens via a lightweight 211k-parameter Conv1D controller atop a frozen LLM. The controller consumes full-trace confidence to decide whether to halt, re-examine, or try a different approach, enabling targeted self-correction with an average of 2.7 refinement steps per problem and roughly 190-fold token reduction relative to 512-sample baselines. Across diverse reasoning benchmarks and three open-source models, the controller achieves 92.6 percent precision when it confidently halts, indicating that confidence dynamics reliably signal correctness without ground-truth verification. We extend this to CoRefine-Tree, a hybrid sequential-parallel variant that adaptively balances exploration and exploitation, with easy serving integration and verifier compatibility. By treating confidence as a control signal rather than a correctness guarantee, CoRefine provides a modular primitive for scalable reasoning and agentic settings with imperfect verifiers.", "AI": {"tldr": "CoRefine\u662f\u4e00\u79cd\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u5f15\u5bfc\u7684\u81ea\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u63a7\u5236\u5668\u5b9e\u73b0\u9ad8\u6548\u63a8\u7406\uff0c\u5927\u5e45\u51cf\u5c11\u8ba1\u7b97\u6210\u672c", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u901a\u5e38\u4f9d\u8d56\u5e76\u884c\u89e3\u7801\uff08\u5982512\u4e2a\u6837\u672c\uff09\u6765\u63d0\u9ad8\u63a8\u7406\u51c6\u786e\u6027\uff0c\u4f46\u8fd9\u4f1a\u5e26\u6765\u5de8\u5927\u7684\u8ba1\u7b97\u5f00\u9500\u3002\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u63a8\u7406\u6027\u80fd", "method": "\u5f15\u5165CoRefine\u65b9\u6cd5\uff0c\u5728\u51bb\u7ed3\u7684LLM\u4e0a\u6dfb\u52a0\u4e00\u4e2a\u8f7b\u91cf\u7ea7211k\u53c2\u6570\u7684Conv1D\u63a7\u5236\u5668\u3002\u63a7\u5236\u5668\u57fa\u4e8e\u5b8c\u6574\u8ddf\u8e2a\u7f6e\u4fe1\u5ea6\u51b3\u5b9a\u662f\u5426\u505c\u6b62\u3001\u91cd\u65b0\u68c0\u67e5\u6216\u5c1d\u8bd5\u4e0d\u540c\u65b9\u6cd5\uff0c\u5b9e\u73b0\u6709\u9488\u5bf9\u6027\u7684\u81ea\u6211\u4fee\u6b63", "result": "\u6bcf\u4e2a\u95ee\u9898\u5e73\u5747\u53ea\u97002.7\u4e2a\u4f18\u5316\u6b65\u9aa4\uff0c\u76f8\u5bf9\u4e8e512\u6837\u672c\u57fa\u7ebf\u51cf\u5c11\u7ea6190\u500d\u7684token\u4f7f\u7528\u3002\u5728\u63a7\u5236\u5668\u81ea\u4fe1\u505c\u6b62\u65f6\u8fbe\u523092.6%\u7684\u7cbe\u786e\u5ea6\uff0c\u8868\u660e\u7f6e\u4fe1\u5ea6\u52a8\u6001\u53ef\u9760\u5730\u6307\u793a\u6b63\u786e\u6027\u3002\u6269\u5c55\u5230CoRefine-Tree\u6df7\u5408\u53d8\u4f53\uff0c\u81ea\u9002\u5e94\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528", "conclusion": "\u901a\u8fc7\u5c06\u7f6e\u4fe1\u5ea6\u89c6\u4e3a\u63a7\u5236\u4fe1\u53f7\u800c\u975e\u6b63\u786e\u6027\u4fdd\u8bc1\uff0cCoRefine\u4e3a\u53ef\u6269\u5c55\u63a8\u7406\u548c\u4e0d\u5b8c\u7f8e\u9a8c\u8bc1\u5668\u7684\u667a\u80fd\u4f53\u8bbe\u7f6e\u63d0\u4f9b\u4e86\u6a21\u5757\u5316\u539f\u8bed"}}
{"id": "2602.08968", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08968", "abs": "https://arxiv.org/abs/2602.08968", "authors": ["Lucas Maes", "Quentin Le Lidec", "Dan Haramati", "Nassim Massaudi", "Damien Scieur", "Yann LeCun", "Randall Balestriero"], "title": "stable-worldmodel-v1: Reproducible World Modeling Research and Evaluation", "comment": null, "summary": "World Models have emerged as a powerful paradigm for learning compact, predictive representations of environment dynamics, enabling agents to reason, plan, and generalize beyond direct experience. Despite recent interest in World Models, most available implementations remain publication-specific, severely limiting their reusability, increasing the risk of bugs, and reducing evaluation standardization. To mitigate these issues, we introduce stable-worldmodel (SWM), a modular, tested, and documented world-model research ecosystem that provides efficient data-collection tools, standardized environments, planning algorithms, and baseline implementations. In addition, each environment in SWM enables controllable factors of variation, including visual and physical properties, to support robustness and continual learning research. Finally, we demonstrate the utility of SWM by using it to study zero-shot robustness in DINO-WM.", "AI": {"tldr": "SWM\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u3001\u7ecf\u8fc7\u6d4b\u8bd5\u548c\u6587\u6863\u5316\u7684\u4e16\u754c\u6a21\u578b\u7814\u7a76\u751f\u6001\u7cfb\u7edf\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u4e16\u754c\u6a21\u578b\u5b9e\u73b0\u7f3a\u4e4f\u53ef\u91cd\u7528\u6027\u3001\u6807\u51c6\u5316\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u5927\u591a\u6570\u4e16\u754c\u6a21\u578b\u5b9e\u73b0\u90fd\u662f\u9488\u5bf9\u7279\u5b9a\u8bba\u6587\u7684\uff0c\u8fd9\u4e25\u91cd\u9650\u5236\u4e86\u5b83\u4eec\u7684\u53ef\u91cd\u7528\u6027\uff0c\u589e\u52a0\u4e86bug\u98ce\u9669\uff0c\u5e76\u964d\u4f4e\u4e86\u8bc4\u4f30\u6807\u51c6\u5316\u7a0b\u5ea6\u3002", "method": "\u5f00\u53d1\u4e86stable-worldmodel\uff08SWM\uff09\u751f\u6001\u7cfb\u7edf\uff0c\u63d0\u4f9b\u9ad8\u6548\u7684\u6570\u636e\u6536\u96c6\u5de5\u5177\u3001\u6807\u51c6\u5316\u73af\u5883\u3001\u89c4\u5212\u7b97\u6cd5\u548c\u57fa\u7ebf\u5b9e\u73b0\uff0c\u6bcf\u4e2a\u73af\u5883\u90fd\u652f\u6301\u53ef\u63a7\u7684\u53d8\u5316\u56e0\u7d20\u3002", "result": "SWM\u4e3a\u4e16\u754c\u6a21\u578b\u7814\u7a76\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u5e73\u53f0\uff0c\u652f\u6301\u9c81\u68d2\u6027\u548c\u6301\u7eed\u5b66\u4e60\u7814\u7a76\uff0c\u5e76\u901a\u8fc7\u5728DINO-WM\u4e2d\u7814\u7a76\u96f6\u6837\u672c\u9c81\u68d2\u6027\u5c55\u793a\u4e86\u5176\u5b9e\u7528\u6027\u3002", "conclusion": "SWM\u89e3\u51b3\u4e86\u4e16\u754c\u6a21\u578b\u7814\u7a76\u4e2d\u7f3a\u4e4f\u6807\u51c6\u5316\u548c\u53ef\u91cd\u7528\u6027\u7684\u95ee\u9898\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u4fc3\u8fdb\u4e86\u8be5\u9886\u57df\u7684\u8fdb\u6b65\u3002"}}
{"id": "2602.08990", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08990", "abs": "https://arxiv.org/abs/2602.08990", "authors": ["Shiyang Feng", "Runmin Ma", "Xiangchao Yan", "Yue Fan", "Yusong Hu", "Songtao Huang", "Shuaiyu Zhang", "Zongsheng Cao", "Tianshuo Peng", "Jiakang Yuan", "Zijie Guo", "Zhijie Zhong", "Shangheng Du", "Weida Wang", "Jinxin Shi", "Yuhao Zhou", "Xiaohan He", "Zhiyin Yu", "Fangchen Yu", "Qihao Zheng", "Jiamin Wu", "Mianxin Liu", "Chi Zhang", "Shaowei Hou", "Shuya Li", "Yankai Jiang", "Wenjie Lou", "Lilong Wang", "Zifu Wang", "Jiong Wang", "Wanghan Xu", "Yue Deng", "Dongrui Liu", "Yiheng Wang", "Wenlong Zhang", "Fenghua Ling", "Shufei Zhang", "Xiaosong Wang", "Shuangjia Zheng", "Xun Huang", "Siqi Sun", "Shuyue Hu", "Peng Ye", "Chunfeng Song", "Bin Wang", "Conghui He", "Yihao Liu", "Xin Li", "Qibin Hou", "Tao Chen", "Xiangyu Yue", "Bin Wang", "Liang He", "Dahua Lin", "Bowen Zhou", "Bo Zhang", "Lei Bai"], "title": "InternAgent-1.5: A Unified Agentic Framework for Long-Horizon Autonomous Scientific Discovery", "comment": "Code and project page: https://github.com/InternScience/InternAgent", "summary": "We introduce InternAgent-1.5, a unified system designed for end-to-end scientific discovery across computational and empirical domains. The system is built on a structured architecture composed of three coordinated subsystems for generation, verification, and evolution. These subsystems are supported by foundational capabilities for deep research, solution optimization, and long horizon memory. The architecture allows InternAgent-1.5 to operate continuously across extended discovery cycles while maintaining coherent and improving behavior. It also enables the system to coordinate computational modeling and laboratory experimentation within a single unified system. We evaluate InternAgent-1.5 on scientific reasoning benchmarks such as GAIA, HLE, GPQA, and FrontierScience, and the system achieves leading performance that demonstrates strong foundational capabilities. Beyond these benchmarks, we further assess two categories of discovery tasks. In algorithm discovery tasks, InternAgent-1.5 autonomously designs competitive methods for core machine learning problems. In empirical discovery tasks, it executes complete computational or wet lab experiments and produces scientific findings in earth, life, biological, and physical domains. Overall, these results show that InternAgent-1.5 provides a general and scalable framework for autonomous scientific discovery.", "AI": {"tldr": "InternAgent-1.5\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u79d1\u5b66\u53d1\u73b0\u7cfb\u7edf\uff0c\u901a\u8fc7\u751f\u6210\u3001\u9a8c\u8bc1\u3001\u6f14\u5316\u4e09\u4e2a\u534f\u8c03\u5b50\u7cfb\u7edf\uff0c\u5728\u8ba1\u7b97\u548c\u5b9e\u9a8c\u9886\u57df\u5b9e\u73b0\u81ea\u4e3b\u79d1\u5b66\u53d1\u73b0\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c\u5b9e\u9645\u53d1\u73b0\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u7edf\u4e00\u7684\u7cfb\u7edf\uff0c\u80fd\u591f\u5728\u8ba1\u7b97\u548c\u5b9e\u9a8c\u9886\u57df\u8fdb\u884c\u7aef\u5230\u7aef\u7684\u79d1\u5b66\u53d1\u73b0\uff0c\u534f\u8c03\u8ba1\u7b97\u5efa\u6a21\u548c\u5b9e\u9a8c\u5ba4\u5b9e\u9a8c\uff0c\u5b9e\u73b0\u81ea\u4e3b\u3001\u8fde\u7eed\u7684\u79d1\u5b66\u63a2\u7d22\u3002", "method": "\u91c7\u7528\u7ed3\u6784\u5316\u67b6\u6784\uff0c\u5305\u542b\u4e09\u4e2a\u534f\u8c03\u5b50\u7cfb\u7edf\uff1a\u751f\u6210\u3001\u9a8c\u8bc1\u548c\u6f14\u5316\uff0c\u652f\u6301\u6df1\u5ea6\u7814\u7a76\u3001\u89e3\u51b3\u65b9\u6848\u4f18\u5316\u548c\u957f\u65f6\u7a0b\u8bb0\u5fc6\u7b49\u57fa\u7840\u80fd\u529b\uff0c\u4f7f\u7cfb\u7edf\u80fd\u591f\u5728\u6269\u5c55\u7684\u53d1\u73b0\u5468\u671f\u4e2d\u6301\u7eed\u8fd0\u884c\u3002", "result": "\u5728GAIA\u3001HLE\u3001GPQA\u548cFrontierScience\u7b49\u79d1\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u9886\u5148\u6027\u80fd\uff1b\u5728\u7b97\u6cd5\u53d1\u73b0\u4efb\u52a1\u4e2d\u81ea\u4e3b\u8bbe\u8ba1\u673a\u5668\u5b66\u4e60\u95ee\u9898\u7684\u7ade\u4e89\u6027\u65b9\u6cd5\uff1b\u5728\u5b9e\u9a8c\u53d1\u73b0\u4efb\u52a1\u4e2d\u6267\u884c\u5b8c\u6574\u7684\u8ba1\u7b97\u6216\u6e7f\u5b9e\u9a8c\u5ba4\u5b9e\u9a8c\uff0c\u5728\u5730\u7403\u3001\u751f\u547d\u3001\u751f\u7269\u548c\u7269\u7406\u9886\u57df\u4ea7\u751f\u79d1\u5b66\u53d1\u73b0\u3002", "conclusion": "InternAgent-1.5\u4e3a\u81ea\u4e3b\u79d1\u5b66\u53d1\u73b0\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u4e14\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u5c55\u793a\u4e86\u5728\u8ba1\u7b97\u548c\u5b9e\u9a8c\u9886\u57df\u7684\u5f3a\u5927\u79d1\u5b66\u53d1\u73b0\u80fd\u529b\u3002"}}
{"id": "2602.09000", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09000", "abs": "https://arxiv.org/abs/2602.09000", "authors": ["Ali Hatamizadeh", "Shrimai Prabhumoye", "Igor Gitman", "Ximing Lu", "Seungju Han", "Wei Ping", "Yejin Choi", "Jan Kautz"], "title": "iGRPO: Self-Feedback-Driven LLM Reasoning", "comment": "Tech report", "summary": "Large Language Models (LLMs) have shown promise in solving complex mathematical problems, yet they still fall short of producing accurate and consistent solutions. Reinforcement Learning (RL) is a framework for aligning these models with task-specific rewards, improving overall quality and reliability. Group Relative Policy Optimization (GRPO) is an efficient, value-function-free alternative to Proximal Policy Optimization (PPO) that leverages group-relative reward normalization. We introduce Iterative Group Relative Policy Optimization (iGRPO), a two-stage extension of GRPO that adds dynamic self-conditioning through model-generated drafts. In Stage 1, iGRPO samples multiple exploratory drafts and selects the highest-reward draft using the same scalar reward signal used for optimization. In Stage 2, it appends this best draft to the original prompt and applies a GRPO-style update on draft-conditioned refinements, training the policy to improve beyond its strongest prior attempt. Under matched rollout budgets, iGRPO consistently outperforms GRPO across base models (e.g., Nemotron-H-8B-Base-8K and DeepSeek-R1 Distilled), validating its effectiveness on diverse reasoning benchmarks. Moreover, applying iGRPO to OpenReasoning-Nemotron-7B trained on AceReason-Math achieves new state-of-the-art results of 85.62\\% and 79.64\\% on AIME24 and AIME25, respectively. Ablations further show that the refinement wrapper generalizes beyond GRPO variants, benefits from a generative judge, and alters learning dynamics by delaying entropy collapse. These results underscore the potential of iterative, self-feedback-based RL for advancing verifiable mathematical reasoning.", "AI": {"tldr": "iGRPO\u662f\u4e00\u79cd\u4e24\u9636\u6bb5\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u578b\u751f\u6210\u8349\u7a3f\u548c\u52a8\u6001\u81ea\u6211\u6761\u4ef6\u5316\u6765\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u65b0\u7684SOTA\u7ed3\u679c\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u89e3\u51b3\u590d\u6742\u6570\u5b66\u95ee\u9898\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u4ecd\u96be\u4ee5\u4ea7\u751f\u51c6\u786e\u4e14\u4e00\u81f4\u7684\u89e3\u51b3\u65b9\u6848\u3002\u9700\u8981\u66f4\u6709\u6548\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u6765\u63d0\u5347\u6a21\u578b\u7684\u8d28\u91cf\u548c\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u8fed\u4ee3\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316(iGRPO)\uff0c\u8fd9\u662fGRPO\u7684\u4e24\u9636\u6bb5\u6269\u5c55\uff1a\u7b2c\u4e00\u9636\u6bb5\u91c7\u6837\u591a\u4e2a\u63a2\u7d22\u6027\u8349\u7a3f\u5e76\u9009\u62e9\u6700\u9ad8\u5956\u52b1\u7684\u8349\u7a3f\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5c06\u6700\u4f73\u8349\u7a3f\u9644\u52a0\u5230\u539f\u59cb\u63d0\u793a\u4e0a\uff0c\u5728\u8349\u7a3f\u6761\u4ef6\u5316\u7684\u6539\u8fdb\u4e0a\u5e94\u7528GRPO\u98ce\u683c\u66f4\u65b0\uff0c\u8bad\u7ec3\u7b56\u7565\u8d85\u8d8a\u5176\u5148\u524d\u7684\u6700\u4f73\u5c1d\u8bd5\u3002", "result": "\u5728\u5339\u914d\u7684rollout\u9884\u7b97\u4e0b\uff0ciGRPO\u5728\u591a\u4e2a\u57fa\u7840\u6a21\u578b\u4e0a\u6301\u7eed\u4f18\u4e8eGRPO\u3002\u5e94\u7528\u4e8eOpenReasoning-Nemotron-7B\u6a21\u578b\u65f6\uff0c\u5728AIME24\u548cAIME25\u4e0a\u5206\u522b\u8fbe\u523085.62%\u548c79.64%\u7684\u65b0SOTA\u7ed3\u679c\u3002", "conclusion": "\u8fed\u4ee3\u3001\u57fa\u4e8e\u81ea\u6211\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60\u5728\u63a8\u8fdb\u53ef\u9a8c\u8bc1\u6570\u5b66\u63a8\u7406\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0ciGRPO\u901a\u8fc7\u52a8\u6001\u81ea\u6211\u6761\u4ef6\u5316\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2602.09003", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.09003", "abs": "https://arxiv.org/abs/2602.09003", "authors": ["Yudong Wang", "Zixuan Fu", "Hengyu Zhao", "Chen Zhao", "Chuyue Zhou", "Xinle Lin", "Hongya Lyu", "Shuaikang Xue", "Yi Yi", "Yingjiao Wang", "Zhi Zheng", "Yuzhou Zhang", "Jie Zhou", "Chaojun Xiao", "Xu Han", "Zhiyuan Liu", "Maosong Sun"], "title": "Data Science and Technology Towards AGI Part I: Tiered Data Management", "comment": "16 pages, 3 figures, 7 tables", "summary": "The development of artificial intelligence can be viewed as an evolution of data-driven learning paradigms, with successive shifts in data organization and utilization continuously driving advances in model capability. Current LLM research is dominated by a paradigm that relies heavily on unidirectional scaling of data size, increasingly encountering bottlenecks in data availability, acquisition cost, and training efficiency. In this work, we argue that the development of AGI is entering a new phase of data-model co-evolution, in which models actively guide data management while high-quality data, in turn, amplifies model capabilities. To implement this vision, we propose a tiered data management framework, designed to support the full LLM training lifecycle across heterogeneous learning objectives and cost constraints. Specifically, we introduce an L0-L4 tiered data management framework, ranging from raw uncurated resources to organized and verifiable knowledge. Importantly, LLMs are fully used in data management processes, such as quality scoring and content editing, to refine data across tiers. Each tier is characterized by distinct data properties, management strategies, and training roles, enabling data to be strategically allocated across LLM training stages, including pre-training, mid-training, and alignment. The framework balances data quality, acquisition cost, and marginal training benefit, providing a systematic approach to scalable and sustainable data management. We validate the effectiveness of the proposed framework through empirical studies, in which tiered datasets are constructed from raw corpora and used across multiple training phases. Experimental results demonstrate that tier-aware data utilization significantly improves training efficiency and model performance. To facilitate further research, we release our tiered datasets and processing tools to the community.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2aL0-L4\u5206\u5c42\u6570\u636e\u7ba1\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u6570\u636e\u4e0e\u6a21\u578b\u534f\u540c\u8fdb\u5316\u7684\u65b9\u5f0f\u89e3\u51b3\u5f53\u524dLLM\u8bad\u7ec3\u4e2d\u6570\u636e\u89c4\u6a21\u5355\u5411\u6269\u5c55\u7684\u74f6\u9888\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5f53\u524dLLM\u7814\u7a76\u8fc7\u5ea6\u4f9d\u8d56\u6570\u636e\u89c4\u6a21\u7684\u5355\u5411\u6269\u5c55\uff0c\u9762\u4e34\u6570\u636e\u53ef\u7528\u6027\u3001\u83b7\u53d6\u6210\u672c\u548c\u8bad\u7ec3\u6548\u7387\u7684\u74f6\u9888\u3002\u4f5c\u8005\u8ba4\u4e3aAGI\u53d1\u5c55\u6b63\u8fdb\u5165\u6570\u636e\u4e0e\u6a21\u578b\u534f\u540c\u8fdb\u5316\u7684\u65b0\u9636\u6bb5\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u7684\u6570\u636e\u7ba1\u7406\u65b9\u6cd5\u6765\u5e73\u8861\u6570\u636e\u8d28\u91cf\u3001\u83b7\u53d6\u6210\u672c\u548c\u8bad\u7ec3\u6548\u76ca\u3002", "method": "\u63d0\u51faL0-L4\u5206\u5c42\u6570\u636e\u7ba1\u7406\u6846\u67b6\uff0c\u4ece\u539f\u59cb\u672a\u6574\u7406\u8d44\u6e90\u5230\u7ec4\u7ec7\u5316\u53ef\u9a8c\u8bc1\u77e5\u8bc6\u5206\u4e3a\u4e94\u4e2a\u5c42\u7ea7\u3002\u5229\u7528LLM\u8fdb\u884c\u6570\u636e\u8d28\u91cf\u7ba1\u7406\uff08\u8d28\u91cf\u8bc4\u5206\u3001\u5185\u5bb9\u7f16\u8f91\u7b49\uff09\uff0c\u6839\u636e\u6570\u636e\u7279\u6027\u548c\u7ba1\u7406\u7b56\u7565\u5c06\u6570\u636e\u6218\u7565\u6027\u5730\u5206\u914d\u5230\u9884\u8bad\u7ec3\u3001\u4e2d\u671f\u8bad\u7ec3\u548c\u5bf9\u9f50\u7b49\u4e0d\u540c\u8bad\u7ec3\u9636\u6bb5\u3002", "result": "\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u4f7f\u7528\u5206\u5c42\u6570\u636e\u96c6\u8fdb\u884c\u591a\u9636\u6bb5\u8bad\u7ec3\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5206\u5c42\u611f\u77e5\u7684\u6570\u636e\u5229\u7528\u80fd\u663e\u8457\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\u3002\u4f5c\u8005\u8fd8\u5411\u793e\u533a\u53d1\u5e03\u4e86\u5206\u5c42\u6570\u636e\u96c6\u548c\u5904\u7406\u5de5\u5177\u3002", "conclusion": "\u63d0\u51fa\u7684\u5206\u5c42\u6570\u636e\u7ba1\u7406\u6846\u67b6\u4e3a\u53ef\u6269\u5c55\u548c\u53ef\u6301\u7eed\u7684\u6570\u636e\u7ba1\u7406\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u6570\u636e\u4e0e\u6a21\u578b\u7684\u534f\u540c\u8fdb\u5316\uff0c\u5e73\u8861\u4e86\u6570\u636e\u8d28\u91cf\u3001\u83b7\u53d6\u6210\u672c\u548c\u8fb9\u9645\u8bad\u7ec3\u6548\u76ca\uff0c\u63a8\u52a8\u4e86AGI\u53d1\u5c55\u7684\u65b0\u8303\u5f0f\u3002"}}
{"id": "2602.09007", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.09007", "abs": "https://arxiv.org/abs/2602.09007", "authors": ["Haodong Li", "Jingwei Wu", "Quan Sun", "Guopeng Li", "Juanxi Tian", "Huanyu Zhang", "Yanlin Lai", "Ruichuan An", "Hongbo Peng", "Yuhong Dai", "Chenxi Li", "Chunmei Qing", "Jia Wang", "Ziyang Meng", "Zheng Ge", "Xiangyu Zhang", "Daxin Jiang"], "title": "GEBench: Benchmarking Image Generation Models as GUI Environments", "comment": "23 pages, 5 figures, 4 tables", "summary": "Recent advancements in image generation models have enabled the prediction of future Graphical User Interface (GUI) states based on user instructions. However, existing benchmarks primarily focus on general domain visual fidelity, leaving the evaluation of state transitions and temporal coherence in GUI-specific contexts underexplored. To address this gap, we introduce GEBench, a comprehensive benchmark for evaluating dynamic interaction and temporal coherence in GUI generation. GEBench comprises 700 carefully curated samples spanning five task categories, covering both single-step interactions and multi-step trajectories across real-world and fictional scenarios, as well as grounding point localization. To support systematic evaluation, we propose GE-Score, a novel five-dimensional metric that assesses Goal Achievement, Interaction Logic, Content Consistency, UI Plausibility, and Visual Quality. Extensive evaluations on current models indicate that while they perform well on single-step transitions, they struggle significantly with maintaining temporal coherence and spatial grounding over longer interaction sequences. Our findings identify icon interpretation, text rendering, and localization precision as critical bottlenecks. This work provides a foundation for systematic assessment and suggests promising directions for future research toward building high-fidelity generative GUI environments. The code is available at: https://github.com/stepfun-ai/GEBench.", "AI": {"tldr": "GEBench\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30GUI\u52a8\u6001\u4ea4\u4e92\u548c\u65f6\u5e8f\u4e00\u81f4\u6027\u7684\u65b0\u57fa\u51c6\uff0c\u5305\u542b700\u4e2a\u6837\u672c\u548c\u4e94\u7ef4\u8bc4\u4f30\u6307\u6807\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u5355\u6b65\u8f6c\u6362\u8868\u73b0\u826f\u597d\u4f46\u5728\u957f\u5e8f\u5217\u65f6\u5e8f\u4e00\u81f4\u6027\u548c\u7a7a\u95f4\u5b9a\u4f4d\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002", "motivation": "\u73b0\u6709\u56fe\u50cf\u751f\u6210\u6a21\u578b\u80fd\u591f\u57fa\u4e8e\u7528\u6237\u6307\u4ee4\u9884\u6d4b\u672a\u6765GUI\u72b6\u6001\uff0c\u4f46\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u901a\u7528\u9886\u57df\u7684\u89c6\u89c9\u4fdd\u771f\u5ea6\uff0c\u5bf9GUI\u7279\u5b9a\u573a\u666f\u4e2d\u7684\u72b6\u6001\u8f6c\u6362\u548c\u65f6\u5e8f\u4e00\u81f4\u6027\u7684\u8bc4\u4f30\u4e0d\u8db3\u3002\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u5f15\u5165GEBench\u57fa\u51c6\uff0c\u5305\u542b700\u4e2a\u7cbe\u5fc3\u7b56\u5212\u7684\u6837\u672c\uff0c\u6db5\u76d65\u4e2a\u4efb\u52a1\u7c7b\u522b\uff08\u5355\u6b65\u4ea4\u4e92\u3001\u591a\u6b65\u8f68\u8ff9\u3001\u771f\u5b9e\u4e0e\u865a\u6784\u573a\u666f\u3001\u5b9a\u4f4d\u70b9\u63a5\u5730\uff09\u3002\u63d0\u51faGE-Score\u4e94\u7ef4\u8bc4\u4f30\u6307\u6807\uff1a\u76ee\u6807\u8fbe\u6210\u5ea6\u3001\u4ea4\u4e92\u903b\u8f91\u3001\u5185\u5bb9\u4e00\u81f4\u6027\u3001UI\u5408\u7406\u6027\u548c\u89c6\u89c9\u8d28\u91cf\u3002", "result": "\u5bf9\u73b0\u6709\u6a21\u578b\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0c\u5b83\u4eec\u5728\u5355\u6b65\u8f6c\u6362\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u7ef4\u6301\u957f\u4ea4\u4e92\u5e8f\u5217\u7684\u65f6\u5e8f\u4e00\u81f4\u6027\u548c\u7a7a\u95f4\u5b9a\u4f4d\u65b9\u9762\u5b58\u5728\u663e\u8457\u56f0\u96be\u3002\u56fe\u6807\u89e3\u91ca\u3001\u6587\u672c\u6e32\u67d3\u548c\u5b9a\u4f4d\u7cbe\u5ea6\u662f\u5173\u952e\u74f6\u9888\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u7cfb\u7edf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u5e76\u4e3a\u672a\u6765\u6784\u5efa\u9ad8\u4fdd\u771f\u751f\u6210\u5f0fGUI\u73af\u5883\u7684\u7814\u7a76\u6307\u660e\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2602.07071", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07071", "abs": "https://arxiv.org/abs/2602.07071", "authors": ["S M Rakib UI Karim", "Wenyi Lu", "Sean Goggins"], "title": "Artificial Intelligence in Open Source Software Engineering: A Foundation for Sustainability", "comment": null, "summary": "Open-source software (OSS) is foundational to modern digital infrastructure, yet this context for group work continues to struggle to ensure sufficient contributions in many critical cases. This literature review explores how artificial intelligence (AI) is being leveraged to address critical challenges to OSS sustainability, including maintaining contributor engagement, securing funding, ensuring code quality and security, fostering healthy community dynamics, and preventing project abandonment. Synthesizing recent interdisciplinary research, the paper identifies key applications of AI in this domain, including automated bug triaging, system maintenance, contributor onboarding and mentorship, community health analytics, vulnerability detection, and task automation. The review also examines the limitations and ethical concerns that arise from applying AI in OSS contexts, including data availability, bias and fairness, transparency, risks of misuse, and the preservation of human-centered values in collaborative development. By framing AI not as a replacement but as a tool to augment human infrastructure, this study highlights both the promise and pitfalls of AI-driven interventions. It concludes by identifying critical research gaps and proposing future directions at the intersection of AI, sustainability, and OSS, aiming to support more resilient and equitable open-source ecosystems.", "AI": {"tldr": "\u8fd9\u7bc7\u6587\u732e\u7efc\u8ff0\u63a2\u8ba8\u4e86\u4eba\u5de5\u667a\u80fd\u5982\u4f55\u88ab\u7528\u6765\u89e3\u51b3\u5f00\u6e90\u8f6f\u4ef6\u53ef\u6301\u7eed\u6027\u9762\u4e34\u7684\u6311\u6218\uff0c\u5305\u62ec\u7ef4\u62a4\u8d21\u732e\u8005\u53c2\u4e0e\u5ea6\u3001\u786e\u4fdd\u8d44\u91d1\u3001\u4ee3\u7801\u8d28\u91cf\u4e0e\u5b89\u5168\u3001\u793e\u533a\u5065\u5eb7\u4ee5\u53ca\u9632\u6b62\u9879\u76ee\u5e9f\u5f03\u7b49\u95ee\u9898\u3002", "motivation": "\u5f00\u6e90\u8f6f\u4ef6\u662f\u73b0\u4ee3\u6570\u5b57\u57fa\u7840\u8bbe\u65bd\u7684\u57fa\u7840\uff0c\u4f46\u5728\u8bb8\u591a\u5173\u952e\u60c5\u51b5\u4e0b\u4ecd\u7136\u96be\u4ee5\u786e\u4fdd\u8db3\u591f\u7684\u8d21\u732e\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u5229\u7528\u4eba\u5de5\u667a\u80fd\u89e3\u51b3\u5f00\u6e90\u8f6f\u4ef6\u53ef\u6301\u7eed\u6027\u9762\u4e34\u7684\u6311\u6218\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u7efc\u5408\u8fd1\u671f\u7684\u8de8\u5b66\u79d1\u7814\u7a76\uff0c\u5206\u6790\u4eba\u5de5\u667a\u80fd\u5728\u5f00\u6e90\u8f6f\u4ef6\u9886\u57df\u7684\u5e94\u7528\uff0c\u5305\u62ec\u81ea\u52a8\u5316bug\u5206\u7c7b\u3001\u7cfb\u7edf\u7ef4\u62a4\u3001\u8d21\u732e\u8005\u5f15\u5bfc\u3001\u793e\u533a\u5065\u5eb7\u5206\u6790\u3001\u6f0f\u6d1e\u68c0\u6d4b\u548c\u4efb\u52a1\u81ea\u52a8\u5316\u7b49\u65b9\u9762\u3002", "result": "\u7814\u7a76\u8bc6\u522b\u4e86\u4eba\u5de5\u667a\u80fd\u5728\u5f00\u6e90\u8f6f\u4ef6\u9886\u57df\u7684\u5173\u952e\u5e94\u7528\uff0c\u540c\u65f6\u4e5f\u63ed\u793a\u4e86\u5e94\u7528\u4eba\u5de5\u667a\u80fd\u7684\u5c40\u9650\u6027\u548c\u4f26\u7406\u95ee\u9898\uff0c\u5305\u62ec\u6570\u636e\u53ef\u7528\u6027\u3001\u504f\u89c1\u4e0e\u516c\u5e73\u6027\u3001\u900f\u660e\u5ea6\u3001\u6ee5\u7528\u98ce\u9669\u4ee5\u53ca\u4fdd\u62a4\u534f\u4f5c\u5f00\u53d1\u4e2d\u4ee5\u4eba\u4e3a\u672c\u7684\u4ef7\u503c\u89c2\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4eba\u5de5\u667a\u80fd\u4e0d\u5e94\u88ab\u89c6\u4e3a\u66ff\u4ee3\u54c1\uff0c\u800c\u662f\u589e\u5f3a\u4eba\u7c7b\u57fa\u7840\u8bbe\u65bd\u7684\u5de5\u5177\u3002\u7814\u7a76\u6307\u51fa\u4e86\u5173\u952e\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u5e76\u63d0\u51fa\u4e86\u4eba\u5de5\u667a\u80fd\u3001\u53ef\u6301\u7eed\u6027\u548c\u5f00\u6e90\u8f6f\u4ef6\u4ea4\u53c9\u9886\u57df\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u65e8\u5728\u652f\u6301\u66f4\u5177\u97e7\u6027\u548c\u516c\u5e73\u6027\u7684\u5f00\u6e90\u751f\u6001\u7cfb\u7edf\u3002"}}
