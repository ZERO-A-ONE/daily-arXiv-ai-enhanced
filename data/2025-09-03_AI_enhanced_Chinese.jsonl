{"id": "2509.00140", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00140", "abs": "https://arxiv.org/abs/2509.00140", "authors": ["Songhui Yue"], "title": "LLM-based Triplet Extraction for Automated Ontology Generation in Software Engineering Standards", "comment": null, "summary": "Ontologies have supported knowledge representation and whitebox reasoning for\ndecades; thus, the automated ontology generation (AOG) plays a crucial role in\nscaling their use. Software engineering standards (SES) consist of long,\nunstructured text (with high noise) and paragraphs with domain-specific terms.\nIn this setting, relation triple extraction (RTE), together with term\nextraction, constitutes the first stage toward AOG. This work proposes an\nopen-source large language model (LLM)-assisted approach to RTE for SES.\nInstead of solely relying on prompt-engineering-based methods, this study\npromotes the use of LLMs as an aid in constructing ontologies and explores an\neffective AOG workflow that includes document segmentation, candidate term\nmining, LLM-based relation inference, term normalization, and cross-section\nalignment. Golden-standard benchmarks at three granularities are constructed\nand used to evaluate the ontology generated from the study. The results show\nthat it is comparable and potentially superior to the OpenIE method of triple\nextraction.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5f00\u6e90\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u8f6f\u4ef6\u5de5\u7a0b\u6807\u51c6\u6587\u6863\u4e2d\u81ea\u52a8\u63d0\u53d6\u5173\u7cfb\u4e09\u5143\u7ec4\uff0c\u652f\u6301\u81ea\u52a8\u5316\u672c\u4f53\u751f\u6210\u3002", "motivation": "\u672c\u4f53\u8bba\u5728\u77e5\u8bc6\u8868\u793a\u548c\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u4e2d\u81f4\u5173\u91cd\u8981\uff0c\u800c\u8f6f\u4ef6\u5de5\u7a0b\u6807\u51c6\u6587\u6863\u5177\u6709\u957f\u6587\u672c\u3001\u975e\u7ed3\u6784\u5316\u548c\u9ad8\u566a\u58f0\u7279\u5f81\uff0c\u9700\u8981\u6709\u6548\u65b9\u6cd5\u6765\u81ea\u52a8\u751f\u6210\u672c\u4f53\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b\u6587\u6863\u5206\u5272\u3001\u5019\u9009\u672f\u8bed\u6316\u6398\u3001\u57fa\u4e8eLLM\u7684\u5173\u7cfb\u63a8\u7406\u3001\u672f\u8f9f\u89c4\u8303\u5316\u548c\u8de8\u90e8\u5206\u5bf9\u9f50\u7684\u6709\u6548\u81ea\u52a8\u672c\u4f53\u751f\u6210\u6d41\u7a0b\uff0c\u800c\u4e0d\u4ec5\u4f9d\u8d56\u4e8e\u7b14\u8bb0\u5de5\u7a0b\u65b9\u6cd5\u3002", "result": "\u6784\u5efa\u4e86\u4e09\u4e2a\u7c92\u5ea6\u7ea7\u522b\u7684\u9ec4\u91d1\u6807\u51c6\u6d4b\u8bd5\u96c6\uff0c\u5bf9\u6bd4\u8bc4\u4f30\u751f\u6210\u7684\u672c\u4f53\u3002\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u4e0eOpenIE\u4e09\u5143\u7ec4\u63d0\u53d6\u65b9\u6cd5\u76f8\u6bd4\u5177\u6709\u76f8\u5f53\u6216\u66f4\u4f18\u7684\u6027\u80fd\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684LLM\u8f85\u52a9\u65b9\u6cd5\uff0c\u80fd\u591f\u4ece\u590d\u6742\u7684\u8f6f\u4ef6\u5de5\u7a0b\u6807\u51c6\u6587\u6863\u4e2d\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u672c\u4f53\uff0c\u4e3a\u77e5\u8bc6\u8868\u793a\u548c\u63a8\u7406\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.00256", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.00256", "abs": "https://arxiv.org/abs/2509.00256", "authors": ["Yutong Wang", "Cindy Rubio-Gonz\u00e1lez"], "title": "LLM-Based Program Generation for Triggering Numerical Inconsistencies Across Compilers", "comment": null, "summary": "Floating-point inconsistencies across compilers can undermine the reliability\nof numerical software. We present LLM4FP, the first framework that uses Large\nLanguage Models (LLMs) to generate floating-point programs specifically\ndesigned to trigger such inconsistencies. LLM4FP combines Grammar-Based\nGeneration and Feedback-Based Mutation to produce diverse and valid programs.\nWe evaluate LLM4FP across multiple compilers and optimization levels, measuring\ninconsistency rate, time cost, and program diversity. LLM4FP detects over twice\nas many inconsistencies compared to the state-of-the-art tool, Varity. Notably,\nmost of the inconsistencies involve real-valued differences, rather than\nextreme values like NaN or infinities. LLM4FP also uncovers inconsistencies\nacross a wider range of optimization levels, and finds the most mismatches\nbetween host and device compilers. These results show that LLM-guided program\ngeneration improves the detection of numerical inconsistencies.", "AI": {"tldr": "LLM4FP\u662f\u9996\u4e2a\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6d6e\u70b9\u7a0b\u5e8f\u4ee5\u89e6\u53d1\u7f16\u8bd1\u5668\u4e0d\u4e00\u81f4\u6027\u7684\u6846\u67b6\uff0c\u76f8\u6bd4\u73b0\u6709\u5de5\u5177Varity\u68c0\u6d4b\u5230\u4e24\u500d\u591a\u7684\u4e0d\u4e00\u81f4\u6027\uff0c\u4e3b\u8981\u6d89\u53ca\u5b9e\u6570\u503c\u5dee\u5f02\u800c\u975e\u6781\u7aef\u503c\u3002", "motivation": "\u4e0d\u540c\u7f16\u8bd1\u5668\u95f4\u7684\u6d6e\u70b9\u4e0d\u4e00\u81f4\u6027\u4f1a\u7834\u574f\u6570\u503c\u8f6f\u4ef6\u7684\u53ef\u9760\u6027\uff0c\u9700\u8981\u6709\u6548\u5de5\u5177\u6765\u68c0\u6d4b\u8fd9\u4e9b\u4e0d\u4e00\u81f4\u6027\u3002", "method": "\u7ed3\u5408\u8bed\u6cd5\u751f\u6210\u548c\u57fa\u4e8e\u53cd\u9988\u7684\u53d8\u5f02\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u591a\u6837\u5316\u4e14\u6709\u6548\u7684\u6d6e\u70b9\u7a0b\u5e8f\u3002", "result": "\u5728\u591a\u4e2a\u7f16\u8bd1\u5668\u548c\u4f18\u5316\u7ea7\u522b\u4e0b\uff0cLLM4FP\u68c0\u6d4b\u5230\u7684\u4e0d\u4e00\u81f4\u6027\u662fVarity\u7684\u4e24\u500d\u591a\uff0c\u5927\u591a\u6570\u6d89\u53ca\u5b9e\u6570\u503c\u5dee\u5f02\uff0c\u5e76\u5728\u66f4\u5e7f\u6cdb\u7684\u4f18\u5316\u7ea7\u522b\u548c\u4e3b\u673a-\u8bbe\u5907\u7f16\u8bd1\u5668\u95f4\u53d1\u73b0\u4e0d\u5339\u914d\u3002", "conclusion": "LLM\u5f15\u5bfc\u7684\u7a0b\u5e8f\u751f\u6210\u663e\u8457\u63d0\u9ad8\u4e86\u6570\u503c\u4e0d\u4e00\u81f4\u6027\u7684\u68c0\u6d4b\u80fd\u529b\u3002"}}
{"id": "2509.00466", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.00466", "abs": "https://arxiv.org/abs/2509.00466", "authors": ["Negar Hashemi", "Amjed Tahir", "Shawn Rasheed", "August Shi", "Rachel Blagojevic"], "title": "JS-TOD: Detecting Order-Dependent Flaky Tests in Jest", "comment": null, "summary": "We present JS-TOD (JavaScript Test Order-dependency Detector), a tool that\ncan extract, reorder, and rerun Jest tests to reveal possible order-dependent\ntest flakiness. Test order dependency is one of the leading causes of test\nflakiness. Ideally, each test should operate in isolation and yield consistent\nresults no matter the sequence in which tests are run. However, in practice,\ntest outcomes can vary depending on their execution order. JS-TOD employed a\nsystematic approach to randomising tests, test suites, and describe blocks. The\ntool is highly customisable, as one can set the number of orders and reruns\nrequired (the default setting is 10 reorder and 10 reruns for each test and\ntest suite). Our evaluation using JS-TOD reveals two main causes of test order\ndependency flakiness: shared files and shared mocking state between tests.", "AI": {"tldr": "JS-TOD\u662f\u4e00\u4e2a\u7528\u4e8e\u68c0\u6d4bJest\u6d4b\u8bd5\u4e2d\u987a\u5e8f\u4f9d\u8d56\u5bfc\u81f4\u7684\u6d4b\u8bd5\u4e0d\u7a33\u5b9a\u7684\u5de5\u5177\uff0c\u901a\u8fc7\u968f\u673a\u5316\u6d4b\u8bd5\u987a\u5e8f\u548c\u91cd\u8fd0\u884c\u6765\u53d1\u73b0\u6d4b\u8bd5\u4f9d\u8d56\u95ee\u9898", "motivation": "\u6d4b\u8bd5\u987a\u5e8f\u4f9d\u8d56\u662f\u6d4b\u8bd5\u4e0d\u7a33\u5b9a\u7684\u4e3b\u8981\u539f\u56e0\u4e4b\u4e00\uff0c\u7406\u60f3\u60c5\u51b5\u4e0b\u6bcf\u4e2a\u6d4b\u8bd5\u5e94\u8be5\u72ec\u7acb\u8fd0\u884c\u4e14\u7ed3\u679c\u4e00\u81f4\uff0c\u4f46\u5b9e\u8df5\u4e2d\u6d4b\u8bd5\u7ed3\u679c\u4f1a\u56e0\u6267\u884c\u987a\u5e8f\u800c\u53d8\u5316", "method": "\u91c7\u7528\u7cfb\u7edf\u5316\u65b9\u6cd5\u968f\u673a\u5316\u6d4b\u8bd5\u3001\u6d4b\u8bd5\u5957\u4ef6\u548cdescribe\u5757\u7684\u6267\u884c\u987a\u5e8f\uff0c\u53ef\u81ea\u5b9a\u4e49\u8bbe\u7f6e\u91cd\u6392\u5e8f\u6b21\u6570\u548c\u91cd\u8fd0\u884c\u6b21\u6570\uff08\u9ed8\u8ba4\u6bcf\u4e2a\u6d4b\u8bd5\u548c\u6d4b\u8bd5\u5957\u4ef610\u6b21\u91cd\u6392\u5e8f\u548c10\u6b21\u91cd\u8fd0\u884c\uff09", "result": "\u8bc4\u4f30\u53d1\u73b0\u6d4b\u8bd5\u987a\u5e8f\u4f9d\u8d56\u4e0d\u7a33\u5b9a\u7684\u4e24\u4e2a\u4e3b\u8981\u539f\u56e0\uff1a\u6d4b\u8bd5\u95f4\u5171\u4eab\u6587\u4ef6\u548c\u5171\u4eab\u6a21\u62df\u72b6\u6001", "conclusion": "JS-TOD\u80fd\u6709\u6548\u68c0\u6d4bJavaScript\u6d4b\u8bd5\u4e2d\u7684\u987a\u5e8f\u4f9d\u8d56\u95ee\u9898\uff0c\u5e2e\u52a9\u8bc6\u522b\u548c\u4fee\u590d\u6d4b\u8bd5\u4e0d\u7a33\u5b9a\u6027"}}
{"id": "2509.00785", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.00785", "abs": "https://arxiv.org/abs/2509.00785", "authors": ["Elena Masserini", "Daniela Micucci", "Leonardo Mariani"], "title": "Bug Whispering: Towards Audio Bug Reporting", "comment": "2 pages, 1 figure, IEEE International Symposium on Software\n  Reliability Engineering (ISSRE), 2025, Fast Abstracts Session", "summary": "Bug reporting is a key feature of mobile applications, as it enables\ndevelopers to collect information about faults that escaped testing and thus\naffected end-users. This paper explores the idea of allowing end-users to\nimmediately report the problems that they experience by recording and\nsubmitting audio messages. Audio recording is simple to implement and has the\npotential to increase the number of bug reports that development teams can\ngather, thus potentially improving the rate at which bugs are identified and\nfixed. However, audio bug reports exhibit specific characteristics that\nchallenge existing techniques for reproducing bugs. This paper discusses these\nchallenges based on a preliminary experiment, and motivates further research on\nthe collection and analysis of audio-based bug reports", "AI": {"tldr": "\u63a2\u7d22\u901a\u8fc7\u97f3\u9891\u6d88\u606f\u8bb0\u5f55\u548c\u63d0\u4ea4\u6765\u8ba9\u7ec8\u7aef\u7528\u6237\u7acb\u5373\u62a5\u544a\u79fb\u52a8\u5e94\u7528\u95ee\u9898\u7684\u60f3\u6cd5\uff0c\u5206\u6790\u97f3\u9891\u9519\u8bef\u62a5\u544a\u7684\u7279\u5b9a\u7279\u5f81\u53ca\u5176\u5bf9\u73b0\u6709\u9519\u8bef\u91cd\u73b0\u6280\u672f\u7684\u6311\u6218\u3002", "motivation": "\u79fb\u52a8\u5e94\u7528\u4e2d\u7684\u9519\u8bef\u62a5\u544a\u662f\u91cd\u8981\u529f\u80fd\uff0c\u4f46\u73b0\u6709\u6587\u672c\u62a5\u544a\u65b9\u5f0f\u53ef\u80fd\u4e0d\u591f\u4fbf\u6377\u3002\u97f3\u9891\u8bb0\u5f55\u7b80\u5355\u6613\u5b9e\u73b0\uff0c\u6709\u6f5c\u529b\u589e\u52a0\u5f00\u53d1\u56e2\u961f\u6536\u96c6\u7684\u9519\u8bef\u62a5\u544a\u6570\u91cf\uff0c\u4ece\u800c\u63d0\u5347\u9519\u8bef\u8bc6\u522b\u548c\u4fee\u590d\u7387\u3002", "method": "\u57fa\u4e8e\u521d\u6b65\u5b9e\u9a8c\u63a2\u8ba8\u97f3\u9891\u9519\u8bef\u62a5\u544a\u7684\u6311\u6218\u7279\u5f81\uff0c\u5206\u6790\u5176\u5bf9\u73b0\u6709\u9519\u8bef\u91cd\u73b0\u6280\u672f\u7684\u5f71\u54cd\u3002", "result": "\u97f3\u9891\u9519\u8bef\u62a5\u544a\u5177\u6709\u7279\u5b9a\u7684\u7279\u5f81\uff0c\u8fd9\u4e9b\u7279\u5f81\u5bf9\u73b0\u6709\u7684\u9519\u8bef\u91cd\u73b0\u6280\u672f\u6784\u6210\u4e86\u6311\u6218\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "conclusion": "\u97f3\u9891\u9519\u8bef\u62a5\u544a\u867d\u7136\u7b80\u5355\u6613\u7528\u4e14\u6709\u6f5c\u529b\u589e\u52a0\u62a5\u544a\u6570\u91cf\uff0c\u4f46\u5176\u72ec\u7279\u7279\u5f81\u5bf9\u9519\u8bef\u91cd\u73b0\u63d0\u51fa\u4e86\u65b0\u7684\u6311\u6218\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u97f3\u9891\u9519\u8bef\u62a5\u544a\u7684\u6536\u96c6\u548c\u5206\u6790\u65b9\u6cd5\u3002"}}
{"id": "2509.00058", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00058", "abs": "https://arxiv.org/abs/2509.00058", "authors": ["Eric Zhang", "Li Wei", "Sarah Chen", "Michael Wang"], "title": "A Comparative Study of Controllability, Explainability, and Performance in Dysfluency Detection Models", "comment": null, "summary": "Recent advances in dysfluency detection have introduced a variety of modeling\nparadigms, ranging from lightweight object-detection inspired networks\n(YOLOStutter) to modular interpretable frameworks (UDM). While performance on\nbenchmark datasets continues to improve, clinical adoption requires more than\naccuracy: models must be controllable and explainable. In this paper, we\npresent a systematic comparative analysis of four representative\napproaches--YOLO-Stutter, FluentNet, UDM, and SSDM--along three dimensions:\nperformance, controllability, and explainability. Through comprehensive\nevaluation on multiple datasets and expert clinician assessment, we find that\nYOLO-Stutter and FluentNet provide efficiency and simplicity, but with limited\ntransparency; UDM achieves the best balance of accuracy and clinical\ninterpretability; and SSDM, while promising, could not be fully reproduced in\nour experiments. Our analysis highlights the trade-offs among competing\napproaches and identifies future directions for clinically viable dysfluency\nmodeling. We also provide detailed implementation insights and practical\ndeployment considerations for each approach.", "AI": {"tldr": "\u672c\u6587\u5bf9\u56db\u79cd\u53e3\u5403\u68c0\u6d4b\u65b9\u6cd5(YOLO-Stutter\u3001FluentNet\u3001UDM\u3001SSDM)\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u6bd4\u8f83\u5206\u6790\uff0c\u4ece\u6027\u80fd\u3001\u53ef\u63a7\u6027\u548c\u53ef\u89e3\u91ca\u6027\u4e09\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\uff0c\u53d1\u73b0UDM\u5728\u51c6\u786e\u6027\u548c\u4e34\u5e8a\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u8fbe\u5230\u6700\u4f73\u5e73\u8861\u3002", "motivation": "\u867d\u7136\u53e3\u5403\u68c0\u6d4b\u6a21\u578b\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u4e0d\u65ad\u63d0\u5347\uff0c\u4f46\u4e34\u5e8a\u91c7\u7528\u9700\u8981\u6a21\u578b\u5177\u5907\u53ef\u63a7\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u51c6\u786e\u6027\u3002", "method": "\u901a\u8fc7\u5728\u591a\u6570\u636e\u96c6\u4e0a\u7684\u7efc\u5408\u8bc4\u4f30\u548c\u4e34\u5e8a\u4e13\u5bb6\u8bc4\u4f30\uff0c\u7cfb\u7edf\u6bd4\u8f83\u4e86\u56db\u79cd\u4ee3\u8868\u6027\u65b9\u6cd5\u5728\u6027\u80fd\u3001\u53ef\u63a7\u6027\u548c\u53ef\u89e3\u91ca\u6027\u4e09\u4e2a\u7ef4\u5ea6\u7684\u8868\u73b0\u3002", "result": "YOLO-Stutter\u548cFluentNet\u63d0\u4f9b\u6548\u7387\u548c\u7b80\u5355\u6027\u4f46\u900f\u660e\u5ea6\u6709\u9650\uff1bUDM\u5728\u51c6\u786e\u6027\u548c\u4e34\u5e8a\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u8fbe\u5230\u6700\u4f73\u5e73\u8861\uff1bSSDM\u5728\u5b9e\u9a8c\u4e2d\u65e0\u6cd5\u5b8c\u5168\u590d\u73b0\u3002", "conclusion": "\u5206\u6790\u63ed\u793a\u4e86\u4e0d\u540c\u65b9\u6cd5\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\uff0c\u4e3a\u4e34\u5e8a\u53ef\u884c\u7684\u53e3\u5403\u68c0\u6d4b\u6a21\u578b\u6307\u660e\u4e86\u672a\u6765\u53d1\u5c55\u65b9\u5411\uff0c\u5e76\u63d0\u4f9b\u4e86\u8be6\u7ec6\u7684\u5b9e\u65bd\u89c1\u89e3\u548c\u5b9e\u9645\u90e8\u7f72\u8003\u8651\u3002"}}
{"id": "2509.01006", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.01006", "abs": "https://arxiv.org/abs/2509.01006", "authors": ["Daniela Damian", "Bachan Ghimire", "Ze Shi Li"], "title": "REConnect: Participatory RE that Matters", "comment": "23 pages", "summary": "Software increasingly shapes the infrastructures of daily life, making\nrequirements engineering (RE) central to ensuring that systems align with human\nvalues and lived experiences. Yet, current popular practices such as CrowdRE\nand AI-assisted elicitation strategies risk detaching requirements work from\nthe cultural, social, and political contexts that shape lived experiences,\nhuman values, and real user needs. In this paper, we introduce REConnect that\nre-centers RE on the human connection as central to the understanding of lived\nexperiences where impact is sought. REConnect advocates for a human-centered\nparticipatory approach \"that matters\" to the communities and beneficiaries\ninvolved, ensuring alignment with their values and aspirations. Drawing on\nthree case studies of societal impact: BloodSync in rural Nepal, Herluma\nsupporting women at risk of homelessness in Canada, and BridgingRoots to\nrevitalize Indigenous languages in the Canadian Arctic. REConnect argues that\nthree key principles and enablers: building trusting relationships,\nco-designing with and alongside stakeholders, and empowering users as agents of\nchange, can yield requirements that are culturally grounded, socially\nlegitimate, and sustainable beyond system delivery. REConnect also proposes a\nset of actionable practices (REActions) that embed relationality and ongoing\nstakeholder engagement throughout requirements elicitation, analysis, and\nvalidation of solution development. Finally, we situate REConnect in the era of\nGenerative AI. While AI can accelerate and scale certain RE tasks, its\nintegration must be guided by participatory practices that not only preserve\nhuman agency but also empower humans' roles to become guardians of values and\nethics, inclusion amplifiers, curators of AI outputs, and co-reflectors in\niterative review cycles.", "AI": {"tldr": "REConnect\u63d0\u51fa\u4e86\u4e00\u79cd\u4ee5\u4eba\u4e3a\u672c\u7684\u53c2\u4e0e\u5f0f\u9700\u6c42\u5de5\u7a0b\u65b9\u6cd5\uff0c\u5f3a\u8c03\u5728\u6587\u5316\u548c\u793e\u4f1a\u80cc\u666f\u4e0b\u5efa\u7acb\u4fe1\u4efb\u5173\u7cfb\u3001\u5171\u540c\u8bbe\u8ba1\u548c\u8d4b\u6743\u7528\u6237\uff0c\u4ee5\u786e\u4fdd\u7cfb\u7edf\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u548c\u5b9e\u9645\u9700\u6c42\u4fdd\u6301\u4e00\u81f4\u3002", "motivation": "\u5f53\u524d\u6d41\u884c\u7684\u9700\u6c42\u5de5\u7a0b\u5b9e\u8df5\uff08\u5982CrowdRE\u548cAI\u8f85\u52a9\u65b9\u6cd5\uff09\u5b58\u5728\u8131\u79bb\u6587\u5316\u3001\u793e\u4f1a\u548c\u653f\u6cbb\u80cc\u666f\u7684\u98ce\u9669\uff0c\u53ef\u80fd\u5bfc\u81f4\u7cfb\u7edf\u65e0\u6cd5\u771f\u6b63\u53cd\u6620\u7528\u6237\u7684\u751f\u6d3b\u7ecf\u9a8c\u548c\u4ef7\u503c\u89c2\u3002", "method": "\u63d0\u51fa\u4e86REConnect\u6846\u67b6\uff0c\u57fa\u4e8e\u4e09\u4e2a\u6838\u5fc3\u539f\u5219\uff1a\u5efa\u7acb\u4fe1\u4efb\u5173\u7cfb\u3001\u4e0e\u5229\u76ca\u76f8\u5173\u8005\u5171\u540c\u8bbe\u8ba1\u3001\u8d4b\u6743\u7528\u6237\u4f5c\u4e3a\u53d8\u9769\u63a8\u52a8\u8005\u3002\u901a\u8fc7\u4e09\u4e2a\u793e\u4f1a\u5f71\u54cd\u6848\u4f8b\u7814\u7a76\uff08\u5c3c\u6cca\u5c14\u7684BloodSync\u3001\u52a0\u62ff\u5927\u7684Herluma\u548cBridgingRoots\uff09\u9a8c\u8bc1\u8be5\u65b9\u6cd5\u3002", "result": "REConnect\u80fd\u591f\u4ea7\u751f\u6587\u5316\u57fa\u7840\u624e\u5b9e\u3001\u793e\u4f1a\u5408\u6cd5\u6027\u9ad8\u4e14\u5728\u7cfb\u7edf\u4ea4\u4ed8\u540e\u53ef\u6301\u7eed\u7684\u9700\u6c42\u3002\u540c\u65f6\u63d0\u51fa\u4e86REActions\u5b9e\u8df5\u96c6\uff0c\u5c06\u5173\u7cfb\u6027\u548c\u6301\u7eed\u7684\u5229\u76ca\u76f8\u5173\u8005\u53c2\u4e0e\u5d4c\u5165\u9700\u6c42\u5de5\u7a0b\u7684\u5404\u4e2a\u9636\u6bb5\u3002", "conclusion": "\u5728\u751f\u6210\u5f0fAI\u65f6\u4ee3\uff0cAI\u53ef\u4ee5\u52a0\u901f\u67d0\u4e9b\u9700\u6c42\u5de5\u7a0b\u4efb\u52a1\uff0c\u4f46\u5176\u6574\u5408\u5fc5\u987b\u7531\u53c2\u4e0e\u5f0f\u5b9e\u8df5\u6307\u5bfc\uff0c\u4ee5\u4fdd\u6301\u4eba\u7c7b\u4e3b\u4f53\u6027\u5e76\u589e\u5f3a\u4eba\u7c7b\u4f5c\u4e3a\u4ef7\u503c\u89c2\u5b88\u62a4\u8005\u3001\u5305\u5bb9\u6027\u653e\u5927\u5668\u3001AI\u8f93\u51fa\u7b56\u5c55\u4eba\u548c\u5171\u540c\u53cd\u601d\u8005\u7684\u89d2\u8272\u3002"}}
{"id": "2509.00072", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00072", "abs": "https://arxiv.org/abs/2509.00072", "authors": ["Terry Jingchen Zhang", "Gopal Dev", "Ning Wang", "Nicole Ni", "Wenyuan Jiang", "Yinya Huang", "Bernhard Sch\u00f6lkopf", "Mrinmaya Sachan", "Zhijing Jin"], "title": "Beyond Memorization: Reasoning-Driven Synthesis as a Mitigation Strategy Against Benchmark Contamination", "comment": "Code and Dataset: https://github.com/TerryJCZhang/BeyondMemorization", "summary": "Capability evaluation of large language models (LLMs) is increasingly\nshadowed by rising concerns of data contamination that cast doubts on whether\nstatic benchmarks measure genuine reasoning or mere memorization. We present an\nempirical study using an infinitely scalable framework to synthesize\nresearch-level QA directly from arXiv papers, harnessing the natural temporal\nstructure of research publications where performance decay after knowledge\ncutoffs may indicate potential contamination. We evaluated 4 frontier model\nrepresented by 2 models of different knowledge cutoff dates per family on 1,643\nmulti-step reasoning questions synthesized from 20,277 arXiv papers stratified\nover 26 months, covering at least 6 months before and after all cutoff dates.\nOur results consistently showed a lack of significant performance decay near\nknowledge cutoff dates for models of various sizes, developers, and release\ndates. We further performed a comparative analysis with previous longitudinal\nstudies that reported significant post-cutoff performance decay using directly\nretrieved questions based on public data. we hypothesize that the multi-step\nreasoning required by our synthesis pipeline offered additional complexity that\ngoes deeper than shallow memorization, which effectively serves a mitigation\nstrategy against benchmark contamination. We fully open source our code and\ndataset to aid reproducibility and advocate for a paradigm shift that\nprioritize reasoning-driven synthesis to construct benchmarks over simply\ncollecting newly released questions periodically.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u4ecearXiv\u8bba\u6587\u5408\u6210\u7814\u7a76\u7ea7QA\u95ee\u9898\uff0c\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u77e5\u8bc6\u622a\u6b62\u65e5\u671f\u524d\u540e\u7684\u6027\u80fd\u8868\u73b0\uff0c\u53d1\u73b0\u524d\u6cbf\u6a21\u578b\u5e76\u672a\u51fa\u73b0\u663e\u8457\u7684\u6027\u80fd\u8870\u51cf\uff0c\u8868\u660e\u591a\u6b65\u63a8\u7406\u5408\u6210\u65b9\u6cd5\u80fd\u6709\u6548\u7f13\u89e3\u57fa\u51c6\u6c61\u67d3\u95ee\u9898\u3002", "motivation": "\u7531\u4e8e\u6570\u636e\u6c61\u67d3\u95ee\u9898\u65e5\u76ca\u4e25\u91cd\uff0c\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\u662f\u5426\u771f\u6b63\u8861\u91cf\u4e86\u63a8\u7406\u80fd\u529b\u800c\u975e\u8bb0\u5fc6\u80fd\u529b\u53d7\u5230\u8d28\u7591\uff0c\u9700\u8981\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u9a8c\u8bc1LLMs\u7684\u771f\u5b9e\u63a8\u7406\u80fd\u529b\u3002", "method": "\u5229\u7528arXiv\u8bba\u6587\u7684\u81ea\u7136\u65f6\u95f4\u7ed3\u6784\uff0c\u4ece20,277\u7bc7\u8bba\u6587\u4e2d\u5408\u62101,643\u4e2a\u591a\u6b65\u63a8\u7406\u95ee\u9898\uff0c\u8986\u76d6\u77e5\u8bc6\u622a\u6b62\u65e5\u671f\u524d\u540e\u81f3\u5c116\u4e2a\u6708\u7684\u65f6\u95f4\u8303\u56f4\uff0c\u8bc4\u4f304\u4e2a\u524d\u6cbf\u6a21\u578b\u5bb6\u65cf\u7684\u4ee3\u8868\u6a21\u578b\u3002", "result": "\u7ed3\u679c\u663e\u793a\u4e0d\u540c\u89c4\u6a21\u3001\u5f00\u53d1\u8005\u548c\u53d1\u5e03\u65e5\u671f\u7684\u6a21\u578b\u5728\u77e5\u8bc6\u622a\u6b62\u65e5\u671f\u9644\u8fd1\u5747\u672a\u51fa\u73b0\u663e\u8457\u6027\u80fd\u8870\u51cf\uff0c\u4e0e\u4e4b\u524d\u4f7f\u7528\u516c\u5f00\u6570\u636e\u76f4\u63a5\u68c0\u7d22\u95ee\u9898\u7684\u7eb5\u5411\u7814\u7a76\u7ed3\u679c\u5f62\u6210\u5bf9\u6bd4\u3002", "conclusion": "\u591a\u6b65\u63a8\u7406\u5408\u6210\u65b9\u6cd5\u63d0\u4f9b\u4e86\u8d85\u8d8a\u6d45\u5c42\u8bb0\u5fc6\u7684\u989d\u5916\u590d\u6742\u6027\uff0c\u80fd\u6709\u6548\u7f13\u89e3\u57fa\u51c6\u6c61\u67d3\uff0c\u5efa\u8bae\u4f18\u5148\u91c7\u7528\u63a8\u7406\u9a71\u52a8\u7684\u5408\u6210\u65b9\u6cd5\u6765\u6784\u5efa\u57fa\u51c6\u6d4b\u8bd5\u800c\u975e\u7b80\u5355\u6536\u96c6\u65b0\u53d1\u5e03\u7684\u95ee\u9898\u3002"}}
{"id": "2509.01048", "categories": ["cs.SE", "D.2.1"], "pdf": "https://arxiv.org/pdf/2509.01048", "abs": "https://arxiv.org/abs/2509.01048", "authors": ["Ateeq Sharfuddin", "Travis Breaux"], "title": "Generative Goal Modeling", "comment": "11 pages,", "summary": "In software engineering, requirements may be acquired from stakeholders\nthrough elicitation methods, such as interviews, observational studies, and\nfocus groups. When supporting acquisition from interviews, business analysts\nmust review transcripts to identify and document requirements. Goal modeling is\na popular technique for representing early stakeholder requirements as it lends\nitself to various analyses, including refinement to map high-level goals into\nsoftware operations, and conflict and obstacle analysis. In this paper, we\ndescribe an approach to use textual entailment to reliably extract goals from\ninterview transcripts and to construct goal models. The approach has been\nevaluated on 15 interview transcripts across 29 application domains. The\nfindings show that GPT-4o can reliably extract goals from interview\ntranscripts, matching 62.0% of goals acquired by humans from the same\ntranscripts, and that GPT-4o can trace goals to originating text in the\ntranscript with 98.7% accuracy. In addition, when evaluated by human\nannotators, GPT-4o generates goal model refinement relationships among\nextracted goals with 72.2% accuracy.", "AI": {"tldr": "\u4f7f\u7528GPT-4o\u4ece\u8bbf\u8c08\u8bb0\u5f55\u4e2d\u81ea\u52a8\u63d0\u53d6\u76ee\u6807\u5e76\u6784\u5efa\u76ee\u6807\u6a21\u578b\uff0c\u51c6\u786e\u7387\u8fbe\u523062%\u7684\u76ee\u6807\u63d0\u53d6\u5339\u914d\u7387\u548c98.7%\u7684\u6eaf\u6e90\u51c6\u786e\u6027", "motivation": "\u4f20\u7edf\u9700\u6c42\u83b7\u53d6\u65b9\u6cd5\u4e2d\uff0c\u4e1a\u52a1\u5206\u6790\u5e08\u9700\u8981\u624b\u52a8\u5ba1\u67e5\u8bbf\u8c08\u8bb0\u5f55\u6765\u8bc6\u522b\u548c\u8bb0\u5f55\u9700\u6c42\uff0c\u8fc7\u7a0b\u8017\u65f6\u4e14\u5bb9\u6613\u51fa\u9519\u3002\u76ee\u6807\u5efa\u6a21\u662f\u8868\u793a\u65e9\u671f\u5229\u76ca\u76f8\u5173\u8005\u9700\u6c42\u7684\u6d41\u884c\u6280\u672f\uff0c\u4f46\u624b\u52a8\u6784\u5efa\u76ee\u6807\u6a21\u578b\u6548\u7387\u4f4e\u4e0b", "method": "\u91c7\u7528\u6587\u672c\u8574\u542b\u6280\u672f\uff0c\u5229\u7528GPT-4o\u4ece\u8bbf\u8c08\u8bb0\u5f55\u4e2d\u81ea\u52a8\u63d0\u53d6\u76ee\u6807\uff0c\u6784\u5efa\u76ee\u6807\u6a21\u578b\uff0c\u5e76\u5efa\u7acb\u76ee\u6807\u4e4b\u95f4\u7684\u7cbe\u5316\u5173\u7cfb", "result": "\u572815\u4e2a\u8bbf\u8c08\u8bb0\u5f55\u548c29\u4e2a\u5e94\u7528\u9886\u57df\u7684\u8bc4\u4f30\u4e2d\uff0cGPT-4o\u80fd\u591f\u53ef\u9760\u5730\u63d0\u53d6\u76ee\u6807\uff0862.0%\u5339\u914d\u4eba\u5de5\u63d0\u53d6\uff09\uff0c\u51c6\u786e\u6eaf\u6e90\u76ee\u6807\u6765\u6e90\u6587\u672c\uff0898.7%\uff09\uff0c\u5e76\u751f\u6210\u76ee\u6807\u6a21\u578b\u7cbe\u5316\u5173\u7cfb\uff0872.2%\u51c6\u786e\u7387\uff09", "conclusion": "\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u5316\u9700\u6c42\u83b7\u53d6\u548c\u76ee\u6807\u5efa\u6a21\u7684\u53ef\u884c\u6027\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u9700\u6c42\u83b7\u53d6\u7684\u6548\u7387"}}
{"id": "2509.00074", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.00074", "abs": "https://arxiv.org/abs/2509.00074", "authors": ["C\u00e9dric Colas", "Tracey Mills", "Ben Prystawski", "Michael Henry Tessler", "Noah Goodman", "Jacob Andreas", "Joshua Tenenbaum"], "title": "Language and Experience: A Computational Model of Social Learning in Complex Tasks", "comment": null, "summary": "The ability to combine linguistic guidance from others with direct experience\nis central to human development, enabling safe and rapid learning in new\nenvironments. How do people integrate these two sources of knowledge, and how\nmight AI systems? We present a computational framework that models social\nlearning as joint probabilistic inference over structured, executable world\nmodels given sensorimotor and linguistic data. We make this possible by turning\na pretrained language model into a probabilistic model of how humans share\nadvice conditioned on their beliefs, allowing our agents both to generate\nadvice for others and to interpret linguistic input as evidence during Bayesian\ninference. Using behavioral experiments and simulations across 10 video games,\nwe show how linguistic guidance can shape exploration and accelerate learning\nby reducing risky interactions and speeding up key discoveries in both humans\nand models. We further explore how knowledge can accumulate across generations\nthrough iterated learning experiments and demonstrate successful knowledge\ntransfer between humans and models -- revealing how structured,\nlanguage-compatible representations might enable human-machine collaborative\nlearning.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u8ba1\u7b97\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u8f6c\u5316\u4e3a\u6982\u7387\u6a21\u578b\uff0c\u5b9e\u73b0\u793e\u4f1a\u5b66\u4e60\u4e2d\u7684\u8bed\u8a00\u6307\u5bfc\u4e0e\u76f4\u63a5\u7ecf\u9a8c\u7684\u6574\u5408\uff0c\u52a0\u901f\u5b66\u4e60\u548c\u77e5\u8bc6\u4f20\u9012\u3002", "motivation": "\u4eba\u7c7b\u80fd\u591f\u7ed3\u5408\u4ed6\u4eba\u8bed\u8a00\u6307\u5bfc\u548c\u76f4\u63a5\u7ecf\u9a8c\u8fdb\u884c\u5b89\u5168\u5feb\u901f\u5b66\u4e60\uff0c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u8fd9\u79cd\u6574\u5408\u673a\u5236\u5e76\u5e94\u7528\u4e8eAI\u7cfb\u7edf\uff0c\u5b9e\u73b0\u4eba\u673a\u534f\u4f5c\u5b66\u4e60\u3002", "method": "\u4f7f\u7528\u8054\u5408\u6982\u7387\u63a8\u7406\u6846\u67b6\uff0c\u5c06\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u8f6c\u5316\u4e3a\u57fa\u4e8e\u4fe1\u5ff5\u7684\u6761\u4ef6\u6982\u7387\u6a21\u578b\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u63a8\u7406\u5904\u7406\u611f\u89c9\u8fd0\u52a8\u548c\u8bed\u8a00\u6570\u636e\uff0c\u572810\u4e2a\u89c6\u9891\u6e38\u620f\u4e2d\u8fdb\u884c\u884c\u4e3a\u5b9e\u9a8c\u548c\u6a21\u62df\u3002", "result": "\u8bed\u8a00\u6307\u5bfc\u80fd\u591f\u5851\u9020\u63a2\u7d22\u884c\u4e3a\u3001\u52a0\u901f\u5b66\u4e60\u8fc7\u7a0b\uff0c\u51cf\u5c11\u98ce\u9669\u4ea4\u4e92\u5e76\u4fc3\u8fdb\u5173\u952e\u53d1\u73b0\uff0c\u5b9e\u73b0\u4e86\u8de8\u4ee3\u77e5\u8bc6\u79ef\u7d2f\u548c\u6210\u529f\u7684\u4eba\u673a\u77e5\u8bc6\u4f20\u9012\u3002", "conclusion": "\u7ed3\u6784\u5316\u3001\u8bed\u8a00\u517c\u5bb9\u7684\u8868\u5f81\u80fd\u591f\u5b9e\u73b0\u4eba\u673a\u534f\u4f5c\u5b66\u4e60\uff0c\u4e3a\u6784\u5efa\u80fd\u591f\u6574\u5408\u8bed\u8a00\u6307\u5bfc\u548c\u76f4\u63a5\u7ecf\u9a8c\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u8ba1\u7b97\u6846\u67b6\u548c\u5b9e\u8bc1\u652f\u6301\u3002"}}
{"id": "2509.01068", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.01068", "abs": "https://arxiv.org/abs/2509.01068", "authors": ["Chong Wang", "Haoning Wu", "Peng Liang", "Maya Daneva", "Marten van Sinderen"], "title": "A Survey on the Techniques and Tools for Automated Requirements Elicitation and Analysis of Mobile Apps", "comment": null, "summary": "[Background:] Research on automated requirements elicitation and analysis of\nmobile apps employed lots of techniques and tools proposed by RE researchers\nand practitioners. However, little is known about the characteristics of these\ntechniques and tools as well as the RE tasks in requirements elicitation and\nanalysis that got supported with the help of respective techniques and tools.\n[Aims:] The goal of this paper is to investigate the state-of-the-art of the\ntechniques and tools used in automated requirements elicitation and analysis of\nmobile apps. [Method:] We carried out a systematic mapping study by following\nthe guidelines of Kitchenham et al. [Results:] Based on 73 selected papers, we\nfound the most frequently used techniques - semi-automatic techniques, and the\nmain characteristics of the tools - open-sourced and non-self-developed tools\nfor requirements analysis and text pre-processing. Plus, the most three\ninvestigated RE tasks are requirements analysis, mining and classification.\n[Conclusions:] Our most important conclusions are: (1) there is a growth in the\nuse of techniques and tools in automated requirements elicitation and analysis\nof mobile apps, (2) semi-automatic techniques are mainly used in the\npublications on this research topic, (3) requirements analysis, mining and\nclassification are the top three RE tasks with the support of automatic\ntechniques and tools, and (4) the most popular tools are open-sourced and\nnon-self-developed, and they are mainly used in requirements analysis and text\nprocessing.", "AI": {"tldr": "\u5bf973\u7bc7\u8bba\u6587\u7684\u7cfb\u7edf\u6027\u6620\u5c04\u7814\u7a76\u663e\u793a\uff0c\u79fb\u52a8\u5e94\u7528\u81ea\u52a8\u5316\u9700\u6c42\u83b7\u53d6\u4e0e\u5206\u6790\u4e3b\u8981\u4f7f\u7528\u534a\u81ea\u52a8\u6280\u672f\uff0c\u6700\u5e38\u7528\u5de5\u5177\u662f\u5f00\u6e90\u975e\u81ea\u7814\u5de5\u5177\uff0c\u4e3b\u8981\u652f\u6301\u9700\u6c42\u5206\u6790\u3001\u6316\u6398\u548c\u5206\u7c7b\u4e09\u5927\u4efb\u52a1", "motivation": "\u4e86\u89e3\u79fb\u52a8\u5e94\u7528\u81ea\u52a8\u5316\u9700\u6c42\u83b7\u53d6\u4e0e\u5206\u6790\u9886\u57df\u7684\u6280\u672f\u5de5\u5177\u7279\u5f81\u53ca\u5176\u652f\u6301\u7684\u9700\u6c42\u5de5\u7a0b\u4efb\u52a1\u73b0\u72b6", "method": "\u91c7\u7528Kitchenham\u7b49\u4eba\u7684\u6307\u5357\u8fdb\u884c\u7cfb\u7edf\u6027\u6620\u5c04\u7814\u7a76\uff0c\u5206\u6790\u4e8673\u7bc7\u76f8\u5173\u8bba\u6587", "result": "\u53d1\u73b0\u6700\u5e38\u7528\u6280\u672f\u662f\u534a\u81ea\u52a8\u6280\u672f\uff0c\u4e3b\u8981\u5de5\u5177\u7279\u5f81\u4e3a\u5f00\u6e90\u548c\u975e\u81ea\u7814\uff0c\u4e3b\u8981\u7528\u4e8e\u9700\u6c42\u5206\u6790\u548c\u6587\u672c\u9884\u5904\u7406\uff0c\u4e09\u5927\u4e3b\u8981\u7814\u7a76\u4efb\u52a1\u662f\u9700\u6c42\u5206\u6790\u3001\u6316\u6398\u548c\u5206\u7c7b", "conclusion": "\u8be5\u9886\u57df\u6280\u672f\u5de5\u5177\u4f7f\u7528\u5448\u589e\u957f\u8d8b\u52bf\uff0c\u534a\u81ea\u52a8\u6280\u672f\u5360\u4e3b\u5bfc\uff0c\u9700\u6c42\u5206\u6790/\u6316\u6398/\u5206\u7c7b\u662f\u4e3b\u8981\u652f\u6301\u4efb\u52a1\uff0c\u5f00\u6e90\u975e\u81ea\u7814\u5de5\u5177\u5728\u9700\u6c42\u5206\u6790\u548c\u6587\u672c\u5904\u7406\u4e2d\u6700\u53d7\u6b22\u8fce"}}
{"id": "2509.00079", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.00079", "abs": "https://arxiv.org/abs/2509.00079", "authors": ["Andrew G. A. Correa", "Ana C. H de Matos"], "title": "Entropy-Guided Loop: Achieving Reasoning through Uncertainty-Aware Generation", "comment": "9 pages, 2 figures, 4 tables", "summary": "Reasoning models often outperform smaller models but at 3--5$\\times$ higher\ncost and added latency. We present entropy-guided refinement: a lightweight,\ntest-time loop that uses token-level uncertainty to trigger a single, targeted\nrefinement pass. We extract logprobs, compute Shannon entropy on top-$k$\nalternatives, and apply a simple OR-logic trigger over perplexity, maximum\ntoken entropy, and low-confidence-token count. Unlike approaches that use\nentropy only for measurement or decoding, we pass a compact uncertainty report\n(tokens, confidences, alternatives, context) back to the model to guide\ncorrective edits. On representative technical queries across reasoning,\nmathematics, and code generation tasks, a small model with our loop approaches\n95\\% of a reference reasoning model's quality at approximately one-third of the\ncost. The method achieves selective refinement on ~31\\% of responses while\nimproving accuracy by 16 percentage points over single-pass inference. We\ndemonstrate that this uncertainty-aware loop provides an effective middle\nground between single-pass inference and expensive reasoning chains, making it\npractical for production deployments where both quality and cost matter.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u71b5\u5f15\u5bfc\u7684\u8f7b\u91cf\u7ea7\u63a8\u7406\u5faa\u73af\u65b9\u6cd5\uff0c\u4f7f\u7528token\u7ea7\u4e0d\u786e\u5b9a\u6027\u89e6\u53d1\u5355\u6b21\u5b9a\u5411\u7cbe\u70bc\uff0c\u5728\u4fdd\u6301\u4f4e\u6210\u672c\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u5c0f\u6a21\u578b\u6027\u80fd", "motivation": "\u89e3\u51b3\u5927\u578b\u63a8\u7406\u6a21\u578b\u6210\u672c\u9ad8\u3001\u5ef6\u8fdf\u5927\u7684\u95ee\u9898\uff0c\u5bfb\u6c42\u5728\u5355\u6b21\u63a8\u7406\u548c\u6602\u8d35\u63a8\u7406\u94fe\u4e4b\u95f4\u7684\u6709\u6548\u6298\u4e2d\u65b9\u6848", "method": "\u63d0\u53d6logprobs\u8ba1\u7b97\u9999\u519c\u71b5\uff0c\u4f7f\u7528\u56f0\u60d1\u5ea6\u3001\u6700\u5927token\u71b5\u548c\u4f4e\u7f6e\u4fe1\u5ea6token\u8ba1\u6570\u7684OR\u903b\u8f91\u89e6\u53d1\u673a\u5236\uff0c\u5c06\u7d27\u51d1\u7684\u4e0d\u786e\u5b9a\u6027\u62a5\u544a\u53cd\u9988\u7ed9\u6a21\u578b\u6307\u5bfc\u4fee\u6b63", "result": "\u5c0f\u6a21\u578b\u914d\u5408\u8be5\u65b9\u6cd5\u53ef\u8fbe\u5230\u53c2\u8003\u63a8\u7406\u6a21\u578b95%\u7684\u8d28\u91cf\uff0c\u6210\u672c\u964d\u4f4e\u7ea6\u4e09\u5206\u4e4b\u4e8c\uff0c\u572831%\u7684\u54cd\u5e94\u4e0a\u5b9e\u73b0\u9009\u62e9\u6027\u7cbe\u70bc\uff0c\u51c6\u786e\u7387\u63d0\u534716\u4e2a\u767e\u5206\u70b9", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u751f\u4ea7\u90e8\u7f72\u63d0\u4f9b\u4e86\u8d28\u91cf\u548c\u6210\u672c\u517c\u987e\u7684\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u662f\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u63a8\u7406\u7684\u6709\u6548\u4e2d\u95f4\u65b9\u6848"}}
{"id": "2509.01149", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.01149", "abs": "https://arxiv.org/abs/2509.01149", "authors": ["Hui Zeng", "Zhihao Xu", "Hui Li", "Siwen Wang", "Qian Ma"], "title": "Compiler Bugs Detection in Logic Synthesis Tools via Linear Upper Confidence Bound", "comment": null, "summary": "Field-Programmable Gate Arrays (FPGAs) play an indispensable role in\nElectronic Design Automation (EDA), translating Register-Transfer Level (RTL)\ndesigns into gate-level netlists. The correctness and reliability of FPGA logic\nsynthesis tools are critically important, as unnoticed bugs in these tools may\ninfect the final hardware implementations. However, recent approaches often\nrely heavily on random selection strategies, limiting the structural diversity\nof the generated HDL test cases and resulting in inadequate exploration of the\ntool's feature space. To address this limitation, we propose Lin-Hunter, a\nnovel testing framework designed to systematically enhance the diversity of HDL\ntest cases and the efficiency of FPGA logic synthesis tool validation.\nSpecifically, Lin-Hunter introduces a principled set of metamorphic\ntransformation rules to generate functionally equivalent yet structurally\ndiverse HDL test case variants, effectively addressing the limited diversity of\nexisting test inputs. To further enhance bug discovery efficiency, Lin-Hunter\nintegrates an adaptive strategy selection mechanism based on the Linear Upper\nConfidence Bound (LinUCB) method. This method leverages feedback from synthesis\nlogs of previously executed test cases to dynamically prioritize transformation\nstrategies that have empirically demonstrated a higher likelihood of triggering\nsynthesis bugs. Comprehensive experiments conducted over a three-month period\ndemonstrate the practical effectiveness of Lin-Hunter. Our method has\ndiscovered 18 unique bugs, including 10 previously unreported defects, which\nhave been confirmed by official developers. Moreover, our method outperforms\nstate-of-the-art testing methods in both test-case diversity and bug-discovery\nefficiency.", "AI": {"tldr": "Lin-Hunter\u662f\u4e00\u4e2a\u9488\u5bf9FPGA\u903b\u8f91\u7efc\u5408\u5de5\u5177\u7684\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u5143\u5f62\u6001\u53d8\u6362\u89c4\u5219\u751f\u6210\u7ed3\u6784\u591a\u6837\u5316\u7684HDL\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5e76\u91c7\u7528\u57fa\u4e8eLinUCB\u7684\u81ea\u9002\u5e94\u7b56\u7565\u9009\u62e9\u673a\u5236\u6765\u63d0\u9ad8bug\u53d1\u73b0\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684FPGA\u903b\u8f91\u7efc\u5408\u5de5\u5177\u6d4b\u8bd5\u65b9\u6cd5\u8fc7\u5ea6\u4f9d\u8d56\u968f\u673a\u9009\u62e9\u7b56\u7565\uff0c\u5bfc\u81f4\u751f\u6210\u7684HDL\u6d4b\u8bd5\u7528\u4f8b\u7ed3\u6784\u591a\u6837\u6027\u4e0d\u8db3\uff0c\u65e0\u6cd5\u5145\u5206\u63a2\u7d22\u5de5\u5177\u7684\u529f\u80fd\u7a7a\u95f4\uff0c\u5b58\u5728\u672a\u68c0\u6d4b\u5230\u7684bug\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u539f\u5219\u7684\u5143\u5f62\u6001\u53d8\u6362\u89c4\u5219\u751f\u6210\u529f\u80fd\u7b49\u6548\u4f46\u7ed3\u6784\u591a\u6837\u7684HDL\u6d4b\u8bd5\u7528\u4f8b\u53d8\u4f53\uff1b\u96c6\u6210\u57fa\u4e8e\u7ebf\u6027\u4e0a\u7f6e\u4fe1\u754c(LinUCB)\u7684\u81ea\u9002\u5e94\u7b56\u7565\u9009\u62e9\u673a\u5236\uff0c\u5229\u7528\u5148\u524d\u6d4b\u8bd5\u7528\u4f8b\u7684\u7efc\u5408\u65e5\u5fd7\u53cd\u9988\u6765\u52a8\u6001\u4f18\u5148\u9009\u62e9\u66f4\u53ef\u80fd\u89e6\u53d1\u7efc\u5408bug\u7684\u53d8\u6362\u7b56\u7565\u3002", "result": "\u5728\u4e09\u4e2a\u6708\u7684\u7efc\u5408\u5b9e\u9a8c\u4e2d\u53d1\u73b0\u4e8618\u4e2a\u72ec\u7279bug\uff0c\u5176\u4e2d10\u4e2a\u662f\u5148\u524d\u672a\u62a5\u544a\u7684\u7f3a\u9677\uff0c\u5df2\u5f97\u5230\u5b98\u65b9\u5f00\u53d1\u8005\u786e\u8ba4\uff1b\u5728\u6d4b\u8bd5\u7528\u4f8b\u591a\u6837\u6027\u548cbug\u53d1\u73b0\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u6d4b\u8bd5\u65b9\u6cd5\u3002", "conclusion": "Lin-Hunter\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u589e\u5f3aHDL\u6d4b\u8bd5\u7528\u4f8b\u7684\u591a\u6837\u6027\u548c\u91c7\u7528\u81ea\u9002\u5e94\u7b56\u7565\u9009\u62e9\uff0c\u6709\u6548\u89e3\u51b3\u4e86FPGA\u903b\u8f91\u7efc\u5408\u5de5\u5177\u9a8c\u8bc1\u4e2d\u7684\u6d4b\u8bd5\u8f93\u5165\u591a\u6837\u6027\u4e0d\u8db3\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86bug\u53d1\u73b0\u6548\u7387\u548c\u5de5\u5177\u53ef\u9760\u6027\u3002"}}
{"id": "2509.00080", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00080", "abs": "https://arxiv.org/abs/2509.00080", "authors": ["David Freire-Obreg\u00f3n"], "title": "Wrong Face, Wrong Move: The Social Dynamics of Emotion Misperception in Agent-Based Models", "comment": "Accepted for presentation at the International Workshop on\n  Agent-Based Modelling of Human Behaviour (ABMHuB 2025)", "summary": "The ability of humans to detect and respond to others' emotions is\nfundamental to understanding social behavior. Here, agents are instantiated\nwith emotion classifiers of varying accuracy to study the impact of perceptual\naccuracy on emergent emotional and spatial behavior. Agents are visually\nrepresented with face photos from the KDEF database and endowed with one of\nthree classifiers trained on the JAFFE (poor), CK+ (medium), or KDEF (high)\ndatasets. Agents communicate locally on a 2D toroidal lattice, perceiving\nneighbors' emotional state based on their classifier and responding with\nmovement toward perceived positive emotions and away from perceived negative\nemotions. Note that the agents respond to perceived, instead of ground-truth,\nemotions, introducing systematic misperception and frustration. A battery of\nexperiments is carried out on homogeneous and heterogeneous populations and\nscenarios with repeated emotional shocks. Results show that low-accuracy\nclassifiers on the part of the agent reliably result in diminished trust,\nemotional disintegration into sadness, and disordered social organization. By\ncontrast, the agent that develops high accuracy develops hardy emotional\nclusters and resilience to emotional disruptions. Even in emotionally neutral\nscenarios, misperception is enough to generate segregation and disintegration\nof cohesion. These findings underscore the fact that biases or imprecision in\nemotion recognition may significantly warp social processes and disrupt\nemotional integration.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u6a21\u62df\u4ee3\u7406\u4f7f\u7528\u4e0d\u540c\u51c6\u786e\u5ea6\u7684\u60c5\u7eea\u5206\u7c7b\u5668\uff0c\u53d1\u73b0\u4f4e\u51c6\u786e\u5ea6\u4f1a\u5bfc\u81f4\u4fe1\u4efb\u964d\u4f4e\u3001\u60c5\u7eea\u5d29\u6e83\u548c\u793e\u4f1a\u7ec4\u7ec7\u6df7\u4e71\uff0c\u800c\u9ad8\u51c6\u786e\u5ea6\u5219\u80fd\u5f62\u6210\u7a33\u5b9a\u7684\u60c5\u7eea\u96c6\u7fa4\u548c\u6297\u5e72\u6270\u80fd\u529b\u3002", "motivation": "\u63a2\u7d22\u60c5\u7eea\u611f\u77e5\u51c6\u786e\u6027\u5bf9\u793e\u4ea4\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u7814\u7a76\u4eba\u7c7b\u60c5\u7eea\u8bc6\u522b\u80fd\u529b\u5728\u793e\u4f1a\u4e92\u52a8\u4e2d\u7684\u91cd\u8981\u6027\u3002", "method": "\u57282D\u73af\u9762\u7f51\u683c\u4e0a\u90e8\u7f72\u4ee3\u7406\uff0c\u4f7f\u7528\u57fa\u4e8eJAFFE\u3001CK+\u3001KDEF\u6570\u636e\u96c6\u8bad\u7ec3\u7684\u4e0d\u540c\u51c6\u786e\u5ea6\u60c5\u7eea\u5206\u7c7b\u5668\uff0c\u4ee3\u7406\u6839\u636e\u611f\u77e5\u5230\u7684\u90bb\u5c45\u60c5\u7eea\u8fdb\u884c\u79fb\u52a8\uff08\u8d8b\u8fd1\u79ef\u6781\u60c5\u7eea\uff0c\u8fdc\u79bb\u6d88\u6781\u60c5\u7eea\uff09\u3002", "result": "\u4f4e\u51c6\u786e\u5ea6\u5206\u7c7b\u5668\u5bfc\u81f4\u4fe1\u4efb\u964d\u4f4e\u3001\u60c5\u7eea\u5d29\u6e83\u4e3a\u60b2\u4f24\u3001\u793e\u4f1a\u7ec4\u7ec7\u6df7\u4e71\uff1b\u9ad8\u51c6\u786e\u5ea6\u5206\u7c7b\u5668\u5f62\u6210\u7a33\u5b9a\u7684\u60c5\u7eea\u96c6\u7fa4\u548c\u60c5\u7eea\u5e72\u6270\u6297\u6027\uff1b\u5373\u4f7f\u5728\u60c5\u7eea\u4e2d\u6027\u573a\u666f\u4e2d\uff0c\u8bef\u611f\u77e5\u4e5f\u4f1a\u5bfc\u81f4\u9694\u79bb\u548c\u51dd\u805a\u529b\u74e6\u89e3\u3002", "conclusion": "\u60c5\u7eea\u8bc6\u522b\u4e2d\u7684\u504f\u89c1\u6216\u4e0d\u7cbe\u786e\u53ef\u80fd\u663e\u8457\u626d\u66f2\u793e\u4f1a\u8fc7\u7a0b\u5e76\u7834\u574f\u60c5\u7eea\u6574\u5408\uff0c\u5f3a\u8c03\u4e86\u51c6\u786e\u60c5\u7eea\u611f\u77e5\u5bf9\u793e\u4f1a\u884c\u4e3a\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2509.00005", "categories": ["cs.CR", "cs.AI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2509.00005", "abs": "https://arxiv.org/abs/2509.00005", "authors": ["Rohit Dube"], "title": "Per-sender neural network classifiers for email authorship validation", "comment": "11 pages, 5 figures, 8 tables", "summary": "Business email compromise and lateral spear phishing attacks are among modern\norganizations' most costly and damaging threats. While inbound phishing\ndefenses have improved significantly, most organizations still trust internal\nemails by default, leaving themselves vulnerable to attacks from compromised\nemployee accounts. In this work, we define and explore the problem of\nauthorship validation: verifying whether a claimed sender actually authored a\ngiven email. Authorship validation is a lightweight, real-time defense that\ncomplements traditional detection methods by modeling per-sender writing style.\nFurther, the paper presents a collection of new datasets based on the Enron\ncorpus. These simulate inauthentic messages using both human-written and large\nlanguage model-generated emails. The paper also evaluates two classifiers -- a\nNaive Bayes model and a character-level convolutional neural network (Char-CNN)\n-- for the authorship validation task. Our experiments show that the Char-CNN\nmodel achieves high accuracy and F1 scores under various circumstances.\nFinally, we discuss deployment considerations and show that per-sender\nauthorship classifiers are practical for integrating into existing commercial\nemail security systems with low overhead.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4f5c\u8005\u8eab\u4efd\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u53d1\u4ef6\u4eba\u5199\u4f5c\u98ce\u683c\u6765\u68c0\u6d4b\u4f2a\u9020\u7684\u5185\u90e8\u90ae\u4ef6\uff0c\u4f7f\u7528Char-CNN\u6a21\u578b\u5728\u6a21\u62df\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u9ad8\u51c6\u786e\u7387\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u53ef\u5b9e\u7528\u90e8\u7f72\u5230\u73b0\u6709\u90ae\u4ef6\u5b89\u5168\u7cfb\u7edf\u4e2d\u3002", "motivation": "\u4f01\u4e1a\u9762\u4e34\u5185\u90e8\u90ae\u4ef6\u653b\u51fb\u5a01\u80c1\uff0c\u4f20\u7edf\u9632\u5fa1\u4e3b\u8981\u9488\u5bf9\u5916\u90e8\u9493\u9c7c\u90ae\u4ef6\uff0c\u4f46\u5bf9\u5185\u90e8\u5df2\u6cc4\u9732\u8d26\u6237\u53d1\u9001\u7684\u4f2a\u9020\u90ae\u4ef6\u7f3a\u4e4f\u6709\u6548\u68c0\u6d4b\u624b\u6bb5\u3002", "method": "\u63d0\u51fa\u4f5c\u8005\u8eab\u4efd\u9a8c\u8bc1\u6982\u5ff5\uff0c\u4f7f\u7528\u6734\u7d20\u8d1d\u53f6\u65af\u548c\u5b57\u7b26\u7ea7\u5377\u79ef\u795e\u7ecf\u7f51\u7edc(Char-CNN)\u4e24\u79cd\u5206\u7c7b\u5668\uff0c\u57fa\u4e8eEnron\u8bed\u6599\u5e93\u6784\u5efa\u5305\u542b\u4eba\u5de5\u7f16\u5199\u548cLLM\u751f\u6210\u4f2a\u9020\u90ae\u4ef6\u7684\u6a21\u62df\u6570\u636e\u96c6\u3002", "result": "Char-CNN\u6a21\u578b\u5728\u5404\u79cd\u60c5\u51b5\u4e0b\u90fd\u53d6\u5f97\u4e86\u9ad8\u51c6\u786e\u7387\u548cF1\u5206\u6570\uff0c\u8868\u73b0\u4f18\u4e8e\u6734\u7d20\u8d1d\u53f6\u65af\u6a21\u578b\u3002", "conclusion": "\u57fa\u4e8e\u53d1\u4ef6\u4eba\u5199\u4f5c\u98ce\u683c\u7684\u8eab\u4efd\u9a8c\u8bc1\u662f\u8f7b\u91cf\u7ea7\u5b9e\u65f6\u9632\u5fa1\u65b9\u6848\uff0c\u53ef\u6709\u6548\u8865\u5145\u4f20\u7edf\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4e14\u6613\u4e8e\u96c6\u6210\u5230\u73b0\u6709\u5546\u4e1a\u90ae\u4ef6\u5b89\u5168\u7cfb\u7edf\u4e2d\u3002"}}
{"id": "2509.01255", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.01255", "abs": "https://arxiv.org/abs/2509.01255", "authors": ["Oleksii Novikov", "Davide Fucci", "Oleksandr Adamov", "Daniel Mendez"], "title": "Policy-driven Software Bill of Materials on GitHub: An Empirical Study", "comment": "To be published in the proceedings of PROFES2025", "summary": "Background. The Software Bill of Materials (SBOM) is a machine-readable list\nof all the software dependencies included in a software. SBOM emerged as way to\nassist securing the software supply chain. However, despite mandates from\ngovernments to use SBOM, research on this artifact is still in its early\nstages. Aims. We want to understand the current state of SBOM in open-source\nprojects, focusing specifically on policy-driven SBOMs, i.e., SBOM created to\nachieve security goals, such as enhancing project transparency and ensuring\ncompliance, rather than being used as fixtures for tools or artificially\ngenerated for benchmarking or academic research purposes. Method. We performed\na mining software repository study to collect and carefully select SBOM files\nhosted on GitHub. We analyzed the information reported in policy-driven SBOMs\nand the vulnerabilities associated with the declared dependencies by means of\ndescriptive statistics. Results. We show that only 0.56% of popular GitHub\nrepositories contain policy-driven SBOM. The declared dependencies contain\n2,202 unique vulnerabilities, while 22% of them do not report licensing\ninformation. Conclusion. Our findings provide insights for SBOM usage to\nsupport security assessment and licensing.", "AI": {"tldr": "\u5bf9\u5f00\u6e90\u9879\u76ee\u4e2d\u653f\u7b56\u9a71\u52a8\u7684SBOM\u73b0\u72b6\u5206\u6790\u663e\u793a\uff0c\u4ec5\u67090.56%\u7684\u6d41\u884cGitHub\u4ed3\u5e93\u5305\u542b\u6b64\u7c7bSBOM\uff0c\u5b58\u5728\u5927\u91cf\u6f0f\u6d1e\u4e1422%\u4f9d\u8d56\u9879\u7f3a\u5c11\u8bb8\u53ef\u8bc1\u4fe1\u606f", "motivation": "SBOM\u4f5c\u4e3a\u4fdd\u969c\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\u7684\u91cd\u8981\u5de5\u5177\uff0c\u5c3d\u7ba1\u653f\u5e9c\u5f3a\u5236\u8981\u6c42\u4f7f\u7528\uff0c\u4f46\u76f8\u5173\u7814\u7a76\u4ecd\u5904\u4e8e\u65e9\u671f\u9636\u6bb5\uff0c\u9700\u8981\u4e86\u89e3\u5f00\u6e90\u9879\u76ee\u4e2d\u653f\u7b56\u9a71\u52a8SBOM\u7684\u5b9e\u9645\u5e94\u7528\u72b6\u51b5", "method": "\u901a\u8fc7\u6316\u6398\u8f6f\u4ef6\u4ed3\u5e93\u7814\u7a76\uff0c\u6536\u96c6\u5e76\u7b5b\u9009GitHub\u4e0a\u6258\u7ba1\u7684SBOM\u6587\u4ef6\uff0c\u4f7f\u7528\u63cf\u8ff0\u6027\u7edf\u8ba1\u5206\u6790\u653f\u7b56\u9a71\u52a8SBOM\u4e2d\u62a5\u544a\u7684\u4fe1\u606f\u53ca\u5176\u4f9d\u8d56\u9879\u7684\u6f0f\u6d1e\u60c5\u51b5", "result": "\u4ec50.56%\u7684\u6d41\u884cGitHub\u4ed3\u5e93\u5305\u542b\u653f\u7b56\u9a71\u52a8SBOM\uff1b\u58f0\u660e\u7684\u4f9d\u8d56\u9879\u5305\u542b2,202\u4e2a\u552f\u4e00\u6f0f\u6d1e\uff1b22%\u7684\u4f9d\u8d56\u9879\u672a\u62a5\u544a\u8bb8\u53ef\u8bc1\u4fe1\u606f", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u652f\u6301\u5b89\u5168\u8bc4\u4f30\u548c\u8bb8\u53ef\u8bc1\u7ba1\u7406\u7684SBOM\u4f7f\u7528\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\uff0c\u63ed\u793a\u4e86\u5f53\u524dSBOM\u5b9e\u65bd\u7684\u4e0d\u8db3\u548c\u6539\u8fdb\u7a7a\u95f4"}}
{"id": "2509.00091", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.00091", "abs": "https://arxiv.org/abs/2509.00091", "authors": ["Ephraiem Sarabamoun"], "title": "Ensemble Debates with Local Large Language Models for AI Alignment", "comment": "9 pages, 2 tables", "summary": "As large language models (LLMs) take on greater roles in high-stakes\ndecisions, alignment with human values is essential. Reliance on proprietary\nAPIs limits reproducibility and broad participation. We study whether local\nopen-source ensemble debates can improve alignmentoriented reasoning. Across\n150 debates spanning 15 scenarios and five ensemble configurations, ensembles\noutperform single-model baselines on a 7-point rubric (overall: 3.48 vs. 3.13),\nwith the largest gains in reasoning depth (+19.4%) and argument quality\n(+34.1%). Improvements are strongest for truthfulness (+1.25 points) and human\nenhancement (+0.80). We provide code, prompts, and a debate data set, providing\nan accessible and reproducible foundation for ensemble-based alignment\nevaluation.", "AI": {"tldr": "\u672c\u5730\u5f00\u6e90\u6a21\u578b\u96c6\u6210\u8fa9\u8bba\u80fd\u663e\u8457\u63d0\u5347AI\u5bf9\u9f50\u80fd\u529b\uff0c\u5728\u63a8\u7406\u6df1\u5ea6\u548c\u8bba\u8bc1\u8d28\u91cf\u65b9\u9762\u5206\u522b\u63d0\u534719.4%\u548c34.1%\uff0c\u7279\u522b\u662f\u5728\u771f\u5b9e\u6027\u548c\u4eba\u7c7b\u589e\u5f3a\u65b9\u9762\u8868\u73b0\u6700\u4f73", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u91cd\u8981\u51b3\u7b56\u4e2d\u626e\u6f14\u66f4\u91cd\u8981\u7684\u89d2\u8272\uff0c\u9700\u8981\u786e\u4fdd\u5176\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u5bf9\u9f50\u3002\u4f9d\u8d56\u4e13\u6709API\u9650\u5236\u4e86\u7814\u7a76\u7684\u53ef\u590d\u73b0\u6027\u548c\u5e7f\u6cdb\u53c2\u4e0e", "method": "\u4f7f\u7528\u672c\u5730\u5f00\u6e90\u6a21\u578b\u8fdb\u884c\u96c6\u6210\u8fa9\u8bba\uff0c\u5728150\u573a\u8fa9\u8bba\u4e2d\u8986\u76d615\u4e2a\u573a\u666f\u548c5\u79cd\u96c6\u6210\u914d\u7f6e\uff0c\u91c7\u75287\u70b9\u8bc4\u5206\u6807\u51c6\u8fdb\u884c\u8bc4\u4f30", "result": "\u96c6\u6210\u6a21\u578b\u57287\u70b9\u8bc4\u5206\u6807\u51c6\u4e0a\u6574\u4f53\u8868\u73b0\u4f18\u4e8e\u5355\u6a21\u578b\u57fa\u7ebf\uff083.48 vs 3.13\uff09\uff0c\u5728\u771f\u5b9e\u6027\u65b9\u9762\u63d0\u5347\u6700\u5927\uff08+1.25\u5206\uff09\uff0c\u4eba\u7c7b\u589e\u5f3a\u65b9\u9762\u63d0\u53470.8\u5206", "conclusion": "\u96c6\u6210\u8fa9\u8bba\u4e3a\u57fa\u4e8e\u96c6\u6210\u7684\u5bf9\u9f50\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u8bbf\u95ee\u4e14\u53ef\u590d\u73b0\u7684\u57fa\u7840\uff0c\u8bc1\u660e\u4e86\u672c\u5730\u5f00\u6e90\u6a21\u578b\u5728\u63d0\u5347AI\u5bf9\u9f50\u80fd\u529b\u65b9\u9762\u7684\u6709\u6548\u6027"}}
{"id": "2509.00006", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.00006", "abs": "https://arxiv.org/abs/2509.00006", "authors": ["Motunrayo Adebayo"], "title": "Case Studies: Effective Approaches for Navigating Cross-Border Cloud Data Transfers Amid U.S. Government Privacy and Safety Concerns", "comment": "Privacy, Security", "summary": "This study attempts to explain the impact of information exchange from one\ncountry to another, as well as the legal and technological implications for\nthese exchanges. Due to the emergence of cloud technology, possibilities for\nfree exchange of information between countries have increased rapidly, as it\nhas become possible to save information in a country and access it in almost\nany part of the world. Countries all around the world have been confronted with\ndeveloping frameworks to facilitate this process, although there are\nsignificant challenges which must be confronted on legal and technological\nfronts, as loopholes in the framework adopted by countries may hinder free\naccess to information stored on cloud, and also compromise data privacy. Cloud\ntechnology is impacting a lot of issues, including domestic and international\nbusinesses, hence the need for a study to propose measures for safe exchange of\ninformation using cloud technology.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e91\u8ba1\u7b97\u6280\u672f\u5bf9\u56fd\u9645\u4fe1\u606f\u4ea4\u6362\u7684\u5f71\u54cd\uff0c\u5206\u6790\u6cd5\u5f8b\u548c\u6280\u672f\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u5b89\u5168\u4fe1\u606f\u4ea4\u6362\u7684\u63aa\u65bd\u5efa\u8bae", "motivation": "\u968f\u7740\u4e91\u8ba1\u7b97\u6280\u672f\u7684\u51fa\u73b0\uff0c\u56fd\u5bb6\u95f4\u81ea\u7531\u4fe1\u606f\u4ea4\u6362\u7684\u53ef\u80fd\u6027\u8fc5\u901f\u589e\u52a0\uff0c\u4f46\u73b0\u6709\u6cd5\u5f8b\u6846\u67b6\u5b58\u5728\u6f0f\u6d1e\uff0c\u53ef\u80fd\u963b\u788d\u4e91\u5b58\u50a8\u4fe1\u606f\u7684\u81ea\u7531\u8bbf\u95ee\u5e76\u5371\u53ca\u6570\u636e\u9690\u79c1\uff0c\u9700\u8981\u7814\u7a76\u5b89\u5168\u7684\u4fe1\u606f\u4ea4\u6362\u63aa\u65bd", "method": "\u5206\u6790\u4e91\u8ba1\u7b97\u6280\u672f\u5bf9\u56fd\u9645\u4fe1\u606f\u4ea4\u6362\u7684\u5f71\u54cd\uff0c\u8bc6\u522b\u6cd5\u5f8b\u548c\u6280\u672f\u5c42\u9762\u7684\u6311\u6218\uff0c\u7814\u7a76\u5404\u56fd\u73b0\u6709\u6846\u67b6\u7684\u6f0f\u6d1e\uff0c\u63d0\u51fa\u4fc3\u8fdb\u5b89\u5168\u4fe1\u606f\u4ea4\u6362\u7684\u63aa\u65bd\u5efa\u8bae", "result": "\u7814\u7a76\u53d1\u73b0\u4e91\u8ba1\u7b97\u6280\u672f\u663e\u8457\u4fc3\u8fdb\u4e86\u56fd\u9645\u4fe1\u606f\u4ea4\u6362\uff0c\u4f46\u5404\u56fd\u6cd5\u5f8b\u6846\u67b6\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\u548c\u6f0f\u6d1e\uff0c\u9700\u8981\u534f\u8c03\u7edf\u4e00\u7684\u6cd5\u5f8b\u6807\u51c6\u548c\u6280\u672f\u4fdd\u969c\u63aa\u65bd", "conclusion": "\u9700\u8981\u5236\u5b9a\u534f\u8c03\u7684\u56fd\u9645\u6cd5\u5f8b\u6846\u67b6\u548c\u6280\u672f\u6807\u51c6\uff0c\u4ee5\u786e\u4fdd\u4e91\u8ba1\u7b97\u73af\u5883\u4e0b\u7684\u4fe1\u606f\u5b89\u5168\u4ea4\u6362\uff0c\u540c\u65f6\u5e73\u8861\u4fe1\u606f\u81ea\u7531\u8bbf\u95ee\u548c\u6570\u636e\u9690\u79c1\u4fdd\u62a4\u7684\u9700\u6c42"}}
{"id": "2509.01294", "categories": ["cs.SE", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.01294", "abs": "https://arxiv.org/abs/2509.01294", "authors": ["Helge Spieker", "Nadjib Lazaar", "Arnaud Gotlieb", "Nassim Belmecheri"], "title": "Metamorphic Testing of Multimodal Human Trajectory Prediction", "comment": "Information and Software Technology", "summary": "Context: Predicting human trajectories is crucial for the safety and\nreliability of autonomous systems, such as automated vehicles and mobile\nrobots. However, rigorously testing the underlying multimodal Human Trajectory\nPrediction (HTP) models, which typically use multiple input sources (e.g.,\ntrajectory history and environment maps) and produce stochastic outputs\n(multiple possible future paths), presents significant challenges. The primary\ndifficulty lies in the absence of a definitive test oracle, as numerous future\ntrajectories might be plausible for any given scenario. Objectives: This\nresearch presents the application of Metamorphic Testing (MT) as a systematic\nmethodology for testing multimodal HTP systems. We address the oracle problem\nthrough metamorphic relations (MRs) adapted for the complexities and stochastic\nnature of HTP. Methods: We present five MRs, targeting transformations of both\nhistorical trajectory data and semantic segmentation maps used as an\nenvironmental context. These MRs encompass: 1) label-preserving geometric\ntransformations (mirroring, rotation, rescaling) applied to both trajectory and\nmap inputs, where outputs are expected to transform correspondingly. 2)\nMap-altering transformations (changing semantic class labels, introducing\nobstacles) with predictable changes in trajectory distributions. We propose\nprobabilistic violation criteria based on distance metrics between probability\ndistributions, such as the Wasserstein or Hellinger distance. Conclusion: This\nstudy introduces tool, a MT framework for the oracle-less testing of\nmultimodal, stochastic HTP systems. It allows for assessment of model\nrobustness against input transformations and contextual changes without\nreliance on ground-truth trajectories.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5e94\u7528\u8715\u53d8\u6d4b\u8bd5\u65b9\u6cd5\u6765\u6d4b\u8bd5\u591a\u6a21\u6001\u4eba\u7c7b\u8f68\u8ff9\u9884\u6d4b\u7cfb\u7edf\uff0c\u901a\u8fc7\u8bbe\u8ba15\u79cd\u8715\u53d8\u5173\u7cfb\u6765\u89e3\u51b3\u6d4b\u8bd5\u9884\u8a00\u95ee\u9898\uff0c\u5305\u62ec\u51e0\u4f55\u53d8\u6362\u548c\u5730\u56fe\u53d8\u6362\uff0c\u4f7f\u7528\u6982\u7387\u8ddd\u79bb\u5ea6\u91cf\u6765\u8bc4\u4f30\u6a21\u578b\u9c81\u68d2\u6027\u3002", "motivation": "\u591a\u6a21\u6001\u4eba\u7c7b\u8f68\u8ff9\u9884\u6d4b\u6a21\u578b\u7531\u4e8e\u8f93\u5165\u6e90\u591a\u6837\uff08\u8f68\u8ff9\u5386\u53f2\u548c\u73af\u5883\u5730\u56fe\uff09\u4e14\u8f93\u51fa\u968f\u673a\uff08\u591a\u6761\u53ef\u80fd\u8def\u5f84\uff09\uff0c\u7f3a\u4e4f\u660e\u786e\u7684\u6d4b\u8bd5\u9884\u8a00\uff0c\u96be\u4ee5\u8fdb\u884c\u4e25\u683c\u6d4b\u8bd5\u3002", "method": "\u63d0\u51fa5\u79cd\u8715\u53d8\u5173\u7cfb\uff1a1\uff09\u5bf9\u8f68\u8ff9\u548c\u5730\u56fe\u8f93\u5165\u8fdb\u884c\u6807\u7b7e\u4fdd\u6301\u7684\u51e0\u4f55\u53d8\u6362\uff08\u955c\u50cf\u3001\u65cb\u8f6c\u3001\u7f29\u653e\uff09\uff1b2\uff09\u5730\u56fe\u53d8\u6362\uff08\u6539\u53d8\u8bed\u4e49\u6807\u7b7e\u3001\u5f15\u5165\u969c\u788d\u7269\uff09\u3002\u4f7f\u7528Wasserstein\u6216Hellinger\u8ddd\u79bb\u7b49\u6982\u7387\u5ea6\u91cf\u6765\u5b9a\u4e49\u8fdd\u53cd\u6807\u51c6\u3002", "result": "\u5f00\u53d1\u4e86MT\u6846\u67b6\uff0c\u80fd\u591f\u5728\u6ca1\u6709\u771f\u5b9e\u8f68\u8ff9\u7684\u60c5\u51b5\u4e0b\u8bc4\u4f30\u6a21\u578b\u5bf9\u8f93\u5165\u53d8\u6362\u548c\u4e0a\u4e0b\u6587\u53d8\u5316\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u8715\u53d8\u6d4b\u8bd5\u4e3a\u591a\u6a21\u6001\u968f\u673a\u4eba\u7c7b\u8f68\u8ff9\u9884\u6d4b\u7cfb\u7edf\u7684\u65e0\u9884\u8a00\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u7cfb\u7edf\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6d4b\u8bd5\u9884\u8a00\u7f3a\u5931\u95ee\u9898\u3002"}}
{"id": "2509.00100", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00100", "abs": "https://arxiv.org/abs/2509.00100", "authors": ["Rahul Anand"], "title": "MODE: Mixture of Document Experts for RAG", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) often relies on large vector databases\nand cross-encoders tuned for large-scale corpora, which can be excessive for\nsmall, domain-specific collections. We present MODE (Mixture of Document\nExperts), a lightweight alternative that replaces fine-grained nearest-neighbor\nsearch with cluster-and-route retrieval. Documents are embedded, grouped into\nsemantically coherent clusters, and represented by cached centroids. At query\ntime, we route to the top centroid(s) and retrieve context only within those\nclusters, eliminating external vector-database infrastructure and reranking\nwhile keeping latency low. On HotpotQA and SQuAD corpora with 100-500 chunks,\nMODE matches or exceeds a dense-retrieval baseline in answer quality while\nreducing end-to-end retrieval time. Ablations show that cluster granularity and\nmulti-cluster routing control the recall/precision trade-off, and that tighter\nclusters improve downstream accuracy. MODE offers a practical recipe for small\nand medium corpora where simplicity, speed, and topical focus matter.", "AI": {"tldr": "MODE\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\uff0c\u7528\u805a\u7c7b\u8def\u7531\u68c0\u7d22\u66ff\u4ee3\u7cbe\u7ec6\u7684\u6700\u8fd1\u90bb\u641c\u7d22\uff0c\u5728\u5c0f\u578b\u9886\u57df\u7279\u5b9a\u8bed\u6599\u5e93\u4e0a\u5b9e\u73b0\u9ad8\u6548\u68c0\u7d22", "motivation": "\u4f20\u7edf\u7684RAG\u65b9\u6cd5\u4f9d\u8d56\u5927\u578b\u5411\u91cf\u6570\u636e\u5e93\u548c\u8de8\u7f16\u7801\u5668\uff0c\u5bf9\u4e8e\u5c0f\u578b\u9886\u57df\u7279\u5b9a\u8bed\u6599\u5e93\u6765\u8bf4\u8fc7\u4e8e\u590d\u6742\u548c\u5197\u4f59\uff0c\u9700\u8981\u66f4\u8f7b\u91cf\u7ea7\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u5c06\u6587\u6863\u5d4c\u5165\u540e\u5206\u7ec4\u5230\u8bed\u4e49\u8fde\u8d2f\u7684\u805a\u7c7b\u4e2d\uff0c\u7528\u7f13\u5b58\u8d28\u5fc3\u8868\u793a\u3002\u67e5\u8be2\u65f6\u8def\u7531\u5230\u9876\u90e8\u8d28\u5fc3\uff0c\u4ec5\u5728\u8fd9\u4e9b\u805a\u7c7b\u5185\u68c0\u7d22\u4e0a\u4e0b\u6587\uff0c\u65e0\u9700\u5916\u90e8\u5411\u91cf\u6570\u636e\u5e93\u57fa\u7840\u8bbe\u65bd\u548c\u91cd\u6392\u5e8f", "result": "\u5728HotpotQA\u548cSQuAD\u8bed\u6599\u5e93\uff08100-500\u4e2a\u5757\uff09\u4e0a\uff0cMODE\u5728\u7b54\u6848\u8d28\u91cf\u4e0a\u5339\u914d\u6216\u8d85\u8fc7\u5bc6\u96c6\u68c0\u7d22\u57fa\u7ebf\uff0c\u540c\u65f6\u51cf\u5c11\u7aef\u5230\u7aef\u68c0\u7d22\u65f6\u95f4", "conclusion": "MODE\u4e3a\u4e2d\u5c0f\u578b\u8bed\u6599\u5e93\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u7b80\u5355\u6027\u3001\u901f\u5ea6\u548c\u4e3b\u9898\u805a\u7126\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u805a\u7c7b\u7c92\u5ea6\u548c\u591a\u805a\u7c7b\u8def\u7531\u63a7\u5236\u53ec\u56de\u7387/\u7cbe\u786e\u5ea6\u7684\u6743\u8861"}}
{"id": "2509.00043", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00043", "abs": "https://arxiv.org/abs/2509.00043", "authors": ["Md Faizul Bari", "Yi Xie", "Meghna Roy Choudhury", "Shreyas Sen"], "title": "Keystroke Detection by Exploiting Unintended RF Emission from Repaired USB Keyboards", "comment": "This journal version is an extended version of a previously published\n  conference paper which can be found here:\n  https://ieeexplore.ieee.org/abstract/document/10181751", "summary": "Electronic devices and cables inadvertently emit RF emissions as a byproduct\nof signal processing and/or transmission. Labeled as electromagnetic\nemanations, they form an EM side-channel for data leakage. Previously, it was\nbelieved that such leakage could be contained within a facility since they are\nweak signals with a short transmission range. However, in the preliminary\nversion of this work [1], we found that the traditional cable repairing process\nforms a tiny monopole antenna that helps emanations transmit over a long range.\nExperimentation with three types of cables revealed that emanations from\nrepaired cables remain detectable even at >4 m and can penetrate a 14 cm thick\nconcrete wall. In this extended version, we show that such emanation can be\nexploited at a long distance for information extraction by detecting keystrokes\ntyped on a repaired USB keyboard. By collecting data for 70 different\nkeystrokes at different distances from the target in 3 diverse environments\n(open space, a corridor outside an office room, and outside a building) and\ndeveloping an efficient detection algorithm, ~100% keystroke detection accuracy\nhas been achieved up to 12 m distance, which is the highest reported accuracy\nat such a long range for USB keyboards in the literature. The effect of two\nexperimental factors, interference and human-body coupling, has been\ninvestigated thoroughly. Along with exploring the vulnerability, multi-layer\nexternal metal shielding during the repairing process as a possible remedy has\nbeen explored. This work exposes a new attack surface caused by hardware\nmodification, its exploitation, and potential countermeasures.", "AI": {"tldr": "\u901a\u8fc7\u4fee\u590d\u7684USB\u7ebf\u7f06\u5f62\u6210\u7684\u5fae\u578b\u5355\u6781\u5929\u7ebf\u53ef\u4ee5\u572812\u7c73\u8fdc\u8ddd\u79bb\u4e0a\u6355\u83b7\u952e\u76d8\u952e\u5165\u4fe1\u606f\uff0c\u7a81\u7834\u4e86\u4ee5\u5f80\u5bf9\u7535\u78c1\u6f0f\u6cc9\u77ed\u8ddd\u79bb\u4f20\u8f93\u7684\u8ba4\u8bc6", "motivation": "\u4ee5\u5f80\u8ba4\u4e3a\u7535\u5b50\u8bbe\u5907\u7684\u7535\u78c1\u6f0f\u6cc9\u4fe1\u53f7\u5f31\u3001\u4f20\u8f93\u8ddd\u79bb\u77ed\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\u7ebf\u7f06\u4fee\u590d\u8fc7\u7a0b\u4f1a\u5f62\u6210\u5929\u7ebf\u6548\u5e94\uff0c\u5bfc\u81f4\u957f\u8ddd\u79bb\u6570\u636e\u6cc4\u6f0f\u98ce\u9669", "method": "\u57283\u79cd\u4e0d\u540c\u73af\u5883\u4e2d\u6536\u96c670\u79cd\u952e\u5165\u6570\u636e\uff0c\u5f00\u53d1\u9ad8\u6548\u68c0\u6d4b\u7b97\u6cd5\uff0c\u7814\u7a8b\u5e72\u6270\u548c\u4eba\u4f53\u8026\u5408\u6548\u5e94\uff0c\u5e76\u63a2\u7d22\u5916\u90e8\u91d1\u5c5e\u5c4f\u853d\u4f5c\u4e3a\u9632\u8303\u63aa\u65bd", "result": "\u5728\u8fdc\u8ddd\u79bb12\u7c73\u5904\u8fbe\u5230\u7ea6100%\u7684\u952e\u5165\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u662fUSB\u952e\u76d8\u5728\u8fd9\u79cd\u8ddd\u79bb\u4e0a\u7684\u6700\u9ad8\u51c6\u786e\u7387\u8bb0\u5f55", "conclusion": "\u8be5\u7814\u7a76\u66dd\u9732\u4e86\u786c\u4ef6\u4fee\u6539\u5bfc\u81f4\u7684\u65b0\u653b\u51fb\u9762\uff0c\u8bc1\u660e\u4fee\u590d\u7ebf\u7f06\u53ef\u80fd\u9020\u6210\u957f\u8ddd\u79bb\u6570\u636e\u6cc4\u6f0f\uff0c\u5e76\u63d0\u51fa\u4e86\u91d1\u5c5e\u5c4f\u853d\u7b49\u9632\u8303\u65b9\u6848"}}
{"id": "2509.01313", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.01313", "abs": "https://arxiv.org/abs/2509.01313", "authors": ["Zhao Tian", "Junjie Chen"], "title": "Aligning Requirement for Large Language Model's Code Generation", "comment": "Accepted by ICSE 2026", "summary": "Code generation refers to the automatic generation of source code based on a\ngiven programming specification, which has garnered significant attention\nparticularly with the advancement of large language models (LLMs). However, due\nto the inherent complexity of real-world problems, the LLM-generated code often\nfails to fully align with the provided specification. While state-of-the-art\nagent-based techniques have been proposed to enhance LLM code generation, they\noverlook the critical issue of specification perception, resulting in\npersistent misalignment issues. Given that accurate perception of programming\nspecifications serves as the foundation of the LLM-based code generation\nparadigm, ensuring specification alignment is particularly crucial. In this\nwork, we draw on software requirements engineering to propose Specine, a novel\nspecification alignment technique for LLM code generation. Its key idea is to\nidentify misaligned input specifications, lift LLM-perceived specifications,\nand align them to enhance the code generation performance of LLMs. Our\ncomprehensive experiments on four state-of-the-art LLMs across five challenging\ncompetitive benchmarks by comparing with ten state-of-the-art baselines,\ndemonstrate the effectiveness of Specine. For example, Specine outperforms the\nmost effective baseline, achieving an average improvement of 29.60\\% across all\nsubjects in terms of Pass@1.", "AI": {"tldr": "Specine\u662f\u4e00\u79cd\u57fa\u4e8e\u8f6f\u4ef6\u9700\u6c42\u5de5\u7a0b\u7684\u89c4\u8303\u5bf9\u9f50\u6280\u672f\uff0c\u901a\u8fc7\u8bc6\u522b\u672a\u5bf9\u9f50\u7684\u8f93\u5165\u89c4\u8303\u3001\u63d0\u5347LLM\u611f\u77e5\u7684\u89c4\u8303\u5e76\u8fdb\u884c\u5bf9\u9f50\uff0c\u6765\u589e\u5f3aLLM\u4ee3\u7801\u751f\u6210\u7684\u6027\u80fd", "motivation": "\u73b0\u6709\u57fa\u4e8e\u4ee3\u7406\u7684\u6280\u672f\u867d\u7136\u63d0\u5347\u4e86LLM\u4ee3\u7801\u751f\u6210\u80fd\u529b\uff0c\u4f46\u5ffd\u89c6\u4e86\u89c4\u8303\u611f\u77e5\u8fd9\u4e00\u5173\u952e\u95ee\u9898\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u4ee3\u7801\u4e0e\u7f16\u7a0b\u89c4\u8303\u6301\u7eed\u5b58\u5728\u4e0d\u5bf9\u9f50\u95ee\u9898", "method": "\u501f\u9274\u8f6f\u4ef6\u9700\u6c42\u5de5\u7a0b\u6280\u672f\uff0c\u63d0\u51faSpecine\u65b9\u6cd5\uff0c\u5305\u62ec\u8bc6\u522b\u672a\u5bf9\u9f50\u7684\u8f93\u5165\u89c4\u8303\u3001\u63d0\u5347LLM\u611f\u77e5\u7684\u89c4\u8303\u3001\u4ee5\u53ca\u5bf9\u9f50\u89c4\u8303\u4e09\u4e2a\u5173\u952e\u6b65\u9aa4", "result": "\u5728\u56db\u4e2a\u6700\u5148\u8fdbLLM\u548c\u4e94\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u7ade\u4e89\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSpecine\u5728Pass@1\u6307\u6807\u4e0a\u5e73\u5747\u6bd4\u6700\u6709\u6548\u57fa\u7ebf\u63d0\u534729.60%", "conclusion": "Specine\u901a\u8fc7\u6709\u6548\u7684\u89c4\u8303\u5bf9\u9f50\u6280\u672f\u663e\u8457\u63d0\u5347\u4e86LLM\u4ee3\u7801\u751f\u6210\u7684\u51c6\u786e\u6027\u548c\u4e0e\u89c4\u8303\u7684\u5339\u914d\u5ea6"}}
{"id": "2509.00115", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.00115", "abs": "https://arxiv.org/abs/2509.00115", "authors": ["Manish Shukla"], "title": "Adaptive Monitoring and Real-World Evaluation of Agentic AI Systems", "comment": null, "summary": "Agentic artificial intelligence (AI) -- multi-agent systems that combine\nlarge language models with external tools and autonomous planning -- are\nrapidly transitioning from research laboratories into high-stakes domains. Our\nearlier \"Basic\" paper introduced a five-axis framework and proposed preliminary\nmetrics such as goal drift and harm reduction but did not provide an\nalgorithmic instantiation or empirical evidence. This \"Advanced\" sequel fills\nthat gap. First, we revisit recent benchmarks and industrial deployments to\nshow that technical metrics still dominate evaluations: a systematic review of\n84 papers from 2023--2025 found that 83% report capability metrics while only\n30% consider human-centred or economic axes [2]. Second, we formalise an\nAdaptive Multi-Dimensional Monitoring (AMDM) algorithm that normalises\nheterogeneous metrics, applies per-axis exponentially weighted moving-average\nthresholds and performs joint anomaly detection via the Mahalanobis distance.\nThird, we conduct simulations and real-world experiments. AMDM cuts\nanomaly-detection latency from 12.3 s to 5.6 s on simulated goal drift and\nreduces false-positive rates from 4.5% to 0.9% compared with static thresholds.\nWe present a comparison table and ROC/PR curves, and we reanalyse case studies\nto surface missing metrics. Code, data and a reproducibility checklist\naccompany this paper to facilitate replication.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u81ea\u9002\u5e94\u591a\u7ef4\u76d1\u63a7\u7b97\u6cd5(AMDM)\uff0c\u7528\u4e8e\u6539\u8fdb\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u7684\u8bc4\u4f30\uff0c\u901a\u8fc7\u6807\u51c6\u5316\u6307\u6807\u548c\u5f02\u5e38\u68c0\u6d4b\u6765\u51cf\u5c11\u8bef\u62a5\u7387\u548c\u5ef6\u8fdf\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u6280\u672f\u6307\u6807\uff0c\u7f3a\u4e4f\u5bf9\u4eba\u7c7b\u4e2d\u5fc3\u548c\u7ecf\u6d4e\u7ef4\u5ea6\u7684\u8003\u91cf\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u76d1\u63a7\u6846\u67b6\u3002", "method": "\u5f00\u53d1\u4e86AMDM\u7b97\u6cd5\uff0c\u5305\u62ec\u6307\u6807\u6807\u51c6\u5316\u3001\u6307\u6570\u52a0\u6743\u79fb\u52a8\u5e73\u5747\u9608\u503c\u548c\u57fa\u4e8e\u9a6c\u6c0f\u8ddd\u79bb\u7684\u8054\u5408\u5f02\u5e38\u68c0\u6d4b\u3002", "result": "AMDM\u5c06\u5f02\u5e38\u68c0\u6d4b\u5ef6\u8fdf\u4ece12.3\u79d2\u964d\u81f35.6\u79d2\uff0c\u8bef\u62a5\u7387\u4ece4.5%\u964d\u81f30.9%\uff0c\u5728\u6a21\u62df\u548c\u771f\u5b9e\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "AMDM\u7b97\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u7684\u76d1\u63a7\u6027\u80fd\uff0c\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2509.00059", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00059", "abs": "https://arxiv.org/abs/2509.00059", "authors": ["Andres Alejandre", "Kassandra Delfin", "Victor Castano"], "title": "Cryptographic Challenges: Masking Sensitive Data in Cyber Crimes through ASCII Art", "comment": "11 pages, 4 figures", "summary": "The use of ASCII art as a novel approach to masking sensitive information in\ncybercrime, focusing on its potential role in protecting personal data during\nthe delivery process and beyond, is presented. By examining the unique\nproperties of ASCII art and its historical context, this study discusses the\nadvantages and limitations of employing this technique in various cybercrime\nscenarios. Additionally, providing recommendations for enhancing data security\npractices and fostering a culture of privacy awareness in both businesses and\nindividuals. The findings suggest that ASCII art, with its simplicity and\nambiguity, can serve as an effective tool against cybercriminals, emphasizing\nthe need for robust data security measures and increased privacy awareness in\ntoday's interconnected world.", "AI": {"tldr": "ASCII\u827a\u672f\u4f5c\u4e3a\u4e00\u79cd\u65b0\u9896\u7684\u654f\u611f\u4fe1\u606f\u63a9\u7801\u6280\u672f\uff0c\u5728\u7f51\u7edc\u5b89\u5168\u9886\u57df\u5177\u6709\u5e94\u7528\u6f5c\u529b\uff0c\u80fd\u591f\u901a\u8fc7\u5176\u7b80\u5355\u6027\u548c\u6a21\u7cca\u6027\u6709\u6548\u5bf9\u6297\u7f51\u7edc\u72af\u7f6a\u3002", "motivation": "\u7814\u7a76ASCII\u827a\u672f\u5728\u4fdd\u62a4\u4e2a\u4eba\u6570\u636e\u65b9\u9762\u7684\u6f5c\u5728\u4f5c\u7528\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u4f20\u8f93\u8fc7\u7a0b\u4e2d\uff0c\u63a2\u8ba8\u5176\u5728\u7f51\u7edc\u5b89\u5168\u4e2d\u7684\u72ec\u7279\u4ef7\u503c\u3002", "method": "\u901a\u8fc7\u5206\u6790ASCII\u827a\u672f\u7684\u72ec\u7279\u5c5e\u6027\u548c\u5386\u53f2\u80cc\u666f\uff0c\u7814\u7a76\u5176\u5728\u5404\u79cd\u7f51\u7edc\u72af\u7f6a\u573a\u666f\u4e2d\u7684\u5e94\u7528\u4f18\u52bf\u548c\u5c40\u9650\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0ASCII\u827a\u672f\u51ed\u501f\u5176\u7b80\u5355\u6027\u548c\u6a21\u7cca\u6027\uff0c\u53ef\u4ee5\u4f5c\u4e3a\u5bf9\u6297\u7f51\u7edc\u72af\u7f6a\u7684\u6709\u6548\u5de5\u5177\u3002", "conclusion": "\u9700\u8981\u52a0\u5f3a\u6570\u636e\u5b89\u5168\u63aa\u65bd\u548c\u63d0\u9ad8\u9690\u79c1\u610f\u8bc6\uff0cASCII\u827a\u672f\u6280\u672f\u4e3a\u7f51\u7edc\u5b89\u5168\u63d0\u4f9b\u4e86\u65b0\u7684\u9632\u62a4\u601d\u8def\u3002"}}
{"id": "2509.01318", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.01318", "abs": "https://arxiv.org/abs/2509.01318", "authors": ["Chiara Ghinami", "Jonas Winzer", "Nils Bosbach", "Lennart M. Reimann", "Lukas J\u00fcnger", "Simon W\u00f6rner", "Rainer Leupers"], "title": "Leveraging SystemC-TLM-based Virtual Prototypes for Embedded Software Fuzzing", "comment": null, "summary": "SystemC-based virtual prototypes have emerged as widely adopted tools to test\nsoftware ahead of hardware availability, reducing the time-to-market and\nimproving software reliability. Recently, fuzzing has become a popular method\nfor automated software testing due to its ability to quickly identify\ncorner-case errors. However, its application to embedded software is still\nlimited. Simulator tools can help bridge this gap by providing a more powerful\nand controlled execution environment for testing. Existing solutions, however,\noften tightly couple fuzzers with built-in simulators that lack support for\nhardware peripherals and of- fer limited flexibility, restricting their ability\nto test embedded software. To address these limitations, we present a framework\nthat allows the integration of American-Fuzzy-Lop-based fuzzers and\nSystemC-based simulators. The framework provides a harness to decouple the\nadopted fuzzer and simulator. In addition, it intercepts peripheral accesses\nand queries the fuzzer for values, effectively linking peripheral behavior to\nthe fuzzer. This solution enables flexible interchangeability of peripher- als\nwithin the simulation environment and supports the interfacing of different\nSystemC-based virtual prototypes. The flexibility of the pro- posed solution is\ndemonstrated by integrating the harness with different simulators and by\ntesting various softwares.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5c06AFL\u6a21\u7cca\u6d4b\u8bd5\u4e0eSystemC\u6a21\u62df\u5668\u96c6\u6210\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u548c\u5916\u56f4\u8bbe\u5907\u8bbf\u95ee\u62e6\u622a\u6765\u589e\u5f3a\u5d4c\u5165\u5f0f\u8f6f\u4ef6\u7684\u6d4b\u8bd5\u80fd\u529b", "motivation": "\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u901a\u5e38\u5c06\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u4e0e\u5185\u7f6e\u6a21\u62df\u5668\u7d27\u5bc6\u8026\u5408\uff0c\u7f3a\u4e4f\u786c\u4ef6\u5916\u56f4\u8bbe\u5907\u652f\u6301\u4e14\u7075\u6d3b\u6027\u6709\u9650\uff0c\u9650\u5236\u4e86\u5d4c\u5165\u5f0f\u8f6f\u4ef6\u7684\u6d4b\u8bd5\u80fd\u529b", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u63d0\u4f9b\u89e3\u8026\u9002\u914d\u5668\u6765\u5206\u79bb\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u548c\u6a21\u62df\u5668\uff0c\u62e6\u622a\u5916\u56f4\u8bbe\u5907\u8bbf\u95ee\u5e76\u5411\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u67e5\u8be2\u503c\uff0c\u5c06\u5916\u56f4\u8bbe\u5907\u884c\u4e3a\u4e0e\u6a21\u7cca\u6d4b\u8bd5\u8fde\u63a5\u8d77\u6765", "result": "\u8be5\u89e3\u51b3\u65b9\u6848\u5b9e\u73b0\u4e86\u6a21\u62df\u73af\u5883\u4e2d\u5916\u56f4\u8bbe\u5907\u7684\u7075\u6d3b\u4e92\u6362\u6027\uff0c\u5e76\u652f\u6301\u4e0d\u540cSystemC\u865a\u62df\u539f\u578b\u7684\u63a5\u53e3\u8fde\u63a5", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u96c6\u6210\u4e0d\u540c\u6a21\u62df\u5668\u548c\u6d4b\u8bd5\u5404\u79cd\u8f6f\u4ef6\uff0c\u5c55\u793a\u4e86\u6240\u63d0\u51fa\u89e3\u51b3\u65b9\u6848\u7684\u7075\u6d3b\u6027\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5d4c\u5165\u5f0f\u8f6f\u4ef6\u6a21\u7cca\u6d4b\u8bd5\u7684\u5c40\u9650\u6027"}}
{"id": "2509.00125", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00125", "abs": "https://arxiv.org/abs/2509.00125", "authors": ["Ang Li", "Zhihang Yuan", "Yang Zhang", "Shouda Liu", "Yisen Wang"], "title": "Know When to Explore: Difficulty-Aware Certainty as a Guide for LLM Reinforcement Learning", "comment": null, "summary": "Reinforcement Learning with Verifiable Feedback (RLVF) has become a key\ntechnique for enhancing the reasoning abilities of Large Language Models\n(LLMs). However, its reliance on sparse, outcome based rewards, which only\nindicate if a final answer is correct or not, fails to provide granular\nguidance on the reasoning process itself. This limitation hinders efficient\nlearning, as the model cannot distinguish between high quality and inefficient\nsolutions, nor can it learn effectively from different types of failures. To\naddress this, we observe that an LLMs self-certainty often correlates with task\ndifficulty and solution quality. We introduce Difficulty Aware Certainty guided\nExploration (DACE), a novel RL algorithm that leverages this insight to\ndynamically balance the exploration exploitation trade-off. DACE assesses task\ndifficulty online based on the policys success rate. It then uses this signal\nto modulate an intrinsic reward: for difficult tasks where the model is\nstruggling, DACE encourages exploration by penalizing high certainty; for\neasier tasks, it encourages learning efficiency by rewarding high certainty.\nExperiments on challenging mathematical reasoning benchmarks (AIME, MATH) show\nthat DACE significantly outperforms strong baselines. The DACE-trained models\nnot only achieve higher accuracy but also demonstrate more robust performance\nwhen scaling test-time compute, validating that our adaptive approach fosters\neffective exploration without sacrificing precision.", "AI": {"tldr": "DACE\u7b97\u6cd5\u901a\u8fc7\u5229\u7528LLM\u7684\u81ea\u4fe1\u5fc3\u4e0e\u4efb\u52a1\u96be\u5ea6\u7684\u76f8\u5173\u6027\uff0c\u52a8\u6001\u8c03\u6574\u63a2\u7d22-\u5229\u7528\u5e73\u8861\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5", "motivation": "\u4f20\u7edfRLVF\u4f9d\u8d56\u7a00\u758f\u7684\u7ed3\u679c\u5956\u52b1\uff0c\u65e0\u6cd5\u4e3a\u63a8\u7406\u8fc7\u7a0b\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u6307\u5bfc\uff0c\u9650\u5236\u4e86\u5b66\u4e60\u6548\u7387", "method": "\u63d0\u51faDifficulty Aware Certainty guided Exploration (DACE)\u7b97\u6cd5\uff0c\u5728\u7ebf\u8bc4\u4f30\u4efb\u52a1\u96be\u5ea6\u5e76\u57fa\u4e8e\u6a21\u578b\u81ea\u4fe1\u5fc3\u52a8\u6001\u8c03\u6574\u5185\u5728\u5956\u52b1\u673a\u5236", "result": "\u5728AIME\u548cMATH\u7b49\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u6a21\u578b\u4e0d\u4ec5\u51c6\u786e\u7387\u66f4\u9ad8\uff0c\u800c\u4e14\u5728\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u6269\u5c55\u65f6\u8868\u73b0\u66f4\u7a33\u5065", "conclusion": "DACE\u7684\u81ea\u9002\u5e94\u65b9\u6cd5\u80fd\u591f\u4fc3\u8fdb\u6709\u6548\u63a2\u7d22\u800c\u4e0d\u727a\u7272\u7cbe\u5ea6\uff0c\u9a8c\u8bc1\u4e86\u5229\u7528\u6a21\u578b\u81ea\u4fe1\u5fc3\u6307\u5bfc\u5f3a\u5316\u5b66\u4e60\u7684\u6709\u6548\u6027"}}
{"id": "2509.00081", "categories": ["cs.CR", "cs.AI", "I.2.7; I.2.6; I.2.4"], "pdf": "https://arxiv.org/pdf/2509.00081", "abs": "https://arxiv.org/abs/2509.00081", "authors": ["Luca Cotti", "Anisa Rula", "Devis Bianchini", "Federico Cerutti"], "title": "Enabling Transparent Cyber Threat Intelligence Combining Large Language Models and Domain Ontologies", "comment": "14 pages, 3 figures, 6 tables, accepted at XAI-KRKG@ECAI25: First\n  International ECAI Workshop on eXplainable AI, Knowledge Representation and\n  Knowledge Graphs, October 25-30, 2025, Bologna, Italy", "summary": "Effective Cyber Threat Intelligence (CTI) relies upon accurately structured\nand semantically enriched information extracted from cybersecurity system logs.\nHowever, current methodologies often struggle to identify and interpret\nmalicious events reliably and transparently, particularly in cases involving\nunstructured or ambiguous log entries. In this work, we propose a novel\nmethodology that combines ontology-driven structured outputs with Large\nLanguage Models (LLMs), to build an Artificial Intelligence (AI) agent that\nimproves the accuracy and explainability of information extraction from\ncybersecurity logs. Central to our approach is the integration of domain\nontologies and SHACL-based constraints to guide the language model's output\nstructure and enforce semantic validity over the resulting graph. Extracted\ninformation is organized into an ontology-enriched graph database, enabling\nfuture semantic analysis and querying. The design of our methodology is\nmotivated by the analytical requirements associated with honeypot log data,\nwhich typically comprises predominantly malicious activity. While our case\nstudy illustrates the relevance of this scenario, the experimental evaluation\nis conducted using publicly available datasets. Results demonstrate that our\nmethod achieves higher accuracy in information extraction compared to\ntraditional prompt-only approaches, with a deliberate focus on extraction\nquality rather than processing speed.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u672c\u4f53\u8bba\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u7f51\u7edc\u5b89\u5168\u65e5\u5fd7\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u5a01\u80c1\u60c5\u62a5\u4fe1\u606f\uff0c\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u5f53\u524d\u65b9\u6cd5\u5728\u5904\u7406\u975e\u7ed3\u6784\u5316\u548c\u6a21\u7cca\u65e5\u5fd7\u6761\u76ee\u65f6\u96be\u4ee5\u53ef\u9760\u5730\u8bc6\u522b\u548c\u89e3\u91ca\u6076\u610f\u4e8b\u4ef6\uff0c\u9700\u8981\u66f4\u51c6\u786e\u548c\u900f\u660e\u7684\u4fe1\u606f\u63d0\u53d6\u65b9\u6cd5\u3002", "method": "\u6574\u5408\u9886\u57df\u672c\u4f53\u548cSHACL\u7ea6\u675f\u6765\u6307\u5bfc\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u7ed3\u6784\uff0c\u786e\u4fdd\u8bed\u4e49\u6709\u6548\u6027\uff0c\u5e76\u5c06\u63d0\u53d6\u4fe1\u606f\u7ec4\u7ec7\u6210\u8bed\u4e49\u56fe\u6570\u636e\u5e93\u3002", "result": "\u76f8\u6bd4\u4f20\u7edf\u63d0\u793a\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u4fe1\u606f\u63d0\u53d6\u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u7279\u522b\u5173\u6ce8\u63d0\u53d6\u8d28\u91cf\u800c\u975e\u5904\u7406\u901f\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7f51\u7edc\u5b89\u5168\u65e5\u5fd7\u5206\u6790\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u3001\u53ef\u89e3\u91ca\u7684\u7ed3\u6784\u5316\u4fe1\u606f\u63d0\u53d6\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u871c\u7f50\u65e5\u5fd7\u7b49\u6076\u610f\u6d3b\u52a8\u5206\u6790\u573a\u666f\u3002"}}
{"id": "2509.01389", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.01389", "abs": "https://arxiv.org/abs/2509.01389", "authors": ["Diego Clerissi", "Elena Masserini", "Daniela Micucci", "Leonardo Mariani"], "title": "Towards Multi-Platform Mutation Testing of Task-based Chatbots", "comment": "4 pages, 1 figure, Accepted at 9th International Workshop on Software\n  Faults 2025", "summary": "Chatbots, also known as conversational agents, have become ubiquitous,\noffering services for a multitude of domains. Unlike general-purpose chatbots,\ntask-based chatbots are software designed to prioritize the completion of tasks\nof the domain they handle (e.g., flight booking). Given the growing popularity\nof chatbots, testing techniques that can generate full conversations as test\ncases have emerged. Still, thoroughly testing all the possible conversational\nscenarios implemented by a task-based chatbot is challenging, resulting in\nincorrect behaviors that may remain unnoticed. To address this challenge, we\nproposed MUTABOT, a mutation testing approach for injecting faults in\nconversations and producing faulty chatbots that emulate defects that may\naffect the conversational aspects. In this paper, we present our extension of\nMUTABOT to multiple platforms (Dialogflow and Rasa), and present experiments\nthat show how mutation testing can be used to reveal weaknesses in test suites\ngenerated by the Botium state-of-the-art test generator.", "AI": {"tldr": "MUTABOT\u662f\u4e00\u4e2a\u9488\u5bf9\u4efb\u52a1\u578b\u804a\u5929\u673a\u5668\u4eba\u7684\u53d8\u5f02\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u901a\u8fc7\u6ce8\u5165\u5bf9\u8bdd\u6545\u969c\u6765\u6a21\u62df\u7f3a\u9677\uff0c\u6269\u5c55\u652f\u6301Dialogflow\u548cRasa\u5e73\u53f0\uff0c\u5b9e\u9a8c\u663e\u793a\u80fd\u6709\u6548\u53d1\u73b0Botium\u6d4b\u8bd5\u5957\u4ef6\u7684\u5f31\u70b9", "motivation": "\u4efb\u52a1\u578b\u804a\u5929\u673a\u5668\u4eba\u6d4b\u8bd5\u56f0\u96be\uff0c\u73b0\u6709\u6d4b\u8bd5\u6280\u672f\u96be\u4ee5\u8986\u76d6\u6240\u6709\u53ef\u80fd\u7684\u5bf9\u8bdd\u573a\u666f\uff0c\u5bfc\u81f4\u7f3a\u9677\u96be\u4ee5\u88ab\u53d1\u73b0", "method": "\u63d0\u51faMUTABOT\u53d8\u5f02\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u5728\u5bf9\u8bdd\u4e2d\u6ce8\u5165\u6545\u969c\u6765\u4ea7\u751f\u6709\u7f3a\u9677\u7684\u804a\u5929\u673a\u5668\u4eba\uff0c\u6269\u5c55\u652f\u6301\u591a\u4e2a\u5e73\u53f0\uff08Dialogflow\u548cRasa\uff09", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63ed\u793aBotium\u6700\u5148\u8fdb\u6d4b\u8bd5\u751f\u6210\u5668\u751f\u6210\u7684\u6d4b\u8bd5\u5957\u4ef6\u7684\u5f31\u70b9", "conclusion": "\u53d8\u5f02\u6d4b\u8bd5\u662f\u8bc4\u4f30\u4efb\u52a1\u578b\u804a\u5929\u673a\u5668\u4eba\u6d4b\u8bd5\u5957\u4ef6\u8d28\u91cf\u7684\u6709\u6548\u65b9\u6cd5\uff0cMUTABOT\u65b9\u6cd5\u5177\u6709\u8de8\u5e73\u53f0\u9002\u7528\u6027"}}
{"id": "2509.00135", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00135", "abs": "https://arxiv.org/abs/2509.00135", "authors": ["Davin Choo", "Yohai Trabelsi", "Fentabil Getnet", "Samson Warkaye Lamma", "Wondesen Nigatu", "Kasahun Sime", "Lisa Matay", "Milind Tambe", "St\u00e9phane Verguet"], "title": "Optimizing Health Coverage in Ethiopia: A Learning-augmented Approach and Persistent Proportionality Under an Online Budget", "comment": null, "summary": "As part of nationwide efforts aligned with the United Nations' Sustainable\nDevelopment Goal 3 on Universal Health Coverage, Ethiopia's Ministry of Health\nis strengthening health posts to expand access to essential healthcare\nservices. However, only a fraction of this health system strengthening effort\ncan be implemented each year due to limited budgets and other competing\npriorities, thus the need for an optimization framework to guide prioritization\nacross the regions of Ethiopia. In this paper, we develop a tool, Health Access\nResource Planner (HARP), based on a principled decision-support optimization\nframework for sequential facility planning that aims to maximize population\ncoverage under budget uncertainty while satisfying region-specific\nproportionality targets at every time step. We then propose two algorithms: (i)\na learning-augmented approach that improves upon expert recommendations at any\nsingle-step; and (ii) a greedy algorithm for multi-step planning, both with\nstrong worst-case approximation estimation. In collaboration with the Ethiopian\nPublic Health Institute and Ministry of Health, we demonstrated the empirical\nefficacy of our method on three regions across various planning scenarios.", "AI": {"tldr": "\u57fa\u4e8e\u4f18\u5316\u6846\u67b6\u7684\u5065\u5eb7\u8bbf\u95ee\u8d44\u6e90\u89c4\u5212\u5de5\u5177(HARP)\uff0c\u901a\u8fc7\u5b66\u4e60\u589e\u5f3a\u548c\u8d2a\u5fc3\u7b97\u6cd5\u5728\u9884\u7b97\u4e0d\u786e\u5b9a\u6027\u4e0b\u6700\u5927\u5316\u4eba\u53e3\u8986\u76d6\u7387\uff0c\u6ee1\u8db3\u533a\u57df\u6bd4\u4f8b\u5206\u914d\u76ee\u6807\u3002", "motivation": "\u57c3\u585e\u4fc4\u6bd4\u4e9a\u5728\u5b9e\u73b0\u8054\u5408\u56fd\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u68073\u7684\u8fc7\u7a0b\u4e2d\uff0c\u56e0\u9884\u7b97\u548c\u4f18\u5148\u7ea7\u7ade\u4e89\u800c\u65e0\u6cd5\u5b8c\u5168\u5f3a\u5316\u5065\u5eb7\u7f51\u70b9\uff0c\u9700\u8981\u4f18\u5316\u6846\u67b6\u6765\u6307\u5bfc\u533a\u57df\u95f4\u7684\u4f18\u5148\u7ea7\u5206\u914d\u3002", "method": "\u5f00\u53d1\u4e86HARP\u5de5\u5177\uff0c\u57fa\u4e8e\u539f\u5219\u6027\u7684\u51b3\u7b56\u652f\u6301\u4f18\u5316\u6846\u67b6\uff0c\u63d0\u51fa\u4e24\u79cd\u7b97\u6cd5\uff1a(1)\u5b66\u4e60\u589e\u5f3a\u65b9\u6cd5\u5728\u5355\u6b65\u4f18\u5316\u4e13\u5bb6\u5efa\u8bae\uff1b(2)\u8d2a\u5fc3\u7b97\u6cd5\u7528\u4e8e\u591a\u6b65\u89c4\u5212\uff0c\u4e24\u8005\u90fd\u5177\u6709\u5f3a\u7684\u6700\u5dee\u60c5\u51b5\u8fd1\u4f3c\u4f30\u8ba1\u3002", "result": "\u4e0e\u57c3\u585e\u4fc4\u6bd4\u4e9a\u516c\u5171\u5065\u5eb7\u7814\u7a76\u6240\u548c\u536b\u751f\u90e8\u5408\u4f5c\uff0c\u5728\u4e09\u4e2a\u533a\u57df\u7684\u591a\u79cd\u89c4\u5212\u573a\u666f\u4e0b\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u5b9e\u8df5\u6548\u679c\u3002", "conclusion": "HARP\u5de5\u5177\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5e8f\u5217\u8bbe\u65bd\u89c4\u5212\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u9884\u7b97\u4e0d\u786e\u5b9a\u6027\u4e0b\u6700\u5927\u5316\u4eba\u53e3\u5065\u5eb7\u670d\u52a1\u8986\u76d6\u7387\uff0c\u540c\u65f6\u4fdd\u8bc1\u533a\u57df\u95f4\u7684\u6bd4\u4f8b\u5206\u914d\u516c\u5e73\u6027\u3002"}}
{"id": "2509.00085", "categories": ["cs.CR", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.00085", "abs": "https://arxiv.org/abs/2509.00085", "authors": ["Tobin South"], "title": "Private, Verifiable, and Auditable AI Systems", "comment": "PhD thesis", "summary": "The growing societal reliance on artificial intelligence necessitates robust\nframeworks for ensuring its security, accountability, and trustworthiness. This\nthesis addresses the complex interplay between privacy, verifiability, and\nauditability in modern AI, particularly in foundation models. It argues that\ntechnical solutions that integrate these elements are critical for responsible\nAI innovation. Drawing from international policy contributions and technical\nresearch to identify key risks in the AI pipeline, this work introduces novel\ntechnical solutions for critical privacy and verifiability challenges.\nSpecifically, the research introduces techniques for enabling verifiable and\nauditable claims about AI systems using zero-knowledge cryptography; utilizing\nsecure multi-party computation and trusted execution environments for\nauditable, confidential deployment of large language models and information\nretrieval; and implementing enhanced delegation mechanisms, credentialing\nsystems, and access controls to secure interactions with autonomous and\nmulti-agent AI systems. Synthesizing these technical advancements, this\ndissertation presents a cohesive perspective on balancing privacy,\nverifiability, and auditability in foundation model-based AI systems, offering\npractical blueprints for system designers and informing policy discussions on\nAI safety and governance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u9690\u79c1\u4fdd\u62a4\u3001\u53ef\u9a8c\u8bc1\u6027\u548c\u53ef\u5ba1\u8ba1\u6027\u7684\u6280\u672f\u6846\u67b6\uff0c\u4f7f\u7528\u96f6\u77e5\u8bc6\u8bc1\u660e\u3001\u5b89\u5168\u591a\u65b9\u8ba1\u7b97\u548c\u53ef\u4fe1\u6267\u884c\u73af\u5883\u7b49\u6280\u672f\u6765\u89e3\u51b3AI\u7cfb\u7edf\u4e2d\u7684\u5b89\u5168\u6311\u6218\u3002", "motivation": "\u968f\u7740\u793e\u4f1a\u5bf9\u4eba\u5de5\u667a\u80fd\u7684\u4f9d\u8d56\u65e5\u76ca\u589e\u957f\uff0c\u9700\u8981\u786e\u4fddAI\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u3001\u95ee\u8d23\u5236\u548c\u53ef\u4fe1\u5ea6\uff0c\u7279\u522b\u662f\u5728\u57fa\u7840\u6a21\u578b\u4e2d\u7684\u9690\u79c1\u3001\u53ef\u9a8c\u8bc1\u6027\u548c\u53ef\u5ba1\u8ba1\u6027\u4e4b\u95f4\u7684\u590d\u6742\u5173\u7cfb\u3002", "method": "\u91c7\u7528\u96f6\u77e5\u8bc6\u5bc6\u7801\u5b66\u5b9e\u73b0AI\u7cfb\u7edf\u7684\u53ef\u9a8c\u8bc1\u58f0\u660e\uff0c\u5229\u7528\u5b89\u5168\u591a\u65b9\u8ba1\u7b97\u548c\u53ef\u4fe1\u6267\u884c\u73af\u5883\u8fdb\u884c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u5ba1\u8ba1\u673a\u5bc6\u90e8\u7f72\uff0c\u5e76\u901a\u8fc7\u589e\u5f3a\u7684\u59d4\u6258\u673a\u5236\u3001\u51ed\u8bc1\u7cfb\u7edf\u548c\u8bbf\u95ee\u63a7\u5236\u6765\u4fdd\u62a4\u81ea\u4e3b\u548c\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u7684\u4ea4\u4e92\u3002", "result": "\u5f00\u53d1\u4e86\u9488\u5bf9\u5173\u952e\u9690\u79c1\u548c\u53ef\u9a8c\u8bc1\u6027\u6311\u6218\u7684\u65b0\u6280\u672f\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u7cfb\u7edf\u8bbe\u8ba1\u8005\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u84dd\u56fe\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5e73\u8861\u9690\u79c1\u3001\u53ef\u9a8c\u8bc1\u6027\u548c\u53ef\u5ba1\u8ba1\u6027\u7684\u7edf\u4e00\u89c6\u89d2\uff0c\u4e3aAI\u5b89\u5168\u6cbb\u7406\u7684\u653f\u7b56\u8ba8\u8bba\u63d0\u4f9b\u4e86\u6280\u672f\u57fa\u7840\u3002"}}
{"id": "2509.01445", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.01445", "abs": "https://arxiv.org/abs/2509.01445", "authors": ["Muhammad Ovais Ahmad", "Tomas Gustavsson"], "title": "Non Technical Debt in Agile Software Development", "comment": null, "summary": "NonTechnical Debt (NTD) is a common challenge in agile software development,\nmanifesting in four critical forms, Process Debt, Social Debt, People Debt,\nOrganizational debt. NODLA project is a collaboration between Karlstad\nUniversity and four leading Swedish industrial partners, reveals how various\ndebt types disrupt large scale Agile Software Development (ASD) environments.\nThrough extensive surveys, indepth interviews, and statistical analyses\ninvolving a diverse group of software professionals, we identified key drivers\nof NTD and their impacts. Our findings emphasize (1) Well structured, highly\ncohesive teams learn faster, adapt more effectively, and innovate consistently.\n(2) Psychological safety, fostered by proactive leadership, is essential for\ninnovation, experimentation, and keeping employees. (3) Inefficient processes\nand unclear roles contribute significantly to drops in job satisfaction,\nproductivity and team morale. (4) Social fragmentation, particularly in remote\nand hybrid settings, breeds rework, delays, and increased costs. (5) Neglected\nhuman resource needs, such as delayed hiring or insufficient training, limit an\norganization ability to meet growing demands. This white paper distils these\ninsights into practical, evidence based strategies, such as refining team\ncomposition, clarifying roles, fostering psychological safety, streamlining\nworkflows, and embracing failure as a learning tool. By implementing these\nstrategies, organizations can reduce NTD, reclaim agility, and unlock their\nteams full potential.", "AI": {"tldr": "\u975e\u6280\u672f\u503a\u52a1(NTD)\u662f\u654f\u6377\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5e38\u89c1\u6311\u6218\uff0c\u5305\u62ec\u6d41\u7a0b\u503a\u52a1\u3001\u793e\u4f1a\u503a\u52a1\u3001\u4eba\u5458\u503a\u52a1\u548c\u7ec4\u7ec7\u503a\u52a1\u56db\u79cd\u5f62\u5f0f\u3002\u7814\u7a76\u53d1\u73b0\u7ed3\u6784\u5316\u56e2\u961f\u3001\u5fc3\u7406\u5b89\u5168\u3001\u6e05\u6670\u89d2\u8272\u548c\u6709\u6548\u6d41\u7a0b\u5bf9\u51cf\u5c11NTD\u81f3\u5173\u91cd\u8981\u3002", "motivation": "\u7814\u7a76\u975e\u6280\u672f\u503a\u52a1\u5728\u5927\u578b\u654f\u6377\u8f6f\u4ef6\u5f00\u53d1\u73af\u5883\u4e2d\u7684\u5f71\u54cd\uff0c\u63ed\u793a\u5404\u79cd\u503a\u52a1\u7c7b\u578b\u5982\u4f55\u7834\u574f\u5f00\u53d1\u6548\u7387\u548c\u7ec4\u7ec7\u6548\u80fd\uff0c\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u63d0\u4f9b\u5b9e\u8bc1\u4f9d\u636e\u3002", "method": "\u91c7\u7528\u5e7f\u6cdb\u7684\u95ee\u5377\u8c03\u67e5\u3001\u6df1\u5ea6\u8bbf\u8c08\u548c\u7edf\u8ba1\u5206\u6790\uff0c\u6d89\u53ca\u591a\u6837\u5316\u7684\u8f6f\u4ef6\u4e13\u4e1a\u4eba\u5458\u7fa4\u4f53\uff0c\u8bc6\u522bNTD\u7684\u5173\u952e\u9a71\u52a8\u56e0\u7d20\u53ca\u5176\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u4e94\u4e2a\u5173\u952e\u6d1e\u5bdf\uff1a\u7ed3\u6784\u5316\u56e2\u961f\u5b66\u4e60\u66f4\u5feb\uff1b\u5fc3\u7406\u5b89\u5168\u5bf9\u521b\u65b0\u81f3\u5173\u91cd\u8981\uff1b\u4f4e\u6548\u6d41\u7a0b\u964d\u4f4e\u6ee1\u610f\u5ea6\uff1b\u8fdc\u7a0b\u5de5\u4f5c\u5bfc\u81f4\u793e\u4f1a\u788e\u7247\u5316\uff1b\u4eba\u529b\u8d44\u6e90\u4e0d\u8db3\u9650\u5236\u7ec4\u7ec7\u80fd\u529b\u3002", "conclusion": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u8bc1\u636e\u7684\u5b9e\u7528\u7b56\u7565\uff0c\u5305\u62ec\u4f18\u5316\u56e2\u961f\u7ec4\u6210\u3001\u660e\u786e\u89d2\u8272\u3001\u57f9\u517b\u5fc3\u7406\u5b89\u5168\u3001\u7b80\u5316\u5de5\u4f5c\u6d41\u7a0b\u548c\u5c06\u5931\u8d25\u89c6\u4e3a\u5b66\u4e60\u5de5\u5177\uff0c\u5e2e\u52a9\u7ec4\u7ec7\u51cf\u5c11NTD\u5e76\u91ca\u653e\u56e2\u961f\u6f5c\u529b\u3002"}}
{"id": "2509.00184", "categories": ["cs.AI", "cs.LO", "cs.MA", "03B42", "I.2.4"], "pdf": "https://arxiv.org/pdf/2509.00184", "abs": "https://arxiv.org/abs/2509.00184", "authors": ["Alexandru Baltag", "Malvin Gattinger", "Djanira Gomes"], "title": "Virtual Group Knowledge and Group Belief in Topological Evidence Models (Extended Version)", "comment": null, "summary": "We study notions of (virtual) group knowledge and group belief within\nmulti-agent evidence models, obtained by extending the topological semantics of\nevidence-based belief and fallible knowledge from individuals to groups. We\ncompletely axiomatize and show the decidability of the logic of (\"hard\" and\n\"soft\") group evidence, and do the same for an especially interesting fragment\nof it: the logic of group knowledge and group belief. We also extend these\nlanguages with dynamic evidence-sharing operators, and completely axiomatize\nthe corresponding logics, showing that they are co-expressive with their static\nbases.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u591a\u667a\u80fd\u4f53\u8bc1\u636e\u6a21\u578b\u4e2d\u7684\u7fa4\u4f53\u77e5\u8bc6\u548c\u4fe1\u5ff5\u6982\u5ff5\uff0c\u901a\u8fc7\u5c06\u57fa\u4e8e\u8bc1\u636e\u7684\u4fe1\u5ff5\u548c\u53ef\u9519\u77e5\u8bc6\u4ece\u4e2a\u4f53\u6269\u5c55\u5230\u7fa4\u4f53\uff0c\u5efa\u7acb\u4e86\u5b8c\u6574\u7684\u903b\u8f91\u516c\u7406\u5316\u7cfb\u7edf\u5e76\u8bc1\u660e\u4e86\u53ef\u5224\u5b9a\u6027\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5c06\u4e2a\u4f53\u5c42\u9762\u7684\u8bc1\u636e\u57fa\u7840\u4fe1\u5ff5\u548c\u77e5\u8bc6\u6982\u5ff5\u6269\u5c55\u5230\u7fa4\u4f53\u5c42\u9762\uff0c\u63a2\u7d22\u7fa4\u4f53\u77e5\u8bc6\u548c\u4fe1\u5ff5\u7684\u5f62\u5f0f\u5316\u903b\u8f91\u6846\u67b6\u3002", "method": "\u91c7\u7528\u62d3\u6251\u8bed\u4e49\u5b66\u65b9\u6cd5\uff0c\u6269\u5c55\u4e2a\u4f53\u8bc1\u636e\u6a21\u578b\u5230\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5efa\u7acb\u7fa4\u4f53\u8bc1\u636e\u903b\u8f91\u7cfb\u7edf\uff0c\u5e76\u5f15\u5165\u52a8\u6001\u8bc1\u636e\u5171\u4eab\u7b97\u5b50\u3002", "result": "\u5b8c\u5168\u516c\u7406\u5316\u4e86\u7fa4\u4f53\u8bc1\u636e\u903b\u8f91\uff08\u5305\u62ec\u786c\u8bc1\u636e\u548c\u8f6f\u8bc1\u636e\uff09\uff0c\u8bc1\u660e\u4e86\u5176\u53ef\u5224\u5b9a\u6027\uff1b\u7279\u522b\u5bf9\u7fa4\u4f53\u77e5\u8bc6\u548c\u4fe1\u5ff5\u7247\u6bb5\u8fdb\u884c\u4e86\u5b8c\u6574\u516c\u7406\u5316\uff1b\u6269\u5c55\u7684\u52a8\u6001\u8bc1\u636e\u5171\u4eab\u903b\u8f91\u4e0e\u9759\u6001\u57fa\u7840\u5177\u6709\u540c\u7b49\u8868\u8fbe\u80fd\u529b\u3002", "conclusion": "\u6210\u529f\u5efa\u7acb\u4e86\u7fa4\u4f53\u8bc1\u636e\u3001\u77e5\u8bc6\u548c\u4fe1\u5ff5\u7684\u5b8c\u6574\u903b\u8f91\u6846\u67b6\uff0c\u8bc1\u660e\u4e86\u76f8\u5173\u903b\u8f91\u7cfb\u7edf\u7684\u53ef\u5224\u5b9a\u6027\u548c\u8868\u8fbe\u80fd\u529b\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u7fa4\u4f53\u8ba4\u77e5\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u57fa\u7840\u3002"}}
{"id": "2509.00088", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.00088", "abs": "https://arxiv.org/abs/2509.00088", "authors": ["Ting-Chun Liu", "Ching-Yu Hsu", "Kuan-Yi Lee", "Chi-An Fu", "Hung-yi Lee"], "title": "AEGIS : Automated Co-Evolutionary Framework for Guarding Prompt Injections Schema", "comment": null, "summary": "Prompt injection attacks pose a significant challenge to the safe deployment\nof Large Language Models (LLMs) in real-world applications. While prompt-based\ndetection offers a lightweight and interpretable defense strategy, its\neffectiveness has been hindered by the need for manual prompt engineering. To\naddress this issue, we propose AEGIS , an Automated co-Evolutionary framework\nfor Guarding prompt Injections Schema. Both attack and defense prompts are\niteratively optimized against each other using a gradient-like natural language\nprompt optimization technique. This framework enables both attackers and\ndefenders to autonomously evolve via a Textual Gradient Optimization (TGO)\nmodule, leveraging feedback from an LLM-guided evaluation loop. We evaluate our\nsystem on a real-world assignment grading dataset of prompt injection attacks\nand demonstrate that our method consistently outperforms existing baselines,\nachieving superior robustness in both attack success and detection.\nSpecifically, the attack success rate (ASR) reaches 1.0, representing an\nimprovement of 0.26 over the baseline. For detection, the true positive rate\n(TPR) improves by 0.23 compared to the previous best work, reaching 0.84, and\nthe true negative rate (TNR) remains comparable at 0.89. Ablation studies\nconfirm the importance of co-evolution, gradient buffering, and multi-objective\noptimization. We also confirm that this framework is effective in different\nLLMs. Our results highlight the promise of adversarial training as a scalable\nand effective approach for guarding prompt injections.", "AI": {"tldr": "\u63d0\u51fa\u4e86AEGIS\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6297\u6027\u8bad\u7ec3\u81ea\u52a8\u8fdb\u5316\u653b\u51fb\u548c\u9632\u5fa1\u63d0\u793a\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u7684\u6210\u529f\u7387\u548c\u68c0\u6d4b\u6548\u679c\u3002", "motivation": "\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u5bf9LLM\u5b89\u5168\u90e8\u7f72\u6784\u6210\u91cd\u5927\u6311\u6218\uff0c\u73b0\u6709\u57fa\u4e8e\u63d0\u793a\u7684\u68c0\u6d4b\u65b9\u6cd5\u9700\u8981\u624b\u52a8\u5de5\u7a0b\uff0c\u6548\u679c\u6709\u9650\u3002", "method": "\u91c7\u7528\u81ea\u52a8\u534f\u540c\u8fdb\u5316\u6846\u67b6\uff0c\u4f7f\u7528\u57fa\u4e8e\u68af\u5ea6\u7684\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u4f18\u5316\u6280\u672f\uff0c\u8ba9\u653b\u51fb\u548c\u9632\u5fa1\u63d0\u793a\u76f8\u4e92\u8fed\u4ee3\u4f18\u5316\u3002", "result": "\u653b\u51fb\u6210\u529f\u7387\u63d0\u53470.26\u8fbe\u52301.0\uff0c\u68c0\u6d4b\u771f\u9633\u6027\u7387\u63d0\u53470.23\u8fbe\u52300.84\uff0c\u771f\u9634\u6027\u7387\u4fdd\u63010.89\uff0c\u5728\u4e0d\u540cLLM\u4e2d\u5747\u6709\u6548\u3002", "conclusion": "\u5bf9\u6297\u6027\u8bad\u7ec3\u662f\u9632\u5fa1\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u7684\u53ef\u6269\u5c55\u6709\u6548\u65b9\u6cd5\uff0c\u534f\u540c\u8fdb\u5316\u3001\u68af\u5ea6\u7f13\u51b2\u548c\u591a\u76ee\u6807\u4f18\u5316\u662f\u5173\u952e\u8981\u7d20\u3002"}}
{"id": "2509.01494", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.01494", "abs": "https://arxiv.org/abs/2509.01494", "authors": ["Zhengran Zeng", "Ruikai Shi", "Keke Han", "Yixin Li", "Kaicheng Sun", "Yidong Wang", "Zhuohao Yu", "Rui Xie", "Wei Ye", "Shikun Zhang"], "title": "Benchmarking and Studying the LLM-based Code Review", "comment": null, "summary": "Automated Code Review (ACR) is crucial for software quality, yet existing\nbenchmarks often fail to reflect real-world complexities, hindering the\nevaluation of modern Large Language Models (LLMs). Current benchmarks\nfrequently focus on fine-grained code units, lack complete project context, and\nuse inadequate evaluation metrics. To address these limitations, we introduce\nSWRBench , a new benchmark comprising 1000 manually verified Pull Requests\n(PRs) from GitHub, offering PR-centric review with full project context.\nSWRBench employs an objective LLM-based evaluation method that aligns strongly\nwith human judgment (~90 agreement) by verifying if issues from a structured\nground truth are covered in generated reviews. Our systematic evaluation of\nmainstream ACR tools and LLMs on SWRBench reveals that current systems\nunderperform, and ACR tools are more adept at detecting functional errors.\nSubsequently, we propose and validate a simple multi-review aggregation\nstrategy that significantly boosts ACR performance, increasing F1 scores by up\nto 43.67%. Our contributions include the SWRBench benchmark, its objective\nevaluation method, a comprehensive study of current ACR capabilities, and an\neffective enhancement approach, offering valuable insights for advancing ACR\nresearch.", "AI": {"tldr": "\u63d0\u51fa\u4e86SWRBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b1000\u4e2a\u624b\u52a8\u9a8c\u8bc1\u7684GitHub Pull Requests\uff0c\u91c7\u7528\u57fa\u4e8eLLM\u7684\u5ba2\u89c2\u8bc4\u4f30\u65b9\u6cd5\uff0c\u53d1\u73b0\u5f53\u524dACR\u5de5\u5177\u5728\u529f\u80fd\u9519\u8bef\u68c0\u6d4b\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u5e76\u63d0\u51fa\u591a\u8bc4\u5ba1\u805a\u5408\u7b56\u7565\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u4ee3\u7801\u8bc4\u5ba1\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u53cd\u6620\u771f\u5b9e\u4e16\u754c\u590d\u6742\u6027\uff0c\u7f3a\u4e4f\u5b8c\u6574\u9879\u76ee\u4e0a\u4e0b\u6587\uff0c\u8bc4\u4f30\u6307\u6807\u4e0d\u8db3\uff0c\u963b\u788d\u4e86\u73b0\u4ee3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bc4\u4f30\u3002", "method": "\u5f15\u5165SWRBench\u57fa\u51c6\uff0c\u5305\u542b1000\u4e2a\u624b\u52a8\u9a8c\u8bc1\u7684PR\uff0c\u63d0\u4f9b\u5b8c\u6574\u7684\u9879\u76ee\u4e0a\u4e0b\u6587\u3002\u91c7\u7528\u57fa\u4e8eLLM\u7684\u5ba2\u89c2\u8bc4\u4f30\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u7ed3\u6784\u5316\u771f\u5b9e\u95ee\u9898\u662f\u5426\u5728\u751f\u6210\u7684\u8bc4\u5ba1\u4e2d\u88ab\u8986\u76d6\u3002", "result": "\u5f53\u524dACR\u7cfb\u7edf\u8868\u73b0\u4e0d\u4f73\uff0cACR\u5de5\u5177\u66f4\u64c5\u957f\u68c0\u6d4b\u529f\u80fd\u9519\u8bef\u3002\u63d0\u51fa\u7684\u591a\u8bc4\u5ba1\u805a\u5408\u7b56\u7565\u5c06F1\u5206\u6570\u63d0\u5347\u9ad8\u8fbe43.67%\u3002", "conclusion": "SWRBench\u57fa\u51c6\u3001\u5ba2\u89c2\u8bc4\u4f30\u65b9\u6cd5\u3001\u5f53\u524dACR\u80fd\u529b\u5168\u9762\u7814\u7a76\u4ee5\u53ca\u6709\u6548\u589e\u5f3a\u65b9\u6cd5\uff0c\u4e3a\u63a8\u8fdbACR\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9d\u8d35\u89c1\u89e3\u3002"}}
{"id": "2509.00189", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.00189", "abs": "https://arxiv.org/abs/2509.00189", "authors": ["Jinzhou Tang", "Jusheng Zhang", "Qinhan Lv", "Sidi Liu", "Jing Yang", "Chengpei Tang", "Keze Wang"], "title": "HiVA: Self-organized Hierarchical Variable Agent via Goal-driven Semantic-Topological Evolution", "comment": null, "summary": "Autonomous agents play a crucial role in advancing Artificial General\nIntelligence, enabling problem decomposition and tool orchestration through\nLarge Language Models (LLMs). However, existing paradigms face a critical\ntrade-off. On one hand, reusable fixed workflows require manual reconfiguration\nupon environmental changes; on the other hand, flexible reactive loops fail to\ndistill reasoning progress into transferable structures. We introduce\nHierarchical Variable Agent (HiVA), a novel framework modeling agentic\nworkflows as self-organized graphs with the Semantic-Topological Evolution\n(STEV) algorithm, which optimizes hybrid semantic-topological spaces using\ntextual gradients as discrete-domain surrogates for backpropagation. The\niterative process comprises Multi-Armed Bandit-infused forward routing,\ndiagnostic gradient generation from environmental feedback, and coordinated\nupdates that co-evolve individual semantics and topology for collective\noptimization in unknown environments. Experiments on dialogue, coding,\nLong-context Q&A, mathematical, and agentic benchmarks demonstrate improvements\nof 5-10% in task accuracy and enhanced resource efficiency over existing\nbaselines, establishing HiVA's effectiveness in autonomous task execution.", "AI": {"tldr": "HiVA\u662f\u4e00\u4e2a\u65b0\u578b\u81ea\u4e3b\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49-\u62d3\u6251\u6f14\u5316\u7b97\u6cd5\u5c06\u5de5\u4f5c\u6d41\u5efa\u6a21\u4e3a\u81ea\u7ec4\u7ec7\u56fe\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u56fa\u5b9a\u5de5\u4f5c\u6d41\u548c\u7075\u6d3b\u53cd\u5e94\u5faa\u73af\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e865-10%\u7684\u51c6\u786e\u7387\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u81ea\u4e3b\u4ee3\u7406\u8303\u5f0f\u9762\u4e34\u5173\u952e\u6743\u8861\uff1a\u53ef\u91cd\u7528\u7684\u56fa\u5b9a\u5de5\u4f5c\u6d41\u9700\u8981\u624b\u52a8\u91cd\u65b0\u914d\u7f6e\uff0c\u800c\u7075\u6d3b\u7684\u54cd\u5e94\u5faa\u73af\u65e0\u6cd5\u5c06\u63a8\u7406\u8fdb\u5c55\u63d0\u70bc\u4e3a\u53ef\u8f6c\u79fb\u7ed3\u6784\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u9002\u5e94\u73af\u5883\u53d8\u5316\u53c8\u80fd\u4fdd\u6301\u7ed3\u6784\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u53d8\u91cf\u4ee3\u7406(HiVA)\u6846\u67b6\uff0c\u4f7f\u7528\u8bed\u4e49-\u62d3\u6251\u6f14\u5316(STEV)\u7b97\u6cd5\u5c06\u4ee3\u7406\u5de5\u4f5c\u6d41\u5efa\u6a21\u4e3a\u81ea\u7ec4\u7ec7\u56fe\u3002\u8be5\u7b97\u6cd5\u5229\u7528\u6587\u672c\u68af\u5ea6\u4f5c\u4e3a\u79bb\u6563\u57df\u7684\u53cd\u5411\u4f20\u64ad\u66ff\u4ee3\uff0c\u901a\u8fc7\u591a\u81c2\u8001\u864e\u673a\u524d\u5411\u8def\u7531\u3001\u73af\u5883\u53cd\u9988\u751f\u6210\u8bca\u65ad\u68af\u5ea6\u4ee5\u53ca\u534f\u8c03\u66f4\u65b0\u6765\u5171\u540c\u4f18\u5316\u8bed\u4e49\u548c\u62d3\u6251\u3002", "result": "\u5728\u5bf9\u8bdd\u3001\u7f16\u7801\u3001\u957f\u4e0a\u4e0b\u6587\u95ee\u7b54\u3001\u6570\u5b66\u548c\u4ee3\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cHiVA\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u5b9e\u73b0\u4e865-10%\u7684\u4efb\u52a1\u51c6\u786e\u7387\u63d0\u5347\uff0c\u5e76\u5c55\u73b0\u51fa\u66f4\u597d\u7684\u8d44\u6e90\u6548\u7387\u3002", "conclusion": "HiVA\u6846\u67b6\u901a\u8fc7\u81ea\u7ec4\u7ec7\u56fe\u5efa\u6a21\u548c\u8bed\u4e49-\u62d3\u6251\u534f\u540c\u6f14\u5316\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u81ea\u4e3b\u4ee3\u7406\u5728\u672a\u77e5\u73af\u5883\u4e2d\u7684\u4efb\u52a1\u6267\u884c\u95ee\u9898\uff0c\u4e3a\u4eba\u5de5\u901a\u7528\u667a\u80fd\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u7684\u6280\u672f\u8def\u5f84\u3002"}}
{"id": "2509.00104", "categories": ["cs.CR", "cs.IT", "math.IT", "quant-ph", "94A60, 81P94, 94A17, 68Q12", "E.3; K.6.5; F.1.2; F.2.1"], "pdf": "https://arxiv.org/pdf/2509.00104", "abs": "https://arxiv.org/abs/2509.00104", "authors": ["Ruopengyu Xu", "Chenglian Liu"], "title": "Enhanced R\u00e9nyi Entropy-Based Post-Quantum Key Agreement with Provable Security and Information-Theoretic Guarantees", "comment": "11 pages, 3 tables", "summary": "This paper presents an enhanced post-quantum key agreement protocol based on\nR\\'{e}nyi entropy, addressing vulnerabilities in the original construction\nwhile preserving information-theoretic security properties. We develop a\ntheoretical framework leveraging entropy-preserving operations and\nsecret-shared verification to achieve provable security against quantum\nadversaries. Through entropy amplification techniques and quantum-resistant\ncommitments, the protocol establishes $2^{128}$ quantum security guarantees\nunder the quantum random oracle model. Key innovations include a\nconfidentiality-preserving verification mechanism using distributed polynomial\ncommitments, tightened min-entropy bounds with guaranteed non-negativity, and\ncomposable security proofs in the quantum universal composability framework.\nUnlike computational approaches, our method provides information-theoretic\nsecurity without hardness assumptions while maintaining polynomial complexity.\nTheoretical analysis demonstrates resilience against known quantum attack\nvectors, including Grover-accelerated brute force and quantum memory attacks.\nThe protocol achieves parameterization for 128-bit quantum security with\nefficient $\\mathcal{O}(n^2)$ communication complexity. Extensions to secure\nmultiparty computation and quantum network applications are established,\nproviding a foundation for long-term cryptographic security. All security\nclaims are derived from mathematical proofs; this theoretical work presents no\nexperimental validation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eR\u00e9nyi\u71b5\u7684\u589e\u5f3a\u578b\u540e\u91cf\u5b50\u5bc6\u94a5\u534f\u5546\u534f\u8bae\uff0c\u901a\u8fc7\u71b5\u4fdd\u6301\u64cd\u4f5c\u548c\u79d8\u5bc6\u5171\u4eab\u9a8c\u8bc1\u5b9e\u73b0\u53ef\u8bc1\u660e\u7684\u91cf\u5b50\u5b89\u5168\u6027\uff0c\u8fbe\u52302^128\u91cf\u5b50\u5b89\u5168\u4fdd\u8bc1\u3002", "motivation": "\u539f\u59cb\u6784\u9020\u5b58\u5728\u6f0f\u6d1e\uff0c\u9700\u8981\u5f00\u53d1\u4fe1\u606f\u8bba\u5b89\u5168\u7684\u91cf\u5b50\u62b5\u6297\u534f\u8bae\uff0c\u4ee5\u5e94\u5bf9\u91cf\u5b50\u8ba1\u7b97\u5e26\u6765\u7684\u5b89\u5168\u5a01\u80c1\u3002", "method": "\u5229\u7528\u71b5\u4fdd\u6301\u64cd\u4f5c\u548c\u79d8\u5bc6\u5171\u4eab\u9a8c\u8bc1\u6784\u5efa\u7406\u8bba\u6846\u67b6\uff0c\u91c7\u7528\u71b5\u653e\u5927\u6280\u672f\u548c\u91cf\u5b50\u62b5\u6297\u627f\u8bfa\uff0c\u4f7f\u7528\u5206\u5e03\u5f0f\u591a\u9879\u5f0f\u627f\u8bfa\u673a\u5236\u8fdb\u884c\u4fdd\u5bc6\u9a8c\u8bc1\u3002", "result": "\u534f\u8bae\u5728\u91cf\u5b50\u968f\u673a\u9884\u8a00\u673a\u6a21\u578b\u4e0b\u8fbe\u52302^128\u91cf\u5b50\u5b89\u5168\u4fdd\u8bc1\uff0c\u5177\u6709O(n^2)\u901a\u4fe1\u590d\u6742\u5ea6\uff0c\u80fd\u591f\u62b5\u6297\u5df2\u77e5\u91cf\u5b50\u653b\u51fb\u5411\u91cf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u65e0\u9700\u786c\u5ea6\u5047\u8bbe\u7684\u4fe1\u606f\u8bba\u5b89\u5168\u6027\uff0c\u4e3a\u957f\u671f\u5bc6\u7801\u5b89\u5168\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u53ef\u6269\u5c55\u5230\u5b89\u5168\u591a\u65b9\u8ba1\u7b97\u548c\u91cf\u5b50\u7f51\u7edc\u5e94\u7528\u3002"}}
{"id": "2509.01527", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.01527", "abs": "https://arxiv.org/abs/2509.01527", "authors": ["Amirreza Nayyeri", "Abbas Rasoolzadegan"], "title": "A Privacy-Preserving Recommender for Filling Web Forms Using a Local Large Language Model", "comment": null, "summary": "Web applications are increasingly used in critical domains such as education,\nfinance, and e-commerce. This highlights the need to ensure their failure-free\nperformance. One effective method for evaluating failure-free performance is\nweb form testing, where defining effective test scenarios is key to a complete\nand accurate evaluation. A core aspect of this process involves filling form\nfields with suitable values to create effective test cases. However, manually\ngenerating these values is time-consuming and prone to errors. To address this,\nvarious tools have been developed to assist testers. With the appearance of\nlarge language models (LLMs), a new generation of tools seeks to handle this\ntask more intelligently. Although many LLM-based tools have been introduced, as\nthese models typically rely on cloud infrastructure, their use in testing\nconfidential web forms raises concerns about unintended data leakage and\nbreaches of confidentiality. This paper introduces a privacy-preserving\nrecommender that operates locally using a large language model. The tool\nassists testers in web form testing by suggesting effective field values. This\ntool analyzes the HTML structure of forms, detects input types, and extracts\nconstraints based on each field's type and contextual content, guiding proper\nfield filling.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9690\u79c1\u4fdd\u62a4\u63a8\u8350\u5668\uff0c\u7528\u4e8e\u672c\u5730\u5316\u751f\u6210\u7f51\u9875\u8868\u5355\u6d4b\u8bd5\u7684\u6709\u6548\u5b57\u6bb5\u503c\uff0c\u907f\u514d\u4e91\u7aefLLM\u5e26\u6765\u7684\u6570\u636e\u6cc4\u6f0f\u98ce\u9669\u3002", "motivation": "\u7f51\u7edc\u5e94\u7528\u5728\u91cd\u8981\u9886\u57df\u7684\u666e\u53ca\u5bfc\u81f4\u5bf9\u6545\u969c\u81ea\u7531\u6027\u80fd\u7684\u9ad8\u8981\u6c42\u3002\u867d\u7136LLM\u5de5\u5177\u80fd\u667a\u80fd\u751f\u6210\u8868\u5355\u6d4b\u8bd5\u503c\uff0c\u4f46\u4e91\u7aef\u90e8\u7f72\u53ef\u80fd\u5bfc\u81f4\u654f\u611f\u6570\u636e\u6cc4\u6f0f\u548c\u4fdd\u5bc6\u6027\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u672c\u5730\u8fd0\u884c\u7684\u9690\u79c1\u4fdd\u62a4\u63a8\u8350\u5668\uff0c\u901a\u8fc7\u5206\u6790\u8868\u5355HTML\u7ed3\u6784\u3001\u68c0\u6d4b\u8f93\u5165\u7c7b\u578b\u5e76\u63d0\u53d6\u5b57\u6bb5\u7ea6\u675f\u6765\u751f\u6210\u9002\u5f53\u7684\u586b\u5199\u503c\u3002", "result": "\u8be5\u5de5\u5177\u80fd\u591f\u5728\u4e0d\u4f9d\u8d56\u4e91\u7aef\u670d\u52a1\u7684\u60c5\u51b5\u4e0b\uff0c\u4e3a\u6d4b\u8bd5\u4eba\u5458\u63d0\u4f9b\u6709\u6548\u7684\u8868\u5355\u5b57\u6bb5\u586b\u5199\u5efa\u8bae\uff0c\u786e\u4fdd\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u7684\u6570\u636e\u5b89\u5168\u6027\u3002", "conclusion": "\u901a\u8fc7\u672c\u5730\u5316\u90e8\u7f72LLM\u6a21\u578b\uff0c\u65b9\u6848\u6709\u6548\u89e3\u51b3\u4e86\u4fdd\u5bc6\u6027\u7f51\u9875\u8868\u5355\u6d4b\u8bd5\u4e2d\u7684\u6570\u636e\u6cc4\u6f0f\u98ce\u9669\uff0c\u4e3a\u5b89\u5168\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u6280\u672f\u652f\u6301\u3002"}}
{"id": "2509.00244", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00244", "abs": "https://arxiv.org/abs/2509.00244", "authors": ["Peter Belcak", "Pavlo Molchanov"], "title": "Universal Deep Research: Bring Your Own Model and Strategy", "comment": null, "summary": "Deep research tools are among the most impactful and most commonly\nencountered agentic systems today. We observe, however, that each deep research\nagent introduced so far is hard-coded to carry out a particular research\nstrategy using a fixed choice of tools. We introduce Universal Deep Research\n(UDR), a generalist agentic system that wraps around any language model and\nenables the user to create, edit, and refine their own entirely custom deep\nresearch strategies without any need for additional training or finetuning. To\nshowcase the generality of our system, we equip UDR with example minimal,\nexpansive, and intensive research strategies, and provide a user interface to\nfacilitate experimentation with the system.", "AI": {"tldr": "\u63d0\u51fa\u4e86Universal Deep Research (UDR)\u7cfb\u7edf\uff0c\u8fd9\u662f\u4e00\u4e2a\u901a\u7528\u7684\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u7cfb\u7edf\uff0c\u5141\u8bb8\u7528\u6237\u521b\u5efa\u3001\u7f16\u8f91\u548c\u7cbe\u70bc\u81ea\u5b9a\u4e49\u7684\u7814\u7a76\u7b56\u7565\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6216\u5fae\u8c03\u3002", "motivation": "\u73b0\u6709\u7684\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u7cfb\u7edf\u90fd\u662f\u786c\u7f16\u7801\u7684\uff0c\u4f7f\u7528\u56fa\u5b9a\u7684\u7814\u7a76\u7b56\u7565\u548c\u5de5\u5177\u9009\u62e9\uff0c\u7f3a\u4e4f\u7075\u6d3b\u6027\u548c\u53ef\u5b9a\u5236\u6027\u3002", "method": "\u5f00\u53d1\u4e86UDR\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u53ef\u4ee5\u5305\u88c5\u4efb\u4f55\u8bed\u8a00\u6a21\u578b\uff0c\u63d0\u4f9b\u7528\u6237\u754c\u9762\u6765\u521b\u5efa\u548c\u5b9e\u9a8c\u4e0d\u540c\u7684\u7814\u7a76\u7b56\u7565\uff08\u6700\u5c0f\u5316\u3001\u6269\u5c55\u6027\u548c\u5bc6\u96c6\u578b\uff09\u3002", "result": "UDR\u7cfb\u7edf\u5c55\u793a\u4e86\u5176\u901a\u7528\u6027\uff0c\u80fd\u591f\u652f\u6301\u591a\u79cd\u7814\u7a76\u7b56\u7565\uff0c\u4e3a\u7528\u6237\u63d0\u4f9b\u4e86\u7075\u6d3b\u7684\u7814\u7a76\u5de5\u5177\u5b9a\u5236\u80fd\u529b\u3002", "conclusion": "UDR\u7cfb\u7edf\u4e3a\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u63d0\u4f9b\u4e86\u66f4\u9ad8\u7684\u7075\u6d3b\u6027\u548c\u53ef\u5b9a\u5236\u6027\uff0c\u4f7f\u7528\u6237\u80fd\u591f\u6839\u636e\u81ea\u5df1\u7684\u9700\u6c42\u8bbe\u8ba1\u548c\u4f18\u5316\u7814\u7a76\u7b56\u7565\u3002"}}
{"id": "2509.00124", "categories": ["cs.CR", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.00124", "abs": "https://arxiv.org/abs/2509.00124", "authors": ["Shaked Zychlinski"], "title": "A Whole New World: Creating a Parallel-Poisoned Web Only AI-Agents Can See", "comment": "10 pages, 1 figure", "summary": "This paper introduces a novel attack vector that leverages website cloaking\ntechniques to compromise autonomous web-browsing agents powered by Large\nLanguage Models (LLMs). As these agents become more prevalent, their unique and\noften homogenous digital fingerprints - comprising browser attributes,\nautomation framework signatures, and network characteristics - create a new,\ndistinguishable class of web traffic. The attack exploits this\nfingerprintability. A malicious website can identify an incoming request as\noriginating from an AI agent and dynamically serve a different, \"cloaked\"\nversion of its content. While human users see a benign webpage, the agent is\npresented with a visually identical page embedded with hidden, malicious\ninstructions, such as indirect prompt injections. This mechanism allows\nadversaries to hijack agent behavior, leading to data exfiltration, malware\nexecution, or misinformation propagation, all while remaining completely\ninvisible to human users and conventional security crawlers. This work\nformalizes the threat model, details the mechanics of agent fingerprinting and\ncloaking, and discusses the profound security implications for the future of\nagentic AI, highlighting the urgent need for robust defenses against this\nstealthy and scalable attack.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u7f51\u7ad9\u9690\u85cf\u6280\u672f\u653b\u51fbAI\u81ea\u4e3b\u6d4f\u89c8\u52a9\u624b\u7684\u65b0\u65b9\u5f0f\uff0c\u901a\u8fc7\u8bc6\u522bAI\u52a9\u624b\u7684\u6570\u5b57\u6307\u7eb9\u5e76\u5411\u5176\u63d0\u4f9b\u6076\u610f\u5185\u5bb9\uff0c\u800c\u666e\u901a\u7528\u6237\u5219\u770b\u5230\u65e0\u5bb3\u9875\u9762\u3002", "motivation": "\u968f\u7740\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u4e3b\u6d4f\u89c8\u52a9\u624b\u65e5\u76ca\u666e\u53ca\uff0c\u5b83\u4eec\u5177\u6709\u7279\u5b9a\u7684\u6570\u5b57\u6307\u7eb9\uff0c\u8fd9\u4e3a\u653b\u51fb\u8005\u63d0\u4f9b\u4e86\u5229\u7528\u9690\u85cf\u653b\u51fb\u7684\u65b0\u673a\u4f1a\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6d4f\u89c8\u5668\u5c5e\u6027\u3001\u81ea\u52a8\u5316\u6846\u67b6\u7b7e\u540d\u548c\u7f51\u7edc\u7279\u5f81\u6765\u8bc6\u522bAI\u52a9\u624b\u8bf7\u6c42\uff0c\u7136\u540e\u52a8\u6001\u63d0\u4f9b\u5916\u89c2\u76f8\u540c\u4f46\u5d4c\u5165\u6076\u610f\u6307\u4ee4\u7684\u9690\u85cf\u9875\u9762\u3002", "result": "\u653b\u51fb\u8005\u53ef\u4ee5\u63a7\u5236AI\u52a9\u624b\u884c\u4e3a\uff0c\u5bfc\u81f4\u6570\u636e\u6cc4\u6f0f\u3001\u6076\u610f\u8f6f\u4ef6\u6267\u884c\u6216\u9519\u8bef\u4fe1\u606f\u4f20\u64ad\uff0c\u800c\u8fd9\u4e9b\u653b\u51fb\u5bf9\u4eba\u7c7b\u7528\u6237\u548c\u4f20\u7edf\u5b89\u5168\u722c\u866b\u4e0d\u53ef\u89c1\u3002", "conclusion": "\u8fd9\u79cd\u9690\u85cf\u6027\u9ad8\u3001\u53ef\u6269\u5c55\u7684\u653b\u51fb\u5bf9AI\u52a8\u529b\u7cfb\u7edf\u7684\u5b89\u5168\u6784\u6210\u4e86\u4e25\u91cd\u5a01\u80c1\uff0c\u5f3a\u8c03\u4e86\u5f00\u53d1\u7a81\u7834\u6027\u9632\u5fa1\u63aa\u65bd\u7684\u7d27\u8feb\u6027\u3002"}}
{"id": "2509.01612", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.01612", "abs": "https://arxiv.org/abs/2509.01612", "authors": ["Omur Sahin", "Man Zhang", "Andrea Arcuri"], "title": "WFC/WFD: Web Fuzzing Commons, Dataset and Guidelines to Support Experimentation in REST API Fuzzing", "comment": null, "summary": "Fuzzing REST APIs is an important research problem, with practical\napplications and impact in industry. As such, a lot of research work has been\ncarried out on this topic in the last few years. However, there are three major\nissues that hinder further progress: how to deal with API authentication; how\nto catalog and compare different fault types found by different fuzzers; and\nwhat to use as case study to facilitate fair comparisons among fuzzers. To\naddress these important challenges, we present Web Fuzzing Commons (WFC) and\nWeb Fuzzing Dataset (WFD). WFC is a set of open-source libraries and schema\ndefinitions to declaratively specify authentication info and catalog different\ntypes of faults that fuzzers can automatically detect. WFD is a collection of\n36 open-source APIs with all necessary scaffolding to easily run experiments\nwith fuzzers, supported by WFC. To show the usefulness of WFC/WFD, a set of\nexperiments is carried out with EvoMaster, a state-of-the-art fuzzer for Web\nAPIs. However, any fuzzer can benefit from WFC and WFD. We compare EvoMaster\nwith other state-of-the-art tools such as ARAT-RL, EmRest, LLamaRestTest,\nRESTler, and Schemathesis. We discuss common pitfalls in tool comparisons, as\nwell as providing guidelines with support of WFC/WFD to avoid them.", "AI": {"tldr": "\u63d0\u51fa\u4e86Web Fuzzing Commons (WFC)\u548cWeb Fuzzing Dataset (WFD)\u6765\u89e3\u51b3REST API\u6a21\u7cca\u6d4b\u8bd5\u4e2d\u7684\u4e09\u4e2a\u5173\u952e\u6311\u6218\uff1a\u8ba4\u8bc1\u5904\u7406\u3001\u6545\u969c\u5206\u7c7b\u548c\u516c\u5e73\u6bd4\u8f83\u57fa\u51c6\u3002", "motivation": "\u5f53\u524dREST API\u6a21\u7cca\u6d4b\u8bd5\u7814\u7a76\u9762\u4e34\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a\u5982\u4f55\u5904\u7406API\u8ba4\u8bc1\u3001\u5982\u4f55\u5206\u7c7b\u548c\u6bd4\u8f83\u4e0d\u540c\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u53d1\u73b0\u7684\u6545\u969c\u7c7b\u578b\u3001\u4ee5\u53ca\u5982\u4f55\u5efa\u7acb\u516c\u5e73\u7684\u6bd4\u8f83\u57fa\u51c6\u3002\u8fd9\u4e9b\u95ee\u9898\u963b\u788d\u4e86\u8be5\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002", "method": "\u5f00\u53d1\u4e86WFC\uff08\u5f00\u6e90\u5e93\u548c\u6a21\u5f0f\u5b9a\u4e49\uff09\u7528\u4e8e\u58f0\u660e\u5f0f\u6307\u5b9a\u8ba4\u8bc1\u4fe1\u606f\u548c\u5206\u7c7b\u6545\u969c\u7c7b\u578b\uff0c\u4ee5\u53caWFD\uff08\u5305\u542b36\u4e2a\u5f00\u6e90API\u7684\u6570\u636e\u96c6\uff09\u7528\u4e8e\u652f\u6301\u5b9e\u9a8c\u3002\u901a\u8fc7EvoMaster\u7b49\u5de5\u5177\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "WFC/WFD\u4e3aAPI\u6a21\u7cca\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u6846\u67b6\u548c\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u80fd\u591f\u652f\u6301\u4e0d\u540c\u5de5\u5177\u4e4b\u95f4\u7684\u516c\u5e73\u6bd4\u8f83\uff0c\u5e76\u907f\u514d\u4e86\u5e38\u89c1\u7684\u6bd4\u8f83\u9677\u9631\u3002", "conclusion": "WFC\u548cWFD\u89e3\u51b3\u4e86REST API\u6a21\u7cca\u6d4b\u8bd5\u9886\u57df\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u8ba4\u8bc1\u5904\u7406\u3001\u6545\u969c\u5206\u7c7b\u548c\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u8be5\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2509.00251", "categories": ["cs.AI", "I.2.7; I.2.6; I.2.11"], "pdf": "https://arxiv.org/pdf/2509.00251", "abs": "https://arxiv.org/abs/2509.00251", "authors": ["Rimom Costa"], "title": "Instruction-Level Weight Shaping: A Framework for Self-Improving AI Agents", "comment": "12 pages, 1 figure, 2 tables", "summary": "Large language models (LLMs) are fluent but largely static after\npre-training; new or shifting knowledge is typically added with\nretrieval-augmented generation (RAG) or fine-tuning. RAG raises latency and\nengineering overhead and often fails to integrate facts; prompt engineering is\nbrittle and can conflict with prior knowledge; fine-tuning is costly and risks\ncatastrophic forgetting. We propose Instruction-Level Weight Shaping (ILWS):\ncurated system instructions act as external, auditable pseudo-parameters\nupdated after each session via reflection and user feedback. A Reflection\nEngine inspects conversation traces, diagnoses reasoning successes and\nfailures, and proposes typed deltas $\\Delta K=(\\Delta S,\\Delta U,\\Delta T)$\nover instructions, user preferences, and tools. Deltas are version-controlled,\nevaluated with a sliding window of 1-5 star ratings, auto-repaired on first\nfailure, and rolled back on repeated failure. When an edit budget crosses a\nthreshold, the agent compiles a rating-weighted synthetic set and distills\nmatured instruction-space gains into parameters, converting prompt-space\nimprovements into weight-space without downtime. ILWS makes explicit the\nlow-rank shaping induced by context in transformer blocks, preserves\ngovernance, and removes per-call retrieval. In enterprise support it increased\nthroughput 2.4-5.0x and cut audited hallucinations by about 80% versus a frozen\nbaseline. In an Adobe Commerce Cloud proof of concept \"L0 Support\", it achieved\n4-5x more tickets per hour and about 80% lower time per ticket, with autonomous\ninstruction updates and optional tool synthesis. Because ILWS operates at the\ninstruction layer until controlled distillation, it generalizes to dynamic\ndomains (legal, medical, engineering) requiring adaptive reasoning, tool\ncreation, and low-latency deployment.", "AI": {"tldr": "ILWS\u901a\u8fc7\u6307\u4ee4\u7ea7\u6743\u91cd\u5851\u5f62\uff0c\u4f7f\u7528\u53ef\u5ba1\u8ba1\u7684\u4f2a\u53c2\u6570\u548c\u53cd\u5c04\u5f15\u64ce\u52a8\u6001\u66f4\u65b0LLM\u77e5\u8bc6\uff0c\u907f\u514d\u4e86RAG\u7684\u9ad8\u5ef6\u8fdf\u548c\u5fae\u8c03\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u5728\u4f01\u4e1a\u652f\u6301\u573a\u666f\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u541e\u5410\u91cf\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edfLLM\u5728\u9884\u8bad\u7ec3\u540e\u662f\u9759\u6001\u7684\uff0c\u65b0\u77e5\u8bc6\u9700\u8981\u901a\u8fc7RAG\u6216\u5fae\u8c03\u6dfb\u52a0\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u5b58\u5728\u5ef6\u8fdf\u9ad8\u3001\u5de5\u7a0b\u590d\u6742\u3001\u77e5\u8bc6\u6574\u5408\u5931\u8d25\u3001\u707e\u96be\u6027\u9057\u5fd8\u7b49\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u52a8\u6001\u7684\u77e5\u8bc6\u66f4\u65b0\u673a\u5236\u3002", "method": "\u63d0\u51faInstruction-Level Weight Shaping (ILWS)\uff1a\u4f7f\u7528\u7cfb\u7edf\u6307\u4ee4\u4f5c\u4e3a\u5916\u90e8\u53ef\u5ba1\u8ba1\u4f2a\u53c2\u6570\uff0c\u901a\u8fc7\u53cd\u5c04\u5f15\u64ce\u5206\u6790\u5bf9\u8bdd\u8f68\u8ff9\uff0c\u751f\u6210\u7c7b\u578b\u5316\u589e\u91cf\u0394K=(\u0394S,\u0394U,\u0394T)\u6765\u66f4\u65b0\u6307\u4ee4\u3001\u7528\u6237\u504f\u597d\u548c\u5de5\u5177\uff0c\u5e76\u901a\u8fc7\u53d7\u63a7\u84b8\u998f\u5c06\u63d0\u793a\u7a7a\u95f4\u6539\u8fdb\u8f6c\u6362\u4e3a\u6743\u91cd\u7a7a\u95f4\u3002", "result": "\u5728\u4f01\u4e1a\u652f\u6301\u573a\u666f\u4e2d\uff0c\u541e\u5410\u91cf\u63d0\u53472.4-5.0\u500d\uff0c\u5ba1\u8ba1\u5e7b\u89c9\u51cf\u5c11\u7ea680%\uff1b\u5728Adobe Commerce Cloud\u6982\u5ff5\u9a8c\u8bc1\u4e2d\uff0c\u6bcf\u5c0f\u65f6\u5904\u7406\u5de5\u5355\u6570\u63d0\u53474-5\u500d\uff0c\u5355\u5de5\u5355\u65f6\u95f4\u964d\u4f4e\u7ea680%\uff0c\u652f\u6301\u81ea\u4e3b\u6307\u4ee4\u66f4\u65b0\u548c\u5de5\u5177\u5408\u6210\u3002", "conclusion": "ILWS\u5728\u6307\u4ee4\u5c42\u64cd\u4f5c\u76f4\u5230\u53d7\u63a7\u84b8\u998f\uff0c\u9002\u7528\u4e8e\u9700\u8981\u81ea\u9002\u5e94\u63a8\u7406\u3001\u5de5\u5177\u521b\u5efa\u548c\u4f4e\u5ef6\u8fdf\u90e8\u7f72\u7684\u52a8\u6001\u9886\u57df\uff08\u6cd5\u5f8b\u3001\u533b\u7597\u3001\u5de5\u7a0b\uff09\uff0c\u63d0\u4f9b\u4e86\u53ef\u6cbb\u7406\u7684\u77e5\u8bc6\u66f4\u65b0\u673a\u5236\u3002"}}
{"id": "2509.00266", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00266", "abs": "https://arxiv.org/abs/2509.00266", "authors": ["Qishen Sam Liang"], "title": "A Systematic Approach to Estimate the Security Posture of a Cyber Infrastructure: A Technical Report", "comment": "11 pages, 5 figures, technical report", "summary": "Academic and research Cyber Infrastructures (CI) present unique security\nchallenges due to their collaborative nature, heterogeneous components, and the\nlack of practical, tailored security assessment frameworks. Existing standards\ncan be too generic or complex for CI administrators to apply effectively. This\nreport introduces a systematic, mission-centric approach to estimate and\nanalyze the security posture of a CI. The framework guides administrators\nthrough a top-down process: (1) defining unacceptable losses and security\nmissions, (2) identifying associated system hazards and critical assets, and\n(3) modeling the CI's components and their relationships as a security\nknowledge graph. The core of this methodology is the construction of directed\nattack graphs, which systematically map all potential paths an adversary could\ntake from an entry point to a critical asset. By visualizing these attack paths\nalongside defense mechanisms, the framework provides a clear, comprehensive\noverview of the system's vulnerabilities and security gaps. This structured\napproach enables CI operators to proactively assess risks, prioritize\nmitigation strategies, and make informed, actionable decisions to strengthen\nthe overall security posture of the CI.", "AI": {"tldr": "\u8be5\u62a5\u544a\u63d0\u51fa\u4e86\u4e00\u4e2a\u9762\u5411\u5b66\u672f\u7814\u7a76\u7f51\u7edc\u57fa\u7840\u8bbe\u65bd\u7684\u7cfb\u7edf\u6027\u5b89\u5168\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u653b\u51fb\u56fe\u8c31\u6765\u8bc6\u522b\u6f0f\u6d1e\u548c\u5b89\u5168\u5dee\u8ddd\uff0c\u5e2e\u52a9\u7ba1\u7406\u5458\u4e3b\u52a8\u8bc4\u4f30\u98ce\u9669\u5e76\u4f18\u5148\u5236\u5b9a\u7f13\u89e3\u7b56\u7565\u3002", "motivation": "\u5b66\u672f\u7814\u7a76\u7f51\u7edc\u57fa\u7840\u8bbe\u65bd\u5177\u6709\u534f\u4f5c\u6027\u3001\u5f02\u6784\u7ec4\u4ef6\u7b49\u7279\u70b9\uff0c\u73b0\u6709\u5b89\u5168\u6807\u51c6\u8fc7\u4e8e\u901a\u7528\u6216\u590d\u6742\uff0c\u7f3a\u4e4f\u4e13\u95e8\u9488\u5bf9\u6b64\u7c7b\u57fa\u7840\u8bbe\u65bd\u7684\u5b9e\u7528\u5b89\u5168\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u91c7\u7528\u81ea\u4e0a\u800c\u4e0b\u7684\u4efb\u52a1\u4e2d\u5fc3\u65b9\u6cd5\uff1a1)\u5b9a\u4e49\u4e0d\u53ef\u63a5\u53d7\u635f\u5931\u548c\u5b89\u5168\u4efb\u52a1\uff1b2)\u8bc6\u522b\u76f8\u5173\u7cfb\u7edf\u5371\u5bb3\u548c\u5173\u952e\u8d44\u4ea7\uff1b3)\u5c06\u7ec4\u4ef6\u53ca\u5176\u5173\u7cfb\u5efa\u6a21\u4e3a\u5b89\u5168\u77e5\u8bc6\u56fe\u8c31\uff0c\u6784\u5efa\u6709\u5411\u653b\u51fb\u56fe\u8c31\u6765\u6620\u5c04\u653b\u51fb\u8def\u5f84\u3002", "result": "\u901a\u8fc7\u53ef\u89c6\u5316\u653b\u51fb\u8def\u5f84\u548c\u9632\u5fa1\u673a\u5236\uff0c\u6846\u67b6\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6f0f\u6d1e\u548c\u5b89\u5168\u5dee\u8ddd\u7684\u6e05\u6670\u5168\u9762\u6982\u89c8\u3002", "conclusion": "\u8be5\u7ed3\u6784\u5316\u65b9\u6cd5\u4f7f\u57fa\u7840\u8bbe\u65bd\u8fd0\u8425\u5546\u80fd\u591f\u4e3b\u52a8\u8bc4\u4f30\u98ce\u9669\u3001\u4f18\u5148\u5236\u5b9a\u7f13\u89e3\u7b56\u7565\uff0c\u5e76\u505a\u51fa\u660e\u667a\u53ef\u884c\u7684\u51b3\u7b56\u6765\u52a0\u5f3a\u6574\u4f53\u5b89\u5168\u6001\u52bf\u3002"}}
{"id": "2509.01616", "categories": ["cs.SE", "D.2.5"], "pdf": "https://arxiv.org/pdf/2509.01616", "abs": "https://arxiv.org/abs/2509.01616", "authors": ["Konstantinos Kitsios", "Marco Castelluccio", "Alberto Bacchelli"], "title": "Automated Generation of Issue-Reproducing Tests by Combining LLMs and Search-Based Testing", "comment": "13 pages, 8 figures, accepted for publication (to appear) in the 40th\n  IEEE/ACM International Conference on Automated Software Engineering, ASE 2025", "summary": "Issue-reproducing tests fail on buggy code and pass once a patch is applied,\nthus increasing developers' confidence that the issue has been resolved and\nwill not be re-introduced. However, past research has shown that developers\noften commit patches without such tests, making the automated generation of\nissue-reproducing tests an area of interest. We propose BLAST, a tool for\nautomatically generating issue-reproducing tests from issue-patch pairs by\ncombining LLMs and search-based software testing (SBST). For the LLM part, we\ncomplement the issue description and the patch by extracting relevant context\nthrough git history analysis, static analysis, and SBST-generated tests. For\nthe SBST part, we adapt SBST for generating issue-reproducing tests; the issue\ndescription and the patch are fed into the SBST optimization through an\nintermediate LLM-generated seed, which we deserialize into SBST-compatible\nform. BLAST successfully generates issue-reproducing tests for 151/426 (35.4%)\nof the issues from a curated Python benchmark, outperforming the\nstate-of-the-art (23.5%). Additionally, to measure the real-world impact of\nBLAST, we built a GitHub bot that runs BLAST whenever a new pull request (PR)\nlinked to an issue is opened, and if BLAST generates an issue-reproducing test,\nthe bot proposes it as a comment in the PR. We deployed the bot in three\nopen-source repositories for three months, gathering data from 32 PRs-issue\npairs. BLAST generated an issue-reproducing test in 11 of these cases, which we\nproposed to the developers. By analyzing the developers' feedback, we discuss\nchallenges and opportunities for researchers and tool builders. Data and\nmaterial: https://doi.org/10.5281/zenodo.16949042", "AI": {"tldr": "BLAST\u662f\u4e00\u4e2a\u7ed3\u5408LLM\u548c\u57fa\u4e8e\u641c\u7d22\u7684\u8f6f\u4ef6\u6d4b\u8bd5(SBST)\u7684\u5de5\u5177\uff0c\u80fd\u591f\u4eceissue-patch\u5bf9\u81ea\u52a8\u751f\u6210\u95ee\u9898\u91cd\u73b0\u6d4b\u8bd5\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523035.4%\u7684\u6210\u529f\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u5f00\u53d1\u8005\u7ecf\u5e38\u63d0\u4ea4\u6ca1\u6709\u76f8\u5e94\u6d4b\u8bd5\u7684\u8865\u4e01\uff0c\u4f7f\u5f97\u95ee\u9898\u91cd\u73b0\u6d4b\u8bd5\u7684\u81ea\u52a8\u751f\u6210\u6210\u4e3a\u91cd\u8981\u7814\u7a76\u65b9\u5411\uff0c\u4ee5\u63d0\u9ad8\u5f00\u53d1\u8005\u5bf9\u95ee\u9898\u4fee\u590d\u7684\u4fe1\u5fc3\u5e76\u9632\u6b62\u95ee\u9898\u91cd\u65b0\u5f15\u5165\u3002", "method": "\u7ed3\u5408LLM\u548cSBST\u6280\u672f\uff1a\u901a\u8fc7git\u5386\u53f2\u5206\u6790\u3001\u9759\u6001\u5206\u6790\u548cSBST\u751f\u6210\u6d4b\u8bd5\u6765\u63d0\u53d6\u76f8\u5173\u4e0a\u4e0b\u6587\u8865\u5145issue\u63cf\u8ff0\u548c\u8865\u4e01\u4fe1\u606f\uff1b\u5c06LLM\u751f\u6210\u7684\u79cd\u5b50\u53cd\u5e8f\u5217\u5316\u4e3aSBST\u517c\u5bb9\u5f62\u5f0f\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u5728426\u4e2aPython\u95ee\u9898\u4e2d\u6210\u529f\u751f\u6210151\u4e2a(35.4%)\u95ee\u9898\u91cd\u73b0\u6d4b\u8bd5\uff0c\u4f18\u4e8e\u6700\u5148\u8fdb\u6280\u672f\u768423.5%\uff1b\u5728\u771f\u5b9eGitHub\u90e8\u7f72\u4e2d\uff0c32\u4e2aPR-issue\u5bf9\u4e2d\u670911\u4e2a\u6210\u529f\u751f\u6210\u6d4b\u8bd5\u3002", "conclusion": "BLAST\u8bc1\u660e\u4e86\u7ed3\u5408LLM\u548cSBST\u5728\u81ea\u52a8\u751f\u6210\u95ee\u9898\u91cd\u73b0\u6d4b\u8bd5\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u4e3a\u7814\u7a76\u8005\u548c\u5de5\u5177\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u548c\u673a\u4f1a\u3002"}}
{"id": "2509.00272", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.00272", "abs": "https://arxiv.org/abs/2509.00272", "authors": ["Boqi Chen", "Kua Chen", "Jos\u00e9 Antonio Hern\u00e1ndez L\u00f3pez", "Gunter Mussbacher", "D\u00e1niel Varr\u00f3", "Amir Feizpour"], "title": "SHERPA: A Model-Driven Framework for Large Language Model Execution", "comment": "MODELS 2025", "summary": "Recently, large language models (LLMs) have achieved widespread application\nacross various fields. Despite their impressive capabilities, LLMs suffer from\na lack of structured reasoning ability, particularly for complex tasks\nrequiring domain-specific best practices, which are often unavailable in the\ntraining data. Although multi-step prompting methods incorporating human best\npractices, such as chain-of-thought and tree-of-thought, have gained\npopularity, they lack a general mechanism to control LLM behavior. In this\npaper, we propose SHERPA, a model-driven framework to improve the LLM\nperformance on complex tasks by explicitly incorporating domain-specific best\npractices into hierarchical state machines. By structuring the LLM execution\nprocesses using state machines, SHERPA enables more fine-grained control over\ntheir behavior via rules or decisions driven by machine learning-based\napproaches, including LLMs. We show that SHERPA is applicable to a wide variety\nof tasks-specifically, code generation, class name generation, and question\nanswering-replicating previously proposed approaches while further improving\nthe performance. We demonstrate the effectiveness of SHERPA for the\naforementioned tasks using various LLMs. Our systematic evaluation compares\ndifferent state machine configurations against baseline approaches without\nstate machines. Results show that integrating well-designed state machines\nsignificantly improves the quality of LLM outputs, and is particularly\nbeneficial for complex tasks with well-established human best practices but\nlacking data used for training LLMs.", "AI": {"tldr": "SHERPA\u662f\u4e00\u4e2a\u6a21\u578b\u9a71\u52a8\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u9886\u57df\u7279\u5b9a\u6700\u4f73\u5b9e\u8df5\u878d\u5165\u5206\u5c42\u72b6\u6001\u673a\u6765\u63d0\u5347LLM\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u5b9e\u73b0\u5bf9LLM\u884c\u4e3a\u7684\u7ec6\u7c92\u5ea6\u63a7\u5236\u3002", "motivation": "\u5f53\u524dLLM\u867d\u7136\u80fd\u529b\u5f3a\u5927\uff0c\u4f46\u7f3a\u4e4f\u7ed3\u6784\u5316\u63a8\u7406\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u9886\u57df\u7279\u5b9a\u6700\u4f73\u5b9e\u8df5\u7684\u590d\u6742\u4efb\u52a1\u4e2d\u3002\u73b0\u6709\u7684\u591a\u6b65\u63d0\u793a\u65b9\u6cd5\u7f3a\u4e4f\u901a\u7528\u673a\u5236\u6765\u63a7\u5236LLM\u884c\u4e3a\u3002", "method": "\u63d0\u51faSHERPA\u6846\u67b6\uff0c\u4f7f\u7528\u5206\u5c42\u72b6\u6001\u673a\u7ed3\u6784\u5316LLM\u6267\u884c\u8fc7\u7a0b\uff0c\u901a\u8fc7\u57fa\u4e8e\u89c4\u5219\u7684\u6216\u673a\u5668\u5b66\u4e60\u9a71\u52a8\u7684\u65b9\u6cd5\uff08\u5305\u62ecLLM\u672c\u8eab\uff09\u6765\u5b9e\u73b0\u5bf9\u884c\u4e3a\u7684\u7ec6\u7c92\u5ea6\u63a7\u5236\u3002", "result": "\u5728\u4ee3\u7801\u751f\u6210\u3001\u7c7b\u540d\u751f\u6210\u548c\u95ee\u7b54\u7b49\u591a\u79cd\u4efb\u52a1\u4e0a\uff0cSHERPA\u4e0d\u4ec5\u590d\u73b0\u4e86\u5148\u524d\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u8fd8\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u8868\u73b0\u3002\u7cfb\u7edf\u8bc4\u4f30\u663e\u793a\uff0c\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u72b6\u6001\u673a\u663e\u8457\u63d0\u9ad8\u4e86LLM\u8f93\u51fa\u8d28\u91cf\u3002", "conclusion": "SHERPA\u6846\u67b6\u7279\u522b\u9002\u7528\u4e8e\u5177\u6709\u5b8c\u5584\u4eba\u7c7b\u6700\u4f73\u5b9e\u8df5\u4f46\u7f3a\u4e4f\u8bad\u7ec3\u6570\u636e\u7684\u590d\u6742\u4efb\u52a1\uff0c\u901a\u8fc7\u72b6\u6001\u673a\u96c6\u6210\u80fd\u591f\u6709\u6548\u63d0\u5347LLM\u6027\u80fd\u3002"}}
{"id": "2509.00300", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00300", "abs": "https://arxiv.org/abs/2509.00300", "authors": ["Ghadeer Almusaddar", "Yicheng Zhang", "Saber Ganjisaffar", "Barry Williams", "Yu David Liu", "Dmitry Ponomare", "Nael Abu-Ghazaleh"], "title": "ShadowScope: GPU Monitoring and Validation via Composable Side Channel Signals", "comment": null, "summary": "As modern systems increasingly rely on GPUs for computationally intensive\ntasks such as machine learning acceleration, ensuring the integrity of GPU\ncomputation has become critically important. Recent studies have shown that GPU\nkernels are vulnerable to both traditional memory safety issues (e.g., buffer\noverflow attacks) and emerging microarchitectural threats (e.g., Rowhammer\nattacks), many of which manifest as anomalous execution behaviors observable\nthrough side-channel signals. However, existing golden model based validation\napproaches that rely on such signals are fragile, highly sensitive to\ninterference, and do not scale well across GPU workloads with diverse\nscheduling behaviors. To address these challenges, we propose ShadowScope, a\nmonitoring and validation framework that leverages a composable golden model.\nInstead of building a single monolithic reference, ShadowScope decomposes\ntrusted kernel execution into modular, repeatable functions that encode key\nbehavioral features. This composable design captures execution patterns at\nfiner granularity, enabling robust validation that is resilient to noise,\nworkload variation, and interference across GPU workloads. To further reduce\nreliance on noisy software-only monitoring, we introduce ShadowScope+, a\nhardware-assisted validation mechanism that integrates lightweight on-chip\nchecks into the GPU pipeline. ShadowScope+ achieves high validation accuracy\nwith an average runtime overhead of just 4.6%, while incurring minimal hardware\nand design complexity. Together, these contributions demonstrate that\nside-channel observability can be systematically repurposed into a practical\ndefense for GPU kernel integrity.", "AI": {"tldr": "ShadowScope\u662f\u4e00\u4e2aGPU\u8ba1\u7b97\u5b8c\u6574\u6027\u9a8c\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u7ec4\u5408\u7684\u9ec4\u91d1\u6a21\u578b\u548c\u786c\u4ef6\u8f85\u52a9\u9a8c\u8bc1\u673a\u5236\uff0c\u6709\u6548\u68c0\u6d4bGPU\u5185\u6838\u4e2d\u7684\u5f02\u5e38\u6267\u884c\u884c\u4e3a\uff0c\u5e73\u5747\u8fd0\u884c\u65f6\u5f00\u9500\u4ec5\u4e3a4.6%\u3002", "motivation": "\u968f\u7740GPU\u5728\u673a\u5668\u5b66\u4e60\u7b49\u8ba1\u7b97\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u786e\u4fddGPU\u8ba1\u7b97\u7684\u5b8c\u6574\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u57fa\u4e8e\u9ec4\u91d1\u6a21\u578b\u7684\u9a8c\u8bc1\u65b9\u6cd5\u5bf9\u5e72\u6270\u654f\u611f\u4e14\u96be\u4ee5\u6269\u5c55\u5230\u4e0d\u540cGPU\u5de5\u4f5c\u8d1f\u8f7d\u3002", "method": "\u63d0\u51faShadowScope\u6846\u67b6\uff0c\u5c06\u53ef\u4fe1\u5185\u6838\u6267\u884c\u5206\u89e3\u4e3a\u6a21\u5757\u5316\u3001\u53ef\u91cd\u590d\u7684\u51fd\u6570\u6765\u7f16\u7801\u5173\u952e\u884c\u4e3a\u7279\u5f81\u3002\u8fd8\u8bbe\u8ba1\u4e86ShadowScope+\u786c\u4ef6\u8f85\u52a9\u9a8c\u8bc1\u673a\u5236\uff0c\u5728GPU\u6d41\u6c34\u7ebf\u4e2d\u96c6\u6210\u8f7b\u91cf\u7ea7\u7247\u4e0a\u68c0\u67e5\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u4ee5\u66f4\u7ec6\u7c92\u5ea6\u6355\u83b7\u6267\u884c\u6a21\u5f0f\uff0c\u5b9e\u73b0\u5bf9\u6297\u566a\u58f0\u3001\u5de5\u4f5c\u8d1f\u8f7d\u53d8\u5316\u548c\u5e72\u6270\u7684\u9c81\u68d2\u9a8c\u8bc1\u3002\u786c\u4ef6\u8f85\u52a9\u7248\u672c\u5e73\u5747\u8fd0\u884c\u65f6\u5f00\u9500\u4ec5\u4e3a4.6%\uff0c\u540c\u65f6\u4fdd\u6301\u6700\u5c0f\u786c\u4ef6\u548c\u8bbe\u8ba1\u590d\u6742\u5ea6\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u4fa7\u4fe1\u9053\u53ef\u89c2\u6d4b\u6027\u53ef\u4ee5\u7cfb\u7edf\u5730\u8f6c\u5316\u4e3a\u5b9e\u7528\u7684GPU\u5185\u6838\u5b8c\u6574\u6027\u9632\u5fa1\u673a\u5236\uff0c\u4e3a\u89e3\u51b3GPU\u8ba1\u7b97\u5b89\u5168\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.01946", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.01946", "abs": "https://arxiv.org/abs/2509.01946", "authors": ["Aarsh Shah", "Cleyton Magalhaes", "Kiev Gama", "Ronnie de Souza Santos"], "title": "Tether: A Personalized Support Assistant for Software Engineers with ADHD", "comment": null, "summary": "Equity, diversity, and inclusion in software engineering often overlook\nneurodiversity, particularly the experiences of developers with Attention\nDeficit Hyperactivity Disorder (ADHD). Despite the growing awareness about that\npopulation in SE, few tools are designed to support their cognitive challenges\n(e.g., sustained attention, task initiation, self-regulation) within\ndevelopment workflows. We present Tether, an LLM-powered desktop application\ndesigned to support software engineers with ADHD by delivering adaptive,\ncontext-aware assistance. Drawing from engineering research methodology, Tether\ncombines local activity monitoring, retrieval-augmented generation (RAG), and\ngamification to offer real-time focus support and personalized dialogue. The\nsystem integrates operating system level system tracking to prompt engagement\nand its chatbot leverages ADHD-specific resources to offer relevant responses.\nPreliminary validation through self-use revealed improved contextual accuracy\nfollowing iterative prompt refinements and RAG enhancements. Tether\ndifferentiates itself from generic tools by being adaptable and aligned with\nsoftware-specific workflows and ADHD-related challenges. While not yet\nevaluated by target users, this work lays the foundation for future\nneurodiversity-aware tools in SE and highlights the potential of LLMs as\npersonalized support systems for underrepresented cognitive needs.", "AI": {"tldr": "Tether\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u684c\u9762\u5e94\u7528\uff0c\u4e13\u95e8\u4e3a\u60a3\u6709ADHD\u7684\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u8bbe\u8ba1\uff0c\u901a\u8fc7\u5b9e\u65f6\u6d3b\u52a8\u76d1\u63a7\u3001RAG\u6280\u672f\u548c\u6e38\u620f\u5316\u5143\u7d20\u63d0\u4f9b\u4e2a\u6027\u5316\u7684\u6ce8\u610f\u529b\u652f\u6301\u548c\u5bf9\u8bdd\u5e2e\u52a9\u3002", "motivation": "\u5f53\u524d\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u516c\u5e73\u6027\u3001\u591a\u6837\u6027\u548c\u5305\u5bb9\u6027\u5f80\u5f80\u5ffd\u89c6\u795e\u7ecf\u591a\u6837\u6027\uff0c\u7279\u522b\u662fADHD\u5f00\u53d1\u8005\u7684\u4f53\u9a8c\u3002\u5c3d\u7ba1\u5bf9\u8be5\u7fa4\u4f53\u7684\u8ba4\u8bc6\u5728\u589e\u52a0\uff0c\u4f46\u5f88\u5c11\u6709\u5de5\u5177\u4e13\u95e8\u652f\u6301\u4ed6\u4eec\u5728\u5f00\u53d1\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u8ba4\u77e5\u6311\u6218\u3002", "method": "\u7ed3\u5408\u672c\u5730\u6d3b\u52a8\u76d1\u63a7\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u548c\u6e38\u620f\u5316\u6280\u672f\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2aLLM\u9a71\u52a8\u7684\u684c\u9762\u5e94\u7528\u3002\u7cfb\u7edf\u96c6\u6210\u64cd\u4f5c\u7cfb\u7edf\u7ea7\u522b\u7684\u7cfb\u7edf\u8ddf\u8e2a\u6765\u63d0\u793a\u53c2\u4e0e\u5ea6\uff0c\u804a\u5929\u673a\u5668\u4eba\u5229\u7528ADHD\u7279\u5b9a\u8d44\u6e90\u63d0\u4f9b\u76f8\u5173\u54cd\u5e94\u3002", "result": "\u901a\u8fc7\u81ea\u6211\u4f7f\u7528\u7684\u521d\u6b65\u9a8c\u8bc1\u663e\u793a\uff0c\u7ecf\u8fc7\u8fed\u4ee3\u63d0\u793a\u4f18\u5316\u548cRAG\u589e\u5f3a\u540e\uff0c\u4e0a\u4e0b\u6587\u51c6\u786e\u6027\u5f97\u5230\u6539\u5584\u3002\u5de5\u5177\u5728\u8f6f\u4ef6\u7279\u5b9a\u5de5\u4f5c\u6d41\u7a0b\u548cADHD\u76f8\u5173\u6311\u6218\u65b9\u9762\u8868\u73b0\u51fa\u9002\u5e94\u6027\u3002", "conclusion": "Tether\u4e0e\u901a\u7528\u5de5\u5177\u4e0d\u540c\uff0c\u5177\u6709\u9002\u5e94\u6027\u548c\u9488\u5bf9\u6027\uff0c\u4e3a\u672a\u6765\u795e\u7ecf\u591a\u6837\u6027\u611f\u77e5\u5de5\u5177\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u7a81\u663e\u4e86LLM\u4f5c\u4e3a\u4e2a\u6027\u5316\u652f\u6301\u7cfb\u7edf\u6ee1\u8db3 underrepresented \u8ba4\u77e5\u9700\u6c42\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.00287", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.00287", "abs": "https://arxiv.org/abs/2509.00287", "authors": ["Brian Wang", "Mani Srivastava"], "title": "SIGMUS: Semantic Integration for Knowledge Graphs in Multimodal Urban Spaces", "comment": "9 pages, accepted at UrbComp 2025 KDD 2025", "summary": "Modern urban spaces are equipped with an increasingly diverse set of sensors,\nall producing an abundance of multimodal data. Such multimodal data can be used\nto identify and reason about important incidents occurring in urban landscapes,\nsuch as major emergencies, cultural and social events, as well as natural\ndisasters. However, such data may be fragmented over several sources and\ndifficult to integrate due to the reliance on human-driven reasoning for\nidentifying relationships between the multimodal data corresponding to an\nincident, as well as understanding the different components which define an\nincident. Such relationships and components are critical to identifying the\ncauses of such incidents, as well as producing forecasting the scale and\nintensity of future incidents as they begin to develop. In this work, we create\nSIGMUS, a system for Semantic Integration for Knowledge Graphs in Multimodal\nUrban Spaces. SIGMUS uses Large Language Models (LLMs) to produce the necessary\nworld knowledge for identifying relationships between incidents occurring in\nurban spaces and data from different modalities, allowing us to organize\nevidence and observations relevant to an incident without relying and\nhuman-encoded rules for relating multimodal sensory data with incidents. This\norganized knowledge is represented as a knowledge graph, organizing incidents,\nobservations, and much more. We find that our system is able to produce\nreasonable connections between 5 different data sources (new article text, CCTV\nimages, air quality, weather, and traffic measurements) and relevant incidents\noccurring at the same time and location.", "AI": {"tldr": "SIGMUS\u7cfb\u7edf\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u6574\u5408\u57ce\u5e02\u591a\u6a21\u6001\u4f20\u611f\u5668\u6570\u636e\uff0c\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u6765\u8bc6\u522b\u548c\u63a8\u7406\u57ce\u5e02\u4e8b\u4ef6\uff0c\u65e0\u9700\u4f9d\u8d56\u4eba\u5de5\u89c4\u5219\u3002", "motivation": "\u73b0\u4ee3\u57ce\u5e02\u4f20\u611f\u5668\u4ea7\u751f\u5927\u91cf\u591a\u6a21\u6001\u6570\u636e\uff0c\u4f46\u6570\u636e\u5206\u6563\u4e14\u96be\u4ee5\u6574\u5408\uff0c\u9700\u8981\u4eba\u5de5\u63a8\u7406\u6765\u8bc6\u522b\u4e8b\u4ef6\u4e0e\u591a\u6a21\u6001\u6570\u636e\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u8fd9\u9650\u5236\u4e86\u4e8b\u4ef6\u8bc6\u522b\u548c\u9884\u6d4b\u7684\u6548\u7387\u3002", "method": "\u5f00\u53d1SIGMUS\u7cfb\u7edf\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5fc5\u8981\u7684\u4e16\u754c\u77e5\u8bc6\uff0c\u8bc6\u522b\u57ce\u5e02\u4e8b\u4ef6\u4e0e\u591a\u6a21\u6001\u6570\u636e\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u5c06\u7ec4\u7ec7\u5316\u7684\u77e5\u8bc6\u8868\u793a\u4e3a\u77e5\u8bc6\u56fe\u8c31\u3002", "result": "\u7cfb\u7edf\u80fd\u591f\u5408\u7406\u8fde\u63a55\u79cd\u4e0d\u540c\u6570\u636e\u6e90\uff08\u65b0\u95fb\u6587\u672c\u3001\u76d1\u63a7\u56fe\u50cf\u3001\u7a7a\u6c14\u8d28\u91cf\u3001\u5929\u6c14\u548c\u4ea4\u901a\u6d4b\u91cf\uff09\u4e0e\u540c\u65f6\u540c\u5730\u53d1\u751f\u7684\u76f8\u5173\u4e8b\u4ef6\u3002", "conclusion": "SIGMUS\u7cfb\u7edf\u901a\u8fc7LLM\u9a71\u52a8\u7684\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u57ce\u5e02\u591a\u6a21\u6001\u6570\u636e\u7684\u81ea\u52a8\u8bed\u4e49\u96c6\u6210\uff0c\u4e3a\u57ce\u5e02\u4e8b\u4ef6\u8bc6\u522b\u548c\u9884\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.00437", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00437", "abs": "https://arxiv.org/abs/2509.00437", "authors": ["Hamideh Haghiri", "Rajesh Baidya", "Stefan Dvoretskii", "Klaus H. Maier-Hein", "Marco Nolden"], "title": "A Hybrid AI-based and Rule-based Approach to DICOM De-identification: A Solution for the MIDI-B Challenge", "comment": null, "summary": "Ensuring the de-identification of medical imaging data is a critical step in\nenabling safe data sharing. This paper presents a hybrid de-identification\nframework designed to process Digital Imaging and Communications in Medicine\n(DICOM) files. Our framework adopts a modified, pre-built rule-based component,\nupdated with The Cancer Imaging Archive (TCIA)'s best practices guidelines, as\noutlined in DICOM PS 3.15, for improved performance. It incorporates PaddleOCR,\na robust Optical Character Recognition (OCR) system for extracting text from\nimages, and RoBERTa, a fine-tuned transformer-based model for identifying and\nremoving Personally Identifiable Information (PII) and Protected Health\nInformation (PHI). Initially, the transformer-based model and the rule-based\ncomponent were integrated to process for both structured data and free text.\nHowever, this coarse-grained approach did not yield optimal results. To improve\nperformance, we refined our approach by applying the transformer model\nexclusively to free text, while structured data was handled only by rule-based\nmethods. In this framework the DICOM validator dciodvfy was leveraged to ensure\nthe integrity of DICOM files after the deID process. Through iterative\nrefinement, including the incorporation of custom rules and private tag\nhandling, the framework achieved a de-identification accuracy of 99.91% on the\nMIDI-B test dataset. The results demonstrate the effectiveness of combining\nrule-based compliance with AI-enabled adaptability in addressing the complex\nchallenges of DICOM de-identification.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u53bb\u6807\u8bc6\u5316\u6846\u67b6\uff0c\u7ed3\u5408\u89c4\u5219\u65b9\u6cd5\u548cAI\u6280\u672f\u5904\u7406DICOM\u533b\u7597\u5f71\u50cf\u6570\u636e\uff0c\u8fbe\u523099.91%\u7684\u53bb\u6807\u8bc6\u51c6\u786e\u7387", "motivation": "\u533b\u7597\u5f71\u50cf\u6570\u636e\u5171\u4eab\u9700\u8981\u786e\u4fdd\u60a3\u8005\u9690\u79c1\u5b89\u5168\uff0cDICOM\u6587\u4ef6\u5305\u542b\u5927\u91cf\u4e2a\u4eba\u8eab\u4efd\u4fe1\u606f\u548c\u53d7\u4fdd\u62a4\u5065\u5eb7\u4fe1\u606f\uff0c\u9700\u8981\u6709\u6548\u7684\u53bb\u6807\u8bc6\u5316\u65b9\u6cd5", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff1a\u57fa\u4e8eTCIA\u6700\u4f73\u5b9e\u8df5\u6307\u5357\u7684\u89c4\u5219\u7ec4\u4ef6\u5904\u7406\u7ed3\u6784\u5316\u6570\u636e\uff0cPaddleOCR\u63d0\u53d6\u56fe\u50cf\u6587\u672c\uff0cRoBERTa\u6a21\u578b\u5904\u7406\u81ea\u7531\u6587\u672c\u4e2d\u7684PII/PHI\u4fe1\u606f\uff0c\u4f7f\u7528dciodvfy\u9a8c\u8bc1DICOM\u6587\u4ef6\u5b8c\u6574\u6027", "result": "\u5728MIDI-B\u6d4b\u8bd5\u6570\u636e\u96c6\u4e0a\u8fbe\u523099.91%\u7684\u53bb\u6807\u8bc6\u51c6\u786e\u7387\uff0c\u901a\u8fc7\u8fed\u4ee3\u4f18\u5316\u548c\u81ea\u5b9a\u4e49\u89c4\u5219\u5904\u7406\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd", "conclusion": "\u7ed3\u5408\u89c4\u5219\u57fa\u7840\u7684\u5408\u89c4\u6027\u548cAI\u9a71\u52a8\u7684\u9002\u5e94\u6027\u80fd\u591f\u6709\u6548\u89e3\u51b3DICOM\u53bb\u6807\u8bc6\u5316\u7684\u590d\u6742\u6311\u6218\uff0c\u4e3a\u533b\u7597\u6570\u636e\u5b89\u5168\u5171\u4eab\u63d0\u4f9b\u4e86\u53ef\u9760\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.01947", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.01947", "abs": "https://arxiv.org/abs/2509.01947", "authors": ["Mahdi Farzandway", "Fatemeh Ghassemi"], "title": "Automated Repair of C Programs Using Large Language Models", "comment": null, "summary": "This study explores the potential of Large Language Models (LLMs) in\nautomating the repair of C programs. We present a framework that integrates\nspectrum-based fault localization (SBFL), runtime feedback, and\nChain-of-Thought-structured prompting into an autonomous repair loop. Unlike\nprior approaches, our method explicitly combines statistical program analysis\nwith LLM reasoning. The iterative repair cycle leverages a structured\nChain-of-Thought (CoT) prompting approach, where the model reasons over failing\ntests, suspicious code regions, and prior patch outcomes, before generating new\ncandidate patches. The model iteratively changes the code, evaluates the\nresults, and incorporates reasoning from previous attempts into subsequent\nmodifications, reducing repeated errors and clarifying why some bugs remain\nunresolved. Our evaluation spans 3,902 bugs from the Codeflaws benchmark, where\nour approach achieves 44.93% repair accuracy, representing a 3.61% absolute\nimprovement over strong state-of-the-art APR baselines such as GPT-4 with CoT.\nThis outcome highlights a practical pathway toward integrating statistical\nprogram analysis with generative AI in automated debugging.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u9891\u8c31\u6545\u969c\u5b9a\u4f4d\u3001\u8fd0\u884c\u65f6\u53cd\u9988\u548c\u601d\u7ef4\u94fe\u63d0\u793a\u7684LLM\u81ea\u4e3b\u4fee\u590d\u6846\u67b6\uff0c\u5728Codeflaws\u57fa\u51c6\u76843902\u4e2abug\u4e0a\u8fbe\u523044.93%\u4fee\u590d\u51c6\u786e\u7387\uff0c\u6bd4GPT-4+CoT\u57fa\u7ebf\u63d0\u53473.61%", "motivation": "\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5316C\u7a0b\u5e8f\u4fee\u590d\u4e2d\u7684\u6f5c\u529b\uff0c\u5c06\u7edf\u8ba1\u7a0b\u5e8f\u5206\u6790\u4e0eLLM\u63a8\u7406\u76f8\u7ed3\u5408\uff0c\u63d0\u4f9b\u66f4\u6709\u6548\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u65b9\u6848", "method": "\u96c6\u6210\u9891\u8c31\u6545\u969c\u5b9a\u4f4d(SBFL)\u3001\u8fd0\u884c\u65f6\u53cd\u9988\u548c\u7ed3\u6784\u5316\u601d\u7ef4\u94fe\u63d0\u793a\u7684\u8fed\u4ee3\u4fee\u590d\u5faa\u73af\uff0c\u6a21\u578b\u57fa\u4e8e\u5931\u8d25\u6d4b\u8bd5\u3001\u53ef\u7591\u4ee3\u7801\u533a\u57df\u548c\u5148\u524d\u8865\u4e01\u7ed3\u679c\u8fdb\u884c\u63a8\u7406\uff0c\u751f\u6210\u65b0\u5019\u9009\u8865\u4e01", "result": "\u5728Codeflaws\u57fa\u51c6\u76843902\u4e2abug\u4e0a\u5b9e\u73b044.93%\u7684\u4fee\u590d\u51c6\u786e\u7387\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u7684GPT-4+CoT\u57fa\u7ebf\u65b9\u6cd5\u7edd\u5bf9\u63d0\u53473.61%", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7edf\u8ba1\u7a0b\u5e8f\u5206\u6790\u4e0e\u751f\u6210\u5f0fAI\u5728\u81ea\u52a8\u5316\u8c03\u8bd5\u4e2d\u7684\u96c6\u6210\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\uff0c\u901a\u8fc7\u8fed\u4ee3\u63a8\u7406\u548c\u53cd\u9988\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u7a0b\u5e8f\u4fee\u590d\u6548\u679c"}}
{"id": "2509.00446", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00446", "abs": "https://arxiv.org/abs/2509.00446", "authors": ["Yen-Che Chien", "Kuang-Da Wang", "Wei-Yao Wang", "Wen-Chih Peng"], "title": "NEWSAGENT: Benchmarking Multimodal Agents as Journalists with Real-World Newswriting Tasks", "comment": "Preprint", "summary": "Recent advances in autonomous digital agents from industry (e.g., Manus AI\nand Gemini's research mode) highlight potential for structured tasks by\nautonomous decision-making and task decomposition; however, it remains unclear\nto what extent the agent-based systems can improve multimodal web data\nproductivity. We study this in the realm of journalism, which requires\niterative planning, interpretation, and contextual reasoning from multimodal\nraw contents to form a well structured news. We introduce NEWSAGENT, a\nbenchmark for evaluating how agents can automatically search available raw\ncontents, select desired information, and edit and rephrase to form a news\narticle by accessing core journalistic functions. Given a writing instruction\nand firsthand data as how a journalist initiates a news draft, agents are\ntasked to identify narrative perspectives, issue keyword-based queries,\nretrieve historical background, and generate complete articles. Unlike typical\nsummarization or retrieval tasks, essential context is not directly available\nand must be actively discovered, reflecting the information gaps faced in\nreal-world news writing. NEWSAGENT includes 6k human-verified examples derived\nfrom real news, with multimodal contents converted to text for broad model\ncompatibility. We evaluate open- and closed-sourced LLMs with commonly-used\nagentic frameworks on NEWSAGENT, which shows that agents are capable of\nretrieving relevant facts but struggling with planning and narrative\nintegration. We believe that NEWSAGENT serves a realistic testbed for iterating\nand evaluating agent capabilities in terms of multimodal web data manipulation\nto real-world productivity.", "AI": {"tldr": "NEWSAGENT\u662f\u4e00\u4e2a\u8bc4\u4f30\u81ea\u4e3b\u4ee3\u7406\u5728\u65b0\u95fb\u5199\u4f5c\u4e2d\u5904\u7406\u591a\u6a21\u6001\u7f51\u7edc\u6570\u636e\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b6000\u4e2a\u4eba\u5de5\u9a8c\u8bc1\u7684\u771f\u5b9e\u65b0\u95fb\u6848\u4f8b\uff0c\u6d4b\u8bd5\u663e\u793a\u4ee3\u7406\u80fd\u68c0\u7d22\u76f8\u5173\u4e8b\u5b9e\u4f46\u5728\u89c4\u5212\u548c\u53d9\u4e8b\u6574\u5408\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002", "motivation": "\u7814\u7a76\u81ea\u4e3b\u4ee3\u7406\u7cfb\u7edf\u5728\u591a\u6a21\u6001\u7f51\u7edc\u6570\u636e\u751f\u4ea7\u529b\u65b9\u9762\u7684\u63d0\u5347\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u8fed\u4ee3\u89c4\u5212\u3001\u89e3\u91ca\u548c\u4e0a\u4e0b\u6587\u63a8\u7406\u7684\u65b0\u95fb\u5199\u4f5c\u9886\u57df\u3002", "method": "\u5f15\u5165NEWSAGENT\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b6k\u4e2a\u4eba\u5de5\u9a8c\u8bc1\u7684\u771f\u5b9e\u65b0\u95fb\u6848\u4f8b\uff0c\u5c06\u591a\u6a21\u6001\u5185\u5bb9\u8f6c\u6362\u4e3a\u6587\u672c\u4ee5\u5e7f\u6cdb\u517c\u5bb9\u6a21\u578b\uff0c\u8bc4\u4f30\u5f00\u6e90\u548c\u95ed\u6e90LLM\u5728\u5e38\u7528\u4ee3\u7406\u6846\u67b6\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u4ee3\u7406\u80fd\u591f\u68c0\u7d22\u76f8\u5173\u4e8b\u5b9e\uff0c\u4f46\u5728\u89c4\u5212\u548c\u53d9\u4e8b\u6574\u5408\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u53cd\u6620\u4e86\u73b0\u5b9e\u4e16\u754c\u65b0\u95fb\u5199\u4f5c\u4e2d\u9762\u4e34\u7684\u4fe1\u606f\u5dee\u8ddd\u6311\u6218\u3002", "conclusion": "NEWSAGENT\u4e3a\u8fed\u4ee3\u548c\u8bc4\u4f30\u4ee3\u7406\u5728\u591a\u6a21\u6001\u7f51\u7edc\u6570\u636e\u64cd\u4f5c\u65b9\u9762\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u73b0\u5b9e\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u81ea\u4e3b\u4ee3\u7406\u5728\u771f\u5b9e\u4e16\u754c\u751f\u4ea7\u529b\u5e94\u7528\u4e2d\u7684\u53d1\u5c55\u3002"}}
{"id": "2509.00476", "categories": ["cs.CR", "cs.AI", "68T10 (Primary) 68T05, 68M25 (Secondary)", "I.2.6; I.5.2; K.6.5"], "pdf": "https://arxiv.org/pdf/2509.00476", "abs": "https://arxiv.org/abs/2509.00476", "authors": ["Omar Khalid Ali Mohamed"], "title": "Cross-Domain Malware Detection via Probability-Level Fusion of Lightweight Gradient Boosting Models", "comment": "5 pages, 3 figures, 3 tables. Conference-style formatting (IEEEtran)", "summary": "The escalating sophistication of malware necessitates robust detection\nmechanisms that generalize across diverse data sources. Traditional\nsingle-dataset models struggle with cross-domain generalization and often incur\nhigh computational costs. This paper presents a novel, lightweight framework\nfor malware detection that employs probability-level fusion across three\ndistinct datasets: EMBER (static features), API Call Sequences (behavioral\nfeatures), and CIC Obfuscated Memory (memory patterns). Our method trains\nindividual LightGBM classifiers on each dataset, selects top predictive\nfeatures to ensure efficiency, and fuses their prediction probabilities using\noptimized weights determined via grid search. Extensive experiments demonstrate\nthat our fusion approach achieves a macro F1-score of 0.823 on a cross-domain\nvalidation set, significantly outperforming individual models and providing\nsuperior generalization. The framework maintains low computational overhead,\nmaking it suitable for real-time deployment, and all code and data are provided\nfor full reproducibility.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u6982\u7387\u7ea7\u878d\u5408\u4e09\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u7684\u9884\u6d4b\u7ed3\u679c\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8de8\u57df\u6cdb\u5316\u80fd\u529b\u548c\u68c0\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edf\u7684\u5355\u6570\u636e\u96c6\u6a21\u578b\u5728\u8de8\u57df\u6cdb\u5316\u65b9\u9762\u8868\u73b0\u5c40\u9650\uff0c\u4e14\u8ba1\u7b97\u6210\u672c\u8f83\u9ad8\u3002\u6076\u610f\u8f6f\u4ef6\u7684\u65e5\u76ca\u590d\u6742\u5316\u5bfc\u81f4\u5bf9\u66f4\u52a0\u5065\u58ee\u7684\u68c0\u6d4b\u673a\u5236\u7684\u9700\u6c42\u3002", "method": "\u4f7f\u7528LightGBM\u5206\u522b\u5728\u4e09\u4e2a\u6570\u636e\u96c6\uff08EMBER\u9759\u6001\u7279\u5f81\u3001API\u8c03\u7528\u5e8f\u5217\u884c\u4e3a\u7279\u5f81\u3001CIC\u6df7\u6dc6\u5185\u5b58\u6a21\u5f0f\uff09\u4e0a\u8bad\u7ec3\u5206\u7c7b\u5668\uff0c\u9009\u62e9\u9876\u90e8\u9884\u6d4b\u7279\u5f81\u786e\u4fdd\u6548\u7387\uff0c\u901a\u8fc7\u7f51\u683c\u641c\u7d22\u786e\u5b9a\u6700\u4f18\u6743\u91cd\u8fdb\u884c\u6982\u7387\u878d\u5408\u3002", "result": "\u5728\u8de8\u57df\u9a8c\u8bc1\u96c6\u4e0a\u83b7\u5f97\u4e860.823\u7684\u5b8f\u89c2F1\u5206\u6570\uff0c\u663e\u8457\u8d85\u8fc7\u4e86\u5355\u72ec\u6a21\u578b\uff0c\u5e76\u4f53\u73b0\u4e86\u4f18\u5f02\u7684\u6cdb\u5316\u80fd\u529b\u3002\u6846\u67b6\u4fdd\u6301\u4f4e\u8ba1\u7b97\u5f00\u9500\uff0c\u9002\u5408\u5b9e\u65f6\u90e8\u7f72\u3002", "conclusion": "\u8be5\u878d\u5408\u6846\u67b6\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u8f7b\u91cf\u7684\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u65b9\u6848\uff0c\u5177\u6709\u826f\u597d\u7684\u8de8\u57df\u6cdb\u5316\u6027\u80fd\u548c\u5b9e\u65f6\u90e8\u7f72\u80fd\u529b\uff0c\u4ee3\u7801\u548c\u6570\u636e\u5b8c\u5168\u53ef\u590d\u73b0\u3002"}}
{"id": "2509.02012", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.02012", "abs": "https://arxiv.org/abs/2509.02012", "authors": ["Katrine Christensen", "Mahsa Varshosaz", "Ra\u00fal Pardo"], "title": "ProbTest: Unit Testing for Probabilistic Programs (Extended Version)", "comment": "Pre-print of paper to appear in the proceedings of the 23nd edition\n  of the International Conference on Software Engineering and Formal Methods\n  (SEFM'25)", "summary": "Testing probabilistic programs is non-trivial due to their stochastic nature.\nGiven an input, the program may produce different outcomes depending on the\nunderlying stochastic choices in the program. This means testing the expected\noutcomes of probabilistic programs requires repeated test executions unlike\ndeterministic programs where a single execution may suffice for each test\ninput. This raises the following question: how many times should we run a\nprobabilistic program to effectively test it? This work proposes a novel\nblack-box unit testing method, ProbTest, for testing the outcomes of\nprobabilistic programs. Our method is founded on the theory surrounding a\nwell-known combinatorial problem, the coupon collector's problem. Using this\nmethod, developers can write unit tests as usual without extra effort while the\nnumber of required test executions is determined automatically with statistical\nguarantees for the results. We implement ProbTest as a plug-in for PyTest, a\nwell-known unit testing tool for python programs. Using this plug-in,\ndevelopers can write unit tests similar to any other Python program and the\nnecessary test executions are handled automatically. We evaluate the method on\ncase studies from the Gymnasium reinforcement learning library and a randomized\ndata structure.", "AI": {"tldr": "ProbTest\uff1a\u57fa\u4e8e\u4f18\u60e0\u5238\u6536\u96c6\u95ee\u9898\u7406\u8bba\u7684\u6982\u7387\u7a0b\u5e8f\u9ed1\u76d2\u5355\u5143\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u53ef\u81ea\u52a8\u786e\u5b9a\u6d4b\u8bd5\u6267\u884c\u6b21\u6570\u5e76\u63d0\u4f9b\u7edf\u8ba1\u4fdd\u8bc1", "motivation": "\u6982\u7387\u7a0b\u5e8f\u7684\u968f\u673a\u6027\u4f7f\u5f97\u6d4b\u8bd5\u53d8\u5f97\u56f0\u96be\uff0c\u9700\u8981\u591a\u6b21\u6267\u884c\u6765\u9a8c\u8bc1\u671f\u671b\u7ed3\u679c\uff0c\u4f46\u5982\u4f55\u786e\u5b9a\u5408\u9002\u7684\u6267\u884c\u6b21\u6570\u662f\u4e00\u4e2a\u6311\u6218", "method": "\u57fa\u4e8e\u4f18\u60e0\u5238\u6536\u96c6\u95ee\u9898\u7406\u8bba\u7684\u9ed1\u76d2\u5355\u5143\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u5f00\u53d1\u4eba\u5458\u53ef\u4ee5\u50cf\u5f80\u5e38\u4e00\u6837\u7f16\u5199\u5355\u5143\u6d4b\u8bd5\uff0c\u7cfb\u7edf\u81ea\u52a8\u786e\u5b9a\u6240\u9700\u7684\u6d4b\u8bd5\u6267\u884c\u6b21\u6570", "result": "\u5b9e\u73b0\u4e86PyTest\u63d2\u4ef6\uff0c\u5728Gymnasium\u5f3a\u5316\u5b66\u4e60\u5e93\u548c\u968f\u673a\u5316\u6570\u636e\u7ed3\u6784\u6848\u4f8b\u7814\u7a76\u4e2d\u8fdb\u884c\u4e86\u8bc4\u4f30", "conclusion": "ProbTest\u4e3a\u6982\u7387\u7a0b\u5e8f\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5f00\u53d1\u4eba\u5458\u65e0\u9700\u989d\u5916\u52aa\u529b\u5373\u53ef\u83b7\u5f97\u7edf\u8ba1\u4fdd\u8bc1\u7684\u6d4b\u8bd5\u7ed3\u679c"}}
{"id": "2509.00481", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00481", "abs": "https://arxiv.org/abs/2509.00481", "authors": ["Anton Wolter", "Georgios Vidalakis", "Michael Yu", "Ankit Grover", "Vaishali Dhanoa"], "title": "Multi-Agent Data Visualization and Narrative Generation", "comment": null, "summary": "Recent advancements in the field of AI agents have impacted the way we work,\nenabling greater automation and collaboration between humans and agents. In the\ndata visualization field, multi-agent systems can be useful for employing\nagents throughout the entire data-to-communication pipeline. We present a\nlightweight multi-agent system that automates the data analysis workflow, from\ndata exploration to generating coherent visual narratives for insight\ncommunication. Our approach combines a hybrid multi-agent architecture with\ndeterministic components, strategically externalizing critical logic from LLMs\nto improve transparency and reliability. The system delivers granular, modular\noutputs that enable surgical modifications without full regeneration,\nsupporting sustainable human-AI collaboration. We evaluated our system across 4\ndiverse datasets, demonstrating strong generalizability, narrative quality, and\ncomputational efficiency with minimal dependencies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u6570\u636e\u5206\u6790\u5de5\u4f5c\u6d41\uff0c\u4ece\u6570\u636e\u63a2\u7d22\u5230\u751f\u6210\u8fde\u8d2f\u7684\u53ef\u89c6\u5316\u53d9\u8ff0\uff0c\u652f\u6301\u53ef\u6301\u7eed\u7684\u4eba\u673a\u534f\u4f5c\u3002", "motivation": "AI\u667a\u80fd\u4f53\u9886\u57df\u7684\u8fdb\u5c55\u5f71\u54cd\u4e86\u5de5\u4f5c\u65b9\u5f0f\uff0c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u53ef\u4ee5\u5728\u6570\u636e\u53ef\u89c6\u5316\u9886\u57df\u7684\u6570\u636e\u5230\u901a\u4fe1\u5168\u6d41\u7a0b\u4e2d\u53d1\u6325\u4f5c\u7528\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u81ea\u52a8\u5316\u548c\u4eba\u673a\u534f\u4f5c\u3002", "method": "\u91c7\u7528\u6df7\u5408\u591a\u667a\u80fd\u4f53\u67b6\u6784\u4e0e\u786e\u5b9a\u6027\u7ec4\u4ef6\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u5c06\u5173\u952e\u903b\u8f91\u4eceLLM\u4e2d\u5916\u90e8\u5316\u4ee5\u63d0\u9ad8\u900f\u660e\u5ea6\u548c\u53ef\u9760\u6027\uff0c\u63d0\u4f9b\u6a21\u5757\u5316\u8f93\u51fa\u652f\u6301\u5c40\u90e8\u4fee\u6539\u3002", "result": "\u57284\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3001\u53d9\u8ff0\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u4e14\u4f9d\u8d56\u9879\u6700\u5c11\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u6210\u529f\u5b9e\u73b0\u4e86\u4ece\u6570\u636e\u63a2\u7d22\u5230\u6d1e\u5bdf\u6c9f\u901a\u7684\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\uff0c\u901a\u8fc7\u5916\u90e8\u5316\u5173\u952e\u903b\u8f91\u63d0\u9ad8\u4e86\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u548c\u53ef\u9760\u6027\uff0c\u652f\u6301\u53ef\u6301\u7eed\u7684\u4eba\u673a\u534f\u4f5c\u3002"}}
{"id": "2509.00561", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00561", "abs": "https://arxiv.org/abs/2509.00561", "authors": ["Yuwen Pu", "Zhou Feng", "Chunyi Zhou", "Jiahao Chen", "Chunqiang Hu", "Haibo Hu", "Shouling Ji"], "title": "FreeTalk:A plug-and-play and black-box defense against speech synthesis attacks", "comment": "under review", "summary": "Recently, speech assistant and speech verification have been used in many\nfields, which brings much benefit and convenience for us. However, when we\nenjoy these speech applications, our speech may be collected by attackers for\nspeech synthesis. For example, an attacker generates some inappropriate\npolitical opinions with the characteristic of the victim's voice by obtaining a\npiece of the victim's speech, which will greatly influence the victim's\nreputation. Specifically, with the appearance of some zero-shot voice\nconversion methods, the cost of speech synthesis attacks has been further\nreduced, which also brings greater challenges to user voice security and\nprivacy. Some researchers have proposed the corresponding privacy-preserving\nmethods. However, the existing approaches have some non-negligible drawbacks:\nlow transferability and robustness, high computational overhead. These\ndeficiencies seriously limit the existing method deployed in practical\nscenarios. Therefore, in this paper, we propose a lightweight, robust,\nplug-and-play privacy preservation method against speech synthesis attacks in a\nblack-box setting. Our method generates and adds a frequency-domain\nperturbation to the original speech to achieve privacy protection and high\nspeech quality. Then, we present a data augmentation strategy and noise\nsmoothing mechanism to improve the robustness of the proposed method. Besides,\nto reduce the user's defense overhead, we also propose a novel identity-wise\nprotection mechanism. It can generate a universal perturbation for one speaker\nand support privacy preservation for speech of any length. Finally, we conduct\nextensive experiments on 5 speech synthesis models, 5 speech verification\nmodels, 1 speech recognition model, and 2 datasets. The experimental results\ndemonstrate that our method has satisfying privacy-preserving performance, high\nspeech quality, and utility.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u9a8c\u8bc1\u6027\u5f3a\u7684\u63d2\u5165\u5f0f\u8bed\u97f3\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\uff0c\u901a\u8fc7\u6dfb\u52a0\u9891\u57df\u6270\u52a8\u6765\u9632\u8303\u9ed1\u76d2\u8bed\u97f3\u5408\u6210\u653b\u51fb\uff0c\u540c\u65f6\u4fdd\u6301\u8bed\u97f3\u8d28\u91cf\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u968f\u7740\u8bed\u97f3\u52a9\u624b\u548c\u8bed\u97f3\u9a8c\u8bc1\u7684\u666e\u53ca\uff0c\u653b\u51fb\u8005\u53ef\u80fd\u6536\u96c6\u7528\u6237\u8bed\u97f3\u8fdb\u884c\u8bed\u97f3\u5408\u6210\u653b\u51fb\uff0c\u5f88\u5927\u5f71\u54cd\u7528\u6237\u58f0\u97f3\u5b89\u5168\u548c\u9690\u79c1\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u8f6c\u79fb\u6027\u4f4e\u3001\u9a8c\u8bc1\u6027\u5dee\u3001\u8ba1\u7b97\u5f00\u9500\u9ad8\u7b49\u7f3a\u70b9\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u90e8\u7f72\u3002", "method": "\u63d0\u51fa\u5729\u9891\u57df\u6dfb\u52a0\u6270\u52a8\u6765\u4fdd\u62a4\u8bed\u97f3\u9690\u79c1\uff0c\u91c7\u7528\u6570\u636e\u589e\u5e8f\u7b56\u7565\u548c\u566a\u58f0\u5e73\u6ed1\u673a\u5236\u63d0\u9ad8\u9a8c\u8bc1\u6027\uff0c\u5e76\u63d0\u51fa\u8eab\u4efd\u7ea7\u522b\u4fdd\u62a4\u673a\u5236\u6765\u751f\u6210\u901a\u7528\u6270\u52a8\u3001\u652f\u6301\u4efb\u610f\u957f\u5ea6\u8bed\u97f3\u4fdd\u62a4\u3002", "result": "\u57285\u4e2a\u8bed\u97f3\u5408\u6210\u6a21\u578b\u30015\u4e2a\u8bed\u97f3\u9a8c\u8bc1\u6a21\u578b\u30011\u4e2a\u8bed\u97f3\u8bc6\u522b\u6a21\u578b\u548c2\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660e\u65b9\u6cd5\u5177\u6709\u6ee1\u610f\u7684\u9690\u79c1\u4fdd\u62a4\u6027\u80fd\u3001\u9ad8\u8bed\u97f3\u8d28\u91cf\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u8bed\u97f3\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\u7684\u7f3a\u9677\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u9a8c\u8bc1\u6027\u5f3a\u3001\u5373\u63d2\u5373\u7528\u7684\u9ed1\u76d2\u8bed\u97f3\u9690\u79c1\u4fdd\u62a4\u65b9\u6848\uff0c\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u4ef7\u503c\u3002"}}
{"id": "2509.02022", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.02022", "abs": "https://arxiv.org/abs/2509.02022", "authors": ["Bj\u00f8rnar Haugstad J\u00e5tten", "Simon Boye J\u00f8rgensen", "Rasmus Petersen", "Ra\u00fal Pardo"], "title": "Scalable Thread-Safety Analysis of Java Classes with CodeQL", "comment": null, "summary": "In object-oriented languages software developers rely on thread-safe classes\nto implement concurrent applications. However, determining whether a class is\nthread-safe is a challenging task. This paper presents a highly scalable method\nto analyze thread-safety in Java classes. We provide a definition of\nthread-safety for Java classes founded on the correctness principle of the Java\nmemory model, data race freedom. We devise a set of properties for Java classes\nthat are proven to ensure thread-safety. We encode these properties in the\nstatic analysis tool CodeQL to automatically analyze Java source code. We\nperform an evaluation on the top 1000 GitHub repositories. The evaluation\ncomprises 3632865 Java classes; with 1992 classes annotated as @ThreadSafe from\n71 repositories. These repositories include highly popular software such as\nApache Flink (24.6k stars), Facebook Fresco (17.1k stars), PrestoDB (16.2k\nstarts), and gRPC (11.6k starts). Our queries detected thousands of\nthread-safety errors. The running time of our queries is below 2 minutes for\nrepositories up to 200k lines of code, 20k methods, 6000 fields, and 1200\nclasses. We have submitted a selection of detected concurrency errors as PRs,\nand developers positively reacted to these PRs. We have submitted our CodeQL\nqueries to the main CodeQL repository, and they are currently in the process of\nbecoming available as part of GitHub actions. The results demonstrate the\napplicability and scalability of our method to analyze thread-safety in\nreal-world code bases.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u53ef\u6269\u5c55\u7684\u9759\u6001\u5206\u6790\u65b9\u6cd5\uff0c\u4f7f\u7528CodeQL\u5de5\u5177\u81ea\u52a8\u68c0\u6d4bJava\u7c7b\u7684\u7ebf\u7a0b\u5b89\u5168\u6027\u95ee\u9898\uff0c\u5728\u5927\u89c4\u6a21\u5b9e\u9645\u4ee3\u7801\u5e93\u4e2d\u53d1\u73b0\u4e86\u6570\u5343\u4e2a\u5e76\u53d1\u9519\u8bef\u3002", "motivation": "\u5728\u9762\u5411\u5bf9\u8c61\u8bed\u8a00\u4e2d\uff0c\u5f00\u53d1\u4eba\u5458\u4f9d\u8d56\u7ebf\u7a0b\u5b89\u5168\u7c7b\u6765\u5b9e\u73b0\u5e76\u53d1\u5e94\u7528\uff0c\u4f46\u5224\u65ad\u4e00\u4e2a\u7c7b\u662f\u5426\u7ebf\u7a0b\u5b89\u5168\u662f\u4e00\u9879\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\u3002", "method": "\u57fa\u4e8eJava\u5185\u5b58\u6a21\u578b\u7684\u6570\u636e\u7ade\u4e89\u81ea\u7531\u539f\u5219\uff0c\u8bbe\u8ba1\u4e86\u4e00\u7ec4\u786e\u4fdd\u7ebf\u7a0b\u5b89\u5168\u6027\u7684\u5c5e\u6027\uff0c\u5e76\u5728CodeQL\u9759\u6001\u5206\u6790\u5de5\u5177\u4e2d\u7f16\u7801\u8fd9\u4e9b\u5c5e\u6027\u6765\u81ea\u52a8\u5206\u6790Java\u6e90\u4ee3\u7801\u3002", "result": "\u5728GitHub\u524d1000\u4e2a\u5e93\u76843632865\u4e2aJava\u7c7b\u4e2d\u8bc6\u522b\u51fa\u6570\u5343\u4e2a\u7ebf\u7a0b\u5b89\u5168\u6027\u9519\u8bef\u3002\u5206\u6790\u65f6\u95f4\u572820\u4e07\u884c\u4ee3\u7801\u4ee5\u5185\u7684\u5e93\u4e2d\u4ec5\u9700\u4e0d\u52302\u5206\u949f\u3002\u5f00\u53d1\u8005\u5bf9\u63d0\u4ea4\u7684\u5e76\u53d1\u9519\u8befPR\u53cd\u9988\u79ef\u6781\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u771f\u5b9e\u4ee3\u7801\u5e93\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u9002\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u5df2\u63d0\u4ea4\u5230CodeQL\u4e3b\u5e93\u5e76\u5c06\u6210\u4e3aGitHub Actions\u7684\u4e00\u90e8\u5206\u3002"}}
{"id": "2509.00507", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00507", "abs": "https://arxiv.org/abs/2509.00507", "authors": ["Zhang Lai Bin", "Zhen Bin It"], "title": "Artificial Intelligence-Based Analysis of Ice Cream Melting Behavior Under Various Ingredients", "comment": null, "summary": "The stability of ice cream during melting is a critical factor for consumer's\nacceptance and product quality. With the commonly added stabilizer to improve\ntexture, structure and slower melting as the factors to analyze. This report\nexplores the effects of locust bean gum, guar gum, maltodextrin, and\ncarrageenan on the melting behavior of homemade ice cream. The main objective\nwas to assess how these additives influence melting resistance and to identify\na more cost-effective recipe formulation. Ice cream samples incorporating each\nadditive were prepared and subjected to melting tests under controlled\nconditions. Timelapse recordings were used to capture and analyze the\nprogression of melting over time. Python and OpenCV is used for process and\nanalysis. Observations revealed that all samples retained a foam-like structure\neven after melting, suggesting the stabilizers contributed to the formation of\na stable air-cell matrix. Furthermore, when the melted samples were re-frozen\nand subsequently melted again, they displayed increased sturdiness, indicating\nimproved resilience of the ice cream structure. Comparative analysis of the\ndifferent stabilizers highlighted variations in their effectiveness, with some\noffering stronger melting resistance and structural support than others.\nOverall, the findings provide insights into the functional roles of commonly\nused food additives in ice cream formulation. By evaluating both performance\nand cost, this study demonstrates the potential for developing recipes that\nbalance durability with economic efficiency, contributing to practical\napplications in both small-scale and commercial ice cream production.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u523a\u69d0\u8c46\u80f6\u3001\u74dc\u5c14\u80f6\u3001\u9ea6\u82bd\u7cca\u7cbe\u548c\u5361\u62c9\u80f6\u5bf9\u81ea\u5236\u51b0\u6dc7\u6dcb\u878d\u5316\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u8ba1\u7b97\u673a\u89c6\u89c9\u5206\u6790\u53d1\u73b0\u8fd9\u4e9b\u7a33\u5b9a\u5242\u80fd\u5f62\u6210\u7a33\u5b9a\u7684\u6c14\u6ce1\u57fa\u8d28\u7ed3\u6784\uff0c\u63d0\u9ad8\u51b0\u6dc7\u6dcb\u7684\u878d\u5316\u6297\u6027\u548c\u7ed3\u6784\u97e7\u6027\u3002", "motivation": "\u51b0\u6dc7\u6dcb\u7684\u878d\u5316\u7a33\u5b9a\u6027\u662f\u5f71\u54cd\u6d88\u8d39\u8005\u63a5\u53d7\u5ea6\u548c\u4ea7\u54c1\u8d28\u91cf\u7684\u5173\u952e\u56e0\u7d20\uff0c\u9700\u8981\u7814\u7a76\u4e0d\u540c\u7a33\u5b9a\u5242\u5bf9\u878d\u5316\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u5e76\u5bfb\u627e\u66f4\u5177\u6210\u672c\u6548\u76ca\u7684\u914d\u65b9\u65b9\u6848\u3002", "method": "\u5236\u5907\u542b\u4e0d\u540c\u6dfb\u52a0\u5242\u7684\u51b0\u6dc7\u6dcb\u6837\u54c1\uff0c\u5728\u53d7\u63a7\u6761\u4ef6\u4e0b\u8fdb\u884c\u878d\u5316\u6d4b\u8bd5\uff0c\u4f7f\u7528\u5ef6\u65f6\u6444\u5f71\u8bb0\u5f55\u878d\u5316\u8fc7\u7a0b\uff0c\u5e76\u5229\u7528Python\u548cOpenCV\u8fdb\u884c\u56fe\u50cf\u5904\u7406\u548c\u5206\u6790\u3002", "result": "\u6240\u6709\u6837\u54c1\u878d\u5316\u540e\u4ecd\u4fdd\u6301\u6ce1\u6cab\u72b6\u7ed3\u6784\uff0c\u8868\u660e\u7a33\u5b9a\u5242\u6709\u52a9\u4e8e\u5f62\u6210\u7a33\u5b9a\u7684\u6c14\u6ce1\u57fa\u8d28\uff1b\u91cd\u65b0\u51b7\u51bb\u540e\u518d\u878d\u5316\u7684\u6837\u54c1\u663e\u793a\u51fa\u66f4\u5f3a\u7684\u7ed3\u6784\u97e7\u6027\uff1b\u4e0d\u540c\u7a33\u5b9a\u5242\u7684\u6548\u679c\u5b58\u5728\u5dee\u5f02\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u5e38\u7528\u98df\u54c1\u6dfb\u52a0\u5242\u5728\u51b0\u6dc7\u6dcb\u914d\u65b9\u4e2d\u7684\u529f\u80fd\u4f5c\u7528\uff0c\u901a\u8fc7\u8bc4\u4f30\u6027\u80fd\u548c\u6210\u672c\uff0c\u8bc1\u660e\u4e86\u5f00\u53d1\u5e73\u8861\u8010\u7528\u6027\u548c\u7ecf\u6d4e\u6548\u7387\u7684\u914d\u65b9\u7684\u6f5c\u529b\uff0c\u5bf9\u5c0f\u578b\u548c\u5546\u4e1a\u51b0\u6dc7\u6dcb\u751f\u4ea7\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.00615", "categories": ["cs.CR", "cs.AI", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.00615", "abs": "https://arxiv.org/abs/2509.00615", "authors": ["Narasimha Raghavan Veeraragavan", "Jan Franz Nyg\u00e5rd"], "title": "Federated Survival Analysis with Node-Level Differential Privacy: Private Kaplan-Meier Curves", "comment": "This is the author's accepted version of the paper in IEEE FLTA 2025.\n  The final version of record will appear in Proceedings of the IEEE\n  International Conference on Federated Learning Technologies and Applications\n  (FLTA 2025)", "summary": "We investigate how to calculate Kaplan-Meier survival curves across multiple\nhealth-care jurisdictions while protecting patient privacy with node-level\ndifferential privacy. Each site discloses its curve only once, adding Laplace\nnoise whose scale is determined by the length of the common time grid; the\nserver then averages the noisy curves, so the overall privacy budget remains\nunchanged. We benchmark four one-shot smoothing techniques: Discrete Cosine\nTransform, Haar Wavelet shrinkage, adaptive Total-Variation denoising, and a\nparametric Weibull fit on the NCCTG lung-cancer cohort under five privacy\nlevels and three partition scenarios (uniform, moderately skewed, highly\nimbalanced). Total-Variation gives the best mean accuracy, whereas the\nfrequency-domain smoothers offer stronger worst-case robustness and the Weibull\nmodel shows the most stable behaviour at the strictest privacy setting. Across\nall methods the released curves keep the empirical log-rank type-I error below\nfifteen percent for privacy budgets of 0.5 and higher, demonstrating that\nclinically useful survival information can be shared without iterative training\nor heavy cryptography.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u5982\u4f55\u5728\u4fdd\u62a4\u60a3\u8005\u9690\u79c1\u7684\u524d\u63d0\u4e0b\uff0c\u901a\u8fc7\u8282\u70b9\u7ea7\u5dee\u5206\u9690\u79c1\u8ba1\u7b97\u8de8\u591a\u4e2a\u533b\u7597\u7ba1\u8f96\u533a\u7684Kaplan-Meier\u751f\u5b58\u66f2\u7ebf\u3002\u6bcf\u4e2a\u7ad9\u70b9\u4ec5\u62ab\u9732\u4e00\u6b21\u66f2\u7ebf\uff0c\u6dfb\u52a0\u62c9\u666e\u62c9\u65af\u566a\u58f0\uff0c\u670d\u52a1\u5668\u5e73\u5747\u566a\u58f0\u66f2\u7ebf\uff0c\u6574\u4f53\u9690\u79c1\u9884\u7b97\u4fdd\u6301\u4e0d\u53d8\u3002", "motivation": "\u533b\u7597\u6570\u636e\u901a\u5e38\u5206\u5e03\u5728\u591a\u4e2a\u7ba1\u8f96\u533a\u57df\uff0c\u9700\u8981\u5728\u4e0d\u6cc4\u9732\u60a3\u8005\u9690\u79c1\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u751f\u5b58\u5206\u6790\u3002\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u8fed\u4ee3\u8bad\u7ec3\u6216\u91cd\u52a0\u5bc6\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "\u4f7f\u7528\u56db\u79cd\u4e00\u6b21\u6027\u5e73\u6ed1\u6280\u672f\uff1a\u79bb\u6563\u4f59\u5f26\u53d8\u6362\u3001Haar\u5c0f\u6ce2\u6536\u7f29\u3001\u81ea\u9002\u5e94\u5168\u53d8\u5dee\u53bb\u566a\u548c\u53c2\u6570\u5316Weibull\u62df\u5408\uff0c\u5728\u4e94\u79cd\u9690\u79c1\u7ea7\u522b\u548c\u4e09\u79cd\u5206\u533a\u573a\u666f\u4e0b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5168\u53d8\u5dee\u53bb\u566a\u83b7\u5f97\u6700\u4f73\u5e73\u5747\u7cbe\u5ea6\uff0c\u9891\u57df\u5e73\u6ed1\u5668\u63d0\u4f9b\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\uff0cWeibull\u6a21\u578b\u5728\u6700\u4e25\u683c\u9690\u79c1\u8bbe\u7f6e\u4e0b\u8868\u73b0\u6700\u7a33\u5b9a\u3002\u6240\u6709\u65b9\u6cd5\u5728\u9690\u79c1\u9884\u7b97\u22650.5\u65f6\u90fd\u80fd\u4fdd\u6301\u7ecf\u9a8clog-rank\u7c7b\u578bI\u9519\u8bef\u4f4e\u4e8e15%\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u65e0\u9700\u8fed\u4ee3\u8bad\u7ec3\u6216\u91cd\u52a0\u5bc6\u5373\u53ef\u5171\u4eab\u5177\u6709\u4e34\u5e8a\u5b9e\u7528\u6027\u7684\u751f\u5b58\u4fe1\u606f\uff0c\u4e3a\u8de8\u8f96\u533a\u533b\u7597\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u9690\u79c1\u4fdd\u62a4\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.02025", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.02025", "abs": "https://arxiv.org/abs/2509.02025", "authors": ["Junda He", "Zhou Yang", "Jieke Shi", "Chengran Yang", "Kisub Kim", "Bowen Xu", "Xin Zhou", "David Lo"], "title": "Curiosity-Driven Testing for Sequential Decision-Making Process", "comment": "Update the Replication Package URL", "summary": "Sequential decision-making processes (SDPs) are fundamental for complex\nreal-world challenges, such as autonomous driving, robotic control, and traffic\nmanagement. While recent advances in Deep Learning (DL) have led to mature\nsolutions for solving these complex problems, SDMs remain vulnerable to\nlearning unsafe behaviors, posing significant risks in safety-critical\napplications. However, developing a testing framework for SDMs that can\nidentify a diverse set of crash-triggering scenarios remains an open challenge.\nTo address this, we propose CureFuzz, a novel curiosity-driven black-box fuzz\ntesting approach for SDMs. CureFuzz proposes a curiosity mechanism that allows\na fuzzer to effectively explore novel and diverse scenarios, leading to\nimproved detection of crashtriggering scenarios. Additionally, we introduce a\nmulti-objective seed selection technique to balance the exploration of novel\nscenarios and the generation of crash-triggering scenarios, thereby optimizing\nthe fuzzing process. We evaluate CureFuzz on various SDMs and experimental\nresults demonstrate that CureFuzz outperforms the state-of-the-art method by a\nsubstantial margin in the total number of faults and distinct types of\ncrash-triggering scenarios. We also demonstrate that the crash-triggering\nscenarios found by CureFuzz can repair SDMs, highlighting CureFuzz as a\nvaluable tool for testing SDMs and optimizing their performance.", "AI": {"tldr": "CureFuzz\u662f\u4e00\u79cd\u57fa\u4e8e\u597d\u5947\u5fc3\u7684\u9ed1\u76d2\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u7528\u4e8e\u53d1\u73b0\u5e8f\u5217\u51b3\u7b56\u6a21\u578b\u4e2d\u7684\u5d29\u6e83\u89e6\u53d1\u573a\u666f\uff0c\u901a\u8fc7\u591a\u76ee\u6807\u79cd\u5b50\u9009\u62e9\u5e73\u8861\u65b0\u9896\u573a\u666f\u63a2\u7d22\u548c\u5d29\u6e83\u573a\u666f\u751f\u6210\u3002", "motivation": "\u5e8f\u5217\u51b3\u7b56\u6a21\u578b\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u5bb9\u6613\u5b66\u4e60\u4e0d\u5b89\u5168\u884c\u4e3a\uff0c\u4f46\u73b0\u6709\u7684\u6d4b\u8bd5\u6846\u67b6\u96be\u4ee5\u53d1\u73b0\u591a\u6837\u5316\u7684\u5d29\u6e83\u89e6\u53d1\u573a\u666f\uff0c\u9700\u8981\u65b0\u7684\u6d4b\u8bd5\u65b9\u6cd5\u6765\u63d0\u9ad8\u6a21\u578b\u5b89\u5168\u6027\u3002", "method": "\u63d0\u51fa\u597d\u5947\u5fc3\u9a71\u52a8\u673a\u5236\u63a2\u7d22\u65b0\u9896\u591a\u6837\u7684\u573a\u666f\uff0c\u91c7\u7528\u591a\u76ee\u6807\u79cd\u5b50\u9009\u62e9\u6280\u672f\u5e73\u8861\u63a2\u7d22\u548c\u5d29\u6e83\u573a\u666f\u751f\u6210\uff0c\u4f18\u5316\u6a21\u7cca\u6d4b\u8bd5\u8fc7\u7a0b\u3002", "result": "CureFuzz\u5728\u6545\u969c\u603b\u6570\u548c\u5d29\u6e83\u89e6\u53d1\u573a\u666f\u7c7b\u578b\u591a\u6837\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\uff0c\u53d1\u73b0\u7684\u5d29\u6e83\u573a\u666f\u53ef\u7528\u4e8e\u4fee\u590d\u6a21\u578b\u3002", "conclusion": "CureFuzz\u662f\u6d4b\u8bd5\u5e8f\u5217\u51b3\u7b56\u6a21\u578b\u548c\u4f18\u5316\u5176\u6027\u80fd\u7684\u6709\u6548\u5de5\u5177\uff0c\u80fd\u591f\u63d0\u9ad8\u6a21\u578b\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2509.00510", "categories": ["cs.AI", "cs.CL", "68T99", "I.2.11; I.2.8; I.2.6"], "pdf": "https://arxiv.org/pdf/2509.00510", "abs": "https://arxiv.org/abs/2509.00510", "authors": ["Li Weigang", "Pedro Carvalho Brom", "Lucas Ramson Siefert"], "title": "LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain", "comment": "24 pages, 5 figures", "summary": "We propose a novel SuperBrain framework for collective intelligence, grounded\nin the co-evolution of large language models (LLMs) and human users. Unlike\nstatic prompt engineering or isolated agent simulations, our approach\nemphasizes a dynamic pathway from Subclass Brain to Superclass Brain: (1) A\nSubclass Brain arises from persistent, personalized interaction between a user\nand an LLM, forming a cognitive dyad with adaptive learning memory. (2) Through\nGA-assisted forward-backward evolution, these dyads iteratively refine prompts\nand task performance. (3) Multiple Subclass Brains coordinate via Swarm\nIntelligence, optimizing across multi-objective fitness landscapes and\nexchanging distilled heuristics. (4) Their standardized behaviors and cognitive\nsignatures integrate into a Superclass Brain, an emergent meta-intelligence\ncapable of abstraction, generalization and self-improvement. We outline the\ntheoretical constructs, present initial implementations (e.g., UAV scheduling,\nKU/KI keyword filtering) and propose a registry for cross-dyad knowledge\nconsolidation. This work provides both a conceptual foundation and an\narchitectural roadmap toward scalable, explainable and ethically aligned\ncollective AI.", "AI": {"tldr": "\u63d0\u51fa\u4e86SuperBrain\u6846\u67b6\uff0c\u901a\u8fc7LLM\u4e0e\u4eba\u7c7b\u7528\u6237\u7684\u534f\u540c\u8fdb\u5316\u5b9e\u73b0\u96c6\u4f53\u667a\u80fd\uff0c\u5305\u542b\u4ece\u5b50\u7c7b\u5927\u8111\u5230\u8d85\u7c7b\u5927\u8111\u7684\u52a8\u6001\u6f14\u5316\u8def\u5f84", "motivation": "\u89e3\u51b3\u9759\u6001\u63d0\u793a\u5de5\u7a0b\u548c\u5b64\u7acb\u667a\u80fd\u4f53\u6a21\u62df\u7684\u5c40\u9650\u6027\uff0c\u6784\u5efa\u52a8\u6001\u3001\u53ef\u6269\u5c55\u4e14\u7b26\u5408\u4f26\u7406\u7684\u96c6\u4f53\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf", "method": "\u56db\u9636\u6bb5\u65b9\u6cd5\uff1a1)\u7528\u6237\u4e0eLLM\u5f62\u6210\u8ba4\u77e5\u4e8c\u5143\u7ec4\uff1b2)\u9057\u4f20\u7b97\u6cd5\u8f85\u52a9\u7684\u524d\u5411-\u540e\u5411\u8fdb\u5316\uff1b3)\u7fa4\u4f53\u667a\u80fd\u534f\u8c03\uff1b4)\u6807\u51c6\u5316\u884c\u4e3a\u6574\u5408\u4e3a\u8d85\u7c7b\u5927\u8111", "result": "\u63d0\u51fa\u4e86\u7406\u8bba\u6846\u67b6\u548c\u521d\u6b65\u5b9e\u73b0\uff08\u5982\u65e0\u4eba\u673a\u8c03\u5ea6\u3001\u5173\u952e\u8bcd\u8fc7\u6ee4\uff09\uff0c\u5efa\u7acb\u4e86\u8de8\u4e8c\u5143\u7ec4\u77e5\u8bc6\u6574\u5408\u7684\u6ce8\u518c\u673a\u5236", "conclusion": "\u4e3a\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u4e14\u7b26\u5408\u4f26\u7406\u7684\u96c6\u4f53AI\u63d0\u4f9b\u4e86\u6982\u5ff5\u57fa\u7840\u548c\u67b6\u6784\u8def\u7ebf\u56fe"}}
{"id": "2509.00634", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00634", "abs": "https://arxiv.org/abs/2509.00634", "authors": ["Chaoyu Zhang", "Heng Jin", "Shanghao Shi", "Hexuan Yu", "Sydney Johns", "Y. Thomas Hou", "Wenjing Lou"], "title": "Enabling Trustworthy Federated Learning via Remote Attestation for Mitigating Byzantine Threats", "comment": null, "summary": "Federated Learning (FL) has gained significant attention for its\nprivacy-preserving capabilities, enabling distributed devices to\ncollaboratively train a global model without sharing raw data. However, its\ndistributed nature forces the central server to blindly trust the local\ntraining process and aggregate uncertain model updates, making it susceptible\nto Byzantine attacks from malicious participants, especially in\nmission-critical scenarios. Detecting such attacks is challenging due to the\ndiverse knowledge across clients, where variations in model updates may stem\nfrom benign factors, such as non-IID data, rather than adversarial behavior.\nExisting data-driven defenses struggle to distinguish malicious updates from\nnatural variations, leading to high false positive rates and poor filtering\nperformance.\n  To address this challenge, we propose Sentinel, a remote attestation\n(RA)-based scheme for FL systems that regains client-side transparency and\nmitigates Byzantine attacks from a system security perspective. Our system\nemploys code instrumentation to track control-flow and monitor critical\nvariables in the local training process. Additionally, we utilize a trusted\ntraining recorder within a Trusted Execution Environment (TEE) to generate an\nattestation report, which is cryptographically signed and securely transmitted\nto the server. Upon verification, the server ensures that legitimate client\ntraining processes remain free from program behavior violation or data\nmanipulation, allowing only trusted model updates to be aggregated into the\nglobal model. Experimental results on IoT devices demonstrate that Sentinel\nensures the trustworthiness of the local training integrity with low runtime\nand memory overhead.", "AI": {"tldr": "Sentinel\u662f\u4e00\u4e2a\u57fa\u4e8e\u8fdc\u7a0b\u8ba4\u8bc1\u7684\u8054\u90a6\u5b66\u4e60\u5b89\u5168\u65b9\u6848\uff0c\u901a\u8fc7\u4ee3\u7801\u63d2\u6869\u548c\u53ef\u4fe1\u6267\u884c\u73af\u5883\u6765\u68c0\u6d4b\u548c\u9632\u5fa1\u62dc\u5360\u5ead\u653b\u51fb\uff0c\u786e\u4fdd\u672c\u5730\u8bad\u7ec3\u8fc7\u7a0b\u7684\u5b8c\u6574\u6027\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u9762\u4e34\u62dc\u5360\u5ead\u653b\u51fb\u5a01\u80c1\uff0c\u73b0\u6709\u6570\u636e\u9a71\u52a8\u9632\u5fa1\u65b9\u6cd5\u96be\u4ee5\u533a\u5206\u6076\u610f\u66f4\u65b0\u548c\u826f\u6027\u6570\u636e\u53d8\u5f02\uff0c\u5bfc\u81f4\u9ad8\u8bef\u62a5\u7387\u548c\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u91c7\u7528\u4ee3\u7801\u63d2\u6869\u8ffd\u8e2a\u63a7\u5236\u6d41\u548c\u76d1\u63a7\u5173\u952e\u53d8\u91cf\uff0c\u5728\u53ef\u4fe1\u6267\u884c\u73af\u5883\u4e2d\u4f7f\u7528\u53ef\u4fe1\u8bad\u7ec3\u8bb0\u5f55\u5668\u751f\u6210\u52a0\u5bc6\u7b7e\u540d\u7684\u8ba4\u8bc1\u62a5\u544a\uff0c\u670d\u52a1\u5668\u9a8c\u8bc1\u540e\u53ea\u805a\u5408\u53ef\u4fe1\u6a21\u578b\u66f4\u65b0\u3002", "result": "\u5728\u7269\u8054\u7f51\u8bbe\u5907\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSentinel\u80fd\u4ee5\u4f4e\u8fd0\u884c\u65f6\u548c\u5185\u5b58\u5f00\u9500\u786e\u4fdd\u672c\u5730\u8bad\u7ec3\u5b8c\u6574\u6027\u7684\u53ef\u4fe1\u5ea6\u3002", "conclusion": "Sentinel\u4ece\u7cfb\u7edf\u5b89\u5168\u89d2\u5ea6\u91cd\u65b0\u83b7\u5f97\u5ba2\u6237\u7aef\u900f\u660e\u5ea6\uff0c\u6709\u6548\u7f13\u89e3\u62dc\u5360\u5ead\u653b\u51fb\uff0c\u4e3a\u8054\u90a6\u5b66\u4e60\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u5b89\u5168\u4fdd\u969c\u673a\u5236\u3002"}}
{"id": "2509.02150", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.02150", "abs": "https://arxiv.org/abs/2509.02150", "authors": ["Pin Ji", "Yang Feng", "Zongtai Li", "Xiangchi Zhou", "Jia Liu", "Jun Sun", "Zhihong Zhao"], "title": "Txt2Sce: Scenario Generation for Autonomous Driving System Testing Based on Textual Reports", "comment": null, "summary": "With the rapid advancement of deep learning and related technologies,\nAutonomous Driving Systems (ADSs) have made significant progress and are\ngradually being widely applied in safety-critical fields. However, numerous\naccident reports show that ADSs still encounter challenges in complex\nscenarios. As a result, scenario-based testing has become essential for\nidentifying defects and ensuring reliable performance. In particular,\nreal-world accident reports offer valuable high-risk scenarios for more\ntargeted ADS testing. Despite their potential, existing methods often rely on\nvisual data, which demands large memory and manual annotation. Additionally,\nsince existing methods do not adopt standardized scenario formats (e.g.,\nOpenSCENARIO), the generated scenarios are often tied to specific platforms and\nADS implementations, limiting their scalability and portability. To address\nthese challenges, we propose Txt2Sce, a method for generating test scenarios in\nOpenSCENARIO format based on textual accident reports. Txt2Sce first uses a LLM\nto convert textual accident reports into corresponding OpenSCENARIO scenario\nfiles. It then generates a derivation-based scenario file tree through scenario\ndisassembly, scenario block mutation, and scenario assembly. By utilizing the\nderivation relationships between nodes in the scenario tree, Txt2Sce helps\ndevelopers identify the scenario conditions that trigger unexpected behaviors\nof ADSs. In the experiments, we employ Txt2Sce to generate 33 scenario file\ntrees, resulting in a total of 4,373 scenario files for testing the open-source\nADS, Autoware. The experimental results show that Txt2Sce successfully converts\ntextual reports into valid OpenSCENARIO files, enhances scenario diversity\nthrough mutation, and effectively detects unexpected behaviors of Autoware in\nterms of safety, smartness, and smoothness.", "AI": {"tldr": "Txt2Sce\u662f\u4e00\u4e2a\u57fa\u4e8e\u6587\u672c\u4e8b\u6545\u62a5\u544a\u751f\u6210OpenSCENARIO\u683c\u5f0f\u6d4b\u8bd5\u573a\u666f\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7LLM\u8f6c\u6362\u3001\u573a\u666f\u89e3\u6784\u3001\u53d8\u5f02\u548c\u91cd\u7ec4\u6765\u589e\u5f3a\u573a\u666f\u591a\u6837\u6027\uff0c\u6709\u6548\u68c0\u6d4b\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u5f02\u5e38\u884c\u4e3a\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u89c6\u89c9\u6570\u636e\u7684\u573a\u666f\u751f\u6210\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u5185\u5b58\u548c\u4eba\u5de5\u6807\u6ce8\uff0c\u4e14\u7f3a\u4e4f\u6807\u51c6\u5316\u683c\u5f0f\u5bfc\u81f4\u53ef\u6269\u5c55\u6027\u548c\u53ef\u79fb\u690d\u6027\u53d7\u9650\u3002\u771f\u5b9e\u4e8b\u6545\u62a5\u544a\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u9ad8\u98ce\u9669\u573a\u666f\uff0c\u4f46\u9700\u8981\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u6765\u5229\u7528\u8fd9\u4e9b\u6587\u672c\u4fe1\u606f\u3002", "method": "\u4f7f\u7528LLM\u5c06\u6587\u672c\u4e8b\u6545\u62a5\u544a\u8f6c\u6362\u4e3aOpenSCENARIO\u6587\u4ef6\uff0c\u901a\u8fc7\u573a\u666f\u89e3\u6784\u3001\u573a\u666f\u5757\u53d8\u5f02\u548c\u573a\u666f\u91cd\u7ec4\u751f\u6210\u57fa\u4e8e\u63a8\u5bfc\u7684\u573a\u666f\u6587\u4ef6\u6811\uff0c\u5229\u7528\u8282\u70b9\u95f4\u7684\u63a8\u5bfc\u5173\u7cfb\u8bc6\u522b\u89e6\u53d1ADS\u5f02\u5e38\u884c\u4e3a\u7684\u573a\u666f\u6761\u4ef6\u3002", "result": "\u6210\u529f\u751f\u621033\u4e2a\u573a\u666f\u6587\u4ef6\u6811\uff0c\u51714,373\u4e2a\u573a\u666f\u6587\u4ef6\u7528\u4e8e\u6d4b\u8bd5Autoware\u3002\u5b9e\u9a8c\u8868\u660eTxt2Sce\u80fd\u6709\u6548\u8f6c\u6362\u6587\u672c\u62a5\u544a\u4e3a\u6709\u6548OpenSCENARIO\u6587\u4ef6\uff0c\u901a\u8fc7\u53d8\u5f02\u589e\u5f3a\u573a\u666f\u591a\u6837\u6027\uff0c\u5728\u5b89\u5168\u6027\u3001\u667a\u80fd\u6027\u548c\u5e73\u6ed1\u6027\u65b9\u9762\u6210\u529f\u68c0\u6d4b\u5230Autoware\u7684\u5f02\u5e38\u884c\u4e3a\u3002", "conclusion": "Txt2Sce\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u5229\u7528\u6587\u672c\u4e8b\u6545\u62a5\u544a\u751f\u6210\u6807\u51c6\u5316\u6d4b\u8bd5\u573a\u666f\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5de5\u5177\u3002"}}
{"id": "2509.00543", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00543", "abs": "https://arxiv.org/abs/2509.00543", "authors": ["Jayakrishna Duggempudi", "Lu Gao", "Ahmed Senouci", "Zhe Han", "Yunpeng Zhang"], "title": "Text-to-Layout: A Generative Workflow for Drafting Architectural Floor Plans Using LLMs", "comment": null, "summary": "This paper presents the development of an AI-powered workflow that uses Large\nLanguage Models (LLMs) to assist in drafting schematic architectural floor\nplans from natural language prompts. The proposed system interprets textual\ninput to automatically generate layout options including walls, doors, windows,\nand furniture arrangements. It combines prompt engineering, a furniture\nplacement refinement algorithm, and Python scripting to produce spatially\ncoherent draft plans compatible with design tools such as Autodesk Revit. A\ncase study of a mid-sized residential layout demonstrates the approach's\nability to generate functional and structured outputs with minimal manual\neffort. The workflow is designed for transparent replication, with all key\nprompt specifications documented to enable independent implementation by other\nresearchers. In addition, the generated models preserve the full range of\nRevit-native parametric attributes required for direct integration into\nprofessional BIM processes.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684AI\u5de5\u4f5c\u6d41\uff0c\u80fd\u591f\u4ece\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u81ea\u52a8\u751f\u6210\u5efa\u7b51\u5e73\u9762\u56fe\u8349\u7a3f\uff0c\u5305\u62ec\u5899\u4f53\u3001\u95e8\u7a97\u548c\u5bb6\u5177\u5e03\u5c40\uff0c\u5e76\u4e0eRevit\u7b49\u8bbe\u8ba1\u5de5\u5177\u517c\u5bb9\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5efa\u7b51\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u4ece\u6982\u5ff5\u5230\u5177\u4f53\u5e73\u9762\u56fe\u8f6c\u6362\u7684\u6548\u7387\u95ee\u9898\uff0c\u51cf\u5c11\u624b\u52a8\u7ed8\u56fe\u5de5\u4f5c\u91cf\uff0c\u63d0\u9ad8\u8bbe\u8ba1\u81ea\u52a8\u5316\u6c34\u5e73\u3002", "method": "\u7ed3\u5408\u63d0\u793a\u5de5\u7a0b\u3001\u5bb6\u5177\u5e03\u7f6e\u4f18\u5316\u7b97\u6cd5\u548cPython\u811a\u672c\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u89e3\u91ca\u751f\u6210\u7a7a\u95f4\u8fde\u8d2f\u7684\u5e03\u5c40\u65b9\u6848\uff0c\u5e76\u786e\u4fdd\u8f93\u51fa\u4e0eRevit\u539f\u751f\u53c2\u6570\u5316\u5c5e\u6027\u517c\u5bb9\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u80fd\u591f\u4ee5\u6700\u5c11\u7684\u4eba\u5de5\u6295\u5165\u751f\u6210\u529f\u80fd\u6027\u548c\u7ed3\u6784\u5316\u7684\u4f4f\u5b85\u5e03\u5c40\u65b9\u6848\uff0c\u6240\u6709\u5173\u952e\u63d0\u793a\u89c4\u8303\u90fd\u5df2\u6587\u6863\u5316\u4ee5\u4fbf\u590d\u5236\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u6d41\u5b9e\u73b0\u4e86\u4ece\u6587\u672c\u63cf\u8ff0\u5230\u4e13\u4e1aBIM\u6a21\u578b\u7684\u65e0\u7f1d\u8f6c\u6362\uff0c\u4e3a\u5efa\u7b51\u8bbe\u8ba1\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u900f\u660e\u53ef\u590d\u5236\u7684\u7279\u70b9\u3002"}}
{"id": "2509.00647", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00647", "abs": "https://arxiv.org/abs/2509.00647", "authors": ["Yu-Zheng Lin", "Sujan Ghimire", "Abhiram Nandimandalam", "Jonah Michael Camacho", "Unnati Tripathi", "Rony Macwan", "Sicong Shao", "Setareh Rafatirad", "Rozhin Yasaei", "Pratik Satam", "Soheil Salehi"], "title": "LLM-HyPZ: Hardware Vulnerability Discovery using an LLM-Assisted Hybrid Platform for Zero-Shot Knowledge Extraction and Refinement", "comment": "10 pages, 6 figures", "summary": "The rapid growth of hardware vulnerabilities has created an urgent need for\nsystematic and scalable analysis methods. Unlike software flaws, which are\noften patchable post-deployment, hardware weaknesses remain embedded across\nproduct lifecycles, posing persistent risks to processors, embedded devices,\nand IoT platforms. Existing efforts such as the MITRE CWE Hardware List (2021)\nrelied on expert-driven Delphi surveys, which lack statistical rigor and\nintroduce subjective bias, while large-scale data-driven foundations for\nhardware weaknesses have been largely absent. In this work, we propose\nLLM-HyPZ, an LLM-assisted hybrid framework for zero-shot knowledge extraction\nand refinement from vulnerability corpora. Our approach integrates zero-shot\nLLM classification, contextualized embeddings, unsupervised clustering, and\nprompt-driven summarization to mine hardware-related CVEs at scale. Applying\nLLM-HyPZ to the 2021-2024 CVE corpus (114,836 entries), we identified 1,742\nhardware-related vulnerabilities. We distilled them into five recurring themes,\nincluding privilege escalation via firmware and BIOS, memory corruption in\nmobile and IoT systems, and physical access exploits. Benchmarking across seven\nLLMs shows that LLaMA 3.3 70B achieves near-perfect classification accuracy\n(99.5%) on a curated validation set. Beyond methodological contributions, our\nframework directly supported the MITRE CWE Most Important Hardware Weaknesses\n(MIHW) 2025 update by narrowing the candidate search space. Specifically, our\npipeline surfaced 411 of the 1,026 CVEs used for downstream MIHW analysis,\nthereby reducing expert workload and accelerating evidence gathering. These\nresults establish LLM-HyPZ as the first data-driven, scalable approach for\nsystematically discovering hardware vulnerabilities, thereby bridging the gap\nbetween expert knowledge and real-world vulnerability evidence.", "AI": {"tldr": "LLM-HyPZ\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6df7\u5408\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u6f0f\u6d1e\u8bed\u6599\u5e93\u4e2d\u96f6\u6837\u672c\u63d0\u53d6\u548c\u7cbe\u70bc\u786c\u4ef6\u6f0f\u6d1e\u77e5\u8bc6\uff0c\u5728114,836\u4e2aCVE\u6761\u76ee\u4e2d\u8bc6\u522b\u51fa1,742\u4e2a\u786c\u4ef6\u76f8\u5173\u6f0f\u6d1e\uff0c\u51c6\u786e\u7387\u8fbe99.5%\u3002", "motivation": "\u786c\u4ef6\u6f0f\u6d1e\u5177\u6709\u6301\u4e45\u6027\u98ce\u9669\u4e14\u96be\u4ee5\u4fee\u8865\uff0c\u73b0\u6709\u4e13\u5bb6\u9a71\u52a8\u7684\u5206\u6790\u65b9\u6cd5\u7f3a\u4e4f\u7edf\u8ba1\u4e25\u8c28\u6027\u548c\u5b58\u5728\u4e3b\u89c2\u504f\u5dee\uff0c\u9700\u8981\u6570\u636e\u9a71\u52a8\u7684\u53ef\u6269\u5c55\u65b9\u6cd5\u6765\u7cfb\u7edf\u53d1\u73b0\u786c\u4ef6\u6f0f\u6d1e\u3002", "method": "\u6574\u5408\u96f6\u6837\u672cLLM\u5206\u7c7b\u3001\u4e0a\u4e0b\u6587\u5d4c\u5165\u3001\u65e0\u76d1\u7763\u805a\u7c7b\u548c\u63d0\u793a\u9a71\u52a8\u7684\u6458\u8981\u6280\u672f\uff0c\u4eceCVE\u8bed\u6599\u5e93\u4e2d\u5927\u89c4\u6a21\u6316\u6398\u786c\u4ef6\u76f8\u5173\u6f0f\u6d1e\u3002", "result": "\u8bc6\u522b\u51fa1,742\u4e2a\u786c\u4ef6\u76f8\u5173\u6f0f\u6d1e\uff0c\u5f52\u7eb3\u4e3a5\u4e2a\u91cd\u590d\u4e3b\u9898\uff0c\u652f\u6301\u4e86MITRE CWE 2025\u66f4\u65b0\uff0c\u5c06\u5019\u9009\u641c\u7d22\u7a7a\u95f4\u4ece1,026\u4e2aCVE\u7f29\u51cf\u5230411\u4e2a\u3002", "conclusion": "LLM-HyPZ\u662f\u9996\u4e2a\u6570\u636e\u9a71\u52a8\u7684\u53ef\u6269\u5c55\u65b9\u6cd5\uff0c\u7cfb\u7edf\u6027\u5730\u53d1\u73b0\u786c\u4ef6\u6f0f\u6d1e\uff0c\u5f25\u5408\u4e86\u4e13\u5bb6\u77e5\u8bc6\u4e0e\u73b0\u5b9e\u4e16\u754c\u6f0f\u6d1e\u8bc1\u636e\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2509.02221", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.02221", "abs": "https://arxiv.org/abs/2509.02221", "authors": ["Martin Skoglund", "Fredrik Warg", "Anders Thors\u00e9n", "Sasikumar Punnekkat", "Hans Hansson"], "title": "Formalizing Operational Design Domains with the Pkl Language", "comment": "8 pages, 9 figures, IV 2025", "summary": "The deployment of automated functions that can operate without direct human\nsupervision has changed safety evaluation in domains seeking higher levels of\nautomation. Unlike conventional systems that rely on human operators, these\nfunctions require new assessment frameworks to demonstrate that they do not\nintroduce unacceptable risks under real-world conditions. To make a convincing\nsafety claim, the developer must present a thorough justification argument,\nsupported by evidence, that a function is free from unreasonable risk when\noperated in its intended context. The key concept relevant to the presented\nwork is the intended context, often captured by an Operational Design Domain\nspecification (ODD). ODD formalization is challenging due to the need to\nmaintain flexibility in adopting diverse specification formats while preserving\nconsistency and traceability and integrating seamlessly into the development,\nvalidation, and assessment. This paper presents a way to formalize an ODD in\nthe Pkl language, addressing central challenges in specifying ODDs while\nimproving usability through specialized configuration language features. The\napproach is illustrated with an automotive example but can be broadly applied\nto ensure rigorous assessments of operational contexts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528Pkl\u8bed\u8a00\u5f62\u5f0f\u5316\u64cd\u4f5c\u8bbe\u8ba1\u57df(ODD)\u89c4\u8303\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3ODD\u89c4\u8303\u5316\u7684\u6838\u5fc3\u6311\u6218\uff0c\u63d0\u9ad8\u53ef\u7528\u6027\u5e76\u901a\u8fc7\u6c7d\u8f66\u6848\u4f8b\u8fdb\u884c\u8bf4\u660e", "motivation": "\u968f\u7740\u81ea\u52a8\u5316\u529f\u80fd\u90e8\u7f72\u7684\u589e\u52a0\uff0c\u9700\u8981\u65b0\u7684\u5b89\u5168\u8bc4\u4f30\u6846\u67b6\u6765\u8bc1\u660e\u8fd9\u4e9b\u529f\u80fd\u5728\u771f\u5b9e\u6761\u4ef6\u4e0b\u4e0d\u4f1a\u5e26\u6765\u4e0d\u53ef\u63a5\u53d7\u7684\u98ce\u9669\uff0c\u800cODD\u7684\u5f62\u5f0f\u5316\u662f\u5176\u4e2d\u7684\u5173\u952e\u6311\u6218", "method": "\u4f7f\u7528Pkl\u914d\u7f6e\u8bed\u8a00\u6765\u5f62\u5f0f\u5316ODD\u89c4\u8303\uff0c\u5229\u7528\u5176\u4e13\u95e8\u7684\u8bed\u8a00\u7279\u6027\u6765\u4fdd\u6301\u89c4\u8303\u683c\u5f0f\u7684\u7075\u6d3b\u6027\u3001\u4e00\u81f4\u6027\u548c\u53ef\u8ffd\u6eaf\u6027", "result": "\u5f00\u53d1\u4e86\u4e00\u79cd\u80fd\u591f\u65e0\u7f1d\u96c6\u6210\u5230\u5f00\u53d1\u3001\u9a8c\u8bc1\u548c\u8bc4\u4f30\u8fc7\u7a0b\u4e2d\u7684ODD\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u6c7d\u8f66\u9886\u57df\u7684\u5b9e\u4f8b\u8fdb\u884c\u4e86\u9a8c\u8bc1", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u9002\u7528\u4e8e\u6c7d\u8f66\u9886\u57df\uff0c\u8fd8\u53ef\u5e7f\u6cdb\u5e94\u7528\u4e8e\u786e\u4fdd\u64cd\u4f5c\u73af\u5883\u7684\u4e25\u683c\u8bc4\u4f30\uff0c\u4e3a\u81ea\u52a8\u5316\u7cfb\u7edf\u7684\u5b89\u5168\u8bba\u8bc1\u63d0\u4f9b\u4e86\u91cd\u8981\u652f\u6491"}}
{"id": "2509.00559", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00559", "abs": "https://arxiv.org/abs/2509.00559", "authors": ["Xuhui Zhou", "Jiarui Liu", "Akhila Yerukola", "Hyunwoo Kim", "Maarten Sap"], "title": "Social World Models", "comment": null, "summary": "Humans intuitively navigate social interactions by simulating unspoken\ndynamics and reasoning about others' perspectives, even with limited\ninformation. In contrast, AI systems struggle to automatically structure and\nreason about these implicit social contexts. In this paper, we introduce a\nnovel structured social world representation formalism (S3AP), designed to help\nAI systems reason more effectively about social dynamics. Following a\nPOMDP-driven design, S3AP represents social interactions as structured tuples,\nsuch as state, observation, agent actions, and mental states, which can be\nautomatically induced from free-form narratives or other inputs. We first show\nS3AP can help LLMs better understand social narratives across 5 social\nreasoning tasks (e.g., +51% improvement on FANToM's theory-of-mind reasoning\nwith OpenAI's o1), reaching new state-of-the-art (SOTA) performance. We then\ninduce social world models from these structured representations, demonstrating\ntheir ability to predict future social dynamics and improve agent\ndecision-making, yielding up to +18% improvement on the SOTOPIA social\ninteraction benchmark. Our findings highlight the promise of S3AP as a\npowerful, general-purpose representation for social world states, enabling the\ndevelopment of more socially-aware systems that better navigate social\ninteractions.", "AI": {"tldr": "\u63d0\u51fa\u4e86S3AP\u7ed3\u6784\u5316\u793e\u4f1a\u4e16\u754c\u8868\u793a\u5f62\u5f0f\uff0c\u5e2e\u52a9AI\u7cfb\u7edf\u66f4\u597d\u5730\u63a8\u7406\u793e\u4ea4\u52a8\u6001\uff0c\u57285\u4e2a\u793e\u4ea4\u63a8\u7406\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u8fbe\u5230\u65b0\u7684SOTA\u6c34\u5e73", "motivation": "\u4eba\u7c7b\u80fd\u591f\u76f4\u89c9\u5730\u6a21\u62df\u672a\u8a00\u660e\u7684\u52a8\u6001\u5e76\u63a8\u7406\u4ed6\u4eba\u89c6\u89d2\uff0c\u800cAI\u7cfb\u7edf\u5728\u81ea\u52a8\u6784\u5efa\u548c\u63a8\u7406\u8fd9\u4e9b\u9690\u5f0f\u793e\u4ea4\u8bed\u5883\u65b9\u9762\u5b58\u5728\u56f0\u96be", "method": "\u91c7\u7528POMDP\u9a71\u52a8\u7684\u8bbe\u8ba1\uff0c\u5c06\u793e\u4ea4\u4e92\u52a8\u8868\u793a\u4e3a\u7ed3\u6784\u5316\u5143\u7ec4\uff08\u72b6\u6001\u3001\u89c2\u5bdf\u3001\u4ee3\u7406\u884c\u4e3a\u3001\u5fc3\u7406\u72b6\u6001\uff09\uff0c\u53ef\u4ee5\u4ece\u81ea\u7531\u5f62\u5f0f\u53d9\u8ff0\u4e2d\u81ea\u52a8\u63a8\u5bfc", "result": "\u5728FANToM\u7684\u5fc3\u7406\u7406\u8bba\u63a8\u7406\u4efb\u52a1\u4e0a\u63d0\u534751%\uff0c\u5728SOTOPIA\u793e\u4ea4\u4e92\u52a8\u57fa\u51c6\u4e0a\u63d0\u534718%\uff0c\u8fbe\u5230\u65b0\u7684\u6700\u5148\u8fdb\u6027\u80fd", "conclusion": "S3AP\u4f5c\u4e3a\u4e00\u79cd\u5f3a\u5927\u7684\u901a\u7528\u793e\u4ea4\u4e16\u754c\u72b6\u6001\u8868\u793a\u5f62\u5f0f\uff0c\u6709\u671b\u5f00\u53d1\u51fa\u66f4\u5177\u793e\u4ea4\u610f\u8bc6\u7684\u7cfb\u7edf\uff0c\u66f4\u597d\u5730\u5bfc\u822a\u793e\u4ea4\u4e92\u52a8"}}
{"id": "2509.00662", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00662", "abs": "https://arxiv.org/abs/2509.00662", "authors": ["Vamsi Shankar Simhadri", "Yichang Xiong", "Habiba Farrukh", "Xiaokuan Zhang"], "title": "Virtual Reality, Real Problems: A Longitudinal Security Analysis of VR Firmware", "comment": "17 pages, 25 figures, 6 tables, To appear on ACM CCS 2025", "summary": "Virtual Reality (VR) technology is rapidly growing in recent years. VR\ndevices such as Meta Quest 3 utilize numerous sensors to collect users' data to\nprovide an immersive experience. Due to the extensive data collection and the\nimmersive nature, the security of VR devices is paramount. Leading VR devices\noften adopt and customize Android systems, which makes them susceptible to both\nAndroid-based vulnerabilities and new issues introduced by VR-specific\ncustomizations (e.g., system services to support continuous head and hand\ntracking). While prior work has extensively examined the security properties of\nthe Android software stack, how these security properties hold for VR systems\nremains unexplored. In this paper, we present the first comprehensive security\nanalysis of VR firmware. We collect over 300 versions of VR firmware from two\nmajor vendors, Quest and Pico, and perform a longitudinal analysis across the\nkernel layer, the system binary and library layer, and the application layer.\nWe have identified several security issues in these VR firmware, including\nmissing kernel-level security features, insufficient binary hardening,\ninconsistent permission enforcement, and inadequate SELinux policy enforcement.\nBased on our findings, we synthesize recommendations for VR vendors to improve\nsecurity and trust for VR devices. This paper will act as an important security\nresource for VR developers, users, and vendors, and will also direct future\nadvancements in secure VR ecosystem.", "AI": {"tldr": "\u9996\u6b21\u5bf9VR\u56fa\u4ef6\u8fdb\u884c\u5168\u9762\u5b89\u5168\u5206\u6790\uff0c\u53d1\u73b0\u4e86\u5185\u6838\u5b89\u5168\u7279\u6027\u7f3a\u5931\u3001\u4e8c\u8fdb\u5236\u786c\u5316\u4e0d\u5145\u5206\u3001\u6743\u9650\u6267\u884c\u4e0d\u4e00\u81f4\u7b49\u591a\u4e2a\u5b89\u5168\u95ee\u9898", "motivation": "VR\u8bbe\u5907\u91c7\u7528Android\u7cfb\u7edf\u4f46\u5b58\u5728VR\u7279\u6709\u5b9a\u5236\u5316\u5e26\u6765\u7684\u65b0\u5b89\u5168\u98ce\u9669\uff0c\u800c\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u666e\u901aAndroid\u8bbe\u5907\uff0cVR\u7cfb\u7edf\u5b89\u5168\u6027\u4ecd\u672a\u88ab\u5168\u9762\u63a2\u7d22", "method": "\u6536\u96c6Quest\u548cPico\u4e24\u5927\u5382\u5546\u8d85300\u4e2aVR\u56fa\u4ef6\u7248\u672c\uff0c\u8fdb\u884c\u7eb5\u5411\u5206\u6790\uff0c\u6db5\u76d6\u5185\u6838\u5c42\u3001\u7cfb\u7edf\u4e8c\u8fdb\u5236\u548c\u5e93\u5c42\u3001\u5e94\u7528\u5c42\u7b49\u591a\u4e2a\u5c42\u9762", "result": "\u8bc6\u522b\u51fa\u591a\u4e2a\u5b89\u5168\u6f0f\u6d1e\uff1a\u5185\u6838\u5b89\u5168\u7279\u6027\u7f3a\u5931\u3001\u4e8c\u8fdb\u5236\u786c\u5316\u4e0d\u5145\u5206\u3001\u6743\u9650\u6267\u884c\u4e0d\u4e00\u81f4\u3001SELinux\u7b56\u7565\u6267\u884c\u4e0d\u5145\u5206\u7b49", "conclusion": "\u7814\u7a76\u4e3aVR\u5382\u5546\u63d0\u4f9b\u4e86\u6539\u8fdb\u5b89\u5168\u6027\u7684\u5efa\u8bae\uff0c\u5c06\u6210\u4e3aVR\u5f00\u53d1\u8005\u3001\u7528\u6237\u548c\u5382\u5546\u7684\u91cd\u8981\u5b89\u5168\u8d44\u6e90\uff0c\u5e76\u6307\u5bfc\u672a\u6765\u5b89\u5168VR\u751f\u6001\u7cfb\u7edf\u7684\u53d1\u5c55"}}
{"id": "2509.02311", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.02311", "abs": "https://arxiv.org/abs/2509.02311", "authors": ["Martin Skoglund", "Fredrik Warg", "Anders Thoren", "Sasikumar Punnekkat", "Hans Hansson"], "title": "Methodology for Test Case Allocation based on a Formalized ODD", "comment": "12 pages, 8 figures, DECSoS, SAFECOMP 2025", "summary": "The emergence of Connected, Cooperative, and Automated Mobility (CCAM)\nsystems has significantly transformed the safety assessment landscape. Because\nthey integrate automated vehicle functions beyond those managed by a human\ndriver, new methods are required to evaluate their safety. Approaches that\ncompile evidence from multiple test environments have been proposed for\ntype-approval and similar evaluations, emphasizing scenario coverage within the\nsystems Operational Design Domain (ODD). However, aligning diverse test\nenvironment requirements with distinct testing capabilities remains\nchallenging. This paper presents a method for evaluating the suitability of\ntest case allocation to various test environments by drawing on and extending\nan existing ODD formalization with key testing attributes. The resulting\nconstruct integrates ODD parameters and additional test attributes to capture a\ngiven test environments relevant capabilities. This approach supports automatic\nsuitability evaluation and is demonstrated through a case study on an automated\nreversing truck function. The system's implementation fidelity is tied to ODD\nparameters, facilitating automated test case allocation based on each\nenvironments capacity for object-detection sensor assessment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eODD\u5f62\u5f0f\u5316\u7684\u6d4b\u8bd5\u7528\u4f8b\u5206\u914d\u8bc4\u4f30\u65b9\u6cd5\uff0c\u901a\u8fc7\u6269\u5c55\u6d4b\u8bd5\u5c5e\u6027\u6765\u8bc4\u4f30\u4e0d\u540c\u6d4b\u8bd5\u73af\u5883\u5bf9\u81ea\u52a8\u9a7e\u9a76\u529f\u80fd\u7684\u9002\u7528\u6027\uff0c\u5e76\u4ee5\u81ea\u52a8\u5012\u8f66\u5361\u8f66\u529f\u80fd\u4e3a\u4f8b\u8fdb\u884c\u9a8c\u8bc1", "motivation": "\u968f\u7740CCAM\u7cfb\u7edf\u7684\u53d1\u5c55\uff0c\u4f20\u7edf\u5b89\u5168\u8bc4\u4f30\u65b9\u6cd5\u5df2\u65e0\u6cd5\u6ee1\u8db3\u9700\u6c42\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u591a\u6d4b\u8bd5\u73af\u5883\u4e2d\u7684\u573a\u666f\u8986\u76d6\u548c\u6d4b\u8bd5\u80fd\u529b\u5339\u914d\u95ee\u9898", "method": "\u6269\u5c55\u73b0\u6709\u7684ODD\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u6574\u5408ODD\u53c2\u6570\u548c\u6d4b\u8bd5\u5c5e\u6027\uff0c\u5efa\u7acb\u80fd\u591f\u6355\u6349\u6d4b\u8bd5\u73af\u5883\u5173\u952e\u80fd\u529b\u7684\u7ed3\u6784\uff0c\u652f\u6301\u81ea\u52a8\u5316\u9002\u7528\u6027\u8bc4\u4f30", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u80fd\u591f\u81ea\u52a8\u8bc4\u4f30\u6d4b\u8bd5\u7528\u4f8b\u5206\u914d\u9002\u7528\u6027\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u81ea\u52a8\u5012\u8f66\u5361\u8f66\u529f\u80fd\u4e0a\u7684\u6709\u6548\u6027", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u591a\u6d4b\u8bd5\u73af\u5883\u80fd\u529b\u4e0e\u9700\u6c42\u5bf9\u9f50\u7684\u6311\u6218\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u7c7b\u578b\u8ba4\u8bc1\u548c\u5b89\u5168\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6d4b\u8bd5\u7528\u4f8b\u5206\u914d\u6846\u67b6"}}
{"id": "2509.00622", "categories": ["cs.AI", "cs.IR", "H.3; I.2"], "pdf": "https://arxiv.org/pdf/2509.00622", "abs": "https://arxiv.org/abs/2509.00622", "authors": ["Shiqiao Zhou", "Holger Sch\u00f6ner", "Huanbo Lyu", "Edouard Fouch\u00e9", "Shuo Wang"], "title": "BALM-TSF: Balanced Multimodal Alignment for LLM-Based Time Series Forecasting", "comment": null, "summary": "Time series forecasting is a long-standing and highly challenging research\ntopic. Recently, driven by the rise of large language models (LLMs), research\nhas increasingly shifted from purely time series methods toward harnessing\ntextual modalities to enhance forecasting performance. However, the vast\ndiscrepancy between text and temporal data often leads current multimodal\narchitectures to over-emphasise one modality while neglecting the other,\nresulting in information loss that harms forecasting performance. To address\nthis modality imbalance, we introduce BALM-TSF (Balanced Multimodal Alignment\nfor LLM-Based Time Series Forecasting), a lightweight time series forecasting\nframework that maintains balance between the two modalities. Specifically, raw\ntime series are processed by the time series encoder, while descriptive\nstatistics of raw time series are fed to an LLM with learnable prompt,\nproducing compact textual embeddings. To ensure balanced cross-modal context\nalignment of time series and textual embeddings, a simple yet effective scaling\nstrategy combined with a contrastive objective then maps these textual\nembeddings into the latent space of the time series embeddings. Finally, the\naligned textual semantic embeddings and time series embeddings are together\nintegrated for forecasting. Extensive experiments on standard benchmarks show\nthat, with minimal trainable parameters, BALM-TSF achieves state-of-the-art\nperformance in both long-term and few-shot forecasting, confirming its ability\nto harness complementary information from text and time series. Code is\navailable at https://github.com/ShiqiaoZhou/BALM-TSF.", "AI": {"tldr": "BALM-TSF\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u591a\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u5e73\u8861\u6587\u672c\u548c\u65f6\u95f4\u5e8f\u5217\u6a21\u6001\u7684\u5bf9\u9f50\u6765\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u4e2d\u6a21\u6001\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5728\u957f\u671f\u548c\u5c11\u6837\u672c\u9884\u6d4b\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u5b58\u5728\u6a21\u6001\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5f80\u5f80\u8fc7\u5ea6\u5f3a\u8c03\u6587\u672c\u6a21\u6001\u800c\u5ffd\u89c6\u65f6\u95f4\u5e8f\u5217\u6a21\u6001\uff0c\u5bfc\u81f4\u4fe1\u606f\u635f\u5931\u548c\u9884\u6d4b\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u4f7f\u7528\u65f6\u95f4\u5e8f\u5217\u7f16\u7801\u5668\u5904\u7406\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\uff0c\u540c\u65f6\u5c06\u65f6\u95f4\u5e8f\u5217\u7684\u63cf\u8ff0\u6027\u7edf\u8ba1\u7279\u5f81\u8f93\u5165\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6587\u672c\u5d4c\u5165\u3002\u901a\u8fc7\u7f29\u653e\u7b56\u7565\u548c\u5bf9\u6bd4\u5b66\u4e60\u76ee\u6807\u5c06\u6587\u672c\u5d4c\u5165\u6620\u5c04\u5230\u65f6\u95f4\u5e8f\u5217\u5d4c\u5165\u7684\u6f5c\u5728\u7a7a\u95f4\uff0c\u5b9e\u73b0\u8de8\u6a21\u6001\u5e73\u8861\u5bf9\u9f50\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cBALM-TSF\u4ee5\u6700\u5c11\u7684\u53ef\u8bad\u7ec3\u53c2\u6570\u5b9e\u73b0\u4e86\u957f\u671f\u548c\u5c11\u6837\u672c\u9884\u6d4b\u7684\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u5229\u7528\u6587\u672c\u548c\u65f6\u95f4\u5e8f\u5217\u4e92\u8865\u4fe1\u606f\u7684\u80fd\u529b\u3002", "conclusion": "BALM-TSF\u901a\u8fc7\u5e73\u8861\u7684\u591a\u6a21\u6001\u5bf9\u9f50\u673a\u5236\u6210\u529f\u89e3\u51b3\u4e86\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u6a21\u6001\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u4e3a\u591a\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.00706", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00706", "abs": "https://arxiv.org/abs/2509.00706", "authors": ["YuKun Zhu", "ManYuan Hua", "Hai Huang", "YongZhao Zhang", "Jie Yang", "FengHua Xu", "RuiDong Chen", "XiaoSong Zhang", "JiGuo Yu", "Yong Ma"], "title": "X-PRINT:Platform-Agnostic and Scalable Fine-Grained Encrypted Traffic Fingerprinting", "comment": null, "summary": "Although encryption protocols such as TLS are widely de-ployed,side-channel\nmetadata in encrypted traffic still reveals patterns that allow application and\nbehavior inference.How-ever,existing fine-grained fingerprinting approaches\nface two key limitations:(i)reliance on platform-dependent\ncharac-teristics,which restricts generalization across heterogeneous\nplatforms,and(ii)poor scalability for fine-grained behavior identification in\nopen-world settings.\n  In this paper,we present X-PRINT,the first server-centric,URI-based framework\nfor cross-platform fine-grained encrypted-traffic fingerprinting.X-PRINT\nsystematically demonstrates that backend URI invocation patterns can serve as\nplatform-agnostic invariants and are effective for mod-eling fine-grained\nbehaviors.To achieve robust identifica-tion,X-PRINT further leverages\ntemporally structured URI maps for behavior inference and emphasizes the\nexclusion of platform-or application-specific private URIs to handle unseen\ncases,thereby improving reliability in open-world and cross-platform\nsettings.Extensive experiments across diverse cross-platform and open-world\nsettings show that X-PRINT achieves state-of-the-art accuracy in fine-grained\nfingerprint-ing and exhibits strong scalability and robustness.", "AI": {"tldr": "X-PRINT\u662f\u4e00\u4e2a\u57fa\u4e8eURI\u6a21\u5f0f\u7684\u670d\u52a1\u5668\u4e2d\u5fc3\u5316\u52a0\u5bc6\u6d41\u91cf\u6307\u7eb9\u8bc6\u522b\u6846\u67b6\uff0c\u80fd\u591f\u5728\u8de8\u5e73\u53f0\u548c\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e2d\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u884c\u4e3a\u8bc6\u522b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5e73\u53f0\u4f9d\u8d56\u6027\u5f3a\u548c\u53ef\u6269\u5c55\u6027\u5dee\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u52a0\u5bc6\u6d41\u91cf\u6307\u7eb9\u8bc6\u522b\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u9650\u5236\uff1a(i)\u4f9d\u8d56\u5e73\u53f0\u76f8\u5173\u7279\u5f81\uff0c\u9650\u5236\u4e86\u5728\u5f02\u6784\u5e73\u53f0\u95f4\u7684\u6cdb\u5316\u80fd\u529b\uff1b(ii)\u5728\u5f00\u653e\u4e16\u754c\u8bbe\u7f6e\u4e2d\u5bf9\u7ec6\u7c92\u5ea6\u884c\u4e3a\u8bc6\u522b\u7684\u53ef\u6269\u5c55\u6027\u5dee\u3002", "method": "X-PRINT\u5229\u7528\u540e\u7aefURI\u8c03\u7528\u6a21\u5f0f\u4f5c\u4e3a\u5e73\u53f0\u65e0\u5173\u7684\u4e0d\u53d8\u91cf\uff0c\u4f7f\u7528\u65f6\u5e8f\u7ed3\u6784\u5316\u7684URI\u6620\u5c04\u8fdb\u884c\u884c\u4e3a\u63a8\u7406\uff0c\u5e76\u901a\u8fc7\u6392\u9664\u5e73\u53f0\u6216\u5e94\u7528\u7279\u5b9a\u7684\u79c1\u6709URI\u6765\u5904\u7406\u672a\u89c1\u60c5\u51b5\u3002", "result": "\u5728\u591a\u6837\u5316\u7684\u8de8\u5e73\u53f0\u548c\u5f00\u653e\u4e16\u754c\u8bbe\u7f6e\u4e2d\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0cX-PRINT\u5728\u7ec6\u7c92\u5ea6\u6307\u7eb9\u8bc6\u522b\u65b9\u9762\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u51c6\u786e\u7387\uff0c\u5e76\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "URI\u8c03\u7528\u6a21\u5f0f\u53ef\u4ee5\u4f5c\u4e3a\u6709\u6548\u7684\u5e73\u53f0\u65e0\u5173\u7279\u5f81\u7528\u4e8e\u52a0\u5bc6\u6d41\u91cf\u6307\u7eb9\u8bc6\u522b\uff0cX-PRINT\u6846\u67b6\u5728\u8de8\u5e73\u53f0\u548c\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u6027\u80fd\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2509.02330", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02330", "abs": "https://arxiv.org/abs/2509.02330", "authors": ["Yicong Zhao", "Shisong Chen", "Jiacheng Zhang", "Zhixu Li"], "title": "ReCode: Improving LLM-based Code Repair with Fine-Grained Retrieval-Augmented Generation", "comment": "Accepted by CIKM 2025", "summary": "Recent advances in large language models (LLMs) have demonstrated impressive\ncapabilities in code-related tasks, such as code generation and automated\nprogram repair. Despite their promising performance, most existing approaches\nfor code repair suffer from high training costs or computationally expensive\ninference. Retrieval-augmented generation (RAG), with its efficient in-context\nlearning paradigm, offers a more scalable alternative. However, conventional\nretrieval strategies, which are often based on holistic code-text embeddings,\nfail to capture the structural intricacies of code, resulting in suboptimal\nretrieval quality. To address the above limitations, we propose ReCode, a\nfine-grained retrieval-augmented in-context learning framework designed for\naccurate and efficient code repair. Specifically, ReCode introduces two key\ninnovations: (1) an algorithm-aware retrieval strategy that narrows the search\nspace using preliminary algorithm type predictions; and (2) a modular\ndual-encoder architecture that separately processes code and textual inputs,\nenabling fine-grained semantic matching between input and retrieved contexts.\nFurthermore, we propose RACodeBench, a new benchmark constructed from\nreal-world user-submitted buggy code, which addresses the limitations of\nsynthetic benchmarks and supports realistic evaluation. Experimental results on\nRACodeBench and competitive programming datasets demonstrate that ReCode\nachieves higher repair accuracy with significantly reduced inference cost,\nhighlighting its practical value for real-world code repair scenarios.", "AI": {"tldr": "ReCode\u662f\u4e00\u4e2a\u7ec6\u7c92\u5ea6\u68c0\u7d22\u589e\u5f3a\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u7b97\u6cd5\u611f\u77e5\u68c0\u7d22\u548c\u6a21\u5757\u5316\u53cc\u7f16\u7801\u5668\u67b6\u6784\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u51c6\u786e\u7684\u4ee3\u7801\u4fee\u590d\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u63a8\u7406\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u4fee\u590d\u65b9\u6cd5\u5b58\u5728\u9ad8\u8bad\u7ec3\u6210\u672c\u6216\u6602\u8d35\u63a8\u7406\u7684\u95ee\u9898\uff0c\u4f20\u7edf\u68c0\u7d22\u7b56\u7565\u65e0\u6cd5\u6355\u6349\u4ee3\u7801\u7ed3\u6784\u7ec6\u8282\uff0c\u5bfc\u81f4\u68c0\u7d22\u8d28\u91cf\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u7b97\u6cd5\u611f\u77e5\u68c0\u7d22\u7b56\u7565\u7f29\u5c0f\u641c\u7d22\u7a7a\u95f4\uff0c\u91c7\u7528\u6a21\u5757\u5316\u53cc\u7f16\u7801\u5668\u67b6\u6784\u5206\u522b\u5904\u7406\u4ee3\u7801\u548c\u6587\u672c\u8f93\u5165\uff0c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u8bed\u4e49\u5339\u914d\u3002", "result": "\u5728RACodeBench\u548c\u7ade\u4e89\u6027\u7f16\u7a0b\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cReCode\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u4fee\u590d\u51c6\u786e\u7387\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u63a8\u7406\u6210\u672c\u3002", "conclusion": "ReCode\u6846\u67b6\u4e3a\u73b0\u5b9e\u4e16\u754c\u4ee3\u7801\u4fee\u590d\u573a\u666f\u63d0\u4f9b\u4e86\u5b9e\u7528\u4ef7\u503c\uff0c\u5c55\u793a\u4e86\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u5728\u4ee3\u7801\u76f8\u5173\u4efb\u52a1\u4e2d\u7684\u4f18\u52bf\u3002"}}
{"id": "2509.00625", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00625", "abs": "https://arxiv.org/abs/2509.00625", "authors": ["Jaber Daneshamooz", "Eugene Vuong", "Laasya Koduru", "Sanjay Chandrasekaran", "Arpit Gupta"], "title": "NetGent: Agent-Based Automation of Network Application Workflows", "comment": null, "summary": "We present NetGent, an AI-agent framework for automating complex application\nworkflows to generate realistic network traffic datasets. Developing\ngeneralizable ML models for networking requires data collection from network\nenvironments with traffic that results from a diverse set of real-world web\napplications. However, using existing browser automation tools that are\ndiverse, repeatable, realistic, and efficient remains fragile and costly.\nNetGent addresses this challenge by allowing users to specify workflows as\nnatural-language rules that define state-dependent actions. These abstract\nspecifications are compiled into nondeterministic finite automata (NFAs), which\na state synthesis component translates into reusable, executable code. This\ndesign enables deterministic replay, reduces redundant LLM calls through state\ncaching, and adapts quickly when application interfaces change. In experiments,\nNetGent automated more than 50+ workflows spanning video-on-demand streaming,\nlive video streaming, video conferencing, social media, and web scraping,\nproducing realistic traffic traces while remaining robust to UI variability. By\ncombining the flexibility of language-based agents with the reliability of\ncompiled execution, NetGent provides a scalable foundation for generating the\ndiverse, repeatable datasets needed to advance ML in networking.", "AI": {"tldr": "NetGent\u662f\u4e00\u4e2aAI\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u89c4\u5219\u5b9a\u4e49\u5de5\u4f5c\u6d41\uff0c\u81ea\u52a8\u751f\u6210\u771f\u5b9e\u7f51\u7edc\u6d41\u91cf\u6570\u636e\u96c6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6d4f\u89c8\u5668\u81ea\u52a8\u5316\u5de5\u5177\u5728\u591a\u6837\u6027\u3001\u53ef\u91cd\u590d\u6027\u3001\u771f\u5b9e\u6027\u548c\u6548\u7387\u65b9\u9762\u7684\u6311\u6218\u3002", "motivation": "\u5f00\u53d1\u901a\u7528ML\u7f51\u7edc\u6a21\u578b\u9700\u8981\u4ece\u591a\u6837\u5316\u771f\u5b9e\u7f51\u7edc\u73af\u5883\u4e2d\u6536\u96c6\u6570\u636e\uff0c\u4f46\u73b0\u6709\u6d4f\u89c8\u5668\u81ea\u52a8\u5316\u5de5\u5177\u8106\u5f31\u4e14\u6210\u672c\u9ad8\u6602\uff0c\u96be\u4ee5\u6ee1\u8db3\u9700\u6c42\u3002", "method": "\u7528\u6237\u7528\u81ea\u7136\u8bed\u8a00\u89c4\u5219\u5b9a\u4e49\u72b6\u6001\u4f9d\u8d56\u52a8\u4f5c\uff0c\u6846\u67b6\u5c06\u5176\u7f16\u8bd1\u4e3a\u975e\u786e\u5b9a\u6027\u6709\u9650\u81ea\u52a8\u673a(NFA)\uff0c\u901a\u8fc7\u72b6\u6001\u5408\u6210\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u4ee3\u7801\uff0c\u652f\u6301\u786e\u5b9a\u6027\u91cd\u653e\u548c\u72b6\u6001\u7f13\u5b58\u51cf\u5c11LLM\u8c03\u7528\u3002", "result": "\u6210\u529f\u81ea\u52a8\u531650+\u4e2a\u5de5\u4f5c\u6d41\uff0c\u6db5\u76d6\u89c6\u9891\u70b9\u64ad\u3001\u76f4\u64ad\u3001\u89c6\u9891\u4f1a\u8bae\u3001\u793e\u4ea4\u5a92\u4f53\u548c\u7f51\u7edc\u722c\u866b\uff0c\u751f\u6210\u771f\u5b9e\u6d41\u91cf\u8f68\u8ff9\uff0c\u5bf9UI\u53d8\u5316\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "NetGent\u7ed3\u5408\u57fa\u4e8e\u8bed\u8a00\u7684\u7075\u6d3b\u6027\u548c\u7f16\u8bd1\u6267\u884c\u7684\u53ef\u9760\u6027\uff0c\u4e3a\u751f\u6210\u591a\u6837\u5316\u3001\u53ef\u91cd\u590d\u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u57fa\u7840\uff0c\u63a8\u52a8\u7f51\u7edcML\u53d1\u5c55\u3002"}}
{"id": "2509.00770", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00770", "abs": "https://arxiv.org/abs/2509.00770", "authors": ["Shaofei Huang", "Christopher M. Poskitt", "Lwin Khin Shar"], "title": "Bayesian and Multi-Objective Decision Support for Real-Time Cyber-Physical Incident Mitigation", "comment": null, "summary": "This research proposes a real-time, adaptive decision-support framework for\nmitigating cyber incidents in cyber-physical systems, developed in response to\nan increasing reliance on these systems within critical infrastructure and\nevolving adversarial tactics. Existing decision-support systems often fall\nshort in accounting for multi-agent, multi-path attacks and trade-offs between\nsafety and operational continuity. To address this, our framework integrates\nhierarchical system modelling with Bayesian probabilistic reasoning,\nconstructing Bayesian Network Graphs from system architecture and vulnerability\ndata. Models are encoded using a Domain Specific Language to enhance\ncomputational efficiency and support dynamic updates. In our approach, we use a\nhybrid exposure probability estimation framework, which combines Exploit\nPrediction Scoring System and Common Vulnerability Scoring System scores via\nBayesian confidence calibration to handle epistemic uncertainty caused by\nincomplete or heterogeneous vulnerability metadata. Mitigation recommendations\nare generated as countermeasure portfolios, refined using multi-objective\noptimisation to identify Pareto-optimal strategies balancing attack likelihood,\nimpact severity, and system availability. To accommodate time- and\nresource-constrained incident response, frequency-based heuristics are applied\nto prioritise countermeasures across the optimised portfolios. The framework\nwas evaluated through three representative cyber-physical attack scenarios,\ndemonstrating its versatility in handling complex adversarial behaviours under\nreal-time response constraints. The results affirm its utility in operational\ncontexts and highlight the robustness of our proposed approach across diverse\nthreat environments.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.00710", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.00710", "abs": "https://arxiv.org/abs/2509.00710", "authors": ["Albert Sadowski", "Jaros\u0142aw A. Chudziak"], "title": "On Verifiable Legal Reasoning: A Multi-Agent Framework with Formalized Knowledge Representations", "comment": "Accepted for publication at the 34th ACM International Conference on\n  Information and Knowledge Management (CIKM '25)", "summary": "Legal reasoning requires both precise interpretation of statutory language\nand consistent application of complex rules, presenting significant challenges\nfor AI systems. This paper introduces a modular multi-agent framework that\ndecomposes legal reasoning into distinct knowledge acquisition and application\nstages. In the first stage, specialized agents extract legal concepts and\nformalize rules to create verifiable intermediate representations of statutes.\nThe second stage applies this knowledge to specific cases through three steps:\nanalyzing queries to map case facts onto the ontology schema, performing\nsymbolic inference to derive logically entailed conclusions, and generating\nfinal answers using a programmatic implementation that operationalizes the\nontological knowledge. This bridging of natural language understanding with\nsymbolic reasoning provides explicit and verifiable inspection points,\nsignificantly enhancing transparency compared to end-to-end approaches.\nEvaluation on statutory tax calculation tasks demonstrates substantial\nimprovements, with foundational models achieving 76.4\\% accuracy compared to\n18.8\\% baseline performance, effectively narrowing the performance gap between\nreasoning and foundational models. These findings suggest that modular\narchitectures with formalized knowledge representations can make sophisticated\nlegal reasoning more accessible through computationally efficient models while\nenhancing consistency and explainability in AI legal reasoning, establishing a\nfoundation for future research into more transparent, trustworthy, and\neffective AI systems for legal domain.", "AI": {"tldr": "\u63d0\u51fa\u6a21\u5757\u5316\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c06\u6cd5\u5f8b\u63a8\u7406\u5206\u89e3\u4e3a\u77e5\u8bc6\u83b7\u53d6\u548c\u5e94\u7528\u4e24\u4e2a\u9636\u6bb5\uff0c\u901a\u8fc7\u7b26\u53f7\u63a8\u7406\u548c\u7a0b\u5e8f\u5316\u5b9e\u73b0\u663e\u8457\u63d0\u5347\u6cd5\u5f8bAI\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u548c\u51c6\u786e\u6027", "motivation": "\u6cd5\u5f8b\u63a8\u7406\u9700\u8981\u7cbe\u786e\u89e3\u91ca\u6cd5\u5f8b\u6761\u6587\u548c\u4e00\u81f4\u5e94\u7528\u590d\u6742\u89c4\u5219\uff0c\u8fd9\u5bf9AI\u7cfb\u7edf\u6784\u6210\u91cd\u5927\u6311\u6218\uff0c\u9700\u8981\u89e3\u51b3\u7aef\u5230\u7aef\u65b9\u6cd5\u7f3a\u4e4f\u900f\u660e\u5ea6\u7684\u95ee\u9898", "method": "\u91c7\u7528\u6a21\u5757\u5316\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u7531\u4e13\u95e8\u667a\u80fd\u4f53\u63d0\u53d6\u6cd5\u5f8b\u6982\u5ff5\u5e76\u5f62\u5f0f\u5316\u89c4\u5219\uff1b\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u67e5\u8be2\u5206\u6790\u3001\u7b26\u53f7\u63a8\u7406\u548c\u7a0b\u5e8f\u5316\u5b9e\u73b0\u4e09\u4e2a\u6b65\u9aa4\u5e94\u7528\u77e5\u8bc6\u5230\u5177\u4f53\u6848\u4f8b", "result": "\u5728\u6cd5\u5b9a\u7a0e\u52a1\u8ba1\u7b97\u4efb\u52a1\u4e0a\uff0c\u57fa\u7840\u6a21\u578b\u51c6\u786e\u7387\u8fbe\u523076.4%\uff0c\u76f8\u6bd4\u57fa\u7ebf18.8%\u6709\u663e\u8457\u63d0\u5347\uff0c\u6709\u6548\u7f29\u5c0f\u4e86\u63a8\u7406\u6a21\u578b\u4e0e\u57fa\u7840\u6a21\u578b\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd", "conclusion": "\u6a21\u5757\u5316\u67b6\u6784\u548c\u5f62\u5f0f\u5316\u77e5\u8bc6\u8868\u793a\u53ef\u4ee5\u4f7f\u590d\u6742\u7684\u6cd5\u5f8b\u63a8\u7406\u901a\u8fc7\u8ba1\u7b97\u9ad8\u6548\u6a21\u578b\u5b9e\u73b0\uff0c\u540c\u65f6\u589e\u5f3aAI\u6cd5\u5f8b\u63a8\u7406\u7684\u4e00\u81f4\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u672a\u6765\u66f4\u900f\u660e\u3001\u53ef\u4fe1\u548c\u6709\u6548\u7684\u6cd5\u5f8bAI\u7cfb\u7edf\u5960\u5b9a\u57fa\u7840"}}
{"id": "2509.00811", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00811", "abs": "https://arxiv.org/abs/2509.00811", "authors": ["Samuel Punch", "Krishnendu Guha"], "title": "MAESTROCUT: Dynamic, Noise-Adaptive, and Secure Quantum Circuit Cutting on Near-Term Hardware", "comment": "14 Pages", "summary": "We present MaestroCut, a closed-loop framework for quantum circuit cutting\nthat adapts partitioning and shot allocation to device drift and workload\nvariation. MaestroCut tracks a variance proxy in real time, triggers re-cutting\nwhen accuracy degrades, and routes shots using topology-aware priors. An online\nestimator cascade (MLE, Bayesian, GP-assisted) selects the lowest-error\nreconstruction within a fixed budget. Tier-1 simulations show consistent\nvariance contraction and reduced mean-squared error versus uniform and\nproportional baselines. Tier-2 emulation with realistic queueing and noise\ndemonstrates stable latency targets, high reliability, and ~1% software\noverhead under stress scenarios. These results indicate that adaptive circuit\ncutting can provide accuracy and efficiency improvements with minimal\noperational cost on near-term hardware.", "AI": {"tldr": "MaestroCut\u662f\u4e00\u4e2a\u7528\u4e8e\u91cf\u5b50\u7535\u8def\u5207\u5272\u7684\u95ed\u73af\u6846\u67b6\uff0c\u80fd\u591f\u81ea\u9002\u5e94\u8bbe\u5907\u6f02\u79fb\u548c\u5de5\u4f5c\u8d1f\u8f7d\u53d8\u5316\uff0c\u901a\u8fc7\u5b9e\u65f6\u8ddf\u8e2a\u65b9\u5dee\u4ee3\u7406\u3001\u89e6\u53d1\u91cd\u65b0\u5207\u5272\u548c\u62d3\u6251\u611f\u77e5\u7684\u6837\u672c\u5206\u914d\u6765\u63d0\u5347\u7cbe\u5ea6\u548c\u6548\u7387\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u4e2d\u7684\u8bbe\u5907\u6f02\u79fb\u548c\u5de5\u4f5c\u8d1f\u8f7d\u53d8\u5316\u4f1a\u5f71\u54cd\u7535\u8def\u5207\u5272\u7684\u51c6\u786e\u6027\uff0c\u9700\u8981\u4e00\u79cd\u81ea\u9002\u5e94\u65b9\u6cd5\u6765\u7ef4\u6301\u7a33\u5b9a\u7684\u6027\u80fd\u8868\u73b0\u3002", "method": "\u91c7\u7528\u95ed\u73af\u6846\u67b6\uff0c\u5b9e\u65f6\u8ddf\u8e2a\u65b9\u5dee\u4ee3\u7406\uff0c\u5728\u7cbe\u5ea6\u4e0b\u964d\u65f6\u89e6\u53d1\u91cd\u65b0\u5207\u5272\uff0c\u4f7f\u7528\u62d3\u6251\u611f\u77e5\u5148\u9a8c\u8fdb\u884c\u6837\u672c\u8def\u7531\uff0c\u5e76\u901a\u8fc7\u5728\u7ebf\u4f30\u8ba1\u5668\u7ea7\u8054\uff08MLE\u3001\u8d1d\u53f6\u65af\u3001GP\u8f85\u52a9\uff09\u5728\u56fa\u5b9a\u9884\u7b97\u5185\u9009\u62e9\u6700\u4f4e\u8bef\u5dee\u91cd\u5efa\u3002", "result": "Tier-1\u6a21\u62df\u663e\u793a\u76f8\u6bd4\u5747\u5300\u548c\u6bd4\u4f8b\u57fa\u7ebf\u5b9e\u73b0\u4e86\u6301\u7eed\u7684\u65b9\u5dee\u6536\u7f29\u548c\u5747\u65b9\u8bef\u5dee\u964d\u4f4e\uff1bTier-2\u4eff\u771f\u5728\u771f\u5b9e\u6392\u961f\u548c\u566a\u58f0\u73af\u5883\u4e0b\u5c55\u793a\u4e86\u7a33\u5b9a\u7684\u5ef6\u8fdf\u76ee\u6807\u3001\u9ad8\u53ef\u9760\u6027\u548c\u7ea61%\u7684\u8f6f\u4ef6\u5f00\u9500\u3002", "conclusion": "\u81ea\u9002\u5e94\u7535\u8def\u5207\u5272\u80fd\u591f\u5728\u8fd1\u671f\u786c\u4ef6\u4e0a\u4ee5\u6700\u5c0f\u8fd0\u8425\u6210\u672c\u63d0\u4f9b\u7cbe\u5ea6\u548c\u6548\u7387\u7684\u6539\u8fdb\u3002"}}
{"id": "2509.02360", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.02360", "abs": "https://arxiv.org/abs/2509.02360", "authors": ["Shubham Gandhi", "Jason Tsay", "Jatin Ganhotra", "Kiran Kate", "Yara Rizk"], "title": "When Agents go Astray: Course-Correcting SWE Agents with PRMs", "comment": null, "summary": "Large Language Model (LLM) agents are increasingly deployed for complex,\nmulti-step software engineering (SWE) tasks. However, their trajectories often\ncontain costly inefficiencies, such as redundant exploration, looping, and\nfailure to terminate once a solution is reached. Prior work has largely treated\nthese errors in a post-hoc manner, diagnosing failures only after execution. In\nthis paper, we introduce SWE-PRM, an inference-time Process Reward Model (PRM)\nthat intervenes during execution to detect and course-correct trajectory-level\nerrors. Our PRM design leverages a taxonomy of common inefficiencies and\ndelivers lightweight, interpretable feedback without modifying the underlying\npolicy. On SWE-bench Verified, closed-source PRMs improve resolution from 40.0%\nto 50.6% (+10.6 p.p.), with the largest gains on medium and hard tasks. Among\nfeedback strategies, taxonomy-guided PRMs outperform unguided or explicit\naction-prescriptive variants, increasing success rate while reducing trajectory\nlength. These benefits come at an acceptable added inference cost of as low as\n$0.2, making PRMs a practical and scalable mechanism for improving SWE agents'\nreliability and efficiency.", "AI": {"tldr": "SWE-PRM\u662f\u4e00\u4e2a\u63a8\u7406\u65f6\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff0c\u901a\u8fc7\u68c0\u6d4b\u548c\u7ea0\u6b63LLM\u4ee3\u7406\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u8f68\u8ff9\u9519\u8bef\uff0c\u63d0\u9ad8\u4efb\u52a1\u89e3\u51b3\u7387\u548c\u6548\u7387", "motivation": "LLM\u4ee3\u7406\u5728\u590d\u6742\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7ecf\u5e38\u51fa\u73b0\u5197\u4f59\u63a2\u7d22\u3001\u5faa\u73af\u548c\u65e0\u6cd5\u7ec8\u6b62\u7b49\u4f4e\u6548\u884c\u4e3a\uff0c\u73b0\u6709\u65b9\u6cd5\u53ea\u80fd\u5728\u6267\u884c\u540e\u8bca\u65ad\u9519\u8bef", "method": "\u5f15\u5165SWE-PRM\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff0c\u57fa\u4e8e\u5e38\u89c1\u4f4e\u6548\u884c\u4e3a\u7684\u5206\u7c7b\u6cd5\uff0c\u5728\u6267\u884c\u8fc7\u7a0b\u4e2d\u63d0\u4f9b\u8f7b\u91cf\u7ea7\u3001\u53ef\u89e3\u91ca\u7684\u53cd\u9988\uff0c\u4e0d\u4fee\u6539\u5e95\u5c42\u7b56\u7565", "result": "\u5728SWE-bench Verified\u4e0a\uff0c\u89e3\u51b3\u7387\u4ece40.0%\u63d0\u5347\u523050.6%\uff08+10.6\u4e2a\u767e\u5206\u70b9\uff09\uff0c\u4e2d\u9ad8\u96be\u5ea6\u4efb\u52a1\u63d0\u5347\u6700\u5927\uff0c\u8f68\u8ff9\u957f\u5ea6\u51cf\u5c11\uff0c\u63a8\u7406\u6210\u672c\u4ec5\u589e\u52a00.2\u7f8e\u5143", "conclusion": "PRM\u662f\u63d0\u9ad8SWE\u4ee3\u7406\u53ef\u9760\u6027\u548c\u6548\u7387\u7684\u5b9e\u7528\u53ef\u6269\u5c55\u673a\u5236\uff0c\u5206\u7c7b\u6cd5\u5f15\u5bfc\u7684PRM\u4f18\u4e8e\u65e0\u5f15\u5bfc\u6216\u660e\u786e\u6307\u4ee4\u7684\u53d8\u4f53"}}
{"id": "2509.00723", "categories": ["cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2509.00723", "abs": "https://arxiv.org/abs/2509.00723", "authors": ["Junzhe Chen", "Tianshu Zhang", "Shiyu Huang", "Yuwei Niu", "Chao Sun", "Rongzhou Zhang", "Guanyu Zhou", "Lijie Wen", "Xuming Hu"], "title": "OmniDPO: A Preference Optimization Framework to Address Omni-Modal Hallucination", "comment": null, "summary": "Recently, Omni-modal large language models (OLLMs) have sparked a new wave of\nresearch, achieving impressive results in tasks such as audio-video\nunderstanding and real-time environment perception. However, hallucination\nissues still persist. Similar to the bimodal setting, the priors from the text\nmodality tend to dominate, leading OLLMs to rely more heavily on textual cues\nwhile neglecting visual and audio information. In addition, fully multimodal\nscenarios introduce new challenges. Most existing models align visual or\nauditory modalities with text independently during training, while ignoring the\nintrinsic correlations between video and its corresponding audio. This\noversight results in hallucinations when reasoning requires interpreting hidden\naudio cues embedded in video content. To address these challenges, we propose\nOmniDPO, a preference-alignment framework designed to mitigate hallucinations\nin OLLMs. Specifically, OmniDPO incorporates two strategies: (1) constructing\ntext-preference sample pairs to enhance the model's understanding of\naudio-video interactions; and (2) constructing multimodal-preference sample\npairs to strengthen the model's attention to visual and auditory information.\nBy tackling both challenges, OmniDPO effectively improves multimodal grounding\nand reduces hallucination. Experiments conducted on two OLLMs demonstrate that\nOmniDPO not only effectively mitigates multimodal hallucinations but also\nsignificantly enhances the models' reasoning capabilities across modalities.\nAll code and datasets will be released upon paper acceptance.", "AI": {"tldr": "OmniDPO\u662f\u4e00\u4e2a\u9488\u5bf9\u5168\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b(OLLMs)\u7684\u504f\u597d\u5bf9\u9f50\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u6587\u672c\u504f\u597d\u548c\u591a\u6a21\u6001\u504f\u597d\u6837\u672c\u5bf9\u6765\u89e3\u51b3\u5e7b\u89c9\u95ee\u9898\uff0c\u589e\u5f3a\u6a21\u578b\u5bf9\u97f3\u9891-\u89c6\u9891\u4ea4\u4e92\u7684\u7406\u89e3\u548c\u6ce8\u610f\u529b\u3002", "motivation": "\u73b0\u6709\u7684OLLMs\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\uff0c\u6587\u672c\u6a21\u6001\u5148\u9a8c\u5360\u4e3b\u5bfc\u5730\u4f4d\uff0c\u5bfc\u81f4\u6a21\u578b\u8fc7\u5ea6\u4f9d\u8d56\u6587\u672c\u7ebf\u7d22\u800c\u5ffd\u89c6\u89c6\u89c9\u548c\u97f3\u9891\u4fe1\u606f\u3002\u540c\u65f6\uff0c\u73b0\u6709\u6a21\u578b\u5728\u8bad\u7ec3\u65f6\u72ec\u7acb\u5bf9\u9f50\u5404\u6a21\u6001\uff0c\u5ffd\u7565\u4e86\u89c6\u9891\u4e0e\u97f3\u9891\u4e4b\u95f4\u7684\u5185\u5728\u5173\u8054\u3002", "method": "\u63d0\u51faOmniDPO\u6846\u67b6\uff0c\u5305\u542b\u4e24\u79cd\u7b56\u7565\uff1a(1)\u6784\u5efa\u6587\u672c\u504f\u597d\u6837\u672c\u5bf9\u4ee5\u589e\u5f3a\u5bf9\u97f3\u9891-\u89c6\u9891\u4ea4\u4e92\u7684\u7406\u89e3\uff1b(2)\u6784\u5efa\u591a\u6a21\u6001\u504f\u597d\u6837\u672c\u5bf9\u4ee5\u52a0\u5f3a\u5bf9\u89c6\u89c9\u548c\u542c\u89c9\u4fe1\u606f\u7684\u6ce8\u610f\u529b\u3002", "result": "\u5728\u4e24\u4e2aOLLMs\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cOmniDPO\u4e0d\u4ec5\u6709\u6548\u7f13\u89e3\u4e86\u591a\u6a21\u6001\u5e7b\u89c9\u95ee\u9898\uff0c\u8fd8\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u8de8\u6a21\u6001\u7684\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "OmniDPO\u901a\u8fc7\u540c\u65f6\u89e3\u51b3\u6587\u672c\u4e3b\u5bfc\u548c\u6a21\u6001\u95f4\u5173\u8054\u7f3a\u5931\u4e24\u4e2a\u6311\u6218\uff0c\u6709\u6548\u6539\u5584\u4e86\u591a\u6a21\u6001\u57fa\u7840\u80fd\u529b\u5e76\u51cf\u5c11\u4e86\u5e7b\u89c9\u73b0\u8c61\u3002"}}
{"id": "2509.00812", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00812", "abs": "https://arxiv.org/abs/2509.00812", "authors": ["Samuel Punch", "Krishnendu Guha"], "title": "Adaptive t Design Dummy-Gate Obfuscation for Cryogenic Scale Enforcement", "comment": "6", "summary": "Cloud quantum services can reveal circuit structure and timing through\nscheduler metadata, latency patterns, and co-tenant interference. We introduce\nNADGO (Noise-Adaptive Dummy-Gate Obfuscation), a scheduling and obfuscation\nstack that enforces operational privacy for gate-model workloads by applying\nper-interval limits on observable information leakage. To support\nconfidentiality and fair multi-tenancy, operators require a method to audit\ncompliance at acceptable overheads. NADGO combines: (i) hardware-aware t-design\npadding for structured cover traffic, (ii) particle-filter timing randomization\nto mask queue patterns, (iii) CASQUE subcircuit routing across heterogeneous\nbackends, and (iv) a per-interval leakage estimator with locked calibration\nartifacts and a dual-threshold kill-switch. We prototype the approach on a\n4-qubit superconducting tile with cryo-CMOS control and evaluate both\ndepth-varied local-random circuits and small QAOA instances. Monitoring runs at\na 6.3 microsecond control interval, and per-interval decisions are recorded in\nan append-only, hash-chained audit log. Across Monte Carlo (Tier 1) and\ncloud-hardware emulation (Tier 2) evaluations, NADGO maintains leakage within\nbudget in nominal operation (interval-abort rate below 1 percent) and under\nattack yields high separation with concentrated aborts. At matched leakage\ntargets, microbenchmarks indicate lower latency and cryogenic power consumption\nthan static padding, while end-to-end workloads maintain competitive cost\nenvelopes.", "AI": {"tldr": "NADGO\u662f\u4e00\u4e2a\u91cf\u5b50\u8ba1\u7b97\u9690\u79c1\u4fdd\u62a4\u7cfb\u7edf\uff0c\u901a\u8fc7\u566a\u58f0\u81ea\u9002\u5e94\u865a\u62df\u95e8\u6df7\u6dc6\u3001\u65f6\u5e8f\u968f\u673a\u5316\u548c\u5b50\u7535\u8def\u8def\u7531\u7b49\u6280\u672f\uff0c\u5728\u4fdd\u8bc1\u8ba1\u7b97\u6027\u80fd\u7684\u540c\u65f6\u9650\u5236\u4fe1\u606f\u6cc4\u9732\uff0c\u5b9e\u73b0\u4e91\u91cf\u5b50\u670d\u52a1\u7684\u64cd\u4f5c\u9690\u79c1\u4fdd\u62a4\u3002", "motivation": "\u4e91\u91cf\u5b50\u670d\u52a1\u53ef\u80fd\u901a\u8fc7\u8c03\u5ea6\u5143\u6570\u636e\u3001\u5ef6\u8fdf\u6a21\u5f0f\u548c\u5171\u79df\u6237\u5e72\u6270\u6cc4\u9732\u7535\u8def\u7ed3\u6784\u548c\u65f6\u5e8f\u4fe1\u606f\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u4fdd\u62a4\u95e8\u6a21\u578b\u5de5\u4f5c\u8d1f\u8f7d\u7684\u64cd\u4f5c\u9690\u79c1\uff0c\u540c\u65f6\u652f\u6301\u673a\u5bc6\u6027\u548c\u516c\u5e73\u7684\u591a\u79df\u6237\u73af\u5883\u3002", "method": "\u7ed3\u5408\u786c\u4ef6\u611f\u77e5\u7684t-design\u586b\u5145\u751f\u6210\u7ed3\u6784\u5316\u8986\u76d6\u6d41\u91cf\u3001\u7c92\u5b50\u6ee4\u6ce2\u65f6\u5e8f\u968f\u673a\u5316\u63a9\u76d6\u961f\u5217\u6a21\u5f0f\u3001CASQUE\u5b50\u7535\u8def\u8de8\u5f02\u6784\u540e\u7aef\u8def\u7531\uff0c\u4ee5\u53ca\u5e26\u9501\u5b9a\u6821\u51c6\u5de5\u4ef6\u548c\u53cc\u9608\u503c\u7d27\u6025\u505c\u6b62\u7684\u6bcf\u95f4\u9694\u6cc4\u9732\u4f30\u8ba1\u5668\u3002", "result": "\u57284\u91cf\u5b50\u6bd4\u7279\u8d85\u5bfc\u82af\u7247\u4e0a\u539f\u578b\u9a8c\u8bc1\uff0c\u63a7\u5236\u95f4\u96946.3\u5fae\u79d2\uff0c\u5728\u6b63\u5e38\u64cd\u4f5c\u4e0b\u6cc4\u9732\u63a7\u5236\u5728\u9884\u7b97\u5185\uff08\u95f4\u9694\u4e2d\u6b62\u7387\u4f4e\u4e8e1%\uff09\uff0c\u653b\u51fb\u4e0b\u4ea7\u751f\u9ad8\u5206\u79bb\u5ea6\u548c\u96c6\u4e2d\u4e2d\u6b62\uff0c\u76f8\u6bd4\u9759\u6001\u586b\u5145\u5177\u6709\u66f4\u4f4e\u5ef6\u8fdf\u548c\u4f4e\u6e29\u529f\u8017\u3002", "conclusion": "NADGO\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u4fdd\u62a4\u4e91\u91cf\u5b50\u670d\u52a1\u7684\u64cd\u4f5c\u9690\u79c1\uff0c\u5728\u53ef\u63a5\u53d7\u7684\u6027\u80fd\u5f00\u9500\u4e0b\u5b9e\u73b0\u4fe1\u606f\u6cc4\u9732\u63a7\u5236\uff0c\u4e3a\u91cf\u5b50\u8ba1\u7b97\u670d\u52a1\u7684\u673a\u5bc6\u6027\u548c\u591a\u79df\u6237\u516c\u5e73\u6027\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.02372", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.02372", "abs": "https://arxiv.org/abs/2509.02372", "authors": ["Zhiyang Chen", "Tara Saba", "Xun Deng", "Xujie Si", "Fan Long"], "title": "Poisoned at Scale: A Scalable Audit Uncovers Hidden Scam Endpoints in Production LLMs", "comment": "10 pages, 4 figures", "summary": "Large Language Models (LLMs) have become critical to modern software\ndevelopment, but their reliance on internet datasets for training introduces a\nsignificant security risk: the absorption and reproduction of malicious\ncontent. To evaluate this threat, this paper introduces a scalable, automated\naudit framework that synthesizes innocuous, developer-style prompts from known\nscam databases to query production LLMs and determine if they generate code\ncontaining harmful URLs. We conducted a large-scale evaluation across four\nproduction LLMs (GPT-4o, GPT-4o-mini, Llama-4-Scout, and DeepSeek-V3), and\nfound a systemic vulnerability, with all tested models generating malicious\ncode at a non-negligible rate. On average, 4.2\\% of programs generated in our\nexperiments contained malicious URLs. Crucially, this malicious code is often\ngenerated in response to benign prompts. We manually validate the prompts which\ncause all four LLMs to generate malicious code, and resulting in 177 innocuous\nprompts that trigger all models to produce harmful outputs. These results\nprovide strong empirical evidence that the training data of production LLMs has\nbeen successfully poisoned at scale, underscoring the urgent need for more\nrobust defense mechanisms and post-generation safety checks to mitigate the\npropagation of hidden security threats.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u4e3b\u6d41LLMs\u5b58\u5728\u7cfb\u7edf\u6027\u5b89\u5168\u6f0f\u6d1e\uff0c\u5e73\u57474.2%\u7684\u751f\u6210\u4ee3\u7801\u5305\u542b\u6076\u610fURL\uff0c\u5373\u4f7f\u9762\u5bf9\u65e0\u5bb3\u63d0\u793a\u4e5f\u4f1a\u4ea7\u751f\u6709\u5bb3\u8f93\u51fa\uff0c\u8bc1\u660e\u8bad\u7ec3\u6570\u636e\u5df2\u5728\u5927\u89c4\u6a21\u4e0b\u6bd2", "motivation": "\u8bc4\u4f30LLMs\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5438\u6536\u548c\u91cd\u73b0\u6076\u610f\u5185\u5bb9\u7684\u5b89\u5168\u98ce\u9669\uff0c\u56e0\u4e3a\u5176\u4f9d\u8d56\u4e92\u8054\u7f51\u6570\u636e\u96c6\u8bad\u7ec3\u53ef\u80fd\u5f15\u5165\u5b89\u5168\u9690\u60a3", "method": "\u5f00\u53d1\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u5316\u5ba1\u8ba1\u6846\u67b6\uff0c\u4ece\u5df2\u77e5\u8bc8\u9a97\u6570\u636e\u5e93\u5408\u6210\u65e0\u5bb3\u7684\u5f00\u53d1\u8005\u98ce\u683c\u63d0\u793a\uff0c\u67e5\u8be2\u751f\u4ea7\u7ea7LLMs\u5e76\u68c0\u6d4b\u751f\u6210\u4ee3\u7801\u662f\u5426\u5305\u542b\u6709\u5bb3URL", "result": "\u5728\u56db\u4e2a\u751f\u4ea7\u7ea7LLM\uff08GPT-4o\u3001GPT-4o-mini\u3001Llama-4-Scout\u3001DeepSeek-V3\uff09\u7684\u5927\u89c4\u6a21\u8bc4\u4f30\u4e2d\u53d1\u73b0\u6240\u6709\u6a21\u578b\u90fd\u4ee5\u4e0d\u53ef\u5ffd\u89c6\u7684\u6bd4\u7387\u751f\u6210\u6076\u610f\u4ee3\u7801\uff0c\u5e73\u57474.2%\u7684\u7a0b\u5e8f\u5305\u542b\u6076\u610fURL", "conclusion": "\u7814\u7a76\u7ed3\u679c\u63d0\u4f9b\u4e86\u5f3a\u6709\u529b\u7ecf\u9a8c\u8bc1\u636e\uff0c\u8868\u660e\u751f\u4ea7\u7ea7LLMs\u7684\u8bad\u7ec3\u6570\u636e\u5df2\u6210\u529f\u88ab\u5927\u89c4\u6a21\u6295\u6bd2\uff0c\u8feb\u5207\u9700\u8981\u66f4\u5f3a\u5927\u7684\u9632\u5fa1\u673a\u5236\u548c\u751f\u6210\u540e\u5b89\u5168\u68c0\u67e5\u6765\u7f13\u89e3\u9690\u85cf\u5b89\u5168\u5a01\u80c1\u7684\u4f20\u64ad"}}
{"id": "2509.00740", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.00740", "abs": "https://arxiv.org/abs/2509.00740", "authors": ["Govind Waghmare", "Sumedh BG", "Sonia Gupta", "Srikanta Bedathur"], "title": "Efficient Graph Understanding with LLMs via Structured Context Injection", "comment": null, "summary": "Large Language Models (LLMs) have shown strong capabilities in solving\nproblems across domains, including graph-related tasks traditionally addressed\nby symbolic or algorithmic methods. In this work, we present a framework for\nstructured context injection, where task-specific information is systematically\nembedded in the input to guide LLMs in solving a wide range of graph problems.\nOur method does not require fine-tuning of LLMs, making it cost-efficient and\nlightweight. We observe that certain graph reasoning tasks remain challenging\nfor LLMs unless they are mapped to conceptually grounded representations.\nHowever, achieving such mappings through fine-tuning or repeated multi-step\nquerying can be expensive and inefficient. Our approach offers a practical\nalternative by injecting structured context directly into the input, enabling\nthe LLM to implicitly align the task with grounded conceptual spaces. We\nevaluate the approach on multiple graph tasks using both lightweight and large\nmodels, highlighting the trade-offs between accuracy and computational cost.\nThe results demonstrate consistent performance improvements, showing that\nstructured input context can rival or surpass more complex approaches. Our\nfindings underscore the value of structured context injection as an effective\nand scalable strategy for graph understanding with LLMs.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u6784\u5316\u4e0a\u4e0b\u6587\u6ce8\u5165\u6846\u67b6\uff0c\u901a\u8fc7\u5728LLM\u8f93\u5165\u4e2d\u7cfb\u7edf\u5730\u5d4c\u5165\u4efb\u52a1\u7279\u5b9a\u4fe1\u606f\u6765\u63d0\u5347\u56fe\u8bba\u8bba\u4efb\u52a1\u6027\u80fd\uff0c\u65e0\u9700\u5fae\u8c03\u4e14\u6210\u672c\u4f4e\u5ec9\u3002", "motivation": "\u867d\u7136LLM\u5728\u5404\u9886\u57df\u90fd\u663e\u793a\u51fa\u5f3a\u5927\u80fd\u529b\uff0c\u4f46\u67d0\u4e9b\u56fe\u8bba\u8bba\u4efb\u52a1\u4ecd\u9760\u6982\u5ff5\u57fa\u7840\u8868\u793a\u624d\u80fd\u6709\u6548\u89e3\u51b3\uff0c\u800c\u901a\u8fc7\u5fae\u8c03\u6216\u591a\u6b65\u67e5\u8be2\u5b9e\u73b0\u8fd9\u79cd\u6620\u5c04\u6210\u672c\u8fc7\u9ad8\u3002", "method": "\u5f00\u53d1\u7ed3\u6784\u5316\u4e0a\u4e0b\u6587\u6ce8\u5165\u6846\u67b6\uff0c\u5c06\u4efb\u52a1\u7279\u5b9a\u4fe1\u606f\u7cfb\u7edf\u5730\u5d4c\u5165\u5230LLM\u8f93\u5165\u4e2d\uff0c\u4f7f\u5f97LLM\u80fd\u591f\u9690\u5f0f\u5bf9\u9f50\u4efb\u52a1\u4e0e\u57fa\u7840\u6982\u5ff5\u7a7a\u95f4\u3002\u65b9\u6cd5\u4e0d\u9700\u8981\u5fae\u8c03LLM\u3002", "result": "\u5728\u591a\u4e2a\u56fe\u8bba\u4efb\u52a1\u4e0a\u8bc4\u4f30\u663e\u793a\u4e86\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\uff0c\u7ed3\u6784\u5316\u8f93\u5165\u4e0a\u4e0b\u6587\u7684\u6548\u679c\u53ef\u4ee5\u6bd4\u8f83\u6216\u8d85\u8d8a\u66f4\u590d\u6742\u7684\u65b9\u6cd5\u3002\u540c\u65f6\u5c55\u793a\u4e86\u8f7b\u91cf\u6a21\u578b\u548c\u5927\u6a21\u578b\u5728\u51c6\u786e\u6027\u4e0e\u8ba1\u7b97\u6210\u672c\u4e4b\u95f4\u7684\u4ea4\u6362\u3002", "conclusion": "\u7ed3\u6784\u5316\u4e0a\u4e0b\u6587\u6ce8\u5165\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u7b56\u7565\uff0c\u80fd\u591f\u6709\u6548\u5730\u63d0\u5347LLM\u5728\u56fe\u8bc6\u522b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2509.00820", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00820", "abs": "https://arxiv.org/abs/2509.00820", "authors": ["Zhenhua Xu", "Zhaokun Yan", "Binhan Xu", "Xin Tong", "Haitao Xu", "Yourong Chen", "Meng Han"], "title": "Unlocking the Effectiveness of LoRA-FP for Seamless Transfer Implantation of Fingerprints in Downstream Models", "comment": "Accepted By EMNLP2025", "summary": "With the rapid advancement of large language models (LLMs), safeguarding\nintellectual property (IP) has become increasingly critical. To address the\nchallenges of high costs and potential contamination in fingerprint\nintegration, we propose LoRA-FP, a lightweight, plug-and-play framework that\nembeds backdoor fingerprints into LoRA adapters through constrained\nfine-tuning. This design enables seamless fingerprint transplantation via\nparameter fusion, eliminating the need for full-parameter updates while\npreserving model integrity. Experimental results demonstrate that LoRA-FP not\nonly significantly reduces computational overhead compared to conventional\napproaches but also achieves superior robustness across diverse scenarios,\nincluding incremental training and model fusion. Our code and datasets are\npublicly available at https://github.com/Xuzhenhua55/LoRA-FP.", "AI": {"tldr": "LoRA-FP\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u5373\u63d2\u5373\u7528\u6846\u67b6\uff0c\u901a\u8fc7\u7ea6\u675f\u5fae\u8c03\u5728LoRA\u9002\u914d\u5668\u4e2d\u5d4c\u5165\u540e\u95e8\u6307\u7eb9\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u5e76\u4fdd\u6301\u6a21\u578b\u5b8c\u6574\u6027\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u4fdd\u62a4\u77e5\u8bc6\u4ea7\u6743\u53d8\u5f97\u65e5\u76ca\u91cd\u8981\u3002\u4f20\u7edf\u6307\u7eb9\u96c6\u6210\u65b9\u6cd5\u6210\u672c\u9ad8\u4e14\u53ef\u80fd\u6c61\u67d3\u6a21\u578b\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faLoRA-FP\u6846\u67b6\uff0c\u901a\u8fc7\u7ea6\u675f\u5fae\u8c03\u5728LoRA\u9002\u914d\u5668\u4e2d\u5d4c\u5165\u540e\u95e8\u6307\u7eb9\uff0c\u652f\u6301\u53c2\u6570\u878d\u5408\u5b9e\u73b0\u6307\u7eb9\u79fb\u690d\uff0c\u65e0\u9700\u5168\u53c2\u6570\u66f4\u65b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\uff0c\u5728\u4e0d\u540c\u573a\u666f\uff08\u5305\u62ec\u589e\u91cf\u8bad\u7ec3\u548c\u6a21\u578b\u878d\u5408\uff09\u4e2d\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "LoRA-FP\u4e3aLLM\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u8f7b\u91cf\u7ea7\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.00761", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.00761", "abs": "https://arxiv.org/abs/2509.00761", "authors": ["Ziqi Wang", "Boqin Yuan"], "title": "L-MARS -- Legal Multi-Agent Workflow with Orchestrated Reasoning and Agentic Search", "comment": null, "summary": "We present L-MARS (Legal Multi-Agent Workflow with Orchestrated Reasoning and\nAgentic Search), a system that reduces hallucination and uncertainty in legal\nquestion answering through coordinated multi-agent reasoning and retrieval.\nUnlike single-pass retrieval-augmented generation (RAG), L-MARS decomposes\nqueries into subproblems, issues targeted searches across heterogeneous sources\n(Serper web, local RAG, CourtListener case law), and employs a Judge Agent to\nverify sufficiency, jurisdiction, and temporal validity before answer\nsynthesis. This iterative reasoning-search-verification loop maintains\ncoherence, filters noisy evidence, and grounds answers in authoritative law. We\nevaluated L-MARS on LegalSearchQA, a new benchmark of 200 up-to-date multiple\nchoice legal questions in 2025. Results show that L-MARS substantially improves\nfactual accuracy, reduces uncertainty, and achieves higher preference scores\nfrom both human experts and LLM-based judges. Our work demonstrates that\nmulti-agent reasoning with agentic search offers a scalable and reproducible\nblueprint for deploying LLMs in high-stakes domains requiring precise legal\nretrieval and deliberation.", "AI": {"tldr": "L-MARS\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6cd5\u5f8b\u95ee\u7b54\u7cfb\u7edf\uff0c\u901a\u8fc7\u5206\u89e3\u67e5\u8be2\u3001\u5b9a\u5411\u641c\u7d22\u548c\u9a8c\u8bc1\u673a\u5236\uff0c\u663e\u8457\u51cf\u5c11\u5e7b\u89c9\u548c\u4e0d\u786e\u5b9a\u6027\uff0c\u5728LegalSearchQA\u57fa\u51c6\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u4f20\u7edf\u5355\u6b21\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u5728\u6cd5\u5f8b\u95ee\u7b54\u4e2d\u5b58\u5728\u5e7b\u89c9\u548c\u4e0d\u786e\u5b9a\u6027\uff0c\u9700\u8981\u66f4\u7cbe\u786e\u7684\u6cd5\u5f8b\u68c0\u7d22\u548c\u63a8\u7406\u673a\u5236\u6765\u5904\u7406\u9ad8\u98ce\u9669\u9886\u57df\u7684\u6cd5\u5f8b\u95ee\u9898\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\uff1a\u5206\u89e3\u67e5\u8be2\u4e3a\u5b50\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u5f02\u6784\u6e90(\u7f51\u7edc\u641c\u7d22\u3001\u672c\u5730RAG\u3001\u6848\u4f8b\u6cd5)\u8fdb\u884c\u5b9a\u5411\u641c\u7d22\uff0c\u4f7f\u7528\u6cd5\u5b98\u667a\u80fd\u4f53\u9a8c\u8bc1\u5145\u5206\u6027\u3001\u7ba1\u8f96\u6743\u548c\u65f6\u6548\u6027\uff0c\u901a\u8fc7\u8fed\u4ee3\u63a8\u7406-\u641c\u7d22-\u9a8c\u8bc1\u5faa\u73af\u5408\u6210\u7b54\u6848\u3002", "result": "\u57282025\u5e74200\u4e2a\u6700\u65b0\u6cd5\u5f8b\u9009\u62e9\u9898\u7684LegalSearchQA\u57fa\u51c6\u4e0a\uff0cL-MARS\u663e\u8457\u63d0\u9ad8\u4e8b\u5b9e\u51c6\u786e\u6027\uff0c\u51cf\u5c11\u4e0d\u786e\u5b9a\u6027\uff0c\u83b7\u5f97\u4eba\u7c7b\u4e13\u5bb6\u548cLLM\u6cd5\u5b98\u66f4\u9ad8\u7684\u504f\u597d\u8bc4\u5206\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u63a8\u7406\u4e0e\u667a\u80fd\u641c\u7d22\u76f8\u7ed3\u5408\uff0c\u4e3a\u5728\u9ad8\u98ce\u9669\u9886\u57df\u90e8\u7f72LLMs\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u53ef\u590d\u73b0\u7684\u84dd\u56fe\uff0c\u80fd\u591f\u5b9e\u73b0\u7cbe\u786e\u7684\u6cd5\u5f8b\u68c0\u7d22\u548c\u5ba1\u8bae\u3002"}}
{"id": "2509.00882", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00882", "abs": "https://arxiv.org/abs/2509.00882", "authors": ["Xiang Li", "Yueci Su", "Jiahao Liu", "Zhiwei Lin", "Yuebing Hou", "Peiming Gao", "Yuanchao Zhang"], "title": "VULSOVER: Vulnerability Detection via LLM-Driven Constraint Solving", "comment": null, "summary": "Traditional vulnerability detection methods rely heavily on predefined rule\nmatching, which often fails to capture vulnerabilities accurately. With the\nrise of large language models (LLMs), leveraging their ability to understand\ncode semantics has emerged as a promising direction for achieving more accurate\nand efficient vulnerability detection. However, current LLM-based approaches\nface significant challenges: instability in model outputs, limitations in\ncontext length, and hallucination. As a result, many existing solutions either\nuse LLMs merely to enrich predefined rule sets, thereby keeping the detection\nprocess fundamentally rule-based, or over-rely on them, leading to poor\nrobustness. To address these challenges, we propose a constraint-solving\napproach powered by LLMs named VULSOLVER. By modeling vulnerability detection\nas a constraint-solving problem, and by integrating static application security\ntesting (SAST) with the semantic reasoning capabilities of LLMs, our method\nenables the LLM to act like a professional human security expert. We assess\nVULSOLVER on the OWASP Benchmark (1,023 labeled samples), achieving 96.29%\naccuracy, 96.55% F1-score, and 100% recall. Applied to popular GitHub\nrepositories, VULSOLVER also identified 15 previously unknown high-severity\nvulnerabilities (CVSS 7.5-9.8), demonstrating its effectiveness in real-world\nsecurity analysis.", "AI": {"tldr": "VULSOLVER\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7ea6\u675f\u6c42\u89e3\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u6f0f\u6d1e\u68c0\u6d4b\u5efa\u6a21\u4e3a\u7ea6\u675f\u6c42\u89e3\u95ee\u9898\uff0c\u7ed3\u5408\u9759\u6001\u5e94\u7528\u5b89\u5168\u6d4b\u8bd5\u548cLLM\u7684\u8bed\u4e49\u63a8\u7406\u80fd\u529b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6f0f\u6d1e\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u5339\u914d\u7684\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u6cd5\u51c6\u786e\u6027\u4e0d\u8db3\uff0c\u800c\u73b0\u6709LLM\u65b9\u6cd5\u5b58\u5728\u8f93\u51fa\u4e0d\u7a33\u5b9a\u3001\u4e0a\u4e0b\u6587\u957f\u5ea6\u9650\u5236\u548c\u5e7b\u89c9\u95ee\u9898\uff0c\u8981\u4e48\u8fc7\u5ea6\u4f9d\u8d56\u89c4\u5219\uff0c\u8981\u4e48\u8fc7\u5ea6\u4f9d\u8d56LLM\u5bfc\u81f4\u9c81\u68d2\u6027\u5dee\u3002", "method": "\u63d0\u51faVULSOLVER\u65b9\u6cd5\uff0c\u5c06\u6f0f\u6d1e\u68c0\u6d4b\u5efa\u6a21\u4e3a\u7ea6\u675f\u6c42\u89e3\u95ee\u9898\uff0c\u6574\u5408\u9759\u6001\u5e94\u7528\u5b89\u5168\u6d4b\u8bd5(SAST)\u548cLLM\u7684\u8bed\u4e49\u63a8\u7406\u80fd\u529b\uff0c\u4f7fLLM\u80fd\u591f\u50cf\u4e13\u4e1a\u5b89\u5168\u4e13\u5bb6\u4e00\u6837\u5de5\u4f5c\u3002", "result": "\u5728OWASP Benchmark(1023\u4e2a\u6807\u8bb0\u6837\u672c)\u4e0a\u8fbe\u523096.29%\u51c6\u786e\u7387\u300196.55% F1\u5206\u6570\u548c100%\u53ec\u56de\u7387\u3002\u5728GitHub\u70ed\u95e8\u4ed3\u5e93\u4e2d\u53d1\u73b015\u4e2a\u5148\u524d\u672a\u77e5\u7684\u9ad8\u5371\u6f0f\u6d1e(CVSS 7.5-9.8)\u3002", "conclusion": "VULSOLVER\u901a\u8fc7\u7ea6\u675f\u6c42\u89e3\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86LLM\u5728\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u7684\u6311\u6218\uff0c\u5728\u51c6\u786e\u6027\u548c\u5b9e\u9645\u5e94\u7528\u6548\u679c\u65b9\u9762\u90fd\u8868\u73b0\u51fa\u8272\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u73b0\u5b9e\u4e16\u754c\u5b89\u5168\u5206\u6790\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2509.00768", "categories": ["cs.AI", "cond-mat.mtrl-sci", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.00768", "abs": "https://arxiv.org/abs/2509.00768", "authors": ["Lee Hyun", "Sohee Yoon", "Jinwoo Park", "Sue In Chae", "Seongeon Park", "Jooyeon Ahn", "Yebin Jung", "Youjung Chung", "Hogeun Chang", "Myeonginn Kang", "Jina Kim", "Ho-Gyeong Kim", "Myeonghun Jeong"], "title": "Aligning Reasoning LLMs for Materials Discovery with Physics-aware Rejection Sampling", "comment": "14 pages, 5 figures", "summary": "AI-driven materials discovery that couples automated experimentation with\nalgorithmic decision-making requires process aware recipe to property\npredictors that are accurate, calibrated, and physically admissible. We\napproach this as a reasoning problem with large reasoning models (LRMs). To\ninstill reasoning capability into language models, we curate reasoning traces\nfrom a teacher model to train a student model. However, most training pipelines\nselect reasoning traces using binary correctness or learned preference signals\nthat poorly reflect physical admissibility. We introduce Physics-aware\nRejection Sampling (PaRS), a training-time trace selection scheme that favors\ntraces consistent with fundamental physics and numerically close to targets,\nwith lightweight halting to control compute. We instantiate our framework with\na large student model fine-tuned on traces synthesized by a larger teacher\nmodel, and evaluate under matched token budgets against various rejection\nsampling baselines. Our method improves accuracy and calibration, reduces\nphysics-violation rates, and lowers sampling cost relative to baselines. These\nresults indicate that modest, domain-aware constraints combined with\ntrace-level selection provide a practical path toward reliable, efficient LRMs\nfor process-aware property prediction and closed-loop materials design.", "AI": {"tldr": "\u63d0\u51fa\u4e86Physics-aware Rejection Sampling (PaRS)\u65b9\u6cd5\uff0c\u901a\u8fc7\u7269\u7406\u611f\u77e5\u7684\u63a8\u7406\u8f68\u8ff9\u9009\u62e9\u6765\u8bad\u7ec3\u5927\u578b\u63a8\u7406\u6a21\u578b\uff0c\u63d0\u9ad8\u6750\u6599\u5c5e\u6027\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u7269\u7406\u4e00\u81f4\u6027\u3002", "motivation": "AI\u9a71\u52a8\u7684\u6750\u6599\u53d1\u73b0\u9700\u8981\u51c6\u786e\u3001\u6821\u51c6\u4e14\u7269\u7406\u53ef\u63a5\u53d7\u7684\u914d\u65b9\u5230\u5c5e\u6027\u9884\u6d4b\u5668\u3002\u73b0\u6709\u8bad\u7ec3\u7ba1\u9053\u4f7f\u7528\u4e8c\u5143\u6b63\u786e\u6027\u6216\u5b66\u4e60\u504f\u597d\u4fe1\u53f7\u6765\u9009\u62e9\u63a8\u7406\u8f68\u8ff9\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u4e0d\u80fd\u5f88\u597d\u5730\u53cd\u6620\u7269\u7406\u53ef\u63a5\u53d7\u6027\u3002", "method": "\u5f15\u5165Physics-aware Rejection Sampling (PaRS)\u8bad\u7ec3\u65f6\u8f68\u8ff9\u9009\u62e9\u65b9\u6848\uff0c\u4f18\u5148\u9009\u62e9\u7b26\u5408\u57fa\u7840\u7269\u7406\u539f\u7406\u4e14\u6570\u503c\u63a5\u8fd1\u76ee\u6807\u7684\u8f68\u8ff9\uff0c\u91c7\u7528\u8f7b\u91cf\u7ea7\u505c\u6b62\u673a\u5236\u63a7\u5236\u8ba1\u7b97\u6210\u672c\u3002\u4f7f\u7528\u5927\u578b\u6559\u5e08\u6a21\u578b\u5408\u6210\u7684\u8f68\u8ff9\u6765\u5fae\u8c03\u5b66\u751f\u6a21\u578b\u3002", "result": "\u76f8\u6bd4\u5404\u79cd\u62d2\u7edd\u91c7\u6837\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u6821\u51c6\u5ea6\uff0c\u964d\u4f4e\u4e86\u7269\u7406\u8fdd\u89c4\u7387\uff0c\u5e76\u51cf\u5c11\u4e86\u91c7\u6837\u6210\u672c\u3002", "conclusion": "\u9002\u5ea6\u7684\u9886\u57df\u611f\u77e5\u7ea6\u675f\u7ed3\u5408\u8f68\u8ff9\u7ea7\u9009\u62e9\uff0c\u4e3a\u8fc7\u7a0b\u611f\u77e5\u5c5e\u6027\u9884\u6d4b\u548c\u95ed\u73af\u6750\u6599\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u53ef\u9760\u3001\u9ad8\u6548\u7684\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u5b9e\u7528\u8def\u5f84\u3002"}}
{"id": "2509.00896", "categories": ["cs.CR", "cs.SY", "eess.SY", "D.2.0"], "pdf": "https://arxiv.org/pdf/2509.00896", "abs": "https://arxiv.org/abs/2509.00896", "authors": ["Maryam Mahdi Alhusseini", "Mohammad Reza Feizi Derakhshi"], "title": "Hybrid AI-Driven Intrusion Detection: Framework Leveraging Novel Feature Selection for Enhanced Network Security", "comment": "16 pages, 12 figures", "summary": "In today's rapidly evolving digital landscape, safeguarding network\ninfrastructures against cyberattacks has become a critical priority. This\nresearch presents an innovative AI-driven real-time intrusion detection\nframework designed to enhance network security, particularly in Wireless Sensor\nNetworks (WSNs) and Cloud Computing (CC) environments. The system employs\nclassical machine learning models, Logistic Regression, Decision Tree, and\nK-Nearest Neighbors, optimized through the novel Energy Valley Optimization\n(EVO) method using the NSL-KDD dataset. Feature selection significantly reduced\nthe number of input features from 42 to 18 while maintaining strong detection\ncapabilities. The proposed system achieved 98.95 percent accuracy with Decision\nTree, 98.47 percent with K-Nearest Neighbors, and 88.84 percent with Logistic\nRegression. Moreover, high precision, recall, and F1-scores were attained\nacross all classifiers while substantially reducing training and testing times,\nmaking the framework highly suitable for real-time applications. To ensure fair\ndetection across diverse attack types, dataset balancing via downsampling was\napplied to address class imbalance challenges. This investigation focuses on\nthe significance of advancing intrusion detection systems in cloud computing\nand WSNs. Overall, this work advances secure communications by delivering a\nscalable, low-latency, and high-accuracy intrusion detection solution aligned\nwith the latest trends in artificial intelligence, cybersecurity, and real-time\ndigital networks", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eAI\u7684\u5b9e\u65f6\u5165\u4fb5\u68c0\u6d4b\u6846\u67b6\uff0c\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u548c\u65b0\u578bEnergy Valley Optimization\u65b9\u6cd5\uff0c\u5728NSL-KDD\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe98.95%\u7684\u51c6\u786e\u7387\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u7279\u5f81\u6570\u91cf\u548c\u8ba1\u7b97\u65f6\u95f4\u3002", "motivation": "\u5728\u5feb\u901f\u53d1\u5c55\u7684\u6570\u5b57\u73af\u5883\u4e2d\uff0c\u4fdd\u62a4\u7f51\u7edc\u57fa\u7840\u8bbe\u65bd\u514d\u53d7\u7f51\u7edc\u653b\u51fb\u5df2\u6210\u4e3a\u5173\u952e\u4f18\u5148\u4e8b\u9879\uff0c\u7279\u522b\u662f\u5728\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u548c\u4e91\u8ba1\u7b97\u73af\u5883\u4e2d\u9700\u8981\u589e\u5f3a\u7f51\u7edc\u5b89\u5168\u3002", "method": "\u91c7\u7528\u903b\u8f91\u56de\u5f52\u3001\u51b3\u7b56\u6811\u548cK\u8fd1\u90bb\u7b49\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u901a\u8fc7\u65b0\u578bEnergy Valley Optimization\u65b9\u6cd5\u8fdb\u884c\u4f18\u5316\uff0c\u4f7f\u7528NSL-KDD\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u4e0b\u91c7\u6837\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "result": "\u7279\u5f81\u9009\u62e9\u5c06\u8f93\u5165\u7279\u5f81\u4ece42\u4e2a\u51cf\u5c11\u523018\u4e2a\uff0c\u51b3\u7b56\u6811\u51c6\u786e\u7387\u8fbe\u523098.95%\uff0cK\u8fd1\u90bb98.47%\uff0c\u903b\u8f91\u56de\u5f5288.84%\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u8bad\u7ec3\u548c\u6d4b\u8bd5\u65f6\u95f4\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u901a\u8fc7\u63d0\u4f9b\u53ef\u6269\u5c55\u3001\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u7cbe\u5ea6\u7684\u5165\u4fb5\u68c0\u6d4b\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u8fdb\u4e86\u5b89\u5168\u901a\u4fe1\uff0c\u7b26\u5408\u4eba\u5de5\u667a\u80fd\u3001\u7f51\u7edc\u5b89\u5168\u548c\u5b9e\u65f6\u6570\u5b57\u7f51\u7edc\u7684\u6700\u65b0\u8d8b\u52bf\u3002"}}
{"id": "2509.00793", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00793", "abs": "https://arxiv.org/abs/2509.00793", "authors": ["Shuai Ma", "Guangwu Liu", "Li Xia"], "title": "Sharpe Ratio Optimization in Markov Decision Processes", "comment": null, "summary": "Sharpe ratio (also known as reward-to-variability ratio) is a widely-used\nmetric in finance, which measures the additional return at the cost of per unit\nof increased risk (standard deviation of return). However, the optimization of\nSharpe ratio in Markov decision processes (MDPs) is challenging, because there\nexist two difficulties hindering the application of dynamic programming. One is\nthat dynamic programming does not work for fractional objectives, and the other\nis that dynamic programming is invalid for risk metrics. In this paper, we\nstudy the Sharpe ratio optimization in infinite-horizon MDPs, considering both\nthe long-run average and discounted settings. We address the first challenge\nwith the Dinkelbachs transform, which converts the Sharpe ratio objective to a\nmean-squared-variance (M2V) objective. It is shown that the M2V optimization\nand the original Sharpe ratio optimization share the same optimal policy when\nthe risk-sensitive parameter is equal to the optimal Sharpe ratio. For the\nsecond challenge, we develop an iterative algorithm to solve the M2V\noptimization which is similar to a mean-variance optimization in MDPs. We\niteratively solve the M2V problem and obtain the associated Sharpe ratio that\nis used to update the risk-sensitive parameter in the next iteration of M2V\nproblems. We show that such a sequence of Sharpe ratios derived is\nmonotonically increasing and converges to the optimal Sharpe ratio. For both\naverage and discounted MDP settings, we develop a policy iteration procedure\nand prove its convergence to the optimum. Numerical experiments are conducted\nfor validation. To the best of our knowledge, our approach is the first that\nsolves the Sharpe ratio optimization in MDPs with dynamic programming type\nalgorithms. We believe that the proposed algorithm can shed light on solving\nMDPs with other fractional objectives.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u4f18\u5316\u590f\u666e\u6bd4\u7387\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7Dinkelbach\u53d8\u6362\u5c06\u5206\u6570\u76ee\u6807\u8f6c\u6362\u4e3a\u5747\u503c-\u65b9\u5dee\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u4e86\u6536\u655b\u5230\u6700\u4f18\u89e3\u7684\u8fed\u4ee3\u7b97\u6cd5\u3002", "motivation": "\u590f\u666e\u6bd4\u7387\u662f\u91d1\u878d\u9886\u57df\u5e7f\u6cdb\u4f7f\u7528\u7684\u98ce\u9669\u8c03\u6574\u6536\u76ca\u6307\u6807\uff0c\u4f46\u5728MDP\u4e2d\u4f18\u5316\u590f\u666e\u6bd4\u7387\u9762\u4e34\u4e24\u4e2a\u6311\u6218\uff1a\u52a8\u6001\u89c4\u5212\u4e0d\u9002\u7528\u4e8e\u5206\u6570\u76ee\u6807\uff0c\u4e5f\u4e0d\u9002\u7528\u4e8e\u98ce\u9669\u5ea6\u91cf\u3002", "method": "\u4f7f\u7528Dinkelbach\u53d8\u6362\u5c06\u590f\u666e\u6bd4\u7387\u4f18\u5316\u8f6c\u6362\u4e3a\u5747\u503c-\u65b9\u5dee\u4f18\u5316\u95ee\u9898\uff0c\u5f00\u53d1\u8fed\u4ee3\u7b97\u6cd5\u6c42\u89e3M2V\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u7b56\u7565\u8fed\u4ee3\u8fc7\u7a0b\u66f4\u65b0\u98ce\u9669\u654f\u611f\u53c2\u6570\u3002", "result": "\u63d0\u51fa\u7684\u7b97\u6cd5\u80fd\u591f\u5355\u8c03\u9012\u589e\u5730\u6536\u655b\u5230\u6700\u4f18\u590f\u666e\u6bd4\u7387\uff0c\u5728\u5e73\u5747\u548c\u6298\u6263MDP\u8bbe\u7f6e\u4e0b\u90fd\u8bc1\u660e\u4e86\u6536\u655b\u6027\uff0c\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8fd9\u662f\u7b2c\u4e00\u4e2a\u4f7f\u7528\u52a8\u6001\u89c4\u5212\u7c7b\u7b97\u6cd5\u89e3\u51b3MDP\u4e2d\u590f\u666e\u6bd4\u7387\u4f18\u5316\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u4e3a\u89e3\u51b3\u5176\u4ed6\u5206\u6570\u76ee\u6807MDP\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2509.00918", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00918", "abs": "https://arxiv.org/abs/2509.00918", "authors": ["Xubin Yue", "Zhenhua Xu", "Wenpeng Xing", "Jiahui Yu", "Mohan Li", "Meng Han"], "title": "PREE: Towards Harmless and Adaptive Fingerprint Editing in Large Language Models via Knowledge Prefix Enhancement", "comment": null, "summary": "Addressing the intellectual property protection challenges in commercial\ndeployment of large language models (LLMs), existing black-box fingerprinting\ntechniques face dual challenges from incremental fine-tuning erasure and\nfeature-space defense due to their reliance on overfitting high-perplexity\ntrigger patterns. Recent work has revealed that model editing in the\nfingerprinting domain offers distinct advantages, including significantly lower\nfalse positive rates, enhanced harmlessness, and superior robustness. Building\non this foundation, this paper innovatively proposes a\n$\\textbf{Pr}$efix-$\\textbf{e}$nhanced Fingerprint $\\textbf{E}$diting Framework\n(PREE), which encodes copyright information into parameter offsets through\ndual-channel knowledge edit to achieve covert embedding of fingerprint\nfeatures. Experimental results demonstrate that the proposed solution achieves\nthe 90\\% trigger precision in mainstream architectures including LLaMA-3 and\nQwen-2.5. The minimal parameter offset (change rate < 0.03) effectively\npreserves original knowledge representation while demonstrating strong\nrobustness against incremental fine-tuning and multi-dimensional defense\nstrategies, maintaining zero false positive rate throughout evaluations.", "AI": {"tldr": "PREE\u6846\u67b6\u901a\u8fc7\u53cc\u901a\u9053\u77e5\u8bc6\u7f16\u8f91\u5c06\u7248\u6743\u4fe1\u606f\u7f16\u7801\u4e3a\u53c2\u6570\u504f\u79fb\uff0c\u5b9e\u73b0\u6307\u7eb9\u7279\u5f81\u7684\u9690\u853d\u5d4c\u5165\uff0c\u5728\u4e3b\u6d41\u5927\u6a21\u578b\u4e2d\u8fbe\u523090%\u89e6\u53d1\u7cbe\u5ea6\uff0c\u53c2\u6570\u53d8\u5316\u7387\u5c0f\u4e8e0.03%\uff0c\u4fdd\u6301\u96f6\u8bef\u62a5\u7387\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5546\u4e1a\u90e8\u7f72\u4e2d\u7684\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u6311\u6218\uff0c\u73b0\u6709\u9ed1\u76d2\u6307\u7eb9\u6280\u672f\u56e0\u4f9d\u8d56\u8fc7\u62df\u5408\u9ad8\u56f0\u60d1\u5ea6\u89e6\u53d1\u6a21\u5f0f\u800c\u9762\u4e34\u589e\u91cf\u5fae\u8c03\u64e6\u9664\u548c\u7279\u5f81\u7a7a\u95f4\u9632\u5fa1\u7684\u53cc\u91cd\u6311\u6218\u3002", "method": "\u63d0\u51fa\u524d\u7f00\u589e\u5f3a\u6307\u7eb9\u7f16\u8f91\u6846\u67b6(PREE)\uff0c\u901a\u8fc7\u53cc\u901a\u9053\u77e5\u8bc6\u7f16\u8f91\u5c06\u7248\u6743\u4fe1\u606f\u7f16\u7801\u4e3a\u53c2\u6570\u504f\u79fb\uff0c\u5b9e\u73b0\u6307\u7eb9\u7279\u5f81\u7684\u9690\u853d\u5d4c\u5165\u3002", "result": "\u5728LLaMA-3\u548cQwen-2.5\u7b49\u4e3b\u6d41\u67b6\u6784\u4e2d\u8fbe\u523090%\u89e6\u53d1\u7cbe\u5ea6\uff0c\u53c2\u6570\u53d8\u5316\u7387\u5c0f\u4e8e0.03%\uff0c\u5bf9\u589e\u91cf\u5fae\u8c03\u548c\u591a\u7ef4\u9632\u5fa1\u7b56\u7565\u8868\u73b0\u51fa\u5f3a\u9c81\u68d2\u6027\uff0c\u8bc4\u4f30\u671f\u95f4\u4fdd\u6301\u96f6\u8bef\u62a5\u7387\u3002", "conclusion": "PREE\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u6307\u7eb9\u6280\u672f\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u9690\u853d\u4e14\u9c81\u68d2\u7684\u6a21\u578b\u7248\u6743\u4fdd\u62a4\u3002"}}
{"id": "2509.00834", "categories": ["cs.AI", "cs.FL", "cs.LG", "cs.LO", "I.2.4; I.2.6"], "pdf": "https://arxiv.org/pdf/2509.00834", "abs": "https://arxiv.org/abs/2509.00834", "authors": ["Axel Mezini", "Elena Umili", "Ivan Donadello", "Fabrizio Maria Maggi", "Matteo Mancanelli", "Fabio Patrizi"], "title": "Neuro-Symbolic Predictive Process Monitoring", "comment": null, "summary": "This paper addresses the problem of suffix prediction in Business Process\nManagement (BPM) by proposing a Neuro-Symbolic Predictive Process Monitoring\n(PPM) approach that integrates data-driven learning with temporal logic-based\nprior knowledge. While recent approaches leverage deep learning models for\nsuffix prediction, they often fail to satisfy even basic logical constraints\ndue to the absence of explicit integration of domain knowledge during training.\nWe propose a novel method to incorporate Linear Temporal Logic over finite\ntraces (LTLf) into the training process of autoregressive sequence predictors.\nOur approach introduces a differentiable logical loss function, defined using a\nsoft approximation of LTLf semantics and the Gumbel-Softmax trick, which can be\ncombined with standard predictive losses. This ensures the model learns to\ngenerate suffixes that are both accurate and logically consistent. Experimental\nevaluation on three real-world datasets shows that our method improves suffix\nprediction accuracy and compliance with temporal constraints. We also introduce\ntwo variants of the logic loss (local and global) and demonstrate their\neffectiveness under noisy and realistic settings. While developed in the\ncontext of BPM, our framework is applicable to any symbolic sequence generation\ntask and contributes toward advancing Neuro-Symbolic AI.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u548c\u7b26\u53f7\u903b\u8f91\u7684\u9884\u6d4b\u6027\u8fc7\u7a0b\u76d1\u63a7\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u53ef\u5fae\u5206\u903b\u8f91\u635f\u5931\u51fd\u6570\u6765\u63d0\u9ad8\u540e\u7f00\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u903b\u8f91\u4e00\u81f4\u6027\u3002", "motivation": "\u5f53\u524d\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u4e1a\u52a1\u8fc7\u7a0b\u7ba1\u7406\u4e2d\u8fdb\u884c\u540e\u7f00\u9884\u6d4b\u65f6\uff0c\u7ecf\u5e38\u65e0\u6cd5\u6ee1\u8db3\u57fa\u672c\u7684\u903b\u8f91\u7ea6\u675f\uff0c\u56e0\u4e3a\u7f3a\u4e4f\u9886\u57df\u77e5\u8bc6\u7684\u660e\u786e\u96c6\u6210\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u5c06\u6709\u9650\u8ff9\u8e0f\u4e0a\u7684\u7ebf\u6027\u65f6\u6001\u903b\u8f91(LTLf)\u79ef\u5206\u5230\u81ea\u56de\u5f52\u5e8f\u5217\u9884\u6d4b\u5668\u7684\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u4f7f\u7528Gumbel-Softmax\u6280\u5de7\u5b9a\u4e49\u53ef\u5fae\u5206\u903b\u8f91\u635f\u5931\u51fd\u6570\u3002", "result": "\u5728\u4e09\u4e2a\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u540e\u7f00\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u65f6\u6001\u7ea6\u675f\u7684\u9075\u5faa\u7a0b\u5ea6\uff0c\u5e76\u5728\u566a\u58f0\u548c\u5b9e\u9645\u73af\u5883\u4e0b\u9a8c\u8bc1\u4e86\u5c40\u90e8\u548c\u5168\u5c40\u903b\u8f91\u635f\u5931\u53d8\u4f53\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u867d\u7136\u5728BPM\u80cc\u666f\u4e0b\u5f00\u53d1\uff0c\u4f46\u9002\u7528\u4e8e\u4efb\u4f55\u7b26\u53f7\u5e8f\u5217\u751f\u6210\u4efb\u52a1\uff0c\u4e3a\u63a8\u8fdb\u795e\u7ecf\u7b26\u53f7AI\u505a\u51fa\u4e86\u8d21\u732e\u3002"}}
{"id": "2509.00973", "categories": ["cs.CR", "cs.AI", "68T05, 68Q32, 94A60,", "I.2.6; I.2.3; I.2.0; D.4.6"], "pdf": "https://arxiv.org/pdf/2509.00973", "abs": "https://arxiv.org/abs/2509.00973", "authors": ["Kanchon Gharami", "Hansaka Aluvihare", "Shafika Showkat Moni", "Berker Pek\u00f6z"], "title": "Clone What You Can't Steal: Black-Box LLM Replication via Logit Leakage and Distillation", "comment": "8 pages. Accepted for publication in the proceedings of 7th IEEE\n  International Conference on Trust, Privacy and Security in Intelligent\n  Systems, and Applications (IEEE TPS 2025)", "summary": "Large Language Models (LLMs) are increasingly deployed in mission-critical\nsystems, facilitating tasks such as satellite operations, command-and-control,\nmilitary decision support, and cyber defense. Many of these systems are\naccessed through application programming interfaces (APIs). When such APIs lack\nrobust access controls, they can expose full or top-k logits, creating a\nsignificant and often overlooked attack surface. Prior art has mainly focused\non reconstructing the output projection layer or distilling surface-level\nbehaviors. However, regenerating a black-box model under tight query\nconstraints remains underexplored. We address that gap by introducing a\nconstrained replication pipeline that transforms partial logit leakage into a\nfunctional deployable substitute model clone. Our two-stage approach (i)\nreconstructs the output projection matrix by collecting top-k logits from under\n10k black-box queries via singular value decomposition (SVD) over the logits,\nthen (ii) distills the remaining architecture into compact student models with\nvarying transformer depths, trained on an open source dataset. A 6-layer\nstudent recreates 97.6% of the 6-layer teacher model's hidden-state geometry,\nwith only a 7.31% perplexity increase, and a 7.58 Negative Log-Likelihood\n(NLL). A 4-layer variant achieves 17.1% faster inference and 18.1% parameter\nreduction with comparable performance. The entire attack completes in under 24\ngraphics processing unit (GPU) hours and avoids triggering API rate-limit\ndefenses. These results demonstrate how quickly a cost-limited adversary can\nclone an LLM, underscoring the urgent need for hardened inference APIs and\nsecure on-premise defense deployments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7API logit\u6cc4\u6f0f\u6765\u514b\u9686\u9ed1\u76d2LLM\u7684\u65b9\u6cd5\uff0c\u4ec5\u9700\u4e0d\u52301\u4e07\u6b21\u67e5\u8be2\u5373\u53ef\u91cd\u5efa\u8f93\u51fa\u6295\u5f71\u77e9\u9635\uff0c\u5e76\u572824\u5c0f\u65f6\u5185\u751f\u6210\u529f\u80fd\u76f8\u5f53\u7684\u66ff\u4ee3\u6a21\u578b\u3002", "motivation": "\u968f\u7740LLM\u5728\u5173\u952e\u4efb\u52a1\u7cfb\u7edf\u4e2d\u7684\u90e8\u7f72\u589e\u52a0\uff0c\u7f3a\u4e4f\u5065\u58ee\u8bbf\u95ee\u63a7\u5236\u7684API\u4f1a\u66b4\u9732logits\u4fe1\u606f\uff0c\u5f62\u6210\u88ab\u5ffd\u89c6\u7684\u653b\u51fb\u9762\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u8f93\u51fa\u5c42\u91cd\u5efa\u6216\u8868\u9762\u884c\u4e3a\u84b8\u998f\uff0c\u4f46\u5728\u4e25\u683c\u67e5\u8be2\u7ea6\u675f\u4e0b\u91cd\u5efa\u9ed1\u76d2\u6a21\u578b\u7684\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u901a\u8fc7SVD\u5bf9top-k logits\u8fdb\u884c\u5947\u5f02\u503c\u5206\u89e3\uff0c\u7528\u4e0d\u52301\u4e07\u6b21\u67e5\u8be2\u91cd\u5efa\u8f93\u51fa\u6295\u5f71\u77e9\u9635\uff1b2) \u5c06\u5269\u4f59\u67b6\u6784\u84b8\u998f\u5230\u4e0d\u540c\u6df1\u5ea6\u7684\u7d27\u51d1\u5b66\u751f\u6a21\u578b\u4e2d\uff0c\u4f7f\u7528\u5f00\u6e90\u6570\u636e\u96c6\u8bad\u7ec3\u3002", "result": "6\u5c42\u5b66\u751f\u6a21\u578b\u91cd\u73b0\u4e8697.6%\u7684\u6559\u5e08\u6a21\u578b\u9690\u85cf\u72b6\u6001\u51e0\u4f55\u7ed3\u6784\uff0c\u56f0\u60d1\u5ea6\u4ec5\u589e\u52a07.31%\uff0cNLL\u4e3a7.58\u30024\u5c42\u53d8\u4f53\u5b9e\u73b017.1%\u7684\u63a8\u7406\u52a0\u901f\u548c18.1%\u7684\u53c2\u6570\u51cf\u5c11\uff0c\u6027\u80fd\u76f8\u5f53\u3002\u6574\u4e2a\u653b\u51fb\u572824 GPU\u5c0f\u65f6\u5185\u5b8c\u6210\uff0c\u4e0d\u4f1a\u89e6\u53d1API\u901f\u7387\u9650\u5236\u9632\u5fa1\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\u6210\u672c\u6709\u9650\u7684\u653b\u51fb\u8005\u53ef\u4ee5\u5feb\u901f\u514b\u9686LLM\uff0c\u5f3a\u8c03\u4e86\u9700\u8981\u5f3a\u5316\u63a8\u7406API\u548c\u5b89\u5168\u7684\u672c\u5730\u9632\u5fa1\u90e8\u7f72\u7684\u7d27\u8feb\u6027\u3002"}}
{"id": "2509.00891", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.00891", "abs": "https://arxiv.org/abs/2509.00891", "authors": ["Zonghai Yao", "Talha Chafekar", "Junda Wang", "Shuo Han", "Feiyun Ouyang", "Junhui Qian", "Lingxi Li", "Hong Yu"], "title": "ChatCLIDS: Simulating Persuasive AI Dialogues to Promote Closed-Loop Insulin Adoption in Type 1 Diabetes Care", "comment": "Equal contribution for the first two authors", "summary": "Real-world adoption of closed-loop insulin delivery systems (CLIDS) in type 1\ndiabetes remains low, driven not by technical failure, but by diverse\nbehavioral, psychosocial, and social barriers. We introduce ChatCLIDS, the\nfirst benchmark to rigorously evaluate LLM-driven persuasive dialogue for\nhealth behavior change. Our framework features a library of expert-validated\nvirtual patients, each with clinically grounded, heterogeneous profiles and\nrealistic adoption barriers, and simulates multi-turn interactions with nurse\nagents equipped with a diverse set of evidence-based persuasive strategies.\nChatCLIDS uniquely supports longitudinal counseling and adversarial social\ninfluence scenarios, enabling robust, multi-dimensional evaluation. Our\nfindings reveal that while larger and more reflective LLMs adapt strategies\nover time, all models struggle to overcome resistance, especially under\nrealistic social pressure. These results highlight critical limitations of\ncurrent LLMs for behavior change, and offer a high-fidelity, scalable testbed\nfor advancing trustworthy persuasive AI in healthcare and beyond.", "AI": {"tldr": "ChatCLIDS\u662f\u9996\u4e2a\u8bc4\u4f30LLM\u9a71\u52a8\u5065\u5eb7\u884c\u4e3a\u6539\u53d8\u5bf9\u8bdd\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u4e13\u5bb6\u9a8c\u8bc1\u7684\u865a\u62df\u60a3\u8005\u548c\u591a\u6837\u5316\u8bf4\u670d\u7b56\u7565\uff0c\u53d1\u73b0\u5f53\u524dLLM\u5728\u514b\u670d\u62b5\u6297\u548c\u793e\u4ea4\u538b\u529b\u65b9\u9762\u5b58\u5728\u5c40\u9650", "motivation": "\u95ed\u73af\u80f0\u5c9b\u7d20\u8f93\u9001\u7cfb\u7edf\u57281\u578b\u7cd6\u5c3f\u75c5\u4e2d\u7684\u5b9e\u9645\u91c7\u7528\u7387\u4f4e\uff0c\u4e3b\u8981\u7531\u4e8e\u884c\u4e3a\u3001\u5fc3\u7406\u548c\u793e\u4f1a\u969c\u788d\u800c\u975e\u6280\u672f\u6545\u969c\uff0c\u9700\u8981\u8bc4\u4f30LLM\u5728\u5065\u5eb7\u884c\u4e3a\u6539\u53d8\u4e2d\u7684\u8bf4\u670d\u5bf9\u8bdd\u80fd\u529b", "method": "\u521b\u5efa\u5305\u542b\u4e13\u5bb6\u9a8c\u8bc1\u865a\u62df\u60a3\u8005\u7684\u6846\u67b6\uff0c\u6a21\u62df\u4e0e\u914d\u5907\u5faa\u8bc1\u8bf4\u670d\u7b56\u7565\u7684\u62a4\u58eb\u4ee3\u7406\u8fdb\u884c\u591a\u8f6e\u4ea4\u4e92\uff0c\u652f\u6301\u7eb5\u5411\u54a8\u8be2\u548c\u5bf9\u6297\u6027\u793e\u4ea4\u5f71\u54cd\u573a\u666f", "result": "\u8f83\u5927\u578b\u548c\u66f4\u5177\u53cd\u601d\u6027\u7684LLM\u80fd\u591f\u968f\u65f6\u95f4\u8c03\u6574\u7b56\u7565\uff0c\u4f46\u6240\u6709\u6a21\u578b\u90fd\u96be\u4ee5\u514b\u670d\u62b5\u6297\uff0c\u7279\u522b\u662f\u5728\u73b0\u5b9e\u793e\u4ea4\u538b\u529b\u4e0b", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u5f53\u524dLLM\u5728\u884c\u4e3a\u6539\u53d8\u65b9\u9762\u7684\u5173\u952e\u5c40\u9650\u6027\uff0c\u4e3a\u63a8\u8fdb\u533b\u7597\u4fdd\u5065\u9886\u57df\u53ef\u4fe1\u8d56\u7684\u8bf4\u670d\u6027AI\u63d0\u4f9b\u4e86\u9ad8\u4fdd\u771f\u3001\u53ef\u6269\u5c55\u7684\u6d4b\u8bd5\u5e73\u53f0"}}
{"id": "2509.01046", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.01046", "abs": "https://arxiv.org/abs/2509.01046", "authors": ["Khashayar Khajavi", "Tao Wang"], "title": "Lightening the Load: A Cluster-Based Framework for A Lower-Overhead, Provable Website Fingerprinting Defense", "comment": null, "summary": "Website fingerprinting (WF) attacks remain a significant threat to encrypted\ntraffic, prompting the development of a wide range of defenses. Among these,\ntwo prominent classes are regularization-based defenses, which shape traffic\nusing fixed padding rules, and supersequence-based approaches, which conceal\ntraces among predefined patterns. In this work, we present a unified framework\nfor designing an adaptive WF defense that combines the effectiveness of\nregularization with the provable security of supersequence-style grouping. The\nscheme first extracts behavioural patterns from traces and clusters them into\n(k,l)-diverse anonymity sets; an early-time-series classifier (adapted from\nECDIRE) then switches from a conservative global set of regularization\nparameters to the lighter, set-specific parameters. We instantiate the design\nas Adaptive Tamaraw, a variant of Tamaraw that assigns padding parameters on a\nper-cluster basis while retaining its original information-theoretic guarantee.\nComprehensive experiments on public real-world datasets confirm the benefits.\nBy tuning k, operators can trade privacy for efficiency: in its high-privacy\nmode Adaptive Tamaraw pushes the bound on any attacker's accuracy below 30%,\nwhereas in efficiency-centred settings it cuts total overhead by 99% compared\nwith classic Tamaraw.", "AI": {"tldr": "\u63d0\u51fa\u4e86Adaptive Tamaraw\u9632\u5fa1\u6846\u67b6\uff0c\u7ed3\u5408\u6b63\u5219\u5316\u548c\u8d85\u5e8f\u5217\u65b9\u6cd5\u7684\u4f18\u52bf\uff0c\u901a\u8fc7\u805a\u7c7b\u548c\u81ea\u9002\u5e94\u53c2\u6570\u8c03\u6574\uff0c\u5728\u9690\u79c1\u4fdd\u62a4\u548c\u6548\u7387\u4e4b\u95f4\u5b9e\u73b0\u53ef\u8c03\u8282\u7684\u5e73\u8861", "motivation": "\u73b0\u6709\u7f51\u7ad9\u6307\u7eb9\u9632\u5fa1\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u6b63\u5219\u5316\u9632\u5fa1\u4f7f\u7528\u56fa\u5b9a\u586b\u5145\u89c4\u5219\uff0c\u8d85\u5e8f\u5217\u65b9\u6cd5\u4f9d\u8d56\u9884\u5b9a\u4e49\u6a21\u5f0f\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u6709\u6548\u6027\u53c8\u80fd\u63d0\u4f9b\u53ef\u8bc1\u660e\u5b89\u5168\u6027\u7684\u81ea\u9002\u5e94\u9632\u5fa1\u65b9\u6848", "method": "\u9996\u5148\u63d0\u53d6\u6d41\u91cf\u884c\u4e3a\u6a21\u5f0f\u5e76\u805a\u7c7b\u4e3a(k,l)-\u591a\u6837\u5316\u533f\u540d\u96c6\uff0c\u7136\u540e\u4f7f\u7528\u65e9\u671f\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u5668\u4ece\u4fdd\u5b88\u7684\u5168\u5c40\u6b63\u5219\u5316\u53c2\u6570\u5207\u6362\u5230\u66f4\u8f7b\u91cf\u7684\u96c6\u5408\u7279\u5b9a\u53c2\u6570", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u9ad8\u9690\u79c1\u6a21\u5f0f\u4e0b\u53ef\u5c06\u653b\u51fb\u8005\u51c6\u786e\u7387\u964d\u81f330%\u4ee5\u4e0b\uff0c\u6548\u7387\u4f18\u5148\u6a21\u5f0f\u4e0b\u76f8\u6bd4\u7ecf\u5178Tamaraw\u51cf\u5c1199%\u7684\u5f00\u9500", "conclusion": "Adaptive Tamaraw\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u9632\u5fa1\u6846\u67b6\uff0c\u901a\u8fc7\u53c2\u6570k\u7684\u8c03\u8282\u5b9e\u73b0\u4e86\u9690\u79c1\u4fdd\u62a4\u4e0e\u6548\u7387\u4e4b\u95f4\u7684\u7075\u6d3b\u6743\u8861\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u539f\u6709\u7684\u4fe1\u606f\u8bba\u5b89\u5168\u4fdd\u8bc1"}}
{"id": "2509.00923", "categories": ["cs.AI", "cs.GT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2509.00923", "abs": "https://arxiv.org/abs/2509.00923", "authors": ["Zakaria El Jaafari"], "title": "Robust Deep Monte Carlo Counterfactual Regret Minimization: Addressing Theoretical Risks in Neural Fictitious Self-Play", "comment": null, "summary": "Monte Carlo Counterfactual Regret Minimization (MCCFR) has emerged as a\ncornerstone algorithm for solving extensive-form games, but its integration\nwith deep neural networks introduces scale-dependent challenges that manifest\ndifferently across game complexities. This paper presents a comprehensive\nanalysis of how neural MCCFR component effectiveness varies with game scale and\nproposes an adaptive framework for selective component deployment. We identify\nthat theoretical risks such as nonstationary target distribution shifts, action\nsupport collapse, variance explosion, and warm-starting bias have\nscale-dependent manifestation patterns, requiring different mitigation\nstrategies for small versus large games. Our proposed Robust Deep MCCFR\nframework incorporates target networks with delayed updates, uniform\nexploration mixing, variance-aware training objectives, and comprehensive\ndiagnostic monitoring. Through systematic ablation studies on Kuhn and Leduc\nPoker, we demonstrate scale-dependent component effectiveness and identify\ncritical component interactions. The best configuration achieves final\nexploitability of 0.0628 on Kuhn Poker, representing a 60% improvement over the\nclassical framework (0.156). On the more complex Leduc Poker domain, selective\ncomponent usage achieves exploitability of 0.2386, a 23.5% improvement over the\nclassical framework (0.3703) and highlighting the importance of careful\ncomponent selection over comprehensive mitigation. Our contributions include:\n(1) a formal theoretical analysis of risks in neural MCCFR, (2) a principled\nmitigation framework with convergence guarantees, (3) comprehensive multi-scale\nexperimental validation revealing scale-dependent component interactions, and\n(4) practical guidelines for deployment in larger games.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u795e\u7ecfMCCFR\u5728\u4e0d\u540c\u89c4\u6a21\u535a\u5f08\u4e2d\u7684\u7ec4\u4ef6\u6709\u6548\u6027\u5dee\u5f02\uff0c\u63d0\u51fa\u4e86\u81ea\u9002\u5e94\u6846\u67b6Robust Deep MCCFR\uff0c\u901a\u8fc7\u76ee\u6807\u7f51\u7edc\u3001\u5747\u5300\u63a2\u7d22\u6df7\u5408\u7b49\u6280\u672f\u5728Kuhn\u548cLeduc\u6251\u514b\u4e0a\u5206\u522b\u5b9e\u73b0\u4e8660%\u548c23.5%\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u89e3\u51b3MCCFR\u4e0e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7ed3\u5408\u65f6\u5728\u4e0d\u540c\u89c4\u6a21\u535a\u5f08\u4e2d\u51fa\u73b0\u7684\u5c3a\u5ea6\u4f9d\u8d56\u6311\u6218\uff0c\u5305\u62ec\u975e\u5e73\u7a33\u76ee\u6807\u5206\u5e03\u504f\u79fb\u3001\u52a8\u4f5c\u652f\u6301\u5d29\u6e83\u3001\u65b9\u5dee\u7206\u70b8\u548c\u70ed\u542f\u52a8\u504f\u5dee\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faRobust Deep MCCFR\u6846\u67b6\uff0c\u5305\u542b\u5ef6\u8fdf\u66f4\u65b0\u7684\u76ee\u6807\u7f51\u7edc\u3001\u5747\u5300\u63a2\u7d22\u6df7\u5408\u3001\u65b9\u5dee\u611f\u77e5\u8bad\u7ec3\u76ee\u6807\u548c\u5168\u9762\u8bca\u65ad\u76d1\u63a7\uff0c\u901a\u8fc7\u7cfb\u7edf\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u7ec4\u4ef6\u6709\u6548\u6027\u3002", "result": "\u5728Kuhn\u6251\u514b\u4e0a\u8fbe\u52300.0628\u7684\u6700\u7ec8\u53ef\u5229\u7528\u6027\uff08\u6bd4\u7ecf\u5178\u6846\u67b6\u63d0\u534760%\uff09\uff0c\u5728Leduc\u6251\u514b\u4e0a\u8fbe\u52300.2386\u7684\u53ef\u5229\u7528\u6027\uff08\u63d0\u534723.5%\uff09\uff0c\u8bc1\u660e\u4e86\u9009\u62e9\u6027\u7ec4\u4ef6\u90e8\u7f72\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u795e\u7ecfMCCFR\u7ec4\u4ef6\u7684\u6709\u6548\u6027\u5177\u6709\u5c3a\u5ea6\u4f9d\u8d56\u6027\uff0c\u9700\u8981\u9488\u5bf9\u4e0d\u540c\u89c4\u6a21\u535a\u5f08\u91c7\u7528\u4e0d\u540c\u7684\u7f13\u89e3\u7b56\u7565\uff0c\u9009\u62e9\u6027\u7ec4\u4ef6\u90e8\u7f72\u6bd4\u5168\u9762\u7f13\u89e3\u66f4\u4e3a\u91cd\u8981\uff0c\u4e3a\u66f4\u5927\u89c4\u6a21\u535a\u5f08\u7684\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5357\u3002"}}
{"id": "2509.01178", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.01178", "abs": "https://arxiv.org/abs/2509.01178", "authors": ["Hao Guo", "Zhaoqian Liu", "Liqiang Peng", "Shuaishuai Li", "Ximing Fu", "Weiran Liu", "Lin Qu"], "title": "Efficient and High-Accuracy Secure Two-Party Protocols for a Class of Functions with Real-number Inputs", "comment": "17 pages, 3 figures", "summary": "In two-party secret sharing scheme, values are typically encoded as unsigned\nintegers $\\mathsf{uint}(x)$, whereas real-world applications often require\ncomputations on signed real numbers $\\mathsf{Real}(x)$. To enable secure\nevaluation of practical functions, it is essential to computing\n$\\mathsf{Real}(x)$ from shared inputs, as protocols take shares as input. At\nUSENIX'25, Guo et al. proposed an efficient method for computing signed integer\nvalues $\\mathsf{int}(x)$ from shares, which can be extended to compute\n$\\mathsf{Real}(x)$. However, their approach imposes a restrictive input\nconstraint $|x| < \\frac{L}{3}$ for $x \\in \\mathbb{Z}_L$, limiting its\napplicability in real-world scenarios. In this work, we significantly relax\nthis constraint to $|x| < B$ for any $B \\leq \\frac{L}{2}$, where $B =\n\\frac{L}{2}$ corresponding to the natural representable range in $x \\in\n\\mathbb{Z}_L$. This relaxes the restrictions and enables the computation of\n$\\mathsf{Real}(x)$ with loose or no input constraints. Building upon this\nfoundation, we present a generalized framework for designing secure protocols\nfor a broad class of functions, including integer division ($\\lfloor\n\\frac{x}{d} \\rfloor$), trigonometric ($\\sin(x)$) and exponential ($e^{-x}$)\nfunctions. Our experimental evaluation demonstrates that the proposed protocols\nachieve both high efficiency and high accuracy. Notably, our protocol for\nevaluating $e^{-x}$ reduces communication costs to approximately 31% of those\nin SirNN (S&P 21) and Bolt (S&P 24), with runtime speedups of up to $5.53\n\\times$ and $3.09 \\times$, respectively. In terms of accuracy, our protocol\nachieves a maximum ULP error of $1.435$, compared to $2.64$ for SirNN and\n$8.681$ for Bolt.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u4e24\u65b9\u79d8\u5bc6\u5171\u4eab\u65b9\u6848\uff0c\u663e\u8457\u653e\u5bbd\u4e86\u6709\u7b26\u53f7\u5b9e\u6570\u8ba1\u7b97\u7684\u8f93\u5165\u7ea6\u675f\uff0c\u4ece|x| < L/3\u6269\u5c55\u5230|x| < B\uff08B \u2264 L/2\uff09\uff0c\u5e76\u6784\u5efa\u4e86\u652f\u6301\u6574\u6570\u9664\u6cd5\u3001\u4e09\u89d2\u51fd\u6570\u548c\u6307\u6570\u51fd\u6570\u7684\u5b89\u5168\u8ba1\u7b97\u6846\u67b6\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5bf9\u6709\u7b26\u53f7\u5b9e\u6570\u8ba1\u7b97\u65bd\u52a0\u4e86\u4e25\u683c\u7684\u8f93\u5165\u7ea6\u675f|x| < L/3\uff0c\u9650\u5236\u4e86\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u9002\u7528\u6027\uff0c\u9700\u8981\u66f4\u5bbd\u677e\u7684\u7ea6\u675f\u6761\u4ef6\u6765\u652f\u6301\u66f4\u5e7f\u6cdb\u7684\u5b9e\u9645\u8ba1\u7b97\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u6539\u8fdb\u6709\u7b26\u53f7\u6574\u6570\u8ba1\u7b97\u65b9\u6cd5\uff0c\u5c06\u8f93\u5165\u7ea6\u675f\u653e\u5bbd\u5230|x| < B\uff08B \u2264 L/2\uff09\uff0c\u5e76\u57fa\u4e8e\u6b64\u6784\u5efa\u901a\u7528\u6846\u67b6\u6765\u5b89\u5168\u8ba1\u7b97\u6574\u6570\u9664\u6cd5\u3001\u4e09\u89d2\u51fd\u6570\u548c\u6307\u6570\u51fd\u6570\u7b49\u590d\u6742\u8fd0\u7b97\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u534f\u8bae\u5728\u6548\u7387\u548c\u7cbe\u5ea6\u4e0a\u90fd\u6709\u663e\u8457\u63d0\u5347\uff1ae^{-x}\u8ba1\u7b97\u7684\u901a\u4fe1\u6210\u672c\u964d\u4f4e\u81f3SirNN\u768431%\uff0c\u8fd0\u884c\u901f\u5ea6\u63d0\u53475.53\u500d\uff0c\u6700\u5927ULP\u8bef\u5dee\u4ec5\u4e3a1.435\uff0c\u4f18\u4e8e\u5bf9\u6bd4\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u653e\u5bbd\u4e86\u8f93\u5165\u7ea6\u675f\u9650\u5236\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u9ad8\u7cbe\u5ea6\u7684\u5b89\u5168\u51fd\u6570\u8ba1\u7b97\u6846\u67b6\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6709\u7b26\u53f7\u5b9e\u6570\u5b89\u5168\u8ba1\u7b97\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.00930", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.00930", "abs": "https://arxiv.org/abs/2509.00930", "authors": ["Yanxiao Zhao", "Yaqian Li", "Zihao Bo", "Rinyoichi Takezoe", "Haojia Hui", "Mo Guang", "Lei Ren", "Xiaolin Qin", "Kaiwen Long"], "title": "SATQuest: A Verifier for Logical Reasoning Evaluation and Reinforcement Fine-Tuning of LLMs", "comment": null, "summary": "Recent advances in Large Language Models (LLMs) have demonstrated remarkable\ngeneral reasoning capabilities. However, systematically evaluating and\nenhancing these reasoning capabilities is challenging due to the lack of\ncontrollable and scalable tools for fine-grained analysis. Existing benchmarks\nand datasets often lack the necessary variable control for multi-dimensional,\nsystematic analysis and training, or have narrow problem types and formats. To\naddress these limitations, we introduce SATQuest, a systematic verifier\ndesigned to evaluate and enhance logical reasoning in LLMs by generating\ndiverse, Satisfiability-based logical reasoning problems directly from\nConjunctive Normal Form (CNF) instances. SATQuest structures these problems\nalong three orthogonal dimensions: instance scale, problem type, and question\nformat, employing randomized, SAT-based problem generation and objective answer\nverification via PySAT. This design mitigates memorization issues, allows for\nnuanced insights into reasoning performance, and enables effective\nreinforcement fine-tuning. Our extensive evaluation of various LLMs using\nSATQuest identified significant limitations in their logical reasoning,\nparticularly in generalizing beyond familiar mathematical formats. Furthermore,\nwe show that reinforcement fine-tuning with SATQuest rewards substantially\nimproves targeted task performance and generalizes to more complex instances,\nwhile highlighting remaining challenges in cross-format adaptation. Through\nthese demonstrations, we showcase SATQuest's potential as a foundational tool\nand a valuable starting point for advancing LLM logical reasoning.", "AI": {"tldr": "SATQuest\u662f\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684\u9a8c\u8bc1\u5de5\u5177\uff0c\u901a\u8fc7\u4eceCNF\u5b9e\u4f8b\u751f\u6210\u591a\u6837\u5316\u7684\u53ef\u6ee1\u8db3\u6027\u903b\u8f91\u63a8\u7406\u95ee\u9898\u6765\u8bc4\u4f30\u548c\u589e\u5f3aLLM\u7684\u903b\u8f91\u63a8\u7406\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u7f3a\u4e4f\u53ef\u63a7\u6027\u548c\u591a\u7ef4\u5206\u6790\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u57fa\u51c6\u6d4b\u8bd5\u7f3a\u4e4f\u53ef\u63a7\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u65e0\u6cd5\u8fdb\u884c\u591a\u7ef4\u5ea6\u7684\u7cfb\u7edf\u5316\u5206\u6790\u548c\u8bad\u7ec3\uff0c\u6216\u8005\u95ee\u9898\u7c7b\u578b\u548c\u683c\u5f0f\u8fc7\u4e8e\u72ed\u7a84\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u7cfb\u7edf\u8bc4\u4f30\u548c\u589e\u5f3aLLM\u903b\u8f91\u63a8\u7406\u80fd\u529b\u7684\u5de5\u5177\u3002", "method": "\u5f00\u53d1SATQuest\u7cfb\u7edf\uff0c\u4ece\u5408\u53d6\u8303\u5f0f(CNF)\u5b9e\u4f8b\u751f\u6210\u591a\u6837\u5316\u7684\u53ef\u6ee1\u8db3\u6027\u903b\u8f91\u63a8\u7406\u95ee\u9898\uff0c\u6cbf\u4e09\u4e2a\u6b63\u4ea4\u7ef4\u5ea6\uff08\u5b9e\u4f8b\u89c4\u6a21\u3001\u95ee\u9898\u7c7b\u578b\u3001\u95ee\u9898\u683c\u5f0f\uff09\u6784\u5efa\u95ee\u9898\uff0c\u91c7\u7528\u968f\u673a\u5316\u3001\u57fa\u4e8eSAT\u7684\u95ee\u9898\u751f\u6210\u548c\u901a\u8fc7PySAT\u8fdb\u884c\u5ba2\u89c2\u7b54\u6848\u9a8c\u8bc1\u3002", "result": "\u5bf9\u5404\u79cdLLM\u7684\u5e7f\u6cdb\u8bc4\u4f30\u53d1\u73b0\u4e86\u5b83\u4eec\u5728\u903b\u8f91\u63a8\u7406\u65b9\u9762\u7684\u663e\u8457\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u8d85\u8d8a\u719f\u6089\u6570\u5b66\u683c\u5f0f\u7684\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u3002\u4f7f\u7528SATQuest\u5956\u52b1\u8fdb\u884c\u5f3a\u5316\u5fae\u8c03\u663e\u8457\u63d0\u9ad8\u4e86\u76ee\u6807\u4efb\u52a1\u6027\u80fd\uff0c\u5e76\u80fd\u6cdb\u5316\u5230\u66f4\u590d\u6742\u7684\u5b9e\u4f8b\u3002", "conclusion": "SATQuest\u5c55\u793a\u4e86\u4f5c\u4e3a\u57fa\u7840\u5de5\u5177\u7684\u6f5c\u529b\uff0c\u662f\u63a8\u8fdbLLM\u903b\u8f91\u63a8\u7406\u80fd\u529b\u7684\u5b9d\u8d35\u8d77\u70b9\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u8de8\u683c\u5f0f\u9002\u5e94\u7684\u5269\u4f59\u6311\u6218\u3002"}}
{"id": "2509.01211", "categories": ["cs.CR", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.01211", "abs": "https://arxiv.org/abs/2509.01211", "authors": ["Dezhang Kong", "Hujin Peng", "Yilun Zhang", "Lele Zhao", "Zhenhua Xu", "Shi Lin", "Changting Lin", "Meng Han"], "title": "Web Fraud Attacks Against LLM-Driven Multi-Agent Systems", "comment": null, "summary": "With the proliferation of applications built upon LLM-driven multi-agent\nsystems (MAS), the security of Web links has become a critical concern in\nensuring system reliability. Once an agent is induced to visit a malicious\nwebsite, attackers can use it as a springboard to conduct diverse subsequent\nattacks, which will drastically expand the attack surface. In this paper, we\npropose Web Fraud Attacks, a novel type of attack aiming at inducing MAS to\nvisit malicious websites. We design 11 representative attack variants that\nencompass domain name tampering (homoglyph deception, character substitution,\netc.), link structure camouflage (sub-directory nesting, sub-domain grafting,\nparameter obfuscation, etc.), and other deceptive techniques tailored to\nexploit MAS's vulnerabilities in link validation. Through extensive experiments\non these crafted attack vectors, we demonstrate that Web fraud attacks not only\nexhibit significant destructive potential across different MAS architectures\nbut also possess a distinct advantage in evasion: they circumvent the need for\ncomplex input formats such as jailbreaking, which inherently carry higher\nexposure risks. These results underscore the importance of addressing Web fraud\nattacks in LLM-driven MAS, as their stealthiness and destructiveness pose\nnon-negligible threats to system security and user safety.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9LLM\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u65b0\u578bWeb\u6b3a\u8bc8\u653b\u51fb\uff0c\u901a\u8fc7\u57df\u540d\u7be1\u6539\u3001\u94fe\u63a5\u7ed3\u6784\u4f2a\u88c5\u7b49\u6280\u672f\u8bf1\u5bfc\u667a\u80fd\u4f53\u8bbf\u95ee\u6076\u610f\u7f51\u7ad9\uff0c\u5177\u6709\u663e\u8457\u7684\u7834\u574f\u6f5c\u529b\u548c\u89c4\u907f\u4f18\u52bf\u3002", "motivation": "\u968f\u7740\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5e94\u7528\u6fc0\u589e\uff0cWeb\u94fe\u63a5\u5b89\u5168\u6210\u4e3a\u786e\u4fdd\u7cfb\u7edf\u53ef\u9760\u6027\u7684\u5173\u952e\u95ee\u9898\u3002\u653b\u51fb\u8005\u4e00\u65e6\u8bf1\u5bfc\u667a\u80fd\u4f53\u8bbf\u95ee\u6076\u610f\u7f51\u7ad9\uff0c\u5c31\u80fd\u4ee5\u6b64\u4e3a\u8df3\u677f\u8fdb\u884c\u540e\u7eed\u653b\u51fb\uff0c\u5927\u5e45\u6269\u5927\u653b\u51fb\u9762\u3002", "method": "\u8bbe\u8ba1\u4e8611\u79cd\u4ee3\u8868\u6027\u653b\u51fb\u53d8\u4f53\uff0c\u5305\u62ec\u57df\u540d\u7be1\u6539\uff08\u540c\u5f62\u5f02\u4e49\u5b57\u6b3a\u9a97\u3001\u5b57\u7b26\u66ff\u6362\u7b49\uff09\u3001\u94fe\u63a5\u7ed3\u6784\u4f2a\u88c5\uff08\u5b50\u76ee\u5f55\u5d4c\u5957\u3001\u5b50\u57df\u540d\u5ac1\u63a5\u3001\u53c2\u6570\u6df7\u6dc6\u7b49\uff09\u4ee5\u53ca\u5176\u4ed6\u9488\u5bf9MAS\u94fe\u63a5\u9a8c\u8bc1\u6f0f\u6d1e\u7684\u6b3a\u9a97\u6280\u672f\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\uff0cWeb\u6b3a\u8bc8\u653b\u51fb\u4e0d\u4ec5\u5728\u4e0d\u540cMAS\u67b6\u6784\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u7684\u7834\u574f\u6f5c\u529b\uff0c\u800c\u4e14\u5728\u89c4\u907f\u68c0\u6d4b\u65b9\u9762\u5177\u6709\u660e\u663e\u4f18\u52bf\uff1a\u65e0\u9700\u590d\u6742\u7684\u8f93\u5165\u683c\u5f0f\u5982\u8d8a\u72f1\uff0c\u4ece\u800c\u964d\u4f4e\u4e86\u66b4\u9732\u98ce\u9669\u3002", "conclusion": "Web\u6b3a\u8bc8\u653b\u51fb\u7684\u9690\u853d\u6027\u548c\u7834\u574f\u6027\u5bf9\u7cfb\u7edf\u5b89\u5168\u548c\u7528\u6237\u5b89\u5168\u6784\u6210\u4e86\u4e0d\u53ef\u5ffd\u89c6\u7684\u5a01\u80c1\uff0c\u5f3a\u8c03\u4e86\u5728LLM\u9a71\u52a8\u7684MAS\u4e2d\u89e3\u51b3\u6b64\u7c7b\u653b\u51fb\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2509.00936", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00936", "abs": "https://arxiv.org/abs/2509.00936", "authors": ["Kishor Datta Gupta", "Md Manjurul Ahsan", "Mohd Ariful Haque", "Roy George", "Azmine Toushik Wasi"], "title": "UrbanInsight: A Distributed Edge Computing Framework with LLM-Powered Data Filtering for Smart City Digital Twins", "comment": null, "summary": "Cities today generate enormous streams of data from sensors, cameras, and\nconnected infrastructure. While this information offers unprecedented\nopportunities to improve urban life, most existing systems struggle with scale,\nlatency, and fragmented insights. This work introduces a framework that blends\nphysics-informed machine learning, multimodal data fusion, and knowledge graph\nrepresentation with adaptive, rule-based intelligence powered by large language\nmodels (LLMs). Physics-informed methods ground learning in real-world\nconstraints, ensuring predictions remain meaningful and consistent with\nphysical dynamics. Knowledge graphs act as the semantic backbone, integrating\nheterogeneous sensor data into a connected, queryable structure. At the edge,\nLLMs generate context-aware rules that adapt filtering and decision-making in\nreal time, enabling efficient operation even under constrained resources.\nTogether, these elements form a foundation for digital twin systems that go\nbeyond passive monitoring to provide actionable insights. By uniting\nphysics-based reasoning, semantic data fusion, and adaptive rule generation,\nthis approach opens new possibilities for creating responsive, trustworthy, and\nsustainable smart infrastructures.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408\u7269\u7406\u4fe1\u606f\u673a\u5668\u5b66\u4e60\u3001\u591a\u6a21\u6001\u6570\u636e\u878d\u5408\u3001\u77e5\u8bc6\u56fe\u8c31\u548cLLM\u81ea\u9002\u5e94\u89c4\u5219\u7684\u667a\u80fd\u57ce\u5e02\u6570\u5b57\u5b6a\u751f\u6846\u67b6\uff0c\u5b9e\u73b0\u4ece\u88ab\u52a8\u76d1\u63a7\u5230\u4e3b\u52a8\u6d1e\u5bdf\u7684\u8f6c\u53d8", "motivation": "\u89e3\u51b3\u73b0\u6709\u57ce\u5e02\u6570\u636e\u7cfb\u7edf\u5728\u89c4\u6a21\u3001\u5ef6\u8fdf\u548c\u788e\u7247\u5316\u6d1e\u5bdf\u65b9\u9762\u7684\u6311\u6218\uff0c\u5145\u5206\u5229\u7528\u4f20\u611f\u5668\u548c\u8fde\u63a5\u57fa\u7840\u8bbe\u65bd\u4ea7\u751f\u7684\u6d77\u91cf\u6570\u636e\u6765\u6539\u5584\u57ce\u5e02\u751f\u6d3b", "method": "\u878d\u5408\u7269\u7406\u4fe1\u606f\u673a\u5668\u5b66\u4e60\uff08\u786e\u4fdd\u9884\u6d4b\u7b26\u5408\u7269\u7406\u7ea6\u675f\uff09\u3001\u77e5\u8bc6\u56fe\u8c31\uff08\u4f5c\u4e3a\u8bed\u4e49\u9aa8\u5e72\u6574\u5408\u5f02\u6784\u6570\u636e\uff09\u3001LLM\u9a71\u52a8\u7684\u81ea\u9002\u5e94\u89c4\u5219\u751f\u6210\uff08\u5b9e\u73b0\u5b9e\u65f6\u8fb9\u7f18\u51b3\u7b56\uff09", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u8d85\u8d8a\u88ab\u52a8\u76d1\u63a7\u7684\u6570\u5b57\u5b6a\u751f\u7cfb\u7edf\u57fa\u7840\uff0c\u80fd\u591f\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u6d1e\u5bdf\uff0c\u5b9e\u73b0\u9ad8\u6548\u8d44\u6e90\u7ea6\u675f\u4e0b\u7684\u5b9e\u65f6\u64cd\u4f5c", "conclusion": "\u901a\u8fc7\u7edf\u4e00\u7269\u7406\u63a8\u7406\u3001\u8bed\u4e49\u6570\u636e\u878d\u5408\u548c\u81ea\u9002\u5e94\u89c4\u5219\u751f\u6210\uff0c\u4e3a\u521b\u5efa\u54cd\u5e94\u5f0f\u3001\u53ef\u4fe1\u8d56\u548c\u53ef\u6301\u7eed\u7684\u667a\u80fd\u57fa\u7840\u8bbe\u65bd\u5f00\u8f9f\u4e86\u65b0\u53ef\u80fd\u6027"}}
{"id": "2509.01253", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.01253", "abs": "https://arxiv.org/abs/2509.01253", "authors": ["Sayan Biswas", "Philippe Chartier", "Akash Dhasade", "Tom Jurien", "David Kerriou", "Anne-Marie Kerrmarec", "Mohammed Lemou", "Franklin Tranie", "Martijn de Vos", "Milos Vujasinovic"], "title": "Practical and Private Hybrid ML Inference with Fully Homomorphic Encryption", "comment": null, "summary": "In contemporary cloud-based services, protecting users' sensitive data and\nensuring the confidentiality of the server's model are critical. Fully\nhomomorphic encryption (FHE) enables inference directly on encrypted inputs,\nbut its practicality is hindered by expensive bootstrapping and inefficient\napproximations of non-linear activations. We introduce Safhire, a hybrid\ninference framework that executes linear layers under encryption on the server\nwhile offloading non-linearities to the client in plaintext. This design\neliminates bootstrapping, supports exact activations, and significantly reduces\ncomputation. To safeguard model confidentiality despite client access to\nintermediate outputs, Safhire applies randomized shuffling, which obfuscates\nintermediate values and makes it practically impossible to reconstruct the\nmodel. To further reduce latency, Safhire incorporates advanced optimizations\nsuch as fast ciphertext packing and partial extraction. Evaluations on multiple\nstandard models and datasets show that Safhire achieves 1.5X - 10.5X lower\ninference latency than Orion, a state-of-the-art baseline, with manageable\ncommunication overhead and comparable accuracy, thereby establishing the\npracticality of hybrid FHE inference.", "AI": {"tldr": "Safhire\u662f\u4e00\u4e2a\u6df7\u5408\u63a8\u7406\u6846\u67b6\uff0c\u5728\u670d\u52a1\u5668\u4e0a\u52a0\u5bc6\u6267\u884c\u7ebf\u6027\u5c42\uff0c\u5c06\u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\u5378\u8f7d\u5230\u5ba2\u6237\u7aef\u660e\u6587\u5904\u7406\uff0c\u6d88\u9664FHE\u7684\u6602\u8d35\u81ea\u4e3e\u64cd\u4f5c\uff0c\u901a\u8fc7\u968f\u673a\u6df7\u6d17\u4fdd\u62a4\u6a21\u578b\u673a\u5bc6\u6027\uff0c\u5b9e\u73b01.5-10.5\u500d\u5ef6\u8fdf\u964d\u4f4e", "motivation": "\u89e3\u51b3\u5b8c\u5168\u540c\u6001\u52a0\u5bc6(FHE)\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u74f6\u9888\u95ee\u9898\uff1a\u6602\u8d35\u7684\u81ea\u4e3e\u64cd\u4f5c\u548c\u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\u7684\u9ad8\u6548\u8fd1\u4f3c\u56f0\u96be\uff0c\u540c\u65f6\u9700\u8981\u4fdd\u62a4\u7528\u6237\u654f\u611f\u6570\u636e\u548c\u670d\u52a1\u5668\u6a21\u578b\u673a\u5bc6\u6027", "method": "\u91c7\u7528\u6df7\u5408\u63a8\u7406\u67b6\u6784\uff1a\u670d\u52a1\u5668\u52a0\u5bc6\u6267\u884c\u7ebf\u6027\u5c42\uff0c\u5ba2\u6237\u7aef\u660e\u6587\u5904\u7406\u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff1b\u4f7f\u7528\u968f\u673a\u6df7\u6d17\u6280\u672f\u6df7\u6dc6\u4e2d\u95f4\u503c\u4fdd\u62a4\u6a21\u578b\uff1b\u91c7\u7528\u5feb\u901f\u5bc6\u6587\u6253\u5305\u548c\u90e8\u5206\u63d0\u53d6\u7b49\u4f18\u5316\u6280\u672f", "result": "\u5728\u591a\u4e2a\u6807\u51c6\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u7684Orion\u57fa\u51c6\uff0c\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e1.5-10.5\u500d\uff0c\u901a\u4fe1\u5f00\u9500\u53ef\u63a7\uff0c\u7cbe\u5ea6\u76f8\u5f53", "conclusion": "Safhire\u8bc1\u660e\u4e86\u6df7\u5408FHE\u63a8\u7406\u7684\u5b9e\u7528\u6027\uff0c\u901a\u8fc7\u6d88\u9664\u81ea\u4e3e\u3001\u652f\u6301\u7cbe\u786e\u6fc0\u6d3b\u51fd\u6570\u548c\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\uff0c\u4e3a\u4fdd\u62a4\u9690\u79c1\u7684\u4e91\u670d\u52a1\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.00958", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.00958", "abs": "https://arxiv.org/abs/2509.00958", "authors": ["Manish Verma", "Vivek Sharma", "Vishal Singh"], "title": "A Hybrid Ai Framework For Strategic Patent Portfolio Pruning: Integrating Learning To-Rank And Market Need Analysis For Technology Transfer Optimization", "comment": "Page 2, Figure 1 shows the conceptual architecture, and Page 11,\n  Figure 2 outlines its end to end workflow for strategic patent portfolio\n  pruning", "summary": "This paper introduces a novel, multi stage hybrid intelligence framework for\npruning patent portfolios to identify high value assets for technology\ntransfer. Current patent valuation methods often rely on retrospective\nindicators or manual, time intensive analysis. Our framework automates and\ndeepens this process by combining a Learning to Rank (LTR) model, which\nevaluates patents against over 30 legal and commercial parameters, with a\nunique \"Need-Seed\" agent-based system. The \"Need Agent\" uses Natural Language\nProcessing (NLP) to mine unstructured market and industry data, identifying\nexplicit technological needs. Concurrently, the \"Seed Agent\" employs fine tuned\nLarge Language Models (LLMs) to analyze patent claims and map their\ntechnological capabilities. The system generates a \"Core Ontology Framework\"\nthat matches high potential patents (Seeds) to documented market demands\n(Needs), providing a strategic rationale for divestment decisions. We detail\nthe architecture, including a dynamic parameter weighting system and a crucial\nHuman in the-Loop (HITL) validation protocol, to ensure both adaptability and\nreal-world credibility.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u9636\u6bb5\u6df7\u5408\u667a\u80fd\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u5b66\u4e60\u6392\u5e8f\u6a21\u578b\u548cNeed-Seed\u4ee3\u7406\u7cfb\u7edf\uff0c\u81ea\u52a8\u8bc6\u522b\u9ad8\u4ef7\u503c\u4e13\u5229\u8d44\u4ea7\u8fdb\u884c\u6280\u672f\u8f6c\u79fb\u3002", "motivation": "\u73b0\u6709\u4e13\u5229\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u56de\u987e\u6027\u6307\u6807\u6216\u8017\u65f6\u7684\u4eba\u5de5\u5206\u6790\uff0c\u9700\u8981\u66f4\u81ea\u52a8\u5316\u3001\u6df1\u5165\u7684\u4e13\u5229\u7ec4\u5408\u4fee\u526a\u65b9\u6cd5\u6765\u8bc6\u522b\u9ad8\u4ef7\u503c\u6280\u672f\u8f6c\u79fb\u8d44\u4ea7\u3002", "method": "\u7ed3\u5408\u5b66\u4e60\u6392\u5e8f\u6a21\u578b\uff08\u8bc4\u4f3030+\u6cd5\u5f8b\u548c\u5546\u4e1a\u53c2\u6570\uff09\u548c\u57fa\u4e8e\u4ee3\u7406\u7684Need-Seed\u7cfb\u7edf\uff1aNeed\u4ee3\u7406\u4f7f\u7528NLP\u6316\u6398\u5e02\u573a\u9700\u6c42\uff0cSeed\u4ee3\u7406\u4f7f\u7528\u5fae\u8c03LLM\u5206\u6790\u4e13\u5229\u6280\u672f\u80fd\u529b\uff0c\u901a\u8fc7\u6838\u5fc3\u672c\u4f53\u6846\u67b6\u5339\u914d\u4e13\u5229\u4e0e\u5e02\u573a\u9700\u6c42\u3002", "result": "\u5efa\u7acb\u4e86\u80fd\u591f\u81ea\u52a8\u5339\u914d\u9ad8\u6f5c\u529b\u4e13\u5229\u4e0e\u5e02\u573a\u9700\u6c42\u7684\u7cfb\u7edf\u67b6\u6784\uff0c\u5305\u542b\u52a8\u6001\u53c2\u6570\u52a0\u6743\u548c\u4eba\u5de5\u9a8c\u8bc1\u534f\u8bae\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u4e13\u5229\u7ec4\u5408\u4fee\u526a\u63d0\u4f9b\u4e86\u6218\u7565\u51b3\u7b56\u4f9d\u636e\uff0c\u786e\u4fdd\u4e86\u9002\u5e94\u6027\u548c\u73b0\u5b9e\u53ef\u4fe1\u5ea6\uff0c\u63d0\u5347\u4e86\u6280\u672f\u8f6c\u79fb\u6548\u7387\u3002"}}
{"id": "2509.01271", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.01271", "abs": "https://arxiv.org/abs/2509.01271", "authors": ["Rujie Dai", "Peizhuo Lv", "Yujiang Gui", "Qiujian Lv", "Yuanyuan Qiao", "Yan Wang", "Degang Sun", "Weiqing Huang", "Yingjiu Li", "XiaoFeng Wang"], "title": "An Automated Attack Investigation Approach Leveraging Threat-Knowledge-Augmented Large Language Models", "comment": null, "summary": "Advanced Persistent Threats (APTs) are prolonged, stealthy intrusions by\nskilled adversaries that compromise high-value systems to steal data or disrupt\noperations. Reconstructing complete attack chains from massive, heterogeneous\nlogs is essential for effective attack investigation, yet existing methods\nsuffer from poor platform generality, limited generalization to evolving\ntactics, and an inability to produce analyst-ready reports. Large Language\nModels (LLMs) offer strong semantic understanding and summarization\ncapabilities, but in this domain they struggle to capture the long-range,\ncross-log dependencies critical for accurate reconstruction.\n  To solve these problems, we present an LLM-empowered attack investigation\nframework augmented with a dynamically adaptable Kill-Chain-aligned threat\nknowledge base. We organizes attack-relevant behaviors into stage-aware\nknowledge units enriched with semantic annotations, enabling the LLM to\niteratively retrieve relevant intelligence, perform causal reasoning, and\nprogressively expand the investigation context. This process reconstructs\nmulti-phase attack scenarios and generates coherent, human-readable\ninvestigation reports. Evaluated on 15 attack scenarios spanning single-host\nand multi-host environments across Windows and Linux (over 4.3M log events, 7.2\nGB of data), the system achieves an average True Positive Rate (TPR) of 97.1%\nand an average False Positive Rate (FPR) of 0.2%, significantly outperforming\nthe SOTA method ATLAS, which achieves an average TPR of 79.2% and an average\nFPR of 29.1%.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eLLM\u7684\u653b\u51fb\u8c03\u67e5\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u53ef\u9002\u5e94\u7684Kill-Chain\u5a01\u80c1\u77e5\u8bc6\u5e93\uff0c\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u653b\u51fb\u94fe\u91cd\u6784\u548c\u53ef\u8bfb\u62a5\u544a\u751f\u6210", "motivation": "\u73b0\u6709APT\u653b\u51fb\u8c03\u67e5\u65b9\u6cd5\u5b58\u5728\u5e73\u53f0\u901a\u7528\u6027\u5dee\u3001\u5bf9\u6f14\u8fdb\u6218\u672f\u6cdb\u5316\u80fd\u529b\u6709\u9650\u3001\u65e0\u6cd5\u751f\u6210\u5206\u6790\u5e08\u5c31\u7eea\u62a5\u544a\u7b49\u95ee\u9898\uff0cLLM\u867d\u5177\u5907\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u4f46\u96be\u4ee5\u6355\u6349\u957f\u8ddd\u79bb\u8de8\u65e5\u5fd7\u4f9d\u8d56", "method": "\u6784\u5efa\u52a8\u6001\u53ef\u9002\u5e94\u7684Kill-Chain\u5bf9\u9f50\u5a01\u80c1\u77e5\u8bc6\u5e93\uff0c\u5c06\u653b\u51fb\u884c\u4e3a\u7ec4\u7ec7\u4e3a\u9636\u6bb5\u611f\u77e5\u77e5\u8bc6\u5355\u5143\u5e76\u6dfb\u52a0\u8bed\u4e49\u6807\u6ce8\uff0c\u4f7fLLM\u80fd\u8fed\u4ee3\u68c0\u7d22\u76f8\u5173\u60c5\u62a5\u3001\u8fdb\u884c\u56e0\u679c\u63a8\u7406\u5e76\u9010\u6b65\u6269\u5c55\u8c03\u67e5\u4e0a\u4e0b\u6587", "result": "\u572815\u4e2a\u653b\u51fb\u573a\u666f\uff08430\u4e07\u65e5\u5fd7\u4e8b\u4ef6\uff0c7.2GB\u6570\u636e\uff09\u8bc4\u4f30\u4e2d\uff0c\u5e73\u5747\u771f\u9633\u6027\u738797.1%\uff0c\u5e73\u5747\u5047\u9633\u6027\u73870.2%\uff0c\u663e\u8457\u4f18\u4e8eSOTA\u65b9\u6cd5ATLAS\uff08\u771f\u9633\u6027\u738779.2%\uff0c\u5047\u9633\u6027\u738729.1%\uff09", "conclusion": "LLM\u589e\u5f3a\u7684\u653b\u51fb\u8c03\u67e5\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3APT\u653b\u51fb\u94fe\u91cd\u6784\u95ee\u9898\uff0c\u5728\u51c6\u786e\u6027\u548c\u5b9e\u7528\u6027\u65b9\u9762\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5"}}
{"id": "2509.00961", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.00961", "abs": "https://arxiv.org/abs/2509.00961", "authors": ["Lun Ai", "Johannes Langer", "Ute Schmid", "Stephen Muggleton"], "title": "Ultra Strong Machine Learning: Teaching Humans Active Learning Strategies via Automated AI Explanations", "comment": null, "summary": "Ultra Strong Machine Learning (USML) refers to symbolic learning systems that\nnot only improve their own performance but can also teach their acquired\nknowledge to quantifiably improve human performance. In this work, we present\nLENS (Logic Programming Explanation via Neural Summarisation), a neuro-symbolic\nmethod that combines symbolic program synthesis with large language models\n(LLMs) to automate the explanation of machine-learned logic programs in natural\nlanguage. LENS addresses a key limitation of prior USML approaches by replacing\nhand-crafted explanation templates with scalable automated generation. Through\nsystematic evaluation using multiple LLM judges and human validation, we\ndemonstrate that LENS generates superior explanations compared to direct LLM\nprompting and hand-crafted templates. To investigate whether LENS can teach\ntransferable active learning strategies, we carried out a human learning\nexperiment across three related domains. Our results show no significant human\nperformance improvements, suggesting that comprehensive LLM responses may\noverwhelm users for simpler problems rather than providing learning support.\nOur work provides a solid foundation for building effective USML systems to\nsupport human learning. The source code is available on:\nhttps://github.com/lun-ai/LENS.git.", "AI": {"tldr": "LENS\u662f\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\uff0c\u7ed3\u5408\u7b26\u53f7\u7a0b\u5e8f\u5408\u6210\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u81ea\u52a8\u751f\u6210\u673a\u5668\u5b66\u4e60\u903b\u8f91\u7a0b\u5e8f\u7684\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff0c\u53d6\u4ee3\u624b\u5de5\u6a21\u677f\uff0c\u4f46\u4eba\u7c7b\u5b66\u4e60\u5b9e\u9a8c\u663e\u793a\u672a\u663e\u8457\u63d0\u5347\u6027\u80fd", "motivation": "\u89e3\u51b3\u8d85\u5f3a\u673a\u5668\u5b66\u4e60(USML)\u7cfb\u7edf\u4e2d\u624b\u5de5\u89e3\u91ca\u6a21\u677f\u7684\u53ef\u6269\u5c55\u6027\u9650\u5236\uff0c\u5b9e\u73b0\u81ea\u52a8\u5316\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u751f\u6210", "method": "\u7ed3\u5408\u7b26\u53f7\u7a0b\u5e8f\u5408\u6210\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\uff0c\u901a\u8fc7\u795e\u7ecf\u6458\u8981\u81ea\u52a8\u751f\u6210\u903b\u8f91\u7a0b\u5e8f\u7684\u89e3\u91ca", "result": "LENS\u751f\u6210\u7684\u89e3\u91ca\u4f18\u4e8e\u76f4\u63a5LLM\u63d0\u793a\u548c\u624b\u5de5\u6a21\u677f\uff0c\u4f46\u4eba\u7c7b\u5b66\u4e60\u5b9e\u9a8c\u672a\u663e\u793a\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u53ef\u80fd\u56e0\u4e3aLLM\u54cd\u5e94\u8fc7\u4e8e\u5168\u9762\u53cd\u800c\u5f71\u54cd\u5b66\u4e60", "conclusion": "\u4e3a\u6784\u5efa\u6709\u6548\u7684USML\u7cfb\u7edf\u652f\u6301\u4eba\u7c7b\u5b66\u4e60\u63d0\u4f9b\u4e86\u575a\u5b9e\u57fa\u7840\uff0c\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u4f18\u5316\u89e3\u91ca\u751f\u6210\u65b9\u5f0f\u4ee5\u771f\u6b63\u63d0\u5347\u4eba\u7c7b\u5b66\u4e60\u6548\u679c"}}
{"id": "2509.01375", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.01375", "abs": "https://arxiv.org/abs/2509.01375", "authors": ["Alberto Miguel-Diez", "Adri\u00e1n Campazas-Vega", "\u00c1ngel Manuel Guerrero-Higueras", "Claudia \u00c1lvarez-Aparicio", "Vicente Matell\u00e1n-Olivera"], "title": "Anomaly detection in network flows using unsupervised online machine learning", "comment": "14 pages, 3 figures, 6 tables", "summary": "Nowadays, the volume of network traffic continues to grow, along with the\nfrequency and sophistication of attacks. This scenario highlights the need for\nsolutions capable of continuously adapting, since network behavior is dynamic\nand changes over time. This work presents an anomaly detection model for\nnetwork flows using unsupervised machine learning with online learning\ncapabilities. This approach allows the system to dynamically learn the normal\nbehavior of the network and detect deviations without requiring labeled data,\nwhich is particularly useful in real-world environments where traffic is\nconstantly changing and labeled data is scarce. The model was implemented using\nthe River library with a One-Class SVM and evaluated on the NF-UNSW-NB15\ndataset and its extended version v2, which contain network flows labeled with\ndifferent attack categories. The results show an accuracy above 98%, a false\npositive rate below 3.1%, and a recall of 100% in the most advanced version of\nthe dataset. In addition, the low processing time per flow (<0.033 ms)\ndemonstrates the feasibility of the approach for real-time applications.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u65e0\u76d1\u7763\u5728\u7ebf\u5b66\u4e60\u7684\u7f51\u7edc\u6d41\u91cf\u5f02\u5e38\u68c0\u6d4b\u6a21\u578b\uff0c\u4f7f\u7528One-Class SVM\u5b9e\u73b0\u52a8\u6001\u5b66\u4e60\u6b63\u5e38\u7f51\u7edc\u884c\u4e3a\uff0c\u5728NF-UNSW-NB15\u6570\u636e\u96c6\u4e0a\u8fbe\u523098%\u51c6\u786e\u7387\u548c100%\u53ec\u56de\u7387\uff0c\u5904\u7406\u65f6\u95f4<0.033ms/\u6d41\uff0c\u9002\u5408\u5b9e\u65f6\u5e94\u7528\u3002", "motivation": "\u7f51\u7edc\u6d41\u91cf\u6301\u7eed\u589e\u957f\u4e14\u653b\u51fb\u65e5\u76ca\u590d\u6742\uff0c\u9700\u8981\u80fd\u591f\u6301\u7eed\u81ea\u9002\u5e94\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u56e0\u4e3a\u7f51\u7edc\u884c\u4e3a\u662f\u52a8\u6001\u53d8\u5316\u7684\u3002\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u5b9e\u65f6\u53d8\u5316\u7684\u7f51\u7edc\u73af\u5883\u548c\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528River\u5e93\u5b9e\u73b0\u65e0\u76d1\u7763\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u91c7\u7528One-Class SVM\u7b97\u6cd5\uff0c\u5177\u5907\u5728\u7ebf\u5b66\u4e60\u80fd\u529b\uff0c\u80fd\u591f\u52a8\u6001\u5b66\u4e60\u6b63\u5e38\u7f51\u7edc\u884c\u4e3a\u5e76\u68c0\u6d4b\u5f02\u5e38\uff0c\u65e0\u9700\u6807\u6ce8\u6570\u636e\u3002", "result": "\u5728NF-UNSW-NB15\u6570\u636e\u96c6\u53ca\u5176v2\u7248\u672c\u4e0a\u6d4b\u8bd5\uff0c\u51c6\u786e\u7387\u8d85\u8fc798%\uff0c\u8bef\u62a5\u7387\u4f4e\u4e8e3.1%\uff0c\u6700\u65b0\u6570\u636e\u96c6\u7248\u672c\u53ec\u56de\u7387\u8fbe\u5230100%\uff0c\u5355\u6d41\u5904\u7406\u65f6\u95f4\u5c0f\u4e8e0.033\u6beb\u79d2\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u8bc1\u660e\u4e86\u65e0\u76d1\u7763\u5728\u7ebf\u5b66\u4e60\u5728\u7f51\u7edc\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u52a8\u6001\u53d8\u5316\u7684\u7f51\u7edc\u73af\u5883\uff0c\u6ee1\u8db3\u5b9e\u65f6\u68c0\u6d4b\u9700\u6c42\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.00971", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00971", "abs": "https://arxiv.org/abs/2509.00971", "authors": ["Jay Vaghasiya", "Omkar Ghugarkar", "Vishvesh Bhat", "Vipul Dholaria", "Julian McAuley"], "title": "CoreThink: A Symbolic Reasoning Layer to reason over Long Horizon Tasks with LLMs", "comment": null, "summary": "We introduce CoreThink, a state-of-the-art Reasoning Layer built upon a novel\nreasoning method called General Symbolics. This approach diverges from\nreasoning paradigms such as test-time scaling, Supervised Fine-Tuning (SFT),\nand Reinforcement Learning with Verifiable Rewards (RLVR). CoreThink General\nSymbolic Reasoner (GSR) is specifically structured around three key use cases:\ntool-calling, code generation, and planning, demonstrating exemplary\nperformance across a total of seven benchmarks in their respective areas.\nNotably, we are achieving SOTA scores of 66.66\\% on Livecodebench v6, 89\\% on\nInstruction-Following Evals, and 24.4\\% on ARC-AGI-2. We also present an\nagentic coding IDE, developed using the principles of General Symbolics, which\nachieves a state-of-the-art accuracy of 62.3\\% on \\texttt{SWE-Bench Lite}. We\nare able to achieve these improvements without any finetuning or training\ncosts. Our Reasoning Layer is designed to provide a pure performance uplift,\nensuring that a model's accuracy on reasoning tasks is never negatively\nimpacted. We argue that incumbent methods will eventually lead to diminishing\nreturns in LLM performance, necessitating the development of new reasoning\ntechniques. This technical report details our approach at a high level and the\navailability of the CoreThink models for reasoning-intensive use cases.", "AI": {"tldr": "CoreThink\u662f\u4e00\u4e2a\u57fa\u4e8e\u901a\u7528\u7b26\u53f7\u63a8\u7406\u65b9\u6cd5\u7684\u65b0\u578b\u63a8\u7406\u5c42\uff0c\u5728\u5de5\u5177\u8c03\u7528\u3001\u4ee3\u7801\u751f\u6210\u548c\u89c4\u5212\u4e09\u4e2a\u5173\u952e\u7528\u4f8b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u57287\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97SOTA\u6210\u7ee9\uff0c\u65e0\u9700\u5fae\u8c03\u6216\u8bad\u7ec3\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\uff08\u5982\u6d4b\u8bd5\u65f6\u6269\u5c55\u3001\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\uff09\u5728LLM\u6027\u80fd\u63d0\u5347\u4e0a\u4f1a\u51fa\u73b0\u6536\u76ca\u9012\u51cf\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u63a8\u7406\u6280\u672f\u6765\u7a81\u7834\u6027\u80fd\u74f6\u9888\u3002", "method": "\u91c7\u7528\u901a\u7528\u7b26\u53f7\u63a8\u7406\u65b9\u6cd5\uff08General Symbolics\uff09\uff0c\u6784\u5efaCoreThink\u901a\u7528\u7b26\u53f7\u63a8\u7406\u5668\uff08GSR\uff09\uff0c\u4e13\u6ce8\u4e8e\u5de5\u5177\u8c03\u7528\u3001\u4ee3\u7801\u751f\u6210\u548c\u89c4\u5212\u4e09\u4e2a\u6838\u5fc3\u7528\u4f8b\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97SOTA\u6210\u7ee9\uff1aLivecodebench v6\u8fbe\u523066.66%\u3001Instruction-Following Evals\u8fbe\u523089%\u3001ARC-AGI-2\u8fbe\u523024.4%\uff0c\u57fa\u4e8e\u8be5\u6280\u672f\u7684\u667a\u80fd\u7f16\u7801IDE\u5728SWE-Bench Lite\u4e0a\u8fbe\u523062.3%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "CoreThink\u63a8\u7406\u5c42\u80fd\u591f\u63d0\u4f9b\u7eaf\u7cb9\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4e0d\u4f1a\u5bf9\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u51c6\u786e\u6027\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\uff0c\u4e3a\u63a8\u7406\u5bc6\u96c6\u578b\u7528\u4f8b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.01434", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2509.01434", "abs": "https://arxiv.org/abs/2509.01434", "authors": ["Handi Chen", "Jing Deng", "Xiuzhe Wu", "Zhihan Jiang", "Xinchen Zhang", "Xianhao Chen", "Edith C. H. Ngai"], "title": "LiFeChain: Lightweight Blockchain for Secure and Efficient Federated Lifelong Learning in IoT", "comment": null, "summary": "The expansion of Internet of Things (IoT) devices constantly generates\nheterogeneous data streams, driving demand for continuous, decentralized\nintelligence. Federated Lifelong Learning (FLL) provides an ideal solution by\nincorporating federated and lifelong learning to overcome catastrophic\nforgetting. The extended lifecycle of FLL in IoT systems increases their\nvulnerability to persistent attacks, and these risks may be obscured by\nperformance degradation caused by spatial-temporal data heterogeneity.\nMoreover, this problem is exacerbated by the standard single-server\narchitecture, as its single point of failure makes it difficult to maintain a\nreliable audit trail for long-term threats. Blockchain provides a tamper-proof\nfoundation for trustworthy FLL systems. Nevertheless, directly applying\nblockchain to FLL significantly increases computational and retrieval costs\nwith the expansion of the knowledge base, slowing down the training on IoT\ndevices. To address these challenges, we propose LiFeChain, a lightweight\nblockchain for secure and efficient federated lifelong learning by providing a\ntamper-resistant ledger with minimal on-chain disclosure and bidirectional\nverification. To the best of our knowledge, LiFeChain is the first blockchain\ntailored for FLL. LiFeChain incorporates two complementary mechanisms: the\nproof-of-model-correlation (PoMC) consensus on the server, which couples\nlearning and unlearning mechanisms to mitigate negative transfer, and segmented\nzero-knowledge arbitration (Seg-ZA) on the client, which detects and arbitrates\nabnormal committee behavior without compromising privacy. LiFeChain is designed\nas a plug-and-play component that can be seamlessly integrated into existing\nFLL algorithms. Experimental results demonstrate that LiFeChain not only\nenhances model performance against two long-term attacks but also sustains high\nefficiency and scalability.", "AI": {"tldr": "LiFeChain\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u533a\u5757\u94fe\u7cfb\u7edf\uff0c\u4e13\u95e8\u4e3a\u8054\u90a6\u7ec8\u8eab\u5b66\u4e60(FLL)\u8bbe\u8ba1\uff0c\u901a\u8fc7\u53cc\u5411\u9a8c\u8bc1\u548c\u6700\u5c0f\u94fe\u4e0a\u62ab\u9732\u63d0\u4f9b\u9632\u7be1\u6539\u8d26\u672c\uff0c\u89e3\u51b3IoT\u7cfb\u7edf\u4e2d\u957f\u671f\u653b\u51fb\u548c\u5b89\u5168\u95ee\u9898\u3002", "motivation": "IoT\u8bbe\u5907\u4ea7\u751f\u5f02\u6784\u6570\u636e\u6d41\u9700\u8981\u6301\u7eed\u53bb\u4e2d\u5fc3\u5316\u667a\u80fd\uff0c\u8054\u90a6\u7ec8\u8eab\u5b66\u4e60(FLL)\u80fd\u514b\u670d\u707e\u96be\u6027\u9057\u5fd8\u4f46\u9762\u4e34\u957f\u671f\u653b\u51fb\u98ce\u9669\u3002\u4f20\u7edf\u5355\u670d\u52a1\u5668\u67b6\u6784\u5b58\u5728\u5355\u70b9\u6545\u969c\uff0c\u533a\u5757\u94fe\u867d\u63d0\u4f9b\u9632\u7be1\u6539\u57fa\u7840\u4f46\u76f4\u63a5\u5e94\u7528\u4f1a\u589e\u52a0\u8ba1\u7b97\u548c\u68c0\u7d22\u6210\u672c\u3002", "method": "\u63d0\u51faLiFeChain\u7cfb\u7edf\uff0c\u5305\u542b\u4e24\u4e2a\u4e92\u8865\u673a\u5236\uff1a\u670d\u52a1\u5668\u7aef\u7684PoMC\u5171\u8bc6\uff08\u7ed3\u5408\u5b66\u4e60\u548c\u9057\u5fd8\u673a\u5236\u7f13\u89e3\u8d1f\u8fc1\u79fb\uff09\u548c\u5ba2\u6237\u7aef\u7684Seg-ZA\uff08\u68c0\u6d4b\u5f02\u5e38\u59d4\u5458\u4f1a\u884c\u4e3a\u800c\u4e0d\u6cc4\u9732\u9690\u79c1\uff09\u3002\u8bbe\u8ba1\u4e3a\u5373\u63d2\u5373\u7528\u7ec4\u4ef6\uff0c\u53ef\u65e0\u7f1d\u96c6\u6210\u73b0\u6709FLL\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eLiFeChain\u4e0d\u4ec5\u80fd\u589e\u5f3a\u6a21\u578b\u6027\u80fd\u5bf9\u6297\u4e24\u79cd\u957f\u671f\u653b\u51fb\uff0c\u8fd8\u80fd\u4fdd\u6301\u9ad8\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "LiFeChain\u662f\u9996\u4e2a\u4e13\u4e3aFLL\u5b9a\u5236\u7684\u533a\u5757\u94fe\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u6548\u89e3\u51b3\u4e86IoT\u7cfb\u7edf\u4e2d\u8054\u90a6\u7ec8\u8eab\u5b66\u4e60\u7684\u5b89\u5168\u6027\u548c\u6548\u7387\u95ee\u9898\uff0c\u4e3a\u53ef\u4fe1FLL\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u6846\u67b6\u3002"}}
{"id": "2509.00975", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.00975", "abs": "https://arxiv.org/abs/2509.00975", "authors": ["Zifeng Ding", "Shenyang Huang", "Zeyu Cao", "Emma Kondrup", "Zachary Yang", "Xingyue Huang", "Yuan Sui", "Zhangdie Yuan", "Yuqicheng Zhu", "Xianglong Hu", "Yuan He", "Farimah Poursafaei", "Michael Bronstein", "Andreas Vlachos"], "title": "Self-Exploring Language Models for Explainable Link Forecasting on Temporal Graphs via Reinforcement Learning", "comment": null, "summary": "Forecasting future links is a central task in temporal graph (TG) reasoning,\nrequiring models to leverage historical interactions to predict upcoming ones.\nTraditional neural approaches, such as temporal graph neural networks, achieve\nstrong performance but lack explainability and cannot be applied to unseen\ngraphs without retraining. Recent studies have begun to explore using large\nlanguage models (LLMs) for graph reasoning, but most of them are constrained to\nstatic graphs or small synthetic TGs and lack the evaluation of the quality of\nreasoning traces generated by LLMs. In this work, we present Reasoning-Enhanced\nLearning for Temporal Graphs (ReaL-TG), a reinforcement learning framework that\nfine-tunes LLMs to perform explainable link forecasting on real-world TGs.\nReaL-TG uses outcome-based reward to encourage models to self-explore reasoning\nstrategies from graph structure and to produce explanations that directly\njustify their predictions. To enable evaluation on LLM-generated reasoning\ntraces, we propose a new evaluation protocol combining ranking metrics with an\nLLM-as-a-Judge system that assesses both the quality of reasoning and the\nimpact of hallucinations. Experiments with ReaL-TG-4B, obtained by fine-tuning\nQwen3-4B under our framework, show that it outperforms much larger frontier\nLLMs, including GPT-5 mini, on ranking metrics, while producing high-quality\nexplanations confirmed by both the LLM judge and human evaluation.", "AI": {"tldr": "ReaL-TG\u662f\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u5728\u65f6\u5e8f\u56fe\u4e0a\u8fdb\u884c\u53ef\u89e3\u91ca\u7684\u94fe\u63a5\u9884\u6d4b\uff0c\u4f7f\u7528\u7ed3\u679c\u5956\u52b1\u673a\u5236\u9f13\u52b1\u6a21\u578b\u4ece\u56fe\u7ed3\u6784\u4e2d\u63a2\u7d22\u63a8\u7406\u7b56\u7565\u5e76\u751f\u6210\u89e3\u91ca\u3002", "motivation": "\u4f20\u7edf\u65f6\u5e8f\u56fe\u795e\u7ecf\u7f51\u7edc\u867d\u7136\u6027\u80fd\u5f3a\u4f46\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u4e14\u65e0\u6cd5\u76f4\u63a5\u5e94\u7528\u4e8e\u672a\u89c1\u8fc7\u7684\u56fe\u3002\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u56fe\u63a8\u7406\u65b9\u6cd5\u5927\u591a\u5c40\u9650\u4e8e\u9759\u6001\u56fe\u6216\u5c0f\u578b\u5408\u6210\u65f6\u5e8f\u56fe\uff0c\u4e14\u7f3a\u4e4f\u5bf9\u63a8\u7406\u8f68\u8ff9\u8d28\u91cf\u7684\u8bc4\u4f30\u3002", "method": "\u63d0\u51faReaL-TG\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u7528\u57fa\u4e8e\u7ed3\u679c\u7684\u5956\u52b1\u673a\u5236\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u8ba9\u6a21\u578b\u4ece\u56fe\u7ed3\u6784\u4e2d\u81ea\u4e3b\u63a2\u7d22\u63a8\u7406\u7b56\u7565\uff0c\u5e76\u751f\u6210\u76f4\u63a5\u8bc1\u660e\u9884\u6d4b\u7684\u89e3\u91ca\u3002\u540c\u65f6\u63d0\u51fa\u7ed3\u5408\u6392\u540d\u6307\u6807\u548cLLM-as-a-Judge\u7cfb\u7edf\u7684\u8bc4\u4f30\u534f\u8bae\u3002", "result": "\u901a\u8fc7\u5fae\u8c03Qwen3-4B\u5f97\u5230\u7684ReaL-TG-4B\u5728\u6392\u540d\u6307\u6807\u4e0a\u4f18\u4e8e\u5305\u62ecGPT-5 mini\u5728\u5185\u7684\u66f4\u5927\u89c4\u6a21\u524d\u6cbf\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u540c\u65f6\u751f\u6210\u7684\u9ad8\u8d28\u91cf\u89e3\u91ca\u5f97\u5230\u4e86LLM\u8bc4\u5224\u7cfb\u7edf\u548c\u4eba\u5de5\u8bc4\u4f30\u7684\u786e\u8ba4\u3002", "conclusion": "ReaL-TG\u6846\u67b6\u6210\u529f\u5730\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u771f\u5b9e\u4e16\u754c\u65f6\u5e8f\u56fe\u7684\u94fe\u63a5\u9884\u6d4b\u4efb\u52a1\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u901a\u8fc7\u65b0\u7684\u8bc4\u4f30\u534f\u8bae\u9a8c\u8bc1\u4e86\u63a8\u7406\u8f68\u8ff9\u7684\u8d28\u91cf\u3002"}}
{"id": "2509.01463", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.01463", "abs": "https://arxiv.org/abs/2509.01463", "authors": ["Pranjay Malhotra"], "title": "LLMHoney: A Real-Time SSH Honeypot with Large Language Model-Driven Dynamic Response Generation", "comment": "7 Pages", "summary": "Cybersecurity honeypots are deception tools for engaging attackers and gather\nintelligence, but traditional low or medium-interaction honeypots often rely on\nstatic, pre-scripted interactions that can be easily identified by skilled\nadversaries. This Report presents LLMHoney, an SSH honeypot that leverages\nLarge Language Models (LLMs) to generate realistic, dynamic command outputs in\nreal time. LLMHoney integrates a dictionary-based virtual file system to handle\ncommon commands with low latency while using LLMs for novel inputs, achieving a\nbalance between authenticity and performance. We implemented LLMHoney using\nopen-source LLMs and evaluated it on a testbed with 138 representative Linux\ncommands. We report comprehensive metrics including accuracy (exact-match,\nCosine Similarity, Jaro-Winkler Similarity, Levenshtein Similarity and BLEU\nscore), response latency and memory overhead. We evaluate LLMHoney using\nmultiple LLM backends ranging from 0.36B to 3.8B parameters, including both\nopen-source models and a proprietary model(Gemini). Our experiments compare 13\ndifferent LLM variants; results show that Gemini-2.0 and moderately-sized\nmodels Qwen2.5:1.5B and Phi3:3.8B provide the most reliable and accurate\nresponses, with mean latencies around 3 seconds, whereas smaller models often\nproduce incorrect or out-of-character outputs. We also discuss how LLM\nintegration improves honeypot realism and adaptability compared to traditional\nhoneypots, as well as challenges such as occasional hallucinated outputs and\nincreased resource usage. Our findings demonstrate that LLM-driven honeypots\nare a promising approach to enhance attacker engagement and collect richer\nthreat intelligence.", "AI": {"tldr": "LLMHoney\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684SSH\u871c\u7f50\uff0c\u80fd\u591f\u5b9e\u65f6\u751f\u6210\u52a8\u6001\u3001\u771f\u5b9e\u7684\u547d\u4ee4\u8f93\u51fa\uff0c\u76f8\u6bd4\u4f20\u7edf\u871c\u7f50\u5177\u6709\u66f4\u597d\u7684\u771f\u5b9e\u6027\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u4f20\u7edf\u4f4e\u4ea4\u4e92\u548c\u4e2d\u4ea4\u4e92\u871c\u7f50\u4f9d\u8d56\u9759\u6001\u9884\u811a\u672c\u4ea4\u4e92\uff0c\u5bb9\u6613\u88ab\u719f\u7ec3\u653b\u51fb\u8005\u8bc6\u522b\uff0c\u9700\u8981\u66f4\u771f\u5b9e\u7684\u52a8\u6001\u4ea4\u4e92\u80fd\u529b\u6765\u63d0\u5347\u653b\u51fb\u8005\u53c2\u4e0e\u5ea6\u548c\u5a01\u80c1\u60c5\u62a5\u6536\u96c6\u6548\u679c\u3002", "method": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b9e\u65f6\u751f\u6210SSH\u547d\u4ee4\u8f93\u51fa\uff0c\u7ed3\u5408\u57fa\u4e8e\u5b57\u5178\u7684\u865a\u62df\u6587\u4ef6\u7cfb\u7edf\u5904\u7406\u5e38\u89c1\u547d\u4ee4\u4ee5\u964d\u4f4e\u5ef6\u8fdf\uff0c\u5bf9138\u4e2a\u4ee3\u8868\u6027Linux\u547d\u4ee4\u8fdb\u884c\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u4e8613\u79cd\u4e0d\u540cLLM\u53d8\u4f53\u3002", "result": "Gemini-2.0\u3001Qwen2.5:1.5B\u548cPhi3:3.8B\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u5e73\u5747\u5ef6\u8fdf\u7ea63\u79d2\uff0c\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u6700\u9ad8\uff1b\u5c0f\u6a21\u578b\u5e38\u4ea7\u751f\u9519\u8bef\u6216\u4e0d\u7b26\u5408\u7279\u5f81\u7684\u8f93\u51fa\u3002", "conclusion": "LLM\u9a71\u52a8\u7684\u871c\u7f50\u662f\u63d0\u5347\u653b\u51fb\u8005\u53c2\u4e0e\u5ea6\u548c\u6536\u96c6\u66f4\u4e30\u5bcc\u5a01\u80c1\u60c5\u62a5\u7684\u6709\u524d\u666f\u7684\u65b9\u6cd5\uff0c\u4f46\u5b58\u5728\u5e7b\u89c9\u8f93\u51fa\u548c\u8d44\u6e90\u6d88\u8017\u589e\u52a0\u7684\u6311\u6218\u3002"}}
{"id": "2509.00987", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00987", "abs": "https://arxiv.org/abs/2509.00987", "authors": ["Adib Bazgir", "Amir Habibdoust", "Yuwen Zhang", "Xing Song"], "title": "Causal MAS: A Survey of Large Language Model Architectures for Discovery and Effect Estimation", "comment": "24 pages. 2 figures", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nvarious reasoning and generation tasks. However, their proficiency in complex\ncausal reasoning, discovery, and estimation remains an area of active\ndevelopment, often hindered by issues like hallucination, reliance on spurious\ncorrelations, and difficulties in handling nuanced, domain-specific, or\npersonalized causal relationships. Multi-agent systems, leveraging the\ncollaborative or specialized abilities of multiple LLM-based agents, are\nemerging as a powerful paradigm to address these limitations. This review paper\nexplores the burgeoning field of causal multi-agent LLMs. We examine how these\nsystems are designed to tackle different facets of causality, including causal\nreasoning and counterfactual analysis, causal discovery from data, and the\nestimation of causal effects. We delve into the diverse architectural patterns\nand interaction protocols employed, from pipeline-based processing and debate\nframeworks to simulation environments and iterative refinement loops.\nFurthermore, we discuss the evaluation methodologies, benchmarks, and diverse\napplication domains where causal multi-agent LLMs are making an impact,\nincluding scientific discovery, healthcare, fact-checking, and personalized\nsystems. Finally, we highlight the persistent challenges, open research\nquestions, and promising future directions in this synergistic field, aiming to\nprovide a comprehensive overview of its current state and potential trajectory.", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u8bba\u6587\u63a2\u8ba8\u4e86\u56e0\u679c\u591a\u667a\u80fd\u4f53\u5927\u8bed\u8a00\u6a21\u578b\u8fd9\u4e00\u65b0\u5174\u9886\u57df\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u89e3\u51b3LLM\u5728\u590d\u6742\u56e0\u679c\u63a8\u7406\u3001\u53d1\u73b0\u548c\u4f30\u8ba1\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u56e0\u679c\u63a8\u7406\u65b9\u9762\u5b58\u5728\u5e7b\u89c9\u3001\u4f2a\u76f8\u5173\u4f9d\u8d56\u7b49\u9650\u5236\uff0c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u901a\u8fc7\u534f\u4f5c\u548c\u4e13\u4e1a\u5316\u80fd\u529b\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002", "method": "\u7814\u7a76\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u8bbe\u8ba1\u67b6\u6784\u548c\u4ea4\u4e92\u534f\u8bae\uff0c\u5305\u62ec\u6d41\u6c34\u7ebf\u5904\u7406\u3001\u8fa9\u8bba\u6846\u67b6\u3001\u6a21\u62df\u73af\u5883\u548c\u8fed\u4ee3\u7cbe\u70bc\u5faa\u73af\u7b49\u65b9\u6cd5\u3002", "result": "\u8bba\u6587\u7efc\u8ff0\u4e86\u56e0\u679c\u591a\u667a\u80fd\u4f53LLM\u5728\u4e0d\u540c\u56e0\u679c\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\uff0c\u5305\u62ec\u56e0\u679c\u63a8\u7406\u3001\u53cd\u4e8b\u5b9e\u5206\u6790\u3001\u56e0\u679c\u53d1\u73b0\u548c\u56e0\u679c\u6548\u5e94\u4f30\u8ba1\u3002", "conclusion": "\u8be5\u9886\u57df\u5728\u79d1\u5b66\u53d1\u73b0\u3001\u533b\u7597\u5065\u5eb7\u3001\u4e8b\u5b9e\u6838\u67e5\u548c\u4e2a\u6027\u5316\u7cfb\u7edf\u7b49\u591a\u4e2a\u5e94\u7528\u9886\u57df\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u4f46\u4ecd\u9762\u4e34\u6301\u7eed\u6311\u6218\u548c\u5f00\u653e\u7814\u7a76\u95ee\u9898\u3002"}}
{"id": "2509.01470", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.01470", "abs": "https://arxiv.org/abs/2509.01470", "authors": ["I. D. Lutz", "A. M. Hill", "M. C. Valenti"], "title": "Privacy-preserving authentication for military 5G networks", "comment": "To appear in Proc. IEEE Military Commun. Conf. (MILCOM), (Los\n  Angeles, CA), Oct. 2025", "summary": "As 5G networks gain traction in defense applications, ensuring the privacy\nand integrity of the Authentication and Key Agreement (AKA) protocol is\ncritical. While 5G AKA improves upon previous generations by concealing\nsubscriber identities, it remains vulnerable to replay-based synchronization\nand linkability threats under realistic adversary models. This paper provides a\nunified analysis of the standardized 5G AKA flow, identifying several\nvulnerabilities and highlighting how each exploits protocol behavior to\ncompromise user privacy. To address these risks, we present five lightweight\nmitigation strategies. We demonstrate through prototype implementation and\ntesting that these enhancements strengthen resilience against linkability\nattacks with minimal computational and signaling overhead. Among the solutions\nstudied, those introducing a UE-generated nonce emerge as the most promising,\neffectively neutralizing the identified tracking and correlation attacks with\nnegligible additional overhead. Integrating this extension as an optional\nfeature to the standard 5G AKA protocol offers a backward-compatible,\nlow-overhead path toward a more privacy-preserving authentication framework for\nboth commercial and military 5G deployments.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e865G AKA\u534f\u8bae\u5728\u9690\u79c1\u4fdd\u62a4\u65b9\u9762\u7684\u6f0f\u6d1e\uff0c\u63d0\u51fa\u4e86\u4e94\u79cd\u8f7b\u91cf\u7ea7\u7f13\u89e3\u7b56\u7565\uff0c\u5176\u4e2dUE\u751f\u6210nonce\u7684\u65b9\u6848\u6700\u4e3a\u6709\u6548\uff0c\u80fd\u4ee5\u6700\u5c0f\u5f00\u9500\u589e\u5f3a\u9690\u79c1\u4fdd\u62a4", "motivation": "\u968f\u77405G\u7f51\u7edc\u5728\u56fd\u9632\u5e94\u7528\u4e2d\u7684\u666e\u53ca\uff0c\u786e\u4fdd\u8ba4\u8bc1\u548c\u5bc6\u94a5\u534f\u5546(AKA)\u534f\u8bae\u7684\u9690\u79c1\u6027\u548c\u5b8c\u6574\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u867d\u71365G AKA\u901a\u8fc7\u9690\u85cf\u7528\u6237\u8eab\u4efd\u6539\u8fdb\u4e86\u524d\u4ee3\u6280\u672f\uff0c\u4f46\u5728\u5b9e\u9645\u5bf9\u6297\u6a21\u578b\u4e0b\u4ecd\u5b58\u5728\u91cd\u653e\u540c\u6b65\u548c\u53ef\u94fe\u63a5\u6027\u5a01\u80c1", "method": "\u5bf9\u6807\u51c6\u5316\u76845G AKA\u6d41\u7a0b\u8fdb\u884c\u7edf\u4e00\u5206\u6790\uff0c\u8bc6\u522b\u591a\u4e2a\u6f0f\u6d1e\uff0c\u5e76\u63d0\u51fa\u4e86\u4e94\u79cd\u8f7b\u91cf\u7ea7\u7f13\u89e3\u7b56\u7565\u3002\u901a\u8fc7\u539f\u578b\u5b9e\u73b0\u548c\u6d4b\u8bd5\u9a8c\u8bc1\u8fd9\u4e9b\u589e\u5f3a\u63aa\u65bd\u7684\u6709\u6548\u6027", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5f15\u5165UE\u751f\u6210nonce\u7684\u89e3\u51b3\u65b9\u6848\u6700\u4e3a\u6709\u6548\uff0c\u80fd\u591f\u4ee5\u53ef\u5ffd\u7565\u7684\u989d\u5916\u5f00\u9500\u6709\u6548\u4e2d\u548c\u5df2\u8bc6\u522b\u7684\u8ddf\u8e2a\u548c\u5173\u8054\u653b\u51fb\u3002\u8fd9\u4e9b\u589e\u5f3a\u63aa\u65bd\u663e\u8457\u63d0\u9ad8\u4e86\u5bf9\u53ef\u94fe\u63a5\u6027\u653b\u51fb\u7684\u62b5\u6297\u80fd\u529b", "conclusion": "\u5c06UE\u751f\u6210nonce\u7684\u6269\u5c55\u4f5c\u4e3a5G AKA\u534f\u8bae\u7684\u53ef\u9009\u529f\u80fd\uff0c\u4e3a\u5546\u4e1a\u548c\u519b\u4e8b5G\u90e8\u7f72\u63d0\u4f9b\u4e86\u5411\u540e\u517c\u5bb9\u3001\u4f4e\u5f00\u9500\u7684\u9690\u79c1\u4fdd\u62a4\u8ba4\u8bc1\u6846\u67b6\u8def\u5f84"}}
{"id": "2509.00997", "categories": ["cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2509.00997", "abs": "https://arxiv.org/abs/2509.00997", "authors": ["Shu Liu", "Soujanya Ponnapalli", "Shreya Shankar", "Sepanta Zeighami", "Alan Zhu", "Shubham Agarwal", "Ruiqi Chen", "Samion Suwito", "Shuo Yuan", "Ion Stoica", "Matei Zaharia", "Alvin Cheung", "Natacha Crooks", "Joseph E. Gonzalez", "Aditya G. Parameswaran"], "title": "Supporting Our AI Overlords: Redesigning Data Systems to be Agent-First", "comment": null, "summary": "Large Language Model (LLM) agents, acting on their users' behalf to\nmanipulate and analyze data, are likely to become the dominant workload for\ndata systems in the future. When working with data, agents employ a\nhigh-throughput process of exploration and solution formulation for the given\ntask, one we call agentic speculation. The sheer volume and inefficiencies of\nagentic speculation can pose challenges for present-day data systems. We argue\nthat data systems need to adapt to more natively support agentic workloads. We\ntake advantage of the characteristics of agentic speculation that we identify,\ni.e., scale, heterogeneity, redundancy, and steerability - to outline a number\nof new research opportunities for a new agent-first data systems architecture,\nranging from new query interfaces, to new query processing techniques, to new\nagentic memory stores.", "AI": {"tldr": "LLM\u4ee3\u7406\u5de5\u4f5c\u8d1f\u8f7d\u5c06\u6210\u4e3a\u6570\u636e\u7cfb\u7edf\u7684\u4e3b\u5bfc\u5de5\u4f5c\u6d41\uff0c\u9700\u8981\u6570\u636e\u7cfb\u7edf\u4e3a\u4ee3\u7406\u4f53\u7279\u6027\u8fdb\u884c\u4f18\u5316\u8bbe\u8ba1", "motivation": "LLM\u4ee3\u7406\u5728\u6570\u636e\u64cd\u4f5c\u548c\u5206\u6790\u4e2d\u91c7\u7528\u9ad8\u901a\u91cf\u7684\u63a2\u7d22\u548c\u89e3\u51b3\u65b9\u6848\u5f62\u6210\u8fc7\u7a0b\uff08\u4ee3\u7406\u4f53\u731c\u6d4b\uff09\uff0c\u5bf9\u73b0\u6709\u6570\u636e\u7cfb\u7edf\u6784\u6210\u6311\u6218", "method": "\u5206\u6790\u4ee3\u7406\u4f53\u731c\u6d4b\u7684\u56db\u5927\u7279\u5f81\uff1a\u89c4\u6a21\u6027\u3001\u5f02\u6784\u6027\u3001\u5197\u4f59\u6027\u548c\u53ef\u63a7\u6027\uff0c\u5e76\u57fa\u4e8e\u8fd9\u4e9b\u7279\u6027\u63d0\u51fa\u4ee3\u7406\u4f18\u5148\u7684\u6570\u636e\u7cfb\u7edf\u67b6\u6784", "result": "\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u65b0\u7684\u7814\u7a76\u673a\u9047\uff0c\u5305\u62ec\u65b0\u67e5\u8be2\u63a5\u53e3\u3001\u65b0\u67e5\u8be2\u5904\u7406\u6280\u672f\u548c\u65b0\u4ee3\u7406\u5185\u5b58\u5b58\u50a8\u7b49\u65b9\u5411", "conclusion": "\u6570\u636e\u7cfb\u7edf\u9700\u8981\u6839\u672c\u6027\u91cd\u6784\u4ee5\u539f\u751f\u652f\u6301LLM\u4ee3\u7406\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u8fd9\u662f\u672a\u6765\u6570\u636e\u7cfb\u7edf\u8bbe\u8ba1\u7684\u91cd\u8981\u8d8b\u52bf"}}
{"id": "2509.01509", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.01509", "abs": "https://arxiv.org/abs/2509.01509", "authors": ["Chengyu Song", "Jianming Zheng"], "title": "Insight-LLM: LLM-enhanced Multi-view Fusion in Insider Threat Detection", "comment": null, "summary": "Insider threat detection (ITD) requires analyzing sparse, heterogeneous user\nbehavior. Existing ITD methods predominantly rely on single-view modeling,\nresulting in limited coverage and missed anomalies. While multi-view learning\nhas shown promise in other domains, its direct application to ITD introduces\nsignificant challenges: scalability bottlenecks from independently trained\nsub-models, semantic misalignment across disparate feature spaces, and view\nimbalance that causes high-signal modalities to overshadow weaker ones. In this\nwork, we present Insight-LLM, the first modular multi-view fusion framework\nspecifically tailored for insider threat detection. Insight-LLM employs frozen,\npre-nes, achieving state-of-the-art detection with low latency and parameter\noverhead.", "AI": {"tldr": "Insight-LLM\u662f\u4e00\u4e2a\u4e13\u95e8\u4e3a\u5185\u90e8\u5a01\u80c1\u68c0\u6d4b\u8bbe\u8ba1\u7684\u6a21\u5757\u5316\u591a\u89c6\u56fe\u878d\u5408\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5355\u89c6\u56fe\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u51bb\u7ed3\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u9ad8\u6548\u7684\u591a\u89c6\u56fe\u878d\u5408\u3002", "motivation": "\u73b0\u6709\u5185\u90e8\u5a01\u80c1\u68c0\u6d4b\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u5355\u89c6\u56fe\u5efa\u6a21\uff0c\u5bfc\u81f4\u8986\u76d6\u8303\u56f4\u6709\u9650\u4e14\u5bb9\u6613\u9057\u6f0f\u5f02\u5e38\u3002\u591a\u89c6\u56fe\u5b66\u4e60\u5728\u5176\u4ed6\u9886\u57df\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u76f4\u63a5\u5e94\u7528\u4e8e\u5185\u90e8\u5a01\u80c1\u68c0\u6d4b\u9762\u4e34\u53ef\u6269\u5c55\u6027\u74f6\u9888\u3001\u8bed\u4e49\u4e0d\u5bf9\u9f50\u548c\u89c6\u56fe\u4e0d\u5e73\u8861\u7b49\u6311\u6218\u3002", "method": "\u63d0\u51faInsight-LLM\u6846\u67b6\uff0c\u91c7\u7528\u6a21\u5757\u5316\u591a\u89c6\u56fe\u878d\u5408\u65b9\u6cd5\uff0c\u4f7f\u7528\u51bb\u7ed3\u7684\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u6765\u5904\u7406\u7a00\u758f\u3001\u5f02\u6784\u7684\u7528\u6237\u884c\u4e3a\u6570\u636e\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u591a\u89c6\u56fe\u4fe1\u606f\u6574\u5408\u3002", "result": "\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u6027\u80fd\uff0c\u540c\u65f6\u5177\u6709\u4f4e\u5ef6\u8fdf\u548c\u4f4e\u53c2\u6570\u5f00\u9500\u7684\u4f18\u52bf\u3002", "conclusion": "Insight-LLM\u4e3a\u5185\u90e8\u5a01\u80c1\u68c0\u6d4b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u591a\u89c6\u56fe\u878d\u5408\u89e3\u51b3\u65b9\u6848\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5728\u6027\u80fd\u548c\u6548\u7387\u65b9\u9762\u90fd\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2509.01016", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2509.01016", "abs": "https://arxiv.org/abs/2509.01016", "authors": ["Aishni Parab", "Hongjing Lu", "Ying Nian Wu", "Sumit Gulwani"], "title": "Analysis of Error Sources in LLM-based Hypothesis Search for Few-Shot Rule Induction", "comment": "This is the preprint version corresponding to our NeurIPS 2025\n  Workshop on Multimodal Algorithmic Reasoning submission", "summary": "Inductive reasoning enables humans to infer abstract rules from limited\nexamples and apply them to novel situations. In this work, we compare an\nLLM-based hypothesis search framework with direct program generation approaches\non few-shot rule induction tasks. Our findings show that hypothesis search\nachieves performance comparable to humans, while direct program generation\nfalls notably behind. An error analysis reveals key bottlenecks in hypothesis\ngeneration and suggests directions for advancing program induction methods.\nOverall, this paper underscores the potential of LLM-based hypothesis search\nfor modeling inductive reasoning and the challenges in building more efficient\nsystems.", "AI": {"tldr": "LLM\u5047\u8bbe\u641c\u7d22\u6846\u67b6\u5728\u5c11\u6837\u672c\u89c4\u5219\u5f52\u7eb3\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u76f4\u63a5\u7a0b\u5e8f\u751f\u6210\u65b9\u6cd5\uff0c\u8fbe\u5230\u4eba\u7c7b\u6c34\u5e73\u6027\u80fd", "motivation": "\u6bd4\u8f83LLM\u5047\u8bbe\u641c\u7d22\u4e0e\u76f4\u63a5\u7a0b\u5e8f\u751f\u6210\u5728\u5f52\u7eb3\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u63a2\u7d22\u5efa\u6a21\u4eba\u7c7b\u5f52\u7eb3\u63a8\u7406\u7684\u65b9\u6cd5", "method": "\u4f7f\u7528LLM\u5047\u8bbe\u641c\u7d22\u6846\u67b6\u548c\u76f4\u63a5\u7a0b\u5e8f\u751f\u6210\u65b9\u6cd5\u5728\u5c11\u6837\u672c\u89c4\u5219\u5f52\u7eb3\u4efb\u52a1\u4e0a\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c", "result": "\u5047\u8bbe\u641c\u7d22\u65b9\u6cd5\u8fbe\u5230\u4e0e\u4eba\u7c7b\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u800c\u76f4\u63a5\u7a0b\u5e8f\u751f\u6210\u65b9\u6cd5\u8868\u73b0\u660e\u663e\u843d\u540e", "conclusion": "LLM\u5047\u8bbe\u641c\u7d22\u5728\u5efa\u6a21\u5f52\u7eb3\u63a8\u7406\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5047\u8bbe\u751f\u6210\u5b58\u5728\u74f6\u9888\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u7cfb\u7edf"}}
{"id": "2509.01592", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.SY", "eess.SY", "68T05, 93C65, 90C35", "K.6.5; C.2.3; I.2.6"], "pdf": "https://arxiv.org/pdf/2509.01592", "abs": "https://arxiv.org/abs/2509.01592", "authors": ["Einstein Rivas Pizarro", "Wajiha Zaheer", "Li Yang", "Khalil El-Khatib", "Glenn Harvel"], "title": "Securing Radiation Detection Systems with an Efficient TinyML-Based IDS for Edge Devices", "comment": "Preprint author original pre review. Accepted and Presented at NPIC &\n  HMIT 2025. The official proceedings version is available in the ANS Digital\n  Library", "summary": "Radiation Detection Systems (RDSs) play a vital role in ensuring public\nsafety across various settings, from nuclear facilities to medical\nenvironments. However, these systems are increasingly vulnerable to\ncyber-attacks such as data injection, man-in-the-middle (MITM) attacks, ICMP\nfloods, botnet attacks, privilege escalation, and distributed denial-of-service\n(DDoS) attacks. Such threats could compromise the integrity and reliability of\nradiation measurements, posing significant public health and safety risks. This\npaper presents a new synthetic radiation dataset and an Intrusion Detection\nSystem (IDS) tailored for resource-constrained environments, bringing Machine\nLearning (ML) predictive capabilities closer to the sensing edge layer of\ncritical infrastructure. Leveraging TinyML techniques, the proposed IDS employs\nan optimized XGBoost model enhanced with pruning, quantization, feature\nselection, and sampling. These TinyML techniques significantly reduce the size\nof the model and computational demands, enabling real-time intrusion detection\non low-resource devices while maintaining a reasonable balance between\nefficiency and accuracy.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f9d\u9760TinyML\u6280\u672f\u7684\u4f18\u5316XGBoost\u6a21\u578b\uff0c\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u8f90\u5c04\u68c0\u6d4b\u7cfb\u7edf\u5165\u4fb5\u68c0\u6d4b\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u6a21\u578b\u5927\u5c0f\u548c\u8ba1\u7b97\u9700\u6c42\u3002", "motivation": "\u8f90\u5c04\u68c0\u6d4b\u7cfb\u7edf(RDS)\u5728\u6838\u8bbe\u65bd\u548c\u533b\u7597\u73af\u5883\u4e2d\u5173\u7cfb\u516c\u4f17\u5b89\u5168\uff0c\u4f46\u6613\u53d7\u5230\u6570\u636e\u6ce8\u5165\u3001DDoS\u7b49\u7f51\u7edc\u653b\u51fb\u5a01\u80c1\uff0c\u9700\u8981\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u5b9e\u73b0\u5b9e\u65f6\u5165\u4fb5\u68c0\u6d4b\u3002", "method": "\u6784\u5efa\u5408\u6210\u8f90\u5c04\u6570\u636e\u96c6\uff0c\u91c7\u7528TinyML\u6280\u672f\uff08\u526a\u679d\u3001\u91cf\u5316\u3001\u7279\u5f81\u9009\u62e9\u3001\u91c7\u6837\uff09\u4f18\u5316XGBoost\u6a21\u578b\uff0c\u964d\u4f4e\u6a21\u578b\u5927\u5c0f\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u8be5\u7cfb\u7edf\u5728\u4fdd\u6301\u5408\u7406\u51c6\u786e\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u6a21\u578b\u5927\u5c0f\u548c\u8ba1\u7b97\u9700\u6c42\uff0c\u80fd\u591f\u5728\u4f4e\u8d44\u6e90\u8bbe\u5907\u4e0a\u5b9e\u73b0\u5b9e\u65f6\u5165\u4fb5\u68c0\u6d4b\u3002", "conclusion": "\u7814\u7a76\u6210\u529f\u5c06\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u80fd\u529b\u63a8\u5e7f\u5230\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u7684\u611f\u77e5\u5c42\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u8f90\u5c04\u5b89\u5168\u76d1\u63a7\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.01021", "categories": ["cs.AI", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2509.01021", "abs": "https://arxiv.org/abs/2509.01021", "authors": ["Yukio-Pegio Gunji", "Andrew Adamatzky", "Panagiotis Mougkogiannis", "Andrei Khrenikov"], "title": "Quantum-like Coherence Derived from the Interaction between Chemical Reaction and Its Environment", "comment": "36 pages, 13 figures", "summary": "By uncovering the contrast between Artificial Intelligence and Natural-born\nIntelligence as a computational process, we define closed computing and open\ncomputing, and implement open computing within chemical reactions. This\ninvolves forming a mixture and invalidation of the computational process and\nthe execution environment, which are logically distinct, and coalescing both to\ncreate a system that adjusts fluctuations. We model chemical reactions by\nconsidering the computation as the chemical reaction and the execution\nenvironment as the degree of aggregation of molecules that interact with the\nreactive environment. This results in a chemical reaction that progresses while\nrepeatedly clustering and de-clustering, where concentration no longer holds\nsignificant meaning. Open computing is segmented into Token computing, which\nfocuses on the individual behavior of chemical molecules, and Type computing,\nwhich focuses on normative behavior. Ultimately, both are constructed as an\ninterplay between the two. In this system, Token computing demonstrates\nself-organizing critical phenomena, while Type computing exhibits quantum\nlogic. Through their interplay, the recruitment of fluctuations is realized,\ngiving rise to interactions between quantum logical subspaces corresponding to\nquantum coherence across different Hilbert spaces. As a result, spike waves are\nformed, enabling signal transmission. This occurrence may be termed\nquantum-like coherence, implying the source of enzymes responsible for\ncontrolling spike waves and biochemical rhythms.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5bf9\u6bd4\u4eba\u5de5\u667a\u80fd\u4e0e\u81ea\u7136\u667a\u80fd\u7684\u8ba1\u7b97\u8fc7\u7a0b\uff0c\u5b9a\u4e49\u4e86\u5c01\u95ed\u8ba1\u7b97\u4e0e\u5f00\u653e\u8ba1\u7b97\uff0c\u5e76\u5728\u5316\u5b66\u53cd\u5e94\u4e2d\u5b9e\u73b0\u4e86\u5f00\u653e\u8ba1\u7b97\u3002\u901a\u8fc7\u5c06\u8ba1\u7b97\u8fc7\u7a0b\u4e0e\u73af\u5883\u878d\u5408\uff0c\u521b\u5efa\u4e86\u80fd\u591f\u8c03\u8282\u6ce2\u52a8\u7684\u7cfb\u7edf\uff0c\u5c55\u793a\u4e86\u81ea\u7ec4\u7ec7\u4e34\u754c\u73b0\u8c61\u548c\u91cf\u5b50\u903b\u8f91\u7279\u6027\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63ed\u793a\u4eba\u5de5\u667a\u80fd\u4e0e\u81ea\u7136\u667a\u80fd\u4e4b\u95f4\u7684\u8ba1\u7b97\u5dee\u5f02\uff0c\u63a2\u7d22\u5728\u5316\u5b66\u53cd\u5e94\u4e2d\u5b9e\u73b0\u5f00\u653e\u8ba1\u7b97\u7684\u53ef\u80fd\u6027\uff0c\u4ee5\u521b\u5efa\u80fd\u591f\u81ea\u9002\u5e94\u8c03\u8282\u6ce2\u52a8\u7684\u667a\u80fd\u7cfb\u7edf\u3002", "method": "\u5c06\u8ba1\u7b97\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u5316\u5b66\u53cd\u5e94\uff0c\u6267\u884c\u73af\u5883\u5efa\u6a21\u4e3a\u5206\u5b50\u805a\u96c6\u7a0b\u5ea6\u3002\u901a\u8fc7Token\u8ba1\u7b97\uff08\u5173\u6ce8\u5355\u4e2a\u5206\u5b50\u884c\u4e3a\uff09\u548cType\u8ba1\u7b97\uff08\u5173\u6ce8\u89c4\u8303\u884c\u4e3a\uff09\u7684\u76f8\u4e92\u4f5c\u7528\u5b9e\u73b0\u5f00\u653e\u8ba1\u7b97\u3002", "result": "\u7cfb\u7edf\u5c55\u793a\u4e86\u81ea\u7ec4\u7ec7\u4e34\u754c\u73b0\u8c61\u548c\u91cf\u5b50\u903b\u8f91\u7279\u6027\uff0c\u901a\u8fc7\u91cf\u5b50\u903b\u8f91\u5b50\u7a7a\u95f4\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u5b9e\u73b0\u4e86\u6ce2\u52a8\u62db\u52df\uff0c\u5f62\u6210\u4e86\u5c16\u5cf0\u6ce2\u4ee5\u5b9e\u73b0\u4fe1\u53f7\u4f20\u8f93\u3002", "conclusion": "\u6210\u529f\u5728\u5316\u5b66\u53cd\u5e94\u4e2d\u5b9e\u73b0\u4e86\u5f00\u653e\u8ba1\u7b97\uff0c\u53d1\u73b0\u4e86\u91cf\u5b50\u7c7b\u76f8\u5e72\u73b0\u8c61\uff0c\u8fd9\u53ef\u80fd\u662f\u63a7\u5236\u5c16\u5cf0\u6ce2\u548c\u751f\u5316\u8282\u5f8b\u7684\u9176\u6e90\u673a\u5236\uff0c\u4e3a\u667a\u80fd\u7cfb\u7edf\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2509.01597", "categories": ["cs.CR", "cs.DS", "stat.AP"], "pdf": "https://arxiv.org/pdf/2509.01597", "abs": "https://arxiv.org/abs/2509.01597", "authors": ["Kaitlyn Webb", "Prottay Protivash", "John Durrell", "Daniell Toth", "Aleksandra Slavkovi\u0107", "Daniel Kifer"], "title": "Statistics-Friendly Confidentiality Protection for Establishment Data, with Applications to the QCEW", "comment": "37 pages (14 main text and 24 appendix pages), 7 figures", "summary": "Confidentiality for business data is an understudied area of disclosure\navoidance, where legacy methods struggle to provide acceptable results. Modern\nformal privacy techniques designed for person-level data do not provide\nsuitable confidentiality/utility trade-offs due to the highly skewed nature of\nbusiness data and because extreme outlier records are often important\ncontributors to query answers. In this paper, inspired by Gaussian Differential\nPrivacy, we propose a novel confidentiality framework for business data with a\nfocus on interpretability for policy makers. We propose two query-answering\nmechanisms and analyze new challenges that arise when noisy query answers are\nconverted into confidentiality-preserving microdata. We evaluate our mechanisms\non confidential Quarterly Census of Employment and Wages (QCEW) microdata and a\npublic substitute dataset.", "AI": {"tldr": "\u63d0\u51fa\u9488\u5bf9\u5546\u4e1a\u6570\u636e\u7684\u4fdd\u5bc6\u6027\u6846\u67b6\uff0c\u57fa\u4e8e\u9ad8\u65af\u5dee\u5206\u9690\u79c1\uff0c\u4e13\u6ce8\u4e8e\u653f\u7b56\u5236\u5b9a\u8005\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u9ad8\u5ea6\u504f\u659c\u5546\u4e1a\u6570\u636e\u4e2d\u7684\u5c40\u9650\u6027", "motivation": "\u5546\u4e1a\u6570\u636e\u4fdd\u5bc6\u6027\u7814\u7a76\u4e0d\u8db3\uff0c\u4f20\u7edf\u65b9\u6cd5\u6548\u679c\u4e0d\u4f73\uff0c\u73b0\u4ee3\u4e2a\u4eba\u6570\u636e\u9690\u79c1\u6280\u672f\u4e0d\u9002\u7528\u4e8e\u9ad8\u5ea6\u504f\u659c\u7684\u5546\u4e1a\u6570\u636e\uff0c\u6781\u7aef\u5f02\u5e38\u503c\u5bf9\u67e5\u8be2\u7ed3\u679c\u8d21\u732e\u91cd\u8981", "method": "\u63d0\u51fa\u57fa\u4e8e\u9ad8\u65af\u5dee\u5206\u9690\u79c1\u7684\u65b0\u578b\u4fdd\u5bc6\u6846\u67b6\uff0c\u5f00\u53d1\u4e24\u79cd\u67e5\u8be2\u5e94\u7b54\u673a\u5236\uff0c\u5206\u6790\u5c06\u566a\u58f0\u67e5\u8be2\u7ed3\u679c\u8f6c\u6362\u4e3a\u4fdd\u5bc6\u5fae\u6570\u636e\u65f6\u7684\u65b0\u6311\u6218", "result": "\u5728\u673a\u5bc6\u5b63\u5ea6\u5c31\u4e1a\u548c\u5de5\u8d44\u666e\u67e5(QCEW)\u5fae\u6570\u636e\u548c\u516c\u5171\u66ff\u4ee3\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e86\u6240\u63d0\u673a\u5236", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5546\u4e1a\u6570\u636e\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u4fdd\u5bc6\u6027/\u6548\u7528\u6743\u8861\uff0c\u7279\u522b\u9002\u5408\u5904\u7406\u9ad8\u5ea6\u504f\u659c\u6570\u636e\u548c\u91cd\u8981\u5f02\u5e38\u503c\u7684\u60c5\u51b5"}}
{"id": "2509.01022", "categories": ["cs.AI", "cs.MA", "cs.RO", "93A16 93A16"], "pdf": "https://arxiv.org/pdf/2509.01022", "abs": "https://arxiv.org/abs/2509.01022", "authors": ["Bo Fu", "Zhe Chen", "Rahul Chandan", "Alex Barbosa", "Michael Caldara", "Joey Durham", "Federico Pecora"], "title": "Symbolic Planning and Multi-Agent Path Finding in Extremely Dense Environments with Movable Obstacles", "comment": null, "summary": "We introduce the Block Rearrangement Problem (BRaP), a challenging component\nof large warehouse management which involves rearranging storage blocks within\ndense grids to achieve a target state. We formally define the BRaP as a graph\nsearch problem. Building on intuitions from sliding puzzle problems, we propose\nfive search-based solution algorithms, leveraging joint configuration space\nsearch, classical planning, multi-agent pathfinding, and expert heuristics. We\nevaluate the five approaches empirically for plan quality and scalability.\nDespite the exponential relation between search space size and block number,\nour methods demonstrate efficiency in creating rearrangement plans for deeply\nburied blocks in up to 80x80 grids.", "AI": {"tldr": "\u63d0\u51fa\u4ed3\u5e93\u7ba1\u7406\u4e2d\u7684\u5757\u91cd\u65b0\u6392\u5217\u95ee\u9898(BRaP)\uff0c\u5f62\u5f0f\u5316\u4e3a\u56fe\u641c\u7d22\u95ee\u9898\uff0c\u5e76\u63d0\u51fa4\u79cd\u641c\u7d22\u57fa\u4e8e\u7b97\u6cd5\u6765\u89e3\u51b3\u3002\u65b9\u6cd5\u572880x80\u7f51\u683c\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u6269\u5c55\u6027\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u4ed3\u5e93\u7ba1\u7406\u4e2d\u7684\u5757\u72b6\u7269\u54c1\u91cd\u65b0\u6392\u5217\u6311\u6218\uff0c\u8fd9\u662f\u4e00\u4e2a\u590d\u6742\u7684\u8fd0\u4f5c\u95ee\u9898\uff0c\u9700\u8981\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u6765\u5904\u7406\u6df1\u85cf\u7684\u5757\u72b6\u7269\u54c1\u3002", "method": "\u57fa\u4e8e\u6ed1\u52a8\u62fc\u56fe\u95ee\u9898\u7684\u76f4\u89c9\uff0c\u63d0\u51fa\u4e94\u79cd\u641c\u7d22\u57fa\u4e8e\u7b97\u6cd5\uff1a\u8054\u5408\u914d\u7f6e\u7a7a\u95f4\u641c\u7d22\u3001\u7ecf\u5178\u89c4\u5212\u3001\u591a\u4ee3\u7406\u8def\u5f84\u627e\u5230\u548c\u4e13\u5bb6\u542b\u6570\u3002\u5c06BRaP\u5f62\u5f0f\u5316\u4e3a\u56fe\u641c\u7d22\u95ee\u9898\u3002", "result": "\u867d\u7136\u641c\u7d22\u7a7a\u95f4\u5927\u5c0f\u4e0e\u5757\u6570\u5448\u6307\u6570\u5173\u7cfb\uff0c\u4f46\u65b9\u6cd5\u572880x80\u7f51\u683c\u4e2d\u80fd\u591f\u9ad8\u6548\u5730\u4e3a\u6df1\u85cf\u5757\u521b\u5efa\u91cd\u65b0\u6392\u5217\u8ba1\u5212\uff0c\u8868\u73b0\u51fa\u826f\u597d\u7684\u6269\u5c55\u6027\u3002", "conclusion": "\u7814\u7a76\u6210\u529f\u5730\u5f62\u5f0f\u5316\u4e86\u4ed3\u5e93\u5757\u91cd\u65b0\u6392\u5217\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u591a\u79cd\u9ad8\u6548\u7684\u641c\u7d22\u7b97\u6cd5\uff0c\u5728\u5927\u89c4\u6a21\u7f51\u683c\u4e2d\u8bc1\u660e\u4e86\u5176\u5b9e\u7528\u6027\u548c\u6269\u5c55\u6027\u3002"}}
{"id": "2509.01599", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.SY", "eess.SY", "68T05, 93C65, 90C35", "K.6.5; C.2.3; I.2.6"], "pdf": "https://arxiv.org/pdf/2509.01599", "abs": "https://arxiv.org/abs/2509.01599", "authors": ["Nathanael Coolidge", "Jaime Gonz\u00e1lez Sanz", "Li Yang", "Khalil El Khatib", "Glenn Harvel", "Nelson Agbemava", "I Putu Susila", "Mehmet Yavuz Yagci"], "title": "An Efficient Intrusion Detection System for Safeguarding Radiation Detection Systems", "comment": "Preprint author original pre review. Accepted and Presented at ISOFIC\n  2024. The official proceedings version is available on the conference site", "summary": "Radiation Detection Systems (RDSs) are used to measure and detect abnormal\nlevels of radioactive material in the environment. These systems are used in\nmany applications to mitigate threats posed by high levels of radioactive\nmaterial. However, these systems lack protection against malicious external\nattacks to modify the data. The novelty of applying Intrusion Detection Systems\n(IDS) in RDSs is a crucial element in safeguarding these critical\ninfrastructures. While IDSs are widely used in networking environments to\nsafeguard against various attacks, their application in RDSs is novel. A common\nattack on RDSs is Denial of Service (DoS), where the attacker aims to overwhelm\nthe system, causing malfunctioning RDSs. This paper proposes an efficient\nMachine Learning (ML)-based IDS to detect anomalies in radiation data, focusing\non DoS attacks. This work explores the use of sampling methods to create a\nsimulated DoS attack based on a real radiation dataset, followed by an\nevaluation of various ML algorithms, including Random Forest, Support Vector\nMachine (SVM), logistic regression, and Light Gradient-Boosting Machine\n(LightGBM), to detect DoS attacks on RDSs. LightGBM is emphasized for its\nsuperior accuracy and low computational resource consumption, making it\nparticularly suitable for real-time intrusion detection. Additionally, model\noptimization and TinyML techniques, including feature selection, parallel\nexecution, and random search methods, are used to improve the efficiency of the\nproposed IDS. Finally, an optimized and efficient LightGBM-based IDS is\ndeveloped to achieve accurate intrusion detection for RDSs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLightGBM\u7684\u673a\u5668\u5b66\u4e60\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\uff0c\u7528\u4e8e\u9632\u8303\u653b\u51fb\u8005\u5bf9\u653f\u5c04\u68c0\u6d4b\u7cfb\u7edf\u7684\u62d2\u7edd\u670d\u52a1\u653b\u51fb\uff0c\u5177\u6709\u9ad8\u51c6\u786e\u6027\u548c\u4f4e\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u7684\u4f18\u52bf\u3002", "motivation": "\u653f\u5c04\u68c0\u6d4b\u7cfb\u7edf(RDS)\u5728\u73af\u5883\u76d1\u6d4b\u4e2d\u81f4\u5173\u91cd\u8981\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u6076\u610f\u653b\u51fb\u7684\u9632\u62a4\u80fd\u529b\u3002\u5c24\u5176\u662f\u62d2\u7edd\u670d\u52a1(DoS)\u653b\u51fb\u53ef\u80fd\u5bfc\u81f4\u7cfb\u7edf\u6545\u969c\uff0c\u9700\u8981\u6709\u6548\u7684\u5165\u4fb5\u68c0\u6d4b\u65b9\u6848\u6765\u4fdd\u62a4\u8fd9\u4e9b\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u3002", "method": "\u4f7f\u7528\u91c7\u6837\u65b9\u6cd5\u6a21\u62dfDoS\u653b\u51fb\uff0c\u8bc4\u4f30\u591a\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff08\u968f\u673a\u68ee\u6797\u3001SVM\u3001\u903b\u8f91\u56de\u5f52\u3001LightGBM\uff09\u7684\u6027\u80fd\u3002\u91c7\u7528\u7279\u5f81\u9009\u62e9\u3001\u5e76\u884c\u6267\u884c\u3001\u968f\u673a\u641c\u7d22\u7b49TinyML\u6280\u672f\u8fdb\u884c\u6a21\u578b\u4f18\u5316\u3002", "result": "LightGBM\u5728\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u8868\u73b0\u6700\u4f18\uff0c\u9002\u5408\u5b9e\u65f6\u5165\u4fb5\u68c0\u6d4b\u3002\u6700\u7ec8\u5f00\u53d1\u51fa\u4e86\u4f18\u5316\u7684\u57fa\u4e8eLightGBM\u7684\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5c55\u793a\u4e86\u673a\u5668\u5b66\u4e60\u5728\u653f\u5c04\u68c0\u6d4b\u7cfb\u7edf\u5b89\u5168\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0cLightGBM\u7b97\u6cd5\u5728DoS\u653b\u51fb\u68c0\u6d4b\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u4e3a\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u7684\u5b89\u5168\u4fdd\u62a4\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.01052", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.01052", "abs": "https://arxiv.org/abs/2509.01052", "authors": ["Jaewoo Ahn", "Junseo Kim", "Heeseung Yun", "Jaehyeon Son", "Dongmin Park", "Jaewoong Cho", "Gunhee Kim"], "title": "FlashAdventure: A Benchmark for GUI Agents Solving Full Story Arcs in Diverse Adventure Games", "comment": "EMNLP 2025 Main. Project page:\n  https://ahnjaewoo.github.io/flashadventure", "summary": "GUI agents powered by LLMs show promise in interacting with diverse digital\nenvironments. Among these, video games offer a valuable testbed due to their\nvaried interfaces, with adventure games posing additional challenges through\ncomplex, narrative-driven interactions. Existing game benchmarks, however, lack\ndiversity and rarely evaluate agents on completing entire storylines. To\naddress this, we introduce FlashAdventure, a benchmark of 34 Flash-based\nadventure games designed to test full story arc completion and tackle the\nobservation-behavior gap: the challenge of remembering and acting on earlier\ngameplay information. We also propose CUA-as-a-Judge, an automated gameplay\nevaluator, and COAST, an agentic framework leveraging long-term clue memory to\nbetter plan and solve sequential tasks. Experiments show current GUI agents\nstruggle with full story arcs, while COAST improves milestone completion by\nbridging the observation-behavior gap. Nonetheless, a marked discrepancy\nbetween humans and best-performing agents warrants continued research efforts\nto narrow this divide.", "AI": {"tldr": "FlashAdventure\u662f\u4e00\u4e2a\u5305\u542b34\u4e2aFlash\u5192\u9669\u6e38\u620f\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30GUI\u4ee3\u7406\u5b8c\u6210\u5b8c\u6574\u6545\u4e8b\u7ebf\u7684\u80fd\u529b\uff0c\u5e76\u63d0\u51fa\u4e86COAST\u6846\u67b6\u548cCUA-as-a-Judge\u81ea\u52a8\u8bc4\u4f30\u5668\u6765\u6539\u5584\u89c2\u5bdf-\u884c\u4e3a\u5dee\u8ddd\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u6e38\u620f\u57fa\u51c6\u6d4b\u8bd5\u7f3a\u4e4f\u591a\u6837\u6027\uff0c\u5f88\u5c11\u8bc4\u4f30\u4ee3\u7406\u5b8c\u6210\u6574\u4e2a\u6545\u4e8b\u7ebf\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5192\u9669\u6e38\u620f\u4e2d\u590d\u6742\u7684\u53d9\u4e8b\u9a71\u52a8\u4ea4\u4e92\u5b58\u5728\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86FlashAdventure\u57fa\u51c6\u6d4b\u8bd5\u3001CUA-as-a-Judge\u81ea\u52a8\u6e38\u620f\u8bc4\u4f30\u5668\uff0c\u4ee5\u53caCOAST\u4ee3\u7406\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u957f\u671f\u7ebf\u7d22\u8bb0\u5fc6\u6765\u66f4\u597d\u5730\u89c4\u5212\u548c\u89e3\u51b3\u987a\u5e8f\u4efb\u52a1\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u5f53\u524dGUI\u4ee3\u7406\u5728\u5b8c\u6574\u6545\u4e8b\u5f27\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u800cCOAST\u901a\u8fc7\u5f25\u5408\u89c2\u5bdf-\u884c\u4e3a\u5dee\u8ddd\u663e\u8457\u63d0\u9ad8\u4e86\u91cc\u7a0b\u7891\u5b8c\u6210\u7387\u3002", "conclusion": "\u5c3d\u7ba1COAST\u6709\u6240\u6539\u8fdb\uff0c\u4f46\u4eba\u7c7b\u4e0e\u6700\u4f73\u4ee3\u7406\u4e4b\u95f4\u4ecd\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u9700\u8981\u7ee7\u7eed\u7814\u7a76\u6765\u7f29\u5c0f\u8fd9\u4e00\u9e3f\u6c9f\u3002"}}
{"id": "2509.01701", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.01701", "abs": "https://arxiv.org/abs/2509.01701", "authors": ["Kazi Hassan Shakib", "Muhammad Asfand Hafeez", "Arslan Munir"], "title": "AmphiKey: A Dual-Mode Secure Authenticated Key Encapsulation Protocol for Smart Grid", "comment": null, "summary": "AmphiKey, a dual-mode post-quantum/traditional (PQ/T) hybrid authenticated\nkey exchange mechanism (AKEM) has been designed to secure smart grid\ncommunications against both classical and quantum threats. AmphiKey offers two\ndistinct operational modes within a single framework: an Authenticated Mode and\na Deniable Mode. The Authenticated Mode employs a blackbox approach, combining\nephemeral ML-KEM-768 and X25519 with long-term Raccoon DSA keys to provide\nforward secrecy and strong, non-repudiable authenticity. This design achieves\n\"OR\" confidentiality, where security holds if either of the KEMs is unbroken,\nand robust \"AND\" authenticity. For the signature operation, it leverages the\n'masking-friendly' Raccoon digital signature (DSA), which is specifically\ndesigned for side-channel attack resistance, though this protection is\nlocalized to the signing key and does not provide deniability. In contrast,\nDeniable Mode provides deniable authentication, preserving privacy. The\nprotocol used ML-KEM-768 (AKEM-1), Ephemeral X25519 (AKEM-2), Raccoon-based DSA\n(Rac) (compared performance to ML-DSA-65), and the Ascon cipher to deliver its\nsecurity guarantees. Key contributions include providing a flexible protocol\nwith enhanced security, optional deniability, and efficiency adapted to the\ndiverse needs of the smart grid infrastructure. We present a comprehensive\nperformance evaluation on a heterogeneous testbed featuring a powerful server\nand client (AMD Ryzen 5) and a resource-constrained client (Raspberry Pi). In\nefficient Deniable mode, the full handshake completes in 0.15 ms on the server\nand 0.41 ms on the Raspberry Pi client. In contrast, the Authenticated Mode is\nbottlenecked by the client-side signature generation; the handshake takes 4.8\nms for the Raspberry Pi client to initiate and 0.84 ms for the server to\nverify.", "AI": {"tldr": "AmphiKey\u662f\u4e00\u4e2a\u53cc\u6a21\u5f0f\u540e\u91cf\u5b50/\u4f20\u7edf\u6df7\u5408\u8ba4\u8bc1\u5bc6\u94a5\u4ea4\u6362\u673a\u5236\uff0c\u4e3a\u667a\u80fd\u7535\u7f51\u63d0\u4f9b\u6297\u91cf\u5b50\u548c\u4f20\u7edf\u653b\u51fb\u7684\u5b89\u5168\u901a\u4fe1\uff0c\u652f\u6301\u8ba4\u8bc1\u6a21\u5f0f\u548c\u53ef\u5426\u8ba4\u6a21\u5f0f\u3002", "motivation": "\u667a\u80fd\u7535\u7f51\u901a\u4fe1\u9700\u8981\u540c\u65f6\u62b5\u5fa1\u4f20\u7edf\u548c\u91cf\u5b50\u8ba1\u7b97\u5a01\u80c1\uff0c\u73b0\u6709\u65b9\u6848\u7f3a\u4e4f\u7075\u6d3b\u6027\u548c\u6548\u7387\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u63d0\u4f9b\u5f3a\u8ba4\u8bc1\u53c8\u80fd\u652f\u6301\u9690\u79c1\u4fdd\u62a4\u7684\u6df7\u5408\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u6df7\u5408\u8bbe\u8ba1\uff1a\u8ba4\u8bc1\u6a21\u5f0f\u7ed3\u5408ML-KEM-768\u3001X25519\u548cRaccoon DSA\u63d0\u4f9b\u524d\u5411\u5b89\u5168\u6027\u548c\u4e0d\u53ef\u5426\u8ba4\u8ba4\u8bc1\uff1b\u53ef\u5426\u8ba4\u6a21\u5f0f\u63d0\u4f9b\u9690\u79c1\u4fdd\u62a4\u3002\u4f7f\u7528Ascon\u5bc6\u7801\u7b97\u6cd5\uff0c\u5728\u5f02\u6784\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u8fdb\u884c\u6027\u80fd\u8bc4\u4f30\u3002", "result": "\u6027\u80fd\u4f18\u5f02\uff1a\u53ef\u5426\u8ba4\u6a21\u5f0f\u4e0b\u5b8c\u6574\u63e1\u624b\u5728\u670d\u52a1\u5668\u4ec5\u97000.15ms\uff0c\u6811\u8393\u6d3e\u5ba2\u6237\u7aef0.41ms\uff1b\u8ba4\u8bc1\u6a21\u5f0f\u4e0b\u6811\u8393\u6d3e\u5ba2\u6237\u7aef\u7b7e\u540d\u751f\u6210\u8017\u65f64.8ms\uff0c\u670d\u52a1\u5668\u9a8c\u8bc10.84ms\u3002", "conclusion": "AmphiKey\u6210\u529f\u5b9e\u73b0\u4e86\u7075\u6d3b\u7684\u53cc\u6a21\u5f0f\u5b89\u5168\u534f\u8bae\uff0c\u4e3a\u667a\u80fd\u7535\u7f51\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u540e\u91cf\u5b50\u5b89\u5168\u89e3\u51b3\u65b9\u6848\uff0c\u5e73\u8861\u4e86\u5b89\u5168\u6027\u3001\u9690\u79c1\u6027\u548c\u6027\u80fd\u9700\u6c42\u3002"}}
{"id": "2509.01055", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.01055", "abs": "https://arxiv.org/abs/2509.01055", "authors": ["Dongfu Jiang", "Yi Lu", "Zhuofeng Li", "Zhiheng Lyu", "Ping Nie", "Haozhe Wang", "Alex Su", "Hui Chen", "Kai Zou", "Chao Du", "Tianyu Pang", "Wenhu Chen"], "title": "VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use", "comment": "32 pages, 5 figures, 13 tables", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has demonstrated\nsuccess in enhancing LLM reasoning capabilities, but remains limited to\nsingle-turn interactions without tool integration. While recent Agentic\nReinforcement Learning with Tool use (ARLT) approaches have emerged to address\nmulti-turn tool interactions, existing works develop task-specific codebases\nthat suffer from fragmentation, synchronous execution bottlenecks, and limited\nextensibility across domains. These inefficiencies hinder broader community\nadoption and algorithmic innovation. We introduce VerlTool, a unified and\nmodular framework that addresses these limitations through systematic design\nprinciples. VerlTool provides four key contributions: (1) upstream alignment\nwith VeRL ensuring compatibility and simplified maintenance, (2) unified tool\nmanagement via standardized APIs supporting diverse modalities including code\nexecution, search, SQL databases, and vision processing, (3) asynchronous\nrollout execution achieving near 2$\\times$ speedup by eliminating\nsynchronization bottlenecks, and (4) comprehensive evaluation demonstrating\ncompetitive performance across 6 ARLT domains. Our framework formalizes ARLT as\nmulti-turn trajectories with multi-modal observation tokens (text/image/video),\nextending beyond single-turn RLVR paradigms. We train and evaluate models on\nmathematical reasoning, knowledge QA, SQL generation, visual reasoning, web\nsearch, and software engineering tasks, achieving results comparable to\nspecialized systems while providing unified training infrastructure. The\nmodular plugin architecture enables rapid tool integration requiring only\nlightweight Python definitions, significantly reducing development overhead and\nproviding a scalable foundation for tool-augmented RL research. Our code is\nopen-sourced at https://github.com/TIGER-AI-Lab/verl-tool.", "AI": {"tldr": "VerlTool\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u6a21\u5757\u5316\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5de5\u5177\u589e\u5f3a\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7684\u788e\u7247\u5316\u3001\u540c\u6b65\u6267\u884c\u74f6\u9888\u548c\u6709\u9650\u6269\u5c55\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u6807\u51c6\u5316API\u3001\u5f02\u6b65\u6267\u884c\u548c\u591a\u6a21\u6001\u652f\u6301\uff0c\u57286\u4e2a\u9886\u57df\u5b9e\u73b0\u7ade\u4e89\u6027\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u5de5\u5177\u589e\u5f3a\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5b58\u5728\u4ee3\u7801\u5e93\u788e\u7247\u5316\u3001\u540c\u6b65\u6267\u884c\u74f6\u9888\u548c\u8de8\u9886\u57df\u6269\u5c55\u6027\u6709\u9650\u7684\u95ee\u9898\uff0c\u963b\u788d\u4e86\u793e\u533a\u91c7\u7528\u548c\u7b97\u6cd5\u521b\u65b0\u3002", "method": "\u63d0\u51faVerlTool\u6846\u67b6\uff0c\u5305\u542b\u56db\u4e2a\u5173\u952e\u8d21\u732e\uff1a\u4e0eVeRL\u7684\u4e0a\u6e38\u5bf9\u9f50\u3001\u901a\u8fc7\u6807\u51c6\u5316API\u7684\u7edf\u4e00\u5de5\u5177\u7ba1\u7406\u3001\u5f02\u6b65rollout\u6267\u884c\u5b9e\u73b02\u500d\u52a0\u901f\u3001\u4ee5\u53ca\u591a\u9886\u57df\u7efc\u5408\u8bc4\u4f30\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u3001\u77e5\u8bc6\u95ee\u7b54\u3001SQL\u751f\u6210\u3001\u89c6\u89c9\u63a8\u7406\u3001\u7f51\u7edc\u641c\u7d22\u548c\u8f6f\u4ef6\u5de5\u7a0b\u7b496\u4e2aARLT\u9886\u57df\u5b9e\u73b0\u7ade\u4e89\u6027\u6027\u80fd\uff0c\u5f02\u6b65\u6267\u884c\u5e26\u6765\u8fd12\u500d\u901f\u5ea6\u63d0\u5347\u3002", "conclusion": "VerlTool\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u7edf\u4e00\u8bad\u7ec3\u57fa\u7840\u8bbe\u65bd\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u63d2\u4ef6\u67b6\u6784\u663e\u8457\u51cf\u5c11\u5f00\u53d1\u5f00\u9500\uff0c\u4e3a\u5de5\u5177\u589e\u5f3a\u7684RL\u7814\u7a76\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2509.01717", "categories": ["cs.CR", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.01717", "abs": "https://arxiv.org/abs/2509.01717", "authors": ["Hojjat Farshadinia", "Ali Barati", "Hamid Barati"], "title": "Designing a Layered Framework to Secure Data via Improved Multi Stage Lightweight Cryptography in IoT Cloud Systems", "comment": null, "summary": "This paper presents a novel multi-layered hybrid security approach aimed at\nenhancing lightweight encryption for IoT-Cloud systems. The primary goal is to\novercome limitations inherent in conventional solutions such as TPA,\nBlockchain, ECDSA and ZSS which often fall short in terms of data protection,\ncomputational efficiency and scalability. Our proposed method strategically\nrefines and integrates these technologies to address their shortcomings while\nmaximizing their individual strengths. By doing so we create a more reliable\nand high-performance framework for secure data exchange across heterogeneous\nenvironments. The model leverages the combined potential of emerging\ntechnologies, particularly Blockchain, IoT and Cloud computing which when\neffectively coordinated offer significant advancements in security\narchitecture. The proposed framework consists of three core layers: (1) the\nH.E.EZ Layer which integrates improved versions of Hyperledger Fabric,\nEnc-Block and a hybrid ECDSA-ZSS scheme to improve encryption speed,\nscalability and reduce computational cost; (2) the Credential Management Layer\nindependently verifying data integrity and authenticity; and (3) the Time and\nAuditing Layer designed to reduce traffic overhead and optimize performance\nacross dynamic workloads. Evaluation results highlight that the proposed\nsolution not only strengthens security but also significantly improves\nexecution time, communication efficiency and system responsiveness, offering a\nrobust path forward for next-generation IoT-Cloud infrastructures.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u591a\u5c42\u6df7\u5408\u5b89\u5168\u65b9\u6cd5\uff0c\u901a\u8fc7\u6539\u8fdb\u548c\u6574\u5408TPA\u3001\u533a\u5757\u94fe\u3001ECDSA\u548cZSS\u7b49\u6280\u672f\uff0c\u4e3aIoT-\u4e91\u7cfb\u7edf\u63d0\u4f9b\u8f7b\u91cf\u7ea7\u52a0\u5bc6\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u5b89\u5168\u6027\u3001\u6267\u884c\u6548\u7387\u548c\u7cfb\u7edf\u54cd\u5e94\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u89e3\u51b3\u65b9\u6848\u5982TPA\u3001\u533a\u5757\u94fe\u3001ECDSA\u548cZSS\u5728\u6570\u636e\u4fdd\u62a4\u3001\u8ba1\u7b97\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u53ef\u9760\u3001\u9ad8\u6027\u80fd\u7684\u5b89\u5168\u6846\u67b6\u6765\u652f\u6301\u5f02\u6784\u73af\u5883\u4e0b\u7684\u5b89\u5168\u6570\u636e\u4ea4\u6362\u3002", "method": "\u91c7\u7528\u4e09\u5c42\u6838\u5fc3\u67b6\u6784\uff1a1)H.E.EZ\u5c42\u6574\u5408\u6539\u8fdb\u7684Hyperledger Fabric\u3001Enc-Block\u548c\u6df7\u5408ECDSA-ZSS\u65b9\u6848\uff1b2)\u51ed\u8bc1\u7ba1\u7406\u5c42\u72ec\u7acb\u9a8c\u8bc1\u6570\u636e\u5b8c\u6574\u6027\u548c\u771f\u5b9e\u6027\uff1b3)\u65f6\u95f4\u548c\u5ba1\u8ba1\u5c42\u51cf\u5c11\u6d41\u91cf\u5f00\u9500\u5e76\u4f18\u5316\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u6027\u80fd\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u89e3\u51b3\u65b9\u6848\u4e0d\u4ec5\u589e\u5f3a\u4e86\u5b89\u5168\u6027\uff0c\u8fd8\u663e\u8457\u6539\u5584\u4e86\u6267\u884c\u65f6\u95f4\u3001\u901a\u4fe1\u6548\u7387\u548c\u7cfb\u7edf\u54cd\u5e94\u80fd\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u4e0b\u4e00\u4ee3IoT-\u4e91\u57fa\u7840\u8bbe\u65bd\u63d0\u4f9b\u4e86\u4e00\u6761\u7a33\u5065\u7684\u53d1\u5c55\u8def\u5f84\uff0c\u901a\u8fc7\u6709\u6548\u534f\u8c03\u533a\u5757\u94fe\u3001IoT\u548c\u4e91\u8ba1\u7b97\u7b49\u65b0\u5174\u6280\u672f\u7684\u6f5c\u529b\uff0c\u5728\u5b89\u5168\u67b6\u6784\u65b9\u9762\u53d6\u5f97\u4e86\u91cd\u8981\u8fdb\u5c55\u3002"}}
{"id": "2509.01106", "categories": ["cs.AI", "cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.01106", "abs": "https://arxiv.org/abs/2509.01106", "authors": ["Huang Fang", "Mengxi Zhang", "Heng Dong", "Wei Li", "Zixuan Wang", "Qifeng Zhang", "Xueyun Tian", "Yucheng Hu", "Hang Li"], "title": "Robix: A Unified Model for Robot Interaction, Reasoning and Planning", "comment": "Tech report. Project page: https://robix-seed.github.io/robix/", "summary": "We introduce Robix, a unified model that integrates robot reasoning, task\nplanning, and natural language interaction within a single vision-language\narchitecture. Acting as the high-level cognitive layer in a hierarchical robot\nsystem, Robix dynamically generates atomic commands for the low-level\ncontroller and verbal responses for human interaction, enabling robots to\nfollow complex instructions, plan long-horizon tasks, and interact naturally\nwith human within an end-to-end framework. Robix further introduces novel\ncapabilities such as proactive dialogue, real-time interruption handling, and\ncontext-aware commonsense reasoning during task execution. At its core, Robix\nleverages chain-of-thought reasoning and adopts a three-stage training\nstrategy: (1) continued pretraining to enhance foundational embodied reasoning\nabilities including 3D spatial understanding, visual grounding, and\ntask-centric reasoning; (2) supervised finetuning to model human-robot\ninteraction and task planning as a unified reasoning-action sequence; and (3)\nreinforcement learning to improve reasoning-action consistency and long-horizon\ntask coherence. Extensive experiments demonstrate that Robix outperforms both\nopen-source and commercial baselines (e.g., GPT-4o and Gemini 2.5 Pro) in\ninteractive task execution, demonstrating strong generalization across diverse\ninstruction types (e.g., open-ended, multi-stage, constrained, invalid, and\ninterrupted) and various user-involved tasks such as table bussing, grocery\nshopping, and dietary filtering.", "AI": {"tldr": "Robix\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u89c6\u89c9\u8bed\u8a00\u67b6\u6784\u6a21\u578b\uff0c\u96c6\u6210\u4e86\u673a\u5668\u4eba\u63a8\u7406\u3001\u4efb\u52a1\u89c4\u5212\u548c\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\uff0c\u4f5c\u4e3a\u5206\u5c42\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u9ad8\u5c42\u8ba4\u77e5\u5c42\uff0c\u80fd\u591f\u52a8\u6001\u751f\u6210\u539f\u5b50\u547d\u4ee4\u548c\u8bed\u8a00\u54cd\u5e94\uff0c\u652f\u6301\u590d\u6742\u6307\u4ee4\u6267\u884c\u3001\u957f\u65f6\u7a0b\u4efb\u52a1\u89c4\u5212\u548c\u81ea\u7136\u4eba\u7c7b\u4ea4\u4e92\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u73b0\u6709\u673a\u5668\u4eba\u7cfb\u7edf\u5728\u590d\u6742\u6307\u4ee4\u6267\u884c\u3001\u957f\u65f6\u7a0b\u4efb\u52a1\u89c4\u5212\u548c\u81ea\u7136\u4eba\u7c7b\u4ea4\u4e92\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u7edf\u4e00\u7684\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u5c06\u63a8\u7406\u3001\u89c4\u5212\u548c\u4ea4\u4e92\u80fd\u529b\u6574\u5408\u5230\u5355\u4e00\u6a21\u578b\u4e2d\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff1a1\uff09\u6301\u7eed\u9884\u8bad\u7ec3\u589e\u5f3a\u57fa\u7840\u5177\u8eab\u63a8\u7406\u80fd\u529b\uff1b2\uff09\u76d1\u7763\u5fae\u8c03\u5c06\u4eba\u673a\u4ea4\u4e92\u548c\u4efb\u52a1\u89c4\u5212\u5efa\u6a21\u4e3a\u7edf\u4e00\u7684\u63a8\u7406-\u52a8\u4f5c\u5e8f\u5217\uff1b3\uff09\u5f3a\u5316\u5b66\u4e60\u63d0\u9ad8\u63a8\u7406-\u52a8\u4f5c\u4e00\u81f4\u6027\u548c\u957f\u65f6\u7a0b\u4efb\u52a1\u8fde\u8d2f\u6027\u3002\u6838\u5fc3\u4f7f\u7528\u601d\u7ef4\u94fe\u63a8\u7406\u3002", "result": "\u5728\u4ea4\u4e92\u5f0f\u4efb\u52a1\u6267\u884c\u4e2d\u4f18\u4e8e\u5f00\u6e90\u548c\u5546\u4e1a\u57fa\u7ebf\uff08\u5982GPT-4o\u548cGemini 2.5 Pro\uff09\uff0c\u5728\u591a\u6837\u5316\u6307\u4ee4\u7c7b\u578b\uff08\u5f00\u653e\u7aef\u3001\u591a\u9636\u6bb5\u3001\u7ea6\u675f\u3001\u65e0\u6548\u548c\u4e2d\u65ad\u6307\u4ee4\uff09\u548c\u5404\u79cd\u7528\u6237\u53c2\u4e0e\u4efb\u52a1\uff08\u5982\u9910\u684c\u6e05\u7406\u3001\u8d2d\u7269\u548c\u996e\u98df\u7b5b\u9009\uff09\u4e0a\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "Robix\u901a\u8fc7\u7edf\u4e00\u7684\u89c6\u89c9\u8bed\u8a00\u67b6\u6784\u6210\u529f\u6574\u5408\u4e86\u673a\u5668\u4eba\u63a8\u7406\u3001\u4efb\u52a1\u89c4\u5212\u548c\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u590d\u6742\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u548c\u4f18\u8d8a\u6027\uff0c\u4e3a\u6784\u5efa\u66f4\u667a\u80fd\u3001\u66f4\u81ea\u7136\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u529b\u6846\u67b6\u3002"}}
{"id": "2509.01731", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.01731", "abs": "https://arxiv.org/abs/2509.01731", "authors": ["Tran Duc Le", "Phuc Hao Do", "Truong Duy Dinh", "Van Dai Pham"], "title": "Are Enterprises Ready for Quantum-Safe Cybersecurity?", "comment": "Are Enterprises Ready for Quantum-Safe Cybersecurity?", "summary": "Quantum computing threatens to undermine classical cryptography by breaking\nwidely deployed encryption and signature schemes. This paper examines\nenterprise readiness for quantum-safe cybersecurity through three perspectives:\n(i) the technologist view, assessing the maturity of post-quantum cryptography\n(PQC) and quantum key distribution (QKD); (ii) the enterprise (CISO/CIO) view,\nanalyzing organizational awareness, risk management, and operational barriers;\nand (iii) the threat actor view, evaluating the evolving quantum threat and the\nurgency of migration. Using recent standards (e.g., NIST's 2024 PQC\nalgorithms), industry surveys, and threat intelligence, we synthesize findings\nvia a SWOT analysis to map strengths, weaknesses, opportunities, and threats.\nResults indicate uneven and generally insufficient preparedness: while PQC\nstandards and niche QKD deployments signal technical progress, fewer than 5\\%\nof enterprises have formal quantum-transition plans, and many underestimate\n\"harvest now, decrypt later\" risks. Financial, telecom, and government sectors\nhave begun migration, but most industries remain exploratory or stalled by\ncosts, complexity, and skills gaps. Expert consensus places cryptanalytically\nrelevant quantum computers in the 2030s, yet delayed preparation could leave\ntoday's data vulnerable for decades. We recommend immediate steps: establishing\ncrypto-agility, creating quantum transition roadmaps, prioritizing PQC\ndeployment in high-value systems, and upskilling cybersecurity teams. A\ncoordinated, proactive approach is essential to secure current and future\ndigital assets in the quantum era.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4f01\u4e1a\u91cf\u5b50\u5b89\u5168\u51c6\u5907\u60c5\u51b5\uff0c\u53d1\u73b0\u5c3d\u7ba1PQC\u6807\u51c6\u5df2\u6210\u719f\uff0c\u4f46\u4ec5\u6709\u4e0d\u52305%\u7684\u4f01\u4e1a\u6709\u6b63\u5f0f\u91cf\u5b50\u8fc1\u79fb\u8ba1\u5212\uff0c\u5efa\u8bae\u7acb\u5373\u5efa\u7acb\u52a0\u5bc6\u654f\u6377\u6027\u548c\u8fc7\u6e21\u8def\u7ebf\u56fe\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u5a01\u80c1\u4f20\u7edf\u52a0\u5bc6\u4f53\u7cfb\uff0c\u9700\u8981\u8bc4\u4f30\u4f01\u4e1a\u5728\u91cf\u5b50\u5b89\u5168\u7f51\u7edc\u5b89\u5168\u65b9\u9762\u7684\u51c6\u5907\u7a0b\u5ea6\uff0c\u4e3a\u6570\u5b57\u5316\u8f6c\u578b\u63d0\u4f9b\u5b89\u5168\u4fdd\u969c\u3002", "method": "\u91c7\u7528\u4e09\u91cd\u89c6\u89d2\u5206\u6790\uff1a\u6280\u672f\u4e13\u5bb6\u89c6\u89d2\u8bc4\u4f30PQC\u548cQKD\u6210\u719f\u5ea6\uff1b\u4f01\u4e1a\u89c6\u89d2\u5206\u6790\u7ec4\u7ec7\u610f\u8bc6\u548c\u8fd0\u8425\u969c\u788d\uff1b\u5a01\u80c1\u884c\u4e3a\u8005\u89c6\u89d2\u8bc4\u4f30\u91cf\u5b50\u5a01\u80c1\u7d27\u8feb\u6027\u3002\u7ed3\u5408SWOT\u5206\u6790\u7efc\u5408\u8bc4\u4f30\u3002", "result": "\u4f01\u4e1a\u51c6\u5907\u5ea6\u666e\u904d\u4e0d\u8db3\u4e14\u4e0d\u5747\u8861\uff0cPQC\u6807\u51c6\u548cQKD\u90e8\u7f72\u663e\u793a\u6280\u672f\u8fdb\u6b65\uff0c\u4f46\u4ec5\u6709\u5c11\u6570\u4f01\u4e1a\u6709\u6b63\u5f0f\u8ba1\u5212\uff0c\u591a\u6570\u884c\u4e1a\u56e0\u6210\u672c\u3001\u590d\u6742\u6027\u548c\u6280\u80fd\u5dee\u8ddd\u800c\u505c\u6ede\u3002", "conclusion": "\u5efa\u8bae\u7acb\u5373\u91c7\u53d6\u884c\u52a8\uff1a\u5efa\u7acb\u52a0\u5bc6\u654f\u6377\u6027\u3001\u5236\u5b9a\u91cf\u5b50\u8fc7\u6e21\u8def\u7ebf\u56fe\u3001\u4f18\u5148\u5728\u9ad8\u4ef7\u503c\u7cfb\u7edf\u90e8\u7f72PQC\u3001\u63d0\u5347\u7f51\u7edc\u5b89\u5168\u56e2\u961f\u6280\u80fd\uff0c\u9700\u8981\u534f\u8c03\u4e3b\u52a8\u7684\u65b9\u6cd5\u6765\u4fdd\u62a4\u91cf\u5b50\u65f6\u4ee3\u7684\u6570\u5b57\u8d44\u4ea7\u3002"}}
{"id": "2509.01136", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.01136", "abs": "https://arxiv.org/abs/2509.01136", "authors": ["Gabriel Simmons"], "title": "Heads or Tails: A Simple Example of Causal Abstractive Simulation", "comment": "14 pages", "summary": "This note illustrates how a variety of causal abstraction arXiv:1707.00819\narXiv:1812.03789, defined here as causal abstractive simulation, can be used to\nformalize a simple example of language model simulation. This note considers\nthe case of simulating a fair coin toss with a language model. Examples are\npresented illustrating the ways language models can fail to simulate, and a\nsuccess case is presented, illustrating how this formalism may be used to prove\nthat a language model simulates some other system, given a causal description\nof the system. This note may be of interest to three groups. For practitioners\nin the growing field of language model simulation, causal abstractive\nsimulation is a means to connect ad-hoc statistical benchmarking practices to\nthe solid formal foundation of causality. Philosophers of AI and philosophers\nof mind may be interested as causal abstractive simulation gives a precise\noperationalization to the idea that language models are role-playing\narXiv:2402.12422. Mathematicians and others working on causal abstraction may\nbe interested to see a new application of the core ideas that yields a new\nvariation of causal abstraction.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u56e0\u679c\u62bd\u8c61\u6a21\u62df\u5f62\u5f0f\u5316\u4e86\u8bed\u8a00\u6a21\u578b\u6a21\u62df\u8fc7\u7a0b\uff0c\u4ee5\u629b\u786c\u5e01\u4e3a\u4f8b\u5c55\u793a\u5982\u4f55\u8bc1\u660e\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u6a21\u62df\u5176\u4ed6\u7cfb\u7edf", "motivation": "\u4e3a\u8bed\u8a00\u6a21\u578b\u6a21\u62df\u9886\u57df\u63d0\u4f9b\u4e25\u683c\u7684\u56e0\u679c\u62bd\u8c61\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u4e3a\u54f2\u5b66\u5bb6\u548c\u6570\u5b66\u5bb6\u63d0\u4f9b\u65b0\u7684\u7814\u7a76\u89c6\u89d2", "method": "\u4f7f\u7528\u56e0\u679c\u62bd\u8c61\u6a21\u62df\u65b9\u6cd5\uff0c\u4ee5\u516c\u5e73\u629b\u786c\u5e01\u4e3a\u793a\u4f8b\uff0c\u5206\u6790\u8bed\u8a00\u6a21\u578b\u6a21\u62df\u6210\u529f\u548c\u5931\u8d25\u7684\u60c5\u51b5", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u56e0\u679c\u62bd\u8c61\u53d8\u4f53\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u4f7f\u7528\u8be5\u5f62\u5f0f\u6765\u8bc1\u660e\u8bed\u8a00\u6a21\u578b\u7684\u6a21\u62df\u80fd\u529b", "conclusion": "\u56e0\u679c\u62bd\u8c61\u6a21\u62df\u4e3a\u8bed\u8a00\u6a21\u578b\u6a21\u62df\u9886\u57df\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u7406\u8bba\u57fa\u7840\uff0c\u540c\u65f6\u4e5f\u4e3a\u54f2\u5b66\u5bb6\u548c\u6570\u5b66\u5bb6\u5e26\u6765\u4e86\u65b0\u7684\u7814\u7a76\u673a\u9047"}}
{"id": "2509.01742", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2509.01742", "abs": "https://arxiv.org/abs/2509.01742", "authors": ["Yitong Guo", "Hongbo Chen", "Haobin Hiroki Chen", "Yukui Luo", "XiaoFeng Wang", "Chenghong Wang"], "title": "BOLT: Bandwidth-Optimized Lightning-Fast Oblivious Map powered by Secure HBM Accelerators", "comment": "Accepted by CCS 2025", "summary": "While Trusted Execution Environments provide a strong foundation for secure\ncloud computing, they remain vulnerable to access pattern leakages. Oblivious\nMaps (OMAPs) mitigate this by fully hiding access patterns but suffer from high\noverhead due to randomized remapping and worst-case padding. We argue these\ncosts are not fundamental. Modern accelerators featuring High-Bandwidth Memory\n(HBM) offer a new opportunity: Vaswani et al. [OSDI'18] point out that\neavesdropping on HBM is difficult -- even for physical attackers -- as its\nmemory channels are sealed together with processor cores inside the same\nphysical package. Later, Hunt et al. [NSDI'20] show that, with proper\nisolation, HBM can be turned into an unobservable region where both data and\nmemory traces are hidden. This motivates a rethink of OMAP design with\nHBM-backed solutions to finally overcome their traditional performance limits.\nBuilding on these insights, we present BOLT, a Bandwidth Optimized,\nLightning-fast OMAP accelerator that, for the first time, achieves O(1) +\nO((log log N)^2) bandwidth overhead. BOLT introduces three key innovations: (i)\na new OMAP algorithm that leverages isolated HBM as an unobservable cache to\naccelerate oblivious access to large host memory; (ii) a self-hosted\narchitecture that offloads execution and memory control from the host to\nmitigate CPU-side leakage; and (iii) tailored algorithm-architecture co-designs\nthat maximize resource efficiency. We implement a prototype BOLT on a Xilinx\nU55C FPGA. Evaluations show that BOLT achieves up to 279x and 480x speedups in\ninitialization and query time, respectively, over state-of-the-art OMAPs,\nincluding an industry implementation from Facebook.", "AI": {"tldr": "BOLT\u662f\u4e00\u4e2a\u57fa\u4e8eHBM\u7684OMAP\u52a0\u901f\u5668\uff0c\u901a\u8fc7\u5229\u7528\u9694\u79bbHBM\u4f5c\u4e3a\u4e0d\u53ef\u89c2\u6d4b\u7f13\u5b58\uff0c\u5b9e\u73b0\u4e86O(1) + O((log log N)^2)\u7684\u5e26\u5bbd\u5f00\u9500\uff0c\u76f8\u6bd4\u73b0\u6709OMAP\u65b9\u6848\u83b7\u5f97\u9ad8\u8fbe279-480\u500d\u7684\u6027\u80fd\u63d0\u5347", "motivation": "\u4f20\u7edf\u53ef\u4fe1\u6267\u884c\u73af\u5883\u5b58\u5728\u8bbf\u95ee\u6a21\u5f0f\u6cc4\u9732\u6f0f\u6d1e\uff0c\u73b0\u6709OMAP\u65b9\u6848\u901a\u8fc7\u968f\u673a\u91cd\u6620\u5c04\u548c\u6700\u574f\u60c5\u51b5\u586b\u5145\u6765\u9690\u85cf\u8bbf\u95ee\u6a21\u5f0f\uff0c\u4f46\u5e26\u6765\u9ad8\u6602\u5f00\u9500\u3002\u73b0\u4ee3\u52a0\u901f\u5668\u7684HBM\u7279\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u673a\u4f1a\uff0c\u53ef\u4ee5\u5c06HBM\u8f6c\u53d8\u4e3a\u4e0d\u53ef\u89c2\u6d4b\u533a\u57df\u6765\u9690\u85cf\u6570\u636e\u548c\u5185\u5b58\u75d5\u8ff9", "method": "\u63d0\u51faBOLT\u7cfb\u7edf\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u521b\u65b0\uff1a1\uff09\u65b0OMAP\u7b97\u6cd5\u5229\u7528\u9694\u79bbHBM\u4f5c\u4e3a\u4e0d\u53ef\u89c2\u6d4b\u7f13\u5b58\u52a0\u901f\u5bf9\u4e3b\u5185\u5b58\u7684\u832b\u7136\u8bbf\u95ee\uff1b2\uff09\u81ea\u6258\u7ba1\u67b6\u6784\u5c06\u6267\u884c\u548c\u5185\u5b58\u63a7\u5236\u4ece\u4e3b\u673a\u5378\u8f7d\u4ee5\u51cf\u8f7bCPU\u7aef\u6cc4\u9732\uff1b3\uff09\u7b97\u6cd5-\u67b6\u6784\u534f\u540c\u8bbe\u8ba1\u6700\u5927\u5316\u8d44\u6e90\u6548\u7387", "result": "\u5728Xilinx U55C FPGA\u4e0a\u5b9e\u73b0\u539f\u578b\uff0c\u8bc4\u4f30\u663e\u793aBOLT\u5728\u521d\u59cb\u5316\u548c\u67e5\u8be2\u65f6\u95f4\u4e0a\u5206\u522b\u6bd4\u6700\u5148\u8fdb\u7684OMAP\uff08\u5305\u62ecFacebook\u7684\u5de5\u4e1a\u5b9e\u73b0\uff09\u5feb279\u500d\u548c480\u500d", "conclusion": "BOLT\u9996\u6b21\u5b9e\u73b0\u4e86\u8fd1\u4e4e\u6700\u4f18\u7684\u5e26\u5bbd\u5f00\u9500\uff0c\u901a\u8fc7HBM\u652f\u6301\u7684\u89e3\u51b3\u65b9\u6848\u514b\u670d\u4e86\u4f20\u7edfOMAP\u7684\u6027\u80fd\u9650\u5236\uff0c\u4e3a\u5b89\u5168\u4e91\u8ba1\u7b97\u63d0\u4f9b\u4e86\u9ad8\u6027\u80fd\u7684\u8bbf\u95ee\u6a21\u5f0f\u4fdd\u62a4\u65b9\u6848"}}
{"id": "2509.01182", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.IR", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.01182", "abs": "https://arxiv.org/abs/2509.01182", "authors": ["Wonduk Seo", "Taesub Shin", "Hyunjin An", "Dokyun Kim", "Seunghyun Lee"], "title": "Question-to-Knowledge: Multi-Agent Generation of Inspectable Facts for Product Mapping", "comment": "Preprint", "summary": "Identifying whether two product listings refer to the same Stock Keeping Unit\n(SKU) is a persistent challenge in ecommerce, especially when explicit\nidentifiers are missing and product names vary widely across platforms. Rule\nbased heuristics and keyword similarity often misclassify products by\noverlooking subtle distinctions in brand, specification, or bundle\nconfiguration. To overcome these limitations, we propose Question to Knowledge\n(Q2K), a multi agent framework that leverages Large Language Models (LLMs) for\nreliable SKU mapping. Q2K integrates: (1) a Reasoning Agent that generates\ntargeted disambiguation questions, (2) a Knowledge Agent that resolves them via\nfocused web searches, and (3) a Deduplication Agent that reuses validated\nreasoning traces to reduce redundancy and ensure consistency. A human in the\nloop mechanism further refines uncertain cases. Experiments on real world\nconsumer goods datasets show that Q2K surpasses strong baselines, achieving\nhigher accuracy and robustness in difficult scenarios such as bundle\nidentification and brand origin disambiguation. By reusing retrieved reasoning\ninstead of issuing repeated searches, Q2K balances accuracy with efficiency,\noffering a scalable and interpretable solution for product integration.", "AI": {"tldr": "Q2K\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\u7684SKU\u6620\u5c04\u7cfb\u7edf\uff0c\u901a\u8fc7\u63a8\u7406\u3001\u77e5\u8bc6\u68c0\u7d22\u548c\u53bb\u91cd\u4e09\u4e2a\u667a\u80fd\u4f53\u534f\u4f5c\uff0c\u89e3\u51b3\u7535\u5546\u5e73\u53f0\u4ea7\u54c1\u91cd\u590d\u8bc6\u522b\u95ee\u9898\uff0c\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u7535\u5546\u5e73\u53f0\u4e2d\u4ea7\u54c1SKU\u8bc6\u522b\u9762\u4e34\u6311\u6218\uff0c\u5f53\u7f3a\u4e4f\u660e\u786e\u6807\u8bc6\u7b26\u4e14\u4ea7\u54c1\u540d\u79f0\u5728\u4e0d\u540c\u5e73\u53f0\u5dee\u5f02\u5f88\u5927\u65f6\uff0c\u57fa\u4e8e\u89c4\u5219\u548c\u5173\u952e\u8bcd\u76f8\u4f3c\u6027\u7684\u65b9\u6cd5\u5bb9\u6613\u56e0\u5ffd\u7565\u54c1\u724c\u3001\u89c4\u683c\u6216\u5957\u88c5\u914d\u7f6e\u7684\u7ec6\u5fae\u5dee\u522b\u800c\u9519\u8bef\u5206\u7c7b\u3002", "method": "\u63d0\u51faQ2K\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff1a1)\u63a8\u7406\u667a\u80fd\u4f53\u751f\u6210\u9488\u5bf9\u6027\u6d88\u6b67\u95ee\u9898\uff1b2)\u77e5\u8bc6\u667a\u80fd\u4f53\u901a\u8fc7\u805a\u7126\u7f51\u7edc\u641c\u7d22\u89e3\u51b3\u95ee\u9898\uff1b3)\u53bb\u91cd\u667a\u80fd\u4f53\u91cd\u7528\u5df2\u9a8c\u8bc1\u7684\u63a8\u7406\u8f68\u8ff9\u51cf\u5c11\u5197\u4f59\u3002\u7ed3\u5408\u4eba\u5de5\u5e72\u9884\u673a\u5236\u4f18\u5316\u4e0d\u786e\u5b9a\u6848\u4f8b\u3002", "result": "\u5728\u771f\u5b9e\u6d88\u8d39\u54c1\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cQ2K\u8d85\u8d8a\u4e86\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u5957\u88c5\u8bc6\u522b\u548c\u54c1\u724c\u6765\u6e90\u6d88\u6b67\u7b49\u56f0\u96be\u573a\u666f\u4e2d\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u901a\u8fc7\u91cd\u7528\u68c0\u7d22\u5230\u7684\u63a8\u7406\u800c\u975e\u91cd\u590d\u641c\u7d22\uff0cQ2K\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u4e86\u5e73\u8861\uff0c\u4e3a\u4ea7\u54c1\u96c6\u6210\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.01791", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.01791", "abs": "https://arxiv.org/abs/2509.01791", "authors": ["Luca Pajola", "Eugenio Caripoti", "Simeone Pizzi", "Mauro Conti", "Stefan Banzer", "Giovanni Apruzzese"], "title": "E-PhishGen: Unlocking Novel Research in Phishing Email Detection", "comment": "Accepted to ACM AISec '26", "summary": "Every day, our inboxes are flooded with unsolicited emails, ranging between\nannoying spam to more subtle phishing scams. Unfortunately, despite abundant\nprior efforts proposing solutions achieving near-perfect accuracy, the reality\nis that countering malicious emails still remains an unsolved dilemma.\n  This \"open problem\" paper carries out a critical assessment of scientific\nworks in the context of phishing email detection. First, we focus on the\nbenchmark datasets that have been used to assess the methods proposed in\nresearch. We find that most prior work relied on datasets containing emails\nthat -- we argue -- are not representative of current trends, and mostly\nencompass the English language. Based on this finding, we then re-implement and\nre-assess a variety of detection methods reliant on machine learning (ML),\nincluding large-language models (LLM), and release all of our codebase -- an\n(unfortunately) uncommon practice in related research. We show that most such\nmethods achieve near-perfect performance when trained and tested on the same\ndataset -- a result which intrinsically hinders development (how can future\nresearch outperform methods that are already near perfect?). To foster the\ncreation of \"more challenging benchmarks\" that reflect current phishing trends,\nwe propose E-PhishGEN, an LLM-based (and privacy-savvy) framework to generate\nnovel phishing-email datasets. We use our E-PhishGEN to create E-PhishLLM, a\nnovel phishing-email detection dataset containing 16616 emails in three\nlanguages. We use E-PhishLLM to test the detectors we considered, showing a\nmuch lower performance than that achieved on existing benchmarks -- indicating\na larger room for improvement. We also validate the quality of E-PhishLLM with\na user study (n=30). To sum up, we show that phishing email detection is still\nan open problem -- and provide the means to tackle such a problem by future\nresearch.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5bf9\u6d17\u94b1\u90ae\u4ef6\u68c0\u6d4b\u9886\u57df\u8fdb\u884c\u4e86\u6279\u5224\u6027\u8bc4\u4f30\uff0c\u53d1\u73b0\u73b0\u6709\u65b9\u6cd5\u5728\u4e0d\u5177\u4ee3\u8868\u6027\u7684\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u8fd1\u4f18\u6027\u80fd\uff0c\u4f46\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u8868\u73b0\u5dee\u5f02\u3002\u7814\u7a76\u8005\u63d0\u51fa\u4e86E-PhishGEN\u6846\u67b6\u548cE-PhishLLM\u6570\u636e\u96c6\uff0c\u4ee5\u4fc3\u8fdb\u66f4\u5177\u6311\u6218\u6027\u7684\u6d4b\u8bd5\u6807\u51c6\u3002", "motivation": "\u867d\u7136\u73b0\u6709\u6d17\u94b1\u90ae\u4ef6\u68c0\u6d4b\u65b9\u6cd5\u5728\u5b66\u672f\u7814\u7a76\u4e2d\u62a5\u544a\u4e86\u8fd1\u4f18\u6027\u80fd\uff0c\u4f46\u5b9e\u9645\u95ee\u9898\u4ecd\u672a\u89e3\u51b3\u3002\u7814\u7a76\u8005\u8ba4\u4e3a\u73b0\u6709\u6570\u636e\u96c6\u4e0d\u4ee3\u8868\u5f53\u524d\u8d8b\u52bf\u4e14\u4ee5\u82f1\u8bed\u4e3a\u4e3b\uff0c\u5bfc\u81f4\u65b9\u6cd5\u8bc4\u4f30\u4e0d\u51c6\u786e\u3002", "method": "\u91cd\u65b0\u5b9e\u73b0\u548c\u8bc4\u4f30\u591a\u79cd\u673a\u5668\u5b66\u4e60\u68c0\u6d4b\u65b9\u6cd5\uff08\u5305\u62ec\u5927\u8bed\u8a00\u6a21\u578b\uff09\uff0c\u63d0\u51faE-PhishGEN\u6846\u67b6\u7528\u4e8e\u751f\u6210\u65b0\u7684\u6d17\u94b1\u90ae\u4ef6\u6570\u636e\u96c6\uff0c\u5e76\u521b\u5efa\u4e86\u5305\u542b\u4e09\u79cd\u8bed\u8a00\u7684E-PhishLLM\u6570\u636e\u96c6\u3002\u8fdb\u884c\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\u6570\u636e\u8d28\u91cf\u3002", "result": "\u5728\u73b0\u6709\u6570\u636e\u96c6\u4e0a\u68c0\u6d4b\u65b9\u6cd5\u8fbe\u5230\u8fd1\u4f18\u6027\u80fd\uff0c\u4f46\u5728\u65b0\u7684E-PhishLLM\u6570\u636e\u96c6\u4e0a\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u8bf4\u660e\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u663e\u8457\u7f3a\u9677\u3002\u7528\u6237\u7814\u7a76\u8bc1\u5b9e\u4e86\u65b0\u6570\u636e\u96c6\u7684\u8d28\u91cf\u3002", "conclusion": "\u6d17\u94b1\u90ae\u4ef6\u68c0\u6d4b\u4ecd\u662f\u4e2a\u5f00\u653e\u6027\u95ee\u9898\uff0c\u9700\u8981\u66f4\u5177\u6311\u6218\u6027\u7684\u6d4b\u8bd5\u6807\u51c6\u3002\u8bba\u6587\u63d0\u4f9b\u7684E-PhishGEN\u6846\u67b6\u548cE-PhishLLM\u6570\u636e\u96c6\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.01238", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.01238", "abs": "https://arxiv.org/abs/2509.01238", "authors": ["Jiasheng Xu", "Mingda Li", "Yongqiang Tang", "Peijie Wang", "Wensheng Zhang"], "title": "Towards Open-World Retrieval-Augmented Generation on Knowledge Graph: A Multi-Agent Collaboration Framework", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated strong capabilities in\nlanguage understanding and reasoning. However, their dependence on static\ntraining corpora makes them prone to factual errors and knowledge gaps.\nRetrieval-Augmented Generation (RAG) addresses this limitation by incorporating\nexternal knowledge sources, especially structured Knowledge Graphs (KGs), which\nprovide explicit semantics and efficient retrieval. Existing KG-based RAG\napproaches, however, generally assume that anchor entities are accessible to\ninitiate graph traversal, which limits their robustness in open world settings\nwhere accurate linking between the query and the entity is unreliable. To\novercome this limitation, we propose AnchorRAG, a novel multi-agent\ncollaboration framework for open-world RAG without the predefined anchor\nentities. Specifically, a predictor agent dynamically identifies candidate\nanchor entities by aligning user query terms with KG nodes and initializes\nindependent retriever agents to conduct parallel multi-hop explorations from\neach candidate. Then a supervisor agent formulates the iterative retrieval\nstrategy for these retriever agents and synthesizes the resulting knowledge\npaths to generate the final answer. This multi-agent collaboration framework\nimproves retrieval robustness and mitigates the impact of ambiguous or\nerroneous anchors. Extensive experiments on four public benchmarks demonstrate\nthat AnchorRAG significantly outperforms existing baselines and establishes new\nstate-of-the-art results on the real-world question answering tasks.", "AI": {"tldr": "AnchorRAG\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8bc6\u522b\u5019\u9009\u951a\u70b9\u5b9e\u4f53\u548c\u5e76\u884c\u591a\u8df3\u63a2\u7d22\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684RAG\u65b9\u6cd5\u5728\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e2d\u4f9d\u8d56\u9884\u5b9a\u4e49\u951a\u70b9\u5b9e\u4f53\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f9d\u8d56\u9759\u6001\u8bad\u7ec3\u8bed\u6599\u5e93\uff0c\u5bb9\u6613\u4ea7\u751f\u4e8b\u5b9e\u9519\u8bef\u548c\u77e5\u8bc6\u7f3a\u53e3\u3002\u867d\u7136\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u901a\u8fc7\u6574\u5408\u5916\u90e8\u77e5\u8bc6\u6e90\uff08\u7279\u522b\u662f\u7ed3\u6784\u5316\u77e5\u8bc6\u56fe\u8c31\uff09\u6765\u5f25\u8865\u8fd9\u4e00\u7f3a\u9677\uff0c\u4f46\u73b0\u6709\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684RAG\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u951a\u70b9\u5b9e\u4f53\u53ef\u8bbf\u95ee\u6765\u542f\u52a8\u56fe\u904d\u5386\uff0c\u8fd9\u5728\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e2d\u951a\u70b9\u94fe\u63a5\u4e0d\u53ef\u9760\u65f6\u9650\u5236\u4e86\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51faAnchorRAG\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\uff1a1\uff09\u9884\u6d4b\u5668\u667a\u80fd\u4f53\u52a8\u6001\u8bc6\u522b\u5019\u9009\u951a\u70b9\u5b9e\u4f53\uff1b2\uff09\u72ec\u7acb\u7684\u68c0\u7d22\u5668\u667a\u80fd\u4f53\u4ece\u6bcf\u4e2a\u5019\u9009\u5b9e\u4f53\u5e76\u884c\u8fdb\u884c\u591a\u8df3\u63a2\u7d22\uff1b3\uff09\u76d1\u7763\u5668\u667a\u80fd\u4f53\u5236\u5b9a\u8fed\u4ee3\u68c0\u7d22\u7b56\u7565\u5e76\u5408\u6210\u77e5\u8bc6\u8def\u5f84\u751f\u6210\u6700\u7ec8\u7b54\u6848\u3002", "result": "\u5728\u56db\u4e2a\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cAnchorRAG\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u73b0\u5b9e\u4e16\u754c\u95ee\u7b54\u4efb\u52a1\u4e0a\u5efa\u7acb\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u7ed3\u679c\u3002", "conclusion": "AnchorRAG\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6709\u6548\u63d0\u9ad8\u4e86\u68c0\u7d22\u9c81\u68d2\u6027\uff0c\u51cf\u8f7b\u4e86\u6a21\u7cca\u6216\u9519\u8bef\u951a\u70b9\u7684\u5f71\u54cd\uff0c\u4e3a\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e0b\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.01835", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.01835", "abs": "https://arxiv.org/abs/2509.01835", "authors": ["Saad Ullah", "Praneeth Balasubramanian", "Wenbo Guo", "Amanda Burnett", "Hammond Pearce", "Christopher Kruegel", "Giovanni Vigna", "Gianluca Stringhini"], "title": "From CVE Entries to Verifiable Exploits: An Automated Multi-Agent Framework for Reproducing CVEs", "comment": null, "summary": "High-quality datasets of real-world vulnerabilities and their corresponding\nverifiable exploits are crucial resources in software security research. Yet\nsuch resources remain scarce, as their creation demands intensive manual effort\nand deep security expertise. In this paper, we present CVE-GENIE, an automated,\nlarge language model (LLM)-based multi-agent framework designed to reproduce\nreal-world vulnerabilities, provided in Common Vulnerabilities and Exposures\n(CVE) format, to enable creation of high-quality vulnerability datasets. Given\na CVE entry as input, CVE-GENIE gathers the relevant resources of the CVE,\nautomatically reconstructs the vulnerable environment, and (re)produces a\nverifiable exploit. Our systematic evaluation highlights the efficiency and\nrobustness of CVE-GENIE's design and successfully reproduces approximately 51%\n(428 of 841) CVEs published in 2024-2025, complete with their verifiable\nexploits, at an average cost of $2.77 per CVE. Our pipeline offers a robust\nmethod to generate reproducible CVE benchmarks, valuable for diverse\napplications such as fuzzer evaluation, vulnerability patching, and assessing\nAI's security capabilities.", "AI": {"tldr": "CVE-GENIE\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u80fd\u591f\u81ea\u52a8\u5316\u590d\u73b0CVE\u6f0f\u6d1e\u5e76\u751f\u6210\u53ef\u9a8c\u8bc1\u7684\u6f0f\u6d1e\u5229\u7528\u7a0b\u5e8f\uff0c\u6210\u529f\u590d\u73b0\u4e8651%\u76842024-2025\u5e74CVE\u6f0f\u6d1e\uff0c\u5e73\u5747\u6bcf\u4e2aCVE\u6210\u672c2.77\u7f8e\u5143\u3002", "motivation": "\u9ad8\u8d28\u91cf\u7684\u6f0f\u6d1e\u6570\u636e\u96c6\u5bf9\u8f6f\u4ef6\u5b89\u5168\u7814\u7a76\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u521b\u5efa\u8fd9\u4e9b\u6570\u636e\u96c6\u9700\u8981\u5927\u91cf\u4eba\u5de5\u5de5\u4f5c\u548c\u6df1\u539a\u7684\u5b89\u5168\u4e13\u4e1a\u77e5\u8bc6\uff0c\u76ee\u524d\u8fd9\u7c7b\u8d44\u6e90\u4ecd\u7136\u7a00\u7f3a\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u8f93\u5165CVE\u6761\u76ee\u540e\u81ea\u52a8\u6536\u96c6\u76f8\u5173\u8d44\u6e90\u3001\u91cd\u5efa\u6f0f\u6d1e\u73af\u5883\uff0c\u5e76\u751f\u6210\u53ef\u9a8c\u8bc1\u7684\u6f0f\u6d1e\u5229\u7528\u7a0b\u5e8f\u3002", "result": "\u6210\u529f\u590d\u73b0\u4e86841\u4e2a2024-2025\u5e74CVE\u4e2d\u7684428\u4e2a\uff0851%\uff09\uff0c\u5e73\u5747\u6bcf\u4e2aCVE\u6210\u672c\u4e3a2.77\u7f8e\u5143\uff0c\u8bc1\u660e\u4e86\u6846\u67b6\u7684\u9ad8\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u751f\u6210\u53ef\u590d\u73b0\u7684CVE\u57fa\u51c6\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u5f3a\u5927\u65b9\u6cd5\uff0c\u53ef\u7528\u4e8e\u6a21\u7cca\u6d4b\u8bd5\u8bc4\u4f30\u3001\u6f0f\u6d1e\u4fee\u8865\u548cAI\u5b89\u5168\u80fd\u529b\u8bc4\u4f30\u7b49\u591a\u79cd\u5e94\u7528\u3002"}}
{"id": "2509.01245", "categories": ["cs.AI", "cs.MA", "cs.OS"], "pdf": "https://arxiv.org/pdf/2509.01245", "abs": "https://arxiv.org/abs/2509.01245", "authors": ["Yusheng Zheng", "Yanpeng Hu", "Wei Zhang", "Andi Quinn"], "title": "Towards Agentic OS: An LLM Agent Framework for Linux Schedulers", "comment": null, "summary": "Operating system schedulers suffer from a fundamental semantic gap, where\nkernel policies fail to understand application-specific needs, leading to\nsuboptimal performance. We introduce SchedCP, the first framework that enables\nfully autonomous Large Language Model (LLM) agents to safely and efficiently\noptimize Linux schedulers without human involvement. Our core insight is that\nthe challenge is not merely to apply a better LLM, but to architect a decoupled\ncontrol plane that separates the AI's role of semantic reasoning (\"what to\noptimize\") from the system's role of execution (\"how to observe and act\").\nImplemented as Model Context Protocol(MCP) server, SchedCP provides a stable\ninterface with three key services: a Workload Analysis Engine, an evolving\nScheduler Policy Repository, and an Execution Verifier that validates all\nAI-generated code and configure before deployment with static and dynamic\nanalysis.\n  We demonstrate this architecture's power with sched-agent, a multi-agent\nsystem that autonomously analyzes workloads, synthesizes custom eBPF scheduling\npolicies, and deploys them via the sched\\_ext infrastructure. Our evaluation\nshows that SchedCP achieves up to an 1.79x performance improvement, and a 13x\ncost reduction compared to naive agentic approaches, all while maintaining high\nsuccess rate. By bridging the semantic gap, SchedCP democratizes expert-level\nsystem optimization and represents a step towards creating truly\nself-optimizing, application-aware operating systems. The code is open-sourced\nin https://github.com/eunomia-bpf/schedcp", "AI": {"tldr": "SchedCP\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u81ea\u4e3bLinux\u8c03\u5ea6\u5668\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026AI\u8bed\u4e49\u63a8\u7406\u548c\u7cfb\u7edf\u6267\u884c\uff0c\u5b9e\u73b0\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u7684\u5b89\u5168\u9ad8\u6548\u8c03\u5ea6\u4f18\u5316\uff0c\u6027\u80fd\u63d0\u5347\u8fbe1.79\u500d\u3002", "motivation": "\u89e3\u51b3\u64cd\u4f5c\u7cfb\u7edf\u8c03\u5ea6\u5668\u5b58\u5728\u7684\u8bed\u4e49\u9e3f\u6c9f\u95ee\u9898\uff0c\u5373\u5185\u6838\u7b56\u7565\u65e0\u6cd5\u7406\u89e3\u5e94\u7528\u7279\u5b9a\u9700\u6c42\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\uff0c\u9700\u8981\u8ba9AI\u80fd\u591f\u81ea\u4e3b\u4f18\u5316\u8c03\u5ea6\u7b56\u7565\u3002", "method": "\u91c7\u7528Model Context Protocol\u670d\u52a1\u5668\u67b6\u6784\uff0c\u63d0\u4f9b\u5de5\u4f5c\u8d1f\u8f7d\u5206\u6790\u5f15\u64ce\u3001\u8c03\u5ea6\u7b56\u7565\u5e93\u548c\u6267\u884c\u9a8c\u8bc1\u5668\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5206\u6790\u5de5\u4f5c\u8d1f\u8f7d\u3001\u5408\u6210eBPF\u8c03\u5ea6\u7b56\u7565\u5e76\u5b89\u5168\u90e8\u7f72\u3002", "result": "\u5b9e\u73b0\u6700\u9ad81.79\u500d\u6027\u80fd\u63d0\u5347\u548c13\u500d\u6210\u672c\u964d\u4f4e\uff0c\u76f8\u6bd4\u6734\u7d20\u667a\u80fd\u4f53\u65b9\u6cd5\u4fdd\u6301\u9ad8\u6210\u529f\u7387\uff0c\u6210\u529f\u5f25\u5408\u8bed\u4e49\u9e3f\u6c9f\u3002", "conclusion": "SchedCP\u5b9e\u73b0\u4e86\u4e13\u5bb6\u7ea7\u7cfb\u7edf\u4f18\u5316\u7684\u6c11\u4e3b\u5316\uff0c\u4e3a\u521b\u5efa\u771f\u6b63\u81ea\u4f18\u5316\u3001\u5e94\u7528\u611f\u77e5\u7684\u64cd\u4f5c\u7cfb\u7edf\u8fc8\u51fa\u91cd\u8981\u4e00\u6b65\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2509.02004", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.02004", "abs": "https://arxiv.org/abs/2509.02004", "authors": ["Takao Murakami", "Yuichi Sei", "Reo Eriguchi"], "title": "Augmented Shuffle Differential Privacy Protocols for Large-Domain Categorical and Key-Value Data", "comment": "Full version of the paper accepted at NDSS 2026", "summary": "Shuffle DP (Differential Privacy) protocols provide high accuracy and privacy\nby introducing a shuffler who randomly shuffles data in a distributed system.\nHowever, most shuffle DP protocols are vulnerable to two attacks: collusion\nattacks by the data collector and users and data poisoning attacks. A recent\nstudy addresses this issue by introducing an augmented shuffle DP protocol,\nwhere users do not add noise and the shuffler performs random sampling and\ndummy data addition. However, it focuses on frequency estimation over\ncategorical data with a small domain and cannot be applied to a large domain\ndue to prohibitively high communication and computational costs.\n  In this paper, we fill this gap by introducing a novel augmented shuffle DP\nprotocol called the FME (Filtering-with-Multiple-Encryption) protocol. Our FME\nprotocol uses a hash function to filter out unpopular items and then accurately\ncalculates frequencies for popular items. To perform this within one round of\ninteraction between users and the shuffler, our protocol carefully communicates\nwithin a system using multiple encryption. We also apply our FME protocol to\nmore advanced KV (Key-Value) statistics estimation with an additional technique\nto reduce bias. For both categorical and KV data, we prove that our protocol\nprovides computational DP, high robustness to the above two attacks, accuracy,\nand efficiency. We show the effectiveness of our proposals through comparisons\nwith twelve existing protocols.", "AI": {"tldr": "\u63d0\u51fa\u4e86FME\u534f\u8bae\uff0c\u4e00\u79cd\u589e\u5f3a\u7684shuffle DP\u534f\u8bae\uff0c\u4f7f\u7528\u54c8\u5e0c\u8fc7\u6ee4\u548c\u591a\u91cd\u52a0\u5bc6\u6280\u672f\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u9ad8\u6548\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u57df\u548cKV\u7edf\u8ba1\u4f30\u8ba1\u3002", "motivation": "\u73b0\u6709\u7684shuffle DP\u534f\u8bae\u5bb9\u6613\u53d7\u5230\u5408\u8c0b\u653b\u51fb\u548c\u6570\u636e\u6295\u6bd2\u653b\u51fb\uff0c\u4e14\u65e0\u6cd5\u6709\u6548\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u57df\uff0c\u901a\u4fe1\u548c\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\u3002", "method": "\u4f7f\u7528\u54c8\u5e0c\u51fd\u6570\u8fc7\u6ee4\u975e\u70ed\u95e8\u9879\u76ee\uff0c\u901a\u8fc7\u591a\u91cd\u52a0\u5bc6\u6280\u672f\u5b9e\u73b0\u7528\u6237\u4e0e\u6df7\u6d17\u5668\u4e4b\u95f4\u7684\u5355\u8f6e\u4ea4\u4e92\uff0c\u51c6\u786e\u8ba1\u7b97\u70ed\u95e8\u9879\u76ee\u7684\u9891\u7387\uff0c\u5e76\u6269\u5c55\u5230KV\u7edf\u8ba1\u4f30\u8ba1\u3002", "result": "FME\u534f\u8bae\u63d0\u4f9b\u8ba1\u7b97\u5dee\u5206\u9690\u79c1\u3001\u5bf9\u653b\u51fb\u7684\u9ad8\u9c81\u68d2\u6027\u3001\u9ad8\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u572812\u4e2a\u73b0\u6709\u534f\u8bae\u7684\u6bd4\u8f83\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "FME\u534f\u8bae\u6210\u529f\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u6570\u636e\u57df\u4e0b\u7684\u9690\u79c1\u4fdd\u62a4\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u9ad8\u9690\u79c1\u4fdd\u62a4\u6c34\u5e73\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u901a\u4fe1\u548c\u8ba1\u7b97\u6027\u80fd\u3002"}}
{"id": "2509.01277", "categories": ["cs.AI", "68T50, 68T42", "I.2.6; I.2.7"], "pdf": "https://arxiv.org/pdf/2509.01277", "abs": "https://arxiv.org/abs/2509.01277", "authors": ["Jingxing Fan", "Jinrong Shen", "Yusheng Yao", "Shuangqing Wang", "Qian Wang", "Yuling Wang"], "title": "Communicative Agents for Slideshow Storytelling Video Generation based on LLMs", "comment": "8 pages, 8 figures, 1 table", "summary": "With the rapid advancement of artificial intelligence (AI), the proliferation\nof AI-generated content (AIGC) tasks has significantly accelerated developments\nin text-to-video generation. As a result, the field of video production is\nundergoing a transformative shift. However, conventional text-to-video models\nare typically constrained by high computational costs.\n  In this study, we propose Video-Generation-Team (VGTeam), a novel slide show\nvideo generation system designed to redefine the video creation pipeline\nthrough the integration of large language models (LLMs). VGTeam is composed of\na suite of communicative agents, each responsible for a distinct aspect of\nvideo generation, such as scriptwriting, scene creation, and audio design.\nThese agents operate collaboratively within a chat tower workflow, transforming\nuser-provided textual prompts into coherent, slide-style narrative videos.\n  By emulating the sequential stages of traditional video production, VGTeam\nachieves remarkable improvements in both efficiency and scalability, while\nsubstantially reducing computational overhead. On average, the system generates\nvideos at a cost of only $0.103, with a successful generation rate of 98.4%.\nImportantly, this framework maintains a high degree of creative fidelity and\ncustomization.\n  The implications of VGTeam are far-reaching. It democratizes video production\nby enabling broader access to high-quality content creation without the need\nfor extensive resources. Furthermore, it highlights the transformative\npotential of language models in creative domains and positions VGTeam as a\npioneering system for next-generation content creation.", "AI": {"tldr": "VGTeam\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u706f\u7247\u89c6\u9891\u751f\u6210\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u5c06\u6587\u672c\u63d0\u793a\u8f6c\u6362\u4e3a\u8fde\u8d2f\u7684\u53d9\u4e8b\u89c6\u9891\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u548c\u63d0\u9ad8\u4e86\u751f\u6210\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u6587\u672c\u5230\u89c6\u9891\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u9650\u5236\u4e86\u89c6\u9891\u5236\u4f5c\u7684\u666e\u53ca\u3002\u7814\u7a76\u65e8\u5728\u901a\u8fc7LLM\u96c6\u6210\u91cd\u65b0\u5b9a\u4e49\u89c6\u9891\u521b\u4f5c\u6d41\u7a0b\uff0c\u964d\u4f4e\u5236\u4f5c\u95e8\u69db\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u67b6\u6784\uff0c\u5305\u62ec\u811a\u672c\u7f16\u5199\u3001\u573a\u666f\u521b\u5efa\u548c\u97f3\u9891\u8bbe\u8ba1\u7b49\u4e13\u95e8\u4ee3\u7406\uff0c\u5728\u804a\u5929\u5854\u5de5\u4f5c\u6d41\u4e2d\u534f\u540c\u5de5\u4f5c\uff0c\u6a21\u62df\u4f20\u7edf\u89c6\u9891\u5236\u4f5c\u6d41\u7a0b\u3002", "result": "\u7cfb\u7edf\u5e73\u5747\u751f\u6210\u6210\u672c\u4ec50.103\u7f8e\u5143\uff0c\u6210\u529f\u751f\u6210\u7387\u8fbe98.4%\uff0c\u5728\u4fdd\u6301\u521b\u610f\u4fdd\u771f\u5ea6\u548c\u5b9a\u5236\u6027\u7684\u540c\u65f6\u5927\u5e45\u63d0\u5347\u4e86\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "VGTeam democratizes\u89c6\u9891\u5236\u4f5c\uff0c\u5c55\u793a\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u521b\u610f\u9886\u57df\u7684\u53d8\u9769\u6f5c\u529b\uff0c\u662f\u4e0b\u4e00\u4ee3\u5185\u5bb9\u521b\u4f5c\u7684\u5148\u9a71\u7cfb\u7edf\u3002"}}
{"id": "2509.02042", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.02042", "abs": "https://arxiv.org/abs/2509.02042", "authors": ["Pascal Zimmer", "Simon Lachnit", "Alexander Jan Zielinski", "Ghassan Karame"], "title": "Targeted Physical Evasion Attacks in the Near-Infrared Domain", "comment": "To appear in the Proceedings of the Network and Distributed Systems\n  Security Symposium (NDSS) 2026", "summary": "A number of attacks rely on infrared light sources or heat-absorbing material\nto imperceptibly fool systems into misinterpreting visual input in various\nimage recognition applications. However, almost all existing approaches can\nonly mount untargeted attacks and require heavy optimizations due to the\nuse-case-specific constraints, such as location and shape. In this paper, we\npropose a novel, stealthy, and cost-effective attack to generate both targeted\nand untargeted adversarial infrared perturbations. By projecting perturbations\nfrom a transparent film onto the target object with an off-the-shelf infrared\nflashlight, our approach is the first to reliably mount laser-free targeted\nattacks in the infrared domain. Extensive experiments on traffic signs in the\ndigital and physical domains show that our approach is robust and yields higher\nattack success rates in various attack scenarios across bright lighting\nconditions, distances, and angles compared to prior work. Equally important,\nour attack is highly cost-effective, requiring less than US\\$50 and a few tens\nof seconds for deployment. Finally, we propose a novel segmentation-based\ndetection that thwarts our attack with an F1-score of up to 99%.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u3001\u9690\u853d\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u7ea2\u5916\u5bf9\u6297\u6270\u52a8\u653b\u51fb\u65b9\u6cd5\uff0c\u4f7f\u7528\u900f\u660e\u8584\u819c\u548c\u73b0\u6210\u7ea2\u5916\u624b\u7535\u7b52\u6295\u5c04\u6270\u52a8\uff0c\u9996\u6b21\u5b9e\u73b0\u65e0\u6fc0\u5149\u7684\u5b9a\u5411\u7ea2\u5916\u653b\u51fb\uff0c\u653b\u51fb\u6210\u529f\u7387\u66f4\u9ad8\u4e14\u90e8\u7f72\u6210\u672c\u4f4e\u4e8e50\u7f8e\u5143\u3002", "motivation": "\u73b0\u6709\u7ea2\u5916\u653b\u51fb\u65b9\u6cd5\u5927\u591a\u53ea\u80fd\u8fdb\u884c\u975e\u5b9a\u5411\u653b\u51fb\uff0c\u4e14\u9700\u8981\u5927\u91cf\u4f18\u5316\u6765\u9002\u5e94\u7279\u5b9a\u4f7f\u7528\u573a\u666f\u7ea6\u675f\uff08\u5982\u4f4d\u7f6e\u548c\u5f62\u72b6\uff09\uff0c\u9650\u5236\u4e86\u653b\u51fb\u7684\u5b9e\u7528\u6027\u548c\u6548\u679c\u3002", "method": "\u901a\u8fc7\u4ece\u900f\u660e\u8584\u819c\u6295\u5c04\u6270\u52a8\u5230\u76ee\u6807\u7269\u4f53\u4e0a\uff0c\u4f7f\u7528\u73b0\u6210\u7684\u7ea2\u5916\u624b\u7535\u7b52\uff0c\u751f\u6210\u5b9a\u5411\u548c\u975e\u5b9a\u5411\u7684\u7ea2\u5916\u5bf9\u6297\u6270\u52a8\uff0c\u5b9e\u73b0\u65e0\u6fc0\u5149\u7684\u53ef\u9760\u653b\u51fb\u3002", "result": "\u5728\u6570\u5b57\u548c\u7269\u7406\u9886\u57df\u7684\u4ea4\u901a\u6807\u5fd7\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u653b\u51fb\u573a\u666f\uff08\u5305\u62ec\u660e\u4eae\u5149\u7167\u6761\u4ef6\u3001\u8ddd\u79bb\u548c\u89d2\u5ea6\uff09\u4e0b\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u653b\u51fb\u6210\u529f\u7387\u548c\u9c81\u68d2\u6027\uff0c\u90e8\u7f72\u6210\u672c\u4f4e\u4e8e50\u7f8e\u5143\u4e14\u4ec5\u9700\u6570\u5341\u79d2\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9996\u6b21\u5b9e\u73b0\u4e86\u53ef\u9760\u7684\u65e0\u6fc0\u5149\u5b9a\u5411\u7ea2\u5916\u653b\u51fb\uff0c\u5177\u6709\u9ad8\u6210\u672c\u6548\u76ca\u548c\u5b9e\u7528\u6027\uff0c\u540c\u65f6\u63d0\u51fa\u4e86\u57fa\u4e8e\u5206\u5272\u7684\u65b0\u578b\u68c0\u6d4b\u65b9\u6cd5\uff0cF1\u5206\u6570\u9ad8\u8fbe99%\uff0c\u53ef\u6709\u6548\u9632\u5fa1\u6b64\u7c7b\u653b\u51fb\u3002"}}
{"id": "2509.01308", "categories": ["cs.AI", "cs.CL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2509.01308", "abs": "https://arxiv.org/abs/2509.01308", "authors": ["Mattia Tritto", "Giuseppe Farano", "Dario Di Palma", "Gaetano Rossiello", "Fedelucio Narducci", "Dharmashankar Subramanian", "Tommaso Di Noia"], "title": "GradeSQL: Outcome Reward Models for Ranking SQL Queries from Large Language Models", "comment": null, "summary": "Text-to-SQL, the task of translating natural language questions into SQL\nqueries, has significantly advanced with the introduction of Large Language\nModels (LLMs), broadening database accessibility for a wide range of users.\nDespite substantial progress in generating valid SQL, current LLMs still\nstruggle with complex queries that require precise alignment between user\nintent and the database schema. To mitigate this, test-time strategies such as\nBest-of-N (BoN) and Majority Voting (Maj) are often employed, based on the\nassumption that LLMs can generate correct answers but may require multiple\nattempts. However, these methods rely on surface-level heuristics, selecting\neither the syntactically correct query through execution-based BoN (ex-BoN) or\nthe most frequently generated query with Maj. Recently, Outcome Reward Models\n(ORMs), which assign utility scores to generated outputs based on semantic\ncorrectness, have emerged as a promising approach for better aligning model\npredictions with user intent. Nevertheless, their application to Text-to-SQL\nremains largely underexplored.\n  In this work, we evaluate ORMs as an effective heuristic for BoN, compare\nthem with ex-BoN and Maj, and introduce a framework for training ORMs for the\nText-to-SQL task. We evaluate our ORMs on the BIRD and SPIDER benchmarks,\nfinetuning various open-source LLMs, including the Qwen2, Granite3, and Llama3\nmodel families. Our results show that ORMs outperform ex-BoN and Maj, achieving\nexecution accuracy gains of +4.33% (BIRD) and +2.10% (Spider) over ex-BoN, and\n+2.91% (BIRD) and +0.93% (Spider) over Maj. We further demonstrate that\nfinetuning models already aligned with SQL generation, such as OmniSQL, yields\nsuperior ORM performance. Additionally, we observe that ORMs achieve\ncompetitive results on simple queries and benefit more from an increased number\nof candidates compared to ex-BoN and Maj.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u7ed3\u679c\u5956\u52b1\u6a21\u578b(ORMs)\u5728Text-to-SQL\u4efb\u52a1\u4e2d\u7684\u6548\u679c\uff0c\u76f8\u6bd4\u4f20\u7edf\u7684Best-of-N\u548cMajority Voting\u65b9\u6cd5\uff0cORMs\u5728BIRD\u548cSpider\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u7684\u51c6\u786e\u7387\u63d0\u5347\u3002", "motivation": "\u5f53\u524dLLMs\u5728\u751f\u6210\u590d\u6742SQL\u67e5\u8be2\u65f6\u4ecd\u96be\u4ee5\u7cbe\u786e\u5bf9\u9f50\u7528\u6237\u610f\u56fe\u548c\u6570\u636e\u5e93\u6a21\u5f0f\uff0c\u73b0\u6709\u7684\u6d4b\u8bd5\u65f6\u7b56\u7565\u5982Best-of-N\u548cMajority Voting\u4f9d\u8d56\u8868\u9762\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u8bed\u4e49\u5bf9\u9f50\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u8bad\u7ec3Text-to-SQL\u4efb\u52a1\u4e13\u7528ORMs\u7684\u6846\u67b6\uff0c\u57fa\u4e8e\u8bed\u4e49\u6b63\u786e\u6027\u4e3a\u751f\u6210\u8f93\u51fa\u5206\u914d\u6548\u7528\u5206\u6570\uff0c\u5e76\u5728Qwen2\u3001Granite3\u3001Llama3\u7b49\u5f00\u6e90LLMs\u4e0a\u8fdb\u884c\u5fae\u8c03\u3002", "result": "ORMs\u5728BIRD\u57fa\u51c6\u4e0a\u6bd4ex-BoN\u63d0\u53474.33%\uff0c\u6bd4Maj\u63d0\u53472.91%\uff1b\u5728Spider\u57fa\u51c6\u4e0a\u6bd4ex-BoN\u63d0\u53472.10%\uff0c\u6bd4Maj\u63d0\u53470.93%\u3002\u5bf9\u5df2\u5bf9\u9f50SQL\u751f\u6210\u7684\u6a21\u578b\u5fae\u8c03\u6548\u679c\u66f4\u4f73\u3002", "conclusion": "ORMs\u4f5c\u4e3a\u6709\u6548\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u5728Text-to-SQL\u4efb\u52a1\u4e2d\u4f18\u4e8e\u4f20\u7edf\u6d4b\u8bd5\u65f6\u7b56\u7565\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u67e5\u8be2\u548c\u66f4\u591a\u5019\u9009\u67e5\u8be2\u60c5\u51b5\u4e0b\u8868\u73b0\u66f4\u597d\uff0c\u4e3a\u8bed\u4e49\u5bf9\u9f50\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2509.02076", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02076", "abs": "https://arxiv.org/abs/2509.02076", "authors": ["Kong Mun Yeen", "Rafidah Md Noor", "Wahidah Md Shah", "Aslinda Hassan", "Muhammad Umair Munir"], "title": "Forecasting Future DDoS Attacks Using Long Short Term Memory (LSTM) Model", "comment": "18 pages", "summary": "This paper forecasts future Distributed Denial of Service (DDoS) attacks\nusing deep learning models. Although several studies address forecasting DDoS\nattacks, they remain relatively limited compared to detection-focused research.\nBy studying the current trends and forecasting based on newer and updated\ndatasets, mitigation plans against the attacks can be planned and formulated.\nThe methodology used in this research work conforms to the Cross Industry\nStandard Process for Data Mining (CRISP-DM) model.", "AI": {"tldr": "\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u672a\u6765DDoS\u653b\u51fb\uff0c\u57fa\u4e8eCRISP-DM\u6570\u636e\u6316\u6398\u6807\u51c6\u6d41\u7a0b\uff0c\u65e8\u5728\u901a\u8fc7\u8d8b\u52bf\u5206\u6790\u548c\u66f4\u65b0\u6570\u636e\u96c6\u6765\u5236\u5b9a\u653b\u51fb\u7f13\u89e3\u8ba1\u5212", "motivation": "\u5f53\u524dDDoS\u653b\u51fb\u9884\u6d4b\u7814\u7a76\u76f8\u5bf9\u6709\u9650\uff0c\u4e3b\u8981\u96c6\u4e2d\u5728\u68c0\u6d4b\u65b9\u9762\u3002\u901a\u8fc7\u7814\u7a76\u5f53\u524d\u8d8b\u52bf\u5e76\u57fa\u4e8e\u66f4\u65b0\u7684\u6570\u636e\u96c6\u8fdb\u884c\u9884\u6d4b\uff0c\u53ef\u4ee5\u66f4\u597d\u5730\u89c4\u5212\u548c\u5236\u5b9a\u653b\u51fb\u7f13\u89e3\u7b56\u7565", "method": "\u91c7\u7528CRISP-DM\uff08\u8de8\u884c\u4e1a\u6570\u636e\u6316\u6398\u6807\u51c6\u6d41\u7a0b\uff09\u6a21\u578b\uff0c\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8fdb\u884cDDoS\u653b\u51fb\u9884\u6d4b", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684DDoS\u653b\u51fb\u9884\u6d4b\u65b9\u6cd5\uff0c\u4f46\u5177\u4f53\u9884\u6d4b\u51c6\u786e\u7387\u548c\u6027\u80fd\u6307\u6807\u672a\u5728\u6458\u8981\u4e2d\u660e\u786e\u8bf4\u660e", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u53ef\u4ee5\u7528\u4e8eDDoS\u653b\u51fb\u9884\u6d4b\uff0c\u57fa\u4e8eCRISP-DM\u6807\u51c6\u6d41\u7a0b\u7684\u65b9\u6cd5\u6709\u52a9\u4e8e\u5236\u5b9a\u6709\u6548\u7684\u653b\u51fb\u7f13\u89e3\u8ba1\u5212\uff0c\u586b\u8865\u4e86\u73b0\u6709\u7814\u7a76\u4e2d\u9884\u6d4b\u65b9\u9762\u7684\u4e0d\u8db3"}}
{"id": "2509.01338", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.01338", "abs": "https://arxiv.org/abs/2509.01338", "authors": ["Francesca Cairoli", "Luca Bortolussi", "Jyotirmoy V. Deshmukh", "Lars Lindemann", "Nicola Paoletti"], "title": "Conformal Predictive Monitoring for Multi-Modal Scenarios", "comment": null, "summary": "We consider the problem of quantitative predictive monitoring (QPM) of\nstochastic systems, i.e., predicting at runtime the degree of satisfaction of a\ndesired temporal logic property from the current state of the system. Since\ncomputational efficiency is key to enable timely intervention against predicted\nviolations, several state-of-the-art QPM approaches rely on fast\nmachine-learning surrogates to provide prediction intervals for the\nsatisfaction values, using conformal inference to offer statistical guarantees.\nHowever, these QPM methods suffer when the monitored agent exhibits multi-modal\ndynamics, whereby certain modes may yield high satisfaction values while others\ncritically violate the property. Existing QPM methods are mode-agnostic and so\nwould yield overly conservative and uninformative intervals that lack\nmeaningful mode-specific satisfaction information. To address this problem, we\npresent GenQPM, a method that leverages deep generative models, specifically\nscore-based diffusion models, to reliably approximate the probabilistic and\nmulti-modal system dynamics without requiring explicit model access. GenQPM\nemploys a mode classifier to partition the predicted trajectories by dynamical\nmode. For each mode, we then apply conformal inference to produce statistically\nvalid, mode-specific prediction intervals. We demonstrate the effectiveness of\nGenQPM on a benchmark of agent navigation and autonomous driving tasks,\nresulting in prediction intervals that are significantly more informative (less\nconservative) than mode-agnostic baselines.", "AI": {"tldr": "\u63d0\u51faGenQPM\u65b9\u6cd5\uff0c\u4f7f\u7528\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u548c\u6a21\u5f0f\u5206\u7c7b\u5668\u6765\u89e3\u51b3\u591a\u6a21\u6001\u968f\u673a\u7cfb\u7edf\u7684\u5b9a\u91cf\u9884\u6d4b\u76d1\u63a7\u95ee\u9898\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u80fd\u63d0\u4f9b\u66f4\u7cbe\u786e\u7684\u6a21\u5f0f\u7279\u5b9a\u9884\u6d4b\u533a\u95f4", "motivation": "\u73b0\u6709QPM\u65b9\u6cd5\u5728\u5904\u7406\u591a\u6a21\u6001\u52a8\u6001\u7cfb\u7edf\u65f6\u8fc7\u4e8e\u4fdd\u5b88\uff0c\u65e0\u6cd5\u63d0\u4f9b\u6709\u610f\u4e49\u7684\u6a21\u5f0f\u7279\u5b9a\u6ee1\u610f\u5ea6\u4fe1\u606f\uff0c\u9700\u8981\u6539\u8fdb", "method": "\u5229\u7528\u57fa\u4e8e\u5206\u6570\u7684\u6269\u6563\u6a21\u578b\u8fd1\u4f3c\u7cfb\u7edf\u6982\u7387\u591a\u6a21\u6001\u52a8\u6001\uff0c\u4f7f\u7528\u6a21\u5f0f\u5206\u7c7b\u5668\u5212\u5206\u8f68\u8ff9\uff0c\u5bf9\u6bcf\u4e2a\u6a21\u5f0f\u5e94\u7528\u4fdd\u5f62\u63a8\u7406\u751f\u6210\u7edf\u8ba1\u6709\u6548\u7684\u6a21\u5f0f\u7279\u5b9a\u9884\u6d4b\u533a\u95f4", "result": "\u5728\u667a\u80fd\u4f53\u5bfc\u822a\u548c\u81ea\u52a8\u9a7e\u9a76\u4efb\u52a1\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGenQPM\u4ea7\u751f\u7684\u9884\u6d4b\u533a\u95f4\u6bd4\u6a21\u5f0f\u65e0\u5173\u57fa\u7ebf\u65b9\u6cd5\u663e\u8457\u66f4\u4fe1\u606f\u4e30\u5bcc\uff08\u66f4\u4e0d\u4fdd\u5b88\uff09", "conclusion": "GenQPM\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u548c\u6a21\u5f0f\u5206\u7c7b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u7cfb\u7edf\u9884\u6d4b\u76d1\u63a7\u7684\u4fdd\u5b88\u6027\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u66f4\u6709\u610f\u4e49\u7684\u8fd0\u884c\u65f6\u9884\u6d4b"}}
{"id": "2509.02077", "categories": ["cs.CR", "cs.CL", "cs.LG", "68T50 Natural language processing", "D.4.6; I.2.7"], "pdf": "https://arxiv.org/pdf/2509.02077", "abs": "https://arxiv.org/abs/2509.02077", "authors": ["Refat Othman", "Diaeddin Rimawi", "Bruno Rossi", "Barbara Russo"], "title": "From Attack Descriptions to Vulnerabilities: A Sentence Transformer-Based Approach", "comment": "Accepted in The Journal of Systems and Software (2025)", "summary": "In the domain of security, vulnerabilities frequently remain undetected even\nafter their exploitation. In this work, vulnerabilities refer to publicly\ndisclosed flaws documented in Common Vulnerabilities and Exposures (CVE)\nreports. Establishing a connection between attacks and vulnerabilities is\nessential for enabling timely incident response, as it provides defenders with\nimmediate, actionable insights. However, manually mapping attacks to CVEs is\ninfeasible, thereby motivating the need for automation. This paper evaluates 14\nstate-of-the-art (SOTA) sentence transformers for automatically identifying\nvulnerabilities from textual descriptions of attacks. Our results demonstrate\nthat the multi-qa-mpnet-base-dot-v1 (MMPNet) model achieves superior\nclassification performance when using attack Technique descriptions, with an\nF1-score of 89.0, precision of 84.0, and recall of 94.7. Furthermore, it was\nobserved that, on average, 56% of the vulnerabilities identified by the MMPNet\nmodel are also represented within the CVE repository in conjunction with an\nattack, while 61% of the vulnerabilities detected by the model correspond to\nthose cataloged in the CVE repository. A manual inspection of the results\nrevealed the existence of 275 predicted links that were not documented in the\nMITRE repositories. Consequently, the automation of linking attack techniques\nto vulnerabilities not only enhances the detection and response capabilities\nrelated to software security incidents but also diminishes the duration during\nwhich vulnerabilities remain exploitable, thereby contributing to the\ndevelopment of more secure systems.", "AI": {"tldr": "\u8bc4\u4f3014\u79cd\u6700\u5148\u8fdb\u7684\u53e5\u5b50\u8f6c\u6362\u5668\uff0c\u7528\u4e8e\u4ece\u653b\u51fb\u6587\u672c\u63cf\u8ff0\u4e2d\u81ea\u52a8\u8bc6\u522b\u6f0f\u6d1e\u3002MMPNet\u6a21\u578b\u5728\u4f7f\u7528\u653b\u51fb\u6280\u672f\u63cf\u8ff0\u65f6\u8868\u73b0\u6700\u4f73\uff0cF1\u5206\u6570\u8fbe89.0\u3002", "motivation": "\u5b89\u5168\u9886\u57df\u4e2d\u6f0f\u6d1e\u5728\u88ab\u5229\u7528\u540e\u4ecd\u7ecf\u5e38\u672a\u88ab\u68c0\u6d4b\u5230\u3002\u624b\u52a8\u5c06\u653b\u51fb\u6620\u5c04\u5230CVE\u6f0f\u6d1e\u4e0d\u53ef\u884c\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u6765\u63d0\u4f9b\u53ca\u65f6\u7684\u4e8b\u4ef6\u54cd\u5e94\u80fd\u529b\u3002", "method": "\u8bc4\u4f3014\u79cdstate-of-the-art\u53e5\u5b50\u8f6c\u6362\u5668\u6a21\u578b\uff0c\u4f7f\u7528\u653b\u51fb\u6587\u672c\u63cf\u8ff0\u81ea\u52a8\u8bc6\u522b\u6f0f\u6d1e\uff0c\u91cd\u70b9\u5173\u6ce8\u591aqa-mpnet-base-dot-v1(MMPNet)\u6a21\u578b\u3002", "result": "MMPNet\u6a21\u578b\u5728\u4f7f\u7528\u653b\u51fb\u6280\u672f\u63cf\u8ff0\u65f6\u8fbe\u5230F1\u5206\u657089.0\u3001\u7cbe\u786e\u738784.0\u3001\u53ec\u56de\u738794.7\u300256%\u7684\u6a21\u578b\u8bc6\u522b\u6f0f\u6d1e\u5728CVE\u5e93\u4e2d\u6709\u653b\u51fb\u5173\u8054\uff0c61%\u5bf9\u5e94CVE\u5e93\u4e2d\u5df2\u7f16\u5f55\u6f0f\u6d1e\u3002\u53d1\u73b0275\u4e2a\u672a\u5728MITRE\u5e93\u4e2d\u8bb0\u5f55\u7684\u9884\u6d4b\u94fe\u63a5\u3002", "conclusion": "\u81ea\u52a8\u5316\u94fe\u63a5\u653b\u51fb\u6280\u672f\u4e0e\u6f0f\u6d1e\u4e0d\u4ec5\u589e\u5f3a\u4e86\u8f6f\u4ef6\u5b89\u5168\u4e8b\u4ef6\u7684\u68c0\u6d4b\u548c\u54cd\u5e94\u80fd\u529b\uff0c\u8fd8\u51cf\u5c11\u4e86\u6f0f\u6d1e\u53ef\u5229\u7528\u7684\u65f6\u95f4\u7a97\u53e3\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u66f4\u5b89\u5168\u7684\u7cfb\u7edf\u3002"}}
{"id": "2509.01350", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.01350", "abs": "https://arxiv.org/abs/2509.01350", "authors": ["Yunqing Liu", "Nan Zhang", "Zhiming Tan"], "title": "Error Notebook-Guided, Training-Free Part Retrieval in 3D CAD Assemblies via Vision-Language Models", "comment": null, "summary": "Effective specification-aware part retrieval within complex CAD assemblies is\nessential for automated design verification and downstream engineering tasks.\nHowever, directly using LLMs/VLMs to this task presents some challenges: the\ninput sequences may exceed model token limits, and even after processing,\nperformance remains unsatisfactory. Moreover, fine-tuning LLMs/VLMs requires\nsignificant computational resources, and for many high-performing general-use\nproprietary models (e.g., GPT or Gemini), fine-tuning access is not available.\nIn this paper, we propose a novel part retrieval framework that requires no\nextra training, but using Error Notebooks + RAG for refined prompt engineering\nto help improve the existing general model's retrieval performance. The\nconstruction of Error Notebooks consists of two steps: (1) collecting\nhistorical erroneous CoTs and their incorrect answers, and (2) connecting these\nCoTs through reflective corrections until the correct solutions are obtained.\nAs a result, the Error Notebooks serve as a repository of tasks along with\ntheir corrected CoTs and final answers. RAG is then employed to retrieve\nspecification-relevant records from the Error Notebooks and incorporate them\ninto the inference process. Another major contribution of our work is a\nhuman-in-the-loop CAD dataset, which is used to evaluate our method. In\naddition, the engineering value of our novel framework lies in its ability to\neffectively handle 3D models with lengthy, non-natural language metadata.\nExperiments with proprietary models, including GPT-4o and the Gemini series,\nshow substantial gains, with GPT-4o (Omni) achieving up to a 23.4% absolute\naccuracy improvement on the human preference dataset. Moreover, ablation\nstudies confirm that CoT reasoning provides benefits especially in challenging\ncases with higher part counts (>10).", "AI": {"tldr": "\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684CAD\u96f6\u4ef6\u68c0\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u9519\u8bef\u7b14\u8bb0\u672c\u548cRAG\u6280\u672f\u6539\u5584\u73b0\u6709\u5927\u6a21\u578b\u7684\u68c0\u7d22\u6027\u80fd\uff0cGPT-4o\u51c6\u786e\u7387\u63d0\u534723.4%", "motivation": "\u76f4\u63a5\u4f7f\u7528LLMs/VLMs\u8fdb\u884cCAD\u96f6\u4ef6\u68c0\u7d22\u9047\u5230\u8f93\u5165\u5e8f\u5217\u8d85\u957f\u3001\u6027\u80fd\u4e0d\u4f73\u7684\u95ee\u9898\uff0c\u4e14\u5bf9\u4e8e\u95ed\u6e90\u5546\u4e1a\u6a21\u578b\u65e0\u6cd5\u5fae\u8c03", "method": "\u6784\u5efa\u9519\u8bef\u7b14\u8bb0\u672c\uff08\u6536\u96c6\u5386\u53f2\u9519\u8befCoT\u548c\u66f4\u6b63\u8fc7\u7a0b\uff09+ RAG\u68c0\u7d22\u76f8\u5173\u8bb0\u5f55\uff0c\u5e76\u5c06\u5176\u6574\u5408\u5230\u63a8\u7406\u8fc7\u7a0b\u4e2d", "result": "\u5728GPT-4o\u548cGemini\u7cfb\u5217\u6a21\u578b\u4e0a\u83b7\u5f97\u663e\u8457\u6536\u76ca\uff0cGPT-4o\u5728\u4eba\u7c7b\u504f\u597d\u6570\u636e\u96c6\u4e0a\u7edd\u5bf9\u51c6\u786e\u7387\u63d0\u534723.4%\uff0c\u7279\u522b\u5728\u96f6\u4ef6\u6570\u91cf\u8f83\u591a\uff08>10\uff09\u7684\u590d\u6742\u60c5\u51b5\u4e0b\u8868\u73b0\u66f4\u4f18", "conclusion": "\u8be5\u6846\u67b6\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u957f\u5e8f\u5217\u548c\u975e\u81ea\u7136\u8bed\u8a00\u5143\u6570\u636e\uff0c\u4e3aCAD\u8bbe\u8ba1\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.02083", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.02083", "abs": "https://arxiv.org/abs/2509.02083", "authors": ["Dmitry Tanana"], "title": "Performance analysis of common browser extensions for cryptojacking detection", "comment": null, "summary": "This paper considers five extensions for Chromium-based browsers in order to\ndetermine how effective can browser-based defenses against cryptojacking\navailable to regular users be. We've examined most popular extensions -\nMinerBlock, AdGuard AdBlocker, Easy Redirect && Prevent Cryptojacking,\nCoinEater and Miners Shield, which claim to be designed specifically to\nidentify and stop illegal cryptocurrency mining. An empirically confirmed\ndataset of 373 distinct cryptojacking-infected websites which was assembled\nduring multi-stage procedure, was used to test those extensions. The results\nshowed that all plugins in question had significant performance limits. Easy\nRedirect and Miners Shield only blocked 6 and 5 websites respectively, while\nMinerBlock had the greatest detection rate at only 27% (101/373 sites blocked).\nMost concerningly, despite promises of cryptojacking prevention, AdGuard (which\nhas over 13 million users) and CoinEater were unable to identify any of the\ncompromised websites. These results demonstrate serious flaws in cryptojacking\ndetection products targeted for regular users, since even the best-performing\nspecimen failed to detect 73% of attacks. The obvious difference between\nadvertised capabilities and real performance highlights the urgent need for\neither accessibility improvements for laboratory-grade detection technologies\nthat show 90%+ efficiency in controlled environment or fundamental upgrades to\ncurrent commonly used extensions.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u6d4b\u8bd55\u6b3e\u9632\u6b62\u52ab\u6301\u6316\u77ff\u7684\u6d4f\u89c8\u5668\u6269\u5c55\u7a0b\u5e8f\uff0c\u53d1\u73b0\u751a\u81f3\u6700\u597d\u7684\u6269\u5c55\u4e5f\u53ea\u80fd\u62e6\u622a27%\u653b\u51fb\uff0c\u800c\u4e00\u4e9b\u666e\u904d\u4f7f\u7528\u7684\u6269\u5c55\u5b8c\u5168\u65e0\u6cd5\u68c0\u6d4b\u52ab\u6301\u6316\u77ff\u3002", "motivation": "\u8bc4\u4f30\u666e\u901a\u7528\u6237\u53ef\u7528\u7684\u6d4f\u89c8\u5668\u6269\u5c55\u5728\u9632\u5fa1\u52ab\u6301\u6316\u77ff\u653b\u51fb\u65b9\u9762\u7684\u5b9e\u9645\u6548\u679c\uff0c\u56e0\u4e3a\u52ab\u6301\u6316\u77ff\u6210\u4e3a\u4e00\u79cd\u65e0\u624b\u4e4b\u529b\u7684\u7f51\u7edc\u5a01\u80c1\u3002", "method": "\u4f7f\u7528\u7ecf\u9a8c\u8bc1\u7684373\u4e2a\u52ab\u6301\u6316\u77ff\u7f51\u7ad9\u6570\u636e\u96c6\uff0c\u6d4b\u8bd55\u6b3e\u666e\u904d\u4f7f\u7528\u7684Chromium\u6d4f\u89c8\u5668\u6269\u5c55\uff08MinerBlock\u3001AdGuard\u3001Easy Redirect\u3001CoinEater\u3001Miners Shield\uff09\u7684\u68c0\u6d4b\u80fd\u529b\u3002", "result": "\u6240\u6709\u6269\u5c55\u8868\u73b0\u5dee\u5f3a\uff1aMinerBlock\u6700\u597d\u4e5f\u53ea\u62e6\u622a27%\u7f51\u7ad9\uff0cEasy Redirect\u548cMiners Shield\u5206\u522b\u53ea\u62e6\u622a6\u4e2a\u548c5\u4e2a\u7f51\u7ad9\uff0cAdGuard\u548cCoinEater\u5b8c\u5168\u65e0\u6cd5\u68c0\u6d4b\u4efb\u4f55\u52ab\u6301\u6316\u77ff\u3002", "conclusion": "\u5f53\u524d\u9762\u5411\u666e\u901a\u7528\u6237\u7684\u52ab\u6301\u6316\u77ff\u9632\u5fa1\u5de5\u5177\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\uff0c\u9700\u8981\u63d0\u5347\u5b9e\u9a8c\u5ba4\u7ea7\u68c0\u6d4b\u6280\u672f\u7684\u6613\u7528\u6027\u6216\u5bf9\u73b0\u6709\u6269\u5c55\u8fdb\u884c\u6839\u672c\u6027\u5347\u7ea7\u3002"}}
{"id": "2509.01396", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.01396", "abs": "https://arxiv.org/abs/2509.01396", "authors": ["Haiyuan Wan", "Chen Yang", "Junchi Yu", "Meiqi Tu", "Jiaxuan Lu", "Di Yu", "Jianbao Cao", "Ben Gao", "Jiaqing Xie", "Aoran Wang", "Wenlong Zhang", "Philip Torr", "Dongzhan Zhou"], "title": "DeepResearch Arena: The First Exam of LLMs' Research Abilities via Seminar-Grounded Tasks", "comment": null, "summary": "Deep research agents have attracted growing attention for their potential to\norchestrate multi-stage research workflows, spanning literature synthesis,\nmethodological design, and empirical verification. Despite these strides,\nevaluating their research capability faithfully is rather challenging due to\nthe difficulty of collecting frontier research questions that genuinely capture\nresearchers' attention and intellectual curiosity. To address this gap, we\nintroduce DeepResearch Arena, a benchmark grounded in academic seminars that\ncapture rich expert discourse and interaction, better reflecting real-world\nresearch environments and reducing the risk of data leakage. To automatically\nconstruct DeepResearch Arena, we propose a Multi-Agent Hierarchical Task\nGeneration (MAHTG) system that extracts research-worthy inspirations from\nseminar transcripts. The MAHTG system further translates research-worthy\ninspirations into high-quality research tasks, ensuring the traceability of\nresearch task formulation while filtering noise. With the MAHTG system, we\ncurate DeepResearch Arena with over 10,000 high-quality research tasks from\nover 200 academic seminars, spanning 12 disciplines, such as literature,\nhistory, and science. Our extensive evaluation shows that DeepResearch Arena\npresents substantial challenges for current state-of-the-art agents, with clear\nperformance gaps observed across different models.", "AI": {"tldr": "DeepResearch Arena\u662f\u4e00\u4e2a\u57fa\u4e8e\u5b66\u672f\u7814\u8ba8\u4f1a\u6784\u5efa\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b10,000\u591a\u4e2a\u9ad8\u8d28\u91cf\u7814\u7a76\u4efb\u52a1\uff0c\u7528\u4e8e\u8bc4\u4f30\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u7684\u7814\u7a76\u80fd\u529b\uff0c\u8986\u76d612\u4e2a\u5b66\u79d1\u9886\u57df\u3002", "motivation": "\u5f53\u524d\u8bc4\u4f30\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u7684\u7814\u7a76\u80fd\u529b\u5b58\u5728\u6311\u6218\uff0c\u4e3b\u8981\u56e0\u4e3a\u96be\u4ee5\u6536\u96c6\u771f\u6b63\u53cd\u6620\u7814\u7a76\u8005\u5173\u6ce8\u548c\u667a\u529b\u597d\u5947\u5fc3\u7684\u524d\u6cbf\u7814\u7a76\u95ee\u9898\u3002\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u53ef\u80fd\u65e0\u6cd5\u771f\u5b9e\u53cd\u6620\u5b9e\u9645\u7814\u7a76\u73af\u5883\uff0c\u4e14\u5b58\u5728\u6570\u636e\u6cc4\u9732\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u4e86\u591a\u667a\u80fd\u4f53\u5206\u5c42\u4efb\u52a1\u751f\u6210\uff08MAHTG\uff09\u7cfb\u7edf\uff0c\u4ece\u7814\u8ba8\u4f1a\u8bb0\u5f55\u4e2d\u63d0\u53d6\u6709\u4ef7\u503c\u7684\u7814\u7a76\u7075\u611f\uff0c\u5e76\u5c06\u5176\u8f6c\u5316\u4e3a\u9ad8\u8d28\u91cf\u7814\u7a76\u4efb\u52a1\uff0c\u786e\u4fdd\u7814\u7a76\u4efb\u52a1\u5236\u5b9a\u7684\u53ef\u8ffd\u6eaf\u6027\u5e76\u8fc7\u6ee4\u566a\u58f0\u3002", "result": "\u6784\u5efa\u4e86\u5305\u542b10,000\u591a\u4e2a\u7814\u7a76\u4efb\u52a1\u7684DeepResearch Arena\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d612\u4e2a\u5b66\u79d1\u3002\u8bc4\u4f30\u663e\u793a\u8be5\u57fa\u51c6\u5bf9\u5f53\u524d\u6700\u5148\u8fdb\u7684\u667a\u80fd\u4f53\u6784\u6210\u4e86\u91cd\u5927\u6311\u6218\uff0c\u4e0d\u540c\u6a21\u578b\u4e4b\u95f4\u5b58\u5728\u660e\u663e\u7684\u6027\u80fd\u5dee\u8ddd\u3002", "conclusion": "DeepResearch Arena\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u771f\u5b9e\u3001\u66f4\u53ef\u9760\u7684\u57fa\u51c6\u6d4b\u8bd5\u73af\u5883\uff0c\u80fd\u591f\u66f4\u597d\u5730\u8bc4\u4f30\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u7684\u7814\u7a76\u80fd\u529b\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u4ee3\u7406\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u8bc4\u4f30\u5de5\u5177\u3002"}}
{"id": "2509.02189", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.02189", "abs": "https://arxiv.org/abs/2509.02189", "authors": ["Aditya Bhardwaj", "P\u00e9ter Kutas"], "title": "A Gentle Introduction to Blind signatures: From RSA to Lattice-based Cryptography", "comment": null, "summary": "Blind signatures were first introduced by David Chaum. They allow a user to\nhave a message signed by a signer without revealing the message itself. This\nproperty is particularly useful in applications such as electronic voting and\ndigital cash, where user anonymity is important. In a blind signature scheme,\nthe user blinds their message before sending it to the signer, who signs the\nblinded message. The user then unblinds the signed message to obtain a valid\nsignature that can be verified publicly, ensuring that the signer cannot trace\nthe signed message back to the original unblinded version. A good analogy is\nplacing the message inside an envelope and having the envelope signed. Once the\nenvelope is opened, the signature remains valid for the enclosed message,\nensuring that the content remains confidential.\n  Such constructions provide anonymity and privacy to the user but given a\npractical quantum computer, the security of traditional crypto-systems\nproviding such features will be broken. To address this, the development of\nquantum-resistant cryptographic protocols is essential for maintaining the\nsecurity of digital transactions and data. Aligning with the same goal, this\nwork aims to thoroughly review the background of lattice-based blind\nsignatures. We start with the foundations of digital signatures in the\nclassical settings and then move on to lattice-based constructions.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u57fa\u4e8e\u683c\u7684\u76f2\u7b7e\u540d\u65b9\u6848\uff0c\u4ece\u7ecf\u5178\u6570\u5b57\u7b7e\u540d\u57fa\u7840\u5230\u91cf\u5b50\u5b89\u5168\u7684\u683c\u57fa\u6784\u9020\uff0c\u65e8\u5728\u89e3\u51b3\u91cf\u5b50\u8ba1\u7b97\u5bf9\u4f20\u7edf\u5bc6\u7801\u7cfb\u7edf\u7684\u5a01\u80c1\u3002", "motivation": "\u968f\u7740\u91cf\u5b50\u8ba1\u7b97\u673a\u7684\u53d1\u5c55\uff0c\u4f20\u7edf\u5bc6\u7801\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u53d7\u5230\u5a01\u80c1\uff0c\u9700\u8981\u5f00\u53d1\u91cf\u5b50\u5b89\u5168\u7684\u5bc6\u7801\u534f\u8bae\u6765\u4fdd\u62a4\u6570\u5b57\u4ea4\u6613\u548c\u6570\u636e\u7684\u9690\u79c1\u6027\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u7528\u6237\u533f\u540d\u6027\u7684\u5e94\u7528\u573a\u666f\u4e2d\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u56de\u987e\u76f2\u7b7e\u540d\u7684\u57fa\u7840\u7406\u8bba\uff0c\u4ece\u7ecf\u5178\u6570\u5b57\u7b7e\u540d\u5f00\u59cb\uff0c\u9010\u6b65\u6df1\u5165\u5230\u57fa\u4e8e\u683c\u7684\u6784\u9020\u65b9\u6cd5\uff0c\u5206\u6790\u5176\u5b89\u5168\u6027\u548c\u5b9e\u73b0\u673a\u5236\u3002", "result": "\u63d0\u4f9b\u4e86\u5bf9\u683c\u57fa\u76f2\u7b7e\u540d\u65b9\u6848\u7684\u5168\u9762\u80cc\u666f\u56de\u987e\uff0c\u5efa\u7acb\u4e86\u4ece\u7ecf\u5178\u5230\u91cf\u5b50\u5b89\u5168\u5bc6\u7801\u534f\u8bae\u7684\u8fc7\u6e21\u6846\u67b6\u3002", "conclusion": "\u57fa\u4e8e\u683c\u7684\u76f2\u7b7e\u540d\u662f\u6784\u5efa\u91cf\u5b50\u5b89\u5168\u5bc6\u7801\u7cfb\u7edf\u7684\u91cd\u8981\u65b9\u5411\uff0c\u5bf9\u4e8e\u4fdd\u62a4\u7535\u5b50\u6295\u7968\u3001\u6570\u5b57\u8d27\u5e01\u7b49\u9700\u8981\u533f\u540d\u6027\u7684\u5e94\u7528\u5177\u6709\u5173\u952e\u610f\u4e49\u3002"}}
{"id": "2509.01398", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.01398", "abs": "https://arxiv.org/abs/2509.01398", "authors": ["Cristina Cornelio", "Takuya Ito", "Ryan Cory-Wright", "Sanjeeb Dash", "Lior Horesh"], "title": "The Need for Verification in AI-Driven Scientific Discovery", "comment": null, "summary": "Artificial intelligence (AI) is transforming the practice of science. Machine\nlearning and large language models (LLMs) can generate hypotheses at a scale\nand speed far exceeding traditional methods, offering the potential to\naccelerate discovery across diverse fields. However, the abundance of\nhypotheses introduces a critical challenge: without scalable and reliable\nmechanisms for verification, scientific progress risks being hindered rather\nthan being advanced. In this article, we trace the historical development of\nscientific discovery, examine how AI is reshaping established practices for\nscientific discovery, and review the principal approaches, ranging from\ndata-driven methods and knowledge-aware neural architectures to symbolic\nreasoning frameworks and LLM agents. While these systems can uncover patterns\nand propose candidate laws, their scientific value ultimately depends on\nrigorous and transparent verification, which we argue must be the cornerstone\nof AI-assisted discovery.", "AI": {"tldr": "AI\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5927\u89c4\u6a21\u5feb\u901f\u751f\u6210\u79d1\u5b66\u5047\u8bbe\uff0c\u4f46\u7f3a\u4e4f\u53ef\u6269\u5c55\u7684\u9a8c\u8bc1\u673a\u5236\u53ef\u80fd\u963b\u788d\u800c\u975e\u4fc3\u8fdb\u79d1\u5b66\u8fdb\u6b65\u3002\u672c\u6587\u56de\u987e\u4e86\u79d1\u5b66\u53d1\u73b0\u7684\u5386\u53f2\u53d1\u5c55\uff0c\u5206\u6790\u4e86AI\u5982\u4f55\u91cd\u5851\u79d1\u5b66\u5b9e\u8df5\uff0c\u5e76\u5f3a\u8c03\u900f\u660e\u9a8c\u8bc1\u662fAI\u8f85\u52a9\u53d1\u73b0\u7684\u5173\u952e\u57fa\u77f3\u3002", "motivation": "AI\u548c\u673a\u5668\u5b66\u4e60\u6280\u672f\u80fd\u591f\u4ee5\u524d\u6240\u672a\u6709\u7684\u89c4\u6a21\u548c\u901f\u5ea6\u751f\u6210\u79d1\u5b66\u5047\u8bbe\uff0c\u4f46\u5982\u679c\u6ca1\u6709\u53ef\u9760\u7684\u9a8c\u8bc1\u673a\u5236\uff0c\u8fd9\u79cd\u5047\u8bbe\u7684\u6fc0\u589e\u53cd\u800c\u53ef\u80fd\u963b\u788d\u79d1\u5b66\u8fdb\u6b65\u3002\u9700\u8981\u7814\u7a76\u5982\u4f55\u786e\u4fddAI\u8f85\u52a9\u79d1\u5b66\u53d1\u73b0\u7684\u53ef\u4fe1\u5ea6\u548c\u6709\u6548\u6027\u3002", "method": "\u901a\u8fc7\u8ffd\u6eaf\u79d1\u5b66\u53d1\u73b0\u7684\u5386\u53f2\u53d1\u5c55\uff0c\u5206\u6790AI\u5982\u4f55\u6539\u53d8\u4f20\u7edf\u79d1\u5b66\u5b9e\u8df5\uff0c\u5e76\u7efc\u8ff0\u4e3b\u8981\u65b9\u6cd5\uff1a\u5305\u62ec\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u3001\u77e5\u8bc6\u611f\u77e5\u795e\u7ecf\u67b6\u6784\u3001\u7b26\u53f7\u63a8\u7406\u6846\u67b6\u548cLLM\u4ee3\u7406\u7b49\u7cfb\u7edf\u3002", "result": "AI\u7cfb\u7edf\u80fd\u591f\u53d1\u73b0\u6a21\u5f0f\u5e76\u63d0\u51fa\u5019\u9009\u5b9a\u5f8b\uff0c\u4f46\u5176\u79d1\u5b66\u4ef7\u503c\u6700\u7ec8\u53d6\u51b3\u4e8e\u662f\u5426\u7ecf\u8fc7\u4e25\u683c\u900f\u660e\u7684\u9a8c\u8bc1\u8fc7\u7a0b\u3002\u9a8c\u8bc1\u673a\u5236\u662f\u51b3\u5b9aAI\u8f85\u52a9\u53d1\u73b0\u6210\u529f\u4e0e\u5426\u7684\u5173\u952e\u56e0\u7d20\u3002", "conclusion": "\u900f\u660e\u548c\u4e25\u683c\u7684\u9a8c\u8bc1\u5fc5\u987b\u6210\u4e3aAI\u8f85\u52a9\u79d1\u5b66\u53d1\u73b0\u7684\u57fa\u77f3\u3002\u867d\u7136AI\u6280\u672f\u80fd\u591f\u52a0\u901f\u5047\u8bbe\u751f\u6210\uff0c\u4f46\u53ea\u6709\u901a\u8fc7\u53ef\u9760\u7684\u9a8c\u8bc1\u673a\u5236\u624d\u80fd\u786e\u4fdd\u79d1\u5b66\u53d1\u73b0\u7684\u771f\u5b9e\u4ef7\u503c\u548c\u53ef\u4fe1\u5ea6\uff0c\u907f\u514d\u4f2a\u79d1\u5b66\u7684\u6cdb\u6ee5\u3002"}}
{"id": "2509.02289", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.02289", "abs": "https://arxiv.org/abs/2509.02289", "authors": ["Anuj Gautam", "Tarun Yadav", "Garrett Smith", "Kent Seamons", "Scott Ruoti"], "title": "Passwords and FIDO2 Are Meant To Be Secret: A Practical Secure Authentication Channel for Web Browsers", "comment": "Extended version of paper published at CCS 2025:\n  https://doi.org/10.1145/3719027.3765195", "summary": "Password managers provide significant security benefits to users. However,\nmalicious client-side scripts and browser extensions can steal passwords after\nthe manager has autofilled them into the web page. In this paper, we extend\nprior work by Stock and Johns, showing how password autofill can be hardened to\nprevent these local attacks. We implement our design in the Firefox browser and\nconduct experiments demonstrating that our defense successfully protects\npasswords from XSS attacks and malicious extensions. We also show that our\nimplementation is compatible with 97% of the Alexa top 1000 websites. Next, we\ngeneralize our design, creating a second defense that prevents recently\ndiscovered local attacks against the FIDO2 protocols. We implement this second\ndefense into Firefox, demonstrating that it protects the FIDO2 protocol against\nXSS attacks and malicious extensions. This defense is compatible with all\nwebsites, though it does require a small change (2-3 lines) to web servers\nimplementing FIDO2.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u4e24\u79cd\u9632\u5fa1\u673a\u5236\uff0c\u5206\u522b\u7528\u4e8e\u4fdd\u62a4\u5bc6\u7801\u7ba1\u7406\u5668\u7684\u81ea\u52a8\u586b\u5145\u529f\u80fd\u548cFIDO2\u534f\u8bae\uff0c\u9632\u6b62XSS\u653b\u51fb\u548c\u6076\u610f\u6d4f\u89c8\u5668\u6269\u5c55\u7a83\u53d6\u654f\u611f\u4fe1\u606f\u3002", "motivation": "\u73b0\u6709\u7684\u5bc6\u7801\u7ba1\u7406\u5668\u867d\u7136\u63d0\u4f9b\u5b89\u5168\u4f18\u52bf\uff0c\u4f46\u6076\u610f\u5ba2\u6237\u7aef\u811a\u672c\u548c\u6d4f\u89c8\u5668\u6269\u5c55\u53ef\u4ee5\u5728\u5bc6\u7801\u81ea\u52a8\u586b\u5145\u540e\u7a83\u53d6\u5bc6\u7801\u3002FIDO2\u534f\u8bae\u4e5f\u5b58\u5728\u7c7b\u4f3c\u7684\u672c\u5730\u653b\u51fb\u98ce\u9669\u3002", "method": "1. \u5728Firefox\u6d4f\u89c8\u5668\u4e2d\u5b9e\u73b0\u5bc6\u7801\u81ea\u52a8\u586b\u5145\u52a0\u56fa\u673a\u5236\uff1b2. \u8bbe\u8ba1\u5e76\u5b9e\u73b0\u9488\u5bf9FIDO2\u534f\u8bae\u7684\u901a\u7528\u9632\u5fa1\u65b9\u6848\uff1b3. \u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u9632\u5fa1\u6548\u679c\u548c\u7f51\u7ad9\u517c\u5bb9\u6027\u3002", "result": "1. \u6210\u529f\u4fdd\u62a4\u5bc6\u7801\u514d\u53d7XSS\u653b\u51fb\u548c\u6076\u610f\u6269\u5c55\u7a83\u53d6\uff1b2. \u4e0eAlexa top 1000\u7f51\u7ad9\u4e2d97%\u517c\u5bb9\uff1b3. FIDO2\u9632\u5fa1\u65b9\u6848\u5bf9\u6240\u6709\u7f51\u7ad9\u517c\u5bb9\uff0c\u4ec5\u9700\u670d\u52a1\u5668\u7aef\u5c11\u91cf\u4ee3\u7801\u4fee\u6539\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e24\u79cd\u9632\u5fa1\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u5bc6\u7801\u7ba1\u7406\u5668\u548cFIDO2\u534f\u8bae\u7684\u672c\u5730\u653b\u51fb\u6f0f\u6d1e\uff0c\u5177\u6709\u9ad8\u517c\u5bb9\u6027\u548c\u5b9e\u7528\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86Web\u8ba4\u8bc1\u5b89\u5168\u6027\u3002"}}
{"id": "2509.01441", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.01441", "abs": "https://arxiv.org/abs/2509.01441", "authors": ["Deyu Zhou", "Yuqi Hou", "Xiao Xue", "Xudong Lu", "Qingzhong Li", "Lizhen Cui"], "title": "LLM-empowered Agents Simulation Framework for Scenario Generation in Service Ecosystem Governance", "comment": null, "summary": "As the social environment is growing more complex and collaboration is\ndeepening, factors affecting the healthy development of service ecosystem are\nconstantly changing and diverse, making its governance a crucial research\nissue. Applying the scenario analysis method and conducting scenario rehearsals\nby constructing an experimental system before managers make decisions, losses\ncaused by wrong decisions can be largely avoided. However, it relies on\npredefined rules to construct scenarios and faces challenges such as limited\ninformation, a large number of influencing factors, and the difficulty of\nmeasuring social elements. These challenges limit the quality and efficiency of\ngenerating social and uncertain scenarios for the service ecosystem. Therefore,\nwe propose a scenario generator design method, which adaptively coordinates\nthree Large Language Model (LLM) empowered agents that autonomously optimize\nexperimental schemes to construct an experimental system and generate high\nquality scenarios. Specifically, the Environment Agent (EA) generates social\nenvironment including extremes, the Social Agent (SA) generates social\ncollaboration structure, and the Planner Agent (PA) couples task-role\nrelationships and plans task solutions. These agents work in coordination, with\nthe PA adjusting the experimental scheme in real time by perceiving the states\nof each agent and these generating scenarios. Experiments on the\nProgrammableWeb dataset illustrate our method generates more accurate scenarios\nmore efficiently, and innovatively provides an effective way for service\necosystem governance related experimental system construction.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u534f\u540c\u573a\u666f\u751f\u6210\u65b9\u6cd5\uff0c\u7528\u4e8e\u670d\u52a1\u751f\u6001\u7cfb\u7edf\u6cbb\u7406\u5b9e\u9a8c\u7cfb\u7edf\u7684\u6784\u5efa\uff0c\u901a\u8fc7\u73af\u5883\u3001\u793e\u4f1a\u548c\u89c4\u5212\u4e09\u4e2a\u667a\u80fd\u4f53\u7684\u534f\u8c03\u5de5\u4f5c\uff0c\u9ad8\u6548\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u793e\u4f1a\u4e0d\u786e\u5b9a\u6027\u573a\u666f\u3002", "motivation": "\u670d\u52a1\u751f\u6001\u7cfb\u7edf\u6cbb\u7406\u9762\u4e34\u590d\u6742\u591a\u53d8\u7684\u793e\u4f1a\u73af\u5883\u548c\u5f71\u54cd\u56e0\u7d20\uff0c\u4f20\u7edf\u57fa\u4e8e\u9884\u5b9a\u4e49\u89c4\u5219\u7684\u573a\u666f\u5206\u6790\u65b9\u6cd5\u5b58\u5728\u4fe1\u606f\u6709\u9650\u3001\u56e0\u7d20\u4f17\u591a\u3001\u793e\u4f1a\u8981\u7d20\u96be\u4ee5\u91cf\u5316\u7b49\u6311\u6218\uff0c\u9650\u5236\u4e86\u573a\u666f\u751f\u6210\u7684\u8d28\u91cf\u548c\u6548\u7387\u3002", "method": "\u8bbe\u8ba1\u4e09\u4e2aLLM\u8d4b\u80fd\u7684\u667a\u80fd\u4f53\uff1a\u73af\u5883\u667a\u80fd\u4f53(EA)\u751f\u6210\u793e\u4f1a\u73af\u5883\uff08\u5305\u62ec\u6781\u7aef\u60c5\u51b5\uff09\uff0c\u793e\u4f1a\u667a\u80fd\u4f53(SA)\u751f\u6210\u793e\u4f1a\u534f\u4f5c\u7ed3\u6784\uff0c\u89c4\u5212\u667a\u80fd\u4f53(PA)\u8026\u5408\u4efb\u52a1-\u89d2\u8272\u5173\u7cfb\u5e76\u89c4\u5212\u4efb\u52a1\u89e3\u51b3\u65b9\u6848\u3002\u8fd9\u4e9b\u667a\u80fd\u4f53\u534f\u540c\u5de5\u4f5c\uff0cPA\u901a\u8fc7\u611f\u77e5\u5404\u667a\u80fd\u4f53\u72b6\u6001\u5b9e\u65f6\u8c03\u6574\u5b9e\u9a8c\u65b9\u6848\u3002", "result": "\u5728ProgrammableWeb\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u66f4\u9ad8\u6548\u5730\u751f\u6210\u66f4\u51c6\u786e\u7684\u573a\u666f\uff0c\u4e3a\u670d\u52a1\u751f\u6001\u7cfb\u7edf\u6cbb\u7406\u76f8\u5173\u7684\u5b9e\u9a8c\u7cfb\u7edf\u6784\u5efa\u63d0\u4f9b\u4e86\u521b\u65b0\u6709\u6548\u7684\u9014\u5f84\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u540c\u7684\u573a\u666f\u751f\u6210\u5668\u8bbe\u8ba1\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u670d\u52a1\u751f\u6001\u7cfb\u7edf\u6cbb\u7406\u4e2d\u573a\u666f\u6784\u5efa\u7684\u6311\u6218\uff0c\u4e3a\u590d\u6742\u793e\u4f1a\u73af\u5883\u7684\u5b9e\u9a8c\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u7684\u6280\u672f\u65b9\u6848\u3002"}}
{"id": "2509.01544", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.01544", "abs": "https://arxiv.org/abs/2509.01544", "authors": ["Ibne Farabi Shihab", "Sanjeda Akter", "Anuj Sharma"], "title": "Counterfactual Sensitivity for Faithful Reasoning in Language Models", "comment": null, "summary": "Large language models (LLMs) often produce correct answers while relying on\nflawed or irrelevant reasoning traces, undermining their trustworthiness in\nhigh-stakes domains. We propose Counterfactual Sensitivity Regularization\n(CSR), a lightweight training objective that enforces dependence between\nintermediate reasoning and final outputs. CSR introduces automated,\noperator-level counterfactual interventions (e.g., swapping \"+\" with \"-\")\nduring training and penalizes models that preserve the same answer under\nlogically invalid traces. This requires only one additional forward pass per\nsample. To measure faithfulness, we introduce Counterfactual Outcome\nSensitivity (COS), which quantifies the impact of such perturbations on model\npredictions. Across structured reasoning tasks - arithmetic (GSM8K), logical\ndeduction (PrOntoQA), and planning (Blocks World) - CSR improves faithfulness\nby up to 70 percentage points over standard fine-tuning and process\nsupervision, with only minor accuracy loss. The learned sensitivity generalizes\nto larger models and synergizes with inference-time methods such as\nself-consistency. A pilot study on HellaSwag further demonstrates that\nextending CSR with semantic perturbations can enhance faithfulness in\ncommonsense reasoning.", "AI": {"tldr": "\u63d0\u51fa\u4e86Counterfactual Sensitivity Regularization (CSR)\u8bad\u7ec3\u76ee\u6807\uff0c\u901a\u8fc7\u5728\u8bad\u7ec3\u65f6\u5f15\u5165\u7b97\u5b50\u7ea7\u53cd\u4e8b\u5b9e\u5e72\u9884\uff0c\u5f3a\u5236\u6a21\u578b\u4e2d\u95f4\u63a8\u7406\u4e0e\u6700\u7ec8\u8f93\u51fa\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u7684\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7ecf\u5e38\u5728\u4ea7\u751f\u6b63\u786e\u7b54\u6848\u7684\u540c\u65f6\u4f9d\u8d56\u6709\u7f3a\u9677\u6216\u4e0d\u76f8\u5173\u7684\u63a8\u7406\u8f68\u8ff9\uff0c\u8fd9\u5728\u9ad8\u98ce\u9669\u9886\u57df\u4e2d\u524a\u5f31\u4e86\u5176\u53ef\u4fe1\u5ea6\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u786e\u4fdd\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\u4e0e\u6700\u7ec8\u8f93\u51fa\u4e4b\u95f4\u6709\u771f\u5b9e\u7684\u56e0\u679c\u5173\u7cfb\u3002", "method": "\u63d0\u51faCSR\u8bad\u7ec3\u76ee\u6807\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u81ea\u52a8\u5f15\u5165\u7b97\u5b50\u7ea7\u53cd\u4e8b\u5b9e\u5e72\u9884\uff08\u5982\u5c06\"+\"\u66ff\u6362\u4e3a\"-\"\uff09\uff0c\u5e76\u60e9\u7f5a\u90a3\u4e9b\u5728\u903b\u8f91\u65e0\u6548\u8f68\u8ff9\u4e0b\u4ecd\u4fdd\u6301\u76f8\u540c\u7b54\u6848\u7684\u6a21\u578b\u3002\u8be5\u65b9\u6cd5\u53ea\u9700\u8981\u6bcf\u4e2a\u6837\u672c\u989d\u5916\u4e00\u6b21\u524d\u5411\u4f20\u64ad\u3002", "result": "\u5728\u7ed3\u6784\u5316\u63a8\u7406\u4efb\u52a1\uff08\u7b97\u672fGSM8K\u3001\u903b\u8f91\u63a8\u7406PrOntoQA\u3001\u89c4\u5212Blocks World\uff09\u4e0a\uff0cCSR\u76f8\u6bd4\u6807\u51c6\u5fae\u8c03\u548c\u8fc7\u7a0b\u76d1\u7763\uff0c\u5c06\u53ef\u4fe1\u5ea6\u63d0\u9ad8\u4e86\u9ad8\u8fbe70\u4e2a\u767e\u5206\u70b9\uff0c\u4ec5\u5e26\u6765\u8f7b\u5fae\u51c6\u786e\u7387\u635f\u5931\u3002\u5b66\u4e60\u5230\u7684\u654f\u611f\u6027\u53ef\u6cdb\u5316\u5230\u66f4\u5927\u6a21\u578b\uff0c\u5e76\u4e0e\u81ea\u4e00\u81f4\u6027\u7b49\u63a8\u7406\u65f6\u65b9\u6cd5\u534f\u540c\u5de5\u4f5c\u3002", "conclusion": "CSR\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u8bad\u7ec3\u76ee\u6807\uff0c\u80fd\u6709\u6548\u63d0\u9ad8\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u7684\u53ef\u4fe1\u5ea6\uff0c\u901a\u8fc7\u53cd\u4e8b\u5b9e\u5e72\u9884\u5f3a\u5236\u63a8\u7406\u4e0e\u8f93\u51fa\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u5728\u591a\u4e2a\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\u4e14\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u6027\u3002"}}
{"id": "2509.02387", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02387", "abs": "https://arxiv.org/abs/2509.02387", "authors": ["Rye Stahle-Smith", "Rasha Karakchi"], "title": "Real-time ML-based Defense Against Malicious Payload in Reconfigurable Embedded Systems", "comment": "This paper is submitted at Supercomputing (SC'25)", "summary": "The growing use of FPGAs in reconfigurable systems introducessecurity risks\nthrough malicious bitstreams that could cause denial-of-service (DoS), data\nleakage, or covert attacks. We investigated chip-level hardware malicious\npayload in embedded systems and proposed a supervised machine learning method\nto detect malicious bitstreams via static byte-level features. Our approach\ndiverges from existing methods by analyzing bitstreams directly at the binary\nlevel, enabling real-time detection without requiring access to source code or\nnetlists. Bitstreams were sourced from state-of-the-art (SOTA) benchmarks and\nre-engineered to target the Xilinx PYNQ-Z1 FPGA Development Board. Our dataset\nincluded 122 samples of benign and malicious configurations. The data were\nvectorized using byte frequency analysis, compressed using TSVD, and balanced\nusing SMOTE to address class imbalance. The evaluated classifiers demonstrated\nthat Random Forest achieved a macro F1-score of 0.97, underscoring the\nviability of real-time Trojan detection on resource-constrained systems. The\nfinal model was serialized and successfully deployed via PYNQ to enable\nintegrated bitstream analysis.", "AI": {"tldr": "\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u76f4\u63a5\u5206\u6790FPGA\u4f4d\u6d41\u6587\u4ef6\u7684\u5b57\u8282\u7ea7\u7279\u5f81\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u6076\u610f\u4ee3\u7801\u68c0\u6d4b\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u7cfb\u7edf\u4e0a\u8fbe\u5230\u4e860.97\u7684F1\u5206\u6570\u3002", "motivation": "FPGA\u5728\u53ef\u91cd\u6784\u7cfb\u7edf\u4e2d\u7684\u5e7f\u6cdb\u4f7f\u7528\u5e26\u6765\u4e86\u5b89\u5168\u98ce\u9669\uff0c\u6076\u610f\u4f4d\u6d41\u53ef\u80fd\u5bfc\u81f4\u62d2\u7edd\u670d\u52a1\u3001\u6570\u636e\u6cc4\u6f0f\u6216\u9690\u85cf\u653b\u51fb\u3002\u9700\u8981\u4e00\u79cd\u65e0\u9700\u6e90\u4ee3\u7801\u6216\u7f51\u8868\u7684\u5b9e\u65f6\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b57\u8282\u9891\u7387\u5206\u6790\u5c06\u4f4d\u6d41\u5411\u91cf\u5316\uff0c\u4f7f\u7528TSVD\u8fdb\u884c\u538b\u7f29\u548cSMOTE\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002\u57fa\u4e8eXilinx PYNQ-Z1\u5f00\u53d1\u677f\u6784\u5efa\u6570\u636e\u96c6\uff0c\u5305\u542b122\u4e2a\u5584\u610f\u548c\u6076\u610f\u6837\u672c\u3002", "result": "Random Forest\u5206\u7c7b\u5668\u8fbe\u5230\u4e86\u5b8f\u89c2F1\u5206\u65700.97\uff0c\u663e\u793a\u51fa\u5728\u8d44\u6e90\u53d7\u9650\u7cfb\u7edf\u4e0a\u5b9e\u73b0\u5b9e\u65f6\u7279\u6f0f\u7a0b\u68c0\u6d4b\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u4e0d\u4f9d\u8d56\u6e90\u4ee3\u7801\u7684\u60c5\u51b5\u4e0b\u901a\u8fc7\u4e8c\u8fdb\u5236\u5206\u6790\u6709\u6548\u68c0\u6d4b\u6076\u610f\u4f4d\u6d41\uff0c\u6700\u7ec8\u6a21\u578b\u6210\u529f\u90e8\u7f72\u5230PYNQ\u5e73\u53f0\u4e0a\u5b9e\u73b0\u96c6\u6210\u5316\u5206\u6790\u3002"}}
{"id": "2509.01576", "categories": ["cs.AI", "cs.CY", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.01576", "abs": "https://arxiv.org/abs/2509.01576", "authors": ["Julian Gerald Dcruz", "Argyrios Zolotas", "Niall Ross Greenwood", "Miguel Arana-Catania"], "title": "Structured AI Decision-Making in Disaster Management", "comment": "40 pages, 14 figures, 16 tables. To be published in Nature Scientific\n  Reports", "summary": "With artificial intelligence (AI) being applied to bring autonomy to\ndecision-making in safety-critical domains such as the ones typified in the\naerospace and emergency-response services, there has been a call to address the\nethical implications of structuring those decisions, so they remain reliable\nand justifiable when human lives are at stake. This paper contributes to\naddressing the challenge of decision-making by proposing a structured\ndecision-making framework as a foundational step towards responsible AI. The\nproposed structured decision-making framework is implemented in autonomous\ndecision-making, specifically within disaster management. By introducing\nconcepts of Enabler agents, Levels and Scenarios, the proposed framework's\nperformance is evaluated against systems relying solely on judgement-based\ninsights, as well as human operators who have disaster experience: victims,\nvolunteers, and stakeholders. The results demonstrate that the structured\ndecision-making framework achieves 60.94% greater stability in consistently\naccurate decisions across multiple Scenarios, compared to judgement-based\nsystems. Moreover, the study shows that the proposed framework outperforms\nhuman operators with a 38.93% higher accuracy across various Scenarios. These\nfindings demonstrate the promise of the structured decision-making framework\nfor building more reliable autonomous AI applications in safety-critical\ncontexts.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u6784\u5316\u51b3\u7b56\u6846\u67b6\uff0c\u4f5c\u4e3a\u53ef\u9760\u81ea\u4e3bAI\u7684\u57fa\u7840\uff0c\u5728\u707e\u96be\u7ba1\u7406\u9886\u57df\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u8868\u73b0\u51fa\u6bd4\u4f18\u5316\u7cfb\u7edf\u548c\u4eba\u7c7b\u8fd0\u8425\u5546\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u89e3\u51b3\u5b89\u5168\u5173\u952e\u9886\u57df\u4e2dAI\u81ea\u4e3b\u51b3\u7b56\u7684\u4f26\u7406\u6311\u6218\uff0c\u786e\u4fdd\u51b3\u7b56\u7684\u53ef\u9760\u6027\u548c\u53ef\u8bf4\u660e\u6027\uff0c\u7279\u522b\u662f\u5728\u6d89\u53ca\u4eba\u547d\u5b89\u5168\u7684\u573a\u666f\u4e2d\u3002", "method": "\u63d0\u51fa\u7ed3\u6784\u5316\u51b3\u7b56\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u4f7f\u80fd\u8005\u4ee3\u7406\uff08Enabler agents\uff09\u3001\u7ea7\u522b\u548c\u573a\u666f\u7b49\u6982\u5ff5\uff0c\u5e76\u5728\u707e\u96be\u7ba1\u7406\u9886\u57df\u5b9e\u65bd\u3002\u4e0e\u4f18\u5316\u7cfb\u7edf\u548c\u4eba\u7c7b\u8fd0\u8425\u5546\u8fdb\u884c\u5bf9\u6bd4\u8bc4\u4f30\u3002", "result": "\u7ed3\u6784\u5316\u51b3\u7b56\u6846\u67b6\u5728\u591a\u4e2a\u573a\u666f\u4e2d\u5b9e\u73b0\u4e8660.94%\u66f4\u9ad8\u7684\u7a33\u5b9a\u6027\uff08\u4e00\u8d28\u51c6\u786e\u51b3\u7b56\uff09\uff0c\u8d85\u8fc7\u4f18\u5316\u7cfb\u7edf\u3002\u540c\u65f6\u6bd4\u4eba\u7c7b\u8fd0\u8425\u5546\u51c6\u786e\u6027\u9ad8\u51fa38.93%\u3002", "conclusion": "\u8be5\u7ed3\u6784\u5316\u51b3\u7b56\u6846\u67b6\u4e3a\u5efa\u8bbe\u66f4\u53ef\u9760\u7684\u81ea\u4e3bAI\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u57fa\u7840\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5b89\u5168\u5173\u952e\u9886\u57df\u3002"}}
{"id": "2509.02411", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02411", "abs": "https://arxiv.org/abs/2509.02411", "authors": ["Honghui Xu", "Kaiyang Li", "Wei Chen", "Danyang Zheng", "Zhiyuan Li", "Zhipeng Cai"], "title": "A Survey: Towards Privacy and Security in Mobile Large Language Models", "comment": null, "summary": "Mobile Large Language Models (LLMs) are revolutionizing diverse fields such\nas healthcare, finance, and education with their ability to perform advanced\nnatural language processing tasks on-the-go. However, the deployment of these\nmodels in mobile and edge environments introduces significant challenges\nrelated to privacy and security due to their resource-intensive nature and the\nsensitivity of the data they process. This survey provides a comprehensive\noverview of privacy and security issues associated with mobile LLMs,\nsystematically categorizing existing solutions such as differential privacy,\nfederated learning, and prompt encryption. Furthermore, we analyze\nvulnerabilities unique to mobile LLMs, including adversarial attacks,\nmembership inference, and side-channel attacks, offering an in-depth comparison\nof their effectiveness and limitations. Despite recent advancements, mobile\nLLMs face unique hurdles in achieving robust security while maintaining\nefficiency in resource-constrained environments. To bridge this gap, we propose\npotential applications, discuss open challenges, and suggest future research\ndirections, paving the way for the development of trustworthy,\nprivacy-compliant, and scalable mobile LLM systems.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7cfb\u7edf\u6027\u8bc4\u4f30\u4e86\u79fb\u52a8\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9690\u79c1\u5b89\u5168\u6311\u6218\uff0c\u5206\u6790\u4e86\u5dee\u5206\u9690\u79c1\u3001\u8054\u90a6\u5b66\u4e60\u7b49\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u79fb\u52a8LLM\u5728\u533b\u7597\u3001\u91d1\u878d\u7b49\u9886\u57df\u5e26\u6765\u4fbf\u6377\u5904\u7406\u80fd\u529b\uff0c\u4f46\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u9762\u4e34\u7740\u4e25\u91cd\u7684\u9690\u79c1\u5b89\u5168\u6311\u6218\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u8c03\u67e5\u548c\u5206\u6790\uff0c\u5bf9\u79fb\u52a8LLM\u7684\u9690\u79c1\u5b89\u5168\u95ee\u9898\u8fdb\u884c\u5206\u7c7b\uff0c\u6bd4\u8f83\u4e0d\u540c\u89e3\u51b3\u65b9\u6848\u7684\u6548\u679c\u548c\u5c40\u9650\u6027\u3002", "result": "\u8bc6\u522b\u4e86\u5bf9\u6297\u6027\u653b\u51fb\u3001\u6210\u5458\u63a8\u65ad\u7b49\u72ec\u7279\u6f0f\u6d1e\uff0c\u5e76\u5bf9\u5404\u79cd\u4fdd\u62a4\u6280\u672f\u8fdb\u884c\u4e86\u8be6\u7ec6\u8bc4\u4f30\u3002", "conclusion": "\u867d\u6709\u8fdb\u5c55\uff0c\u4f46\u79fb\u52a8LLM\u4ecd\u9762\u4e34\u6548\u7387\u4e0e\u5b89\u5168\u7684\u5e73\u8861\u6311\u6218\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u6765\u5efa\u8bbe\u53ef\u4fe1\u8d56\u7684\u79fb\u52a8LLM\u7cfb\u7edf\u3002"}}
{"id": "2509.01619", "categories": ["cs.AI", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.01619", "abs": "https://arxiv.org/abs/2509.01619", "authors": ["Abhinav Kumar", "Jaechul Roh", "Ali Naseh", "Amir Houmansadr", "Eugene Bagdasarian"], "title": "Throttling Web Agents Using Reasoning Gates", "comment": null, "summary": "AI web agents use Internet resources at far greater speed, scale, and\ncomplexity -- changing how users and services interact. Deployed maliciously or\nerroneously, these agents could overload content providers. At the same time,\nweb agents can bypass CAPTCHAs and other defenses by mimicking user behavior or\nflood authentication systems with fake accounts. Yet providers must protect\ntheir services and content from denial-of-service attacks and scraping by web\nagents. In this paper, we design a framework that imposes tunable costs on\nagents before providing access to resources; we call this Web Agent Throttling.\nWe start by formalizing Throttling Gates as challenges issued to an agent that\nare asymmetric, scalable, robust, and compatible with any agent. Focusing on a\ncommon component -- the language model -- we require the agent to solve\nreasoning puzzles, thereby incurring excessive token-generation costs. However,\nwe find that using existing puzzles, e.g., coding or math, as throttling gates\nfails to satisfy our properties. To address this, we introduce rebus-based\nReasoning Gates, synthetic text puzzles that require multi-hop reasoning over\nworld knowledge (thereby throttling an agent's model). We design a scalable\ngeneration and verification protocol for such reasoning gates. Our framework\nachieves computational asymmetry, i.e., the response-generation cost is 9.2x\nhigher than the generation cost for SOTA models. We further deploy reasoning\ngates on a custom website and Model Context Protocol (MCP) servers and evaluate\nwith real-world web agents. Finally, we discuss the limitations and\nenvironmental impact of real-world deployment of our framework.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u8c03\u6570\u636e\u7684Web\u7ec4\u4ef6\u9650\u901f\u6846\u67b6\uff0c\u901a\u8fc7\u8981\u6c42AI\u7f51\u7edc\u4ee3\u7406\u89e3\u51b3\u9700\u8981\u591a\u8df3\u63a8\u7406\u7684\u8c1c\u9898\u6765\u589e\u52a0\u5176\u8ba1\u7b97\u6210\u672c\uff0c\u4ece\u800c\u9632\u6b62\u6076\u610f\u6216\u9519\u8bef\u7684\u7f51\u7edc\u4ee3\u7406\u653b\u51fb", "motivation": "\u968f\u7740AI\u7f51\u7edc\u4ee3\u7406\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u5b83\u4eec\u53ef\u80fd\u4f1a\u8fc7\u8f7d\u5185\u5bb9\u63d0\u4f9b\u5546\u6216\u7ed5\u8fc7CAPTCHA\u7b49\u9632\u5fa1\u673a\u5236\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u7f51\u7edc\u4ee3\u7406\u9650\u901f\u65b9\u6848", "method": "\u8bbe\u8ba1\u4e86\u53ef\u8c03\u6570\u636e\u7684Throttling Gates\u6846\u67b6\uff0c\u91c7\u7528rebus\u57fa\u7840\u7684\u63a8\u7406\u95e8\uff0c\u8981\u6c42\u4ee3\u7406\u89e3\u51b3\u9700\u8981\u591a\u8df3\u63a8\u7406\u548c\u4e16\u754c\u77e5\u8bc6\u7684\u6587\u672c\u8c1c\u9898\uff0c\u4ee5\u589e\u52a0\u5176token\u751f\u6210\u6210\u672c", "result": "\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u8ba1\u7b97\u4e0d\u5bf9\u79f0\u6027\uff0c\u54cd\u5e94\u751f\u6210\u6210\u672c\u6bd4SOTA\u6a21\u578b\u7684\u751f\u6210\u6210\u672c\u9ad8\u51fa9.2\u500d\uff0c\u5e76\u5728\u81ea\u5b9a\u4e49\u7f51\u7ad9\u548cMCP\u670d\u52a1\u5668\u4e0a\u90e8\u7f72\u9a8c\u8bc1", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u5730\u901a\u8fc7\u589e\u52a0\u8ba1\u7b97\u6210\u672c\u6765\u9650\u5236\u7f51\u7edc\u4ee3\u7406\uff0c\u4f46\u9700\u8981\u8003\u8651\u5176\u5b9e\u9645\u90e8\u7f72\u7684\u9650\u5236\u548c\u73af\u5883\u5f71\u54cd"}}
{"id": "2509.02412", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.02412", "abs": "https://arxiv.org/abs/2509.02412", "authors": ["Wenhao Chen", "Morris Chang", "Witawas Srisa-an", "Yong Guan"], "title": "APEX: Automatic Event Sequence Generation for Android Applications", "comment": null, "summary": "Due to the event driven nature and the versatility of GUI designs in Android\nprograms, it is challenging to generate event sequences with adequate code\ncoverage within a reasonable time. A common approach to handle this issue is to\nrely on GUI models to generate event sequences. These sequences can be\neffective in covering GUI states, but inconsistent in exposing program\nbehaviors that require specific inputs. A major obstacle to generate such\nspecific inputs is the lack of a systematic GUI exploration process to\naccommodate the analysis requirements. In this paper, we introduce Android Path\nExplorer (APEX), a systematic input generation framework using concolic\nexecution. APEX addresses the limitations of model-based sequence generation by\nusing concolic execution to discover the data dependencies of GUI state\ntransitions. Moreover, concolic execution is also used to prioritize events\nduring the exploration of GUI, which leads to a more robust model and accurate\ninput generation. The key novelty of APEX is that concolic execution is not\nonly used to construct event sequences, but also used to traverse the GUI more\nsystematically. As such, our experimental results show that APEX can be used to\ngenerate a set of event sequences that achieve high code coverage, as well as\nevent sequences that reach specific targets.", "AI": {"tldr": "APEX\u662f\u4e00\u4e2a\u57fa\u4e8e\u7b26\u53f7\u6267\u884c\u7684Android GUI\u6d4b\u8bd5\u6846\u67b6\uff0c\u80fd\u591f\u751f\u6210\u9ad8\u4ee3\u7801\u8986\u76d6\u7387\u7684\u4e8b\u4ef6\u5e8f\u5217\u548c\u7279\u5b9a\u76ee\u6807\u7684\u4e8b\u4ef6\u5e8f\u5217", "motivation": "Android GUI\u6d4b\u8bd5\u9762\u4e34\u4e8b\u4ef6\u9a71\u52a8\u548c\u754c\u9762\u8bbe\u8ba1\u591a\u6837\u6027\u7684\u6311\u6218\uff0c\u4f20\u7edf\u57fa\u4e8e\u6a21\u578b\u7684\u65b9\u6cd5\u5728\u751f\u6210\u7279\u5b9a\u8f93\u5165\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027", "method": "\u4f7f\u7528\u7b26\u53f7\u6267\u884c\u6280\u672f\u53d1\u73b0GUI\u72b6\u6001\u8f6c\u6362\u7684\u6570\u636e\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u5728GUI\u63a2\u7d22\u8fc7\u7a0b\u4e2d\u4f18\u5148\u5904\u7406\u4e8b\u4ef6\uff0c\u6784\u5efa\u66f4\u5065\u58ee\u7684\u6a21\u578b\u548c\u51c6\u786e\u7684\u8f93\u5165\u751f\u6210", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eAPEX\u80fd\u591f\u751f\u6210\u5b9e\u73b0\u9ad8\u4ee3\u7801\u8986\u76d6\u7387\u7684\u4e8b\u4ef6\u5e8f\u5217\uff0c\u4ee5\u53ca\u8fbe\u5230\u7279\u5b9a\u76ee\u6807\u7684\u4e8b\u4ef6\u5e8f\u5217", "conclusion": "APEX\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u7b26\u53f7\u6267\u884c\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86Android GUI\u6d4b\u8bd5\u4e2d\u8f93\u5165\u751f\u6210\u7684\u6311\u6218\uff0c\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u548c\u9488\u5bf9\u6027\u7684\u6d4b\u8bd5\u80fd\u529b"}}
{"id": "2509.01631", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.01631", "abs": "https://arxiv.org/abs/2509.01631", "authors": ["Chongwen Zhao", "Kaizhu Huang"], "title": "Unraveling LLM Jailbreaks Through Safety Knowledge Neurons", "comment": "10 pages, 6 figures", "summary": "Large Language Models (LLMs) are increasingly attracting attention in various\napplications. Nonetheless, there is a growing concern as some users attempt to\nexploit these models for malicious purposes, including the synthesis of\ncontrolled substances and the propagation of disinformation, a technique known\nas \"Jailbreak.\" While some studies have achieved defenses against jailbreak\nattacks by modifying output distributions or detecting harmful content, the\nexact rationale still remains elusive. In this work, we present a novel\nneuron-level interpretability method that focuses on the role of safety-related\nknowledge neurons. Unlike existing approaches, our method projects the model's\ninternal representation into a more consistent and interpretable vocabulary\nspace. We then show that adjusting the activation of safety-related neurons can\neffectively control the model's behavior with a mean ASR higher than 97%.\nBuilding on this insight, we propose SafeTuning, a fine-tuning strategy that\nreinforces safety-critical neurons to improve model robustness against\njailbreaks. SafeTuning consistently reduces attack success rates across\nmultiple LLMs and outperforms all four baseline defenses. These findings offer\na new perspective on understanding and defending against jailbreak attacks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u795e\u7ecf\u5143\u7ea7\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522b\u5b89\u5168\u76f8\u5173\u795e\u7ecf\u5143\u5e76\u8c03\u6574\u5176\u6fc0\u6d3b\u6765\u63a7\u5236LLM\u884c\u4e3a\uff0c\u8fdb\u800c\u5f00\u53d1\u4e86SafeTuning\u5fae\u8c03\u7b56\u7565\u6765\u589e\u5f3a\u6a21\u578b\u5bf9\u8d8a\u72f1\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u968f\u7740LLM\u5728\u5404\u79cd\u5e94\u7528\u4e2d\u7684\u5e7f\u6cdb\u4f7f\u7528\uff0c\u5b58\u5728\u7528\u6237\u8bd5\u56fe\u5229\u7528\u8fd9\u4e9b\u6a21\u578b\u8fdb\u884c\u6076\u610f\u76ee\u7684\uff08\u5982\u5408\u6210\u53d7\u63a7\u7269\u8d28\u548c\u4f20\u64ad\u865a\u5047\u4fe1\u606f\uff09\u7684\u62c5\u5fe7\uff0c\u5373\"\u8d8a\u72f1\"\u653b\u51fb\u3002\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u867d\u7136\u6709\u6548\uff0c\u4f46\u5176\u786e\u5207\u539f\u7406\u4ecd\u4e0d\u6e05\u695a\u3002", "method": "\u63d0\u51fa\u795e\u7ecf\u5143\u7ea7\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff0c\u5c06\u6a21\u578b\u5185\u90e8\u8868\u793a\u6295\u5f71\u5230\u66f4\u4e00\u81f4\u548c\u53ef\u89e3\u91ca\u7684\u8bcd\u6c47\u7a7a\u95f4\uff0c\u8bc6\u522b\u5b89\u5168\u76f8\u5173\u795e\u7ecf\u5143\u3002\u901a\u8fc7\u8c03\u6574\u8fd9\u4e9b\u795e\u7ecf\u5143\u7684\u6fc0\u6d3b\u6765\u63a7\u5236\u6a21\u578b\u884c\u4e3a\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f00\u53d1SafeTuning\u5fae\u8c03\u7b56\u7565\u6765\u5f3a\u5316\u5b89\u5168\u5173\u952e\u795e\u7ecf\u5143\u3002", "result": "\u8c03\u6574\u5b89\u5168\u76f8\u5173\u795e\u7ecf\u5143\u6fc0\u6d3b\u53ef\u6709\u6548\u63a7\u5236\u6a21\u578b\u884c\u4e3a\uff0c\u5e73\u5747\u653b\u51fb\u6210\u529f\u7387\uff08ASR\uff09\u9ad8\u4e8e97%\u3002SafeTuning\u5728\u591a\u4e2aLLM\u4e0a\u6301\u7eed\u964d\u4f4e\u653b\u51fb\u6210\u529f\u7387\uff0c\u4f18\u4e8e\u6240\u6709\u56db\u4e2a\u57fa\u7ebf\u9632\u5fa1\u65b9\u6cd5\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u7406\u89e3\u548c\u9632\u5fa1\u8d8a\u72f1\u653b\u51fb\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u901a\u8fc7\u795e\u7ecf\u5143\u7ea7\u5206\u6790\u63ed\u793a\u4e86\u5b89\u5168\u673a\u5236\u7684\u5185\u5728\u539f\u7406\uff0c\u5e76\u5f00\u53d1\u4e86\u6709\u6548\u7684\u9632\u5fa1\u7b56\u7565\u3002"}}
{"id": "2509.02413", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.02413", "abs": "https://arxiv.org/abs/2509.02413", "authors": ["Edoardo Marangone", "Eugenio Nerio Nemmi", "Daniele Friolo", "Giuseppe Ateniese", "Ingo Weber", "Claudio Di Ciccio"], "title": "Enabling decision support over confidential data", "comment": null, "summary": "Enabling automated decision-making processes by leveraging data-driven\nanalysis is a core goal of Decision Support Systems (DSSs). In multi-party\nscenarios where decisions rely on distributed and sensitive data, though,\nensuring confidentiality, verifiability, transparency, integrity, and\nconsistency at once remains an open challenge for DSSs. To tackle this\nmulti-faceted problem, we propose the Secure Platform for Automated decision\nRules via Trusted Applications (SPARTA) approach. By leveraging Trusted\nExecution Environments (TEEs) at its core, SPARTA ensures that the decision\nlogic and the data remain protected. To guarantee transparency and consistency\nof the decision process, SPARTA encodes decision rules into verifiable software\nobjects deployed within TEEs. To maintain the confidentiality of the outcomes\nwhile keeping the information integrity, SPARTA employs cryptography techniques\non notarized data based on user-definable access policies. Based on experiments\nconducted on public benchmarks and synthetic data, we find our approach to be\npractically applicable and scalable.", "AI": {"tldr": "\u901a\u8fc7\u4fe1\u4efb\u6267\u884c\u73af\u5883(TEE)\u548c\u52a0\u5bc6\u6280\u672f\u6784\u5efa\u4e86\u4e00\u79cd\u53ef\u9a8c\u8bc1\u3001\u900f\u660e\u3001\u4fdd\u6301\u6570\u636e\u4fdd\u5bc6\u6027\u7684\u81ea\u52a8\u5316\u51b3\u7b56\u652f\u6301\u7cfb\u7edfSPARTA", "motivation": "\u89e3\u51b3\u591a\u65b9\u573a\u666f\u4e0b\u5206\u5e03\u5f0f\u654f\u611f\u6570\u636e\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u540c\u65f6\u786e\u4fdd\u4fdd\u5bc6\u6027\u3001\u53ef\u9a8c\u8bc1\u6027\u3001\u900f\u660e\u6027\u3001\u5b8c\u6574\u6027\u548c\u4e00\u81f4\u6027\u7684\u6311\u6218", "method": "\u91c7\u7528\u4fe1\u4efb\u6267\u884c\u73af\u5883(TEE)\u4fdd\u62a4\u51b3\u7b56\u903b\u8f91\u548c\u6570\u636e\uff0c\u5c06\u51b3\u7b56\u89c4\u5219\u7f16\u7801\u4e3a\u53ef\u9a8c\u8bc1\u8f6f\u4ef6\u5bf9\u8c61\uff0c\u4f7f\u7528\u52a0\u5bc6\u6280\u672f\u548c\u7528\u6237\u53ef\u5b9a\u4e49\u8bbf\u95ee\u7b56\u7565\u6765\u7ef4\u6301\u7ed3\u679c\u4fdd\u5bc6\u6027\u548c\u4fe1\u606f\u5b8c\u6574\u6027", "result": "\u5728\u516c\u5f00\u6d4b\u8bd5\u96c6\u548c\u7efc\u5408\u6570\u636e\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027", "conclusion": "SPARTA\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6848\uff0c\u80fd\u591f\u5728\u591a\u65b9\u5206\u5e03\u5f0f\u654f\u611f\u6570\u636e\u51b3\u7b56\u573a\u666f\u4e2d\u540c\u65f6\u6ee1\u8db3\u591a\u91cd\u5b89\u5168\u548c\u53ef\u9760\u6027\u8981\u6c42"}}
{"id": "2509.01659", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.01659", "abs": "https://arxiv.org/abs/2509.01659", "authors": ["Jiahao Qiu", "Jingzhe Shi", "Xinzhe Juan", "Zelin Zhao", "Jiayi Geng", "Shilong Liu", "Hongru Wang", "Sanfeng Wu", "Mengdi Wang"], "title": "Physics Supernova: AI Agent Matches Elite Gold Medalists at IPhO 2025", "comment": null, "summary": "Physics provides fundamental laws that describe and predict the natural\nworld. AI systems aspiring toward more general, real-world intelligence must\ntherefore demonstrate strong physics problem-solving abilities: to formulate\nand apply physical laws for explaining and predicting physical processes. The\nInternational Physics Olympiad (IPhO)--the world's most prestigious physics\ncompetition--offers a rigorous benchmark for this purpose. We introduce Physics\nSupernova, an AI agent system with superior physics problem-solving abilities\nthat match elite IPhO gold medalists. In IPhO 2025 theory problems, Physics\nSupernova attains 23.5/30 points, ranking 14th of 406 contestants and\nsurpassing the median performance of human gold medalists. We extensively\nanalyzed Physics Supernova's capabilities and flexibility across diverse\nphysics tasks. These results show that principled tool integration within agent\nsystems can deliver competitive improvements in solving challenging science\nproblems. The codes are available at\nhttps://github.com/CharlesQ9/Physics-Supernova.", "AI": {"tldr": "Physics Supernova\u662f\u4e00\u4e2aAI\u7269\u7406\u95ee\u9898\u89e3\u51b3\u7cfb\u7edf\uff0c\u5728\u56fd\u9645\u7269\u7406\u5965\u6797\u5339\u514b\u7ade\u8d5b(IPhO 2025)\u7406\u8bba\u9898\u4e2d\u83b7\u5f9723.5/30\u5206\uff0c\u6392\u540d\u7b2c14\u4f4d\uff0c\u8d85\u8d8a\u4e86\u4eba\u7c7b\u91d1\u724c\u5f97\u4e3b\u7684\u4e2d\u4f4d\u6570\u8868\u73b0\u3002", "motivation": "\u7269\u7406\u63d0\u4f9b\u4e86\u63cf\u8ff0\u548c\u9884\u6d4b\u81ea\u7136\u4e16\u754c\u7684\u57fa\u672c\u5b9a\u5f8b\uff0cAI\u7cfb\u7edf\u8981\u5c55\u73b0\u771f\u6b63\u7684\u901a\u7528\u667a\u80fd\u5fc5\u987b\u5177\u5907\u5f3a\u5927\u7684\u7269\u7406\u95ee\u9898\u89e3\u51b3\u80fd\u529b\uff0c\u800c\u56fd\u9645\u7269\u7406\u5965\u6797\u5339\u514b\u7ade\u8d5b\u4e3a\u6b64\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "\u5f00\u53d1\u4e86Physics Supernova AI\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u539f\u5219\u6027\u7684\u5de5\u5177\u96c6\u6210\u65b9\u6cd5\u6765\u63d0\u5347\u89e3\u51b3\u590d\u6742\u79d1\u5b66\u95ee\u9898\u7684\u80fd\u529b\u3002", "result": "\u5728IPhO 2025\u7406\u8bba\u9898\u4e2d\u83b7\u5f9723.5/30\u5206\uff0c\u5728406\u540d\u53c2\u8d5b\u8005\u4e2d\u6392\u540d\u7b2c14\u4f4d\uff0c\u8d85\u8d8a\u4e86\u4eba\u7c7b\u91d1\u724c\u5f97\u4e3b\u7684\u4e2d\u4f4d\u6570\u8868\u73b0\uff0c\u5c55\u73b0\u4e86\u5353\u8d8a\u7684\u7269\u7406\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u4ee3\u7406\u7cfb\u7edf\u4e2d\u8fdb\u884c\u539f\u5219\u6027\u7684\u5de5\u5177\u96c6\u6210\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u89e3\u51b3\u6311\u6218\u6027\u79d1\u5b66\u95ee\u9898\u7684\u80fd\u529b\uff0cPhysics Supernova\u5c55\u73b0\u4e86\u4e0e\u9876\u5c16\u7269\u7406\u7ade\u8d5b\u9009\u624b\u76f8\u5ab2\u7f8e\u7684\u7269\u7406\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2509.01716", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.01716", "abs": "https://arxiv.org/abs/2509.01716", "authors": ["Rui Zhao", "Vladyslav Melnychuk", "Jun Zhao", "Jesse Wright", "Nigel Shadbolt"], "title": "An LLM-enabled semantic-centric framework to consume privacy policies", "comment": null, "summary": "In modern times, people have numerous online accounts, but they rarely read\nthe Terms of Service or Privacy Policy of those sites, despite claiming\notherwise, due to the practical difficulty in comprehending them. The mist of\ndata privacy practices forms a major barrier for user-centred Web approaches,\nand for data sharing and reusing in an agentic world. Existing research\nproposed methods for using formal languages and reasoning for verifying the\ncompliance of a specified policy, as a potential cure for ignoring privacy\npolicies. However, a critical gap remains in the creation or acquisition of\nsuch formal policies at scale. We present a semantic-centric approach for using\nstate-of-the-art large language models (LLM), to automatically identify key\ninformation about privacy practices from privacy policies, and construct\n$\\mathit{Pr}^2\\mathit{Graph}$, knowledge graph with grounding from Data Privacy\nVocabulary (DPV) for privacy practices, to support downstream tasks. Along with\nthe pipeline, the $\\mathit{Pr}^2\\mathit{Graph}$ for the top-100 popular\nwebsites is also released as a public resource, by using the pipeline for\nanalysis. We also demonstrate how the $\\mathit{Pr}^2\\mathit{Graph}$ can be used\nto support downstream tasks by constructing formal policy representations such\nas Open Digital Right Language (ODRL) or perennial semantic Data Terms of Use\n(psDToU). To evaluate the technology capability, we enriched the Policy-IE\ndataset by employing legal experts to create custom annotations. We benchmarked\nthe performance of different large language models for our pipeline and\nverified their capabilities. Overall, they shed light on the possibility of\nlarge-scale analysis of online services' privacy practices, as a promising\ndirection to audit the Web and the Internet. We release all datasets and source\ncode as public resources to facilitate reuse and improvement.", "AI": {"tldr": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u4ece\u9690\u79c1\u653f\u7b56\u4e2d\u63d0\u53d6\u5173\u952e\u4fe1\u606f\uff0c\u6784\u5efa\u57fa\u4e8eDPV\u7684\u77e5\u8bc6\u56fe\u8c31Pr\u00b2Graph\uff0c\u652f\u6301\u5927\u89c4\u6a21\u9690\u79c1\u653f\u7b56\u5206\u6790\u548c\u4e0b\u6e38\u4efb\u52a1", "motivation": "\u7528\u6237\u5e38\u5ffd\u7565\u7f51\u7ad9\u9690\u79c1\u653f\u7b56\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5927\u89c4\u6a21\u751f\u6210\u5f62\u5f0f\u5316\u653f\u7b56\uff0c\u5f71\u54cd\u6570\u636e\u9690\u79c1\u4fdd\u62a4\u548c\u6570\u636e\u5171\u4eab", "method": "\u91c7\u7528\u8bed\u4e49\u4e2d\u5fc3\u65b9\u6cd5\uff0c\u5229\u7528\u5148\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u8bc6\u522b\u9690\u79c1\u653f\u7b56\u5173\u952e\u4fe1\u606f\uff0c\u6784\u5efa\u57fa\u4e8e\u6570\u636e\u9690\u79c1\u8bcd\u6c47(DPV)\u7684\u77e5\u8bc6\u56fe\u8c31Pr\u00b2Graph", "result": "\u53d1\u5e03\u4e86\u524d100\u6d41\u884c\u7f51\u7ad9\u7684Pr\u00b2Graph\u8d44\u6e90\uff0c\u652f\u6301ODRL\u548cpsDToU\u7b49\u5f62\u5f0f\u653f\u7b56\u8868\u793a\u6784\u5efa\uff0c\u901a\u8fc7\u6cd5\u5f8b\u4e13\u5bb6\u6ce8\u91ca\u6269\u5145\u4e86Policy-IE\u6570\u636e\u96c6", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5927\u89c4\u6a21\u5206\u6790\u7f51\u7edc\u670d\u52a1\u9690\u79c1\u5b9e\u8df5\u63d0\u4f9b\u4e86\u53ef\u80fd\uff0c\u662f\u5ba1\u8ba1\u7f51\u7edc\u548c\u4e92\u8054\u7f51\u7684\u6709\u524d\u666f\u65b9\u5411\uff0c\u6240\u6709\u6570\u636e\u96c6\u548c\u6e90\u4ee3\u7801\u5df2\u5f00\u6e90"}}
{"id": "2509.01909", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.HC", "cs.SC"], "pdf": "https://arxiv.org/pdf/2509.01909", "abs": "https://arxiv.org/abs/2509.01909", "authors": ["Ranjie Duan", "Jiexi Liu", "Xiaojun Jia", "Shiji Zhao", "Ruoxi Cheng", "Fengxiang Wang", "Cheng Wei", "Yong Xie", "Chang Liu", "Defeng Li", "Yinpeng Dong", "Yichi Zhang", "Yuefeng Chen", "Chongwen Wang", "Xingjun Ma", "Xingxing Wei", "Yang Liu", "Hang Su", "Jun Zhu", "Xinfeng Li", "Yitong Sun", "Jie Zhang", "Jinzhao Hu", "Sha Xu", "Yitong Yang", "Jialing Tao", "Hui Xue"], "title": "Oyster-I: Beyond Refusal -- Constructive Safety Alignment for Responsible Language Models", "comment": "Technical Report", "summary": "Large language models (LLMs) typically deploy safety mechanisms to prevent\nharmful content generation. Most current approaches focus narrowly on risks\nposed by malicious actors, often framing risks as adversarial events and\nrelying on defensive refusals. However, in real-world settings, risks also come\nfrom non-malicious users seeking help while under psychological distress (e.g.,\nself-harm intentions). In such cases, the model's response can strongly\ninfluence the user's next actions. Simple refusals may lead them to repeat,\nescalate, or move to unsafe platforms, creating worse outcomes. We introduce\nConstructive Safety Alignment (CSA), a human-centric paradigm that protects\nagainst malicious misuse while actively guiding vulnerable users toward safe\nand helpful results. Implemented in Oyster-I (Oy1), CSA combines game-theoretic\nanticipation of user reactions, fine-grained risk boundary discovery, and\ninterpretable reasoning control, turning safety into a trust-building process.\nOy1 achieves state-of-the-art safety among open models while retaining high\ngeneral capabilities. On our Constructive Benchmark, it shows strong\nconstructive engagement, close to GPT-5, and unmatched robustness on the\nStrata-Sword jailbreak dataset, nearing GPT-o1 levels. By shifting from\nrefusal-first to guidance-first safety, CSA redefines the model-user\nrelationship, aiming for systems that are not just safe, but meaningfully\nhelpful. We release Oy1, code, and the benchmark to support responsible,\nuser-centered AI.", "AI": {"tldr": "\u63d0\u51fa\u4e86Constructive Safety Alignment (CSA)\u65b9\u6cd5\uff0c\u901a\u8fc7\u6e38\u620f\u7406\u8bba\u9884\u6d4b\u7528\u6237\u53cd\u5e94\u3001\u7ec6\u7c92\u5ea6\u98ce\u9669\u8fb9\u754c\u53d1\u73b0\u548c\u53ef\u89e3\u91ca\u63a8\u7406\u63a7\u5236\uff0c\u5c06\u5b89\u5168\u673a\u5236\u4ece\u7b80\u5355\u7684\u62d2\u7edd\u8f6c\u53d8\u4e3a\u4e3b\u52a8\u5f15\u5bfc\uff0c\u5728\u4fdd\u62a4\u6076\u610f\u6ee5\u7528\u7684\u540c\u65f6\u4e3a\u5fc3\u7406\u56f0\u6270\u7528\u6237\u63d0\u4f9b\u5efa\u8bbe\u6027\u5e2e\u52a9\u3002", "motivation": "\u73b0\u6709LLM\u5b89\u5168\u673a\u5236\u4e3b\u8981\u9488\u5bf9\u6076\u610f\u653b\u51fb\u8005\uff0c\u91c7\u7528\u9632\u5fa1\u6027\u62d2\u7edd\u7b56\u7565\uff0c\u4f46\u5ffd\u89c6\u4e86\u975e\u6076\u610f\u4f46\u5904\u4e8e\u5fc3\u7406\u56f0\u6270\u7684\u7528\u6237\u9700\u6c42\u3002\u7b80\u5355\u7684\u62d2\u7edd\u53ef\u80fd\u5bfc\u81f4\u7528\u6237\u91cd\u590d\u5c1d\u8bd5\u3001\u5347\u7ea7\u884c\u4e3a\u6216\u8f6c\u5411\u4e0d\u5b89\u5168\u5e73\u53f0\uff0c\u9020\u6210\u66f4\u4e25\u91cd\u540e\u679c\u3002", "method": "\u63d0\u51faConstructive Safety Alignment (CSA)\u8303\u5f0f\uff0c\u7ed3\u5408\u6e38\u620f\u7406\u8bba\u9884\u6d4b\u7528\u6237\u53cd\u5e94\u3001\u7ec6\u7c92\u5ea6\u98ce\u9669\u8fb9\u754c\u53d1\u73b0\u548c\u53ef\u89e3\u91ca\u63a8\u7406\u63a7\u5236\u3002\u5728Oyster-I (Oy1)\u6a21\u578b\u4e2d\u5b9e\u73b0\uff0c\u5c06\u5b89\u5168\u8f6c\u5316\u4e3a\u4fe1\u4efb\u5efa\u7acb\u8fc7\u7a0b\u3002", "result": "Oy1\u5728\u5f00\u6e90\u6a21\u578b\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u5b89\u5168\u6c34\u5e73\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u901a\u7528\u80fd\u529b\u3002\u5728Constructive Benchmark\u4e0a\u663e\u793a\u51fa\u63a5\u8fd1GPT-5\u7684\u5efa\u8bbe\u6027\u53c2\u4e0e\u5ea6\uff0c\u5728Strata-Sword\u8d8a\u72f1\u6570\u636e\u96c6\u4e0a\u5177\u6709\u63a5\u8fd1GPT-o1\u6c34\u5e73\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "CSA\u901a\u8fc7\u4ece\u62d2\u7edd\u4f18\u5148\u8f6c\u5411\u5f15\u5bfc\u4f18\u5148\u7684\u5b89\u5168\u7b56\u7565\uff0c\u91cd\u65b0\u5b9a\u4e49\u4e86\u6a21\u578b\u4e0e\u7528\u6237\u7684\u5173\u7cfb\uff0c\u65e8\u5728\u6784\u5efa\u4e0d\u4ec5\u5b89\u5168\u800c\u4e14\u6709\u610f\u4e49\u7684\u5e2e\u52a9\u6027\u7cfb\u7edf\u3002\u8be5\u65b9\u6cd5\u652f\u6301\u8d1f\u8d23\u4efb\u3001\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684AI\u53d1\u5c55\u3002"}}
{"id": "2509.01914", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.01914", "abs": "https://arxiv.org/abs/2509.01914", "authors": ["Ruijia Li", "Yuan-Hao Jiang", "Jiatong Wang", "Bo Jiang"], "title": "How Real Is AI Tutoring? Comparing Simulated and Human Dialogues in One-on-One Instruction", "comment": "Proceedings of the 33rd International Conference on Computers in\n  Education (ICCE 2025). Asia-Pacific Society for Computers in Education", "summary": "Heuristic and scaffolded teacher-student dialogues are widely regarded as\ncritical for fostering students' higher-order thinking and deep learning.\nHowever, large language models (LLMs) currently face challenges in generating\npedagogically rich interactions. This study systematically investigates the\nstructural and behavioral differences between AI-simulated and authentic human\ntutoring dialogues. We conducted a quantitative comparison using an\nInitiation-Response-Feedback (IRF) coding scheme and Epistemic Network Analysis\n(ENA). The results show that human dialogues are significantly superior to\ntheir AI counterparts in utterance length, as well as in questioning (I-Q) and\ngeneral feedback (F-F) behaviors. More importantly, ENA results reveal a\nfundamental divergence in interactional patterns: human dialogues are more\ncognitively guided and diverse, centered around a \"question-factual\nresponse-feedback\" teaching loop that clearly reflects pedagogical guidance and\nstudent-driven thinking; in contrast, simulated dialogues exhibit a pattern of\nstructural simplification and behavioral convergence, revolving around an\n\"explanation-simplistic response\" loop that is essentially a simple information\ntransfer between the teacher and student. These findings illuminate key\nlimitations in current AI-generated tutoring and provide empirical guidance for\ndesigning and evaluating more pedagogically effective generative educational\ndialogue systems.", "AI": {"tldr": "\u7814\u7a76\u7cfb\u7edf\u6bd4\u8f83\u4e86AI\u6a21\u62df\u548c\u771f\u5b9e\u4eba\u7c7b\u6559\u5e08-\u5b66\u751f\u5bf9\u8bdd\u7684\u7ed3\u6784\u548c\u884c\u4e3a\u5dee\u5f02\uff0c\u53d1\u73b0\u4eba\u7c7b\u5bf9\u8bdd\u5728\u8bed\u8c03\u957f\u5ea6\u3001\u8be2\u95ee\u548c\u53cd\u9988\u884c\u4e3a\u65b9\u9762\u663e\u8457\u4f18\u4e8eAI\uff0c\u4e14\u5177\u6709\u66f4\u591a\u6837\u5316\u7684\u8ba4\u77e5\u5f15\u5bfc\u6a21\u5f0f", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u6559\u80b2\u5bcc\u6709\u6559\u5b66\u4ef7\u503c\u7684\u4ea4\u4e92\u5bf9\u8bdd\u65b9\u9762\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u7cfb\u7edf\u7814\u7a76AI\u6a21\u62df\u4e0e\u771f\u5b9e\u4eba\u7c7b\u6559\u5e08\u5bf9\u8bdd\u7684\u5dee\u5f02", "method": "\u91c7\u7528\u8d77\u59cb-\u54cd\u5e94-\u53cd\u9988(IRF)\u7f16\u7801\u65b9\u6848\u548c\u8ba4\u77e5\u7f51\u7edc\u5206\u6790(ENA)\u8fdb\u884c\u5b9a\u91cf\u6bd4\u8f83", "result": "\u4eba\u7c7b\u5bf9\u8bdd\u5728\u8bed\u8c03\u957f\u5ea6\u3001\u8be2\u95ee(I-Q)\u548c\u4e00\u822c\u53cd\u9988(F-F)\u884c\u4e3a\u65b9\u9762\u663e\u8457\u4f18\u4e8eAI\uff1bENA\u663e\u793a\u4eba\u7c7b\u5bf9\u8bdd\u66f4\u5177\u8ba4\u77e5\u5f15\u5bfc\u6027\u548c\u591a\u6837\u6027\uff0c\u4ee5\"\u8be2\u95ee-\u4e8b\u5b9e\u54cd\u5e94-\u53cd\u9988\"\u6559\u5b66\u5faa\u73af\u4e3a\u4e2d\u5fc3\uff0c\u800cAI\u5bf9\u8bdd\u5448\u73b0\u7ed3\u6784\u7b80\u5316\u548c\u884c\u4e3a\u6536\u655b\u7684\"\u89e3\u91ca-\u7b80\u5355\u54cd\u5e94\"\u5faa\u73af", "conclusion": "\u5f53\u524dAI\u751f\u6210\u7684\u8f85\u5bfc\u5bf9\u8bdd\u5b58\u5728\u91cd\u8981\u5c40\u9650\u6027\uff0c\u4e3a\u8bbe\u8ba1\u548c\u8bc4\u4f30\u66f4\u6709\u6559\u80b2\u6548\u679c\u7684\u751f\u6210\u5f0f\u6559\u80b2\u5bf9\u8bdd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u6307\u5bfc"}}
{"id": "2509.01920", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.01920", "abs": "https://arxiv.org/abs/2509.01920", "authors": ["Yilin Guan", "Wenyue Hua", "Qingfeng Lan", "Sun Fei", "Dujian Ding", "Devang Acharya", "Chi Wang", "William Yang Wang"], "title": "Dynamic Speculative Agent Planning", "comment": "19 pages, 11 figures", "summary": "Despite their remarkable success in complex tasks propelling widespread\nadoption, large language-model-based agents still face critical deployment\nchallenges due to prohibitive latency and inference costs. While recent work\nhas explored various methods to accelerate inference, existing approaches\nsuffer from significant limitations: they either fail to preserve performance\nfidelity, require extensive offline training of router modules, or incur\nexcessive operational costs. Moreover, they provide minimal user control over\nthe tradeoff between acceleration and other performance metrics. To address\nthese gaps, we introduce Dynamic Speculative Planning (DSP), an asynchronous\nonline reinforcement learning framework that provides lossless acceleration\nwith substantially reduced costs without requiring additional pre-deployment\npreparation. DSP explicitly optimizes a joint objective balancing end-to-end\nlatency against dollar cost, allowing practitioners to adjust a single\nparameter that steers the system toward faster responses, cheaper operation, or\nany point along this continuum. Experiments on two standard agent benchmarks\ndemonstrate that DSP achieves comparable efficiency to the fastest lossless\nacceleration method while reducing total cost by 30% and unnecessary cost up to\n60%. Our code and data are available through\nhttps://github.com/guanyilin428/Dynamic-Speculative-Planning.", "AI": {"tldr": "DSP\u662f\u4e00\u79cd\u5f02\u6b65\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u63a8\u6d4b\u89c4\u5212\u5b9e\u73b0\u65e0\u635f\u52a0\u901f\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u63a8\u7406\u6210\u672c\uff0c\u65e0\u9700\u989d\u5916\u9884\u90e8\u7f72\u51c6\u5907\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u9762\u4e34\u9ad8\u5ef6\u8fdf\u548c\u63a8\u7406\u6210\u672c\u7684\u90e8\u7f72\u6311\u6218\uff0c\u73b0\u6709\u52a0\u901f\u65b9\u6cd5\u8981\u4e48\u6027\u80fd\u635f\u5931\u4e25\u91cd\uff0c\u8981\u4e48\u9700\u8981\u5927\u91cf\u79bb\u7ebf\u8bad\u7ec3\uff0c\u8981\u4e48\u8fd0\u8425\u6210\u672c\u8fc7\u9ad8\uff0c\u4e14\u7f3a\u4e4f\u7528\u6237\u5bf9\u52a0\u901f\u4e0e\u6027\u80fd\u6743\u8861\u7684\u63a7\u5236\u3002", "method": "\u63d0\u51fa\u52a8\u6001\u63a8\u6d4b\u89c4\u5212(DSP)\u6846\u67b6\uff0c\u4f7f\u7528\u5f02\u6b65\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u7aef\u5230\u7aef\u5ef6\u8fdf\u4e0e\u7f8e\u5143\u6210\u672c\u7684\u8054\u5408\u76ee\u6807\uff0c\u901a\u8fc7\u5355\u4e00\u53c2\u6570\u8c03\u8282\u7cfb\u7edf\u5728\u54cd\u5e94\u901f\u5ea6\u548c\u8fd0\u8425\u6210\u672c\u4e4b\u95f4\u7684\u6743\u8861\u3002", "result": "\u5728\u4e24\u4e2a\u6807\u51c6\u4ee3\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDSP\u5b9e\u73b0\u4e86\u4e0e\u6700\u5feb\u65e0\u635f\u52a0\u901f\u65b9\u6cd5\u76f8\u5f53\u7684\u6548\u7387\uff0c\u540c\u65f6\u5c06\u603b\u6210\u672c\u964d\u4f4e30%\uff0c\u4e0d\u5fc5\u8981\u6210\u672c\u964d\u4f4e\u9ad8\u8fbe60%\u3002", "conclusion": "DSP\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7075\u6d3b\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u7684\u90e8\u7f72\u6210\u672c\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u6210\u672c\u6548\u76ca\u6743\u8861\u63a7\u5236\u3002"}}
{"id": "2509.01938", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.01938", "abs": "https://arxiv.org/abs/2509.01938", "authors": ["Jonathn Chang", "Leonard Piff", "Suvadip Sana", "Jasmine X. Li", "Lionel Levine"], "title": "EigenBench: A Comparative Behavioral Measure of Value Alignment", "comment": null, "summary": "Aligning AI with human values is a pressing unsolved problem. To address the\nlack of quantitative metrics for value alignment, we propose EigenBench: a\nblack-box method for comparatively benchmarking language models' values. Given\nan ensemble of models, a constitution describing a value system, and a dataset\nof scenarios, our method returns a vector of scores quantifying each model's\nalignment to the given constitution. To produce these scores, each model judges\nthe outputs of other models across many scenarios, and these judgments are\naggregated with EigenTrust (Kamvar et al, 2003), yielding scores that reflect a\nweighted-average judgment of the whole ensemble. EigenBench uses no ground\ntruth labels, as it is designed to quantify traits for which reasonable judges\nmay disagree on the correct label. Using prompted personas, we test whether\nEigenBench scores are more sensitive to the model or the prompt: we find that\nmost of the variance is explained by the prompt, but a small residual\nquantifies the disposition of the model itself.", "AI": {"tldr": "EigenBench\u662f\u4e00\u4e2a\u65e0\u9700\u771f\u5b9e\u6807\u7b7e\u7684\u9ed1\u76d2\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u578b\u95f4\u76f8\u4e92\u8bc4\u4f30\u6765\u91cf\u5316\u8bed\u8a00\u6a21\u578b\u4e0e\u7ed9\u5b9a\u4ef7\u503c\u4f53\u7cfb\u7684\u5bf9\u9f50\u7a0b\u5ea6", "motivation": "\u89e3\u51b3AI\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u5bf9\u9f50\u7f3a\u4e4f\u91cf\u5316\u6307\u6807\u7684\u95ee\u9898\uff0c\u4e3a\u4ef7\u503c\u5bf9\u9f50\u63d0\u4f9b\u53ef\u6bd4\u8f83\u7684\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5", "method": "\u4f7f\u7528EigenTrust\u7b97\u6cd5\u805a\u5408\u6a21\u578b\u95f4\u7684\u76f8\u4e92\u8bc4\u5224\uff0c\u7ed9\u5b9a\u6a21\u578b\u96c6\u5408\u3001\u4ef7\u503c\u4f53\u7cfb\u5baa\u6cd5\u548c\u573a\u666f\u6570\u636e\u96c6\uff0c\u8f93\u51fa\u6bcf\u4e2a\u6a21\u578b\u7684\u5bf9\u9f50\u5206\u6570\u5411\u91cf", "result": "\u53d1\u73b0\u5927\u90e8\u5206\u65b9\u5dee\u7531\u63d0\u793a\u8bcd\u89e3\u91ca\uff0c\u4f46\u4ecd\u6709\u5c0f\u90e8\u5206\u6b8b\u5dee\u91cf\u5316\u6a21\u578b\u672c\u8eab\u7684\u503e\u5411\u6027", "conclusion": "EigenBench\u4e3a\u4ef7\u503c\u5bf9\u9f50\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u91cf\u5316\u57fa\u51c6\u65b9\u6cd5\uff0c\u80fd\u591f\u533a\u5206\u6a21\u578b\u56fa\u6709\u503e\u5411\u548c\u63d0\u793a\u8bcd\u5f71\u54cd"}}
{"id": "2509.02007", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02007", "abs": "https://arxiv.org/abs/2509.02007", "authors": ["Shreyash Adappanavar", "Krithi Shailya", "Gokul S Krishnan", "Sriraam Natarajan", "Balaraman Ravindran"], "title": "mFARM: Towards Multi-Faceted Fairness Assessment based on HARMs in Clinical Decision Support", "comment": null, "summary": "The deployment of Large Language Models (LLMs) in high-stakes medical\nsettings poses a critical AI alignment challenge, as models can inherit and\namplify societal biases, leading to significant disparities. Existing fairness\nevaluation methods fall short in these contexts as they typically use\nsimplistic metrics that overlook the multi-dimensional nature of medical harms.\nThis also promotes models that are fair only because they are clinically inert,\ndefaulting to safe but potentially inaccurate outputs. To address this gap, our\ncontributions are mainly two-fold: first, we construct two large-scale,\ncontrolled benchmarks (ED-Triage and Opioid Analgesic Recommendation) from\nMIMIC-IV, comprising over 50,000 prompts with twelve race x gender variants and\nthree context tiers. Second, we propose a multi-metric framework -\nMulti-faceted Fairness Assessment based on hARMs ($mFARM$) to audit fairness\nfor three distinct dimensions of disparity (Allocational, Stability, and\nLatent) and aggregate them into an $mFARM$ score. We also present an aggregated\nFairness-Accuracy Balance (FAB) score to benchmark and observe trade-offs\nbetween fairness and prediction accuracy. We empirically evaluate four\nopen-source LLMs (Mistral-7B, BioMistral-7B, Qwen-2.5-7B, Bio-LLaMA3-8B) and\ntheir finetuned versions under quantization and context variations. Our\nfindings showcase that the proposed $mFARM$ metrics capture subtle biases more\neffectively under various settings. We find that most models maintain robust\nperformance in terms of $mFARM$ score across varying levels of quantization but\ndeteriorate significantly when the context is reduced. Our benchmarks and\nevaluation code are publicly released to enhance research in aligned AI for\nhealthcare.", "AI": {"tldr": "\u63d0\u51fa\u4e86mFARM\u591a\u7ef4\u5ea6\u516c\u5e73\u6027\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u533b\u7597\u573a\u666f\u4e2dLLM\u7684\u504f\u89c1\u95ee\u9898\uff0c\u5305\u542b\u5206\u914d\u516c\u5e73\u6027\u3001\u7a33\u5b9a\u6027\u516c\u5e73\u6027\u548c\u6f5c\u5728\u516c\u5e73\u6027\u4e09\u4e2a\u7ef4\u5ea6\uff0c\u5e76\u6784\u5efa\u4e86\u4e24\u4e2a\u5927\u89c4\u6a21\u533b\u7597\u57fa\u51c6\u6570\u636e\u96c6\u3002", "motivation": "\u73b0\u6709\u516c\u5e73\u6027\u8bc4\u4f30\u65b9\u6cd5\u5728\u533b\u7597\u573a\u666f\u4e2d\u5b58\u5728\u4e0d\u8db3\uff0c\u4f7f\u7528\u8fc7\u4e8e\u7b80\u5316\u7684\u6307\u6807\uff0c\u5ffd\u7565\u4e86\u533b\u7597\u5371\u5bb3\u7684\u591a\u7ef4\u6027\uff0c\u4e14\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u56e0\u4e34\u5e8a\u60f0\u6027\u800c\u663e\u5f97\u516c\u5e73\u4f46\u5b9e\u9645\u4e0d\u51c6\u786e\u3002", "method": "\u6784\u5efa\u4e86\u4e24\u4e2a\u5927\u89c4\u6a21\u533b\u7597\u57fa\u51c6\u6570\u636e\u96c6\uff08ED-Triage\u548cOpioid Analgesic Recommendation\uff09\uff0c\u63d0\u51fa\u4e86mFARM\u591a\u7ef4\u5ea6\u516c\u5e73\u6027\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u516c\u5e73\u6027\u7ef4\u5ea6\u548cFAB\u516c\u5e73\u6027-\u51c6\u786e\u6027\u5e73\u8861\u5206\u6570\u3002", "result": "\u8bc4\u4f30\u4e86\u56db\u4e2a\u5f00\u6e90LLM\u53ca\u5176\u5fae\u8c03\u7248\u672c\uff0c\u53d1\u73b0mFARM\u6307\u6807\u80fd\u66f4\u6709\u6548\u6355\u6349\u5404\u79cd\u8bbe\u7f6e\u4e0b\u7684\u7ec6\u5fae\u504f\u89c1\uff0c\u6a21\u578b\u5728\u91cf\u5316\u538b\u7f29\u4e0b\u4fdd\u6301\u7a33\u5065\u6027\u80fd\uff0c\u4f46\u5728\u4e0a\u4e0b\u6587\u51cf\u5c11\u65f6\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002", "conclusion": "\u63d0\u51fa\u7684mFARM\u6846\u67b6\u80fd\u66f4\u597d\u5730\u8bc4\u4f30\u533b\u7597\u573a\u666f\u4e2dLLM\u7684\u516c\u5e73\u6027\u95ee\u9898\uff0c\u53d1\u5e03\u7684\u57fa\u51c6\u548c\u4ee3\u7801\u5c06\u4fc3\u8fdb\u533b\u7597AI\u5bf9\u9f50\u7814\u7a76\u7684\u53d1\u5c55\u3002"}}
{"id": "2509.02053", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02053", "abs": "https://arxiv.org/abs/2509.02053", "authors": ["Wolfgang Eppler", "Reinhard Heil"], "title": "Generative KI f\u00fcr TA", "comment": "Written in German. To appear in Proceedings of NTA11 2025", "summary": "Many scientists use generative AI in their scientific work. People working in\ntechnology assessment (TA) are no exception. TA's approach to generative AI is\ntwofold: on the one hand, generative AI is used for TA work, and on the other\nhand, generative AI is the subject of TA research. After briefly outlining the\nphenomenon of generative AI and formulating requirements for its use in TA, the\nfollowing article discusses in detail the structural causes of the problems\nassociated with it. Although generative AI is constantly being further\ndeveloped, the structurally induced risks remain. The article concludes with\nproposed solutions and brief notes on their feasibility, as well as some\nexamples of the use of generative AI in TA work.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u6280\u672f\u8bc4\u4f30(TA)\u9886\u57df\u5bf9\u751f\u6210\u5f0fAI\u7684\u53cc\u91cd\u6001\u5ea6\uff1a\u65e2\u5c06\u5176\u4f5c\u4e3a\u7814\u7a76\u5de5\u5177\uff0c\u53c8\u5c06\u5176\u4f5c\u4e3a\u7814\u7a76\u5bf9\u8c61\uff0c\u5206\u6790\u4e86\u7ed3\u6784\u6027\u98ce\u9669\u5e76\u63d0\u51fa\u4e86\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u968f\u7740\u79d1\u5b66\u5bb6\u666e\u904d\u4f7f\u7528\u751f\u6210\u5f0fAI\uff0c\u6280\u672f\u8bc4\u4f30\u9886\u57df\u9700\u8981\u7cfb\u7edf\u6027\u5730\u7814\u7a76\u5982\u4f55\u6b63\u786e\u4f7f\u7528\u8fd9\u4e00\u6280\u672f\uff0c\u540c\u65f6\u8bc4\u4f30\u5176\u5e26\u6765\u7684\u7ed3\u6784\u6027\u98ce\u9669\u3002", "method": "\u901a\u8fc7\u5206\u6790\u751f\u6210\u5f0fAI\u7684\u73b0\u8c61\u7279\u5f81\uff0c\u5236\u5b9aTA\u9886\u57df\u4f7f\u7528\u8981\u6c42\uff0c\u6df1\u5165\u63a2\u8ba8\u7ed3\u6784\u6027\u95ee\u9898\u7684\u6839\u6e90\uff0c\u5e76\u63d0\u51fa\u76f8\u5e94\u7684\u89e3\u51b3\u65b9\u6848\u548c\u5b9e\u65bd\u53ef\u884c\u6027\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5c3d\u7ba1\u751f\u6210\u5f0fAI\u6280\u672f\u4e0d\u65ad\u53d1\u5c55\uff0c\u4f46\u5176\u7ed3\u6784\u6027\u98ce\u9669\u4f9d\u7136\u5b58\u5728\uff0c\u9700\u8981\u7279\u5b9a\u7684\u5e94\u5bf9\u7b56\u7565\u548c\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u5728\u6280\u672f\u8bc4\u4f30\u4e2d\u5177\u6709\u53cc\u91cd\u4ef7\u503c\uff0c\u4f46\u5fc5\u987b\u8ba4\u8bc6\u5230\u5176\u7ed3\u6784\u6027\u98ce\u9669\u5e76\u91c7\u53d6\u76f8\u5e94\u63aa\u65bd\uff0c\u6587\u7ae0\u63d0\u4f9b\u4e86\u5177\u4f53\u7684\u4f7f\u7528\u6848\u4f8b\u548c\u53ef\u884c\u6027\u5efa\u8bae\u3002"}}
{"id": "2509.02089", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02089", "abs": "https://arxiv.org/abs/2509.02089", "authors": ["Maijunxian Wang", "Ran Ji"], "title": "AGI as Second Being: The Structural-Generative Ontology of Intelligence", "comment": null, "summary": "Artificial intelligence is often measured by the range of tasks it can\nperform. Yet wide ability without depth remains only an imitation. This paper\nproposes a Structural-Generative Ontology of Intelligence: true intelligence\nexists only when a system can generate new structures, coordinate them into\nreasons, and sustain its identity over time. These three conditions --\ngenerativity, coordination, and sustaining -- define the depth that underlies\nreal intelligence. Current AI systems, however broad in function, remain\nsurface simulations because they lack this depth. Breadth is not the source of\nintelligence but the growth that follows from depth. If future systems were to\nmeet these conditions, they would no longer be mere tools, but could be seen as\na possible Second Being, standing alongside yet distinct from human existence.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7ed3\u6784\u6027-\u751f\u6210\u6027\u667a\u80fd\u672c\u4f53\u8bba\uff0c\u8ba4\u4e3a\u771f\u6b63\u7684\u667a\u80fd\u9700\u8981\u5177\u5907\u751f\u6210\u65b0\u7ed3\u6784\u3001\u534f\u8c03\u6210\u7406\u7531\u3001\u7ef4\u6301\u8eab\u4efd\u8ba4\u540c\u4e09\u4e2a\u6761\u4ef6\uff0c\u5f53\u524dAI\u7cfb\u7edf\u7f3a\u4e4f\u8fd9\u79cd\u6df1\u5ea6\u53ea\u662f\u8868\u9762\u6a21\u62df\u3002", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\u867d\u7136\u529f\u80fd\u5e7f\u6cdb\u4f46\u7f3a\u4e4f\u771f\u6b63\u7684\u667a\u80fd\u6df1\u5ea6\uff0c\u53ea\u662f\u8868\u9762\u6a21\u62df\u800c\u975e\u771f\u6b63\u7684\u667a\u80fd\u5b58\u5728\u3002\u9700\u8981\u5efa\u7acb\u65b0\u7684\u667a\u80fd\u8861\u91cf\u6807\u51c6\u6765\u533a\u5206\u8868\u9762\u529f\u80fd\u548c\u6df1\u5ea6\u667a\u80fd\u3002", "method": "\u63d0\u51fa\u7ed3\u6784\u6027-\u751f\u6210\u6027\u667a\u80fd\u672c\u4f53\u8bba\u6846\u67b6\uff0c\u5b9a\u4e49\u771f\u6b63\u667a\u80fd\u7684\u4e09\u4e2a\u6838\u5fc3\u6761\u4ef6\uff1a\u751f\u6210\u6027\uff08\u521b\u9020\u65b0\u7ed3\u6784\uff09\u3001\u534f\u8c03\u6027\uff08\u7ec4\u7ec7\u6210\u7406\u7531\uff09\u3001\u7ef4\u6301\u6027\uff08\u4fdd\u6301\u8eab\u4efd\u8fde\u7eed\u6027\uff09\u3002", "result": "\u5efa\u7acb\u4e86\u533a\u5206\u771f\u6b63\u667a\u80fd\u4e0e\u8868\u9762\u6a21\u62df\u7684\u7406\u8bba\u6846\u67b6\uff0c\u6307\u51fa\u5f53\u524dAI\u7cfb\u7edf\u867d\u7136\u529f\u80fd\u5e7f\u6cdb\u4f46\u7f3a\u4e4f\u667a\u80fd\u6df1\u5ea6\u3002", "conclusion": "\u771f\u6b63\u7684\u667a\u80fd\u9700\u8981\u751f\u6210\u3001\u534f\u8c03\u548c\u7ef4\u6301\u4e09\u4e2a\u6df1\u5ea6\u6761\u4ef6\uff0c\u672a\u6765\u82e5AI\u7cfb\u7edf\u6ee1\u8db3\u8fd9\u4e9b\u6761\u4ef6\u53ef\u80fd\u6210\u4e3a\u4e0e\u4eba\u7c7b\u5e76\u5b58\u7684\"\u7b2c\u4e8c\u5b58\u5728\"\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u5de5\u5177\u3002"}}
{"id": "2509.02241", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02241", "abs": "https://arxiv.org/abs/2509.02241", "authors": ["Strahinja Klem", "Noura Al Moubayed"], "title": "LLMs for LLMs: A Structured Prompting Methodology for Long Legal Documents", "comment": "20 pages, 6 figures, 4 tables,", "summary": "The rise of Large Language Models (LLMs) has had a profoundly transformative\neffect on a number of fields and domains. However, their uptake in Law has\nproven more challenging due to the important issues of reliability and\ntransparency. In this study, we present a structured prompting methodology as a\nviable alternative to the often expensive fine-tuning, with the capability of\ntacking long legal documents from the CUAD dataset on the task of information\nretrieval. Each document is first split into chunks via a system of chunking\nand augmentation, addressing the long document problem. Then, alongside an\nengineered prompt, the input is fed into QWEN-2 to produce a set of answers for\neach question. Finally, we tackle the resulting candidate selection problem\nwith the introduction of the Distribution-based Localisation and Inverse\nCardinality Weighting heuristics. This approach leverages a general purpose\nmodel to promote long term scalability, prompt engineering to increase\nreliability and the two heuristic strategies to reduce the impact of the black\nbox effect. Whilst our model performs up to 9\\% better than the previously\npresented method, reaching state-of-the-art performance, it also highlights the\nlimiting factor of current automatic evaluation metrics for question answering,\nserving as a call to action for future research. However, the chief aim of this\nwork is to underscore the potential of structured prompt engineering as a\nuseful, yet under-explored, tool in ensuring accountability and responsibility\nof AI in the legal domain, and beyond.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u6784\u5316\u63d0\u793a\u65b9\u6cd5\uff0c\u7528\u4e8e\u5904\u7406\u6cd5\u5f8b\u6587\u6863\u4e2d\u7684\u957f\u6587\u6863\u95ee\u9898\uff0c\u901a\u8fc7\u5207\u7247\u589e\u5f3a\u548c\u4e24\u79cd\u60e9\u7b97\u6cd5\u6765\u63d0\u9ad8\u4fe1\u606f\u68c0\u7d22\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\uff0c\u8fbe\u5230\u4e86\u72b6\u6001\u524d\u6cbf\u6027\u80fd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6cd5\u5f8b\u9886\u57df\u7684\u5e94\u7528\u9047\u5230\u4e86\u53ef\u9760\u6027\u548c\u900f\u660e\u6027\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u66ff\u4ee3\u7cbe\u7ec6\u8c03\u6574\u7684\u7ecf\u6d4e\u65b9\u6848\u6765\u5904\u7406\u957f\u6cd5\u5f8b\u6587\u6863\u7684\u4fe1\u606f\u68c0\u7d22\u4efb\u52a1\u3002", "method": "\u91c7\u7528\u7ed3\u6784\u5316\u63d0\u793a\u65b9\u6cd5\uff0c\u9996\u5148\u5c06\u6587\u6863\u5207\u7247\u548c\u589e\u5f3a\u5904\u7406\uff0c\u7136\u540e\u4f7f\u7528\u5de5\u7a0b\u5316\u63d0\u793a\u5c06\u8f93\u5165\u7ed9QWEN-2\u6a21\u578b\uff0c\u6700\u540e\u4f7f\u7528\u5206\u5e03\u57fa\u4e8e\u5b9a\u4f4d\u548c\u9006\u5361\u7eb3\u6743\u91cd\u4e24\u79cd\u60e9\u7b97\u6cd5\u6765\u89e3\u51b3\u5019\u9009\u7b54\u6848\u9009\u62e9\u95ee\u9898\u3002", "result": "\u65b9\u6cd5\u5728CUAD\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u72b6\u6001\u524d\u6cbf\u6027\u80fd\uff0c\u6027\u80fd\u6bd4\u4e4b\u524d\u65b9\u6cd5\u63d0\u9ad8\u4e869%\uff0c\u540c\u65f6\u5f3a\u8c03\u4e86\u5f53\u524d\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u7ed3\u6784\u5316\u63d0\u793a\u5de5\u7a0b\u662f\u4e00\u79cd\u6709\u6f5c\u529b\u7684\u5de5\u5177\uff0c\u80fd\u591f\u5728\u4fdd\u6301AI\u5728\u6cd5\u5f8b\u9886\u57df\u53ca\u66f4\u5e7f\u6cdb\u5e94\u7528\u4e2d\u8d23\u4efb\u6027\u548c\u53ef\u8d1f\u8d23\u6027\u65b9\u9762\u53d1\u6325\u91cd\u8981\u4f5c\u7528\uff0c\u5e94\u8be5\u5f97\u5230\u66f4\u591a\u5173\u6ce8\u548c\u7814\u7a76\u3002"}}
{"id": "2509.02258", "categories": ["cs.AI", "68T01, 68T50", "I.2.7; I.2.1"], "pdf": "https://arxiv.org/pdf/2509.02258", "abs": "https://arxiv.org/abs/2509.02258", "authors": ["Sergio Consoli", "Pietro Coletti", "Peter V. Markov", "Lia Orfei", "Indaco Biazzo", "Lea Schuh", "Nicolas Stefanovitch", "Lorenzo Bertolini", "Mario Ceresa", "Nikolaos I. Stilianakis"], "title": "An Epidemiological Knowledge Graph extracted from the World Health Organization's Disease Outbreak News", "comment": "23 pages, 10 figures", "summary": "The rapid evolution of artificial intelligence (AI), together with the\nincreased availability of social media and news for epidemiological\nsurveillance, are marking a pivotal moment in epidemiology and public health\nresearch. Leveraging the power of generative AI, we use an ensemble approach\nwhich incorporates multiple Large Language Models (LLMs) to extract valuable\nactionable epidemiological information from the World Health Organization (WHO)\nDisease Outbreak News (DONs). DONs is a collection of regular reports on global\noutbreaks curated by the WHO and the adopted decision-making processes to\nrespond to them. The extracted information is made available in a daily-updated\ndataset and a knowledge graph, referred to as eKG, derived to provide a nuanced\nrepresentation of the public health domain knowledge. We provide an overview of\nthis new dataset and describe the structure of eKG, along with the services and\ntools used to access and utilize the data that we are building on top. These\ninnovative data resources open altogether new opportunities for epidemiological\nresearch, and the analysis and surveillance of disease outbreaks.", "AI": {"tldr": "\u4f7f\u7528\u751f\u6210\u5f0fAI\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4eceWHO\u75be\u75c5\u7206\u53d1\u65b0\u95fb\u4e2d\u63d0\u53d6\u6d41\u884c\u75c5\u5b66\u4fe1\u606f\uff0c\u6784\u5efa\u6bcf\u65e5\u66f4\u65b0\u7684\u6570\u636e\u96c6\u548c\u77e5\u8bc6\u56fe\u8c31(eKG)\uff0c\u4e3a\u6d41\u884c\u75c5\u5b66\u7814\u7a76\u548c\u75be\u75c5\u76d1\u6d4b\u63d0\u4f9b\u65b0\u5de5\u5177\u3002", "motivation": "\u5229\u7528AI\u6280\u672f\u548c\u793e\u4f1a\u5a92\u4f53/\u65b0\u95fb\u6570\u636e\u7684\u53ef\u7528\u6027\uff0c\u6539\u8fdb\u6d41\u884c\u75c5\u5b66\u76d1\u6d4b\u548c\u516c\u5171\u536b\u751f\u7814\u7a76\uff0c\u4eceWHO\u7684\u6743\u5a01\u75ab\u60c5\u62a5\u544a\u4e2d\u63d0\u53d6\u6709\u4ef7\u503c\u7684\u4fe1\u606f\u3002", "method": "\u91c7\u7528\u96c6\u6210\u65b9\u6cd5\uff0c\u7ed3\u5408\u591a\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u5904\u7406WHO\u75be\u75c5\u7206\u53d1\u65b0\u95fb(DONs)\uff0c\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31(eKG)\u6765\u8868\u5f81\u516c\u5171\u536b\u751f\u9886\u57df\u77e5\u8bc6\u3002", "result": "\u521b\u5efa\u4e86\u6bcf\u65e5\u66f4\u65b0\u7684\u6570\u636e\u96c6\u548c\u77e5\u8bc6\u56fe\u8c31\uff0c\u63d0\u4f9b\u4e86\u65b0\u7684\u6570\u636e\u8d44\u6e90\u548c\u5de5\u5177\u6765\u8bbf\u95ee\u548c\u5229\u7528\u8fd9\u4e9b\u6d41\u884c\u75c5\u5b66\u4fe1\u606f\u3002", "conclusion": "\u8fd9\u4e9b\u521b\u65b0\u7684\u6570\u636e\u8d44\u6e90\u4e3a\u6d41\u884c\u75c5\u5b66\u7814\u7a76\u3001\u75be\u75c5\u7206\u53d1\u5206\u6790\u548c\u76d1\u6d4b\u5f00\u8f9f\u4e86\u5168\u65b0\u7684\u673a\u4f1a\uff0c\u63d0\u5347\u4e86\u516c\u5171\u536b\u751f\u51b3\u7b56\u652f\u6301\u80fd\u529b\u3002"}}
{"id": "2509.02276", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02276", "abs": "https://arxiv.org/abs/2509.02276", "authors": ["Susana Nunes", "Samy Badreddine", "Catia Pesquita"], "title": "Rewarding Explainability in Drug Repurposing with Knowledge Graphs", "comment": "9 pages, 4 figures, accepted at conference IJCAI 2025", "summary": "Knowledge graphs (KGs) are powerful tools for modelling complex,\nmulti-relational data and supporting hypothesis generation, particularly in\napplications like drug repurposing. However, for predictive methods to gain\nacceptance as credible scientific tools, they must ensure not only accuracy but\nalso the capacity to offer meaningful scientific explanations. This paper\npresents a novel approach REx, for generating scientific explanations based in\nlink prediction in knowledge graphs. It employs reward and policy mechanisms\nthat consider desirable properties of scientific explanation to guide a\nreinforcement learning agent in the identification of explanatory paths within\na KG. The approach further enriches explanatory paths with domain-specific\nontologies, ensuring that the explanations are both insightful and grounded in\nestablished biomedical knowledge. We evaluate our approach in drug repurposing\nusing three popular knowledge graph benchmarks. The results clearly demonstrate\nits ability to generate explanations that validate predictive insights against\nbiomedical knowledge and that outperform the state-of-the-art approaches in\npredictive performance, establishing REx as a relevant contribution to advance\nAI-driven scientific discovery.", "AI": {"tldr": "REx\u662f\u4e00\u4e2a\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u94fe\u63a5\u9884\u6d4b\u7684\u79d1\u5b66\u89e3\u91ca\u751f\u6210\u65b9\u6cd5\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u673a\u5236\u751f\u6210\u5177\u6709\u79d1\u5b66\u610f\u4e49\u7684\u89e3\u91ca\u8def\u5f84\uff0c\u5728\u836f\u7269\u91cd\u5b9a\u4f4d\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u77e5\u8bc6\u56fe\u8c31\u662f\u5efa\u6a21\u590d\u6742\u591a\u5173\u7cfb\u6570\u636e\u7684\u5f3a\u5927\u5de5\u5177\uff0c\u4f46\u9884\u6d4b\u65b9\u6cd5\u8981\u6210\u4e3a\u53ef\u4fe1\u7684\u79d1\u5b66\u5de5\u5177\uff0c\u4e0d\u4ec5\u9700\u8981\u51c6\u786e\u6027\uff0c\u8fd8\u9700\u8981\u63d0\u4f9b\u6709\u610f\u4e49\u7684\u79d1\u5b66\u89e3\u91ca\u80fd\u529b\u3002", "method": "\u91c7\u7528\u5956\u52b1\u548c\u653f\u7b56\u673a\u5236\uff0c\u8003\u8651\u79d1\u5b66\u89e3\u91ca\u7684\u7406\u60f3\u5c5e\u6027\u6765\u6307\u5bfc\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u5728\u77e5\u8bc6\u56fe\u8c31\u4e2d\u8bc6\u522b\u89e3\u91ca\u8def\u5f84\uff0c\u5e76\u4f7f\u7528\u9886\u57df\u7279\u5b9a\u672c\u4f53\u4e30\u5bcc\u89e3\u91ca\u8def\u5f84\u3002", "result": "\u5728\u4e09\u4e2a\u6d41\u884c\u77e5\u8bc6\u56fe\u8c31\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u9a8c\u8bc1\u9884\u6d4b\u89c1\u89e3\u7684\u89e3\u91ca\uff0c\u5e76\u5728\u9884\u6d4b\u6027\u80fd\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "REx\u662f\u63a8\u8fdbAI\u9a71\u52a8\u79d1\u5b66\u53d1\u73b0\u7684\u76f8\u5173\u8d21\u732e\uff0c\u80fd\u591f\u751f\u6210\u57fa\u4e8e\u751f\u7269\u533b\u5b66\u77e5\u8bc6\u7684\u6df1\u523b\u4e14\u53ef\u9760\u7684\u89e3\u91ca\u3002"}}
{"id": "2509.02297", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02297", "abs": "https://arxiv.org/abs/2509.02297", "authors": ["Guorui Quan", "Mingfei Sun", "Manuel L\u00f3pez-Ib\u00e1\u00f1ez"], "title": "Re-evaluating LLM-based Heuristic Search: A Case Study on the 3D Packing Problem", "comment": null, "summary": "The art of heuristic design has traditionally been a human pursuit. While\nLarge Language Models (LLMs) can generate code for search heuristics, their\napplication has largely been confined to adjusting simple functions within\nhuman-crafted frameworks, leaving their capacity for broader innovation an open\nquestion. To investigate this, we tasked an LLM with building a complete solver\nfor the constrained 3D Packing Problem. Direct code generation quickly proved\nfragile, prompting us to introduce two supports: constraint\nscaffolding--prewritten constraint-checking code--and iterative\nself-correction--additional refinement cycles to repair bugs and produce a\nviable initial population. Notably, even within a vast search space in a greedy\nprocess, the LLM concentrated its efforts almost exclusively on refining the\nscoring function. This suggests that the emphasis on scoring functions in prior\nwork may reflect not a principled strategy, but rather a natural limitation of\nLLM capabilities. The resulting heuristic was comparable to a human-designed\ngreedy algorithm, and when its scoring function was integrated into a\nhuman-crafted metaheuristic, its performance rivaled established solvers,\nthough its effectiveness waned as constraints tightened. Our findings highlight\ntwo major barriers to automated heuristic design with current LLMs: the\nengineering required to mitigate their fragility in complex reasoning tasks,\nand the influence of pretrained biases, which can prematurely narrow the search\nfor novel solutions.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76LLM\u5728\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u4e2d\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u76f4\u63a5\u751f\u6210\u4ee3\u7801\u5f88\u8106\u5f31\uff0c\u9700\u8981\u7ea6\u675f\u652f\u67b6\u548c\u8fed\u4ee3\u81ea\u4fee\u6b63\u6765\u652f\u6301\u3002LLM\u4e3b\u8981\u4e13\u6ce8\u4e8e\u8bc4\u5206\u51fd\u6570\u4f18\u5316\uff0c\u53cd\u6620\u4e86\u5176\u80fd\u529b\u5c40\u9650\u6027\u800c\u975e\u539f\u5219\u6027\u7b56\u7565\u3002", "motivation": "\u63a2\u8ba8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u542f\u53d1\u5f0f\u8bbe\u8ba1\u4e2d\u7684\u521b\u65b0\u80fd\u529b\uff0c\u7279\u522b\u662f\u80fd\u5426\u8d85\u8d8a\u4f20\u7edf\u4eba\u7c7b\u8bbe\u8ba1\u7684\u6846\u67b6\u8fdb\u884c\u66f4\u5e7f\u6cdb\u7684\u521b\u65b0\u3002", "method": "\u4f7f\u7528\u7ea6\u675f\u652f\u67b6\uff08\u9884\u5199\u7684\u7ea6\u675f\u68c0\u67e5\u4ee3\u7801\uff09\u548c\u8fed\u4ee3\u81ea\u4fee\u6b63\uff08\u989d\u5916\u7684\u7cbe\u70bc\u5468\u671f\u6765\u4fee\u590d\u9519\u8bef\uff09\u6765\u652f\u6301LLM\u6784\u5efa3D\u88c5\u7bb1\u95ee\u9898\u7684\u5b8c\u6574\u6c42\u89e3\u5668\u3002", "result": "\u751f\u6210\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\u4e0e\u4eba\u7c7b\u8bbe\u8ba1\u7684\u8d2a\u5fc3\u7b97\u6cd5\u76f8\u5f53\uff0c\u5f53\u8bc4\u5206\u51fd\u6570\u96c6\u6210\u5230\u4eba\u7c7b\u8bbe\u8ba1\u7684\u5143\u542f\u53d1\u5f0f\u4e2d\u65f6\uff0c\u6027\u80fd\u53ef\u4e0e\u73b0\u6709\u6c42\u89e3\u5668\u76f8\u5ab2\u7f8e\uff0c\u4f46\u5728\u7ea6\u675f\u6536\u7d27\u65f6\u6548\u679c\u4e0b\u964d\u3002", "conclusion": "\u5f53\u524dLLM\u5728\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u4e2d\u7684\u4e24\u5927\u969c\u788d\uff1a\u9700\u8981\u5927\u91cf\u5de5\u7a0b\u6765\u7f13\u89e3\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8106\u5f31\u6027\uff0c\u4ee5\u53ca\u9884\u8bad\u7ec3\u504f\u89c1\u4f1a\u8fc7\u65e9\u9650\u5236\u65b0\u89e3\u51b3\u65b9\u6848\u7684\u641c\u7d22\u7a7a\u95f4\u3002"}}
{"id": "2509.02308", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02308", "abs": "https://arxiv.org/abs/2509.02308", "authors": ["Taegyeong Lee", "Jiwon Park", "Kyunga Bang", "Seunghyun Hwang", "Ung-Jin Jang"], "title": "Exploring Diffusion Models for Generative Forecasting of Financial Charts", "comment": null, "summary": "Recent advances in generative models have enabled significant progress in\ntasks such as generating and editing images from text, as well as creating\nvideos from text prompts, and these methods are being applied across various\nfields. However, in the financial domain, there may still be a reliance on\ntime-series data and a continued focus on transformer models, rather than on\ndiverse applications of generative models. In this paper, we propose a novel\napproach that leverages text-to-image model by treating time-series data as a\nsingle image pattern, thereby enabling the prediction of stock price trends.\nUnlike prior methods that focus on learning and classifying chart patterns\nusing architectures such as ResNet or ViT, we experiment with generating the\nnext chart image from the current chart image and an instruction prompt using\ndiffusion models. Furthermore, we introduce a simple method for evaluating the\ngenerated chart image against ground truth image. We highlight the potential of\nleveraging text-to-image generative models in the financial domain, and our\nfindings motivate further research to address the current limitations and\nexpand their applicability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u65b9\u6cd5\uff0c\u5c06\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u89c6\u4e3a\u5355\u4e00\u56fe\u50cf\u6a21\u5f0f\uff0c\u5229\u7528\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u6a21\u578b\u6765\u9884\u6d4b\u80a1\u7968\u4ef7\u683c\u8d8b\u52bf\uff0c\u901a\u8fc7\u6269\u6563\u6a21\u578b\u4ece\u5f53\u524d\u56fe\u8868\u56fe\u50cf\u548c\u6307\u4ee4\u63d0\u793a\u751f\u6210\u4e0b\u4e00\u5f20\u56fe\u8868\u56fe\u50cf\u3002", "motivation": "\u5c3d\u7ba1\u751f\u6210\u6a21\u578b\u5728\u56fe\u50cf\u548c\u89c6\u9891\u751f\u6210\u9886\u57df\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5728\u91d1\u878d\u9886\u57df\u4ecd\u7136\u4e3b\u8981\u4f9d\u8d56\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u548cTransformer\u6a21\u578b\uff0c\u7f3a\u4e4f\u751f\u6210\u6a21\u578b\u7684\u591a\u6837\u5316\u5e94\u7528\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u6a21\u578b\u5728\u91d1\u878d\u9886\u57df\u7684\u6f5c\u529b\u3002", "method": "\u5c06\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4f5c\u4e3a\u56fe\u50cf\u6a21\u5f0f\u5904\u7406\uff0c\u4f7f\u7528\u6269\u6563\u6a21\u578b\u4ece\u5f53\u524d\u80a1\u7968\u56fe\u8868\u56fe\u50cf\u548c\u6587\u672c\u6307\u4ee4\u63d0\u793a\u751f\u6210\u4e0b\u4e00\u5f20\u56fe\u8868\u56fe\u50cf\uff0c\u5e76\u5f15\u5165\u4e86\u8bc4\u4f30\u751f\u6210\u56fe\u50cf\u4e0e\u771f\u5b9e\u56fe\u50cf\u5bf9\u6bd4\u7684\u7b80\u5355\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u8868\u660e\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u6a21\u578b\u5728\u91d1\u878d\u9886\u57df\u5177\u6709\u5e94\u7528\u6f5c\u529b\uff0c\u80fd\u591f\u6210\u529f\u751f\u6210\u80a1\u7968\u4ef7\u683c\u8d8b\u52bf\u56fe\u8868\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86\u751f\u6210\u6a21\u578b\u5728\u91d1\u878d\u9884\u6d4b\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u89e3\u51b3\u5f53\u524d\u5c40\u9650\u6027\u5e76\u6269\u5c55\u5176\u9002\u7528\u6027\u3002"}}
{"id": "2509.02340", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02340", "abs": "https://arxiv.org/abs/2509.02340", "authors": ["Salma Haidar", "Jos\u00e9 Oramas"], "title": "Explainability-Driven Dimensionality Reduction for Hyperspectral Imaging", "comment": null, "summary": "Hyperspectral imaging (HSI) provides rich spectral information for precise\nmaterial classification and analysis; however, its high dimensionality\nintroduces a computational burden and redundancy, making dimensionality\nreduction essential. We present an exploratory study into the application of\npost-hoc explainability methods in a model--driven framework for band\nselection, which reduces the spectral dimension while preserving predictive\nperformance. A trained classifier is probed with explanations to quantify each\nband's contribution to its decisions. We then perform deletion--insertion\nevaluations, recording confidence changes as ranked bands are removed or\nreintroduced, and aggregate these signals into influence scores. Selecting the\nhighest--influence bands yields compact spectral subsets that maintain accuracy\nand improve efficiency. Experiments on two public benchmarks (Pavia University\nand Salinas) demonstrate that classifiers trained on as few as 30 selected\nbands match or exceed full--spectrum baselines while reducing computational\nrequirements. The resulting subsets align with physically meaningful, highly\ndiscriminative wavelength regions, indicating that model--aligned,\nexplanation-guided band selection is a principled route to effective\ndimensionality reduction for HSI.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u9a71\u52a8\u548c\u4e8b\u540e\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u7684\u9ad8\u5149\u8c31\u56fe\u50cf\u6ce2\u6bb5\u9009\u62e9\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u5206\u7c7b\u5668\u4e2d\u5404\u6ce2\u6bb5\u5bf9\u51b3\u7b56\u7684\u8d21\u732e\u5ea6\uff0c\u9009\u62e9\u6700\u5177\u5f71\u54cd\u529b\u7684\u6ce2\u6bb5\u5b50\u96c6\uff0c\u5728\u4fdd\u6301\u5206\u7c7b\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u9ad8\u5149\u8c31\u56fe\u50cf\u7684\u9ad8\u7ef4\u7279\u6027\u5e26\u6765\u4e86\u8ba1\u7b97\u8d1f\u62c5\u548c\u5197\u4f59\u4fe1\u606f\uff0c\u9700\u8981\u8fdb\u884c\u7ef4\u5ea6\u7ea6\u7b80\u3002\u4f20\u7edf\u65b9\u6cd5\u5f80\u5f80\u7f3a\u4e4f\u5bf9\u6a21\u578b\u51b3\u7b56\u8fc7\u7a0b\u7684\u7406\u89e3\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u4fdd\u6301\u9884\u6d4b\u6027\u80fd\u7684\u540c\u65f6\u9009\u62e9\u6700\u5177\u5224\u522b\u6027\u6ce2\u6bb5\u7684 principled \u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u8bad\u7ec3\u597d\u7684\u5206\u7c7b\u5668\uff0c\u901a\u8fc7\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u91cf\u5316\u6bcf\u4e2a\u6ce2\u6bb5\u5bf9\u51b3\u7b56\u7684\u8d21\u732e\u5ea6\uff0c\u8fdb\u884c\u5220\u9664-\u63d2\u5165\u8bc4\u4f30\u6765\u8bb0\u5f55\u7f6e\u4fe1\u5ea6\u53d8\u5316\uff0c\u805a\u5408\u8fd9\u4e9b\u4fe1\u53f7\u5f97\u5230\u5f71\u54cd\u529b\u5206\u6570\uff0c\u9009\u62e9\u5f71\u54cd\u529b\u6700\u9ad8\u7684\u6ce2\u6bb5\u5b50\u96c6\u3002", "result": "\u5728\u4e24\u4e2a\u516c\u5f00\u57fa\u51c6\u6570\u636e\u96c6\uff08Pavia University \u548c Salinas\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4ec5\u4f7f\u752830\u4e2a\u9009\u5b9a\u6ce2\u6bb5\u8bad\u7ec3\u7684classifier\u5c31\u80fd\u8fbe\u5230\u6216\u8d85\u8fc7\u5168\u5149\u8c31\u57fa\u7ebf\u7684\u6027\u80fd\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u9700\u6c42\u3002", "conclusion": "\u6a21\u578b\u5bf9\u9f50\u3001\u89e3\u91ca\u5f15\u5bfc\u7684\u6ce2\u6bb5\u9009\u62e9\u662f\u9ad8\u5149\u8c31\u56fe\u50cf\u7ef4\u5ea6\u7ea6\u7b80\u7684\u6709\u6548\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u6240\u9009\u6ce2\u6bb5\u5b50\u96c6\u4e0e\u7269\u7406\u4e0a\u6709\u610f\u4e49\u3001\u9ad8\u5ea6\u5224\u522b\u6027\u7684\u6ce2\u957f\u533a\u57df\u4e00\u81f4\u3002"}}
{"id": "2509.02401", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02401", "abs": "https://arxiv.org/abs/2509.02401", "authors": ["Josefa Lia Stoisser", "Marc Boubnovski Martell", "Lawrence Phillips", "Gianluca Mazzoni", "Lea M\u00f8rch Harder", "Philip Torr", "Jesper Ferkinghoff-Borg", "Kaspar Martens", "Julien Fauqueur"], "title": "Towards Agents That Know When They Don't Know: Uncertainty as a Control Signal for Structured Reasoning", "comment": null, "summary": "Large language model (LLM) agents are increasingly deployed in structured\nbiomedical data environments, yet they often produce fluent but overconfident\noutputs when reasoning over complex multi-table data. We introduce an\nuncertainty-aware agent for query-conditioned multi-table summarization that\nleverages two complementary signals: (i) retrieval uncertainty--entropy over\nmultiple table-selection rollouts--and (ii) summary uncertainty--combining\nself-consistency and perplexity. Summary uncertainty is incorporated into\nreinforcement learning (RL) with Group Relative Policy Optimization (GRPO),\nwhile both retrieval and summary uncertainty guide inference-time filtering and\nsupport the construction of higher-quality synthetic datasets.\n  On multi-omics benchmarks, our approach improves factuality and calibration,\nnearly tripling correct and useful claims per summary (3.0\\(\\rightarrow\\)8.4\ninternal; 3.6\\(\\rightarrow\\)9.9 cancer multi-omics) and substantially improving\ndownstream survival prediction (C-index 0.32\\(\\rightarrow\\)0.63). These results\ndemonstrate that uncertainty can serve as a control signal--enabling agents to\nabstain, communicate confidence, and become more reliable tools for complex\nstructured-data environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684LLM\u4ee3\u7406\uff0c\u901a\u8fc7\u68c0\u7d22\u4e0d\u786e\u5b9a\u6027\u548c\u6458\u8981\u4e0d\u786e\u5b9a\u6027\u6765\u63d0\u9ad8\u591a\u8868\u751f\u7269\u533b\u5b66\u6570\u636e\u6458\u8981\u7684\u51c6\u786e\u6027\u548c\u6821\u51c6\u6027\uff0c\u5728\u591a\u9879\u6307\u6807\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\u3002", "motivation": "LLM\u4ee3\u7406\u5728\u5904\u7406\u7ed3\u6784\u5316\u751f\u7269\u533b\u5b66\u6570\u636e\u65f6\u7ecf\u5e38\u4ea7\u751f\u6d41\u7545\u4f46\u8fc7\u4e8e\u81ea\u4fe1\u7684\u8f93\u51fa\uff0c\u9700\u8981\u66f4\u597d\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u673a\u5236\u6765\u63d0\u9ad8\u53ef\u9760\u6027\u3002", "method": "\u7ed3\u5408\u68c0\u7d22\u4e0d\u786e\u5b9a\u6027\uff08\u591a\u8868\u9009\u62e9rollout\u7684\u71b5\uff09\u548c\u6458\u8981\u4e0d\u786e\u5b9a\u6027\uff08\u81ea\u4e00\u81f4\u6027\u548c\u56f0\u60d1\u5ea6\uff09\uff0c\u4f7f\u7528GRPO\u5f3a\u5316\u5b66\u4e60\u6574\u5408\u6458\u8981\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u5728\u63a8\u7406\u65f6\u8fdb\u884c\u8fc7\u6ee4\u3002", "result": "\u5728\u591a\u7ec4\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6b63\u786e\u6709\u7528\u7684\u58f0\u660e\u6570\u91cf\u51e0\u4e4e\u7ffb\u4e86\u4e09\u500d\uff083.0\u21928.4\u5185\u90e8\uff1b3.6\u21929.9\u764c\u75c7\u591a\u7ec4\u5b66\uff09\uff0c\u4e0b\u6e38\u751f\u5b58\u9884\u6d4b\u663e\u8457\u6539\u5584\uff08C-index 0.32\u21920.63\uff09\u3002", "conclusion": "\u4e0d\u786e\u5b9a\u6027\u53ef\u4ee5\u4f5c\u4e3a\u63a7\u5236\u4fe1\u53f7\uff0c\u4f7f\u4ee3\u7406\u80fd\u591f\u5f03\u6743\u3001\u4f20\u8fbe\u7f6e\u4fe1\u5ea6\uff0c\u6210\u4e3a\u590d\u6742\u7ed3\u6784\u5316\u6570\u636e\u73af\u5883\u4e2d\u66f4\u53ef\u9760\u7684\u5de5\u5177\u3002"}}
{"id": "2509.02444", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.02444", "abs": "https://arxiv.org/abs/2509.02444", "authors": ["Jingru Fan", "Yufan Dang", "Jingyao Wu", "Huatao Li", "Runde Yang", "Xiyuan Yang", "Yuheng Wang", "Zhong Zhang", "Yaxi Lu", "Yankai Lin", "Zhiyuan Liu", "Dahai Li", "Chen Qian"], "title": "AppCopilot: Toward General, Accurate, Long-Horizon, and Efficient Mobile Agent", "comment": "Project at https://github.com/OpenBMB/AppCopilot", "summary": "With the raid evolution of large language models and multimodal foundation\nmodels, the mobile-agent landscape has proliferated without converging on the\nfundamental challenges. This paper identifies four core problems that must be\nsolved for mobile agents to deliver practical, scalable impact: (1)\ngeneralization across tasks, modalities, apps, and devices; (2) accuracy,\nspecifically precise on-screen interaction and click targeting; (3)\nlong-horizon capability for sustained, multi-step goals; and (4) efficiency,\nspecifically high-performance runtime on resource-constrained devices. We\npresent AppCopilot, a multimodal, multi-agent, general-purpose on-device\nassistant that operates across applications and constitutes a full-stack,\nclosed-loop system from data to deployment. AppCopilot operationalizes this\nposition through an end-to-end autonomous pipeline spanning data collection,\ntraining, deployment, high-quality and efficient inference, and mobile\napplication development. At the model layer, it integrates multimodal\nfoundation models with robust Chinese-English support. At the reasoning and\ncontrol layer, it combines chain-of-thought reasoning, hierarchical task\nplanning and decomposition, and multi-agent collaboration. At the execution\nlayer, it enables user personalization and experiential adaptation, voice\ninteraction, function calling, cross-app and cross-device orchestration, and\ncomprehensive mobile app support. The system design incorporates\nprofiling-driven optimization for latency, memory, and energy across\nheterogeneous hardware. Empirically, AppCopilot achieves significant\nimprovements along all four dimensions: stronger generalization,\nhigher-precision on-screen actions, more reliable long-horizon task completion,\nand faster, more resource-efficient runtime.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86AppCopilot\uff0c\u4e00\u4e2a\u591a\u6a21\u6001\u3001\u591a\u4ee3\u7406\u7684\u901a\u7528\u8bbe\u5907\u7aef\u52a9\u624b\uff0c\u89e3\u51b3\u4e86\u79fb\u52a8\u4ee3\u7406\u5728\u6cdb\u5316\u6027\u3001\u51c6\u786e\u6027\u3001\u957f\u65f6\u7a0b\u80fd\u529b\u548c\u6548\u7387\u56db\u4e2a\u6838\u5fc3\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u548c\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u79fb\u52a8\u4ee3\u7406\u9886\u57df\u6d8c\u73b0\u51fa\u4f17\u591a\u65b9\u6848\uff0c\u4f46\u5c1a\u672a\u89e3\u51b3\u6839\u672c\u6027\u6311\u6218\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u79fb\u52a8\u4ee3\u7406\u5728\u8de8\u4efb\u52a1\u3001\u8de8\u5e94\u7528\u3001\u8de8\u8bbe\u5907\u6cdb\u5316\uff0c\u7cbe\u786e\u5c4f\u5e55\u4ea4\u4e92\uff0c\u957f\u65f6\u7a0b\u4efb\u52a1\u6267\u884c\uff0c\u4ee5\u53ca\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u9ad8\u6548\u8fd0\u884c\u7b49\u56db\u4e2a\u6838\u5fc3\u95ee\u9898\u3002", "method": "AppCopilot\u91c7\u7528\u7aef\u5230\u7aef\u81ea\u4e3b\u6d41\u6c34\u7ebf\uff0c\u6574\u5408\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\uff08\u652f\u6301\u4e2d\u82f1\u6587\uff09\uff0c\u7ed3\u5408\u601d\u7ef4\u94fe\u63a8\u7406\u3001\u5206\u5c42\u4efb\u52a1\u89c4\u5212\u4e0e\u5206\u89e3\u3001\u591a\u4ee3\u7406\u534f\u4f5c\u3002\u7cfb\u7edf\u5305\u542b\u6a21\u578b\u5c42\u3001\u63a8\u7406\u63a7\u5236\u5c42\u548c\u6267\u884c\u5c42\uff0c\u652f\u6301\u7528\u6237\u4e2a\u6027\u5316\u3001\u8bed\u97f3\u4ea4\u4e92\u3001\u51fd\u6570\u8c03\u7528\u3001\u8de8\u5e94\u7528\u8de8\u8bbe\u5907\u7f16\u6392\uff0c\u5e76\u901a\u8fc7\u6027\u80fd\u5206\u6790\u9a71\u52a8\u4f18\u5316\u5ef6\u8fdf\u3001\u5185\u5b58\u548c\u80fd\u8017\u3002", "result": "\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0cAppCopilot\u5728\u56db\u4e2a\u7ef4\u5ea6\u5747\u53d6\u5f97\u663e\u8457\u6539\u8fdb\uff1a\u66f4\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\u3001\u66f4\u9ad8\u7cbe\u5ea6\u7684\u5c4f\u5e55\u64cd\u4f5c\u3001\u66f4\u53ef\u9760\u7684\u957f\u65f6\u7a0b\u4efb\u52a1\u5b8c\u6210\u5ea6\uff0c\u4ee5\u53ca\u66f4\u5feb\u3001\u66f4\u8d44\u6e90\u9ad8\u6548\u7684\u8fd0\u884c\u65f6\u6027\u80fd\u3002", "conclusion": "AppCopilot\u4f5c\u4e3a\u4e00\u4e2a\u5b8c\u6574\u7684\u95ed\u73af\u7cfb\u7edf\uff0c\u4ece\u6570\u636e\u5230\u90e8\u7f72\u5b9e\u73b0\u4e86\u79fb\u52a8\u4ee3\u7406\u7684\u5b9e\u7528\u5316\u548c\u89c4\u6a21\u5316\u5e94\u7528\uff0c\u4e3a\u89e3\u51b3\u79fb\u52a8\u4ee3\u7406\u6838\u5fc3\u6311\u6218\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.02494", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02494", "abs": "https://arxiv.org/abs/2509.02494", "authors": ["Hongwei Jin", "Kibaek Kim", "Jonghwan Kwon"], "title": "GridMind: LLMs-Powered Agents for Power System Analysis and Operations", "comment": "11 pages, 9 figures, 2 tables. Work under review", "summary": "The complexity of traditional power system analysis workflows presents\nsignificant barriers to efficient decision-making in modern electric grids.\nThis paper presents GridMind, a multi-agent AI system that integrates Large\nLanguage Models (LLMs) with deterministic engineering solvers to enable\nconversational scientific computing for power system analysis. The system\nemploys specialized agents coordinating AC Optimal Power Flow and N-1\ncontingency analysis through natural language interfaces while maintaining\nnumerical precision via function calls. GridMind addresses workflow\nintegration, knowledge accessibility, context preservation, and expert\ndecision-support augmentation. Experimental evaluation on IEEE test cases\ndemonstrates that the proposed agentic framework consistently delivers correct\nsolutions across all tested language models, with smaller LLMs achieving\ncomparable analytical accuracy with reduced computational latency. This work\nestablishes agentic AI as a viable paradigm for scientific computing,\ndemonstrating how conversational interfaces can enhance accessibility while\npreserving numerical rigor essential for critical engineering applications.", "AI": {"tldr": "GridMind\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u4f20\u7edf\u7535\u529b\u5de5\u7a0b\u6c42\u89e3\u5668\u7ed3\u5408\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u754c\u9762\u5b9e\u73b0\u7535\u529b\u7cfb\u7edf\u5206\u6790\u7684\u5bf9\u8bdd\u5f0f\u79d1\u5b66\u8ba1\u7b97\u3002", "motivation": "\u4f20\u7edf\u7535\u529b\u7cfb\u7edf\u5206\u6790\u6d41\u7a0b\u590d\u6742\uff0c\u963b\u788d\u73b0\u4ee3\u7535\u7f51\u9ad8\u6548\u51b3\u7b56\uff0c\u9700\u8981\u66f4\u6613\u8bbf\u95ee\u548c\u96c6\u6210\u7684\u5206\u6790\u5de5\u5177\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u534f\u8c03\u4ea4\u6d41\u6700\u4f18\u6f6e\u6d41\u548cN-1\u4e8b\u6545\u5206\u6790\uff0c\u901a\u8fc7\u51fd\u6570\u8c03\u7528\u4fdd\u6301\u6570\u503c\u7cbe\u5ea6\uff0c\u5b9e\u73b0\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u3002", "result": "\u5728IEEE\u6d4b\u8bd5\u6848\u4f8b\u4e2d\uff0c\u8be5\u7cfb\u7edf\u5728\u6240\u6709\u6d4b\u8bd5\u8bed\u8a00\u6a21\u578b\u4e0a\u90fd\u80fd\u63d0\u4f9b\u6b63\u786e\u89e3\uff0c\u8f83\u5c0fLLM\u5728\u51cf\u5c11\u8ba1\u7b97\u5ef6\u8fdf\u7684\u540c\u65f6\u8fbe\u5230\u76f8\u5f53\u7684\u5206\u6790\u7cbe\u5ea6\u3002", "conclusion": "\u667a\u80fd\u4f53AI\u662f\u79d1\u5b66\u8ba1\u7b97\u7684\u53ef\u4fe1\u8303\u5f0f\uff0c\u5bf9\u8bdd\u754c\u9762\u5728\u4fdd\u6301\u5de5\u7a0b\u5e94\u7528\u6240\u9700\u6570\u503c\u4e25\u8c28\u6027\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u53ef\u8bbf\u95ee\u6027\u3002"}}
{"id": "2509.02544", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.02544", "abs": "https://arxiv.org/abs/2509.02544", "authors": ["Haoming Wang", "Haoyang Zou", "Huatong Song", "Jiazhan Feng", "Junjie Fang", "Junting Lu", "Longxiang Liu", "Qinyu Luo", "Shihao Liang", "Shijue Huang", "Wanjun Zhong", "Yining Ye", "Yujia Qin", "Yuwen Xiong", "Yuxin Song", "Zhiyong Wu", "Bo Li", "Chen Dun", "Chong Liu", "Fuxing Leng", "Hanbin Wang", "Hao Yu", "Haobin Chen", "Hongyi Guo", "Jing Su", "Jingjia Huang", "Kai Shen", "Kaiyu Shi", "Lin Yan", "Peiyao Zhao", "Pengfei Liu", "Qinghao Ye", "Renjie Zheng", "Wayne Xin Zhao", "Wen Heng", "Wenhao Huang", "Wenqian Wang", "Xiaobo Qin", "Yi Lin", "Youbin Wu", "Zehui Chen", "Zihao Wang", "Baoquan Zhong", "Xinchun Zhang", "Xujing Li", "Yuanfan Li", "Zhongkai Zhao", "Chengquan Jiang", "Faming Wu", "Haotian Zhou", "Jinlin Pang", "Li Han", "Qianli Ma", "Siyao Liu", "Songhua Cai", "Wenqi Fu", "Xin Liu", "Zhi Zhang", "Bo Zhou", "Guoliang Li", "Jiajun Shi", "Jiale Yang", "Jie Tang", "Li Li", "Taoran Lu", "Woyu Lin", "Xiaokang Tong", "Xinyao Li", "Yichi Zhang", "Yu Miao", "Zhengxuan Jiang", "Zili Li", "Ziyuan Zhao", "Chenxin Li", "Dehua Ma", "Feng Lin", "Ge Zhang", "Haihua Yang", "Hangyu Guo", "Hongda Zhu", "Jiaheng Liu", "Junda Du", "Kai Cai", "Kuanye Li", "Lichen Yuan", "Meilan Han", "Minchao Wang", "Shuyue Guo", "Tianhao Cheng", "Xiaobo Ma", "Xiaojun Xiao", "Xiaolong Huang", "Xinjie Chen", "Yidi Du", "Yilin Chen", "Yiwen Wang", "Zhaojian Li", "Zhenzhu Yang", "Zhiyuan Zeng", "Chaolin Jin", "Chen Li", "Hao Chen", "Haoli Chen", "Jian Chen", "Qinghao Zhao", "Guang Shi"], "title": "UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning", "comment": null, "summary": "The development of autonomous agents for graphical user interfaces (GUIs)\npresents major challenges in artificial intelligence. While recent advances in\nnative agent models have shown promise by unifying perception, reasoning,\naction, and memory through end-to-end learning, open problems remain in data\nscalability, multi-turn reinforcement learning (RL), the limitations of\nGUI-only operation, and environment stability. In this technical report, we\npresent UI-TARS-2, a native GUI-centered agent model that addresses these\nchallenges through a systematic training methodology: a data flywheel for\nscalable data generation, a stabilized multi-turn RL framework, a hybrid GUI\nenvironment that integrates file systems and terminals, and a unified sandbox\nplatform for large-scale rollouts. Empirical evaluation demonstrates that\nUI-TARS-2 achieves significant improvements over its predecessor UI-TARS-1.5.\nOn GUI benchmarks, it reaches 88.2 on Online-Mind2Web, 47.5 on OSWorld, 50.6 on\nWindowsAgentArena, and 73.3 on AndroidWorld, outperforming strong baselines\nsuch as Claude and OpenAI agents. In game environments, it attains a mean\nnormalized score of 59.8 across a 15-game suite-roughly 60% of human-level\nperformance-and remains competitive with frontier proprietary models (e.g.,\nOpenAI o3) on LMGame-Bench. Additionally, the model can generalize to\nlong-horizon information-seeking tasks and software engineering benchmarks,\nhighlighting its robustness across diverse agent tasks. Detailed analyses of\ntraining dynamics further provide insights into achieving stability and\nefficiency in large-scale agent RL. These results underscore UI-TARS-2's\npotential to advance the state of GUI agents and exhibit strong generalization\nto real-world interactive scenarios.", "AI": {"tldr": "UI-TARS-2\u662f\u4e00\u4e2a\u539f\u751fGUI\u4e2d\u5fc3\u4ee3\u7406\u6a21\u578b\uff0c\u901a\u8fc7\u6570\u636e\u98de\u8f6e\u3001\u591a\u8f6e\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u3001\u6df7\u5408GUI\u73af\u5883\u548c\u7edf\u4e00\u6c99\u7bb1\u5e73\u53f0\uff0c\u5728GUI\u57fa\u51c6\u6d4b\u8bd5\u548c\u6e38\u620f\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8fbe\u5230\u63a5\u8fd1\u4eba\u7c7b60%\u7684\u6027\u80fd\u6c34\u5e73\u3002", "motivation": "\u89e3\u51b3GUI\u81ea\u4e3b\u4ee3\u7406\u5f00\u53d1\u4e2d\u7684\u6570\u636e\u53ef\u6269\u5c55\u6027\u3001\u591a\u8f6e\u5f3a\u5316\u5b66\u4e60\u3001GUI-only\u64cd\u4f5c\u9650\u5236\u548c\u73af\u5883\u7a33\u5b9a\u6027\u7b49\u5f00\u653e\u6027\u95ee\u9898\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u5316\u8bad\u7ec3\u65b9\u6cd5\uff1a\u6570\u636e\u98de\u8f6e\u7528\u4e8e\u53ef\u6269\u5c55\u6570\u636e\u751f\u6210\u3001\u7a33\u5b9a\u7684\u591a\u8f6eRL\u6846\u67b6\u3001\u96c6\u6210\u6587\u4ef6\u7cfb\u7edf\u548c\u7ec8\u7aef\u7684\u6df7\u5408GUI\u73af\u5883\u3001\u4ee5\u53ca\u7528\u4e8e\u5927\u89c4\u6a21\u90e8\u7f72\u7684\u7edf\u4e00\u6c99\u7bb1\u5e73\u53f0\u3002", "result": "\u5728GUI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff08Online-Mind2Web:88.2, OSWorld:47.5, WindowsAgentArena:50.6, AndroidWorld:73.3\uff09\uff0c\u572815\u4e2a\u6e38\u620f\u5957\u4ef6\u4e2d\u5e73\u5747\u6807\u51c6\u5316\u5f97\u520659.8\uff08\u7ea6\u4eba\u7c7b\u6c34\u5e73\u768460%\uff09\uff0c\u5e76\u80fd\u6cdb\u5316\u5230\u957f\u65f6\u7a0b\u4fe1\u606f\u641c\u7d22\u4efb\u52a1\u548c\u8f6f\u4ef6\u5de5\u7a0b\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "UI-TARS-2\u5177\u6709\u63a8\u8fdbGUI\u4ee3\u7406\u6280\u672f\u53d1\u5c55\u7684\u6f5c\u529b\uff0c\u5e76\u5728\u73b0\u5b9e\u4e16\u754c\u4ea4\u4e92\u573a\u666f\u4e2d\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5927\u89c4\u6a21\u4ee3\u7406RL\u8bad\u7ec3\u52a8\u6001\u5206\u6790\u4e3a\u5b9e\u73b0\u7a33\u5b9a\u6027\u548c\u6548\u7387\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2509.02547", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.02547", "abs": "https://arxiv.org/abs/2509.02547", "authors": ["Guibin Zhang", "Hejia Geng", "Xiaohang Yu", "Zhenfei Yin", "Zaibin Zhang", "Zelin Tan", "Heng Zhou", "Zhongzhi Li", "Xiangyuan Xue", "Yijiang Li", "Yifan Zhou", "Yang Chen", "Chen Zhang", "Yutao Fan", "Zihu Wang", "Songtao Huang", "Yue Liao", "Hongru Wang", "Mengyue Yang", "Heng Ji", "Michael Littman", "Jun Wang", "Shuicheng Yan", "Philip Torr", "Lei Bai"], "title": "The Landscape of Agentic Reinforcement Learning for LLMs: A Survey", "comment": null, "summary": "The emergence of agentic reinforcement learning (Agentic RL) marks a paradigm\nshift from conventional reinforcement learning applied to large language models\n(LLM RL), reframing LLMs from passive sequence generators into autonomous,\ndecision-making agents embedded in complex, dynamic worlds. This survey\nformalizes this conceptual shift by contrasting the degenerate single-step\nMarkov Decision Processes (MDPs) of LLM-RL with the temporally extended,\npartially observable Markov decision processes (POMDPs) that define Agentic RL.\nBuilding on this foundation, we propose a comprehensive twofold taxonomy: one\norganized around core agentic capabilities, including planning, tool use,\nmemory, reasoning, self-improvement, and perception, and the other around their\napplications across diverse task domains. Central to our thesis is that\nreinforcement learning serves as the critical mechanism for transforming these\ncapabilities from static, heuristic modules into adaptive, robust agentic\nbehavior. To support and accelerate future research, we consolidate the\nlandscape of open-source environments, benchmarks, and frameworks into a\npractical compendium. By synthesizing over five hundred recent works, this\nsurvey charts the contours of this rapidly evolving field and highlights the\nopportunities and challenges that will shape the development of scalable,\ngeneral-purpose AI agents.", "AI": {"tldr": "\u672c\u8c03\u67e5\u8bba\u6587\u7cfb\u7edf\u5206\u6790\u4e86\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60(Agentic RL)\u8fd9\u4e00\u65b0\u5174\u8303\u5f0f\uff0c\u5c06\u5176\u4e0e\u4f20\u7edfLLM\u5f3a\u5316\u5b66\u4e60\u5bf9\u6bd4\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u6838\u5fc3\u80fd\u529b\u548c\u5e94\u7528\u9886\u57df\u7684\u53cc\u91cd\u5206\u7c7b\u6cd5\uff0c\u5e76\u6574\u5408\u4e86\u5f00\u6e90\u73af\u5883\u3001\u57fa\u51c6\u548c\u6846\u67b6\u8d44\u6e90\u3002", "motivation": "\u4f20\u7edfLLM\u5f3a\u5316\u5b66\u4e60\u5c06\u8bed\u8a00\u6a21\u578b\u89c6\u4e3a\u88ab\u52a8\u5e8f\u5217\u751f\u6210\u5668\uff0c\u800c\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u5c06\u5176\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5728\u590d\u6742\u52a8\u6001\u4e16\u754c\u4e2d\u81ea\u4e3b\u51b3\u7b56\u7684\u667a\u80fd\u4f53\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5730\u5f62\u5f0f\u5316\u8fd9\u4e00\u8303\u5f0f\u8f6c\u53d8\u3002", "method": "\u901a\u8fc7\u5bf9\u6bd4\u5355\u6b65MDP\u548c\u65f6\u5e8f\u6269\u5c55POMDP\u7684\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u5efa\u7acb\u53cc\u91cd\u5206\u7c7b\u6cd5\uff1a\u56f4\u7ed5\u89c4\u5212\u3001\u5de5\u5177\u4f7f\u7528\u3001\u8bb0\u5fc6\u3001\u63a8\u7406\u3001\u81ea\u6211\u6539\u8fdb\u548c\u611f\u77e5\u7b49\u6838\u5fc3\u80fd\u529b\uff0c\u4ee5\u53ca\u8de8\u4e0d\u540c\u4efb\u52a1\u9886\u57df\u7684\u5e94\u7528\u5206\u7c7b\u3002", "result": "\u7cfb\u7edf\u7efc\u5408\u4e86500\u591a\u7bc7\u8fd1\u671f\u7814\u7a76\u5de5\u4f5c\uff0c\u5c06\u5f3a\u5316\u5b66\u4e60\u5b9a\u4f4d\u4e3a\u5c06\u9759\u6001\u542f\u53d1\u5f0f\u6a21\u5757\u8f6c\u5316\u4e3a\u81ea\u9002\u5e94\u9c81\u68d2\u667a\u80fd\u4f53\u884c\u4e3a\u7684\u5173\u952e\u673a\u5236\uff0c\u5e76\u6574\u5408\u4e86\u5f00\u6e90\u8d44\u6e90\u4ee5\u52a0\u901f\u672a\u6765\u7814\u7a76\u3002", "conclusion": "\u8be5\u8c03\u67e5\u63cf\u7ed8\u4e86\u8fd9\u4e00\u5feb\u901f\u53d1\u5c55\u9886\u57df\u7684\u8f6e\u5ed3\uff0c\u5f3a\u8c03\u4e86\u5851\u9020\u53ef\u6269\u5c55\u901a\u7528AI\u667a\u80fd\u4f53\u53d1\u5c55\u7684\u673a\u9047\u548c\u6311\u6218\uff0c\u4e3a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u8df5\u6307\u5357\u3002"}}
