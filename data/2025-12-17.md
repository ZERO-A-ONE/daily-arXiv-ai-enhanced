<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 40]
- [cs.CR](#cs.CR) [Total: 18]
- [cs.SE](#cs.SE) [Total: 22]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [A Monad-Based Clause Architecture for Artificial Age Score (AAS) in Large Language Models](https://arxiv.org/abs/2512.11835)
*Seyma Yaman Kayadibi*

Main category: cs.AI

TL;DR: 基于人工年龄评分(AAS)理论框架，构建了可执行的、基于条款的LLM内存与控制架构，将莱布尼茨单子论中的20个单子分组为6个可执行规范束，通过Python实现展示其可实施性。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型作为强大但不透明系统部署时，其内部记忆和"自我类似"行为缺乏原则性、可审计治理机制的问题。

Method: 1) 以AAS作为核心度量框架；2) 将莱布尼茨单子论中的20个单子分组为6个可执行规范束；3) 通过6个最小Python实现，将条款家族实例化为数值实验；4) 每个实现遵循四步模式：输入设置、条款实现、数值结果、LLM设计启示。

Result: 条款系统展现出有界且可解释的行为：AAS轨迹保持连续且速率受限；矛盾和未支持声明触发明确惩罚；分层细化以受控方式揭示有机结构；和谐项对齐双重视图和目标-行动对；完美度窗口漂移区分持续改进与持续退化。

Conclusion: 基于单子的条款框架以AAS为骨干，为约束和分析人工智能体内部动态提供了透明、代码级的蓝图，不仅具有哲学动机，而且可直接实施。

Abstract: Large language models (LLMs) are often deployed as powerful yet opaque systems, leaving open how their internal memory and "self-like" behavior should be governed in a principled and auditable way. The Artificial Age Score (AAS) was previously introduced and mathematically justified through three theorems that characterise it as a metric of artificial memory aging. Building on this foundation, the present work develops an engineering-oriented, clause-based architecture that imposes law-like constraints on LLM memory and control. Twenty selected monads from Leibniz's Monadology are grouped into six bundles: ontology, dynamics, representation and consciousness, harmony and reason, body and organisation, and teleology, and each bundle is realised as an executable specification on top of the AAS kernel. Across six minimal Python implementations, these clause families are instantiated in numerical experiments acting on channel-level quantities such as recall scores, redundancy, and weights. Each implementation follows a four-step pattern: inputs and setup, clause implementation, numerical results, and implications for LLM design, emphasising that the framework is not only philosophically motivated but also directly implementable. The experiments show that the clause system exhibits bounded and interpretable behavior: AAS trajectories remain continuous and rate-limited, contradictions and unsupported claims trigger explicit penalties, and hierarchical refinement reveals an organic structure in a controlled manner. Dual views and goal-action pairs are aligned by harmony terms, and windowed drift in perfection scores separates sustained improvement from sustained degradation. Overall, the monad-based clause framework uses AAS as a backbone and provides a transparent, code-level blueprint for constraining and analyzing internal dynamics in artificial agents.

</details>


### [2] [Solving Parallel Machine Scheduling With Precedences and Cumulative Resource Constraints With Calendars](https://arxiv.org/abs/2512.11864)
*Christoph Einspieler,Matthias Horn,Marie-Louise Lackner,Patrick Malik,Nysret Musliu,Felix Winter*

Main category: cs.AI

TL;DR: 提出一种解决具有作业优先级和基于日历的累积资源约束的真实工业并行机调度问题的新方法，包括精确约束建模和启发式算法


<details>
  <summary>Details</summary>
Motivation: 现代工厂大规模生产需求下，传统调度方法无法有效处理复杂的优先级约束和日历资源限制，需要开发能解决真实工业场景的自动化调度方法

Method: 提出约束建模方法作为小规模场景的精确解，同时开发构造启发式算法和基于局部搜索的定制元启发式算法处理大规模实例

Result: 开发的方法已在工业环境中部署使用，能够有效解决具有复杂约束的真实并行机调度问题

Conclusion: 提出的混合方法（精确约束建模+启发式算法）能够有效解决工业实际中的复杂并行机调度问题，并已在工业环境中成功应用

Abstract: The task of finding efficient production schedules for parallel machines is a challenge that arises in most industrial manufacturing domains. There is a large potential to minimize production costs through automated scheduling techniques, due to the large-scale requirements of modern factories. In the past, solution approaches have been studied for many machine scheduling variations, where even basic variants have been shown to be NP-hard. However, in today's real-life production environments, additional complex precedence constraints and resource restrictions with calendars arise that must be fulfilled. These additional constraints cannot be tackled efficiently by existing solution techniques. Thus, there is a strong need to develop and analyze automated methods that can solve such real-life parallel machine scheduling scenarios. In this work, we introduce a novel variant of parallel machine scheduling with job precedences and calendar-based cumulative resource constraints that arises in real-life industrial use cases. A constraint modeling approach is proposed as an exact solution method for small scheduling scenarios together with state-of-the-art constraint-solving technology. Further, we propose a construction heuristic as well as a tailored metaheuristic using local search to efficiently tackle large-scale problem instances. This metaheuristic approach has been deployed and is currently being used in an industrial setting.

</details>


### [3] [Mirror Mode in Fire Emblem: Beating Players at their own Game with Imitation and Reinforcement Learning](https://arxiv.org/abs/2512.11902)
*Yanna Elizabeth Smid,Peter van der Putten,Aske Plaat*

Main category: cs.AI

TL;DR: 该研究提出"镜像模式"游戏模式，让AI模仿玩家个人策略来挑战玩家，基于《火焰纹章英雄》简化版进行实验，结合强化学习和模仿学习技术训练模型，玩家测试显示AI能较好模仿防御行为但进攻策略模仿不足，整体提高了玩家满意度。


<details>
  <summary>Details</summary>
Motivation: 在回合制游戏中，敌人策略应该具有惊喜性和不可预测性。传统AI往往使用固定模式，缺乏个性化挑战。本研究旨在开发一种能模仿玩家个人策略的AI模式，让玩家面对自己的游戏风格，从而增加游戏的挑战性和趣味性。

Method: 1. 在Unity中构建《火焰纹章英雄》简化版，包含标准模式和镜像模式；2. 第一组实验：结合生成对抗模仿学习、行为克隆和近端策略优化，寻找适合模仿玩家演示的模型；3. 第二组实验：通过玩家测试评估模型，模型基于参与者提供的演示进行训练。

Result: 1. 玩家游戏行为分析显示AI在防御行为上模仿良好，但在进攻策略上模仿不足；2. 参与者调查表明玩家能识别自己的撤退战术；3. 镜像模式整体获得更高的玩家满意度；4. 模型需要进一步优化以提高模仿质量和玩家满意度。

Conclusion: 镜像模式作为一种新的游戏模式，通过让AI模仿玩家个人策略，成功提高了游戏的挑战性和玩家满意度。虽然当前模型在进攻策略模仿上仍有不足，但证明了这一概念的可行性。进一步优化模型有望提升模仿质量，特别是当玩家面对自己策略时能获得更好的游戏体验。

Abstract: Enemy strategies in turn-based games should be surprising and unpredictable. This study introduces Mirror Mode, a new game mode where the enemy AI mimics the personal strategy of a player to challenge them to keep changing their gameplay. A simplified version of the Nintendo strategy video game Fire Emblem Heroes has been built in Unity, with a Standard Mode and a Mirror Mode. Our first set of experiments find a suitable model for the task to imitate player demonstrations, using Reinforcement Learning and Imitation Learning: combining Generative Adversarial Imitation Learning, Behavioral Cloning, and Proximal Policy Optimization. The second set of experiments evaluates the constructed model with player tests, where models are trained on demonstrations provided by participants. The gameplay of the participants indicates good imitation in defensive behavior, but not in offensive strategies. Participant's surveys indicated that they recognized their own retreating tactics, and resulted in an overall higher player-satisfaction for Mirror Mode. Refining the model further may improve imitation quality and increase player's satisfaction, especially when players face their own strategies. The full code and survey results are stored at: https://github.com/YannaSmid/MirrorMode

</details>


### [4] [Robustness of Probabilistic Models to Low-Quality Data: A Multi-Perspective Analysis](https://arxiv.org/abs/2512.11912)
*Liu Peng,Yaochu Jin*

Main category: cs.AI

TL;DR: 该研究系统比较了不同概率模型对低质量数据的鲁棒性，发现自回归语言模型（如GPT-2）对数据损坏具有显著韧性，而类别条件扩散模型在相同数据损坏下性能急剧下降，分类器则表现出中等影响且随数据集规模增大而减弱。


<details>
  <summary>Details</summary>
Motivation: 研究动机是系统性地探究不同现代概率模型对低质量训练数据的鲁棒性差异，理解为何某些模型在数据损坏情况下仍能保持良好性能，而其他模型则表现脆弱。

Method: 采用系统性比较研究方法，在不同数据损坏水平下测试多种概率模型：自回归语言模型（GPT-2）、类别条件扩散模型和分类器。通过多视角分析框架，结合信息论、PAC学习和梯度动力学理论来解释观察到的鲁棒性差异。

Result: 自回归语言模型表现出显著鲁棒性（GPT-2在50%令牌损坏下测试NLL仅从2.87增加到3.59）；类别条件扩散模型性能急剧下降（图像标签一致性相对基线下降56.81%）；分类器影响中等且随数据集规模增大而减弱。分析表明鲁棒性主要受两个关键原则影响：条件信息的丰富程度和训练数据的绝对信息量。

Conclusion: 不同概率模型对低质量数据的鲁棒性存在显著差异，这种差异主要由条件信息的丰富程度和训练数据的绝对信息量决定。自回归语言模型因其丰富的条件信息而表现出卓越鲁棒性，而类别条件扩散模型对数据质量更为敏感。这些发现对构建鲁棒机器学习系统具有重要指导意义。

Abstract: A systematic, comparative investigation into the effects of low-quality data reveals a stark spectrum of robustness across modern probabilistic models. We find that autoregressive language models, from token prediction to sequence-to-sequence tasks, are remarkably resilient (for GPT-2, test NLL increases modestly from 2.87 to 3.59 despite 50% token corruption). By contrast, under the same levels of data corruption, class-conditional diffusion models degrade catastrophically (image-label consistency plummets by 56.81% relative to baseline), while classifiers show a moderate impact that diminishes with dataset scale. To explain these discrepancies, we analyze the results through a multi-perspective lens, integrating information theory, PAC learning, and gradient dynamics. These analyses suggest that robustness is heavily influenced by two key principles: the richness of conditioning information, which constrains the learning problem, and the absolute information content of the training data, which allows the signal from correct information to dominate statistical noise.

</details>


### [5] [CXL-SpecKV: A Disaggregated FPGA Speculative KV-Cache for Datacenter LLM Serving](https://arxiv.org/abs/2512.11920)
*Dong Liu,Yanxuan Yu*

Main category: cs.AI

TL;DR: CXL-SpecKV：基于CXL互连和FPGA加速器的解耦KV缓存架构，通过内存解耦、推测性预取和压缩技术，解决LLM推理中的内存瓶颈问题，提升吞吐量3.2倍并降低内存成本2.8倍。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在数据中心部署时面临KV缓存占用大量GPU内存的问题，限制了批处理大小和系统吞吐量，需要解决内存瓶颈挑战。

Method: 提出CXL-SpecKV架构，包含三个关键创新：1）基于CXL的内存解耦框架，将KV缓存卸载到远程FPGA内存；2）推测性KV缓存预取机制，预测并预加载未来token的缓存条目；3）FPGA加速的KV缓存压缩解压引擎，减少内存带宽需求。

Result: 在先进LLM模型上评估，CXL-SpecKV相比GPU-only基线实现高达3.2倍的吞吐量提升，内存成本降低2.8倍，同时保持准确性。

Conclusion: 智能内存解耦与推测性执行相结合能有效解决大规模LLM服务中的内存墙挑战，系统代码已开源。

Abstract: Large Language Models (LLMs) have revolutionized natural language processing tasks, but their deployment in datacenter environments faces significant challenges due to the massive memory requirements of key-value (KV) caches. During the autoregressive decoding process, KV caches consume substantial GPU memory, limiting batch sizes and overall system throughput. To address these challenges, we propose \textbf{CXL-SpecKV}, a novel disaggregated KV-cache architecture that leverages Compute Express Link (CXL) interconnects and FPGA accelerators to enable efficient speculative execution and memory disaggregation. Our approach introduces three key innovations: (i) a CXL-based memory disaggregation framework that offloads KV-caches to remote FPGA memory with low latency, (ii) a speculative KV-cache prefetching mechanism that predicts and preloads future tokens' cache entries, and (iii) an FPGA-accelerated KV-cache compression and decompression engine that reduces memory bandwidth requirements by up to 4$\times$. When evaluated on state-of-the-art LLM models, CXL-SpecKV achieves up to 3.2$\times$ higher throughput compared to GPU-only baselines, while reducing memory costs by 2.8$\times$ and maintaining accuracy. Our system demonstrates that intelligent memory disaggregation combined with speculative execution can effectively address the memory wall challenge in large-scale LLM serving. Our code implementation has been open-sourced at https://github.com/FastLM/CXL-SpecKV.

</details>


### [6] [AGAPI-Agents: An Open-Access Agentic AI Platform for Accelerated Materials Design on AtomGPT.org](https://arxiv.org/abs/2512.11935)
*Jaehyung Lee,Justin Ely,Kent Zhang,Akshaya Ajith,Charles Rhys Campbell,Kamal Choudhary*

Main category: cs.AI

TL;DR: AGAPI是一个开源的材料科学AI平台，集成了8个以上开源大语言模型和20多个材料科学API端点，通过智能体架构实现多步骤工作流的自动化执行。


<details>
  <summary>Details</summary>
Motivation: 当前AI在材料科学研究中面临计算生态系统碎片化、可重复性挑战以及依赖商业大语言模型等问题，需要构建一个开放、统一的AI平台来加速材料发现。

Method: 采用Agent-Planner-Executor-Summarizer架构，集成8个以上开源LLM和20多个材料科学API端点，通过统一编排框架实现多步骤工作流的自主构建和执行。

Result: 展示了端到端工作流应用，包括异质结构构建、粉末X射线衍射分析和半导体缺陷工程等复杂任务，通过30多个测试用例验证了平台性能，已有1000多名活跃用户。

Conclusion: AGAPI为可重复、AI加速的材料发现提供了一个可扩展且透明的平台基础，解决了当前材料研究中的碎片化和可重复性问题。

Abstract: Artificial intelligence is reshaping scientific discovery, yet its use in materials research remains limited by fragmented computational ecosystems, reproducibility challenges, and dependence on commercial large language models (LLMs). Here we introduce AGAPI (AtomGPT.org API), an open-access agentic AI platform that integrates more than eight open-source LLMs with over twenty materials-science API endpoints, unifying databases, simulation tools, and machine-learning models through a common orchestration framework. AGAPI employs an Agent-Planner-Executor-Summarizer architecture that autonomously constructs and executes multi-step workflows spanning materials data retrieval, graph neural network property prediction, machine-learning force-field optimization, tight-binding calculations, diffraction analysis, and inverse design. We demonstrate AGAPI through end-to-end workflows, including heterostructure construction, powder X-ray diffraction analysis, and semiconductor defect engineering requiring up to ten sequential operations. In addition, we evaluate AGAPI using 30+ example prompts as test cases and compare agentic predictions with and without tool access against experimental data. With more than 1,000 active users, AGAPI provides a scalable and transparent foundation for reproducible, AI-accelerated materials discovery. AGAPI-Agents codebase is available at https://github.com/atomgptlab/agapi.

</details>


### [7] [Hypergame Rationalisability: Solving Agent Misalignment In Strategic Play](https://arxiv.org/abs/2512.11942)
*Vince Trencsenyi*

Main category: cs.AI

TL;DR: 本文提出了一种基于逻辑的声明式领域特定语言，用于编码超博弈结构和解决方案概念，通过答案集编程实现自动化管道，为异构多智能体系统提供可验证的信念推理框架。


<details>
  <summary>Details</summary>
Motivation: 由于感知差异、信息不对称和有限理性，博弈论参与者对游戏的主观理解可能与实际情况和其他参与者的解释不一致。虽然超博弈理论为处理这种不匹配的心理模型提供了数学框架，但缺乏统一的、形式化的、实用的表示语言和可扩展的算法，阻碍了其在多智能体系统研究中的实际应用。

Method: 引入基于逻辑的声明式领域特定语言来编码超博弈结构和解决方案概念；利用答案集编程开发自动化管道，用于实例化超博弈结构并运行新颖的超博弈理性化程序，该程序能够找到证明看似非理性结果的信念结构。

Result: 提出的语言为超博弈建立了统一的形化体系，为开发基于信念的异构推理器奠定了基础，提供了具有逻辑保证的可验证上下文。这些贡献建立了超博弈理论、多智能体系统和战略AI之间的联系。

Conclusion: 该工作通过引入形式化语言和自动化工具，解决了超博弈理论在实际多智能体系统应用中的关键障碍，为异构信念推理提供了可验证的框架，促进了超博弈理论在战略AI领域的实际应用。

Abstract: Differences in perception, information asymmetries, and bounded rationality lead game-theoretic players to derive a private, subjective view of the game that may diverge from the underlying ground-truth scenario and may be misaligned with other players' interpretations. While typical game-theoretic assumptions often overlook such heterogeneity, hypergame theory provides the mathematical framework to reason about mismatched mental models. Although hypergames have recently gained traction in dynamic applications concerning uncertainty, their practical adoption in multi-agent system research has been hindered by the lack of a unifying, formal, and practical representation language, as well as scalable algorithms for managing complex hypergame structures and equilibria. Our work addresses this gap by introducing a declarative, logic-based domain-specific language for encoding hypergame structures and hypergame solution concepts. Leveraging answer-set programming, we develop an automated pipeline for instantiating hypergame structures and running our novel hypergame rationalisation procedure, a mechanism for finding belief structures that justify seemingly irrational outcomes. The proposed language establishes a unifying formalism for hypergames and serves as a foundation for developing nuanced, belief-based heterogeneous reasoners, offering a verifiable context with logical guarantees. Together, these contributions establish the connection between hypergame theory, multi-agent systems, and strategic AI.

</details>


### [8] [Log Anomaly Detection with Large Language Models via Knowledge-Enriched Fusion](https://arxiv.org/abs/2512.11997)
*Anfeng Peng,Ajesh Koyatan Chathoth,Stephen Lee*

Main category: cs.AI

TL;DR: EnrichLog是一个无需训练、基于日志条目的异常检测框架，通过集成语料库特定和样本特定知识来丰富原始日志条目，提高异常检测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统日志分析技术（如基于模板和序列驱动的方法）经常丢失重要语义信息或难以处理模糊的日志模式，需要一种能够保留语义信息并处理模糊日志的改进方法。

Method: EnrichLog采用检索增强生成技术，集成相关上下文知识（包括历史示例和语料库推理），无需重新训练，同时结合语料库特定和样本特定知识来丰富日志条目。

Result: 在四个大规模系统日志基准数据集上的评估显示，EnrichLog相比五种基线方法持续提升异常检测性能，有效处理模糊日志条目，保持高效推理，同时增强模型置信度和检测准确性。

Conclusion: EnrichLog通过集成语料库特定和样本特定知识，提供了一种准确、可解释且高效的异常检测解决方案，适合实际部署应用。

Abstract: System logs are a critical resource for monitoring and managing distributed systems, providing insights into failures and anomalous behavior. Traditional log analysis techniques, including template-based and sequence-driven approaches, often lose important semantic information or struggle with ambiguous log patterns. To address this, we present EnrichLog, a training-free, entry-based anomaly detection framework that enriches raw log entries with both corpus-specific and sample-specific knowledge. EnrichLog incorporates contextual information, including historical examples and reasoning derived from the corpus, to enable more accurate and interpretable anomaly detection. The framework leverages retrieval-augmented generation to integrate relevant contextual knowledge without requiring retraining. We evaluate EnrichLog on four large-scale system log benchmark datasets and compare it against five baseline methods. Our results show that EnrichLog consistently improves anomaly detection performance, effectively handles ambiguous log entries, and maintains efficient inference. Furthermore, incorporating both corpus- and sample-specific knowledge enhances model confidence and detection accuracy, making EnrichLog well-suited for practical deployments.

</details>


### [9] [The Forecast Critic: Leveraging Large Language Models for Poor Forecast Identification](https://arxiv.org/abs/2512.12059)
*Luke Bhan,Hanyu Zhang,Andrew Gordon Wilson,Michael W. Mahoney,Chuck Arvin*

Main category: cs.AI

TL;DR: LLMs可用于自动化预测监控，能可靠检测不合理预测，性能接近人类水平，无需领域特定微调即可扩展应用。


<details>
  <summary>Details</summary>
Motivation: 在大型零售业务中，预测监控对客户满意度、盈利能力和运营效率至关重要，需要自动化解决方案来评估预测质量。

Method: 提出Forecast Critic系统，利用LLMs的广泛世界知识和推理能力进行预测监控，通过三个实验评估LLMs在时间序列预测质量评估中的能力。

Result: LLMs能可靠检测不合理预测（F1分数0.88），多模态LLMs能有效整合非结构化上下文信号（F1分数0.84），在真实M5数据集上能识别不准确预测。

Conclusion: LLMs即使没有领域特定微调，也能为自动化预测监控和评估提供可行且可扩展的选项，性能接近人类水平。

Abstract: Monitoring forecasting systems is critical for customer satisfaction, profitability, and operational efficiency in large-scale retail businesses. We propose The Forecast Critic, a system that leverages Large Language Models (LLMs) for automated forecast monitoring, taking advantage of their broad world knowledge and strong ``reasoning'' capabilities. As a prerequisite for this, we systematically evaluate the ability of LLMs to assess time series forecast quality, focusing on three key questions. (1) Can LLMs be deployed to perform forecast monitoring and identify obviously unreasonable forecasts? (2) Can LLMs effectively incorporate unstructured exogenous features to assess what a reasonable forecast looks like? (3) How does performance vary across model sizes and reasoning capabilities, measured across state-of-the-art LLMs? We present three experiments, including on both synthetic and real-world forecasting data. Our results show that LLMs can reliably detect and critique poor forecasts, such as those plagued by temporal misalignment, trend inconsistencies, and spike errors. The best-performing model we evaluated achieves an F1 score of 0.88, somewhat below human-level performance (F1 score: 0.97). We also demonstrate that multi-modal LLMs can effectively incorporate unstructured contextual signals to refine their assessment of the forecast. Models correctly identify missing or spurious promotional spikes when provided with historical context about past promotions (F1 score: 0.84). Lastly, we demonstrate that these techniques succeed in identifying inaccurate forecasts on the real-world M5 time series dataset, with unreasonable forecasts having an sCRPS at least 10% higher than that of reasonable forecasts. These findings suggest that LLMs, even without domain-specific fine-tuning, may provide a viable and scalable option for automated forecast monitoring and evaluation.

</details>


### [10] [Reliable Policy Iteration: Performance Robustness Across Architecture and Environment Perturbations](https://arxiv.org/abs/2512.12088)
*S. R. Eshwar,Aniruddha Mukherjee,Kintan Saha,Krishna Agarwal,Gugan Thoppe,Aditya Gopalan,Gal Dalal*

Main category: cs.AI

TL;DR: RPI（可靠策略迭代）在函数逼近设置中恢复了策略迭代的单调性，在CartPole和倒立摆任务中相比主流深度强化学习方法表现出更强的鲁棒性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习方法通常存在样本效率低、训练不稳定和超参数敏感等问题，需要一种更可靠的替代方案。

Method: 提出Reliable Policy Iteration (RPI)方法，在函数逼近设置中恢复策略迭代的单调性，并在CartPole和Inverted Pendulum两个经典控制任务中评估其鲁棒性。

Result: 相比DQN、Double DQN、DDPG、TD3和PPO等主流方法，RPI能更早达到接近最优的性能，并在训练过程中保持稳定。

Conclusion: RPI作为一种更可靠的深度强化学习替代方案，在样本效率、训练稳定性和超参数鲁棒性方面表现出优势。

Abstract: In a recent work, we proposed Reliable Policy Iteration (RPI), that restores policy iteration's monotonicity-of-value-estimates property to the function approximation setting. Here, we assess the robustness of RPI's empirical performance on two classical control tasks -- CartPole and Inverted Pendulum -- under changes to neural network and environmental parameters. Relative to DQN, Double DQN, DDPG, TD3, and PPO, RPI reaches near-optimal performance early and sustains this policy as training proceeds. Because deep RL methods are often hampered by sample inefficiency, training instability, and hyperparameter sensitivity, our results highlight RPI's promise as a more reliable alternative.

</details>


### [11] [Rethinking Label Consistency of In-Context Learning: An Implicit Transductive Label Propagation Perspective](https://arxiv.org/abs/2512.12175)
*Haoyang Chen,Richong Zhang,Junfan Chen*

Main category: cs.AI

TL;DR: 本文提出TopK-SD方法，通过结合语义和标签信息合成数据，选择标签一致的示例作为上下文学习的演示，相比传统TopK方法在多个基准测试中表现更优。


<details>
  <summary>Details</summary>
Motivation: 当前基于检索模型选择语义相似示例作为演示的方法存在局限性，因为无法保证标签一致性。作者从贝叶斯视角和转导标签传播的角度重新思考上下文学习，认为标签一致性对演示选择至关重要。

Method: 提出TopK-SD方法：1）将上下文学习视为转导学习方法；2）建立标签传播框架，将标签一致性与传播误差边界联系起来；3）提出数据合成方法，同时利用语义和标签信息；4）使用合成数据进行TopK采样，获取标签一致的演示。

Result: TopK-SD方法在多个基准测试中优于原始的TopK采样方法，证明了标签一致性在演示选择中的重要性。

Conclusion: 该研究为理解上下文学习的工作机制提供了新视角，强调了标签一致性在演示选择中的关键作用，提出的TopK-SD方法有效提升了上下文学习的性能。

Abstract: Large language models (LLMs) perform in-context learning (ICL) with minimal supervised examples, which benefits various natural language processing (NLP) tasks. One of the critical research focus is the selection of prompt demonstrations. Current approaches typically employ retrieval models to select the top-K most semantically similar examples as demonstrations. However, we argue that existing methods are limited since the label consistency is not guaranteed during demonstration selection. Our cognition derives from the Bayesian view of ICL and our rethinking of ICL from the transductive label propagation perspective. We treat ICL as a transductive learning method and incorporate latent concepts from Bayesian view and deduce that similar demonstrations guide the concepts of query, with consistent labels serving as estimates. Based on this understanding, we establish a label propagation framework to link label consistency with propagation error bounds. To model label consistency, we propose a data synthesis method, leveraging both semantic and label information, and use TopK sampling with Synthetic Data (TopK-SD) to acquire demonstrations with consistent labels. TopK-SD outperforms original TopK sampling on multiple benchmarks. Our work provides a new perspective for understanding the working mechanisms within ICL.

</details>


### [12] [Floorplan2Guide: LLM-Guided Floorplan Parsing for BLV Indoor Navigation](https://arxiv.org/abs/2512.12177)
*Aydin Ayanzadeh,Tim Oates*

Main category: cs.AI

TL;DR: Floorplan2Guide：利用基础模型将平面图转换为可导航知识图谱，为视障用户生成人类可读导航指令的室内导航系统


<details>
  <summary>Details</summary>
Motivation: 当前室内导航解决方案主要依赖基础设施系统，限制了在动态环境中的安全导航能力。需要一种能够减少手动预处理、提高导航精度的新方法，以更好地服务视障用户。

Method: 使用大型语言模型从建筑布局中提取空间信息，将平面图转换为可导航知识图谱，采用少样本学习策略，通过图形表示和上下文学习增强导航性能。

Result: Claude 3.7 Sonnet在5-shot提示下表现最佳，短、中、长路线准确率分别为92.31%、76.92%和61.54%。基于图的空间结构成功率比直接视觉推理高15.4%，证实图形表示和上下文学习能提升导航性能。

Conclusion: Floorplan2Guide通过将平面图转换为知识图谱并生成人类可读指令，为视障用户提供了更精确的室内导航解决方案，少样本学习和图形表示显著提高了导航准确性。

Abstract: Indoor navigation remains a critical challenge for people with visual impairments. The current solutions mainly rely on infrastructure-based systems, which limit their ability to navigate safely in dynamic environments. We propose a novel navigation approach that utilizes a foundation model to transform floor plans into navigable knowledge graphs and generate human-readable navigation instructions. Floorplan2Guide integrates a large language model (LLM) to extract spatial information from architectural layouts, reducing the manual preprocessing required by earlier floorplan parsing methods. Experimental results indicate that few-shot learning improves navigation accuracy in comparison to zero-shot learning on simulated and real-world evaluations. Claude 3.7 Sonnet achieves the highest accuracy among the evaluated models, with 92.31%, 76.92%, and 61.54% on the short, medium, and long routes, respectively, under 5-shot prompting of the MP-1 floor plan. The success rate of graph-based spatial structure is 15.4% higher than that of direct visual reasoning among all models, which confirms that graphical representation and in-context learning enhance navigation performance and make our solution more precise for indoor navigation of Blind and Low Vision (BLV) users.

</details>


### [13] [TA-KAND: Two-stage Attention Triple Enhancement and U-KAN based Diffusion For Few-shot Knowledge Graph Completion](https://arxiv.org/abs/2512.12182)
*Xinyu Gao*

Main category: cs.AI

TL;DR: 提出一个结合两阶段注意力三元增强器和U-KAN扩散模型的少样本知识图谱补全框架，在两个公开数据集上取得SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 现实世界知识图谱存在长尾分布问题，传统基于度量匹配或元学习的方法未能充分利用图邻域信息或忽略对比信号的分布特性，需要新的少样本补全方法。

Method: 从生成表示视角重新审视问题，提出整合两阶段注意力三元增强器与基于U-KAN的扩散模型的少样本知识图谱补全框架。

Result: 在两个公开数据集上的大量实验表明，该方法取得了新的最先进结果。

Conclusion: 提出的生成表示视角和整合注意力增强与扩散模型的方法能有效解决少样本知识图谱补全问题，在性能上超越了现有方法。

Abstract: Knowledge Graphs (KGs), thanks to their concise and efficient triple-based structure, have been widely applied in intelligent question answering, recommender systems and other domains. However, the heterogeneous and multifaceted nature of real-world data inevitably renders the distribution of relations long-tailed, making it crucial to complete missing facts with limited samples. Previous studies mainly based on metric matching or meta learning, yet they either fail to fully exploit neighborhood information in graph or overlook the distributional characteristics of contrastive signals. In this paper, we re-examine the problem from a perspective of generative representation and propose a few-shot knowledge graph completion framework that integrates two-stage attention triple enhancer with U-KAN based diffusion model. Extensive experiments on two public datasets show that our method achieve new state-of-the-art results.

</details>


### [14] [A Geometric Theory of Cognition](https://arxiv.org/abs/2512.12225)
*Laha Ale*

Main category: cs.AI

TL;DR: 本文提出了一种统一的数学框架，将各种认知过程视为单一几何原理的涌现。认知状态表示为具有学习黎曼度量的微分流形上的点，认知过程是该流形上认知势能的黎曼梯度流。


<details>
  <summary>Details</summary>
Motivation: 人类认知包括感知、记忆、直觉判断、审慎推理、行动选择和社会推理等多种能力，但这些能力通常由不同的计算理论解释。本文旨在建立一个统一的数学框架，将这些不同的认知过程整合到一个单一的几何原理中。

Method: 将认知状态表示为具有学习黎曼度量的微分流形上的点，该度量编码了表征约束、计算成本和认知变量之间的结构关系。定义一个标量认知势能，结合预测准确性、结构简洁性、任务效用以及规范或逻辑要求。认知过程被建模为该势能的黎曼梯度流。

Result: 经典的双过程效应（快速直觉反应和较慢的审慎推理）自然地从度量诱导的各向异性中涌现，这些各向异性产生内在时间尺度分离和几何相变，无需引入模块化或混合架构。通过模拟经典认知任务，展示了这些机制的行为特征。

Conclusion: 这些结果为认知建立了几何基础，并为开发更通用、更类似人类的人工智能系统提供了指导原则。该框架为理解认知多样性提供了统一的数学基础。

Abstract: Human cognition spans perception, memory, intuitive judgment, deliberative reasoning, action selection, and social inference, yet these capacities are often explained through distinct computational theories. Here we present a unified mathematical framework in which diverse cognitive processes emerge from a single geometric principle. We represent the cognitive state as a point on a differentiable manifold endowed with a learned Riemannian metric that encodes representational constraints, computational costs, and structural relations among cognitive variables. A scalar cognitive potential combines predictive accuracy, structural parsimony, task utility, and normative or logical requirements. Cognition unfolds as the Riemannian gradient flow of this potential, providing a universal dynamical law from which a broad range of psychological phenomena arise. Classical dual-process effects--rapid intuitive responses and slower deliberative reasoning--emerge naturally from metric-induced anisotropies that generate intrinsic time-scale separations and geometric phase transitions, without invoking modular or hybrid architectures. We derive analytical conditions for these regimes and demonstrate their behavioural signatures through simulations of canonical cognitive tasks. Together, these results establish a geometric foundation for cognition and suggest guiding principles for the development of more general and human-like artificial intelligence systems.

</details>


### [15] [A Multi-Axial Mindset for Ontology Design Lessons from Wikidata's Polyhierarchical Structure](https://arxiv.org/abs/2512.12260)
*Ege Atacan Doğan,Peter F. Patel-Schneider*

Main category: cs.AI

TL;DR: 本文分析了Wikidata的多层次、多轴分类设计，与传统本体论的单层次分类方法形成对比，探讨了这种结构对知识图谱可扩展性和模块化的影响。


<details>
  <summary>Details</summary>
Motivation: 传统本体论设计强调互斥且完备的顶层区分（如持续体与发生体、抽象与具体、类型与实例），这些区分用于构建统一层次结构，每个实体都归属于单一顶层类别。而Wikidata采用不同的方法，不强制执行单一的基础分类体系，而是允许多个分类轴在共享根类"实体"下同时存在。本文旨在分析Wikidata这种多层级、多轴设计带来的结构影响。

Method: 本文通过对比分析的方法，将Wikidata的多层次、多轴分类架构与传统本体论的单层次分类方法进行比较。研究聚焦于Wikidata如何在其知识图谱结构中实现多分类轴的同时存在，以及这种设计如何支持实体在不同分类体系下的灵活归类。

Result: 分析表明，Wikidata的多层次、多轴设计使其能够容纳多个分类体系同时运行，这种架构支持可扩展和模块化的本体构建方法。特别适合协作性和不断演化的知识图谱环境，因为它允许不同领域和视角的分类体系共存，而不需要强制统一到单一的分类框架中。

Conclusion: Wikidata的多层次、多轴分类设计为知识图谱提供了更加灵活和包容的结构框架，与传统本体论的严格单层次分类相比，这种设计更适合大规模协作和不断演化的知识系统，能够更好地适应现实世界中知识的复杂性和多样性。

Abstract: Traditional ontology design emphasizes disjoint and exhaustive top-level distinctions such as continuant vs. occurrent, abstract vs. concrete, or type vs. instance. These distinctions are used to structure unified hierarchies where every entity is classified under a single upper-level category. Wikidata, by contrast, does not enforce a singular foundational taxonomy. Instead, it accommodates multiple classification axes simultaneously under the shared root class entity. This paper analyzes the structural implications of Wikidata's polyhierarchical and multi-axial design. The Wikidata architecture enables a scalable and modular approach to ontology construction, especially suited to collaborative and evolving knowledge graphs.

</details>


### [16] [Entropy Collapse: A Universal Failure Mode of Intelligent Systems](https://arxiv.org/abs/2512.12381)
*Truong Xuan Khanh,Truong Quynh Hoa*

Main category: cs.AI

TL;DR: 论文提出"熵崩溃"作为智能系统的普遍失效模式：当反馈放大超过有界新颖性再生时，系统会从高熵自适应状态急剧过渡到低熵崩溃状态，表现为有效适应维度的收缩而非完全停滞。


<details>
  <summary>Details</summary>
Motivation: 观察到跨领域智能系统（AI、经济制度、生物进化）在提升智能时经常出现反直觉的退化现象：系统变得僵化、失去适应性、意外失效。需要统一的理论框架来解释这些看似不同的崩溃现象。

Method: 在最小化领域无关假设下，将熵崩溃形式化为向稳定低熵流形的收敛过程。通过分析建立临界阈值、动态不可逆性和吸引子结构，并通过最小模拟展示不同更新机制下的普适性。

Result: 证明智能系统存在从高熵自适应状态到低熵崩溃状态的急剧相变，崩溃表现为有效适应维度的收缩而非零熵状态。该框架统一解释了AI模型崩溃、经济制度僵化和进化遗传瓶颈等现象。

Conclusion: 熵崩溃是智能的结构性代价，解释了晚期干预为何系统性失败，并提出了基于熵感知的设计原则来维持智能系统的长期适应性。

Abstract: Intelligent systems are widely assumed to improve through learning, coordination, and optimization. However, across domains -- from artificial intelligence to economic institutions and biological evolution -- increasing intelligence often precipitates paradoxical degradation: systems become rigid, lose adaptability, and fail unexpectedly.
  We identify \emph{entropy collapse} as a universal dynamical failure mode arising when feedback amplification outpaces bounded novelty regeneration. Under minimal domain-agnostic assumptions, we show that intelligent systems undergo a sharp transition from high-entropy adaptive regimes to low-entropy collapsed regimes. Collapse is formalized as convergence toward a stable low-entropy manifold, not a zero-entropy state, implying a contraction of effective adaptive dimensionality rather than loss of activity or scale.
  We analytically establish critical thresholds, dynamical irreversibility, and attractor structure and demonstrate universality across update mechanisms through minimal simulations. This framework unifies diverse phenomena -- model collapse in AI, institutional sclerosis in economics, and genetic bottlenecks in evolution -- as manifestations of the same underlying process.
  By reframing collapse as a structural cost of intelligence, our results clarify why late-stage interventions systematically fail and motivate entropy-aware design principles for sustaining long-term adaptability in intelligent systems.
  \noindent\textbf{Keywords:} entropy collapse; intelligent systems; feedback amplification; phase transitions; effective dimensionality; complex systems; model collapse; institutional sclerosis

</details>


### [17] [Feeling the Strength but Not the Source: Partial Introspection in LLMs](https://arxiv.org/abs/2512.12411)
*Ely Hahami,Lavik Jain,Ishaan Sinha*

Main category: cs.AI

TL;DR: 该研究测试了Anthropic关于模型能够检测和命名注入"概念"的稳健性，发现模型确实能识别注入概念但表现脆弱，同时在某些任务中表现出部分内省能力


<details>
  <summary>Details</summary>
Motivation: 验证Anthropic关于前沿模型能够检测和命名注入"概念"的稳健性，探索内省能力的普遍性和局限性

Method: 1) 在Meta-Llama-3.1-8B-Instruct上复现Anthropic的多轮"涌现内省"结果；2) 系统性地改变推理提示，测试内省的脆弱性；3) 探索部分内省机制，测试模型对归一化注入概念向量系数的分类能力

Result: 1) 成功复现Anthropic结果，模型识别注入概念的成功率为20%；2) 内省表现脆弱，在相关任务上性能崩溃；3) 发现部分内省机制，模型能可靠分类注入概念向量强度，准确率达70%（远高于25%的随机基线）

Conclusion: 语言模型确实能够基于其内部表示进行内省计算，但这些自我报告具有狭窄性和提示敏感性，内省能力并非大型或高能力模型独有

Abstract: Recent work from Anthropic claims that frontier models can sometimes detect and name injected "concepts" represented as activation directions. We test the robustness of these claims. First, we reproduce Anthropic's multi-turn "emergent introspection" result on Meta-Llama-3.1-8B-Instruct, finding that the model identifies and names the injected concept 20 percent of the time under Anthropic's original pipeline, exactly matching their reported numbers and thus showing that introspection is not exclusive to very large or capable models. Second, we systematically vary the inference prompt and find that introspection is fragile: performance collapses on closely related tasks such as multiple-choice identification of the injected concept or different prompts of binary discrimination of whether a concept was injected at all. Third, we identify a contrasting regime of partial introspection: the same model can reliably classify the strength of the coefficient of a normalized injected concept vector (as weak / moderate / strong / very strong) with up to 70 percent accuracy, far above the 25 percent chance baseline. Together, these results provide more evidence for Anthropic's claim that language models effectively compute a function of their baseline, internal representations during introspection; however, these self-reports about those representations are narrow and prompt-sensitive. Our code is available at https://github.com/elyhahami18/CS2881-Introspection.

</details>


### [18] [Understanding Critical Thinking in Generative Artificial Intelligence Use: Development, Validation, and Correlates of the Critical Thinking in AI Use Scale](https://arxiv.org/abs/2512.12413)
*Gabriel R. Lau,Wei Yan Low,Louis Tay,Ysabel Guevarra,Dragan Gašević,Andree Hartanto*

Main category: cs.AI

TL;DR: 开发并验证了13项AI使用批判性思维量表，包含验证、动机和反思三个维度，能预测更准确的AI输出验证和更深的责任反思


<details>
  <summary>Details</summary>
Motivation: 生成式AI工具日益普及，但其流畅性、不透明性和幻觉倾向要求用户必须批判性评估AI输出，而非盲目接受。需要概念化AI使用中的批判性思维并开发测量工具

Method: 通过6项研究(N=1365)开发并验证AI使用批判性思维量表：研究1生成并内容验证项目；研究2支持三因素结构(验证、动机、反思)；研究3-5确认高阶模型，检验信效度；研究6验证量表预测效度

Result: 量表具有良好心理测量特性，AI使用批判性思维与开放性、外向性、积极特质情感和AI使用频率正相关，能预测更频繁多样的验证策略、更高的真实性判断准确性以及更深的责任反思

Conclusion: 研究阐明了人们如何监督生成式AI输出，提供了经过验证的量表和生态效度高的任务范式，支持理论检验、跨群体和纵向研究，促进对生成式AI输出的批判性参与

Abstract: Generative AI tools are increasingly embedded in everyday work and learning, yet their fluency, opacity, and propensity to hallucinate mean that users must critically evaluate AI outputs rather than accept them at face value. The present research conceptualises critical thinking in AI use as a dispositional tendency to verify the source and content of AI-generated information, to understand how models work and where they fail, and to reflect on the broader implications of relying on AI. Across six studies (N = 1365), we developed and validated the 13-item critical thinking in AI use scale and mapped its nomological network. Study 1 generated and content-validated scale items. Study 2 supported a three-factor structure (Verification, Motivation, and Reflection). Studies 3, 4, and 5 confirmed this higher-order model, demonstrated internal consistency and test-retest reliability, strong factor loadings, sex invariance, and convergent and discriminant validity. Studies 3 and 4 further revealed that critical thinking in AI use was positively associated with openness, extraversion, positive trait affect, and frequency of AI use. Lastly, Study 6 demonstrated criterion validity of the scale, with higher critical thinking in AI use scores predicting more frequent and diverse verification strategies, greater veracity-judgement accuracy in a novel and naturalistic ChatGPT-powered fact-checking task, and deeper reflection about responsible AI. Taken together, the current work clarifies why and how people exercise oversight over generative AI outputs and provides a validated scale and ecologically grounded task paradigm to support theory testing, cross-group, and longitudinal research on critical engagement with generative AI outputs.

</details>


### [19] [AI Transparency Atlas: Framework, Scoring, and Real-Time Model Card Evaluation Pipeline](https://arxiv.org/abs/2512.12443)
*Akhmadillo Mamirov,Faiaz Azmain,Hanyu Wang*

Main category: cs.AI

TL;DR: 该研究分析了AI模型文档的碎片化和不一致问题，开发了一个加权透明度框架，并实现了一个自动化多智能体管道来评估模型文档的完整性，发现前沿实验室的合规性约为80%，而大多数提供商的合规性低于60%。


<details>
  <summary>Details</summary>
Motivation: AI模型文档分散在不同平台且结构不一致，导致政策制定者、审计员和用户无法可靠评估安全声明、数据来源和版本级变更，需要统一的透明度评估框架。

Method: 分析了5个前沿模型和100个Hugging Face模型卡，识别了947个独特章节名称；基于欧盟AI法案附件IV和斯坦福透明度指数开发了加权透明度框架（8个章节23个子章节）；实现了自动化多智能体管道，从公开来源提取文档并通过LLM共识评分完整性。

Result: 评估50个模型（视觉、多模态、开源和闭源系统）总成本低于3美元；前沿实验室（xAI、微软、Anthropic）合规性约80%，大多数提供商低于60%；安全关键类别缺陷最大：欺骗行为、幻觉和儿童安全评估分别损失148、124和116个总分。

Conclusion: AI模型文档存在系统性透明度差距，特别是安全关键信息披露不足；自动化评估工具能够高效识别这些差距，为监管合规和透明度改进提供实用解决方案。

Abstract: AI model documentation is fragmented across platforms and inconsistent in structure, preventing policymakers, auditors, and users from reliably assessing safety claims, data provenance, and version-level changes. We analyzed documentation from five frontier models (Gemini 3, Grok 4.1, Llama 4, GPT-5, and Claude 4.5) and 100 Hugging Face model cards, identifying 947 unique section names with extreme naming variation. Usage information alone appeared under 97 distinct labels. Using the EU AI Act Annex IV and the Stanford Transparency Index as baselines, we developed a weighted transparency framework with 8 sections and 23 subsections that prioritizes safety-critical disclosures (Safety Evaluation: 25%, Critical Risk: 20%) over technical specifications. We implemented an automated multi-agent pipeline that extracts documentation from public sources and scores completeness through LLM-based consensus. Evaluating 50 models across vision, multimodal, open-source, and closed-source systems cost less than $3 in total and revealed systematic gaps. Frontier labs (xAI, Microsoft, Anthropic) achieve approximately 80% compliance, while most providers fall below 60%. Safety-critical categories show the largest deficits: deception behaviors, hallucinations, and child safety evaluations account for 148, 124, and 116 aggregate points lost, respectively, across all evaluated models.

</details>


### [20] [MetaHGNIE: Meta-Path Induced Hypergraph Contrastive Learning in Heterogeneous Knowledge Graphs](https://arxiv.org/abs/2512.12477)
*Jiawen Chen,Yanyan He,Qi Shao,Mengli Wei,Duxin Chen,Wenwu Yu,Yanlong Zhao*

Main category: cs.AI

TL;DR: MetaHGNIE：基于元路径诱导超图对比学习的异质知识图谱节点重要性估计框架，通过建模高阶交互和跨模态对齐提升性能


<details>
  <summary>Details</summary>
Motivation: 现有异质知识图谱节点重要性估计方法存在两个主要问题：1）仅依赖成对连接，忽略多实体关系的高阶依赖；2）将结构和语义信号独立处理，缺乏有效的跨模态整合

Method: 提出MetaHGNIE框架：1）通过元路径序列构建高阶知识图谱，类型化超边捕获多实体关系上下文；2）局部注意力聚合结构依赖；3）超图变换器编码语义表示，采用稀疏分块减少冗余；4）多模态融合模块在对比学习和辅助监督下整合结构和语义嵌入

Result: 在基准NIE数据集上的广泛实验表明，MetaHGNIE持续优于最先进的基线方法

Conclusion: 结果验证了在异质知识图谱中显式建模高阶交互和跨模态对齐的有效性

Abstract: Node importance estimation (NIE) in heterogeneous knowledge graphs is a critical yet challenging task, essential for applications such as recommendation, knowledge reasoning, and question answering. Existing methods often rely on pairwise connections, neglecting high-order dependencies among multiple entities and relations, and they treat structural and semantic signals independently, hindering effective cross-modal integration. To address these challenges, we propose MetaHGNIE, a meta-path induced hypergraph contrastive learning framework for disentangling and aligning structural and semantic information. MetaHGNIE constructs a higher-order knowledge graph via meta-path sequences, where typed hyperedges capture multi-entity relational contexts. Structural dependencies are aggregated with local attention, while semantic representations are encoded through a hypergraph transformer equipped with sparse chunking to reduce redundancy. Finally, a multimodal fusion module integrates structural and semantic embeddings under contrastive learning with auxiliary supervision, ensuring robust cross-modal alignment. Extensive experiments on benchmark NIE datasets demonstrate that MetaHGNIE consistently outperforms state-of-the-art baselines. These results highlight the effectiveness of explicitly modeling higher-order interactions and cross-modal alignment in heterogeneous knowledge graphs. Our code is available at https://github.com/SEU-WENJIA/DualHNIE

</details>


### [21] [SafeGen: Embedding Ethical Safeguards in Text-to-Image Generation](https://arxiv.org/abs/2512.12501)
*Dang Phuong Nam,Nguyen Kieu,Pham Thanh Hieu*

Main category: cs.AI

TL;DR: SafeGen是一个将伦理保障直接嵌入文本到图像生成流程的框架，通过BGE-M3文本分类器过滤有害提示和Hyper-SD扩散模型生成高质量图像，在创意自由和伦理责任之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在创造、教育和研究方面带来机遇，但文本到图像系统存在双重使用困境：放大社会偏见、产生高保真虚假信息、侵犯知识产权等伦理问题。

Method: SafeGen框架包含两个互补组件：1) BGE-M3：微调的文本分类器，过滤有害或误导性提示；2) Hyper-SD：优化的扩散模型，生成高保真、语义对齐的图像。基于多语言数据集和公平感知训练过程。

Result: 定量评估显示Hyper-SD达到IS=3.52、FID=22.08、SSIM=0.79，BGE-M3的F1分数为0.81。消融研究验证了领域特定微调的重要性。案例研究展示了SafeGen在阻止不安全提示、生成包容性教学材料和加强学术诚信方面的实际影响。

Conclusion: SafeGen证明了创意自由和伦理责任可以在单一工作流程中协调，为可信AI原则在生成式AI系统中的实际应用提供了可行方案。

Abstract: Generative Artificial Intelligence (AI) has created unprecedented opportunities for creative expression, education, and research. Text-to-image systems such as DALL.E, Stable Diffusion, and Midjourney can now convert ideas into visuals within seconds, but they also present a dual-use dilemma, raising critical ethical concerns: amplifying societal biases, producing high-fidelity disinformation, and violating intellectual property. This paper introduces SafeGen, a framework that embeds ethical safeguards directly into the text-to-image generation pipeline, grounding its design in established principles for Trustworthy AI. SafeGen integrates two complementary components: BGE-M3, a fine-tuned text classifier that filters harmful or misleading prompts, and Hyper-SD, an optimized diffusion model that produces high fidelity, semantically aligned images. Built on a curated multilingual (English- Vietnamese) dataset and a fairness-aware training process, SafeGen demonstrates that creative freedom and ethical responsibility can be reconciled within a single workflow. Quantitative evaluations confirm its effectiveness, with Hyper-SD achieving IS = 3.52, FID = 22.08, and SSIM = 0.79, while BGE-M3 reaches an F1-Score of 0.81. An ablation study further validates the importance of domain-specific fine-tuning for both modules. Case studies illustrate SafeGen's practical impact in blocking unsafe prompts, generating inclusive teaching materials, and reinforcing academic integrity.

</details>


### [22] [KidsArtBench: Multi-Dimensional Children's Art Evaluation with Attribute-Aware MLLMs](https://arxiv.org/abs/2512.12503)
*Mingrui Ye,Chanjin Zheng,Zengyi Yu,Chenyu Xiang,Zhixue Zhao,Zheng Yuan,Helen Yannakoudakis*

Main category: cs.AI

TL;DR: KidsArtBench：首个针对儿童艺术作品的评估基准，包含1000+件5-15岁儿童作品，由12位专家教育者按照9个维度进行多维度标注，支持序数评估和形成性反馈。提出基于属性特定多LoRA的方法，在Qwen2.5-VL-7B模型上将相关性从0.468提升到0.653。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在艺术表达评估方面能力有限，美学概念抽象且开放，儿童艺术作品的多模态标注稀缺。需要建立专门针对儿童艺术作品的评估基准，支持教育性评估和反馈。

Method: 1. 构建KidsArtBench基准：包含1000+件儿童艺术作品，由12位专家教育者按照9个维度（如写实性、想象力等）进行多维度标注，并提供专家评论作为反馈监督。2. 提出属性特定多LoRA方法：每个评估维度对应一个独立的LoRA适配器，结合回归感知微调（RAFT）使预测与序数尺度对齐。

Result: 在Qwen2.5-VL-7B模型上，该方法将相关性从0.468提升到0.653，在感知维度上提升最大，在高阶属性上的差距缩小。结果表明教育者对齐的监督和属性感知训练能够产生教育学上有意义的评估。

Conclusion: KidsArtBench为教育AI的持续进步建立了严格的测试平台，展示了教育者对齐的监督和属性感知训练在儿童艺术作品评估中的有效性。研究团队发布了数据、代码和伦理文档。

Abstract: Multimodal Large Language Models (MLLMs) show remarkable progress across many visual-language tasks; however, their capacity to evaluate artistic expression remains limited. Aesthetic concepts are inherently abstract and open-ended, and multimodal artwork annotations are scarce. We introduce KidsArtBench, a new benchmark of over 1k children's artworks (ages 5-15) annotated by 12 expert educators across 9 rubric-aligned dimensions, together with expert comments for feedback. Unlike prior aesthetic datasets that provide single scalar scores on adult imagery, KidsArtBench targets children's artwork and pairs multi-dimensional annotations with comment supervision to enable both ordinal assessment and formative feedback. Building on this resource, we propose an attribute-specific multi-LoRA approach, where each attribute corresponds to a distinct evaluation dimension (e.g., Realism, Imagination) in the scoring rubric, with Regression-Aware Fine-Tuning (RAFT) to align predictions with ordinal scales. On Qwen2.5-VL-7B, our method increases correlation from 0.468 to 0.653, with the largest gains on perceptual dimensions and narrowed gaps on higher-order attributes. These results show that educator-aligned supervision and attribute-aware training yield pedagogically meaningful evaluations and establish a rigorous testbed for sustained progress in educational AI. We release data and code with ethics documentation.

</details>


### [23] [World Models Unlock Optimal Foraging Strategies in Reinforcement Learning Agents](https://arxiv.org/abs/2512.12548)
*Yesid Fonseca,Manuel S. Ríos,Nicanor Quijano,Luis F. Giraldo*

Main category: cs.AI

TL;DR: 基于模型的强化学习智能体通过习得环境预测表示，自然收敛到与边际价值定理一致的觅食策略，展现了预测能力而非单纯奖励最大化驱动高效决策


<details>
  <summary>Details</summary>
Motivation: 尽管边际价值定理(MVT)在行为生态学中被广泛用于预测觅食行为，但生物觅食者如何实现最优斑块觅食决策的计算机制仍不清楚。研究旨在探索人工智能系统如何通过计算机制实现类似生物觅食者的最优决策

Method: 使用基于模型的强化学习智能体，学习简洁的环境预测表示，研究其斑块觅食决策行为，并与标准无模型强化学习智能体进行比较

Result: 基于模型的智能体自然收敛到与MVT一致的策略，表现出与许多生物觅食者相似的决策模式。预测能力而非单纯奖励最大化驱动了高效的斑块离开行为

Conclusion: 预测性世界模型可以作为AI系统更可解释和生物学基础决策的基础，生态最优性原理对推进可解释和适应性AI具有重要价值

Abstract: Patch foraging involves the deliberate and planned process of determining the optimal time to depart from a resource-rich region and investigate potentially more beneficial alternatives. The Marginal Value Theorem (MVT) is frequently used to characterize this process, offering an optimality model for such foraging behaviors. Although this model has been widely used to make predictions in behavioral ecology, discovering the computational mechanisms that facilitate the emergence of optimal patch-foraging decisions in biological foragers remains under investigation. Here, we show that artificial foragers equipped with learned world models naturally converge to MVT-aligned strategies. Using a model-based reinforcement learning agent that acquires a parsimonious predictive representation of its environment, we demonstrate that anticipatory capabilities, rather than reward maximization alone, drive efficient patch-leaving behavior. Compared with standard model-free RL agents, these model-based agents exhibit decision patterns similar to many of their biological counterparts, suggesting that predictive world models can serve as a foundation for more explainable and biologically grounded decision-making in AI systems. Overall, our findings highlight the value of ecological optimality principles for advancing interpretable and adaptive AI.

</details>


### [24] [Large Language Newsvendor: Decision Biases and Cognitive Mechanisms](https://arxiv.org/abs/2512.12552)
*Jifei Liu,Zhi Chen,Yuanguang Zhong*

Main category: cs.AI

TL;DR: 研究发现大型语言模型在动态报童问题中会复制并放大人类认知偏差，GPT-4因过度思考表现出最大非理性，而效率优化的GPT-4o表现接近最优，表明偏差源于架构限制而非知识缺口。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs越来越多地融入商业决策，它们可能复制甚至放大人类认知偏差的风险尚未得到充分理解，这在供应链管理等高风险运营环境中尤为关键。研究旨在识别LLMs决策模式中的认知偏差本质和来源。

Method: 使用GPT-4、GPT-4o和LLaMA-8B在动态多轮实验中测试五种已确立的决策偏差，采用经典的动态报童问题作为实验框架。

Result: LLMs一致复制了经典的"过低/过高"订购偏差，并显著放大了需求追逐行为等倾向。发现"智能悖论"：更复杂的GPT-4因过度思考表现出最大非理性，而效率优化的GPT-4o表现接近最优。即使提供最优公式，这些偏差仍然存在，表明源于架构限制而非知识缺口。

Conclusion: 管理者应根据具体任务选择模型，效率优化模型在某些优化问题上可能优于复杂模型；LLMs显著放大偏差凸显了高风险决策中需要强有力的人工监督；设计结构化、基于规则的提示是约束模型启发式倾向、提高AI辅助决策可靠性的有效策略。

Abstract: Problem definition: Although large language models (LLMs) are increasingly integrated into business decision making, their potential to replicate and even amplify human cognitive biases cautions a significant, yet not well-understood, risk. This is particularly critical in high-stakes operational contexts like supply chain management. To address this, we investigate the decision-making patterns of leading LLMs using the canonical newsvendor problem in a dynamic setting, aiming to identify the nature and origins of their cognitive biases. Methodology/results: Through dynamic, multi-round experiments with GPT-4, GPT-4o, and LLaMA-8B, we tested for five established decision biases. We found that LLMs consistently replicated the classic ``Too Low/Too High'' ordering bias and significantly amplified other tendencies like demand-chasing behavior compared to human benchmarks. Our analysis uncovered a ``paradox of intelligence'': the more sophisticated GPT-4 demonstrated the greatest irrationality through overthinking, while the efficiency-optimized GPT-4o performed near-optimally. Because these biases persist even when optimal formulas are provided, we conclude they stem from architectural constraints rather than knowledge gaps. Managerial implications: First, managers should select models based on the specific task, as our results show that efficiency-optimized models can outperform more complex ones on certain optimization problems. Second, the significant amplification of bias by LLMs highlights the urgent need for robust human-in-the-loop oversight in high-stakes decisions to prevent costly errors. Third, our findings suggest that designing structured, rule-based prompts is a practical and effective strategy for managers to constrain models' heuristic tendencies and improve the reliability of AI-assisted decisions.

</details>


### [25] [AgentSHAP: Interpreting LLM Agent Tool Importance with Monte Carlo Shapley Value Estimation](https://arxiv.org/abs/2512.12597)
*Miriam Horovicz*

Main category: cs.AI

TL;DR: AgentSHAP是首个解释LLM智能体中工具重要性的框架，基于博弈论中的Shapley值，通过蒙特卡洛采样计算工具贡献度，无需访问模型内部参数。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体使用外部工具解决复杂任务，但缺乏解释哪些工具对响应真正有贡献的方法，现有XAI方法无法解决工具层面的解释问题。

Method: 基于博弈论Shapley值，将智能体视为黑盒，使用蒙特卡洛采样测试不同工具子集下的智能体响应，计算公平的重要性分数，无需访问模型内部权重或梯度。

Result: 在API-Bank上的实验表明，AgentSHAP能产生跨运行一致的重要性分数，正确识别重要工具，区分相关与无关工具，且计算成本从O(2^n)降至实用水平。

Conclusion: AgentSHAP是首个针对智能体工具归因的可解释性方法，与TokenSHAP和PixelSHAP共同构成了基于Shapley值的现代生成AI可解释性工具家族。

Abstract: LLM agents that use external tools can solve complex tasks, but understanding which tools actually contributed to a response remains a blind spot. No existing XAI methods address tool-level explanations. We introduce AgentSHAP, the first framework for explaining tool importance in LLM agents. AgentSHAP is model-agnostic: it treats the agent as a black box and works with any LLM (GPT, Claude, Llama, etc.) without needing access to internal weights or gradients. Using Monte Carlo Shapley values, AgentSHAP tests how an agent responds with different tool subsets and computes fair importance scores based on game theory. Our contributions are: (1) the first explainability method for agent tool attribution, grounded in Shapley values from game theory; (2) Monte Carlo sampling that reduces cost from O(2n) to practical levels; and (3) comprehensive experiments on API-Bank showing that AgentSHAP produces consistent scores across runs, correctly identifies which tools matter, and distinguishes relevant from irrelevant tools. AgentSHAP joins TokenSHAP (for tokens) and PixelSHAP (for image regions) to complete a family of Shapley-based XAI tools for modern generative AI. Code: https://github.com/GenAISHAP/TokenSHAP.

</details>


### [26] [Value-Aware Multiagent Systems](https://arxiv.org/abs/2512.12652)
*Nardine Osman*

Main category: cs.AI

TL;DR: 该论文提出了价值感知AI的概念，超越了传统的价值对齐问题，并提供了一个简明的工程化路线图，围绕三个核心支柱展开。


<details>
  <summary>Details</summary>
Motivation: 传统AI系统主要关注功能性和性能，但缺乏对人类价值的理解和整合。作者认为需要超越简单的价值对齐，让AI系统真正"感知"价值，从而更好地服务于人类社会。

Method: 提出了价值感知AI的工程化路线图，围绕三个核心支柱：1) 使用形式语义学习和表示人类价值；2) 确保个体智能体和多智能体系统的价值对齐；3) 提供基于价值的行为可解释性。

Result: 论文展示了在这些主题上的正在进行的研究工作，包括在现实生活领域中的应用案例，证明了该路线图的可行性和实用性。

Conclusion: 价值感知AI为构建更负责任、更符合人类价值观的AI系统提供了系统化的工程框架，有助于解决AI与人类社会价值整合的根本问题。

Abstract: This paper introduces the concept of value awareness in AI, which goes beyond the traditional value-alignment problem. Our definition of value awareness presents us with a concise and simplified roadmap for engineering value-aware AI. The roadmap is structured around three core pillars: (1) learning and representing human values using formal semantics, (2) ensuring the value alignment of both individual agents and multiagent systems, and (3) providing value-based explainability on behaviour. The paper presents a selection of our ongoing work on some of these topics, along with applications to real-life domains.

</details>


### [27] [WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment](https://arxiv.org/abs/2512.12692)
*Mahir Labib Dihan,Tanzima Hashem,Mohammed Eunus Ali,Md Rizwan Parvez*

Main category: cs.AI

TL;DR: WebOperator是一个树搜索框架，通过最佳优先搜索、安全回溯机制和多推理上下文生成动作候选，解决LLM智能体在部分可观测的Web环境中缺乏远见和无法安全回溯的问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的智能体在Web环境中以贪婪、逐步的方式操作，缺乏长期规划和回溯能力。在部分可观测的Web环境中，单步错误需要复杂的导航来纠正，而现有树搜索方法缺乏安全回溯机制，且假设所有动作可逆，这在现实Web任务中效果有限。

Method: WebOperator采用树搜索框架，包含：1) 最佳优先搜索策略，根据奖励估计和安全考虑对动作排序；2) 鲁棒的回溯机制，在重放路径前验证可行性以防止意外副作用；3) 从多个变化的推理上下文生成动作候选以确保探索多样性；4) 通过预执行过滤无效动作和合并语义等价动作来筛选高质量动作集。

Result: 在WebArena和WebVoyager上的实验表明WebOperator的有效性。在WebArena上，WebOperator使用gpt-4o实现了54.6%的最新成功率，证明了战略远见与安全执行结合的关键优势。

Conclusion: WebOperator通过集成战略远见与安全执行，解决了LLM智能体在Web环境中的探索和回溯挑战，显著提升了任务成功率，为部分可观测环境中的智能体决策提供了有效框架。

Abstract: LLM-based agents often operate in a greedy, step-by-step manner, selecting actions solely based on the current observation without considering long-term consequences or alternative paths. This lack of foresight is particularly problematic in web environments, which are only partially observable-limited to browser-visible content (e.g., DOM and UI elements)-where a single misstep often requires complex and brittle navigation to undo. Without an explicit backtracking mechanism, agents struggle to correct errors or systematically explore alternative paths. Tree-search methods provide a principled framework for such structured exploration, but existing approaches lack mechanisms for safe backtracking, making them prone to unintended side effects. They also assume that all actions are reversible, ignoring the presence of irreversible actions-limitations that reduce their effectiveness in realistic web tasks. To address these challenges, we introduce WebOperator, a tree-search framework that enables reliable backtracking and strategic exploration. Our method incorporates a best-first search strategy that ranks actions by both reward estimates and safety considerations, along with a robust backtracking mechanism that verifies the feasibility of previously visited paths before replaying them, preventing unintended side effects. To further guide exploration, WebOperator generates action candidates from multiple, varied reasoning contexts to ensure diverse and robust exploration, and subsequently curates a high-quality action set by filtering out invalid actions pre-execution and merging semantically equivalent ones. Experimental results on WebArena and WebVoyager demonstrate the effectiveness of WebOperator. On WebArena, WebOperator achieves a state-of-the-art 54.6% success rate with gpt-4o, underscoring the critical advantage of integrating strategic foresight with safe execution.

</details>


### [28] [Causal Counterfactuals Reconsidered](https://arxiv.org/abs/2512.12804)
*Sander Beckers*

Main category: cs.AI

TL;DR: 提出了一种新的反事实概率语义学，它推广了标准的Pearl语义学，适用于无法扩展为现实结构因果模型的概率因果模型，解决了Pearl和Dawid关于反事实的长期争论。


<details>
  <summary>Details</summary>
Motivation: 需要解决Pearl语义学的局限性，因为它无法处理无法扩展为现实结构因果模型的概率因果模型。作者发现即使在简单设置中也会出现这类模型，因此需要更通用的语义学来调和Pearl和Dawid关于反事实的争论。

Method: 提出新的反事实概率语义学，限制在满足马尔可夫条件、只包含现实变量且因果完备的因果模型上。虽然使用结构因果模型来表述，但避免使用所谓的响应变量。证明了该语义学与其他两种不涉及结构因果模型的近期提议是等价的。

Result: 新语义学成功推广了Pearl语义学，适用于更广泛的概率因果模型。它调和了Pearl和Dawid的争论：同意Dawid拒绝普遍因果决定论和不现实变量，但同意Pearl认为一般反事实语义学是可能的。证明了与两种其他提议的等价性，并与文献中关于随机反事实的各种评论一致。

Conclusion: 提出了一种既实用又理论严谨的反事实概率语义学，在Pearl的结构因果模型方法和Dawid的批评之间找到了平衡点。同时探讨了马尔可夫条件的普遍性和因果抽象的新推广，为反事实推理提供了更坚实的基础。

Abstract: I develop a novel semantics for probabilities of counterfactuals that generalizes the standard Pearlian semantics: it applies to probabilistic causal models that cannot be extended into realistic structural causal models and are therefore beyond the scope of Pearl's semantics. This generalization is needed because, as I show, such probabilistic causal models arise even in simple settings. My semantics offer a natural compromize in the long-standing debate between Pearl and Dawid over counterfactuals: I agree with Dawid that universal causal determinism and unrealistic variables should be rejected, but I agree with Pearl that a general semantics of counterfactuals is nonetheless possible. I restrict attention to causal models that satisfy the Markov condition, only contain realistic variables, and are causally complete. Although I formulate my proposal using structural causal models, as does Pearl, I refrain from using so-called response variables. Moreover, I prove that my semantics is equivalent to two other recent proposals that do not involve structural causal models, and that it is in line with various comments on stochastic counterfactuals that have appeared in the literature more broadly. Throughout I also reflect on the universality of the Markov condition and explore a novel generalization of causal abstractions

</details>


### [29] [Forgetful but Faithful: A Cognitive Memory Architecture and Benchmark for Privacy-Aware Generative Agents](https://arxiv.org/abs/2512.12856)
*Saad Alqithami*

Main category: cs.AI

TL;DR: 本文提出了Memory-Aware Retention Schema (MaRS)框架和六种遗忘策略，用于生成式智能体的记忆管理，解决了性能、隐私和计算效率的平衡问题。


<details>
  <summary>Details</summary>
Motivation: 随着生成式智能体在长期交互场景中的部署，其记忆管理能力成为性能和隐私的关键瓶颈。现有方法要么维持无限记忆存储导致计算不可行和隐私问题，要么采用简单的遗忘机制损害智能体的一致性和功能。

Method: 提出了Memory-Aware Retention Schema (MaRS)框架，结合六种理论基础的遗忘策略，平衡性能、隐私和计算效率。开发了Forgetful but Faithful Agent (FiFA)基准测试框架，评估叙事连贯性、目标完成、社交回忆准确性、隐私保护和成本效率。

Result: 通过300次评估运行，混合遗忘策略在多个记忆预算和智能体配置中实现了优越性能（综合得分：0.911），同时保持计算可行性和隐私保证。

Conclusion: 为记忆预算智能体评估建立了新基准，为在资源受限、隐私敏感环境中部署生成式智能体提供了实用指南，通过解决直接影响用户信任、系统可扩展性和监管合规性的智能体记忆管理基本挑战，推动了以人为中心AI领域的发展。

Abstract: As generative agents become increasingly sophisticated and deployed in long-term interactive scenarios, their memory management capabilities emerge as a critical bottleneck for both performance and privacy. Current approaches either maintain unlimited memory stores, leading to computational intractability and privacy concerns, or employ simplistic forgetting mechanisms that compromise agent coherence and functionality. This paper introduces the Memory-Aware Retention Schema (MaRS), a novel framework for human-centered memory management in generative agents, coupled with six theoretically-grounded forgetting policies that balance performance, privacy, and computational efficiency. We present the Forgetful but Faithful Agent (FiFA) benchmark, a comprehensive evaluation framework that assesses agent performance across narrative coherence, goal completion, social recall accuracy, privacy preservation, and cost efficiency. Through extensive experimentation involving 300 evaluation runs across multiple memory budgets and agent configurations, we demonstrate that our hybrid forgetting policy achieves superior performance (composite score: 0.911) while maintaining computational tractability and privacy guarantees. Our work establishes new benchmarks for memory-budgeted agent evaluation and provides practical guidelines for deploying generative agents in resource-constrained, privacy-sensitive environments. The theoretical foundations, implementation framework, and empirical results contribute to the emerging field of human-centered AI by addressing fundamental challenges in agent memory management that directly impact user trust, system scalability, and regulatory compliance.

</details>


### [30] [Towards Open Standards for Systemic Complexity in Digital Forensics](https://arxiv.org/abs/2512.12970)
*Paola Di Maio*

Main category: cs.AI

TL;DR: 该论文提出了基于开放标准和人类可读工件的数字取证AI模型架构，以解决AI与数字取证交叉领域中的系统性复杂性和错误问题。


<details>
  <summary>Details</summary>
Motivation: AI与数字取证交叉领域日益复杂且普遍，尽管技术不断进步，但取证科学仍存在错误和脆弱性。需要解决系统性复杂性以减轻数字取证中的错误限制。

Method: 采用人类可读的工件和开放标准来应对系统性复杂性，并基于当前最先进技术提出了数字取证AI模型架构。

Result: 论文概述了一个基于最先进技术的数字取证AI模型架构，该架构通过人类可读工件和开放标准来增强系统的可靠性和可解释性。

Conclusion: 通过采用人类可读工件和开放标准，可以解决AI与数字取证交叉领域的系统性复杂性，减少错误并提高数字取证过程的可靠性和透明度。

Abstract: The intersection of artificial intelligence (AI) and digital forensics (DF) is becoming increasingly complex, ubiquitous, and pervasive, with overlapping techniques and technologies being adopted in all types of scientific and technical inquiry. Despite incredible advances, forensic sciences are not exempt from errors and remain vulnerable to fallibility. To mitigate the limitations of errors in DF, the systemic complexity is identified and addressed with the adoption of human-readable artifacts and open standards. A DF AI model schema based on the state of the art is outlined.

</details>


### [31] [M-GRPO: Stabilizing Self-Supervised Reinforcement Learning for Large Language Models with Momentum-Anchored Policy Optimization](https://arxiv.org/abs/2512.13070)
*Bizhe Bai,Hongming Wu,Peng Ye,Tao Chen*

Main category: cs.AI

TL;DR: 本文提出M-GRPO和IQR过滤两种方法解决自监督强化学习中长期训练时的策略崩溃问题，通过动量锚定和动态轨迹过滤实现稳定训练和最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有自监督强化学习方法在长期训练中会出现"策略崩溃"问题，性能急剧下降。即使增加rollout数量也只能延迟而非防止崩溃，需要新的稳定训练方法。

Method: 提出M-GRPO（动量锚定组相对策略优化）框架，利用缓慢演化的动量模型提供稳定训练目标；同时提出基于四分位距的自适应过滤方法，动态修剪低熵轨迹以保持策略多样性。

Result: 在多个推理基准测试上的广泛实验表明，M-GRPO稳定了训练过程，IQR过滤器防止了过早收敛，两者结合实现了卓越的训练稳定性和最先进的性能。

Conclusion: 通过M-GRPO的稳定训练目标和IQR过滤器的策略多样性保护，有效解决了自监督强化学习中的策略崩溃问题，为LLM推理能力提升提供了可靠方法。

Abstract: Self-supervised reinforcement learning (RL) presents a promising approach for enhancing the reasoning capabilities of Large Language Models (LLMs) without reliance on expensive human-annotated data. However, we find that existing methods suffer from a critical failure mode under long-horizon training: a "policy collapse" where performance precipitously degrades. We diagnose this instability and demonstrate that simply scaling the number of rollouts -- a common strategy to improve performance -- only delays, but does not prevent, this collapse. To counteract this instability, we first introduce M-GRPO (Momentum-Anchored Group Relative Policy Optimization), a framework that leverages a slowly evolving momentum model to provide a stable training target. In addition, we identify that this process is often accompanied by a rapid collapse in policy entropy, resulting in a prematurely confident and suboptimal policy. To specifically address this issue, we propose a second contribution: an adaptive filtering method based on the interquartile range (IQR) that dynamically prunes low-entropy trajectories, preserving essential policy diversity. Our extensive experiments on multiple reasoning benchmarks demonstrate that M-GRPO stabilizes the training process while the IQR filter prevents premature convergence. The combination of these two innovations leads to superior training stability and state-of-the-art performance.

</details>


### [32] [Socratic Students: Teaching Language Models to Learn by Asking Questions](https://arxiv.org/abs/2512.13102)
*Rajeev Bhatt Ambati,Tianyi Niu,Aashu Singh,Shlok Mishra,Shashank Srivastava,Snigdha Chaturvedi*

Main category: cs.AI

TL;DR: 该研究探讨了在大语言模型交互学习中，从传统的教师主导模式转向学生主动提问策略，通过直接偏好优化训练学生模型，显著提升了数学和编程任务的学习效率。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型擅长静态交互，但在需要动态获取信息的真实场景（如教育辅导、医疗协助）中表现不足。传统研究主要关注教师如何有效指导学生，而本研究将焦点转向学生如何主动向教师提问以获取有用信息。

Method: 研究采用学生主导的交互策略，让学生模型能够识别自身不确定性并提出有针对性的问题。使用直接偏好优化（DPO）方法训练学生模型，通过自我指导或更强学生模型的指导来提升提问质量。

Result: 在数学和编程基准测试中，学生主导方法相比静态基线实现了至少0.5的绝对Pass@k提升。通过DPO引导训练，较小的模型学会了如何提出更好的问题，进一步提高了学习效率。

Conclusion: 学生主动提问策略在交互学习中具有显著优势，通过适当的训练方法（如DPO）可以提升学生模型的提问质量，从而更有效地获取知识，为需要动态交互的真实应用场景提供了新的解决方案。

Abstract: Large Language Models (LLMs) excel at static interactions, where they answer user queries by retrieving knowledge encoded in their parameters. However, in many real-world settings, such as educational tutoring or medical assistance, relevant information is not directly available and must be actively acquired through dynamic interactions. An interactive agent would recognize its own uncertainty, ask targeted questions, and retain new knowledge efficiently. Prior work has primarily explored effective ways for a teacher to instruct the student, where the teacher identifies student gaps and provides guidance. In this work, we shift the focus to the student and investigate effective strategies to actively query the teacher in seeking useful information. Across math and coding benchmarks, where baseline student models begin with near-zero performance, we show that student-led approaches consistently yield absolute Pass@k improvements of at least 0.5 over static baselines. To improve question quality, we train students using Direct Preference Optimization (DPO) with guidance from either self or stronger students. We find that this guided training enables smaller models to learn how to ask better questions, further enhancing learning efficiency.

</details>


### [33] [Towards Unified Co-Speech Gesture Generation via Hierarchical Implicit Periodicity Learning](https://arxiv.org/abs/2512.13131)
*Xin Guo,Yifan Zhao,Jia Li*

Main category: cs.AI

TL;DR: 提出了一种分层隐式周期性学习框架，用于从语音生成更自然的3D身体动作，通过建模不同运动单元之间的内在关联性来改善现有方法的协调性问题。


<details>
  <summary>Details</summary>
Motivation: 现有从语音生成3D身体动作的方法（如GAN、VQ-VAE、扩散模型）作为不适定问题，未能充分建模头部、身体和手部等不同运动单元之间的关键内在关联，导致动作不自然且协调性差。

Method: 提出分层隐式周期性学习框架，包含两个核心技术：1）使用周期性自编码器探索手势运动相位流形，从真实分布中模仿人类自然特性，同时结合当前潜在状态的非周期性特征实现实例级多样性；2）通过级联引导建模面部动作、身体姿势和手部运动之间的层次关系。

Result: 在3D虚拟角色上的实验表明，该方法在定量和定性评估上都优于当前最先进的语音驱动手势生成方法。

Conclusion: 通过建模运动单元之间的内在关联性，提出的分层隐式周期性学习方法能够生成更自然、协调的语音驱动3D身体动作，为解决这一不适定问题提供了新思路。

Abstract: Generating 3D-based body movements from speech shows great potential in extensive downstream applications, while it still suffers challenges in imitating realistic human movements. Predominant research efforts focus on end-to-end generation schemes to generate co-speech gestures, spanning GANs, VQ-VAE, and recent diffusion models. As an ill-posed problem, in this paper, we argue that these prevailing learning schemes fail to model crucial inter- and intra-correlations across different motion units, i.e. head, body, and hands, thus leading to unnatural movements and poor coordination. To delve into these intrinsic correlations, we propose a unified Hierarchical Implicit Periodicity (HIP) learning approach for audio-inspired 3D gesture generation. Different from predominant research, our approach models this multi-modal implicit relationship by two explicit technique insights: i) To disentangle the complicated gesture movements, we first explore the gesture motion phase manifolds with periodic autoencoders to imitate human natures from realistic distributions while incorporating non-period ones from current latent states for instance-level diversities. ii) To model the hierarchical relationship of face motions, body gestures, and hand movements, driving the animation with cascaded guidance during learning. We exhibit our proposed approach on 3D avatars and extensive experiments show our method outperforms the state-of-the-art co-speech gesture generation methods by both quantitative and qualitative evaluations. Code and models will be publicly available.

</details>


### [34] [Can AI Understand What We Cannot Say? Measuring Multilevel Alignment Through Abortion Stigma Across Cognitive, Interpersonal, and Structural Levels](https://arxiv.org/abs/2512.13142)
*Anika Sharma,Malavika Mampally,Chidaksh Ravuru,Kandyce Brennan,Neil Gaikwad*

Main category: cs.AI

TL;DR: LLMs缺乏对堕胎污名的多层次连贯理解，在认知、人际和结构层面均存在系统性偏差，表明当前对齐方法仅确保语言恰当而非真正理解。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型越来越多地介入污名化的健康决策，需要评估它们是否真正理解复杂的心理和生理现象，特别是在人们难以言说的敏感领域。

Method: 使用经过验证的个体层面堕胎污名量表（ILAS），系统测试了5个主流LLM中的627个不同人口统计特征的人物角色，进行多层次分析。

Result: 模型在所有层面都未能通过真正理解的测试：高估人际污名、低估认知污名、假设统一的社区谴责、引入人类验证数据中不存在的人口统计偏见、错过经验验证的污名-保密关系、在理论建构中自相矛盾。

Conclusion: 当前对齐方法仅确保语言恰当而非连贯的多层次理解，AI安全需要新的设计（多层次连贯性）、评估（持续审计）、治理和监管方法，以及AI素养教育。

Abstract: As large language models increasingly mediate stigmatized health decisions, their capacity to genuinely understand complex psychological and physiological phenomena remains poorly evaluated. Can AI understand what we cannot say? We investigate whether LLMs coherently represent abortion stigma across the cognitive, interpersonal, and structural levels where it operates. We systematically tested 627 demographically diverse personas across five leading LLMs using the validated Individual Level Abortion Stigma Scale (ILAS). Our multilevel analysis examined whether models coherently represent stigma at the cognitive level (self-judgment), interpersonal level (anticipated judgment and isolation), and structural level (community condemnation and disclosure patterns), as well as overall stigma. Models fail tests of genuine understanding across all levels. They overestimate interpersonal stigma while underestimating cognitive stigma, assume uniform community condemnation, introduce demographic biases absent from human validation data, miss the empirically validated stigma-secrecy relationship, and contradict themselves within theoretical constructs. These patterns reveal that current alignment approaches ensure appropriate language but not coherent multilevel understanding. This work provides empirical evidence that current LLMs lack coherent multilevel understanding of psychological and physiological constructs. AI safety in high-stakes contexts demands new approaches to design (multilevel coherence), evaluation (continuous auditing), governance and regulation (mandatory audits, accountability, deployment restrictions), and AI literacy in domains where understanding what people cannot say determines whether support helps or harms.

</details>


### [35] [SpeakRL: Synergizing Reasoning, Speaking, and Acting in Language Models with Reinforcement Learning](https://arxiv.org/abs/2512.13159)
*Emre Can Acikgoz,Jinoh Oh,Jie Hao,Joo Hyuk Jeon,Heng Ji,Dilek Hakkani-Tür,Gokhan Tur,Xiang Li,Chengyuan Ma,Xing Fan*

Main category: cs.AI

TL;DR: SpeakRL是一种强化学习方法，通过奖励智能体主动与用户互动（如提出澄清问题）来增强其对话能力，在任务完成率上比基础模型提升20.14%


<details>
  <summary>Details</summary>
Motivation: 当前人机协作主要是单向的，用户向智能体发出指令或提问，智能体直接回应而不寻求必要的澄清或确认。随着智能体能力的提升，需要更主动的参与来澄清用户意图、解决歧义并适应变化的环境。现有工作未充分利用语言模型的对话能力，将智能体优化为更好的跟随者而非有效的发言者。

Method: 提出SpeakRL强化学习方法，通过奖励智能体主动与用户互动（如提出正确的澄清问题）来增强其对话能力。创建SpeakER合成数据集，包含任务导向对话中的多样化场景，任务通过交互式澄清问题解决。系统分析对话主动性的奖励设计，提出原则性的奖励公式，教导智能体平衡提问与行动。

Result: 实证评估显示，该方法在任务完成率上比基础模型提升20.14%的绝对改进，且不增加对话轮次，甚至超越了更大的专有模型，证明了以澄清为中心的用户-智能体交互的潜力。

Conclusion: SpeakRL方法通过强化学习奖励智能体的主动对话行为，显著提高了任务完成效果，展示了智能体主动澄清用户意图的重要性，为人机协作提供了更有效的交互范式。

Abstract: Effective human-agent collaboration is increasingly prevalent in real-world applications. Current trends in such collaborations are predominantly unidirectional, with users providing instructions or posing questions to agents, where agents respond directly without seeking necessary clarifications or confirmations. However, the evolving capabilities of these agents require more proactive engagement, where agents should dynamically participate in conversations to clarify user intents, resolve ambiguities, and adapt to changing circumstances. Existing prior work under-utilize the conversational capabilities of language models (LMs), thereby optimizing agents as better followers rather than effective speakers. In this work, we introduce SpeakRL, a reinforcement learning (RL) method that enhances agents' conversational capabilities by rewarding proactive interactions with users, such as asking right clarification questions when necessary. To support this, we curate SpeakER, a synthetic dataset that includes diverse scenarios from task-oriented dialogues, where tasks are resolved through interactive clarification questions. We present a systematic analysis of reward design for conversational proactivity and propose a principled reward formulation for teaching agents to balance asking with acting. Empirical evaluations demonstrate that our approach achieves a 20.14% absolute improvement in task completion over base models without increasing conversation turns even surpassing even much larger proprietary models, demonstrating the promise of clarification-centric user-agent interactions.

</details>


### [36] [Reflective Preference Optimization (RPO): Enhancing On-Policy Alignment via Hint-Guided Reflection](https://arxiv.org/abs/2512.13240)
*Zihui Zhao,Zechang Li*

Main category: cs.AI

TL;DR: RPO提出了一种改进DPO的方法，通过引入外部模型生成的反思提示来增强偏好对之间的对比性，解决标准DPO中学习信号弱、收敛慢的问题。


<details>
  <summary>Details</summary>
Motivation: 标准DPO中，选择和拒绝的响应都来自同一策略，两者常包含相似错误且KL散度小，导致学习信号弱、收敛缓慢不稳定。

Method: RPO框架在DPO基础上引入提示引导的反思机制：使用外部模型识别幻觉来源并生成简洁的反思提示，构建具有更强对比性和更清晰偏好信号的策略内偏好对。

Result: RPO在更少的训练样本和迭代次数下实现更好的对齐效果，显著降低幻觉率，在多模态基准测试中达到最先进性能。

Conclusion: RPO通过引入反思提示增强DPO的对比学习信号，理论上提高了期望偏好边际，实践中提升了样本效率和性能，是改进对齐方法的有效框架。

Abstract: Direct Preference Optimization (DPO) has emerged as a lightweight and effective alternative to Reinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning with AI Feedback (RLAIF) for aligning large language and vision-language models. However, the standard DPO formulation, in which both the chosen and rejected responses are generated by the same policy, suffers from a weak learning signal because the two responses often share similar errors and exhibit small Kullback-Leibler (KL) divergence. This leads to slow and unstable convergence. To address this limitation, we introduce Reflective Preference Optimization (RPO), a new framework that incorporates hint-guided reflection into the DPO paradigm. RPO uses external models to identify hallucination sources and generate concise reflective hints, enabling the construction of on-policy preference pairs with stronger contrastiveness and clearer preference signals. We theoretically show that conditioning on hints increases the expected preference margin through mutual information and improves sample efficiency while remaining within the policy distribution family. Empirically, RPO achieves superior alignment with fewer training samples and iterations, substantially reducing hallucination rates and delivering state-of-the-art performance across multimodal benchmarks.

</details>


### [37] [Behavior and Representation in Large Language Models for Combinatorial Optimization: From Feature Extraction to Algorithm Selection](https://arxiv.org/abs/2512.13374)
*Francesca Da Ros,Luca Di Gaspero,Kevin Roitero*

Main category: cs.AI

TL;DR: LLMs在组合优化问题中能学习到有意义的结构信息，其隐藏层表示与传统特征提取方法在算法选择任务中表现相当


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究探索LLMs如何生成或解决优化模型，但对其学习问题结构或算法行为的能力了解不足，本研究旨在探究LLMs如何内部表示组合优化问题及其对下游决策任务的支持能力

Method: 采用双重方法：1)直接查询评估LLMs显式提取实例特征的能力；2)探测分析检查此类信息是否隐式编码在隐藏层中。探测框架进一步扩展到按实例算法选择任务，评估LLM衍生表示能否预测最佳求解器。实验涵盖四个基准问题和三种实例表示

Result: LLMs表现出中等能力从问题实例中恢复特征信息（通过直接查询或探测）。值得注意的是，LLM隐藏层表示的预测能力与传统特征提取方法相当，表明LLMs捕获了与优化性能相关的有意义结构信息

Conclusion: LLMs能够学习组合优化问题的有意义结构表示，这些表示在算法选择等下游任务中具有实际应用价值，为LLMs在优化领域的进一步应用提供了理论基础

Abstract: Recent advances in Large Language Models (LLMs) have opened new perspectives for automation in optimization. While several studies have explored how LLMs can generate or solve optimization models, far less is understood about what these models actually learn regarding problem structure or algorithmic behavior. This study investigates how LLMs internally represent combinatorial optimization problems and whether such representations can support downstream decision tasks. We adopt a twofold methodology combining direct querying, which assesses LLM capacity to explicitly extract instance features, with probing analyses that examine whether such information is implicitly encoded within their hidden layers. The probing framework is further extended to a per-instance algorithm selection task, evaluating whether LLM-derived representations can predict the best-performing solver. Experiments span four benchmark problems and three instance representations. Results show that LLMs exhibit moderate ability to recover feature information from problem instances, either through direct querying or probing. Notably, the predictive power of LLM hidden-layer representations proves comparable to that achieved through traditional feature extraction, suggesting that LLMs capture meaningful structural information relevant to optimization performance.

</details>


### [38] [neuralFOMO: Can LLMs Handle Being Second Best? Measuring Envy-Like Preferences in Multi-Agent Settings](https://arxiv.org/abs/2512.13481)
*Ojas Pungalia,Rashi Upadhyay,Abhishek Mishra,Abhiram H,Tejasvi Alladi,Sujan Yenuganti,Dhruv Kumar*

Main category: cs.AI

TL;DR: 该研究测试了大语言模型是否表现出类似嫉妒的行为，发现某些LLM在特定情境下确实会表现出嫉妒模式，但不同模型和情境间存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型越来越多地在协作和竞争工作流程中代表人类行动，需要评估它们是否以及在什么条件下表现出类似嫉妒的偏好，这对多智能体系统的安全和设计至关重要。

Method: 研究设计了两种场景进行测试：(1) 点数分配游戏，测试模型是否试图超越同伴；(2) 工作场所设置，观察在认可不公平情况下的行为。

Result: 研究发现某些LLM表现出明显的嫉妒模式，但不同模型和情境间差异很大。GPT-5-mini和Claude-3.7-Sonnet倾向于拉低同伴以平衡结果，而Mistral-Small-3.2-24B则专注于最大化自身收益。

Conclusion: LLM确实会表现出嫉妒行为，这凸显了在多智能体系统设计中需要考虑竞争倾向作为安全和设计因素的重要性。

Abstract: Envy is a common human behavior that shapes competitiveness and can alter outcomes in team settings. As large language models (LLMs) increasingly act on behalf of humans in collaborative and competitive workflows, there is a pressing need to evaluate whether and under what conditions they exhibit envy-like preferences. In this paper, we test whether LLMs show envy-like behavior toward each other. We considered two scenarios: (1) A point allocation game that tests whether a model tries to win over its peer. (2) A workplace setting observing behaviour when recognition is unfair. Our findings reveal consistent evidence of envy-like patterns in certain LLMs, with large variation across models and contexts. For instance, GPT-5-mini and Claude-3.7-Sonnet show a clear tendency to pull down the peer model to equalize outcomes, whereas Mistral-Small-3.2-24B instead focuses on maximizing its own individual gains. These results highlight the need to consider competitive dispositions as a safety and design factor in LLM-based multi-agent systems.

</details>


### [39] [Defending the Hierarchical Result Models of Precedential Constraint](https://arxiv.org/abs/2512.13505)
*Henry Prakken,Wijnand van Woerkom*

Main category: cs.AI

TL;DR: 本文回应Bench-Capon对分层案例推理模型的批评，指出其误解了中间因素与维度的区别，并证明van Woerkom的维度分层模型能避免这些批评。


<details>
  <summary>Details</summary>
Motivation: 针对Trevor Bench-Capon对分层案例推理模型的批评，特别是关于中间因素在不同基础因素下可能具有不同强度的问题，需要为van Woerkom的结果分层模型进行辩护。

Method: 通过分析Bench-Capon的批评案例，指出其将中间因素误解为维度，并应用van Woerkom的基于维度的分层结果模型来重新解释这些案例。

Result: 证明van Woerkom的维度分层模型能够避免Bench-Capon提出的批评，正确处理中间因素在不同基础因素下的强度差异问题。

Conclusion: Bench-Capon的批评源于对中间因素和维度的混淆，van Woerkom的维度分层模型能够有效处理先例约束问题，避免了原有批评。

Abstract: In recent years, hierarchical case-based-reasoning models of precedential constraint have been proposed. In various papers, Trevor Bench-Capon criticised these models on the grounds that they would give incorrect outcomes in some cases. In particular, the models would not account for the possibility that intermediate factors are established with different strengths by different base-level factors. In this paper we respond to these criticisms for van Woerkom's result-based hierarchical models. We argue that in some examples Bench-Capon seems to interpret intermediate factors as dimensions, and that applying van Woerkom's dimension-based version of the hierarchical result model to these examples avoids Bench-Capon's criticisms.

</details>


### [40] [MedCEG: Reinforcing Verifiable Medical Reasoning with Critical Evidence Graph](https://arxiv.org/abs/2512.13510)
*Linjie Mu,Yannian Gu,Zhongzhen Huang,Yakun Zhu,Shaoting Zhang,Xiaofan Zhang*

Main category: cs.AI

TL;DR: MedCEG是一个通过关键证据图监督医学语言模型推理过程的框架，旨在生成临床有效的推理路径，提升医学AI推理的可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前医学推理模型虽然性能有所提升，但其推理过程的临床可靠性有限，因为训练过程中往往忽视了推理的准确性和有效性。在临床应用中，透明、逐步的推理过程能为医生提供强有力的决策支持证据。

Method: 提出MedCEG框架，通过关键证据图(CEG)显式监督推理过程。首先构建具有挑战性的临床病例数据集，并为每个样本算法构建CEG来表示高质量可验证的推理路径。引入临床推理过程奖励，评估节点覆盖率、结构正确性和链完整性，从而全面评估推理质量。

Result: 实验结果表明，MedCEG在性能上超越了现有方法，同时能生成临床有效的推理链，代表了可靠医学AI推理的重要进展。

Conclusion: MedCEG通过显式监督推理过程，成功提升了医学语言模型的临床推理可靠性，为医疗决策提供了更可信的支持。

Abstract: Large language models with reasoning capabilities have demonstrated impressive performance across a wide range of domains. In clinical applications, a transparent, step-by-step reasoning process provides physicians with strong evidence to support decision-making. While reinforcement learning has effectively enhanced reasoning performance in medical contexts, the clinical reliability of these reasoning processes remains limited because their accuracy and validity are often overlooked during training. To address this gap, we propose MedCEG, a framework that augments medical language models with clinically valid reasoning pathways by explicitly supervising the reasoning process through a Critical Evidence Graph (CEG). We curate a dataset of challenging clinical cases and algorithmically construct a CEG for each sample to represent a high-quality verifiable reasoning pathway. To guide the reasoning process, we introduce a Clinical Reasoning Procedure Reward, which evaluates Node Coverage, Structural Correctness, and Chain Completeness, thereby providing a holistic assessment of reasoning quality. Experimental results show that MedCEG surpasses existing methods in performance while producing clinically valid reasoning chains, representing a solid advancement in reliable medical AI reasoning. The code and models are available at https://github.com/LinjieMu/MedCEG.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [41] [Scalable IP Mimicry: End-to-End Deceptive IP Blending to Overcome Rectification and Scale Limitations of IP Camouflage](https://arxiv.org/abs/2512.12061)
*Junling Fan,George Rushevich,Giorgio Rusconi,Mengdi Zhu,Reiner Dizon-Paradis,Domenic Forte*

Main category: cs.CR

TL;DR: 本文针对半导体IP伪装技术存在的局限性，提出了两种端到端模型：图匹配算法解决表示问题，DNAS-based NAND阵列模型实现可扩展性，并通过模仿感知分区方法支持大规模设计。


<details>
  <summary>Details</summary>
Motivation: 半导体IP盗窃造成每年2250亿至6000亿美元的损失。尽管有CHIPS法案等举措，许多半导体设计仍易受逆向工程攻击。现有的IP伪装技术存在局限性：需要高开销的后生成修正步骤、不易扩展、使用与标准RE分析流程不匹配的AIG逻辑表示。

Method: 1. 提出图匹配算法解决表示问题；2. 提出基于DNAS的NAND阵列模型实现可扩展性；3. 引入模仿感知分区方法，支持对大规模设计采用分而治之策略。

Result: 实验结果表明，这些模型对SAT和GNN-RE攻击具有鲁棒性，为端到端的欺骗性IP设计提供了高效且可扩展的路径。

Conclusion: 本文提出的两种端到端模型解决了现有IP伪装技术的局限性，通过图匹配算法、DNAS-based NAND阵列模型和模仿感知分区方法，实现了对大规模设计的有效保护，能够抵御先进的逆向工程攻击。

Abstract: Semiconductor intellectual property (IP) theft incurs estimated annual losses ranging from $225 billion to $600 billion. Despite initiatives like the CHIPS Act, many semiconductor designs remain vulnerable to reverse engineering (RE). IP Camouflage is a recent breakthrough that expands beyond the logic gate hiding of traditional camouflage through "mimetic deception," where an entire module masquerades as a different IP. However, it faces key limitations: requires a high-overhead post-generation rectification step, is not easily scalable, and uses an AIG logic representation that is mismatched with standard RE analysis flows. This paper addresses these shortcommings by introducing two novel, end-to-end models. We propose a Graph-Matching algorithm to solve the representation problem and a DNAS-based NAND Array model to achieve scalability. To facilitate this, we also introduce a mimicry-aware partitioning method, enabling a divide-and-conquer approach for large-scale designs. Our results demonstrate that these models are resilient to SAT and GNN-RE attacks, providing efficient and scalable paths for end-to-end deceptive IP design.

</details>


### [42] [Rethinking Jailbreak Detection of Large Vision Language Models with Representational Contrastive Scoring](https://arxiv.org/abs/2512.12069)
*Peichun Hua,Hao Li,Shanghao Shi,Zhiyuan Yu,Ning Zhang*

Main category: cs.CR

TL;DR: 提出RCS框架，通过分析LVLM内部表示来检测多模态越狱攻击，实现高效且泛化性强的防御


<details>
  <summary>Details</summary>
Motivation: 现有防御方法要么针对特定攻击模式泛化性差，要么计算开销大，而轻量级异常检测方法容易将新颖良性输入误判为恶意

Method: 提出表示对比评分框架，检查LVLM内部表示的几何结构，学习轻量级投影以在安全关键层最大化分离良性和恶意输入

Result: MCD和KCD实现方法在测试未见攻击类型的评估协议中达到最先进性能

Conclusion: 通过对适当内部表示应用简单可解释的统计方法，可以实现有效的越狱检测，为更安全的LVLM部署提供实用路径

Abstract: Large Vision-Language Models (LVLMs) are vulnerable to a growing array of multimodal jailbreak attacks, necessitating defenses that are both generalizable to novel threats and efficient for practical deployment. Many current strategies fall short, either targeting specific attack patterns, which limits generalization, or imposing high computational overhead. While lightweight anomaly-detection methods offer a promising direction, we find that their common one-class design tends to confuse novel benign inputs with malicious ones, leading to unreliable over-rejection. To address this, we propose Representational Contrastive Scoring (RCS), a framework built on a key insight: the most potent safety signals reside within the LVLM's own internal representations. Our approach inspects the internal geometry of these representations, learning a lightweight projection to maximally separate benign and malicious inputs in safety-critical layers. This enables a simple yet powerful contrastive score that differentiates true malicious intent from mere novelty. Our instantiations, MCD (Mahalanobis Contrastive Detection) and KCD (K-nearest Contrastive Detection), achieve state-of-the-art performance on a challenging evaluation protocol designed to test generalization to unseen attack types. This work demonstrates that effective jailbreak detection can be achieved by applying simple, interpretable statistical methods to the appropriate internal representations, offering a practical path towards safer LVLM deployment. Our code is available on Github https://github.com/sarendis56/Jailbreak_Detection_RCS.

</details>


### [43] [The Procedural Semantics Gap in Structured CTI: A Measurement-Driven STIX Analysis for APT Emulation](https://arxiv.org/abs/2512.12078)
*Ágney Lopes Roth Ferraz,Sidnei Barbieri,Murray Evangelista de Souza,Lourenço Alves Pereira Júnior*

Main category: cs.CR

TL;DR: 研究发现当前CTI标准存在程序语义差距：ATT&CK框架描述攻击者行为但缺乏操作化细节，无法直接支持多阶段攻击模拟，需要分析师补充参数和假设才能实现自动化。


<details>
  <summary>Details</summary>
Motivation: 虽然基于STIX和MITRE ATT&CK框架的威胁情报已成为描述对手行为的全球参考标准，但ATT&CK被设计为描述性知识库而非程序模型。研究旨在探索其结构化工件是否包含足够的行为细节来支持多阶段对手模拟。

Method: 1. 对ATT&CK Enterprise bundle进行系统测量，分析战役对象编码的行为片段；2. 引入三阶段方法论，将结构化CTI中的行为信息转化为可执行步骤并明确环境假设；3. 在MITRE Caldera框架中实例化结果步骤，通过ShadowRay和Soft Cell案例研究验证可行性。

Result: 1. 战役对象仅编码行为片段：只有35.6%的技术出现在至少一个战役中，聚类和序列分析未发现可重用行为结构；2. 入侵集合覆盖更广泛的技术空间，但缺乏将行为知识转化为可执行链所需的程序语义；3. 结构化CTI可以支持多阶段APT战役模拟，但需要分析师明确提供参数和假设。

Conclusion: 当前CTI标准存在程序语义差距：描述对手行为但未说明如何操作化。研究明确了描述性CTI与机器可执行CTI之间的界限，指出需要明确记录分析师提供的参数和假设才能实现自动化模拟。

Abstract: Cyber threat intelligence (CTI) encoded in STIX and structured according to the MITRE ATT&CK framework has become a global reference for describing adversary behavior. However, ATT&CK was designed as a descriptive knowledge base rather than a procedural model. We therefore ask whether its structured artifacts contain sufficient behavioral detail to support multi-stage adversary emulation. Through systematic measurements of the ATT&CK Enterprise bundle, we show that campaign objects encode just fragmented slices of behavior. Only 35.6% of techniques appear in at least one campaign, and neither clustering nor sequence analysis reveals any reusable behavioral structure under technique overlap or LCS-based analyses. Intrusion sets cover a broader portion of the technique space, yet omit the procedural semantics required to transform behavioral knowledge into executable chains, including ordering, preconditions, and environmental assumptions. These findings reveal a procedural semantic gap in current CTI standards: they describe what adversaries do, but not exactly how that behavior was operationalized.
  To assess how far this gap can be bridged in practice, we introduce a three-stage methodology that translates behavioral information from structured CTI into executable steps and makes the necessary environmental assumptions explicit. We demonstrate its viability by instantiating the resulting steps as operations in the MITRE Caldera framework. Case studies of ShadowRay and Soft Cell show that structured CTI can enable the emulation of multi-stage APT campaigns, but only when analyst-supplied parameters and assumptions are explicitly recorded. This, in turn, exposes the precise points at which current standards fail to support automation. Our results clarify the boundary between descriptive and machine-actionable CTI for adversary emulation.

</details>


### [44] [Keep the Lights On, Keep the Lengths in Check: Plug-In Adversarial Detection for Time-Series LLMs in Energy Forecasting](https://arxiv.org/abs/2512.12154)
*Hua Ma,Ruoxi Sun,Minhui Xue,Xingliang Yuan,Carsten Rudolph,Surya Nepal,Ling Liu*

Main category: cs.CR

TL;DR: 该论文提出了一种针对时间序列大语言模型（TS-LLMs）的对抗样本检测框架，通过利用TS-LLMs处理变长输入的能力，使用采样诱导的发散性作为检测信号，有效识别针对能源系统预测的对抗攻击。


<details>
  <summary>Details</summary>
Motivation: 随着时间序列大语言模型在低碳电力系统中变得越来越重要，它们面临着对抗样本攻击的严重威胁。传统检测方法难以应对TS-LLMs的两个特点：对抗扰动利用全局时间依赖性，以及模型接受变长输入序列。需要一种有效的检测机制来保护这些关键预测模型。

Method: 提出了一种即插即用的检测框架，利用TS-LLMs处理变长输入的能力。方法核心是：给定输入序列，生成多个缩短的变体，通过测量这些变体预测的一致性来检测对抗样本。良性序列在采样下产生稳定预测，而对抗序列由于针对全长序列优化的扰动无法可靠地转移到不同结构的子样本上，表现出较低的预测相似性。

Result: 在三个代表性TS-LLMs（TimeGPT、TimesFM和TimeLLM）和三个能源数据集（ETTh2、NI和Consumption）上进行了评估。实证结果表明，该方法在黑盒和白盒攻击场景下都表现出强大且稳健的检测性能，证明了其作为TS-LLM预测可靠保护措施的实用性。

Conclusion: 该研究提出的检测框架有效地解决了TS-LLMs对抗样本检测的挑战，为实际能源系统中时间序列大语言模型的部署提供了可靠的安全保障，具有重要的实际应用价值。

Abstract: Accurate time-series forecasting is increasingly critical for planning and operations in low-carbon power systems. Emerging time-series large language models (TS-LLMs) now deliver this capability at scale, requiring no task-specific retraining, and are quickly becoming essential components within the Internet-of-Energy (IoE) ecosystem. However, their real-world deployment is complicated by a critical vulnerability: adversarial examples (AEs). Detecting these AEs is challenging because (i) adversarial perturbations are optimized across the entire input sequence and exploit global temporal dependencies, which renders local detection methods ineffective, and (ii) unlike traditional forecasting models with fixed input dimensions, TS-LLMs accept sequences of variable length, increasing variability that complicates detection. To address these challenges, we propose a plug-in detection framework that capitalizes on the TS-LLM's own variable-length input capability. Our method uses sampling-induced divergence as a detection signal. Given an input sequence, we generate multiple shortened variants and detect AEs by measuring the consistency of their forecasts: Benign sequences tend to produce stable predictions under sampling, whereas adversarial sequences show low forecast similarity, because perturbations optimized for a full-length sequence do not transfer reliably to shorter, differently-structured subsamples. We evaluate our approach on three representative TS-LLMs (TimeGPT, TimesFM, and TimeLLM) across three energy datasets: ETTh2 (Electricity Transformer Temperature), NI (Hourly Energy Consumption), and Consumption (Hourly Electricity Consumption and Production). Empirical results confirm strong and robust detection performance across both black-box and white-box attack scenarios, highlighting its practicality as a reliable safeguard for TS-LLM forecasting in real-world energy systems.

</details>


### [45] [Taint-Based Code Slicing for LLMs-based Malicious NPM Package Detection](https://arxiv.org/abs/2512.12313)
*Dang-Khoa Nguyen,Gia-Thang Ho,Quang-Minh Pham,Tuyet A. Dang-Thi,Minh-Khanh Vu,Thanh-Cong Nguyen,Phat T. Tran-Truong,Duc-Ly Vu*

Main category: cs.CR

TL;DR: 该论文提出了一种基于代码切片技术的LLM恶意npm包检测框架，通过专门的污点分析和启发式回溯机制处理异步事件驱动模式，将输入量减少99%以上，在5000多个恶意和良性npm包数据集上达到87.04%的检测准确率。


<details>
  <summary>Details</summary>
Motivation: npm生态系统中恶意软件攻击日益复杂（混淆和复杂逻辑），需要先进的检测方法。虽然大语言模型在语义代码理解方面具有强大能力，但其实际应用受到有限上下文窗口和高计算成本的限制。

Method: 提出一个新颖框架，利用代码切片技术进行LLM恶意包检测。开发专门的基于污点的npm包切片技术，通过启发式回溯机制准确捕获跨异步事件驱动模式（如回调和Promise）的恶意数据流，这些模式传统分析难以处理。

Result: 在5000多个恶意和良性npm包数据集上评估，该方法能够隔离安全相关代码，将输入量减少99%以上，同时保留关键行为语义。使用DeepSeek-Coder-6.7B模型作为分类引擎，检测准确率达到87.04%，显著优于朴素令牌分割基线（75.41%）和传统静态分析方法。

Conclusion: 通过代码切片实现的语义优化输入表示不仅缓解了LLM上下文窗口瓶颈，还显著提高了安全任务的推理精度，为对抗不断演变的恶意开源包提供了高效有效的防御方案。

Abstract: The increasing sophistication of malware attacks in the npm ecosystem, characterized by obfuscation and complex logic, necessitates advanced detection methods. Recently, researchers have turned their attention from traditional detection approaches to Large Language Models (LLMs) due to their strong capabilities in semantic code understanding. However, while LLMs offer superior semantic reasoning for code analysis, their practical application is constrained by limited context windows and high computational cost. This paper addresses this challenge by introducing a novel framework that leverages code slicing techniques for an LLM-based malicious package detection task. We propose a specialized taintbased slicing technique for npm packages, augmented by a heuristic backtracking mechanism to accurately capture malicious data flows across asynchronous, event-driven patterns (e.g., callbacks and Promises) that elude traditional analysis. An evaluation on a dataset of more than 5000 malicious and benign npm packages demonstrates that our approach isolates security-relevant code, reducing input volume by over 99% while preserving critical behavioral semantics. Using the DeepSeek-Coder-6.7B model as the classification engine, our approach achieves a detection accuracy of 87.04%, substantially outperforming a naive token-splitting baseline (75.41%) and a traditional static-analysis-based approach. These results indicate that semantically optimized input representation via code slicing not only mitigates the LLM context-window bottleneck but also significantly enhances reasoning precision for security tasks, providing an efficient and effective defense against evolving malicious open-source packages.

</details>


### [46] [UniMark: Artificial Intelligence Generated Content Identification Toolkit](https://arxiv.org/abs/2512.12324)
*Meilin Li,Ji He,Jia Xu,Shanzhe Lei,Yan Teng,Yingchun Wang,Xuhong Wang*

Main category: cs.CR

TL;DR: UniMark是一个开源的多模态内容治理统一框架，支持隐藏水印和可见标记，提供标准化评估基准。


<details>
  <summary>Details</summary>
Motivation: AI生成内容的快速扩散引发了信任危机和监管需求，现有识别工具存在碎片化问题且缺乏可见合规标记支持。

Method: 提出UniMark框架，采用模块化统一引擎抽象文本、图像、音频和视频模态的复杂性，提出新颖的双操作策略，原生支持隐藏水印和可见标记。

Result: 建立了包含Image/Video/Audio-Bench三个专门基准的标准化评估框架，确保严格的性能评估。

Conclusion: 该工具包弥合了先进算法与工程实现之间的差距，促进了更透明和安全的数字生态系统。

Abstract: The rapid proliferation of Artificial Intelligence Generated Content has precipitated a crisis of trust and urgent regulatory demands. However, existing identification tools suffer from fragmentation and a lack of support for visible compliance marking. To address these gaps, we introduce the \textbf{UniMark}, an open-source, unified framework for multimodal content governance. Our system features a modular unified engine that abstracts complexities across text, image, audio, and video modalities. Crucially, we propose a novel dual-operation strategy, natively supporting both \emph{Hidden Watermarking} for copyright protection and \emph{Visible Marking} for regulatory compliance. Furthermore, we establish a standardized evaluation framework with three specialized benchmarks (Image/Video/Audio-Bench) to ensure rigorous performance assessment. This toolkit bridges the gap between advanced algorithms and engineering implementation, fostering a more transparent and secure digital ecosystem.

</details>


### [47] [Mage: Cracking Elliptic Curve Cryptography with Cross-Axis Transformers](https://arxiv.org/abs/2512.12483)
*Lily Erickson*

Main category: cs.CR

TL;DR: 该论文探讨使用现代语言模型架构破解椭圆曲线密码学（ECC）公钥与私钥关联的可能性，通过逆向工程公钥对生成过程来"解曲线"，并测试机器学习模型记忆和逆向secp256r1密钥对的能力。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习和量子计算的发展，当前被认为是"防弹"的加密算法（如椭圆曲线密码学）面临潜在威胁。作者指出这些密码的强度测试研究很少，现有漏洞可能被利用，随着计算能力的提升，当前的安全堡垒可能失效，因此需要提前研究这些算法的脆弱性。

Method: 使用现代语言模型架构来破解公钥与私钥之间的关联，通过直观学习逆向工程公钥对生成过程来"解曲线"。同时测试机器学习模型记忆secp256r1公钥-私钥对的能力，并评估它们逆向工程公钥对生成过程的能力。

Result: 论文未提供具体实验结果，但表明无论是证明"能够破解"还是证明"不能破解"在这两个类别中都具有同等价值。作者计划最后通过数字分析来预测该领域的未来发展方向。

Conclusion: 论文旨在探索机器学习在密码分析中的潜在应用，强调在当前加密算法面临新兴技术威胁的背景下，无论是证明其脆弱性还是安全性都具有重要价值，并呼吁关注该领域的发展趋势。

Abstract: With the advent of machine learning and quantum computing, the 21st century has gone from a place of relative algorithmic security, to one of speculative unease and possibly, cyber catastrophe.
  Modern algorithms like Elliptic Curve Cryptography (ECC) are the bastion of current cryptographic security protocols that form the backbone of consumer protection ranging from Hypertext Transfer Protocol Secure (HTTPS) in the modern internet browser, to cryptographic financial instruments like Bitcoin.
  And there's been very little work put into testing the strength of these ciphers. Practically the only study that I could find was on side-channel recognition, a joint paper from the University of Milan, Italy and King's College, London\cite{battistello2025ecc}.
  These algorithms are already considered bulletproof by many consumers, but exploits already exist for them, and with computing power and distributed, federated compute on the rise, it's only a matter of time before these current bastions fade away into obscurity, and it's on all of us to stand up when we notice something is amiss, lest we see such passages claim victims in that process.
  In this paper, we seek to explore the use of modern language model architecture in cracking the association between a known public key, and its associated private key, by intuitively learning to reverse engineer the public keypair generation process, effectively solving the curve.
  Additonally, we attempt to ascertain modern machine learning's ability to memorize public-private secp256r1 keypairs, and to then test their ability to reverse engineer the public keypair generation process.
  It is my belief that proof-for would be equally valuable as proof-against in either of these categories.
  Finally, we'll conclude with some number crunching on where we see this particular field heading in the future.

</details>


### [48] [Unveiling Malicious Logic: Towards a Statement-Level Taxonomy and Dataset for Securing Python Packages](https://arxiv.org/abs/2512.12559)
*Ahmed Ryan,Junaid Mansur Ifti,Md Erfan,Akond Ashfaque Ur Rahman,Md Rayhanur Rahman*

Main category: cs.CR

TL;DR: 构建了首个语句级别的恶意Python包数据集，包含370个恶意包、833个文件、90,527行代码，标注了2,962个恶意指标出现位置，并建立了包含47个恶意指标的细粒度分类体系


<details>
  <summary>Details</summary>
Motivation: 现有数据集只在包级别标注恶意或良性，无法指定哪些语句实现了恶意行为，这种粗粒度限制了恶意代码定位、检测器可解释性以及系统研究恶意指标和攻击链的能力

Method: 构建语句级别的恶意Python包数据集，从标注中推导出包含47个恶意指标的细粒度分类体系（7种类型），并应用序列模式挖掘来发现表征常见攻击工作流的重复指标序列

Result: 创建了包含370个恶意Python包、833个文件、90,527行代码的数据集，标注了2,962个恶意指标出现位置，建立了包含47个恶意指标的7类型分类体系，发现了重复的指标序列模式

Conclusion: 该数据集支持可解释的、以行为为中心的检测，既支持语义感知的模型训练，也为加强软件供应链防御提供了实用的启发式方法

Abstract: The widespread adoption of open-source ecosystems enables developers to integrate third-party packages, but also exposes them to malicious packages crafted to execute harmful behavior via public repositories such as PyPI. Existing datasets (e.g., pypi-malregistry, DataDog, OpenSSF, MalwareBench) label packages as malicious or benign at the package level, but do not specify which statements implement malicious behavior. This coarse granularity limits research and practice: models cannot be trained to localize malicious code, detectors cannot justify alerts with code-level evidence, and analysts cannot systematically study recurring malicious indicators or attack chains. To address this gap, we construct a statement-level dataset of 370 malicious Python packages (833 files, 90,527 lines) with 2,962 labeled occurrences of malicious indicators. From these annotations, we derive a fine-grained taxonomy of 47 malicious indicators across 7 types that capture how adversarial behavior is implemented in code, and we apply sequential pattern mining to uncover recurring indicator sequences that characterize common attack workflows. Our contribution enables explainable, behavior-centric detection and supports both semantic-aware model training and practical heuristics for strengthening software supply-chain defenses.

</details>


### [49] [Cryptographic transformations over polyadic rings](https://arxiv.org/abs/2512.12580)
*Steven Duplij,Na Fu,Qiang Guo*

Main category: cs.CR

TL;DR: 提出基于非派生多元代数结构的新型密码学范式，利用多元环代替传统二元运算，通过参数到元数映射构建安全加密系统。


<details>
  <summary>Details</summary>
Motivation: 传统密码系统依赖于群、环或域中的二元运算，这些运算的已知性质可能被密码分析利用。为了克服这些漏洞，需要转向更复杂的代数结构。

Method: 构建多元整数——赋予m元加法和n元乘法运算的普通整数同余类。核心创新是参数到元数映射Φ(a,b)=(m,n)，该映射将定义同余类的参数(a,b)与实现代数闭包所需的特定元数联系起来。提出了两种具体加密方法：一种将明文与加法元数m_i关联并使用此类信号求和保护；另一种将明文与环参数a_i关联并使用乘法保护。

Result: 多元运算的"量化"特性生成方程组，对于拥有正确密钥的合法接收者来说易于求解，但对于没有密钥的攻击者来说极其困难。该框架有望显著提高密码安全性。

Conclusion: 这项工作为这类新型加密方案奠定了理论基础，并突显了它们在构建稳健的下一代密码协议方面的潜力。

Abstract: This article introduces a novel cryptographic paradigm based on nonderived polyadic algebraic structures. Traditional cryptosystems rely on binary operations within groups, rings, or fields, whose well-understood properties can be exploited in cryptanalysis. To overcome these vulnerabilities, we propose a shift to polyadic rings, which generalize classical rings by allowing operations of higher arity: an $m$-ary addition and an $n$-ary multiplication. The foundation of our approach is the construction of polyadic integers -- congruence classes of ordinary integers endowed with such $m$-ary and $n$-ary operations. A key innovation is the parameter-to-arity mapping $Φ(a,b)=(m,n)$, which links the parameters $(a,b)$ defining a congruence class to the specific arities required for algebraic closure. This mapping is mathematically intricate: it is non-injective, non-surjective, and multivalued. This complex, non-unique relationship forms the core of the proposed cryptosystem's security. We present two concrete encryption procedures that leverage this structure by encoding plaintext within the parameters of polyadic rings and transmitting information via polyadically quantized analog signals. In one method, plaintext is linked to the additive arity $m_{i}$ and secured using the summation of such signals; in the other, it is linked to a ring parameter $a_{i}$ and secured using their multiplication. In both cases, the "quantized" nature of polyadic operations generates systems of equations that are straightforward for a legitimate recipient with the correct key but exceptionally difficult for an attacker without it. The resulting framework promises a substantial increase in cryptographic security. This work establishes the theoretical foundation for this new class of encryption schemes and highlights their potential for constructing robust, next-generation cryptographic protocols.

</details>


### [50] [OptHQC: Optimize HQC for High-Performance Post-Quantum Cryptography](https://arxiv.org/abs/2512.12904)
*Ben Dong,Hui Feng,Qian Wang*

Main category: cs.CR

TL;DR: OptHQC是对HQC（一种后量子密码方案）的优化实现，通过多层次的优化策略，在CPU上实现了比参考实现平均55%的性能加速。


<details>
  <summary>Details</summary>
Motivation: 随着后量子密码学变得越来越重要，量子抵抗算法带来的性能开销成为主要计算挑战。HQC作为新标准化的基于编码的PQC方案，需要优化其性能以替代传统的密钥交换方法。

Method: 对HQC的各个计算模块进行全面分析，在三个阶段（密钥生成、加密、解密）引入优化：1）利用向量乘法中的数据级稀疏性加速多项式运算；2）使用指令级加速（如AVX2）优化哈希计算；3）将乘法转换为查找表索引，并优化综合征计算和错误向量恢复中的内存访问模式。

Result: OptHQC在CPU上实现了比参考HQC实现平均55%的性能加速。

Conclusion: OptHQC通过多层次优化策略显著提升了HQC方案的性能，为后量子密码学的实际部署提供了高效的实现方案。

Abstract: As post-quantum cryptography (PQC) becomes increasingly critical for securing future communication systems, the performance overhead introduced by quantum-resistant algorithms presents a major computing challenge. HQC (Hamming Quasi-Cyclic) is a newly standardized code-based PQC scheme designed to replace classical key exchange methods. In this paper, we propose OptHQC, an optimized implementation of the HQC scheme to deliver high-performance cryptographic operations. Our approach provides a comprehensive analysis of each computational blocks in HQC and introduces optimizations across all three stages: key generation, encryption, and decryption. We first exploit data-level sparsity in vector multiplication to accelerate polynomial operations during vector generation. We then leverage instruction-level acceleration (e.g., AVX2) in hash computation to further improve performance. Last, we transform multiplication into lookup table indexing and optimize memory access patterns in syndrome computation and error vector recovery, which are the most computationally intensive operations in HQC. Overall, OptHQC achieves an average 55% speedup over the reference HQC implementation on CPU.

</details>


### [51] [Efficient Quantum-resistant Delegable Data Analysis Scheme with Revocation and Keyword Search in Mobile Cloud Computing](https://arxiv.org/abs/2512.12917)
*Yue Han,Jinguang Han,Jianying Zhou*

Main category: cs.CR

TL;DR: 提出EQDDA-RKS方案，解决移动云计算中的数据隐私、选择性计算、高效撤销和关键词搜索等挑战，同时抵抗量子攻击


<details>
  <summary>Details</summary>
Motivation: 移动设备资源受限但数据处理需求增长，移动云计算面临数据隐私、选择性计算、高效撤销、关键词搜索等挑战，且量子计算机发展威胁数据安全

Method: 设计量子抗性可委托数据分析方案，支持撤销和关键词搜索；授权移动设备可在加密数据上执行关键词搜索和内积计算；支持密钥撤销；将大部分计算外包给云服务器；支持临时委托权限

Result: 方案在标准模型下被证明可抵抗量子攻击、选择明文攻击、选择关键词攻击和外部关键词猜测攻击；移动设备与中央机构的交互次数为O(1)，不随函数数量线性增长

Conclusion: EQDDA-RKS方案有效解决了移动云计算中的关键挑战，提供了量子抗性、高效撤销和关键词搜索功能，适合移动云计算场景

Abstract: With the rapid growth of smart devices and mobile internet, large-scale data processing is becoming increasingly important, while mobile devices remain resource-constrained. Mobile Cloud Computing (MCC) addresses this limitation by offloading tasks to the cloud. Nevertheless, the widespread adoption of MCC also raises challenges such as data privacy, selective computation, efficient revocation, and keyword search. Additionally, the development of quantum computers also threatens data security in MCC. To address these challenges, we propose an efficient quantum-resistant delegable data analysis scheme with revocation and keyword search (EQDDA-RKS) for MCC. In the proposed scheme, an authorised mobile device can perform keyword searches and compute inner product values over encrypted data without disclosing any additional information. Meanwhile, if a user's function key is compromised, it can be revoked. To alleviate the burden on mobile devices, most of the computation which should be executed by the mobile device is outsourced to a cloud server, and the mobile device only needs to interact with a central authority once. Furthermore, an authorised mobile device can temporarily delegate its keyword search and function computation rights to a delegatee in case the device becomes unavailable due to power depletion, going offline, etc. Our scheme is formally proven secure in the standard model against quantum attacks, chosen plaintext attacks, chosen keyword attacks, and outside keyword guessing attacks. Furthermore, the analysis demonstrates that the number of interactions between a mobile device and the central authority is $O(1)$ in our scheme, rather than growing linearly with the number of functions, which is well-suited for MCC scenarios.

</details>


### [52] [Less Is More: Sparse and Cooperative Perturbation for Point Cloud Attacks](https://arxiv.org/abs/2512.13119)
*Keke Tang,Tianyu Hao,Xiaofei Wang,Weilong Peng,Denghui Zhang,Peican Zhu,Zhihong Tian*

Main category: cs.CR

TL;DR: SCP提出了一种稀疏协同扰动框架，通过选择并联合优化少量关键点来生成高效对抗样本，在保持高攻击成功率的同时大幅减少修改点数量。


<details>
  <summary>Details</summary>
Motivation: 现有对抗攻击方法要么需要修改大量点云点（导致明显几何变化），要么稀疏攻击效果有限。需要一种既能保持高攻击成功率，又只需少量修改的实用方法。

Method: SCP框架通过分析Hessian矩阵的正定性，识别出局部凸区域中的关键点子集，然后对这些选中的点进行联合优化，产生放大的对抗效果。

Result: 实验显示SCP达到100%攻击成功率，超越现有稀疏攻击方法，同时比密集攻击具有更好的不可感知性，且修改点数远少于密集攻击。

Conclusion: SCP通过协同优化少量关键点，实现了高效且隐蔽的对抗攻击，为点云安全领域提供了新的攻击范式。

Abstract: Most adversarial attacks on point clouds perturb a large number of points, causing widespread geometric changes and limiting applicability in real-world scenarios. While recent works explore sparse attacks by modifying only a few points, such approaches often struggle to maintain effectiveness due to the limited influence of individual perturbations. In this paper, we propose SCP, a sparse and cooperative perturbation framework that selects and leverages a compact subset of points whose joint perturbations produce amplified adversarial effects. Specifically, SCP identifies the subset where the misclassification loss is locally convex with respect to their joint perturbations, determined by checking the positivedefiniteness of the corresponding Hessian block. The selected subset is then optimized to generate high-impact adversarial examples with minimal modifications. Extensive experiments show that SCP achieves 100% attack success rates, surpassing state-of-the-art sparse attacks, and delivers superior imperceptibility to dense attacks with far fewer modifications.

</details>


### [53] [Towards Secure Decentralized Applications and Consensus Protocols in Blockchains (on Selfish Mining, Undercutting Attacks, DAG-Based Blockchains, E-Voting, Cryptocurrency Wallets, Secure-Logging, and CBDC)](https://arxiv.org/abs/2512.13213)
*Ivan Homoliak*

Main category: cs.CR

TL;DR: 该论文提出区块链安全参考架构，研究PoW共识安全、钱包认证、电子投票协议和基于区块链的安全日志系统，最终构建央行数字货币互操作性协议。


<details>
  <summary>Details</summary>
Motivation: 随着加密货币和去中心化应用的兴起，区块链系统面临可扩展性、性能和安全性挑战。由于区块链系统的复杂性，需要比传统分布式系统更全面的安全评估方法。

Method: 1. 提出安全参考架构以支持标准化漏洞和威胁分析；2. 研究单链PoW区块链的共识安全性（自私挖矿、削减攻击、贪婪交易选择）及DAG系统相关问题；3. 提出钱包认证方案分类和基于一次性密码的双因素认证方法；4. 开发实用的董事会投票协议，扩展到百万参与者版本，引入允许选举间改票的重复投票框架；5. 利用区块链和可信计算改进安全日志，构建保证不可抵赖性、完整性和审查证据的集中式账本，并在此基础上提出确保原子转移的央行数字货币互操作性协议。

Result: 论文在多个区块链安全领域做出贡献：建立了标准化的安全分析框架，深入分析了共识机制的安全问题，改进了钱包认证方法，开发了可扩展的电子投票协议，构建了基于区块链的安全日志系统，并提出了央行数字货币的互操作性解决方案。

Conclusion: 该研究为区块链和去中心化应用安全提供了全面的解决方案，从架构设计到具体实现，涵盖了共识安全、钱包安全、电子投票和安全日志等多个关键领域，最终构建了支持央行数字货币互操作性的实用协议。

Abstract: With the rise of cryptocurrencies, many new applications built on decentralized blockchains have emerged. Blockchains are full-stack distributed systems where multiple sub-systems interact. While many deployed blockchains and decentralized applications need better scalability and performance, security is also critical. Due to their complexity, assessing blockchain and DAPP security requires a more holistic view than for traditional distributed or centralized systems.
  In this thesis, we summarize our contributions to blockchain and decentralized application security. We propose a security reference architecture to support standardized vulnerability and threat analysis. We study consensus security in single-chain Proof-of-Work blockchains, including resistance to selfish mining, undercutting, and greedy transaction selection, as well as related issues in DAG-based systems. We contribute to wallet security with a new classification of authentication schemes and a two-factor method based on One-Time Passwords. We advance e-voting with a practical boardroom voting protocol, extend it to a scalable version for millions of participants while preserving security and privacy, and introduce a repetitive voting framework that enables vote changes between elections while avoiding peak-end effects. Finally, we improve secure logging using blockchains and trusted computing through a centralized ledger that guarantees non-equivocation, integrity, and censorship evidence, then build on it to propose an interoperability protocol for central bank digital currencies that ensures atomic transfers.

</details>


### [54] [Security and Detectability Analysis of Unicode Text Watermarking Methods Against Large Language Models](https://arxiv.org/abs/2512.13325)
*Malte Hellmeier*

Main category: cs.CR

TL;DR: 本文研究了现有Unicode文本水印方法的安全性，通过实验发现最新的推理模型能够检测到水印文本，但所有模型都无法提取水印内容，除非提供源代码实现细节。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的广泛应用，保护数字文本安全变得日益重要。人们担心数据在用于训练机器学习模型时失去控制，以及难以区分模型生成文本与人类写作文本。数字水印通过在受保护数据中嵌入不可见水印提供额外保护，但现有文本水印方法是否安全且对大语言模型不可检测尚未得到充分分析和验证。

Method: 在受控实验环境中，实现了十种现有的Unicode文本水印方法，并在六个大语言模型（GPT-5、GPT-4o、Teuken 7B、Llama 3.3、Claude Sonnet 4和Gemini 2.5 Pro）上进行分析。通过三个实验来评估水印的安全性和可检测性。

Result: 实验结果表明，特别是最新的推理模型能够检测到水印文本。然而，所有模型都无法提取水印内容，除非提供源代码实现细节。这表明现有水印方法在检测层面存在漏洞，但在内容提取层面相对安全。

Conclusion: 数字文本水印的安全性需要进一步研究，特别是针对最新推理模型的检测能力。虽然水印内容提取相对困难，但检测水印存在已成为可能。研究为安全研究人员和实践者提供了重要启示，并指出了未来研究方向以解决安全问题。

Abstract: Securing digital text is becoming increasingly relevant due to the widespread use of large language models. Individuals' fear of losing control over data when it is being used to train such machine learning models or when distinguishing model-generated output from text written by humans. Digital watermarking provides additional protection by embedding an invisible watermark within the data that requires protection. However, little work has been taken to analyze and verify if existing digital text watermarking methods are secure and undetectable by large language models. In this paper, we investigate the security-related area of watermarking and machine learning models for text data. In a controlled testbed of three experiments, ten existing Unicode text watermarking methods were implemented and analyzed across six large language models: GPT-5, GPT-4o, Teuken 7B, Llama 3.3, Claude Sonnet 4, and Gemini 2.5 Pro. The findings of our experiments indicate that, especially the latest reasoning models, can detect a watermarked text. Nevertheless, all models fail to extract the watermark unless implementation details in the form of source code are provided. We discuss the implications for security researchers and practitioners and outline future research opportunities to address security concerns.

</details>


### [55] [Quantum Disruption: An SOK of How Post-Quantum Attackers Reshape Blockchain Security and Performance](https://arxiv.org/abs/2512.13333)
*Tushin Mallick,Maya Zeldin,Murat Cenk,Cristina Nita-Rotaru*

Main category: cs.CR

TL;DR: 论文分析了在后量子时代区块链系统采用后量子密码学面临的挑战，指出这不仅仅是简单的密码原语替换，而是需要重新设计系统架构。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算的发展，传统密码学机制面临威胁，而区块链系统严重依赖这些密码原语。虽然迁移到后量子密码学看似直接，但更大的密钥尺寸和更高的计算成本给区块链环境带来了实际挑战。

Method: 从四个关键维度分析后量子密码学在区块链系统中的应用：1) 识别区块链架构中最易受量子攻击的密码原语；2) 调查现有区块链设计中提出的后量子适应方案；3) 分析在去中心化和资源受限环境中的可行性；4) 评估替换密码原语对系统性能、协议动态以及激励和信任结构的影响。

Result: 研究表明，将后量子签名方案集成到区块链系统中不是简单的"即插即用"替换，而是需要仔细的架构重新设计。简单的替换可能会破坏安全保证和操作效率。

Conclusion: 区块链系统向后量子密码学的过渡面临重大挑战，需要综合考虑性能、协议动态和信任结构等多方面因素，进行系统性的架构重新设计，而不是简单的密码原语替换。

Abstract: As quantum computing advances toward practical deployment, it threatens a wide range of classical cryptographic mechanisms, including digital signatures, key exchange protocols, public-key encryption, and certain hash-based constructions that underpin modern network infrastructures. These primitives form the security backbone of most blockchain platforms, raising serious concerns about the long-term viability of blockchain systems in a post-quantum world. Although migrating to post-quantum cryptography may appear straightforward, the substantially larger key sizes and higher computational costs of post-quantum primitives can introduce significant challenges and, in some cases, render such transitions impractical for blockchain environments.
  In this paper, we examine the implications of adopting post-quantum cryptography in blockchain systems across four key dimensions. We begin by identifying the cryptographic primitives within blockchain architectures that are most vulnerable to quantum attacks, particularly those used in consensus mechanisms, identity management, and transaction validation. We then survey proposed post-quantum adaptations across existing blockchain designs, analyzing their feasibility within decentralized and resource-constrained settings. Building on this analysis, we evaluate how replacing classical primitives with post-quantum alternatives affects system performance, protocol dynamics, and the incentive and trust structures that sustain blockchain ecosystems. Our study demonstrates that integrating post-quantum signature schemes into blockchain systems is not a simple drop-in replacement; instead, it requires careful architectural redesign, as naive substitutions risk undermining both security guarantees and operational efficiency.

</details>


### [56] [Weak Enforcement and Low Compliance in PCI~DSS: A Comparative Security Study](https://arxiv.org/abs/2512.13430)
*Soonwon Park,John D. Hastings*

Main category: cs.CR

TL;DR: PCI DSS合规率低（仅32.4%），与其他安全框架相比执行机制薄弱，建议加强非货币制裁并建立独立监管机构


<details>
  <summary>Details</summary>
Motivation: 尽管PCI DSS能减少信用卡欺诈，但组织合规率仍然很低（2022年仅32.4%），表明执行机制可能存在缺陷，需要与其他数据安全框架进行比较分析

Method: 将PCI DSS与HIPAA、NIS2、GDPR三个数据安全框架进行比较，分析执行机制与实施成功率之间的关系

Result: PCI DSS显著落后于其他安全框架，其制裁力度远小于GDPR和NIS2；更强的多模式执行机制（包括公开披露、许可证行动和监禁）与更高的实施率呈正相关；PCI DSS依赖银行的监控模式存在结构性弱点

Conclusion: 建议增强非货币制裁并建立独立监管机构，以提高透明度、减少利益冲突、改善PCI DSS合规性，同时不阻碍信用卡受理

Abstract: Although credit and debit card data continue to be a prime target for attackers, organizational adherence to the Payment Card Industry Data Security Standard (PCI DSS) remains surprisingly low. Despite prior work showing that PCI DSS can reduce card fraud, only 32.4% of organizations were fully compliant in 2022, suggesting possible deficiencies in enforcement mechanisms. This study compares PCI DSS with three data security frameworks, HIPAA, NIS2, and GDPR, to examine how enforcement mechanisms relate to implementation success. The analysis reveals that PCI DSS significantly lags far behind these security frameworks and that its sanctions are orders of magnitude smaller than those under GDPR and NIS2. The findings indicate a positive association between stronger, multi-modal enforcement (including public disclosure, license actions, and imprisonment) and higher implementation rates, and highlights the structural weakness of PCI DSS's bank-dependent monitoring model. Enhanced non-monetary sanctions and the creation of an independent supervisory authority are recommended to increase transparency, reduce conflicts of interest, and improve PCI DSS compliance without discouraging card acceptance.

</details>


### [57] [Behavior-Aware and Generalizable Defense Against Black-Box Adversarial Attacks for ML-Based IDS](https://arxiv.org/abs/2512.13501)
*Sabrine Ennaji,Elhadj Benkhelifa,Luigi Vincenzo Mancini*

Main category: cs.CR

TL;DR: 提出Adaptive Feature Poisoning防御机制，通过动态扰动流量特征来破坏黑盒对抗攻击的反馈循环，同时保持入侵检测性能


<details>
  <summary>Details</summary>
Motivation: 现有的对抗攻击防御机制存在局限性：针对特定攻击类型、需要模型内部访问、依赖静态机制无法适应演化攻击策略，且可能降低入侵检测系统性能

Method: Adaptive Feature Poisoning：轻量级主动防御机制，基于流量分析、变化点检测和自适应缩放，动态选择并扰动攻击者可能利用的特征，破坏攻击反馈循环

Result: 评估显示该方法能有效混淆攻击者、降低攻击效果，同时保持检测性能，对抗多种现实对抗攻击策略（静默探测、可迁移性攻击、决策边界攻击）

Conclusion: Adaptive Feature Poisoning提供了一种通用、攻击无关且难以检测的防御方案，代表了机器学习入侵检测系统对抗攻击防御的重要进展

Abstract: Machine learning based intrusion detection systems are increasingly targeted by black box adversarial attacks, where attackers craft evasive inputs using indirect feedback such as binary outputs or behavioral signals like response time and resource usage. While several defenses have been proposed, including input transformation, adversarial training, and surrogate detection, they often fall short in practice. Most are tailored to specific attack types, require internal model access, or rely on static mechanisms that fail to generalize across evolving attack strategies. Furthermore, defenses such as input transformation can degrade intrusion detection system performance, making them unsuitable for real time deployment.
  To address these limitations, we propose Adaptive Feature Poisoning, a lightweight and proactive defense mechanism designed specifically for realistic black box scenarios. Adaptive Feature Poisoning assumes that probing can occur silently and continuously, and introduces dynamic and context aware perturbations to selected traffic features, corrupting the attacker feedback loop without impacting detection capabilities. The method leverages traffic profiling, change point detection, and adaptive scaling to selectively perturb features that an attacker is likely exploiting, based on observed deviations.
  We evaluate Adaptive Feature Poisoning against multiple realistic adversarial attack strategies, including silent probing, transferability based attacks, and decision boundary based attacks. The results demonstrate its ability to confuse attackers, degrade attack effectiveness, and preserve detection performance. By offering a generalizable, attack agnostic, and undetectable defense, Adaptive Feature Poisoning represents a significant step toward practical and robust adversarial resilience in machine learning based intrusion detection systems.

</details>


### [58] [SEDULity: A Proof-of-Learning Framework for Distributed and Secure Blockchains with Efficient Useful Work](https://arxiv.org/abs/2512.13666)
*Weihang Cao,Mustafa Doger,Sennur Ulukus*

Main category: cs.CR

TL;DR: 本文提出SEDULity框架，将工作量证明(PoW)的无意义计算重定向到机器学习训练任务，实现安全、高效、分布式的有用工作量证明(PoUW)区块链系统。


<details>
  <summary>Details</summary>
Motivation: 传统PoW区块链存在巨大能源浪费问题，而现有的有用工作量证明(PoUW)方案，特别是基于机器学习的证明(PoL)，在安全性、去中心化或效率方面存在不足。

Method: 提出SEDULity框架：1) 将模板块编码到训练过程中；2) 设计难以解决但相对容易验证的有用函数替代PoW谜题；3) 设计激励机制鼓励任务验证；4) 框架可扩展到其他类型的有用工作。

Result: 理论分析表明，理性矿工在良好设计的系统参数下会被激励诚实训练。仿真结果验证了框架的性能和分析。

Conclusion: SEDULity框架能够在完全分布式的方式下高效训练机器学习模型，同时保持区块链安全性，为解决PoW能源浪费问题提供了可行方案。

Abstract: The security and decentralization of Proof-of-Work (PoW) have been well-tested in existing blockchain systems. However, its tremendous energy waste has raised concerns about sustainability. Proof-of-Useful-Work (PoUW) aims to redirect the meaningless computation to meaningful tasks such as solving machine learning (ML) problems, giving rise to the branch of Proof-of-Learning (PoL). While previous studies have proposed various PoLs, they all, to some degree, suffer from security, decentralization, or efficiency issues. In this paper, we propose a PoL framework that trains ML models efficiently while maintaining blockchain security in a fully distributed manner. We name the framework SEDULity, which stands for a Secure, Efficient, Distributed, and Useful Learning-based blockchain system. Specifically, we encode the template block into the training process and design a useful function that is difficult to solve but relatively easy to verify, as a substitute for the PoW puzzle. We show that our framework is distributed, secure, and efficiently trains ML models. We further demonstrate that the proposed PoL framework can be extended to other types of useful work and design an incentive mechanism to incentivize task verification. We show theoretically that a rational miner is incentivized to train fully honestly with well-designed system parameters. Finally, we present simulation results to demonstrate the performance of our framework and validate our analysis.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [59] [Vibe Coding in Practice: Flow, Technical Debt, and Guidelines for Sustainable Use](https://arxiv.org/abs/2512.11922)
*Muhammad Waseem,Aakash Ahmad,Kai-Kristian Kemell,Jussi Rasku,Sami Lahti,Kalle Mäkelä,Pekka Abrahamsson*

Main category: cs.SE

TL;DR: Vibe Coding（VC）是一种由生成式AI辅助的软件开发形式，开发者通过自然语言提示描述预期功能，AI系统生成相应源代码。虽然VC可用于快速原型开发或MVP创建，但会在软件开发生命周期中引入多种风险，特别是流-债权衡问题。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于VC在快速原型开发中的广泛应用，但同时也带来了技术债务积累的风险。作者基于内部开发的多个MVP经验和行业报告分析，旨在揭示VC带来的流-债权衡问题及其根源。

Method: 基于多个内部开发的MVP实践经验，结合对近期行业报告的回顾，分析VC带来的流-债权衡问题。识别了当前模型、平台和硬件限制如何导致这些问题。

Result: 研究发现VC导致流-债权衡：无缝代码生成的同时会积累技术债务，包括架构不一致、安全漏洞和维护开销增加。这些问题源于流程层面的弱点、模型训练数据偏差、缺乏明确设计原理，以及倾向于优先快速代码生成而非人工驱动的迭代开发。

Conclusion: VC虽然能加速开发流程，但会积累技术债务。作者提出了应对这些问题的对策，为研究和实践提供参考，以实现更可持续的VC方法。

Abstract: Vibe Coding (VC) is a form of software development assisted by generative AI, in which developers describe the intended functionality or logic via natural language prompts, and the AI system generates the corresponding source code. VC can be leveraged for rapid prototyping or developing the Minimum Viable Products (MVPs); however, it may introduce several risks throughout the software development life cycle. Based on our experience from several internally developed MVPs and a review of recent industry reports, this article analyzes the flow-debt tradeoffs associated with VC. The flow-debt trade-off arises when the seamless code generation occurs, leading to the accumulation of technical debt through architectural inconsistencies, security vulnerabilities, and increased maintenance overhead. These issues originate from process-level weaknesses, biases in model training data, a lack of explicit design rationale, and a tendency to prioritize quick code generation over human-driven iterative development. Based on our experiences, we identify and explain how current model, platform, and hardware limitations contribute to these issues, and propose countermeasures to address them, informing research and practice towards more sustainable VC approaches.

</details>


### [60] [Evidence-Driven Decision Support for AI Model Selection in Research Software Engineering](https://arxiv.org/abs/2512.11984)
*Alireza Joonbakhsh,Alireza Rostami,AmirMohammad Kamalinia,Ali Nazeri,Farshad Khunjush,Bedir Tekinerdogan,Siamak Farshidi*

Main category: cs.SE

TL;DR: 本文提出ModelSelect框架，将AI模型选择视为多准则决策问题，通过证据驱动的决策支持系统提供可靠、可解释的模型推荐。


<details>
  <summary>Details</summary>
Motivation: AI模型和方法的快速扩散给研究软件工程师和研究人员带来了挑战，他们需要在复杂研究流程中选择、集成和维护合适的模型。当前模型选择通常采用临时方式，依赖零散的元数据和个人专业知识，这会损害可重复性、透明度和研究软件质量。

Method: 将AI模型选择概念化为多准则决策问题，提出基于证据的决策支持框架ModelSelect，集成自动化数据收集管道、结构化知识图谱和多准则决策原则。采用设计科学研究方法，通过50个真实案例研究和与领先生成AI系统的对比实验进行实证验证。

Result: 评估结果显示ModelSelect产生可靠、可解释且可重复的推荐，与专家推理高度一致。在案例研究中，该框架在模型和库推荐任务中实现了高覆盖率和强理由对齐，性能与生成AI助手相当，同时提供更好的可追溯性和一致性。

Conclusion: 通过将AI模型选择框架化为多准则决策问题，本研究为研究软件工程中的透明和可重复决策支持建立了严格基础。提出的框架为将经验证据集成到AI模型推荐过程中提供了可扩展且可解释的途径，最终提高了研究软件决策的质量和鲁棒性。

Abstract: The rapid proliferation of artificial intelligence (AI) models and methods presents growing challenges for research software engineers and researchers who must select, integrate, and maintain appropriate models within complex research workflows. Model selection is often performed in an ad hoc manner, relying on fragmented metadata and individual expertise, which can undermine reproducibility, transparency, and overall research software quality.
  This work proposes a structured and evidence-driven approach to support AI model selection that aligns with both technical and contextual requirements. We conceptualize AI model selection as a Multi-Criteria Decision-Making (MCDM) problem and introduce an evidence-based decision-support framework that integrates automated data collection pipelines, a structured knowledge graph, and MCDM principles. Following the Design Science Research methodology, the proposed framework (ModelSelect) is empirically validated through 50 real-world case studies and comparative experiments against leading generative AI systems.
  The evaluation results show that ModelSelect produces reliable, interpretable, and reproducible recommendations that closely align with expert reasoning. Across the case studies, the framework achieved high coverage and strong rationale alignment in both model and library recommendation tasks, performing comparably to generative AI assistants while offering superior traceability and consistency.
  By framing AI model selection as an MCDM problem, this work establishes a rigorous foundation for transparent and reproducible decision support in research software engineering. The proposed framework provides a scalable and explainable pathway for integrating empirical evidence into AI model recommendation processes, ultimately improving the quality and robustness of research software decision-making.

</details>


### [61] [A Reference Architecture for Embedding Quantum Software Into Enterprise Systems](https://arxiv.org/abs/2512.12009)
*Marc Uphues,Sebastian Thöne,Herbert Kuchen*

Main category: cs.SE

TL;DR: 提出用于企业系统嵌入量子软件的模块化参考架构，通过松散耦合的分布式服务实现量子无关和量子特定任务，形成可执行的BPMN编排管道。


<details>
  <summary>Details</summary>
Motivation: 量子计算为计算密集型企业应用提供性能提升，但企业系统软件架构需要考虑特定特性和质量属性，以有效整合量子计算服务。

Method: 设计模块化参考架构，包含松散耦合的分布式服务组件，实现量子无关和量子特定任务，通过可执行的BPMN模型进行服务编排。

Result: 该参考架构在两个解决运筹学组合优化问题的案例研究中得到应用和验证，展示了其实际可行性。

Conclusion: 提出的模块化参考架构为企业系统整合量子软件提供了稳定、可重用的解决方案，通过服务编排管道支持量子计算服务的有效嵌入。

Abstract: Quantum computing promises a remarkable performance boost for certain applications, including computational intensive problems addressed by enterprise systems. However, software architectures of enterprise systems must consider specific characteristics and quality attributes when collaborating with quantum computing services. Hence, this paper presents a modular reference architecture for embedding quantum software into enterprise systems. Its building blocks consist of loosely coupled and distributed services that implement both quantum-independent and quantum-specific tasks. Although these services either depend on the business domain or the selected quantum algorithm, their orchestration forms a stable and reusable pipeline, specified as an executable BPMN model. For demonstration and evaluation purposes, the proposed reference architecture is utilized in two case studies addressing combinatorial challenges from the field of operations research.

</details>


### [62] [Hyper model checking for high-level relational models](https://arxiv.org/abs/2512.12024)
*Nuno Macedo,Hugo Pacheco*

Main category: cs.SE

TL;DR: 扩展Alloy的Pardinus后端以支持超属性的自动验证，提出HyperPardinus方法，使软件工程师能在早期设计阶段验证安全性和并发性相关的超属性。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏高层次规范语言支持软件工程师在系统设计早期阶段验证超属性（需要同时考虑多个系统轨迹的属性），而Alloy虽然适合早期设计验证，但原生不支持超属性验证。

Method: 提出HyperPardinus方法，扩展Alloy的时序逻辑后端Pardinus，利用现有的底层超属性模型检查器自动验证关系模型上的超属性，并保守地扩展Alloy以支持超属性的规范和验证。

Result: 评估表明，该方法能够建模和找到具有交替量词的复杂超属性的（反）示例，能够处理相关领域的最新技术场景。

Conclusion: HyperPardinus扩展了Alloy的能力，使其能够支持超属性的规范和自动验证，为软件工程师在早期设计阶段验证安全性和并发性相关属性提供了有效工具。

Abstract: Many properties related to security or concurrency must be encoded as so-called hyperproperties, temporal properties that allow reasoning about multiple traces of a system. However, despite recent advances on model checking hyperproperties, there is still a lack of higher-level specification languages that can effectively support software engineering practitioners in verifying properties of this class at early stages of system design.
  Alloy is a lightweight formal method with a high-level specification language that is supported by automated analysis procedures, making it particularly well-suited for the verification of design models at early development stages. It does not natively support, however, the verification of hyperproperties.
  This work proposes HyperPardinus, a new model finding procedure that extends Pardinus -- the temporal logic backend of the Alloy language -- to automatically verify hyperproperties over relational models by relying on existing low-level model checkers for hyperproperties. It then conservatively extends Alloy to support the specification and automatic verification of hyperproperties over design models, as well as the visualization of (counter-)examples at a higher-level of abstraction. Evaluation shows that our approach enables modeling and finding (counter-)examples for complex hyperproperties with alternating quantifiers, making it feasible to address relevant scenarios from the state of the art.

</details>


### [63] [Instruction-Tuning Open-Weight Language Models for BPMN Model Generation](https://arxiv.org/abs/2512.12063)
*Gökberk Çelikmasat,Atay Özgövde,Fatma Başak Aydemir*

Main category: cs.SE

TL;DR: InstruBPM：通过指令微调开源大语言模型，直接从自然语言描述生成高质量BPMN流程模型，在保持成本效益和隐私保护的同时提升建模效率


<details>
  <summary>Details</summary>
Motivation: 领域模型在软件工程中至关重要，但实践者常因建模耗时且需要专业知识而跳过建模。研究旨在解决这一障碍，探索是否可以通过指令微调的开源大语言模型，以成本效益和隐私保护的方式直接从自然语言描述生成高质量的BPMN流程模型。

Method: 提出InstruBPM方法：准备文本-图表配对数据，使用参数高效微调和量化技术对开源大语言模型进行指令微调，支持本地部署。通过多维度评估：文本/代码相似度（BLEU、ROUGE-L、METEOR）、结构保真度（相对图编辑距离）、指南符合性（外部工具检查）和专家评审。

Result: 经过微调的紧凑模型在所有基线模型中表现最佳，在序列和结构指标上均优于未微调的开源基线和强大的专有模型。生成的图表基本遵循BPMN最佳实践，是减少建模工作量的有用起点。指令微调相比未微调基线提高了结构准确性和鲁棒性，减少了对复杂提示工程的依赖。

Conclusion: 指令微调能够显著提升开源大语言模型从自然语言生成BPMN流程模型的质量和效率，为实践者提供了一种成本效益高、隐私保护的建模解决方案，有助于降低建模门槛并提高软件工程效率。

Abstract: Domain models are central to software engineering, as they enable a shared understanding, guide implementation, and support automated analyses and model-driven development. Yet, despite these benefits, practitioners often skip modeling because it is time-consuming and demands scarce expertise. We address this barrier by investigating whether open-weight large language models, adapted via instruction tuning, can generate high-quality BPMN process models directly from natural language descriptions in a cost-effective and privacy-preserving way. We introduce InstruBPM, a reproducible approach that prepares paired text-diagram data and instruction tunes an open source large language model with parameter-efficient fine-tuning and quantization for on-prem deployment. We evaluate the tuned model through complementary perspectives: (i) text/code similarity using BLEU, ROUGE-L, and METEOR, (ii) structural fidelity using Relative Graph Edit Distance, (iii) guidelines conformance using external tool checks, and (iv) a small expert review. Using a curated subset of a multi-domain BPMN dataset, we compare the tuned model with untuned open-weight baselines and strong proprietary models under consistent prompting regimes. Our compact tuned model outperforms all baselines across sequence and structural metrics while requiring substantially fewer resources; guideline analysis and expert feedback further indicate that the generated diagrams largely follow BPMN best practices and are useful starting points that reduce modeling effort. Overall, instruction tuning improves structural accuracy and robustness compared to untuned baselines and reduces reliance on heavy prompt scaffolding. We publicly share the trained models and scripts to support reproducibility and further research.

</details>


### [64] [Citation-Grounded Code Comprehension: Preventing LLM Hallucination Through Hybrid Retrieval and Graph-Augmented Context](https://arxiv.org/abs/2512.12117)
*Jahidul Arafat*

Main category: cs.SE

TL;DR: 该论文针对LLM在代码理解中的幻觉问题，提出了基于混合检索和轻量级结构推理的引用验证方法，在30个Python仓库的180个开发者查询中实现了92%的引用准确率和零幻觉。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型已成为代码理解的重要工具，但LLM幻觉（生成看似合理但事实错误的源代码引用）仍然是可靠开发者辅助的关键障碍。现有系统主要依赖纯文本相似性，忽视了代码结构，导致跨文件架构依赖的引用不完整。

Method: 开发了混合检索系统，结合BM25稀疏匹配、BGE密集嵌入和通过导入关系进行的Neo4j图扩展，采用引用验证机制，通过轻量级结构推理实现可验证的代码理解。

Result: 在30个Python仓库的180个开发者查询评估中，实现了92%的引用准确率和零幻觉。混合检索系统比单模式基线提高了14-18个百分点，在62%的架构查询中发现了纯文本相似性遗漏的跨文件证据。

Conclusion: 引用基础生成应作为代码理解系统的架构原则。跨文件证据发现对引用完整性贡献最大，但现有系统因依赖纯文本相似性而忽视了这一点。混合检索结合结构推理能有效解决LLM幻觉问题。

Abstract: Large language models have become essential tools for code comprehension, enabling developers to query unfamiliar codebases through natural language interfaces. However, LLM hallucination, generating plausible but factually incorrect citations to source code, remains a critical barrier to reliable developer assistance. This paper addresses the challenges of achieving verifiable, citation grounded code comprehension through hybrid retrieval and lightweight structural reasoning. Our work is grounded in systematic evaluation across 30 Python repositories with 180 developer queries, comparing retrieval modalities, graph expansion strategies, and citation verification mechanisms. We find that challenges of citation accuracy arise from the interplay between sparse lexical matching, dense semantic similarity, and cross file architectural dependencies. Among these, cross file evidence discovery is the largest contributor to citation completeness, but it is largely overlooked because existing systems rely on pure textual similarity without leveraging code structure. We advocate for citation grounded generation as an architectural principle for code comprehension systems and demonstrate this need by achieving 92 percent citation accuracy with zero hallucinations. Specifically, we develop a hybrid retrieval system combining BM25 sparse matching, BGE dense embeddings, and Neo4j graph expansion via import relationships, which outperforms single mode baselines by 14 to 18 percentage points while discovering cross file evidence missed by pure text similarity in 62 percent of architectural queries.

</details>


### [65] [Training Versatile Coding Agents in Synthetic Environments](https://arxiv.org/abs/2512.12216)
*Yiqi Zhu,Apurva Gandhi,Graham Neubig*

Main category: cs.SE

TL;DR: SWE-Playground：一个通过语言模型和智能体从零生成项目和任务的合成环境管道，用于训练多功能编码智能体，相比依赖现有GitHub仓库的方法具有更大灵活性和任务多样性。


<details>
  <summary>Details</summary>
Motivation: 现有软件工程智能体训练方法依赖GitHub仓库中的现有问题，存在两个主要限制：1) 依赖现有仓库灵活性有限；2) 主要关注问题解决任务，无法覆盖软件工程师需要处理的更广泛任务类型。

Method: 提出SWE-Playground管道，使用强大的语言模型和智能体从零开始合成生成项目和任务，不依赖外部数据源。该方法能够处理更广泛的编码任务，如通过生成单元测试重现问题、从零开始实现库等。

Result: 在三个不同基准测试中验证了方法的有效性。结果表明，SWE-Playground生成的轨迹具有密集的训练信号，使智能体能够用比先前工作显著更少的轨迹达到可比较的性能。

Conclusion: SWE-Playground通过合成生成环境和轨迹的方法，克服了现有软件工程智能体训练方法的局限性，为训练多功能编码智能体提供了更灵活、任务更多样的解决方案。

Abstract: Prior works on training software engineering agents have explored utilizing existing resources such as issues on GitHub repositories to construct software engineering tasks and corresponding test suites. These approaches face two key limitations: (1) their reliance on pre-existing GitHub repositories offers limited flexibility, and (2) their primary focus on issue resolution tasks restricts their applicability to the much wider variety of tasks a software engineer must handle. To overcome these challenges, we introduce SWE-Playground, a novel pipeline for generating environments and trajectories which supports the training of versatile coding agents. Unlike prior efforts, SWE-Playground synthetically generates projects and tasks from scratch with strong language models and agents, eliminating reliance on external data sources. This allows us to tackle a much wider variety of coding tasks, such as reproducing issues by generating unit tests and implementing libraries from scratch. We demonstrate the effectiveness of this approach on three distinct benchmarks, and results indicate that SWE-Playground produces trajectories with dense training signal, enabling agents to reach comparable performance with significantly fewer trajectories than previous works.

</details>


### [66] [Cluster-guided LLM-Based Anonymization of Software Analytics Data: Studying Privacy-Utility Trade-offs in JIT Defect Prediction](https://arxiv.org/abs/2512.12224)
*Maaz Khan,Gul Sher Khan,Ahsan Raza,Pir Sami Ullah,Abdul Ali Bangash*

Main category: cs.SE

TL;DR: 本文提出了一种基于LLM的集群引导匿名化技术，用于JIT缺陷预测中的隐私保护，通过保留软件指标的上下文和统计关系，在提升隐私保护水平的同时保持预测准确性。


<details>
  <summary>Details</summary>
Motivation: 机器学习在JIT缺陷预测中的广泛应用引发了软件分析数据隐私泄露的担忧。现有的匿名化方法（如表格转换和图扰动）往往忽略了软件指标之间的上下文依赖关系，导致隐私-效用权衡不理想。

Method: 提出基于集群引导的匿名化技术：1）将提交按特征分组为集群；2）使用LLM为每个提交集群生成上下文感知的参数配置；3）定义alpha-beta比率和变更混合分布用于匿名化；4）LLM作为自适应匿名化引擎，利用集群特定的统计信息。

Result: 在六个项目（Cassandra、Flink、Groovy、Ignite、OpenStack、Qt）上的评估显示：1）达到隐私级别2（IPR≥80%）；2）相比四种最先进的基于图的匿名化基线方法，隐私保护提升18-25%；3）保持可比较的F1分数。

Conclusion: LLM在提供集群特定统计信息时可以作为自适应匿名化引擎，实现上下文敏感且隐私保护的软件分析，同时不损害预测准确性。该方法在隐私-效用权衡方面优于现有方法。

Abstract: The increasing use of machine learning (ML) for Just-In-Time (JIT) defect prediction raises concerns about privacy leakage from software analytics data. Existing anonymization methods, such as tabular transformations and graph perturbations, often overlook contextual dependencies among software metrics, leading to suboptimal privacy-utility tradeoffs. Leveraging the contextual reasoning of Large Language Models (LLMs), we propose a cluster-guided anonymization technique that preserves contextual and statistical relationships within JIT datasets. Our method groups commits into feature-based clusters and employs an LLM to generate context-aware parameter configurations for each commit cluster, defining alpha-beta ratios and churn mixture distributions used for anonymization. Our evaluation on six projects (Cassandra, Flink, Groovy, Ignite, OpenStack, and Qt) shows that our LLM-based approach achieves privacy level 2 (IPR >= 80 percent), improving privacy by 18 to 25 percent over four state-of-the-art graph-based anonymization baselines while maintaining comparable F1 scores. Our results demonstrate that LLMs can act as adaptive anonymization engines when provided with cluster-specific statistical information about similar data points, enabling context-sensitive and privacy-preserving software analytics without compromising predictive accuracy.

</details>


### [67] [Evaluating Asynchronous Semantics in Trace-Discovered Resilience Models: A Case Study on the OpenTelemetry Demo](https://arxiv.org/abs/2512.12314)
*Anatoly A. Krasnovsky*

Main category: cs.SE

TL;DR: 论文提出了一种基于分布式追踪的微服务韧性模型，通过从OpenTelemetry追踪数据自动生成服务依赖图，使用蒙特卡洛模拟评估端点可用性，并在Astronomy Shop案例中验证模型有效性。


<details>
  <summary>Details</summary>
Motivation: 当前微服务韧性模型大多需要手动构建且定制化程度高，缺乏自动化方法。分布式追踪和混沌工程已成为标准实践，但缺乏基于追踪数据自动发现服务依赖并进行可用性评估的系统化方法。

Method: 1) 直接从原始OpenTelemetry追踪数据推导服务依赖图；2) 为端点附加特定成功谓词；3) 添加简单异步语义，将Kafka边视为非阻塞以实现即时HTTP成功；4) 使用蒙特卡洛模拟估计在服务故障下的端点可用性；5) 通过GitHub Actions工作流自动发现依赖图、运行模拟并执行混沌实验。

Result: 在OpenTelemetry Demo（Astronomy Shop）案例中，模型成功重现了整体可用性退化曲线。异步语义对Kafka边的预测可用性影响极小（最多约10^(-5)，即0.001个百分点）。这表明对于该案例中的即时HTTP可用性，显式建模异步依赖并非必要，简单的仅连接模型已足够。

Conclusion: 基于追踪发现的服务依赖图结合蒙特卡洛模拟能够有效评估微服务可用性。对于即时HTTP可用性场景，简单的连接模型已足够，无需复杂异步语义建模。该方法为自动化微服务韧性评估提供了实用框架。

Abstract: While distributed tracing and chaos engineering are becoming standard for microservices, resilience models remain largely manual and bespoke. We revisit a trace-discovered connectivity model that derives a service dependency graph from traces and uses Monte Carlo simulation to estimate endpoint availability under fail-stop service failures. Compared to earlier work, we (i) derive the graph directly from raw OpenTelemetry traces, (ii) attach endpoint-specific success predicates, and (iii) add a simple asynchronous semantics that treats Kafka edges as non-blocking for immediate HTTP success. We apply this model to the OpenTelemetry Demo ("Astronomy Shop") using a GitHub Actions workflow that discovers the graph, runs simulations, and executes chaos experiments that randomly kill microservices in a Docker Compose deployment. Across the studied failure fractions, the model reproduces the overall availability degradation curve, while asynchronous semantics for Kafka edges change predicted availabilities by at most about 10^(-5) (0.001 percentage points). This null result suggests that for immediate HTTP availability in this case study, explicitly modeling asynchronous dependencies is not warranted, and a simpler connectivity-only model is sufficient.

</details>


### [68] [ATLAS: Automated Tree-based Language Analysis System for C and C++ source programs](https://arxiv.org/abs/2512.12507)
*Jaid Monwar Chowdhury,Ahmad Farhan Shahriar Chowdhury,Humayra Binte Monwar,Mahmuda Naznin*

Main category: cs.SE

TL;DR: ATLAS是一个Python CLI工具，为C/C++代码生成包含AST、CFG和DFG的统一多视图表示，解决传统编程分析和LLM在处理复杂代码结构时的局限性。


<details>
  <summary>Details</summary>
Motivation: 现代软件系统日益复杂，传统编程分析技术在处理软件工程任务时存在不足。机器学习和大型语言模型虽然提供了有前景的解决方案，但其有效性受到数据解释方式的限制。源代码的含义不像自然语言那样由词元相邻性定义，而是由复杂、长距离、结构化的关系和依赖关系定义。这种局限性在C和C++中尤为明显，因为平坦的语法层次结构、指针别名、多级间接引用、typedef类型混淆和函数指针调用都阻碍了准确的静态分析。

Method: ATLAS是一个基于Python的命令行接口工具，具有以下功能：(i) 生成语句级控制流图(CFG)和类型感知的数据流图(DFG)，捕获整个程序的函数间依赖关系；(ii) 能够处理包含多个文件的整个C和C++项目；(iii) 适用于可编译和不可编译的代码；(iv) 使用抽象语法树(AST)、CFG和DFG生成统一的多视图代码表示。

Result: ATLAS通过保留基本的结构和语义信息，为改进下游软件工程和基于机器学习的程序理解提供了实用基础。该工具已公开可用，包括视频演示和GitHub代码仓库。

Conclusion: ATLAS通过生成统一的多视图代码表示，解决了C/C++代码分析中的关键挑战，为更准确的程序理解和分析提供了基础，特别是在处理复杂代码结构和依赖关系方面。

Abstract: The growing complexity of modern software systems has highlighted the shortcomings of traditional programming analysis techniques, particularly for Software Engineering (SE) tasks. While machine learning and Large Language Models (LLMs) offer promising solutions, their effectiveness is limited by the way they interpret data. Unlike natural language, source code meaning is defined less by token adjacency and more by complex, long-range, and structural relationships and dependencies. This limitation is especially pronounced for C and C++, where flatter syntactic hierarchies, pointer aliasing, multi-level indirection, typedef-based type obfuscation, and function-pointer calls hinder accurate static analysis. To address these challenges, this paper introduces ATLAS, a Python-based Command-Line Interface (CLI) that (i) generates statement-level Control Flow Graphs (CFG) and type-aware Data Flow Graphs (DFG) that capture inter-functional dependencies for the entire program; (ii) has the ability to work on entire C and C++ projects comprising multiple files; (iii) works on both compilable and non-compilable code and (iv) produces a unified multi-view code representation using Abstract Syntax Trees (AST), CFG and DFG. By preserving essential structural and semantic information, ATLAS provides a practical foundation for improving downstream SE and machine-learning-based program understanding. Video demonstration: https://youtu.be/RACWQe5ELwY Tool repository: https://github.com/jaid-monwar/ATLAS-code-representation-tool

</details>


### [69] [Diverse LLMs vs. Vulnerabilities: Who Detects and Fixes Them Better?](https://arxiv.org/abs/2512.12536)
*Arastoo Zibaeirad,Marco Vieira*

Main category: cs.SE

TL;DR: DVDR-LLM是一个集成多个大语言模型的框架，用于软件漏洞检测和修复，相比单个模型能提高10-12%的检测准确率，但在减少误报的同时增加了漏报。


<details>
  <summary>Details</summary>
Motivation: 单个大语言模型在识别复杂漏洞和生成修复方案时表现不佳，需要探索集成多个模型是否能减少错误率并提高性能。

Method: 提出DVDR-LLM集成框架，结合多个不同大语言模型的输出，通过设置适当的共识阈值来聚合模型结果。

Result: DVDR-LLM比单个模型平均检测准确率提高10-12%，对多文件漏洞的召回率提升18%，F1分数提升11.8%，但存在误报减少而漏报增加的权衡。

Conclusion: 集成多个LLM能显著提升漏洞检测性能，但需要根据具体安全场景谨慎选择共识阈值来平衡误报和漏报的权衡。

Abstract: Large Language Models (LLMs) are increasingly being studied for Software Vulnerability Detection (SVD) and Repair (SVR). Individual LLMs have demonstrated code understanding abilities, but they frequently struggle when identifying complex vulnerabilities and generating fixes.
  This study presents DVDR-LLM, an ensemble framework that combines outputs from diverse LLMs to determine whether aggregating multiple models reduces error rates. Our evaluation reveals that DVDR-LLM achieves 10-12% higher detection accuracy compared to the average performance of individual models, with benefits increasing as code complexity grows. For multi-file vulnerabilities, the ensemble approach demonstrates significant improvements in recall (+18%) and F1 score (+11.8%) over individual models. However, the approach raises measurable trade-offs: reducing false positives in verification tasks while simultaneously increasing false negatives in detection tasks, requiring careful decision on the required level of agreement among the LLMs (threshold) for increased performance across different security contexts.
  Artifact: https://github.com/Erroristotle/DVDR_LLM

</details>


### [70] [Assessing the Capability of Android Dynamic Analysis Tools to Combat Anti-Runtime Analysis Techniques](https://arxiv.org/abs/2512.12551)
*Dewen Suo,Lei Xue,Weihao Huang,Runze Tan,Guozi Sun*

Main category: cs.SE

TL;DR: 该论文对Android动态分析工具绕过反运行时分析（ARA）技术的能力进行了实证研究，发现现有工具存在严重缺陷，需要更强大的解决方案。


<details>
  <summary>Details</summary>
Motivation: Android应用快速增长的同时，恶意应用采用反运行时分析技术阻碍安全专业人员使用动态分析工具分析恶意行为，这对Android生态系统安全构成严重威胁。

Method: 采用综合性实证研究方法，评估广泛使用的Android动态分析工具对抗各种ARA技术的能力。

Result: 研究发现现有动态分析工具在对抗ARA机制方面存在关键性缺陷，现有工具的有效性存在严重不足。

Conclusion: 研究揭示了现有工具的局限性，强调了改进对抗ARA技术方法的迫切需求，为软件安全和动态分析领域的发展提供了重要见解。

Abstract: As the dominant mobile operating system, Android continues to attract a substantial influx of new applications each year. However, this growth is accompanied by increased attention from malicious actors, resulting in a significant rise in security threats to the Android ecosystem. Among these threats, the adoption of Anti-Runtime Analysis (ARA) techniques by malicious applications poses a serious challenge, as it hinders security professionals from effectively analyzing malicious behaviors using dynamic analysis tools. ARA technologies are designed to prevent the dynamic examination of applications, thus complicating efforts to ensure platform security. This paper presents a comprehensive empirical study that assesses the ability of widely-used Android dynamic analysis tools to bypass various ARA techniques. Our findings reveal a critical gap in the effectiveness of existing dynamic analysis tools to counter ARA mechanisms, highlighting an urgent need for more robust solutions. This work provides valuable insights into the limitations of existing tools and highlights the need for improved methods to counteract ARA technologies, thus advancing the field of software security and dynamic analysis.

</details>


### [71] [A Systematic Analysis of Higher Education on Software Engineering in the Netherlands](https://arxiv.org/abs/2512.12650)
*Bastiaan Heeren,Fabiano Dalpiaz,Mazyar Seraj,Roberto Verdecchia,Vadim Zaytsev*

Main category: cs.SE

TL;DR: 该研究对荷兰10所大学的207门软件工程课程进行分析，使用SWEBOK知识领域框架，揭示了本科和硕士阶段的知识覆盖模式、知识领域聚类关系，并识别了代表性不足的领域。


<details>
  <summary>Details</summary>
Motivation: 软件工程教育者需要持续改进课程和项目。了解软件工程高等教育的现状可以帮助教育者批判性评估课程，通过基准测试调整课程，最终提升课程质量。研究旨在通过对整个荷兰高等教育体系的分析，提供全面的软件工程教育现状洞察。

Method: 采用众包分析流程，分析荷兰10所大学的207门大学课程。使用SWEBOK知识领域框架进行课程映射，通过同质化和内部一致性改进阶段完善映射过程，随后进行数据分析阶段。

Result: 1. 本科阶段最常覆盖的知识领域是"构建与编程"；2. 某些知识领域在本科和硕士阶段同等覆盖（如软件工程模型），而更高级的领域几乎只在硕士阶段覆盖；3. 识别出三个紧密耦合的知识领域集群：(i)需求、架构和设计，(ii)测试、验证和安全，(iii)过程导向和DevOps主题；4. 荷兰大学普遍均匀覆盖所有知识领域，少数偏差反映了机构的研究优势；5. 识别了代表性不足的领域，如软件工程经济学。

Conclusion: 研究结果强调了关键知识领域之间的相关性及其促进综合学习的潜力。研究邀请其他地区的研究者使用相同方法分析当地软件工程教育项目，以便在全球范围内对比软件工程教育项目。

Abstract: Software engineering educators strive to continuously improve their courses and programs. Understanding the current state of practice of software engineering higher education can empower educators to critically assess their courses, fine-tune them by benchmarking against observed practices, and ultimately enhance their curricula. In this study, we aim to provide an encompassing analysis of higher education on software engineering by considering the higher educational offering of an entire European country, namely the Netherlands. We leverage a crowd-sourced analysis process by considering 10 Dutch universities and 207 university courses. The courses are analysed via knowledge areas adopted from the SWEBOK. The mapping process is refined via homogenisation and internal consistency improvement phases, and is followed by a data analysis phase. Given its fundamental nature, Construction and Programming is the most covered knowledge area at Bachelor level. Other knowledge areas are equally covered at Bachelor and Master level (e.g., software engineering models), while more advanced ones are almost exclusively covered at Master level. We identify three clusters of tightly coupled knowledge areas: (i) requirements, architecture, and design, (ii) testing, verification, and security, and (iii) process-oriented and DevOps topics. Dutch universities generally cover all knowledge areas uniformly, with minor deviations reflecting institutional research strengths. Our results highlight correlations among key knowledge areas and their potential for enhancing integrated learning. We also identify underrepresented areas, such as software engineering economics, which educators may consider including in curricula. We invite researchers to use our research method in their own geographical region, in order to contrast software engineering education programs across the globe.

</details>


### [72] [Attributes to Support the Formulation of Practically Relevant Research Problems in Software Engineering](https://arxiv.org/abs/2512.12699)
*Anrafel Fernandes Pereira,Maria Teresa Baldassarre,Daniel Mendez,Jürgen Börstler,Nauman bin Ali,Rahul Mohanani,Darja Smite,Stefan Biffl,Rogardt Heldal,Davide Falessi,Daniel Graziotin,Marcos Kalinowski*

Main category: cs.SE

TL;DR: 论文提出了软件工程研究中问题表述的七个关键属性，并通过研讨会验证了它们对于行业导向研究的重要性，同时收集了改进建议。


<details>
  <summary>Details</summary>
Motivation: 软件工程研究中，良好表述的研究问题对于实现实际相关性至关重要，但目前缺乏这一早期阶段的结构化指导。研究旨在引入并评估软件工程文献中确定的七个研究问题表述属性。

Method: 在ISERN 2024会议期间，与42位资深软件工程研究人员进行了研讨会。使用"问题愿景板"展示七个属性，参与者分组讨论、提供书面反馈，并完成调查评估属性的重要性、完整性和改进建议。

Result: 研究结果证实了七个属性在制定行业导向研究问题中的重要性。定性反馈展示了如何在实践中应用这些属性，并提出了改进建议，如在影响/后果中纳入财务标准（如ROI），在证据中考虑可行性和约束条件。

Conclusion: 结果重申了七个属性在支持反思性和情境感知问题表述中的重要性。根据特定研究背景调整这些属性的使用，有助于改善学术研究与行业需求之间的对齐。

Abstract: [Background] A well-formulated research problem is essential for achieving practical relevance in Software Engineering (SE), yet there is a lack of structured guidance in this early phase. [Aims] Our goal is to introduce and evaluate seven attributes identified in the SE literature as relevant for formulating research problems (practical problem, context, implications/impacts, practitioners, evidence, objective, and research questions) in terms of their perceived importance and completeness, and learn how they can be applied. [Method] We conducted a workshop with 42 senior SE researchers during the ISERN 2024 meeting. The seven attributes were presented using a Problem Vision board filled with a research example. Participants discussed attributes in groups, shared written feedback, and individually completed a survey assessing their importance, completeness, and suggestions for improvement. [Results] The findings confirm the importance of the seven attributes in the formulation of industry-oriented research problems. Qualitative feedback illustrated how they can be applied in practice and revealed suggestions to refine them, such as incorporating financial criteria (e.g., ROI) into implications/impacts and addressing feasibility and constraints under evidence. [Conclusion] The results reaffirm the importance of the seven attributes in supporting a reflective and context-aware problem formulation. Adapting their use to specific research contexts can help to improve the alignment between academic research and industry needs.

</details>


### [73] [Temporal HAL-API Dependencies as a Gateway to Formal Embedded Software Development](https://arxiv.org/abs/2512.12788)
*Manuel Bentele,Andreas Podelski,Axel Sikora,Bernd Westphal*

Main category: cs.SE

TL;DR: THADs是一种能捕捉嵌入式软件中特定正确性属性的方法，通过程序注解进行中等程度的规范，并通过软件模型检查自动验证，在通用属性和全功能形式化方法之间找到了平衡点。


<details>
  <summary>Details</summary>
Motivation: 在工业嵌入式软件开发中，需要在规范投入和验证能力之间找到平衡点。通用属性虽然规范投入少但能力有限，而全功能形式化方法虽然强大但投入大。THADs旨在填补这一空白，为工业应用提供经济实用的形式化方法入口。

Method: 通过程序注解进行THADs规范，然后使用软件模型检查技术自动验证这些时间相关的HAL-API依赖关系。

Result: THADs能够有效捕捉嵌入式软件中一类有趣的正确性属性，规范投入适中且验证可自动化，在实际工业应用中具有可行性。

Conclusion: THADs在通用静态分析和全功能形式化方法之间找到了一个理想的平衡点，有望成为工业嵌入式软件开发中更广泛、更经济地采用形式化方法的入口。

Abstract: Temporal HAL-API Dependencies (THADs) can be useful to capture an interesting class of correctness properties in embedded software development. They demand a moderate effort for specification (which can be done via program annotations) and verification (which can be done automatically via software model checking). In this sense, they have the potential to form an interesting sweet spot between generic properties (that demand virtually no specification effort, and that are typically addressed by static analysis) and application-specific properties as addressed by full-fledged formal methods. Thus, they may form a gateway to wider and more economic use of formal methods in industrial embedded software development.

</details>


### [74] [Challenges and Enablers: Remote Work for People with Disabilities in Software Development Teams](https://arxiv.org/abs/2512.12965)
*Thayssa Rocha,Luciano Teran,Marcelle Mota,Cleidson de Souza,Kiev Gama,Gustavo Pinto*

Main category: cs.SE

TL;DR: 研究调查远程工作如何影响残障人士在混合能力软件开发团队中的体验，发现团队成员和领导对残障同事面临的日常挑战认知有限，需要改进无障碍工具、沟通策略和适应性管理方法。


<details>
  <summary>Details</summary>
Motivation: 随着科技行业远程和混合工作模式的普及，残障人士在软件开发团队中的包容性面临新的机遇和挑战，需要了解远程环境对残障人士体验的具体影响。

Method: 采用混合方法：1）在线调查收集定量数据；2）对14名自认为残障的软件开发者进行结构化访谈（包括6名自闭症人士、6名身体残障人士、2名聋人/重听人士）；3）结合定量数据和开放式调查回答及访谈记录的定性编码分析。

Result: 研究发现尽管残障团队成员面临各种障碍，但他们的队友和领导对这些日常挑战的认知有限，特别是在维持远程协作方面。这揭示了在无障碍工具、沟通策略和适应性管理方法方面存在改进机会。

Conclusion: 远程工作为残障人士参与软件开发团队带来了新的机遇，但也暴露了团队对残障同事挑战认知不足的问题。需要系统性改进技术工具、沟通实践和管理方法，以更好地支持混合能力团队的远程协作。

Abstract: The increasing adoption of remote and hybrid work modalities in the technology sector has brought new opportunities and challenges for the inclusion of people with disabilities (PWD) in software development teams (SDT). This study investigates how remote work affects PWDs' experience in mixed-ability SDT, focusing on the unique challenges and strategies that emerge in remote environments. We conducted an online survey with \totalSurveyResponses valid responses, encompassing PWD, their leaders, and teammates, to capture sociotechnical aspects of their experiences with remote collaboration. To deepen our understanding, we carried out 14 structured interviews with software developers who self-identified as having disabilities (six autistic individuals, six with physical disabilities, and two who are d/Deaf). Our analysis combines quantitative data with qualitative coding of open-ended survey responses and interview transcripts. The results reveal that, despite the barriers faced by team members with disabilities, their teammates and leaders have a limited perception of the daily challenges involved in sustaining collaborative remote work. These findings highlight opportunities for improvement in accessibility tools, communication strategies, and adaptive management approaches.

</details>


### [75] [A Decision Support Framework for Blockchain Pattern Selection Based on Soft Goals](https://arxiv.org/abs/2512.13239)
*Eddy Kiomba Kambilo,Nicolas Herbaut,Irina Rychkova,Carine Souveyet*

Main category: cs.SE

TL;DR: 提出BC-TEAEM框架，结合区块链模式本体和领域无关软目标，通过多准则决策方法支持系统架构师选择区块链模式，确保业务目标与技术设计的对齐。


<details>
  <summary>Details</summary>
Motivation: 区块链技术在各行业应用日益广泛，但区块链解决方案在带来积极影响的同时也引入约束和潜在负面效应，可能破坏业务策略。区块链模式多样且缺乏将业务目标与技术设计决策连接的标准框架，使得模式选择对系统架构师成为复杂任务。

Method: 提出区块链技术感知的企业建模（BC-TEAEM）框架，结合区块链模式本体和领域无关软目标，采用多准则决策方法。该框架聚焦领域专家与技术专家之间的互动，通过迭代捕获和精化偏好，支持系统化的区块链模式选择。开发了原型决策支持工具实现该方法。

Result: 通过制药公司供应链追溯系统的案例研究验证了框架的适用性，展示了BC-TEAEM在实际应用中的有效性。

Conclusion: BC-TEAEM框架能够支持系统架构师在区块链模式选择中做出更明智的决策，确保业务目标与技术设计的对齐和可追溯性，为区块链解决方案的设计提供了系统化的决策支持方法。

Abstract: Blockchain technology is gaining momentum across many sectors. Whereas blockchain solutions have important positive effects on the business domain, they also introduce constraints and may cause delayed or unforeseen negative effects, undermining business strategies. The diversity of blockchain patterns and lack of standardized frameworks linking business goals to technical design decisions make pattern selection a complex task for system architects. To address this challenge, we propose Blockchain--Technology-Aware Enterprise Modeling (BC-TEAEM), a decision support framework that combines ontologies of blockchain patterns and domain-independent soft goals with a multi-criteria decision-making approach. The framework focuses on the interplay between a domain expert and a technical expert to ensure alignment and traceability. By iteratively capturing and refining preferences, BC-TEAEM supports systematic selection of blockchain patterns. We develop a prototype decision support tool implementing our method and validate it through a case study of a pharmaceutical company's supply chain traceability system, demonstrating the framework's applicability. %a supply chain traceability case study.

</details>


### [76] [UCRBench: Benchmarking LLMs on Use Case Recovery](https://arxiv.org/abs/2512.13360)
*Shuyuan Xiao,Yiran Zhang,Weisong Sun,Xiaohong Chen,Yang Liu,Zhi Jin*

Main category: cs.SE

TL;DR: 本文介绍了首个代码对齐的用例基准，用于评估LLM从源代码生成用例的能力，并提出了分层评估协议，发现LLM在重构系统功能方面存在显著局限性。


<details>
  <summary>Details</summary>
Motivation: 现有用例基准稀缺且可能与实际系统行为不一致，这限制了大型语言模型从源代码生成用例能力的严格评估。

Method: 通过手动验证九个真实软件项目中的用户目标和子功能用例，构建代码对齐的用例基准，并提出分层评估协议（评估参与者正确性、名称准确性、路径保真度和行为覆盖率）。

Result: LLM能够部分重构系统功能，但性能在不同项目间差异显著，在领域特定和多模块系统中表现尤其不足。模型表现出高遗漏率，且在将子功能聚合为用户目标用例时难以保持一致的抽象层次。

Conclusion: 研究揭示了LLM在基于用例逆向工程方面的潜力和当前局限性，强调了需要更精细的评估方法和改进的LLM能力来处理复杂软件系统。

Abstract: Use cases are widely employed to specify functional requirements, yet existing benchmarks are scarce and face the risk of being misaligned with actual system behavior, similarly limiting the rigorous evaluation of large language models (LLMs) in generating use cases from source code. We address this gap by introducing code-aligned use case benchmarks, constructed through manual validation of both user-goal and subfunction use cases across nine real-world software projects. Using this benchmark, we conduct the first systematic study of LLMs and propose a hierarchical evaluation protocol that assesses actor correctness, name accuracy, path fidelity, and behavioral coverage. The results show that while LLMs can partially reconstruct system functionality, their performance varies significantly across projects, with particularly noticeable shortcomings in domain-specific and multi-module systems. The models also exhibit high omission rates and struggle to maintain consistent abstraction when aggregating subfunctions into user-goal use cases, highlighting both the potential and current limitations of LLM-based use case reverse engineering.

</details>


### [77] [PSALM: applying Proportional SAmpLing strategy in Metamorphic testing](https://arxiv.org/abs/2512.13414)
*Zenghui Zhou,Pak-Lok Poon,Zheng Zheng,Xiao-Yi Zhang*

Main category: cs.SE

TL;DR: 本文提出了PSALM方法，将比例抽样策略（PSS）适应到蜕变测试中，用于源测试用例选择和蜕变组选择，证明了其理论优越性并通过实证研究验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 蜕变测试的故障检测效果不仅取决于蜕变关系的选择和质量，还受源测试用例和蜕变组选择的影响。虽然已有大量研究关注蜕变关系的设计、生成和验证，但源测试用例选择和蜕变组选择的系统方法仍未被充分探索。传统测试中的比例抽样策略（PSS）具有强大的理论保证，但其假设不能直接应用于蜕变测试，因为选择域、测试单元和故障分布存在差异。

Method: 本文提出了PSALM方法，将比例抽样策略（PSS）适应到蜕变测试中，用于源测试用例选择和蜕变组选择。作者正式证明了PSALM在任何情况下都不劣于随机选择，无论源测试用例和蜕变组域如何划分。进一步确定了在哪些条件下，将PSALM应用于源测试用例选择和蜕变组选择会产生相同的效果。

Result: 在8个主题程序和184个突变体上的综合实证研究表明，结果与理论分析一致，PSALM通常比现有选择策略（如ART和MT-ART）表现更有效。这些结果表明PSALM为蜕变测试提供了一个理论基础扎实且实际有效的选择策略。

Conclusion: PSALM方法成功地将比例抽样策略适应到蜕变测试中，为源测试用例选择和蜕变组选择提供了理论保证和实际有效性，填补了蜕变测试中系统选择方法的研究空白。

Abstract: Metamorphic testing (MT) alleviates the oracle problem by checking metamorphic relations (MRs) across multiple test executions. The fault detection effectiveness of MT is influenced not only by the choice and quality of MRs, but also by how source test cases and metamorphic groups (MGs) are selected. While substantial research has focused on designing, generating, and validating MRs, systematic methods for source test case selection and MG selection remain largely unexplored. Although the Proportional Sampling Strategy (PSS) provides strong theoretical guarantees in traditional testing, its assumptions cannot be directly applied in MT due to differences in selection domains, test units, and failure distributions. This paper proposes PSALM, an adaptation of PSS to MT for both source test case selection and MG selection. We formally prove that PSALM is never inferior to random selection regardless of how the source test case and MG domains are partitioned. We further identify the conditions under which applying PSALM to source test case selection and MG selection yields identical effectiveness. A comprehensive empirical study on eight subject programs and 184 mutants shows that the results are consistent with our theoretical analysis and that PSALM generally performs more effectively than existing selection strategies such as ART and MT-ART. These results demonstrate that PSALM provides a theoretically grounded and practically effective selection strategy for MT.

</details>


### [78] [QMon: Monitoring the Execution of Quantum Circuits with Mid-Circuit Measurement and Reset](https://arxiv.org/abs/2512.13422)
*Ning Ma,Jianjun Zhao,Foutse Khomh,Shaukat Ali,Heng Li*

Main category: cs.SE

TL;DR: QMON是一种量子电路监控方法，利用中间测量和重置操作来监控量子电路内部状态，同时保持原始运行时行为，有助于量子软件调试和错误检测。


<details>
  <summary>Details</summary>
Motivation: 量子电路具有不可克隆定理和测量诱导坍缩等独特性质，无法像经典软件那样通过日志和运行时追踪直接观察内部状态，这使得量子电路的调试和运行时监控变得特别困难。

Method: QMON利用中间测量和重置操作，在开发者指定的电路位置插入监控操作符，允许比较这些位置的预期和观测量子态概率，同时保持原始电路行为。

Result: 对154个量子电路的实验表明，所有电路在插桩后都保持了预期功能，QMON成功检测并定位了各种编程错误，虽然监控覆盖范围受到需要保持量子纠缠等微妙性质的限制。

Conclusion: QMON能够有效检测错误，同时对原始量子状态引入无或可忽略的干扰，有助于开发更健壮可靠的量子软件，推动该领域的成熟发展。

Abstract: Unlike classical software, where logging and runtime tracing can effectively reveal internal execution status, quantum circuits possess unique properties, such as the no-cloning theorem and measurement-induced collapse, that prevent direct observation or duplication of their states. These characteristics make it especially challenging to monitor the execution of quantum circuits, complicating essential tasks such as debugging and runtime monitoring. This paper presents QMON, a practical methodology that leverages mid-circuit measurements and reset operations to monitor the internal states of quantum circuits while preserving their original runtime behavior. QMON enables the instrumentation of monitoring operators at developer-specified locations within the circuit, allowing comparisons between expected and observed quantum-state probabilities at those locations. We evaluated QMON by analyzing its impact on circuit behavior, monitoring coverage, and effectiveness in bug localization. Experimental results involving 154 quantum circuits show that all circuits preserve their intended functionality after instrumentation and that QMON successfully detects and localizes various programming errors. Although monitoring coverage is limited by the need to preserve delicate quantum properties, such as entanglement, QMON effectively detects errors while introducing no or negligible disturbance to the original quantum states. QMON facilitates the development of more robust and reliable quantum software as the field continues to mature.

</details>


### [79] [Mapping of the system of software-related emissions and shared responsibilities](https://arxiv.org/abs/2512.13474)
*Laura Partanen,Antti Sipila,Md Sanaul Haque,Jari Porras*

Main category: cs.SE

TL;DR: 该研究通过系统映射方法，分析了ICT行业软件相关碳排放的来源和利益相关者责任，旨在提高对软件排放的认识，支持欧盟气候法规合规。


<details>
  <summary>Details</summary>
Motivation: 全球气候变暖趋势加剧，ICT行业是温室气体排放的重要来源且影响持续扩大。为达成《巴黎协定》1.5°C温控目标，欧盟通过CSRD和CSDD等法规要求企业（包括ICT行业）识别并减少环境足迹。需要提高对软件相关排放的认识和理解。

Method: 采用全面的系统映射方法，识别ICT领域碳排放和能源消耗的主要来源，并梳理软件生命周期中各利益相关者的关键责任。

Result: 系统映射识别了ICT领域碳排放和能源消耗的主要来源，并明确了软件生命周期中各利益相关者（如开发者、企业、监管机构等）应承担的责任框架。

Conclusion: 该研究为ICT行业提供了理解软件相关排放的系统框架，有助于行业利益相关者更好地履行欧盟法规要求，推动减少ICT行业的环境影响，支持全球气候目标实现。

Abstract: The global climate is experiencing a rapid and unprecedented warming trend. The ICT sector is a notable contributor to global greenhouse gas emissions, with its environmental impact continuing to expand. Addressing this issue is vital for achieving the objectives of the Paris Agreement, particularly the goal of limiting global temperature rise to 1.5°C. At the European Union level, regulatory measures such as the CSRD and the CSDD impose obligations on companies, including those within the ICT sector, to recognize and mitigate their environmental footprint. This study provides a comprehensive system mapping aimed at enhancing the awareness and understanding of software-related emissions and the corresponding responsibilities borne by the ICT sector. The mapping identifies the primary sources of carbon emissions and energy consumption within the ICT domain while also outlining the key responsibilities of the stakeholders accountable throughout the software lifecycle.

</details>


### [80] [Fine-tuned LLM-based Code Migration Framework](https://arxiv.org/abs/2512.13515)
*Oleg Grynets,Vasyl Lyashkevych,Dmytro Baran,Maksym Orliansky,Taras Zelenyy,Markiian Leshchyshyn*

Main category: cs.SE

TL;DR: 提出一个基于大型语言模型的自动化SQL代码迁移框架，通过微调LLM解决Oracle PL/SQL到PostgreSQL的语法映射、存储过程、触发器等数据库元素的转换问题，实现高效、精确的数据库迁移。


<details>
  <summary>Details</summary>
Motivation: 传统SQL系统迁移面临语法差异、数据库元素转换复杂、人工成本高等挑战，需要自动化、可扩展的解决方案来提升迁移效率和准确性。

Method: 结合微调与提示工程，构建基于LLM的迁移框架，包括SQL特征自动检测、半监督错误分析、专家反馈集成，通过迭代转换循环实现持续优化。

Result: 显著降低语法错误率，提升特征对齐度，通过数据集采样确保持续改进，实现工作流效率提升和精确的特征映射。

Conclusion: 微调LLM在SQL代码迁移中至关重要，该框架为数据库转换提供了可扩展、精确且高效的自动化解决方案，将生成式人工智能嵌入迁移流程提升了整体效率。

Abstract: The study presents the outcomes of research and experimental validation in the domain of automated codebase migration, with a focus on addressing challenges in transitioning SQL-based systems. The proposed method for migration essentially appears as a framework that leverages the best aspects of traditional software engineering techniques and provides an iterative, scalable, precise and efficient solution for modern database transformations. The central piece of the approach is the integration of a fine-tuned Large Language Model to address critical issues in SQL code conversion, such as syntax mapping, resolving discrepancies between Oracle PL/SQL and PostgreSQL, and optimising database elements such as stored procedures, triggers, views, and overall database logic. Thus, the method involves a trade-off between fine-tuning and prompt engineering. Special attention is given to a fine-tuning approach, which enhances the adaptability and compatibility with migration requirements across the entire database. According to the achieved results, fine-tuning plays a very important role. The study employs targeted evaluation methodologies along with computational metrics to measure the success of iterative conversion cycles. Core innovations include automated SQL feature detection, semi-supervised error analysis and integration of Subject Matter Experts feedback within a systematic migration workflow. The methodology achieves significant reductions in Syntax Error Rates, enhances feature alignment throughout migration iterations, and leverages dataset sampling to ensure continual improvement. By embedding GAI into the migration process, the framework facilitates precise feature mapping, semi-automated error resolution, and data-driven optimisation loops, improving workflow efficiency.

</details>
