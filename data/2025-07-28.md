<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 15]
- [cs.CR](#cs.CR) [Total: 10]
- [cs.AI](#cs.AI) [Total: 15]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Exploring the Landscape of Fairness Interventions in Software Engineering](https://arxiv.org/abs/2507.18726)
*Sadia Afrin Mim*

Main category: cs.SE

TL;DR: 论文总结了AI公平性问题及其解决方法。


<details>
  <summary>Details</summary>
Motivation: AI在实际应用中存在数据偏见等风险，需解决公平性问题。

Method: 综述了多种公平性干预措施和研究。

Result: 总结了现有解决公平性问题的方法。

Conclusion: 公平性干预对AI应用至关重要。

Abstract: Current developments in AI made it broadly significant for reducing human
labor and expenses across several essential domains, including healthcare and
finance. However, the application of AI in the actual world poses multiple
risks and disadvantages due to potential risk factors in data (e.g., biased
dataset). Practitioners developed a number of fairness interventions for
addressing these kinds of problems. The paper acts as a survey, summarizing the
various studies and approaches that have been developed to address fairness
issues

</details>


### [2] [Agentic Program Repair from Test Failures at Scale: A Neuro-symbolic approach with static analysis and test execution feedback](https://arxiv.org/abs/2507.18755)
*Chandra Maddila,Adam Tait,Claire Chang,Daniel Cheng,Nauman Ahmad,Vijayaraghavan Murali,Marshall Roch,Arnaud Avondet,Aaron Meltzer,Victor Montalvao,Michael Hopko,Chris Waterson,Parth Thakkar,Renuka Fernandez,Kristian Kristensen,Sivan Barzily,Sherry Chen,Rui Abreu,Nachiappan Nagappan,Payam Shodjai,Killian Murphy,James Everingham,Aparna Ramani,Peter C. Rigby*

Main category: cs.SE

TL;DR: 开发了一个基于LLM的工程代理，用于大规模修复代码中的测试失败问题，结合ReAct框架和静态分析工具，取得了42.3%的解决率。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs的发展，大型组织可以利用其进行复杂的程序修复工作，尤其是在大规模代码库中。

Method: 以Llama为基础，使用ReAct框架开发代理，通过静态分析和测试失败反馈优化解决方案，并利用LLM-as-a-Judge确保补丁质量。

Result: 离线评估中，70B模型表现接近405B模型，生产环境中31.5%的修复被采纳。

Conclusion: 工程代理在代码修复中表现出潜力，但仍需进一步优化以提高解决率和采纳率。

Abstract: Aim: With the advent of LLMs, sophisticated agentic program repair has become
viable at large organizations with large codebases. In this work, we develop an
Engineering Agent that fixes the source code based on test failures at scale
across diverse software offerings internally.
  Method: Using Llama as the base, we employ the ReAct harness to develop an
agent. We start with a test failure that was triaged by a rule-based test
failure bot. We then set up an agentic harness and allow the agent to reason
and run a set of 15 actions from reading a file to generating a patch. We
provide feedback to the agent through static analysis and test failures so it
can refine its solution. We leverage an LLM-as-a-Judge to ensure that the patch
conforms to the standards followed by a human review to land fixes.
  Benchmark Findings: We curated offline benchmarks for our patch generator,
the Engineering Agent loop, and the LLM-as-a-Judge. In offline evaluations we
found that a specialized 70B model is highly competitive with the much larger
but vanilla Llama-405B. In an ablation study, we found that the ReAct harness
(neural model) benefited from the symbolic information from static analysis
tools and test execution traces. A model that strikes a balance between the
solve rate and error rate vs the cost and latency has a benchmark solve rate of
42.3% using an average 11.8 feedback iterations.
  Production Findings: In a three month period, 80% of the generated fixes were
reviewed, of which 31.5% were landed (25.5% of the total number of generated
fixes).
  Feedback from Engineers: We used open coding to extract qualitative themes
from engineers' feedback. We saw positive feedback in the form of quick
approvals, gratitude, and surprise. We also found mixed feedback when the
Engineering Agent's solution was partially correct and it served as a good
starting point.

</details>


### [3] [MemoCoder: Automated Function Synthesis using LLM-Supported Agents](https://arxiv.org/abs/2507.18812)
*Yiping Jia,Zhen Ming Jiang,Shayan Noei,Ying Zou*

Main category: cs.SE

TL;DR: MemoCoder是一个多智能体框架，通过协作解决问题和从过去的修复中学习，提升代码生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在迭代调试和错误处理方面表现不佳，且缺乏知识积累机制。

Method: 提出MemoCoder框架，包含修复知识集和导师智能体，支持知识复用和错误模式识别。

Result: 在多个基准测试中，MemoCoder表现优于零样本提示和自修复策略。

Conclusion: MemoCoder在迭代优化和知识引导的代码生成中具有显著优势。

Abstract: With the widespread adoption of Large Language Models (LLMs) such as GitHub
Copilot and ChatGPT, developers increasingly rely on AI-assisted tools to
support code generation. While LLMs can generate syntactically correct
solutions for well-structured programming tasks, they often struggle with
challenges that require iterative debugging, error handling, or adaptation to
diverse problem structures. Existing approaches such as fine-tuning or
self-repair strategies either require costly retraining or lack mechanisms to
accumulate and reuse knowledge from previous attempts.
  To address these limitations, we propose MemoCoder, a multi-agent framework
that enables collaborative problem solving and persistent learning from past
fixes. At the core of MemoCoder is a Fixing Knowledge Set, which stores
successful repairs and supports retrieval for future tasks. A central Mentor
Agent supervises the repair process by identifying recurring error patterns and
refining high-level fixing strategies, providing a novel supervisory role that
guides the self-repair loop. We evaluate MemoCoder across three public
benchmarks -- MBPP, HumanEval, and LiveCodeBench -- spanning a range of problem
complexities. Experimental results show that MemoCoder consistently outperforms
both zero-shot prompting and a Self-Repair strategy, with improvements ranging
from 3.1% to 12.1% in Pass@10 and from 1.4% to 14.5% in Pass@50, demonstrating
its effectiveness in iterative refinement and knowledge-guided code generation.

</details>


### [4] [Exploring the Jupyter Ecosystem: An Empirical Study of Bugs and Vulnerabilities](https://arxiv.org/abs/2507.18833)
*Wenyuan Jiang,Diany Pressato,Harsh Darji,Thibaud Lutellier*

Main category: cs.SE

TL;DR: 本文通过大规模实证研究分析了Jupyter Notebook中的错误和漏洞，发现配置问题和API使用错误是常见问题，并探讨了相关安全风险。


<details>
  <summary>Details</summary>
Motivation: Jupyter Notebook作为数据科学家的主要工具，其独特性使得传统软件工程模型难以适用，因此需要专门研究其错误和漏洞。

Method: 收集并分析两大平台的Notebook数据集，进行定量分析（如复杂度指标、贡献者活动等）和定性研究（基于扎根理论的错误分类），同时评估部署框架的安全风险。

Result: 研究发现配置问题和API使用错误是最常见的错误，并揭示了Notebook部署框架的相关安全风险。

Conclusion: Notebook的支持不如传统软件，导致代码复杂、配置错误和维护不足，需要更多关注和改进。

Abstract: Background. Jupyter notebooks are one of the main tools used by data
scientists. Notebooks include features (configuration scripts, markdown,
images, etc.) that make them challenging to analyze compared to traditional
software. As a result, existing software engineering models, tools, and studies
do not capture the uniqueness of Notebook's behavior. Aims. This paper aims to
provide a large-scale empirical study of bugs and vulnerabilities in the
Notebook ecosystem. Method. We collected and analyzed a large dataset of
Notebooks from two major platforms. Our methodology involved quantitative
analyses of notebook characteristics (such as complexity metrics, contributor
activity, and documentation) to identify factors correlated with bugs.
Additionally, we conducted a qualitative study using grounded theory to
categorize notebook bugs, resulting in a comprehensive bug taxonomy. Finally,
we analyzed security-related commits and vulnerability reports to assess risks
associated with Notebook deployment frameworks. Results. Our findings highlight
that configuration issues are among the most common bugs in notebook documents,
followed by incorrect API usage. Finally, we explore common vulnerabilities
associated with popular deployment frameworks to better understand risks
associated with Notebook development. Conclusions. This work highlights that
notebooks are less well-supported than traditional software, resulting in more
complex code, misconfiguration, and poor maintenance.

</details>


### [5] [SLICEMATE: Accurate and Scalable Static Program Slicing via LLM-Powered Agents](https://arxiv.org/abs/2507.18957)
*Jianming Chang,Jieke Shi,Yunbo Lyu,Xin Zhou,Lulu Wang,Zhou Yang,Bixin Li,David Lo*

Main category: cs.SE

TL;DR: SliceMate是一种基于大型语言模型（LLM）代理的新型静态程序切片解决方案，通过三个专门代理（合成、验证和优化）实现高精度切片，无需显式依赖图构建。


<details>
  <summary>Details</summary>
Motivation: 传统切片工具依赖计算成本高的依赖图可达性分析，难以扩展到大型程序或处理语法不完整代码；现有学习方法虽更鲁棒，但在规范代码上性能不足。

Method: SliceMate集成三个代理：合成代理（扩展扫描范围生成候选切片）、验证代理（检查切片完整性和简洁性）和优化代理（修复切片）。

Result: 实验结果显示，SliceMate在2,200个手动标注的Java和Python程序（5至8,577行）上显著优于传统和学习方法。

Conclusion: SliceMate通过LLM代理实现高效、高精度的静态程序切片，解决了传统方法的扩展性和鲁棒性问题。

Abstract: Static program slicing, which extracts the executable portions of a program
that affect the values at a specific location, supports many software analysis
tasks such as debugging and security auditing. However, traditional slicing
tools rely on computationally expensive reachability analysis over dependency
graphs, which struggle to scale to large programs and often fail to handle code
with incomplete syntax. Recently emerged learning-based methods, while more
robust to such cases, still fall short of achieving comparable performance to
traditional methods on well-formed code.
  In this work, we propose SliceMate, a novel static program slicing solution
powered by Large Language Model (LLM) agents. It bypasses the need for explicit
dependency graph construction and achieving superior slicing accuracy.
Concretely, SliceMate integrates three specialized agents: (1) a synthesis
agent that produces candidate slices by incrementally expanding the scan scope
across functions and files guided by LLM-inferred dependencies; (2) a
verification agent that performs conciseness and completeness checks of the
candidate slices, detecting missing or irrelevant statements; and (3) a
refinement agent that repairs the slices with minimal edits in accordance with
the verification results. These agents are orchestrated by a control module
that ensures timely convergence and outputs high-quality slices without manual
intervention. For rigorous evaluation, we construct a new and high-quality
benchmark, SliceBench, comprising 2,200 manually annotated Java and Python
programs, with program lengths ranging from 5 to 8,577 lines, significantly
larger than those in existing slicing benchmarks. Experimental results show
that SliceMate greatly outperforms both traditional and learning-based slicing
tools.

</details>


### [6] [Classifying Issues in Open-source GitHub Repositories](https://arxiv.org/abs/2507.18982)
*Amir Hossain Raaj,Fairuz Nawer Meem,Sadia Afrin Mim*

Main category: cs.SE

TL;DR: 该论文旨在利用机器学习和深度神经网络模型对GitHub开源社区中的问题进行自动分类，以解决标签缺失的问题，从而加快开发流程。


<details>
  <summary>Details</summary>
Motivation: GitHub上许多开源仓库的问题缺乏规范的标签，这影响了开发效率。通过自动分类问题，可以优化问题解决流程。

Method: 分析了GitHub上著名的开源仓库，并使用ML和DNN模型对问题进行分类，标签包括API、文档、增强等常见类别。

Result: 研究表明，DNN模型在问题分类任务中表现优于其他方法。

Conclusion: 自动分类GitHub问题可以有效提升开发效率，DNN模型是实现这一目标的有效工具。

Abstract: GitHub is the most widely used platform for software maintenance in the
open-source community. Developers report issues on GitHub from time to time
while facing difficulties. Having labels on those issues can help developers
easily address those issues with prior knowledge of labels. However, most of
the GitHub repositories do not maintain regular labeling for the issues. The
goal of this work is to classify issues in the open-source community using ML
\& DNN models. There are thousands of open-source repositories on GitHub. Some
of the repositories label their issues properly whereas some of them do not.
When issues are pre-labeled, the problem-solving process and the immediate
assignment of corresponding personnel are facilitated for the team, thereby
expediting the development process. In this work, we conducted an analysis of
prominent GitHub open-source repositories. We classified the issues in some
common labels which are: API, Documentation, Enhancement, Question, Easy,
Help-wanted, Dependency, CI, Waiting for OP's response, Test, Bug, etc. Our
study shows that DNN models outperf

</details>


### [7] [SESR-Eval: Dataset for Evaluating LLMs in the Title-Abstract Screening of Systematic Reviews](https://arxiv.org/abs/2507.19027)
*Aleksi Huotala,Miikka Kuutila,Mika Mäntylä*

Main category: cs.SE

TL;DR: 论文提出了一个名为SESR-Eval的基准数据集，用于评估大语言模型（LLMs）在软件工程系统综述标题-摘要筛选中的表现，发现LLMs性能差异不大，但成本较低，目前不建议自动化使用。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在系统综述标题-摘要筛选中的性能，并为其在软件工程中的应用提供依据。

Method: 从169个系统综述研究中选择24个构建数据集，使用9种LLMs进行基准测试。

Result: SESR-Eval数据集包含34,528个标记研究，LLMs表现相似，但准确性差异较大，成本低于40美元/研究。

Conclusion: LLMs目前不推荐用于自动化筛选，未来将研究影响性能的因素。

Abstract: Background: The use of large language models (LLMs) in the title-abstract
screening process of systematic reviews (SRs) has shown promising results, but
suffers from limited performance evaluation. Aims: Create a benchmark dataset
to evaluate the performance of LLMs in the title-abstract screening process of
SRs. Provide evidence whether using LLMs in title-abstract screening in
software engineering is advisable. Method: We start with 169 SR research
artifacts and find 24 of those to be suitable for inclusion in the dataset.
Using the dataset we benchmark title-abstract screening using 9 LLMs. Results:
We present the SESR-Eval (Software Engineering Systematic Review Evaluation)
dataset containing 34,528 labeled primary studies, sourced from 24 secondary
studies published in software engineering (SE) journals. Most LLMs performed
similarly and the differences in screening accuracy between secondary studies
are greater than differences between LLMs. The cost of using an LLM is
relatively low - less than $40 per secondary study even for the most expensive
model. Conclusions: Our benchmark enables monitoring AI performance in the
screening task of SRs in software engineering. At present, LLMs are not yet
recommended for automating the title-abstract screening process, since accuracy
varies widely across secondary studies, and no LLM managed a high recall with
reasonable precision. In future, we plan to investigate factors that influence
LLM screening performance between studies.

</details>


### [8] [Exploring the Use of LLMs for Requirements Specification in an IT Consulting Company](https://arxiv.org/abs/2507.19113)
*Liliana Pasquale,Azzurra Ragone,Emanuele Piemontese,Armin Amiri Darban*

Main category: cs.SE

TL;DR: 使用大型语言模型（LLM）自动化需求规范生成，减少时间和人力，但需人工修订。


<details>
  <summary>Details</summary>
Motivation: 需求规范生成过程繁琐且耗时，知识分散于多种来源。

Method: 利用LLM生成Epic FDS和用户故事，并与人类分析师生成的结果进行比较。

Result: LLM可自动化需求规范，但质量依赖输入且需人工修订。

Conclusion: 建议LLM作为起草工具，人类分析师提供关键监督，实现高质量需求工程文档。

Abstract: In practice, requirements specification remains a critical challenge. The
knowledge necessary to generate a specification can often be fragmented across
diverse sources (e.g., meeting minutes, emails, and high-level product
descriptions), making the process cumbersome and time-consuming. In this paper,
we report our experience using large language models (LLMs) in an IT consulting
company to automate the requirements specification process. In this company,
requirements are specified using a Functional Design Specification (FDS), a
document that outlines the functional requirements and features of a system,
application, or process. We provide LLMs with a summary of the requirements
elicitation documents and FDS templates, prompting them to generate Epic FDS
(including high-level product descriptions) and user stories, which are
subsequently compiled into a complete FDS document. We compared the correctness
and quality of the FDS generated by three state-of-the-art LLMs against those
produced by human analysts. Our results show that LLMs can help automate and
standardize the requirements specification, reducing time and human effort.
However, the quality of LLM-generated FDS highly depends on inputs and often
requires human revision. Thus, we advocate for a synergistic approach in which
an LLM serves as an effective drafting tool while human analysts provide the
critical contextual and technical oversight necessary for high-quality
requirements engineering (RE) documentation.

</details>


### [9] [Automated Code Review Using Large Language Models at Ericsson: An Experience Report](https://arxiv.org/abs/2507.19115)
*Shweta Ramesh,Joy Bose,Hamender Singh,A K Raghavan,Sujoy Roychowdhury,Giriprasad Sridhara,Nishrith Saini,Ricardo Britto*

Main category: cs.SE

TL;DR: 论文探讨了利用大型语言模型（LLMs）和静态程序分析自动化代码审查的经验，旨在减轻开发者的认知负担。


<details>
  <summary>Details</summary>
Motivation: 代码审查是保证软件质量的重要手段，但依赖经验丰富的开发者，且耗时。自动化代码审查可以缓解这一问题。

Method: 开发了一个基于LLMs和静态程序分析的轻量级工具，并进行了初步实验。

Result: 实验结果显示工具表现令人鼓舞。

Conclusion: 自动化代码审查工具有潜力提升开发效率，减轻开发者负担。

Abstract: Code review is one of the primary means of assuring the quality of released
software along with testing and static analysis. However, code review requires
experienced developers who may not always have the time to perform an in-depth
review of code. Thus, automating code review can help alleviate the cognitive
burden on experienced software developers allowing them to focus on their
primary activities of writing code to add new features and fix bugs. In this
paper, we describe our experience in using Large Language Models towards
automating the code review process in Ericsson. We describe the development of
a lightweight tool using LLMs and static program analysis. We then describe our
preliminary experiments with experienced developers in evaluating our code
review tool and the encouraging results.

</details>


### [10] [Fine-Tuning Multilingual Language Models for Code Review: An Empirical Study on Industrial C# Projects](https://arxiv.org/abs/2507.19271)
*Igli Begolli,Meltem Aksoy,Daniel Neider*

Main category: cs.SE

TL;DR: 研究评估了单语言微调对开源语言模型在代码审查任务中的性能影响，发现其优于多语言基线，但人类审查员在复杂任务中仍更优。


<details>
  <summary>Details</summary>
Motivation: 代码审查对软件质量至关重要，但耗时且认知负担重，语言模型为自动化审查任务提供了新途径。

Method: 对三种模型（CodeReviewer、CodeLlama-7B、DeepSeek-R1-Distill）进行单语言微调，使用C#数据集，并与ASAT和人类审查员对比。

Result: 单语言微调提高了模型的准确性和相关性，但人类在语义复杂任务中表现更优。

Conclusion: 语言对齐和任务特定适配对优化语言模型在自动化代码审查中至关重要。

Abstract: Code review is essential for maintaining software quality but often
time-consuming and cognitively demanding, especially in industrial
environments. Recent advancements in language models (LMs) have opened new
avenues for automating core review tasks. This study presents the empirical
evaluation of monolingual fine-tuning on the performance of open-source LMs
across three key automated code review tasks: Code Change Quality Estimation,
Review Comment Generation, and Code Refinement. We fine-tuned three distinct
models, CodeReviewer, CodeLlama-7B, and DeepSeek-R1-Distill, on a C\# specific
dataset combining public benchmarks with industrial repositories. Our study
investigates how different configurations of programming languages and natural
languages in the training data affect LM performance, particularly in comment
generation. Additionally, we benchmark the fine-tuned models against an
automated software analysis tool (ASAT) and human reviewers to evaluate their
practical utility in real-world settings. Our results show that monolingual
fine-tuning improves model accuracy and relevance compared to multilingual
baselines. While LMs can effectively support code review workflows, especially
for routine or repetitive tasks, human reviewers remain superior in handling
semantically complex or context-sensitive changes. Our findings highlight the
importance of language alignment and task-specific adaptation in optimizing LMs
for automated code review.

</details>


### [11] [Mut4All: Fuzzing Compilers via LLM-Synthesized Mutators Learned from Bug Reports](https://arxiv.org/abs/2507.19275)
*Bo Wang,Pengyang Wang,Chong Chen,Qi Sun,Jieke Shi,Chengran Yang,Ming Deng,Youfang Lin,Zhou Yang,David Lo*

Main category: cs.SE

TL;DR: Mut4All是一个全自动、语言无关的框架，利用LLM和编译器知识生成高质量变异器，显著提升模糊测试效果。


<details>
  <summary>Details</summary>
Motivation: 现代语言结构复杂，传统变异器设计依赖人工，难以扩展和跨语言通用。

Method: Mut4All通过三个代理：变异器发明、实现合成和优化，自动化生成变异器。

Result: 处理1000个错误报告，生成722个变异器，成本低，发现96个编译器错误。

Conclusion: Mut4All在独特崩溃检测和覆盖率上优于现有方法，展示了自动化变异器设计的潜力。

Abstract: Mutation-based fuzzing is effective for uncovering compiler bugs, but
designing high-quality mutators for modern languages with complex constructs
(e.g., templates, macros) remains challenging. Existing methods rely heavily on
manual design or human-in-the-loop correction, limiting scalability and
cross-language generalizability.
  We present Mut4All, a fully automated, language-agnostic framework that
synthesizes mutators using Large Language Models (LLMs) and compiler-specific
knowledge from bug reports. It consists of three agents: (1) a mutator
invention agent that identifies mutation targets and generates mutator metadata
using compiler-related insights; (2) a mutator implementation synthesis agent,
fine-tuned to produce initial implementations; and (3) a mutator refinement
agent that verifies and corrects the mutators via unit-test feedback.
  Mut4All processes 1000 bug reports (500 Rust, 500 C++), yielding 319 Rust and
403 C++ mutators at ~$0.08 each via GPT-4o. Our customized fuzzer, using these
mutators, finds 62 bugs in Rust compilers (38 new, 7 fixed) and 34 bugs in C++
compilers (16 new, 1 fixed). Mut4All outperforms existing methods in both
unique crash detection and coverage, ranking first on Rust and second on C++.

</details>


### [12] [ReCatcher: Towards LLMs Regression Testing for Code Generation](https://arxiv.org/abs/2507.19390)
*Altaf Allah Abbassi,Leuson Da Silva,Amin Nikanjam,Foutse Khomh*

Main category: cs.SE

TL;DR: ReCatcher是一个用于Python代码生成的回归测试框架，通过比较逻辑正确性、静态代码质量和执行性能来评估LLM更新中的回归问题。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的快速更新，可能引入代码质量和性能的回归问题，需要系统化的评估工具。

Method: ReCatcher通过三个维度（逻辑正确性、静态代码质量和执行性能）比较两个LLM（通常是当前模型和候选更新）。

Result: 评估显示，不同更新场景（如微调、合并和新模型发布）会引入不同程度的回归问题，例如语法错误增加12%，正确性下降18%。

Conclusion: ReCatcher在逻辑和性能方面优于基线方法，强调了在采用新模型前进行系统回归评估的重要性。

Abstract: Large Language Models (LLMs) for code generation evolve rapidly through
fine-tuning, merging, or new model releases. However, such updates can
introduce regressions, not only in correctness but also in code quality and
performance. To address this, we present ReCatcher, a regression testing
framework for Python code generation. ReCatcher systematically compares two
LLMs, typically a current model and a candidate update, across three
dimensions: logical correctness, static code quality, and execution
performance. We apply ReCatcher to assess regressions across three update
scenarios, fine-tuning, merging, and model release, using CodeLlama,
DeepSeek-Coder, and GPT-4o. Our evaluation shows that fine-tuning with
cross-language datasets increases syntax errors by up to 12%. Merging with
general-purpose models like Llama2 leads to regressions in correctness by up to
18%. GPT-4o introduces regressions of up to 50% in handling missing imports
compared to GPT-3.5-turbo, while GPT-4o-mini suffers up to 80% performance
degradation in execution time versus GPT-4o. Overall, logical correctness,
performance, and error handling (e.g., syntax errors and missing imports) are
the most regression-prone areas. Comparing ReCatcher with baseline solutions,
it presents better and consistent accuracy across logical and performance
aspects. ReCatcher highlights the importance of systematic regression
evaluation before adopting new models, while assisting researchers and
practitioners in making more informed update decisions.

</details>


### [13] [SDVDiag: A Modular Platform for the Diagnosis of Connected Vehicle Functions](https://arxiv.org/abs/2507.19403)
*Matthias Weiß,Falk Dettinger,Michael Weyrich*

Main category: cs.SE

TL;DR: SDVDiag是一个用于自动化诊断联网车辆功能的可扩展平台，通过动态图分析和异常检测快速定位故障根源。


<details>
  <summary>Details</summary>
Motivation: 联网车辆的高可靠性和可用性需求要求快速解决故障，但复杂的云/边缘架构和依赖关系使得手动分析不可行。

Method: SDVDiag平台支持从数据收集到根因追踪的完整流程，通过动态图更新和异常监控实现自适应诊断。

Result: 在5G测试环境中，SDVDiag能够可靠检测注入的故障，减少停机时间。

Conclusion: SDVDiag为联网车辆提供了一种高效的自动化故障诊断解决方案，具有实际应用潜力。

Abstract: Connected and software-defined vehicles promise to offer a broad range of
services and advanced functions to customers, aiming to increase passenger
comfort and support autonomous driving capabilities. Due to the high
reliability and availability requirements of connected vehicles, it is crucial
to resolve any occurring failures quickly. To achieve this however, a complex
cloud/edge architecture with a mesh of dependencies must be navigated to
diagnose the responsible root cause. As such, manual analyses become unfeasible
since they would significantly delay the troubleshooting.
  To address this challenge, this paper presents SDVDiag, an extensible
platform for the automated diagnosis of connected vehicle functions. The
platform enables the creation of pipelines that cover all steps from initial
data collection to the tracing of potential root causes. In addition, SDVDiag
supports self-adaptive behavior by the ability to exchange modules at runtime.
Dependencies between functions are detected and continuously updated, resulting
in a dynamic graph view of the system. In addition, vital system metrics are
monitored for anomalies. Whenever an incident is investigated, a snapshot of
the graph is taken and augmented by relevant anomalies. Finally, the analysis
is performed by traversing the graph and creating a ranking of the most likely
causes.
  To evaluate the platform, it is deployed inside an 5G test fleet environment
for connected vehicle functions. The results show that injected faults can be
detected reliably. As such, the platform offers the potential to gain new
insights and reduce downtime by identifying problems and their causes at an
early stage.

</details>


### [14] [Resolving Build Conflicts via Example-Based and Rule-Based Program Transformations](https://arxiv.org/abs/2507.19432)
*Sheikh Shadab Towqir,Fei He,Todd Mytkowicz,Na Meng*

Main category: cs.SE

TL;DR: BUCOR是一个新的构建冲突解决工具，结合了基于示例和基于规则的策略，有效解决了合并冲突。


<details>
  <summary>Details</summary>
Motivation: 合并冲突（包括文本冲突和构建测试冲突）会降低软件质量和开发效率，现有工具对某些冲突（如方法移除）支持不足。

Method: BUCOR通过比较基础、左、右三个版本检测冲突，并采用基于示例（BUCOR-E）和基于规则（BUCOR-R）的策略解决冲突。

Result: 在88个真实构建冲突中，BUCOR为65个案例生成至少一个解决方案，并正确解决了43个冲突。

Conclusion: BUCOR的混合策略（结合上下文感知学习和规则）有效解决冲突，为未来更智能的合并工具提供了方向。

Abstract: Merge conflicts often arise when developers integrate changes from different
software branches. The conflicts can result from overlapping edits in programs
(i.e., textual conflicts) or cause build and test errors (i.e., build and test
conflicts). They degrade software quality and hinder programmer productivity.
While several tools detect build conflicts, few offer meaningful support for
resolving cases like those caused by method removal. To overcome limitations of
existing tools, we introduce BUCOR (Build Conflict Resolver), a new conflict
resolver. BUCOR first detects conflicts by comparing three versions related to
a merging scenario: base b, left l, and right r. To resolve conflicts, it
employs two complementary strategies: example-based transformation (BUCOR-E)
and rule-based transformation (BUCOR-R). BUCOR-R applies predefined rules to
handle common, well-understood conflicts. BUCOR-E mines branch versions (l and
r) for exemplar edits applied to fix related build errors. From these examples,
it infers and generalizes program transformation patterns to resolve more
complex conflicts.
  We evaluated BUCOR on 88 real-world build conflicts spanning 21 distinct
conflict types. BUCOR generated at least one solution for 65 cases and
correctly resolved 43 conflicts. We observed that this hybrid
approach--combining context-aware, example-based learning with structured,
rule-based resolution--can effectively help resolve conflicts. Our research
sheds light on future directions for more intelligent and automated merge
tools.

</details>


### [15] [An OpenSource CI/CD Pipeline for Variant-Rich Software-Defined Vehicles](https://arxiv.org/abs/2507.19446)
*Matthias Weiß,Anish Navalgund,Johannes Stümpfle,Falk Dettinger,Michael Weyrich*

Main category: cs.SE

TL;DR: 本文提出了一种针对软件定义车辆（SDV）的开源CI/CD流水线，通过容器化工具实现标准化、可移植和可扩展的生态系统，支持OTA更新和AI模型部署。


<details>
  <summary>Details</summary>
Motivation: 由于SDV的软件版本和变体数量不断增加，且缺乏统一的集成环境，需要一种动态编排功能的方法来确保异构系统的可靠运行。

Method: 采用容器化开源工具构建自动化CI/CD流水线，包括构建、测试和部署阶段，并开发定制OTA中间件以支持软件更新和回滚。

Result: 在自动代客泊车（AVP）场景中验证了流水线的有效性，实现了无缝OTA更新、正确变体选择和跨目标编排。

Conclusion: 该流水线为SDV的软件变体和OTA更新管理提供了可扩展且高效的解决方案，推动了未来移动技术的发展。

Abstract: Software-defined vehicles (SDVs) offer a wide range of connected
functionalities, including enhanced driving behavior and fleet management.
These features are continuously updated via over-the-air (OTA) mechanisms,
resulting in a growing number of software versions and variants due to the
diversity of vehicles, cloud/edge environments, and stakeholders involved. The
lack of a unified integration environment further complicates development, as
connected mobility solutions are often built in isolation. To ensure reliable
operations across heterogeneous systems, a dynamic orchestration of functions
that considers hardware and software variability is essential. This paper
presents an open-source CI/CD pipeline tailored for SDVs. It automates the
build, test, and deployment phases using a combination of containerized
open-source tools, creating a standardized, portable, and scalable ecosystem
accessible to all stakeholders. Additionally, a custom OTA middleware
distributes software updates and supports rollbacks across vehicles and backend
services. Update variants are derived based on deployment target dependencies
and hardware configurations. The pipeline also supports continuous development
and deployment of AI models for autonomous driving features. Its effectiveness
is evaluated using an automated valet parking (AVP) scenario involving
TurtleBots and a coordinating backend server. Two object detection variants are
developed and deployed to match hardware-specific requirements. Results
demonstrate seamless OTA updates, correct variant selection, and successful
orchestration across all targets. Overall, the proposed pipeline provides a
scalable and efficient solution for managing software variants and OTA updates
in SDVs, contributing to the advancement of future mobility technologies.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [16] [Bridging Cloud Convenience and Protocol Transparency: A Hybrid Architecture for Ethereum Node Operations on Amazon Managed Blockchain](https://arxiv.org/abs/2507.18774)
*S M Mostaq Hossain,Amani Altarawneh,Maanak Gupta*

Main category: cs.CR

TL;DR: 论文提出了一种混合服务导向架构，用于在亚马逊托管区块链（AMB）上部署和监控以太坊全节点，结合了EC2的可观测性、IAM安全策略和AWS CDK自动化，实现了高性能和透明性。


<details>
  <summary>Details</summary>
Motivation: 随着区块链技术在企业和研究领域的广泛应用，对安全、可扩展且性能透明的节点基础设施的需求日益迫切。自托管以太坊节点虽提供操作控制，但缺乏弹性且维护复杂。

Method: 采用混合架构，结合AMB与EC2的可观测性工具、IAM安全策略和AWS CDK自动化，通过Web3.py和JSON-RPC收集实时数据，并通过CloudWatch进行监控。

Result: 架构支持超过1000个实时数据点的收集（如gas利用率、交易延迟等），实现了性能跟踪和异常检测，同时保持了托管服务的操作简便性。

Conclusion: 该架构在AMB上实现了首个可重复、性能监测的以太坊部署，适用于研究和生产环境，兼具安全性和透明性。

Abstract: As blockchain technologies are increasingly adopted in enterprise and
research domains, the need for secure, scalable, and performance-transparent
node infrastructure has become critical. While self-hosted Ethereum nodes offer
operational control, they often lack elasticity and require complex
maintenance. This paper presents a hybrid, service-oriented architecture for
deploying and monitoring Ethereum full nodes using Amazon Managed Blockchain
(AMB), integrated with EC2-based observability, IAM-enforced security policies,
and reproducible automation via the AWS Cloud Development Kit. Our architecture
supports end-to-end observability through custom EC2 scripts leveraging Web3.py
and JSON-RPC, collecting over 1,000 real-time data points-including gas
utilization, transaction inclusion latency, and mempool dynamics. These metrics
are visualized and monitored through AWS CloudWatch, enabling service-level
performance tracking and anomaly detection. This cloud-native framework
restores low-level observability lost in managed environments while maintaining
the operational simplicity of managed services. By bridging the simplicity of
AMB with the transparency required for protocol research and enterprise
monitoring, this work delivers one of the first reproducible,
performance-instrumented Ethereum deployments on AMB. The proposed hybrid
architecture enables secure, observable, and reproducible Ethereum node
operations in cloud environments, suitable for both research and production
use.

</details>


### [17] [Resolving Indirect Calls in Binary Code via Cross-Reference Augmented Graph Neural Networks](https://arxiv.org/abs/2507.18801)
*Haotian Zhang,Kun Liu,Cristian Garces,Chenke Luo,Yu Lei,Jiang Ming*

Main category: cs.CR

TL;DR: NeuCall使用图神经网络解决二进制代码中间接调用目标解析问题，通过增强控制流图和高质量训练对提升准确性。


<details>
  <summary>Details</summary>
Motivation: 二进制代码分析中，间接调用目标解析是长期挑战，影响静态分析的完整性。现有方法准确性和可扩展性不足，机器学习方法受限于低质量训练对和代码表示。

Method: NeuCall通过增强控制流图（包含数据和代码交叉引用）和编译器级类型分析生成高质量训练对，设计图神经网络模型预测目标。

Result: 在x86_64架构的真实二进制代码上，NeuCall的F1分数达95.2%，优于现有ML方法。

Conclusion: NeuCall能构建精确的过程间控制流图，推动二进制分析和安全应用发展。

Abstract: Binary code analysis is essential in scenarios where source code is
unavailable, with extensive applications across various security domains.
However, accurately resolving indirect call targets remains a longstanding
challenge in maintaining the integrity of static analysis in binary code. This
difficulty arises because the operand of a call instruction (e.g., call rax)
remains unknown until runtime, resulting in an incomplete inter-procedural
control flow graph (CFG). Previous approaches have struggled with low accuracy
and limited scalability. To address these limitations, recent work has
increasingly turned to machine learning (ML) to enhance analysis. However, this
ML-driven approach faces two significant obstacles: low-quality callsite-callee
training pairs and inadequate binary code representation, both of which
undermine the accuracy of ML models. In this paper, we introduce NeuCall, a
novel approach for resolving indirect calls using graph neural networks.
Existing ML models in this area often overlook key elements such as data and
code cross-references, which are essential for understanding a program's
control flow. In contrast, NeuCall augments CFGs with cross-references,
preserving rich semantic information. Additionally, we leverage advanced
compiler-level type analysis to generate high-quality callsite-callee training
pairs, enhancing model precision and reliability. We further design a graph
neural model that leverages augmented CFGs and relational graph convolutions
for accurate target prediction. Evaluated against real-world binaries from
GitHub and the Arch User Repository on x86_64 architecture, NeuCall achieves an
F1 score of 95.2%, outperforming state-of-the-art ML-based approaches. These
results highlight NeuCall's effectiveness in building precise inter-procedural
CFGs and its potential to advance downstream binary analysis and security
applications.

</details>


### [18] [How to Copy-Protect Malleable-Puncturable Cryptographic Functionalities Under Arbitrary Challenge Distributions](https://arxiv.org/abs/2507.19032)
*Alper Çakan,Vipul Goyal*

Main category: cs.CR

TL;DR: 本文提出了一种新的量子复制保护方案，扩展了可保护的功能类别，适用于可延展可穿刺的密码方案，并提升了安全性。


<details>
  <summary>Details</summary>
Motivation: 现有量子复制保护方案仅适用于特定类别的密码方案，限制了其应用范围。本文旨在扩展可保护的方案类别，并提升安全性。

Method: 定义了一类可延展可穿刺的密码方案，并设计了一种新的量子复制保护方案，适用于此类方案。

Result: 新方案能够保护更广泛的密码方案，且安全性更高，适用于任意高最小熵的挑战分布。

Conclusion: 本文扩展了量子复制保护的应用范围，为更广泛的密码方案提供了安全的复制保护方法。

Abstract: A quantum copy-protection scheme (Aaronson, CCC 2009) encodes a functionality
into a quantum state such that given this state, no efficient adversary can
create two (possibly entangled) quantum states that are both capable of running
the functionality. There has been a recent line of works on constructing
provably-secure copy-protection schemes for general classes of schemes in the
plain model, and most recently the recent work of \c{C}akan and Goyal (IACR
Eprint, 2025) showed how to copy-protect all cryptographically puncturable
schemes with pseudorandom puncturing points. In this work, we show how to
copy-protect even a larger class of schemes. We define a class of cryptographic
schemes called malleable-puncturable schemes where the only requirement is that
one can create a circuit that is capable of answering inputs at points that are
unrelated to the challenge in the security game but does not help the adversary
answer inputs related to the challenge. This is a flexible generalization of
puncturable schemes, and can capture a wide range of primitives that was not
known how to copy-protect prior to our work. Going further, we show that our
scheme is secure against arbitrary high min-entropy challenge distributions
whereas previous work has only considered schemes that are punctured at
pseudorandom points.

</details>


### [19] [Virtual local area network over HTTP for launching an insider attack](https://arxiv.org/abs/2507.19055)
*Yuksel Arslan*

Main category: cs.CR

TL;DR: 论文展示了如何通过内部攻击将局域网（LAN）隐蔽地暴露在互联网上，利用未使用的次要IP地址和HTTP协议绕过现有安全机制。


<details>
  <summary>Details</summary>
Motivation: 现代生活中计算机和网络的重要性日益增加，数据安全至关重要。现有安全措施主要针对外部威胁，而内部攻击的防护相对薄弱。

Method: 通过利用LAN中未使用的次要IP地址和HTTP协议，展示外部机器如何绕过防火墙和IDS等安全机制访问LAN。

Result: 揭示了即使有强大的外部防护措施，内部攻击仍能成功暴露LAN的漏洞。

Conclusion: 内部攻击对数据安全构成重大威胁，现有安全机制需加强内部防护。

Abstract: Computers and computer networks have become integral to virtually every
aspect of modern life, with the Internet playing an indispensable role.
Organizations, businesses, and individuals now store vast amounts of
proprietary, confidential, and personal data digitally. As such, ensuring the
security of this data from unauthorized access is critical. Common security
measures, such as firewalls, intrusion detection systems (IDS), intrusion
prevention systems (IPS), and antivirus software, are constantly evolving to
safeguard computer systems and networks. However, these tools primarily focus
on defending against external threats, leaving systems vulnerable to insider
attacks. Security solutions designed to mitigate risks originating from within
the organization are relatively limited and often ineffective. This paper
demonstrates how a Local Area Network (LAN) can be covertly exposed to the
Internet via an insider attack. Specifically, it illustrates how an external
machine can gain access to a LAN by exploiting an unused secondary IP address
of the attacked LAN, effectively bypassing existing security mechanisms by also
exploiting Hyper Text Transfer Protocol (HTTP). Despite the presence of robust
external protections, such as firewalls and IDS, this form of insider attack
reveals significant vulnerabilities in the way internal threats are addressed.

</details>


### [20] [PurpCode: Reasoning for Safer Code Generation](https://arxiv.org/abs/2507.19060)
*Jiawei Liu,Nirav Diwan,Zhe Wang,Haoyu Zhai,Xiaona Zhou,Kiet A. Nguyen,Tianjiao Yu,Muntasir Wahed,Yinlin Deng,Hadjer Benkraouda,Yuxiang Wei,Lingming Zhang,Ismini Lourentzou,Gang Wang*

Main category: cs.CR

TL;DR: PurpCode是一种后训练方法，用于训练安全的代码推理模型，生成安全代码并防御恶意网络活动。通过规则学习和强化学习两阶段训练，结合红队测试数据，开发了PurpCode-32B模型，表现出卓越的网络安全性和实用性。


<details>
  <summary>Details</summary>
Motivation: 当前代码生成模型在网络安全方面存在不足，容易生成不安全代码或助长恶意活动。PurpCode旨在填补这一空白，提供一种安全的代码推理模型。

Method: PurpCode采用两阶段训练：1) 规则学习，明确教导模型引用网络安全规则生成无漏洞代码；2) 强化学习，通过多目标奖励机制优化安全性和实用性。结合红队测试数据增强训练。

Result: 开发的PurpCode-32B模型在网络安全方面表现最优，同时减少了过度拒绝率，保持了代码生成和通用安全知识的实用性。

Conclusion: PurpCode提供了一种有效的后训练方法，显著提升了代码推理模型的网络安全性和实用性，为安全代码生成提供了新思路。

Abstract: We introduce PurpCode, the first post-training recipe for training safe code
reasoning models towards generating secure code and defending against malicious
cyberactivities. PurpCode trains a reasoning model in two stages: (i) Rule
Learning, which explicitly teaches the model to reference cybersafety rules to
generate vulnerability-free code and to avoid facilitating malicious
cyberactivities; and (ii) Reinforcement Learning, which optimizes model safety
and preserves model utility through diverse, multi-objective reward mechanisms.
To empower the training pipelines with comprehensive cybersafety data, we
conduct internal red-teaming to synthesize comprehensive and high-coverage
prompts based on real-world tasks for inducing unsafe cyberactivities in the
model. Based on PurpCode, we develop a reasoning-based coding model, namely
PurpCode-32B, which demonstrates state-of-the-art cybersafety, outperforming
various frontier models. Meanwhile, our alignment method decreases the model
overrefusal rates in both general and cybersafety-specific scenarios, while
preserving model utility in both code generation and common security knowledge.

</details>


### [21] [PrompTrend: Continuous Community-Driven Vulnerability Discovery and Assessment for Large Language Models](https://arxiv.org/abs/2507.19185)
*Tarek Gasmi,Ramzi Guesmi,Mootez Aloui,Jihene Bennaceur*

Main category: cs.CR

TL;DR: PrompTrend系统通过收集和分析在线社区的漏洞数据，揭示高级能力与漏洞增加相关，心理攻击效果优于技术攻击，并强调LLM安全需结合社会技术监测。


<details>
  <summary>Details</summary>
Motivation: 静态基准测试无法捕捉在线社区实验中LLM的漏洞，需动态监测系统。

Method: PrompTrend系统收集漏洞数据，采用多维评分评估，分析198个漏洞和9个商业模型。

Result: 高级能力与漏洞增加相关，心理攻击效果显著，平台动态影响攻击效果，分类准确率达78%。

Conclusion: LLM安全需综合社会技术监测，能力提升未必改善安全，心理攻击是主要威胁。

Abstract: Static benchmarks fail to capture LLM vulnerabilities emerging through
community experimentation in online forums. We present PrompTrend, a system
that collects vulnerability data across platforms and evaluates them using
multidimensional scoring, with an architecture designed for scalable
monitoring. Cross-sectional analysis of 198 vulnerabilities collected from
online communities over a five-month period (January-May 2025) and tested on
nine commercial models reveals that advanced capabilities correlate with
increased vulnerability in some architectures, psychological attacks
significantly outperform technical exploits, and platform dynamics shape attack
effectiveness with measurable model-specific patterns. The PrompTrend
Vulnerability Assessment Framework achieves 78% classification accuracy while
revealing limited cross-model transferability, demonstrating that effective LLM
security requires comprehensive socio-technical monitoring beyond traditional
periodic assessment. Our findings challenge the assumption that capability
advancement improves security and establish community-driven psychological
manipulation as the dominant threat vector for current language models.

</details>


### [22] [On the Security of a Code-Based PIR Scheme](https://arxiv.org/abs/2507.19295)
*Svenja Lage,Hannes Bartz*

Main category: cs.CR

TL;DR: CB-cPIR是一种基于编码理论的PIR方案，但研究发现其存在严重漏洞，安全性降低，且在通信成本上竞争力不足。


<details>
  <summary>Details</summary>
Motivation: 探索基于编码理论的PIR方案，以多样化后量子安全的基础。

Method: 分析CB-cPIR方案的安全性，并与现有PIR方案进行对比。

Result: CB-cPIR存在关键漏洞，安全性降低，通信成本竞争力不足。

Conclusion: 仍需研究基于编码理论的PIR方案，作为基于格方案的替代选择。

Abstract: Private Information Retrieval (PIR) schemes allow clients to retrieve files
from a database without disclosing the requested file's identity to the server.
In the pursuit of post-quantum security, most recent PIR schemes rely on hard
lattice problems. In contrast, the so called CB-cPIR scheme stands out as a
pioneering effort to base PIR schemes on hard problems in coding theory,
thereby contributing significantly to the diversification of security
foundations. However, our research reveals a critical vulnerability in CB-cPIR,
substantially diminishing its security levels. Moreover, a comparative analysis
with state-of-the-art PIR schemes shows that CB-cPIR's advantages are reduced,
making it less competitive in terms of the communication cost. Nevertheless,
our findings highlight the importance of continued research into code-based PIR
schemes, as they have the potential to provide a valuable alternative to
lattice-based approaches.

</details>


### [23] [Empowering IoT Firmware Secure Update with Customization Rights](https://arxiv.org/abs/2507.19367)
*Weihao Chen,Yansong Gao,Boyu Kuang,Jin B. Hong,Yuqing Zhang,Anmin Fu*

Main category: cs.CR

TL;DR: 论文研究了IoT设备固件更新中的模块化定制漏洞，提出了IMUP框架以提升安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有防御措施主要关注整体固件，忽略了模块化定制带来的安全风险，导致攻击面扩大。

Method: 通过分析200台Linux IoT设备，发现五个未记录的漏洞，并提出IMUP框架，结合变色龙哈希、服务器端计算卸载和缓存技术。

Result: IMUP在95%密钥泄露时仍能显著提高攻击成本，服务器生成时间减少2.9倍，设备停机时间减少5.9倍。

Conclusion: 模块化定制增加了安全风险，IMUP有效解决了相关挑战，提升了更新安全性和性能。

Abstract: Firmware updates remain the primary line of defense for IoT devices; however,
the update channel itself has become a well-established attack vector. Existing
defenses mainly focus on securing monolithic firmware images, leaving
module-level customization -a growing user demand-largely unprotected and
insufficiently explored. To address this gap, we conduct a pilot study on the
update workflows of 200 Linux-based IoT devices across 23 vendors, uncovering
five previously undocumented vulnerabilities caused by customization practices.
A broader analysis of update-related CVEs from 2020 to 2024 reveals that over
half originate from customization-induced issues. These findings highlight a
critical yet underexamined reality: as customization increases, so does the
attack surface, while current defenses fail to keep pace. We propose IMUP
(Integrity-Centric Modular Update Platform), the first framework to address two
key challenges: constructing a trustworthy cross-module integrity chain and
scaling update performance under mass customization. IMUP combines three
techniques: per-module chameleon hashing for integrity, server-side
proof-of-work offloading to reduce device overhead, and server-side caching to
reuse module combinations, minimizing rebuild costs. Security analysis shows
that even when 95 percent of secret keys are exposed, forging a valid image
incurs over 300 times the cost of the legitimate server. Experiments on
heterogeneous IoT devices demonstrate that IMUP reduces server-side generation
time by 2.9 times and device downtime by 5.9 times compared to a
package-manager baseline.

</details>


### [24] [Transcript Franking for Encrypted Messaging](https://arxiv.org/abs/2507.19391)
*Armin Namavari,Thomas Ristenpart*

Main category: cs.CR

TL;DR: 论文提出了一种称为“transcript franking”的新协议，用于在端到端加密消息平台中报告多消息内容，填补了现有单消息报告协议的不足。


<details>
  <summary>Details</summary>
Motivation: 现有消息报告协议仅支持单消息报告，而实际应用中需要报告多消息内容，存在安全目标与实践需求之间的差距。

Method: 定义了transcript franking的语法、语义和安全性，并提出了高效的两方和群组消息构造方案。

Result: 提出了transcript franking协议，并证明了其安全性，同时讨论了实际部署的可行性。

Conclusion: transcript franking填补了现有协议的不足，为端到端加密消息平台提供了更实用的多消息报告解决方案。

Abstract: Message franking is an indispensable abuse mitigation tool for end-to-end
encrypted (E2EE) messaging platforms. With it, users who receive harmful
content can securely report that content to platform moderators. However, while
real-world deployments of reporting require the disclosure of multiple
messages, existing treatments of message franking only consider the report of a
single message. As a result, there is a gap between the security goals achieved
by constructions and those needed in practice. Our work introduces transcript
franking, a new type of protocol that allows reporting subsets of conversations
such that moderators can cryptographically verify message causality and
contents. We define syntax, semantics, and security for transcript franking in
two-party and group messaging. We then present efficient constructions for
transcript franking and prove their security. Looking toward deployment
considerations, we provide detailed discussion of how real-world messaging
systems can incorporate our protocols.

</details>


### [25] [Running in CIRCLE? A Simple Benchmark for LLM Code Interpreter Security](https://arxiv.org/abs/2507.19399)
*Gabriel Chua*

Main category: cs.CR

TL;DR: 论文提出了CIRCLE基准测试，用于评估大语言模型（LLM）集成代码解释器时的系统级网络安全风险，发现商业模型存在显著漏洞。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs集成代码解释器，其功能增强但也带来新的网络安全威胁，需系统性评估这些风险。

Method: 提出CIRCLE基准测试，包含1,260个针对CPU、内存和磁盘资源耗尽的提示，并自动化评估LLMs的响应和代码执行情况。

Result: 评估7个商业模型发现显著漏洞，间接提示尤其削弱模型防御，不同模型间差异明显。

Conclusion: 需制定网络安全基准、缓解工具和行业标准，以安全部署LLM解释器集成。

Abstract: As large language models (LLMs) increasingly integrate native code
interpreters, they enable powerful real-time execution capabilities,
substantially expanding their utility. However, such integrations introduce
potential system-level cybersecurity threats, fundamentally different from
prompt-based vulnerabilities. To systematically evaluate these
interpreter-specific risks, we propose CIRCLE (Code-Interpreter Resilience
Check for LLM Exploits), a simple benchmark comprising 1,260 prompts targeting
CPU, memory, and disk resource exhaustion. Each risk category includes
explicitly malicious ("direct") and plausibly benign ("indirect") prompt
variants. Our automated evaluation framework assesses not only whether LLMs
refuse or generates risky code, but also executes the generated code within the
interpreter environment to evaluate code correctness, simplifications made by
the LLM to make the code safe, or execution timeouts. Evaluating 7 commercially
available models from OpenAI and Google, we uncover significant and
inconsistent vulnerabilities. For instance, evaluations show substantial
disparities even within providers - OpenAI's o4-mini correctly refuses risky
requests at 7.1%, notably higher rates compared to GPT-4.1 at 0.5%. Results
particularly underscore that indirect, socially-engineered prompts
substantially weaken model defenses. This highlights an urgent need for
interpreter-specific cybersecurity benchmarks, dedicated mitigation tools
(e.g., guardrails), and clear industry standards to guide safe and responsible
deployment of LLM interpreter integrations. The benchmark dataset and
evaluation code are publicly released to foster further research.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [26] [Initial Steps in Integrating Large Reasoning and Action Models for Service Composition](https://arxiv.org/abs/2507.18775)
*Ilche Georgievski,Marco Aiello*

Main category: cs.AI

TL;DR: 论文提出结合大型推理模型（LRM）和大型动作模型（LAM）的框架，以解决服务组合中的语义推理和执行问题。


<details>
  <summary>Details</summary>
Motivation: 服务组合在构建自适应智能系统中面临推理能力有限和执行机制脆弱的挑战。

Method: 提出集成LRM和LAM的架构框架，LRM负责语义推理，LAM负责动态执行。

Result: 该框架能自动化服务组合，弥合意图与执行之间的差距。

Conclusion: LRM-LAM集成有望将服务组合转变为基于自然语言意图的自动化、用户友好过程。

Abstract: Service composition remains a central challenge in building adaptive and
intelligent software systems, often constrained by limited reasoning
capabilities or brittle execution mechanisms. This paper explores the
integration of two emerging paradigms enabled by large language models: Large
Reasoning Models (LRMs) and Large Action Models (LAMs). We argue that LRMs
address the challenges of semantic reasoning and ecosystem complexity while
LAMs excel in dynamic action execution and system interoperability. However,
each paradigm has complementary limitations - LRMs lack grounded action
capabilities, and LAMs often struggle with deep reasoning. We propose an
integrated LRM-LAM architectural framework as a promising direction for
advancing automated service composition. Such a system can reason about service
requirements and constraints while dynamically executing workflows, thus
bridging the gap between intention and execution. This integration has the
potential to transform service composition into a fully automated,
user-friendly process driven by high-level natural language intent.

</details>


### [27] [Simulation-Driven Reinforcement Learning in Queuing Network Routing Optimization](https://arxiv.org/abs/2507.18795)
*Fatima Al-Ani,Molly Wang,Jevon Charles,Aaron Ong,Joshua Forday,Vinayak Modi*

Main category: cs.AI

TL;DR: 提出了一种基于Dyna-DDPG的强化学习框架，用于优化复杂排队网络的路径决策，适用于制造和通信领域。


<details>
  <summary>Details</summary>
Motivation: 传统排队方法在动态和不确定环境中表现不佳，因此需要一种更鲁棒的解决方案。

Method: 结合Deep Deterministic Policy Gradient（DDPG）和Dyna-style规划（Dyna-DDPG），并开发了灵活的仿真环境。

Result: 实验表明，该框架能快速学习有效的路径策略，在干扰下保持鲁棒性，并能扩展到更大网络。

Conclusion: 该框架不仅性能优越，还注重软件工程实践，确保可重现性和可维护性，适用于实际部署。

Abstract: This study focuses on the development of a simulation-driven reinforcement
learning (RL) framework for optimizing routing decisions in complex queueing
network systems, with a particular emphasis on manufacturing and communication
applications. Recognizing the limitations of traditional queueing methods,
which often struggle with dynamic, uncertain environments, we propose a robust
RL approach leveraging Deep Deterministic Policy Gradient (DDPG) combined with
Dyna-style planning (Dyna-DDPG). The framework includes a flexible and
configurable simulation environment capable of modeling diverse queueing
scenarios, disruptions, and unpredictable conditions. Our enhanced Dyna-DDPG
implementation incorporates separate predictive models for next-state
transitions and rewards, significantly improving stability and sample
efficiency. Comprehensive experiments and rigorous evaluations demonstrate the
framework's capability to rapidly learn effective routing policies that
maintain robust performance under disruptions and scale effectively to larger
network sizes. Additionally, we highlight strong software engineering practices
employed to ensure reproducibility and maintainability of the framework,
enabling practical deployment in real-world scenarios.

</details>


### [28] [A Neuroscience-Inspired Dual-Process Model of Compositional Generalization](https://arxiv.org/abs/2507.18868)
*Alex Noviello,Claas Beger,Jacob Groner,Kevin Ellis,Weinan Sun*

Main category: cs.AI

TL;DR: MIRAGE框架通过模拟人脑HPC-PFC交互机制，实现了系统性组合泛化，在SCAN基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决AI系统在组合任务中系统性泛化的核心挑战，借鉴人脑海马体与前额叶皮层的协作机制。

Method: MIRAGE包含两个模块：基于Transformer的神经分解器和模式引擎，分别模拟直觉性模式识别和逻辑推理。

Result: 在SCAN基准测试中达到>99%准确率，仅需1.19M参数。消融实验验证了模式质量和迭代优化的关键作用。

Conclusion: MIRAGE通过显式管理模式结构和迭代优化，实现了系统性组合泛化，为AI系统提供了新思路。

Abstract: Systematic compositional generalization - constructing and understanding
novel combinations of known building blocks - remains a core challenge for AI
systems. Human cognition achieves this flexibility via the interplay of the
hippocampus (HPC) and prefrontal cortex (PFC): the hippocampus rapidly encodes
episodes, and the prefrontal cortex consolidates them into reusable schemas for
reasoning. Drawing on these insights, we present MIRAGE (Meta-Inference with
Rules and Abstractions from Generalized Experience), a framework that achieves
systematic generalization on compositional tasks. MIRAGE has two interacting
modules mirroring the brain's deliberative HPC-PFC loop and intuitive
neocortical pattern recognition. (1) The meta-trained Transformer Neural
Decomposer, paralleling neocortical "System 1" computation, is trained on a
task-agnostic stream of randomly sampled compositional grammars and applies one
decomposition step per pass, with successive passes iteratively refining the
sequence representation. (2) The Schema Engine, analogous to the HPC-PFC
"System 2" loop, dynamically extracts, ranks, and applies reusable schemas,
storing variable bindings in episodic memory and expanding them when needed. By
explicitly equipping the Transformer component of MIRAGE with actively managed
schematic structures, our model performs systematic compositional operations
through explicit schema application and transformation, relying solely on
frozen weights when solving entirely novel tasks. This approach demonstrates
systematic compositional generalization on the SCAN benchmark, achieving > 99%
accuracy on all task splits with only 1.19M parameters in the transformer
module. Ablation studies confirm that MIRAGE's systematicity critically depends
on the quality of extracted schemas and the model's iterative refinement
process.

</details>


### [29] [Success in Humanoid Reinforcement Learning under Partial Observation](https://arxiv.org/abs/2507.18883)
*Wuhao Wang,Zhiyong Chen*

Main category: cs.AI

TL;DR: 首次在部分可观测环境下成功训练人形机器人策略，性能接近全状态访问的先进结果，关键是一种新型历史编码器。


<details>
  <summary>Details</summary>
Motivation: 解决部分可观测性下人形机器人控制策略学习的挑战，尤其是在高维任务中。

Method: 提出一种新型历史编码器，处理固定长度的过去观测序列，集成到无模型算法中。

Result: 策略性能接近全状态基线，仅需原始状态的三分之一到三分之二，且能适应机器人属性变化。

Conclusion: 历史编码器通过重建上下文信息实现稳健决策，为部分可观测环境下的强化学习提供了有效解决方案。

Abstract: Reinforcement learning has been widely applied to robotic control, but
effective policy learning under partial observability remains a major
challenge, especially in high-dimensional tasks like humanoid locomotion. To
date, no prior work has demonstrated stable training of humanoid policies with
incomplete state information in the benchmark Gymnasium Humanoid-v4
environment. The objective in this environment is to walk forward as fast as
possible without falling, with rewards provided for staying upright and moving
forward, and penalties incurred for excessive actions and external contact
forces. This research presents the first successful instance of learning under
partial observability in this environment. The learned policy achieves
performance comparable to state-of-the-art results with full state access,
despite using only one-third to two-thirds of the original states. Moreover,
the policy exhibits adaptability to robot properties, such as variations in
body part masses. The key to this success is a novel history encoder that
processes a fixed-length sequence of past observations in parallel. Integrated
into a standard model-free algorithm, the encoder enables performance on par
with fully observed baselines. We hypothesize that it reconstructs essential
contextual information from recent observations, thereby enabling robust
decision-making.

</details>


### [30] [Towards Improving Long-Tail Entity Predictions in Temporal Knowledge Graphs through Global Similarity and Weighted Sampling](https://arxiv.org/abs/2507.18977)
*Mehrnoosh Mirtaheri,Ryan A. Rossi,Sungchul Kim,Kanak Mahadik,Tong Yu,Xiang Chen,Mohammad Rostami*

Main category: cs.AI

TL;DR: 提出了一种针对时序知识图谱（TKG）的增量训练框架，解决新实体和稀疏连接问题，结合模型无关的增强层和加权采样策略，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 传统TKG补全模型假设训练时可访问整个图谱，忽略了图谱动态演化带来的挑战，如新知识吸收和新实体处理。

Method: 结合模型无关的增强层（基于全局实体相似性）和加权采样策略（侧重稀疏实体边），可增强现有TKG补全方法。

Result: 在两个基准数据集上，方法在总链接预测、归纳链接预测及长尾实体处理上优于现有方法，MRR提升15%。

Conclusion: 该框架有效缓解灾难性遗忘，增强了TKG补全方法的鲁棒性，特别适用于增量训练场景。

Abstract: Temporal Knowledge Graph (TKG) completion models traditionally assume access
to the entire graph during training. This overlooks challenges stemming from
the evolving nature of TKGs, such as: (i) the model's requirement to generalize
and assimilate new knowledge, and (ii) the task of managing new or unseen
entities that often have sparse connections. In this paper, we present an
incremental training framework specifically designed for TKGs, aiming to
address entities that are either not observed during training or have sparse
connections. Our approach combines a model-agnostic enhancement layer with a
weighted sampling strategy, that can be augmented to and improve any existing
TKG completion method. The enhancement layer leverages a broader, global
definition of entity similarity, which moves beyond mere local neighborhood
proximity of GNN-based methods. The weighted sampling strategy employed in
training accentuates edges linked to infrequently occurring entities. We
evaluate our method on two benchmark datasets, and demonstrate that our
framework outperforms existing methods in total link prediction, inductive link
prediction, and in addressing long-tail entities. Notably, our method achieves
a 10\% improvement and a 15\% boost in MRR for these datasets. The results
underscore the potential of our approach in mitigating catastrophic forgetting
and enhancing the robustness of TKG completion methods, especially in an
incremental training context

</details>


### [31] [Fine-Grained Traffic Inference from Road to Lane via Spatio-Temporal Graph Node Generation](https://arxiv.org/abs/2507.19089)
*Shuhao Li,Weidong Yang,Yue Cui,Xiaoxing Liu,Lingkai Meng,Lipeng Ma,Fan Zhang*

Main category: cs.AI

TL;DR: 论文提出了一种名为FRTI的任务，旨在通过有限的道路数据生成更详细的车道级交通信息，并设计了一个两阶段框架RoadDiff来解决该任务。


<details>
  <summary>Details</summary>
Motivation: 获取车道级交通数据是数据驱动模型的关键瓶颈，现有传感器类型和数量有限，且跟踪算法准确性存在问题。

Method: 设计了RoadDiff框架，包括Road-Lane Correlation Autoencoder-Decoder和Lane Diffusion Module，充分利用道路数据的时空依赖性和分布关系。

Result: 在六个不同道路条件的数据集上验证了RoadDiff模型的有效性。

Conclusion: RoadDiff为精确交通管理提供了更节能和经济的解决方案。

Abstract: Fine-grained traffic management and prediction are fundamental to key
applications such as autonomous driving, lane change guidance, and traffic
signal control. However, obtaining lane-level traffic data has become a
critical bottleneck for data-driven models due to limitations in the types and
number of sensors and issues with the accuracy of tracking algorithms. To
address this, we propose the Fine-grained Road Traffic Inference (FRTI) task,
which aims to generate more detailed lane-level traffic information using
limited road data, providing a more energy-efficient and cost-effective
solution for precise traffic management. This task is abstracted as the first
scene of the spatio-temporal graph node generation problem. We designed a
two-stage framework--RoadDiff--to solve the FRTI task. solve the FRTI task.
This framework leverages the Road-Lane Correlation Autoencoder-Decoder and the
Lane Diffusion Module to fully utilize the limited spatio-temporal dependencies
and distribution relationships of road data to accurately infer fine-grained
lane traffic states. Based on existing research, we designed several baseline
models with the potential to solve the FRTI task and conducted extensive
experiments on six datasets representing different road conditions to validate
the effectiveness of the RoadDiff model in addressing the FRTI task. The
relevant datasets and code are available at
https://github.com/ShuhaoLii/RoadDiff.

</details>


### [32] [Pareto-NRPA: A Novel Monte-Carlo Search Algorithm for Multi-Objective Optimization](https://arxiv.org/abs/2507.19109)
*Noé Lallouet,Tristan Cazenave,Cyrille Enderli*

Main category: cs.AI

TL;DR: Pareto-NRPA是一种新的蒙特卡洛算法，用于离散搜索空间的多目标优化问题，扩展了单目标问题的NRPA算法。


<details>
  <summary>Details</summary>
Motivation: 将单目标优化的NRPA算法扩展到多目标优化问题，解决现有算法在收敛性和多样性上的不足。

Method: 采用多策略并行探索解空间，并在搜索的每个层级维护非支配前沿，策略更新基于Pareto前沿的多样性和隔离性。

Result: 在MO-TSPTW问题和神经网络架构搜索任务中，Pareto-NRPA表现优于现有算法，尤其在受限搜索空间中。

Conclusion: Pareto-NRPA是NRPA算法在多目标优化中的首次成功扩展，具有竞争力和潜力。

Abstract: We introduce Pareto-NRPA, a new Monte-Carlo algorithm designed for
multi-objective optimization problems over discrete search spaces. Extending
the Nested Rollout Policy Adaptation (NRPA) algorithm originally formulated for
single-objective problems, Pareto-NRPA generalizes the nested search and policy
update mechanism to multi-objective optimization. The algorithm uses a set of
policies to concurrently explore different regions of the solution space and
maintains non-dominated fronts at each level of search. Policy adaptation is
performed with respect to the diversity and isolation of sequences within the
Pareto front. We benchmark Pareto-NRPA on two classes of problems: a novel
bi-objective variant of the Traveling Salesman Problem with Time Windows
problem (MO-TSPTW), and a neural architecture search task on well-known
benchmarks. Results demonstrate that Pareto-NRPA achieves competitive
performance against state-of-the-art multi-objective algorithms, both in terms
of convergence and diversity of solutions. Particularly, Pareto-NRPA strongly
outperforms state-of-the-art evolutionary multi-objective algorithms on
constrained search spaces. To our knowledge, this work constitutes the first
adaptation of NRPA to the multi-objective setting.

</details>


### [33] [OS-MAP: How Far Can Computer-Using Agents Go in Breadth and Depth?](https://arxiv.org/abs/2507.19132)
*Xuetian Chen,Yinghao Chen,Xinfeng Yuan,Zhuo Peng,Lu Chen,Yuekeng Li,Zhoujia Zhang,Yingqian Huang,Leyan Huang,Jiaqing Liang,Tianbao Xie,Zhiyong Wu,Qiushi Sun,Biqing Qi,Bowen Zhou*

Main category: cs.AI

TL;DR: OS-MAP是一个用于日常计算机自动化任务的基准测试，通过五级自动化分类和需求层次结构评估代理能力，揭示当前代理在高阶任务中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试未能考虑任务异质性和代理能力与实际用户需求的匹配，阻碍了针对性能力开发和研究成果的实际应用。

Method: 提出OS-MAP基准，包含416个任务，按五级自动化分类和需求层次结构组织，评估代理的自动化水平和泛化能力。

Result: 实验表明，即使最先进的代理在涉及感知、推理和协调的高阶任务中表现不佳。

Conclusion: OS-MAP为计算机代理的研究和部署提供了结构化评估框架，揭示了当前技术的局限性，推动未来进步。

Abstract: Computer-using agents have shown strong potential to boost human productivity
and enable new application forms across platforms. While recent advances have
led to usable applications, existing benchmarks fail to account for the
internal task heterogeneity and the corresponding agent capabilities, as well
as their alignment with actual user demands-hindering both targeted capability
development and the reliable transition of research progress into practical
deployment. To bridge the gap, we present OS-MAP, a benchmark for daily
computer-using automation that organizes its 416 realistic tasks across 15
applications along two key dimensions: a five-level taxonomy of automation and
a generalization scope derived from a real-world user demand hierarchy. To
enable fine-grained analysis of required capabilities and alignment with
real-world scenarios, OS-MAP evaluates agents along two dimensions: automation
level across a five-level taxonomy, and generalization scope across a demand
hierarchy. This design captures varying levels of required agent autonomy and
generalization, forming a performance-generalization evaluation matrix for
structured and comprehensive assessment. Experiments show that even
State-of-the-Art agents with VLM backbones struggle with higher-level tasks
involving perception, reasoning, and coordination-highlighting the need for a
deeper understanding of current strengths and limitations to drive the future
progress in computer-using agents research and deployment. All code,
environments, baselines, and data are publicly available at
https://github.com/OS-Copilot/OS-Map.

</details>


### [34] [PhysDrive: A Multimodal Remote Physiological Measurement Dataset for In-vehicle Driver Monitoring](https://arxiv.org/abs/2507.19172)
*Jiyao Wang,Xiao Yang,Qingyong Hu,Jiankai Tang,Can Liu,Dengbo He,Yuntao Wang,Yingcong Chen,Kaishun Wu*

Main category: cs.AI

TL;DR: PhysDrive是一个大规模多模态数据集，用于无接触车内生理监测，解决了现有数据集的局限性，并提供了全面的基准测试和开源代码。


<details>
  <summary>Details</summary>
Motivation: 现有远程生理监测数据集规模小、多样性不足，无法满足真实驾驶场景的需求。

Method: PhysDrive收集了48名驾驶员的多模态数据（RGB、近红外相机、毫米波雷达）和六种同步生理信号，覆盖多种驾驶条件。

Result: 数据集为信号处理和深度学习方法提供了全面基准，并开源了代码。

Conclusion: PhysDrive将成为多模态驾驶员监测和智能座舱系统研究的基础资源。

Abstract: Robust and unobtrusive in-vehicle physiological monitoring is crucial for
ensuring driving safety and user experience. While remote physiological
measurement (RPM) offers a promising non-invasive solution, its translation to
real-world driving scenarios is critically constrained by the scarcity of
comprehensive datasets. Existing resources are often limited in scale, modality
diversity, the breadth of biometric annotations, and the range of captured
conditions, thereby omitting inherent real-world challenges in driving. Here,
we present PhysDrive, the first large-scale multimodal dataset for contactless
in-vehicle physiological sensing with dedicated consideration on various
modality settings and driving factors. PhysDrive collects data from 48 drivers,
including synchronized RGB, near-infrared camera, and raw mmWave radar data,
accompanied with six synchronized ground truths (ECG, BVP, Respiration, HR, RR,
and SpO2). It covers a wide spectrum of naturalistic driving conditions,
including driver motions, dynamic natural light, vehicle types, and road
conditions. We extensively evaluate both signal-processing and deep-learning
methods on PhysDrive, establishing a comprehensive benchmark across all
modalities, and release full open-source code with compatibility for mainstream
public toolboxes. We envision PhysDrive will serve as a foundational resource
and accelerate research on multimodal driver monitoring and smart-cockpit
systems.

</details>


### [35] [Faster Lifting for Ordered Domains with Predecessor Relations](https://arxiv.org/abs/2507.19182)
*Kuncheng Zou,Jiahao Mai,Yonggang Zhang,Yuyi Wang,Ondřej Kuželka,Yuanhong Wang,Yi Chang*

Main category: cs.AI

TL;DR: 论文提出了一种新算法，直接在公理中处理前驱关系，显著提升了有序域上的推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理有序域和前驱关系时效率低下，尤其是在涉及前驱关系时。

Method: 将前驱关系作为公理的一部分，设计了一种新算法，支持直接处理前驱关系。

Result: 新算法在实验中对前驱关系推理任务和组合数学问题实现了数量级的加速。

Conclusion: 新算法显著提升了有序域推理的效率，尤其在前驱关系处理上表现优异。

Abstract: We investigate lifted inference on ordered domains with predecessor
relations, where the elements of the domain respect a total (cyclic) order, and
every element has a distinct (clockwise) predecessor. Previous work has
explored this problem through weighted first-order model counting (WFOMC),
which computes the weighted sum of models for a given first-order logic
sentence over a finite domain. In WFOMC, the order constraint is typically
encoded by the linear order axiom introducing a binary predicate in the
sentence to impose a linear ordering on the domain elements. The immediate and
second predecessor relations are then encoded by the linear order predicate.
Although WFOMC with the linear order axiom is theoretically tractable, existing
algorithms struggle with practical applications, particularly when the
predecessor relations are involved. In this paper, we treat predecessor
relations as a native part of the axiom and devise a novel algorithm that
inherently supports these relations. The proposed algorithm not only provides
an exponential speedup for the immediate and second predecessor relations,
which are known to be tractable, but also handles the general k-th predecessor
relations. The extensive experiments on lifted inference tasks and
combinatorics math problems demonstrate the efficiency of our algorithm,
achieving speedups of a full order of magnitude.

</details>


### [36] [Knowledge Grafting: A Mechanism for Optimizing AI Model Deployment in Resource-Constrained Environments](https://arxiv.org/abs/2507.19261)
*Osama Almurshed,Ashish Kaushal,Asmail Muftah,Nitin Auluck,Omer Rana*

Main category: cs.AI

TL;DR: 论文提出了一种名为知识嫁接的新方法，通过将大型模型的特征移植到小型模型中，显著减少了模型大小并提升了性能。


<details>
  <summary>Details</summary>
Motivation: 解决AI模型在资源受限环境中部署的挑战，避免传统模型大小与性能的权衡问题。

Method: 采用知识嫁接机制，将大型模型（供体）的选定特征移植到小型模型（砧木）中。

Result: 模型大小减少88.54%，验证准确率提升至89.97%，测试准确率达90.45%。

Conclusion: 知识嫁接方法有效优化了资源受限环境中的AI模型部署，具有广泛的应用潜力。

Abstract: The increasing adoption of Artificial Intelligence (AI) has led to larger,
more complex models with numerous parameters that require substantial computing
power -- resources often unavailable in many real-world application scenarios.
Our paper addresses this challenge by introducing knowledge grafting, a novel
mechanism that optimizes AI models for resource-constrained environments by
transferring selected features (the scion) from a large donor model to a
smaller rootstock model. The approach achieves an 88.54% reduction in model
size (from 64.39 MB to 7.38 MB), while improving generalization capability of
the model. Our new rootstock model achieves 89.97% validation accuracy (vs.
donor's 87.47%), maintains lower validation loss (0.2976 vs. 0.5068), and
performs exceptionally well on unseen test data with 90.45% accuracy. It
addresses the typical size vs performance trade-off, and enables deployment of
AI frameworks on resource-constrained devices with enhanced performance. We
have tested our approach on an agricultural weed detection scenario, however,
it can be extended across various edge computing scenarios, potentially
accelerating AI adoption in areas with limited hardware/software support -- by
mirroring in a similar manner the horticultural grafting enables productive
cultivation in challenging agri-based environments.

</details>


### [37] [Modeling Uncertainty: Constraint-Based Belief States in Imperfect-Information Games](https://arxiv.org/abs/2507.19263)
*Achille Morenville,Éric Piette*

Main category: cs.AI

TL;DR: 论文研究了在隐藏棋子身份的游戏中，基于约束的信念模型与概率扩展模型的性能对比，发现两者效果相近。


<details>
  <summary>Details</summary>
Motivation: 解决不完全信息游戏中代理需基于部分知识决策的挑战，通过游戏模型本身处理状态估计。

Method: 提出两种信念表示方法：基于约束的模型（CSP）和概率扩展模型（Belief Propagation），并在两种游戏中评估。

Result: 约束基信念与概率推理效果相当，代理性能差异微小。

Conclusion: 约束基信念在许多场景下足以支持有效决策。

Abstract: In imperfect-information games, agents must make decisions based on partial
knowledge of the game state. The Belief Stochastic Game model addresses this
challenge by delegating state estimation to the game model itself. This allows
agents to operate on externally provided belief states, thereby reducing the
need for game-specific inference logic. This paper investigates two approaches
to represent beliefs in games with hidden piece identities: a constraint-based
model using Constraint Satisfaction Problems and a probabilistic extension
using Belief Propagation to estimate marginal probabilities. We evaluated the
impact of both representations using general-purpose agents across two
different games. Our findings indicate that constraint-based beliefs yield
results comparable to those of probabilistic inference, with minimal
differences in agent performance. This suggests that constraint-based belief
states alone may suffice for effective decision-making in many settings.

</details>


### [38] [Integrating LLM in Agent-Based Social Simulation: Opportunities and Challenges](https://arxiv.org/abs/2507.19364)
*Patrick Taillandier,Jean Daniel Zucker,Arnaud Grignard,Benoit Gaudou,Nghi Quang Huynh,Alexis Drogoul*

Main category: cs.AI

TL;DR: 本文探讨了大型语言模型（LLMs）在社交模拟中的应用潜力与局限性，提出了结合传统建模平台的混合方法。


<details>
  <summary>Details</summary>
Motivation: 从计算社会科学的角度分析LLMs在模拟人类认知和社会行为中的能力与不足，推动更有效的模拟工具发展。

Method: 分为三部分：1）评估LLMs在人类认知模拟中的表现；2）调查LLMs在多智能体模拟中的应用；3）提出混合建模方法。

Result: LLMs在交互式模拟中表现良好，但在解释性或预测性建模中存在局限性。混合方法能结合灵活性与透明度。

Conclusion: 建议将LLMs与传统建模平台结合，以平衡语言推理的表达力与规则系统的严谨性。

Abstract: This position paper examines the use of Large Language Models (LLMs) in
social simulation, analyzing both their potential and their limitations from a
computational social science perspective. The first part reviews recent
findings on the ability of LLMs to replicate key aspects of human cognition,
including Theory of Mind reasoning and social inference, while also
highlighting significant limitations such as cognitive biases, lack of true
understanding, and inconsistencies in behavior. The second part surveys
emerging applications of LLMs in multi-agent simulation frameworks, focusing on
system architectures, scale, and validation strategies. Notable projects such
as Generative Agents (Smallville) and AgentSociety are discussed in terms of
their design choices, empirical grounding, and methodological innovations.
Particular attention is given to the challenges of behavioral fidelity,
calibration, and reproducibility in large-scale LLM-driven simulations. The
final section distinguishes between contexts where LLMs, like other black-box
systems, offer direct value-such as interactive simulations and serious
games-and those where their use is more problematic, notably in explanatory or
predictive modeling. The paper concludes by advocating for hybrid approaches
that integrate LLMs into traditional agent-based modeling platforms (GAMA,
Netlogo, etc), enabling modelers to combine the expressive flexibility of
language-based reasoning with the transparency and analytical rigor of
classical rule-based systems.

</details>


### [39] [Learning neuro-symbolic convergent term rewriting systems](https://arxiv.org/abs/2507.19372)
*Flavio Petruzzellis,Alberto Testolin,Alessandro Sperduti*

Main category: cs.AI

TL;DR: 论文提出了一种基于神经符号架构的框架，用于学习收敛的项重写系统，并展示了两种模块化实现（NRS和FastNRS），在泛化和多任务学习中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决符号算法执行的泛化和分布外性能问题。

Method: 采用神经符号架构，设计NRS和FastNRS两种模型，结合算法启发式设计和关键架构元素。

Result: 模型在数学公式简化任务中表现优异，FastNRS在内存效率、训练速度和推理时间上有显著提升，且在多任务学习中表现良好。

Conclusion: 提出的系统在多个任务中优于强基线模型，包括专用算法模型和通用大语言模型。

Abstract: Building neural systems that can learn to execute symbolic algorithms is a
challenging open problem in artificial intelligence, especially when aiming for
strong generalization and out-of-distribution performance. In this work, we
introduce a general framework for learning convergent term rewriting systems
using a neuro-symbolic architecture inspired by the rewriting algorithm itself.
We present two modular implementations of such architecture: the Neural
Rewriting System (NRS) and the Fast Neural Rewriting System (FastNRS). As a
result of algorithmic-inspired design and key architectural elements, both
models can generalize to out-of-distribution instances, with FastNRS offering
significant improvements in terms of memory efficiency, training speed, and
inference time. We evaluate both architectures on four tasks involving the
simplification of mathematical formulas and further demonstrate their
versatility in a multi-domain learning scenario, where a single model is
trained to solve multiple types of problems simultaneously. The proposed system
significantly outperforms two strong neural baselines: the Neural Data Router,
a recent transformer variant specifically designed to solve algorithmic
problems, and GPT-4o, one of the most powerful general-purpose large-language
models. Moreover, our system matches or outperforms the latest o1-preview model
from OpenAI that excels in reasoning benchmarks.

</details>


### [40] [Hierarchical Deep Reinforcement Learning Framework for Multi-Year Asset Management Under Budget Constraints](https://arxiv.org/abs/2507.19458)
*Amir Fard,Arnold X. -X. Yuan*

Main category: cs.AI

TL;DR: 提出了一种分层深度强化学习方法，用于多年度基础设施规划，通过分解预算和维护决策，解决了现有方法的可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 基础设施资产管理中的预算规划与维护优化面临组合动作空间、资产退化多样性、严格预算约束和环境不确定性等复杂性，限制了现有方法的可扩展性。

Method: 采用分层深度强化学习框架，分为高层预算规划器和低层维护规划器，结合线性规划投影和分层Soft Actor-Critic框架，确保预算合规性。

Result: 在10、15和20个污水管网规模的案例研究中，该方法比传统深度Q学习和遗传算法收敛更快、扩展性更好，且能提供接近最优的解决方案。

Conclusion: 提出的分层方法有效解决了基础设施规划中的复杂性和可扩展性问题，为多年度预算和维护优化提供了高效解决方案。

Abstract: Budget planning and maintenance optimization are crucial for infrastructure
asset management, ensuring cost-effectiveness and sustainability. However, the
complexity arising from combinatorial action spaces, diverse asset
deterioration, stringent budget constraints, and environmental uncertainty
significantly limits existing methods' scalability. This paper proposes a
Hierarchical Deep Reinforcement Learning methodology specifically tailored to
multi-year infrastructure planning. Our approach decomposes the problem into
two hierarchical levels: a high-level Budget Planner allocating annual budgets
within explicit feasibility bounds, and a low-level Maintenance Planner
prioritizing assets within the allocated budget. By structurally separating
macro-budget decisions from asset-level prioritization and integrating linear
programming projection within a hierarchical Soft Actor-Critic framework, the
method efficiently addresses exponential growth in the action space and ensures
rigorous budget compliance. A case study evaluating sewer networks of varying
sizes (10, 15, and 20 sewersheds) illustrates the effectiveness of the proposed
approach. Compared to conventional Deep Q-Learning and enhanced genetic
algorithms, our methodology converges more rapidly, scales effectively, and
consistently delivers near-optimal solutions even as network size grows.

</details>
