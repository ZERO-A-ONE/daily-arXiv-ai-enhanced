<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 12]
- [cs.CR](#cs.CR) [Total: 10]
- [cs.SE](#cs.SE) [Total: 8]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Calibrated Trust in Dealing with LLM Hallucinations: A Qualitative Study](https://arxiv.org/abs/2512.09088)
*Adrian Ryser,Florian Allwein,Tim Schlippe*

Main category: cs.AI

TL;DR: 该研究探讨了大语言模型幻觉如何影响用户信任，发现幻觉不会导致全面不信任，而是引发情境化的信任校准，并识别出直觉作为新的信任因素。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解大语言模型产生的幻觉（事实错误但看似合理）如何影响用户对LLM的信任以及用户与LLM的互动方式。

Method: 采用定性研究方法，对192名参与者进行研究，探索日常使用中幻觉对信任的影响。

Result: 研究发现：1) 幻觉不会导致全面不信任，而是引发情境敏感的信任校准；2) 确认了期望、先前经验、用户专业知识等信任因素；3) 识别出直觉作为幻觉检测的新因素；4) 信任动态还受情境因素影响，特别是感知风险和决策风险。

Conclusion: 研究验证了递归信任校准过程，并将直觉作为用户相关信任因素纳入其中，基于这些发现提出了负责任和反思性使用LLM的实践建议。

Abstract: Hallucinations are outputs by Large Language Models (LLMs) that are factually incorrect yet appear plausible [1]. This paper investigates how such hallucinations influence users' trust in LLMs and users' interaction with LLMs. To explore this in everyday use, we conducted a qualitative study with 192 participants. Our findings show that hallucinations do not result in blanket mistrust but instead lead to context-sensitive trust calibration. Building on the calibrated trust model by Lee & See [2] and Afroogh et al.'s trust-related factors [3], we confirm expectancy [3], [4], prior experience [3], [4], [5], and user expertise & domain knowledge [3], [4] as userrelated (human) trust factors, and identify intuition as an additional factor relevant for hallucination detection. Additionally, we found that trust dynamics are further influenced by contextual factors, particularly perceived risk [3] and decision stakes [6]. Consequently, we validate the recursive trust calibration process proposed by Blöbaum [7] and extend it by including intuition as a user-related trust factor. Based on these insights, we propose practical recommendations for responsible and reflective LLM use.

</details>


### [2] [AI TIPS 2.0: A Comprehensive Framework for Operationalizing AI Governance](https://arxiv.org/abs/2512.09114)
*Pamela Gupta*

Main category: cs.AI

TL;DR: AI TIPS 2.0框架解决当前AI治理三大挑战：用例级风险评估不足、现有框架缺乏可操作控制、规模化实施机制缺失


<details>
  <summary>Details</summary>
Motivation: 当前AI治理框架存在三个关键缺陷：1) 缺乏针对具体用例的风险评估能力，如Humana集体诉讼案所示；2) 现有框架如ISO 42001和NIST AI RMF停留在概念层面，缺乏可操作控制；3) 组织缺乏规模化实施治理的机制，无法将可信AI实践嵌入开发生命周期

Method: 提出AI TIPS 2.0（人工智能信任集成支柱可持续性框架），这是对2019年开发的综合操作框架的更新，比NIST AI风险管理框架早四年，直接针对上述挑战提供解决方案

Result: AI TIPS 2.0框架能够：1) 提供针对具体用例的风险评估方法；2) 将治理要求转化为具体技术实施；3) 建立规模化操作机制，嵌入可信AI实践，量化测量合规性，并为从董事会到数据科学家的不同角色提供适当可见性

Conclusion: AI TIPS 2.0框架填补了当前AI治理的关键空白，为组织提供了可操作、可扩展的解决方案，以应对AI部署中的风险评估、技术实施和规模化治理挑战

Abstract: The deployment of AI systems faces three critical governance challenges that current frameworks fail to adequately address. First, organizations struggle with inadequate risk assessment at the use case level, exemplified by the Humana class action lawsuit and other high impact cases where an AI system deployed to production exhibited both significant bias and high error rates, resulting in improper healthcare claim denials. Each AI use case presents unique risk profiles requiring tailored governance, yet most frameworks provide one size fits all guidance. Second, existing frameworks like ISO 42001 and NIST AI RMF remain at high conceptual levels, offering principles without actionable controls, leaving practitioners unable to translate governance requirements into specific technical implementations. Third, organizations lack mechanisms for operationalizing governance at scale, with no systematic approach to embed trustworthy AI practices throughout the development lifecycle, measure compliance quantitatively, or provide role-appropriate visibility from boards to data scientists. We present AI TIPS, Artificial Intelligence Trust-Integrated Pillars for Sustainability 2.0, update to the comprehensive operational framework developed in 2019,four years before NIST's AI Risk Management Framework, that directly addresses these challenges.

</details>


### [3] [A Categorical Analysis of Large Language Models and Why LLMs Circumvent the Symbol Grounding Problem](https://arxiv.org/abs/2512.09117)
*Luciano Floridi,Yiyang Jia,Fernando Tohmé*

Main category: cs.AI

TL;DR: 论文提出一个形式化范畴框架，分析人类和LLM如何将内容转化为关于可能世界状态空间的真值命题，论证LLM并未解决而是绕过了符号接地问题


<details>
  <summary>Details</summary>
Motivation: 研究人类和大型语言模型在将内容转化为真值命题时的认知差异，探讨LLM是否真正解决了符号接地问题

Method: 采用形式化的范畴理论框架，分析内容到可能世界状态空间W的真值命题转换过程

Result: 论证LLM并未真正解决符号接地问题，而是通过不同机制绕过了该问题

Conclusion: LLM与人类在符号接地方面存在本质差异，LLM的运作机制并未真正解决符号接地问题

Abstract: This paper presents a formal, categorical framework for analysing how humans and large language models (LLMs) transform content into truth-evaluated propositions about a state space of possible worlds W , in order to argue that LLMs do not solve but circumvent the symbol grounding problem.

</details>


### [4] [SDialog: A Python Toolkit for End-to-End Agent Building, User Simulation, Dialog Generation, and Evaluation](https://arxiv.org/abs/2512.09142)
*Sergio Burdisso,Séverin Baroudi,Yanis Labrak,David Grunert,Pawel Cyrta,Yiyang Chen,Srikanth Madikeri,Esaú Villatoro-Tello,Thomas Schaaf,Ricard Marxer,Petr Motlicek*

Main category: cs.AI

TL;DR: SDialog是一个开源Python工具包，集成了对话生成、评估和机制可解释性，为构建和分析基于LLM的对话系统提供端到端框架。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏一个统一的框架来系统性地构建、评估和理解基于大语言模型的对话系统，需要将对话生成、评估和机制可解释性整合到一个工具包中。

Method: 围绕标准化的Dialog表示构建，提供：1）基于角色的多智能体模拟与可组合编排；2）结合语言指标、LLM作为评判者和功能正确性验证器的综合评估；3）通过特征消融和诱导进行激活检查和引导的机制可解释性工具；4）包含3D房间建模和麦克风效果的完整声学模拟音频生成。

Result: SDialog工具包集成了所有主流LLM后端，支持在统一API下进行混合后端实验，实现了对话生成、评估和可解释性的耦合。

Conclusion: SDialog通过对话中心的架构，使研究人员能够更系统地构建、基准测试和理解对话系统，为对话AI研究提供了统一的端到端框架。

Abstract: We present SDialog, an MIT-licensed open-source Python toolkit that unifies dialog generation, evaluation and mechanistic interpretability into a single end-to-end framework for building and analyzing LLM-based conversational agents. Built around a standardized \texttt{Dialog} representation, SDialog provides: (1) persona-driven multi-agent simulation with composable orchestration for controlled, synthetic dialog generation, (2) comprehensive evaluation combining linguistic metrics, LLM-as-a-judge and functional correctness validators, (3) mechanistic interpretability tools for activation inspection and steering via feature ablation and induction, and (4) audio generation with full acoustic simulation including 3D room modeling and microphone effects. The toolkit integrates with all major LLM backends, enabling mixed-backend experiments under a unified API. By coupling generation, evaluation, and interpretability in a dialog-centric architecture, SDialog enables researchers to build, benchmark and understand conversational systems more systematically.

</details>


### [5] [Visual Categorization Across Minds and Models: Cognitive Analysis of Human Labeling and Neuro-Symbolic Integration](https://arxiv.org/abs/2512.09340)
*Chethana Prasad Kabgere*

Main category: cs.AI

TL;DR: 该研究对比人类与AI系统在模糊视觉刺激下的图像标注表现，分析两者在表征、推理和置信度校准方面的异同，为未来神经符号架构提供认知基础。


<details>
  <summary>Details</summary>
Motivation: 理解人类与AI系统如何解释模糊视觉刺激，对于揭示感知、推理和决策的本质至关重要。通过对比两者在低分辨率、感知退化刺激下的表现，可以深入了解生物与人工系统的认知差异。

Method: 结合计算认知科学、认知架构和连接主义-符号混合模型，对比人类策略（类比推理、形状识别、置信度调节）与AI的特征处理。基于Marr的三层次假设、Simon的有限理性和Thagard的表征与情感框架，分析参与者反应与Grad-CAM可视化模型注意力的关系。使用ACT-R和Soar认知架构解释人类行为。

Result: 研究发现人类与AI系统在表征、推理和置信度校准方面存在关键相似点和差异。人类表现出层次化和启发式决策策略，而AI主要依赖特征处理。Grad-CAM可视化揭示了模型注意力模式与人类认知策略的对比。

Conclusion: 研究为未来神经符号架构提供认知基础，这些架构将结构化符号推理与连接主义表征相结合，受具身性、可解释性和认知对齐原则指导，有望开发出既高效又可解释且具有认知基础的AI系统。

Abstract: Understanding how humans and AI systems interpret ambiguous visual stimuli offers critical insight into the nature of perception, reasoning, and decision-making. This paper examines image labeling performance across human participants and deep neural networks, focusing on low-resolution, perceptually degraded stimuli. Drawing from computational cognitive science, cognitive architectures, and connectionist-symbolic hybrid models, we contrast human strategies such as analogical reasoning, shape-based recognition, and confidence modulation with AI's feature-based processing. Grounded in Marr's tri-level hypothesis, Simon's bounded rationality, and Thagard's frameworks of representation and emotion, we analyze participant responses in relation to Grad-CAM visualizations of model attention. Human behavior is further interpreted through cognitive principles modeled in ACT-R and Soar, revealing layered and heuristic decision strategies under uncertainty. Our findings highlight key parallels and divergences between biological and artificial systems in representation, inference, and confidence calibration. The analysis motivates future neuro-symbolic architectures that unify structured symbolic reasoning with connectionist representations. Such architectures, informed by principles of embodiment, explainability, and cognitive alignment, offer a path toward AI systems that are not only performant but also interpretable and cognitively grounded.

</details>


### [6] [Toward Closed-loop Molecular Discovery via Language Model, Property Alignment and Strategic Search](https://arxiv.org/abs/2512.09566)
*Junkai Ji,Zhangfan Yang,Dong Xu,Ruibin Bai,Jianqiang Li,Tingjun Hou,Zexuan Zhu*

Main category: cs.AI

TL;DR: Trio是一个整合了基于片段的分子语言建模、强化学习和蒙特卡洛树搜索的分子生成框架，用于有效且可解释的闭环靶向分子设计。


<details>
  <summary>Details</summary>
Motivation: 传统药物发现方法耗时昂贵，高通量和基于对接的虚拟筛选成功率低、可扩展性有限。现有的生成模型存在泛化能力不足、可解释性差、过度强调结合亲和力而忽视关键药理学特性等问题，限制了其转化应用价值。

Method: Trio框架整合三个关键组件：1) 基于片段的分子语言建模实现上下文感知的片段组装；2) 强化学习强制执行物理化学和合成可行性；3) 蒙特卡洛树搜索在探索新型化学型和利用有前景的中间体之间实现平衡搜索。

Result: 实验结果表明，Trio可靠地生成化学有效且药理学增强的配体，在结合亲和力(+7.85%)、药物相似性(+11.10%)和合成可及性(+12.05%)方面优于最先进方法，同时将分子多样性扩展了四倍以上。

Conclusion: Trio框架通过整合多种先进技术，实现了有效、可解释的靶向分子设计，在保持化学有效性的同时显著提升了配体的药理学特性和多样性，为药物发现提供了有前景的新方法。

Abstract: Drug discovery is a time-consuming and expensive process, with traditional high-throughput and docking-based virtual screening hampered by low success rates and limited scalability. Recent advances in generative modelling, including autoregressive, diffusion, and flow-based approaches, have enabled de novo ligand design beyond the limits of enumerative screening. Yet these models often suffer from inadequate generalization, limited interpretability, and an overemphasis on binding affinity at the expense of key pharmacological properties, thereby restricting their translational utility. Here we present Trio, a molecular generation framework integrating fragment-based molecular language modeling, reinforcement learning, and Monte Carlo tree search, for effective and interpretable closed-loop targeted molecular design. Through the three key components, Trio enables context-aware fragment assembly, enforces physicochemical and synthetic feasibility, and guides a balanced search between the exploration of novel chemotypes and the exploitation of promising intermediates within protein binding pockets. Experimental results show that Trio reliably achieves chemically valid and pharmacologically enhanced ligands, outperforming state-of-the-art approaches with improved binding affinity (+7.85%), drug-likeness (+11.10%) and synthetic accessibility (+12.05%), while expanding molecular diversity more than fourfold.

</details>


### [7] [An End-to-end Planning Framework with Agentic LLMs and PDDL](https://arxiv.org/abs/2512.09629)
*Emanuele La Malfa,Ping Zhu,Samuele Marro,Sara Bernardini,Michael Wooldridge*

Main category: cs.AI

TL;DR: 提出一个基于验证器的端到端规划框架，使用LLM将自然语言规范自动转换为PDDL模型，通过多智能体迭代优化解决时间约束、最优性等问题，最终生成可读的自然语言计划。


<details>
  <summary>Details</summary>
Motivation: 解决人类用自然语言描述规划问题时存在的模糊性、矛盾性，以及LLM在复杂规划任务（如Blocksworld、汉诺塔）中表现不佳的问题，实现无需人工干预的端到端自动化规划。

Method: 使用编排器接收自然语言规范，通过多个LLM驱动的子模块（智能体）迭代细化为PDDL模型，解决时间约束、最优性等需求，再交由外部规划引擎生成计划，最后将计划翻译回自然语言。

Result: 框架在Google NaturalPlan、PlanBench等多个基准测试中表现灵活有效，能够处理Blocksworld、汉诺塔等LLM难以应对的规划问题，支持与Fast Downward、LPG等多种PDDL规划引擎集成。

Conclusion: 该框架代表了LLM辅助端到端规划的重要进展，能够自动处理自然语言规范中的模糊性和矛盾，生成正确且可读的计划，无需人工干预，具有广泛的适用性和集成能力。

Abstract: We present an end-to-end framework for planning supported by verifiers. An orchestrator receives a human specification written in natural language and converts it into a PDDL (Planning Domain Definition Language) model, where the domain and problem are iteratively refined by sub-modules (agents) to address common planning requirements, such as time constraints and optimality, as well as ambiguities and contradictions that may exist in the human specification. The validated domain and problem are then passed to an external planning engine to generate a plan. The orchestrator and agents are powered by Large Language Models (LLMs) and require no human intervention at any stage of the process. Finally, a module translates the final plan back into natural language to improve human readability while maintaining the correctness of each step. We demonstrate the flexibility and effectiveness of our framework across various domains and tasks, including the Google NaturalPlan benchmark and PlanBench, as well as planning problems like Blocksworld and the Tower of Hanoi (where LLMs are known to struggle even with small instances). Our framework can be integrated with any PDDL planning engine and validator (such as Fast Downward, LPG, POPF, VAL, and uVAL, which we have tested) and represents a significant step toward end-to-end planning aided by LLMs.

</details>


### [8] [Gaussian Process Aggregation for Root-Parallel Monte Carlo Tree Search with Continuous Actions](https://arxiv.org/abs/2512.09727)
*Junlin Xiao,Victor-Alexandru Darvariu,Bruno Lacerda,Nick Hawes*

Main category: cs.AI

TL;DR: 本文提出了一种使用高斯过程回归来聚合连续动作空间中多线程MCTS统计数据的方法，在6个不同领域中都优于现有聚合策略，且推理时间增加有限。


<details>
  <summary>Details</summary>
Motivation: 在连续动作空间中，当计算时间有限但需要最佳性能时，如何有效聚合不同线程的统计数据是一个重要但尚未充分探索的问题。

Method: 使用高斯过程回归来获取未在环境中试验过的有希望动作的价值估计，从而改进根并行MCTS在连续动作空间中的统计聚合。

Result: 在6个不同领域进行的系统评估表明，该方法优于现有的聚合策略，同时推理时间仅适度增加。

Conclusion: 高斯过程回归为连续动作空间中的根并行MCTS提供了一种有效的统计聚合方法，在性能提升和计算成本之间取得了良好平衡。

Abstract: Monte Carlo Tree Search is a cornerstone algorithm for online planning, and its root-parallel variant is widely used when wall clock time is limited but best performance is desired. In environments with continuous action spaces, how to best aggregate statistics from different threads is an important yet underexplored question. In this work, we introduce a method that uses Gaussian Process Regression to obtain value estimates for promising actions that were not trialed in the environment. We perform a systematic evaluation across 6 different domains, demonstrating that our approach outperforms existing aggregation strategies while requiring a modest increase in inference time.

</details>


### [9] [RIFT: A Scalable Methodology for LLM Accelerator Fault Assessment using Reinforcement Learning](https://arxiv.org/abs/2512.09829)
*Khurram Khalil,Muhammad Mahad Khaliq,Khaza Anuarul Hoque*

Main category: cs.AI

TL;DR: RIFT框架使用强化学习自动化发现最小化、高影响故障场景，加速AI加速器故障评估，相比进化方法提速2.2倍，相比随机故障注入减少99%测试向量，同时提供更好的故障覆盖率。


<details>
  <summary>Details</summary>
Motivation: 现代AI加速器规模巨大，传统故障评估方法面临计算成本过高、关键故障模式覆盖率不足的问题，需要更高效的故障评估框架。

Method: RIFT将复杂的最坏情况故障搜索转化为序列决策问题，结合混合灵敏度分析进行搜索空间剪枝，使用强化学习智能生成最小化、高影响的测试套件。

Result: 在十亿参数大语言模型工作负载和NVIDIA A100 GPU上评估，RIFT相比进化方法实现2.2倍故障评估加速，相比随机故障注入减少99%测试向量，同时获得更优故障覆盖率。RIFT指导的选择性纠错码比统一三模冗余保护的成本效益提高12.8倍。

Conclusion: RIFT提供可扩展的故障评估框架，能自动生成UVM兼容验证工件，确保结果可直接集成到商业RTL验证流程中，为智能硬件保护策略提供可操作数据。

Abstract: The massive scale of modern AI accelerators presents critical challenges to traditional fault assessment methodologies, which face prohibitive computational costs and provide poor coverage of critical failure modes. This paper introduces RIFT (Reinforcement Learning-guided Intelligent Fault Targeting), a scalable framework that automates the discovery of minimal, high-impact fault scenarios for efficient design-time fault assessment. RIFT transforms the complex search for worst-case faults into a sequential decision-making problem, combining hybrid sensitivity analysis for search space pruning with reinforcement learning to intelligently generate minimal, high-impact test suites. Evaluated on billion-parameter Large Language Model (LLM) workloads using NVIDIA A100 GPUs, RIFT achieves a \textbf{2.2$\times$} fault assessment speedup over evolutionary methods and reduces the required test vector volume by over \textbf{99\%} compared to random fault injection, all while achieving \textbf{superior fault coverage}. The proposed framework also provides actionable data to enable intelligent hardware protection strategies, demonstrating that RIFT-guided selective error correction code provides a \textbf{12.8$\times$} improvement in \textbf{cost-effectiveness} (coverage per unit area) compared to uniform triple modular redundancy protection. RIFT automatically generates UVM-compliant verification artifacts, ensuring its findings are directly actionable and integrable into commercial RTL verification workflows.

</details>


### [10] [Interpretation as Linear Transformation: A Cognitive-Geometric Model of Belief and Meaning](https://arxiv.org/abs/2512.09831)
*Chainarong Amornbunchornvej*

Main category: cs.AI

TL;DR: 该论文提出了一个几何框架来建模认知异构智能体之间的信念、动机和影响，将信念形式化为结构化向量，通过线性解释映射进行传播，并建立了信念存活的代数条件。


<details>
  <summary>Details</summary>
Motivation: 论文旨在解决认知异构智能体之间的信念传播和理解问题。传统方法依赖共享信息或理性假设，但作者认为意义保存应基于结构兼容性。需要建立一个统一的框架来分析信念在多样化认知几何中的传播、变异和消失。

Method: 为每个智能体构建个性化的价值空间（向量空间），信念被形式化为结构化向量（抽象存在）。信念传播通过线性解释映射实现，信念只有在避免这些映射的零空间时才能存活。提出了"无零空间领导条件"等代数约束来分析信念动态。

Result: 展示了信念扭曲、动机漂移、反事实评估和相互理解限制如何从纯代数约束中产生。领导力被表征为表征可达性的属性而非说服或权威。解释了抽象存在如何在多样化认知几何中传播、变异或消失。

Conclusion: 该认知几何视角通过将意义保存建立在结构兼容性而非共享信息或理性上，统一了概念空间、社会认识论和AI价值对齐的见解。为分析异构智能体间的信念动态提供了通用基础，并阐明了人类和人工系统中影响的认知边界。

Abstract: This paper develops a geometric framework for modeling belief, motivation, and influence across cognitively heterogeneous agents. Each agent is represented by a personalized value space, a vector space encoding the internal dimensions through which the agent interprets and evaluates meaning. Beliefs are formalized as structured vectors-abstract beings-whose transmission is mediated by linear interpretation maps. A belief survives communication only if it avoids the null spaces of these maps, yielding a structural criterion for intelligibility, miscommunication, and belief death.
  Within this framework, I show how belief distortion, motivational drift, counterfactual evaluation, and the limits of mutual understanding arise from purely algebraic constraints. A central result-"the No-Null-Space Leadership Condition"-characterizes leadership as a property of representational reachability rather than persuasion or authority. More broadly, the model explains how abstract beings can propagate, mutate, or disappear as they traverse diverse cognitive geometries.
  The account unifies insights from conceptual spaces, social epistemology, and AI value alignment by grounding meaning preservation in structural compatibility rather than shared information or rationality. I argue that this cognitive-geometric perspective clarifies the epistemic boundaries of influence in both human and artificial systems, and offers a general foundation for analyzing belief dynamics across heterogeneous agents.

</details>


### [11] [Human-in-the-Loop and AI: Crowdsourcing Metadata Vocabulary for Materials Science](https://arxiv.org/abs/2512.09895)
*Jane Greenberg,Scott McClellan,Addy Ireland,Robert Sammarco,Colton Gerber,Christopher B. Rauch,Mat Kelly,John Kunze,Yuan An,Eric Toberer*

Main category: cs.AI

TL;DR: MatSci-YAMZ是一个结合AI和人类在环（包括众包）的平台，用于支持元数据词汇表开发，在材料科学领域进行了概念验证，展示了AI-HILT模型的可行性。


<details>
  <summary>Details</summary>
Motivation: 元数据词汇表对推进FAIR和FARR数据原则至关重要，但其发展受到人力资源有限和标准化实践不一致的限制。

Method: 开发MatSci-YAMZ平台，整合AI和人类在环（HILT）方法，包括众包。在材料科学领域进行概念验证，6名参与者通过平台贡献术语定义和示例，通过迭代反馈循环精炼AI生成的定义。

Result: 成功创建了19个AI生成的定义，迭代反馈循环证明了AI-HILT精炼的可行性。确认了AI-HILT模型的可行性，包括：1）成功的概念验证；2）与FAIR和开放科学原则一致；3）指导未来研究的研究协议；4）跨领域扩展的潜力。

Conclusion: MatSci-YAMZ的基础模型有潜力增强语义透明度，减少共识构建和元数据词汇表开发所需的时间。

Abstract: Metadata vocabularies are essential for advancing FAIR and FARR data principles, but their development constrained by limited human resources and inconsistent standardization practices. This paper introduces MatSci-YAMZ, a platform that integrates artificial intelligence (AI) and human-in-the-loop (HILT), including crowdsourcing, to support metadata vocabulary development. The paper reports on a proof-of-concept use case evaluating the AI-HILT model in materials science, a highly interdisciplinary domain Six (6) participants affiliated with the NSF Institute for Data-Driven Dynamical Design (ID4) engaged with the MatSci-YAMZ plaform over several weeks, contributing term definitions and providing examples to prompt the AI-definitions refinement. Nineteen (19) AI-generated definitions were successfully created, with iterative feedback loops demonstrating the feasibility of AI-HILT refinement. Findings confirm the feasibility AI-HILT model highlighting 1) a successful proof of concept, 2) alignment with FAIR and open-science principles, 3) a research protocol to guide future studies, and 4) the potential for scalability across domains. Overall, MatSci-YAMZ's underlying model has the capacity to enhance semantic transparency and reduce time required for consensus building and metadata vocabulary development.

</details>


### [12] [SCOPE: Language Models as One-Time Teacher for Hierarchical Planning in Text Environments](https://arxiv.org/abs/2512.09897)
*Haoye Lu,Pavan Seshadri,Kaheer Suleman*

Main category: cs.AI

TL;DR: SCOPE是一种一次性分层规划器，利用LLM生成的子目标仅用于初始化，然后预训练轻量级学生模型，显著提高了效率但降低了可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的规划方法存在计算成本高、部署效率低的问题，且通常使用未经调整的固定参数LLM，无法适应目标任务。需要一种更高效的规划方法。

Method: SCOPE采用一次性分层规划方法，仅使用LLM生成的子目标进行初始化，然后从示例轨迹中直接推导子目标来预训练轻量级学生模型，避免了重复查询LLM。

Result: 在TextCraft环境中，SCOPE达到0.56的成功率（优于ADaPT的0.52），并将推理时间从164.4秒大幅减少到仅3.0秒。

Conclusion: 尽管LLM生成的子目标可能不是最优的，但仍能为文本规划任务中的分层目标分解提供良好的起点，SCOPE在保持性能的同时显著提高了效率。

Abstract: Long-term planning in complex, text-based environments presents significant challenges due to open-ended action spaces, ambiguous observations, and sparse feedback. Recent research suggests that large language models (LLMs) encode rich semantic knowledge about the world, which can be valuable for guiding agents in high-level reasoning and planning across both embodied and purely textual settings. However, existing approaches often depend heavily on querying LLMs during training and inference, making them computationally expensive and difficult to deploy efficiently. In addition, these methods typically employ a pretrained, unaltered LLM whose parameters remain fixed throughout training, providing no opportunity for adaptation to the target task. To address these limitations, we introduce SCOPE (Subgoal-COnditioned Pretraining for Efficient planning), a one-shot hierarchical planner that leverages LLM-generated subgoals only at initialization to pretrain a lightweight student model. Unlike prior approaches that distill LLM knowledge by repeatedly prompting the model to adaptively generate subgoals during training, our method derives subgoals directly from example trajectories. This design removes the need for repeated LLM queries, significantly improving efficiency, though at the cost of reduced explainability and potentially suboptimal subgoals. Despite their suboptimality, our results on the TextCraft environment show that LLM-generated subgoals can still serve as a strong starting point for hierarchical goal decomposition in text-based planning tasks. Compared to the LLM-based hierarchical agent ADaPT (Prasad et al., 2024), which achieves a 0.52 success rate, our method reaches 0.56 and reduces inference time from 164.4 seconds to just 3.0 seconds.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [13] [EMMap: A Systematic Framework for Spatial EMFI Mapping and Fault Classification on Microcontrollers](https://arxiv.org/abs/2512.09049)
*Gandham Sai Santhosh,Siddhartha Sanjay Naik,Ritwik Badola,Chester Rebeiro*

Main category: cs.CR

TL;DR: 提出一个平台无关的电磁故障注入空间映射与故障分类框架，用于系统性地分析微控制器对电磁故障注入的空间敏感性


<details>
  <summary>Details</summary>
Motivation: 现有文献缺乏统一的电磁故障注入空间敏感性映射和故障行为分类方法，需要建立系统化的分析框架

Method: 基于O'Flynn和Kuhnapfel等人的研究，开发平台无关的空间电磁故障注入映射和故障分类框架，在三种代表性微控制器上进行初步实验验证

Result: 在Xtensa LX6 (ESP32)和两个ChipWhisper板上进行了初步实验，展示了该方法的实际应用，为分析不同嵌入式架构的电磁故障注入敏感性提供了可复现的工作流程

Conclusion: 提出的框架为研究人员分析各种嵌入式架构的电磁故障注入敏感性提供了通用且可复现的方法，有助于系统性地理解空间探头位置对故障结果的影响

Abstract: Electromagnetic Fault Injection (EMFI) is a powerful technique for inducing bit flips and instruction-level perturbations on microcontrollers, yet existing literature lacks a unified methodology for systematically mapping spatial sensitivity and classifying resulting fault behaviors. Building on insights from O'Flynn and Kuhnapfel et al., we introduce a platform-agnostic framework for Spatial EMFI Mapping and Fault Classification, aimed at understanding how spatial probe position influences fault outcomes. We present pilot experiments on three representative microcontroller targets including the Xtensa LX6 (ESP32) and two ChipWhisper boards not as definitive evaluations, but as illustrative demonstrations of how the proposed methodology can be applied in practice. These preliminary observations motivate a generalized and reproducible workflow that researchers can adopt when analyzing EMFI susceptibility across diverse embedded architectures.

</details>


### [14] [Exposing Vulnerabilities in Counterfeit Prevention Systems Utilizing Physically Unclonable Surface Features](https://arxiv.org/abs/2512.09150)
*Anirudh Nakra,Nayeeb Rashid,Chau-Wai Wong,Min Wu*

Main category: cs.CR

TL;DR: 该论文提出纸质表面物理不可克隆特征(PUFs)认证系统存在安全漏洞，通过建立操作框架揭示系统级脆弱性，设计了物理拒绝服务和数字伪造攻击，强调需要安全对策来确保可靠的防伪认证。


<details>
  <summary>Details</summary>
Motivation: 现有基于纸质表面微观不规则特征的防伪认证方法可能存在安全漏洞，导致技术可行性与实际安全部署之间存在差距，需要系统性地分析这些漏洞以确保可靠的防伪系统。

Method: 通过形式化纸质PUF认证的操作框架，揭示物理和数字领域的系统级脆弱性，设计物理拒绝服务和数字伪造攻击来验证漏洞，并进行分阶段的安全分析。

Result: 设计的攻击证明了纸质PUF认证系统存在可被利用的漏洞，强调需要安全对策来确保认证的可靠性和弹性，提出的框架为未来防伪系统设计提供了安全分析基础。

Conclusion: 纸质表面PUF认证系统需要全面的安全对策来应对物理和数字领域的攻击，提出的操作框架为系统级安全分析和未来防伪系统设计提供了指导。

Abstract: Counterfeit products pose significant risks to public health and safety through infiltrating untrusted supply chains. Among numerous anti-counterfeiting techniques, leveraging inherent, unclonable microscopic irregularities of paper surfaces is an accurate and cost-effective solution. Prior work of this approach has focused on enabling ubiquitous acquisition of these physically unclonable features (PUFs). However, we will show that existing authentication methods relying on paper surface PUFs may be vulnerable to adversaries, resulting in a gap between technological feasibility and secure real-world deployment. This gap is investigated through formalizing an operational framework for paper-PUF-based authentication. Informed by this framework, we reveal system-level vulnerabilities across both physical and digital domains, designing physical denial-of-service and digital forgery attacks to disrupt proper authentication. The effectiveness of the designed attacks underscores the strong need for security countermeasures for reliable and resilient authentication based on paper PUFs. The proposed framework further facilitates a comprehensive, stage-by-stage security analysis, guiding the design of future counterfeit prevention systems. This analysis delves into potential attack strategies, offering a foundational understanding of how various system components, such as physical features and verification processes, might be exploited by adversaries.

</details>


### [15] [Analysis of the Security Design, Engineering, and Implementation of the SecureDNA System](https://arxiv.org/abs/2512.09233)
*Alan T. Sherman,Jeremy J. Romanik Romano,Edward Zieglar,Enis Golaszewski,Jonathan D. Fuchs,William E. Byrd*

Main category: cs.CR

TL;DR: 论文分析了SecureDNA系统的安全性，发现其自定义的SCEP认证协议仅实现单向认证，存在结构弱点，可能导致绕过速率限制和响应篡改风险。


<details>
  <summary>Details</summary>
Motivation: SecureDNA系统旨在通过加密技术保护DNA合成订单请求和危险数据库的机密性，但需要对其系统设计、工程实现和安全性进行全面分析，以识别潜在漏洞。

Method: 通过分析源代码（版本1.0.8），研究密钥管理、证书基础设施、认证和速率限制机制；首次对相互认证、基本请求和豁免处理协议进行形式化方法分析。

Result: 发现SCEP协议仅实现单向认证，违反深度防御原则，可能导致绕过速率限制；存在密码绑定不足问题，可能允许在TLS通道内篡改数据库响应；提出并验证了缓解措施。

Conclusion: SecureDNA系统存在结构安全性弱点，软件版本1.1.0已通过SCEP+协议修复了SCEP问题，但建议进一步强化安全工程以避免底层结构弱点。

Abstract: We analyze security aspects of the SecureDNA system regarding its system design, engineering, and implementation. This system enables DNA synthesizers to screen order requests against a database of hazards. By applying novel cryptography, the system aims to keep order requests and the database of hazards secret. Discerning the detailed operation of the system in part from source code (Version 1.0.8), our analysis examines key management, certificate infrastructure, authentication, and rate-limiting mechanisms. We also perform the first formal-methods analysis of the mutual authentication, basic request, and exemption-handling protocols.
  Without breaking the cryptography, our main finding is that SecureDNA's custom mutual authentication protocol SCEP achieves only one-way authentication: the hazards database and keyservers never learn with whom they communicate. This structural weakness violates the principle of defense in depth and enables an adversary to circumvent rate limits that protect the secrecy of the hazards database, if the synthesizer connects with a malicious or corrupted keyserver or hashed database. We point out an additional structural weakness that also violates the principle of defense in depth: inadequate cryptographic bindings prevent the system from detecting if responses, within a TLS channel, from the hazards database were modified. Consequently, if a synthesizer were to reconnect with the database over the same TLS session, an adversary could replay and swap responses from the database without breaking TLS. Although the SecureDNA implementation does not allow such reconnections, it would be stronger security engineering to avoid the underlying structural weakness. We identify these vulnerabilities and suggest and verify mitigations, including adding strong bindings. Software Version 1.1.0 fixes SCEP with our proposed SCEP+ protocol.

</details>


### [16] [ObliInjection: Order-Oblivious Prompt Injection Attack to LLM Agents with Multi-source Data](https://arxiv.org/abs/2512.09321)
*Ruiqi Wang,Yuqi Jia,Neil Zhenqiang Gong*

Main category: cs.CR

TL;DR: ObliInjection是针对多源输入LLM应用的首个提示注入攻击方法，通过顺序无关损失函数和orderGCG算法优化污染段，即使只控制少量输入段也能有效攻击。


<details>
  <summary>Details</summary>
Motivation: 现有提示注入攻击主要针对单一来源输入，在多源输入场景下效果有限。攻击者通常只能控制部分输入源，且不知道各源段在输入中的排列顺序，需要开发能应对这种不确定性的攻击方法。

Method: 提出ObliInjection攻击框架，包含两个关键技术：1) 顺序无关损失函数，量化LLM无论干净段和污染段如何排序都能完成攻击者选定任务的可能性；2) orderGCG算法，专门用于最小化顺序无关损失并优化污染段。

Result: 在三个不同应用领域的数据集和12个LLM上的综合实验表明，ObliInjection攻击效果显著，即使输入数据中6-100个段中只有一个被污染，也能成功实施攻击。

Conclusion: ObliInjection是首个针对多源输入LLM应用的提示注入攻击方法，通过解决顺序不确定性挑战，显著提高了攻击成功率，揭示了多源输入场景下的安全风险。

Abstract: Prompt injection attacks aim to contaminate the input data of an LLM to mislead it into completing an attacker-chosen task instead of the intended task. In many applications and agents, the input data originates from multiple sources, with each source contributing a segment of the overall input. In these multi-source scenarios, an attacker may control only a subset of the sources and contaminate the corresponding segments, but typically does not know the order in which the segments are arranged within the input. Existing prompt injection attacks either assume that the entire input data comes from a single source under the attacker's control or ignore the uncertainty in the ordering of segments from different sources. As a result, their success is limited in domains involving multi-source data.
  In this work, we propose ObliInjection, the first prompt injection attack targeting LLM applications and agents with multi-source input data. ObliInjection introduces two key technical innovations: the order-oblivious loss, which quantifies the likelihood that the LLM will complete the attacker-chosen task regardless of how the clean and contaminated segments are ordered; and the orderGCG algorithm, which is tailored to minimize the order-oblivious loss and optimize the contaminated segments. Comprehensive experiments across three datasets spanning diverse application domains and twelve LLMs demonstrate that ObliInjection is highly effective, even when only one out of 6-100 segments in the input data is contaminated.

</details>


### [17] [Proof of Trusted Execution: A Consensus Paradigm for Deterministic Blockchain Finality](https://arxiv.org/abs/2512.09409)
*Kyle Habib,Vladislav Kapitsyn,Giovanni Mazzeo,Faisal Mehrban*

Main category: cs.CR

TL;DR: 提出PoTE共识协议，通过可信执行环境替代传统PoW和PoS，实现单轮验证、无分叉的高性能共识


<details>
  <summary>Details</summary>
Motivation: 现有区块链共识协议存在结构性限制：PoW能耗高、延迟大；PoS存在权益集中、长程攻击等安全漏洞，且性能受限于时隙时间和多轮委员会投票

Method: 提出PoTE共识范式，验证者在异构VM-based TEEs中运行相同规范程序，生成厂商支持的证明，将代码哈希与区块内容绑定。利用确定性执行和公开随机性派生唯一提议者

Result: PoTE避免分叉，消除时隙时间瓶颈，单轮验证即可提交区块，满足Trillion去中心化交易所的高吞吐量需求

Conclusion: PoTE通过可信执行环境实现高效共识，克服传统共识协议的结构性限制，为高性能区块链应用提供可行方案

Abstract: Current blockchain consensus protocols -- notably, Proof of Work (PoW) and Proof of Stake (PoS) -- deliver global agreement but exhibit structural constraints. PoW anchors security in heavy computation, inflating energy use and imposing high confirmation latency. PoS improves efficiency but introduces stake concentration, long-range and "nothing-at-stake" vulnerabilities, and a hard performance ceiling shaped by slot times and multi-round committee voting. In this paper, we propose Proof of Trusted Execution (PoTE), a consensus paradigm where agreement emerges from verifiable execution rather than replicated re-execution. Validators operate inside heterogeneous VM-based TEEs, each running the same canonical program whose measurement is publicly recorded, and each producing vendor-backed attestations that bind the enclave code hash to the block contents. Because the execution is deterministic and the proposer is uniquely derived from public randomness, PoTE avoids forks, eliminates slot.time bottlenecks, and commits blocks in a single round of verification. We present the design of a PoTE consensus client, describe our reference implementation, and evaluate its performance against the stringent throughput requirements of the Trillion decentralized exchange.

</details>


### [18] [Reference Recommendation based Membership Inference Attack against Hybrid-based Recommender Systems](https://arxiv.org/abs/2512.09442)
*Xiaoxiao Chi,Xuyun Zhang,Yan Wang,Hongsheng Hu,Wanchun Dou*

Main category: cs.CR

TL;DR: 该论文提出了一种针对混合推荐系统的成员推理攻击方法，利用个性化推荐特性来推断用户数据是否被用于训练推荐系统。


<details>
  <summary>Details</summary>
Motivation: 现有成员推理攻击方法未能充分利用推荐系统的独特特性，仅适用于包含两种推荐算法的混合系统，无法有效攻击基于相同算法同时利用用户-物品历史交互和用户/物品属性的混合推荐系统。

Method: 提出基于度量的成员推理攻击方法：利用个性化特性获取目标用户的参考推荐，然后提出相对成员度量，结合目标用户的历史交互、目标推荐和参考推荐来推断用户数据的成员状态。

Result: 通过理论和实证研究证明了所提出的基于度量的成员推理攻击在混合推荐系统上的有效性。

Conclusion: 混合推荐系统中的个性化特性会影响成员推理攻击的效果，提出的方法填补了现有攻击方法在混合推荐系统上的研究空白。

Abstract: Recommender systems have been widely deployed across various domains such as e-commerce and social media, and intelligently suggest items like products and potential friends to users based on their preferences and interaction history, which are often privacy-sensitive. Recent studies have revealed that recommender systems are prone to membership inference attacks (MIAs), where an attacker aims to infer whether or not a user's data has been used for training a target recommender system. However, existing MIAs fail to exploit the unique characteristic of recommender systems, and therefore are only applicable to mixed recommender systems consisting of two recommendation algorithms. This leaves a gap in investigating MIAs against hybrid-based recommender systems where the same algorithm utilizing user-item historical interactions and attributes of users and items serves and produces personalised recommendations. To investigate how the personalisation in hybrid-based recommender systems influences MIA, we propose a novel metric-based MIA. Specifically, we leverage the characteristic of personalisation to obtain reference recommendation for any target users. Then, a relative membership metric is proposed to exploit a target user's historical interactions, target recommendation, and reference recommendation to infer the membership of the target user's data. Finally, we theoretically and empirically demonstrate the efficacy of the proposed metric-based MIA on hybrid-based recommender systems.

</details>


### [19] [Chasing Shadows: Pitfalls in LLM Security Research](https://arxiv.org/abs/2512.09549)
*Jonathan Evertz,Niklas Risse,Nicolai Neuer,Andreas Müller,Philipp Normann,Gaetano Sapia,Srishti Gupta,David Pape,Soumya Shaw,Devansh Srivastav,Christian Wressnegger,Erwin Quiring,Thorsten Eisenhofer,Daniel Arp,Lea Schönherr*

Main category: cs.CR

TL;DR: 该研究识别了LLM在安全研究中存在的9个常见陷阱，分析了72篇顶会论文发现每篇至少存在一个陷阱，且大多数未被识别，通过案例研究展示了这些陷阱的实际影响，并提出了改进指南。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在安全研究中的应用日益广泛，但其独特特性对研究的可复现性、严谨性和评估范式提出了挑战。现有关于机器学习研究陷阱的研究主要针对传统模型，未能充分覆盖LLM带来的新问题。

Method: 1. 识别了9个与LLM相关的常见研究陷阱，覆盖数据收集、预训练、微调、提示和评估全过程；2. 分析了2023-2024年安全与软件工程顶会的72篇同行评审论文；3. 通过4个实证案例研究展示单个陷阱的实际影响。

Result: 1. 所有72篇论文都至少包含一个陷阱；2. 每个陷阱都在多篇论文中出现；3. 只有15.7%的陷阱被明确讨论，大多数未被识别；4. 案例研究表明这些陷阱可能导致评估误导、性能虚高或可复现性受损。

Conclusion: LLM在安全研究中存在系统性研究陷阱问题，大多数未被研究者识别。需要提高对这些陷阱的认识，并采取具体措施来确保研究的严谨性、可复现性和有效性。论文提供了可操作的指南来支持未来研究。

Abstract: Large language models (LLMs) are increasingly prevalent in security research. Their unique characteristics, however, introduce challenges that undermine established paradigms of reproducibility, rigor, and evaluation. Prior work has identified common pitfalls in traditional machine learning research, but these studies predate the advent of LLMs. In this paper, we identify \emph{nine} common pitfalls that have become (more) relevant with the emergence of LLMs and that can compromise the validity of research involving them. These pitfalls span the entire computation process, from data collection, pre-training, and fine-tuning to prompting and evaluation.
  We assess the prevalence of these pitfalls across all 72 peer-reviewed papers published at leading Security and Software Engineering venues between 2023 and 2024. We find that every paper contains at least one pitfall, and each pitfall appears in multiple papers. Yet only 15.7\% of the present pitfalls were explicitly discussed, suggesting that the majority remain unrecognized. To understand their practical impact, we conduct four empirical case studies showing how individual pitfalls can mislead evaluation, inflate performance, or impair reproducibility. Based on our findings, we offer actionable guidelines to support the community in future work.

</details>


### [20] [Defining Cost Function of Steganography with Large Language Models](https://arxiv.org/abs/2512.09769)
*Hanzhou Wu,Yige Wang*

Main category: cs.CR

TL;DR: 该论文首次尝试使用大语言模型定义隐写术的成本函数，通过两阶段策略（LLM引导的程序合成+进化搜索）自动生成优于现有方法的成本函数。


<details>
  <summary>Details</summary>
Motivation: 传统隐写术成本函数设计严重依赖专家知识或需要大规模数据集进行成本学习，作者希望探索使用大语言模型自动设计成本函数的新方法。

Method: 采用两阶段策略：第一阶段通过结构化提示从LLM响应中合成计算机程序形式的成本函数，并用预训练的隐写分析模型评估；第二阶段为每个候选成本函数重新训练隐写分析模型，根据检测准确率确定最优成本函数，通过迭代方式收集最佳成本函数。

Result: 实验表明，该方法设计的成本函数在抵抗隐写分析工具方面显著优于现有工作，验证了所提方法的优越性。

Conclusion: 这是首次将LLMs应用于隐写术高级成本函数设计的工作，为隐写术设计提供了新视角，可能启发进一步研究。

Abstract: In this paper, we make the first attempt towards defining cost function of steganography with large language models (LLMs), which is totally different from previous works that rely heavily on expert knowledge or require large-scale datasets for cost learning. To achieve this goal, a two-stage strategy combining LLM-guided program synthesis with evolutionary search is applied in the proposed method. In the first stage, a certain number of cost functions in the form of computer program are synthesized from LLM responses to structured prompts. These cost functions are then evaluated with pretrained steganalysis models so that candidate cost functions suited to steganography can be collected. In the second stage, by retraining a steganalysis model for each candidate cost function, the optimal cost function(s) can be determined according to the detection accuracy. This two-stage strategy is performed by an iterative fashion so that the best cost function can be collected at the last iteration. Experiments show that the proposed method enables LLMs to design new cost functions of steganography that significantly outperform existing works in terms of resisting steganalysis tools, which verifies the superiority of the proposed method. To the best knowledge of the authors, this is the first work applying LLMs to the design of advanced cost function of steganography, which presents a novel perspective for steganography design and may shed light on further research.

</details>


### [21] [FlipLLM: Efficient Bit-Flip Attacks on Multimodal LLMs using Reinforcement Learning](https://arxiv.org/abs/2512.09872)
*Khurram Khalil,Khaza Anuarul Hoque*

Main category: cs.CR

TL;DR: FlipLLM：基于强化学习的通用框架，用于高效发现大语言模型和视觉语言模型中的比特翻转攻击漏洞，比现有方法快2.5倍，并能指导硬件级防御。


<details>
  <summary>Details</summary>
Motivation: 当前生成式AI模型（如LLMs和VLMs）虽然性能优异，但对硬件级比特翻转攻击（BFA）存在脆弱性。现有BFA发现方法缺乏通用性和可扩展性，难以在合理时间内分析现代基础模型的庞大参数空间和复杂依赖关系。

Method: 提出FlipLLM框架，将BFA发现建模为序列决策问题，结合敏感性引导的层剪枝和Q学习，高效识别能引发灾难性故障的最小、高影响力比特集合。

Result: FlipLLM在多种模型（GPT-2 Large、LLaMA 3.1 8B、DeepSeek-V2 7B、LLaVA 1.6）和数据集（MMLU、MMLU-Pro、VQAv2、TextVQA）上验证有效，比SOTA方法快2.5倍。仅翻转5比特就能使LLaMA 3.1 8B准确率从69.9%降至0.2%，翻转7比特使LLaVA的VQA得分从78%降至近0%。

Conclusion: FlipLLM为语言和多模态基础模型的BFA漏洞评估提供了首个可扩展、自适应的方法论，其识别的关键比特位置能有效指导硬件级防御机制（如ECC SECDED）的部署，具有实际应用价值。

Abstract: Generative Artificial Intelligence models, such as Large Language Models (LLMs) and Large Vision Models (VLMs), exhibit state-of-the-art performance but remain vulnerable to hardware-based threats, specifically bit-flip attacks (BFAs). Existing BFA discovery methods lack generalizability and struggle to scale, often failing to analyze the vast parameter space and complex interdependencies of modern foundation models in a reasonable time. This paper proposes FlipLLM, a reinforcement learning (RL) architecture-agnostic framework that formulates BFA discovery as a sequential decision-making problem. FlipLLM combines sensitivity-guided layer pruning with Q-learning to efficiently identify minimal, high-impact bit sets that can induce catastrophic failure. We demonstrate the effectiveness and generalizability of FlipLLM by applying it to a diverse set of models, including prominent text-only LLMs (GPT-2 Large, LLaMA 3.1 8B, and DeepSeek-V2 7B), VLMs such as LLaVA 1.6, and datasets, such as MMLU, MMLU-Pro, VQAv2, and TextVQA. Our results show that FlipLLM can identify critical bits that are vulnerable to BFAs up to 2.5x faster than SOTA methods. We demonstrate that flipping the FlipLLM-identified bits plummets the accuracy of LLaMA 3.1 8B from 69.9% to ~0.2%, and for LLaVA's VQA score from 78% to almost 0%, by flipping as few as 5 and 7 bits, respectively. Further analysis reveals that applying standard hardware protection mechanisms, such as ECC SECDED, to the FlipLLM-identified bit locations completely mitigates the BFA impact, demonstrating the practical value of our framework in guiding hardware-level defenses. FlipLLM offers the first scalable and adaptive methodology for exploring the BFA vulnerability of both language and multimodal foundation models, paving the way for comprehensive hardware-security evaluation.

</details>


### [22] [ByteShield: Adversarially Robust End-to-End Malware Detection through Byte Masking](https://arxiv.org/abs/2512.09883)
*Daniel Gibert,Felip Manyà*

Main category: cs.CR

TL;DR: 提出一种基于字节级掩码的端到端恶意软件检测器防御机制，通过生成多个掩码版本、独立分类和阈值投票来对抗对抗性攻击，优于随机平滑防御。


<details>
  <summary>Details</summary>
Motivation: 现有端到端恶意软件检测器容易受到对抗性攻击，而基于随机化和去随机化平滑的防御技术仍无法有效应对插入大型对抗性载荷的攻击，需要更有效的防御机制。

Method: 提出确定性掩码策略，在字节级别对输入文件进行系统性的掩码处理，生成多个掩码版本，每个版本独立分类，然后通过基于阈值的投票机制产生最终分类结果。

Result: 在EMBER和BODMAS数据集上的实验结果表明，该防御机制优于随机化和去随机化平滑防御，能够有效对抗多种功能保持操作生成的对抗性样本，同时在干净样本上保持高准确率。

Conclusion: 提出的基于字节级掩码的防御机制能够有效增强端到端恶意软件检测器对抗对抗性攻击的能力，通过确定性掩码策略确保对文件的全面覆盖，在最佳情况下完全遮蔽对抗性载荷，最坏情况下也能减少其影响。

Abstract: Research has proven that end-to-end malware detectors are vulnerable to adversarial attacks. In response, the research community has proposed defenses based on randomized and (de)randomized smoothing. However, these techniques remain susceptible to attacks that insert large adversarial payloads. To address these limitations, we propose a novel defense mechanism designed to harden end-to-end malware detectors by leveraging masking at the byte level. This mechanism operates by generating multiple masked versions of the input file, independently classifying each version, and then applying a threshold-based voting mechanism to produce the final classification. Key to this defense is a deterministic masking strategy that systematically strides a mask across the entire input file. Unlike randomized smoothing defenses, which randomly mask or delete bytes, this structured approach ensures coverage of the file over successive versions. In the best-case scenario, this strategy fully occludes the adversarial payload, effectively neutralizing its influence on the model's decision. In the worst-case scenario, it partially occludes the adversarial payload, reducing its impact on the model's predictions. By occluding the adversarial payload in one or more masked versions, this defense ensures that some input versions remain representative of the file's original intent, allowing the voting mechanism to suppress the influence of the adversarial payload. Results achieved on the EMBER and BODMAS datasets demonstrate the suitability of our defense, outperforming randomized and (de)randomized smoothing defenses against adversarial examples generated with a wide range of functionality-preserving manipulations while maintaining high accuracy on clean examples.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [23] [Llama-based source code vulnerability detection: Prompt engineering vs Fine tuning](https://arxiv.org/abs/2512.09006)
*Dyna Soumhane Ouchebara,Stéphane Dupont*

Main category: cs.SE

TL;DR: 研究探索使用Llama-3.1 8B大语言模型进行源代码漏洞检测，测试了多种微调和提示工程方法，发现微调对任务解决至关重要，其中提出的双微调方法表现良好。


<details>
  <summary>Details</summary>
Motivation: 随着软件开发周期加速，软件漏洞数量持续增加，自动化源代码漏洞检测变得至关重要。大语言模型被认为是当前性能最好的AI模型之一，研究旨在探索其在漏洞检测任务中的表现，并通过各种技术提升其效果。

Method: 使用开源的Llama-3.1 8B模型，从BigVul和PrimeVul数据集中提取源代码样本。探索了多种微调和提示工程设置，特别提出了新颖的双微调方法，并测试了较少研究的测试时微调方法。还使用了检索增强生成作为示例选择技术。

Result: 研究发现微调对解决漏洞检测任务至关重要，双微调方法表现良好，Llama模型在漏洞检测方面具有潜力。虽然提示工程效果不佳，但检索增强生成作为示例选择技术表现相对较好。

Conclusion: 研究部分问题得到解答，但仍有许多问题待解决，为未来工作提供了多个方向。研究强调了微调的重要性，展示了双微调方法的性能，以及Llama模型在源代码漏洞检测任务中的潜力。

Abstract: The significant increase in software production, driven by the acceleration of development cycles over the past two decades, has led to a steady rise in software vulnerabilities, as shown by statistics published yearly by the CVE program. The automation of the source code vulnerability detection (CVD) process has thus become essential, and several methods have been proposed ranging from the well established program analysis techniques to the more recent AI-based methods. Our research investigates Large Language Models (LLMs), which are considered among the most performant AI models to date, for the CVD task. The objective is to study their performance and apply different state-of-the-art techniques to enhance their effectiveness for this task. We explore various fine-tuning and prompt engineering settings. We particularly suggest one novel approach for fine-tuning LLMs which we call Double Fine-tuning, and also test the understudied Test-Time fine-tuning approach. We leverage the recent open-source Llama-3.1 8B, with source code samples extracted from BigVul and PrimeVul datasets. Our conclusions highlight the importance of fine-tuning to resolve the task, the performance of Double tuning, as well as the potential of Llama models for CVD. Though prompting proved ineffective, Retrieval augmented generation (RAG) performed relatively well as an example selection technique. Overall, some of our research questions have been answered, and many are still on hold, which leaves us many future work perspectives. Code repository is available here: https://github.com/DynaSoumhaneOuchebara/Llama-based-vulnerability-detection.

</details>


### [24] [TritonForge: Profiling-Guided Framework for Automated Triton Kernel Optimization](https://arxiv.org/abs/2512.09196)
*Haonan Li,Keyu Man,Partha Kanuparthy,Hanning Chen,Wei Sun,Sreen Tallam,Chenguang Zhu,Kevin Zhu,Zhiyun Qian*

Main category: cs.SE

TL;DR: TritonForge是一个基于性能剖析的自动化Triton GPU内核优化框架，通过集成内核分析、运行时剖析和迭代代码转换，实现了高达5倍的性能提升。


<details>
  <summary>Details</summary>
Motivation: 尽管Triton DSL简化了GPU内核开发，但要达到专家级性能仍需深入了解GPU架构和底层性能权衡，这是一个劳动密集型任务。

Method: TritonForge采用剖析引导的框架，集成内核分析、运行时剖析和迭代代码转换，利用数据驱动的剖析反馈识别性能瓶颈，提出针对性代码修改并自动评估效果。原型系统使用大语言模型辅助代码推理和转换，但框架保持模块化和模型无关性。

Result: 在不同内核类型和GPU架构上，TritonForge相比基线实现实现了高达5倍的性能提升，平均成功率为1.76倍。

Conclusion: TritonForge为自动化GPU性能优化提供了基础框架，展示了剖析引导方法在减少人工优化工作量方面的潜力。

Abstract: High-performance GPU kernel optimization remains a critical yet labor-intensive task in modern machine learning workloads. Although Triton, a domain-specific language for GPU programming, enables developers to write efficient kernels with concise code, achieving expert-level performance still requires deep understanding of GPU architectures and low-level performance trade-offs. We present TritonForge, a profiling-guided framework for automated Triton kernel optimization. TritonForge integrates kernel analysis, runtime profiling, and iterative code transformation to streamline the optimization process. By incorporating data-driven feedback from profiling results, the system identifies performance bottlenecks, proposes targeted code modifications, and evaluates their impact automatically. While our prototype leverages large language models (LLMs) to assist in code reasoning and transformation, the framework remains modular and model-agnostic. Across diverse kernel types and GPU architectures, TritonForge achieves up to 5x performance improvement over baseline implementations and on average 1.76x of the cases are successful, providing a foundation for future research in automated GPU performance optimization.

</details>


### [25] [Bug Priority Change Prediction: An Exploratory Study on Apache Software](https://arxiv.org/abs/2512.09216)
*Guangzong Cai,Zengyang Li,Peng Liang,Ran Mo,Hui Liu,Yutao Ma*

Main category: cs.SE

TL;DR: 该研究提出了一种基于bug修复演化特征和类别不平衡处理策略的两阶段bug报告优先级变化预测方法，在32个Apache项目数据集上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 在JIRA等issue跟踪系统中，bug报告的优先级会随着修复过程而变化，但手动评估优先级变化依赖开发者主观判断且耗时费力，容易导致错误评估而影响及时修复。目前缺乏关于bug优先级变化预测的研究。

Method: 将bug生命周期分为报告阶段和修复阶段，为每个阶段构建优先级变化预测模型。采用bug修复演化特征和类别不平衡处理策略来提升模型性能。

Result: 在32个Apache项目数据集上的实验表明，所提出的bug修复演化特征和类别不平衡处理策略能有效提升预测模型性能。报告阶段模型的F1-score达到0.798，修复阶段模型的F1-weighted和F1-macro分别为0.712和0.613。跨项目适用性分析显示模型在不同项目间性能差异较大但整体表现良好，不同优先级水平的预测性能相对一致且较高。

Conclusion: 提出的两阶段bug优先级变化预测方法能有效预测bug优先级变化，为自动化优先级管理提供了可行方案，有助于提高bug修复效率。

Abstract: Bug fixing is a critical activity in the software development process. In issue tracking systems such as JIRA, each bug report is assigned a priority level to indicate the urgency and importance level of the bug. The priority may change during the bug fixing process, indicating that the urgency and importance level of the bug will change with the bug fixing. However, manually evaluating priority changes for bugs is a tedious process that heavily relies on the subjective judgment of developers and project managers, leading to incorrect priority changes and thus hindering timely bug fixes. Given the lack of research on bug priority change prediction, we propose a novel two-phase bug report priority change prediction method based on bug fixing evolution features and class imbalance handling strategy. Specifically, we divided the bug lifecycle into two phases: bug reporting and bug fixing, and constructed bug priority change prediction models for each phase. To evaluate the performance of our method, we conducted experiments on a bug dataset constructed from 32 non-trivial Apache projects. The experimental results show that our proposed bug fixing evolution features and the adopted class imbalance handling strategy can effectively improve the performance of prediction models. The F1-score of the prediction model constructed for the bug reporting phase reached 0.798, while the F1-weighted and F1-macro of the prediction model constructed for the bug fixing phase were 0.712 and 0.613, respectively. Furthermore, we explored the cross-project applicability of our prediction models and their performance at different priority levels. The findings indicate large variations in model performance across different projects, although the overall scores remain decent. Meanwhile, the predictive performance across various priority levels remained relatively consistently high.

</details>


### [26] [Explainable Verification of Hierarchical Workflows Mined from Event Logs with Shapley Values](https://arxiv.org/abs/2512.09562)
*Radoslaw Klimek,Jakub Blazowski*

Main category: cs.SE

TL;DR: 将工作流挖掘转化为逻辑规范分析，结合Shapley值量化工作流元素贡献，实现可解释的工作流分析


<details>
  <summary>Details</summary>
Motivation: 传统工作流挖掘虽然能从事件日志中发现分层过程树，但无法解释模型为何满足或违反逻辑属性，以及单个元素如何影响整体行为。需要一种方法来理解工作流模型的内部机制和元素贡献。

Method: 1) 将挖掘的工作流转换为逻辑规范；2) 使用自动定理证明器分析可满足性、活性和安全性等属性；3) 基于合作博弈论的Shapley值将结果归因于工作流元素并量化其贡献。

Result: 在基准数据集上的实验表明，该方法能够：1) 识别关键节点；2) 揭示冗余结构；3) 暴露有害结构。为可解释的工作流分析提供了有效工具。

Conclusion: 该方法为可解释的工作流分析开辟了新方向，对软件工程实践具有直接相关性，支持合规检查、流程优化、冗余减少以及下一代流程挖掘工具的设计。

Abstract: Workflow mining discovers hierarchical process trees from event logs, but it remains unclear why such models satisfy or violate logical properties, or how individual elements contribute to overall behavior. We propose to translate mined workflows into logical specifications and analyze properties such as satisfiability, liveness, and safety with automated theorem provers. On this basis, we adapt Shapley values from cooperative game theory to attribute outcomes to workflow elements and quantify their contributions. Experiments on benchmark datasets show that this combination identifies critical nodes, reveals redundancies, and exposes harmful structures. This outlines a novel direction for explainable workflow analysis with direct relevance to software engineering practice, supporting compliance checks, process optimization, redundancy reduction, and the design of next-generation process mining tools.

</details>


### [27] [Model management to support systems engineering workflows using ontology-based knowledge graphs](https://arxiv.org/abs/2512.09596)
*Arkadiusz Ryś,Lucas Lima,Joeri Exelmans,Dennis Janssens,Hans Vangheluwe*

Main category: cs.SE

TL;DR: 提出一个基于本体的框架来管理CPS工作流执行产生的建模工件，通过知识图谱存储和推理系统工程数据，并开发了相应工具支持工作流设计、执行和工件管理。


<details>
  <summary>Details</summary>
Motivation: 随着系统工程从文档中心转向基于模型的方法，数字化带来了存储和访问等挑战。在CPS开发中，不同领域的专家使用多种形式化方法执行复杂工作流，存储这些工作流知识可以减少开发工作量，支持可重复性和数据推理。

Method: 1. 使用OML（本体建模语言）形式化定义工作流基本概念、相关形式化方法和工件；2. 构建包含系统工程数据的知识图谱；3. 开发支持工作流设计、执行和工件存储的工具，包括版本控制、查询和推理功能；4. 在真实世界的驱动系统智能传感器系统开发场景中应用该框架。

Result: 该框架不仅帮助系统工程师解决了存储和版本控制等基本困难，还减少了访问相关信息所需的时间，并能从知识图谱中推断出新知识。

Conclusion: 提出的基于本体的框架有效支持了CPS工作流工件的管理，通过知识图谱和配套工具提升了系统工程开发的效率和知识推理能力。

Abstract: System engineering has been shifting from document-centric to model-based approaches, where assets are becoming more and more digital. Although digitisation conveys several benefits, it also brings several concerns (e.g., storage and access) and opportunities. In the context of Cyber- Physical Systems (CPS), we have experts from various domains executing complex workflows and manipulating models in a plethora of different formalisms, each with their own methods, techniques and tools. Storing knowledge on these workflows can reduce considerable effort during system development not only to allow their repeatability and replicability but also to access and reason on data generated by their execution. In this work, we propose a framework to manage modelling artefacts generated from workflow executions. The basic workflow concepts, related formalisms and artefacts are formally defined in an ontology specified in OML (Ontology Modelling Language). This ontology enables the construction of a knowledge graph that contains system engineering data to which we can apply reasoning. We also developed several tools to support system engineering during the design of workflows, their enactment, and artefact storage, considering versioning, querying and reasoning on the stored data. These tools also hide the complexity of manipulating the knowledge graph directly. Finally, we have applied our proposed framework in a real-world system development scenario of a drivetrain smart sensor system. Results show that our proposal not only helped the system engineer with fundamental difficulties like storage and versioning but also reduced the time needed to access relevant information and new knowledge that can be inferred from the knowledge graph.

</details>


### [28] [LogICL: Distilling LLM Reasoning to Bridge the Semantic Gap in Cross-Domain Log Anomaly Detection](https://arxiv.org/abs/2512.09627)
*Jingwei Ye,Zhi Wang,Chenbin Su,Jieshuai Yang,Jiayi Ding,Chunbo Liu,Ge Chu*

Main category: cs.SE

TL;DR: LogICL：一个将大语言模型推理能力蒸馏到轻量级编码器的框架，用于解决跨域日志异常检测中的冷启动问题，通过推理感知的演示选择和语义对齐实现高效部署。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的日志异常检测模型需要大量资源和标注数据，在目标域日志稀缺时存在冷启动问题。现有的跨域方法依赖表面词汇相似性，难以捕捉结构差异下的潜在语义等价性。

Method: 提出LogICL框架，训练时构建delta矩阵衡量演示对零样本推理的效用，通过多目标损失优化编码器（包括ICL引导项、最大均值差异和对比损失）。推理时，编码器基于语义相似性和delta分数检索推理感知演示，结合冻结LLM进行上下文学习。

Result: 在少样本和零样本跨域基准测试中，LogICL实现了最先进的性能，能够超越表面词汇相似性，有效捕捉潜在语义等价性，实现快速部署。

Conclusion: LogICL通过将LLM推理能力蒸馏到轻量级编码器，解决了跨域日志异常检测中的冷启动问题，实现了高效、准确且可解释的检测，为异构系统提供了有效的解决方案。

Abstract: Effective log anomaly detection is critical to sustaining reliability in large-scale IT infrastructures. Transformer-based models require substantial resources and labeled data, exacerbating the cold-start problem in target domains where logs are scarce. Existing cross-domain methods leverage source logs but struggle with generalization due to reliance on surface lexical similarity, failing to capture latent semantic equivalence amid structural divergences. To address this, we propose LogICL, a framework distilling Large Language Model (LLM) reasoning into a lightweight encoder for cross-domain anomaly detection. During training, LogICL constructs a delta matrix measuring the utility of demonstrations selected via Maximal Marginal Relevance relative to zero-shot inference. The encoder is optimized via a multi-objective loss comprising an ICL-Guided term that aligns representations based on reasoning assistance utility, maximum mean discrepancy for domain alignment, and supervised contrastive loss. At inference, the optimized encoder retrieves reasoning-aware demonstrations using semantic similarity and delta scores, enabling frozen-LLM in-context learning with Chain-of-Thought for accurate and interpretable detection. Experiments on few-shot and zero-shot cross-domain benchmarks confirm LogICL achieves state-of-the-art performance across heterogeneous systems. Further analysis via visualizations and case studies confirms LogICL bridges the semantic gap beyond surface lexical similarity, effectively capturing latent semantic equivalence for rapid deployment.

</details>


### [29] [Understanding Chain-of-Thought Effectiveness in Code Generation: An Empirical and Information-Theoretic Analysis](https://arxiv.org/abs/2512.09679)
*Naizhu Jin,Zhong Li,Guang Yang,Tian Zhang,Qingkai Zeng*

Main category: cs.SE

TL;DR: 本文通过信息论视角系统研究CoT提示在代码生成中的作用机制，发现结构化CoT方法显著提升性能，且效果取决于模型容量和语言类型系统。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在代码生成上表现优异，但Chain-of-Thought提示如何帮助代码生成的机制尚不明确，需要系统性的实证和信息论研究来理解其有效性。

Method: 使用条件互信息I(Y;C|X)作为概念框架，评估五种CoT范式（Zero-Shot、Zero-Shot CoT、Self-Planning、Structured CoT、Reasoning-CoT），在六个Python基准、一个包含12种编程语言的多语言基准以及六个参数规模从7B到480B的模型上进行系统实验。

Result: 外部引导的CoT持续优于直接生成，结构化方法平均提升Pass@1 5-12%，同时比反思推理使用更少的token；CoT效果取决于语言类型系统和模型容量；推理质量至关重要：高质量结构化CoT比轻量级替代方案准确率显著更高，而简单的Zero-Shot CoT甚至可能降低性能。

Conclusion: 研究结果为基于模型容量、语言特性和任务复杂度选择CoT策略提供了实用指导，强调了结构化高质量推理在代码生成中的重要性。

Abstract: Large language models (LLMs) achieve strong performance on code generation, but the mechanisms by which Chain-of-Thought (CoT) prompting helps remain unclear. We present a systematic empirical and information-theoretic study of CoT effectiveness in neural code generation, evaluating five paradigms (Zero-Shot, Zero-Shot CoT, Self-Planning, Structured CoT, Reasoning-CoT) across six Python benchmarks, a multilingual benchmark with 12 programming languages, and six models from 7B to 480B parameters, using conditional mutual information $I(Y;C|X)$ as a conceptual lens. Our results show that externally guided CoT consistently outperforms direct generation, with structured methods improving Pass@1 by 5--12\% on average while using substantially fewer tokens than reflective reasoning, and that CoT benefits depend on language type systems and model capacity. We further find that reasoning \emph{quality} is critical: high-quality structured CoT from strong generators yields significantly higher accuracy than lightweight alternatives with the same template, whereas naive Zero-Shot CoT can even degrade performance. These findings provide practical guidance for choosing CoT strategies based on model capacity, language characteristics, and task complexity.

</details>


### [30] [Quantifying Uncertainty in Machine Learning-Based Pervasive Systems: Application to Human Activity Recognition](https://arxiv.org/abs/2512.09775)
*Vladimir Balditsyn,Philippe Lalanda,German Vega,Stéphanie Chollet*

Main category: cs.SE

TL;DR: 该论文提出了一种量化机器学习系统不确定性的方法，通过运行时评估模型预测的相关性，并在人类活动识别领域进行了应用验证。


<details>
  <summary>Details</summary>
Motivation: 机器学习系统与传统软件不同，无法通过严格测试保证无错误运行，其运行边界不确定，需要量化不确定性来增强系统可靠性。

Method: 提出量化ML系统不确定性的方法，通过选择和联合使用一组技术来评估模型预测在运行时的相关性。

Result: 在人类活动识别领域应用并评估了该方法，结果证明了该方法的有效性，并为领域专家提供了详细的分析支持。

Conclusion: 提出的不确定性量化方法对于提高机器学习系统的可靠性和可解释性具有重要意义，特别是在异构和动态变化的应用领域中。

Abstract: The recent convergence of pervasive computing and machine learning has given rise to numerous services, impacting almost all areas of economic and social activity. However, the use of AI techniques precludes certain standard software development practices, which emphasize rigorous testing to ensure the elimination of all bugs and adherence to well-defined specifications. ML models are trained on numerous high-dimensional examples rather than being manually coded. Consequently, the boundaries of their operating range are uncertain, and they cannot guarantee absolute error-free performance. In this paper, we propose to quantify uncertainty in ML-based systems. To achieve this, we propose to adapt and jointly utilize a set of selected techniques to evaluate the relevance of model predictions at runtime. We apply and evaluate these proposals in the highly heterogeneous and evolving domain of Human Activity Recognition (HAR). The results presented demonstrate the relevance of the approach, and we discuss in detail the assistance provided to domain experts.

</details>
