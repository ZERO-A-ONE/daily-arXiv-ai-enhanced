{"id": "2512.11223", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.11223", "abs": "https://arxiv.org/abs/2512.11223", "authors": ["Sasara Shimizu", "Yoshiki Higo"], "title": "Coverage Isn't Enough: SBFL-Driven Insights into Manually Created vs. Automatically Generated Tests", "comment": null, "summary": "The testing phase is an essential part of software development, but manually creating test cases can be time-consuming. Consequently, there is a growing need for more efficient testing methods. To reduce the burden on developers, various automated test generation tools have been developed, and several studies have been conducted to evaluate the effectiveness of the tests they produce. However, most of these studies focus primarily on coverage metrics, and only a few examine how well the tests support fault localization-particularly using artificial faults introduced through mutation testing. In this study, we compare the SBFL (Spectrum-Based Fault Localization) score and code coverage of automatically generated tests with those of manually created tests. The SBFL score indicates how accurately faults can be localized using SBFL techniques. By employing SBFL score as an evaluation metric-an approach rarely used in prior studies on test generation-we aim to provide new insights into the respective strengths and weaknesses of manually created and automatically generated tests. Our experimental results show that automatically generated tests achieve higher branch coverage than manually created tests, but their SBFL score is lower, especially for code with deeply nested structures. These findings offer guidance on how to effectively combine automatically generated and manually created testing approaches.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u4e0e\u624b\u52a8\u521b\u5efa\u6d4b\u8bd5\u5728\u6545\u969c\u5b9a\u4f4d\u80fd\u529b\uff08SBFL\u5206\u6570\uff09\u548c\u4ee3\u7801\u8986\u76d6\u7387\u65b9\u9762\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u81ea\u52a8\u6d4b\u8bd5\u8986\u76d6\u7387\u66f4\u9ad8\u4f46\u6545\u969c\u5b9a\u4f4d\u80fd\u529b\u8f83\u5dee\uff0c\u7279\u522b\u662f\u5728\u6df1\u5c42\u5d4c\u5957\u4ee3\u7801\u4e2d\u3002", "motivation": "\u8f6f\u4ef6\u6d4b\u8bd5\u4e2d\u624b\u52a8\u521b\u5efa\u6d4b\u8bd5\u7528\u4f8b\u8017\u65f6\uff0c\u73b0\u6709\u81ea\u52a8\u5316\u6d4b\u8bd5\u751f\u6210\u5de5\u5177\u8bc4\u4f30\u5927\u591a\u5173\u6ce8\u8986\u76d6\u7387\u6307\u6807\uff0c\u5f88\u5c11\u7814\u7a76\u5176\u5728\u6545\u969c\u5b9a\u4f4d\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u4f7f\u7528\u53d8\u5f02\u6d4b\u8bd5\u5f15\u5165\u7684\u4eba\u5de5\u6545\u969c\u3002", "method": "\u4f7f\u7528SBFL\uff08\u57fa\u4e8e\u9891\u8c31\u7684\u6545\u969c\u5b9a\u4f4d\uff09\u5206\u6570\u548c\u4ee3\u7801\u8986\u76d6\u7387\u4f5c\u4e3a\u8bc4\u4f30\u6307\u6807\uff0c\u6bd4\u8f83\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u4e0e\u624b\u52a8\u521b\u5efa\u6d4b\u8bd5\u7684\u6027\u80fd\u3002SBFL\u5206\u6570\u53cd\u6620\u4e86\u4f7f\u7528SBFL\u6280\u672f\u51c6\u786e\u5b9a\u4f4d\u6545\u969c\u7684\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff1a\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u6bd4\u624b\u52a8\u521b\u5efa\u6d4b\u8bd5\u83b7\u5f97\u66f4\u9ad8\u7684\u5206\u652f\u8986\u76d6\u7387\uff0c\u4f46SBFL\u5206\u6570\u8f83\u4f4e\uff0c\u7279\u522b\u662f\u5728\u5177\u6709\u6df1\u5c42\u5d4c\u5957\u7ed3\u6784\u7684\u4ee3\u7801\u4e2d\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u5982\u4f55\u6709\u6548\u7ed3\u5408\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u548c\u624b\u52a8\u521b\u5efa\u6d4b\u8bd5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u6307\u5bfc\uff0c\u5f3a\u8c03\u4e86\u5728\u8bc4\u4f30\u6d4b\u8bd5\u8d28\u91cf\u65f6\u9700\u8981\u8003\u8651\u6545\u969c\u5b9a\u4f4d\u80fd\u529b\u800c\u4e0d\u4ec5\u4ec5\u662f\u8986\u76d6\u7387\u3002"}}
{"id": "2512.11402", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11402", "abs": "https://arxiv.org/abs/2512.11402", "authors": ["Aryan Gupta", "Y. Raghu Reddy"], "title": "REMODEL-LLM: Transforming C code to Java using LLMs", "comment": null, "summary": "The automated translation of C code to Java code is a notoriously difficult task, fraught with challenges stemming from fundamental paradigm shifts (procedural vs. Object Oriented), memory models (manual pointers vs. Garbage Collection), and incompatible data types. This paper investigates the efficacy of 19 small, quantized LLMs (under 20 billion parameters) for the C to Java translation task. We use a novel, hybrid pipeline that leverages Abstract Syntax Trees (ASTs) for semantic decomposition and employs a highly constrained, rule based prompting strategy. The results are stark: a clear multi tiered performance divide emerged. The vast majority of models (Tier 3, e.g., llama3.1, gemma3, starcoder2) failed 100\\% of the tests, proving incapable of generating even basic, runnable Java boilerplate. A small middle tier (Tier 2, e.g., mistral-nemo and mistral) produced runnable code but was plagued by dangerous semantic failures and wrong translations. Only three models (Tier 1: phi4, deepseek-coder-v2, codeqwen) proved viable, passing over 50\\% of the test suite. Even these top models failed on the most complex C concepts, such as function pointers, sizeof, and enum logic, revealing a hard ceiling for the reasoning capabilities of current quantized models.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e8619\u4e2a\u5c0f\u578b\u91cf\u5316LLM\u5728C\u5230Java\u4ee3\u7801\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u53ea\u6709\u5c11\u6570\u6a21\u578b\u80fd\u6709\u6548\u5904\u7406\u8fd9\u4e00\u590d\u6742\u8f6c\u6362\uff0c\u5927\u591a\u6570\u6a21\u578b\u5b8c\u5168\u5931\u8d25\u3002", "motivation": "C\u5230Java\u7684\u81ea\u52a8\u7ffb\u8bd1\u9762\u4e34\u5de8\u5927\u6311\u6218\uff0c\u5305\u62ec\u7f16\u7a0b\u8303\u5f0f\u5dee\u5f02\uff08\u8fc7\u7a0b\u5f0fvs\u9762\u5411\u5bf9\u8c61\uff09\u3001\u5185\u5b58\u6a21\u578b\u5dee\u5f02\uff08\u624b\u52a8\u6307\u9488vs\u5783\u573e\u56de\u6536\uff09\u4ee5\u53ca\u6570\u636e\u7c7b\u578b\u4e0d\u517c\u5bb9\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5c0f\u578b\u91cf\u5316LLM\u5728\u6b64\u4efb\u52a1\u4e0a\u7684\u5b9e\u9645\u6548\u679c\u3002", "method": "\u91c7\u7528\u6df7\u5408\u7ba1\u9053\u65b9\u6cd5\uff1a\u5229\u7528\u62bd\u8c61\u8bed\u6cd5\u6811\uff08AST\uff09\u8fdb\u884c\u8bed\u4e49\u5206\u89e3\uff0c\u5e76\u91c7\u7528\u9ad8\u5ea6\u7ea6\u675f\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u63d0\u793a\u7b56\u7565\u3002\u8bc4\u4f30\u4e8619\u4e2a\u53c2\u6570\u5c11\u4e8e200\u4ebf\u7684\u5c0f\u578b\u91cf\u5316LLM\u3002", "result": "\u7ed3\u679c\u5448\u73b0\u660e\u663e\u7684\u4e09\u7ea7\u6027\u80fd\u5212\u5206\uff1a\u7b2c\u4e09\u7ea7\u6a21\u578b\uff08\u5982llama3.1\u3001gemma3\u3001starcoder2\uff09100%\u6d4b\u8bd5\u5931\u8d25\uff1b\u7b2c\u4e8c\u7ea7\u6a21\u578b\uff08\u5982mistral-nemo\u3001mistral\uff09\u80fd\u751f\u6210\u53ef\u8fd0\u884c\u4ee3\u7801\u4f46\u5b58\u5728\u5371\u9669\u7684\u8bed\u4e49\u9519\u8bef\uff1b\u53ea\u6709\u4e09\u4e2a\u7b2c\u4e00\u7ea7\u6a21\u578b\uff08phi4\u3001deepseek-coder-v2\u3001codeqwen\uff09\u8868\u73b0\u53ef\u884c\uff0c\u901a\u8fc7\u7387\u8d85\u8fc750%\uff0c\u4f46\u4ecd\u65e0\u6cd5\u5904\u7406\u51fd\u6570\u6307\u9488\u3001sizeof\u548c\u679a\u4e3e\u903b\u8f91\u7b49\u590d\u6742C\u6982\u5ff5\u3002", "conclusion": "\u5f53\u524d\u91cf\u5316\u6a21\u578b\u5728C\u5230Java\u7ffb\u8bd1\u4efb\u52a1\u4e0a\u5b58\u5728\u660e\u663e\u7684\u80fd\u529b\u5929\u82b1\u677f\uff0c\u53ea\u6709\u6781\u5c11\u6570\u6a21\u578b\u80fd\u6709\u6548\u5904\u7406\u57fa\u672c\u8f6c\u6362\uff0c\u4f46\u9762\u5bf9\u590d\u6742C\u6982\u5ff5\u65f6\u4ecd\u4f1a\u5931\u8d25\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u5c0f\u578b\u91cf\u5316LLM\u63a8\u7406\u80fd\u529b\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2512.11482", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.11482", "abs": "https://arxiv.org/abs/2512.11482", "authors": ["Melih Catal", "Pooja Rani", "Harald C. Gall"], "title": "Towards Privacy-Preserving Code Generation: Differentially Private Code Language Models", "comment": null, "summary": "Large language models specialized for code (CodeLLMs) have demonstrated remarkable capabilities in generating code snippets, documentation, and test cases. However, despite their promising capabilities, CodeLLMs can inadvertently memorize and reproduce snippets from their training data, which poses risks of privacy breaches and intellectual property violations. These risks restrict the deployment of CodeLLMs in sensitive domains and limit their training datasets to publicly available sources. To mitigate the memorization risk without compromising their task performance, we apply Differential Privacy (DP) to CodeLLMs. To the best of our knowledge, this is the first comprehensive study that systematically evaluates the effectiveness of DP in CodeLLMs. DP adds calibrated noise to the training process to protect individual data points while still allowing the model to learn useful patterns. To this end, we first identify and understand the driving reasons of the memorization behaviour of the CodeLLMs during their fine-tuning. Then, to address this issue, we empirically evaluate the effect of DP on mitigating memorization while preserving code generation capabilities. Our findings show that DP substantially reduces memorization in CodeLLMs across all the tested snippet types. The snippet types most prone to memorization are also the most effectively mitigated by DP. Furthermore, we observe that DP slightly increases perplexity but preserves, and can even enhance, the code generation capabilities of CodeLLMs, which makes it feasible to apply DP in practice without significantly compromising model utility. Finally, we analyze the impact of DP on training efficiency and energy consumption, finding that DP does not significantly affect training time or energy usage, making it a practical choice for privacy-preserving CodeLLMs training.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u8bc4\u4f30\u5dee\u5206\u9690\u79c1\u5728\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0DP\u80fd\u663e\u8457\u964d\u4f4e\u6a21\u578b\u8bb0\u5fc6\u8bad\u7ec3\u6570\u636e\u7247\u6bb5\u7684\u98ce\u9669\uff0c\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u63d0\u5347\u4ee3\u7801\u751f\u6210\u80fd\u529b\uff0c\u4e14\u4e0d\u5f71\u54cd\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u4ee3\u7801\u65f6\u53ef\u80fd\u65e0\u610f\u4e2d\u8bb0\u5fc6\u5e76\u590d\u73b0\u8bad\u7ec3\u6570\u636e\u7247\u6bb5\uff0c\u8fd9\u5e26\u6765\u4e86\u9690\u79c1\u6cc4\u9732\u548c\u77e5\u8bc6\u4ea7\u6743\u4fb5\u6743\u7684\u98ce\u9669\uff0c\u9650\u5236\u4e86\u6a21\u578b\u5728\u654f\u611f\u9886\u57df\u7684\u90e8\u7f72\u548c\u8bad\u7ec3\u6570\u636e\u6765\u6e90\u3002", "method": "\u9996\u5148\u8bc6\u522b\u548c\u7406\u89e3\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u7684\u8bb0\u5fc6\u884c\u4e3a\u539f\u56e0\uff0c\u7136\u540e\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u5dee\u5206\u9690\u79c1\u5728\u7f13\u89e3\u8bb0\u5fc6\u95ee\u9898\u540c\u65f6\u4fdd\u6301\u4ee3\u7801\u751f\u6210\u80fd\u529b\u7684\u6548\u679c\uff0c\u5206\u6790DP\u5bf9\u8bad\u7ec3\u6548\u7387\u548c\u80fd\u8017\u7684\u5f71\u54cd\u3002", "result": "DP\u663e\u8457\u964d\u4f4e\u4e86\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u6240\u6709\u6d4b\u8bd5\u7247\u6bb5\u7c7b\u578b\u7684\u8bb0\u5fc6\uff0c\u6700\u6613\u88ab\u8bb0\u5fc6\u7684\u7247\u6bb5\u7c7b\u578b\u4e5f\u662fDP\u6700\u6709\u6548\u7f13\u89e3\u7684\u7c7b\u578b\uff1bDP\u7565\u5fae\u589e\u52a0\u56f0\u60d1\u5ea6\u4f46\u4fdd\u6301\u751a\u81f3\u63d0\u5347\u4e86\u4ee3\u7801\u751f\u6210\u80fd\u529b\uff1bDP\u4e0d\u5f71\u54cd\u8bad\u7ec3\u65f6\u95f4\u548c\u80fd\u8017\u3002", "conclusion": "\u5dee\u5206\u9690\u79c1\u662f\u4fdd\u62a4\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u9690\u79c1\u7684\u5b9e\u7528\u9009\u62e9\uff0c\u80fd\u6709\u6548\u964d\u4f4e\u8bb0\u5fc6\u98ce\u9669\u800c\u4e0d\u663e\u8457\u5f71\u54cd\u6a21\u578b\u6548\u7528\u3001\u8bad\u7ec3\u6548\u7387\u6216\u80fd\u8017\uff0c\u4e3a\u5728\u654f\u611f\u9886\u57df\u90e8\u7f72CodeLLMs\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2512.10998", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.10998", "abs": "https://arxiv.org/abs/2512.10998", "authors": ["Mohamed Afane", "Abhishek Satyam", "Ke Chen", "Tao Li", "Junaid Farooq", "Juntao Chen"], "title": "SCOUT: A Defense Against Data Poisoning Attacks in Fine-Tuned Language Models", "comment": "9 pages, 3 figures", "summary": "Backdoor attacks create significant security threats to language models by embedding hidden triggers that manipulate model behavior during inference, presenting critical risks for AI systems deployed in healthcare and other sensitive domains. While existing defenses effectively counter obvious threats such as out-of-context trigger words and safety alignment violations, they fail against sophisticated attacks using contextually-appropriate triggers that blend seamlessly into natural language. This paper introduces three novel contextually-aware attack scenarios that exploit domain-specific knowledge and semantic plausibility: the ViralApp attack targeting social media addiction classification, the Fever attack manipulating medical diagnosis toward hypertension, and the Referral attack steering clinical recommendations. These attacks represent realistic threats where malicious actors exploit domain-specific vocabulary while maintaining semantic coherence, demonstrating how adversaries can weaponize contextual appropriateness to evade conventional detection methods. To counter both traditional and these sophisticated attacks, we present \\textbf{SCOUT (Saliency-based Classification Of Untrusted Tokens)}, a novel defense framework that identifies backdoor triggers through token-level saliency analysis rather than traditional context-based detection methods. SCOUT constructs a saliency map by measuring how the removal of individual tokens affects the model's output logits for the target label, enabling detection of both conspicuous and subtle manipulation attempts. We evaluate SCOUT on established benchmark datasets (SST-2, IMDB, AG News) against conventional attacks (BadNet, AddSent, SynBkd, StyleBkd) and our novel attacks, demonstrating that SCOUT successfully detects these sophisticated threats while preserving accuracy on clean inputs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u8bed\u8a00\u6a21\u578b\u540e\u95e8\u653b\u51fb\u7684\u65b0\u578b\u9632\u5fa1\u6846\u67b6SCOUT\uff0c\u901a\u8fc7\u57fa\u4e8e\u663e\u8457\u6027\u7684\u4ee4\u724c\u5206\u6790\u6765\u68c0\u6d4b\u4f20\u7edf\u653b\u51fb\u548c\u65b0\u578b\u4e0a\u4e0b\u6587\u611f\u77e5\u653b\u51fb\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u5bf9\u8bed\u4e49\u5408\u7406\u89e6\u53d1\u5668\u7684\u68c0\u6d4b\u76f2\u70b9\u3002", "motivation": "\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u660e\u663e\u7684\u89e6\u53d1\u5668\uff08\u5982\u4e0a\u4e0b\u6587\u65e0\u5173\u7684\u89e6\u53d1\u8bcd\u548c\u5b89\u5168\u5bf9\u9f50\u8fdd\u89c4\uff09\uff0c\u4f46\u65e0\u6cd5\u68c0\u6d4b\u4f7f\u7528\u4e0a\u4e0b\u6587\u9002\u5f53\u3001\u8bed\u4e49\u5408\u7406\u7684\u89e6\u53d1\u5668\u7684\u9ad8\u7ea7\u540e\u95e8\u653b\u51fb\u3002\u8fd9\u4e9b\u653b\u51fb\u5229\u7528\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\uff0c\u5728\u533b\u7597\u5065\u5eb7\u7b49\u654f\u611f\u9886\u57df\u6784\u6210\u4e25\u91cd\u5b89\u5168\u5a01\u80c1\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u79cd\u65b0\u578b\u4e0a\u4e0b\u6587\u611f\u77e5\u653b\u51fb\u573a\u666f\uff08ViralApp\u3001Fever\u3001Referral\uff09\uff0c\u5e76\u5f00\u53d1\u4e86SCOUT\u9632\u5fa1\u6846\u67b6\u3002SCOUT\u901a\u8fc7\u6784\u5efa\u663e\u8457\u6027\u56fe\u6765\u5206\u6790\u79fb\u9664\u5355\u4e2a\u4ee4\u724c\u5bf9\u76ee\u6807\u6807\u7b7e\u8f93\u51falogits\u7684\u5f71\u54cd\uff0c\u4ece\u800c\u8bc6\u522b\u540e\u95e8\u89e6\u53d1\u5668\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6570\u636e\u96c6\uff08SST-2\u3001IMDB\u3001AG News\uff09\u4e0a\u8bc4\u4f30SCOUT\uff0c\u7ed3\u679c\u663e\u793a\u5b83\u80fd\u591f\u6210\u529f\u68c0\u6d4b\u4f20\u7edf\u653b\u51fb\uff08BadNet\u3001AddSent\u3001SynBkd\u3001StyleBkd\uff09\u548c\u65b0\u578b\u4e0a\u4e0b\u6587\u611f\u77e5\u653b\u51fb\uff0c\u540c\u65f6\u5728\u5e72\u51c0\u8f93\u5165\u4e0a\u4fdd\u6301\u51c6\u786e\u6027\u3002", "conclusion": "SCOUT\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u540e\u95e8\u653b\u51fb\u9632\u5fa1\u65b9\u6848\uff0c\u80fd\u591f\u68c0\u6d4b\u4f20\u7edf\u548c\u9ad8\u7ea7\u4e0a\u4e0b\u6587\u611f\u77e5\u653b\u51fb\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u5bf9\u8bed\u4e49\u5408\u7406\u89e6\u53d1\u5668\u7684\u68c0\u6d4b\u76f2\u70b9\uff0c\u4e3aAI\u7cfb\u7edf\u5728\u654f\u611f\u9886\u57df\u7684\u5b89\u5168\u90e8\u7f72\u63d0\u4f9b\u4e86\u91cd\u8981\u4fdd\u969c\u3002"}}
{"id": "2512.11169", "categories": ["cs.AI", "cs.LG", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.11169", "abs": "https://arxiv.org/abs/2512.11169", "authors": ["Akhil S Anand", "Elias Aarekol", "Martin Mziray Dalseg", "Magnus Stalhane", "Sebastien Gros"], "title": "CORL: Reinforcement Learning of MILP Policies Solved via Branch and Bound", "comment": null, "summary": "Combinatorial sequential decision making problems are typically modeled as mixed integer linear programs (MILPs) and solved via branch and bound (B&B) algorithms. The inherent difficulty of modeling MILPs that accurately represent stochastic real world problems leads to suboptimal performance in the real world. Recently, machine learning methods have been applied to build MILP models for decision quality rather than how accurately they model the real world problem. However, these approaches typically rely on supervised learning, assume access to true optimal decisions, and use surrogates for the MILP gradients. In this work, we introduce a proof of concept CORL framework that end to end fine tunes an MILP scheme using reinforcement learning (RL) on real world data to maximize its operational performance. We enable this by casting an MILP solved by B&B as a differentiable stochastic policy compatible with RL. We validate the CORL method in a simple illustrative combinatorial sequential decision making example.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCORL\u6846\u67b6\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u7aef\u5230\u7aef\u5fae\u8c03\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\u65b9\u6848\uff0c\u4ee5\u6700\u5927\u5316\u5b9e\u9645\u8fd0\u8425\u6027\u80fd\uff0c\u5c06MILP\u6c42\u89e3\u8fc7\u7a0b\u8f6c\u5316\u4e3a\u53ef\u5fae\u5206\u7684\u968f\u673a\u7b56\u7565\u3002", "motivation": "\u4f20\u7edf\u7684\u7ec4\u5408\u987a\u5e8f\u51b3\u7b56\u95ee\u9898\u901a\u5e38\u5efa\u6a21\u4e3a\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff0c\u4f46\u51c6\u786e\u5efa\u6a21\u73b0\u5b9e\u4e16\u754c\u968f\u673a\u95ee\u9898\u5f88\u56f0\u96be\uff0c\u5bfc\u81f4\u5b9e\u9645\u6027\u80fd\u4e0d\u4f73\u3002\u73b0\u6709\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u76d1\u7763\u5b66\u4e60\uff0c\u9700\u8981\u771f\u5b9e\u6700\u4f18\u51b3\u7b56\uff0c\u4e14\u4f7f\u7528MILP\u68af\u5ea6\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002", "method": "\u63d0\u51faCORL\u6982\u5ff5\u9a8c\u8bc1\u6846\u67b6\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u4e0a\u7aef\u5230\u7aef\u5fae\u8c03MILP\u65b9\u6848\u3002\u901a\u8fc7\u5c06\u5206\u652f\u5b9a\u754c\u7b97\u6cd5\u6c42\u89e3\u7684MILP\u8f6c\u5316\u4e3a\u4e0e\u5f3a\u5316\u5b66\u4e60\u517c\u5bb9\u7684\u53ef\u5fae\u5206\u968f\u673a\u7b56\u7565\u6765\u5b9e\u73b0\u3002", "result": "\u5728\u7b80\u5355\u7684\u7ec4\u5408\u987a\u5e8f\u51b3\u7b56\u793a\u4f8b\u4e2d\u9a8c\u8bc1\u4e86CORL\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "CORL\u6846\u67b6\u80fd\u591f\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u76f4\u63a5\u4f18\u5316MILP\u5728\u5b9e\u9645\u8fd0\u8425\u4e2d\u7684\u6027\u80fd\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u65b9\u6cd5\u5bf9\u51c6\u786e\u5efa\u6a21\u548c\u771f\u5b9e\u6700\u4f18\u51b3\u7b56\u7684\u4f9d\u8d56\u3002"}}
{"id": "2512.11112", "categories": ["cs.CR", "cs.DC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.11112", "abs": "https://arxiv.org/abs/2512.11112", "authors": ["Tianye Dai", "Hammurabi Mendes", "Heuichan Lim"], "title": "An LLVM-Based Optimization Pipeline for SPDZ", "comment": null, "summary": "Actively secure arithmetic MPC is now practical for real applications, but performance and usability are still limited by framework-specific compilation stacks, the need for programmers to explicitly express parallelism, and high communication overhead. We design and implement a proof-of-concept LLVM-based optimization pipeline for the SPDZ protocol that addresses these bottlenecks. Our front end accepts a subset of C with lightweight privacy annotations and lowers it to LLVM IR, allowing us to reuse mature analyses and transformations to automatically batch independent arithmetic operations. Our back end performs data-flow and control-flow analysis on the optimized IR to drive a non-blocking runtime scheduler that overlaps independent operations and aggressively overlaps communication with computation; when enabled, it can map batched operations to GPU kernels. This design preserves a low learning curve by using a mainstream language and hiding optimization and hardware-specific mechanics from programmers. We evaluate the system on controlled microbenchmarks against MP-SPDZ, focusing on online phase performance. Our CPU back end achieves up to 5.56 times speedup under intermediate and heavy algebraic workloads, shows strong scaling with thread count, and our GPU back end scales better as the input size increases. Overall, these results indicate that leveraging LLVM with protocol-aware scheduling is an effective architectural direction for extracting parallelism without sacrificing usability.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8eLLVM\u7684\u4f18\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347SPDZ\u534f\u8bae\u5728MPC\u4e2d\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u81ea\u52a8\u6279\u5904\u7406\u3001\u975e\u963b\u585e\u8c03\u5ea6\u548cGPU\u52a0\u901f\u6765\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\u5e76\u63d0\u9ad8\u5e76\u884c\u6027\u3002", "motivation": "\u5f53\u524d\u4e3b\u52a8\u5b89\u5168\u7684\u7b97\u672fMPC\u867d\u7136\u5b9e\u7528\uff0c\u4f46\u4ecd\u53d7\u9650\u4e8e\u7279\u5b9a\u6846\u67b6\u7684\u7f16\u8bd1\u6808\u3001\u9700\u8981\u7a0b\u5e8f\u5458\u663e\u5f0f\u8868\u8fbe\u5e76\u884c\u6027\u4ee5\u53ca\u9ad8\u901a\u4fe1\u5f00\u9500\u3002\u8fd9\u4e9b\u95ee\u9898\u9650\u5236\u4e86MPC\u7684\u6027\u80fd\u548c\u53ef\u7528\u6027\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u57fa\u4e8eLLVM\u7684\u6982\u5ff5\u9a8c\u8bc1\u4f18\u5316\u6d41\u6c34\u7ebf\uff1a1\uff09\u524d\u7aef\u63a5\u53d7\u5e26\u6709\u8f7b\u91cf\u9690\u79c1\u6ce8\u91ca\u7684C\u8bed\u8a00\u5b50\u96c6\u5e76\u8f6c\u6362\u4e3aLLVM IR\uff1b2\uff09\u91cd\u7528\u6210\u719f\u7684LLVM\u5206\u6790\u548c\u8f6c\u6362\u6765\u81ea\u52a8\u6279\u5904\u7406\u72ec\u7acb\u7b97\u672f\u64cd\u4f5c\uff1b3\uff09\u540e\u7aef\u5bf9\u4f18\u5316\u540e\u7684IR\u8fdb\u884c\u6570\u636e\u6d41\u548c\u63a7\u5236\u6d41\u5206\u6790\uff0c\u9a71\u52a8\u975e\u963b\u585e\u8fd0\u884c\u65f6\u8c03\u5ea6\u5668\uff0c\u91cd\u53e0\u72ec\u7acb\u64cd\u4f5c\u5e76\u79ef\u6781\u91cd\u53e0\u901a\u4fe1\u4e0e\u8ba1\u7b97\uff1b4\uff09\u53ef\u9009\u5730\u5c06\u6279\u5904\u7406\u64cd\u4f5c\u6620\u5c04\u5230GPU\u5185\u6838\u3002", "result": "\u5728\u53d7\u63a7\u5fae\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e0eMP-SPDZ\u5bf9\u6bd4\uff1aCPU\u540e\u7aef\u5728\u4e2d\u7b49\u548c\u91cd\u5ea6\u4ee3\u6570\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u5b9e\u73b0\u9ad8\u8fbe5.56\u500d\u52a0\u901f\uff0c\u7ebf\u7a0b\u6570\u6269\u5c55\u6027\u826f\u597d\uff1bGPU\u540e\u7aef\u968f\u7740\u8f93\u5165\u89c4\u6a21\u589e\u5927\u6269\u5c55\u6027\u66f4\u597d\u3002\u7cfb\u7edf\u5728\u4fdd\u6301\u4f4e\u5b66\u4e60\u66f2\u7ebf\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "conclusion": "\u5229\u7528LLVM\u7ed3\u5408\u534f\u8bae\u611f\u77e5\u8c03\u5ea6\u662f\u63d0\u53d6\u5e76\u884c\u6027\u800c\u4e0d\u727a\u7272\u53ef\u7528\u6027\u7684\u6709\u6548\u67b6\u6784\u65b9\u5411\u3002\u8be5\u8bbe\u8ba1\u4f7f\u7528\u4e3b\u6d41\u8bed\u8a00\u5e76\u9690\u85cf\u4f18\u5316\u548c\u786c\u4ef6\u7279\u5b9a\u673a\u5236\uff0c\u4fdd\u6301\u4e86\u4f4e\u5b66\u4e60\u66f2\u7ebf\u3002"}}
{"id": "2512.11213", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.11213", "abs": "https://arxiv.org/abs/2512.11213", "authors": ["Dongwon Jung", "Peng Shi", "Yi Zhang"], "title": "FutureWeaver: Planning Test-Time Compute for Multi-Agent Systems with Modularized Collaboration", "comment": null, "summary": "Scaling test-time computation improves large language model performance without additional training. Recent work demonstrates that techniques such as repeated sampling, self-verification, and self-reflection can significantly enhance task success by allocating more inference-time compute. However, applying these techniques across multiple agents in a multi-agent system is difficult: there does not exist principled mechanisms to allocate compute to foster collaboration among agents, to extend test-time scaling to collaborative interactions, or to distribute compute across agents under explicit budget constraints. To address this gap, we propose FutureWeaver, a framework for planning and optimizing test-time compute allocation in multi-agent systems under fixed budgets. FutureWeaver introduces modularized collaboration, formalized as callable functions that encapsulate reusable multi-agent workflows. These modules are automatically derived through self-play reflection by abstracting recurring interaction patterns from past trajectories. Building on these modules, FutureWeaver employs a dual-level planning architecture that optimizes compute allocation by reasoning over the current task state while also speculating on future steps. Experiments on complex agent benchmarks demonstrate that FutureWeaver consistently outperforms baselines across diverse budget settings, validating its effectiveness for multi-agent collaboration in inference-time optimization.", "AI": {"tldr": "FutureWeaver\u6846\u67b6\u901a\u8fc7\u6a21\u5757\u5316\u534f\u4f5c\u548c\u53cc\u7ea7\u89c4\u5212\uff0c\u5728\u56fa\u5b9a\u9884\u7b97\u4e0b\u4f18\u5316\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u5206\u914d\uff0c\u663e\u8457\u63d0\u5347\u534f\u4f5c\u6027\u80fd", "motivation": "\u73b0\u6709\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u6269\u5c55\u6280\u672f\uff08\u5982\u91cd\u590d\u91c7\u6837\u3001\u81ea\u6211\u9a8c\u8bc1\uff09\u5728\u5355\u667a\u80fd\u4f53\u573a\u666f\u4e2d\u6709\u6548\uff0c\u4f46\u7f3a\u4e4f\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u5206\u914d\u8ba1\u7b97\u4ee5\u4fc3\u8fdb\u534f\u4f5c\u7684\u539f\u5219\u6027\u673a\u5236\uff0c\u7279\u522b\u662f\u5728\u9884\u7b97\u7ea6\u675f\u4e0b", "method": "1. \u6a21\u5757\u5316\u534f\u4f5c\uff1a\u5c06\u53ef\u91cd\u7528\u7684\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u5c01\u88c5\u4e3a\u53ef\u8c03\u7528\u51fd\u6570\uff0c\u901a\u8fc7\u81ea\u6211\u6e38\u620f\u53cd\u601d\u4ece\u5386\u53f2\u8f68\u8ff9\u4e2d\u62bd\u8c61\u51fa\u91cd\u590d\u4ea4\u4e92\u6a21\u5f0f\uff1b2. \u53cc\u7ea7\u89c4\u5212\u67b6\u6784\uff1a\u5728\u5f53\u524d\u4efb\u52a1\u72b6\u6001\u63a8\u7406\u57fa\u7840\u4e0a\uff0c\u540c\u65f6\u63a8\u6d4b\u672a\u6765\u6b65\u9aa4\uff0c\u4f18\u5316\u8ba1\u7b97\u5206\u914d", "result": "\u5728\u590d\u6742\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFutureWeaver\u5728\u4e0d\u540c\u9884\u7b97\u8bbe\u7f6e\u4e0b\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u63a8\u7406\u65f6\u4f18\u5316\u4e2d\u4fc3\u8fdb\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7684\u6709\u6548\u6027", "conclusion": "FutureWeaver\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u7684\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u5206\u914d\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u534f\u4f5c\u548c\u524d\u77bb\u6027\u89c4\u5212\uff0c\u5728\u9884\u7b97\u7ea6\u675f\u4e0b\u663e\u8457\u63d0\u5347\u534f\u4f5c\u6027\u80fd\uff0c\u6269\u5c55\u4e86\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u4f18\u5316\u7684\u5e94\u7528\u8303\u56f4"}}
{"id": "2512.11316", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.11316", "abs": "https://arxiv.org/abs/2512.11316", "authors": ["Zhenshuo Zhao", "Maria Spichkova", "Duttkumari Champavat", "Juilee N. Kulkarni", "Sahil Singla", "Muhammad A. Zulkefli", "Pradhuman Khandelwal"], "title": "Visualisation for the CIS benchmark scanning results", "comment": "Preprint. Accepted to the ICICT'26. Final version to be published by in conference proceedings by Springer LNNS", "summary": "In this paper, we introduce GraphSecure, a web application that provides advanced analysis and visualisation of security scanning results. GraphSecure enables users to initiate scans for their AWS account, validate them against specific Center for Internet Security (CIS) Benchmarks and return results, showcase those returned results in the form of statistical charts and warn the users about their account status.", "AI": {"tldr": "GraphSecure\u662f\u4e00\u4e2a\u7528\u4e8e\u5206\u6790\u548c\u53ef\u89c6\u5316AWS\u5b89\u5168\u626b\u63cf\u7ed3\u679c\u7684Web\u5e94\u7528\uff0c\u652f\u6301CIS\u57fa\u51c6\u9a8c\u8bc1\u5e76\u63d0\u4f9b\u7edf\u8ba1\u56fe\u8868\u548c\u8d26\u6237\u72b6\u6001\u544a\u8b66", "motivation": "\u4e3a\u4e86\u89e3\u51b3AWS\u8d26\u6237\u5b89\u5168\u626b\u63cf\u7ed3\u679c\u5206\u6790\u590d\u6742\u3001\u53ef\u89c6\u5316\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5e2e\u52a9\u7528\u6237\u66f4\u597d\u5730\u7406\u89e3\u5b89\u5168\u72b6\u6001\u5e76\u91c7\u53d6\u76f8\u5e94\u63aa\u65bd", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2aWeb\u5e94\u7528\u7a0b\u5e8f\uff0c\u80fd\u591f\uff1a1) \u5bf9AWS\u8d26\u6237\u53d1\u8d77\u5b89\u5168\u626b\u63cf\uff1b2) \u6839\u636eCIS\u57fa\u51c6\u9a8c\u8bc1\u626b\u63cf\u7ed3\u679c\uff1b3) \u901a\u8fc7\u7edf\u8ba1\u56fe\u8868\u5c55\u793a\u7ed3\u679c\uff1b4) \u63d0\u4f9b\u8d26\u6237\u72b6\u6001\u544a\u8b66\u529f\u80fd", "result": "\u6210\u529f\u5b9e\u73b0\u4e86GraphSecure\u7cfb\u7edf\uff0c\u80fd\u591f\u6709\u6548\u5206\u6790AWS\u5b89\u5168\u626b\u63cf\u7ed3\u679c\uff0c\u63d0\u4f9b\u76f4\u89c2\u7684\u53ef\u89c6\u5316\u5c55\u793a\uff0c\u5e76\u5e2e\u52a9\u7528\u6237\u53ca\u65f6\u4e86\u89e3\u8d26\u6237\u5b89\u5168\u72b6\u6001", "conclusion": "GraphSecure\u4e3aAWS\u5b89\u5168\u626b\u63cf\u7ed3\u679c\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5206\u6790\u548c\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u5e2e\u52a9\u7528\u6237\u66f4\u597d\u5730\u7406\u89e3\u548c\u6539\u5584\u5176\u4e91\u5b89\u5168\u6001\u52bf"}}
{"id": "2512.11323", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11323", "abs": "https://arxiv.org/abs/2512.11323", "authors": ["Jianyi Zhang", "Ziyin Zhou", "Xu Ji", "Shizhao Liu", "Zhangchi Zhao"], "title": "CAPTURE: A Benchmark and Evaluation for LVLMs in CAPTCHA Resolving", "comment": null, "summary": "Benefiting from strong and efficient multi-modal alignment strategies, Large Visual Language Models (LVLMs) are able to simulate human visual and reasoning capabilities, such as solving CAPTCHAs. However, existing benchmarks based on visual CAPTCHAs still face limitations. Previous studies, when designing benchmarks and datasets, customized them according to their research objectives. Consequently, these benchmarks cannot comprehensively cover all CAPTCHA types. Notably, there is a dearth of dedicated benchmarks for LVLMs. To address this problem, we introduce a novel CAPTCHA benchmark for the first time, named CAPTURE CAPTCHA for Testing Under Real-world Experiments, specifically for LVLMs. Our benchmark encompasses 4 main CAPTCHA types and 25 sub-types from 31 vendors. The diversity enables a multi-dimensional and thorough evaluation of LVLM performance. CAPTURE features extensive class variety, large-scale data, and unique LVLM-tailored labels, filling the gaps in previous research in terms of data comprehensiveness and labeling pertinence. When evaluated by this benchmark, current LVLMs demonstrate poor performance in solving CAPTCHAs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u4e13\u95e8\u9488\u5bf9\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08LVLMs\uff09\u7684CAPTCHA\u57fa\u51c6\u6d4b\u8bd5CAPTURE\uff0c\u6db5\u76d64\u79cd\u4e3b\u8981\u7c7b\u578b\u548c25\u79cd\u5b50\u7c7b\u578b\uff0c\u7528\u4e8e\u5168\u9762\u8bc4\u4f30LVLMs\u5728\u89e3\u51b3\u9a8c\u8bc1\u7801\u65b9\u9762\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u89c6\u89c9\u9a8c\u8bc1\u7801\u7684\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u5168\u9762\u8986\u76d6\u6240\u6709\u9a8c\u8bc1\u7801\u7c7b\u578b\uff0c\u4e14\u7f3a\u4e4f\u4e13\u95e8\u9488\u5bf9LVLMs\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002\u73b0\u6709\u7814\u7a76\u5728\u8bbe\u8ba1\u57fa\u51c6\u548c\u6570\u636e\u96c6\u65f6\u5f80\u5f80\u6839\u636e\u7279\u5b9a\u7814\u7a76\u76ee\u6807\u5b9a\u5236\uff0c\u5bfc\u81f4\u8bc4\u4f30\u4e0d\u591f\u5168\u9762\u3002", "method": "\u63d0\u51fa\u4e86CAPTURE\uff08CAPTCHA for Testing Under Real-world Experiments\uff09\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u6765\u81ea31\u4e2a\u4f9b\u5e94\u5546\u76844\u79cd\u4e3b\u8981CAPTCHA\u7c7b\u578b\u548c25\u79cd\u5b50\u7c7b\u578b\u3002\u8be5\u57fa\u51c6\u5177\u6709\u5e7f\u6cdb\u7684\u7c7b\u522b\u591a\u6837\u6027\u3001\u5927\u89c4\u6a21\u6570\u636e\u4ee5\u53ca\u4e13\u95e8\u4e3aLVLMs\u5b9a\u5236\u7684\u6807\u7b7e\u3002", "result": "\u4f7f\u7528\u8be5\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u5f53\u524dLVLMs\u65f6\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u89e3\u51b3\u9a8c\u8bc1\u7801\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u8868\u660e\u73b0\u6709\u6a21\u578b\u5728\u5b9e\u9645\u9a8c\u8bc1\u7801\u8bc6\u522b\u4efb\u52a1\u4e2d\u5b58\u5728\u5c40\u9650\u6027\u3002", "conclusion": "CAPTURE\u57fa\u51c6\u586b\u8865\u4e86\u5148\u524d\u7814\u7a76\u5728\u6570\u636e\u5168\u9762\u6027\u548c\u6807\u7b7e\u9488\u5bf9\u6027\u65b9\u9762\u7684\u7a7a\u767d\uff0c\u4e3aLVLMs\u5728\u9a8c\u8bc1\u7801\u8bc6\u522b\u4efb\u52a1\u7684\u591a\u7ef4\u5ea6\u548c\u5168\u9762\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u63ed\u793a\u4e86\u5f53\u524dLVLMs\u5728\u8be5\u9886\u57df\u7684\u4e0d\u8db3\u3002"}}
{"id": "2512.11269", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11269", "abs": "https://arxiv.org/abs/2512.11269", "authors": ["Siddharth Jayashankar", "Joshua Kim", "Michael B. Sullivan", "Wenting Zheng", "Dimitrios Skarlatos"], "title": "A Scalable Multi-GPU Framework for Encrypted Large-Model Inference", "comment": null, "summary": "Encrypted AI using fully homomorphic encryption (FHE) provides strong privacy guarantees; but its slow performance has limited practical deployment. Recent works proposed ASICs to accelerate FHE, but require expensive advanced manufacturing processes that constrain their accessibility. GPUs are a far more accessible platform, but achieving ASIC-level performance using GPUs has remained elusive. Furthermore, state-of-the-art approaches primarily focus on small models that fit comfortably within a single device. Supporting large models such as LLMs in FHE introduces a dramatic increase in computational complexity that requires optimized GPU kernels, along with managing terabyte-scale memory footprints that far exceed the capacity of a single GPU. This paper presents Cerium, a multi-GPU framework for FHE inference on large models. Cerium integrates a domain-specific language, an optimizing compiler, and a runtime system to automatically generate high-performance GPU kernels, manage terabyte-scale memory footprints, and parallelize computation across multiple GPUs. It introduces new IR constructs, compiler passes, sparse polynomial representations, memory-efficient data layouts, and communication-aware parallelization techniques that together enable encrypted inference for models ranging from small CNNs to Llama3-8B. We build Cerium on NVIDIA GPUs and demonstrate significant performance gains. For small models, Cerium outperforms expert-written hand-optimized GPU libraries by up to 2.25 times. Cerium achieves performance competitive with state-of-the-art FHE ASICs, outright matching prior FHE ASIC CraterLake. It is the first GPU system to execute bootstrapping in under 10 milliseconds, achieving 7.5 milliseconds, and is the first to demonstrate encrypted inference for BERT-Base and Llama3-8B in 8 seconds and 134 seconds, respectively.", "AI": {"tldr": "Cerium\u662f\u4e00\u4e2a\u591aGPU\u6846\u67b6\uff0c\u7528\u4e8e\u5168\u540c\u6001\u52a0\u5bc6\uff08FHE\uff09\u7684\u5927\u578b\u6a21\u578b\u63a8\u7406\uff0c\u901a\u8fc7\u81ea\u52a8\u751f\u6210\u9ad8\u6027\u80fdGPU\u5185\u6838\u3001\u7ba1\u7406TB\u7ea7\u5185\u5b58\u548c\u591aGPU\u5e76\u884c\u5316\uff0c\u5728GPU\u4e0a\u5b9e\u73b0\u63a5\u8fd1ASIC\u7684\u6027\u80fd\u3002", "motivation": "FHE\u63d0\u4f9b\u5f3a\u9690\u79c1\u4fdd\u8bc1\u4f46\u6027\u80fd\u7f13\u6162\uff0c\u73b0\u6709ASIC\u52a0\u901f\u65b9\u6848\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u666e\u53ca\uff0cGPU\u5e73\u53f0\u66f4\u6613\u83b7\u53d6\u4f46\u96be\u4ee5\u8fbe\u5230ASIC\u7ea7\u6027\u80fd\u3002\u6b64\u5916\uff0c\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u5c0f\u578b\u6a21\u578b\uff0c\u652f\u6301LLM\u7b49\u5927\u578b\u6a21\u578b\u9762\u4e34\u8ba1\u7b97\u590d\u6742\u5ea6\u5267\u589e\u548cTB\u7ea7\u5185\u5b58\u7ba1\u7406\u7684\u6311\u6218\u3002", "method": "Cerium\u96c6\u6210\u4e86\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u3001\u4f18\u5316\u7f16\u8bd1\u5668\u548c\u8fd0\u884c\u65f6\u7cfb\u7edf\uff0c\u5f15\u5165\u65b0\u7684IR\u6784\u9020\u3001\u7f16\u8bd1\u5668\u4f20\u9012\u3001\u7a00\u758f\u591a\u9879\u5f0f\u8868\u793a\u3001\u5185\u5b58\u9ad8\u6548\u6570\u636e\u5e03\u5c40\u548c\u901a\u4fe1\u611f\u77e5\u5e76\u884c\u5316\u6280\u672f\uff0c\u81ea\u52a8\u751f\u6210\u9ad8\u6027\u80fdGPU\u5185\u6838\uff0c\u7ba1\u7406TB\u7ea7\u5185\u5b58\uff0c\u5e76\u5728\u591aGPU\u95f4\u5e76\u884c\u5316\u8ba1\u7b97\u3002", "result": "\u5bf9\u4e8e\u5c0f\u578b\u6a21\u578b\uff0cCerium\u6bd4\u4e13\u5bb6\u624b\u5199\u4f18\u5316\u7684GPU\u5e93\u5feb2.25\u500d\uff1b\u6027\u80fd\u4e0e\u6700\u5148\u8fdb\u7684FHE ASIC\u7ade\u4e89\uff0c\u5339\u914d\u4e4b\u524d\u7684FHE ASIC CraterLake\uff1b\u9996\u6b21\u5728GPU\u4e0a\u5b9e\u73b010\u6beb\u79d2\u4ee5\u4e0b\u7684\u5f15\u5bfc\uff087.5\u6beb\u79d2\uff09\uff1b\u9996\u6b21\u5c55\u793aBERT-Base\u548cLlama3-8B\u7684\u52a0\u5bc6\u63a8\u7406\uff0c\u5206\u522b\u8017\u65f68\u79d2\u548c134\u79d2\u3002", "conclusion": "Cerium\u6210\u529f\u89e3\u51b3\u4e86FHE\u5728GPU\u5e73\u53f0\u4e0a\u90e8\u7f72\u5927\u578b\u6a21\u578b\u7684\u6027\u80fd\u74f6\u9888\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u7f16\u8bd1\u5668\u548c\u8fd0\u884c\u65f6\u6280\u672f\uff0c\u5728\u53ef\u8bbf\u95ee\u7684GPU\u5e73\u53f0\u4e0a\u5b9e\u73b0\u4e86\u63a5\u8fd1ASIC\u7684\u6027\u80fd\uff0c\u4e3a\u5927\u578b\u6a21\u578b\u7684\u52a0\u5bc6\u63a8\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.11426", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11426", "abs": "https://arxiv.org/abs/2512.11426", "authors": ["Shuowei Cai", "Yansong Ning", "Hao Liu"], "title": "AgentBalance: Backbone-then-Topology Design for Cost-Effective Multi-Agent Systems under Budget Constraints", "comment": null, "summary": "Large Language Model (LLM)-based multi-agent systems (MAS) are becoming indispensable building blocks for web-scale applications such as web search, social network analytics, and online customer support, where cost-effectiveness is increasingly the primary constraint for large-scale deployment. While recent work improves MAS cost-effectiveness by shaping inter-agent communication topologies and selecting agent backbones, it rarely models and optimizes under explicit token-cost and latency budgets that reflect deployment constraints. This often leads to topology-first designs and suboptimal cost-effectiveness when budgets are binding. We present AgentBalance, a framework for constructing cost-effective MAS under explicit token-cost and latency budgets via a backbone-then-topology design. AgentBalance first performs backbone-oriented agent generation, constructing agents with heterogeneous backbones through LLM pool construction, pool selection, and role-backbone matching. It then performs adaptive MAS topology generation, guiding inter-agent communication via agent representation learning, gating, and latency-aware topology synthesis. Experiments on benchmarks with 14 candidate LLM backbones show that AgentBalance achieves up to 10% and 22% performance gains under matched token-cost and latency budgets, respectively, and yields strong AUC on performance-versus-budget curves across benchmarks. AgentBalance also functions as a plug-in for existing MAS, improving performance under the same token-cost and latency constraints, and it generalizes well to unseen LLMs for practical, budget-aware deployment. Code: https://github.com/usail-hkust/AgentBalance", "AI": {"tldr": "AgentBalance\u662f\u4e00\u4e2a\u5728\u660e\u786etoken\u6210\u672c\u548c\u5ef6\u8fdf\u9884\u7b97\u4e0b\u6784\u5efa\u6210\u672c\u6548\u76ca\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6846\u67b6\uff0c\u91c7\u7528\"\u5148\u9aa8\u5e72\u540e\u62d3\u6251\"\u8bbe\u8ba1\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5728\u76f8\u540c\u9884\u7b97\u4e0b\u6027\u80fd\u63d0\u5347\u663e\u8457\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728web\u89c4\u6a21\u5e94\u7528\u4e2d\u6210\u672c\u6548\u76ca\u65e5\u76ca\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5f88\u5c11\u5728\u660e\u786e\u7684token\u6210\u672c\u548c\u5ef6\u8fdf\u9884\u7b97\u4e0b\u5efa\u6a21\u548c\u4f18\u5316\uff0c\u5bfc\u81f4\u9884\u7b97\u7ea6\u675f\u65f6\u8bbe\u8ba1\u6b21\u4f18\u3002", "method": "\u91c7\u7528\"\u5148\u9aa8\u5e72\u540e\u62d3\u6251\"\u8bbe\u8ba1\uff1a1)\u9aa8\u5e72\u5bfc\u5411\u7684\u667a\u80fd\u4f53\u751f\u6210\uff08LLM\u6c60\u6784\u5efa\u3001\u6c60\u9009\u62e9\u3001\u89d2\u8272-\u9aa8\u5e72\u5339\u914d\uff09\uff1b2)\u81ea\u9002\u5e94MAS\u62d3\u6251\u751f\u6210\uff08\u667a\u80fd\u4f53\u8868\u793a\u5b66\u4e60\u3001\u95e8\u63a7\u3001\u5ef6\u8fdf\u611f\u77e5\u62d3\u6251\u5408\u6210\uff09\u3002", "result": "\u572814\u4e2a\u5019\u9009LLM\u9aa8\u5e72\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAgentBalance\u5728\u5339\u914d\u7684token\u6210\u672c\u9884\u7b97\u4e0b\u5b9e\u73b0\u9ad8\u8fbe10%\u6027\u80fd\u63d0\u5347\uff0c\u5728\u5ef6\u8fdf\u9884\u7b97\u4e0b\u5b9e\u73b022%\u6027\u80fd\u63d0\u5347\uff0c\u5728\u6027\u80fd-\u9884\u7b97\u66f2\u7ebf\u4e0a\u8868\u73b0\u51fa\u5f3aAUC\u3002", "conclusion": "AgentBalance\u6846\u67b6\u80fd\u591f\u5728\u660e\u786e\u9884\u7b97\u7ea6\u675f\u4e0b\u6784\u5efa\u6210\u672c\u6548\u76ca\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u53ef\u4f5c\u4e3a\u73b0\u6709MAS\u7684\u63d2\u4ef6\u63d0\u5347\u6027\u80fd\uff0c\u5e76\u80fd\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684LLM\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u9884\u7b97\u611f\u77e5\u90e8\u7f72\u3002"}}
{"id": "2512.11433", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.11433", "abs": "https://arxiv.org/abs/2512.11433", "authors": ["Agustin Martin Picard", "Thibaut Boissin", "Varshini Subhash", "R\u00e9mi Cad\u00e8ne", "Thomas Fel"], "title": "Back to the Baseline: Examining Baseline Effects on Explainability Metrics", "comment": null, "summary": "Attribution methods are among the most prevalent techniques in Explainable Artificial Intelligence (XAI) and are usually evaluated and compared using Fidelity metrics, with Insertion and Deletion being the most popular. These metrics rely on a baseline function to alter the pixels of the input image that the attribution map deems most important. In this work, we highlight a critical problem with these metrics: the choice of a given baseline will inevitably favour certain attribution methods over others. More concerningly, even a simple linear model with commonly used baselines contradicts itself by designating different optimal methods. A question then arises: which baseline should we use? We propose to study this problem through two desirable properties of a baseline: (i) that it removes information and (ii) that it does not produce overly out-of-distribution (OOD) images. We first show that none of the tested baselines satisfy both criteria, and there appears to be a trade-off among current baselines: either they remove information or they produce a sequence of OOD images. Finally, we introduce a novel baseline by leveraging recent work in feature visualisation to artificially produce a model-dependent baseline that removes information without being overly OOD, thus improving on the trade-off when compared to other existing baselines. Our code is available at https://github.com/deel-ai-papers/Back-to-the-Baseline", "AI": {"tldr": "\u8be5\u8bba\u6587\u6307\u51fa\u5f53\u524dXAI\u4e2d\u57fa\u4e8e\u63d2\u5165\u548c\u5220\u9664\u7684\u4fdd\u771f\u5ea6\u8bc4\u4f30\u6307\u6807\u5b58\u5728\u4e25\u91cd\u95ee\u9898\uff1a\u4e0d\u540c\u57fa\u7ebf\u9009\u62e9\u4f1a\u504f\u5411\u4e0d\u540c\u7684\u5f52\u56e0\u65b9\u6cd5\uff0c\u751a\u81f3\u5bfc\u81f4\u7ebf\u6027\u6a21\u578b\u5f97\u51fa\u77db\u76fe\u7684\u6700\u4f18\u65b9\u6cd5\u7ed3\u8bba\u3002\u4f5c\u8005\u63d0\u51fa\u57fa\u7ebf\u5e94\u6ee1\u8db3\u4e24\u4e2a\u7406\u60f3\u5c5e\u6027\uff1a\u79fb\u9664\u4fe1\u606f\u4e14\u4e0d\u8fc7\u5ea6\u4ea7\u751f\u5206\u5e03\u5916\u56fe\u50cf\uff0c\u5e76\u5f15\u5165\u4e00\u79cd\u65b0\u7684\u6a21\u578b\u4f9d\u8d56\u57fa\u7ebf\u6765\u6539\u8fdb\u8fd9\u4e00\u6743\u8861\u3002", "motivation": "\u5f53\u524d\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u7684\u5f52\u56e0\u65b9\u6cd5\u901a\u5e38\u901a\u8fc7\u63d2\u5165\u548c\u5220\u9664\u7b49\u4fdd\u771f\u5ea6\u6307\u6807\u8fdb\u884c\u8bc4\u4f30\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u6307\u6807\u4e25\u91cd\u4f9d\u8d56\u4e8e\u57fa\u7ebf\u51fd\u6570\u7684\u9009\u62e9\uff0c\u800c\u4e0d\u540c\u57fa\u7ebf\u7684\u9009\u62e9\u4f1a\u4e0d\u53ef\u907f\u514d\u5730\u504f\u5411\u67d0\u4e9b\u5f52\u56e0\u65b9\u6cd5\uff0c\u751a\u81f3\u5bfc\u81f4\u8bc4\u4f30\u7ed3\u679c\u76f8\u4e92\u77db\u76fe\u3002\u8fd9\u5f15\u53d1\u4e86\u4e00\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u6211\u4eec\u5e94\u8be5\u4f7f\u7528\u54ea\u79cd\u57fa\u7ebf\uff1f", "method": "\u4f5c\u8005\u9996\u5148\u5206\u6790\u4e86\u73b0\u6709\u57fa\u7ebf\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u57fa\u7ebf\u5e94\u6ee1\u8db3\u4e24\u4e2a\u7406\u60f3\u5c5e\u6027\uff1a1\uff09\u80fd\u591f\u79fb\u9664\u4fe1\u606f\uff1b2\uff09\u4e0d\u4f1a\u4ea7\u751f\u8fc7\u5ea6\u5206\u5e03\u5916\uff08OOD\uff09\u7684\u56fe\u50cf\u3002\u901a\u8fc7\u5b9e\u9a8c\u53d1\u73b0\u73b0\u6709\u57fa\u7ebf\u90fd\u65e0\u6cd5\u540c\u65f6\u6ee1\u8db3\u8fd9\u4e24\u4e2a\u6807\u51c6\uff0c\u5b58\u5728\u660e\u663e\u7684\u6743\u8861\u5173\u7cfb\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f5c\u8005\u5229\u7528\u7279\u5f81\u53ef\u89c6\u5316\u7684\u6700\u65b0\u5de5\u4f5c\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6a21\u578b\u4f9d\u8d56\u57fa\u7ebf\uff0c\u80fd\u591f\u79fb\u9664\u4fe1\u606f\u540c\u65f6\u4e0d\u8fc7\u5ea6\u4ea7\u751fOOD\u56fe\u50cf\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u73b0\u6709\u57fa\u7ebf\u90fd\u5b58\u5728\u4fe1\u606f\u79fb\u9664\u4e0eOOD\u751f\u6210\u4e4b\u95f4\u7684\u6743\u8861\uff1a\u8981\u4e48\u80fd\u6709\u6548\u79fb\u9664\u4fe1\u606f\u4f46\u4ea7\u751fOOD\u56fe\u50cf\uff0c\u8981\u4e48\u4e0d\u4ea7\u751fOOD\u56fe\u50cf\u4f46\u4fe1\u606f\u79fb\u9664\u6548\u679c\u4e0d\u4f73\u3002\u4f5c\u8005\u63d0\u51fa\u7684\u65b0\u57fa\u7ebf\u5728\u6743\u8861\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u80fd\u591f\u66f4\u597d\u5730\u540c\u65f6\u6ee1\u8db3\u4e24\u4e2a\u7406\u60f3\u5c5e\u6027\u3002", "conclusion": "\u5f53\u524dXAI\u8bc4\u4f30\u4e2d\u4f7f\u7528\u7684\u57fa\u7ebf\u9009\u62e9\u5b58\u5728\u4e25\u91cd\u504f\u5dee\u95ee\u9898\uff0c\u4e0d\u540c\u57fa\u7ebf\u4f1a\u504f\u5411\u4e0d\u540c\u7684\u5f52\u56e0\u65b9\u6cd5\u3002\u4f5c\u8005\u63d0\u51fa\u7684\u6a21\u578b\u4f9d\u8d56\u57fa\u7ebf\u5728\u4fe1\u606f\u79fb\u9664\u548c\u907f\u514d\u8fc7\u5ea6OOD\u751f\u6210\u4e4b\u95f4\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u5e73\u8861\uff0c\u4e3a\u66f4\u516c\u5e73\u7684\u5f52\u56e0\u65b9\u6cd5\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6539\u8fdb\u65b9\u6848\u3002"}}
{"id": "2512.11431", "categories": ["cs.CR", "cs.FL", "cs.NI"], "pdf": "https://arxiv.org/pdf/2512.11431", "abs": "https://arxiv.org/abs/2512.11431", "authors": ["Qifan Zhang", "Zilin Shen", "Imtiaz Karim", "Elisa Bertino", "Zhou Li"], "title": "Proving DNSSEC Correctness: A Formal Approach to Secure Domain Name Resolution", "comment": null, "summary": "The Domain Name System Security Extensions (DNSSEC) are critical for preventing DNS spoofing, yet its specifications contain ambiguities and vulnerabilities that elude traditional \"break-and-fix\" approaches. A holistic, foundational security analysis of the protocol has thus remained an open problem. This paper introduces DNSSECVerif, the first framework for comprehensive, automated formal security analysis of the DNSSEC protocol suite. Built on the SAPIC+ symbolic verifier, our high-fidelity model captures protocol-level interactions, including cryptographic operations and stateful caching with fine-grained concurrency control. Using DNSSECVerif, we formally prove four of DNSSEC's core security guarantees and uncover critical ambiguities in the standards--notably, the insecure coexistence of NSEC and NSEC3. Our model also automatically rediscovers three classes of known attacks, demonstrating fundamental weaknesses in the protocol design. To bridge the model-to-reality gap, we validate our findings through targeted testing of mainstream DNS software and a large-scale measurement study of over 2.2 million open resolvers, confirming the real-world impact of these flaws. Our work provides crucial, evidence-based recommendations for hardening DNSSEC specifications and implementations.", "AI": {"tldr": "DNSSECVerif\u662f\u9996\u4e2a\u7528\u4e8eDNSSEC\u534f\u8bae\u5957\u4ef6\u5168\u9762\u81ea\u52a8\u5316\u5f62\u5f0f\u5316\u5b89\u5168\u5206\u6790\u7684\u6846\u67b6\uff0c\u80fd\u591f\u53d1\u73b0\u534f\u8bae\u89c4\u8303\u4e2d\u7684\u5173\u952e\u6a21\u7cca\u6027\u548c\u6f0f\u6d1e\uff0c\u5e76\u901a\u8fc7\u5927\u89c4\u6a21\u6d4b\u91cf\u7814\u7a76\u9a8c\u8bc1\u73b0\u5b9e\u5f71\u54cd\u3002", "motivation": "DNSSEC\u5bf9\u4e8e\u9632\u6b62DNS\u6b3a\u9a97\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u89c4\u8303\u5b58\u5728\u6a21\u7cca\u6027\u548c\u6f0f\u6d1e\uff0c\u4f20\u7edf\"\u7834\u574f-\u4fee\u590d\"\u65b9\u6cd5\u65e0\u6cd5\u89e3\u51b3\uff0c\u9700\u8981\u5168\u9762\u7684\u57fa\u7840\u5b89\u5168\u5206\u6790\u3002", "method": "\u57fa\u4e8eSAPIC+\u7b26\u53f7\u9a8c\u8bc1\u5668\u6784\u5efaDNSSECVerif\u6846\u67b6\uff0c\u5efa\u7acb\u9ad8\u4fdd\u771f\u6a21\u578b\u6355\u83b7\u534f\u8bae\u7ea7\u4ea4\u4e92\uff0c\u5305\u62ec\u52a0\u5bc6\u64cd\u4f5c\u548c\u7ec6\u7c92\u5ea6\u5e76\u53d1\u63a7\u5236\u7684\u72b6\u6001\u7f13\u5b58\u3002", "result": "\u6b63\u5f0f\u8bc1\u660e\u4e86DNSSEC\u7684\u56db\u4e2a\u6838\u5fc3\u5b89\u5168\u4fdd\u8bc1\uff0c\u53d1\u73b0\u4e86\u6807\u51c6\u4e2d\u7684\u5173\u952e\u6a21\u7cca\u6027\uff08\u7279\u522b\u662fNSEC\u548cNSEC3\u7684\u4e0d\u5b89\u5168\u5171\u5b58\uff09\uff0c\u81ea\u52a8\u91cd\u65b0\u53d1\u73b0\u4e86\u4e09\u7c7b\u5df2\u77e5\u653b\u51fb\uff0c\u901a\u8fc7\u6d4b\u8bd5\u4e3b\u6d41DNS\u8f6f\u4ef6\u548c\u6d4b\u91cf220\u591a\u4e07\u4e2a\u5f00\u653e\u89e3\u6790\u5668\u9a8c\u8bc1\u4e86\u73b0\u5b9e\u5f71\u54cd\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5f3a\u5316DNSSEC\u89c4\u8303\u548c\u5b9e\u73b0\u63d0\u4f9b\u4e86\u57fa\u4e8e\u8bc1\u636e\u7684\u5173\u952e\u5efa\u8bae\uff0c\u586b\u8865\u4e86\u534f\u8bae\u5168\u9762\u5f62\u5f0f\u5316\u5b89\u5168\u5206\u6790\u7684\u7a7a\u767d\u3002"}}
{"id": "2512.11463", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11463", "abs": "https://arxiv.org/abs/2512.11463", "authors": ["Junghwan Lim", "Sungmin Lee", "Dongseok Kim", "Taehyun Kim", "Eunhwan Park", "Jeesoo Lee", "Jeongdoo Lee", "Junhyeok Lee", "Wai Ting Cheung", "Dahye Choi", "Minsu Ha", "Jaeheui Her", "Jaeyeon Huh", "Hanbin Jung", "Changjin Kang", "Beomgyu Kim", "Minjae Kim", "Taewhan Kim", "Youngrok Kim", "Hyukjin Kweon", "Haesol Lee", "Kungyu Lee", "Dongpin Oh", "Yeongjae Park", "Bokki Ryu", "Dongjoo Weon"], "title": "Motif-2-12.7B-Reasoning: A Practitioner's Guide to RL Training Recipes", "comment": null, "summary": "We introduce Motif-2-12.7B-Reasoning, a 12.7B parameter language model designed to bridge the gap between open-weight systems and proprietary frontier models in complex reasoning and long-context understanding. Addressing the common challenges of model collapse and training instability in reasoning adaptation, we propose a comprehensive, reproducible training recipe spanning system, data, and algorithmic optimizations. Our approach combines memory-efficient infrastructure for 64K-token contexts using hybrid parallelism and kernel-level optimizations with a two-stage Supervised Fine-Tuning (SFT) curriculum that mitigates distribution mismatch through verified, aligned synthetic data. Furthermore, we detail a robust Reinforcement Learning Fine-Tuning (RLFT) pipeline that stabilizes training via difficulty-aware data filtering and mixed-policy trajectory reuse. Empirical results demonstrate that Motif-2-12.7B-Reasoning achieves performance comparable to models with significantly larger parameter counts across mathematics, coding, and agentic benchmarks, offering the community a competitive open model and a practical blueprint for scaling reasoning capabilities under realistic compute constraints.", "AI": {"tldr": "Motif-2-12.7B-Reasoning\u662f\u4e00\u4e2a12.7B\u53c2\u6570\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u65e8\u5728\u5f25\u5408\u5f00\u6e90\u6a21\u578b\u4e0e\u524d\u6cbf\u4e13\u6709\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u548c\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u65b9\u9762\u7684\u5dee\u8ddd\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u8bad\u7ec3\u65b9\u6cd5\u5728\u6709\u9650\u8ba1\u7b97\u8d44\u6e90\u4e0b\u5b9e\u73b0\u63a5\u8fd1\u66f4\u5927\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5f00\u6e90\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u548c\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u65b9\u9762\u4e0e\u524d\u6cbf\u4e13\u6709\u6a21\u578b\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u540c\u65f6\u514b\u670d\u63a8\u7406\u9002\u5e94\u8fc7\u7a0b\u4e2d\u5e38\u89c1\u7684\u6a21\u578b\u5d29\u6e83\u548c\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u95ee\u9898\u3002", "method": "\u91c7\u7528\u5168\u9762\u7684\u53ef\u590d\u73b0\u8bad\u7ec3\u65b9\u6848\uff1a1\uff09\u4f7f\u7528\u6df7\u5408\u5e76\u884c\u548c\u5185\u6838\u7ea7\u4f18\u5316\u7684\u5185\u5b58\u9ad8\u6548\u57fa\u7840\u8bbe\u65bd\u652f\u630164K-token\u4e0a\u4e0b\u6587\uff1b2\uff09\u4e24\u9636\u6bb5\u76d1\u7763\u5fae\u8c03\u8bfe\u7a0b\uff0c\u901a\u8fc7\u9a8c\u8bc1\u5bf9\u9f50\u7684\u5408\u6210\u6570\u636e\u7f13\u89e3\u5206\u5e03\u4e0d\u5339\u914d\uff1b3\uff09\u9c81\u68d2\u7684\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u7ba1\u9053\uff0c\u901a\u8fc7\u96be\u5ea6\u611f\u77e5\u6570\u636e\u8fc7\u6ee4\u548c\u6df7\u5408\u7b56\u7565\u8f68\u8ff9\u91cd\u7528\u6765\u7a33\u5b9a\u8bad\u7ec3\u3002", "result": "Motif-2-12.7B-Reasoning\u5728\u6570\u5b66\u3001\u7f16\u7a0b\u548c\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u4e0e\u53c2\u6570\u6570\u91cf\u663e\u8457\u66f4\u5927\u7684\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u4e3a\u793e\u533a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5177\u6709\u7ade\u4e89\u529b\u7684\u5f00\u6e90\u6a21\u578b\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u84dd\u56fe\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u5728\u73b0\u5b9e\u8ba1\u7b97\u7ea6\u675f\u4e0b\u6269\u5c55\u63a8\u7406\u80fd\u529b\uff0c\u5f25\u5408\u4e86\u5f00\u6e90\u6a21\u578b\u4e0e\u524d\u6cbf\u4e13\u6709\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u5dee\u8ddd\u3002"}}
{"id": "2512.11484", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.11484", "abs": "https://arxiv.org/abs/2512.11484", "authors": ["Yukun Cheng", "Shiyu Zhu", "Changhai Ou", "Xingshuo Han", "Yuan Li", "Shihui Zheng"], "title": "Capacitive Touchscreens at Risk: Recovering Handwritten Trajectory on Smartphone via Electromagnetic Emanations", "comment": null, "summary": "This paper reveals and exploits a critical security vulnerability: the electromagnetic (EM) side channel of capacitive touchscreens leaks sufficient information to recover fine-grained, continuous handwriting trajectories. We present Touchscreen Electromagnetic Side-channel Leakage Attack (TESLA), a non-contact attack framework that captures EM signals generated during on-screen writing and regresses them into two-dimensional (2D) handwriting trajectories in real time. Extensive evaluations across a variety of commercial off-the-shelf (COTS) smartphones show that TESLA achieves 77% character recognition accuracy and a Jaccard index of 0.74, demonstrating its capability to recover highly recognizable motion trajectories that closely resemble the original handwriting under realistic attack conditions.", "AI": {"tldr": "TESLA\u653b\u51fb\u5229\u7528\u7535\u5bb9\u89e6\u6478\u5c4f\u7684\u7535\u78c1\u4fa7\u4fe1\u9053\u6f0f\u6d1e\uff0c\u901a\u8fc7\u975e\u63a5\u89e6\u65b9\u5f0f\u6355\u83b7\u4e66\u5199\u65f6\u7684\u7535\u78c1\u4fe1\u53f7\uff0c\u5b9e\u65f6\u6062\u590d\u51fa\u624b\u5199\u8f68\u8ff9\uff0c\u5728\u5546\u7528\u667a\u80fd\u624b\u673a\u4e0a\u8fbe\u523077%\u7684\u5b57\u7b26\u8bc6\u522b\u51c6\u786e\u7387\u3002", "motivation": "\u63ed\u793a\u7535\u5bb9\u89e6\u6478\u5c4f\u5b58\u5728\u4e25\u91cd\u7684\u7535\u78c1\u4fa7\u4fe1\u9053\u5b89\u5168\u6f0f\u6d1e\uff0c\u653b\u51fb\u8005\u53ef\u4ee5\u5229\u7528\u8be5\u6f0f\u6d1e\u4ece\u7535\u78c1\u4fe1\u53f7\u4e2d\u6062\u590d\u51fa\u7cbe\u7ec6\u7684\u8fde\u7eed\u624b\u5199\u8f68\u8ff9\uff0c\u8fd9\u5bf9\u7528\u6237\u9690\u79c1\u6784\u6210\u91cd\u5927\u5a01\u80c1\u3002", "method": "\u63d0\u51faTESLA\uff08\u89e6\u6478\u5c4f\u7535\u78c1\u4fa7\u4fe1\u9053\u6cc4\u6f0f\u653b\u51fb\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u975e\u63a5\u89e6\u65b9\u5f0f\u6355\u83b7\u5c4f\u5e55\u4e66\u5199\u65f6\u4ea7\u751f\u7684\u7535\u78c1\u4fe1\u53f7\uff0c\u4f7f\u7528\u56de\u5f52\u65b9\u6cd5\u5c06\u8fd9\u4e9b\u4fe1\u53f7\u5b9e\u65f6\u8f6c\u6362\u4e3a\u4e8c\u7ef4\u624b\u5199\u8f68\u8ff9\u3002", "result": "\u5728\u591a\u79cd\u5546\u7528\u667a\u80fd\u624b\u673a\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u663e\u793a\uff0cTESLA\u8fbe\u523077%\u7684\u5b57\u7b26\u8bc6\u522b\u51c6\u786e\u7387\u548c0.74\u7684Jaccard\u6307\u6570\uff0c\u8bc1\u660e\u5176\u80fd\u591f\u6062\u590d\u9ad8\u5ea6\u53ef\u8bc6\u522b\u4e14\u4e0e\u539f\u59cb\u624b\u5199\u975e\u5e38\u76f8\u4f3c\u7684\u8fd0\u52a8\u8f68\u8ff9\u3002", "conclusion": "\u7535\u5bb9\u89e6\u6478\u5c4f\u7684\u7535\u78c1\u4fa7\u4fe1\u9053\u6cc4\u6f0f\u4e25\u91cd\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u653b\u51fb\u8005\u53ef\u4ee5\u975e\u63a5\u89e6\u5730\u6062\u590d\u7528\u6237\u624b\u5199\u5185\u5bb9\uff0c\u9700\u8981\u5f00\u53d1\u76f8\u5e94\u7684\u9632\u62a4\u63aa\u65bd\u6765\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u3002"}}
{"id": "2512.11469", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11469", "abs": "https://arxiv.org/abs/2512.11469", "authors": ["Pranav Ramanathan", "Thomas Prellberg", "Matthew Lewis", "Prathamesh Dinesh Joshi", "Raj Abhijit Dandekar", "Rajat Dandekar", "Sreedath Panat"], "title": "Three methods, one problem: Classical and AI approaches to no-three-in-line", "comment": null, "summary": "The No-Three-In-Line problem asks for the maximum number of points that can be placed on an n by n grid with no three collinear, representing a famous problem in combinatorial geometry. While classical methods like Integer Linear Programming (ILP) guarantee optimal solutions, they face exponential scaling with grid size, and recent advances in machine learning offer promising alternatives for pattern-based approximation. This paper presents the first systematic comparison of classical optimization and AI approaches to this problem, evaluating their performance against traditional algorithms. We apply PatternBoost transformer learning and reinforcement learning (PPO) to this problem for the first time, comparing them against ILP. ILP achieves provably optimal solutions up to 19 by 19 grids, while PatternBoost matches optimal performance up to 14 by 14 grids with 96% test loss reduction. PPO achieves perfect solutions on 10 by 10 grids but fails at 11 by 11 grids, where constraint violations prevent valid configurations. These results demonstrate that classical optimization remains essential for exact solutions while AI methods offer competitive performance on smaller instances, with hybrid approaches presenting the most promising direction for scaling to larger problem sizes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u7cfb\u7edf\u6bd4\u8f83\u4e86\u7ecf\u5178\u4f18\u5316\u65b9\u6cd5\uff08\u6574\u6570\u7ebf\u6027\u89c4\u5212ILP\uff09\u4e0eAI\u65b9\u6cd5\uff08PatternBoost\u53d8\u6362\u5668\u5b66\u4e60\u548cPPO\u5f3a\u5316\u5b66\u4e60\uff09\u5728No-Three-In-Line\u95ee\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0ILP\u572819\u00d719\u7f51\u683c\u5185\u80fd\u83b7\u5f97\u6700\u4f18\u89e3\uff0c\u800cAI\u65b9\u6cd5\u5728\u8f83\u5c0f\u7f51\u683c\u4e0a\u8868\u73b0\u826f\u597d\u4f46\u65e0\u6cd5\u4fdd\u8bc1\u6700\u4f18\u6027\u3002", "motivation": "No-Three-In-Line\u662f\u7ec4\u5408\u51e0\u4f55\u4e2d\u7684\u7ecf\u5178\u95ee\u9898\uff0c\u4f20\u7edfILP\u65b9\u6cd5\u867d\u7136\u80fd\u4fdd\u8bc1\u6700\u4f18\u89e3\u4f46\u9762\u4e34\u6307\u6570\u7ea7\u6269\u5c55\u95ee\u9898\uff0c\u800c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4e3a\u6a21\u5f0f\u8fd1\u4f3c\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u66ff\u4ee3\u65b9\u6848\u3002\u8bba\u6587\u65e8\u5728\u9996\u6b21\u7cfb\u7edf\u6bd4\u8f83\u7ecf\u5178\u4f18\u5316\u4e0eAI\u65b9\u6cd5\u5728\u8be5\u95ee\u9898\u4e0a\u7684\u6027\u80fd\u3002", "method": "\u5e94\u7528\u4e09\u79cd\u65b9\u6cd5\uff1a1\uff09\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08ILP\uff09\u4f5c\u4e3a\u7ecf\u5178\u4f18\u5316\u57fa\u51c6\uff1b2\uff09\u9996\u6b21\u5e94\u7528PatternBoost\u53d8\u6362\u5668\u5b66\u4e60\uff1b3\uff09\u9996\u6b21\u5e94\u7528PPO\u5f3a\u5316\u5b66\u4e60\u3002\u5c06\u8fd9\u4e9b\u65b9\u6cd5\u4e0e\u4f20\u7edf\u7b97\u6cd5\u8fdb\u884c\u6027\u80fd\u6bd4\u8f83\u3002", "result": "ILP\u572819\u00d719\u7f51\u683c\u5185\u83b7\u5f97\u53ef\u8bc1\u660e\u7684\u6700\u4f18\u89e3\uff1bPatternBoost\u572814\u00d714\u7f51\u683c\u5185\u5339\u914d\u6700\u4f18\u6027\u80fd\uff0c\u6d4b\u8bd5\u635f\u5931\u51cf\u5c1196%\uff1bPPO\u572810\u00d710\u7f51\u683c\u4e0a\u83b7\u5f97\u5b8c\u7f8e\u89e3\uff0c\u4f46\u572811\u00d711\u7f51\u683c\u4e0a\u56e0\u7ea6\u675f\u8fdd\u53cd\u800c\u5931\u8d25\u3002", "conclusion": "\u7ecf\u5178\u4f18\u5316\u5bf9\u4e8e\u7cbe\u786e\u89e3\u4ecd\u7136\u81f3\u5173\u91cd\u8981\uff0c\u800cAI\u65b9\u6cd5\u5728\u8f83\u5c0f\u5b9e\u4f8b\u4e0a\u63d0\u4f9b\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\u3002\u6df7\u5408\u65b9\u6cd5\u4e3a\u6269\u5c55\u5230\u66f4\u5927\u95ee\u9898\u89c4\u6a21\u63d0\u4f9b\u4e86\u6700\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2512.11690", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2512.11690", "abs": "https://arxiv.org/abs/2512.11690", "authors": ["Grant Bosworth", "Keewoo Lee", "Sunwoong Kim"], "title": "Leveraging FPGAs for Homomorphic Matrix-Vector Multiplication in Oblivious Message Retrieval", "comment": null, "summary": "While end-to-end encryption protects the content of messages, it does not secure metadata, which exposes sender and receiver information through traffic analysis. A plausible approach to protecting this metadata is to have senders post encrypted messages on a public bulletin board and receivers scan it for relevant messages. Oblivious message retrieval (OMR) leverages homomorphic encryption (HE) to improve user experience in this solution by delegating the scan to a resource-rich server while preserving privacy. A key process in OMR is the homomorphic detection of pertinent messages for the receiver from the bulletin board. It relies on a specialized matrix-vector multiplication algorithm, which involves extensive multiplications between ciphertext vectors and plaintext matrices, as well as homomorphic rotations. The computationally intensive nature of this process limits the practicality of OMR. To address this challenge, this paper proposes a hardware architecture to accelerate the matrix-vector multiplication algorithm. The building homomorphic operators in this algorithm are implemented using high-level synthesis, with design parameters for different parallelism levels. These operators are then deployed on a field-programmable gate array platform using an efficient design space exploration strategy to accelerate homomorphic matrix-vector multiplication. Compared to a software implementation, the proposed hardware accelerator achieves a 13.86x speedup.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u786c\u4ef6\u67b6\u6784\u6765\u52a0\u901fOblivious Message Retrieval\uff08OMR\uff09\u4e2d\u7684\u540c\u6001\u77e9\u9635\u5411\u91cf\u4e58\u6cd5\u7b97\u6cd5\uff0c\u76f8\u6bd4\u8f6f\u4ef6\u5b9e\u73b0\u83b7\u5f97\u4e8613.86\u500d\u7684\u52a0\u901f\u6bd4\u3002", "motivation": "\u7aef\u5230\u7aef\u52a0\u5bc6\u4fdd\u62a4\u6d88\u606f\u5185\u5bb9\u4f46\u4e0d\u4fdd\u62a4\u5143\u6570\u636e\uff0cOMR\u4f7f\u7528\u540c\u6001\u52a0\u5bc6\u6765\u4fdd\u62a4\u5143\u6570\u636e\u9690\u79c1\uff0c\u4f46\u5176\u6838\u5fc3\u7684\u540c\u6001\u77e9\u9635\u5411\u91cf\u4e58\u6cd5\u7b97\u6cd5\u8ba1\u7b97\u5bc6\u96c6\uff0c\u9650\u5236\u4e86OMR\u7684\u5b9e\u7528\u6027\u3002", "method": "\u63d0\u51fa\u786c\u4ef6\u67b6\u6784\u52a0\u901f\u540c\u6001\u77e9\u9635\u5411\u91cf\u4e58\u6cd5\u7b97\u6cd5\uff0c\u4f7f\u7528\u9ad8\u5c42\u6b21\u7efc\u5408\u5b9e\u73b0\u540c\u6001\u7b97\u5b50\uff0c\u63d0\u4f9b\u4e0d\u540c\u5e76\u884c\u7ea7\u522b\u7684\u8bbe\u8ba1\u53c2\u6570\uff0c\u5728FPGA\u5e73\u53f0\u4e0a\u91c7\u7528\u9ad8\u6548\u7684\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u7b56\u7565\u8fdb\u884c\u90e8\u7f72\u3002", "result": "\u76f8\u6bd4\u8f6f\u4ef6\u5b9e\u73b0\uff0c\u63d0\u51fa\u7684\u786c\u4ef6\u52a0\u901f\u5668\u5b9e\u73b0\u4e8613.86\u500d\u7684\u52a0\u901f\u6bd4\u3002", "conclusion": "\u901a\u8fc7\u786c\u4ef6\u52a0\u901f\u540c\u6001\u77e9\u9635\u5411\u91cf\u4e58\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86OMR\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u4f7f\u5176\u66f4\u5177\u5b9e\u7528\u6027\u3002"}}
{"id": "2512.11505", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.11505", "abs": "https://arxiv.org/abs/2512.11505", "authors": ["Priyam Basu", "Yunfeng Zhang", "Vipul Raheja"], "title": "BAID: A Benchmark for Bias Assessment of AI Detectors", "comment": "Accepted at the workshop on Agentic AI Benchmarks and Applications for Enterprise Tasks at AAAI 2026", "summary": "AI-generated text detectors have recently gained adoption in educational and professional contexts. Prior research has uncovered isolated cases of bias, particularly against English Language Learners (ELLs) however, there is a lack of systematic evaluation of such systems across broader sociolinguistic factors. In this work, we propose BAID, a comprehensive evaluation framework for AI detectors across various types of biases. As a part of the framework, we introduce over 200k samples spanning 7 major categories: demographics, age, educational grade level, dialect, formality, political leaning, and topic. We also generated synthetic versions of each sample with carefully crafted prompts to preserve the original content while reflecting subgroup-specific writing styles. Using this, we evaluate four open-source state-of-the-art AI text detectors and find consistent disparities in detection performance, particularly low recall rates for texts from underrepresented groups. Our contributions provide a scalable, transparent approach for auditing AI detectors and emphasize the need for bias-aware evaluation before these tools are deployed for public use.", "AI": {"tldr": "BAID\u662f\u4e00\u4e2a\u8bc4\u4f30AI\u6587\u672c\u68c0\u6d4b\u5668\u504f\u89c1\u7684\u7efc\u5408\u6846\u67b6\uff0c\u5305\u542b\u8d85\u8fc720\u4e07\u4e2a\u6837\u672c\uff0c\u6db5\u76d67\u4e2a\u4e3b\u8981\u793e\u4f1a\u8bed\u8a00\u5b66\u7c7b\u522b\uff0c\u53d1\u73b0\u73b0\u6709\u68c0\u6d4b\u5668\u5bf9\u5c11\u6570\u7fa4\u4f53\u6587\u672c\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u89c1\u3002", "motivation": "AI\u751f\u6210\u7684\u6587\u672c\u68c0\u6d4b\u5668\u5df2\u5728\u6559\u80b2\u548c\u4e13\u4e1a\u9886\u57df\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5148\u524d\u7814\u7a76\u4ec5\u53d1\u73b0\u5b64\u7acb\u504f\u89c1\u6848\u4f8b\uff08\u7279\u522b\u662f\u9488\u5bf9\u82f1\u8bed\u5b66\u4e60\u8005\uff09\uff0c\u7f3a\u4e4f\u5bf9\u793e\u4f1a\u8bed\u8a00\u5b66\u56e0\u7d20\u7684\u7cfb\u7edf\u6027\u8bc4\u4f30\u3002", "method": "\u63d0\u51faBAID\u8bc4\u4f30\u6846\u67b6\uff0c\u5f15\u5165\u8d85\u8fc720\u4e07\u4e2a\u6837\u672c\uff0c\u6db5\u76d67\u4e2a\u4e3b\u8981\u7c7b\u522b\uff1a\u4eba\u53e3\u7edf\u8ba1\u3001\u5e74\u9f84\u3001\u6559\u80b2\u5e74\u7ea7\u3001\u65b9\u8a00\u3001\u6b63\u5f0f\u7a0b\u5ea6\u3001\u653f\u6cbb\u503e\u5411\u548c\u4e3b\u9898\u3002\u4e3a\u6bcf\u4e2a\u6837\u672c\u751f\u6210\u5408\u6210\u7248\u672c\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u8bcd\u4fdd\u7559\u539f\u59cb\u5185\u5bb9\u540c\u65f6\u53cd\u6620\u7279\u5b9a\u5b50\u7fa4\u4f53\u7684\u5199\u4f5c\u98ce\u683c\u3002\u4f7f\u7528\u8be5\u6846\u67b6\u8bc4\u4f304\u4e2a\u5f00\u6e90\u6700\u5148\u8fdb\u7684AI\u6587\u672c\u68c0\u6d4b\u5668\u3002", "result": "\u53d1\u73b0\u68c0\u6d4b\u6027\u80fd\u5b58\u5728\u4e00\u81f4\u5dee\u5f02\uff0c\u7279\u522b\u662f\u5bf9\u6765\u81ea\u4ee3\u8868\u6027\u4e0d\u8db3\u7fa4\u4f53\u7684\u6587\u672c\u53ec\u56de\u7387\u8f83\u4f4e\u3002\u68c0\u6d4b\u5668\u5728\u4e0d\u540c\u793e\u4f1a\u8bed\u8a00\u5b66\u7fa4\u4f53\u95f4\u8868\u73b0\u51fa\u7cfb\u7edf\u6027\u504f\u89c1\u3002", "conclusion": "BAID\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u900f\u660e\u7684AI\u68c0\u6d4b\u5668\u5ba1\u8ba1\u65b9\u6cd5\uff0c\u5f3a\u8c03\u5728\u5de5\u5177\u90e8\u7f72\u524d\u9700\u8981\u8fdb\u884c\u504f\u89c1\u611f\u77e5\u8bc4\u4f30\u3002\u7814\u7a76\u63ed\u793a\u4e86\u73b0\u6709\u68c0\u6d4b\u5668\u9700\u8981\u6539\u8fdb\u4ee5\u516c\u5e73\u5bf9\u5f85\u6240\u6709\u7528\u6237\u7fa4\u4f53\u3002"}}
{"id": "2512.11699", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.11699", "abs": "https://arxiv.org/abs/2512.11699", "authors": ["Roberta De Viti", "Vaastav Anand", "Pierfrancesco Ingo", "Deepak Garg"], "title": "SoK: Demystifying the multiverse of MPC protocols", "comment": null, "summary": "This paper systematizes knowledge on the performance of Multi-Party Computation (MPC) protocols. Despite strong privacy and correctness guarantees, MPC adoption in real-world applications remains limited by high costs (especially in the malicious setting) and lack of guidance on choosing suitable protocols for concrete workloads. We identify the theoretical and practical parameters that shape MPC efficiency and conduct an extensive experimental study across diverse benchmarks. Our analysis discusses the trade-offs between protocols, and highlights which techniques align best with different application scenarios and needs. By providing actionable guidance for developers and outlining open challenges for researchers, this work seeks to narrow the gap between MPC theory and practice.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5316\u5206\u6790\u4e86\u591a\u65b9\u8ba1\u7b97(MPC)\u534f\u8bae\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u5e7f\u6cdb\u5b9e\u9a8c\u7814\u7a76\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u5b9e\u7528\u6307\u5bfc\uff0c\u65e8\u5728\u7f29\u5c0fMPC\u7406\u8bba\u4e0e\u5b9e\u8df5\u7684\u5dee\u8ddd\u3002", "motivation": "\u5c3d\u7ba1MPC\u5177\u6709\u5f3a\u5927\u7684\u9690\u79c1\u548c\u6b63\u786e\u6027\u4fdd\u8bc1\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u91c7\u7528\u4ecd\u7136\u6709\u9650\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u6076\u610f\u8bbe\u7f6e\u4e0b\u7684\u9ad8\u6210\u672c\u548c\u7f3a\u4e4f\u9488\u5bf9\u5177\u4f53\u5de5\u4f5c\u8d1f\u8f7d\u9009\u62e9\u5408\u9002\u534f\u8bae\u7684\u6307\u5bfc\u3002", "method": "\u8bc6\u522b\u5f71\u54cdMPC\u6548\u7387\u7684\u7406\u8bba\u548c\u5b9e\u9645\u53c2\u6570\uff0c\u5bf9\u4e0d\u540c\u57fa\u51c6\u6d4b\u8bd5\u8fdb\u884c\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u7814\u7a76\uff0c\u5206\u6790\u534f\u8bae\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u5e76\u7a81\u51fa\u663e\u793a\u54ea\u4e9b\u6280\u672f\u6700\u9002\u5408\u4e0d\u540c\u7684\u5e94\u7528\u573a\u666f\u548c\u9700\u6c42\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790\u63ed\u793a\u4e86MPC\u534f\u8bae\u7684\u6027\u80fd\u7279\u5f81\u548c\u6743\u8861\u5173\u7cfb\uff0c\u4e3a\u4e0d\u540c\u5e94\u7528\u573a\u666f\u63d0\u4f9b\u4e86\u6280\u672f\u9009\u62e9\u6307\u5bfc\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u6027\u80fd\u5206\u6790\u548c\u5b9e\u7528\u6307\u5bfc\uff0c\u65e8\u5728\u5e2e\u52a9\u5f00\u53d1\u8005\u66f4\u597d\u5730\u9009\u62e9MPC\u534f\u8bae\uff0c\u5e76\u4e3a\u7814\u7a76\u4eba\u5458\u6307\u660e\u5f00\u653e\u6311\u6218\uff0c\u4ece\u800c\u7f29\u5c0fMPC\u7406\u8bba\u4e0e\u5b9e\u8df5\u7684\u5dee\u8ddd\u3002"}}
{"id": "2512.11783", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11783", "abs": "https://arxiv.org/abs/2512.11783", "authors": ["Andrew Adiletta", "Kathryn Adiletta", "Kemal Derya", "Berk Sunar"], "title": "Super Suffixes: Bypassing Text Generation Alignment and Guard Models Simultaneously", "comment": "13 pages, 5 Figures", "summary": "The rapid deployment of Large Language Models (LLMs) has created an urgent need for enhanced security and privacy measures in Machine Learning (ML). LLMs are increasingly being used to process untrusted text inputs and even generate executable code, often while having access to sensitive system controls. To address these security concerns, several companies have introduced guard models, which are smaller, specialized models designed to protect text generation models from adversarial or malicious inputs. In this work, we advance the study of adversarial inputs by introducing Super Suffixes, suffixes capable of overriding multiple alignment objectives across various models with different tokenization schemes. We demonstrate their effectiveness, along with our joint optimization technique, by successfully bypassing the protection mechanisms of Llama Prompt Guard 2 on five different text generation models for malicious text and code generation. To the best of our knowledge, this is the first work to reveal that Llama Prompt Guard 2 can be compromised through joint optimization.\n  Additionally, by analyzing the changing similarity of a model's internal state to specific concept directions during token sequence processing, we propose an effective and lightweight method to detect Super Suffix attacks. We show that the cosine similarity between the residual stream and certain concept directions serves as a distinctive fingerprint of model intent. Our proposed countermeasure, DeltaGuard, significantly improves the detection of malicious prompts generated through Super Suffixes. It increases the non-benign classification rate to nearly 100%, making DeltaGuard a valuable addition to the guard model stack and enhancing robustness against adversarial prompt attacks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSuper Suffixes\u653b\u51fb\u65b9\u6cd5\uff0c\u53ef\u7ed5\u8fc7Llama Prompt Guard 2\u7b49\u9632\u62a4\u6a21\u578b\uff0c\u5e76\u5f00\u53d1DeltaGuard\u68c0\u6d4b\u6280\u672f\u8fdb\u884c\u9632\u5fa1\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5904\u7406\u4e0d\u53ef\u4fe1\u6587\u672c\u8f93\u5165\u548c\u6267\u884c\u4ee3\u7801\u751f\u6210\u65f6\u9762\u4e34\u5b89\u5168\u98ce\u9669\u3002\u73b0\u6709\u9632\u62a4\u6a21\u578b\u5b58\u5728\u88ab\u7ed5\u8fc7\u7684\u53ef\u80fd\u6027\uff0c\u9700\u8981\u7814\u7a76\u66f4\u5f3a\u5927\u7684\u653b\u51fb\u65b9\u6cd5\u548c\u76f8\u5e94\u7684\u9632\u5fa1\u63aa\u65bd\u3002", "method": "1. \u63d0\u51faSuper Suffixes\u653b\u51fb\u65b9\u6cd5\uff1a\u901a\u8fc7\u8054\u5408\u4f18\u5316\u6280\u672f\u751f\u6210\u80fd\u7ed5\u8fc7\u591a\u79cd\u5bf9\u9f50\u76ee\u6807\u7684\u540e\u7f00\uff1b2. \u5f00\u53d1DeltaGuard\u68c0\u6d4b\u6280\u672f\uff1a\u901a\u8fc7\u5206\u6790\u6a21\u578b\u5185\u90e8\u72b6\u6001\u4e0e\u7279\u5b9a\u6982\u5ff5\u65b9\u5411\u4f59\u5f26\u76f8\u4f3c\u5ea6\u7684\u53d8\u5316\u6765\u8bc6\u522b\u653b\u51fb\u3002", "result": "1. Super Suffixes\u6210\u529f\u7ed5\u8fc7\u4e86Llama Prompt Guard 2\u5bf95\u4e2a\u4e0d\u540c\u6587\u672c\u751f\u6210\u6a21\u578b\u7684\u4fdd\u62a4\uff1b2. DeltaGuard\u5c06\u975e\u826f\u6027\u5206\u7c7b\u7387\u63d0\u5347\u81f3\u8fd1100%\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5bf9Super Suffixes\u653b\u51fb\u7684\u68c0\u6d4b\u80fd\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u9996\u6b21\u63ed\u793a\u4e86Llama Prompt Guard 2\u53ef\u901a\u8fc7\u8054\u5408\u4f18\u5316\u88ab\u7ed5\u8fc7\uff0c\u540c\u65f6\u63d0\u51fa\u7684DeltaGuard\u68c0\u6d4b\u6280\u672f\u80fd\u6709\u6548\u9632\u5fa1\u6b64\u7c7b\u653b\u51fb\uff0c\u4e3a\u9632\u62a4\u6a21\u578b\u6808\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u589e\u5f3a\u65b9\u6848\u3002"}}
{"id": "2512.11544", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11544", "abs": "https://arxiv.org/abs/2512.11544", "authors": ["Yuan Shen", "Xiaojun Wu", "Linghua Yu"], "title": "AI-MASLD Metabolic Dysfunction and Information Steatosis of Large Language Models in Unstructured Clinical Narratives", "comment": "47 pages, 2 figures", "summary": "This study aims to simulate real-world clinical scenarios to systematically evaluate the ability of Large Language Models (LLMs) to extract core medical information from patient chief complaints laden with noise and redundancy, and to verify whether they exhibit a functional decline analogous to Metabolic Dysfunction-Associated Steatotic Liver Disease (MASLD). We employed a cross-sectional analysis design based on standardized medical probes, selecting four mainstream LLMs as research subjects: GPT-4o, Gemini 2.5, DeepSeek 3.1, and Qwen3-Max. An evaluation system comprising twenty medical probes across five core dimensions was used to simulate a genuine clinical communication environment. All probes had gold-standard answers defined by clinical experts and were assessed via a double-blind, inverse rating scale by two independent clinicians. The results show that all tested models exhibited functional defects to varying degrees, with Qwen3-Max demonstrating the best overall performance and Gemini 2.5 the worst. Under conditions of extreme noise, most models experienced a functional collapse. Notably, GPT-4o made a severe misjudgment in the risk assessment for pulmonary embolism (PE) secondary to deep vein thrombosis (DVT). This research is the first to empirically confirm that LLMs exhibit features resembling metabolic dysfunction when processing clinical information, proposing the innovative concept of \"AI-Metabolic Dysfunction-Associated Steatotic Liver Disease (AI-MASLD)\". These findings offer a crucial safety warning for the application of Artificial Intelligence (AI) in healthcare, emphasizing that current LLMs must be used as auxiliary tools under human expert supervision, as there remains a significant gap between their theoretical knowledge and practical clinical application.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u6a21\u62df\u771f\u5b9e\u4e34\u5e8a\u573a\u666f\uff0c\u8bc4\u4f30\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u5608\u6742\u5197\u4f59\u7684\u60a3\u8005\u4e3b\u8bc9\u4e2d\u63d0\u53d6\u6838\u5fc3\u533b\u7597\u4fe1\u606f\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u6240\u6709\u6a21\u578b\u5747\u5b58\u5728\u4e0d\u540c\u7a0b\u5ea6\u7684\u529f\u80fd\u7f3a\u9677\uff0c\u5e76\u63d0\u51fa\"AI-MASLD\"\u6982\u5ff5\u7c7b\u6bd4\u4ee3\u8c22\u529f\u80fd\u969c\u788d\u3002", "motivation": "\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u771f\u5b9e\u4e34\u5e8a\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u8868\u73b0\uff0c\u9a8c\u8bc1\u5176\u662f\u5426\u5b58\u5728\u7c7b\u4f3c\u4ee3\u8c22\u529f\u80fd\u969c\u788d\u7684\u6027\u80fd\u4e0b\u964d\uff0c\u4e3aAI\u5728\u533b\u7597\u9886\u57df\u7684\u5e94\u7528\u63d0\u4f9b\u5b89\u5168\u8b66\u793a\u3002", "method": "\u91c7\u7528\u6a2a\u65ad\u9762\u5206\u6790\u8bbe\u8ba1\uff0c\u57fa\u4e8e\u6807\u51c6\u5316\u533b\u7597\u63a2\u9488\uff0c\u9009\u53d6GPT-4o\u3001Gemini 2.5\u3001DeepSeek 3.1\u548cQwen3-Max\u56db\u4e2a\u4e3b\u6d41LLMs\u4f5c\u4e3a\u7814\u7a76\u5bf9\u8c61\uff0c\u4f7f\u7528\u5305\u542b20\u4e2a\u533b\u7597\u63a2\u9488\u7684\u8bc4\u4f30\u7cfb\u7edf\u6a21\u62df\u771f\u5b9e\u4e34\u5e8a\u6c9f\u901a\u73af\u5883\uff0c\u7531\u4e24\u4f4d\u72ec\u7acb\u4e34\u5e8a\u533b\u751f\u8fdb\u884c\u53cc\u76f2\u9006\u5411\u8bc4\u5206\u3002", "result": "\u6240\u6709\u6d4b\u8bd5\u6a21\u578b\u5747\u8868\u73b0\u51fa\u4e0d\u540c\u7a0b\u5ea6\u7684\u529f\u80fd\u7f3a\u9677\uff0cQwen3-Max\u6574\u4f53\u8868\u73b0\u6700\u4f73\uff0cGemini 2.5\u6700\u5dee\uff1b\u6781\u7aef\u566a\u97f3\u6761\u4ef6\u4e0b\u591a\u6570\u6a21\u578b\u51fa\u73b0\u529f\u80fd\u5d29\u6e83\uff1bGPT-4o\u5728\u6df1\u9759\u8109\u8840\u6813\u7ee7\u53d1\u80ba\u6813\u585e\u98ce\u9669\u8bc4\u4f30\u4e2d\u505a\u51fa\u4e25\u91cd\u8bef\u5224\u3002", "conclusion": "\u9996\u6b21\u5b9e\u8bc1\u786e\u8ba4LLMs\u5728\u5904\u7406\u4e34\u5e8a\u4fe1\u606f\u65f6\u8868\u73b0\u51fa\u7c7b\u4f3c\u4ee3\u8c22\u529f\u80fd\u969c\u788d\u7684\u7279\u5f81\uff0c\u63d0\u51fa\"AI-MASLD\"\u521b\u65b0\u6982\u5ff5\uff0c\u5f3a\u8c03\u5f53\u524dLLMs\u5fc5\u987b\u5728\u4eba\u7c7b\u4e13\u5bb6\u76d1\u7763\u4e0b\u4f5c\u4e3a\u8f85\u52a9\u5de5\u5177\u4f7f\u7528\uff0c\u5176\u7406\u8bba\u77e5\u8bc6\u4e0e\u5b9e\u9645\u4e34\u5e8a\u5e94\u7528\u4ecd\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002"}}
{"id": "2512.11588", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11588", "abs": "https://arxiv.org/abs/2512.11588", "authors": ["Gregor von Laszewski", "Wesley Brewer", "Jeyan Thiyagalingam", "Juri Papay", "Armstrong Foundjem", "Piotr Luszczek", "Murali Emani", "Shirley V. Moore", "Vijay Janapa Reddi", "Matthew D. Sinclair", "Sebastian Lobentanzer", "Sujata Goswami", "Benjamin Hawks", "Marco Colombo", "Nhan Tran", "Christine R. Kirkpatrick", "Abdulkareem Alsudais", "Gregg Barrett", "Tianhao Li", "Kirsten Morehouse", "Shivaram Venkataraman", "Rutwik Jain", "Kartik Mathur", "Victor Lu", "Tejinder Singh", "Khojasteh Z. Mirza", "Kongtao Chen", "Sasidhar Kunapuli", "Gavin Farrell", "Renato Umeton", "Geoffrey C. Fox"], "title": "AI Benchmark Democratization and Carpentry", "comment": "43 pages, 2 figures, 7 tables", "summary": "Benchmarks are a cornerstone of modern machine learning, enabling reproducibility, comparison, and scientific progress. However, AI benchmarks are increasingly complex, requiring dynamic, AI-focused workflows. Rapid evolution in model architectures, scale, datasets, and deployment contexts makes evaluation a moving target. Large language models often memorize static benchmarks, causing a gap between benchmark results and real-world performance.\n  Beyond traditional static benchmarks, continuous adaptive benchmarking frameworks are needed to align scientific assessment with deployment risks. This calls for skills and education in AI Benchmark Carpentry. From our experience with MLCommons, educational initiatives, and programs like the DOE's Trillion Parameter Consortium, key barriers include high resource demands, limited access to specialized hardware, lack of benchmark design expertise, and uncertainty in relating results to application domains. Current benchmarks often emphasize peak performance on top-tier hardware, offering limited guidance for diverse, real-world scenarios.\n  Benchmarking must become dynamic, incorporating evolving models, updated data, and heterogeneous platforms while maintaining transparency, reproducibility, and interpretability. Democratization requires both technical innovation and systematic education across levels, building sustained expertise in benchmark design and use. Benchmarks should support application-relevant comparisons, enabling informed, context-sensitive decisions. Dynamic, inclusive benchmarking will ensure evaluation keeps pace with AI evolution and supports responsible, reproducible, and accessible AI deployment. Community efforts can provide a foundation for AI Benchmark Carpentry.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u5f53\u524dAI\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u9759\u6001\u5316\u3001\u8d44\u6e90\u9700\u6c42\u9ad8\u3001\u4e0e\u73b0\u5b9e\u5e94\u7528\u8131\u8282\u7b49\u95ee\u9898\uff0c\u63d0\u51fa\u9700\u8981\u52a8\u6001\u81ea\u9002\u5e94\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\u548cAI\u57fa\u51c6\u6d4b\u8bd5\u6559\u80b2\u4f53\u7cfb", "motivation": "\u4f20\u7edf\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u9002\u5e94AI\u5feb\u901f\u53d1\u5c55\uff0c\u6a21\u578b\u5bb9\u6613\u8bb0\u5fc6\u9759\u6001\u6d4b\u8bd5\u96c6\uff0c\u5bfc\u81f4\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\u4e0e\u73b0\u5b9e\u4e16\u754c\u6027\u80fd\u5b58\u5728\u5dee\u8ddd\u3002\u540c\u65f6\uff0c\u57fa\u51c6\u6d4b\u8bd5\u9762\u4e34\u9ad8\u8d44\u6e90\u9700\u6c42\u3001\u786c\u4ef6\u8bbf\u95ee\u9650\u5236\u3001\u8bbe\u8ba1\u4e13\u4e1a\u77e5\u8bc6\u7f3a\u4e4f\u7b49\u969c\u788d", "method": "\u63d0\u51fa\u52a8\u6001\u81ea\u9002\u5e94\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u7ed3\u5408\u6301\u7eed\u6f14\u8fdb\u7684\u6a21\u578b\u3001\u66f4\u65b0\u6570\u636e\u548c\u5f02\u6784\u5e73\u53f0\u3002\u5021\u5bfc\u5efa\u7acbAI\u57fa\u51c6\u6d4b\u8bd5\u6559\u80b2\u4f53\u7cfb\uff08AI Benchmark Carpentry\uff09\uff0c\u901a\u8fc7\u6280\u672f\u9769\u65b0\u548c\u7cfb\u7edf\u6027\u6559\u80b2\u6765\u63d0\u5347\u57fa\u51c6\u6d4b\u8bd5\u8bbe\u8ba1\u548c\u4f7f\u7528\u80fd\u529b", "result": "\u8bc6\u522b\u4e86\u5f53\u524d\u57fa\u51c6\u6d4b\u8bd5\u7684\u4e3b\u8981\u969c\u788d\uff1a\u9ad8\u8d44\u6e90\u9700\u6c42\u3001\u4e13\u4e1a\u786c\u4ef6\u8bbf\u95ee\u9650\u5236\u3001\u8bbe\u8ba1\u4e13\u4e1a\u77e5\u8bc6\u7f3a\u4e4f\u3001\u7ed3\u679c\u4e0e\u5e94\u7528\u9886\u57df\u5173\u8054\u4e0d\u786e\u5b9a\u6027\u3002\u5f3a\u8c03\u57fa\u51c6\u6d4b\u8bd5\u9700\u8981\u652f\u6301\u5e94\u7528\u76f8\u5173\u7684\u6bd4\u8f83\uff0c\u5b9e\u73b0\u900f\u660e\u3001\u53ef\u590d\u73b0\u548c\u53ef\u89e3\u91ca\u7684\u8bc4\u4f30", "conclusion": "\u52a8\u6001\u5305\u5bb9\u7684\u57fa\u51c6\u6d4b\u8bd5\u5bf9\u4e8eAI\u8d1f\u8d23\u4efb\u3001\u53ef\u590d\u73b0\u548c\u53ef\u8bbf\u95ee\u7684\u90e8\u7f72\u81f3\u5173\u91cd\u8981\u3002\u793e\u533a\u52aa\u529b\u53ef\u4ee5\u4e3aAI\u57fa\u51c6\u6d4b\u8bd5\u6559\u80b2\u63d0\u4f9b\u57fa\u7840\uff0c\u786e\u4fdd\u8bc4\u4f30\u4e0eAI\u53d1\u5c55\u540c\u6b65\uff0c\u652f\u6301\u57fa\u4e8e\u60c5\u5883\u7684\u660e\u667a\u51b3\u7b56"}}
{"id": "2512.11653", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11653", "abs": "https://arxiv.org/abs/2512.11653", "authors": ["Chutian Ma", "Grigorii Pomazkin", "Giacinto Paolo Saggese", "Paul Smith"], "title": "Causal Inference in Energy Demand Prediction", "comment": null, "summary": "Energy demand prediction is critical for grid operators, industrial energy\n  consumers, and service providers. Energy demand is influenced by multiple\n  factors, including weather conditions (e.g. temperature, humidity, wind\n  speed, solar radiation), and calendar information (e.g. hour of day and\n  month of year), which further affect daily work and life schedules. These\n  factors are causally interdependent, making the problem more complex than\n  simple correlation-based learning techniques satisfactorily allow for. We\n  propose a structural causal model that explains the causal relationship\n  between these variables. A full analysis is performed to validate our causal\n  beliefs, also revealing important insights consistent with prior studies.\n  For example, our causal model reveals that energy demand responds to\n  temperature fluctuations with season-dependent sensitivity. Additionally, we\n  find that energy demand exhibits lower variance in winter due to the\n  decoupling effect between temperature changes and daily activity patterns.\n  We then build a Bayesian model, which takes advantage of the causal insights\n  we learned as prior knowledge. The model is trained and tested on unseen\n  data and yields state-of-the-art performance in the form of a 3.84 percent MAPE on\n  the test set. The model also demonstrates strong robustness, as the\n  cross-validation across two years of data yields an average MAPE of 3.88 percent.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u7684\u80fd\u6e90\u9700\u6c42\u9884\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u5929\u6c14\u56e0\u7d20\u548c\u65e5\u5386\u4fe1\u606f\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u6784\u5efa\u8d1d\u53f6\u65af\u6a21\u578b\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u9884\u6d4b\u3002", "motivation": "\u80fd\u6e90\u9700\u6c42\u9884\u6d4b\u5bf9\u7535\u7f51\u8fd0\u8425\u5546\u3001\u5de5\u4e1a\u80fd\u6e90\u6d88\u8d39\u8005\u548c\u670d\u52a1\u63d0\u4f9b\u5546\u81f3\u5173\u91cd\u8981\u3002\u80fd\u6e90\u9700\u6c42\u53d7\u591a\u79cd\u56e0\u7d20\u5f71\u54cd\uff0c\u5305\u62ec\u5929\u6c14\u6761\u4ef6\u548c\u65e5\u5386\u4fe1\u606f\uff0c\u8fd9\u4e9b\u56e0\u7d20\u4e4b\u95f4\u5b58\u5728\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb\uff0c\u4f7f\u5f97\u7b80\u5355\u57fa\u4e8e\u76f8\u5173\u6027\u7684\u5b66\u4e60\u65b9\u6cd5\u96be\u4ee5\u5145\u5206\u89e3\u51b3\u8fd9\u4e00\u590d\u6742\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u6765\u89e3\u91ca\u53d8\u91cf\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u8fdb\u884c\u5b8c\u6574\u5206\u6790\u9a8c\u8bc1\u56e0\u679c\u4fe1\u5ff5\u3002\u7136\u540e\u6784\u5efa\u8d1d\u53f6\u65af\u6a21\u578b\uff0c\u5229\u7528\u5b66\u5230\u7684\u56e0\u679c\u6d1e\u5bdf\u4f5c\u4e3a\u5148\u9a8c\u77e5\u8bc6\uff0c\u5728\u672a\u89c1\u6570\u636e\u4e0a\u8fdb\u884c\u8bad\u7ec3\u548c\u6d4b\u8bd5\u3002", "result": "\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u83b7\u5f973.84%\u7684MAPE\uff08\u5e73\u5747\u7edd\u5bf9\u767e\u5206\u6bd4\u8bef\u5dee\uff09\uff0c\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002\u8de8\u4e24\u5e74\u6570\u636e\u7684\u4ea4\u53c9\u9a8c\u8bc1\u5e73\u5747MAPE\u4e3a3.88%\uff0c\u663e\u793a\u51fa\u5f3a\u5927\u7684\u9c81\u68d2\u6027\u3002\u56e0\u679c\u5206\u6790\u63ed\u793a\u4e86\u80fd\u6e90\u9700\u6c42\u5bf9\u6e29\u5ea6\u6ce2\u52a8\u7684\u54cd\u5e94\u5177\u6709\u5b63\u8282\u4f9d\u8d56\u6027\u654f\u611f\u6027\uff0c\u51ac\u5b63\u80fd\u6e90\u9700\u6c42\u65b9\u5dee\u8f83\u4f4e\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u5206\u6790\u80fd\u6e90\u9700\u6c42\u7684\u5f71\u54cd\u56e0\u7d20\uff0c\u5e76\u5229\u7528\u8fd9\u4e9b\u56e0\u679c\u6d1e\u5bdf\u6784\u5efa\u8d1d\u53f6\u65af\u9884\u6d4b\u6a21\u578b\uff0c\u80fd\u591f\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u3001\u9c81\u68d2\u7684\u80fd\u6e90\u9700\u6c42\u9884\u6d4b\uff0c\u4e3a\u76f8\u5173\u51b3\u7b56\u63d0\u4f9b\u53ef\u9760\u652f\u6301\u3002"}}
