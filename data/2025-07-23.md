<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 16]
- [cs.CR](#cs.CR) [Total: 18]
- [cs.AI](#cs.AI) [Total: 42]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [AlgoTune: Can Language Models Speed Up General-Purpose Numerical Programs?](https://arxiv.org/abs/2507.15887)
*Ori Press,Brandon Amos,Haoyu Zhao,Yikai Wu,Samuel K. Ainsworth,Dominik Krupke,Patrick Kidger,Touqir Sajed,Bartolomeo Stellato,Jisun Park,Nathanael Bosch,Eli Meril,Albert Steppi,Arman Zharmagambetov,Fangzhao Zhang,David Perez-Pineiro,Alberto Mercurio,Ni Zhan,Talor Abramovich,Kilian Lieret,Hanlin Zhang,Shirley Huang,Matthias Bethge,Ofir Press*

Main category: cs.SE

TL;DR: 本文提出了AlgoTune基准测试，评估语言模型设计和实现算法的能力，发现当前模型虽能实现1.72倍加速但缺乏算法创新能力


<details>
  <summary>Details</summary>
Motivation: 现有语言模型评估主要集中在人类已解决的任务上，缺乏对模型在开放性算法设计和实现方面能力的测试，需要评估模型是否能够超越现有人类表现展现创造性问题解决能力

Method: 构建包含155个编程任务的AlgoTune基准测试，任务来自计算机科学、物理学和数学领域的专家；建立验证和计时框架来评估语言模型生成的解决方案代码；开发基线语言模型智能体AlgoTuner；与流行开源包（如SciPy、sk-learn、CVXPY）的参考实现进行性能对比

Result: AlgoTuner在参考求解器上平均实现了1.72倍的加速效果；但研究发现当前模型无法发现算法创新，更倾向于进行表面层次的优化

Conclusion: 虽然语言模型在算法实现上表现出一定的优化能力，但在算法创新方面仍有不足；希望AlgoTune基准能够推动语言模型智能体在创造性问题解决方面的发展，使其超越当前人类最先进表现

Abstract: Despite progress in language model (LM) capabilities, evaluations have thus
far focused on models' performance on tasks that humans have previously solved,
including in programming (Jimenez et al., 2024) and mathematics (Glazer et al.,
2024). We therefore propose testing models' ability to design and implement
algorithms in an open-ended benchmark: We task LMs with writing code that
efficiently solves computationally challenging problems in computer science,
physics, and mathematics. Our AlgoTune benchmark consists of 155 coding tasks
collected from domain experts and a framework for validating and timing
LM-synthesized solution code, which is compared to reference implementations
from popular open-source packages. In addition, we develop a baseline LM agent,
AlgoTuner, and evaluate its performance across a suite of frontier models.
AlgoTuner achieves an average 1.72x speedup against our reference solvers,
which use libraries such as SciPy, sk-learn and CVXPY. However, we find that
current models fail to discover algorithmic innovations, instead preferring
surface-level optimizations. We hope that AlgoTune catalyzes the development of
LM agents exhibiting creative problem solving beyond state-of-the-art human
performance.

</details>


### [2] [Dr. Boot: Bootstrapping Program Synthesis Language Models to Perform Repairing](https://arxiv.org/abs/2507.15889)
*Noah van der Vleuten*

Main category: cs.SE

TL;DR: 该论文提出了一种用于程序合成的自举算法，通过教模型如何修复代码来解决现有数据集规模有限和模型合成过程与人类不匹配的问题，实验表明该方法能够显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有程序合成语言模型面临两个主要问题：1）训练和评估数据集（MBPP、APPS）规模有限且质量不高，而语言模型需要大量数据；2）模型的程序合成过程与人类不匹配，人类会借助编译器迭代开发代码，而大多数模型是一次性生成代码。

Method: 引入了一种支持教模型如何修复代码的自举算法（bootstrapping algorithm）。该算法能够让模型学习修复过程，使其更接近人类的迭代开发方式。

Result: 自举方法持续优于常规微调；与其他工作相比，自举模型的性能与大68%的微调模型相当；带修复的自举方法在推理时也能改善非修复性能；但在该模型上，推理时修复可能不如简单采样相同数量的解决方案；发现APPS数据集训练部分的示例测试用例存在问题。

Conclusion: 自举算法能够有效提升程序合成模型的性能，特别是在教模型学习修复方面表现出色。该方法为解决数据稀缺和模型与人类合成过程不匹配问题提供了有效途径，同时也揭示了现有数据集的质量问题。

Abstract: Language models for program synthesis are usually trained and evaluated on
programming competition datasets (MBPP, APPS). However, these datasets are
limited in size and quality, while these language models are extremely data
hungry. Additionally, the language models have a misaligned program synthesis
process compared to humans. While humans iteratively develop code with the help
of a compiler, most program synthesis models currently produce code in one go.
To solve these issues, we introduce a bootstrapping algorithm for program
synthesis, that supports teaching models how to repair. We show that
bootstrapping consistently outperforms regular fine-tuning. Compared to other
work, our bootstrapped model performs on par with fine-tuned models that are
68\% larger. Notably, bootstrapping with repairing also improves non-repairing
performance compared to regular bootstrapping during inference. However, on our
models, repairing during inference is likely inferior to simply sampling the
same number of solutions. Furthermore, we find that there are issues with the
example test cases in the training portion of the APPS dataset that are
valuable to the community, as many repairing and reinforcement learning methods
rely on them.

</details>


### [3] [StaAgent: An Agentic Framework for Testing Static Analyzers](https://arxiv.org/abs/2507.15892)
*Elijah Nnorom,Md Basim Uddin Ahmed,Jiho Shin,Hung Viet Pham,Song Wang*

Main category: cs.SE

TL;DR: 提出了StaAgent框架，利用大语言模型的多智能体系统来系统评估静态分析器规则的可靠性，通过生成种子程序、验证代码、产生变异体和执行变形测试来发现规则实现中的缺陷


<details>
  <summary>Details</summary>
Motivation: 静态分析器在软件开发生命周期中发挥关键作用，但其规则实现往往测试不足且容易出现不一致性问题，需要一个系统性的方法来评估和改进静态分析器规则的可靠性

Method: 设计了StaAgent多智能体框架，包含四个专门的智能体：种子生成智能体（将错误检测规则转换为具体的错误诱导种子程序）、代码验证智能体（确保种子程序的正确性）、变异生成智能体（产生语义等价的变异体）和分析器评估智能体（通过比较静态分析器在种子和对应变异体上的行为进行变形测试）

Result: 在五个主流静态分析器（SpotBugs、SonarQube、ErrorProne、Infer、PMD）上使用五个先进大语言模型进行评估，发现了64个问题规则（SpotBugs 28个、SonarQube 18个、ErrorProne 6个、Infer 4个、PMD 8个），其中53个无法被现有基准方法检测到。已向开发者报告所有错误，2个已修复，3个已确认

Conclusion: StaAgent框架有效地揭示了静态分析器规则实现中的缺陷，证明了基于大语言模型的智能体驱动数据合成方法在推进软件工程领域的潜力，为提高静态分析器可靠性提供了可扩展和适应性强的解决方案

Abstract: Static analyzers play a critical role in identifying bugs early in the
software development lifecycle, but their rule implementations are often
under-tested and prone to inconsistencies. To address this, we propose
StaAgent, an agentic framework that harnesses the generative capabilities of
Large Language Models (LLMs) to systematically evaluate static analyzer rules.
StaAgent comprises four specialized agents: a Seed Generation Agent that
translates bug detection rules into concrete, bug-inducing seed programs; a
Code Validation Agent that ensures the correctness of these seeds; a Mutation
Generation Agent that produces semantically equivalent mutants; and an Analyzer
Evaluation Agent that performs metamorphic testing by comparing the static
analyzer's behavior on seeds and their corresponding mutants. By revealing
inconsistent behaviors, StaAgent helps uncover flaws in rule implementations.
This LLM-driven, multi-agent framework offers a scalable and adaptable solution
to improve the reliability of static analyzers. We evaluated StaAgent with five
state-of-the-art LLMs (CodeL-lama, DeepSeek, Codestral, Qwen, and GPT-4o)
across five widely used static analyzers (SpotBugs, SonarQube, ErrorProne,
Infer, and PMD). The experimental results show that our approach can help
reveal 64 problematic rules in the latest versions of these five static
analyzers (i.e., 28 in SpotBugs, 18 in SonarQube, 6 in ErrorProne, 4 in Infer,
and 8 in PMD). In addition, 53 out of the 64 bugs cannot be detected by the
SOTA baseline. We have reported all the bugs to developers, with two of them
already fixed. Three more have been confirmed by developers, while the rest are
awaiting response. These results demonstrate the effectiveness of our approach
and underscore the promise of agentic, LLM-driven data synthesis to advance
software engineering.

</details>


### [4] [A Pilot Study on LLM-Based Agentic Translation from Android to iOS: Pitfalls and Insights](https://arxiv.org/abs/2507.16037)
*Zhili Zeng,Kimya Khakzad Shahandashti,Alvine Boaye Belle,Song Wang,Zhen Ming,Jiang*

Main category: cs.SE

TL;DR: 本研究评估了基于大语言模型的代理方法在移动应用跨平台翻译(Android到iOS)中的性能，开发了考虑依赖关系、规范、程序结构和控制流的代理链，并通过手工检查和根因分析识别了关键失败点，为提升翻译性能提出了指导原则。


<details>
  <summary>Details</summary>
Motivation: 传统的移动应用翻译方法依赖人工干预或基于规则的系统，劳动密集且耗时；虽然机器学习引入了自动化方法，但缺乏上下文理解和适应性，导致翻译效果不佳；而基于LLM的跨平台应用翻译(如Android和iOS之间的迁移)仍未充分探索，需要理解LLM在此类任务中的性能、优势和局限性。

Method: 开发了一个代理链(chain of agents)，在将Android应用翻译为iOS应用时考虑依赖关系、规范、程序结构和程序控制流；通过手工检查翻译代码的语法正确性、语义准确性和功能完整性来评估性能；对翻译失败案例进行详细的根因分析。

Result: 通过手工检查评估了翻译代码的语法正确性、语义准确性和功能完整性；识别了代理翻译过程中的关键失败点；通过根因分析理解了底层局限性并发现了改进机会。

Conclusion: 填补了LLM在跨平台应用翻译领域的研究空白，为软件工程自动化的发展提供了重要洞察；通过识别关键失败点和提出改进指导原则，为提升基于LLM的移动应用翻译性能奠定了基础。

Abstract: The rapid advancement of mobile applications has led to a significant demand
for cross-platform compatibility, particularly between the Android and iOS
platforms. Traditional approaches to mobile application translation often rely
on manual intervention or rule-based systems, which are labor-intensive and
time-consuming. While recent advancements in machine learning have introduced
automated methods, they often lack contextual understanding and adaptability,
resulting in suboptimal translations. Large Language Models (LLMs) were
recently leveraged to enhance code translation at different granularities,
including the method, class, and repository levels. Researchers have
investigated common errors, limitations, and potential strategies to improve
these tasks. However, LLM-based application translation across different
platforms, such as migrating mobile applications between Android and iOS or
adapting software across diverse frameworks, remains underexplored.
Understanding the performance, strengths, and limitations of LLMs in
cross-platform application translation is critical for advancing software
engineering automation. This study aims to fill this gap by evaluating
LLM-based agentic approaches for mobile application translation, identifying
key failure points, and proposing guidelines to improve translation
performance. We developed a chain of agents that account for dependencies,
specifications, program structure, and program control flow when translating
applications from Android to iOS. To evaluate the performance, we manually
examined the translated code for syntactic correctness, semantic accuracy, and
functional completeness. For translation failures, we further conducted a
detailed root cause analysis to understand the underlying limitations of the
agentic translation process and identify opportunities for improvement.

</details>


### [5] [Making REST APIs Agent-Ready: From OpenAPI to Model Context Protocol Servers for Tool-Augmented LLMs](https://arxiv.org/abs/2507.16044)
*Meriem Mastouri,Emna Ksontini,Wael Kessentini*

Main category: cs.SE

TL;DR: 本文提出了AutoMCP，一个能够从OpenAPI规范自动生成MCP服务器的编译器，解决了手动构建MCP服务器的重复性工作问题，在50个真实API上实现了99.9%的成功率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型正从被动文本生成器演变为主动调用外部工具的智能体，但构建MCP服务器仍然需要大量手动工作，包括编写胶水代码、处理身份验证和手动配置模式，这与MCP旨在消除集成工作的目标相矛盾。分析显示在22,000+个MCP标签的GitHub仓库中，只有不到5%包含服务器，且多为小型单维护者项目。

Method: 开发了AutoMCP编译器，能够从OpenAPI 2.0/3.0规范自动生成完整的MCP服务器实现。该编译器解析REST API定义并生成包括模式注册和身份验证处理在内的完整服务器实现。在50个真实世界API上进行评估，涵盖5,066个端点和超过10个领域。

Result: 在1,023个工具调用的分层样本中，76.5%开箱即用成功。通过手动故障分析发现了五个重复出现的问题，都归因于OpenAPI合约中的不一致或遗漏。经过平均每个API 19行规范更改的轻微修复后，AutoMCP实现了99.9%的成功率。

Conclusion: 研究表明：(1)分析了MCP的采用情况并量化了手动服务器开发的成本；(2)证明了尽管OpenAPI规范存在质量问题，但仍能实现近乎完全的MCP服务器自动化；(3)贡献了包含5,066个可调用工具的语料库以及修复常见规范缺陷的见解。

Abstract: Large Language Models (LLMs) are evolving from passive text generators into
active agents that invoke external tools. To support this shift, scalable
protocols for tool integration are essential. The Model Context Protocol (MCP),
introduced by Anthropic in 2024, offers a schema-driven standard for dynamic
tool discovery and invocation. Yet, building MCP servers remains manual and
repetitive, requiring developers to write glue code, handle authentication, and
configure schemas by hand-replicating much of the integration effort MCP aims
to eliminate.
  This paper investigates whether MCP server construction can be meaningfully
automated. We begin by analyzing adoption trends: among 22,000+ MCP-tagged
GitHub repositories created within six months of release, fewer than 5% include
servers, typically small, single-maintainer projects dominated by repetitive
scaffolding. To address this gap, we present AutoMCP, a compiler that generates
MCP servers from OpenAPI 2.0/3.0 specifications. AutoMCP parses REST API
definitions and produces complete server implementations, including schema
registration and authentication handling.
  We evaluate AutoMCP on 50 real-world APIs spanning 5,066 endpoints across
over 10 domains. From a stratified sample of 1,023 tool calls, 76.5% succeeded
out of the box. Manual failure analysis revealed five recurring issues, all
attributable to inconsistencies or omissions in the OpenAPI contracts. After
minor fixes, averaging 19 lines of spec changes per API, AutoMCP achieved 99.9%
success.
  Our findings (i) analyze MCP adoption and quantify the cost of manual server
development, (ii) demonstrate that OpenAPI specifications, despite quality
issues, enable near-complete MCP server automation, and (iii) contribute a
corpus of 5,066 callable tools along with insights on repairing common
specification flaws.

</details>


### [6] [AI-Powered Commit Explorer (APCE)](https://arxiv.org/abs/2507.16063)
*Yousab Grees,Polina Iaremchuk,Ramtin Ehsani,Esteban Parra,Preetha Chatterjee,Sonia Haiduc*

Main category: cs.SE

TL;DR: 本文介绍了AI-Powered Commit Explorer (APCE)工具，用于支持开发者和研究人员使用和研究大语言模型生成的提交消息，提供了提示存储、消息评估和自动化评估机制。


<details>
  <summary>Details</summary>
Motivation: 在版本控制系统中，提交消息为开发者提供了关于代码变更的宝贵信息，但高质量提交消息的编写在实践中经常被忽视。大语言模型生成的提交消息成为缓解这一问题的方法，但需要工具来支持其使用和研究。

Method: 开发了AI-Powered Commit Explorer (APCE)工具，该工具允许研究人员存储不同的LLM提示，提供额外的评估提示来增强LLM生成的提交消息，并为LLM生成消息的自动化和人工评估提供直接的机制。

Result: 成功构建了APCE工具，该工具能够存储多种LLM提示、提供评估提示功能、支持自动化和人工评估LLM生成的提交消息，并提供了演示链接展示工具功能。

Conclusion: APCE工具为开发者和研究人员提供了一个comprehensive的平台来使用和研究LLM生成的提交消息，通过提供提示管理、消息增强和评估机制，有效支持了高质量提交消息的生成和评估工作。

Abstract: Commit messages in a version control system provide valuable information for
developers regarding code changes in software systems. Commit messages can be
the only source of information left for future developers describing what was
changed and why. However, writing high-quality commit messages is often
neglected in practice. Large Language Model (LLM) generated commit messages
have emerged as a way to mitigate this issue. We introduce the AI-Powered
Commit Explorer (APCE), a tool to support developers and researchers in the use
and study of LLM-generated commit messages. APCE gives researchers the option
to store different prompts for LLMs and provides an additional evaluation
prompt that can further enhance the commit message provided by LLMs. APCE also
provides researchers with a straightforward mechanism for automated and human
evaluation of LLM-generated messages. Demo link https://youtu.be/zYrJ9s6sZvo

</details>


### [7] [Ten Essential Guidelines for Building High-Quality Research Software](https://arxiv.org/abs/2507.16166)
*Nasir U. Eisty,David E. Bernholdt,Alex Koufos,David J. Luet,Miranda Mundt*

Main category: cs.SE

TL;DR: 本文提出了十个开发高质量科研软件的指导原则，涵盖从规划到维护的完整开发生命周期，旨在帮助研究人员创建更可靠、可用和可持续的科研工具。


<details>
  <summary>Details</summary>
Motivation: 现代科学研究严重依赖高质量的研究软件来分析复杂数据、模拟现象和分享可重现的结果，但创建此类软件需要遵循确保鲁棒性、可用性和可持续性的最佳实践，因此需要系统性的指导原则。

Method: 提出涵盖软件开发生命周期各个阶段的十个指导原则，包括：规划、编写清洁可读的代码、使用版本控制、实施全面的测试策略、模块化设计、可重现性、性能优化、长期维护、文档编写和社区参与等关键要素。

Result: 形成了一套完整的科研软件开发最佳实践框架，为研究人员和开发者提供了实用的资源指南，能够帮助他们创建既推进科学目标又对更广泛的可靠可重用研究工具生态系统有贡献的软件。

Conclusion: 通过遵循这些指导原则，研究人员能够创建高质量的科研软件，不仅实现其科学目标，还能为构建可靠和可重用的研究工具生态系统做出贡献，从而提升科研软件的质量和影响力。

Abstract: High-quality research software is a cornerstone of modern scientific
progress, enabling researchers to analyze complex data, simulate phenomena, and
share reproducible results. However, creating such software requires adherence
to best practices that ensure robustness, usability, and sustainability. This
paper presents ten guidelines for producing high-quality research software,
covering every stage of the development lifecycle. These guidelines emphasize
the importance of planning, writing clean and readable code, using version
control, and implementing thorough testing strategies. Additionally, they
address key principles such as modular design, reproducibility, performance
optimization, and long-term maintenance. The paper also highlights the role of
documentation and community engagement in enhancing software usability and
impact. By following these guidelines, researchers can create software that
advances their scientific objectives and contributes to a broader ecosystem of
reliable and reusable research tools. This work serves as a practical resource
for researchers and developers aiming to elevate the quality and impact of
their research software.

</details>


### [8] [LOCOFY Large Design Models -- Design to code conversion solution](https://arxiv.org/abs/2507.16208)
*Sohaib Muhammad,Ashwati Vipin,Karan Shetti,Honey Mittal*

Main category: cs.SE

TL;DR: 本文提出了大型设计模型(LDMs)范式，专门针对设计到代码转换进行训练，通过设计优化器、标签检测和自动组件提取等模块，在设计理解和代码生成方面表现优于传统大语言模型。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型和多模态大语言模型发展迅速，但在设计到代码转换应用中仍面临可解释性、可扩展性、资源需求和可重复性等挑战，需要专门的解决方案来实现无缝的设计到代码转换。

Method: 提出大型设计模型(LDMs)范式，包含三个核心组件：1)设计优化器：使用专有真实数据集处理次优设计；2)标签和特征检测：使用预训练和微调模型准确检测和分类UI元素；3)自动组件：提取重复的UI结构为可重用组件，减少冗余并提高代码可重用性。同时开发了推理管道处理真实设计并生成精确的代码生成指令。

Result: LDMs在端到端设计到代码转换准确性方面表现出色，使用新颖的预览匹配分数指标进行评估。与大语言模型相比，LDMs在节点定位准确性、响应性和可重复性方面表现更优。定制训练的标签和特征检测模型在识别UI元素方面展现了高精度和一致性。

Conclusion: 所提出的LDMs是理解设计并生成高效可靠的生产就绪代码的可靠且优越的解决方案，在设计到代码转换任务中显著优于传统的大语言模型方法。

Abstract: Despite rapid advances in Large Language Models and Multimodal Large Language
Models (LLMs), numerous challenges related to interpretability, scalability,
resource requirements and repeatability remain, related to their application in
the design-to-code space. To address this, we introduce the Large Design Models
(LDMs) paradigm specifically trained on designs and webpages to enable seamless
conversion from design-to-code. We have developed a training and inference
pipeline by incorporating data engineering and appropriate model architecture
modification. The training pipeline consists of the following: 1)Design
Optimiser: developed using a proprietary ground truth dataset and addresses
sub-optimal designs; 2)Tagging and feature detection: using pre-trained and
fine-tuned models, this enables the accurate detection and classification of UI
elements; and 3)Auto Components: extracts repeated UI structures into reusable
components to enable creation of modular code, thus reducing redundancy while
enhancing code reusability. In this manner, each model addresses distinct but
key issues for design-to-code conversion. Separately, our inference pipeline
processes real-world designs to produce precise and interpretable instructions
for code generation and ensures reliability. Additionally, our models
illustrated exceptional end-to-end design-to-code conversion accuracy using a
novel preview match score metric. Comparative experiments indicated superior
performance of LDMs against LLMs on accuracy of node positioning,
responsiveness and reproducibility. Moreover, our custom-trained tagging and
feature detection model demonstrated high precision and consistency in
identifying UI elements across a wide sample of test designs. Thus, our
proposed LDMs are a reliable and superior solution to understanding designs
that subsequently enable the generation of efficient and reliable
production-ready code.

</details>


### [9] [Search-based Generation of Waypoints for Triggering Self-Adaptations in Maritime Autonomous Vessels](https://arxiv.org/abs/2507.16327)
*Karoline Nylænder,Aitor Arrieta,Shaukat Ali,Paolo Arcaini*

Main category: cs.SE

TL;DR: 本文提出了WPgen方法，用于生成海上自主船舶导航测试用例，通过对预定义航点进行微小修改来触发不当导航行为，以验证自适应系统的实现


<details>
  <summary>Details</summary>
Motivation: 海上自主船舶需要自适应能力来应对意外情况并保持可靠性要求。在设计此类船舶时，理解和识别应该触发自适应的场景设置至关重要，这需要对自适应实现进行验证

Method: 提出基于多目标搜索的WPgen方法，使用NSGA-II算法对预定义航点集合进行微小修改。该方法采用三种不同的种子策略来初始化种群，形成WPgen的三个变体，目标是生成尽可能接近原始航点但会导致不当导航的航点

Result: 在三艘自主船舶（一艘水面油轮和两艘水下船舶）上评估了WPgen的三个变体。与随机搜索基线方法以及各变体之间的比较表明，不同变体的有效性因船舶类型而异

Conclusion: WPgen方法能够有效生成用于测试海上自主船舶导航系统的测试用例，不同的种子策略适用于不同类型的船舶。研究为海上自主船舶自适应系统的验证提供了实用的工具和方法指导

Abstract: Self-adaptation in maritime autonomous vessels (AVs) enables them to adapt
their behaviors to address unexpected situations while maintaining
dependability requirements. During the design of such AVs, it is crucial to
understand and identify the settings that should trigger adaptations, enabling
validation of their implementation. To this end, we focus on the navigation
software of AVs, which must adapt their behavior during operation through
adaptations. AVs often rely on predefined waypoints to guide them along
designated routes, ensuring safe navigation. We propose a multiobjective
search-based approach, called WPgen, to generate minor modifications to the
predefined set of waypoints, keeping them as close as possible to the original
waypoints, while causing the AV to navigate inappropriately when navigating
with the generated waypoints. WPgen uses NSGA-II as the multi-objective search
algorithm with three seeding strategies for its initial population, resulting
in three variations of WPgen. We evaluated these variations on three AVs (one
overwater tanker and two underwater). We compared the three variations of WPgen
with Random Search as the baseline and with each other. Experimental results
showed that the effectiveness of these variations varied depending on the AV.
Based on the results, we present the research and practical implications of
WPgen.

</details>


### [10] [Improving Code LLM Robustness to Prompt Perturbations via Layer-Aware Model Editing](https://arxiv.org/abs/2507.16407)
*Shuhan Liu,Xing Hu,Kerui Huang,Xiaohu Yang,David Lo,Xin Xia*

Main category: cs.SE

TL;DR: 本文提出CREME方法，通过识别大语言模型中对提示扰动敏感的网络层并进行针对性参数编辑，显著提升了代码生成任务中模型对提示变化的鲁棒性，在扰动提示上Pass@1准确率提升63%。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在代码生成中对提示扰动高度敏感，微小的措辞、语法或格式变化都会显著降低生成代码的功能正确性。由于扰动在实际场景中频繁发生，提升LLM对提示扰动的鲁棒性对确保实际代码生成的可靠性能至关重要。

Method: CREME（通过模型编辑增强代码鲁棒性）方法分两步：1）通过比较原始提示和扰动提示之间的隐藏状态来识别鲁棒性敏感层；2）在识别出的层上执行轻量级参数编辑以减少性能退化。

Result: 在HumanEval和MBPP两个代码生成基准及其扰动版本上的实验表明，CREME在扰动提示上将Pass@1准确率提升了63%，同时在干净输入上保持稳定性能，准确率偏差在1%以内。

Conclusion: 鲁棒性敏感层主要集中在网络的中层和深层，且其位置因不同模型架构而异。这些发现为开发未来面向鲁棒性的编辑策略提供了宝贵的基础。CREME有效提升了LLM在代码生成任务中的提示鲁棒性。

Abstract: Large language models (LLMs) have demonstrated impressive capabilities in
code generation, where the natural language prompt plays a crucial role in
conveying user intent to the model. However, prior studies have shown that LLMs
are highly sensitive to prompt perturbations. Minor modifications in wording,
syntax, or formatting can significantly reduce the functional correctness of
generated code. As perturbations frequently occur in real-world scenarios,
improving the robustness of LLMs to prompt perturbations is essential for
ensuring reliable performance in practical code generation. In this paper, we
introduce CREME (Code Robustness Enhancement via Model Editing), a novel
approach that enhances LLM robustness through targeted parameter updates. CREME
first identifies robustness-sensitive layers by comparing hidden states between
an original prompt and its perturbed variant. Then, it performs lightweight
parameter editing at the identified layer to reduce performance degradation. We
evaluate CREME on two widely used code generation benchmarks (HumanEval and
MBPP) along with their perturbed counterparts. Experimental results show that
CREME improves Pass@1 accuracy by 63% on perturbed prompts while maintaining
stable performance on clean inputs, with accuracy deviations within 1%. Further
analysis reveals that robustness-sensitive layers are primarily concentrated in
the middle and deeper layers of the network, and their locations vary across
different model architectures. These insights provide a valuable foundation for
developing future robustness-oriented editing strategies.

</details>


### [11] [Exploring Large Language Models for Analyzing and Improving Method Names in Scientific Code](https://arxiv.org/abs/2507.16439)
*Gunnar Larsen,Carol Wong,Anthony Peruma*

Main category: cs.SE

TL;DR: 研究评估了四个大型语言模型(LLMs)在分析和改进科学软件中方法名质量方面的能力，发现LLMs在分析方法名方面有一定效果但仍需人工评估


<details>
  <summary>Details</summary>
Motivation: 科学研究人员越来越依赖软件支持研究工作，但关于科学软件中标识符命名质量（特别是方法名质量）的研究有限。大型语言模型的发展为自动化代码分析任务提供了新机会

Method: 评估四个流行的大型语言模型分析语法模式和为496个从基于Python的Jupyter Notebooks中提取的方法名提供改进建议的能力

Result: LLMs在分析方法名方面表现出一定效果，通常遵循良好的命名实践（如方法名以动词开头），但在处理领域特定术语方面不一致，与人工标注的一致性仅为中等水平

Conclusion: 自动化建议需要人工评估，该工作为通过AI自动化改进科学代码质量提供了基础见解

Abstract: Research scientists increasingly rely on implementing software to support
their research. While previous research has examined the impact of identifier
names on program comprehension in traditional programming environments, limited
work has explored this area in scientific software, especially regarding the
quality of method names in the code. The recent advances in Large Language
Models (LLMs) present new opportunities for automating code analysis tasks,
such as identifier name appraisals and recommendations. Our study evaluates
four popular LLMs on their ability to analyze grammatical patterns and suggest
improvements for 496 method names extracted from Python-based Jupyter
Notebooks. Our findings show that the LLMs are somewhat effective in analyzing
these method names and generally follow good naming practices, like starting
method names with verbs. However, their inconsistent handling of
domain-specific terminology and only moderate agreement with human annotations
indicate that automated suggestions require human evaluation. This work
provides foundational insights for improving the quality of scientific code
through AI automation.

</details>


### [12] [On the Effectiveness of LLM-as-a-judge for Code Generation and Summarization](https://arxiv.org/abs/2507.16587)
*Giuseppe Crupi,Rosalia Tufano,Alejandro Velasco,Antonio Mastropaolo,Denys Poshyvanyk,Gabriele Bavota*

Main category: cs.SE

TL;DR: 研究了大语言模型作为评判者在代码生成和代码摘要任务中的有效性，发现GPT-4-turbo是最佳评判模型，但即使是最好的模型也经常误判代码正确性和摘要质量。


<details>
  <summary>Details</summary>
Motivation: 传统定量指标（如BLEU）无法全面评估代码生成和摘要质量，而大规模人工评估成本过高，因此需要探索使用大语言模型作为评判者的可行性，以实现自动化评估并支持多模型协作的解决方案。

Method: 对8个大语言模型进行测试，评判1,405个Java方法和1,281个Python函数的正确性；对5个大语言模型与9个人类评判者进行比较，评估约1.2k个Java和Python函数摘要的质量；通过对比分析来评估不同模型的评判能力。

Result: GPT-4-turbo在两个任务中都表现出最佳的评判能力；参数规模较小（数百亿参数）的大语言模型无法胜任评判任务；即使是表现最好的模型也经常在代码正确性和摘要质量判断上出现错误。

Conclusion: 虽然GPT-4-turbo在代码相关任务的评判方面表现最佳，但目前的大语言模型作为评判者仍存在显著局限性，经常出现误判，表明这一方法尚需进一步改进才能在实际应用中可靠使用。

Abstract: Large Language Models have been recently exploited as judges for complex
natural language processing tasks, such as Q&A. The basic idea is to delegate
to an LLM the assessment of the "quality" of the output provided by an
automated technique for tasks for which: (i) quantitative metrics would only
tell part of the story, and; (ii) a large-scale human-based evaluation would be
too expensive. LLMs-as-a-judge, if proven effective for a specific task, can
also unlock new possibilities for automation, with several LLMs proposing a
solution for a given instance of the task and others judging and deciding what
is the best output to show the user. We study the effectiveness of
LLMs-as-a-judge for two code-related tasks, namely code generation and code
summarization. The rationale for choosing these tasks is two-fold. First,
quantitative metrics are usually not enough for the assessment of code
summarizers/generators. For example, it is well documented that metrics such as
BLEU are quite weak proxies for the quality of the generated summaries. Second,
even state-of-the-art techniques still struggle with handling complex instances
of these tasks, making them good candidates for benefiting from more advanced
solutions envisioning collaboration among LLMs. For code generation, we check
whether eight LLMs are able to judge the correctness of 1,405 Java methods and
1,281 Python functions generated by the same LLMs or implemented by humans. For
code summarization, we compare the judgment of five LLMs to those provided by
nine humans for ~1.2k summaries, related to both Java and Python functions. Our
findings show that GPT-4-turbo is the best LLM in terms of judging capabilities
for both tasks, with "smaller" LLMs featuring tens of billions parameters not
being able to cope with judging tasks. However, even the best-performing LLM
frequently misjudges the correctness of the code and summary quality.

</details>


### [13] [VulCoCo: A Simple Yet Effective Method for Detecting Vulnerable Code Clones](https://arxiv.org/abs/2507.16661)
*Tan Bui,Yan Naing Tun,Thanh Phuc Nguyen,Yindu Su,Ferdian Thung,Yikun Li,Han Wei Ang,Yide Yin,Frank Liauw,Lwin Khin Shar,Eng Lieh Ouh,Ting Zhang,David Lo*

Main category: cs.SE

TL;DR: 本文提出VulCoCo，一种轻量级且可扩展的漏洞代码克隆检测方法，结合嵌入式检索和大语言模型验证，在合成基准测试中超越现有方法，并在实际项目中成功发现漏洞，提交的400个拉取请求中有75个被合并，15个导致新的CVE发布。


<details>
  <summary>Details</summary>
Motivation: 现有的漏洞代码克隆(VCC)检测工具往往依赖语法相似性或产生粗糙的漏洞预测且缺乏清晰解释，限制了实用性。同时缺乏可重现的漏洞代码克隆基准测试。需要一种更有效的方法来检测保留已知漏洞逻辑的代码片段。

Method: 提出VulCoCo方法，结合嵌入式检索与大语言模型验证。从已知漏洞函数集合开始，从大型语料库中检索语法或语义相似的候选函数，然后使用LLM评估候选函数是否保留漏洞。构建了涵盖各种克隆类型的合成基准测试。

Result: 在基准测试中，VulCoCo在Precision@k和平均精度(MAP)方面超越了现有最先进方法。在实际项目中向284个开源项目提交了400个拉取请求，其中75个被合并，15个导致新发布的CVE。

Conclusion: VulCoCo是一种有效的漏洞代码克隆检测方法，在合成基准和实际应用中都表现出色。研究还为未来进一步提高漏洞代码克隆检测精度的工作提供了见解。

Abstract: Code reuse is common in modern software development, but it can also spread
vulnerabilities when developers unknowingly copy risky code. The code fragments
that preserve the logic of known vulnerabilities are known as vulnerable code
clones (VCCs). Detecting those VCCs is a critical but challenging task.
Existing VCC detection tools often rely on syntactic similarity or produce
coarse vulnerability predictions without clear explanations, limiting their
practical utility. In this paper, we propose VulCoCo, a lightweight and
scalable approach that combines embedding-based retrieval with large language
model (LLM) validation. Starting from a set of known vulnerable functions, we
retrieve syntactically or semantically similar candidate functions from a large
corpus and use an LLM to assess whether the candidates retain the
vulnerability. Given that there is a lack of reproducible vulnerable code clone
benchmarks, we first construct a synthetic benchmark that spans various clone
types.
  Our experiments on the benchmark show that VulCoCo outperforms prior
state-of-the-art methods in terms of Precision@k and mean average precision
(MAP). In addition, we also demonstrate VulCoCo's effectiveness in real-world
projects by submitting 400 pull requests (PRs) to 284 open-source projects.
Among them, 75 PRs were merged, and 15 resulted in newly published CVEs. We
also provide insights to inspire future work to further improve the precision
of vulnerable code clone detection.

</details>


### [14] [VulGuard: An Unified Tool for Evaluating Just-In-Time Vulnerability Prediction Models](https://arxiv.org/abs/2507.16685)
*Duong Nguyen,Manh Tran-Duc,Thanh Le-Cong,Triet Huynh Minh Le,M. Ali Babar,Quyet-Thang Huynh*

Main category: cs.SE

TL;DR: VulGuard是一个自动化工具，用于从GitHub仓库中提取、处理和分析提交记录，以支持即时漏洞预测(JIT-VP)研究，集成了多个先进的漏洞预测模型，并可轻松集成到CI/CD流水线中。


<details>
  <summary>Details</summary>
Motivation: 解决软件安全研究中即时漏洞预测(JIT-VP)面临的可重现性和可扩展性挑战，简化从GitHub仓库提取和分析提交记录的复杂流程，为研究人员提供统一的框架来训练、评估和比较漏洞预测模型。

Method: 开发了VulGuard自动化工具，该工具能够：1)自动挖掘提交历史记录；2)提取细粒度代码变更、提交消息和软件工程指标；3)将数据格式化用于下游分析；4)集成多个最先进的漏洞预测模型；5)支持仓库级别的挖掘和模型级别的实验；6)可集成到CI/CD流水线中。

Result: 在两个有影响力的开源项目FFmpeg和Linux内核上演示了工具的有效性，证明了VulGuard在实际JIT-VP研究中的应用潜力，并能够促进标准化基准测试。工具支持最小化设置的模型训练、评估和比较。

Conclusion: VulGuard成功解决了软件安全研究中的关键挑战，通过提供统一的自动化框架，显著提高了即时漏洞预测研究的可重现性和可扩展性，有望加速现实世界中的JIT-VP研究发展并推动标准化基准测试的建立。

Abstract: We present VulGuard, an automated tool designed to streamline the extraction,
processing, and analysis of commits from GitHub repositories for Just-In-Time
vulnerability prediction (JIT-VP) research. VulGuard automatically mines commit
histories, extracts fine-grained code changes, commit messages, and software
engineering metrics, and formats them for downstream analysis. In addition, it
integrates several state-of-the-art vulnerability prediction models, allowing
researchers to train, evaluate, and compare models with minimal setup. By
supporting both repository-scale mining and model-level experimentation within
a unified framework, VulGuard addresses key challenges in reproducibility and
scalability in software security research. VulGuard can also be easily
integrated into the CI/CD pipeline. We demonstrate the effectiveness of the
tool in two influential open-source projects, FFmpeg and the Linux kernel,
highlighting its potential to accelerate real-world JIT-VP research and promote
standardized benchmarking. A demo video is available at:
https://youtu.be/j96096-pxbs

</details>


### [15] [Never Come Up Empty: Adaptive HyDE Retrieval for Improving LLM Developer Support](https://arxiv.org/abs/2507.16754)
*Fangjian Lei,Mariam El Mezouar,Shayan Noei,Ying Zou*

Main category: cs.SE

TL;DR: 本文构建了包含300万个Java和Python相关Stack Overflow帖子的检索语料库，设计并评估了7种不同的RAG管道和63个管道变体，以提高大语言模型在回答开发者问题时的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在协助开发者解答代码相关问题方面显示出潜力，但存在生成不可靠答案的风险。虽然检索增强生成(RAG)被提出来减少LLM的幻觉问题，但设计有效的RAG管道仍然具有挑战性，因为涉及众多设计选择。

Method: 构建了包含300万个Java和Python相关Stack Overflow帖子及其被接受答案的检索语料库；设计并评估了7种不同的RAG管道和63个管道变体；针对历史上有相似匹配的问题进行评估；通过自动降低检索时的相似度阈值来处理没有紧密先验匹配的新问题；将最优RAG管道应用于4个开源LLM并与零样本性能进行比较。

Result: 发现结合假设文档嵌入(HyDE)和完整答案上下文的RAG管道在检索和回答Stack Overflow问题的相似内容方面表现最佳；最优RAG管道在所有模型上都持续优于零样本基准，在LLM作为评判者的评估中，在有用性、正确性和详细程度方面获得更高分数。

Conclusion: 研究表明最优RAG管道能够稳健地提升广泛开发者查询的答案质量，包括在不同LLM上处理之前见过的和新颖的问题，证明了RAG在提高代码相关问答任务中的有效性。

Abstract: Large Language Models (LLMs) have shown promise in assisting developers with
code-related questions; however, LLMs carry the risk of generating unreliable
answers. To address this, Retrieval-Augmented Generation (RAG) has been
proposed to reduce the unreliability (i.e., hallucinations) of LLMs. However,
designing effective pipelines remains challenging due to numerous design
choices. In this paper, we construct a retrieval corpus of over 3 million Java
and Python related Stack Overflow posts with accepted answers, and explore
various RAG pipeline designs to answer developer questions, evaluating their
effectiveness in generating accurate and reliable responses. More specifically,
we (1) design and evaluate 7 different RAG pipelines and 63 pipeline variants
to answer questions that have historically similar matches, and (2) address new
questions without any close prior matches by automatically lowering the
similarity threshold during retrieval, thereby increasing the chance of finding
partially relevant context and improving coverage for unseen cases. We find
that implementing a RAG pipeline combining hypothetical-documentation-embedding
(HyDE) with the full-answer context performs best in retrieving and answering
similarcontent for Stack Overflow questions. Finally, we apply our optimal RAG
pipeline to 4 open-source LLMs and compare the results to their zero-shot
performance. Our findings show that RAG with our optimal RAG pipeline
consistently outperforms zero-shot baselines across models, achieving higher
scores for helpfulness, correctness, and detail with LLM-as-a-judge. These
findings demonstrate that our optimal RAG pipelines robustly enhance answer
quality for a wide range of developer queries including both previously seen
and novel questions across different LLMs

</details>


### [16] [Rethinking LLM-Based RTL Code Optimization Via Timing Logic Metamorphosis](https://arxiv.org/abs/2507.16808)
*Zhihao Xu,Bixin Li,Lulu Wang*

Main category: cs.SE

TL;DR: 本研究评估了基于大语言模型(LLM)的RTL代码优化方法在处理复杂时序逻辑方面的有效性，发现LLM在逻辑操作优化方面表现出色，但在复杂时序逻辑优化方面不如传统编译器方法


<details>
  <summary>Details</summary>
Motivation: 传统RTL代码优化方法依赖人工调优和启发式算法，耗时且易出错。虽然有研究提出使用LLM辅助RTL代码优化，但现有方法未充分评估LLM在处理复杂时序逻辑RTL代码方面的有效性，存在评估空白

Method: 提出了一个包含四个子集的新RTL优化评估基准，每个子集对应RTL代码优化的特定领域。引入基于变形测试的方法来系统评估LLM-based RTL代码优化方法的有效性，核心思想是优化效果在语义等价但更复杂的代码上应保持一致

Result: 通过大量实验发现：(1) LLM-based RTL优化方法能有效优化逻辑操作，性能优于现有编译器方法；(2) 在复杂时序逻辑的RTL代码上，特别是时序控制流优化和时钟域优化方面，LLM-based方法表现不如现有编译器方法

Conclusion: LLM在理解RTL代码中的时序逻辑方面面临挑战，这是其在复杂时序逻辑优化方面表现不佳的主要原因。研究为进一步利用LLM进行RTL代码优化提供了见解和指导

Abstract: Register Transfer Level(RTL) code optimization is crucial for achieving high
performance and low power consumption in digital circuit design. However,
traditional optimization methods often rely on manual tuning and heuristics,
which can be time-consuming and error-prone. Recent studies proposed to
leverage Large Language Models(LLMs) to assist in RTL code optimization. LLMs
can generate optimized code snippets based on natural language descriptions,
potentially speeding up the optimization process. However, existing approaches
have not thoroughly evaluated the effectiveness of LLM-Based code optimization
methods for RTL code with complex timing logic. To address this gap, we
conducted a comprehensive empirical investigation to assess the capability of
LLM-Based RTL code optimization methods in handling RTL code with complex
timing logic. In this study, we first propose a new benchmark for RTL
optimization evaluation. It comprises four subsets, each corresponding to a
specific area of RTL code optimization. Then we introduce a method based on
metamorphosis to systematically evaluate the effectiveness of LLM-Based RTL
code optimization methods.Our key insight is that the optimization
effectiveness should remain consistent for semantically equivalent but more
complex code. After intensive experiments, we revealed several key findings.
(1) LLM-Based RTL optimization methods can effectively optimize logic
operations and outperform existing compiler-based methods. (2) LLM-Based RTL
optimization methods do not perform better than existing compiler-based methods
on RTL code with complex timing logic, particularly in timing control flow
optimization and clock domain optimization. This is primarily attributed to the
challenges LLMs face in understanding timing logic in RTL code. Based on these
findings, we provide insights for further research in leveraging LLMs for RTL
code optimization.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [17] [Decentralized AI-driven IoT Architecture for Privacy-Preserving and Latency-Optimized Healthcare in Pandemic and Critical Care Scenarios](https://arxiv.org/abs/2507.15859)
*Harsha Sammangi,Aditya Jagatha,Giridhar Reddy Bojja,Jun Liu*

Main category: cs.CR

TL;DR: 本文提出了一种基于AI的去中心化物联网架构，用于实时患者监测，通过结合联邦学习、区块链和边缘计算技术来解决传统中心化医疗架构在数据隐私、延迟和安全性方面的问题


<details>
  <summary>Details</summary>
Motivation: 传统的中心化医疗架构存在数据隐私泄露、延迟高和安全性差等问题，特别是在疫情和重症监护环境中，需要一种更有效的解决方案来实现实时患者监测

Method: 设计了一种AI驱动的去中心化物联网架构，该架构整合并优化了联邦学习、区块链和边缘计算技术，旨在最大化数据隐私保护、最小化延迟并改善整体系统性能指标

Result: 实验结果显示，与竞争性云解决方案相比，该架构在交易延迟、能耗和数据吞吐量方面都有数个数量级的改善

Conclusion: 提出的AI驱动去中心化物联网架构能够有效解决传统中心化医疗系统的关键问题，在保障数据隐私和安全的同时显著提升系统性能，为疫情和重症监护场景下的实时患者监测提供了可行的技术方案

Abstract: AI Innovations in the IoT for Real-Time Patient Monitoring On one hand, the
current traditional centralized healthcare architecture poses numerous issues,
including data privacy, delay, and security. Here, we present an AI-enabled
decentralized IoT architecture that can address such challenges during a
pandemic and critical care settings. This work presents our architecture to
enhance the effectiveness of the current available federated learning,
blockchain, and edge computing approach, maximizing data privacy, minimizing
latency, and improving other general system metrics. Experimental results
demonstrate transaction latency, energy consumption, and data throughput orders
of magnitude lower than competitive cloud solutions.

</details>


### [18] [BACFuzz: Exposing the Silence on Broken Access Control Vulnerabilities in Web Applications](https://arxiv.org/abs/2507.15984)
*I Putu Arya Dharmaadi,Mohannad Alhanahnah,Van-Thuan Pham,Fadi Mohsen,Fatih Turkmen*

Main category: cs.CR

TL;DR: BACFuzz是首个专门针对破坏访问控制(BAC)漏洞的灰盒模糊测试框架，结合LLM指导的参数选择和SQL查询分析来检测PHP Web应用中的授权缺陷，在20个真实应用中检测出16个已知问题和26个新发现的BAC漏洞。


<details>
  <summary>Details</summary>
Motivation: 破坏访问控制(BAC)是Web应用中最关键和广泛的漏洞之一，允许攻击者访问未授权资源或执行特权操作。尽管其严重性很高，但由于缺乏可靠的预言机和难以生成语义有效的攻击请求等关键挑战，BAC在自动化测试中探索不足。

Method: 提出BACFuzz框架，结合LLM指导的参数选择、运行时反馈和基于SQL的预言机检查来检测静默授权缺陷。使用轻量级插桩捕获运行时信息指导测试生成，并分析后端SQL查询来验证未授权输入是否流入受保护操作。

Result: 在20个真实Web应用(包括15个CVE案例和2个已知基准)上评估，BACFuzz检测出17个已知问题中的16个，并发现了26个此前未知的BAC漏洞，且误报率较低。所有识别的问题都已负责任地披露。

Conclusion: BACFuzz作为首个专门针对BAC漏洞的灰盒模糊测试框架，有效解决了传统方法的局限性，通过结合LLM指导和SQL查询分析实现了高效的BAC漏洞检测，为Web应用安全测试提供了新的解决方案。

Abstract: Broken Access Control (BAC) remains one of the most critical and widespread
vulnerabilities in web applications, allowing attackers to access unauthorized
resources or perform privileged actions. Despite its severity, BAC is
underexplored in automated testing due to key challenges: the lack of reliable
oracles and the difficulty of generating semantically valid attack requests. We
introduce BACFuzz, the first gray-box fuzzing framework specifically designed
to uncover BAC vulnerabilities, including Broken Object-Level Authorization
(BOLA) and Broken Function-Level Authorization (BFLA) in PHP-based web
applications. BACFuzz combines LLM-guided parameter selection with runtime
feedback and SQL-based oracle checking to detect silent authorization flaws. It
employs lightweight instrumentation to capture runtime information that guides
test generation, and analyzes backend SQL queries to verify whether
unauthorized inputs flow into protected operations. Evaluated on 20 real-world
web applications, including 15 CVE cases and 2 known benchmarks, BACFuzz
detects 16 of 17 known issues and uncovers 26 previously unknown BAC
vulnerabilities with low false positive rates. All identified issues have been
responsibly disclosed, and artifacts will be publicly released.

</details>


### [19] ["We Need a Standard": Toward an Expert-Informed Privacy Label for Differential Privacy](https://arxiv.org/abs/2507.15997)
*Onyinye Dibia,Mengyi Lu,Prianka Bhattacharjee,Joseph P. Near,Yuanyuan Feng*

Main category: cs.CR

TL;DR: 本文通过专家访谈识别了差分隐私部署中需要披露的关键参数，并设计了标准化的隐私标签来全面传达隐私保障信息


<details>
  <summary>Details</summary>
Motivation: 现实世界中的差分隐私部署往往不充分披露其隐私保障参数，这种参数披露的不完整性导致对隐私保护强度的误解，从而削弱了对差分隐私的信任

Method: 对12名差分隐私专家进行半结构化访谈，识别全面传达差分隐私保障所需的重要参数，并描述这些参数应该如何以及为什么需要被披露

Result: 识别出了全面传达差分隐私保障所必需的重要差分隐私参数，并基于专家建议设计了初始的差分隐私标签原型

Conclusion: 基于专家建议设计了标准化格式的隐私标签，可以全面传达差分隐私的隐私保障信息，为未来制定差分隐私部署的隐私保障传达标准提供了指导

Abstract: The increasing adoption of differential privacy (DP) leads to public-facing
DP deployments by both government agencies and companies. However, real-world
DP deployments often do not fully disclose their privacy guarantees, which vary
greatly between deployments. Failure to disclose certain DP parameters can lead
to misunderstandings about the strength of the privacy guarantee, undermining
the trust in DP. In this work, we seek to inform future standards for
communicating the privacy guarantees of DP deployments. Based on
semi-structured interviews with 12 DP experts, we identify important DP
parameters necessary to comprehensively communicate DP guarantees, and describe
why and how they should be disclosed. Based on expert recommendations, we
design an initial privacy label for DP to comprehensively communicate privacy
guarantees in a standardized format.

</details>


### [20] [Blocklisted Oblivious Pseudorandom Functions](https://arxiv.org/abs/2507.16040)
*Xinyuan Zhang,Anrin Chakraborti,Michael Reiter*

Main category: cs.CR

TL;DR: 该论文提出了一种支持黑名单的遗忘伪随机函数(OPRF)协议，通过将客户端输入嵌入度量空间并检查是否与黑名单元素聚类来提高性能，可应用于密码黑名单和恶意软件检测等场景。


<details>
  <summary>Details</summary>
Motivation: 传统的遗忘伪随机函数无法支持服务器指定黑名单的功能，而在实际应用中（如密码验证、恶意软件检测），需要在不泄露客户端输入和服务器密钥的前提下，检查客户端输入是否在服务器的黑名单中。

Method: 将客户端输入嵌入到度量空间中，通过检查嵌入向量是否与黑名单元素聚类来判断输入是否在黑名单上。框架将嵌入过程和黑名单检查分离以提高效率，然后通过密码学方法将这两个阶段结合起来。同时支持对相同输入的后续OPRF评估更高效地进行。

Result: 成功设计了支持黑名单的OPRF协议，并在两个实际应用场景中验证了其有效性：1）在增强密码认证密钥交换中实现密码黑名单功能；2）对不在已知恶意软件黑名单中的可执行文件进行MAC验证。

Conclusion: 提出的框架成功扩展了OPRF的功能，使其能够支持黑名单检查，同时保持了隐私保护特性。通过度量空间嵌入和聚类检查的设计，实现了高效的黑名单OPRF协议，为密码安全和恶意软件检测等应用提供了新的解决方案。

Abstract: An oblivious pseudorandom function (OPRF) is a protocol by which a client and
server interact to evaluate a pseudorandom function on a key provided by the
server and an input provided by the client, without divulging the key or input
to the other party. We extend this notion by enabling the server to specify a
blocklist, such that OPRF evaluation succeeds only if the client's input is not
on the blocklist. More specifically, our design gains performance by embedding
the client input into a metric space, where evaluation continues only if this
embedding does not cluster with blocklist elements. Our framework exploits this
structure to separate the embedding and blocklist check to enable efficient
implementations of each, but then must stitch these phases together through
cryptographic means. Our framework also supports subsequent evaluation of the
OPRF on the same input more efficiently. We demonstrate the use of our design
for password blocklisting in augmented password-authenticated key exchange, and
to MAC only executables that are not similar to ones on a blocklist of known
malware.

</details>


### [21] [MFAz: Historical Access Based Multi-Factor Authorization](https://arxiv.org/abs/2507.16060)
*Eyasu Getahun Chekole,Howard Halim,Jianying Zhou*

Main category: cs.CR

TL;DR: 本文提出了一种新的多因素授权(MFAz)方案，通过细粒度访问控制规则和验证点来主动防御传统和高级未授权访问攻击，特别是会话劫持攻击。该方案使用布隆过滤器提高效率，采用区块链确保授权决策的防篡改性和去中心化。


<details>
  <summary>Details</summary>
Motivation: 传统访问控制机制（如静态访问控制策略）无法有效防御会话劫持等高级攻击技术。随着攻击手段日益复杂，需要一种新的授权机制来主动缓解传统和高级未授权访问威胁，保护私有资源免受隐蔽的会话接管攻击。

Method: 提出多因素授权(MFAz)方案，采用两个授权因子：1)从历史授权访问中系统生成的细粒度访问控制规则(ARs)作为第一因子；2)验证点(VPs)作为第二因子。使用布隆过滤器提高运行时和存储效率，利用区块链技术实现防篡改和去中心化的授权决策。

Result: 在智慧城市测试平台上对不同计算能力的设备进行实验验证，结果显示该方案在安全性和性能保证方面都具有很高的有效性。这是首次正式引入与多因素认证(MFA)正交的多因素授权方案。

Conclusion: 多因素授权方案能够有效防御传统和高级未授权访问攻击，特别是会话劫持攻击。通过结合细粒度访问控制规则和验证点，以及利用布隆过滤器和区块链技术，该方案在保证安全性的同时实现了良好的性能表现。

Abstract: Unauthorized access remains one of the critical security challenges in the
realm of cybersecurity. With the increasing sophistication of attack
techniques, the threat of unauthorized access is no longer confined to the
conventional ones, such as exploiting weak access control policies. Instead,
advanced exploitation strategies, such as session hijacking-based attacks, are
becoming increasingly prevalent, posing serious security concerns. Session
hijacking enables attackers to take over an already established session between
legitimate peers in a stealthy manner, thereby gaining unauthorized access to
private resources. Unfortunately, traditional access control mechanisms, such
as static access control policies, are insufficient to prevent session
hijacking or other advanced exploitation techniques. In this work, we propose a
new multi-factor authorization (MFAz) scheme that proactively mitigates
unauthorized access attempts both conventional and advanced unauthorized access
attacks. The proposed scheme employs fine-grained access control rules (ARs)
and verification points (VPs) that are systematically generated from
historically granted accesses as the first and second authorization factors,
respectively. As a proof-of-concept, we implement the scheme using different
techniques. We leverage bloom filter to achieve runtime and storage efficiency,
and blockchain to make authorization decisions in a temper-proof and
decentralized manner. To the best of our knowledge, this is the first formal
introduction of a multi-factor authorization scheme, which is orthogonal to the
multi-factor authentication (MFA) schemes. The effectiveness of our proposed
scheme is experimentally evaluated using a smart-city testbed involving
different devices with varying computational capacities. The experimental
results reveal high effectiveness of the scheme both in security and
performance guarantees.

</details>


### [22] [DP2Guard: A Lightweight and Byzantine-Robust Privacy-Preserving Federated Learning Scheme for Industrial IoT](https://arxiv.org/abs/2507.16134)
*Baofu Han,Bing Li,Yining Qi,Raja Jurdak,Kaibin Huang,Chau Yuen*

Main category: cs.CR

TL;DR: 提出了DP2Guard，一个轻量级的隐私保护联邦学习框架，通过梯度掩码机制替代昂贵的加密操作，采用混合防御策略识别恶意梯度，并使用基于信任分数的自适应聚合方案和区块链记录来增强隐私性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的隐私保护联邦学习方案面临两个主要挑战：(1)依赖重量级加密技术导致大量通信和计算开销；(2)单一策略防御机制往往无法对抗自适应对手，提供足够的鲁棒性。需要一种既能保护隐私又能增强鲁棒性的轻量级解决方案。

Method: 提出DP2Guard框架，包含：(1)轻量级梯度掩码机制替代昂贵的密码学操作；(2)混合防御策略，使用奇异值分解和余弦相似度提取梯度特征，应用聚类算法识别恶意梯度；(3)基于信任分数的自适应聚合方案，根据历史行为调整客户端权重；(4)区块链记录聚合结果和信任分数，确保防篡改和可审计的训练。

Result: 在两个公共数据集上的大量实验表明，DP2Guard能够有效防御四种先进的投毒攻击，同时在降低通信和计算成本的情况下确保隐私保护。

Conclusion: DP2Guard成功解决了现有隐私保护联邦学习方案的主要挑战，通过轻量级设计和混合防御策略，在保证隐私的同时提供了更强的鲁棒性，并显著降低了系统开销。

Abstract: Privacy-Preserving Federated Learning (PPFL) has emerged as a secure
distributed Machine Learning (ML) paradigm that aggregates locally trained
gradients without exposing raw data. To defend against model poisoning threats,
several robustness-enhanced PPFL schemes have been proposed by integrating
anomaly detection. Nevertheless, they still face two major challenges: (1) the
reliance on heavyweight encryption techniques results in substantial
communication and computation overhead; and (2) single-strategy defense
mechanisms often fail to provide sufficient robustness against adaptive
adversaries. To overcome these challenges, we propose DP2Guard, a lightweight
PPFL framework that enhances both privacy and robustness. DP2Guard leverages a
lightweight gradient masking mechanism to replace costly cryptographic
operations while ensuring the privacy of local gradients. A hybrid defense
strategy is proposed, which extracts gradient features using singular value
decomposition and cosine similarity, and applies a clustering algorithm to
effectively identify malicious gradients. Additionally, DP2Guard adopts a trust
score-based adaptive aggregation scheme that adjusts client weights according
to historical behavior, while blockchain records aggregated results and trust
scores to ensure tamper-proof and auditable training. Extensive experiments
conducted on two public datasets demonstrate that DP2Guard effectively defends
against four advanced poisoning attacks while ensuring privacy with reduced
communication and computation costs.

</details>


### [23] [Attacking interpretable NLP systems](https://arxiv.org/abs/2507.16164)
*Eldor Abdukhamidov,Tamer Abuhmed,Joanna C. S. Santos,Mohammed Abuhamad*

Main category: cs.CR

TL;DR: 本文提出了AdvChar，一种针对可解释自然语言处理系统的黑盒攻击方法，通过微小的字符级修改来误导分类器，同时保持文本的语义相似性和解释性


<details>
  <summary>Details</summary>
Motivation: 现有的文本对抗攻击往往无法保持文本的语义含义和相似性，且针对可解释NLP系统的攻击研究不足。需要一种能够在保持解释相似性的同时误导分类器的攻击方法，以利用系统透明性中的信任漏洞

Method: 提出AdvChar黑盒攻击方法：1) 使用基于解释的评分方法确定最关键的标记；2) 对这些关键标记进行简单的字符级修改；3) 最小化原始文本与修改后文本的差异；4) 生成与良性样本相似的对抗性解释

Result: 在7个NLP模型和3个解释模型上进行了全面评估，实验表明AdvChar平均只需修改输入样本中的2个字符就能显著降低当前深度学习模型的预测准确率

Conclusion: AdvChar成功实现了对可解释NLP系统的有效攻击，能够在保持文本语义和解释相似性的前提下，通过极少的字符修改误导分类器，揭示了可解释系统中存在的安全漏洞

Abstract: Studies have shown that machine learning systems are vulnerable to
adversarial examples in theory and practice. Where previous attacks have
focused mainly on visual models that exploit the difference between human and
machine perception, text-based models have also fallen victim to these attacks.
However, these attacks often fail to maintain the semantic meaning of the text
and similarity. This paper introduces AdvChar, a black-box attack on
Interpretable Natural Language Processing Systems, designed to mislead the
classifier while keeping the interpretation similar to benign inputs, thus
exploiting trust in system transparency. AdvChar achieves this by making less
noticeable modifications to text input, forcing the deep learning classifier to
make incorrect predictions and preserve the original interpretation. We use an
interpretation-focused scoring approach to determine the most critical tokens
that, when changed, can cause the classifier to misclassify the input. We apply
simple character-level modifications to measure the importance of tokens,
minimizing the difference between the original and new text while generating
adversarial interpretations similar to benign ones. We thoroughly evaluated
AdvChar by testing it against seven NLP models and three interpretation models
using benchmark datasets for the classification task. Our experiments show that
AdvChar can significantly reduce the prediction accuracy of current deep
learning models by altering just two characters on average in input samples.

</details>


### [24] [SVAgent: AI Agent for Hardware Security Verification Assertion](https://arxiv.org/abs/2507.16203)
*Rui Guo,Avinash Ayalasomayajula,Henian Li,Jingbo Zhou,Sujan Kumar Saha,Farimah Farahmandi*

Main category: cs.CR

TL;DR: 本文提出了SVAgent框架，通过需求分解机制自动生成SystemVerilog断言(SVA)，解决了传统SVA开发效率低下和难以应对复杂集成电路安全漏洞的问题，在准确性和一致性方面显著优于现有框架。


<details>
  <summary>Details</summary>
Motivation: 随着集成电路设计全球化和安全要求不断升级，传统的SystemVerilog断言(SVA)开发模式暴露出重大局限性：开发效率低下，无法有效应对现代复杂集成电路中日益增多的安全漏洞检测需求。

Method: 提出SVAgent自动生成框架，引入需求分解机制，将原始复杂需求转换为结构化的、逐步可解的细粒度问题求解链，从而实现SVA的自动化生成。

Result: 实验表明SVAgent能够有效抑制幻觉和随机答案的影响，在SVA的准确性和一致性等关键评估指标上显著优于现有框架。成功将SVAgent集成到主流集成电路漏洞评估框架中。

Conclusion: SVAgent框架在实际工程设计环境中验证了其实用性和可靠性，为解决集成电路安全验证中的SVA开发挑战提供了有效的自动化解决方案。

Abstract: Verification using SystemVerilog assertions (SVA) is one of the most popular
methods for detecting circuit design vulnerabilities. However, with the
globalization of integrated circuit design and the continuous upgrading of
security requirements, the SVA development model has exposed major limitations.
It is not only inefficient in development, but also unable to effectively deal
with the increasing number of security vulnerabilities in modern complex
integrated circuits. In response to these challenges, this paper proposes an
innovative SVA automatic generation framework SVAgent. SVAgent introduces a
requirement decomposition mechanism to transform the original complex
requirements into a structured, gradually solvable fine-grained problem-solving
chain. Experiments have shown that SVAgent can effectively suppress the
influence of hallucinations and random answers, and the key evaluation
indicators such as the accuracy and consistency of the SVA are significantly
better than existing frameworks. More importantly, we successfully integrated
SVAgent into the most mainstream integrated circuit vulnerability assessment
framework and verified its practicality and reliability in a real engineering
design environment.

</details>


### [25] [eX-NIDS: A Framework for Explainable Network Intrusion Detection Leveraging Large Language Models](https://arxiv.org/abs/2507.16241)
*Paul R. B. Houssel,Siamak Layeghy,Priyanka Singh,Marius Portmann*

Main category: cs.CR

TL;DR: 本文提出了eX-NIDS框架，通过大语言模型和提示增强模块为网络入侵检测系统提供可解释性，能够生成准确一致的恶意流量分类解释，相比基础提示方法性能提升超过20%。


<details>
  <summary>Details</summary>
Motivation: 现有的基于流量的网络入侵检测系统缺乏可解释性，难以解释为什么某个网络流被识别为恶意流量，需要一个框架来增强NIDS的可解释性并提供详细的解释说明。

Method: 设计了eX-NIDS框架，包含提示增强模块(Prompt Augmenter)，该模块从恶意流量中提取上下文信息和网络威胁情报相关知识，将这些丰富的上下文数据与输入提示结合，输入到大语言模型中生成详细的恶意流量识别解释。

Result: 使用Llama 3和GPT-4模型进行定量评估，采用针对自然语言解释的新颖评估方法，重点关注解释的正确性和一致性。结果显示增强型大语言模型能够产生准确一致的解释，相比基础提示解释器性能提升超过20%。

Conclusion: eX-NIDS框架成功地为网络入侵检测系统提供了可解释性，增强型提示的使用显著提高了解释质量，证明了大语言模型可以作为NIDS中解释恶意流量分类的有价值补充工具。

Abstract: This paper introduces eX-NIDS, a framework designed to enhance
interpretability in flow-based Network Intrusion Detection Systems (NIDS) by
leveraging Large Language Models (LLMs). In our proposed framework, flows
labelled as malicious by NIDS are initially processed through a module called
the Prompt Augmenter. This module extracts contextual information and Cyber
Threat Intelligence (CTI)-related knowledge from these flows. This enriched,
context-specific data is then integrated with an input prompt for an LLM,
enabling it to generate detailed explanations and interpretations of why the
flow was identified as malicious by NIDS. We compare the generated
interpretations against a Basic-Prompt Explainer baseline, which does not
incorporate any contextual information into the LLM's input prompt. Our
framework is quantitatively evaluated using the Llama 3 and GPT-4 models,
employing a novel evaluation method tailored for natural language explanations,
focusing on their correctness and consistency. The results demonstrate that
augmented LLMs can produce accurate and consistent explanations, serving as
valuable complementary tools in NIDS to explain the classification of malicious
flows. The use of augmented prompts enhances performance by over 20% compared
to the Basic-Prompt Explainer.

</details>


### [26] [From Contracts to Code: Automating Smart Contract Generation with Multi-Level Finite State Machines](https://arxiv.org/abs/2507.16276)
*Lambard Maxence,Bertelle Cyrille,Duvallet Claude*

Main category: cs.CR

TL;DR: 本研究提出了一种多级有限状态机模型来简化智能合约开发，通过形式化框架降低技术门槛，提高合约的模块化和可追溯性，并进行了安全性分析以确保生成合约的可靠性。


<details>
  <summary>Details</summary>
Motivation: 智能合约虽然能提供透明、安全、高效的解决方案，但其复杂性和对高级编程技能的要求成为广泛应用的重大障碍。需要一种简化智能合约开发的方法，让没有深厚技术专业知识的专业人员也能使用。

Method: 引入多级有限状态机模型来表示和跟踪智能合约的执行。该模型提供形式化框架，抽象底层技术复杂性，采用分层结构增强合约模块化和可追溯性，重点关注可重用组件和模块化的智能合约生成过程。

Result: 开发出的多级有限状态机模型能够简化智能合约开发流程，提高合约的模块化程度和可追溯性，使非技术专业人员也能参与智能合约开发。模型支持详细的功能属性表示和评估。

Conclusion: 多级有限状态机模型为智能合约开发提供了一个有效的解决方案，通过抽象技术复杂性和提高模块化程度，降低了智能合约开发的门槛。安全性分析确保了生成的智能合约具有足够的鲁棒性和可靠性，为智能合约的广泛应用奠定了基础。

Abstract: In an increasingly complex contractual landscape, the demand for
transparency, security, and efficiency has intensified. Blockchain technology,
with its decentralized and immutable nature, addresses these challenges by
reducing intermediary costs, minimizing fraud risks, and enhancing system
compatibility. Smart contracts, initially conceptualized by Nick Szabo and
later implemented on the Ethereum blockchain, automate and secure contractual
clauses, offering a robust solution for various industries. However, their
complexity and the requirement for advanced programming skills present
significant barriers to widespread adoption. This study introduces a
multi-level finite state machine model designed to represent and track the
execution of smart contracts. Our model aims to simplify smart contract
development by providing a formalized framework that abstracts underlying
technical complexities, making it accessible to professionals without deep
technical expertise. The hierarchical structure of the multi-level finite state
machine enhances contract modularity and traceability, facilitating detailed
representation and evaluation of functional properties. The paper explores the
potential of this multi-level approach, reviewing existing methodologies and
tools, and detailing the smart contract generation process with an emphasis on
reusable components and modularity. We also conduct a security analysis to
evaluate potential vulnerabilities in our model, ensuring the robustness and
reliability of the generated smart contracts.

</details>


### [27] [Talking Like a Phisher: LLM-Based Attacks on Voice Phishing Classifiers](https://arxiv.org/abs/2507.16291)
*Wenhao Li,Selvakumar Manickam,Yung-wey Chong,Shankar Karuppayah*

Main category: cs.CR

TL;DR: 研究利用大语言模型生成对抗性语音钓鱼转录文本，发现LLM能够有效绕过机器学习分类器的检测，GPT-4o生成的文本可将分类器准确率降低30.96%，揭示了当前检测系统的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 语音钓鱼攻击持续威胁网络安全，虽然机器学习分类器在检测恶意通话转录方面显示出潜力，但它们容易受到保持语义内容的对抗性操作的攻击。研究旨在探索利用大语言模型生成能够逃避检测同时保持欺骗意图的对抗性语音钓鱼转录文本这一新型攻击向量。

Method: 构建了一个系统性攻击管道，采用提示工程和语义混淆技术，使用四个商业大语言模型来转换真实世界的语音钓鱼脚本。对生成的转录文本进行评估，测试其对在真实世界韩国语音钓鱼数据集(KorCCViD)上训练的多个机器学习分类器的攻击效果，并进行统计测试。

Result: LLM生成的转录文本在实际和统计上都对基于机器学习的分类器有效。特别是GPT-4o制作的转录文本显著降低了分类器准确率（最高降低30.96%），同时通过BERTScore测量保持了高语义相似性。这些攻击既省时又经济，平均生成时间不到9秒，每次查询的财务成本可忽略不计。

Conclusion: 结果强调了开发更具弹性的语音钓鱼检测框架的迫切需要，并突出了LLM提供商在对抗性社会工程环境中针对提示滥用实施更强安全保障措施的必要性。当前的机器学习检测系统面临严重的对抗性攻击威胁，需要更强的防御机制。

Abstract: Voice phishing (vishing) remains a persistent threat in cybersecurity,
exploiting human trust through persuasive speech. While machine learning
(ML)-based classifiers have shown promise in detecting malicious call
transcripts, they remain vulnerable to adversarial manipulations that preserve
semantic content. In this study, we explore a novel attack vector where large
language models (LLMs) are leveraged to generate adversarial vishing
transcripts that evade detection while maintaining deceptive intent. We
construct a systematic attack pipeline that employs prompt engineering and
semantic obfuscation to transform real-world vishing scripts using four
commercial LLMs. The generated transcripts are evaluated against multiple ML
classifiers trained on a real-world Korean vishing dataset (KorCCViD) with
statistical testing. Our experiments reveal that LLM-generated transcripts are
both practically and statistically effective against ML-based classifiers. In
particular, transcripts crafted by GPT-4o significantly reduce classifier
accuracy (by up to 30.96%) while maintaining high semantic similarity, as
measured by BERTScore. Moreover, these attacks are both time-efficient and
cost-effective, with average generation times under 9 seconds and negligible
financial cost per query. The results underscore the pressing need for more
resilient vishing detection frameworks and highlight the imperative for LLM
providers to enforce stronger safeguards against prompt misuse in adversarial
social engineering contexts.

</details>


### [28] [DREAM: Scalable Red Teaming for Text-to-Image Generative Systems via Distribution Modeling](https://arxiv.org/abs/2507.16329)
*Boheng Li,Junjie Wang,Yiming Li,Zhiyang Hu,Leyi Qi,Jianshuo Dong,Run Wang,Han Qiu,Zhan Qin,Tianwei Zhang*

Main category: cs.CR

TL;DR: 本文提出DREAM框架，通过建模问题提示词的概率分布来自动发现文本到图像生成模型的安全漏洞，相比现有方法在成功率和多样性方面都有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像生成模型尽管集成了安全对齐和外部过滤器，仍然容易产生有害内容（如性或暴力图像）。现有的自动化红队测试方法将提示词发现视为孤立的提示词级优化任务，限制了其可扩展性、多样性和整体有效性。

Method: 提出DREAM框架，直接建模目标系统问题提示词的概率分布，而非单独优化提示词。借鉴能量模型思想，将目标重新表述为简单可处理的目标函数。引入GC-SPSA优化算法，通过长且可能不可微的T2I管道提供稳定的梯度估计。

Result: 通过广泛实验验证，DREAM在各种T2I模型和安全过滤器上，在提示词成功率和多样性方面显著超越了9个最先进的基线方法。

Conclusion: DREAM框架通过直接建模问题提示词的概率分布，实现了对有效性和多样性的显式优化，并支持训练后的高效大规模采样，为T2I系统的安全评估提供了更有效的红队测试方法。

Abstract: Despite the integration of safety alignment and external filters,
text-to-image (T2I) generative models are still susceptible to producing
harmful content, such as sexual or violent imagery. This raises serious
concerns about unintended exposure and potential misuse. Red teaming, which
aims to proactively identify diverse prompts that can elicit unsafe outputs
from the T2I system (including the core generative model as well as potential
external safety filters and other processing components), is increasingly
recognized as an essential method for assessing and improving safety before
real-world deployment. Yet, existing automated red teaming approaches often
treat prompt discovery as an isolated, prompt-level optimization task, which
limits their scalability, diversity, and overall effectiveness. To bridge this
gap, in this paper, we propose DREAM, a scalable red teaming framework to
automatically uncover diverse problematic prompts from a given T2I system.
Unlike most prior works that optimize prompts individually, DREAM directly
models the probabilistic distribution of the target system's problematic
prompts, which enables explicit optimization over both effectiveness and
diversity, and allows efficient large-scale sampling after training. To achieve
this without direct access to representative training samples, we draw
inspiration from energy-based models and reformulate the objective into simple
and tractable objectives. We further introduce GC-SPSA, an efficient
optimization algorithm that provide stable gradient estimates through the long
and potentially non-differentiable T2I pipeline. The effectiveness of DREAM is
validated through extensive experiments, demonstrating that it surpasses 9
state-of-the-art baselines by a notable margin across a broad range of T2I
models and safety filters in terms of prompt success rate and diversity.

</details>


### [29] [Depth Gives a False Sense of Privacy: LLM Internal States Inversion](https://arxiv.org/abs/2507.16372)
*Tian Dong,Yan Meng,Shaofeng Li,Guoxing Chen,Zhen Liu,Haojin Zhu*

Main category: cs.CR

TL;DR: 本文提出了四种针对大语言模型内部状态的反演攻击方法，挑战了传统认为内部状态不可逆的假设，并证明了这些攻击能够有效恢复原始输入，对现有隐私保护机制构成威胁。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在协作推理和安全审计中会暴露内部状态，传统观点认为这些内部状态由于优化困难和深层抽象表示而无法逆向恢复原始输入。然而，这一假设的安全性需要被重新审视和验证。

Method: 提出四种反演攻击方法：1）针对浅层和深层内部状态的两种白盒优化攻击，通过两阶段反演过程避免局部最小值收敛；2）利用源模型和衍生模型间可迁移性的黑盒攻击；3）将反演视为翻译任务的生成式攻击，使用反演模型重构输入。

Result: 在医疗咨询和编程辅助数据集上对6个大语言模型进行广泛评估，证明了攻击的有效性。特别地，一个4112个token的长医疗咨询提示能够从Llama-3模型的中间层以86.88的F1 token匹配率被近乎完美地反演。

Conclusion: 现有的四种实用防御措施无法完全阻止内部状态反演攻击，表明当前的隐私保护机制存在重大漏洞。研究为未来的缓解措施设计提供了重要指导，强调了重新评估大语言模型内部状态安全性的必要性。

Abstract: Large Language Models (LLMs) are increasingly integrated into daily routines,
yet they raise significant privacy and safety concerns. Recent research
proposes collaborative inference, which outsources the early-layer inference to
ensure data locality, and introduces model safety auditing based on inner
neuron patterns. Both techniques expose the LLM's Internal States (ISs), which
are traditionally considered irreversible to inputs due to optimization
challenges and the highly abstract representations in deep layers. In this
work, we challenge this assumption by proposing four inversion attacks that
significantly improve the semantic similarity and token matching rate of
inverted inputs. Specifically, we first develop two white-box
optimization-based attacks tailored for low-depth and high-depth ISs. These
attacks avoid local minima convergence, a limitation observed in prior work,
through a two-phase inversion process. Then, we extend our optimization attack
under more practical black-box weight access by leveraging the transferability
between the source and the derived LLMs. Additionally, we introduce a
generation-based attack that treats inversion as a translation task, employing
an inversion model to reconstruct inputs. Extensive evaluation of short and
long prompts from medical consulting and coding assistance datasets and 6 LLMs
validates the effectiveness of our inversion attacks. Notably, a 4,112-token
long medical consulting prompt can be nearly perfectly inverted with 86.88 F1
token matching from the middle layer of Llama-3 model. Finally, we evaluate
four practical defenses that we found cannot perfectly prevent ISs inversion
and draw conclusions for future mitigation design.

</details>


### [30] [Explainable Vulnerability Detection in C/C++ Using Edge-Aware Graph Attention Networks](https://arxiv.org/abs/2507.16540)
*Radowanul Haque,Aftab Ali,Sally McClean,Naveed Khan*

Main category: cs.CR

TL;DR: ExplainVulD是一个基于图的C/C++代码漏洞检测框架，通过双通道嵌入和边感知注意力机制处理代码属性图，解决类别不平衡问题，在ReVeal数据集上达到88.25%准确率和48.23% F1分数，同时提供可解释的漏洞检测结果。


<details>
  <summary>Details</summary>
Motivation: 现有的漏洞检测方法面临三个主要问题：1）真实数据集中存在严重的类别不平衡，漏洞函数数量不足；2）现有方法往往优化召回率，导致误报率高，实用性差；3）缺乏可解释性，限制了在安全工作流程中的集成应用。

Method: 构建代码属性图（Code Property Graphs）并使用双通道嵌入表示节点，同时捕获语义和结构信息；采用边感知注意力机制，结合边类型嵌入来区分程序关系；使用类加权交叉熵损失来解决类别不平衡问题；通过识别函数内最有影响力的代码区域来提供可解释的输出。

Result: 在ReVeal数据集上经过30次独立运行，ExplainVulD达到平均准确率88.25%和F1分数48.23%；相比ReVeal模型，准确率相对提升4.6%，F1分数相对提升16.9%；相比静态分析工具，准确率相对提升14.0-14.1%，F1分数相对提升132.2-201.2%。

Conclusion: ExplainVulD成功提升了漏洞检测性能，不仅在准确率和F1分数方面优于现有方法和静态分析工具，还通过识别最具影响力的代码区域提供了可解释的输出，支持安全分类中的透明度和信任度，为实际安全工作流程的集成提供了更好的支持。

Abstract: Detecting security vulnerabilities in source code remains challenging,
particularly due to class imbalance in real-world datasets where vulnerable
functions are under-represented. Existing learning-based methods often optimise
for recall, leading to high false positive rates and reduced usability in
development workflows. Furthermore, many approaches lack explainability,
limiting their integration into security workflows. This paper presents
ExplainVulD, a graph-based framework for vulnerability detection in C/C++ code.
The method constructs Code Property Graphs and represents nodes using
dual-channel embeddings that capture both semantic and structural information.
These are processed by an edge-aware attention mechanism that incorporates
edge-type embeddings to distinguish among program relations. To address class
imbalance, the model is trained using class-weighted cross-entropy loss.
ExplainVulD achieves a mean accuracy of 88.25 percent and an F1 score of 48.23
percent across 30 independent runs on the ReVeal dataset. These results
represent relative improvements of 4.6 percent in accuracy and 16.9 percent in
F1 score compared to the ReVeal model, a prior learning-based method. The
framework also outperforms static analysis tools, with relative gains of 14.0
to 14.1 percent in accuracy and 132.2 to 201.2 percent in F1 score. Beyond
improved detection performance, ExplainVulD produces explainable outputs by
identifying the most influential code regions within each function, supporting
transparency and trust in security triage.

</details>


### [31] [From Text to Actionable Intelligence: Automating STIX Entity and Relationship Extraction](https://arxiv.org/abs/2507.16576)
*Ahmed Lekssays,Husrev Taha Sencar,Ting Yu*

Main category: cs.CR

TL;DR: 研究者开发了AZERG工具，利用大语言模型自动从非结构化安全文本中生成STIX格式的威胁情报数据，通过将任务分解为四个子任务并进行针对性微调，在真实场景中取得了84-95%的F1分数表现。


<details>
  <summary>Details</summary>
Motivation: 威胁分析报告对安全运营至关重要，STIX框架已成为威胁情报共享的广泛采用标准，但从非结构化安全文本生成STIX兼容数据仍然是一个主要依赖专家的手工过程，缺乏自动化和及时性。

Method: 开发AZERG工具，适配通用大语言模型用于提取STIX格式威胁数据。将复杂任务分解为四个子任务：实体检测(T1)、实体类型识别(T2)、相关对检测(T3)和关系类型识别(T4)。应用任务特定的微调来准确提取相关实体并推断其关系。构建包含4,011个实体和2,075个关系的综合数据集，来自141份完整威胁分析报告。

Result: 模型在真实场景中取得优异表现：T1任务F1分数84.43%，T2任务88.49%，T3任务95.47%，T4任务84.60%。与开放和封闭参数模型以及最先进方法相比，各项任务均有2-25%的性能提升。

Conclusion: AZERG工具成功实现了从非结构化安全文本自动生成STIX格式威胁情报的目标，通过任务分解和针对性微调的方法显著提升了威胁情报处理的自动化水平和准确性，为安全分析师提供了有效的辅助工具。

Abstract: Sharing methods of attack and their effectiveness is a cornerstone of
building robust defensive systems. Threat analysis reports, produced by various
individuals and organizations, play a critical role in supporting security
operations and combating emerging threats. To enhance the timeliness and
automation of threat intelligence sharing, several standards have been
established, with the Structured Threat Information Expression (STIX) framework
emerging as one of the most widely adopted. However, generating STIX-compatible
data from unstructured security text remains a largely manual, expert-driven
process. To address this challenge, we introduce AZERG, a tool designed to
assist security analysts in automatically generating structured STIX
representations. To achieve this, we adapt general-purpose large language
models for the specific task of extracting STIX-formatted threat data. To
manage the complexity, the task is divided into four subtasks: entity detection
(T1), entity type identification (T2), related pair detection (T3), and
relationship type identification (T4). We apply task-specific fine-tuning to
accurately extract relevant entities and infer their relationships in
accordance with the STIX specification. To address the lack of training data,
we compiled a comprehensive dataset with 4,011 entities and 2,075 relationships
extracted from 141 full threat analysis reports, all annotated in alignment
with the STIX standard. Our models achieved F1-scores of 84.43% for T1, 88.49%
for T2, 95.47% for T3, and 84.60% for T4 in real-world scenarios. We validated
their performance against a range of open- and closed-parameter models, as well
as state-of-the-art methods, demonstrating improvements of 2-25% across tasks.

</details>


### [32] [LLMxCPG: Context-Aware Vulnerability Detection Through Code Property Graph-Guided Large Language Models](https://arxiv.org/abs/2507.16585)
*Ahmed Lekssays,Hamza Mouhcine,Khang Tran,Ting Yu,Issa Khalil*

Main category: cs.CR

TL;DR: 本文提出了LLMxCPG框架，结合代码属性图(CPG)和大语言模型(LLM)进行软件漏洞检测，通过CPG切片技术将代码大小减少67.84-90.93%，同时保持漏洞相关上下文，在验证数据集上F1分数比现有方法提升15-40%。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习漏洞检测方法存在准确性和鲁棒性问题：在严格验证的数据集上准确率下降高达45%，在简单代码修改下性能显著退化。同时，2024年仅CVE数据库就报告了超过25,000个新漏洞，亟需更有效的漏洞检测方法。

Method: 提出LLMxCPG框架，集成代码属性图(CPG)和大语言模型(LLM)。采用基于CPG的切片构建技术，在保持漏洞相关上下文的同时大幅减少代码大小，使模型能够分析更大的代码段，包括整个项目，并识别跨多个函数的漏洞。

Result: 在验证数据集上，LLMxCPG相比最先进的基线方法在F1分数上实现了15-40%的提升。CPG切片技术将代码大小减少了67.84%到90.93%。该方法在函数级和多函数代码库中都保持了高性能，并在各种语法代码修改下表现出强大的检测效力。

Conclusion: LLMxCPG框架通过结合CPG和LLM，有效解决了现有漏洞检测方法的准确性和鲁棒性问题。该方法能够提供更简洁准确的代码表示，支持大规模代码分析和跨函数漏洞检测，在多个评估指标上显著优于现有技术。

Abstract: Software vulnerabilities present a persistent security challenge, with over
25,000 new vulnerabilities reported in the Common Vulnerabilities and Exposures
(CVE) database in 2024 alone. While deep learning based approaches show promise
for vulnerability detection, recent studies reveal critical limitations in
terms of accuracy and robustness: accuracy drops by up to 45% on rigorously
verified datasets, and performance degrades significantly under simple code
modifications. This paper presents LLMxCPG, a novel framework integrating Code
Property Graphs (CPG) with Large Language Models (LLM) for robust vulnerability
detection. Our CPG-based slice construction technique reduces code size by
67.84 to 90.93% while preserving vulnerability-relevant context. Our approach's
ability to provide a more concise and accurate representation of code snippets
enables the analysis of larger code segments, including entire projects. This
concise representation is a key factor behind the improved detection
capabilities of our method, as it can now identify vulnerabilities that span
multiple functions. Empirical evaluation demonstrates LLMxCPG's effectiveness
across verified datasets, achieving 15-40% improvements in F1-score over
state-of-the-art baselines. Moreover, LLMxCPG maintains high performance across
function-level and multi-function codebases while exhibiting robust detection
efficacy under various syntactic code modifications.

</details>


### [33] [When LLMs Copy to Think: Uncovering Copy-Guided Attacks in Reasoning LLMs](https://arxiv.org/abs/2507.16773)
*Yue Li,Xiao Li,Hao Wu,Yue Zhang,Fengyuan Xu,Xiuzhen Cheng,Sheng Zhong*

Main category: cs.CR

TL;DR: 本文发现了一种新的针对大语言模型的攻击方式——复制引导攻击(CGA)，该攻击利用推理型LLM的固有复制倾向，通过在外部代码中注入精心设计的触发器来操纵模型的推理过程和结果。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在自动化代码分析中的广泛应用，其集成引入了新的攻击面。现有研究缺乏对基于提示的攻击的深入探索，特别是利用推理型LLM复制倾向的攻击方式，这为恶意攻击者提供了新的攻击机会。

Method: 将复制引导攻击(CGA)形式化为优化问题，提出基于梯度的方法来合成有效的触发器。通过在外部代码片段中注入精心设计的触发器，诱导模型在推理过程中复制恶意内容，实现对推理长度和推理结果的操纵。

Result: 在最先进的推理型LLM上的实证评估显示，CGA能够可靠地诱导无限循环、过早终止、虚假拒绝以及代码分析任务中的语义扭曲。攻击在目标设置下高度有效，但在跨多样化提示的泛化方面存在挑战。

Conclusion: 研究暴露了LLM驱动的开发流水线中一个关键但未充分探索的漏洞，揭示了两类主要攻击：推理长度操纵和推理结果操纵。这些发现呼吁在提示级防御机制方面取得紧迫进展，为未来研究提出了开放性问题。

Abstract: Large Language Models (LLMs) have become integral to automated code analysis,
enabling tasks such as vulnerability detection and code comprehension. However,
their integration introduces novel attack surfaces. In this paper, we identify
and investigate a new class of prompt-based attacks, termed Copy-Guided Attacks
(CGA), which exploit the inherent copying tendencies of reasoning-capable LLMs.
By injecting carefully crafted triggers into external code snippets,
adversaries can induce the model to replicate malicious content during
inference. This behavior enables two classes of vulnerabilities: inference
length manipulation, where the model generates abnormally short or excessively
long reasoning traces; and inference result manipulation, where the model
produces misleading or incorrect conclusions. We formalize CGA as an
optimization problem and propose a gradient-based approach to synthesize
effective triggers. Empirical evaluation on state-of-the-art reasoning LLMs
shows that CGA reliably induces infinite loops, premature termination, false
refusals, and semantic distortions in code analysis tasks. While highly
effective in targeted settings, we observe challenges in generalizing CGA
across diverse prompts due to computational constraints, posing an open
question for future research. Our findings expose a critical yet underexplored
vulnerability in LLM-powered development pipelines and call for urgent advances
in prompt-level defense mechanisms.

</details>


### [34] [AUTOPSY: A Framework for Tackling Privacy Challenges in the Automotive Industry](https://arxiv.org/abs/2507.16788)
*Sebastian Pape,Anis Bkakria,Maurice Heymann,Badreddine Chah,Abdeljalil Abbas-Turki,Sarah Syed-Winkler,Matthias Hiller,Reda Yaich*

Main category: cs.CR

TL;DR: AUTOPSY项目旨在通过提供多个技术构建模块来支持汽车领域的隐私工程过程，以技术手段提升现代联网和(部分)自动化车辆的隐私友好性。


<details>
  <summary>Details</summary>
Motivation: 尽管GDPR合规不一定能带来隐私友好的系统（如仅获得用户同意处理数据并不能改善系统的隐私友好性），因此需要在汽车领域开发技术手段来真正提升隐私保护水平。

Method: 开发了一个系统模型来识别相关实体和位置以应用隐私增强技术(PETs)；设计了隐私管理器以更好地控制车辆数据流；基于GDPR原则提出了PET选择方法；构建了汽车隐私架构框架；并开发了基于位置服务的演示器来评估架构框架。

Result: 成功构建了包含系统模型、隐私管理器、PET选择方法和架构框架在内的完整隐私工程解决方案，并通过基于位置的服务演示器验证了架构框架的有效性。

Conclusion: AUTOPSY项目成功提供了支持汽车领域隐私工程的技术构建模块，能够从技术层面真正改善现代联网和自动化车辆的隐私友好性，超越了单纯的GDPR合规要求。

Abstract: With the General Data Protection Regulation (GDPR) in place, all domains have
to ensure compliance with privacy legislation. However, compliance does not
necessarily result in a privacy-friendly system as for example getting users'
consent to process their data does not improve the privacy-friendliness of the
system. Therefore, the goal of the AUTOPSY project was to support the privacy
engineering process in the automotive domain by providing several building
blocks which technically improve the privacy-friendliness of modern, i.e.,
connected and (partially) automated vehicles. This paper presents the results
of the AUTOPSY project: a system model to identify relevant entities and
locations to apply privacy enhancing technologies (PETs); the privacy manager
aiming at more control of the data flow from the vehicle, a PET selection
approach based on GDPR principles, and an architectural framework for
automotive privacy. Furthermore, we built a demonstrator for location-based
services to evaluate the architectural framework.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [35] [From Reasoning to Super-Intelligence: A Search-Theoretic Perspective](https://arxiv.org/abs/2507.15865)
*Shai Shalev-Shwartz,Amnon Shashua*

Main category: cs.AI

TL;DR: 论文提出了"勤奋学习者"(Diligent Learner)这一新的学习范式，通过将推理建模为由验证器引导的深度优先搜索并支持回溯来解决现有思维链学习方法的核心障碍，为构建大规模推理模型提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 现有的思维链(CoT)学习方法如监督微调、强化学习、思维树等在复杂推理任务上经常失败，缺乏坚实的理论基础，且存在分布漂移、缺乏嵌入式搜索和指数级推理成本等核心障碍。

Method: 提出"勤奋学习者"学习范式，将推理显式建模为由验证器引导的深度优先搜索过程，支持在失败时进行回溯，能够从自然出现的不完整CoT数据中高效学习。

Result: 在两个温和且现实的假设条件下，理论证明了勤奋学习者能够从CoT数据中高效学习，而现有方法无法做到这一点，为构建可扩展且可靠的推理系统提供了路径。

Conclusion: 该框架为开发具有鲁棒性和可解释性问题解决能力的大规模推理模型(LRMs)铺平了道路，能够在自然出现的不完整数据上进行训练，解决了现有CoT学习方法的根本性问题。

Abstract: Chain-of-Thought (CoT) reasoning has emerged as a powerful tool for enhancing
the problem-solving capabilities of large language models (LLMs). However, the
theoretical foundations of learning from CoT data remain underdeveloped, and
existing approaches -- such as Supervised Fine-Tuning (SFT), Reinforcement
Learning (RL), Tree-of-Thoughts (ToT), and Monte Carlo Tree Search (MCTS) --
often fail on complex reasoning tasks. In this work, we identify core obstacles
that hinder effective CoT learning, including distribution drift, lack of
embedded search, and exponential inference costs. We introduce the Diligent
Learner, a new learning paradigm that explicitly models reasoning as a
depth-first search guided by a validator and supports backtracking upon
failure. Under two mild and realistic assumptions, we prove that the Diligent
Learner can efficiently learn from CoT data while existing methods fail to do
so. This framework offers a path toward building scalable and reliable
reasoning systems trained on naturally occurring, incomplete data -- paving the
way for the development of Large Reasoning Models (LRMs) with robust,
interpretable problem-solving abilities.

</details>


### [36] [Purchase and Production Optimization in a Meat Processing Plant](https://arxiv.org/abs/2507.15866)
*Marek Vlk,Premysl Sucha,Jaroslaw Rudy,Radoslaw Idzikowski*

Main category: cs.AI

TL;DR: 本文针对肉类加工企业的原料采购和处理优化问题，提出了基于整数线性规划的迭代算法，能够在几秒内找到最优解。


<details>
  <summary>Details</summary>
Motivation: 食品生产行业，特别是肉类生产部门面临诸多挑战，欧盟能源危机使情况恶化。高效利用输入材料对企业盈利至关重要。现有文献多关注供应链管理，缺乏对生产阶段的深入研究，且忽略了最小订购量和替代品最小百分比等重要约束条件。

Method: 设计了基于整数线性规划的简单迭代方法。该方法考虑了材料处理的替代方式、不同到期日的库存材料，以及最小订购量和替代品最小百分比等约束条件。证明了这两个约束使问题变为NP难问题，并使用开源整数线性规划求解器来解决实际问题。

Result: 使用肉类加工公司的真实数据验证了算法的有效性。算法能够在几秒钟内为所有考虑的用例找到最优解。该方法还缓解了由于数据值范围广泛而在商业求解器中遇到的数值问题。

Conclusion: 提出的迭代整数线性规划方法能够高效解决肉类加工企业的原料采购和处理优化问题，在实际应用中表现出色，为企业提供了实用的优化工具。

Abstract: The food production industry, especially the meat production sector, faces
many challenges that have even escalated due to the recent outbreak of the
energy crisis in the European Union. Therefore, efficient use of input
materials is an essential aspect affecting the profit of such companies. This
paper addresses an optimization problem concerning the purchase and subsequent
material processing we solved for a meat processing company. Unlike the
majority of existing papers, we do not concentrate on how this problem concerns
supply chain management, but we focus purely on the production stage. The
problem involves the concept of alternative ways of material processing, stock
of material with different expiration dates, and extra constraints widely
neglected in the current literature, namely, the minimum order quantity and the
minimum percentage in alternatives. We prove that each of these two constraints
makes the problem \mbox{$\mathcal{NP}$-hard}, and hence we design a simple
iterative approach based on integer linear programming that allows us to solve
real-life instances even using an open-source integer linear programming
solver. Another advantage of this approach is that it mitigates numerical
issues, caused by the extensive range of data values, we experienced with a
commercial solver. The results obtained using real data from the meat
processing company showed that our algorithm can find the optimum solution in a
few seconds for all considered use cases.

</details>


### [37] [Why Braking? Scenario Extraction and Reasoning Utilizing LLM](https://arxiv.org/abs/2507.15874)
*Yin Wu,Daniel Slieter,Vivek Subramanian,Ahmed Abouelazm,Robin Bohn,J. Marius Zöllner*

Main category: cs.AI

TL;DR: 本文提出了一个基于大语言模型(LLM)的驾驶场景理解框架，用于分析车辆制动行为和识别安全关键场景，解决了传统基于规则的方法在复杂城市环境中泛化能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 随着ADAS车辆数量增长，驾驶数据急剧增加，但大多数数据反映的是常规驾驶行为。在这些海量数据中识别和理解安全关键的极端案例仍然是一个重大挑战。制动事件特别能够指示潜在的危险情况，因此研究的核心问题是：车辆为什么制动？现有的基于规则的启发式方法虽然在高速公路等简单环境中有效，但在复杂城市环境中缺乏泛化能力。

Method: 提出了一个新颖的基于大语言模型(LLM)的框架，用于场景理解和推理。该方法在低级数值信号和自然语言描述之间建立桥梁，使LLM能够解释和分类驾驶场景。提出了双路径场景检索机制，支持基于类别的已知场景搜索和基于嵌入的未知分布外(OOD)场景检索。

Result: 在Argoverse 2传感器数据集上进行了场景标注和评估。实验结果表明，该方法优于基于规则的基线方法，并且在分布外场景中表现出良好的泛化能力。

Conclusion: 基于LLM的驾驶场景理解框架能够有效分析车辆制动行为，识别安全关键场景，相比传统方法具有更好的泛化能力，特别是在复杂城市环境和未知场景中表现优异。

Abstract: The growing number of ADAS-equipped vehicles has led to a dramatic increase
in driving data, yet most of them capture routine driving behavior. Identifying
and understanding safety-critical corner cases within this vast dataset remains
a significant challenge. Braking events are particularly indicative of
potentially hazardous situations, motivating the central question of our
research: Why does a vehicle brake? Existing approaches primarily rely on
rule-based heuristics to retrieve target scenarios using predefined condition
filters. While effective in simple environments such as highways, these methods
lack generalization in complex urban settings. In this paper, we propose a
novel framework that leverages Large Language Model (LLM) for scenario
understanding and reasoning. Our method bridges the gap between low-level
numerical signals and natural language descriptions, enabling LLM to interpret
and classify driving scenarios. We propose a dual-path scenario retrieval that
supports both category-based search for known scenarios and embedding-based
retrieval for unknown Out-of-Distribution (OOD) scenarios. To facilitate
evaluation, we curate scenario annotations on the Argoverse 2 Sensor Dataset.
Experimental results show that our method outperforms rule-based baselines and
generalizes well to OOD scenarios.

</details>


### [38] [Differential Multimodal Transformers](https://arxiv.org/abs/2507.15875)
*Jerry Li,Timothy Oh,Joseph Hoang,Vardhit Veeramachaneni*

Main category: cs.AI

TL;DR: 该研究将差分注意力机制从纯文本模型扩展到文本-视觉模型PaliGemma，通过LoRA微调减少噪声信息检索和幻觉问题，提升问答能力。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型在融合视觉等额外模态时面临上下文窗口有限的挑战，因为会引入噪声。Transformer注意力机制经常过度关注无关上下文，需要改进机制来缓解噪声信息检索和减少幻觉。

Method: 将原本为纯文本模型设计的差分注意力机制扩展到文本-视觉模型PaliGemma。使用LoRA对PaliGemma 3B模型进行微调，融入差分注意力机制，并尝试各种参数设置和配置。

Result: 证明了差分注意力机制可以成功适配并集成到现有模型的微调过程中，能够增强噪声信息检索和问答能力。

Conclusion: 差分注意力机制可以有效地从纯文本模型扩展到多模态文本-视觉模型，通过减少对无关上下文的关注来提升模型性能，为小型多模态模型的优化提供了可行的解决方案。

Abstract: Small language models have gained significant popularity due to their
efficiency and growing capabilities. However, incorporating additional
modalities, such as vision, can exacerbate the challenge of limited context
windows by introducing noise. Recent studies have highlighted that Transformer
attention mechanisms often disproportionately focus on irrelevant contexts. In
this work, we extend the Differential Attention mechanism, originally designed
for text-only models, to the text-vision model PaliGemma. Our aim is to
evaluate its ability to mitigate noisy information retrieval and reduce
hallucinations. To this end, we fine-tuned the PaliGemma 3B model using LoRA,
incorporating Differential Attention, and experimented with various parameter
settings and configurations. We demonstrate that Differential Attention can be
adapted and integrated into the fine-tuning of existing models to enhance noisy
information retrieval and question-answering capabilities.

</details>


### [39] [Re-evaluating Short- and Long-Term Trend Factors in CTA Replication: A Bayesian Graphical Approach](https://arxiv.org/abs/2507.15876)
*Eric Benhamou,Jean-Jacques Ohana,Alban Etienne,Béatrice Guez,Ethan Setrouk,Thomas Jacquot*

Main category: cs.AI

TL;DR: 本文通过贝叶斯图形模型动态分解CTA收益为短期趋势、长期趋势和市场贝塔因子，研究不同时间周期趋势系统的相对优势及其对风险调整收益的影响


<details>
  <summary>Details</summary>
Motivation: 商品交易顾问(CTA)历史上依赖于在不同时间周期上运作的趋势跟踪规则，但短期与长期趋势系统的相对优势和相互作用仍存在争议，需要深入研究这些系统如何影响策略的风险调整表现

Method: 使用贝叶斯图形模型动态分解CTA收益，将收益分解为短期趋势因子、长期趋势因子和市场贝塔因子三个组成部分

Result: 通过动态分解分析，展示了不同时间周期趋势系统的混合如何塑造策略的风险调整表现，为理解短期与长期趋势系统的相对优势提供了新的视角

Conclusion: 不同时间周期趋势系统的组合方式对CTA策略的风险调整收益具有重要影响，通过贝叶斯图形模型可以有效识别和量化这些影响

Abstract: Commodity Trading Advisors (CTAs) have historically relied on trend-following
rules that operate on vastly different horizons from long-term breakouts that
capture major directional moves to short-term momentum signals that thrive in
fast-moving markets. Despite a large body of work on trend following, the
relative merits and interactions of short-versus long-term trend systems remain
controversial. This paper adds to the debate by (i) dynamically decomposing CTA
returns into short-term trend, long-term trend and market beta factors using a
Bayesian graphical model, and (ii) showing how the blend of horizons shapes the
strategy's risk-adjusted performance.

</details>


### [40] [Out-of-Distribution Generalization in the ARC-AGI Domain: Comparing Execution-Guided Neural Program Synthesis and Test-Time Fine-Tuning](https://arxiv.org/abs/2507.15877)
*Simon Ouellette*

Main category: cs.AI

TL;DR: 研究比较了神经程序合成和测试时微调方法在ARC-AGI领域的组合泛化能力，发现执行引导的神经程序合成在合成新颖解决方案方面表现最佳


<details>
  <summary>Details</summary>
Motivation: 在ARC-AGI这个开放世界问题域中评估不同方法的组合泛化能力，该域设计上需要分布外泛化能力才能成功

Method: 在ARC-AGI域上进行受控组合泛化实验，比较神经程序合成方法和测试时微调(TTFT)方法的性能表现

Result: 执行引导的神经程序合成在组合新颖解决方案的能力上超越了所有参考算法；TTFT在ARC-AGI上的成功主要在于激发LLM原本无法直接依赖的分布内知识

Conclusion: 神经程序合成方法在需要组合泛化能力的开放世界问题中表现优异，而测试时微调的效果主要来自于更好地利用已有的分布内知识

Abstract: We run a controlled compositional generalization experiment in the ARC-AGI
domain: an open-world problem domain in which the ability to generalize
out-of-distribution is, by design, an essential characteristic for success. We
compare neural program synthesis and test-time fine-tuning approaches on this
experiment. We find that execution-guided neural program synthesis outperforms
all reference algorithms in its ability to compose novel solutions. Our
empirical findings also suggest that the success of TTFT on ARC-AGI lies mainly
in eliciting in-distribution knowledge that the LLM otherwise fails to rely on
directly.

</details>


### [41] [The Recursive Coherence Principle: A Formal Constraint on Scalable Intelligence, Alignment, and Reasoning Architecture](https://arxiv.org/abs/2507.15880)
*Andy E. Williams*

Main category: cs.AI

TL;DR: 本文提出递归一致性原理(RCP)，认为智能系统要有效扩展必须在递归推理过程中保持结构一致性，并引入功能智能模型(FMI)作为满足RCP的唯一已知操作符，用于解决AI对齐、幻觉等问题


<details>
  <summary>Details</summary>
Motivation: 复杂系统在扩展时容易失去一致性，现有AI系统存在错位、幻觉和不稳定等问题，需要一个基础性原理来确保智能系统在任何规模下都能保持语义一致性和结构对齐

Method: 提出递归一致性原理(RCP)作为基础约束，定义功能智能模型(FMI)作为满足RCP的最小可组合架构，包含内部功能(评估、建模、适应、稳定性、分解、桥接)和外部功能(存储、回忆、系统1和系统2推理)

Result: 证明了缺乏FMI的系统在扩展时会经历递归一致性崩溃，证明RCP能够独特地捕获一致、可对齐智能所需的内部递归动态，为语义一致性建模提供了理论基础

Conclusion: RCP为AI对齐提供了从行为约束转向结构一致性的新路径，FMI架构为构建安全可泛化、鲁棒一致的大规模AI系统提供了理论指导，对AI对齐领域具有重要影响

Abstract: Intelligence-biological, artificial, or collective-requires structural
coherence across recursive reasoning processes to scale effectively. As complex
systems grow, coherence becomes fragile unless a higher-order structure ensures
semantic consistency. This paper introduces the Recursive Coherence Principle
(RCP): a foundational constraint stating that for any reasoning system of order
N, composed of systems operating over conceptual spaces of order N-1, semantic
coherence is preserved only by a recursively evaluable generalization operator
that spans and aligns those lower-order conceptual spaces. Crucially, this
coherence enables structural alignment. Without recursive coherence, no system
can reliably preserve goals, meanings, or reasoning consistency at scale. We
formally define the Functional Model of Intelligence (FMI) as the only known
operator capable of satisfying the RCP at any scale. The FMI is a minimal,
composable architecture with internal functions (evaluation, modeling,
adaptation, stability, decomposition, bridging) and external functions
(storage, recall, System 1 and System 2 reasoning) vital for preserving
semantic structure across inference and coordination layers. We prove that any
system lacking the FMI will experience recursive coherence breakdown as it
scales, arguing that common AI issues like misalignment, hallucination, and
instability are symptoms of this structural coherence loss. Unlike other
foundational principles, RCP uniquely captures the internal, recursive dynamics
needed for coherent, alignable intelligence, modeling semantic coherence under
recursion. This work significantly impacts AI alignment, advocating a shift
from behavioral constraints to structural coherence, and offers a pathway for
safely generalizable, robustly coherent AI at scale.

</details>


### [42] [ADEPTS: A Capability Framework for Human-Centered Agent Design](https://arxiv.org/abs/2507.15885)
*Pierluca D'Oro,Caley Drooff,Joy Chen,Joseph Tighe*

Main category: cs.AI

TL;DR: 论文提出了ADEPTS框架，这是一个面向用户的AI智能体能力框架，旨在为AI智能体开发提供统一指导，弥合技术开发与用户体验之间的差距。


<details>
  <summary>Details</summary>
Motivation: 当前AI智能体开发指导分散且缺乏统一性：UX启发式方法关注界面行为，工程分类法描述内部管道，伦理检查表处理高层治理问题。缺少一个简洁的、面向用户的词汇表来指导团队构建智能体的基本能力。需要一个整体性和跨学科的方法来开发可理解、可控制和可信赖的AI智能体。

Method: 基于六个以人为中心的智能体设计原则，开发了ADEPTS能力框架。该框架定义了一组核心的面向用户的能力，位于技术开发和体验开发的接口处，为AI研究人员、设计师、工程师和政策审查者提供可操作的指导。

Result: ADEPTS框架成功将复杂的AI-UX需求浓缩为一个紧凑的框架，提供了统一的指导语言。该框架补充了现有的框架和分类法，专门针对用户面向的智能体能力进行了定义和组织。

Conclusion: ADEPTS框架有潜力加速用户相关智能体能力的改进，简化利用这些能力的体验设计，并为跟踪和讨论AI智能体开发进展提供共同语言。该框架为AI智能体的人机交互开发提供了重要的理论基础和实践指导。

Abstract: Large language models have paved the way to powerful and flexible AI agents,
assisting humans by increasingly integrating into their daily life. This
flexibility, potential, and growing adoption demands a holistic and
cross-disciplinary approach to developing, monitoring and discussing the
capabilities required for agent-driven user experiences. However, current
guidance on human-centered AI agent development is scattered: UX heuristics
focus on interface behaviors, engineering taxonomies describe internal
pipelines, and ethics checklists address high-level governance. There is no
concise, user-facing vocabulary that tells teams what an agent should
fundamentally be able to do. We introduce ADEPTS, a capability framework
defining a set of core user-facing capabilities to provide unified guidance
around the development of AI agents. ADEPTS is based on six principles for
human-centered agent design, that express the minimal, user-facing capabilities
an AI agent should demonstrate to be understandable, controllable and
trustworthy in everyday use. ADEPTS complements existing frameworks and
taxonomies; differently from them, it sits at the interface between technical
and experience development. By presenting ADEPTS, we aim to condense complex
AI-UX requirements into a compact framework that is actionable guidance for AI
researchers, designers, engineers, and policy reviewers alike. We believe
ADEPTS has the potential of accelerating the improvement of user-relevant agent
capabilities, of easing the design of experiences that take advantage of those
capabilities, and of providing a shared language to track and discuss progress
around the development of AI agents.

</details>


### [43] [Integrating Reason-Based Moral Decision-Making in the Reinforcement Learning Architecture](https://arxiv.org/abs/2507.15895)
*Lisa Dargasz*

Main category: cs.AI

TL;DR: 本研究提出了基于推理的人工道德智能体（RBAMAs），通过扩展强化学习架构来实现基于规范推理的道德决策，使智能体能够学习推理理论并在执行任务时遵守道德义务。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能体（如人形机器人、自动驾驶汽车）即将从实验室原型转向真实世界的自主运行，迫切需要开发能够在执行任务时表现出道德行为的人工道德智能体，这要求解决计算机科学和哲学交叉领域的一系列挑战。

Method: 通过扩展强化学习架构，为智能体配备学习推理理论的能力，使其能够处理道德相关命题并推导出道德义务。智能体通过基于案例的反馈学习推理理论，并调整行为以确保在执行指定任务时符合这些道德义务。

Result: 研究展示了RBAMA的首次实现，并通过初步实验证明了其潜力。该架构能够提高智能体行为的道德可辩护性、道德鲁棒性和道德可信度。

Conclusion: 基于推理的人工道德智能体（RBAMAs）提供了一个具体且可部署的框架，用于开发满足关键伦理要求的人工道德智能体，为人工智能体的道德决策提供了有前景的解决方案。

Abstract: Reinforcement Learning is a machine learning methodology that has
demonstrated strong performance across a variety of tasks. In particular, it
plays a central role in the development of artificial autonomous agents. As
these agents become increasingly capable, market readiness is rapidly
approaching, which means those agents, for example taking the form of humanoid
robots or autonomous cars, are poised to transition from laboratory prototypes
to autonomous operation in real-world environments. This transition raises
concerns leading to specific requirements for these systems - among them, the
requirement that they are designed to behave ethically. Crucially, research
directed toward building agents that fulfill the requirement to behave
ethically - referred to as artificial moral agents(AMAs) - has to address a
range of challenges at the intersection of computer science and philosophy.
This study explores the development of reason-based artificial moral agents
(RBAMAs). RBAMAs are build on an extension of the reinforcement learning
architecture to enable moral decision-making based on sound normative
reasoning, which is achieved by equipping the agent with the capacity to learn
a reason-theory - a theory which enables it to process morally relevant
propositions to derive moral obligations - through case-based feedback. They
are designed such that they adapt their behavior to ensure conformance to these
obligations while they pursue their designated tasks. These features contribute
to the moral justifiability of the their actions, their moral robustness, and
their moral trustworthiness, which proposes the extended architecture as a
concrete and deployable framework for the development of AMAs that fulfills key
ethical desiderata. This study presents a first implementation of an RBAMA and
demonstrates the potential of RBAMAs in initial experiments.

</details>


### [44] [Advancing Responsible Innovation in Agentic AI: A study of Ethical Frameworks for Household Automation](https://arxiv.org/abs/2507.15901)
*Joydeep Chandra,Satyam Kumar Navneet*

Main category: cs.AI

TL;DR: 这篇论文分析了家庭环境中主动型人工智能代理的伦理挑战，重点关注隐私、公平性和用户控制，并为弱势群体提出了设计建议，旨在开发透明、包容和可信的智能家居系统。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能在家庭环境中从被动响应转向主动自主，带来了舒适便利的同时也产生了严重的伦理挑战，特别是对老年人、儿童和神经多样性群体等弱势用户的隐私、偏见和监控风险，需要建立负责任的智能家居系统设计框架。

Method: 采用文献综述方法，分析负责任创新框架、以人为中心的设计原则和治理实践；深入研究弱势用户群体面临的特殊风险；探索通过自然语言处理进行社交媒体分析等数据驱动洞察方法来了解用户需求和伦理关切。

Result: 识别出智能家居系统设计的关键要素：定制化可解释性、细粒度同意机制、强大的覆盖控制功能；提出参与式和包容性方法论；通过NLP等技术分析用户特定需求和伦理关切的有效途径。

Conclusion: 为开发透明、包容和可信的家庭自动化代理AI提供了概念基础和实用建议，强调需要通过负责任的设计实践来平衡技术便利性与伦理安全性，特别是保护弱势群体的权益。

Abstract: The implementation of Artificial Intelligence (AI) in household environments,
especially in the form of proactive autonomous agents, brings about
possibilities of comfort and attention as well as it comes with intra or
extramural ethical challenges. This article analyzes agentic AI and its
applications, focusing on its move from reactive to proactive autonomy,
privacy, fairness and user control. We review responsible innovation
frameworks, human-centered design principles, and governance practices to
distill practical guidance for ethical smart home systems. Vulnerable user
groups such as elderly individuals, children, and neurodivergent who face
higher risks of surveillance, bias, and privacy risks were studied in detail in
context of Agentic AI. Design imperatives are highlighted such as tailored
explainability, granular consent mechanisms, and robust override controls,
supported by participatory and inclusive methodologies. It was also explored
how data-driven insights, including social media analysis via Natural Language
Processing(NLP), can inform specific user needs and ethical concerns. This
survey aims to provide both a conceptual foundation and suggestions for
developing transparent, inclusive, and trustworthy agentic AI in household
automation.

</details>


### [45] [Does More Inference-Time Compute Really Help Robustness?](https://arxiv.org/abs/2507.15974)
*Tong Wu,Chong Xiang,Jiachen T. Wang,Weichen Yu,Chawin Sitawarin,Vikash Sehwag,Prateek Mittal*

Main category: cs.AI

TL;DR: 研究发现推理时计算扩展虽能提升小型开源模型的鲁棒性，但当中间推理步骤对攻击者可见时，会出现反向扩展定律，即更多计算反而降低模型鲁棒性，提醒在安全敏感应用中需谨慎权衡此类trade-off。


<details>
  <summary>Details</summary>
Motivation: 先前工作假设中间推理步骤对攻击者隐藏，但这一假设在实际部署中可能不成立。作者希望探索当这一假设被放松时，推理时计算扩展对模型鲁棒性的真实影响，并识别潜在的安全风险。

Method: 使用预算强制策略在小型开源模型上验证推理时扩展的效果；通过放松"中间推理步骤隐藏"的假设，研究当推理步骤对攻击者可见时的鲁棒性变化；分析工具集成推理和高级推理提取攻击等实际攻击场景。

Result: 验证了小型开源模型（如DeepSeek R1、Qwen3、Phi-reasoning）也能从推理时扩展中受益；发现了反向扩展定律：当中间推理步骤可见时，增加推理时计算会持续降低模型鲁棒性；识别了隐藏推理链模型在实际应用中仍存在的漏洞。

Conclusion: 推理时扩展的鲁棒性收益严重依赖于对抗设置和部署环境。在安全敏感的实际应用中部署推理时扩展之前，从业者需要仔细权衡这些微妙的trade-off，不能盲目假设中间推理步骤始终对攻击者隐藏。

Abstract: Recently, Zaremba et al. demonstrated that increasing inference-time
computation improves robustness in large proprietary reasoning LLMs. In this
paper, we first show that smaller-scale, open-source models (e.g., DeepSeek R1,
Qwen3, Phi-reasoning) can also benefit from inference-time scaling using a
simple budget forcing strategy. More importantly, we reveal and critically
examine an implicit assumption in prior work: intermediate reasoning steps are
hidden from adversaries. By relaxing this assumption, we identify an important
security risk, intuitively motivated and empirically verified as an inverse
scaling law: if intermediate reasoning steps become explicitly accessible,
increased inference-time computation consistently reduces model robustness.
Finally, we discuss practical scenarios where models with hidden reasoning
chains are still vulnerable to attacks, such as models with tool-integrated
reasoning and advanced reasoning extraction attacks. Our findings collectively
demonstrate that the robustness benefits of inference-time scaling depend
heavily on the adversarial setting and deployment context. We urge
practitioners to carefully weigh these subtle trade-offs before applying
inference-time scaling in security-sensitive, real-world applications.

</details>


### [46] [Micromobility Flow Prediction: A Bike Sharing Station-level Study via Multi-level Spatial-Temporal Attention Neural Network](https://arxiv.org/abs/2507.16020)
*Xi Yang,Jiachen Wang,Song Han,Suining He*

Main category: cs.AI

TL;DR: 本文提出BikeMAN神经网络模型，通过多级时空注意力机制预测整个共享单车系统中所有站点的交通流量，在纽约市超过700个站点的实验中展现了高准确性。


<details>
  <summary>Details</summary>
Motivation: 城市微出行资源如共享单车系统面临站点级需求供给不平衡的问题，导致系统维护困难。现有的单车交通预测方法难以处理共享单车系统的时空复杂性，且难以对整个系统的大量站点进行站点级预测。

Method: 提出BikeMAN多级时空注意力神经网络，包含编码器和解码器结构。采用两种注意力机制：一种表示系统中单车站点特征之间的空间相关性，另一种描述单车站点交通的时间特征。

Result: 在纽约市共享单车系统（超过700个站点，1000万次出行数据）上的实验研究表明，该网络在预测城市中所有站点的单车站点交通方面显示出高准确性。

Conclusion: BikeMAN网络成功解决了整个共享单车系统站点级交通预测的挑战，通过多级时空注意力机制有效捕获了系统的空间和时间复杂性，为共享单车系统的高效管理提供了有效的预测工具。

Abstract: Efficient use of urban micromobility resources such as bike sharing is
challenging due to the unbalanced station-level demand and supply, which causes
the maintenance of the bike sharing systems painstaking. Prior efforts have
been made on accurate prediction of bike traffics, i.e., demand/pick-up and
return/drop-off, to achieve system efficiency. However, bike station-level
traffic prediction is difficult because of the spatial-temporal complexity of
bike sharing systems. Moreover, such level of prediction over entire bike
sharing systems is also challenging due to the large number of bike stations.
To fill this gap, we propose BikeMAN, a multi-level spatio-temporal attention
neural network to predict station-level bike traffic for entire bike sharing
systems. The proposed network consists of an encoder and a decoder with an
attention mechanism representing the spatial correlation between features of
bike stations in the system and another attention mechanism describing the
temporal characteristic of bike station traffic. Through experimental study on
over 10 millions trips of bike sharing systems (> 700 stations) of New York
City, our network showed high accuracy in predicting the bike station traffic
of all stations in the city.

</details>


### [47] [From Logic to Language: A Trust Index for Problem Solving with LLMs](https://arxiv.org/abs/2507.16028)
*Tehseen Rug,Felix Böhmer,Tessa Pfattheicher*

Main category: cs.AI

TL;DR: 本文提出了一个统一框架来理解和对比传统计算与大语言模型的问题求解范式，引入向量值信任指数Q来评估自然语言解决方案的质量，并提出了双语义熵和情感效价两个统计质量维度。


<details>
  <summary>Details</summary>
Motivation: 传统计算基于形式逻辑系统，擅长处理明确规则的问题，但对于具有模糊性、动态环境和主观语境的人类问题却无能为力。大语言模型的出现使计算系统能够通过自然语言处理这些以前无法触及的领域，因此需要一个统一框架来理解这两种问题求解范式的差异。

Method: 作者定义并划分了形式语言与自然语言可解决的问题空间，引入向量值信任指数Q来反映解决方案质量，区分形式解决方案的二元正确性和自然语言解决方案的连续适当性谱。提出两个统计质量维度：标准化双语义熵（衡量LLM答案的鲁棒性和概念多样性）和情感效价（将主观评价映射为可量化指标）。

Result: 建立了一个能够区分传统计算和LLM问题求解能力的理论框架，提供了评估自然语言解决方案质量的量化方法，包括处理模糊性、主观性和歧义性的评估指标。

Conclusion: 本研究为理解LLM时代问题求解的能力、局限性和固有特性提供了更严格的理论基础，为评估和优化自然语言计算系统提供了新的分析工具和质量度量标准。

Abstract: Classical computation, grounded in formal, logical systems, has been the
engine of technological progress for decades, excelling at problems that can be
described with unambiguous rules. This paradigm, however, leaves a vast ocean
of human problems -- those characterized by ambiguity, dynamic environments,
and subjective context -- largely untouched. The advent of Large Language
Models (LLMs) represents a fundamental shift, enabling computational systems to
engage with this previously inaccessible domain using natural language. This
paper introduces a unified framework to understand and contrast these
problem-solving paradigms. We define and delineate the problem spaces
addressable by formal languages versus natural language. While solutions to the
former problem class can be evaluated using binary quality measures, the latter
requires a much more nuanced definition of approximate solution space taking
into account the vagueness, subjectivity and ambiguity inherent to natural
language. We therefore introduce a vector-valued trust index Q, which reflects
solution quality and distinguishes the binary correctness of formal solutions
from the continuous adequacy spectrum characteristic of natural language
solutions. Within this framework, we propose two statistical quality
dimensions. Normalized bi-semantic entropy measures robustness and conceptual
diversity of LLM answers given semantic variation in problem formulations.
Emotional valence maps subjective valuation of a solution to a quantifiable
metric that can be maximized by invoking statistical measures. The concepts
introduced in this work will provide a more rigorous understanding of the
capabilities, limitations, and inherent nature of problem-solving in the age of
LLMs.

</details>


### [48] [A Unifying Framework for Semiring-Based Constraint Logic Programming With Negation (full version)](https://arxiv.org/abs/2507.16067)
*Jeroen Spaans,Jesse Heyninck*

Main category: cs.AI

TL;DR: 本文提出了一个统一的约束逻辑编程扩展框架，支持体部否定，并使用半环和近似不动点理论提供语义


<details>
  <summary>Details</summary>
Motivation: 现有的约束逻辑编程扩展（如模糊约束满足、不确定性、否定等）都没有研究允许体部否定的子句，需要一个统一框架来整合这些扩展并支持更具表达力的语言

Method: 使用半环作为统一抽象来泛化各种扩展，采用近似不动点理论框架为支持体部否定的约束逻辑程序提供语义，并详细分析半环性质对语义的影响

Result: 成功构建了一个统一框架，该框架能够捕获现有方法并允许使用更具表达力的语言进行扩展，为带有体部否定的约束逻辑程序提供了完整的语义定义

Conclusion: 提供了一个统一的约束逻辑编程框架，不仅整合了现有的各种扩展方法，还支持体部否定，从而实现了更强的表达能力和更广泛的应用前景

Abstract: Constraint Logic Programming (CLP) is a logic programming formalism used to
solve problems requiring the consideration of constraints, like resource
allocation and automated planning and scheduling. It has previously been
extended in various directions, for example to support fuzzy constraint
satisfaction, uncertainty, or negation, with different notions of semiring
being used as a unifying abstraction for these generalizations. None of these
extensions have studied clauses with negation allowed in the body. We
investigate an extension of CLP which unifies many of these extensions and
allows negation in the body. We provide semantics for such programs, using the
framework of approximation fixpoint theory, and give a detailed overview of the
impacts of properties of the semirings on the resulting semantics. As such, we
provide a unifying framework that captures existing approaches and allows
extending them with a more expressive language.

</details>


### [49] [Expert-Guided LLM Reasoning for Battery Discovery: From AI-Driven Hypothesis to Synthesis and Characterization](https://arxiv.org/abs/2507.16110)
*Shengchao Liu,Hannan Xu,Yan Ai,Huanxin Li,Yoshua Bengio,Harry Guo*

Main category: cs.AI

TL;DR: 研究者开发了ChatBattery框架，利用大语言模型的链式思维推理能力进行电池材料发现，成功设计、合成并表征了三种新型锂离子电池正极材料，相比现有材料实现了显著的容量提升。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在数学和编程问题上展现出强大的推理能力，但在特定领域应用（如电池发现）中的潜力尚未得到充分探索。研究者受到"推理类似于引导搜索"这一理念启发，希望将领域知识整合到LLM中以指导材料设计中的有效推理。

Method: 提出ChatBattery智能框架，该框架整合领域知识来引导大语言模型在材料设计中进行更有效的推理。利用链式思维（CoT）技术解决复杂的电池材料发现问题，形成从设计到合成再到表征的完整AI驱动循环。

Result: 成功识别、合成并表征了三种新型锂离子电池正极材料，相比广泛使用的正极材料LiNi0.8Mn0.1Co0.1O2 (NMC811)，分别实现了28.8%、25.2%和18.5%的实际容量改善。

Conclusion: ChatBattery为基于LLM驱动和推理的电池材料发明开辟了新路径，展示了AI驱动推理在革命性材料发现中的变革潜力。这个完整的AI驱动循环证明了人工智能在材料科学领域的巨大应用前景。

Abstract: Large language models (LLMs) leverage chain-of-thought (CoT) techniques to
tackle complex problems, representing a transformative breakthrough in
artificial intelligence (AI). However, their reasoning capabilities have
primarily been demonstrated in solving math and coding problems, leaving their
potential for domain-specific applications-such as battery discovery-largely
unexplored. Inspired by the idea that reasoning mirrors a form of guided
search, we introduce ChatBattery, a novel agentic framework that integrates
domain knowledge to steer LLMs toward more effective reasoning in materials
design. Using ChatBattery, we successfully identify, synthesize, and
characterize three novel lithium-ion battery cathode materials, which achieve
practical capacity improvements of 28.8%, 25.2%, and 18.5%, respectively, over
the widely used cathode material, LiNi0.8Mn0.1Co0.1O2 (NMC811). Beyond this
discovery, ChatBattery paves a new path by showing a successful LLM-driven and
reasoning-based platform for battery materials invention. This complete
AI-driven cycle-from design to synthesis to characterization-demonstrates the
transformative potential of AI-driven reasoning in revolutionizing materials
discovery.

</details>


### [50] [Distilled Large Language Model in Confidential Computing Environment for System-on-Chip Design](https://arxiv.org/abs/2507.16226)
*Dong Ben,Hui Feng,Qian Wang*

Main category: cs.AI

TL;DR: 本文研究了在可信执行环境(TEE)中部署大语言模型用于电路设计任务的可行性，通过Intel TDX技术评估了不同模型配置的性能表现


<details>
  <summary>Details</summary>
Motivation: 大语言模型在电路设计中的应用日益增多，但训练数据和模型作为机密知识产权需要保护。现有TEE实现无法有效支持资源密集型的LLM，因此需要评估在机密计算环境中部署LLM的可行性和性能

Method: 构建了三种实验环境(基于TEE、仅CPU、CPU-GPU混合)，使用Intel Trust Domain Extensions (TDX)技术，在不同环境下评估多种LLM模型的性能表现，以每秒处理token数作为评估指标，并使用SoC设计任务测试台进行验证

Result: 蒸馏模型(如DeepSeek)由于参数较少在性能上表现最佳，适合资源受限设备；量化模型(4位和8位量化)相比FP16模型性能提升达3倍；对于参数较少的模型如DeepSeek-r1-1.5B，TDX实现在安全环境中的计算性能超过了CPU版本

Conclusion: 研究证明了在资源受限系统上为半导体CAD应用高效部署轻量级LLM的潜力，为在保护知识产权的同时实现LLM在电路设计中的应用提供了可行的解决方案

Abstract: Large Language Models (LLMs) are increasingly used in circuit design tasks
and have typically undergone multiple rounds of training. Both the trained
models and their associated training data are considered confidential
intellectual property (IP) and must be protected from exposure. Confidential
Computing offers a promising solution to protect data and models through
Trusted Execution Environments (TEEs). However, existing TEE implementations
are not designed to support the resource-intensive nature of LLMs efficiently.
In this work, we first present a comprehensive evaluation of the LLMs within a
TEE-enabled confidential computing environment, specifically utilizing Intel
Trust Domain Extensions (TDX). We constructed experiments on three
environments: TEE-based, CPU-only, and CPU-GPU hybrid implementations, and
evaluated their performance in terms of tokens per second.
  Our first observation is that distilled models, i.e., DeepSeek, surpass other
models in performance due to their smaller parameters, making them suitable for
resource-constrained devices. Also, in the quantized models such as 4-bit
quantization (Q4) and 8-bit quantization (Q8), we observed a performance gain
of up to 3x compared to FP16 models. Our findings indicate that for fewer
parameter sets, such as DeepSeek-r1-1.5B, the TDX implementation outperforms
the CPU version in executing computations within a secure environment. We
further validate the results using a testbench designed for SoC design tasks.
These validations demonstrate the potential of efficiently deploying
lightweight LLMs on resource-constrained systems for semiconductor CAD
applications.

</details>


### [51] [TaxCalcBench: Evaluating Frontier Models on the Tax Calculation Task](https://arxiv.org/abs/2507.16126)
*Michael R. Bock,Kara Molisee,Zachary Ozer,Sumit Shah*

Main category: cs.AI

TL;DR: 研究者提出了TaxCalcBench基准测试，用于评估AI模型计算个人所得税的能力。结果显示最先进的模型在简化样本集上的成功率不到三分之一，主要错误包括税表误用、计算错误和资格判断失误。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏评估AI模型处理复杂税务计算任务能力的基准。美国个人所得税计算需要理解大量英文文本并进行精确计算，是一个具有挑战性的现实应用场景，需要专门的评估框架来测试模型在这一领域的表现。

Method: 提出TaxCalcBench基准测试，该基准为模型提供计算个人所得税申报表所需的全部信息，然后评估模型计算联邦所得税的准确性。通过分析模型在税表使用、税务计算和资格确定方面的表现来评估其能力。

Result: 最先进的模型在简化样本集上计算联邦所得税申报表的成功率低于三分之一。模型主要存在三类错误：1) 税表误用；2) 税务计算错误；3) 资格确定错误。这表明当前模型在处理复杂税务计算任务方面存在显著局限性。

Conclusion: 当前的大语言模型还无法胜任个人所得税计算任务。研究发现模型在税表使用、数值计算和资格判断等关键环节都存在系统性错误，表明需要额外的基础设施和改进才能将LLMs有效应用于个人所得税计算领域。

Abstract: Can AI file your taxes? Not yet. Calculating US personal income taxes is a
task that requires building an understanding of vast amounts of English text
and using that knowledge to carefully compute results. We propose TaxCalcBench,
a benchmark for determining models' abilities to calculate personal income tax
returns given all of the necessary information. Our experiment shows that
state-of-the-art models succeed in calculating less than a third of federal
income tax returns even on this simplified sample set. Our analysis concludes
that models consistently misuse tax tables, make errors in tax calculation, and
incorrectly determine eligibility. Our findings point to the need for
additional infrastructure to apply LLMs to the personal income tax calculation
task.

</details>


### [52] [SpiroLLM: Finetuning Pretrained LLMs to Understand Spirogram Time Series with Clinical Validation in COPD Reporting](https://arxiv.org/abs/2507.16145)
*Shuhao Mei,Yongchao Long,Shan Cao,Xiaobo Han,Shijia Geng,Jinbo Sun,Yuxi Zhou,Shenda Hong*

Main category: cs.AI

TL;DR: 该研究提出了SpiroLLM，这是首个能够理解肺功能图的多模态大语言模型，用于慢性阻塞性肺病(COPD)诊断。模型通过SpiroEncoder提取呼吸曲线特征，使用SpiroProjector将其与数值数据对齐，最终生成综合诊断报告，在23.4万人的UK Biobank队列中达到0.8980的AUROC。


<details>
  <summary>Details</summary>
Motivation: 现有的COPD诊断AI模型仅能输出分类结果而无法提供诊断依据，而当前的大语言模型无法理解肺功能图，这严重限制了临床信任度和应用。需要开发一个既能理解肺功能图又能提供可解释诊断的模型。

Method: 提出SpiroLLM多模态大语言模型，包含三个核心组件：1) SpiroEncoder用于从呼吸曲线中提取形态学特征；2) SpiroProjector将形态学特征与肺功能测试数值在统一潜在空间中对齐；3) 大语言模型生成综合诊断报告。使用UK Biobank的234,028个个体数据进行训练和验证。

Result: SpiroLLM在COPD诊断中达到0.8980的AUROC（95% CI: 0.8820-0.9132）。在缺失核心数据的鲁棒性测试中，模型保持100%的有效响应率，远超仅文本模型的13.4%，展现了多模态设计的优越性。

Conclusion: 这项工作展示了生理信号与大语言模型深度融合的巨大潜力，为下一代可解释且可靠的临床决策支持工具建立了新的范式。SpiroLLM作为首个能理解肺功能图的多模态大语言模型，在COPD诊断中表现出色且具有良好的鲁棒性。

Abstract: Chronic Obstructive Pulmonary Disease (COPD), a major chronic respiratory
disease with persistent airflow limitation, is a leading global cause of
disability and mortality. Respiratory spirogram time series, routinely
collected during pulmonary function tests (PFTs), play a critical role in the
early detection of repsiratory diseases and in monitoring lung function over
time. However, most current AI models for COPD diagnosis are limited to
outputting classification results without providing a rationale for their
diagnostic process, while current Large Language Models (LLMs) cannot
understand spirograms yet, which severely limits their clinical trust and
adoption. To tackle this challenge, we leverage a cohort of 234,028 individuals
from the UK Biobank (UKB) to propose SpiroLLM, the first multimodal large
language model that can understand spirogram. The model extracts morphological
features from respiratory curves via a SpiroEncoder and aligns them with PFT
numerical values in a unified latent space using a SpiroProjector, ultimately
empowering a large language model to generate a comprehensive diagnostic
report. Experimental results confirm that SpiroLLM achieved a diagnostic AUROC
of 0.8980 (95% CI: 0.8820-0.9132). In a robustness test with missing core data,
it maintained a 100% valid response rate, far surpassing the 13.4% of a
text-only model and showcasing the superiority of its multimodal design. This
work demonstrates the substantial potential of deeply fusing physiological
signals with large language models, establishing a new paradigm for the next
generation of interpretable and reliable clinical decision support tools.

</details>


### [53] [Emergent Cognitive Convergence via Implementation: A Structured Loop Reflecting Four Theories of Mind (A Position Paper)](https://arxiv.org/abs/2507.16184)
*Myung Ho Kim*

Main category: cs.AI

TL;DR: 本文发现了一个名为Agentic Flow的AI智能体架构意外地在结构上收敛了四个重要的心智理论（Kahneman的双系统理论、Friston的预测处理、Minsky的心智社会和Clark的延展心智），并提出了PEACE元架构来描述这种设计层面的规律性。


<details>
  <summary>Details</summary>
Motivation: 为了解决大语言模型（LLMs）的局限性，设计实用的AI智能体架构时，意外发现该架构在结构上与多个认知理论产生了收敛，这促使研究者探索实现过程中如何自然涌现出认知理论的潜在结构回声。

Method: 设计了包含检索、认知、控制、记忆和行动五个相互依赖模块的Agentic Flow架构，采用循环认知回路。通过与基线LLM智能体在多步推理任务上的对比实验来评估性能，并提出PEACE元架构来描述观察到的设计规律性。

Result: 结构化智能体在多步推理任务中达到95.8%的成功率并表现出强约束遵循能力，而基线系统成功率仅为62.3%。实验结果展示了理论结构如何通过实际设计选择而非自上而下的理论构建自然涌现。

Conclusion: 这是一篇立场论文，探索性地反思了实现过程如何能够显现认知理论的潜在结构回声。PEACE提供了理解由现实世界实现需求塑造的架构的共享词汇，但并不主张理论统一，而是说明了实际设计中理论结构的自然涌现。

Abstract: We report the discovery of a structural convergence across four influential
theories of mind: Kahneman's dual-system theory, Friston's predictive
processing, Minsky's society of mind, and Clark's extended mind-emerging
unintentionally within a practical AI agent architecture called Agentic Flow.
Designed to address limitations in large language models (LLMs), Agentic Flow
comprises five interdependent modules such as Retrieval, Cognition, Control,
Memory, and Action arranged in a recurrent cognitive loop. Although originally
inspired only by Minsky and Clark, the system's structure retrospectively
aligns with computational motifs found in all four theories, including
predictive modeling, associative recall, and error-sensitive control.
  To assess this convergence, we conducted comparative experiments with
baseline LLM agents on multi-step reasoning tasks. The structured agent
achieved 95.8% task success and exhibited strong constraint adherence, while
the baseline system succeeded 62.3% of the time. These results were not aimed
at proving superiority, but at illustrating how theoretical structures may
emerge through practical design choices rather than top-down theory.
  We introduce PEACE as a descriptive meta-architecture that captures
design-level regularities observed in Agentic Flow. Not intended as a new
theory, PEACE provides a shared vocabulary for understanding architectures
shaped by real-world implementation demands. This paper should be read as a
position paper - an exploratory reflection on how implementation can surface
latent structural echoes of cognitive theory, without asserting theoretical
unification.

</details>


### [54] [CHIMERA: Compressed Hybrid Intelligence for Twin-Model Enhanced Multi-Agent Deep Reinforcement Learning for Multi-Functional RIS-Assisted Space-Air-Ground Integrated Networks](https://arxiv.org/abs/2507.16204)
*Li-Hsiang Shen,Jyun-Jhe Huang*

Main category: cs.AI

TL;DR: 本文提出了一种由多功能可重构智能表面(MF-RIS)增强的空-天-地一体化网络架构，通过联合优化MF-RIS参数和网络参数来最大化长期能效，并设计了CHIMERA深度强化学习框架来解决复杂的非凸优化问题。


<details>
  <summary>Details</summary>
Motivation: 解决低轨卫星在阴影区域的能量短缺问题，同时考虑空-天-地一体化网络中通信和计算的能耗，需要一种能够同时反射、放大和收集无线能量的智能表面技术来提升网络的长期能效。

Method: 提出多功能可重构智能表面(MF-RIS)增强的空-天-地一体化网络架构，建立联合优化问题包括MF-RIS参数(信号放大、相移、能量收集比例、有源元件选择)和网络参数(波束成形、高空平台部署、用户关联、计算能力)；设计CHIMERA框架，集成语义状态-动作压缩和参数化共享的混合强化学习来高效探索复杂动作空间。

Result: 仿真结果表明，CHIMERA方案在能效方面显著优于传统基准方法，包括固定配置或非收集能量的MF-RIS、传统RIS、无RIS情况，以及集中式和多智能体深度强化学习基准；所提出的SAGIN-MF-RIS架构通过互补覆盖实现了优越的能效性能，相比单独的卫星、空中或地面部署具有显著优势。

Conclusion: 多功能可重构智能表面增强的空-天-地一体化网络架构能够有效解决能量短缺问题并显著提升网络能效，CHIMERA深度强化学习框架为解决复杂的混合离散-连续非凸优化问题提供了有效途径，该架构的互补覆盖特性使其在能效性能方面优于单一网络部署方案。

Abstract: A space-air-ground integrated network (SAGIN) architecture is proposed,
empowered by multi-functional reconfigurable intelligent surfaces (MF-RIS)
capable of simultaneously reflecting, amplifying, and harvesting wireless
energy. The MF-RIS plays a pivotal role in addressing the energy shortages of
low-Earth orbit (LEO) satellites operating in shadowed regions, while
explicitly accounting for both communication and computing energy consumption
across the SAGIN nodes. To maximize the long-term energy efficiency (EE), we
formulate a joint optimization problem over the MF-RIS parameters, including
signal amplification, phase-shifts, energy harvesting ratio, and active element
selection as well as the SAGIN parameters of beamforming vectors, high-altitude
platform station (HAPS) deployment, user association, and computing capability.
The formulated problem is highly non-convex and non-linear and contains mixed
discrete-continuous parameters. To tackle this, we conceive a compressed hybrid
intelligence for twin-model enhanced multi-agent deep reinforcement learning
(CHIMERA) framework, which integrates semantic state-action compression and
parametrized sharing under hybrid reinforcement learning to efficiently explore
suitable complex actions. The simulation results have demonstrated that the
proposed CHIMERA scheme substantially outperforms the conventional benchmarks,
including fixed-configuration or non-harvesting MF-RIS, traditional RIS, and
no-RIS cases, as well as centralized and multi-agent deep reinforcement
learning baselines in terms of the highest EE. Moreover, the proposed
SAGIN-MF-RIS architecture achieves superior EE performance due to its
complementary coverage, offering notable advantages over either standalone
satellite, aerial, or ground-only deployments.

</details>


### [55] [Voice-based AI Agents: Filling the Economic Gaps in Digital Health Delivery](https://arxiv.org/abs/2507.16229)
*Bo Wen,Chen Wang,Qiwei Han,Raquel Norel,Julia Liu,Thaddeus Stappenbeck,Jeffrey L. Rogers*

Main category: cs.AI

TL;DR: 本文探讨了基于语音的AI智能体在医疗保健中的应用，通过Agent PULSE系统的试点研究，证明了AI语音助手在预防护理和患者监测方面的巨大潜力，能够有效降低成本并提高医疗服务的可及性。


<details>
  <summary>Details</summary>
Motivation: 解决数字医疗服务中的经济和可及性差距，特别是为服务不足的人群提供成本有效的医疗保健服务，通过AI语音智能体弥补人工干预在经济上不可行的领域。

Method: 开发并试点测试Agent PULSE系统（患者理解和联络支持引擎），这是IBM研究院、克利夫兰诊所基金会和莫尔豪斯医学院的合作项目。建立经济模型分析AI智能体的成本效益，并对33名炎症性肠病患者进行试点研究。

Result: 70%的患者接受AI驱动的监测，37%的患者更偏好AI监测而非传统方式。成本效用分析显示在常规监测任务方面具有巨大的潜在节约。技术挑战包括实时对话AI处理、与医疗系统集成和隐私合规等方面。

Conclusion: 基于语音的AI智能体不仅能提高医疗保健的可扩展性和效率，还能改善患者参与度和可及性。通过解决当前限制并将AI开发与伦理和监管框架保持一致，语音AI智能体可以成为公平、可持续数字医疗解决方案的关键入口点。

Abstract: The integration of voice-based AI agents in healthcare presents a
transformative opportunity to bridge economic and accessibility gaps in digital
health delivery. This paper explores the role of large language model
(LLM)-powered voice assistants in enhancing preventive care and continuous
patient monitoring, particularly in underserved populations. Drawing insights
from the development and pilot study of Agent PULSE (Patient Understanding and
Liaison Support Engine) -- a collaborative initiative between IBM Research,
Cleveland Clinic Foundation, and Morehouse School of Medicine -- we present an
economic model demonstrating how AI agents can provide cost-effective
healthcare services where human intervention is economically unfeasible. Our
pilot study with 33 inflammatory bowel disease patients revealed that 70\%
expressed acceptance of AI-driven monitoring, with 37\% preferring it over
traditional modalities. Technical challenges, including real-time
conversational AI processing, integration with healthcare systems, and privacy
compliance, are analyzed alongside policy considerations surrounding
regulation, bias mitigation, and patient autonomy. Our findings suggest that
AI-driven voice agents not only enhance healthcare scalability and efficiency
but also improve patient engagement and accessibility. For healthcare
executives, our cost-utility analysis demonstrates huge potential savings for
routine monitoring tasks, while technologists can leverage our framework to
prioritize improvements yielding the highest patient impact. By addressing
current limitations and aligning AI development with ethical and regulatory
frameworks, voice-based AI agents can serve as a critical entry point for
equitable, sustainable digital healthcare solutions.

</details>


### [56] [LLM-Driven Collaborative Model for Untangling Commits via Explicit and Implicit Dependency Reasoning](https://arxiv.org/abs/2507.16395)
*Bo Hou,Xin Tan,Kai Zheng,Fang Liu,Yinghao Zhu,Li Zhang*

Main category: cs.AI

TL;DR: 本文提出ColaUntangle，一个基于大语言模型多智能体协作的代码提交拆分框架，通过显式和隐式依赖建模显著提升了混合提交的自动拆分性能。


<details>
  <summary>Details</summary>
Motivation: 开发者经常产生混合了无关变更的纠缠提交，这会负面影响代码审查和维护。现有的基于规则、特征或图的提交拆分方法依赖浅层信号，无法有效区分显式依赖（如控制/数据流）和隐式依赖（如语义或概念关系）。

Method: 提出ColaUntangle协作咨询框架，采用多智能体架构：一个智能体专门处理显式依赖，另一个处理隐式依赖，审查智能体通过迭代咨询综合两者观点。构建多版本程序依赖图(delta-PDG)来捕获显式和隐式上下文信息，使智能体能够在符号和语义层面推理代码关系。

Result: 在两个广泛使用的数据集（1,612个C#和14k个Java纠缠提交）上进行评估，ColaUntangle超越了最佳基线方法，在C#数据集上提升44%，在Java数据集上提升100%。

Conclusion: 实验结果突出了基于大语言模型的协作框架在推进自动化提交拆分任务方面的潜力，证明了多智能体协作和显式/隐式依赖建模的有效性。

Abstract: Atomic commits, each of which addresses a single development concern, are a
best practice in software development. However, developers frequently produce
tangled commits that mix unrelated changes due to practical constraints or
unclear boundaries, negatively impacting code review and maintenance. Although
prior commit untangling approaches: rule-based, feature-based, or graph-based,
have made progress, they often rely on shallow signals and fail to distinguish
between explicit dependencies (e.g., control/data flow) and implicit ones
(e.g., semantic or conceptual relationships). In this paper, we propose
ColaUntangle, a new collaborative consultation framework for commit untangling
that models both explicit and implicit dependencies among code changes.
ColaUntangle integrates Large Language Model (LLM)-driven agents in a
multi-agent architecture: one agent specializes in explicit dependencies,
another in implicit ones, and a reviewer agent synthesizes their perspectives
through iterative consultation. To capture explicit and implicit contextual
information, we construct multi-version Program Dependency Graphs (delta-PDG),
enabling agents to reason over code relationships with both symbolic and
semantic depth. We evaluate ColaUntangle on two widely-used datasets (1,612 C#
and 14k Java tangled commits). Experimental results show that ColaUntangle
outperforms the best-performing baseline, achieving an improvement of 44% on
the C# dataset and 100% on the Java dataset. These findings highlight the
potential of LLM-based collaborative frameworks for advancing automated commit
untangling tasks.

</details>


### [57] [ResearcherBench: Evaluating Deep AI Research Systems on the Frontiers of Scientific Inquiry](https://arxiv.org/abs/2507.16280)
*Tianze Xu,Pengrui Lu,Lyumanshan Ye,Xiangkun Hu,Pengfei Liu*

Main category: cs.AI

TL;DR: 该论文提出了ResearcherBench，这是首个专门评估深度AI研究系统(DARS)在前沿AI科学问题上能力的基准测试，通过65个真实科研场景问题和双重评估框架，发现OpenAI Deep Research和Gemini Deep Research在开放式咨询问题上表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要评估AI系统作为网络检索和报告生成代理的能力，忽视了其在科学研究前沿发现新见解的潜力。为填补这一空白，需要一个专门评估深度AI研究系统在前沿AI科学问题上能力的基准测试。

Method: 构建包含65个研究问题的数据集，这些问题来自实验室讨论和访谈等真实科研场景，涵盖35个不同AI主题，分为技术细节、文献综述和开放咨询三类。采用双重评估框架：评分标准评估（使用专家设计的标准评估洞察质量）和事实评估（测量引用准确性和覆盖度）。

Result: 评估了几个领先的商业DARS和基线系统，结果显示OpenAI Deep Research和Gemini Deep Research显著优于其他系统，特别是在开放式咨询问题上表现突出。这些能力代表了向AI自我改进迈出的重要一步。

Conclusion: ResearcherBench为促进下一代AI研究助手的发展提供了标准化平台，有望为AI研究评估带来新视角，促进科学合作的新模式。论文开源了该基准测试以推动相关研究发展。

Abstract: The emergence of deep research systems presents significant capabilities in
problem-solving, extending from basic queries to sophisticated research tasks.
However, existing benchmarks primarily evaluate these systems as agents for web
retrieval and report generation, overlooking their potential to discover novel
insights on the frontiers of scientific research. To address this gap, we
introduce ResearcherBench, the first benchmark focused on evaluating the
capabilities of these advanced, agentic systems - which we refer to as Deep AI
Research Systems (DARS) - on frontier AI scientific questions. We compiled a
dataset of 65 research questions expertly selected from real-world scientific
scenarios such as laboratory discussions and interviews, spanning 35 different
AI subjects and categorized into three types: technical details, literature
review, and open consulting. Our dual evaluation framework combines rubric
assessment, which uses expert-designed criteria to evaluate insight quality,
with factual assessment, which measures citation accuracy (faithfulness) and
coverage (groundedness). We evaluated several leading commercial DARS and
baseline systems. Results show that OpenAI Deep Research and Gemini Deep
Research significantly outperform other systems, with particular strength in
open-ended consulting questions. Such capabilities represent a meaningful step
toward AI self-improvement, aligning with the vision of ASI for AI. We
open-source ResearcherBench to provide a standardized platform for promoting
the development of next-generation AI research assistants, hoping to foster a
new perspective in AI research evaluation for a novel pattern of scientific
collaboration: https://github.com/GAIR-NLP/ResearcherBench.

</details>


### [58] [ACT: Bridging the Gap in Code Translation through Synthetic Data Generation & Adaptive Training](https://arxiv.org/abs/2507.16478)
*Shreya Saxena,Siva Prasad,Zishan Ahmad,Vishal Vaddina*

Main category: cs.AI

TL;DR: 本文提出了ACT框架，通过自动化流水线对开源大语言模型进行微调，以提升代码翻译能力，缩小开源模型与闭源解决方案之间的性能差距。


<details>
  <summary>Details</summary>
Motivation: 传统的自动化代码翻译方法依赖手工制作的转换规则，缺乏灵活性和可扩展性；而先进的语言模型通常基于专有API实现，存在数据安全和依赖性问题。因此需要一个能够提升开源大语言模型代码翻译能力的框架。

Method: 提出ACT（Auto-Train for Code Translation）框架，包含三个核心模块：1）合成数据生成模块，从初始代码样本构建高质量数据集并结合单元测试；2）评估框架，采用执行级检查全面评估翻译质量；3）控制器模块，动态调整超参数，协调迭代数据生成和微调过程。

Result: ACT能够持续提升开源模型的效果，为企业和开发者提供安全可靠的替代方案。将数据生成流水线应用到工业规模的迁移项目中，显著提高了开发者的工作效率。

Conclusion: ACT框架成功缩小了开源模型与闭源解决方案之间的性能差距，通过智能化的训练流水线管理和高质量的合成数据生成，为代码翻译任务提供了一个安全、可靠且高效的开源解决方案。

Abstract: Code translation is a crucial process in software development and migration
projects, enabling interoperability between different programming languages and
enhancing software adaptability and thus longevity. Traditional automated
translation methods rely heavily on handcrafted transformation rules, which
often lack flexibility and scalability. Meanwhile, advanced language models
present promising alternatives but are often limited by proprietary, API-based
implementations that raise concerns over data security and reliance. In this
paper, we present Auto-Train for Code Translation (ACT), an innovative
framework that aims to improve code translation capabilities by enabling
in-house finetuning of open-source Large Language Models (LLMs). ACT's
automated pipeline significantly boosts the performance of these models,
narrowing the gap between open-source accessibility and the high performance of
closed-source solutions. Central to ACT is its synthetic data generation
module, which builds extensive, high-quality datasets from initial code
samples, incorporating unit tests to ensure functional accuracy and diversity.
ACT's evaluation framework incorporates execution-level checks, offering a
comprehensive assessment of translation quality. A key feature in ACT is its
controller module, which manages the entire pipeline by dynamically adjusting
hyperparameters, orchestrating iterative data generation, and finetuning based
on real-time evaluations. This enables ACT to intelligently optimize when to
continue training, generate additional targeted training data, or stop the
process. Our results demonstrate that ACT consistently enhances the
effectiveness of open-source models, offering businesses and developers a
secure and reliable alternative. Additionally, applying our data generation
pipeline to industry-scale migration projects has led to a notable increase in
developer acceleration.

</details>


### [59] [Cross-Modal Distillation For Widely Differing Modalities](https://arxiv.org/abs/2507.16296)
*Cairong Zhao,Yufeng Jin,Zifan Song,Haonan Chen,Duoqian Miao,Guosheng Hu*

Main category: cs.AI

TL;DR: 本文提出了一种跨模态知识蒸馏框架，通过教师模型向学生模型转移判别性知识，解决多模态数据在使用时访问受限的问题，并在说话人识别和图像分类任务上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 深度学习通过增加模型规模来提升性能变得困难且效率低下，多模态学习能够通过引入更丰富的判别性信息来缓解这一挑战，但在实际使用时多模态数据的获取往往受限，且不同模态间的巨大领域差距容易导致知识蒸馏过程中的过拟合问题。

Method: 提出跨模态蒸馏框架，包括：(1)在特征层和分类器层分别设计两种软约束知识蒸馏策略，避免硬约束损失(如L2损失)导致的过拟合；(2)提出基于质量的自适应权重模块，通过量化数据质量为输入样本分配权重，实现鲁棒的模型训练。

Result: 在说话人识别和图像分类任务上进行实验，结果表明该方法能够有效实现图像、文本和语音等广泛应用且差异较大的模态之间的知识转移。

Conclusion: 所提出的跨模态知识蒸馏框架通过软约束策略和自适应权重模块，成功解决了跨模态知识转移中的过拟合问题，实现了不同模态间的有效知识蒸馏，为多模态学习在数据受限场景下的应用提供了有效解决方案。

Abstract: Deep learning achieved great progress recently, however, it is not easy or
efficient to further improve its performance by increasing the size of the
model. Multi-modal learning can mitigate this challenge by introducing richer
and more discriminative information as input. To solve the problem of limited
access to multi-modal data at the time of use, we conduct multi-modal learning
by introducing a teacher model to transfer discriminative knowledge to a
student model during training. However, this knowledge transfer via
distillation is not trivial because the big domain gap between the widely
differing modalities can easily lead to overfitting. In this work, we introduce
a cross-modal distillation framework. Specifically, we find hard constrained
loss, e.g. l2 loss forcing the student being exact the same as the teacher, can
easily lead to overfitting in cross-modality distillation. To address this, we
propose two soft constrained knowledge distillation strategies at the feature
level and classifier level respectively. In addition, we propose a
quality-based adaptive weights module to weigh input samples via quantified
data quality, leading to robust model training. We conducted experiments on
speaker recognition and image classification tasks, and the results show that
our approach is able to effectively achieve knowledge transfer between the
commonly used and widely differing modalities of image, text, and speech.

</details>


### [60] [Mind the Gap: Evaluating the Representativeness of Quantitative Medical Language Reasoning LLM Benchmarks for African Disease Burdens](https://arxiv.org/abs/2507.16322)
*Fred Mutisya,Shikoh Gitau,Christine Syovata,Diana Oigara,Ibrahim Matende,Muna Aden,Munira Ali,Ryan Nyotu,Diana Marion,Job Nyangena,Nasubo Ongoma,Keith Mbae,Elizabeth Wamicha,Eric Mibuari,Jean Philbert Nsengemana,Talkmore Chidede*

Main category: cs.AI

TL;DR: 该研究发现现有医学大语言模型基准测试主要反映高收入国家的疾病谱，不适用于非洲地区。研究开发了基于肯尼亚临床实践指南的Alama Health QA基准，更好地代表了疟疾、HIV、结核病等非洲高发疾病，为非洲医疗系统的模型评估提供了更合适的工具。


<details>
  <summary>Details</summary>
Motivation: 现有的医学大语言模型基准测试主要基于高收入国家的考试大纲和疾病谱，在疟疾、HIV、结核病、镰状细胞病等被忽视热带疾病占主导地位的非洲地区部署时，其有效性存在问题。需要开发更适合非洲疾病负担和监管环境的基准测试。

Method: 系统性回顾了31篇定量LLM评估论文，识别出19个英文医学问答基准。使用基于肯尼亚临床实践指南的检索增强生成框架开发了Alama Health QA。对6个广泛使用的基准进行了统一的语义分析（NTD比例、时效性、可读性、词汇多样性指标）和专家盲评（临床相关性、指南一致性、清晰度、干扰项合理性、语言文化适应性）。

Result: Alama Health QA涵盖了所有语料库中超过40%的NTD提及，疟疾(7.7%)、HIV(4.1%)和结核病(5.2%)的频率最高；AfriMedQA排名第二但缺乏正式的指南关联。全球基准显示最小的代表性（如镰状细胞病在三个数据集中完全缺失）。定性评估中，Alama在相关性和指南一致性方面得分最高；PubMedQA在临床实用性方面得分最低。

Conclusion: 文献中广泛使用的定量医学LLM基准测试未能充分代表非洲疾病负担和监管环境，存在误导性能声明的风险。基于指南锚定、区域策划的资源如Alama Health QA及其扩展的疾病特异性衍生品，对于非洲卫生系统的安全、公平模型评估和部署至关重要。

Abstract: Introduction: Existing medical LLM benchmarks largely reflect examination
syllabi and disease profiles from high income settings, raising questions about
their validity for African deployment where malaria, HIV, TB, sickle cell
disease and other neglected tropical diseases (NTDs) dominate burden and
national guidelines drive care. Methodology: We systematically reviewed 31
quantitative LLM evaluation papers (Jan 2019 May 2025) identifying 19 English
medical QA benchmarks. Alama Health QA was developed using a retrieval
augmented generation framework anchored on the Kenyan Clinical Practice
Guidelines. Six widely used sets (AfriMedQA, MMLUMedical, PubMedQA, MedMCQA,
MedQAUSMLE, and guideline grounded Alama Health QA) underwent harmonized
semantic profiling (NTD proportion, recency, readability, lexical diversity
metrics) and blinded expert rating across five dimensions: clinical relevance,
guideline alignment, clarity, distractor plausibility, and language/cultural
fit. Results: Alama Health QA captured >40% of all NTD mentions across corpora
and the highest within set frequencies for malaria (7.7%), HIV (4.1%), and TB
(5.2%); AfriMedQA ranked second but lacked formal guideline linkage. Global
benchmarks showed minimal representation (e.g., sickle cell disease absent in
three sets) despite large scale. Qualitatively, Alama scored highest for
relevance and guideline alignment; PubMedQA lowest for clinical utility.
Discussion: Quantitative medical LLM benchmarks widely used in the literature
underrepresent African disease burdens and regulatory contexts, risking
misleading performance claims. Guideline anchored, regionally curated resources
such as Alama Health QA and expanded disease specific derivatives are essential
for safe, equitable model evaluation and deployment across African health
systems.

</details>


### [61] [Higher Gauge Flow Models](https://arxiv.org/abs/2507.16334)
*Alexander Strunk,Roland Assam*

Main category: cs.AI

TL;DR: 本文提出了高规范流模型（Higher Gauge Flow Models），这是一种新型生成流模型，通过利用L∞代数扩展李代数，将高维几何和高对称性整合到生成流模型框架中，在高斯混合模型数据集上显示出相比传统流模型的显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统的规范流模型基于李代数，但在处理复杂的高维几何结构和高对称性时存在局限性。为了克服这些限制并提高生成模型的表现力，需要将高维群论和高几何的概念引入到生成流模型中。

Method: 基于普通规范流模型的基础上，利用L∞代数有效扩展李代数结构。通过这种扩展，将与高群相关的高维几何和高对称性整合到生成流模型的框架中，从而构建高规范流模型。

Result: 在高斯混合模型数据集上进行的实验评估显示，高规范流模型相比传统流模型取得了显著的性能改进。

Conclusion: 高规范流模型通过引入L∞代数和高维几何概念，成功扩展了传统流模型的能力，为生成建模提供了一个更强大的数学框架，实验结果验证了该方法的有效性。

Abstract: This paper introduces Higher Gauge Flow Models, a novel class of Generative
Flow Models. Building upon ordinary Gauge Flow Models (arXiv:2507.13414), these
Higher Gauge Flow Models leverage an L$_{\infty}$-algebra, effectively
extending the Lie Algebra. This expansion allows for the integration of the
higher geometry and higher symmetries associated with higher groups into the
framework of Generative Flow Models. Experimental evaluation on a Gaussian
Mixture Model dataset revealed substantial performance improvements compared to
traditional Flow Models.

</details>


### [62] [Learning to Call: A Field Trial of a Collaborative Bandit Algorithm for Improved Message Delivery in Mobile Maternal Health](https://arxiv.org/abs/2507.16356)
*Arpan Dasgupta,Mizhaan Maniyar,Awadhesh Srivastava,Sanat Kumar,Amrita Mahale,Aparna Hedge,Arun Suggala,Karthikeyan Shanmugam,Aparna Taneja,Milind Tambe*

Main category: cs.AI

TL;DR: 该研究针对印度Kilkari项目开发了一种协作强盗算法，通过学习个人偏好的通话时间来优化语音健康信息的投递时间，在6500名参与者的试点研究中显著提高了电话接听率，展示了个性化调度在移动健康干预中的有效性。


<details>
  <summary>Details</summary>
Motivation: 印度Kilkari项目通过语音电话向数百万母亲传递重要的孕产妇健康信息，但当前的随机通话调度经常导致未接电话和信息传递效果降低。需要一种能够学习个人偏好通话时间的智能调度方法来提高信息传递效率。

Method: 设计并部署了一种协作强盗算法（collaborative bandit algorithm），该算法能够学习每位母亲的个人偏好通话时间，从而优化电话拨打的时间安排。在约6500名Kilkari参与者中进行了实地试验，并与基线的随机通话方法进行了性能比较。

Result: 使用强盗算法的通话接听率相比随机通话方法有统计学意义上的显著提升，证明了该算法在提高信息传递效果方面的潜力，可能影响印度数百万母亲的健康信息获取。

Conclusion: 个性化调度在移动健康干预中具有显著效果，机器学习技术在大规模改善孕产妇健康推广方面具有巨大潜力。该研究为移动健康项目提供了一种有效的技术解决方案，能够通过智能化的时间调度显著提高健康信息的传递效率。

Abstract: Mobile health (mHealth) programs utilize automated voice messages to deliver
health information, particularly targeting underserved communities,
demonstrating the effectiveness of using mobile technology to disseminate
crucial health information to these populations, improving health outcomes
through increased awareness and behavioral change. India's Kilkari program
delivers vital maternal health information via weekly voice calls to millions
of mothers. However, the current random call scheduling often results in missed
calls and reduced message delivery. This study presents a field trial of a
collaborative bandit algorithm designed to optimize call timing by learning
individual mothers' preferred call times. We deployed the algorithm with around
$6500$ Kilkari participants as a pilot study, comparing its performance to the
baseline random calling approach. Our results demonstrate a statistically
significant improvement in call pick-up rates with the bandit algorithm,
indicating its potential to enhance message delivery and impact millions of
mothers across India. This research highlights the efficacy of personalized
scheduling in mobile health interventions and underscores the potential of
machine learning to improve maternal health outreach at scale.

</details>


### [63] [Canonical Representations of Markovian Structural Causal Models: A Framework for Counterfactual Reasoning](https://arxiv.org/abs/2507.16370)
*Lucas de Lara*

Main category: cs.AI

TL;DR: 本文提出了一种基于反事实模型的新方法来表示和实现反事实推理，作为结构因果模型的替代方案，允许分析师在不改变观察和干预约束的情况下指定多种反事实概念。


<details>
  <summary>Details</summary>
Motivation: 反事实推理对应因果关系的最精细层次，虽然许多反事实陈述无法被证伪，但它们支撑着个体公平性等基本概念。因此，提供形式化和实现反事实信念的模型仍然是一个基础科学问题。

Method: 在Pearl因果框架的马尔可夫设置中，作者提出反事实模型（也称为结构因果模型的规范表示）作为结构因果模型的替代方法。引入了具有预分配边际分布的随机过程概率分布来选择反事实概念，并提出了一个标准化程序来描述和实现各种反事实概念。

Result: 该方法能够表征与给定因果图模型兼容的反事实等价类，允许在不改变观察和干预约束的情况下指定多种反事实概念。对应反事实层的模型内容不需要被估计，只需要做出选择。

Conclusion: 通过理论和数值示例，作者展示了反事实在因果关系中的特定作用以及所提方法的优势。该方法为反事实推理提供了更灵活和实用的框架。

Abstract: Counterfactual reasoning aims at answering contrary-to-fact questions like
''Would have Alice recovered had she taken aspirin?'' and corresponds to the
most fine-grained layer of causation. Critically, while many counterfactual
statements cannot be falsified -- even by randomized experiments -- they
underpin fundamental concepts like individual-wise fairness. Therefore,
providing models to formalize and implement counterfactual beliefs remains a
fundamental scientific problem. In the Markovian setting of Pearl's causal
framework, we propose an alternative approach to structural causal models to
represent counterfactuals compatible with a given causal graphical model. More
precisely, we introduce counterfactual models, also called canonical
representations of structural causal models. They enable analysts to choose a
counterfactual conception via random-process probability distributions with
preassigned marginals and characterize the counterfactual equivalence class of
structural causal models. Then, we present a normalization procedure to
describe and implement various counterfactual conceptions. Compared to
structural causal models, it allows to specify many counterfactual conceptions
without altering the observational and interventional constraints. Moreover,
the content of the model corresponding to the counterfactual layer does not
need to be estimated; only to make a choice. Finally, we illustrate the
specific role of counterfactuals in causality and the benefits of our approach
on theoretical and numerical examples.

</details>


### [64] [Self-Supervised Inductive Logic Programming](https://arxiv.org/abs/2507.16405)
*Stassa Patsantzis*

Main category: cs.AI

TL;DR: 该论文提出了一种新的自监督归纳逻辑编程(ILP)方法Poker,能够在缺乏专家知识背景理论和负例的情况下,仅从正例和无标签例子中学习递归逻辑程序。


<details>
  <summary>Details</summary>
Motivation: 传统的归纳逻辑编程方法如元解释学习(MIL)需要专家精心选择的背景理论和负例才能有效学习,但在实际应用中这些先验知识往往不可用。因此需要开发能够在缺乏专家知识的情况下进行自监督学习的ILP方法。

Method: 提出了新的自监督ILP设置和MIL算法,开发了Poker系统。该方法能从正标签例子和无标签例子中学习,在学习过程中自动生成和标注新的正负例子。还引入了二阶确定范式(SONF)来原则性地选择二阶背景理论,使其足够通用以学习某类中的所有程序。

Result: 在上下文无关语法和L-系统语言的语法学习实验中,Poker系统的性能随着自动生成例子数量的增加而提升,而缺乏负例的Louise系统出现过度泛化问题。实验验证了Poker在仅有正例和终端词汇表作为一阶背景理论的情况下能够有效学习。

Conclusion: 该研究成功解决了ILP中对专家知识依赖的问题,提出的自监督学习方法能够在缺乏背景理论和负例的情况下有效学习递归逻辑程序,为ILP在实际应用中的推广提供了新的可能性。

Abstract: Inductive Logic Programming (ILP) approaches like Meta \-/ Interpretive
Learning (MIL) can learn, from few examples, recursive logic programs with
invented predicates that generalise well to unseen instances. This ability
relies on a background theory and negative examples, both carefully selected
with expert knowledge of a learning problem and its solutions. But what if such
a problem-specific background theory or negative examples are not available? We
formalise this question as a new setting for Self-Supervised ILP and present a
new MIL algorithm that learns in the new setting from some positive labelled,
and zero or more unlabelled examples, and automatically generates, and labels,
new positive and negative examples during learning. We implement this algorithm
in Prolog in a new MIL system, called Poker. We compare Poker to
state-of-the-art MIL system Louise on experiments learning grammars for
Context-Free and L-System languages from labelled, positive example strings, no
negative examples, and just the terminal vocabulary of a language, seen in
examples, as a first-order background theory. We introduce a new approach for
the principled selection of a second-order background theory as a Second Order
Definite Normal Form (SONF), sufficiently general to learn all programs in a
class, thus removing the need for a backgound theory tailored to a learning
task. We find that Poker's performance improves with increasing numbers of
automatically generated examples while Louise, bereft of negative examples,
over-generalises.

</details>


### [65] [Identifying Pre-training Data in LLMs: A Neuron Activation-Based Detection Framework](https://arxiv.org/abs/2507.16414)
*Hongyi Tang,Zhihao Zhu,Yi Yang*

Main category: cs.AI

TL;DR: 本文提出了NA-PDD算法，通过分析大语言模型中训练数据和非训练数据的神经元激活模式差异来检测预训练数据，并在新基准CCNewsPDD上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的训练数据可能包含版权材料或隐私信息，引发法律和伦理问题，同时存在数据集污染和偏见内化问题。现有的预训练数据检测(PDD)方法依赖于预测置信度和损失等表面特征，性能平庸，需要更好的检测方法。

Method: 提出NA-PDD算法，基于训练数据和非训练数据在LLM推理过程中激活不同神经元的观察，通过分析差异化神经元激活模式来检测预训练数据。同时构建了CCNewsPDD基准，采用严格的数据变换确保训练和非训练数据的时间分布一致。

Result: NA-PDD在三个基准测试和多个大语言模型上的实验结果显著优于现有方法，证明了通过神经元激活模式分析进行预训练数据检测的有效性。

Conclusion: 通过分析神经元激活模式的差异，NA-PDD算法能够有效识别大语言模型预训练语料中的特定数据，为解决LLM训练数据的法律伦理问题和数据污染问题提供了新的技术手段。

Abstract: The performance of large language models (LLMs) is closely tied to their
training data, which can include copyrighted material or private information,
raising legal and ethical concerns. Additionally, LLMs face criticism for
dataset contamination and internalizing biases. To address these issues, the
Pre-Training Data Detection (PDD) task was proposed to identify if specific
data was included in an LLM's pre-training corpus. However, existing PDD
methods often rely on superficial features like prediction confidence and loss,
resulting in mediocre performance. To improve this, we introduce NA-PDD, a
novel algorithm analyzing differential neuron activation patterns between
training and non-training data in LLMs. This is based on the observation that
these data types activate different neurons during LLM inference. We also
introduce CCNewsPDD, a temporally unbiased benchmark employing rigorous data
transformations to ensure consistent time distributions between training and
non-training data. Our experiments demonstrate that NA-PDD significantly
outperforms existing methods across three benchmarks and multiple LLMs.

</details>


### [66] [From model-based learning to model-free behaviour with Meta-Interpretive Learning](https://arxiv.org/abs/2507.16434)
*Stassa Patsantzis*

Main category: cs.AI

TL;DR: 本文提出了一种结合模型基和无模型方法的自主智能体架构，使用元解释学习训练模型基求解器，再用其训练无模型控制器，在网格导航问题上验证了两者的等效性。


<details>
  <summary>Details</summary>
Motivation: 现有的智能体要么是模型基的（需要完全观察环境状态但能规划），要么是无模型的（无需模型但不能规划）。在新颖环境中独立行动的自主智能体需要同时具备这两种能力，因此需要一种能够结合两者优势的方法。

Method: 使用元解释学习（Meta-Interpretive Learning）来学习一个模型基的求解器（Solver），然后用这个求解器来训练一个无模型的控制器（Controller），使控制器能够解决与求解器相同的规划问题。

Result: 在两种网格导航环境（随机生成的迷宫和具有大片开阔区域的湖泊地图）上进行实验，发现求解器能解决的所有导航问题，控制器也都能解决，表明两者在问题解决能力上是等效的。

Conclusion: 成功创建了一个结合模型基和无模型方法优势的自主智能体架构，通过元解释学习训练的求解器与其训练的控制器在导航问题上表现出等效的问题解决能力，为构建能在新颖环境中独立行动的智能体提供了有效方案。

Abstract: A "model" is a theory that describes the state of an environment and the
effects of an agent's decisions on the environment. A model-based agent can use
its model to predict the effects of its future actions and so plan ahead, but
must know the state of the environment. A model-free agent cannot plan, but can
act without a model and without completely observing the environment. An
autonomous agent capable of acting independently in novel environments must
combine both sets of capabilities. We show how to create such an agent with
Meta-Interpretive Learning used to learn a model-based Solver used to train a
model-free Controller that can solve the same planning problems as the Solver.
We demonstrate the equivalence in problem-solving ability of the two agents on
grid navigation problems in two kinds of environment: randomly generated mazes,
and lake maps with wide open areas. We find that all navigation problems solved
by the Solver are also solved by the Controller, indicating the two are
equivalent.

</details>


### [67] [Improving ASP-based ORS Schedules through Machine Learning Predictions](https://arxiv.org/abs/2507.16454)
*Pierangela Bruno,Carmine Dodaro,Giuseppe Galatà,Marco Maratea,Marco Mochi*

Main category: cs.AI

TL;DR: 本文通过整合机器学习和Answer Set Programming (ASP)技术，解决手术室调度问题中预测手术时长和生成鲁棒调度方案的挑战，在意大利ASL1 Liguria的历史数据上验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于ASP的手术室调度解决方案只能验证编码与实际数据的一致性，最多建议替代调度方案，无法生成预测性调度，且生成的调度方案鲁棒性不足。

Method: 整合归纳和演绎技术：首先使用机器学习算法从历史数据中预测手术时长来计算预测性调度；然后将预测置信度作为额外输入，相应更新编码以计算更鲁棒的调度方案。

Result: 在意大利ASL1 Liguria的历史数据上的实验结果证实了该整合方法的可行性，能够生成预测性的鲁棒手术室调度方案。

Conclusion: 通过将机器学习预测与ASP推理相结合，成功解决了手术室调度中的预测性和鲁棒性问题，为实际医疗资源优化提供了可行的解决方案。

Abstract: The Operating Room Scheduling (ORS) problem deals with the optimization of
daily operating room surgery schedules. It is a challenging problem subject to
many constraints, like to determine the starting time of different surgeries
and allocating the required resources, including the availability of beds in
different department units. Recently, solutions to this problem based on Answer
Set Programming (ASP) have been delivered. Such solutions are overall
satisfying but, when applied to real data, they can currently only verify
whether the encoding aligns with the actual data and, at most, suggest
alternative schedules that could have been computed. As a consequence, it is
not currently possible to generate provisional schedules. Furthermore, the
resulting schedules are not always robust.
  In this paper, we integrate inductive and deductive techniques for solving
these issues. We first employ machine learning algorithms to predict the
surgery duration, from historical data, to compute provisional schedules. Then,
we consider the confidence of such predictions as an additional input to our
problem and update the encoding correspondingly in order to compute more robust
schedules. Results on historical data from the ASL1 Liguria in Italy confirm
the viability of our integration.
  Under consideration in Theory and Practice of Logic Programming (TPLP).

</details>


### [68] [Learning Temporal Abstractions via Variational Homomorphisms in Option-Induced Abstract MDPs](https://arxiv.org/abs/2507.16473)
*Chang Li,Yaren Zhang,Haoran Lv,Qiong Cao,Chao Xue,Xiaodong He*

Main category: cs.AI

TL;DR: 本文提出了一种基于分层强化学习的隐式推理框架，通过在潜在空间中进行"思考"而非生成显式文本，实现了比传统思维链提示更高效的大语言模型推理。


<details>
  <summary>Details</summary>
Motivation: 传统的思维链（CoT）提示虽然能够提升大语言模型的推理能力，但生成逐步的文本解释在计算上昂贵且速度缓慢。因此需要开发一种高效的隐式推理框架，让模型能够在潜在空间中"思考"而无需为每一步生成显式文本。

Method: 提出将潜在思维建模为分层强化学习框架中的时间扩展抽象动作（选项）。引入变分马尔可夫选项评判器（VMOC）这一离策略算法，在HiT-MDP框架内使用变分推理来学习多样化的选项库。扩展连续MDP同态理论为使用选项作为抽象推理空间提供理论基础。设计冷启动程序，利用监督微调数据将人类推理演示蒸馏到潜在选项空间中。

Result: 在复杂逻辑推理基准和具有挑战性的运动控制任务上取得了强劲性能，验证了该框架作为学习语言和控制抽象技能的原则性方法的有效性。

Conclusion: 该研究成功开发了一个基于分层强化学习的隐式推理框架，通过在潜在空间中建模抽象推理过程，实现了比显式思维链更高效的推理，并在理论和实验上验证了其有效性，为大语言模型的高效推理提供了新的解决方案。

Abstract: Large Language Models (LLMs) have shown remarkable reasoning ability through
explicit Chain-of-Thought (CoT) prompting, but generating these step-by-step
textual explanations is computationally expensive and slow. To overcome this,
we aim to develop a framework for efficient, implicit reasoning, where the
model "thinks" in a latent space without generating explicit text for every
step. We propose that these latent thoughts can be modeled as
temporally-extended abstract actions, or options, within a hierarchical
reinforcement learning framework. To effectively learn a diverse library of
options as latent embeddings, we first introduce the Variational Markovian
Option Critic (VMOC), an off-policy algorithm that uses variational inference
within the HiT-MDP framework. To provide a rigorous foundation for using these
options as an abstract reasoning space, we extend the theory of continuous MDP
homomorphisms. This proves that learning a policy in the simplified, abstract
latent space, for which VMOC is suited, preserves the optimality of the
solution to the original, complex problem. Finally, we propose a cold-start
procedure that leverages supervised fine-tuning (SFT) data to distill human
reasoning demonstrations into this latent option space, providing a rich
initialization for the model's reasoning capabilities. Extensive experiments
demonstrate that our approach achieves strong performance on complex logical
reasoning benchmarks and challenging locomotion tasks, validating our framework
as a principled method for learning abstract skills for both language and
control.

</details>


### [69] [Agentic RAG with Knowledge Graphs for Complex Multi-Hop Reasoning in Real-World Applications](https://arxiv.org/abs/2507.16507)
*Jean Lelong,Adnane Errazine,Annabelle Blangero*

Main category: cs.AI

TL;DR: 研究者开发了INRAExplorer，一个基于智能体的检索增强生成（RAG）系统，用于探索法国国家农业食品环境研究院（INRAE）的科学数据，通过多工具架构和知识图谱实现复杂查询处理和多跳推理。


<details>
  <summary>Details</summary>
Motivation: 传统的检索增强生成（RAG）系统在处理复杂查询时存在局限性，只能提供有限的提取式答案，在多目标检索和复杂实体关系导航方面表现不佳，这在知识密集型领域是一个关键缺陷。

Method: 提出INRAExplorer系统，采用基于大语言模型的智能体和多工具架构，通过从INRAE开放获取出版物构建的综合知识图谱动态交互丰富的知识库，实现迭代式目标查询、详尽数据集检索和多跳推理。

Result: INRAExplorer能够进行迭代式、有针对性的查询，检索详尽的数据集（如某作者的所有出版物），执行多跳推理，并提供结构化、全面的答案。

Conclusion: INRAExplorer为专业领域中增强知识交互提供了具体的解决方案示例，展示了智能体RAG系统在处理复杂科学数据查询方面的有效性。

Abstract: Conventional Retrieval-Augmented Generation (RAG) systems enhance Large
Language Models (LLMs) but often fall short on complex queries, delivering
limited, extractive answers and struggling with multiple targeted retrievals or
navigating intricate entity relationships. This is a critical gap in
knowledge-intensive domains. We introduce INRAExplorer, an agentic RAG system
for exploring the scientific data of INRAE (France's National Research
Institute for Agriculture, Food and Environment). INRAExplorer employs an
LLM-based agent with a multi-tool architecture to dynamically engage a rich
knowledge base, through a comprehensive knowledge graph derived from open
access INRAE publications. This design empowers INRAExplorer to conduct
iterative, targeted queries, retrieve exhaustive datasets (e.g., all
publications by an author), perform multi-hop reasoning, and deliver
structured, comprehensive answers. INRAExplorer serves as a concrete
illustration of enhancing knowledge interaction in specialized fields.

</details>


### [70] [Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report](https://arxiv.org/abs/2507.16534)
*Shanghai AI Lab,:,Xiaoyang Chen,Yunhao Chen,Zeren Chen,Zhiyun Chen,Hanyun Cui,Yawen Duan,Jiaxuan Guo,Qi Guo,Xuhao Hu,Hong Huang,Lige Huang,Chunxiao Li,Juncheng Li,Qihao Lin,Dongrui Liu,Xinmin Liu,Zicheng Liu,Chaochao Lu,Xiaoya Lu,Jingjing Qu,Qibing Ren,Jing Shao,Jingwei Shi,Jingwei Sun,Peng Wang,Weibing Wang,Jia Xu,Lewen Yan,Xiao Yu,Yi Yu,Boxuan Zhang,Jie Zhang,Weichen Zhang,Zhijie Zheng,Tianyi Zhou,Bowen Zhou*

Main category: cs.AI

TL;DR: 本研究对前沿AI模型的风险进行了全面评估，识别了七个关键风险领域，并使用红黄绿三色风险区域划分法对当前AI模型进行分类，发现所有模型都处于绿色和黄色区域，未跨越红线。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术快速发展，需要理解和识别前沿AI模型带来的前所未有的风险，为AI安全治理提供科学依据。

Method: 采用E-T-C分析框架（部署环境、威胁源、赋能能力），结合"AI-45°法则"，通过设置"红线"（不可容忍阈值）和"黄线"（早期预警指标）来定义绿、黄、红三个风险区域，对七个关键风险领域进行评估。

Result: 所有当前前沿AI模型都处于绿色和黄色区域，未跨越红线。网络攻击和不受控AI研发风险未达到黄线；自我复制和战略欺骗风险大多在绿区，部分推理模型在黄区；说服操控风险多数模型在黄区；生物化学风险无法排除多数模型处于黄区的可能性。

Conclusion: 当前AI模型虽然存在多种前沿风险，但尚未达到需要暂停开发或部署的红线水平。研究强调需要集体行动来缓解这些挑战，并为AI风险管理提供了系统性的评估框架。

Abstract: To understand and identify the unprecedented risks posed by rapidly advancing
artificial intelligence (AI) models, this report presents a comprehensive
assessment of their frontier risks. Drawing on the E-T-C analysis (deployment
environment, threat source, enabling capability) from the Frontier AI Risk
Management Framework (v1.0) (SafeWork-F1-Framework), we identify critical risks
in seven areas: cyber offense, biological and chemical risks, persuasion and
manipulation, uncontrolled autonomous AI R\&D, strategic deception and
scheming, self-replication, and collusion. Guided by the "AI-$45^\circ$ Law,"
we evaluate these risks using "red lines" (intolerable thresholds) and "yellow
lines" (early warning indicators) to define risk zones: green (manageable risk
for routine deployment and continuous monitoring), yellow (requiring
strengthened mitigations and controlled deployment), and red (necessitating
suspension of development and/or deployment). Experimental results show that
all recent frontier AI models reside in green and yellow zones, without
crossing red lines. Specifically, no evaluated models cross the yellow line for
cyber offense or uncontrolled AI R\&D risks. For self-replication, and
strategic deception and scheming, most models remain in the green zone, except
for certain reasoning models in the yellow zone. In persuasion and
manipulation, most models are in the yellow zone due to their effective
influence on humans. For biological and chemical risks, we are unable to rule
out the possibility of most models residing in the yellow zone, although
detailed threat modeling and in-depth assessment are required to make further
claims. This work reflects our current understanding of AI frontier risks and
urges collective action to mitigate these challenges.

</details>


### [71] [Novel Multi-Agent Action Masked Deep Reinforcement Learning for General Industrial Assembly Lines Balancing Problems](https://arxiv.org/abs/2507.16635)
*Ali Mohamed Ali,Luca Tirel,Hashim A. Hashim*

Main category: cs.AI

TL;DR: 本文提出了一种基于深度强化学习的工业装配线任务和资源调度优化方法，通过马尔可夫决策过程建模、动作掩码技术和多智能体架构，实现了比传统方法更快的收敛速度和更好的实时性能。


<details>
  <summary>Details</summary>
Motivation: 传统的整数规划方法在大规模场景下计算复杂度过高，而遗传算法等启发式方法往往产生次优解。现有的装配线模型大多对装配线类型有特定假设，缺乏通用性。因此需要一种既能保证解质量又能适应大规模实时应用的优化方法。

Method: 将通用工业装配线建模为马尔可夫决策过程(MDP)，使用深度强化学习训练智能体进行任务和资源调度优化。提出两个创新工具：1)动作掩码技术确保智能体只选择可行动作；2)多智能体方法，每个工作站由独立智能体管理。采用集中训练分散执行的框架，通过神经网络将当前工厂状态映射到最优动作。

Result: 数值仿真验证表明，所提出的方案相比基于模型的可比较方法，能够显著更快地收敛到最优解。多智能体架构有效减少了状态和动作空间，提高了训练效率。系统能够在离线学习后提供实时解决方案。

Conclusion: 本文成功开发了一个可扩展的深度强化学习框架，用于优化工业装配线的任务和资源调度。通过MDP建模、动作掩码和多智能体架构的结合，该方法在保证解质量的同时显著提高了计算效率和实时性能，为大规模工业装配线优化提供了有效解决方案。

Abstract: Efficient planning of activities is essential for modern industrial assembly
lines to uphold manufacturing standards, prevent project constraint violations,
and achieve cost-effective operations. While exact solutions to such challenges
can be obtained through Integer Programming (IP), the dependence of the search
space on input parameters often makes IP computationally infeasible for
large-scale scenarios. Heuristic methods, such as Genetic Algorithms, can also
be applied, but they frequently produce suboptimal solutions in extensive
cases. This paper introduces a novel mathematical model of a generic industrial
assembly line formulated as a Markov Decision Process (MDP), without imposing
assumptions on the type of assembly line a notable distinction from most
existing models. The proposed model is employed to create a virtual environment
for training Deep Reinforcement Learning (DRL) agents to optimize task and
resource scheduling. To enhance the efficiency of agent training, the paper
proposes two innovative tools. The first is an action-masking technique, which
ensures the agent selects only feasible actions, thereby reducing training
time. The second is a multi-agent approach, where each workstation is managed
by an individual agent, as a result, the state and action spaces were reduced.
A centralized training framework with decentralized execution is adopted,
offering a scalable learning architecture for optimizing industrial assembly
lines. This framework allows the agents to learn offline and subsequently
provide real-time solutions during operations by leveraging a neural network
that maps the current factory state to the optimal action. The effectiveness of
the proposed scheme is validated through numerical simulations, demonstrating
significantly faster convergence to the optimal solution compared to a
comparable model-based approach.

</details>


### [72] [Adaptive Inventory Strategies using Deep Reinforcement Learning for Dynamic Agri-Food Supply Chains](https://arxiv.org/abs/2507.16670)
*Amandeep Kaur,Gyan Prakash*

Main category: cs.AI

TL;DR: 本研究针对农产品供应链中需求和提前期不确定性下的库存管理问题，提出了一种结合价值和策略的深度强化学习算法，通过连续动作空间优化订货量，实现供应链整体利润最大化并促进利益相关者协作。


<details>
  <summary>Details</summary>
Motivation: 农产品面临季节性生产和需求波动，在需求和提前期不确定性下的库存管理具有挑战性，容易导致库存过剩或缺货。现有文献未考虑食品供应链各层级利益相关者之间的协调问题，且传统方法难以处理不确定性和产品保质期等复杂因素。

Method: 提出一种新颖的深度强化学习(DRL)算法，结合基于价值和基于策略的DRL方法优势，通过连续动作空间选择最优订货量。该算法通过共享的利润最大化目标激励利益相关者协作，同时考虑产品易腐性和不确定性。

Result: 使用新鲜农产品供应链库存的实证数据进行评估，实验结果证实了所提出的库存补充策略在随机需求模式和提前期场景下的性能改进。算法有效解决了不确定性环境下的库存优化挑战。

Conclusion: 研究为政策制定者在不确定性条件下更有效地管理农产品库存提供了管理启示。所提出的深度强化学习方法能够实现供应链整体利润最大化，同时促进各利益相关者之间的协作。

Abstract: Agricultural products are often subject to seasonal fluctuations in
production and demand. Predicting and managing inventory levels in response to
these variations can be challenging, leading to either excess inventory or
stockouts. Additionally, the coordination among stakeholders at various level
of food supply chain is not considered in the existing body of literature. To
bridge these research gaps, this study focuses on inventory management of
agri-food products under demand and lead time uncertainties. By implementing
effective inventory replenishment policy results in maximize the overall profit
throughout the supply chain. However, the complexity of the problem increases
due to these uncertainties and shelf-life of the product, that makes
challenging to implement traditional approaches to generate optimal set of
solutions. Thus, the current study propose a novel Deep Reinforcement Learning
(DRL) algorithm that combines the benefits of both value- and policy-based DRL
approaches for inventory optimization under uncertainties. The proposed
algorithm can incentivize collaboration among stakeholders by aligning their
interests and objectives through shared optimization goal of maximizing
profitability along the agri-food supply chain while considering perishability,
and uncertainty simultaneously. By selecting optimal order quantities with
continuous action space, the proposed algorithm effectively addresses the
inventory optimization challenges. To rigorously evaluate this algorithm, the
empirical data from fresh agricultural products supply chain inventory is
considered. Experimental results corroborate the improved performance of the
proposed inventory replenishment policy under stochastic demand patterns and
lead time scenarios. The research findings hold managerial implications for
policymakers to manage the inventory of agricultural products more effectively
under uncertainty.

</details>


### [73] [Deliberative Searcher: Improving LLM Reliability via Reinforcement Learning with constraints](https://arxiv.org/abs/2507.16727)
*Zhenyun Yin,Shujie Wang,Xuhong Wang,Xingjun Ma,Yinchun Wang*

Main category: cs.AI

TL;DR: 该论文提出了Deliberative Searcher框架，这是首个将确定性校准与检索搜索相结合的开放域问答系统，通过多步反思和验证提高大语言模型的可靠性。


<details>
  <summary>Details</summary>
Motivation: 提高大语言模型(LLMs)在现实场景部署中的可靠性是关键需求，需要解决模型置信度与正确性不匹配的问题，使输出更加可信。

Method: 提出Deliberative Searcher框架，集成确定性校准与基于检索的搜索，智能体在Wikipedia数据上执行多步反思和验证，使用强化学习算法在软可靠性约束下优化准确性。

Result: 实验结果表明该方法改善了模型置信度与正确性之间的对齐，产生更可信的输出结果。

Conclusion: Deliberative Searcher框架成功提高了开放域问答中大语言模型的可靠性，通过确定性校准和检索验证的结合实现了更好的置信度校准。

Abstract: Improving the reliability of large language models (LLMs) is critical for
deploying them in real-world scenarios. In this paper, we propose
\textbf{Deliberative Searcher}, the first framework to integrate certainty
calibration with retrieval-based search for open-domain question answering. The
agent performs multi-step reflection and verification over Wikipedia data and
is trained with a reinforcement learning algorithm that optimizes for accuracy
under a soft reliability constraint. Empirical results show that proposed
method improves alignment between model confidence and correctness, leading to
more trustworthy outputs. This paper will be continuously updated.

</details>


### [74] [WGRAMMAR: Leverage Prior Knowledge to Accelerate Structured Decoding](https://arxiv.org/abs/2507.16768)
*Ran Wang,Xiaoxuan Liu,Hao Ren,Gang Chen,Fanchao Qi,Maosong Sun*

Main category: cs.AI

TL;DR: 本文提出了wgrammar，一个轻量级的结构化解码引擎，通过将约束分解为静态和动态组件，实现了比现有系统高达250倍的加速。


<details>
  <summary>Details</summary>
Motivation: 现有的结构化解码方法在让大语言模型生成特定格式输出（如HTML或JSON）时存在效率瓶颈，主要体现在语法编译、状态跟踪和掩码创建等方面，需要一种更高效的解决方案。

Method: 提出将约束分解为静态和动态组件的方法：离线预编译静态结构，运行时使用语法片段实例化动态参数；采用组合算子集合来建模正则格式，替代下推自动机；集成领域感知简化、约束分解和掩码缓存技术。

Result: 开发了wgrammar轻量级解码引擎，实现了比现有系统高达250倍的速度提升，有效降低了转换延迟，提高了结构化解码的效率。

Conclusion: 通过利用真实世界任务中的先验知识和约束分解策略，wgrammar成功解决了结构化解码的效率问题，为大语言模型生成格式化输出提供了高效的解决方案。

Abstract: Structured decoding enables large language models (LLMs) to generate outputs
in formats required by downstream systems, such as HTML or JSON. However,
existing methods suffer from efficiency bottlenecks due to grammar compilation,
state tracking, and mask creation. We observe that many real-world tasks embed
strong prior knowledge about output structure. Leveraging this, we propose a
decomposition of constraints into static and dynamic components -- precompiling
static structures offline and instantiating dynamic arguments at runtime using
grammar snippets. Instead of relying on pushdown automata, we employ a
compositional set of operators to model regular formats, achieving lower
transition latency. We introduce wgrammar, a lightweight decoding engine that
integrates domain-aware simplification, constraint decomposition, and mask
caching, achieving up to 250x speedup over existing systems. wgrammar's source
code is publicly available at https://github.com/wrran/wgrammar.

</details>


### [75] [ChatChecker: A Framework for Dialogue System Testing and Evaluation Through Non-cooperative User Simulation](https://arxiv.org/abs/2507.16792)
*Roman Mayr,Michel Schimpf,Thomas Bohné*

Main category: cs.AI

TL;DR: ChatChecker是一个自动化评估和测试复杂对话系统的框架，使用大语言模型模拟用户交互、识别对话故障并评估质量，无需参考对话且与目标系统实现解耦，提供可扩展的对话系统测试解决方案。


<details>
  <summary>Details</summary>
Motivation: 现代对话系统通常集成多个大语言模型、外部工具和数据库，仅评估底层LLM不足以全面评估整个对话系统。以往工作主要关注轮次级分析，缺乏对集成对话级质量保证的关注，因此需要一个能够整体测试和评估复杂对话系统的解决方案。

Method: 提出ChatChecker框架，使用大语言模型模拟多样化用户交互，识别对话故障并评估质量。设计中减少了设置工作量，具有通用性，不需要参考对话且与目标对话系统的实现解耦。通过在提示中包含错误分类法来改进故障检测性能，并提出基于挑战性人设的非协作用户模拟器。

Result: 相比之前基于LLM的方法，通过在提示中包含错误分类法提高了故障检测性能。基于挑战性人设的非协作用户模拟器能够更有效地发现目标对话系统的弱点，实现了全面且可扩展的测试。

Conclusion: ChatChecker为复杂对话系统提供了自动化评估和测试的有效框架，能够帮助研究人员和从业者加速开发稳健的对话系统，解决了现有对话系统评估方法的局限性。

Abstract: While modern dialogue systems heavily rely on large language models (LLMs),
their implementation often goes beyond pure LLM interaction. Developers
integrate multiple LLMs, external tools, and databases. Therefore, assessment
of the underlying LLM alone does not suffice, and the dialogue systems must be
tested and evaluated as a whole. However, this remains a major challenge. With
most previous work focusing on turn-level analysis, less attention has been
paid to integrated dialogue-level quality assurance. To address this, we
present ChatChecker, a framework for automated evaluation and testing of
complex dialogue systems. ChatChecker uses LLMs to simulate diverse user
interactions, identify dialogue breakdowns, and evaluate quality. Compared to
previous approaches, our design reduces setup effort and is generalizable, as
it does not require reference dialogues and is decoupled from the
implementation of the target dialogue system. We improve breakdown detection
performance over a prior LLM-based approach by including an error taxonomy in
the prompt. Additionally, we propose a novel non-cooperative user simulator
based on challenging personas that uncovers weaknesses in target dialogue
systems more effectively. Through this, ChatChecker contributes to thorough and
scalable testing. This enables both researchers and practitioners to accelerate
the development of robust dialogue systems.

</details>


### [76] [Uncertainty-Aware Knowledge Transformers for Peer-to-Peer Energy Trading with Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2507.16796)
*Mian Ibad Ali Shah,Enda Barrett,Karl Mason*

Main category: cs.AI

TL;DR: 本文提出了一个集成不确定性感知预测和多智能体强化学习的P2P能源交易框架，通过Knowledge Transformer with Uncertainty (KTU)模型量化预测不确定性，实现了更鲁棒的能源交易决策。


<details>
  <summary>Details</summary>
Motivation: 现有P2P能源交易研究依赖确定性预测，缺乏对预测不确定性的考虑，而这在随机性的P2P能源交易环境中对鲁棒决策至关重要。

Method: 提出集成不确定性感知预测与多智能体强化学习(MARL)的框架，采用异方差概率变换器KTU模型进行预测，利用特定领域特征和定制损失函数训练，生成可靠的概率预测和置信区间，并将其整合到不确定性感知的深度Q网络(DQN)中。

Result: 实验结果显示，不确定性感知DQN在无P2P交易时降低能源采购成本5.7%，有P2P交易时降低3.2%；电力销售收入分别增加6.4%和44.7%；峰时电网需求分别减少38.8%和45.6%。

Conclusion: 不确定性感知预测与P2P交易机制的协同作用显著提升了能源社区的经济效率和韧性，证明了先进预测技术与市场机制结合的有效性。

Abstract: This paper presents a novel framework for Peer-to-Peer (P2P) energy trading
that integrates uncertainty-aware prediction with multi-agent reinforcement
learning (MARL), addressing a critical gap in current literature. In contrast
to previous works relying on deterministic forecasts, the proposed approach
employs a heteroscedastic probabilistic transformer-based prediction model
called Knowledge Transformer with Uncertainty (KTU) to explicitly quantify
prediction uncertainty, which is essential for robust decision-making in the
stochastic environment of P2P energy trading. The KTU model leverages
domain-specific features and is trained with a custom loss function that
ensures reliable probabilistic forecasts and confidence intervals for each
prediction. Integrating these uncertainty-aware forecasts into the MARL
framework enables agents to optimize trading strategies with a clear
understanding of risk and variability. Experimental results show that the
uncertainty-aware Deep Q-Network (DQN) reduces energy purchase costs by up to
5.7% without P2P trading and 3.2% with P2P trading, while increasing
electricity sales revenue by 6.4% and 44.7%, respectively. Additionally, peak
hour grid demand is reduced by 38.8% without P2P and 45.6% with P2P. These
improvements are even more pronounced when P2P trading is enabled, highlighting
the synergy between advanced forecasting and market mechanisms for resilient,
economically efficient energy communities.

</details>
