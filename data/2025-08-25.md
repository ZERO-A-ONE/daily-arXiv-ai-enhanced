<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 17]
- [cs.CR](#cs.CR) [Total: 19]
- [cs.AI](#cs.AI) [Total: 20]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [A Systematic Literature Review of Machine Learning Approaches for Migrating Monolithic Systems to Microservices](https://arxiv.org/abs/2508.15941)
*Imen Trabelsi,Brahim Mahmoudi,Jean Baptiste Minani,Naouel Moha,Yann-Gaël Guéhéneuc*

Main category: cs.SE

TL;DR: 本文通过系统文献综述分析了2015-2024年间81项研究，探讨了机器学习在单体系统向微服务迁移中的应用现状、自动化阶段、技术方法和面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 单体系统向微服务迁移复杂且资源密集，需要机器学习自动化支持，但目前缺乏对ML方法在迁移过程中应用的系统性研究。

Method: 采用PRISMA指南进行系统文献综述，分析81项主要研究，提取和分析数据以回答研究问题，构建ML技术应用分类框架。

Result: 研究发现监控和服务识别阶段研究充分，但打包微服务等阶段尚未探索；存在数据可用性有限、可扩展性约束、工具支持不足和缺乏标准化基准等关键挑战。

Conclusion: 需要更全面的解决方案来解决现有挑战，推动机器学习在微服务迁移中的更广泛应用，特别是在未充分研究的迁移阶段。

Abstract: Scalability and maintainability challenges in monolithic systems have led to
the adoption of microservices, which divide systems into smaller, independent
services. However, migrating existing monolithic systems to microservices is a
complex and resource-intensive task, which can benefit from machine learning
(ML) to automate some of its phases. Choosing the right ML approach for
migration remains challenging for practitioners. Previous works studied
separately the objectives, artifacts, techniques, tools, and benefits and
challenges of migrating monolithic systems to microservices. No work has yet
investigated systematically existing ML approaches for this migration to
understand the \revised{automated migration phases}, inputs used, ML techniques
applied, evaluation processes followed, and challenges encountered. We present
a systematic literature review (SLR) that aggregates, synthesises, and
discusses the approaches and results of 81 primary studies (PSs) published
between 2015 and 2024. We followed the Preferred Reporting Items for Systematic
Review and Meta-Analysis (PRISMA) statement to report our findings and answer
our research questions (RQs). We extract and analyse data from these PSs to
answer our RQs. We synthesise the findings in the form of a classification that
shows the usage of ML techniques in migrating monolithic systems to
microservices. The findings reveal that some phases of the migration process,
such as monitoring and service identification, are well-studied, while others,
like packaging microservices, remain unexplored. Additionally, the findings
highlight key challenges, including limited data availability, scalability and
complexity constraints, insufficient tool support, and the absence of
standardized benchmarking, emphasizing the need for more holistic solutions.

</details>


### [2] [Breaking Barriers in Software Testing: The Power of AI-Driven Automation](https://arxiv.org/abs/2508.16025)
*Saba Naqvi,Mohammad Baqar*

Main category: cs.SE

TL;DR: 提出了一个AI驱动的测试框架，结合NLP、强化学习和预测模型，自动生成和验证测试用例，提高测试效率和可靠性


<details>
  <summary>Details</summary>
Motivation: 传统软件测试方法速度慢、成本高且覆盖率不足，需要更智能的自动化解决方案来应对复杂环境下的软件质量保障需求

Method: 使用自然语言处理将需求转换为可执行测试，通过强化学习持续优化测试用例，结合预测模型进行实时结果验证，并采用策略驱动的信任和公平性模型来减少偏差

Result: 案例研究表明，该方法在缺陷检测、测试工作量减少和发布周期加速方面取得了可衡量的改进

Conclusion: AI增强的测试能够将测试从被动的手工过程转变为主动的自适应系统，有效提升复杂环境下的软件质量

Abstract: Software testing remains critical for ensuring reliability, yet traditional
approaches are slow, costly, and prone to gaps in coverage. This paper presents
an AI-driven framework that automates test case generation and validation using
natural language processing (NLP), reinforcement learning (RL), and predictive
models, embedded within a policy-driven trust and fairness model. The approach
translates natural language requirements into executable tests, continuously
optimizes them through learning, and validates outcomes with real-time analysis
while mitigating bias. Case studies demonstrate measurable gains in defect
detection, reduced testing effort, and faster release cycles, showing that
AI-enhanced testing improves both efficiency and reliability. By addressing
integration and scalability challenges, the framework illustrates how AI can
shift testing from a reactive, manual process to a proactive, adaptive system
that strengthens software quality in increasingly complex environments.

</details>


### [3] [Measuring the effectiveness of code review comments in GitHub repositories: A machine learning approach](https://arxiv.org/abs/2508.16053)
*Shadikur Rahman,Umme Ayman Koana,Hasibul Karim Shanto,Mahmuda Akter,Chitra Roy,Aras M. Ismael*

Main category: cs.SE

TL;DR: 本文通过实证研究比较了7种机器学习算法在代码审查文本情感极性分类中的效果，发现线性支持向量机分类器(SVC)准确率最高。


<details>
  <summary>Details</summary>
Motivation: 程序员需要了解代码审查评论的情感极性以避免误解和错误，因此需要有效的分类方法来识别代码审查文本的语义含义。

Method: 从GitHub三个开源项目中提取了13,557条代码审查评论并进行人工标注，使用7种机器学习算法进行情感极性分类比较。

Result: 线性支持向量机分类器(SVC)在所有测试的机器学习算法中取得了最高的分类准确率。

Conclusion: 该研究为程序员提供了基于代码评论情感分析的解决方案，有助于避免误解和提高开发效率。

Abstract: This paper illustrates an empirical study of the working efficiency of
machine learning techniques in classifying code review text by semantic
meaning. The code review comments from the source control repository in GitHub
were extracted for development activity from the existing year for three
open-source projects. Apart from that, programmers need to be aware of their
code and point out their errors. In that case, it is a must to classify the
sentiment polarity of the code review comments to avoid an error. We manually
labelled 13557 code review comments generated by three open source projects in
GitHub during the existing year. In order to recognize the sentiment polarity
(or sentiment orientation) of code reviews, we use seven machine learning
algorithms and compare those results to find the better ones. Among those
Linear Support Vector Classifier(SVC) classifier technique achieves higher
accuracy than others. This study will help programmers to make any solution
based on code reviews by avoiding misconceptions.

</details>


### [4] [From Benchmark Data To Applicable Program Repair: An Experience Report](https://arxiv.org/abs/2508.16071)
*Mahinthan Chandramohan,Jovan Jancic,Yuntong Zhang,Padmanabhan Krishnan*

Main category: cs.SE

TL;DR: 这篇论文探讨了基于形式规格和LLM的自动程序修复方法，虽在标准测试集上表现优异，但在实际产业缺陷修复中效果有限，显示了学术测试与实际需求的差距。


<details>
  <summary>Details</summary>
Motivation: 解决自动程序修复技术在实际产业环境中效果不佳的问题，探索如何通过形式规格提升LLM在复杂产品代码修复中的性能。

Method: 结合文献中的多种技术，使用形式规格（如JML）为代码添加说明，利用LLM生成更高质量的单元测试，重点关注边界情况和异常处理的覆盖。

Result: 形式规格对逻辑和字符串操作错误修复有显著帮助，但对常见错误（如空指针）效果不明显。测试通过不能保证补丁正确性，实际采用遍历限。

Conclusion: 当前方法在实际应用中有限，需要更高级的验证工具和更丰富的谓词表达。未来工作重点在合同自动机、示例编程、测试案例修复，并集成人类反馈来缩小学术研究与实际需求的差距。

Abstract: This paper describes our approach to automated program repair. We combine
various techniques from the literature to achieve this. Our experiments show
that our approach performs better than other techniques on standard benchmarks.
However, on closer inspection, none of these techniques work on realistic
defects that we see in industry.
  We find that augmenting code with formal specifications enables LLMs to
generate higher-quality unit tests, especially for complex production code with
improved coverage of edge cases and exception handling. However, specifications
add little value for well-understood errors (e.g., null pointer, index out of
bounds), but are beneficial for logic and string manipulation errors. Despite
encouraging benchmark results, real-world adoption is limited since passing
tests do not guarantee correct patches. Current challenges include insufficient
expressiveness of the JML specification language, necessitating advanced
verification tools and richer predicates. Our ongoing work is exploring
contract automata, programming by example, and testcase repair, with a focus on
integrating human feedback and measuring productivity gains - highlighting the
gap between academic benchmarks and practical industry needs

</details>


### [5] [Validating Terrain Models in Digital Twins for Trustworthy sUAS Operations](https://arxiv.org/abs/2508.16104)
*Arturo Miguel Russell Bernal,Maureen Petterson,Pedro Antonio Alarcon Granadeno,Michael Murphy,James Mason,Jane Cleland-Huang*

Main category: cs.SE

TL;DR: 本文提出了一种基于软件工程原则的三维验证流程，用于验证环境数字孪生中的地形模型，以支持小型无人机系统在复杂环境中的安全飞行和任务执行。


<details>
  <summary>Details</summary>
Motivation: 随着小型无人机系统在陌生复杂环境中的部署增加，准确的环境数字孪生（特别是地形模型）对于安全飞行规划和高级能力（如地理定位）至关重要，但现实部署中存在多种不确定性源，需要强大的验证过程。

Method: 提出基于软件工程原则的三维验证流程，包括测试粒度、从仿真到真实世界的流程、以及从简单到边缘条件的分析。使用配备地形感知数字阴影的多无人机平台进行验证。

Result: 通过融合美国地质调查局数据集和卫星影像构建高分辨率地形模型，并开发了系统性的验证方法来应对数据粒度限制、地形不连续性、GPS和传感器误差等挑战。

Conclusion: 该三维验证流程为环境数字孪生地形模型的可靠性验证提供了系统化方法，能够支持小型无人机系统在真实世界条件下的安全运行和任务执行。

Abstract: With the increasing deployment of small Unmanned Aircraft Systems (sUAS) in
unfamiliar and complex environments, Environmental Digital Twins (EDT) that
comprise weather, airspace, and terrain data are critical for safe flight
planning and for maintaining appropriate altitudes during search and
surveillance operations. With the expansion of sUAS capabilities through edge
and cloud computing, accurate EDT are also vital for advanced sUAS
capabilities, like geolocation. However, real-world sUAS deployment introduces
significant sources of uncertainty, necessitating a robust validation process
for EDT components. This paper focuses on the validation of terrain models, one
of the key components of an EDT, for real-world sUAS tasks. These models are
constructed by fusing U.S. Geological Survey (USGS) datasets and satellite
imagery, incorporating high-resolution environmental data to support mission
tasks. Validating both the terrain models and their operational use by sUAS
under real-world conditions presents significant challenges, including limited
data granularity, terrain discontinuities, GPS and sensor inaccuracies, visual
detection uncertainties, as well as onboard resources and timing constraints.
We propose a 3-Dimensions validation process grounded in software engineering
principles, following a workflow across granularity of tests, simulation to
real world, and the analysis of simple to edge conditions. We demonstrate our
approach using a multi-sUAS platform equipped with a Terrain-Aware Digital
Shadow.

</details>


### [6] [The Fools are Certain; the Wise are Doubtful: Exploring LLM Confidence in Code Completion](https://arxiv.org/abs/2508.16131)
*Zoe Kotti,Konstantina Dritsa,Diomidis Spinellis,Panos Louridas*

Main category: cs.SE

TL;DR: 该研究通过测量不同编程语言、模型和数据集上的代码困惑度，评估LLM生成代码时的置信度，发现强类型语言比动态类型语言困惑度更低，脚本语言困惑度更高，且困惑度主要受LLM模型影响而非代码数据集。


<details>
  <summary>Details</summary>
Motivation: 下游指标评估代码LLM的实际效用可能不可靠且计算复杂，而困惑度等内在指标简单通用，可以作为LLM生成代码功能正确性和幻觉风险的代理指标。

Method: 使用多种LLM模型，从657个GitHub项目的1008个文件中采样，测量不同编程语言的代码困惑度，分析语言类型、模型选择和代码特征对模型置信度的影响。

Result: 强类型语言（如Java）困惑度较低，动态类型语言（如Perl）困惑度较高；脚本语言困惑度普遍较高；困惑度主要取决于LLM模型而非代码数据集；代码注释通常会增加困惑度但不影响语言排名。

Conclusion: 研究结果为LLM研究者、开发者和用户提供了基于语言特性、模型选择和代码特征来评估LLM代码补全适用性的实用指导，有助于在特定软件项目中合理选择和使用代码补全工具。

Abstract: Code completion entails the task of providing missing tokens given a
surrounding context. It can boost developer productivity while providing a
powerful code discovery tool. Following the Large Language Model (LLM) wave,
code completion has been approached with diverse LLMs fine-tuned on code (code
LLMs). The performance of code LLMs can be assessed with downstream and
intrinsic metrics. Downstream metrics are usually employed to evaluate the
practical utility of a model, but can be unreliable and require complex
calculations and domain-specific knowledge. In contrast, intrinsic metrics such
as perplexity, entropy, and mutual information, which measure model confidence
or uncertainty, are simple, versatile, and universal across LLMs and tasks, and
can serve as proxies for functional correctness and hallucination risk in
LLM-generated code. Motivated by this, we evaluate the confidence of LLMs when
generating code by measuring code perplexity across programming languages,
models, and datasets using various LLMs, and a sample of 1008 files from 657
GitHub projects. We find that strongly-typed languages exhibit lower perplexity
than dynamically typed languages. Scripting languages also demonstrate higher
perplexity. Perl appears universally high in perplexity, whereas Java appears
low. Code perplexity depends on the employed LLM, but not on the code dataset.
Although code comments often increase perplexity, the language ranking based on
perplexity is barely affected by their presence. LLM researchers, developers,
and users can employ our findings to assess the benefits and suitability of
LLM-based code completion in specific software projects based on how language,
model choice, and code characteristics impact model confidence.

</details>


### [7] [Towards Recommending Usability Improvements with Multimodal Large Language Models](https://arxiv.org/abs/2508.16165)
*Sebastian Lubos,Alexander Felfernig,Gerhard Leitner,Julian Schwazer*

Main category: cs.SE

TL;DR: 使用多模态大语言模型自动进行可用性评估，将可用性问题按严重性排序，为资源有限的组织提供成本效益高的替代方案


<details>
  <summary>Details</summary>
Motivation: 传统可用性评估方法（如可用性测试和检查）虽然有效，但资源密集且需要专家参与，使得小型组织难以承担。多模态LLMs的发展为自动化部分可用性评估流程提供了可能

Method: 将可用性评估制定为推荐任务，多模态LLMs分析软件界面的文本、视觉和结构方面，按严重性对可用性问题进行排序。通过概念验证研究比较LLM生成的改进建议与专家评估

Result: 研究发现LLMs能够实现更快、更具成本效益的可用性评估，在专家资源有限的情况下是实用的替代方案

Conclusion: 多模态LLMs在自动化可用性评估方面显示出巨大潜力，可以为资源受限的组织提供可访问的可用性评估解决方案

Abstract: Usability describes a set of essential quality attributes of user interfaces
(UI) that influence human-computer interaction. Common evaluation methods, such
as usability testing and inspection, are effective but resource-intensive and
require expert involvement. This makes them less accessible for smaller
organizations. Recent advances in multimodal LLMs offer promising opportunities
to automate usability evaluation processes partly by analyzing textual, visual,
and structural aspects of software interfaces. To investigate this possibility,
we formulate usability evaluation as a recommendation task, where multimodal
LLMs rank usability issues by severity. We conducted an initial
proof-of-concept study to compare LLM-generated usability improvement
recommendations with usability expert assessments. Our findings indicate the
potential of LLMs to enable faster and more cost-effective usability
evaluation, which makes it a practical alternative in contexts with limited
expert resources.

</details>


### [8] [LLM-Assisted Semantic Alignment and Integration in Collaborative Model-Based Systems Engineering Using SysML v2](https://arxiv.org/abs/2508.16181)
*Zirui Li,Stephan Husung,Haoze Wang*

Main category: cs.SE

TL;DR: 使用GPT基础的大语言模型辅助SysML v2模型进行语义对齐的结构化提示驱动方法


<details>
  <summary>Details</summary>
Motivation: 解决模型基础系统工程中跨组织协作时独立开发系统模型的语义对齐挑战

Method: 迭代开发包含模型提取、语义匹配和验证的对齐方法和交互提示，利用SysML v2的别名、导入和元数据扩展构造

Result: 通过测量系统示例进行了实践演绎，证明了方法的可行性

Conclusion: 该方法为进行可追踪的软对齐集成提供了基础，同时讨论了其优势和局限性

Abstract: Cross-organizational collaboration in Model-Based Systems Engineering (MBSE)
faces many challenges in achieving semantic alignment across independently
developed system models. SysML v2 introduces enhanced structural modularity and
formal semantics, offering a stronger foundation for interoperable modeling.
Meanwhile, GPT-based Large Language Models (LLMs) provide new capabilities for
assisting model understanding and integration. This paper proposes a
structured, prompt-driven approach for LLM-assisted semantic alignment of SysML
v2 models. The core contribution lies in the iterative development of an
alignment approach and interaction prompts, incorporating model extraction,
semantic matching, and verification. The approach leverages SysML v2 constructs
such as alias, import, and metadata extensions to support traceable, soft
alignment integration. It is demonstrated with a GPT-based LLM through an
example of a measurement system. Benefits and limitations are discussed.

</details>


### [9] [A Systematic Mapping Study on Smart Cities Modeling Approaches](https://arxiv.org/abs/2508.16273)
*Maria Teresa Rossi,Martina De Sanctis,Ludovico Iovino,Manuel Wimmer*

Main category: cs.SE

TL;DR: 这篇论文通过系统性地图研究分析了智慧城市建模方法，发现智慧治理是最受关注的维度，并识别了主要的建模方法和研究趋势。


<details>
  <summary>Details</summary>
Motivation: 智慧城市作为一个多学科领域，需要理解不同建模方法在各个应用领域的使用情况，以获得对现有研究趋势的整体视角，并指导未来研究方向。

Method: 采用Petersen等人的系统性地图研究指南，对智慧城市建模方法进行系统性分析和分类，识别关键贡献、出版趋势和研究方向。

Result: 主要发现：(i)智慧治理是最受关注的维度；(ii)业务、架构和本体论建模方法最常用；(iii)大部分建模技术尚未在实际环境中得到验证；(iv)不同研究社群在多种发表渠道分享成果。

Conclusion: 该研究为智慧城市建模领域提供了完整的现状分析，可作为后续研究的基础，并对模型驱动工程社区产生积极影响。

Abstract: The Smart City concept was introduced to define an idealized city
characterized by automation and connection. It then evolved rapidly by
including further aspects, such as economy, environment. Since then, many
publications have explored various aspects of Smart Cities across different
application domains and research communities, acknowledging the
interdisciplinary nature of this subject. In particular, our interest focuses
on how smart cities are designed and modeled, as a whole or as regards with
their subsystems, when dealing with the accomplishment of the research goals in
this complex and heterogeneous domain. To this aim, we performed a systematic
mapping study on smart cities modeling approaches identifying the relevant
contributions (i) to get an overview of existing research approaches, (ii) to
identify whether there are any publication trends, and (iii) to identify
possible future research directions. We followed the guidelines for conducting
systematic mapping studies by Petersen et al. to analyze smart cities modeling
publications. Our analysis revealed the following main findings: (i) smart
governance is the most investigated and modeled smart city dimension; (ii) the
most used modeling approaches are business, architectural, and ontological
modeling approaches, spanning multiple application fields; (iii) the great
majority of existing technologies for modeling smart cities are not yet proven
in operational environments; (iv) diverse research communities publish their
results in a multitude of different venues which further motivates the
presented literature study. Researchers can use our results for better
understanding the state-of-the-art in modeling smart cities, and as a
foundation for further analysis of specific approaches about smart cities
modeling. Lastly, we also discuss the impact of our analysis for the
Model-Driven Engineering community.

</details>


### [10] [Metamorphic Coverage](https://arxiv.org/abs/2508.16307)
*Jinsheng Ba,Yuancheng Jiang,Manuel Rigger*

Main category: cs.SE

TL;DR: 提出了蜕变覆盖率(MC)作为评估蜕变测试方法的新指标，相比代码覆盖率和变异测试更有效且高效


<details>
  <summary>Details</summary>
Motivation: 现有代码覆盖率无法准确衡量代码验证程度，而变异测试计算成本过高，需要一种更好的评估蜕变测试方法有效性的指标

Method: 定义并系统评估蜕变覆盖率(MC)，该指标检查蜕变测试中测试输入对执行的不同代码，通过分析差异代码执行来评估测试效果

Result: MC与64个bug中的50个bug修复位置重叠，比行覆盖率对bug数量有更强的正相关性，灵敏度高4倍，计算时间比变异测试少359倍

Conclusion: MC是评估蜕变测试方法的有效指标，可用于指导测试用例生成，相比代码覆盖率能找到更多bug，具有广泛应用前景

Abstract: Metamorphic testing is a widely used methodology that examines an expected
relation between pairs of executions to automatically find bugs, such as
correctness bugs. We found that code coverage cannot accurately measure the
extent to which code is validated and mutation testing is computationally
expensive for evaluating metamorphic testing methods. In this work, we propose
Metamorphic Coverage (MC), a coverage metric that examines the distinct code
executed by pairs of test inputs within metamorphic testing. Our intuition is
that, typically, a bug can be observed if the corresponding code is executed
when executing either test input but not the other one, so covering more
differential code covered by pairs of test inputs might be more likely to
expose bugs. While most metamorphic testing methods have been based on this
general intuition, our work defines and systematically evaluates MC on five
widely used metamorphic testing methods for testing database engines,
compilers, and constraint solvers. The code measured by MC overlaps with the
bug-fix locations of 50 of 64 bugs found by metamorphic testing methods, and MC
has a stronger positive correlation with bug numbers than line coverage. MC is
4x more sensitive than line coverage in distinguishing testing methods'
effectiveness, and the average value of MC is 6x smaller than line coverage
while still capturing the part of the program that is being tested. MC required
359x less time than mutation testing. Based on a case study for an automated
database system testing approach, we demonstrate that when used for feedback
guidance, MC significantly outperforms code coverage, by finding 41\% more
bugs. Consequently, this work might have broad applications for assessing
metamorphic testing methods and improving test-case generation.

</details>


### [11] [SATORI: Static Test Oracle Generation for REST APIs](https://arxiv.org/abs/2508.16318)
*Juan C. Alonso,Alberto Martin-Lopez,Sergio Segura,Gabriele Bavota,Antonio Ruiz-Cortés*

Main category: cs.SE

TL;DR: SATORI是一个基于静态分析的REST API测试预言生成方法，通过分析OpenAPI规范和使用大语言模型来推断API的预期行为，能够自动生成大量有效的测试预言，并在17个工业API操作上达到74.3%的F1分数。


<details>
  <summary>Details</summary>
Motivation: 现有的REST API测试生成工具在测试数据生成方面很强，但在测试预言支持方面受限，通常只能检测崩溃、回归和规范不遵从等问题，需要更全面的测试预言生成方法。

Method: SATORI采用黑盒方法，通过分析OpenAPI规范中的响应字段属性（如名称和描述），使用大语言模型来推断API的预期行为，并扩展PostmanAssertify工具将生成的测试预言转换为可执行断言。

Result: 在12个工业API的17个操作上，SATORI能够为每个操作自动生成多达数百个有效的测试预言，F1分数达到74.3%，优于需要执行API的动态方法AGORA+（69.3%）。两种方法结合可发现90%的标注真实数据集中的预言。

Conclusion: SATORI证明了静态方法在测试预言生成方面的有效性，能够发现18个流行API中的bug并促使文档更新，同时静态和动态预言推断方法具有互补性，结合使用效果最佳。

Abstract: REST API test case generation tools are evolving rapidly, with growing
capabilities for the automated generation of complex tests. However, despite
their strengths in test data generation, these tools are constrained by the
types of test oracles they support, often limited to crashes, regressions, and
noncompliance with API specifications or design standards. This paper
introduces SATORI (Static API Test ORacle Inference), a black-box approach for
generating test oracles for REST APIs by analyzing their OpenAPI Specification.
SATORI uses large language models to infer the expected behavior of an API by
analyzing the properties of the response fields of its operations, such as
their name and descriptions. To foster its adoption, we extended the
PostmanAssertify tool to automatically convert the test oracles reported by
SATORI into executable assertions. Evaluation results on 17 operations from 12
industrial APIs show that SATORI can automatically generate up to hundreds of
valid test oracles per operation. SATORI achieved an F1-score of 74.3%,
outperforming the state-of-the-art dynamic approach AGORA+ (69.3%)-which
requires executing the API-when generating comparable oracle types. Moreover,
our findings show that static and dynamic oracle inference methods are
complementary: together, SATORI and AGORA+ found 90% of the oracles in our
annotated ground-truth dataset. Notably, SATORI uncovered 18 bugs in popular
APIs (Amadeus Hotel, Deutschebahn, FDIC, GitLab, Marvel, OMDb and Vimeo)
leading to documentation updates by the API maintainers.

</details>


### [12] [The (C)omprehensive (A)rchitecture (P)attern (I)ntegration method: Navigating the sea of technology](https://arxiv.org/abs/2508.16341)
*Sebastian Copei,Oliver Hohlfeld,Jens Kosiol*

Main category: cs.SE

TL;DR: CAPI方法通过诊断决策树推荐架构模式，降低技术选型复杂度，经学术和工业界验证有效


<details>
  <summary>Details</summary>
Motivation: 技术变化快速，单个开发者难以掌握所有工具，大型软件系统的工具选择和架构设计决策复杂

Method: 开发CAPI方法，使用诊断决策树根据用户需求推荐架构模式而非具体工具，通过模式抽象降低复杂度

Result: 技术选型主要通过试错进行，CAPI被一致认为有帮助，能够复现参与者的生产架构环境

Conclusion: CAPI方法有效解决了技术选型复杂度问题，通过模式推荐简化决策过程，得到学术和工业界验证

Abstract: The technological landscape changes daily, making it nearly impossible for a
single person to be aware of all trends or available tools that may or may not
be suitable for their software project. This makes tool selection and
architectural design decisions a complex problem, especially for large-scale
software systems. To tackle this issue, we introduce CAPI, the Comprehensive
Architecture Pattern Integration method that uses a diagnostic decision tree to
suggest architectural patterns depending on user needs. By suggesting patterns
instead of tools, the overall complexity for further decisions is lower as
there are fewer architectural patterns than tools due to the abstract nature of
patterns. Moreover, since tools implement patterns, each non-proposed pattern
reduces the number of tools to choose from, reducing complexity. We iteratively
developed CAPI, evaluating its understandability and usability in small studies
with academic participants. When satisfied with the outcome, we performed a
user-study with industry representatives to investigate the state-of-the-art in
technology selection and the effectiveness of our proposed method. We find that
technology selection is largely performed via trial and error, that CAPI is
uniformly perceived as helpful, and that CAPI is able to reproduce the
productive architectural environments of our participants.

</details>


### [13] [AetherCode: Evaluating LLMs' Ability to Win In Premier Programming Competitions](https://arxiv.org/abs/2508.16402)
*Zihan Wang,Jiaze Chen,Zhicheng Liu,Markus Mak,Yidi Du,Geonsik Moon,Luoqi Xu,Aaron Tua,Kunshuo Peng,Jiayi Lu,Mingfei Xia,Boqian Zou,Chenyang Ran,Guang Tian,Shoutai Zhu,Yeheng Duan,Zhenghui Kang,Zhenxing Lin,Shangshu Li,Qiang Luo,Qingshen Long,Zhiyong Chen,Yihan Xiao,Yurong Wu,Daoguang Zan,Yuyi Fu,Mingxuan Wang,Ming Ding*

Main category: cs.SE

TL;DR: AetherCode是一个新的编程基准测试，从IOI和ICPC等顶级编程竞赛中选取问题，提供更广覆盖和更高难度，通过自动生成和人工验证的测试套件来更准确评估大型语言模型的编程能力。


<details>
  <summary>Details</summary>
Motivation: 当前评估高估了大型语言模型的能力，存在基准问题难度不足、范围有限以及低质量测试用例导致的评估偏差问题。

Method: 从IOI和ICPC等顶级编程竞赛中选取问题，通过自动生成和人工验证的混合方式构建全面的测试套件。

Result: AetherCode提供了更准确的大型语言模型能力评估，揭示了LLM与精英人类程序员之间的显著差距。

Conclusion: AetherCode通过结合挑战性问题和严格评估，为代码推理研究设立了新标准，提供了更可靠的能力测量方法。

Abstract: Competitive programming has emerged as a critical benchmark for evaluating
the reasoning and coding capabilities of Large Language Models (LLMs). Despite
impressive progress on existing benchmarks, we argue that current evaluations
overstate model proficiency, masking a substantial gap between LLMs and elite
human programmers. This gap arises from two key limitations: insufficient
difficulty and scope of benchmark problems, and evaluation bias from
low-quality test cases. To address these shortcomings, we present AetherCode, a
new benchmark that draws problems from premier programming competitions such as
IOI and ICPC, offering broader coverage and higher difficulty. AetherCode
further incorporates comprehensive, expert-validated test suites built through
a hybrid of automated generation and human curation, ensuring rigorous and
reliable assessment. By combining challenging problem design with robust
evaluation, AetherCode provides a more faithful measure of LLM capabilities and
sets a new standard for future research in code reasoning.

</details>


### [14] [LLM-GUARD: Large Language Model-Based Detection and Repair of Bugs and Security Vulnerabilities in C++ and Python](https://arxiv.org/abs/2508.16419)
*Akshay Mhatre,Noujoud Nader,Patrick Diehl,Deepti Gupta*

Main category: cs.SE

TL;DR: 本研究对ChatGPT-4、Claude 3和LLaMA 4三种主流大语言模型在软件bug检测方面的能力进行了系统性评估，发现它们在语法和语义错误检测方面表现优异，但在复杂安全漏洞和大规模生产代码场景中性能下降。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在软件开发中的广泛应用，其在检测复杂安全相关漏洞方面的实际效果尚未得到充分探索，需要系统评估这些模型在真实场景中的bug检测能力。

Method: 使用包含基础编程错误、经典安全漏洞和生产级bug的C++和Python基准数据集，采用新颖的多阶段上下文感知提示协议模拟真实调试场景，并通过分级评分标准衡量检测准确性、推理深度和修复质量。

Result: 所有模型在识别范围明确的代码中的语法和语义问题方面表现出色，但在复杂安全漏洞和大规模生产代码场景中性能下降，其中ChatGPT-4和Claude 3通常提供比LLaMA 4更细致的上下文分析。

Conclusion: 大语言模型作为可靠代码分析工具既具有潜力又存在当前限制，适合教育用途和作为自动化代码审计的首轮审查工具，但在复杂安全漏洞检测方面仍需改进。

Abstract: Large Language Models (LLMs) such as ChatGPT-4, Claude 3, and LLaMA 4 are
increasingly embedded in software/application development, supporting tasks
from code generation to debugging. Yet, their real-world effectiveness in
detecting diverse software bugs, particularly complex, security-relevant
vulnerabilities, remains underexplored. This study presents a systematic,
empirical evaluation of these three leading LLMs using a benchmark of
foundational programming errors, classic security flaws, and advanced,
production-grade bugs in C++ and Python. The dataset integrates real code from
SEED Labs, OpenSSL (via the Suresoft GLaDOS database), and PyBugHive, validated
through local compilation and testing pipelines. A novel multi-stage,
context-aware prompting protocol simulates realistic debugging scenarios, while
a graded rubric measures detection accuracy, reasoning depth, and remediation
quality. Our results show that all models excel at identifying syntactic and
semantic issues in well-scoped code, making them promising for educational use
and as first-pass reviewers in automated code auditing. Performance diminishes
in scenarios involving complex security vulnerabilities and large-scale
production code, with ChatGPT-4 and Claude 3 generally providing more nuanced
contextual analyses than LLaMA 4. This highlights both the promise and the
present constraints of LLMs in serving as reliable code analysis tools.

</details>


### [15] [Using LLMs and Essence to Support Software Practice Adoption](https://arxiv.org/abs/2508.16445)
*Sonia Nicoletti,Paolo Ciancarini*

Main category: cs.SE

TL;DR: 研究通过结合Essence标准框架和LLMs，开发了专门的RAG聊天机器人来支持软件工程最佳实践的采用，在领域特定任务中表现超过通用LLMs。


<details>
  <summary>Details</summary>
Motivation: 当前NLP和AI研究集中于代码生成，而对于自动化支持最佳实践采用、工作方式演进和过程健康监控的关注不够。

Method: 开发了一个专门的聊天机器人，采用检索增强生成(RAG)系统从经过精选的知识库中检索相关上下文信息，使用四种不同LLMs创建多个配置。

Result: 系统在领域特定任务中一贯表现超过基线模型，通过检索上下文的相关性和生成响应的质量进行了评估。

Conclusion: 这项工作通过促进结构化软件工程知识的访问，有助于缩小理论框架与实际应用之间的差距，展示了LLM基础自动化在提升软件工程学习和决策能力方面的潜力。

Abstract: Recent advancements in natural language processing (NLP) have enabled the
development of automated tools that support various domains, including software
engineering. However, while NLP and artificial intelligence (AI) research has
extensively focused on tasks such as code generation, less attention has been
given to automating support for the adoption of best practices, the evolution
of ways of working, and the monitoring of process health. This study addresses
this gap by exploring the integration of Essence, a standard and thinking
framework for managing software engineering practices, with large language
models (LLMs). To this end, a specialised chatbot was developed to assist
students and professionals in understanding and applying Essence. The chatbot
employs a retrieval-augmented generation (RAG) system to retrieve relevant
contextual information from a curated knowledge base. Four different LLMs were
used to create multiple chatbot configurations, each evaluated both as a base
model and augmented with the RAG system. The system performance was evaluated
through both the relevance of retrieved context and the quality of generated
responses. Comparative analysis against the general-purpose LLMs demonstrated
that the proposed system consistently outperforms its baseline counterpart in
domain-specific tasks. By facilitating access to structured software
engineering knowledge, this work contributes to bridging the gap between
theoretical frameworks and practical application, potentially improving process
management and the adoption of software development practices. While further
validation through user studies is required, these findings highlight the
potential of LLM-based automation to enhance learning and decision-making in
software engineering.

</details>


### [16] [How Small is Enough? Empirical Evidence of Quantized Small Language Models for Automated Program Repair](https://arxiv.org/abs/2508.16499)
*Kazuki Kusama,Honglin Shu,Masanari Kondo,Yasutaka Kamei*

Main category: cs.SE

TL;DR: 小型语言模型(SLMs)在程序自动修复任务中可以达到与大型语言模型(LLMs)相当甚至更好的准确率，同时显著降低计算资源需求，int8量化进一步提升了效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然提高了程序自动修复的准确性，但计算资源需求过高，因此研究计算资源需求较低的小型语言模型在程序修复任务中的性能表现。

Method: 在QuixBugs基准测试上比较SLMs和LLMs的错误修复准确率，并分析int8量化对APR性能的影响。

Result: 最新SLMs修复错误的准确率与LLMs相当甚至更高，int8量化对APR准确率影响极小但显著降低了内存需求。

Conclusion: SLMs是LLMs在程序自动修复任务中的可行替代方案，提供有竞争力的准确率且计算成本更低，量化技术可在不牺牲效果的前提下进一步提升效率。

Abstract: Background: Large language models (LLMs) have greatly improved the accuracy
of automated program repair (APR) methods. However, LLMs are constrained by
high computational resource requirements. Aims: We focus on small language
models (SLMs), which perform well even with limited computational resources
compared to LLMs. We aim to evaluate whether SLMs can achieve competitive
performance in APR tasks. Method: We conducted experiments on the QuixBugs
benchmark to compare the bug-fixing accuracy of SLMs and LLMs. We also analyzed
the impact of int8 quantization on APR performance. Results: The latest SLMs
can fix bugs as accurately as--or even more accurately than--LLMs. Also, int8
quantization had minimal effect on APR accuracy while significantly reducing
memory requirements. Conclusions: SLMs present a viable alternative to LLMs for
APR, offering competitive accuracy with lower computational costs, and
quantization can further enhance their efficiency without compromising
effectiveness.

</details>


### [17] [ARSP: Automated Repair of Verilog Designs via Semantic Partitioning](https://arxiv.org/abs/2508.16517)
*Bingkun Yao,Ning Wang,Xiangfeng Liu,Yuxin Du,Yuchen Hu,Hong Gao,Zhe Jiang,Nan Guan*

Main category: cs.SE

TL;DR: ARSP是一个两阶段系统，通过语义引导的分段来缓解Verilog调试中的bug信号稀释问题，在工业规模模块上显著优于主流商业LLM和现有调试工具。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的自动化调试方法在工业规模模块上表现不佳，主要原因是长上下文中bug信号被大量无关代码稀释，分散了模型的注意力。

Method: 两阶段系统：分区LLM将模块分割成语义紧密的片段；修复LLM修补每个片段；编辑合并而不改变无关逻辑。使用合成数据框架生成片段级训练对来监督两个模型。

Result: ARSP达到77.92% pass@1和83.88% pass@5，优于Claude-3.7、Strider和MEIC等主流工具。语义分区相比整模块调试提升pass@1 11.6%和pass@5 10.2%。

Conclusion: 片段级范围缩减在基于LLM的Verilog调试中有效，语义分区显著提升了调试性能，解决了工业规模模块中的bug信号稀释问题。

Abstract: Debugging functional Verilog bugs consumes a significant portion of front-end
design time. While Large Language Models (LLMs) have demonstrated great
potential in mitigating this effort, existing LLM-based automated debugging
methods underperform on industrial-scale modules. A major reason for this is
bug signal dilution in long contexts, where a few bug-relevant tokens are
overwhelmed by hundreds of unrelated lines, diffusing the model's attention. To
address this issue, we introduce ARSP, a two-stage system that mitigates
dilution via semantics-guided fragmentation. A Partition LLM splits a module
into semantically tight fragments; a Repair LLM patches each fragment; edits
are merged without altering unrelated logic. A synthetic data framework
generates fragment-level training pairs spanning bug types, design styles, and
scales to supervise both models. Experiments show that ARSP achieves 77.92%
pass@1 and 83.88% pass@5, outperforming mainstream commercial LLMs including
Claude-3.7 and SOTA automated Verilog debugging tools Strider and MEIC. Also,
semantic partitioning improves pass@1 by 11.6% and pass@5 by 10.2% over
whole-module debugging, validating the effectiveness of fragment-level scope
reduction in LLM-based Verilog debugging.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [18] [Implementing Zero Trust Architecture to Enhance Security and Resilience in the Pharmaceutical Supply Chain](https://arxiv.org/abs/2508.15776)
*Saeid Ghasemshirazi,Ghazaleh Shirvani,Marziye Ranjbar Tavakoli,Bahar Ghaedi,Mohammad Amin Langarizadeh*

Main category: cs.CR

TL;DR: 本文探讨零信任架构在医药供应链网络安全中的变革潜力，通过持续验证、最小权限访问和数据中心安全等原则，应对数据泄露、假冒伪劣和供应链中断等挑战。


<details>
  <summary>Details</summary>
Motivation: 医药供应链面临日益严峻的网络安全威胁，这些威胁危及患者安全和运营连续性，需要创新的安全解决方案来保护这一关键生态系统。

Method: 采用零信任架构原则，包括持续验证、最小权限访问和数据中心安全，并通过真实案例研究展示成功实施经验。特别关注麻醉药品、高风险药物和易滥用物质的管理领域。

Result: 零信任架构能够显著提升医药供应链的安全性和韧性，提供增强的数据保护能力，并建立可靠的药品追溯系统以确保药品安全。

Conclusion: 通过实施零信任架构，医药行业能够强化其供应链，有效应对不断变化的网络威胁，确保关键医疗操作的可信度和安全性。

Abstract: The pharmaceutical supply chain faces escalating cybersecurity challenges
threatening patient safety and operational continuity. This paper examines the
transformative potential of zero trust architecture for enhancing security and
resilience within this critical ecosystem. We explore the challenges posed by
data breaches, counterfeiting, and disruptions and introduce the principles of
continuous verification, least-privilege access, and data-centric security
inherent in zero trust. Real-world case studies illustrate successful
implementations. Benefits include heightened security, data protection, and
adaptable resilience. As recognized by researchers and industrialists, a
reliable drug tracing system is crucial for ensuring drug safety throughout the
pharmaceutical production process. One of the most pivotal domains within the
pharmaceutical industry and its associated supply chains where zero trust can
be effectively implemented is in the management of narcotics, high-health-risk
drugs, and abusable substances. By embracing zero trust, the pharmaceutical
industry fortifies its supply chain against constantly changing cyber threats,
ensuring the trustworthiness of critical medical operations.

</details>


### [19] [Towards Stealthy and Effective Backdoor Attacks on Lane Detection: A Naturalistic Data Poisoning Approach](https://arxiv.org/abs/2508.15778)
*Yifan Liao,Yuxin Cao,Yedi Zhang,Wentao He,Yan Xiao,Xianglong Du,Zhiyong Huang,Jin Song Dong*

Main category: cs.CR

TL;DR: DBALD是一个基于扩散模型的自然化后门攻击框架，通过热图定位最优触发位置并生成视觉真实的触发器，在车道检测模型中实现了高攻击成功率和优异隐蔽性


<details>
  <summary>Details</summary>
Motivation: 现有车道检测后门攻击方法的触发器过于人工化和明显，缺乏实际应用价值，需要研究更生态有效的后门攻击来评估模型安全性

Method: 提出DBALD框架：1）基于热图分析找到最优触发位置；2）使用区域编辑扩散过程生成视觉合理的触发器；3）引入车道结构保持和场景一致性损失策略确保隐蔽性

Result: 在4个主流车道检测模型上，DBALD相比现有方法平均攻击成功率提升+10.87%，并显著增强了隐蔽性

Conclusion: 实验结果凸显了车道检测模型在面对真实世界后门威胁时确保鲁棒性的重大实际挑战，DBALD为评估模型安全性提供了有效工具

Abstract: Deep learning-based lane detection (LD) plays a critical role in autonomous
driving and advanced driver assistance systems. However, its vulnerability to
backdoor attacks presents a significant security concern. Existing backdoor
attack methods on LD often exhibit limited practical utility due to the
artificial and conspicuous nature of their triggers. To address this limitation
and investigate the impact of more ecologically valid backdoor attacks on LD
models, we examine the common data poisoning attack and introduce DBALD, a
novel diffusion-based data poisoning framework for generating naturalistic
backdoor triggers. DBALD comprises two key components: optimal trigger position
finding and stealthy trigger generation. Given the insight that attack
performance varies depending on the trigger position, we propose a
heatmap-based method to identify the optimal trigger location, with gradient
analysis to generate attack-specific heatmaps. A region-based editing diffusion
process is then applied to synthesize visually plausible triggers within the
most susceptible regions identified previously. Furthermore, to ensure scene
integrity and stealthy attacks, we introduce two loss strategies: one for
preserving lane structure and another for maintaining the consistency of the
driving scene. Consequently, compared to existing attack methods, DBALD
achieves both a high attack success rate and superior stealthiness. Extensive
experiments on 4 mainstream LD models show that DBALD exceeds state-of-the-art
methods, with an average success rate improvement of +10.87% and significantly
enhanced stealthiness. The experimental results highlight significant practical
challenges in ensuring model robustness against real-world backdoor threats in
LD.

</details>


### [20] [Uplifted Attackers, Human Defenders: The Cyber Offense-Defense Balance for Trailing-Edge Organizations](https://arxiv.org/abs/2508.15808)
*Benjamin Murphy,Twm Stone*

Main category: cs.CR

TL;DR: AI技术进步将使得过去安全投资不足的落后企业面临更大风险，攻击者将更容易发现漏洞并发动攻击，企业需要提升恢复速度和软件弹性。


<details>
  <summary>Details</summary>
Motivation: 探讨AI对网络安全攻防平衡的影响，特别是对于供应链中的落后企业（trailing-edge organizations）的风险，这些企业依赖遗留软件且安全投资不足。

Method: 分析AI技术对网络攻击经济学的影响，论证AI将如何降低攻击成本并增加攻击频率，同时提出改善防御能力的建议。

Result: AI的发展将导致攻击者能够更快地发现和利用漏洞，使得落后企业面临更多的威胁，传统的安全策略将无法应对。

Conclusion: 落后企业必须加强安全防御，提升恢复速度和软件弹性，政府和组织需提供支持以应对AI带来的新挑战。

Abstract: Advances in AI are widely understood to have implications for cybersecurity.
Articles have emphasized the effect of AI on the cyber offense-defense balance,
and commentators can be found arguing either that cyber will privilege
attackers or defenders. For defenders, arguments are often made that AI will
enable solutions like formal verification of all software--and for some
well-equipped companies, this may be true. This conversation, however, does not
match the reality for most companies. "Trailing-edge organizations," as we term
them, rely heavily on legacy software, poorly staff security roles, and
struggle to implement best practices like rapid deployment of security patches.
These decisions may be the result of corporate inertia, but may also be the
result of a seemingly-rational calculation that attackers may not bother
targeting a firm due to lack of economic incentives, and as a result,
underinvestment in defense will not be punished.
  This approach to security may have been sufficient prior to the development
of AI systems, but it is unlikely to remain viable in the near future. We argue
that continuing improvements in AI's capabilities poses additional risks on two
fronts: First, increased usage of AI will alter the economics of the marginal
cyberattack and expose these trailing-edge organizations to more attackers,
more frequently. Second, AI's advances will enable attackers to develop
exploits and launch attacks earlier than they can today--meaning that it is
insufficient for these companies to attain parity with today's leading
defenders, but must instead aim for faster remediation timelines and more
resilient software. The situation today portends a dramatically increased
number of attacks in the near future. Moving forward, we offer a range of
solutions for both organizations and governments to improve the defensive
posture of firms which lag behind their peers today.

</details>


### [21] [CIA+TA Risk Assessment for AI Reasoning Vulnerabilities](https://arxiv.org/abs/2508.15839)
*Yuksel Aydin*

Main category: cs.CR

TL;DR: 提出了认知网络安全框架，保护AI推理过程免受对抗性操纵，扩展了传统CIA安全三元组，建立了量化风险评估方法，并通过实证研究验证了架构依赖性。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统在关键决策中作用日益重要，面临利用推理机制而非技术基础设施的威胁，需要系统性地保护AI推理过程免受对抗性操纵。

Method: 建立认知网络安全学科框架，引入CIA+TA安全模型（增加信任和自主性），开发量化风险评估方法，并通过151名人类参与者和12,180次AI试验进行验证。

Result: 研究发现架构依赖性很强：相同防御措施对漏洞的影响从96%减少到135%放大不等，验证了框架的有效性。

Conclusion: 需要将认知渗透测试作为可信AI部署的治理要求，认知网络安全是传统网络安全和AI安全的重要补充。

Abstract: As AI systems increasingly influence critical decisions, they face threats
that exploit reasoning mechanisms rather than technical infrastructure. We
present a framework for cognitive cybersecurity, a systematic protection of AI
reasoning processes from adversarial manipulation. Our contributions are
threefold. First, we establish cognitive cybersecurity as a discipline
complementing traditional cybersecurity and AI safety, addressing
vulnerabilities where legitimate inputs corrupt reasoning while evading
conventional controls. Second, we introduce the CIA+TA, extending traditional
Confidentiality, Integrity, and Availability triad with Trust (epistemic
validation) and Autonomy (human agency preservation), requirements unique to
systems generating knowledge claims and mediating decisions. Third, we present
a quantitative risk assessment methodology with empirically-derived
coefficients, enabling organizations to measure cognitive security risks. We
map our framework to OWASP LLM Top 10 and MITRE ATLAS, facilitating operational
integration. Validation through previously published studies (151 human
participants; 12,180 AI trials) reveals strong architecture dependence:
identical defenses produce effects ranging from 96% reduction to 135%
amplification of vulnerabilities. This necessitates pre-deployment Cognitive
Penetration Testing as a governance requirement for trustworthy AI deployment.

</details>


### [22] [Unveiling Unicode's Unseen Underpinnings in Undermining Authorship Attribution](https://arxiv.org/abs/2508.15840)
*Robert Dilworth*

Main category: cs.CR

TL;DR: 本文探讨了公共通信中的隐私问题，指出即使采取各种匿名化措施，文本内容本身仍可通过风格计量学分析暴露作者身份，并提出了基于Unicode隐写术的对抗性防御策略。


<details>
  <summary>Details</summary>
Motivation: 公共通信中用户缺乏隐私保护，即使采用各种技术手段匿名化，文本内容的风格特征仍可能通过风格计量学分析泄露作者真实身份，这构成了严重的隐私威胁。

Method: 论文剖析了风格计量学技术，讨论了对抗性风格计量学的反制策略，并通过Unicode隐写术设计了增强的防御方法。

Result: 研究发现文本内容本身是一个明显的攻击向量，即使其他匿名化措施完备，仍可通过作者分析技术识别用户身份。

Conclusion: 公共通信中的隐私保护需要更全面的策略，Unicode隐写术等对抗性技术可以有效增强匿名性，抵御风格计量学分析攻击。

Abstract: When using a public communication channel -- whether formal or informal, such
as commenting or posting on social media -- end users have no expectation of
privacy: they compose a message and broadcast it for the world to see. Even if
an end user takes utmost precautions to anonymize their online presence --
using an alias or pseudonym; masking their IP address; spoofing their
geolocation; concealing their operating system and user agent; deploying
encryption; registering with a disposable phone number or email; disabling
non-essential settings; revoking permissions; and blocking cookies and
fingerprinting -- one obvious element still lingers: the message itself.
Assuming they avoid lapses in judgment or accidental self-exposure, there
should be little evidence to validate their actual identity, right? Wrong. The
content of their message -- necessarily open for public consumption -- exposes
an attack vector: stylometric analysis, or author profiling. In this paper, we
dissect the technique of stylometry, discuss an antithetical counter-strategy
in adversarial stylometry, and devise enhancements through Unicode
steganography.

</details>


### [23] [Self-Disguise Attack: Induce the LLM to disguise itself for AIGT detection evasion](https://arxiv.org/abs/2508.15848)
*Yinghan Zhou,Juan Wen,Wanli Peng,Zhengxian Wu,Ziwei Zhang,Yiming Xue*

Main category: cs.CR

TL;DR: 提出Self-Disguise Attack (SDA)方法，通过对抗特征提取器和检索式上下文示例优化器，让大语言模型主动伪装输出，有效降低AI生成文本检测率，同时保持文本质量。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成文本检测规避方法存在计算成本高和文本质量下降的问题，需要开发更高效的规避技术来提升检测器的实用性和可靠性。

Method: SDA包含两个核心组件：对抗特征提取器生成伪装特征，检索式上下文示例优化器从外部知识库检索相关示例，通过提示工程指导LLM生成抗检测文本。

Result: 实验表明SDA能有效降低多种AIGT检测器对三个不同LLM生成文本的平均检测准确率，同时保持生成文本质量。

Conclusion: SDA方法为AI生成文本检测规避提供了高效解决方案，在降低检测率的同时避免了传统方法的高计算成本和文本质量退化问题。

Abstract: AI-generated text (AIGT) detection evasion aims to reduce the detection
probability of AIGT, helping to identify weaknesses in detectors and enhance
their effectiveness and reliability in practical applications. Although
existing evasion methods perform well, they suffer from high computational
costs and text quality degradation. To address these challenges, we propose
Self-Disguise Attack (SDA), a novel approach that enables Large Language Models
(LLM) to actively disguise its output, reducing the likelihood of detection by
classifiers. The SDA comprises two main components: the adversarial feature
extractor and the retrieval-based context examples optimizer. The former
generates disguise features that enable LLMs to understand how to produce more
human-like text. The latter retrieves the most relevant examples from an
external knowledge base as in-context examples, further enhancing the
self-disguise ability of LLMs and mitigating the impact of the disguise process
on the diversity of the generated text. The SDA directly employs prompts
containing disguise features and optimized context examples to guide the LLM in
generating detection-resistant text, thereby reducing resource consumption.
Experimental results demonstrate that the SDA effectively reduces the average
detection accuracy of various AIGT detectors across texts generated by three
different LLMs, while maintaining the quality of AIGT.

</details>


### [24] [Linkage Attacks Expose Identity Risks in Public ECG Data Sharing](https://arxiv.org/abs/2508.15850)
*Ziyu Wang,Elahe Khatibi,Farshad Firouzi,Sanaz Rahimi Mousavi,Krishnendu Chakrabarty,Amir M. Rahmani*

Main category: cs.CR

TL;DR: 研究表明心电图数据存在严重的隐私风险，即使攻击者只有部分知识也能以85%的准确率重新识别个体，凸显了简单匿名化技术的不足。


<details>
  <summary>Details</summary>
Motivation: 随着心电图数据公开共享的增加，其生物特征属性使个体容易受到链接攻击，需要评估在实际条件下（攻击者只有部分知识）的隐私风险。

Method: 使用来自109名参与者的多样化真实世界数据集，在攻击者具有部分知识的现实条件下评估心电图隐私风险，通过最优置信度阈值进行分析。

Result: 在公共数据集中达到85%的个体重新识别准确率，总体误分类率为14.2%，其中15.6%的未知个体被误分类为已知，12.8%的已知个体被误分类为未知。

Conclusion: 研究结果强调了简单匿名化技术在防止重新识别方面的不足，表明即使有限的攻击者知识也能实现有效的身份链接，迫切需要采用差分隐私、访问控制和加密计算等隐私保护策略。

Abstract: The increasing availability of publicly shared electrocardiogram (ECG) data
raises critical privacy concerns, as its biometric properties make individuals
vulnerable to linkage attacks. Unlike prior studies that assume idealized
adversarial capabilities, we evaluate ECG privacy risks under realistic
conditions where attackers operate with partial knowledge. Using data from 109
participants across diverse real-world datasets, our approach achieves 85%
accuracy in re-identifying individuals in public datasets while maintaining a
14.2% overall misclassification rate at an optimal confidence threshold, with
15.6% of unknown individuals misclassified as known and 12.8% of known
individuals misclassified as unknown. These results highlight the inadequacy of
simple anonymization techniques in preventing re-identification, demonstrating
that even limited adversarial knowledge enables effective identity linkage. Our
findings underscore the urgent need for privacy-preserving strategies, such as
differential privacy, access control, and encrypted computation, to mitigate
re-identification risks while ensuring the utility of shared biosignal data in
healthcare applications.

</details>


### [25] [Securing Swarms: Cross-Domain Adaptation for ROS2-based CPS Anomaly Detection](https://arxiv.org/abs/2508.15865)
*Julia Boone,Fatemeh Afghah*

Main category: cs.CR

TL;DR: 开发了一种适用于网络物理系统（CPS）的自适应异常检测模型，使用域适应技术将网络流量环境中的攻击知识迁移到CPS环境中，无需标记数据即可检测攻击。


<details>
  <summary>Details</summary>
Motivation: 当前大多数入侵检测系统仅基于网络流量数据集进行训练和验证，忽略了CPS多层设计中其他系统层可能发生的独特攻击，导致CPS安全防护存在不足。

Method: 利用域适应技术，将已知攻击知识从纯网络流量环境迁移到CPS环境，开发无需预先标记数据的自适应异常检测模型。

Result: 使用结合网络、操作系统和ROS数据的先进CPS入侵数据集验证，模型在纯网络流量和CPS环境中均表现出色，能够检测不同类型攻击，性能优于其他异常检测方法。

Conclusion: 提出的域适应方法有效解决了CPS多层安全检测问题，为CPS安全防护提供了无需标记数据的自适应检测解决方案，在复杂攻击场景下表现出优越性能。

Abstract: Cyber-physical systems (CPS) are being increasingly utilized for critical
applications. CPS combines sensing and computing elements, often having
multi-layer designs with networking, computational, and physical interfaces,
which provide them with enhanced capabilities for a variety of application
scenarios. However, the combination of physical and computational elements also
makes CPS more vulnerable to attacks compared to network-only systems, and the
resulting impacts of CPS attacks can be substantial. Intelligent intrusion
detection systems (IDS) are an effective mechanism by which CPS can be secured,
but the majority of current solutions often train and validate on network
traffic-only datasets, ignoring the distinct attacks that may occur on other
system layers. In order to address this, we develop an adaptable CPS anomaly
detection model that can detect attacks within CPS without the need for
previously labeled data. To achieve this, we utilize domain adaptation
techniques that allow us to transfer known attack knowledge from a network
traffic-only environment to a CPS environment. We validate our approach using a
state-of-the-art CPS intrusion dataset that combines network, operating system
(OS), and Robot Operating System (ROS) data. Through this dataset, we are able
to demonstrate the effectiveness of our model across network traffic-only and
CPS environments with distinct attack types and its ability to outperform other
anomaly detection methods.

</details>


### [26] [Evolving k-Threshold Visual Cryptography Schemes](https://arxiv.org/abs/2508.15917)
*Xiaoli Zhuo,Xuehu Yan,Lintao Liu,Wei Yan*

Main category: cs.CR

TL;DR: 本文提出了首个适用于任意k值的(k,∞)视觉密码方案，基于随机网格技术，无需像素扩展且对比度更高


<details>
  <summary>Details</summary>
Motivation: 现有视觉密码方案主要针对有限参与者，缺乏适用于无限参与者的(k,∞)VCS构造方法，且存在像素扩展和对比度不足的问题

Method: 首先给出(k,∞)VCS的正式数学定义，然后基于随机网格技术构建适用于任意k的方案，并针对k=2,3进行优化，对k≥4提出对比度增强策略

Result: 理论分析和实验结果表明，所提出的方案在对比度方面表现优越，成功实现了无限参与者的视觉密码共享

Conclusion: 该研究填补了无限参与者视觉密码方案的空白，为实际应用提供了有效的解决方案，具有重要的理论和实践意义

Abstract: In evolving access structures, the number of participants is countably
infinite with no predetermined upper bound. While such structures have been
realized in secret sharing, research in secret image sharing has primarily
focused on visual cryptography schemes (VCS). However, there exists no
construction for $(k,\infty)$ VCS that applies to arbitrary $k$ values without
pixel expansion currently, and the contrast requires enhancement. In this
paper, we first present a formal mathematical definition of $(k,\infty)$ VCS.
Then, propose a $(k,\infty)$ VCS based on random grids that works for arbitrary
$k$. In addition, to further improve contrast, we develop optimized
$(k,\infty)$ VCS for $k=2$ and $3$, along with contrast enhancement strategies
for $k\geq 4$. Theoretical analysis and experimental results demonstrate the
superiority of our proposed schemes.

</details>


### [27] [Strategic Sample Selection for Improved Clean-Label Backdoor Attacks in Text Classification](https://arxiv.org/abs/2508.15934)
*Onur Alp Kirci,M. Emre Gursoy*

Main category: cs.CR

TL;DR: 本文提出了三种样本选择策略（Minimum、Above50、Below50）来提升干净标签场景下的后门攻击效果，通过在模型预测错误或低置信度的样本中注入后门触发器，显著提高了攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 干净标签后门攻击相比脏标签攻击更具挑战性，现有方法攻击成功率有限，需要更有效的样本选择策略来增强攻击效果。

Method: 提出三种样本选择策略：Minimum（选择模型预测置信度最低的样本）、Above50（选择模型预测错误且置信度高于50%的样本）、Below50（选择模型预测错误且置信度低于50%的样本），并将这些策略应用于四种经典后门攻击方法。

Result: 在三个数据集和四种模型上的实验表明，特别是Minimum策略显著提高了攻击成功率（ASR），且对模型干净准确率影响很小甚至没有影响，优于现有的BITE方法。

Conclusion: 所提出的样本选择策略能有效提升干净标签后门攻击的效果，Minimum策略表现最佳，为防御此类攻击提供了重要见解。

Abstract: Backdoor attacks pose a significant threat to the integrity of text
classification models used in natural language processing. While several
dirty-label attacks that achieve high attack success rates (ASR) have been
proposed, clean-label attacks are inherently more difficult. In this paper, we
propose three sample selection strategies to improve attack effectiveness in
clean-label scenarios: Minimum, Above50, and Below50. Our strategies identify
those samples which the model predicts incorrectly or with low confidence, and
by injecting backdoor triggers into such samples, we aim to induce a stronger
association between the trigger patterns and the attacker-desired target label.
We apply our methods to clean-label variants of four canonical backdoor attacks
(InsertSent, WordInj, StyleBkd, SynBkd) and evaluate them on three datasets
(IMDB, SST2, HateSpeech) and four model types (LSTM, BERT, DistilBERT,
RoBERTa). Results show that the proposed strategies, particularly the Minimum
strategy, significantly improve the ASR over random sample selection with
little or no degradation in the model's clean accuracy. Furthermore,
clean-label attacks enhanced by our strategies outperform BITE, a state of the
art clean-label attack method, in many configurations.

</details>


### [28] [PickleBall: Secure Deserialization of Pickle-based Machine Learning Models](https://arxiv.org/abs/2508.15987)
*Andreas D. Kellas,Neophytos Christou,Wenxin Jiang,Penghui Li,Laurent Simon,Yaniv David,Vasileios P. Kemerlis,James C. Davis,Junfeng Yang*

Main category: cs.CR

TL;DR: PickleBall是一个针对机器学习模型安全加载的工具，通过静态分析和动态策略执行来安全加载pickle格式模型，防止恶意代码执行


<details>
  <summary>Details</summary>
Motivation: Hugging Face等模型仓库中存在通过pickle格式模型传播恶意软件的风险，现有防御措施存在不足，44.9%的流行模型仍使用不安全的pickle格式

Method: PickleBall静态分析机器学习库源代码，生成自定义策略指定安全加载行为，并在加载时动态执行策略作为pickle模块的替代品

Result: PickleBall正确加载79.8%的良性pickle模型，拒绝100%恶意样本，相比现有扫描器表现更好，加载良性模型数量比最先进加载器多22%

Conclusion: PickleBall消除了恶意pickle模型任意函数调用的威胁，提高了攻击者依赖代码重用技术的门槛

Abstract: Machine learning model repositories such as the Hugging Face Model Hub
facilitate model exchanges. However, bad actors can deliver malware through
compromised models. Existing defenses such as safer model formats, restrictive
(but inflexible) loading policies, and model scanners have shortcomings: 44.9%
of popular models on Hugging Face still use the insecure pickle format, 15% of
these cannot be loaded by restrictive loading policies, and model scanners have
both false positives and false negatives. Pickle remains the de facto standard
for model exchange, and the ML community lacks a tool that offers transparent
safe loading.
  We present PickleBall to help machine learning engineers load pickle-based
models safely. PickleBall statically analyzes the source code of a given
machine learning library and computes a custom policy that specifies a safe
load-time behavior for benign models. PickleBall then dynamically enforces the
policy during load time as a drop-in replacement for the pickle module.
PickleBall generates policies that correctly load 79.8% of benign pickle-based
models in our dataset, while rejecting all (100%) malicious examples in our
dataset. In comparison, evaluated model scanners fail to identify known
malicious models, and the state-of-art loader loads 22% fewer benign models
than PickleBall. PickleBall removes the threat of arbitrary function invocation
from malicious pickle-based models, raising the bar for attackers to depend on
code reuse techniques.

</details>


### [29] [A Survey of Post-Quantum Cryptography Support in Cryptographic Libraries](https://arxiv.org/abs/2508.16078)
*Nadeem Ahmed,Lei Zhang,Aryya Gangopadhyay*

Main category: cs.CR

TL;DR: 这篇论文评估了主流开源加密库对NIST选定的量子计算安全算法的支持情况，发现各库准备程度差异显著，强调了加强研究、标准化和协调采用的紧迫性。


<details>
  <summary>Details</summary>
Motivation: 量子计算的快速发展对现代加密系统构成了严重威胁，必须向后量子加密过渡。需要评估当前加密库对PQC算法的支持情况以确保安全迁移。

Method: 研究分析了九个广泛使用的开源加密库（OpenSSL、wolfSSL等），重点考察它们对NIST选定的PQC决赛算法的实现情况。分析基于最新文档、发布说明和行业报告。

Result: 各加密库的准备程度存在显著差异。一些库已经集成PQC支持或有清晰的实施路线图，而另一些则落后，造成潜在的安全风险。研究识别了性能交易、实现安全性和实际采用障碍等关键挑战。

Conclusion: 研究强调了继续研究、标准化工作和协调采用策略的紧迫性，以确保安全迁移到量子者耐受的加密环境。

Abstract: The rapid advancement of quantum computing poses a significant threat to
modern cryptographic systems, necessitating the transition to Post-Quantum
Cryptography (PQC). This study evaluates the support for PQC algorithms within
nine widely used open-source cryptographic libraries -- OpenSSL, wolfSSL,
BoringSSL, LibreSSL, Bouncy Castle, libsodium, Crypto++, Botan, and MbedTLS --
focusing on their implementation of the NIST-selected PQC finalists:
CRYSTALS-Kyber, CRYSTALS-Dilithium, FALCON, and SPHINCS+. Our analysis, based
on the latest available documentation, release notes, and industry reports as
of early 2025, reveals a varied state of readiness across these libraries.
While some libraries have integrated PQC support or have clear implementation
roadmaps, others lag behind, creating potential security risks as quantum
threats become more imminent. We discuss key challenges, including performance
trade-offs, implementation security, and adoption hurdles in real-world
cryptographic applications. Our findings highlight the urgent need for
continued research, standardization efforts, and coordinated adoption
strategies to ensure a secure transition to the quantum-resistant cryptographic
landscape.

</details>


### [30] [SoK: Understanding the Fundamentals and Implications of Sensor Out-of-band Vulnerabilities](https://arxiv.org/abs/2508.16133)
*Shilin Xiao,Wenjun Zhu,Yan Jiang,Kai Wang,Peiwang Wang,Chen Yan,Xiaoyu Ji,Wenyuan Xu*

Main category: cs.CR

TL;DR: 提出了传感器带外(OOB)漏洞系统化框架，基于物理原理为传感器攻击面提供全面抽象，通过组件、传感器、系统三个层次分析漏洞，为构建更安全的传感器和CPS提供指导


<details>
  <summary>Details</summary>
Motivation: 现有对传感器硬件漏洞的研究呈现碎片化，缺乏系统化分析框架，且无限攻击信号空间使威胁抽象和防御复杂化

Method: 采用自下而上的系统化方法，在组件层面分析物理原理和限制，传感器层面分类已知攻击并评估实用性，系统层面分析CPS特性对OOB威胁的影响

Result: 建立了首个基于物理原理的传感器攻击面全面抽象框架，提供了对传感器硬件安全的基础性理解

Conclusion: 该框架为传感器设计者、安全研究人员和系统开发者提供了构建更安全传感器和CPS的指导和未来研究方向

Abstract: Sensors are fundamental to cyber-physical systems (CPS), enabling perception
and control by transducing physical stimuli into digital measurements. However,
despite growing research on physical attacks on sensors, our understanding of
sensor hardware vulnerabilities remains fragmented due to the ad-hoc nature of
this field. Moreover, the infinite attack signal space further complicates
threat abstraction and defense. To address this gap, we propose a
systematization framework, termed sensor out-of-band (OOB) vulnerabilities,
that for the first time provides a comprehensive abstraction for sensor attack
surfaces based on underlying physical principles. We adopt a bottom-up
systematization methodology that analyzes OOB vulnerabilities across three
levels. At the component level, we identify the physical principles and
limitations that contribute to OOB vulnerabilities. At the sensor level, we
categorize known attacks and evaluate their practicality. At the system level,
we analyze how CPS features such as sensor fusion, closed-loop control, and
intelligent perception impact the exposure and mitigation of OOB threats. Our
findings offer a foundational understanding of sensor hardware security and
provide guidance and future directions for sensor designers, security
researchers, and system developers aiming to build more secure sensors and CPS.

</details>


### [31] [Evaluating the Defense Potential of Machine Unlearning against Membership Inference Attacks](https://arxiv.org/abs/2508.16150)
*Aristeidis Sidiropoulos,Christos Chrysanthos Nikolaidis,Theodoros Tsiolakis,Nikolaos Pavlidis,Vasilis Perifanis,Pavlos S. Efraimidis*

Main category: cs.CR

TL;DR: 本研究系统评估了机器学习遗忘算法对成员推理攻击(MIA)脆弱性的影响，发现在图像和表格数据集中，遗忘算法和数据特性会显著影响模型对MIA的暴露程度。


<details>
  <summary>Details</summary>
Motivation: 机器学习遗忘主要设计为隐私保护机制，但其对成员推理攻击脆弱性的影响尚未明确，需要系统研究两者之间的关系。

Method: 使用四种不同数据集（两个图像数据集和两个表格数据集），应用最先进的机器学习遗忘算法，系统评估模型在遗忘后对成员推理攻击的脆弱性。

Result: 研究发现机器学习遗忘本身并非MIA的对策，但遗忘算法选择和数据特征会显著影响模型的脆弱性程度。

Conclusion: 这项工作为机器学习遗忘与成员推理攻击之间的相互作用提供了重要见解，为设计隐私保护的机器学习系统提供了指导。

Abstract: Membership Inference Attacks (MIAs) pose a significant privacy risk, as they
enable adversaries to determine whether a specific data point was included in
the training dataset of a model. While Machine Unlearning is primarily designed
as a privacy mechanism to efficiently remove private data from a machine
learning model without the need for full retraining, its impact on the
susceptibility of models to MIA remains an open question. In this study, we
systematically assess the vulnerability of models to MIA after applying
state-of-art Machine Unlearning algorithms. Our analysis spans four diverse
datasets (two from the image domain and two in tabular format), exploring how
different unlearning approaches influence the exposure of models to membership
inference. The findings highlight that while Machine Unlearning is not
inherently a countermeasure against MIA, the unlearning algorithm and data
characteristics can significantly affect a model's vulnerability. This work
provides essential insights into the interplay between Machine Unlearning and
MIAs, offering guidance for the design of privacy-preserving machine learning
systems.

</details>


### [32] [A Relay-Chain-Powered Ciphertext-Policy Attribute-Based Encryption in Intelligent Transportation Systems](https://arxiv.org/abs/2508.16189)
*Aparna Singh,Geetanjali Rathee,Chaker Abdelaziz Kerrache,Mohamed Chahine Ghanem*

Main category: cs.CR

TL;DR: 提出了一种结合中继链驱动加密系统和改进CP-ABE方案的新架构，用于智能交通系统中的安全数据共享，实现动态访问控制和低延迟通信。


<details>
  <summary>Details</summary>
Motivation: 智能交通系统的快速发展对安全、有效和上下文感知的数据共享机制提出了迫切需求，特别是在异构和地理分散的环境中需要解决动态访问和低延迟通信的双重挑战。

Method: 采用全球中继链上的上下文感知智能合约来验证数据属性（事件类型、时间、地理区域），并确定适当的加密策略级别。车载单元使用改进的CP-ABE进行端到端加密，将密文存储在本地化区域区块链中，避免对称加密或链下存储依赖。

Result: 该分布式可扩展模型在实时响应性和安全性之间提供了良好平衡，高敏感事件使用严格的多属性访问规则，常规更新使用轻量策略以减少处理负担，同时具备可追溯性和低延迟撤销功能。

Conclusion: 该架构非常适合在多管辖域运行的下一代车载网络，通过中继链实现全局执行管理，为智能交通系统提供了安全高效的数据共享解决方案。

Abstract: The very high growth of Intelligent Transportation Systems (ITS) has
generated an urgent requirement for secure, effective, and context-aware data
sharing mechanisms, especially over heterogeneous and geographically dispersed
settings. This work suggests a new architecture that combines a relay
chain-driven encryption system with a modified Ciphertext-Policy
Attribute-Based Encryption (CP-ABE) scheme to tackle the double impediment of
dynamic access and low-latency communication. The model proposes a
context-aware smart contract on a worldwide relay chain that checks against
data properties, including event type, time, and geographical region, to
specify the suitable level of encryption policy. From such relay-directed
judgment, On-Board Units (OBUs) encrypt data end-to-end by utilising CP-ABE and
store ciphertext inside localised regional blockchains, preventing dependence
on symmetric encryption or off-chain storage. High-sensitivity events are
secured with firm, multi-attribute access rules, whereas common updates use
light policies to help reduce processing burdens. The crypto system also adds
traceability and low-latency revocation, with global enforcement managed
through the relay chain. This distributed, scalable model provides a proper
balance between responsiveness in real time and security and is extremely apt
for next-gen vehicular networks that function across multi-jurisdictional
domains.

</details>


### [33] [How to Beat Nakamoto in the Race](https://arxiv.org/abs/2508.16202)
*Shu-Jie Cao,Dongning Guo*

Main category: cs.CR

TL;DR: 本文研究了有界网络延迟下的工作量证明Nakamoto共识，提出了最优攻击策略并计算了安全违规的确切概率


<details>
  <summary>Details</summary>
Motivation: 解决区块链安全中的两个长期问题：在给定区块确认延迟下，对手如何最有效地攻击区块安全性，以及由此产生的安全违规概率是多少

Method: 引入马尔可夫决策过程(MDP)框架来精确描述系统状态，提出并证明最优攻击策略"诱饵与切换"，使用马尔科夫链分析计算安全违规的确切概率

Result: 确定了最优攻击策略，计算了任意确认深度下的安全违规概率，揭示了网络延迟、确认规则和区块链安全之间的相互作用

Conclusion: 该研究为Nakamoto共识在有限网络延迟下的安全性提供了精确分析框架和量化结果，对区块链安全设计具有重要指导意义

Abstract: This paper studies proof-of-work Nakamoto consensus under bounded network
delays, settling two long-standing questions in blockchain security: How can an
adversary most effectively attack block safety under a given block confirmation
latency? And what is the resulting probability of safety violation? A Markov
decision process (MDP) framework is introduced to precise characterize the
system state (including the tree and timings of all blocks mined), the
adversary's potential actions, and the state transitions due to the adversarial
action and the random block arrival processes. An optimal attack, called
bait-and-switch, is proposed and proved to maximize the adversary's chance of
violating block safety by "beating Nakamoto in the race". The exact probability
of this violation is calculated for any confirmation depth using Markov chain
analysis, offering fresh insights into the interplay of network delay,
confirmation rules, and blockchain security.

</details>


### [34] [Confusion is the Final Barrier: Rethinking Jailbreak Evaluation and Investigating the Real Misuse Threat of LLMs](https://arxiv.org/abs/2508.16347)
*Yu Yan,Sheng Sun,Zhe Wang,Yijun Lin,Zenghao Duan,zhifei zheng,Min Liu,Zhiyi yin,Jianping Zhang*

Main category: cs.CR

TL;DR: 研究发现大语言模型存在安全评估与现实威胁之间的差距，越狱成功率与有害知识掌握程度不匹配，现有评判框架过度关注毒性语言模式。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的发展，虽然已有研究揭示了其越狱漏洞，但尚不清楚模型是否真正内化了处理现实犯罪的知识，还是仅仅被迫模拟有毒语言模式。这种模糊性引发了关于越狱成功是否源于模型与评判者之间的幻觉循环的担忧。

Method: 通过解耦越狱技术的使用，构建知识密集型问答来调查大语言模型在危险知识掌握、有害任务规划效用和危害性判断鲁棒性方面的滥用威胁。

Result: 实验显示大语言模型的越狱成功率与有害知识掌握程度存在不匹配，现有LLM-as-a-judge框架倾向于将危害性判断锚定在毒性语言模式上。

Conclusion: 研究揭示了现有大语言模型安全评估与现实世界威胁潜力之间的差距，表明需要更全面的安全评估方法。

Abstract: With the development of Large Language Models (LLMs), numerous efforts have
revealed their vulnerabilities to jailbreak attacks. Although these studies
have driven the progress in LLMs' safety alignment, it remains unclear whether
LLMs have internalized authentic knowledge to deal with real-world crimes, or
are merely forced to simulate toxic language patterns. This ambiguity raises
concerns that jailbreak success is often attributable to a hallucination loop
between jailbroken LLM and judger LLM. By decoupling the use of jailbreak
techniques, we construct knowledge-intensive Q\&A to investigate the misuse
threats of LLMs in terms of dangerous knowledge possession, harmful task
planning utility, and harmfulness judgment robustness. Experiments reveal a
mismatch between jailbreak success rates and harmful knowledge possession in
LLMs, and existing LLM-as-a-judge frameworks tend to anchor harmfulness
judgments on toxic language patterns. Our study reveals a gap between existing
LLM safety assessments and real-world threat potential.

</details>


### [35] [Temperature-Resilient Reconfigurable PUF with Dual-Pulse Modulation based on SOT-MRAM Chip](https://arxiv.org/abs/2508.16405)
*Min Wang,Chuanpeng Jiang,Zhaohao Wang,Zhengyi Hou,Zhongkui Zhang,Yuanfu Zhao,Hongxi Liu,Weisheng Zhao*

Main category: cs.CR

TL;DR: 基于SOT-MRAM载体的双脉冲重构策略，实现了在工业级工作温度范围内无需实时温度反馈的实时重构物理不可克隆功能


<details>
  <summary>Details</summary>
Motivation: 物联网时代需要硬件安全解决方案，可重构PUF能提供动态场景下的增强安全能力，但现有技术难以实现独立于环境条件（特别是工作温度）的实时重构

Method: 提出基于SOT-MRAM载体的双脉冲重构策略，通过该策略有效扩大工作窗口并展示优异的PUF指标

Result: 实验结果表明，该设计在工业级工作温度范围内实现了实时重构，无需实时温度的动态反馈

Conclusion: 所提出的SOT-MRAM rPUF设计为下一代物联网保护架构奠定了坚实基础

Abstract: In the Internet of Things (IoT) era, hardware-based security solutions have
become an emerging choice for enhancing end-terminal information security. As
one of the hardware technologies, physical unclonable functions (PUFs) utilize
the inherent variations in the manufacturing process to generate cryptographic
keys. Reconfigurable PUFs (rPUFs), characterized by updating cryptographic
keys, offer enhanced security ability for protecting massive amounts of data in
dynamic operational scenarios. The core challenge lies in achieving real-time
reconfiguration independent of environmental conditions, particularly operating
temperature, which has rarely been investigated and addressed. In this study,
we propose a dual-pulse reconfiguration strategy based on SOT-MRAM carriers,
which effectively widens the operating window and exhibits excellent PUF
metrics. Experimental results demonstrate that our design achieves real-time
reconfiguration across industrial-grade operating temperature ranges, without
the need for dynamic feedback of real-time temperature. The proposed SOT-MRAM
rPUF design lays a solid foundation for next-generation IoT protection
architectures.

</details>


### [36] [Retrieval-Augmented Defense: Adaptive and Controllable Jailbreak Prevention for Large Language Models](https://arxiv.org/abs/2508.16406)
*Guangyu Yang,Jinghong Chen,Jingbiao Mei,Weizhe Lin,Bill Byrne*

Main category: cs.CR

TL;DR: RAD框架通过检索增强生成技术，利用已知攻击样本数据库来检测越狱攻击，无需重新训练即可适应新攻击策略，并在安全性和实用性之间实现可控平衡。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型容易受到越狱攻击，现有防御系统面临两大挑战：需要低成本适应新兴攻击策略，以及平衡安全性和实用性。

Method: 提出检索增强防御(RAD)框架，将已知攻击样本数据库整合到检索增强生成中，用于推断恶意用户查询和攻击策略。

Result: 在StrongREJECT数据集上的实验表明，RAD显著降低了PAP和PAIR等强越狱攻击的有效性，同时对良性查询保持低拒绝率。

Conclusion: RAD提供了一种无需训练即可更新防御策略的方法，并通过可控方式实现了鲁棒的安全-效用权衡。

Abstract: Large Language Models (LLMs) remain vulnerable to jailbreak attacks, which
attempt to elicit harmful responses from LLMs. The evolving nature and
diversity of these attacks pose many challenges for defense systems, including
(1) adaptation to counter emerging attack strategies without costly retraining,
and (2) control of the trade-off between safety and utility. To address these
challenges, we propose Retrieval-Augmented Defense (RAD), a novel framework for
jailbreak detection that incorporates a database of known attack examples into
Retrieval-Augmented Generation, which is used to infer the underlying,
malicious user query and jailbreak strategy used to attack the system. RAD
enables training-free updates for newly discovered jailbreak strategies and
provides a mechanism to balance safety and utility. Experiments on StrongREJECT
show that RAD substantially reduces the effectiveness of strong jailbreak
attacks such as PAP and PAIR while maintaining low rejection rates for benign
queries. We propose a novel evaluation scheme and show that RAD achieves a
robust safety-utility trade-off across a range of operating points in a
controllable manner.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [37] [T-ILR: a Neurosymbolic Integration for LTLf](https://arxiv.org/abs/2508.15943)
*Riccardo Andreoni,Andrei Buliga,Alessandro Daniele,Chiara Ghidini,Marco Montali,Massimiliano Ronzani*

Main category: cs.AI

TL;DR: 提出了T-ILR方法，将时序逻辑规范直接整合到深度学习架构中，用于序列任务，相比现有方法在准确性和计算效率上都有提升


<details>
  <summary>Details</summary>
Motivation: 现有方法主要处理静态领域的符号知识集成，而处理时序逻辑规范的方法仍然不足，特别是需要显式表示有限状态自动机的方法存在局限性

Method: 扩展迭代局部优化(ILR)神经符号算法，利用模糊LTLf解释，提出时序迭代局部优化(T-ILR)方法，将有限迹上的线性时序逻辑(LTLf)规范直接整合到深度学习架构

Result: 在时序神经符号架构基准测试中，T-ILR方法在图像序列分类任务上表现出比现有方法更高的准确性和计算效率

Conclusion: T-ILR方法成功地将时序逻辑规范整合到深度学习框架中，为处理时序知识的序列任务提供了有效的神经符号解决方案

Abstract: State-of-the-art approaches for integrating symbolic knowledge with deep
learning architectures have demonstrated promising results in static domains.
However, methods to handle temporal logic specifications remain underexplored.
The only existing approach relies on an explicit representation of a
finite-state automaton corresponding to the temporal specification. Instead, we
aim at proposing a neurosymbolic framework designed to incorporate temporal
logic specifications, expressed in Linear Temporal Logic over finite traces
(LTLf), directly into deep learning architectures for sequence-based tasks. We
extend the Iterative Local Refinement (ILR) neurosymbolic algorithm, leveraging
the recent introduction of fuzzy LTLf interpretations. We name this proposed
method Temporal Iterative Local Refinement (T-ILR). We assess T-ILR on an
existing benchmark for temporal neurosymbolic architectures, consisting of the
classification of image sequences in the presence of temporal knowledge. The
results demonstrate improved accuracy and computational efficiency compared to
the state-of-the-art method.

</details>


### [38] [CoFE: A Framework Generating Counterfactual ECG for Explainable Cardiac AI-Diagnostics](https://arxiv.org/abs/2508.16033)
*Jong-Hwan Jang,Junho Song,Yong-Yeon Jo*

Main category: cs.AI

TL;DR: 提出了一种可解释性AI框架CoFE，通过生成反事实ECG来解释AI-ECG模型的预测决策，帮助临床应用。


<details>
  <summary>Details</summary>
Motivation: 解决AI基础ECG预测模型在临床实践中的可解释性需求，提高模型透明度和临床决策效果。

Method: 发展了反事实ECG生成框架CoFE，用于演示ECG特征如振幅和间隔如何影响模型预测。通过房颤分类和钾水平回归两个案例研究进行验证。

Result: CoFE框架能够揭示ECG信号中与临床知识相符的特征变化，明确显示有效特征的位置和对模型预测的影响机制。

Conclusion: 该框架有助于提高AI-ECG模型的可解释性，支持更有效的临床决策。

Abstract: Recognizing the need for explainable AI (XAI) approaches to enable the
successful integration of AI-based ECG prediction models (AI-ECG) into clinical
practice, we introduce a framework generating \textbf{Co}unter\textbf{F}actual
\textbf{E}CGs (i,e., named CoFE) to illustrate how specific features, such as
amplitudes and intervals, influence the model's predictive decisions. To
demonstrate the applicability of the CoFE, we present two case studies: atrial
fibrillation classification and potassium level regression models. The CoFE
reveals feature changes in ECG signals that align with the established clinical
knowledge. By clarifying both \textbf{where valid features appear} in the ECG
and \textbf{how they influence the model's predictions}, we anticipate that our
framework will enhance the interpretability of AI-ECG models and support more
effective clinical decision-making. Our demonstration video is available at:
https://www.youtube.com/watch?v=YoW0bNBPglQ.

</details>


### [39] [MMAPG: A Training-Free Framework for Multimodal Multi-hop Question Answering via Adaptive Planning Graphs](https://arxiv.org/abs/2508.16051)
*Yiheng Hu,Xiaoyang Wang,Qing Liu,Xiwei Xu,Qian Fu,Wenjie Zhang,Liming Zhu*

Main category: cs.AI

TL;DR: 提出了一种基于自适应规划图的训练免费多模态多跳问答框架，通过动态规划、检索和推理模块，无需训练即可达到或超越现有训练依赖模型的性能


<details>
  <summary>Details</summary>
Motivation: 现有多模态多跳问答方法依赖顺序检索推理，容易因中间步骤错误而失败，且多模态模型训练成本高昂

Method: 使用自适应规划图框架，包含规划模块（分析当前状态决定下一步行动）、检索模块（模态特定策略处理不同数据类型）和推理模块，支持动态灵活的推理路径探索

Result: 在MultimodalQA和WebQA数据集上的实验表明，该方法无需训练即可匹配或超越依赖训练的现有模型性能

Conclusion: 该方法成功解决了多模态多跳问答中的错误传播和训练成本问题，实现了无需训练的高效多模态信息集成

Abstract: Multimodal Multi-hop question answering requires integrating information from
diverse sources, such as images and texts, to derive answers. Existing methods
typically rely on sequential retrieval and reasoning, where each step builds on
the previous output. However, this single-path paradigm makes them vulnerable
to errors due to misleading intermediate steps. Moreover, developing multimodal
models can be computationally expensive, often requiring extensive training. To
address these limitations, we propose a training-free framework guided by an
Adaptive Planning Graph, which consists of planning, retrieval and reasoning
modules. The planning module analyzes the current state of the Adaptive
Planning Graph, determines the next action and where to expand the graph, which
enables dynamic and flexible exploration of reasoning paths. To handle
retrieval of text to unspecified target modalities, we devise modality-specific
strategies that dynamically adapt to distinct data types. Our approach
preserves the characteristics of multimodal information without costly
task-specific training, enabling seamless integration with up-to-date models.
Finally, the experiments on MultimodalQA and WebQA show that our approach
matches or outperforms existing models that rely on training.

</details>


### [40] [Generative Foundation Model for Structured and Unstructured Electronic Health Records](https://arxiv.org/abs/2508.16054)
*Sonish Sivarajkumar,Hang Zhang,Yuelyu Ji,Maneesh Bilalpur,Xizhi Wu,Chenyu Li,Min Gu Kwak,Shyam Visweswaran,Yanshan Wang*

Main category: cs.AI

TL;DR: GDP是一个多模态基础模型，通过CNN-Transformer编码器处理结构化EHR时间序列数据，并与非结构化临床文本融合，在临床预测和叙事生成任务上均表现出色。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录(EHRs)包含丰富的多模态临床数据，但现有方法简单地将数值数据序列化为文本会丢失时间和定量细节，需要更好的多模态融合方法来提升临床任务性能。

Method: 采用两阶段训练：1)生成式预训练，通过掩码特征预测和下一时间步预测学习时间动态；2)多任务微调，用于临床预测任务。模型使用CNN-Transformer编码器处理结构化时间序列，通过跨模态注意力与LLaMA解码器融合。

Result: 在MIMIC-IV数据集上，临床预测任务表现优异：心衰AUROC=0.923，2型糖尿病AUROC=0.817，30天再入院AUROC=0.627。叙事生成任务ROUGE-L=0.135，BERTScore-F1=0.545。人工评估显示在忠实性、流畅性和临床实用性方面得分最高。

Conclusion: GDP证明了单一多模态基础模型能够同时进行临床事件预测和高质量临床叙事生成，其灵活架构可扩展到更多模态，有望减少医院文档工作量而不牺牲准确性。

Abstract: Electronic health records (EHRs) are rich clinical data sources but complex
repositories of patient data, spanning structured elements (demographics,
vitals, lab results, codes), unstructured clinical notes and other modalities
of data. Harnessing this heterogeneity is critical for improving patient
outcomes. Recent advances in large language models (LLMs) have enabled
foundation models that can learn from multiple data modalities and support
clinical tasks. However, most current approaches simply serialize numeric EHR
data into text, which risks losing temporal and quantitative detail. We
introduce Generative Deep Patient (GDP), a multimodal foundation model that
natively encodes structured EHR time-series via a CNN-Transformer encoder and
fuses it with unstructured EHRs through cross-modal attention into a
LLaMA-based decoder. GDP is trained in two stages: (1) generative pretraining,
where it learns to produce clinical narratives from raw patient timelines while
also performing masked feature prediction (MFP) and next time-step prediction
(NTP) to capture temporal dynamics; and (2) multi-task fine-tuning for
clinically meaningful predictions (e.g., heart failure, type 2 diabetes, 30-day
readmission). In clinical prediction, GDP demonstrated superior performance on
MIMIC-IV: heart failure AUROC = 0.923, type 2 diabetes AUROC = 0.817, and
30-day readmission AUROC = 0.627. For narrative generation, GDP achieved
ROUGE-L = 0.135 and BERTScore-F1 = 0.545. In a blinded human evaluation,
GDP-Instruct scored highest on faithfulness, fluency, and overall clinical
utility, suggesting reduced hospital documentation workload without sacrificing
accuracy. Our results demonstrate that a single multimodal foundation model can
both predict clinically actionable events and generate high-quality clinical
narratives. Furthermore, GDP's flexible architecture can be extended to
additional modalities.

</details>


### [41] [Urban Comfort Assessment in the Era of Digital Planning: A Multidimensional, Data-driven, and AI-assisted Framework](https://arxiv.org/abs/2508.16057)
*Sijie Yang,Binyu Lei,Filip Biljecki*

Main category: cs.AI

TL;DR: 本文探讨数字规划中城市舒适度的理论解释和评估方法，重点关注多维分析、数据支持和AI辅助三个关键维度


<details>
  <summary>Details</summary>
Motivation: 确保宜居性和舒适性是城市规划的基本目标，但目前缺乏对城市舒适度的明确定义和综合评估框架

Method: 通过理论解释和方法论研究，强调多维分析、数据支持和AI辅助三个维度来评估城市舒适度

Result: 提出了城市舒适度评估的理论框架和方法论路径

Conclusion: 研究为数字规划中的城市舒适度评估提供了理论基础和方法指导，有助于推动更全面的城市舒适度量化分析

Abstract: Ensuring liveability and comfort is one of the fundamental objectives of
urban planning. Numerous studies have employed computational methods to assess
and quantify factors related to urban comfort such as greenery coverage,
thermal comfort, and walkability. However, a clear definition of urban comfort
and its comprehensive evaluation framework remain elusive. Our research
explores the theoretical interpretations and methodologies for assessing urban
comfort within digital planning, emphasising three key dimensions:
multidimensional analysis, data support, and AI assistance.

</details>


### [42] [Integrating Time Series into LLMs via Multi-layer Steerable Embedding Fusion for Enhanced Forecasting](https://arxiv.org/abs/2508.16059)
*Zhuomin Chen,Dan Li,Jiahui Zhou,Shunyu Wu,Haozheng Ye,Jian Lou,See-Kiong Ng*

Main category: cs.AI

TL;DR: MSEF框架通过多层可引导嵌入融合，解决了LLMs在时间序列预测中TS信息在深层逐渐消失的问题，显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法将时间序列信息浅层集成到LLMs中，导致TS表示在深层逐渐消失，文本嵌入与TS表示之间适应效果不佳。

Method: 利用现成的时间序列基础模型提取语义丰富的嵌入，通过层特定引导向量与LLM中间文本表示融合，实现跨层TS信息访问。

Result: 在7个基准测试中，MSEF相比基线平均减少31.8%的MSE，表现出显著的性能提升。

Conclusion: MSEF通过多层TS信息融合机制有效解决了深层信息丢失问题，为LLMs在时间序列预测中的应用提供了新思路。

Abstract: Time series (TS) data are ubiquitous across various application areas,
rendering time series forecasting (TSF) a fundamental task. With the astounding
advances in large language models (LLMs), a variety of methods have been
developed to adapt LLMs for time series forecasting. Despite unlocking the
potential of LLMs in comprehending TS data, existing methods are inherently
constrained by their shallow integration of TS information, wherein LLMs
typically access TS representations at shallow layers, primarily at the input
layer. This causes the influence of TS representations to progressively fade in
deeper layers and eventually leads to ineffective adaptation between textual
embeddings and TS representations. In this paper, we propose the Multi-layer
Steerable Embedding Fusion (MSEF), a novel framework that enables LLMs to
directly access time series patterns at all depths, thereby mitigating the
progressive loss of TS information in deeper layers. Specifically, MSEF
leverages off-the-shelf time series foundation models to extract semantically
rich embeddings, which are fused with intermediate text representations across
LLM layers via layer-specific steering vectors. These steering vectors are
designed to continuously optimize the alignment between time series and textual
modalities and facilitate a layer-specific adaptation mechanism that ensures
efficient few-shot learning capabilities. Experimental results on seven
benchmarks demonstrate significant performance improvements by MSEF compared
with baselines, with an average reduction of 31.8% in terms of MSE. The code is
available at https://github.com/One1sAll/MSEF.

</details>


### [43] [InMind: Evaluating LLMs in Capturing and Applying Individual Human Reasoning Styles](https://arxiv.org/abs/2508.16072)
*Zizhen Li,Chuanhao Li,Yibin Wang,Qi Chen,Diping Song,Yukang Feng,Jianwen Sun,Jiaxin Ai,Fanrui Zhang,Mingzhu Sun,Kaipeng Zhang*

Main category: cs.AI

TL;DR: InMind是一个评估LLM在社交推理游戏中捕捉和应用个性化推理风格的框架，发现通用LLM依赖词汇线索而难以适应动态策略，推理增强型LLM展现出风格敏感推理的早期迹象。


<details>
  <summary>Details</summary>
Motivation: 现有评估忽略了影响人们在社交情境中解释和行动的个性化推理风格，需要测试LLM是否能捕捉和应用这些个性化推理方式。

Method: 提出InMind框架，通过增强结构化游戏数据（回合级策略追踪和赛后反思），在观察者和参与者模式下收集数据，支持四个认知驱动的评估任务。

Result: 通用LLM（包括GPT-4o）经常依赖词汇线索，难以在时间游戏中锚定反思或适应演化策略；推理增强型LLM（如DeepSeek-R1）显示出风格敏感推理的早期迹象。

Conclusion: 当前LLM在个体化适应性推理能力上存在关键局限，InMind框架是朝着认知对齐的人机交互迈出的一步。

Abstract: LLMs have shown strong performance on human-centric reasoning tasks. While
previous evaluations have explored whether LLMs can infer intentions or detect
deception, they often overlook the individualized reasoning styles that
influence how people interpret and act in social contexts. Social deduction
games (SDGs) provide a natural testbed for evaluating individualized reasoning
styles, where different players may adopt diverse but contextually valid
reasoning strategies under identical conditions. To address this, we introduce
InMind, a cognitively grounded evaluation framework designed to assess whether
LLMs can capture and apply personalized reasoning styles in SDGs. InMind
enhances structured gameplay data with round-level strategy traces and
post-game reflections, collected under both Observer and Participant modes. It
supports four cognitively motivated tasks that jointly evaluate both static
alignment and dynamic adaptation. As a case study, we apply InMind to the game
Avalon, evaluating 11 state-of-the-art LLMs. General-purpose LLMs, even GPT-4o
frequently rely on lexical cues, struggling to anchor reflections in temporal
gameplay or adapt to evolving strategies. In contrast, reasoning-enhanced LLMs
like DeepSeek-R1 exhibit early signs of style-sensitive reasoning. These
findings reveal key limitations in current LLMs' capacity for individualized,
adaptive reasoning, and position InMind as a step toward cognitively aligned
human-AI interaction.

</details>


### [44] [IR-Agent: Expert-Inspired LLM Agents for Structure Elucidation from Infrared Spectra](https://arxiv.org/abs/2508.16112)
*Heewoong Noh,Namkyeong Lee,Gyoung S. Na,Kibum Kim,Chanyoung Park*

Main category: cs.AI

TL;DR: IR-Agent是一个新颖的多智能体框架，用于从红外光谱进行分子结构解析，模拟专家分析流程并具有良好扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有红外光谱分析方法未能充分反映专家分析过程，且缺乏整合多种化学知识的灵活性，无法满足实际分析需求。

Method: 提出多智能体框架，每个智能体专门负责红外光谱解释的特定方面，通过互补角色实现集成推理。

Result: 实验表明IR-Agent不仅提高了实验红外光谱的基线性能，还对各种形式的化学信息表现出强适应性。

Conclusion: 该框架能够有效模拟专家驱动的红外分析过程，提高结构解析的准确性，并具有良好的扩展性。

Abstract: Spectral analysis provides crucial clues for the elucidation of unknown
materials. Among various techniques, infrared spectroscopy (IR) plays an
important role in laboratory settings due to its high accessibility and low
cost. However, existing approaches often fail to reflect expert analytical
processes and lack flexibility in incorporating diverse types of chemical
knowledge, which is essential in real-world analytical scenarios. In this
paper, we propose IR-Agent, a novel multi-agent framework for molecular
structure elucidation from IR spectra. The framework is designed to emulate
expert-driven IR analysis procedures and is inherently extensible. Each agent
specializes in a specific aspect of IR interpretation, and their complementary
roles enable integrated reasoning, thereby improving the overall accuracy of
structure elucidation. Through extensive experiments, we demonstrate that
IR-Agent not only improves baseline performance on experimental IR spectra but
also shows strong adaptability to various forms of chemical information.

</details>


### [45] [Extending FKG.in: Towards a Food Claim Traceability Network](https://arxiv.org/abs/2508.16117)
*Saransh Kumar Gupta,Rizwan Gulzar Mir,Lipika Dey,Partha Pratim Das,Anirban Sen,Ramesh Jain*

Main category: cs.AI

TL;DR: 提出食品声明可追溯网络（FCN）作为印度食品知识图谱的扩展，用于追踪、验证和情境化食品相关声明，使用Reddit数据和大型语言模型构建概念验证。


<details>
  <summary>Details</summary>
Motivation: 当前食品声明（从科学健康益处到文化信仰）的基础设施分散且不发达，缺乏系统化的追踪和验证机制，需要建立透明可追溯的食品知识生态系统。

Method: 开发食品声明可追溯网络（FCN），基于印度食品知识图谱FKG.in，采用本体设计和半自动化知识管理流程，利用Reddit数据和大型语言模型进行声明提取和验证。

Result: 构建了FCN概念验证，集成了结构化模式、溯源感知管道和策划数据输入，为食品声明提供结构化、可验证和可解释的建模方法。

Conclusion: 该方法具有应用无关性，可适应不同地理、烹饪或监管环境，旨在为研究人员、政策制定者和消费者提供更透明和负责任的食品知识生态系统。

Abstract: The global food landscape is rife with scientific, cultural, and commercial
claims about what foods are, what they do, what they should not do, or should
not do. These range from rigorously studied health benefits (probiotics improve
gut health) and misrepresentations (soaked almonds make one smarter) to vague
promises (superfoods boost immunity) and culturally rooted beliefs (cold foods
cause coughs). Despite their widespread influence, the infrastructure for
tracing, verifying, and contextualizing these claims remains fragmented and
underdeveloped. In this paper, we propose a Food Claim-Traceability Network
(FCN) as an extension of FKG.in, a knowledge graph of Indian food that we have
been incrementally building. We also present the ontology design and the
semi-automated knowledge curation workflow that we used to develop a proof of
concept of FKG.in-FCN using Reddit data and Large Language Models. FCN
integrates curated data inputs, structured schemas, and provenance-aware
pipelines for food-related claim extraction and validation. While directly
linked to the Indian food knowledge graph as an application, our methodology
remains application-agnostic and adaptable to other geographic, culinary, or
regulatory settings. By modeling food claims and their traceability in a
structured, verifiable, and explainable way, we aim to contribute to more
transparent and accountable food knowledge ecosystems, supporting researchers,
policymakers, and most importantly, everyday consumers in navigating a world
saturated with dietary assertions.

</details>


### [46] [Bridging the Gap in Ophthalmic AI: MM-Retinal-Reason Dataset and OphthaReason Model toward Dynamic Multimodal Reasoning](https://arxiv.org/abs/2508.16129)
*Ruiqi Wu,Yuang Yao,Tengfei Ma,Chenran Zhang,Na Su,Tao Zhou,Geng Chen,Wen Fan,Yi Zhou*

Main category: cs.AI

TL;DR: 提出了第一个眼科多模态推理模型OphthaReason，通过不确定性感知动态思维方法，在基础推理和复杂推理任务上均达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有医学多模态模型主要关注基础推理，而真实临床诊断需要整合异构临床信息与多模态医学影像数据的复杂推理过程。

Method: 构建MM-Retinal-Reason数据集，提出OphthaReason模型，采用不确定性感知动态思维(UADT)方法，通过熵估计样本级不确定性并动态调节模型探索深度。

Result: 在基础和复杂推理任务上均优于通用MLLMs、医学MLLMs、基于RL的医学MLLMs和眼科MLLMs，提升幅度至少为24.92%、15.00%、21.20%和17.66%。

Conclusion: 该研究填补了医学多模态推理的空白，提出的模型和方法能够有效模拟真实临床思维模式，在眼科诊断任务中表现出色。

Abstract: Multimodal large language models (MLLMs) have recently demonstrated
remarkable reasoning abilities with reinforcement learning paradigm. Although
several multimodal reasoning models have been explored in the medical domain,
most of them focus exclusively on basic reasoning, which refers to shallow
inference based on visual feature matching. However, real-world clinical
diagnosis extends beyond basic reasoning, demanding reasoning processes that
integrate heterogeneous clinical information (such as chief complaints and
medical history) with multimodal medical imaging data. To bridge this gap, we
introduce MM-Retinal-Reason, the first ophthalmic multimodal dataset with the
full spectrum of perception and reasoning. It encompasses both basic reasoning
tasks and complex reasoning tasks, aiming to enhance visual-centric fundamental
reasoning capabilities and emulate realistic clinical thinking patterns.
Building upon MM-Retinal-Reason, we propose OphthaReason, the first
ophthalmology-specific multimodal reasoning model with step-by-step reasoning
traces. To enable flexible adaptation to both basic and complex reasoning
tasks, we specifically design a novel method called Uncertainty-Aware Dynamic
Thinking (UADT), which estimates sample-level uncertainty via entropy and
dynamically modulates the model's exploration depth using a shaped advantage
mechanism. Comprehensive experiments demonstrate that our model achieves
state-of-the-art performance on both basic and complex reasoning tasks,
outperforming general-purpose MLLMs, medical MLLMs, RL-based medical MLLMs, and
ophthalmic MLLMs by at least 24.92\%, 15.00\%, 21.20\%, and 17.66\%. Project
Page: \href{https://github.com/lxirich/OphthaReason}{link}.

</details>


### [47] [Graph RAG as Human Choice Model: Building a Data-Driven Mobility Agent with Preference Chain](https://arxiv.org/abs/2508.16172)
*Kai Hu,Parfait Atchade-Adelomou,Carlo Adornetto,Adrian Mora-Carrero,Luis Alonso-Pastor,Ariel Noyman,Yubo Liu,Kent Larson*

Main category: cs.AI

TL;DR: 本文提出Preference Chain方法，结合图检索增强生成和LLM来改进交通系统中人类行为的上下文感知模拟，在Replica数据集上优于标准LLM方法。


<details>
  <summary>Details</summary>
Motivation: 解决生成代理在模拟人类行为时难以产生一致、上下文敏感和现实行为输出的问题，特别是在数据稀缺的新开发城市区域。

Method: 提出Preference Chain方法，整合图检索增强生成（Graph RAG）与大语言模型（LLM），增强交通系统中人类行为的上下文感知模拟能力。

Result: 在Replica数据集上的实验表明，Preference Chain方法在交通方式选择方面比标准LLM更符合现实世界选择。

Conclusion: 该方法为数据稀缺环境中复杂人类行为模拟提供了有前景的框架，可应用于新兴城市移动性建模、个性化出行行为分析和动态交通预测。

Abstract: Understanding human behavior in urban environments is a crucial field within
city sciences. However, collecting accurate behavioral data, particularly in
newly developed areas, poses significant challenges. Recent advances in
generative agents, powered by Large Language Models (LLMs), have shown promise
in simulating human behaviors without relying on extensive datasets.
Nevertheless, these methods often struggle with generating consistent,
context-sensitive, and realistic behavioral outputs. To address these
limitations, this paper introduces the Preference Chain, a novel method that
integrates Graph Retrieval-Augmented Generation (RAG) with LLMs to enhance
context-aware simulation of human behavior in transportation systems.
Experiments conducted on the Replica dataset demonstrate that the Preference
Chain outperforms standard LLM in aligning with real-world transportation mode
choices. The development of the Mobility Agent highlights potential
applications of proposed method in urban mobility modeling for emerging cities,
personalized travel behavior analysis, and dynamic traffic forecasting. Despite
limitations such as slow inference and the risk of hallucination, the method
offers a promising framework for simulating complex human behavior in
data-scarce environments, where traditional data-driven models struggle due to
limited data availability.

</details>


### [48] [Competition and Attraction Improve Model Fusion](https://arxiv.org/abs/2508.16204)
*João Abrantes,Robert Tjarko Lange,Yujin Tang*

Main category: cs.AI

TL;DR: M2N2是一种进化算法，通过动态调整合并边界、多样性保持机制和启发式吸引度量，实现了无需手动分组的模型融合，能够从零开始进化模型并在多个任务上达到先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型融合方法需要手动将模型参数划分为固定组进行合并，这限制了潜在组合的探索和性能提升。

Method: 提出M2N2进化算法，包含三个关键特性：动态调整合并边界、基于自然竞争启发的多样性保持机制、以及启发式吸引度量来识别最有希望的模型对进行融合。

Result: 首次证明模型融合可以从零开始进化模型，在MNIST分类任务上达到与CMA-ES相当的性能但计算效率更高，在语言和图像生成模型融合中达到最先进性能。

Conclusion: M2N2展示了模型融合的强大潜力，能够保持超出适应度函数明确优化的关键模型能力，具有鲁棒性和通用性。

Abstract: Model merging is a powerful technique for integrating the specialized
knowledge of multiple machine learning models into a single model. However,
existing methods require manually partitioning model parameters into fixed
groups for merging, which restricts the exploration of potential combinations
and limits performance. To overcome these limitations, we propose Model Merging
of Natural Niches (M2N2), an evolutionary algorithm with three key features:
(1) dynamic adjustment of merging boundaries to progressively explore a broader
range of parameter combinations; (2) a diversity preservation mechanism
inspired by the competition for resources in nature, to maintain a population
of diverse, high-performing models that are particularly well-suited for
merging; and (3) a heuristicbased attraction metric to identify the most
promising pairs of models for fusion. Our experimental results demonstrate, for
the first time, that model merging can be used to evolve models entirely from
scratch. Specifically, we apply M2N2 to evolve MNIST classifiers from scratch
and achieve performance comparable to CMA-ES, while being computationally more
efficient. Furthermore, M2N2 scales to merge specialized language and image
generation models, achieving state-of-the-art performance. Notably, it
preserves crucial model capabilities beyond those explicitly optimized by the
fitness function, highlighting its robustness and versatility. Our code is
available at https://github.com/SakanaAI/natural_niches

</details>


### [49] [The next question after Turing's question: Introducing the Grow-AI test](https://arxiv.org/abs/2508.16277)
*Alexandru Tugui*

Main category: cs.AI

TL;DR: GROW-AI框架扩展了AI评估方法，通过六项标准游戏化测试来回答"机器能否成长"的问题，提供可比较的AI成熟度评估


<details>
  <summary>Details</summary>
Motivation: 作为图灵测试的自然继承者，旨在评估人工智能是否能够像人类一样"成长"，将人类成长过程概念化地移植到AI领域

Method: 基于六项主要标准(C1-C6)的游戏化评估系统，分为四个竞技场，使用标准化AI日志记录所有决策和行动，通过专家方法确定权重，计算成长指数

Result: 该方法能够对不同类型AI实体(机器人、软件代理、LLMs)进行一致且可比较的"成长"水平评估，多游戏结构突出优势与薄弱环节

Conclusion: GROW-AI通过结合心理学、机器人学、计算机科学和伦理学的综合测试格式，不仅测量性能还捕捉AI实体向成熟度进化的路径，保证了评估的可追溯性和可复现性

Abstract: This study aims to extend the framework for assessing artificial
intelligence, called GROW-AI (Growth and Realization of Autonomous Wisdom),
designed to answer the question "Can machines grow up?" -- a natural successor
to the Turing Test. The methodology applied is based on a system of six primary
criteria (C1-C6), each assessed through a specific "game", divided into four
arenas that explore both the human dimension and its transposition into AI. All
decisions and actions of the entity are recorded in a standardized AI Journal,
the primary source for calculating composite scores. The assessment uses the
prior expert method to establish initial weights, and the global score -- Grow
Up Index -- is calculated as the arithmetic mean of the six scores, with
interpretation on maturity thresholds. The results show that the methodology
allows for a coherent and comparable assessment of the level of "growth" of AI
entities, regardless of their type (robots, software agents, LLMs). The
multi-game structure highlights strengths and vulnerable areas, and the use of
a unified journal guarantees traceability and replicability in the evaluation.
The originality of the work lies in the conceptual transposition of the process
of "growing" from the human world to that of artificial intelligence, in an
integrated testing format that combines perspectives from psychology, robotics,
computer science, and ethics. Through this approach, GROW-AI not only measures
performance but also captures the evolutionary path of an AI entity towards
maturity.

</details>


### [50] [AgentScope 1.0: A Developer-Centric Framework for Building Agentic Applications](https://arxiv.org/abs/2508.16279)
*Dawei Gao,Zitao Li,Yuexiang Xie,Weirui Kuang,Liuyi Yao,Bingchen Qian,Zhijian Ma,Yue Cui,Haohao Luo,Shen Li,Lu Yi,Yi Yu,Shiqi He,Zhiling Luo,Wenmeng Zhou,Zhicheng Zhang,Xuguang He,Ziqian Chen,Weikai Liao,Farruh Isakulovich Kushnazarov,Yaliang Li,Bolin Ding,Jingren Zhou*

Main category: cs.AI

TL;DR: AgentScope 1.0是一个支持工具型智能体与环境交互的框架，提供统一接口、异步设计、内置智能体和工程支持，用于构建可扩展的智能体应用。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，智能体需要结合内在知识和动态工具使用来增强处理现实世界任务的能力，需要一个支持灵活高效工具交互的框架。

Method: 抽象智能体应用的基础组件并提供统一接口和可扩展模块；基于ReAct范式设计系统级异步架构；集成特定场景的内置智能体；提供可视化评估模块和运行时沙盒。

Result: 开发了一个支持人类-智能体和智能体-智能体交互模式的框架，提高了执行效率，使长轨迹智能体应用的开发更易管理和追踪。

Conclusion: AgentScope 1.0为构建可扩展、自适应和有效的智能体应用提供了实用基础，支持安全执行和快速部署。

Abstract: Driven by rapid advancements of Large Language Models (LLMs), agents are
empowered to combine intrinsic knowledge with dynamic tool use, greatly
enhancing their capacity to address real-world tasks. In line with such an
evolution, AgentScope introduces major improvements in a new version (1.0),
towards comprehensively supporting flexible and efficient tool-based
agent-environment interactions for building agentic applications. Specifically,
we abstract foundational components essential for agentic applications and
provide unified interfaces and extensible modules, enabling developers to
easily leverage the latest progress, such as new models and MCPs. Furthermore,
we ground agent behaviors in the ReAct paradigm and offer advanced agent-level
infrastructure based on a systematic asynchronous design, which enriches both
human-agent and agent-agent interaction patterns while improving execution
efficiency. Building on this foundation, we integrate several built-in agents
tailored to specific practical scenarios. AgentScope also includes robust
engineering support for developer-friendly experiences. We provide a scalable
evaluation module with a visual studio interface, making the development of
long-trajectory agentic applications more manageable and easier to trace. In
addition, AgentScope offers a runtime sandbox to ensure safe agent execution
and facilitates rapid deployment in production environments. With these
enhancements, AgentScope provides a practical foundation for building scalable,
adaptive, and effective agentic applications.

</details>


### [51] [Do What? Teaching Vision-Language-Action Models to Reject the Impossible](https://arxiv.org/abs/2508.16292)
*Wen-Han Hsieh,Elvis Hsieh,Dantong Niu,Trevor Darrell,Roei Herzig,David M. Chan*

Main category: cs.AI

TL;DR: 提出了IVA框架，使视觉-语言-动作模型能够检测错误前提指令、进行语言澄清，并执行可行的替代方案，显著提升了错误前提检测和响应成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作模型在处理错误前提指令（引用环境中不存在对象或条件的自然语言命令）时存在局限性，需要开发能够识别、解释和响应这类指令的统一框架。

Method: 提出Instruct-Verify-and-Act (IVA)框架，包含三个组件：(1)检测无法执行的错误前提指令；(2)进行基于语言的澄清或纠正；(3)在感知和动作中落地可行的替代方案。通过构建大规模指令调优设置和半合成数据集来训练模型。

Result: IVA在错误前提检测准确率上比基线提高了97.56%，在错误前提场景中的成功响应率提高了50.78%。

Conclusion: IVA框架有效解决了VLA模型处理错误前提指令的问题，通过统一的检测、澄清和执行机制显著提升了模型的鲁棒性和实用性。

Abstract: Recently, Vision-Language-Action (VLA) models have demonstrated strong
performance on a range of robotic tasks. These models rely on multimodal
inputs, with language instructions playing a crucial role -- not only in
predicting actions, but also in robustly interpreting user intent, even when
the requests are impossible to fulfill. In this work, we investigate how VLAs
can recognize, interpret, and respond to false-premise instructions: natural
language commands that reference objects or conditions absent from the
environment. We propose Instruct-Verify-and-Act (IVA), a unified framework that
(i) detects when an instruction cannot be executed due to a false premise, (ii)
engages in language-based clarification or correction, and (iii) grounds
plausible alternatives in perception and action. Towards this end, we construct
a large-scale instruction tuning setup with structured language prompts and
train a VLA model capable of handling both accurate and erroneous requests. Our
approach leverages a contextually augmented, semi-synthetic dataset containing
paired positive and false-premise instructions, enabling robust detection and
natural language correction. Our experiments show that IVA improves false
premise detection accuracy by 97.56% over baselines, while increasing
successful responses in false-premise scenarios by 50.78%.

</details>


### [52] [Causal Beam Selection for Reliable Initial Access in AI-driven Beam Management](https://arxiv.org/abs/2508.16352)
*Nasir Khan,Asmaa Abdallah,Abdulkadir Celik,Ahmed M. Eltawil,Sinem Coleri*

Main category: cs.AI

TL;DR: 提出了一种因果感知的深度学习框架，通过因果发现和特征选择，显著减少毫米波MIMO系统中的波束对准时间和开销


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的波束对准方法忽略了输入输出之间的因果关系，导致可解释性差、泛化能力弱和波束扫描开销大

Method: 两阶段因果波束选择算法：首先通过因果发现学习接收功率输入与最优波束之间的贝叶斯图，然后基于该图指导DL分类器的因果特征选择

Result: 在保持与传统方法相当性能的同时，输入选择时间减少94.4%，波束扫描开销降低59.4%

Conclusion: 因果感知方法能够有效识别因果相关特征，显著提升毫米波MIMO系统波束对准的效率和可靠性

Abstract: Efficient and reliable beam alignment is a critical requirement for mmWave
multiple-input multiple-output (MIMO) systems, especially in 6G and beyond,
where communication must be fast, adaptive, and resilient to real-world
uncertainties. Existing deep learning (DL)-based beam alignment methods often
neglect the underlying causal relationships between inputs and outputs, leading
to limited interpretability, poor generalization, and unnecessary beam sweeping
overhead. In this work, we propose a causally-aware DL framework that
integrates causal discovery into beam management pipeline. Particularly, we
propose a novel two-stage causal beam selection algorithm to identify a minimal
set of relevant inputs for beam prediction. First, causal discovery learns a
Bayesian graph capturing dependencies between received power inputs and the
optimal beam. Then, this graph guides causal feature selection for the DL-based
classifier. Simulation results reveal that the proposed causal beam selection
matches the performance of conventional methods while drastically reducing
input selection time by 94.4% and beam sweeping overhead by 59.4% by focusing
only on causally relevant features.

</details>


### [53] [GLARE: Agentic Reasoning for Legal Judgment Prediction](https://arxiv.org/abs/2508.16383)
*Xinyu Yang,Chenlong Deng,Zhicheng Dou*

Main category: cs.AI

TL;DR: GLARE是一个基于代理的法律推理框架，通过动态获取关键法律知识来解决大语言模型在法律判决预测中推理不足的问题，提高推理的广度和深度。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在法律领域由于缺乏法律知识而导致推理不足，需要改进法律判决预测的准确性和可靠性。

Method: 引入GLARE代理法律推理框架，通过调用不同模块动态获取关键法律知识，增强推理能力。

Result: 在真实数据集上的实验验证了该方法的有效性，生成的推理链提高了可解释性。

Conclusion: GLARE框架能够有效提升法律判决预测的性能，并为实际应用提供了可能性。

Abstract: Legal judgment prediction (LJP) has become increasingly important in the
legal field. In this paper, we identify that existing large language models
(LLMs) have significant problems of insufficient reasoning due to a lack of
legal knowledge. Therefore, we introduce GLARE, an agentic legal reasoning
framework that dynamically acquires key legal knowledge by invoking different
modules, thereby improving the breadth and depth of reasoning. Experiments
conducted on the real-world dataset verify the effectiveness of our method.
Furthermore, the reasoning chain generated during the analysis process can
increase interpretability and provide the possibility for practical
applications.

</details>


### [54] [Modular Embedding Recomposition for Incremental Learning](https://arxiv.org/abs/2508.16463)
*Aniello Panariello,Emanuele Frascaroli,Pietro Buzzega,Lorenzo Bonicelli,Angelo Porrello,Simone Calderara*

Main category: cs.AI

TL;DR: MoDER方法通过模块化框架训练多个文本专家，在推理时组合专家来合成改进的原型，从而增强视觉语言模型的零样本能力，在14个数据集上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 虽然预训练视觉语言模型具有零样本分类能力，但在下游任务与预训练领域差异较大时仍需微调。现有持续学习方法主要关注保持零样本能力，本文旨在将保持转变为增强。

Method: 提出MoDER方法，训练多个文本专家（每个专家专注于一个已见类别），存储在基础中心。推理时查询中心并组合检索到的专家来合成改进的原型以提升分类性能。

Result: 在两个流行的零样本增量协议（Class-IL和MTIL）上验证了方法的有效性，共包含14个数据集。

Conclusion: MoDER方法成功地将零样本能力的保持转变为增强，通过模块化专家组合的方式显著提升了视觉语言模型在持续学习场景中的性能。

Abstract: The advent of pre-trained Vision-Language Models (VLMs) has significantly
transformed Continual Learning (CL), mainly due to their zero-shot
classification abilities. Such proficiency makes VLMs well-suited for
real-world applications, enabling robust performance on novel unseen classes
without requiring adaptation. However, fine-tuning remains essential when
downstream tasks deviate significantly from the pre-training domain. Prior CL
approaches primarily focus on preserving the zero-shot capabilities of VLMs
during incremental fine-tuning on a downstream task. We take a step further by
devising an approach that transforms preservation into enhancement of the
zero-shot capabilities of VLMs. Our approach, named MoDular Embedding
Recomposition (MoDER), introduces a modular framework that trains multiple
textual experts, each specialized in a single seen class, and stores them in a
foundational hub. At inference time, for each unseen class, we query the hub
and compose the retrieved experts to synthesize a refined prototype that
improves classification. We show the effectiveness of our method across two
popular zero-shot incremental protocols, Class-IL and MTIL, comprising a total
of 14 datasets. The codebase is available at
https://github.com/aimagelab/mammoth.

</details>


### [55] [Constraints-Guided Diffusion Reasoner for Neuro-Symbolic Learning](https://arxiv.org/abs/2508.16524)
*Xuan Zhang,Zhijian Zhou,Weidi Xu,Yanting Miao,Chao Qu,Yuan Qi*

Main category: cs.AI

TL;DR: 使用扩散模型进行神经符号学习的两阶段训练方法，通过改进的PPO算法施加逻辑约束，在数独、迷宫等符号推理任务上取得优异性能


<details>
  <summary>Details</summary>
Motivation: 解决神经网络学习复杂逻辑约束和符号推理的挑战，弥合神经网络输出分布与符号约束之间的差距

Method: 采用两阶段训练策略：第一阶段培养基础推理能力，第二阶段系统学习逻辑约束。将扩散推理器建模为马尔可夫决策过程，使用改进的近端策略优化算法进行微调，基于逻辑一致性的规则奖励信号优化策略

Result: 在数独、迷宫、路径规划和偏好学习等经典符号推理基准测试中，该方法实现了出色的准确性和逻辑一致性

Conclusion: 扩散模型架构能够有效进行神经符号学习，解决逻辑谜题，该方法在神经网络中实现了优异的符号推理性能

Abstract: Enabling neural networks to learn complex logical constraints and fulfill
symbolic reasoning is a critical challenge. Bridging this gap often requires
guiding the neural network's output distribution to move closer to the symbolic
constraints. While diffusion models have shown remarkable generative capability
across various domains, we employ the powerful architecture to perform
neuro-symbolic learning and solve logical puzzles. Our diffusion-based pipeline
adopts a two-stage training strategy: the first stage focuses on cultivating
basic reasoning abilities, while the second emphasizes systematic learning of
logical constraints. To impose hard constraints on neural outputs in the second
stage, we formulate the diffusion reasoner as a Markov decision process and
innovatively fine-tune it with an improved proximal policy optimization
algorithm. We utilize a rule-based reward signal derived from the logical
consistency of neural outputs and adopt a flexible strategy to optimize the
diffusion reasoner's policy. We evaluate our methodology on some classical
symbolic reasoning benchmarks, including Sudoku, Maze, pathfinding and
preference learning. Experimental results demonstrate that our approach
achieves outstanding accuracy and logical consistency among neural networks.

</details>


### [56] [LLM-Based Agents for Competitive Landscape Mapping in Drug Asset Due Diligence](https://arxiv.org/abs/2508.16571)
*Alisa Vinogradova,Vlad Vinogradov,Dmitrii Radkevich,Ilya Yasny,Dmitry Kobyzev,Ivan Izmailov,Katsiaryna Yanchanka,Andrey Doronichev*

Main category: cs.AI

TL;DR: 本文提出了一个用于药物资产尽职调查的竞争对手发现AI代理系统，通过LLM代理将多模态非结构化数据转换为结构化评估语料库，在竞争对手发现任务上达到83%的召回率，比现有系统提升显著。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的AI系统无法可靠检索所有竞争药物名称，且缺乏公认的公开基准测试。药物竞争数据具有投资者特定、付费墙限制、跨注册机构分散、本体不匹配、别名繁多、多模态和快速变化等特点。

Method: 使用LLM代理将5年的多模态非结构化尽职调查备忘录转换为结构化评估语料库，建立指示到竞争药物的映射。引入竞争对手验证LLM作为评判代理，过滤假阳性以最大化精确度并抑制幻觉。

Result: 竞争对手发现代理达到83%的召回率，显著超过OpenAI Deep Research（65%）和Perplexity Labs（60%）。在生物技术VC基金案例中，分析师周转时间从2.5天降至约3小时（约20倍提升）。

Conclusion: 该系统成功解决了药物竞争情报发现的挑战，在生产和实际应用中证明了其有效性，显著提高了竞争分析的效率和准确性。

Abstract: In this paper, we describe and benchmark a competitor-discovery component
used within an agentic AI system for fast drug asset due diligence. A
competitor-discovery AI agent, given an indication, retrieves all drugs
comprising the competitive landscape of that indication and extracts canonical
attributes for these drugs. The competitor definition is investor-specific, and
data is paywalled/licensed, fragmented across registries, ontology-mismatched
by indication, alias-heavy for drug names, multimodal, and rapidly changing.
Although considered the best tool for this problem, the current LLM-based AI
systems aren't capable of reliably retrieving all competing drug names, and
there is no accepted public benchmark for this task. To address the lack of
evaluation, we use LLM-based agents to transform five years of multi-modal,
unstructured diligence memos from a private biotech VC fund into a structured
evaluation corpus mapping indications to competitor drugs with normalized
attributes. We also introduce a competitor validating LLM-as-a-judge agent that
filters out false positives from the list of predicted competitors to maximize
precision and suppress hallucinations. On this benchmark, our
competitor-discovery agent achieves 83% recall, exceeding OpenAI Deep Research
(65%) and Perplexity Labs (60%). The system is deployed in production with
enterprise users; in a case study with a biotech VC investment fund, analyst
turnaround time dropped from 2.5 days to $\sim$3 hours ($\sim$20x) for the
competitive analysis.

</details>
