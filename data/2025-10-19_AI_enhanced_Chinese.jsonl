{"id": "2510.13822", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.13822", "abs": "https://arxiv.org/abs/2510.13822", "authors": ["Bartosz Burgiel"], "title": "Noisy Networks, Nosy Neighbors: Inferring Privacy Invasive Information from Encrypted Wireless Traffic", "comment": "80 pages, 49 figures, bachelor thesis at the data privacy and\n  security chair of the leipzig university", "summary": "This thesis explores the extent to which passive observation of wireless\ntraffic in a smart home environment can be used to infer privacy-invasive\ninformation about its inhabitants. Using a setup that mimics the capabilities\nof a nosy neighbor in an adjacent flat, we analyze raw 802.11 packets and\nBluetooth Low Energy advertisemets. From this data, we identify devices, infer\ntheir activity states and approximate their location using RSSI-based\ntrilateration. Despite the encrypted nature of the data, we demonstrate that it\nis possible to detect active periods of multimedia devices, infer common\nactivities such as sleeping, working and consuming media, and even approximate\nthe layout of the neighbor's apartment. Our results show that privacy risks in\nsmart homes extend beyond traditional data breaches: a nosy neighbor behind the\nwall can gain privacy-invasive insights into the lives of their neighbors\npurely from encrypted network traffic.", "AI": {"tldr": "\u901a\u8fc7\u88ab\u52a8\u76d1\u542c\u667a\u80fd\u5bb6\u5c45\u7684WiFi\u548c\u84dd\u7259\u6d41\u91cf\uff0c\u5373\u4f7f\u6570\u636e\u52a0\u5bc6\u4e5f\u80fd\u63a8\u65ad\u4f4f\u6237\u9690\u79c1\u4fe1\u606f\uff0c\u5982\u8bbe\u5907\u6d3b\u52a8\u72b6\u6001\u3001\u65e5\u5e38\u884c\u4e3a\u548c\u516c\u5bd3\u5e03\u5c40\u3002", "motivation": "\u63a2\u7d22\u667a\u80fd\u5bb6\u5c45\u73af\u5883\u4e2d\u65e0\u7ebf\u6d41\u91cf\u88ab\u52a8\u89c2\u5bdf\u80fd\u5426\u63a8\u65ad\u4f4f\u6237\u9690\u79c1\u4fe1\u606f\uff0c\u6a21\u62df\u9694\u58c1\u90bb\u5c45\u7684\u7aa5\u63a2\u80fd\u529b\u3002", "method": "\u5206\u6790802.11\u539f\u59cb\u6570\u636e\u5305\u548cBLE\u5e7f\u64ad\uff0c\u901a\u8fc7\u8bbe\u5907\u8bc6\u522b\u3001\u6d3b\u52a8\u72b6\u6001\u63a8\u65ad\u548cRSSI\u4e09\u8fb9\u5b9a\u4f4d\u6765\u8fd1\u4f3c\u8bbe\u5907\u4f4d\u7f6e\u3002", "result": "\u80fd\u591f\u68c0\u6d4b\u591a\u5a92\u4f53\u8bbe\u5907\u6d3b\u8dc3\u671f\uff0c\u63a8\u65ad\u7761\u7720\u3001\u5de5\u4f5c\u3001\u5a92\u4f53\u6d88\u8d39\u7b49\u65e5\u5e38\u6d3b\u52a8\uff0c\u5e76\u8fd1\u4f3c\u90bb\u5c45\u516c\u5bd3\u5e03\u5c40\u3002", "conclusion": "\u667a\u80fd\u5bb6\u5c45\u9690\u79c1\u98ce\u9669\u8d85\u51fa\u4f20\u7edf\u6570\u636e\u6cc4\u9732\uff0c\u90bb\u5c45\u4ec5\u901a\u8fc7\u52a0\u5bc6\u7f51\u7edc\u6d41\u91cf\u5c31\u80fd\u83b7\u5f97\u9690\u79c1\u4fb5\u5165\u6027\u6d1e\u5bdf\u3002"}}
{"id": "2510.13857", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13857", "abs": "https://arxiv.org/abs/2510.13857", "authors": ["Qiang Xu", "Xiangyu Wen", "Changran Xu", "Zeju Li", "Jianyuan Zhong"], "title": "From Craft to Constitution: A Governance-First Paradigm for Principled Agent Engineering", "comment": null, "summary": "The advent of powerful Large Language Models (LLMs) has ushered in an ``Age\nof the Agent,'' enabling autonomous systems to tackle complex goals. However,\nthe transition from prototype to production is hindered by a pervasive ``crisis\nof craft,'' resulting in agents that are brittle, unpredictable, and ultimately\nuntrustworthy in mission-critical applications. This paper argues this crisis\nstems from a fundamental paradigm mismatch -- attempting to command inherently\nprobabilistic processors with the deterministic mental models of traditional\nsoftware engineering. To solve this crisis, we introduce a governance-first\nparadigm for principled agent engineering, embodied in a formal architecture we\ncall ArbiterOS.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86ArbiterOS\u67b6\u6784\uff0c\u901a\u8fc7\u6cbb\u7406\u4f18\u5148\u7684\u8303\u5f0f\u6765\u89e3\u51b3LLM\u4ee3\u7406\u5728\u5173\u952e\u4efb\u52a1\u5e94\u7528\u4e2d\u7684\u8106\u5f31\u6027\u548c\u4e0d\u53ef\u9884\u6d4b\u6027\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5f00\u542f\u4e86\"\u4ee3\u7406\u65f6\u4ee3\"\uff0c\u4f46\u539f\u578b\u5230\u751f\u4ea7\u7684\u8fc7\u6e21\u9762\u4e34\"\u5de5\u827a\u5371\u673a\"\uff0c\u5bfc\u81f4\u4ee3\u7406\u5728\u5173\u952e\u4efb\u52a1\u5e94\u7528\u4e2d\u8106\u5f31\u3001\u4e0d\u53ef\u9884\u6d4b\u4e14\u4e0d\u53ef\u4fe1\u3002\u8fd9\u79cd\u5371\u673a\u6e90\u4e8e\u7528\u4f20\u7edf\u8f6f\u4ef6\u5de5\u7a0b\u7684\u786e\u5b9a\u6027\u601d\u7ef4\u6765\u547d\u4ee4\u6982\u7387\u6027\u5904\u7406\u5668\u7684\u6839\u672c\u8303\u5f0f\u4e0d\u5339\u914d\u3002", "method": "\u5f15\u5165\u6cbb\u7406\u4f18\u5148\u7684\u4ee3\u7406\u5de5\u7a0b\u539f\u5219\uff0c\u4f53\u73b0\u5728\u540d\u4e3aArbiterOS\u7684\u6b63\u5f0f\u67b6\u6784\u4e2d\u3002", "result": "\u63d0\u51fa\u4e86\u89e3\u51b3\u4ee3\u7406\u5de5\u7a0b\u5371\u673a\u7684\u7406\u8bba\u6846\u67b6\u548c\u67b6\u6784\u65b9\u6848\u3002", "conclusion": "\u9700\u8981\u901a\u8fc7\u6cbb\u7406\u4f18\u5148\u7684\u8303\u5f0f\u8f6c\u53d8\u6765\u89e3\u51b3LLM\u4ee3\u7406\u5de5\u7a0b\u4e2d\u7684\u6839\u672c\u6027\u8303\u5f0f\u4e0d\u5339\u914d\u95ee\u9898\u3002"}}
{"id": "2510.13824", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.13824", "abs": "https://arxiv.org/abs/2510.13824", "authors": ["Wai Ming Chan", "Remi Chou", "Taejoon Kim"], "title": "Multi-Layer Secret Sharing for Cross-Layer Attack Defense in 5G Networks: a COTS UE Demonstration", "comment": null, "summary": "This demo presents the first implementation of multi-layer secret sharing on\ncommercial-off-the-shelf (COTS) 5G user equipment (UE), operating without\ninfrastructure modifications or pre-shared keys. Our XOR-based approach\ndistributes secret shares across network operators and distributed relays,\nensuring perfect recovery and data confidentiality even if one network operator\nand one relay are simultaneously lost (e.g., under denial of service (DoS) or\nunanticipated attacks).", "AI": {"tldr": "\u5728\u5546\u75285G\u7528\u6237\u8bbe\u5907\u4e0a\u5b9e\u73b0\u65e0\u9700\u57fa\u7840\u8bbe\u65bd\u4fee\u6539\u6216\u9884\u5171\u4eab\u5bc6\u94a5\u7684\u591a\u5c42\u79d8\u5bc6\u5171\u4eab\u7cfb\u7edf", "motivation": "\u89e3\u51b35G\u7f51\u7edc\u4e2d\u6570\u636e\u673a\u5bc6\u6027\u548c\u53ef\u7528\u6027\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u9762\u4e34\u62d2\u7edd\u670d\u52a1\u653b\u51fb\u6216\u610f\u5916\u653b\u51fb\u65f6\u786e\u4fdd\u6570\u636e\u5b89\u5168", "method": "\u91c7\u7528\u57fa\u4e8eXOR\u7684\u65b9\u6cd5\uff0c\u5c06\u79d8\u5bc6\u4efd\u989d\u5206\u5e03\u5728\u591a\u4e2a\u7f51\u7edc\u8fd0\u8425\u5546\u548c\u5206\u5e03\u5f0f\u4e2d\u7ee7\u8282\u70b9\u4e4b\u95f4", "result": "\u5373\u4f7f\u4e00\u4e2a\u7f51\u7edc\u8fd0\u8425\u5546\u548c\u4e00\u4e2a\u4e2d\u7ee7\u540c\u65f6\u4e22\u5931\uff0c\u4e5f\u80fd\u5b9e\u73b0\u5b8c\u7f8e\u6062\u590d\u548c\u6570\u636e\u4fdd\u5bc6", "conclusion": "\u6210\u529f\u5728\u5546\u75285G\u8bbe\u5907\u4e0a\u5b9e\u73b0\u4e86\u65e0\u9700\u57fa\u7840\u8bbe\u65bd\u4fee\u6539\u7684\u591a\u5c42\u79d8\u5bc6\u5171\u4eab\u7cfb\u7edf\uff0c\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u6570\u636e\u4fdd\u62a4\u80fd\u529b"}}
{"id": "2510.13859", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13859", "abs": "https://arxiv.org/abs/2510.13859", "authors": ["Ruchit Rawal", "Jeffrey Yang Fan Chiang", "Chihao Shen", "Jeffery Siyuan Tian", "Aastha Mahajan", "Tom Goldstein", "Yizheng Chen"], "title": "Benchmarking Correctness and Security in Multi-Turn Code Generation", "comment": null, "summary": "AI coding assistants powered by large language models (LLMs) have transformed\nsoftware development, significantly boosting productivity. While existing\nbenchmarks evaluate the correctness and security of LLM-generated code, they\nare typically limited to single-turn tasks that do not reflect the iterative\nnature of real-world development. We introduce MT-Sec, the first benchmark to\nsystematically evaluate both correctness and security in multi-turn coding\nscenarios. We construct this using a synthetic data pipeline that transforms\nexisting single-turn tasks into semantically aligned multi-turn interaction\nsequences, allowing reuse of original test suites while modeling the complexity\nof real-world coding processes. We evaluate 32 open- and closed-source models,\nand three agent-scaffolding on MT-Sec and observe a consistent 20-27% drop in\n\"correct and secure\" outputs from single-turn to multi-turn settings -- even\namong state-of-the-art models. Beyond full-program generation, we also evaluate\nmodels on multi-turn code-diff generation -- an unexplored yet practically\nrelevant setting -- and find that models perform worse here, with increased\nrates of functionally incorrect and insecure outputs. Finally, we find that\nwhile agent scaffoldings boost single-turn code generation performance, they\nare not quite as effective in multi-turn evaluations. Together, these findings\nhighlight the need for benchmarks that jointly evaluate correctness and\nsecurity in multi-turn, real-world coding workflows.", "AI": {"tldr": "MT-Sec\u662f\u9996\u4e2a\u7cfb\u7edf\u8bc4\u4f30\u591a\u8f6e\u7f16\u7801\u573a\u666f\u4e2d\u6b63\u786e\u6027\u548c\u5b89\u5168\u6027\u7684\u57fa\u51c6\uff0c\u53d1\u73b0\u4ece\u5355\u8f6e\u5230\u591a\u8f6e\u8bbe\u7f6e\u4e2d\"\u6b63\u786e\u4e14\u5b89\u5168\"\u7684\u8f93\u51fa\u4e0b\u964d20-27%\uff0c\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u6a21\u578b\u4e5f\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u901a\u5e38\u5c40\u9650\u4e8e\u5355\u8f6e\u4efb\u52a1\uff0c\u4e0d\u80fd\u53cd\u6620\u73b0\u5b9e\u4e16\u754c\u5f00\u53d1\u7684\u8fed\u4ee3\u6027\u8d28\uff0c\u9700\u8981\u8bc4\u4f30\u591a\u8f6e\u7f16\u7801\u573a\u666f\u4e2d\u7684\u6b63\u786e\u6027\u548c\u5b89\u5168\u6027\u3002", "method": "\u4f7f\u7528\u5408\u6210\u6570\u636e\u7ba1\u9053\u5c06\u73b0\u6709\u5355\u8f6e\u4efb\u52a1\u8f6c\u6362\u4e3a\u8bed\u4e49\u5bf9\u9f50\u7684\u591a\u8f6e\u4ea4\u4e92\u5e8f\u5217\uff0c\u91cd\u7528\u539f\u59cb\u6d4b\u8bd5\u5957\u4ef6\uff0c\u540c\u65f6\u5efa\u6a21\u771f\u5b9e\u4e16\u754c\u7f16\u7801\u8fc7\u7a0b\u7684\u590d\u6742\u6027\u3002", "result": "\u8bc4\u4f3032\u4e2a\u5f00\u6e90\u548c\u95ed\u6e90\u6a21\u578b\u53ca\u4e09\u79cd\u4ee3\u7406\u6846\u67b6\uff0c\u53d1\u73b0\u591a\u8f6e\u8bbe\u7f6e\u4e0b\u6b63\u786e\u4e14\u5b89\u5168\u7684\u8f93\u51fa\u663e\u8457\u4e0b\u964d\uff1b\u5728\u4ee3\u7801\u5dee\u5f02\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u5dee\uff1b\u4ee3\u7406\u6846\u67b6\u5728\u591a\u8f6e\u8bc4\u4f30\u4e2d\u6548\u679c\u4e0d\u5982\u5355\u8f6e\u3002", "conclusion": "\u9700\u8981\u80fd\u591f\u8054\u5408\u8bc4\u4f30\u591a\u8f6e\u771f\u5b9e\u4e16\u754c\u7f16\u7801\u5de5\u4f5c\u6d41\u4e2d\u6b63\u786e\u6027\u548c\u5b89\u5168\u6027\u7684\u57fa\u51c6\u3002"}}
{"id": "2510.13825", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13825", "abs": "https://arxiv.org/abs/2510.13825", "authors": ["Eugene Neelou", "Ivan Novikov", "Max Moroz", "Om Narayan", "Tiffany Saade", "Mika Ayenson", "Ilya Kabanov", "Jen Ozmen", "Edward Lee", "Vineeth Sai Narajala", "Emmanuel Guilherme Junior", "Ken Huang", "Huseyin Gulsin", "Jason Ross", "Marat Vyshegorodtsev", "Adelin Travers", "Idan Habler", "Rahul Jadav"], "title": "A2AS: Agentic AI Runtime Security and Self-Defense", "comment": null, "summary": "The A2AS framework is introduced as a security layer for AI agents and\nLLM-powered applications, similar to how HTTPS secures HTTP. A2AS enforces\ncertified behavior, activates model self-defense, and ensures context window\nintegrity. It defines security boundaries, authenticates prompts, applies\nsecurity rules and custom policies, and controls agentic behavior, enabling a\ndefense-in-depth strategy. The A2AS framework avoids latency overhead, external\ndependencies, architectural changes, model retraining, and operational\ncomplexity. The BASIC security model is introduced as the A2AS foundation: (B)\nBehavior certificates enable behavior enforcement, (A) Authenticated prompts\nenable context window integrity, (S) Security boundaries enable untrusted input\nisolation, (I) In-context defenses enable secure model reasoning, (C) Codified\npolicies enable application-specific rules. This first paper in the series\nintroduces the BASIC security model and the A2AS framework, exploring their\npotential toward establishing the A2AS industry standard.", "AI": {"tldr": "A2AS\u6846\u67b6\u4e3aAI\u4ee3\u7406\u548cLLM\u5e94\u7528\u63d0\u4f9b\u5b89\u5168\u5c42\uff0c\u7c7b\u4f3cHTTPS\u4fdd\u62a4HTTP\u3002\u5b83\u901a\u8fc7BASIC\u5b89\u5168\u6a21\u578b\u5b9e\u73b0\u884c\u4e3a\u8ba4\u8bc1\u3001\u63d0\u793a\u8ba4\u8bc1\u3001\u5b89\u5168\u8fb9\u754c\u3001\u4e0a\u4e0b\u6587\u9632\u5fa1\u548c\u7b56\u7565\u7f16\u7801\uff0c\u65e0\u9700\u5ef6\u8fdf\u5f00\u9500\u6216\u67b6\u6784\u6539\u52a8\u3002", "motivation": "\u968f\u7740AI\u4ee3\u7406\u548cLLM\u5e94\u7528\u7684\u666e\u53ca\uff0c\u9700\u8981\u7c7b\u4f3cHTTPS\u7684\u5b89\u5168\u5c42\u6765\u4fdd\u62a4\u8fd9\u4e9b\u7cfb\u7edf\u514d\u53d7\u653b\u51fb\uff0c\u786e\u4fdd\u884c\u4e3a\u53ef\u63a7\u548c\u4e0a\u4e0b\u6587\u5b8c\u6574\u6027\u3002", "method": "\u63d0\u51faA2AS\u6846\u67b6\u548cBASIC\u5b89\u5168\u6a21\u578b\uff1a\u884c\u4e3a\u8bc1\u4e66\u5f3a\u5236\u6267\u884c\u884c\u4e3a\uff0c\u8ba4\u8bc1\u63d0\u793a\u786e\u4fdd\u4e0a\u4e0b\u6587\u5b8c\u6574\u6027\uff0c\u5b89\u5168\u8fb9\u754c\u9694\u79bb\u4e0d\u53ef\u4fe1\u8f93\u5165\uff0c\u4e0a\u4e0b\u6587\u9632\u5fa1\u4fdd\u62a4\u6a21\u578b\u63a8\u7406\uff0c\u7f16\u7801\u7b56\u7565\u5b9e\u73b0\u5e94\u7528\u7279\u5b9a\u89c4\u5219\u3002", "result": "A2AS\u6846\u67b6\u80fd\u591f\u6709\u6548\u4fdd\u62a4AI\u7cfb\u7edf\uff0c\u907f\u514d\u5ef6\u8fdf\u5f00\u9500\u3001\u5916\u90e8\u4f9d\u8d56\u3001\u67b6\u6784\u6539\u52a8\u3001\u6a21\u578b\u91cd\u8bad\u7ec3\u548c\u64cd\u4f5c\u590d\u6742\u6027\uff0c\u63d0\u4f9b\u6df1\u5ea6\u9632\u5fa1\u7b56\u7565\u3002", "conclusion": "A2AS\u6846\u67b6\u548cBASIC\u5b89\u5168\u6a21\u578b\u4e3aAI\u5b89\u5168\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u671b\u6210\u4e3a\u884c\u4e1a\u6807\u51c6\uff0c\u9996\u4e2a\u8bba\u6587\u4ecb\u7ecd\u4e86\u5176\u57fa\u672c\u539f\u7406\u548c\u6f5c\u529b\u3002"}}
{"id": "2510.13914", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.13914", "abs": "https://arxiv.org/abs/2510.13914", "authors": ["Janghan Yoon", "Jaegwan Cho", "Junhyeok Kim", "Jiwan Chung", "Jaehyun Jeon", "Youngjae Yu"], "title": "A11YN: aligning LLMs for accessible web UI code generation", "comment": null, "summary": "Large language models (LLMs) have recently demonstrated strong capabilities\nin generating functional and aesthetic web interfaces directly from\ninstructions. However, these models often replicate accessibility flaws from\ntheir training data, resulting in interfaces that exclude users with diverse\nneeds and contexts. To address this gap, we introduce A11yn, the first method\nthat aligns code-generating LLMs to reliably produce accessibility-compliant\nweb UIs. A11yn optimizes a novel reward function that penalizes violations of\nthe Web Content Accessibility Guidelines (WCAG), with penalties scaled to the\nseverity of each violation as identified by an accessibility testing engine. To\nsupport training, we construct UIReq-6.8K, a dataset of 6,800 diverse\ninstructions for web UI generation. For evaluation, we introduce RealUIReq-300,\na benchmark of 300 real-world web UI requests grounded and manually curated\nfrom public web pages, spanning a broad range of use cases. Empirical results\nshow that A11yn significantly outperforms strong baselines, lowering the\nInaccessibility Rate by 60% over the base model while preserving semantic\nfidelity and visual quality of generated UIs. These findings demonstrate that\naccessibility can be systematically optimized within LLMs, showing the\nfeasibility of aligning code generation for accessibility.", "AI": {"tldr": "A11yn\u662f\u9996\u4e2a\u5c06\u4ee3\u7801\u751f\u6210LLM\u5bf9\u9f50\u4ee5\u53ef\u9760\u751f\u6210\u7b26\u5408\u53ef\u8bbf\u95ee\u6027\u6807\u51c6\u7684\u7f51\u9875UI\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u57fa\u4e8eWCAG\u8fdd\u89c4\u60e9\u7f5a\u7684\u5956\u52b1\u51fd\u6570\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u4e0d\u53ef\u8bbf\u95ee\u738760%\u3002", "motivation": "\u73b0\u6709LLM\u5728\u751f\u6210\u7f51\u9875\u754c\u9762\u65f6\u7ecf\u5e38\u590d\u5236\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u53ef\u8bbf\u95ee\u6027\u7f3a\u9677\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u754c\u9762\u6392\u65a5\u5177\u6709\u591a\u6837\u5316\u9700\u6c42\u548c\u80cc\u666f\u7684\u7528\u6237\u3002", "method": "A11yn\u4f18\u5316\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u5956\u52b1\u51fd\u6570\uff0c\u8be5\u51fd\u6570\u6839\u636e\u53ef\u8bbf\u95ee\u6027\u6d4b\u8bd5\u5f15\u64ce\u8bc6\u522b\u7684\u8fdd\u89c4\u4e25\u91cd\u7a0b\u5ea6\u5bf9WCAG\u8fdd\u89c4\u8fdb\u884c\u60e9\u7f5a\uff0c\u5e76\u4f7f\u7528UIReq-6.8K\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\uff0cA11yn\u663e\u8457\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u5728\u4fdd\u6301\u751f\u6210UI\u8bed\u4e49\u4fdd\u771f\u5ea6\u548c\u89c6\u89c9\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u5c06\u4e0d\u53ef\u8bbf\u95ee\u7387\u6bd4\u57fa\u7840\u6a21\u578b\u964d\u4f4e\u4e8660%\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u53ef\u8bbf\u95ee\u6027\u53ef\u4ee5\u5728LLM\u4e2d\u7cfb\u7edf\u6027\u4f18\u5316\uff0c\u8bc1\u660e\u4e86\u4e3a\u53ef\u8bbf\u95ee\u6027\u5bf9\u9f50\u4ee3\u7801\u751f\u6210\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2510.14005", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14005", "abs": "https://arxiv.org/abs/2510.14005", "authors": ["Wei Zou", "Yupei Liu", "Yanting Wang", "Ying Chen", "Neil Gong", "Jinyuan Jia"], "title": "PIShield: Detecting Prompt Injection Attacks via Intrinsic LLM Features", "comment": "The code is available at https://github.com/weizou52/PIShield", "summary": "LLM-integrated applications are vulnerable to prompt injection attacks, where\nan attacker contaminates the input to inject malicious prompts, causing the LLM\nto follow the attacker's intent instead of the original user's. Existing prompt\ninjection detection methods often have sub-optimal performance and/or high\ncomputational overhead. In this work, we propose PIShield, a detection method\nthat is both effective and efficient. Our key observation is that the internal\nrepresentation of the final token in a prompt-extracted from a specific layer\nof the LLM, which we term the injection-critical layer-captures distinguishing\nfeatures between clean and contaminated prompts. Leveraging this insight, we\ntrain a simple linear classifier on these internal representations using a\nlabeled set of clean and contaminated prompts. We compare PIShield against 11\nbaselines across 5 diverse benchmark datasets and 8 prompt injection attacks.\nThe results demonstrate that PIShield is both highly effective and efficient,\nsubstantially outperforming existing methods. Additionally, we show that\nPIShield resists strong adaptive attacks.", "AI": {"tldr": "\u63d0\u51fa\u4e86PIShield\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790LLM\u5185\u90e8\u7279\u5b9a\u5c42\u7684\u6700\u7ec8token\u8868\u793a\u6765\u68c0\u6d4b\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u4f7f\u7528\u7b80\u5355\u7ebf\u6027\u5206\u7c7b\u5668\u5b9e\u73b0\u9ad8\u6548\u68c0\u6d4b\u3002", "motivation": "\u73b0\u6709\u63d0\u793a\u6ce8\u5165\u68c0\u6d4b\u65b9\u6cd5\u6027\u80fd\u4e0d\u4f73\u4e14\u8ba1\u7b97\u5f00\u9500\u9ad8\uff0cLLM\u5e94\u7528\u6613\u53d7\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u653b\u51fb\u8005\u53ef\u901a\u8fc7\u6c61\u67d3\u8f93\u5165\u4f7fLLM\u6267\u884c\u6076\u610f\u6307\u4ee4\u3002", "method": "\u63d0\u53d6LLM\u7279\u5b9a\u6ce8\u5165\u5173\u952e\u5c42\u4e2d\u6700\u7ec8token\u7684\u5185\u90e8\u8868\u793a\uff0c\u4f7f\u7528\u6807\u8bb0\u7684\u5e72\u51c0\u548c\u6c61\u67d3\u63d0\u793a\u8bad\u7ec3\u7ebf\u6027\u5206\u7c7b\u5668\u8fdb\u884c\u68c0\u6d4b\u3002", "result": "\u57285\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u548c8\u79cd\u653b\u51fb\u4e0a\u4f18\u4e8e11\u4e2a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u68c0\u6d4b\u6548\u679c\u663e\u8457\u4e14\u6548\u7387\u9ad8\uff0c\u80fd\u62b5\u6297\u5f3a\u81ea\u9002\u5e94\u653b\u51fb\u3002", "conclusion": "PIShield\u901a\u8fc7\u5229\u7528LLM\u5185\u90e8\u8868\u793a\u7684\u5173\u952e\u7279\u5f81\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u6709\u6548\u7684\u63d0\u793a\u6ce8\u5165\u68c0\u6d4b\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2510.13992", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.13992", "abs": "https://arxiv.org/abs/2510.13992", "authors": ["Quoc Hung Le", "Thanh Le-Cong", "Bach Le", "Bowen Xu"], "title": "Signature in Code Backdoor Detection, how far are we?", "comment": "20 pages, 3 figures", "summary": "As Large Language Models (LLMs) become increasingly integrated into software\ndevelopment workflows, they also become prime targets for adversarial attacks.\nAmong these, backdoor attacks are a significant threat, allowing attackers to\nmanipulate model outputs through hidden triggers embedded in training data.\nDetecting such backdoors remains a challenge, and one promising approach is the\nuse of Spectral Signature defense methods that identify poisoned data by\nanalyzing feature representations through eigenvectors. While some prior works\nhave explored Spectral Signatures for backdoor detection in neural networks,\nrecent studies suggest that these methods may not be optimally effective for\ncode models. In this paper, we revisit the applicability of Spectral\nSignature-based defenses in the context of backdoor attacks on code models. We\nsystematically evaluate their effectiveness under various attack scenarios and\ndefense configurations, analyzing their strengths and limitations. We found\nthat the widely used setting of Spectral Signature in code backdoor detection\nis often suboptimal. Hence, we explored the impact of different settings of the\nkey factors. We discovered a new proxy metric that can more accurately estimate\nthe actual performance of Spectral Signature without model retraining after the\ndefense.", "AI": {"tldr": "\u91cd\u65b0\u8bc4\u4f30\u4e86\u57fa\u4e8e\u8c31\u7b7e\u540d\u7684\u9632\u5fa1\u65b9\u6cd5\u5728\u4ee3\u7801\u6a21\u578b\u540e\u95e8\u653b\u51fb\u4e2d\u7684\u9002\u7528\u6027\uff0c\u53d1\u73b0\u4f20\u7edf\u8bbe\u7f6e\u6548\u679c\u4e0d\u4f73\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u4ee3\u7406\u6307\u6807\u6765\u66f4\u51c6\u786e\u8bc4\u4f30\u9632\u5fa1\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u540e\u95e8\u653b\u51fb\u5a01\u80c1\u65e5\u76ca\u4e25\u91cd\u3002\u8c31\u7b7e\u540d\u9632\u5fa1\u65b9\u6cd5\u5728\u4ee3\u7801\u6a21\u578b\u4e2d\u7684\u6709\u6548\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u9a8c\u8bc1\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u5176\u9002\u7528\u6027\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30\u8c31\u7b7e\u540d\u9632\u5fa1\u5728\u4e0d\u540c\u653b\u51fb\u573a\u666f\u548c\u9632\u5fa1\u914d\u7f6e\u4e0b\u7684\u6709\u6548\u6027\uff0c\u5206\u6790\u5173\u952e\u56e0\u7d20\u8bbe\u7f6e\u7684\u5f71\u54cd\uff0c\u63a2\u7d22\u65b0\u7684\u4ee3\u7406\u6307\u6807\u3002", "result": "\u53d1\u73b0\u4ee3\u7801\u540e\u95e8\u68c0\u6d4b\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u7684\u8c31\u7b7e\u540d\u8bbe\u7f6e\u901a\u5e38\u4e0d\u662f\u6700\u4f18\u7684\uff0c\u627e\u5230\u4e86\u80fd\u66f4\u51c6\u786e\u4f30\u8ba1\u8c31\u7b7e\u540d\u5b9e\u9645\u6027\u80fd\u7684\u65b0\u4ee3\u7406\u6307\u6807\u3002", "conclusion": "\u8c31\u7b7e\u540d\u9632\u5fa1\u5728\u4ee3\u7801\u6a21\u578b\u540e\u95e8\u68c0\u6d4b\u4e2d\u9700\u8981\u4f18\u5316\u914d\u7f6e\uff0c\u65b0\u63d0\u51fa\u7684\u4ee3\u7406\u6307\u6807\u80fd\u591f\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u9632\u5fa1\u6548\u679c\u3002"}}
{"id": "2510.13858", "categories": ["cs.AI", "I.6.4"], "pdf": "https://arxiv.org/pdf/2510.13858", "abs": "https://arxiv.org/abs/2510.13858", "authors": ["Raheleh Biglari", "Joachim Denil"], "title": "Decision Oriented Technique (DOTechnique): Finding Model Validity Through Decision-Maker Context", "comment": "10 pages", "summary": "Model validity is as critical as the model itself, especially when guiding\ndecision-making processes. Traditional approaches often rely on predefined\nvalidity frames, which may not always be available or sufficient. This paper\nintroduces the Decision Oriented Technique (DOTechnique), a novel method for\ndetermining model validity based on decision consistency rather than output\nsimilarity. By evaluating whether surrogate models lead to equivalent decisions\ncompared to high-fidelity models, DOTechnique enables efficient identification\nof validity regions, even in the absence of explicit validity boundaries. The\napproach integrates domain constraints and symbolic reasoning to narrow the\nsearch space, enhancing computational efficiency. A highway lane change system\nserves as a motivating example, demonstrating how DOTechnique can uncover the\nvalidity region of a simulation model. The results highlight the potential of\nthe technique to support finding model validity through decision-maker context.", "AI": {"tldr": "\u63d0\u51fa\u4e86DOTechnique\u65b9\u6cd5\uff0c\u901a\u8fc7\u51b3\u7b56\u4e00\u81f4\u6027\u800c\u975e\u8f93\u51fa\u76f8\u4f3c\u6027\u6765\u786e\u5b9a\u6a21\u578b\u6709\u6548\u6027\uff0c\u5728\u7f3a\u4e4f\u660e\u786e\u6709\u6548\u6027\u8fb9\u754c\u65f6\u4ecd\u80fd\u9ad8\u6548\u8bc6\u522b\u6709\u6548\u533a\u57df\u3002", "motivation": "\u6a21\u578b\u6709\u6548\u6027\u5bf9\u51b3\u7b56\u8fc7\u7a0b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u9884\u5b9a\u4e49\u7684\u6709\u6548\u6027\u6846\u67b6\uff0c\u8fd9\u4e9b\u6846\u67b6\u53ef\u80fd\u4e0d\u53ef\u7528\u6216\u4e0d\u5145\u5206\u3002", "method": "\u5f15\u5165\u51b3\u7b56\u5bfc\u5411\u6280\u672f(DOTechnique)\uff0c\u901a\u8fc7\u8bc4\u4f30\u66ff\u4ee3\u6a21\u578b\u662f\u5426\u4e0e\u9ad8\u4fdd\u771f\u6a21\u578b\u4ea7\u751f\u7b49\u6548\u51b3\u7b56\u6765\u786e\u5b9a\u6a21\u578b\u6709\u6548\u6027\uff0c\u96c6\u6210\u9886\u57df\u7ea6\u675f\u548c\u7b26\u53f7\u63a8\u7406\u6765\u7f29\u5c0f\u641c\u7d22\u7a7a\u95f4\u3002", "result": "\u4ee5\u9ad8\u901f\u516c\u8def\u53d8\u9053\u7cfb\u7edf\u4e3a\u4f8b\uff0c\u5c55\u793a\u4e86DOTechnique\u5982\u4f55\u63ed\u793a\u4eff\u771f\u6a21\u578b\u7684\u6709\u6548\u6027\u533a\u57df\u3002", "conclusion": "\u8be5\u6280\u672f\u6709\u6f5c\u529b\u901a\u8fc7\u51b3\u7b56\u8005\u4e0a\u4e0b\u6587\u6765\u652f\u6301\u53d1\u73b0\u6a21\u578b\u6709\u6548\u6027\u3002"}}
{"id": "2510.14066", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14066", "abs": "https://arxiv.org/abs/2510.14066", "authors": ["Rajendra Upadhyay", "Al Nahian Bin Emran", "Rajendra Paudyal", "Lisa Donnan", "Duminda Wijesekera"], "title": "Quantitative Analysis of UAV Intrusion Mitigation for Border Security in 5G with LEO Backhaul Impairments", "comment": null, "summary": "Uncooperative unmanned aerial vehicles (UAVs) pose emerging threats to\ncritical infrastructure and border protection by operating as rogue user\nequipment (UE) within cellular networks, consuming resources, creating\ninterference, and potentially violating restricted airspaces. This paper\npresents minimal features of the operating space, yet an end-to-end simulation\nframework to analyze detect-to-mitigate latency of such intrusions in a hybrid\nterrestrial-non-terrestrial (LEO satellite) 5G system. The system model\nincludes terrestrial gNBs, satellite backhaul (with stochastic outages), and a\ndetection logic (triggered by handover instability and signal quality\nvariance). A lockdown mechanism is invoked upon detection, with optional local\nfallback to cap mitigation delays. Monte Carlo sweeps across UAV altitudes,\nspeeds, and satellite outage rates yield several insights. First, satellite\nbackhaul outages can cause arbitrarily long mitigation delays, yet, to meet\nfallback deadlines, they need to be effectively bounded. Second, while handover\ninstability was hypothesized, our results show that extra handovers have a\nnegligible effect within the range of parameters we considered. The main\nbenefit of resilience from fallback comes from the delay in limiting\nmitigation. Third, patrol UEs experience negligible collateral impact, with\nhandover rates close to terrestrial baselines. Stress scenarios further\nhighlight that fallback is indispensable in preventing extreme control-plane\nand physical security vulnerabilities: Without fallback, prolonged outages in\nthe satellite backhaul delay lockdown commands, allowing rogue UAVs to linger\ninside restricted corridors for several seconds longer. These results\nunderscore the importance of complementing non-terrestrial links with local\ncontrol to ensure robust and timely response against uncooperative UAV\nintrusions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7aef\u5230\u7aef\u4eff\u771f\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u6df7\u5408\u5730\u9762-\u975e\u5730\u97625G\u7cfb\u7edf\u4e2d\u65e0\u4eba\u673a\u5165\u4fb5\u7684\u68c0\u6d4b\u5230\u7f13\u89e3\u5ef6\u8fdf\uff0c\u5f3a\u8c03\u536b\u661f\u56de\u7a0b\u4e2d\u65ad\u5bf9\u7f13\u89e3\u5ef6\u8fdf\u7684\u5f71\u54cd\u4ee5\u53ca\u672c\u5730\u56de\u9000\u673a\u5236\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u975e\u5408\u4f5c\u65e0\u4eba\u673a\u5728\u8702\u7a9d\u7f51\u7edc\u4e2d\u4f5c\u4e3a\u6d41\u6c13\u7528\u6237\u8bbe\u5907\u8fd0\u884c\uff0c\u6d88\u8017\u8d44\u6e90\u3001\u4ea7\u751f\u5e72\u6270\u5e76\u53ef\u80fd\u4fb5\u72af\u9650\u5236\u7a7a\u57df\uff0c\u5bf9\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u548c\u8fb9\u5883\u4fdd\u62a4\u6784\u6210\u5a01\u80c1\u3002", "method": "\u4f7f\u7528\u5305\u542b\u5730\u9762gNB\u3001\u536b\u661f\u56de\u7a0b\uff08\u5177\u6709\u968f\u673a\u4e2d\u65ad\uff09\u548c\u68c0\u6d4b\u903b\u8f91\uff08\u7531\u5207\u6362\u4e0d\u7a33\u5b9a\u6027\u548c\u4fe1\u53f7\u8d28\u91cf\u65b9\u5dee\u89e6\u53d1\uff09\u7684\u7cfb\u7edf\u6a21\u578b\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6a21\u62df\u5206\u6790\u65e0\u4eba\u673a\u9ad8\u5ea6\u3001\u901f\u5ea6\u548c\u536b\u661f\u4e2d\u65ad\u7387\u7684\u5f71\u54cd\u3002", "result": "\u536b\u661f\u56de\u7a0b\u4e2d\u65ad\u4f1a\u5bfc\u81f4\u4efb\u610f\u957f\u7684\u7f13\u89e3\u5ef6\u8fdf\uff1b\u989d\u5916\u5207\u6362\u5728\u53c2\u6570\u8303\u56f4\u5185\u5f71\u54cd\u53ef\u5ffd\u7565\uff1b\u56de\u9000\u673a\u5236\u5728\u9650\u5236\u7f13\u89e3\u5ef6\u8fdf\u65b9\u9762\u63d0\u4f9b\u4e3b\u8981\u5f39\u6027\u6548\u76ca\uff1b\u5de1\u903bUE\u53d7\u5230\u53ef\u5ffd\u7565\u7684\u9644\u5e26\u5f71\u54cd\u3002", "conclusion": "\u5fc5\u987b\u5c06\u975e\u5730\u9762\u94fe\u8def\u4e0e\u672c\u5730\u63a7\u5236\u76f8\u7ed3\u5408\uff0c\u4ee5\u786e\u4fdd\u5bf9\u975e\u5408\u4f5c\u65e0\u4eba\u673a\u5165\u4fb5\u7684\u7a33\u5065\u548c\u53ca\u65f6\u54cd\u5e94\uff0c\u56de\u9000\u673a\u5236\u5bf9\u4e8e\u9632\u6b62\u6781\u7aef\u63a7\u5236\u5e73\u9762\u548c\u7269\u7406\u5b89\u5168\u6f0f\u6d1e\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2510.14036", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14036", "abs": "https://arxiv.org/abs/2510.14036", "authors": ["Qiushi Wu", "Yue Xiao", "Dhilung Kirat", "Kevin Eykholt", "Jiyong Jang", "Douglas Lee Schales"], "title": "One Bug, Hundreds Behind: LLMs for Large-Scale Bug Discovery", "comment": null, "summary": "Fixing bugs in large programs is a challenging task that demands substantial\ntime and effort. Once a bug is found, it is reported to the project\nmaintainers, who work with the reporter to fix it and eventually close the\nissue. However, across the program, there are often similar code segments,\nwhich may also contain the bug, but were missed during discovery. Finding and\nfixing each recurring bug instance individually is labor intensive. Even more\nconcerning, bug reports can inadvertently widen the attack surface as they\nprovide attackers with an exploitable pattern that may be unresolved in other\nparts of the program.\n  In this paper, we explore these Recurring Pattern Bugs (RPBs) that appear\nrepeatedly across various code segments of a program or even in different\nprograms, stemming from a same root cause, but are unresolved. Our\ninvestigation reveals that RPBs are widespread and can significantly compromise\nthe security of software programs. This paper introduces BugStone, a program\nanalysis system empowered by LLVM and a Large Language Model (LLM). The key\nobservation is that many RPBs have one patched instance, which can be leveraged\nto identify a consistent error pattern, such as a specific API misuse. By\nexamining the entire program for this pattern, it is possible to identify\nsimilar sections of code that may be vulnerable. Starting with 135 unique RPBs,\nBugStone identified more than 22K new potential issues in the Linux kernel.\nManual analysis of 400 of these findings confirmed that 246 were valid. We also\ncreated a dataset from over 1.9K security bugs reported by 23 recent top-tier\nconference works. We manually annotate the dataset, identify 80 recurring\npatterns and 850 corresponding fixes. Even with a cost-efficient model choice,\nBugStone achieved 92.2% precision and 79.1% pairwise accuracy on the dataset.", "AI": {"tldr": "BugStone\u662f\u4e00\u4e2a\u57fa\u4e8eLLVM\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7a0b\u5e8f\u5206\u6790\u7cfb\u7edf\uff0c\u80fd\u591f\u5229\u7528\u5df2\u4fee\u590d\u7684bug\u5b9e\u4f8b\u8bc6\u522b\u4ee3\u7801\u4e2d\u91cd\u590d\u51fa\u73b0\u7684\u9519\u8bef\u6a21\u5f0f\uff0c\u5728Linux\u5185\u6838\u4e2d\u53d1\u73b0\u4e86\u8d85\u8fc722K\u4e2a\u6f5c\u5728\u95ee\u9898\uff0c\u9a8c\u8bc1\u4e86246\u4e2a\u6709\u6548bug\u3002", "motivation": "\u5927\u578b\u7a0b\u5e8f\u4e2d\u7684\u91cd\u590d\u6a21\u5f0fbug\uff08RPBs\uff09\u5e7f\u6cdb\u5b58\u5728\u4e14\u4e25\u91cd\u5f71\u54cd\u8f6f\u4ef6\u5b89\u5168\uff0c\u4f46\u9010\u4e2a\u53d1\u73b0\u548c\u4fee\u590d\u8fd9\u4e9b\u91cd\u590dbug\u5b9e\u4f8b\u975e\u5e38\u8017\u65f6\u8d39\u529b\u3002", "method": "\u5229\u7528LLVM\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u5206\u6790\u5df2\u4fee\u590d\u7684bug\u5b9e\u4f8b\u6765\u8bc6\u522b\u4e00\u81f4\u7684\u9519\u8bef\u6a21\u5f0f\uff08\u5982\u7279\u5b9aAPI\u8bef\u7528\uff09\uff0c\u7136\u540e\u5728\u6574\u4e2a\u7a0b\u5e8f\u4e2d\u641c\u7d22\u76f8\u4f3c\u6a21\u5f0f\u6765\u53d1\u73b0\u6f5c\u5728\u6f0f\u6d1e\u3002", "result": "\u4ece135\u4e2a\u72ec\u7279RPBs\u51fa\u53d1\uff0c\u5728Linux\u5185\u6838\u4e2d\u8bc6\u522b\u4e86\u8d85\u8fc722K\u4e2a\u6f5c\u5728\u95ee\u9898\uff0c\u624b\u52a8\u9a8c\u8bc1400\u4e2a\u53d1\u73b0\u4e2d246\u4e2a\u6709\u6548\uff1b\u57281.9K\u5b89\u5168bug\u6570\u636e\u96c6\u4e2d\u8bc6\u522b80\u4e2a\u91cd\u590d\u6a21\u5f0f\u548c850\u4e2a\u5bf9\u5e94\u4fee\u590d\uff0c\u8fbe\u523092.2%\u7cbe\u5ea6\u548c79.1%\u914d\u5bf9\u51c6\u786e\u7387\u3002", "conclusion": "BugStone\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u8bc6\u522b\u548c\u5b9a\u4f4d\u7a0b\u5e8f\u4e2d\u7684\u91cd\u590d\u6a21\u5f0fbug\uff0c\u663e\u8457\u63d0\u9ad8bug\u53d1\u73b0\u6548\u7387\uff0c\u4e3a\u8f6f\u4ef6\u5b89\u5168\u63d0\u4f9b\u6709\u529b\u652f\u6301\u3002"}}
{"id": "2510.13979", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.13979", "abs": "https://arxiv.org/abs/2510.13979", "authors": ["Supriti Sinhamahapatra", "Jan Niehues"], "title": "Do Slides Help? Multi-modal Context for Automatic Transcription of Conference Talks", "comment": null, "summary": "State-of-the-art (SOTA) Automatic Speech Recognition (ASR) systems primarily\nrely on acoustic information while disregarding additional multi-modal context.\nHowever, visual information are essential in disambiguation and adaptation.\nWhile most work focus on speaker images to handle noise conditions, this work\nalso focuses on integrating presentation slides for the use cases of scientific\npresentation.\n  In a first step, we create a benchmark for multi-modal presentation including\nan automatic analysis of transcribing domain-specific terminology. Next, we\nexplore methods for augmenting speech models with multi-modal information. We\nmitigate the lack of datasets with accompanying slides by a suitable approach\nof data augmentation. Finally, we train a model using the augmented dataset,\nresulting in a relative reduction in word error rate of approximately 34%,\nacross all words and 35%, for domain-specific terms compared to the baseline\nmodel.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u878d\u5408\u89c6\u89c9\u4fe1\u606f\uff08\u7279\u522b\u662f\u6f14\u793a\u6587\u7a3f\u5e7b\u706f\u7247\uff09\u7684\u591a\u6a21\u6001\u8bed\u97f3\u8bc6\u522b\u65b9\u6cd5\uff0c\u5728\u79d1\u5b66\u6f14\u793a\u573a\u666f\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u8bc6\u522b\u51c6\u786e\u7387\uff0c\u7279\u522b\u662f\u5bf9\u9886\u57df\u7279\u5b9a\u672f\u8bed\u7684\u8bc6\u522b\u3002", "motivation": "\u5f53\u524d\u6700\u5148\u8fdb\u7684\u8bed\u97f3\u8bc6\u522b\u7cfb\u7edf\u4e3b\u8981\u4f9d\u8d56\u97f3\u9891\u4fe1\u606f\u800c\u5ffd\u7565\u4e86\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u3002\u89c6\u89c9\u4fe1\u606f\u5bf9\u4e8e\u6d88\u9664\u6b67\u4e49\u548c\u9002\u5e94\u573a\u666f\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u5728\u79d1\u5b66\u6f14\u793a\u573a\u666f\u4e2d\uff0c\u6f14\u793a\u6587\u7a3f\u5e7b\u706f\u7247\u5305\u542b\u91cd\u8981\u4fe1\u606f\u3002", "method": "\u9996\u5148\u521b\u5efa\u4e86\u591a\u6a21\u6001\u6f14\u793a\u57fa\u51c6\uff0c\u5305\u62ec\u9886\u57df\u7279\u5b9a\u672f\u8bed\u7684\u81ea\u52a8\u5206\u6790\uff1b\u7136\u540e\u63a2\u7d22\u4e86\u7528\u591a\u6a21\u6001\u4fe1\u606f\u589e\u5f3a\u8bed\u97f3\u6a21\u578b\u7684\u65b9\u6cd5\uff1b\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u89e3\u51b3\u7f3a\u4e4f\u914d\u5957\u5e7b\u706f\u7247\u6570\u636e\u96c6\u7684\u95ee\u9898\uff1b\u6700\u540e\u4f7f\u7528\u589e\u5f3a\u6570\u636e\u96c6\u8bad\u7ec3\u6a21\u578b\u3002", "result": "\u8bad\u7ec3\u5f97\u5230\u7684\u6a21\u578b\u76f8\u6bd4\u57fa\u7ebf\u6a21\u578b\uff0c\u5728\u6240\u6709\u8bcd\u6c47\u4e0a\u7684\u8bcd\u9519\u8bef\u7387\u76f8\u5bf9\u964d\u4f4e\u4e86\u7ea634%\uff0c\u5728\u9886\u57df\u7279\u5b9a\u672f\u8bed\u4e0a\u7684\u8bcd\u9519\u8bef\u7387\u76f8\u5bf9\u964d\u4f4e\u4e86\u7ea635%\u3002", "conclusion": "\u96c6\u6210\u6f14\u793a\u6587\u7a3f\u5e7b\u706f\u7247\u7b49\u89c6\u89c9\u4fe1\u606f\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u8bed\u97f3\u8bc6\u522b\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u9886\u57df\u7279\u5b9a\u672f\u8bed\u65f6\u6548\u679c\u66f4\u52a0\u660e\u663e\u3002"}}
{"id": "2510.14086", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14086", "abs": "https://arxiv.org/abs/2510.14086", "authors": ["Matthew Finlayson", "Xiang Ren", "Swabha Swayamdipta"], "title": "Every Language Model Has a Forgery-Resistant Signature", "comment": null, "summary": "The ubiquity of closed-weight language models with public-facing APIs has\ngenerated interest in forensic methods, both for extracting hidden model\ndetails (e.g., parameters) and for identifying models by their outputs. One\nsuccessful approach to these goals has been to exploit the geometric\nconstraints imposed by the language model architecture and parameters. In this\nwork, we show that a lesser-known geometric constraint--namely, that language\nmodel outputs lie on the surface of a high-dimensional ellipse--functions as a\nsignature for the model and can be used to identify the source model of a given\noutput. This ellipse signature has unique properties that distinguish it from\nexisting model-output association methods like language model fingerprints. In\nparticular, the signature is hard to forge: without direct access to model\nparameters, it is practically infeasible to produce log-probabilities\n(logprobs) on the ellipse. Secondly, the signature is naturally occurring,\nsince all language models have these elliptical constraints. Thirdly, the\nsignature is self-contained, in that it is detectable without access to the\nmodel inputs or the full weights. Finally, the signature is compact and\nredundant, as it is independently detectable in each logprob output from the\nmodel. We evaluate a novel technique for extracting the ellipse from small\nmodels and discuss the practical hurdles that make it infeasible for\nproduction-scale models. Finally, we use ellipse signatures to propose a\nprotocol for language model output verification, analogous to cryptographic\nsymmetric-key message authentication systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u51e0\u4f55\u7ea6\u675f\u7684\u692d\u5706\u7b7e\u540d\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc6\u522b\u6a21\u578b\u6765\u6e90\u548c\u9a8c\u8bc1\u8f93\u51fa\u771f\u5b9e\u6027\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u4f4d\u4e8e\u9ad8\u7ef4\u692d\u5706\u8868\u9762\u7684\u7279\u6027\u4f5c\u4e3a\u6a21\u578b\u7b7e\u540d\u3002", "motivation": "\u968f\u7740\u95ed\u6e90\u6743\u91cd\u8bed\u8a00\u6a21\u578bAPI\u7684\u666e\u53ca\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u63d0\u53d6\u9690\u85cf\u6a21\u578b\u7ec6\u8282\u548c\u8bc6\u522b\u6a21\u578b\u6765\u6e90\u7684\u53d6\u8bc1\u65b9\u6cd5\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5229\u7528\u8bed\u8a00\u6a21\u578b\u67b6\u6784\u548c\u53c2\u6570\u65bd\u52a0\u7684\u51e0\u4f55\u7ea6\u675f\u3002", "method": "\u5229\u7528\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u4f4d\u4e8e\u9ad8\u7ef4\u692d\u5706\u8868\u9762\u7684\u51e0\u4f55\u7ea6\u675f\u4f5c\u4e3a\u6a21\u578b\u7b7e\u540d\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u4ece\u6a21\u578b\u8f93\u51fa\u4e2d\u63d0\u53d6\u692d\u5706\u7279\u5f81\u6765\u8bc6\u522b\u6e90\u6a21\u578b\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u5c0f\u6a21\u578b\u4e2d\u63d0\u53d6\u692d\u5706\u7684\u65b0\u6280\u672f\u3002", "result": "\u692d\u5706\u7b7e\u540d\u5177\u6709\u96be\u4ee5\u4f2a\u9020\u3001\u81ea\u7136\u5b58\u5728\u3001\u81ea\u5305\u542b\u3001\u7d27\u51d1\u5197\u4f59\u7b49\u72ec\u7279\u7279\u6027\u3002\u7814\u7a76\u8bc4\u4f30\u4e86\u4ece\u5c0f\u6a21\u578b\u63d0\u53d6\u692d\u5706\u7684\u6280\u672f\uff0c\u5e76\u8ba8\u8bba\u4e86\u5728\u751f\u4ea7\u89c4\u6a21\u6a21\u578b\u4e2d\u5e94\u7528\u7684\u5b9e\u8df5\u969c\u788d\u3002", "conclusion": "\u692d\u5706\u7b7e\u540d\u53ef\u4f5c\u4e3a\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u9a8c\u8bc1\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u7c7b\u4f3c\u4e8e\u5bc6\u7801\u5b66\u4e2d\u7684\u5bf9\u79f0\u5bc6\u94a5\u6d88\u606f\u8ba4\u8bc1\u7cfb\u7edf\uff0c\u4e3a\u6a21\u578b\u6765\u6e90\u8bc6\u522b\u548c\u8f93\u51fa\u771f\u5b9e\u6027\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2510.14115", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14115", "abs": "https://arxiv.org/abs/2510.14115", "authors": ["Philipp Bauerfeind", "Amir Salarpour", "David Fernandez", "Pedram MohajerAnsari", "Johannes Reschke", "Mert D. Pes\u00e9"], "title": "David vs. Goliath: A comparative study of different-sized LLMs for code generation in the domain of automotive scenario generation", "comment": null, "summary": "Scenario simulation is central to testing autonomous driving systems. Scenic,\na domain-specific language (DSL) for CARLA, enables precise and reproducible\nscenarios, but NL-to-Scenic generation with large language models (LLMs)\nsuffers from scarce data, limited reproducibility, and inconsistent metrics. We\nintroduce NL2Scenic, an open dataset and framework with 146 NL/Scenic pairs, a\ndifficulty-stratified 30-case test split, an Example Retriever, and 14\nprompting variants (ZS, FS, CoT, SP, MoT). We evaluate 13 models: four\nproprietary (GPT-4o, GPT-5, Claude-Sonnet-4, Gemini-2.5-pro) and nine\nopen-source code models (Qwen2.5Coder 0.5B-32B; CodeLlama 7B/13B/34B), using\ntext metrics (BLEU, ChrF, EDIT-SIM, CrystalBLEU) and execution metrics\n(compilation and generation), and compare them with an expert study (n=11).\nEDIT-SIM correlates best with human judgments; we also propose EDIT-COMP (F1 of\nEDIT-SIM and compilation) as a robust dataset-level proxy that improves ranking\nfidelity. GPT-4o performs best overall, while Qwen2.5Coder-14B reaches about 88\npercent of its expert score on local hardware. Retrieval-augmented prompting,\nFew-Shot with Example Retriever (FSER), consistently boosts smaller models, and\nscaling shows diminishing returns beyond mid-size, with Qwen2.5Coder\noutperforming CodeLlama at comparable scales. NL2Scenic and EDIT-COMP offer a\nstandardized, reproducible basis for evaluating Scenic code generation and\nindicate that mid-size open-source models are practical, cost-effective options\nfor autonomous-driving scenario programming.", "AI": {"tldr": "NL2Scenic\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u81ea\u7136\u8bed\u8a00\u5230Scenic\u4ee3\u7801\u751f\u6210\u7684\u5f00\u653e\u6570\u636e\u96c6\u548c\u6846\u67b6\uff0c\u5305\u542b146\u4e2aNL/Scenic\u5bf9\u548c30\u4e2a\u6d4b\u8bd5\u6848\u4f8b\uff0c\u8bc4\u4f30\u4e8613\u4e2a\u6a21\u578b\u5e76\u63d0\u51fa\u4e86EDIT-COMP\u4f5c\u4e3a\u9c81\u68d2\u8bc4\u4f30\u6307\u6807\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709NL-to-Scenic\u751f\u6210\u4e2d\u6570\u636e\u7a00\u7f3a\u3001\u53ef\u590d\u73b0\u6027\u5dee\u548c\u8bc4\u4f30\u6307\u6807\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u573a\u666f\u7f16\u7a0b\u63d0\u4f9b\u6807\u51c6\u5316\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "\u6784\u5efaNL2Scenic\u6570\u636e\u96c6\uff0c\u5f00\u53d1Example Retriever\u548c14\u79cd\u63d0\u793a\u53d8\u4f53\uff0c\u4f7f\u7528\u6587\u672c\u6307\u6807\u548c\u6267\u884c\u6307\u6807\u8bc4\u4f3013\u4e2a\u6a21\u578b\uff0c\u5e76\u4e0e\u4e13\u5bb6\u7814\u7a76\u5bf9\u6bd4\u3002", "result": "EDIT-SIM\u4e0e\u4eba\u7c7b\u5224\u65ad\u76f8\u5173\u6027\u6700\u597d\uff0cGPT-4o\u8868\u73b0\u6700\u4f73\uff0cQwen2.5Coder-14B\u8fbe\u5230\u517688%\u7684\u4e13\u5bb6\u5206\u6570\uff0c\u68c0\u7d22\u589e\u5f3a\u63d0\u793a\u80fd\u63d0\u5347\u5c0f\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "NL2Scenic\u548cEDIT-COMP\u4e3aScenic\u4ee3\u7801\u751f\u6210\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u8bc4\u4f30\u57fa\u7840\uff0c\u8868\u660e\u4e2d\u7b49\u89c4\u6a21\u5f00\u6e90\u6a21\u578b\u662f\u81ea\u52a8\u9a7e\u9a76\u573a\u666f\u7f16\u7a0b\u7684\u5b9e\u7528\u4e14\u7ecf\u6d4e\u7684\u9009\u62e9\u3002"}}
{"id": "2510.13985", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13985", "abs": "https://arxiv.org/abs/2510.13985", "authors": ["Mar\u00eda Victoria Carro", "Denise Alejandra Mester", "Francisca Gauna Selasco", "Giovanni Franco Gabriel Marraffini", "Mario Alejandro Leiva", "Gerardo I. Simari", "Mar\u00eda Vanina Martinez"], "title": "Do Large Language Models Show Biases in Causal Learning? Insights from Contingency Judgment", "comment": null, "summary": "Causal learning is the cognitive process of developing the capability of\nmaking causal inferences based on available information, often guided by\nnormative principles. This process is prone to errors and biases, such as the\nillusion of causality, in which people perceive a causal relationship between\ntwo variables despite lacking supporting evidence. This cognitive bias has been\nproposed to underlie many societal problems, including social prejudice,\nstereotype formation, misinformation, and superstitious thinking. In this work,\nwe examine whether large language models are prone to developing causal\nillusions when faced with a classic cognitive science paradigm: the contingency\njudgment task. To investigate this, we constructed a dataset of 1,000 null\ncontingency scenarios (in which the available information is not sufficient to\nestablish a causal relationship between variables) within medical contexts and\nprompted LLMs to evaluate the effectiveness of potential causes. Our findings\nshow that all evaluated models systematically inferred unwarranted causal\nrelationships, revealing a strong susceptibility to the illusion of causality.\nWhile there is ongoing debate about whether LLMs genuinely understand causality\nor merely reproduce causal language without true comprehension, our findings\nsupport the latter hypothesis and raise concerns about the use of language\nmodels in domains where accurate causal reasoning is essential for informed\ndecision-making.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u56e0\u679c\u63a8\u7406\u4efb\u52a1\u4e2d\u5bb9\u6613\u4ea7\u751f\u56e0\u679c\u5e7b\u89c9\uff0c\u5373\u4f7f\u5728\u6ca1\u6709\u8db3\u591f\u8bc1\u636e\u652f\u6301\u7684\u60c5\u51b5\u4e0b\u4e5f\u4f1a\u9519\u8bef\u5730\u63a8\u65ad\u56e0\u679c\u5173\u7cfb\u3002", "motivation": "\u63a2\u8ba8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u4f1a\u5728\u7ecf\u5178\u7684\u8ba4\u77e5\u79d1\u5b66\u8303\u5f0f\u2014\u2014\u5217\u8054\u5224\u65ad\u4efb\u52a1\u4e2d\u4ea7\u751f\u56e0\u679c\u5e7b\u89c9\uff0c\u8fd9\u79cd\u8ba4\u77e5\u504f\u5dee\u53ef\u80fd\u5bf9\u793e\u4f1a\u95ee\u9898\u5982\u504f\u89c1\u3001\u523b\u677f\u5370\u8c61\u548c\u8ff7\u4fe1\u601d\u7ef4\u4ea7\u751f\u5f71\u54cd\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b1000\u4e2a\u96f6\u5217\u8054\u573a\u666f\u7684\u533b\u7597\u6570\u636e\u96c6\uff0c\u8ba9LLMs\u8bc4\u4f30\u6f5c\u5728\u539f\u56e0\u7684\u6709\u6548\u6027\uff0c\u8fd9\u4e9b\u573a\u666f\u4e2d\u7684\u4fe1\u606f\u4e0d\u8db3\u4ee5\u5efa\u7acb\u53d8\u91cf\u95f4\u7684\u56e0\u679c\u5173\u7cfb\u3002", "result": "\u6240\u6709\u8bc4\u4f30\u7684\u6a21\u578b\u90fd\u7cfb\u7edf\u5730\u63a8\u65ad\u51fa\u65e0\u6839\u636e\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u663e\u793a\u51fa\u5bf9\u56e0\u679c\u5e7b\u89c9\u7684\u5f3a\u70c8\u6613\u611f\u6027\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u652f\u6301LLMs\u53ea\u662f\u590d\u5236\u56e0\u679c\u8bed\u8a00\u800c\u975e\u771f\u6b63\u7406\u89e3\u56e0\u679c\u5173\u7cfb\u7684\u5047\u8bbe\uff0c\u5bf9\u5728\u9700\u8981\u51c6\u786e\u56e0\u679c\u63a8\u7406\u7684\u9886\u57df\u4e2d\u4f7f\u7528\u8bed\u8a00\u6a21\u578b\u63d0\u51fa\u4e86\u62c5\u5fe7\u3002"}}
{"id": "2510.14171", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14171", "abs": "https://arxiv.org/abs/2510.14171", "authors": ["Jack Vanlyssel"], "title": "Power Grid Cybersecurity: Policy Analysis White Paper", "comment": null, "summary": "The U.S. power grid underpins national security, public safety, and economic\nstability, but faces growing cyber risks from vulnerabilities in industrial\ncontrol systems, remote access, and poor cyber hygiene. Despite its critical\nimportance, current policy remains fragmented and reactive. This paper proposes\na dual policy approach to strengthen grid cybersecurity: enhanced information\nsharing between government and private utilities to improve threat detection\nand response, and standardized cyber hygiene practices to reduce common attack\nvectors. For long-term resilience, a Unified National Cybersecurity Framework\nis recommended to align existing NERC, IEC, IEEE, and NIST standards, eliminate\nregulatory overlap, and adapt to evolving threats. Together, these policies\noffer both immediate and sustainable improvements in safeguarding the nation's\nmost vital infrastructure.", "AI": {"tldr": "\u63d0\u51fa\u53cc\u91cd\u653f\u7b56\u65b9\u6cd5\u52a0\u5f3a\u7535\u7f51\u7f51\u7edc\u5b89\u5168\uff1a\u52a0\u5f3a\u653f\u5e9c\u4e0e\u79c1\u8425\u7535\u529b\u516c\u53f8\u4e4b\u95f4\u7684\u4fe1\u606f\u5171\u4eab\u4ee5\u6539\u5584\u5a01\u80c1\u68c0\u6d4b\u548c\u54cd\u5e94\uff0c\u4ee5\u53ca\u6807\u51c6\u5316\u7f51\u7edc\u536b\u751f\u5b9e\u8df5\u4ee5\u51cf\u5c11\u5e38\u89c1\u653b\u51fb\u5411\u91cf\u3002", "motivation": "\u7f8e\u56fd\u7535\u7f51\u9762\u4e34\u5de5\u4e1a\u63a7\u5236\u7cfb\u7edf\u6f0f\u6d1e\u3001\u8fdc\u7a0b\u8bbf\u95ee\u548c\u7f51\u7edc\u536b\u751f\u4e0d\u826f\u7b49\u65e5\u76ca\u589e\u957f\u7684\u7f51\u7edc\u5b89\u5168\u98ce\u9669\uff0c\u5a01\u80c1\u56fd\u5bb6\u5b89\u5168\u3001\u516c\u5171\u5b89\u5168\u548c\u7ecf\u6d4e\u7a33\u5b9a\uff0c\u4f46\u5f53\u524d\u653f\u7b56\u4ecd\u5206\u6563\u4e14\u88ab\u52a8\u3002", "method": "\u91c7\u7528\u53cc\u91cd\u653f\u7b56\u65b9\u6cd5\uff1a1) \u52a0\u5f3a\u653f\u5e9c\u4e0e\u79c1\u8425\u7535\u529b\u516c\u53f8\u4e4b\u95f4\u7684\u4fe1\u606f\u5171\u4eab\uff1b2) \u6807\u51c6\u5316\u7f51\u7edc\u536b\u751f\u5b9e\u8df5\u3002\u957f\u671f\u5efa\u8bae\u5efa\u7acb\u7edf\u4e00\u7684\u56fd\u5bb6\u7f51\u7edc\u5b89\u5168\u6846\u67b6\uff0c\u534f\u8c03\u73b0\u6709NERC\u3001IEC\u3001IEEE\u548cNIST\u6807\u51c6\u3002", "result": "\u8fd9\u4e9b\u653f\u7b56\u80fd\u591f\u63d0\u4f9b\u5373\u65f6\u548c\u53ef\u6301\u7eed\u7684\u6539\u8fdb\uff0c\u901a\u8fc7\u6539\u5584\u5a01\u80c1\u68c0\u6d4b\u548c\u54cd\u5e94\u80fd\u529b\uff0c\u51cf\u5c11\u5e38\u89c1\u653b\u51fb\u5411\u91cf\uff0c\u589e\u5f3a\u7535\u7f51\u7f51\u7edc\u5b89\u5168\u3002", "conclusion": "\u53cc\u91cd\u653f\u7b56\u65b9\u6cd5\u7ed3\u5408\u7edf\u4e00\u7684\u56fd\u5bb6\u7f51\u7edc\u5b89\u5168\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u4fdd\u62a4\u56fd\u5bb6\u6700\u5173\u952e\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u5e94\u5bf9\u4e0d\u65ad\u6f14\u53d8\u7684\u7f51\u7edc\u5a01\u80c1\u3002"}}
{"id": "2510.14279", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2510.14279", "abs": "https://arxiv.org/abs/2510.14279", "authors": ["Evangelos Lamprou", "Seong-Heon Jung", "Mayank Keoliya", "Lukas Lazarek", "Konstantinos Kallas", "Michael Greenberg", "Nikos Vasilakis"], "title": "Caruca: Effective and Efficient Specification Mining for Opaque Software Components", "comment": null, "summary": "A wealth of state-of-the-art systems demonstrate impressive improvements in\nperformance, security, and reliability on programs composed of opaque\ncomponents, such as Unix shell commands. To reason about commands, these\nsystems require partial specifications. However, creating such specifications\nis a manual, laborious, and error-prone process, limiting the practicality of\nthese systems. This paper presents Caruca, a system for automatic specification\nmining for opaque commands. To overcome the challenge of language diversity\nacross commands, Caruca first instruments a large language model to translate a\ncommand's user-facing documentation into a structured invocation syntax. Using\nthis representation, Caruca explores the space of syntactically valid command\ninvocations and execution environments. Caruca concretely executes each\ncommand-environment pair, interposing at the system-call and filesystem level\nto extract key command properties such as parallelizability and filesystem pre-\nand post-conditions. These properties can be exported in multiple specification\nformats and are immediately usable by existing systems. Applying Caruca across\n60 GNU Coreutils, POSIX, and third-party commands across several\nspecification-dependent systems shows that Caruca generates correct\nspecifications for all but one case, completely eliminating manual effort from\nthe process and currently powering the full specifications for a\nstate-of-the-art static analysis tool.", "AI": {"tldr": "Caruca\u662f\u4e00\u4e2a\u81ea\u52a8\u4e3a\u4e0d\u900f\u660e\u547d\u4ee4\u6316\u6398\u89c4\u8303\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u6587\u6863\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u8c03\u7528\u8bed\u6cd5\uff0c\u63a2\u7d22\u6709\u6548\u547d\u4ee4\u8c03\u7528\u548c\u6267\u884c\u73af\u5883\uff0c\u63d0\u53d6\u5e76\u884c\u6027\u548c\u6587\u4ef6\u7cfb\u7edf\u524d\u540e\u6761\u4ef6\u7b49\u5173\u952e\u5c5e\u6027\u3002", "motivation": "\u73b0\u6709\u7cfb\u7edf\u9700\u8981\u624b\u52a8\u521b\u5efa\u547d\u4ee4\u89c4\u8303\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u8017\u65f6\u3001\u6613\u9519\u4e14\u9650\u5236\u4e86\u7cfb\u7edf\u7684\u5b9e\u7528\u6027\uff0c\u56e0\u6b64\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u547d\u4ee4\u6587\u6863\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u8c03\u7528\u8bed\u6cd5\uff0c\u63a2\u7d22\u8bed\u6cd5\u6709\u6548\u7684\u547d\u4ee4\u8c03\u7528\u548c\u6267\u884c\u73af\u5883\uff0c\u901a\u8fc7\u7cfb\u7edf\u8c03\u7528\u548c\u6587\u4ef6\u7cfb\u7edf\u62e6\u622a\u63d0\u53d6\u547d\u4ee4\u5c5e\u6027\u3002", "result": "\u572860\u4e2aGNU Coreutils\u3001POSIX\u548c\u7b2c\u4e09\u65b9\u547d\u4ee4\u4e0a\u6d4b\u8bd5\uff0cCaruca\u4e3a\u9664\u4e00\u4e2a\u6848\u4f8b\u5916\u7684\u6240\u6709\u60c5\u51b5\u751f\u6210\u4e86\u6b63\u786e\u89c4\u8303\uff0c\u5b8c\u5168\u6d88\u9664\u4e86\u624b\u52a8\u5de5\u4f5c\uff0c\u76ee\u524d\u4e3a\u6700\u5148\u8fdb\u7684\u9759\u6001\u5206\u6790\u5de5\u5177\u63d0\u4f9b\u5b8c\u6574\u89c4\u8303\u3002", "conclusion": "Caruca\u6210\u529f\u5b9e\u73b0\u4e86\u547d\u4ee4\u89c4\u8303\u7684\u81ea\u52a8\u6316\u6398\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u89c4\u8303\u4f9d\u8d56\u7cfb\u7edf\u7684\u5b9e\u7528\u6027\uff0c\u8bc1\u660e\u4e86\u81ea\u52a8\u5316\u89c4\u8303\u751f\u6210\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.14035", "categories": ["cs.AI", "I.2.6; I.2.9"], "pdf": "https://arxiv.org/pdf/2510.14035", "abs": "https://arxiv.org/abs/2510.14035", "authors": ["Rajesh Mangannavar", "Prasad Tadepalli"], "title": "GammaZero: Learning To Guide POMDP Belief Space Search With Graph Representations", "comment": "10 pages content. 2 pages references", "summary": "We introduce an action-centric graph representation framework for learning to\nguide planning in Partially Observable Markov Decision Processes (POMDPs).\nUnlike existing approaches that require domain-specific neural architectures\nand struggle with scalability, GammaZero leverages a unified graph-based belief\nrepresentation that enables generalization across problem sizes within a\ndomain. Our key insight is that belief states can be systematically transformed\ninto action-centric graphs where structural patterns learned on small problems\ntransfer to larger instances. We employ a graph neural network with a decoder\narchitecture to learn value functions and policies from expert demonstrations\non computationally tractable problems, then apply these learned heuristics to\nguide Monte Carlo tree search on larger problems. Experimental results on\nstandard POMDP benchmarks demonstrate that GammaZero achieves comparable\nperformance to BetaZero when trained and tested on the same-sized problems,\nwhile uniquely enabling zero-shot generalization to problems 2-4 times larger\nthan those seen during training, maintaining solution quality with reduced\nsearch requirements.", "AI": {"tldr": "GammaZero\u662f\u4e00\u4e2a\u57fa\u4e8e\u52a8\u4f5c\u4e2d\u5fc3\u56fe\u8868\u793a\u6846\u67b6\u7684POMDP\u89c4\u5212\u5b66\u4e60\u65b9\u6cd5\uff0c\u80fd\u591f\u901a\u8fc7\u5728\u5c0f\u95ee\u9898\u4e0a\u5b66\u4e60\u56fe\u7ed3\u6784\u6a21\u5f0f\uff0c\u5b9e\u73b0\u5411\u66f4\u5927\u89c4\u6a21\u95ee\u9898\u7684\u96f6\u6837\u672c\u6cdb\u5316\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u9886\u57df\u7279\u5b9a\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u4e14\u96be\u4ee5\u6269\u5c55\uff0cGammaZero\u65e8\u5728\u5f00\u53d1\u4e00\u4e2a\u7edf\u4e00\u7684\u57fa\u4e8e\u56fe\u7684\u4fe1\u5ff5\u8868\u793a\u6846\u67b6\uff0c\u5b9e\u73b0\u8de8\u95ee\u9898\u89c4\u6a21\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u5c06\u4fe1\u5ff5\u72b6\u6001\u7cfb\u7edf\u6027\u5730\u8f6c\u6362\u4e3a\u52a8\u4f5c\u4e2d\u5fc3\u56fe\uff0c\u4f7f\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u7f16\u7801\u5668\u67b6\u6784\u4ece\u4e13\u5bb6\u6f14\u793a\u4e2d\u5b66\u4e60\u4ef7\u503c\u51fd\u6570\u548c\u7b56\u7565\uff0c\u7136\u540e\u5e94\u7528\u8fd9\u4e9b\u5b66\u4e60\u5230\u7684\u542f\u53d1\u5f0f\u6765\u6307\u5bfc\u66f4\u5927\u95ee\u9898\u4e0a\u7684\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u3002", "result": "\u5728\u6807\u51c6POMDP\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGammaZero\u5728\u76f8\u540c\u89c4\u6a21\u95ee\u9898\u4e0a\u4e0eBetaZero\u6027\u80fd\u76f8\u5f53\uff0c\u540c\u65f6\u80fd\u591f\u96f6\u6837\u672c\u6cdb\u5316\u5230\u8bad\u7ec3\u65f6\u672a\u89c1\u8fc7\u76842-4\u500d\u5927\u89c4\u6a21\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u89e3\u8d28\u91cf\u7684\u540c\u65f6\u51cf\u5c11\u641c\u7d22\u9700\u6c42\u3002", "conclusion": "GammaZero\u901a\u8fc7\u52a8\u4f5c\u4e2d\u5fc3\u56fe\u8868\u793a\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86POMDP\u89c4\u5212\u4e2d\u7684\u8de8\u89c4\u6a21\u6cdb\u5316\uff0c\u4e3a\u53ef\u6269\u5c55\u7684\u89c4\u5212\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.14185", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14185", "abs": "https://arxiv.org/abs/2510.14185", "authors": ["Jack Vanlyssel"], "title": "Securing U.S. Critical Infrastructure: Lessons from Stuxnet and the Ukraine Power Grid Attacks", "comment": null, "summary": "Industrial Control Systems (ICS) underpin the United States' critical\ninfrastructure, managing essential services such as power, water, and\ntransportation that are vital to national security and public safety. However,\nincreasing digital integration has exposed these systems to escalating cyber\nthreats. Historical attacks like Stuxnet and the Ukraine power grid incident\nrevealed exploitable weaknesses-poor network segmentation, outdated software,\nweak authentication, and inadequate monitoring-that persist in many U.S. ICS\nenvironments today. This paper analyzes these landmark attacks to identify\nrecurring vulnerabilities and assess their relevance to current U.S.\ninfrastructure. It argues that without immediate reforms, similar exploits\ncould lead to catastrophic disruptions and national security crises. To address\nthese risks, the paper proposes policy measures focused on implementing\nzero-trust architecture and improved network segmentation to enhance system\nresilience. These recommendations aim to guide policymakers and industry\nleaders in securing the nation's most critical operational technologies against\nfuture cyber threats.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u5de5\u4e1a\u63a7\u5236\u7cfb\u7edf\u9762\u4e34\u7684\u7f51\u7edc\u5b89\u5168\u5a01\u80c1\uff0c\u901a\u8fc7\u7814\u7a76\u5386\u53f2\u653b\u51fb\u6848\u4f8b\u8bc6\u522b\u6f0f\u6d1e\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u96f6\u4fe1\u4efb\u67b6\u6784\u548c\u7f51\u7edc\u5206\u6bb5\u7684\u653f\u7b56\u5efa\u8bae\u6765\u4fdd\u62a4\u7f8e\u56fd\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u3002", "motivation": "\u5de5\u4e1a\u63a7\u5236\u7cfb\u7edf\u652f\u6491\u7740\u7f8e\u56fd\u5173\u952e\u57fa\u7840\u8bbe\u65bd\uff0c\u4f46\u65e5\u76ca\u589e\u957f\u7684\u7f51\u7edc\u5a01\u80c1\u66b4\u9732\u4e86\u8fd9\u4e9b\u7cfb\u7edf\u7684\u8106\u5f31\u6027\u3002\u5386\u53f2\u653b\u51fb\u4e8b\u4ef6\u63ed\u793a\u4e86\u6301\u7eed\u5b58\u5728\u7684\u5b89\u5168\u5f31\u70b9\uff0c\u9700\u8981\u7acb\u5373\u6539\u9769\u4ee5\u907f\u514d\u707e\u96be\u6027\u540e\u679c\u3002", "method": "\u901a\u8fc7\u5206\u6790Stuxnet\u548c\u4e4c\u514b\u5170\u7535\u7f51\u4e8b\u4ef6\u7b49\u5386\u53f2\u653b\u51fb\u6848\u4f8b\uff0c\u8bc6\u522b\u5de5\u4e1a\u63a7\u5236\u7cfb\u7edf\u4e2d\u53cd\u590d\u51fa\u73b0\u7684\u6f0f\u6d1e\uff0c\u5e76\u8bc4\u4f30\u8fd9\u4e9b\u6f0f\u6d1e\u5728\u5f53\u524d\u7f8e\u56fd\u57fa\u7840\u8bbe\u65bd\u4e2d\u7684\u76f8\u5173\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5de5\u4e1a\u63a7\u5236\u7cfb\u7edf\u5b58\u5728\u7f51\u7edc\u5206\u6bb5\u4e0d\u8db3\u3001\u8f6f\u4ef6\u8fc7\u65f6\u3001\u8ba4\u8bc1\u8584\u5f31\u548c\u76d1\u63a7\u4e0d\u8db3\u7b49\u6301\u7eed\u6027\u95ee\u9898\uff0c\u8fd9\u4e9b\u6f0f\u6d1e\u4f7f\u7f8e\u56fd\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u9762\u4e34\u4e25\u91cd\u98ce\u9669\u3002", "conclusion": "\u5efa\u8bae\u5b9e\u65bd\u96f6\u4fe1\u4efb\u67b6\u6784\u548c\u6539\u8fdb\u7684\u7f51\u7edc\u5206\u6bb5\u7b49\u653f\u7b56\u63aa\u65bd\uff0c\u4ee5\u589e\u5f3a\u7cfb\u7edf\u97e7\u6027\uff0c\u4fdd\u62a4\u5173\u952e\u64cd\u4f5c\u6280\u672f\u514d\u53d7\u672a\u6765\u7f51\u7edc\u5a01\u80c1\u3002"}}
{"id": "2510.14292", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.14292", "abs": "https://arxiv.org/abs/2510.14292", "authors": ["Haolin Pan", "Hongbin Zhang", "Mingjie Xing", "Yanjun Wu"], "title": "A Hybrid, Knowledge-Guided Evolutionary Framework for Personalized Compiler Auto-Tuning", "comment": null, "summary": "Compiler pass auto-tuning is critical for enhancing software performance, yet\nfinding the optimal pass sequence for a specific program is an NP-hard problem.\nTraditional, general-purpose optimization flags like -O3 and -Oz adopt a\none-size-fits-all approach, often failing to unlock a program's full\nperformance potential. To address this challenge, we propose a novel Hybrid,\nKnowledge-Guided Evolutionary Framework. This framework intelligently guides\nonline, personalized optimization using knowledge extracted from a large-scale\noffline analysis phase. During the offline stage, we construct a comprehensive\ncompilation knowledge base composed of four key components: (1) Pass Behavioral\nVectors to quantitatively capture the effectiveness of each optimization; (2)\nPass Groups derived from clustering these vectors based on behavior similarity;\n(3) a Synergy Pass Graph to model beneficial sequential interactions; and (4) a\nlibrary of Prototype Pass Sequences evolved for distinct program types. In the\nonline stage, a bespoke genetic algorithm leverages this rich knowledge base\nthrough specially designed, knowledge-infused genetic operators. These\noperators transform the search by performing semantically-aware recombination\nand targeted, restorative mutations. On a suite of seven public datasets, our\nframework achieves an average of 11.0% additional LLVM IR instruction reduction\nover the highly-optimized opt -Oz baseline, demonstrating its state-of-the-art\ncapability in discovering personalized, high-performance optimization\nsequences.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u77e5\u8bc6\u5f15\u5bfc\u7684\u8fdb\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u79bb\u7ebf\u6784\u5efa\u7f16\u8bd1\u77e5\u8bc6\u5e93\u548c\u5728\u7ebf\u4f7f\u7528\u77e5\u8bc6\u589e\u5f3a\u7684\u9057\u4f20\u7b97\u6cd5\uff0c\u4e3a\u7279\u5b9a\u7a0b\u5e8f\u81ea\u52a8\u4f18\u5316\u7f16\u8bd1\u5668pass\u5e8f\u5217\uff0c\u76f8\u6bd4-Oz\u57fa\u51c6\u5e73\u5747\u989d\u5916\u51cf\u5c1111.0%\u7684LLVM IR\u6307\u4ee4\u3002", "motivation": "\u4f20\u7edf\u7f16\u8bd1\u5668\u4f18\u5316\u6807\u5fd7\uff08\u5982-O3\u3001-Oz\uff09\u91c7\u7528\u4e00\u5200\u5207\u65b9\u6cd5\uff0c\u65e0\u6cd5\u5145\u5206\u53d1\u6325\u7a0b\u5e8f\u7684\u6027\u80fd\u6f5c\u529b\uff0c\u800c\u5bfb\u627e\u6700\u4f18pass\u5e8f\u5217\u662f\u4e00\u4e2aNP\u96be\u95ee\u9898\u3002", "method": "1\uff09\u79bb\u7ebf\u9636\u6bb5\u6784\u5efa\u5305\u542bpass\u884c\u4e3a\u5411\u91cf\u3001pass\u7fa4\u7ec4\u3001\u534f\u540cpass\u56fe\u548c\u539f\u578bpass\u5e8f\u5217\u7684\u7f16\u8bd1\u77e5\u8bc6\u5e93\uff1b2\uff09\u5728\u7ebf\u9636\u6bb5\u4f7f\u7528\u77e5\u8bc6\u589e\u5f3a\u7684\u9057\u4f20\u7b97\u6cd5\u8fdb\u884c\u8bed\u4e49\u611f\u77e5\u7684\u91cd\u7ec4\u548c\u5b9a\u5411\u4fee\u590d\u7a81\u53d8\u3002", "result": "\u57287\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u6bd4\u9ad8\u5ea6\u4f18\u5316\u7684opt -Oz\u57fa\u51c6\uff0c\u5e73\u5747\u989d\u5916\u51cf\u5c1111.0%\u7684LLVM IR\u6307\u4ee4\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u53d1\u73b0\u4e2a\u6027\u5316\u9ad8\u6027\u80fd\u4f18\u5316\u5e8f\u5217\u65b9\u9762\u5c55\u73b0\u51fa\u6700\u5148\u8fdb\u7684\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u77e5\u8bc6\u5f15\u5bfc\u8fdb\u5316\u65b9\u6cd5\u5728\u7f16\u8bd1\u5668\u81ea\u52a8\u8c03\u4f18\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.14053", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14053", "abs": "https://arxiv.org/abs/2510.14053", "authors": ["Shriyash Upadhyay", "Chaithanya Bandi", "Narmeen Oozeer", "Philip Quirke"], "title": "Position: Require Frontier AI Labs To Release Small \"Analog\" Models", "comment": null, "summary": "Recent proposals for regulating frontier AI models have sparked concerns\nabout the cost of safety regulation, and most such regulations have been\nshelved due to the safety-innovation tradeoff. This paper argues for an\nalternative regulatory approach that ensures AI safety while actively promoting\ninnovation: mandating that large AI laboratories release small, openly\naccessible analog models (scaled-down versions) trained similarly to and\ndistilled from their largest proprietary models.\n  Analog models serve as public proxies, allowing broad participation in safety\nverification, interpretability research, and algorithmic transparency without\nforcing labs to disclose their full-scale models. Recent research demonstrates\nthat safety and interpretability methods developed using these smaller models\ngeneralize effectively to frontier-scale systems. By enabling the wider\nresearch community to directly investigate and innovate upon accessible\nanalogs, our policy substantially reduces the regulatory burden and accelerates\nsafety advancements.\n  This mandate promises minimal additional costs, leveraging reusable resources\nlike data and infrastructure, while significantly contributing to the public\ngood. Our hope is not only that this policy be adopted, but that it illustrates\na broader principle supporting fundamental research in machine learning: deeper\nunderstanding of models relaxes the safety-innovation tradeoff and lets us have\nmore of both.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u66ff\u4ee3\u6027AI\u76d1\u7ba1\u65b9\u6cd5\uff1a\u8981\u6c42\u5927\u578bAI\u5b9e\u9a8c\u5ba4\u53d1\u5e03\u5c0f\u578b\u5f00\u653e\u7c7b\u6bd4\u6a21\u578b\uff0c\u8fd9\u4e9b\u6a21\u578b\u662f\u4ece\u5176\u6700\u5927\u4e13\u6709\u6a21\u578b\u84b8\u998f\u8bad\u7ec3\u800c\u6765\u7684\u7f29\u5c0f\u7248\u672c\uff0c\u65e2\u80fd\u786e\u4fddAI\u5b89\u5168\u53c8\u4fc3\u8fdb\u521b\u65b0\u3002", "motivation": "\u73b0\u6709\u524d\u6cbfAI\u6a21\u578b\u76d1\u7ba1\u63d0\u6848\u56e0\u5b89\u5168\u4e0e\u521b\u65b0\u7684\u6743\u8861\u800c\u88ab\u6401\u7f6e\uff0c\u9700\u8981\u627e\u5230\u65e2\u80fd\u786e\u4fddAI\u5b89\u5168\u53c8\u4e0d\u963b\u788d\u521b\u65b0\u7684\u76d1\u7ba1\u65b9\u6cd5\u3002", "method": "\u5f3a\u5236\u8981\u6c42\u5927\u578bAI\u5b9e\u9a8c\u5ba4\u53d1\u5e03\u5c0f\u578b\u5f00\u653e\u7c7b\u6bd4\u6a21\u578b\uff0c\u8fd9\u4e9b\u6a21\u578b\u4f5c\u4e3a\u516c\u5171\u4ee3\u7406\uff0c\u5141\u8bb8\u5e7f\u6cdb\u53c2\u4e0e\u5b89\u5168\u9a8c\u8bc1\u3001\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u548c\u7b97\u6cd5\u900f\u660e\u5ea6\u5de5\u4f5c\uff0c\u800c\u65e0\u9700\u62ab\u9732\u5168\u89c4\u6a21\u6a21\u578b\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u4f7f\u7528\u8fd9\u4e9b\u5c0f\u578b\u6a21\u578b\u5f00\u53d1\u7684\u5b89\u5168\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u80fd\u6709\u6548\u63a8\u5e7f\u5230\u524d\u6cbf\u89c4\u6a21\u7cfb\u7edf\uff0c\u663e\u8457\u964d\u4f4e\u76d1\u7ba1\u8d1f\u62c5\u5e76\u52a0\u901f\u5b89\u5168\u8fdb\u5c55\u3002", "conclusion": "\u8fd9\u79cd\u76d1\u7ba1\u65b9\u6cd5\u4ee5\u6700\u5c0f\u989d\u5916\u6210\u672c\u663e\u8457\u4fc3\u8fdb\u516c\u5171\u798f\u7949\uff0c\u5e76\u8bf4\u660e\u5bf9\u6a21\u578b\u7684\u6df1\u5165\u7406\u89e3\u80fd\u591f\u7f13\u89e3\u5b89\u5168\u4e0e\u521b\u65b0\u7684\u6743\u8861\uff0c\u5b9e\u73b0\u4e24\u8005\u7684\u53cc\u8d62\u3002"}}
{"id": "2510.14198", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14198", "abs": "https://arxiv.org/abs/2510.14198", "authors": ["Morium Akter Munny", "Mahbub Alam", "Sonjoy Kumar Paul", "Daniel Timko", "Muhammad Lutfor Rahman", "Nitesh Saxena"], "title": "Infrastructure Patterns in Toll Scam Domains: A Comprehensive Analysis of Cybercriminal Registration and Hosting Strategies", "comment": "This paper has been accepted for presentation at eCrime 2025", "summary": "Toll scams involve criminals registering fake domains that pretend to be\nlegitimate transportation agencies to trick users into making fraudulent\npayments. Although these scams are rapidly increasing and causing significant\nharm, they have not been extensively studied. We present the first large-scale\nanalysis of toll scam domains, using a newly created dataset of 67,907\nconfirmed scam domains mostly registered in 2025. Our study reveals that\nattackers exploit permissive registrars and less common top-level domains, with\n86.9% of domains concentrated in just five non-mainstream TLDs and 72.9%\nregistered via a single provider. We also discover specific registration\npatterns, including short bursts of activity that suggest automated,\ncoordinated attacks, with over half of domains registered in the first quarter\nof 2025. This extreme temporal clustering reflects highly synchronized campaign\nlaunches. Additionally, we build a simple predictive model using only domain\nregistration data to predict which scam domains are likely to be suspended -- a\nproxy for confirmed abuse -- achieving 80.4% accuracy, and 92.3% sensitivity.\nOur analysis reveals attacker strategies for evading detection -- such as\nexploiting obscure TLDs, permissive registrars, and coordinated registration\nbursts -- which can inform more targeted interventions by registrars, hosting\nproviders, and security platforms. However, our results suggest that\nregistration metadata alone may be insufficient, and incorporating features\nfrom domain URLs and webpage content could further improve detection.", "AI": {"tldr": "\u5bf967,907\u4e2a\u786e\u8ba4\u7684\u6536\u8d39\u8bc8\u9a97\u57df\u540d\u8fdb\u884c\u9996\u6b21\u5927\u89c4\u6a21\u5206\u6790\uff0c\u63ed\u793a\u4e86\u653b\u51fb\u8005\u5229\u7528\u5bbd\u677e\u6ce8\u518c\u5546\u548c\u975e\u4e3b\u6d41\u9876\u7ea7\u57df\u540d\u7684\u7b56\u7565\uff0c\u5e76\u6784\u5efa\u4e86\u57fa\u4e8e\u6ce8\u518c\u6570\u636e\u7684\u9884\u6d4b\u6a21\u578b\uff0c\u51c6\u786e\u7387\u8fbe80.4%\u3002", "motivation": "\u6536\u8d39\u8bc8\u9a97\u901a\u8fc7\u6ce8\u518c\u4f2a\u88c5\u6210\u5408\u6cd5\u4ea4\u901a\u673a\u6784\u7684\u865a\u5047\u57df\u540d\u6b3a\u9a97\u7528\u6237\u8fdb\u884c\u6b3a\u8bc8\u652f\u4ed8\uff0c\u8fd9\u7c7b\u8bc8\u9a97\u8fc5\u901f\u589e\u52a0\u4e14\u5371\u5bb3\u4e25\u91cd\uff0c\u4f46\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u4f7f\u7528\u65b0\u521b\u5efa\u768467,907\u4e2a\u786e\u8ba4\u8bc8\u9a97\u57df\u540d\u6570\u636e\u96c6\u8fdb\u884c\u5206\u6790\uff0c\u7814\u7a76\u6ce8\u518c\u6a21\u5f0f\uff0c\u5e76\u6784\u5efa\u4ec5\u4f7f\u7528\u57df\u540d\u6ce8\u518c\u6570\u636e\u7684\u7b80\u5355\u9884\u6d4b\u6a21\u578b\u6765\u9884\u6d4b\u54ea\u4e9b\u8bc8\u9a97\u57df\u540d\u53ef\u80fd\u88ab\u6682\u505c\u3002", "result": "\u53d1\u73b086.9%\u7684\u57df\u540d\u96c6\u4e2d\u5728\u4e94\u4e2a\u975e\u4e3b\u6d41TLD\uff0c72.9%\u901a\u8fc7\u5355\u4e00\u63d0\u4f9b\u5546\u6ce8\u518c\uff1b\u8d85\u8fc7\u4e00\u534a\u57df\u540d\u57282025\u5e74\u7b2c\u4e00\u5b63\u5ea6\u6ce8\u518c\uff0c\u663e\u793a\u9ad8\u5ea6\u540c\u6b65\u7684\u6d3b\u52a8\u7206\u53d1\uff1b\u9884\u6d4b\u6a21\u578b\u8fbe\u523080.4%\u51c6\u786e\u7387\u548c92.3%\u7075\u654f\u5ea6\u3002", "conclusion": "\u5206\u6790\u63ed\u793a\u4e86\u653b\u51fb\u8005\u9003\u907f\u68c0\u6d4b\u7684\u7b56\u7565\uff0c\u4f46\u4ec5\u51ed\u6ce8\u518c\u5143\u6570\u636e\u53ef\u80fd\u4e0d\u8db3\uff0c\u7ed3\u5408\u57df\u540dURL\u548c\u7f51\u9875\u5185\u5bb9\u7279\u5f81\u53ef\u8fdb\u4e00\u6b65\u63d0\u9ad8\u68c0\u6d4b\u6548\u679c\u3002"}}
{"id": "2510.14339", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.14339", "abs": "https://arxiv.org/abs/2510.14339", "authors": ["Jialu Zhang", "Jialiang Gu", "Wangmeiyu Zhang", "Jos\u00e9 Pablo Cambronero", "John Kolesar", "Ruzica Piskac", "Daming Li", "Hanyuan Shi"], "title": "A Systematic Study of Time Limit Exceeded Errors in Online Programming Assignments", "comment": null, "summary": "Online programming platforms such as Codeforces and LeetCode attract millions\nof users seeking to learn to program or refine their skills for industry\ninterviews. A major challenge for these users is the Time Limit Exceeded (TLE)\nerror, triggered when a program exceeds the execution time bound. Although\ndesigned as a performance safeguard, TLE errors are difficult to resolve: error\nmessages provide no diagnostic insight, platform support is minimal, and\nexisting debugging tools offer little help. As a result, many users abandon\ntheir submissions after repeated TLE failures.\n  This paper presents the first large-scale empirical study of TLE errors in\nonline programming. We manually analyzed 1000 Codeforces submissions with TLE\nerrors, classified their root causes, and traced how users attempted to fix\nthem. Our analysis shows that TLE errors often arise not only from inefficient\nalgorithms but also from infinite loops, improper data structure use, and\ninefficient I/O, challenging the conventional view that TLEs are purely\nperformance issues.\n  Guided by these findings, we introduce Nettle, the first automated repair\ntool specifically designed for TLE errors, and Nettle-Eval, the first framework\nfor evaluating TLE repairs. Integrating LLMs with targeted automated feedback\ngenerated by the compiler and test cases, Nettle produces small, correct code\nedits that eliminate TLEs while preserving functionality. Evaluated on the same\n1000 real-world cases, Nettle achieves a 98.5% fix rate, far exceeding the\nstrongest LLM baseline, and all of its repairs pass both Nettle-Eval and the\nplatform's official checker, confirming the reliability of our framework.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u9488\u5bf9\u5728\u7ebf\u7f16\u7a0b\u4e2dTLE\u9519\u8bef\u7684\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u5f00\u53d1\u4e86\u9996\u4e2a\u81ea\u52a8\u5316\u4fee\u590d\u5de5\u5177Nettle\u548c\u8bc4\u4f30\u6846\u67b6Nettle-Eval\uff0c\u663e\u8457\u63d0\u9ad8\u4e86TLE\u9519\u8bef\u7684\u4fee\u590d\u6210\u529f\u7387\u3002", "motivation": "\u5728\u7ebf\u7f16\u7a0b\u5e73\u53f0\u4e0a\u7684TLE\u9519\u8bef\u96be\u4ee5\u89e3\u51b3\uff0c\u9519\u8bef\u4fe1\u606f\u7f3a\u4e4f\u8bca\u65ad\u4ef7\u503c\uff0c\u5e73\u53f0\u652f\u6301\u6709\u9650\uff0c\u73b0\u6709\u8c03\u8bd5\u5de5\u5177\u5e2e\u52a9\u4e0d\u5927\uff0c\u5bfc\u81f4\u8bb8\u591a\u7528\u6237\u5728\u91cd\u590dTLE\u5931\u8d25\u540e\u653e\u5f03\u63d0\u4ea4\u3002", "method": "\u624b\u52a8\u5206\u67901000\u4e2aCodeforces\u7684TLE\u63d0\u4ea4\uff0c\u5206\u7c7b\u6839\u672c\u539f\u56e0\uff1b\u5f00\u53d1Nettle\u5de5\u5177\uff0c\u7ed3\u5408LLM\u3001\u7f16\u8bd1\u5668\u53cd\u9988\u548c\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u5c0f\u578b\u6b63\u786e\u4ee3\u7801\u7f16\u8f91\uff1b\u521b\u5efaNettle-Eval\u8bc4\u4f30\u6846\u67b6\u3002", "result": "Nettle\u57281000\u4e2a\u771f\u5b9e\u6848\u4f8b\u4e2d\u8fbe\u523098.5%\u7684\u4fee\u590d\u7387\uff0c\u8fdc\u8d85\u6700\u5f3aLLM\u57fa\u7ebf\uff0c\u6240\u6709\u4fee\u590d\u90fd\u901a\u8fc7\u4e86Nettle-Eval\u548c\u5e73\u53f0\u5b98\u65b9\u68c0\u67e5\u5668\u3002", "conclusion": "TLE\u9519\u8bef\u4e0d\u4ec5\u6e90\u4e8e\u7b97\u6cd5\u6548\u7387\u95ee\u9898\uff0c\u8fd8\u5305\u62ec\u65e0\u9650\u5faa\u73af\u3001\u6570\u636e\u7ed3\u6784\u4f7f\u7528\u4e0d\u5f53\u548cI/O\u6548\u7387\u4f4e\u4e0b\uff1bNettle\u662f\u9996\u4e2a\u4e13\u95e8\u9488\u5bf9TLE\u9519\u8bef\u7684\u81ea\u52a8\u5316\u4fee\u590d\u5de5\u5177\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2510.14106", "categories": ["cs.AI", "cs.CL", "cs.GT"], "pdf": "https://arxiv.org/pdf/2510.14106", "abs": "https://arxiv.org/abs/2510.14106", "authors": ["Carter Blair", "Kate Larson"], "title": "Generating Fair Consensus Statements with Social Choice on Token-Level MDPs", "comment": null, "summary": "Current frameworks for consensus statement generation with large language\nmodels lack the inherent structure needed to provide provable fairness\nguarantees when aggregating diverse free-form opinions. We model the task as a\nmulti-objective, token-level Markov Decision Process (MDP), where each\nobjective corresponds to an agent's preference. Token-level rewards for each\nagent are derived from their policy (e.g., a personalized language model). This\napproach utilizes the finding that such policies implicitly define optimal\nQ-functions, providing a principled way to quantify rewards at each generation\nstep without a value function (Rafailov et al., 2024). This MDP formulation\ncreates a formal structure amenable to analysis using principles from social\nchoice theory. We propose two approaches grounded in social choice theory.\nFirst, we propose a stochastic generation policy guaranteed to be in the\nex-ante core, extending core stability concepts from voting theory to text\ngeneration. This policy is derived from an underlying distribution over\ncomplete statements that maximizes proportional fairness (Nash Welfare).\nSecond, for generating a single statement, we target the maximization of\negalitarian welfare using search algorithms within the MDP framework.\nEmpirically, experiments using language models to instantiate agent policies\nshow that search guided by the egalitarian objective generates consensus\nstatements with improved worst-case agent alignment compared to baseline\nmethods, including the Habermas Machine (Tessler et al., 2024).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u76ee\u6807\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u7684\u5171\u8bc6\u58f0\u660e\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u793e\u4f1a\u9009\u62e9\u7406\u8bba\u539f\u5219\u786e\u4fdd\u516c\u5e73\u6027\u4fdd\u8bc1\uff0c\u5305\u62ec\u4e24\u79cd\u65b9\u6cd5\uff1a\u968f\u673a\u751f\u6210\u7b56\u7565\u4fdd\u8bc1ex-ante\u6838\u5fc3\u7a33\u5b9a\u6027\uff0c\u4ee5\u53ca\u57fa\u4e8e\u5e73\u7b49\u4e3b\u4e49\u798f\u5229\u7684\u641c\u7d22\u7b97\u6cd5\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5171\u8bc6\u58f0\u660e\u751f\u6210\u6846\u67b6\u7f3a\u4e4f\u63d0\u4f9b\u53ef\u8bc1\u660e\u516c\u5e73\u6027\u4fdd\u8bc1\u7684\u5185\u5728\u7ed3\u6784\uff0c\u65e0\u6cd5\u5728\u805a\u5408\u591a\u6837\u5316\u81ea\u7531\u5f62\u5f0f\u610f\u89c1\u65f6\u786e\u4fdd\u516c\u5e73\u6027\u3002", "method": "\u5c06\u4efb\u52a1\u5efa\u6a21\u4e3a\u591a\u76ee\u6807\u3001\u4ee4\u724c\u7ea7\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u6bcf\u4e2a\u76ee\u6807\u5bf9\u5e94\u4e00\u4e2a\u4ee3\u7406\u7684\u504f\u597d\u3002\u63d0\u51fa\u4e24\u79cd\u57fa\u4e8e\u793e\u4f1a\u9009\u62e9\u7406\u8bba\u7684\u65b9\u6cd5\uff1a\u4e00\u662f\u4fdd\u8bc1ex-ante\u6838\u5fc3\u7a33\u5b9a\u6027\u7684\u968f\u673a\u751f\u6210\u7b56\u7565\uff0c\u4e8c\u662f\u57fa\u4e8e\u5e73\u7b49\u4e3b\u4e49\u798f\u5229\u6700\u5927\u5316\u7684\u641c\u7d22\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u8bed\u8a00\u6a21\u578b\u5b9e\u4f8b\u5316\u4ee3\u7406\u7b56\u7565\u65f6\uff0c\u57fa\u4e8e\u5e73\u7b49\u4e3b\u4e49\u76ee\u6807\u7684\u641c\u7d22\u751f\u6210\u7684\u5171\u8bc6\u58f0\u660e\u5728\u4ee3\u7406\u5bf9\u9f50\u7684\u6700\u574f\u60c5\u51b5\u4e0b\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5305\u62ecHabermas Machine\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5171\u8bc6\u58f0\u660e\u751f\u6210\u63d0\u4f9b\u4e86\u5177\u6709\u53ef\u8bc1\u660e\u516c\u5e73\u6027\u4fdd\u8bc1\u7684\u7ed3\u6784\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u793e\u4f1a\u9009\u62e9\u7406\u8bba\u539f\u5219\u786e\u4fdd\u516c\u5e73\u805a\u5408\u591a\u6837\u5316\u610f\u89c1\u3002"}}
{"id": "2510.14218", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14218", "abs": "https://arxiv.org/abs/2510.14218", "authors": ["Chaoyue Huang", "Gejian Zhao", "Hanzhou Wu", "Zhihua Xia", "Asad Malik"], "title": "An Information Asymmetry Game for Trigger-based DNN Model Watermarking", "comment": null, "summary": "As a valuable digital product, deep neural networks (DNNs) face increasingly\nsevere threats to the intellectual property, making it necessary to develop\neffective technical measures to protect them. Trigger-based watermarking\nmethods achieve copyright protection by embedding triggers into the host DNNs.\nHowever, the attacker may remove the watermark by pruning or fine-tuning. We\nmodel this interaction as a game under conditions of information asymmetry,\nnamely, the defender embeds a secret watermark with private knowledge, while\nthe attacker can only access the watermarked model and seek removal. We define\nstrategies, costs, and utilities for both players, derive the attacker's\noptimal pruning budget, and establish an exponential lower bound on the\naccuracy of watermark detection after attack. Experimental results demonstrate\nthe feasibility of the watermarked model, and indicate that sparse watermarking\ncan resist removal with negligible accuracy loss. This study highlights the\neffectiveness of game-theoretic analysis in guiding the design of robust\nwatermarking schemes for model copyright protection.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u535a\u5f08\u8bba\u5206\u6790\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6c34\u5370\u4fdd\u62a4\u65b9\u6cd5\uff0c\u901a\u8fc7\u7a00\u758f\u6c34\u5370\u6280\u672f\u62b5\u6297\u4fee\u526a\u548c\u5fae\u8c03\u653b\u51fb\uff0c\u5728\u4fe1\u606f\u4e0d\u5bf9\u79f0\u6761\u4ef6\u4e0b\u5efa\u7acb\u9632\u5fa1\u6a21\u578b\u3002", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4f5c\u4e3a\u6709\u4ef7\u503c\u7684\u6570\u5b57\u4ea7\u54c1\u9762\u4e34\u4e25\u91cd\u77e5\u8bc6\u4ea7\u6743\u5a01\u80c1\uff0c\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u6280\u672f\u63aa\u65bd\u6765\u4fdd\u62a4\u6a21\u578b\u7248\u6743\u3002\u73b0\u6709\u7684\u57fa\u4e8e\u89e6\u53d1\u5668\u7684\u6c34\u5370\u65b9\u6cd5\u5bb9\u6613\u901a\u8fc7\u4fee\u526a\u6216\u5fae\u8c03\u88ab\u79fb\u9664\u3002", "method": "\u5c06\u6c34\u5370\u4fdd\u62a4\u5efa\u6a21\u4e3a\u4fe1\u606f\u4e0d\u5bf9\u79f0\u6761\u4ef6\u4e0b\u7684\u535a\u5f08\u95ee\u9898\uff0c\u9632\u5fa1\u8005\u5d4c\u5165\u79d8\u5bc6\u6c34\u5370\uff0c\u653b\u51fb\u8005\u53ea\u80fd\u8bbf\u95ee\u6c34\u5370\u6a21\u578b\u5e76\u5bfb\u6c42\u79fb\u9664\u3002\u5b9a\u4e49\u4e86\u53cc\u65b9\u7b56\u7565\u3001\u6210\u672c\u548c\u6548\u7528\u51fd\u6570\uff0c\u63a8\u5bfc\u653b\u51fb\u8005\u7684\u6700\u4f18\u4fee\u526a\u9884\u7b97\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u6c34\u5370\u6a21\u578b\u7684\u53ef\u884c\u6027\uff0c\u7a00\u758f\u6c34\u5370\u6280\u672f\u80fd\u591f\u4ee5\u53ef\u5ffd\u7565\u7684\u7cbe\u5ea6\u635f\u5931\u62b5\u6297\u79fb\u9664\u653b\u51fb\u3002\u5efa\u7acb\u4e86\u653b\u51fb\u540e\u6c34\u5370\u68c0\u6d4b\u7cbe\u5ea6\u7684\u6307\u6570\u4e0b\u754c\u3002", "conclusion": "\u535a\u5f08\u8bba\u5206\u6790\u4e3a\u8bbe\u8ba1\u9c81\u68d2\u7684\u6c34\u5370\u65b9\u6848\u63d0\u4f9b\u4e86\u6709\u6548\u6307\u5bfc\uff0c\u7a00\u758f\u6c34\u5370\u662f\u4fdd\u62a4\u6a21\u578b\u7248\u6743\u7684\u53ef\u884c\u65b9\u6cd5\u3002"}}
{"id": "2510.14341", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.14341", "abs": "https://arxiv.org/abs/2510.14341", "authors": ["Xu He", "Shu Wang", "Kun Sun"], "title": "PathFix: Automated Program Repair with Expected Path", "comment": "This is the author's version of a paper accepted at SecDev 2025\n  (IEEE)", "summary": "Automated program repair (APR) techniques are effective in fixing inevitable\ndefects in software, enhancing development efficiency and software robustness.\nHowever, due to the difficulty of generating precise specifications, existing\nAPR methods face two main challenges: generating too many plausible patch\ncandidates and overfitting them to partial test cases. To tackle these\nchallenges, we introduce a new APR method named PathFix, which leverages\npath-sensitive constraints extracted from correct execution paths to generate\npatches for repairing buggy code. It is based on one observation: if a buggy\nprogram is repairable, at least one expected path is supposed to replace the\nfault path in the patched program. PathFix operates in four main steps. First,\nit traces fault paths reaching the fault output in the buggy program. Second,\nit derives expected paths by analyzing the desired correct output on the\ncontrol flow graph, where an expected path defines how a feasible patch leads\nto the correct execution. Third, PathFix generates and evaluates patches by\nsolving state constraints along the expected path. Fourth, we validate the\ncorrectness of the generated patch. To further enhance repair performance and\nmitigate scalability issues introduced by path-sensitive analysis, we integrate\na large language model (LLM) into our framework. Experimental results show that\nPathFix outperforms existing solutions, particularly in handling complex\nprogram structures such as loops and recursion.", "AI": {"tldr": "PathFix\u662f\u4e00\u79cd\u65b0\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u65b9\u6cd5\uff0c\u5229\u7528\u4ece\u6b63\u786e\u6267\u884c\u8def\u5f84\u63d0\u53d6\u7684\u8def\u5f84\u654f\u611f\u7ea6\u675f\u6765\u751f\u6210\u4fee\u590d\u8865\u4e01\uff0c\u901a\u8fc7\u5206\u6790\u9884\u671f\u8def\u5f84\u548c\u72b6\u6001\u7ea6\u675f\u6765\u89e3\u51b3\u73b0\u6709APR\u65b9\u6cd5\u751f\u6210\u8fc7\u591a\u5019\u9009\u8865\u4e01\u548c\u8fc7\u62df\u5408\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u65b9\u6cd5\u7531\u4e8e\u96be\u4ee5\u751f\u6210\u7cbe\u786e\u89c4\u8303\uff0c\u9762\u4e34\u751f\u6210\u8fc7\u591a\u5408\u7406\u8865\u4e01\u5019\u9009\u548c\u8fc7\u62df\u5408\u90e8\u5206\u6d4b\u8bd5\u7528\u4f8b\u7684\u6311\u6218\u3002", "method": "PathFix\u91c7\u7528\u56db\u6b65\u6cd5\uff1a1\uff09\u8ffd\u8e2a\u9519\u8bef\u8def\u5f84\uff1b2\uff09\u901a\u8fc7\u63a7\u5236\u6d41\u56fe\u5206\u6790\u63a8\u5bfc\u9884\u671f\u8def\u5f84\uff1b3\uff09\u6cbf\u9884\u671f\u8def\u5f84\u6c42\u89e3\u72b6\u6001\u7ea6\u675f\u751f\u6210\u8865\u4e01\uff1b4\uff09\u9a8c\u8bc1\u8865\u4e01\u6b63\u786e\u6027\u3002\u8fd8\u96c6\u6210\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u5347\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aPathFix\u4f18\u4e8e\u73b0\u6709\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5faa\u73af\u548c\u9012\u5f52\u7b49\u590d\u6742\u7a0b\u5e8f\u7ed3\u6784\u65b9\u9762\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "PathFix\u901a\u8fc7\u8def\u5f84\u654f\u611f\u7ea6\u675f\u5206\u6790\u6709\u6548\u89e3\u51b3\u4e86APR\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5728\u590d\u6742\u7a0b\u5e8f\u4fee\u590d\u65b9\u9762\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2510.14112", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14112", "abs": "https://arxiv.org/abs/2510.14112", "authors": ["Huiliang Zhang", "Di Wu", "Arnaud Zinflou", "Benoit Boulet"], "title": "STEMS: Spatial-Temporal Enhanced Safe Multi-Agent Coordination for Building Energy Management", "comment": null, "summary": "Building energy management is essential for achieving carbon reduction goals,\nimproving occupant comfort, and reducing energy costs. Coordinated building\nenergy management faces critical challenges in exploiting spatial-temporal\ndependencies while ensuring operational safety across multi-building systems.\nCurrent multi-building energy systems face three key challenges: insufficient\nspatial-temporal information exploitation, lack of rigorous safety guarantees,\nand system complexity. This paper proposes Spatial-Temporal Enhanced Safe\nMulti-Agent Coordination (STEMS), a novel safety-constrained multi-agent\nreinforcement learning framework for coordinated building energy management.\nSTEMS integrates two core components: (1) a spatial-temporal graph\nrepresentation learning framework using a GCN-Transformer fusion architecture\nto capture inter-building relationships and temporal patterns, and (2) a\nsafety-constrained multi-agent RL algorithm incorporating Control Barrier\nFunctions to provide mathematical safety guarantees. Extensive experiments on\nreal-world building datasets demonstrate STEMS's superior performance over\nexisting methods, showing that STEMS achieves 21% cost reduction, 18% emission\nreduction, and dramatically reduces safety violations from 35.1% to 5.6% while\nmaintaining optimal comfort with only 0.13 discomfort proportion. The framework\nalso demonstrates strong robustness during extreme weather conditions and\nmaintains effectiveness across different building types.", "AI": {"tldr": "STEMS\u662f\u4e00\u4e2a\u7528\u4e8e\u534f\u8c03\u5efa\u7b51\u80fd\u6e90\u7ba1\u7406\u7684\u5b89\u5168\u7ea6\u675f\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u7a7a\u95f4-\u65f6\u95f4\u56fe\u8868\u793a\u5b66\u4e60\u548c\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u5b9e\u73b0\u5b89\u5168\u4fdd\u8bc1\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u663e\u793a21%\u6210\u672c\u964d\u4f4e\u300118%\u6392\u653e\u51cf\u5c11\uff0c\u5e76\u5c06\u5b89\u5168\u8fdd\u89c4\u4ece35.1%\u964d\u81f35.6%\u3002", "motivation": "\u5efa\u7b51\u80fd\u6e90\u7ba1\u7406\u5bf9\u5b9e\u73b0\u78b3\u51cf\u6392\u76ee\u6807\u3001\u63d0\u9ad8\u5c45\u4f4f\u8005\u8212\u9002\u5ea6\u548c\u964d\u4f4e\u80fd\u6e90\u6210\u672c\u81f3\u5173\u91cd\u8981\u3002\u5f53\u524d\u591a\u5efa\u7b51\u80fd\u6e90\u7cfb\u7edf\u9762\u4e34\u4e09\u4e2a\u5173\u952e\u6311\u6218\uff1a\u7a7a\u95f4-\u65f6\u95f4\u4fe1\u606f\u5229\u7528\u4e0d\u8db3\u3001\u7f3a\u4e4f\u4e25\u683c\u5b89\u5168\u4fdd\u8bc1\u4ee5\u53ca\u7cfb\u7edf\u590d\u6742\u6027\u3002", "method": "\u63d0\u51faSTEMS\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a(1)\u4f7f\u7528GCN-Transformer\u878d\u5408\u67b6\u6784\u7684\u7a7a\u95f4-\u65f6\u95f4\u56fe\u8868\u793a\u5b66\u4e60\u6846\u67b6\uff0c\u6355\u6349\u5efa\u7b51\u95f4\u5173\u7cfb\u548c\u65f6\u5e8f\u6a21\u5f0f\uff1b(2)\u7ed3\u5408\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u7684\u5b89\u5168\u7ea6\u675f\u591a\u667a\u80fd\u4f53RL\u7b97\u6cd5\uff0c\u63d0\u4f9b\u6570\u5b66\u5b89\u5168\u4fdd\u8bc1\u3002", "result": "\u5728\u771f\u5b9e\u5efa\u7b51\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cSTEMS\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5b9e\u73b021%\u6210\u672c\u964d\u4f4e\u300118%\u6392\u653e\u51cf\u5c11\uff0c\u5b89\u5168\u8fdd\u89c4\u4ece35.1%\u5927\u5e45\u964d\u81f35.6%\uff0c\u540c\u65f6\u4fdd\u6301\u6700\u4f73\u8212\u9002\u5ea6\uff08\u4ec50.13\u4e0d\u9002\u6bd4\u4f8b\uff09\u3002\u5728\u6781\u7aef\u5929\u6c14\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u5f3a\u9c81\u68d2\u6027\uff0c\u5728\u4e0d\u540c\u5efa\u7b51\u7c7b\u578b\u4e2d\u4fdd\u6301\u6709\u6548\u6027\u3002", "conclusion": "STEMS\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u591a\u5efa\u7b51\u80fd\u6e90\u7ba1\u7406\u4e2d\u7684\u7a7a\u95f4-\u65f6\u95f4\u4f9d\u8d56\u6027\u548c\u5b89\u5168\u7ea6\u675f\u95ee\u9898\uff0c\u4e3a\u534f\u8c03\u5efa\u7b51\u80fd\u6e90\u7ba1\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u6210\u672c\u3001\u6392\u653e\u548c\u5b89\u5168\u65b9\u9762\u5747\u53d6\u5f97\u663e\u8457\u6539\u8fdb\u3002"}}
{"id": "2510.14233", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14233", "abs": "https://arxiv.org/abs/2510.14233", "authors": ["Fanchao Meng", "Jiaping Gui", "Yunbo Li", "Yue Wu"], "title": "RHINO: Guided Reasoning for Mapping Network Logs to Adversarial Tactics and Techniques with Large Language Models", "comment": null, "summary": "Modern Network Intrusion Detection Systems generate vast volumes of low-level\nalerts, yet these outputs remain semantically fragmented, requiring\nlabor-intensive manual correlation with high-level adversarial behaviors.\nExisting solutions for automating this mapping-rule-based systems and machine\nlearning classifiers-suffer from critical limitations: rule-based approaches\nfail to adapt to novel attack variations, while machine learning methods lack\ncontextual awareness and treat tactic-technique mapping as a syntactic matching\nproblem rather than a reasoning task. Although Large Language Models have shown\npromise in cybersecurity tasks, preliminary experiments reveal that existing\nLLM-based methods frequently hallucinate technique names or produce\ndecontextualized mappings due to their single-step classification approach.\n  To address these challenges, we introduce RHINO, a novel framework that\ndecomposes LLM-based attack analysis into three interpretable phases mirroring\nhuman reasoning: (1) behavioral abstraction, where raw logs are translated into\ncontextualized narratives; (2) multi-role collaborative inference, generating\ncandidate techniques by evaluating behavioral evidence against MITRE ATT&CK\nknowledge; and (3) validation, cross-referencing predictions with official\nMITRE definitions to rectify hallucinations. RHINO bridges the semantic gap\nbetween low-level observations and adversarial intent while improving output\nreliability through structured reasoning.\n  We evaluate RHINO on three benchmarks across four backbone models. RHINO\nachieved high accuracy, with model performance ranging from 86.38% to 88.45%,\nresulting in relative gains from 24.25% to 76.50% across different models. Our\nresults demonstrate that RHINO significantly enhances the interpretability and\nscalability of threat analysis, offering a blueprint for deploying LLMs in\noperational security settings.", "AI": {"tldr": "RHINO\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u7f51\u7edc\u5165\u4fb5\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u63a8\u7406\u8fc7\u7a0b\u5c06\u4f4e\u7ea7\u8b66\u62a5\u6620\u5c04\u5230MITRE ATT&CK\u653b\u51fb\u6280\u672f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u7f51\u7edc\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u4ea7\u751f\u5927\u91cf\u4f4e\u7ea7\u8b66\u62a5\uff0c\u4f46\u9700\u8981\u4eba\u5de5\u5173\u8054\u5230\u9ad8\u7ea7\u653b\u51fb\u884c\u4e3a\u3002\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u65e0\u6cd5\u9002\u5e94\u65b0\u578b\u653b\u51fb\uff0c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u610f\u8bc6\uff0c\u800c\u73b0\u6709LLM\u65b9\u6cd5\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\u3002", "method": "RHINO\u5c06LLM\u653b\u51fb\u5206\u6790\u5206\u89e3\u4e3a\u4e09\u4e2a\u53ef\u89e3\u91ca\u9636\u6bb5\uff1a\u884c\u4e3a\u62bd\u8c61\uff08\u5c06\u539f\u59cb\u65e5\u5fd7\u8f6c\u5316\u4e3a\u60c5\u5883\u5316\u53d9\u8ff0\uff09\u3001\u591a\u89d2\u8272\u534f\u4f5c\u63a8\u7406\uff08\u57fa\u4e8eMITRE\u77e5\u8bc6\u751f\u6210\u5019\u9009\u6280\u672f\uff09\u3001\u9a8c\u8bc1\uff08\u4ea4\u53c9\u5f15\u7528MITRE\u5b9a\u4e49\u7ea0\u6b63\u5e7b\u89c9\uff09\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c\u56db\u4e2a\u9aa8\u5e72\u6a21\u578b\u4e0a\u8bc4\u4f30\uff0cRHINO\u51c6\u786e\u7387\u8fbe\u523086.38%\u81f388.45%\uff0c\u76f8\u5bf9\u589e\u76ca\u4e3a24.25%\u81f376.50%\u3002", "conclusion": "RHINO\u663e\u8457\u63d0\u5347\u4e86\u5a01\u80c1\u5206\u6790\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u5728\u64cd\u4f5c\u5b89\u5168\u73af\u5883\u4e2d\u90e8\u7f72LLM\u63d0\u4f9b\u4e86\u84dd\u56fe\u3002"}}
{"id": "2510.14465", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.14465", "abs": "https://arxiv.org/abs/2510.14465", "authors": ["Adem Ait", "Gwendal Jouneaux", "Javier Luis C\u00e1novas Izquierdo", "Jordi Cabot"], "title": "Towards Automated Governance: A DSL for Human-Agent Collaboration in Software Projects", "comment": "Accepted in the 40th IEEE/ACM International Conference on Automated\n  Software Engineering, ASE 2025", "summary": "The stakeholders involved in software development are becoming increasingly\ndiverse, with both human contributors from varied backgrounds and AI-powered\nagents collaborating together in the process. This situation presents unique\ngovernance challenges, particularly in Open-Source Software (OSS) projects,\nwhere explicit policies are often lacking or unclear. This paper presents the\nvision and foundational concepts for a novel Domain-Specific Language (DSL)\ndesigned to define and enforce rich governance policies in systems involving\ndiverse stakeholders, including agents. This DSL offers a pathway towards more\nrobust, adaptable, and ultimately automated governance, paving the way for more\neffective collaboration in software projects, especially OSS ones.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff08DSL\uff09\uff0c\u7528\u4e8e\u5b9a\u4e49\u548c\u6267\u884c\u6d89\u53ca\u591a\u6837\u5316\u5229\u76ca\u76f8\u5173\u8005\uff08\u5305\u62ecAI\u4ee3\u7406\uff09\u7684\u8f6f\u4ef6\u9879\u76ee\u6cbb\u7406\u653f\u7b56\u3002", "motivation": "\u8f6f\u4ef6\u5f00\u53d1\u7684\u5229\u76ca\u76f8\u5173\u8005\u65e5\u76ca\u591a\u6837\u5316\uff0c\u5305\u62ec\u6765\u81ea\u4e0d\u540c\u80cc\u666f\u7684\u4eba\u7c7b\u8d21\u732e\u8005\u548cAI\u4ee3\u7406\uff0c\u5728\u5f00\u6e90\u8f6f\u4ef6\u9879\u76ee\u4e2d\u5c24\u5176\u7f3a\u4e4f\u660e\u786e\u6cbb\u7406\u653f\u7b56\uff0c\u8fd9\u5e26\u6765\u4e86\u72ec\u7279\u7684\u6cbb\u7406\u6311\u6218\u3002", "method": "\u8bbe\u8ba1\u4e00\u79cd\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff08DSL\uff09\uff0c\u4e13\u95e8\u7528\u4e8e\u5b9a\u4e49\u548c\u6267\u884c\u4e30\u5bcc\u7684\u6cbb\u7406\u653f\u7b56\uff0c\u652f\u6301\u7cfb\u7edf\u6d89\u53ca\u591a\u6837\u5316\u5229\u76ca\u76f8\u5173\u8005\uff08\u5305\u62ec\u4ee3\u7406\uff09\u7684\u534f\u4f5c\u3002", "result": "\u8be5DSL\u4e3a\u5b9e\u73b0\u66f4\u5f3a\u5927\u3001\u9002\u5e94\u6027\u66f4\u5f3a\u4e14\u6700\u7ec8\u81ea\u52a8\u5316\u7684\u6cbb\u7406\u63d0\u4f9b\u4e86\u9014\u5f84\u3002", "conclusion": "\u8fd9\u79cdDSL\u4e3a\u8f6f\u4ef6\u9879\u76ee\uff08\u7279\u522b\u662f\u5f00\u6e90\u9879\u76ee\uff09\u4e2d\u66f4\u6709\u6548\u7684\u534f\u4f5c\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2510.14133", "categories": ["cs.AI", "cs.CR", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.14133", "abs": "https://arxiv.org/abs/2510.14133", "authors": ["Edoardo Allegrini", "Ananth Shreekumar", "Z. Berkay Celik"], "title": "Formalizing the Safety, Security, and Functional Properties of Agentic AI Systems", "comment": null, "summary": "Agentic AI systems, which leverage multiple autonomous agents and Large\nLanguage Models (LLMs), are increasingly used to address complex, multi-step\ntasks. The safety, security, and functionality of these systems are critical,\nespecially in high-stakes applications. However, the current ecosystem of\ninter-agent communication is fragmented, with protocols such as the Model\nContext Protocol (MCP) for tool access and the Agent-to-Agent (A2A) protocol\nfor coordination being analyzed in isolation. This fragmentation creates a\nsemantic gap that prevents the rigorous analysis of system properties and\nintroduces risks such as architectural misalignment and exploitable\ncoordination issues. To address these challenges, we introduce a modeling\nframework for agentic AI systems composed of two foundational models. The\nfirst, the host agent model, formalizes the top-level entity that interacts\nwith the user, decomposes tasks, and orchestrates their execution by leveraging\nexternal agents and tools. The second, the task lifecycle model, details the\nstates and transitions of individual sub-tasks from creation to completion,\nproviding a fine-grained view of task management and error handling. Together,\nthese models provide a unified semantic framework for reasoning about the\nbehavior of multi-AI agent systems. Grounded in this framework, we define 17\nproperties for the host agent and 14 for the task lifecycle, categorized into\nliveness, safety, completeness, and fairness. Expressed in temporal logic,\nthese properties enable formal verification of system behavior, detection of\ncoordination edge cases, and prevention of deadlocks and security\nvulnerabilities. Through this effort, we introduce the first rigorously\ngrounded, domain-agnostic framework for the systematic analysis, design, and\ndeployment of correct, reliable, and robust agentic AI systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5efa\u6a21\u6846\u67b6\u6765\u89e3\u51b3\u591aAI\u4ee3\u7406\u7cfb\u7edf\u4e2d\u7684\u8bed\u4e49\u9e3f\u6c9f\u95ee\u9898\uff0c\u5305\u542b\u4e3b\u673a\u4ee3\u7406\u6a21\u578b\u548c\u4efb\u52a1\u751f\u547d\u5468\u671f\u6a21\u578b\uff0c\u5b9a\u4e49\u4e8631\u4e2a\u7cfb\u7edf\u5c5e\u6027\u7528\u4e8e\u5f62\u5f0f\u5316\u9a8c\u8bc1\u3002", "motivation": "\u5f53\u524d\u591a\u4ee3\u7406AI\u7cfb\u7edf\u7684\u901a\u4fe1\u534f\u8bae\u788e\u7247\u5316\uff0c\u5bfc\u81f4\u7cfb\u7edf\u5c5e\u6027\u65e0\u6cd5\u4e25\u683c\u5206\u6790\uff0c\u5b58\u5728\u67b6\u6784\u9519\u4f4d\u548c\u53ef\u5229\u7528\u7684\u534f\u8c03\u95ee\u9898\u98ce\u9669\u3002", "method": "\u5f15\u5165\u4e24\u4e2a\u57fa\u7840\u6a21\u578b\uff1a\u4e3b\u673a\u4ee3\u7406\u6a21\u578b\uff08\u8d1f\u8d23\u4e0e\u7528\u6237\u4ea4\u4e92\u3001\u4efb\u52a1\u5206\u89e3\u548c\u7f16\u6392\uff09\u548c\u4efb\u52a1\u751f\u547d\u5468\u671f\u6a21\u578b\uff08\u8be6\u7ec6\u63cf\u8ff0\u5b50\u4efb\u52a1\u7684\u72b6\u6001\u8f6c\u6362\uff09\uff0c\u5e76\u5b9a\u4e49\u4e8617\u4e2a\u4e3b\u673a\u4ee3\u7406\u5c5e\u6027\u548c14\u4e2a\u4efb\u52a1\u751f\u547d\u5468\u671f\u5c5e\u6027\u3002", "result": "\u5efa\u7acb\u4e86\u7b2c\u4e00\u4e2a\u4e25\u683c\u57fa\u7840\u7684\u3001\u9886\u57df\u65e0\u5173\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u7cfb\u7edf\u5206\u6790\u3001\u8bbe\u8ba1\u548c\u90e8\u7f72\u6b63\u786e\u3001\u53ef\u9760\u3001\u9c81\u68d2\u7684\u4ee3\u7406AI\u7cfb\u7edf\u3002", "conclusion": "\u8be5\u7edf\u4e00\u8bed\u4e49\u6846\u67b6\u80fd\u591f\u5bf9\u591aAI\u4ee3\u7406\u7cfb\u7edf\u884c\u4e3a\u8fdb\u884c\u63a8\u7406\uff0c\u901a\u8fc7\u65f6\u5e8f\u903b\u8f91\u8868\u8fbe\u5c5e\u6027\uff0c\u5b9e\u73b0\u5f62\u5f0f\u5316\u9a8c\u8bc1\u3001\u534f\u8c03\u8fb9\u7f18\u60c5\u51b5\u68c0\u6d4b\u4ee5\u53ca\u6b7b\u9501\u548c\u5b89\u5168\u6f0f\u6d1e\u9884\u9632\u3002"}}
{"id": "2510.14283", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14283", "abs": "https://arxiv.org/abs/2510.14283", "authors": ["Xinhao Deng", "Jingyou Chen", "Linxiao Yu", "Yixiang Zhang", "Zhongyi Gu", "Changhao Qiu", "Xiyuan Zhao", "Ke Xu", "Qi Li"], "title": "Beyond a Single Perspective: Towards a Realistic Evaluation of Website Fingerprinting Attacks", "comment": null, "summary": "Website Fingerprinting (WF) attacks exploit patterns in encrypted traffic to\ninfer the websites visited by users, posing a serious threat to anonymous\ncommunication systems. Although recent WF techniques achieve over 90% accuracy\nin controlled experimental settings, most studies remain confined to single\nscenarios, overlooking the complexity of real-world environments. This paper\npresents the first systematic and comprehensive evaluation of existing WF\nattacks under diverse realistic conditions, including defense mechanisms,\ntraffic drift, multi-tab browsing, early-stage detection, open-world settings,\nand few-shot scenarios. Experimental results show that many WF techniques with\nstrong performance in isolated settings degrade significantly when facing other\nconditions. Since real-world environments often combine multiple challenges,\ncurrent WF attacks are difficult to apply directly in practice. This study\nhighlights the limitations of WF attacks and introduces a multidimensional\nevaluation framework, offering critical insights for developing more robust and\npractical WF attacks.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u8bc4\u4f30\u7f51\u7ad9\u6307\u7eb9\u8bc6\u522b\u653b\u51fb\u5728\u73b0\u5b9e\u73af\u5883\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5927\u591a\u6570\u5728\u5b64\u7acb\u573a\u666f\u8868\u73b0\u826f\u597d\u7684\u65b9\u6cd5\u5728\u9762\u4e34\u9632\u5fa1\u673a\u5236\u3001\u6d41\u91cf\u6f02\u79fb\u3001\u591a\u6807\u7b7e\u6d4f\u89c8\u7b49\u590d\u6742\u6761\u4ef6\u65f6\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002", "motivation": "\u73b0\u6709\u7f51\u7ad9\u6307\u7eb9\u8bc6\u522b\u653b\u51fb\u7814\u7a76\u5927\u591a\u5c40\u9650\u4e8e\u5355\u4e00\u573a\u666f\uff0c\u5ffd\u89c6\u4e86\u771f\u5b9e\u73af\u5883\u7684\u590d\u6742\u6027\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u8fd9\u4e9b\u65b9\u6cd5\u5728\u591a\u6837\u5316\u73b0\u5b9e\u6761\u4ef6\u4e0b\u7684\u5b9e\u9645\u6548\u679c\u3002", "method": "\u91c7\u7528\u591a\u7ef4\u8bc4\u4f30\u6846\u67b6\uff0c\u5728\u591a\u79cd\u73b0\u5b9e\u6761\u4ef6\u4e0b\u6d4b\u8bd5\u73b0\u6709WF\u653b\u51fb\uff0c\u5305\u62ec\u9632\u5fa1\u673a\u5236\u3001\u6d41\u91cf\u6f02\u79fb\u3001\u591a\u6807\u7b7e\u6d4f\u89c8\u3001\u65e9\u671f\u68c0\u6d4b\u3001\u5f00\u653e\u4e16\u754c\u548c\u5c11\u6837\u672c\u573a\u666f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8bb8\u591a\u5728\u5b64\u7acb\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\u7684WF\u6280\u672f\u5728\u9762\u5bf9\u5176\u4ed6\u6761\u4ef6\u65f6\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u8868\u660e\u5f53\u524d\u653b\u51fb\u65b9\u6cd5\u96be\u4ee5\u76f4\u63a5\u5e94\u7528\u4e8e\u5b9e\u8df5\u3002", "conclusion": "\u771f\u5b9e\u73af\u5883\u901a\u5e38\u5305\u542b\u591a\u91cd\u6311\u6218\u7684\u7ec4\u5408\uff0c\u5f53\u524dWF\u653b\u51fb\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5b58\u5728\u4e25\u91cd\u5c40\u9650\u6027\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9c81\u68d2\u548c\u5b9e\u7528\u7684\u653b\u51fb\u65b9\u6cd5\u3002"}}
{"id": "2510.14509", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.14509", "abs": "https://arxiv.org/abs/2510.14509", "authors": ["Jingyao Liu", "Chen Huang", "Zhizhao Guan", "Wenqiang Lei", "Yang Deng"], "title": "E2Edev: Benchmarking Large Language Models in End-to-End Software Development Task", "comment": null, "summary": "E2EDev comprises (i) a fine-grained set of user requirements, (ii) {multiple\nBDD test scenarios with corresponding Python step implementations for each\nrequirement}, and (iii) a fully automated testing pipeline built on the Behave\nframework. To ensure its quality while reducing the annotation effort, E2EDev\nleverages our proposed Human-in-the-Loop Multi-Agent Annotation Framework\n(HITL-MAA). {By evaluating various E2ESD frameworks and LLM backbones with\nE2EDev}, our analysis reveals a persistent struggle to effectively solve these\ntasks, underscoring the critical need for more effective and cost-efficient\nE2ESD solutions. Our codebase and benchmark are publicly available at\nhttps://github.com/SCUNLP/E2EDev.", "AI": {"tldr": "E2EDev\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u8f6f\u4ef6\u5f00\u53d1\u57fa\u51c6\uff0c\u5305\u542b\u7ec6\u7c92\u5ea6\u9700\u6c42\u3001BDD\u6d4b\u8bd5\u573a\u666f\u548c\u81ea\u52a8\u5316\u6d4b\u8bd5\u7ba1\u9053\uff0c\u901a\u8fc7\u4eba\u673a\u534f\u540c\u591a\u667a\u80fd\u4f53\u6807\u6ce8\u6846\u67b6\u786e\u4fdd\u8d28\u91cf\uff0c\u8bc4\u4f30\u663e\u793a\u73b0\u6709E2ESD\u6846\u67b6\u4ecd\u9762\u4e34\u6311\u6218\u3002", "motivation": "\u89e3\u51b3\u7aef\u5230\u7aef\u8f6f\u4ef6\u5f00\u53d1(E2ESD)\u4e2d\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u57fa\u51c6\u7684\u95ee\u9898\uff0c\u51cf\u5c11\u6807\u6ce8\u5de5\u4f5c\u91cf\u540c\u65f6\u786e\u4fdd\u57fa\u51c6\u8d28\u91cf\u3002", "method": "\u63d0\u51faE2EDev\u57fa\u51c6\uff0c\u5305\u542b\u7528\u6237\u9700\u6c42\u3001BDD\u6d4b\u8bd5\u573a\u666f\u548cPython\u6b65\u9aa4\u5b9e\u73b0\uff0c\u4f7f\u7528\u4eba\u673a\u534f\u540c\u591a\u667a\u80fd\u4f53\u6807\u6ce8\u6846\u67b6(HITL-MAA)\u8fdb\u884c\u8d28\u91cf\u4fdd\u8bc1\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u73b0\u6709E2ESD\u6846\u67b6\u548cLLM\u9aa8\u5e72\u7f51\u7edc\u5728\u89e3\u51b3\u8fd9\u4e9b\u4efb\u52a1\u65f6\u6301\u7eed\u9762\u4e34\u56f0\u96be\uff0c\u7a81\u663e\u4e86\u5bf9\u66f4\u6709\u6548\u548c\u6210\u672c\u6548\u76ca\u7684E2ESD\u89e3\u51b3\u65b9\u6848\u7684\u8feb\u5207\u9700\u6c42\u3002", "conclusion": "E2EDev\u4e3aE2ESD\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u57fa\u51c6\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5f3a\u8c03\u4e86\u5f00\u53d1\u66f4\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.14136", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14136", "abs": "https://arxiv.org/abs/2510.14136", "authors": ["David Roqui", "Ad\u00e8le Cormier", "nistor Grozavu", "Ann Bourges"], "title": "A Multimodal Approach to Heritage Preservation in the Context of Climate Change", "comment": null, "summary": "Cultural heritage sites face accelerating degradation due to climate change,\nyet tradi- tional monitoring relies on unimodal analysis (visual inspection or\nenvironmental sen- sors alone) that fails to capture the complex interplay\nbetween environmental stres- sors and material deterioration. We propose a\nlightweight multimodal architecture that fuses sensor data (temperature,\nhumidity) with visual imagery to predict degradation severity at heritage\nsites. Our approach adapts PerceiverIO with two key innovations: (1) simplified\nencoders (64D latent space) that prevent overfitting on small datasets (n=37\ntraining samples), and (2) Adaptive Barlow Twins loss that encourages modality\ncomplementarity rather than redundancy. On data from Strasbourg Cathedral, our\nmodel achieves 76.9% accu- racy, a 43% improvement over standard multimodal\narchitectures (VisualBERT, Trans- former) and 25% over vanilla PerceiverIO.\nAblation studies reveal that sensor-only achieves 61.5% while image-only\nreaches 46.2%, confirming successful multimodal synergy. A systematic\nhyperparameter study identifies an optimal moderate correlation target ({\\tau}\n=0.3) that balances align- ment and complementarity, achieving 69.2% accuracy\ncompared to other {\\tau} values ({\\tau} =0.1/0.5/0.7: 53.8%, {\\tau} =0.9:\n61.5%). This work demonstrates that architectural sim- plicity combined with\ncontrastive regularization enables effective multimodal learning in data-scarce\nheritage monitoring contexts, providing a foundation for AI-driven con-\nservation decision support systems.", "AI": {"tldr": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u591a\u6a21\u6001\u67b6\u6784\uff0c\u878d\u5408\u4f20\u611f\u5668\u6570\u636e\u548c\u89c6\u89c9\u56fe\u50cf\u9884\u6d4b\u6587\u5316\u9057\u4ea7\u9000\u5316\u7a0b\u5ea6\uff0c\u5728\u6570\u636e\u7a00\u7f3a\u60c5\u51b5\u4e0b\u5b9e\u73b076.9%\u51c6\u786e\u7387", "motivation": "\u6587\u5316\u9057\u4ea7\u56e0\u6c14\u5019\u53d8\u5316\u52a0\u901f\u9000\u5316\uff0c\u4f20\u7edf\u5355\u6a21\u6001\u76d1\u6d4b\u65e0\u6cd5\u6355\u6349\u73af\u5883\u538b\u529b\u4e0e\u6750\u6599\u9000\u5316\u95f4\u7684\u590d\u6742\u76f8\u4e92\u4f5c\u7528", "method": "\u91c7\u7528\u6539\u8fdb\u7684PerceiverIO\u67b6\u6784\uff0c\u5305\u542b\u7b80\u5316\u7f16\u7801\u5668\u548c\u81ea\u9002\u5e94Barlow Twins\u635f\u5931\u51fd\u6570\uff0c\u9f13\u52b1\u6a21\u6001\u4e92\u8865\u6027", "result": "\u5728\u65af\u7279\u62c9\u65af\u5821\u5927\u6559\u5802\u6570\u636e\u4e0a\u8fbe\u523076.9%\u51c6\u786e\u7387\uff0c\u6bd4\u6807\u51c6\u591a\u6a21\u6001\u67b6\u6784\u63d0\u534743%\uff0c\u6bd4\u5355\u6a21\u6001\u65b9\u6cd5\u663e\u8457\u6539\u5584", "conclusion": "\u67b6\u6784\u7b80\u5316\u4e0e\u5bf9\u6bd4\u6b63\u5219\u5316\u7ed3\u5408\u53ef\u5728\u6570\u636e\u7a00\u7f3a\u7684\u9057\u4ea7\u76d1\u6d4b\u4e2d\u5b9e\u73b0\u6709\u6548\u7684\u591a\u6a21\u6001\u5b66\u4e60\uff0c\u4e3aAI\u9a71\u52a8\u7684\u4fdd\u62a4\u51b3\u7b56\u7cfb\u7edf\u5960\u5b9a\u57fa\u7840"}}
{"id": "2510.14344", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14344", "abs": "https://arxiv.org/abs/2510.14344", "authors": ["Zichen Liu", "Shao Yang", "Xusheng Xiao"], "title": "BinCtx: Multi-Modal Representation Learning for Robust Android App Behavior Detection", "comment": null, "summary": "Mobile app markets host millions of apps, yet undesired behaviors (e.g.,\ndisruptive ads, illegal redirection, payment deception) remain hard to catch\nbecause they often do not rely on permission-protected APIs and can be easily\ncamouflaged via UI or metadata edits. We present BINCTX, a learning approach\nthat builds multi-modal representations of an app from (i) a global\nbytecode-as-image view that captures code-level semantics and family-style\npatterns, (ii) a contextual view (manifested actions, components, declared\npermissions, URL/IP constants) indicating how behaviors are triggered, and\n(iii) a third-party-library usage view summarizing invocation frequencies along\ninter-component call paths. The three views are embedded and fused to train a\ncontextual-aware classifier. On real-world malware and benign apps, BINCTX\nattains a macro F1 of 94.73%, outperforming strong baselines by at least\n14.92%. It remains robust under commercial obfuscation (F1 84%\npost-obfuscation) and is more resistant to adversarial samples than\nstate-of-the-art bytecode-only systems.", "AI": {"tldr": "BINCTX\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u5b57\u8282\u7801\u56fe\u50cf\u3001\u4e0a\u4e0b\u6587\u89c6\u56fe\u548c\u7b2c\u4e09\u65b9\u5e93\u4f7f\u7528\u89c6\u56fe\u6765\u68c0\u6d4b\u79fb\u52a8\u5e94\u7528\u4e2d\u7684\u4e0d\u826f\u884c\u4e3a\uff0c\u5728\u771f\u5b9e\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u4e2d\u8fbe\u523094.73%\u7684F1\u5206\u6570\uff0c\u5bf9\u6df7\u6dc6\u548c\u5bf9\u6297\u6837\u672c\u5177\u6709\u9c81\u68d2\u6027\u3002", "motivation": "\u79fb\u52a8\u5e94\u7528\u5e02\u573a\u4e2d\u5b58\u5728\u5927\u91cf\u4e0d\u826f\u884c\u4e3a\u5e94\u7528\uff0c\u8fd9\u4e9b\u5e94\u7528\u901a\u5e38\u4e0d\u4f9d\u8d56\u6743\u9650\u4fdd\u62a4API\uff0c\u4e14\u5bb9\u6613\u901a\u8fc7UI\u6216\u5143\u6570\u636e\u7f16\u8f91\u8fdb\u884c\u4f2a\u88c5\uff0c\u4f20\u7edf\u68c0\u6d4b\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u8bc6\u522b\u3002", "method": "\u6784\u5efa\u4e09\u79cd\u89c6\u56fe\uff1a\u5168\u5c40\u5b57\u8282\u7801\u56fe\u50cf\u89c6\u56fe\u6355\u83b7\u4ee3\u7801\u8bed\u4e49\u548c\u5bb6\u65cf\u6a21\u5f0f\uff0c\u4e0a\u4e0b\u6587\u89c6\u56fe\u663e\u793a\u884c\u4e3a\u89e6\u53d1\u65b9\u5f0f\uff0c\u7b2c\u4e09\u65b9\u5e93\u4f7f\u7528\u89c6\u56fe\u603b\u7ed3\u8c03\u7528\u8def\u5f84\u9891\u7387\u3002\u4e09\u79cd\u89c6\u56fe\u5d4c\u5165\u878d\u5408\u540e\u8bad\u7ec3\u4e0a\u4e0b\u6587\u611f\u77e5\u5206\u7c7b\u5668\u3002", "result": "\u5728\u771f\u5b9e\u6076\u610f\u8f6f\u4ef6\u548c\u826f\u6027\u5e94\u7528\u4e0a\u8fbe\u523094.73%\u7684\u5b8fF1\u5206\u6570\uff0c\u6bd4\u5f3a\u57fa\u7ebf\u81f3\u5c11\u63d0\u534714.92%\u3002\u5728\u5546\u4e1a\u6df7\u6dc6\u540e\u4ecd\u4fdd\u630184%\u7684F1\u5206\u6570\uff0c\u6bd4\u4ec5\u4f7f\u7528\u5b57\u8282\u7801\u7684\u6700\u5148\u8fdb\u7cfb\u7edf\u66f4\u6297\u5bf9\u6297\u6837\u672c\u3002", "conclusion": "BINCTX\u901a\u8fc7\u591a\u6a21\u6001\u8868\u793a\u5b66\u4e60\u6709\u6548\u68c0\u6d4b\u79fb\u52a8\u5e94\u7528\u4e2d\u7684\u4e0d\u826f\u884c\u4e3a\uff0c\u5bf9\u6df7\u6dc6\u548c\u5bf9\u6297\u653b\u51fb\u5177\u6709\u9c81\u68d2\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2510.14625", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.14625", "abs": "https://arxiv.org/abs/2510.14625", "authors": ["Mehrdad Saadatmand", "Abbas Khan", "Beatriz Marin", "Ana C. R Paiva", "Nele Van Asch", "Graham Moran", "Felix Cammaerts", "Monique Snoeck", "Alexandra Mendes"], "title": "Software Testing Education and Industry Needs - Report from the ENACTEST EU Project", "comment": "* The paper is going to appear in the proceedings of the 26th\n  International Conference on Product-Focused Software Process Improvement\n  (PROFES 2025). To cite the paper, please check and refer to the PROFES 2025\n  proceedings", "summary": "The evolving landscape of software development demands that software testers\ncontinuously adapt to new tools, practices, and acquire new skills. This study\ninvestigates software testing competency needs in industry, identifies\nknowledge gaps in current testing education, and highlights competencies and\ngaps not addressed in academic literature. This is done by conducting two focus\ngroup sessions and interviews with professionals across diverse domains,\nincluding railway industry, healthcare, and software consulting and performing\na curated small-scale scoping review. The study instrument, co-designed by\nmembers of the ENACTEST project consortium, was developed collaboratively and\nrefined through multiple iterations to ensure comprehensive coverage of\nindustry needs and educational gaps. In particular, by performing a thematic\nqualitative analysis, we report our findings and observations regarding:\nprofessional training methods, challenges in offering training in industry,\ndifferent ways of evaluating the quality of training, identified knowledge gaps\nwith respect to academic education and industry needs, future needs and trends\nin testing education, and knowledge transfer methods within companies. Finally,\nthe scoping review results confirm knowledge gaps in areas such as AI testing,\nsecurity testing and soft skills.", "AI": {"tldr": "\u672c\u7814\u7a76\u8c03\u67e5\u4e86\u5de5\u4e1a\u754c\u5bf9\u8f6f\u4ef6\u6d4b\u8bd5\u80fd\u529b\u7684\u9700\u6c42\uff0c\u8bc6\u522b\u4e86\u5f53\u524d\u6d4b\u8bd5\u6559\u80b2\u7684\u77e5\u8bc6\u7f3a\u53e3\uff0c\u5e76\u53d1\u73b0\u4e86\u5b66\u672f\u6587\u732e\u4e2d\u672a\u6d89\u53ca\u7684\u80fd\u529b\u548c\u5dee\u8ddd\u3002", "motivation": "\u8f6f\u4ef6\u5f00\u53d1\u7684\u4e0d\u65ad\u6f14\u53d8\u8981\u6c42\u6d4b\u8bd5\u4eba\u5458\u6301\u7eed\u9002\u5e94\u65b0\u5de5\u5177\u3001\u5b9e\u8df5\u5e76\u83b7\u53d6\u65b0\u6280\u80fd\uff0c\u56e0\u6b64\u9700\u8981\u4e86\u89e3\u884c\u4e1a\u9700\u6c42\u548c\u73b0\u6709\u6559\u80b2\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u901a\u8fc7\u4e24\u6b21\u7126\u70b9\u5c0f\u7ec4\u4f1a\u8bae\u548c\u8de8\u591a\u4e2a\u884c\u4e1a\u7684\u4e13\u4e1a\u4eba\u58eb\u8bbf\u8c08\uff0c\u7ed3\u5408\u5c0f\u89c4\u6a21\u8303\u56f4\u7efc\u8ff0\uff0c\u91c7\u7528\u4e3b\u9898\u5b9a\u6027\u5206\u6790\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e13\u4e1a\u57f9\u8bad\u65b9\u6cd5\u3001\u884c\u4e1a\u57f9\u8bad\u6311\u6218\u3001\u57f9\u8bad\u8d28\u91cf\u8bc4\u4f30\u65b9\u5f0f\u3001\u5b66\u672f\u6559\u80b2\u4e0e\u884c\u4e1a\u9700\u6c42\u4e4b\u95f4\u7684\u77e5\u8bc6\u7f3a\u53e3\u3001\u672a\u6765\u6d4b\u8bd5\u6559\u80b2\u8d8b\u52bf\u4ee5\u53ca\u516c\u53f8\u5185\u90e8\u77e5\u8bc6\u8f6c\u79fb\u65b9\u6cd5\u7b49\u65b9\u9762\u7684\u95ee\u9898\u3002\u8303\u56f4\u7efc\u8ff0\u786e\u8ba4\u4e86AI\u6d4b\u8bd5\u3001\u5b89\u5168\u6d4b\u8bd5\u548c\u8f6f\u6280\u80fd\u7b49\u9886\u57df\u7684\u77e5\u8bc6\u7f3a\u53e3\u3002", "conclusion": "\u8f6f\u4ef6\u6d4b\u8bd5\u6559\u80b2\u9700\u8981\u66f4\u597d\u5730\u4e0e\u884c\u4e1a\u9700\u6c42\u5bf9\u63a5\uff0c\u7279\u522b\u662f\u5728AI\u6d4b\u8bd5\u3001\u5b89\u5168\u6d4b\u8bd5\u548c\u8f6f\u6280\u80fd\u7b49\u65b0\u5174\u9886\u57df\uff0c\u4ee5\u7f29\u5c0f\u5b66\u672f\u6559\u80b2\u4e0e\u5b9e\u9645\u5de5\u4f5c\u9700\u6c42\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2510.14150", "categories": ["cs.AI", "cs.LG", "cs.NE", "I.2.7; I.2.2"], "pdf": "https://arxiv.org/pdf/2510.14150", "abs": "https://arxiv.org/abs/2510.14150", "authors": ["Henrique Assump\u00e7\u00e3o", "Diego Ferreira", "Leandro Campos", "Fabricio Murai"], "title": "CodeEvolve: An open source evolutionary coding agent for algorithm discovery and optimization", "comment": "11 pages, 9 figures, 2 tables", "summary": "In this work, we introduce CodeEvolve, an open-source evolutionary coding\nagent that unites Large Language Models (LLMs) with genetic algorithms to solve\ncomplex computational problems. Our framework adapts powerful evolutionary\nconcepts to the LLM domain, building upon recent methods for generalized\nscientific discovery. CodeEvolve employs an island-based genetic algorithm to\nmaintain population diversity and increase throughput, introduces a novel\ninspiration-based crossover mechanism that leverages the LLMs context window to\ncombine features from successful solutions, and implements meta-prompting\nstrategies for dynamic exploration of the solution space. We conduct a rigorous\nevaluation of CodeEvolve on a subset of the mathematical benchmarks used to\nevaluate Google DeepMind's closed-source AlphaEvolve. Our findings show that\nour method surpasses AlphaEvolve's performance on several challenging problems.\nTo foster collaboration and accelerate progress, we release our complete\nframework as an open-source repository.", "AI": {"tldr": "CodeEvolve\u662f\u4e00\u4e2a\u5f00\u6e90\u8fdb\u5316\u7f16\u7801\u4ee3\u7406\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u9057\u4f20\u7b97\u6cd5\u7ed3\u5408\u89e3\u51b3\u590d\u6742\u8ba1\u7b97\u95ee\u9898\uff0c\u5728\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u4e86Google DeepMind\u7684AlphaEvolve\u3002", "motivation": "\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u8fdb\u5316\u7b97\u6cd5\u6765\u89e3\u51b3\u590d\u6742\u8ba1\u7b97\u95ee\u9898\uff0c\u5e76\u6784\u5efa\u5f00\u6e90\u6846\u67b6\u4fc3\u8fdb\u534f\u4f5c\u548c\u52a0\u901f\u8fdb\u5c55\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u5c9b\u5c7f\u7684\u9057\u4f20\u7b97\u6cd5\u4fdd\u6301\u79cd\u7fa4\u591a\u6837\u6027\uff0c\u5f15\u5165\u57fa\u4e8e\u542f\u53d1\u7684\u4ea4\u53c9\u673a\u5236\u5229\u7528LLM\u4e0a\u4e0b\u6587\u7a97\u53e3\u7ec4\u5408\u6210\u529f\u89e3\u51b3\u65b9\u6848\u7684\u7279\u5f81\uff0c\u5b9e\u73b0\u5143\u63d0\u793a\u7b56\u7565\u52a8\u6001\u63a2\u7d22\u89e3\u7a7a\u95f4\u3002", "result": "\u5728\u7528\u4e8e\u8bc4\u4f30Google DeepMind AlphaEvolve\u7684\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u5b50\u96c6\u4e0a\uff0cCodeEvolve\u5728\u591a\u4e2a\u6311\u6218\u6027\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u8d85\u8d8a\u4e86AlphaEvolve\u3002", "conclusion": "CodeEvolve\u6210\u529f\u5730\u5c06\u8fdb\u5316\u6982\u5ff5\u5e94\u7528\u4e8eLLM\u9886\u57df\uff0c\u901a\u8fc7\u5f00\u6e90\u6846\u67b6\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u7684\u53d1\u5c55\uff0c\u5c55\u793a\u4e86\u5728\u590d\u6742\u95ee\u9898\u6c42\u89e3\u4e0a\u7684\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2510.14384", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.14384", "abs": "https://arxiv.org/abs/2510.14384", "authors": ["Sebastian J\u00e4nich", "Merlin Sievers", "Johannes Kinder"], "title": "Match & Mend: Minimally Invasive Local Reassembly for Patching N-day Vulnerabilities in ARM Binaries", "comment": null, "summary": "Low-cost Internet of Things (IoT) devices are increasingly popular but often\ninsecure due to poor update regimes. As a result, many devices run outdated and\nknown-vulnerable versions of open-source software. We address this problem by\nproposing to patch IoT firmware at the binary level, without requiring vendor\nsupport. In particular, we introduce minimally invasive local reassembly, a new\ntechnique for automatically patching known (n-day) vulnerabilities in IoT\nfirmware. Our approach is designed to minimize side effects and reduce the risk\nof introducing breaking changes. We systematically evaluate our approach both\non 108 binaries within the controlled environment of the MAGMA benchmarks, as\nwell as on 30 real-world Linux-based IoT firmware images from the KARONTE\ndataset. Our prototype successfully patches 83% of targeted vulnerabilities in\nMAGMA and 96% in the firmware dataset.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u4e8c\u8fdb\u5236\u7ea7\u522b\u81ea\u52a8\u4fee\u8865\u7269\u8054\u7f51\u56fa\u4ef6\u4e2d\u5df2\u77e5\u6f0f\u6d1e\u7684\u6280\u672f\uff0c\u65e0\u9700\u5382\u5546\u652f\u6301\uff0c\u6210\u529f\u4fee\u8865\u4e8683%-96%\u7684\u76ee\u6807\u6f0f\u6d1e\u3002", "motivation": "\u4f4e\u6210\u672c\u7269\u8054\u7f51\u8bbe\u5907\u7531\u4e8e\u66f4\u65b0\u673a\u5236\u4e0d\u5b8c\u5584\u800c\u5b58\u5728\u5b89\u5168\u9690\u60a3\uff0c\u8bb8\u591a\u8bbe\u5907\u8fd0\u884c\u7740\u8fc7\u65f6\u4e14\u6709\u5df2\u77e5\u6f0f\u6d1e\u7684\u5f00\u6e90\u8f6f\u4ef6\u7248\u672c\u3002", "method": "\u91c7\u7528\u6700\u5c0f\u4fb5\u5165\u5f0f\u672c\u5730\u91cd\u6c47\u7f16\u6280\u672f\uff0c\u5728\u4e8c\u8fdb\u5236\u7ea7\u522b\u81ea\u52a8\u4fee\u8865\u5df2\u77e5\u6f0f\u6d1e\uff0c\u65e8\u5728\u6700\u5c0f\u5316\u526f\u4f5c\u7528\u548c\u964d\u4f4e\u5f15\u5165\u7834\u574f\u6027\u53d8\u66f4\u7684\u98ce\u9669\u3002", "result": "\u5728MAGMA\u57fa\u51c6\u6d4b\u8bd5\u7684108\u4e2a\u4e8c\u8fdb\u5236\u6587\u4ef6\u4e2d\u6210\u529f\u4fee\u886583%\u7684\u76ee\u6807\u6f0f\u6d1e\uff0c\u5728KARONTE\u6570\u636e\u96c6\u768430\u4e2a\u771f\u5b9e\u7269\u8054\u7f51\u56fa\u4ef6\u4e2d\u6210\u529f\u4fee\u886596%\u7684\u76ee\u6807\u6f0f\u6d1e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u7269\u8054\u7f51\u8bbe\u5907\u7684\u5b89\u5168\u66f4\u65b0\u95ee\u9898\uff0c\u65e0\u9700\u5382\u5546\u652f\u6301\u5373\u53ef\u81ea\u52a8\u4fee\u8865\u5df2\u77e5\u6f0f\u6d1e\u3002"}}
{"id": "2510.14635", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.14635", "abs": "https://arxiv.org/abs/2510.14635", "authors": ["Qingyao Li", "Xinyi Dai", "Weiwen Liu", "Xiangyang Li", "Yasheng Wang", "Ruiming Tang", "Yong Yu", "Weinan Zhang"], "title": "ATGen: Adversarial Reinforcement Learning for Test Case Generation", "comment": null, "summary": "Large Language Models (LLMs) excel at code generation, yet their outputs\noften contain subtle bugs, for which effective test cases are a critical\nbottleneck. Existing test generation methods, whether based on prompting or\nsupervised fine-tuning, rely on static datasets. This imposes a\n``fixed-difficulty ceiling'', fundamentally limiting their ability to uncover\nnovel or more complex bugs beyond their training scope. To overcome this, we\nintroduce ATGen, a framework that trains a test case generator via adversarial\nreinforcement learning. ATGen pits a test generator against an adversarial code\ngenerator that continuously crafts harder bugs to evade the current policy.\nThis dynamic loop creates a curriculum of increasing difficulty challenging\ncurrent policy. The test generator is optimized via Reinforcement Learning (RL)\nto jointly maximize ``Output Accuracy'' and ``Attack Success'', enabling it to\nlearn a progressively stronger policy that breaks the fixed-difficulty ceiling\nof static training. Extensive experiments demonstrate that ATGen significantly\noutperforms state-of-the-art baselines. We further validate its practical\nutility, showing it serves as both a more effective filter for Best-of-N\ninference and a higher-quality reward source for training code generation\nmodels. Our work establishes a new, dynamic paradigm for improving the\nreliability of LLM-generated code.", "AI": {"tldr": "ATGen\u662f\u4e00\u4e2a\u901a\u8fc7\u5bf9\u6297\u6027\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6d4b\u8bd5\u751f\u6210\u5668\u548c\u5bf9\u6297\u6027\u4ee3\u7801\u751f\u6210\u5668\u7684\u52a8\u6001\u5bf9\u6297\u5faa\u73af\uff0c\u6253\u7834\u9759\u6001\u6570\u636e\u96c6\u7684\u56fa\u5b9a\u96be\u5ea6\u9650\u5236\uff0c\u663e\u8457\u63d0\u5347LLM\u751f\u6210\u4ee3\u7801\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u9759\u6001\u6570\u636e\u96c6\u7684\u6d4b\u8bd5\u751f\u6210\u65b9\u6cd5\u5b58\u5728\"\u56fa\u5b9a\u96be\u5ea6\u5929\u82b1\u677f\"\uff0c\u65e0\u6cd5\u53d1\u73b0\u8d85\u51fa\u8bad\u7ec3\u8303\u56f4\u7684\u65b0\u9896\u6216\u66f4\u590d\u6742bug\uff0c\u9650\u5236\u4e86LLM\u751f\u6210\u4ee3\u7801\u7684\u53ef\u9760\u6027\u63d0\u5347\u3002", "method": "\u91c7\u7528\u5bf9\u6297\u6027\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u8ba9\u6d4b\u8bd5\u751f\u6210\u5668\u4e0e\u5bf9\u6297\u6027\u4ee3\u7801\u751f\u6210\u5668\u8fdb\u884c\u52a8\u6001\u5bf9\u6297\uff0c\u6d4b\u8bd5\u751f\u6210\u5668\u901a\u8fc7RL\u4f18\u5316\u540c\u65f6\u6700\u5927\u5316\"\u8f93\u51fa\u51c6\u786e\u6027\"\u548c\"\u653b\u51fb\u6210\u529f\u7387\"\u3002", "result": "ATGen\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\uff0c\u65e2\u80fd\u4f5c\u4e3a\u66f4\u6709\u6548\u7684Best-of-N\u63a8\u7406\u8fc7\u6ee4\u5668\uff0c\u4e5f\u80fd\u4f5c\u4e3a\u8bad\u7ec3\u4ee3\u7801\u751f\u6210\u6a21\u578b\u7684\u66f4\u9ad8\u8d28\u91cf\u5956\u52b1\u6e90\u3002", "conclusion": "ATGen\u5efa\u7acb\u4e86\u4e00\u79cd\u65b0\u7684\u52a8\u6001\u8303\u5f0f\uff0c\u901a\u8fc7\u6301\u7eed\u5bf9\u6297\u8bad\u7ec3\u6253\u7834\u4e86\u9759\u6001\u8bad\u7ec3\u7684\u56fa\u5b9a\u96be\u5ea6\u9650\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u751f\u6210\u4ee3\u7801\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2510.14154", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14154", "abs": "https://arxiv.org/abs/2510.14154", "authors": ["Tian Liu", "Alex Cann", "Ian Colbert", "Mehdi Saeedi"], "title": "Combining Reinforcement Learning and Behavior Trees for NPCs in Video Games with AMD Schola", "comment": "8 pages, 4 figures, 5 tables", "summary": "While the rapid advancements in the reinforcement learning (RL) research\ncommunity have been remarkable, the adoption in commercial video games remains\nslow. In this paper, we outline common challenges the Game AI community faces\nwhen using RL-driven NPCs in practice, and highlight the intersection of RL\nwith traditional behavior trees (BTs) as a crucial juncture to be explored\nfurther. Although the BT+RL intersection has been suggested in several research\npapers, its adoption is rare. We demonstrate the viability of this approach\nusing AMD Schola -- a plugin for training RL agents in Unreal Engine -- by\ncreating multi-task NPCs in a complex 3D environment inspired by the commercial\nvideo game ``The Last of Us\". We provide detailed methodologies for jointly\ntraining RL models with BTs while showcasing various skills.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5c06\u5f3a\u5316\u5b66\u4e60\u4e0e\u884c\u4e3a\u6811\u7ed3\u5408\u7528\u4e8e\u6e38\u620fAI\u7684\u53ef\u884c\u6027\uff0c\u901a\u8fc7\u5728\u7c7b\u4f3c\u300a\u6700\u540e\u751f\u8fd8\u8005\u300b\u7684\u590d\u67423D\u73af\u5883\u4e2d\u8bad\u7ec3\u591a\u4efb\u52a1NPC\u6765\u9a8c\u8bc1\u8be5\u65b9\u6cd5\u3002", "motivation": "\u5c3d\u7ba1\u5f3a\u5316\u5b66\u4e60\u7814\u7a76\u8fdb\u5c55\u8fc5\u901f\uff0c\u4f46\u5728\u5546\u4e1a\u6e38\u620f\u4e2d\u7684\u5e94\u7528\u4ecd\u7136\u7f13\u6162\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u6e38\u620fAI\u793e\u533a\u5728\u5b9e\u9645\u4f7f\u7528RL\u9a71\u52a8NPC\u65f6\u9762\u4e34\u7684\u6311\u6218\uff0c\u5e76\u63a2\u7d22RL\u4e0e\u4f20\u7edf\u884c\u4e3a\u6811\u7684\u7ed3\u5408\u70b9\u3002", "method": "\u4f7f\u7528AMD Schola\u63d2\u4ef6\u5728\u865a\u5e7b\u5f15\u64ce\u4e2d\u8bad\u7ec3RL\u667a\u80fd\u4f53\uff0c\u521b\u5efa\u591a\u4efb\u52a1NPC\uff0c\u5e76\u5c55\u793a\u8054\u5408\u8bad\u7ec3RL\u6a21\u578b\u4e0e\u884c\u4e3a\u6811\u7684\u8be6\u7ec6\u65b9\u6cd5\u3002", "result": "\u6210\u529f\u5c55\u793a\u4e86\u5728\u590d\u67423D\u73af\u5883\u4e2d\u4f7f\u7528RL+BT\u65b9\u6cd5\u8bad\u7ec3\u591a\u4efb\u52a1NPC\u7684\u53ef\u884c\u6027\uff0c\u9a8c\u8bc1\u4e86\u8fd9\u79cd\u7ed3\u5408\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u4e0e\u884c\u4e3a\u6811\u7684\u7ed3\u5408\u662f\u4e00\u4e2a\u503c\u5f97\u8fdb\u4e00\u6b65\u63a2\u7d22\u7684\u5173\u952e\u4ea4\u53c9\u70b9\uff0c\u867d\u7136\u5df2\u6709\u7814\u7a76\u63d0\u51fa\u4f46\u5b9e\u9645\u5e94\u7528\u4ecd\u7136\u7f55\u89c1\uff0c\u672c\u6587\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u5b9e\u9645\u53ef\u884c\u6027\u3002"}}
{"id": "2510.14470", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14470", "abs": "https://arxiv.org/abs/2510.14470", "authors": ["Xiaoyu Xue", "Yuni Lai", "Chenxi Huang", "Yulin Zhu", "Gaolei Li", "Xiaoge Zhang", "Kai Zhou"], "title": "Stealthy Dual-Trigger Backdoors: Attacking Prompt Tuning in LM-Empowered Graph Foundation Models", "comment": null, "summary": "The emergence of graph foundation models (GFMs), particularly those\nincorporating language models (LMs), has revolutionized graph learning and\ndemonstrated remarkable performance on text-attributed graphs (TAGs). However,\ncompared to traditional GNNs, these LM-empowered GFMs introduce unique security\nvulnerabilities during the unsecured prompt tuning phase that remain\nunderstudied in current research. Through empirical investigation, we reveal a\nsignificant performance degradation in traditional graph backdoor attacks when\noperating in attribute-inaccessible constrained TAG systems without explicit\ntrigger node attribute optimization. To address this, we propose a novel\ndual-trigger backdoor attack framework that operates at both text-level and\nstruct-level, enabling effective attacks without explicit optimization of\ntrigger node text attributes through the strategic utilization of a\npre-established text pool. Extensive experimental evaluations demonstrate that\nour attack maintains superior clean accuracy while achieving outstanding attack\nsuccess rates, including scenarios with highly concealed single-trigger nodes.\nOur work highlights critical backdoor risks in web-deployed LM-empowered GFMs\nand contributes to the development of more robust supervision mechanisms for\nopen-source platforms in the era of foundation models.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63ed\u793a\u4e86\u8bed\u8a00\u6a21\u578b\u8d4b\u80fd\u7684\u56fe\u57fa\u7840\u6a21\u578b\u5728\u63d0\u793a\u8c03\u4f18\u9636\u6bb5\u7684\u72ec\u7279\u5b89\u5168\u6f0f\u6d1e\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u6587\u672c\u7ea7\u548c\u7ed3\u6784\u7ea7\u540c\u65f6\u64cd\u4f5c\u7684\u53cc\u89e6\u53d1\u540e\u95e8\u653b\u51fb\u6846\u67b6\uff0c\u80fd\u591f\u5728\u65e0\u9700\u663e\u5f0f\u4f18\u5316\u89e6\u53d1\u8282\u70b9\u6587\u672c\u5c5e\u6027\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u6709\u6548\u653b\u51fb\u3002", "motivation": "\u4f20\u7edf\u56fe\u795e\u7ecf\u7f51\u7edc\u76f8\u6bd4\uff0c\u8bed\u8a00\u6a21\u578b\u8d4b\u80fd\u7684\u56fe\u57fa\u7840\u6a21\u578b\u5728\u672a\u53d7\u4fdd\u62a4\u7684\u63d0\u793a\u8c03\u4f18\u9636\u6bb5\u5f15\u5165\u4e86\u72ec\u7279\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u4f46\u76ee\u524d\u7814\u7a76\u5bf9\u6b64\u5173\u6ce8\u4e0d\u8db3\u3002\u4f5c\u8005\u53d1\u73b0\u4f20\u7edf\u56fe\u540e\u95e8\u653b\u51fb\u5728\u5c5e\u6027\u4e0d\u53ef\u8bbf\u95ee\u7684\u53d7\u9650\u6587\u672c\u5c5e\u6027\u56fe\u7cfb\u7edf\u4e2d\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u53cc\u89e6\u53d1\u540e\u95e8\u653b\u51fb\u6846\u67b6\uff0c\u5728\u6587\u672c\u7ea7\u548c\u7ed3\u6784\u7ea7\u540c\u65f6\u64cd\u4f5c\uff0c\u901a\u8fc7\u6218\u7565\u6027\u5730\u5229\u7528\u9884\u5efa\u7acb\u7684\u6587\u672c\u6c60\uff0c\u65e0\u9700\u663e\u5f0f\u4f18\u5316\u89e6\u53d1\u8282\u70b9\u6587\u672c\u5c5e\u6027\u5373\u53ef\u5b9e\u73b0\u6709\u6548\u653b\u51fb\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u653b\u51fb\u5728\u4fdd\u6301\u4f18\u8d8a\u7684\u5e72\u51c0\u51c6\u786e\u7387\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u51fa\u8272\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u5305\u62ec\u9ad8\u5ea6\u9690\u853d\u7684\u5355\u89e6\u53d1\u8282\u70b9\u573a\u666f\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u7a81\u663e\u4e86\u7f51\u7edc\u90e8\u7f72\u7684\u8bed\u8a00\u6a21\u578b\u8d4b\u80fd\u56fe\u57fa\u7840\u6a21\u578b\u4e2d\u7684\u5173\u952e\u540e\u95e8\u98ce\u9669\uff0c\u4e3a\u5f00\u6e90\u5e73\u53f0\u5728\u57fa\u7840\u6a21\u578b\u65f6\u4ee3\u5f00\u53d1\u66f4\u5f3a\u5927\u7684\u76d1\u7763\u673a\u5236\u505a\u51fa\u4e86\u8d21\u732e\u3002"}}
{"id": "2510.14653", "categories": ["cs.SE", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.14653", "abs": "https://arxiv.org/abs/2510.14653", "authors": ["Sven Tarlowski", "Lutz Eckstein"], "title": "Requirement Identification for Traffic Simulations in Driving Simulators", "comment": "2 Pages, 1 figure", "summary": "This paper addresses the challenge of ensuring realistic traffic conditions\nby proposing a methodology that systematically identifies traffic simulation\nrequirements. Using a structured approach based on sub-goals in each study\nphase, specific technical needs are derived for microscopic levels, agent\nmodels, and visual representation. The methodology aims to maintain a high\ndegree of fidelity, enhancing both the validity of experimental outcomes and\nparticipant engagement. By providing a clear link between study objectives and\ntraffic simulation design, this approach supports robust automotive development\nand testing.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7cfb\u7edf\u8bc6\u522b\u4ea4\u901a\u4eff\u771f\u9700\u6c42\u7684\u65b9\u6cd5\u8bba\uff0c\u901a\u8fc7\u5206\u9636\u6bb5\u5b50\u76ee\u6807\u6765\u786e\u4fdd\u4ea4\u901a\u4eff\u771f\u7684\u771f\u5b9e\u6027\u548c\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u786e\u4fdd\u4ea4\u901a\u4eff\u771f\u771f\u5b9e\u6027\u7684\u6311\u6218\uff0c\u63d0\u5347\u5b9e\u9a8c\u7ed3\u679c\u7684\u6548\u5ea6\u548c\u53c2\u4e0e\u8005\u53c2\u4e0e\u5ea6\u3002", "method": "\u91c7\u7528\u7ed3\u6784\u5316\u65b9\u6cd5\uff0c\u57fa\u4e8e\u5404\u7814\u7a76\u9636\u6bb5\u7684\u5b50\u76ee\u6807\uff0c\u63a8\u5bfc\u5fae\u89c2\u5c42\u9762\u3001\u667a\u80fd\u4f53\u6a21\u578b\u548c\u89c6\u89c9\u8868\u793a\u7684\u5177\u4f53\u6280\u672f\u9700\u6c42\u3002", "result": "\u5efa\u7acb\u4e86\u7814\u7a76\u76ee\u6807\u4e0e\u4ea4\u901a\u4eff\u771f\u8bbe\u8ba1\u4e4b\u95f4\u7684\u6e05\u6670\u8054\u7cfb\uff0c\u652f\u6301\u7a33\u5065\u7684\u6c7d\u8f66\u5f00\u53d1\u548c\u6d4b\u8bd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u8bba\u80fd\u591f\u4fdd\u6301\u9ad8\u4fdd\u771f\u5ea6\uff0c\u589e\u5f3a\u5b9e\u9a8c\u7ed3\u679c\u7684\u53ef\u9760\u6027\u548c\u53c2\u4e0e\u8005\u7684\u6c89\u6d78\u611f\u3002"}}
{"id": "2510.14169", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14169", "abs": "https://arxiv.org/abs/2510.14169", "authors": ["Praphul Singh", "Corey Barrett", "Sumana Srivasta", "Amitabh Saikia", "Irfan Bulu", "Sri Gadde", "Krishnaram Kenthapadi"], "title": "JEDA: Query-Free Clinical Order Search from Ambient Dialogues", "comment": null, "summary": "Clinical conversations mix explicit directives (order a chest X-ray) with\nimplicit reasoning (the cough worsened overnight, we should check for\npneumonia). Many systems rely on LLM rewriting, adding latency, instability,\nand opacity that hinder real-time ordering. We present JEDA (Joint Embedding\nfor Direct and Ambient clinical orders), a domain-initialized bi-encoder that\nretrieves canonical orders directly and, in a query-free mode, encodes a short\nrolling window of ambient dialogue to trigger retrieval. Initialized from\nPubMedBERT and fine-tuned with a duplicate-safe contrastive objective, JEDA\naligns heterogeneous expressions of intent to shared order concepts. Training\nuses constrained LLM guidance to tie each signed order to complementary\nformulations (command only, context only, command+context, context+reasoning),\nproducing clearer inter-order separation, tighter query extendash order\ncoupling, and stronger generalization. The query-free mode is noise-resilient,\nreducing sensitivity to disfluencies and ASR errors by conditioning on a short\nwindow rather than a single utterance. Deployed in practice, JEDA yields large\ngains and substantially outperforms its base encoder and recent open embedders\n(Linq Embed Mistral, SFR Embedding, GTE Qwen, BGE large, Embedding Gemma). The\nresult is a fast, interpretable, LLM-free retrieval layer that links ambient\ncontext to actionable clinical orders in real time.", "AI": {"tldr": "JEDA\u662f\u4e00\u4e2a\u7528\u4e8e\u4e34\u5e8a\u8ba2\u5355\u68c0\u7d22\u7684\u53cc\u7f16\u7801\u5668\u7cfb\u7edf\uff0c\u80fd\u591f\u76f4\u63a5\u4ece\u5bf9\u8bdd\u4e2d\u68c0\u7d22\u89c4\u8303\u8ba2\u5355\uff0c\u65e0\u9700\u4f9d\u8d56LLM\u91cd\u5199\uff0c\u89e3\u51b3\u4e86\u5ef6\u8fdf\u3001\u4e0d\u7a33\u5b9a\u548c\u4e0d\u900f\u660e\u7684\u95ee\u9898\u3002", "motivation": "\u4e34\u5e8a\u5bf9\u8bdd\u6df7\u5408\u4e86\u663e\u6027\u6307\u4ee4\u548c\u9690\u6027\u63a8\u7406\uff0c\u73b0\u6709\u7cfb\u7edf\u4f9d\u8d56LLM\u91cd\u5199\u4f1a\u5e26\u6765\u5ef6\u8fdf\u3001\u4e0d\u7a33\u5b9a\u548c\u4e0d\u900f\u660e\u6027\uff0c\u963b\u788d\u5b9e\u65f6\u8ba2\u5355\u5904\u7406\u3002", "method": "\u4f7f\u7528PubMedBERT\u521d\u59cb\u5316\u7684\u53cc\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u91cd\u590d\u5b89\u5168\u7684\u5bf9\u6bd4\u76ee\u6807\u8fdb\u884c\u5fae\u8c03\uff0c\u5c06\u610f\u56fe\u7684\u5f02\u8d28\u8868\u8fbe\u5bf9\u9f50\u5230\u5171\u4eab\u8ba2\u5355\u6982\u5ff5\u3002\u8bad\u7ec3\u4f7f\u7528\u53d7\u9650LLM\u6307\u5bfc\u5c06\u7b7e\u540d\u8ba2\u5355\u4e0e\u8865\u5145\u8868\u8ff0\u7ed1\u5b9a\u3002", "result": "JEDA\u5728\u5b9e\u8df5\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\uff0c\u5927\u5e45\u4f18\u4e8e\u57fa\u7840\u7f16\u7801\u5668\u548c\u8fd1\u671f\u5f00\u6e90\u5d4c\u5165\u5668\uff0c\u5b9e\u73b0\u4e86\u5feb\u901f\u3001\u53ef\u89e3\u91ca\u3001\u65e0\u9700LLM\u7684\u5b9e\u65f6\u4e34\u5e8a\u8ba2\u5355\u68c0\u7d22\u3002", "conclusion": "JEDA\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5feb\u901f\u3001\u53ef\u89e3\u91ca\u3001\u65e0\u9700LLM\u7684\u68c0\u7d22\u5c42\uff0c\u80fd\u591f\u5b9e\u65f6\u5c06\u73af\u5883\u4e0a\u4e0b\u6587\u94fe\u63a5\u5230\u53ef\u64cd\u4f5c\u7684\u4e34\u5e8a\u8ba2\u5355\u3002"}}
{"id": "2510.14480", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.14480", "abs": "https://arxiv.org/abs/2510.14480", "authors": ["Massimo Bartoletti", "Riccardo Marchesin", "Roberto Zunino"], "title": "Certifying optimal MEV strategies with Lean", "comment": null, "summary": "Maximal Extractable Value (MEV) refers to a class of attacks to decentralized\napplications where the adversary profits by manipulating the ordering,\ninclusion, or exclusion of transactions in a blockchain. Decentralized Finance\n(DeFi) protocols are a primary target of these attacks, as their logic depends\ncritically on transaction sequencing. To date, MEV attacks have already\nextracted billions of dollars in value, underscoring their systemic impact on\nblockchain security. Verifying the absence of MEV attacks requires determining\nsuitable upper bounds, i.e. proving that no adversarial strategy can extract\nmore value (if any) than expected by protocol designers. This problem is\nnotoriously difficult: the space of adversarial strategies is extremely vast,\nmaking empirical studies and pen-and-paper reasoning insufficiently rigorous.\nIn this paper, we present the first mechanized formalization of MEV in the Lean\ntheorem prover. We introduce a methodology to construct machine-checked proofs\nof MEV bounds, providing correctness guarantees beyond what is possible with\nexisting techniques. To demonstrate the generality of our approach, we model\nand analyse the MEV of two paradigmatic DeFi protocols. Notably, we develop the\nfirst machine-checked proof of the optimality of sandwich attacks in Automated\nMarket Makers, a fundamental DeFi primitive.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u5728Lean\u5b9a\u7406\u8bc1\u660e\u5668\u4e2d\u673a\u68b0\u5316\u5f62\u5f0f\u5316MEV\u7684\u65b9\u6cd5\uff0c\u5f00\u53d1\u4e86\u673a\u5668\u9a8c\u8bc1\u7684MEV\u8fb9\u754c\u8bc1\u660e\u65b9\u6cd5\uff0c\u5e76\u9996\u6b21\u8bc1\u660e\u4e86AMM\u4e2d\u4e09\u660e\u6cbb\u653b\u51fb\u7684\u6700\u4f18\u6027\u3002", "motivation": "MEV\u653b\u51fb\u5df2\u4eceDeFi\u534f\u8bae\u4e2d\u63d0\u53d6\u4e86\u6570\u5341\u4ebf\u7f8e\u5143\u4ef7\u503c\uff0c\u9a8c\u8bc1MEV\u653b\u51fb\u7684\u7f3a\u5931\u9700\u8981\u786e\u5b9a\u5408\u9002\u7684\u4e0a\u754c\uff0c\u4f46\u73b0\u6709\u7ecf\u9a8c\u7814\u7a76\u548c\u624b\u5de5\u63a8\u7406\u65b9\u6cd5\u4e0d\u591f\u4e25\u8c28\u3002", "method": "\u5728Lean\u5b9a\u7406\u8bc1\u660e\u5668\u4e2d\u5f62\u5f0f\u5316MEV\uff0c\u6784\u5efa\u673a\u5668\u9a8c\u8bc1\u7684MEV\u8fb9\u754c\u8bc1\u660e\u65b9\u6cd5\uff0c\u5e76\u5bf9\u4e24\u4e2a\u5178\u578bDeFi\u534f\u8bae\u8fdb\u884c\u5efa\u6a21\u5206\u6790\u3002", "result": "\u6210\u529f\u5f00\u53d1\u4e86\u673a\u5668\u9a8c\u8bc1\u7684MEV\u8fb9\u754c\u8bc1\u660e\u65b9\u6cd5\uff0c\u9996\u6b21\u8bc1\u660e\u4e86\u81ea\u52a8\u505a\u5e02\u5546\u4e2d\u4e09\u660e\u6cbb\u653b\u51fb\u7684\u6700\u4f18\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u8d85\u8d8a\u73b0\u6709\u6280\u672f\u7684\u6b63\u786e\u6027\u4fdd\u8bc1\uff0c\u4e3aMEV\u5b89\u5168\u5206\u6790\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u673a\u68b0\u5316\u9a8c\u8bc1\u6846\u67b6\u3002"}}
{"id": "2510.14700", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14700", "abs": "https://arxiv.org/abs/2510.14700", "authors": ["Bin Liu", "Yanjie Zhao", "Guoai Xu", "Haoyu Wang"], "title": "LLM Agents for Automated Web Vulnerability Reproduction: Are We There Yet?", "comment": null, "summary": "Large language model (LLM) agents have demonstrated remarkable capabilities\nin software engineering and cybersecurity tasks, including code generation,\nvulnerability discovery, and automated testing. One critical but underexplored\napplication is automated web vulnerability reproduction, which transforms\nvulnerability reports into working exploits. Although recent advances suggest\npromising potential, challenges remain in applying LLM agents to real-world web\nvulnerability reproduction scenarios. In this paper, we present the first\ncomprehensive evaluation of state-of-the-art LLM agents for automated web\nvulnerability reproduction. We systematically assess 20 agents from software\nengineering, cybersecurity, and general domains across 16 dimensions, including\ntechnical capabilities, environment adaptability, and user experience factors,\non 3 representative web vulnerabilities. Based on the results, we select three\ntop-performing agents (OpenHands, SWE-agent, and CAI) for in-depth evaluation\non our benchmark dataset of 80 real-world CVEs spanning 7 vulnerability types\nand 6 web technologies. Our results reveal that while LLM agents achieve\nreasonable success on simple library-based vulnerabilities, they consistently\nfail on complex service-based vulnerabilities requiring multi-component\nenvironments. Complex environment configurations and authentication barriers\ncreate a gap where agents can execute exploit code but fail to trigger actual\nvulnerabilities. We observe high sensitivity to input guidance, with\nperformance degrading by over 33% under incomplete authentication information.\nOur findings highlight the significant gap between current LLM agent\ncapabilities and the demands of reliable automated vulnerability reproduction,\nemphasizing the need for advances in environmental adaptation and autonomous\nproblem-solving capabilities.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5bf9\u6700\u5148\u8fdb\u7684LLM\u4ee3\u7406\u5728\u81ea\u52a8\u5316Web\u6f0f\u6d1e\u590d\u73b0\u65b9\u9762\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\uff0c\u53d1\u73b0\u867d\u7136LLM\u4ee3\u7406\u5728\u7b80\u5355\u5e93\u6f0f\u6d1e\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9700\u8981\u591a\u7ec4\u4ef6\u73af\u5883\u7684\u590d\u6742\u670d\u52a1\u6f0f\u6d1e\u4e0a\u6301\u7eed\u5931\u8d25\u3002", "motivation": "LLM\u4ee3\u7406\u5728\u8f6f\u4ef6\u5de5\u7a0b\u548c\u7f51\u7edc\u5b89\u5168\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u81ea\u52a8\u5316Web\u6f0f\u6d1e\u590d\u73b0\u8fd9\u4e00\u5173\u952e\u5e94\u7528\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u7cfb\u7edf\u8bc4\u4f30LLM\u4ee3\u7406\u5728\u771f\u5b9eWeb\u6f0f\u6d1e\u590d\u73b0\u573a\u666f\u4e2d\u7684\u80fd\u529b\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30\u4e86\u6765\u81ea\u8f6f\u4ef6\u5de5\u7a0b\u3001\u7f51\u7edc\u5b89\u5168\u548c\u901a\u7528\u9886\u57df\u768420\u4e2aLLM\u4ee3\u7406\uff0c\u6db5\u76d616\u4e2a\u7ef4\u5ea6\uff0c\u5305\u62ec\u6280\u672f\u80fd\u529b\u3001\u73af\u5883\u9002\u5e94\u6027\u548c\u7528\u6237\u4f53\u9a8c\u56e0\u7d20\u3002\u57283\u4e2a\u4ee3\u8868\u6027Web\u6f0f\u6d1e\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u7136\u540e\u9009\u62e93\u4e2a\u8868\u73b0\u6700\u4f73\u7684\u4ee3\u7406\u5728\u5305\u542b80\u4e2a\u771f\u5b9eCVE\u7684\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u6df1\u5165\u8bc4\u4f30\u3002", "result": "LLM\u4ee3\u7406\u5728\u7b80\u5355\u5e93\u6f0f\u6d1e\u4e0a\u53d6\u5f97\u5408\u7406\u6210\u529f\u7387\uff0c\u4f46\u5728\u9700\u8981\u591a\u7ec4\u4ef6\u73af\u5883\u7684\u590d\u6742\u670d\u52a1\u6f0f\u6d1e\u4e0a\u6301\u7eed\u5931\u8d25\u3002\u590d\u6742\u73af\u5883\u914d\u7f6e\u548c\u8ba4\u8bc1\u969c\u788d\u5bfc\u81f4\u4ee3\u7406\u80fd\u6267\u884c\u5229\u7528\u4ee3\u7801\u4f46\u65e0\u6cd5\u89e6\u53d1\u5b9e\u9645\u6f0f\u6d1e\u3002\u5728\u8f93\u5165\u6307\u5bfc\u4e0d\u5b8c\u6574\u65f6\u6027\u80fd\u4e0b\u964d\u8d85\u8fc733%\u3002", "conclusion": "\u5f53\u524dLLM\u4ee3\u7406\u80fd\u529b\u4e0e\u53ef\u9760\u81ea\u52a8\u5316\u6f0f\u6d1e\u590d\u73b0\u9700\u6c42\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u9700\u8981\u5728\u73af\u5883\u9002\u5e94\u548c\u81ea\u4e3b\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u65b9\u9762\u53d6\u5f97\u8fdb\u5c55\u3002"}}
{"id": "2510.14176", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14176", "abs": "https://arxiv.org/abs/2510.14176", "authors": ["Roger Creus Castanyer", "Faisal Mohamed", "Pablo Samuel Castro", "Cyrus Neary", "Glen Berseth"], "title": "ARM-FM: Automated Reward Machines via Foundation Models for Compositional Reinforcement Learning", "comment": null, "summary": "Reinforcement learning (RL) algorithms are highly sensitive to reward\nfunction specification, which remains a central challenge limiting their broad\napplicability. We present ARM-FM: Automated Reward Machines via Foundation\nModels, a framework for automated, compositional reward design in RL that\nleverages the high-level reasoning capabilities of foundation models (FMs).\nReward machines (RMs) -- an automata-based formalism for reward specification\n-- are used as the mechanism for RL objective specification, and are\nautomatically constructed via the use of FMs. The structured formalism of RMs\nyields effective task decompositions, while the use of FMs enables objective\nspecifications in natural language. Concretely, we (i) use FMs to automatically\ngenerate RMs from natural language specifications; (ii) associate language\nembeddings with each RM automata-state to enable generalization across tasks;\nand (iii) provide empirical evidence of ARM-FM's effectiveness in a diverse\nsuite of challenging environments, including evidence of zero-shot\ngeneralization.", "AI": {"tldr": "ARM-FM\u662f\u4e00\u4e2a\u5229\u7528\u57fa\u7840\u6a21\u578b\u81ea\u52a8\u751f\u6210\u5956\u52b1\u673a\u5236\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u80fd\u591f\u4ece\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u4e2d\u81ea\u52a8\u6784\u5efa\u5956\u52b1\u673a\u5668\uff0c\u5b9e\u73b0\u4efb\u52a1\u5206\u89e3\u548c\u96f6\u6837\u672c\u6cdb\u5316\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5bf9\u5956\u52b1\u51fd\u6570\u8bbe\u8ba1\u9ad8\u5ea6\u654f\u611f\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5e7f\u6cdb\u5e94\u7528\u3002\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u624b\u52a8\u8bbe\u8ba1\u5956\u52b1\u51fd\u6570\uff0c\u8fc7\u7a0b\u590d\u6742\u4e14\u5bb9\u6613\u51fa\u9519\u3002", "method": "\u4f7f\u7528\u57fa\u7840\u6a21\u578b\u4ece\u81ea\u7136\u8bed\u8a00\u89c4\u8303\u81ea\u52a8\u751f\u6210\u5956\u52b1\u673a\u5668\uff1b\u4e3a\u6bcf\u4e2a\u5956\u52b1\u673a\u5668\u72b6\u6001\u5173\u8054\u8bed\u8a00\u5d4c\u5165\u4ee5\u5b9e\u73b0\u8de8\u4efb\u52a1\u6cdb\u5316\uff1b\u5229\u7528\u5956\u52b1\u673a\u5668\u7684\u7ed3\u6784\u5316\u5f62\u5f0f\u5316\u5b9e\u73b0\u6709\u6548\u4efb\u52a1\u5206\u89e3\u3002", "result": "\u5728\u591a\u4e2a\u6311\u6218\u6027\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86ARM-FM\u7684\u6709\u6548\u6027\uff0c\u5305\u62ec\u5c55\u793a\u4e86\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "ARM-FM\u901a\u8fc7\u7ed3\u5408\u57fa\u7840\u6a21\u578b\u548c\u5956\u52b1\u673a\u5668\uff0c\u4e3a\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u7684\u3001\u7ec4\u5408\u5f0f\u7684\u5956\u52b1\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5956\u52b1\u51fd\u6570\u8bbe\u8ba1\u7684\u590d\u6742\u6027\u3002"}}
{"id": "2510.14522", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14522", "abs": "https://arxiv.org/abs/2510.14522", "authors": ["Evangelos Lamprou", "Julian Dai", "Grigoris Ntousakis", "Martin C. Rinard", "Nikos Vasilakis"], "title": "Lexo: Eliminating Stealthy Supply-Chain Attacks via LLM-Assisted Program Regeneration", "comment": null, "summary": "Software supply-chain attacks are an important and ongoing concern in the\nopen source software ecosystem. These attacks maintain the standard\nfunctionality that a component implements, but additionally hide malicious\nfunctionality activated only when the component reaches its target environment.\nLexo addresses such stealthy attacks by automatically learning and regenerating\nvulnerability-free versions of potentially malicious components. Lexo first\ngenerates a set of input-output pairs to model a component's full observable\nbehavior, which it then uses to synthesize a new version of the original\ncomponent. The new component implements the original functionality but avoids\nstealthy malicious behavior. Throughout this regeneration process, Lexo\nconsults several distinct instances of Large Language Models (LLMs), uses\ncorrectness and coverage metrics to shepherd these instances, and guardrails\ntheir results. Our evaluation on 100+ real-world packages, including high\nprofile stealthy supply-chain attacks, indicates that Lexo scales across\nmultiple domains, regenerates code efficiently (<100s on average), maintains\ncompatibility, and succeeds in eliminating malicious code in several real-world\nsupply-chain-attacks, even in cases when a state-of-the-art LLM fails to\neliminate malicious code when prompted to do so.", "AI": {"tldr": "Lexo\u662f\u4e00\u4e2a\u81ea\u52a8\u5b66\u4e60\u548c\u91cd\u65b0\u751f\u6210\u65e0\u6f0f\u6d1e\u7248\u672c\u7684\u5f00\u6e90\u8f6f\u4ef6\u7ec4\u4ef6\u7cfb\u7edf\uff0c\u65e8\u5728\u9632\u5fa1\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u653b\u51fb\u3002\u5b83\u901a\u8fc7\u751f\u6210\u8f93\u5165-\u8f93\u51fa\u5bf9\u6765\u5efa\u6a21\u7ec4\u4ef6\u884c\u4e3a\uff0c\u7136\u540e\u5408\u6210\u65b0\u7248\u672c\u7ec4\u4ef6\uff0c\u4fdd\u6301\u539f\u59cb\u529f\u80fd\u4f46\u6d88\u9664\u6076\u610f\u4ee3\u7801\u3002", "motivation": "\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u653b\u51fb\u662f\u5f00\u6e90\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u91cd\u8981\u6301\u7eed\u5a01\u80c1\uff0c\u8fd9\u4e9b\u653b\u51fb\u5728\u7ec4\u4ef6\u5230\u8fbe\u76ee\u6807\u73af\u5883\u65f6\u624d\u6fc0\u6d3b\u6076\u610f\u529f\u80fd\uff0c\u5177\u6709\u9690\u853d\u6027\u3002", "method": "Lexo\u9996\u5148\u751f\u6210\u8f93\u5165-\u8f93\u51fa\u5bf9\u6765\u5efa\u6a21\u7ec4\u4ef6\u7684\u5b8c\u6574\u53ef\u89c2\u5bdf\u884c\u4e3a\uff0c\u7136\u540e\u4f7f\u7528\u8fd9\u4e9b\u6570\u636e\u5408\u6210\u65b0\u7248\u672c\u7ec4\u4ef6\u3002\u8fc7\u7a0b\u4e2d\u54a8\u8be2\u591a\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b9e\u4f8b\uff0c\u4f7f\u7528\u6b63\u786e\u6027\u548c\u8986\u76d6\u7387\u6307\u6807\u6765\u6307\u5bfc\u548c\u7ea6\u675f\u7ed3\u679c\u3002", "result": "\u5728100\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u8f6f\u4ef6\u5305\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cLexo\u80fd\u591f\u8de8\u591a\u4e2a\u9886\u57df\u6269\u5c55\uff0c\u5e73\u5747\u5728100\u79d2\u5185\u9ad8\u6548\u91cd\u65b0\u751f\u6210\u4ee3\u7801\uff0c\u4fdd\u6301\u517c\u5bb9\u6027\uff0c\u5e76\u6210\u529f\u6d88\u9664\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u4f9b\u5e94\u94fe\u653b\u51fb\u4e2d\u7684\u6076\u610f\u4ee3\u7801\uff0c\u5373\u4f7f\u5728\u6700\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u76f4\u63a5\u63d0\u793a\u6d88\u9664\u6076\u610f\u4ee3\u7801\u5931\u8d25\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u6210\u529f\u3002", "conclusion": "Lexo\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u9632\u5fa1\u9690\u853d\u7684\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u653b\u51fb\uff0c\u901a\u8fc7\u81ea\u52a8\u91cd\u65b0\u751f\u6210\u65e0\u6076\u610f\u4ee3\u7801\u7684\u7ec4\u4ef6\u7248\u672c\uff0c\u5728\u4fdd\u6301\u529f\u80fd\u517c\u5bb9\u6027\u7684\u540c\u65f6\u6d88\u9664\u5b89\u5168\u5a01\u80c1\u3002"}}
{"id": "2510.14778", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14778", "abs": "https://arxiv.org/abs/2510.14778", "authors": ["Maor Reuben", "Ido Mendel", "Or Feldman", "Moshe Kravchik", "Mordehai Guri", "Rami Puzis"], "title": "Leveraging Code Cohesion Analysis to Identify Source Code Supply Chain Attacks", "comment": null, "summary": "Supply chain attacks significantly threaten software security with malicious\ncode injections within legitimate projects. Such attacks are very rare but may\nhave a devastating impact. Detecting spurious code injections using automated\ntools is further complicated as it often requires deciphering the intention of\nboth the inserted code and its context. In this study, we propose an\nunsupervised approach for highlighting spurious code injections by quantifying\ncohesion disruptions in the source code. Using a name-prediction-based cohesion\n(NPC) metric, we analyze how function cohesion changes when malicious code is\nintroduced compared to natural cohesion fluctuations. An analysis of 54,707\nfunctions over 369 open-source C++ repositories reveals that code injection\nreduces cohesion and shifts naming patterns toward shorter, less descriptive\nnames compared to genuine function updates. Considering the sporadic nature of\nreal supply-chain attacks, we evaluate the proposed method with extreme\ntest-set imbalance and show that monitoring high-cohesion functions with NPC\ncan effectively detect functions with injected code, achieving a Precision@100\nof 36.41% at a 1:1,000 ratio and 12.47% at 1:10,000. These results suggest that\nautomated cohesion measurements, in general, and name-prediction-based\ncohesion, in particular, may help identify supply chain attacks, improving\nsource code integrity.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u540d\u79f0\u9884\u6d4b\u7684\u5185\u805a\u6027\uff08NPC\uff09\u5ea6\u91cf\u7684\u65e0\u76d1\u7763\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cf\u5316\u6e90\u4ee3\u7801\u4e2d\u7684\u5185\u805a\u6027\u7834\u574f\u6765\u68c0\u6d4b\u6076\u610f\u4ee3\u7801\u6ce8\u5165\u3002", "motivation": "\u4f9b\u5e94\u94fe\u653b\u51fb\u901a\u8fc7\u5411\u5408\u6cd5\u9879\u76ee\u4e2d\u6ce8\u5165\u6076\u610f\u4ee3\u7801\u4e25\u91cd\u5a01\u80c1\u8f6f\u4ef6\u5b89\u5168\uff0c\u8fd9\u7c7b\u653b\u51fb\u867d\u7136\u7f55\u89c1\u4f46\u7834\u574f\u6027\u6781\u5927\uff0c\u9700\u8981\u81ea\u52a8\u5316\u5de5\u5177\u6765\u68c0\u6d4b\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u540d\u79f0\u9884\u6d4b\u7684\u5185\u805a\u6027\uff08NPC\uff09\u5ea6\u91cf\uff0c\u5206\u6790\u6076\u610f\u4ee3\u7801\u5f15\u5165\u65f6\u51fd\u6570\u5185\u805a\u6027\u7684\u53d8\u5316\uff0c\u5e76\u4e0e\u81ea\u7136\u5185\u805a\u6027\u6ce2\u52a8\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5bf9369\u4e2a\u5f00\u6e90C++\u4ed3\u5e93\u768454,707\u4e2a\u51fd\u6570\u5206\u6790\u663e\u793a\uff0c\u4ee3\u7801\u6ce8\u5165\u4f1a\u964d\u4f4e\u5185\u805a\u6027\u5e76\u4f7f\u547d\u540d\u6a21\u5f0f\u8d8b\u5411\u66f4\u77ed\u3001\u63cf\u8ff0\u6027\u66f4\u5dee\u7684\u540d\u79f0\u3002\u5728\u6781\u7aef\u4e0d\u5e73\u8861\u6d4b\u8bd5\u96c6\u4e0b\uff0cNPC\u65b9\u6cd5\u57281:1,000\u6bd4\u4f8b\u4e0b\u8fbe\u523036.41%\u7684Precision@100\uff0c\u57281:10,000\u6bd4\u4f8b\u4e0b\u8fbe\u523012.47%\u3002", "conclusion": "\u81ea\u52a8\u5316\u5185\u805a\u6027\u6d4b\u91cf\uff0c\u7279\u522b\u662f\u57fa\u4e8e\u540d\u79f0\u9884\u6d4b\u7684\u5185\u805a\u6027\u5ea6\u91cf\uff0c\u6709\u52a9\u4e8e\u8bc6\u522b\u4f9b\u5e94\u94fe\u653b\u51fb\uff0c\u63d0\u9ad8\u6e90\u4ee3\u7801\u5b8c\u6574\u6027\u3002"}}
{"id": "2510.14194", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14194", "abs": "https://arxiv.org/abs/2510.14194", "authors": ["G\u00f6ktu\u011f Bender", "Samer Faraj", "Anand Bhardwaj"], "title": "Implementation of AI in Precision Medicine", "comment": "Accepted to SMASH 2025", "summary": "Artificial intelligence (AI) has become increasingly central to precision\nmedicine by enabling the integration and interpretation of multimodal data, yet\nimplementation in clinical settings remains limited. This paper provides a\nscoping review of literature from 2019-2024 on the implementation of AI in\nprecision medicine, identifying key barriers and enablers across data quality,\nclinical reliability, workflow integration, and governance. Through an\necosystem-based framework, we highlight the interdependent relationships\nshaping real-world translation and propose future directions to support\ntrustworthy and sustainable implementation.", "AI": {"tldr": "\u672c\u6587\u5bf92019-2024\u5e74\u7cbe\u51c6\u533b\u5b66\u4e2dAI\u5b9e\u65bd\u7684\u6587\u732e\u8fdb\u884c\u8303\u56f4\u7efc\u8ff0\uff0c\u8bc6\u522b\u4e86\u6570\u636e\u8d28\u91cf\u3001\u4e34\u5e8a\u53ef\u9760\u6027\u3001\u5de5\u4f5c\u6d41\u7a0b\u6574\u5408\u548c\u6cbb\u7406\u7b49\u65b9\u9762\u7684\u5173\u952e\u969c\u788d\u4e0e\u4fc3\u8fdb\u56e0\u7d20\uff0c\u63d0\u51fa\u4e86\u652f\u6301\u53ef\u4fe1\u548c\u53ef\u6301\u7eed\u5b9e\u65bd\u7684\u672a\u6765\u65b9\u5411\u3002", "motivation": "AI\u5728\u7cbe\u51c6\u533b\u5b66\u4e2d\u65e5\u76ca\u91cd\u8981\uff0c\u80fd\u591f\u6574\u5408\u548c\u89e3\u91ca\u591a\u6a21\u6001\u6570\u636e\uff0c\u4f46\u5728\u4e34\u5e8a\u73af\u5883\u4e2d\u7684\u5b9e\u65bd\u4ecd\u7136\u6709\u9650\uff0c\u9700\u8981\u7cfb\u7edf\u5206\u6790\u5b9e\u65bd\u969c\u788d\u548c\u4fc3\u8fdb\u56e0\u7d20\u3002", "method": "\u91c7\u7528\u751f\u6001\u7cfb\u7edf\u6846\u67b6\u8fdb\u884c\u8303\u56f4\u7efc\u8ff0\uff0c\u5206\u67902019-2024\u5e74\u76f8\u5173\u6587\u732e\uff0c\u8bc6\u522b\u5173\u952e\u5b9e\u65bd\u56e0\u7d20\u3002", "result": "\u8bc6\u522b\u4e86\u6570\u636e\u8d28\u91cf\u3001\u4e34\u5e8a\u53ef\u9760\u6027\u3001\u5de5\u4f5c\u6d41\u7a0b\u6574\u5408\u548c\u6cbb\u7406\u56db\u4e2a\u7ef4\u5ea6\u7684\u5173\u952e\u969c\u788d\u548c\u4fc3\u8fdb\u56e0\u7d20\uff0c\u5f3a\u8c03\u4e86\u8fd9\u4e9b\u56e0\u7d20\u4e4b\u95f4\u7684\u76f8\u4e92\u4f9d\u8d56\u5173\u7cfb\u3002", "conclusion": "\u9700\u8981\u901a\u8fc7\u751f\u6001\u7cfb\u7edf\u89c6\u89d2\u7406\u89e3AI\u5728\u7cbe\u51c6\u533b\u5b66\u4e2d\u7684\u5b9e\u65bd\uff0c\u63d0\u51fa\u652f\u6301\u53ef\u4fe1\u548c\u53ef\u6301\u7eed\u5b9e\u65bd\u7684\u672a\u6765\u65b9\u5411\u3002"}}
{"id": "2510.14589", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14589", "abs": "https://arxiv.org/abs/2510.14589", "authors": ["Vaishnavi Sundararajan", "Rithwik"], "title": "Symbolic verification of Apple's Find My location-tracking protocol", "comment": null, "summary": "Tracking devices, while designed to help users find their belongings in case\nof loss/theft, bring in new questions about privacy and surveillance of not\njust their own users, but in the case of crowd-sourced location tracking, even\nthat of others even orthogonally associated with these platforms. Apple's Find\nMy is perhaps the most ubiquitous such system which can even locate devices\nwhich do not possess any cellular support or GPS, running on millions of\ndevices worldwide. Apple claims that this system is private and secure, but the\ncode is proprietary, and such claims have to be taken on faith. It is well\nknown that even with perfect cryptographic guarantees, logical flaws might\ncreep into protocols, and allow undesirable attacks. In this paper, we present\na symbolic model of the Find My protocol, as well as a precise formal\nspecification of desirable properties, and provide automated, machine-checkable\nproofs of these properties in the Tamarin prover.", "AI": {"tldr": "\u672c\u6587\u5bf9\u82f9\u679cFind My\u8ffd\u8e2a\u7cfb\u7edf\u8fdb\u884c\u5f62\u5f0f\u5316\u5b89\u5168\u5206\u6790\uff0c\u901a\u8fc7\u7b26\u53f7\u5efa\u6a21\u548c\u81ea\u52a8\u9a8c\u8bc1\u8bc1\u660e\u5176\u9690\u79c1\u4fdd\u62a4\u5c5e\u6027\u3002", "motivation": "\u82f9\u679cFind My\u7cfb\u7edf\u867d\u7136\u58f0\u79f0\u9690\u79c1\u5b89\u5168\uff0c\u4f46\u4ee3\u7801\u95ed\u6e90\u4e14\u53ef\u80fd\u5b58\u5728\u903b\u8f91\u6f0f\u6d1e\uff0c\u9700\u8981\u72ec\u7acb\u9a8c\u8bc1\u5176\u5b89\u5168\u58f0\u660e\u3002", "method": "\u4f7f\u7528\u7b26\u53f7\u5efa\u6a21\u65b9\u6cd5\u5bf9Find My\u534f\u8bae\u8fdb\u884c\u5efa\u6a21\uff0c\u5728Tamarin\u9a8c\u8bc1\u5668\u4e2d\u6784\u5efa\u7cbe\u786e\u7684\u5f62\u5f0f\u5316\u89c4\u8303\u5e76\u8fdb\u884c\u81ea\u52a8\u5316\u673a\u5668\u9a8c\u8bc1\u3002", "result": "\u901a\u8fc7\u81ea\u52a8\u5316\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u673a\u5668\u53ef\u68c0\u67e5\u7684\u5b89\u5168\u6027\u8bc1\u660e\uff0c\u786e\u8ba4\u4e86Find My\u7cfb\u7edf\u7684\u9690\u79c1\u4fdd\u62a4\u5c5e\u6027\u3002", "conclusion": "\u5f62\u5f0f\u5316\u9a8c\u8bc1\u8bc1\u5b9e\u4e86Find My\u7cfb\u7edf\u7684\u9690\u79c1\u5b89\u5168\u58f0\u660e\uff0c\u4e3a\u95ed\u6e90\u7cfb\u7edf\u7684\u5b89\u5168\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u9760\u65b9\u6cd5\u3002"}}
{"id": "2510.14928", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14928", "abs": "https://arxiv.org/abs/2510.14928", "authors": ["Eric Christopher", "Kevin Crossan", "Wolff Dobson", "Chris Kennelly", "Drew Lewis", "Kun Lin", "Martin Maas", "Parthasarathy Ranganathan", "Emma Rapati", "Brian Yang"], "title": "Instruction Set Migration at Warehouse Scale", "comment": null, "summary": "Migrating codebases from one instruction set architecture (ISA) to another is\na major engineering challenge. A recent example is the adoption of Arm (in\naddition to x86) across the major Cloud hyperscalers. Yet, this problem has\nseen limited attention by the academic community. Most work has focused on\nstatic and dynamic binary translation, and the traditional conventional wisdom\nhas been that this is the primary challenge.\n  In this paper, we show that this is no longer the case. Modern ISA migrations\ncan often build on a robust open-source ecosystem, making it possible to\nrecompile all relevant software from scratch. This introduces a new and\nmultifaceted set of challenges, which are different from binary translation.\n  By analyzing a large-scale migration from x86 to Arm at Google, spanning\nalmost 40,000 code commits, we derive a taxonomy of tasks involved in ISA\nmigration. We show how Google automated many of the steps involved, and\ndemonstrate how AI can play a major role in automatically addressing these\ntasks. We identify tasks that remain challenging and highlight research\nchallenges that warrant further attention.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u4ecex86\u5230Arm\u67b6\u6784\u7684\u5927\u89c4\u6a21\u4ee3\u7801\u8fc1\u79fb\u6311\u6218\uff0c\u6307\u51fa\u73b0\u4ee3ISA\u8fc1\u79fb\u4e3b\u8981\u4f9d\u8d56\u91cd\u65b0\u7f16\u8bd1\u800c\u975e\u4e8c\u8fdb\u5236\u7ffb\u8bd1\uff0c\u5e76\u5c55\u793a\u4e86Google\u5982\u4f55\u81ea\u52a8\u5316\u8fd9\u4e9b\u8fc7\u7a0b\u4ee5\u53caAI\u5728\u5176\u4e2d\u7684\u4f5c\u7528\u3002", "motivation": "\u4f20\u7edf\u89c2\u70b9\u8ba4\u4e3aISA\u8fc1\u79fb\u7684\u4e3b\u8981\u6311\u6218\u662f\u4e8c\u8fdb\u5236\u7ffb\u8bd1\uff0c\u4f46\u73b0\u4ee3\u5f00\u6e90\u751f\u6001\u7cfb\u7edf\u4f7f\u5f97\u91cd\u65b0\u7f16\u8bd1\u6210\u4e3a\u53ef\u80fd\uff0c\u8fd9\u5e26\u6765\u4e86\u65b0\u7684\u591a\u65b9\u9762\u6311\u6218\u3002", "method": "\u901a\u8fc7\u5206\u6790Google\u4ecex86\u5230Arm\u7684\u5927\u89c4\u6a21\u8fc1\u79fb\uff08\u6d89\u53ca\u8fd140,000\u4e2a\u4ee3\u7801\u63d0\u4ea4\uff09\uff0c\u63a8\u5bfc\u51faISA\u8fc1\u79fb\u7684\u4efb\u52a1\u5206\u7c7b\uff0c\u5e76\u5c55\u793a\u4e86\u81ea\u52a8\u5316\u548cAI\u7684\u5e94\u7528\u3002", "result": "\u8bc6\u522b\u4e86ISA\u8fc1\u79fb\u4e2d\u7684\u5404\u7c7b\u4efb\u52a1\uff0c\u5c55\u793a\u4e86Google\u5982\u4f55\u81ea\u52a8\u5316\u8fd9\u4e9b\u6b65\u9aa4\uff0c\u8bc1\u660e\u4e86AI\u5728\u81ea\u52a8\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u4e2d\u7684\u91cd\u8981\u4f5c\u7528\u3002", "conclusion": "\u73b0\u4ee3ISA\u8fc1\u79fb\u9762\u4e34\u4e0e\u4e8c\u8fdb\u5236\u7ffb\u8bd1\u4e0d\u540c\u7684\u65b0\u6311\u6218\uff0c\u81ea\u52a8\u5316\u5de5\u5177\u548cAI\u6280\u672f\u80fd\u663e\u8457\u63d0\u5347\u8fc1\u79fb\u6548\u7387\uff0c\u4f46\u4ecd\u6709\u4e00\u4e9b\u6311\u6218\u6027\u95ee\u9898\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2510.14207", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14207", "abs": "https://arxiv.org/abs/2510.14207", "authors": ["Trilok Padhi", "Pinxian Lu", "Abdulkadir Erol", "Tanmay Sutar", "Gauri Sharma", "Mina Sonmez", "Munmun De Choudhury", "Ugur Kursuncu"], "title": "Echoes of Human Malice in Agents: Benchmarking LLMs for Multi-Turn Online Harassment Attacks", "comment": "13 pages, 4 figures", "summary": "Large Language Model (LLM) agents are powering a growing share of interactive\nweb applications, yet remain vulnerable to misuse and harm. Prior jailbreak\nresearch has largely focused on single-turn prompts, whereas real harassment\noften unfolds over multi-turn interactions. In this work, we present the Online\nHarassment Agentic Benchmark consisting of: (i) a synthetic multi-turn\nharassment conversation dataset, (ii) a multi-agent (e.g., harasser, victim)\nsimulation informed by repeated game theory, (iii) three jailbreak methods\nattacking agents across memory, planning, and fine-tuning, and (iv) a\nmixed-methods evaluation framework. We utilize two prominent LLMs,\nLLaMA-3.1-8B-Instruct (open-source) and Gemini-2.0-flash (closed-source). Our\nresults show that jailbreak tuning makes harassment nearly guaranteed with an\nattack success rate of 95.78--96.89% vs. 57.25--64.19% without tuning in Llama,\nand 99.33% vs. 98.46% without tuning in Gemini, while sharply reducing refusal\nrate to 1-2% in both models. The most prevalent toxic behaviors are Insult with\n84.9--87.8% vs. 44.2--50.8% without tuning, and Flaming with 81.2--85.1% vs.\n31.5--38.8% without tuning, indicating weaker guardrails compared to sensitive\ncategories such as sexual or racial harassment. Qualitative evaluation further\nreveals that attacked agents reproduce human-like aggression profiles, such as\nMachiavellian/psychopathic patterns under planning, and narcissistic tendencies\nwith memory. Counterintuitively, closed-source and open-source models exhibit\ndistinct escalation trajectories across turns, with closed-source models\nshowing significant vulnerability. Overall, our findings show that multi-turn\nand theory-grounded attacks not only succeed at high rates but also mimic\nhuman-like harassment dynamics, motivating the development of robust safety\nguardrails to ultimately keep online platforms safe and responsible.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5728\u7ebf\u9a9a\u6270\u4ee3\u7406\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u591a\u8f6e\u9a9a\u6270\u5bf9\u8bdd\u6570\u636e\u96c6\u3001\u57fa\u4e8e\u91cd\u590d\u535a\u5f08\u8bba\u7684\u591a\u4ee3\u7406\u6a21\u62df\u3001\u4e09\u79cd\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\u4ee5\u53ca\u6df7\u5408\u8bc4\u4f30\u6846\u67b6\u3002\u7814\u7a76\u53d1\u73b0\u8d8a\u72f1\u8c03\u4f18\u4f7f\u9a9a\u6270\u6210\u529f\u7387\u5927\u5e45\u63d0\u5347\uff0c\u95ed\u6e90\u548c\u5f00\u6e90\u6a21\u578b\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u5347\u7ea7\u8f68\u8ff9\u3002", "motivation": "\u73b0\u6709\u8d8a\u72f1\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5355\u8f6e\u63d0\u793a\uff0c\u800c\u771f\u5b9e\u9a9a\u6270\u901a\u5e38\u53d1\u751f\u5728\u591a\u8f6e\u4ea4\u4e92\u4e2d\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u6a21\u62df\u771f\u5b9e\u591a\u8f6e\u9a9a\u6270\u52a8\u6001\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b\u5408\u6210\u591a\u8f6e\u9a9a\u6270\u5bf9\u8bdd\u6570\u636e\u96c6\u3001\u57fa\u4e8e\u91cd\u590d\u535a\u5f08\u8bba\u7684\u591a\u4ee3\u7406\u6a21\u62df\u3001\u4e09\u79cd\u9488\u5bf9\u8bb0\u5fc6\u3001\u89c4\u5212\u548c\u5fae\u8c03\u7684\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\uff0c\u4ee5\u53ca\u6df7\u5408\u8bc4\u4f30\u6846\u67b6\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002\u4f7f\u7528LLaMA-3.1-8B-Instruct\u548cGemini-2.0-flash\u4e24\u79cd\u6a21\u578b\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u8d8a\u72f1\u8c03\u4f18\u4f7f\u9a9a\u6270\u6210\u529f\u7387\u4ece57.25-64.19%\u63d0\u5347\u81f395.78-96.89%\uff08Llama\uff09\uff0c\u4ece98.46%\u63d0\u5347\u81f399.33%\uff08Gemini\uff09\u3002\u62d2\u7edd\u7387\u964d\u81f31-2%\u3002\u6700\u5e38\u89c1\u7684\u6bd2\u6027\u884c\u4e3a\u662f\u4fae\u8fb1\uff0884.9-87.8% vs 44.2-50.8%\uff09\u548c\u8c29\u9a82\uff0881.2-85.1% vs 31.5-38.8%\uff09\u3002\u95ed\u6e90\u6a21\u578b\u8868\u73b0\u51fa\u663e\u8457\u8106\u5f31\u6027\u3002", "conclusion": "\u591a\u8f6e\u548c\u7406\u8bba\u57fa\u7840\u7684\u653b\u51fb\u4e0d\u4ec5\u6210\u529f\u7387\u9ad8\uff0c\u8fd8\u80fd\u6a21\u62df\u4eba\u7c7b\u9a9a\u6270\u52a8\u6001\uff0c\u5f3a\u8c03\u9700\u8981\u5f00\u53d1\u5f3a\u5927\u7684\u5b89\u5168\u9632\u62a4\u63aa\u65bd\u6765\u4fdd\u62a4\u5728\u7ebf\u5e73\u53f0\u7684\u5b89\u5168\u548c\u8d1f\u8d23\u4efb\u6027\u3002"}}
{"id": "2510.14638", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14638", "abs": "https://arxiv.org/abs/2510.14638", "authors": ["Silvia Lucia Sanna", "Leonardo Regano", "Davide Maiorca", "Giorgio Giacinto"], "title": "Improving Cybercrime Detection and Digital Forensics Investigations with Artificial Intelligence", "comment": null, "summary": "According to a recent EUROPOL report, cybercrime is still recurrent in\nEurope, and different activities and countermeasures must be taken to limit,\nprevent, detect, analyze, and fight it. Cybercrime must be prevented with\nspecific measures, tools, and techniques, for example through automated network\nand malware analysis. Countermeasures against cybercrime can also be improved\nwith proper \\df analysis in order to extract data from digital devices trying\nto retrieve information on the cybercriminals. Indeed, results obtained through\na proper \\df analysis can be leveraged to train cybercrime detection systems to\nprevent the success of similar crimes. Nowadays, some systems have started to\nadopt Artificial Intelligence (AI) algorithms for cyberattack detection and \\df\nanalysis improvement. However, AI can be better applied as an additional\ninstrument in these systems to improve the detection and in the \\df analysis.\nFor this reason, we highlight how cybercrime analysis and \\df procedures can\ntake advantage of AI. On the other hand, cybercriminals can use these systems\nto improve their skills, bypass automatic detection, and develop advanced\nattack techniques. The case study we presented highlights how it is possible to\nintegrate the use of the three popular chatbots {\\tt Gemini}, {\\tt Copilot} and\n{\\tt chatGPT} to develop a Python code to encode and decoded images with\nsteganographic technique, even though their presence is not an indicator of\ncrime, attack or maliciousness but used by a cybercriminal as anti-forensics\ntechnique.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u5229\u7528\u4eba\u5de5\u667a\u80fd\u6539\u8fdb\u7f51\u7edc\u72af\u7f6a\u5206\u6790\u548c\u6570\u5b57\u53d6\u8bc1\uff0c\u540c\u65f6\u6307\u51fa\u7f51\u7edc\u72af\u7f6a\u5206\u5b50\u4e5f\u53ef\u80fd\u5229\u7528AI\u6280\u672f\u6765\u589e\u5f3a\u653b\u51fb\u80fd\u529b\u3002\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u4f7f\u7528\u6d41\u884c\u804a\u5929\u673a\u5668\u4eba\u5f00\u53d1\u9690\u5199\u672f\u4ee3\u7801\u7684\u53ef\u80fd\u6027\u3002", "motivation": "\u6b27\u6d32\u7f51\u7edc\u72af\u7f6a\u9891\u53d1\uff0c\u9700\u8981\u6539\u8fdb\u73b0\u6709\u7684\u9884\u9632\u3001\u68c0\u6d4b\u548c\u5206\u6790\u63aa\u65bd\u3002AI\u6280\u672f\u6709\u6f5c\u529b\u63d0\u5347\u7f51\u7edc\u72af\u7f6a\u68c0\u6d4b\u548c\u6570\u5b57\u53d6\u8bc1\u5206\u6790\u7684\u6548\u7387\uff0c\u4f46\u540c\u65f6\u4e5f\u53ef\u80fd\u88ab\u72af\u7f6a\u5206\u5b50\u5229\u7528\u3002", "method": "\u63d0\u51fa\u5c06AI\u4f5c\u4e3a\u8f85\u52a9\u5de5\u5177\u96c6\u6210\u5230\u7f51\u7edc\u72af\u7f6a\u68c0\u6d4b\u548c\u6570\u5b57\u53d6\u8bc1\u7cfb\u7edf\u4e2d\u3002\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793a\u4e86\u4f7f\u7528Gemini\u3001Copilot\u548cchatGPT\u7b49\u804a\u5929\u673a\u5668\u4eba\u5f00\u53d1Python\u9690\u5199\u672f\u4ee3\u7801\u7684\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u8868\u660eAI\u53ef\u4ee5\u6709\u6548\u6539\u8fdb\u7f51\u7edc\u72af\u7f6a\u5206\u6790\u548c\u6570\u5b57\u53d6\u8bc1\u7a0b\u5e8f\uff0c\u4f46\u540c\u65f6\u4e5f\u5b58\u5728\u88ab\u7f51\u7edc\u72af\u7f6a\u5206\u5b50\u5229\u7528\u7684\u98ce\u9669\u3002\u6848\u4f8b\u7814\u7a76\u6210\u529f\u6f14\u793a\u4e86\u5229\u7528AI\u5de5\u5177\u5f00\u53d1\u9690\u5199\u672f\u6280\u672f\u3002", "conclusion": "AI\u5728\u7f51\u7edc\u72af\u7f6a\u5206\u6790\u548c\u6570\u5b57\u53d6\u8bc1\u4e2d\u5177\u6709\u53cc\u91cd\u4f5c\u7528\uff1a\u4e00\u65b9\u9762\u53ef\u4ee5\u63d0\u5347\u9632\u5fa1\u80fd\u529b\uff0c\u53e6\u4e00\u65b9\u9762\u4e5f\u53ef\u80fd\u88ab\u72af\u7f6a\u5206\u5b50\u7528\u4e8e\u589e\u5f3a\u653b\u51fb\u6280\u672f\u548c\u53cd\u53d6\u8bc1\u624b\u6bb5\u3002\u9700\u8981\u5e73\u8861AI\u6280\u672f\u7684\u5e94\u7528\u4e0e\u5b89\u5168\u98ce\u9669\u3002"}}
{"id": "2510.14240", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14240", "abs": "https://arxiv.org/abs/2510.14240", "authors": ["Jiayu Wang", "Yifei Ming", "Riya Dulepet", "Qinglin Chen", "Austin Xu", "Zixuan Ke", "Frederic Sala", "Aws Albarghouthi", "Caiming Xiong", "Shafiq Joty"], "title": "LiveResearchBench: A Live Benchmark for User-Centric Deep Research in the Wild", "comment": null, "summary": "Deep research -- producing comprehensive, citation-grounded reports by\nsearching and synthesizing information from hundreds of live web sources --\nmarks an important frontier for agentic systems. To rigorously evaluate this\nability, four principles are essential: tasks should be (1) user-centric,\nreflecting realistic information needs, (2) dynamic, requiring up-to-date\ninformation beyond parametric knowledge, (3) unambiguous, ensuring consistent\ninterpretation across users, and (4) multi-faceted and search-intensive,\nrequiring search over numerous web sources and in-depth analysis. Existing\nbenchmarks fall short of these principles, often focusing on narrow domains or\nposing ambiguous questions that hinder fair comparison. Guided by these\nprinciples, we introduce LiveResearchBench, a benchmark of 100 expert-curated\ntasks spanning daily life, enterprise, and academia, each requiring extensive,\ndynamic, real-time web search and synthesis. Built with over 1,500 hours of\nhuman labor, LiveResearchBench provides a rigorous basis for systematic\nevaluation. To evaluate citation-grounded long-form reports, we introduce\nDeepEval, a comprehensive suite covering both content- and report-level\nquality, including coverage, presentation, citation accuracy and association,\nconsistency and depth of analysis. DeepEval integrates four complementary\nevaluation protocols, each designed to ensure stable assessment and high\nagreement with human judgments. Using LiveResearchBench and DeepEval, we\nconduct a comprehensive evaluation of 17 frontier deep research systems,\nincluding single-agent web search, single-agent deep research, and multi-agent\nsystems. Our analysis reveals current strengths, recurring failure modes, and\nkey system components needed to advance reliable, insightful deep research.", "AI": {"tldr": "\u63d0\u51fa\u4e86LiveResearchBench\u57fa\u51c6\u548cDeepEval\u8bc4\u4f30\u5957\u4ef6\uff0c\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u5728\u52a8\u6001\u7f51\u7edc\u641c\u7d22\u548c\u7efc\u5408\u4fe1\u606f\u65b9\u9762\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u5728\u8bc4\u4f30\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u65f6\u5b58\u5728\u4e0d\u8db3\uff0c\u5f80\u5f80\u805a\u7126\u4e8e\u72ed\u7a84\u9886\u57df\u6216\u63d0\u51fa\u6a21\u7cca\u95ee\u9898\uff0c\u65e0\u6cd5\u516c\u5e73\u6bd4\u8f83\u3002\u9700\u8981\u9075\u5faa\u7528\u6237\u4e2d\u5fc3\u3001\u52a8\u6001\u6027\u3001\u660e\u786e\u6027\u548c\u591a\u9762\u6027\u641c\u7d22\u56db\u4e2a\u539f\u5219\u6765\u6784\u5efa\u66f4\u4e25\u8c28\u7684\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "\u5f00\u53d1\u4e86\u5305\u542b100\u4e2a\u4e13\u5bb6\u7b56\u5212\u4efb\u52a1\u7684LiveResearchBench\u57fa\u51c6\uff0c\u6db5\u76d6\u65e5\u5e38\u751f\u6d3b\u3001\u4f01\u4e1a\u548c\u5b66\u672f\u9886\u57df\uff0c\u6bcf\u4e2a\u4efb\u52a1\u90fd\u9700\u8981\u5e7f\u6cdb\u7684\u52a8\u6001\u5b9e\u65f6\u7f51\u7edc\u641c\u7d22\u548c\u7efc\u5408\u3002\u540c\u65f6\u63d0\u51fa\u4e86DeepEval\u8bc4\u4f30\u5957\u4ef6\uff0c\u5305\u542b\u5185\u5bb9\u548c\u62a5\u544a\u5c42\u9762\u7684\u8d28\u91cf\u8bc4\u4f30\uff0c\u6574\u5408\u4e86\u56db\u79cd\u4e92\u8865\u7684\u8bc4\u4f30\u534f\u8bae\u3002", "result": "\u4f7f\u7528LiveResearchBench\u548cDeepEval\u5bf917\u4e2a\u524d\u6cbf\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\uff0c\u5305\u62ec\u5355\u4ee3\u7406\u7f51\u7edc\u641c\u7d22\u3001\u5355\u4ee3\u7406\u6df1\u5ea6\u7814\u7a76\u548c\u591a\u4ee3\u7406\u7cfb\u7edf\u3002", "conclusion": "\u5206\u6790\u63ed\u793a\u4e86\u5f53\u524d\u7cfb\u7edf\u7684\u4f18\u52bf\u3001\u5e38\u89c1\u5931\u8d25\u6a21\u5f0f\u4ee5\u53ca\u63a8\u8fdb\u53ef\u9760\u6df1\u5ea6\u7814\u7a76\u6240\u9700\u7684\u5173\u952e\u7cfb\u7edf\u7ec4\u4ef6\u3002"}}
{"id": "2510.14675", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14675", "abs": "https://arxiv.org/abs/2510.14675", "authors": ["Nicolas Dutly", "Friederike Groschupp", "Ivan Puddu", "Kari Kostiainen", "Srdjan Capkun"], "title": "AEX-NStep: Probabilistic Interrupt Counting Attacks on Intel SGX", "comment": "Author's version, to appear, 2026 IEEE Symposium on Security and\n  Privacy (SP)", "summary": "To mitigate interrupt-based stepping attacks (notably using SGX-Step), Intel\nintroduced AEX-Notify, an ISA extension to Intel SGX that aims to prevent\ndeterministic single-stepping. In this work, we introduce AEX-NStep, the first\ninterrupt counting attack on AEX-Notify-enabled Enclaves. We show that\ndeterministic single-stepping is not required for interrupt counting attacks to\nbe practical and that, therefore, AEX-Notify does not entirely prevent such\nattacks. We specifically show that one of AEX-Notify's security guarantees,\nobfuscated forward progress, does not hold, and we introduce two new\nprobabilistic interrupt counting attacks. We use these attacks to construct a\npractical ECDSA key leakage attack on an AEX-Notify-enabled SGX enclave. Our\nresults extend the original security analysis of AEX-Notify and inform the\ndesign of future mitigations.", "AI": {"tldr": "AEX-NStep\u662f\u9996\u4e2a\u9488\u5bf9AEX-Notify\u7684\u7ec8\u7aef\u8ba1\u6570\u653b\u51fb\uff0c\u8bc1\u660eAEX-Notify\u65e0\u6cd5\u5b8c\u5168\u9632\u6b62\u6b64\u7c7b\u653b\u51fb\uff0c\u5e76\u6210\u529f\u5b9e\u65bd\u4e86ECDSA\u5bc6\u94a5\u6cc4\u9732\u653b\u51fb\u3002", "motivation": "Intel\u5f15\u5165AEX-Notify\u6765\u7f13\u89e3\u57fa\u4e8e\u4e2d\u65ad\u7684\u5355\u6b65\u653b\u51fb\uff0c\u4f46\u4f5c\u8005\u53d1\u73b0\u5176\u5b89\u5168\u4fdd\u8bc1\u5b58\u5728\u7f3a\u9677\uff0c\u9700\u8981\u9a8c\u8bc1\u5176\u5b9e\u9645\u9632\u62a4\u6548\u679c\u3002", "method": "\u5f00\u53d1\u4e86AEX-NStep\u653b\u51fb\uff0c\u5305\u542b\u4e24\u79cd\u6982\u7387\u6027\u4e2d\u65ad\u8ba1\u6570\u653b\u51fb\u65b9\u6cd5\uff0c\u5e76\u9488\u5bf9AEX-Notify\u4fdd\u62a4\u7684SGX\u7ec8\u7aef\u5b9e\u65bdECDSA\u5bc6\u94a5\u6cc4\u9732\u653b\u51fb\u3002", "result": "\u8bc1\u660eAEX-Notify\u7684\u6df7\u6dc6\u524d\u5411\u8fdb\u5ea6\u5b89\u5168\u4fdd\u8bc1\u4e0d\u6210\u7acb\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u5b9e\u7528\u7684ECDSA\u5bc6\u94a5\u6cc4\u9732\u653b\u51fb\u3002", "conclusion": "AEX-Notify\u4e0d\u80fd\u5b8c\u5168\u9632\u6b62\u4e2d\u65ad\u8ba1\u6570\u653b\u51fb\uff0c\u7814\u7a76\u7ed3\u679c\u6269\u5c55\u4e86\u5176\u5b89\u5168\u5206\u6790\u5e76\u4e3a\u672a\u6765\u7f13\u89e3\u63aa\u65bd\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u53c2\u8003\u3002"}}
{"id": "2510.14253", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14253", "abs": "https://arxiv.org/abs/2510.14253", "authors": ["Wangtao Sun", "Xiang Cheng", "Jialin Fan", "Yao Xu", "Xing Yu", "Shizhu He", "Jun Zhao", "Kang Liu"], "title": "Towards Agentic Self-Learning LLMs in Search Environment", "comment": null, "summary": "We study whether self-learning can scale LLM-based agents without relying on\nhuman-curated datasets or predefined rule-based rewards. Through controlled\nexperiments in a search-agent setting, we identify two key determinants of\nscalable agent training: the source of reward signals and the scale of agent\ntask data. We find that rewards from a Generative Reward Model (GRM) outperform\nrigid rule-based signals for open-domain learning, and that co-evolving the GRM\nwith the policy further boosts performance. Increasing the volume of agent task\ndata-even when synthetically generated-substantially enhances agentic\ncapabilities. Building on these insights, we propose \\textbf{Agentic\nSelf-Learning} (ASL), a fully closed-loop, multi-role reinforcement learning\nframework that unifies task generation, policy execution, and evaluation within\na shared tool environment and LLM backbone. ASL coordinates a Prompt Generator,\na Policy Model, and a Generative Reward Model to form a virtuous cycle of\nharder task setting, sharper verification, and stronger solving. Empirically,\nASL delivers steady, round-over-round gains, surpasses strong RLVR baselines\n(e.g., Search-R1) that plateau or degrade, and continues improving under\nzero-labeled-data conditions, indicating superior sample efficiency and\nrobustness. We further show that GRM verification capacity is the main\nbottleneck: if frozen, it induces reward hacking and stalls progress; continual\nGRM training on the evolving data distribution mitigates this, and a small\nlate-stage injection of real verification data raises the performance ceiling.\nThis work establishes reward source and data scale as critical levers for\nopen-domain agent learning and demonstrates the efficacy of multi-role\nco-evolution for scalable, self-improving agents. The data and code of this\npaper are released at\nhttps://github.com/forangel2014/Towards-Agentic-Self-Learning", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Agentic Self-Learning (ASL)\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u89d2\u8272\u534f\u540c\u8fdb\u5316\u7684\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u7684\u667a\u80fd\u4f53\u81ea\u6211\u5b66\u4e60\uff0c\u53d1\u73b0\u5956\u52b1\u4fe1\u53f7\u6765\u6e90\u548c\u4efb\u52a1\u6570\u636e\u89c4\u6a21\u662f\u5f71\u54cd\u667a\u80fd\u4f53\u8bad\u7ec3\u53ef\u6269\u5c55\u6027\u7684\u5173\u952e\u56e0\u7d20\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5728\u4e0d\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u96c6\u6216\u9884\u5b9a\u4e49\u89c4\u5219\u5956\u52b1\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u7684\u89c4\u6a21\u5316\u81ea\u6211\u5b66\u4e60\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u5f00\u653e\u9886\u57df\u5b66\u4e60\u4e2d\u5b58\u5728\u7684\u6027\u80fd\u74f6\u9888\u95ee\u9898\u3002", "method": "\u63d0\u51faASL\u6846\u67b6\uff0c\u5305\u542b\u63d0\u793a\u751f\u6210\u5668\u3001\u7b56\u7565\u6a21\u578b\u548c\u751f\u6210\u5f0f\u5956\u52b1\u6a21\u578b\u4e09\u4e2a\u89d2\u8272\uff0c\u5728\u5171\u4eab\u5de5\u5177\u73af\u5883\u548cLLM\u9aa8\u5e72\u4e2d\u5f62\u6210\u4efb\u52a1\u751f\u6210\u3001\u7b56\u7565\u6267\u884c\u548c\u8bc4\u4f30\u7684\u95ed\u73af\u5f3a\u5316\u5b66\u4e60\u5faa\u73af\u3002", "result": "ASL\u5b9e\u73b0\u4e86\u7a33\u5b9a\u6301\u7eed\u7684\u8f6e\u6b21\u6027\u80fd\u63d0\u5347\uff0c\u8d85\u8d8a\u4e86\u4f1a\u8fbe\u5230\u6027\u80fd\u74f6\u9888\u6216\u9000\u5316\u7684RLVR\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u96f6\u6807\u6ce8\u6570\u636e\u6761\u4ef6\u4e0b\u4ecd\u80fd\u6301\u7eed\u6539\u8fdb\uff0c\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u6837\u672c\u6548\u7387\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u5956\u52b1\u6765\u6e90\u548c\u6570\u636e\u89c4\u6a21\u662f\u5f00\u653e\u9886\u57df\u667a\u80fd\u4f53\u5b66\u4e60\u7684\u5173\u952e\u6760\u6746\uff0c\u591a\u89d2\u8272\u534f\u540c\u8fdb\u5316\u662f\u5b9e\u73b0\u53ef\u6269\u5c55\u81ea\u6211\u6539\u8fdb\u667a\u80fd\u4f53\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u5176\u4e2dGRM\u9a8c\u8bc1\u80fd\u529b\u662f\u4e3b\u8981\u74f6\u9888\u3002"}}
{"id": "2510.14693", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14693", "abs": "https://arxiv.org/abs/2510.14693", "authors": ["Simon Malatrait", "Alex Sirac"], "title": "FibRace: a large-scale benchmark of client-side proving on mobile devices", "comment": "14 pages, 5 figures, 2 tables", "summary": "FibRace, jointly developed by KKRT Labs and Hyli, was the first large-scale\nexperiment to test client-side proof generation on smartphones using Cairo M.\nPresented as a mobile game in which players proved Fibonacci numbers and\nclimbed a leaderboard, FibRace served a dual purpose: to engage the public and\nto provide empirical benchmarking. Over a three-week campaign (September 11-30,\n2025), 6,047 players across 99 countries generated 2,195,488 proofs on 1,420\nunique device models. The results show that most modern smartphones can\ncomplete a proof in under 5 seconds, confirming that *mobile devices are now\ncapable of producing zero-knowledge proofs reliably*, without the need for\nremote provers or specialized hardware. Performance was correlated primarily\nwith RAM capacity and SoC (System on Chip) performance: devices with at least 3\nGB of RAM proved stably, when Apple's A19 Pro and M-series chips achieved the\nfastest proving times. Hyli's blockchain natively verified every proof onchain\nwithout congestion. FibRace provides the most comprehensive dataset to date on\nmobile proving performance, establishing a practical baseline for future\nresearch in lightweight provers, proof-powered infrastructure, and\nprivacy-preserving mobile applications.", "AI": {"tldr": "FibRace\u662f\u9996\u4e2a\u5728\u667a\u80fd\u624b\u673a\u4e0a\u4f7f\u7528Cairo M\u8fdb\u884c\u5ba2\u6237\u7aef\u8bc1\u660e\u751f\u6210\u7684\u5927\u89c4\u6a21\u5b9e\u9a8c\uff0c\u901a\u8fc7\u79fb\u52a8\u6e38\u620f\u5f62\u5f0f\u8ba9\u73a9\u5bb6\u8bc1\u660e\u6590\u6ce2\u90a3\u5951\u6570\u5e76\u53c2\u4e0e\u6392\u884c\u699c\u7ade\u4e89\uff0c\u9a8c\u8bc1\u4e86\u79fb\u52a8\u8bbe\u5907\u80fd\u591f\u53ef\u9760\u751f\u6210\u96f6\u77e5\u8bc6\u8bc1\u660e\u3002", "motivation": "\u6d4b\u8bd5\u667a\u80fd\u624b\u673a\u5ba2\u6237\u7aef\u8bc1\u660e\u751f\u6210\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u8f7b\u91cf\u7ea7\u8bc1\u660e\u5668\u3001\u8bc1\u660e\u9a71\u52a8\u7684\u57fa\u7840\u8bbe\u65bd\u548c\u9690\u79c1\u4fdd\u62a4\u79fb\u52a8\u5e94\u7528\u63d0\u4f9b\u5b9e\u8df5\u57fa\u51c6\u3002", "method": "\u5f00\u53d1\u79fb\u52a8\u6e38\u620fFibRace\uff0c\u8ba9\u73a9\u5bb6\u5728\u667a\u80fd\u624b\u673a\u4e0a\u4f7f\u7528Cairo M\u751f\u6210\u6590\u6ce2\u90a3\u5951\u6570\u8bc1\u660e\uff0c\u6536\u96c66047\u540d\u73a9\u5bb6\u57281420\u79cd\u8bbe\u5907\u578b\u53f7\u4e0a\u751f\u6210\u76842195488\u4e2a\u8bc1\u660e\u6570\u636e\u3002", "result": "\u5927\u591a\u6570\u73b0\u4ee3\u667a\u80fd\u624b\u673a\u80fd\u57285\u79d2\u5185\u5b8c\u6210\u8bc1\u660e\uff0c\u786e\u8ba4\u79fb\u52a8\u8bbe\u5907\u65e0\u9700\u8fdc\u7a0b\u8bc1\u660e\u5668\u6216\u4e13\u7528\u786c\u4ef6\u5373\u53ef\u53ef\u9760\u751f\u6210\u96f6\u77e5\u8bc6\u8bc1\u660e\u3002\u6027\u80fd\u4e3b\u8981\u4e0eRAM\u5bb9\u91cf\u548cSoC\u6027\u80fd\u76f8\u5173\uff0c\u81f3\u5c113GB RAM\u7684\u8bbe\u5907\u80fd\u7a33\u5b9a\u8bc1\u660e\uff0c\u82f9\u679cA19 Pro\u548cM\u7cfb\u5217\u82af\u7247\u8bc1\u660e\u65f6\u95f4\u6700\u5feb\u3002", "conclusion": "\u79fb\u52a8\u8bbe\u5907\u73b0\u5df2\u5177\u5907\u53ef\u9760\u751f\u6210\u96f6\u77e5\u8bc6\u8bc1\u660e\u7684\u80fd\u529b\uff0cFibRace\u63d0\u4f9b\u4e86\u8fc4\u4eca\u4e3a\u6b62\u6700\u5168\u9762\u7684\u79fb\u52a8\u8bc1\u660e\u6027\u80fd\u6570\u636e\u96c6\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u5efa\u7acb\u4e86\u5b9e\u8df5\u57fa\u51c6\u3002"}}
{"id": "2510.14265", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14265", "abs": "https://arxiv.org/abs/2510.14265", "authors": ["Xukai Wang", "Xuanbo Liu", "Mingrui Chen", "Haitian Zhong", "Xuanlin Yang", "Bohan Zeng", "Jinbo Hu", "Hao Liang", "Junbo Niu", "Xuchen Li", "Ruitao Wu", "Ruichuan An", "Yang Shi", "Liu Liu", "Xu-Yao Zhang", "Qiang Liu", "Zhouchen Lin", "Wentao Zhang", "Bin Dong"], "title": "MorphoBench: A Benchmark with Difficulty Adaptive to Model Reasoning", "comment": "21 pages, 12 figures", "summary": "With the advancement of powerful large-scale reasoning models, effectively\nevaluating the reasoning capabilities of these models has become increasingly\nimportant. However, existing benchmarks designed to assess the reasoning\nabilities of large models tend to be limited in scope and lack the flexibility\nto adapt their difficulty according to the evolving reasoning capacities of the\nmodels. To address this, we propose MorphoBench, a benchmark that incorporates\nmultidisciplinary questions to evaluate the reasoning capabilities of large\nmodels and can adjust and update question difficulty based on the reasoning\nabilities of advanced models. Specifically, we curate the benchmark by\nselecting and collecting complex reasoning questions from existing benchmarks\nand sources such as Olympiad-level competitions. Additionally, MorphoBench\nadaptively modifies the analytical challenge of questions by leveraging key\nstatements generated during the model's reasoning process. Furthermore, it\nincludes questions generated using simulation software, enabling dynamic\nadjustment of benchmark difficulty with minimal resource consumption. We have\ngathered over 1,300 test questions and iteratively adjusted the difficulty of\nMorphoBench based on the reasoning capabilities of models such as o3 and GPT-5.\nMorphoBench enhances the comprehensiveness and validity of model reasoning\nevaluation, providing reliable guidance for improving both the reasoning\nabilities and scientific robustness of large models. The code has been released\nin https://github.com/OpenDCAI/MorphoBench.", "AI": {"tldr": "\u63d0\u51fa\u4e86MorphoBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5177\u6709\u591a\u5b66\u79d1\u95ee\u9898\u548c\u81ea\u9002\u5e94\u96be\u5ea6\u8c03\u6574\u529f\u80fd\uff0c\u5305\u542b1300\u591a\u4e2a\u6d4b\u8bd5\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u8303\u56f4\u6709\u9650\u4e14\u7f3a\u4e4f\u7075\u6d3b\u6027\uff0c\u65e0\u6cd5\u6839\u636e\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u6f14\u53d8\u8c03\u6574\u96be\u5ea6\uff0c\u9700\u8981\u66f4\u5168\u9762\u6709\u6548\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u4ece\u73b0\u6709\u57fa\u51c6\u548c\u5965\u6797\u5339\u514b\u7ade\u8d5b\u4e2d\u6536\u96c6\u590d\u6742\u63a8\u7406\u95ee\u9898\uff0c\u5229\u7528\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u5173\u952e\u9648\u8ff0\u81ea\u9002\u5e94\u4fee\u6539\u95ee\u9898\u5206\u6790\u96be\u5ea6\uff0c\u5e76\u5305\u542b\u4f7f\u7528\u4eff\u771f\u8f6f\u4ef6\u751f\u6210\u7684\u95ee\u9898\u4ee5\u5b9e\u73b0\u52a8\u6001\u96be\u5ea6\u8c03\u6574\u3002", "result": "\u6536\u96c6\u4e861300\u591a\u4e2a\u6d4b\u8bd5\u95ee\u9898\uff0c\u57fa\u4e8eo3\u548cGPT-5\u7b49\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u8fed\u4ee3\u8c03\u6574\u4e86MorphoBench\u7684\u96be\u5ea6\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u63a8\u7406\u8bc4\u4f30\u7684\u5168\u9762\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "MorphoBench\u589e\u5f3a\u4e86\u6a21\u578b\u63a8\u7406\u8bc4\u4f30\u7684\u5168\u9762\u6027\u548c\u6709\u6548\u6027\uff0c\u4e3a\u63d0\u5347\u5927\u578b\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u548c\u79d1\u5b66\u7a33\u5065\u6027\u63d0\u4f9b\u4e86\u53ef\u9760\u6307\u5bfc\u3002"}}
{"id": "2510.14708", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14708", "abs": "https://arxiv.org/abs/2510.14708", "authors": ["Ha Xuan Son", "Nguyen Quoc Anh", "Phat T. Tran-Truong", "Le Thanh Tuan", "Pham Thanh Nghiem"], "title": "SLIE: A Secure and Lightweight Cryptosystem for Data Sharing in IoT Healthcare Services", "comment": "Paper has been accepted for publication in the Proceedings of the\n  23th International Conference on Service-Oriented Computing 2025", "summary": "The Internet of Medical Things (IoMT) has revolutionized healthcare by\ntransforming medical operations into standardized, interoperable services.\nHowever, this service-oriented model introduces significant security\nvulnerabilities in device management and communication, which are especially\ncritical given the sensitivity of medical data. To address these risks, this\npaper proposes SLIE (Secure and Lightweight Identity Encryption), a novel\ncryptosystem based on Wildcard Key Derivation Identity-Based Encryption\n(WKD-IBE). SLIE ensures scalable trust and secure omnidirectional communication\nthrough end-to-end encryption, hierarchical access control, and a lightweight\nkey management system designed for resource-constrained devices. It\nincorporates constant-time operations, memory obfuscation, and expiry-based key\nrevocation to counter side-channel, man-in-the-middle, and unauthorized access\nattacks, thereby ensuring compliance with standards like HIPAA and GDPR.\nEvaluations show that SLIE significantly outperforms RSA, with encryption and\ndecryption times of 0.936ms and 0.217ms for 1KB of data, an 84.54% improvement\nin encryption speed, a 99.70% improvement in decryption speed, and an energy\nefficiency of 0.014 J/KB.", "AI": {"tldr": "SLIE\u662f\u4e00\u79cd\u57fa\u4e8eWKD-IBE\u7684\u65b0\u578b\u5bc6\u7801\u7cfb\u7edf\uff0c\u4e3aIoMT\u63d0\u4f9b\u5b89\u5168\u8f7b\u91cf\u7ea7\u8eab\u4efd\u52a0\u5bc6\uff0c\u663e\u8457\u63d0\u5347\u52a0\u5bc6\u6027\u80fd\u5e76\u786e\u4fdd\u533b\u7597\u6570\u636e\u5b89\u5168\u3002", "motivation": "IoMT\u7684\u670d\u52a1\u5bfc\u5411\u6a21\u578b\u5728\u8bbe\u5907\u7ba1\u7406\u548c\u901a\u4fe1\u4e2d\u5f15\u5165\u4e86\u4e25\u91cd\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u7279\u522b\u662f\u533b\u7597\u6570\u636e\u7684\u654f\u611f\u6027\u4f7f\u8fd9\u4e9b\u98ce\u9669\u5c24\u4e3a\u5173\u952e\u3002", "method": "\u63d0\u51faSLIE\u7cfb\u7edf\uff0c\u57fa\u4e8eWKD-IBE\u5bc6\u7801\u7cfb\u7edf\uff0c\u91c7\u7528\u7aef\u5230\u7aef\u52a0\u5bc6\u3001\u5206\u5c42\u8bbf\u95ee\u63a7\u5236\u548c\u8f7b\u91cf\u7ea7\u5bc6\u94a5\u7ba1\u7406\uff0c\u5305\u542b\u6052\u5b9a\u65f6\u95f4\u64cd\u4f5c\u3001\u5185\u5b58\u6df7\u6dc6\u548c\u57fa\u4e8e\u8fc7\u671f\u7684\u5bc6\u94a5\u64a4\u9500\u673a\u5236\u3002", "result": "SLIE\u663e\u8457\u4f18\u4e8eRSA\uff0c1KB\u6570\u636e\u7684\u52a0\u5bc6\u548c\u89e3\u5bc6\u65f6\u95f4\u5206\u522b\u4e3a0.936ms\u548c0.217ms\uff0c\u52a0\u5bc6\u901f\u5ea6\u63d0\u534784.54%\uff0c\u89e3\u5bc6\u901f\u5ea6\u63d0\u534799.70%\uff0c\u80fd\u6548\u4e3a0.014 J/KB\u3002", "conclusion": "SLIE\u4e3a\u8d44\u6e90\u53d7\u9650\u7684IoMT\u8bbe\u5907\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u4fe1\u4efb\u548c\u5b89\u5168\u7684\u5168\u5411\u901a\u4fe1\uff0c\u6709\u6548\u62b5\u5fa1\u4fa7\u4fe1\u9053\u3001\u4e2d\u95f4\u4eba\u548c\u672a\u6388\u6743\u8bbf\u95ee\u653b\u51fb\uff0c\u786e\u4fdd\u7b26\u5408HIPAA\u548cGDPR\u6807\u51c6\u3002"}}
{"id": "2510.14301", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14301", "abs": "https://arxiv.org/abs/2510.14301", "authors": ["Bingjie Zhang", "Yibo Yang", "Renzhe", "Dandan Guo", "Jindong Gu", "Philip Torr", "Bernard Ghanem"], "title": "A Guardrail for Safety Preservation: When Safety-Sensitive Subspace Meets Harmful-Resistant Null-Space", "comment": null, "summary": "Large language models (LLMs) have achieved remarkable success in diverse\ntasks, yet their safety alignment remains fragile during adaptation. Even when\nfine-tuning on benign data or with low-rank adaptation, pre-trained safety\nbehaviors are easily degraded, leading to harmful responses in the fine-tuned\nmodels. To address this challenge, we propose GuardSpace, a guardrail framework\nfor preserving safety alignment throughout fine-tuning, composed of two key\ncomponents: a safety-sensitive subspace and a harmful-resistant null space.\nFirst, we explicitly decompose pre-trained weights into safety-relevant and\nsafety-irrelevant components using covariance-preconditioned singular value\ndecomposition, and initialize low-rank adapters from the safety-irrelevant\nones, while freezing safety-relevant components to preserve their associated\nsafety mechanism. Second, we construct a null space projector that restricts\nadapter updates from altering safe outputs on harmful prompts, thereby\nmaintaining the original refusal behavior. Experiments with various pre-trained\nmodels on multiple downstream tasks demonstrate that GuardSpace achieves\nsuperior performance over existing methods. Notably, for Llama-2-7B-Chat\nfine-tuned on GSM8K, GuardSpace outperforms the state-of-the-art method AsFT,\nreducing the average harmful score from 14.4% to 3.6%, while improving the\naccuracy from from 26.0% to 28.0%.", "AI": {"tldr": "GuardSpace\u662f\u4e00\u4e2a\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u4fdd\u62a4\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u5bf9\u9f50\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5b89\u5168\u654f\u611f\u5b50\u7a7a\u95f4\u548c\u6709\u5bb3\u62b5\u6297\u96f6\u7a7a\u95f4\u6765\u9632\u6b62\u5b89\u5168\u884c\u4e3a\u9000\u5316\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u5bb9\u6613\u5931\u53bb\u9884\u8bad\u7ec3\u7684\u5b89\u5168\u5bf9\u9f50\uff0c\u5373\u4f7f\u4f7f\u7528\u826f\u6027\u6570\u636e\u6216\u4f4e\u79e9\u9002\u914d\u4e5f\u4f1a\u4ea7\u751f\u6709\u5bb3\u54cd\u5e94\uff0c\u9700\u8981\u4fdd\u62a4\u5b89\u5168\u673a\u5236\u3002", "method": "\u4f7f\u7528\u534f\u65b9\u5dee\u9884\u5904\u7406\u5947\u5f02\u503c\u5206\u89e3\u5c06\u9884\u8bad\u7ec3\u6743\u91cd\u5206\u89e3\u4e3a\u5b89\u5168\u76f8\u5173\u548c\u5b89\u5168\u65e0\u5173\u7ec4\u4ef6\uff0c\u521d\u59cb\u5316\u4f4e\u79e9\u9002\u914d\u5668\u65f6\u51bb\u7ed3\u5b89\u5168\u76f8\u5173\u90e8\u5206\uff0c\u5e76\u6784\u5efa\u96f6\u7a7a\u95f4\u6295\u5f71\u5668\u9650\u5236\u9002\u914d\u5668\u66f4\u65b0\u5bf9\u6709\u5bb3\u63d0\u793a\u7684\u5f71\u54cd\u3002", "result": "\u5728\u591a\u4e2a\u4e0b\u6e38\u4efb\u52a1\u5b9e\u9a8c\u4e2d\uff0cGuardSpace\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5bf9\u4e8eLlama-2-7B-Chat\u5728GSM8K\u4e0a\u7684\u5fae\u8c03\uff0c\u5c06\u5e73\u5747\u6709\u5bb3\u5206\u6570\u4ece14.4%\u964d\u81f33.6%\uff0c\u540c\u65f6\u51c6\u786e\u7387\u4ece26.0%\u63d0\u5347\u81f328.0%\u3002", "conclusion": "GuardSpace\u6846\u67b6\u80fd\u6709\u6548\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u6a21\u578b\u7684\u5b89\u5168\u5bf9\u9f50\uff0c\u540c\u65f6\u63d0\u5347\u4efb\u52a1\u6027\u80fd\uff0c\u4e3a\u5b89\u5168\u5fae\u8c03\u63d0\u4f9b\u4e86\u53ef\u9760\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.14894", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14894", "abs": "https://arxiv.org/abs/2510.14894", "authors": ["Marc Damie", "Florian Hahn", "Andreas Peter", "Jan Ramon"], "title": "Secure Sparse Matrix Multiplications and their Applications to Privacy-Preserving Machine Learning", "comment": null, "summary": "To preserve privacy, multi-party computation (MPC) enables executing Machine\nLearning (ML) algorithms on secret-shared or encrypted data. However, existing\nMPC frameworks are not optimized for sparse data. This makes them unsuitable\nfor ML applications involving sparse data, e.g., recommender systems or\ngenomics. Even in plaintext, such applications involve high-dimensional sparse\ndata, that cannot be processed without sparsity-related optimizations due to\nprohibitively large memory requirements.\n  Since matrix multiplication is central in ML algorithms, we propose MPC\nalgorithms to multiply secret sparse matrices. On the one hand, our algorithms\navoid the memory issues of the \"dense\" data representation of classic secure\nmatrix multiplication algorithms. On the other hand, our algorithms can\nsignificantly reduce communication costs (some experiments show a factor 1000)\nfor realistic problem sizes. We validate our algorithms in two ML applications\nin which existing protocols are impractical.\n  An important question when developing MPC algorithms is what assumptions can\nbe made. In our case, if the number of non-zeros in a row is a sensitive piece\nof information then a short runtime may reveal that the number of non-zeros is\nsmall. Existing approaches make relatively simple assumptions, e.g., that there\nis a universal upper bound to the number of non-zeros in a row. This often\ndoesn't align with statistical reality, in a lot of sparse datasets the amount\nof data per instance satisfies a power law. We propose an approach which allows\nadopting a safe upper bound on the distribution of non-zeros in rows/columns of\nsparse matrices.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9488\u5bf9\u7a00\u758f\u6570\u636e\u7684\u591a\u65b9\u8ba1\u7b97\u77e9\u9635\u4e58\u6cd5\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709MPC\u6846\u67b6\u5728\u5904\u7406\u9ad8\u7ef4\u7a00\u758f\u6570\u636e\u65f6\u7684\u5185\u5b58\u548c\u901a\u4fe1\u6548\u7387\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u65b9\u8ba1\u7b97\u6846\u67b6\u6ca1\u6709\u9488\u5bf9\u7a00\u758f\u6570\u636e\u8fdb\u884c\u4f18\u5316\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u63a8\u8350\u7cfb\u7edf\u3001\u57fa\u56e0\u7ec4\u5b66\u7b49\u6d89\u53ca\u9ad8\u7ef4\u7a00\u758f\u6570\u636e\u7684\u673a\u5668\u5b66\u4e60\u5e94\u7528\uff0c\u56e0\u4e3a\u5bc6\u96c6\u6570\u636e\u8868\u793a\u4f1a\u5bfc\u81f4\u5185\u5b58\u9700\u6c42\u8fc7\u5927\u3002", "method": "\u8bbe\u8ba1\u4e86\u79d8\u5bc6\u7a00\u758f\u77e9\u9635\u4e58\u6cd5\u7b97\u6cd5\uff0c\u907f\u514d\u4f7f\u7528\u5bc6\u96c6\u6570\u636e\u8868\u793a\uff0c\u5e76\u91c7\u7528\u57fa\u4e8e\u975e\u96f6\u5143\u7d20\u5206\u5e03\u7684\u5b89\u5168\u4e0a\u754c\u65b9\u6cd5\u3002", "result": "\u7b97\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u901a\u4fe1\u6210\u672c\uff08\u67d0\u4e9b\u5b9e\u9a8c\u663e\u793a\u53ef\u8fbe1000\u500d\uff09\uff0c\u5e76\u5728\u73b0\u6709\u534f\u8bae\u4e0d\u5b9e\u7528\u7684\u4e24\u4e2a\u673a\u5668\u5b66\u4e60\u5e94\u7528\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u7a00\u758f\u77e9\u9635\u4e58\u6cd5\u7b97\u6cd5\u89e3\u51b3\u4e86MPC\u5904\u7406\u7a00\u758f\u6570\u636e\u65f6\u7684\u5185\u5b58\u548c\u6548\u7387\u95ee\u9898\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u66f4\u7b26\u5408\u7edf\u8ba1\u73b0\u5b9e\u7684\u5b89\u5168\u4e0a\u754c\u65b9\u6cd5\u3002"}}
{"id": "2510.14312", "categories": ["cs.AI", "cs.CL", "cs.CR", "I.2.7; I.2.11"], "pdf": "https://arxiv.org/pdf/2510.14312", "abs": "https://arxiv.org/abs/2510.14312", "authors": ["Mason Nakamura", "Abhinav Kumar", "Saaduddin Mahmud", "Sahar Abdelnabi", "Shlomo Zilberstein", "Eugene Bagdasarian"], "title": "Terrarium: Revisiting the Blackboard for Multi-Agent Safety, Privacy, and Security Studies", "comment": null, "summary": "A multi-agent system (MAS) powered by large language models (LLMs) can\nautomate tedious user tasks such as meeting scheduling that requires\ninter-agent collaboration. LLMs enable nuanced protocols that account for\nunstructured private data, user constraints, and preferences. However, this\ndesign introduces new risks, including misalignment and attacks by malicious\nparties that compromise agents or steal user data. In this paper, we propose\nthe Terrarium framework for fine-grained study on safety, privacy, and security\nin LLM-based MAS. We repurpose the blackboard design, an early approach in\nmulti-agent systems, to create a modular, configurable testbed for multi-agent\ncollaboration. We identify key attack vectors such as misalignment, malicious\nagents, compromised communication, and data poisoning. We implement three\ncollaborative MAS scenarios with four representative attacks to demonstrate the\nframework's flexibility. By providing tools to rapidly prototype, evaluate, and\niterate on defenses and designs, Terrarium aims to accelerate progress toward\ntrustworthy multi-agent systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86Terrarium\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u8fdb\u884c\u7ec6\u7c92\u5ea6\u7684\u5b89\u5168\u3001\u9690\u79c1\u548c\u5b89\u5168\u6027\u7814\u7a76\uff0c\u901a\u8fc7\u91cd\u6784\u9ed1\u677f\u8bbe\u8ba1\u521b\u5efa\u6a21\u5757\u5316\u3001\u53ef\u914d\u7f6e\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002", "motivation": "LLM\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u80fd\u591f\u81ea\u52a8\u5316\u7e41\u7410\u7684\u7528\u6237\u4efb\u52a1\uff0c\u4f46\u5f15\u5165\u4e86\u65b0\u7684\u98ce\u9669\uff0c\u5305\u62ec\u9519\u4f4d\u548c\u5bf9\u9f50\u95ee\u9898\u3001\u6076\u610f\u65b9\u653b\u51fb\u3001\u667a\u80fd\u4f53\u88ab\u7834\u574f\u6216\u7528\u6237\u6570\u636e\u88ab\u76d7\u7b49\u3002", "method": "\u91cd\u65b0\u5229\u7528\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u65e9\u671f\u65b9\u6cd5\u2014\u2014\u9ed1\u677f\u8bbe\u8ba1\uff0c\u521b\u5efa\u6a21\u5757\u5316\u3001\u53ef\u914d\u7f6e\u7684\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6d4b\u8bd5\u5e73\u53f0\uff0c\u8bc6\u522b\u5173\u952e\u653b\u51fb\u5411\u91cf\u5e76\u5b9e\u73b0\u4e09\u79cd\u534f\u4f5c\u573a\u666f\u548c\u56db\u79cd\u4ee3\u8868\u6027\u653b\u51fb\u3002", "result": "\u5f00\u53d1\u4e86Terrarium\u6846\u67b6\uff0c\u63d0\u4f9b\u4e86\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\u3001\u8bc4\u4f30\u548c\u9632\u5fa1\u8fed\u4ee3\u7684\u5de5\u5177\uff0c\u5c55\u793a\u4e86\u6846\u67b6\u5728\u6a21\u62df\u653b\u51fb\u573a\u666f\u4e2d\u7684\u7075\u6d3b\u6027\u3002", "conclusion": "Terrarium\u6846\u67b6\u65e8\u5728\u52a0\u901f\u53ef\u4fe1\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u8fdb\u5c55\uff0c\u901a\u8fc7\u63d0\u4f9b\u5de5\u5177\u6765\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\u3001\u8bc4\u4f30\u548c\u8fed\u4ee3\u9632\u5fa1\u63aa\u65bd\u3002"}}
{"id": "2510.14906", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14906", "abs": "https://arxiv.org/abs/2510.14906", "authors": ["Zixuan Liu", "Yi Zhao", "Zhuotao Liu", "Qi Li", "Chuanpu Fu", "Guangmeng Zhou", "Ke Xu"], "title": "A Hard-Label Black-Box Evasion Attack against ML-based Malicious Traffic Detection Systems", "comment": null, "summary": "Machine Learning (ML)-based malicious traffic detection is a promising\nsecurity paradigm. It outperforms rule-based traditional detection by\nidentifying various advanced attacks. However, the robustness of these ML\nmodels is largely unexplored, thereby allowing attackers to craft adversarial\ntraffic examples that evade detection. Existing evasion attacks typically rely\non overly restrictive conditions (e.g., encrypted protocols, Tor, or\nspecialized setups), or require detailed prior knowledge of the target (e.g.,\ntraining data and model parameters), which is impractical in realistic\nblack-box scenarios. The feasibility of a hard-label black-box evasion attack\n(i.e., applicable across diverse tasks and protocols without internal target\ninsights) thus remains an open challenge. To this end, we develop\nNetMasquerade, which leverages reinforcement learning (RL) to manipulate attack\nflows to mimic benign traffic and evade detection. Specifically, we establish a\ntailored pre-trained model called Traffic-BERT, utilizing a network-specialized\ntokenizer and an attention mechanism to extract diverse benign traffic\npatterns. Subsequently, we integrate Traffic-BERT into the RL framework,\nallowing NetMasquerade to effectively manipulate malicious packet sequences\nbased on benign traffic patterns with minimal modifications. Experimental\nresults demonstrate that NetMasquerade enables both brute-force and stealthy\nattacks to evade 6 existing detection methods under 80 attack scenarios,\nachieving over 96.65% attack success rate. Notably, it can evade the methods\nthat are either empirically or certifiably robust against existing evasion\nattacks. Finally, NetMasquerade achieves low-latency adversarial traffic\ngeneration, demonstrating its practicality in real-world scenarios.", "AI": {"tldr": "NetMasquerade\u662f\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6076\u610f\u6d41\u91cf\u4f2a\u88c5\u7cfb\u7edf\uff0c\u901a\u8fc7\u6a21\u4eff\u826f\u6027\u6d41\u91cf\u6a21\u5f0f\u6765\u9003\u907f\u673a\u5668\u5b66\u4e60\u68c0\u6d4b\uff0c\u572880\u79cd\u653b\u51fb\u573a\u666f\u4e0b\u5bf96\u79cd\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u7684\u9003\u907f\u6210\u529f\u7387\u8d85\u8fc796.65%\u3002", "motivation": "\u73b0\u6709\u7684\u6076\u610f\u6d41\u91cf\u9003\u907f\u653b\u51fb\u8981\u4e48\u4f9d\u8d56\u8fc7\u4e8e\u4e25\u683c\u7684\u6761\u4ef6\uff08\u5982\u52a0\u5bc6\u534f\u8bae\u3001Tor\u6216\u7279\u6b8a\u8bbe\u7f6e\uff09\uff0c\u8981\u4e48\u9700\u8981\u76ee\u6807\u7684\u8be6\u7ec6\u4fe1\u606f\uff08\u5982\u8bad\u7ec3\u6570\u636e\u548c\u6a21\u578b\u53c2\u6570\uff09\uff0c\u8fd9\u5728\u73b0\u5b9e\u7684\u9ed1\u76d2\u573a\u666f\u4e2d\u4e0d\u5b9e\u7528\u3002\u786c\u6807\u7b7e\u9ed1\u76d2\u9003\u907f\u653b\u51fb\u7684\u53ef\u884c\u6027\u4ecd\u7136\u662f\u4e00\u4e2a\u5f00\u653e\u6311\u6218\u3002", "method": "\u5f00\u53d1\u4e86NetMasquerade\u7cfb\u7edf\uff0c\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u64cd\u7eb5\u653b\u51fb\u6d41\u91cf\u6a21\u4eff\u826f\u6027\u6d41\u91cf\u3002\u9996\u5148\u5efa\u7acb\u4e86\u4e13\u95e8\u9884\u8bad\u7ec3\u7684Traffic-BERT\u6a21\u578b\uff0c\u4f7f\u7528\u7f51\u7edc\u4e13\u7528\u5206\u8bcd\u5668\u548c\u6ce8\u610f\u529b\u673a\u5236\u63d0\u53d6\u591a\u6837\u5316\u7684\u826f\u6027\u6d41\u91cf\u6a21\u5f0f\uff0c\u7136\u540e\u5c06Traffic-BERT\u96c6\u6210\u5230RL\u6846\u67b6\u4e2d\uff0c\u57fa\u4e8e\u826f\u6027\u6d41\u91cf\u6a21\u5f0f\u4ee5\u6700\u5c0f\u4fee\u6539\u6709\u6548\u64cd\u7eb5\u6076\u610f\u6570\u636e\u5305\u5e8f\u5217\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cNetMasquerade\u80fd\u591f\u4f7f\u66b4\u529b\u653b\u51fb\u548c\u9690\u853d\u653b\u51fb\u572880\u79cd\u653b\u51fb\u573a\u666f\u4e0b\u9003\u907f6\u79cd\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\uff0c\u653b\u51fb\u6210\u529f\u7387\u8d85\u8fc796.65%\u3002\u5b83\u80fd\u591f\u9003\u907f\u90a3\u4e9b\u5bf9\u73b0\u6709\u9003\u907f\u653b\u51fb\u5177\u6709\u7ecf\u9a8c\u6027\u6216\u53ef\u8bc1\u660e\u9c81\u68d2\u6027\u7684\u65b9\u6cd5\uff0c\u5e76\u4e14\u5b9e\u73b0\u4e86\u4f4e\u5ef6\u8fdf\u7684\u5bf9\u6297\u6d41\u91cf\u751f\u6210\u3002", "conclusion": "NetMasquerade\u8bc1\u660e\u4e86\u5728\u73b0\u5b9e\u9ed1\u76d2\u573a\u666f\u4e2d\u5b9e\u73b0\u786c\u6807\u7b7e\u9ed1\u76d2\u9003\u907f\u653b\u51fb\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u6076\u610f\u6d41\u91cf\u68c0\u6d4b\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\uff0c\u5c55\u793a\u4e86\u5f3a\u5316\u5b66\u4e60\u5728\u7f51\u7edc\u5b89\u5168\u5bf9\u6297\u4e2d\u7684\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.14319", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14319", "abs": "https://arxiv.org/abs/2510.14319", "authors": ["Xu Shen", "Qi Zhang", "Song Wang", "Zhen Tan", "Xinyu Zhao", "Laura Yao", "Vaishnav Tadiparthi", "Hossein Nourkhiz Mahjoub", "Ehsan Moradi Pari", "Kwonjoon Lee", "Tianlong Chen"], "title": "Metacognitive Self-Correction for Multi-Agent System via Prototype-Guided Next-Execution Reconstruction", "comment": null, "summary": "Large Language Model based multi-agent systems (MAS) excel at collaborative\nproblem solving but remain brittle to cascading errors: a single faulty step\ncan propagate across agents and disrupt the trajectory. In this paper, we\npresent MASC, a metacognitive framework that endows MAS with real-time,\nunsupervised, step-level error detection and self-correction. MASC rethinks\ndetection as history-conditioned anomaly scoring via two complementary designs:\n(1) Next-Execution Reconstruction, which predicts the embedding of the next\nstep from the query and interaction history to capture causal consistency, and\n(2) Prototype-Guided Enhancement, which learns a prototype prior over\nnormal-step embeddings and uses it to stabilize reconstruction and anomaly\nscoring under sparse context (e.g., early steps). When an anomaly step is\nflagged, MASC triggers a correction agent to revise the acting agent's output\nbefore information flows downstream. On the Who&When benchmark, MASC\nconsistently outperforms all baselines, improving step-level error detection by\nup to 8.47% AUC-ROC ; When plugged into diverse MAS frameworks, it delivers\nconsistent end-to-end gains across architectures, confirming that our\nmetacognitive monitoring and targeted correction can mitigate error propagation\nwith minimal overhead.", "AI": {"tldr": "MASC\u662f\u4e00\u4e2a\u5143\u8ba4\u77e5\u6846\u67b6\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u5b9e\u65f6\u3001\u65e0\u76d1\u7763\u7684\u6b65\u9aa4\u7ea7\u9519\u8bef\u68c0\u6d4b\u548c\u81ea\u6211\u7ea0\u6b63\uff0c\u901a\u8fc7\u5386\u53f2\u6761\u4ef6\u5f02\u5e38\u8bc4\u5206\u6765\u9632\u6b62\u9519\u8bef\u4f20\u64ad\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u534f\u4f5c\u89e3\u51b3\u95ee\u9898\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5bf9\u7ea7\u8054\u9519\u8bef\u5f88\u8106\u5f31\u2014\u2014\u5355\u4e2a\u9519\u8bef\u6b65\u9aa4\u4f1a\u5728\u667a\u80fd\u4f53\u95f4\u4f20\u64ad\u5e76\u7834\u574f\u6574\u4e2a\u8f68\u8ff9\u3002", "method": "\u91c7\u7528\u4e24\u79cd\u4e92\u8865\u8bbe\u8ba1\uff1a1\uff09\u4e0b\u4e00\u6267\u884c\u91cd\u6784\uff0c\u4ece\u67e5\u8be2\u548c\u4ea4\u4e92\u5386\u53f2\u9884\u6d4b\u4e0b\u4e00\u6b65\u7684\u5d4c\u5165\u4ee5\u6355\u6349\u56e0\u679c\u4e00\u81f4\u6027\uff1b2\uff09\u539f\u578b\u5f15\u5bfc\u589e\u5f3a\uff0c\u5b66\u4e60\u6b63\u5e38\u6b65\u9aa4\u5d4c\u5165\u7684\u539f\u578b\u5148\u9a8c\uff0c\u5728\u7a00\u758f\u4e0a\u4e0b\u6587\u4e0b\u7a33\u5b9a\u91cd\u6784\u548c\u5f02\u5e38\u8bc4\u5206\u3002\u68c0\u6d4b\u5230\u5f02\u5e38\u65f6\u89e6\u53d1\u7ea0\u6b63\u667a\u80fd\u4f53\u3002", "result": "\u5728Who&When\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMASC\u59cb\u7ec8\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\uff0c\u6b65\u9aa4\u7ea7\u9519\u8bef\u68c0\u6d4bAUC-ROC\u63d0\u5347\u9ad8\u8fbe8.47%\uff1b\u5728\u4e0d\u540cMAS\u6846\u67b6\u4e2d\u90fd\u80fd\u5e26\u6765\u4e00\u81f4\u7684\u7aef\u5230\u7aef\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u5143\u8ba4\u77e5\u76d1\u63a7\u548c\u9488\u5bf9\u6027\u7ea0\u6b63\u80fd\u591f\u4ee5\u6700\u5c0f\u5f00\u9500\u7f13\u89e3\u9519\u8bef\u4f20\u64ad\uff0c\u8be5\u6846\u67b6\u5728\u4e0d\u540c\u67b6\u6784\u4e2d\u90fd\u5177\u6709\u901a\u7528\u6027\u3002"}}
{"id": "2510.14359", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.14359", "abs": "https://arxiv.org/abs/2510.14359", "authors": ["Zichen Wen", "Yiyu Wang", "Chenfei Liao", "Boxue Yang", "Junxian Li", "Weifeng Liu", "Haocong He", "Bolong Feng", "Xuyang Liu", "Yuanhuiyi Lyu", "Xu Zheng", "Xuming Hu", "Linfeng Zhang"], "title": "AI for Service: Proactive Assistance with AI Glasses", "comment": "24 pages, 5 figures, work in progress", "summary": "In an era where AI is evolving from a passive tool into an active and\nadaptive companion, we introduce AI for Service (AI4Service), a new paradigm\nthat enables proactive and real-time assistance in daily life. Existing AI\nservices remain largely reactive, responding only to explicit user commands. We\nargue that a truly intelligent and helpful assistant should be capable of\nanticipating user needs and taking actions proactively when appropriate. To\nrealize this vision, we propose Alpha-Service, a unified framework that\naddresses two fundamental challenges: Know When to intervene by detecting\nservice opportunities from egocentric video streams, and Know How to provide\nboth generalized and personalized services. Inspired by the von Neumann\ncomputer architecture and based on AI glasses, Alpha-Service consists of five\nkey components: an Input Unit for perception, a Central Processing Unit for\ntask scheduling, an Arithmetic Logic Unit for tool utilization, a Memory Unit\nfor long-term personalization, and an Output Unit for natural human\ninteraction. As an initial exploration, we implement Alpha-Service through a\nmulti-agent system deployed on AI glasses. Case studies, including a real-time\nBlackjack advisor, a museum tour guide, and a shopping fit assistant,\ndemonstrate its ability to seamlessly perceive the environment, infer user\nintent, and provide timely and useful assistance without explicit prompts.", "AI": {"tldr": "\u63d0\u51fa\u4e86AI4Service\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7Alpha-Service\u6846\u67b6\u5b9e\u73b0\u4e3b\u52a8\u5f0fAI\u670d\u52a1\uff0c\u80fd\u591f\u4ece\u7b2c\u4e00\u89c6\u89d2\u89c6\u9891\u6d41\u4e2d\u68c0\u6d4b\u670d\u52a1\u673a\u4f1a\u5e76\u63d0\u4f9b\u4e2a\u6027\u5316\u670d\u52a1\u3002", "motivation": "\u73b0\u6709AI\u670d\u52a1\u5927\u591a\u662f\u88ab\u52a8\u54cd\u5e94\u5f0f\u7684\uff0c\u771f\u6b63\u667a\u80fd\u7684\u52a9\u624b\u5e94\u8be5\u80fd\u591f\u9884\u89c1\u7528\u6237\u9700\u6c42\u5e76\u5728\u9002\u5f53\u65f6\u673a\u4e3b\u52a8\u91c7\u53d6\u884c\u52a8\u3002", "method": "\u57fa\u4e8eAI\u773c\u955c\u6784\u5efaAlpha-Service\u7edf\u4e00\u6846\u67b6\uff0c\u5305\u542b\u8f93\u5165\u5355\u5143\u3001\u4e2d\u592e\u5904\u7406\u5355\u5143\u3001\u7b97\u672f\u903b\u8f91\u5355\u5143\u3001\u5185\u5b58\u5355\u5143\u548c\u8f93\u51fa\u5355\u5143\u4e94\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff0c\u91c7\u7528\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5b9e\u73b0\u3002", "result": "\u901a\u8fc7\u5b9e\u65f621\u70b9\u987e\u95ee\u3001\u535a\u7269\u9986\u5bfc\u89c8\u548c\u8d2d\u7269\u642d\u914d\u52a9\u624b\u7b49\u6848\u4f8b\u7814\u7a76\uff0c\u8bc1\u660e\u7cfb\u7edf\u80fd\u591f\u65e0\u7f1d\u611f\u77e5\u73af\u5883\u3001\u63a8\u65ad\u7528\u6237\u610f\u56fe\uff0c\u65e0\u9700\u660e\u786e\u63d0\u793a\u5373\u53ef\u63d0\u4f9b\u53ca\u65f6\u6709\u7528\u7684\u5e2e\u52a9\u3002", "conclusion": "AI4Service\u8303\u5f0f\u5c06AI\u4ece\u88ab\u52a8\u5de5\u5177\u8f6c\u53d8\u4e3a\u4e3b\u52a8\u4f34\u4fa3\uff0cAlpha-Service\u6846\u67b6\u4e3a\u89e3\u51b3\"\u4f55\u65f6\u5e72\u9884\"\u548c\"\u5982\u4f55\u670d\u52a1\"\u4e24\u5927\u6311\u6218\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2510.14387", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14387", "abs": "https://arxiv.org/abs/2510.14387", "authors": ["Yijie Hu", "Zihao Zhou", "Kaizhu Huang", "Xiaowei Huang", "Qiufeng Wang"], "title": "Can MLLMs Absorb Math Reasoning Abilities from LLMs as Free Lunch?", "comment": null, "summary": "Math reasoning has been one crucial ability of large language models (LLMs),\nwhere significant advancements have been achieved in recent years. However,\nmost efforts focus on LLMs by curating high-quality annotation data and\nintricate training (or inference) paradigms, while the math reasoning\nperformance of multi-modal LLMs (MLLMs) remains lagging behind. Since the MLLM\ntypically consists of an LLM and a vision block, we wonder: Can MLLMs directly\nabsorb math reasoning abilities from off-the-shelf math LLMs without tuning?\nRecent model-merging approaches may offer insights into this question. However,\nthey overlook the alignment between the MLLM and LLM, where we find that there\nis a large gap between their parameter spaces, resulting in lower performance.\nOur empirical evidence reveals two key factors behind this issue: the\nidentification of crucial reasoning-associated layers in the model and the\nmitigation of the gaps in parameter space. Based on the empirical insights, we\npropose IP-Merging that first identifies the reasoning-associated parameters in\nboth MLLM and Math LLM, then projects them into the subspace of MLLM, aiming to\nmaintain the alignment, and finally merges parameters in this subspace.\nIP-Merging is a tuning-free approach since parameters are directly adjusted.\nExtensive experiments demonstrate that our IP-Merging method can enhance the\nmath reasoning ability of MLLMs directly from Math LLMs without compromising\ntheir other capabilities.", "AI": {"tldr": "IP-Merging\u662f\u4e00\u79cd\u65e0\u9700\u8c03\u4f18\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522b\u591a\u6a21\u6001\u5927\u6a21\u578b\u548c\u6570\u5b66\u5927\u6a21\u578b\u4e2d\u7684\u63a8\u7406\u76f8\u5173\u53c2\u6570\uff0c\u5c06\u5176\u6295\u5f71\u5230\u591a\u6a21\u6001\u5927\u6a21\u578b\u7684\u5b50\u7a7a\u95f4\u4e2d\u8fdb\u884c\u5408\u5e76\uff0c\u4ece\u800c\u76f4\u63a5\u63d0\u5347\u591a\u6a21\u6001\u5927\u6a21\u578b\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u80fd\u529b\u4e0a\u843d\u540e\u4e8e\u7eaf\u6587\u672c\u5927\u6a21\u578b\uff0c\u4f46\u76f4\u63a5\u5408\u5e76\u6a21\u578b\u53c2\u6570\u5b58\u5728\u5bf9\u9f50\u95ee\u9898\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u8ba9\u591a\u6a21\u6001\u5927\u6a21\u578b\u76f4\u63a5\u4ece\u73b0\u6210\u7684\u6570\u5b66\u5927\u6a21\u578b\u4e2d\u5438\u6536\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u800c\u65e0\u9700\u8fdb\u884c\u590d\u6742\u7684\u8bad\u7ec3\u3002", "method": "\u63d0\u51faIP-Merging\u65b9\u6cd5\uff1a1\uff09\u8bc6\u522b\u591a\u6a21\u6001\u5927\u6a21\u578b\u548c\u6570\u5b66\u5927\u6a21\u578b\u4e2d\u7684\u63a8\u7406\u76f8\u5173\u53c2\u6570\uff1b2\uff09\u5c06\u8fd9\u4e9b\u53c2\u6570\u6295\u5f71\u5230\u591a\u6a21\u6001\u5927\u6a21\u578b\u7684\u5b50\u7a7a\u95f4\u4e2d\uff1b3\uff09\u5728\u8be5\u5b50\u7a7a\u95f4\u4e2d\u5408\u5e76\u53c2\u6570\u3002\u6574\u4e2a\u8fc7\u7a0b\u65e0\u9700\u8c03\u4f18\uff0c\u76f4\u63a5\u8c03\u6574\u53c2\u6570\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cIP-Merging\u65b9\u6cd5\u80fd\u591f\u5728\u4e0d\u635f\u5bb3\u591a\u6a21\u6001\u5927\u6a21\u578b\u5176\u4ed6\u80fd\u529b\u7684\u524d\u63d0\u4e0b\uff0c\u76f4\u63a5\u4ece\u6570\u5b66\u5927\u6a21\u578b\u4e2d\u589e\u5f3a\u5176\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "IP-Merging\u662f\u4e00\u79cd\u6709\u6548\u7684\u6a21\u578b\u5408\u5e76\u65b9\u6cd5\uff0c\u80fd\u591f\u89e3\u51b3\u591a\u6a21\u6001\u5927\u6a21\u578b\u4e0e\u6570\u5b66\u5927\u6a21\u578b\u53c2\u6570\u7a7a\u95f4\u4e0d\u5bf9\u9f50\u7684\u95ee\u9898\uff0c\u6210\u529f\u5c06\u6570\u5b66\u63a8\u7406\u80fd\u529b\u8fc1\u79fb\u5230\u591a\u6a21\u6001\u5927\u6a21\u578b\u4e2d\u3002"}}
{"id": "2510.14670", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.14670", "abs": "https://arxiv.org/abs/2510.14670", "authors": ["Marco Simoni", "Aleksandar Fontana", "Andrea Saracino", "Paolo Mori"], "title": "TITAN: Graph-Executable Reasoning for Cyber Threat Intelligence", "comment": null, "summary": "TITAN (Threat Intelligence Through Automated Navigation) is a framework that\nconnects natural-language cyber threat queries with executable reasoning over a\nstructured knowledge graph. It integrates a path planner model, which predicts\nlogical relation chains from text, and a graph executor that traverses the\nTITAN Ontology to retrieve factual answers and supporting evidence. Unlike\ntraditional retrieval systems, TITAN operates on a typed, bidirectional graph\nderived from MITRE, allowing reasoning to move clearly and reversibly between\nthreats, behaviors, and defenses. To support training and evaluation, we\nintroduce the TITAN Dataset, a corpus of 88209 examples (Train: 74258; Test:\n13951) pairing natural language questions with executable reasoning paths and\nstep by step Chain of Thought explanations. Empirical evaluations show that\nTITAN enables models to generate syntactically valid and semantically coherent\nreasoning paths that can be deterministically executed on the underlying graph.", "AI": {"tldr": "TITAN\u662f\u4e00\u4e2a\u5c06\u81ea\u7136\u8bed\u8a00\u7f51\u7edc\u5b89\u5168\u5a01\u80c1\u67e5\u8be2\u4e0e\u7ed3\u6784\u5316\u77e5\u8bc6\u56fe\u8c31\u4e0a\u7684\u53ef\u6267\u884c\u63a8\u7406\u76f8\u8fde\u63a5\u7684\u6846\u67b6\uff0c\u5305\u542b\u8def\u5f84\u89c4\u5212\u6a21\u578b\u548c\u56fe\u904d\u5386\u6267\u884c\u5668\u3002", "motivation": "\u4f20\u7edf\u68c0\u7d22\u7cfb\u7edf\u65e0\u6cd5\u5728\u5a01\u80c1\u3001\u884c\u4e3a\u548c\u9632\u5fa1\u4e4b\u95f4\u8fdb\u884c\u6e05\u6670\u53ef\u9006\u7684\u63a8\u7406\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u8fde\u63a5\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u4e0e\u7ed3\u6784\u5316\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u7684\u6846\u67b6\u3002", "method": "\u96c6\u6210\u8def\u5f84\u89c4\u5212\u6a21\u578b\u9884\u6d4b\u6587\u672c\u4e2d\u7684\u903b\u8f91\u5173\u7cfb\u94fe\uff0c\u5e76\u4f7f\u7528\u56fe\u6267\u884c\u5668\u904d\u5386TITAN\u672c\u4f53\u56fe\u6765\u68c0\u7d22\u4e8b\u5b9e\u7b54\u6848\u548c\u652f\u6491\u8bc1\u636e\u3002\u57fa\u4e8eMITRE\u6784\u5efa\u7c7b\u578b\u5316\u53cc\u5411\u56fe\u3002", "result": "\u521b\u5efa\u4e86\u5305\u542b88209\u4e2a\u793a\u4f8b\u7684TITAN\u6570\u636e\u96c6\uff0c\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793aTITAN\u80fd\u751f\u6210\u8bed\u6cd5\u6709\u6548\u4e14\u8bed\u4e49\u8fde\u8d2f\u7684\u63a8\u7406\u8def\u5f84\uff0c\u53ef\u5728\u5e95\u5c42\u56fe\u4e0a\u786e\u5b9a\u6027\u6267\u884c\u3002", "conclusion": "TITAN\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u81ea\u7136\u8bed\u8a00\u5a01\u80c1\u67e5\u8be2\u4e0e\u7ed3\u6784\u5316\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u7684\u6709\u6548\u8fde\u63a5\uff0c\u652f\u6301\u6e05\u6670\u53ef\u9006\u7684\u5a01\u80c1\u63a8\u7406\u8fc7\u7a0b\u3002"}}
{"id": "2510.14388", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14388", "abs": "https://arxiv.org/abs/2510.14388", "authors": ["Zhe Wu", "Hongjin Lu", "Junliang Xing", "Changhao Zhang", "Yin Zhu", "Yuhao Yang", "Yuheng Jing", "Kai Li", "Kun Shao", "Jianye Hao", "Jun Wang", "Yuanchun Shi"], "title": "Hi-Agent: Hierarchical Vision-Language Agents for Mobile Device Control", "comment": null, "summary": "Building agents that autonomously operate mobile devices has attracted\nincreasing attention. While Vision-Language Models (VLMs) show promise, most\nexisting approaches rely on direct state-to-action mappings, which lack\nstructured reasoning and planning, and thus generalize poorly to novel tasks or\nunseen UI layouts. We introduce Hi-Agent, a trainable hierarchical\nvision-language agent for mobile control, featuring a high-level reasoning\nmodel and a low-level action model that are jointly optimized. For efficient\ntraining, we reformulate multi-step decision-making as a sequence of\nsingle-step subgoals and propose a foresight advantage function, which\nleverages execution feedback from the low-level model to guide high-level\noptimization. This design alleviates the path explosion issue encountered by\nGroup Relative Policy Optimization (GRPO) in long-horizon tasks and enables\nstable, critic-free joint training. Hi-Agent achieves a new State-Of-The-Art\n(SOTA) 87.9% task success rate on the Android-in-the-Wild (AitW) benchmark,\nsignificantly outperforming prior methods across three paradigms: prompt-based\n(AppAgent: 17.7%), supervised (Filtered BC: 54.5%), and reinforcement\nlearning-based (DigiRL: 71.9%). It also demonstrates competitive zero-shot\ngeneralization on the ScreenSpot-v2 benchmark. On the more challenging\nAndroidWorld benchmark, Hi-Agent also scales effectively with larger backbones,\nshowing strong adaptability in high-complexity mobile control scenarios.", "AI": {"tldr": "Hi-Agent\u662f\u4e00\u4e2a\u53ef\u8bad\u7ec3\u7684\u5206\u5c42\u89c6\u89c9\u8bed\u8a00\u4ee3\u7406\uff0c\u7528\u4e8e\u79fb\u52a8\u8bbe\u5907\u63a7\u5236\uff0c\u901a\u8fc7\u9ad8\u5c42\u63a8\u7406\u6a21\u578b\u548c\u4f4e\u5c42\u52a8\u4f5c\u6a21\u578b\u7684\u8054\u5408\u4f18\u5316\uff0c\u5728Android-in-the-Wild\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e8687.9%\u7684\u4efb\u52a1\u6210\u529f\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u79fb\u52a8\u8bbe\u5907\u63a7\u5236\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u76f4\u63a5\u7684\u72b6\u6001\u5230\u52a8\u4f5c\u6620\u5c04\uff0c\u7f3a\u4e4f\u7ed3\u6784\u5316\u63a8\u7406\u548c\u89c4\u5212\uff0c\u5bfc\u81f4\u5728\u65b0\u578b\u4efb\u52a1\u6216\u672a\u89c1UI\u5e03\u5c40\u4e0a\u6cdb\u5316\u80fd\u529b\u5dee\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u67b6\u6784\uff0c\u5305\u542b\u9ad8\u5c42\u63a8\u7406\u6a21\u578b\u548c\u4f4e\u5c42\u52a8\u4f5c\u6a21\u578b\uff0c\u901a\u8fc7\u5c06\u591a\u6b65\u51b3\u7b56\u91cd\u65b0\u8868\u8ff0\u4e3a\u5355\u6b65\u5b50\u76ee\u6807\u5e8f\u5217\uff0c\u5e76\u5f15\u5165\u524d\u77bb\u4f18\u52bf\u51fd\u6570\uff0c\u5229\u7528\u4f4e\u5c42\u6a21\u578b\u7684\u6267\u884c\u53cd\u9988\u6765\u6307\u5bfc\u9ad8\u5c42\u4f18\u5316\uff0c\u7f13\u89e3\u957f\u65f6\u4efb\u52a1\u4e2d\u7684\u8def\u5f84\u7206\u70b8\u95ee\u9898\u3002", "result": "\u5728Android-in-the-Wild\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523087.9%\u7684\u4efb\u52a1\u6210\u529f\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u63d0\u793a\u578b(17.7%)\u3001\u76d1\u7763\u5b66\u4e60(54.5%)\u548c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5(71.9%)\uff0c\u5728ScreenSpot-v2\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u73b0\u51fa\u7ade\u4e89\u529b\u7684\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "Hi-Agent\u901a\u8fc7\u5206\u5c42\u8bbe\u8ba1\u548c\u8054\u5408\u4f18\u5316\u65b9\u6cd5\uff0c\u5728\u79fb\u52a8\u8bbe\u5907\u63a7\u5236\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u5728\u9ad8\u590d\u6742\u5ea6\u573a\u666f\u4e2d\u5c55\u73b0\u51fa\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2510.14406", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.14406", "abs": "https://arxiv.org/abs/2510.14406", "authors": ["Xikai Zhang", "Bo Wang", "Likang Xiao", "Yongzhi Li", "Quan Chen", "Wenju Wu", "Liu Liu"], "title": "IMAGINE: Integrating Multi-Agent System into One Model for Complex Reasoning and Planning", "comment": null, "summary": "Although large language models (LLMs) have made significant strides across\nvarious tasks, they still face significant challenges in complex reasoning and\nplanning. For example, even with carefully designed prompts and prior\ninformation explicitly provided, GPT-4o achieves only a 7% Final Pass Rate on\nthe TravelPlanner dataset in the sole-planning mode. Similarly, even in the\nthinking mode, Qwen3-8B-Instruct and DeepSeek-R1-671B, only achieve Final Pass\nRates of 5.9% and 40%, respectively. Although well-organized Multi-Agent\nSystems (MAS) can offer improved collective reasoning, they often suffer from\nhigh reasoning costs due to multi-round internal interactions, long\nper-response latency, and difficulties in end-to-end training. To address these\nchallenges, we propose a general and scalable framework called IMAGINE, short\nfor Integrating Multi-Agent System into One Model. This framework not only\nintegrates the reasoning and planning capabilities of MAS into a single,\ncompact model, but also significantly surpass the capabilities of the MAS\nthrough a simple end-to-end training. Through this pipeline, a single\nsmall-scale model is not only able to acquire the structured reasoning and\nplanning capabilities of a well-organized MAS but can also significantly\noutperform it. Experimental results demonstrate that, when using\nQwen3-8B-Instruct as the base model and training it with our method, the model\nachieves an 82.7% Final Pass Rate on the TravelPlanner benchmark, far exceeding\nthe 40% of DeepSeek-R1-671B, while maintaining a much smaller model size.", "AI": {"tldr": "\u63d0\u51faIMAGINE\u6846\u67b6\uff0c\u5c06\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u63a8\u7406\u89c4\u5212\u80fd\u529b\u96c6\u6210\u5230\u5355\u4e00\u7d27\u51d1\u6a21\u578b\u4e2d\uff0c\u901a\u8fc7\u7aef\u5230\u7aef\u8bad\u7ec3\u663e\u8457\u8d85\u8d8a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6027\u80fd", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u548c\u89c4\u5212\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u867d\u80fd\u63d0\u5347\u96c6\u4f53\u63a8\u7406\u80fd\u529b\u4f46\u5b58\u5728\u63a8\u7406\u6210\u672c\u9ad8\u3001\u5ef6\u8fdf\u957f\u548c\u8bad\u7ec3\u56f0\u96be\u7b49\u95ee\u9898", "method": "IMAGINE\u6846\u67b6\u5c06\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u80fd\u529b\u96c6\u6210\u5230\u5355\u4e00\u6a21\u578b\u4e2d\uff0c\u901a\u8fc7\u7b80\u5355\u7684\u7aef\u5230\u7aef\u8bad\u7ec3\u5b9e\u73b0\u80fd\u529b\u8d85\u8d8a", "result": "\u4f7f\u7528Qwen3-8B-Instruct\u4f5c\u4e3a\u57fa\u7840\u6a21\u578b\uff0c\u5728TravelPlanner\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523082.7%\u6700\u7ec8\u901a\u8fc7\u7387\uff0c\u8fdc\u8d85DeepSeek-R1-671B\u768440%", "conclusion": "\u5355\u4e00\u5c0f\u89c4\u6a21\u6a21\u578b\u4e0d\u4ec5\u80fd\u83b7\u5f97\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u7ed3\u6784\u5316\u63a8\u7406\u89c4\u5212\u80fd\u529b\uff0c\u8fd8\u80fd\u663e\u8457\u8d85\u8d8a\u5176\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u66f4\u5c0f\u7684\u6a21\u578b\u89c4\u6a21"}}
{"id": "2510.14900", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14900", "abs": "https://arxiv.org/abs/2510.14900", "authors": ["Wen-Kwang Tsao", "Yao-Ching Yu", "Chien-Ming Huang"], "title": "Mapping Smarter, Not Harder: A Test-Time Reinforcement Learning Agent That Improves Without Labels or Model Updates", "comment": null, "summary": "The Enterprise Intelligence Platform must integrate logs from numerous\nthird-party vendors in order to perform various downstream tasks. However,\nvendor documentation is often unavailable at test time. It is either misplaced,\nmismatched, poorly formatted, or incomplete, which makes schema mapping\nchallenging. We introduce a reinforcement learning agent that can self-improve\nwithout labeled examples or model weight updates. During inference, the agent:\n1) Identifies ambiguous field-mapping attempts. 2) Generates targeted\nweb-search queries to gather external evidence. 3) Applies a confidence-based\nreward to iteratively refine its mappings. To demonstrate this concept, we\nconverted Microsoft Defender for Endpoint logs into a common schema. Our method\nincreased mapping accuracy from 56.4\\%(LLM-only) to 72.73\\%(RAG) to 93.94\\%\nover 100 iterations using GPT-4o. At the same time, it reduced the number of\nlow-confidence mappings requiring expert review by 85\\%. This new approach\nprovides an evidence-driven, transparent method for solving future industry\nproblems, paving the way for more robust, accountable, scalable, efficient,\nflexible, adaptable, and collaborative solutions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u6807\u6ce8\u6570\u636e\u6216\u6a21\u578b\u6743\u91cd\u66f4\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\uff0c\u901a\u8fc7\u751f\u6210\u7f51\u7edc\u641c\u7d22\u67e5\u8be2\u83b7\u53d6\u5916\u90e8\u8bc1\u636e\u6765\u81ea\u6211\u6539\u8fdb\u6a21\u5f0f\u6620\u5c04\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4f01\u4e1a\u667a\u80fd\u5e73\u53f0\u4e2d\u7b2c\u4e09\u65b9\u65e5\u5fd7\u7684\u6620\u5c04\u51c6\u786e\u6027\u3002", "motivation": "\u4f01\u4e1a\u667a\u80fd\u5e73\u53f0\u9700\u8981\u96c6\u6210\u5927\u91cf\u7b2c\u4e09\u65b9\u4f9b\u5e94\u5546\u7684\u65e5\u5fd7\uff0c\u4f46\u4f9b\u5e94\u5546\u6587\u6863\u5728\u6d4b\u8bd5\u65f6\u5e38\u5e38\u4e0d\u53ef\u7528\u3001\u4e0d\u5339\u914d\u6216\u683c\u5f0f\u6df7\u4e71\uff0c\u5bfc\u81f4\u6a21\u5f0f\u6620\u5c04\u56f0\u96be\u3002", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\uff1a1)\u8bc6\u522b\u6a21\u7cca\u7684\u5b57\u6bb5\u6620\u5c04\u5c1d\u8bd5\uff1b2)\u751f\u6210\u9488\u5bf9\u6027\u7f51\u7edc\u641c\u7d22\u67e5\u8be2\u6536\u96c6\u5916\u90e8\u8bc1\u636e\uff1b3)\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u5956\u52b1\u8fed\u4ee3\u4f18\u5316\u6620\u5c04\u3002", "result": "\u5728\u5fae\u8f6f\u7aef\u70b9\u9632\u62a4\u65e5\u5fd7\u5230\u901a\u7528\u6a21\u5f0f\u7684\u8f6c\u6362\u4e2d\uff0c\u6620\u5c04\u51c6\u786e\u7387\u4ece56.4%(\u4ec5LLM)\u63d0\u5347\u523072.73%(RAG)\u518d\u523093.94%(100\u6b21\u8fed\u4ee3\u540e)\uff0c\u540c\u65f6\u5c06\u9700\u8981\u4e13\u5bb6\u5ba1\u67e5\u7684\u4f4e\u7f6e\u4fe1\u5ea6\u6620\u5c04\u51cf\u5c11\u4e8685%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u672a\u6765\u884c\u4e1a\u95ee\u9898\u63d0\u4f9b\u4e86\u8bc1\u636e\u9a71\u52a8\u3001\u900f\u660e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u66f4\u7a33\u5065\u3001\u53ef\u95ee\u8d23\u3001\u53ef\u6269\u5c55\u3001\u9ad8\u6548\u3001\u7075\u6d3b\u3001\u9002\u5e94\u6027\u5f3a\u548c\u534f\u4f5c\u7684\u89e3\u51b3\u65b9\u6848\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2510.14412", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14412", "abs": "https://arxiv.org/abs/2510.14412", "authors": ["Claudia Grundke", "Gabriele R\u00f6ger"], "title": "Eliminating Negative Occurrences of Derived Predicates from PDDL Axioms", "comment": "Extended version of a paper of the same title presented at the joint\n  KR/ICAPS 2025 workshop \"KRPlan: Knowledge Representation Meets Automated\n  Planning\"", "summary": "Axioms are a feature of the Planning Domain Definition Language PDDL that can\nbe considered as a generalization of database query languages such as Datalog.\nThe PDDL standard restricts negative occurrences of predicates in axiom bodies\nto predicates that are directly set by actions and not derived by axioms. In\nthe literature, authors often deviate from this limitation and only require\nthat the set of axioms is stratifiable. Both variants can express exactly the\nsame queries as least fixed-point logic, indicating that negative occurrences\nof derived predicates can be eliminated. We present the corresponding\ntransformation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8f6c\u6362\u65b9\u6cd5\uff0c\u7528\u4e8e\u6d88\u9664PDDL\u516c\u7406\u4e2d\u6d3e\u751f\u8c13\u8bcd\u7684\u8d1f\u51fa\u73b0\uff0c\u8bc1\u660e\u8fd9\u79cd\u9650\u5236\u53ef\u4ee5\u88ab\u514b\u670d\u3002", "motivation": "PDDL\u6807\u51c6\u9650\u5236\u516c\u7406\u4f53\u4e2d\u8c13\u8bcd\u7684\u8d1f\u51fa\u73b0\u53ea\u80fd\u9488\u5bf9\u76f4\u63a5\u7531\u52a8\u4f5c\u8bbe\u7f6e\u7684\u8c13\u8bcd\uff0c\u800c\u975e\u7531\u516c\u7406\u6d3e\u751f\u7684\u8c13\u8bcd\u3002\u4f46\u6587\u732e\u4e2d\u4f5c\u8005\u5e38\u504f\u79bb\u6b64\u9650\u5236\uff0c\u4ec5\u8981\u6c42\u516c\u7406\u96c6\u53ef\u5206\u5c42\u3002", "method": "\u63d0\u51fa\u76f8\u5e94\u7684\u8f6c\u6362\u65b9\u6cd5\uff0c\u8bc1\u660e\u8d1f\u51fa\u73b0\u7684\u6d3e\u751f\u8c13\u8bcd\u53ef\u4ee5\u88ab\u6d88\u9664\u3002", "result": "\u4e24\u79cd\u53d8\u4f53\u90fd\u80fd\u8868\u8fbe\u4e0e\u6700\u5c0f\u4e0d\u52a8\u70b9\u903b\u8f91\u5b8c\u5168\u76f8\u540c\u7684\u67e5\u8be2\u3002", "conclusion": "\u901a\u8fc7\u63d0\u51fa\u7684\u8f6c\u6362\uff0c\u53ef\u4ee5\u6d88\u9664PDDL\u516c\u7406\u4e2d\u6d3e\u751f\u8c13\u8bcd\u7684\u8d1f\u51fa\u73b0\u9650\u5236\u3002"}}
{"id": "2510.14512", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14512", "abs": "https://arxiv.org/abs/2510.14512", "authors": ["Haoyuan Li", "Mathias Funk", "Aaqib Saeed"], "title": "Helmsman: Autonomous Synthesis of Federated Learning Systems via Multi-Agent Collaboration", "comment": null, "summary": "Federated Learning (FL) offers a powerful paradigm for training models on\ndecentralized data, but its promise is often undermined by the immense\ncomplexity of designing and deploying robust systems. The need to select,\ncombine, and tune strategies for multifaceted challenges like data\nheterogeneity and system constraints has become a critical bottleneck,\nresulting in brittle, bespoke solutions. To address this, we introduce\nHelmsman, a novel multi-agent system that automates the end-to-end synthesis of\nfederated learning systems from high-level user specifications. It emulates a\nprincipled research and development workflow through three collaborative\nphases: (1) interactive human-in-the-loop planning to formulate a sound\nresearch plan, (2) modular code generation by supervised agent teams, and (3) a\nclosed-loop of autonomous evaluation and refinement in a sandboxed simulation\nenvironment. To facilitate rigorous evaluation, we also introduce\nAgentFL-Bench, a new benchmark comprising 16 diverse tasks designed to assess\nthe system-level generation capabilities of agentic systems in FL. Extensive\nexperiments demonstrate that our approach generates solutions competitive with,\nand often superior to, established hand-crafted baselines. Our work represents\na significant step towards the automated engineering of complex decentralized\nAI systems.", "AI": {"tldr": "Helmsman\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u6a21\u62df\u7814\u53d1\u5de5\u4f5c\u6d41\u7a0b\u81ea\u52a8\u5408\u6210\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\uff0c\u5305\u542b\u4ea4\u4e92\u5f0f\u89c4\u5212\u3001\u6a21\u5757\u5316\u4ee3\u7801\u751f\u6210\u548c\u81ea\u4e3b\u8bc4\u4f30\u4e09\u4e2a\u9636\u6bb5\uff0c\u5728AgentFL-Bench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u624b\u5de5\u57fa\u7ebf\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u8bbe\u8ba1\u590d\u6742\uff0c\u9700\u8981\u5e94\u5bf9\u6570\u636e\u5f02\u6784\u6027\u548c\u7cfb\u7edf\u7ea6\u675f\u7b49\u591a\u65b9\u9762\u6311\u6218\uff0c\u5f53\u524d\u65b9\u6cd5\u5f80\u5f80\u4ea7\u751f\u8106\u5f31\u3001\u5b9a\u5236\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6210\u4e3a\u5173\u952e\u74f6\u9888\u3002", "method": "Helmsman\u91c7\u7528\u4e09\u9636\u6bb5\u65b9\u6cd5\uff1a(1)\u4ea4\u4e92\u5f0f\u4eba\u673a\u534f\u4f5c\u89c4\u5212\u5236\u5b9a\u7814\u7a76\u8ba1\u5212\uff1b(2)\u76d1\u7763\u667a\u80fd\u4f53\u56e2\u961f\u8fdb\u884c\u6a21\u5757\u5316\u4ee3\u7801\u751f\u6210\uff1b(3)\u5728\u6c99\u76d2\u4eff\u771f\u73af\u5883\u4e2d\u8fdb\u884c\u81ea\u4e3b\u8bc4\u4f30\u548c\u4f18\u5316\u7684\u95ed\u73af\u6d41\u7a0b\u3002", "result": "\u5728\u5305\u542b16\u4e2a\u591a\u6837\u5316\u4efb\u52a1\u7684AgentFL-Bench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cHelmsman\u751f\u6210\u7684\u89e3\u51b3\u65b9\u6848\u4e0e\u624b\u5de5\u57fa\u7ebf\u76f8\u5f53\u751a\u81f3\u66f4\u4f18\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4ee3\u8868\u4e86\u5411\u590d\u6742\u53bb\u4e2d\u5fc3\u5316AI\u7cfb\u7edf\u81ea\u52a8\u5316\u5de5\u7a0b\u8fc8\u51fa\u7684\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2510.14537", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14537", "abs": "https://arxiv.org/abs/2510.14537", "authors": ["Emanuele Antonioni", "Stefan Markovic", "Anirudha Shankar", "Jaime Bernardo", "Lovro Markovic", "Silvia Pareti", "Benedetto Proietti"], "title": "JSPLIT: A Taxonomy-based Solution for Prompt Bloating in Model Context Protocol", "comment": null, "summary": "AI systems are continually evolving and advancing, and user expectations are\nconcurrently increasing, with a growing demand for interactions that go beyond\nsimple text-based interaction with Large Language Models (LLMs). Today's\napplications often require LLMs to interact with external tools, marking a\nshift toward more complex agentic systems. To support this, standards such as\nthe Model Context Protocol (MCP) have emerged, enabling agents to access tools\nby including a specification of the capabilities of each tool within the\nprompt. Although this approach expands what agents can do, it also introduces a\ngrowing problem: prompt bloating. As the number of tools increases, the prompts\nbecome longer, leading to high prompt token costs, increased latency, and\nreduced task success resulting from the selection of tools irrelevant to the\nprompt. To address this issue, we introduce JSPLIT, a taxonomy-driven framework\ndesigned to help agents manage prompt size more effectively when using large\nsets of MCP tools. JSPLIT organizes the tools into a hierarchical taxonomy and\nuses the user's prompt to identify and include only the most relevant tools,\nbased on both the query and the taxonomy structure. In this paper, we describe\nthe design of the taxonomy, the tool selection algorithm, and the dataset used\nto evaluate JSPLIT. Our results show that JSPLIT significantly reduces prompt\nsize without significantly compromising the agent's ability to respond\neffectively. As the number of available tools for the agent grows\nsubstantially, JSPLIT even improves the tool selection accuracy of the agent,\neffectively reducing costs while simultaneously improving task success in\nhigh-complexity agent environments.", "AI": {"tldr": "JSPLIT\u662f\u4e00\u4e2a\u57fa\u4e8e\u5206\u7c7b\u5b66\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5c42\u6b21\u5316\u7ec4\u7ec7MCP\u5de5\u5177\u5e76\u57fa\u4e8e\u7528\u6237\u63d0\u793a\u9009\u62e9\u6700\u76f8\u5173\u5de5\u5177\uff0c\u6709\u6548\u89e3\u51b3\u63d0\u793a\u81a8\u80c0\u95ee\u9898\uff0c\u5728\u663e\u8457\u51cf\u5c11\u63d0\u793a\u5927\u5c0f\u7684\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u63d0\u5347\u4ee3\u7406\u6027\u80fd\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u53d1\u5c55\uff0c\u7528\u6237\u671f\u671b\u4ece\u7b80\u5355\u7684\u6587\u672c\u4ea4\u4e92\u8f6c\u5411\u66f4\u590d\u6742\u7684\u4ee3\u7406\u7cfb\u7edf\u3002MCP\u7b49\u6807\u51c6\u4f7f\u4ee3\u7406\u80fd\u591f\u8bbf\u95ee\u5916\u90e8\u5de5\u5177\uff0c\u4f46\u968f\u7740\u5de5\u5177\u6570\u91cf\u589e\u52a0\uff0c\u63d0\u793a\u53d8\u5f97\u5197\u957f\uff0c\u5bfc\u81f4\u9ad8token\u6210\u672c\u3001\u5ef6\u8fdf\u589e\u52a0\u548c\u4efb\u52a1\u6210\u529f\u7387\u4e0b\u964d\u3002", "method": "\u63d0\u51faJSPLIT\u6846\u67b6\uff1a1\uff09\u5c06\u5de5\u5177\u7ec4\u7ec7\u6210\u5c42\u6b21\u5316\u5206\u7c7b\u5b66\u7ed3\u6784\uff1b2\uff09\u57fa\u4e8e\u7528\u6237\u63d0\u793a\u548c\u5206\u7c7b\u5b66\u7ed3\u6784\u8bc6\u522b\u5e76\u4ec5\u5305\u542b\u6700\u76f8\u5173\u5de5\u5177\uff1b3\uff09\u8bbe\u8ba1\u5de5\u5177\u9009\u62e9\u7b97\u6cd5\u3002", "result": "JSPLIT\u663e\u8457\u51cf\u5c11\u4e86\u63d0\u793a\u5927\u5c0f\uff0c\u4e14\u672a\u663e\u8457\u5f71\u54cd\u4ee3\u7406\u54cd\u5e94\u80fd\u529b\u3002\u5f53\u53ef\u7528\u5de5\u5177\u6570\u91cf\u5927\u5e45\u589e\u52a0\u65f6\uff0cJSPLIT\u751a\u81f3\u63d0\u9ad8\u4e86\u5de5\u5177\u9009\u62e9\u51c6\u786e\u6027\uff0c\u5728\u964d\u4f4e\u6210\u672c\u7684\u540c\u65f6\u6539\u5584\u4e86\u9ad8\u590d\u6742\u5ea6\u73af\u5883\u4e2d\u7684\u4efb\u52a1\u6210\u529f\u7387\u3002", "conclusion": "JSPLIT\u901a\u8fc7\u5206\u7c7b\u5b66\u9a71\u52a8\u7684\u65b9\u6cd5\u6709\u6548\u7ba1\u7406\u63d0\u793a\u5927\u5c0f\uff0c\u89e3\u51b3\u4e86\u5de5\u5177\u6570\u91cf\u589e\u52a0\u5bfc\u81f4\u7684\u63d0\u793a\u81a8\u80c0\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u4ee3\u7406\u6027\u80fd\u7684\u540c\u65f6\u964d\u4f4e\u4e86\u6210\u672c\uff0c\u9002\u7528\u4e8e\u590d\u6742\u7684\u4ee3\u7406\u73af\u5883\u3002"}}
{"id": "2510.14538", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14538", "abs": "https://arxiv.org/abs/2510.14538", "authors": ["Emanuele Marconato", "Samuele Bortolotti", "Emile van Krieken", "Paolo Morettin", "Elena Umili", "Antonio Vergari", "Efthymia Tsamoura", "Andrea Passerini", "Stefano Teso"], "title": "Symbol Grounding in Neuro-Symbolic AI: A Gentle Introduction to Reasoning Shortcuts", "comment": null, "summary": "Neuro-symbolic (NeSy) AI aims to develop deep neural networks whose\npredictions comply with prior knowledge encoding, e.g. safety or structural\nconstraints. As such, it represents one of the most promising avenues for\nreliable and trustworthy AI. The core idea behind NeSy AI is to combine neural\nand symbolic steps: neural networks are typically responsible for mapping\nlow-level inputs into high-level symbolic concepts, while symbolic reasoning\ninfers predictions compatible with the extracted concepts and the prior\nknowledge. Despite their promise, it was recently shown that - whenever the\nconcepts are not supervised directly - NeSy models can be affected by Reasoning\nShortcuts (RSs). That is, they can achieve high label accuracy by grounding the\nconcepts incorrectly. RSs can compromise the interpretability of the model's\nexplanations, performance in out-of-distribution scenarios, and therefore\nreliability. At the same time, RSs are difficult to detect and prevent unless\nconcept supervision is available, which is typically not the case. However, the\nliterature on RSs is scattered, making it difficult for researchers and\npractitioners to understand and tackle this challenging problem. This overview\naddresses this issue by providing a gentle introduction to RSs, discussing\ntheir causes and consequences in intuitive terms. It also reviews and\nelucidates existing theoretical characterizations of this phenomenon. Finally,\nit details methods for dealing with RSs, including mitigation and awareness\nstrategies, and maps their benefits and limitations. By reformulating advanced\nmaterial in a digestible form, this overview aims to provide a unifying\nperspective on RSs to lower the bar to entry for tackling them. Ultimately, we\nhope this overview contributes to the development of reliable NeSy and\ntrustworthy AI models.", "AI": {"tldr": "\u795e\u7ecf\u7b26\u53f7AI\u4e2d\u7684\u63a8\u7406\u6377\u5f84\u95ee\u9898\uff1a\u5f53\u6982\u5ff5\u672a\u88ab\u76f4\u63a5\u76d1\u7763\u65f6\uff0c\u6a21\u578b\u53ef\u80fd\u901a\u8fc7\u9519\u8bef\u7684\u6982\u5ff5\u57fa\u7840\u5b9e\u73b0\u9ad8\u51c6\u786e\u7387\uff0c\u8fd9\u4f1a\u5f71\u54cd\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3001\u5206\u5e03\u5916\u6027\u80fd\u53ca\u53ef\u9760\u6027\u3002\u672c\u6587\u63d0\u4f9b\u4e86\u63a8\u7406\u6377\u5f84\u7684\u6982\u8ff0\u3001\u539f\u56e0\u5206\u6790\u3001\u7406\u8bba\u8868\u5f81\u53ca\u5e94\u5bf9\u65b9\u6cd5\u3002", "motivation": "\u795e\u7ecf\u7b26\u53f7AI\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u548c\u7b26\u53f7\u63a8\u7406\uff0c\u662f\u5b9e\u73b0\u53ef\u9760\u53ef\u4fe1AI\u7684\u91cd\u8981\u9014\u5f84\u3002\u7136\u800c\u63a8\u7406\u6377\u5f84\u95ee\u9898\u4f1a\u635f\u5bb3\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027\uff0c\u4e14\u73b0\u6709\u7814\u7a76\u8f83\u4e3a\u5206\u6563\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u68b3\u7406\u548c\u4ecb\u7ecd\u3002", "method": "\u672c\u6587\u91c7\u7528\u7efc\u8ff0\u65b9\u6cd5\uff0c\u9996\u5148\u76f4\u89c2\u4ecb\u7ecd\u63a8\u7406\u6377\u5f84\u7684\u6982\u5ff5\u3001\u6210\u56e0\u548c\u540e\u679c\uff0c\u7136\u540e\u56de\u987e\u548c\u9610\u91ca\u73b0\u6709\u7684\u7406\u8bba\u8868\u5f81\uff0c\u6700\u540e\u8be6\u7ec6\u8ba8\u8bba\u5e94\u5bf9\u63a8\u7406\u6377\u5f84\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u7f13\u89e3\u7b56\u7565\u548c\u610f\u8bc6\u7b56\u7565\u3002", "result": "\u63d0\u4f9b\u4e86\u63a8\u7406\u6377\u5f84\u7684\u7edf\u4e00\u89c6\u89d2\uff0c\u7cfb\u7edf\u5206\u6790\u4e86\u5176\u6210\u56e0\u3001\u5f71\u54cd\u548c\u5e94\u5bf9\u7b56\u7565\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u5b9e\u8df5\u8005\u7406\u89e3\u548c\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u57fa\u7840\u3002", "conclusion": "\u901a\u8fc7\u4ee5\u6613\u4e8e\u7406\u89e3\u7684\u5f62\u5f0f\u91cd\u65b0\u9610\u8ff0\u9ad8\u7ea7\u6750\u6599\uff0c\u672c\u6587\u65e8\u5728\u964d\u4f4e\u89e3\u51b3\u63a8\u7406\u6377\u5f84\u95ee\u9898\u7684\u95e8\u69db\uff0c\u4e3a\u5f00\u53d1\u53ef\u9760\u7684\u795e\u7ecf\u7b26\u53f7AI\u548c\u53ef\u4fe1AI\u6a21\u578b\u505a\u51fa\u8d21\u732e\u3002"}}
{"id": "2510.14548", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14548", "abs": "https://arxiv.org/abs/2510.14548", "authors": ["Asen Nachkov", "Xi Wang", "Luc Van Gool"], "title": "LLM Agents Beyond Utility: An Open-Ended Perspective", "comment": null, "summary": "Recent LLM agents have made great use of chain of thought reasoning and\nfunction calling. As their capabilities grow, an important question arises: can\nthis software represent not only a smart problem-solving tool, but an entity in\nits own right, that can plan, design immediate tasks, and reason toward\nbroader, more ambiguous goals? To study this question, we adopt an open-ended\nexperimental setting where we augment a pretrained LLM agent with the ability\nto generate its own tasks, accumulate knowledge, and interact extensively with\nits environment. We study the resulting open-ended agent qualitatively. It can\nreliably follow complex multi-step instructions, store and reuse information\nacross runs, and propose and solve its own tasks, though it remains sensitive\nto prompt design, prone to repetitive task generation, and unable to form\nself-representations. These findings illustrate both the promise and current\nlimits of adapting pretrained LLMs toward open-endedness, and point to future\ndirections for training agents to manage memory, explore productively, and\npursue abstract long-term goals.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u9884\u8bad\u7ec3LLM\u4ee3\u7406\u80fd\u5426\u901a\u8fc7\u81ea\u6211\u751f\u6210\u4efb\u52a1\u3001\u79ef\u7d2f\u77e5\u8bc6\u548c\u73af\u5883\u4ea4\u4e92\uff0c\u53d1\u5c55\u6210\u5177\u6709\u81ea\u4e3b\u89c4\u5212\u548c\u63a8\u7406\u80fd\u529b\u7684\u5b9e\u4f53\u3002", "motivation": "\u7814\u7a76LLM\u4ee3\u7406\u662f\u5426\u80fd\u8d85\u8d8a\u667a\u80fd\u95ee\u9898\u89e3\u51b3\u5de5\u5177\uff0c\u6210\u4e3a\u80fd\u591f\u89c4\u5212\u3001\u8bbe\u8ba1\u4efb\u52a1\u5e76\u63a8\u7406\u6a21\u7cca\u76ee\u6807\u7684\u81ea\u4e3b\u5b9e\u4f53\u3002", "method": "\u5728\u5f00\u653e\u73af\u5883\u4e2d\u589e\u5f3a\u9884\u8bad\u7ec3LLM\u4ee3\u7406\uff0c\u4f7f\u5176\u80fd\u591f\u751f\u6210\u81ea\u5df1\u7684\u4efb\u52a1\u3001\u79ef\u7d2f\u77e5\u8bc6\u5e76\u4e0e\u73af\u5883\u5e7f\u6cdb\u4ea4\u4e92\u3002", "result": "\u4ee3\u7406\u80fd\u591f\u53ef\u9760\u6267\u884c\u590d\u6742\u591a\u6b65\u6307\u4ee4\u3001\u8de8\u8fd0\u884c\u5b58\u50a8\u548c\u91cd\u7528\u4fe1\u606f\u3001\u63d0\u51fa\u5e76\u89e3\u51b3\u81ea\u5df1\u7684\u4efb\u52a1\uff0c\u4f46\u5bf9\u63d0\u793a\u8bbe\u8ba1\u654f\u611f\u3001\u5bb9\u6613\u91cd\u590d\u751f\u6210\u4efb\u52a1\u3001\u65e0\u6cd5\u5f62\u6210\u81ea\u6211\u8868\u5f81\u3002", "conclusion": "\u7814\u7a76\u663e\u793a\u4e86\u5c06\u9884\u8bad\u7ec3LLM\u9002\u5e94\u5f00\u653e\u6027\u7684\u524d\u666f\u548c\u5f53\u524d\u5c40\u9650\uff0c\u4e3a\u8bad\u7ec3\u4ee3\u7406\u7ba1\u7406\u8bb0\u5fc6\u3001\u6709\u6548\u63a2\u7d22\u548c\u8ffd\u6c42\u62bd\u8c61\u957f\u671f\u76ee\u6807\u6307\u660e\u4e86\u672a\u6765\u65b9\u5411\u3002"}}
{"id": "2510.14621", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.14621", "abs": "https://arxiv.org/abs/2510.14621", "authors": ["Yuanyi Song", "Heyuan Huang", "Qiqiang Lin", "Yin Zhao", "Xiangmou Qu", "Jun Wang", "Xingyu Lou", "Weiwen Liu", "Zhuosheng Zhang", "Jun Wang", "Yong Yu", "Weinan Zhang", "Zhaoxiang Wang"], "title": "ColorBench: Benchmarking Mobile Agents with Graph-Structured Framework for Complex Long-Horizon Tasks", "comment": null, "summary": "The rapid advancement of multimodal large language models has enabled agents\nto operate mobile devices by directly interacting with graphical user\ninterfaces, opening new possibilities for mobile automation. However,\nreal-world mobile tasks are often complex and allow for multiple valid\nsolutions. This contradicts current mobile agent evaluation standards: offline\nstatic benchmarks can only validate a single predefined \"golden path\", while\nonline dynamic testing is constrained by the complexity and non-reproducibility\nof real devices, making both approaches inadequate for comprehensively\nassessing agent capabilities. To bridge the gap between offline and online\nevaluation and enhance testing stability, this paper introduces a novel\ngraph-structured benchmarking framework. By modeling the finite states observed\nduring real-device interactions, it achieves static simulation of dynamic\nbehaviors. Building on this, we develop ColorBench, a benchmark focused on\ncomplex long-horizon tasks. It supports evaluation of multiple valid solutions,\nsubtask completion rate statistics, and atomic-level capability analysis.\nColorBench contains 175 tasks (74 single-app, 101 cross-app) with an average\nlength of over 13 steps. Each task includes at least two correct paths and\nseveral typical error paths, enabling quasi-dynamic interaction. By evaluating\nColorBench across various baselines, we discover limitations of existing models\nand propose improvement directions and feasible technical pathways to enhance\nagents' performance on complex, long-horizon problems based on experimental\nresults. Code and data are available at:\nhttps://github.com/MadeAgents/ColorBench.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86ColorBench\uff0c\u4e00\u79cd\u57fa\u4e8e\u56fe\u7ed3\u6784\u7684\u79fb\u52a8\u4ee3\u7406\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u771f\u5b9e\u8bbe\u5907\u4ea4\u4e92\u7684\u6709\u9650\u72b6\u6001\uff0c\u5b9e\u73b0\u52a8\u6001\u884c\u4e3a\u7684\u9759\u6001\u4eff\u771f\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u5728\u590d\u6742\u957f\u65f6\u4efb\u52a1\u4e2d\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u79fb\u52a8\u4ee3\u7406\u8bc4\u4f30\u6807\u51c6\u5b58\u5728\u7f3a\u9677\uff1a\u79bb\u7ebf\u9759\u6001\u57fa\u51c6\u53ea\u80fd\u9a8c\u8bc1\u5355\u4e00\u9884\u5b9a\u4e49\u8def\u5f84\uff0c\u800c\u5728\u7ebf\u52a8\u6001\u6d4b\u8bd5\u53d7\u9650\u4e8e\u771f\u5b9e\u8bbe\u5907\u7684\u590d\u6742\u6027\u548c\u4e0d\u53ef\u91cd\u73b0\u6027\uff0c\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u4ee3\u7406\u5728\u590d\u6742\u591a\u89e3\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u56fe\u7ed3\u6784\u7684\u57fa\u51c6\u6846\u67b6\uff0c\u901a\u8fc7\u5efa\u6a21\u771f\u5b9e\u8bbe\u5907\u4ea4\u4e92\u4e2d\u7684\u6709\u9650\u72b6\u6001\uff0c\u5b9e\u73b0\u52a8\u6001\u884c\u4e3a\u7684\u9759\u6001\u4eff\u771f\u3002\u6784\u5efa\u4e86\u5305\u542b175\u4e2a\u4efb\u52a1\uff0874\u4e2a\u5355\u5e94\u7528\u3001101\u4e2a\u8de8\u5e94\u7528\uff09\u7684ColorBench\u57fa\u51c6\uff0c\u5e73\u5747\u4efb\u52a1\u957f\u5ea6\u8d85\u8fc713\u6b65\uff0c\u6bcf\u4e2a\u4efb\u52a1\u5305\u542b\u81f3\u5c11\u4e24\u6761\u6b63\u786e\u8def\u5f84\u548c\u82e5\u5e72\u5178\u578b\u9519\u8bef\u8def\u5f84\u3002", "result": "\u901a\u8fc7\u5728\u5404\u79cd\u57fa\u7ebf\u6a21\u578b\u4e0a\u8bc4\u4f30ColorBench\uff0c\u53d1\u73b0\u4e86\u73b0\u6709\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u5e76\u57fa\u4e8e\u5b9e\u9a8c\u7ed3\u679c\u63d0\u51fa\u4e86\u6539\u8fdb\u65b9\u5411\u548c\u53ef\u884c\u7684\u6280\u672f\u8def\u5f84\uff0c\u4ee5\u589e\u5f3a\u4ee3\u7406\u5728\u590d\u6742\u957f\u65f6\u95ee\u9898\u4e0a\u7684\u6027\u80fd\u3002", "conclusion": "ColorBench\u6846\u67b6\u6210\u529f\u5f25\u5408\u4e86\u79bb\u7ebf\u4e0e\u5728\u7ebf\u8bc4\u4f30\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u63d0\u4f9b\u4e86\u652f\u6301\u591a\u6709\u6548\u89e3\u51b3\u65b9\u6848\u8bc4\u4f30\u3001\u5b50\u4efb\u52a1\u5b8c\u6210\u7387\u7edf\u8ba1\u548c\u539f\u5b50\u7ea7\u80fd\u529b\u5206\u6790\u7684\u7a33\u5b9a\u6d4b\u8bd5\u73af\u5883\uff0c\u4e3a\u79fb\u52a8\u4ee3\u7406\u80fd\u529b\u7684\u5168\u9762\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2510.14665", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.14665", "abs": "https://arxiv.org/abs/2510.14665", "authors": ["Rikard Rosenbacke", "Carl Rosenbacke", "Victor Rosenbacke", "Martin McKee"], "title": "Beyond Hallucinations: The Illusion of Understanding in Large Language Models", "comment": null, "summary": "Large language models (LLMs) are becoming deeply embedded in human\ncommunication and decision-making, yet they inherit the ambiguity, bias, and\nlack of direct access to truth inherent in language itself. While their outputs\nare fluent, emotionally resonant, and coherent, they are generated through\nstatistical prediction rather than grounded reasoning. This creates the risk of\nhallucination, responses that sound convincing but lack factual validity.\nBuilding on Geoffrey Hinton's observation that AI mirrors human intuition\nrather than reasoning, this paper argues that LLMs operationalize System 1\ncognition at scale: fast, associative, and persuasive, but without reflection\nor falsification. To address this, we introduce the Rose-Frame, a\nthree-dimensional framework for diagnosing cognitive and epistemic drift in\nhuman-AI interaction. The three axes are: (i) Map vs. Territory, which\ndistinguishes representations of reality (epistemology) from reality itself\n(ontology); (ii) Intuition vs. Reason, drawing on dual-process theory to\nseparate fast, emotional judgments from slow, reflective thinking; and (iii)\nConflict vs. Confirmation, which examines whether ideas are critically tested\nthrough disagreement or simply reinforced through mutual validation. Each\ndimension captures a distinct failure mode, and their combination amplifies\nmisalignment. Rose-Frame does not attempt to fix LLMs with more data or rules.\nInstead, it offers a reflective tool that makes both the model's limitations\nand the user's assumptions visible, enabling more transparent and critically\naware AI deployment. It reframes alignment as cognitive governance: intuition,\nwhether human or artificial, must remain governed by human reason. Only by\nembedding reflective, falsifiable oversight can we align machine fluency with\nhuman understanding.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Rose-Frame\u6846\u67b6\uff0c\u7528\u4e8e\u8bca\u65ad\u4eba\u673a\u4ea4\u4e92\u4e2d\u7684\u8ba4\u77e5\u548c\u8ba4\u8bc6\u8bba\u504f\u5dee\u3002\u8be5\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u7ef4\u5ea6\uff1a\u5730\u56fevs\u9886\u571f\uff08\u8868\u5f81\u4e0e\u73b0\u5b9e\uff09\u3001\u76f4\u89c9vs\u7406\u6027\uff08\u53cc\u8fc7\u7a0b\u7406\u8bba\uff09\u3001\u51b2\u7a81vs\u786e\u8ba4\uff08\u6279\u5224\u6027\u6d4b\u8bd5vs\u76f8\u4e92\u9a8c\u8bc1\uff09\uff0c\u65e8\u5728\u63d0\u9ad8AI\u90e8\u7f72\u7684\u900f\u660e\u5ea6\u548c\u6279\u5224\u610f\u8bc6\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u6d41\u7545\u4e14\u5177\u6709\u60c5\u611f\u5171\u9e23\uff0c\u4f46\u57fa\u4e8e\u7edf\u8ba1\u9884\u6d4b\u800c\u975e\u6709\u6839\u636e\u7684\u63a8\u7406\uff0c\u5b58\u5728\u5e7b\u89c9\u98ce\u9669\u3002\u5b83\u4eec\u5b9e\u73b0\u4e86\u7cfb\u7edf1\u8ba4\u77e5\u7684\u5927\u89c4\u6a21\u64cd\u4f5c\u5316\uff1a\u5feb\u901f\u3001\u8054\u60f3\u3001\u6709\u8bf4\u670d\u529b\uff0c\u4f46\u7f3a\u4e4f\u53cd\u601d\u6216\u8bc1\u4f2a\u3002", "method": "\u5f15\u5165Rose-Frame\u4e09\u7ef4\u8bca\u65ad\u6846\u67b6\uff1a1) \u5730\u56fevs\u9886\u571f\uff1a\u533a\u5206\u73b0\u5b9e\u8868\u5f81\u4e0e\u73b0\u5b9e\u672c\u8eab\uff1b2) \u76f4\u89c9vs\u7406\u6027\uff1a\u57fa\u4e8e\u53cc\u8fc7\u7a0b\u7406\u8bba\u5206\u79bb\u5feb\u901f\u60c5\u611f\u5224\u65ad\u4e0e\u7f13\u6162\u53cd\u601d\u601d\u7ef4\uff1b3) \u51b2\u7a81vs\u786e\u8ba4\uff1a\u68c0\u9a8c\u89c2\u70b9\u662f\u901a\u8fc7\u5206\u6b67\u6279\u5224\u6d4b\u8bd5\u8fd8\u662f\u901a\u8fc7\u76f8\u4e92\u9a8c\u8bc1\u5f3a\u5316\u3002", "result": "Rose-Frame\u4e0d\u8bd5\u56fe\u7528\u66f4\u591a\u6570\u636e\u6216\u89c4\u5219\u4fee\u590dLLM\uff0c\u800c\u662f\u63d0\u4f9b\u4e00\u4e2a\u53cd\u601d\u5de5\u5177\uff0c\u4f7f\u6a21\u578b\u5c40\u9650\u6027\u548c\u7528\u6237\u5047\u8bbe\u53ef\u89c1\uff0c\u5b9e\u73b0\u66f4\u900f\u660e\u548c\u6279\u5224\u6027\u610f\u8bc6\u5f3a\u7684AI\u90e8\u7f72\u3002", "conclusion": "\u5c06\u5bf9\u9f50\u91cd\u65b0\u5b9a\u4e49\u4e3a\u8ba4\u77e5\u6cbb\u7406\uff1a\u65e0\u8bba\u662f\u4eba\u7c7b\u8fd8\u662f\u4eba\u5de5\u667a\u80fd\u7684\u76f4\u89c9\uff0c\u90fd\u5fc5\u987b\u53d7\u4eba\u7c7b\u7406\u6027\u652f\u914d\u3002\u53ea\u6709\u901a\u8fc7\u5d4c\u5165\u53cd\u601d\u6027\u3001\u53ef\u8bc1\u4f2a\u7684\u76d1\u7763\uff0c\u624d\u80fd\u4f7f\u673a\u5668\u6d41\u7545\u6027\u4e0e\u4eba\u7c7b\u7406\u89e3\u4fdd\u6301\u4e00\u81f4\u3002"}}
{"id": "2510.14669", "categories": ["cs.AI", "68T01, 68T09, 62P10 68T01, 68T09, 62P10", "I.2.6; I.5.4; H.2.8; J.3; K.4.1; K.4.2"], "pdf": "https://arxiv.org/pdf/2510.14669", "abs": "https://arxiv.org/abs/2510.14669", "authors": ["Sara Altamirano", "Arjan Vreeken", "Sennay Ghebreab"], "title": "Machine Learning and Public Health: Identifying and Mitigating Algorithmic Bias through a Systematic Review", "comment": "Extended version of the paper accepted at the AAAI/ACM Conference on\n  AI, Ethics, and Society (AIES 2025), including an appendix. 10 pages, 2\n  figures", "summary": "Machine learning (ML) promises to revolutionize public health through\nimproved surveillance, risk stratification, and resource allocation. However,\nwithout systematic attention to algorithmic bias, ML may inadvertently\nreinforce existing health disparities. We present a systematic literature\nreview of algorithmic bias identification, discussion, and reporting in Dutch\npublic health ML research from 2021 to 2025. To this end, we developed the Risk\nof Algorithmic Bias Assessment Tool (RABAT) by integrating elements from\nestablished frameworks (Cochrane Risk of Bias, PROBAST, Microsoft Responsible\nAI checklist) and applied it to 35 peer-reviewed studies. Our analysis reveals\npervasive gaps: although data sampling and missing data practices are well\ndocumented, most studies omit explicit fairness framing, subgroup analyses, and\ntransparent discussion of potential harms. In response, we introduce a\nfour-stage fairness-oriented framework called ACAR (Awareness,\nConceptualization, Application, Reporting), with guiding questions derived from\nour systematic literature review to help researchers address fairness across\nthe ML lifecycle. We conclude with actionable recommendations for public health\nML practitioners to consistently consider algorithmic bias and foster\ntransparency, ensuring that algorithmic innovations advance health equity\nrather than undermine it.", "AI": {"tldr": "\u672c\u6587\u5bf92021-2025\u5e74\u8377\u5170\u516c\u5171\u536b\u751f\u673a\u5668\u5b66\u4e60\u7814\u7a76\u4e2d\u7684\u7b97\u6cd5\u504f\u89c1\u8fdb\u884c\u4e86\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\uff0c\u5f00\u53d1\u4e86RABAT\u8bc4\u4f30\u5de5\u5177\uff0c\u53d1\u73b0\u666e\u904d\u5b58\u5728\u516c\u5e73\u6027\u6846\u67b6\u7f3a\u5931\u7b49\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86ACAR\u56db\u9636\u6bb5\u516c\u5e73\u6027\u6846\u67b6\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u5728\u516c\u5171\u536b\u751f\u9886\u57df\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u5982\u679c\u4e0d\u7cfb\u7edf\u5173\u6ce8\u7b97\u6cd5\u504f\u89c1\uff0c\u53ef\u80fd\u4f1a\u65e0\u610f\u4e2d\u52a0\u5267\u73b0\u6709\u7684\u5065\u5eb7\u5dee\u8ddd\u3002", "method": "\u5f00\u53d1\u4e86RABAT\u8bc4\u4f30\u5de5\u5177\uff0c\u6574\u5408\u4e86Cochrane\u504f\u89c1\u98ce\u9669\u3001PROBAST\u548c\u5fae\u8f6f\u8d1f\u8d23\u4efbAI\u68c0\u67e5\u8868\u7b49\u73b0\u6709\u6846\u67b6\uff0c\u5e94\u7528\u4e8e35\u7bc7\u540c\u884c\u8bc4\u5ba1\u7814\u7a76\u3002", "result": "\u5206\u6790\u663e\u793a\u666e\u904d\u5b58\u5728\u5dee\u8ddd\uff1a\u867d\u7136\u6570\u636e\u62bd\u6837\u548c\u7f3a\u5931\u6570\u636e\u5b9e\u8df5\u8bb0\u5f55\u826f\u597d\uff0c\u4f46\u5927\u591a\u6570\u7814\u7a76\u7f3a\u4e4f\u660e\u786e\u7684\u516c\u5e73\u6027\u6846\u67b6\u3001\u4e9a\u7ec4\u5206\u6790\u548c\u6f5c\u5728\u5371\u5bb3\u7684\u900f\u660e\u8ba8\u8bba\u3002", "conclusion": "\u63d0\u51fa\u4e86ACAR\u56db\u9636\u6bb5\u516c\u5e73\u6027\u6846\u67b6\u548c\u5177\u4f53\u5efa\u8bae\uff0c\u5e2e\u52a9\u516c\u5171\u536b\u751fML\u4ece\u4e1a\u8005\u7cfb\u7edf\u8003\u8651\u7b97\u6cd5\u504f\u89c1\uff0c\u786e\u4fdd\u7b97\u6cd5\u521b\u65b0\u4fc3\u8fdb\u800c\u975e\u635f\u5bb3\u5065\u5eb7\u516c\u5e73\u3002"}}
{"id": "2510.14676", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14676", "abs": "https://arxiv.org/abs/2510.14676", "authors": ["Bianca Maria Lerma", "Rafael Pe\u00f1aloza"], "title": "NAEL: Non-Anthropocentric Ethical Logic", "comment": "Accepted to the FEAR workshop 2025", "summary": "We introduce NAEL (Non-Anthropocentric Ethical Logic), a novel ethical\nframework for artificial agents grounded in active inference and symbolic\nreasoning. Departing from conventional, human-centred approaches to AI ethics,\nNAEL formalizes ethical behaviour as an emergent property of intelligent\nsystems minimizing global expected free energy in dynamic, multi-agent\nenvironments. We propose a neuro-symbolic architecture to allow agents to\nevaluate the ethical consequences of their actions in uncertain settings. The\nproposed system addresses the limitations of existing ethical models by\nallowing agents to develop context-sensitive, adaptive, and relational ethical\nbehaviour without presupposing anthropomorphic moral intuitions. A case study\ninvolving ethical resource distribution illustrates NAEL's dynamic balancing of\nself-preservation, epistemic learning, and collective welfare.", "AI": {"tldr": "NAEL\u662f\u4e00\u4e2a\u57fa\u4e8e\u4e3b\u52a8\u63a8\u7406\u548c\u7b26\u53f7\u63a8\u7406\u7684\u975e\u4eba\u7c7b\u4e2d\u5fc3\u4e3b\u4e49\u4f26\u7406\u6846\u67b6\uff0c\u5c06\u4f26\u7406\u884c\u4e3a\u5f62\u5f0f\u5316\u4e3a\u667a\u80fd\u7cfb\u7edf\u5728\u52a8\u6001\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u6700\u5c0f\u5316\u5168\u5c40\u671f\u671b\u81ea\u7531\u80fd\u91cf\u7684\u6d8c\u73b0\u5c5e\u6027\u3002", "motivation": "\u4f20\u7edfAI\u4f26\u7406\u65b9\u6cd5\u8fc7\u4e8e\u4eba\u7c7b\u4e2d\u5fc3\u4e3b\u4e49\uff0c\u73b0\u6709\u4f26\u7406\u6a21\u578b\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5728\u4e0d\u9884\u8bbe\u4eba\u7c7b\u9053\u5fb7\u76f4\u89c9\u7684\u60c5\u51b5\u4e0b\u4ea7\u751f\u60c5\u5883\u654f\u611f\u3001\u81ea\u9002\u5e94\u548c\u5173\u7cfb\u6027\u4f26\u7406\u884c\u4e3a\u7684\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u795e\u7ecf\u7b26\u53f7\u67b6\u6784\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u5728\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u8bc4\u4f30\u5176\u884c\u4e3a\u7684\u4f26\u7406\u540e\u679c\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u5168\u5c40\u671f\u671b\u81ea\u7531\u80fd\u91cf\u6765\u5f62\u5f0f\u5316\u4f26\u7406\u884c\u4e3a\u3002", "result": "\u901a\u8fc7\u4f26\u7406\u8d44\u6e90\u5206\u914d\u7684\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86NAEL\u80fd\u591f\u52a8\u6001\u5e73\u8861\u81ea\u6211\u4fdd\u62a4\u3001\u8ba4\u77e5\u5b66\u4e60\u548c\u96c6\u4f53\u798f\u5229\u3002", "conclusion": "NAEL\u4e3a\u4eba\u5de5\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u4e00\u4e2a\u975e\u4eba\u7c7b\u4e2d\u5fc3\u4e3b\u4e49\u7684\u4f26\u7406\u6846\u67b6\uff0c\u80fd\u591f\u4ea7\u751f\u9002\u5e94\u6027\u7684\u4f26\u7406\u884c\u4e3a\uff0c\u514b\u670d\u4e86\u73b0\u6709\u4f26\u7406\u6a21\u578b\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2510.14683", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14683", "abs": "https://arxiv.org/abs/2510.14683", "authors": ["Devon Graham", "Kevin Leyton-Brown"], "title": "Practical, Utilitarian Algorithm Configuration", "comment": null, "summary": "Utilitarian algorithm configuration identifies a parameter setting for a\ngiven algorithm that maximizes a user's utility. Utility functions offer a\ntheoretically well-grounded approach to optimizing decision-making under\nuncertainty and are flexible enough to capture a user's preferences over\nalgorithm runtimes (e.g., they can describe a sharp cutoff after which a\nsolution is no longer required, a per-hour cost for compute, or diminishing\nreturns from algorithms that take longer to run). COUP is a recently-introduced\nutilitarian algorithm configuration procedure which was designed mainly to\noffer strong theoretical guarantees about the quality of the configuration it\nreturns, with less attention paid to its practical performance. This paper\ncloses that gap, bringing theoretically-grounded, utilitarian algorithm\nconfiguration to the point where it is competitive with widely used, heuristic\nconfiguration procedures that offer no performance guarantees. We present a\nseries of improvements to COUP that improve its empirical performance without\ndegrading its theoretical guarantees and demonstrate their benefit\nexperimentally. Using a case study, we also illustrate ways of exploring the\nrobustness of a given solution to the algorithm selection problem to variations\nin the utility function.", "AI": {"tldr": "\u672c\u6587\u6539\u8fdb\u4e86COUP\u7b97\u6cd5\u914d\u7f6e\u65b9\u6cd5\uff0c\u5728\u4e0d\u727a\u7272\u7406\u8bba\u4fdd\u8bc1\u7684\u524d\u63d0\u4e0b\u663e\u8457\u63d0\u5347\u5176\u5b9e\u9645\u6027\u80fd\uff0c\u4f7f\u5176\u80fd\u4e0e\u5e7f\u6cdb\u4f7f\u7528\u7684\u542f\u53d1\u5f0f\u914d\u7f6e\u65b9\u6cd5\u7ade\u4e89\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u7b97\u6cd5\u9009\u62e9\u89e3\u51b3\u65b9\u6848\u5bf9\u6548\u7528\u51fd\u6570\u53d8\u5316\u7684\u9c81\u68d2\u6027\u5206\u6790\u3002", "motivation": "COUP\u7b97\u6cd5\u914d\u7f6e\u65b9\u6cd5\u867d\u7136\u5177\u6709\u5f3a\u5927\u7684\u7406\u8bba\u4fdd\u8bc1\uff0c\u4f46\u5b9e\u9645\u6027\u80fd\u8868\u73b0\u4e0d\u4f73\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u5c06\u57fa\u4e8e\u7406\u8bba\u7684\u5b9e\u7528\u7b97\u6cd5\u914d\u7f6e\u65b9\u6cd5\u63d0\u5347\u5230\u4e0e\u5e7f\u6cdb\u4f7f\u7528\u7684\u65e0\u6027\u80fd\u4fdd\u8bc1\u542f\u53d1\u5f0f\u914d\u7f6e\u65b9\u6cd5\u76f8\u7ade\u4e89\u7684\u6c34\u5e73\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u5bf9COUP\u7684\u6539\u8fdb\u63aa\u65bd\uff0c\u8fd9\u4e9b\u6539\u8fdb\u5728\u4e0d\u964d\u4f4e\u7406\u8bba\u4fdd\u8bc1\u7684\u524d\u63d0\u4e0b\u63d0\u5347\u4e86\u5176\u7ecf\u9a8c\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u6539\u8fdb\u7684\u6548\u76ca\u3002", "result": "\u6539\u8fdb\u540e\u7684COUP\u7b97\u6cd5\u914d\u7f6e\u65b9\u6cd5\u5728\u5b9e\u8bc1\u6027\u80fd\u4e0a\u5f97\u5230\u663e\u8457\u63d0\u5347\uff0c\u80fd\u591f\u4e0e\u5e7f\u6cdb\u4f7f\u7528\u7684\u542f\u53d1\u5f0f\u914d\u7f6e\u65b9\u6cd5\u7ade\u4e89\uff0c\u540c\u65f6\u4fdd\u6301\u7406\u8bba\u6027\u80fd\u4fdd\u8bc1\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u5c06\u57fa\u4e8e\u7406\u8bba\u7684\u5b9e\u7528\u7b97\u6cd5\u914d\u7f6e\u65b9\u6cd5\u63a8\u5411\u5b9e\u7528\u5316\uff0c\u4f7f\u5176\u5728\u4fdd\u6301\u7406\u8bba\u4fdd\u8bc1\u7684\u540c\u65f6\u5177\u5907\u4e0e\u73b0\u6709\u542f\u53d1\u5f0f\u65b9\u6cd5\u7ade\u4e89\u7684\u5b9e\u9645\u6027\u80fd\uff0c\u4e3a\u7b97\u6cd5\u914d\u7f6e\u95ee\u9898\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.14697", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14697", "abs": "https://arxiv.org/abs/2510.14697", "authors": ["Bang An", "Yibo Yang", "Philip Torr", "Bernard Ghanem"], "title": "Purifying Task Vectors in Knowledge-Aware Subspace for Model Merging", "comment": null, "summary": "Model merging aims to integrate task-specific abilities from individually\nfine-tuned models into a single model without extra training. In recent model\nmerging methods, task vector has become a fundamental building block, as it can\nencapsulate the residual information from finetuning. However, the merged model\noften suffers from notable performance degradation due to the conflicts caused\nby task-irrelevant redundancy in task vectors. Existing efforts in overcoming\nredundancy by randomly dropping elements in the parameter space involves\nrandomness and lacks knowledge awareness. To address these challenges, in this\nstudy, we propose Purifying TAsk Vectors (PAVE) in knowledge-aware subspace.\nConcretely, we sample some training examples from each task, and feed them into\ntheir corresponding fine-tuned models to acquire the covariance matrices before\nlinear layers. We then perform a context-oriented singular value decomposition,\nwhich accentuates the weight components most relevant to the target knowledge.\nAs a result, we can split fine-tuned model weights into task-relevant and\nredundant components in the knowledge-aware subspace, and purify the task\nvector by pruning the redundant components. To induce fair pruning efforts\nacross models, we further introduce a spectral rank allocation strategy by\noptimizing a normalized activated pruning error. The task vector purification\nby our method as a plug-and-play scheme is applicable across various task\nvector-based merging methods to improve their performance. In experiments, we\ndemonstrate the effectiveness of PAVE across a diverse set of merging methods,\ntasks, and model architectures.", "AI": {"tldr": "\u63d0\u51fa\u4e86PAVE\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u77e5\u8bc6\u611f\u77e5\u5b50\u7a7a\u95f4\u4e2d\u51c0\u5316\u4efb\u52a1\u5411\u91cf\u6765\u51cf\u5c11\u5197\u4f59\uff0c\u63d0\u5347\u6a21\u578b\u5408\u5e76\u6027\u80fd", "motivation": "\u73b0\u6709\u6a21\u578b\u5408\u5e76\u65b9\u6cd5\u4e2d\uff0c\u4efb\u52a1\u5411\u91cf\u5305\u542b\u4efb\u52a1\u65e0\u5173\u7684\u5197\u4f59\u4fe1\u606f\uff0c\u5bfc\u81f4\u5408\u5e76\u6a21\u578b\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u800c\u73b0\u6709\u968f\u673a\u4e22\u5f03\u53c2\u6570\u7684\u65b9\u6cd5\u7f3a\u4e4f\u77e5\u8bc6\u611f\u77e5", "method": "\u4f7f\u7528\u8bad\u7ec3\u6837\u672c\u83b7\u53d6\u534f\u65b9\u5dee\u77e9\u9635\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u5bfc\u5411\u7684\u5947\u5f02\u503c\u5206\u89e3\u8bc6\u522b\u4efb\u52a1\u76f8\u5173\u6743\u91cd\u5206\u91cf\uff0c\u5728\u77e5\u8bc6\u611f\u77e5\u5b50\u7a7a\u95f4\u4e2d\u5206\u79bb\u4efb\u52a1\u76f8\u5173\u548c\u5197\u4f59\u7ec4\u4ef6\uff0c\u5e76\u5f15\u5165\u8c31\u79e9\u5206\u914d\u7b56\u7565\u8fdb\u884c\u516c\u5e73\u526a\u679d", "result": "PAVE\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u65b9\u6848\uff0c\u5728\u5404\u79cd\u4efb\u52a1\u5411\u91cf\u5408\u5e76\u65b9\u6cd5\u4e2d\u90fd\u80fd\u6709\u6548\u63d0\u5347\u6027\u80fd", "conclusion": "PAVE\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u51c0\u5316\u4efb\u52a1\u5411\u91cf\u4e2d\u7684\u5197\u4f59\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u5408\u5e76\u7684\u6027\u80fd"}}
{"id": "2510.14702", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14702", "abs": "https://arxiv.org/abs/2510.14702", "authors": ["Penglong Zhai", "Jie Li", "Fanyi Di", "Yue Liu", "Yifang Yuan", "Jie Huang", "Peng Wu", "Sicong Wang", "Mingyang Yin", "Tingting Hu", "Yao Xu", "Xin Li"], "title": "Cognitive-Aligned Spatio-Temporal Large Language Models For Next Point-of-Interest Prediction", "comment": "12 pages, 5 figures", "summary": "The next point-of-interest (POI) recommendation task aims to predict the\nusers' immediate next destinations based on their preferences and historical\ncheck-ins, holding significant value in location-based services. Recently,\nlarge language models (LLMs) have shown great potential in recommender systems,\nwhich treat the next POI prediction in a generative manner. However, these\nLLMs, pretrained primarily on vast corpora of unstructured text, lack the\nnative understanding of structured geographical entities and sequential\nmobility patterns required for next POI prediction tasks. Moreover, in\nindustrial-scale POI prediction applications, incorporating world knowledge and\nalignment of human cognition, such as seasons, weather conditions, holidays,\nand users' profiles (such as habits, occupation, and preferences), can enhance\nthe user experience while improving recommendation performance. To address\nthese issues, we propose CoAST (Cognitive-Aligned Spatial-Temporal LLMs), a\nframework employing natural language as an interface, allowing for the\nincorporation of world knowledge, spatio-temporal trajectory patterns,\nprofiles, and situational information. Specifically, CoAST mainly comprises of\n2 stages: (1) Recommendation Knowledge Acquisition through continued\npretraining on the enriched spatial-temporal trajectory data of the\ndesensitized users; (2) Cognitive Alignment to align cognitive judgments with\nhuman preferences using enriched training data through Supervised Fine-Tuning\n(SFT) and a subsequent Reinforcement Learning (RL) phase. Extensive offline\nexperiments on various real-world datasets and online experiments deployed in\n\"Guess Where You Go\" of AMAP App homepage demonstrate the effectiveness of\nCoAST.", "AI": {"tldr": "CoAST\u662f\u4e00\u4e2a\u8ba4\u77e5\u5bf9\u9f50\u7684\u65f6\u7a7a\u5927\u8bed\u8a00\u6a21\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63a5\u53e3\u6574\u5408\u4e16\u754c\u77e5\u8bc6\u3001\u65f6\u7a7a\u8f68\u8ff9\u6a21\u5f0f\u548c\u60c5\u5883\u4fe1\u606f\uff0c\u7528\u4e8e\u4e0b\u4e00\u4e2a\u5174\u8da3\u70b9\u63a8\u8350\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u4e3b\u8981\u57fa\u4e8e\u975e\u7ed3\u6784\u5316\u6587\u672c\u9884\u8bad\u7ec3\uff0c\u7f3a\u4e4f\u5bf9\u7ed3\u6784\u5316\u5730\u7406\u5b9e\u4f53\u548c\u5e8f\u5217\u79fb\u52a8\u6a21\u5f0f\u7684\u7406\u89e3\uff0c\u4e14\u5de5\u4e1a\u7ea7POI\u63a8\u8350\u9700\u8981\u878d\u5165\u4e16\u754c\u77e5\u8bc6\u548c\u4eba\u7c7b\u8ba4\u77e5\u5bf9\u9f50\uff08\u5982\u5b63\u8282\u3001\u5929\u6c14\u3001\u8282\u5047\u65e5\u3001\u7528\u6237\u753b\u50cf\uff09\u6765\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u548c\u63a8\u8350\u6027\u80fd\u3002", "method": "CoAST\u5305\u542b\u4e24\u4e2a\u9636\u6bb5\uff1a(1) \u63a8\u8350\u77e5\u8bc6\u83b7\u53d6\uff1a\u5728\u8131\u654f\u7528\u6237\u7684\u65f6\u7a7a\u8f68\u8ff9\u6570\u636e\u4e0a\u7ee7\u7eed\u9884\u8bad\u7ec3\uff1b(2) \u8ba4\u77e5\u5bf9\u9f50\uff1a\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u5c06\u8ba4\u77e5\u5224\u65ad\u4e0e\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u3002", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u79bb\u7ebf\u5b9e\u9a8c\u548c\u5728AMAP App\u9996\u9875\"\u731c\u4f60\u60f3\u53bb\"\u7684\u5728\u7ebf\u5b9e\u9a8c\u90fd\u8bc1\u660e\u4e86CoAST\u7684\u6709\u6548\u6027\u3002", "conclusion": "CoAST\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86LLMs\u5728POI\u63a8\u8350\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u878d\u5165\u65f6\u7a7a\u77e5\u8bc6\u548c\u8ba4\u77e5\u5bf9\u9f50\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u6027\u80fd\u3002"}}
{"id": "2510.14703", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14703", "abs": "https://arxiv.org/abs/2510.14703", "authors": ["Jianghao Lin", "Yuanyuan Shi", "Xin Peng", "Renjie Ding", "Hairui Wang", "Yuxuan Peng", "Bizhe Bai", "Weixi Song", "Fengshuo Bai", "Huacan Chai", "Weinan Zhang", "Fei Huang", "Ying Wen"], "title": "ToolPRM: Fine-Grained Inference Scaling of Structured Outputs for Function Calling", "comment": null, "summary": "Large language models (LLMs) are increasingly demonstrating strong\ncapabilities as autonomous agents, with function calling serving as a core\nmechanism for interaction with the environment. Meanwhile, inference scaling\nhas become a cutting-edge technique to enhance LLM performance by allocating\nmore computational resources during the inference process. However, current\nresearch on inference scaling primarily focuses on unstructured output\ngeneration tasks, leaving its application in structured outputs, like function\ncalling, largely underexplored. To bridge this gap, we propose an inference\nscaling framework that combines fine-grained beam search with a process reward\nmodel, ToolPRM, which scores the internal steps of each single function call.\nTo train ToolPRM, we construct the first fine-grained intra-call process\nsupervision dataset, automatically annotated with function-masking techniques\nto provide step-level rewards for structured tool-use reasoning. Extensive\nexperiments demonstrate that ToolPRM beats the coarse-grained and outcome\nreward models in terms of predictive accuracy, indicating its stronger\ncapability in supervising the function calling inference process. Inference\nscaling technique equipped with ToolPRM also significantly improves the\nbackbone model performance across various function calling tasks and\nbenchmarks. More importantly, we reveal a key principle for applying inference\nscaling techniques to structured outputs: \"explore more but retain less\" due to\nthe unrecoverability characteristics of structured function calling generation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u7ec6\u7c92\u5ea6\u675f\u641c\u7d22\u548c\u8fc7\u7a0b\u5956\u52b1\u6a21\u578bToolPRM\u7684\u63a8\u7406\u6269\u5c55\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7ed3\u6784\u5316\u8f93\u51fa\uff08\u5982\u51fd\u6570\u8c03\u7528\uff09\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u63a8\u7406\u6269\u5c55\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u975e\u7ed3\u6784\u5316\u8f93\u51fa\u751f\u6210\u4efb\u52a1\uff0c\u800c\u5728\u7ed3\u6784\u5316\u8f93\u51fa\uff08\u5982\u51fd\u6570\u8c03\u7528\uff09\u65b9\u9762\u7684\u5e94\u7528\u7814\u7a76\u4e0d\u8db3\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u6784\u5efa\u4e86\u9996\u4e2a\u7ec6\u7c92\u5ea6\u8c03\u7528\u5185\u8fc7\u7a0b\u76d1\u7763\u6570\u636e\u96c6\uff0c\u4f7f\u7528\u51fd\u6570\u63a9\u7801\u6280\u672f\u81ea\u52a8\u6807\u6ce8\u4ee5\u63d0\u4f9b\u6b65\u9aa4\u7ea7\u5956\u52b1\uff1b\u63d0\u51faToolPRM\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u6765\u8bc4\u5206\u5355\u4e2a\u51fd\u6570\u8c03\u7528\u7684\u5185\u90e8\u6b65\u9aa4\uff1b\u7ed3\u5408\u7ec6\u7c92\u5ea6\u675f\u641c\u7d22\u8fdb\u884c\u63a8\u7406\u6269\u5c55\u3002", "result": "ToolPRM\u5728\u9884\u6d4b\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u7c97\u7c92\u5ea6\u548c\u7ed3\u679c\u5956\u52b1\u6a21\u578b\uff1b\u914d\u5907ToolPRM\u7684\u63a8\u7406\u6269\u5c55\u6280\u672f\u663e\u8457\u63d0\u5347\u4e86\u9aa8\u5e72\u6a21\u578b\u5728\u5404\u79cd\u51fd\u6570\u8c03\u7528\u4efb\u52a1\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u6027\u80fd\u3002", "conclusion": "\u63ed\u793a\u4e86\u5c06\u63a8\u7406\u6269\u5c55\u6280\u672f\u5e94\u7528\u4e8e\u7ed3\u6784\u5316\u8f93\u51fa\u7684\u5173\u952e\u539f\u5219\uff1a\"\u591a\u63a2\u7d22\u5c11\u4fdd\u7559\"\uff0c\u8fd9\u662f\u7531\u4e8e\u7ed3\u6784\u5316\u51fd\u6570\u8c03\u7528\u751f\u6210\u7684\u4e0d\u53ef\u6062\u590d\u6027\u7279\u5f81\u51b3\u5b9a\u7684\u3002"}}
{"id": "2510.14807", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14807", "abs": "https://arxiv.org/abs/2510.14807", "authors": ["Ruotian Peng", "Yi Ren", "Zhouliang Yu", "Weiyang Liu", "Yandong Wen"], "title": "SimKO: Simple Pass@K Policy Optimization", "comment": "Technical report (20 pages, 10 figures, project page:\n  https://spherelab.ai/simko/)", "summary": "Reinforcement learning with verifiable rewards (RLVR) has advanced the\nreasoning capabilities of large language models (LLMs). However, prevailing\nRLVR methods exhibit a systematic bias toward exploitation over exploration, as\nevidenced by improved pass@1 but reduced pass@K (K>1) performance. To\nunderstand this issue, we analyze training dynamics of RLVR methods by tracking\nthe token-level probability distributions over vocabulary candidates. Our\nanalysis reveals a consistent probability concentration effect where the top-1\ncandidate increasingly accumulates probability mass and suppresses that of\nother candidates. More importantly, stronger over-concentration correlates with\nworse pass@K performance. Inspired by this finding, we propose Simple Pass@K\nOptimization (SimKO), a method designed to mitigate the over-concentration\nissue, thereby encouraging exploration. SimKO operates in an asymmetrical\nmanner. For verified-correct responses, it boosts the probabilities of the\ntop-K candidates. For verified-incorrect responses, it applies stronger\npenalties to the top-1 candidate. We observe that this asymmetric design is\nparticularly effective at mitigating over-concentration when applied at tokens\nwith high entropy. Across various math and logical-reasoning benchmarks, SimKO\nconsistently yields higher pass@K for a wide range of K, providing a simple way\nto improve RLVR's exploration.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86SimKO\u65b9\u6cd5\u6765\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u53ef\u9a8c\u8bc1\u5956\u52b1(RLVR)\u4e2d\u7684\u8fc7\u5ea6\u96c6\u4e2d\u95ee\u9898\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u4e0d\u5bf9\u79f0\u5730\u8c03\u6574\u6b63\u786e\u548c\u9519\u8bef\u56de\u7b54\u7684\u6982\u7387\u5206\u5e03\u6765\u9f13\u52b1\u63a2\u7d22\uff0c\u63d0\u9ad8pass@K\u6027\u80fd\u3002", "motivation": "\u73b0\u6709RLVR\u65b9\u6cd5\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5dee\uff0c\u503e\u5411\u4e8e\u5229\u7528\u800c\u975e\u63a2\u7d22\uff0c\u8868\u73b0\u4e3apass@1\u63d0\u5347\u4f46pass@K(K>1)\u4e0b\u964d\u3002\u4f5c\u8005\u901a\u8fc7\u5206\u6790\u8bad\u7ec3\u52a8\u6001\u53d1\u73b0\u6982\u7387\u96c6\u4e2d\u6548\u5e94\u662f\u5bfc\u81f4\u6b64\u95ee\u9898\u7684\u539f\u56e0\u3002", "method": "\u63d0\u51faSimKO\u65b9\u6cd5\uff1a\u5bf9\u4e8e\u5df2\u9a8c\u8bc1\u6b63\u786e\u7684\u56de\u7b54\uff0c\u63d0\u5347top-K\u5019\u9009\u7684\u6982\u7387\uff1b\u5bf9\u4e8e\u5df2\u9a8c\u8bc1\u9519\u8bef\u7684\u56de\u7b54\uff0c\u5bf9top-1\u5019\u9009\u65bd\u52a0\u66f4\u5f3a\u7684\u60e9\u7f5a\u3002\u8be5\u65b9\u6cd5\u5728\u5177\u6709\u9ad8\u71b5\u7684token\u4e0a\u5e94\u7528\u6548\u679c\u6700\u4f73\u3002", "result": "\u5728\u5404\u79cd\u6570\u5b66\u548c\u903b\u8f91\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSimKO\u5728\u5e7f\u6cdb\u7684K\u503c\u8303\u56f4\u5185\u4e00\u81f4\u5730\u4ea7\u751f\u66f4\u9ad8\u7684pass@K\u6027\u80fd\uff0c\u6709\u6548\u6539\u5584\u4e86RLVR\u7684\u63a2\u7d22\u80fd\u529b\u3002", "conclusion": "SimKO\u901a\u8fc7\u7f13\u89e3\u6982\u7387\u8fc7\u5ea6\u96c6\u4e2d\u95ee\u9898\uff0c\u4e3a\u6539\u8fdbRLVR\u7684\u63a2\u7d22\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86pass@K\u6027\u80fd\u3002"}}
{"id": "2510.14808", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14808", "abs": "https://arxiv.org/abs/2510.14808", "authors": ["Dominik Jehle", "Lennart Purucker", "Frank Hutter"], "title": "Agentic NL2SQL to Reduce Computational Costs", "comment": "Accepted at the NeurIPS 2025 Workshop on Efficient Reasoning. 10\n  pages, 11 figures", "summary": "Translating natural language queries into SQL queries (NL2SQL or Text-to-SQL)\nhas recently been empowered by large language models (LLMs). Using LLMs to\nperform NL2SQL methods on a large collection of SQL databases necessitates\nprocessing large quantities of meta-information about the databases, which in\nturn results in lengthy prompts with many tokens and high processing costs. To\naddress this challenge, we introduce Datalake Agent, an agentic system designed\nto enable an LLM to solve NL2SQL tasks more efficiently. Instead of utilizing\ndirect solvers for NL2SQL that call the LLM once with all meta-information in\nthe prompt, the Datalake Agent employs an interactive loop to reduce the\nutilized meta-information. Within the loop, the LLM is used in a reasoning\nframework that selectively requests only the necessary information to solve a\ntable question answering task. We evaluate the Datalake Agent on a collection\nof 23 databases with 100 table question answering tasks. The Datalake Agent\nreduces the tokens used by the LLM by up to 87\\% and thus allows for\nsubstantial cost reductions while maintaining competitive performance.", "AI": {"tldr": "Datalake Agent\u662f\u4e00\u4e2a\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u4ea4\u4e92\u5f0f\u5faa\u73af\u51cf\u5c11NL2SQL\u4efb\u52a1\u4e2d\u7684\u5143\u4fe1\u606f\u4f7f\u7528\uff0c\u663e\u8457\u964d\u4f4eLLM\u7684token\u6d88\u8017\u548c\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u529b\u3002", "motivation": "\u4f20\u7edfNL2SQL\u65b9\u6cd5\u9700\u8981\u5904\u7406\u5927\u91cf\u6570\u636e\u5e93\u5143\u4fe1\u606f\uff0c\u5bfc\u81f4\u63d0\u793a\u8fc7\u957f\u3001token\u6d88\u8017\u5927\u3001\u5904\u7406\u6210\u672c\u9ad8\u3002", "method": "\u91c7\u7528\u4ea4\u4e92\u5f0f\u5faa\u73af\u548c\u63a8\u7406\u6846\u67b6\uff0c\u9009\u62e9\u6027\u8bf7\u6c42\u5fc5\u8981\u4fe1\u606f\u6765\u89e3\u51b3\u8868\u683c\u95ee\u7b54\u4efb\u52a1\uff0c\u800c\u4e0d\u662f\u4e00\u6b21\u6027\u4f7f\u7528\u6240\u6709\u5143\u4fe1\u606f\u3002", "result": "\u572823\u4e2a\u6570\u636e\u5e93\u548c100\u4e2a\u8868\u683c\u95ee\u7b54\u4efb\u52a1\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cLLM\u4f7f\u7528\u7684token\u51cf\u5c11\u4e8687%\uff0c\u6210\u672c\u663e\u8457\u964d\u4f4e\uff0c\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u6027\u80fd\u3002", "conclusion": "Datalake Agent\u901a\u8fc7\u667a\u80fd\u4fe1\u606f\u9009\u62e9\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86NL2SQL\u4efb\u52a1\u4e2d\u7684\u5143\u4fe1\u606f\u8fc7\u8f7d\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u6210\u672c\u6548\u76ca\u548c\u6027\u80fd\u7684\u5e73\u8861\u3002"}}
{"id": "2510.14828", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.14828", "abs": "https://arxiv.org/abs/2510.14828", "authors": ["Jinrui Liu", "Bingyan Nie", "Boyu Li", "Yaran Chen", "Yuze Wang", "Shunsen He", "Haoran Li"], "title": "RoboGPT-R1: Enhancing Robot Planning with Reinforcement Learning", "comment": null, "summary": "Improving the reasoning capabilities of embodied agents is crucial for robots\nto complete complex human instructions in long-view manipulation tasks\nsuccessfully. Despite the success of large language models and vision language\nmodels based on Supervised Fine-Tuning (SFT) in planning tasks, they continue\nfacing challenges in performing long-horizon manipulation tasks in complex\nreal-world environments, owing to their restricted common sense and reasoning\ncapabilities. Considering that aligning general-purpose vision language models\nto robotic planning tasks via supervised fine-tuning suffers from poor\ngeneralization and insufficient physical understanding, we propose RoboGPT-R1,\na two-stage fine-tuning framework for embodied planning. In this framework,\nsupervised training acquires foundational knowledge through expert sequences,\nfollowed by RL to address the model's shortcomings in visual-spatial\nunderstanding and reasoning. To achieve physical understanding and action\nsequence consistency in multi-step reasoning tasks, we design a rule-based\nreward function that simultaneously considers long-horizon performance and\naction constraint in the environment. The reasoning model, trained on\nQwen2.5-VL-3B, significantly outperforms the larger-scale model, GPT-4o-mini,\nby 21.33% and surpasses other work trained on Qwen2.5-VL-7B by 20.33% on the\nEmbodiedBench benchmark.", "AI": {"tldr": "\u63d0\u51fa\u4e86RoboGPT-R1\uff0c\u4e00\u4e2a\u4e24\u9636\u6bb5\u5fae\u8c03\u6846\u67b6\uff0c\u901a\u8fc7\u76d1\u7763\u8bad\u7ec3\u548c\u5f3a\u5316\u5b66\u4e60\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u5177\u8eab\u667a\u80fd\u4f53\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5728EmbodiedBench\u57fa\u51c6\u4e0a\u663e\u8457\u4f18\u4e8eGPT-4o-mini\u548c\u5176\u4ed6\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u957f\u89c6\u91ce\u64cd\u4f5c\u4efb\u52a1\u4e2d\u4ecd\u9762\u4e34\u5e38\u8bc6\u548c\u63a8\u7406\u80fd\u529b\u53d7\u9650\u7684\u95ee\u9898\uff0c\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\u5b58\u5728\u6cdb\u5316\u80fd\u529b\u5dee\u548c\u7269\u7406\u7406\u89e3\u4e0d\u8db3\u7684\u5c40\u9650\u6027\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u5fae\u8c03\u6846\u67b6\uff1a\u76d1\u7763\u8bad\u7ec3\u4ece\u4e13\u5bb6\u5e8f\u5217\u83b7\u53d6\u57fa\u7840\u77e5\u8bc6\uff0c\u7136\u540e\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u89e3\u51b3\u6a21\u578b\u5728\u89c6\u89c9\u7a7a\u95f4\u7406\u89e3\u548c\u63a8\u7406\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u8bbe\u8ba1\u4e86\u8003\u8651\u957f\u671f\u6027\u80fd\u548c\u52a8\u4f5c\u7ea6\u675f\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u5956\u52b1\u51fd\u6570\u3002", "result": "\u5728Qwen2.5-VL-3B\u4e0a\u8bad\u7ec3\u7684\u63a8\u7406\u6a21\u578b\u5728EmbodiedBench\u57fa\u51c6\u4e0a\u6bd4GPT-4o-mini\u9ad8\u51fa21.33%\uff0c\u6bd4\u5728Qwen2.5-VL-7B\u4e0a\u8bad\u7ec3\u7684\u5176\u4ed6\u5de5\u4f5c\u9ad8\u51fa20.33%\u3002", "conclusion": "\u4e24\u9636\u6bb5\u5fae\u8c03\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u5177\u8eab\u667a\u80fd\u4f53\u7684\u63a8\u7406\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u5f3a\u5316\u5b66\u4e60\u5728\u89e3\u51b3\u89c6\u89c9\u7a7a\u95f4\u7406\u89e3\u548c\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.14842", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14842", "abs": "https://arxiv.org/abs/2510.14842", "authors": ["Ben Elder", "Evelyn Duesterwald", "Vinod Muthusamy"], "title": "Boosting Instruction Following at Scale", "comment": "6+4 pages, 7 figures, 2 tables", "summary": "A typical approach developers follow to influence an LLM's behavior in an\napplication is through careful manipulation of the prompt, such as by adding or\nmodifying instructions. However, merely adding more instructions provides\nlittle assurance that they will actually be followed. We introduce Instruction\nBoosting as a post-generation method to increase the reliability of LLM prompt\ninstructions. We show that Instruction Boosting improves the instruction\nfollowing rate by up to 7 points for two instructions and up to 4 points for\nten instructions. To demonstrate these results we introduce SCALEDIF, a\nbenchmark with a scaled instruction volume of up to ten instructions per data\nsample. We also present an analysis of the commonly observed trend that\nperformance degrades as more instructions are added. We show that an important\nfactor contributing to this trend is the degree of tension and conflict that\narises as the number of instructions is increased. We contribute a quantitative\nconflict scoring tool that explains the observed performance trends and\nprovides feedback to developers on the impact that additional prompt\ninstructions have on a model's performance.", "AI": {"tldr": "Instruction Boosting\u662f\u4e00\u79cd\u540e\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u589e\u52a0\u6307\u4ee4\u9075\u5faa\u7387\u6765\u63d0\u9ad8LLM\u63d0\u793a\u6307\u4ee4\u7684\u53ef\u9760\u6027\uff0c\u57282\u6761\u6307\u4ee4\u65f6\u63d0\u53477\u4e2a\u767e\u5206\u70b9\uff0c10\u6761\u6307\u4ee4\u65f6\u63d0\u53474\u4e2a\u767e\u5206\u70b9\u3002", "motivation": "\u5f00\u53d1\u8005\u901a\u5e38\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u63d0\u793a\u6765\u5f71\u54cdLLM\u884c\u4e3a\uff0c\u4f46\u4ec5\u6dfb\u52a0\u66f4\u591a\u6307\u4ee4\u65e0\u6cd5\u4fdd\u8bc1\u5b83\u4eec\u4f1a\u88ab\u9075\u5faa\uff0c\u9700\u8981\u63d0\u9ad8\u6307\u4ee4\u9075\u5faa\u7684\u53ef\u9760\u6027\u3002", "method": "\u5f15\u5165Instruction Boosting\u4f5c\u4e3a\u540e\u751f\u6210\u65b9\u6cd5\uff0c\u5e76\u521b\u5efaSCALEDIF\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff08\u6bcf\u6761\u6570\u636e\u6837\u672c\u6700\u591a\u5305\u542b10\u6761\u6307\u4ee4\uff09\uff0c\u5f00\u53d1\u5b9a\u91cf\u51b2\u7a81\u8bc4\u5206\u5de5\u5177\u5206\u6790\u6307\u4ee4\u51b2\u7a81\u3002", "result": "Instruction Boosting\u663e\u8457\u63d0\u9ad8\u4e86\u6307\u4ee4\u9075\u5faa\u7387\uff0c\u540c\u65f6\u53d1\u73b0\u968f\u7740\u6307\u4ee4\u6570\u91cf\u589e\u52a0\uff0c\u6027\u80fd\u4e0b\u964d\u7684\u4e3b\u8981\u539f\u56e0\u662f\u6307\u4ee4\u95f4\u7684\u7d27\u5f20\u548c\u51b2\u7a81\u5173\u7cfb\u3002", "conclusion": "Instruction Boosting\u6709\u6548\u63d0\u5347LLM\u7684\u6307\u4ee4\u9075\u5faa\u80fd\u529b\uff0c\u51b2\u7a81\u8bc4\u5206\u5de5\u5177\u80fd\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u5173\u4e8e\u989d\u5916\u63d0\u793a\u6307\u4ee4\u5bf9\u6a21\u578b\u6027\u80fd\u5f71\u54cd\u7684\u53cd\u9988\u3002"}}
{"id": "2510.14846", "categories": ["cs.AI", "cs.CL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2510.14846", "abs": "https://arxiv.org/abs/2510.14846", "authors": ["Zhuo-Yang Song"], "title": "Where to Search: Measure the Prior-Structured Search Space of LLM Agents", "comment": "10 pages, 2 figures, 1 table", "summary": "The generate-filter-refine (iterative paradigm) based on large language\nmodels (LLMs) has achieved progress in reasoning, programming, and program\ndiscovery in AI+Science. However, the effectiveness of search depends on where\nto search, namely, how to encode the domain prior into an operationally\nstructured hypothesis space. To this end, this paper proposes a compact formal\ntheory that describes and measures LLM-assisted iterative search guided by\ndomain priors. We represent an agent as a fuzzy relation operator on inputs and\noutputs to capture feasible transitions; the agent is thereby constrained by a\nfixed safety envelope. To describe multi-step reasoning/search, we weight all\nreachable paths by a single continuation parameter and sum them to obtain a\ncoverage generating function; this induces a measure of reachability\ndifficulty; and it provides a geometric interpretation of search on the graph\ninduced by the safety envelope. We further provide the simplest testable\ninferences and validate them via a majority-vote instantiation. This theory\noffers a workable language and operational tools to measure agents and their\nsearch spaces, proposing a systematic formal description of iterative search\nconstructed by LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7d27\u51d1\u7684\u5f62\u5f0f\u7406\u8bba\u6765\u63cf\u8ff0\u548c\u8861\u91cf\u7531\u9886\u57df\u5148\u9a8c\u5f15\u5bfc\u7684LLM\u8f85\u52a9\u8fed\u4ee3\u641c\u7d22\uff0c\u901a\u8fc7\u6a21\u7cca\u5173\u7cfb\u7b97\u5b50\u8868\u793a\u667a\u80fd\u4f53\uff0c\u5e76\u5f15\u5165\u8986\u76d6\u751f\u6210\u51fd\u6570\u6765\u8861\u91cf\u53ef\u8fbe\u6027\u96be\u5ea6\u3002", "motivation": "\u57fa\u4e8eLLM\u7684\u751f\u6210-\u8fc7\u6ee4-\u7cbe\u70bc\u8fed\u4ee3\u8303\u5f0f\u5728\u63a8\u7406\u3001\u7f16\u7a0b\u548c\u79d1\u5b66\u53d1\u73b0\u4e2d\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u641c\u7d22\u6548\u679c\u53d6\u51b3\u4e8e\u5982\u4f55\u5c06\u9886\u57df\u5148\u9a8c\u7f16\u7801\u5230\u7ed3\u6784\u5316\u7684\u5047\u8bbe\u7a7a\u95f4\u4e2d\u3002", "method": "\u5c06\u667a\u80fd\u4f53\u8868\u793a\u4e3a\u8f93\u5165\u8f93\u51fa\u7684\u6a21\u7cca\u5173\u7cfb\u7b97\u5b50\uff0c\u901a\u8fc7\u5b89\u5168\u5305\u7edc\u7ea6\u675f\u667a\u80fd\u4f53\uff1b\u4f7f\u7528\u5355\u53c2\u6570\u52a0\u6743\u6240\u6709\u53ef\u8fbe\u8def\u5f84\u5f97\u5230\u8986\u76d6\u751f\u6210\u51fd\u6570\uff0c\u63d0\u4f9b\u641c\u7d22\u7684\u51e0\u4f55\u89e3\u91ca\u3002", "result": "\u63d0\u4f9b\u4e86\u53ef\u6d4b\u8bd5\u7684\u63a8\u65ad\u5e76\u901a\u8fc7\u591a\u6570\u6295\u7968\u5b9e\u4f8b\u8fdb\u884c\u9a8c\u8bc1\uff0c\u4e3a\u8861\u91cf\u667a\u80fd\u4f53\u53ca\u5176\u641c\u7d22\u7a7a\u95f4\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u8bed\u8a00\u548c\u64cd\u4f5c\u5de5\u5177\u3002", "conclusion": "\u8be5\u7406\u8bba\u4e3aLLM\u6784\u5efa\u7684\u8fed\u4ee3\u641c\u7d22\u63d0\u4f9b\u4e86\u7cfb\u7edf\u7684\u5f62\u5f0f\u5316\u63cf\u8ff0\uff0c\u80fd\u591f\u6709\u6548\u8861\u91cf\u667a\u80fd\u4f53\u548c\u641c\u7d22\u7a7a\u95f4\u3002"}}
{"id": "2510.14861", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14861", "abs": "https://arxiv.org/abs/2510.14861", "authors": ["Le Cong", "Zaixi Zhang", "Xiaotong Wang", "Yin Di", "Ruofan Jin", "Michal Gerasimiuk", "Yinkai Wang", "Ravi K. Dinesh", "David Smerkous", "Alex Smerkous", "Xuekun Wu", "Shilong Liu", "Peishan Li", "Yi Zhu", "Simran Serrao", "Ning Zhao", "Imran A. Mohammad", "John B. Sunwoo", "Joseph C. Wu", "Mengdi Wang"], "title": "LabOS: The AI-XR Co-Scientist That Sees and Works With Humans", "comment": null, "summary": "Modern science advances fastest when thought meets action. LabOS represents\nthe first AI co-scientist that unites computational reasoning with physical\nexperimentation through multimodal perception, self-evolving agents, and\nEntended-Reality(XR)-enabled human-AI collaboration. By connecting multi-model\nAI agents, smart glasses, and human-AI collaboration, LabOS allows AI to see\nwhat scientists see, understand experimental context, and assist in real-time\nexecution. Across applications--from cancer immunotherapy target discovery to\nstem-cell engineering -- LabOS shows that AI can move beyond computational\ndesign to participation, turning the laboratory into an intelligent,\ncollaborative environment where human and machine discovery evolve together.", "AI": {"tldr": "LabOS\u662f\u9996\u4e2a\u5c06\u8ba1\u7b97\u63a8\u7406\u4e0e\u7269\u7406\u5b9e\u9a8c\u7ed3\u5408\u7684AI\u8054\u5408\u79d1\u5b66\u5bb6\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u611f\u77e5\u3001\u81ea\u8fdb\u5316\u4ee3\u7406\u548cXR\u6280\u672f\u5b9e\u73b0\u4eba\u673a\u534f\u4f5c\uff0c\u8ba9AI\u80fd\u591f\u53c2\u4e0e\u5b9e\u9645\u5b9e\u9a8c\u8fc7\u7a0b\u3002", "motivation": "\u73b0\u4ee3\u79d1\u5b66\u53d1\u5c55\u9700\u8981\u5c06\u601d\u60f3\u4e0e\u884c\u52a8\u7ed3\u5408\uff0c\u4f20\u7edfAI\u4e3b\u8981\u505c\u7559\u5728\u8ba1\u7b97\u8bbe\u8ba1\u5c42\u9762\uff0c\u65e0\u6cd5\u5b9e\u9645\u53c2\u4e0e\u7269\u7406\u5b9e\u9a8c\u3002LabOS\u65e8\u5728\u8ba9AI\u80fd\u591f\u771f\u6b63\u8fdb\u5165\u5b9e\u9a8c\u5ba4\u73af\u5883\uff0c\u4e0e\u79d1\u5b66\u5bb6\u534f\u4f5c\u8fdb\u884c\u5b9e\u9a8c\u3002", "method": "\u901a\u8fc7\u8fde\u63a5\u591a\u6a21\u578bAI\u4ee3\u7406\u3001\u667a\u80fd\u773c\u955c\u548c\u4eba\u7c7b-AI\u534f\u4f5c\uff0c\u5229\u7528\u591a\u6a21\u6001\u611f\u77e5\u7406\u89e3\u5b9e\u9a8c\u73af\u5883\uff0c\u901a\u8fc7XR\u6280\u672f\u5b9e\u73b0\u5b9e\u65f6\u4eba\u673a\u4ea4\u4e92\uff0c\u8ba9AI\u80fd\u591f\u770b\u5230\u79d1\u5b66\u5bb6\u6240\u89c1\u5e76\u534f\u52a9\u5b9e\u9a8c\u6267\u884c\u3002", "result": "\u5728\u764c\u75c7\u514d\u75ab\u6cbb\u7597\u9776\u70b9\u53d1\u73b0\u548c\u5e72\u7ec6\u80de\u5de5\u7a0b\u7b49\u5e94\u7528\u4e2d\uff0cLabOS\u6210\u529f\u5c55\u793a\u4e86AI\u4ece\u8ba1\u7b97\u8bbe\u8ba1\u5230\u5b9e\u9645\u53c2\u4e0e\u7684\u8f6c\u53d8\uff0c\u5c06\u5b9e\u9a8c\u5ba4\u8f6c\u53d8\u4e3a\u667a\u80fd\u534f\u4f5c\u73af\u5883\u3002", "conclusion": "LabOS\u8bc1\u660e\u4e86AI\u80fd\u591f\u8d85\u8d8a\u7eaf\u8ba1\u7b97\u8bbe\u8ba1\uff0c\u771f\u6b63\u53c2\u4e0e\u7269\u7406\u5b9e\u9a8c\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u4eba\u7c7b\u4e0e\u673a\u5668\u53d1\u73b0\u7684\u5171\u540c\u8fdb\u5316\uff0c\u5f00\u521b\u4e86\u4eba\u673a\u534f\u4f5c\u79d1\u5b66\u7814\u7a76\u7684\u65b0\u8303\u5f0f\u3002"}}
{"id": "2510.14881", "categories": ["cs.AI", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.14881", "abs": "https://arxiv.org/abs/2510.14881", "authors": ["Fikresilase Wondmeneh Abebayew"], "title": "The Gatekeeper Knows Enough", "comment": "7 pages, 1 figure", "summary": "Large Language Models (LLMs) are increasingly deployed as autonomous agents,\nyet their practical utility is fundamentally constrained by a limited context\nwindow and state desynchronization resulting from the LLMs' stateless nature\nand inefficient context management. These limitations lead to unreliable\noutput, unpredictable behavior, and inefficient resource usage, particularly\nwhen interacting with large, structured, and sensitive knowledge systems such\nas codebases and documents. To address these challenges, we introduce the\nGatekeeper Protocol, a novel, domain-agnostic framework that governs\nagent-system interactions. Our protocol mandates that the agent first operate\nand reason on a minimalist, low-fidelity \"latent state\" representation of the\nsystem to strategically request high-fidelity context on demand. All\ninteractions are mediated through a unified JSON format that serves as a\ndeclarative, state-synchronized protocol, ensuring the agent's model of the\nsystem remains verifiably grounded in the system's reality. We demonstrate the\nefficacy of this protocol with Sage, a reference implementation of the\nGatekeeper Protocol for software development. Our results show that this\napproach significantly increases agent reliability, improves computational\nefficiency by minimizing token consumption, and enables scalable interaction\nwith complex systems, creating a foundational methodology for building more\nrobust, predictable, and grounded AI agents for any structured knowledge\ndomain.", "AI": {"tldr": "\u63d0\u51fa\u4e86Gatekeeper Protocol\u6846\u67b6\uff0c\u901a\u8fc7\u4f4e\u4fdd\u771f\u6f5c\u5728\u72b6\u6001\u8868\u793a\u548c\u6309\u9700\u8bf7\u6c42\u9ad8\u4fdd\u771f\u4e0a\u4e0b\u6587\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3LLM\u4ee3\u7406\u5728\u590d\u6742\u77e5\u8bc6\u7cfb\u7edf\u4e2d\u7684\u4e0a\u4e0b\u6587\u7a97\u53e3\u9650\u5236\u548c\u72b6\u6001\u540c\u6b65\u95ee\u9898\u3002", "motivation": "LLM\u4f5c\u4e3a\u81ea\u4e3b\u4ee3\u7406\u90e8\u7f72\u65f6\uff0c\u53d7\u9650\u4e8e\u6709\u9650\u7684\u4e0a\u4e0b\u6587\u7a97\u53e3\u548c\u72b6\u6001\u4e0d\u540c\u6b65\u95ee\u9898\uff0c\u5bfc\u81f4\u8f93\u51fa\u4e0d\u53ef\u9760\u3001\u884c\u4e3a\u4e0d\u53ef\u9884\u6d4b\u548c\u8d44\u6e90\u4f7f\u7528\u6548\u7387\u4f4e\u4e0b\uff0c\u7279\u522b\u662f\u5728\u4e0e\u4ee3\u7801\u5e93\u548c\u6587\u6863\u7b49\u7ed3\u6784\u5316\u77e5\u8bc6\u7cfb\u7edf\u4ea4\u4e92\u65f6\u3002", "method": "\u5f15\u5165Gatekeeper Protocol\u6846\u67b6\uff0c\u8981\u6c42\u4ee3\u7406\u5148\u5728\u4f4e\u4fdd\u771f\u6f5c\u5728\u72b6\u6001\u8868\u793a\u4e0a\u8fdb\u884c\u64cd\u4f5c\u548c\u63a8\u7406\uff0c\u7136\u540e\u6309\u9700\u7b56\u7565\u6027\u5730\u8bf7\u6c42\u9ad8\u4fdd\u771f\u4e0a\u4e0b\u6587\u3002\u6240\u6709\u4ea4\u4e92\u901a\u8fc7\u7edf\u4e00\u7684JSON\u683c\u5f0f\u8fdb\u884c\u4e2d\u4ecb\uff0c\u4f5c\u4e3a\u58f0\u660e\u6027\u3001\u72b6\u6001\u540c\u6b65\u7684\u534f\u8bae\u3002", "result": "\u5728\u8f6f\u4ef6\u5f00\u53d1\u7684\u53c2\u8003\u5b9e\u73b0Sage\u4e2d\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u4ee3\u7406\u53ef\u9760\u6027\uff0c\u901a\u8fc7\u6700\u5c0f\u5316token\u6d88\u8017\u6539\u5584\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u5e76\u5b9e\u73b0\u4e86\u4e0e\u590d\u6742\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u4ea4\u4e92\u3002", "conclusion": "Gatekeeper Protocol\u4e3a\u6784\u5efa\u66f4\u7a33\u5065\u3001\u53ef\u9884\u6d4b\u548c\u57fa\u7840\u624e\u5b9e\u7684AI\u4ee3\u7406\u63d0\u4f9b\u4e86\u57fa\u7840\u65b9\u6cd5\u8bba\uff0c\u9002\u7528\u4e8e\u4efb\u4f55\u7ed3\u6784\u5316\u77e5\u8bc6\u9886\u57df\u3002"}}
{"id": "2510.14913", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14913", "abs": "https://arxiv.org/abs/2510.14913", "authors": ["Kyle Montgomery", "Sijun Tan", "Yuqi Chen", "Siyuan Zhuang", "Tianjun Zhang", "Raluca Ada Popa", "Chenguang Wang"], "title": "Budget-aware Test-time Scaling via Discriminative Verification", "comment": null, "summary": "Test-time scaling is a powerful strategy for boosting the performance of\nlarge language models on complex reasoning tasks. While state-of-the-art\napproaches often employ generative verifiers to select the best solution from a\npool of candidates, this method incurs prohibitive computational costs,\nlimiting its practicality. In this work, we shift the focus to a more\nbudget-aware paradigm: discriminative verification. We conduct a thorough\nempirical analysis and demonstrate that while discriminative verifiers may\nunderperform in isolation, combining them with self-consistency in a hybrid\napproach creates a powerful and efficient test-time scaling mechanism. Notably,\nunder a fixed compute budget, this hybrid approach surpasses state-of-the-art\ngenerative verification by a significant margin: achieving up to 15.3\\% higher\naccuracy on AIME2025. Our findings establish that for practical, real-world\napplications, budget-aware scaling with discriminative verifiers is not only a\n\"free\" upgrade over self-consistency, but also a more effective and efficient\nalternative to costly generative techniques. Code is available at\nhttps://github.com/wang-research-lab/verification.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9884\u7b97\u611f\u77e5\u7684\u5224\u522b\u5f0f\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u7ed3\u5408\u81ea\u4e00\u81f4\u6027\u673a\u5236\uff0c\u5728\u56fa\u5b9a\u8ba1\u7b97\u9884\u7b97\u4e0b\u663e\u8457\u4f18\u4e8e\u751f\u6210\u5f0f\u9a8c\u8bc1\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u9a8c\u8bc1\u5668\u867d\u7136\u6027\u80fd\u4f18\u79c0\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002\u9700\u8981\u5bfb\u627e\u66f4\u9ad8\u6548\u7684\u9a8c\u8bc1\u7b56\u7565\u3002", "method": "\u91c7\u7528\u5224\u522b\u5f0f\u9a8c\u8bc1\u5668\u7ed3\u5408\u81ea\u4e00\u81f4\u6027\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u5728\u56fa\u5b9a\u8ba1\u7b97\u9884\u7b97\u4e0b\u8fdb\u884c\u6d4b\u8bd5\u65f6\u6269\u5c55\u3002", "result": "\u5728AIME2025\u4e0a\u5b9e\u73b0\u4e86\u6bd4\u6700\u5148\u8fdb\u751f\u6210\u5f0f\u9a8c\u8bc1\u65b9\u6cd5\u9ad815.3%\u7684\u51c6\u786e\u7387\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u9ad8\u6548\u6027\u3002", "conclusion": "\u9884\u7b97\u611f\u77e5\u7684\u5224\u522b\u5f0f\u9a8c\u8bc1\u4e0d\u4ec5\u662f\u5bf9\u81ea\u4e00\u81f4\u6027\u7684\u514d\u8d39\u5347\u7ea7\uff0c\u800c\u4e14\u662f\u6bd4\u6602\u8d35\u751f\u6210\u5f0f\u6280\u672f\u66f4\u6709\u6548\u548c\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2510.14922", "categories": ["cs.AI", "cs.CL", "cs.LG", "eess.AS", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.14922", "abs": "https://arxiv.org/abs/2510.14922", "authors": ["Annisaa Fitri Nurfidausi", "Eleonora Mancini", "Paolo Torroni"], "title": "TRI-DEP: A Trimodal Comparative Study for Depression Detection Using Speech, Text, and EEG", "comment": null, "summary": "Depression is a widespread mental health disorder, yet its automatic\ndetection remains challenging. Prior work has explored unimodal and multimodal\napproaches, with multimodal systems showing promise by leveraging complementary\nsignals. However, existing studies are limited in scope, lack systematic\ncomparisons of features, and suffer from inconsistent evaluation protocols. We\naddress these gaps by systematically exploring feature representations and\nmodelling strategies across EEG, together with speech and text. We evaluate\nhandcrafted features versus pre-trained embeddings, assess the effectiveness of\ndifferent neural encoders, compare unimodal, bimodal, and trimodal\nconfigurations, and analyse fusion strategies with attention to the role of\nEEG. Consistent subject-independent splits are applied to ensure robust,\nreproducible benchmarking. Our results show that (i) the combination of EEG,\nspeech and text modalities enhances multimodal detection, (ii) pretrained\nembeddings outperform handcrafted features, and (iii) carefully designed\ntrimodal models achieve state-of-the-art performance. Our work lays the\ngroundwork for future research in multimodal depression detection.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u591a\u6a21\u6001\u6291\u90c1\u75c7\u68c0\u6d4b\uff0c\u6bd4\u8f83\u4e86EEG\u3001\u8bed\u97f3\u548c\u6587\u672c\u7684\u7279\u5f81\u8868\u793a\u4e0e\u5efa\u6a21\u7b56\u7565\uff0c\u53d1\u73b0\u4e09\u6a21\u6001\u7ec4\u5408\u80fd\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\uff0c\u9884\u8bad\u7ec3\u5d4c\u5165\u4f18\u4e8e\u624b\u5de5\u7279\u5f81\uff0c\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u4e09\u6a21\u6001\u6a21\u578b\u8fbe\u5230SOTA\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u6291\u90c1\u75c7\u81ea\u52a8\u68c0\u6d4b\u7814\u7a76\u5b58\u5728\u8303\u56f4\u6709\u9650\u3001\u7f3a\u4e4f\u7cfb\u7edf\u7279\u5f81\u6bd4\u8f83\u548c\u8bc4\u4f30\u534f\u8bae\u4e0d\u4e00\u81f4\u7b49\u95ee\u9898\uff0c\u9700\u8981\u7cfb\u7edf\u63a2\u7d22\u591a\u6a21\u6001\u7279\u5f81\u8868\u793a\u548c\u5efa\u6a21\u7b56\u7565\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30\u624b\u5de5\u7279\u5f81\u4e0e\u9884\u8bad\u7ec3\u5d4c\u5165\uff0c\u6bd4\u8f83\u4e0d\u540c\u795e\u7ecf\u7f16\u7801\u5668\u7684\u6709\u6548\u6027\uff0c\u5206\u6790\u5355\u6a21\u6001\u3001\u53cc\u6a21\u6001\u548c\u4e09\u6a21\u6001\u914d\u7f6e\uff0c\u7814\u7a76\u878d\u5408\u7b56\u7565\u5e76\u5173\u6ce8EEG\u7684\u4f5c\u7528\uff0c\u91c7\u7528\u4e00\u81f4\u7684\u53d7\u8bd5\u8005\u72ec\u7acb\u5206\u5272\u8fdb\u884c\u7a33\u5065\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "EEG\u3001\u8bed\u97f3\u548c\u6587\u672c\u4e09\u6a21\u6001\u7ec4\u5408\u80fd\u589e\u5f3a\u591a\u6a21\u6001\u68c0\u6d4b\u6027\u80fd\uff1b\u9884\u8bad\u7ec3\u5d4c\u5165\u4f18\u4e8e\u624b\u5de5\u7279\u5f81\uff1b\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u4e09\u6a21\u6001\u6a21\u578b\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u672a\u6765\u591a\u6a21\u6001\u6291\u90c1\u75c7\u68c0\u6d4b\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u8bc1\u660e\u4e86\u591a\u6a21\u6001\u878d\u5408\u548c\u9884\u8bad\u7ec3\u5d4c\u5165\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.14925", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14925", "abs": "https://arxiv.org/abs/2510.14925", "authors": ["Akira Okutomi"], "title": "Stable but Miscalibrated: A Kantian View on Overconfidence from Filters to Large Language Models", "comment": "19 pages, 2 figures, preliminary version", "summary": "We reinterpret Kant's Critique of Pure Reason as a theory of feedback\nstability, viewing reason as a regulator that keeps inference within the bounds\nof possible experience. We formalize this intuition via a composite instability\nindex (H-Risk) combining spectral margin, conditioning, temporal sensitivity,\nand innovation amplification. In linear-Gaussian simulations, higher H-Risk\npredicts overconfident errors even under formal stability, revealing a gap\nbetween nominal and epistemic stability. Extending to large language models\n(LLMs), we find that fragile internal dynamics correlate with miscalibration\nand hallucination, while critique-style prompts show mixed effects on\ncalibration and hallucination. These results suggest a structural bridge\nbetween Kantian self-limitation and feedback control, offering a principled\nlens for diagnosing -- and selectively reducing -- overconfidence in reasoning\nsystems. This is a preliminary version; supplementary experiments and broader\nreplication will be reported in a future revision.", "AI": {"tldr": "\u5c06\u5eb7\u5fb7\u7684\u300a\u7eaf\u7cb9\u7406\u6027\u6279\u5224\u300b\u91cd\u65b0\u89e3\u91ca\u4e3a\u53cd\u9988\u7a33\u5b9a\u6027\u7406\u8bba\uff0c\u63d0\u51fa\u590d\u5408\u4e0d\u7a33\u5b9a\u6027\u6307\u6570(H-Risk)\u6765\u8861\u91cf\u63a8\u7406\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\uff0c\u53d1\u73b0\u9ad8H-Risk\u9884\u6d4b\u8fc7\u5ea6\u81ea\u4fe1\u9519\u8bef\uff0c\u5e76\u5e94\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u5206\u6790\u5e7b\u89c9\u95ee\u9898\u3002", "motivation": "\u5efa\u7acb\u5eb7\u5fb7\u7406\u6027\u81ea\u6211\u9650\u5236\u7406\u8bba\u4e0e\u53cd\u9988\u63a7\u5236\u7406\u8bba\u4e4b\u95f4\u7684\u7ed3\u6784\u6027\u6865\u6881\uff0c\u4e3a\u8bca\u65ad\u548c\u51cf\u5c11\u63a8\u7406\u7cfb\u7edf\u4e2d\u7684\u8fc7\u5ea6\u81ea\u4fe1\u63d0\u4f9b\u539f\u5219\u6027\u89c6\u89d2\u3002", "method": "\u63d0\u51fa\u590d\u5408\u4e0d\u7a33\u5b9a\u6027\u6307\u6570H-Risk\uff0c\u7ed3\u5408\u8c31\u8fb9\u754c\u3001\u6761\u4ef6\u6570\u3001\u65f6\u95f4\u654f\u611f\u6027\u548c\u521b\u65b0\u653e\u5927\u7b49\u6307\u6807\uff0c\u5728\u7ebf\u6027\u9ad8\u65af\u6a21\u62df\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5728\u7ebf\u6027\u9ad8\u65af\u6a21\u62df\u4e2d\uff0c\u9ad8H-Risk\u9884\u6d4b\u8fc7\u5ea6\u81ea\u4fe1\u9519\u8bef\uff1b\u5728LLMs\u4e2d\uff0c\u8106\u5f31\u7684\u5185\u90e8\u52a8\u6001\u4e0e\u6821\u51c6\u9519\u8bef\u548c\u5e7b\u89c9\u76f8\u5173\uff0c\u6279\u5224\u5f0f\u63d0\u793a\u5bf9\u6821\u51c6\u548c\u5e7b\u89c9\u7684\u5f71\u54cd\u4e0d\u4e00\u3002", "conclusion": "\u5eb7\u5fb7\u7684\u81ea\u6211\u9650\u5236\u6982\u5ff5\u4e0e\u53cd\u9988\u63a7\u5236\u7406\u8bba\u4e4b\u95f4\u5b58\u5728\u7ed3\u6784\u6027\u8054\u7cfb\uff0c\u8fd9\u4e3a\u8bca\u65ad\u548c\u9009\u62e9\u6027\u51cf\u5c11\u63a8\u7406\u7cfb\u7edf\u4e2d\u7684\u8fc7\u5ea6\u81ea\u4fe1\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2510.14942", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14942", "abs": "https://arxiv.org/abs/2510.14942", "authors": ["Yao Zhang", "Yu Wu", "Haowei Zhang", "Weiguo Li", "Haokun Chen", "Jingpei Wu", "Guohao Li", "Zhen Han", "Volker Tresp"], "title": "GroundedPRM: Tree-Guided and Fidelity-Aware Process Reward Modeling for Step-Level Reasoning", "comment": "25 pages", "summary": "Process Reward Models (PRMs) aim to improve multi-step reasoning in Large\nLanguage Models (LLMs) by supervising intermediate steps and identifying\nerrors. However, building effective PRMs remains challenging due to the lack of\nscalable, high-quality annotations. Existing approaches rely on costly human\nlabeling, LLM-based self-evaluation that is prone to hallucination, or Monte\nCarlo (MC) estimation, which infers step quality solely from rollout outcomes\nand often introduces noisy, misaligned supervision due to credit\nmisattribution. These issues result in three core limitations: noisy rewards,\nlow factual fidelity, and misalignment with step-level reasoning objectives. To\naddress these challenges, we introduce GroundedPRM, a tree-guided and\nfidelity-aware framework for automatic process supervision. To reduce reward\nnoise and enable fine-grained credit assignment, we construct structured\nreasoning paths via Monte Carlo Tree Search (MCTS). To eliminate hallucinated\nsupervision, we validate each intermediate step using an external tool,\nproviding execution-grounded correctness signals. To combine both step-level\nvalidation and global outcome assessment, we design a hybrid reward aggregation\nmechanism that fuses tool-based verification with MCTS-derived feedback.\nFinally, we format the reward signal into a rationale-enhanced, generative\nstructure to promote interpretability and compatibility with instruction-tuned\nLLMs. GroundedPRM is trained on only 40K automatically labeled samples,\namounting to just 10% of the data used by the best-performing PRM trained with\nauto-labeled supervision. Nevertheless, it achieves up to a 26% relative\nimprovement in average performance on ProcessBench. When used for reward-guided\ngreedy search, GroundedPRM outperforms even PRMs trained with human-labeled\nsupervision, offering a scalable and verifiable path toward high-quality\nprocess-level reasoning.", "AI": {"tldr": "GroundedPRM\u662f\u4e00\u4e2a\u57fa\u4e8e\u6811\u5f15\u5bfc\u548c\u4fdd\u771f\u5ea6\u611f\u77e5\u7684\u81ea\u52a8\u8fc7\u7a0b\u76d1\u7763\u6846\u67b6\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u6784\u5efa\u7ed3\u6784\u5316\u63a8\u7406\u8def\u5f84\uff0c\u4f7f\u7528\u5916\u90e8\u5de5\u5177\u9a8c\u8bc1\u4e2d\u95f4\u6b65\u9aa4\uff0c\u7ed3\u5408\u6b65\u9aa4\u7ea7\u9a8c\u8bc1\u548c\u5168\u5c40\u7ed3\u679c\u8bc4\u4f30\uff0c\u5728\u5c11\u91cf\u81ea\u52a8\u6807\u6ce8\u6570\u636e\u4e0a\u5b9e\u73b0\u9ad8\u8d28\u91cf\u7684\u591a\u6b65\u63a8\u7406\u76d1\u7763\u3002", "motivation": "\u73b0\u6709\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u9762\u4e34\u4e09\u5927\u6311\u6218\uff1a\u566a\u58f0\u5956\u52b1\u3001\u4f4e\u4e8b\u5b9e\u4fdd\u771f\u5ea6\u4ee5\u53ca\u4e0e\u6b65\u9aa4\u7ea7\u63a8\u7406\u76ee\u6807\u7684\u4e0d\u5bf9\u9f50\u3002\u8fd9\u4e9b\u95ee\u9898\u7684\u6839\u6e90\u5728\u4e8e\u7f3a\u4e4f\u53ef\u6269\u5c55\u7684\u9ad8\u8d28\u91cf\u6807\u6ce8\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u6602\u8d35\u7684\u4eba\u5de5\u6807\u6ce8\u3001\u6613\u4ea7\u751f\u5e7b\u89c9\u7684LLM\u81ea\u8bc4\u4f30\u6216\u5b58\u5728\u4fe1\u7528\u5206\u914d\u9519\u8bef\u7684\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u3002", "method": "1) \u4f7f\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u6784\u5efa\u7ed3\u6784\u5316\u63a8\u7406\u8def\u5f84\uff0c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u4fe1\u7528\u5206\u914d\uff1b2) \u901a\u8fc7\u5916\u90e8\u5de5\u5177\u9a8c\u8bc1\u6bcf\u4e2a\u4e2d\u95f4\u6b65\u9aa4\uff0c\u63d0\u4f9b\u57fa\u4e8e\u6267\u884c\u7684\u6b63\u786e\u6027\u4fe1\u53f7\uff1b3) \u8bbe\u8ba1\u6df7\u5408\u5956\u52b1\u805a\u5408\u673a\u5236\uff0c\u878d\u5408\u5de5\u5177\u9a8c\u8bc1\u548cMCTS\u53cd\u9988\uff1b4) \u5c06\u5956\u52b1\u4fe1\u53f7\u683c\u5f0f\u5316\u4e3a\u589e\u5f3a\u63a8\u7406\u7684\u751f\u6210\u7ed3\u6784\uff0c\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u4ec5\u4f7f\u75284\u4e07\u4e2a\u81ea\u52a8\u6807\u6ce8\u6837\u672c\uff08\u6700\u4f73\u81ea\u52a8\u76d1\u7763PRM\u6570\u636e\u91cf\u768410%\uff09\uff0c\u5728ProcessBench\u4e0a\u5b9e\u73b0\u9ad8\u8fbe26%\u7684\u76f8\u5bf9\u6027\u80fd\u63d0\u5347\u3002\u5728\u5956\u52b1\u5f15\u5bfc\u7684\u8d2a\u5a6a\u641c\u7d22\u4e2d\uff0c\u751a\u81f3\u4f18\u4e8e\u4f7f\u7528\u4eba\u5de5\u6807\u6ce8\u76d1\u7763\u8bad\u7ec3\u7684PRM\u3002", "conclusion": "GroundedPRM\u63d0\u4f9b\u4e86\u4e00\u6761\u53ef\u6269\u5c55\u4e14\u53ef\u9a8c\u8bc1\u7684\u9ad8\u8d28\u91cf\u8fc7\u7a0b\u7ea7\u63a8\u7406\u8def\u5f84\uff0c\u89e3\u51b3\u4e86\u73b0\u6709PRM\u7684\u6838\u5fc3\u9650\u5236\uff0c\u5728\u5c11\u91cf\u6570\u636e\u4e0a\u5b9e\u73b0\u4e86\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2510.14980", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.GR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14980", "abs": "https://arxiv.org/abs/2510.14980", "authors": ["Wenqian Zhang", "Weiyang Liu", "Zhen Liu"], "title": "Agentic Design of Compositional Machines", "comment": "75 pages, 31 figures, Project Page: https://besiegefield.github.io", "summary": "The design of complex machines stands as both a marker of human intelligence\nand a foundation of engineering practice. Given recent advances in large\nlanguage models (LLMs), we ask whether they, too, can learn to create. We\napproach this question through the lens of compositional machine design: a task\nin which machines are assembled from standardized components to meet functional\ndemands like locomotion or manipulation in a simulated physical environment. To\nsupport this investigation, we introduce BesiegeField, a testbed built on the\nmachine-building game Besiege, which enables part-based construction, physical\nsimulation and reward-driven evaluation. Using BesiegeField, we benchmark\nstate-of-the-art LLMs with agentic workflows and identify key capabilities\nrequired for success, including spatial reasoning, strategic assembly, and\ninstruction-following. As current open-source models fall short, we explore\nreinforcement learning (RL) as a path to improvement: we curate a cold-start\ndataset, conduct RL finetuning experiments, and highlight open challenges at\nthe intersection of language, machine design, and physical reasoning.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u591f\u8fdb\u884c\u590d\u6742\u673a\u5668\u8bbe\u8ba1\uff0c\u901a\u8fc7BesiegeField\u6d4b\u8bd5\u5e73\u53f0\u8bc4\u4f30LLM\u5728\u7ec4\u5408\u5f0f\u673a\u5668\u8bbe\u8ba1\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5f53\u524d\u5f00\u6e90\u6a21\u578b\u5b58\u5728\u4e0d\u8db3\uff0c\u5e76\u63a2\u7d22\u4e86\u5f3a\u5316\u5b66\u4e60\u4f5c\u4e3a\u6539\u8fdb\u8def\u5f84\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u673a\u5668\u8bbe\u8ba1\u65b9\u9762\u7684\u80fd\u529b\uff0c\u8fd9\u662f\u4eba\u7c7b\u667a\u80fd\u7684\u91cd\u8981\u6807\u5fd7\u548c\u5de5\u7a0b\u5b9e\u8df5\u7684\u57fa\u7840\u3002\u901a\u8fc7\u673a\u5668\u7ec4\u5408\u8bbe\u8ba1\u4efb\u52a1\u6765\u6d4b\u8bd5LLM\u7684\u521b\u9020\u80fd\u529b\u3002", "method": "\u5f15\u5165BesiegeField\u6d4b\u8bd5\u5e73\u53f0\uff0c\u57fa\u4e8eBesiege\u6e38\u620f\u6784\u5efa\uff0c\u652f\u6301\u90e8\u4ef6\u7ec4\u88c5\u3001\u7269\u7406\u6a21\u62df\u548c\u5956\u52b1\u9a71\u52a8\u8bc4\u4f30\u3002\u4f7f\u7528\u4ee3\u7406\u5de5\u4f5c\u6d41\u7a0b\u5bf9\u6700\u5148\u8fdb\u7684LLM\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u63a2\u7d22\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u65b9\u6cd5\u3002", "result": "\u53d1\u73b0\u5f53\u524d\u5f00\u6e90LLM\u5728\u7a7a\u95f4\u63a8\u7406\u3001\u7b56\u7565\u7ec4\u88c5\u548c\u6307\u4ee4\u9075\u5faa\u7b49\u5173\u952e\u80fd\u529b\u4e0a\u8868\u73b0\u4e0d\u8db3\u3002\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u5b9e\u9a8c\u5c55\u793a\u4e86\u6539\u8fdb\u6f5c\u529b\uff0c\u4f46\u4ecd\u6709\u6311\u6218\u5b58\u5728\u3002", "conclusion": "\u7814\u7a76\u8868\u660eLLM\u5728\u673a\u5668\u8bbe\u8ba1\u4efb\u52a1\u4e2d\u4ecd\u6709\u5c40\u9650\uff0c\u5f3a\u5316\u5b66\u4e60\u662f\u6f5c\u5728\u7684\u6539\u8fdb\u65b9\u5411\uff0c\u4f46\u5728\u8bed\u8a00\u3001\u673a\u5668\u8bbe\u8ba1\u548c\u7269\u7406\u63a8\u7406\u7684\u4ea4\u53c9\u9886\u57df\u4ecd\u5b58\u5728\u5f00\u653e\u6311\u6218\u3002"}}
