{"id": "2602.15968", "categories": ["cs.SE", "cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.15968", "abs": "https://arxiv.org/abs/2602.15968", "authors": ["Pedro Reynolds-Cu\u00e9llar", "Marisol Wong-Villacres", "Adriana Alvarado Garcia", "Heila Precel"], "title": "From Reflection to Repair: A Scoping Review of Dataset Documentation Tools", "comment": "to be published at the CHI conference on Human Factors in Computing Systems", "summary": "Dataset documentation is widely recognized as essential for the responsible development of automated systems. Despite growing efforts to support documentation through different kinds of artifacts, little is known about the motivations shaping documentation tool design or the factors hindering their adoption. We present a systematic review supported by mixed-methods analysis of 59 dataset documentation publications to examine the motivations behind building documentation tools, how authors conceptualize documentation practices, and how these tools connect to existing systems, regulations, and cultural norms. Our analysis shows four persistent patterns in dataset documentation conceptualization that potentially impede adoption and standardization: unclear operationalizations of documentation's value, decontextualized designs, unaddressed labor demands, and a tendency to treat integration as future work. Building on these findings, we propose a shift in Responsible AI tool design toward institutional rather than individual solutions, and outline actions the HCI community can take to enable sustainable documentation practices.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u7cfb\u7edf\u7efc\u8ff0\u548c\u6df7\u5408\u65b9\u6cd5\u5206\u6790\u4e8659\u7bc7\u6570\u636e\u96c6\u6587\u6863\u51fa\u7248\u7269\uff0c\u53d1\u73b0\u6587\u6863\u5de5\u5177\u8bbe\u8ba1\u7684\u56db\u5927\u969c\u788d\uff1a\u4ef7\u503c\u5b9a\u4e49\u4e0d\u6e05\u3001\u8bbe\u8ba1\u8131\u79bb\u4e0a\u4e0b\u6587\u3001\u672a\u89e3\u51b3\u52b3\u52a8\u9700\u6c42\u3001\u96c6\u6210\u88ab\u89c6\u4e3a\u672a\u6765\u5de5\u4f5c\uff0c\u5e76\u63d0\u51fa\u5e94\u5411\u673a\u6784\u5316\u89e3\u51b3\u65b9\u6848\u8f6c\u53d8\u3002", "motivation": "\u5c3d\u7ba1\u6570\u636e\u96c6\u6587\u6863\u5bf9\u8d1f\u8d23\u4efbAI\u5f00\u53d1\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u5bf9\u6587\u6863\u5de5\u5177\u8bbe\u8ba1\u52a8\u673a\u548c\u91c7\u7528\u969c\u788d\u4e86\u89e3\u6709\u9650\u3002\u4f5c\u8005\u65e8\u5728\u901a\u8fc7\u7cfb\u7edf\u5206\u6790\u7406\u89e3\u6587\u6863\u5de5\u5177\u80cc\u540e\u7684\u8bbe\u8ba1\u52a8\u673a\u3001\u6587\u6863\u5b9e\u8df5\u6982\u5ff5\u5316\u65b9\u5f0f\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u5de5\u5177\u5982\u4f55\u4e0e\u73b0\u6709\u7cfb\u7edf\u3001\u6cd5\u89c4\u548c\u6587\u5316\u89c4\u8303\u8fde\u63a5\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u7efc\u8ff0\u548c\u6df7\u5408\u65b9\u6cd5\u5206\u6790\uff0c\u7814\u7a76\u4e8659\u7bc7\u6570\u636e\u96c6\u6587\u6863\u51fa\u7248\u7269\uff0c\u4ece\u591a\u4e2a\u7ef4\u5ea6\u5206\u6790\u6587\u6863\u5de5\u5177\u7684\u8bbe\u8ba1\u52a8\u673a\u3001\u6982\u5ff5\u5316\u65b9\u5f0f\u4ee5\u53ca\u4e0e\u73b0\u6709\u751f\u6001\u7cfb\u7edf\u7684\u8fde\u63a5\u3002", "result": "\u5206\u6790\u63ed\u793a\u4e86\u6570\u636e\u96c6\u6587\u6863\u6982\u5ff5\u5316\u7684\u56db\u4e2a\u6301\u7eed\u6a21\u5f0f\uff1a\u6587\u6863\u4ef7\u503c\u7684\u64cd\u4f5c\u5316\u5b9a\u4e49\u4e0d\u6e05\u6670\u3001\u8bbe\u8ba1\u8131\u79bb\u4e0a\u4e0b\u6587\u3001\u672a\u89e3\u51b3\u52b3\u52a8\u9700\u6c42\u3001\u503e\u5411\u4e8e\u5c06\u96c6\u6210\u89c6\u4e3a\u672a\u6765\u5de5\u4f5c\u3002\u8fd9\u4e9b\u6a21\u5f0f\u53ef\u80fd\u963b\u788d\u6587\u6863\u5de5\u5177\u7684\u91c7\u7528\u548c\u6807\u51c6\u5316\u3002", "conclusion": "\u57fa\u4e8e\u7814\u7a76\u53d1\u73b0\uff0c\u4f5c\u8005\u5efa\u8bae\u8d1f\u8d23\u4efbAI\u5de5\u5177\u8bbe\u8ba1\u5e94\u4ece\u4e2a\u4f53\u89e3\u51b3\u65b9\u6848\u8f6c\u5411\u673a\u6784\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u6982\u8ff0\u4e86HCI\u793e\u533a\u53ef\u4ee5\u91c7\u53d6\u7684\u884c\u52a8\uff0c\u4ee5\u652f\u6301\u53ef\u6301\u7eed\u7684\u6587\u6863\u5b9e\u8df5\u3002"}}
{"id": "2602.16012", "categories": ["cs.AI", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.16012", "abs": "https://arxiv.org/abs/2602.16012", "authors": ["Jieyi Bi", "Zhiguang Cao", "Jianan Zhou", "Wen Song", "Yaoxin Wu", "Jie Zhang", "Yining Ma", "Cathy Wu"], "title": "Towards Efficient Constraint Handling in Neural Solvers for Routing Problems", "comment": "Accepted by ICLR 2026", "summary": "Neural solvers have achieved impressive progress in addressing simple routing problems, particularly excelling in computational efficiency. However, their advantages under complex constraints remain nascent, for which current constraint-handling schemes via feasibility masking or implicit feasibility awareness can be inefficient or inapplicable for hard constraints. In this paper, we present Construct-and-Refine (CaR), the first general and efficient constraint-handling framework for neural routing solvers based on explicit learning-based feasibility refinement. Unlike prior construction-search hybrids that target reducing optimality gaps through heavy improvements yet still struggle with hard constraints, CaR achieves efficient constraint handling by designing a joint training framework that guides the construction module to generate diverse and high-quality solutions well-suited for a lightweight improvement process, e.g., 10 steps versus 5k steps in prior work. Moreover, CaR presents the first use of construction-improvement-shared representation, enabling potential knowledge sharing across paradigms by unifying the encoder, especially in more complex constrained scenarios. We evaluate CaR on typical hard routing constraints to showcase its broader applicability. Results demonstrate that CaR achieves superior feasibility, solution quality, and efficiency compared to both classical and neural state-of-the-art solvers.", "AI": {"tldr": "CaR\u662f\u4e00\u4e2a\u57fa\u4e8e\u663e\u5f0f\u5b66\u4e60\u53ef\u884c\u6027\u7ec6\u5316\u7684\u795e\u7ecf\u8def\u7531\u6c42\u89e3\u5668\u7ea6\u675f\u5904\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u8bad\u7ec3\u6307\u5bfc\u6784\u9020\u6a21\u5757\u751f\u6210\u9002\u5408\u8f7b\u91cf\u7ea7\u6539\u8fdb\u8fc7\u7a0b\u7684\u591a\u6837\u5316\u9ad8\u8d28\u91cf\u89e3\uff0c\u5728\u590d\u6742\u7ea6\u675f\u4e0b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u795e\u7ecf\u6c42\u89e3\u5668\u5728\u7b80\u5355\u8def\u7531\u95ee\u9898\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5728\u590d\u6742\u7ea6\u675f\u4e0b\u7684\u4f18\u52bf\u5c1a\u4e0d\u6210\u719f\u3002\u73b0\u6709\u7684\u901a\u8fc7\u53ef\u884c\u6027\u63a9\u7801\u6216\u9690\u5f0f\u53ef\u884c\u6027\u611f\u77e5\u7684\u7ea6\u675f\u5904\u7406\u65b9\u6848\u5bf9\u4e8e\u786c\u7ea6\u675f\u53ef\u80fd\u6548\u7387\u4f4e\u4e0b\u6216\u4e0d\u9002\u7528\u3002", "method": "\u63d0\u51faConstruct-and-Refine (CaR)\u6846\u67b6\uff0c\u57fa\u4e8e\u663e\u5f0f\u5b66\u4e60\u53ef\u884c\u6027\u7ec6\u5316\u3002\u8bbe\u8ba1\u8054\u5408\u8bad\u7ec3\u6846\u67b6\u6307\u5bfc\u6784\u9020\u6a21\u5757\u751f\u6210\u9002\u5408\u8f7b\u91cf\u7ea7\u6539\u8fdb\u8fc7\u7a0b\u7684\u591a\u6837\u5316\u9ad8\u8d28\u91cf\u89e3\uff0c\u5e76\u9996\u6b21\u4f7f\u7528\u6784\u9020-\u6539\u8fdb\u5171\u4eab\u8868\u793a\uff0c\u7edf\u4e00\u7f16\u7801\u5668\u5b9e\u73b0\u8de8\u8303\u5f0f\u77e5\u8bc6\u5171\u4eab\u3002", "result": "\u5728\u5178\u578b\u786c\u8def\u7531\u7ea6\u675f\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cCaR\u5728\u53ef\u884c\u6027\u3001\u89e3\u8d28\u91cf\u548c\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u7ecf\u5178\u548c\u795e\u7ecf\u6700\u5148\u8fdb\u7684\u6c42\u89e3\u5668\u3002", "conclusion": "CaR\u662f\u7b2c\u4e00\u4e2a\u901a\u7528\u4e14\u9ad8\u6548\u7684\u795e\u7ecf\u8def\u7531\u6c42\u89e3\u5668\u7ea6\u675f\u5904\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u5b66\u4e60\u53ef\u884c\u6027\u7ec6\u5316\u548c\u6784\u9020-\u6539\u8fdb\u5171\u4eab\u8868\u793a\uff0c\u5728\u590d\u6742\u7ea6\u675f\u573a\u666f\u4e0b\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2602.16156", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.16156", "abs": "https://arxiv.org/abs/2602.16156", "authors": ["Rohit Chatterjee", "Yunqi Li", "Prashant Nalini Vasudevan"], "title": "Weak Zero-Knowledge and One-Way Functions", "comment": null, "summary": "We study the implications of the existence of weak Zero-Knowledge (ZK) protocols for worst-case hard languages. These are protocols that have completeness, soundness, and zero-knowledge errors (denoted $\u03b5_c$, $\u03b5_s$, and $\u03b5_z$, respectively) that might not be negligible. Under the assumption that there are worst-case hard languages in NP, we show the following:\n  1. If all languages in NP have NIZK proofs or arguments satisfying $ \u03b5_c+\u03b5_s+ \u03b5_z < 1 $, then One-Way Functions (OWFs) exist.\n  This covers all possible non-trivial values for these error rates. It additionally implies that if all languages in NP have such NIZK proofs and $\u03b5_c$ is negligible, then they also have NIZK proofs where all errors are negligible. Previously, these results were known under the more restrictive condition $ \u03b5_c+\\sqrt{\u03b5_s}+\u03b5_z < 1 $ [Chakraborty et al., CRYPTO 2025].\n  2. If all languages in NP have $k$-round public-coin ZK proofs or arguments satisfying $ \u03b5_c+\u03b5_s+(2k-1).\u03b5_z < 1 $, then OWFs exist.\n  3. If, for some constant $k$, all languages in NP have $k$-round public-coin ZK proofs or arguments satisfying $ \u03b5_c+\u03b5_s+k.\u03b5_z < 1 $, then infinitely-often OWFs exist.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5f31\u96f6\u77e5\u8bc6\u534f\u8bae\u5bf9\u6700\u574f\u60c5\u51b5\u56f0\u96be\u8bed\u8a00\u5b58\u5728\u6027\u7684\u5f71\u54cd\uff0c\u6539\u8fdb\u4e86\u5148\u524d\u5173\u4e8e\u96f6\u77e5\u8bc6\u534f\u8bae\u8bef\u5dee\u53c2\u6570\u4e0e\u5355\u5411\u51fd\u6570\u5b58\u5728\u6027\u5173\u7cfb\u7684\u6761\u4ef6\u3002", "motivation": "\u7814\u7a76\u96f6\u77e5\u8bc6\u534f\u8bae\u4e2d\u975e\u53ef\u5ffd\u7565\u7684\u8bef\u5dee\u53c2\u6570\uff08\u5b8c\u5907\u6027\u3001\u53ef\u9760\u6027\u548c\u96f6\u77e5\u8bc6\u8bef\u5dee\uff09\u5bf9\u5bc6\u7801\u5b66\u57fa\u7840\u5047\u8bbe\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u8fd9\u4e9b\u8bef\u5dee\u53c2\u6570\u4e0e\u5355\u5411\u51fd\u6570\u5b58\u5728\u6027\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u5728NP\u4e2d\u5b58\u5728\u6700\u574f\u60c5\u51b5\u56f0\u96be\u8bed\u8a00\u7684\u5047\u8bbe\u4e0b\uff0c\u5206\u6790\u4e0d\u540c\u8bef\u5dee\u53c2\u6570\u7ec4\u5408\u6761\u4ef6\uff08\u03b5_c+\u03b5_s+\u03b5_z < 1\u7b49\uff09\u4e0b\uff0c\u96f6\u77e5\u8bc6\u534f\u8bae\u7684\u5b58\u5728\u6027\u4e0e\u5355\u5411\u51fd\u6570\u5b58\u5728\u6027\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "1. \u6539\u8fdb\u4e86Chakraborty\u7b49\u4eba\u7684\u7ed3\u679c\uff0c\u5c06\u6761\u4ef6\u4ece\u03b5_c+\u221a\u03b5_s+\u03b5_z < 1\u653e\u5bbd\u5230\u03b5_c+\u03b5_s+\u03b5_z < 1\uff1b2. \u7ed9\u51fa\u4e86k\u8f6e\u516c\u5f00\u63b7\u5e01\u96f6\u77e5\u8bc6\u534f\u8bae\u4e0e\u5355\u5411\u51fd\u6570\u5b58\u5728\u6027\u7684\u5173\u7cfb\uff1b3. \u8bc1\u660e\u4e86\u5e38\u6570\u8f6e\u534f\u8bae\u4e0b\u8f83\u5f31\u6761\u4ef6\u4e0b\u7684\u65e0\u9650\u7ecf\u5e38\u5355\u5411\u51fd\u6570\u5b58\u5728\u6027\u3002", "conclusion": "\u5373\u4f7f\u96f6\u77e5\u8bc6\u534f\u8bae\u5177\u6709\u975e\u53ef\u5ffd\u7565\u7684\u8bef\u5dee\u53c2\u6570\uff0c\u53ea\u8981\u6ee1\u8db3\u7279\u5b9a\u7684\u8bef\u5dee\u7ec4\u5408\u6761\u4ef6\uff0c\u8fd9\u4e9b\u534f\u8bae\u7684\u5b58\u5728\u4ecd\u7136\u80fd\u591f\u4fdd\u8bc1\u5355\u5411\u51fd\u6570\u7684\u5b58\u5728\uff0c\u8fd9\u6df1\u5316\u4e86\u6211\u4eec\u5bf9\u96f6\u77e5\u8bc6\u534f\u8bae\u4e0e\u5bc6\u7801\u5b66\u57fa\u7840\u5047\u8bbe\u4e4b\u95f4\u5173\u7cfb\u7684\u7406\u89e3\u3002"}}
{"id": "2602.15983", "categories": ["cs.SE", "cs.AI", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.15983", "abs": "https://arxiv.org/abs/2602.15983", "authors": ["Junbo Jacob Lian", "Yujun Sun", "Huiling Chen", "Chaoyu Zhang", "Chung-Piaw Teo"], "title": "ReLoop: Structured Modeling and Behavioral Verification for Reliable LLM-Based Optimization", "comment": "Code and benchmark: \\url{https://github.com/junbolian/ReLoop}", "summary": "Large language models (LLMs) can translate natural language into optimization code, but silent failures pose a critical risk: code that executes and returns solver-feasible solutions may encode semantically incorrect formulations, creating a feasibility-correctness gap of up to 90 percentage points on compositional problems. We introduce ReLoop, addressing silent failures from two complementary directions. Structured generation decomposes code production into a four-stage reasoning chain (understand, formalize, synthesize, verify) that mirrors expert modeling practice, with explicit variable-type reasoning and self-verification to prevent formulation errors at their source. Behavioral verification detects errors that survive generation by testing whether the formulation responds correctly to solver-based parameter perturbation, without requiring ground truth -- an external semantic signal that bypasses the self-consistency problem inherent in LLM-based code review. The two mechanisms are complementary: structured generation dominates on complex compositional problems, while behavioral verification becomes the largest single contributor on problems with localized formulation defects. Together with execution recovery via IIS-enhanced diagnostics, ReLoop raises correctness from 22.6% to 31.1% and execution from 72.1% to 100.0% on the strongest model, with consistent gains across five models spanning three paradigms (foundation, SFT, RL) and three benchmarks. We additionally release RetailOpt-190, 190 compositional retail optimization scenarios targeting the multi-constraint interactions where LLMs most frequently fail.", "AI": {"tldr": "ReLoop\u901a\u8fc7\u7ed3\u6784\u5316\u751f\u6210\u548c\u884c\u4e3a\u9a8c\u8bc1\u89e3\u51b3LLM\u5c06\u81ea\u7136\u8bed\u8a00\u8f6c\u6362\u4e3a\u4f18\u5316\u4ee3\u7801\u65f6\u7684\u9759\u9ed8\u5931\u8d25\u95ee\u9898\uff0c\u5c06\u6b63\u786e\u7387\u4ece22.6%\u63d0\u5347\u523031.1%\uff0c\u6267\u884c\u7387\u4ece72.1%\u63d0\u5347\u5230100%", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u5c06\u81ea\u7136\u8bed\u8a00\u8f6c\u6362\u4e3a\u4f18\u5316\u4ee3\u7801\uff0c\u4f46\u5b58\u5728\u9759\u9ed8\u5931\u8d25\u98ce\u9669\uff1a\u4ee3\u7801\u80fd\u6267\u884c\u5e76\u8fd4\u56de\u53ef\u884c\u89e3\uff0c\u4f46\u53ef\u80fd\u7f16\u7801\u4e86\u8bed\u4e49\u9519\u8bef\u7684\u516c\u5f0f\uff0c\u5728\u7ec4\u5408\u95ee\u9898\u4e0a\u53ef\u884c\u6027-\u6b63\u786e\u6027\u5dee\u8ddd\u9ad8\u8fbe90\u4e2a\u767e\u5206\u70b9", "method": "\u63d0\u51faReLoop\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u4e92\u8865\u673a\u5236\uff1a1) \u7ed3\u6784\u5316\u751f\u6210\uff1a\u5c06\u4ee3\u7801\u751f\u6210\u5206\u89e3\u4e3a\u7406\u89e3\u3001\u5f62\u5f0f\u5316\u3001\u5408\u6210\u3001\u9a8c\u8bc1\u56db\u9636\u6bb5\u63a8\u7406\u94fe\uff0c\u5305\u542b\u663e\u5f0f\u53d8\u91cf\u7c7b\u578b\u63a8\u7406\u548c\u81ea\u6211\u9a8c\u8bc1\uff1b2) \u884c\u4e3a\u9a8c\u8bc1\uff1a\u901a\u8fc7\u57fa\u4e8e\u6c42\u89e3\u5668\u7684\u53c2\u6570\u6270\u52a8\u6d4b\u8bd5\u516c\u5f0f\u54cd\u5e94\uff0c\u65e0\u9700\u771f\u5b9e\u6807\u7b7e\uff1b3) \u901a\u8fc7IIS\u589e\u5f3a\u8bca\u65ad\u7684\u6267\u884c\u6062\u590d", "result": "\u5728\u6700\u5f3a\u6a21\u578b\u4e0a\u5c06\u6b63\u786e\u7387\u4ece22.6%\u63d0\u5347\u523031.1%\uff0c\u6267\u884c\u7387\u4ece72.1%\u63d0\u5347\u5230100%\uff0c\u5728\u4e94\u4e2a\u6a21\u578b\uff08\u57fa\u7840\u6a21\u578b\u3001SFT\u3001RL\uff09\u548c\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u5747\u83b7\u5f97\u4e00\u81f4\u63d0\u5347\u3002\u540c\u65f6\u53d1\u5e03\u4e86RetailOpt-190\u6570\u636e\u96c6", "conclusion": "\u7ed3\u6784\u5316\u751f\u6210\u5728\u590d\u6742\u7ec4\u5408\u95ee\u9898\u4e0a\u5360\u4e3b\u5bfc\uff0c\u884c\u4e3a\u9a8c\u8bc1\u5728\u5c40\u90e8\u516c\u5f0f\u7f3a\u9677\u95ee\u9898\u4e0a\u8d21\u732e\u6700\u5927\u3002\u4e24\u79cd\u673a\u5236\u4e92\u8865\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u4f18\u5316\u4ee3\u7801\u751f\u6210\u7684\u9759\u9ed8\u5931\u8d25\u95ee\u9898"}}
{"id": "2602.16268", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.16268", "abs": "https://arxiv.org/abs/2602.16268", "authors": ["Marvin Beckmann", "Christian Majenz"], "title": "Quantum Oracle Distribution Switching and its Applications to Fully Anonymous Ring Signatures", "comment": null, "summary": "Ring signatures are a powerful primitive that allows a member to sign on behalf of a group, without revealing their identity. Recently, ring signatures have received additional attention as an ingredient for post-quantum deniable authenticated key exchange, e.g., for a post-quantum version of the Signal protocol, employed by virtually all end-to-end-encrypted messenger services. While several ring signature constructions from post-quantum assumptions offer suitable security and efficiency for use in deniable key exchange, they are currently proven secure in the random oracle model (ROM) only, which is insufficient for post-quantum security.\n  In this work, we provide four security reductions in the quantum-accessible random oracle model (QROM) for two generic ring signature constructions: two for the AOS framework and two for a construction paradigm based on ring trapdoors, whose generic backbone we formalize. The two security proofs for AOS ring signatures differ in their requirements on the underlying sigma protocol and their tightness. The two reductions for the ring-trapdoor-based ring signatures exhibit various differences in requirements and the security they provide. We employ the measure-and-reprogram technique, QROM straightline extraction tools based on the compressed oracle, history-free reductions and QROM reprogramming tools. To make use of R\u00e9nyi divergence properties in the QROM, we study the behavior of quantum algorithms that interact with an oracle whose distribution is based on one of two different distributions over the set of outputs. We provide tight bounds for the statistical distance, show that the R\u00e9nyi divergence can not be used to replace the entire oracle and provide a workaround.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e3a\u4e24\u79cd\u901a\u7528\u73af\u7b7e\u540d\u6784\u9020\uff08AOS\u6846\u67b6\u548c\u57fa\u4e8e\u73af\u9677\u95e8\u7684\u6784\u9020\uff09\u63d0\u4f9b\u4e86\u56db\u4e2a\u91cf\u5b50\u968f\u673a\u9884\u8a00\u673a\u6a21\u578b\uff08QROM\uff09\u4e0b\u7684\u5b89\u5168\u5f52\u7ea6\uff0c\u586b\u8865\u4e86\u540e\u91cf\u5b50\u73af\u7b7e\u540d\u5728QROM\u4e2d\u7f3a\u4e4f\u5f62\u5f0f\u5316\u5b89\u5168\u8bc1\u660e\u7684\u7a7a\u767d\u3002", "motivation": "\u73af\u7b7e\u540d\u5728\u540e\u91cf\u5b50\u53ef\u5426\u8ba4\u8ba4\u8bc1\u5bc6\u94a5\u4ea4\u6362\uff08\u5982Signal\u534f\u8bae\u7684\u540e\u91cf\u5b50\u7248\u672c\uff09\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\uff0c\u4f46\u73b0\u6709\u7684\u540e\u91cf\u5b50\u73af\u7b7e\u540d\u6784\u9020\u4ec5\u5728\u968f\u673a\u9884\u8a00\u673a\u6a21\u578b\uff08ROM\uff09\u4e2d\u88ab\u8bc1\u660e\u5b89\u5168\uff0c\u8fd9\u5bf9\u4e8e\u540e\u91cf\u5b50\u5b89\u5168\u6027\u6765\u8bf4\u662f\u4e0d\u591f\u7684\u3002\u9700\u8981\u4e3a\u8fd9\u4e9b\u6784\u9020\u63d0\u4f9b\u91cf\u5b50\u968f\u673a\u9884\u8a00\u673a\u6a21\u578b\uff08QROM\uff09\u4e0b\u7684\u5b89\u5168\u8bc1\u660e\u3002", "method": "\u91c7\u7528\u6d4b\u91cf\u91cd\u7f16\u7a0b\u6280\u672f\u3001\u57fa\u4e8e\u538b\u7f29\u9884\u8a00\u673a\u7684QROM\u76f4\u7ebf\u63d0\u53d6\u5de5\u5177\u3001\u65e0\u5386\u53f2\u5f52\u7ea6\u548cQROM\u91cd\u7f16\u7a0b\u5de5\u5177\u3002\u7814\u7a76\u4e86\u91cf\u5b50\u7b97\u6cd5\u4e0e\u57fa\u4e8e\u4e24\u79cd\u4e0d\u540c\u8f93\u51fa\u5206\u5e03\u9884\u8a00\u673a\u4ea4\u4e92\u7684\u884c\u4e3a\uff0c\u5206\u6790\u4e86\u7edf\u8ba1\u8ddd\u79bb\u7684\u7d27\u754c\uff0c\u5e76\u63d0\u4f9b\u4e86\u4f7f\u7528R\u00e9nyi\u6563\u5ea6\u7684\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u4e3aAOS\u6846\u67b6\u63d0\u4f9b\u4e86\u4e24\u4e2a\u5b89\u5168\u5f52\u7ea6\uff08\u5bf9\u5e95\u5c42sigma\u534f\u8bae\u7684\u8981\u6c42\u548c\u7d27\u81f4\u6027\u4e0d\u540c\uff09\uff0c\u4e3a\u57fa\u4e8e\u73af\u9677\u95e8\u7684\u6784\u9020\u63d0\u4f9b\u4e86\u4e24\u4e2a\u5b89\u5168\u5f52\u7ea6\uff08\u5728\u8981\u6c42\u548c\u5b89\u5168\u6027\u65b9\u9762\u5404\u6709\u5dee\u5f02\uff09\u3002\u5efa\u7acb\u4e86QROM\u4e0b\u73af\u7b7e\u540d\u7684\u5f62\u5f0f\u5316\u5b89\u5168\u8bc1\u660e\u6846\u67b6\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u586b\u8865\u4e86\u540e\u91cf\u5b50\u73af\u7b7e\u540d\u5728QROM\u4e2d\u7f3a\u4e4f\u5f62\u5f0f\u5316\u5b89\u5168\u8bc1\u660e\u7684\u91cd\u8981\u7a7a\u767d\uff0c\u4e3a\u540e\u91cf\u5b50\u53ef\u5426\u8ba4\u8ba4\u8bc1\u5bc6\u94a5\u4ea4\u6362\u534f\u8bae\uff08\u5982Signal\u7684\u540e\u91cf\u5b50\u7248\u672c\uff09\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u63a8\u52a8\u4e86\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2602.16039", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16039", "abs": "https://arxiv.org/abs/2602.16039", "authors": ["Hang Li", "Kaiqi Yang", "Xianxuan Long", "Fedor Filippov", "Yucheng Chu", "Yasemin Copur-Gencturk", "Peng He", "Cory Miller", "Namsoo Shin", "Joseph Krajcik", "Hui Liu", "Jiliang Tang"], "title": "How Uncertain Is the Grade? A Benchmark of Uncertainty Metrics for LLM-Based Automatic Assessment", "comment": null, "summary": "The rapid rise of large language models (LLMs) is reshaping the landscape of automatic assessment in education. While these systems demonstrate substantial advantages in adaptability to diverse question types and flexibility in output formats, they also introduce new challenges related to output uncertainty, stemming from the inherently probabilistic nature of LLMs. Output uncertainty is an inescapable challenge in automatic assessment, as assessment results often play a critical role in informing subsequent pedagogical actions, such as providing feedback to students or guiding instructional decisions. Unreliable or poorly calibrated uncertainty estimates can lead to unstable downstream interventions, potentially disrupting students' learning processes and resulting in unintended negative consequences. To systematically understand this challenge and inform future research, we benchmark a broad range of uncertainty quantification methods in the context of LLM-based automatic assessment. Although the effectiveness of these methods has been demonstrated in many tasks across other domains, their applicability and reliability in educational settings, particularly for automatic grading, remain underexplored. Through comprehensive analyses of uncertainty behaviors across multiple assessment datasets, LLM families, and generation control settings, we characterize the uncertainty patterns exhibited by LLMs in grading scenarios. Based on these findings, we evaluate the strengths and limitations of different uncertainty metrics and analyze the influence of key factors, including model families, assessment tasks, and decoding strategies, on uncertainty estimates. Our study provides actionable insights into the characteristics of uncertainty in LLM-based automatic assessment and lays the groundwork for developing more reliable and effective uncertainty-aware grading systems in the future.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6559\u80b2\u81ea\u52a8\u8bc4\u4f30\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\uff0c\u5206\u6790\u4e86\u4e0d\u786e\u5b9a\u6027\u6a21\u5f0f\u53ca\u5176\u5f71\u54cd\u56e0\u7d20\uff0c\u4e3a\u5f00\u53d1\u66f4\u53ef\u9760\u7684\u8bc4\u4f30\u7cfb\u7edf\u63d0\u4f9b\u57fa\u7840\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6559\u80b2\u81ea\u52a8\u8bc4\u4f30\u4e2d\u5c55\u73b0\u51fa\u4f18\u52bf\uff0c\u4f46\u5176\u56fa\u6709\u7684\u6982\u7387\u6027\u672c\u8d28\u5f15\u5165\u4e86\u8f93\u51fa\u4e0d\u786e\u5b9a\u6027\u7684\u6311\u6218\u3002\u8bc4\u4f30\u7ed3\u679c\u5bf9\u540e\u7eed\u6559\u5b66\u51b3\u7b56\u81f3\u5173\u91cd\u8981\uff0c\u4e0d\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u53ef\u80fd\u5bfc\u81f4\u4e0d\u7a33\u5b9a\u7684\u6559\u5b66\u5e72\u9884\uff0c\u5f71\u54cd\u5b66\u751f\u5b66\u4e60\u8fc7\u7a0b\u3002\u76ee\u524d\u8fd9\u4e9b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u5728\u6559\u80b2\u8bc4\u4f30\u9886\u57df\u7684\u9002\u7528\u6027\u548c\u53ef\u9760\u6027\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5728LLM\u81ea\u52a8\u8bc4\u4f30\u7684\u80cc\u666f\u4e0b\uff0c\u5bf9\u5e7f\u6cdb\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002\u901a\u8fc7\u7efc\u5408\u5206\u6790\u591a\u4e2a\u8bc4\u4f30\u6570\u636e\u96c6\u3001\u4e0d\u540cLLM\u5bb6\u65cf\u548c\u751f\u6210\u63a7\u5236\u8bbe\u7f6e\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u884c\u4e3a\uff0c\u63cf\u8ff0LLM\u5728\u8bc4\u5206\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u7684\u4e0d\u786e\u5b9a\u6027\u6a21\u5f0f\u3002\u8bc4\u4f30\u4e0d\u540c\u4e0d\u786e\u5b9a\u6027\u6307\u6807\u7684\u4f18\u7f3a\u70b9\uff0c\u5e76\u5206\u6790\u6a21\u578b\u5bb6\u65cf\u3001\u8bc4\u4f30\u4efb\u52a1\u548c\u89e3\u7801\u7b56\u7565\u7b49\u5173\u952e\u56e0\u7d20\u5bf9\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86LLM\u5728\u81ea\u52a8\u8bc4\u5206\u573a\u666f\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u6a21\u5f0f\u7279\u5f81\uff0c\u8bc4\u4f30\u4e86\u4e0d\u540c\u4e0d\u786e\u5b9a\u6027\u6307\u6807\u7684\u4f18\u52bf\u548c\u5c40\u9650\u6027\uff0c\u5e76\u5206\u6790\u4e86\u6a21\u578b\u5bb6\u65cf\u3001\u8bc4\u4f30\u4efb\u52a1\u548c\u89e3\u7801\u7b56\u7565\u7b49\u56e0\u7d20\u5bf9\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u5f71\u54cd\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7406\u89e3LLM\u81ea\u52a8\u8bc4\u4f30\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u7279\u5f81\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\uff0c\u4e3a\u672a\u6765\u5f00\u53d1\u66f4\u53ef\u9760\u548c\u6709\u6548\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u8bc4\u5206\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2602.16304", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.16304", "abs": "https://arxiv.org/abs/2602.16304", "authors": ["Ahmed Ryan", "Ibrahim Khalil", "Abdullah Al Jahid", "Md Erfan", "Akond Ashfaque Ur Rahman", "Md Rayhanur Rahman"], "title": "Mind the Gap: Evaluating LLMs for High-Level Malicious Package Detection vs. Fine-Grained Indicator Identification", "comment": null, "summary": "The prevalence of malicious packages in open-source repositories, such as PyPI, poses a critical threat to the software supply chain. While Large Language Models (LLMs) have emerged as a promising tool for automated security tasks, their effectiveness in detecting malicious packages and indicators remains underexplored. This paper presents a systematic evaluation of 13 LLMs for detecting malicious software packages. Using a curated dataset of 4,070 packages (3,700 benign and 370 malicious), we evaluate model performance across two tasks: binary classification (package detection) and multi-label classification (identification of specific malicious indicators). We further investigate the impact of prompting strategies, temperature settings, and model specifications on detection accuracy. We find a significant \"granularity gap\" in LLMs' capabilities. While GPT-4.1 achieves near-perfect performance in binary detection (F1 $\\approx$ 0.99), performance degrades by approximately 41\\% when the task shifts to identifying specific malicious indicators. We observe that general models are best for filtering out the majority of threats, while specialized coder models are better at detecting attacks that follow a strict, predictable code structure. Our correlation analysis indicates that parameter size and context width have negligible explanatory power regarding detection accuracy. We conclude that while LLMs are powerful detectors at the package level, they lack the semantic depth required for precise identification at the granular indicator level.", "AI": {"tldr": "LLMs\u5728\u6076\u610f\u8f6f\u4ef6\u5305\u68c0\u6d4b\u4e2d\u5b58\u5728\"\u7c92\u5ea6\u5dee\u8ddd\"\uff1aGPT-4.1\u5728\u4e8c\u8fdb\u5236\u5206\u7c7b\u4e2d\u8868\u73b0\u4f18\u5f02\uff08F1\u22480.99\uff09\uff0c\u4f46\u5728\u8bc6\u522b\u5177\u4f53\u6076\u610f\u6307\u6807\u65f6\u6027\u80fd\u4e0b\u964d\u7ea641%\u3002\u901a\u7528\u6a21\u578b\u9002\u5408\u8fc7\u6ee4\u591a\u6570\u5a01\u80c1\uff0c\u800c\u4e13\u7528\u7f16\u7801\u6a21\u578b\u66f4\u64c5\u957f\u68c0\u6d4b\u7ed3\u6784\u5316\u653b\u51fb\u3002", "motivation": "\u5f00\u6e90\u4ed3\u5e93\uff08\u5982PyPI\uff09\u4e2d\u6076\u610f\u8f6f\u4ef6\u5305\u7684\u666e\u904d\u5b58\u5728\u5bf9\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u6784\u6210\u4e25\u91cd\u5a01\u80c1\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5df2\u6210\u4e3a\u81ea\u52a8\u5316\u5b89\u5168\u4efb\u52a1\u7684\u6709\u524d\u666f\u5de5\u5177\uff0c\u4f46\u5b83\u4eec\u5728\u68c0\u6d4b\u6076\u610f\u8f6f\u4ef6\u5305\u548c\u5177\u4f53\u6307\u6807\u65b9\u9762\u7684\u6709\u6548\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u4f7f\u7528\u5305\u542b4,070\u4e2a\u8f6f\u4ef6\u5305\uff083,700\u4e2a\u826f\u6027\uff0c370\u4e2a\u6076\u610f\uff09\u7684\u7cbe\u9009\u6570\u636e\u96c6\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e8613\u4e2aLLMs\u5728\u4e24\u4e2a\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff1a\u4e8c\u8fdb\u5236\u5206\u7c7b\uff08\u8f6f\u4ef6\u5305\u68c0\u6d4b\uff09\u548c\u591a\u6807\u7b7e\u5206\u7c7b\uff08\u8bc6\u522b\u5177\u4f53\u6076\u610f\u6307\u6807\uff09\u3002\u8fdb\u4e00\u6b65\u7814\u7a76\u4e86\u63d0\u793a\u7b56\u7565\u3001\u6e29\u5ea6\u8bbe\u7f6e\u548c\u6a21\u578b\u89c4\u683c\u5bf9\u68c0\u6d4b\u51c6\u786e\u6027\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0LLMs\u5b58\u5728\u663e\u8457\u7684\"\u7c92\u5ea6\u5dee\u8ddd\"\uff1aGPT-4.1\u5728\u4e8c\u8fdb\u5236\u68c0\u6d4b\u4e2d\u8fbe\u5230\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u6027\u80fd\uff08F1\u22480.99\uff09\uff0c\u4f46\u5728\u8bc6\u522b\u5177\u4f53\u6076\u610f\u6307\u6807\u65f6\u6027\u80fd\u4e0b\u964d\u7ea641%\u3002\u901a\u7528\u6a21\u578b\u6700\u9002\u5408\u8fc7\u6ee4\u5927\u591a\u6570\u5a01\u80c1\uff0c\u800c\u4e13\u7528\u7f16\u7801\u6a21\u578b\u66f4\u64c5\u957f\u68c0\u6d4b\u9075\u5faa\u4e25\u683c\u3001\u53ef\u9884\u6d4b\u4ee3\u7801\u7ed3\u6784\u7684\u653b\u51fb\u3002\u76f8\u5173\u6027\u5206\u6790\u8868\u660e\u53c2\u6570\u5927\u5c0f\u548c\u4e0a\u4e0b\u6587\u5bbd\u5ea6\u5bf9\u68c0\u6d4b\u51c6\u786e\u6027\u7684\u89e3\u91ca\u529b\u53ef\u4ee5\u5ffd\u7565\u4e0d\u8ba1\u3002", "conclusion": "\u867d\u7136LLMs\u5728\u8f6f\u4ef6\u5305\u7ea7\u522b\u662f\u5f3a\u5927\u7684\u68c0\u6d4b\u5668\uff0c\u4f46\u5b83\u4eec\u7f3a\u4e4f\u5728\u7c92\u5ea6\u6307\u6807\u7ea7\u522b\u8fdb\u884c\u7cbe\u786e\u8bc6\u522b\u6240\u9700\u7684\u8bed\u4e49\u6df1\u5ea6\u3002\u901a\u7528\u6a21\u578b\u548c\u4e13\u7528\u7f16\u7801\u6a21\u578b\u5404\u6709\u4f18\u52bf\uff0c\u9700\u8981\u6839\u636e\u5177\u4f53\u4efb\u52a1\u9009\u62e9\u5408\u9002\u7684\u6a21\u578b\u3002"}}
{"id": "2602.16091", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.16091", "abs": "https://arxiv.org/abs/2602.16091", "authors": ["Amirali Rayegan", "Tim Menzies"], "title": "Can Causality Cure Confusion Caused By Correlation (in Software Analytics)?", "comment": "Submitted to MSR'26 in Registered Report track", "summary": "Background: Symbolic models, particularly decision trees, are widely used in software engineering for explainable analytics in defect prediction, configuration tuning, and software quality assessment. Most of these models rely on correlational split criteria, such as variance reduction or information gain, which identify statistical associations but cannot imply causation between X and Y. Recent empirical studies in software engineering show that both correlational models and causal discovery algorithms suffer from pronounced instability. This instability arises from two complementary issues: 1-Correlation-based methods conflate association with causation. 2-Causal discovery algorithms rely on heuristic approximations to cope with the NP-hard nature of structure learning, causing their inferred graphs to vary widely under minor input perturbations. Together, these issues undermine trust, reproducibility, and the reliability of explanations in real-world SE tasks. Objective: This study investigates whether incorporating causality-aware split criteria into symbolic models can improve their stability and robustness, and whether such gains come at the cost of predictive or optimization performance. We additionally examine how the stability of human expert judgments compares to that of automated models. Method: Using 120+ multi-objective optimization tasks from the MOOT repository of multi-objective optimization tasks, we evaluate stability through a preregistered bootstrap-ensemble protocol that measures variance with win-score assignments. We compare the stability of human causal assessments with correlation-based decision trees (EZR). We would also compare the causality-aware trees, which leverage conditional-entropy split criteria and confounder filtering. Stability and performance differences are analyzed using statistical methods (variance, Gini Impurity, KS test, Cliff's delta)", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u5728\u7b26\u53f7\u6a21\u578b\uff08\u7279\u522b\u662f\u51b3\u7b56\u6811\uff09\u4e2d\u5f15\u5165\u56e0\u679c\u611f\u77e5\u5206\u5272\u51c6\u5219\u662f\u5426\u80fd\u63d0\u9ad8\u7a33\u5b9a\u6027\uff0c\u540c\u65f6\u8bc4\u4f30\u5176\u5bf9\u9884\u6d4b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u6bd4\u8f83\u4eba\u7c7b\u4e13\u5bb6\u5224\u65ad\u4e0e\u81ea\u52a8\u5316\u6a21\u578b\u7684\u7a33\u5b9a\u6027\u5dee\u5f02\u3002", "motivation": "\u5f53\u524d\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u7684\u7b26\u53f7\u6a21\u578b\uff08\u5982\u51b3\u7b56\u6811\uff09\u4e3b\u8981\u4f9d\u8d56\u76f8\u5173\u6027\u5206\u5272\u51c6\u5219\uff08\u5982\u65b9\u5dee\u51cf\u5c11\u3001\u4fe1\u606f\u589e\u76ca\uff09\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u6df7\u6dc6\u4e86\u5173\u8054\u4e0e\u56e0\u679c\u5173\u7cfb\uff0c\u5bfc\u81f4\u6a21\u578b\u4e0d\u7a33\u5b9a\u3002\u540c\u65f6\uff0c\u56e0\u679c\u53d1\u73b0\u7b97\u6cd5\u56e0NP\u96be\u95ee\u9898\u800c\u4f9d\u8d56\u542f\u53d1\u5f0f\u8fd1\u4f3c\uff0c\u5728\u8f7b\u5fae\u8f93\u5165\u6270\u52a8\u4e0b\u7ed3\u679c\u53d8\u5316\u5f88\u5927\u3002\u8fd9\u4e9b\u95ee\u9898\u5f71\u54cd\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u89e3\u91ca\u7684\u53ef\u4fe1\u5ea6\u3001\u53ef\u91cd\u590d\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "\u4f7f\u7528MOOT\u5b58\u50a8\u5e93\u4e2d\u7684120\u591a\u4e2a\u591a\u76ee\u6807\u4f18\u5316\u4efb\u52a1\uff0c\u901a\u8fc7\u9884\u6ce8\u518c\u7684\u81ea\u4e3e\u96c6\u6210\u534f\u8bae\u8bc4\u4f30\u7a33\u5b9a\u6027\uff0c\u6d4b\u91cf\u65b9\u5dee\u548c\u80dc\u7387\u5f97\u5206\u3002\u6bd4\u8f83\u4eba\u7c7b\u56e0\u679c\u8bc4\u4f30\u4e0e\u57fa\u4e8e\u76f8\u5173\u6027\u7684\u51b3\u7b56\u6811\uff08EZR\uff09\uff0c\u4ee5\u53ca\u56e0\u679c\u611f\u77e5\u6811\uff08\u5229\u7528\u6761\u4ef6\u71b5\u5206\u5272\u51c6\u5219\u548c\u6df7\u6742\u56e0\u5b50\u8fc7\u6ee4\uff09\u3002\u4f7f\u7528\u7edf\u8ba1\u65b9\u6cd5\uff08\u65b9\u5dee\u3001\u57fa\u5c3c\u4e0d\u7eaf\u5ea6\u3001KS\u68c0\u9a8c\u3001Cliff's delta\uff09\u5206\u6790\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u5dee\u5f02\u3002", "result": "\u8bba\u6587\u6458\u8981\u4e2d\u672a\u63d0\u4f9b\u5177\u4f53\u7ed3\u679c\uff0c\u4f46\u7814\u7a76\u8bbe\u8ba1\u65e8\u5728\u8bc4\u4f30\u56e0\u679c\u611f\u77e5\u5206\u5272\u51c6\u5219\u662f\u5426\u80fd\u63d0\u9ad8\u7b26\u53f7\u6a21\u578b\u7684\u7a33\u5b9a\u6027\uff0c\u540c\u65f6\u4e0d\u727a\u7272\u9884\u6d4b\u6216\u4f18\u5316\u6027\u80fd\uff0c\u5e76\u6bd4\u8f83\u4eba\u7c7b\u4e13\u5bb6\u5224\u65ad\u4e0e\u81ea\u52a8\u5316\u6a21\u578b\u7684\u7a33\u5b9a\u6027\u5dee\u5f02\u3002", "conclusion": "\u7814\u7a76\u65e8\u5728\u9a8c\u8bc1\u56e0\u679c\u611f\u77e5\u5206\u5272\u51c6\u5219\u80fd\u5426\u89e3\u51b3\u5f53\u524d\u7b26\u53f7\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u5e94\u7528\u4e2d\u9762\u4e34\u7684\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u4e3a\u6784\u5efa\u66f4\u53ef\u9760\u3001\u53ef\u89e3\u91ca\u7684\u8f6f\u4ef6\u5206\u6790\u6a21\u578b\u63d0\u4f9b\u7406\u8bba\u548c\u65b9\u6cd5\u652f\u6301\u3002"}}
{"id": "2602.16106", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.16106", "abs": "https://arxiv.org/abs/2602.16106", "authors": ["Shahriar Rumi Dipto", "Saikat Mondal", "Chanchal K. Roy"], "title": "Algorithm-Based Pipeline for Reliable and Intent-Preserving Code Translation with LLMs", "comment": "Accepted at 34th IEEE/ACM International Conference on Program Comprehension (ICPC 2026)", "summary": "Code translation, the automatic conversion of programs between languages, is a growing use case for Large Language Models (LLMs). However, direct one-shot translation often fails to preserve program intent, leading to errors in control flow, type handling, and I/O behavior. We propose an algorithm-based pipeline that introduces a language-neutral intermediate specification to capture these details before code generation. This study empirically evaluates the extent to which structured planning can improve translation accuracy and reliability relative to direct translation. We conduct an automated paired experiment - direct and algorithm-based to translate between Python and Java using five widely used LLMs on the Avatar and CodeNet datasets. For each combination (model, dataset, approach, and direction), we compile and execute the translated program and run the tests provided. We record compilation results, runtime behavior, timeouts (e.g., infinite loop), and test outcomes. We compute accuracy from these tests, counting a translation as correct only if it compiles, runs without exceptions or timeouts, and passes all tests. We then map every failed compile-time and runtime case to a unified, language-aware taxonomy and compare subtype frequencies between the direct and algorithm-based approaches. Overall, the Algorithm-based approach increases micro-average accuracy from 67.7% to 78.5% (10.8% increase). It eliminates lexical and token errors by 100%, reduces incomplete constructs by 72.7%, and structural and declaration issues by 61.1%. It also substantially lowers runtime dependency and entry-point failures by 78.4%. These results demonstrate that algorithm-based pipelines enable more reliable, intent-preserving code translation, providing a foundation for robust multilingual programming assistants.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7b97\u6cd5\u7684\u4ee3\u7801\u7ffb\u8bd1\u7ba1\u9053\uff0c\u901a\u8fc7\u5f15\u5165\u8bed\u8a00\u4e2d\u7acb\u7684\u4e2d\u95f4\u89c4\u8303\u6765\u6355\u83b7\u7a0b\u5e8f\u610f\u56fe\u7ec6\u8282\uff0c\u76f8\u6bd4\u76f4\u63a5\u7ffb\u8bd1\u5c06\u51c6\u786e\u7387\u4ece67.7%\u63d0\u5347\u523078.5%\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u5404\u7c7b\u7f16\u8bd1\u548c\u8fd0\u884c\u65f6\u9519\u8bef\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u7ffb\u8bd1\u4e2d\u7ecf\u5e38\u65e0\u6cd5\u4fdd\u6301\u7a0b\u5e8f\u610f\u56fe\uff0c\u5bfc\u81f4\u63a7\u5236\u6d41\u3001\u7c7b\u578b\u5904\u7406\u548cI/O\u884c\u4e3a\u9519\u8bef\u3002\u76f4\u63a5\u4e00\u6b21\u6027\u7ffb\u8bd1\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u7ed3\u6784\u5316\u7684\u65b9\u6cd5\u6765\u786e\u4fdd\u7ffb\u8bd1\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u7b97\u6cd5\u7684\u7ffb\u8bd1\u7ba1\u9053\uff0c\u5f15\u5165\u8bed\u8a00\u4e2d\u7acb\u7684\u4e2d\u95f4\u89c4\u8303\u6765\u6355\u83b7\u7a0b\u5e8f\u7ec6\u8282\uff0c\u7136\u540e\u751f\u6210\u4ee3\u7801\u3002\u4f7f\u7528\u4e94\u79cd\u5e7f\u6cdb\u4f7f\u7528\u7684LLM\u5728Avatar\u548cCodeNet\u6570\u636e\u96c6\u4e0a\u8fdb\u884cPython\u548cJava\u4e4b\u95f4\u7684\u81ea\u52a8\u5316\u914d\u5bf9\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u76f4\u63a5\u7ffb\u8bd1\u548c\u7b97\u6cd5\u7ffb\u8bd1\u65b9\u6cd5\u3002\u901a\u8fc7\u7f16\u8bd1\u6267\u884c\u3001\u6d4b\u8bd5\u8fd0\u884c\u3001\u9519\u8bef\u5206\u7c7b\u7b49\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "\u7b97\u6cd5\u65b9\u6cd5\u5c06\u5fae\u5e73\u5747\u51c6\u786e\u7387\u4ece67.7%\u63d0\u9ad8\u523078.5%\uff08\u63d0\u534710.8%\uff09\u3002\u5b8c\u5168\u6d88\u9664\u4e86\u8bcd\u6c47\u548c\u6807\u8bb0\u9519\u8bef\uff08100%\uff09\uff0c\u51cf\u5c11\u4e8672.7%\u7684\u4e0d\u5b8c\u6574\u7ed3\u6784\u9519\u8bef\uff0c\u51cf\u5c11\u4e8661.1%\u7684\u7ed3\u6784\u548c\u58f0\u660e\u95ee\u9898\uff0c\u964d\u4f4e\u4e8678.4%\u7684\u8fd0\u884c\u65f6\u4f9d\u8d56\u548c\u5165\u53e3\u70b9\u5931\u8d25\u3002", "conclusion": "\u57fa\u4e8e\u7b97\u6cd5\u7684\u7ba1\u9053\u80fd\u591f\u5b9e\u73b0\u66f4\u53ef\u9760\u3001\u610f\u56fe\u4fdd\u6301\u7684\u4ee3\u7801\u7ffb\u8bd1\uff0c\u4e3a\u5065\u58ee\u7684\u591a\u8bed\u8a00\u7f16\u7a0b\u52a9\u624b\u63d0\u4f9b\u4e86\u57fa\u7840\u3002\u7ed3\u6784\u5316\u89c4\u5212\u663e\u8457\u63d0\u9ad8\u4e86\u7ffb\u8bd1\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2602.16066", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16066", "abs": "https://arxiv.org/abs/2602.16066", "authors": ["Martin Klissarov", "Jonathan Cook", "Diego Antognini", "Hao Sun", "Jingling Li", "Natasha Jaques", "Claudiu Musat", "Edward Grefenstette"], "title": "Improving Interactive In-Context Learning from Natural Language Feedback", "comment": null, "summary": "Adapting one's thought process based on corrective feedback is an essential ability in human learning, particularly in collaborative settings. In contrast, the current large language model training paradigm relies heavily on modeling vast, static corpora. While effective for knowledge acquisition, it overlooks the interactive feedback loops essential for models to adapt dynamically to their context. In this work, we propose a framework that treats this interactive in-context learning ability not as an emergent property, but as a distinct, trainable skill. We introduce a scalable method that transforms single-turn verifiable tasks into multi-turn didactic interactions driven by information asymmetry. We first show that current flagship models struggle to integrate corrective feedback on hard reasoning tasks. We then demonstrate that models trained with our approach dramatically improve the ability to interactively learn from language feedback. More specifically, the multi-turn performance of a smaller model nearly reaches that of a model an order of magnitude larger. We also observe robust out-of-distribution generalization: interactive training on math problems transfers to diverse domains like coding, puzzles and maze navigation. Our qualitative analysis suggests that this improvement is due to an enhanced in-context plasticity. Finally, we show that this paradigm offers a unified path to self-improvement. By training the model to predict the teacher's critiques, effectively modeling the feedback environment, we convert this external signal into an internal capability, allowing the model to self-correct even without a teacher.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u8bad\u7ec3\u6846\u67b6\uff0c\u5c06\u4ea4\u4e92\u5f0f\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u4f5c\u4e3a\u53ef\u8bad\u7ec3\u6280\u80fd\u800c\u975e\u6d8c\u73b0\u7279\u6027\uff0c\u901a\u8fc7\u4fe1\u606f\u4e0d\u5bf9\u79f0\u5c06\u5355\u8f6e\u53ef\u9a8c\u8bc1\u4efb\u52a1\u8f6c\u5316\u4e3a\u591a\u8f6e\u6559\u5b66\u4e92\u52a8\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u4ece\u8bed\u8a00\u53cd\u9988\u4e2d\u5b66\u4e60\u7684\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e3b\u8981\u4f9d\u8d56\u9759\u6001\u8bed\u6599\u5e93\u5efa\u6a21\uff0c\u5ffd\u89c6\u4e86\u4eba\u7c7b\u5b66\u4e60\u4e2d\u57fa\u4e8e\u7ea0\u6b63\u53cd\u9988\u52a8\u6001\u8c03\u6574\u601d\u7ef4\u8fc7\u7a0b\u7684\u5173\u952e\u80fd\u529b\u3002\u8fd9\u79cd\u4ea4\u4e92\u5f0f\u53cd\u9988\u5faa\u73af\u5bf9\u4e8e\u6a21\u578b\u5728\u534f\u4f5c\u73af\u5883\u4e2d\u52a8\u6001\u9002\u5e94\u4e0a\u4e0b\u6587\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u53ef\u6269\u5c55\u65b9\u6cd5\uff0c\u5c06\u5355\u8f6e\u53ef\u9a8c\u8bc1\u4efb\u52a1\u8f6c\u5316\u4e3a\u591a\u8f6e\u6559\u5b66\u4e92\u52a8\uff0c\u5229\u7528\u4fe1\u606f\u4e0d\u5bf9\u79f0\u9a71\u52a8\u4ea4\u4e92\u3002\u8bad\u7ec3\u6a21\u578b\u9884\u6d4b\u6559\u5e08\u7684\u6279\u8bc4\uff0c\u4ece\u800c\u5c06\u5916\u90e8\u53cd\u9988\u4fe1\u53f7\u8f6c\u5316\u4e3a\u5185\u90e8\u80fd\u529b\uff0c\u5b9e\u73b0\u81ea\u6211\u7ea0\u6b63\u3002", "result": "\u7ecf\u8be5\u65b9\u6cd5\u8bad\u7ec3\u7684\u5c0f\u6a21\u578b\u591a\u8f6e\u6027\u80fd\u63a5\u8fd1\u5927\u4e00\u4e2a\u6570\u91cf\u7ea7\u7684\u5927\u6a21\u578b\uff1b\u5728\u6570\u5b66\u95ee\u9898\u4e0a\u7684\u4ea4\u4e92\u8bad\u7ec3\u80fd\u6cdb\u5316\u5230\u7f16\u7a0b\u3001\u8c1c\u9898\u548c\u8ff7\u5bab\u5bfc\u822a\u7b49\u591a\u6837\u9886\u57df\uff1b\u6a21\u578b\u5c55\u73b0\u51fa\u589e\u5f3a\u7684\u4e0a\u4e0b\u6587\u53ef\u5851\u6027\uff0c\u5e76\u80fd\u5b9e\u73b0\u81ea\u6211\u6539\u8fdb\u3002", "conclusion": "\u4ea4\u4e92\u5f0f\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u53ef\u4f5c\u4e3a\u53ef\u8bad\u7ec3\u6280\u80fd\u5f00\u53d1\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u5347\u6a21\u578b\u4ece\u53cd\u9988\u4e2d\u5b66\u4e60\u7684\u80fd\u529b\uff0c\u8fd8\u63d0\u4f9b\u7edf\u4e00\u7684\u81ea\u6211\u6539\u8fdb\u8def\u5f84\uff0c\u4f7f\u6a21\u578b\u80fd\u5728\u65e0\u6559\u5e08\u60c5\u51b5\u4e0b\u81ea\u6211\u7ea0\u6b63\u3002"}}
{"id": "2602.16480", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.16480", "abs": "https://arxiv.org/abs/2602.16480", "authors": ["Yiwen Lu"], "title": "SRFed: Mitigating Poisoning Attacks in Privacy-Preserving Federated Learning with Heterogeneous Data", "comment": "Federated learning, functional encryption, privacy-preserving machine learning, neural networks", "summary": "Federated Learning (FL) enables collaborative model training without exposing clients' private data, and has been widely adopted in privacy-sensitive scenarios. However, FL faces two critical security threats: curious servers that may launch inference attacks to reconstruct clients' private data, and compromised clients that can launch poisoning attacks to disrupt model aggregation. Existing solutions mitigate these attacks by combining mainstream privacy-preserving techniques with defensive aggregation strategies. However, they either incur high computation and communication overhead or perform poorly under non-independent and identically distributed (Non-IID) data settings. To tackle these challenges, we propose SRFed, an efficient Byzantine-robust and privacy-preserving FL framework for Non-IID scenarios. First, we design a decentralized efficient functional encryption (DEFE) scheme to support efficient model encryption and non-interactive decryption. DEFE also eliminates third-party reliance and defends against server-side inference attacks. Second, we develop a privacy-preserving defensive model aggregation mechanism based on DEFE. This mechanism filters poisonous models under Non-IID data by layer-wise projection and clustering-based analysis. Theoretical analysis and extensive experiments show that SRFed outperforms state-of-the-art baselines in privacy protection, Byzantine robustness, and efficiency.", "AI": {"tldr": "SRFed\u662f\u4e00\u4e2a\u9488\u5bf9\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u53bb\u4e2d\u5fc3\u5316\u529f\u80fd\u52a0\u5bc6\u548c\u9690\u79c1\u4fdd\u62a4\u7684\u9632\u5fa1\u6027\u805a\u5408\u673a\u5236\uff0c\u540c\u65f6\u62b5\u5fa1\u670d\u52a1\u5668\u63a8\u7406\u653b\u51fb\u548c\u5ba2\u6237\u7aef\u6295\u6bd2\u653b\u51fb\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u9762\u4e34\u4e24\u5927\u5b89\u5168\u5a01\u80c1\uff1a\u597d\u5947\u670d\u52a1\u5668\u53ef\u80fd\u53d1\u8d77\u63a8\u7406\u653b\u51fb\u91cd\u6784\u5ba2\u6237\u7aef\u79c1\u6709\u6570\u636e\uff0c\u4ee5\u53ca\u88ab\u653b\u9677\u5ba2\u6237\u7aef\u53ef\u80fd\u53d1\u8d77\u6295\u6bd2\u653b\u51fb\u7834\u574f\u6a21\u578b\u805a\u5408\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u8981\u4e48\u8ba1\u7b97\u901a\u4fe1\u5f00\u9500\u9ad8\uff0c\u8981\u4e48\u5728\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u573a\u666f\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002", "method": "1. \u8bbe\u8ba1\u53bb\u4e2d\u5fc3\u5316\u9ad8\u6548\u529f\u80fd\u52a0\u5bc6\u65b9\u6848\uff0c\u652f\u6301\u9ad8\u6548\u6a21\u578b\u52a0\u5bc6\u548c\u975e\u4ea4\u4e92\u5f0f\u89e3\u5bc6\uff0c\u6d88\u9664\u7b2c\u4e09\u65b9\u4f9d\u8d56\u5e76\u9632\u5fa1\u670d\u52a1\u5668\u7aef\u63a8\u7406\u653b\u51fb\uff1b2. \u57fa\u4e8e\u8be5\u52a0\u5bc6\u65b9\u6848\u5f00\u53d1\u9690\u79c1\u4fdd\u62a4\u7684\u9632\u5fa1\u6027\u6a21\u578b\u805a\u5408\u673a\u5236\uff0c\u901a\u8fc7\u5206\u5c42\u6295\u5f71\u548c\u57fa\u4e8e\u805a\u7c7b\u7684\u5206\u6790\u5728\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u4e0b\u8fc7\u6ee4\u6709\u6bd2\u6a21\u578b\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cSRFed\u5728\u9690\u79c1\u4fdd\u62a4\u3001\u62dc\u5360\u5ead\u9c81\u68d2\u6027\u548c\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "SRFed\u4e3a\u8054\u90a6\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u62dc\u5360\u5ead\u9c81\u68d2\u4e14\u9690\u79c1\u4fdd\u62a4\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u573a\u666f\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u8ba1\u7b97\u5f00\u9500\u548c\u975e\u72ec\u7acb\u540c\u5206\u5e03\u9002\u5e94\u6027\u65b9\u9762\u7684\u4e0d\u8db3\u3002"}}
{"id": "2602.16499", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.16499", "abs": "https://arxiv.org/abs/2602.16499", "authors": ["Carsten Ellwein", "David Dietrich", "Jessica Roth", "Rozana Cvitkovic", "Andreas Wortmann"], "title": "Software-heavy Asset Administration Shells: Classification and Use Cases", "comment": null, "summary": "The Asset Administration Shell (AAS) is an emerging technology for the implementation of digital twins in the field of manufacturing. Software is becoming increasingly important, not only in general but specifically in relation to manufacturing, especially with regard to digital manufacturing and a shift towards the usage of artificial intelligence. This increases the need not only to model software, but also to integrate services directly into the AAS. The existing literature contains individual solutions to implement such software-heavy AAS. However, there is no systematic analysis of software architectures that integrate software services directly into the AAS. This paper aims to fill this research gap and differentiate architectures based on software quality criteria as well as typical manufacturing use cases. This work may be considered as an interpretation guideline for software-heavy AAS, both in academia and for practitioners.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5206\u6790\u4e86\u5c06\u8f6f\u4ef6\u670d\u52a1\u76f4\u63a5\u96c6\u6210\u5230\u8d44\u4ea7\u7ba1\u7406\u58f3(AAS)\u4e2d\u7684\u8f6f\u4ef6\u67b6\u6784\uff0c\u586b\u8865\u4e86\u73b0\u6709\u6587\u732e\u4e2d\u7f3a\u4e4f\u7cfb\u7edf\u6027\u5206\u6790\u7684\u7a7a\u767d\u3002", "motivation": "\u8d44\u4ea7\u7ba1\u7406\u58f3(AAS)\u662f\u5b9e\u73b0\u5236\u9020\u4e1a\u6570\u5b57\u5b6a\u751f\u7684\u65b0\u5174\u6280\u672f\u3002\u968f\u7740\u8f6f\u4ef6\u5728\u5236\u9020\u4e1a\u4e2d\u7684\u91cd\u8981\u6027\u65e5\u76ca\u589e\u52a0\uff0c\u7279\u522b\u662f\u5728\u6570\u5b57\u5316\u5236\u9020\u548c\u4eba\u5de5\u667a\u80fd\u5e94\u7528\u65b9\u9762\uff0c\u4e0d\u4ec5\u9700\u8981\u5efa\u6a21\u8f6f\u4ef6\uff0c\u8fd8\u9700\u8981\u5c06\u670d\u52a1\u76f4\u63a5\u96c6\u6210\u5230AAS\u4e2d\u3002\u73b0\u6709\u6587\u732e\u867d\u7136\u5305\u542b\u4e86\u4e2a\u522b\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5c06\u8f6f\u4ef6\u670d\u52a1\u76f4\u63a5\u96c6\u6210\u5230AAS\u7684\u8f6f\u4ef6\u67b6\u6784\u7684\u7cfb\u7edf\u6027\u5206\u6790\u3002", "method": "\u57fa\u4e8e\u8f6f\u4ef6\u8d28\u91cf\u6807\u51c6\u548c\u5178\u578b\u5236\u9020\u4e1a\u7528\u4f8b\u5bf9\u67b6\u6784\u8fdb\u884c\u533a\u5206\u548c\u7cfb\u7edf\u5206\u6790\uff0c\u4e3a\u8f6f\u4ef6\u5bc6\u96c6\u578bAAS\u63d0\u4f9b\u89e3\u91ca\u6027\u6307\u5bfc\u6846\u67b6\u3002", "result": "\u63d0\u51fa\u4e86\u9488\u5bf9\u8f6f\u4ef6\u5bc6\u96c6\u578bAAS\u7684\u67b6\u6784\u5206\u7c7b\u548c\u5206\u6790\u6846\u67b6\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u4e3a\u5b66\u672f\u754c\u548c\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u6307\u5bfc\u3002", "conclusion": "\u672c\u6587\u4e3a\u8f6f\u4ef6\u5bc6\u96c6\u578b\u8d44\u4ea7\u7ba1\u7406\u58f3\u63d0\u4f9b\u4e86\u67b6\u6784\u5206\u6790\u6846\u67b6\uff0c\u65e2\u53ef\u4f5c\u4e3a\u5b66\u672f\u7814\u7a76\u7684\u7406\u8bba\u57fa\u7840\uff0c\u4e5f\u53ef\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u5b9e\u65bd\u6307\u5bfc\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u5236\u9020\u4e1a\u6570\u5b57\u5316\u8f6c\u578b\u4e2d\u8f6f\u4ef6\u670d\u52a1\u7684\u6709\u6548\u96c6\u6210\u3002"}}
{"id": "2602.16105", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16105", "abs": "https://arxiv.org/abs/2602.16105", "authors": ["Thinh Hung Truong", "Jey Han Lau", "Jianzhong Qi"], "title": "GPSBench: Do Large Language Models Understand GPS Coordinates?", "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed in applications that interact with the physical world, such as navigation, robotics, or mapping, making robust geospatial reasoning a critical capability. Despite that, LLMs' ability to reason about GPS coordinates and real-world geography remains underexplored. We introduce GPSBench, a dataset of 57,800 samples across 17 tasks for evaluating geospatial reasoning in LLMs, spanning geometric coordinate operations (e.g., distance and bearing computation) and reasoning that integrates coordinates with world knowledge. Focusing on intrinsic model capabilities rather than tool use, we evaluate 14 state-of-the-art LLMs and find that GPS reasoning remains challenging, with substantial variation across tasks: models are generally more reliable at real-world geographic reasoning than at geometric computations. Geographic knowledge degrades hierarchically, with strong country-level performance but weak city-level localization, while robustness to coordinate noise suggests genuine coordinate understanding rather than memorization. We further show that GPS-coordinate augmentation can improve in downstream geospatial tasks, and that finetuning induces trade-offs between gains in geometric computation and degradation in world knowledge. Our dataset and reproducible code are available at https://github.com/joey234/gpsbench", "AI": {"tldr": "GPSBench\u662f\u4e00\u4e2a\u5305\u542b57,800\u4e2a\u6837\u672c\u3001\u8986\u76d617\u4e2a\u4efb\u52a1\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5730\u7406\u7a7a\u95f4\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u771f\u5b9e\u4e16\u754c\u5730\u7406\u63a8\u7406\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u51e0\u4f55\u8ba1\u7b97\uff0c\u4e14\u5730\u7406\u77e5\u8bc6\u5448\u73b0\u5c42\u7ea7\u6027\u9000\u5316\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5bfc\u822a\u3001\u673a\u5668\u4eba\u3001\u5730\u56fe\u7b49\u7269\u7406\u4e16\u754c\u4ea4\u4e92\u5e94\u7528\u4e2d\u7684\u90e8\u7f72\u589e\u52a0\uff0c\u7a33\u5065\u7684\u5730\u7406\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0cLLM\u5728GPS\u5750\u6807\u548c\u771f\u5b9e\u4e16\u754c\u5730\u7406\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5f15\u5165GPSBench\u6570\u636e\u96c6\uff0c\u5305\u542b57,800\u4e2a\u6837\u672c\u548c17\u4e2a\u4efb\u52a1\uff0c\u6db5\u76d6\u51e0\u4f55\u5750\u6807\u64cd\u4f5c\uff08\u5982\u8ddd\u79bb\u548c\u65b9\u4f4d\u8ba1\u7b97\uff09\u4ee5\u53ca\u5750\u6807\u4e0e\u4e16\u754c\u77e5\u8bc6\u7ed3\u5408\u7684\u63a8\u7406\u3002\u8bc4\u4f30\u4e8614\u4e2a\u6700\u5148\u8fdb\u7684LLM\uff0c\u4e13\u6ce8\u4e8e\u5185\u5728\u6a21\u578b\u80fd\u529b\u800c\u975e\u5de5\u5177\u4f7f\u7528\u3002", "result": "GPS\u63a8\u7406\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u4e0d\u540c\u4efb\u52a1\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff1a\u6a21\u578b\u5728\u771f\u5b9e\u4e16\u754c\u5730\u7406\u63a8\u7406\u65b9\u9762\u901a\u5e38\u6bd4\u51e0\u4f55\u8ba1\u7b97\u66f4\u53ef\u9760\u3002\u5730\u7406\u77e5\u8bc6\u5448\u73b0\u5c42\u7ea7\u6027\u9000\u5316\uff0c\u56fd\u5bb6\u5c42\u9762\u8868\u73b0\u5f3a\u4f46\u57ce\u5e02\u5c42\u9762\u5b9a\u4f4d\u5f31\u3002\u5750\u6807\u566a\u58f0\u7684\u9c81\u68d2\u6027\u8868\u660e\u6a21\u578b\u5177\u6709\u771f\u6b63\u7684\u5750\u6807\u7406\u89e3\u800c\u975e\u7b80\u5355\u8bb0\u5fc6\u3002GPS\u5750\u6807\u589e\u5f3a\u53ef\u4ee5\u6539\u5584\u4e0b\u6e38\u5730\u7406\u7a7a\u95f4\u4efb\u52a1\uff0c\u5fae\u8c03\u4f1a\u5728\u51e0\u4f55\u8ba1\u7b97\u589e\u76ca\u548c\u4e16\u754c\u77e5\u8bc6\u9000\u5316\u4e4b\u95f4\u4ea7\u751f\u6743\u8861\u3002", "conclusion": "GPSBench\u4e3a\u8bc4\u4f30LLM\u7684\u5730\u7406\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u7cfb\u7edf\u57fa\u51c6\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u5728\u51e0\u4f55\u8ba1\u7b97\u548c\u5730\u7406\u77e5\u8bc6\u6574\u5408\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u6539\u8fdb\u63d0\u4f9b\u4e86\u65b9\u5411\uff0c\u540c\u65f6\u5c55\u793a\u4e86\u5750\u6807\u589e\u5f3a\u548c\u5fae\u8c03\u7b56\u7565\u7684\u6f5c\u529b\u4e0e\u6743\u8861\u3002"}}
{"id": "2602.16671", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16671", "abs": "https://arxiv.org/abs/2602.16671", "authors": ["Jaid Monwar Chowdhury", "Chi-An Fu", "Reyhaneh Jabbarvand"], "title": "SPARC: Scenario Planning and Reasoning for Automated C Unit Test Generation", "comment": "9 pages, 6 figures, 4 tables", "summary": "Automated unit test generation for C remains a formidable challenge due to the semantic gap between high-level program intent and the rigid syntactic constraints of pointer arithmetic and manual memory management. While Large Language Models (LLMs) exhibit strong generative capabilities, direct intent-to-code synthesis frequently suffers from the leap-to-code failure mode, where models prematurely emit code without grounding in program structure, constraints, and semantics. This will result in non-compilable tests, hallucinated function signatures, low branch coverage, and semantically irrelevant assertions that cannot properly capture bugs. We introduce SPARC, a neuro-symbolic, scenario-based framework that bridges this gap through four stages: (1) Control Flow Graph (CFG) analysis, (2) an Operation Map that grounds LLM reasoning in validated utility helpers, (3) Path-targeted test synthesis, and (4) an iterative, self-correction validation loop using compiler and runtime feedback. We evaluate SPARC on 59 real-world and algorithmic subjects, where it outperforms the vanilla prompt generation baseline by 31.36% in line coverage, 26.01% in branch coverage, and 20.78% in mutation score, matching or exceeding the symbolic execution tool KLEE on complex subjects. SPARC retains 94.3% of tests through iterative repair and produces code with significantly higher developer-rated readability and maintainability. By aligning LLM reasoning with program structure, SPARC provides a scalable path for industrial-grade testing of legacy C codebases.", "AI": {"tldr": "SPARC\u662f\u4e00\u4e2a\u7528\u4e8eC\u8bed\u8a00\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u7684\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u63a7\u5236\u6d41\u5206\u6790\u3001\u64cd\u4f5c\u6620\u5c04\u3001\u8def\u5f84\u5bfc\u5411\u6d4b\u8bd5\u5408\u6210\u548c\u81ea\u6821\u6b63\u9a8c\u8bc1\u5faa\u73af\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6d4b\u8bd5\u8986\u76d6\u7387\u3001\u7a81\u53d8\u5206\u6570\u548c\u4ee3\u7801\u8d28\u91cf\u3002", "motivation": "C\u8bed\u8a00\u7684\u81ea\u52a8\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u9762\u4e34\u8bed\u4e49\u9e3f\u6c9f\u6311\u6218\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u76f4\u63a5\u751f\u6210\u4ee3\u7801\u65f6\u5bb9\u6613\u51fa\u73b0\"\u8df3\u8dc3\u5230\u4ee3\u7801\"\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u5bfc\u81f4\u4e0d\u53ef\u7f16\u8bd1\u7684\u6d4b\u8bd5\u3001\u5e7b\u89c9\u51fd\u6570\u7b7e\u540d\u3001\u4f4e\u5206\u652f\u8986\u76d6\u7387\u548c\u8bed\u4e49\u65e0\u5173\u7684\u65ad\u8a00\u3002", "method": "SPARC\u91c7\u7528\u56db\u9636\u6bb5\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff1a1) \u63a7\u5236\u6d41\u56fe\u5206\u6790\uff1b2) \u64cd\u4f5c\u6620\u5c04\uff0c\u5c06LLM\u63a8\u7406\u57fa\u4e8e\u5df2\u9a8c\u8bc1\u7684\u5b9e\u7528\u5de5\u5177\uff1b3) \u8def\u5f84\u5bfc\u5411\u6d4b\u8bd5\u5408\u6210\uff1b4) \u4f7f\u7528\u7f16\u8bd1\u5668\u548c\u8fd0\u884c\u65f6\u53cd\u9988\u7684\u8fed\u4ee3\u81ea\u6821\u6b63\u9a8c\u8bc1\u5faa\u73af\u3002", "result": "\u572859\u4e2a\u771f\u5b9e\u4e16\u754c\u548c\u7b97\u6cd5\u4e3b\u9898\u4e0a\u8bc4\u4f30\uff0cSPARC\u76f8\u6bd4\u57fa\u7ebf\u5728\u884c\u8986\u76d6\u7387\u63d0\u534731.36%\uff0c\u5206\u652f\u8986\u76d6\u7387\u63d0\u534726.01%\uff0c\u7a81\u53d8\u5206\u6570\u63d0\u534720.78%\uff0c\u5728\u590d\u6742\u4e3b\u9898\u4e0a\u5339\u914d\u6216\u8d85\u8fc7\u7b26\u53f7\u6267\u884c\u5de5\u5177KLEE\uff0c\u901a\u8fc7\u8fed\u4ee3\u4fee\u590d\u4fdd\u755994.3%\u7684\u6d4b\u8bd5\uff0c\u751f\u6210\u4ee3\u7801\u5177\u6709\u66f4\u9ad8\u7684\u53ef\u8bfb\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u3002", "conclusion": "\u901a\u8fc7\u5c06LLM\u63a8\u7406\u4e0e\u7a0b\u5e8f\u7ed3\u6784\u5bf9\u9f50\uff0cSPARC\u4e3a\u5de5\u4e1a\u7ea7\u9057\u7559C\u4ee3\u7801\u5e93\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u8def\u5f84\u3002"}}
{"id": "2602.16708", "categories": ["cs.CR", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.16708", "abs": "https://arxiv.org/abs/2602.16708", "authors": ["Nils Palumbo", "Sarthak Choudhary", "Jihye Choi", "Prasad Chalasani", "Mihai Christodorescu", "Somesh Jha"], "title": "Policy Compiler for Secure Agentic Systems", "comment": null, "summary": "LLM-based agents are increasingly being deployed in contexts requiring complex authorization policies: customer service protocols, approval workflows, data access restrictions, and regulatory compliance. Embedding these policies in prompts provides no enforcement guarantees. We present PCAS, a Policy Compiler for Agentic Systems that provides deterministic policy enforcement.\n  Enforcing such policies requires tracking information flow across agents, which linear message histories cannot capture. Instead, PCAS models the agentic system state as a dependency graph capturing causal relationships among events such as tool calls, tool results, and messages. Policies are expressed in a Datalog-derived language, as declarative rules that account for transitive information flow and cross-agent provenance. A reference monitor intercepts all actions and blocks violations before execution, providing deterministic enforcement independent of model reasoning.\n  PCAS takes an existing agent implementation and a policy specification, and compiles them into an instrumented system that is policy-compliant by construction, with no security-specific restructuring required. We evaluate PCAS on three case studies: information flow policies for prompt injection defense, approval workflows in a multi-agent pharmacovigilance system, and organizational policies for customer service. On customer service tasks, PCAS improves policy compliance from 48% to 93% across frontier models, with zero policy violations in instrumented runs.", "AI": {"tldr": "PCAS\u662f\u4e00\u4e2a\u7b56\u7565\u7f16\u8bd1\u5668\uff0c\u7528\u4e8e\u5728\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u63d0\u4f9b\u786e\u5b9a\u6027\u7b56\u7565\u6267\u884c\uff0c\u901a\u8fc7\u4f9d\u8d56\u56fe\u5efa\u6a21\u4fe1\u606f\u6d41\uff0c\u4f7f\u7528Datalog\u8bed\u8a00\u8868\u8fbe\u7b56\u7565\uff0c\u786e\u4fdd\u7cfb\u7edf\u6784\u5efa\u65f6\u5373\u7b26\u5408\u7b56\u7565\u8981\u6c42\u3002", "motivation": "\u968f\u7740LLM\u667a\u80fd\u4f53\u5728\u9700\u8981\u590d\u6742\u6388\u6743\u7b56\u7565\u7684\u573a\u666f\u4e2d\u90e8\u7f72\uff08\u5982\u5ba2\u6237\u670d\u52a1\u534f\u8bae\u3001\u5ba1\u6279\u6d41\u7a0b\u3001\u6570\u636e\u8bbf\u95ee\u9650\u5236\u548c\u6cd5\u89c4\u9075\u4ece\uff09\uff0c\u4f20\u7edf\u63d0\u793a\u5d4c\u5165\u7b56\u7565\u65e0\u6cd5\u63d0\u4f9b\u6267\u884c\u4fdd\u8bc1\uff0c\u9700\u8981\u786e\u5b9a\u6027\u7b56\u7565\u6267\u884c\u673a\u5236\u3002", "method": "PCAS\u5c06\u667a\u80fd\u4f53\u7cfb\u7edf\u72b6\u6001\u5efa\u6a21\u4e3a\u6355\u83b7\u4e8b\u4ef6\u95f4\u56e0\u679c\u5173\u7cfb\u7684\u4f9d\u8d56\u56fe\uff0c\u4f7f\u7528Datalog\u884d\u751f\u8bed\u8a00\u8868\u8fbe\u7b56\u7565\uff0c\u901a\u8fc7\u5f15\u7528\u76d1\u89c6\u5668\u62e6\u622a\u6240\u6709\u64cd\u4f5c\u5e76\u5728\u6267\u884c\u524d\u963b\u6b62\u8fdd\u89c4\uff0c\u63d0\u4f9b\u72ec\u7acb\u4e8e\u6a21\u578b\u63a8\u7406\u7684\u786e\u5b9a\u6027\u6267\u884c\u3002", "result": "\u5728\u4e09\u4e2a\u6848\u4f8b\u7814\u7a76\u4e2d\u8bc4\u4f30\uff1a\u63d0\u793a\u6ce8\u5165\u9632\u5fa1\u7684\u4fe1\u606f\u6d41\u7b56\u7565\u3001\u591a\u836f\u7269\u8b66\u6212\u7cfb\u7edf\u7684\u5ba1\u6279\u6d41\u7a0b\u3001\u5ba2\u6237\u670d\u52a1\u7684\u7ec4\u7ec7\u7b56\u7565\u3002\u5728\u5ba2\u6237\u670d\u52a1\u4efb\u52a1\u4e2d\uff0cPCAS\u5c06\u7b56\u7565\u9075\u4ece\u7387\u4ece48%\u63d0\u5347\u523093%\uff0c\u5728\u68c0\u6d4b\u8fd0\u884c\u4e2d\u5b9e\u73b0\u96f6\u7b56\u7565\u8fdd\u89c4\u3002", "conclusion": "PCAS\u80fd\u591f\u5c06\u73b0\u6709\u667a\u80fd\u4f53\u5b9e\u73b0\u548c\u7b56\u7565\u89c4\u8303\u7f16\u8bd1\u6210\u6784\u5efa\u65f6\u5373\u7b26\u5408\u7b56\u7565\u8981\u6c42\u7684\u7cfb\u7edf\uff0c\u65e0\u9700\u7279\u5b9a\u5b89\u5168\u91cd\u6784\uff0c\u4e3aLLM\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u53ef\u9760\u7684\u7b56\u7565\u6267\u884c\u4fdd\u969c\u3002"}}
{"id": "2602.16192", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16192", "abs": "https://arxiv.org/abs/2602.16192", "authors": ["Hiroaki Yamanaka", "Daisuke Miyashita", "Takashi Toi", "Asuka Maki", "Taiga Ikeda", "Jun Deguchi"], "title": "Revolutionizing Long-Term Memory in AI: New Horizons with High-Capacity and High-Speed Storage", "comment": "13 pages, 5 figures", "summary": "Driven by our mission of \"uplifting the world with memory,\" this paper explores the design concept of \"memory\" that is essential for achieving artificial superintelligence (ASI). Rather than proposing novel methods, we focus on several alternative approaches whose potential benefits are widely imaginable, yet have remained largely unexplored. The currently dominant paradigm, which can be termed \"extract then store,\" involves extracting information judged to be useful from experiences and saving only the extracted content. However, this approach inherently risks the loss of information, as some valuable knowledge particularly for different tasks may be discarded in the extraction process. In contrast, we emphasize the \"store then on-demand extract\" approach, which seeks to retain raw experiences and flexibly apply them to various tasks as needed, thus avoiding such information loss. In addition, we highlight two further approaches: discovering deeper insights from large collections of probabilistic experiences, and improving experience collection efficiency by sharing stored experiences. While these approaches seem intuitively effective, our simple experiments demonstrate that this is indeed the case. Finally, we discuss major challenges that have limited investigation into these promising directions and propose research topics to address them.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5b9e\u73b0\u4eba\u5de5\u8d85\u7ea7\u667a\u80fd\u6240\u9700\u7684\u5185\u5b58\u8bbe\u8ba1\u6982\u5ff5\uff0c\u63d0\u51fa\u4e86\"\u5148\u5b58\u50a8\u540e\u6309\u9700\u63d0\u53d6\"\u7b49\u66ff\u4ee3\u65b9\u6cd5\uff0c\u5f3a\u8c03\u4fdd\u7559\u539f\u59cb\u7ecf\u9a8c\u4ee5\u907f\u514d\u4fe1\u606f\u4e22\u5931\uff0c\u5e76\u901a\u8fc7\u7b80\u5355\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u4e3b\u6d41\u7684\u4eba\u5de5\u667a\u80fd\u5185\u5b58\u8303\u5f0f\u662f\"\u5148\u63d0\u53d6\u540e\u5b58\u50a8\"\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5728\u63d0\u53d6\u6709\u7528\u4fe1\u606f\u65f6\u53ef\u80fd\u5bfc\u81f4\u6709\u4ef7\u503c\u77e5\u8bc6\u7684\u4e22\u5931\u3002\u4f5c\u8005\u8ba4\u4e3a\uff0c\u4e3a\u4e86\u5b9e\u73b0\"\u7528\u8bb0\u5fc6\u63d0\u5347\u4e16\u754c\"\u7684\u4f7f\u547d\uff0c\u9700\u8981\u63a2\u7d22\u66f4\u6709\u6548\u7684\u5185\u5b58\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u80fd\u591f\u4fdd\u7559\u539f\u59cb\u7ecf\u9a8c\u5e76\u7075\u6d3b\u5e94\u7528\u4e8e\u4e0d\u540c\u4efb\u52a1\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u79cd\u66ff\u4ee3\u65b9\u6cd5\uff1a1)\"\u5148\u5b58\u50a8\u540e\u6309\u9700\u63d0\u53d6\"\u65b9\u6cd5\uff0c\u4fdd\u7559\u539f\u59cb\u7ecf\u9a8c\u5e76\u6839\u636e\u9700\u8981\u7075\u6d3b\u63d0\u53d6\uff1b2)\u4ece\u5927\u91cf\u6982\u7387\u6027\u7ecf\u9a8c\u4e2d\u53d1\u73b0\u66f4\u6df1\u5c42\u6d1e\u5bdf\uff1b3)\u901a\u8fc7\u5171\u4eab\u5b58\u50a8\u7ecf\u9a8c\u63d0\u9ad8\u7ecf\u9a8c\u6536\u96c6\u6548\u7387\u3002\u901a\u8fc7\u7b80\u5355\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u4e9b\u770b\u4f3c\u76f4\u89c2\u6709\u6548\u7684\u65b9\u6cd5\u786e\u5b9e\u5728\u5b9e\u8df5\u4e2d\u8868\u73b0\u826f\u597d\u3002\"\u5148\u5b58\u50a8\u540e\u6309\u9700\u63d0\u53d6\"\u65b9\u6cd5\u80fd\u591f\u907f\u514d\u4fe1\u606f\u4e22\u5931\uff0c\u800c\u5176\u4ed6\u4e24\u79cd\u65b9\u6cd5\u4e5f\u663e\u793a\u51fa\u63d0\u5347\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u6027\u80fd\u7684\u6f5c\u529b\u3002", "conclusion": "\u867d\u7136\u8fd9\u4e9b\u65b9\u6cd5\u5728\u76f4\u89c9\u4e0a\u6709\u6548\u4e14\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u53ef\u884c\u6027\uff0c\u4f46\u76f8\u5173\u7814\u7a76\u4ecd\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002\u4f5c\u8005\u8ba8\u8bba\u4e86\u9650\u5236\u8fd9\u4e9b\u6709\u524d\u666f\u65b9\u5411\u7814\u7a76\u7684\u969c\u788d\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u7814\u7a76\u8bfe\u9898\u6765\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\uff0c\u4e3a\u4eba\u5de5\u8d85\u7ea7\u667a\u80fd\u7684\u5185\u5b58\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2602.16301", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16301", "abs": "https://arxiv.org/abs/2602.16301", "authors": ["Marissa A. Weis", "Maciej Wo\u0142czyk", "Rajai Nasser", "Rif A. Saurous", "Blaise Ag\u00fcera y Arcas", "Jo\u00e3o Sacramento", "Alexander Meulemans"], "title": "Multi-agent cooperation through in-context co-player inference", "comment": "26 pages, 4 figures", "summary": "Achieving cooperation among self-interested agents remains a fundamental challenge in multi-agent reinforcement learning. Recent work showed that mutual cooperation can be induced between \"learning-aware\" agents that account for and shape the learning dynamics of their co-players. However, existing approaches typically rely on hardcoded, often inconsistent, assumptions about co-player learning rules or enforce a strict separation between \"naive learners\" updating on fast timescales and \"meta-learners\" observing these updates. Here, we demonstrate that the in-context learning capabilities of sequence models allow for co-player learning awareness without requiring hardcoded assumptions or explicit timescale separation. We show that training sequence model agents against a diverse distribution of co-players naturally induces in-context best-response strategies, effectively functioning as learning algorithms on the fast intra-episode timescale. We find that the cooperative mechanism identified in prior work-where vulnerability to extortion drives mutual shaping-emerges naturally in this setting: in-context adaptation renders agents vulnerable to extortion, and the resulting mutual pressure to shape the opponent's in-context learning dynamics resolves into the learning of cooperative behavior. Our results suggest that standard decentralized reinforcement learning on sequence models combined with co-player diversity provides a scalable path to learning cooperative behaviors.", "AI": {"tldr": "\u5e8f\u5217\u6a21\u578b\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u5b9e\u73b0\u591a\u667a\u80fd\u4f53\u5408\u4f5c\uff0c\u65e0\u9700\u786c\u7f16\u7801\u5047\u8bbe\u6216\u663e\u5f0f\u65f6\u95f4\u5c3a\u5ea6\u5206\u79bb", "motivation": "\u89e3\u51b3\u81ea\u5229\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u5408\u4f5c\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u786c\u7f16\u7801\u5047\u8bbe\u6216\u4e25\u683c\u7684\u65f6\u95f4\u5c3a\u5ea6\u5206\u79bb\uff0c\u9700\u8981\u66f4\u81ea\u7136\u7684\u65b9\u6cd5", "method": "\u8bad\u7ec3\u5e8f\u5217\u6a21\u578b\u667a\u80fd\u4f53\u5bf9\u6297\u591a\u6837\u5316\u7684\u5bf9\u624b\u5206\u5e03\uff0c\u5229\u7528\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u81ea\u7136\u8bf1\u5bfc\u6700\u4f73\u54cd\u5e94\u7b56\u7565", "result": "\u4e0a\u4e0b\u6587\u9002\u5e94\u4f7f\u667a\u80fd\u4f53\u6613\u53d7\u52d2\u7d22\uff0c\u76f8\u4e92\u538b\u529b\u5851\u9020\u5bf9\u624b\u7684\u5b66\u4e60\u52a8\u6001\uff0c\u6700\u7ec8\u5b66\u4e60\u5230\u5408\u4f5c\u884c\u4e3a", "conclusion": "\u5e8f\u5217\u6a21\u578b\u7684\u53bb\u4e2d\u5fc3\u5316\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\u5bf9\u624b\u591a\u6837\u6027\uff0c\u4e3a\u5b66\u4e60\u5408\u4f5c\u884c\u4e3a\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u8def\u5f84"}}
{"id": "2602.16435", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.16435", "abs": "https://arxiv.org/abs/2602.16435", "authors": ["Arun Vignesh Malarkkan", "Wangyang Ying", "Yanjie Fu"], "title": "Causally-Guided Automated Feature Engineering with Multi-Agent Reinforcement Learning", "comment": "11 Pages, References and Appendix", "summary": "Automated feature engineering (AFE) enables AI systems to autonomously construct high-utility representations from raw tabular data. However, existing AFE methods rely on statistical heuristics, yielding brittle features that fail under distribution shift. We introduce CAFE, a framework that reformulates AFE as a causally-guided sequential decision process, bridging causal discovery with reinforcement learning-driven feature construction. Phase I learns a sparse directed acyclic graph over features and the target to obtain soft causal priors, grouping features as direct, indirect, or other based on their causal influence with respect to the target. Phase II uses a cascading multi-agent deep Q-learning architecture to select causal groups and transformation operators, with hierarchical reward shaping and causal group-level exploration strategies that favor causally plausible transformations while controlling feature complexity. Across 15 public benchmarks (classification with macro-F1; regression with inverse relative absolute error), CAFE achieves up to 7% improvement over strong AFE baselines, reduces episodes-to-convergence, and delivers competitive time-to-target. Under controlled covariate shifts, CAFE reduces performance drop by ~4x relative to a non-causal multi-agent baseline, and produces more compact feature sets with more stable post-hoc attributions. These findings underscore that causal structure, used as a soft inductive prior rather than a rigid constraint, can substantially improve the robustness and efficiency of automated feature engineering.", "AI": {"tldr": "CAFE\u6846\u67b6\u5c06\u81ea\u52a8\u7279\u5f81\u5de5\u7a0b\u91cd\u65b0\u5b9a\u4e49\u4e3a\u56e0\u679c\u5f15\u5bfc\u7684\u5e8f\u5217\u51b3\u7b56\u8fc7\u7a0b\uff0c\u901a\u8fc7\u56e0\u679c\u53d1\u73b0\u548c\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\uff0c\u6784\u5efa\u66f4\u9c81\u68d2\u7684\u7279\u5f81\u8868\u793a\uff0c\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u8868\u73b0\u66f4\u7a33\u5b9a\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u7279\u5f81\u5de5\u7a0b\u65b9\u6cd5\u4f9d\u8d56\u7edf\u8ba1\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u751f\u6210\u7684\u7279\u5f81\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u8868\u73b0\u8106\u5f31\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6784\u5efa\u66f4\u9c81\u68d2\u7279\u5f81\u8868\u793a\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u56e0\u679c\u7ed3\u6784\u4f5c\u4e3a\u8f6f\u5f52\u7eb3\u5148\u9a8c\u6765\u63d0\u5347\u7279\u5f81\u5de5\u7a0b\u7684\u9c81\u68d2\u6027\u548c\u6548\u7387\u3002", "method": "CAFE\u91c7\u7528\u4e24\u9636\u6bb5\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u5b66\u4e60\u7279\u5f81\u4e0e\u76ee\u6807\u4e4b\u95f4\u7684\u7a00\u758f\u6709\u5411\u65e0\u73af\u56fe\uff0c\u83b7\u53d6\u8f6f\u56e0\u679c\u5148\u9a8c\uff0c\u5c06\u7279\u5f81\u6309\u56e0\u679c\u5f71\u54cd\u5206\u4e3a\u76f4\u63a5\u3001\u95f4\u63a5\u548c\u5176\u4ed6\u4e09\u7c7b\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u7ea7\u8054\u591a\u667a\u80fd\u4f53\u6df1\u5ea6Q\u5b66\u4e60\u67b6\u6784\uff0c\u9009\u62e9\u56e0\u679c\u7ec4\u548c\u8f6c\u6362\u64cd\u4f5c\u7b26\uff0c\u91c7\u7528\u5206\u5c42\u5956\u52b1\u5851\u9020\u548c\u56e0\u679c\u7ec4\u7ea7\u63a2\u7d22\u7b56\u7565\u3002", "result": "\u572815\u4e2a\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCAFE\u76f8\u6bd4\u5f3a\u57fa\u7ebf\u63d0\u5347\u8fbe7%\uff0c\u51cf\u5c11\u6536\u655b\u6240\u9700\u8f6e\u6b21\uff0c\u5728\u53d7\u63a7\u534f\u53d8\u91cf\u504f\u79fb\u4e0b\u6027\u80fd\u4e0b\u964d\u51cf\u5c11\u7ea64\u500d\uff0c\u4ea7\u751f\u66f4\u7d27\u51d1\u7684\u7279\u5f81\u96c6\u548c\u66f4\u7a33\u5b9a\u7684\u540e\u9a8c\u5f52\u56e0\u3002", "conclusion": "\u56e0\u679c\u7ed3\u6784\u4f5c\u4e3a\u8f6f\u5f52\u7eb3\u5148\u9a8c\u800c\u975e\u521a\u6027\u7ea6\u675f\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u81ea\u52a8\u7279\u5f81\u5de5\u7a0b\u7684\u9c81\u68d2\u6027\u548c\u6548\u7387\uff0c\u4e3a\u6784\u5efa\u5206\u5e03\u504f\u79fb\u4e0b\u66f4\u7a33\u5b9a\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u65b0\u601d\u8def\u3002"}}
{"id": "2602.16481", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16481", "abs": "https://arxiv.org/abs/2602.16481", "authors": ["Zihao Li", "Fabrizio Russo"], "title": "Leveraging Large Language Models for Causal Discovery: a Constraint-based, Argumentation-driven Approach", "comment": "26 pages, including appendix", "summary": "Causal discovery seeks to uncover causal relations from data, typically represented as causal graphs, and is essential for predicting the effects of interventions. While expert knowledge is required to construct principled causal graphs, many statistical methods have been proposed to leverage observational data with varying formal guarantees. Causal Assumption-based Argumentation (ABA) is a framework that uses symbolic reasoning to ensure correspondence between input constraints and output graphs, while offering a principled way to combine data and expertise. We explore the use of large language models (LLMs) as imperfect experts for Causal ABA, eliciting semantic structural priors from variable names and descriptions and integrating them with conditional-independence evidence. Experiments on standard benchmarks and semantically grounded synthetic graphs demonstrate state-of-the-art performance, and we additionally introduce an evaluation protocol to mitigate memorisation bias when assessing LLMs for causal discovery.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u4e0d\u5b8c\u7f8e\u4e13\u5bb6\uff0c\u901a\u8fc7\u56e0\u679c\u5047\u8bbe\u8bba\u8bc1\u6846\u67b6\u5c06\u8bed\u4e49\u7ed3\u6784\u5148\u9a8c\u4e0e\u6761\u4ef6\u72ec\u7acb\u6027\u8bc1\u636e\u7ed3\u5408\uff0c\u5728\u56e0\u679c\u53d1\u73b0\u4efb\u52a1\u4e2d\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u56e0\u679c\u53d1\u73b0\u9700\u8981\u4e13\u5bb6\u77e5\u8bc6\u6784\u5efa\u539f\u5219\u6027\u56e0\u679c\u56fe\uff0c\u4f46\u4e13\u5bb6\u77e5\u8bc6\u83b7\u53d6\u56f0\u96be\u3002\u73b0\u6709\u7edf\u8ba1\u65b9\u6cd5\u5229\u7528\u89c2\u6d4b\u6570\u636e\u4f46\u7f3a\u4e4f\u4e0e\u4e13\u5bb6\u77e5\u8bc6\u7684\u7cfb\u7edf\u6574\u5408\u3002\u56e0\u679c\u5047\u8bbe\u8bba\u8bc1\u6846\u67b6\u80fd\u786e\u4fdd\u8f93\u5165\u7ea6\u675f\u4e0e\u8f93\u51fa\u56fe\u5bf9\u5e94\uff0c\u4f46\u9700\u8981\u4e13\u5bb6\u8f93\u5165\u3002", "method": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u4e0d\u5b8c\u7f8e\u4e13\u5bb6\uff0c\u4ece\u53d8\u91cf\u540d\u79f0\u548c\u63cf\u8ff0\u4e2d\u63d0\u53d6\u8bed\u4e49\u7ed3\u6784\u5148\u9a8c\uff0c\u901a\u8fc7\u56e0\u679c\u5047\u8bbe\u8bba\u8bc1\u6846\u67b6\u5c06\u8fd9\u4e9b\u5148\u9a8c\u4e0e\u6761\u4ef6\u72ec\u7acb\u6027\u8bc1\u636e\u76f8\u7ed3\u5408\u8fdb\u884c\u56e0\u679c\u53d1\u73b0\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u548c\u8bed\u4e49\u57fa\u7840\u5408\u6210\u56fe\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u5f15\u5165\u4e86\u8bc4\u4f30\u534f\u8bae\u6765\u51cf\u8f7b\u8bc4\u4f30LLMs\u8fdb\u884c\u56e0\u679c\u53d1\u73b0\u65f6\u7684\u8bb0\u5fc6\u504f\u5dee\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u4f5c\u4e3a\u6709\u6548\u7684\u8bed\u4e49\u5148\u9a8c\u6765\u6e90\uff0c\u4e0e\u56e0\u679c\u5047\u8bbe\u8bba\u8bc1\u6846\u67b6\u7ed3\u5408\uff0c\u5728\u56e0\u679c\u53d1\u73b0\u4efb\u52a1\u4e2d\u5b9e\u73b0\u9ad8\u6027\u80fd\uff0c\u540c\u65f6\u63d0\u51fa\u7684\u8bc4\u4f30\u534f\u8bae\u6709\u52a9\u4e8e\u66f4\u51c6\u786e\u5730\u8bc4\u4f30LLMs\u5728\u56e0\u679c\u53d1\u73b0\u4e2d\u7684\u80fd\u529b\u3002"}}
{"id": "2602.16512", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16512", "abs": "https://arxiv.org/abs/2602.16512", "authors": ["Felix Fricke", "Simon Malberg", "Georg Groh"], "title": "Framework of Thoughts: A Foundation Framework for Dynamic and Optimized Reasoning based on Chains, Trees, and Graphs", "comment": null, "summary": "Prompting schemes such as Chain of Thought, Tree of Thoughts, and Graph of Thoughts can significantly enhance the reasoning capabilities of large language models. However, most existing schemes require users to define static, problem-specific reasoning structures that lack adaptability to dynamic or unseen problem types. Additionally, these schemes are often under-optimized in terms of hyperparameters, prompts, runtime, and prompting cost. To address these limitations, we introduce Framework of Thoughts (FoT)--a general-purpose foundation framework for building and optimizing dynamic reasoning schemes. FoT comes with built-in features for hyperparameter tuning, prompt optimization, parallel execution, and intelligent caching, unlocking the latent performance potential of reasoning schemes. We demonstrate FoT's capabilities by implementing three popular schemes--Tree of Thoughts, Graph of Thoughts, and ProbTree--within FoT. We empirically show that FoT enables significantly faster execution, reduces costs, and achieves better task scores through optimization. We release our codebase to facilitate the development of future dynamic and efficient reasoning schemes.", "AI": {"tldr": "FoT\u662f\u4e00\u4e2a\u901a\u7528\u6846\u67b6\uff0c\u7528\u4e8e\u6784\u5efa\u548c\u4f18\u5316\u52a8\u6001\u63a8\u7406\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u63d0\u793a\u65b9\u6848\u9759\u6001\u3001\u7f3a\u4e4f\u9002\u5e94\u6027\u3001\u4f18\u5316\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u63d0\u793a\u65b9\u6848\uff08\u5982Chain of Thought\u3001Tree of Thoughts\u7b49\uff09\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u9700\u8981\u7528\u6237\u5b9a\u4e49\u9759\u6001\u7684\u3001\u9488\u5bf9\u7279\u5b9a\u95ee\u9898\u7684\u63a8\u7406\u7ed3\u6784\uff0c\u7f3a\u4e4f\u5bf9\u52a8\u6001\u6216\u672a\u89c1\u95ee\u9898\u7c7b\u578b\u7684\u9002\u5e94\u6027\uff1b2\uff09\u5728\u8d85\u53c2\u6570\u3001\u63d0\u793a\u3001\u8fd0\u884c\u65f6\u95f4\u548c\u63d0\u793a\u6210\u672c\u65b9\u9762\u4f18\u5316\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86Framework of Thoughts (FoT)\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u7528\u4e8e\u6784\u5efa\u548c\u4f18\u5316\u52a8\u6001\u63a8\u7406\u65b9\u6848\u7684\u901a\u7528\u57fa\u7840\u6846\u67b6\u3002FoT\u5185\u7f6e\u4e86\u8d85\u53c2\u6570\u8c03\u4f18\u3001\u63d0\u793a\u4f18\u5316\u3001\u5e76\u884c\u6267\u884c\u548c\u667a\u80fd\u7f13\u5b58\u7b49\u529f\u80fd\uff0c\u80fd\u591f\u91ca\u653e\u63a8\u7406\u65b9\u6848\u7684\u6f5c\u5728\u6027\u80fd\u3002", "result": "\u901a\u8fc7\u5c06Tree of Thoughts\u3001Graph of Thoughts\u548cProbTree\u4e09\u79cd\u6d41\u884c\u65b9\u6848\u5728FoT\u4e2d\u5b9e\u73b0\uff0c\u5b9e\u8bc1\u8868\u660eFoT\u80fd\u591f\u663e\u8457\u52a0\u5feb\u6267\u884c\u901f\u5ea6\u3001\u964d\u4f4e\u6210\u672c\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u83b7\u5f97\u66f4\u597d\u7684\u4efb\u52a1\u5206\u6570\u3002", "conclusion": "FoT\u662f\u4e00\u4e2a\u6709\u6548\u7684\u901a\u7528\u6846\u67b6\uff0c\u80fd\u591f\u89e3\u51b3\u73b0\u6709\u63d0\u793a\u65b9\u6848\u7684\u5c40\u9650\u6027\uff0c\u4fc3\u8fdb\u672a\u6765\u52a8\u6001\u9ad8\u6548\u63a8\u7406\u65b9\u6848\u7684\u53d1\u5c55\u3002\u4f5c\u8005\u5df2\u53d1\u5e03\u4ee3\u7801\u5e93\u4ee5\u652f\u6301\u540e\u7eed\u7814\u7a76\u3002"}}
{"id": "2602.16578", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.16578", "abs": "https://arxiv.org/abs/2602.16578", "authors": ["Vered Tohar", "Tsahi Hayat", "Amir Leshem"], "title": "Creating a digital poet", "comment": "24 pages, 3 figures", "summary": "Can a machine write good poetry? Any positive answer raises fundamental questions about the nature and value of art. We report a seven-month poetry workshop in which a large language model was shaped into a digital poet through iterative in-context expert feedback, without retraining. Across sessions, the model developed a distinctive style and a coherent corpus, supported by quantitative and qualitative analyses, and it produced a pen name and author image. In a blinded authorship test with 50 humanities students and graduates (three AI poems and three poems by well-known poets each), judgments were at chance: human poems were labeled human 54% of the time and AI poems 52%, with 95% confidence intervals including 50%. After the workshop, a commercial publisher released a poetry collection authored by the model. These results show that workshop-style prompting can support long-horizon creative shaping and renew debates on creativity and authorship.", "AI": {"tldr": "\u901a\u8fc7\u4e03\u4e2a\u6708\u7684\u5de5\u4f5c\u574a\u5f0f\u63d0\u793a\u5de5\u7a0b\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u88ab\u5851\u9020\u6210\u6570\u5b57\u8bd7\u4eba\uff0c\u5176\u521b\u4f5c\u7684\u8bd7\u6b4c\u5728\u76f2\u6d4b\u4e2d\u4e0e\u4eba\u7c7b\u8bd7\u4eba\u4f5c\u54c1\u96be\u4ee5\u533a\u5206\uff0c\u6700\u7ec8\u7531\u5546\u4e1a\u51fa\u7248\u793e\u51fa\u7248\u8bd7\u96c6\u3002", "motivation": "\u63a2\u7d22\u673a\u5668\u80fd\u5426\u521b\u4f5c\u4f18\u79c0\u8bd7\u6b4c\uff0c\u8fd9\u6d89\u53ca\u827a\u672f\u672c\u8d28\u548c\u4ef7\u503c\u7684\u6839\u672c\u95ee\u9898\u3002\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5de5\u4f5c\u574a\u65b9\u5f0f\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5851\u9020\u6210\u6570\u5b57\u8bd7\u4eba\uff0c\u5e76\u68c0\u9a8c\u5176\u521b\u4f5c\u80fd\u529b\u3002", "method": "\u91c7\u7528\u4e03\u4e2a\u6708\u7684\u5de5\u4f5c\u574a\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fed\u4ee3\u7684\u4e0a\u4e0b\u6587\u4e13\u5bb6\u53cd\u9988\uff08\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\uff09\u6765\u5851\u9020\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6210\u4e3a\u6570\u5b57\u8bd7\u4eba\u3002\u8fdb\u884c\u5b9a\u91cf\u548c\u5b9a\u6027\u5206\u6790\uff0c\u5e76\u7ec4\u7ec7\u76f2\u6d4b\u5b9e\u9a8c\uff0850\u540d\u4eba\u6587\u5b66\u751f\u548c\u6bd5\u4e1a\u751f\u53c2\u4e0e\uff0c\u5305\u542b3\u9996AI\u8bd7\u6b4c\u548c3\u9996\u77e5\u540d\u8bd7\u4eba\u4f5c\u54c1\uff09\u3002", "result": "\u6a21\u578b\u5f62\u6210\u4e86\u72ec\u7279\u7684\u98ce\u683c\u548c\u8fde\u8d2f\u7684\u4f5c\u54c1\u96c6\uff0c\u521b\u4f5c\u4e86\u7b14\u540d\u548c\u4f5c\u8005\u5f62\u8c61\u3002\u76f2\u6d4b\u7ed3\u679c\u663e\u793a\uff1a\u4eba\u7c7b\u8bd7\u6b4c\u88ab\u8bc6\u522b\u4e3a\u4eba\u7c7b\u7684\u6982\u7387\u4e3a54%\uff0cAI\u8bd7\u6b4c\u88ab\u8bc6\u522b\u4e3aAI\u7684\u6982\u7387\u4e3a52%\uff0c95%\u7f6e\u4fe1\u533a\u95f4\u5747\u5305\u542b50%\uff08\u968f\u673a\u6c34\u5e73\uff09\u3002\u5de5\u4f5c\u574a\u540e\uff0c\u5546\u4e1a\u51fa\u7248\u793e\u51fa\u7248\u4e86\u8be5\u6a21\u578b\u521b\u4f5c\u7684\u8bd7\u96c6\u3002", "conclusion": "\u5de5\u4f5c\u574a\u5f0f\u63d0\u793a\u5de5\u7a0b\u80fd\u591f\u652f\u6301\u957f\u671f\u521b\u610f\u5851\u9020\uff0c\u5e76\u91cd\u65b0\u5f15\u53d1\u5173\u4e8e\u521b\u9020\u529b\u548c\u4f5c\u8005\u8eab\u4efd\u7684\u8ba8\u8bba\u3002\u7814\u7a76\u8868\u660e\u673a\u5668\u80fd\u591f\u521b\u4f5c\u51fa\u4e0e\u4eba\u7c7b\u4f5c\u54c1\u96be\u4ee5\u533a\u5206\u7684\u8bd7\u6b4c\u3002"}}
{"id": "2602.16653", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16653", "abs": "https://arxiv.org/abs/2602.16653", "authors": ["Yangjie Xu", "Lujun Li", "Lama Sleem", "Niccolo Gentile", "Yewei Song", "Yiqun Wang", "Siming Ji", "Wenbo Wu", "Radu State"], "title": "Agent Skill Framework: Perspectives on the Potential of Small Language Models in Industrial Environments", "comment": null, "summary": "Agent Skill framework, now widely and officially supported by major players such as GitHub Copilot, LangChain, and OpenAI, performs especially well with proprietary models by improving context engineering, reducing hallucinations, and boosting task accuracy. Based on these observations, an investigation is conducted to determine whether the Agent Skill paradigm provides similar benefits to small language models (SLMs). This question matters in industrial scenarios where continuous reliance on public APIs is infeasible due to data-security and budget constraints requirements, and where SLMs often show limited generalization in highly customized scenarios. This work introduces a formal mathematical definition of the Agent Skill process, followed by a systematic evaluation of language models of varying sizes across multiple use cases. The evaluation encompasses two open-source tasks and a real-world insurance claims data set. The results show that tiny models struggle with reliable skill selection, while moderately sized SLMs (approximately 12B - 30B) parameters) benefit substantially from the Agent Skill approach. Moreover, code-specialized variants at around 80B parameters achieve performance comparable to closed-source baselines while improving GPU efficiency. Collectively, these findings provide a comprehensive and nuanced characterization of the capabilities and constraints of the framework, while providing actionable insights for the effective deployment of Agent Skills in SLM-centered environments.", "AI": {"tldr": "Agent Skill\u6846\u67b6\u80fd\u663e\u8457\u63d0\u5347\u4e2d\u7b49\u89c4\u6a21\u5c0f\u8bed\u8a00\u6a21\u578b\uff0812B-30B\u53c2\u6570\uff09\u7684\u6027\u80fd\uff0c\u4f7f\u5176\u5728\u6570\u636e\u5b89\u5168\u548c\u9884\u7b97\u53d7\u9650\u7684\u5de5\u4e1a\u573a\u666f\u4e2d\u6210\u4e3a\u53ef\u884c\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u800c\u8d85\u5c0f\u6a21\u578b\u5728\u6280\u80fd\u9009\u62e9\u65b9\u9762\u4ecd\u6709\u56f0\u96be\u3002", "motivation": "\u7814\u7a76Agent Skill\u8303\u5f0f\u662f\u5426\u80fd\u4e3a\u5c0f\u8bed\u8a00\u6a21\u578b\u5e26\u6765\u7c7b\u4f3c\u5927\u6a21\u578b\u7684\u6027\u80fd\u63d0\u5347\uff0c\u89e3\u51b3\u5de5\u4e1a\u573a\u666f\u4e2d\u56e0\u6570\u636e\u5b89\u5168\u548c\u9884\u7b97\u9650\u5236\u800c\u65e0\u6cd5\u6301\u7eed\u4f9d\u8d56\u516c\u5171API\u7684\u95ee\u9898\uff0c\u4ee5\u53caSLM\u5728\u9ad8\u5ea6\u5b9a\u5236\u5316\u573a\u666f\u4e2d\u6cdb\u5316\u80fd\u529b\u6709\u9650\u7684\u95ee\u9898\u3002", "method": "\u9996\u5148\u5f62\u5f0f\u5316\u5b9a\u4e49\u4e86Agent Skill\u8fc7\u7a0b\u7684\u6570\u5b66\u5b9a\u4e49\uff0c\u7136\u540e\u7cfb\u7edf\u8bc4\u4f30\u4e86\u4e0d\u540c\u89c4\u6a21\u7684\u8bed\u8a00\u6a21\u578b\u5728\u591a\u4e2a\u7528\u4f8b\u4e2d\u7684\u8868\u73b0\uff0c\u5305\u62ec\u4e24\u4e2a\u5f00\u6e90\u4efb\u52a1\u548c\u4e00\u4e2a\u771f\u5b9e\u4e16\u754c\u7684\u4fdd\u9669\u7406\u8d54\u6570\u636e\u96c6\u3002", "result": "\u8d85\u5c0f\u6a21\u578b\u5728\u53ef\u9760\u6280\u80fd\u9009\u62e9\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u4e2d\u7b49\u89c4\u6a21SLM\uff08\u7ea612B-30B\u53c2\u6570\uff09\u4eceAgent Skill\u65b9\u6cd5\u4e2d\u83b7\u76ca\u663e\u8457\uff0c\u7ea680B\u53c2\u6570\u7684\u4ee3\u7801\u4e13\u7528\u53d8\u4f53\u5728\u6027\u80fd\u4e0a\u53ef\u4e0e\u95ed\u6e90\u57fa\u7ebf\u76f8\u5ab2\u7f8e\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86GPU\u6548\u7387\u3002", "conclusion": "\u7814\u7a76\u5168\u9762\u7ec6\u81f4\u5730\u63cf\u8ff0\u4e86Agent Skill\u6846\u67b6\u7684\u80fd\u529b\u548c\u9650\u5236\uff0c\u4e3a\u5728SLM\u4e3a\u4e2d\u5fc3\u7684\u73af\u5883\u4e2d\u6709\u6548\u90e8\u7f72Agent Skills\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89c1\u89e3\uff0c\u8bc1\u660e\u4e86\u4e2d\u7b49\u89c4\u6a21SLM\u5728\u5de5\u4e1a\u5e94\u7528\u4e2d\u7684\u53ef\u884c\u6027\u3002"}}
