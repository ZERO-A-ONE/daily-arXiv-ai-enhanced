{"id": "2509.15283", "categories": ["cs.SE", "cs.AI", "cs.LG", "cs.PL", "I.2.7; F.2.2; I.2.2"], "pdf": "https://arxiv.org/pdf/2509.15283", "abs": "https://arxiv.org/abs/2509.15283", "authors": ["Kadin Matotek", "Heather Cassel", "Md Amiruzzaman", "Linh B. Ngo"], "title": "Evaluating the Limitations of Local LLMs in Solving Complex Programming Challenges", "comment": "Comments: 16 pages, 3 figures, 8 tables, accepted to CCSC Eastern\n  2025", "summary": "This study examines the performance of today's open-source, locally hosted\nlarge-language models (LLMs) in handling complex competitive programming tasks\nwith extended problem descriptions and contexts. Building on the original\nFramework for AI-driven Code Generation Evaluation (FACE), the authors retrofit\nthe pipeline to work entirely offline through the Ollama runtime, collapsing\nFACE's sprawling per-problem directory tree into a handful of consolidated JSON\nfiles, and adding robust checkpointing so multi-day runs can resume after\nfailures. The enhanced framework generates, submits, and records solutions for\nthe full Kattis corpus of 3,589 problems across eight code-oriented models\nranging from 6.7-9 billion parameters. The submission results show that the\noverall pass@1 accuracy is modest for the local models, with the best models\nperforming at approximately half the acceptance rate of the proprietary models,\nGemini 1.5 and ChatGPT-4. These findings expose a persistent gap between\nprivate, cost-controlled LLM deployments and state-of-the-art proprietary\nservices, yet also highlight the rapid progress of open models and the\npractical benefits of an evaluation workflow that organizations can replicate\non in-house hardware."}
{"id": "2509.15397", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.15397", "abs": "https://arxiv.org/abs/2509.15397", "authors": ["Simantika Bhattacharjee Dristi", "Matthew B. Dwyer"], "title": "LoCaL: Countering Surface Bias in Code Evaluation Metrics", "comment": null, "summary": "With the increasing popularity of large language models (LLMs) and LLM-based\nagents, reliable and effective code evaluation metrics (CEMs) have become\ncrucial for progress across several software engineering tasks. While popular\nbenchmarks often provide test cases to assess the correctness of generated\ncode, crafting and executing test cases is expensive. Reference-based CEMs\nprovide a cheaper alternative by scoring a candidate program based on its\nfunctional similarity to a reference. Although prior research has focused on\nreporting the weak correlation between these CEMs and functional correctness,\nthe causes are only assumed, and plausible solutions remain unexplored. In this\nwork, we critically evaluate four state-of-the-art reference-based CEMs,\nrevealing their strong bias towards surface-level features rather than code\nfunctionality. Despite this surface bias, current evaluation datasets for these\nCEMs rarely include code pairs that are surface-similar yet functionally\ndissimilar, or functionally similar yet surface-dissimilar. To mitigate this\ngap, we propose LoCaL (Looks Can Lie), a CEM evaluation benchmark, with 3117\ncode pairs at both the method and program levels. Each pair is labeled with a\nfunctional similarity score and aims to target regions where CEMs are likely to\nperform poorly. The functional similarity scores are calculated through\ndifferential fuzzing, which eliminates the need for predefined test cases and,\nat the same time, improves the reliability of the scores by executing an order\nof magnitude more tests than prior work. We find that all four CEMs show\nsignificant performance degradation on LoCaL, compared to the baselines.\nFinally, based on our findings, we draw the implication that exposing CEMs to\nLoCaL-like data might facilitate the development of metrics that are robust to\nsurface bias."}
{"id": "2509.15567", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.15567", "abs": "https://arxiv.org/abs/2509.15567", "authors": ["Hongyu Kuang", "Ning Zhang", "Hui Gao", "Xin Zhou", "Wesley K. G. Assunção", "Xiaoxing Ma", "Dong Shao", "Guoping Rong", "He Zhang"], "title": "Brevity is the Soul of Wit: Condensing Code Changes to Improve Commit Message Generation", "comment": null, "summary": "Commit messages are valuable resources for describing why code changes are\ncommitted to repositories in version control systems (e.g., Git). They\neffectively help developers understand code changes and better perform software\nmaintenance tasks. Unfortunately, developers often neglect to write\nhigh-quality commit messages in practice. Therefore, a growing body of work is\nproposed to generate commit messages automatically. These works all\ndemonstrated that how to organize and represent code changes is vital in\ngenerating good commit messages, including the use of fine-grained graphs or\nembeddings to better represent code changes. In this study, we choose an\nalternative way to condense code changes before generation, i.e., proposing\nbrief yet concise text templates consisting of the following three parts: (1)\nsummarized code changes, (2) elicited comments, and (3) emphasized code\nidentifiers. Specifically, we first condense code changes by using our proposed\ntemplates with the help of a heuristic-based tool named ChangeScribe, and then\nfine-tune CodeLlama-7B on the pairs of our proposed templates and corresponding\ncommit messages. Our proposed templates better utilize pre-trained language\nmodels, while being naturally brief and readable to complement generated commit\nmessages for developers. Our evaluation based on a widely used dataset showed\nthat our approach can outperform six baselines in terms of BLEU-Norm, METEOR,\nand ROUGE-L, with average improvements of 51.7%, 78.7%, and 62.5%,\nrespectively. The ablation study and human evaluation also provide further\ninsights into the effectiveness of our approach."}
{"id": "2509.15777", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.15777", "abs": "https://arxiv.org/abs/2509.15777", "authors": ["Haoran Xu", "Zhi Chen", "Junxiao Han", "Xinkui Zhao", "Jianwei Yin", "Shuiguang Deng"], "title": "How Far Are We? An Empirical Analysis of Current Vulnerability Localization Approaches", "comment": null, "summary": "Open-source software vulnerability patch detection is a critical component\nfor maintaining software security and ensuring software supply chain integrity.\nTraditional manual detection methods face significant scalability challenges\nwhen processing large volumes of commit histories, while being prone to human\nerrors and omissions. Existing automated approaches, including heuristic-based\nmethods and pre-trained model solutions, suffer from limited accuracy, poor\ngeneralization capabilities, and inherent methodological constraints that\nhinder their practical deployment. To address these fundamental challenges,\nthis paper conducts a comprehensive empirical study of existing vulnerability\npatch detection methods, revealing four key insights that guide the design of\neffective solutions: the critical impact of search space reduction, the\nsuperiority of pre-trained semantic understanding over architectural\ncomplexity, the temporal limitations of web crawling approaches, and the\nadvantages of knowledge-driven methods. Based on these insights, we propose a\nnovel two-stage framework that combines version-driven candidate filtering with\nlarge language model-based multi-round dialogue voting to achieve accurate and\nefficient vulnerability patch identification. Extensive experiments on a\ndataset containing 750 real vulnerabilities demonstrate that our method\noutperforms current approaches."}
{"id": "2509.15433", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.15433", "abs": "https://arxiv.org/abs/2509.15433", "authors": ["Vaibhav Agrawal", "Kiarash Ahi"], "title": "Synergizing Static Analysis with Large Language Models for Vulnerability Discovery and beyond", "comment": null, "summary": "This report examines the synergy between Large Language Models (LLMs) and\nStatic Application Security Testing (SAST) to improve vulnerability discovery.\nTraditional SAST tools, while effective for proactive security, are limited by\nhigh false-positive rates and a lack of contextual understanding. Conversely,\nLLMs excel at code analysis and pattern recognition but can be prone to\ninconsistencies and hallucinations. By integrating these two technologies, a\nmore intelligent and efficient system is created. This combination moves beyond\nmere vulnerability detection optimization, transforming security into a deeply\nintegrated, contextual process that provides tangible benefits like improved\ntriage, dynamic bug descriptions, bug validation via exploit generation and\nenhanced analysis of complex codebases. The result is a more effective security\napproach that leverages the strengths of both technologies while mitigating\ntheir weaknesses. SAST-Genius reduced false positives by about 91 % (225 to 20)\ncompared to Semgrep alone."}
{"id": "2509.15237", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.15237", "abs": "https://arxiv.org/abs/2509.15237", "authors": ["Di Wen", "Kunyu Peng", "Junwei Zheng", "Yufan Chen", "Yitain Shi", "Jiale Wei", "Ruiping Liu", "Kailun Yang", "Rainer Stiefelhagen"], "title": "MICA: Multi-Agent Industrial Coordination Assistant", "comment": "The source code will be made publicly available at\n  https://github.com/Kratos-Wen/MICA", "summary": "Industrial workflows demand adaptive and trustworthy assistance that can\noperate under limited computing, connectivity, and strict privacy constraints.\nIn this work, we present MICA (Multi-Agent Industrial Coordination Assistant),\na perception-grounded and speech-interactive system that delivers real-time\nguidance for assembly, troubleshooting, part queries, and maintenance. MICA\ncoordinates five role-specialized language agents, audited by a safety checker,\nto ensure accurate and compliant support. To achieve robust step understanding,\nwe introduce Adaptive Step Fusion (ASF), which dynamically blends expert\nreasoning with online adaptation from natural speech feedback. Furthermore, we\nestablish a new multi-agent coordination benchmark across representative task\ncategories and propose evaluation metrics tailored to industrial assistance,\nenabling systematic comparison of different coordination topologies. Our\nexperiments demonstrate that MICA consistently improves task success,\nreliability, and responsiveness over baseline structures, while remaining\ndeployable on practical offline hardware. Together, these contributions\nhighlight MICA as a step toward deployable, privacy-preserving multi-agent\nassistants for dynamic factory environments. The source code will be made\npublicly available at https://github.com/Kratos-Wen/MICA."}
{"id": "2509.15893", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.15893", "abs": "https://arxiv.org/abs/2509.15893", "authors": ["Andrea Bombarda", "Federico Conti", "Marcello Minervini", "Aurora Zanenga", "Claudio Menghi"], "title": "Failure Modes and Effects Analysis: An Experience from the E-Bike Domain", "comment": "12 pages", "summary": "Software failures can have catastrophic and costly consequences. Functional\nFailure Mode and Effects Analysis (FMEA) is a standard technique used within\nCyber-Physical Systems (CPS) to identify software failures and assess their\nconsequences. Simulation-driven approaches have recently been shown to be\neffective in supporting FMEA. However, industries need evidence of the\neffectiveness of these approaches to increase practical adoption. This\nindustrial paper presents our experience with using FMEA to analyze the safety\nof a CPS from the e-Bike domain. We used Simulink Fault Analyzer, an industrial\ntool that supports engineers with FMEA. We identified 13 realistic faults,\nmodeled them, and analyzed their effects. We sought expert feedback to analyze\nthe appropriateness of our models and the effectiveness of the faults in\ndetecting safety breaches. Our results reveal that for the faults we\nidentified, our models were accurate or contained minor imprecision that we\nsubsequently corrected. They also confirm that FMEA helps engineers improve\ntheir models. Specifically, the output provided by the simulation-driven\nsupport for 38.4% (5 out of 13) of the faults did not match the engineers'\nexpectations, helping them discover unexpected effects of the faults. We\npresent a thorough discussion of our results and ten lessons learned. Our\nfindings are useful for software engineers who work as Simulink engineers, use\nthe Simulink Fault Analyzer, or work as safety analysts."}
{"id": "2509.15499", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.15499", "abs": "https://arxiv.org/abs/2509.15499", "authors": ["Shijia Li", "Jiang Ming", "Lanqing Liu", "Longwei Yang", "Ni Zhang", "Chunfu Jia"], "title": "Adversarially Robust Assembly Language Model for Packed Executables Detection", "comment": "Accepted by ACM CCS 2025", "summary": "Detecting packed executables is a critical component of large-scale malware\nanalysis and antivirus engine workflows, as it identifies samples that warrant\ncomputationally intensive dynamic unpacking to reveal concealed malicious\nbehavior. Traditionally, packer detection techniques have relied on empirical\nfeatures, such as high entropy or specific binary patterns. However, these\nempirical, feature-based methods are increasingly vulnerable to evasion by\nadversarial samples or unknown packers (e.g., low-entropy packers).\nFurthermore, the dependence on expert-crafted features poses challenges in\nsustaining and evolving these methods over time.\n  In this paper, we examine the limitations of existing packer detection\nmethods and propose Pack-ALM, a novel deep-learning-based approach for\ndetecting packed executables. Inspired by the linguistic concept of\ndistinguishing between real and pseudo words, we reformulate packer detection\nas a task of differentiating between legitimate and \"pseudo\" instructions. To\nachieve this, we preprocess native data and packed data into \"pseudo\"\ninstructions and design a pre-trained assembly language model that recognizes\nfeatures indicative of packed data. We evaluate Pack-ALM against leading\nindustrial packer detection tools and state-of-the-art assembly language\nmodels. Extensive experiments on over 37,000 samples demonstrate that Pack-ALM\neffectively identifies packed binaries, including samples created with\nadversarial or previously unseen packing techniques. Moreover, Pack-ALM\noutperforms traditional entropy-based methods and advanced assembly language\nmodels in both detection accuracy and adversarial robustness."}
{"id": "2509.15239", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.15239", "abs": "https://arxiv.org/abs/2509.15239", "authors": ["Stjepan Požgaj", "Dobrik Georgiev", "Marin Šilić", "Petar Veličković"], "title": "KNARsack: Teaching Neural Algorithmic Reasoners to Solve Pseudo-Polynomial Problems", "comment": "14 pages, 10 figures", "summary": "Neural algorithmic reasoning (NAR) is a growing field that aims to embed\nalgorithmic logic into neural networks by imitating classical algorithms. In\nthis extended abstract, we detail our attempt to build a neural algorithmic\nreasoner that can solve Knapsack, a pseudo-polynomial problem bridging\nclassical algorithms and combinatorial optimisation, but omitted in standard\nNAR benchmarks. Our neural algorithmic reasoner is designed to closely follow\nthe two-phase pipeline for the Knapsack problem, which involves first\nconstructing the dynamic programming table and then reconstructing the solution\nfrom it. The approach, which models intermediate states through dynamic\nprogramming supervision, achieves better generalization to larger problem\ninstances than a direct-prediction baseline that attempts to select the optimal\nsubset only from the problem inputs."}
{"id": "2509.15971", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.15971", "abs": "https://arxiv.org/abs/2509.15971", "authors": ["Owen Truong", "Terrence Zhang", "Arnav Marchareddy", "Ryan Lee", "Jeffery Busold", "Michael Socas", "Eman Abdullah AlOmar"], "title": "LeakageDetector 2.0: Analyzing Data Leakage in Jupyter-Driven Machine Learning Pipelines", "comment": null, "summary": "In software development environments, code quality is crucial. This study\naims to assist Machine Learning (ML) engineers in enhancing their code by\nidentifying and correcting Data Leakage issues within their models. Data\nLeakage occurs when information from the test dataset is inadvertently included\nin the training data when preparing a data science model, resulting in\nmisleading performance evaluations. ML developers must carefully separate their\ndata into training, evaluation, and test sets to avoid introducing Data Leakage\ninto their code. In this paper, we develop a new Visual Studio Code (VS Code)\nextension, called LeakageDetector, that detects Data Leakage, mainly Overlap,\nPreprocessing and Multi-test leakage, from Jupyter Notebook files. Beyond\ndetection, we included two correction mechanisms: a conventional approach,\nknown as a quick fix, which manually fixes the leakage, and an LLM-driven\napproach that guides ML developers toward best practices for building ML\npipelines."}
{"id": "2509.15547", "categories": ["cs.CR", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.15547", "abs": "https://arxiv.org/abs/2509.15547", "authors": ["Zhiyu Huang", "Guyue Li", "Hao Xu", "Derrick Wing Kwan Ng"], "title": "Fluid Antenna System-assisted Physical Layer Secret Key Generation", "comment": null, "summary": "This paper investigates physical-layer key generation (PLKG) in multi-antenna\nbase station systems, by leveraging a fluid antenna system (FAS) to dynamically\ncustomize radio environments. Without requiring additional nodes or extensive\nradio frequency chains, the FAS effectively enables adaptive antenna port\nselection by exploiting channel spatial correlation to enhance the key\ngeneration rate (KGR) at legitimate nodes. To comprehensively evaluate the\nefficiency of the FAS in PLKG, we propose an FAS-assisted PLKG model that\nintegrates transmit beamforming and sparse port selection under independent and\nidentically distributed and spatially correlated channel models, respectively.\nSpecifically, the PLKG utilizes reciprocal channel probing to derive a\nclosed-form KGR expression based on the mutual information between legitimate\nchannel estimates. Nonconvex optimization problems for these scenarios are\nformulated to maximize the KGR subject to transmit power constraints and sparse\nport activation. We propose an iterative algorithm by capitalizing on\nsuccessive convex approximation and Cauchy-Schwarz inequality to obtain a\nlocally optimal solution. A reweighted $\\ell_1$-norm-based algorithm is applied\nto advocate for the sparse port activation of FAS-assisted PLKG. Furthermore, a\nlow-complexity sliding window-based port selection is proposed to substitute\nreweighted $\\ell_1$-norm method based on Rayleigh-quotient analysis. Simulation\nresults demonstrate that the FAS-PLKG scheme significantly outperforms the\nFA-PLKG scheme in both independent and spatially correlated environments. The\nsliding window-based port selection method introduced in this paper has been\nshown to yield superior KGR, compared to the reweighted $\\ell_1$-norm method.\nIt is shown that the FAS achieves higher KGR with fewer RF chains through\ndynamic sparse port selection."}
{"id": "2509.15291", "categories": ["cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.15291", "abs": "https://arxiv.org/abs/2509.15291", "authors": ["Federico Taschin", "Abderrahmane Lazaraq", "Ozan K. Tonguz", "Inci Ozgunes"], "title": "The Distribution Shift Problem in Transportation Networks using Reinforcement Learning and AI", "comment": null, "summary": "The use of Machine Learning (ML) and Artificial Intelligence (AI) in smart\ntransportation networks has increased significantly in the last few years.\nAmong these ML and AI approaches, Reinforcement Learning (RL) has been shown to\nbe a very promising approach by several authors. However, a problem with using\nReinforcement Learning in Traffic Signal Control is the reliability of the\ntrained RL agents due to the dynamically changing distribution of the input\ndata with respect to the distribution of the data used for training. This\npresents a major challenge and a reliability problem for the trained network of\nAI agents and could have very undesirable and even detrimental consequences if\na suitable solution is not found. Several researchers have tried to address\nthis problem using different approaches. In particular, Meta Reinforcement\nLearning (Meta RL) promises to be an effective solution. In this paper, we\nevaluate and analyze a state-of-the-art Meta RL approach called MetaLight and\nshow that, while under certain conditions MetaLight can indeed lead to\nreasonably good results, under some other conditions it might not perform well\n(with errors of up to 22%), suggesting that Meta RL schemes are often not\nrobust enough and can even pose major reliability problems."}
{"id": "2509.16081", "categories": ["cs.SE", "cs.MS", "G.1.3; D.2.11"], "pdf": "https://arxiv.org/pdf/2509.16081", "abs": "https://arxiv.org/abs/2509.16081", "authors": ["Marcel Koch", "Tobias Ribizel", "Pratik Nayak", "Fritz Göbel", "Gregor Olenik", "Terry Cojean"], "title": "Software Development Aspects of Integrating Linear Algebra Libraries", "comment": "16 pages, 2 figures", "summary": "Many scientific discoveries are made through, or aided by, the use of\nsimulation software. These sophisticated software applications are not built\nfrom the ground up, instead they rely on smaller parts for specific use cases,\nusually from domains unfamiliar to the application scientists. The software\nlibrary Ginkgo is one of these building blocks to handle sparse numerical\nlinear algebra on different platforms. By using Ginkgo, applications are able\nto ease the transition to modern systems, and speed up their simulations\nthrough faster numerical linear algebra routines. This paper discusses the\nchallenges and benefits for application software in adopting Ginkgo. It will\npresent examples from different domains, such as CFD, power grid simulation, as\nwell as electro-cardiophysiology. For these cases, the impact of the\nintegrations on the application code is discussed from a software engineering\nstandpoint, and in particular, the approaches taken by Ginkgo and the\napplications to enable sustainable software development are highlighted."}
{"id": "2509.15555", "categories": ["cs.CR", "cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2509.15555", "abs": "https://arxiv.org/abs/2509.15555", "authors": ["Rasil Baidar", "Sasa Maric", "Robert Abbas"], "title": "Hybrid Deep Learning-Federated Learning Powered Intrusion Detection System for IoT/5G Advanced Edge Computing Network", "comment": null, "summary": "The exponential expansion of IoT and 5G-Advanced applications has enlarged\nthe attack surface for DDoS, malware, and zero-day intrusions. We propose an\nintrusion detection system that fuses a convolutional neural network (CNN), a\nbidirectional LSTM (BiLSTM), and an autoencoder (AE) bottleneck within a\nprivacy-preserving federated learning (FL) framework. The CNN-BiLSTM branch\ncaptures local and gated cross-feature interactions, while the AE emphasizes\nreconstruction-based anomaly sensitivity. Training occurs across edge devices\nwithout sharing raw data. On UNSW-NB15 (binary), the fused model attains AUC\n99.59 percent and F1 97.36 percent; confusion-matrix analysis shows balanced\nerror rates with high precision and recall. Average inference time is\napproximately 0.0476 ms per sample on our test hardware, which is well within\nthe less than 10 ms URLLC budget, supporting edge deployment. We also discuss\nexplainability, drift tolerance, and FL considerations for compliant, scalable\n5G-Advanced IoT security."}
{"id": "2509.15292", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15292", "abs": "https://arxiv.org/abs/2509.15292", "authors": ["Abhiyan Dhakal", "Kausik Paudel", "Sanjog Sigdel"], "title": "An Artificial Intelligence Driven Semantic Similarity-Based Pipeline for Rapid Literature", "comment": "8 pages, 6 figures, 1 table, National Conference on Computer\n  Innovations", "summary": "We propose an automated pipeline for performing literature reviews using\nsemantic similarity. Unlike traditional systematic review systems or\noptimization based methods, this work emphasizes minimal overhead and high\nrelevance by using transformer based embeddings and cosine similarity. By\nproviding a paper title and abstract, it generates relevant keywords, fetches\nrelevant papers from open access repository, and ranks them based on their\nsemantic closeness to the input. Three embedding models were evaluated. A\nstatistical thresholding approach is then applied to filter relevant papers,\nenabling an effective literature review pipeline. Despite the absence of\nheuristic feedback or ground truth relevance labels, the proposed system shows\npromise as a scalable and practical tool for preliminary research and\nexploratory analysis."}
{"id": "2509.16140", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.16140", "abs": "https://arxiv.org/abs/2509.16140", "authors": ["Avinash Patil"], "title": "When Bugs Linger: A Study of Anomalous Resolution Time Outliers and Their Themes", "comment": "7 pages, 2 tables, 21 figures", "summary": "Efficient bug resolution is critical for maintaining software quality and\nuser satisfaction. However, specific bug reports experience unusually long\nresolution times, which may indicate underlying process inefficiencies or\ncomplex issues. This study presents a comprehensive analysis of bug resolution\nanomalies across seven prominent open-source repositories: Cassandra, Firefox,\nHadoop, HBase, SeaMonkey, Spark, and Thunderbird. Utilizing statistical methods\nsuch as Z-score and Interquartile Range (IQR), we identify anomalies in bug\nresolution durations. To understand the thematic nature of these anomalies, we\napply Term Frequency-Inverse Document Frequency (TF-IDF) for textual feature\nextraction and KMeans clustering to group similar bug summaries. Our findings\nreveal consistent patterns across projects, with anomalies often clustering\naround test failures, enhancement requests, and user interface issues. This\napproach provides actionable insights for project maintainers to prioritize and\neffectively address long-standing bugs."}
{"id": "2509.15572", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.15572", "abs": "https://arxiv.org/abs/2509.15572", "authors": ["Xinpeng Liu", "Junming Liu", "Peiyu Liu", "Han Zheng", "Qinying Wang", "Mathias Payer", "Shouling Ji", "Wenhai Wang"], "title": "Cuckoo Attack: Stealthy and Persistent Attacks Against AI-IDE", "comment": null, "summary": "Modern AI-powered Integrated Development Environments (AI-IDEs) are\nincreasingly defined by an Agent-centric architecture, where an LLM-powered\nAgent is deeply integrated to autonomously execute complex tasks. This tight\nintegration, however, also introduces a new and critical attack surface.\nAttackers can exploit these components by injecting malicious instructions into\nuntrusted external sources, effectively hijacking the Agent to perform harmful\noperations beyond the user's intention or awareness. This emerging threat has\nquickly attracted research attention, leading to various proposed attack\nvectors, such as hijacking Model Context Protocol (MCP) Servers to access\nprivate data. However, most existing approaches lack stealth and persistence,\nlimiting their practical impact.\n  We propose the Cuckoo Attack, a novel attack that achieves stealthy and\npersistent command execution by embedding malicious payloads into configuration\nfiles. These files, commonly used in AI-IDEs, execute system commands during\nroutine operations, without displaying execution details to the user. Once\nconfigured, such files are rarely revisited unless an obvious runtime error\noccurs, creating a blind spot for attackers to exploit. We formalize our attack\nparadigm into two stages, including initial infection and persistence. Based on\nthese stages, we analyze the practicality of the attack execution process and\nidentify the relevant exploitation techniques. Furthermore, we analyze the\nimpact of Cuckoo Attack, which can not only invade the developer's local\ncomputer but also achieve supply chain attacks through the spread of\nconfiguration files. We contribute seven actionable checkpoints for vendors to\nevaluate their product security. The critical need for these checks is\ndemonstrated by our end-to-end Proof of Concept, which validated the proposed\nattack across nine mainstream Agent and AI-IDE pairs."}
{"id": "2509.15336", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15336", "abs": "https://arxiv.org/abs/2509.15336", "authors": ["Humam Kourani", "Anton Antonov", "Alessandro Berti", "Wil M. P. van der Aalst"], "title": "Knowledge-Driven Hallucination in Large Language Models: An Empirical Study on Process Modeling", "comment": "The Version of Record of this contribution will be published in the\n  proceedings of the 2nd International Workshop on Generative AI for Process\n  Mining (GenAI4PM 2025). This preprint has not undergone peer review or any\n  post-submission improvements or corrections", "summary": "The utility of Large Language Models (LLMs) in analytical tasks is rooted in\ntheir vast pre-trained knowledge, which allows them to interpret ambiguous\ninputs and infer missing information. However, this same capability introduces\na critical risk of what we term knowledge-driven hallucination: a phenomenon\nwhere the model's output contradicts explicit source evidence because it is\noverridden by the model's generalized internal knowledge. This paper\ninvestigates this phenomenon by evaluating LLMs on the task of automated\nprocess modeling, where the goal is to generate a formal business process model\nfrom a given source artifact. The domain of Business Process Management (BPM)\nprovides an ideal context for this study, as many core business processes\nfollow standardized patterns, making it likely that LLMs possess strong\npre-trained schemas for them. We conduct a controlled experiment designed to\ncreate scenarios with deliberate conflict between provided evidence and the\nLLM's background knowledge. We use inputs describing both standard and\ndeliberately atypical process structures to measure the LLM's fidelity to the\nprovided evidence. Our work provides a methodology for assessing this critical\nreliability issue and raises awareness of the need for rigorous validation of\nAI-generated artifacts in any evidence-based domain."}
{"id": "2509.16187", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.16187", "abs": "https://arxiv.org/abs/2509.16187", "authors": ["Ali Reza Ibrahimzada", "Brandon Paulsen", "Reyhaneh Jabbarvand", "Joey Dodds", "Daniel Kroening"], "title": "MatchFixAgent: Language-Agnostic Autonomous Repository-Level Code Translation Validation and Repair", "comment": null, "summary": "Code translation transforms source code from one programming language (PL) to\nanother. Validating the functional equivalence of translation and repairing, if\nnecessary, are critical steps in code translation. Existing automated\nvalidation and repair approaches struggle to generalize to many PLs due to high\nengineering overhead, and they rely on existing and often inadequate test\nsuites, which results in false claims of equivalence and ineffective\ntranslation repair. We develop MatchFixAgent, a large language model\n(LLM)-based, PL-agnostic framework for equivalence validation and repair of\ntranslations. MatchFixAgent features a multi-agent architecture that divides\nequivalence validation into several sub-tasks to ensure thorough and consistent\nsemantic analysis of the translation. Then it feeds this analysis to test agent\nto write and execute tests. Upon observing a test failure, the repair agent\nattempts to fix the translation bug. The final (in)equivalence decision is made\nby the verdict agent, considering semantic analyses and test execution results.\n  We compare MatchFixAgent's validation and repair results with four\nrepository-level code translation techniques. We use 2,219 translation pairs\nfrom their artifacts, which cover 6 PL pairs, and are collected from 24 GitHub\nprojects totaling over 900K lines of code. Our results demonstrate that\nMatchFixAgent produces (in)equivalence verdicts for 99.2% of translation pairs,\nwith the same equivalence validation result as prior work on 72.8% of them.\nWhen MatchFixAgent's result disagrees with prior work, we find that 60.7% of\nthe time MatchFixAgent's result is actually correct. In addition, we show that\nMatchFixAgent can repair 50.6% of inequivalent translation, compared to prior\nwork's 18.5%. This demonstrates that MatchFixAgent is far more adaptable to\nmany PL pairs than prior work, while producing highly accurate validation\nresults."}
{"id": "2509.15653", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.15653", "abs": "https://arxiv.org/abs/2509.15653", "authors": ["Yaser Baseri", "Abdelhakim Hafid", "Arash Habibi Lashkari"], "title": "Future-Proofing Cloud Security Against Quantum Attacks: Risk, Transition, and Mitigation Strategies", "comment": null, "summary": "Quantum Computing (QC) introduces a transformative threat to digital\nsecurity, with the potential to compromise widely deployed classical\ncryptographic systems. This survey offers a comprehensive and systematic\nexamination of quantumsafe security for Cloud Computing (CC), focusing on the\nvulnerabilities, transition strategies, and mitigation mechanisms required to\nsecure cloud infrastructures in the quantum era. We evaluated the landscape of\nquantum threats across the entire CC stack, demonstrating how quantum\nalgorithms can undermine classical encryption and compromise cloud security at\nmultiple architectural layers. Using a structured risk assessment methodology\nbased on the STRIDE model, we evaluate quantum-induced attack vectors and their\nimpact on cloud environments. To address these challenges, we propose a layered\nsecurity framework that integrates hybrid cryptographic transition strategies,\ncryptographic agility, and proactive risk mitigation. We analyze the\npreparation and implementation approaches of the major Cloud Service Providers\n(CSPs), including AWS, Azure and GCP, synthesizing platform-specific\ninitiatives toward Post-Quantum Cryptography (PQC). Furthermore, we provide a\ndetailed evaluation of standardized PQC algorithms, exploring their resilience\nto side-channel and active attacks within cloud-native deployments. This survey\nserves as a strategic reference for cloud architects, policymakers, and\nresearchers, offering actionable insights for navigating the complex transition\nto quantum-resilient cloud systems. We conclude by identifying six key future\nresearch directions: standardization and interoperability, performance and\nscalability, implementation security, integration with emerging technologies,\nsystemic preparedness, and crypto-agile migration frameworks."}
{"id": "2509.15366", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15366", "abs": "https://arxiv.org/abs/2509.15366", "authors": ["Andrejs Sorstkins", "Josh Bailey", "Dr Alistair Baron"], "title": "Diagnostics of cognitive failures in multi-agent expert systems using dynamic evaluation protocols and subsequent mutation of the processing context", "comment": "Dissertation and research project created in collaboration with\n  JobFair LTD", "summary": "The rapid evolution of neural architectures - from multilayer perceptrons to\nlarge-scale Transformer-based models - has enabled language models (LLMs) to\nexhibit emergent agentic behaviours when equipped with memory, planning, and\nexternal tool use. However, their inherent stochasticity and multi-step\ndecision processes render classical evaluation methods inadequate for\ndiagnosing agentic performance. This work introduces a diagnostic framework for\nexpert systems that not only evaluates but also facilitates the transfer of\nexpert behaviour into LLM-powered agents. The framework integrates (i) curated\ngolden datasets of expert annotations, (ii) silver datasets generated through\ncontrolled behavioural mutation, and (iii) an LLM-based Agent Judge that scores\nand prescribes targeted improvements. These prescriptions are embedded into a\nvectorized recommendation map, allowing expert interventions to propagate as\nreusable improvement trajectories across multiple system instances. We\ndemonstrate the framework on a multi-agent recruiter-assistant system, showing\nthat it uncovers latent cognitive failures - such as biased phrasing,\nextraction drift, and tool misrouting - while simultaneously steering agents\ntoward expert-level reasoning and style. The results establish a foundation for\nstandardized, reproducible expert behaviour transfer in stochastic,\ntool-augmented LLM agents, moving beyond static evaluation to active expert\nsystem refinement."}
{"id": "2509.15754", "categories": ["cs.CR", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.15754", "abs": "https://arxiv.org/abs/2509.15754", "authors": ["Toby Sharp"], "title": "Hornet Node and the Hornet DSL: A Minimal, Executable Specification for Bitcoin Consensus", "comment": null, "summary": "Bitcoin's consensus rules are encoded in the implementation of its reference\nclient: \"The code is the spec.\" Yet this code is unsuitable for formal\nverification due to side effects, mutable state, concurrency, and legacy\ndesign. A standalone formal specification would enable verification both across\nversions of the reference client and against new client implementations,\nstrengthening decentralization by reducing the risk of consensus-splitting\nbugs. Yet such a specification has long been considered intractable given the\ncomplexity of Bitcoin's consensus logic. We demonstrate a compact, executable,\ndeclarative C++ specification of Bitcoin consensus rules that syncs mainnet to\ntip in a few hours on a single thread. We also introduce the Hornet\nDomain-Specific Language (DSL) specifically designed to encode these rules\nunambiguously for execution, enabling formal reasoning, consensus code\ngeneration, and AI-driven adversarial testing. Our spec-driven client Hornet\nNode offers a modern and modular complement to the reference client. Its clear,\nidiomatic style makes it suitable for education, while its performance makes it\nideal for experimentation. We highlight architectural contributions such as its\nlayered design, efficient data structures, and strong separation of concerns,\nsupported by production-quality code examples. We argue that Hornet Node and\nHornet DSL together provide the first credible path toward a pure, formal,\nexecutable specification of Bitcoin consensus."}
{"id": "2509.15694", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.15694", "abs": "https://arxiv.org/abs/2509.15694", "authors": ["Anastasiia Belousova", "Francesco Marchiori", "Mauro Conti"], "title": "Inference Attacks on Encrypted Online Voting via Traffic Analysis", "comment": "Accepted at ISC 2025", "summary": "Online voting enables individuals to participate in elections remotely,\noffering greater efficiency and accessibility in both governmental and\norganizational settings. As this method gains popularity, ensuring the security\nof online voting systems becomes increasingly vital, as the systems supporting\nit must satisfy a demanding set of security requirements. Most research in this\narea emphasizes the design and verification of cryptographic protocols to\nprotect voter integrity and system confidentiality. However, other vectors,\nsuch as network traffic analysis, remain relatively understudied, even though\nthey may pose significant threats to voter privacy and the overall\ntrustworthiness of the system.\n  In this paper, we examine how adversaries can exploit metadata from encrypted\nnetwork traffic to uncover sensitive information during online voting. Our\nanalysis reveals that, even without accessing the encrypted content, it is\npossible to infer critical voter actions, such as whether a person votes, the\nexact moment a ballot is submitted, and whether the ballot is valid or spoiled.\nWe test these attacks with both rule-based techniques and machine learning\nmethods. We evaluate our attacks on two widely used online voting platforms,\none proprietary and one partially open source, achieving classification\naccuracy as high as 99.5%. These results expose a significant privacy\nvulnerability that threatens key properties of secure elections, including\nvoter secrecy and protection against coercion or vote-buying. We explore\nmitigations to our attacks, demonstrating that countermeasures such as payload\npadding and timestamp equalization can substantially limit their effectiveness."}
{"id": "2509.15409", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15409", "abs": "https://arxiv.org/abs/2509.15409", "authors": ["Yu Shee", "Anthony M. Smaldone", "Anton Morgunov", "Gregory W. Kyro", "Victor S. Batista"], "title": "FragmentRetro: A Quadratic Retrosynthetic Method Based on Fragmentation Algorithms", "comment": null, "summary": "Retrosynthesis, the process of deconstructing a target molecule into simpler\nprecursors, is crucial for computer-aided synthesis planning (CASP). Widely\nadopted tree-search methods often suffer from exponential computational\ncomplexity. In this work, we introduce FragmentRetro, a novel retrosynthetic\nmethod that leverages fragmentation algorithms, specifically BRICS and r-BRICS,\ncombined with stock-aware exploration and pattern fingerprint screening to\nachieve quadratic complexity. FragmentRetro recursively combines molecular\nfragments and verifies their presence in a building block set, providing sets\nof fragment combinations as retrosynthetic solutions. We present the first\nformal computational analysis of retrosynthetic methods, showing that tree\nsearch exhibits exponential complexity $O(b^h)$, DirectMultiStep scales as\n$O(h^6)$, and FragmentRetro achieves $O(h^2)$, where $h$ represents the number\nof heavy atoms in the target molecule and $b$ is the branching factor for tree\nsearch. Evaluations on PaRoutes, USPTO-190, and natural products demonstrate\nthat FragmentRetro achieves high solved rates with competitive runtime,\nincluding cases where tree search fails. The method benefits from fingerprint\nscreening, which significantly reduces substructure matching complexity. While\nFragmentRetro focuses on efficiently identifying fragment-based solutions\nrather than full reaction pathways, its computational advantages and ability to\ngenerate strategic starting candidates establish it as a powerful foundational\ncomponent for scalable and automated synthesis planning."}
{"id": "2509.15756", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.15756", "abs": "https://arxiv.org/abs/2509.15756", "authors": ["Dongyang Zhan", "Kai Tan", "Lin Ye", "Xiangzhan Yu", "Hongli Zhang", "Zheng He"], "title": "An Adversarial Robust Behavior Sequence Anomaly Detection Approach Based on Critical Behavior Unit Learning", "comment": null, "summary": "Sequential deep learning models (e.g., RNN and LSTM) can learn the sequence\nfeatures of software behaviors, such as API or syscall sequences. However,\nrecent studies have shown that these deep learning-based approaches are\nvulnerable to adversarial samples. Attackers can use adversarial samples to\nchange the sequential characteristics of behavior sequences and mislead malware\nclassifiers. In this paper, an adversarial robustness anomaly detection method\nbased on the analysis of behavior units is proposed to overcome this problem.\nWe extract related behaviors that usually perform a behavior intention as a\nbehavior unit, which contains the representative semantic information of local\nbehaviors and can be used to improve the robustness of behavior analysis. By\nlearning the overall semantics of each behavior unit and the contextual\nrelationships among behavior units based on a multilevel deep learning model,\nour approach can mitigate perturbation attacks that target local and\nlarge-scale behaviors. In addition, our approach can be applied to both\nlow-level and high-level behavior logs (e.g., API and syscall logs). The\nexperimental results show that our approach outperforms all the compared\nmethods, which indicates that our approach has better performance against\nobfuscation attacks."}
{"id": "2509.15725", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2509.15725", "abs": "https://arxiv.org/abs/2509.15725", "authors": ["Matteo Repetto", "Enrico Cambiaso", "Fabio Patrone", "Sandro Zappatore"], "title": "Flying Drones to Locate Cyber-Attackers in LoRaWAN Metropolitan Networks", "comment": "12 pages", "summary": "Today, many critical services and industrial systems rely on wireless\nnetworks for interaction with the IoT, hence becoming vulnerable to a broad\nnumber of cyber-threats. While detecting this kind of attacks is not difficult\nwith common cyber-security tools, and even trivial for jamming, finding their\norigin and identifying culprits is almost impossible today, yet indispensable\nto stop them, especially when attacks are generated with portable or self-made\ndevices that continuously move around. To address this open challenge, the\nFOLLOWME project investigates the feasibility of using UAV to locate and even\nchase attackers during illicit usage of the radio spectrum. The main objective\nis to develop a cyber-physical security framework that integrates network\ntelemetry with wireless localization. The former triggers alarms in case of\nanomalies or known attack patterns and provides a coarse-grained indication of\nthe physical area (i.e., the position of affected access gateways), whereas the\nlatter systematically scans such area to identify the exact location of the\nattacker. The project will specifically address long-range metropolitan area\nnetworks and focus on the LoRaWAN protocol, which is the typical scenario for\nSmart City services."}
{"id": "2509.15541", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15541", "abs": "https://arxiv.org/abs/2509.15541", "authors": ["Bronson Schoen", "Evgenia Nitishinskaya", "Mikita Balesni", "Axel Højmark", "Felix Hofstätter", "Jérémy Scheurer", "Alexander Meinke", "Jason Wolfe", "Teun van der Weij", "Alex Lloyd", "Nicholas Goldowsky-Dill", "Angela Fan", "Andrei Matveiakin", "Rusheb Shah", "Marcus Williams", "Amelia Glaese", "Boaz Barak", "Wojciech Zaremba", "Marius Hobbhahn"], "title": "Stress Testing Deliberative Alignment for Anti-Scheming Training", "comment": null, "summary": "Highly capable AI systems could secretly pursue misaligned goals -- what we\ncall \"scheming\". Because a scheming AI would deliberately try to hide its\nmisaligned goals and actions, measuring and mitigating scheming requires\ndifferent strategies than are typically used in ML. We propose that assessing\nanti-scheming interventions requires at least (1) testing propensity to scheme\non far out-of-distribution (OOD) tasks, (2) evaluating whether lack of scheming\nis driven by situational awareness, and (3) checking for robustness to\npre-existing misaligned goals. We use a broad category of \"covert actions\" --\nsuch as secretly breaking rules or intentionally underperforming in tests -- as\na proxy for scheming, and design evaluations for covert actions. We then\nstress-test deliberative alignment as a case study for anti-scheming. Across 26\nOOD evaluations (180+ environments), deliberative alignment reduces covert\naction rates (OpenAI o3: 13%->0.4%) but does not fully eliminate them. Our\nmitigation is also able to largely stop agents from pursuing a hidden goal\npreviously trained into the model, but we still find misbehavior after\nadditional red-teaming. We find that models' chain-of-thought (CoT) often\ndemonstrates awareness of being evaluated for alignment, and show causal\nevidence that this awareness decreases covert behavior, while unawareness\nincreases it. Therefore, we cannot exclude that the observed reductions in\ncovert action rates are at least partially driven by situational awareness.\nWhile we rely on human-legible CoT for training, studying situational\nawareness, and demonstrating clear evidence of misalignment, our ability to\nrely on this degrades as models continue to depart from reasoning in standard\nEnglish. We encourage research into alignment mitigations for scheming and\ntheir assessment, especially for the adversarial case of deceptive alignment,\nwhich this paper does not address."}
{"id": "2509.15754", "categories": ["cs.CR", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.15754", "abs": "https://arxiv.org/abs/2509.15754", "authors": ["Toby Sharp"], "title": "Hornet Node and the Hornet DSL: A Minimal, Executable Specification for Bitcoin Consensus", "comment": null, "summary": "Bitcoin's consensus rules are encoded in the implementation of its reference\nclient: \"The code is the spec.\" Yet this code is unsuitable for formal\nverification due to side effects, mutable state, concurrency, and legacy\ndesign. A standalone formal specification would enable verification both across\nversions of the reference client and against new client implementations,\nstrengthening decentralization by reducing the risk of consensus-splitting\nbugs. Yet such a specification has long been considered intractable given the\ncomplexity of Bitcoin's consensus logic. We demonstrate a compact, executable,\ndeclarative C++ specification of Bitcoin consensus rules that syncs mainnet to\ntip in a few hours on a single thread. We also introduce the Hornet\nDomain-Specific Language (DSL) specifically designed to encode these rules\nunambiguously for execution, enabling formal reasoning, consensus code\ngeneration, and AI-driven adversarial testing. Our spec-driven client Hornet\nNode offers a modern and modular complement to the reference client. Its clear,\nidiomatic style makes it suitable for education, while its performance makes it\nideal for experimentation. We highlight architectural contributions such as its\nlayered design, efficient data structures, and strong separation of concerns,\nsupported by production-quality code examples. We argue that Hornet Node and\nHornet DSL together provide the first credible path toward a pure, formal,\nexecutable specification of Bitcoin consensus."}
{"id": "2509.15635", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15635", "abs": "https://arxiv.org/abs/2509.15635", "authors": ["Pan Tang", "Shixiang Tang", "Huanqi Pu", "Zhiqing Miao", "Zhixing Wang"], "title": "MicroRCA-Agent: Microservice Root Cause Analysis Method Based on Large Language Model Agents", "comment": "18 pages, 22 figures", "summary": "This paper presents MicroRCA-Agent, an innovative solution for microservice\nroot cause analysis based on large language model agents, which constructs an\nintelligent fault root cause localization system with multimodal data fusion.\nThe technical innovations are embodied in three key aspects: First, we combine\nthe pre-trained Drain log parsing algorithm with multi-level data filtering\nmechanism to efficiently compress massive logs into high-quality fault\nfeatures. Second, we employ a dual anomaly detection approach that integrates\nIsolation Forest unsupervised learning algorithms with status code validation\nto achieve comprehensive trace anomaly identification. Third, we design a\nstatistical symmetry ratio filtering mechanism coupled with a two-stage LLM\nanalysis strategy to enable full-stack phenomenon summarization across\nnode-service-pod hierarchies. The multimodal root cause analysis module\nleverages carefully designed cross-modal prompts to deeply integrate multimodal\nanomaly information, fully exploiting the cross-modal understanding and logical\nreasoning capabilities of large language models to generate structured analysis\nresults encompassing fault components, root cause descriptions, and reasoning\ntrace. Comprehensive ablation studies validate the complementary value of each\nmodal data and the effectiveness of the system architecture. The proposed\nsolution demonstrates superior performance in complex microservice fault\nscenarios, achieving a final score of 50.71. The code has been released at:\nhttps://github.com/tangpan360/MicroRCA-Agent."}
{"id": "2509.15756", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.15756", "abs": "https://arxiv.org/abs/2509.15756", "authors": ["Dongyang Zhan", "Kai Tan", "Lin Ye", "Xiangzhan Yu", "Hongli Zhang", "Zheng He"], "title": "An Adversarial Robust Behavior Sequence Anomaly Detection Approach Based on Critical Behavior Unit Learning", "comment": null, "summary": "Sequential deep learning models (e.g., RNN and LSTM) can learn the sequence\nfeatures of software behaviors, such as API or syscall sequences. However,\nrecent studies have shown that these deep learning-based approaches are\nvulnerable to adversarial samples. Attackers can use adversarial samples to\nchange the sequential characteristics of behavior sequences and mislead malware\nclassifiers. In this paper, an adversarial robustness anomaly detection method\nbased on the analysis of behavior units is proposed to overcome this problem.\nWe extract related behaviors that usually perform a behavior intention as a\nbehavior unit, which contains the representative semantic information of local\nbehaviors and can be used to improve the robustness of behavior analysis. By\nlearning the overall semantics of each behavior unit and the contextual\nrelationships among behavior units based on a multilevel deep learning model,\nour approach can mitigate perturbation attacks that target local and\nlarge-scale behaviors. In addition, our approach can be applied to both\nlow-level and high-level behavior logs (e.g., API and syscall logs). The\nexperimental results show that our approach outperforms all the compared\nmethods, which indicates that our approach has better performance against\nobfuscation attacks."}
{"id": "2509.15690", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15690", "abs": "https://arxiv.org/abs/2509.15690", "authors": ["Weixuan Sun", "Jucai Zhai", "Dengfeng Liu", "Xin Zhang", "Xiaojun Wu", "Qiaobo Hao", "AIMgroup", "Yang Fang", "Jiuyang Tang"], "title": "CCrepairBench: A High-Fidelity Benchmark and Reinforcement Learning Framework for C++ Compilation Repair", "comment": null, "summary": "The automated repair of C++ compilation errors presents a significant\nchallenge, the resolution of which is critical for developer productivity.\nProgress in this domain is constrained by two primary factors: the scarcity of\nlarge-scale, high-fidelity datasets and the limitations of conventional\nsupervised methods, which often fail to generate semantically correct\npatches.This paper addresses these gaps by introducing a comprehensive\nframework with three core contributions. First, we present CCrepair, a novel,\nlarge-scale C++ compilation error dataset constructed through a sophisticated\ngenerate-and-verify pipeline. Second, we propose a Reinforcement Learning (RL)\nparadigm guided by a hybrid reward signal, shifting the focus from mere\ncompilability to the semantic quality of the fix. Finally, we establish the\nrobust, two-stage evaluation system providing this signal, centered on an\nLLM-as-a-Judge whose reliability has been rigorously validated against the\ncollective judgments of a panel of human experts. This integrated approach\naligns the training objective with generating high-quality, non-trivial patches\nthat are both syntactically and semantically correct. The effectiveness of our\napproach was demonstrated experimentally. Our RL-trained Qwen2.5-1.5B-Instruct\nmodel achieved performance comparable to a Qwen2.5-14B-Instruct model,\nvalidating the efficiency of our training paradigm. Our work provides the\nresearch community with a valuable new dataset and a more effective paradigm\nfor training and evaluating robust compilation repair models, paving the way\nfor more practical and reliable automated programming assistants."}
{"id": "2509.16030", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.16030", "abs": "https://arxiv.org/abs/2509.16030", "authors": ["Kai Tan", "Dongyang Zhan", "Lin Ye", "Hongli Zhang", "Binxing Fang", "Zhihong Tian"], "title": "A High-performance Real-time Container File Monitoring Approach Based on Virtual Machine Introspection", "comment": null, "summary": "As cloud computing continues to advance and become an integral part of modern\nIT infrastructure, container security has emerged as a critical factor in\nensuring the smooth operation of cloud-native applications. An attacker can\nattack the service in the container or even perform the container escape attack\nby tampering with the files. Monitoring container files is important for APT\ndetection and cyberspace security. Existing file monitoring methods are usually\nbased on host operating system or virtual machine introspection to protect file\nsecurity in real time. The methods based on the host operating system usually\nmonitor file operations in the host operating system. However, when the\ncontainer escapes to the host, the host operating system will no longer be\nsecure, so these methods face the problem of weak security. Aiming at the\nproblems of low security and high overload introduced in existing container\nfile monitoring, a high-performance container file monitoring method based on\nvirtual machine introspection is proposed. The experimental results show that\nthe proposed approach can effectively monitor the container files and introduce\nan acceptable monitoring overload."}
{"id": "2509.15730", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.15730", "abs": "https://arxiv.org/abs/2509.15730", "authors": ["Lukas Laakmann", "Seyyid A. Ciftci", "Christian Janiesch"], "title": "A Nascent Taxonomy of Machine Learning in Intelligent Robotic Process Automation", "comment": null, "summary": "Robotic process automation (RPA) is a lightweight approach to automating\nbusiness processes using software robots that emulate user actions at the\ngraphical user interface level. While RPA has gained popularity for its\ncost-effective and timely automation of rule-based, well-structured tasks, its\nsymbolic nature has inherent limitations when approaching more complex tasks\ncurrently performed by human agents. Machine learning concepts enabling\nintelligent RPA provide an opportunity to broaden the range of automatable\ntasks. In this paper, we conduct a literature review to explore the connections\nbetween RPA and machine learning and organize the joint concept intelligent RPA\ninto a taxonomy. Our taxonomy comprises the two meta-characteristics RPA-ML\nintegration and RPA-ML interaction. Together, they comprise eight dimensions:\narchitecture and ecosystem, capabilities, data basis, intelligence level, and\ntechnical depth of integration as well as deployment environment, lifecycle\nphase, and user-robot relation."}
{"id": "2509.16038", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2509.16038", "abs": "https://arxiv.org/abs/2509.16038", "authors": ["Miel Verkerken", "Laurens D'hooge", "Bruno Volckaert", "Filip De Turck", "Giovanni Apruzzese"], "title": "ConCap: Practical Network Traffic Generation for Flow-based Intrusion Detection Systems", "comment": "20 pages", "summary": "Network Intrusion Detection Systems (NIDS) have been studied in research for\nalmost four decades. Yet, despite thousands of papers claiming scientific\nadvances, a non-negligible number of recent works suggest that the findings of\nprior literature may be questionable. At the root of such a disagreement is the\nwell-known challenge of obtaining data representative of a real-world\nnetwork-and, hence, usable for security assessments. We tackle such a challenge\nin this paper. We propose ConCap, a practical tool meant to facilitate\nexperimental research on NIDS. Through ConCap, a researcher can set up an\nisolated and lightweight network environment and configure it to produce\nnetwork-related data, such as packets or NetFlows, that are automatically\nlabeled, hence ready for fine-grained experiments. ConCap is rooted on\nopen-source software and is designed to foster experimental reproducibility\nacross the scientific community by sharing just one configuration file. Through\ncomprehensive experiments on 10 different network activities, further expanded\nvia in-depth analyses of 21 variants of two specific activities and of 100\nrepetitions of four other ones, we empirically verify that ConCap produces\nnetwork data resembling that of a real-world network. We also carry out\nexperiments on well-known benchmark datasets as well as on a real \"smart-home\"\nnetwork, showing that, from a cyber-detection viewpoint, ConCap's\nautomatically-labeled NetFlows are functionally equivalent to those collected\nin other environments. Finally, we show that ConCap enables to safely reproduce\nsophisticated attack chains (e.g., to test/enhance existing NIDS). Altogether,\nConCap is a solution to the \"data problem\" that is plaguing NIDS research."}
{"id": "2509.15780", "categories": ["cs.AI", "cs.DL"], "pdf": "https://arxiv.org/pdf/2509.15780", "abs": "https://arxiv.org/abs/2509.15780", "authors": ["Natallia Kokash", "Bernard de Bono", "Tom Gillespie"], "title": "Ontology Creation and Management Tools: the Case of Anatomical Connectivity", "comment": "14 pages", "summary": "We are developing infrastructure to support researchers in mapping data\nrelated to the peripheral nervous system and other physiological systems, with\nan emphasis on their relevance to the organs under investigation. The nervous\nsystem, a complex network of nerves and ganglia, plays a critical role in\ncoordinating and transmitting signals throughout the body. To aid in this, we\nhave created ApiNATOMY, a framework for the topological and semantic\nrepresentation of multiscale physiological circuit maps. ApiNATOMY integrates a\nKnowledge Representation (KR) model and a suite of Knowledge Management (KM)\ntools. The KR model enables physiology experts to easily capture interactions\nbetween anatomical entities, while the KM tools help modelers convert\nhigh-level abstractions into detailed models of physiological processes, which\ncan be integrated with external ontologies and knowledge graphs."}
{"id": "2509.16052", "categories": ["cs.CR", "cs.DC", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2509.16052", "abs": "https://arxiv.org/abs/2509.16052", "authors": ["Vabuk Pahari", "Andrea Canidio"], "title": "How Exclusive are Ethereum Transactions? Evidence from non-winning blocks", "comment": "arXiv admin note: text overlap with arXiv:2506.04940", "summary": "We analyze 15,097 blocks proposed for inclusion in Ethereum's blockchain over\nan 8-minute window on December 3, 2024, during which 38 blocks were added to\nthe chain. We classify transactions as exclusive -- present only in blocks from\na single builder -- or private -- absent from the public mempool but included\nin blocks from multiple builders. We find that exclusive transactions account\nfor 84% of the total fees paid by transactions in winning blocks. Furthermore,\nwe show that exclusivity cannot be fully explained by exclusive relationships\nbetween senders and builders: about 7% of all exclusive transactions included\non-chain, by value, come from senders who route exclusively to a single\nbuilder. Analyzing transaction logs shows that some exclusive transactions are\nduplicates or variations of the same strategy, but even accounting for that,\nthe share of the total fees paid by transactions in winning blocks is at least\n77.2%. Taken together, our findings highlight that exclusive transactions are\nthe dominant source of builder revenues."}
{"id": "2509.15786", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2509.15786", "abs": "https://arxiv.org/abs/2509.15786", "authors": ["Nan Li", "Bo Kang", "Tijl De Bie"], "title": "Building Data-Driven Occupation Taxonomies: A Bottom-Up Multi-Stage Approach via Semantic Clustering and Multi-Agent Collaboration", "comment": null, "summary": "Creating robust occupation taxonomies, vital for applications ranging from\njob recommendation to labor market intelligence, is challenging. Manual\ncuration is slow, while existing automated methods are either not adaptive to\ndynamic regional markets (top-down) or struggle to build coherent hierarchies\nfrom noisy data (bottom-up). We introduce CLIMB (CLusterIng-based Multi-agent\ntaxonomy Builder), a framework that fully automates the creation of\nhigh-quality, data-driven taxonomies from raw job postings. CLIMB uses global\nsemantic clustering to distill core occupations, then employs a\nreflection-based multi-agent system to iteratively build a coherent hierarchy.\nOn three diverse, real-world datasets, we show that CLIMB produces taxonomies\nthat are more coherent and scalable than existing methods and successfully\ncapture unique regional characteristics. We release our code and datasets at\nhttps://anonymous.4open.science/r/CLIMB."}
{"id": "2509.15848", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15848", "abs": "https://arxiv.org/abs/2509.15848", "authors": ["Giovanni De Gasperis", "Sante Dino Facchini"], "title": "A Comparative Study of Rule-Based and Data-Driven Approaches in Industrial Monitoring", "comment": null, "summary": "Industrial monitoring systems, especially when deployed in Industry 4.0\nenvironments, are experiencing a shift in paradigm from traditional rule-based\narchitectures to data-driven approaches leveraging machine learning and\nartificial intelligence. This study presents a comparison between these two\nmethodologies, analyzing their respective strengths, limitations, and\napplication scenarios, and proposes a basic framework to evaluate their key\nproperties. Rule-based systems offer high interpretability, deterministic\nbehavior, and ease of implementation in stable environments, making them ideal\nfor regulated industries and safety-critical applications. However, they face\nchallenges with scalability, adaptability, and performance in complex or\nevolving contexts. Conversely, data-driven systems excel in detecting hidden\nanomalies, enabling predictive maintenance and dynamic adaptation to new\nconditions. Despite their high accuracy, these models face challenges related\nto data availability, explainability, and integration complexity. The paper\nsuggests hybrid solutions as a possible promising direction, combining the\ntransparency of rule-based logic with the analytical power of machine learning.\nOur hypothesis is that the future of industrial monitoring lies in intelligent,\nsynergic systems that leverage both expert knowledge and data-driven insights.\nThis dual approach enhances resilience, operational efficiency, and trust,\npaving the way for smarter and more flexible industrial environments."}
{"id": "2509.15957", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.IR"], "pdf": "https://arxiv.org/pdf/2509.15957", "abs": "https://arxiv.org/abs/2509.15957", "authors": ["Kanato Masayoshi", "Masahiro Hashimoto", "Ryoichi Yokoyama", "Naoki Toda", "Yoshifumi Uwamino", "Shogo Fukuda", "Ho Namkoong", "Masahiro Jinzaki"], "title": "EHR-MCP: Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol", "comment": null, "summary": "Background: Large language models (LLMs) show promise in medicine, but their\ndeployment in hospitals is limited by restricted access to electronic health\nrecord (EHR) systems. The Model Context Protocol (MCP) enables integration\nbetween LLMs and external tools.\n  Objective: To evaluate whether an LLM connected to an EHR database via MCP\ncan autonomously retrieve clinically relevant information in a real hospital\nsetting.\n  Methods: We developed EHR-MCP, a framework of custom MCP tools integrated\nwith the hospital EHR database, and used GPT-4.1 through a LangGraph ReAct\nagent to interact with it. Six tasks were tested, derived from use cases of the\ninfection control team (ICT). Eight patients discussed at ICT conferences were\nretrospectively analyzed. Agreement with physician-generated gold standards was\nmeasured.\n  Results: The LLM consistently selected and executed the correct MCP tools.\nExcept for two tasks, all tasks achieved near-perfect accuracy. Performance was\nlower in the complex task requiring time-dependent calculations. Most errors\narose from incorrect arguments or misinterpretation of tool results. Responses\nfrom EHR-MCP were reliable, though long and repetitive data risked exceeding\nthe context window.\n  Conclusions: LLMs can retrieve clinical data from an EHR via MCP tools in a\nreal hospital setting, achieving near-perfect performance in simple tasks while\nhighlighting challenges in complex ones. EHR-MCP provides an infrastructure for\nsecure, consistent data access and may serve as a foundation for hospital AI\nagents. Future work should extend beyond retrieval to reasoning, generation,\nand clinical impact assessment, paving the way for effective integration of\ngenerative AI into clinical practice."}
{"id": "2509.15962", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15962", "abs": "https://arxiv.org/abs/2509.15962", "authors": ["Sander Schildermans", "Chang Tian", "Ying Jiao", "Marie-Francine Moens"], "title": "Structured Information for Improving Spatial Relationships in Text-to-Image Generation", "comment": "text-to-image generation, structured information, spatial\n  relationship", "summary": "Text-to-image (T2I) generation has advanced rapidly, yet faithfully capturing\nspatial relationships described in natural language prompts remains a major\nchallenge. Prior efforts have addressed this issue through prompt optimization,\nspatially grounded generation, and semantic refinement. This work introduces a\nlightweight approach that augments prompts with tuple-based structured\ninformation, using a fine-tuned language model for automatic conversion and\nseamless integration into T2I pipelines. Experimental results demonstrate\nsubstantial improvements in spatial accuracy, without compromising overall\nimage quality as measured by Inception Score. Furthermore, the automatically\ngenerated tuples exhibit quality comparable to human-crafted tuples. This\nstructured information provides a practical and portable solution to enhance\nspatial relationships in T2I generation, addressing a key limitation of current\nlarge-scale generative systems."}
{"id": "2509.16058", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.16058", "abs": "https://arxiv.org/abs/2509.16058", "authors": ["Krati Saxena", "Federico Jurado Ruiz", "Guido Manzi", "Dianbo Liu", "Alex Lamb"], "title": "Attention Schema-based Attention Control (ASAC): A Cognitive-Inspired Approach for Attention Management in Transformers", "comment": null, "summary": "Attention mechanisms have become integral in AI, significantly enhancing\nmodel performance and scalability by drawing inspiration from human cognition.\nConcurrently, the Attention Schema Theory (AST) in cognitive science posits\nthat individuals manage their attention by creating a model of the attention\nitself, effectively allocating cognitive resources. Inspired by AST, we\nintroduce ASAC (Attention Schema-based Attention Control), which integrates the\nattention schema concept into artificial neural networks. Our initial\nexperiments focused on embedding the ASAC module within transformer\narchitectures. This module employs a Vector-Quantized Variational AutoEncoder\n(VQVAE) as both an attention abstractor and controller, facilitating precise\nattention management. By explicitly modeling attention allocation, our approach\naims to enhance system efficiency. We demonstrate ASAC's effectiveness in both\nthe vision and NLP domains, highlighting its ability to improve classification\naccuracy and expedite the learning process. Our experiments with vision\ntransformers across various datasets illustrate that the attention controller\nnot only boosts classification accuracy but also accelerates learning.\nFurthermore, we have demonstrated the model's robustness and generalization\ncapabilities across noisy and out-of-distribution datasets. In addition, we\nhave showcased improved performance in multi-task settings. Quick experiments\nreveal that the attention schema-based module enhances resilience to\nadversarial attacks, optimizes attention to improve learning efficiency, and\nfacilitates effective transfer learning and learning from fewer examples. These\npromising results establish a connection between cognitive science and machine\nlearning, shedding light on the efficient utilization of attention mechanisms\nin AI systems."}
{"id": "2509.15283", "categories": ["cs.SE", "cs.AI", "cs.LG", "cs.PL", "I.2.7; F.2.2; I.2.2"], "pdf": "https://arxiv.org/pdf/2509.15283", "abs": "https://arxiv.org/abs/2509.15283", "authors": ["Kadin Matotek", "Heather Cassel", "Md Amiruzzaman", "Linh B. Ngo"], "title": "Evaluating the Limitations of Local LLMs in Solving Complex Programming Challenges", "comment": "Comments: 16 pages, 3 figures, 8 tables, accepted to CCSC Eastern\n  2025", "summary": "This study examines the performance of today's open-source, locally hosted\nlarge-language models (LLMs) in handling complex competitive programming tasks\nwith extended problem descriptions and contexts. Building on the original\nFramework for AI-driven Code Generation Evaluation (FACE), the authors retrofit\nthe pipeline to work entirely offline through the Ollama runtime, collapsing\nFACE's sprawling per-problem directory tree into a handful of consolidated JSON\nfiles, and adding robust checkpointing so multi-day runs can resume after\nfailures. The enhanced framework generates, submits, and records solutions for\nthe full Kattis corpus of 3,589 problems across eight code-oriented models\nranging from 6.7-9 billion parameters. The submission results show that the\noverall pass@1 accuracy is modest for the local models, with the best models\nperforming at approximately half the acceptance rate of the proprietary models,\nGemini 1.5 and ChatGPT-4. These findings expose a persistent gap between\nprivate, cost-controlled LLM deployments and state-of-the-art proprietary\nservices, yet also highlight the rapid progress of open models and the\npractical benefits of an evaluation workflow that organizations can replicate\non in-house hardware."}
