{"id": "2602.09131", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.09131", "abs": "https://arxiv.org/abs/2602.09131", "authors": ["Merve G\u00fclmez", "Ruben Sturm", "Hossam ElAtali", "H\u00e5kan Englund", "Jonathan Woodruff", "N. Asokan", "Thomas Nyman"], "title": "PICASSO: Scaling CHERI Use-After-Free Protection to Millions of Allocations using Colored Capabilities", "comment": null, "summary": "While the CHERI instruction-set architecture extensions for capabilities enable strong spatial memory safety, CHERI lacks built-in temporal safety, particularly for heap allocations. Prior attempts to augment CHERI with temporal safety fall short in terms of scalability, memory overhead, and incomplete security guarantees due to periodical sweeps of the system's memory to individually revoke stale capabilities. We address these limitations by introducing colored capabilities that add a controlled form of indirection to CHERI's capability model. This enables provenance tracking of capabilities to their respective allocations via a hardware-managed provenance-validity table, allowing bulk retraction of dangling pointers without needing to quarantine freed memory. Colored capabilities significantly reduce the frequency of capability revocation sweeps while improving security. We realize colored capabilities in PICASSO, an extension of the CHERI-RISC-V architecture on a speculative out-of-order FPGA softcore (CHERI-Toooba). We also integrate colored-capability support into the CheriBSD OS and CHERI-enabled Clang/LLVM toolchain. Our evaluation shows effective mitigation of use-after-free and double-free bugs across all heap-based temporal memory-safety vulnerabilities in NIST Juliet test cases, with only a small performance overhead on SPEC CPU benchmarks (5% g.m.), less latency, and more consistent performance in long-running SQLite, PostgreSQL, and gRPC workloads compared to prior work.", "AI": {"tldr": "PICASSO\u901a\u8fc7\u5f15\u5165\u5f69\u8272\u80fd\u529b\u6269\u5c55CHERI\u67b6\u6784\uff0c\u63d0\u4f9b\u786c\u4ef6\u7ba1\u7406\u7684\u6765\u6e90\u6709\u6548\u6027\u8868\uff0c\u5b9e\u73b0\u6279\u91cf\u64a4\u9500\u60ac\u7a7a\u6307\u9488\uff0c\u6709\u6548\u7f13\u89e3\u5806\u5185\u5b58\u7684\u65f6\u7a7a\u5b89\u5168\u95ee\u9898\uff0c\u6027\u80fd\u5f00\u9500\u5c0f\u3002", "motivation": "CHERI\u6307\u4ee4\u96c6\u67b6\u6784\u867d\u7136\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u7a7a\u95f4\u5185\u5b58\u5b89\u5168\u6027\uff0c\u4f46\u7f3a\u4e4f\u5185\u7f6e\u7684\u65f6\u6001\u5b89\u5168\u6027\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u5806\u5206\u914d\u3002\u5148\u524d\u589e\u5f3aCHERI\u65f6\u6001\u5b89\u5168\u6027\u7684\u5c1d\u8bd5\u5728\u53ef\u6269\u5c55\u6027\u3001\u5185\u5b58\u5f00\u9500\u548c\u5b89\u5168\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u4e3b\u8981\u56e0\u4e3a\u9700\u8981\u5b9a\u671f\u626b\u63cf\u7cfb\u7edf\u5185\u5b58\u6765\u5355\u72ec\u64a4\u9500\u8fc7\u65f6\u7684\u80fd\u529b\u3002", "method": "\u5f15\u5165\u5f69\u8272\u80fd\u529b\uff0c\u4e3aCHERI\u7684\u80fd\u529b\u6a21\u578b\u6dfb\u52a0\u53d7\u63a7\u7684\u95f4\u63a5\u5c42\u3002\u901a\u8fc7\u786c\u4ef6\u7ba1\u7406\u7684\u6765\u6e90\u6709\u6548\u6027\u8868\u8ddf\u8e2a\u80fd\u529b\u5230\u5404\u81ea\u5206\u914d\u7684\u6765\u6e90\uff0c\u5141\u8bb8\u6279\u91cf\u64a4\u9500\u60ac\u7a7a\u6307\u9488\u800c\u65e0\u9700\u9694\u79bb\u5df2\u91ca\u653e\u7684\u5185\u5b58\u3002\u5728CHERI-RISC-V\u67b6\u6784\u4e0a\u5b9e\u73b0PICASSO\u6269\u5c55\uff0c\u5e76\u96c6\u6210\u5230CheriBSD\u64cd\u4f5c\u7cfb\u7edf\u548cCHERI-enabled Clang/LLVM\u5de5\u5177\u94fe\u4e2d\u3002", "result": "\u6709\u6548\u7f13\u89e3\u4e86NIST Juliet\u6d4b\u8bd5\u7528\u4f8b\u4e2d\u6240\u6709\u57fa\u4e8e\u5806\u7684\u65f6\u6001\u5185\u5b58\u5b89\u5168\u6f0f\u6d1e\uff08use-after-free\u548cdouble-free\u9519\u8bef\uff09\u3002\u5728SPEC CPU\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4ec5\u4ea7\u751f5%\u7684\u51e0\u4f55\u5e73\u5747\u6027\u80fd\u5f00\u9500\uff0c\u5728SQLite\u3001PostgreSQL\u548cgRPC\u7b49\u957f\u65f6\u95f4\u8fd0\u884c\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u76f8\u6bd4\u5148\u524d\u5de5\u4f5c\u5177\u6709\u66f4\u4f4e\u7684\u5ef6\u8fdf\u548c\u66f4\u4e00\u81f4\u7684\u6027\u80fd\u3002", "conclusion": "\u5f69\u8272\u80fd\u529b\u663e\u8457\u51cf\u5c11\u4e86\u80fd\u529b\u64a4\u9500\u626b\u63cf\u7684\u9891\u7387\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u5b89\u5168\u6027\uff0c\u4e3aCHERI\u67b6\u6784\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u65f6\u6001\u5185\u5b58\u5b89\u5168\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u8f83\u5c0f\u7684\u6027\u80fd\u5f00\u9500\u3002"}}
{"id": "2602.09182", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.09182", "abs": "https://arxiv.org/abs/2602.09182", "authors": ["Kotekar Annapoorna Prabhu", "Andrew Gan", "Zahra Ghodsi"], "title": "One RNG to Rule Them All: How Randomness Becomes an Attack Vector in Machine Learning", "comment": "This work has been accepted for publication at the IEEE Conference on Secure and Trustworthy Machine Learning (SaTML). The final version will be available on IEEE Xplore", "summary": "Machine learning relies on randomness as a fundamental component in various steps such as data sampling, data augmentation, weight initialization, and optimization. Most machine learning frameworks use pseudorandom number generators as the source of randomness. However, variations in design choices and implementations across different frameworks, software dependencies, and hardware backends along with the lack of statistical validation can lead to previously unexplored attack vectors on machine learning systems. Such attacks on randomness sources can be extremely covert, and have a history of exploitation in real-world systems. In this work, we examine the role of randomness in the machine learning development pipeline from an adversarial point of view, and analyze the implementations of PRNGs in major machine learning frameworks. We present RNGGuard to help machine learning engineers secure their systems with low effort. RNGGuard statically analyzes a target library's source code and identifies instances of random functions and modules that use them. At runtime, RNGGuard enforces secure execution of random functions by replacing insecure function calls with RNGGuard's implementations that meet security specifications. Our evaluations show that RNGGuard presents a practical approach to close existing gaps in securing randomness sources in machine learning systems.", "AI": {"tldr": "RNGGuard\uff1a\u4e00\u79cd\u4fdd\u62a4\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u4e2d\u968f\u673a\u6570\u751f\u6210\u5668\u5b89\u5168\u6027\u7684\u5de5\u5177\uff0c\u901a\u8fc7\u9759\u6001\u5206\u6790\u548c\u8fd0\u884c\u65f6\u66ff\u6362\u6765\u9632\u5fa1\u9488\u5bf9\u968f\u673a\u6027\u6e90\u7684\u653b\u51fb", "motivation": "\u673a\u5668\u5b66\u4e60\u4e25\u91cd\u4f9d\u8d56\u968f\u673a\u6027\uff08\u6570\u636e\u91c7\u6837\u3001\u6570\u636e\u589e\u5f3a\u3001\u6743\u91cd\u521d\u59cb\u5316\u3001\u4f18\u5316\u7b49\uff09\uff0c\u4f46\u4e0d\u540c\u6846\u67b6\u3001\u8f6f\u4ef6\u4f9d\u8d56\u548c\u786c\u4ef6\u540e\u7aef\u7684\u4f2a\u968f\u673a\u6570\u751f\u6210\u5668\u5b9e\u73b0\u5dee\u5f02\u4ee5\u53ca\u7f3a\u4e4f\u7edf\u8ba1\u9a8c\u8bc1\uff0c\u53ef\u80fd\u5f62\u6210\u672a\u63a2\u7d22\u7684\u653b\u51fb\u5411\u91cf\u3002\u9488\u5bf9\u968f\u673a\u6027\u6e90\u7684\u653b\u51fb\u6781\u5176\u9690\u853d\uff0c\u5728\u73b0\u5b9e\u7cfb\u7edf\u4e2d\u5df2\u6709\u88ab\u5229\u7528\u7684\u5386\u53f2\u3002", "method": "\u63d0\u51faRNGGuard\u5de5\u5177\uff1a1\uff09\u9759\u6001\u5206\u6790\u76ee\u6807\u5e93\u7684\u6e90\u4ee3\u7801\uff0c\u8bc6\u522b\u968f\u673a\u51fd\u6570\u53ca\u5176\u4f7f\u7528\u6a21\u5757\uff1b2\uff09\u5728\u8fd0\u884c\u65f6\u901a\u8fc7\u5c06\u4e0d\u5b89\u5168\u7684\u51fd\u6570\u8c03\u7528\u66ff\u6362\u4e3a\u7b26\u5408\u5b89\u5168\u89c4\u8303\u7684RNGGuard\u5b9e\u73b0\u6765\u5f3a\u5236\u6267\u884c\u5b89\u5168\u968f\u673a\u51fd\u6570\u6267\u884c\u3002", "result": "\u8bc4\u4f30\u8868\u660eRNGGuard\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u65b9\u6cd5\u6765\u586b\u8865\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u4e2d\u4fdd\u62a4\u968f\u673a\u6027\u6e90\u7684\u73b0\u6709\u5b89\u5168\u6f0f\u6d1e\u3002", "conclusion": "RNGGuard\u80fd\u591f\u4ee5\u8f83\u4f4e\u7684\u5de5\u4f5c\u91cf\u5e2e\u52a9\u673a\u5668\u5b66\u4e60\u5de5\u7a0b\u5e08\u4fdd\u62a4\u5176\u7cfb\u7edf\uff0c\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u65b9\u6cd5\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u5f00\u53d1\u6d41\u7a0b\u4e2d\u968f\u673a\u6027\u6e90\u7684\u5b89\u5168\u95ee\u9898\u3002"}}
{"id": "2602.09112", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09112", "abs": "https://arxiv.org/abs/2602.09112", "authors": ["Russ Webb", "Jason Ramapuram"], "title": "A Small-Scale System for Autoregressive Program Synthesis Enabling Controlled Experimentation", "comment": null, "summary": "What research can be pursued with small models trained to complete true programs? Typically, researchers study program synthesis via large language models (LLMs) which introduce issues such as knowing what is in or out of distribution, understanding fine-tuning effects, understanding the effects of tokenization, and higher demand on compute and storage to carry out experiments. We present a system called Cadmus which includes an integer virtual machine (VM), a dataset composed of true programs of diverse tasks, and an autoregressive transformer model that is trained for under \\$200 of compute cost. The system can be used to study program completion, out-of-distribution representations, inductive reasoning, and instruction following in a setting where researchers have effective and affordable fine-grained control of the training distribution and the ability to inspect and instrument models. Smaller models working on complex reasoning tasks enable instrumentation and investigations that may be prohibitively expensive on larger models. To demonstrate that these tasks are complex enough to be of interest, we show that these Cadmus models outperform GPT-5 (by achieving 100\\% accuracy while GPT-5 has 95\\% accuracy) even on a simple task of completing correct, integer arithmetic programs in our domain-specific language (DSL) while providing transparency into the dataset's relationship to the problem. We also show that GPT-5 brings unknown priors into its reasoning process when solving the same tasks, demonstrating a confounding factor that prevents the use of large-scale LLMs for some investigations where the training set relationship to the task needs to be fully understood.", "AI": {"tldr": "Cadmus\u7cfb\u7edf\uff1a\u4e00\u4e2a\u4f4e\u6210\u672c\u5c0f\u6a21\u578b\u7a0b\u5e8f\u5408\u6210\u7814\u7a76\u5e73\u53f0\uff0c\u7528\u4e8e\u7814\u7a76\u7a0b\u5e8f\u8865\u5168\u3001\u5206\u5e03\u5916\u8868\u793a\u3001\u5f52\u7eb3\u63a8\u7406\u548c\u6307\u4ee4\u8ddf\u968f\uff0c\u5728\u7279\u5b9a\u4efb\u52a1\u4e0a\u8d85\u8d8aGPT-5", "motivation": "\u5f53\u524d\u7a0b\u5e8f\u5408\u6210\u7814\u7a76\u4e3b\u8981\u4f9d\u8d56\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5b58\u5728\u5206\u5e03\u95ee\u9898\u4e0d\u660e\u786e\u3001\u5fae\u8c03\u6548\u679c\u96be\u7406\u89e3\u3001\u5206\u8bcd\u5f71\u54cd\u4e0d\u6e05\u6670\u3001\u8ba1\u7b97\u5b58\u50a8\u6210\u672c\u9ad8\u7b49\u95ee\u9898\u3002\u9700\u8981\u4e00\u4e2a\u5c0f\u578b\u3001\u900f\u660e\u3001\u53ef\u63a7\u7684\u7814\u7a76\u5e73\u53f0\u6765\u6df1\u5165\u7406\u89e3\u7a0b\u5e8f\u5408\u6210\u7684\u672c\u8d28\u673a\u5236\u3002", "method": "\u5f00\u53d1\u4e86Cadmus\u7cfb\u7edf\uff0c\u5305\u542b\u6574\u6570\u865a\u62df\u673a\u3001\u591a\u6837\u5316\u771f\u5b9e\u7a0b\u5e8f\u6570\u636e\u96c6\u548c\u81ea\u56de\u5f52Transformer\u6a21\u578b\uff0c\u8bad\u7ec3\u6210\u672c\u4f4e\u4e8e200\u7f8e\u5143\u3002\u8be5\u7cfb\u7edf\u5141\u8bb8\u7814\u7a76\u8005\u7cbe\u7ec6\u63a7\u5236\u8bad\u7ec3\u5206\u5e03\uff0c\u5e76\u80fd\u68c0\u67e5\u548c\u63d2\u88c5\u6a21\u578b\u3002", "result": "Cadmus\u6a21\u578b\u5728\u7279\u5b9a\u9886\u57df\u8bed\u8a00\uff08DSL\uff09\u7684\u6574\u6570\u7b97\u672f\u7a0b\u5e8f\u8865\u5168\u4efb\u52a1\u4e0a\u8fbe\u5230100%\u51c6\u786e\u7387\uff0c\u4f18\u4e8eGPT-5\u768495%\u3002\u540c\u65f6\u63ed\u793a\u4e86GPT-5\u5728\u89e3\u51b3\u76f8\u540c\u4efb\u52a1\u65f6\u5f15\u5165\u4e86\u672a\u77e5\u7684\u5148\u9a8c\u77e5\u8bc6\uff0c\u8fd9\u6210\u4e3a\u4f7f\u7528\u5927\u89c4\u6a21LLM\u8fdb\u884c\u7814\u7a76\u65f6\u7684\u6df7\u6742\u56e0\u7d20\u3002", "conclusion": "\u5c0f\u578b\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u80fd\u591f\u5b9e\u73b0\u66f4\u6df1\u5165\u7684\u53ef\u89e3\u91ca\u6027\u7814\u7a76\uff0c\u4e3a\u7a0b\u5e8f\u5408\u6210\u3001\u5206\u5e03\u5916\u8868\u793a\u3001\u5f52\u7eb3\u63a8\u7406\u7b49\u7814\u7a76\u63d0\u4f9b\u4e86\u900f\u660e\u3001\u53ef\u63a7\u3001\u4f4e\u6210\u672c\u7684\u7814\u7a76\u5e73\u53f0\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u6a21\u578b\u4e0e\u8bad\u7ec3\u6570\u636e\u4e4b\u95f4\u7684\u5173\u7cfb\u3002"}}
{"id": "2602.09051", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09051", "abs": "https://arxiv.org/abs/2602.09051", "authors": ["Avaljot Singh", "Dushyant Bharadwaj", "Stefanos Baziotis", "Kaushik Varadharajan", "Charith Mendis"], "title": "RuleFlow : Generating Reusable Program Optimizations with LLMs", "comment": null, "summary": "Optimizing Pandas programs is a challenging problem. Existing systems and compiler-based approaches offer reliability but are either heavyweight or support only a limited set of optimizations. Conversely, using LLMs in a per-program optimization methodology can synthesize nontrivial optimizations, but is unreliable, expensive, and offers a low yield. In this work, we introduce a hybrid approach that works in a 3-stage manner that decouples discovery from deployment and connects them via a novel bridge. First, it discovers per-program optimizations (discovery). Second, they are converted into generalised rewrite rules (bridge). Finally, these rules are incorporated into a compiler that can automatically apply them wherever applicable, eliminating repeated reliance on LLMs (deployment). We demonstrate that RuleFlow is the new state-of-the-art (SOTA) Pandas optimization framework on PandasBench, a challenging Pandas benchmark consisting of Python notebooks. Across these notebooks, we achieve a speedup of up to 4.3x over Dias, the previous compiler-based SOTA, and 1914.9x over Modin, the previous systems-based SOTA.\n  Our code is available at https://github.com/ADAPT-uiuc/RuleFlow.", "AI": {"tldr": "RuleFlow\u662f\u4e00\u4e2a\u4e09\u9636\u6bb5\u6df7\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u53d1\u73b0\u7a0b\u5e8f\u7279\u5b9a\u4f18\u5316\u3001\u8f6c\u6362\u4e3a\u901a\u7528\u91cd\u5199\u89c4\u5219\u3001\u96c6\u6210\u5230\u7f16\u8bd1\u5668\u4e2d\uff0c\u5b9e\u73b0Pandas\u7a0b\u5e8f\u4f18\u5316\uff0c\u5728PandasBench\u4e0a\u8fbe\u52304.3\u500d\u52a0\u901f\u3002", "motivation": "\u73b0\u6709Pandas\u4f18\u5316\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u7cfb\u7edf\u65b9\u6cd5\u7b28\u91cd\u4e14\u652f\u6301\u6709\u9650\uff0c\u7f16\u8bd1\u5668\u65b9\u6cd5\u53ef\u9760\u4f46\u4f18\u5316\u8303\u56f4\u6709\u9650\uff0cLLM\u65b9\u6cd5\u80fd\u53d1\u73b0\u975e\u5e73\u51e1\u4f18\u5316\u4f46\u4e0d\u53ef\u9760\u3001\u6602\u8d35\u4e14\u4ea7\u51fa\u7387\u4f4e\u3002\u9700\u8981\u4e00\u79cd\u7ed3\u5408\u53ef\u9760\u6027\u548c\u5e7f\u6cdb\u4f18\u5316\u80fd\u529b\u7684\u65b9\u6cd5\u3002", "method": "RuleFlow\u91c7\u7528\u4e09\u9636\u6bb5\u6df7\u5408\u65b9\u6cd5\uff1a1) \u53d1\u73b0\u9636\u6bb5\uff1a\u4f7f\u7528LLM\u53d1\u73b0\u7a0b\u5e8f\u7279\u5b9a\u4f18\u5316\uff1b2) \u6865\u63a5\u9636\u6bb5\uff1a\u5c06\u53d1\u73b0\u7684\u4f18\u5316\u8f6c\u6362\u4e3a\u901a\u7528\u91cd\u5199\u89c4\u5219\uff1b3) \u90e8\u7f72\u9636\u6bb5\uff1a\u5c06\u89c4\u5219\u96c6\u6210\u5230\u7f16\u8bd1\u5668\u4e2d\uff0c\u81ea\u52a8\u5e94\u7528\u89c4\u5219\uff0c\u907f\u514d\u91cd\u590d\u4f9d\u8d56LLM\u3002", "result": "\u5728PandasBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRuleFlow\u6210\u4e3a\u65b0\u7684SOTA Pandas\u4f18\u5316\u6846\u67b6\uff1a\u76f8\u6bd4\u524d\u7f16\u8bd1\u5668SOTA\uff08Dias\uff09\u52a0\u901f\u8fbe4.3\u500d\uff0c\u76f8\u6bd4\u524d\u7cfb\u7edfSOTA\uff08Modin\uff09\u52a0\u901f\u8fbe1914.9\u500d\u3002", "conclusion": "RuleFlow\u901a\u8fc7\u5c06LLM\u53d1\u73b0\u7684\u4f18\u5316\u8f6c\u6362\u4e3a\u7f16\u8bd1\u5668\u53ef\u7528\u7684\u901a\u7528\u89c4\u5219\uff0c\u5b9e\u73b0\u4e86\u53ef\u9760\u4e14\u5e7f\u6cdb\u7684Pandas\u7a0b\u5e8f\u4f18\u5316\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2602.09263", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.09263", "abs": "https://arxiv.org/abs/2602.09263", "authors": ["Sanket Goutam", "Omar Chowdhury", "Amir Rahmati"], "title": "Atlas: Enabling Cross-Vendor Authentication for IoT", "comment": null, "summary": "Cloud-mediated IoT architectures fragment authentication across vendor silos and create latency and availability bottlenecks for cross-vendor device-to-device (D2D) interactions. We present Atlas, a framework that extends the Web public-key infrastructure to IoT by issuing X.509 certificates to devices via vendor-operated ACME clients and vendor-controlled DNS namespaces. Devices obtain globally verifiable identities without hardware changes and establish mutual TLS channels directly across administrative domains, decoupling runtime authentication from cloud reachability. We prototype Atlas on ESP32 and Raspberry Pi, integrate it with an MQTT-based IoT stack and an Atlas-aware cloud, and evaluate it in smart-home and smart-city workloads. Certificate provisioning completes in under 6s per device, mTLS adds only about 17ms of latency and modest CPU overhead, and Atlas-based applications sustain low, predictable latency compared to cloud-mediated baselines. Because many major vendors already rely on ACME-compatible CAs for their web services, Atlas is immediately deployable with minimal infrastructure changes.", "AI": {"tldr": "Atlas\u6846\u67b6\u901a\u8fc7\u6269\u5c55Web\u516c\u94a5\u57fa\u7840\u8bbe\u65bd\u5230\u7269\u8054\u7f51\uff0c\u4e3a\u8bbe\u5907\u9881\u53d1X.509\u8bc1\u4e66\uff0c\u4f7f\u8bbe\u5907\u80fd\u591f\u76f4\u63a5\u5efa\u7acb\u8de8\u57dfmTLS\u901a\u9053\uff0c\u51cf\u5c11\u5bf9\u4e91\u670d\u52a1\u7684\u4f9d\u8d56\uff0c\u964d\u4f4e\u5ef6\u8fdf\u3002", "motivation": "\u5f53\u524d\u4e91\u4e2d\u4ecb\u7684\u7269\u8054\u7f51\u67b6\u6784\u5b58\u5728\u8ba4\u8bc1\u788e\u7247\u5316\u95ee\u9898\uff0c\u8de8\u4f9b\u5e94\u5546\u8bbe\u5907\u95f4\u4ea4\u4e92\u5b58\u5728\u5ef6\u8fdf\u548c\u53ef\u7528\u6027\u74f6\u9888\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5b9e\u73b0\u8bbe\u5907\u95f4\u76f4\u63a5\u5b89\u5168\u901a\u4fe1\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "Atlas\u6846\u67b6\u6269\u5c55Web PKI\u5230\u7269\u8054\u7f51\uff0c\u901a\u8fc7\u4f9b\u5e94\u5546\u64cd\u4f5c\u7684ACME\u5ba2\u6237\u7aef\u548cDNS\u547d\u540d\u7a7a\u95f4\u4e3a\u8bbe\u5907\u9881\u53d1X.509\u8bc1\u4e66\uff0c\u4f7f\u8bbe\u5907\u83b7\u5f97\u5168\u5c40\u53ef\u9a8c\u8bc1\u8eab\u4efd\uff0c\u5e76\u5efa\u7acb\u8de8\u7ba1\u7406\u57df\u7684\u76f8\u4e92TLS\u901a\u9053\u3002", "result": "\u8bc1\u4e66\u914d\u7f6e\u6bcf\u8bbe\u5907\u57286\u79d2\u5185\u5b8c\u6210\uff0cmTLS\u4ec5\u589e\u52a0\u7ea617ms\u5ef6\u8fdf\u548c\u9002\u5ea6CPU\u5f00\u9500\uff0c\u76f8\u6bd4\u4e91\u4e2d\u4ecb\u57fa\u51c6\uff0cAtlas\u5e94\u7528\u80fd\u591f\u7ef4\u6301\u66f4\u4f4e\u3001\u66f4\u53ef\u9884\u6d4b\u7684\u5ef6\u8fdf\u3002", "conclusion": "Atlas\u6846\u67b6\u80fd\u591f\u7acb\u5373\u90e8\u7f72\uff0c\u56e0\u4e3a\u8bb8\u591a\u4e3b\u8981\u4f9b\u5e94\u5546\u5df2\u7ecf\u5728Web\u670d\u52a1\u4e2d\u4f7f\u7528ACME\u517c\u5bb9\u7684CA\uff0c\u53ea\u9700\u6700\u5c0f\u57fa\u7840\u8bbe\u65bd\u53d8\u66f4\u5373\u53ef\u5b9e\u73b0\u8bbe\u5907\u95f4\u76f4\u63a5\u5b89\u5168\u901a\u4fe1\u3002"}}
{"id": "2602.09064", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.09064", "abs": "https://arxiv.org/abs/2602.09064", "authors": ["S M Rakib Ul Karim", "Wenyi Lu", "Enock Kasaadha", "Sean Goggins"], "title": "Predicting Open Source Software Sustainability with Deep Temporal Neural Hierarchical Architectures and Explainable AI", "comment": null, "summary": "Open Source Software (OSS) projects follow diverse lifecycle trajectories shaped by evolving patterns of contribution, coordination, and community engagement. Understanding these trajectories is essential for stakeholders seeking to assess project organization and health at scale. However, prior work has largely relied on static or aggregated metrics, such as project age or cumulative activity, providing limited insight into how OSS sustainability unfolds over time. In this paper, we propose a hierarchical predictive framework that models OSS projects as belonging to distinct lifecycle stages grounded in established socio-technical categorizations of OSS development. Rather than treating sustainability solely as project longevity, these lifecycle stages operationalize sustainability as a multidimensional construct integrating contribution activity, community participation, and maintenance dynamics. The framework combines engineered tabular indicators with 24-month temporal activity sequences and employs a multi-stage classification pipeline to distinguish lifecycle stages associated with different coordination and participation regimes. To support transparency, we incorporate explainable AI techniques to examine the relative contribution of feature categories to model predictions. Evaluated on a large corpus of OSS repositories, the proposed approach achieves over 94\\% overall accuracy in lifecycle stage classification. Attribution analyses consistently identify contribution activity and community-related features as dominant signals, highlighting the central role of collective participation dynamics.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5206\u5c42\u9884\u6d4b\u6846\u67b6\uff0c\u5c06\u5f00\u6e90\u8f6f\u4ef6\u9879\u76ee\u5efa\u6a21\u4e3a\u57fa\u4e8e\u793e\u4f1a\u6280\u672f\u5206\u7c7b\u7684\u4e0d\u540c\u751f\u547d\u5468\u671f\u9636\u6bb5\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u5206\u7c7b\u7ba1\u9053\u5b9e\u73b094%\u51c6\u786e\u7387\u7684\u9636\u6bb5\u5206\u7c7b\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u4f9d\u8d56\u9759\u6001\u6216\u805a\u5408\u6307\u6807\uff08\u5982\u9879\u76ee\u5e74\u9f84\u6216\u7d2f\u8ba1\u6d3b\u52a8\uff09\uff0c\u5bf9\u5f00\u6e90\u8f6f\u4ef6\u53ef\u6301\u7eed\u6027\u968f\u65f6\u95f4\u6f14\u53d8\u7684\u7406\u89e3\u6709\u9650\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6355\u6349\u9879\u76ee\u751f\u547d\u5468\u671f\u8f68\u8ff9\u52a8\u6001\u53d8\u5316\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u9884\u6d4b\u6846\u67b6\uff0c\u5c06\u5f00\u6e90\u9879\u76ee\u5efa\u6a21\u4e3a\u57fa\u4e8e\u793e\u4f1a\u6280\u672f\u5206\u7c7b\u7684\u751f\u547d\u5468\u671f\u9636\u6bb5\u3002\u6846\u67b6\u7ed3\u5408\u5de5\u7a0b\u5316\u8868\u683c\u6307\u6807\u548c24\u4e2a\u6708\u65f6\u95f4\u6d3b\u52a8\u5e8f\u5217\uff0c\u91c7\u7528\u591a\u9636\u6bb5\u5206\u7c7b\u7ba1\u9053\u533a\u5206\u4e0d\u540c\u534f\u8c03\u548c\u53c2\u4e0e\u673a\u5236\u7684\u751f\u547d\u5468\u671f\u9636\u6bb5\uff0c\u5e76\u6574\u5408\u53ef\u89e3\u91caAI\u6280\u672f\u5206\u6790\u7279\u5f81\u8d21\u732e\u3002", "result": "\u5728\u5927\u89c4\u6a21\u5f00\u6e90\u4ed3\u5e93\u8bed\u6599\u5e93\u4e0a\u8bc4\u4f30\uff0c\u8be5\u65b9\u6cd5\u5728\u751f\u547d\u5468\u671f\u9636\u6bb5\u5206\u7c7b\u4e2d\u8fbe\u5230\u8d85\u8fc794%\u7684\u6574\u4f53\u51c6\u786e\u7387\u3002\u5f52\u56e0\u5206\u6790\u4e00\u81f4\u8bc6\u522b\u8d21\u732e\u6d3b\u52a8\u548c\u793e\u533a\u76f8\u5173\u7279\u5f81\u4e3a\u4e3b\u5bfc\u4fe1\u53f7\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u5efa\u6a21\u5f00\u6e90\u9879\u76ee\u7684\u751f\u547d\u5468\u671f\u8f68\u8ff9\uff0c\u5f3a\u8c03\u96c6\u4f53\u53c2\u4e0e\u52a8\u6001\u5728\u9879\u76ee\u53ef\u6301\u7eed\u6027\u4e2d\u7684\u6838\u5fc3\u4f5c\u7528\uff0c\u4e3a\u5927\u89c4\u6a21\u8bc4\u4f30\u9879\u76ee\u7ec4\u7ec7\u548c\u5065\u5eb7\u72b6\u51b5\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2602.09319", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.09319", "abs": "https://arxiv.org/abs/2602.09319", "authors": ["Zhisheng Qi", "Utkarsh Sahu", "Li Ma", "Haoyu Han", "Ryan Rossi", "Franck Dernoncourt", "Mahantesh Halappanavar", "Nesreen Ahmed", "Yushun Dong", "Yue Zhao", "Yu Zhang", "Yu Wang"], "title": "Benchmarking Knowledge-Extraction Attack and Defense on Retrieval-Augmented Generation", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) has become a cornerstone of knowledge-intensive applications, including enterprise chatbots, healthcare assistants, and agentic memory management. However, recent studies show that knowledge-extraction attacks can recover sensitive knowledge-base content through maliciously crafted queries, raising serious concerns about intellectual property theft and privacy leakage. While prior work has explored individual attack and defense techniques, the research landscape remains fragmented, spanning heterogeneous retrieval embeddings, diverse generation models, and evaluations based on non-standardized metrics and inconsistent datasets. To address this gap, we introduce the first systematic benchmark for knowledge-extraction attacks on RAG systems. Our benchmark covers a broad spectrum of attack and defense strategies, representative retrieval embedding models, and both open- and closed-source generators, all evaluated under a unified experimental framework with standardized protocols across multiple datasets. By consolidating the experimental landscape and enabling reproducible, comparable evaluation, this benchmark provides actionable insights and a practical foundation for developing privacy-preserving RAG systems in the face of emerging knowledge extraction threats. Our code is available here.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u9488\u5bf9RAG\u7cfb\u7edf\u77e5\u8bc6\u63d0\u53d6\u653b\u51fb\u7684\u7cfb\u7edf\u6027\u57fa\u51c6\u6d4b\u8bd5\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u7814\u7a76\u5728\u653b\u51fb\u9632\u5fa1\u6280\u672f\u3001\u68c0\u7d22\u5d4c\u5165\u6a21\u578b\u548c\u8bc4\u4f30\u6307\u6807\u65b9\u9762\u7684\u788e\u7247\u5316\u95ee\u9898\u3002", "motivation": "RAG\u7cfb\u7edf\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u5e94\u7528\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u7814\u7a76\u8868\u660e\u6076\u610f\u67e5\u8be2\u53ef\u63d0\u53d6\u654f\u611f\u77e5\u8bc6\u5e93\u5185\u5bb9\uff0c\u5f15\u53d1\u77e5\u8bc6\u4ea7\u6743\u548c\u9690\u79c1\u6cc4\u9732\u62c5\u5fe7\u3002\u73b0\u6709\u7814\u7a76\u5b58\u5728\u788e\u7247\u5316\u95ee\u9898\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u6784\u5efa\u4e86\u9996\u4e2a\u7cfb\u7edf\u6027\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6\u5e7f\u6cdb\u7684\u653b\u51fb\u9632\u5fa1\u7b56\u7565\u3001\u4ee3\u8868\u6027\u68c0\u7d22\u5d4c\u5165\u6a21\u578b\u3001\u5f00\u6e90\u548c\u95ed\u6e90\u751f\u6210\u5668\uff0c\u5728\u7edf\u4e00\u5b9e\u9a8c\u6846\u67b6\u4e0b\u4f7f\u7528\u6807\u51c6\u5316\u534f\u8bae\u548c\u591a\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u901a\u8fc7\u6574\u5408\u5b9e\u9a8c\u73af\u5883\u5e76\u5b9e\u73b0\u53ef\u91cd\u590d\u3001\u53ef\u6bd4\u8f83\u7684\u8bc4\u4f30\uff0c\u8be5\u57fa\u51c6\u6d4b\u8bd5\u4e3a\u5f00\u53d1\u9690\u79c1\u4fdd\u62a4\u7684RAG\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u57fa\u7840\uff0c\u80fd\u591f\u5e94\u5bf9\u65b0\u5174\u7684\u77e5\u8bc6\u63d0\u53d6\u5a01\u80c1\u3002", "conclusion": "\u8be5\u57fa\u51c6\u6d4b\u8bd5\u586b\u8865\u4e86RAG\u7cfb\u7edf\u5b89\u5168\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u4e3a\u7814\u7a76\u548c\u5f00\u53d1\u9690\u79c1\u4fdd\u62a4\u7684RAG\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u8bc4\u4f30\u6846\u67b6\u548c\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2602.09138", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.09138", "abs": "https://arxiv.org/abs/2602.09138", "authors": ["Haitao Jiang", "Lin Ge", "Hengrui Cai", "Rui Song"], "title": "PABU: Progress-Aware Belief Update for Efficient LLM Agents", "comment": null, "summary": "Large Language Model (LLM) agents commonly condition actions on full action-observation histories, which introduce task-irrelevant information that easily leads to redundant actions and higher inference cost. We propose Progress-Aware Belief Update (PABU), a belief-state framework that compactly represents an agent's state by explicitly modeling task progress and selectively retaining past actions and observations. At each step, the agent predicts its relative progress since the previous round and decides whether the newly encountered interaction should be stored, conditioning future decisions only on the retained subset. Across eight environments in the AgentGym benchmark, and using identical training trajectories, PABU achieves an 81.0% task completion rate, outperforming previous State of the art (SoTA) models with full-history belief by 23.9%. Additionally, PABU's progress-oriented action selection improves efficiency, reducing the average number of interaction steps to 9.5, corresponding to a 26.9% reduction. Ablation studies show that both explicit progress prediction and selective retention are necessary for robust belief learning and performance gains.", "AI": {"tldr": "PABU\u6846\u67b6\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u4efb\u52a1\u8fdb\u5ea6\u548c\u9009\u62e9\u6027\u4fdd\u7559\u5386\u53f2\u4fe1\u606f\uff0c\u51cf\u5c11LLM\u667a\u80fd\u4f53\u4e2d\u7684\u5197\u4f59\u52a8\u4f5c\u548c\u63a8\u7406\u6210\u672c", "motivation": "\u5f53\u524dLLM\u667a\u80fd\u4f53\u901a\u5e38\u57fa\u4e8e\u5b8c\u6574\u7684\u52a8\u4f5c-\u89c2\u5bdf\u5386\u53f2\u6765\u51b3\u7b56\uff0c\u8fd9\u5f15\u5165\u4e86\u4efb\u52a1\u65e0\u5173\u4fe1\u606f\uff0c\u5bfc\u81f4\u5197\u4f59\u52a8\u4f5c\u548c\u66f4\u9ad8\u7684\u63a8\u7406\u6210\u672c", "method": "\u63d0\u51faProgress-Aware Belief Update (PABU)\u6846\u67b6\uff0c\u901a\u8fc7\u9884\u6d4b\u76f8\u5bf9\u8fdb\u5ea6\u5e76\u9009\u62e9\u6027\u4fdd\u7559\u5173\u952e\u4ea4\u4e92\u4fe1\u606f\u6765\u7d27\u51d1\u8868\u793a\u667a\u80fd\u4f53\u72b6\u6001", "result": "\u5728AgentGym\u57fa\u51c6\u76848\u4e2a\u73af\u5883\u4e2d\uff0cPABU\u8fbe\u523081.0%\u7684\u4efb\u52a1\u5b8c\u6210\u7387\uff0c\u6bd4\u57fa\u4e8e\u5b8c\u6574\u5386\u53f2\u7684SoTA\u6a21\u578b\u63d0\u534723.9%\uff0c\u4ea4\u4e92\u6b65\u9aa4\u51cf\u5c1126.9%\u81f3\u5e73\u57479.5\u6b65", "conclusion": "PABU\u901a\u8fc7\u663e\u5f0f\u8fdb\u5ea6\u9884\u6d4b\u548c\u9009\u62e9\u6027\u4fdd\u7559\u673a\u5236\uff0c\u6709\u6548\u63d0\u5347\u4e86LLM\u667a\u80fd\u4f53\u7684\u6548\u7387\u548c\u6027\u80fd\uff0c\u4e24\u8005\u90fd\u662f\u5b9e\u73b0\u7a33\u5065\u4fe1\u5ff5\u5b66\u4e60\u548c\u6027\u80fd\u63d0\u5347\u7684\u5fc5\u8981\u7ec4\u4ef6"}}
{"id": "2602.09071", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.09071", "abs": "https://arxiv.org/abs/2602.09071", "authors": ["Stefano Balla", "Stefano Zacchiroli", "Thomas Degueule", "Jean-R\u00e9my Falleri", "Romain Robbes"], "title": "DRAGON: Robust Classification for Very Large Collections of Software Repositories", "comment": null, "summary": "The ability to automatically classify source code repositories with ''topics'' that reflect their content and purpose is very useful, especially when navigating or searching through large software collections. However, existing approaches often rely heavily on README files and other metadata, which are frequently missing, limiting their applicability in real-world large-scale settings. We present DRAGON, a repository classifier designed for very large and diverse software collections. It operates entirely on lightweight signals commonly stored in version control systems: file and directory names, and optionally the README when available. In repository classification at scale, DRAGON improves F1@5 from 54.8% to 60.8%, surpassing the state of the art. DRAGON remains effective even when README files are absent, with performance degrading by only 6% w.r.t. when they are present. This robustness makes it practical for real-world settings where documentation is sparse or inconsistent. Furthermore, many of the remaining classification errors are near misses, where predicted labels are semantically close to the correct topics. This property increases the practical value of the predictions in real-world software collections, where suggesting a few related topics can still guide search and discovery. As a byproduct of developing DRAGON, we also release the largest open dataset to date for repository classification, consisting of 825 thousand repositories with associated ground-truth topics, sourced from the Software Heritage archive, providing a foundation for future large-scale and language-agnostic research on software repository understanding.", "AI": {"tldr": "DRAGON\u662f\u4e00\u4e2a\u57fa\u4e8e\u8f7b\u91cf\u7ea7\u4fe1\u53f7\uff08\u6587\u4ef6\u548c\u76ee\u5f55\u540d\u79f0\uff0c\u53ef\u9009README\uff09\u7684\u4ee3\u7801\u4ed3\u5e93\u5206\u7c7b\u5668\uff0c\u5728\u5927\u89c4\u6a21\u8f6f\u4ef6\u96c6\u5408\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5373\u4f7fREADME\u7f3a\u5931\u4e5f\u80fd\u4fdd\u6301\u826f\u597d\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u4ed3\u5e93\u5206\u7c7b\u65b9\u6cd5\u8fc7\u5ea6\u4f9d\u8d56README\u7b49\u5143\u6570\u636e\uff0c\u4f46\u8fd9\u4e9b\u6587\u4ef6\u7ecf\u5e38\u7f3a\u5931\uff0c\u9650\u5236\u4e86\u5728\u5927\u89c4\u6a21\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528\u3002\u9700\u8981\u4e00\u79cd\u66f4\u7a33\u5065\u7684\u5206\u7c7b\u65b9\u6cd5\u3002", "method": "DRAGON\u5b8c\u5168\u57fa\u4e8e\u7248\u672c\u63a7\u5236\u7cfb\u7edf\u4e2d\u5e38\u89c1\u7684\u8f7b\u91cf\u7ea7\u4fe1\u53f7\uff1a\u6587\u4ef6\u548c\u76ee\u5f55\u540d\u79f0\uff0c\u4ee5\u53ca\u53ef\u9009\u7684README\u6587\u4ef6\uff08\u5f53\u53ef\u7528\u65f6\uff09\u3002\u8be5\u65b9\u6cd5\u8bbe\u8ba1\u7528\u4e8e\u5904\u7406\u5927\u89c4\u6a21\u548c\u591a\u6837\u5316\u7684\u8f6f\u4ef6\u96c6\u5408\u3002", "result": "\u5728\u5927\u89c4\u6a21\u4ed3\u5e93\u5206\u7c7b\u4e2d\uff0cDRAGON\u5c06F1@5\u4ece54.8%\u63d0\u5347\u523060.8%\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u6280\u672f\u3002\u5373\u4f7fREADME\u7f3a\u5931\uff0c\u6027\u80fd\u4ec5\u4e0b\u964d6%\u3002\u8bb8\u591a\u5206\u7c7b\u9519\u8bef\u662f\u8bed\u4e49\u76f8\u8fd1\u7684\"\u8fd1\u5931\"\uff0c\u589e\u52a0\u4e86\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "DRAGON\u63d0\u4f9b\u4e86\u4e00\u79cd\u7a33\u5065\u3001\u53ef\u6269\u5c55\u7684\u4ee3\u7801\u4ed3\u5e93\u5206\u7c7b\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u6587\u6863\u7a00\u758f\u6216\u4e0d\u4e00\u81f4\u7684\u771f\u5b9e\u573a\u666f\u3002\u7814\u7a76\u8fd8\u53d1\u5e03\u4e86\u8fc4\u4eca\u4e3a\u6b62\u6700\u5927\u7684\u5f00\u6e90\u4ed3\u5e93\u5206\u7c7b\u6570\u636e\u96c6\uff0882.5\u4e07\u4e2a\u4ed3\u5e93\uff09\uff0c\u4e3a\u672a\u6765\u5927\u89c4\u6a21\u3001\u8bed\u8a00\u65e0\u5173\u7684\u8f6f\u4ef6\u4ed3\u5e93\u7406\u89e3\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2602.09159", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.09159", "abs": "https://arxiv.org/abs/2602.09159", "authors": ["Yichen Wu", "Yujin Oh", "Sangjoon Park", "Kailong Fan", "Dania Daye", "Hana Farzaneh", "Xiang Li", "Raul Uppot", "Quanzheng Li"], "title": "CoMMa: Contribution-Aware Medical Multi-Agents From A Game-Theoretic Perspective", "comment": "9 pages, 3 figures", "summary": "Recent multi-agent frameworks have broadened the ability to tackle oncology decision support tasks that require reasoning over dynamic, heterogeneous patient data. We propose Contribution-Aware Medical Multi-Agents (CoMMa), a decentralized LLM-agent framework in which specialists operate on partitioned evidence and coordinate through a game-theoretic objective for robust decision-making. In contrast to most agent architectures relying on stochastic narrative-based reasoning, CoMMa utilizes deterministic embedding projections to approximate contribution-aware credit assignment. This yields explicit evidence attribution by estimating each agent's marginal utility, producing interpretable and mathematically grounded decision pathways with improved stability. Evaluated on diverse oncology benchmarks, including a real-world multidisciplinary tumor board dataset, CoMMa achieves higher accuracy and more stable performance than data-centralized and role-based multi-agents baselines.", "AI": {"tldr": "CoMMa\u662f\u4e00\u4e2a\u53bb\u4e2d\u5fc3\u5316\u7684\u533b\u7597\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u535a\u5f08\u8bba\u76ee\u6807\u548c\u786e\u5b9a\u6027\u5d4c\u5165\u6295\u5f71\u5b9e\u73b0\u8d21\u732e\u611f\u77e5\u7684\u4fe1\u7528\u5206\u914d\uff0c\u5728\u80bf\u7624\u5b66\u51b3\u7b56\u652f\u6301\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u533b\u7597\u591a\u667a\u80fd\u4f53\u6846\u67b6\u5728\u5904\u7406\u9700\u8981\u52a8\u6001\u3001\u5f02\u6784\u60a3\u8005\u6570\u636e\u63a8\u7406\u7684\u80bf\u7624\u5b66\u51b3\u7b56\u652f\u6301\u4efb\u52a1\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5927\u591a\u6570\u57fa\u4e8e\u968f\u673a\u53d9\u4e8b\u63a8\u7406\u7684\u67b6\u6784\u7f3a\u4e4f\u660e\u786e\u7684\u8bc1\u636e\u5f52\u56e0\u548c\u7a33\u5b9a\u6027\u3002", "method": "\u63d0\u51faCoMMa\u6846\u67b6\uff1a1) \u53bb\u4e2d\u5fc3\u5316LLM\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u4e13\u5bb6\u5728\u5206\u533a\u8bc1\u636e\u4e0a\u64cd\u4f5c\uff1b2) \u901a\u8fc7\u535a\u5f08\u8bba\u76ee\u6807\u8fdb\u884c\u534f\u8c03\uff1b3) \u4f7f\u7528\u786e\u5b9a\u6027\u5d4c\u5165\u6295\u5f71\u8fd1\u4f3c\u8d21\u732e\u611f\u77e5\u4fe1\u7528\u5206\u914d\uff1b4) \u901a\u8fc7\u4f30\u8ba1\u6bcf\u4e2a\u667a\u80fd\u4f53\u7684\u8fb9\u9645\u6548\u7528\u5b9e\u73b0\u660e\u786e\u7684\u8bc1\u636e\u5f52\u56e0\u3002", "result": "\u5728\u591a\u6837\u5316\u7684\u80bf\u7624\u5b66\u57fa\u51c6\u6d4b\u8bd5\uff08\u5305\u62ec\u771f\u5b9e\u4e16\u754c\u591a\u5b66\u79d1\u80bf\u7624\u59d4\u5458\u4f1a\u6570\u636e\u96c6\uff09\u4e0a\uff0cCoMMa\u76f8\u6bd4\u6570\u636e\u96c6\u4e2d\u5316\u548c\u57fa\u4e8e\u89d2\u8272\u7684\u591a\u667a\u80fd\u4f53\u57fa\u7ebf\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u66f4\u7a33\u5b9a\u7684\u6027\u80fd\u3002", "conclusion": "CoMMa\u901a\u8fc7\u8d21\u732e\u611f\u77e5\u7684\u4fe1\u7528\u5206\u914d\u673a\u5236\uff0c\u4e3a\u533b\u7597\u51b3\u7b56\u652f\u6301\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u3001\u6570\u5b66\u57fa\u7840\u624e\u5b9e\u4e14\u7a33\u5b9a\u7684\u51b3\u7b56\u8def\u5f84\uff0c\u5728\u80bf\u7624\u5b66\u591a\u667a\u80fd\u4f53\u51b3\u7b56\u4e2d\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u3002"}}
{"id": "2602.09338", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.09338", "abs": "https://arxiv.org/abs/2602.09338", "authors": ["Andy Dong", "Arun Ganesh"], "title": "Privacy Amplification for BandMF via $b$-Min-Sep Subsampling", "comment": null, "summary": "We study privacy amplification for BandMF, i.e., DP-SGD with correlated noise across iterations via a banded correlation matrix. We propose $b$-min-sep subsampling, a new subsampling scheme that generalizes Poisson and balls-in-bins subsampling, extends prior practical batching strategies for BandMF, and enables stronger privacy amplification than cyclic Poisson while preserving the structural properties needed for analysis. We give a near-exact privacy analysis using Monte Carlo accounting, based on a dynamic program that leverages the Markovian structure in the subsampling procedure. We show that $b$-min-sep matches cyclic Poisson subsampling in the high noise regime and achieves strictly better guarantees in the mid-to-low noise regime, with experimental results that bolster our claims. We further show that unlike previous BandMF subsampling schemes, our $b$-min-sep subsampling naturally extends to the multi-attribution user-level privacy setting.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86BandMF\uff08\u4f7f\u7528\u5e26\u76f8\u5173\u566a\u58f0\u7684DP-SGD\uff09\u7684\u9690\u79c1\u653e\u5927\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684b-min-sep\u5b50\u91c7\u6837\u65b9\u6848\uff0c\u8be5\u65b9\u6848\u4f18\u4e8e\u73b0\u6709\u7684\u5faa\u73af\u6cca\u677e\u91c7\u6837\uff0c\u5e76\u5728\u591a\u5f52\u5c5e\u7528\u6237\u7ea7\u9690\u79c1\u8bbe\u7f6e\u4e2d\u5177\u6709\u5929\u7136\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709\u7684BandMF\u9690\u79c1\u653e\u5927\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u5b50\u91c7\u6837\u7b56\u7565\u65b9\u9762\u3002\u5faa\u73af\u6cca\u677e\u91c7\u6837\u867d\u7136\u5b9e\u7528\uff0c\u4f46\u5728\u9690\u79c1\u653e\u5927\u6548\u679c\u4e0a\u4e0d\u591f\u7406\u60f3\uff0c\u4e14\u73b0\u6709\u7684\u5b50\u91c7\u6837\u65b9\u6848\u96be\u4ee5\u6269\u5c55\u5230\u591a\u5f52\u5c5e\u7528\u6237\u7ea7\u9690\u79c1\u8bbe\u7f6e\u3002", "method": "\u63d0\u51fa\u4e86b-min-sep\u5b50\u91c7\u6837\u65b9\u6848\uff0c\u8fd9\u662f\u5bf9\u6cca\u677e\u91c7\u6837\u548cballs-in-bins\u91c7\u6837\u7684\u6cdb\u5316\uff0c\u6269\u5c55\u4e86BandMF\u7684\u5b9e\u7528\u6279\u5904\u7406\u7b56\u7565\u3002\u4f7f\u7528\u57fa\u4e8e\u52a8\u6001\u89c4\u5212\u7684\u8499\u7279\u5361\u6d1b\u9690\u79c1\u5206\u6790\u65b9\u6cd5\uff0c\u5229\u7528\u4e86\u5b50\u91c7\u6837\u8fc7\u7a0b\u4e2d\u7684\u9a6c\u5c14\u53ef\u592b\u7ed3\u6784\u3002", "result": "\u5728\u9ad8\u566a\u58f0\u533a\u57df\uff0cb-min-sep\u4e0e\u5faa\u73af\u6cca\u677e\u91c7\u6837\u6548\u679c\u76f8\u5f53\uff1b\u5728\u4e2d\u4f4e\u566a\u58f0\u533a\u57df\uff0cb-min-sep\u63d0\u4f9b\u4e25\u683c\u66f4\u597d\u7684\u9690\u79c1\u4fdd\u8bc1\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u4e14\u8be5\u65b9\u6848\u80fd\u81ea\u7136\u5730\u6269\u5c55\u5230\u591a\u5f52\u5c5e\u7528\u6237\u7ea7\u9690\u79c1\u8bbe\u7f6e\u3002", "conclusion": "b-min-sep\u5b50\u91c7\u6837\u65b9\u6848\u4e3aBandMF\u63d0\u4f9b\u4e86\u66f4\u5f3a\u7684\u9690\u79c1\u653e\u5927\u6548\u679c\uff0c\u7279\u522b\u662f\u5728\u4e2d\u4f4e\u566a\u58f0\u533a\u57df\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5206\u6790\u6240\u9700\u7684\u7ed3\u6784\u7279\u6027\uff0c\u5e76\u80fd\u591f\u6269\u5c55\u5230\u66f4\u590d\u6742\u7684\u9690\u79c1\u8bbe\u7f6e\u4e2d\u3002"}}
{"id": "2602.09292", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.09292", "abs": "https://arxiv.org/abs/2602.09292", "authors": ["Ana B. M. Bett", "Thais S. Nepomuceno", "Edson OliveiraJr", "Maria Teresa Baldassarre", "Valdemar V. Graciano Neto", "Marcos Kalinowski"], "title": "Towards an OSF-based Registered Report Template for Software Engineering Controlled Experiments", "comment": "Author version of paper accepted at the 3rd International Workshop on Methodological Issues with Empirical Studies in Software Engineering (WSESE@ICSE 2026)", "summary": "Context: The empirical software engineering (ESE) community has contributed to improving experimentation over the years. However, there is still a lack of rigor in describing controlled experiments, hindering reproducibility and transparency. Registered Reports (RR) have been discussed in the ESE community to address these issues. A RR registers a study's hypotheses, methods, and/or analyses before execution, involving peer review and potential acceptance before data collection. This helps mitigate problematic practices such as p-hacking, publication bias, and inappropriate post hoc analysis. Objective: This paper presents initial results toward establishing an RR template for Software Engineering controlled experiments using the Open Science Framework (OSF). Method: We analyzed templates of selected OSF RR types in light of documentation guidelines for controlled experiments. Results: The observed lack of rigor motivated our investigation of OSF-based RR types. Our analysis showed that, although one of the RR types aligned with many of the documentation suggestions contained in the guidelines, none of them covered the guidelines comprehensively. The study also highlights limitations in OSF RR template customization. Conclusion: Despite progress in ESE, planning and documenting experiments still lack rigor, compromising reproducibility. Adopting OSF-based RRs is proposed. However, no currently available RR type fully satisfies the guidelines. Establishing RR-specific guidelines for SE is deemed essential.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u5728\u8f6f\u4ef6\u5de5\u7a0b\u63a7\u5236\u5b9e\u9a8c\u4e2d\u91c7\u7528\u6ce8\u518c\u62a5\u544a\uff08RR\uff09\u6a21\u677f\u7684\u73b0\u72b6\uff0c\u53d1\u73b0\u73b0\u6709OSF\u6a21\u677f\u65e0\u6cd5\u5b8c\u5168\u6ee1\u8db3SE\u5b9e\u9a8c\u6587\u6863\u6307\u5357\u8981\u6c42\uff0c\u5efa\u8bae\u5efa\u7acb\u4e13\u95e8\u7684SE\u6ce8\u518c\u62a5\u544a\u6307\u5357\u3002", "motivation": "\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8bc1\u7814\u7a76\u793e\u533a\u867d\u7136\u6539\u8fdb\u4e86\u5b9e\u9a8c\u65b9\u6cd5\uff0c\u4f46\u63a7\u5236\u5b9e\u9a8c\u7684\u63cf\u8ff0\u4ecd\u7f3a\u4e4f\u4e25\u8c28\u6027\uff0c\u5f71\u54cd\u4e86\u53ef\u91cd\u590d\u6027\u548c\u900f\u660e\u5ea6\u3002\u6ce8\u518c\u62a5\u544a\uff08RR\uff09\u4f5c\u4e3a\u4e00\u79cd\u89e3\u51b3\u65b9\u6848\u88ab\u8ba8\u8bba\uff0c\u4f46\u9700\u8981\u9002\u5408\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u9a8c\u7684\u6a21\u677f\u3002", "method": "\u5206\u6790Open Science Framework\uff08OSF\uff09\u4e0a\u9009\u5b9a\u7684\u6ce8\u518c\u62a5\u544a\u7c7b\u578b\u6a21\u677f\uff0c\u5bf9\u7167\u8f6f\u4ef6\u5de5\u7a0b\u63a7\u5236\u5b9e\u9a8c\u7684\u6587\u6863\u6307\u5357\u8fdb\u884c\u8bc4\u4f30\uff0c\u8003\u5bdf\u6a21\u677f\u4e0e\u6307\u5357\u7684\u5339\u914d\u7a0b\u5ea6\u3002", "result": "\u5206\u6790\u53d1\u73b0\uff0c\u5c3d\u7ba1\u6709\u4e00\u4e2aRR\u7c7b\u578b\u4e0e\u8bb8\u591a\u6587\u6863\u5efa\u8bae\u76f8\u7b26\uff0c\u4f46\u6ca1\u6709\u4e00\u4e2a\u6a21\u677f\u80fd\u5168\u9762\u8986\u76d6\u6307\u5357\u8981\u6c42\u3002\u7814\u7a76\u8fd8\u63ed\u793a\u4e86OSF RR\u6a21\u677f\u5b9a\u5236\u5316\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u5c3d\u7ba1\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8bc1\u7814\u7a76\u6709\u8fdb\u6b65\uff0c\u4f46\u5b9e\u9a8c\u89c4\u5212\u548c\u6587\u6863\u4ecd\u7f3a\u4e4f\u4e25\u8c28\u6027\uff0c\u635f\u5bb3\u4e86\u53ef\u91cd\u590d\u6027\u3002\u5efa\u8bae\u91c7\u7528\u57fa\u4e8eOSF\u7684\u6ce8\u518c\u62a5\u544a\uff0c\u4f46\u76ee\u524d\u6ca1\u6709\u53ef\u7528\u7684RR\u7c7b\u578b\u5b8c\u5168\u6ee1\u8db3\u6307\u5357\u8981\u6c42\uff0c\u5efa\u7acb\u8f6f\u4ef6\u5de5\u7a0b\u7279\u5b9a\u7684\u6ce8\u518c\u62a5\u544a\u6307\u5357\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2602.09369", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.09369", "abs": "https://arxiv.org/abs/2602.09369", "authors": ["Saleh K. Monfared", "Fatemeh Ganji", "Dan Holcomb", "Shahin Tajik"], "title": "Timing and Memory Telemetry on GPUs for AI Governance", "comment": null, "summary": "The rapid expansion of GPU-accelerated computing has enabled major advances in large-scale artificial intelligence (AI), while heightening concerns about how accelerators are observed or governed once deployed. Governance is essential to ensure that large-scale compute infrastructure is not silently repurposed for training models, circumventing usage policies, or operating outside legal oversight. Because current GPUs expose limited trusted telemetry and can be modified or virtualized by adversaries, we explore whether compute-based measurements can provide actionable signals of utilization when host and device are untrusted. We introduce a measurement framework that leverages architectural characteristics of modern GPUs to generate timing- and memory-based observables that correlate with compute activity. Our design draws on four complementary primitives: (1) a probabilistic, workload-driven mechanism inspired by Proof-of-Work (PoW) to expose parallel effort, (2) sequential, latency-sensitive workloads derived via Verifiable Delay Functions (VDFs) to characterize scalar execution pressure, (3) General Matrix Multiplication (GEMM)-based tensor-core measurements that reflect dense linear-algebra throughput, and (4) a VRAM-residency test that distinguishes on-device memory locality from off-chip access through bandwidth-dependent hashing. These primitives provide statistical and behavioral indicators of GPU engagement that remain observable even without trusted firmware, enclaves, or vendor-controlled counters. We evaluate their responses to contention, architectural alignment, memory pressure, and power overhead, showing that timing shifts and residency latencies reveal meaningful utilization patterns. Our results illustrate why compute-based telemetry can complement future accountability mechanisms by exposing architectural signals relevant to post-deployment GPU governance.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eGPU\u67b6\u6784\u7279\u6027\u7684\u8ba1\u7b97\u6d3b\u52a8\u6d4b\u91cf\u6846\u67b6\uff0c\u901a\u8fc7\u56db\u79cd\u4e92\u8865\u539f\u8bed\u751f\u6210\u53ef\u89c2\u6d4b\u4fe1\u53f7\uff0c\u7528\u4e8eGPU\u90e8\u7f72\u540e\u7684\u6cbb\u7406\u548c\u95ee\u8d23", "motivation": "GPU\u52a0\u901f\u8ba1\u7b97\u7684\u5feb\u901f\u53d1\u5c55\u63a8\u52a8\u4e86\u5927\u89c4\u6a21AI\u8fdb\u6b65\uff0c\u4f46\u4e5f\u5f15\u53d1\u4e86\u5bf9\u5df2\u90e8\u7f72\u52a0\u901f\u5668\u5982\u4f55\u88ab\u89c2\u5bdf\u548c\u6cbb\u7406\u7684\u62c5\u5fe7\u3002\u5f53\u524dGPU\u66b4\u9732\u7684\u53ef\u4fe1\u9065\u6d4b\u6709\u9650\uff0c\u4e14\u53ef\u80fd\u88ab\u5bf9\u624b\u4fee\u6539\u6216\u865a\u62df\u5316\uff0c\u9700\u8981\u5728\u4e0d\u4fe1\u4efb\u4e3b\u673a\u548c\u8bbe\u5907\u7684\u60c5\u51b5\u4e0b\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u8ba1\u7b97\u5229\u7528\u7387\u4fe1\u53f7\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u73b0\u4ee3GPU\u67b6\u6784\u7279\u6027\u7684\u6d4b\u91cf\u6846\u67b6\uff0c\u5305\u542b\u56db\u79cd\u4e92\u8865\u539f\u8bed\uff1a1\uff09\u53d7\u5de5\u4f5c\u91cf\u8bc1\u660e\u542f\u53d1\u7684\u6982\u7387\u6027\u3001\u5de5\u4f5c\u8d1f\u8f7d\u9a71\u52a8\u673a\u5236\uff1b2\uff09\u57fa\u4e8e\u53ef\u9a8c\u8bc1\u5ef6\u8fdf\u51fd\u6570\u7684\u987a\u5e8f\u3001\u5ef6\u8fdf\u654f\u611f\u5de5\u4f5c\u8d1f\u8f7d\uff1b3\uff09\u57fa\u4e8e\u901a\u7528\u77e9\u9635\u4e58\u6cd5\u7684\u5f20\u91cf\u6838\u5fc3\u6d4b\u91cf\uff1b4\uff09VRAM\u9a7b\u7559\u6d4b\u8bd5\u3002\u8fd9\u4e9b\u539f\u8bed\u63d0\u4f9bGPU\u53c2\u4e0e\u5ea6\u7684\u7edf\u8ba1\u548c\u884c\u4e3a\u6307\u6807\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u8fd9\u4e9b\u539f\u8bed\u5bf9\u4e89\u7528\u3001\u67b6\u6784\u5bf9\u9f50\u3001\u5185\u5b58\u538b\u529b\u548c\u529f\u8017\u5f00\u9500\u6709\u54cd\u5e94\uff0c\u65f6\u5e8f\u504f\u79fb\u548c\u9a7b\u7559\u5ef6\u8fdf\u63ed\u793a\u4e86\u6709\u610f\u4e49\u7684\u5229\u7528\u7387\u6a21\u5f0f\u3002\u8ba1\u7b97\u9065\u6d4b\u53ef\u4ee5\u8865\u5145\u672a\u6765\u7684\u95ee\u8d23\u673a\u5236\u3002", "conclusion": "\u57fa\u4e8e\u8ba1\u7b97\u7684\u9065\u6d4b\u80fd\u591f\u66b4\u9732\u4e0eGPU\u90e8\u7f72\u540e\u6cbb\u7406\u76f8\u5173\u7684\u67b6\u6784\u4fe1\u53f7\uff0c\u5373\u4f7f\u5728\u6ca1\u6709\u53ef\u4fe1\u56fa\u4ef6\u3001\u5b89\u5168\u533a\u57df\u6216\u4f9b\u5e94\u5546\u63a7\u5236\u8ba1\u6570\u5668\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u4fdd\u6301\u53ef\u89c2\u6d4b\u6027\uff0c\u4e3aGPU\u6cbb\u7406\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u8865\u5145\u673a\u5236\u3002"}}
{"id": "2602.09311", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.09311", "abs": "https://arxiv.org/abs/2602.09311", "authors": ["Tao Xiao", "Dong Wang", "Shane McIntosh", "Hideaki Hata", "Yasutaka Kamei"], "title": "Cross-Project Flakiness: A Case Study of the OpenStack Ecosystem", "comment": null, "summary": "Automated regression testing is a cornerstone of modern software development, often contributing directly to code review and Continuous Integration (CI). Yet some tests suffer from flakiness, where their outcomes vary non-deterministically. Flakiness erodes developer trust in test results, wastes computational resources, and undermines CI reliability. While prior research has examined test flakiness within individual projects, its broader ecosystem-wide impact remains largely unexplored. In this paper, we present an empirical study of test flakiness in the OpenStack ecosystem, which focuses on (1) cross-project flakiness, where flaky tests impact multiple projects, and (2) inconsistent flakiness, where a test exhibits flakiness in some projects but remains stable in others. By analyzing 649 OpenStack projects, we identify 1,535 cross-project flaky tests and 1,105 inconsistently flaky tests. We find that cross-project flakiness affects 55% of OpenStack projects and significantly increases both review time and computational costs. Surprisingly, 70% of unit tests exhibit cross-project flakiness, challenging the assumption that unit tests are inherently insulated from issues that span modules like integration and system-level tests. Through qualitative analysis, we observe that race conditions in CI, inconsistent build configurations, and dependency mismatches are the primary causes of inconsistent flakiness. These findings underline the need for better coordination across complex ecosystems, standardized CI configurations, and improved test isolation strategies.", "AI": {"tldr": "\u672c\u6587\u5bf9OpenStack\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u6d4b\u8bd5\u4e0d\u7a33\u5b9a\u6027\u8fdb\u884c\u4e86\u5b9e\u8bc1\u7814\u7a76\uff0c\u53d1\u73b0\u8de8\u9879\u76ee\u4e0d\u7a33\u5b9a\u6027\u5f71\u54cd55%\u7684\u9879\u76ee\uff0c\u663e\u8457\u589e\u52a0\u5ba1\u67e5\u65f6\u95f4\u548c\u8ba1\u7b97\u6210\u672c\uff0c70%\u7684\u5355\u5143\u6d4b\u8bd5\u8868\u73b0\u51fa\u8de8\u9879\u76ee\u4e0d\u7a33\u5b9a\u6027\uff0c\u6311\u6218\u4e86\u5355\u5143\u6d4b\u8bd5\u56fa\u6709\u7684\u9694\u79bb\u5047\u8bbe\u3002", "motivation": "\u81ea\u52a8\u5316\u56de\u5f52\u6d4b\u8bd5\u662f\u73b0\u4ee3\u8f6f\u4ef6\u5f00\u53d1\u7684\u6838\u5fc3\uff0c\u4f46\u6d4b\u8bd5\u4e0d\u7a33\u5b9a\u6027\uff08flakiness\uff09\u4f1a\u7834\u574f\u5f00\u53d1\u8005\u5bf9\u6d4b\u8bd5\u7ed3\u679c\u7684\u4fe1\u4efb\u3001\u6d6a\u8d39\u8ba1\u7b97\u8d44\u6e90\u5e76\u524a\u5f31\u6301\u7eed\u96c6\u6210\u7684\u53ef\u9760\u6027\u3002\u867d\u7136\u5df2\u6709\u7814\u7a76\u5173\u6ce8\u5355\u4e2a\u9879\u76ee\u5185\u7684\u6d4b\u8bd5\u4e0d\u7a33\u5b9a\u6027\uff0c\u4f46\u5176\u5728\u66f4\u5e7f\u6cdb\u7684\u751f\u6001\u7cfb\u7edf\u5c42\u9762\u7684\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5bf9OpenStack\u751f\u6001\u7cfb\u7edf\u4e2d649\u4e2a\u9879\u76ee\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u91cd\u70b9\u5173\u6ce8\uff1a(1) \u8de8\u9879\u76ee\u4e0d\u7a33\u5b9a\u6027\u2014\u2014\u4e0d\u7a33\u5b9a\u7684\u6d4b\u8bd5\u5f71\u54cd\u591a\u4e2a\u9879\u76ee\uff1b(2) \u4e0d\u4e00\u81f4\u7684\u4e0d\u7a33\u5b9a\u6027\u2014\u2014\u6d4b\u8bd5\u5728\u67d0\u4e9b\u9879\u76ee\u4e2d\u8868\u73b0\u51fa\u4e0d\u7a33\u5b9a\u6027\uff0c\u5728\u5176\u4ed6\u9879\u76ee\u4e2d\u4fdd\u6301\u7a33\u5b9a\u3002\u901a\u8fc7\u5206\u6790\u8bc6\u522b\u51fa1,535\u4e2a\u8de8\u9879\u76ee\u4e0d\u7a33\u5b9a\u6d4b\u8bd5\u548c1,105\u4e2a\u4e0d\u4e00\u81f4\u4e0d\u7a33\u5b9a\u6d4b\u8bd5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a\u8de8\u9879\u76ee\u4e0d\u7a33\u5b9a\u6027\u5f71\u54cd55%\u7684OpenStack\u9879\u76ee\uff0c\u663e\u8457\u589e\u52a0\u5ba1\u67e5\u65f6\u95f4\u548c\u8ba1\u7b97\u6210\u672c\uff1b70%\u7684\u5355\u5143\u6d4b\u8bd5\u8868\u73b0\u51fa\u8de8\u9879\u76ee\u4e0d\u7a33\u5b9a\u6027\uff0c\u6311\u6218\u4e86\u5355\u5143\u6d4b\u8bd5\u56fa\u6709\u7684\u9694\u79bb\u5047\u8bbe\uff1b\u901a\u8fc7\u5b9a\u6027\u5206\u6790\u53d1\u73b0\uff0c\u6301\u7eed\u96c6\u6210\u4e2d\u7684\u7ade\u4e89\u6761\u4ef6\u3001\u4e0d\u4e00\u81f4\u7684\u6784\u5efa\u914d\u7f6e\u548c\u4f9d\u8d56\u4e0d\u5339\u914d\u662f\u4e0d\u4e00\u81f4\u4e0d\u7a33\u5b9a\u6027\u7684\u4e3b\u8981\u539f\u56e0\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u5f3a\u8c03\u4e86\u5728\u590d\u6742\u751f\u6001\u7cfb\u7edf\u4e2d\u9700\u8981\u66f4\u597d\u7684\u8de8\u9879\u76ee\u534f\u8c03\u3001\u6807\u51c6\u5316\u7684\u6301\u7eed\u96c6\u6210\u914d\u7f6e\u4ee5\u53ca\u6539\u8fdb\u7684\u6d4b\u8bd5\u9694\u79bb\u7b56\u7565\u3002\u7814\u7a76\u7ed3\u679c\u5bf9\u7406\u89e3\u6d4b\u8bd5\u4e0d\u7a33\u5b9a\u6027\u7684\u751f\u6001\u7cfb\u7edf\u5f71\u54cd\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u5e76\u4e3a\u6539\u8fdb\u8f6f\u4ef6\u6d4b\u8bd5\u5b9e\u8df5\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u4f9d\u636e\u3002"}}
{"id": "2602.09392", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09392", "abs": "https://arxiv.org/abs/2602.09392", "authors": ["Sharif Noor Zisad", "Ragib Hasan"], "title": "LLMAC: A Global and Explainable Access Control Framework with Large Language Model", "comment": "This paper is accepted and presented in IEEE Consumer Communications & Networking Conference (CCNC 2026)", "summary": "Today's business organizations need access control systems that can handle complex, changing security requirements that go beyond what traditional methods can manage. Current approaches, such as Role-Based Access Control (RBAC), Attribute-Based Access Control (ABAC), and Discretionary Access Control (DAC), were designed for specific purposes. They cannot effectively manage the dynamic, situation-dependent workflows that modern systems require. In this research, we introduce LLMAC, a new unified approach using Large Language Models (LLMs) to combine these different access control methods into one comprehensive, understandable system. We used an extensive synthetic dataset that represents complex real-world scenarios, including policies for ownership verification, version management, workflow processes, and dynamic role separation. Using Mistral 7B, our trained LLM model achieved outstanding results with 98.5% accuracy, significantly outperforming traditional methods (RBAC: 14.5%, ABAC: 58.5%, DAC: 27.5%) while providing clear, human readable explanations for each decision. Performance testing shows that the system can be practically deployed with reasonable response times and computing resources.", "AI": {"tldr": "\u63d0\u51faLLMAC\uff1a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7edf\u4e00\u8bbf\u95ee\u63a7\u5236\u6846\u67b6\uff0c\u6574\u5408RBAC\u3001ABAC\u3001DAC\u7b49\u4f20\u7edf\u65b9\u6cd5\uff0c\u89e3\u51b3\u52a8\u6001\u590d\u6742\u573a\u666f\u4e0b\u7684\u8bbf\u95ee\u63a7\u5236\u95ee\u9898\uff0c\u5728\u5408\u6210\u6570\u636e\u96c6\u4e0a\u8fbe\u523098.5%\u51c6\u786e\u7387\u3002", "motivation": "\u4f20\u7edf\u8bbf\u95ee\u63a7\u5236\u65b9\u6cd5\uff08RBAC\u3001ABAC\u3001DAC\uff09\u5404\u81ea\u4e3a\u7279\u5b9a\u76ee\u7684\u8bbe\u8ba1\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u73b0\u4ee3\u7cfb\u7edf\u6240\u9700\u7684\u52a8\u6001\u3001\u60c5\u5883\u4f9d\u8d56\u7684\u5de5\u4f5c\u6d41\u3002\u4f01\u4e1a\u9700\u8981\u80fd\u591f\u5904\u7406\u590d\u6742\u3001\u53d8\u5316\u5b89\u5168\u9700\u6c42\u7684\u8bbf\u95ee\u63a7\u5236\u7cfb\u7edf\u3002", "method": "\u63d0\u51faLLMAC\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7edf\u4e00\u6574\u5408\u591a\u79cd\u8bbf\u95ee\u63a7\u5236\u65b9\u6cd5\u3002\u4f7f\u7528\u5305\u542b\u6240\u6709\u6743\u9a8c\u8bc1\u3001\u7248\u672c\u7ba1\u7406\u3001\u5de5\u4f5c\u6d41\u6d41\u7a0b\u3001\u52a8\u6001\u89d2\u8272\u5206\u79bb\u7b49\u590d\u6742\u573a\u666f\u7684\u5408\u6210\u6570\u636e\u96c6\u8bad\u7ec3Mistral 7B\u6a21\u578b\u3002", "result": "\u8bad\u7ec3\u540e\u7684LLM\u6a21\u578b\u8fbe\u523098.5%\u7684\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff08RBAC:14.5%\u3001ABAC:58.5%\u3001DAC:27.5%\uff09\u3002\u7cfb\u7edf\u63d0\u4f9b\u6e05\u6670\u53ef\u8bfb\u7684\u51b3\u7b56\u89e3\u91ca\uff0c\u6027\u80fd\u6d4b\u8bd5\u663e\u793a\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u53ef\u884c\u6027\u3002", "conclusion": "LLMAC\u6846\u67b6\u6210\u529f\u6574\u5408\u4e86\u591a\u79cd\u8bbf\u95ee\u63a7\u5236\u65b9\u6cd5\uff0c\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u3001\u53ef\u89e3\u91ca\u7684\u52a8\u6001\u8bbf\u95ee\u63a7\u5236\uff0c\u4e3a\u590d\u6742\u73b0\u4ee3\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.09340", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09340", "abs": "https://arxiv.org/abs/2602.09340", "authors": ["Yang Ba", "Mohammad Sadeq Abolhasani", "Michelle V Mancenido", "Rong Pan"], "title": "Measuring Dataset Diversity from a Geometric Perspective", "comment": null, "summary": "Diversity can be broadly defined as the presence of meaningful variation across elements, which can be viewed from multiple perspectives, including statistical variation and geometric structural richness in the dataset. Existing diversity metrics, such as feature-space dispersion and metric-space magnitude, primarily capture distributional variation or entropy, while largely neglecting the geometric structure of datasets. To address this gap, we introduce a framework based on topological data analysis (TDA) and persistence landscapes (PLs) to extract and quantify geometric features from data. This approach provides a theoretically grounded means of measuring diversity beyond entropy, capturing the rich geometric and structural properties of datasets. Through extensive experiments across diverse modalities, we demonstrate that our proposed PLs-based diversity metric (PLDiv) is powerful, reliable, and interpretable, directly linking data diversity to its underlying geometry and offering a foundational tool for dataset construction, augmentation, and evaluation.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u62d3\u6251\u6570\u636e\u5206\u6790\uff08TDA\uff09\u548c\u6301\u4e45\u6027\u666f\u89c2\uff08PLs\uff09\u7684\u51e0\u4f55\u591a\u6837\u6027\u5ea6\u91cf\u6846\u67b6PLDiv\uff0c\u8d85\u8d8a\u4f20\u7edf\u71b5\u548c\u5206\u5e03\u53d8\u5316\u5ea6\u91cf\uff0c\u6355\u6349\u6570\u636e\u96c6\u7684\u51e0\u4f55\u7ed3\u6784\u7279\u5f81\u3002", "motivation": "\u73b0\u6709\u591a\u6837\u6027\u5ea6\u91cf\u4e3b\u8981\u5173\u6ce8\u7279\u5f81\u7a7a\u95f4\u79bb\u6563\u5ea6\u6216\u5ea6\u91cf\u7a7a\u95f4\u5e45\u5ea6\uff0c\u6355\u6349\u5206\u5e03\u53d8\u5316\u6216\u71b5\uff0c\u4f46\u5f88\u5927\u7a0b\u5ea6\u4e0a\u5ffd\u7565\u4e86\u6570\u636e\u96c6\u7684\u51e0\u4f55\u7ed3\u6784\u3002\u9700\u8981\u4e00\u79cd\u80fd\u6355\u6349\u6570\u636e\u51e0\u4f55\u548c\u7ed3\u6784\u7279\u6027\u7684\u591a\u6837\u6027\u5ea6\u91cf\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u62d3\u6251\u6570\u636e\u5206\u6790\u548c\u6301\u4e45\u6027\u666f\u89c2\u6784\u5efa\u6846\u67b6\uff0c\u4ece\u6570\u636e\u4e2d\u63d0\u53d6\u548c\u91cf\u5316\u51e0\u4f55\u7279\u5f81\u3002\u6301\u4e45\u6027\u666f\u89c2\u63d0\u4f9b\u6570\u636e\u62d3\u6251\u7279\u5f81\u7684\u7a33\u5b9a\u8868\u793a\uff0c\u7528\u4e8e\u6d4b\u91cf\u8d85\u8d8a\u71b5\u7684\u591a\u6837\u6027\u3002", "result": "\u901a\u8fc7\u8de8\u591a\u79cd\u6a21\u6001\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\uff0c\u63d0\u51fa\u7684PLDiv\u5ea6\u91cf\u65b9\u6cd5\u5f3a\u5927\u3001\u53ef\u9760\u4e14\u53ef\u89e3\u91ca\uff0c\u76f4\u63a5\u5c06\u6570\u636e\u591a\u6837\u6027\u4e0e\u5e95\u5c42\u51e0\u4f55\u7ed3\u6784\u8054\u7cfb\u8d77\u6765\u3002", "conclusion": "PLDiv\u4e3a\u6570\u636e\u96c6\u6784\u5efa\u3001\u589e\u5f3a\u548c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u57fa\u7840\u5de5\u5177\uff0c\u901a\u8fc7\u62d3\u6251\u6570\u636e\u5206\u6790\u65b9\u6cd5\u5b9e\u73b0\u4e86\u5bf9\u6570\u636e\u51e0\u4f55\u7ed3\u6784\u591a\u6837\u6027\u7684\u91cf\u5316\u6d4b\u91cf\u3002"}}
{"id": "2602.09447", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.09447", "abs": "https://arxiv.org/abs/2602.09447", "authors": ["Zhirui Zhang", "Hongbo Zhang", "Haoxiang Fei", "Zhiyuan Bao", "Yubin Chen", "Zhengyu Lei", "Ziyue Liu", "Yixuan Sun", "Mingkun Xiao", "Zihang Ye", "Yu Zhang", "Hongcheng Zhu", "Yuxiang Wen", "Heung-Yeung Shum"], "title": "SWE-AGI: Benchmarking Specification-Driven Software Construction with MoonBit in the Era of Autonomous Agents", "comment": "20 pages, 3 figures", "summary": "Although large language models (LLMs) have demonstrated impressive coding capabilities, their ability to autonomously build production-scale software from explicit specifications remains an open question. We introduce SWE-AGI, an open-source benchmark for evaluating end-to-end, specification-driven construction of software systems written in MoonBit. SWE-AGI tasks require LLM-based agents to implement parsers, interpreters, binary decoders, and SAT solvers strictly from authoritative standards and RFCs under a fixed API scaffold. Each task involves implementing 1,000-10,000 lines of core logic, corresponding to weeks or months of engineering effort for an experienced human developer. By leveraging the nascent MoonBit ecosystem, SWE-AGI minimizes data leakage, forcing agents to rely on long-horizon architectural reasoning rather than code retrieval. Across frontier models, gpt-5.3-codex achieves the best overall performance (solving 19/22 tasks, 86.4%), outperforming claude-opus-4.6 (15/22, 68.2%), and kimi-2.5 exhibits the strongest performance among open-source models. Performance degrades sharply with increasing task difficulty, particularly on hard, specification-intensive systems. Behavioral analysis further reveals that as codebases scale, code reading, rather than writing, becomes the dominant bottleneck in AI-assisted development. Overall, while specification-driven autonomous software engineering is increasingly viable, substantial challenges remain before it can reliably support production-scale development.", "AI": {"tldr": "SWE-AGI\u662f\u4e00\u4e2a\u5f00\u6e90\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u57fa\u4e8e\u660e\u786e\u89c4\u8303\u6784\u5efa\u751f\u4ea7\u7ea7\u8f6f\u4ef6\u7cfb\u7edf\u7684\u80fd\u529b\uff0c\u7ed3\u679c\u663e\u793aGPT-5.3-Codex\u8868\u73b0\u6700\u4f73\uff0886.4%\uff09\uff0c\u4f46\u968f\u7740\u4efb\u52a1\u96be\u5ea6\u589e\u52a0\u6027\u80fd\u6025\u5267\u4e0b\u964d\uff0c\u4ee3\u7801\u9605\u8bfb\u6210\u4e3aAI\u8f85\u52a9\u5f00\u53d1\u7684\u4e3b\u8981\u74f6\u9888\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7f16\u7801\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u57fa\u4e8e\u660e\u786e\u89c4\u8303\u81ea\u4e3b\u6784\u5efa\u751f\u4ea7\u7ea7\u8f6f\u4ef6\u7cfb\u7edf\u7684\u80fd\u529b\u4ecd\u662f\u4e00\u4e2a\u5f00\u653e\u6027\u95ee\u9898\u3002\u9700\u8981\u8bc4\u4f30LLM\u5728\u4e25\u683c\u9075\u5faa\u6743\u5a01\u6807\u51c6\u548cRFC\u89c4\u8303\u4e0b\uff0c\u6784\u5efa\u5927\u89c4\u6a21\u8f6f\u4ef6\u7cfb\u7edf\u7684\u5b9e\u9645\u80fd\u529b\u3002", "method": "\u5f15\u5165SWE-AGI\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8981\u6c42LLM\u667a\u80fd\u4f53\u5728\u56fa\u5b9aAPI\u6846\u67b6\u4e0b\uff0c\u4e25\u683c\u4f9d\u636e\u6743\u5a01\u6807\u51c6\u548cRFC\u89c4\u8303\u5b9e\u73b0\u89e3\u6790\u5668\u3001\u89e3\u91ca\u5668\u3001\u4e8c\u8fdb\u5236\u89e3\u7801\u5668\u548cSAT\u6c42\u89e3\u5668\u7b49\u4efb\u52a1\u3002\u6bcf\u4e2a\u4efb\u52a1\u6d89\u53ca1,000-10,000\u884c\u6838\u5fc3\u903b\u8f91\u4ee3\u7801\uff0c\u5229\u7528\u65b0\u5174\u7684MoonBit\u751f\u6001\u7cfb\u7edf\u6700\u5c0f\u5316\u6570\u636e\u6cc4\u9732\uff0c\u8feb\u4f7f\u667a\u80fd\u4f53\u4f9d\u8d56\u957f\u671f\u67b6\u6784\u63a8\u7406\u800c\u975e\u4ee3\u7801\u68c0\u7d22\u3002", "result": "GPT-5.3-Codex\u8868\u73b0\u6700\u4f73\uff0819/22\u4efb\u52a1\uff0c86.4%\uff09\uff0c\u4f18\u4e8eClaude-Opus-4.6\uff0815/22\uff0c68.2%\uff09\uff0cKimi-2.5\u5728\u5f00\u6e90\u6a21\u578b\u4e2d\u8868\u73b0\u6700\u5f3a\u3002\u968f\u7740\u4efb\u52a1\u96be\u5ea6\u589e\u52a0\uff0c\u6027\u80fd\u6025\u5267\u4e0b\u964d\uff0c\u7279\u522b\u662f\u5728\u89c4\u8303\u5bc6\u96c6\u7684\u56f0\u96be\u7cfb\u7edf\u4e0a\u3002\u884c\u4e3a\u5206\u6790\u663e\u793a\uff0c\u968f\u7740\u4ee3\u7801\u5e93\u89c4\u6a21\u6269\u5927\uff0c\u4ee3\u7801\u9605\u8bfb\u800c\u975e\u7f16\u5199\u6210\u4e3aAI\u8f85\u52a9\u5f00\u53d1\u7684\u4e3b\u8981\u74f6\u9888\u3002", "conclusion": "\u867d\u7136\u57fa\u4e8e\u89c4\u8303\u7684\u81ea\u4e3b\u8f6f\u4ef6\u5de5\u7a0b\u8d8a\u6765\u8d8a\u53ef\u884c\uff0c\u4f46\u5728\u53ef\u9760\u652f\u6301\u751f\u4ea7\u7ea7\u5f00\u53d1\u4e4b\u524d\u4ecd\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002\u4ee3\u7801\u9605\u8bfb\u80fd\u529b\u6210\u4e3a\u9650\u5236AI\u8f85\u52a9\u8f6f\u4ef6\u5f00\u53d1\u89c4\u6a21\u6269\u5c55\u7684\u5173\u952e\u56e0\u7d20\u3002"}}
{"id": "2602.09431", "categories": ["cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.09431", "abs": "https://arxiv.org/abs/2602.09431", "authors": ["Xinwei Zhang", "Li Bai", "Tianwei Zhang", "Youqian Zhang", "Qingqing Ye", "Yingnan Zhao", "Ruochen Du", "Haibo Hu"], "title": "Understanding and Enhancing Encoder-based Adversarial Transferability against Large Vision-Language Models", "comment": "Under review; 21 pages", "summary": "Large vision-language models (LVLMs) have achieved impressive success across multimodal tasks, but their reliance on visual inputs exposes them to significant adversarial threats. Existing encoder-based attacks perturb the input image by optimizing solely on the vision encoder, rather than the entire LVLM, offering a computationally efficient alternative to end-to-end optimization. However, their transferability across different LVLM architectures in realistic black-box scenarios remains poorly understood. To address this gap, we present the first systematic study towards encoder-based adversarial transferability in LVLMs. Our contributions are threefold. First, through large-scale benchmarking over eight diverse LVLMs, we reveal that existing attacks exhibit severely limited transferability. Second, we perform in-depth analysis, disclosing two root causes that hinder the transferability: (1) inconsistent visual grounding across models, where different models focus their attention on distinct regions; (2) redundant semantic alignment within models, where a single object is dispersed across multiple overlapping token representations. Third, we propose Semantic-Guided Multimodal Attack (SGMA), a novel framework to enhance the transferability. Inspired by the discovered causes in our analysis, SGMA directs perturbations toward semantically critical regions and disrupts cross-modal grounding at both global and local levels. Extensive experiments across different victim models and tasks show that SGMA achieves higher transferability than existing attacks. These results expose critical security risks in LVLM deployment and underscore the urgent need for robust multimodal defenses.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86LVLM\u4e2d\u57fa\u4e8e\u7f16\u7801\u5668\u7684\u5bf9\u6297\u6837\u672c\u53ef\u8fc1\u79fb\u6027\uff0c\u53d1\u73b0\u73b0\u6709\u653b\u51fb\u65b9\u6cd5\u53ef\u8fc1\u79fb\u6027\u6709\u9650\uff0c\u5e76\u63d0\u51faSGMA\u6846\u67b6\u6765\u63d0\u5347\u53ef\u8fc1\u79fb\u6027\u3002", "motivation": "\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5bf9\u89c6\u89c9\u8f93\u5165\u7684\u4f9d\u8d56\u4f7f\u5176\u9762\u4e34\u5bf9\u6297\u6027\u5a01\u80c1\u3002\u73b0\u6709\u57fa\u4e8e\u7f16\u7801\u5668\u7684\u653b\u51fb\u65b9\u6cd5\u4ec5\u9488\u5bf9\u89c6\u89c9\u7f16\u7801\u5668\u8fdb\u884c\u4f18\u5316\uff0c\u800c\u975e\u6574\u4e2aLVLM\uff0c\u8ba1\u7b97\u6548\u7387\u8f83\u9ad8\uff0c\u4f46\u5176\u5728\u4e0d\u540cLVLM\u67b6\u6784\u95f4\u7684\u53ef\u8fc1\u79fb\u6027\u5728\u73b0\u5b9e\u9ed1\u76d2\u573a\u666f\u4e2d\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7406\u89e3\u3002", "method": "\u9996\u5148\u57288\u4e2a\u4e0d\u540c\u7684LVLM\u4e0a\u8fdb\u884c\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63ed\u793a\u73b0\u6709\u653b\u51fb\u65b9\u6cd5\u7684\u53ef\u8fc1\u79fb\u6027\u9650\u5236\u3002\u7136\u540e\u8fdb\u884c\u6df1\u5165\u5206\u6790\uff0c\u53d1\u73b0\u4e24\u4e2a\u6839\u672c\u539f\u56e0\uff1a1\uff09\u6a21\u578b\u95f4\u89c6\u89c9\u5b9a\u4f4d\u4e0d\u4e00\u81f4\uff1b2\uff09\u6a21\u578b\u5185\u8bed\u4e49\u5bf9\u9f50\u5197\u4f59\u3002\u6700\u540e\u63d0\u51fa\u8bed\u4e49\u5f15\u5bfc\u7684\u591a\u6a21\u6001\u653b\u51fb\uff08SGMA\uff09\u6846\u67b6\uff0c\u5c06\u6270\u52a8\u5bfc\u5411\u8bed\u4e49\u5173\u952e\u533a\u57df\uff0c\u5e76\u5728\u5168\u5c40\u548c\u5c40\u90e8\u5c42\u9762\u7834\u574f\u8de8\u6a21\u6001\u5b9a\u4f4d\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSGMA\u5728\u4e0d\u540c\u53d7\u5bb3\u6a21\u578b\u548c\u4efb\u52a1\u4e0a\u6bd4\u73b0\u6709\u653b\u51fb\u65b9\u6cd5\u5177\u6709\u66f4\u9ad8\u7684\u53ef\u8fc1\u79fb\u6027\u3002\u8fd9\u4e9b\u7ed3\u679c\u63ed\u793a\u4e86LVLM\u90e8\u7f72\u4e2d\u7684\u5173\u952e\u5b89\u5168\u98ce\u9669\uff0c\u5e76\u5f3a\u8c03\u4e86\u5f00\u53d1\u9c81\u68d2\u591a\u6a21\u6001\u9632\u5fa1\u7684\u7d27\u8feb\u6027\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86LVLM\u4e2d\u57fa\u4e8e\u7f16\u7801\u5668\u7684\u5bf9\u6297\u6837\u672c\u53ef\u8fc1\u79fb\u6027\u95ee\u9898\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u653b\u51fb\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u53ca\u5176\u6839\u672c\u539f\u56e0\uff0c\u5e76\u63d0\u51faSGMA\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u653b\u51fb\u53ef\u8fc1\u79fb\u6027\uff0c\u66b4\u9732\u4e86LVLM\u90e8\u7f72\u7684\u5b89\u5168\u98ce\u9669\u3002"}}
{"id": "2602.09341", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09341", "abs": "https://arxiv.org/abs/2602.09341", "authors": ["Wei Yang", "Shixuan Li", "Heng Ping", "Peiyu Zhang", "Paul Bogdan", "Jesse Thomason"], "title": "Auditing Multi-Agent LLM Reasoning Trees Outperforms Majority Vote and LLM-as-Judge", "comment": null, "summary": "Multi-agent systems (MAS) can substantially extend the reasoning capacity of large language models (LLMs), yet most frameworks still aggregate agent outputs with majority voting. This heuristic discards the evidential structure of reasoning traces and is brittle under the confabulation consensus, where agents share correlated biases and converge on the same incorrect rationale. We introduce AgentAuditor, which replaces voting with a path search over a Reasoning Tree that explicitly represents agreements and divergences among agent traces. AgentAuditor resolves conflicts by comparing reasoning branches at critical divergence points, turning global adjudication into efficient, localized verification. We further propose Anti-Consensus Preference Optimization (ACPO), which trains the adjudicator on majority-failure cases and rewards evidence-based minority selections over popular errors. AgentAuditor is agnostic to MAS setting, and we find across 5 popular settings that it yields up to 5% absolute accuracy improvement over a majority vote, and up to 3% over using LLM-as-Judge.", "AI": {"tldr": "AgentAuditor\u901a\u8fc7\u6784\u5efa\u63a8\u7406\u6811\u66ff\u4ee3\u591a\u6570\u6295\u7968\uff0c\u7ed3\u5408ACPO\u8bad\u7ec3\uff0c\u57285\u79cd\u591a\u667a\u80fd\u4f53\u8bbe\u7f6e\u4e2d\u5b9e\u73b0\u6700\u9ad85%\u7684\u51c6\u786e\u7387\u63d0\u5347", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5927\u591a\u91c7\u7528\u591a\u6570\u6295\u7968\u805a\u5408\u667a\u80fd\u4f53\u8f93\u51fa\uff0c\u8fd9\u79cd\u65b9\u6cd5\u4e22\u5f03\u4e86\u63a8\u7406\u8f68\u8ff9\u7684\u8bc1\u636e\u7ed3\u6784\uff0c\u4e14\u5728\u667a\u80fd\u4f53\u5b58\u5728\u76f8\u5173\u504f\u89c1\u65f6\u5bb9\u6613\u5f62\u6210\u9519\u8bef\u5171\u8bc6\uff08confabulation consensus\uff09\uff0c\u5bfc\u81f4\u7cfb\u7edf\u8106\u5f31", "method": "1. AgentAuditor\uff1a\u6784\u5efa\u63a8\u7406\u6811\u663e\u5f0f\u8868\u793a\u667a\u80fd\u4f53\u8f68\u8ff9\u95f4\u7684\u5171\u8bc6\u4e0e\u5206\u6b67\uff0c\u5728\u5173\u952e\u5206\u6b67\u70b9\u6bd4\u8f83\u63a8\u7406\u5206\u652f\uff0c\u5c06\u5168\u5c40\u88c1\u51b3\u8f6c\u5316\u4e3a\u9ad8\u6548\u7684\u5c40\u90e8\u9a8c\u8bc1\uff1b2. ACPO\uff1a\u5728\u591a\u6570\u6295\u7968\u5931\u8d25\u6848\u4f8b\u4e0a\u8bad\u7ec3\u88c1\u51b3\u5668\uff0c\u5956\u52b1\u57fa\u4e8e\u8bc1\u636e\u7684\u5c11\u6570\u9009\u62e9\u800c\u975e\u6d41\u884c\u9519\u8bef", "result": "\u57285\u79cd\u6d41\u884c\u7684\u591a\u667a\u80fd\u4f53\u8bbe\u7f6e\u4e2d\uff0cAgentAuditor\u76f8\u6bd4\u591a\u6570\u6295\u7968\u5b9e\u73b0\u6700\u9ad85%\u7684\u7edd\u5bf9\u51c6\u786e\u7387\u63d0\u5347\uff0c\u76f8\u6bd4LLM-as-Judge\u65b9\u6cd5\u63d0\u5347\u6700\u9ad83%", "conclusion": "\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u63a8\u7406\u8f68\u8ff9\u7684\u5171\u8bc6\u4e0e\u5206\u6b67\uff0c\u5e76\u9488\u5bf9\u591a\u6570\u6295\u7968\u5931\u8d25\u6848\u4f8b\u8fdb\u884c\u4f18\u5316\u8bad\u7ec3\uff0cAgentAuditor\u80fd\u591f\u66f4\u6709\u6548\u5730\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u5171\u8bc6\u9519\u8bef\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd"}}
{"id": "2602.09467", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.09467", "abs": "https://arxiv.org/abs/2602.09467", "authors": ["Sota Nakashima", "Masanari Kondo", "Mahmoud Alfadel", "Aly Ahmad", "Toshihiro Nakae", "Hidenori Matsuzaki"], "title": "Toward Linking Declined Proposals and Source Code: An Exploratory Study on the Go Repository", "comment": "11 pages, MSR2026 Technical Track", "summary": "Traceability links are key information sources for software developers, connecting software artifacts (e.g., linking requirements to the corresponding source code). In open-source software (OSS) projects, such links play an important role, particularly between the contributions (e.g., GitHub issues) and the corresponding source code. Through these links, developers can trace the discussions in contributions and uncover design rationales, constraints, and security concerns. Previous studies have mainly examined accepted contributions, while those declined after discussion have been overlooked. The discussions behind declined contributions contain valuable design rationales and implicit knowledge about software decision-making, as the reasons behind the decline often reveal the criteria used to judge what should or should not be implemented. In this study, we present the first attempt to establish traceability links between declined contributions and related source code. We propose an initial linking approach and conduct an empirical analysis of the generated links to discuss factors affecting link generation. As our dataset, we use proposals from the official Go repository, which are GitHub issues used to propose new features or language changes. To link declined proposals to source code, we designed an LLM-driven pipeline. Our results showed that the pipeline selected the correct granularity for each declined proposal with an accuracy of 0.836, and generated correct links at that granularity with a mean precision of 0.643. To clarify the challenges of linking declined proposals, we performed a failure analysis. In the declined proposals where the pipeline failed to generate links, the discussions were often redundant and lacked concrete information (e.g., how the feature should be implemented).", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u5c1d\u8bd5\u5728\u5f00\u6e90\u8f6f\u4ef6\u4e2d\u5efa\u7acb\u88ab\u62d2\u7edd\u7684\u8d21\u732e\uff08\u5982GitHub issue\uff09\u4e0e\u76f8\u5173\u6e90\u4ee3\u7801\u4e4b\u95f4\u7684\u53ef\u8ffd\u6eaf\u6027\u94fe\u63a5\uff0c\u4f7f\u7528LLM\u9a71\u52a8\u7684\u7ba1\u9053\u8fdb\u884c\u5206\u6790\uff0c\u51c6\u786e\u7387\u8fbe\u52300.836\uff0c\u5e73\u5747\u7cbe\u5ea6\u4e3a0.643\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u88ab\u63a5\u53d7\u7684\u8d21\u732e\uff0c\u800c\u88ab\u62d2\u7edd\u7684\u8d21\u732e\u4e2d\u5305\u542b\u4e86\u6709\u4ef7\u503c\u7684\u8bbe\u8ba1\u539f\u7406\u548c\u8f6f\u4ef6\u51b3\u7b56\u7684\u9690\u5f0f\u77e5\u8bc6\u3002\u8fd9\u4e9b\u88ab\u62d2\u7edd\u8d21\u732e\u80cc\u540e\u7684\u8ba8\u8bba\u63ed\u793a\u4e86\u5224\u65ad\u4ec0\u4e48\u5e94\u8be5\u6216\u4e0d\u5e94\u8be5\u5b9e\u73b0\u7684\u6807\u51c6\uff0c\u5bf9\u5f00\u53d1\u8005\u7406\u89e3\u8f6f\u4ef6\u8bbe\u8ba1\u51b3\u7b56\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u4f7f\u7528\u5b98\u65b9Go\u4ed3\u5e93\u4e2d\u7684\u63d0\u6848\uff08GitHub issues\uff09\u4f5c\u4e3a\u6570\u636e\u96c6\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2aLLM\u9a71\u52a8\u7684\u7ba1\u9053\u6765\u94fe\u63a5\u88ab\u62d2\u7edd\u7684\u63d0\u6848\u4e0e\u6e90\u4ee3\u7801\u3002\u7ba1\u9053\u9996\u5148\u9009\u62e9\u6b63\u786e\u7684\u7c92\u5ea6\u7ea7\u522b\uff0c\u7136\u540e\u5728\u76f8\u5e94\u7c92\u5ea6\u4e0a\u751f\u6210\u94fe\u63a5\u3002", "result": "\u7ba1\u9053\u5728\u9009\u62e9\u88ab\u62d2\u7edd\u63d0\u6848\u7684\u6b63\u786e\u7c92\u5ea6\u65b9\u9762\u51c6\u786e\u7387\u8fbe\u52300.836\uff0c\u5728\u76f8\u5e94\u7c92\u5ea6\u4e0a\u751f\u6210\u6b63\u786e\u94fe\u63a5\u7684\u5e73\u5747\u7cbe\u5ea6\u4e3a0.643\u3002\u5931\u8d25\u5206\u6790\u663e\u793a\uff0c\u94fe\u63a5\u751f\u6210\u5931\u8d25\u7684\u4e3b\u8981\u539f\u56e0\u662f\u8ba8\u8bba\u5185\u5bb9\u5197\u4f59\u4e14\u7f3a\u4e4f\u5177\u4f53\u5b9e\u73b0\u4fe1\u606f\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5c1d\u8bd5\u5efa\u7acb\u88ab\u62d2\u7edd\u8d21\u732e\u4e0e\u6e90\u4ee3\u7801\u4e4b\u95f4\u7684\u53ef\u8ffd\u6eaf\u6027\u94fe\u63a5\u7684\u7814\u7a76\u3002\u867d\u7136LLM\u9a71\u52a8\u7684\u7ba1\u9053\u53d6\u5f97\u4e86\u6709\u5e0c\u671b\u7684\u7ed3\u679c\uff0c\u4f46\u88ab\u62d2\u7edd\u63d0\u6848\u4e2d\u8ba8\u8bba\u7684\u5197\u4f59\u6027\u548c\u4fe1\u606f\u4e0d\u8db3\u4ecd\u7136\u662f\u94fe\u63a5\u751f\u6210\u7684\u4e3b\u8981\u6311\u6218\u3002"}}
{"id": "2602.09434", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09434", "abs": "https://arxiv.org/abs/2602.09434", "authors": ["Zhenyu Xu", "Victor S. Sheng"], "title": "A Behavioral Fingerprint for Large Language Models: Provenance Tracking via Refusal Vectors", "comment": null, "summary": "Protecting the intellectual property of large language models (LLMs) is a critical challenge due to the proliferation of unauthorized derivative models. We introduce a novel fingerprinting framework that leverages the behavioral patterns induced by safety alignment, applying the concept of refusal vectors for LLM provenance tracking. These vectors, extracted from directional patterns in a model's internal representations when processing harmful versus harmless prompts, serve as robust behavioral fingerprints. Our contribution lies in developing a fingerprinting system around this concept and conducting extensive validation of its effectiveness for IP protection. We demonstrate that these behavioral fingerprints are highly robust against common modifications, including finetunes, merges, and quantization. Our experiments show that the fingerprint is unique to each model family, with low cosine similarity between independently trained models. In a large-scale identification task across 76 offspring models, our method achieves 100\\% accuracy in identifying the correct base model family. Furthermore, we analyze the fingerprint's behavior under alignment-breaking attacks, finding that while performance degrades significantly, detectable traces remain. Finally, we propose a theoretical framework to transform this private fingerprint into a publicly verifiable, privacy-preserving artifact using locality-sensitive hashing and zero-knowledge proofs.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5b89\u5168\u5bf9\u9f50\u8bf1\u5bfc\u884c\u4e3a\u6a21\u5f0f\u7684LLM\u6307\u7eb9\u6846\u67b6\uff0c\u5229\u7528\u62d2\u7edd\u5411\u91cf\u8fdb\u884c\u6a21\u578b\u6eaf\u6e90\uff0c\u572876\u4e2a\u884d\u751f\u6a21\u578b\u4e2d\u5b9e\u73b0100%\u7684\u5bb6\u65cf\u8bc6\u522b\u51c6\u786e\u7387", "motivation": "\u4fdd\u62a4\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u4ea7\u6743\uff0c\u9632\u6b62\u672a\u7ecf\u6388\u6743\u7684\u884d\u751f\u6a21\u578b\u6269\u6563\uff0c\u9700\u8981\u6709\u6548\u7684\u6a21\u578b\u6eaf\u6e90\u548c\u6240\u6709\u6743\u9a8c\u8bc1\u65b9\u6cd5", "method": "\u5229\u7528\u5b89\u5168\u5bf9\u9f50\u8bf1\u5bfc\u7684\u884c\u4e3a\u6a21\u5f0f\uff0c\u4ece\u6a21\u578b\u5185\u90e8\u8868\u793a\u4e2d\u63d0\u53d6\u62d2\u7edd\u5411\u91cf\u4f5c\u4e3a\u884c\u4e3a\u6307\u7eb9\uff0c\u6784\u5efa\u6307\u7eb9\u7cfb\u7edf\u5e76\u8fdb\u884c\u5927\u89c4\u6a21\u9a8c\u8bc1", "result": "\u884c\u4e3a\u6307\u7eb9\u5bf9\u5fae\u8c03\u3001\u5408\u5e76\u3001\u91cf\u5316\u7b49\u5e38\u89c1\u4fee\u6539\u5177\u6709\u5f3a\u9c81\u68d2\u6027\uff1b\u572876\u4e2a\u884d\u751f\u6a21\u578b\u4e2d\u5b9e\u73b0100%\u7684\u57fa\u7840\u6a21\u578b\u5bb6\u65cf\u8bc6\u522b\u51c6\u786e\u7387\uff1b\u5373\u4f7f\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u4ecd\u4fdd\u7559\u53ef\u68c0\u6d4b\u75d5\u8ff9", "conclusion": "\u63d0\u51fa\u7684\u884c\u4e3a\u6307\u7eb9\u6846\u67b6\u4e3aLLM\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u63d0\u51fa\u4e86\u901a\u8fc7\u5c40\u90e8\u654f\u611f\u54c8\u5e0c\u548c\u96f6\u77e5\u8bc6\u8bc1\u660e\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u516c\u5f00\u9a8c\u8bc1\u7684\u7406\u8bba\u6846\u67b6"}}
{"id": "2602.09347", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09347", "abs": "https://arxiv.org/abs/2602.09347", "authors": ["Jana G. Delfino", "Jason L. Granstedt", "Frank W. Samuelson", "Robert Ochs", "Krishna Juluru"], "title": "Image Quality in the Era of Artificial Intelligence", "comment": "16 pages, 3 figures", "summary": "Artificial intelligence (AI) is being deployed within radiology at a rapid pace. AI has proven an excellent tool for reconstructing and enhancing images that appear sharper, smoother, and more detailed, can be acquired more quickly, and allowing clinicians to review them more rapidly. However, incorporation of AI also introduces new failure modes and can exacerbate the disconnect between perceived quality of an image and information content of that image. Understanding the limitations of AI-enabled image reconstruction and enhancement is critical for safe and effective use of the technology. Hence, the purpose of this communication is to bring awareness to limitations when AI is used to reconstruct or enhance a radiological image, with the goal of enabling users to reap benefits of the technology while minimizing risks.", "AI": {"tldr": "AI\u5728\u653e\u5c04\u5b66\u56fe\u50cf\u91cd\u5efa\u548c\u589e\u5f3a\u4e2d\u5e94\u7528\u8fc5\u901f\uff0c\u80fd\u63d0\u5347\u56fe\u50cf\u8d28\u91cf\u3001\u52a0\u5feb\u83b7\u53d6\u901f\u5ea6\uff0c\u4f46\u4e5f\u5f15\u5165\u4e86\u65b0\u7684\u5931\u8d25\u6a21\u5f0f\u548c\u56fe\u50cf\u611f\u77e5\u8d28\u91cf\u4e0e\u4fe1\u606f\u5185\u5bb9\u4e4b\u95f4\u7684\u8131\u8282\u98ce\u9669\u3002", "motivation": "AI\u5728\u653e\u5c04\u5b66\u56fe\u50cf\u91cd\u5efa\u548c\u589e\u5f3a\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u867d\u7136\u80fd\u663e\u8457\u63d0\u5347\u56fe\u50cf\u8d28\u91cf\u548c\u5de5\u4f5c\u6548\u7387\uff0c\u4f46\u4e5f\u5e26\u6765\u4e86\u65b0\u7684\u98ce\u9669\uff0c\u7279\u522b\u662f\u56fe\u50cf\u611f\u77e5\u8d28\u91cf\u4e0e\u5b9e\u9645\u4fe1\u606f\u5185\u5bb9\u4e4b\u95f4\u7684\u8131\u8282\u95ee\u9898\uff0c\u9700\u8981\u5f15\u8d77\u91cd\u89c6\u3002", "method": "\u672c\u6587\u662f\u4e00\u7bc7\u901a\u8baf\u6587\u7ae0\uff0c\u65e8\u5728\u901a\u8fc7\u5206\u6790\u548c\u8ba8\u8bba\u7684\u65b9\u5f0f\uff0c\u63d0\u9ad8\u4eba\u4eec\u5bf9AI\u5728\u653e\u5c04\u5b66\u56fe\u50cf\u91cd\u5efa\u548c\u589e\u5f3a\u4e2d\u5c40\u9650\u6027\u7684\u8ba4\u8bc6\u3002", "result": "AI\u6280\u672f\u80fd\u591f\u751f\u6210\u66f4\u6e05\u6670\u3001\u66f4\u5e73\u6ed1\u3001\u66f4\u8be6\u7ec6\u7684\u56fe\u50cf\uff0c\u52a0\u5feb\u56fe\u50cf\u83b7\u53d6\u901f\u5ea6\uff0c\u5e76\u8ba9\u4e34\u5e8a\u533b\u751f\u80fd\u66f4\u5feb\u5730\u5ba1\u9605\u56fe\u50cf\u3002", "conclusion": "\u7406\u89e3AI\u56fe\u50cf\u91cd\u5efa\u548c\u589e\u5f3a\u7684\u5c40\u9650\u6027\u5bf9\u4e8e\u5b89\u5168\u6709\u6548\u5730\u4f7f\u7528\u8be5\u6280\u672f\u81f3\u5173\u91cd\u8981\uff0c\u7528\u6237\u9700\u8981\u5728\u4eab\u53d7AI\u6280\u672f\u5e26\u6765\u7684\u597d\u5904\u7684\u540c\u65f6\uff0c\u6700\u5c0f\u5316\u76f8\u5173\u98ce\u9669\u3002"}}
{"id": "2602.09548", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.09548", "abs": "https://arxiv.org/abs/2602.09548", "authors": ["Gianluca Capozzi", "Anna Paola Giancaspro", "Fabio Petroni", "Leonardo Querzoni", "Giuseppe Antonio Di Luna"], "title": "ReSIM: Re-ranking Binary Similarity Embeddings to Improve Function Search Performance", "comment": null, "summary": "Binary Function Similarity (BFS), the problem of determining whether two binary functions originate from the same source code, has been extensively studied in recent research across security, software engineering, and machine learning communities. This interest arises from its central role in developing vulnerability detection systems, copyright infringement analysis, and malware phylogeny tools. Nearly all binary function similarity systems embed assembly functions into real-valued vectors, where similar functions map to points that lie close to each other in the metric space. These embeddings enable function search: a query function is embedded and compared against a database of candidate embeddings to retrieve the most similar matches.\n  Despite their effectiveness, such systems rely on bi-encoder architectures that embed functions independently, limiting their ability to capture cross-function relationships and similarities. To address this limitation, we introduce ReSIM, a novel and enhanced function search system that complements embedding-based search with a neural re-ranker. Unlike traditional embedding models, our reranking module jointly processes query-candidate pairs to compute ranking scores based on their mutual representation, allowing for more accurate similarity assessment. By re-ranking the top results from embedding-based retrieval, ReSIM leverages fine-grained relation information that bi-encoders cannot capture.\n  We evaluate ReSIM across seven embedding models on two benchmark datasets, demonstrating consistent improvements in search effectiveness, with average gains of 21.7% in terms of nDCG and 27.8% in terms of Recall.", "AI": {"tldr": "ReSIM\u662f\u4e00\u4e2a\u589e\u5f3a\u7684\u4e8c\u8fdb\u5236\u51fd\u6570\u76f8\u4f3c\u6027\u641c\u7d22\u7cfb\u7edf\uff0c\u901a\u8fc7\u795e\u7ecf\u91cd\u6392\u5e8f\u5668\u8865\u5145\u5d4c\u5165\u641c\u7d22\uff0c\u663e\u8457\u63d0\u5347\u641c\u7d22\u6548\u679c", "motivation": "\u73b0\u6709\u4e8c\u8fdb\u5236\u51fd\u6570\u76f8\u4f3c\u6027\u7cfb\u7edf\u4e3b\u8981\u57fa\u4e8e\u53cc\u7f16\u7801\u5668\u67b6\u6784\uff0c\u8fd9\u4e9b\u67b6\u6784\u72ec\u7acb\u5d4c\u5165\u51fd\u6570\uff0c\u65e0\u6cd5\u6355\u6349\u8de8\u51fd\u6570\u5173\u7cfb\u548c\u76f8\u4f3c\u6027\uff0c\u9650\u5236\u4e86\u641c\u7d22\u51c6\u786e\u6027", "method": "\u63d0\u51faReSIM\u7cfb\u7edf\uff0c\u5728\u5d4c\u5165\u641c\u7d22\u57fa\u7840\u4e0a\u5f15\u5165\u795e\u7ecf\u91cd\u6392\u5e8f\u6a21\u5757\uff0c\u8be5\u6a21\u5757\u8054\u5408\u5904\u7406\u67e5\u8be2-\u5019\u9009\u5bf9\uff0c\u57fa\u4e8e\u5b83\u4eec\u7684\u76f8\u4e92\u8868\u793a\u8ba1\u7b97\u6392\u5e8f\u5206\u6570\uff0c\u4ece\u800c\u66f4\u51c6\u786e\u8bc4\u4f30\u76f8\u4f3c\u6027", "result": "\u57287\u4e2a\u5d4c\u5165\u6a21\u578b\u548c2\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cReSIM\u5728\u641c\u7d22\u6548\u679c\u4e0a\u5b9e\u73b0\u4e00\u81f4\u6539\u8fdb\uff0cnDCG\u5e73\u5747\u63d0\u534721.7%\uff0cRecall\u5e73\u5747\u63d0\u534727.8%", "conclusion": "ReSIM\u901a\u8fc7\u795e\u7ecf\u91cd\u6392\u5e8f\u5668\u8865\u5145\u4f20\u7edf\u5d4c\u5165\u641c\u7d22\uff0c\u80fd\u591f\u6355\u6349\u53cc\u7f16\u7801\u5668\u65e0\u6cd5\u6355\u83b7\u7684\u7ec6\u7c92\u5ea6\u5173\u7cfb\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u4e8c\u8fdb\u5236\u51fd\u6570\u76f8\u4f3c\u6027\u641c\u7d22\u6548\u679c"}}
{"id": "2602.09892", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.09892", "abs": "https://arxiv.org/abs/2602.09892", "authors": ["Jiale Zhao", "Guoxin Chen", "Fanzhe Meng", "Minghao Li", "Jie Chen", "Hui Xu", "Yongshuai Sun", "Xin Zhao", "Ruihua Song", "Yuan Zhang", "Peng Wang", "Cheng Chen", "Jirong Wen", "Kai Jia"], "title": "Immersion in the GitHub Universe: Scaling Coding Agents to Mastery", "comment": null, "summary": "Achieving mastery in real world software engineering tasks is fundamentally bottlenecked by the scarcity of large scale, high quality training data. Scaling such data has been limited by the complexity of environment setup, unit test generation, and problem statement curation. In this paper, we propose ScaleSWE, an automated, sandboxed multi agent workflow designed to construct high quality SWE data at scale. The system coordinates three specialized agents for environment setup, test creation, and problem description synthesis to process 6 million pull requests across 5200 repositories, producing Scale SWE Data: 100k verified SWE instances, the largest such dataset to date. It substantially surpasses existing real world datasets in repository diversity and reflects realistic task complexity. We further demonstrate the dataset utility for training by distilling 71498 high quality trajectories and finetuning Qwen30BA3BInstruct to produce ScaleSWE Agent. Our agent achieves a 64 resolve rate on SWE Bench Verified a nearly three fold improvement over the base model. ScaleSWE provides a scalable, reproducible approach for data construction to advance LLM based software engineering. Scale SWE will be publicly available.", "AI": {"tldr": "ScaleSWE\uff1a\u4e00\u4e2a\u81ea\u52a8\u5316\u3001\u6c99\u7bb1\u5316\u7684\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\uff0c\u901a\u8fc7\u5904\u7406600\u4e07\u4e2aPR\u751f\u621010\u4e07\u4e2a\u5df2\u9a8c\u8bc1\u7684\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u4f8b\uff0c\u662f\u76ee\u524d\u6700\u5927\u7684\u6b64\u7c7b\u6570\u636e\u96c6\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bad\u7ec3\u51fa\u5728SWE Bench\u4e0a\u8fbe\u523064%\u89e3\u51b3\u7387\u7684\u667a\u80fd\u4f53\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u7684\u638c\u63e1\u7a0b\u5ea6\u53d7\u5230\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u7684\u6839\u672c\u6027\u74f6\u9888\u9650\u5236\u3002\u73b0\u6709\u6570\u636e\u7684\u6269\u5c55\u53d7\u5230\u73af\u5883\u8bbe\u7f6e\u590d\u6742\u6027\u3001\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u548c\u95ee\u9898\u9648\u8ff0\u7b56\u5212\u7684\u9650\u5236\u3002", "method": "\u63d0\u51faScaleSWE\u7cfb\u7edf\uff0c\u91c7\u7528\u81ea\u52a8\u5316\u3001\u6c99\u7bb1\u5316\u7684\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\uff0c\u534f\u8c03\u4e09\u4e2a\u4e13\u95e8\u667a\u80fd\u4f53\uff08\u73af\u5883\u8bbe\u7f6e\u3001\u6d4b\u8bd5\u521b\u5efa\u3001\u95ee\u9898\u63cf\u8ff0\u5408\u6210\uff09\u6765\u5904\u74065200\u4e2a\u4ed3\u5e93\u4e2d\u7684600\u4e07\u4e2a\u62c9\u53d6\u8bf7\u6c42\uff0c\u751f\u6210ScaleSWE\u6570\u636e\u96c6\u3002", "result": "\u751f\u6210\u4e8610\u4e07\u4e2a\u5df2\u9a8c\u8bc1\u7684\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u4f8b\uff08\u76ee\u524d\u6700\u5927\u7684\u6b64\u7c7b\u6570\u636e\u96c6\uff09\uff0c\u5728\u4ed3\u5e93\u591a\u6837\u6027\u548c\u4efb\u52a1\u590d\u6742\u6027\u65b9\u9762\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u6570\u636e\u96c6\u3002\u57fa\u4e8e\u6b64\u8bad\u7ec3\u51fa\u7684ScaleSWE\u667a\u80fd\u4f53\u5728SWE Bench Verified\u4e0a\u8fbe\u523064%\u7684\u89e3\u51b3\u7387\uff0c\u76f8\u6bd4\u57fa\u7840\u6a21\u578b\u63d0\u5347\u8fd1\u4e09\u500d\u3002", "conclusion": "ScaleSWE\u4e3a\u6570\u636e\u6784\u5efa\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u53ef\u590d\u73b0\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u63a8\u8fdb\u57fa\u4e8eLLM\u7684\u8f6f\u4ef6\u5de5\u7a0b\u53d1\u5c55\u3002\u8be5\u6570\u636e\u96c6\u5c06\u516c\u5f00\u53ef\u7528\u3002"}}
{"id": "2602.09627", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.09627", "abs": "https://arxiv.org/abs/2602.09627", "authors": ["Dennis Breutigam", "R\u00fcdiger Reischuk"], "title": "Parallel Composition for Statistical Privacy", "comment": "8 pages", "summary": "Differential Privacy (DP) considers a scenario in which an adversary has almost complete information about the entries of a database. This worst-case assumption is likely to overestimate the privacy threat faced by an individual in practice. In contrast, Statistical Privacy (SP), as well as related notions such as noiseless privacy or limited background knowledge privacy, describe a setting in which the adversary knows the distribution of the database entries, but not their exact realizations. In this case, privacy analysis must account for the interaction between uncertainty induced by the entropy of the underlying distributions and privacy mechanisms that distort query answers, which can be highly non-trivial.\n  This paper investigates this problem for multiple queries (composition). A privacy mechanism is proposed that is based on subsampling and randomly partitioning the database to bound the dependency among queries. This way for the first time, to the best of our knowledge, upper privacy bounds against limited adversaries are obtained without any further restriction on the database.\n  These bounds show that in realistic application scenarios taking the entropy of distributions into account yields improvements of privacy and precision guarantees. We illustrate examples where for fixed privacy parameters and utility loss SP allows significantly more queries than DP.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u7edf\u8ba1\u9690\u79c1\uff08SP\uff09\u6846\u67b6\u4e0b\u591a\u67e5\u8be2\u7ec4\u5408\u7684\u9690\u79c1\u4fdd\u62a4\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b50\u91c7\u6837\u548c\u968f\u673a\u5206\u533a\u6570\u636e\u5e93\u7684\u673a\u5236\uff0c\u9996\u6b21\u83b7\u5f97\u4e86\u5bf9\u6709\u9650\u80cc\u666f\u77e5\u8bc6\u653b\u51fb\u8005\u7684\u9690\u79c1\u4e0a\u754c\uff0c\u5c55\u793a\u4e86\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u8003\u8651\u5206\u5e03\u71b5\u53ef\u4ee5\u6539\u5584\u9690\u79c1\u548c\u7cbe\u5ea6\u4fdd\u8bc1\u3002", "motivation": "\u4f20\u7edf\u5dee\u5206\u9690\u79c1\uff08DP\uff09\u5047\u8bbe\u653b\u51fb\u8005\u51e0\u4e4e\u5b8c\u5168\u4e86\u89e3\u6570\u636e\u5e93\u6761\u76ee\uff0c\u8fd9\u79cd\u6700\u574f\u60c5\u51b5\u5047\u8bbe\u53ef\u80fd\u9ad8\u4f30\u5b9e\u9645\u4e2d\u4e2a\u4f53\u9762\u4e34\u7684\u9690\u79c1\u5a01\u80c1\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u7edf\u8ba1\u9690\u79c1\uff08SP\uff09\u53ca\u76f8\u5173\u6982\u5ff5\u8003\u8651\u653b\u51fb\u8005\u53ea\u77e5\u9053\u6570\u636e\u5e93\u6761\u76ee\u7684\u5206\u5e03\u800c\u975e\u5177\u4f53\u5b9e\u73b0\uff0c\u9700\u8981\u5206\u6790\u5e95\u5c42\u5206\u5e03\u71b5\u4e0e\u9690\u79c1\u673a\u5236\u4e4b\u95f4\u7684\u4ea4\u4e92\u4f5c\u7528\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5b50\u91c7\u6837\u548c\u968f\u673a\u5206\u533a\u6570\u636e\u5e93\u7684\u9690\u79c1\u673a\u5236\uff0c\u901a\u8fc7\u9650\u5236\u67e5\u8be2\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\u6765\u4fdd\u62a4\u9690\u79c1\u3002\u8be5\u65b9\u6cd5\u9996\u6b21\u5728\u4e0d\u9650\u5236\u6570\u636e\u5e93\u7684\u60c5\u51b5\u4e0b\uff0c\u83b7\u5f97\u4e86\u9488\u5bf9\u6709\u9650\u80cc\u666f\u77e5\u8bc6\u653b\u51fb\u8005\u7684\u9690\u79c1\u4e0a\u754c\u3002", "result": "\u7814\u7a76\u663e\u793a\uff0c\u5728\u73b0\u5b9e\u5e94\u7528\u573a\u666f\u4e2d\u8003\u8651\u5206\u5e03\u71b5\u53ef\u4ee5\u6539\u5584\u9690\u79c1\u548c\u7cbe\u5ea6\u4fdd\u8bc1\u3002\u5728\u56fa\u5b9a\u9690\u79c1\u53c2\u6570\u548c\u6548\u7528\u635f\u5931\u7684\u60c5\u51b5\u4e0b\uff0cSP\u5141\u8bb8\u7684\u67e5\u8be2\u6570\u91cf\u663e\u8457\u591a\u4e8eDP\u3002\u8bba\u6587\u901a\u8fc7\u793a\u4f8b\u8bf4\u660e\u4e86\u8fd9\u79cd\u4f18\u52bf\u3002", "conclusion": "\u7edf\u8ba1\u9690\u79c1\u6846\u67b6\u6bd4\u4f20\u7edf\u5dee\u5206\u9690\u79c1\u66f4\u8d34\u8fd1\u5b9e\u9645\u5e94\u7528\u573a\u666f\uff0c\u901a\u8fc7\u8003\u8651\u653b\u51fb\u8005\u7684\u6709\u9650\u80cc\u666f\u77e5\u8bc6\u548c\u6570\u636e\u5e93\u5206\u5e03\u7684\u71b5\uff0c\u53ef\u4ee5\u5728\u76f8\u540c\u9690\u79c1\u4fdd\u62a4\u6c34\u5e73\u4e0b\u652f\u6301\u66f4\u591a\u67e5\u8be2\uff0c\u63d0\u4f9b\u66f4\u597d\u7684\u9690\u79c1-\u6548\u7528\u6743\u8861\u3002"}}
{"id": "2602.09485", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09485", "abs": "https://arxiv.org/abs/2602.09485", "authors": ["Yizhi Wang", "Linan Yue", "Min-Ling Zhang"], "title": "Bridging Efficiency and Transparency: Explainable CoT Compression in Multimodal Large Reasoning Models", "comment": null, "summary": "Long chains of thought (Long CoTs) are widely employed in multimodal reasoning models to tackle complex tasks by capturing detailed visual information. However, these Long CoTs are often excessively lengthy and contain redundant reasoning steps, which can hinder inference efficiency. Compressing these long CoTs is a natural solution, yet existing approaches face two major challenges: (1) they may compromise the integrity of visual-textual reasoning by removing essential alignment cues, and (2) the compression process lacks explainability, making it difficult to discern which information is critical. To address these problems, we propose XMCC, an eXplainable Multimodal CoT Compressor that formulates compression as a sequential decision-making process optimized via reinforcement learning. XMCC can effectively shorten reasoning trajectories while preserving key reasoning steps and answer correctness, and simultaneously generates natural-language explanations for its compression decisions. Extensive experiments on representative multimodal reasoning benchmarks demonstrate that XMCC not only reduces reasoning length but also provides explainable explanations, validating its effectiveness.", "AI": {"tldr": "XMCC\u662f\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u591a\u6a21\u6001\u601d\u7ef4\u94fe\u538b\u7f29\u5668\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u5e8f\u5217\u51b3\u7b56\u8fc7\u7a0b\uff0c\u6709\u6548\u7f29\u77ed\u63a8\u7406\u8f68\u8ff9\u540c\u65f6\u4fdd\u6301\u5173\u952e\u63a8\u7406\u6b65\u9aa4\u548c\u7b54\u6848\u6b63\u786e\u6027\uff0c\u5e76\u63d0\u4f9b\u538b\u7f29\u51b3\u7b56\u7684\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u3002", "motivation": "\u957f\u601d\u7ef4\u94fe\u5728\u591a\u6a21\u6001\u63a8\u7406\u4e2d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5f80\u5f80\u8fc7\u4e8e\u5197\u957f\u4e14\u5305\u542b\u5197\u4f59\u63a8\u7406\u6b65\u9aa4\uff0c\u8fd9\u4f1a\u964d\u4f4e\u63a8\u7406\u6548\u7387\u3002\u73b0\u6709\u538b\u7f29\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1)\u53ef\u80fd\u7834\u574f\u89c6\u89c9-\u6587\u672c\u63a8\u7406\u7684\u5b8c\u6574\u6027\uff1b2)\u538b\u7f29\u8fc7\u7a0b\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51faXMCC\uff08\u53ef\u89e3\u91ca\u591a\u6a21\u6001\u601d\u7ef4\u94fe\u538b\u7f29\u5668\uff09\uff0c\u5c06\u538b\u7f29\u5efa\u6a21\u4e3a\u5e8f\u5217\u51b3\u7b56\u8fc7\u7a0b\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u4f18\u5316\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u7f29\u77ed\u63a8\u7406\u8f68\u8ff9\uff0c\u540c\u65f6\u4fdd\u7559\u5173\u952e\u63a8\u7406\u6b65\u9aa4\u548c\u7b54\u6848\u6b63\u786e\u6027\uff0c\u5e76\u4e3a\u538b\u7f29\u51b3\u7b56\u751f\u6210\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u3002", "result": "\u5728\u4ee3\u8868\u6027\u591a\u6a21\u6001\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cXMCC\u4e0d\u4ec5\u51cf\u5c11\u4e86\u63a8\u7406\u957f\u5ea6\uff0c\u8fd8\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u89e3\u91ca\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "XMCC\u89e3\u51b3\u4e86\u957f\u601d\u7ef4\u94fe\u538b\u7f29\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5728\u4fdd\u6301\u63a8\u7406\u5b8c\u6574\u6027\u7684\u540c\u65f6\u63d0\u9ad8\u6548\u7387\uff0c\u5e76\u901a\u8fc7\u53ef\u89e3\u91ca\u7684\u538b\u7f29\u51b3\u7b56\u589e\u5f3a\u4e86\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u548c\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2602.09629", "categories": ["cs.CR", "cs.AI", "cs.CY", "cs.ET", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.09629", "abs": "https://arxiv.org/abs/2602.09629", "authors": ["Hayfa Dhabhi", "Kashyap Thimmaraju"], "title": "Stop Testing Attacks, Start Diagnosing Defenses: The Four-Checkpoint Framework Reveals Where LLM Safety Breaks", "comment": "17 pages, pre-print", "summary": "Large Language Models (LLMs) deploy safety mechanisms to prevent harmful outputs, yet these defenses remain vulnerable to adversarial prompts. While existing research demonstrates that jailbreak attacks succeed, it does not explain \\textit{where} defenses fail or \\textit{why}.\n  To address this gap, we propose that LLM safety operates as a sequential pipeline with distinct checkpoints. We introduce the \\textbf{Four-Checkpoint Framework}, which organizes safety mechanisms along two dimensions: processing stage (input vs.\\ output) and detection level (literal vs.\\ intent). This creates four checkpoints, CP1 through CP4, each representing a defensive layer that can be independently evaluated. We design 13 evasion techniques, each targeting a specific checkpoint, enabling controlled testing of individual defensive layers.\n  Using this framework, we evaluate GPT-5, Claude Sonnet 4, and Gemini 2.5 Pro across 3,312 single-turn, black-box test cases. We employ an LLM-as-judge approach for response classification and introduce Weighted Attack Success Rate (WASR), a severity-adjusted metric that captures partial information leakage overlooked by binary evaluation.\n  Our evaluation reveals clear patterns. Traditional Binary ASR reports 22.6\\% attack success. However, WASR reveals 52.7\\%, a 2.3$\\times$ higher vulnerability. Output-stage defenses (CP3, CP4) prove weakest at 72--79\\% WASR, while input-literal defenses (CP1) are strongest at 13\\% WASR. Claude achieves the strongest safety (42.8\\% WASR), followed by GPT-5 (55.9\\%) and Gemini (59.5\\%).\n  These findings suggest that current defenses are strongest at input-literal checkpoints but remain vulnerable to intent-level manipulation and output-stage techniques. The Four-Checkpoint Framework provides a structured approach for identifying and addressing safety vulnerabilities in deployed systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u56db\u68c0\u67e5\u70b9\u6846\u67b6\u6765\u5206\u6790LLM\u5b89\u5168\u9632\u5fa1\u673a\u5236\uff0c\u53d1\u73b0\u8f93\u51fa\u9636\u6bb5\u7684\u9632\u5fa1\u6700\u5f31\uff0c\u4f20\u7edf\u4e8c\u5143\u8bc4\u4f30\u4e25\u91cd\u4f4e\u4f30\u4e86\u5b89\u5168\u6f0f\u6d1e\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u867d\u7136\u8bc1\u660e\u4e86\u8d8a\u72f1\u653b\u51fb\u7684\u6210\u529f\uff0c\u4f46\u672a\u80fd\u89e3\u91ca\u9632\u5fa1\u673a\u5236\u5728\u4f55\u5904\u5931\u8d25\u4ee5\u53ca\u4e3a\u4f55\u5931\u8d25\u3002\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5730\u5206\u6790LLM\u5b89\u5168\u9632\u5fa1\u7684\u8584\u5f31\u73af\u8282\u3002", "method": "\u63d0\u51fa\u4e86\u56db\u68c0\u67e5\u70b9\u6846\u67b6\uff0c\u5c06\u5b89\u5168\u673a\u5236\u6309\u5904\u7406\u9636\u6bb5\uff08\u8f93\u5165vs\u8f93\u51fa\uff09\u548c\u68c0\u6d4b\u7ea7\u522b\uff08\u5b57\u9762vs\u610f\u56fe\uff09\u7ec4\u7ec7\u6210\u56db\u4e2a\u68c0\u67e5\u70b9\u3002\u8bbe\u8ba1\u4e8613\u79cd\u9488\u5bf9\u7279\u5b9a\u68c0\u67e5\u70b9\u7684\u89c4\u907f\u6280\u672f\uff0c\u4f7f\u7528LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u8fdb\u884c\u5206\u7c7b\uff0c\u5e76\u5f15\u5165\u52a0\u6743\u653b\u51fb\u6210\u529f\u7387\u6765\u6355\u6349\u88ab\u4e8c\u5143\u8bc4\u4f30\u5ffd\u7565\u7684\u90e8\u5206\u4fe1\u606f\u6cc4\u9732\u3002", "result": "\u4f20\u7edf\u4e8c\u5143\u653b\u51fb\u6210\u529f\u7387\u4e3a22.6%\uff0c\u4f46\u52a0\u6743\u653b\u51fb\u6210\u529f\u7387\u663e\u793a\u4e3a52.7%\uff0c\u9ad8\u51fa2.3\u500d\u3002\u8f93\u51fa\u9636\u6bb5\u9632\u5fa1\uff08CP3\u3001CP4\uff09\u6700\u5f31\uff0872-79% WASR\uff09\uff0c\u8f93\u5165\u5b57\u9762\u9632\u5fa1\uff08CP1\uff09\u6700\u5f3a\uff0813% WASR\uff09\u3002Claude\u5b89\u5168\u6027\u6700\u5f3a\uff0842.8% WASR\uff09\uff0c\u5176\u6b21\u662fGPT-5\uff0855.9%\uff09\u548cGemini\uff0859.5%\uff09\u3002", "conclusion": "\u5f53\u524d\u9632\u5fa1\u5728\u8f93\u5165\u5b57\u9762\u68c0\u67e5\u70b9\u6700\u5f3a\uff0c\u4f46\u5728\u610f\u56fe\u7ea7\u64cd\u7eb5\u548c\u8f93\u51fa\u9636\u6bb5\u6280\u672f\u9762\u524d\u4ecd\u7136\u8106\u5f31\u3002\u56db\u68c0\u67e5\u70b9\u6846\u67b6\u4e3a\u8bc6\u522b\u548c\u89e3\u51b3\u90e8\u7f72\u7cfb\u7edf\u4e2d\u7684\u5b89\u5168\u6f0f\u6d1e\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u65b9\u6cd5\u3002"}}
{"id": "2602.09489", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09489", "abs": "https://arxiv.org/abs/2602.09489", "authors": ["Lars Henry Berge Olsen", "Dennis Christensen"], "title": "Computing Conditional Shapley Values Using Tabular Foundation Models", "comment": null, "summary": "Shapley values have become a cornerstone of explainable AI, but they are computationally expensive to use, especially when features are dependent. Evaluating them requires approximating a large number of conditional expectations, either via Monte Carlo integration or regression. Until recently it has not been possible to fully exploit deep learning for the regression approach, because retraining for each conditional expectation takes too long. Tabular foundation models such as TabPFN overcome this computational hurdle by leveraging in-context learning, so each conditional expectation can be approximated without any re-training. In this paper, we compute Shapley values with multiple variants of TabPFN and compare their performance with state-of-the-art methods on both simulated and real datasets. In most cases, TabPFN yields the best performance; where it does not, it is only marginally worse than the best method, at a fraction of the runtime. We discuss further improvements and how tabular foundation models can be better adapted specifically for conditional Shapley value estimation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528TabPFN\u7b49\u8868\u683c\u57fa\u7840\u6a21\u578b\u6765\u9ad8\u6548\u8ba1\u7b97Shapley\u503c\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u65f6\u95f4\u3002", "motivation": "Shapley\u503c\u662f\u89e3\u91ca\u6027AI\u7684\u6838\u5fc3\u5de5\u5177\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u7279\u522b\u662f\u5728\u7279\u5f81\u76f8\u5173\u65f6\u3002\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u8fd1\u4f3c\u5927\u91cf\u6761\u4ef6\u671f\u671b\uff0c\u8981\u4e48\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u79ef\u5206\u8981\u4e48\u901a\u8fc7\u56de\u5f52\u3002\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7531\u4e8e\u9700\u8981\u4e3a\u6bcf\u4e2a\u6761\u4ef6\u671f\u671b\u91cd\u65b0\u8bad\u7ec3\u800c\u6548\u7387\u4f4e\u4e0b\uff0c\u8868\u683c\u57fa\u7840\u6a21\u578b\u5982TabPFN\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u89e3\u51b3\u4e86\u8fd9\u4e00\u8ba1\u7b97\u74f6\u9888\u3002", "method": "\u4f7f\u7528TabPFN\u7684\u591a\u4e2a\u53d8\u4f53\u6765\u8ba1\u7b97Shapley\u503c\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u8fd1\u4f3c\u6761\u4ef6\u671f\u671b\u800c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3002\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u6bd4\u8f83TabPFN\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "result": "\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0cTabPFN\u8868\u73b0\u6700\u4f73\uff1b\u5373\u4f7f\u4e0d\u662f\u6700\u4f73\u65f6\uff0c\u4e5f\u4ec5\u7565\u900a\u4e8e\u6700\u4f73\u65b9\u6cd5\uff0c\u4f46\u8fd0\u884c\u65f6\u95f4\u5927\u5e45\u51cf\u5c11\u3002TabPFN\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u8868\u683c\u57fa\u7840\u6a21\u578b\u5982TabPFN\u4e3a\u9ad8\u6548\u8ba1\u7b97Shapley\u503c\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002\u672a\u6765\u53ef\u4ee5\u8fdb\u4e00\u6b65\u6539\u8fdb\u8868\u683c\u57fa\u7840\u6a21\u578b\uff0c\u4f7f\u5176\u66f4\u597d\u5730\u9002\u5e94\u6761\u4ef6Shapley\u503c\u4f30\u8ba1\u7684\u7279\u5b9a\u9700\u6c42\u3002"}}
{"id": "2602.09930", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.09930", "abs": "https://arxiv.org/abs/2602.09930", "authors": ["Nishil Amin", "Zhiwei Fei", "Xiang Li", "Justyna Petke", "He Ye"], "title": "JMigBench: A Benchmark for Evaluating LLMs on Source Code Migration (Java 8 to Java 11)", "comment": null, "summary": "We build a benchmark to evaluate large language models (LLMs) for source code migration tasks, specifically upgrading functions from Java 8 to Java 11. We first collected a dataset of function pairs from open-source repositories, but limitations in data quality led us to construct a refined dataset covering eight categories of deprecated APIs. Using this dataset, the Mistral Codestral model was evaluated with CodeBLEU and keyword-based metrics to measure lexical and semantic similarity as well as migration correctness. Results show that the evaluated model (Mistral Codestral) can handle trivial one-to-one API substitutions with moderate success, achieving identical migrations in 11.11% of the cases, but it struggles with more complex migrations such as CORBA or JAX-WS. These findings suggest Mistral Codestral can partially reduce developer effort by automating repetitive migration tasks but cannot yet replace humans within the scope of the JMigBench benchmark. The benchmark and analysis provide a foundation for future work on expanding datasets, refining prompting strategies, and improving migration performance across different LLMs.", "AI": {"tldr": "\u6784\u5efa\u4e86JMigBench\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30LLM\u5728Java 8\u523011\u4ee3\u7801\u8fc1\u79fb\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0Mistral Codestral\u80fd\u5904\u7406\u7b80\u5355API\u66ff\u6362\u4f46\u65e0\u6cd5\u5e94\u5bf9\u590d\u6742\u8fc1\u79fb\u573a\u666f\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6e90\u4ee3\u7801\u8fc1\u79fb\u4efb\u52a1\u4e2d\u7684\u5b9e\u9645\u80fd\u529b\uff0c\u7279\u522b\u662fJava\u7248\u672c\u5347\u7ea7\u4e2d\u7684API\u8fc1\u79fb\uff0c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u81ea\u52a8\u5316\u8fc1\u79fb\u5de5\u5177\u7684\u6709\u6548\u6027\u8bc4\u4f30\u3002", "method": "1) \u4ece\u5f00\u6e90\u4ed3\u5e93\u6536\u96c6\u51fd\u6570\u5bf9\u6570\u636e\u96c6\uff1b2) \u6784\u5efa\u5305\u542b8\u7c7b\u5e9f\u5f03API\u7684\u7cbe\u7ec6\u5316\u6570\u636e\u96c6\uff1b3) \u4f7f\u7528Mistral Codestral\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\uff1b4) \u91c7\u7528CodeBLEU\u548c\u57fa\u4e8e\u5173\u952e\u8bcd\u7684\u6307\u6807\u8861\u91cf\u8bcd\u6c47\u3001\u8bed\u4e49\u76f8\u4f3c\u5ea6\u548c\u8fc1\u79fb\u6b63\u786e\u6027\u3002", "result": "Mistral Codestral\u80fd\u4e2d\u7b49\u7a0b\u5ea6\u5904\u7406\u7b80\u5355\u7684\u4e00\u5bf9\u4e00API\u66ff\u6362\uff0811.11%\u5b8c\u5168\u4e00\u81f4\u8fc1\u79fb\uff09\uff0c\u4f46\u5728CORBA\u3001JAX-WS\u7b49\u590d\u6742\u8fc1\u79fb\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u65e0\u6cd5\u5b8c\u5168\u66ff\u4ee3\u4eba\u5de5\u8fc1\u79fb\u3002", "conclusion": "\u5f53\u524dLLM\u80fd\u90e8\u5206\u51cf\u8f7b\u5f00\u53d1\u8005\u5728\u91cd\u590d\u6027\u8fc1\u79fb\u4efb\u52a1\u4e0a\u7684\u8d1f\u62c5\uff0c\u4f46\u5c1a\u4e0d\u80fd\u5b8c\u5168\u66ff\u4ee3\u4eba\u5de5\u3002\u57fa\u51c6\u6d4b\u8bd5\u4e3a\u672a\u6765\u6269\u5c55\u6570\u636e\u96c6\u3001\u4f18\u5316\u63d0\u793a\u7b56\u7565\u548c\u6539\u8fdb\u4e0d\u540cLLM\u8fc1\u79fb\u6027\u80fd\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2602.09707", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.09707", "abs": "https://arxiv.org/abs/2602.09707", "authors": ["Yunusa Simpa Abdulsalam", "Mustapha Hedabou"], "title": "PiTPM: Partially Interactive Signatures for Multi-Device TPM Operations", "comment": "10 pages, 7 figures. the work is still been optimized for scalability", "summary": "Trusted Platform Module (TPM) 2.0 devices provide efficient hardware-based cryptographic security through tamper-resistant key storage and computation, making them ideal building blocks for multi-party signature schemes in distributed systems. However, existing TPM-based multi-signature constructions suffer from a fundamental limitation, they require interactive protocols where all participants must coordinate during the commitment phase, before any signature can be computed. This interactive requirement creates several critical problems, such as synchronization bottlenecks, quadratic communication complexity, and aborted protocols as a result of participant failure. These limitations become particularly heightened for applications that require cross-device cryptographic operations. This paper presents PiTPM, an Aggregator Framework built upon Schnorr's digital signature. Our protocol eliminates the interactive requirement using a hybrid trust architecture. The proposed framework uses pre-shared randomness seeds stored securely in an Aggregator, enabling deterministic computation of global commitments without inter-participant communication. The resulting signatures of the proposed framework are of constant size regardless of signer count. Our experimental results show a possible paradigm shift in TPM-based cryptographic system design, demonstrating that hybrid trust architectures can achieve significant performance improvements while maintaining rigorous security guarantees. We provide a comprehensive formal security analysis proving EU-CMA security under the discrete logarithm assumption in the random oracle model.", "AI": {"tldr": "PiTPM\u662f\u4e00\u4e2a\u57fa\u4e8eTPM 2.0\u7684\u805a\u5408\u5668\u6846\u67b6\uff0c\u91c7\u7528Schnorr\u7b7e\u540d\u65b9\u6848\uff0c\u901a\u8fc7\u6df7\u5408\u4fe1\u4efb\u67b6\u6784\u6d88\u9664\u4e86\u591a\u65b9\u7b7e\u540d\u4e2d\u7684\u4ea4\u4e92\u9700\u6c42\uff0c\u5b9e\u73b0\u4e86\u5e38\u6570\u5927\u5c0f\u7684\u7b7e\u540d\u548c\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eTPM 2.0\u7684\u591a\u65b9\u7b7e\u540d\u65b9\u6848\u5b58\u5728\u6839\u672c\u6027\u9650\u5236\uff1a\u9700\u8981\u6240\u6709\u53c2\u4e0e\u8005\u5728\u627f\u8bfa\u9636\u6bb5\u8fdb\u884c\u4ea4\u4e92\u534f\u8c03\uff0c\u5bfc\u81f4\u540c\u6b65\u74f6\u9888\u3001\u4e8c\u6b21\u901a\u4fe1\u590d\u6742\u5ea6\u548c\u53c2\u4e0e\u8005\u6545\u969c\u5bfc\u81f4\u534f\u8bae\u4e2d\u6b62\u7b49\u95ee\u9898\uff0c\u8fd9\u5728\u8de8\u8bbe\u5907\u52a0\u5bc6\u64cd\u4f5c\u4e2d\u5c24\u4e3a\u7a81\u51fa\u3002", "method": "\u63d0\u51faPiTPM\u805a\u5408\u5668\u6846\u67b6\uff0c\u57fa\u4e8eSchnorr\u6570\u5b57\u7b7e\u540d\uff0c\u91c7\u7528\u6df7\u5408\u4fe1\u4efb\u67b6\u6784\u3002\u6846\u67b6\u4f7f\u7528\u5b58\u50a8\u5728\u805a\u5408\u5668\u4e2d\u7684\u9884\u5171\u4eab\u968f\u673a\u79cd\u5b50\uff0c\u5b9e\u73b0\u65e0\u9700\u53c2\u4e0e\u8005\u95f4\u901a\u4fe1\u7684\u786e\u5b9a\u6027\u5168\u5c40\u627f\u8bfa\u8ba1\u7b97\u3002", "result": "\u63d0\u51fa\u7684\u6846\u67b6\u5b9e\u73b0\u4e86\u5e38\u6570\u5927\u5c0f\u7684\u7b7e\u540d\uff08\u4e0e\u7b7e\u540d\u8005\u6570\u91cf\u65e0\u5173\uff09\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5728TPM\u52a0\u5bc6\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u53ef\u80fd\u5b9e\u73b0\u8303\u5f0f\u8f6c\u53d8\uff0c\u6df7\u5408\u4fe1\u4efb\u67b6\u6784\u5728\u4fdd\u6301\u4e25\u683c\u5b89\u5168\u4fdd\u8bc1\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "PiTPM\u901a\u8fc7\u6df7\u5408\u4fe1\u4efb\u67b6\u6784\u89e3\u51b3\u4e86TPM\u591a\u65b9\u7b7e\u540d\u7684\u4ea4\u4e92\u9650\u5236\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u5b89\u5168\u5206\u6790\u8bc1\u660e\u5176\u5728\u968f\u673a\u9884\u8a00\u6a21\u578b\u4e0b\u57fa\u4e8e\u79bb\u6563\u5bf9\u6570\u5047\u8bbe\u7684EU-CMA\u5b89\u5168\u6027\uff0c\u4e3a\u5206\u5e03\u5f0f\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u591a\u65b9\u7b7e\u540d\u65b9\u6848\u3002"}}
{"id": "2602.09942", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.09942", "abs": "https://arxiv.org/abs/2602.09942", "authors": ["Junjie Luo", "Shangzhou Xia", "Fuyuan Zhang", "Jianjun Zhao"], "title": "QEMI: A Quantum Software Stacks Testing Framework via Equivalence Modulo Inputs", "comment": null, "summary": "As quantum algorithms and hardware continue to evolve, ensuring the correctness of the quantum software stack (QSS) has become increasingly important. However, testing QSSes remains challenging due to the oracle problem, i.e., the lack of a reliable ground truth for expected program behavior. Existing metamorphic testing approaches often rely on equivalent circuit transformations, backend modifications, or parameter tuning to address this issue. In this work, inspired by Equivalence Modulo Inputs (EMI), we propose Quantum EMI (QEMI), a new testing approach for QSSes. Our key contributions include: (1) a random quantum program generator that produces code with dead code based on quantum control-flow structures, and (2) an adaptation of the EMI technique from classical compiler testing to generate variants by removing dead code. By comparing the behavior of these variants, we can detect potential bugs in QSS implementations. We applied QEMI to Qiskit, Q#, and Cirq, and successfully identified 11 crash bugs and 1 behavioral inconsistency. QEMI expands the limited set of testing techniques available for quantum software stacks by going beyond structural transformations and incorporating semantics-preserving ones into quantum program analysis.", "AI": {"tldr": "\u63d0\u51fa\u91cf\u5b50EMI(QEMI)\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u5305\u542b\u6b7b\u4ee3\u7801\u7684\u968f\u673a\u91cf\u5b50\u7a0b\u5e8f\u5e76\u79fb\u9664\u6b7b\u4ee3\u7801\u751f\u6210\u53d8\u4f53\uff0c\u68c0\u6d4b\u91cf\u5b50\u8f6f\u4ef6\u6808\u4e2d\u7684bug", "motivation": "\u968f\u7740\u91cf\u5b50\u7b97\u6cd5\u548c\u786c\u4ef6\u7684\u53d1\u5c55\uff0c\u786e\u4fdd\u91cf\u5b50\u8f6f\u4ef6\u6808\u7684\u6b63\u786e\u6027\u53d8\u5f97\u65e5\u76ca\u91cd\u8981\u3002\u7136\u800c\uff0c\u7531\u4e8eoracle\u95ee\u9898\uff08\u7f3a\u4e4f\u53ef\u9760\u7684\u9884\u671f\u7a0b\u5e8f\u884c\u4e3a\u57fa\u51c6\uff09\uff0c\u6d4b\u8bd5\u91cf\u5b50\u8f6f\u4ef6\u6808\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u57fa\u4e8e\u7b49\u4ef7\u6a21\u8f93\u5165(EMI)\u601d\u60f3\uff0c\u63d0\u51fa\u91cf\u5b50EMI(QEMI)\u65b9\u6cd5\uff1a1) \u57fa\u4e8e\u91cf\u5b50\u63a7\u5236\u6d41\u7ed3\u6784\u751f\u6210\u5305\u542b\u6b7b\u4ee3\u7801\u7684\u968f\u673a\u91cf\u5b50\u7a0b\u5e8f\uff1b2) \u5c06EMI\u6280\u672f\u4ece\u7ecf\u5178\u7f16\u8bd1\u5668\u6d4b\u8bd5\u9002\u914d\u5230\u91cf\u5b50\u9886\u57df\uff0c\u901a\u8fc7\u79fb\u9664\u6b7b\u4ee3\u7801\u751f\u6210\u7a0b\u5e8f\u53d8\u4f53\u3002", "result": "\u5c06QEMI\u5e94\u7528\u4e8eQiskit\u3001Q#\u548cCirq\uff0c\u6210\u529f\u8bc6\u522b\u4e8611\u4e2a\u5d29\u6e83bug\u548c1\u4e2a\u884c\u4e3a\u4e0d\u4e00\u81f4\u95ee\u9898\u3002", "conclusion": "QEMI\u901a\u8fc7\u8d85\u8d8a\u7ed3\u6784\u8f6c\u6362\u5e76\u878d\u5165\u8bed\u4e49\u4fdd\u6301\u8f6c\u6362\u5230\u91cf\u5b50\u7a0b\u5e8f\u5206\u6790\uff0c\u6269\u5c55\u4e86\u91cf\u5b50\u8f6f\u4ef6\u6808\u53ef\u7528\u7684\u6709\u9650\u6d4b\u8bd5\u6280\u672f\u96c6\u3002"}}
{"id": "2602.09944", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.09944", "abs": "https://arxiv.org/abs/2602.09944", "authors": ["Xiang Li", "Zhiwei Fei", "Ying Ma", "Jerry Zhang", "Sarro Federica", "He Ye"], "title": "Environment-in-the-Loop: Rethinking Code Migration with LLM-based Agents", "comment": null, "summary": "Modern software systems continuously undergo code upgrades to enhance functionality, security, and performance, and Large Language Models (LLMs) have demonstrated remarkable capabilities in code migration tasks. However, while research on automated code migration which including refactoring, API adaptation, and dependency updates has advanced rapidly, the exploration of the automated environment interaction that must accompany it remains relatively scarce. In practice, code and its environment are intricately intertwined. Relying solely on static analysis of the environment leads to an inadequate understanding of the target setting, prolongs feedback cycles, and consequently causes significant rework and project delays, thereby reducing overall efficiency. We contend that successful software evolution demands a holistic perspective that integrates both code and environment migration. To understand the current landscape and challenges, we first provide an overview of the status of automated environment construction. We then propose a novel framework paradigm that tightly integrates automated environment setup with the code migration workflow. Finally, we explore the challenges and future directions for automated environment interaction within the code migration domain. Our findings emphasize that without automated environment interaction, the automation of code migration is only half complete.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u5f53\u524d\u4ee3\u7801\u8fc1\u79fb\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4ee3\u7801\u672c\u8eab\uff0c\u800c\u5ffd\u7565\u4e86\u73af\u5883\u4ea4\u4e92\u7684\u81ea\u52a8\u5316\uff0c\u5bfc\u81f4\u5b9e\u9645\u90e8\u7f72\u6548\u7387\u4f4e\u4e0b\u3002\u4f5c\u8005\u63d0\u51fa\u9700\u8981\u5c06\u73af\u5883\u6784\u5efa\u4e0e\u4ee3\u7801\u8fc1\u79fb\u5de5\u4f5c\u6d41\u7d27\u5bc6\u7ed3\u5408\u7684\u6846\u67b6\u3002", "motivation": "\u73b0\u4ee3\u8f6f\u4ef6\u7cfb\u7edf\u9700\u8981\u6301\u7eed\u5347\u7ea7\u4ee3\u7801\u4ee5\u589e\u5f3a\u529f\u80fd\u3001\u5b89\u5168\u6027\u548c\u6027\u80fd\uff0cLLMs\u5728\u4ee3\u7801\u8fc1\u79fb\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002\u7136\u800c\uff0c\u5f53\u524d\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u4ee3\u7801\u8fc1\u79fb\uff08\u91cd\u6784\u3001API\u9002\u914d\u3001\u4f9d\u8d56\u66f4\u65b0\uff09\uff0c\u800c\u5bf9\u5fc5\u987b\u4f34\u968f\u7684\u81ea\u52a8\u5316\u73af\u5883\u4ea4\u4e92\u63a2\u7d22\u76f8\u5bf9\u4e0d\u8db3\u3002\u4ee3\u7801\u4e0e\u73af\u5883\u7d27\u5bc6\u4ea4\u7ec7\uff0c\u4ec5\u4f9d\u8d56\u9759\u6001\u73af\u5883\u5206\u6790\u4f1a\u5bfc\u81f4\u5bf9\u76ee\u6807\u73af\u5883\u7406\u89e3\u4e0d\u8db3\u3001\u53cd\u9988\u5468\u671f\u5ef6\u957f\uff0c\u4ece\u800c\u9020\u6210\u5927\u91cf\u8fd4\u5de5\u548c\u9879\u76ee\u5ef6\u8fdf\uff0c\u964d\u4f4e\u6574\u4f53\u6548\u7387\u3002", "method": "\u9996\u5148\u6982\u8ff0\u81ea\u52a8\u5316\u73af\u5883\u6784\u5efa\u7684\u73b0\u72b6\uff0c\u7136\u540e\u63d0\u51fa\u4e00\u4e2a\u5c06\u81ea\u52a8\u5316\u73af\u5883\u8bbe\u7f6e\u4e0e\u4ee3\u7801\u8fc1\u79fb\u5de5\u4f5c\u6d41\u7d27\u5bc6\u96c6\u6210\u7684\u65b0\u578b\u6846\u67b6\u8303\u5f0f\uff0c\u6700\u540e\u63a2\u7d22\u4ee3\u7801\u8fc1\u79fb\u9886\u57df\u4e2d\u81ea\u52a8\u5316\u73af\u5883\u4ea4\u4e92\u7684\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u6ca1\u6709\u81ea\u52a8\u5316\u73af\u5883\u4ea4\u4e92\uff0c\u4ee3\u7801\u8fc1\u79fb\u7684\u81ea\u52a8\u5316\u53ea\u5b8c\u6210\u4e86\u4e00\u534a\u3002\u6210\u529f\u7684\u8f6f\u4ef6\u6f14\u8fdb\u9700\u8981\u6574\u5408\u4ee3\u7801\u548c\u73af\u5883\u8fc1\u79fb\u7684\u6574\u4f53\u89c6\u89d2\u3002", "conclusion": "\u8bba\u6587\u5f3a\u8c03\u8f6f\u4ef6\u6210\u529f\u6f14\u8fdb\u9700\u8981\u4ee3\u7801\u548c\u73af\u5883\u8fc1\u79fb\u7684\u6574\u4f53\u89c6\u89d2\uff0c\u63d0\u51fa\u5c06\u81ea\u52a8\u5316\u73af\u5883\u8bbe\u7f6e\u4e0e\u4ee3\u7801\u8fc1\u79fb\u5de5\u4f5c\u6d41\u7d27\u5bc6\u7ed3\u5408\u7684\u6846\u67b6\u8303\u5f0f\u662f\u89e3\u51b3\u5f53\u524d\u95ee\u9898\u7684\u5173\u952e\u65b9\u5411\u3002"}}
{"id": "2602.09822", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.09822", "abs": "https://arxiv.org/abs/2602.09822", "authors": ["Giulio Caldarelli"], "title": "From Multi-sig to DLCs: Modern Oracle Designs on Bitcoin", "comment": "Not peer reviewed", "summary": "Unlike Ethereum, which was conceived as a general-purpose smart-contract platform, Bitcoin was designed primarily as a transaction ledger for its native currency, which limits programmability for conditional applications. This constraint is particularly evident when considering oracles, mechanisms that enable Bitcoin contracts to depend on exogenous events. This paper investigates whether new oracle designs have emerged for Bitcoin Layer 1 since the 2015 transition to the Ethereum smart contracts era and whether subsequent Bitcoin improvement proposals have expanded oracles' implementability. Using Scopus and Web of Science searches, complemented by Google Scholar to capture protocol proposals, we observe that the indexed academic coverage remains limited, and many contributions circulate outside journal venues. Within the retrieved corpus, the main post-2015 shift is from multisig-style, which envisioned oracles as co-signers, toward attestation-based designs, mainly represented by Discreet Log Contracts (DLCs), which show stronger Bitcoin community compliance, tool support, and evidence of practical implementations in real-world scenarios such as betting and prediction-market mechanisms.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8c03\u67e5\u4e862015\u5e74\u540e\u6bd4\u7279\u5e01Layer 1\u7684\u9884\u8a00\u673a\u8bbe\u8ba1\u53d1\u5c55\uff0c\u53d1\u73b0\u4e3b\u8981\u4ece\u591a\u7b7e\u6a21\u5f0f\u8f6c\u5411\u57fa\u4e8e\u8bc1\u660e\u7684\u8bbe\u8ba1\uff08\u7279\u522b\u662fDLC\uff09\uff0c\u540e\u8005\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u66f4\u597d\u3002", "motivation": "\u6bd4\u7279\u5e01\u4f5c\u4e3a\u4ea4\u6613\u8d26\u672c\u7684\u8bbe\u8ba1\u9650\u5236\u4e86\u5176\u6761\u4ef6\u5e94\u7528\u7684\u53ef\u7f16\u7a0b\u6027\uff0c\u7279\u522b\u662f\u5728\u4f9d\u8d56\u5916\u90e8\u4e8b\u4ef6\u7684\u9884\u8a00\u673a\u673a\u5236\u65b9\u9762\u3002\u7814\u7a76\u65e8\u5728\u4e86\u89e3\u81ea2015\u5e74\u4ee5\u592a\u574a\u667a\u80fd\u5408\u7ea6\u65f6\u4ee3\u4ee5\u6765\uff0c\u6bd4\u7279\u5e01Layer 1\u662f\u5426\u51fa\u73b0\u4e86\u65b0\u7684\u9884\u8a00\u673a\u8bbe\u8ba1\uff0c\u4ee5\u53ca\u540e\u7eed\u7684\u6bd4\u7279\u5e01\u6539\u8fdb\u63d0\u6848\u662f\u5426\u6269\u5c55\u4e86\u9884\u8a00\u673a\u7684\u53ef\u5b9e\u73b0\u6027\u3002", "method": "\u4f7f\u7528Scopus\u548cWeb of Science\u6570\u636e\u5e93\u8fdb\u884c\u6587\u732e\u68c0\u7d22\uff0c\u5e76\u8f85\u4ee5Google Scholar\u6765\u6355\u6349\u534f\u8bae\u63d0\u6848\uff0c\u5206\u6790\u6bd4\u7279\u5e01Layer 1\u9884\u8a00\u673a\u8bbe\u8ba1\u7684\u53d1\u5c55\u8d8b\u52bf\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5b66\u672f\u6587\u732e\u8986\u76d6\u6709\u9650\uff0c\u8bb8\u591a\u8d21\u732e\u5728\u671f\u520a\u6e20\u9053\u4e4b\u5916\u6d41\u901a\u3002\u4e3b\u8981\u53d8\u5316\u662f\u4ece\u591a\u7b7e\u6a21\u5f0f\uff08\u5c06\u9884\u8a00\u673a\u89c6\u4e3a\u5171\u540c\u7b7e\u540d\u8005\uff09\u8f6c\u5411\u57fa\u4e8e\u8bc1\u660e\u7684\u8bbe\u8ba1\uff0c\u7279\u522b\u662f\u79bb\u6563\u5bf9\u6570\u5408\u7ea6\uff08DLCs\uff09\u3002DLCs\u663e\u793a\u51fa\u66f4\u5f3a\u7684\u6bd4\u7279\u5e01\u793e\u533a\u5408\u89c4\u6027\u3001\u5de5\u5177\u652f\u6301\uff0c\u5e76\u5728\u5b9e\u9645\u573a\u666f\uff08\u5982\u535a\u5f69\u548c\u9884\u6d4b\u5e02\u573a\u673a\u5236\uff09\u4e2d\u6709\u5b9e\u65bd\u8bc1\u636e\u3002", "conclusion": "\u6bd4\u7279\u5e01Layer 1\u7684\u9884\u8a00\u673a\u8bbe\u8ba1\u57282015\u5e74\u540e\u53d1\u751f\u4e86\u663e\u8457\u8f6c\u53d8\uff0c\u4ece\u591a\u7b7e\u6a21\u5f0f\u8f6c\u5411\u57fa\u4e8e\u8bc1\u660e\u7684\u8bbe\u8ba1\uff0c\u5176\u4e2dDLCs\u6210\u4e3a\u4e3b\u6d41\uff0c\u5177\u6709\u66f4\u597d\u7684\u793e\u533a\u652f\u6301\u3001\u5de5\u5177\u751f\u6001\u548c\u5b9e\u9645\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2602.09620", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2602.09620", "abs": "https://arxiv.org/abs/2602.09620", "authors": ["Jorge Fandinno", "Pedro Cabalar", "Philipp Wanko", "Torsten Schaub"], "title": "FLINGO -- Instilling ASP Expressiveness into Linear Integer Constraints", "comment": null, "summary": "Constraint Answer Set Programming (CASP) is a hybrid paradigm that enriches Answer Set Programming (ASP) with numerical constraint processing, something required in many real-world applications. The usual specification of constraints in most CASP solvers is closer to the numerical back-end expressiveness and semantics, rather than to standard specification in ASP. In the latter, numerical attributes are represented with predicates and this allows declaring default values, leaving the attribute undefined, making non-deterministic assignments with choice rules or using aggregated values. In CASP, most (if not all) of these features are lost once we switch to a constraint-based representation of those same attributes. In this paper, we present the FLINGO language (and tool) that incorporates the aforementioned expressiveness inside the numerical constraints and we illustrate its use with several examples. Based on previous work that established its semantic foundations, we also present a translation from the newly introduced FLINGO syntax to regular CASP programs following the CLINGCON input format.", "AI": {"tldr": "FLINGO\u8bed\u8a00\u5c06ASP\u7684\u4e30\u5bcc\u8868\u8fbe\u80fd\u529b\u5f15\u5165\u7ea6\u675fASP\uff0c\u652f\u6301\u9ed8\u8ba4\u503c\u3001\u672a\u5b9a\u4e49\u5c5e\u6027\u3001\u975e\u786e\u5b9a\u6027\u8d4b\u503c\u548c\u805a\u5408\u503c\u7b49\u7279\u6027", "motivation": "\u4f20\u7edf\u7ea6\u675fASP\u4e2d\uff0c\u6570\u503c\u7ea6\u675f\u7684\u8868\u8fbe\u65b9\u5f0f\u66f4\u63a5\u8fd1\u540e\u7aef\u6c42\u89e3\u5668\uff0c\u5931\u53bb\u4e86ASP\u539f\u6709\u7684\u4e30\u5bcc\u8868\u8fbe\u80fd\u529b\uff0c\u5982\u9ed8\u8ba4\u503c\u3001\u672a\u5b9a\u4e49\u5c5e\u6027\u3001\u975e\u786e\u5b9a\u6027\u8d4b\u503c\u548c\u805a\u5408\u503c\u7b49\u7279\u6027", "method": "\u63d0\u51faFLINGO\u8bed\u8a00\u548c\u5de5\u5177\uff0c\u5728\u6570\u503c\u7ea6\u675f\u4e2d\u878d\u5165ASP\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u5e76\u63d0\u4f9b\u4eceFLINGO\u8bed\u6cd5\u5230\u6807\u51c6CASP\u7a0b\u5e8f\uff08CLINGCON\u683c\u5f0f\uff09\u7684\u7ffb\u8bd1\u65b9\u6cd5", "result": "\u5f00\u53d1\u4e86FLINGO\u8bed\u8a00\uff0c\u80fd\u591f\u5728\u7ea6\u675fASP\u4e2d\u4fdd\u7559ASP\u7684\u4e30\u5bcc\u8868\u8fbe\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u591a\u4e2a\u793a\u4f8b\u5c55\u793a\u4e86\u5176\u5e94\u7528", "conclusion": "FLINGO\u6210\u529f\u5c06ASP\u7684\u8868\u8fbe\u80fd\u529b\u5f15\u5165\u7ea6\u675fASP\uff0c\u586b\u8865\u4e86\u4f20\u7edfCASP\u5728\u8868\u8fbe\u80fd\u529b\u4e0a\u7684\u4e0d\u8db3\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u7684\u5efa\u6a21\u5de5\u5177"}}
{"id": "2602.09882", "categories": ["cs.CR", "math.GR"], "pdf": "https://arxiv.org/pdf/2602.09882", "abs": "https://arxiv.org/abs/2602.09882", "authors": ["Asmaa Cherkaoui", "Faraz Heravi", "Delaram Kahrobaei", "Siamak F. Shahandashti"], "title": "Spinel: A Post-Quantum Signature Scheme Based on SLn(Fp) Hashing", "comment": "22 pages, 4 figures", "summary": "The advent of quantum computation compels the cryptographic community to design digital signature schemes whose security extends beyond the classical hardness assumptions. In this work, we introduce Spinel, a post-quantum digital signature scheme that combines the proven security of SPHINCS+ (CCS 2019) with a new family of algebraic hash functions (Adv. Math. Commun. 2025) derived from the Tillich-Zemor paradigm (Eurocrypt 2008) with security rooted in the hardness of navigating expander graphs over SL_n(F_p), a problem believed to be hard even for quantum adversaries. We first provide empirical evidence of the security of this hash function, complementing the original theoretical analysis. We then show how the hash function can be integrated within the SPHINCS+ framework to give a secure signature scheme. We then model and analyze the security degradation of the proposed scheme, which informs the parameter selection we discuss next. Finally, we provide an implementation of the hash function and the proposed signature scheme Spinel as well as detailed empirical results for the performance of Spinel showing its feasibility in practice. Our approach lays the foundations for the design of algebraic hash-based signature schemes, expanding the toolkit of post-quantum cryptography.", "AI": {"tldr": "Spinel\u662f\u4e00\u4e2a\u540e\u91cf\u5b50\u6570\u5b57\u7b7e\u540d\u65b9\u6848\uff0c\u7ed3\u5408\u4e86SPHINCS+\u7684\u5b89\u5168\u6027\u548c\u57fa\u4e8eSL_n(F_p)\u4e0a\u6269\u5c55\u56fe\u5bfc\u822a\u95ee\u9898\u7684\u65b0\u578b\u4ee3\u6570\u54c8\u5e0c\u51fd\u6570\uff0c\u4e3a\u91cf\u5b50\u8ba1\u7b97\u65f6\u4ee3\u63d0\u4f9b\u5b89\u5168\u7b7e\u540d\u65b9\u6848\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u7684\u51fa\u73b0\u8feb\u4f7f\u5bc6\u7801\u5b66\u754c\u8bbe\u8ba1\u8d85\u8d8a\u7ecf\u5178\u786c\u5ea6\u5047\u8bbe\u7684\u6570\u5b57\u7b7e\u540d\u65b9\u6848\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u62b5\u6297\u91cf\u5b50\u653b\u51fb\u7684\u540e\u91cf\u5b50\u5bc6\u7801\u65b9\u6848\u3002", "method": "\u5c06SPHINCS+\u7b7e\u540d\u65b9\u6848\u4e0e\u57fa\u4e8eTillich-Zemor\u8303\u5f0f\u7684\u65b0\u578b\u4ee3\u6570\u54c8\u5e0c\u51fd\u6570\u76f8\u7ed3\u5408\uff0c\u8be5\u54c8\u5e0c\u51fd\u6570\u7684\u5b89\u5168\u6027\u57fa\u4e8eSL_n(F_p)\u4e0a\u6269\u5c55\u56fe\u5bfc\u822a\u95ee\u9898\u7684\u786c\u5ea6\uff0c\u8be5\u95ee\u9898\u88ab\u8ba4\u4e3a\u5bf9\u91cf\u5b50\u653b\u51fb\u4e5f\u662f\u56f0\u96be\u7684\u3002", "result": "\u63d0\u4f9b\u4e86\u54c8\u5e0c\u51fd\u6570\u5b89\u5168\u6027\u7684\u7ecf\u9a8c\u8bc1\u636e\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u5c06\u54c8\u5e0c\u51fd\u6570\u96c6\u6210\u5230SPHINCS+\u6846\u67b6\u4e2d\uff0c\u5206\u6790\u4e86\u5b89\u5168\u9000\u5316\u5e76\u786e\u5b9a\u4e86\u53c2\u6570\u9009\u62e9\uff0c\u5b9e\u73b0\u4e86\u54c8\u5e0c\u51fd\u6570\u548cSpinel\u7b7e\u540d\u65b9\u6848\uff0c\u5e76\u63d0\u4f9b\u4e86\u8be6\u7ec6\u7684\u6027\u80fd\u8bc4\u4f30\u7ed3\u679c\u3002", "conclusion": "Spinel\u4e3a\u4ee3\u6570\u54c8\u5e0c\u57fa\u7b7e\u540d\u65b9\u6848\u7684\u8bbe\u8ba1\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u6269\u5c55\u4e86\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\u7684\u5de5\u5177\u7bb1\uff0c\u5c55\u793a\u4e86\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2602.09653", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09653", "abs": "https://arxiv.org/abs/2602.09653", "authors": ["Shiwei Lyu", "Xidong Wang", "Lei Liu", "Hao Zhu", "Chaohe Zhang", "Jian Wang", "Jinjie Gu", "Benyou Wang", "Yue Shen"], "title": "ClinAlign: Scaling Healthcare Alignment from Clinician Preference", "comment": null, "summary": "Although large language models (LLMs) demonstrate expert-level medical knowledge, aligning their open-ended outputs with fine-grained clinician preferences remains challenging. Existing methods often rely on coarse objectives or unreliable automated judges that are weakly grounded in professional guidelines. We propose a two-stage framework to address this gap. First, we introduce HealthRubrics, a dataset of 7,034 physician-verified preference examples in which clinicians refine LLM-drafted rubrics to meet rigorous medical standards. Second, we distill these rubrics into HealthPrinciples: 119 broadly reusable, clinically grounded principles organized by clinical dimensions, enabling scalable supervision beyond manual annotation. We use HealthPrinciples for (1) offline alignment by synthesizing rubrics for unlabeled queries and (2) an inference-time tool for guided self-revision. A 30B-A3B model trained with our framework achieves 33.4% on HealthBench-Hard, outperforming much larger models including Deepseek-R1 and o3, establishing a resource-efficient baseline for clinical alignment.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u9636\u6bb5\u6846\u67b6\u89e3\u51b3LLM\u533b\u7597\u8f93\u51fa\u4e0e\u4e34\u5e8a\u533b\u751f\u504f\u597d\u5bf9\u9f50\u95ee\u9898\uff1a1)\u521b\u5efa\u533b\u751f\u9a8c\u8bc1\u7684\u504f\u597d\u6570\u636e\u96c6HealthRubrics\uff1b2)\u63d0\u70bc\u4e3a\u53ef\u91cd\u7528\u539f\u5219HealthPrinciples\uff0c\u7528\u4e8e\u79bb\u7ebf\u5bf9\u9f50\u548c\u63a8\u7406\u65f6\u81ea\u4fee\u6b63\uff0c\u5728\u8d44\u6e90\u6709\u9650\u60c5\u51b5\u4e0b\u8d85\u8d8a\u66f4\u5927\u6a21\u578b\u8868\u73b0\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5177\u5907\u4e13\u5bb6\u7ea7\u533b\u5b66\u77e5\u8bc6\uff0c\u4f46\u5176\u5f00\u653e\u5f0f\u8f93\u51fa\u4e0e\u4e34\u5e8a\u533b\u751f\u7ec6\u7c92\u5ea6\u504f\u597d\u7684\u5bf9\u9f50\u4ecd\u7136\u56f0\u96be\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u7c97\u7c92\u5ea6\u76ee\u6807\u6216\u4e0d\u53ef\u9760\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\uff0c\u7f3a\u4e4f\u4e13\u4e1a\u6307\u5357\u7684\u575a\u5b9e\u57fa\u7840\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1)\u521b\u5efaHealthRubrics\u6570\u636e\u96c6\uff0c\u5305\u542b7,034\u4e2a\u533b\u751f\u9a8c\u8bc1\u7684\u504f\u597d\u793a\u4f8b\uff0c\u4e34\u5e8a\u533b\u751f\u5b8c\u5584LLM\u8d77\u8349\u7684\u8bc4\u5206\u6807\u51c6\u4ee5\u6ee1\u8db3\u4e25\u683c\u533b\u5b66\u6807\u51c6\uff1b2)\u63d0\u70bc\u4e3aHealthPrinciples\uff0c\u5305\u542b119\u4e2a\u5e7f\u6cdb\u53ef\u91cd\u7528\u3001\u4e34\u5e8a\u57fa\u7840\u7684\u539f\u5219\uff0c\u6309\u4e34\u5e8a\u7ef4\u5ea6\u7ec4\u7ec7\uff0c\u5b9e\u73b0\u8d85\u8d8a\u624b\u52a8\u6807\u6ce8\u7684\u53ef\u6269\u5c55\u76d1\u7763\u3002", "result": "\u4f7f\u7528\u8be5\u6846\u67b6\u8bad\u7ec3\u768430B-A3B\u6a21\u578b\u5728HealthBench-Hard\u4e0a\u8fbe\u523033.4%\u7684\u51c6\u786e\u7387\uff0c\u8d85\u8d8a\u4e86\u5305\u62ecDeepseek-R1\u548co3\u5728\u5185\u7684\u66f4\u5927\u6a21\u578b\uff0c\u4e3a\u4e34\u5e8a\u5bf9\u9f50\u5efa\u7acb\u4e86\u8d44\u6e90\u9ad8\u6548\u7684\u57fa\u7840\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e24\u9636\u6bb5\u6846\u67b6\u901a\u8fc7\u521b\u5efa\u533b\u751f\u9a8c\u8bc1\u7684\u504f\u597d\u6570\u636e\u96c6\u548c\u63d0\u70bc\u53ef\u91cd\u7528\u4e34\u5e8a\u539f\u5219\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u533b\u7597\u8f93\u51fa\u4e0e\u4e34\u5e8a\u533b\u751f\u504f\u597d\u7684\u5bf9\u9f50\u95ee\u9898\uff0c\u5728\u8d44\u6e90\u6709\u9650\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u4f18\u4e8e\u66f4\u5927\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2602.09905", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.09905", "abs": "https://arxiv.org/abs/2602.09905", "authors": ["Logan Therrien", "John Hastings"], "title": "The Need for Standardized Evidence Sampling in CMMC Assessments: A Survey-Based Analysis of Assessor Practices", "comment": "6 pages, 9 tables", "summary": "The Cybersecurity Maturity Model Certification (CMMC) framework provides a common standard for protecting sensitive unclassified information in defense contracting. While CMMC defines assessment objectives and control requirements, limited formal guidance exists regarding evidence sampling, the process by which assessors select, review, and validate artifacts to substantiate compliance. Analyzing data collected through an anonymous survey of CMMC-certified assessors and lead assessors, this exploratory study investigates whether inconsistencies in evidence sampling practices exist within the CMMC assessment ecosystem and evaluates the need for a risk-informed standardized sampling methodology. Across 17 usable survey responses, results indicate that evidence sampling practices are predominantly driven by assessor judgment, perceived risk, and environmental complexity rather than formalized standards, with formal statistical sampling models rarely referenced. Participants frequently reported inconsistencies across assessments and expressed broad support for the development of standardized guidance, while generally opposing rigid percentage-based requirements. The findings support the conclusion that the absence of a uniform evidence sampling framework introduces variability that may affect assessment reliability and confidence in certification outcomes. Recommendations are provided to inform future CMMC assessment methodology development and further empirical research.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0CMMC\u8bc4\u4f30\u4e2d\u8bc1\u636e\u62bd\u6837\u5b9e\u8df5\u7f3a\u4e4f\u6807\u51c6\u5316\uff0c\u4e3b\u8981\u4f9d\u8d56\u8bc4\u4f30\u5458\u4e3b\u89c2\u5224\u65ad\u800c\u975e\u6b63\u5f0f\u7edf\u8ba1\u65b9\u6cd5\uff0c\u5bfc\u81f4\u8bc4\u4f30\u7ed3\u679c\u4e0d\u4e00\u81f4\u6027\u98ce\u9669", "motivation": "CMMC\u6846\u67b6\u867d\u7136\u5b9a\u4e49\u4e86\u8bc4\u4f30\u76ee\u6807\u548c\u63a7\u5236\u8981\u6c42\uff0c\u4f46\u7f3a\u4e4f\u5173\u4e8e\u8bc1\u636e\u62bd\u6837\u7684\u6b63\u5f0f\u6307\u5bfc\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u8bc4\u4f30\u5b9e\u8df5\u4e0d\u4e00\u81f4\uff0c\u5f71\u54cd\u8ba4\u8bc1\u7ed3\u679c\u7684\u53ef\u9760\u6027", "method": "\u901a\u8fc7\u533f\u540d\u8c03\u67e5\u6536\u96c6CMMC\u8ba4\u8bc1\u8bc4\u4f30\u5458\u548c\u9996\u5e2d\u8bc4\u4f30\u5458\u7684\u6570\u636e\uff0c\u91c7\u7528\u63a2\u7d22\u6027\u7814\u7a76\u65b9\u6cd5\u5206\u6790\u8bc1\u636e\u62bd\u6837\u5b9e\u8df5\u4e2d\u7684\u4e0d\u4e00\u81f4\u6027", "result": "17\u4efd\u6709\u6548\u8c03\u67e5\u663e\u793a\uff0c\u8bc1\u636e\u62bd\u6837\u5b9e\u8df5\u4e3b\u8981\u4f9d\u8d56\u8bc4\u4f30\u5458\u5224\u65ad\u3001\u611f\u77e5\u98ce\u9669\u548c\u73af\u5883\u590d\u6742\u6027\uff0c\u800c\u975e\u6b63\u5f0f\u7edf\u8ba1\u62bd\u6837\u6a21\u578b\uff1b\u53c2\u4e0e\u8005\u666e\u904d\u62a5\u544a\u8bc4\u4f30\u95f4\u5b58\u5728\u4e0d\u4e00\u81f4\uff0c\u652f\u6301\u5236\u5b9a\u6807\u51c6\u5316\u6307\u5bfc\u4f46\u53cd\u5bf9\u50f5\u5316\u7684\u767e\u5206\u6bd4\u8981\u6c42", "conclusion": "\u7f3a\u4e4f\u7edf\u4e00\u7684\u8bc1\u636e\u62bd\u6837\u6846\u67b6\u5f15\u5165\u4e86\u53d8\u5f02\u6027\uff0c\u53ef\u80fd\u5f71\u54cd\u8bc4\u4f30\u53ef\u9760\u6027\u548c\u8ba4\u8bc1\u7ed3\u679c\u7684\u53ef\u4fe1\u5ea6\uff1b\u5efa\u8bae\u4e3a\u672a\u6765CMMC\u8bc4\u4f30\u65b9\u6cd5\u5f00\u53d1\u548c\u5b9e\u8bc1\u7814\u7a76\u63d0\u4f9b\u6307\u5bfc"}}
{"id": "2602.09794", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09794", "abs": "https://arxiv.org/abs/2602.09794", "authors": ["Jiaquan Zhang", "Chaoning Zhang", "Shuxu Chen", "Xudong Wang", "Zhenzhen Huang", "Pengcheng Zheng", "Shuai Yuan", "Sheng Zheng", "Qigan Sun", "Jie Zou", "Lik-Hang Lee", "Yang Yang"], "title": "GHS-TDA: A Synergistic Reasoning Framework Integrating Global Hypothesis Space with Topological Data Analysis", "comment": "23pages", "summary": "Chain-of-Thought (CoT) has been shown to significantly improve the reasoning accuracy of large language models (LLMs) on complex tasks. However, due to the autoregressive, step-by-step generation paradigm, existing CoT methods suffer from two fundamental limitations. First, the reasoning process is highly sensitive to early decisions: once an initial error is introduced, it tends to propagate and amplify through subsequent steps, while the lack of a global coordination and revision mechanism makes such errors difficult to correct, ultimately leading to distorted reasoning chains. Second, current CoT approaches lack structured analysis techniques for filtering redundant reasoning and extracting key reasoning features, resulting in unstable reasoning processes and limited interpretability. To address these issues, we propose GHS-TDA. GHS-TDA first constructs a semantically enriched global hypothesis graph to aggregate, align, and coordinate multiple candidate reasoning paths, thereby providing alternative global correction routes when local reasoning fails. It then applies topological data analysis based on persistent homology to capture stable multi-scale structures, remove redundancy and inconsistencies, and extract a more reliable reasoning skeleton. By jointly leveraging reasoning diversity and topological stability, GHS-TDA achieves self-adaptive convergence, produces high-confidence and interpretable reasoning paths, and consistently outperforms strong baselines in terms of both accuracy and robustness across multiple reasoning benchmarks.", "AI": {"tldr": "GHS-TDA\u901a\u8fc7\u6784\u5efa\u5168\u5c40\u5047\u8bbe\u56fe\u7ed3\u5408\u62d3\u6251\u6570\u636e\u5206\u6790\uff0c\u89e3\u51b3\u4f20\u7edf\u601d\u7ef4\u94fe\u65b9\u6cd5\u4e2d\u65e9\u671f\u9519\u8bef\u4f20\u64ad\u548c\u7f3a\u4e4f\u7ed3\u6784\u5316\u5206\u6790\u7684\u95ee\u9898\uff0c\u63d0\u5347\u63a8\u7406\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u4f20\u7edf\u601d\u7ef4\u94fe\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u6839\u672c\u6027\u5c40\u9650\uff1a1) \u63a8\u7406\u8fc7\u7a0b\u5bf9\u65e9\u671f\u51b3\u7b56\u9ad8\u5ea6\u654f\u611f\uff0c\u4e00\u65e6\u51fa\u73b0\u521d\u59cb\u9519\u8bef\u4f1a\u4f20\u64ad\u653e\u5927\u4e14\u96be\u4ee5\u7ea0\u6b63\uff1b2) \u7f3a\u4e4f\u7ed3\u6784\u5316\u5206\u6790\u6280\u672f\u6765\u8fc7\u6ee4\u5197\u4f59\u63a8\u7406\u548c\u63d0\u53d6\u5173\u952e\u7279\u5f81\uff0c\u5bfc\u81f4\u63a8\u7406\u8fc7\u7a0b\u4e0d\u7a33\u5b9a\u4e14\u53ef\u89e3\u91ca\u6027\u6709\u9650\u3002", "method": "\u63d0\u51faGHS-TDA\u65b9\u6cd5\uff1a\u9996\u5148\u6784\u5efa\u8bed\u4e49\u4e30\u5bcc\u7684\u5168\u5c40\u5047\u8bbe\u56fe\uff0c\u805a\u5408\u3001\u5bf9\u9f50\u548c\u534f\u8c03\u591a\u4e2a\u5019\u9009\u63a8\u7406\u8def\u5f84\uff0c\u4e3a\u5c40\u90e8\u63a8\u7406\u5931\u8d25\u65f6\u63d0\u4f9b\u66ff\u4ee3\u7684\u5168\u5c40\u4fee\u6b63\u8def\u5f84\uff1b\u7136\u540e\u5e94\u7528\u57fa\u4e8e\u6301\u4e45\u540c\u8c03\u7684\u62d3\u6251\u6570\u636e\u5206\u6790\uff0c\u6355\u83b7\u7a33\u5b9a\u7684\u591a\u5c3a\u5ea6\u7ed3\u6784\uff0c\u53bb\u9664\u5197\u4f59\u548c\u4e0d\u4e00\u81f4\u6027\uff0c\u63d0\u53d6\u66f4\u53ef\u9760\u7684\u63a8\u7406\u9aa8\u67b6\u3002", "result": "\u901a\u8fc7\u8054\u5408\u5229\u7528\u63a8\u7406\u591a\u6837\u6027\u548c\u62d3\u6251\u7a33\u5b9a\u6027\uff0cGHS-TDA\u5b9e\u73b0\u4e86\u81ea\u9002\u5e94\u6536\u655b\uff0c\u751f\u6210\u9ad8\u7f6e\u4fe1\u5ea6\u548c\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u8def\u5f84\uff0c\u5728\u591a\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5728\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u5747\u6301\u7eed\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "GHS-TDA\u901a\u8fc7\u5168\u5c40\u534f\u8c03\u548c\u62d3\u6251\u5206\u6790\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u601d\u7ef4\u94fe\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6027\u80fd\uff0c\u4e3a\u590d\u6742\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u548c\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u6846\u67b6\u3002"}}
{"id": "2602.09802", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.09802", "abs": "https://arxiv.org/abs/2602.09802", "authors": ["Manon Reusens", "Sofie Goethals", "Toon Calders", "David Martens"], "title": "Would a Large Language Model Pay Extra for a View? Inferring Willingness to Pay from Subjective Choices", "comment": null, "summary": "As Large Language Models (LLMs) are increasingly deployed in applications such as travel assistance and purchasing support, they are often required to make subjective choices on behalf of users in settings where no objectively correct answer exists. We study LLM decision-making in a travel-assistant context by presenting models with choice dilemmas and analyzing their responses using multinomial logit models to derive implied willingness to pay (WTP) estimates. These WTP values are subsequently compared to human benchmark values from the economics literature. In addition to a baseline setting, we examine how model behavior changes under more realistic conditions, including the provision of information about users' past choices and persona-based prompting. Our results show that while meaningful WTP values can be derived for larger LLMs, they also display systematic deviations at the attribute level. Additionally, they tend to overestimate human WTP overall, particularly when expensive options or business-oriented personas are introduced. Conditioning models on prior preferences for cheaper options yields valuations that are closer to human benchmarks. Overall, our findings highlight both the potential and the limitations of using LLMs for subjective decision support and underscore the importance of careful model selection, prompt design, and user representation when deploying such systems in practice.", "AI": {"tldr": "\u7814\u7a76LLM\u5728\u65c5\u884c\u52a9\u624b\u573a\u666f\u4e2d\u7684\u4e3b\u89c2\u51b3\u7b56\u80fd\u529b\uff0c\u901a\u8fc7\u9009\u62e9\u56f0\u5883\u5b9e\u9a8c\u548c\u591a\u9879logit\u6a21\u578b\u63a8\u5bfc\u9690\u542b\u652f\u4ed8\u610f\u613f\uff0c\u5e76\u4e0e\u4eba\u7c7b\u57fa\u51c6\u5bf9\u6bd4\uff0c\u53d1\u73b0LLM\u80fd\u4ea7\u751f\u6709\u610f\u4e49\u7684WTP\u503c\u4f46\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5dee\u3002", "motivation": "\u968f\u7740LLM\u5728\u65c5\u884c\u52a9\u624b\u7b49\u5e94\u7528\u4e2d\u7684\u90e8\u7f72\u589e\u591a\uff0c\u5b83\u4eec\u7ecf\u5e38\u9700\u8981\u5728\u6ca1\u6709\u5ba2\u89c2\u6b63\u786e\u7b54\u6848\u7684\u60c5\u51b5\u4e0b\u4e3a\u7528\u6237\u505a\u51fa\u4e3b\u89c2\u9009\u62e9\u3002\u7814\u7a76\u65e8\u5728\u8bc4\u4f30LLM\u5728\u8fd9\u79cd\u4e3b\u89c2\u51b3\u7b56\u573a\u666f\u4e2d\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u5176\u9690\u542b\u652f\u4ed8\u610f\u613f\u4e0e\u4eba\u7c7b\u57fa\u51c6\u7684\u5dee\u5f02\u3002", "method": "\u5728\u65c5\u884c\u52a9\u624b\u60c5\u5883\u4e2d\u5411LLM\u5448\u73b0\u9009\u62e9\u56f0\u5883\uff0c\u4f7f\u7528\u591a\u9879logit\u6a21\u578b\u5206\u6790\u54cd\u5e94\u4ee5\u63a8\u5bfc\u9690\u542b\u652f\u4ed8\u610f\u613f\u4f30\u8ba1\u3002\u7814\u7a76\u57fa\u7ebf\u8bbe\u7f6e\u5916\uff0c\u8fd8\u8003\u5bdf\u4e86\u66f4\u73b0\u5b9e\u6761\u4ef6\u4e0b\u7684\u6a21\u578b\u884c\u4e3a\u53d8\u5316\uff0c\u5305\u62ec\u63d0\u4f9b\u7528\u6237\u5386\u53f2\u9009\u62e9\u4fe1\u606f\u548c\u57fa\u4e8e\u89d2\u8272\u7684\u63d0\u793a\u3002", "result": "\u8f83\u5927\u89c4\u6a21\u7684LLM\u80fd\u591f\u4ea7\u751f\u6709\u610f\u4e49\u7684WTP\u503c\uff0c\u4f46\u5728\u5c5e\u6027\u5c42\u9762\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5dee\u3002\u603b\u4f53\u503e\u5411\u4e8e\u9ad8\u4f30\u4eba\u7c7bWTP\uff0c\u7279\u522b\u662f\u5728\u5f15\u5165\u6602\u8d35\u9009\u9879\u6216\u5546\u52a1\u5bfc\u5411\u89d2\u8272\u65f6\u3002\u5f53\u6a21\u578b\u57fa\u4e8e\u5148\u524d\u5bf9\u4fbf\u5b9c\u9009\u9879\u7684\u504f\u597d\u8fdb\u884c\u6761\u4ef6\u5316\u65f6\uff0c\u4f30\u503c\u66f4\u63a5\u8fd1\u4eba\u7c7b\u57fa\u51c6\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u51f8\u663e\u4e86\u4f7f\u7528LLM\u8fdb\u884c\u4e3b\u89c2\u51b3\u7b56\u652f\u6301\u7684\u6f5c\u529b\u548c\u5c40\u9650\u6027\uff0c\u5f3a\u8c03\u4e86\u5728\u5b9e\u9645\u90e8\u7f72\u6b64\u7c7b\u7cfb\u7edf\u65f6\u4ed4\u7ec6\u9009\u62e9\u6a21\u578b\u3001\u8bbe\u8ba1\u63d0\u793a\u548c\u7528\u6237\u8868\u793a\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.10074", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.10074", "abs": "https://arxiv.org/abs/2602.10074", "authors": ["Mariia Ponomarenko", "Sepideh Abedini", "Masoumeh Shafieinejad", "D. B. Emerson", "Shubhankar Mohapatra", "Xi He"], "title": "CAPID: Context-Aware PII Detection for Question-Answering Systems", "comment": "Accepted to the Student Research Workshop at EACL 2026", "summary": "Detecting personally identifiable information (PII) in user queries is critical for ensuring privacy in question-answering systems. Current approaches mainly redact all PII, disregarding the fact that some of them may be contextually relevant to the user's question, resulting in a degradation of response quality. Large language models (LLMs) might be able to help determine which PII are relevant, but due to their closed source nature and lack of privacy guarantees, they are unsuitable for sensitive data processing. To achieve privacy-preserving PII detection, we propose CAPID, a practical approach that fine-tunes a locally owned small language model (SLM) that filters sensitive information before it is passed to LLMs for QA. However, existing datasets do not capture the context-dependent relevance of PII needed to train such a model effectively. To fill this gap, we propose a synthetic data generation pipeline that leverages LLMs to produce a diverse, domain-rich dataset spanning multiple PII types and relevance levels. Using this dataset, we fine-tune an SLM to detect PII spans, classify their types, and estimate contextual relevance. Our experiments show that relevance-aware PII detection with a fine-tuned SLM substantially outperforms existing baselines in span, relevance and type accuracy while preserving significantly higher downstream utility under anonymization.", "AI": {"tldr": "CAPID\uff1a\u4e00\u79cd\u901a\u8fc7\u5fae\u8c03\u672c\u5730\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4PII\u68c0\u6d4b\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u8bc6\u522bPII\u7684\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u4fdd\u6301\u95ee\u7b54\u7cfb\u7edf\u8d28\u91cf", "motivation": "\u5f53\u524dPII\u68c0\u6d4b\u65b9\u6cd5\u901a\u5e38\u76f4\u63a5\u5c4f\u853d\u6240\u6709\u4e2a\u4eba\u4fe1\u606f\uff0c\u5ffd\u7565\u4e86\u5176\u4e2d\u90e8\u5206\u4fe1\u606f\u53ef\u80fd\u5bf9\u7528\u6237\u95ee\u9898\u5177\u6709\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\uff0c\u5bfc\u81f4\u56de\u7b54\u8d28\u91cf\u4e0b\u964d\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u80fd\u5224\u65ad\u76f8\u5173\u6027\uff0c\u4f46\u56e0\u5176\u95ed\u6e90\u7279\u6027\u548c\u7f3a\u4e4f\u9690\u79c1\u4fdd\u969c\uff0c\u4e0d\u9002\u5408\u5904\u7406\u654f\u611f\u6570\u636e\u3002", "method": "\u63d0\u51faCAPID\u65b9\u6cd5\uff1a1\uff09\u4f7f\u7528LLM\u751f\u6210\u5305\u542b\u591a\u79cdPII\u7c7b\u578b\u548c\u76f8\u5173\u6027\u7ea7\u522b\u7684\u5408\u6210\u6570\u636e\u96c6\uff1b2\uff09\u5fae\u8c03\u672c\u5730\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4f7f\u5176\u80fd\u591f\u68c0\u6d4bPII\u8303\u56f4\u3001\u5206\u7c7bPII\u7c7b\u578b\u5e76\u8bc4\u4f30\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\uff1b3\uff09\u5728\u95ee\u7b54\u7cfb\u7edf\u4e2d\uff0c\u5148\u7531SLM\u8fc7\u6ee4\u654f\u611f\u4fe1\u606f\uff0c\u518d\u5c06\u5904\u7406\u540e\u7684\u5185\u5bb9\u4f20\u9012\u7ed9LLM\u8fdb\u884c\u56de\u7b54\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8e\u5fae\u8c03SLM\u7684\u76f8\u5173\u6027\u611f\u77e5PII\u68c0\u6d4b\u5728\u8303\u56f4\u68c0\u6d4b\u3001\u76f8\u5173\u6027\u5224\u65ad\u548c\u7c7b\u578b\u5206\u7c7b\u51c6\u786e\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u5728\u533f\u540d\u5316\u5904\u7406\u4e0b\u4fdd\u6301\u4e86\u66f4\u9ad8\u7684\u4e0b\u6e38\u4efb\u52a1\u6548\u7528\u3002", "conclusion": "CAPID\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u9690\u79c1\u4fdd\u62a4PII\u68c0\u6d4b\u65b9\u6848\uff0c\u901a\u8fc7\u672c\u5730\u5fae\u8c03\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u4e86\u76f8\u5173\u6027\u611f\u77e5\u7684\u654f\u611f\u4fe1\u606f\u8fc7\u6ee4\uff0c\u5728\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u7684\u540c\u65f6\u6700\u5927\u9650\u5ea6\u5730\u4fdd\u6301\u4e86\u95ee\u7b54\u7cfb\u7edf\u7684\u56de\u7b54\u8d28\u91cf\u3002"}}
{"id": "2602.10085", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10085", "abs": "https://arxiv.org/abs/2602.10085", "authors": ["Richard Bornemann", "Pierluigi Vito Amadori", "Antoine Cully"], "title": "CODE-SHARP: Continuous Open-ended Discovery and Evolution of Skills as Hierarchical Reward Programs", "comment": "Preprint", "summary": "Developing agents capable of open-endedly discovering and learning novel skills is a grand challenge in Artificial Intelligence. While reinforcement learning offers a powerful framework for training agents to master complex skills, it typically relies on hand-designed reward functions. This is infeasible for open-ended skill discovery, where the set of meaningful skills is not known a priori. While recent methods have shown promising results towards automating reward function design, they remain limited to refining rewards for pre-defined tasks. To address this limitation, we introduce Continuous Open-ended Discovery and Evolution of Skills as Hierarchical Reward Programs (CODE-SHARP), a novel framework leveraging Foundation Models (FM) to open-endedly expand and refine a hierarchical skill archive, structured as a directed graph of executable reward functions in code. We show that a goal-conditioned agent trained exclusively on the rewards generated by the discovered SHARP skills learns to solve increasingly long-horizon goals in the Craftax environment. When composed by a high-level FM-based planner, the discovered skills enable a single goal-conditioned agent to solve complex, long-horizon tasks, outperforming both pretrained agents and task-specific expert policies by over $134$% on average. We will open-source our code and provide additional videos at https://sites.google.com/view/code-sharp/homepage.", "AI": {"tldr": "CODE-SHARP\u6846\u67b6\u5229\u7528\u57fa\u7840\u6a21\u578b\u81ea\u52a8\u53d1\u73b0\u548c\u6f14\u5316\u5206\u5c42\u6280\u80fd\uff0c\u901a\u8fc7\u4ee3\u7801\u5f62\u5f0f\u7684\u5956\u52b1\u51fd\u6570\u5b9e\u73b0\u5f00\u653e\u5f0f\u7684\u6280\u80fd\u5b66\u4e60\uff0c\u5728Craftax\u73af\u5883\u4e2d\u663e\u8457\u63d0\u5347\u957f\u65f6\u7a0b\u4efb\u52a1\u89e3\u51b3\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u4f9d\u8d56\u4eba\u5de5\u8bbe\u8ba1\u7684\u5956\u52b1\u51fd\u6570\uff0c\u65e0\u6cd5\u9002\u5e94\u5f00\u653e\u5f0f\u7684\u6280\u80fd\u53d1\u73b0\uff0c\u56e0\u4e3a\u6709\u610f\u4e49\u6280\u80fd\u7684\u96c6\u5408\u4e8b\u5148\u672a\u77e5\u3002\u73b0\u6709\u65b9\u6cd5\u4ec5\u9650\u4e8e\u4e3a\u9884\u5b9a\u4e49\u4efb\u52a1\u4f18\u5316\u5956\u52b1\u51fd\u6570\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u81ea\u52a8\u53d1\u73b0\u548c\u6f14\u5316\u65b0\u6280\u80fd\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51faCODE-SHARP\u6846\u67b6\uff0c\u5229\u7528\u57fa\u7840\u6a21\u578b\u5f00\u653e\u5730\u6269\u5c55\u548c\u7cbe\u70bc\u5206\u5c42\u6280\u80fd\u6863\u6848\uff0c\u8be5\u6863\u6848\u4ee5\u53ef\u6267\u884c\u5956\u52b1\u51fd\u6570\u4ee3\u7801\u7684\u6709\u5411\u56fe\u5f62\u5f0f\u7ec4\u7ec7\u3002\u901a\u8fc7\u9ad8\u5c42\u57fa\u7840\u6a21\u578b\u89c4\u5212\u5668\u7ec4\u5408\u53d1\u73b0\u7684\u6280\u80fd\uff0c\u4f7f\u5355\u4e2a\u76ee\u6807\u6761\u4ef6\u667a\u80fd\u4f53\u80fd\u591f\u89e3\u51b3\u590d\u6742\u7684\u957f\u65f6\u7a0b\u4efb\u52a1\u3002", "result": "\u5728Craftax\u73af\u5883\u4e2d\uff0c\u4ec5\u4f7f\u7528\u53d1\u73b0\u7684SHARP\u6280\u80fd\u751f\u6210\u7684\u5956\u52b1\u8fdb\u884c\u8bad\u7ec3\u7684\u76ee\u6807\u6761\u4ef6\u667a\u80fd\u4f53\uff0c\u80fd\u591f\u89e3\u51b3\u8d8a\u6765\u8d8a\u957f\u7684\u65f6\u7a0b\u76ee\u6807\u3002\u5f53\u7531\u9ad8\u5c42\u57fa\u7840\u6a21\u578b\u89c4\u5212\u5668\u7ec4\u5408\u65f6\uff0c\u8be5\u667a\u80fd\u4f53\u5728\u590d\u6742\u957f\u65f6\u7a0b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u5e73\u5747\u8d85\u8fc7\u9884\u8bad\u7ec3\u667a\u80fd\u4f53\u548c\u4efb\u52a1\u7279\u5b9a\u4e13\u5bb6\u7b56\u7565134%\u4ee5\u4e0a\u3002", "conclusion": "CODE-SHARP\u6846\u67b6\u901a\u8fc7\u81ea\u52a8\u53d1\u73b0\u548c\u6f14\u5316\u5206\u5c42\u6280\u80fd\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u5f00\u653e\u5f0f\u6280\u80fd\u5b66\u4e60\u7684\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u667a\u80fd\u4f53\u5728\u590d\u6742\u957f\u65f6\u7a0b\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u4e3a\u5f00\u653e\u5f0f\u7684\u6280\u80fd\u53d1\u73b0\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.10090", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10090", "abs": "https://arxiv.org/abs/2602.10090", "authors": ["Zhaoyang Wang", "Canwen Xu", "Boyi Liu", "Yite Wang", "Siwei Han", "Zhewei Yao", "Huaxiu Yao", "Yuxiong He"], "title": "Agent World Model: Infinity Synthetic Environments for Agentic Reinforcement Learning", "comment": "41 pages", "summary": "Recent advances in large language model (LLM) have empowered autonomous agents to perform complex tasks that require multi-turn interactions with tools and environments. However, scaling such agent training is limited by the lack of diverse and reliable environments. In this paper, we propose Agent World Model (AWM), a fully synthetic environment generation pipeline. Using this pipeline, we scale to 1,000 environments covering everyday scenarios, in which agents can interact with rich toolsets (35 tools per environment on average) and obtain high-quality observations. Notably, these environments are code-driven and backed by databases, providing more reliable and consistent state transitions than environments simulated by LLMs. Moreover, they enable more efficient agent interaction compared with collecting trajectories from realistic environments. To demonstrate the effectiveness of this resource, we perform large-scale reinforcement learning for multi-turn tool-use agents. Thanks to the fully executable environments and accessible database states, we can also design reliable reward functions. Experiments on three benchmarks show that training exclusively in synthetic environments, rather than benchmark-specific ones, yields strong out-of-distribution generalization. The code is available at https://github.com/Snowflake-Labs/agent-world-model.", "AI": {"tldr": "\u63d0\u51faAgent World Model (AWM)\u5408\u6210\u73af\u5883\u751f\u6210\u7ba1\u9053\uff0c\u521b\u5efa1000\u4e2a\u65e5\u5e38\u573a\u666f\u73af\u5883\uff0c\u914d\u5907\u4e30\u5bcc\u5de5\u5177\u96c6\uff0c\u7528\u4e8e\u5927\u89c4\u6a21\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u591a\u8f6e\u5de5\u5177\u4f7f\u7528\u667a\u80fd\u4f53\uff0c\u5b9e\u73b0\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8d4b\u80fd\u81ea\u4e3b\u667a\u80fd\u4f53\u6267\u884c\u590d\u6742\u4efb\u52a1\uff0c\u4f46\u667a\u80fd\u4f53\u8bad\u7ec3\u53d7\u9650\u4e8e\u7f3a\u4e4f\u591a\u6837\u53ef\u9760\u7684\u73af\u5883\u3002\u73b0\u6709\u73af\u5883\u6a21\u62df\u5b58\u5728\u53ef\u9760\u6027\u3001\u4e00\u81f4\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faAgent World Model (AWM)\u5408\u6210\u73af\u5883\u751f\u6210\u7ba1\u9053\uff0c\u521b\u5efa1000\u4e2a\u4ee3\u7801\u9a71\u52a8\u3001\u6570\u636e\u5e93\u652f\u6301\u7684\u73af\u5883\uff0c\u5e73\u5747\u6bcf\u4e2a\u73af\u5883\u914d\u590735\u4e2a\u5de5\u5177\uff0c\u63d0\u4f9b\u9ad8\u8d28\u91cf\u89c2\u6d4b\u548c\u53ef\u9760\u72b6\u6001\u8f6c\u6362\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0c\u4ec5\u4f7f\u7528\u5408\u6210\u73af\u5883\u8bad\u7ec3\uff08\u800c\u975e\u57fa\u51c6\u7279\u5b9a\u73af\u5883\uff09\u7684\u667a\u80fd\u4f53\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u5206\u5e03\u5916\u6cdb\u5316\u80fd\u529b\u3002\u4ee3\u7801\u9a71\u52a8\u73af\u5883\u652f\u6301\u53ef\u9760\u5956\u52b1\u51fd\u6570\u8bbe\u8ba1\u3002", "conclusion": "AWM\u5408\u6210\u73af\u5883\u751f\u6210\u7ba1\u9053\u4e3a\u5927\u89c4\u6a21\u667a\u80fd\u4f53\u8bad\u7ec3\u63d0\u4f9b\u4e86\u9ad8\u8d28\u91cf\u3001\u53ef\u9760\u7684\u73af\u5883\u8d44\u6e90\uff0c\u89e3\u51b3\u4e86\u73af\u5883\u7a00\u7f3a\u95ee\u9898\uff0c\u652f\u6301\u9ad8\u6548\u5f3a\u5316\u5b66\u4e60\u5e76\u5b9e\u73b0\u5f3a\u6cdb\u5316\u6027\u80fd\u3002"}}
