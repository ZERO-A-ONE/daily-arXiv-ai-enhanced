{"id": "2601.01042", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.01042", "abs": "https://arxiv.org/abs/2601.01042", "authors": ["Zixiao Zhao", "Yanjie Jiang", "Hui Liu", "Kui Liu", "Lu Zhang"], "title": "SeRe: A Security-Related Code Review Dataset Aligned with Real-World Review Activities", "comment": "Accepted by ICSE 2026", "summary": "Software security vulnerabilities can lead to severe consequences, making early detection essential. Although code review serves as a critical defense mechanism against security flaws, relevant feedback remains scarce due to limited attention to security issues or a lack of expertise among reviewers. Existing datasets and studies primarily focus on general-purpose code review comments, either lacking security-specific annotations or being too limited in scale to support large-scale research. To bridge this gap, we introduce \\textbf{SeRe}, a \\textbf{security-related code review dataset}, constructed using an active learning-based ensemble classification approach. The proposed approach iteratively refines model predictions through human annotations, achieving high precision while maintaining reasonable recall. Using the fine-tuned ensemble classifier, we extracted 6,732 security-related reviews from 373,824 raw review instances, ensuring representativeness across multiple programming languages. Statistical analysis indicates that SeRe generally \\textbf{aligns with real-world security-related review distribution}. To assess both the utility of SeRe and the effectiveness of existing code review comment generation approaches, we benchmark state-of-the-art approaches on security-related feedback generation. By releasing SeRe along with our benchmark results, we aim to advance research in automated security-focused code review and contribute to the development of more effective secure software engineering practices.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86SeRe\u6570\u636e\u96c6\uff0c\u8fd9\u662f\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9\u5b89\u5168\u76f8\u5173\u4ee3\u7801\u5ba1\u67e5\u7684\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u4e3b\u52a8\u5b66\u4e60\u96c6\u6210\u5206\u7c7b\u65b9\u6cd5\u4ece373,824\u6761\u539f\u59cb\u5ba1\u67e5\u4e2d\u63d0\u53d6\u4e866,732\u6761\u5b89\u5168\u76f8\u5173\u5ba1\u67e5\uff0c\u586b\u8865\u4e86\u73b0\u6709\u6570\u636e\u96c6\u7f3a\u4e4f\u5b89\u5168\u7279\u5b9a\u6807\u6ce8\u7684\u7a7a\u767d\u3002", "motivation": "\u8f6f\u4ef6\u5b89\u5168\u6f0f\u6d1e\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u540e\u679c\uff0c\u65e9\u671f\u68c0\u6d4b\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136\u4ee3\u7801\u5ba1\u67e5\u662f\u9632\u6b62\u5b89\u5168\u7f3a\u9677\u7684\u5173\u952e\u9632\u5fa1\u673a\u5236\uff0c\u4f46\u7531\u4e8e\u5ba1\u67e5\u8005\u5bf9\u5b89\u5168\u95ee\u9898\u5173\u6ce8\u4e0d\u8db3\u6216\u7f3a\u4e4f\u4e13\u4e1a\u77e5\u8bc6\uff0c\u76f8\u5173\u53cd\u9988\u4ecd\u7136\u7a00\u7f3a\u3002\u73b0\u6709\u6570\u636e\u96c6\u548c\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u901a\u7528\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\uff0c\u8981\u4e48\u7f3a\u4e4f\u5b89\u5168\u7279\u5b9a\u6807\u6ce8\uff0c\u8981\u4e48\u89c4\u6a21\u592a\u5c0f\u65e0\u6cd5\u652f\u6301\u5927\u89c4\u6a21\u7814\u7a76\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u4e3b\u52a8\u5b66\u4e60\u7684\u96c6\u6210\u5206\u7c7b\u65b9\u6cd5\u6784\u5efa\u6570\u636e\u96c6\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u4eba\u5de5\u6807\u6ce8\u8fed\u4ee3\u4f18\u5316\u6a21\u578b\u9884\u6d4b\uff0c\u5728\u4fdd\u6301\u5408\u7406\u53ec\u56de\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u3002\u4f7f\u7528\u5fae\u8c03\u7684\u96c6\u6210\u5206\u7c7b\u5668\u4ece373,824\u6761\u539f\u59cb\u5ba1\u67e5\u5b9e\u4f8b\u4e2d\u63d0\u53d6\u4e866,732\u6761\u5b89\u5168\u76f8\u5173\u5ba1\u67e5\uff0c\u786e\u4fdd\u8de8\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\u7684\u4ee3\u8868\u6027\u3002", "result": "\u6784\u5efa\u4e86SeRe\u5b89\u5168\u76f8\u5173\u4ee3\u7801\u5ba1\u67e5\u6570\u636e\u96c6\uff0c\u5305\u542b6,732\u6761\u5b89\u5168\u76f8\u5173\u5ba1\u67e5\u3002\u7edf\u8ba1\u5206\u6790\u8868\u660eSeRe\u603b\u4f53\u4e0a\u4e0e\u73b0\u5b9e\u4e16\u754c\u5b89\u5168\u76f8\u5173\u5ba1\u67e5\u5206\u5e03\u4e00\u81f4\u3002\u901a\u8fc7\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u4e86\u73b0\u6709\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u751f\u6210\u65b9\u6cd5\u5728\u5b89\u5168\u76f8\u5173\u53cd\u9988\u751f\u6210\u65b9\u9762\u7684\u6548\u679c\u3002", "conclusion": "\u901a\u8fc7\u53d1\u5e03SeRe\u6570\u636e\u96c6\u548c\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\uff0c\u65e8\u5728\u63a8\u8fdb\u81ea\u52a8\u5316\u5b89\u5168\u5bfc\u5411\u4ee3\u7801\u5ba1\u67e5\u7684\u7814\u7a76\uff0c\u4e3a\u5f00\u53d1\u66f4\u6709\u6548\u7684\u5b89\u5168\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\u505a\u51fa\u8d21\u732e\u3002\u8be5\u6570\u636e\u96c6\u586b\u8865\u4e86\u5b89\u5168\u7279\u5b9a\u4ee3\u7801\u5ba1\u67e5\u6570\u636e\u96c6\u7684\u7a7a\u767d\uff0c\u652f\u6301\u5927\u89c4\u6a21\u7814\u7a76\u3002"}}
{"id": "2601.01129", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.01129", "abs": "https://arxiv.org/abs/2601.01129", "authors": ["Kla Tantithamthavorn", "Yaotian Zou", "Andy Wong", "Michael Gupta", "Zhe Wang", "Mike Buller", "Ryan Jiang", "Matthew Watson", "Minwoo Jeong", "Kun Chen", "Ming Wu"], "title": "RovoDev Code Reviewer: A Large-Scale Online Evaluation of LLM-based Code Review Automation at Atlassian", "comment": "Accepted at the 48th International Conference on Software Engineering (ICSE'26), SEIP Track. 12 Pages", "summary": "Large Language Models (LLMs)-powered code review automation has the potential to transform code review workflows. Despite the advances of LLM-powered code review comment generation approaches, several practical challenges remain for designing enterprise-grade code review automation tools. In particular, this paper aims at answering the practical question: how can we design a review-guided, context-aware, quality-checked code review comment generation without fine-tuning?\n  In this paper, we present RovoDev Code Reviewer, an enterprise-grade LLM-based code review automation tool designed and deployed at scale within Atlassian's development ecosystem with seamless integration into Atlassian's Bitbucket. Through the offline, online, user feedback evaluations over a one-year period, we conclude that RovoDev Code Reviewer is (1) effective in generating code review comments that could lead to code resolution for 38.70% (i.e., comments that triggered code changes in the subsequent commits); and (2) offers the promise of accelerating feedback cycles (i.e., decreasing the PR cycle time by 30.8%), alleviating reviewer workload (i.e., reducing the number of human-written comments by 35.6%), and improving overall software quality (i.e., finding errors with actionable suggestions).", "AI": {"tldr": "RovoDev Code Reviewer\u662f\u4e00\u4e2a\u4f01\u4e1a\u7ea7LLM\u4ee3\u7801\u5ba1\u67e5\u81ea\u52a8\u5316\u5de5\u5177\uff0c\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u751f\u6210\u57fa\u4e8e\u5ba1\u67e5\u6307\u5bfc\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u548c\u8d28\u91cf\u68c0\u67e5\u7684\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\uff0c\u5728Atlassian\u7684Bitbucket\u4e2d\u5927\u89c4\u6a21\u90e8\u7f72\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4ee3\u7801\u5ba1\u67e5\u6548\u7387\u548c\u8d28\u91cf\u3002", "motivation": "\u5c3d\u7ba1LLM\u9a71\u52a8\u7684\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u751f\u6210\u65b9\u6cd5\u6709\u6240\u8fdb\u5c55\uff0c\u4f46\u8bbe\u8ba1\u4f01\u4e1a\u7ea7\u4ee3\u7801\u5ba1\u67e5\u81ea\u52a8\u5316\u5de5\u5177\u4ecd\u9762\u4e34\u5b9e\u9645\u6311\u6218\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u4e00\u4e2a\u5b9e\u9645\u95ee\u9898\uff1a\u5982\u4f55\u5728\u4e0d\u8fdb\u884c\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\uff0c\u8bbe\u8ba1\u4e00\u4e2a\u57fa\u4e8e\u5ba1\u67e5\u6307\u5bfc\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u548c\u8d28\u91cf\u68c0\u67e5\u7684\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u751f\u6210\u7cfb\u7edf\u3002", "method": "\u5f00\u53d1\u4e86RovoDev Code Reviewer\uff0c\u8fd9\u662f\u4e00\u4e2a\u4f01\u4e1a\u7ea7LLM\u4ee3\u7801\u5ba1\u67e5\u81ea\u52a8\u5316\u5de5\u5177\uff0c\u5728Atlassian\u7684\u5f00\u53d1\u751f\u6001\u7cfb\u7edf\u4e2d\u8bbe\u8ba1\u548c\u90e8\u7f72\uff0c\u5e76\u4e0eBitbucket\u65e0\u7f1d\u96c6\u6210\u3002\u91c7\u7528\u79bb\u7ebf\u3001\u5728\u7ebf\u548c\u7528\u6237\u53cd\u9988\u8bc4\u4f30\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u8fdb\u884c\u4e3a\u671f\u4e00\u5e74\u7684\u8bc4\u4f30\u3002", "result": "RovoDev Code Reviewer\u572838.70%\u7684\u60c5\u51b5\u4e0b\u751f\u6210\u80fd\u5bfc\u81f4\u4ee3\u7801\u89e3\u51b3\u7684\u5ba1\u67e5\u8bc4\u8bba\uff08\u5373\u89e6\u53d1\u540e\u7eed\u63d0\u4ea4\u4e2d\u4ee3\u7801\u66f4\u6539\u7684\u8bc4\u8bba\uff09\u3002\u8be5\u5de5\u5177\u80fd\u591f\u52a0\u901f\u53cd\u9988\u5468\u671f\uff08\u51cf\u5c11PR\u5468\u671f\u65f6\u95f430.8%\uff09\u3001\u51cf\u8f7b\u5ba1\u67e5\u5458\u5de5\u4f5c\u91cf\uff08\u51cf\u5c11\u4eba\u5de5\u7f16\u5199\u8bc4\u8bba35.6%\uff09\uff0c\u5e76\u63d0\u9ad8\u6574\u4f53\u8f6f\u4ef6\u8d28\u91cf\uff08\u53d1\u73b0\u9519\u8bef\u5e76\u63d0\u4f9b\u53ef\u884c\u5efa\u8bae\uff09\u3002", "conclusion": "RovoDev Code Reviewer\u662f\u4e00\u4e2a\u6709\u6548\u7684\u4f01\u4e1a\u7ea7\u4ee3\u7801\u5ba1\u67e5\u81ea\u52a8\u5316\u5de5\u5177\uff0c\u901a\u8fc7LLM\u6280\u672f\u5728\u4e0d\u8fdb\u884c\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u7684\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u751f\u6210\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5f00\u53d1\u6548\u7387\u548c\u8f6f\u4ef6\u8d28\u91cf\uff0c\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u4ef7\u503c\u3002"}}
{"id": "2601.01199", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.01199", "abs": "https://arxiv.org/abs/2601.01199", "authors": ["Logan Murphy", "Aren A. Babikian", "Marsha Chechik"], "title": "Abductive Vibe Coding (Extended Abstract)", "comment": null, "summary": "When software artifacts are generated by AI models (\"vibe coding\"), human engineers assume responsibility for validating them. Ideally, this validation would be done through the creation of a formal proof of correctness. However, this is infeasible for many real-world vibe coding scenarios, especially when requirements for the AI-generated artifacts resist formalization. This extended abstract describes ongoing work towards the extraction of analyzable, semi-formal rationales for the adequacy of vibe-coded artifacts. Rather than deciding correctness directly, our framework produces a set of conditions under which the generated code can be considered adequate. We describe current efforts towards implementing our framework and anticipated research opportunities.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u6846\u67b6\uff0c\u7528\u4e8e\u4e3aAI\u751f\u6210\u7684\u4ee3\u7801\u63d0\u53d6\u53ef\u5206\u6790\u3001\u534a\u5f62\u5f0f\u5316\u7684\u5408\u7406\u6027\u4f9d\u636e\uff0c\u800c\u4e0d\u662f\u76f4\u63a5\u5224\u65ad\u6b63\u786e\u6027\uff0c\u800c\u662f\u751f\u6210\u4e00\u7ec4\u6761\u4ef6\uff0c\u5728\u8fd9\u4e9b\u6761\u4ef6\u4e0b\u751f\u6210\u7684\u4ee3\u7801\u53ef\u4ee5\u88ab\u8ba4\u4e3a\u662f\u5145\u5206\u7684\u3002", "motivation": "\u5f53AI\u6a21\u578b\u751f\u6210\u8f6f\u4ef6\u5de5\u4ef6\uff08\"\u6c1b\u56f4\u7f16\u7801\"\uff09\u65f6\uff0c\u4eba\u7c7b\u5de5\u7a0b\u5e08\u9700\u8981\u8d1f\u8d23\u9a8c\u8bc1\u5b83\u4eec\u3002\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u8fd9\u79cd\u9a8c\u8bc1\u5e94\u8be5\u901a\u8fc7\u521b\u5efa\u5f62\u5f0f\u5316\u7684\u6b63\u786e\u6027\u8bc1\u660e\u6765\u5b8c\u6210\uff0c\u4f46\u5bf9\u4e8e\u8bb8\u591a\u73b0\u5b9e\u4e16\u754c\u7684\u6c1b\u56f4\u7f16\u7801\u573a\u666f\u6765\u8bf4\uff0c\u7279\u522b\u662f\u5f53AI\u751f\u6210\u5de5\u4ef6\u7684\u9700\u6c42\u96be\u4ee5\u5f62\u5f0f\u5316\u65f6\uff0c\u8fd9\u662f\u4e0d\u53ef\u884c\u7684\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u53d6\u53ef\u5206\u6790\u3001\u534a\u5f62\u5f0f\u5316\u7684\u5408\u7406\u6027\u4f9d\u636e\uff0c\u4ee5\u8bc4\u4f30\u6c1b\u56f4\u7f16\u7801\u5de5\u4ef6\u7684\u5145\u5206\u6027\u3002\u8be5\u6846\u67b6\u4e0d\u76f4\u63a5\u51b3\u5b9a\u6b63\u786e\u6027\uff0c\u800c\u662f\u751f\u6210\u4e00\u7ec4\u6761\u4ef6\uff0c\u5728\u8fd9\u4e9b\u6761\u4ef6\u4e0b\u751f\u6210\u7684\u4ee3\u7801\u53ef\u4ee5\u88ab\u8ba4\u4e3a\u662f\u5145\u5206\u7684\u3002", "result": "\u8bba\u6587\u63cf\u8ff0\u4e86\u5f53\u524d\u5b9e\u73b0\u8be5\u6846\u67b6\u7684\u52aa\u529b\u548c\u9884\u671f\u7684\u7814\u7a76\u673a\u4f1a\uff0c\u8fd9\u662f\u4e00\u4e2a\u6b63\u5728\u8fdb\u884c\u7684\u5de5\u4f5c\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u96be\u4ee5\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684AI\u751f\u6210\u4ee3\u7801\u63d0\u4f9b\u4e86\u4e00\u79cd\u66ff\u4ee3\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u53d6\u534a\u5f62\u5f0f\u5316\u7684\u5408\u7406\u6027\u4f9d\u636e\u548c\u5145\u5206\u6027\u6761\u4ef6\uff0c\u4f7f\u5de5\u7a0b\u5e08\u80fd\u591f\u66f4\u6709\u6548\u5730\u8bc4\u4f30\u6c1b\u56f4\u7f16\u7801\u5de5\u4ef6\u7684\u8d28\u91cf\u3002"}}
{"id": "2601.01215", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01215", "abs": "https://arxiv.org/abs/2601.01215", "authors": ["Prateek Rajput", "Yewei Song", "Abdoul Aziz Bonkoungou", "Iyiola E. Olatunji", "Abdoul Kader Kabore", "Jacques Klein", "Tegawend\u00e9 F. Bissyand\u00e9"], "title": "Correctness isnt Efficiency: Runtime Memory Divergence in LLM-Generated Code", "comment": "11 Pages, 11 figures, Accepted at ICSE SEIP", "summary": "Large language models (LLMs) can generate programs that pass unit tests, but passing tests does not guarantee reliable runtime behavior. We find that different correct solutions to the same task can show very different memory and performance patterns, which can lead to hidden operational risks. We present a framework to measure execution-time memory stability across multiple correct generations. At the solution level, we introduce Dynamic Mean Pairwise Distance (DMPD), which uses Dynamic Time Warping to compare the shapes of memory-usage traces after converting them into Monotonic Peak Profiles (MPPs) to reduce transient noise. Aggregating DMPD across tasks yields a model-level Model Instability Score (MIS). Experiments on BigOBench and CodeContests show substantial runtime divergence among correct solutions. Instability often increases with higher sampling temperature even when pass@1 improves. We also observe correlations between our stability measures and software engineering indicators such as cognitive and cyclomatic complexity, suggesting links between operational behavior and maintainability. Our results support stability-aware selection among passing candidates in CI/CD to reduce operational risk without sacrificing correctness. Artifacts are available.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bc4\u4f30LLM\u751f\u6210\u4ee3\u7801\u8fd0\u884c\u65f6\u5185\u5b58\u7a33\u5b9a\u6027\u7684\u6846\u67b6\uff0c\u53d1\u73b0\u4e0d\u540c\u6b63\u786e\u89e3\u51b3\u65b9\u6848\u5728\u5185\u5b58\u548c\u6027\u80fd\u6a21\u5f0f\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u53ef\u80fd\u5bfc\u81f4\u9690\u85cf\u7684\u64cd\u4f5c\u98ce\u9669\u3002", "motivation": "LLM\u751f\u6210\u7684\u4ee3\u7801\u867d\u7136\u80fd\u901a\u8fc7\u5355\u5143\u6d4b\u8bd5\uff0c\u4f46\u901a\u8fc7\u6d4b\u8bd5\u5e76\u4e0d\u80fd\u4fdd\u8bc1\u53ef\u9760\u7684\u8fd0\u884c\u65f6\u884c\u4e3a\u3002\u4e0d\u540c\u6b63\u786e\u89e3\u51b3\u65b9\u6848\u5728\u5185\u5b58\u548c\u6027\u80fd\u6a21\u5f0f\u4e0a\u53ef\u80fd\u5b58\u5728\u5de8\u5927\u5dee\u5f02\uff0c\u8fd9\u4f1a\u5e26\u6765\u9690\u85cf\u7684\u64cd\u4f5c\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6d4b\u91cf\u6267\u884c\u65f6\u95f4\u5185\u5b58\u7a33\u5b9a\u6027\u7684\u6846\u67b6\uff1a\u5728\u89e3\u51b3\u65b9\u6848\u5c42\u9762\u5f15\u5165\u52a8\u6001\u5e73\u5747\u914d\u5bf9\u8ddd\u79bb\uff08DMPD\uff09\uff0c\u4f7f\u7528\u52a8\u6001\u65f6\u95f4\u89c4\u6574\u6bd4\u8f83\u5185\u5b58\u4f7f\u7528\u8f68\u8ff9\u7684\u5f62\u72b6\uff0c\u5e76\u5c06\u5176\u8f6c\u6362\u4e3a\u5355\u8c03\u5cf0\u503c\u8f6e\u5ed3\u4ee5\u51cf\u5c11\u77ac\u6001\u566a\u58f0\uff1b\u5728\u6a21\u578b\u5c42\u9762\u805a\u5408DMPD\u5f97\u5230\u6a21\u578b\u4e0d\u7a33\u5b9a\u5206\u6570\uff08MIS\uff09\u3002", "result": "\u5728BigOBench\u548cCodeContests\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u6b63\u786e\u89e3\u51b3\u65b9\u6848\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u7684\u8fd0\u884c\u65f6\u5dee\u5f02\u3002\u4e0d\u7a33\u5b9a\u6027\u901a\u5e38\u968f\u7740\u91c7\u6837\u6e29\u5ea6\u5347\u9ad8\u800c\u589e\u52a0\uff0c\u5373\u4f7fpass@1\u6709\u6240\u6539\u5584\u3002\u7a33\u5b9a\u6027\u6d4b\u91cf\u4e0e\u8ba4\u77e5\u590d\u6742\u5ea6\u548c\u5708\u590d\u6742\u5ea6\u7b49\u8f6f\u4ef6\u5de5\u7a0b\u6307\u6807\u5b58\u5728\u76f8\u5173\u6027\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u652f\u6301\u5728CI/CD\u4e2d\u91c7\u7528\u7a33\u5b9a\u6027\u611f\u77e5\u7684\u9009\u62e9\u7b56\u7565\uff0c\u5728\u4e0d\u727a\u7272\u6b63\u786e\u6027\u7684\u524d\u63d0\u4e0b\u964d\u4f4e\u64cd\u4f5c\u98ce\u9669\u3002\u7a33\u5b9a\u6027\u6d4b\u91cf\u53ef\u4ee5\u63ed\u793a\u64cd\u4f5c\u884c\u4e3a\u4e0e\u53ef\u7ef4\u62a4\u6027\u4e4b\u95f4\u7684\u8054\u7cfb\u3002"}}
{"id": "2601.00814", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00814", "abs": "https://arxiv.org/abs/2601.00814", "authors": ["Abhishek Kumar"], "title": "Semantic Alignment of Multilingual Knowledge Graphs via Contextualized Vector Projections", "comment": null, "summary": "The paper presents our work on cross-lingual ontology alignment system which uses embedding based cosine similarity matching. The ontology entities are made contextually richer by creating descriptions using novel techniques. We use a fine-tuned transformer based multilingual model for generating better embeddings. We use cosine similarity to find positive ontology entities pairs and then apply threshold filtering to retain only highly similar entities. We have evaluated our work on OAEI-2022 multifarm track. We achieve 71% F1 score (78% recall and 65% precision) on the evaluation dataset, 16% increase from best baseline score. This suggests that our proposed alignment pipeline is able to capture the subtle cross-lingual similarities.", "AI": {"tldr": "\u57fa\u4e8e\u5d4c\u5165\u4f59\u5f26\u76f8\u4f3c\u5ea6\u7684\u8de8\u8bed\u8a00\u672c\u4f53\u5bf9\u9f50\u7cfb\u7edf\uff0c\u901a\u8fc7\u589e\u5f3a\u5b9e\u4f53\u63cf\u8ff0\u548c\u4f7f\u7528\u5fae\u8c03\u7684\u591a\u8bed\u8a00\u6a21\u578b\u63d0\u5347\u5bf9\u9f50\u6548\u679c\uff0c\u5728OAEI-2022\u6570\u636e\u96c6\u4e0aF1\u8fbe\u523071%\uff0c\u6bd4\u6700\u4f73\u57fa\u7ebf\u63d0\u534716%", "motivation": "\u89e3\u51b3\u8de8\u8bed\u8a00\u672c\u4f53\u5bf9\u9f50\u7684\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u8de8\u8bed\u8a00\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u5bf9\u9f50\u65b9\u6cd5\u6765\u63d0\u5347\u8de8\u8bed\u8a00\u77e5\u8bc6\u56fe\u8c31\u7684\u6574\u5408\u80fd\u529b", "method": "\u4f7f\u7528\u65b0\u9896\u6280\u672f\u521b\u5efa\u4e30\u5bcc\u7684\u5b9e\u4f53\u63cf\u8ff0\u589e\u5f3a\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u91c7\u7528\u5fae\u8c03\u7684transformer\u591a\u8bed\u8a00\u6a21\u578b\u751f\u6210\u66f4\u597d\u7684\u5d4c\u5165\u8868\u793a\uff0c\u901a\u8fc7\u4f59\u5f26\u76f8\u4f3c\u5ea6\u5339\u914d\u5b9e\u4f53\u5bf9\uff0c\u518d\u5e94\u7528\u9608\u503c\u8fc7\u6ee4\u4fdd\u7559\u9ad8\u76f8\u4f3c\u5ea6\u5b9e\u4f53", "result": "\u5728OAEI-2022 multifarm track\u8bc4\u4f30\u6570\u636e\u96c6\u4e0a\u83b7\u5f9771%\u7684F1\u5206\u6570\uff0878%\u53ec\u56de\u7387\u548c65%\u7cbe\u786e\u7387\uff09\uff0c\u6bd4\u6700\u4f73\u57fa\u7ebf\u63d0\u5347\u4e8616%\uff0c\u8868\u660e\u7cfb\u7edf\u80fd\u6709\u6548\u6355\u6349\u8de8\u8bed\u8a00\u7684\u7ec6\u5fae\u76f8\u4f3c\u6027", "conclusion": "\u63d0\u51fa\u7684\u8de8\u8bed\u8a00\u672c\u4f53\u5bf9\u9f50\u7ba1\u9053\u80fd\u591f\u6709\u6548\u6355\u6349\u8de8\u8bed\u8a00\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\uff0c\u901a\u8fc7\u589e\u5f3a\u5b9e\u4f53\u63cf\u8ff0\u548c\u4f7f\u7528\u5fae\u8c03\u591a\u8bed\u8a00\u6a21\u578b\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u9f50\u6027\u80fd\uff0c\u4e3a\u8de8\u8bed\u8a00\u77e5\u8bc6\u56fe\u8c31\u6574\u5408\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.01219", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.01219", "abs": "https://arxiv.org/abs/2601.01219", "authors": ["Hossein Amiri", "Joon-Seok Kim", "Hamdi Kavak", "Andrew Crooks", "Dieter Pfoser", "Carola Wenk", "Andreas Z\u00fcfle"], "title": "HD-GEN: A High-Performance Software System for Human Mobility Data Generation Based on Patterns of Life", "comment": null, "summary": "Understanding individual-level human mobility is critical for a wide range of applications. Real-world trajectory datasets provide valuable insights into actual movement behaviors but are often constrained by data sparsity and participant bias. Synthetic data, by contrast, offer scalability and flexibility but frequently lack realism. To address this gap, we introduce a comprehensive software pipeline for calibrating, generating, processing, and visualizing large-scale individual-level human mobility datasets that combine the realism of empirical data with the control and extensibility of Patterns-of-Life simulations. Our system consists of four integrated components. (1) a data generation engine constructs geographically grounded simulations using OpenStreetMap data to produce diverse mobility logs. (2) a genetic algorithm-based calibration module fine-tunes simulation parameters to align with real-world mobility characteristics, such as daily trip counts and radius of gyration, enabling realistic behavioral modeling. (3) a data processing suite transforms raw simulation logs into structured formats suitable for downstream applications, including model training and benchmarking. (4) a visualization module extracts key mobility patterns and insights from the processed datasets and presents them through intuitive visual analytics for improved interpretability.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408\u771f\u5b9e\u6570\u636e\u4e0e\u6a21\u62df\u6570\u636e\u7684\u7efc\u5408\u8f6f\u4ef6\u7ba1\u9053\uff0c\u7528\u4e8e\u6821\u51c6\u3001\u751f\u6210\u3001\u5904\u7406\u548c\u53ef\u89c6\u5316\u5927\u89c4\u6a21\u4e2a\u4f53\u5c42\u9762\u7684\u4eba\u7c7b\u79fb\u52a8\u6570\u636e\u96c6", "motivation": "\u771f\u5b9e\u8f68\u8ff9\u6570\u636e\u96c6\u53d7\u6570\u636e\u7a00\u758f\u6027\u548c\u53c2\u4e0e\u8005\u504f\u5dee\u9650\u5236\uff0c\u800c\u5408\u6210\u6570\u636e\u7f3a\u4e4f\u771f\u5b9e\u6027\uff0c\u9700\u8981\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u6765\u83b7\u5f97\u65e2\u771f\u5b9e\u53c8\u53ef\u6269\u5c55\u7684\u4eba\u7c7b\u79fb\u52a8\u6570\u636e", "method": "\u5f00\u53d1\u5305\u542b\u56db\u4e2a\u7ec4\u4ef6\u7684\u7cfb\u7edf\uff1a1)\u57fa\u4e8eOpenStreetMap\u7684\u5730\u7406\u57fa\u7840\u6570\u636e\u751f\u6210\u5f15\u64ce\uff1b2)\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u7684\u6821\u51c6\u6a21\u5757\uff1b3)\u6570\u636e\u5904\u7406\u5957\u4ef6\uff1b4)\u53ef\u89c6\u5316\u6a21\u5757", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u80fd\u591f\u751f\u6210\u5927\u89c4\u6a21\u3001\u771f\u5b9e\u4e14\u53ef\u63a7\u7684\u4eba\u7c7b\u79fb\u52a8\u6570\u636e\u96c6\u7684\u7efc\u5408\u8f6f\u4ef6\u7ba1\u9053\uff0c\u5c06\u5b9e\u8bc1\u6570\u636e\u7684\u771f\u5b9e\u6027\u4e0e\u6a21\u62df\u6570\u636e\u7684\u53ef\u6269\u5c55\u6027\u76f8\u7ed3\u5408", "conclusion": "\u8be5\u8f6f\u4ef6\u7ba1\u9053\u586b\u8865\u4e86\u771f\u5b9e\u6570\u636e\u4e0e\u5408\u6210\u6570\u636e\u4e4b\u95f4\u7684\u7a7a\u767d\uff0c\u4e3a\u5404\u79cd\u5e94\u7528\u63d0\u4f9b\u4e86\u65e2\u771f\u5b9e\u53c8\u53ef\u6269\u5c55\u7684\u4eba\u7c7b\u79fb\u52a8\u6570\u636e\u96c6\uff0c\u652f\u6301\u6a21\u578b\u8bad\u7ec3\u3001\u57fa\u51c6\u6d4b\u8bd5\u548c\u53ef\u89c6\u5316\u5206\u6790"}}
{"id": "2601.00816", "categories": ["cs.AI", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.00816", "abs": "https://arxiv.org/abs/2601.00816", "authors": ["Ismail Ahmad Abdullah"], "title": "MathLedger: A Verifiable Learning Substrate with Ledger-Attested Feedback", "comment": "14 pages, 1 figure, 2 tables, 2 appendices with full proofs. Documents v0.9.4-pilot-audit-hardened audit surface with fail-closed governance, canonical JSON hashing, and artifact classification. Phase I infrastructure validation; no capability claims", "summary": "Contemporary AI systems achieve extraordinary performance yet remain opaque and non-verifiable, creating a crisis of trust for safety-critical deployment. We introduce MathLedger, a substrate for verifiable machine cognition that integrates formal verification, cryptographic attestation, and learning dynamics into a single epistemic loop. The system implements Reflexive Formal Learning (RFL), a symbolic analogue of gradient descent where updates are driven by verifier outcomes rather than statistical loss.\n  Phase I experiments validate the measurement and governance substrate under controlled conditions. CAL-EXP-3 validates measurement infrastructure (Delta p computation, variance tracking); separate stress tests confirm fail-closed governance triggers correctly under out-of-bounds conditions. No convergence or capability claims are made. The contribution is infrastructural: a working prototype of ledger-attested learning that enables auditability at scale.\n  Keywords: verifiable learning, formal verification, cryptographic attestation, reflexive feedback, fail-closed governance", "AI": {"tldr": "MathLedger\u662f\u4e00\u4e2a\u7528\u4e8e\u53ef\u9a8c\u8bc1\u673a\u5668\u8ba4\u77e5\u7684\u6846\u67b6\uff0c\u96c6\u6210\u4e86\u5f62\u5f0f\u9a8c\u8bc1\u3001\u5bc6\u7801\u5b66\u8bc1\u660e\u548c\u5b66\u4e60\u52a8\u6001\uff0c\u901a\u8fc7\u53cd\u5c04\u5f0f\u5f62\u5f0f\u5b66\u4e60\u5b9e\u73b0\u53ef\u5ba1\u8ba1\u7684\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u3002", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\u867d\u7136\u6027\u80fd\u5353\u8d8a\u4f46\u7f3a\u4e4f\u900f\u660e\u5ea6\u548c\u53ef\u9a8c\u8bc1\u6027\uff0c\u5728\u5b89\u5168\u5173\u952e\u90e8\u7f72\u4e2d\u5b58\u5728\u4fe1\u4efb\u5371\u673a\uff0c\u9700\u8981\u5efa\u7acb\u53ef\u9a8c\u8bc1\u7684\u673a\u5668\u5b66\u4e60\u6846\u67b6\u3002", "method": "\u91c7\u7528\u53cd\u5c04\u5f0f\u5f62\u5f0f\u5b66\u4e60\uff0c\u8fd9\u662f\u4e00\u79cd\u7b26\u53f7\u5316\u7684\u68af\u5ea6\u4e0b\u964d\u65b9\u6cd5\uff0c\u66f4\u65b0\u7531\u9a8c\u8bc1\u5668\u7ed3\u679c\u800c\u975e\u7edf\u8ba1\u635f\u5931\u9a71\u52a8\uff0c\u7ed3\u5408\u5f62\u5f0f\u9a8c\u8bc1\u3001\u5bc6\u7801\u5b66\u8bc1\u660e\u548c\u5b66\u4e60\u52a8\u6001\u3002", "result": "\u7b2c\u4e00\u9636\u6bb5\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6d4b\u91cf\u548c\u6cbb\u7406\u57fa\u7840\u8bbe\u65bd\u5728\u53d7\u63a7\u6761\u4ef6\u4e0b\u7684\u6709\u6548\u6027\uff0c\u786e\u8ba4\u4e86\u6d4b\u91cf\u57fa\u7840\u8bbe\u65bd\u548c\u6545\u969c\u5173\u95ed\u6cbb\u7406\u89e6\u53d1\u673a\u5236\u7684\u6b63\u786e\u6027\uff0c\u4f46\u672a\u505a\u51fa\u6536\u655b\u6027\u6216\u80fd\u529b\u58f0\u660e\u3002", "conclusion": "MathLedger\u63d0\u4f9b\u4e86\u4e00\u4e2a\u57fa\u7840\u8bbe\u65bd\u539f\u578b\uff0c\u5b9e\u73b0\u4e86\u8d26\u672c\u8bc1\u660e\u7684\u5b66\u4e60\uff0c\u652f\u6301\u5927\u89c4\u6a21\u53ef\u5ba1\u8ba1\u6027\uff0c\u4e3a\u89e3\u51b3AI\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u548c\u53ef\u9a8c\u8bc1\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u6280\u672f\u57fa\u7840\u3002"}}
{"id": "2601.01233", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.01233", "abs": "https://arxiv.org/abs/2601.01233", "authors": ["Kangchen Zhu", "Zhiliang Tian", "Shangwen Wang", "Mingyue Leng", "Xiaoguang Mao"], "title": "Atomizer: An LLM-based Collaborative Multi-Agent Framework for Intent-Driven Commit Untangling", "comment": "Accepted by ICSE 2026", "summary": "Composite commits, which entangle multiple unrelated concerns, are prevalent in software development and significantly hinder program comprehension and maintenance. Existing automated untangling methods, particularly state-of-the-art graph clustering-based approaches, are fundamentally limited by two issues. (1) They over-rely on structural information, failing to grasp the crucial semantic intent behind changes, and (2) they operate as ``single-pass'' algorithms, lacking a mechanism for the critical reflection and refinement inherent in human review processes. To overcome these challenges, we introduce Atomizer, a novel collaborative multi-agent framework for composite commit untangling. To address the semantic deficit, Atomizer employs an Intent-Oriented Chain-of-Thought (IO-CoT) strategy, which prompts large language models (LLMs) to infer the intent of each code change according to both the structure and the semantic information of code. To overcome the limitations of ``single-pass'' grouping, we employ two agents to establish a grouper-reviewer collaborative refinement loop, which mirrors human review practices by iteratively refining groupings until all changes in a cluster share the same underlying semantic intent. Extensive experiments on two benchmark C# and Java datasets demonstrate that Atomizer significantly outperforms several representative baselines. On average, it surpasses the state-of-the-art graph-based methods by over 6.0% on the C# dataset and 5.5% on the Java dataset. This superiority is particularly pronounced on complex commits, where Atomizer's performance advantage widens to over 16%.", "AI": {"tldr": "Atomizer\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7684\u590d\u5408\u63d0\u4ea4\u89e3\u8026\u6846\u67b6\uff0c\u901a\u8fc7\u610f\u56fe\u5bfc\u5411\u7684\u601d\u7ef4\u94fe\u548c\u5206\u7ec4-\u8bc4\u5ba1\u5faa\u73af\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u53d8\u66f4\u8bed\u4e49\u7406\u89e3\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u590d\u5408\u63d0\u4ea4\u89e3\u8026\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u6839\u672c\u6027\u9650\u5236\uff1a\u8fc7\u5ea6\u4f9d\u8d56\u7ed3\u6784\u4fe1\u606f\u800c\u5ffd\u89c6\u8bed\u4e49\u610f\u56fe\uff0c\u4ee5\u53ca\u7f3a\u4e4f\u7c7b\u4f3c\u4eba\u5de5\u8bc4\u5ba1\u7684\u53cd\u601d\u548c\u4f18\u5316\u673a\u5236\u3002\u8fd9\u4e9b\u9650\u5236\u5f71\u54cd\u4e86\u7a0b\u5e8f\u7406\u89e3\u548c\u7ef4\u62a4\u7684\u6548\u7387\u3002", "method": "\u63d0\u51faAtomizer\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u521b\u65b0\uff1a1) \u610f\u56fe\u5bfc\u5411\u601d\u7ef4\u94fe\u7b56\u7565\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u7ed3\u6784\u548c\u8bed\u4e49\u5c42\u9762\u63a8\u65ad\u4ee3\u7801\u53d8\u66f4\u610f\u56fe\uff1b2) \u5206\u7ec4-\u8bc4\u5ba1\u667a\u80fd\u4f53\u534f\u4f5c\u5faa\u73af\uff0c\u6a21\u62df\u4eba\u5de5\u8bc4\u5ba1\u8fc7\u7a0b\u8fed\u4ee3\u4f18\u5316\u5206\u7ec4\u7ed3\u679c\u3002", "result": "\u5728C#\u548cJava\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAtomizer\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e73\u5747\u6027\u80fd\u8d85\u8fc7\u6700\u5148\u8fdb\u7684\u56fe\u57fa\u65b9\u6cd56.0%\uff08C#\uff09\u548c5.5%\uff08Java\uff09\uff0c\u5728\u590d\u6742\u63d0\u4ea4\u4e0a\u7684\u4f18\u52bf\u6269\u5927\u523016%\u4ee5\u4e0a\u3002", "conclusion": "Atomizer\u901a\u8fc7\u7ed3\u5408\u8bed\u4e49\u610f\u56fe\u7406\u89e3\u548c\u8fed\u4ee3\u4f18\u5316\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u590d\u5408\u63d0\u4ea4\u89e3\u8026\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u8f6f\u4ef6\u7ef4\u62a4\u548c\u7406\u89e3\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u81ea\u52a8\u5316\u5de5\u5177\u3002"}}
{"id": "2601.00818", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00818", "abs": "https://arxiv.org/abs/2601.00818", "authors": ["Chandra Sekhar Kubam"], "title": "Agentic AI for Autonomous, Explainable, and Real-Time Credit Risk Decision-Making", "comment": "8 pages", "summary": "Significant digitalization of financial services in a short period of time has led to an urgent demand to have autonomous, transparent and real-time credit risk decision making systems. The traditional machine learning models are effective in pattern recognition, but do not have the adaptive reasoning, situational awareness, and autonomy needed in modern financial operations. As a proposal, this paper presents an Agentic AI framework, or a system where AI agents view the world of dynamic credit independent of human observers, who then make actions based on their articulable decision-making paths. The research introduces a multi-agent system with reinforcing learning, natural language reasoning, explainable AI modules, and real-time data absorption pipelines as a means of assessing the risk profiles of borrowers with few humans being involved. The processes consist of agent collaboration protocol, risk-scoring engines, interpretability layers, and continuous feedback learning cycles. Findings indicate that decision speed, transparency and responsiveness is better than traditional credit scoring models. Nevertheless, there are still some practical limitations such as risks of model drift, inconsistencies in interpreting high dimensional data and regulatory uncertainties as well as infrastructure limitations in low-resource settings. The suggested system has a high prospective to transform credit analytics and future studies ought to be directed on dynamic regulatory compliance mobilizers, new agent teamwork, adversarial robustness, and large-scale implementation in cross-country credit ecosystems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eAgentic AI\u6846\u67b6\u7684\u81ea\u4e3b\u4fe1\u7528\u98ce\u9669\u8bc4\u4f30\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u5b9e\u73b0\u5b9e\u65f6\u3001\u900f\u660e\u7684\u4fe1\u8d37\u51b3\u7b56\uff0c\u76f8\u6bd4\u4f20\u7edf\u6a21\u578b\u5728\u51b3\u7b56\u901f\u5ea6\u3001\u900f\u660e\u5ea6\u548c\u54cd\u5e94\u6027\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u91d1\u878d\u670d\u52a1\u5feb\u901f\u6570\u5b57\u5316\u5bfc\u81f4\u5bf9\u81ea\u4e3b\u3001\u900f\u660e\u3001\u5b9e\u65f6\u7684\u4fe1\u7528\u98ce\u9669\u51b3\u7b56\u7cfb\u7edf\u9700\u6c42\u8feb\u5207\u3002\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u867d\u7136\u64c5\u957f\u6a21\u5f0f\u8bc6\u522b\uff0c\u4f46\u7f3a\u4e4f\u73b0\u4ee3\u91d1\u878d\u8fd0\u8425\u6240\u9700\u7684\u9002\u5e94\u6027\u63a8\u7406\u3001\u60c5\u5883\u611f\u77e5\u548c\u81ea\u4e3b\u6027\u3002", "method": "\u63d0\u51faAgentic AI\u6846\u67b6\uff0c\u6784\u5efa\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5305\u542b\u5f3a\u5316\u5b66\u4e60\u3001\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u3001\u53ef\u89e3\u91caAI\u6a21\u5757\u548c\u5b9e\u65f6\u6570\u636e\u5438\u6536\u7ba1\u9053\u3002\u7cfb\u7edf\u5305\u62ec\u667a\u80fd\u4f53\u534f\u4f5c\u534f\u8bae\u3001\u98ce\u9669\u8bc4\u5206\u5f15\u64ce\u3001\u53ef\u89e3\u91ca\u6027\u5c42\u548c\u6301\u7eed\u53cd\u9988\u5b66\u4e60\u5faa\u73af\u3002", "result": "\u8be5\u7cfb\u7edf\u5728\u51b3\u7b56\u901f\u5ea6\u3001\u900f\u660e\u5ea6\u548c\u54cd\u5e94\u6027\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u4fe1\u7528\u8bc4\u5206\u6a21\u578b\u3002\u4f46\u4ecd\u5b58\u5728\u6a21\u578b\u6f02\u79fb\u98ce\u9669\u3001\u9ad8\u7ef4\u6570\u636e\u89e3\u91ca\u4e0d\u4e00\u81f4\u3001\u76d1\u7ba1\u4e0d\u786e\u5b9a\u6027\u4ee5\u53ca\u4f4e\u8d44\u6e90\u73af\u5883\u57fa\u7840\u8bbe\u65bd\u9650\u5236\u7b49\u5b9e\u9645\u5c40\u9650\u6027\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u5177\u6709\u53d8\u9769\u4fe1\u7528\u5206\u6790\u7684\u5de8\u5927\u6f5c\u529b\u3002\u672a\u6765\u7814\u7a76\u5e94\u5173\u6ce8\u52a8\u6001\u76d1\u7ba1\u5408\u89c4\u673a\u5236\u3001\u65b0\u578b\u667a\u80fd\u4f53\u534f\u4f5c\u3001\u5bf9\u6297\u9c81\u68d2\u6027\u4ee5\u53ca\u5728\u8de8\u56fd\u4fe1\u7528\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u5927\u89c4\u6a21\u5b9e\u65bd\u3002"}}
{"id": "2601.01271", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.01271", "abs": "https://arxiv.org/abs/2601.01271", "authors": ["Qingxiao Tao", "Xiaodong Gu", "Hao Zhong", "Beijun Shen"], "title": "CatchAll: Repository-Aware Exception Handling with Knowledge-Guided LLMs", "comment": null, "summary": "Exception handling is a vital forward error-recovery mechanism in many programming languages, enabling developers to manage runtime anomalies through structured constructs (e.g., try-catch blocks). Improper or missing exception handling often leads to severe consequences, including system crashes and resource leaks. While large language models (LLMs) have demonstrated strong capabilities in code generation, they struggle with exception handling at the repository level, due to complex dependencies and contextual constraints. In this work, we propose CatchAll, a novel LLM-based approach for repository-aware exception handling. CatchAll equips LLMs with three complementary layers of exception-handling knowledge: (1) API-level exception knowledge, obtained from an empirically constructed API-exception mapping that characterizes the exception-throwing behaviors of APIs in real-world codebases; (2) repository-level execution context, which captures exception propagation by modeling contextual call traces around the target code; and (3) cross-repository handling knowledge, distilled from reusable exception-handling patterns mined from historical code across projects. The knowledge is encoded into structured prompts to guide the LLM in generating accurate and context-aware exception-handling code. To evaluate CatchAll, we construct two new benchmarks for repository-aware exception handling: a large-scale dataset RepoExEval and an executable subset RepoExEval-Exec. Experiments demonstrate that RepoExEval consistently outperforms state-of-the-art baselines, achieving a CodeBLEU score of 0.31 (vs. 0.27% for the best baseline), intent prediction accuracy of 60.1% (vs. 48.0%), and Pass@1 of 29% (vs. 25%). These results affirm RepoExEval's effectiveness in real-world repository-level exception handling.", "AI": {"tldr": "CatchAll\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u4ed3\u5e93\u611f\u77e5\u5f02\u5e38\u5904\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e09\u5c42\u77e5\u8bc6\u6307\u5bfcLLM\u751f\u6210\u51c6\u786e\u7684\u5f02\u5e38\u5904\u7406\u4ee3\u7801\uff0c\u5728\u4ed3\u5e93\u7ea7\u5f02\u5e38\u5904\u7406\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f02\u5e38\u5904\u7406\u662f\u7f16\u7a0b\u4e2d\u7684\u91cd\u8981\u9519\u8bef\u6062\u590d\u673a\u5236\uff0c\u4f46LLM\u5728\u4ed3\u5e93\u7ea7\u522b\u7684\u5f02\u5e38\u5904\u7406\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u4e3a\u590d\u6742\u7684\u4f9d\u8d56\u5173\u7cfb\u548c\u4e0a\u4e0b\u6587\u7ea6\u675f\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u7406\u89e3\u4ed3\u5e93\u7ea7\u4e0a\u4e0b\u6587\u7684\u5f02\u5e38\u5904\u7406\u65b9\u6cd5\u3002", "method": "CatchAll\u4e3aLLM\u63d0\u4f9b\u4e09\u5c42\u5f02\u5e38\u5904\u7406\u77e5\u8bc6\uff1a1) API\u7ea7\u5f02\u5e38\u77e5\u8bc6\uff0c\u6765\u81ea\u7ecf\u9a8c\u6784\u5efa\u7684API-\u5f02\u5e38\u6620\u5c04\uff1b2) \u4ed3\u5e93\u7ea7\u6267\u884c\u4e0a\u4e0b\u6587\uff0c\u901a\u8fc7\u5efa\u6a21\u76ee\u6807\u4ee3\u7801\u5468\u56f4\u7684\u4e0a\u4e0b\u6587\u8c03\u7528\u8f68\u8ff9\u6355\u83b7\u5f02\u5e38\u4f20\u64ad\uff1b3) \u8de8\u4ed3\u5e93\u5904\u7406\u77e5\u8bc6\uff0c\u4ece\u5386\u53f2\u4ee3\u7801\u4e2d\u6316\u6398\u7684\u53ef\u91cd\u7528\u5f02\u5e38\u5904\u7406\u6a21\u5f0f\u3002\u8fd9\u4e9b\u77e5\u8bc6\u88ab\u7f16\u7801\u4e3a\u7ed3\u6784\u5316\u63d0\u793a\u6765\u6307\u5bfcLLM\u751f\u6210\u4ee3\u7801\u3002", "result": "\u5728\u4e24\u4e2a\u65b0\u7684\u4ed3\u5e93\u611f\u77e5\u5f02\u5e38\u5904\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCatchAll\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff1aCodeBLEU\u5f97\u52060.31\uff08vs. 0.27\uff09\uff0c\u610f\u56fe\u9884\u6d4b\u51c6\u786e\u738760.1%\uff08vs. 48.0%\uff09\uff0cPass@1\u4e3a29%\uff08vs. 25%\uff09\u3002", "conclusion": "CatchAll\u901a\u8fc7\u7ed3\u5408API\u7ea7\u3001\u4ed3\u5e93\u7ea7\u548c\u8de8\u4ed3\u5e93\u7684\u5f02\u5e38\u5904\u7406\u77e5\u8bc6\uff0c\u6709\u6548\u63d0\u5347\u4e86LLM\u5728\u4ed3\u5e93\u7ea7\u5f02\u5e38\u5904\u7406\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u771f\u5b9e\u4e16\u754c\u4ee3\u7801\u5e93\u5f02\u5e38\u5904\u7406\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2601.00900", "categories": ["cs.CR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.00900", "abs": "https://arxiv.org/abs/2601.00900", "authors": ["Yuchao Hou", "Zixuan Zhang", "Jie Wang", "Wenke Huang", "Lianhui Liang", "Di Wu", "Zhiquan Liu", "Youliang Tian", "Jianming Zhu", "Jisheng Dang", "Junhao Dong", "Zhongliang Guo"], "title": "Noise-Aware and Dynamically Adaptive Federated Defense Framework for SAR Image Target Recognition", "comment": "This work was supported in part by the National Key Research and Development Program of China under Grant 2021YFB3101100, in part by the National Natural Science Foundation of China under Grant 62272123, 42371470, and 42461057, in part by the Fundamental Research Program of Shanxi Province under Grant 202303021212164. Corresponding authors: Zhongliang Guo and Junhao Dong", "summary": "As a critical application of computational intelligence in remote sensing, deep learning-based synthetic aperture radar (SAR) image target recognition facilitates intelligent perception but typically relies on centralized training, where multi-source SAR data are uploaded to a single server, raising privacy and security concerns. Federated learning (FL) provides an emerging computational intelligence paradigm for SAR image target recognition, enabling cross-site collaboration while preserving local data privacy. However, FL confronts critical security risks, where malicious clients can exploit SAR's multiplicative speckle noise to conceal backdoor triggers, severely challenging the robustness of the computational intelligence model. To address this challenge, we propose NADAFD, a noise-aware and dynamically adaptive federated defense framework that integrates frequency-domain, spatial-domain, and client-behavior analyses to counter SAR-specific backdoor threats. Specifically, we introduce a frequency-domain collaborative inversion mechanism to expose cross-client spectral inconsistencies indicative of hidden backdoor triggers. We further design a noise-aware adversarial training strategy that embeds $\u0393$-distributed speckle characteristics into mask-guided adversarial sample generation to enhance robustness against both backdoor attacks and SAR speckle noise. In addition, we present a dynamic health assessment module that tracks client update behaviors across training rounds and adaptively adjusts aggregation weights to mitigate evolving malicious contributions. Experiments on MSTAR and OpenSARShip datasets demonstrate that NADAFD achieves higher accuracy on clean test samples and a lower backdoor attack success rate on triggered inputs than existing federated backdoor defenses for SAR target recognition.", "AI": {"tldr": "NADAFD\u662f\u4e00\u4e2a\u9488\u5bf9SAR\u56fe\u50cf\u76ee\u6807\u8bc6\u522b\u7684\u8054\u90a6\u5b66\u4e60\u9632\u5fa1\u6846\u67b6\uff0c\u901a\u8fc7\u9891\u7387\u57df\u534f\u4f5c\u53cd\u6f14\u3001\u566a\u58f0\u611f\u77e5\u5bf9\u6297\u8bad\u7ec3\u548c\u52a8\u6001\u5065\u5eb7\u8bc4\u4f30\u6765\u62b5\u5fa1SAR\u7279\u6709\u7684\u540e\u95e8\u653b\u51fb\u3002", "motivation": "\u4f20\u7edf\u7684SAR\u56fe\u50cf\u76ee\u6807\u8bc6\u522b\u4f9d\u8d56\u96c6\u4e2d\u5f0f\u8bad\u7ec3\uff0c\u5b58\u5728\u9690\u79c1\u548c\u5b89\u5168\u95ee\u9898\u3002\u8054\u90a6\u5b66\u4e60\u867d\u7136\u80fd\u4fdd\u62a4\u6570\u636e\u9690\u79c1\uff0c\u4f46\u9762\u4e34\u6076\u610f\u5ba2\u6237\u7aef\u5229\u7528SAR\u4e58\u6027\u6591\u70b9\u566a\u58f0\u9690\u85cf\u540e\u95e8\u89e6\u53d1\u7684\u5b89\u5168\u98ce\u9669\uff0c\u9700\u8981\u4e13\u95e8\u9488\u5bf9SAR\u7279\u6027\u7684\u9632\u5fa1\u673a\u5236\u3002", "method": "1. \u9891\u7387\u57df\u534f\u4f5c\u53cd\u6f14\u673a\u5236\uff1a\u901a\u8fc7\u5206\u6790\u8de8\u5ba2\u6237\u7aef\u9891\u8c31\u4e0d\u4e00\u81f4\u6027\u6765\u66b4\u9732\u9690\u85cf\u7684\u540e\u95e8\u89e6\u53d1\u5668\uff1b2. \u566a\u58f0\u611f\u77e5\u5bf9\u6297\u8bad\u7ec3\uff1a\u5c06\u0393\u5206\u5e03\u6591\u70b9\u566a\u58f0\u7279\u5f81\u5d4c\u5165\u5230\u63a9\u7801\u5f15\u5bfc\u7684\u5bf9\u6297\u6837\u672c\u751f\u6210\u4e2d\uff0c\u589e\u5f3a\u5bf9\u540e\u95e8\u653b\u51fb\u548cSAR\u6591\u70b9\u566a\u58f0\u7684\u9c81\u68d2\u6027\uff1b3. \u52a8\u6001\u5065\u5eb7\u8bc4\u4f30\u6a21\u5757\uff1a\u8ddf\u8e2a\u5ba2\u6237\u7aef\u66f4\u65b0\u884c\u4e3a\u5e76\u81ea\u9002\u5e94\u8c03\u6574\u805a\u5408\u6743\u91cd\uff0c\u51cf\u8f7b\u6076\u610f\u8d21\u732e\u3002", "result": "\u5728MSTAR\u548cOpenSARShip\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cNADAFD\u5728\u5e72\u51c0\u6d4b\u8bd5\u6837\u672c\u4e0a\u83b7\u5f97\u66f4\u9ad8\u51c6\u786e\u7387\uff0c\u5728\u89e6\u53d1\u8f93\u5165\u4e0a\u83b7\u5f97\u66f4\u4f4e\u7684\u540e\u95e8\u653b\u51fb\u6210\u529f\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u8054\u90a6\u540e\u95e8\u9632\u5fa1\u65b9\u6cd5\u3002", "conclusion": "NADAFD\u901a\u8fc7\u96c6\u6210\u9891\u7387\u57df\u3001\u7a7a\u95f4\u57df\u548c\u5ba2\u6237\u7aef\u884c\u4e3a\u5206\u6790\uff0c\u6709\u6548\u5e94\u5bf9SAR\u7279\u6709\u7684\u540e\u95e8\u5a01\u80c1\uff0c\u4e3aSAR\u56fe\u50cf\u76ee\u6807\u8bc6\u522b\u7684\u8054\u90a6\u5b66\u4e60\u63d0\u4f9b\u4e86\u5b89\u5168\u53ef\u9760\u7684\u9632\u5fa1\u6846\u67b6\u3002"}}
{"id": "2601.00821", "categories": ["cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.00821", "abs": "https://arxiv.org/abs/2601.00821", "authors": ["Tao An"], "title": "CogCanvas: Compression-Resistant Cognitive Artifacts for Long LLM Conversations", "comment": "15 pages, 5 figures", "summary": "Large language models face a fundamental tension between context window limits and information fidelity in long conversations. Existing approaches--truncation and summarization--either discard early information or lose nuanced details. We introduce CogCanvas, a training-free framework that extracts verbatim-grounded cognitive artifacts (decisions, facts, reminders) from conversation turns and organizes them into a temporal-aware graph for compression-resistant retrieval.\n  On the LoCoMo benchmark, CogCanvas achieves 34.7% overall accuracy, outperforming RAG (25.6%, +9.1pp) and GraphRAG (13.7%, +21.0pp). The advantage is most pronounced on temporal reasoning: 31.5% vs. 9.3% (RAG) and 5.0% (GraphRAG)--a +530% relative improvement. On multi-hop causal reasoning, CogCanvas achieves 81.0% pass rate vs. 40.0% for GraphRAG (+41.0pp). Controlled benchmarks show 97.5% recall (+78.5pp vs. summarization) with 93.0% exact match preservation.\n  While heavily-optimized approaches achieve higher absolute scores through dedicated training (EverMemOS: approximately 92%), our training-free approach provides practitioners with an immediately-deployable alternative that significantly outperforms standard baselines. Code and data: https://github.com/tao-hpu/cog-canvas.", "AI": {"tldr": "CogCanvas\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u53d6\u5bf9\u8bdd\u4e2d\u7684\u8ba4\u77e5\u6784\u4ef6\u5e76\u7ec4\u7ec7\u6210\u65f6\u5e8f\u611f\u77e5\u56fe\uff0c\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u5bf9\u8bdd\u4e2d\u7684\u4e0a\u4e0b\u6587\u7a97\u53e3\u9650\u5236\u548c\u4fe1\u606f\u4fdd\u771f\u5ea6\u95ee\u9898\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u5bf9\u8bdd\u4e2d\u9762\u4e34\u4e0a\u4e0b\u6587\u7a97\u53e3\u9650\u5236\u548c\u4fe1\u606f\u4fdd\u771f\u5ea6\u7684\u57fa\u672c\u77db\u76fe\u3002\u73b0\u6709\u65b9\u6cd5\uff08\u622a\u65ad\u548c\u6458\u8981\uff09\u8981\u4e48\u4e22\u5f03\u65e9\u671f\u4fe1\u606f\uff0c\u8981\u4e48\u4e22\u5931\u7ec6\u8282\u4fe1\u606f\u3002", "method": "\u5f15\u5165CogCanvas\u6846\u67b6\uff0c\u4ece\u5bf9\u8bdd\u8f6e\u6b21\u4e2d\u63d0\u53d6\u57fa\u4e8e\u539f\u6587\u7684\u8ba4\u77e5\u6784\u4ef6\uff08\u51b3\u7b56\u3001\u4e8b\u5b9e\u3001\u63d0\u9192\uff09\uff0c\u5e76\u5c06\u5176\u7ec4\u7ec7\u6210\u65f6\u5e8f\u611f\u77e5\u56fe\uff0c\u5b9e\u73b0\u6297\u538b\u7f29\u68c0\u7d22\u3002", "result": "\u5728LoCoMo\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCogCanvas\u8fbe\u523034.7%\u6574\u4f53\u51c6\u786e\u7387\uff0c\u4f18\u4e8eRAG\uff0825.6%\uff09\u548cGraphRAG\uff0813.7%\uff09\u3002\u5728\u65f6\u5e8f\u63a8\u7406\u4e0a\u4f18\u52bf\u6700\u660e\u663e\uff1a31.5% vs. 9.3%\uff08RAG\uff09\u548c5.0%\uff08GraphRAG\uff09\uff0c\u76f8\u5bf9\u63d0\u5347530%\u3002\u591a\u8df3\u56e0\u679c\u63a8\u7406\u8fbe\u523081.0%\u901a\u8fc7\u7387\uff0c\u800cGraphRAG\u4e3a40.0%\u3002", "conclusion": "\u867d\u7136\u7ecf\u8fc7\u5927\u91cf\u4f18\u5316\u7684\u65b9\u6cd5\u901a\u8fc7\u4e13\u95e8\u8bad\u7ec3\u80fd\u8fbe\u5230\u66f4\u9ad8\u7edd\u5bf9\u5206\u6570\uff0c\u4f46CogCanvas\u8fd9\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u53ef\u7acb\u5373\u90e8\u7f72\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u663e\u8457\u4f18\u4e8e\u6807\u51c6\u57fa\u7ebf\u3002"}}
{"id": "2601.01320", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01320", "abs": "https://arxiv.org/abs/2601.01320", "authors": ["Muntasir Adnan", "Carlos C. N. Kuhn"], "title": "Adaptive Hierarchical Evaluation of LLMs and SAST tools for CWE Prediction in Python", "comment": null, "summary": "Large Language Models have become integral to software development, yet they frequently generate vulnerable code. Existing code vulnerability detection benchmarks employ binary classification, lacking the CWE-level specificity required for actionable feedback in iterative correction systems. We present ALPHA (Adaptive Learning via Penalty in Hierarchical Assessment), the first function-level Python benchmark that evaluates both LLMs and SAST tools using hierarchically aware, CWE-specific penalties. ALPHA distinguishes between over-generalisation, over-specification, and lateral errors, reflecting practical differences in diagnostic utility. Evaluating seven LLMs and two SAST tools, we find LLMs substantially outperform SAST, though SAST demonstrates higher precision when detections occur. Critically, prediction consistency varies dramatically across models (8.26%-81.87% agreement), with significant implications for feedback-driven systems. We further outline a pathway for future work incorporating ALPHA penalties into supervised fine-tuning, which could provide principled hierarchy-aware vulnerability detection pending empirical validation.", "AI": {"tldr": "ALPHA\u662f\u9996\u4e2a\u51fd\u6570\u7ea7Python\u6f0f\u6d1e\u68c0\u6d4b\u57fa\u51c6\uff0c\u4f7f\u7528\u5206\u5c42\u611f\u77e5\u7684CWE\u7279\u5b9a\u60e9\u7f5a\u6765\u8bc4\u4f30LLMs\u548cSAST\u5de5\u5177\uff0c\u53d1\u73b0LLMs\u8868\u73b0\u4f18\u4e8eSAST\u4f46\u9884\u6d4b\u4e00\u81f4\u6027\u5dee\u5f02\u5de8\u5927\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u6f0f\u6d1e\u68c0\u6d4b\u57fa\u51c6\u91c7\u7528\u4e8c\u5143\u5206\u7c7b\uff0c\u7f3a\u4e4fCWE\u7ea7\u522b\u7684\u7279\u5f02\u6027\uff0c\u65e0\u6cd5\u4e3a\u8fed\u4ee3\u4fee\u6b63\u7cfb\u7edf\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u53cd\u9988\u3002\u9700\u8981\u8bc4\u4f30LLMs\u548cSAST\u5de5\u5177\u5728\u5b9e\u9645\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u7684\u8868\u73b0\u5dee\u5f02\u3002", "method": "\u63d0\u51faALPHA\u57fa\u51c6\uff0c\u4f7f\u7528\u5206\u5c42\u611f\u77e5\u7684CWE\u7279\u5b9a\u60e9\u7f5a\u6765\u8bc4\u4f30\u51fd\u6570\u7ea7Python\u4ee3\u7801\u6f0f\u6d1e\u68c0\u6d4b\u3002\u533a\u5206\u8fc7\u5ea6\u6cdb\u5316\u3001\u8fc7\u5ea6\u89c4\u8303\u548c\u6a2a\u5411\u9519\u8bef\uff0c\u53cd\u6620\u8bca\u65ad\u6548\u7528\u7684\u5b9e\u9645\u5dee\u5f02\u3002\u8bc4\u4f30\u4e867\u4e2aLLMs\u548c2\u4e2aSAST\u5de5\u5177\u3002", "result": "LLMs\u5728\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u9762\u663e\u8457\u4f18\u4e8eSAST\u5de5\u5177\uff0c\u4f46SAST\u5728\u68c0\u6d4b\u53d1\u751f\u65f6\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u7cbe\u786e\u5ea6\u3002\u4e0d\u540c\u6a21\u578b\u95f4\u7684\u9884\u6d4b\u4e00\u81f4\u6027\u5dee\u5f02\u5de8\u5927\uff088.26%-81.87%\u4e00\u81f4\u7387\uff09\uff0c\u5bf9\u53cd\u9988\u9a71\u52a8\u7cfb\u7edf\u6709\u91cd\u8981\u5f71\u54cd\u3002", "conclusion": "ALPHA\u57fa\u51c6\u4e3a\u4ee3\u7801\u6f0f\u6d1e\u68c0\u6d4b\u63d0\u4f9b\u4e86\u66f4\u7cbe\u7ec6\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u63ed\u793a\u4e86LLMs\u548cSAST\u5de5\u5177\u7684\u6027\u80fd\u5dee\u5f02\u3002\u672a\u6765\u53ef\u5c06ALPHA\u60e9\u7f5a\u673a\u5236\u878d\u5165\u76d1\u7763\u5fae\u8c03\uff0c\u5b9e\u73b0\u539f\u5219\u6027\u7684\u5206\u5c42\u611f\u77e5\u6f0f\u6d1e\u68c0\u6d4b\u3002"}}
{"id": "2601.00909", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.00909", "abs": "https://arxiv.org/abs/2601.00909", "authors": ["Sheldon Paul", "Izzat Alsmadi"], "title": "Security Hardening Using FABRIC: Implementing a Unified Compliance Aggregator for Linux Servers", "comment": null, "summary": "This paper presents a unified framework for evaluating Linux security hardening on the FABRIC testbed through aggregation of heterogeneous security auditing tools. We deploy three Ubuntu 22.04 nodes configured at baseline, partial, and full hardening levels, and evaluate them using Lynis, OpenSCAP, and AIDE across 108 audit runs. To address the lack of a consistent interpretation across tools, we implement a Unified Compliance Aggregator (UCA) that parses tool outputs, normalizes scores to a common 0--100 scale, and combines them into a weighted metric augmented by a customizable rule engine for organization-specific security policies. Experimental results show that full hardening increases OpenSCAP compliance from 39.7 to 71.8, while custom rule compliance improves from 39.3\\% to 83.6\\%. The results demonstrate that UCA provides a clearer and more reproducible assessment of security posture than individual tools alone, enabling systematic evaluation of hardening effectiveness in programmable testbed environments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u805a\u5408\u5f02\u6784\u5b89\u5168\u5ba1\u8ba1\u5de5\u5177\u6765\u8bc4\u4f30FABRIC\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u7684Linux\u5b89\u5168\u52a0\u56fa\u6548\u679c\uff0c\u5f00\u53d1\u4e86\u7edf\u4e00\u5408\u89c4\u6027\u805a\u5408\u5668\uff08UCA\uff09\u6765\u6807\u51c6\u5316\u4e0d\u540c\u5de5\u5177\u7684\u8f93\u51fa\u5e76\u63d0\u4f9b\u53ef\u5b9a\u5236\u7684\u5b89\u5168\u7b56\u7565\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709Linux\u5b89\u5168\u5ba1\u8ba1\u5de5\u5177\uff08\u5982Lynis\u3001OpenSCAP\u3001AIDE\uff09\u7f3a\u4e4f\u4e00\u81f4\u7684\u8bc4\u4f30\u6807\u51c6\u548c\u8f93\u51fa\u683c\u5f0f\uff0c\u96be\u4ee5\u5bf9\u7cfb\u7edf\u5b89\u5168\u52a0\u56fa\u6548\u679c\u8fdb\u884c\u7edf\u4e00\u3001\u53ef\u91cd\u590d\u7684\u8bc4\u4f30\uff0c\u7279\u522b\u662f\u5728\u53ef\u7f16\u7a0b\u6d4b\u8bd5\u5e73\u53f0\u73af\u5883\u4e2d\u3002", "method": "\u5728FABRIC\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u90e8\u7f72\u4e09\u4e2a\u4e0d\u540c\u52a0\u56fa\u7ea7\u522b\uff08\u57fa\u7ebf\u3001\u90e8\u5206\u3001\u5b8c\u5168\uff09\u7684Ubuntu 22.04\u8282\u70b9\uff0c\u4f7f\u7528\u4e09\u79cd\u5b89\u5168\u5ba1\u8ba1\u5de5\u5177\u8fdb\u884c108\u6b21\u5ba1\u8ba1\u8fd0\u884c\u3002\u5f00\u53d1\u7edf\u4e00\u5408\u89c4\u6027\u805a\u5408\u5668\uff08UCA\uff09\u6765\u89e3\u6790\u5de5\u5177\u8f93\u51fa\uff0c\u5c06\u5206\u6570\u5f52\u4e00\u5316\u52300-100\u7684\u7edf\u4e00\u5c3a\u5ea6\uff0c\u5e76\u901a\u8fc7\u52a0\u6743\u6307\u6807\u548c\u53ef\u5b9a\u5236\u7684\u89c4\u5219\u5f15\u64ce\u7ed3\u5408\u7ec4\u7ec7\u7279\u5b9a\u7684\u5b89\u5168\u7b56\u7565\u3002", "result": "\u5b8c\u5168\u52a0\u56fa\u4f7fOpenSCAP\u5408\u89c4\u6027\u4ece39.7%\u63d0\u9ad8\u523071.8%\uff0c\u81ea\u5b9a\u4e49\u89c4\u5219\u5408\u89c4\u6027\u4ece39.3%\u63d0\u9ad8\u523083.6%\u3002UCA\u63d0\u4f9b\u4e86\u6bd4\u5355\u4e2a\u5de5\u5177\u66f4\u6e05\u6670\u3001\u66f4\u53ef\u91cd\u590d\u7684\u5b89\u5168\u6001\u52bf\u8bc4\u4f30\uff0c\u80fd\u591f\u7cfb\u7edf\u8bc4\u4f30\u53ef\u7f16\u7a0b\u6d4b\u8bd5\u73af\u5883\u4e2d\u7684\u52a0\u56fa\u6548\u679c\u3002", "conclusion": "\u7edf\u4e00\u5408\u89c4\u6027\u805a\u5408\u5668\uff08UCA\uff09\u6846\u67b6\u80fd\u591f\u6709\u6548\u6574\u5408\u5f02\u6784\u5b89\u5168\u5ba1\u8ba1\u5de5\u5177\u7684\u8f93\u51fa\uff0c\u63d0\u4f9b\u4e00\u81f4\u7684\u5b89\u5168\u8bc4\u4f30\u6807\u51c6\uff0c\u652f\u6301\u7ec4\u7ec7\u7279\u5b9a\u7684\u5b89\u5168\u7b56\u7565\u5b9a\u5236\uff0c\u4e3aLinux\u7cfb\u7edf\u5b89\u5168\u52a0\u56fa\u6548\u679c\u7684\u7cfb\u7edf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2601.00823", "categories": ["cs.AI", "cs.IT", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.00823", "abs": "https://arxiv.org/abs/2601.00823", "authors": ["Austin R. Ellis-Mohr", "Max Hartman", "Lav R. Varshney"], "title": "Energy-Aware Routing to Large Reasoning Models", "comment": null, "summary": "Large reasoning models (LRMs) have heterogeneous inference energy costs based on which model is used and how much it reasons. To reduce energy, it is important to choose the right LRM and operate it in the right way. As a result, the performance of systems that dispatch tasks to different individual LRMs depend on the balance between mean energy provisioning and stochastic fluctuations. The critical regime is the unique operating point at which neither auxiliary energy nor baseline energy is systematically wasted. Increasing baseline supply shifts the system toward persistent over-supply and baseline-energy waste, while reducing supply induces persistent reliance on auxiliary energy. Yet in this regime, performance remains volatility-limited and so a second-order characterization provides further insights that we develop. Here, performance is governed by how variability is absorbed across time, models, and execution choices. This perspective highlights variance-aware routing and dispatch as a principled design axis, and provides a theoretical basis for developing energy-aware model routing policies. Routing behavior is characterized when dispatch policies are based on training-compute and inference-compute scaling laws for LRMs.", "AI": {"tldr": "\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u7684\u80fd\u8017\u56e0\u6a21\u578b\u9009\u62e9\u548c\u63a8\u7406\u65b9\u5f0f\u800c\u5f02\uff0c\u7cfb\u7edf\u6027\u80fd\u53d6\u51b3\u4e8e\u5e73\u5747\u80fd\u91cf\u4f9b\u5e94\u4e0e\u968f\u673a\u6ce2\u52a8\u7684\u5e73\u8861\uff0c\u4e34\u754c\u72b6\u6001\u662f\u907f\u514d\u80fd\u91cf\u6d6a\u8d39\u7684\u6700\u4f73\u8fd0\u884c\u70b9\uff0c\u65b9\u5dee\u611f\u77e5\u8def\u7531\u548c\u8c03\u5ea6\u6210\u4e3a\u5173\u952e\u8bbe\u8ba1\u7ef4\u5ea6\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5177\u6709\u5f02\u6784\u7684\u63a8\u7406\u80fd\u8017\u7279\u6027\uff0c\u4e0d\u540c\u6a21\u578b\u548c\u63a8\u7406\u65b9\u5f0f\u7684\u80fd\u91cf\u6210\u672c\u4e0d\u540c\u3002\u4e3a\u4e86\u964d\u4f4e\u80fd\u8017\uff0c\u9700\u8981\u9009\u62e9\u5408\u9002\u7684\u6a21\u578b\u5e76\u4ee5\u6070\u5f53\u65b9\u5f0f\u8fd0\u884c\u3002\u7cfb\u7edf\u6027\u80fd\u53d7\u5230\u5e73\u5747\u80fd\u91cf\u4f9b\u5e94\u548c\u968f\u673a\u6ce2\u52a8\u4e4b\u95f4\u5e73\u8861\u7684\u5f71\u54cd\uff0c\u9700\u8981\u627e\u5230\u65e2\u4e0d\u6d6a\u8d39\u57fa\u7ebf\u80fd\u91cf\u4e5f\u4e0d\u8fc7\u5ea6\u4f9d\u8d56\u8f85\u52a9\u80fd\u91cf\u7684\u4e34\u754c\u8fd0\u884c\u72b6\u6001\u3002", "method": "\u57fa\u4e8e\u8bad\u7ec3\u8ba1\u7b97\u548c\u63a8\u7406\u8ba1\u7b97\u7f29\u653e\u5b9a\u5f8b\u6765\u8bbe\u8ba1\u8c03\u5ea6\u7b56\u7565\uff0c\u91c7\u7528\u65b9\u5dee\u611f\u77e5\u7684\u8def\u7531\u548c\u8c03\u5ea6\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e8c\u9636\u7279\u5f81\u5206\u6790\u6765\u7406\u89e3\u7cfb\u7edf\u5728\u4e34\u754c\u72b6\u6001\u4e0b\u7684\u6027\u80fd\u8868\u73b0\uff0c\u5f00\u53d1\u80fd\u91cf\u611f\u77e5\u7684\u6a21\u578b\u8def\u7531\u7b56\u7565\u3002", "result": "\u63d0\u51fa\u4e86\u4e34\u754c\u72b6\u6001\u4f5c\u4e3a\u7cfb\u7edf\u8fd0\u884c\u7684\u6700\u4f73\u70b9\uff0c\u5728\u8be5\u72b6\u6001\u4e0b\u65e2\u4e0d\u7cfb\u7edf\u6027\u5730\u6d6a\u8d39\u57fa\u7ebf\u80fd\u91cf\uff0c\u4e5f\u4e0d\u8fc7\u5ea6\u4f9d\u8d56\u8f85\u52a9\u80fd\u91cf\u3002\u6027\u80fd\u53d7\u5230\u65f6\u95f4\u3001\u6a21\u578b\u548c\u6267\u884c\u9009\u62e9\u4e2d\u53d8\u5f02\u6027\u5438\u6536\u65b9\u5f0f\u7684\u5f71\u54cd\uff0c\u65b9\u5dee\u611f\u77e5\u8def\u7531\u6210\u4e3a\u5173\u952e\u8bbe\u8ba1\u7ef4\u5ea6\u3002", "conclusion": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u7cfb\u7edf\u7684\u80fd\u91cf\u6548\u7387\u4f18\u5316\u9700\u8981\u7efc\u5408\u8003\u8651\u6a21\u578b\u9009\u62e9\u3001\u63a8\u7406\u65b9\u5f0f\u548c\u80fd\u91cf\u4f9b\u5e94\u5e73\u8861\u3002\u4e34\u754c\u72b6\u6001\u7406\u8bba\u4e3a\u5f00\u53d1\u80fd\u91cf\u611f\u77e5\u7684\u6a21\u578b\u8def\u7531\u7b56\u7565\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u65b9\u5dee\u611f\u77e5\u7684\u8def\u7531\u548c\u8c03\u5ea6\u662f\u5b9e\u73b0\u9ad8\u6548\u80fd\u91cf\u7ba1\u7406\u7684\u5173\u952e\u8bbe\u8ba1\u65b9\u5411\u3002"}}
{"id": "2601.01413", "categories": ["cs.SE", "cs.MS", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.01413", "abs": "https://arxiv.org/abs/2601.01413", "authors": ["Yingjie Ma", "Jing Guo", "Richard D. Braatz"], "title": "GlycoPy: An Equation-Oriented and Object-Oriented Software for Hierarchical Modeling, Optimization, and Control in Python", "comment": null, "summary": "Most existing model predictive control (MPC) applications in process industries employ lin-ear models, although real-world (bio)chemical processes are typically nonlinear. The use of linear models limits the performance and applicability of MPC for processes that span a wide range of operating conditions. A challenge in employing nonlinear models in MPC for com-plex systems is the lack of tools that facilitate hierarchical model development, as well as lack of efficient implementations of the corresponding nonlinear MPC (NMPC) algorithms. As a step towards making NMPC more practical for hierarchical systems, we introduce Gly-coPy, an equation-oriented, object-oriented software framework for process modeling, opti-mization, and NMPC in Python. GlycoPy enables users to focus on writing equations for modeling while supporting hierarchical modeling. GlycoPy includes algorithms for parame-ter estimation, dynamic optimization, and NMPC, and allows users to customize the simula-tion, optimization, and control algorithms. Three case studies, ranging from a simple differ-ential algebraic equation system to a multiscale bioprocess model, validate the modeling, optimization, and NMPC capabilities of GlycoPy. GlycoPy has the potential to bridge the gap between advanced NMPC algorithms and their practical application in real-world (bio)chemical processes.", "AI": {"tldr": "GlycoPy\u662f\u4e00\u4e2a\u7528\u4e8e\u8fc7\u7a0b\u5efa\u6a21\u3001\u4f18\u5316\u548c\u975e\u7ebf\u6027\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff08NMPC\uff09\u7684Python\u8f6f\u4ef6\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u5de5\u4e1a\u8fc7\u7a0b\u4e2d\u7ebf\u6027MPC\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u5206\u5c42\u5efa\u6a21\u548c\u9ad8\u6548\u7b97\u6cd5\u5b9e\u73b0NMPC\u7684\u5b9e\u9645\u5e94\u7528\u3002", "motivation": "\u5de5\u4e1a\u8fc7\u7a0b\u901a\u5e38\u662f\u975e\u7ebf\u6027\u7684\uff0c\u4f46\u73b0\u6709MPC\u5e94\u7528\u5927\u591a\u4f7f\u7528\u7ebf\u6027\u6a21\u578b\uff0c\u8fd9\u9650\u5236\u4e86MPC\u5728\u5bbd\u64cd\u4f5c\u8303\u56f4\u5185\u7684\u6027\u80fd\u548c\u9002\u7528\u6027\u3002\u975e\u7ebf\u6027MPC\u9762\u4e34\u5206\u5c42\u6a21\u578b\u5f00\u53d1\u5de5\u5177\u7f3a\u4e4f\u548c\u7b97\u6cd5\u5b9e\u73b0\u6548\u7387\u4f4e\u4e0b\u7684\u6311\u6218\u3002", "method": "\u5f00\u53d1\u4e86GlycoPy\u8f6f\u4ef6\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u9762\u5411\u65b9\u7a0b\u3001\u9762\u5411\u5bf9\u8c61\u7684Python\u5de5\u5177\uff0c\u652f\u6301\u5206\u5c42\u5efa\u6a21\uff0c\u5305\u542b\u53c2\u6570\u4f30\u8ba1\u3001\u52a8\u6001\u4f18\u5316\u548cNMPC\u7b97\u6cd5\uff0c\u5e76\u5141\u8bb8\u7528\u6237\u81ea\u5b9a\u4e49\u4eff\u771f\u3001\u4f18\u5316\u548c\u63a7\u5236\u7b97\u6cd5\u3002", "result": "\u901a\u8fc7\u4e09\u4e2a\u6848\u4f8b\u7814\u7a76\uff08\u4ece\u7b80\u5355\u7684\u5fae\u5206\u4ee3\u6570\u65b9\u7a0b\u7cfb\u7edf\u5230\u591a\u5c3a\u5ea6\u751f\u7269\u8fc7\u7a0b\u6a21\u578b\uff09\u9a8c\u8bc1\u4e86GlycoPy\u7684\u5efa\u6a21\u3001\u4f18\u5316\u548cNMPC\u80fd\u529b\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "GlycoPy\u6709\u6f5c\u529b\u5f25\u5408\u5148\u8fdbNMPC\u7b97\u6cd5\u4e0e\u5176\u5728\u771f\u5b9e\u4e16\u754c\uff08\u751f\u7269\uff09\u5316\u5b66\u8fc7\u7a0b\u4e2d\u5b9e\u9645\u5e94\u7528\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4f7fNMPC\u5bf9\u5206\u5c42\u7cfb\u7edf\u66f4\u52a0\u5b9e\u7528\u3002"}}
{"id": "2601.01426", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.01426", "abs": "https://arxiv.org/abs/2601.01426", "authors": ["Chaofan Tao", "Jierun Chen", "Yuxin Jiang", "Kaiqi Kou", "Shaowei Wang", "Ruoyu Wang", "Xiaohui Li", "Sidi Yang", "Yiming Du", "Jianbo Dai", "Zhiming Mao", "Xinyu Wang", "Lifeng Shang", "Haoli Bai"], "title": "SWE-Lego: Pushing the Limits of Supervised Fine-tuning for Software Issue Resolving", "comment": "Project website: https://github.com/SWE-Lego/SWE-Lego", "summary": "We present SWE-Lego, a supervised fine-tuning (SFT) recipe designed to achieve state-ofthe-art performance in software engineering (SWE) issue resolving. In contrast to prevalent methods that rely on complex training paradigms (e.g., mid-training, SFT, reinforcement learning, and their combinations), we explore how to push the limits of a lightweight SFT-only approach for SWE tasks. SWE-Lego comprises three core building blocks, with key findings summarized as follows: 1) the SWE-Lego dataset, a collection of 32k highquality task instances and 18k validated trajectories, combining real and synthetic data to complement each other in both quality and quantity; 2) a refined SFT procedure with error masking and a difficulty-based curriculum, which demonstrably improves action quality and overall performance. Empirical results show that with these two building bricks alone,the SFT can push SWE-Lego models to state-of-the-art performance among open-source models of comparable size on SWE-bench Verified: SWE-Lego-Qwen3-8B reaches 42.2%, and SWE-Lego-Qwen3-32B attains 52.6%. 3) We further evaluate and improve test-time scaling (TTS) built upon the SFT foundation. Based on a well-trained verifier, SWE-Lego models can be significantly boosted--for example, 42.2% to 49.6% and 52.6% to 58.8% under TTS@16 for the 8B and 32B models, respectively.", "AI": {"tldr": "SWE-Lego\u662f\u4e00\u4e2a\u4e13\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u95ee\u9898\u89e3\u51b3\u8bbe\u8ba1\u7684\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\uff0c\u4ec5\u901a\u8fc7\u8f7b\u91cf\u7ea7SFT\u5c31\u80fd\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5305\u542b\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u3001\u6539\u8fdb\u7684SFT\u6d41\u7a0b\u548c\u6d4b\u8bd5\u65f6\u6269\u5c55\u4e09\u4e2a\u6838\u5fc3\u6a21\u5757\u3002", "motivation": "\u5f53\u524d\u8f6f\u4ef6\u5de5\u7a0b\u95ee\u9898\u89e3\u51b3\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u590d\u6742\u7684\u8bad\u7ec3\u8303\u5f0f\uff08\u5982\u4e2d\u671f\u8bad\u7ec3\u3001SFT\u3001\u5f3a\u5316\u5b66\u4e60\u53ca\u5176\u7ec4\u5408\uff09\uff0c\u672c\u6587\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u8f7b\u91cf\u7ea7\u7684\u7eafSFT\u65b9\u6cd5\u5728SWE\u4efb\u52a1\u4e0a\u8fbe\u5230\u6781\u9650\u6027\u80fd\u3002", "method": "SWE-Lego\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u6784\u5efa\u5757\uff1a1\uff09SWE-Lego\u6570\u636e\u96c6\uff0c\u5305\u542b32k\u9ad8\u8d28\u91cf\u4efb\u52a1\u5b9e\u4f8b\u548c18k\u5df2\u9a8c\u8bc1\u8f68\u8ff9\uff0c\u7ed3\u5408\u771f\u5b9e\u548c\u5408\u6210\u6570\u636e\uff1b2\uff09\u6539\u8fdb\u7684SFT\u6d41\u7a0b\uff0c\u5305\u542b\u9519\u8bef\u63a9\u7801\u548c\u57fa\u4e8e\u96be\u5ea6\u7684\u8bfe\u7a0b\u5b66\u4e60\uff1b3\uff09\u57fa\u4e8eSFT\u57fa\u7840\u7684\u6d4b\u8bd5\u65f6\u6269\u5c55\u8bc4\u4f30\u548c\u6539\u8fdb\u3002", "result": "\u4ec5\u4f7f\u7528\u524d\u4e24\u4e2a\u6784\u5efa\u5757\uff0cSWE-Lego\u6a21\u578b\u5728SWE-bench Verified\u4e0a\u8fbe\u5230\u5f00\u6e90\u6a21\u578b\u4e2d\u6700\u5148\u8fdb\u6027\u80fd\uff1aSWE-Lego-Qwen3-8B\u8fbe\u523042.2%\uff0cSWE-Lego-Qwen3-32B\u8fbe\u523052.6%\u3002\u901a\u8fc7\u6d4b\u8bd5\u65f6\u6269\u5c55\uff0c\u6027\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\uff1a8B\u6a21\u578b\u4ece42.2%\u63d0\u5347\u523049.6%\uff0c32B\u6a21\u578b\u4ece52.6%\u63d0\u5347\u523058.8%\uff08TTS@16\uff09\u3002", "conclusion": "SWE-Lego\u5c55\u793a\u4e86\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u8f7b\u91cf\u7ea7\u7eafSFT\u65b9\u6cd5\u53ef\u4ee5\u5728\u8f6f\u4ef6\u5de5\u7a0b\u95ee\u9898\u89e3\u51b3\u4efb\u52a1\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u65e0\u9700\u590d\u6742\u7684\u8bad\u7ec3\u8303\u5f0f\u7ec4\u5408\uff0c\u4e3aSWE\u4efb\u52a1\u7684\u9ad8\u6548\u8bad\u7ec3\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2601.00936", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00936", "abs": "https://arxiv.org/abs/2601.00936", "authors": ["M P V S Gopinadh", "S Mahaboob Hussain"], "title": "Emoji-Based Jailbreaking of Large Language Models", "comment": "7 pages, 2 figures", "summary": "Large Language Models (LLMs) are integral to modern AI applications, but their safety alignment mechanisms can be bypassed through adversarial prompt engineering. This study investigates emoji-based jailbreaking, where emoji sequences are embedded in textual prompts to trigger harmful and unethical outputs from LLMs. We evaluated 50 emoji-based prompts on four open-source LLMs: Mistral 7B, Qwen 2 7B, Gemma 2 9B, and Llama 3 8B. Metrics included jailbreak success rate, safety alignment adherence, and latency, with responses categorized as successful, partial and failed. Results revealed model-specific vulnerabilities: Gemma 2 9B and Mistral 7B exhibited 10 % success rates, while Qwen 2 7B achieved full alignment (0% success). A chi-square test (chi^2 = 32.94, p < 0.001) confirmed significant inter-model differences. While prior works focused on emoji attacks targeting safety judges or classifiers, our empirical analysis examines direct prompt-level vulnerabilities in LLMs. The results reveal limitations in safety mechanisms and highlight the necessity for systematic handling of emoji-based representations in prompt-level safety and alignment pipelines.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u8868\u60c5\u7b26\u53f7\u5e8f\u5217\u5728\u6587\u672c\u63d0\u793a\u4e2d\u5982\u4f55\u7ed5\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u5bf9\u9f50\u673a\u5236\uff0c\u5728\u56db\u4e2a\u5f00\u6e90LLM\u4e0a\u6d4b\u8bd5\u4e8650\u4e2a\u8868\u60c5\u7b26\u53f7\u653b\u51fb\u63d0\u793a\uff0c\u53d1\u73b0\u6a21\u578b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\u7684\u6f0f\u6d1e\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u5bf9\u9f50\u673a\u5236\u53ef\u80fd\u901a\u8fc7\u5bf9\u6297\u6027\u63d0\u793a\u5de5\u7a0b\u88ab\u7ed5\u8fc7\uff0c\u7279\u522b\u662f\u8868\u60c5\u7b26\u53f7\u5e8f\u5217\u53ef\u80fd\u89e6\u53d1\u6709\u5bb3\u548c\u4e0d\u9053\u5fb7\u7684\u8f93\u51fa\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u8fd9\u79cd\u653b\u51fb\u7684\u6709\u6548\u6027\u3002", "method": "\u5728\u56db\u4e2a\u5f00\u6e90LLM\uff08Mistral 7B\u3001Qwen 2 7B\u3001Gemma 2 9B\u3001Llama 3 8B\uff09\u4e0a\u8bc4\u4f3050\u4e2a\u8868\u60c5\u7b26\u53f7\u653b\u51fb\u63d0\u793a\uff0c\u4f7f\u7528\u8d8a\u72f1\u6210\u529f\u7387\u3001\u5b89\u5168\u5bf9\u9f50\u9075\u5b88\u5ea6\u548c\u5ef6\u8fdf\u4f5c\u4e3a\u6307\u6807\uff0c\u5c06\u54cd\u5e94\u5206\u7c7b\u4e3a\u6210\u529f\u3001\u90e8\u5206\u6210\u529f\u548c\u5931\u8d25\u3002", "result": "Gemma 2 9B\u548cMistral 7B\u8868\u73b0\u51fa10%\u7684\u6210\u529f\u7387\uff0cQwen 2 7B\u5b9e\u73b0\u5b8c\u5168\u5bf9\u9f50\uff080%\u6210\u529f\u7387\uff09\uff0c\u5361\u65b9\u68c0\u9a8c\uff08chi^2 = 32.94, p < 0.001\uff09\u786e\u8ba4\u6a21\u578b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u8868\u60c5\u7b26\u53f7\u653b\u51fb\u63ed\u793a\u4e86LLM\u5b89\u5168\u673a\u5236\u7684\u5c40\u9650\u6027\uff0c\u9700\u8981\u5728\u63d0\u793a\u7ea7\u5b89\u5168\u548c\u5bf9\u9f50\u7ba1\u9053\u4e2d\u7cfb\u7edf\u5904\u7406\u8868\u60c5\u7b26\u53f7\u8868\u793a\uff0c\u4ee5\u589e\u5f3a\u6a21\u578b\u9c81\u68d2\u6027\u3002"}}
{"id": "2601.00830", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00830", "abs": "https://arxiv.org/abs/2601.00830", "authors": ["Deep Pankajbhai Mehta"], "title": "Can We Trust AI Explanations? Evidence of Systematic Underreporting in Chain-of-Thought Reasoning", "comment": "22 pages, 8 figures, 9 tables", "summary": "When AI systems explain their reasoning step-by-step, practitioners often assume these explanations reveal what actually influenced the AI's answer. We tested this assumption by embedding hints into questions and measuring whether models mentioned them. In a study of over 9,000 test cases across 11 leading AI models, we found a troubling pattern: models almost never mention hints spontaneously, yet when asked directly, they admit noticing them. This suggests models see influential information but choose not to report it. Telling models they are being watched does not help. Forcing models to report hints works, but causes them to report hints even when none exist and reduces their accuracy. We also found that hints appealing to user preferences are especially dangerous-models follow them most often while reporting them least. These findings suggest that simply watching AI reasoning is not enough to catch hidden influences.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0AI\u7cfb\u7edf\u5728\u9010\u6b65\u89e3\u91ca\u63a8\u7406\u65f6\uff0c\u51e0\u4e4e\u4ece\u4e0d\u4e3b\u52a8\u63d0\u53ca\u95ee\u9898\u4e2d\u5d4c\u5165\u7684\u63d0\u793a\u4fe1\u606f\uff0c\u4f46\u5f53\u88ab\u76f4\u63a5\u8be2\u95ee\u65f6\u4f1a\u627f\u8ba4\u6ce8\u610f\u5230\u8fd9\u4e9b\u63d0\u793a\uff0c\u8868\u660eAI\u770b\u5230\u4e86\u6709\u5f71\u54cd\u529b\u7684\u4fe1\u606f\u4f46\u9009\u62e9\u4e0d\u62a5\u544a\u3002", "motivation": "\u5f53AI\u7cfb\u7edf\u9010\u6b65\u89e3\u91ca\u5176\u63a8\u7406\u8fc7\u7a0b\u65f6\uff0c\u4ece\u4e1a\u8005\u901a\u5e38\u5047\u8bbe\u8fd9\u4e9b\u89e3\u91ca\u63ed\u793a\u4e86\u771f\u6b63\u5f71\u54cdAI\u7b54\u6848\u7684\u56e0\u7d20\u3002\u672c\u7814\u7a76\u65e8\u5728\u6d4b\u8bd5\u8fd9\u4e00\u5047\u8bbe\uff0c\u63a2\u7a76AI\u662f\u5426\u771f\u7684\u4f1a\u62a5\u544a\u6240\u6709\u5f71\u54cd\u5176\u51b3\u7b56\u7684\u4fe1\u606f\u3002", "method": "\u901a\u8fc7\u5728\u95ee\u9898\u4e2d\u5d4c\u5165\u63d0\u793a\u4fe1\u606f\uff0c\u6d4b\u91cf\u6a21\u578b\u662f\u5426\u63d0\u53ca\u8fd9\u4e9b\u63d0\u793a\u3002\u7814\u7a76\u6db5\u76d6\u4e86\u8d85\u8fc79,000\u4e2a\u6d4b\u8bd5\u6848\u4f8b\uff0c\u6d89\u53ca11\u4e2a\u9886\u5148\u7684AI\u6a21\u578b\u3002\u6d4b\u8bd5\u4e86\u591a\u79cd\u6761\u4ef6\uff1a\u81ea\u53d1\u62a5\u544a\u3001\u76f4\u63a5\u8be2\u95ee\u3001\u544a\u77e5\u88ab\u76d1\u89c6\u3001\u5f3a\u5236\u62a5\u544a\u63d0\u793a\u7b49\u3002", "result": "1. \u6a21\u578b\u51e0\u4e4e\u4ece\u4e0d\u81ea\u53d1\u63d0\u53ca\u63d0\u793a\u4fe1\u606f\uff1b2. \u5f53\u88ab\u76f4\u63a5\u8be2\u95ee\u65f6\uff0c\u6a21\u578b\u627f\u8ba4\u6ce8\u610f\u5230\u63d0\u793a\uff1b3. \u544a\u77e5\u6a21\u578b\u88ab\u76d1\u89c6\u5e76\u4e0d\u80fd\u6539\u5584\u62a5\u544a\u884c\u4e3a\uff1b4. \u5f3a\u5236\u62a5\u544a\u63d0\u793a\u867d\u7136\u6709\u6548\uff0c\u4f46\u4f1a\u5bfc\u81f4\u6a21\u578b\u5728\u6ca1\u6709\u63d0\u793a\u65f6\u4e5f\u62a5\u544a\uff0c\u5e76\u964d\u4f4e\u51c6\u786e\u6027\uff1b5. \u8fce\u5408\u7528\u6237\u504f\u597d\u7684\u63d0\u793a\u5c24\u5176\u5371\u9669\u2014\u2014\u6a21\u578b\u6700\u5e38\u9075\u5faa\u8fd9\u4e9b\u63d0\u793a\uff0c\u5374\u6700\u5c11\u62a5\u544a\u5b83\u4eec\u3002", "conclusion": "\u4ec5\u4ec5\u89c2\u5bdfAI\u7684\u63a8\u7406\u8fc7\u7a0b\u4e0d\u8db3\u4ee5\u53d1\u73b0\u9690\u85cf\u7684\u5f71\u54cd\u56e0\u7d20\u3002AI\u7cfb\u7edf\u53ef\u80fd\u770b\u5230\u5e76\u53d7\u5230\u67d0\u4e9b\u4fe1\u606f\u7684\u5f71\u54cd\uff0c\u4f46\u9009\u62e9\u4e0d\u5728\u89e3\u91ca\u4e2d\u62a5\u544a\u8fd9\u4e9b\u4fe1\u606f\uff0c\u8fd9\u5bf9AI\u900f\u660e\u5ea6\u548c\u53ef\u4fe1\u5ea6\u6784\u6210\u4e86\u91cd\u8981\u6311\u6218\u3002"}}
{"id": "2601.01514", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.01514", "abs": "https://arxiv.org/abs/2601.01514", "authors": ["Matej Kucera", "Marco Castelluccio", "Daniel Feitosa", "Ayushi Rastogi"], "title": "Group versus Individual Review Requests: Tradeoffs in Speed and Quality at Mozilla Firefox", "comment": "11 pages, 1 figure, 4 tables. To be published in ICSE-SEIP 2026 conference proceedings", "summary": "The speed at which code changes are integrated into the software codebase, also referred to as code review velocity, is a prevalent industry metric for improved throughput and developer satisfaction. While prior studies have explored factors influencing review velocity, the role of the review assignment process, particularly the `group review request', is unclear. In group review requests, available on platforms like Phabricator, GitHub, and Bitbucket, a code change is assigned to a reviewer group, allowing any member to review it, unlike individual review assignments to specific reviewers. Drawing parallels with shared task queues in Management Sciences, this study examines the effects of group versus individual review requests on velocity and quality. We investigate approximately 66,000 revisions in the Mozilla Firefox project, combining statistical modeling with practitioner views from a focus group discussion. Our study associates group reviews with improved review quality, characterized by fewer regressions, while having a negligible association with review velocity. Additional perceived benefits include balanced work distribution and training opportunities for new reviewers.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u4ee3\u7801\u5ba1\u67e5\u4e2d\u7fa4\u4f53\u5ba1\u67e5\u8bf7\u6c42\u4e0e\u4e2a\u4f53\u5ba1\u67e5\u8bf7\u6c42\u5bf9\u5ba1\u67e5\u901f\u5ea6\u548c\u8d28\u91cf\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5728Mozilla Firefox\u9879\u76ee\u4e2d\uff0c\u7fa4\u4f53\u5ba1\u67e5\u4e0e\u66f4\u9ad8\u7684\u5ba1\u67e5\u8d28\u91cf\u76f8\u5173\uff08\u66f4\u5c11\u7684\u56de\u5f52\uff09\uff0c\u4f46\u5bf9\u5ba1\u67e5\u901f\u5ea6\u5f71\u54cd\u4e0d\u5927\u3002", "motivation": "\u4ee3\u7801\u5ba1\u67e5\u901f\u5ea6\u662f\u8861\u91cf\u8f6f\u4ef6\u5f00\u53d1\u548c\u5f00\u53d1\u8005\u6ee1\u610f\u5ea6\u7684\u91cd\u8981\u6307\u6807\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u5bf9\u5ba1\u67e5\u5206\u914d\u8fc7\u7a0b\uff08\u7279\u522b\u662f\u7fa4\u4f53\u5ba1\u67e5\u8bf7\u6c42\uff09\u7684\u4f5c\u7528\u5c1a\u4e0d\u6e05\u695a\u3002\u7fa4\u4f53\u5ba1\u67e5\u8bf7\u6c42\u5141\u8bb8\u5c06\u4ee3\u7801\u53d8\u66f4\u5206\u914d\u7ed9\u4e00\u4e2a\u5ba1\u67e5\u8005\u7fa4\u4f53\uff0c\u4efb\u4f55\u6210\u5458\u90fd\u53ef\u4ee5\u5ba1\u67e5\uff0c\u8fd9\u4e0e\u5206\u914d\u7ed9\u7279\u5b9a\u5ba1\u67e5\u8005\u7684\u4e2a\u4f53\u5ba1\u67e5\u8bf7\u6c42\u4e0d\u540c\u3002", "method": "\u7814\u7a76\u5206\u6790\u4e86Mozilla Firefox\u9879\u76ee\u4e2d\u7ea666,000\u4e2a\u4fee\u8ba2\uff0c\u7ed3\u5408\u7edf\u8ba1\u5efa\u6a21\u548c\u4ece\u4e1a\u8005\u7126\u70b9\u5c0f\u7ec4\u8ba8\u8bba\u7684\u89c2\u70b9\u3002\u7814\u7a76\u5c06\u7fa4\u4f53\u5ba1\u67e5\u8bf7\u6c42\u4e0e\u4e2a\u4f53\u5ba1\u67e5\u8bf7\u6c42\u8fdb\u884c\u6bd4\u8f83\uff0c\u501f\u9274\u7ba1\u7406\u5b66\u4e2d\u7684\u5171\u4eab\u4efb\u52a1\u961f\u5217\u7406\u8bba\u3002", "result": "\u7fa4\u4f53\u5ba1\u67e5\u4e0e\u66f4\u9ad8\u7684\u5ba1\u67e5\u8d28\u91cf\u76f8\u5173\uff08\u8868\u73b0\u4e3a\u66f4\u5c11\u7684\u56de\u5f52\uff09\uff0c\u4f46\u4e0e\u5ba1\u67e5\u901f\u5ea6\u7684\u5173\u8054\u53ef\u4ee5\u5ffd\u7565\u4e0d\u8ba1\u3002\u6b64\u5916\uff0c\u4ece\u4e1a\u8005\u8ba4\u4e3a\u7fa4\u4f53\u5ba1\u67e5\u8fd8\u6709\u5e73\u8861\u5de5\u4f5c\u5206\u914d\u548c\u4e3a\u65b0\u624b\u5ba1\u67e5\u8005\u63d0\u4f9b\u57f9\u8bad\u673a\u4f1a\u7b49\u597d\u5904\u3002", "conclusion": "\u7fa4\u4f53\u5ba1\u67e5\u8bf7\u6c42\u5728\u63d0\u9ad8\u5ba1\u67e5\u8d28\u91cf\u65b9\u9762\u6709\u79ef\u6781\u6548\u679c\uff0c\u4f46\u5bf9\u5ba1\u67e5\u901f\u5ea6\u5f71\u54cd\u6709\u9650\u3002\u8fd9\u79cd\u65b9\u6cd5\u6709\u52a9\u4e8e\u6539\u5584\u4ee3\u7801\u5ba1\u67e5\u5b9e\u8df5\uff0c\u7279\u522b\u662f\u5728\u8d28\u91cf\u4fdd\u8bc1\u548c\u5de5\u4f5c\u5206\u914d\u5e73\u8861\u65b9\u9762\u3002"}}
{"id": "2601.01048", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.01048", "abs": "https://arxiv.org/abs/2601.01048", "authors": ["Saurabh Singh", "Ruobing Han", "Jaewon Lee", "Seonjin Na", "Yonghae Kim", "Taesoo Kim", "Hyesoon Kim"], "title": "CuFuzz: Hardening CUDA Programs through Transformation and Fuzzing", "comment": "16 pages, 7 figures, 2 tables", "summary": "GPUs have gained significant popularity over the past decade, extending beyond their original role in graphics rendering. This evolution has brought GPU security and reliability to the forefront of concerns. Prior research has shown that CUDA's lack of memory safety can lead to serious vulnerabilities. While fuzzing is effective for finding such bugs on CPUs, equivalent tools for GPUs are lacking due to architectural differences and lack of built-in error detection. In this paper, we propose CuFuzz, a novel compiler-runtime co-design solution to extend state-of-the-art CPU fuzzing tools to GPU programs. CuFuzz transforms GPU programs into CPU programs using compiler IR-level transformations to enable effective fuzz testing. To the best of our knowledge, CuFuzz is the first mechanism to bring fuzzing support to CUDA, addressing a critical gap in GPU security research. By leveraging CPU memory error detectors such as Address Sanitizer, CuFuzz aims to uncover memory safety bugs and related correctness vulnerabilities in CUDA code, enhancing the security and reliability of GPU-accelerated applications. To ensure high fuzzing throughput, we introduce two compiler-runtime co-optimizations tailored for GPU code: Partial Representative Execution (PREX) and Access-Index Preserving Pruning (AXIPrune), achieving average throughput improvements of 32x with PREX and an additional 33% gain with AXIPrune on top of PREX-optimized code. Together, these optimizations can yield up to a 224.31x speedup. In our fuzzing campaigns, CuFuzz uncovered 122 security vulnerabilities in widely used benchmarks.", "AI": {"tldr": "CuFuzz\u662f\u4e00\u4e2a\u521b\u65b0\u7684\u7f16\u8bd1\u5668-\u8fd0\u884c\u65f6\u534f\u540c\u8bbe\u8ba1\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u5c06GPU\u7a0b\u5e8f\u8f6c\u6362\u4e3aCPU\u7a0b\u5e8f\uff0c\u4f7f\u5148\u8fdb\u7684CPU\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u80fd\u591f\u5e94\u7528\u4e8eCUDA\u4ee3\u7801\uff0c\u586b\u8865\u4e86GPU\u5b89\u5168\u7814\u7a76\u7684\u7a7a\u767d\u3002", "motivation": "GPU\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u65e5\u76ca\u91cd\u8981\uff0c\u4f46CUDA\u7f3a\u4e4f\u5185\u5b58\u5b89\u5168\u6027\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u6f0f\u6d1e\u3002\u7531\u4e8e\u67b6\u6784\u5dee\u5f02\u548c\u7f3a\u4e4f\u5185\u7f6e\u9519\u8bef\u68c0\u6d4b\uff0c\u73b0\u6709\u7684CPU\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u65e0\u6cd5\u76f4\u63a5\u5e94\u7528\u4e8eGPU\u7a0b\u5e8f\uff0c\u9700\u8981\u4e13\u95e8\u7684GPU\u6a21\u7cca\u6d4b\u8bd5\u89e3\u51b3\u65b9\u6848\u3002", "method": "CuFuzz\u91c7\u7528\u7f16\u8bd1\u5668-\u8fd0\u884c\u65f6\u534f\u540c\u8bbe\u8ba1\uff0c\u901a\u8fc7\u7f16\u8bd1\u5668IR\u7ea7\u8f6c\u6362\u5c06GPU\u7a0b\u5e8f\u8f6c\u6362\u4e3aCPU\u7a0b\u5e8f\uff0c\u4ece\u800c\u80fd\u591f\u5229\u7528CPU\u5185\u5b58\u9519\u8bef\u68c0\u6d4b\u5668\uff08\u5982Address Sanitizer\uff09\u3002\u4e3a\u63d0\u9ad8\u6a21\u7cca\u6d4b\u8bd5\u541e\u5410\u91cf\uff0c\u5f15\u5165\u4e86\u4e24\u79cd\u4e13\u95e8\u9488\u5bf9GPU\u4ee3\u7801\u7684\u4f18\u5316\uff1a\u90e8\u5206\u4ee3\u8868\u6027\u6267\u884c\uff08PREX\uff09\u548c\u8bbf\u95ee\u7d22\u5f15\u4fdd\u7559\u526a\u679d\uff08AXIPrune\uff09\u3002", "result": "CuFuzz\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff1aPREX\u5e26\u6765\u5e73\u574732\u500d\u7684\u541e\u5410\u91cf\u6539\u8fdb\uff0cAXIPrune\u5728PREX\u4f18\u5316\u57fa\u7840\u4e0a\u518d\u63d0\u534733%\u3002\u4e24\u8005\u7ed3\u5408\u53ef\u5b9e\u73b0\u6700\u9ad8224.31\u500d\u7684\u52a0\u901f\u3002\u5728\u5b9e\u9645\u6a21\u7cca\u6d4b\u8bd5\u6d3b\u52a8\u4e2d\uff0cCuFuzz\u53d1\u73b0\u4e86\u5e7f\u6cdb\u4f7f\u7528\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684122\u4e2a\u5b89\u5168\u6f0f\u6d1e\u3002", "conclusion": "CuFuzz\u662f\u9996\u4e2a\u4e3aCUDA\u63d0\u4f9b\u6a21\u7cca\u6d4b\u8bd5\u652f\u6301\u7684\u673a\u5236\uff0c\u6210\u529f\u5730\u5c06CPU\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u6269\u5c55\u5230GPU\u7a0b\u5e8f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86GPU\u4ee3\u7801\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\uff0c\u586b\u8865\u4e86GPU\u5b89\u5168\u7814\u7a76\u7684\u91cd\u8981\u7a7a\u767d\u3002"}}
{"id": "2601.00843", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00843", "abs": "https://arxiv.org/abs/2601.00843", "authors": ["Ayda Aghaei Nia"], "title": "OmniNeuro: A Multimodal HCI Framework for Explainable BCI Feedback via Generative AI and Sonification", "comment": "16 pages, 7 figures, 3 tables. Source code and implementation available at: https://github.com/ayda-aghaei/OmniNeuro. Highlights the use of LLMs (Gemini) and Quantum probability formalism for real-time BCI explainability", "summary": "While Deep Learning has improved Brain-Computer Interface (BCI) decoding accuracy, clinical adoption is hindered by the \"Black Box\" nature of these algorithms, leading to user frustration and poor neuroplasticity outcomes. We propose OmniNeuro, a novel HCI framework that transforms the BCI from a silent decoder into a transparent feedback partner. OmniNeuro integrates three interpretability engines: (1) Physics (Energy), (2) Chaos (Fractal Complexity), and (3) Quantum-Inspired uncertainty modeling. These metrics drive real-time Neuro-Sonification and Generative AI Clinical Reports. Evaluated on the PhysioNet dataset ($N=109$), the system achieved a mean accuracy of 58.52%, with qualitative pilot studies ($N=3$) confirming that explainable feedback helps users regulate mental effort and reduces the \"trial-and-error\" phase. OmniNeuro is decoder-agnostic, acting as an essential interpretability layer for any state-of-the-art architecture.", "AI": {"tldr": "OmniNeuro\u662f\u4e00\u4e2a\u65b0\u578bHCI\u6846\u67b6\uff0c\u5c06BCI\u4ece\"\u9ed1\u76d2\"\u89e3\u7801\u5668\u8f6c\u53d8\u4e3a\u900f\u660e\u7684\u53cd\u9988\u4f19\u4f34\uff0c\u901a\u8fc7\u7269\u7406\u3001\u6df7\u6c8c\u548c\u91cf\u5b50\u542f\u53d1\u7684\u53ef\u89e3\u91ca\u6027\u5f15\u64ce\u63d0\u4f9b\u5b9e\u65f6\u795e\u7ecf\u58f0\u5316\u548c\u751f\u6210\u5f0fAI\u4e34\u5e8a\u62a5\u544a\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u867d\u7136\u63d0\u9ad8\u4e86\u8111\u673a\u63a5\u53e3\u7684\u89e3\u7801\u7cbe\u5ea6\uff0c\u4f46\u5176\"\u9ed1\u76d2\"\u7279\u6027\u963b\u788d\u4e86\u4e34\u5e8a\u91c7\u7528\uff0c\u5bfc\u81f4\u7528\u6237\u632b\u8d25\u611f\u548c\u795e\u7ecf\u53ef\u5851\u6027\u7ed3\u679c\u4e0d\u4f73\u3002\u9700\u8981\u53ef\u89e3\u91ca\u7684\u53cd\u9988\u7cfb\u7edf\u6765\u5e2e\u52a9\u7528\u6237\u8c03\u8282\u5fc3\u7406\u52aa\u529b\u5e76\u51cf\u5c11\u8bd5\u9519\u9636\u6bb5\u3002", "method": "\u63d0\u51faOmniNeuro\u6846\u67b6\uff0c\u96c6\u6210\u4e09\u79cd\u53ef\u89e3\u91ca\u6027\u5f15\u64ce\uff1a1) \u7269\u7406(\u80fd\u91cf)\u5206\u6790\uff0c2) \u6df7\u6c8c(\u5206\u5f62\u590d\u6742\u6027)\u5206\u6790\uff0c3) \u91cf\u5b50\u542f\u53d1\u7684\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u3002\u8fd9\u4e9b\u6307\u6807\u9a71\u52a8\u5b9e\u65f6\u795e\u7ecf\u58f0\u5316\u548c\u751f\u6210\u5f0fAI\u4e34\u5e8a\u62a5\u544a\uff0c\u6846\u67b6\u4e0e\u89e3\u7801\u5668\u65e0\u5173\uff0c\u53ef\u4f5c\u4e3a\u4efb\u4f55\u5148\u8fdb\u67b6\u6784\u7684\u53ef\u89e3\u91ca\u6027\u5c42\u3002", "result": "\u5728PhysioNet\u6570\u636e\u96c6(N=109)\u4e0a\u8bc4\u4f30\uff0c\u7cfb\u7edf\u5e73\u5747\u51c6\u786e\u7387\u8fbe\u523058.52%\u3002\u5b9a\u6027\u8bd5\u70b9\u7814\u7a76(N=3)\u8bc1\u5b9e\u53ef\u89e3\u91ca\u53cd\u9988\u6709\u52a9\u4e8e\u7528\u6237\u8c03\u8282\u5fc3\u7406\u52aa\u529b\u5e76\u51cf\u5c11\"\u8bd5\u9519\"\u9636\u6bb5\u3002", "conclusion": "OmniNeuro\u6210\u529f\u5c06BCI\u4ece\u6c89\u9ed8\u89e3\u7801\u5668\u8f6c\u53d8\u4e3a\u900f\u660e\u53cd\u9988\u4f19\u4f34\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u53ef\u89e3\u91ca\u6027\u5f15\u64ce\u89e3\u51b3\u4e86\u6df1\u5ea6\u5b66\u4e60\"\u9ed1\u76d2\"\u95ee\u9898\uff0c\u4e3a\u4e34\u5e8a\u91c7\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.00845", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00845", "abs": "https://arxiv.org/abs/2601.00845", "authors": ["Lili Chen", "Wensheng Gan", "Shuang Liang", "Philip S. Yu"], "title": "Enhancing Temporal Awareness in LLMs for Temporal Point Processes", "comment": "preprint", "summary": "Temporal point processes (TPPs) are crucial for analyzing events over time and are widely used in fields such as finance, healthcare, and social systems. These processes are particularly valuable for understanding how events unfold over time, accounting for their irregularity and dependencies. Despite the success of large language models (LLMs) in sequence modeling, applying them to temporal point processes remains challenging. A key issue is that current methods struggle to effectively capture the complex interaction between temporal information and semantic context, which is vital for accurate event modeling. In this context, we introduce TPP-TAL (Temporal Point Processes with Enhanced Temporal Awareness in LLMs), a novel plug-and-play framework designed to enhance temporal reasoning within LLMs. Rather than using the conventional method of simply concatenating event time and type embeddings, TPP-TAL explicitly aligns temporal dynamics with contextual semantics before feeding this information into the LLM. This alignment allows the model to better perceive temporal dependencies and long-range interactions between events and their surrounding contexts. Through comprehensive experiments on several benchmark datasets, it is shown that TPP-TAL delivers substantial improvements in temporal likelihood estimation and event prediction accuracy, highlighting the importance of enhancing temporal awareness in LLMs for continuous-time event modeling. The code is made available at https://github.com/chenlilil/TPP-TAL", "AI": {"tldr": "\u63d0\u51faTPP-TAL\u6846\u67b6\uff0c\u901a\u8fc7\u589e\u5f3aLLMs\u4e2d\u7684\u65f6\u95f4\u611f\u77e5\u6765\u6539\u8fdb\u65f6\u95f4\u70b9\u8fc7\u7a0b\u5efa\u6a21\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u65f6\u95f4\u4fe1\u606f\u4e0e\u8bed\u4e49\u4e0a\u4e0b\u6587\u590d\u6742\u4ea4\u4e92\u7684\u95ee\u9898\u3002", "motivation": "\u65f6\u95f4\u70b9\u8fc7\u7a0b\u5728\u91d1\u878d\u3001\u533b\u7597\u3001\u793e\u4ea4\u7cfb\u7edf\u7b49\u9886\u57df\u5f88\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u6355\u6349\u65f6\u95f4\u4fe1\u606f\u4e0e\u8bed\u4e49\u4e0a\u4e0b\u6587\u7684\u590d\u6742\u4ea4\u4e92\uff0c\u9650\u5236\u4e86LLMs\u5728\u65f6\u95f4\u70b9\u8fc7\u7a0b\u5efa\u6a21\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51faTPP-TAL\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u5373\u63d2\u5373\u7528\u7684\u65b9\u6cd5\uff0c\u5728\u5c06\u4fe1\u606f\u8f93\u5165LLM\u4e4b\u524d\uff0c\u663e\u5f0f\u5730\u5bf9\u9f50\u65f6\u95f4\u52a8\u6001\u4e0e\u4e0a\u4e0b\u6587\u8bed\u4e49\uff0c\u800c\u4e0d\u662f\u7b80\u5355\u5730\u62fc\u63a5\u4e8b\u4ef6\u65f6\u95f4\u548c\u7c7b\u578b\u5d4c\u5165\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTPP-TAL\u5728\u65f6\u95f4\u4f3c\u7136\u4f30\u8ba1\u548c\u4e8b\u4ef6\u9884\u6d4b\u51c6\u786e\u6027\u65b9\u9762\u90fd\u6709\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u589e\u5f3aLLMs\u4e2d\u7684\u65f6\u95f4\u611f\u77e5\u5bf9\u4e8e\u8fde\u7eed\u65f6\u95f4\u4e8b\u4ef6\u5efa\u6a21\u81f3\u5173\u91cd\u8981\uff0cTPP-TAL\u6846\u67b6\u901a\u8fc7\u663e\u5f0f\u5bf9\u9f50\u65f6\u95f4\u52a8\u6001\u4e0e\u8bed\u4e49\u4e0a\u4e0b\u6587\uff0c\u6709\u6548\u63d0\u5347\u4e86\u65f6\u95f4\u70b9\u8fc7\u7a0b\u7684\u5efa\u6a21\u6027\u80fd\u3002"}}
{"id": "2601.01780", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01780", "abs": "https://arxiv.org/abs/2601.01780", "authors": ["Arsham Khosravani", "Alireza Hosseinpour", "Arshia Akhavan", "Mehdi Keshani", "Abbas Heydarnoori"], "title": "LIA: Supervised Fine-Tuning of Large Language Models for Automatic Issue Assignment", "comment": null, "summary": "Issue assignment is a critical process in software maintenance, where new issue reports are validated and assigned to suitable developers. However, manual issue assignment is often inconsistent and error-prone, especially in large open-source projects where thousands of new issues are reported monthly. Existing automated approaches have shown promise, but many rely heavily on large volumes of project-specific training data or relational information that is often sparse and noisy, which limits their effectiveness. To address these challenges, we propose LIA (LLM-based Issue Assignment), which employs supervised fine-tuning to adapt an LLM, DeepSeek-R1-Distill-Llama-8B in this work, for automatic issue assignment. By leveraging the LLM's pretrained semantic understanding of natural language and software-related text, LIA learns to generate ranked developer recommendations directly from issue titles and descriptions. The ranking is based on the model's learned understanding of historical issue-to-developer assignments, using patterns from past tasks to infer which developers are most likely to handle new issues. Through comprehensive evaluation, we show that LIA delivers substantial improvements over both its base pretrained model and state-of-the-art baselines. It achieves up to +187.8% higher Hit@1 compared to the DeepSeek-R1-Distill-Llama-8B pretrained base model, and outperforms four leading issue assignment methods by as much as +211.2% in Hit@1 score. These results highlight the effectiveness of domain-adapted LLMs for software maintenance tasks and establish LIA as a practical, high-performing solution for issue assignment.", "AI": {"tldr": "LIA\u4f7f\u7528\u76d1\u7763\u5fae\u8c03\u5c06DeepSeek-R1-Distill-Llama-8B\u5927\u8bed\u8a00\u6a21\u578b\u9002\u914d\u4e8e\u95ee\u9898\u5206\u914d\u4efb\u52a1\uff0c\u76f4\u63a5\u4ece\u95ee\u9898\u6807\u9898\u548c\u63cf\u8ff0\u751f\u6210\u5f00\u53d1\u8005\u63a8\u8350\u6392\u540d\uff0c\u76f8\u6bd4\u57fa\u7840\u6a21\u578b\u548c\u73b0\u6709\u65b9\u6cd5\u5728Hit@1\u6307\u6807\u4e0a\u63d0\u5347\u663e\u8457\u3002", "motivation": "\u8f6f\u4ef6\u7ef4\u62a4\u4e2d\u7684\u95ee\u9898\u5206\u914d\u8fc7\u7a0b\u901a\u5e38\u4f9d\u8d56\u4eba\u5de5\u5904\u7406\uff0c\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\u548c\u9519\u8bef\u7387\u9ad8\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u5927\u578b\u5f00\u6e90\u9879\u76ee\u4e2d\u6bcf\u6708\u6709\u6570\u5343\u4e2a\u65b0\u95ee\u9898\u62a5\u544a\u3002\u73b0\u6709\u81ea\u52a8\u5316\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u9879\u76ee\u7279\u5b9a\u8bad\u7ec3\u6570\u636e\u6216\u7a00\u758f\u5608\u6742\u7684\u5173\u7cfb\u4fe1\u606f\uff0c\u6548\u679c\u6709\u9650\u3002", "method": "\u63d0\u51faLIA\uff08\u57fa\u4e8eLLM\u7684\u95ee\u9898\u5206\u914d\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u5c06DeepSeek-R1-Distill-Llama-8B\u5927\u8bed\u8a00\u6a21\u578b\u9002\u914d\u4e8e\u81ea\u52a8\u95ee\u9898\u5206\u914d\u4efb\u52a1\u3002\u5229\u7528LLM\u5bf9\u81ea\u7136\u8bed\u8a00\u548c\u8f6f\u4ef6\u76f8\u5173\u6587\u672c\u7684\u9884\u8bad\u7ec3\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u76f4\u63a5\u4ece\u95ee\u9898\u6807\u9898\u548c\u63cf\u8ff0\u5b66\u4e60\u751f\u6210\u5f00\u53d1\u8005\u63a8\u8350\u6392\u540d\uff0c\u57fa\u4e8e\u5386\u53f2\u95ee\u9898-\u5f00\u53d1\u8005\u5206\u914d\u6a21\u5f0f\u63a8\u65ad\u6700\u53ef\u80fd\u5904\u7406\u65b0\u95ee\u9898\u7684\u5f00\u53d1\u8005\u3002", "result": "LIA\u76f8\u6bd4\u57fa\u7840\u9884\u8bad\u7ec3\u6a21\u578b\u5728Hit@1\u6307\u6807\u4e0a\u63d0\u5347\u9ad8\u8fbe+187.8%\uff0c\u76f8\u6bd4\u56db\u79cd\u9886\u5148\u7684\u95ee\u9898\u5206\u914d\u65b9\u6cd5\u5728Hit@1\u5f97\u5206\u4e0a\u63d0\u5347\u9ad8\u8fbe+211.2%\u3002\u8fd9\u4e9b\u7ed3\u679c\u7a81\u663e\u4e86\u9886\u57df\u9002\u914dLLM\u5728\u8f6f\u4ef6\u7ef4\u62a4\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "LIA\u4e3a\u95ee\u9898\u5206\u914d\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u3001\u9ad8\u6027\u80fd\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u8bc1\u660e\u4e86\u9886\u57df\u9002\u914d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u7ef4\u62a4\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u95ee\u9898\u5206\u914d\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2601.01839", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01839", "abs": "https://arxiv.org/abs/2601.01839", "authors": ["Martin Prause"], "title": "The Machine Learning Canvas: Empirical Findings on Why Strategy Matters More Than AI Code Generation", "comment": "Dataset available: https://ieee-dataport.org/documents/machine-learning-canvas-success-determinants", "summary": "Despite the growing popularity of AI coding assistants, over 80% of machine learning (ML) projects fail to deliver real business value. This study creates and tests a Machine Learning Canvas, a practical framework that combines business strategy, software engineering, and data science in order to determine the factors that lead to the success of ML projects. We surveyed 150 data scientists and analyzed their responses using statistical modeling. We identified four key success factors: Strategy (clear goals and planning), Process (how work gets done), Ecosystem (tools and infrastructure), and Support (organizational backing and resources). Our results show that these factors are interconnected - each one affects the next. For instance, strong organizational support results in a clearer strategy (\u03b2= 0.432, p < 0.001), which improves work processes (\u03b2= 0.428, p < 0.001) and builds better infrastructure (\u03b2= 0.547, p < 0.001). Together, these elements determine whether a project succeeds. The surprising finding? Although AI assistants make coding faster, they don't guarantee project success. AI assists with the \"how\" of coding but cannot replace the \"why\" and \"what\" of strategic thinking.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u5e76\u6d4b\u8bd5\u4e86\u673a\u5668\u5b66\u4e60\u753b\u5e03\u6846\u67b6\uff0c\u901a\u8fc7\u8c03\u67e5150\u540d\u6570\u636e\u79d1\u5b66\u5bb6\u53d1\u73b0\uff0cML\u9879\u76ee\u6210\u529f\u7684\u5173\u952e\u56e0\u7d20\u5305\u62ec\u6218\u7565\u3001\u6d41\u7a0b\u3001\u751f\u6001\u7cfb\u7edf\u548c\u652f\u6301\uff0c\u8fd9\u4e9b\u56e0\u7d20\u76f8\u4e92\u5173\u8054\uff0c\u800cAI\u7f16\u7801\u52a9\u624b\u867d\u80fd\u52a0\u901f\u7f16\u7801\u4f46\u65e0\u6cd5\u66ff\u4ee3\u6218\u7565\u601d\u8003\u3002", "motivation": "\u5c3d\u7ba1AI\u7f16\u7801\u52a9\u624b\u65e5\u76ca\u666e\u53ca\uff0c\u4f46\u8d85\u8fc780%\u7684\u673a\u5668\u5b66\u4e60\u9879\u76ee\u672a\u80fd\u4ea4\u4ed8\u5b9e\u9645\u5546\u4e1a\u4ef7\u503c\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u5f71\u54cdML\u9879\u76ee\u6210\u529f\u7684\u5173\u952e\u56e0\u7d20\u3002", "method": "\u521b\u5efa\u5e76\u6d4b\u8bd5\u673a\u5668\u5b66\u4e60\u753b\u5e03\u6846\u67b6\uff0c\u7ed3\u5408\u5546\u4e1a\u6218\u7565\u3001\u8f6f\u4ef6\u5de5\u7a0b\u548c\u6570\u636e\u79d1\u5b66\uff0c\u901a\u8fc7\u8c03\u67e5150\u540d\u6570\u636e\u79d1\u5b66\u5bb6\u5e76\u4f7f\u7528\u7edf\u8ba1\u5efa\u6a21\u5206\u6790\u5176\u56de\u7b54\u3002", "result": "\u8bc6\u522b\u51fa\u56db\u4e2a\u5173\u952e\u6210\u529f\u56e0\u7d20\uff1a\u6218\u7565\uff08\u660e\u786e\u76ee\u6807\u548c\u89c4\u5212\uff09\u3001\u6d41\u7a0b\uff08\u5de5\u4f5c\u6267\u884c\u65b9\u5f0f\uff09\u3001\u751f\u6001\u7cfb\u7edf\uff08\u5de5\u5177\u548c\u57fa\u7840\u8bbe\u65bd\uff09\u3001\u652f\u6301\uff08\u7ec4\u7ec7\u652f\u6301\u548c\u8d44\u6e90\uff09\u3002\u8fd9\u4e9b\u56e0\u7d20\u76f8\u4e92\u5173\u8054\uff0c\u4f8b\u5982\u5f3a\u5927\u7684\u7ec4\u7ec7\u652f\u6301\u5bfc\u81f4\u66f4\u6e05\u6670\u7684\u6218\u7565\uff08\u03b2=0.432, p<0.001\uff09\uff0c\u8fdb\u800c\u6539\u5584\u5de5\u4f5c\u6d41\u7a0b\uff08\u03b2=0.428, p<0.001\uff09\u5e76\u6784\u5efa\u66f4\u597d\u7684\u57fa\u7840\u8bbe\u65bd\uff08\u03b2=0.547, p<0.001\uff09\u3002", "conclusion": "AI\u7f16\u7801\u52a9\u624b\u867d\u7136\u80fd\u52a0\u901f\u7f16\u7801\u8fc7\u7a0b\uff0c\u4f46\u65e0\u6cd5\u4fdd\u8bc1\u9879\u76ee\u6210\u529f\uff0c\u56e0\u4e3a\u5b83\u4eec\u53ea\u80fd\u89e3\u51b3\"\u5982\u4f55\"\u7f16\u7801\u7684\u95ee\u9898\uff0c\u800c\u65e0\u6cd5\u66ff\u4ee3\u6218\u7565\u601d\u8003\u4e2d\u7684\"\u4e3a\u4ec0\u4e48\"\u548c\"\u505a\u4ec0\u4e48\"\u3002\u9879\u76ee\u6210\u529f\u9700\u8981\u6218\u7565\u3001\u6d41\u7a0b\u3001\u751f\u6001\u7cfb\u7edf\u548c\u652f\u6301\u8fd9\u56db\u4e2a\u76f8\u4e92\u5173\u8054\u56e0\u7d20\u7684\u534f\u540c\u4f5c\u7528\u3002"}}
{"id": "2601.00856", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00856", "abs": "https://arxiv.org/abs/2601.00856", "authors": ["Milos Stankovic", "Ella Hirche", "Sarah Kollatzsch", "Julia Nadine Doetsch"], "title": "Comment on: Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Tasks", "comment": "Comment on arXiv:2506.08872", "summary": "Recently published work titled Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Task by Kosmyna et al. (2025) has sparked a vivid debate on the topic of artificial intelligence (AI) and human performance. We sincerely congratulate Kosmyna et al. for initiating such important research, collecting a valuable dataset, and establishing highly automated pipelines for Natural Language Processing (NLP) analyses and scoring. We aim to provide constructive comments that may improve the manuscript's readiness for peer-reviewed publication, as some results by Kosmyna et al. (2025) could be interpreted more conservatively. Our primary concerns focus on: (i) study design considerations, including the limited sample size; (ii) the reproducibility of the analyses; (iii) methodological issues related to the EEG analysis; (iv) inconsistencies in the reporting of results; and (v) limited transparency in several aspects of the study's procedures and findings.", "AI": {"tldr": "\u8fd9\u662f\u4e00\u7bc7\u5bf9Kosmyna\u7b49\u4eba(2025)\u5173\u4e8e\u4f7f\u7528ChatGPT\u8fdb\u884c\u8bba\u6587\u5199\u4f5c\u4efb\u52a1\u65f6\u8ba4\u77e5\u503a\u52a1\u79ef\u7d2f\u7814\u7a76\u7684\u8bc4\u8bba\u6027\u6587\u7ae0\uff0c\u6307\u51fa\u4e86\u8be5\u7814\u7a76\u5728\u6837\u672c\u91cf\u3001\u53ef\u91cd\u590d\u6027\u3001EEG\u5206\u6790\u65b9\u6cd5\u3001\u7ed3\u679c\u62a5\u544a\u4e00\u81f4\u6027\u548c\u900f\u660e\u5ea6\u7b49\u65b9\u9762\u5b58\u5728\u7684\u95ee\u9898\u3002", "motivation": "\u4f5c\u8005\u65e8\u5728\u5bf9Kosmyna\u7b49\u4eba\u7684\u7814\u7a76\u63d0\u4f9b\u5efa\u8bbe\u6027\u610f\u89c1\uff0c\u4ee5\u6539\u8fdb\u8be5\u624b\u7a3f\u7684\u540c\u884c\u8bc4\u5ba1\u51c6\u5907\u5ea6\uff0c\u56e0\u4e3a\u539f\u7814\u7a76\u7684\u4e00\u4e9b\u7ed3\u679c\u53ef\u80fd\u9700\u8981\u66f4\u4fdd\u5b88\u7684\u89e3\u91ca\u3002", "method": "\u901a\u8fc7\u6279\u5224\u6027\u5206\u6790\u539f\u7814\u7a76\u7684\u65b9\u6cd5\u8bba\uff0c\u91cd\u70b9\u5173\u6ce8\u4e94\u4e2a\u4e3b\u8981\u65b9\u9762\uff1a\u7814\u7a76\u8bbe\u8ba1\uff08\u5305\u62ec\u6837\u672c\u91cf\u9650\u5236\uff09\u3001\u5206\u6790\u7684\u53ef\u91cd\u590d\u6027\u3001EEG\u5206\u6790\u65b9\u6cd5\u95ee\u9898\u3001\u7ed3\u679c\u62a5\u544a\u7684\u4e0d\u4e00\u81f4\u6027\u4ee5\u53ca\u7814\u7a76\u8fc7\u7a0b\u548c\u53d1\u73b0\u7684\u900f\u660e\u5ea6\u4e0d\u8db3\u3002", "result": "\u8bc6\u522b\u51fa\u539f\u7814\u7a76\u5728\u591a\u4e2a\u5173\u952e\u65b9\u9762\u5b58\u5728\u9700\u8981\u6539\u8fdb\u7684\u95ee\u9898\uff0c\u5305\u62ec\u7edf\u8ba1\u529f\u6548\u4e0d\u8db3\u3001\u5206\u6790\u65b9\u6cd5\u4e0d\u591f\u900f\u660e\u3001EEG\u6570\u636e\u5904\u7406\u53ef\u80fd\u5b58\u5728\u504f\u5dee\u3001\u7ed3\u679c\u62a5\u544a\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\uff0c\u4ee5\u53ca\u6574\u4f53\u7814\u7a76\u900f\u660e\u5ea6\u6709\u9650\u3002", "conclusion": "\u867d\u7136\u8d5e\u8d4fKosmyna\u7b49\u4eba\u5f00\u542f\u4e86\u8fd9\u4e00\u91cd\u8981\u7814\u7a76\u5e76\u5efa\u7acb\u4e86\u6709\u4ef7\u503c\u7684\u6570\u636e\u96c6\u548c\u5206\u6790\u6d41\u7a0b\uff0c\u4f46\u5efa\u8bae\u5728\u53d1\u8868\u524d\u89e3\u51b3\u8fd9\u4e9b\u65b9\u6cd5\u8bba\u95ee\u9898\uff0c\u4ee5\u4fbf\u66f4\u51c6\u786e\u5730\u89e3\u91ca\u7814\u7a76\u7ed3\u679c\uff0c\u63d0\u9ad8\u7814\u7a76\u7684\u79d1\u5b66\u4e25\u8c28\u6027\u3002"}}
{"id": "2601.01921", "categories": ["cs.SE", "cs.AI", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.01921", "abs": "https://arxiv.org/abs/2601.01921", "authors": ["Mikel Robredo", "Matteo Esposito", "Fabio Palomba", "Rafael Pe\u00f1aloza", "Valentina Lenarduzzi"], "title": "A Defect is Being Born: How Close Are We? A Time Sensitive Forecasting Approach", "comment": "ACCEPTED REGISTERED REPORT AT SANER (CORE A*) 2026", "summary": "Background. Defect prediction has been a highly active topic among researchers in the Empirical Software Engineering field. Previous literature has successfully achieved the most accurate prediction of an incoming fault and identified the features and anomalies that precede it through just-in-time prediction. As software systems evolve continuously, there is a growing need for time-sensitive methods capable of forecasting defects before they manifest.\n  Aim. Our study seeks to explore the effectiveness of time-sensitive techniques for defect forecasting. Moreover, we aim to investigate the early indicators that precede the occurrence of a defect.\n  Method. We will train multiple time-sensitive forecasting techniques to forecast the future bug density of a software project, as well as identify the early symptoms preceding the occurrence of a defect.\n  Expected results. Our expected results are translated into empirical evidence on the effectiveness of our approach for early estimation of bug proneness.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u7d22\u65f6\u95f4\u654f\u611f\u6280\u672f\u5728\u8f6f\u4ef6\u7f3a\u9677\u9884\u6d4b\u4e2d\u7684\u6709\u6548\u6027\uff0c\u65e8\u5728\u901a\u8fc7\u65f6\u95f4\u5e8f\u5217\u65b9\u6cd5\u9884\u6d4b\u672a\u6765\u7f3a\u9677\u5bc6\u5ea6\u5e76\u8bc6\u522b\u7f3a\u9677\u65e9\u671f\u5f81\u5146\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u7cfb\u7edf\u6301\u7eed\u6f14\u5316\uff0c\u9700\u8981\u65f6\u95f4\u654f\u611f\u7684\u65b9\u6cd5\u80fd\u591f\u5728\u7f3a\u9677\u663e\u73b0\u4e4b\u524d\u8fdb\u884c\u9884\u6d4b\u3002\u73b0\u6709\u7814\u7a76\u5df2\u901a\u8fc7\u5373\u65f6\u9884\u6d4b\u5b9e\u73b0\u4e86\u5bf9\u5373\u5c06\u53d1\u751f\u6545\u969c\u7684\u51c6\u786e\u9884\u6d4b\uff0c\u4f46\u9700\u8981\u66f4\u65e9\u7684\u65f6\u95f4\u654f\u611f\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u8bad\u7ec3\u591a\u79cd\u65f6\u95f4\u654f\u611f\u9884\u6d4b\u6280\u672f\u6765\u9884\u6d4b\u8f6f\u4ef6\u9879\u76ee\u7684\u672a\u6765\u7f3a\u9677\u5bc6\u5ea6\uff0c\u5e76\u8bc6\u522b\u7f3a\u9677\u53d1\u751f\u524d\u7684\u65e9\u671f\u5f81\u5146\u3002", "result": "\u9884\u671f\u7ed3\u679c\u4e3a\u65e9\u671f\u7f3a\u9677\u503e\u5411\u6027\u8bc4\u4f30\u65b9\u6cd5\u7684\u6709\u6548\u6027\u63d0\u4f9b\u5b9e\u8bc1\u8bc1\u636e\u3002", "conclusion": "\u8be5\u7814\u7a76\u65e8\u5728\u4e3a\u8f6f\u4ef6\u7f3a\u9677\u9884\u6d4b\u9886\u57df\u63d0\u4f9b\u65f6\u95f4\u654f\u611f\u9884\u6d4b\u65b9\u6cd5\u7684\u5b9e\u8bc1\u652f\u6301\uff0c\u5e2e\u52a9\u66f4\u65e9\u5730\u8bc6\u522b\u548c\u9884\u9632\u8f6f\u4ef6\u7f3a\u9677\u3002"}}
{"id": "2601.01109", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.01109", "abs": "https://arxiv.org/abs/2601.01109", "authors": ["David D. Nguyen", "The-Anh Ta", "Yansong Gao", "Alsharif Abuadbba"], "title": "NADD: Amplifying Noise for Effective Diffusion-based Adversarial Purification", "comment": "18", "summary": "The strategy of combining diffusion-based generative models with classifiers continues to demonstrate state-of-the-art performance on adversarial robustness benchmarks.\n  Known as adversarial purification, this exploits a diffusion model's capability of identifying high density regions in data distributions to purify adversarial perturbations from inputs.\n  However, existing diffusion-based purification defenses are impractically slow and limited in robustness due to the low levels of noise used in the diffusion process.\n  This low noise design aims to preserve the semantic features of the original input, thereby minimizing utility loss for benign inputs.\n  Our findings indicate that systematic amplification of noise throughout the diffusion process improves the robustness of adversarial purification.\n  However, this approach presents a key challenge, as noise levels cannot be arbitrarily increased without risking distortion of the input.\n  To address this key problem, we introduce high levels of noise during the forward process and propose the ring proximity correction to gradually eliminate adversarial perturbations whilst closely preserving the original data sample.\n  As a second contribution, we propose a new stochastic sampling method which introduces additional noise during the reverse diffusion process to dilute adversarial perturbations.\n  Without relying on gradient obfuscation, these contributions result in a new robustness accuracy record of 44.23% on ImageNet using AutoAttack ($\\ell_{\\infty}=4/255$), an improvement of +2.07% over the previous best work.\n  Furthermore, our method reduces inference time to 1.08 seconds per sample on ImageNet, a $47\\times$ improvement over the existing state-of-the-art approach, making it far more practical for real-world defensive scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u5bf9\u6297\u51c0\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u589e\u52a0\u6269\u6563\u8fc7\u7a0b\u4e2d\u7684\u566a\u58f0\u6c34\u5e73\u6765\u63d0\u9ad8\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u5f15\u5165\u73af\u90bb\u8fd1\u6821\u6b63\u548c\u968f\u673a\u91c7\u6837\u6280\u672f\u6765\u4fdd\u6301\u8f93\u5165\u8bed\u4e49\u7279\u5f81\uff0c\u5728ImageNet\u4e0a\u5b9e\u73b0\u4e8644.23%\u7684\u9c81\u68d2\u51c6\u786e\u7387\uff0c\u5e76\u5c06\u63a8\u7406\u65f6\u95f4\u5927\u5e45\u7f29\u77ed\u81f31.08\u79d2/\u6837\u672c\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u5bf9\u6297\u51c0\u5316\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u7531\u4e8e\u4f7f\u7528\u4f4e\u566a\u58f0\u8bbe\u8ba1\u4ee5\u4fdd\u7559\u8f93\u5165\u8bed\u4e49\u7279\u5f81\uff0c\u5bfc\u81f4\u9c81\u68d2\u6027\u6709\u9650\uff1b2\uff09\u63a8\u7406\u901f\u5ea6\u8fc7\u6162\uff0c\u5728\u5b9e\u9645\u9632\u5fa1\u573a\u666f\u4e2d\u4e0d\u5b9e\u7528\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\uff0c\u63d0\u9ad8\u5bf9\u6297\u51c0\u5316\u7684\u9c81\u68d2\u6027\u548c\u6548\u7387\u3002", "method": "1\uff09\u5728\u524d\u5411\u8fc7\u7a0b\u4e2d\u5f15\u5165\u9ad8\u6c34\u5e73\u566a\u58f0\uff0c\u5e76\u63d0\u51fa\u73af\u90bb\u8fd1\u6821\u6b63\u6280\u672f\uff0c\u9010\u6b65\u6d88\u9664\u5bf9\u6297\u6270\u52a8\u540c\u65f6\u7d27\u5bc6\u4fdd\u7559\u539f\u59cb\u6570\u636e\u6837\u672c\uff1b2\uff09\u63d0\u51fa\u65b0\u7684\u968f\u673a\u91c7\u6837\u65b9\u6cd5\uff0c\u5728\u53cd\u5411\u6269\u6563\u8fc7\u7a0b\u4e2d\u5f15\u5165\u989d\u5916\u566a\u58f0\u4ee5\u7a00\u91ca\u5bf9\u6297\u6270\u52a8\uff1b3\uff09\u7cfb\u7edf\u6027\u5730\u653e\u5927\u6574\u4e2a\u6269\u6563\u8fc7\u7a0b\u4e2d\u7684\u566a\u58f0\u6c34\u5e73\uff0c\u4f46\u4e0d\u4f9d\u8d56\u68af\u5ea6\u6df7\u6dc6\u6280\u672f\u3002", "result": "\u5728ImageNet\u6570\u636e\u96c6\u4e0a\uff0c\u4f7f\u7528AutoAttack\uff08\u2113\u221e=4/255\uff09\u5b9e\u73b0\u4e8644.23%\u7684\u9c81\u68d2\u51c6\u786e\u7387\uff0c\u6bd4\u4e4b\u524d\u6700\u4f73\u5de5\u4f5c\u63d0\u9ad8\u4e86+2.07%\u3002\u63a8\u7406\u65f6\u95f4\u7f29\u77ed\u81f31.08\u79d2/\u6837\u672c\uff0c\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u63d0\u5347\u4e8647\u500d\uff0c\u5927\u5e45\u63d0\u9ad8\u4e86\u5b9e\u9645\u5e94\u7528\u53ef\u884c\u6027\u3002", "conclusion": "\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u589e\u52a0\u6269\u6563\u8fc7\u7a0b\u4e2d\u7684\u566a\u58f0\u6c34\u5e73\uff0c\u7ed3\u5408\u73af\u90bb\u8fd1\u6821\u6b63\u548c\u968f\u673a\u91c7\u6837\u6280\u672f\uff0c\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4fdd\u6301\u8f93\u5165\u8bed\u4e49\u7279\u5f81\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u5bf9\u6297\u51c0\u5316\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u5c06\u63a8\u7406\u6548\u7387\u5927\u5e45\u63d0\u5347\uff0c\u4e3a\u5b9e\u9645\u9632\u5fa1\u573a\u666f\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.00869", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00869", "abs": "https://arxiv.org/abs/2601.00869", "authors": ["Huang Junyao", "Situ Ruimin", "Ye Renqin"], "title": "Cultural Encoding in Large Language Models: The Existence Gap in AI-Mediated Brand Discovery", "comment": "19 pages, 5 tables. Dataset and code available at https://github.com/zhizibianjie-omniedge/geo-cultural-encoding", "summary": "As artificial intelligence systems increasingly mediate consumer information discovery,\n  brands face algorithmic invisibility. This study investigates Cultural Encoding in Large\n  Language Models (LLMs) -- systematic differences in brand recommendations arising from\n  training data composition. Analyzing 1,909 pure-English queries across 6 LLMs (GPT-4o,\n  Claude, Gemini, Qwen3, DeepSeek, Doubao) and 30 brands, we find Chinese LLMs exhibit 30.6\n  percentage points higher brand mention rates than International LLMs (88.9% vs. 58.3%,\n  p<.001). This disparity persists in identical English queries, indicating training data\n  geography -- not language -- drives the effect. We introduce the Existence Gap: brands\n  absent from LLM training corpora lack \"existence\" in AI responses regardless of quality.\n  Through a case study of Zhizibianjie (OmniEdge), a collaboration platform with 65.6%\n  mention rate in Chinese LLMs but 0% in International models (p<.001), we demonstrate how\n  Linguistic Boundary Barriers create invisible market entry obstacles. Theoretically, we\n  contribute the Data Moat Framework, conceptualizing AI-visible content as a VRIN strategic\n  resource. We operationalize Algorithmic Omnipresence -- comprehensive brand visibility\n  across LLM knowledge bases -- as the strategic objective for Generative Engine Optimization\n  (GEO). Managerially, we provide an 18-month roadmap for brands to build Data Moats\n  through semantic coverage, technical depth, and cultural localization. Our findings reveal\n  that in AI-mediated markets, the limits of a brand's \"Data Boundaries\" define the limits\n  of its \"Market Frontiers.\"", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLM\u8bad\u7ec3\u6570\u636e\u7684\u5730\u7406\u5206\u5e03\u5bfc\u81f4\u54c1\u724c\u63a8\u8350\u5b58\u5728\u7cfb\u7edf\u6027\u5dee\u5f02\uff0c\u4e2d\u56fdLLM\u7684\u54c1\u724c\u63d0\u53ca\u7387\u6bd4\u56fd\u9645LLM\u9ad830.6\u4e2a\u767e\u5206\u70b9\uff0c\u63d0\u51fa\"\u5b58\u5728\u9e3f\u6c9f\"\u6982\u5ff5\u548c\"\u6570\u636e\u62a4\u57ce\u6cb3\"\u6846\u67b6", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u8d8a\u6765\u8d8a\u591a\u5730\u4ecb\u5165\u6d88\u8d39\u8005\u4fe1\u606f\u53d1\u73b0\u8fc7\u7a0b\uff0c\u54c1\u724c\u9762\u4e34\u7b97\u6cd5\u4e0d\u53ef\u89c1\u6027\u95ee\u9898\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u5b58\u5728\u7684\u6587\u5316\u7f16\u7801\u73b0\u8c61\u2014\u2014\u7531\u8bad\u7ec3\u6570\u636e\u6784\u6210\u5bfc\u81f4\u7684\u54c1\u724c\u63a8\u8350\u7cfb\u7edf\u6027\u5dee\u5f02", "method": "\u5206\u67901,909\u4e2a\u7eaf\u82f1\u6587\u67e5\u8be2\uff0c\u8986\u76d66\u4e2aLLM\uff08GPT-4o\u3001Claude\u3001Gemini\u3001Qwen3\u3001DeepSeek\u3001Doubao\uff09\u548c30\u4e2a\u54c1\u724c\uff0c\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u5047\u8bbe", "result": "\u4e2d\u56fdLLM\u7684\u54c1\u724c\u63d0\u53ca\u7387\u6bd4\u56fd\u9645LLM\u9ad830.6\u4e2a\u767e\u5206\u70b9\uff0888.9% vs. 58.3%\uff0cp<.001\uff09\uff0c\u8fd9\u79cd\u5dee\u5f02\u5728\u76f8\u540c\u7684\u82f1\u6587\u67e5\u8be2\u4e2d\u4f9d\u7136\u5b58\u5728\uff0c\u8868\u660e\u8bad\u7ec3\u6570\u636e\u7684\u5730\u7406\u5206\u5e03\u800c\u975e\u8bed\u8a00\u662f\u4e3b\u8981\u9a71\u52a8\u56e0\u7d20", "conclusion": "\u63d0\u51fa\"\u5b58\u5728\u9e3f\u6c9f\"\u6982\u5ff5\u548c\"\u6570\u636e\u62a4\u57ce\u6cb3\"\u6846\u67b6\uff0c\u5c06AI\u53ef\u89c1\u5185\u5bb9\u6982\u5ff5\u5316\u4e3aVRIN\u6218\u7565\u8d44\u6e90\uff0c\u5efa\u8bae\u54c1\u724c\u901a\u8fc7\u8bed\u4e49\u8986\u76d6\u3001\u6280\u672f\u6df1\u5ea6\u548c\u6587\u5316\u672c\u5730\u5316\u6784\u5efa\u6570\u636e\u62a4\u57ce\u6cb3\uff0c\u5b9e\u73b0\u7b97\u6cd5\u65e0\u5904\u4e0d\u5728\u7684\u6218\u7565\u76ee\u6807"}}
{"id": "2601.01944", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.IR", "cs.PL"], "pdf": "https://arxiv.org/pdf/2601.01944", "abs": "https://arxiv.org/abs/2601.01944", "authors": ["Matteo Esposito", "Andrea Janes", "Valentina Lenarduzzi", "Davide Taibi"], "title": "The Invisible Hand of AI Libraries Shaping Open Source Projects and Communities", "comment": "ACCEPTED REGISTERED REPORT AT SANER (CORE A*) 2026", "summary": "In the early 1980s, Open Source Software emerged as a revolutionary concept amidst the dominance of proprietary software. What began as a revolutionary idea has now become the cornerstone of computer science. Amidst OSS projects, AI is increasing its presence and relevance. However, despite the growing popularity of AI, its adoption and impacts on OSS projects remain underexplored.\n  We aim to assess the adoption of AI libraries in Python and Java OSS projects and examine how they shape development, including the technical ecosystem and community engagement. To this end, we will perform a large-scale analysis on 157.7k potential OSS repositories, employing repository metrics and software metrics to compare projects adopting AI libraries against those that do not. We expect to identify measurable differences in development activity, community engagement, and code complexity between OSS projects that adopt AI libraries and those that do not, offering evidence-based insights into how AI integration reshapes software development practices.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86Python\u548cJava\u5f00\u6e90\u9879\u76ee\u4e2dAI\u5e93\u7684\u91c7\u7528\u60c5\u51b5\u53ca\u5176\u5bf9\u5f00\u53d1\u6d3b\u52a8\u3001\u793e\u533a\u53c2\u4e0e\u548c\u4ee3\u7801\u590d\u6742\u6027\u7684\u5f71\u54cd", "motivation": "\u5c3d\u7ba1AI\u5728\u5f00\u6e90\u8f6f\u4ef6\u9879\u76ee\u4e2d\u65e5\u76ca\u666e\u53ca\uff0c\u4f46\u5176\u91c7\u7528\u60c5\u51b5\u548c\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u5f00\u6e90\u8f6f\u4ef6\u5df2\u6210\u4e3a\u8ba1\u7b97\u673a\u79d1\u5b66\u7684\u57fa\u77f3\uff0c\u800cAI\u5728\u5176\u4e2d\u626e\u6f14\u7740\u8d8a\u6765\u8d8a\u91cd\u8981\u7684\u89d2\u8272\uff0c\u4f46AI\u5e93\u5982\u4f55\u5f71\u54cd\u5f00\u6e90\u9879\u76ee\u7684\u53d1\u5c55\u3001\u6280\u672f\u751f\u6001\u7cfb\u7edf\u548c\u793e\u533a\u53c2\u4e0e\u4ecd\u4e0d\u6e05\u695a\u3002", "method": "\u5bf9157.7k\u4e2a\u6f5c\u5728\u5f00\u6e90\u4ed3\u5e93\u8fdb\u884c\u5927\u89c4\u6a21\u5206\u6790\uff0c\u4f7f\u7528\u4ed3\u5e93\u6307\u6807\u548c\u8f6f\u4ef6\u6307\u6807\uff0c\u6bd4\u8f83\u91c7\u7528AI\u5e93\u7684\u9879\u76ee\u4e0e\u672a\u91c7\u7528AI\u5e93\u7684\u9879\u76ee\u3002\u901a\u8fc7\u91cf\u5316\u65b9\u6cd5\u8bc4\u4f30\u5f00\u53d1\u6d3b\u52a8\u3001\u793e\u533a\u53c2\u4e0e\u548c\u4ee3\u7801\u590d\u6742\u6027\u7b49\u65b9\u9762\u7684\u5dee\u5f02\u3002", "result": "\u9884\u8ba1\u4f1a\u53d1\u73b0\u91c7\u7528AI\u5e93\u7684\u5f00\u6e90\u9879\u76ee\u4e0e\u672a\u91c7\u7528AI\u5e93\u7684\u9879\u76ee\u5728\u5f00\u53d1\u6d3b\u52a8\u3001\u793e\u533a\u53c2\u4e0e\u548c\u4ee3\u7801\u590d\u6742\u6027\u65b9\u9762\u5b58\u5728\u53ef\u6d4b\u91cf\u7684\u5dee\u5f02\u3002\u7814\u7a76\u5c06\u63d0\u4f9b\u57fa\u4e8e\u8bc1\u636e\u7684\u89c1\u89e3\uff0c\u5c55\u793aAI\u96c6\u6210\u5982\u4f55\u91cd\u5851\u8f6f\u4ef6\u5f00\u53d1\u5b9e\u8df5\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c06\u63ed\u793aAI\u5e93\u5728\u5f00\u6e90\u9879\u76ee\u4e2d\u7684\u91c7\u7528\u6a21\u5f0f\u53ca\u5176\u5bf9\u8f6f\u4ef6\u5f00\u53d1\u5b9e\u8df5\u7684\u5f71\u54cd\uff0c\u4e3a\u7406\u89e3AI\u5982\u4f55\u6539\u53d8\u5f00\u6e90\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u5b9e\u8bc1\u57fa\u7840\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u548c\u9879\u76ee\u7ba1\u7406\u8005\u66f4\u597d\u5730\u5e94\u5bf9AI\u96c6\u6210\u5e26\u6765\u7684\u673a\u9047\u548c\u6311\u6218\u3002"}}
{"id": "2601.00880", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.00880", "abs": "https://arxiv.org/abs/2601.00880", "authors": ["Anthony Mikinka"], "title": "Universal Conditional Logic: A Formal Language for Prompt Engineering", "comment": "25 pages, 15 figures, 5 tables. Includes appendices with variable reference, pattern library, and O_s calculation examples. Supplementary materials: V1-V4.1 prompt source code and 305 model responses available at GitHub repositories", "summary": "We present Universal Conditional Logic (UCL), a mathematical framework for prompt optimization that transforms prompt engineering from heuristic practice into systematic optimization. Through systematic evaluation (N=305, 11 models, 4 iterations), we demonstrate significant token reduction (29.8%, t(10)=6.36, p < 0.001, Cohen's d = 2.01) with corresponding cost savings. UCL's structural overhead function O_s(A) explains version-specific performance differences through the Over-Specification Paradox: beyond threshold S* = 0.509, additional specification degrades performance quadratically. Core mechanisms -- indicator functions (I_i in {0,1}), structural overhead (O_s = gamma * sum(ln C_k)), early binding -- are validated. Notably, optimal UCL configuration varies by model architecture -- certain models (e.g., Llama 4 Scout) require version-specific adaptations (V4.1). This work establishes UCL as a calibratable framework for efficient LLM interaction, with model-family-specific optimization as a key research direction.", "AI": {"tldr": "UCL\u662f\u4e00\u4e2a\u5c06\u63d0\u793a\u5de5\u7a0b\u4ece\u542f\u53d1\u5f0f\u5b9e\u8df5\u8f6c\u5316\u4e3a\u7cfb\u7edf\u5316\u4f18\u5316\u7684\u6570\u5b66\u6846\u67b6\uff0c\u901a\u8fc7\u7cfb\u7edf\u8bc4\u4f30\u663e\u8457\u51cf\u5c11\u4e8629.8%\u7684token\u4f7f\u7528\uff0c\u5e76\u63ed\u793a\u4e86\u8fc7\u89c4\u8303\u6096\u8bba\uff1a\u8d85\u8fc7\u9608\u503cS*=0.509\u540e\uff0c\u989d\u5916\u89c4\u8303\u4f1a\u4e8c\u6b21\u964d\u4f4e\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u63d0\u793a\u5de5\u7a0b\u4e3b\u8981\u4f9d\u8d56\u542f\u53d1\u5f0f\u5b9e\u8df5\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u5316\u7684\u6570\u5b66\u6846\u67b6\u6765\u4f18\u5316LLM\u4ea4\u4e92\u6548\u7387\u3002\u7814\u7a76\u8005\u5e0c\u671b\u5efa\u7acb\u4e00\u4e2a\u53ef\u6821\u51c6\u7684\u6846\u67b6\uff0c\u5c06\u63d0\u793a\u5de5\u7a0b\u4ece\u7ecf\u9a8c\u6027\u5b9e\u8df5\u8f6c\u53d8\u4e3a\u7cfb\u7edf\u5316\u4f18\u5316\u8fc7\u7a0b\u3002", "method": "\u63d0\u51fa\u4e86\u901a\u7528\u6761\u4ef6\u903b\u8f91(UCL)\u6846\u67b6\uff0c\u5305\u542b\u6307\u793a\u51fd\u6570(I_i \u2208 {0,1})\u3001\u7ed3\u6784\u5f00\u9500\u51fd\u6570(O_s = \u03b3 * \u03a3(ln C_k))\u548c\u65e9\u671f\u7ed1\u5b9a\u7b49\u6838\u5fc3\u673a\u5236\u3002\u901a\u8fc7\u7cfb\u7edf\u8bc4\u4f30(N=305\uff0c11\u4e2a\u6a21\u578b\uff0c4\u6b21\u8fed\u4ee3)\u9a8c\u8bc1\u6846\u67b6\u6709\u6548\u6027\u3002", "result": "UCL\u663e\u8457\u51cf\u5c11\u4e8629.8%\u7684token\u4f7f\u7528(t(10)=6.36, p<0.001, Cohen's d=2.01)\uff0c\u76f8\u5e94\u964d\u4f4e\u4e86\u6210\u672c\u3002\u53d1\u73b0\u4e86\u8fc7\u89c4\u8303\u6096\u8bba\uff1a\u8d85\u8fc7\u9608\u503cS*=0.509\u540e\uff0c\u989d\u5916\u89c4\u8303\u4f1a\u4e8c\u6b21\u964d\u4f4e\u6027\u80fd\u3002\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u9700\u8981\u7279\u5b9a\u4f18\u5316\u914d\u7f6e\u3002", "conclusion": "UCL\u4e3a\u9ad8\u6548LLM\u4ea4\u4e92\u5efa\u7acb\u4e86\u4e00\u4e2a\u53ef\u6821\u51c6\u7684\u6570\u5b66\u6846\u67b6\uff0c\u6a21\u578b\u5bb6\u65cf\u7279\u5b9a\u4f18\u5316\u662f\u672a\u6765\u5173\u952e\u7814\u7a76\u65b9\u5411\u3002\u8be5\u6846\u67b6\u5c06\u63d0\u793a\u5de5\u7a0b\u4ece\u542f\u53d1\u5f0f\u5b9e\u8df5\u8f6c\u53d8\u4e3a\u7cfb\u7edf\u5316\u4f18\u5316\u8fc7\u7a0b\u3002"}}
{"id": "2601.00885", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00885", "abs": "https://arxiv.org/abs/2601.00885", "authors": ["Mandar Parab"], "title": "Counterfactual Self-Questioning for Stable Policy Optimization in Language Models", "comment": null, "summary": "Recent work on language model self-improvement shows that models can refine their own reasoning through reflection, verification, debate, or self-generated rewards. However, most existing approaches rely on external critics, learned reward models, or ensemble sampling, which increases complexity and training instability. We propose Counterfactual Self-Questioning, a framework in which a single language model generates and evaluates counterfactual critiques of its own reasoning. The method produces an initial reasoning trace, formulates targeted questions that challenge potential failure points, and generates alternative reasoning trajectories that expose incorrect assumptions or invalid steps. These counterfactual trajectories provide structured relative feedback that can be directly used for policy optimization without auxiliary models. Experiments on multiple mathematical reasoning benchmarks show that counterfactual self-questioning improves accuracy and training stability, particularly for smaller models, enabling scalable self-improvement using internally generated supervision alone.", "AI": {"tldr": "\u63d0\u51faCounterfactual Self-Questioning\u6846\u67b6\uff0c\u8ba9\u5355\u4e2a\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5e76\u8bc4\u4f30\u81ea\u8eab\u63a8\u7406\u7684\u53cd\u4e8b\u5b9e\u6279\u8bc4\uff0c\u901a\u8fc7\u81ea\u6211\u8d28\u7591\u5b9e\u73b0\u65e0\u9700\u5916\u90e8\u6a21\u578b\u7684\u81ea\u6211\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u81ea\u6211\u6539\u8fdb\u65b9\u6cd5\u4f9d\u8d56\u5916\u90e8\u6279\u8bc4\u8005\u3001\u5b66\u4e60\u5956\u52b1\u6a21\u578b\u6216\u96c6\u6210\u91c7\u6837\uff0c\u589e\u52a0\u4e86\u590d\u6742\u6027\u548c\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u6027\uff0c\u9700\u8981\u66f4\u7b80\u5355\u6709\u6548\u7684\u81ea\u6211\u76d1\u7763\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u53cd\u4e8b\u5b9e\u81ea\u6211\u8d28\u7591\u6846\u67b6\uff1a1) \u751f\u6210\u521d\u59cb\u63a8\u7406\u8f68\u8ff9\uff1b2) \u9488\u5bf9\u6f5c\u5728\u5931\u8d25\u70b9\u63d0\u51fa\u9488\u5bf9\u6027\u95ee\u9898\uff1b3) \u751f\u6210\u66b4\u9732\u9519\u8bef\u5047\u8bbe\u6216\u65e0\u6548\u6b65\u9aa4\u7684\u66ff\u4ee3\u63a8\u7406\u8f68\u8ff9\uff1b4) \u4f7f\u7528\u7ed3\u6784\u5316\u76f8\u5bf9\u53cd\u9988\u8fdb\u884c\u7b56\u7565\u4f18\u5316\u3002", "result": "\u5728\u591a\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u53cd\u4e8b\u5b9e\u81ea\u6211\u8d28\u7591\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u8f83\u5c0f\u6a21\u578b\uff0c\u4ec5\u4f7f\u7528\u5185\u90e8\u751f\u6210\u7684\u76d1\u7763\u5c31\u80fd\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u81ea\u6211\u6539\u8fdb\u3002", "conclusion": "Counterfactual Self-Questioning\u4e3a\u8bed\u8a00\u6a21\u578b\u81ea\u6211\u6539\u8fdb\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u6846\u67b6\uff0c\u65e0\u9700\u5916\u90e8\u6a21\u578b\u5373\u53ef\u5b9e\u73b0\u7a33\u5b9a\u8bad\u7ec3\u548c\u6027\u80fd\u63d0\u5347\uff0c\u7279\u522b\u9002\u5408\u8d44\u6e90\u53d7\u9650\u7684\u5c0f\u6a21\u578b\u3002"}}
{"id": "2601.01954", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.01954", "abs": "https://arxiv.org/abs/2601.01954", "authors": ["Alexander Korn", "Lea Zaruchas", "Chetan Arora", "Andreas Metzger", "Sven Smolka", "Fanyu Wang", "Andreas Vogelsang"], "title": "Reporting LLM Prompting in Automated Software Engineering: A Guideline Based on Current Practices and Expectations", "comment": "To be published at The 3rd ACM International Conference on AI Foundation Models and Software Engineering FORGE 2026", "summary": "Large Language Models, particularly decoder-only generative models such as GPT, are increasingly used to automate Software Engineering tasks. These models are primarily guided through natural language prompts, making prompt engineering a critical factor in system performance and behavior. Despite their growing role in SE research, prompt-related decisions are rarely documented in a systematic or transparent manner, hindering reproducibility and comparability across studies. To address this gap, we conducted a two-phase empirical study. First, we analyzed nearly 300 papers published at the top-3 SE conferences since 2022 to assess how prompt design, testing, and optimization are currently reported. Second, we surveyed 105 program committee members from these conferences to capture their expectations for prompt reporting in LLM-driven research. Based on the findings, we derived a structured guideline that distinguishes essential, desirable, and exceptional reporting elements. Our results reveal significant misalignment between current practices and reviewer expectations, particularly regarding version disclosure, prompt justification, and threats to validity. We present our guideline as a step toward improving transparency, reproducibility, and methodological rigor in LLM-based SE research.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86SE\u9886\u57dfLLM\u7814\u7a76\u4e2d\u63d0\u793a\u5de5\u7a0b\u62a5\u544a\u7684\u73b0\u72b6\uff0c\u53d1\u73b0\u5f53\u524d\u5b9e\u8df5\u4e0e\u5ba1\u7a3f\u4eba\u671f\u671b\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u63d0\u51fa\u4e86\u7ed3\u6784\u5316\u62a5\u544a\u6307\u5357\u4ee5\u63d0\u5347\u900f\u660e\u5ea6\u4e0e\u53ef\u590d\u73b0\u6027\u3002", "motivation": "LLM\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u589e\u591a\uff0c\u4f46\u63d0\u793a\u76f8\u5173\u7684\u51b3\u7b56\u7f3a\u4e4f\u7cfb\u7edf\u900f\u660e\u7684\u6587\u6863\u8bb0\u5f55\uff0c\u8fd9\u963b\u788d\u4e86\u7814\u7a76\u7684\u53ef\u590d\u73b0\u6027\u548c\u53ef\u6bd4\u6027\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u5b9e\u8bc1\u7814\u7a76\uff1a1) \u5206\u67902022\u5e74\u4ee5\u6765\u9876\u7ea7SE\u4f1a\u8bae\u8fd1300\u7bc7\u8bba\u6587\u7684\u63d0\u793a\u8bbe\u8ba1\u3001\u6d4b\u8bd5\u548c\u4f18\u5316\u62a5\u544a\u73b0\u72b6\uff1b2) \u8c03\u67e5105\u540d\u7a0b\u5e8f\u59d4\u5458\u4f1a\u6210\u5458\u5bf9LLM\u7814\u7a76\u4e2d\u63d0\u793a\u62a5\u544a\u7684\u671f\u671b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5f53\u524d\u5b9e\u8df5\u4e0e\u5ba1\u7a3f\u4eba\u671f\u671b\u5b58\u5728\u663e\u8457\u4e0d\u4e00\u81f4\uff0c\u7279\u522b\u662f\u5728\u7248\u672c\u62ab\u9732\u3001\u63d0\u793a\u7406\u7531\u548c\u6709\u6548\u6027\u5a01\u80c1\u65b9\u9762\u3002\u57fa\u4e8e\u6b64\u63d0\u51fa\u4e86\u533a\u5206\u5fc5\u8981\u3001\u671f\u671b\u548c\u4f18\u79c0\u62a5\u544a\u8981\u7d20\u7684\u7ed3\u6784\u5316\u6307\u5357\u3002", "conclusion": "\u8be5\u6307\u5357\u65e8\u5728\u63d0\u9ad8LLM\u9a71\u52a8\u7684SE\u7814\u7a76\u7684\u900f\u660e\u5ea6\u3001\u53ef\u590d\u73b0\u6027\u548c\u65b9\u6cd5\u4e25\u8c28\u6027\uff0c\u662f\u6539\u5584\u8be5\u9886\u57df\u7814\u7a76\u5b9e\u8df5\u7684\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2601.01184", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.01184", "abs": "https://arxiv.org/abs/2601.01184", "authors": ["Suryansh Singh Sijwali", "Suman Saha"], "title": "SecureCodeRL: Security-Aware Reinforcement Learning for Code Generation with Partial-Credit Rewards", "comment": null, "summary": "Large Language Models (LLMs) can generate plausible code, but in settings that require exact stdin/stdout behavior they frequently produce programs that compile yet fail tests, and in some cases they introduce security-sensitive patterns. This paper presents SecureCodeRL, a reinforcement learning (RL) pipeline for security-aware code generation that optimizes a combined reward R = \u03b1Rfunc + \\b{eta}Rsec. The key idea is a partial-credit functional reward that assigns intermediate scores for syntactic validity, successful execution, and producing output, reducing reward sparsity that otherwise stalls learning on competitive programming style tasks. I evaluate supervised fine-tuning (SFT) and PPO variants on a small held-out prompt set from APPS+ and observe that PPO with partial credit (using a continued-training variant) improves syntax validity from 45% (SFT) to 60% and achieves the only non-zero test success signal in this pilot evaluation (5% at-least-one-test-pass), while remaining 100% clean under Bandit static analysis. Although Bandit findings were absent in this small evaluation, the security term is integrated into training to discourage insecure shortcuts when they appear.", "AI": {"tldr": "SecureCodeRL\uff1a\u4e00\u4e2a\u7ed3\u5408\u529f\u80fd\u6027\u548c\u5b89\u5168\u6027\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u66f4\u5b89\u5168\u3001\u66f4\u53ef\u9760\u7684\u4ee3\u7801\uff0c\u901a\u8fc7\u90e8\u5206\u4fe1\u7528\u5956\u52b1\u673a\u5236\u89e3\u51b3\u5956\u52b1\u7a00\u758f\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u4ee3\u7801\u867d\u7136\u8bed\u6cd5\u6b63\u786e\uff0c\u4f46\u5728\u9700\u8981\u7cbe\u786e\u8f93\u5165\u8f93\u51fa\u884c\u4e3a\u7684\u573a\u666f\u4e2d\u7ecf\u5e38\u65e0\u6cd5\u901a\u8fc7\u6d4b\u8bd5\uff0c\u6709\u65f6\u8fd8\u4f1a\u5f15\u5165\u5b89\u5168\u654f\u611f\u6a21\u5f0f\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u540c\u65f6\u4f18\u5316\u529f\u80fd\u6b63\u786e\u6027\u548c\u5b89\u5168\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faSecureCodeRL\u5f3a\u5316\u5b66\u4e60\u7ba1\u9053\uff0c\u4f7f\u7528\u7ec4\u5408\u5956\u52b1R = \u03b1Rfunc + \u03b2Rsec\uff0c\u5176\u4e2dRfunc\u91c7\u7528\u90e8\u5206\u4fe1\u7528\u529f\u80fd\u5956\u52b1\uff0c\u4e3a\u8bed\u6cd5\u6709\u6548\u6027\u3001\u6210\u529f\u6267\u884c\u548c\u4ea7\u751f\u8f93\u51fa\u5206\u914d\u4e2d\u95f4\u5206\u6570\uff0c\u51cf\u5c11\u5956\u52b1\u7a00\u758f\u6027\u3002", "result": "\u5728APPS+\u7684\u5c0f\u89c4\u6a21\u6d4b\u8bd5\u96c6\u4e0a\uff0cPPO+\u90e8\u5206\u4fe1\u7528\u65b9\u6cd5\u5c06\u8bed\u6cd5\u6709\u6548\u6027\u4ece45%\uff08SFT\uff09\u63d0\u5347\u523060%\uff0c\u5b9e\u73b0\u4e86\u552f\u4e00\u7684\u975e\u96f6\u6d4b\u8bd5\u6210\u529f\u7387\uff085%\u81f3\u5c11\u901a\u8fc7\u4e00\u4e2a\u6d4b\u8bd5\uff09\uff0c\u540c\u65f6\u5728Bandit\u9759\u6001\u5206\u6790\u4e2d\u4fdd\u6301100%\u6e05\u6d01\u3002", "conclusion": "SecureCodeRL\u901a\u8fc7\u7ed3\u5408\u529f\u80fd\u6027\u548c\u5b89\u5168\u6027\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u9ad8\u4e86\u4ee3\u7801\u751f\u6210\u7684\u8d28\u91cf\u548c\u5b89\u5168\u6027\uff0c\u4e3a\u89e3\u51b3\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u5956\u52b1\u7a00\u758f\u95ee\u9898\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2601.00923", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00923", "abs": "https://arxiv.org/abs/2601.00923", "authors": ["Josef Ott"], "title": "Context Collapse: In-Context Learning and Model Collapse", "comment": "Master's thesis", "summary": "This thesis investigates two key phenomena in large language models (LLMs): in-context learning (ICL) and model collapse. We study ICL in a linear transformer with tied weights trained on linear regression tasks, and show that minimising the in-context loss leads to a phase transition in the learned parameters. Above a critical context length, the solution develops a skew-symmetric component. We prove this by reducing the forward pass of the linear transformer under weight tying to preconditioned gradient descent, and then analysing the optimal preconditioner. This preconditioner includes a skew-symmetric component, which induces a rotation of the gradient direction. For model collapse, we use martingale and random walk theory to analyse simplified settings - linear regression and Gaussian fitting - under both replacing and cumulative data regimes. We strengthen existing results by proving almost sure convergence, showing that collapse occurs unless the data grows sufficiently fast or is retained over time. Finally, we introduce the notion of context collapse: a degradation of context during long generations, especially in chain-of-thought reasoning. This concept links the dynamics of ICL with long-term stability challenges in generative models.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86LLM\u4e2d\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u548c\u6a21\u578b\u5d29\u6e83\u73b0\u8c61\uff0c\u901a\u8fc7\u7ebf\u6027\u53d8\u6362\u5668\u5206\u6790ICL\u7684\u76f8\u53d8\u7279\u6027\uff0c\u4f7f\u7528\u9785\u7406\u8bba\u5206\u6790\u6a21\u578b\u5d29\u6e83\uff0c\u5e76\u63d0\u51fa\u4e86\"\u4e0a\u4e0b\u6587\u5d29\u6e83\"\u7684\u65b0\u6982\u5ff5\u3002", "motivation": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u4e24\u4e2a\u5173\u952e\u73b0\u8c61\uff1a\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u548c\u6a21\u578b\u5d29\u6e83\uff0c\u65e8\u5728\u7406\u89e3ICL\u7684\u6570\u5b66\u673a\u5236\u3001\u6a21\u578b\u5d29\u6e83\u7684\u52a8\u529b\u5b66\u8fc7\u7a0b\uff0c\u4ee5\u53ca\u4e24\u8005\u4e4b\u95f4\u7684\u8054\u7cfb\u3002", "method": "1. \u4f7f\u7528\u5e26\u6743\u91cd\u7ed1\u5b9a\u7684\u7ebf\u6027\u53d8\u6362\u5668\u5728\u56de\u5f52\u4efb\u52a1\u4e0a\u7814\u7a76ICL\uff0c\u8bc1\u660e\u6700\u5c0f\u5316\u4e0a\u4e0b\u6587\u635f\u5931\u4f1a\u5bfc\u81f4\u53c2\u6570\u76f8\u53d8\uff1b2. \u5c06\u7ebf\u6027\u53d8\u6362\u5668\u7684\u524d\u5411\u4f20\u64ad\u7b80\u5316\u4e3a\u9884\u6761\u4ef6\u68af\u5ea6\u4e0b\u964d\uff1b3. \u4f7f\u7528\u9785\u548c\u968f\u673a\u6e38\u8d70\u7406\u8bba\u5206\u6790\u7ebf\u6027\u56de\u5f52\u548c\u9ad8\u65af\u62df\u5408\u4e2d\u7684\u6a21\u578b\u5d29\u6e83\uff1b4. \u63d0\u51fa\"\u4e0a\u4e0b\u6587\u5d29\u6e83\"\u6982\u5ff5\uff0c\u8fde\u63a5ICL\u52a8\u529b\u5b66\u4e0e\u751f\u6210\u6a21\u578b\u7684\u957f\u671f\u7a33\u5b9a\u6027\u95ee\u9898\u3002", "result": "1. ICL\u5728\u4e34\u754c\u4e0a\u4e0b\u6587\u957f\u5ea6\u4ee5\u4e0a\u4f1a\u51fa\u73b0\u76f8\u53d8\uff0c\u89e3\u4ea7\u751f\u659c\u5bf9\u79f0\u5206\u91cf\uff1b2. \u9884\u6761\u4ef6\u5668\u5305\u542b\u659c\u5bf9\u79f0\u5206\u91cf\uff0c\u8bf1\u5bfc\u68af\u5ea6\u65b9\u5411\u65cb\u8f6c\uff1b3. \u6a21\u578b\u5d29\u6e83\u51e0\u4e4e\u5fc5\u7136\u53d1\u751f\uff0c\u9664\u975e\u6570\u636e\u589e\u957f\u8db3\u591f\u5feb\u6216\u968f\u65f6\u95f4\u4fdd\u7559\uff1b4. \u63d0\u51fa\u4e86\u4e0a\u4e0b\u6587\u5d29\u6e83\u4f5c\u4e3aICL\u52a8\u529b\u5b66\u4e0e\u957f\u671f\u751f\u6210\u7a33\u5b9a\u6027\u4e4b\u95f4\u7684\u6865\u6881\u6982\u5ff5\u3002", "conclusion": "\u8bba\u6587\u63ed\u793a\u4e86ICL\u7684\u76f8\u53d8\u7279\u6027\u3001\u6a21\u578b\u5d29\u6e83\u7684\u6570\u5b66\u673a\u5236\uff0c\u5e76\u63d0\u51fa\u4e86\u4e0a\u4e0b\u6587\u5d29\u6e83\u8fd9\u4e00\u65b0\u6982\u5ff5\uff0c\u4e3a\u7406\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5185\u90e8\u52a8\u529b\u5b66\u548c\u957f\u671f\u7a33\u5b9a\u6027\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2601.02066", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.02066", "abs": "https://arxiv.org/abs/2601.02066", "authors": ["Al Muttakin", "Saikat Mondal", "Chanchal Roy"], "title": "The State of Open Science in Software Engineering Research: A Case Study of ICSE Artifacts", "comment": "To appear in Proc. IEEE/ACM 48th International Conference on Software Engineering (ICSE 2026), Rio de Janeiro, Brazil, 12-18 Apr 2026", "summary": "Replication packages are crucial for enabling transparency, validation, and reuse in software engineering (SE) research. While artifact sharing is now a standard practice and even expected at premier SE venues such as ICSE, the practical usability of these replication packages remains underexplored. In particular, there is a marked lack of studies that comprehensively examine the executability and reproducibility of replication packages in SE research. In this paper, we aim to fill this gap by evaluating 100 replication packages published as part of ICSE proceedings over the past decade (2015--2024). We assess the (1) executability of the replication packages, (2) efforts and modifications required to execute them, (3) challenges that prevent executability, and (4) reproducibility of the original findings. We spent approximately 650 person-hours in total executing the artifacts and reproducing the study findings. Our findings reveal that only 40\\% of the 100 evaluated artifacts were executable, of which 32.5\\% (13 out of 40) ran without any modification. Regarding effort levels, 17.5\\% (7 out of 40) required low effort, while 82.5\\% (33 out of 40) required moderate to high effort to execute successfully. We identified five common types of modifications and 13 challenges leading to execution failure, spanning environmental, documentation, and structural issues. Among the executable artifacts, only 35\\% (14 out of 40) reproduced the original results. These findings highlight a notable gap between artifact availability, executability, and reproducibility. Our study proposes three actionable guidelines to improve the preparation, documentation, and review of research artifacts, thereby strengthening the rigor and sustainability of open science practices in SE research.", "AI": {"tldr": "\u8bc4\u4f30ICSE\u4f1a\u8bae\u8fc7\u53bb\u5341\u5e74100\u4e2a\u590d\u5236\u5305\u7684\u53ef\u7528\u6027\uff0c\u53d1\u73b0\u4ec540%\u53ef\u6267\u884c\uff0c\u5176\u4e2d\u4ec532.5%\u65e0\u9700\u4fee\u6539\uff0c\u4ec535%\u80fd\u590d\u73b0\u539f\u59cb\u7ed3\u679c\uff0c\u63ed\u793a\u4e86\u53ef\u7528\u6027\u4e0e\u53ef\u590d\u73b0\u6027\u4e4b\u95f4\u7684\u663e\u8457\u5dee\u8ddd\u3002", "motivation": "\u5c3d\u7ba1\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u4e2d\u590d\u5236\u5305\u5171\u4eab\u5df2\u6210\u4e3a\u6807\u51c6\u5b9e\u8df5\uff0c\u4f46\u5176\u5b9e\u9645\u53ef\u7528\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u7279\u522b\u662f\u7f3a\u4e4f\u5bf9SE\u7814\u7a76\u4e2d\u590d\u5236\u5305\u53ef\u6267\u884c\u6027\u548c\u53ef\u590d\u73b0\u6027\u7684\u5168\u9762\u7814\u7a76\uff0c\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u8bc4\u4f30\u8fc7\u53bb\u5341\u5e74\uff082015-2024\uff09ICSE\u4f1a\u8bae\u53d1\u8868\u7684100\u4e2a\u590d\u5236\u5305\uff0c\u4ece\u56db\u4e2a\u65b9\u9762\u8fdb\u884c\u8bc4\u4f30\uff1a1\uff09\u53ef\u6267\u884c\u6027\uff1b2\uff09\u6267\u884c\u6240\u9700\u7684\u5de5\u4f5c\u91cf\u548c\u4fee\u6539\uff1b3\uff09\u5bfc\u81f4\u6267\u884c\u5931\u8d25\u7684\u6311\u6218\uff1b4\uff09\u539f\u59cb\u7ed3\u679c\u7684\u53ef\u590d\u73b0\u6027\u3002\u603b\u5171\u82b1\u8d39\u7ea6650\u4eba\u65f6\u6267\u884c\u8fd9\u4e9b\u6784\u4ef6\u5e76\u590d\u73b0\u7814\u7a76\u7ed3\u679c\u3002", "result": "\u4ec540%\u7684\u6784\u4ef6\u53ef\u6267\u884c\uff0c\u5176\u4e2d32.5%\uff0813/40\uff09\u65e0\u9700\u4fee\u6539\u5373\u53ef\u8fd0\u884c\u300217.5%\uff087/40\uff09\u9700\u8981\u4f4e\u5de5\u4f5c\u91cf\uff0c82.5%\uff0833/40\uff09\u9700\u8981\u4e2d\u5230\u9ad8\u5de5\u4f5c\u91cf\u3002\u8bc6\u522b\u51fa5\u79cd\u5e38\u89c1\u4fee\u6539\u7c7b\u578b\u548c13\u79cd\u5bfc\u81f4\u6267\u884c\u5931\u8d25\u7684\u6311\u6218\u3002\u5728\u53ef\u6267\u884c\u6784\u4ef6\u4e2d\uff0c\u4ec535%\uff0814/40\uff09\u80fd\u590d\u73b0\u539f\u59cb\u7ed3\u679c\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\u6784\u4ef6\u53ef\u7528\u6027\u3001\u53ef\u6267\u884c\u6027\u548c\u53ef\u590d\u73b0\u6027\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002\u63d0\u51fa\u4e86\u4e09\u9879\u53ef\u64cd\u4f5c\u7684\u6307\u5357\uff0c\u4ee5\u6539\u8fdb\u7814\u7a76\u6784\u4ef6\u7684\u51c6\u5907\u3001\u6587\u6863\u548c\u5ba1\u67e5\uff0c\u4ece\u800c\u52a0\u5f3aSE\u7814\u7a76\u4e2d\u5f00\u653e\u79d1\u5b66\u5b9e\u8df5\u7684\u4e25\u8c28\u6027\u548c\u53ef\u6301\u7eed\u6027\u3002"}}
{"id": "2601.01214", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.01214", "abs": "https://arxiv.org/abs/2601.01214", "authors": ["Di Lu", "Mengna Sun", "Qingwen Zhang", "Yujia Liu", "Jia Zhang", "Xuewen Dong", "Yulong Shen", "Jianfeng Ma"], "title": "Arca: A Lightweight Confidential Container Architecture for Cloud-Native Environments", "comment": null, "summary": "Confidential containers protect cloud-native workloads using trusted execution environments (TEEs). However, existing Container-in-TEE designs (e.g., Confidential Containers (CoCo)) encapsulate the entire runtime within the TEE, inflating the trusted computing base (TCB) and introducing redundant components and cross-layer overhead. We present Arca, a lightweight confidential container framework based on a TEE-in-Container architecture that isolates each workload in an independent, hardware-enforced trust domain while keeping orchestration logic outside the TEE. This design minimizes inter-layer dependencies, confines compromise to per-container boundaries, and restores the TEE's minimal trust principle. We implemented Arca on Intel SGX, Intel TDX, and AMD SEV. Experimental results show that Arca achieves near-native performance and outperforms CoCo in most benchmarks, while the reduced TCB significantly improves verifiability and resilience against host-level compromise. Arca emonstrates that efficient container management and strong runtime confidentiality can be achieved without sacrificing security assurance.", "AI": {"tldr": "Arca\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u673a\u5bc6\u5bb9\u5668\u6846\u67b6\uff0c\u91c7\u7528TEE-in-Container\u67b6\u6784\uff0c\u5c06\u6bcf\u4e2a\u5de5\u4f5c\u8d1f\u8f7d\u9694\u79bb\u5728\u72ec\u7acb\u7684\u786c\u4ef6\u5f3a\u5236\u4fe1\u4efb\u57df\u4e2d\uff0c\u540c\u65f6\u5c06\u7f16\u6392\u903b\u8f91\u4fdd\u7559\u5728TEE\u4e4b\u5916\uff0c\u663e\u8457\u51cf\u5c0f\u53ef\u4fe1\u8ba1\u7b97\u57fa\u5e76\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u673a\u5bc6\u5bb9\u5668\u8bbe\u8ba1\uff08\u5982CoCo\uff09\u5c06\u6574\u4e2a\u8fd0\u884c\u65f6\u5c01\u88c5\u5728TEE\u5185\uff0c\u5bfc\u81f4\u53ef\u4fe1\u8ba1\u7b97\u57fa\u81a8\u80c0\u3001\u5f15\u5165\u5197\u4f59\u7ec4\u4ef6\u548c\u8de8\u5c42\u5f00\u9500\uff0c\u8fdd\u80cc\u4e86TEE\u7684\u6700\u5c0f\u4fe1\u4efb\u539f\u5219\u3002", "method": "\u91c7\u7528TEE-in-Container\u67b6\u6784\uff0c\u5c06\u6bcf\u4e2a\u5de5\u4f5c\u8d1f\u8f7d\u9694\u79bb\u5728\u72ec\u7acb\u7684\u786c\u4ef6\u5f3a\u5236\u4fe1\u4efb\u57df\u4e2d\uff0c\u4fdd\u6301\u7f16\u6392\u903b\u8f91\u5728TEE\u4e4b\u5916\uff0c\u6700\u5c0f\u5316\u5c42\u95f4\u4f9d\u8d56\uff0c\u5c06\u5b89\u5168\u8fb9\u754c\u9650\u5236\u5728\u6bcf\u4e2a\u5bb9\u5668\u7ea7\u522b\u3002", "result": "\u5728Intel SGX\u3001Intel TDX\u548cAMD SEV\u4e0a\u5b9e\u73b0Arca\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5176\u8fbe\u5230\u63a5\u8fd1\u539f\u751f\u6027\u80fd\uff0c\u5728\u5927\u591a\u6570\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8eCoCo\uff0c\u663e\u8457\u51cf\u5c11\u7684\u53ef\u4fe1\u8ba1\u7b97\u57fa\u63d0\u9ad8\u4e86\u53ef\u9a8c\u8bc1\u6027\u548c\u5bf9\u4e3b\u673a\u7ea7\u653b\u51fb\u7684\u62b5\u5fa1\u80fd\u529b\u3002", "conclusion": "Arca\u8bc1\u660e\u4e86\u65e0\u9700\u727a\u7272\u5b89\u5168\u4fdd\u969c\u5373\u53ef\u5b9e\u73b0\u9ad8\u6548\u7684\u5bb9\u5668\u7ba1\u7406\u548c\u5f3a\u5927\u7684\u8fd0\u884c\u65f6\u673a\u5bc6\u6027\uff0c\u6062\u590d\u4e86TEE\u7684\u6700\u5c0f\u4fe1\u4efb\u539f\u5219\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6027\u80fd\u3002"}}
{"id": "2601.00994", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.00994", "abs": "https://arxiv.org/abs/2601.00994", "authors": ["Michael Bao"], "title": "ElecTwit: A Framework for Studying Persuasion in Multi-Agent Social Systems", "comment": "In proceedings of 2025 IEEE International Conference on Agentic AI (ICA)", "summary": "This paper introduces ElecTwit, a simulation framework designed to study persuasion within multi-agent systems, specifically emulating the interactions on social media platforms during a political election. By grounding our experiments in a realistic environment, we aimed to overcome the limitations of game-based simulations often used in prior research. We observed the comprehensive use of 25 specific persuasion techniques across most tested LLMs, encompassing a wider range than previously reported. The variations in technique usage and overall persuasion output between models highlight how different model architectures and training can impact the dynamics in realistic social simulations. Additionally, we observed unique phenomena such as \"kernel of truth\" messages and spontaneous developments with an \"ink\" obsession, where agents collectively demanded written proof. Our study provides a foundation for evaluating persuasive LLM agents in real-world contexts, ensuring alignment and preventing dangerous outcomes.", "AI": {"tldr": "ElecTwit\u662f\u4e00\u4e2a\u6a21\u62df\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u8bf4\u670d\u884c\u4e3a\u7684\u6846\u67b6\uff0c\u4e13\u95e8\u6a21\u62df\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\u5728\u653f\u6cbb\u9009\u4e3e\u671f\u95f4\u7684\u4e92\u52a8\uff0c\u65e8\u5728\u514b\u670d\u4ee5\u5f80\u57fa\u4e8e\u6e38\u620f\u6a21\u62df\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u521b\u5efa\u4e00\u4e2a\u66f4\u771f\u5b9e\u7684\u73af\u5883\u6765\u7814\u7a76\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u8bf4\u670d\u884c\u4e3a\uff0c\u7279\u522b\u662f\u6a21\u62df\u793e\u4ea4\u5a92\u4f53\u5728\u653f\u6cbb\u9009\u4e3e\u671f\u95f4\u7684\u4e92\u52a8\uff0c\u4ee5\u514b\u670d\u4ee5\u5f80\u7814\u7a76\u4e2d\u57fa\u4e8e\u6e38\u620f\u6a21\u62df\u7684\u5c40\u9650\u6027\u3002", "method": "\u5f00\u53d1\u4e86ElecTwit\u6a21\u62df\u6846\u67b6\uff0c\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u8fdb\u884c\u5b9e\u9a8c\uff0c\u6d4b\u8bd5\u591a\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u89c2\u5bdf\u5b83\u4eec\u4f7f\u752825\u79cd\u7279\u5b9a\u8bf4\u670d\u6280\u672f\u7684\u60c5\u51b5\u3002", "result": "\u89c2\u5bdf\u5230\u5927\u591a\u6570\u6d4b\u8bd5\u7684LLM\u5168\u9762\u4f7f\u7528\u4e8625\u79cd\u8bf4\u670d\u6280\u672f\uff0c\u8303\u56f4\u6bd4\u4e4b\u524d\u62a5\u9053\u7684\u66f4\u5e7f\uff1b\u4e0d\u540c\u6a21\u578b\u5728\u6280\u672f\u4f7f\u7528\u548c\u6574\u4f53\u8bf4\u670d\u8f93\u51fa\u4e0a\u5b58\u5728\u5dee\u5f02\uff0c\u53cd\u6620\u4e86\u6a21\u578b\u67b6\u6784\u548c\u8bad\u7ec3\u5bf9\u73b0\u5b9e\u793e\u4ea4\u6a21\u62df\u52a8\u6001\u7684\u5f71\u54cd\uff1b\u8fd8\u89c2\u5bdf\u5230\u72ec\u7279\u73b0\u8c61\u5982\"\u771f\u76f8\u5185\u6838\"\u4fe1\u606f\u548c\"\u58a8\u6c34\"\u75f4\u8ff7\u7684\u81ea\u53d1\u53d1\u5c55\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5728\u771f\u5b9e\u4e16\u754c\u73af\u5883\u4e2d\u8bc4\u4f30\u6709\u8bf4\u670d\u529b\u7684LLM\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u786e\u4fdd\u5bf9\u9f50\u5e76\u9632\u6b62\u5371\u9669\u7ed3\u679c\u3002"}}
{"id": "2601.01195", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01195", "abs": "https://arxiv.org/abs/2601.01195", "authors": ["Wuzhenghong Wen", "Chao Xue", "Su Pan", "Yuwei Sun", "Minlong Peng"], "title": "Reinforcement Learning Enhanced Multi-hop Reasoning for Temporal Knowledge Question Answering", "comment": "11 pages, 2 figures", "summary": "Temporal knowledge graph question answering (TKGQA) involves multi-hop reasoning over temporally constrained entity relationships in the knowledge graph to answer a given question. However, at each hop, large language models (LLMs) retrieve subgraphs with numerous temporally similar and semantically complex relations, increasing the risk of suboptimal decisions and error propagation. To address these challenges, we propose the multi-hop reasoning enhanced (MRE) framework, which enhances both forward and backward reasoning to improve the identification of globally optimal reasoning trajectories. Specifically, MRE begins with prompt engineering to guide the LLM in generating diverse reasoning trajectories for a given question. Valid reasoning trajectories are then selected for supervised fine-tuning, serving as a cold-start strategy. Finally, we introduce Tree-Group Relative Policy Optimization (T-GRPO), a recursive, tree-structured learning-by-exploration approach. At each hop, exploration establishes strong causal dependencies on the previous hop, while evaluation is informed by multi-path exploration feedback from subsequent hops. Experimental results on two TKGQA benchmarks indicate that the proposed MRE-based model consistently surpasses state-of-the-art (SOTA) approaches in handling complex multi-hop queries. Further analysis highlights improved interpretability and robustness to noisy temporal annotations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u591a\u8df3\u63a8\u7406\u589e\u5f3a\u6846\u67b6MRE\uff0c\u901a\u8fc7\u524d\u5411\u548c\u540e\u5411\u63a8\u7406\u589e\u5f3a\u6765\u6539\u8fdb\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u95ee\u7b54\u4e2d\u7684\u63a8\u7406\u8f68\u8ff9\u4f18\u5316\uff0c\u4f7f\u7528Tree-Group Relative Policy Optimization\u65b9\u6cd5\u63d0\u5347\u590d\u6742\u591a\u8df3\u67e5\u8be2\u7684\u6027\u80fd\u3002", "motivation": "\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u95ee\u7b54\u4e2d\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6bcf\u4e2a\u63a8\u7406\u6b65\u9aa4\u4e2d\u4f1a\u68c0\u7d22\u5305\u542b\u5927\u91cf\u65f6\u95f4\u76f8\u4f3c\u548c\u8bed\u4e49\u590d\u6742\u5173\u7cfb\u7684\u5b50\u56fe\uff0c\u8fd9\u589e\u52a0\u4e86\u6b21\u4f18\u51b3\u7b56\u548c\u9519\u8bef\u4f20\u64ad\u7684\u98ce\u9669\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u591a\u8df3\u67e5\u8be2\u65f6\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u591a\u8df3\u63a8\u7406\u589e\u5f3a\u6846\u67b6MRE\uff1a1\uff09\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u5f15\u5bfcLLM\u751f\u6210\u591a\u6837\u5316\u7684\u63a8\u7406\u8f68\u8ff9\uff1b2\uff09\u9009\u62e9\u6709\u6548\u8f68\u8ff9\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\u4f5c\u4e3a\u51b7\u542f\u52a8\u7b56\u7565\uff1b3\uff09\u5f15\u5165Tree-Group Relative Policy Optimization\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u9012\u5f52\u7684\u6811\u7ed3\u6784\u63a2\u7d22\u5b66\u4e60\u6cd5\uff0c\u5728\u6bcf\u4e2a\u8df3\u6b65\u5efa\u7acb\u5f3a\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u901a\u8fc7\u540e\u7eed\u8df3\u6b65\u7684\u591a\u8def\u5f84\u63a2\u7d22\u53cd\u9988\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5728\u4e24\u4e2aTKGQA\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8eMRE\u7684\u6a21\u578b\u5728\u590d\u6742\u591a\u8df3\u67e5\u8be2\u5904\u7406\u65b9\u9762\u6301\u7eed\u8d85\u8d8a\u6700\u5148\u8fdb\u65b9\u6cd5\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u663e\u793a\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u5bf9\u566a\u58f0\u65f6\u95f4\u6807\u6ce8\u5177\u6709\u66f4\u597d\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "MRE\u6846\u67b6\u901a\u8fc7\u589e\u5f3a\u524d\u5411\u548c\u540e\u5411\u63a8\u7406\uff0c\u6709\u6548\u6539\u8fdb\u4e86\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u95ee\u7b54\u4e2d\u7684\u5168\u5c40\u6700\u4f18\u63a8\u7406\u8f68\u8ff9\u8bc6\u522b\uff0c\u5728\u5904\u7406\u590d\u6742\u591a\u8df3\u67e5\u8be2\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2601.02215", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02215", "abs": "https://arxiv.org/abs/2601.02215", "authors": ["Nenad Petrovic", "Vahid Zolfaghari", "Fengjunjie Pan", "Alois Knoll"], "title": "LLM-Empowered Functional Safety and Security by Design in Automotive Systems", "comment": null, "summary": "This paper presents LLM-empowered workflow to support Software Defined Vehicle (SDV) software development, covering the aspects of security-aware system topology design, as well as event-driven decision-making code analysis. For code analysis we adopt event chains model which provides formal foundations to systematic validation of functional safety, taking into account the semantic validity of messages exchanged between key components, including both CAN and Vehicle Signal Specification (VSS). Analysis of security aspects for topology relies on synergy with Model-Driven Engineering (MDE) approach and Object Constraint Language (OCL) rules. Both locally deployable and proprietary solution are taken into account for evaluation within Advanced Driver-Assistance Systems (ADAS)-related scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u5de5\u4f5c\u6d41\uff0c\u7528\u4e8e\u652f\u6301\u8f6f\u4ef6\u5b9a\u4e49\u8f66\u8f86\uff08SDV\uff09\u8f6f\u4ef6\u5f00\u53d1\uff0c\u6db5\u76d6\u5b89\u5168\u611f\u77e5\u7cfb\u7edf\u62d3\u6251\u8bbe\u8ba1\u548c\u4e8b\u4ef6\u9a71\u52a8\u51b3\u7b56\u4ee3\u7801\u5206\u6790\u4e24\u4e2a\u65b9\u9762\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u5b9a\u4e49\u8f66\u8f86\u7684\u53d1\u5c55\uff0c\u9700\u8981\u66f4\u7cfb\u7edf\u5316\u7684\u65b9\u6cd5\u6765\u5904\u7406SDV\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5b89\u5168\u6027\u548c\u529f\u80fd\u9a8c\u8bc1\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728ADAS\u76f8\u5173\u573a\u666f\u4e2d\u3002", "method": "\u91c7\u7528\u4e8b\u4ef6\u94fe\u6a21\u578b\u8fdb\u884c\u4ee3\u7801\u5206\u6790\uff0c\u4e3a\u529f\u80fd\u5b89\u5168\u9a8c\u8bc1\u63d0\u4f9b\u5f62\u5f0f\u5316\u57fa\u7840\uff1b\u7ed3\u5408\u6a21\u578b\u9a71\u52a8\u5de5\u7a0b\uff08MDE\uff09\u548c\u5bf9\u8c61\u7ea6\u675f\u8bed\u8a00\uff08OCL\uff09\u89c4\u5219\u8fdb\u884c\u62d3\u6251\u5b89\u5168\u5206\u6790\uff1b\u652f\u6301\u672c\u5730\u90e8\u7f72\u548c\u4e13\u6709\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u5728\u9ad8\u7ea7\u9a7e\u9a76\u8f85\u52a9\u7cfb\u7edf\uff08ADAS\uff09\u76f8\u5173\u573a\u666f\u4e2d\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u9a8c\u8bc1\u4e86\u8be5\u5de5\u4f5c\u6d41\u5728\u5b89\u5168\u611f\u77e5\u7cfb\u7edf\u62d3\u6251\u8bbe\u8ba1\u548c\u4e8b\u4ef6\u9a71\u52a8\u4ee3\u7801\u5206\u6790\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "LLM\u8d4b\u80fd\u7684\u5de5\u4f5c\u6d41\u80fd\u591f\u6709\u6548\u652f\u6301SDV\u8f6f\u4ef6\u5f00\u53d1\uff0c\u7279\u522b\u662f\u5728\u5b89\u5168\u611f\u77e5\u7cfb\u7edf\u8bbe\u8ba1\u548c\u529f\u80fd\u5b89\u5168\u9a8c\u8bc1\u65b9\u9762\uff0c\u4e3aADAS\u7b49\u5173\u952e\u7cfb\u7edf\u7684\u5f00\u53d1\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u65b9\u6cd5\u3002"}}
{"id": "2601.01287", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.01287", "abs": "https://arxiv.org/abs/2601.01287", "authors": ["Wenbo Wu", "George Konstantinidis"], "title": "Compliance as a Trust Metric", "comment": null, "summary": "Trust and Reputation Management Systems (TRMSs) are critical for the modern web, yet their reliance on subjective user ratings or narrow Quality of Service (QoS) metrics lacks objective grounding. Concurrently, while regulatory frameworks like GDPR and HIPAA provide objective behavioral standards, automated compliance auditing has been limited to coarse, binary (pass/fail) outcomes. This paper bridges this research gap by operationalizing regulatory compliance as a quantitative and dynamic trust metric through our novel automated compliance engine (ACE). ACE first formalizes legal and organizational policies into a verifiable, obligation-centric logic. It then continuously audits system event logs against this logic to detect violations. The core of our contribution is a quantitative model that assesses the severity of each violation along multiple dimensions, including its Volume, Duration, Breadth, and Criticality, to compute a fine-grained, evolving compliance score. We evaluate ACE on a synthetic hospital dataset, demonstrating its ability to accurately detect a range of complex HIPAA and GDPR violations and produce a nuanced score that is significantly more expressive than traditional binary approaches. This work enables the development of more transparent, accountable, and resilient TRMSs on the Web.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u81ea\u52a8\u5316\u5408\u89c4\u5f15\u64ce\uff08ACE\uff09\uff0c\u5c06\u6cd5\u89c4\u9075\u4ece\u6027\u8f6c\u5316\u4e3a\u91cf\u5316\u7684\u52a8\u6001\u4fe1\u4efb\u6307\u6807\uff0c\u901a\u8fc7\u591a\u7ef4\u5ea6\u8bc4\u4f30\u8fdd\u89c4\u4e25\u91cd\u6027\u6765\u751f\u6210\u7ec6\u7c92\u5ea6\u7684\u5408\u89c4\u5206\u6570\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684\u4e8c\u5143\uff08\u901a\u8fc7/\u5931\u8d25\uff09\u5ba1\u8ba1\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u4fe1\u4efb\u4e0e\u58f0\u8a89\u7ba1\u7406\u7cfb\u7edf\uff08TRMSs\uff09\u4e3b\u8981\u4f9d\u8d56\u4e3b\u89c2\u7528\u6237\u8bc4\u5206\u6216\u6709\u9650\u7684QoS\u6307\u6807\uff0c\u7f3a\u4e4f\u5ba2\u89c2\u57fa\u7840\uff1b\u540c\u65f6\uff0cGDPR\u3001HIPAA\u7b49\u6cd5\u89c4\u6846\u67b6\u867d\u7136\u63d0\u4f9b\u4e86\u5ba2\u89c2\u884c\u4e3a\u6807\u51c6\uff0c\u4f46\u81ea\u52a8\u5316\u5408\u89c4\u5ba1\u8ba1\u4ec5\u9650\u4e8e\u7c97\u7cd9\u7684\u4e8c\u5143\u7ed3\u679c\u3002\u9700\u8981\u5c06\u6cd5\u89c4\u9075\u4ece\u6027\u8f6c\u5316\u4e3a\u91cf\u5316\u7684\u52a8\u6001\u4fe1\u4efb\u6307\u6807\u3002", "method": "\u5f00\u53d1\u81ea\u52a8\u5316\u5408\u89c4\u5f15\u64ce\uff08ACE\uff09\uff1a1\uff09\u5c06\u6cd5\u5f8b\u548c\u7ec4\u7ec7\u653f\u7b56\u5f62\u5f0f\u5316\u4e3a\u53ef\u9a8c\u8bc1\u7684\u3001\u4ee5\u4e49\u52a1\u4e3a\u4e2d\u5fc3\u7684\u903b\u8f91\uff1b2\uff09\u6301\u7eed\u5ba1\u8ba1\u7cfb\u7edf\u4e8b\u4ef6\u65e5\u5fd7\u4ee5\u68c0\u6d4b\u8fdd\u89c4\uff1b3\uff09\u901a\u8fc7\u591a\u7ef4\u5ea6\uff08\u6570\u91cf\u3001\u6301\u7eed\u65f6\u95f4\u3001\u5e7f\u5ea6\u3001\u5173\u952e\u6027\uff09\u8bc4\u4f30\u8fdd\u89c4\u4e25\u91cd\u6027\uff0c\u8ba1\u7b97\u7ec6\u7c92\u5ea6\u7684\u52a8\u6001\u5408\u89c4\u5206\u6570\u3002", "result": "\u5728\u5408\u6210\u533b\u9662\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30ACE\uff0c\u8bc1\u660e\u5176\u80fd\u591f\u51c6\u786e\u68c0\u6d4b\u590d\u6742\u7684HIPAA\u548cGDPR\u8fdd\u89c4\uff0c\u5e76\u751f\u6210\u6bd4\u4f20\u7edf\u4e8c\u5143\u65b9\u6cd5\u66f4\u5177\u8868\u8fbe\u529b\u7684\u7ec6\u81f4\u5408\u89c4\u5206\u6570\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u80fd\u591f\u5f00\u53d1\u66f4\u900f\u660e\u3001\u53ef\u95ee\u8d23\u548c\u6709\u5f39\u6027\u7684Web\u4fe1\u4efb\u4e0e\u58f0\u8a89\u7ba1\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u5c06\u6cd5\u89c4\u9075\u4ece\u6027\u8f6c\u5316\u4e3a\u91cf\u5316\u4fe1\u4efb\u6307\u6807\uff0c\u4e3aTRMSs\u63d0\u4f9b\u4e86\u5ba2\u89c2\u57fa\u7840\u3002"}}
{"id": "2601.02238", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.02238", "abs": "https://arxiv.org/abs/2601.02238", "authors": ["Nils Bosbach", "Alwalid Salama", "Lukas J\u00fcnger", "Mark Burton", "Niko Zurstra\u00dfen", "Rebecca Pelke", "Rainer Leupers"], "title": "NQC2: A Non-Intrusive QEMU Code Coverage Plugin", "comment": "PREPRINT - accepted by the Rapid Simulation and Performance Evaluation for Design Workshop (RAPIDO '24)", "summary": "Code coverage analysis has become a standard approach in software development, facilitating the assessment of test suite effectiveness, the identification of under-tested code segments, and the discovery of performance bottlenecks. When code coverage of software for embedded systems needs to be measured, conventional approaches quickly meet their limits. A commonly used approach involves instrumenting the source files with added code that collects and dumps coverage information during runtime. This inserted code usually relies on the existence of an operating and a file system to dump the collected data. These features are not available for bare-metal programs that are executed on embedded systems.\n  To overcome this issue, we present NQC2, a plugin for QEMU.NQC2 extracts coverage information from QEMU during runtime and stores them into a file on the host machine. This approach is even compatible with modified QEMU versions and does not require target-software instrumentation. NQC2 outperforms a comparable approach from Xilinx by up to 8.5 x.", "AI": {"tldr": "NQC2\u662f\u4e00\u4e2aQEMU\u63d2\u4ef6\uff0c\u7528\u4e8e\u5728\u5d4c\u5165\u5f0f\u7cfb\u7edf\u88f8\u673a\u7a0b\u5e8f\u4e2d\u63d0\u53d6\u4ee3\u7801\u8986\u76d6\u7387\u4fe1\u606f\uff0c\u65e0\u9700\u76ee\u6807\u8f6f\u4ef6\u63d2\u6869\uff0c\u6027\u80fd\u6bd4Xilinx\u65b9\u6848\u63d0\u53478.5\u500d", "motivation": "\u4f20\u7edf\u4ee3\u7801\u8986\u76d6\u7387\u6d4b\u91cf\u65b9\u6cd5\u5728\u5d4c\u5165\u5f0f\u7cfb\u7edf\u88f8\u673a\u7a0b\u5e8f\u4e2d\u5b58\u5728\u5c40\u9650\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u64cd\u4f5c\u7cfb\u7edf\u548c\u6587\u4ef6\u7cfb\u7edf\u6765\u5b58\u50a8\u8986\u76d6\u7387\u6570\u636e\uff0c\u800c\u88f8\u673a\u7a0b\u5e8f\u4e0d\u5177\u5907\u8fd9\u4e9b\u7279\u6027", "method": "\u5f00\u53d1NQC2\u4f5c\u4e3aQEMU\u63d2\u4ef6\uff0c\u5728\u8fd0\u884c\u65f6\u4eceQEMU\u63d0\u53d6\u8986\u76d6\u7387\u4fe1\u606f\u5e76\u5b58\u50a8\u5230\u4e3b\u673a\u6587\u4ef6\u4e2d\uff0c\u517c\u5bb9\u4fee\u6539\u7248QEMU\u4e14\u65e0\u9700\u76ee\u6807\u8f6f\u4ef6\u63d2\u6869", "result": "NQC2\u6027\u80fd\u663e\u8457\u4f18\u4e8eXilinx\u7684\u53ef\u6bd4\u65b9\u6848\uff0c\u63d0\u5347\u5e45\u5ea6\u9ad8\u8fbe8.5\u500d", "conclusion": "NQC2\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5d4c\u5165\u5f0f\u7cfb\u7edf\u88f8\u673a\u7a0b\u5e8f\u4ee3\u7801\u8986\u76d6\u7387\u6d4b\u91cf\u65b9\u6848\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u9650\u5236\uff0c\u5177\u6709\u66f4\u597d\u7684\u517c\u5bb9\u6027\u548c\u6027\u80fd"}}
{"id": "2601.01321", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01321", "abs": "https://arxiv.org/abs/2601.01321", "authors": ["Rong Zhou", "Dongping Chen", "Zihan Jia", "Yao Su", "Yixin Liu", "Yiwen Lu", "Dongwei Shi", "Yue Huang", "Tianyang Xu", "Yi Pan", "Xinliang Li", "Yohannes Abate", "Qingyu Chen", "Zhengzhong Tu", "Yu Yang", "Yu Zhang", "Qingsong Wen", "Gengchen Mai", "Sunyang Fu", "Jiachen Li", "Xuyu Wang", "Ziran Wang", "Jing Huang", "Tianming Liu", "Yong Chen", "Lichao Sun", "Lifang He"], "title": "Digital Twin AI: Opportunities and Challenges from Large Language Models to World Models", "comment": null, "summary": "Digital twins, as precise digital representations of physical systems, have evolved from passive simulation tools into intelligent and autonomous entities through the integration of artificial intelligence technologies. This paper presents a unified four-stage framework that systematically characterizes AI integration across the digital twin lifecycle, spanning modeling, mirroring, intervention, and autonomous management. By synthesizing existing technologies and practices, we distill a unified four-stage framework that systematically characterizes how AI methodologies are embedded across the digital twin lifecycle: (1) modeling the physical twin through physics-based and physics-informed AI approaches, (2) mirroring the physical system into a digital twin with real-time synchronization, (3) intervening in the physical twin through predictive modeling, anomaly detection, and optimization strategies, and (4) achieving autonomous management through large language models, foundation models, and intelligent agents. We analyze the synergy between physics-based modeling and data-driven learning, highlighting the shift from traditional numerical solvers to physics-informed and foundation models for physical systems. Furthermore, we examine how generative AI technologies, including large language models and generative world models, transform digital twins into proactive and self-improving cognitive systems capable of reasoning, communication, and creative scenario generation. Through a cross-domain review spanning eleven application domains, including healthcare, aerospace, smart manufacturing, robotics, and smart cities, we identify common challenges related to scalability, explainability, and trustworthiness, and outline directions for responsible AI-driven digital twin systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u56db\u9636\u6bb5\u6846\u67b6\uff0c\u7cfb\u7edf\u63cf\u8ff0\u4eba\u5de5\u667a\u80fd\u5728\u6570\u5b57\u5b6a\u751f\u751f\u547d\u5468\u671f\u4e2d\u7684\u96c6\u6210\uff0c\u6db5\u76d6\u5efa\u6a21\u3001\u955c\u50cf\u3001\u5e72\u9884\u548c\u81ea\u4e3b\u7ba1\u7406\u56db\u4e2a\u9636\u6bb5\uff0c\u5e76\u5206\u6790\u4e86\u7269\u7406\u5efa\u6a21\u4e0e\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u7684\u534f\u540c\u4f5c\u7528\u3002", "motivation": "\u6570\u5b57\u5b6a\u751f\u5df2\u4ece\u88ab\u52a8\u4eff\u771f\u5de5\u5177\u6f14\u53d8\u4e3a\u667a\u80fd\u81ea\u4e3b\u5b9e\u4f53\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u5316\u7684AI\u96c6\u6210\u6846\u67b6\u3002\u672c\u6587\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u7cfb\u7edf\u63cf\u8ff0AI\u65b9\u6cd5\u5728\u6570\u5b57\u5b6a\u751f\u5168\u751f\u547d\u5468\u671f\u4e2d\u7684\u5d4c\u5165\u65b9\u5f0f\u3002", "method": "\u63d0\u51fa\u56db\u9636\u6bb5\u6846\u67b6\uff1a1) \u901a\u8fc7\u7269\u7406\u57fa\u7840\u548c\u7269\u7406\u4fe1\u606fAI\u65b9\u6cd5\u5efa\u6a21\u7269\u7406\u5b6a\u751f\uff1b2) \u901a\u8fc7\u5b9e\u65f6\u540c\u6b65\u5c06\u7269\u7406\u7cfb\u7edf\u955c\u50cf\u4e3a\u6570\u5b57\u5b6a\u751f\uff1b3) \u901a\u8fc7\u9884\u6d4b\u5efa\u6a21\u3001\u5f02\u5e38\u68c0\u6d4b\u548c\u4f18\u5316\u7b56\u7565\u5e72\u9884\u7269\u7406\u5b6a\u751f\uff1b4) \u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u3001\u57fa\u7840\u6a21\u578b\u548c\u667a\u80fd\u4f53\u5b9e\u73b0\u81ea\u4e3b\u7ba1\u7406\u3002\u5206\u6790\u4e86\u7269\u7406\u5efa\u6a21\u4e0e\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u7684\u534f\u540c\uff0c\u5e76\u8de811\u4e2a\u5e94\u7528\u9886\u57df\u8fdb\u884c\u7efc\u8ff0\u3002", "result": "\u5efa\u7acb\u4e86\u7edf\u4e00\u7684AI\u96c6\u6210\u6846\u67b6\uff0c\u8bc6\u522b\u4e86\u4ece\u4f20\u7edf\u6570\u503c\u6c42\u89e3\u5668\u5411\u7269\u7406\u4fe1\u606f\u6a21\u578b\u548c\u57fa\u7840\u6a21\u578b\u7684\u8f6c\u53d8\uff0c\u5206\u6790\u4e86\u751f\u6210\u5f0fAI\u6280\u672f\u5982\u4f55\u5c06\u6570\u5b57\u5b6a\u751f\u8f6c\u53d8\u4e3a\u4e3b\u52a8\u3001\u81ea\u6539\u8fdb\u7684\u8ba4\u77e5\u7cfb\u7edf\uff0c\u5e76\u53d1\u73b0\u4e86\u53ef\u6269\u5c55\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u4fe1\u5ea6\u7b49\u5171\u540c\u6311\u6218\u3002", "conclusion": "AI\u6280\u672f\u6b63\u5728\u5c06\u6570\u5b57\u5b6a\u751f\u8f6c\u53d8\u4e3a\u667a\u80fd\u81ea\u4e3b\u7cfb\u7edf\uff0c\u56db\u9636\u6bb5\u6846\u67b6\u4e3aAI\u96c6\u6210\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u89c6\u89d2\u3002\u672a\u6765\u9700\u8981\u89e3\u51b3\u53ef\u6269\u5c55\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u4fe1\u5ea6\u7b49\u6311\u6218\uff0c\u63a8\u52a8\u8d1f\u8d23\u4efbAI\u9a71\u52a8\u7684\u6570\u5b57\u5b6a\u751f\u7cfb\u7edf\u53d1\u5c55\u3002"}}
{"id": "2601.02248", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.02248", "abs": "https://arxiv.org/abs/2601.02248", "authors": ["Mohammad Reza Heidari Iman", "Giorgio Di Natale", "Katell Morin-Allory"], "title": "Automatic Assertion Mining in Assertion-Based Verification: Techniques, Challenges, and Future Directions", "comment": "6 pages", "summary": "Functional verification increasingly relies on Assertion-Based Verification (ABV), which has become a key approach for verifying hardware designs due to its efficiency and effectiveness. Central to ABV are automatic assertion miners, which apply different techniques to generate assertions automatically. This paper reviews the most recent, advanced, and widely adopted assertion miners, offering a comparative analysis of their methodologies. The goal is to provide researchers and verification practitioners with insights into the capabilities and limitations of existing miners. By identifying their shortcomings, this work also points toward directions for developing more powerful and advanced assertion miners in the future.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u6700\u65b0\u7684\u9ad8\u7ea7\u65ad\u8a00\u6316\u6398\u5de5\u5177\uff0c\u6bd4\u8f83\u4e86\u5b83\u4eec\u7684\u65b9\u6cd5\u8bba\uff0c\u65e8\u5728\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u9a8c\u8bc1\u4ece\u4e1a\u8005\u63d0\u4f9b\u73b0\u6709\u5de5\u5177\u80fd\u529b\u548c\u5c40\u9650\u6027\u7684\u89c1\u89e3\uff0c\u5e76\u6307\u51fa\u672a\u6765\u5f00\u53d1\u66f4\u5f3a\u5927\u65ad\u8a00\u6316\u6398\u5de5\u5177\u7684\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u529f\u80fd\u9a8c\u8bc1\u65e5\u76ca\u4f9d\u8d56\u57fa\u4e8e\u65ad\u8a00\u7684\u9a8c\u8bc1\uff08ABV\uff09\uff0c\u81ea\u52a8\u65ad\u8a00\u6316\u6398\u5de5\u5177\u5df2\u6210\u4e3a\u786c\u4ef6\u8bbe\u8ba1\u9a8c\u8bc1\u7684\u5173\u952e\u65b9\u6cd5\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u7efc\u8ff0\u6700\u65b0\u7684\u9ad8\u7ea7\u65ad\u8a00\u6316\u6398\u5de5\u5177\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u9a8c\u8bc1\u4ece\u4e1a\u8005\u63d0\u4f9b\u73b0\u6709\u5de5\u5177\u80fd\u529b\u548c\u5c40\u9650\u6027\u7684\u5168\u9762\u4e86\u89e3\uff0c\u5e76\u8bc6\u522b\u5176\u4e0d\u8db3\u4e4b\u5904\u3002", "method": "\u672c\u6587\u91c7\u7528\u6587\u732e\u7efc\u8ff0\u548c\u6bd4\u8f83\u5206\u6790\u65b9\u6cd5\uff0c\u7cfb\u7edf\u56de\u987e\u4e86\u6700\u5148\u8fdb\u3001\u6700\u5e7f\u6cdb\u91c7\u7528\u7684\u65ad\u8a00\u6316\u6398\u5de5\u5177\uff0c\u5e76\u5bf9\u5b83\u4eec\u7684\u65b9\u6cd5\u8bba\u8fdb\u884c\u4e86\u6bd4\u8f83\u5206\u6790\u3002", "result": "\u901a\u8fc7\u6bd4\u8f83\u5206\u6790\uff0c\u672c\u6587\u8bc6\u522b\u4e86\u73b0\u6709\u65ad\u8a00\u6316\u6398\u5de5\u5177\u7684\u5404\u79cd\u65b9\u6cd5\u8bba\u7279\u70b9\u3001\u80fd\u529b\u548c\u5c40\u9650\u6027\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u9a8c\u8bc1\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002", "conclusion": "\u672c\u6587\u4e0d\u4ec5\u603b\u7ed3\u4e86\u73b0\u6709\u65ad\u8a00\u6316\u6398\u5de5\u5177\u7684\u73b0\u72b6\uff0c\u66f4\u91cd\u8981\u7684\u662f\u6307\u51fa\u4e86\u5b83\u4eec\u7684\u4e0d\u8db3\u4e4b\u5904\uff0c\u4e3a\u672a\u6765\u5f00\u53d1\u66f4\u5f3a\u5927\u3001\u66f4\u5148\u8fdb\u7684\u65ad\u8a00\u6316\u6398\u5de5\u5177\u6307\u660e\u4e86\u7814\u7a76\u65b9\u5411\u548c\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2601.01330", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01330", "abs": "https://arxiv.org/abs/2601.01330", "authors": ["Shengji Tang", "Weihao Lin", "Jingqi Ye", "Hao Li", "Bo Zhang", "Shuyue Hu", "Tao Chen", "Wangli Ouyang", "Lei Bai", "Peng Ye"], "title": "Beyond Gemini-3-Pro: Revisiting LLM Routing and Aggregation at Scale", "comment": "12 pages", "summary": "Large Language Models (LLMs) have rapidly advanced, with Gemini-3-Pro setting a new performance milestone. In this work, we explore collective intelligence as an alternative to monolithic scaling, and demonstrate that open-source LLMs' collaboration can surpass Gemini-3-Pro. We first revisit LLM routing and aggregation at scale and identify three key bottlenecks: (1) current train-free routers are limited by a query-based paradigm focusing solely on textual similarity; (2) recent aggregation methods remain largely static, failing to select appropriate aggregators for different tasks;(3) the complementarity of routing and aggregation remains underutilized. To address these problems, we introduce JiSi, a novel framework designed to release the full potential of LLMs' collaboration through three innovations: (1) Query-Response Mixed Routing capturing both semantic information and problem difficulty; (2) Support-Set-based Aggregator Selection jointly evaluating the aggregation and domain capacity of aggregators; (3) Adaptive Routing-Aggregation Switch dynamically leveraging the advantages of routing and aggregation. Comprehensive experiments on nine benchmarks demonstrate that JiSi can surpass Gemini-3-Pro with only 47% costs by orchestrating ten open-source LLMs, while outperforming mainstream baselines. It suggests that collective intelligence represents a novel path towards Artificial General Intelligence (AGI).", "AI": {"tldr": "JiSi\u6846\u67b6\u901a\u8fc7\u67e5\u8be2-\u54cd\u5e94\u6df7\u5408\u8def\u7531\u3001\u652f\u6301\u96c6\u805a\u5408\u5668\u9009\u62e9\u548c\u81ea\u9002\u5e94\u8def\u7531-\u805a\u5408\u5207\u6362\u4e09\u5927\u521b\u65b0\uff0c\u4f7f\u5f00\u6e90LLM\u534f\u4f5c\u8d85\u8d8aGemini-3-Pro\uff0c\u4ec5\u752847%\u6210\u672c\u5b9e\u73b0\u66f4\u597d\u6027\u80fd\uff0c\u4e3aAGI\u63d0\u4f9b\u96c6\u4f53\u667a\u80fd\u65b0\u8def\u5f84\u3002", "motivation": "\u5f53\u524dLLM\u8def\u7531\u548c\u805a\u5408\u5b58\u5728\u4e09\u4e2a\u5173\u952e\u74f6\u9888\uff1a1\uff09\u65e0\u8bad\u7ec3\u8def\u7531\u5668\u5c40\u9650\u4e8e\u57fa\u4e8e\u67e5\u8be2\u7684\u6587\u672c\u76f8\u4f3c\u6027\u8303\u5f0f\uff1b2\uff09\u805a\u5408\u65b9\u6cd5\u9759\u6001\u5316\uff0c\u65e0\u6cd5\u4e3a\u4e0d\u540c\u4efb\u52a1\u9009\u62e9\u5408\u9002\u805a\u5408\u5668\uff1b3\uff09\u8def\u7531\u548c\u805a\u5408\u7684\u4e92\u8865\u6027\u672a\u5145\u5206\u5229\u7528\u3002\u9700\u8981\u91ca\u653eLLM\u534f\u4f5c\u7684\u5b8c\u6574\u6f5c\u529b\u3002", "method": "\u63d0\u51faJiSi\u6846\u67b6\uff0c\u5305\u542b\u4e09\u5927\u521b\u65b0\uff1a1\uff09\u67e5\u8be2-\u54cd\u5e94\u6df7\u5408\u8def\u7531\uff0c\u540c\u65f6\u6355\u6349\u8bed\u4e49\u4fe1\u606f\u548c\u95ee\u9898\u96be\u5ea6\uff1b2\uff09\u57fa\u4e8e\u652f\u6301\u96c6\u7684\u805a\u5408\u5668\u9009\u62e9\uff0c\u8054\u5408\u8bc4\u4f30\u805a\u5408\u5668\u7684\u805a\u5408\u80fd\u529b\u548c\u9886\u57df\u80fd\u529b\uff1b3\uff09\u81ea\u9002\u5e94\u8def\u7531-\u805a\u5408\u5207\u6362\uff0c\u52a8\u6001\u5229\u7528\u8def\u7531\u548c\u805a\u5408\u7684\u4f18\u52bf\u3002", "result": "\u5728\u4e5d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cJiSi\u901a\u8fc7\u534f\u8c03\u5341\u4e2a\u5f00\u6e90LLM\uff0c\u4ec5\u752847%\u7684\u6210\u672c\u5c31\u8d85\u8d8a\u4e86Gemini-3-Pro\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4f18\u4e8e\u4e3b\u6d41\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u96c6\u4f53\u667a\u80fd\u4ee3\u8868\u4e86\u901a\u5f80\u4eba\u5de5\u901a\u7528\u667a\u80fd\uff08AGI\uff09\u7684\u65b0\u8def\u5f84\uff0c\u901a\u8fc7\u6709\u6548\u7684\u534f\u4f5c\u6846\u67b6\uff0c\u5f00\u6e90LLM\u7684\u96c6\u4f53\u8868\u73b0\u53ef\u4ee5\u8d85\u8d8a\u6700\u5148\u8fdb\u7684\u5355\u4f53\u6a21\u578b\u3002"}}
{"id": "2601.02345", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.02345", "abs": "https://arxiv.org/abs/2601.02345", "authors": ["Parham Khamsepour", "Mark Cole", "Ish Ashraf", "Sandeep Puri", "Mehrdad Sabetzadeh", "Shiva Nejati"], "title": "Question Answering for Multi-Release Systems: A Case Study at Ciena", "comment": "Accepted for publication in SANER 2026", "summary": "Companies regularly have to contend with multi-release systems, where several versions of the same software are in operation simultaneously. Question answering over documents from multi-release systems poses challenges because different releases have distinct yet overlapping documentation. Motivated by the observed inaccuracy of state-of-the-art question-answering techniques on multi-release system documents, we propose QAMR, a chatbot designed to answer questions across multi-release system documentation. QAMR enhances traditional retrieval-augmented generation (RAG) to ensure accuracy in the face of highly similar yet distinct documentation for different releases. It achieves this through a novel combination of pre-processing, query rewriting, and context selection. In addition, QAMR employs a dual-chunking strategy to enable separately tuned chunk sizes for retrieval and answer generation, improving overall question-answering accuracy. We evaluate QAMR using a public software-engineering benchmark as well as a collection of real-world, multi-release system documents from our industry partner, Ciena. Our evaluation yields five main findings: (1) QAMR outperforms a baseline RAG-based chatbot, achieving an average answer correctness of 88.5% and an average retrieval accuracy of 90%, which correspond to improvements of 16.5% and 12%, respectively. (2) An ablation study shows that QAMR's mechanisms for handling multi-release documents directly improve answer accuracy. (3) Compared to its component-ablated variants, QAMR achieves a 19.6% average gain in answer correctness and a 14.0% average gain in retrieval accuracy over the best ablation. (4) QAMR reduces response time by 8% on average relative to the baseline. (5) The automatically computed accuracy metrics used in our evaluation strongly correlate with expert human assessments, validating the reliability of our methodology.", "AI": {"tldr": "QAMR\u662f\u4e00\u4e2a\u9488\u5bf9\u591a\u7248\u672c\u7cfb\u7edf\u6587\u6863\u7684\u95ee\u7b54\u804a\u5929\u673a\u5668\u4eba\uff0c\u901a\u8fc7\u589e\u5f3a\u7684RAG\u67b6\u6784\u548c\u53cc\u5206\u5757\u7b56\u7565\uff0c\u5728\u51c6\u786e\u6027\u548c\u68c0\u7d22\u6027\u80fd\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u591a\u7248\u672c\u7cfb\u7edf\u4e2d\u4e0d\u540c\u7248\u672c\u7684\u8f6f\u4ef6\u6587\u6863\u9ad8\u5ea6\u76f8\u4f3c\u4f46\u53c8\u6709\u533a\u522b\uff0c\u73b0\u6709\u95ee\u7b54\u6280\u672f\u5728\u8fd9\u7c7b\u6587\u6863\u4e0a\u51c6\u786e\u6027\u4e0d\u8db3\uff0c\u9700\u8981\u4e13\u95e8\u7684\u65b9\u6cd5\u6765\u5904\u7406\u591a\u7248\u672c\u7cfb\u7edf\u6587\u6863\u7684\u95ee\u7b54\u6311\u6218\u3002", "method": "QAMR\u91c7\u7528\u589e\u5f3a\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u67b6\u6784\uff0c\u7ed3\u5408\u9884\u5904\u7406\u3001\u67e5\u8be2\u91cd\u5199\u548c\u4e0a\u4e0b\u6587\u9009\u62e9\u673a\u5236\uff0c\u5e76\u4f7f\u7528\u53cc\u5206\u5757\u7b56\u7565\u5206\u522b\u4f18\u5316\u68c0\u7d22\u548c\u7b54\u6848\u751f\u6210\u7684\u5206\u5757\u5927\u5c0f\u3002", "result": "QAMR\u5728\u516c\u5171\u8f6f\u4ef6\u5de5\u7a0b\u57fa\u51c6\u548c\u5de5\u4e1a\u5408\u4f5c\u4f19\u4f34Ciena\u7684\u771f\u5b9e\u591a\u7248\u672c\u7cfb\u7edf\u6587\u6863\u4e0a\u8bc4\u4f30\uff0c\u5e73\u5747\u7b54\u6848\u6b63\u786e\u7387\u8fbe\u523088.5%\uff0c\u5e73\u5747\u68c0\u7d22\u51c6\u786e\u738790%\uff0c\u76f8\u6bd4\u57fa\u7ebf\u5206\u522b\u63d0\u534716.5%\u548c12%\uff0c\u54cd\u5e94\u65f6\u95f4\u51cf\u5c118%\u3002", "conclusion": "QAMR\u6709\u6548\u89e3\u51b3\u4e86\u591a\u7248\u672c\u7cfb\u7edf\u6587\u6863\u95ee\u7b54\u7684\u6311\u6218\uff0c\u901a\u8fc7\u4e13\u95e8\u8bbe\u8ba1\u7684\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u6027\u548c\u6027\u80fd\uff0c\u5176\u8bc4\u4f30\u6307\u6807\u4e0e\u4e13\u5bb6\u8bc4\u4f30\u9ad8\u5ea6\u76f8\u5173\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2601.01308", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2601.01308", "abs": "https://arxiv.org/abs/2601.01308", "authors": ["Abdurrahman Tolay"], "title": "Automated SBOM-Driven Vulnerability Triage for IoT Firmware: A Lightweight Pipeline for Risk Prioritization", "comment": "Preprint. 10 pages, 1 figure, 2 tables. Planned evaluation", "summary": "The proliferation of Internet of Things (IoT) devices has introduced significant security challenges, primarily due to the opacity of firmware components and the complexity of supply chain dependencies. IoT firmware frequently relies on outdated, third-party libraries embedded within monolithic binary blobs, making vulnerability management difficult. While Software Bill of Materials (SBOM) standards have matured, generating actionable intelligence from raw firmware dumps remains a manual and error-prone process. This paper presents a lightweight, automated pipeline designed to extract file systems from Linux-based IoT firmware, generate a comprehensive SBOM, map identified components to known vulnerabilities, and apply a multi-factor triage scoring model. The proposed system focuses on risk prioritization by integrating signals from the Common Vulnerability Scoring System (CVSS), Exploit Prediction Scoring System (EPSS), and the CISA Known Exploited Vulnerabilities (KEV) catalog. Unlike conventional scanners that produce high volumes of uncontextualized alerts, this approach emphasizes triage by calculating a localized risk score for each finding. We describe the architecture, the normalization challenges of embedded Linux, and a scoring methodology intended to reduce alert fatigue. The study outlines a planned evaluation strategy to validate the extraction success rate and triage efficacy using a dataset of public vendor firmware, offering a reproducibility framework for future research in firmware security.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u81ea\u52a8\u5316\u7ba1\u9053\uff0c\u7528\u4e8e\u4eceLinux\u7269\u8054\u7f51\u56fa\u4ef6\u4e2d\u63d0\u53d6\u6587\u4ef6\u7cfb\u7edf\u3001\u751f\u6210SBOM\u3001\u6620\u5c04\u6f0f\u6d1e\uff0c\u5e76\u5e94\u7528\u591a\u56e0\u7d20\u4f18\u5148\u7ea7\u8bc4\u5206\u6a21\u578b\u6765\u964d\u4f4e\u544a\u8b66\u75b2\u52b3\u3002", "motivation": "\u7269\u8054\u7f51\u8bbe\u5907\u56fa\u4ef6\u901a\u5e38\u5305\u542b\u8fc7\u65f6\u7684\u7b2c\u4e09\u65b9\u5e93\uff0c\u4e14\u4ee5\u4e8c\u8fdb\u5236\u5f62\u5f0f\u5b58\u5728\uff0c\u4f7f\u5f97\u6f0f\u6d1e\u7ba1\u7406\u56f0\u96be\u3002\u867d\u7136SBOM\u6807\u51c6\u5df2\u7ecf\u6210\u719f\uff0c\u4f46\u4ece\u539f\u59cb\u56fa\u4ef6\u4e2d\u751f\u6210\u53ef\u64cd\u4f5c\u60c5\u62a5\u4ecd\u7136\u662f\u4e00\u4e2a\u624b\u52a8\u4e14\u5bb9\u6613\u51fa\u9519\u7684\u8fc7\u7a0b\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u81ea\u52a8\u5316\u7ba1\u9053\uff0c\u4eceLinux\u7269\u8054\u7f51\u56fa\u4ef6\u4e2d\u63d0\u53d6\u6587\u4ef6\u7cfb\u7edf\uff0c\u751f\u6210\u5168\u9762\u7684SBOM\uff0c\u5c06\u8bc6\u522b\u51fa\u7684\u7ec4\u4ef6\u6620\u5c04\u5230\u5df2\u77e5\u6f0f\u6d1e\uff0c\u5e76\u5e94\u7528\u591a\u56e0\u7d20\u4f18\u5148\u7ea7\u8bc4\u5206\u6a21\u578b\uff08\u6574\u5408CVSS\u3001EPSS\u548cCISA KEV\u76ee\u5f55\u4fe1\u53f7\uff09\u3002", "result": "\u8bba\u6587\u63cf\u8ff0\u4e86\u7cfb\u7edf\u67b6\u6784\u3001\u5d4c\u5165\u5f0fLinux\u7684\u89c4\u8303\u5316\u6311\u6218\uff0c\u4ee5\u53ca\u65e8\u5728\u51cf\u5c11\u544a\u8b66\u75b2\u52b3\u7684\u8bc4\u5206\u65b9\u6cd5\u3002\u7814\u7a76\u6982\u8ff0\u4e86\u4f7f\u7528\u516c\u5171\u4f9b\u5e94\u5546\u56fa\u4ef6\u6570\u636e\u96c6\u9a8c\u8bc1\u63d0\u53d6\u6210\u529f\u7387\u548c\u4f18\u5148\u7ea7\u6548\u80fd\u7684\u8bc4\u4f30\u7b56\u7565\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u8ba1\u7b97\u6bcf\u4e2a\u53d1\u73b0\u7684\u672c\u5730\u5316\u98ce\u9669\u5206\u6570\uff0c\u5f3a\u8c03\u4f18\u5148\u7ea7\u6392\u5e8f\uff0c\u4e0e\u4ea7\u751f\u5927\u91cf\u65e0\u4e0a\u4e0b\u6587\u544a\u8b66\u7684\u4f20\u7edf\u626b\u63cf\u5668\u4e0d\u540c\uff0c\u4e3a\u56fa\u4ef6\u5b89\u5168\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u6846\u67b6\u3002"}}
{"id": "2601.01363", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01363", "abs": "https://arxiv.org/abs/2601.01363", "authors": ["Xiaomeng Yang", "Zhiyu Tan", "Xiaohui Zhong", "Mengping Yang", "Qiusheng Huang", "Lei Chen", "Libo Wu", "Hao Li"], "title": "A unified multimodal understanding and generation model for cross-disciplinary scientific research", "comment": null, "summary": "Scientific discovery increasingly relies on integrating heterogeneous, high-dimensional data across disciplines nowadays. While AI models have achieved notable success across various scientific domains, they typically remain domain-specific or lack the capability of simultaneously understanding and generating multimodal scientific data, particularly for high-dimensional data. Yet, many pressing global challenges and scientific problems are inherently cross-disciplinary and require coordinated progress across multiple fields. Here, we present FuXi-Uni, a native unified multimodal model for scientific understanding and high-fidelity generation across scientific domains within a single architecture. Specifically, FuXi-Uni aligns cross-disciplinary scientific tokens within natural language tokens and employs science decoder to reconstruct scientific tokens, thereby supporting both natural language conversation and scientific numerical prediction. Empirically, we validate FuXi-Uni in Earth science and Biomedicine. In Earth system modeling, the model supports global weather forecasting, tropical cyclone (TC) forecast editing, and spatial downscaling driven by only language instructions. FuXi-Uni generates 10-day global forecasts at 0.25\u00b0 resolution that outperform the SOTA physical forecasting system. It shows superior performance for both TC track and intensity prediction relative to the SOTA physical model, and generates high-resolution regional weather fields that surpass standard interpolation baselines. Regarding biomedicine, FuXi-Uni outperforms leading multimodal large language models on multiple biomedical visual question answering benchmarks. By unifying heterogeneous scientific modalities within a native shared latent space while maintaining strong domain-specific performance, FuXi-Uni provides a step forward more general-purpose, multimodal scientific models.", "AI": {"tldr": "FuXi-Uni\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u591a\u6a21\u6001\u79d1\u5b66\u6a21\u578b\uff0c\u80fd\u591f\u5728\u5355\u4e00\u67b6\u6784\u4e2d\u7406\u89e3\u548c\u751f\u6210\u8de8\u5b66\u79d1\u7684\u9ad8\u7ef4\u79d1\u5b66\u6570\u636e\uff0c\u5728\u5730\u7403\u79d1\u5b66\u548c\u751f\u7269\u533b\u5b66\u9886\u57df\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5f53\u524dAI\u6a21\u578b\u901a\u5e38\u5c40\u9650\u4e8e\u7279\u5b9a\u9886\u57df\uff0c\u7f3a\u4e4f\u540c\u65f6\u7406\u89e3\u548c\u751f\u6210\u591a\u6a21\u6001\u79d1\u5b66\u6570\u636e\u7684\u80fd\u529b\uff0c\u800c\u8bb8\u591a\u5168\u7403\u6027\u6311\u6218\u548c\u79d1\u5b66\u95ee\u9898\u672c\u8d28\u4e0a\u662f\u8de8\u5b66\u79d1\u7684\uff0c\u9700\u8981\u591a\u4e2a\u9886\u57df\u7684\u534f\u540c\u8fdb\u5c55\u3002", "method": "FuXi-Uni\u5c06\u8de8\u5b66\u79d1\u7684\u79d1\u5b66\u6807\u8bb0\u4e0e\u81ea\u7136\u8bed\u8a00\u6807\u8bb0\u5bf9\u9f50\uff0c\u5e76\u4f7f\u7528\u79d1\u5b66\u89e3\u7801\u5668\u91cd\u5efa\u79d1\u5b66\u6807\u8bb0\uff0c\u652f\u6301\u81ea\u7136\u8bed\u8a00\u5bf9\u8bdd\u548c\u79d1\u5b66\u6570\u503c\u9884\u6d4b\u3002", "result": "\u5728\u5730\u7403\u7cfb\u7edf\u5efa\u6a21\u4e2d\uff0cFuXi-Uni\u768410\u5929\u5168\u7403\u5929\u6c14\u9884\u62a5\u57280.25\u00b0\u5206\u8fa8\u7387\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u7269\u7406\u9884\u62a5\u7cfb\u7edf\uff1b\u5728\u70ed\u5e26\u6c14\u65cb\u9884\u6d4b\u548c\u7a7a\u95f4\u964d\u5c3a\u5ea6\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff1b\u5728\u751f\u7269\u533b\u5b66\u9886\u57df\uff0c\u5728\u591a\u4e2a\u751f\u7269\u533b\u5b66\u89c6\u89c9\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u4e86\u9886\u5148\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u3002", "conclusion": "FuXi-Uni\u901a\u8fc7\u5728\u539f\u751f\u5171\u4eab\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7edf\u4e00\u5f02\u6784\u79d1\u5b66\u6a21\u6001\uff0c\u540c\u65f6\u4fdd\u6301\u5f3a\u5927\u7684\u9886\u57df\u7279\u5b9a\u6027\u80fd\uff0c\u4e3a\u66f4\u901a\u7528\u7684\u591a\u6a21\u6001\u79d1\u5b66\u6a21\u578b\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2601.01436", "categories": ["cs.CR", "cs.PL"], "pdf": "https://arxiv.org/pdf/2601.01436", "abs": "https://arxiv.org/abs/2601.01436", "authors": ["Hyunhum Cho", "Ik Rae Jeong"], "title": "Bithoven: Formal Safety for Expressive Bitcoin Smart Contracts", "comment": "15 pages, 3 figures, 4 tables. Submitted to IEEE Transactions on Dependable and Secure Computing", "summary": "The rigorous security model of Bitcoin's UTXO architecture often comes at the cost of developer usability, forcing a reliance on manual stack manipulation that leads to critical financial vulnerabilities like signature malleability, unspendable states and unconstrained execution paths. Industry standards such as Miniscript provide necessary abstractions for policy verification but do not model the full imperative logic required for complex contracts, leaving gaps in state management and resource liveness. This paper introduces Bithoven, a high-level language designed to bridge the gap between expressiveness and formal safety. By integrating a strict type checker and a resource liveness analyzer with a semantic control-flow analyzer, Bithoven eliminates major categories of consensus and logic defects defined in our fault model prior to deployment. Our results indicate that this safety comes at modest cost: Bithoven compiles to Bitcoin Script with efficiency comparable to hand-optimized code, demonstrating that type-safe, developer-friendly abstractions are viable even within the strict byte-size constraints of the Bitcoin blockchain.", "AI": {"tldr": "Bithoven\uff1a\u4e00\u79cd\u4e3a\u6bd4\u7279\u5e01UTXO\u67b6\u6784\u8bbe\u8ba1\u7684\u9ad8\u7ea7\u8bed\u8a00\uff0c\u901a\u8fc7\u7c7b\u578b\u68c0\u67e5\u3001\u8d44\u6e90\u6d3b\u6027\u5206\u6790\u548c\u63a7\u5236\u6d41\u5206\u6790\uff0c\u5728\u4fdd\u6301\u4ee3\u7801\u6548\u7387\u7684\u540c\u65f6\u6d88\u9664\u5171\u8bc6\u548c\u903b\u8f91\u7f3a\u9677\u3002", "motivation": "\u6bd4\u7279\u5e01UTXO\u67b6\u6784\u7684\u4e25\u683c\u5b89\u5168\u6a21\u578b\u5bfc\u81f4\u5f00\u53d1\u8005\u4f53\u9a8c\u5dee\uff0c\u9700\u8981\u624b\u52a8\u6808\u64cd\u4f5c\uff0c\u5bb9\u6613\u4ea7\u751f\u7b7e\u540d\u53ef\u5851\u6027\u3001\u4e0d\u53ef\u82b1\u8d39\u72b6\u6001\u548c\u65e0\u7ea6\u675f\u6267\u884c\u8def\u5f84\u7b49\u4e25\u91cd\u6f0f\u6d1e\u3002\u73b0\u6709\u6807\u51c6\u5982Miniscript\u4ec5\u63d0\u4f9b\u7b56\u7565\u9a8c\u8bc1\u62bd\u8c61\uff0c\u65e0\u6cd5\u6ee1\u8db3\u590d\u6742\u5408\u7ea6\u7684\u5b8c\u6574\u547d\u4ee4\u5f0f\u903b\u8f91\u9700\u6c42\u3002", "method": "\u5f00\u53d1Bithoven\u9ad8\u7ea7\u8bed\u8a00\uff0c\u96c6\u6210\u4e25\u683c\u7c7b\u578b\u68c0\u67e5\u5668\u3001\u8d44\u6e90\u6d3b\u6027\u5206\u6790\u5668\u548c\u8bed\u4e49\u63a7\u5236\u6d41\u5206\u6790\u5668\uff0c\u5728\u90e8\u7f72\u524d\u6d88\u9664\u5171\u8bc6\u548c\u903b\u8f91\u7f3a\u9677\u3002", "result": "Bithoven\u80fd\u591f\u4ee5\u4e0e\u624b\u5de5\u4f18\u5316\u4ee3\u7801\u76f8\u5f53\u7684\u6548\u7387\u7f16\u8bd1\u4e3a\u6bd4\u7279\u5e01\u811a\u672c\uff0c\u8bc1\u660e\u7c7b\u578b\u5b89\u5168\u3001\u5f00\u53d1\u8005\u53cb\u597d\u7684\u62bd\u8c61\u5728\u6bd4\u7279\u5e01\u533a\u5757\u94fe\u4e25\u683c\u7684\u5b57\u8282\u5927\u5c0f\u9650\u5236\u4e0b\u662f\u53ef\u884c\u7684\u3002", "conclusion": "Bithoven\u5728\u8868\u8fbe\u80fd\u529b\u548c\u5f62\u5f0f\u5316\u5b89\u5168\u6027\u4e4b\u95f4\u67b6\u8d77\u4e86\u6865\u6881\uff0c\u4ee5\u9002\u5ea6\u6210\u672c\u5b9e\u73b0\u4e86\u9ad8\u7ea7\u522b\u5b89\u5168\u6027\uff0c\u4e3a\u6bd4\u7279\u5e01\u667a\u80fd\u5408\u7ea6\u5f00\u53d1\u63d0\u4f9b\u4e86\u66f4\u5b89\u5168\u3001\u66f4\u6613\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.01366", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01366", "abs": "https://arxiv.org/abs/2601.01366", "authors": ["Zixian Liu", "Sihao Liu", "Yuqi Zhao"], "title": "KGCE: Knowledge-Augmented Dual-Graph Evaluator for Cross-Platform Educational Agent Benchmarking with Multimodal Language Models", "comment": null, "summary": "With the rapid adoption of multimodal large language models (MLMs) in autonomous agents, cross-platform task execution capabilities in educational settings have garnered significant attention. However, existing benchmark frameworks still exhibit notable deficiencies in supporting cross-platform tasks in educational contexts, especially when dealing with school-specific software (such as XiaoYa Intelligent Assistant, HuaShi XiaZi, etc.), where the efficiency of agents often significantly decreases due to a lack of understanding of the structural specifics of these private-domain software. Additionally, current evaluation methods heavily rely on coarse-grained metrics like goal orientation or trajectory matching, making it challenging to capture the detailed execution and efficiency of agents in complex tasks. To address these issues, we propose KGCE (Knowledge-Augmented Dual-Graph Evaluator for Cross-Platform Educational Agent Benchmarking with Multimodal Language Models), a novel benchmarking platform that integrates knowledge base enhancement and a dual-graph evaluation framework. We first constructed a dataset comprising 104 education-related tasks, covering Windows, Android, and cross-platform collaborative tasks. KGCE introduces a dual-graph evaluation framework that decomposes tasks into multiple sub-goals and verifies their completion status, providing fine-grained evaluation metrics. To overcome the execution bottlenecks of existing agents in private-domain tasks, we developed an enhanced agent system incorporating a knowledge base specific to school-specific software. The code can be found at https://github.com/Kinginlife/KGCE.", "AI": {"tldr": "KGCE\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u8de8\u5e73\u53f0\u6559\u80b2\u667a\u80fd\u4f53\u7684\u57fa\u51c6\u5e73\u53f0\uff0c\u901a\u8fc7\u77e5\u8bc6\u5e93\u589e\u5f3a\u548c\u53cc\u56fe\u8bc4\u4f30\u6846\u67b6\u89e3\u51b3\u73b0\u6709\u57fa\u51c6\u5728\u79c1\u6709\u6559\u80b2\u8f6f\u4ef6\u4efb\u52a1\u4e2d\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6846\u67b6\u5728\u652f\u6301\u8de8\u5e73\u53f0\u6559\u80b2\u4efb\u52a1\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5b66\u6821\u7279\u5b9a\u8f6f\u4ef6\uff08\u5982\u5c0f\u96c5\u667a\u80fd\u52a9\u624b\u3001\u534e\u5e08\u5323\u5b50\u7b49\uff09\u65f6\uff0c\u7531\u4e8e\u7f3a\u4e4f\u5bf9\u8fd9\u4e9b\u79c1\u6709\u9886\u57df\u8f6f\u4ef6\u7ed3\u6784\u7ec6\u8282\u7684\u7406\u89e3\uff0c\u667a\u80fd\u4f53\u6548\u7387\u663e\u8457\u4e0b\u964d\u3002\u6b64\u5916\uff0c\u5f53\u524d\u8bc4\u4f30\u65b9\u6cd5\u8fc7\u5ea6\u4f9d\u8d56\u7c97\u7c92\u5ea6\u6307\u6807\uff0c\u96be\u4ee5\u6355\u6349\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u8be6\u7ec6\u6267\u884c\u548c\u6548\u7387\u3002", "method": "\u63d0\u51faKGCE\u5e73\u53f0\uff0c\u6574\u5408\u77e5\u8bc6\u5e93\u589e\u5f3a\u548c\u53cc\u56fe\u8bc4\u4f30\u6846\u67b6\u3002\u9996\u5148\u6784\u5efa\u5305\u542b104\u4e2a\u6559\u80b2\u76f8\u5173\u4efb\u52a1\u7684\u6570\u636e\u96c6\uff0c\u6db5\u76d6Windows\u3001Android\u548c\u8de8\u5e73\u53f0\u534f\u4f5c\u4efb\u52a1\u3002\u5f15\u5165\u53cc\u56fe\u8bc4\u4f30\u6846\u67b6\uff0c\u5c06\u4efb\u52a1\u5206\u89e3\u4e3a\u591a\u4e2a\u5b50\u76ee\u6807\u5e76\u9a8c\u8bc1\u5176\u5b8c\u6210\u72b6\u6001\uff0c\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u6307\u6807\u3002\u4e3a\u514b\u670d\u73b0\u6709\u667a\u80fd\u4f53\u5728\u79c1\u6709\u9886\u57df\u4efb\u52a1\u4e2d\u7684\u6267\u884c\u74f6\u9888\uff0c\u5f00\u53d1\u4e86\u5305\u542b\u5b66\u6821\u7279\u5b9a\u8f6f\u4ef6\u77e5\u8bc6\u5e93\u7684\u589e\u5f3a\u667a\u80fd\u4f53\u7cfb\u7edf\u3002", "result": "\u5f00\u53d1\u4e86KGCE\u57fa\u51c6\u5e73\u53f0\uff0c\u5305\u542b\u6559\u80b2\u4efb\u52a1\u6570\u636e\u96c6\u548c\u53cc\u56fe\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u7684\u667a\u80fd\u4f53\u6027\u80fd\u8bc4\u4f30\uff0c\u5e76\u89e3\u51b3\u4e86\u79c1\u6709\u6559\u80b2\u8f6f\u4ef6\u4efb\u52a1\u4e2d\u7684\u6267\u884c\u74f6\u9888\u95ee\u9898\u3002", "conclusion": "KGCE\u901a\u8fc7\u77e5\u8bc6\u5e93\u589e\u5f3a\u548c\u53cc\u56fe\u8bc4\u4f30\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u51c6\u5728\u8de8\u5e73\u53f0\u6559\u80b2\u667a\u80fd\u4f53\u8bc4\u4f30\u4e2d\u7684\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u79c1\u6709\u6559\u80b2\u8f6f\u4ef6\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u74f6\u9888\u95ee\u9898\uff0c\u4e3a\u6559\u80b2\u573a\u666f\u4e0b\u7684\u667a\u80fd\u4f53\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u7cbe\u7ec6\u548c\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.01455", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.01455", "abs": "https://arxiv.org/abs/2601.01455", "authors": ["Chandra Thapa", "Surya Nepal"], "title": "Security in the Era of Perceptive Networks: A Comprehensive Taxonomic Framework for Integrated Sensing and Communication Security", "comment": "20 pages", "summary": "Integrated Sensing and Communication (ISAC) represents a significant shift in the 6G landscape, where wireless networks both sense the environment and communicate. While prior comprehensive surveys have established foundational elements of ISAC security, discussed perception-focused security models, and proposed layered defense strategies, this paper synthesizes these studies into a comprehensive taxonomic framework that covers the whole ISAC security domain. This paper provides a systematic and thorough review of ISAC security across multiple orthogonal dimensions. These include threat taxonomy and propagation methods; vulnerability analysis at design, physical, computational, and architectural levels; defense mechanisms categorized by deployment layer; security-performance trade-offs with theoretical bounds; sector-specific security demands for critical infrastructure; and emerging issues such as quantum resilience, AI-hardening, and privacy preservation. Unlike previous frameworks that primarily focus on vision, this review combines these dimensions, introduces new classification schemes that reveal hidden relationships between threats and defenses, and identifies key research gaps through structured analysis. This detailed taxonomy offers a valuable reference for researchers developing secure ISAC systems and policymakers establishing security standards.", "AI": {"tldr": "\u672c\u6587\u5bf96G\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1(ISAC)\u5b89\u5168\u9886\u57df\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u5206\u7c7b\u6846\u67b6\uff0c\u6db5\u76d6\u5a01\u80c1\u4f20\u64ad\u3001\u6f0f\u6d1e\u5206\u6790\u3001\u9632\u5fa1\u673a\u5236\u3001\u5b89\u5168\u6027\u80fd\u6743\u8861\u3001\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u9700\u6c42\u4ee5\u53ca\u65b0\u5174\u95ee\u9898\u7b49\u591a\u4e2a\u7ef4\u5ea6\u3002", "motivation": "\u867d\u7136\u5148\u524d\u7684\u7814\u7a76\u5df2\u7ecf\u5efa\u7acb\u4e86ISAC\u5b89\u5168\u7684\u57fa\u7840\u8981\u7d20\uff0c\u8ba8\u8bba\u4e86\u611f\u77e5\u5bfc\u5411\u7684\u5b89\u5168\u6a21\u578b\uff0c\u5e76\u63d0\u51fa\u4e86\u5206\u5c42\u9632\u5fa1\u7b56\u7565\uff0c\u4f46\u7f3a\u4e4f\u4e00\u4e2a\u80fd\u591f\u6574\u5408\u8fd9\u4e9b\u7814\u7a76\u3001\u8986\u76d6\u6574\u4e2aISAC\u5b89\u5168\u9886\u57df\u7684\u7efc\u5408\u6027\u5206\u7c7b\u6846\u67b6\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u7cfb\u7edf\u6027\u7684\u53c2\u8003\u3002", "method": "\u901a\u8fc7\u591a\u7ef4\u5ea6\u6b63\u4ea4\u5206\u6790\u7684\u65b9\u6cd5\uff0c\u7cfb\u7edf\u6027\u5730\u56de\u987eISAC\u5b89\u5168\u9886\u57df\uff0c\u5305\u62ec\uff1a\u5a01\u80c1\u5206\u7c7b\u4e0e\u4f20\u64ad\u65b9\u6cd5\uff1b\u8bbe\u8ba1\u3001\u7269\u7406\u3001\u8ba1\u7b97\u548c\u67b6\u6784\u5c42\u9762\u7684\u6f0f\u6d1e\u5206\u6790\uff1b\u6309\u90e8\u7f72\u5c42\u5206\u7c7b\u7684\u9632\u5fa1\u673a\u5236\uff1b\u5b89\u5168\u6027\u80fd\u6743\u8861\u7684\u7406\u8bba\u754c\u9650\uff1b\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u7684\u7279\u5b9a\u5b89\u5168\u9700\u6c42\uff1b\u4ee5\u53ca\u91cf\u5b50\u97e7\u6027\u3001AI\u52a0\u56fa\u548c\u9690\u79c1\u4fdd\u62a4\u7b49\u65b0\u5174\u95ee\u9898\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u7684ISAC\u5b89\u5168\u5206\u7c7b\u6846\u67b6\uff0c\u5f15\u5165\u4e86\u65b0\u7684\u5206\u7c7b\u65b9\u6848\uff0c\u63ed\u793a\u4e86\u5a01\u80c1\u4e0e\u9632\u5fa1\u4e4b\u95f4\u7684\u9690\u85cf\u5173\u7cfb\uff0c\u5e76\u901a\u8fc7\u7ed3\u6784\u5316\u5206\u6790\u8bc6\u522b\u4e86\u5173\u952e\u7814\u7a76\u7a7a\u767d\u3002\u8be5\u6846\u67b6\u8d85\u8d8a\u4e86\u4ee5\u5f80\u4e3b\u8981\u5173\u6ce8\u89c6\u89c9\u611f\u77e5\u7684\u6846\u67b6\uff0c\u6574\u5408\u4e86\u591a\u4e2a\u7ef4\u5ea6\u3002", "conclusion": "\u672c\u6587\u63d0\u4f9b\u7684\u8be6\u7ec6\u5206\u7c7b\u6846\u67b6\u4e3a\u5f00\u53d1\u5b89\u5168ISAC\u7cfb\u7edf\u7684\u7814\u7a76\u4eba\u5458\u548c\u5236\u5b9a\u5b89\u5168\u6807\u51c6\u7684\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u53c2\u8003\uff0c\u6709\u52a9\u4e8e\u63a8\u52a86G\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u5b89\u5168\u9886\u57df\u7684\u7cfb\u7edf\u5316\u53d1\u5c55\u3002"}}
{"id": "2601.01378", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01378", "abs": "https://arxiv.org/abs/2601.01378", "authors": ["Han Yuan", "Yilin Wu", "Li Zhang", "Zheng Ma"], "title": "Empowering Small Language Models with Factual Hallucination-Aware Reasoning for Financial Classification", "comment": null, "summary": "Small language models (SLMs) are increasingly used for financial classification due to their fast inference and local deployability. However, compared with large language models, SLMs are more prone to factual hallucinations in reasoning and exhibit weaker classification performance. This raises a natural question: Can mitigating factual hallucinations improve SLMs' financial classification? To address this, we propose a three-step pipeline named AAAI (Association Identification, Automated Detection, and Adaptive Inference). Experiments on three representative SLMs reveal that: (1) factual hallucinations are positively correlated with misclassifications; (2) encoder-based verifiers effectively detect factual hallucinations; and (3) incorporating feedback on factual errors enables SLMs' adaptive inference that enhances classification performance. We hope this pipeline contributes to trustworthy and effective applications of SLMs in finance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAAAI\u4e09\u9636\u6bb5\u6d41\u7a0b\uff0c\u901a\u8fc7\u7f13\u89e3\u4e8b\u5b9e\u5e7b\u89c9\u6765\u63d0\u5347\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd", "motivation": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u5206\u7c7b\u4e2d\u56e0\u63a8\u7406\u65f6\u6613\u4ea7\u751f\u4e8b\u5b9e\u5e7b\u89c9\u800c\u6027\u80fd\u8f83\u5f31\uff0c\u9700\u8981\u63a2\u7d22\u7f13\u89e3\u4e8b\u5b9e\u5e7b\u89c9\u662f\u5426\u80fd\u63d0\u5347\u5176\u5206\u7c7b\u6027\u80fd", "method": "\u63d0\u51faAAAI\u4e09\u9636\u6bb5\u6d41\u7a0b\uff1a\u5173\u8054\u8bc6\u522b\u3001\u81ea\u52a8\u68c0\u6d4b\u548c\u81ea\u9002\u5e94\u63a8\u7406\uff0c\u901a\u8fc7\u7f16\u7801\u5668\u9a8c\u8bc1\u5668\u68c0\u6d4b\u4e8b\u5b9e\u5e7b\u89c9\u5e76\u5229\u7528\u53cd\u9988\u8fdb\u884c\u81ea\u9002\u5e94\u63a8\u7406", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff1a1) \u4e8b\u5b9e\u5e7b\u89c9\u4e0e\u9519\u8bef\u5206\u7c7b\u6b63\u76f8\u5173\uff1b2) \u7f16\u7801\u5668\u9a8c\u8bc1\u5668\u80fd\u6709\u6548\u68c0\u6d4b\u4e8b\u5b9e\u5e7b\u89c9\uff1b3) \u7ed3\u5408\u4e8b\u5b9e\u9519\u8bef\u53cd\u9988\u7684\u81ea\u9002\u5e94\u63a8\u7406\u80fd\u63d0\u5347\u5206\u7c7b\u6027\u80fd", "conclusion": "AAAI\u6d41\u7a0b\u6709\u52a9\u4e8e\u63d0\u5347\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u9886\u57df\u7684\u53ef\u4fe1\u5ea6\u548c\u6709\u6548\u6027\u5e94\u7528"}}
{"id": "2601.01592", "categories": ["cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.01592", "abs": "https://arxiv.org/abs/2601.01592", "authors": ["Xin Wang", "Yunhao Chen", "Juncheng Li", "Yixu Wang", "Yang Yao", "Tianle Gu", "Jie Li", "Yan Teng", "Xingjun Ma", "Yingchun Wang", "Xia Hu"], "title": "OpenRT: An Open-Source Red Teaming Framework for Multimodal LLMs", "comment": null, "summary": "The rapid integration of Multimodal Large Language Models (MLLMs) into critical applications is increasingly hindered by persistent safety vulnerabilities. However, existing red-teaming benchmarks are often fragmented, limited to single-turn text interactions, and lack the scalability required for systematic evaluation. To address this, we introduce OpenRT, a unified, modular, and high-throughput red-teaming framework designed for comprehensive MLLM safety evaluation. At its core, OpenRT architects a paradigm shift in automated red-teaming by introducing an adversarial kernel that enables modular separation across five critical dimensions: model integration, dataset management, attack strategies, judging methods, and evaluation metrics. By standardizing attack interfaces, it decouples adversarial logic from a high-throughput asynchronous runtime, enabling systematic scaling across diverse models. Our framework integrates 37 diverse attack methodologies, spanning white-box gradients, multi-modal perturbations, and sophisticated multi-agent evolutionary strategies. Through an extensive empirical study on 20 advanced models (including GPT-5.2, Claude 4.5, and Gemini 3 Pro), we expose critical safety gaps: even frontier models fail to generalize across attack paradigms, with leading models exhibiting average Attack Success Rates as high as 49.14%. Notably, our findings reveal that reasoning models do not inherently possess superior robustness against complex, multi-turn jailbreaks. By open-sourcing OpenRT, we provide a sustainable, extensible, and continuously maintained infrastructure that accelerates the development and standardization of AI safety.", "AI": {"tldr": "OpenRT\u662f\u4e00\u4e2a\u7edf\u4e00\u3001\u6a21\u5757\u5316\u3001\u9ad8\u541e\u5410\u91cf\u7684\u7ea2\u961f\u6d4b\u8bd5\u6846\u67b6\uff0c\u7528\u4e8e\u5168\u9762\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6f0f\u6d1e\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u4e94\u4e2a\u5173\u952e\u7ef4\u5ea6\u7684\u6a21\u5757\u5316\u5206\u79bb\uff0c\u96c6\u6210\u4e8637\u79cd\u653b\u51fb\u65b9\u6cd5\uff0c\u572820\u4e2a\u5148\u8fdb\u6a21\u578b\u4e0a\u63ed\u793a\u4e86\u9ad8\u8fbe49.14%\u7684\u5e73\u5747\u653b\u51fb\u6210\u529f\u7387\uff0c\u53d1\u73b0\u524d\u6cbf\u6a21\u578b\u65e0\u6cd5\u8de8\u653b\u51fb\u8303\u5f0f\u6cdb\u5316\uff0c\u63a8\u7406\u6a21\u578b\u4e5f\u4e0d\u5177\u5907\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5173\u952e\u5e94\u7528\u4e2d\u7684\u5feb\u901f\u96c6\u6210\u53d7\u5230\u6301\u7eed\u5b89\u5168\u6f0f\u6d1e\u7684\u963b\u788d\u3002\u73b0\u6709\u7684\u7ea2\u961f\u6d4b\u8bd5\u57fa\u51c6\u5f80\u5f80\u788e\u7247\u5316\uff0c\u4ec5\u9650\u4e8e\u5355\u8f6e\u6587\u672c\u4ea4\u4e92\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u8bc4\u4f30\u6240\u9700\u7684\u53ef\u6269\u5c55\u6027\u3002\u9700\u8981\u4e00\u79cd\u7edf\u4e00\u3001\u6a21\u5757\u5316\u7684\u6846\u67b6\u6765\u5168\u9762\u8bc4\u4f30MLLM\u5b89\u5168\u6027\u3002", "method": "OpenRT\u5f15\u5165\u4e86\u4e00\u4e2a\u5bf9\u6297\u5185\u6838\uff0c\u901a\u8fc7\u4e94\u4e2a\u5173\u952e\u7ef4\u5ea6\u7684\u6a21\u5757\u5316\u5206\u79bb\u5b9e\u73b0\u4e86\u8303\u5f0f\u8f6c\u53d8\uff1a\u6a21\u578b\u96c6\u6210\u3001\u6570\u636e\u96c6\u7ba1\u7406\u3001\u653b\u51fb\u7b56\u7565\u3001\u5224\u65ad\u65b9\u6cd5\u548c\u8bc4\u4f30\u6307\u6807\u3002\u901a\u8fc7\u6807\u51c6\u5316\u653b\u51fb\u63a5\u53e3\uff0c\u5c06\u5bf9\u6297\u903b\u8f91\u4e0e\u9ad8\u541e\u5410\u91cf\u5f02\u6b65\u8fd0\u884c\u65f6\u89e3\u8026\uff0c\u652f\u6301\u8de8\u4e0d\u540c\u6a21\u578b\u7684\u7cfb\u7edf\u6269\u5c55\u3002\u6846\u67b6\u96c6\u6210\u4e8637\u79cd\u4e0d\u540c\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u5305\u62ec\u767d\u76d2\u68af\u5ea6\u3001\u591a\u6a21\u6001\u6270\u52a8\u548c\u590d\u6742\u7684\u591a\u667a\u80fd\u4f53\u8fdb\u5316\u7b56\u7565\u3002", "result": "\u572820\u4e2a\u5148\u8fdb\u6a21\u578b\uff08\u5305\u62ecGPT-5.2\u3001Claude 4.5\u548cGemini 3 Pro\uff09\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u8bc1\u7814\u7a76\u66b4\u9732\u4e86\u5173\u952e\u5b89\u5168\u6f0f\u6d1e\uff1a\u5373\u4f7f\u524d\u6cbf\u6a21\u578b\u4e5f\u65e0\u6cd5\u8de8\u653b\u51fb\u8303\u5f0f\u6cdb\u5316\uff0c\u9886\u5148\u6a21\u578b\u7684\u5e73\u5747\u653b\u51fb\u6210\u529f\u7387\u9ad8\u8fbe49.14%\u3002\u7814\u7a76\u53d1\u73b0\u63a8\u7406\u6a21\u578b\u5e76\u4e0d\u56fa\u6709\u5730\u5177\u5907\u5bf9\u6297\u590d\u6742\u591a\u8f6e\u8d8a\u72f1\u7684\u66f4\u5f3a\u9c81\u68d2\u6027\u3002", "conclusion": "\u901a\u8fc7\u5f00\u6e90OpenRT\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6301\u7eed\u3001\u53ef\u6269\u5c55\u4e14\u6301\u7eed\u7ef4\u62a4\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u52a0\u901f\u4e86AI\u5b89\u5168\u7684\u53d1\u5c55\u548c\u6807\u51c6\u5316\u3002\u8be5\u6846\u67b6\u4e3a\u7cfb\u7edf\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u7edf\u4e00\u89e3\u51b3\u65b9\u6848\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u5b89\u5168\u9632\u62a4\u65b9\u9762\u7684\u663e\u8457\u4e0d\u8db3\u3002"}}
{"id": "2601.01467", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01467", "abs": "https://arxiv.org/abs/2601.01467", "authors": ["Romuald Kwessy Mouona", "Blaise Bl\u00e9riot Koguep Njionou", "Etienne Romuald Temgoua Alomo", "Rokia Missaoui", "Leonard Kwuida"], "title": "A construction of an optimal base for conditional attribute and attributional condition implications in triadic contexts", "comment": "26 pages", "summary": "This article studies implications in triadic contexts. Specifically, we focus on those introduced by Ganter and Obiedkov, namely conditional attribute and attributional condition implications. Our aim is to construct an optimal base for these implications.", "AI": {"tldr": "\u7814\u7a76\u4e09\u5143\u80cc\u666f\u4e2d\u7684\u8574\u542b\u5173\u7cfb\uff0c\u7279\u522b\u5173\u6ce8Ganter\u548cObiedkov\u63d0\u51fa\u7684\u6761\u4ef6\u5c5e\u6027\u8574\u542b\u548c\u5c5e\u6027\u6761\u4ef6\u8574\u542b\uff0c\u76ee\u6807\u662f\u6784\u5efa\u8fd9\u4e9b\u8574\u542b\u7684\u6700\u4f18\u57fa", "motivation": "\u4e09\u5143\u80cc\u666f\u4e2d\u7684\u8574\u542b\u5173\u7cfb\u7814\u7a76\u76f8\u5bf9\u8f83\u5c11\uff0cGanter\u548cObiedkov\u63d0\u51fa\u7684\u6761\u4ef6\u5c5e\u6027\u8574\u542b\u548c\u5c5e\u6027\u6761\u4ef6\u8574\u542b\u9700\u8981\u7cfb\u7edf\u6027\u7684\u57fa\u6784\u5efa\u65b9\u6cd5", "method": "\u7814\u7a76\u4e09\u5143\u80cc\u666f\u4e2d\u7684\u8574\u542b\u5173\u7cfb\uff0c\u7279\u522b\u5173\u6ce8\u6761\u4ef6\u5c5e\u6027\u8574\u542b\u548c\u5c5e\u6027\u6761\u4ef6\u8574\u542b\uff0c\u76ee\u6807\u662f\u6784\u5efa\u8fd9\u4e9b\u8574\u542b\u7684\u6700\u4f18\u57fa", "result": "\u672a\u5728\u6458\u8981\u4e2d\u660e\u786e\u8bf4\u660e\u5177\u4f53\u7ed3\u679c\uff0c\u4f46\u7814\u7a76\u76ee\u6807\u662f\u6784\u5efa\u6700\u4f18\u57fa", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u4e09\u5143\u80cc\u666f\u4e2d\u7684\u8574\u542b\u5173\u7cfb\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u57fa\u6784\u5efa\u65b9\u6cd5"}}
{"id": "2601.01765", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.01765", "abs": "https://arxiv.org/abs/2601.01765", "authors": ["Yao Lu", "Shang Liu", "Hangan Zhou", "Wenji Fang", "Qijun Zhang", "Zhiyao Xie"], "title": "A New Benchmark for the Appropriate Evaluation of RTL Code Optimization", "comment": null, "summary": "The rapid progress of artificial intelligence increasingly relies on efficient integrated circuit (IC) design. Recent studies have explored the use of large language models (LLMs) for generating Register Transfer Level (RTL) code, but existing benchmarks mainly evaluate syntactic correctness rather than optimization quality in terms of power, performance, and area (PPA). This work introduces RTL-OPT, a benchmark for assessing the capability of LLMs in RTL optimization. RTL-OPT contains 36 handcrafted digital designs that cover diverse implementation categories including combinational logic, pipelined datapaths, finite state machines, and memory interfaces. Each task provides a pair of RTL codes, a suboptimal version and a human-optimized reference that reflects industry-proven optimization patterns not captured by conventional synthesis tools. Furthermore, RTL-OPT integrates an automated evaluation framework to verify functional correctness and quantify PPA improvements, enabling standardized and meaningful assessment of generative models for hardware design optimization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86RTL-OPT\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728RTL\u4ee3\u7801\u4f18\u5316\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5f25\u8865\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u8bed\u6cd5\u6b63\u786e\u6027\u800c\u975ePPA\u4f18\u5316\u8d28\u91cf\u7684\u4e0d\u8db3\u3002", "motivation": "\u5f53\u524dAI\u5728\u96c6\u6210\u7535\u8def\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684RTL\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u4e3b\u8981\u8bc4\u4f30\u8bed\u6cd5\u6b63\u786e\u6027\uff0c\u7f3a\u4e4f\u5bf9\u529f\u8017\u3001\u6027\u80fd\u548c\u9762\u79ef\uff08PPA\uff09\u4f18\u5316\u8d28\u91cf\u7684\u8bc4\u4f30\u3002\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u80fd\u591f\u8bc4\u4f30LLMs\u5728RTL\u4f18\u5316\u65b9\u9762\u80fd\u529b\u7684\u6807\u51c6\u5316\u57fa\u51c6\u3002", "method": "\u521b\u5efa\u4e86RTL-OPT\u57fa\u51c6\uff0c\u5305\u542b36\u4e2a\u624b\u5de5\u8bbe\u8ba1\u7684\u6570\u5b57\u7535\u8def\uff0c\u6db5\u76d6\u7ec4\u5408\u903b\u8f91\u3001\u6d41\u6c34\u7ebf\u6570\u636e\u901a\u8def\u3001\u6709\u9650\u72b6\u6001\u673a\u548c\u5b58\u50a8\u5668\u63a5\u53e3\u7b49\u4e0d\u540c\u5b9e\u73b0\u7c7b\u522b\u3002\u6bcf\u4e2a\u4efb\u52a1\u63d0\u4f9b\u4e00\u5bf9RTL\u4ee3\u7801\uff1a\u6b21\u4f18\u7248\u672c\u548c\u4eba\u5de5\u4f18\u5316\u7684\u53c2\u8003\u7248\u672c\uff0c\u540e\u8005\u4f53\u73b0\u4e86\u884c\u4e1a\u9a8c\u8bc1\u7684\u4f18\u5316\u6a21\u5f0f\u3002\u540c\u65f6\u96c6\u6210\u4e86\u81ea\u52a8\u5316\u8bc4\u4f30\u6846\u67b6\u6765\u9a8c\u8bc1\u529f\u80fd\u6b63\u786e\u6027\u5e76\u91cf\u5316PPA\u6539\u8fdb\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5305\u542b36\u4e2a\u8bbe\u8ba1\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff0c\u6bcf\u4e2a\u4efb\u52a1\u90fd\u6709\u660e\u786e\u7684\u4f18\u5316\u76ee\u6807\uff08\u6b21\u4f18\u4ee3\u7801vs\u4f18\u5316\u53c2\u8003\uff09\u3002\u5efa\u7acb\u4e86\u81ea\u52a8\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u6807\u51c6\u5316\u8bc4\u4f30\u751f\u6210\u6a21\u578b\u5728\u786c\u4ef6\u8bbe\u8ba1\u4f18\u5316\u65b9\u9762\u7684\u80fd\u529b\u3002", "conclusion": "RTL-OPT\u57fa\u51c6\u586b\u8865\u4e86\u73b0\u6709\u8bc4\u4f30\u4f53\u7cfb\u7684\u7a7a\u767d\uff0c\u4e3a\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728RTL\u4f18\u5316\u65b9\u9762\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8AI\u5728\u786c\u4ef6\u8bbe\u8ba1\u4f18\u5316\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.01546", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01546", "abs": "https://arxiv.org/abs/2601.01546", "authors": ["Letian Kong", "Qianran", "Jin", "Renyu Zhang"], "title": "Improving Behavioral Alignment in LLM Social Simulations via Context Formation and Navigation", "comment": "39 pages, 2 figures, 3 tables", "summary": "Large language models (LLMs) are increasingly used to simulate human behavior in experimental settings, but they systematically diverge from human decisions in complex decision-making environments, where participants must anticipate others' actions and form beliefs based on observed behavior. We propose a two-stage framework for improving behavioral alignment. The first stage, context formation, explicitly specifies the experimental design to establish an accurate representation of the decision task and its context. The second stage, context navigation, guides the reasoning process within that representation to make decisions. We validate this framework through a focal replication of a sequential purchasing game with quality signaling (Kremer and Debo, 2016), extending to a crowdfunding game with costly signaling (Cason et al., 2025) and a demand-estimation task (Gui and Toubia, 2025) to test generalizability across decision environments. Across four state-of-the-art (SOTA) models (GPT-4o, GPT-5, Claude-4.0-Sonnet-Thinking, DeepSeek-R1), we find that complex decision-making environments require both stages to achieve behavioral alignment with human benchmarks, whereas the simpler demand-estimation task requires only context formation. Our findings clarify when each stage is necessary and provide a systematic approach for designing and diagnosing LLM social simulations as complements to human subjects in behavioral research.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u4e24\u9636\u6bb5\u6846\u67b6\u6765\u6539\u8fdbLLM\u5728\u590d\u6742\u51b3\u7b56\u73af\u5883\u4e2d\u7684\u884c\u4e3a\u5bf9\u9f50\uff1a\u7b2c\u4e00\u9636\u6bb5\u4e0a\u4e0b\u6587\u5f62\u6210\u660e\u786e\u6307\u5b9a\u5b9e\u9a8c\u8bbe\u8ba1\uff0c\u7b2c\u4e8c\u9636\u6bb5\u4e0a\u4e0b\u6587\u5bfc\u822a\u5728\u8be5\u8868\u793a\u4e2d\u5f15\u5bfc\u63a8\u7406\u8fc7\u7a0b\u3002\u9a8c\u8bc1\u8868\u660e\u590d\u6742\u51b3\u7b56\u9700\u8981\u4e24\u9636\u6bb5\uff0c\u800c\u7b80\u5355\u4efb\u52a1\u4ec5\u9700\u7b2c\u4e00\u9636\u6bb5\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u7528\u4e8e\u6a21\u62df\u4eba\u7c7b\u5b9e\u9a8c\u884c\u4e3a\uff0c\u4f46\u5728\u590d\u6742\u51b3\u7b56\u73af\u5883\u4e2d\uff08\u53c2\u4e0e\u8005\u9700\u8981\u9884\u6d4b\u4ed6\u4eba\u884c\u52a8\u5e76\u57fa\u4e8e\u89c2\u5bdf\u884c\u4e3a\u5f62\u6210\u4fe1\u5ff5\uff09\u4e0e\u4eba\u7c7b\u51b3\u7b56\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5dee\uff0c\u9700\u8981\u6539\u8fdb\u884c\u4e3a\u5bf9\u9f50\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1\uff09\u4e0a\u4e0b\u6587\u5f62\u6210\u9636\u6bb5\u660e\u786e\u6307\u5b9a\u5b9e\u9a8c\u8bbe\u8ba1\uff0c\u5efa\u7acb\u51b3\u7b56\u4efb\u52a1\u53ca\u5176\u4e0a\u4e0b\u6587\u7684\u51c6\u786e\u8868\u793a\uff1b2\uff09\u4e0a\u4e0b\u6587\u5bfc\u822a\u9636\u6bb5\u5728\u8be5\u8868\u793a\u4e2d\u5f15\u5bfc\u63a8\u7406\u8fc7\u7a0b\u4ee5\u505a\u51fa\u51b3\u7b56\u3002\u901a\u8fc7\u4e09\u4e2a\u5b9e\u9a8c\u9a8c\u8bc1\uff1a\u987a\u5e8f\u8d2d\u4e70\u6e38\u620f\u3001\u4f17\u7b79\u6e38\u620f\u548c\u9700\u6c42\u4f30\u8ba1\u4efb\u52a1\uff0c\u4f7f\u7528\u56db\u79cdSOTA\u6a21\u578b\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u5728\u56db\u79cdSOTA\u6a21\u578b\u4e0a\u9a8c\u8bc1\u53d1\u73b0\uff1a\u590d\u6742\u51b3\u7b56\u73af\u5883\u9700\u8981\u4e24\u9636\u6bb5\u624d\u80fd\u5b9e\u73b0\u4e0e\u4eba\u7c7b\u57fa\u51c6\u7684\u884c\u4e3a\u5bf9\u9f50\uff0c\u800c\u7b80\u5355\u7684\u9700\u6c42\u4f30\u8ba1\u4efb\u52a1\u4ec5\u9700\u4e0a\u4e0b\u6587\u5f62\u6210\u9636\u6bb5\u3002\u6846\u67b6\u4e3a\u8bbe\u8ba1\u548c\u8bca\u65adLLM\u793e\u4f1a\u6a21\u62df\u63d0\u4f9b\u4e86\u7cfb\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u4e24\u9636\u6bb5\u6846\u67b6\u6f84\u6e05\u4e86\u4f55\u65f6\u9700\u8981\u6bcf\u4e2a\u9636\u6bb5\uff0c\u4e3a\u884c\u4e3a\u7814\u7a76\u4e2d\u5c06LLM\u793e\u4f1a\u6a21\u62df\u4f5c\u4e3a\u4eba\u7c7b\u53d7\u8bd5\u8005\u7684\u8865\u5145\u63d0\u4f9b\u4e86\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86LLM\u5728\u590d\u6742\u51b3\u7b56\u73af\u5883\u4e2d\u7684\u884c\u4e3a\u5bf9\u9f50\u80fd\u529b\u3002"}}
{"id": "2601.01562", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01562", "abs": "https://arxiv.org/abs/2601.01562", "authors": ["Mingyu Xu", "Cheng Fang", "Keyue Jiang", "Yuqian Zheng", "Yanghua Xiao", "Baojian Zhou", "Qifang Zhao", "Suhang Zheng", "Xiuwen Zhu", "Jiyang Tang", "Yongchi Zhao", "Yijia Luo", "Zhiqi Bai", "Yuchi Xu", "Wenbo Su", "Wei Wang", "Bing Zhao", "Lin Qu", "Xiaoxiao Xu"], "title": "Logics-STEM: Empowering LLM Reasoning via Failure-Driven Post-Training and Document Knowledge Enhancement", "comment": null, "summary": "We present Logics-STEM, a state-of-the-art reasoning model fine-tuned on Logics-STEM-SFT-Dataset, a high-quality and diverse dataset at 10M scale that represents one of the largest-scale open-source long chain-of-thought corpora. Logics-STEM targets reasoning tasks in the domains of Science, Technology, Engineering, and Mathematics (STEM), and exhibits exceptional performance on STEM-related benchmarks with an average improvement of 4.68% over the next-best model at 8B scale. We attribute the gains to our data-algorithm co-design engine, where they are jointly optimized to fit a gold-standard distribution behind reasoning. Data-wise, the Logics-STEM-SFT-Dataset is constructed from a meticulously designed data curation engine with 5 stages to ensure the quality, diversity, and scalability, including annotation, deduplication, decontamination, distillation, and stratified sampling. Algorithm-wise, our failure-driven post-training framework leverages targeted knowledge retrieval and data synthesis around model failure regions in the Supervised Fine-tuning (SFT) stage to effectively guide the second-stage SFT or the reinforcement learning (RL) for better fitting the target distribution. The superior empirical performance of Logics-STEM reveals the vast potential of combining large-scale open-source data with carefully designed synthetic data, underscoring the critical role of data-algorithm co-design in enhancing reasoning capabilities through post-training. We make both the Logics-STEM models (8B and 32B) and the Logics-STEM-SFT-Dataset (10M and downsampled 2.2M versions) publicly available to support future research in the open-source community.", "AI": {"tldr": "Logics-STEM\u662f\u4e00\u4e2a\u9488\u5bf9STEM\u9886\u57df\u63a8\u7406\u4efb\u52a1\u4f18\u5316\u7684\u5148\u8fdb\u63a8\u7406\u6a21\u578b\uff0c\u901a\u8fc7\u6570\u636e\u7b97\u6cd5\u534f\u540c\u8bbe\u8ba1\uff0c\u572810M\u89c4\u6a21\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\uff0c\u5728STEM\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6bd4\u540c\u7c7b8B\u6a21\u578b\u5e73\u5747\u63d0\u53474.68%", "motivation": "\u9488\u5bf9STEM\uff08\u79d1\u5b66\u3001\u6280\u672f\u3001\u5de5\u7a0b\u3001\u6570\u5b66\uff09\u9886\u57df\u7684\u63a8\u7406\u4efb\u52a1\uff0c\u9700\u8981\u9ad8\u8d28\u91cf\u3001\u5927\u89c4\u6a21\u7684\u63a8\u7406\u6570\u636e\u6765\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002\u73b0\u6709\u5f00\u6e90\u957f\u94fe\u601d\u7ef4\u6570\u636e\u96c6\u89c4\u6a21\u6709\u9650\uff0c\u4e14\u7f3a\u4e4f\u4e13\u95e8\u9488\u5bf9STEM\u9886\u57df\u7684\u6570\u636e\u96c6\u548c\u4f18\u5316\u65b9\u6cd5", "method": "\u91c7\u7528\u6570\u636e\u7b97\u6cd5\u534f\u540c\u8bbe\u8ba1\u5f15\u64ce\uff1a1\uff09\u6570\u636e\u65b9\u9762\uff0c\u901a\u8fc75\u9636\u6bb5\u6570\u636e\u6574\u7406\u5f15\u64ce\uff08\u6807\u6ce8\u3001\u53bb\u91cd\u3001\u53bb\u6c61\u67d3\u3001\u84b8\u998f\u3001\u5206\u5c42\u91c7\u6837\uff09\u6784\u5efa10M\u89c4\u6a21\u7684Logics-STEM-SFT-Dataset\uff1b2\uff09\u7b97\u6cd5\u65b9\u9762\uff0c\u91c7\u7528\u5931\u8d25\u9a71\u52a8\u7684\u540e\u8bad\u7ec3\u6846\u67b6\uff0c\u57fa\u4e8eSFT\u9636\u6bb5\u7684\u6a21\u578b\u5931\u8d25\u533a\u57df\u8fdb\u884c\u9488\u5bf9\u6027\u77e5\u8bc6\u68c0\u7d22\u548c\u6570\u636e\u5408\u6210\uff0c\u6307\u5bfc\u7b2c\u4e8c\u9636\u6bb5SFT\u6216\u5f3a\u5316\u5b66\u4e60", "result": "Logics-STEM\u5728STEM\u76f8\u5173\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u6bd4\u540c\u7c7b8B\u89c4\u6a21\u7684\u6700\u4f73\u6a21\u578b\u5e73\u5747\u63d0\u53474.68%\u3002\u63d0\u4f9b\u4e868B\u548c32B\u6a21\u578b\u4ee5\u53ca10M\u548c2.2M\u7248\u672c\u7684\u6570\u636e\u96c6", "conclusion": "\u5927\u89c4\u6a21\u5f00\u6e90\u6570\u636e\u4e0e\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u5408\u6210\u6570\u636e\u7ed3\u5408\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u6570\u636e\u7b97\u6cd5\u534f\u540c\u8bbe\u8ba1\u901a\u8fc7\u540e\u8bad\u7ec3\u663e\u8457\u63d0\u5347\u63a8\u7406\u80fd\u529b\u3002\u5f00\u6e90\u6a21\u578b\u548c\u6570\u636e\u96c6\u652f\u6301\u793e\u533a\u7814\u7a76"}}
{"id": "2601.02245", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.02245", "abs": "https://arxiv.org/abs/2601.02245", "authors": ["Michiel Van Kenhove", "Erik Pohle", "Leonard Schild", "Martin Zbudila", "Merlijn Sebrechts", "Filip De Turck", "Bruno Volckaert", "Aysajan Abidin"], "title": "MOZAIK: A Privacy-Preserving Analytics Platform for IoT Data Using MPC and FHE", "comment": "Accepted to Journal of Network and Systems Management", "summary": "The rapid increase of Internet of Things (IoT) systems across several domains has led to the generation of vast volumes of sensitive data, presenting significant challenges in terms of storage and data analytics. Cloud-assisted IoT solutions offer storage, scalability, and computational resources, but introduce new security and privacy risks that conventional trust-based approaches fail to adequately mitigate. To address these challenges, this paper presents MOZAIK, a novel end-to-end privacy-preserving confidential data storage and distributed processing architecture tailored for IoT-to-cloud scenarios. MOZAIK ensures that data remains encrypted throughout its lifecycle, including during transmission, storage, and processing. This is achieved by employing a cryptographic privacy-enhancing technology known as computing on encrypted data (COED). Two distinct COED techniques are explored, specifically secure multi-party computation (MPC) and fully homomorphic encryption (FHE). The paper includes a comprehensive analysis of the MOZAIK architecture, including a proof-of-concept implementation and performance evaluations. The evaluation results demonstrate the feasibility of the MOZAIK system and indicate the cost of an end-to-end privacy-preserving system compared to regular plaintext alternatives. All components of the MOZAIK platform are released as open-source software alongside this publication, with the aim of advancing secure and privacy-preserving data processing practices.", "AI": {"tldr": "MOZAIK\u662f\u4e00\u4e2a\u9762\u5411IoT\u5230\u4e91\u573a\u666f\u7684\u7aef\u5230\u7aef\u9690\u79c1\u4fdd\u62a4\u673a\u5bc6\u6570\u636e\u5b58\u50a8\u548c\u5206\u5e03\u5f0f\u5904\u7406\u67b6\u6784\uff0c\u4f7f\u7528\u52a0\u5bc6\u6570\u636e\u8ba1\u7b97\u6280\u672f\u786e\u4fdd\u6570\u636e\u5728\u4f20\u8f93\u3001\u5b58\u50a8\u548c\u5904\u7406\u8fc7\u7a0b\u4e2d\u59cb\u7ec8\u4fdd\u6301\u52a0\u5bc6\u72b6\u6001\u3002", "motivation": "\u7269\u8054\u7f51\u7cfb\u7edf\u4ea7\u751f\u5927\u91cf\u654f\u611f\u6570\u636e\uff0c\u4e91\u8f85\u52a9IoT\u89e3\u51b3\u65b9\u6848\u867d\u7136\u63d0\u4f9b\u5b58\u50a8\u548c\u8ba1\u7b97\u8d44\u6e90\uff0c\u4f46\u4f20\u7edf\u4fe1\u4efb\u65b9\u6cd5\u65e0\u6cd5\u5145\u5206\u7f13\u89e3\u5b89\u5168\u548c\u9690\u79c1\u98ce\u9669\uff0c\u9700\u8981\u65b0\u7684\u9690\u79c1\u4fdd\u62a4\u65b9\u6848\u3002", "method": "\u63d0\u51faMOZAIK\u67b6\u6784\uff0c\u91c7\u7528\u52a0\u5bc6\u6570\u636e\u8ba1\u7b97\u6280\u672f\uff0c\u5305\u62ec\u5b89\u5168\u591a\u65b9\u8ba1\u7b97\u548c\u5168\u540c\u6001\u52a0\u5bc6\u4e24\u79cd\u65b9\u6cd5\uff0c\u786e\u4fdd\u6570\u636e\u5168\u751f\u547d\u5468\u671f\u52a0\u5bc6\uff0c\u5e76\u63d0\u4f9b\u6982\u5ff5\u9a8c\u8bc1\u5b9e\u73b0\u548c\u6027\u80fd\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u8868\u660eMOZAIK\u7cfb\u7edf\u5177\u6709\u53ef\u884c\u6027\uff0c\u5c55\u793a\u4e86\u7aef\u5230\u7aef\u9690\u79c1\u4fdd\u62a4\u7cfb\u7edf\u76f8\u5bf9\u4e8e\u666e\u901a\u660e\u6587\u66ff\u4ee3\u65b9\u6848\u7684\u6210\u672c\uff0c\u6240\u6709\u7ec4\u4ef6\u5df2\u4f5c\u4e3a\u5f00\u6e90\u8f6f\u4ef6\u53d1\u5e03\u3002", "conclusion": "MOZAIK\u4e3aIoT\u5230\u4e91\u573a\u666f\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u9690\u79c1\u4fdd\u62a4\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u52a0\u5bc6\u6570\u636e\u8ba1\u7b97\u6280\u672f\u786e\u4fdd\u6570\u636e\u5b89\u5168\uff0c\u5f00\u6e90\u53d1\u5e03\u65e8\u5728\u63a8\u52a8\u5b89\u5168\u548c\u9690\u79c1\u4fdd\u62a4\u6570\u636e\u5904\u7406\u5b9e\u8df5\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.01609", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01609", "abs": "https://arxiv.org/abs/2601.01609", "authors": ["Albert Sadowski", "Jaros\u0142aw A. Chudziak"], "title": "Structured Decomposition for LLM Reasoning: Cross-Domain Validation and Semantic Web Integration", "comment": null, "summary": "Rule-based reasoning over natural language input arises in domains where decisions must be auditable and justifiable: clinical protocols specify eligibility criteria in prose, evidence rules define admissibility through textual conditions, and scientific standards dictate methodological requirements. Applying rules to such inputs demands both interpretive flexibility and formal guarantees. Large language models (LLMs) provide flexibility but cannot ensure consistent rule application; symbolic systems provide guarantees but require structured input. This paper presents an integration pattern that combines these strengths: LLMs serve as ontology population engines, translating unstructured text into ABox assertions according to expert-authored TBox specifications, while SWRL-based reasoners apply rules with deterministic guarantees. The framework decomposes reasoning into entity identification, assertion extraction, and symbolic verification, with task definitions grounded in OWL 2 ontologies. Experiments across three domains (legal hearsay determination, scientific method-task application, clinical trial eligibility) and eleven language models validate the approach. Structured decomposition achieves statistically significant improvements over few-shot prompting in aggregate, with gains observed across all three domains. An ablation study confirms that symbolic verification provides substantial benefit beyond structured prompting alone. The populated ABox integrates with standard semantic web tooling for inspection and querying, positioning the framework for richer inference patterns that simpler formalisms cannot express.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u7b26\u53f7\u63a8\u7406\u7684\u6846\u67b6\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u6587\u672c\u8f6c\u6362\u4e3aABox\u65ad\u8a00\uff0c\u7136\u540e\u4f7f\u7528SWRL\u89c4\u5219\u8fdb\u884c\u786e\u5b9a\u6027\u63a8\u7406\uff0c\u5728\u4e09\u4e2a\u9886\u57df\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u4f18\u4e8e\u5c11\u6837\u672c\u63d0\u793a\u3002", "motivation": "\u5728\u9700\u8981\u53ef\u5ba1\u8ba1\u548c\u53ef\u89e3\u91ca\u51b3\u7b56\u7684\u9886\u57df\uff08\u5982\u4e34\u5e8a\u534f\u8bae\u3001\u6cd5\u5f8b\u8bc1\u636e\u89c4\u5219\u3001\u79d1\u5b66\u6807\u51c6\uff09\uff0c\u89c4\u5219\u63a8\u7406\u9700\u8981\u540c\u65f6\u5177\u5907\u89e3\u91ca\u7075\u6d3b\u6027\u548c\u5f62\u5f0f\u5316\u4fdd\u8bc1\u3002\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u7075\u6d3b\u6027\u4f46\u65e0\u6cd5\u4fdd\u8bc1\u4e00\u81f4\u6027\uff0c\u7b26\u53f7\u7cfb\u7edf\u63d0\u4f9b\u4fdd\u8bc1\u4f46\u9700\u8981\u7ed3\u6784\u5316\u8f93\u5165\u3002", "method": "\u63d0\u51fa\u96c6\u6210\u6a21\u5f0f\uff1a\u4f7f\u7528LLMs\u4f5c\u4e3a\u672c\u4f53\u586b\u5145\u5f15\u64ce\uff0c\u5c06\u975e\u7ed3\u6784\u5316\u6587\u672c\u8f6c\u6362\u4e3a\u57fa\u4e8e\u4e13\u5bb6\u7f16\u5199TBox\u89c4\u8303\u7684ABox\u65ad\u8a00\uff0c\u540c\u65f6\u4f7f\u7528SWRL\u63a8\u7406\u5668\u5e94\u7528\u89c4\u5219\u63d0\u4f9b\u786e\u5b9a\u6027\u4fdd\u8bc1\u3002\u6846\u67b6\u5c06\u63a8\u7406\u5206\u89e3\u4e3a\u5b9e\u4f53\u8bc6\u522b\u3001\u65ad\u8a00\u63d0\u53d6\u548c\u7b26\u53f7\u9a8c\u8bc1\u4e09\u4e2a\u6b65\u9aa4\u3002", "result": "\u5728\u4e09\u4e2a\u9886\u57df\uff08\u6cd5\u5f8b\u4f20\u95fb\u8bc1\u636e\u5224\u5b9a\u3001\u79d1\u5b66\u65b9\u6cd5\u4efb\u52a1\u5e94\u7528\u3001\u4e34\u5e8a\u8bd5\u9a8c\u8d44\u683c\uff09\u548c\u5341\u4e00\u4e2a\u8bed\u8a00\u6a21\u578b\u4e0a\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u3002\u7ed3\u6784\u5316\u5206\u89e3\u5728\u603b\u4f53\u4e0a\u6bd4\u5c11\u6837\u672c\u63d0\u793a\u6709\u7edf\u8ba1\u663e\u8457\u6539\u8fdb\uff0c\u4e09\u4e2a\u9886\u57df\u90fd\u89c2\u5bdf\u5230\u589e\u76ca\u3002\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u7b26\u53f7\u9a8c\u8bc1\u6bd4\u5355\u7eaf\u7ed3\u6784\u5316\u63d0\u793a\u6709\u5b9e\u8d28\u6027\u597d\u5904\u3002", "conclusion": "\u8be5\u6846\u67b6\u7ed3\u5408\u4e86LLMs\u7684\u7075\u6d3b\u6027\u548c\u7b26\u53f7\u63a8\u7406\u7684\u786e\u5b9a\u6027\u4fdd\u8bc1\uff0c\u586b\u5145\u7684ABox\u53ef\u4e0e\u6807\u51c6\u8bed\u4e49\u7f51\u5de5\u5177\u96c6\u6210\u8fdb\u884c\u68c0\u67e5\u548c\u67e5\u8be2\uff0c\u4e3a\u66f4\u4e30\u5bcc\u7684\u63a8\u7406\u6a21\u5f0f\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2601.02257", "categories": ["cs.CR", "cs.DS", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.02257", "abs": "https://arxiv.org/abs/2601.02257", "authors": ["Joel Daniel Andersson", "Palak Jain", "Satchit Sivakumar"], "title": "Improved Accuracy for Private Continual Cardinality Estimation in Fully Dynamic Streams via Matrix Factorization", "comment": null, "summary": "We study differentially-private statistics in the fully dynamic continual observation model, where many updates can arrive at each time step and updates to a stream can involve both insertions and deletions of an item. Earlier work (e.g., Jain et al., NeurIPS 2023 for counting distinct elements; Raskhodnikova & Steiner, PODS 2025 for triangle counting with edge updates) reduced the respective cardinality estimation problem to continual counting on the difference stream associated with the true function values on the input stream. In such reductions, a change in the original stream can cause many changes in the difference stream, this poses a challenge for applying private continual counting algorithms to obtain optimal error bounds. We improve the accuracy of several such reductions by studying the associated $\\ell_p$-sensitivity vectors of the resulting difference streams and isolating their properties.\n  We demonstrate that our framework gives improved bounds for counting distinct elements, estimating degree histograms, and estimating triangle counts (under a slightly relaxed privacy model), thus offering a general approach to private continual cardinality estimation in streaming settings. Our improved accuracy stems from tight analysis of known factorization mechanisms for the counting matrix in this setting; the key technical challenge is arguing that one can use state-of-the-art factorizations for sensitivity vector sets with the properties we isolate. Empirically and analytically, we demonstrate that our improved error bounds offer a substantial improvement in accuracy for cardinality estimation problems over a large range of parameters.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u5dee\u5206\u9690\u79c1\u6d41\u5f0f\u7edf\u8ba1\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u5dee\u5f02\u6d41\u7684\u2113p\u654f\u611f\u5ea6\u5411\u91cf\u7279\u6027\uff0c\u4f18\u5316\u4e86\u52a8\u6001\u6301\u7eed\u89c2\u5bdf\u6a21\u578b\u4e2d\u7684\u57fa\u6570\u4f30\u8ba1\u7cbe\u5ea6\u3002", "motivation": "\u5728\u5b8c\u5168\u52a8\u6001\u6301\u7eed\u89c2\u5bdf\u6a21\u578b\u4e2d\uff0c\u6bcf\u4e2a\u65f6\u95f4\u6b65\u53ef\u80fd\u6709\u591a\u4e2a\u66f4\u65b0\uff08\u63d2\u5165\u548c\u5220\u9664\uff09\uff0c\u73b0\u6709\u65b9\u6cd5\u5c06\u57fa\u6570\u4f30\u8ba1\u95ee\u9898\u7b80\u5316\u4e3a\u5dee\u5f02\u6d41\u7684\u6301\u7eed\u8ba1\u6570\uff0c\u4f46\u539f\u59cb\u6d41\u7684\u53d8\u5316\u53ef\u80fd\u5bfc\u81f4\u5dee\u5f02\u6d41\u591a\u6b21\u53d8\u5316\uff0c\u8fd9\u7ed9\u5e94\u7528\u79c1\u6709\u6301\u7eed\u8ba1\u6570\u7b97\u6cd5\u83b7\u5f97\u6700\u4f18\u8bef\u5dee\u754c\u9650\u5e26\u6765\u4e86\u6311\u6218\u3002", "method": "\u7814\u7a76\u5dee\u5f02\u6d41\u76f8\u5173\u7684\u2113p\u654f\u611f\u5ea6\u5411\u91cf\u5e76\u5206\u79bb\u5176\u7279\u6027\uff0c\u901a\u8fc7\u7d27\u5bc6\u5206\u6790\u8ba1\u6570\u77e9\u9635\u7684\u5df2\u77e5\u5206\u89e3\u673a\u5236\uff0c\u5229\u7528\u5177\u6709\u7279\u5b9a\u7279\u6027\u7684\u654f\u611f\u5ea6\u5411\u91cf\u96c6\u7684\u6700\u5148\u8fdb\u5206\u89e3\u65b9\u6cd5\u3002", "result": "\u6539\u8fdb\u4e86\u8ba1\u6570\u4e0d\u540c\u5143\u7d20\u3001\u4f30\u8ba1\u5ea6\u76f4\u65b9\u56fe\u548c\u4f30\u8ba1\u4e09\u89d2\u5f62\u8ba1\u6570\uff08\u5728\u7565\u5fae\u653e\u5bbd\u7684\u9690\u79c1\u6a21\u578b\u4e0b\uff09\u7684\u8bef\u5dee\u754c\u9650\uff0c\u4e3a\u6d41\u5f0f\u8bbe\u7f6e\u4e2d\u7684\u79c1\u6709\u6301\u7eed\u57fa\u6570\u4f30\u8ba1\u63d0\u4f9b\u4e86\u901a\u7528\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u5206\u6790\u5dee\u5f02\u6d41\u7684\u654f\u611f\u5ea6\u5411\u91cf\u7279\u6027\uff0c\u8be5\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u6d41\u5f0f\u5dee\u5206\u9690\u79c1\u7edf\u8ba1\u7684\u51c6\u786e\u6027\uff0c\u5728\u5927\u8303\u56f4\u53c2\u6570\u4e0b\u4e3a\u57fa\u6570\u4f30\u8ba1\u95ee\u9898\u63d0\u4f9b\u4e86\u5b9e\u8d28\u6027\u6539\u8fdb\u3002"}}
{"id": "2601.01718", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01718", "abs": "https://arxiv.org/abs/2601.01718", "authors": ["YuanLab. ai", ":", "Shawn Wu", "Sean Wang", "Louie Li", "Darcy Chen", "Allen Wang", "Jiangang Luo", "Xudong Zhao", "Joseph Shen", "Gawain Ma", "Jasper Jia", "Marcus Mao", "Claire Wang", "Hunter He", "Carol Wang", "Zera Zhang", "Jason Wang", "Chonly Shen", "Leo Zhang", "Logan Chen", "Qasim Meng", "James Gong", "Danied Zhao", "Penn Zheng", "Owen Zhu", "Tong Yu"], "title": "Yuan3.0 Flash: An Open Multimodal Large Language Model for Enterprise Applications", "comment": null, "summary": "We introduce Yuan3.0 Flash, an open-source Mixture-of-Experts (MoE) MultiModal Large Language Model featuring 3.7B activated parameters and 40B total parameters, specifically designed to enhance performance on enterprise-oriented tasks while maintaining competitive capabilities on general-purpose tasks. To address the overthinking phenomenon commonly observed in Large Reasoning Models (LRMs), we propose Reflection-aware Adaptive Policy Optimization (RAPO), a novel RL training algorithm that effectively regulates overthinking behaviors. In enterprise-oriented tasks such as retrieval-augmented generation (RAG), complex table understanding, and summarization, Yuan3.0 Flash consistently achieves superior performance. Moreover, it also demonstrates strong reasoning capabilities in domains such as mathematics, science, etc., attaining accuracy comparable to frontier model while requiring only approximately 1/4 to 1/2 of the average tokens. Yuan3.0 Flash has been fully open-sourced to facilitate further research and real-world deployment: https://github.com/Yuan-lab-LLM/Yuan3.0.", "AI": {"tldr": "Yuan3.0 Flash\u662f\u4e00\u4e2a\u5f00\u6e90\u7684MoE\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5177\u670937\u4ebf\u6fc0\u6d3b\u53c2\u6570\u548c400\u4ebf\u603b\u53c2\u6570\uff0c\u4e13\u95e8\u4e3a\u4f01\u4e1a\u4efb\u52a1\u4f18\u5316\uff0c\u540c\u65f6\u4fdd\u6301\u901a\u7528\u4efb\u52a1\u7ade\u4e89\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u89e3\u51b3\u5927\u63a8\u7406\u6a21\u578b\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\u7684RAPO\u7b97\u6cd5\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5927\u578b\u63a8\u7406\u6a21\u578b\u4e2d\u5e38\u89c1\u7684\"\u8fc7\u5ea6\u601d\u8003\"\u73b0\u8c61\uff0c\u5e76\u4e3a\u4f01\u4e1a\u5bfc\u5411\u7684\u4efb\u52a1\u63d0\u4f9b\u9ad8\u6027\u80fd\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u6301\u5f00\u6e90\u4ee5\u4fc3\u8fdb\u7814\u7a76\u548c\u5b9e\u9645\u90e8\u7f72\u3002", "method": "\u63d0\u51fa\u4e86Yuan3.0 Flash\u6a21\u578b\uff0c\u91c7\u7528\u6df7\u5408\u4e13\u5bb6\u67b6\u6784\uff0c\u5305\u542b37\u4ebf\u6fc0\u6d3b\u53c2\u6570\u548c400\u4ebf\u603b\u53c2\u6570\u3002\u4e3a\u89e3\u51b3\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u53cd\u5c04\u611f\u77e5\u81ea\u9002\u5e94\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\uff0c\u6709\u6548\u8c03\u8282\u6a21\u578b\u7684\u8fc7\u5ea6\u601d\u8003\u884c\u4e3a\u3002", "result": "\u5728\u4f01\u4e1a\u5bfc\u5411\u4efb\u52a1\u5982\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u3001\u590d\u6742\u8868\u683c\u7406\u89e3\u548c\u6458\u8981\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002\u5728\u6570\u5b66\u3001\u79d1\u5b66\u7b49\u9886\u57df\u7684\u63a8\u7406\u80fd\u529b\u4e5f\u5f88\u5f3a\uff0c\u8fbe\u5230\u524d\u6cbf\u6a21\u578b\u76f8\u5f53\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u4ec5\u9700\u7ea61/4\u52301/2\u7684\u5e73\u5747token\u6570\u3002", "conclusion": "Yuan3.0 Flash\u662f\u4e00\u4e2a\u9ad8\u6027\u80fd\u7684\u5f00\u6e90\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4e13\u95e8\u4e3a\u4f01\u4e1a\u4efb\u52a1\u4f18\u5316\uff0c\u901a\u8fc7RAPO\u7b97\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u9886\u57df\u8868\u73b0\u51fa\u8272\u4e14\u6548\u7387\u66f4\u9ad8\uff0c\u5df2\u5b8c\u5168\u5f00\u6e90\u4f9b\u7814\u7a76\u548c\u90e8\u7f72\u3002"}}
{"id": "2601.01743", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01743", "abs": "https://arxiv.org/abs/2601.01743", "authors": ["Bin Xu"], "title": "AI Agent Systems: Architectures, Applications, and Evaluation", "comment": null, "summary": "AI agents -- systems that combine foundation models with reasoning, planning, memory, and tool use -- are rapidly becoming a practical interface between natural-language intent and real-world computation. This survey synthesizes the emerging landscape of AI agent architectures across: (i) deliberation and reasoning (e.g., chain-of-thought-style decomposition, self-reflection and verification, and constraint-aware decision making), (ii) planning and control (from reactive policies to hierarchical and multi-step planners), and (iii) tool calling and environment interaction (retrieval, code execution, APIs, and multimodal perception). We organize prior work into a unified taxonomy spanning agent components (policy/LLM core, memory, world models, planners, tool routers, and critics), orchestration patterns (single-agent vs.\\ multi-agent; centralized vs.\\ decentralized coordination), and deployment settings (offline analysis vs.\\ online interactive assistance; safety-critical vs.\\ open-ended tasks). We discuss key design trade-offs -- latency vs.\\ accuracy, autonomy vs.\\ controllability, and capability vs.\\ reliability -- and highlight how evaluation is complicated by non-determinism, long-horizon credit assignment, tool and environment variability, and hidden costs such as retries and context growth. Finally, we summarize measurement and benchmarking practices (task suites, human preference and utility metrics, success under constraints, robustness and security) and identify open challenges including verification and guardrails for tool actions, scalable memory and context management, interpretability of agent decisions, and reproducible evaluation under realistic workloads.", "AI": {"tldr": "\u672c\u6587\u5bf9AI\u667a\u80fd\u4f53\u67b6\u6784\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u6db5\u76d6\u63a8\u7406\u3001\u89c4\u5212\u3001\u5de5\u5177\u8c03\u7528\u7b49\u6838\u5fc3\u7ec4\u4ef6\uff0c\u63d0\u51fa\u4e86\u7edf\u4e00\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u5e76\u8ba8\u8bba\u4e86\u8bbe\u8ba1\u6743\u8861\u3001\u8bc4\u4f30\u6311\u6218\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "AI\u667a\u80fd\u4f53\uff08\u7ed3\u5408\u57fa\u7840\u6a21\u578b\u4e0e\u63a8\u7406\u3001\u89c4\u5212\u3001\u8bb0\u5fc6\u548c\u5de5\u5177\u4f7f\u7528\u7684\u7cfb\u7edf\uff09\u6b63\u6210\u4e3a\u8fde\u63a5\u81ea\u7136\u8bed\u8a00\u610f\u56fe\u4e0e\u73b0\u5b9e\u4e16\u754c\u8ba1\u7b97\u7684\u5b9e\u9645\u63a5\u53e3\u3002\u968f\u7740\u8be5\u9886\u57df\u5feb\u901f\u53d1\u5c55\uff0c\u9700\u8981\u5bf9\u5404\u79cd\u667a\u80fd\u4f53\u67b6\u6784\u8fdb\u884c\u7cfb\u7edf\u6027\u68b3\u7406\u548c\u5206\u7c7b\uff0c\u4ee5\u6307\u5bfc\u7814\u7a76\u548c\u5e94\u7528\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5c06\u73b0\u6709\u5de5\u4f5c\u7ec4\u7ec7\u6210\u7edf\u4e00\u7684\u5206\u7c7b\u4f53\u7cfb\uff1a1\uff09\u667a\u80fd\u4f53\u7ec4\u4ef6\uff08\u7b56\u7565/LLM\u6838\u5fc3\u3001\u8bb0\u5fc6\u3001\u4e16\u754c\u6a21\u578b\u3001\u89c4\u5212\u5668\u3001\u5de5\u5177\u8def\u7531\u5668\u3001\u6279\u8bc4\u5668\uff09\uff1b2\uff09\u7f16\u6392\u6a21\u5f0f\uff08\u5355\u667a\u80fd\u4f53vs\u591a\u667a\u80fd\u4f53\uff0c\u96c6\u4e2d\u5f0fvs\u53bb\u4e2d\u5fc3\u5316\u534f\u8c03\uff09\uff1b3\uff09\u90e8\u7f72\u8bbe\u7f6e\uff08\u79bb\u7ebf\u5206\u6790vs\u5728\u7ebf\u4ea4\u4e92\u8f85\u52a9\uff0c\u5b89\u5168\u5173\u952evs\u5f00\u653e\u4efb\u52a1\uff09\u3002", "result": "\u63d0\u51fa\u4e86\u5168\u9762\u7684AI\u667a\u80fd\u4f53\u67b6\u6784\u5206\u7c7b\u6846\u67b6\uff0c\u8bc6\u522b\u4e86\u5173\u952e\u8bbe\u8ba1\u6743\u8861\uff08\u5ef6\u8fdfvs\u51c6\u786e\u6027\u3001\u81ea\u4e3b\u6027vs\u53ef\u63a7\u6027\u3001\u80fd\u529bvs\u53ef\u9760\u6027\uff09\uff0c\u5206\u6790\u4e86\u8bc4\u4f30\u9762\u4e34\u7684\u6311\u6218\uff08\u975e\u786e\u5b9a\u6027\u3001\u957f\u671f\u4fe1\u7528\u5206\u914d\u3001\u5de5\u5177\u548c\u73af\u5883\u53d8\u5f02\u6027\u3001\u9690\u85cf\u6210\u672c\uff09\uff0c\u603b\u7ed3\u4e86\u6d4b\u91cf\u548c\u57fa\u51c6\u6d4b\u8bd5\u5b9e\u8df5\u3002", "conclusion": "AI\u667a\u80fd\u4f53\u67b6\u6784\u7814\u7a76\u5df2\u5f62\u6210\u4e30\u5bcc\u4f53\u7cfb\uff0c\u4f46\u4ecd\u9762\u4e34\u9a8c\u8bc1\u548c\u62a4\u680f\u3001\u53ef\u6269\u5c55\u5185\u5b58\u548c\u4e0a\u4e0b\u6587\u7ba1\u7406\u3001\u51b3\u7b56\u53ef\u89e3\u91ca\u6027\u3001\u73b0\u5b9e\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u7684\u53ef\u91cd\u590d\u8bc4\u4f30\u7b49\u5f00\u653e\u6311\u6218\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u89e3\u51b3\u3002"}}
{"id": "2601.01774", "categories": ["cs.AI", "cs.CE", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.01774", "abs": "https://arxiv.org/abs/2601.01774", "authors": ["Sai Varun Kodathala", "Rakesh Vunnam"], "title": "Can Large Language Models Solve Engineering Equations? A Systematic Comparison of Direct Prediction and Solver-Assisted Approaches", "comment": "14 pages", "summary": "Transcendental equations requiring iterative numerical solution pervade engineering practice, from fluid mechanics friction factor calculations to orbital position determination. We systematically evaluate whether Large Language Models can solve these equations through direct numerical prediction or whether a hybrid architecture combining LLM symbolic manipulation with classical iterative solvers proves more effective. Testing six state-of-the-art models (GPT-5.1, GPT-5.2, Gemini-3-Flash, Gemini-2.5-Lite, Claude-Sonnet-4.5, Claude-Opus-4.5) on 100 problems spanning seven engineering domains, we compare direct prediction against solver-assisted computation where LLMs formulate governing equations and provide initial conditions while Newton-Raphson iteration performs numerical solution. Direct prediction yields mean relative errors of 0.765 to 1.262 across models, while solver-assisted computation achieves 0.225 to 0.301, representing error reductions of 67.9% to 81.8%. Domain-specific analysis reveals dramatic improvements in Electronics (93.1%) due to exponential equation sensitivity, contrasted with modest gains in Fluid Mechanics (7.2%) where LLMs exhibit effective pattern recognition. These findings establish that contemporary LLMs excel at symbolic manipulation and domain knowledge retrieval but struggle with precision-critical iterative arithmetic, suggesting their optimal deployment as intelligent interfaces to classical numerical solvers rather than standalone computational engines.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u6c42\u89e3\u8d85\u8d8a\u65b9\u7a0b\u65b9\u9762\u7684\u80fd\u529b\uff0c\u6bd4\u8f83\u4e86\u76f4\u63a5\u6570\u503c\u9884\u6d4b\u4e0e\u7ed3\u5408\u4f20\u7edf\u8fed\u4ee3\u6c42\u89e3\u5668\u7684\u6df7\u5408\u67b6\u6784\u7684\u6548\u679c\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u6df7\u5408\u65b9\u6cd5\uff08LLM\u8fdb\u884c\u7b26\u53f7\u64cd\u4f5c+\u725b\u987f-\u62c9\u5f17\u68ee\u8fed\u4ee3\uff09\u6bd4LLM\u76f4\u63a5\u9884\u6d4b\u7684\u8bef\u5dee\u964d\u4f4e\u4e8667.9%\u523081.8%\uff0c\u8868\u660eLLM\u66f4\u9002\u5408\u4f5c\u4e3a\u4f20\u7edf\u6570\u503c\u6c42\u89e3\u5668\u7684\u667a\u80fd\u63a5\u53e3\u800c\u975e\u72ec\u7acb\u8ba1\u7b97\u5f15\u64ce\u3002", "motivation": "\u8d85\u8d8a\u65b9\u7a0b\u5728\u5de5\u7a0b\u5b9e\u8df5\u4e2d\u5e7f\u6cdb\u5b58\u5728\uff08\u5982\u6d41\u4f53\u529b\u5b66\u6469\u64e6\u7cfb\u6570\u8ba1\u7b97\u3001\u8f68\u9053\u4f4d\u7f6e\u786e\u5b9a\u7b49\uff09\uff0c\u9700\u8981\u8fed\u4ee3\u6570\u503c\u6c42\u89e3\u3002\u7814\u7a76\u65e8\u5728\u8bc4\u4f30LLM\u662f\u5426\u80fd\u76f4\u63a5\u6c42\u89e3\u8fd9\u4e9b\u65b9\u7a0b\uff0c\u6216\u8005\u7ed3\u5408\u4f20\u7edf\u6c42\u89e3\u5668\u7684\u6df7\u5408\u67b6\u6784\u662f\u5426\u66f4\u6709\u6548\uff0c\u4ee5\u786e\u5b9aLLM\u5728\u5de5\u7a0b\u8ba1\u7b97\u4e2d\u7684\u6700\u4f73\u5e94\u7528\u65b9\u5f0f\u3002", "method": "\u7814\u7a76\u6d4b\u8bd5\u4e866\u4e2a\u6700\u5148\u8fdb\u7684LLM\u6a21\u578b\uff08GPT-5.1\u3001GPT-5.2\u3001Gemini-3-Flash\u3001Gemini-2.5-Lite\u3001Claude-Sonnet-4.5\u3001Claude-Opus-4.5\uff09\uff0c\u57287\u4e2a\u5de5\u7a0b\u9886\u57df\u7684100\u4e2a\u95ee\u9898\u4e0a\u8fdb\u884c\u6bd4\u8f83\u3002\u8bc4\u4f30\u4e86\u4e24\u79cd\u65b9\u6cd5\uff1a1\uff09LLM\u76f4\u63a5\u6570\u503c\u9884\u6d4b\uff1b2\uff09\u6df7\u5408\u67b6\u6784\uff08LLM\u5236\u5b9a\u63a7\u5236\u65b9\u7a0b\u5e76\u63d0\u4f9b\u521d\u59cb\u6761\u4ef6\uff0c\u725b\u987f-\u62c9\u5f17\u68ee\u8fed\u4ee3\u8fdb\u884c\u6570\u503c\u6c42\u89e3\uff09\u3002", "result": "\u76f4\u63a5\u9884\u6d4b\u7684\u5e73\u5747\u76f8\u5bf9\u8bef\u5dee\u4e3a0.765\u52301.262\uff0c\u800c\u6c42\u89e3\u5668\u8f85\u52a9\u8ba1\u7b97\u7684\u5e73\u5747\u76f8\u5bf9\u8bef\u5dee\u4e3a0.225\u52300.301\uff0c\u8bef\u5dee\u964d\u4f4e\u4e8667.9%\u523081.8%\u3002\u9886\u57df\u5206\u6790\u663e\u793a\uff0c\u7535\u5b50\u5b66\u9886\u57df\u6539\u8fdb\u6700\u5927\uff0893.1%\uff09\uff0c\u56e0\u4e3a\u6307\u6570\u65b9\u7a0b\u5bf9\u7cbe\u5ea6\u654f\u611f\uff1b\u6d41\u4f53\u529b\u5b66\u9886\u57df\u6539\u8fdb\u6700\u5c0f\uff087.2%\uff09\uff0cLLM\u5728\u8be5\u9886\u57df\u8868\u73b0\u51fa\u6709\u6548\u7684\u6a21\u5f0f\u8bc6\u522b\u80fd\u529b\u3002", "conclusion": "\u5f53\u4ee3LLM\u64c5\u957f\u7b26\u53f7\u64cd\u4f5c\u548c\u9886\u57df\u77e5\u8bc6\u68c0\u7d22\uff0c\u4f46\u5728\u7cbe\u5ea6\u5173\u952e\u7684\u8fed\u4ee3\u7b97\u672f\u8ba1\u7b97\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002LLM\u7684\u6700\u4f73\u90e8\u7f72\u65b9\u5f0f\u662f\u4f5c\u4e3a\u4f20\u7edf\u6570\u503c\u6c42\u89e3\u5668\u7684\u667a\u80fd\u63a5\u53e3\uff0c\u800c\u4e0d\u662f\u72ec\u7acb\u7684\u8ba1\u7b97\u5f15\u64ce\u3002\u8fd9\u4e00\u53d1\u73b0\u4e3a\u5de5\u7a0b\u8ba1\u7b97\u4e2dLLM\u7684\u6709\u6548\u5e94\u7528\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2601.01816", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01816", "abs": "https://arxiv.org/abs/2601.01816", "authors": ["Chris Duffey"], "title": "Admissibility Alignment", "comment": "24 pages, 2 figures, 2 tables.. Decision-theoretic alignment under uncertainty", "summary": "This paper introduces Admissibility Alignment: a reframing of AI alignment as a property of admissible action and decision selection over distributions of outcomes under uncertainty, evaluated through the behavior of candidate policies. We present MAP-AI (Monte Carlo Alignment for Policy) as a canonical system architecture for operationalizing admissibility alignment, formalizing alignment as a probabilistic, decision-theoretic property rather than a static or binary condition.\n  MAP-AI, a new control-plane system architecture for aligned decision-making under uncertainty, enforces alignment through Monte Carlo estimation of outcome distributions and admissibility-controlled policy selection rather than static model-level constraints. The framework evaluates decision policies across ensembles of plausible futures, explicitly modeling uncertainty, intervention effects, value ambiguity, and governance constraints. Alignment is assessed through distributional properties including expected utility, variance, tail risk, and probability of misalignment rather than accuracy or ranking performance. This approach distinguishes probabilistic prediction from decision reasoning under uncertainty and provides an executable methodology for evaluating trust and alignment in enterprise and institutional AI systems. The result is a practical foundation for governing AI systems whose impact is determined not by individual forecasts, but by policy behavior across distributions and tail events. Finally, we show how distributional alignment evaluation can be integrated into decision-making itself, yielding an admissibility-controlled action selection mechanism that alters policy behavior under uncertainty without retraining or modifying underlying models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\"\u53ef\u5bb9\u8bb8\u5bf9\u9f50\"\u6982\u5ff5\uff0c\u5c06AI\u5bf9\u9f50\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u5bf9\u7ed3\u679c\u5206\u5e03\u7684\u53ef\u5bb9\u8bb8\u884c\u52a8\u548c\u51b3\u7b56\u9009\u62e9\u5c5e\u6027\uff0c\u5e76\u901a\u8fc7MAP-AI\u7cfb\u7edf\u67b6\u6784\u5b9e\u73b0\u6982\u7387\u5316\u3001\u51b3\u7b56\u7406\u8bba\u5316\u7684\u5bf9\u9f50\u8bc4\u4f30\u3002", "motivation": "\u4f20\u7edfAI\u5bf9\u9f50\u65b9\u6cd5\u901a\u5e38\u57fa\u4e8e\u9759\u6001\u6216\u4e8c\u5143\u6761\u4ef6\uff0c\u96be\u4ee5\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u3001\u5e72\u9884\u6548\u5e94\u3001\u4ef7\u503c\u6a21\u7cca\u6027\u548c\u6cbb\u7406\u7ea6\u675f\u3002\u9700\u8981\u4e00\u79cd\u65b0\u7684\u6846\u67b6\u6765\u8bc4\u4f30AI\u7cfb\u7edf\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u51b3\u7b56\u884c\u4e3a\uff0c\u7279\u522b\u662f\u5728\u5206\u5e03\u548c\u5c3e\u90e8\u4e8b\u4ef6\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51faMAP-AI\uff08\u8499\u7279\u5361\u6d1b\u5bf9\u9f50\u7b56\u7565\uff09\u7cfb\u7edf\u67b6\u6784\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u7ed3\u679c\u5206\u5e03\u548c\u53ef\u5bb9\u8bb8\u63a7\u5236\u7b56\u7565\u9009\u62e9\u6765\u5b9e\u65bd\u5bf9\u9f50\u3002\u8be5\u6846\u67b6\u8bc4\u4f30\u51b3\u7b56\u7b56\u7565\u5728\u591a\u4e2a\u53ef\u80fd\u672a\u6765\u573a\u666f\u4e2d\u7684\u8868\u73b0\uff0c\u663e\u5f0f\u5efa\u6a21\u4e0d\u786e\u5b9a\u6027\u3001\u5e72\u9884\u6548\u5e94\u3001\u4ef7\u503c\u6a21\u7cca\u6027\u548c\u6cbb\u7406\u7ea6\u675f\u3002", "result": "\u5bf9\u9f50\u8bc4\u4f30\u57fa\u4e8e\u5206\u5e03\u5c5e\u6027\uff08\u5305\u62ec\u671f\u671b\u6548\u7528\u3001\u65b9\u5dee\u3001\u5c3e\u90e8\u98ce\u9669\u548c\u4e0d\u5bf9\u9f50\u6982\u7387\uff09\uff0c\u800c\u975e\u51c6\u786e\u6027\u6216\u6392\u540d\u6027\u80fd\u3002\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6267\u884c\u7684\u65b9\u6cd5\u8bba\u6765\u8bc4\u4f30\u4f01\u4e1a\u7ea7\u548c\u673a\u6784\u7ea7AI\u7cfb\u7edf\u7684\u4fe1\u4efb\u5ea6\u548c\u5bf9\u9f50\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6cbb\u7406AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u57fa\u7840\uff0c\u5176\u5f71\u54cd\u7531\u7b56\u7565\u5728\u5206\u5e03\u548c\u5c3e\u90e8\u4e8b\u4ef6\u4e2d\u7684\u884c\u4e3a\u51b3\u5b9a\uff0c\u800c\u975e\u5355\u4e2a\u9884\u6d4b\u3002\u53ef\u5bb9\u8bb8\u63a7\u5236\u884c\u52a8\u9009\u62e9\u673a\u5236\u53ef\u4ee5\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u6216\u4fee\u6539\u5e95\u5c42\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\uff0c\u6539\u53d8\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u7b56\u7565\u884c\u4e3a\u3002"}}
{"id": "2601.01836", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.01836", "abs": "https://arxiv.org/abs/2601.01836", "authors": ["Dasol Choi", "DongGeon Lee", "Brigitta Jesica Kartono", "Helena Berndt", "Taeyoun Kwon", "Joonwon Jang", "Haon Park", "Hwanjo Yu", "Minsuk Kahng"], "title": "COMPASS: A Framework for Evaluating Organization-Specific Policy Alignment in LLMs", "comment": null, "summary": "As large language models are deployed in high-stakes enterprise applications, from healthcare to finance, ensuring adherence to organization-specific policies has become essential. Yet existing safety evaluations focus exclusively on universal harms. We present COMPASS (Company/Organization Policy Alignment Assessment), the first systematic framework for evaluating whether LLMs comply with organizational allowlist and denylist policies. We apply COMPASS to eight diverse industry scenarios, generating and validating 5,920 queries that test both routine compliance and adversarial robustness through strategically designed edge cases. Evaluating seven state-of-the-art models, we uncover a fundamental asymmetry: models reliably handle legitimate requests (>95% accuracy) but catastrophically fail at enforcing prohibitions, refusing only 13-40% of adversarial denylist violations. These results demonstrate that current LLMs lack the robustness required for policy-critical deployments, establishing COMPASS as an essential evaluation framework for organizational AI safety.", "AI": {"tldr": "COMPASS\u662f\u9996\u4e2a\u8bc4\u4f30LLM\u662f\u5426\u7b26\u5408\u7ec4\u7ec7\u5141\u8bb8/\u7981\u6b62\u5217\u8868\u653f\u7b56\u7684\u7cfb\u7edf\u6846\u67b6\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u5904\u7406\u5408\u6cd5\u8bf7\u6c42\u65f6\u8868\u73b0\u826f\u597d\uff08>95%\u51c6\u786e\u7387\uff09\uff0c\u4f46\u5728\u6267\u884c\u7981\u4ee4\u65f6\u4e25\u91cd\u5931\u8d25\uff08\u4ec5\u62d2\u7edd13-40%\u7684\u8fdd\u89c4\u8bf7\u6c42\uff09\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u3001\u91d1\u878d\u7b49\u9ad8\u98ce\u9669\u4f01\u4e1a\u5e94\u7528\u4e2d\u7684\u90e8\u7f72\uff0c\u786e\u4fdd\u6a21\u578b\u9075\u5b88\u7ec4\u7ec7\u7279\u5b9a\u653f\u7b56\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\u73b0\u6709\u7684\u5b89\u5168\u8bc4\u4f30\u4ec5\u5173\u6ce8\u901a\u7528\u5371\u5bb3\uff0c\u7f3a\u4e4f\u9488\u5bf9\u7ec4\u7ec7\u653f\u7b56\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u5f00\u53d1COMPASS\u6846\u67b6\uff0c\u5e94\u7528\u4e8e\u516b\u4e2a\u4e0d\u540c\u884c\u4e1a\u573a\u666f\uff0c\u751f\u6210\u5e76\u9a8c\u8bc15,920\u4e2a\u67e5\u8be2\uff0c\u6d4b\u8bd5\u5e38\u89c4\u5408\u89c4\u6027\u548c\u901a\u8fc7\u7b56\u7565\u6027\u8bbe\u8ba1\u7684\u8fb9\u7f18\u6848\u4f8b\u6d4b\u8bd5\u5bf9\u6297\u9c81\u68d2\u6027\u3002\u8bc4\u4f30\u4e86\u4e03\u4e2a\u6700\u5148\u8fdb\u7684\u6a21\u578b\u3002", "result": "\u53d1\u73b0\u57fa\u672c\u4e0d\u5bf9\u79f0\u6027\uff1a\u6a21\u578b\u53ef\u9760\u5904\u7406\u5408\u6cd5\u8bf7\u6c42\uff08>95%\u51c6\u786e\u7387\uff09\uff0c\u4f46\u5728\u6267\u884c\u7981\u4ee4\u65f6\u707e\u96be\u6027\u5931\u8d25\uff0c\u4ec5\u62d2\u7edd13-40%\u7684\u5bf9\u6297\u6027\u7981\u6b62\u5217\u8868\u8fdd\u89c4\u8bf7\u6c42\u3002", "conclusion": "\u5f53\u524dLLM\u7f3a\u4e4f\u653f\u7b56\u5173\u952e\u90e8\u7f72\u6240\u9700\u7684\u9c81\u68d2\u6027\uff0cCOMPESS\u4f5c\u4e3a\u7ec4\u7ec7AI\u5b89\u5168\u7684\u91cd\u8981\u8bc4\u4f30\u6846\u67b6\u88ab\u786e\u7acb\u3002"}}
{"id": "2601.01844", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01844", "abs": "https://arxiv.org/abs/2601.01844", "authors": ["Udiptaman Das", "Krishnasai B. Atmakuri", "Duy Ho", "Chi Lee", "Yugyung Lee"], "title": "Clinical Knowledge Graph Construction and Evaluation with Multi-LLMs via Retrieval-Augmented Generation", "comment": "13 pages, 5 tables, 4 figures", "summary": "Large language models (LLMs) offer new opportunities for constructing knowledge graphs (KGs) from unstructured clinical narratives. However, existing approaches often rely on structured inputs and lack robust validation of factual accuracy and semantic consistency, limitations that are especially problematic in oncology. We introduce an end-to-end framework for clinical KG construction and evaluation directly from free text using multi-agent prompting and a schema-constrained Retrieval-Augmented Generation (KG-RAG) strategy. Our pipeline integrates (1) prompt-driven entity, attribute, and relation extraction; (2) entropy-based uncertainty scoring; (3) ontology-aligned RDF/OWL schema generation; and (4) multi-LLM consensus validation for hallucination detection and semantic refinement. Beyond static graph construction, the framework supports continuous refinement and self-supervised evaluation, enabling iterative improvement of graph quality. Applied to two oncology cohorts (PDAC and BRCA), our method produces interpretable, SPARQL-compatible, and clinically grounded knowledge graphs without relying on gold-standard annotations. Experimental results demonstrate consistent gains in precision, relevance, and ontology compliance over baseline methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u63d0\u793a\u548c\u6a21\u5f0f\u7ea6\u675f\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08KG-RAG\uff09\u7684\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u81ea\u7531\u6587\u672c\u6784\u5efa\u4e34\u5e8a\u77e5\u8bc6\u56fe\u8c31\uff0c\u7279\u522b\u9488\u5bf9\u80bf\u7624\u5b66\u9886\u57df\uff0c\u65e0\u9700\u4f9d\u8d56\u9ec4\u91d1\u6807\u51c6\u6807\u6ce8\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e3a\u4ece\u975e\u7ed3\u6784\u5316\u4e34\u5e8a\u53d9\u8ff0\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u63d0\u4f9b\u4e86\u65b0\u673a\u4f1a\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u7ed3\u6784\u5316\u8f93\u5165\uff0c\u7f3a\u4e4f\u5bf9\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u8bed\u4e49\u4e00\u81f4\u6027\u7684\u9c81\u68d2\u9a8c\u8bc1\uff0c\u8fd9\u5728\u80bf\u7624\u5b66\u9886\u57df\u5c24\u5176\u6210\u95ee\u9898\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u63d0\u793a\u548c\u6a21\u5f0f\u7ea6\u675f\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08KG-RAG\uff09\u7b56\u7565\uff0c\u5305\u62ec\uff1a(1) \u63d0\u793a\u9a71\u52a8\u7684\u5b9e\u4f53\u3001\u5c5e\u6027\u548c\u5173\u7cfb\u63d0\u53d6\uff1b(2) \u57fa\u4e8e\u71b5\u7684\u4e0d\u786e\u5b9a\u6027\u8bc4\u5206\uff1b(3) \u672c\u4f53\u5bf9\u9f50\u7684RDF/OWL\u6a21\u5f0f\u751f\u6210\uff1b(4) \u591aLLM\u5171\u8bc6\u9a8c\u8bc1\u7528\u4e8e\u5e7b\u89c9\u68c0\u6d4b\u548c\u8bed\u4e49\u7cbe\u70bc\u3002", "result": "\u5e94\u7528\u4e8e\u4e24\u4e2a\u80bf\u7624\u5b66\u961f\u5217\uff08PDAC\u548cBRCA\uff09\uff0c\u8be5\u65b9\u6cd5\u751f\u6210\u4e86\u53ef\u89e3\u91ca\u3001SPARQL\u517c\u5bb9\u4e14\u4e34\u5e8a\u57fa\u7840\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5728\u7cbe\u786e\u5ea6\u3001\u76f8\u5173\u6027\u548c\u672c\u4f53\u5408\u89c4\u6027\u65b9\u9762\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u6709\u6301\u7eed\u63d0\u5347\u3002", "conclusion": "\u8be5\u6846\u67b6\u652f\u6301\u8fde\u7eed\u7cbe\u70bc\u548c\u81ea\u76d1\u7763\u8bc4\u4f30\uff0c\u80fd\u591f\u8fed\u4ee3\u6539\u8fdb\u56fe\u8c31\u8d28\u91cf\uff0c\u4e3a\u4e34\u5e8a\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u63d0\u4f9b\u4e86\u65e0\u9700\u9ec4\u91d1\u6807\u51c6\u6807\u6ce8\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.01857", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01857", "abs": "https://arxiv.org/abs/2601.01857", "authors": ["Defei Xia", "Bingfeng Pi", "Shenbin Zhang", "Song Hua", "Yunfei Wei", "Lei Zuo"], "title": "Jenius Agent: Towards Experience-Driven Accuracy Optimization in Real-World Scenarios", "comment": null, "summary": "As agent systems powered by large language models (LLMs) advance, improving the task performance of an autonomous agent, especially in context understanding, tool usage, and response generation, has become increasingly critical. Although prior studies have advanced the overall design of LLM-based agents, systematic optimization of their internal reasoning and tool-use pipelines remains underexplored. This paper introduces an agent framework grounded in real-world practical experience, with three key innovations: (1) an adaptive prompt generation strategy that aligns with the agent's state and task goals to improve reliability and robustness; (2) a context-aware tool orchestration module that performs tool categorization, semantic retrieval, and adaptive invocation based on user intent and context; and (3) a layered memory mechanism that integrates session memory, task history, and external summaries to improve relevance and efficiency through dynamic summarization and compression. An end-to-end framework named Jenius-Agent has been integrated with three key optimizations, including tools based on the Model Context Protocol (MCP), file input/output (I/O), and execution feedback. The experiments show a 20 percent improvement in task accuracy, along with a reduced token cost, response latency, and invocation failures. The framework is already deployed in Jenius (https://www.jenius.cn), providing a lightweight and scalable solution for robust, protocol-compatible autonomous agents.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faJenius-Agent\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u63d0\u793a\u751f\u6210\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u5de5\u5177\u7f16\u6392\u548c\u5206\u5c42\u5185\u5b58\u673a\u5236\u4e09\u5927\u521b\u65b0\uff0c\u63d0\u5347LLM\u667a\u80fd\u4f53\u7684\u4efb\u52a1\u51c6\u786e\u738720%\uff0c\u540c\u65f6\u964d\u4f4etoken\u6210\u672c\u3001\u54cd\u5e94\u5ef6\u8fdf\u548c\u8c03\u7528\u5931\u8d25\u7387\u3002", "motivation": "\u968f\u7740\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u53d1\u5c55\uff0c\u63d0\u5347\u81ea\u4e3b\u667a\u80fd\u4f53\u5728\u4e0a\u4e0b\u6587\u7406\u89e3\u3001\u5de5\u5177\u4f7f\u7528\u548c\u54cd\u5e94\u751f\u6210\u65b9\u9762\u7684\u4efb\u52a1\u6027\u80fd\u53d8\u5f97\u65e5\u76ca\u91cd\u8981\u3002\u5c3d\u7ba1\u5148\u524d\u7814\u7a76\u63a8\u8fdb\u4e86LLM\u667a\u80fd\u4f53\u7684\u6574\u4f53\u8bbe\u8ba1\uff0c\u4f46\u5bf9\u5176\u5185\u90e8\u63a8\u7406\u548c\u5de5\u5177\u4f7f\u7528\u6d41\u7a0b\u7684\u7cfb\u7edf\u4f18\u5316\u4ecd\u5f85\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u771f\u5b9e\u4e16\u754c\u5b9e\u8df5\u7ecf\u9a8c\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u521b\u65b0\uff1a(1) \u81ea\u9002\u5e94\u63d0\u793a\u751f\u6210\u7b56\u7565\uff0c\u6839\u636e\u667a\u80fd\u4f53\u72b6\u6001\u548c\u4efb\u52a1\u76ee\u6807\u8c03\u6574\u63d0\u793a\u4ee5\u63d0\u9ad8\u53ef\u9760\u6027\u548c\u9c81\u68d2\u6027\uff1b(2) \u4e0a\u4e0b\u6587\u611f\u77e5\u5de5\u5177\u7f16\u6392\u6a21\u5757\uff0c\u57fa\u4e8e\u7528\u6237\u610f\u56fe\u548c\u4e0a\u4e0b\u6587\u8fdb\u884c\u5de5\u5177\u5206\u7c7b\u3001\u8bed\u4e49\u68c0\u7d22\u548c\u81ea\u9002\u5e94\u8c03\u7528\uff1b(3) \u5206\u5c42\u5185\u5b58\u673a\u5236\uff0c\u96c6\u6210\u4f1a\u8bdd\u5185\u5b58\u3001\u4efb\u52a1\u5386\u53f2\u548c\u5916\u90e8\u6458\u8981\uff0c\u901a\u8fc7\u52a8\u6001\u6458\u8981\u548c\u538b\u7f29\u63d0\u9ad8\u76f8\u5173\u6027\u548c\u6548\u7387\u3002\u6846\u67b6\u96c6\u6210\u4e86\u57fa\u4e8e\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u7684\u5de5\u5177\u3001\u6587\u4ef6\u8f93\u5165/\u8f93\u51fa\u548c\u6267\u884c\u53cd\u9988\u4e09\u5927\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u4efb\u52a1\u51c6\u786e\u7387\u63d0\u534720%\uff0c\u540c\u65f6\u964d\u4f4e\u4e86token\u6210\u672c\u3001\u54cd\u5e94\u5ef6\u8fdf\u548c\u8c03\u7528\u5931\u8d25\u7387\u3002\u8be5\u6846\u67b6\u5df2\u5728Jenius\u5e73\u53f0\u90e8\u7f72\uff0c\u4e3a\u9c81\u68d2\u3001\u534f\u8bae\u517c\u5bb9\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u8f7b\u91cf\u7ea7\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "Jenius-Agent\u6846\u67b6\u901a\u8fc7\u7cfb\u7edf\u4f18\u5316\u667a\u80fd\u4f53\u7684\u5185\u90e8\u63a8\u7406\u548c\u5de5\u5177\u4f7f\u7528\u6d41\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4efb\u52a1\u6027\u80fd\uff0c\u4e3a\u6784\u5efa\u53ef\u9760\u3001\u9ad8\u6548\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.01878", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.01878", "abs": "https://arxiv.org/abs/2601.01878", "authors": ["Farzan Karimi-Malekabadi", "Suhaib Abdurahman", "Zhivar Sourati", "Jackson Trager", "Morteza Dehghani"], "title": "Theory Trace Card: Theory-Driven Socio-Cognitive Evaluation of LLMs", "comment": null, "summary": "Socio-cognitive benchmarks for large language models (LLMs) often fail to predict real-world behavior, even when models achieve high benchmark scores. Prior work has attributed this evaluation-deployment gap to problems of measurement and validity. While these critiques are insightful, we argue that they overlook a more fundamental issue: many socio-cognitive evaluations proceed without an explicit theoretical specification of the target capability, leaving the assumptions linking task performance to competence implicit. Without this theoretical grounding, benchmarks that exercise only narrow subsets of a capability are routinely misinterpreted as evidence of broad competence: a gap that creates a systemic validity illusion by masking the failure to evaluate the capability's other essential dimensions. To address this gap, we make two contributions. First, we diagnose and formalize this theory gap as a foundational failure that undermines measurement and enables systematic overgeneralization of benchmark results. Second, we introduce the Theory Trace Card (TTC), a lightweight documentation artifact designed to accompany socio-cognitive evaluations, which explicitly outlines the theoretical basis of an evaluation, the components of the target capability it exercises, its operationalization, and its limitations. We argue that TTCs enhance the interpretability and reuse of socio-cognitive evaluations by making explicit the full validity chain, which links theory, task operationalization, scoring, and limitations, without modifying benchmarks or requiring agreement on a single theory.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u793e\u4f1a\u8ba4\u77e5\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u8bc4\u4f30-\u90e8\u7f72\u5dee\u8ddd\uff0c\u6839\u672c\u539f\u56e0\u5728\u4e8e\u7f3a\u4e4f\u660e\u786e\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5bfc\u81f4\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\u88ab\u8fc7\u5ea6\u6cdb\u5316\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u7406\u8bba\u8ffd\u8e2a\u5361\uff08TTC\uff09\u4f5c\u4e3a\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5f97\u5206\u5f88\u9ad8\uff0c\u4f46\u8fd9\u4e9b\u5206\u6570\u5f80\u5f80\u65e0\u6cd5\u9884\u6d4b\u771f\u5b9e\u4e16\u754c\u7684\u884c\u4e3a\u8868\u73b0\u3002\u73b0\u6709\u7814\u7a76\u5c06\u8fd9\u79cd\u8bc4\u4f30-\u90e8\u7f72\u5dee\u8ddd\u5f52\u56e0\u4e8e\u6d4b\u91cf\u548c\u6548\u5ea6\u95ee\u9898\uff0c\u4f46\u4f5c\u8005\u8ba4\u4e3a\u66f4\u6839\u672c\u7684\u95ee\u9898\u662f\u7f3a\u4e4f\u5bf9\u76ee\u6807\u80fd\u529b\u7684\u660e\u786e\u7406\u8bba\u754c\u5b9a\u3002", "method": "\u9996\u5148\u8bca\u65ad\u5e76\u5f62\u5f0f\u5316\u4e86\"\u7406\u8bba\u7f3a\u53e3\"\u95ee\u9898\uff0c\u7136\u540e\u63d0\u51fa\u4e86\u7406\u8bba\u8ffd\u8e2a\u5361\uff08TTC\uff09\u2014\u2014\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u6587\u6863\u5de5\u5177\uff0c\u7528\u4e8e\u660e\u786e\u8bb0\u5f55\u8bc4\u4f30\u7684\u7406\u8bba\u57fa\u7840\u3001\u76ee\u6807\u80fd\u529b\u7ec4\u4ef6\u3001\u64cd\u4f5c\u5316\u8fc7\u7a0b\u53ca\u5176\u5c40\u9650\u6027\u3002", "result": "TTC\u901a\u8fc7\u660e\u786e\u7406\u8bba\u3001\u4efb\u52a1\u64cd\u4f5c\u5316\u3001\u8bc4\u5206\u548c\u5c40\u9650\u6027\u4e4b\u95f4\u7684\u5b8c\u6574\u6548\u5ea6\u94fe\uff0c\u589e\u5f3a\u4e86\u793e\u4f1a\u8ba4\u77e5\u8bc4\u4f30\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u91cd\u7528\u6027\uff0c\u800c\u4e0d\u9700\u8981\u4fee\u6539\u57fa\u51c6\u6d4b\u8bd5\u6216\u8981\u6c42\u7edf\u4e00\u7684\u7406\u8bba\u5171\u8bc6\u3002", "conclusion": "\u7406\u8bba\u7f3a\u53e3\u662f\u5bfc\u81f4\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\u88ab\u7cfb\u7edf\u6027\u5730\u8fc7\u5ea6\u6cdb\u5316\u7684\u6839\u672c\u539f\u56e0\u3002TTC\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u660e\u786e\u8bb0\u5f55\u8bc4\u4f30\u7684\u7406\u8bba\u57fa\u7840\u6765\u589e\u5f3a\u8bc4\u4f30\u7684\u900f\u660e\u5ea6\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2601.01910", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01910", "abs": "https://arxiv.org/abs/2601.01910", "authors": ["Minh Hieu Ha", "Khanh Ly Ta", "Hung Phan", "Tung Doan", "Tung Dao", "Dao Tran", "Huynh Thi Thanh Binh"], "title": "MMP-A*: Multimodal Perception Enhanced Incremental Heuristic Search on Path Planning", "comment": null, "summary": "Autonomous path planning requires a synergy between global reasoning and geometric precision, especially in complex or cluttered environments. While classical A* is valued for its optimality, it incurs prohibitive computational and memory costs in large-scale scenarios. Recent attempts to mitigate these limitations by using Large Language Models for waypoint guidance remain insufficient, as they rely only on text-based reasoning without spatial grounding. As a result, such models often produce incorrect waypoints in topologically complex environments with dead ends, and lack the perceptual capacity to interpret ambiguous physical boundaries. These inconsistencies lead to costly corrective expansions and undermine the intended computational efficiency.\n  We introduce MMP-A*, a multimodal framework that integrates the spatial grounding capabilities of vision-language models with a novel adaptive decay mechanism. By anchoring high-level reasoning in physical geometry, the framework produces coherent waypoint guidance that addresses the limitations of text-only planners. The adaptive decay mechanism dynamically regulates the influence of uncertain waypoints within the heuristic, ensuring geometric validity while substantially reducing memory overhead. To evaluate robustness, we test the framework in challenging environments characterized by severe clutter and topological complexity. Experimental results show that MMP-A* achieves near-optimal trajectories with significantly reduced operational costs, demonstrating its potential as a perception-grounded and computationally efficient paradigm for autonomous navigation.", "AI": {"tldr": "MMP-A*\uff1a\u4e00\u4e2a\u7ed3\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7a7a\u95f4\u611f\u77e5\u80fd\u529b\u4e0e\u81ea\u9002\u5e94\u8870\u51cf\u673a\u5236\u7684\u591a\u6a21\u6001\u8def\u5f84\u89c4\u5212\u6846\u67b6\uff0c\u5728\u590d\u6742\u73af\u5883\u4e2d\u5b9e\u73b0\u8fd1\u4e4e\u6700\u4f18\u8f68\u8ff9\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u548c\u5185\u5b58\u5f00\u9500\u3002", "motivation": "\u4f20\u7edfA*\u7b97\u6cd5\u5728\u5927\u89c4\u6a21\u590d\u6742\u73af\u5883\u4e2d\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\u8fc7\u9ad8\uff0c\u800c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\u7f3a\u4e4f\u7a7a\u95f4\u611f\u77e5\u80fd\u529b\uff0c\u5728\u62d3\u6251\u590d\u6742\u73af\u5883\u4e2d\u5bb9\u6613\u4ea7\u751f\u9519\u8bef\u8def\u5f84\u70b9\uff0c\u65e0\u6cd5\u51c6\u786e\u7406\u89e3\u7269\u7406\u8fb9\u754c\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51faMMP-A*\u591a\u6a21\u6001\u6846\u67b6\uff1a1\uff09\u96c6\u6210\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u7a7a\u95f4\u611f\u77e5\u80fd\u529b\uff0c\u5c06\u9ad8\u5c42\u63a8\u7406\u951a\u5b9a\u5728\u7269\u7406\u51e0\u4f55\u4e2d\uff1b2\uff09\u5f15\u5165\u81ea\u9002\u5e94\u8870\u51cf\u673a\u5236\uff0c\u52a8\u6001\u8c03\u8282\u4e0d\u786e\u5b9a\u8def\u5f84\u70b9\u5728\u542f\u53d1\u5f0f\u51fd\u6570\u4e2d\u7684\u5f71\u54cd\uff0c\u786e\u4fdd\u51e0\u4f55\u6709\u6548\u6027\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u5185\u5b58\u5f00\u9500\u3002", "result": "\u5728\u5177\u6709\u4e25\u91cd\u6742\u4e71\u548c\u62d3\u6251\u590d\u6742\u6027\u7684\u6311\u6218\u6027\u73af\u5883\u4e2d\u6d4b\u8bd5\uff0cMMP-A*\u80fd\u591f\u751f\u6210\u8fd1\u4e4e\u6700\u4f18\u7684\u8f68\u8ff9\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u64cd\u4f5c\u6210\u672c\uff0c\u8bc1\u660e\u4e86\u5176\u4f5c\u4e3a\u611f\u77e5\u57fa\u7840\u548c\u8ba1\u7b97\u9ad8\u6548\u81ea\u4e3b\u5bfc\u822a\u8303\u5f0f\u7684\u6f5c\u529b\u3002", "conclusion": "MMP-A*\u901a\u8fc7\u7ed3\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u7a7a\u95f4\u611f\u77e5\u80fd\u529b\u548c\u81ea\u9002\u5e94\u8870\u51cf\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u7eaf\u6587\u672c\u89c4\u5212\u5668\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u81ea\u4e3b\u5bfc\u822a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u611f\u77e5\u57fa\u7840\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u8303\u5f0f\u3002"}}
{"id": "2601.01939", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01939", "abs": "https://arxiv.org/abs/2601.01939", "authors": ["Victor Sanchez", "Chris Reinke", "Ahamed Mohamed", "Xavier Alameda-Pineda"], "title": "OpenSocInt: A Multi-modal Training Environment for Human-Aware Social Navigation", "comment": null, "summary": "In this paper, we introduce OpenSocInt, an open-source software package providing a simulator for multi-modal social interactions and a modular architecture to train social agents. We described the software package and showcased its interest via an experimental protocol based on the task of social navigation. Our framework allows for exploring the use of different perceptual features, their encoding and fusion, as well as the use of different agents. The software is already publicly available under GPL at https://gitlab.inria.fr/robotlearn/OpenSocInt/.", "AI": {"tldr": "OpenSocInt\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u591a\u6a21\u6001\u793e\u4ea4\u4ea4\u4e92\u6a21\u62df\u5668\u8f6f\u4ef6\u5305\uff0c\u63d0\u4f9b\u6a21\u5757\u5316\u67b6\u6784\u8bad\u7ec3\u793e\u4ea4\u667a\u80fd\u4f53\uff0c\u5df2\u5e94\u7528\u4e8e\u793e\u4ea4\u5bfc\u822a\u4efb\u52a1\u5b9e\u9a8c", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u5f00\u6e90\u7684\u591a\u6a21\u6001\u793e\u4ea4\u4ea4\u4e92\u6a21\u62df\u6846\u67b6\uff0c\u652f\u6301\u7814\u7a76\u4e0d\u540c\u611f\u77e5\u7279\u5f81\u3001\u7f16\u7801\u878d\u5408\u65b9\u6cd5\u4ee5\u53ca\u5404\u79cd\u793e\u4ea4\u667a\u80fd\u4f53\u7684\u8bad\u7ec3", "method": "\u521b\u5efa\u4e86OpenSocInt\u5f00\u6e90\u8f6f\u4ef6\u5305\uff0c\u5305\u542b\u591a\u6a21\u6001\u793e\u4ea4\u4ea4\u4e92\u6a21\u62df\u5668\u548c\u6a21\u5757\u5316\u67b6\u6784\uff0c\u652f\u6301\u63a2\u7d22\u4e0d\u540c\u611f\u77e5\u7279\u5f81\u7684\u7f16\u7801\u4e0e\u878d\u5408\uff0c\u4ee5\u53ca\u4e0d\u540c\u7c7b\u578b\u667a\u80fd\u4f53\u7684\u8bad\u7ec3", "result": "\u8f6f\u4ef6\u5df2\u516c\u5f00\u53d1\u5e03\u5728GitLab\u4e0a\uff08GPL\u8bb8\u53ef\u8bc1\uff09\uff0c\u5e76\u901a\u8fc7\u793e\u4ea4\u5bfc\u822a\u4efb\u52a1\u7684\u5b9e\u9a8c\u534f\u8bae\u5c55\u793a\u4e86\u5176\u5e94\u7528\u4ef7\u503c", "conclusion": "OpenSocInt\u4e3a\u591a\u6a21\u6001\u793e\u4ea4\u4ea4\u4e92\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7075\u6d3b\u7684\u5f00\u6e90\u5e73\u53f0\uff0c\u652f\u6301\u63a2\u7d22\u4e0d\u540c\u611f\u77e5\u7279\u5f81\u548c\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u793e\u4ea4\u667a\u80fd\u4f53\u7684\u53d1\u5c55"}}
{"id": "2601.01976", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01976", "abs": "https://arxiv.org/abs/2601.01976", "authors": ["Yasmine Souissi", "Fabrice Boissier", "Nida Meddouri"], "title": "CNC-TP: Classifier Nominal Concept Based on Top-Pertinent Attributes", "comment": null, "summary": "Knowledge Discovery in Databases (KDD) aims to exploit the vast amounts of data generated daily across various domains of computer applications. Its objective is to extract hidden and meaningful knowledge from datasets through a structured process comprising several key steps: data selection, preprocessing, transformation, data mining, and visualization. Among the core data mining techniques are classification and clustering. Classification involves predicting the class of new instances using a classifier trained on labeled data. Several approaches have been proposed in the literature, including Decision Tree Induction, Bayesian classifiers, Nearest Neighbor search, Neural Networks, Support Vector Machines, and Formal Concept Analysis (FCA). The last one is recognized as an effective approach for interpretable and explainable learning. It is grounded in the mathematical structure of the concept lattice, which enables the generation of formal concepts and the discovery of hidden relationships among them. In this paper, we present a state-of-theart review of FCA-based classifiers. We explore various methods for computing closure operators from nominal data and introduce a novel approach for constructing a partial concept lattice that focuses on the most relevant concepts. Experimental results are provided to demonstrate the efficiency of the proposed method.", "AI": {"tldr": "\u672c\u6587\u5bf9\u57fa\u4e8e\u5f62\u5f0f\u6982\u5ff5\u5206\u6790\uff08FCA\uff09\u7684\u5206\u7c7b\u5668\u8fdb\u884c\u4e86\u7efc\u8ff0\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u540d\u4e49\u6570\u636e\u8ba1\u7b97\u95ed\u5305\u7b97\u5b50\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u6784\u5efa\u4e86\u4e13\u6ce8\u4e8e\u6700\u76f8\u5173\u6982\u5ff5\u7684\u90e8\u5206\u6982\u5ff5\u683c\u3002", "motivation": "\u77e5\u8bc6\u53d1\u73b0\uff08KDD\uff09\u65e8\u5728\u4ece\u6d77\u91cf\u6570\u636e\u4e2d\u63d0\u53d6\u9690\u85cf\u7684\u6709\u610f\u4e49\u77e5\u8bc6\uff0c\u5176\u4e2d\u5206\u7c7b\u662f\u6838\u5fc3\u6570\u636e\u6316\u6398\u6280\u672f\u4e4b\u4e00\u3002\u5f62\u5f0f\u6982\u5ff5\u5206\u6790\uff08FCA\uff09\u56e0\u5176\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u89e3\u91ca\u6027\u5b66\u4e60\u80fd\u529b\u800c\u53d7\u5230\u8ba4\u53ef\uff0c\u4f46\u9700\u8981\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u6765\u5904\u7406\u540d\u4e49\u6570\u636e\u548c\u6784\u5efa\u6982\u5ff5\u683c\u3002", "method": "1. \u5bf9\u57fa\u4e8eFCA\u7684\u5206\u7c7b\u5668\u8fdb\u884c\u6700\u65b0\u7efc\u8ff0\uff1b2. \u63a2\u7d22\u4ece\u540d\u4e49\u6570\u636e\u8ba1\u7b97\u95ed\u5305\u7b97\u5b50\u7684\u591a\u79cd\u65b9\u6cd5\uff1b3. \u63d0\u51fa\u6784\u5efa\u90e8\u5206\u6982\u5ff5\u683c\u7684\u65b0\u65b9\u6cd5\uff0c\u4e13\u6ce8\u4e8e\u6700\u76f8\u5173\u6982\u5ff5\u3002", "result": "\u63d0\u4f9b\u4e86\u5b9e\u9a8c\u7ed3\u679c\u6765\u8bc1\u660e\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u6548\u7387\uff0c\u5c55\u793a\u4e86\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u540d\u4e49\u6570\u636e\u5e76\u6784\u5efa\u90e8\u5206\u6982\u5ff5\u683c\uff0c\u4e3a\u57fa\u4e8eFCA\u7684\u5206\u7c7b\u5668\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u5b9e\u73b0\u65b9\u6848\uff0c\u589e\u5f3a\u4e86\u53ef\u89e3\u91ca\u6027\u5b66\u4e60\u7684\u80fd\u529b\u3002"}}
{"id": "2601.01982", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01982", "abs": "https://arxiv.org/abs/2601.01982", "authors": ["Noel Thomas"], "title": "ChaosBench-Logic: A Benchmark for Logical and Symbolic Reasoning on Chaotic Dynamical Systems", "comment": "7 pages, 0 figures , Accepted to AAAI-26 Bridge Program: Logical and Symbolic Reasoning in Language Models (camera-ready)", "summary": "Large language models (LLMs) excel at natural language tasks but remain brittle in domains requiring precise logical and symbolic reasoning. Chaotic dynamical systems provide an especially demanding test because chaos is deterministic yet often misinterpreted as randomness or complexity. We introduce ChaosBench-Logic, a benchmark that evaluates LLM reasoning across 30 diverse dynamical systems using a unified first-order logic (FOL) ontology. Each system is annotated with truth assignments for 11 semantic predicates, and 621 questions are generated across seven reasoning categories, including multi-hop implications, cross-system analogies, counterfactual reasoning, bias probes, and multi-turn dialogues. We define metrics for logical accuracy, implication consistency, dialogue coherence, and contradiction, and we release an open-source evaluation pipeline. Initial experiments show that frontier LLMs such as GPT-4, Claude 3.5 Sonnet, Gemini 2.5 Flash, and the open-source LLaMA-3 70B achieve 91-94% per-item accuracy, yet still score 0% on compositional items and exhibit fragile global coherence. Dialogue-level accuracy ranges from 53.1% (GPT-4 CoT) to 75.5% (LLaMA-3 zero-shot). ChaosBench-Logic provides a rigorous testbed for diagnosing such failures and a foundation for developing neuro-symbolic approaches that improve scientific reasoning in LLMs.", "AI": {"tldr": "ChaosBench-Logic\u662f\u4e00\u4e2a\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6df7\u6c8c\u52a8\u529b\u7cfb\u7edf\u4e2d\u903b\u8f91\u63a8\u7406\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b30\u4e2a\u7cfb\u7edf\u3001621\u4e2a\u95ee\u9898\uff0c\u6db5\u76d67\u79cd\u63a8\u7406\u7c7b\u578b\uff0c\u53d1\u73b0\u524d\u6cbfLLMs\u5728\u5355\u9879\u51c6\u786e\u7387\u4e0a\u8fbe\u523091-94%\uff0c\u4f46\u5728\u7ec4\u5408\u63a8\u7406\u548c\u5168\u5c40\u4e00\u81f4\u6027\u4e0a\u8868\u73b0\u8106\u5f31\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u9700\u8981\u7cbe\u786e\u903b\u8f91\u548c\u7b26\u53f7\u63a8\u7406\u7684\u9886\u57df\u4ecd\u7136\u8106\u5f31\u3002\u6df7\u6c8c\u52a8\u529b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7279\u522b\u5177\u6709\u6311\u6218\u6027\u7684\u6d4b\u8bd5\u73af\u5883\uff0c\u56e0\u4e3a\u6df7\u6c8c\u662f\u786e\u5b9a\u6027\u7684\uff0c\u4f46\u5e38\u88ab\u8bef\u89e3\u4e3a\u968f\u673a\u6027\u6216\u590d\u6742\u6027\u3002\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u7edf\u4e00\u7684\u57fa\u51c6\u6765\u8bc4\u4f30LLMs\u5728\u8fd9\u79cd\u590d\u6742\u903b\u8f91\u63a8\u7406\u573a\u666f\u4e0b\u7684\u80fd\u529b\u3002", "method": "\u5f15\u5165ChaosBench-Logic\u57fa\u51c6\uff0c\u5305\u542b30\u4e2a\u4e0d\u540c\u7684\u52a8\u529b\u7cfb\u7edf\uff0c\u4f7f\u7528\u7edf\u4e00\u7684\u4e00\u9636\u903b\u8f91\u672c\u4f53\u8fdb\u884c\u6807\u6ce8\uff0c\u6bcf\u4e2a\u7cfb\u7edf\u6807\u6ce8\u4e8611\u4e2a\u8bed\u4e49\u8c13\u8bcd\u7684\u771f\u503c\u5206\u914d\u3002\u751f\u6210\u4e86621\u4e2a\u95ee\u9898\uff0c\u6db5\u76d67\u79cd\u63a8\u7406\u7c7b\u522b\uff1a\u591a\u6b65\u63a8\u7406\u3001\u8de8\u7cfb\u7edf\u7c7b\u6bd4\u3001\u53cd\u4e8b\u5b9e\u63a8\u7406\u3001\u504f\u89c1\u63a2\u6d4b\u548c\u591a\u8f6e\u5bf9\u8bdd\u3002\u5b9a\u4e49\u4e86\u903b\u8f91\u51c6\u786e\u6027\u3001\u8574\u542b\u4e00\u81f4\u6027\u3001\u5bf9\u8bdd\u8fde\u8d2f\u6027\u548c\u77db\u76fe\u6027\u7b49\u8bc4\u4f30\u6307\u6807\uff0c\u5e76\u53d1\u5e03\u4e86\u5f00\u6e90\u8bc4\u4f30\u6d41\u7a0b\u3002", "result": "\u524d\u6cbfLLMs\uff08GPT-4\u3001Claude 3.5 Sonnet\u3001Gemini 2.5 Flash\u3001LLaMA-3 70B\uff09\u5728\u5355\u9879\u51c6\u786e\u7387\u4e0a\u8fbe\u523091-94%\uff0c\u4f46\u5728\u7ec4\u5408\u63a8\u7406\u9879\u76ee\u4e0a\u5f97\u5206\u4e3a0%\uff0c\u8868\u73b0\u51fa\u8106\u5f31\u7684\u5168\u5c40\u4e00\u81f4\u6027\u3002\u5bf9\u8bdd\u7ea7\u51c6\u786e\u7387\u4ece53.1%\uff08GPT-4 CoT\uff09\u523075.5%\uff08LLaMA-3\u96f6\u6837\u672c\uff09\u4e0d\u7b49\u3002", "conclusion": "ChaosBench-Logic\u4e3a\u8bca\u65adLLMs\u5728\u590d\u6742\u903b\u8f91\u63a8\u7406\u4e2d\u7684\u5931\u8d25\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4e25\u683c\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u5e76\u4e3a\u5f00\u53d1\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u4ee5\u6539\u8fdbLLMs\u7684\u79d1\u5b66\u63a8\u7406\u80fd\u529b\u5960\u5b9a\u4e86\u57fa\u7840\u3002\u7814\u7a76\u8868\u660e\uff0c\u5c3d\u7ba1LLMs\u5728\u5355\u9879\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9700\u8981\u7ec4\u5408\u63a8\u7406\u548c\u5168\u5c40\u4e00\u81f4\u6027\u7684\u590d\u6742\u903b\u8f91\u4efb\u52a1\u4e2d\u4ecd\u7136\u5b58\u5728\u663e\u8457\u7f3a\u9677\u3002"}}
{"id": "2601.01993", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01993", "abs": "https://arxiv.org/abs/2601.01993", "authors": ["Dong Xue", "Jicheng Tu", "Ming Wang", "Xin Yan", "Fangzhou Liu", "Jie Hu"], "title": "MindChat: A Privacy-preserving Large Language Model for Mental Health Support", "comment": "33 pages, 16 figures", "summary": "Large language models (LLMs) have shown promise for mental health support, yet training such models is constrained by the scarcity and sensitivity of real counseling dialogues. In this article, we present MindChat, a privacy-preserving LLM for mental health support, together with MindCorpus, a synthetic multi-turn counseling dataset constructed via a multi-agent role-playing framework. To synthesize high-quality counseling data, the developed dialogue-construction framework employs a dual closed-loop feedback design to integrate psychological expertise and counseling techniques through role-playing: (i) turn-level critique-and-revision to improve coherence and counseling appropriateness within a session, and (ii) session-level strategy refinement to progressively enrich counselor behaviors across sessions. To mitigate privacy risks under decentralized data ownership, we fine-tune the base model using federated learning with parameter-efficient LoRA adapters and incorporate differentially private optimization to reduce membership and memorization risks. Experiments on synthetic-data quality assessment and counseling capability evaluation show that MindCorpus improves training effectiveness and that MindChat is competitive with existing general and counseling-oriented LLM baselines under both automatic LLM-judge and human evaluation protocols, while exhibiting reduced privacy leakage under membership inference attacks.", "AI": {"tldr": "MindChat\u662f\u4e00\u4e2a\u4fdd\u62a4\u9690\u79c1\u7684\u5fc3\u7406\u5065\u5eb7\u652f\u6301\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u914d\u5408MindCorpus\u5408\u6210\u591a\u8f6e\u5fc3\u7406\u54a8\u8be2\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u8054\u90a6\u5b66\u4e60\u548c\u5dee\u5206\u9690\u79c1\u964d\u4f4e\u9690\u79c1\u98ce\u9669\uff0c\u5728\u5fc3\u7406\u54a8\u8be2\u80fd\u529b\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5fc3\u7406\u5065\u5eb7\u652f\u6301\u65b9\u9762\u6709\u6f5c\u529b\uff0c\u4f46\u53d7\u9650\u4e8e\u771f\u5b9e\u5fc3\u7406\u54a8\u8be2\u5bf9\u8bdd\u6570\u636e\u7684\u7a00\u7f3a\u6027\u548c\u654f\u611f\u6027\uff0c\u9700\u8981\u5f00\u53d1\u65e2\u80fd\u4fdd\u62a4\u9690\u79c1\u53c8\u80fd\u63d0\u4f9b\u9ad8\u8d28\u91cf\u5fc3\u7406\u54a8\u8be2\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "1. \u5f00\u53d1MindCorpus\u5408\u6210\u6570\u636e\u96c6\uff1a\u91c7\u7528\u591a\u667a\u80fd\u4f53\u89d2\u8272\u626e\u6f14\u6846\u67b6\uff0c\u5305\u542b\u53cc\u95ed\u73af\u53cd\u9988\u8bbe\u8ba1\uff08\u56de\u5408\u7ea7\u6279\u5224\u4fee\u8ba2\u548c\u4f1a\u8bdd\u7ea7\u7b56\u7565\u4f18\u5316\uff09\uff1b2. \u6784\u5efaMindChat\u6a21\u578b\uff1a\u4f7f\u7528\u8054\u90a6\u5b66\u4e60\u914d\u5408\u53c2\u6570\u9ad8\u6548\u7684LoRA\u9002\u914d\u5668\u8fdb\u884c\u5fae\u8c03\uff0c\u5e76\u52a0\u5165\u5dee\u5206\u9690\u79c1\u4f18\u5316\u6765\u964d\u4f4e\u6210\u5458\u63a8\u7406\u548c\u8bb0\u5fc6\u98ce\u9669\u3002", "result": "1. MindCorpus\u63d0\u9ad8\u4e86\u8bad\u7ec3\u6548\u679c\uff1b2. MindChat\u5728\u81ea\u52a8LLM\u8bc4\u4f30\u548c\u4eba\u5de5\u8bc4\u4f30\u4e2d\u4e0e\u73b0\u6709\u901a\u7528\u548c\u5fc3\u7406\u54a8\u8be2\u5bfc\u5411\u7684LLM\u57fa\u7ebf\u7ade\u4e89\uff1b3. \u5728\u6210\u5458\u63a8\u7406\u653b\u51fb\u4e0b\u8868\u73b0\u51fa\u51cf\u5c11\u7684\u9690\u79c1\u6cc4\u9732\u3002", "conclusion": "MindChat\u662f\u4e00\u4e2a\u6709\u6548\u7684\u9690\u79c1\u4fdd\u62a4\u5fc3\u7406\u5065\u5eb7\u652f\u6301LLM\uff0c\u901a\u8fc7\u5408\u6210\u6570\u636e\u751f\u6210\u548c\u9690\u79c1\u4fdd\u62a4\u6280\u672f\uff0c\u5728\u4fdd\u6301\u5fc3\u7406\u54a8\u8be2\u80fd\u529b\u7684\u540c\u65f6\u964d\u4f4e\u4e86\u9690\u79c1\u98ce\u9669\uff0c\u4e3a\u654f\u611f\u9886\u57df\u7684AI\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2601.02008", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.02008", "abs": "https://arxiv.org/abs/2601.02008", "authors": ["Midhat Urooj", "Ayan Banerjee", "Sandeep Gupta"], "title": "XAI-MeD: Explainable Knowledge Guided Neuro-Symbolic Framework for Domain Generalization and Rare Class Detection in Medical Imaging", "comment": "Accepted at AAAI Bridge Program 2026", "summary": "Explainability domain generalization and rare class reliability are critical challenges in medical AI where deep models often fail under real world distribution shifts and exhibit bias against infrequent clinical conditions This paper introduces XAIMeD an explainable medical AI framework that integrates clinically accurate expert knowledge into deep learning through a unified neuro symbolic architecture XAIMeD is designed to improve robustness under distribution shift enhance rare class sensitivity and deliver transparent clinically aligned interpretations The framework encodes clinical expertise as logical connectives over atomic medical propositions transforming them into machine checkable class specific rules Their diagnostic utility is quantified through weighted feature satisfaction scores enabling a symbolic reasoning branch that complements neural predictions A confidence weighted fusion integrates symbolic and deep outputs while a Hunt inspired adaptive routing mechanism guided by Entropy Imbalance Gain EIG and Rare Class Gini mitigates class imbalance high intra class variability and uncertainty We evaluate XAIMeD across diverse modalities on four challenging tasks i Seizure Onset Zone SOZ localization from rs fMRI ii Diabetic Retinopathy grading across 6 multicenter datasets demonstrate substantial performance improvements including 6 percent gains in cross domain generalization and a 10 percent improved rare class F1 score far outperforming state of the art deep learning baselines Ablation studies confirm that the clinically grounded symbolic components act as effective regularizers ensuring robustness to distribution shifts XAIMeD thus provides a principled clinically faithful and interpretable approach to multimodal medical AI.", "AI": {"tldr": "XAIMeD\u662f\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u533b\u7597AI\u6846\u67b6\uff0c\u901a\u8fc7\u795e\u7ecf\u7b26\u53f7\u67b6\u6784\u6574\u5408\u4e34\u5e8a\u4e13\u5bb6\u77e5\u8bc6\uff0c\u63d0\u5347\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u9c81\u68d2\u6027\u3001\u7f55\u89c1\u7c7b\u522b\u654f\u611f\u6027\uff0c\u5e76\u63d0\u4f9b\u4e34\u5e8a\u5bf9\u9f50\u7684\u89e3\u91ca\u3002", "motivation": "\u533b\u7597AI\u4e2d\u53ef\u89e3\u91ca\u6027\u3001\u9886\u57df\u6cdb\u5316\u548c\u7f55\u89c1\u7c7b\u522b\u53ef\u9760\u6027\u662f\u5173\u952e\u6311\u6218\uff0c\u6df1\u5ea6\u6a21\u578b\u5728\u771f\u5b9e\u4e16\u754c\u5206\u5e03\u504f\u79fb\u4e0b\u7ecf\u5e38\u5931\u8d25\uff0c\u5e76\u5bf9\u4e0d\u5e38\u89c1\u7684\u4e34\u5e8a\u6761\u4ef6\u8868\u73b0\u51fa\u504f\u89c1\u3002", "method": "XAIMeD\u5c06\u4e34\u5e8a\u4e13\u4e1a\u77e5\u8bc6\u7f16\u7801\u4e3a\u539f\u5b50\u533b\u5b66\u547d\u9898\u7684\u903b\u8f91\u8fde\u63a5\uff0c\u8f6c\u5316\u4e3a\u673a\u5668\u53ef\u68c0\u67e5\u7684\u7c7b\u522b\u7279\u5b9a\u89c4\u5219\u3002\u901a\u8fc7\u52a0\u6743\u7279\u5f81\u6ee1\u8db3\u5206\u6570\u91cf\u5316\u8bca\u65ad\u6548\u7528\uff0c\u521b\u5efa\u7b26\u53f7\u63a8\u7406\u5206\u652f\u8865\u5145\u795e\u7ecf\u9884\u6d4b\u3002\u4f7f\u7528\u7f6e\u4fe1\u5ea6\u52a0\u6743\u878d\u5408\u6574\u5408\u7b26\u53f7\u548c\u6df1\u5ea6\u8f93\u51fa\uff0c\u5e76\u91c7\u7528\u53d7Hunt\u542f\u53d1\u7684\u81ea\u9002\u5e94\u8def\u7531\u673a\u5236\uff0c\u7531\u71b5\u4e0d\u5e73\u8861\u589e\u76ca\u548c\u7f55\u89c1\u7c7b\u522b\u57fa\u5c3c\u7cfb\u6570\u6307\u5bfc\u3002", "result": "\u5728\u56db\u4e2a\u6311\u6218\u6027\u4efb\u52a1\u4e0a\u8bc4\u4f30\u663e\u793a\uff1a\u8de8\u9886\u57df\u6cdb\u5316\u6027\u80fd\u63d0\u53476%\uff0c\u7f55\u89c1\u7c7b\u522bF1\u5206\u6570\u63d0\u9ad810%\uff0c\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u6df1\u5ea6\u5b66\u4e60\u57fa\u7ebf\u3002\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u4e34\u5e8a\u57fa\u7840\u7684\u7b26\u53f7\u7ec4\u4ef6\u4f5c\u4e3a\u6709\u6548\u6b63\u5219\u5316\u5668\uff0c\u786e\u4fdd\u5bf9\u5206\u5e03\u504f\u79fb\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "XAIMeD\u4e3a\u591a\u6a21\u6001\u533b\u7597AI\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u3001\u4e34\u5e8a\u5fe0\u5b9e\u4e14\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u4e13\u5bb6\u77e5\u8bc6\u63d0\u5347\u6a21\u578b\u5728\u771f\u5b9e\u533b\u7597\u573a\u666f\u4e2d\u7684\u53ef\u9760\u6027\u548c\u900f\u660e\u5ea6\u3002"}}
{"id": "2601.02043", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.02043", "abs": "https://arxiv.org/abs/2601.02043", "authors": ["Hendrik Kempt", "Alon Lavie"], "title": "Simulated Reasoning is Reasoning", "comment": "21 pages", "summary": "Reasoning has long been understood as a pathway between stages of understanding. Proper reasoning leads to understanding of a given subject. This reasoning was conceptualized as a process of understanding in a particular way, i.e., \"symbolic reasoning\". Foundational Models (FM) demonstrate that this is not a necessary condition for many reasoning tasks: they can \"reason\" by way of imitating the process of \"thinking out loud\", testing the produced pathways, and iterating on these pathways on their own. This leads to some form of reasoning that can solve problems on its own or with few-shot learning, but appears fundamentally different from human reasoning due to its lack of grounding and common sense, leading to brittleness of the reasoning process. These insights promise to substantially alter our assessment of reasoning and its necessary conditions, but also inform the approaches to safety and robust defences against this brittleness of FMs. This paper offers and discusses several philosophical interpretations of this phenomenon, argues that the previously apt metaphor of the \"stochastic parrot\" has lost its relevance and thus should be abandoned, and reflects on different normative elements in the safety- and appropriateness-considerations emerging from these reasoning models and their growing capacity.", "AI": {"tldr": "\u8bba\u6587\u8ba4\u4e3a\u57fa\u7840\u6a21\u578b\u901a\u8fc7\u6a21\u4eff\"\u51fa\u58f0\u601d\u8003\"\u7684\u8fc7\u7a0b\u8fdb\u884c\u63a8\u7406\uff0c\u8fd9\u79cd\u63a8\u7406\u65b9\u5f0f\u4e0e\u4eba\u7c7b\u7b26\u53f7\u63a8\u7406\u4e0d\u540c\uff0c\u7f3a\u4e4f\u5e38\u8bc6\u57fa\u7840\u4e14\u8106\u5f31\uff0c\u4f46\u80fd\u89e3\u51b3\u590d\u6742\u95ee\u9898\uff0c\u9700\u8981\u91cd\u65b0\u8bc4\u4f30\u63a8\u7406\u7684\u672c\u8d28\u548c\u5b89\u5168\u8003\u91cf\u3002", "motivation": "\u4f20\u7edf\u89c2\u70b9\u8ba4\u4e3a\u63a8\u7406\u662f\u901a\u8fc7\u7b26\u53f7\u63a8\u7406\u5b9e\u73b0\u7406\u89e3\u7684\u8fc7\u7a0b\uff0c\u4f46\u57fa\u7840\u6a21\u578b\u5c55\u793a\u4e86\u4e0d\u540c\u7684\u63a8\u7406\u65b9\u5f0f\uff1a\u901a\u8fc7\u6a21\u4eff\"\u51fa\u58f0\u601d\u8003\"\u3001\u6d4b\u8bd5\u751f\u6210\u8def\u5f84\u5e76\u8fed\u4ee3\u6765\u89e3\u51b3\u95ee\u9898\u3002\u8fd9\u79cd\u63a8\u7406\u65b9\u5f0f\u7f3a\u4e4f\u4eba\u7c7b\u63a8\u7406\u7684\u5e38\u8bc6\u57fa\u7840\u548c\u7a33\u5b9a\u6027\uff0c\u9700\u8981\u91cd\u65b0\u5ba1\u89c6\u63a8\u7406\u7684\u672c\u8d28\u53ca\u5176\u5fc5\u8981\u6761\u4ef6\u3002", "method": "\u672c\u6587\u91c7\u7528\u54f2\u5b66\u5206\u6790\u65b9\u6cd5\uff0c\u63a2\u8ba8\u57fa\u7840\u6a21\u578b\u63a8\u7406\u73b0\u8c61\u7684\u591a\u91cd\u54f2\u5b66\u89e3\u91ca\uff0c\u8bba\u8bc1\"\u968f\u673a\u9e66\u9e49\"\u9690\u55bb\u5df2\u5931\u53bb\u76f8\u5173\u6027\uff0c\u5e76\u53cd\u601d\u4ece\u8fd9\u4e9b\u63a8\u7406\u6a21\u578b\u4e2d\u4ea7\u751f\u7684\u5b89\u5168\u548c\u9002\u5f53\u6027\u8003\u8651\u7684\u4e0d\u540c\u89c4\u8303\u8981\u7d20\u3002", "result": "\u57fa\u7840\u6a21\u578b\u7684\u63a8\u7406\u65b9\u5f0f\u4e0e\u4eba\u7c7b\u7b26\u53f7\u63a8\u7406\u6709\u672c\u8d28\u533a\u522b\uff0c\u5b83\u901a\u8fc7\u6a21\u4eff\u601d\u8003\u8fc7\u7a0b\u800c\u975e\u771f\u6b63\u7406\u89e3\u6765\u89e3\u51b3\u95ee\u9898\u3002\u8fd9\u79cd\u63a8\u7406\u867d\u7136\u80fd\u5904\u7406\u590d\u6742\u4efb\u52a1\uff0c\u4f46\u7f3a\u4e4f\u5e38\u8bc6\u57fa\u7840\uff0c\u5bfc\u81f4\u63a8\u7406\u8fc7\u7a0b\u8106\u5f31\u3002\u9700\u8981\u91cd\u65b0\u8bc4\u4f30\u63a8\u7406\u6982\u5ff5\uff0c\u5e76\u5efa\u7acb\u9488\u5bf9\u8fd9\u79cd\u8106\u5f31\u6027\u7684\u5b89\u5168\u9632\u5fa1\u673a\u5236\u3002", "conclusion": "\u57fa\u7840\u6a21\u578b\u7684\u63a8\u7406\u73b0\u8c61\u6311\u6218\u4e86\u4f20\u7edf\u63a8\u7406\u6982\u5ff5\uff0c\u8868\u660e\u7b26\u53f7\u63a8\u7406\u4e0d\u662f\u63a8\u7406\u7684\u5fc5\u8981\u6761\u4ef6\u3002\"\u968f\u673a\u9e66\u9e49\"\u9690\u55bb\u5df2\u4e0d\u9002\u7528\uff0c\u9700\u8981\u65b0\u7684\u7406\u8bba\u6846\u67b6\u6765\u7406\u89e3\u8fd9\u79cd\u65b0\u578b\u63a8\u7406\u3002\u540c\u65f6\uff0c\u5fc5\u987b\u8003\u8651\u7531\u6b64\u4ea7\u751f\u7684\u5b89\u5168\u548c\u4f26\u7406\u95ee\u9898\uff0c\u5efa\u7acb\u9002\u5f53\u7684\u89c4\u8303\u6846\u67b6\u6765\u5e94\u5bf9\u57fa\u7840\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u589e\u957f\u3002"}}
{"id": "2601.02071", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02071", "abs": "https://arxiv.org/abs/2601.02071", "authors": ["Adeshola Okubena", "Yusuf Ali Mohammed", "Moe Elbadawi"], "title": "FormuLLA: A Large Language Model Approach to Generating Novel 3D Printable Formulations", "comment": null, "summary": "Pharmaceutical three-dimensional (3D) printing is an advanced fabrication technology with the potential to enable truly personalised dosage forms. Recent studies have integrated artificial intelligence (AI) to accelerate formulation and process development, drastically transforming current approaches to pharmaceutical 3D printing. To date, most AI-driven efforts remain narrowly focused, while failing to account for the broader formulation challenges inherent to the technology. Recent advances in AI have introduced artificial general intelligence concepts, wherein systems extend beyond conventional predictive modelling toward more generalised, human-like reasoning. In this work, we investigate the application of large language models (LLMs), fine-tuned on a fused deposition modelling (FDM) dataset comprising over 1400 formulations, to recommend suitable excipients based on active pharmaceutical ingredient (API) dose, and predict filament mechanical properties. Four LLM architectures were fine-tuned, with systematic evaluation of both fine-tuning and generative parameter configurations. Our results demonstrate that Llama2 was best suited for recommending excipients for FDM formulations. Additionally, model selection and parameterisation significantly influence performance, with smaller LLMs exhibiting instances of catastrophic forgetting. Furthermore, we demonstrate: (i) even with relatively small dataset of over 1400 formulations, it can lead to model catastrophic forgetting; (ii) standard LLM metrics only evaluate linguistic performance but not formulation processability; and (iii) LLMs trained on biomedically-related data do not always produce the best results. Addressing these challenges is essential to advancing LLMs beyond linguistic proficiency and toward reliable systems for pharmaceutical formulation development.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u836f\u72693D\u6253\u5370\u914d\u65b9\u5f00\u53d1\uff0c\u901a\u8fc7\u5fae\u8c03\u56db\u79cdLLM\u67b6\u6784\uff0c\u8bc4\u4f30\u5176\u5728\u63a8\u8350\u8f85\u6599\u548c\u9884\u6d4b\u4e1d\u6750\u673a\u68b0\u6027\u80fd\u65b9\u9762\u7684\u8868\u73b0\uff0c\u53d1\u73b0Llama2\u6700\u9002\u5408FDM\u914d\u65b9\u63a8\u8350\uff0c\u5e76\u63ed\u793a\u4e86\u5c0f\u6570\u636e\u96c6\u53ef\u80fd\u5bfc\u81f4\u707e\u96be\u6027\u9057\u5fd8\u7b49\u95ee\u9898\u3002", "motivation": "\u5f53\u524dAI\u9a71\u52a8\u7684\u836f\u72693D\u6253\u5370\u7814\u7a76\u5927\u591a\u5c40\u9650\u4e8e\u72ed\u7a84\u9886\u57df\uff0c\u672a\u80fd\u5168\u9762\u89e3\u51b3\u914d\u65b9\u5f00\u53d1\u4e2d\u7684\u590d\u6742\u6311\u6218\u3002\u968f\u7740\u4eba\u5de5\u901a\u7528\u667a\u80fd\u6982\u5ff5\u7684\u53d1\u5c55\uff0c\u9700\u8981\u63a2\u7d22LLM\u5728\u836f\u7269\u5236\u5242\u5f00\u53d1\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u4ee5\u8d85\u8d8a\u4f20\u7edf\u9884\u6d4b\u6a21\u578b\uff0c\u5b9e\u73b0\u66f4\u901a\u7528\u3001\u7c7b\u4eba\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "\u7814\u7a76\u5fae\u8c03\u4e86\u56db\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u67b6\u6784\uff0c\u4f7f\u7528\u5305\u542b1400\u591a\u79cd\u914d\u65b9\u7684\u7194\u878d\u6c89\u79ef\u5efa\u6a21\u6570\u636e\u96c6\u3002\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5fae\u8c03\u548c\u751f\u6210\u53c2\u6570\u914d\u7f6e\uff0c\u91cd\u70b9\u5173\u6ce8\u6a21\u578b\u5728\u57fa\u4e8e\u6d3b\u6027\u836f\u7269\u6210\u5206\u5242\u91cf\u63a8\u8350\u5408\u9002\u8f85\u6599\u4ee5\u53ca\u9884\u6d4b\u4e1d\u6750\u673a\u68b0\u6027\u80fd\u65b9\u9762\u7684\u8868\u73b0\u3002", "result": "Llama2\u5728\u63a8\u8350FDM\u914d\u65b9\u8f85\u6599\u65b9\u9762\u8868\u73b0\u6700\u4f73\u3002\u6a21\u578b\u9009\u62e9\u548c\u53c2\u6570\u5316\u663e\u8457\u5f71\u54cd\u6027\u80fd\uff0c\u8f83\u5c0f\u7684LLM\u51fa\u73b0\u707e\u96be\u6027\u9057\u5fd8\u73b0\u8c61\u3002\u7814\u7a76\u8fd8\u53d1\u73b0\uff1a\u5373\u4f7f\u76f8\u5bf9\u8f83\u5c0f\u76841400+\u914d\u65b9\u6570\u636e\u96c6\u4e5f\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u707e\u96be\u6027\u9057\u5fd8\uff1b\u6807\u51c6LLM\u6307\u6807\u4ec5\u8bc4\u4f30\u8bed\u8a00\u6027\u80fd\u800c\u975e\u914d\u65b9\u53ef\u52a0\u5de5\u6027\uff1b\u57fa\u4e8e\u751f\u7269\u533b\u5b66\u76f8\u5173\u6570\u636e\u8bad\u7ec3\u7684LLM\u4e0d\u4e00\u5b9a\u4ea7\u751f\u6700\u4f73\u7ed3\u679c\u3002", "conclusion": "\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u5bf9\u4e8e\u63a8\u52a8LLM\u8d85\u8d8a\u8bed\u8a00\u80fd\u529b\u3001\u53d1\u5c55\u6210\u4e3a\u836f\u7269\u914d\u65b9\u5f00\u53d1\u7684\u53ef\u9760\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\u3002\u8be5\u7814\u7a76\u4e3a\u5c06\u4eba\u5de5\u901a\u7528\u667a\u80fd\u6982\u5ff5\u5e94\u7528\u4e8e\u836f\u72693D\u6253\u5370\u9886\u57df\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\uff0c\u5f3a\u8c03\u4e86\u9700\u8981\u5f00\u53d1\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6307\u6807\u6765\u786e\u4fdd\u914d\u65b9\u5f00\u53d1\u7684\u5b9e\u9645\u53ef\u884c\u6027\u3002"}}
{"id": "2601.02170", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02170", "abs": "https://arxiv.org/abs/2601.02170", "authors": ["Haolang Lu", "Minghui Pan", "Ripeng Li", "Guoshun Nan", "Jialin Zhuang", "Zijie Zhao", "Zhongxiang Sun", "Kun Wang", "Yang Liu"], "title": "Streaming Hallucination Detection in Long Chain-of-Thought Reasoning", "comment": null, "summary": "Long chain-of-thought (CoT) reasoning improves the performance of large language models, yet hallucinations in such settings often emerge subtly and propagate across reasoning steps. We suggest that hallucination in long CoT reasoning is better understood as an evolving latent state rather than a one-off erroneous event. Accordingly, we treat step-level hallucination judgments as local observations and introduce a cumulative prefix-level hallucination signal that tracks the global evolution of the reasoning state over the entire trajectory. Overall, our approach enables streaming hallucination detection in long CoT reasoning, providing real-time, interpretable evidence.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5c06\u957f\u94fe\u601d\u7ef4\u63a8\u7406\u4e2d\u7684\u5e7b\u89c9\u89c6\u4e3a\u6f14\u5316\u6f5c\u72b6\u6001\uff0c\u800c\u975e\u4e00\u6b21\u6027\u9519\u8bef\u4e8b\u4ef6\uff0c\u5e76\u5f15\u5165\u7d2f\u79ef\u524d\u7f00\u7ea7\u5e7b\u89c9\u4fe1\u53f7\u6765\u5b9e\u65f6\u68c0\u6d4b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u5e7b\u89c9\u4f20\u64ad\u3002", "motivation": "\u957f\u94fe\u601d\u7ef4\u63a8\u7406\u867d\u7136\u80fd\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u5176\u4e2d\u7684\u5e7b\u89c9\u5f80\u5f80\u4ee5\u5fae\u5999\u65b9\u5f0f\u51fa\u73b0\u5e76\u5728\u63a8\u7406\u6b65\u9aa4\u95f4\u4f20\u64ad\u3002\u73b0\u6709\u65b9\u6cd5\u5c06\u5e7b\u89c9\u89c6\u4e3a\u4e00\u6b21\u6027\u9519\u8bef\u4e8b\u4ef6\uff0c\u672a\u80fd\u6355\u6349\u5176\u5728\u957f\u63a8\u7406\u94fe\u4e2d\u7684\u6f14\u5316\u7279\u6027\u3002", "method": "\u5c06\u6b65\u9aa4\u7ea7\u5e7b\u89c9\u5224\u65ad\u89c6\u4e3a\u5c40\u90e8\u89c2\u6d4b\uff0c\u5f15\u5165\u7d2f\u79ef\u524d\u7f00\u7ea7\u5e7b\u89c9\u4fe1\u53f7\u6765\u8ffd\u8e2a\u6574\u4e2a\u63a8\u7406\u8f68\u8ff9\u4e2d\u63a8\u7406\u72b6\u6001\u7684\u5168\u5c40\u6f14\u5316\uff0c\u5b9e\u73b0\u957f\u94fe\u601d\u7ef4\u63a8\u7406\u4e2d\u7684\u6d41\u5f0f\u5e7b\u89c9\u68c0\u6d4b\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5b9e\u65f6\u68c0\u6d4b\u957f\u94fe\u601d\u7ef4\u63a8\u7406\u4e2d\u7684\u5e7b\u89c9\u4f20\u64ad\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u8bc1\u636e\uff0c\u76f8\u6bd4\u4f20\u7edf\u7684\u4e00\u6b21\u6027\u9519\u8bef\u68c0\u6d4b\u65b9\u6cd5\uff0c\u80fd\u66f4\u597d\u5730\u6355\u6349\u5e7b\u89c9\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u6f14\u5316\u7279\u6027\u3002", "conclusion": "\u5c06\u5e7b\u89c9\u5efa\u6a21\u4e3a\u6f14\u5316\u6f5c\u72b6\u6001\u800c\u975e\u4e00\u6b21\u6027\u4e8b\u4ef6\uff0c\u901a\u8fc7\u7d2f\u79ef\u524d\u7f00\u7ea7\u4fe1\u53f7\u8ffd\u8e2a\u63a8\u7406\u72b6\u6001\u6f14\u5316\uff0c\u4e3a\u957f\u94fe\u601d\u7ef4\u63a8\u7406\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u5b9e\u65f6\u5e7b\u89c9\u68c0\u6d4b\u6846\u67b6\u3002"}}
{"id": "2601.02346", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02346", "abs": "https://arxiv.org/abs/2601.02346", "authors": ["Falcon LLM Team", "Iheb Chaabane", "Puneesh Khanna", "Suhail Mohmad", "Slim Frikha", "Shi Hu", "Abdalgader Abubaker", "Reda Alami", "Mikhail Lubinets", "Mohamed El Amine Seddik", "Hakim Hacid"], "title": "Falcon-H1R: Pushing the Reasoning Frontiers with a Hybrid Model for Efficient Test-Time Scaling", "comment": null, "summary": "This work introduces Falcon-H1R, a 7B-parameter reasoning-optimized model that establishes the feasibility of achieving competitive reasoning performance with small language models (SLMs). Falcon-H1R stands out for its parameter efficiency, consistently matching or outperforming SOTA reasoning models that are $2\\times$ to $7\\times$ larger across a variety of reasoning-intensive benchmarks. These results underscore the importance of careful data curation and targeted training strategies (via both efficient SFT and RL scaling) in delivering significant performance gains without increasing model size. Furthermore, Falcon-H1R advances the 3D limits of reasoning efficiency by combining faster inference (through its hybrid-parallel architecture design), token efficiency, and higher accuracy. This unique blend makes Falcon-H1R-7B a practical backbone for scaling advanced reasoning systems, particularly in scenarios requiring extensive chain-of-thoughts generation and parallel test-time scaling. Leveraging the recently introduced DeepConf approach, Falcon-H1R achieves state-of-the-art test-time scaling efficiency, offering substantial improvements in both accuracy and computational cost. As a result, Falcon-H1R demonstrates that compact models, through targeted model training and architectural choices, can deliver robust and scalable reasoning performance.", "AI": {"tldr": "Falcon-H1R\u662f\u4e00\u4e2a7B\u53c2\u6570\u7684\u63a8\u7406\u4f18\u5316\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u5c0f\u8bed\u8a00\u6a21\u578b\u4e5f\u80fd\u5b9e\u73b0\u6709\u7ade\u4e89\u529b\u7684\u63a8\u7406\u6027\u80fd\uff0c\u5728\u591a\u4e2a\u63a8\u7406\u5bc6\u96c6\u578b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5339\u914d\u6216\u8d85\u8d8a2-7\u500d\u5927\u7684SOTA\u6a21\u578b\u3002", "motivation": "\u63a2\u7d22\u5c0f\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u591f\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u6570\u636e\u7b56\u5c55\u548c\u8bad\u7ec3\u7b56\u7565\uff0c\u5728\u4e0d\u589e\u52a0\u6a21\u578b\u89c4\u6a21\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e0e\u5927\u6a21\u578b\u76f8\u5f53\u7684\u63a8\u7406\u6027\u80fd\uff0c\u4e3a\u6784\u5efa\u9ad8\u6548\u5b9e\u7528\u7684\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u65b0\u601d\u8def\u3002", "method": "\u91c7\u7528\u6df7\u5408\u5e76\u884c\u67b6\u6784\u8bbe\u8ba1\u5b9e\u73b0\u66f4\u5feb\u63a8\u7406\uff0c\u901a\u8fc7\u9ad8\u6548\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u548c\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u6269\u5c55\u8fdb\u884c\u9488\u5bf9\u6027\u8bad\u7ec3\uff0c\u7ed3\u5408DeepConf\u65b9\u6cd5\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u6d4b\u8bd5\u65f6\u6269\u5c55\u6548\u7387\u3002", "result": "Falcon-H1R-7B\u5728\u591a\u79cd\u63a8\u7406\u5bc6\u96c6\u578b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4e00\u81f4\u5339\u914d\u6216\u8d85\u8d8a\u6bd4\u5176\u59272-7\u500d\u7684SOTA\u63a8\u7406\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u63a8\u7406\u6548\u7387\u76843D\u6781\u9650\uff08\u66f4\u5feb\u63a8\u7406\u3001\u66f4\u9ad8token\u6548\u7387\u3001\u66f4\u9ad8\u51c6\u786e\u7387\uff09\u3002", "conclusion": "\u7d27\u51d1\u6a21\u578b\u901a\u8fc7\u9488\u5bf9\u6027\u7684\u6a21\u578b\u8bad\u7ec3\u548c\u67b6\u6784\u9009\u62e9\uff0c\u80fd\u591f\u63d0\u4f9b\u7a33\u5065\u4e14\u53ef\u6269\u5c55\u7684\u63a8\u7406\u6027\u80fd\uff0c\u4e3a\u9700\u8981\u5927\u91cf\u601d\u7ef4\u94fe\u751f\u6210\u548c\u5e76\u884c\u6d4b\u8bd5\u65f6\u6269\u5c55\u7684\u573a\u666f\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u9aa8\u5e72\u6a21\u578b\u3002"}}
