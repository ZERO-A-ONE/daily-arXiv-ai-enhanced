<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 8]
- [cs.CR](#cs.CR) [Total: 14]
- [cs.AI](#cs.AI) [Total: 41]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Context Engineering for Multi-Agent LLM Code Assistants Using Elicit, NotebookLM, ChatGPT, and Claude Code](https://arxiv.org/abs/2508.08322)
*Muhammad Haseeb*

Main category: cs.SE

TL;DR: 提出了一种结合多种AI组件的上下文工程工作流，显著提升了代码生成助手在复杂项目中的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在复杂、多文件项目中因上下文限制和知识缺口表现不佳的问题。

Method: 结合意图翻译、语义文献检索、文档合成和多代理代码生成与验证的集成方法。

Result: 在多代理系统中实现了更高的单次成功率和更好的项目上下文适应性，优于单代理基线方法。

Conclusion: 该方法为生产环境中部署基于LLM的编码助手提供了有效解决方案，并指出了未来研究方向。

Abstract: Large Language Models (LLMs) have shown promise in automating code generation
and software engineering tasks, yet they often struggle with complex,
multi-file projects due to context limitations and knowledge gaps. We propose a
novel context engineering workflow that combines multiple AI components: an
Intent Translator (GPT-5) for clarifying user requirements, an Elicit-powered
semantic literature retrieval for injecting domain knowledge, NotebookLM-based
document synthesis for contextual understanding, and a Claude Code multi-agent
system for code generation and validation. Our integrated approach leverages
intent clarification, retrieval-augmented generation, and specialized
sub-agents orchestrated via Claude's agent framework. We demonstrate that this
method significantly improves the accuracy and reliability of code assistants
in real-world repositories, yielding higher single-shot success rates and
better adherence to project context than baseline single-agent approaches.
Qualitative results on a large Next.js codebase show the multi-agent system
effectively plans, edits, and tests complex features with minimal human
intervention. We compare our system with recent frameworks like CodePlan,
MASAI, and HyperAgent, highlighting how targeted context injection and agent
role decomposition lead to state-of-the-art performance. Finally, we discuss
the implications for deploying LLM-based coding assistants in production, along
with lessons learned on context management and future research directions.

</details>


### [2] [Energy-Aware Code Generation with LLMs: Benchmarking Small vs. Large Language Models for Sustainable AI Programming](https://arxiv.org/abs/2508.08332)
*Humza Ashraf,Syed Muhammad Danish,Aris Leivadeas,Yazan Otoum,Zeeshan Sattar*

Main category: cs.SE

TL;DR: 研究比较了开源小型语言模型（SLMs）和大型语言模型（LLMs）在代码生成中的性能和能源效率，发现SLMs在正确性上虽略逊于LLMs，但在能源效率上表现更优。


<details>
  <summary>Details</summary>
Motivation: 商业LLMs（如ChatGPT）的高能耗和碳排放引发环境担忧，研究旨在探索SLMs是否能以更低能耗实现类似性能。

Method: 评估150个LeetCode编程问题，比较3个开源SLMs和2个商业LLMs在运行时间、内存使用、能耗和正确性上的表现，并以人工编写的代码为基准。

Result: LLMs在所有难度级别上正确性最高，但SLMs在正确输出时更节能，52%的问题中SLMs能耗与LLMs相当或更低。

Conclusion: SLMs在能源效率上优于LLMs，适合对能耗敏感的场景，但需权衡正确性。

Abstract: Large Language Models (LLMs) are widely used for code generation. However,
commercial models like ChatGPT require significant computing power, which leads
to high energy use and carbon emissions. This has raised concerns about their
environmental impact. In this study, we evaluate open-source Small Language
Models (SLMs) trained explicitly for code generation and compare their
performance and energy efficiency against large LLMs and efficient
human-written Python code. The goal is to investigate whether SLMs can match
the performance of LLMs on certain types of programming problems while
producing more energy-efficient code. We evaluate 150 coding problems from
LeetCode, evenly distributed across three difficulty levels: easy, medium, and
hard. Our comparison includes three small open-source models, StableCode-3B,
StarCoderBase-3B, and Qwen2.5-Coder-3B-Instruct, and two large commercial
models, GPT-4.0 and DeepSeek-Reasoner. The generated code is evaluated using
four key metrics: run-time, memory usage, energy consumption, and correctness.
We use human-written solutions as a baseline to assess the quality and
efficiency of the model-generated code. Results indicate that LLMs achieve the
highest correctness across all difficulty levels, but SLMs are often more
energy-efficient when their outputs are correct. In over 52% of the evaluated
problems, SLMs consumed the same or less energy than LLMs.

</details>


### [3] [Improving Merge Pipeline Throughput in Continuous Integration via Pull Request Prioritization](https://arxiv.org/abs/2508.08342)
*Maximilian Jungwirth,Martin Gruber,Gordon Fraser*

Main category: cs.SE

TL;DR: 论文提出了一种基于历史构建数据和PR元数据的预测方法，优化合并管道中PR的顺序，以提高吞吐量。


<details>
  <summary>Details</summary>
Motivation: 大型单体软件仓库的合并管道常因高负载成为瓶颈，现有优化方法依赖特定构建系统，通用性不足。

Method: 利用历史构建数据、PR元数据和上下文信息预测构建成功率，动态优先处理可能通过的PR。

Result: 实验表明，该方法显著优于传统的FIFO和非学习型排序策略。

Conclusion: 该方法不依赖特定构建系统，易于集成到现有自动化合并管道中。

Abstract: Integrating changes into large monolithic software repositories is a critical
step in modern software development that substantially impacts the speed of
feature delivery, the stability of the codebase, and the overall productivity
of development teams. To ensure the stability of the main branch, many
organizations use merge pipelines that test software versions before the
changes are permanently integrated. However, the load on merge pipelines is
often so high that they become bottlenecks, despite the use of parallelization.
Existing optimizations frequently rely on specific build systems, limiting
their generalizability and applicability. In this paper we propose to optimize
the order of PRs in merge pipelines using practical build predictions utilizing
only historical build data, PR metadata, and contextual information to estimate
the likelihood of successful builds in the merge pipeline. By dynamically
prioritizing likely passing PRs during peak hours, this approach maximizes
throughput when it matters most. Experiments conducted on a real-world,
large-scale project demonstrate that predictive ordering significantly
outperforms traditional first-in-first-out (FIFO), as well as
non-learning-based ordering strategies. Unlike alternative optimizations, this
approach is agnostic to the underlying build system and thus easily integrable
into existing automated merge pipelines.

</details>


### [4] [OmniLLP: Enhancing LLM-based Log Level Prediction with Context-Aware Retrieval](https://arxiv.org/abs/2508.08545)
*Youssef Esseddiq Ouatiti,Mohammed Sayagh,Bram Adams,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: OmniLLP通过基于语义相似性和开发者所有权聚类改进日志级别预测，显著提升LLM-based LLPs的准确性。


<details>
  <summary>Details</summary>
Motivation: 日志级别选择对系统可观察性和性能至关重要，但现有LLM-based LLPs依赖随机上下文示例，忽略了代码结构和开发实践。

Method: OmniLLP通过聚类源代码文件（基于语义相似性和开发者所有权）选择上下文示例，提供更一致的提示。

Result: 语义和所有权聚类显著提升预测准确性（AUC提升8%），结合两者可达0.88-0.96 AUC。

Conclusion: 将代码语义和开发者所有权信号整合到LLM-LLPs中，可提供更准确、上下文感知的日志级别预测，提升系统可维护性和可观察性。

Abstract: Developers insert logging statements in source code to capture relevant
runtime information essential for maintenance and debugging activities. Log
level choice is an integral, yet tricky part of the logging activity as it
controls log verbosity and therefore influences systems' observability and
performance. Recent advances in ML-based log level prediction have leveraged
large language models (LLMs) to propose log level predictors (LLPs) that
demonstrated promising performance improvements (AUC between 0.64 and 0.8).
Nevertheless, current LLM-based LLPs rely on randomly selected in-context
examples, overlooking the structure and the diverse logging practices within
modern software projects. In this paper, we propose OmniLLP, a novel LLP
enhancement framework that clusters source files based on (1) semantic
similarity reflecting the code's functional purpose, and (2) developer
ownership cohesion. By retrieving in-context learning examples exclusively from
these semantic and ownership aware clusters, we aim to provide more coherent
prompts to LLPs leveraging LLMs, thereby improving their predictive accuracy.
Our results show that both semantic and ownership-aware clusterings
statistically significantly improve the accuracy (by up to 8\% AUC) of the
evaluated LLM-based LLPs compared to random predictors (i.e., leveraging
randomly selected in-context examples from the whole project). Additionally,
our approach that combines the semantic and ownership signal for in-context
prediction achieves an impressive 0.88 to 0.96 AUC across our evaluated
projects. Our findings highlight the value of integrating software
engineering-specific context, such as code semantic and developer ownership
signals into LLM-LLPs, offering developers a more accurate, contextually-aware
approach to logging and therefore, enhancing system maintainability and
observability.

</details>


### [5] [Hallucinations in Code Change to Natural Language Generation: Prevalence and Evaluation of Detection Metrics](https://arxiv.org/abs/2508.08661)
*Chunhua Liu,Hong Yi Lin,Patanamon Thongtanunam*

Main category: cs.SE

TL;DR: 该论文首次全面分析了代码变更任务中的幻觉问题，发现50%的代码审查和20%的提交消息存在幻觉，并提出多指标结合的方法显著提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 研究代码变更任务中语言模型的幻觉问题，填补现有研究的空白。

Method: 量化幻觉现象，探索基于指标的自动检测方法，结合模型置信度和特征归因指标。

Result: 50%的代码审查和20%的提交消息存在幻觉，多指标结合显著提升检测效果。

Conclusion: 多指标结合方法在幻觉检测中表现优越，模型置信度和特征归因指标具有潜力。

Abstract: Language models have shown strong capabilities across a wide range of tasks
in software engineering, such as code generation, yet they suffer from
hallucinations. While hallucinations have been studied independently in natural
language and code generation, their occurrence in tasks involving code changes
which have a structurally complex and context-dependent format of code remains
largely unexplored. This paper presents the first comprehensive analysis of
hallucinations in two critical tasks involving code change to natural language
generation: commit message generation and code review comment generation. We
quantify the prevalence of hallucinations in recent language models and explore
a range of metric-based approaches to automatically detect them. Our findings
reveal that approximately 50\% of generated code reviews and 20\% of generated
commit messages contain hallucinations. Whilst commonly used metrics are weak
detectors on their own, combining multiple metrics substantially improves
performance. Notably, model confidence and feature attribution metrics
effectively contribute to hallucination detection, showing promise for
inference-time detection.\footnote{All code and data will be released upon
acceptance.

</details>


### [6] [Description and Comparative Analysis of QuRE: A New Industrial Requirements Quality Dataset](https://arxiv.org/abs/2508.08868)
*Henning Femmer,Frank Houdek,Max Unterbusch,Andreas Vogelsang*

Main category: cs.SE

TL;DR: QuRE是一个包含2,111条工业需求的新数据集，通过真实评审过程标注，旨在提升需求质量研究的透明度和可比性。


<details>
  <summary>Details</summary>
Motivation: 需求质量对软件和系统工程至关重要，但现有数据集往往不完整或缺乏细节，限制了实证研究的发展。

Method: 引入QuRE数据集，提供描述性统计并与现有数据集和合成数据进行比较。

Result: QuRE在语言上与现有数据集相似，但具有更详细的上下文描述和长期工业应用背景。

Conclusion: QuRE的发布旨在推动需求质量研究的透明化和标准化，促进更严谨的合作研究。

Abstract: Requirements quality is central to successful software and systems
engineering. Empirical research on quality defects in natural language
requirements relies heavily on datasets, ideally as realistic and
representative as possible. However, such datasets are often inaccessible,
small, or lack sufficient detail. This paper introduces QuRE (Quality in
Requirements), a new dataset comprising 2,111 industrial requirements that have
been annotated through a real-world review process. Previously used for over
five years as part of an industrial contract, this dataset is now being
released to the research community. In this work, we furthermore provide
descriptive statistics on the dataset, including measures such as lexical
diversity and readability, and compare it to existing requirements datasets and
synthetically generated requirements. In contrast to synthetic datasets, QuRE
is linguistically similar to existing ones. However, this dataset comes with a
detailed context description, and its labels have been created and used
systematically and extensively in an industrial context over a period of close
to a decade. Our goal is to foster transparency, comparability, and empirical
rigor by supporting the development of a common gold standard for requirements
quality datasets. This, in turn, will enable more sound and collaborative
research efforts in the field.

</details>


### [7] [Empirical Analysis of Temporal and Spatial Fault Characteristics in Multi-Fault Bug Repositories](https://arxiv.org/abs/2508.08872)
*Dylan Callaghan,Alexandra van der Spuy,Bernd Fischer*

Main category: cs.SE

TL;DR: 论文分析了16个开源Java和Python项目中的软件故障时空特征，发现多数故障长期存在且版本中多故障共存，与原始数据集假设的单故障版本不同。此外，故障虽集中在少数系统部分，但分布均匀，热点较少。


<details>
  <summary>Details</summary>
Motivation: 降低软件维护和演化的成本需要理解软件故障的特征，但现有数据集假设与实际情况存在差异。

Method: 对Defects4J和BugsInPy数据集中的16个项目进行实证分析，研究故障的时空特性。

Result: 多数故障长期存在，版本中多故障共存；故障集中在少数系统部分但分布均匀，热点较少。

Conclusion: 研究揭示了软件故障的实际特征，挑战了原始数据集的假设，为优化测试和评估提供了新视角。

Abstract: Fixing software faults contributes significantly to the cost of software
maintenance and evolution. Techniques for reducing these costs require datasets
of software faults, as well as an understanding of the faults, for optimal
testing and evaluation. In this paper, we present an empirical analysis of the
temporal and spatial characteristics of faults existing in 16 open-source Java
and Python projects, which form part of the Defects4J and BugsInPy datasets,
respectively. Our findings show that many faults in these software systems are
long-lived, leading to the majority of software versions having multiple
coexisting faults. This is in contrast to the assumptions of the original
datasets, where the majority of versions only identify a single fault. In
addition, we show that although the faults are found in only a small subset of
the systems, these faults are often evenly distributed amongst this subset,
leading to relatively few bug hotspots.

</details>


### [8] [Toward Automated Hypervisor Scenario Generation Based on VM Workload Profiling for Resource-Constrained Environments](https://arxiv.org/abs/2508.08952)
*Hyunwoo Kim,Jaeseong Lee,Sunpyo Hong,Changmin Han*

Main category: cs.SE

TL;DR: 本文提出了一种自动化场景生成框架，帮助汽车厂商在多虚拟机环境中高效分配硬件资源，优化超管理器配置。


<details>
  <summary>Details</summary>
Motivation: 随着软件定义车辆（SDV）的兴起，汽车行业转向基于虚拟化的架构，但静态配置难以适应多样化的系统需求和工作负载。

Method: 通过分析运行时行为并结合理论模型和供应商启发式方法，开发工具生成优化的超管理器配置。比较了两种QoS建模方法：领域引导的参数化建模和深度学习建模。

Result: 实际部署表明，该框架显著提高了集成效率并减少了资源受限环境中的开发时间。

Conclusion: 提出的框架有效解决了静态配置的挑战，为汽车行业提供了高效的资源分配解决方案。

Abstract: In the automotive industry, the rise of software-defined vehicles (SDVs) has
  driven a shift toward virtualization-based architectures that consolidate
  diverse automotive workloads on a shared hardware platform. To support this
  evolution, chipset vendors provide board support packages (BSPs), hypervisor
  setups, and resource allocation guidelines. However, adapting these static
  configurations to varying system requirements and workloads remain a
  significant challenge for Tier 1 integrators.
  This paper presents an automated scenario generation framework, which helps
  automotive vendors to allocate hardware resources efficiently across multiple
  VMs. By profiling runtime behavior and integrating both theoretical models
and
  vendor heuristics, the proposed tool generates optimized hypervisor
  configurations tailored to system constraints.
  We compare two main approaches for modeling target QoS based on profiled data
  and resource allocation: domain-guided parametric modeling and deep
  learning-based modeling. We further describe our optimization strategy using
  the selected QoS model to derive efficient resource allocations. Finally, we
  report on real-world deployments to demonstrate the effectiveness of our
  framework in improving integration efficiency and reducing development time
in
  resource-constrained environments.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [9] [Selective KV-Cache Sharing to Mitigate Timing Side-Channels in LLM Inference](https://arxiv.org/abs/2508.08438)
*Kexin Chu,Zecheng Lin,Dawei Xiang,Zixu Shen,Jianchang Su,Cheng Chu,Yiwei Yang,Wenhui Zhang,Wenfei Wu,Wei Zhang*

Main category: cs.CR

TL;DR: SafeKV是一种隐私感知的KV缓存管理框架，通过选择性共享非敏感条目和隔离敏感内容，有效减少时间侧信道攻击，同时保持高性能。


<details>
  <summary>Details</summary>
Motivation: 全局KV缓存共享虽然加速了LLM推理，但引入了时间侧信道攻击风险，现有防御方法性能损失严重。

Method: SafeKV包含混合多级检测管道、统一基数树索引和基于熵的访问监控。

Result: SafeKV减少了94%-97%的攻击，TTFT提升40.58%，吞吐量提升2.66倍。

Conclusion: SafeKV在保持高性能的同时，提供了强大的运行时隐私保障。

Abstract: Global KV-cache sharing has emerged as a key optimization for accelerating
large language model (LLM) inference. However, it exposes a new class of timing
side-channel attacks, enabling adversaries to infer sensitive user inputs via
shared cache entries. Existing defenses, such as per-user isolation, eliminate
leakage but degrade performance by up to 38.9% in time-to-first-token (TTFT),
making them impractical for high-throughput deployment. To address this gap, we
introduce SafeKV (Secure and Flexible KV Cache Sharing), a privacy-aware
KV-cache management framework that selectively shares non-sensitive entries
while confining sensitive content to private caches. SafeKV comprises three
components: (i) a hybrid, multi-tier detection pipeline that integrates
rule-based pattern matching, a general-purpose privacy detector, and
context-aware validation; (ii) a unified radix-tree index that manages public
and private entries across heterogeneous memory tiers (HBM, DRAM, SSD); and
(iii) entropy-based access monitoring to detect and mitigate residual
information leakage. Our evaluation shows that SafeKV mitigates 94% - 97% of
timing-based side-channel attacks. Compared to per-user isolation method,
SafeKV improves TTFT by up to 40.58% and throughput by up to 2.66X across
diverse LLMs and workloads. SafeKV reduces cache-induced TTFT overhead from
50.41% to 11.74% on Qwen3-235B. By combining fine-grained privacy control with
high cache reuse efficiency, SafeKV reclaims the performance advantages of
global sharing while providing robust runtime privacy guarantees for LLM
inference.

</details>


### [10] [Designing with Deception: ML- and Covert Gate-Enhanced Camouflaging to Thwart IC Reverse Engineering](https://arxiv.org/abs/2508.08462)
*Junling Fan,David Koblah,Domenic Forte*

Main category: cs.CR

TL;DR: 提出了一种基于机器学习的集成电路（IC）伪装方法，通过功能保留和外观模仿实现双重伪装，有效抵御物理逆向工程攻击。


<details>
  <summary>Details</summary>
Motivation: 现有IC伪装技术主要关注局部门修改，缺乏全面的欺骗策略，无法全面保护知识产权和系统安全。

Method: 采用And-Inverter Graph Variational Autoencoder（AIG-VAE）编码电路表示，引入新型伪装门（如假反相器、假缓冲器和通用发射器）实现功能隐藏和外观误导。

Result: 实验表明，该方法在保持电路功能的同时，实现了高伪装和相似性评分，且结构开销最小，并能抵御AI增强的逆向工程攻击。

Conclusion: 该方法填补了硬件安全中模仿欺骗的空白，为IC伪装设定了新标准，推动了网络欺骗原则在保护关键系统中的应用。

Abstract: Integrated circuits (ICs) are essential to modern electronic systems, yet
they face significant risks from physical reverse engineering (RE) attacks that
compromise intellectual property (IP) and overall system security. While IC
camouflage techniques have emerged to mitigate these risks, existing approaches
largely focus on localized gate modifications, neglecting comprehensive
deception strategies. To address this gap, we present a machine learning
(ML)-driven methodology that integrates cryptic and mimetic cyber deception
principles to enhance IC security against RE. Our approach leverages a novel
And-Inverter Graph Variational Autoencoder (AIG-VAE) to encode circuit
representations, enabling dual-layered camouflage through functional
preservation and appearance mimicry. By introducing new variants of covert
gates -- Fake Inverters, Fake Buffers, and Universal Transmitters -- our
methodology achieves robust protection by obscuring circuit functionality while
presenting misleading appearances. Experimental results demonstrate the
effectiveness of our strategy in maintaining circuit functionality while
achieving high camouflage and similarity scores with minimal structural
overhead. Additionally, we validate the robustness of our method against
advanced artificial intelligence (AI)-enhanced RE attacks, highlighting its
practical applicability in securing IC designs. By bridging the gap in mimetic
deception for hardware security, our work sets a new standard for IC
camouflage, advancing the application of cyber deception principles to protect
critical systems from adversarial threats.

</details>


### [11] [AI Security Map: Holistic Organization of AI Security Technologies and Impacts on Stakeholders](https://arxiv.org/abs/2508.08583)
*Hiroya Kato,Kentaro Kita,Kento Hasegawa,Seira Hidano*

Main category: cs.CR

TL;DR: 本文提出了一种AI安全地图，全面组织AI安全相关元素及其对信息系统和利益相关者的负面影响，帮助理解它们之间的关系。


<details>
  <summary>Details</summary>
Motivation: 现有研究局限于特定领域或AI元素，难以理解AI安全相关技术、攻击、防御和风险之间的关系及其对利益相关者的负面影响。

Method: 开发了一个AI安全地图，分为信息系统方面（ISA）和外部影响方面（EIA），分类并识别各元素的负面影响。

Result: 通过地图可以理解潜在负面影响及其原因和应对措施，并明确AI系统对利益相关者的影响关系。

Conclusion: AI安全地图为未来研究提供了新视角和建议，并提出了开放性问题。

Abstract: As the social implementation of AI has been steadily progressing, research
and development related to AI security has also been increasing. However,
existing studies have been limited to organizing related techniques, attacks,
defenses, and risks in terms of specific domains or AI elements. Thus, it
extremely difficult to understand the relationships among them and how negative
impacts on stakeholders are brought about. In this paper, we argue that the
knowledge, technologies, and social impacts related to AI security should be
holistically organized to help understand relationships among them. To this
end, we first develop an AI security map that holistically organizes
interrelationships among elements related to AI security as well as negative
impacts on information systems and stakeholders. This map consists of the two
aspects, namely the information system aspect (ISA) and the external influence
aspect (EIA). The elements that AI should fulfill within information systems
are classified under the ISA. The EIA includes elements that affect
stakeholders as a result of AI being attacked or misused. For each element,
corresponding negative impacts are identified. By referring to the AI security
map, one can understand the potential negative impacts, along with their causes
and countermeasures. Additionally, our map helps clarify how the negative
impacts on AI-based systems relate to those on stakeholders. We show some
findings newly obtained by referring to our map. We also provide several
recommendations and open problems to guide future AI security communities.

</details>


### [12] [Generative AI for Critical Infrastructure in Smart Grids: A Unified Framework for Synthetic Data Generation and Anomaly Detection](https://arxiv.org/abs/2508.08593)
*Aydin Zaboli,Junho Hong*

Main category: cs.CR

TL;DR: 本文提出了一种基于生成式AI（GenAI）的异常检测系统（ADS），用于解决IEC61850数字变电站中的网络安全挑战，特别是针对GOOSE协议的漏洞。通过先进的对抗流量变异（AATM）技术生成合成数据集，并结合任务导向对话（ToD）过程，显著提升了攻击模式的检测能力。


<details>
  <summary>Details</summary>
Motivation: 数字变电站中的网络安全事件对电力系统的持续运行构成重大威胁，传统异常检测系统（ADSs）在检测威胁方面存在局限性。因此，需要一种更强大的方法来应对这些挑战。

Method: 提出了一种基于生成式AI（GenAI）的ADS，利用AATM技术生成合成数据集，并结合ToD过程改进攻击模式检测。

Result: GenAI-based ADS在性能评估中优于传统的基于机器学习的ADS，尤其是在检测零日攻击模式方面表现突出。

Conclusion: GenAI-based ADS为解决数字变电站中的网络安全挑战提供了一种有效的解决方案，尤其是在数据稀缺和协议合规性方面表现出色。

Abstract: In digital substations, security events pose significant challenges to the
sustained operation of power systems. To mitigate these challenges, the
implementation of robust defense strategies is critically important. A thorough
process of anomaly identification and detection in information and
communication technology (ICT) frameworks is crucial to ensure secure and
reliable communication and coordination between interconnected devices within
digital substations. Hence, this paper addresses the critical cybersecurity
challenges confronting IEC61850-based digital substations within modern smart
grids, where the integration of advanced communication protocols, e.g., generic
object-oriented substation event (GOOSE), has enhanced energy management and
introduced significant vulnerabilities to cyberattacks. Focusing on the
limitations of traditional anomaly detection systems (ADSs) in detecting
threats, this research proposes a transformative approach by leveraging
generative AI (GenAI) to develop robust ADSs. The primary contributions include
the suggested advanced adversarial traffic mutation (AATM) technique to
generate synthesized and balanced datasets for GOOSE messages, ensuring
protocol compliance and enabling realistic zero-day attack pattern creation to
address data scarcity. Then, the implementation of GenAI-based ADSs
incorporating the task-oriented dialogue (ToD) processes has been explored for
improved detection of attack patterns. Finally, a comparison of the GenAI-based
ADS with machine learning (ML)-based ADSs has been implemented to showcase the
outperformance of the GenAI-based frameworks considering the AATM-generated
GOOSE datasets and standard/advanced performance evaluation metrics.

</details>


### [13] [Hypervisor-based Double Extortion Ransomware Detection Method Using Kitsune Network Features](https://arxiv.org/abs/2508.08655)
*Manabu Hirano,Ryotaro Kobayashi*

Main category: cs.CR

TL;DR: 本文提出了一种针对双重勒索勒索软件攻击的检测方法，结合低级存储、内存行为特征和网络流量特征，利用轻量级Kitsune NIDS检测数据外泄阶段，实验表明检测率提高了0.166。


<details>
  <summary>Details</summary>
Motivation: 由于组织采用更强大的数据备份策略对抗传统加密勒索软件，双重勒索攻击成为主流，需要新的检测方法。

Method: 使用低级存储和内存行为特征、网络流量特征，结合轻量级Kitsune NIDS检测数据外泄阶段。

Result: 实验结果显示，数据外泄阶段的检测率提高了0.166（宏F分数）。

Conclusion: 本文方法有效提升了双重勒索攻击的检测能力，但仍存在局限性，未来需进一步改进。

Abstract: Double extortion ransomware attacks have become mainstream since many
organizations adopt more robust and resilient data backup strategies against
conventional crypto-ransomware. This paper presents detailed attack stages,
tactics, procedures, and tools used in the double extortion ransomware attacks.
We then present a novel detection method using low-level storage and memory
behavioral features and network traffic features obtained from a thin
hypervisor to establish a defense-in-depth strategy for when attackers
compromise OS-level protection. We employed the lightweight \emph{Kitsune}
Network Intrusion Detection System (NIDS)'s network feature to detect the data
exfiltration phase in double extortion ransomware attacks. Our experimental
results showed that the presented method improved by 0.166 in the macro F score
of the data exfiltration phase detection rate. Lastly, we discuss the
limitations of the presented method and future work.

</details>


### [14] [Evasive Ransomware Attacks Using Low-level Behavioral Adversarial Examples](https://arxiv.org/abs/2508.08656)
*Manabu Hirano,Ryotaro Kobayashi*

Main category: cs.CR

TL;DR: 论文提出低层行为对抗样本概念，研究勒索软件如何通过微行为控制函数生成对抗样本以逃避检测。


<details>
  <summary>Details</summary>
Motivation: 保护基于AI的网络安全防御系统免受攻击，尤其是对抗样本攻击。

Method: 提出低层行为对抗样本概念，利用微行为控制函数模拟勒索软件行为变化，生成对抗样本。

Result: 通过Conti勒索软件泄露代码验证，攻击者可通过控制行为特征降低检测率。

Conclusion: 勒索软件可通过行为调整生成对抗样本，威胁AI防御系统。

Abstract: Protecting state-of-the-art AI-based cybersecurity defense systems from cyber
attacks is crucial. Attackers create adversarial examples by adding small
changes (i.e., perturbations) to the attack features to evade or fool the deep
learning model. This paper introduces the concept of low-level behavioral
adversarial examples and its threat model of evasive ransomware. We formulate
the method and the threat model to generate the optimal source code of evasive
malware. We then examine the method using the leaked source code of Conti
ransomware with the micro-behavior control function. The micro-behavior control
function is our test component to simulate changing source code in ransomware;
ransomware's behavior can be changed by specifying the number of threads, file
encryption ratio, and delay after file encryption at the boot time. We
evaluated how much an attacker can control the behavioral features of
ransomware using the micro-behavior control function to decrease the detection
rate of a ransomware detector.

</details>


### [15] [Approximate DBSCAN under Differential Privacy](https://arxiv.org/abs/2508.08749)
*Yuan Qiu,Ke Yi*

Main category: cs.CR

TL;DR: 本文重新审视了差分隐私（DP）下的DBSCAN问题，提出了一种基于“spans”的新定义，并设计了一个线性时间的DP-DBSCAN算法，具有理论和实践优势。


<details>
  <summary>Details</summary>
Motivation: 现有DP-DBSCAN算法在发布聚类标签时缺乏实用性，因此需要一种更有效的方法来支持可视化和分类任务。

Method: 提出基于“spans”的DP-DBSCAN定义，并开发了一个线性时间算法，满足纯DP要求，同时提供理论保证。

Result: 算法在理论和实验中均表现出色，匹配了近似比的下界，并在合成和真实数据集上验证了其性能。

Conclusion: 基于“spans”的DP-DBSCAN定义和算法优于现有方法，更适合实际应用。

Abstract: This paper revisits the DBSCAN problem under differential privacy (DP).
Existing DP-DBSCAN algorithms aim at publishing the cluster labels of the input
points. However, we show that both empirically and theoretically, this approach
cannot offer any utility in the published results. We therefore propose an
alternative definition of DP-DBSCAN based on the notion of spans. We argue that
publishing the spans actually better serves the purposes of visualization and
classification of DBSCAN. Then we present a linear-time DP-DBSCAN algorithm
achieving the sandwich quality guarantee in any constant dimensions, as well as
matching lower bounds on the approximation ratio. A key building block in our
algorithm is a linear-time algorithm for constructing a histogram under
pure-DP, which is of independent interest. Finally, we conducted experiments on
both synthetic and real-world datasets to verify the practical performance of
our DP-DBSCAN algorithm.

</details>


### [16] [Never Compromise to Vulnerabilities: A Comprehensive Survey on AI Governance](https://arxiv.org/abs/2508.08789)
*Yuchu Jiang,Jian Zhao,Yuchen Yuan,Tianle Zhang,Yao Huang,Yanghao Zhang,Yan Wang,Yanshu Li,Xizhong Guo,Yusheng Zhao,Jun Zhang,Zhi Zhang,Xiaojian Lin,Yixiu Zou,Haoxuan Ma,Yuhu Shang,Yuzhi Hu,Keshu Cai,Ruochen Zhang,Boyuan Chen,Yilan Gao,Ziheng Jiao,Yi Qin,Shuangjun Du,Xiao Tong,Zhekun Liu,Yu Chen,Xuankun Rong,Rui Wang,Yejie Zheng,Zhaoxin Fan,Hongyuan Zhang,Pan Zhou,Lei Jin,Hao Zhao,Xu Yang,Jiaojiao Zhao,Jianshu Li,Joey Tianyi Zhou,Zhi-Qi Cheng,Longtao Huang,Zhiyi Liu,Zheng Zhu,Jianan Li,Gang Wang,Qi Li,Xu-Yao Zhang,Yaodong Yang,Mang Ye,Wenqi Ren,Zhaofeng He,Hang Su,Rongrong Ni,Liping Jing,Xingxing Wei,Junliang Xing,Massimo Alioto,Shengmei Shen,Petia Radeva,Dacheng Tao,Ya-Qin Zhang,Shuicheng Yan,Chi Zhang,Zhongjiang He,Xuelong Li*

Main category: cs.CR

TL;DR: 论文提出一个综合框架，整合技术与社会维度，围绕三个支柱（内在安全、衍生安全和社会伦理）解决AI治理的挑战。


<details>
  <summary>Details</summary>
Motivation: AI快速发展带来技术漏洞（如算法偏见和对抗敏感性），引发社会风险（如错误信息和不公平），亟需强有力的AI治理。

Method: 通过系统综述300多项研究，提出一个统一技术方法、评估基准和政策见解的框架，涵盖内在安全、衍生安全和社会伦理。

Result: 识别三大核心挑战：泛化差距、评估不足和监管碎片化，并提出整合技术严谨性与社会责任的研究议程。

Conclusion: 框架为研究者、工程师和政策制定者提供行动指南，开发既稳健安全又符合伦理的AI系统。

Abstract: The rapid advancement of AI has expanded its capabilities across domains, yet
introduced critical technical vulnerabilities, such as algorithmic bias and
adversarial sensitivity, that pose significant societal risks, including
misinformation, inequity, security breaches, physical harm, and eroded public
trust. These challenges highlight the urgent need for robust AI governance. We
propose a comprehensive framework integrating technical and societal
dimensions, structured around three interconnected pillars: Intrinsic Security
(system reliability), Derivative Security (real-world harm mitigation), and
Social Ethics (value alignment and accountability). Uniquely, our approach
unifies technical methods, emerging evaluation benchmarks, and policy insights
to promote transparency, accountability, and trust in AI systems. Through a
systematic review of over 300 studies, we identify three core challenges: (1)
the generalization gap, where defenses fail against evolving threats; (2)
inadequate evaluation protocols that overlook real-world risks; and (3)
fragmented regulations leading to inconsistent oversight. These shortcomings
stem from treating governance as an afterthought, rather than a foundational
design principle, resulting in reactive, siloed efforts that fail to address
the interdependence of technical integrity and societal trust. To overcome
this, we present an integrated research agenda that bridges technical rigor
with social responsibility. Our framework offers actionable guidance for
researchers, engineers, and policymakers to develop AI systems that are not
only robust and secure but also ethically aligned and publicly trustworthy. The
accompanying repository is available at
https://github.com/ZTianle/Awesome-AI-SG.

</details>


### [17] [Image selective encryption analysis using mutual information in CNN based embedding space](https://arxiv.org/abs/2508.08832)
*Ikram Messadi,Giulia Cervia,Vincent Itier*

Main category: cs.CR

TL;DR: 该论文探讨了图像数据中的信息泄漏问题，提出使用互信息（MI）估计器（如经验估计器和MINE框架）来检测选择性加密图像中的泄漏。


<details>
  <summary>Details</summary>
Motivation: 随着数字数据传输规模的扩大，隐私问题日益紧迫，但隐私仍是一个社会构建且模糊的概念，缺乏普遍接受的定量测量。

Method: 结合深度学习、信息论和密码学，研究互信息（MI）估计器在检测图像信息泄漏中的应用。

Result: 研究表明，稳健的估计器需要能够捕捉空间依赖性和残差结构的概率框架。

Conclusion: 这项工作为图像信息泄漏估计提供了一个有前景的方向。

Abstract: As digital data transmission continues to scale, concerns about privacy grow
increasingly urgent - yet privacy remains a socially constructed and
ambiguously defined concept, lacking a universally accepted quantitative
measure. This work examines information leakage in image data, a domain where
information-theoretic guarantees are still underexplored. At the intersection
of deep learning, information theory, and cryptography, we investigate the use
of mutual information (MI) estimators - in particular, the empirical estimator
and the MINE framework - to detect leakage from selectively encrypted images.
Motivated by the intuition that a robust estimator would require a
probabilistic frameworks that can capture spatial dependencies and residual
structures, even within encrypted representations - our work represent a
promising direction for image information leakage estimation.

</details>


### [18] [EditMF: Drawing an Invisible Fingerprint for Your Large Language Models](https://arxiv.org/abs/2508.08836)
*Jiaxuan Wu,Yinghan Zhou,Wanli Peng,Yiming Xue,Juan Wen,Ping Zhong*

Main category: cs.CR

TL;DR: EditMF是一种无需训练的指纹嵌入方法，通过加密知识库中的语义三元组实现高效且隐蔽的模型所有权验证。


<details>
  <summary>Details</summary>
Motivation: 保护大型语言模型（LLM）的知识产权（IP）是资源密集型且昂贵的，现有方法在隐蔽性和效率上存在不足。

Method: 利用加密的人工知识库中的语义三元组，通过因果追踪和零空间更新实现指纹嵌入，验证仅需单次黑盒查询。

Result: 在LLaMA和Qwen模型上，EditMF表现出高隐蔽性、性能损失极小，且鲁棒性远超LoRA指纹。

Conclusion: EditMF是一种高效、低开销的LLM所有权验证解决方案。

Abstract: Training large language models (LLMs) is resource-intensive and expensive,
making protecting intellectual property (IP) for LLMs crucial. Recently,
embedding fingerprints into LLMs has emerged as a prevalent method for
establishing model ownership. However, existing back-door-based methods suffer
from limited stealth and efficiency. To simultaneously address these issues, we
propose EditMF, a training-free fingerprinting paradigm that achieves highly
imperceptible fingerprint embedding with minimal computational overhead.
Ownership bits are mapped to compact, semantically coherent triples drawn from
an encrypted artificial knowledge base (e.g., virtual author-novel-protagonist
facts). Causal tracing localizes the minimal set of layers influencing each
triple, and a zero-space update injects the fingerprint without perturbing
unrelated knowledge. Verification requires only a single black-box query and
succeeds when the model returns the exact pre-embedded protagonist. Empirical
results on LLaMA and Qwen families show that EditMF combines high
imperceptibility with negligible model's performance loss, while delivering
robustness far beyond LoRA-based fingerprinting and approaching that of SFT
embeddings. Extensive experiments demonstrate that EditMF is an effective and
low-overhead solution for secure LLM ownership verification.

</details>


### [19] [Redactable Blockchains: An Overview](https://arxiv.org/abs/2508.08898)
*Federico Calandra,Marco Bernardo,Andrea Esposito,Francesco Fabris*

Main category: cs.CR

TL;DR: 报告探讨了可编辑区块链的必要性，介绍了实现安全编辑的密码学方法，并分析了不同方案的优缺点，特别关注了在私有环境中的实际应用。


<details>
  <summary>Details</summary>
Motivation: 传统区块链的不可变性在需要合规性、错误修正或敏感信息删除的实际场景中带来挑战，可编辑区块链通过可控修改解决了这些问题。

Method: 主要利用变色龙哈希函数和其他编辑方案实现区块链数据的可控修改。

Result: 报告总结了可编辑区块链在医疗、金融、无人机网络和联邦学习等领域的应用潜力。

Conclusion: 可编辑区块链在构建合规、可信和可扩展的数字基础设施方面具有未来潜力，但仍需解决与可逆计算相关的挑战。

Abstract: Blockchains are widely recognized for their immutability, which provides
robust guarantees of data integrity and transparency. However, this same
feature poses significant challenges in real-world situations that require
regulatory compliance, correction of erroneous data, or removal of sensitive
information. Redactable blockchains address the limitations of traditional ones
by enabling controlled, auditable modifications to blockchain data, primarily
through cryptographic mechanisms such as chameleon hash functions and
alternative redaction schemes. This report examines the motivations for
introducing redactability, surveys the cryptographic primitives that enable
secure edits, and analyzes competing approaches and their shortcomings. Special
attention is paid to the practical deployment of redactable blockchains in
private settings, with discussions of use cases in healthcare, finance,
Internet of drones, and federated learning. Finally, the report outlines
further challenges, also in connection with reversible computing, and the
future potential of redactable blockchains in building law-compliant,
trustworthy, and scalable digital infrastructures.

</details>


### [20] [Load-Altering Attacks Against Power Grids: A Case Study Using the GB-36 Bus System Open Dataset](https://arxiv.org/abs/2508.08945)
*Syed Irtiza Maksud,Subhash Lakshminarayana*

Main category: cs.CR

TL;DR: 本文研究了负载改变攻击（LAA）对电网的影响，利用开源数据集和实际电网模型（GB-36 Zone）评估了攻击阈值及电池储能系统（BESS）的缓解效果。


<details>
  <summary>Details</summary>
Motivation: 随着物联网设备的普及，电网面临更多网络威胁，尤其是LAA可能导致电网频率波动甚至崩溃。本文旨在填补学术研究与实际应用之间的空白。

Method: 使用DIgSILENT PowerFactory进行仿真，分析LAA在不同场景下的影响，并评估BESS的快速频率响应能力。

Result: 研究确定了电网对LAA的容忍阈值，并发现BESS的位置和攻击执行延迟对系统响应有显著影响。

Conclusion: BESS能有效缓解LAA影响，研究结果为电网运营商提供了实用见解。

Abstract: The growing digitalization and the rapid adoption of high-powered
Internet-of-Things (IoT)-enabled devices (e.g., EV charging stations) have
increased the vulnerability of power grids to cyber threats. In particular, the
so-called Load Altering Attacks (LAAs) can trigger rapid frequency fluctuations
and potentially destabilize the power grid. This paper aims to bridge the gap
between academic research and practical application by using open-source
datasets released by grid operators. It investigates various LAA scenarios on a
real-world transmission network, namely the Great Britain (GB)-36 Zone model
released by the UK's National Electricity System Operator (NESO). It evaluates
the threshold of LAA severity that the grid can tolerate before triggering
cascading effects. Additionally, it explores how Battery Energy Storage Systems
(BESS) based fast frequency response services can mitigate or prevent such
impacts. Simulations are conducted using DIgSILENT PowerFactory to ensure
realistic system representation. The analysis provides several useful insights
to grid operators on the LAA impact, such as the influence of the relative
locations of BESS and LAA, as well as how delays in attack execution can
influence the overall system response.

</details>


### [21] [Attacks and Defenses Against LLM Fingerprinting](https://arxiv.org/abs/2508.09021)
*Kevin Kurian,Ethan Holland,Sean Oesch*

Main category: cs.CR

TL;DR: 论文研究了大型语言模型（LLM）的指纹攻击与防御，提出基于强化学习的攻击方法和语义保持的输出过滤防御策略。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在敏感环境中的部署增加，指纹攻击对隐私和安全构成威胁，研究旨在提升攻击能力并提供防御方案。

Method: 攻击方法使用强化学习优化查询选择；防御方法通过次级LLM进行语义保持的输出过滤。

Result: 攻击方法仅需3次查询即可提高指纹识别准确率；防御方法在保持输出质量的同时降低了指纹识别准确率。

Conclusion: 研究展示了提升指纹工具能力的潜力，并提供了实用的防御策略。

Abstract: As large language models are increasingly deployed in sensitive environments,
fingerprinting attacks pose significant privacy and security risks. We present
a study of LLM fingerprinting from both offensive and defensive perspectives.
Our attack methodology uses reinforcement learning to automatically optimize
query selection, achieving better fingerprinting accuracy with only 3 queries
compared to randomly selecting 3 queries from the same pool. Our defensive
approach employs semantic-preserving output filtering through a secondary LLM
to obfuscate model identity while maintaining semantic integrity. The defensive
method reduces fingerprinting accuracy across tested models while preserving
output quality. These contributions show the potential to improve
fingerprinting tools capabilities while providing practical mitigation
strategies against fingerprinting attacks.

</details>


### [22] [Developing a Transferable Federated Network Intrusion Detection System](https://arxiv.org/abs/2508.09060)
*Abu Shafin Mohammad Mahdee Jameel,Shreya Ghosh,Aly El Gamal*

Main category: cs.CR

TL;DR: 提出了一种基于深度学习的分布式入侵检测系统，通过最大化已知攻击知识的可迁移性关系，提升对未知攻击的检测能力。


<details>
  <summary>Details</summary>
Motivation: 提升深度学习模型对未知攻击的检测能力，利用已知攻击知识增强模型的可迁移性。

Method: 采用卷积神经网络（CNN）模型，结合两步数据预处理和块基智能聚合（BBSA）算法，最大化可迁移性关系。

Result: 系统在保持高本地检测率的同时，表现出卓越的可迁移性能，且方法具有通用性。

Conclusion: 提出的方法在入侵检测中表现出高效的可迁移性和通用性，适用于不同数据集和模型架构。

Abstract: Intrusion Detection Systems (IDS) are a vital part of a network-connected
device. In this paper, we develop a deep learning based intrusion detection
system that is deployed in a distributed setup across devices connected to a
network. Our aim is to better equip deep learning models against unknown
attacks using knowledge from known attacks. To this end, we develop algorithms
to maximize the number of transferability relationships. We propose a
Convolutional Neural Network (CNN) model, along with two algorithms that
maximize the number of relationships observed. One is a two step data
pre-processing stage, and the other is a Block-Based Smart Aggregation (BBSA)
algorithm. The proposed system succeeds in achieving superior transferability
performance while maintaining impressive local detection rates. We also show
that our method is generalizable, exhibiting transferability potential across
datasets and even with different backbones. The code for this work can be found
at https://github.com/ghosh64/tabfidsv2.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [23] [Topos Theory for Generative AI and LLMs](https://arxiv.org/abs/2508.08293)
*Sridhar Mahadevan*

Main category: cs.AI

TL;DR: 论文提出了一种基于拓扑理论的新型生成式AI架构（GAIAs），利用范畴论的通用构造方法设计新的LLM组合结构，并证明LLM范畴是一个拓扑。


<details>
  <summary>Details</summary>
Motivation: 现有LLM研究多关注线性架构或专家混合模型，而论文旨在通过范畴论的通用性质探索新的组合结构，以提升LLM的表达能力。

Method: 利用范畴论的通用构造（如拉回、推出、指数对象等）设计新的LLM架构，并通过理论证明LLM范畴的完备性和拓扑性质。

Result: 证明了LLM范畴是完备的且构成一个拓扑，支持新的组合结构设计，并通过反向传播的函子化描述提供了潜在实现方案。

Conclusion: 通过范畴论方法，论文为LLM设计提供了新的理论框架和架构可能性，扩展了生成式AI的研究方向。

Abstract: We propose the design of novel categorical generative AI architectures
(GAIAs) using topos theory, a type of category that is ``set-like": a topos has
all (co)limits, is Cartesian closed, and has a subobject classifier. Previous
theoretical results on the Transformer model have shown that it is a universal
sequence-to-sequence function approximator, and dense in the space of all
continuous functions with compact support on the Euclidean space of embeddings
of tokens. Building on this theoretical result, we explore novel architectures
for LLMs that exploit the property that the category of LLMs, viewed as
functions, forms a topos. Previous studies of large language models (LLMs) have
focused on daisy-chained linear architectures or mixture-of-experts. In this
paper, we use universal constructions in category theory to construct novel LLM
architectures based on new types of compositional structures. In particular,
these new compositional structures are derived from universal properties of LLM
categories, and include pullback, pushout, (co) equalizers, exponential
objects, and subobject classifiers. We theoretically validate these new
compositional structures by showing that the category of LLMs is (co)complete,
meaning that all diagrams have solutions in the form of (co)limits. Building on
this completeness result, we then show that the category of LLMs forms a topos,
a ``set-like" category, which requires showing the existence of exponential
objects as well as subobject classifiers. We use a functorial characterization
of backpropagation to define a potential implementation of an LLM topos
architecture.

</details>


### [24] [Topos Causal Models](https://arxiv.org/abs/2508.08295)
*Sridhar Mahadevan*

Main category: cs.AI

TL;DR: 本文提出了一种新的因果模型类别——拓扑因果模型（TCMs），利用拓扑范畴的关键性质（如完备性、子对象分类器和指数对象），展示了这些性质在因果推断中的重要性。


<details>
  <summary>Details</summary>
Motivation: 旨在通过拓扑范畴的性质（如子对象分类器、极限和指数对象）为因果推断提供更强大的数学工具，解决复杂因果图的建模和近似问题。

Method: 定义了TCMs，利用拓扑范畴的性质（如子对象分类器、极限和指数对象）构建因果模型，并通过自然变换衡量近似质量。

Result: 证明了TCMs的范畴是完备的，任何因果图都可以通过极限或余极限“求解”，且因果干预和等价类操作可通过子对象分类器和指数对象实现。

Conclusion: TCMs为因果推断提供了强大的数学框架，支持复杂因果图的建模、干预和等价类推理，并通过内部逻辑扩展了因果模型的形式化表达能力。

Abstract: We propose topos causal models (TCMs), a novel class of causal models that
exploit the key properties of a topos category: they are (co)complete, meaning
all (co)limits exist, they admit a subobject classifier, and allow exponential
objects. The main goal of this paper is to show that these properties are
central to many applications in causal inference. For example, subobject
classifiers allow a categorical formulation of causal intervention, which
creates sub-models. Limits and colimits allow causal diagrams of arbitrary
complexity to be ``solved", using a novel interpretation of causal
approximation. Exponential objects enable reasoning about equivalence classes
of operations on causal models, such as covered edge reversal and causal
homotopy. Analogous to structural causal models (SCMs), TCMs are defined by a
collection of functions, each defining a ``local autonomous" causal mechanism
that assemble to induce a unique global function from exogenous to endogenous
variables. Since the category of TCMs is (co)complete, which we prove in this
paper, every causal diagram has a ``solution" in the form of a (co)limit: this
implies that any arbitrary causal model can be ``approximated" by some global
function with respect to the morphisms going into or out of the diagram.
Natural transformations are crucial in measuring the quality of approximation.
In addition, we show that causal interventions are modeled by subobject
classifiers: any sub-model is defined by a monic arrow into its parent model.
Exponential objects permit reasoning about entire classes of causal
equivalences and interventions. Finally, as TCMs form a topos, they admit an
internal logic defined as a Mitchell-Benabou language with an associated
Kripke-Joyal semantics. We show how to reason about causal models in TCMs using
this internal logic.

</details>


### [25] [An Efficient Application of Goal Programming to Tackle Multiobjective Problems with Recurring Fitness Landscapes](https://arxiv.org/abs/2508.08297)
*Rodrigo Lankaites Pinheiro,Dario Landa-Silva,Wasakorn Laesanklang,Ademir Aparecido Constantino*

Main category: cs.AI

TL;DR: 提出一种方法，利用多目标算法解决一个问题实例，再用目标规划解决其他类似实例，以高效获得近似解。


<details>
  <summary>Details</summary>
Motivation: 解决高度约束多目标问题中近似解获取困难的问题，利用问题实例间相似性提高效率。

Method: 先用计算密集型多目标算法解决一个实例，再用目标规划和单目标算法解决其他实例。

Result: 在多目标车辆路径问题中，该方法能在短时间内产生良好结果。

Conclusion: 结合多目标算法和目标规划，可在相似问题实例中高效找到折中解。

Abstract: Many real-world applications require decision-makers to assess the quality of
solutions while considering multiple conflicting objectives. Obtaining good
approximation sets for highly constrained many-objective problems is often a
difficult task even for modern multiobjective algorithms. In some cases,
multiple instances of the problem scenario present similarities in their
fitness landscapes. That is, there are recurring features in the fitness
landscapes when searching for solutions to different problem instances. We
propose a methodology to exploit this characteristic by solving one instance of
a given problem scenario using computationally expensive multiobjective
algorithms to obtain a good approximation set and then using Goal Programming
with efficient single-objective algorithms to solve other instances of the same
problem scenario. We use three goal-based objective functions and show that on
benchmark instances of the multiobjective vehicle routing problem with time
windows, the methodology is able to produce good results in short computation
time. The methodology allows to combine the effectiveness of state-of-the-art
multiobjective algorithms with the efficiency of goal programming to find good
compromise solutions in problem scenarios where instances have similar fitness
landscapes.

</details>


### [26] [LLM-BI: Towards Fully Automated Bayesian Inference with Large Language Models](https://arxiv.org/abs/2508.08300)
*Yongchao Huang*

Main category: cs.AI

TL;DR: 论文探讨了利用大型语言模型（LLM）自动化贝叶斯推断流程的可行性，提出LLM-BI框架，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯推断的广泛应用受到先验分布和似然函数设定复杂性的限制，需要专业统计知识。本文旨在探索LLM能否自动化这一过程。

Method: 提出LLM-BI框架，通过两个实验验证：实验I展示LLM能从自然语言中提取先验分布；实验II展示LLM能从高层问题描述中指定完整模型结构。

Result: 实验结果表明，LLM能成功自动化贝叶斯建模的关键步骤，为概率编程的自动化推断流程提供了可能。

Conclusion: LLM在自动化贝叶斯推断中具有潜力，LLM-BI框架为简化复杂统计建模提供了新方向。

Abstract: A significant barrier to the widespread adoption of Bayesian inference is the
specification of prior distributions and likelihoods, which often requires
specialized statistical expertise. This paper investigates the feasibility of
using a Large Language Model (LLM) to automate this process. We introduce
LLM-BI (Large Language Model-driven Bayesian Inference), a conceptual pipeline
for automating Bayesian workflows. As a proof-of-concept, we present two
experiments focused on Bayesian linear regression. In Experiment I, we
demonstrate that an LLM can successfully elicit prior distributions from
natural language. In Experiment II, we show that an LLM can specify the entire
model structure, including both priors and the likelihood, from a single
high-level problem description. Our results validate the potential of LLMs to
automate key steps in Bayesian modeling, enabling the possibility of an
automated inference pipeline for probabilistic programming.

</details>


### [27] [First Ask Then Answer: A Framework Design for AI Dialogue Based on Supplementary Questioning with Large Language Models](https://arxiv.org/abs/2508.08308)
*Chuanruo Fu,Yuncheng Du*

Main category: cs.AI

TL;DR: 论文提出了一种名为FATA的新交互范式，通过引导LLMs主动生成多维补充问题，显著提升回答质量和相关性。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在用户信息不完整或模糊时回答不准确的问题。

Method: 采用FATA范式，通过提示词引导LLMs生成补充问题，整合用户反馈后生成回答。

Result: FATA在综合指标上优于基线提示40%，且稳定性更高。

Conclusion: FATA通过用户参与和单轮策略，显著提升了LLMs的交互效果。

Abstract: Large Language Models (LLMs) often struggle to deliver accurate and
actionable answers when user-provided information is incomplete or
ill-specified. We propose a new interaction paradigm, First Ask Then Answer
(FATA), in which, through prompt words, LLMs are guided to proactively generate
multidimensional supplementary questions for users prior to response
generation. Subsequently, by integrating user-provided supplementary
information with the original query through sophisticated prompting techniques,
we achieve substantially improved response quality and relevance. In contrast
to existing clarification approaches -- such as the CLAM framework oriented to
ambiguity and the self-interrogation Self-Ask method -- FATA emphasizes
completeness (beyond mere disambiguation) and user participation (inviting
human input instead of relying solely on model-internal reasoning). It also
adopts a single-turn strategy: all clarifying questions are produced at once,
thereby reducing dialogue length and improving efficiency. Conceptually, FATA
uses the reasoning power of LLMs to scaffold user expression, enabling
non-expert users to formulate more comprehensive and contextually relevant
queries. To evaluate FATA, we constructed a multi-domain benchmark and compared
it with two controls: a baseline prompt (B-Prompt) and a context-enhanced
expert prompt (C-Prompt). Experimental results show that FATA outperforms
B-Prompt by approximately 40% in aggregate metrics and exhibits a coefficient
of variation 8% lower than C-Prompt, indicating superior stability.

</details>


### [28] [What Breaks Knowledge Graph based RAG? Empirical Insights into Reasoning under Incomplete Knowledge](https://arxiv.org/abs/2508.08344)
*Dongzhuoran Zhou,Yuqicheng Zhu,Xiaxia Wang,Hongkuan Zhou,Yuan He,Jiaoyan Chen,Evgeny Kharlamov,Steffen Staab*

Main category: cs.AI

TL;DR: 论文提出了一种评估KG-RAG方法的新方法，发现现有方法在知识缺失时推理能力有限，且依赖记忆。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法无法区分模型是推理还是直接检索答案，且评估指标不一致。

Method: 提出了一种构建基准和评估协议的方法，系统评估知识不完整时的KG-RAG方法。

Result: 当前KG-RAG方法在知识缺失时推理能力有限，依赖记忆，且泛化能力因设计而异。

Conclusion: 需要改进KG-RAG方法以提升其在知识缺失时的推理能力。

Abstract: Knowledge Graph-based Retrieval-Augmented Generation (KG-RAG) is an
increasingly explored approach for combining the reasoning capabilities of
large language models with the structured evidence of knowledge graphs.
However, current evaluation practices fall short: existing benchmarks often
include questions that can be directly answered using existing triples in KG,
making it unclear whether models perform reasoning or simply retrieve answers
directly. Moreover, inconsistent evaluation metrics and lenient answer matching
criteria further obscure meaningful comparisons. In this work, we introduce a
general method for constructing benchmarks, together with an evaluation
protocol, to systematically assess KG-RAG methods under knowledge
incompleteness. Our empirical results show that current KG-RAG methods have
limited reasoning ability under missing knowledge, often rely on internal
memorization, and exhibit varying degrees of generalization depending on their
design.

</details>


### [29] [UrzaGPT: LoRA-Tuned Large Language Models for Card Selection in Collectible Card Games](https://arxiv.org/abs/2508.08382)
*Timo Bertram*

Main category: cs.AI

TL;DR: 论文介绍了UrzaGPT，一个基于大型语言模型（LLM）的AI，用于在《万智牌》中实时推荐选牌决策。通过低秩适应（LoRA）微调，模型在小型数据集上表现优异，展示了LLM在复杂游戏任务中的潜力。


<details>
  <summary>Details</summary>
Motivation: 由于集换式卡牌游戏（CCG）的部分可观察性、长期决策和不断变化的卡牌库，现有AI在任务如组牌和游戏玩法上表现远不如人类。

Method: 从开放权重的LLM出发，使用低秩适应（LoRA）在标注的选牌日志数据集上进行微调，以快速适应游戏的不同扩展版本。

Result: 未经调整的小型LLM（如Llama-3-8B）完全无法完成选牌任务，而GPT-4o的零样本性能为43%。UrzaGPT在微调后，仅用10,000步就达到66.2%的准确率。

Conclusion: 尽管未达到领域专用模型的水平，但研究表明仅使用LLM进行选牌是可行的，未来LLM有望实现高性能、通用且易于更新的选牌AI。

Abstract: Collectible card games (CCGs) are a difficult genre for AI due to their
partial observability, long-term decision-making, and evolving card sets. Due
to this, current AI models perform vastly worse than human players at CCG tasks
such as deckbuilding and gameplay. In this work, we introduce UrzaGPT, a
domain-adapted large language model that recommends real-time drafting
decisions in Magic: The Gathering. Starting from an open-weight LLM, we use
Low-Rank Adaptation fine-tuning on a dataset of annotated draft logs. With
this, we leverage the language modeling capabilities of LLM, and can quickly
adapt to different expansions of the game. We benchmark UrzaGPT in comparison
to zero-shot LLMs and the state-of-the-art domain-specific model. Untuned,
small LLMs like Llama-3-8B are completely unable to draft, but the larger
GPT-4o achieves a zero-shot performance of 43%. Using UrzaGPT to fine-tune
smaller models, we achieve an accuracy of 66.2% using only 10,000 steps.
Despite this not reaching the capability of domain-specific models, we show
that solely using LLMs to draft is possible and conclude that using LLMs can
enable performant, general, and update-friendly drafting AIs in the future.

</details>


### [30] [Bilevel MCTS for Amortized O(1) Node Selection in Classical Planning](https://arxiv.org/abs/2508.08385)
*Masataro Asai*

Main category: cs.AI

TL;DR: 提出了一种改进的MCTS方法，通过双层修改和树折叠技术，解决了节点选择的高时间复杂度问题，实现了与传统队列相当的O(1)时间复杂度。


<details>
  <summary>Details</summary>
Motivation: MCTS在经典规划中因搜索深度大导致节点选择时间显著，而传统游戏树搜索中此成本可忽略。改进目标是降低节点选择的时间复杂度。

Method: 采用双层MCTS修改，从每个选中的叶节点运行最佳优先搜索，并结合树折叠技术减少动作选择步骤。

Result: 实现了节点选择的O(1)时间复杂度，性能显著提升。

Conclusion: 该方法有效解决了MCTS在经典规划中的性能瓶颈，具有实际应用价值。

Abstract: We study an efficient implementation of Multi-Armed Bandit (MAB)-based
Monte-Carlo Tree Search (MCTS) for classical planning. One weakness of MCTS is
that it spends a significant time deciding which node to expand next. While
selecting a node from an OPEN list with $N$ nodes has $O(1)$ runtime complexity
with traditional array-based priority-queues for dense integer keys, the
tree-based OPEN list used by MCTS requires $O(\log N)$, which roughly
corresponds to the search depth $d$. In classical planning, $d$ is arbitrarily
large (e.g., $2^k-1$ in $k$-disk Tower-of-Hanoi) and the runtime for node
selection is significant, unlike in game tree search, where the cost is
negligible compared to the node evaluation (rollouts) because $d$ is inherently
limited by the game (e.g., $d\leq 361$ in Go). To improve this bottleneck, we
propose a bilevel modification to MCTS that runs a best-first search from each
selected leaf node with an expansion budget proportional to $d$, which achieves
amortized $O(1)$ runtime for node selection, equivalent to the traditional
queue-based OPEN list. In addition, we introduce Tree Collapsing, an
enhancement that reduces action selection steps and further improves the
performance.

</details>


### [31] [Solver-Aided Expansion of Loops to Avoid Generate-and-Test](https://arxiv.org/abs/2508.08442)
*Niklas Dewally,Özgür Akgün*

Main category: cs.AI

TL;DR: 提出了一种避免完全枚举的高效约束建模编译方法，通过求解器仅计算所需组合，显著提升编译速度。


<details>
  <summary>Details</summary>
Motivation: 传统方法在编译约束建模语言时需完全枚举循环变量组合，效率低下，尤其是当变量域大且存在选择性条件时。

Method: 利用求解器仅计算生成最终约束所需的组合，避免完全枚举。

Result: 生成的模型与传统方法相同，但编译速度显著提升。

Conclusion: 该方法提高了将高级用户模型转换为求解器可用形式的效率，特别适用于大域和选择性条件的场景。

Abstract: Constraint modelling languages like MiniZinc and Essence rely on unrolling
loops (in the form of quantified expressions and comprehensions) during
compilation. Standard approaches generate all combinations of induction
variables and use partial evaluation to discard those that simplify to identity
elements of associative-commutative operators (e.g. true for conjunction, 0 for
summation). This can be inefficient for problems where most combinations are
ultimately irrelevant. We present a method that avoids full enumeration by
using a solver to compute only the combinations required to generate the final
set of constraints. The resulting model is identical to that produced by
conventional flattening, but compilation can be significantly faster. This
improves the efficiency of translating high-level user models into solver-ready
form, particularly when induction variables range over large domains with
selective preconditions.

</details>


### [32] [OverFill: Two-Stage Models for Efficient Language Model Decoding](https://arxiv.org/abs/2508.08446)
*Woojeong Kim,Junxiong Wang,Jing Nathan Yan,Mohamed Abdelfattah,Alexander M. Rush*

Main category: cs.AI

TL;DR: OverFill通过解耦LLM推理的prefill和decode阶段，优化准确性与效率的权衡，显著提升生成质量并减少延迟。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在推理阶段面临高成本问题，尤其是decode阶段对长序列的延迟影响显著。现有模型未区分prefill和decode的计算特性。

Method: 提出OverFill，将prefill和decode阶段解耦：prefill阶段使用完整模型并行处理输入，decode阶段切换到稀疏剪枝模型顺序生成令牌。

Result: 3B到1B的OverFill配置比1B剪枝模型性能提升83.2%，8B到3B配置比3B剪枝模型提升79.2%，且训练数据需求显著减少。

Conclusion: OverFill在保持性能的同时显著提升效率，为LLM部署提供了一种优化方案。

Abstract: Large language models (LLMs) excel across diverse tasks but face significant
deployment challenges due to high inference costs. LLM inference comprises
prefill (compute-bound) and decode (memory-bound) stages, with decode
dominating latency particularly for long sequences. Current decoder-only models
handle both stages uniformly, despite their distinct computational profiles. We
propose OverFill, which decouples these stages to optimize accuracy-efficiency
tradeoffs. OverFill begins with a full model for prefill, processing system and
user inputs in parallel. It then switches to a dense pruned model, while
generating tokens sequentially. Leveraging more compute during prefill,
OverFill improves generation quality with minimal latency overhead. Our
3B-to-1B OverFill configuration outperforms 1B pruned models by 83.2%, while
the 8B-to-3B configuration improves over 3B pruned models by 79.2% on average
across standard benchmarks. OverFill matches the performance of same-sized
models trained from scratch, while using significantly less training data. Our
code is available at https://github.com/friendshipkim/overfill.

</details>


### [33] [A Fast GRASP Metaheuristic for the Trigger Arc TSP with MIP-Based Construction and Multi-Neighborhood Local Search](https://arxiv.org/abs/2508.08477)
*Joan Salvà Soler,Grégoire de Lambertye*

Main category: cs.AI

TL;DR: 本文提出了一种基于GRASP的元启发式算法，用于解决动态弧成本的触发弧旅行商问题（TA-TSP），在MESS 2024竞赛中表现优异。


<details>
  <summary>Details</summary>
Motivation: TA-TSP扩展了经典TSP，引入了动态弧成本以模拟仓库操作等场景，需要高效算法解决。

Method: 结合多种构造启发式和多邻域局部搜索，构造阶段使用MIP技术，改进阶段应用2-Opt、Swap和Relocate操作。

Result: 在60秒内平均最优间隙为0.77%和0.40%，在合成数据集上比Gurobi优11.3%。

Conclusion: 该算法适合实时路由应用，在MESS 2024中表现优异。

Abstract: The Trigger Arc Traveling Salesman Problem (TA-TSP) extends the classical TSP
by introducing dynamic arc costs that change when specific \textit{trigger}
arcs are traversed, modeling scenarios such as warehouse operations with
compactable storage systems. This paper introduces a GRASP-based metaheuristic
that combines multiple construction heuristics with a multi-neighborhood local
search. The construction phase uses mixed-integer programming (MIP) techniques
to transform the TA-TSP into a sequence of tailored TSP instances, while the
improvement phase applies 2-Opt, Swap, and Relocate operators. Computational
experiments on MESS 2024 competition instances achieved average optimality gaps
of 0.77\% and 0.40\% relative to the best-known solutions within a 60-second
limit. On smaller, synthetically generated datasets, the method produced
solutions 11.3\% better than the Gurobi solver under the same time constraints.
The algorithm finished in the top three at MESS 2024, demonstrating its
suitability for real-time routing applications with state-dependent travel
costs.

</details>


### [34] [Beyond Ordinal Preferences: Why Alignment Needs Cardinal Human Feedback](https://arxiv.org/abs/2508.08486)
*Parker Whitfill,Stewy Slocum*

Main category: cs.AI

TL;DR: 论文指出，基于序数比较的LLM对齐方法存在根本性限制，无法系统性地恢复最优模型。通过引入基数反馈（如支付意愿），可以更好地优化模型偏好，并在下游任务中表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有LLM对齐方法依赖序数偏好数据，但这类数据无法解决模型间的权衡问题（如事实错误与风格改进），导致无法系统性地恢复最优模型。

Method: 提出使用基数反馈（支付意愿）替代序数偏好数据，并公开了一个包含25,000条基数判断的数据集。通过将基数反馈融入偏好微调，优化模型选择。

Result: 实验表明，基于基数反馈的方法能优先处理高影响力改进，并在Arena-Hard等下游基准上优于仅依赖序数数据的方法。

Conclusion: 基数反馈是解决LLM对齐中偏好权衡问题的关键，未来研究应关注更丰富的数据类型以优化模型性能。

Abstract: Alignment techniques for LLMs rely on optimizing preference-based objectives
-- where these preferences are typically elicited as ordinal, binary choices
between responses. Recent work has focused on improving label quality or
mitigating particular biases, but we identify a more fundamental limitation:
these methods collect the wrong kind of data. We prove an impossibility result:
no algorithm relying solely on ordinal comparisons can systematically recover
the most preferred model. Intuitively, ordinal data lacks the information
needed to resolve tradeoffs -- e.g., fixing a factual error on one prompt
versus improving style on another. We show that selecting the optimal model
requires recovering preferences over \emph{models} (rather than just
responses), which can only be identified given cardinal feedback about response
quality. To address this, we collect and publicly release a dataset of 25,000
cardinal judgments using willingness-to-pay elicitations, a well-established
tool from experimental economics. Empirically, we find that incorporating
cardinal feedback into preference fine-tuning allows models to prioritize
high-impact improvements and outperform ordinal-only methods on downstream
benchmarks, such as Arena-Hard.

</details>


### [35] [POMO+: Leveraging starting nodes in POMO for solving Capacitated Vehicle Routing Problem](https://arxiv.org/abs/2508.08493)
*Szymon Jakubicz,Karol Kuźniak,Jan Wawszczak,Paweł Gora*

Main category: cs.AI

TL;DR: POMO+是一种改进的强化学习方法，通过更智能地利用初始节点，在组合优化问题中表现更优。


<details>
  <summary>Details</summary>
Motivation: 尽管POMO在组合优化问题中表现良好，仍有改进空间，特别是在车辆路径问题（VRP）中。

Method: 改进POMO方法，提出POMO+，通过更智能地利用初始节点来寻找解决方案。

Result: 在CVRPLIB数据集上验证，POMO+收敛更快且结果更优，适用于多达100个客户的问题实例。

Conclusion: POMO+为组合优化问题提供了更高效的解决方案，有望推动该领域的进一步发展。

Abstract: In recent years, reinforcement learning (RL) methods have emerged as a
promising approach for solving combinatorial problems. Among RL-based models,
POMO has demonstrated strong performance on a variety of tasks, including
variants of the Vehicle Routing Problem (VRP). However, there is room for
improvement for these tasks. In this work, we improved POMO, creating a method
(\textbf{POMO+}) that leverages the initial nodes to find a solution in a more
informed way. We ran experiments on our new model and observed that our
solution converges faster and achieves better results. We validated our models
on the CVRPLIB dataset and noticed improvements in problem instances with up to
100 customers. We hope that our research in this project can lead to further
advancements in the field.

</details>


### [36] [Large Language Models as Oracles for Ontology Alignment](https://arxiv.org/abs/2508.08500)
*Sviatoslav Lushnei,Dmytro Shumskyi,Severyn Shykula,Ernesto Jimenez-Ruiz,Artur d'Avila Garcez*

Main category: cs.AI

TL;DR: 论文探讨了利用大型语言模型（LLM）替代领域专家进行本体对齐验证的可行性，重点验证对齐系统不确定的部分，并在OAEI任务中评估了多种LLM的性能。


<details>
  <summary>Details</summary>
Motivation: 本体对齐在跨领域数据集成中至关重要，但高质量对齐仍面临挑战，人工参与成本高。

Method: 使用LLM验证对齐系统不确定的部分，并在OAEI任务中评估多种LLM的性能。

Result: LLM在验证不确定对齐时表现良好，性能与模拟Oracle（可变错误率）进行了对比。

Conclusion: LLM可作为领域专家的替代方案，有效降低人工验证成本。

Abstract: Ontology alignment plays a crucial role in integrating diverse data sources
across domains. There is a large plethora of systems that tackle the ontology
alignment problem, yet challenges persist in producing highly quality
correspondences among a set of input ontologies. Human-in-the-loop during the
alignment process is essential in applications requiring very accurate
mappings. User involvement is, however, expensive when dealing with large
ontologies. In this paper, we explore the feasibility of using Large Language
Models (LLM) as an alternative to the domain expert. The use of the LLM focuses
only on the validation of the subset of correspondences where an ontology
alignment system is very uncertain. We have conducted an extensive evaluation
over several matching tasks of the Ontology Alignment Evaluation Initiative
(OAEI), analysing the performance of several state-of-the-art LLMs using
different ontology-driven prompt templates. The LLM results are also compared
against simulated Oracles with variable error rates.

</details>


### [37] [GVGAI-LLM: Evaluating Large Language Model Agents with Infinite Games](https://arxiv.org/abs/2508.08501)
*Yuchen Li,Cong Lin,Muhammad Umair Nasir,Philip Bontrager,Jialin Liu,Julian Togelius*

Main category: cs.AI

TL;DR: GVGAI-LLM是一个基于视频游戏的基准测试，用于评估大型语言模型（LLMs）的推理和问题解决能力。它通过多样化的游戏任务揭示LLMs在空间推理和基础规划上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM基准测试未能充分评估模型在多样化任务中的能力，尤其是空间推理和规划方面。GVGAI-LLM旨在填补这一空白。

Method: 基于General Video Game AI框架，使用游戏描述语言快速生成新游戏和关卡，避免过拟合。游戏场景用ASCII字符表示，便于语言模型处理。

Result: 零样本评估显示LLMs在空间推理和基础规划上存在显著缺陷，结构化提示和空间接地技术仅带来部分改进。

Conclusion: GVGAI-LLM为语言模型能力研究提供了可复现的测试平台，重点关注代理行为和上下文推理。

Abstract: We introduce GVGAI-LLM, a video game benchmark for evaluating the reasoning
and problem-solving capabilities of large language models (LLMs). Built on the
General Video Game AI framework, it features a diverse collection of
arcade-style games designed to test a model's ability to handle tasks that
differ from most existing LLM benchmarks. The benchmark leverages a game
description language that enables rapid creation of new games and levels,
helping to prevent overfitting over time. Each game scene is represented by a
compact set of ASCII characters, allowing for efficient processing by language
models. GVGAI-LLM defines interpretable metrics, including the meaningful step
ratio, step efficiency, and overall score, to assess model behavior. Through
zero-shot evaluations across a broad set of games and levels with diverse
challenges and skill depth, we reveal persistent limitations of LLMs in spatial
reasoning and basic planning. Current models consistently exhibit spatial and
logical errors, motivating structured prompting and spatial grounding
techniques. While these interventions lead to partial improvements, the
benchmark remains very far from solved. GVGAI-LLM provides a reproducible
testbed for advancing research on language model capabilities, with a
particular emphasis on agentic behavior and contextual reasoning.

</details>


### [38] [SynLLM: A Comparative Analysis of Large Language Models for Medical Tabular Synthetic Data Generation via Prompt Engineering](https://arxiv.org/abs/2508.08529)
*Arshia Ilaty,Hossein Shirazi,Hajar Homayouni*

Main category: cs.AI

TL;DR: SynLLM是一个模块化框架，利用20种开源LLMs生成高质量合成医疗数据，通过结构化提示和全面评估确保数据质量与隐私。


<details>
  <summary>Details</summary>
Motivation: 真实医疗数据因隐私法规受限，合成数据成为替代方案，但现有方法缺乏系统提示策略和全面评估框架。

Method: SynLLM采用四种提示类型（如示例驱动和规则约束），结合20种开源LLMs生成数据，并通过多维度评估框架验证。

Result: 在三个医疗数据集上测试显示，规则提示在隐私与质量间取得最佳平衡，LLMs能生成临床合理且隐私安全的合成数据。

Conclusion: SynLLM证明通过精心设计的提示和评估，LLMs可生成高质量合成医疗数据，推动医疗研究数据共享。

Abstract: Access to real-world medical data is often restricted due to privacy
regulations, posing a significant barrier to the advancement of healthcare
research. Synthetic data offers a promising alternative; however, generating
realistic, clinically valid, and privacy-conscious records remains a major
challenge. Recent advancements in Large Language Models (LLMs) offer new
opportunities for structured data generation; however, existing approaches
frequently lack systematic prompting strategies and comprehensive,
multi-dimensional evaluation frameworks.
  In this paper, we present SynLLM, a modular framework for generating
high-quality synthetic medical tabular data using 20 state-of-the-art
open-source LLMs, including LLaMA, Mistral, and GPT variants, guided by
structured prompts. We propose four distinct prompt types, ranging from
example-driven to rule-based constraints, that encode schema, metadata, and
domain knowledge to control generation without model fine-tuning. Our framework
features a comprehensive evaluation pipeline that rigorously assesses generated
data across statistical fidelity, clinical consistency, and privacy
preservation.
  We evaluate SynLLM across three public medical datasets, including Diabetes,
Cirrhosis, and Stroke, using 20 open-source LLMs. Our results show that prompt
engineering significantly impacts data quality and privacy risk, with
rule-based prompts achieving the best privacy-quality balance. SynLLM
establishes that, when guided by well-designed prompts and evaluated with
robust, multi-metric criteria, LLMs can generate synthetic medical data that is
both clinically plausible and privacy-aware, paving the way for safer and more
effective data sharing in healthcare research.

</details>


### [39] [UGM2N: An Unsupervised and Generalizable Mesh Movement Network via M-Uniform Loss](https://arxiv.org/abs/2508.08615)
*Zhichao Wang,Xinhai Chen,Qinglin Wang,Xiang Gao,Qingyang Zhang,Menghan Jia,Xiang Zhang,Jie Liu*

Main category: cs.AI

TL;DR: 提出了一种无监督且通用的网格移动网络（UGM2N），通过局部几何特征学习和物理约束损失函数，实现了高效的网格自适应，具有方程无关的泛化能力和几何独立性。


<details>
  <summary>Details</summary>
Motivation: 传统网格移动方法计算复杂度高且几何灵活性不足，而现有基于监督学习的方法难以实现零样本泛化。

Method: 采用无监督网格自适应，通过局部几何特征学习和M-Uniform损失函数实现网格均匀分布。

Result: 实验表明，UGM2N在多种PDE和网格几何中表现优越，具有多尺度分辨率和无网格纠缠的误差减少能力。

Conclusion: UGM2N在网格自适应中展现出高效的泛化能力和几何独立性，优于现有方法。

Abstract: Partial differential equations (PDEs) form the mathematical foundation for
modeling physical systems in science and engineering, where numerical solutions
demand rigorous accuracy-efficiency tradeoffs. Mesh movement techniques address
this challenge by dynamically relocating mesh nodes to rapidly-varying regions,
enhancing both simulation accuracy and computational efficiency. However,
traditional approaches suffer from high computational complexity and geometric
inflexibility, limiting their applicability, and existing supervised
learning-based approaches face challenges in zero-shot generalization across
diverse PDEs and mesh topologies.In this paper, we present an Unsupervised and
Generalizable Mesh Movement Network (UGM2N). We first introduce unsupervised
mesh adaptation through localized geometric feature learning, eliminating the
dependency on pre-adapted meshes. We then develop a physics-constrained loss
function, M-Uniform loss, that enforces mesh equidistribution at the nodal
level.Experimental results demonstrate that the proposed network exhibits
equation-agnostic generalization and geometric independence in efficient mesh
adaptation. It demonstrates consistent superiority over existing methods,
including robust performance across diverse PDEs and mesh geometries,
scalability to multi-scale resolutions and guaranteed error reduction without
mesh tangling.

</details>


### [40] [AgriGPT: a Large Language Model Ecosystem for Agriculture](https://arxiv.org/abs/2508.08632)
*Bo Yang,Yu Zhang,Lanfei Feng,Yunkui Chen,Jianyu Zhang,Xiao Xu,Nueraili Aierken,Yurui Li,Yuxuan Chen,Guijun Yang,Yong He,Runhe Huang,Shijian Li*

Main category: cs.AI

TL;DR: AgriGPT是一个专为农业设计的LLM生态系统，通过多代理数据引擎构建高质量数据集Agri-342K，并采用Tri-RAG框架增强推理可靠性。实验表明其在农业领域表现优于通用LLM。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在农业领域应用受限，缺乏领域专用模型、数据集和评估框架。

Method: 设计多代理数据引擎构建Agri-342K数据集，采用Tri-RAG（密集检索、稀疏检索和多跳知识图谱推理）框架。

Result: AgriGPT在领域适应和推理任务上显著优于通用LLM。

Conclusion: AgriGPT为农业提供了一个模块化、可扩展的LLM生态系统，并为其他科学和工业领域LLM开发提供了通用框架。

Abstract: Despite the rapid progress of Large Language Models (LLMs), their application
in agriculture remains limited due to the lack of domain-specific models,
curated datasets, and robust evaluation frameworks. To address these
challenges, we propose AgriGPT, a domain-specialized LLM ecosystem for
agricultural usage. At its core, we design a multi-agent scalable data engine
that systematically compiles credible data sources into Agri-342K, a
high-quality, standardized question-answer (QA) dataset. Trained on this
dataset, AgriGPT supports a broad range of agricultural stakeholders, from
practitioners to policy-makers. To enhance factual grounding, we employ
Tri-RAG, a three-channel Retrieval-Augmented Generation framework combining
dense retrieval, sparse retrieval, and multi-hop knowledge graph reasoning,
thereby improving the LLM's reasoning reliability. For comprehensive
evaluation, we introduce AgriBench-13K, a benchmark suite comprising 13 tasks
with varying types and complexities. Experiments demonstrate that AgriGPT
significantly outperforms general-purpose LLMs on both domain adaptation and
reasoning. Beyond the model itself, AgriGPT represents a modular and extensible
LLM ecosystem for agriculture, comprising structured data construction,
retrieval-enhanced generation, and domain-specific evaluation. This work
provides a generalizable framework for developing scientific and
industry-specialized LLMs. All models, datasets, and code will be released to
empower agricultural communities, especially in underserved regions, and to
promote open, impactful research.

</details>


### [41] [Diminution: On Reducing the Size of Grounding ASP Programs](https://arxiv.org/abs/2508.08633)
*HuanYu Yang,Fengming Zhu,YangFan Wu,Jianmin Ji*

Main category: cs.AI

TL;DR: 论文提出了一种称为“diminution”的方法，通过选择Herbrand宇宙的子集来减少ASP中的基础程序规模，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: ASP常因基础程序规模过大而遇到性能瓶颈，现有方法多依赖临时启发式策略，缺乏通用性。

Method: 提出“diminution”概念，定义其形式化性质，并通过特定编码利用现有ASP求解器评估候选子集。

Result: 实验表明，该方法平均减少70%的基础时间，基础文件大小减少85%。

Conclusion: diminution是一种通用且有效的方法，可显著缓解ASP中的基础瓶颈。

Abstract: Answer Set Programming (ASP) is often hindered by the grounding bottleneck:
large Herbrand universes generate ground programs so large that solving becomes
difficult. Many methods employ ad-hoc heuristics to improve grounding
performance, motivating the need for a more formal and generalizable strategy.
We introduce the notion of diminution, defined as a selected subset of the
Herbrand universe used to generate a reduced ground program before solving. We
give a formal definition of diminution, analyze its key properties, and study
the complexity of identifying it. We use a specific encoding that enables
off-the-shelf ASP solver to evaluate candidate subsets. Our approach integrates
seamlessly with existing grounders via domain predicates. In extensive
experiments on five benchmarks, applying diminutions selected by our strategy
yields significant performance improvements, reducing grounding time by up to
70% on average and decreasing the size of grounding files by up to 85%. These
results demonstrate that leveraging diminutions constitutes a robust and
general-purpose approach for alleviating the grounding bottleneck in ASP.

</details>


### [42] [P-CAFE: Personalized Cost-Aware Incremental Feature Selection For Electronic Health Records](https://arxiv.org/abs/2508.08646)
*Naama Kashani,Mira Cohen,Uri Shaham*

Main category: cs.AI

TL;DR: 提出了一种针对电子健康记录（EHR）数据的个性化、在线且成本感知的特征选择框架，以解决传统方法在处理稀疏和异构数据时的不足。


<details>
  <summary>Details</summary>
Motivation: EHR数据的复杂性和多模态特性使得传统特征选择方法难以有效提取有用信息，尤其是在考虑患者个体差异和特征成本时。

Method: 开发了一种在线获取特征的方法，结合预算约束和特征可变性成本，为个体患者定制特征选择。

Result: 该框架能够有效管理稀疏和多模态数据，在多样化的医疗场景中表现出稳健且可扩展的性能。

Conclusion: 该方法支持医生在患者筛查中逐步获取最有信息量的特征，提升诊断信心并优化资源利用。

Abstract: Electronic Health Records (EHR) have revolutionized healthcare by digitizing
patient data, improving accessibility, and streamlining clinical workflows.
However, extracting meaningful insights from these complex and multimodal
datasets remains a significant challenge for researchers. Traditional feature
selection methods often struggle with the inherent sparsity and heterogeneity
of EHR data, especially when accounting for patient-specific variations and
feature costs in clinical applications. To address these challenges, we propose
a novel personalized, online and cost-aware feature selection framework
tailored specifically for EHR datasets. The features are aquired in an online
fashion for individual patients, incorporating budgetary constraints and
feature variability costs. The framework is designed to effectively manage
sparse and multimodal data, ensuring robust and scalable performance in diverse
healthcare contexts. A primary application of our proposed method is to support
physicians' decision making in patient screening scenarios. By guiding
physicians toward incremental acquisition of the most informative features
within budget constraints, our approach aims to increase diagnostic confidence
while optimizing resource utilization.

</details>


### [43] [Prompt-and-Check: Using Large Language Models to Evaluate Communication Protocol Compliance in Simulation-Based Training](https://arxiv.org/abs/2508.08652)
*Vishakha Lall,Yisi Liu*

Main category: cs.AI

TL;DR: 本文提出了一种基于提示推理的轻量级方法（Prompt-and-Check），利用开源大语言模型（LLMs）评估程序性通信合规性，适用于模拟训练中的自动化评估。


<details>
  <summary>Details</summary>
Motivation: 在安全关键领域，程序性通信合规性的准确评估对模拟训练至关重要，但传统方法成本高且难以部署。

Method: 使用上下文丰富的提示，基于转录的语音交换，通过LLMs（如LLaMA 2 7B、LLaMA 3 8B和Mistral 7B）评估协议中的每个检查项是否完成。

Result: 实验表明，提示方法能有效实现上下文感知推理，无需任务特定训练，分类准确性和一致性评分较高。

Conclusion: LLMs在增强训练环境中的反馈和自动化评估方面具有实际应用潜力。

Abstract: Accurate evaluation of procedural communication compliance is essential in
simulation-based training, particularly in safety-critical domains where
adherence to compliance checklists reflects operational competence. This paper
explores a lightweight, deployable approach using prompt-based inference with
open-source large language models (LLMs) that can run efficiently on
consumer-grade GPUs. We present Prompt-and-Check, a method that uses
context-rich prompts to evaluate whether each checklist item in a protocol has
been fulfilled, solely based on transcribed verbal exchanges. We perform a case
study in the maritime domain with participants performing an identical
simulation task, and experiment with models such as LLama 2 7B, LLaMA 3 8B and
Mistral 7B, running locally on an RTX 4070 GPU. For each checklist item, a
prompt incorporating relevant transcript excerpts is fed into the model, which
outputs a compliance judgment. We assess model outputs against expert-annotated
ground truth using classification accuracy and agreement scores. Our findings
demonstrate that prompting enables effective context-aware reasoning without
task-specific training. This study highlights the practical utility of LLMs in
augmenting debriefing, performance feedback, and automated assessment in
training environments.

</details>


### [44] [Hybrid Node-Destroyer Model with Large Neighborhood Search for Solving the Capacitated Vehicle Routing Problem](https://arxiv.org/abs/2508.08659)
*Bachtiar Herdianto,Romain Billot,Flavien Lucas,Marc Sevaux,Daniele Vigo*

Main category: cs.AI

TL;DR: 提出了一种结合机器学习的混合优化求解器，用于提升元启发式算法在CVRP中的性能，通过GNN指导节点移除策略，显著减少搜索空间并提升解的质量。


<details>
  <summary>Details</summary>
Motivation: 解决CVRP中元启发式算法的性能瓶颈，通过机器学习方法优化节点移除策略，降低计算复杂度。

Method: 结合Node-Destroyer模型（基于GNN）和LNS算子，利用图结构特性指导节点移除，无需针对不同规模问题重新训练。

Result: 在标准CVRP基准测试中提升解质量，并成功扩展到30,000节点的大规模实例，优于基线算法。

Conclusion: 提出的混合机制有效提升了元启发式算法的性能，具有普适性和可扩展性。

Abstract: In this research, we propose an iterative learning hybrid optimization solver
developed to strengthen the performance of metaheuristic algorithms in solving
the Capacitated Vehicle Routing Problem (CVRP). The iterative hybrid mechanism
integrates the proposed Node-Destroyer Model, a machine learning hybrid model
that utilized Graph Neural Networks (GNNs) such identifies and selects customer
nodes to guide the Large Neighborhood Search (LNS) operator within the
metaheuristic optimization frameworks. This model leverages the structural
properties of the problem and solution that can be represented as a graph, to
guide strategic selections concerning node removal. The proposed approach
reduces operational complexity and scales down the search space involved in the
optimization process. The hybrid approach is applied specifically to the CVRP
and does not require retraining across problem instances of different sizes.
The proposed hybrid mechanism is able to improve the performance of baseline
metaheuristic algorithms. Our approach not only enhances the solution quality
for standard CVRP benchmarks but also proves scalability on very large-scale
instances with up to 30,000 customer nodes. Experimental evaluations on
benchmark datasets show that the proposed hybrid mechanism is capable of
improving different baseline algorithms, achieving better quality of solutions
under similar settings.

</details>


### [45] [Aryabhata: An exam-focused language model for JEE Math](https://arxiv.org/abs/2508.08665)
*Ritvik Rastogi,Sachin Dharashivkar,Sandeep Varma*

Main category: cs.AI

TL;DR: Aryabhata 1.0是一个7B参数的数学推理模型，专为印度JEE考试优化，通过融合开源模型、课程学习和强化学习提升性能，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在教育领域适用性不足，Aryabhata旨在提供更适合教育用途的小型开源模型。

Method: 融合开源推理模型，通过课程学习和强化学习（RLVR）优化，采用新颖探索策略如自适应组调整和温度缩放。

Result: 在JEE和MATH、GSM8K等基准测试中，Aryabhata在准确性和效率上优于现有模型，并提供教学有用的逐步推理。

Conclusion: Aryabhata作为开源基础模型发布，旨在推动以考试为中心的小型语言模型发展，未来将持续优化以提升学习效果。

Abstract: We present Aryabhata 1.0, a compact 7B parameter math reasoning model
optimized for the Indian academic exam, the Joint Entrance Examination (JEE).
Despite rapid progress in large language models (LLMs), current models often
remain unsuitable for educational use. Aryabhata 1.0 is built by merging strong
open-weight reasoning models, followed by supervised fine-tuning (SFT) with
curriculum learning on verified chain-of-thought (CoT) traces curated through
best-of-$n$ rejection sampling. To further boost performance, we apply
reinforcement learning with verifiable rewards (RLVR) using A2C objective with
group-relative advantage estimation along with novel exploration strategies
such as Adaptive Group Resizing and Temperature Scaling. Evaluated on both
in-distribution (JEE Main 2025) and out-of-distribution (MATH, GSM8K)
benchmarks, Aryabhata outperforms existing models in accuracy and efficiency,
while offering pedagogically useful step-by-step reasoning. We release
Aryabhata as a foundation model to advance exam-centric, open-source small
language models. This marks our first open release for community feedback
(https://huggingface.co/PhysicsWallahAI/Aryabhata-1.0); PW is actively training
future models to further improve learning outcomes for students.

</details>


### [46] [STELAR-VISION: Self-Topology-Aware Efficient Learning for Aligned Reasoning in Vision](https://arxiv.org/abs/2508.08688)
*Chen Li,Han Zhang,Zhantao Yang,Fangyi Chen,Zihan Wang,Anudeepsekhar Bolimera,Marios Savvides*

Main category: cs.AI

TL;DR: STELAR-Vision是一个训练框架，通过拓扑感知推理提升多模态任务的性能，减少冗长输出，并在多个基准测试中显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLMs）依赖链式推理（CoT），难以处理复杂多模态任务且输出冗长，需要更灵活的拓扑结构。

Method: 提出STELAR-Vision框架，核心是TopoAug数据增强管道，结合监督微调和强化学习，优化模型推理效率和准确性。

Result: 在MATH-V和VLM-S2H上，STELAR-Vision比基础模型准确率提升9.7%，并在多个OOD基准测试中表现优异。

Conclusion: STELAR-Vision通过拓扑感知推理和Frugal Learning，显著提升模型性能，具有强泛化能力。

Abstract: Vision-language models (VLMs) have made significant strides in reasoning, yet
they often struggle with complex multimodal tasks and tend to generate overly
verbose outputs. A key limitation is their reliance on chain-of-thought (CoT)
reasoning, despite many tasks benefiting from alternative topologies like trees
or graphs. To address this, we introduce STELAR-Vision, a training framework
for topology-aware reasoning. At its core is TopoAug, a synthetic data pipeline
that enriches training with diverse topological structures. Using supervised
fine-tuning and reinforcement learning, we post-train Qwen2VL models with both
accuracy and efficiency in mind. Additionally, we propose Frugal Learning,
which reduces output length with minimal accuracy loss. On MATH-V and VLM-S2H,
STELAR-Vision improves accuracy by 9.7% over its base model and surpasses the
larger Qwen2VL-72B-Instruct by 7.3%. On five out-of-distribution benchmarks, it
outperforms Phi-4-Multimodal-Instruct by up to 28.4% and
LLaMA-3.2-11B-Vision-Instruct by up to 13.2%, demonstrating strong
generalization. Compared to Chain-Only training, our approach achieves 4.3%
higher overall accuracy on in-distribution datasets and consistently
outperforms across all OOD benchmarks. We have released datasets, and code will
be available.

</details>


### [47] [Simulating Generative Social Agents via Theory-Informed Workflow Design](https://arxiv.org/abs/2508.08726)
*Yuwei Yan,Jinghua Piao,Xiaochong Lan,Chenyang Shao,Pan Hui,Yong Li*

Main category: cs.AI

TL;DR: 提出了一个基于社会认知理论的统一框架，用于设计LLM社交代理，包含动机、行动规划和学习模块，显著提升了行为的真实性和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有社交代理多为场景定制，缺乏通用框架，限制了其在不同社交环境中的泛化能力和行为一致性。

Method: 基于社会认知理论，提出包含动机、行动规划和学习三个模块的框架，指导代理进行目标推理、行动规划和行为适应。

Result: 实验表明，该框架代理在复杂条件下能重现真实人类行为模式，与真实数据偏差降低75%，模块消融研究证实各模块的贡献。

Conclusion: 理论驱动的框架显著提升了LLM社交代理的行为真实性和适应性，为通用社交代理设计提供了系统方法。

Abstract: Recent advances in large language models have demonstrated strong reasoning
and role-playing capabilities, opening new opportunities for agent-based social
simulations. However, most existing agents' implementations are
scenario-tailored, without a unified framework to guide the design. This lack
of a general social agent limits their ability to generalize across different
social contexts and to produce consistent, realistic behaviors. To address this
challenge, we propose a theory-informed framework that provides a systematic
design process for LLM-based social agents. Our framework is grounded in
principles from Social Cognition Theory and introduces three key modules:
motivation, action planning, and learning. These modules jointly enable agents
to reason about their goals, plan coherent actions, and adapt their behavior
over time, leading to more flexible and contextually appropriate responses.
Comprehensive experiments demonstrate that our theory-driven agents reproduce
realistic human behavior patterns under complex conditions, achieving up to 75%
lower deviation from real-world behavioral data across multiple fidelity
metrics compared to classical generative baselines. Ablation studies further
show that removing motivation, planning, or learning modules increases errors
by 1.5 to 3.2 times, confirming their distinct and essential contributions to
generating realistic and coherent social behaviors.

</details>


### [48] [Designing Memory-Augmented AR Agents for Spatiotemporal Reasoning in Personalized Task Assistance](https://arxiv.org/abs/2508.08774)
*Dongwook Choi,Taeyoon Kwon,Dongil Yang,Hyojun Kim,Jinyoung Yeo*

Main category: cs.AI

TL;DR: 论文提出了一种基于记忆增强的AR代理框架，旨在解决现有AR系统在复杂多步骤场景中无法利用用户长期经验和偏好的问题。


<details>
  <summary>Details</summary>
Motivation: 当前AR代理在即时任务中表现良好，但在需要利用用户长期经验和偏好的复杂多步骤场景中存在不足。

Method: 提出了一个包含感知、记忆、时空推理和执行四个模块的框架，用于存储和推理用户的历史交互数据。

Result: 框架通过结合历史和当前上下文，提供个性化的任务辅助，并展示了实际应用的路线图和用例。

Conclusion: 该研究为开发更智能的AR系统提供了方向，旨在将用户交互历史与自适应、情境感知的任务辅助相结合。

Abstract: Augmented Reality (AR) systems are increasingly integrating foundation
models, such as Multimodal Large Language Models (MLLMs), to provide more
context-aware and adaptive user experiences. This integration has led to the
development of AR agents to support intelligent, goal-directed interactions in
real-world environments. While current AR agents effectively support immediate
tasks, they struggle with complex multi-step scenarios that require
understanding and leveraging user's long-term experiences and preferences. This
limitation stems from their inability to capture, retain, and reason over
historical user interactions in spatiotemporal contexts. To address these
challenges, we propose a conceptual framework for memory-augmented AR agents
that can provide personalized task assistance by learning from and adapting to
user-specific experiences over time. Our framework consists of four
interconnected modules: (1) Perception Module for multimodal sensor processing,
(2) Memory Module for persistent spatiotemporal experience storage, (3)
Spatiotemporal Reasoning Module for synthesizing past and present contexts, and
(4) Actuator Module for effective AR communication. We further present an
implementation roadmap, a future evaluation strategy, a potential target
application and use cases to demonstrate the practical applicability of our
framework across diverse domains. We aim for this work to motivate future
research toward developing more intelligent AR systems that can effectively
bridge user's interaction history with adaptive, context-aware task assistance.

</details>


### [49] [A Dual-Axis Taxonomy of Knowledge Editing for LLMs: From Mechanisms to Functions](https://arxiv.org/abs/2508.08795)
*Amir Mohammad Salehoof,Ali Ramezani,Yadollah Yaghoobzadeh,Majid Nili Ahmadabadi*

Main category: cs.AI

TL;DR: 该论文提出了一种基于功能的知识编辑分类法，补充现有机制导向的综述，探讨不同编辑机制对各类知识（如事实、时间、概念等）的适用性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的知识可能过时或不准确，而重新训练成本高昂，知识编辑成为一种高效替代方案。现有综述多关注编辑机制，而忽视了知识的功能性。

Method: 引入功能导向的分类法，结合知识类型（事实、时间、概念等）和编辑机制，系统分析编辑方法的适用性和局限性。

Result: 通过双轴分类法（知识类型和编辑机制）梳理了当前研究现状，总结了现有方法的优缺点，并提出了评估任务和数据集。

Conclusion: 论文为知识编辑领域提供了更全面的视角，指出了未来研究方向和开放性问题。

Abstract: Large language models (LLMs) acquire vast knowledge from large text corpora,
but this information can become outdated or inaccurate. Since retraining is
computationally expensive, knowledge editing offers an efficient alternative --
modifying internal knowledge without full retraining. These methods aim to
update facts precisely while preserving the model's overall capabilities. While
existing surveys focus on the mechanism of editing (e.g., parameter changes vs.
external memory), they often overlook the function of the knowledge being
edited. This survey introduces a novel, complementary function-based taxonomy
to provide a more holistic view. We examine how different mechanisms apply to
various knowledge types -- factual, temporal, conceptual, commonsense, and
social -- highlighting how editing effectiveness depends on the nature of the
target knowledge. By organizing our review along these two axes, we map the
current landscape, outline the strengths and limitations of existing methods,
define the problem formally, survey evaluation tasks and datasets, and conclude
with open challenges and future directions.

</details>


### [50] [GRainsaCK: a Comprehensive Software Library for Benchmarking Explanations of Link Prediction Tasks on Knowledge Graphs](https://arxiv.org/abs/2508.08815)
*Roberto Barile,Claudia d'Amato,Nicola Fanizzi*

Main category: cs.AI

TL;DR: 论文提出了GRainsaCK，一个用于标准化评估知识图谱链接预测解释方法的软件资源。


<details>
  <summary>Details</summary>
Motivation: 知识图谱通常不完整，现有链接预测方法缺乏可解释性，且缺乏统一的评估标准和资源。

Method: 提出GRainsaCK，一个模块化、可扩展的软件资源，支持从模型训练到解释评估的全流程标准化。

Result: GRainsaCK实现了标准化评估流程，并提供了详细文档和教程。

Conclusion: GRainsaCK填补了知识图谱解释方法评估的空白，促进了方法的可重用性和比较。

Abstract: Since Knowledge Graphs are often incomplete, link prediction methods are
adopted for predicting missing facts. Scalable embedding based solutions are
mostly adopted for this purpose, however, they lack comprehensibility, which
may be crucial in several domains. Explanation methods tackle this issue by
identifying supporting knowledge explaining the predicted facts. Regretfully,
evaluating/comparing quantitatively the resulting explanations is challenging
as there is no standard evaluation protocol and overall benchmarking resource.
We fill this important gap by proposing GRainsaCK, a reusable software resource
that fully streamlines all the tasks involved in benchmarking explanations,
i.e., from model training to evaluation of explanations along the same
evaluation protocol. Moreover, GRainsaCK furthers modularity/extensibility by
implementing the main components as functions that can be easily replaced.
Finally, fostering its reuse, we provide extensive documentation including a
tutorial.

</details>


### [51] [Efficient Agent: Optimizing Planning Capability for Multimodal Retrieval Augmented Generation](https://arxiv.org/abs/2508.08816)
*Yuechen Wang,Yuming Qiao,Dan Meng,Jun Yang,Haonan Lu,Zhenyu Yang,Xudong Zhang*

Main category: cs.AI

TL;DR: E-Agent框架通过动态规划和任务执行优化多模态检索增强生成（mRAG），在减少冗余搜索的同时提升准确性。


<details>
  <summary>Details</summary>
Motivation: 解决现有mRAG方法在检索策略和视觉信息利用上的不足，以应对实时场景需求。

Method: 提出E-Agent框架，包含动态规划的多模态工具协调和任务执行序列优化。

Result: 在RemPlan基准测试中，E-Agent比现有方法准确率提升13%，冗余搜索减少37%。

Conclusion: E-Agent通过动态规划和高效执行，显著提升了mRAG系统的性能和实用性。

Abstract: Multimodal Retrieval-Augmented Generation (mRAG) has emerged as a promising
solution to address the temporal limitations of Multimodal Large Language
Models (MLLMs) in real-world scenarios like news analysis and trending topics.
However, existing approaches often suffer from rigid retrieval strategies and
under-utilization of visual information. To bridge this gap, we propose
E-Agent, an agent framework featuring two key innovations: a mRAG planner
trained to dynamically orchestrate multimodal tools based on contextual
reasoning, and a task executor employing tool-aware execution sequencing to
implement optimized mRAG workflows. E-Agent adopts a one-time mRAG planning
strategy that enables efficient information retrieval while minimizing
redundant tool invocations. To rigorously assess the planning capabilities of
mRAG systems, we introduce the Real-World mRAG Planning (RemPlan) benchmark.
This novel benchmark contains both retrieval-dependent and
retrieval-independent question types, systematically annotated with essential
retrieval tools required for each instance. The benchmark's explicit mRAG
planning annotations and diverse question design enhance its practical
relevance by simulating real-world scenarios requiring dynamic mRAG decisions.
Experiments across RemPlan and three established benchmarks demonstrate
E-Agent's superiority: 13% accuracy gain over state-of-the-art mRAG methods
while reducing redundant searches by 37%.

</details>


### [52] [Silicon Minds versus Human Hearts: The Wisdom of Crowds Beats the Wisdom of AI in Emotion Recognition](https://arxiv.org/abs/2508.08830)
*Mustafa Akben,Vinayaka Gude,Haya Ajjan*

Main category: cs.AI

TL;DR: MLLMs在情绪识别任务中表现优于人类个体，但人类集体智慧和人机协作表现更佳。


<details>
  <summary>Details</summary>
Motivation: 探索AI（尤其是MLLMs）在情绪识别方面的能力，并比较其与人类的表现差异。

Method: 使用RMET和MRMET测试MLLMs和人类的情绪识别能力，并分析个体、集体及协作表现。

Result: MLLMs在个体测试中优于人类，但人类集体智慧表现更佳；人机协作表现最佳。

Conclusion: MLLMs在情绪识别方面有潜力，但人类集体智慧和协作模式更具前景。

Abstract: The ability to discern subtle emotional cues is fundamental to human social
intelligence. As artificial intelligence (AI) becomes increasingly common, AI's
ability to recognize and respond to human emotions is crucial for effective
human-AI interactions. In particular, whether such systems can match or surpass
human experts remains to be seen. However, the emotional intelligence of AI,
particularly multimodal large language models (MLLMs), remains largely
unexplored. This study evaluates the emotion recognition abilities of MLLMs
using the Reading the Mind in the Eyes Test (RMET) and its multiracial
counterpart (MRMET), and compares their performance against human participants.
Results show that, on average, MLLMs outperform humans in accurately
identifying emotions across both tests. This trend persists even when comparing
performance across low, medium, and expert-level performing groups. Yet when we
aggregate independent human decisions to simulate collective intelligence,
human groups significantly surpass the performance of aggregated MLLM
predictions, highlighting the wisdom of the crowd. Moreover, a collaborative
approach (augmented intelligence) that combines human and MLLM predictions
achieves greater accuracy than either humans or MLLMs alone. These results
suggest that while MLLMs exhibit strong emotion recognition at the individual
level, the collective intelligence of humans and the synergistic potential of
human-AI collaboration offer the most promising path toward effective emotional
AI. We discuss the implications of these findings for the development of
emotionally intelligent AI systems and future research directions.

</details>


### [53] [Reducing Cognitive Load in Multi-Agent Reinforcement Learning for Mathematical Problem Solving: Decoupling Reasoning and Code Generation](https://arxiv.org/abs/2508.08882)
*Dayu Wang,Jiaye Yang,Weikang Li,Jiahui Liang,Yang Li*

Main category: cs.AI

TL;DR: 论文提出了一种双代理混合框架，通过分离推理和代码生成任务，减少认知干扰，提升数学推理系统的性能。


<details>
  <summary>Details</summary>
Motivation: 当前单代理数学推理系统在同时处理推理和代码生成时存在认知负载干扰，导致性能下降。

Method: 采用双代理框架：推理代理负责问题分解，代码代理处理代码生成与执行。训练结合模仿学习和强化学习。

Result: 双代理框架显著减少了认知干扰，提升了推理和代码生成的协调性。

Conclusion: 分离推理和代码任务的设计有效提升了数学推理系统的稳定性和准确性。

Abstract: Current tool-integrated mathematical reasoning systems often adopt a
single-agent paradigm, where one large language model handles problem
reasoning, code generation, and code execution in an integrated workflow. While
this design eases coordination, we hypothesize that it imposes cognitive load
interference, as the agent must interleave long-horizon reasoning with precise
program synthesis. We validate this hypothesis through a controlled comparison
between a reasoning-only agent and a reasoning-plus-code agent, finding that
the latter produces significantly fewer correct reasoning paths despite having
tool-calling capabilities. To address this, we propose a dual-agent hybrid
framework: a Reasoning Agent performs stepwise problem decomposition, and a
Code Agent handles code generation and execution. Training combines imitation
learning and reinforcement learning: the Code Agent receives strong rewards for
matching intermediate ground-truth programs and weaker rewards for valid
execution, while the Reasoning Agent is optimized chiefly via final-answer
accuracy using advantage estimation to credit intermediate steps. This
decoupled role design reduces cognitive interference and promotes stable
reasoning-coding coordination.

</details>


### [54] [Compass-Thinker-7B Technical Report](https://arxiv.org/abs/2508.08909)
*Anxiang Zeng,Haibo Zhang,Kaixiang Mo,Long Zhang,Shuman Liu,Yanhui Huang,Yawen Liu,Yuepeng Sheng,Yuwei Huang*

Main category: cs.AI

TL;DR: Compass-Thinker-7B模型通过强化学习探索低资源高效推理潜力，在数学任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 减少在大规模模型上直接进行强化学习的高计算成本和资源需求，探索更高效的RL方法。

Method: 基于开源模型设计专用强化学习流程，使用3万可验证数学问题数据集，分阶段配置数据和训练设置。

Result: Compass-Thinker-7B在数学任务上表现优于同规模RL模型，AIME2024评测中达到40%准确率。

Conclusion: 该模型展示了强化学习在低资源条件下的潜力，为更大模型RL研究提供了参考。

Abstract: Recent R1-Zero-like research further demonstrates that reasoning extension
has given large language models (LLMs) unprecedented reasoning capabilities,
and Reinforcement Learning is the core technology to elicit its complex
reasoning. However, conducting RL experiments directly on hyperscale models
involves high computational costs and resource demands, posing significant
risks. We propose the Compass-Thinker-7B model, which aims to explore the
potential of Reinforcement Learning with less computational resources and
costs, and provides insights for further research into RL recipes for larger
models. Compass-Thinker-7B is trained from an open source model through a
specially designed Reinforcement Learning Pipeline. we curate a dataset of 30k
verifiable mathematics problems for the Reinforcement Learning Pipeline. By
configuring data and training settings with different difficulty distributions
for different stages, the potential of the model is gradually released and the
training efficiency is improved. Extensive evaluations show that
Compass-Thinker-7B possesses exceptional reasoning potential, and achieves
superior performance on mathematics compared to the same-sized RL
model.Especially in the challenging AIME2024 evaluation, Compass-Thinker-7B
achieves 40% accuracy.

</details>


### [55] [Safe Semantics, Unsafe Interpretations: Tackling Implicit Reasoning Safety in Large Vision-Language Models](https://arxiv.org/abs/2508.08926)
*Wei Cai,Jian Zhao,Yuchu Jiang,Tianle Zhang,Xuelong Li*

Main category: cs.AI

TL;DR: 论文提出隐式推理安全性概念，揭示大视觉语言模型在多模态输入下的安全隐患，并通过数据集SSUI展示问题，证明简单上下文学习可显著缓解威胁。


<details>
  <summary>Details</summary>
Motivation: 大视觉语言模型在多模态输入下存在安全隐患，隐式推理漏洞可能导致不安全输出，亟需解决。

Method: 提出隐式推理安全性概念，构建数据集SSUI，并通过上下文学习验证缓解效果。

Result: 实验表明，简单的上下文学习能显著减少隐式多模态威胁。

Conclusion: 需改进跨模态隐式推理能力，以应对大视觉语言模型的安全挑战。

Abstract: Large Vision-Language Models face growing safety challenges with multimodal
inputs. This paper introduces the concept of Implicit Reasoning Safety, a
vulnerability in LVLMs. Benign combined inputs trigger unsafe LVLM outputs due
to flawed or hidden reasoning. To showcase this, we developed Safe Semantics,
Unsafe Interpretations, the first dataset for this critical issue. Our
demonstrations show that even simple In-Context Learning with SSUI
significantly mitigates these implicit multimodal threats, underscoring the
urgent need to improve cross-modal implicit reasoning.

</details>


### [56] [Prospect Theory Fails for LLMs: Revealing Instability of Decision-Making under Epistemic Uncertainty](https://arxiv.org/abs/2508.08992)
*Rui Wang,Qihan Lin,Jiayu Liu,Qing Zong,Tianshi Zheng,Weiqi Wang,Yangqiu Song*

Main category: cs.AI

TL;DR: 研究探讨了前景理论（PT）是否适用于大型语言模型（LLMs），以及表达不确定性的认知标记是否影响其决策行为。通过三阶段实验和新的评估框架，发现PT对LLMs的建模并不完全可靠。


<details>
  <summary>Details</summary>
Motivation: 前景理论（PT）用于描述人类在不确定性下的决策行为，但尚未明确是否适用于LLMs，且认知标记（如“可能”）对LLMs决策的影响未被充分研究。

Method: 设计基于经济问卷的三阶段实验，提出更通用的评估框架，引入认知标记对应的概率值来研究其对LLMs决策的影响。

Result: 发现PT对LLMs的决策建模并不一致可靠，尤其是当不确定性以多样化语言形式表达时。

Conclusion: 研究表明，PT在LLMs中的应用存在局限性，认知标记的多样性会影响其决策行为。

Abstract: Prospect Theory (PT) models human decision-making under uncertainty, while
epistemic markers (e.g., maybe) serve to express uncertainty in language.
However, it remains largely unexplored whether Prospect Theory applies to
contemporary Large Language Models and whether epistemic markers, which express
human uncertainty, affect their decision-making behaviour. To address these
research gaps, we design a three-stage experiment based on economic
questionnaires. We propose a more general and precise evaluation framework to
model LLMs' decision-making behaviour under PT, introducing uncertainty through
the empirical probability values associated with commonly used epistemic
markers in comparable contexts. We then incorporate epistemic markers into the
evaluation framework based on their corresponding probability values to examine
their influence on LLM decision-making behaviours. Our findings suggest that
modelling LLMs' decision-making with PT is not consistently reliable,
particularly when uncertainty is expressed in diverse linguistic forms. Our
code is released in https://github.com/HKUST-KnowComp/MarPT.

</details>


### [57] [Intrinsic Memory Agents: Heterogeneous Multi-Agent LLM Systems through Structured Contextual Memory](https://arxiv.org/abs/2508.08997)
*Sizhe Yuen,Francisco Gomez Medina,Ting Su,Yali Du,Adam J. Sobey*

Main category: cs.AI

TL;DR: 论文提出了一种名为“Intrinsic Memory Agents”的新框架，通过结构化、与代理输出共同演化的记忆模板，解决了多代理LLM系统中的记忆一致性和任务完整性挑战。


<details>
  <summary>Details</summary>
Motivation: 多代理LLM系统在复杂协作问题解决中表现出潜力，但受限于上下文窗口，导致记忆一致性、角色遵循和程序完整性等问题。

Method: 采用结构化、代理特定的记忆模板，保持角色对齐的任务相关信息。

Result: 在PDDL数据集上性能提升38.6%，并在复杂数据管道设计任务中表现出更高的质量。

Conclusion: 通过结构化内在记忆方法，可以显著提升多代理LLM系统在结构化规划任务中的能力。

Abstract: Multi-agent systems built on Large Language Models (LLMs) show exceptional
promise for complex collaborative problem-solving, yet they face fundamental
challenges stemming from context window limitations that impair memory
consistency, role adherence, and procedural integrity. This paper introduces
Intrinsic Memory Agents, a novel framework that addresses these limitations
through structured agent-specific memories that evolve intrinsically with agent
outputs. Specifically, our method maintains role-aligned memory templates that
preserve specialized perspectives while focusing on task-relevant information.
We benchmark our approach on the PDDL dataset, comparing its performance to
existing state-of-the-art multi-agentic memory approaches and showing an
improvement of 38.6\% with the highest token efficiency. An additional
evaluation is performed on a complex data pipeline design task, we demonstrate
that our approach produces higher quality designs when comparing 5 metrics:
scalability, reliability, usability, cost-effectiveness and documentation with
additional qualitative evidence of the improvements. Our findings suggest that
addressing memory limitations through structured, intrinsic approaches can
improve the capabilities of multi-agent LLM systems on structured planning
tasks.

</details>


### [58] [Activation Steering for Bias Mitigation: An Interpretable Approach to Safer LLMs](https://arxiv.org/abs/2508.09019)
*Shivam Dubey*

Main category: cs.AI

TL;DR: 提出了一种端到端系统，利用机制可解释性技术直接在模型内部识别和缓解偏见，通过探测和引导向量实现实时干预。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型可能放大有害偏见，传统方法（如数据过滤或后处理）效果有限且不透明。

Method: 1. 训练线性探针检测模型内部偏见的潜在表示；2. 计算引导向量，通过激活模式对比实时干预生成过程。

Result: 在GPT-2-large上实验显示，探针能近乎完美识别偏见，引导向量成功将偏见输出转向中性。

Conclusion: 该系统为构建更安全、可解释的语言模型提供了直接且可复现的方法。

Abstract: As large language models (LLMs) become more integrated into societal systems,
the risk of them perpetuating and amplifying harmful biases becomes a critical
safety concern. Traditional methods for mitigating bias often rely on data
filtering or post-hoc output moderation, which treat the model as an opaque
black box. In this work, we introduce a complete, end-to-end system that uses
techniques from mechanistic interpretability to both identify and actively
mitigate bias directly within a model's internal workings. Our method involves
two primary stages. First, we train linear "probes" on the internal activations
of a model to detect the latent representations of various biases (e.g.,
gender, race, age). Our experiments on \texttt{gpt2-large} demonstrate that
these probes can identify biased content with near-perfect accuracy, revealing
that bias representations become most salient in the model's later layers.
Second, we leverage these findings to compute "steering vectors" by contrasting
the model's activation patterns for biased and neutral statements. By adding
these vectors during inference, we can actively steer the model's generative
process away from producing harmful, stereotypical, or biased content in
real-time. We demonstrate the efficacy of this activation steering technique,
showing that it successfully alters biased completions toward more neutral
alternatives. We present our work as a robust and reproducible system that
offers a more direct and interpretable approach to building safer and more
accountable LLMs.

</details>


### [59] [A First Look at Predictability and Explainability of Pre-request Passenger Waiting Time in Ridesharing Systems](https://arxiv.org/abs/2508.09027)
*Jie Wang,Guang Wang*

Main category: cs.AI

TL;DR: 论文提出了一种基于特征交互的XGBoost模型（FiXGBoost），用于预测乘客在提交乘车请求前的等待时间，提升了预测性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注已知匹配司机信息后的等待时间预测，而提交请求前的等待时间预测对乘客行程规划和用户体验同样重要，但尚未充分研究。

Method: 通过数据驱动分析供需动态对等待时间的影响，设计FiXGBoost模型，结合特征工程和重要性分析。

Result: 在大规模真实数据集（超3000万条记录）上，FiXGBoost表现出色，预测准确且可解释性强。

Conclusion: FiXGBoost为预请求等待时间预测提供了有效解决方案，填补了研究空白，并具有实际应用价值。

Abstract: Passenger waiting time prediction plays a critical role in enhancing both
ridesharing user experience and platform efficiency. While most existing
research focuses on post-request waiting time prediction with knowing the
matched driver information, pre-request waiting time prediction (i.e., before
submitting a ride request and without matching a driver) is also important, as
it enables passengers to plan their trips more effectively and enhance the
experience of both passengers and drivers. However, it has not been fully
studied by existing works. In this paper, we take the first step toward
understanding the predictability and explainability of pre-request passenger
waiting time in ridesharing systems. Particularly, we conduct an in-depth
data-driven study to investigate the impact of demand&supply dynamics on
passenger waiting time. Based on this analysis and feature engineering, we
propose FiXGBoost, a novel feature interaction-based XGBoost model designed to
predict waiting time without knowing the assigned driver information. We
further perform an importance analysis to quantify the contribution of each
factor. Experiments on a large-scale real-world ridesharing dataset including
over 30 million trip records show that our FiXGBoost can achieve a good
performance for pre-request passenger waiting time prediction with high
explainability.

</details>


### [60] [CVCM Track Circuits Pre-emptive Failure Diagnostics for Predictive Maintenance Using Deep Neural Networks](https://arxiv.org/abs/2508.09054)
*Debdeep Mukherjee,Eduardo Di Santi,Clément Lefebvre,Nenad Mijatovic,Victor Martin,Thierry Josse,Jonathan Brown,Kenza Saiah*

Main category: cs.AI

TL;DR: 提出了一种基于深度神经网络的预测性维护框架，用于早期检测铁路轨道电路中的异常，以减少故障和停机时间。


<details>
  <summary>Details</summary>
Motivation: 轨道电路故障可能导致连锁中断，传统方法难以检测早期细微异常，因此需要一种更有效的方法。

Method: 利用深度神经网络分类异常，并通过符合性预测提供不确定性估计。

Result: 在10个CVCM故障案例中验证，总体准确率达99.31%，检测时间在异常出现1%以内。

Conclusion: 该方法具有可扩展性，适用于全球部署的轨道电路和其他铁路系统，提高了运行可靠性。

Abstract: Track circuits are critical for railway operations, acting as the main
signalling sub-system to locate trains. Continuous Variable Current Modulation
(CVCM) is one such technology. Like any field-deployed, safety-critical asset,
it can fail, triggering cascading disruptions. Many failures originate as
subtle anomalies that evolve over time, often not visually apparent in
monitored signals. Conventional approaches, which rely on clear signal changes,
struggle to detect them early. Early identification of failure types is
essential to improve maintenance planning, minimising downtime and revenue
loss. Leveraging deep neural networks, we propose a predictive maintenance
framework that classifies anomalies well before they escalate into failures.
Validated on 10 CVCM failure cases across different installations, the method
is ISO-17359 compliant and outperforms conventional techniques, achieving
99.31% overall accuracy with detection within 1% of anomaly onset. Through
conformal prediction, we provide uncertainty estimates, reaching 99% confidence
with consistent coverage across classes. Given CVCMs global deployment, the
approach is scalable and adaptable to other track circuits and railway systems,
enhancing operational reliability.

</details>


### [61] [SMA: Who Said That? Auditing Membership Leakage in Semi-Black-box RAG Controlling](https://arxiv.org/abs/2508.09105)
*Shixuan Sun,Siyuan Liang,Ruoyu Chen,Jianjie Huang,Jingzhi Li,Xiaochun Cao*

Main category: cs.AI

TL;DR: 论文提出了一种名为SMA的方法，用于在多模态检索增强生成（MRAG）系统中追踪生成内容的来源，解决了现有方法无法区分预训练、外部检索或用户输入的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成方法（如RAG和MRAG）虽然提升了模型的知识覆盖和上下文理解能力，但无法可靠地追踪生成内容的来源，导致隐私泄露责任难以界定。

Method: 论文提出SMA方法，通过半黑盒设置和检索控制能力实现细粒度的来源追踪，并设计了基于零阶优化的归因估计机制，以及跨模态归因技术。

Result: SMA能够有效区分生成内容的来源（预训练、外部检索或用户输入），并首次实现了对MRAG系统中图像检索痕迹的成员推断。

Conclusion: SMA将成员推断的关注点从‘数据是否被记忆’转向‘内容来源何处’，为复杂生成系统的数据溯源审计提供了新视角。

Abstract: Retrieval-Augmented Generation (RAG) and its Multimodal Retrieval-Augmented
Generation (MRAG) significantly improve the knowledge coverage and contextual
understanding of Large Language Models (LLMs) by introducing external knowledge
sources. However, retrieval and multimodal fusion obscure content provenance,
rendering existing membership inference methods unable to reliably attribute
generated outputs to pre-training, external retrieval, or user input, thus
undermining privacy leakage accountability
  To address these challenges, we propose the first Source-aware Membership
Audit (SMA) that enables fine-grained source attribution of generated content
in a semi-black-box setting with retrieval control capabilities.To address the
environmental constraints of semi-black-box auditing, we further design an
attribution estimation mechanism based on zero-order optimization, which
robustly approximates the true influence of input tokens on the output through
large-scale perturbation sampling and ridge regression modeling. In addition,
SMA introduces a cross-modal attribution technique that projects image inputs
into textual descriptions via MLLMs, enabling token-level attribution in the
text modality, which for the first time facilitates membership inference on
image retrieval traces in MRAG systems. This work shifts the focus of
membership inference from 'whether the data has been memorized' to 'where the
content is sourced from', offering a novel perspective for auditing data
provenance in complex generative systems.

</details>


### [62] [OpenCUA: Open Foundations for Computer-Use Agents](https://arxiv.org/abs/2508.09123)
*Xinyuan Wang,Bowen Wang,Dunjie Lu,Junlin Yang,Tianbao Xie,Junli Wang,Jiaqi Deng,Xiaole Guo,Yiheng Xu,Chen Henry Wu,Zhennan Shen,Zhuokai Li,Ryan Li,Xiaochuan Li,Junda Chen,Boyuan Zheng,Peihang Li,Fangyu Lei,Ruisheng Cao,Yeqiao Fu,Dongchan Shin,Martin Shin,Jiarui Hu,Yuyan Wang,Jixuan Chen,Yuxiao Ye,Danyang Zhang,Dikang Du,Hao Hu,Huarong Chen,Zaida Zhou,Yipu Wang,Heng Wang,Diyi Yang,Victor Zhong,Flood Sung,Y. Charles,Zhilin Yang,Tao Yu*

Main category: cs.AI

TL;DR: OpenCUA是一个开源框架，旨在推动计算机使用代理（CUA）的研究，提供数据、模型和工具，并在性能上超越现有开源模型。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型在计算机任务中的潜力增长，封闭系统的细节限制了研究。OpenCUA旨在提供开放框架，以研究CUA的能力、局限性和风险。

Method: OpenCUA包括注释基础设施、大规模数据集AgentNet和可扩展的演示转换管道，支持长链推理。

Result: OpenCUA-32B在OSWorld-Verified上达到34.8%的平均成功率，超越GPT-4o，成为开源模型的新SOTA。

Conclusion: OpenCUA为CUA研究提供了开放基础，其方法在跨领域泛化和计算扩展方面表现优异。

Abstract: Vision-language models have demonstrated impressive capabilities as
computer-use agents (CUAs) capable of automating diverse computer tasks. As
their commercial potential grows, critical details of the most capable CUA
systems remain closed. As these agents will increasingly mediate digital
interactions and execute consequential decisions on our behalf, the research
community needs access to open CUA frameworks to study their capabilities,
limitations, and risks. To bridge this gap, we propose OpenCUA, a comprehensive
open-source framework for scaling CUA data and foundation models. Our framework
consists of: (1) an annotation infrastructure that seamlessly captures human
computer-use demonstrations; (2) AgentNet, the first large-scale computer-use
task dataset spanning 3 operating systems and 200+ applications and websites;
(3) a scalable pipeline that transforms demonstrations into state-action pairs
with reflective long Chain-of-Thought reasoning that sustain robust performance
gains as data scales. Our end-to-end agent models demonstrate strong
performance across CUA benchmarks. In particular, OpenCUA-32B achieves an
average success rate of 34.8% on OSWorld-Verified, establishing a new
state-of-the-art (SOTA) among open-source models and surpassing OpenAI CUA
(GPT-4o). Further analysis confirms that our approach generalizes well across
domains and benefits significantly from increased test-time computation. We
release our annotation tool, datasets, code, and models to build open
foundations for further CUA research.

</details>


### [63] [BrowseMaster: Towards Scalable Web Browsing via Tool-Augmented Programmatic Agent Pair](https://arxiv.org/abs/2508.09129)
*Xianghe Pang,Shuo Tang,Rui Ye,Yuwen Du,Yaxin Du,Siheng Chen*

Main category: cs.AI

TL;DR: BrowseMaster是一个可扩展的框架，通过规划器-执行器代理对解决LLM代理在搜索广度和推理深度上的限制，显著提升了复杂信息检索任务的性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型（LLM）的代理在信息检索中存在搜索广度不足和推理深度受限的问题，无法平衡广泛搜索与策略推理。

Method: 提出BrowseMaster框架，采用规划器制定搜索策略，执行器进行高效检索，两者协同工作以保持连贯的多步推理和广泛探索。

Result: 在英语和中文基准测试中，BrowseMaster表现优异，得分分别为30.0（BrowseComp-en）和46.5（BrowseComp-zh），超越开源和商业基线。

Conclusion: BrowseMaster通过分工协作解决了现有代理的局限性，展示了在复杂推理密集型信息检索任务中的强大能力。

Abstract: Effective information seeking in the vast and ever-growing digital landscape
requires balancing expansive search with strategic reasoning. Current large
language model (LLM)-based agents struggle to achieve this balance due to
limitations in search breadth and reasoning depth, where slow, serial querying
restricts coverage of relevant sources and noisy raw inputs disrupt the
continuity of multi-step reasoning. To address these challenges, we propose
BrowseMaster, a scalable framework built around a programmatically augmented
planner-executor agent pair. The planner formulates and adapts search
strategies based on task constraints, while the executor conducts efficient,
targeted retrieval to supply the planner with concise, relevant evidence. This
division of labor preserves coherent, long-horizon reasoning while sustaining
broad and systematic exploration, overcoming the trade-off that limits existing
agents. Extensive experiments on challenging English and Chinese benchmarks
show that BrowseMaster consistently outperforms open-source and proprietary
baselines, achieving scores of 30.0 on BrowseComp-en and 46.5 on BrowseComp-zh,
which demonstrates its strong capability in complex, reasoning-heavy
information-seeking tasks at scale.

</details>
