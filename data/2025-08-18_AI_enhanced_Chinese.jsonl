{"id": "2508.10976", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.10976", "abs": "https://arxiv.org/abs/2508.10976", "authors": ["Martin Diller", "Sarah Alice Gaggl", "Philipp Hanisch", "Giuseppina Monterosso", "Fritz Rauschenbach"], "title": "Grounding Rule-Based Argumentation Using Datalog", "comment": null, "summary": "ASPIC+ is one of the main general frameworks for rule-based argumentation for\nAI. Although first-order rules are commonly used in ASPIC+ examples, most\nexisting approaches to reason over rule-based argumentation only support\npropositional rules. To enable reasoning over first-order instances, a\npreliminary grounding step is required. As groundings can lead to an\nexponential increase in the size of the input theories, intelligent procedures\nare needed. However, there is a lack of dedicated solutions for ASPIC+.\nTherefore, we propose an intelligent grounding procedure that keeps the size of\nthe grounding manageable while preserving the correctness of the reasoning\nprocess. To this end, we translate the first-order ASPIC+ instance into a\nDatalog program and query a Datalog engine to obtain ground substitutions to\nperform the grounding of rules and contraries. Additionally, we propose\nsimplifications specific to the ASPIC+ formalism to avoid grounding of rules\nthat have no influence on the reasoning process. Finally, we performed an\nempirical evaluation of a prototypical implementation to show scalability.", "AI": {"tldr": "ASPIC+\u6846\u67b6\u7f3a\u4e4f\u5bf9\u4e00\u9636\u89c4\u5219\u63a8\u7406\u7684\u667a\u80fd\u57fa\u7840\u5316\u65b9\u6cd5\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eDatalog\u7684\u667a\u80fd\u57fa\u7840\u5316\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709ASPIC+\u65b9\u6cd5\u4e3b\u8981\u652f\u6301\u547d\u9898\u89c4\u5219\uff0c\u7f3a\u4e4f\u5bf9\u4e00\u9636\u89c4\u5219\u7684\u9ad8\u6548\u57fa\u7840\u5316\u65b9\u6cd5\uff0c\u5bfc\u81f4\u8f93\u5165\u7406\u8bba\u89c4\u6a21\u53ef\u80fd\u6307\u6570\u7ea7\u589e\u957f\u3002", "method": "\u5c06\u4e00\u9636ASPIC+\u5b9e\u4f8b\u8f6c\u5316\u4e3aDatalog\u7a0b\u5e8f\uff0c\u5229\u7528Datalog\u5f15\u64ce\u83b7\u53d6\u57fa\u7840\u5316\u89c4\u5219\u548c\u53cd\u4f8b\uff0c\u5e76\u9488\u5bf9ASPIC+\u5f62\u5f0f\u5316\u63d0\u51fa\u7b80\u5316\u65b9\u6cd5\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u63a7\u5236\u57fa\u7840\u5316\u89c4\u6a21\uff0c\u540c\u65f6\u4fdd\u6301\u63a8\u7406\u6b63\u786e\u6027\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u672c\u6587\u65b9\u6cd5\u586b\u8865\u4e86ASPIC+\u5728\u4e00\u9636\u89c4\u5219\u63a8\u7406\u4e2d\u7684\u7a7a\u767d\uff0c\u4e3a\u9ad8\u6548\u57fa\u7840\u5316\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2508.11034", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.11034", "abs": "https://arxiv.org/abs/2508.11034", "authors": ["Antonio Collante", "Samuel Abedu", "SayedHassan Khatoonabadi", "Ahmad Abdellatif", "Ebube Alor", "Emad Shihab"], "title": "The Impact of Large Language Models (LLMs) on Code Review Process", "comment": null, "summary": "Large language models (LLMs) have recently gained prominence in the field of\nsoftware development, significantly boosting productivity and simplifying\nteamwork. Although prior studies have examined task-specific applications, the\nphase-specific effects of LLM assistance on the efficiency of code review\nprocesses remain underexplored. This research investigates the effect of GPT on\nGitHub pull request (PR) workflows, with a focus on reducing resolution time,\noptimizing phase-specific performance, and assisting developers. We curated a\ndataset of 25,473 PRs from 9,254 GitHub projects and identified GPT-assisted\nPRs using a semi-automated heuristic approach that combines keyword-based\ndetection, regular expression filtering, and manual verification until\nachieving 95% labeling accuracy. We then applied statistical modeling,\nincluding multiple linear regression and Mann-Whitney U test, to evaluate\ndifferences between GPT-assisted and non-assisted PRs, both at the overall\nresolution level and across distinct review phases. Our research has revealed\nthat early adoption of GPT can substantially boost the effectiveness of the PR\nprocess, leading to considerable time savings at various stages. Our findings\nsuggest that GPT-assisted PRs reduced median resolution time by more than 60%\n(9 hours compared to 23 hours for non-assisted PRs). We discovered that\nutilizing GPT can reduce the review time by 33% and the waiting time before\nacceptance by 87%. Analyzing a sample dataset of 300 GPT-assisted PRs, we\ndiscovered that developers predominantly use GPT for code optimization (60%),\nbug fixing (26%), and documentation updates (12%). This research sheds light on\nthe impact of the GPT model on the code review process, offering actionable\ninsights for software teams seeking to enhance workflows and promote seamless\ncollaboration.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86GPT\u5728GitHub\u4ee3\u7801\u5ba1\u67e5\u6d41\u7a0b\u4e2d\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5176\u80fd\u663e\u8457\u51cf\u5c11\u89e3\u51b3\u65f6\u95f4\uff0c\u4f18\u5316\u5404\u9636\u6bb5\u6027\u80fd\uff0c\u5e76\u5e2e\u52a9\u5f00\u53d1\u8005\u3002", "motivation": "\u5c3d\u7ba1LLMs\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u5728\u4ee3\u7801\u5ba1\u67e5\u6d41\u7a0b\u4e2d\u7684\u9636\u6bb5\u7279\u5f02\u6027\u5f71\u54cd\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u534a\u81ea\u52a8\u5316\u65b9\u6cd5\u8bc6\u522bGPT\u8f85\u52a9\u7684PRs\uff0c\u5e76\u5e94\u7528\u7edf\u8ba1\u5efa\u6a21\uff08\u5982\u591a\u5143\u7ebf\u6027\u56de\u5f52\u548cMann-Whitney U\u68c0\u9a8c\uff09\u5206\u6790\u6570\u636e\u3002", "result": "GPT\u8f85\u52a9\u7684PRs\u4e2d\u4f4d\u89e3\u51b3\u65f6\u95f4\u51cf\u5c1160%\uff089\u5c0f\u65f6vs 23\u5c0f\u65f6\uff09\uff0c\u5ba1\u67e5\u65f6\u95f4\u51cf\u5c1133%\uff0c\u7b49\u5f85\u65f6\u95f4\u51cf\u5c1187%\u3002", "conclusion": "GPT\u5728\u4ee3\u7801\u5ba1\u67e5\u4e2d\u7684\u65e9\u671f\u91c7\u7528\u80fd\u663e\u8457\u63d0\u5347\u6548\u7387\uff0c\u4e3a\u56e2\u961f\u534f\u4f5c\u63d0\u4f9b\u5b9e\u7528\u5efa\u8bae\u3002"}}
{"id": "2508.11070", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.11070", "abs": "https://arxiv.org/abs/2508.11070", "authors": ["Zahra Khotanlou", "Kate Larson", "Amir-Hossein Karimi"], "title": "From Individual to Multi-Agent Algorithmic Recourse: Minimizing the Welfare Gap via Capacitated Bipartite Matching", "comment": null, "summary": "Decision makers are increasingly relying on machine learning in sensitive\nsituations. In such settings, algorithmic recourse aims to provide individuals\nwith actionable and minimally costly steps to reverse unfavorable AI-driven\ndecisions. While existing research predominantly focuses on single-individual\n(i.e., seeker) and single-model (i.e., provider) scenarios, real-world\napplications often involve multiple interacting stakeholders. Optimizing\noutcomes for seekers under an individual welfare approach overlooks the\ninherently multi-agent nature of real-world systems, where individuals interact\nand compete for limited resources. To address this, we introduce a novel\nframework for multi-agent algorithmic recourse that accounts for multiple\nrecourse seekers and recourse providers. We model this many-to-many interaction\nas a capacitated weighted bipartite matching problem, where matches are guided\nby both recourse cost and provider capacity. Edge weights, reflecting recourse\ncosts, are optimized for social welfare while quantifying the welfare gap\nbetween individual welfare and this collectively feasible outcome. We propose a\nthree-layer optimization framework: (1) basic capacitated matching, (2) optimal\ncapacity redistribution to minimize the welfare gap, and (3) cost-aware\noptimization balancing welfare maximization with capacity adjustment costs.\nExperimental validation on synthetic and real-world datasets demonstrates that\nour framework enables the many-to-many algorithmic recourse to achieve\nnear-optimal welfare with minimum modification in system settings. This work\nextends algorithmic recourse from individual recommendations to system-level\ndesign, providing a tractable path toward higher social welfare while\nmaintaining individual actionability.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u4e3b\u4f53\u7b97\u6cd5\u8ffd\u7d22\u6846\u67b6\uff0c\u89e3\u51b3\u591a\u8ffd\u7d22\u8005\u548c\u63d0\u4f9b\u8005\u4ea4\u4e92\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u5c42\u4f18\u5316\u5b9e\u73b0\u793e\u4f1a\u798f\u5229\u6700\u5927\u5316\u3002", "motivation": "\u73b0\u5b9e\u5e94\u7528\u4e2d\uff0c\u7b97\u6cd5\u8ffd\u7d22\u901a\u5e38\u6d89\u53ca\u591a\u4e2a\u4ea4\u4e92\u4e3b\u4f53\uff0c\u800c\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u5355\u4e3b\u4f53\u573a\u666f\uff0c\u5ffd\u7565\u4e86\u591a\u4e3b\u4f53\u7ade\u4e89\u8d44\u6e90\u7684\u590d\u6742\u6027\u3002", "method": "\u5c06\u591a\u5bf9\u591a\u4ea4\u4e92\u5efa\u6a21\u4e3a\u5e26\u6743\u4e8c\u5206\u56fe\u5339\u914d\u95ee\u9898\uff0c\u63d0\u51fa\u4e09\u5c42\u4f18\u5316\u6846\u67b6\uff1a\u57fa\u7840\u5339\u914d\u3001\u5bb9\u91cf\u518d\u5206\u914d\u548c\u6210\u672c\u611f\u77e5\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u5728\u7cfb\u7edf\u8bbe\u7f6e\u6700\u5c0f\u4fee\u6539\u4e0b\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u7684\u793e\u4f1a\u798f\u5229\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c06\u7b97\u6cd5\u8ffd\u7d22\u4ece\u4e2a\u4f53\u63a8\u8350\u6269\u5c55\u5230\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u517c\u987e\u793e\u4f1a\u798f\u5229\u4e0e\u4e2a\u4f53\u53ef\u64cd\u4f5c\u6027\u3002"}}
{"id": "2508.11110", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.11110", "abs": "https://arxiv.org/abs/2508.11110", "authors": ["Mukul Singh", "Gust Verbruggen", "Vu Le", "Sumit Gulwani"], "title": "Diffusion is a code repair operator and generator", "comment": "12 pages", "summary": "Code diffusion models generate code by iteratively removing noise from the\nlatent representation of a code snippet. During later steps of the diffusion\nprocess, when the code snippet has almost converged, differences between\ndiscrete representations of these snippets look like last-mile repairs applied\nto broken or incomplete code. We evaluate the extent to which this resemblance\ncan be exploited to leverage pre-trained code diffusion models for the problem\nof last-mile repair by considering two applications with significant potential.\nFirst, we can leverage the diffusion model for last-mile repair by adding noise\nto a broken code snippet and resuming the diffusion process. Second, we can\nleverage the diffusion model to generate arbitrary amount of training data for\nlast-mile repair tasks (that are computationally more efficient) by sampling an\nintermediate program (input) and the final program (output) from the diffusion\nprocess. We perform experiments on 3 domains (Python, Excel and PowerShell) to\nevaluate applications, as well as analyze properties.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5982\u4f55\u5229\u7528\u9884\u8bad\u7ec3\u7684\u4ee3\u7801\u6269\u6563\u6a21\u578b\u8fdb\u884c\u201c\u6700\u540e\u4e00\u82f1\u91cc\u4fee\u590d\u201d\uff0c\u901a\u8fc7\u6dfb\u52a0\u566a\u58f0\u6216\u751f\u6210\u8bad\u7ec3\u6570\u636e\u6765\u4f18\u5316\u4ee3\u7801\u7247\u6bb5\u3002", "motivation": "\u63a2\u7d22\u6269\u6563\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u540e\u671f\u9636\u6bb5\u7684\u6f5c\u529b\uff0c\u5229\u7528\u5176\u4fee\u590d\u80fd\u529b\u89e3\u51b3\u4ee3\u7801\u7247\u6bb5\u7684\u4e0d\u5b8c\u6574\u6216\u9519\u8bef\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u6dfb\u52a0\u566a\u58f0\u5e76\u6062\u590d\u6269\u6563\u8fc7\u7a0b\uff0c\u6216\u4ece\u6269\u6563\u8fc7\u7a0b\u4e2d\u91c7\u6837\u751f\u6210\u8bad\u7ec3\u6570\u636e\uff0c\u8bc4\u4f30\u5176\u5728Python\u3001Excel\u548cPowerShell\u4e2d\u7684\u5e94\u7528\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6269\u6563\u6a21\u578b\u53ef\u4ee5\u6709\u6548\u7528\u4e8e\u6700\u540e\u4e00\u82f1\u91cc\u4fee\u590d\uff0c\u5e76\u751f\u6210\u5927\u91cf\u8bad\u7ec3\u6570\u636e\u3002", "conclusion": "\u6269\u6563\u6a21\u578b\u5728\u4ee3\u7801\u4fee\u590d\u548c\u8bad\u7ec3\u6570\u636e\u751f\u6210\u65b9\u9762\u5177\u6709\u663e\u8457\u6f5c\u529b\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\u548c\u5de5\u5177\u3002"}}
{"id": "2508.11085", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.11085", "abs": "https://arxiv.org/abs/2508.11085", "authors": ["Qingqing Wang", "Liqiang Xiao", "Chang Chang"], "title": "Learn to optimize for automatic proton PBS treatment planning for H&N cancers", "comment": "27 pages, 4 figures", "summary": "Proton PBS treatment planning for H&N cancers involves numerous conflicting\nobjectives, requiring significant effort from human planners to balance and\nsatisfy multiple clinical goals during planning. To achieve this,\nexperience-demanding objective parameter adjustment and computationally\nexpensive inverse optimization are performed iteratively. Extensive efforts\nhave been made to automatically adjust objective parameters, but the most\ntime-consuming component, i.e., inverse optimization, still relies heavily on\ntheory-driven approaches. We propose a data-driven inverse optimizer and\nintegrate it into a PPO-based automatic treatment planning framework to\nautomatically generate high-quality plans within a clinical acceptable planning\ntime. The inverse optimizer is a L2O method that predicts update steps by\nlearning from the task-specific data distribution. For the first time, we\nintegrate techniques designed for long-context processing, originally developed\nfor LLMs, into a Transformer-based L2O framework to address the scalability\nissue of existing L2O methods. The PPO framework functions as an outer-loop\nvirtual planner, autonomously adjusting objective parameters through a policy\nnetwork, and the dose predictor is used to initialize objective parameters. The\ninner-loop L2O inverse optimizer computes machine-deliverable MU values based\non objectives refined by the PPO policy network. 97 patients are collected in\nthis study, and compared with L-BFGSB, our L2O-based inverse optimizer improves\nthe effectiveness and efficiency by 22.97% and 36.41%, respectively. In\nconjunction with the PPO-based learned virtual planner, plans generated by our\nframework within an average of 2.55 hours show improved or comparable OAR\nsparing with superior target coverage for patients with different prescription\ndose levels, number of target volumes, beam angles, etc., compared with\nhuman-generated plans.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6570\u636e\u9a71\u52a8\u7684\u9006\u4f18\u5316\u5668\u548cPPO\u6846\u67b6\u7684\u81ea\u52a8\u6cbb\u7597\u8ba1\u5212\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86H&N\u764c\u75c7\u8d28\u5b50PBS\u6cbb\u7597\u8ba1\u5212\u7684\u6548\u7387\u548c\u8d28\u91cf\u3002", "motivation": "\u4f20\u7edf\u8d28\u5b50PBS\u6cbb\u7597\u8ba1\u5212\u4e2d\uff0c\u76ee\u6807\u53c2\u6570\u8c03\u6574\u548c\u9006\u4f18\u5316\u8017\u65f6\u4e14\u4f9d\u8d56\u7ecf\u9a8c\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u65b9\u6cd5\u63d0\u5347\u6548\u7387\u3002", "method": "\u7ed3\u5408L2O\u9006\u4f18\u5316\u5668\u548cPPO\u6846\u67b6\uff0c\u5229\u7528Transformer\u5904\u7406\u957f\u4e0a\u4e0b\u6587\uff0c\u81ea\u52a8\u8c03\u6574\u76ee\u6807\u53c2\u6570\u5e76\u751f\u6210\u9ad8\u8d28\u91cf\u8ba1\u5212\u3002", "result": "\u76f8\u6bd4L-BFGSB\uff0cL2O\u9006\u4f18\u5316\u5668\u6548\u7387\u63d0\u534736.41%\uff0c\u6548\u679c\u63d0\u534722.97%\uff1b\u751f\u6210\u7684\u8ba1\u5212\u57282.55\u5c0f\u65f6\u5185\u8fbe\u5230\u6216\u4f18\u4e8e\u4eba\u5de5\u8ba1\u5212\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6cbb\u7597\u8ba1\u5212\u7684\u81ea\u52a8\u5316\u6c34\u5e73\u548c\u4e34\u5e8a\u9002\u7528\u6027\uff0c\u4e3a\u590d\u6742\u75c5\u4f8b\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.11126", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.11126", "abs": "https://arxiv.org/abs/2508.11126", "authors": ["Huanting Wang", "Jingzhi Gong", "Huawei Zhang", "Zheng Wang"], "title": "AI Agentic Programming: A Survey of Techniques, Challenges, and Opportunities", "comment": null, "summary": "AI agentic programming is an emerging paradigm in which large language models\n(LLMs) autonomously plan, execute, and interact with external tools like\ncompilers, debuggers, and version control systems to iteratively perform\ncomplex software development tasks. Unlike conventional code generation tools,\nagentic systems are capable of decomposing high-level goals, coordinating\nmulti-step processes, and adapting their behavior based on intermediate\nfeedback. These capabilities are transforming the software development\npractice. As this emerging field evolves rapidly, there is a need to define its\nscope, consolidate its technical foundations, and identify open research\nchallenges. This survey provides a comprehensive and timely review of AI\nagentic programming. We introduce a taxonomy of agent behaviors and system\narchitectures, and examine core techniques including planning, memory and\ncontext management, tool integration, and execution monitoring. We also analyze\nexisting benchmarks and evaluation methodologies used to assess coding agent\nperformance. Our study identifies several key challenges, including limitations\nin handling long context, a lack of persistent memory across tasks, and\nconcerns around safety, alignment with user intent, and collaboration with\nhuman developers. We discuss emerging opportunities to improve the reliability,\nadaptability, and transparency of agentic systems. By synthesizing recent\nadvances and outlining future directions, this survey aims to provide a\nfoundation for research and development in building the next generation of\nintelligent and trustworthy AI coding agents.", "AI": {"tldr": "AI agentic programming\u662f\u4e00\u79cd\u65b0\u5174\u8303\u5f0f\uff0c\u5229\u7528LLMs\u81ea\u4e3b\u89c4\u5212\u3001\u6267\u884c\u548c\u4e0e\u5916\u90e8\u5de5\u5177\u4ea4\u4e92\uff0c\u5b8c\u6210\u590d\u6742\u8f6f\u4ef6\u5f00\u53d1\u4efb\u52a1\u3002\u672c\u6587\u7efc\u8ff0\u4e86\u5176\u884c\u4e3a\u5206\u7c7b\u3001\u7cfb\u7edf\u67b6\u6784\u3001\u6838\u5fc3\u6280\u672f\u53ca\u6311\u6218\u3002", "motivation": "\u968f\u7740AI agentic\u7f16\u7a0b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u9700\u8981\u660e\u786e\u5176\u8303\u56f4\u3001\u5de9\u56fa\u6280\u672f\u57fa\u7840\u5e76\u8bc6\u522b\u7814\u7a76\u6311\u6218\u3002", "method": "\u901a\u8fc7\u5206\u7c7b\u4ee3\u7406\u884c\u4e3a\u4e0e\u7cfb\u7edf\u67b6\u6784\uff0c\u5206\u6790\u89c4\u5212\u3001\u8bb0\u5fc6\u7ba1\u7406\u3001\u5de5\u5177\u96c6\u6210\u7b49\u6838\u5fc3\u6280\u672f\uff0c\u5e76\u8bc4\u4f30\u73b0\u6709\u57fa\u51c6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u3001\u6301\u4e45\u8bb0\u5fc6\u4e0d\u8db3\u53ca\u5b89\u5168\u6027\u7b49\u6311\u6218\uff0c\u540c\u65f6\u63d0\u51fa\u6539\u8fdb\u53ef\u9760\u6027\u548c\u900f\u660e\u6027\u7684\u673a\u4f1a\u3002", "conclusion": "\u672c\u6587\u4e3a\u6784\u5efa\u4e0b\u4e00\u4ee3\u667a\u80fd\u53ef\u4fe1AI\u7f16\u7a0b\u4ee3\u7406\u63d0\u4f9b\u4e86\u7814\u7a76\u57fa\u7840\u4e0e\u672a\u6765\u65b9\u5411\u3002"}}
{"id": "2508.10991", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.10991", "abs": "https://arxiv.org/abs/2508.10991", "authors": ["Wenpeng Xing", "Zhonghao Qi", "Yupeng Qin", "Yilin Li", "Caini Chang", "Jiahui Yu", "Changting Lin", "Zhenzhen Xie", "Meng Han"], "title": "MCP-Guard: A Defense Framework for Model Context Protocol Integrity in Large Language Model Applications", "comment": null, "summary": "The integration of Large Language Models (LLMs) with external tools via\nprotocols such as the Model Context Protocol (MCP) introduces critical security\nvulnerabilities, including prompt injection, data exfiltration, and other\nthreats. To counter these challenges, we propose MCP-Guard, a robust, layered\ndefense architecture designed for LLM--tool interactions. MCP-Guard employs a\nthree-stage detection pipeline that balances efficiency with accuracy: it\nprogresses from lightweight static scanning for overt threats and a deep neural\ndetector for semantic attacks, to our fine-tuned E5-based model achieves\n(96.01) accuracy in identifying adversarial prompts. Finally, a lightweight LLM\narbitrator synthesizes these signals to deliver the final decision while\nminimizing false positives. To facilitate rigorous training and evaluation, we\nalso introduce MCP-AttackBench, a comprehensive benchmark of over 70,000\nsamples. Sourced from public datasets and augmented by GPT-4, MCP-AttackBench\nsimulates diverse, real-world attack vectors in the MCP format, providing a\nfoundation for future research into securing LLM-tool ecosystems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faMCP-Guard\uff0c\u4e00\u79cd\u9488\u5bf9LLM\u4e0e\u5de5\u5177\u4ea4\u4e92\u7684\u5b89\u5168\u9632\u5fa1\u67b6\u6784\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u68c0\u6d4b\u7ba1\u9053\u5e94\u5bf9\u5b89\u5168\u5a01\u80c1\uff0c\u5e76\u5f15\u5165MCP-AttackBench\u4f5c\u4e3a\u8bc4\u4f30\u57fa\u51c6\u3002", "motivation": "LLM\u4e0e\u5916\u90e8\u5de5\u5177\u96c6\u6210\uff08\u5982\u901a\u8fc7MCP\u534f\u8bae\uff09\u4f1a\u5f15\u5165\u5b89\u5168\u6f0f\u6d1e\uff08\u5982\u63d0\u793a\u6ce8\u5165\u3001\u6570\u636e\u6cc4\u9732\u7b49\uff09\uff0c\u4e9f\u9700\u89e3\u51b3\u65b9\u6848\u3002", "method": "MCP-Guard\u91c7\u7528\u4e09\u9636\u6bb5\u68c0\u6d4b\u7ba1\u9053\uff1a\u8f7b\u91cf\u7ea7\u9759\u6001\u626b\u63cf\u3001\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u68c0\u6d4b\u8bed\u4e49\u653b\u51fb\u3001E5\u5fae\u8c03\u6a21\u578b\uff08\u51c6\u786e\u738796.01%\uff09\uff0c\u6700\u540e\u901a\u8fc7\u8f7b\u91cf\u7ea7LLM\u4ef2\u88c1\u5668\u7efc\u5408\u51b3\u7b56\u3002", "result": "MCP-Guard\u5728\u8bc6\u522b\u5bf9\u6297\u6027\u63d0\u793a\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff08\u51c6\u786e\u738796.01%\uff09\uff0c\u5e76\u5f00\u53d1\u4e86\u5305\u542b70,000\u6837\u672c\u7684MCP-AttackBench\u4f5c\u4e3a\u8bc4\u4f30\u57fa\u51c6\u3002", "conclusion": "MCP-Guard\u4e3aLLM-\u5de5\u5177\u4ea4\u4e92\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u51c6\u786e\u7684\u5b89\u5168\u9632\u5fa1\u65b9\u6848\uff0cMCP-AttackBench\u4e3a\u672a\u6765\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.11182", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.11182", "abs": "https://arxiv.org/abs/2508.11182", "authors": ["Matti Berthold", "Lydia Bl\u00fcmel", "Anna Rapberger"], "title": "On Strong and Weak Admissibility in Non-Flat Assumption-Based Argumentation", "comment": null, "summary": "In this work, we broaden the investigation of admissibility notions in the\ncontext of assumption-based argumentation (ABA). More specifically, we study\ntwo prominent alternatives to the standard notion of admissibility from\nabstract argumentation, namely strong and weak admissibility, and introduce the\nrespective preferred, complete and grounded semantics for general (sometimes\ncalled non-flat) ABA. To do so, we use abstract bipolar set-based argumentation\nframeworks (BSAFs) as formal playground since they concisely capture the\nrelations between assumptions and are expressive enough to represent general\nnon-flat ABA frameworks, as recently shown. While weak admissibility has been\nrecently investigated for a restricted fragment of ABA in which assumptions\ncannot be derived (flat ABA), strong admissibility has not been investigated\nfor ABA so far. We introduce strong admissibility for ABA and investigate\ndesirable properties. We furthermore extend the recent investigations of weak\nadmissibility in the flat ABA fragment to the non-flat case. We show that the\ncentral modularization property is maintained under classical, strong, and weak\nadmissibility. We also show that strong and weakly admissible semantics in\nnon-flat ABA share some of the shortcomings of standard admissible semantics\nand discuss ways to address these.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u5047\u8bbe\u57fa\u7840\u8bba\u8bc1\uff08ABA\uff09\u4e2d\u53ef\u63a5\u53d7\u6027\u6982\u5ff5\u7684\u7814\u7a76\uff0c\u91cd\u70b9\u7814\u7a76\u4e86\u5f3a\u548c\u5f31\u53ef\u63a5\u53d7\u6027\uff0c\u5e76\u5f15\u5165\u4e86\u76f8\u5e94\u7684\u4f18\u9009\u3001\u5b8c\u5168\u548c\u57fa\u7840\u8bed\u4e49\u3002", "motivation": "\u7814\u7a76ABA\u4e2d\u975e\u6807\u51c6\u53ef\u63a5\u53d7\u6027\u6982\u5ff5\uff08\u5f3a\u548c\u5f31\u53ef\u63a5\u53d7\u6027\uff09\u53ca\u5176\u5728\u975e\u5e73\u5766ABA\u6846\u67b6\u4e2d\u7684\u5e94\u7528\uff0c\u586b\u8865\u5f3a\u53ef\u63a5\u53d7\u6027\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u4f7f\u7528\u62bd\u8c61\u53cc\u6781\u96c6\u5408\u57fa\u7840\u8bba\u8bc1\u6846\u67b6\uff08BSAFs\uff09\u4f5c\u4e3a\u5f62\u5f0f\u5316\u5de5\u5177\uff0c\u7814\u7a76\u5f3a\u548c\u5f31\u53ef\u63a5\u53d7\u6027\u5728\u975e\u5e73\u5766ABA\u4e2d\u7684\u6027\u8d28\u3002", "result": "\u8bc1\u660e\u4e86\u5f3a\u548c\u5f31\u53ef\u63a5\u53d7\u6027\u5728\u975e\u5e73\u5766ABA\u4e2d\u4fdd\u6301\u6a21\u5757\u5316\u6027\u8d28\uff0c\u4f46\u4e5f\u5b58\u5728\u4e0e\u6807\u51c6\u53ef\u63a5\u53d7\u6027\u7c7b\u4f3c\u7684\u7f3a\u9677\u3002", "conclusion": "\u5f3a\u548c\u5f31\u53ef\u63a5\u53d7\u6027\u5728\u975e\u5e73\u5766ABA\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u89e3\u51b3\u5176\u7f3a\u9677\u3002"}}
{"id": "2508.11147", "categories": ["cs.SE", "D.2.5"], "pdf": "https://arxiv.org/pdf/2508.11147", "abs": "https://arxiv.org/abs/2508.11147", "authors": ["Zhengquan Li", "Zhenhao Li", "Zishuo Ding"], "title": "From Feedback to Failure: Automated Android Performance Issue Reproduction", "comment": "10page, 8 figures", "summary": "Mobile application performance is a vital factor for user experience. Yet,\nperformance issues are notoriously difficult to detect within development\nenvironments, where their manifestations are often less conspicuous and\ndiagnosis proves more challenging. To address this limitation, we propose\nRevPerf, an advanced performance issue reproduction tool that leverages app\nreviews from Google Play to acquire pertinent information. RevPerf employs\nrelevant reviews and prompt engineering to enrich the original review with\nperformance issue details. An execution agent is then employed to generate and\nexecute commands to reproduce the issue. After executing all necessary steps,\nthe system incorporates multifaceted detection methods to identify performance\nissues by monitoring Android logs, GUI changes, and system resource utilization\nduring the reproduction process. Experimental results demonstrate that our\nproposed framework achieves a 70\\% success rate in reproducing performance\nissues on the dataset we constructed and manually validated.", "AI": {"tldr": "RevPerf\u662f\u4e00\u4e2a\u901a\u8fc7Google Play\u8bc4\u8bba\u68c0\u6d4b\u79fb\u52a8\u5e94\u7528\u6027\u80fd\u95ee\u9898\u7684\u5de5\u5177\uff0c\u7ed3\u5408\u63d0\u793a\u5de5\u7a0b\u548c\u591a\u65b9\u9762\u68c0\u6d4b\u65b9\u6cd5\uff0c\u6210\u529f\u7387\u8fbe\u523070%\u3002", "motivation": "\u79fb\u52a8\u5e94\u7528\u6027\u80fd\u95ee\u9898\u5728\u5f00\u53d1\u73af\u5883\u4e2d\u96be\u4ee5\u68c0\u6d4b\uff0c\u5f71\u54cd\u7528\u6237\u4f53\u9a8c\u3002", "method": "\u5229\u7528Google Play\u8bc4\u8bba\u83b7\u53d6\u4fe1\u606f\uff0c\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u4e30\u5bcc\u8bc4\u8bba\u7ec6\u8282\uff0c\u6267\u884c\u4ee3\u7406\u751f\u6210\u5e76\u6267\u884c\u547d\u4ee4\u590d\u73b0\u95ee\u9898\uff0c\u7ed3\u5408\u65e5\u5fd7\u3001GUI\u53d8\u5316\u548c\u8d44\u6e90\u4f7f\u7528\u68c0\u6d4b\u95ee\u9898\u3002", "result": "\u5728\u6784\u5efa\u7684\u6570\u636e\u96c6\u4e0a\uff0cRevPerf\u6210\u529f\u590d\u73b0\u6027\u80fd\u95ee\u9898\u7684\u6210\u529f\u7387\u4e3a70%\u3002", "conclusion": "RevPerf\u80fd\u6709\u6548\u590d\u73b0\u79fb\u52a8\u5e94\u7528\u6027\u80fd\u95ee\u9898\uff0c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2508.11082", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.11082", "abs": "https://arxiv.org/abs/2508.11082", "authors": ["Sina Bagheri", "Masoud Kaveh", "Francisco Hernando-Gallego", "Diego Mart\u00edn", "Nuria Serrano"], "title": "A Constant-Time Hardware Architecture for the CSIDH Key-Exchange Protocol", "comment": null, "summary": "The commutative supersingular isogeny Diffie-Hellman (CSIDH) algorithm is a\npromising post-quantum key exchange protocol, notable for its exceptionally\nsmall key sizes, but hindered by computationally intensive key generation.\nFurthermore, practical implementations must operate in constant time to\nmitigate side-channel vulnerabilities, which presents an additional performance\nchallenge. This paper presents, to our knowledge, the first comprehensive\nhardware study of CSIDH, establishing a performance baseline with a unified\narchitecture on both field-programmable gate array (FPGA) and\napplication-specific integrated circuit (ASIC) platforms. The architecture\nfeatures a top-level finite state machine (FSM) that orchestrates a deeply\npipelined arithmetic logic unit (ALU) to accelerate the underlying 512-bit\nfinite field operations. The ALU employs a parallelized schoolbook multiplier,\ncompleting a 512$\\times$512-bit multiplication in 22 clock cycles and enabling\na full Montgomery modular multiplication in 87 cycles. The constant-time\nCSIDH-512 design requires $1.03\\times10^{8}$ clock cycles per key generation.\nWhen implemented on a Xilinx Zynq UltraScale+ FPGA, the architecture achieves a\n200 MHz clock frequency, corresponding to a 515 ms latency. For ASIC\nimplementation in a 180nm process, the design requires $1.065\\times10^{8}$\nclock cycles and achieves a \\textasciitilde 180 MHz frequency, resulting in a\nkey generation latency of 591 ms. By providing the first public hardware\nperformance metrics for CSIDH on both FPGA and ASIC platforms, this work\ndelivers a crucial benchmark for future isogeny-based post-quantum cryptography\n(PQC) accelerators.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5168\u9762\u7814\u7a76\u4e86CSIDH\u7b97\u6cd5\u7684\u786c\u4ef6\u5b9e\u73b0\uff0c\u63d0\u4f9b\u4e86FPGA\u548cASIC\u5e73\u53f0\u7684\u6027\u80fd\u57fa\u51c6\uff0c\u5c55\u793a\u4e86\u5176\u4f5c\u4e3a\u540e\u91cf\u5b50\u5bc6\u94a5\u4ea4\u6362\u534f\u8bae\u7684\u6f5c\u529b\u3002", "motivation": "CSIDH\u7b97\u6cd5\u56e0\u5176\u6781\u5c0f\u7684\u5bc6\u94a5\u5c3a\u5bf8\u800c\u5907\u53d7\u5173\u6ce8\uff0c\u4f46\u8ba1\u7b97\u5bc6\u96c6\u7684\u5bc6\u94a5\u751f\u6210\u548c\u6052\u5b9a\u65f6\u95f4\u5b9e\u73b0\u7684\u9700\u6c42\u5e26\u6765\u4e86\u6027\u80fd\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u786c\u4ef6\u67b6\u6784\uff0c\u91c7\u7528\u9876\u5c42\u6709\u9650\u72b6\u6001\u673a\uff08FSM\uff09\u548c\u6df1\u5ea6\u6d41\u6c34\u7ebf\u7b97\u672f\u903b\u8f91\u5355\u5143\uff08ALU\uff09\uff0c\u52a0\u901f512\u4f4d\u6709\u9650\u57df\u8fd0\u7b97\u3002", "result": "\u5728FPGA\u4e0a\u5b9e\u73b0200 MHz\u65f6\u949f\u9891\u7387\uff0c\u5bc6\u94a5\u751f\u6210\u5ef6\u8fdf515 ms\uff1bASIC\u4e0a\u5b9e\u73b0180 MHz\u9891\u7387\uff0c\u5ef6\u8fdf591 ms\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u672a\u6765\u57fa\u4e8e\u540c\u6e90\u7684\u540e\u91cf\u5b50\u5bc6\u7801\u52a0\u901f\u5668\u63d0\u4f9b\u4e86\u5173\u952e\u7684\u6027\u80fd\u57fa\u51c6\u3002"}}
{"id": "2508.11252", "categories": ["cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2508.11252", "abs": "https://arxiv.org/abs/2508.11252", "authors": ["Youcheng Huang", "Bowen Qin", "Chen Huang", "Duanyu Feng", "Xi Yang", "Wenqiang Lei"], "title": "Beyond Solving Math Quiz: Evaluating the Ability of Large Reasoning Models to Ask for Information", "comment": null, "summary": "Large Reasoning Models (LRMs) have demonstrated remarkable problem-solving\nabilities in mathematics, as evaluated by existing benchmarks exclusively on\nwell-defined problems. However, such evaluation setup constitutes a critical\ngap, since a genuine intelligent agent should not only solve problems (as a\nmath quiz solver), but also be able~to ask for information when the problems\nlack sufficient information, enabling proactivity in responding users'\nrequests. To bridge such gap, we proposes a new dataset consisting of two types\nof incomplete problems with diverse contexts. Based on the dataset, our\nsystematical evaluation of LRMs reveals their inability in proactively asking\nfor information. In addition, we uncover the behaviors related to overthinking\nand hallucination of LRMs, and highlight the potential and challenges of\nsupervised fine-tuning in learning such ability. We hope to provide new\ninsights in developing LRMs with genuine intelligence, rather than just solving\nproblems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u65b0\u6570\u636e\u96c6\u8bc4\u4f30\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u5728\u4e0d\u5b8c\u6574\u95ee\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u65e0\u6cd5\u4e3b\u52a8\u8bf7\u6c42\u4fe1\u606f\uff0c\u5e76\u63ed\u793a\u5176\u8fc7\u5ea6\u601d\u8003\u548c\u5e7b\u89c9\u884c\u4e3a\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u4ec5\u8bc4\u4f30LRMs\u5728\u660e\u786e\u95ee\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u5ffd\u7565\u4e86\u5176\u4f5c\u4e3a\u667a\u80fd\u4ee3\u7406\u5e94\u5177\u5907\u7684\u4e3b\u52a8\u8bf7\u6c42\u4fe1\u606f\u7684\u80fd\u529b\u3002", "method": "\u6784\u5efa\u5305\u542b\u4e24\u7c7b\u4e0d\u5b8c\u6574\u95ee\u9898\u7684\u6570\u636e\u96c6\uff0c\u7cfb\u7edf\u8bc4\u4f30LRMs\u7684\u8868\u73b0\u3002", "result": "LRMs\u65e0\u6cd5\u4e3b\u52a8\u8bf7\u6c42\u4fe1\u606f\uff0c\u5b58\u5728\u8fc7\u5ea6\u601d\u8003\u548c\u5e7b\u89c9\u884c\u4e3a\u3002\u76d1\u7763\u5fae\u8c03\u5728\u6b64\u80fd\u529b\u5b66\u4e60\u4e0a\u5177\u6709\u6f5c\u529b\u4e0e\u6311\u6218\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5f00\u53d1\u771f\u6b63\u667a\u80fd\u7684LRMs\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u5f3a\u8c03\u5176\u4e0d\u4ec5\u9700\u89e3\u51b3\u95ee\u9898\uff0c\u8fd8\u9700\u5177\u5907\u4e3b\u52a8\u4ea4\u4e92\u80fd\u529b\u3002"}}
{"id": "2508.11179", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.11179", "abs": "https://arxiv.org/abs/2508.11179", "authors": ["Pei Liu", "Terry Zhuo", "Jiawei Deng", "Zhenchang Xing", "Qinghua Lu", "Xiaoning Du", "Hongyu Zhan"], "title": "PTMPicker: Facilitating Efficient Pretrained Model Selection for Application Developers", "comment": null, "summary": "The rapid emergence of pretrained models (PTMs) has attracted significant\nattention from both Deep Learning (DL) researchers and downstream application\ndevelopers. However, selecting appropriate PTMs remains challenging because\nexisting methods typically rely on keyword-based searches in which the keywords\nare often derived directly from function descriptions. This often fails to\nfully capture user intent and makes it difficult to identify suitable models\nwhen developers also consider factors such as bias mitigation, hardware\nrequirements, or license compliance. To address the limitations of\nkeyword-based model search, we propose PTMPicker to accurately identify\nsuitable PTMs. We first define a structured template composed of common and\nessential attributes for PTMs and then PTMPicker represents both candidate\nmodels and user-intended features (i.e., model search requests) in this unified\nformat. To determine whether candidate models satisfy user requirements, it\ncomputes embedding similarities for function-related attributes and uses\nwell-crafted prompts to evaluate special constraints such as license compliance\nand hardware requirements. We scraped a total of 543,949 pretrained models from\nHugging Face to prepare valid candidates for selection. PTMPicker then\nrepresented them in the predefined structured format by extracting their\nassociated descriptions. Guided by the extracted metadata, we synthesized a\ntotal of 15,207 model search requests with carefully designed prompts, as no\nsuch search requests are readily available. Experiments on the curated PTM\ndataset and the synthesized model search requests show that PTMPicker can help\nusers effectively identify models,with 85% of the sampled requests successfully\nlocating appropriate PTMs within the top-10 ranked candidates.", "AI": {"tldr": "PTMPicker\u662f\u4e00\u79cd\u57fa\u4e8e\u7ed3\u6784\u5316\u6a21\u677f\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u9009\u62e9\u5de5\u5177\uff0c\u901a\u8fc7\u7edf\u4e00\u683c\u5f0f\u8868\u793a\u6a21\u578b\u548c\u7528\u6237\u9700\u6c42\uff0c\u7ed3\u5408\u5d4c\u5165\u76f8\u4f3c\u6027\u548c\u63d0\u793a\u8bc4\u4f30\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u9009\u62e9\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5173\u952e\u8bcd\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u641c\u7d22\u65b9\u6cd5\u96be\u4ee5\u5168\u9762\u6355\u6349\u7528\u6237\u610f\u56fe\uff0c\u5c24\u5176\u662f\u5728\u8003\u8651\u504f\u5dee\u7f13\u89e3\u3001\u786c\u4ef6\u9700\u6c42\u6216\u8bb8\u53ef\u8bc1\u5408\u89c4\u6027\u7b49\u56e0\u7d20\u65f6\u3002", "method": "\u5b9a\u4e49\u7ed3\u6784\u5316\u6a21\u677f\u8868\u793a\u6a21\u578b\u548c\u7528\u6237\u9700\u6c42\uff0c\u8ba1\u7b97\u529f\u80fd\u76f8\u5173\u5c5e\u6027\u7684\u5d4c\u5165\u76f8\u4f3c\u6027\uff0c\u5e76\u901a\u8fc7\u63d0\u793a\u8bc4\u4f30\u7279\u6b8a\u7ea6\u675f\uff08\u5982\u8bb8\u53ef\u8bc1\u5408\u89c4\u6027\uff09\u3002", "result": "\u5728Hugging Face\u7684543,949\u4e2a\u9884\u8bad\u7ec3\u6a21\u578b\u4e0a\u6d4b\u8bd5\uff0cPTMPicker\u572885%\u7684\u8bf7\u6c42\u4e2d\u6210\u529f\u5728\u524d10\u540d\u5019\u9009\u6a21\u578b\u4e2d\u5b9a\u4f4d\u5230\u5408\u9002\u6a21\u578b\u3002", "conclusion": "PTMPicker\u901a\u8fc7\u7ed3\u6784\u5316\u8868\u793a\u548c\u7efc\u5408\u8bc4\u4f30\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u8bad\u7ec3\u6a21\u578b\u9009\u62e9\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2508.11095", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.11095", "abs": "https://arxiv.org/abs/2508.11095", "authors": ["Asra Ali", "Jaeho Choi", "Bryant Gipson", "Shruthi Gorantala", "Jeremy Kun", "Wouter Legiest", "Lawrence Lim", "Alexander Viand", "Meron Zerihun Demissie", "Hongren Zheng"], "title": "HEIR: A Universal Compiler for Homomorphic Encryption", "comment": null, "summary": "This work presents Homomorphic Encryption Intermediate Representation (HEIR),\na unified approach to building homomorphic encryption (HE) compilers. HEIR aims\nto support all mainstream techniques in homomorphic encryption, integrate with\nall major software libraries and hardware accelerators, and advance the field\nby providing a platform for research and benchmarking. Built on the MLIR\ncompiler framework, HEIR introduces HE-specific abstraction layers at which\nexisting optimizations and new research ideas may be easily implemented.\nAlthough many HE optimization techniques have been proposed, it remains\ndifficult to combine or compare them effectively. HEIR provides a means to\neffectively explore the space of HE optimizations. HEIR addresses the entire HE\nstack and includes support for various frontends, including Python. The\ncontribution of this work includes: (1) We introduce HEIR as a framework for\nbuilding HE compilers. (2) We validate HEIR's design by porting a large\nfraction of the HE literature to HEIR, and we argue that HEIR can tackle more\ncomplicated and diverse programs than prior literature. (3) We provide evidence\nthat HEIR is emerging as the de facto HE compiler for academic research and\nindustry development.", "AI": {"tldr": "HEIR\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u540c\u6001\u52a0\u5bc6\u7f16\u8bd1\u5668\u6846\u67b6\uff0c\u652f\u6301\u4e3b\u6d41\u6280\u672f\u3001\u8f6f\u4ef6\u5e93\u548c\u786c\u4ef6\u52a0\u901f\u5668\uff0c\u5e76\u63a8\u52a8\u7814\u7a76\u3002", "motivation": "\u89e3\u51b3\u540c\u6001\u52a0\u5bc6\u4f18\u5316\u6280\u672f\u96be\u4ee5\u7ed3\u5408\u548c\u6bd4\u8f83\u7684\u95ee\u9898\uff0c\u63d0\u4f9b\u4e00\u4e2a\u7814\u7a76\u548c\u57fa\u51c6\u6d4b\u8bd5\u5e73\u53f0\u3002", "method": "\u57fa\u4e8eMLIR\u7f16\u8bd1\u5668\u6846\u67b6\uff0c\u5f15\u5165HE\u7279\u5b9a\u62bd\u8c61\u5c42\uff0c\u652f\u6301\u591a\u79cd\u524d\u7aef\uff08\u5982Python\uff09\u3002", "result": "HEIR\u88ab\u9a8c\u8bc1\u80fd\u5904\u7406\u6bd4\u73b0\u6709\u6587\u732e\u66f4\u590d\u6742\u591a\u6837\u7684\u7a0b\u5e8f\uff0c\u5e76\u6210\u4e3a\u5b66\u672f\u548c\u5de5\u4e1a\u754c\u7684\u5b9e\u9645\u6807\u51c6\u3002", "conclusion": "HEIR\u4e3a\u540c\u6001\u52a0\u5bc6\u7f16\u8bd1\u5668\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u5e73\u53f0\uff0c\u63a8\u52a8\u9886\u57df\u53d1\u5c55\u3002"}}
{"id": "2508.11347", "categories": ["cs.AI", "cs.LG", "I.2.4; I.2.6; H.2.8"], "pdf": "https://arxiv.org/pdf/2508.11347", "abs": "https://arxiv.org/abs/2508.11347", "authors": ["Yifei Li", "Lingling Zhang", "Hang Yan", "Tianzhe Zhao", "Zihan Ma", "Muye Huang", "Jun Liu"], "title": "SAGE: Scale-Aware Gradual Evolution for Continual Knowledge Graph Embedding", "comment": "10 pages, 5 figures, Accepted at KDD 2025, code available at\n  https://github.com/lyfxjtu/Dynamic-Embedding", "summary": "Traditional knowledge graph (KG) embedding methods aim to represent entities\nand relations in a low-dimensional space, primarily focusing on static graphs.\nHowever, real-world KGs are dynamically evolving with the constant addition of\nentities, relations and facts. To address such dynamic nature of KGs, several\ncontinual knowledge graph embedding (CKGE) methods have been developed to\nefficiently update KG embeddings to accommodate new facts while maintaining\nlearned knowledge. As KGs grow at different rates and scales in real-world\nscenarios, existing CKGE methods often fail to consider the varying scales of\nupdates and lack systematic evaluation throughout the entire update process. In\nthis paper, we propose SAGE, a scale-aware gradual evolution framework for\nCKGE. Specifically, SAGE firstly determine the embedding dimensions based on\nthe update scales and expand the embedding space accordingly. The Dynamic\nDistillation mechanism is further employed to balance the preservation of\nlearned knowledge and the incorporation of new facts. We conduct extensive\nexperiments on seven benchmarks, and the results show that SAGE consistently\noutperforms existing baselines, with a notable improvement of 1.38% in MRR,\n1.25% in H@1 and 1.6% in H@10. Furthermore, experiments comparing SAGE with\nmethods using fixed embedding dimensions show that SAGE achieves optimal\nperformance on every snapshot, demonstrating the importance of adaptive\nembedding dimensions in CKGE. The codes of SAGE are publicly available at:\nhttps://github.com/lyfxjtu/Dynamic-Embedding.", "AI": {"tldr": "SAGE\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u7ef4\u5ea6\u6269\u5c55\u548c\u52a8\u6001\u84b8\u998f\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u52a8\u6001\u77e5\u8bc6\u56fe\u8c31\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u9759\u6001\u56fe\u8c31\uff0c\u800c\u73b0\u5b9e\u4e2d\u7684\u77e5\u8bc6\u56fe\u8c31\u662f\u52a8\u6001\u53d8\u5316\u7684\uff0c\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u8003\u8651\u66f4\u65b0\u7684\u4e0d\u540c\u89c4\u6a21\u548c\u7cfb\u7edf\u8bc4\u4f30\u3002", "method": "SAGE\u6846\u67b6\u6839\u636e\u66f4\u65b0\u89c4\u6a21\u786e\u5b9a\u5d4c\u5165\u7ef4\u5ea6\u5e76\u6269\u5c55\u5d4c\u5165\u7a7a\u95f4\uff0c\u91c7\u7528\u52a8\u6001\u84b8\u998f\u673a\u5236\u5e73\u8861\u65b0\u65e7\u77e5\u8bc6\u7684\u4fdd\u7559\u4e0e\u6574\u5408\u3002", "result": "\u5728\u4e03\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSAGE\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0cMRR\u3001H@1\u548cH@10\u5206\u522b\u63d0\u53471.38%\u30011.25%\u548c1.6%\u3002", "conclusion": "SAGE\u8bc1\u660e\u4e86\u81ea\u9002\u5e94\u5d4c\u5165\u7ef4\u5ea6\u5728\u52a8\u6001\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5e76\u5728\u6bcf\u4e2a\u5feb\u7167\u4e0a\u5b9e\u73b0\u4e86\u6700\u4f18\u6027\u80fd\u3002"}}
{"id": "2508.11222", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2508.11222", "abs": "https://arxiv.org/abs/2508.11222", "authors": ["Haonan Zhang", "Dongxia Wang", "Yi Liu", "Kexin Chen", "Jiashui Wang", "Xinlei Ying", "Long Liu", "Wenhai Wang"], "title": "ORFuzz: Fuzzing the \"Other Side\" of LLM Safety -- Testing Over-Refusal", "comment": null, "summary": "Large Language Models (LLMs) increasingly exhibit over-refusal - erroneously\nrejecting benign queries due to overly conservative safety measures - a\ncritical functional flaw that undermines their reliability and usability.\nCurrent methods for testing this behavior are demonstrably inadequate,\nsuffering from flawed benchmarks and limited test generation capabilities, as\nhighlighted by our empirical user study. To the best of our knowledge, this\npaper introduces the first evolutionary testing framework, ORFuzz, for the\nsystematic detection and analysis of LLM over-refusals. ORFuzz uniquely\nintegrates three core components: (1) safety category-aware seed selection for\ncomprehensive test coverage, (2) adaptive mutator optimization using reasoning\nLLMs to generate effective test cases, and (3) OR-Judge, a human-aligned judge\nmodel validated to accurately reflect user perception of toxicity and refusal.\nOur extensive evaluations demonstrate that ORFuzz generates diverse, validated\nover-refusal instances at a rate (6.98% average) more than double that of\nleading baselines, effectively uncovering vulnerabilities. Furthermore,\nORFuzz's outputs form the basis of ORFuzzSet, a new benchmark of 1,855 highly\ntransferable test cases that achieves a superior 63.56% average over-refusal\nrate across 10 diverse LLMs, significantly outperforming existing datasets.\nORFuzz and ORFuzzSet provide a robust automated testing framework and a\nvaluable community resource, paving the way for developing more reliable and\ntrustworthy LLM-based software systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faORFuzz\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4b\u548c\u5206\u6790\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u8fc7\u5ea6\u62d2\u7edd\u884c\u4e3a\uff0c\u901a\u8fc7\u8fdb\u5316\u6d4b\u8bd5\u751f\u6210\u591a\u6837\u5316\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5e76\u521b\u5efaORFuzzSet\u57fa\u51c6\u6570\u636e\u96c6\u3002", "motivation": "LLMs\u7684\u8fc7\u5ea6\u62d2\u7edd\u884c\u4e3a\uff08\u9519\u8bef\u62d2\u7edd\u826f\u6027\u67e5\u8be2\uff09\u5f71\u54cd\u5176\u53ef\u9760\u6027\u548c\u53ef\u7528\u6027\uff0c\u73b0\u6709\u6d4b\u8bd5\u65b9\u6cd5\u5b58\u5728\u4e0d\u8db3\u3002", "method": "ORFuzz\u6846\u67b6\u7ed3\u5408\u5b89\u5168\u7c7b\u522b\u611f\u77e5\u79cd\u5b50\u9009\u62e9\u3001\u81ea\u9002\u5e94\u7a81\u53d8\u4f18\u5316\u548cOR-Judge\u8bc4\u4f30\u6a21\u578b\uff0c\u751f\u6210\u591a\u6837\u5316\u6d4b\u8bd5\u7528\u4f8b\u3002", "result": "ORFuzz\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u7684\u6210\u529f\u7387\uff086.98%\uff09\u662f\u73b0\u6709\u65b9\u6cd5\u7684\u4e24\u500d\uff0cORFuzzSet\u57fa\u51c6\u6570\u636e\u96c6\u572810\u79cdLLMs\u4e2d\u5e73\u5747\u8fc7\u5ea6\u62d2\u7edd\u7387\u8fbe63.56%\u3002", "conclusion": "ORFuzz\u548cORFuzzSet\u4e3a\u5f00\u53d1\u66f4\u53ef\u9760\u7684LLM\u7cfb\u7edf\u63d0\u4f9b\u4e86\u81ea\u52a8\u5316\u6d4b\u8bd5\u6846\u67b6\u548c\u793e\u533a\u8d44\u6e90\u3002"}}
{"id": "2508.11325", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.11325", "abs": "https://arxiv.org/abs/2508.11325", "authors": ["Georgios Michail Makrakis", "Jeroen Pijpker", "Remco Hassing", "Rob Loves", "Stephen McCombie"], "title": "Salty Seagull: A VSAT Honeynet to Follow the Bread Crumb of Attacks in Ship Networks", "comment": null, "summary": "Cyber threats against the maritime industry have increased notably in recent\nyears, highlighting the need for innovative cybersecurity approaches. Ships, as\ncritical assets, possess highly specialized and interconnected network\ninfrastructures, where their legacy systems and operational constraints further\nexacerbate their vulnerability to cyberattacks. To better understand this\nevolving threat landscape, we propose the use of cyber-deception techniques and\nin particular honeynets, as a means to gather valuable insights into ongoing\nattack campaigns targeting the maritime sector.\n  In this paper we present Salty Seagull, a honeynet conceived to simulate a\nVSAT system for ships. This environment mimics the operations of a functional\nVSAT system onboard and, at the same time, enables a user to interact with it\nthrough a Web dashboard and a CLI environment. Furthermore, based on existing\nvulnerabilities, we purposefully integrate them into our system to increase\nattacker engagement. We exposed our honeynet for 30 days to the Internet to\nassess its capability and measured the received interaction. Results show that\nwhile numerous generic attacks have been attempted, only one curious attacker\nwith knowledge of the nature of the system and its vulnerabilities managed to\naccess it, without however exploring its full potential.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSalty Seagull\u7684\u871c\u7f51\u7cfb\u7edf\uff0c\u6a21\u62df\u8239\u8236VSAT\u7cfb\u7edf\uff0c\u7528\u4e8e\u6536\u96c6\u9488\u5bf9\u6d77\u4e8b\u884c\u4e1a\u7684\u7f51\u7edc\u653b\u51fb\u6570\u636e\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u7cfb\u7edf\u6210\u529f\u5438\u5f15\u4e86\u653b\u51fb\u8005\uff0c\u4f46\u4ec5\u6709\u4e00\u540d\u5177\u5907\u76f8\u5173\u77e5\u8bc6\u7684\u653b\u51fb\u8005\u6df1\u5165\u8bbf\u95ee\u3002", "motivation": "\u8fd1\u5e74\u6765\u6d77\u4e8b\u884c\u4e1a\u9762\u4e34\u7684\u7f51\u7edc\u5a01\u80c1\u663e\u8457\u589e\u52a0\uff0c\u4f20\u7edf\u7cfb\u7edf\u548c\u64cd\u4f5c\u9650\u5236\u52a0\u5267\u4e86\u5176\u8106\u5f31\u6027\u3002\u9700\u8981\u521b\u65b0\u65b9\u6cd5\u6765\u7406\u89e3\u548c\u5e94\u5bf9\u8fd9\u4e9b\u5a01\u80c1\u3002", "method": "\u8bbe\u8ba1\u4e86Salty Seagull\u871c\u7f51\uff0c\u6a21\u62df\u8239\u8236VSAT\u7cfb\u7edf\uff0c\u5e76\u6545\u610f\u96c6\u6210\u5df2\u77e5\u6f0f\u6d1e\u4ee5\u5438\u5f15\u653b\u51fb\u8005\u3002\u7cfb\u7edf\u901a\u8fc7Web\u4eea\u8868\u677f\u548cCLI\u73af\u5883\u63d0\u4f9b\u4ea4\u4e92\uff0c\u5e76\u66b4\u9732\u4e8e\u4e92\u8054\u7f5130\u5929\u4ee5\u6d4b\u8bd5\u5176\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u671f\u95f4\uff0c\u7cfb\u7edf\u5438\u5f15\u4e86\u5927\u91cf\u901a\u7528\u653b\u51fb\u5c1d\u8bd5\uff0c\u4f46\u4ec5\u6709\u4e00\u540d\u5177\u5907\u7cfb\u7edf\u77e5\u8bc6\u7684\u653b\u51fb\u8005\u6df1\u5165\u8bbf\u95ee\uff0c\u672a\u5b8c\u5168\u63a2\u7d22\u7cfb\u7edf\u6f5c\u529b\u3002", "conclusion": "\u871c\u7f51\u6280\u672f\u53ef\u7528\u4e8e\u6536\u96c6\u6d77\u4e8b\u884c\u4e1a\u7f51\u7edc\u653b\u51fb\u6570\u636e\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u4ee5\u63d0\u9ad8\u653b\u51fb\u8005\u53c2\u4e0e\u5ea6\u548c\u6570\u636e\u6536\u96c6\u6548\u679c\u3002"}}
{"id": "2508.11360", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2508.11360", "abs": "https://arxiv.org/abs/2508.11360", "authors": ["Songqin Nong", "Jingxuan Xu", "Sheng Zhou", "Jianfeng Chen", "Xiaoxuan Tang", "Tao Jiang", "Wenhao Xu"], "title": "CRAFT-GUI: Curriculum-Reinforced Agent For GUI Tasks", "comment": null, "summary": "As autonomous agents become adept at understanding and interacting with\ngraphical user interface (GUI) environments, a new era of automated task\nexecution is emerging. Recent studies have demonstrated that Reinforcement\nLearning (RL) can effectively enhance agents' performance in dynamic\ninteractive GUI environments. However, these methods face two key limitations:\n(1) they overlook the significant variation in difficulty across different GUI\ntasks by treating the entire training data as a uniform set, which hampers the\nagent's ability to adapt its learning process; and (2) most approaches collapse\ntask-specific nuances into a single, coarse reward, leaving the agent with a\nuniform signal that yields inefficient policy updates. To address these\nlimitations, we propose CRAFT-GUI, a curriculum learning framework based on\nGroup Relative Policy Optimization (GRPO) that explicitly accounts for the\nvarying difficulty across trajectories. To enable more fine-grained policy\noptimization, we design a reward function that combines simple rule-based\nsignals with model-judged evaluation, providing richer and more nuanced\nfeedback during training. Experimental results demonstrate that our method\nachieves significant improvements over previous state-of-the-art approaches,\noutperforming them by 5.6% on public benchmarks Android Control and 10.3% on\nour internal online benchmarks, respectively. These findings empirically\nvalidate the effectiveness of integrating reinforcement learning with\ncurriculum learning in GUI interaction tasks.", "AI": {"tldr": "\u63d0\u51faCRAFT-GUI\u6846\u67b6\uff0c\u901a\u8fc7\u8bfe\u7a0b\u5b66\u4e60\u548c\u7ec6\u7c92\u5ea6\u5956\u52b1\u4f18\u5316\uff0c\u63d0\u5347GUI\u4ea4\u4e92\u4efb\u52a1\u4e2d\u5f3a\u5316\u5b66\u4e60\u7684\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5ffd\u89c6GUI\u4efb\u52a1\u96be\u5ea6\u7684\u5dee\u5f02\uff0c\u4e14\u5956\u52b1\u4fe1\u53f7\u8fc7\u4e8e\u7c97\u7cd9\uff0c\u5bfc\u81f4\u5b66\u4e60\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u57fa\u4e8eGRPO\u7684\u8bfe\u7a0b\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u89c4\u5219\u548c\u6a21\u578b\u8bc4\u4f30\u8bbe\u8ba1\u7ec6\u7c92\u5ea6\u5956\u52b1\u51fd\u6570\u3002", "result": "\u5728\u516c\u5f00\u548c\u5185\u90e8\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5206\u522b\u63d0\u53475.6%\u548c10.3%\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u8bfe\u7a0b\u5b66\u4e60\u80fd\u663e\u8457\u63d0\u5347GUI\u4ea4\u4e92\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2508.11257", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.11257", "abs": "https://arxiv.org/abs/2508.11257", "authors": ["Marc Pavel", "Nenad Petrovic", "Lukasz Mazur", "Vahid Zolfaghari", "Fengjunjie Pan", "Alois Knoll"], "title": "Hallucination in LLM-Based Code Generation: An Automotive Case Study", "comment": null, "summary": "Large Language Models (LLMs) have shown significant potential in automating\ncode generation tasks offering new opportunities across software engineering\ndomains. However, their practical application remains limited due to\nhallucinations - outputs that appear plausible but are factually incorrect,\nunverifiable or nonsensical. This paper investigates hallucination phenomena in\nthe context of code generation with a specific focus on the automotive domain.\nA case study is presented that evaluates multiple code LLMs for three different\nprompting complexities ranging from a minimal one-liner prompt to a prompt with\nCovesa Vehicle Signal Specifications (VSS) as additional context and finally to\na prompt with an additional code skeleton. The evaluation reveals a high\nfrequency of syntax violations, invalid reference errors and API knowledge\nconflicts in state-of-the-art models GPT-4.1, Codex and GPT-4o. Among the\nevaluated models, only GPT-4.1 and GPT-4o were able to produce a correct\nsolution when given the most context-rich prompt. Simpler prompting strategies\nfailed to yield a working result, even after multiple refinement iterations.\nThese findings highlight the need for effective mitigation techniques to ensure\nthe safe and reliable use of LLM generated code, especially in safety-critical\ndomains such as automotive software systems.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u5e7b\u89c9\u73b0\u8c61\uff0c\u7279\u522b\u662f\u5728\u6c7d\u8f66\u9886\u57df\u3002\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u8bc4\u4f30\u4e86\u4e0d\u540c\u63d0\u793a\u590d\u6742\u5ea6\u4e0b\u591a\u4e2a\u4ee3\u7801LLM\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5373\u4f7f\u5148\u8fdb\u6a21\u578b\u5982GPT-4.1\u548cGPT-4o\u4e5f\u5b58\u5728\u9ad8\u9891\u7387\u9519\u8bef\u3002", "motivation": "LLM\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5e7b\u89c9\u95ee\u9898\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\uff0c\u5c24\u5176\u662f\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\u5982\u6c7d\u8f66\u8f6f\u4ef6\u7cfb\u7edf\u3002", "method": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\uff0c\u8bc4\u4f30\u4e86\u591a\u4e2a\u4ee3\u7801LLM\uff08\u5982GPT-4.1\u3001Codex\u548cGPT-4o\uff09\u5728\u4e0d\u540c\u63d0\u793a\u590d\u6742\u5ea6\u4e0b\u7684\u8868\u73b0\uff0c\u4ece\u7b80\u5355\u63d0\u793a\u5230\u5305\u542b\u989d\u5916\u4e0a\u4e0b\u6587\u7684\u590d\u6742\u63d0\u793a\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5373\u4f7f\u662f\u5148\u8fdb\u6a21\u578b\u4e5f\u5b58\u5728\u8bed\u6cd5\u9519\u8bef\u3001\u65e0\u6548\u5f15\u7528\u548cAPI\u77e5\u8bc6\u51b2\u7a81\u7b49\u95ee\u9898\u3002\u4ec5GPT-4.1\u548cGPT-4o\u5728\u6700\u590d\u6742\u7684\u63d0\u793a\u4e0b\u80fd\u751f\u6210\u6b63\u786e\u4ee3\u7801\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u9700\u8981\u6709\u6548\u7684\u7f13\u89e3\u6280\u672f\uff0c\u4ee5\u786e\u4fddLLM\u751f\u6210\u7684\u4ee3\u7801\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\u4e2d\u7684\u53ef\u9760\u4f7f\u7528\u3002"}}
{"id": "2508.11472", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.11472", "abs": "https://arxiv.org/abs/2508.11472", "authors": ["Yang Wang", "Yaxin Zhao", "Xinyu Jiao", "Sihan Xu", "Xiangrui Cai", "Ying Zhang", "Xiaojie Yuan"], "title": "RMSL: Weakly-Supervised Insider Threat Detection with Robust Multi-sphere Learning", "comment": "15 pages", "summary": "Insider threat detection aims to identify malicious user behavior by\nanalyzing logs that record user interactions. Due to the lack of fine-grained\nbehavior-level annotations, detecting specific behavior-level anomalies within\nuser behavior sequences is challenging. Unsupervised methods face high false\npositive rates and miss rates due to the inherent ambiguity between normal and\nanomalous behaviors. In this work, we instead introduce weak labels of behavior\nsequences, which have lower annotation costs, i.e., the training labels\n(anomalous or normal) are at sequence-level instead of behavior-level, to\nenhance the detection capability for behavior-level anomalies by learning\ndiscriminative features. To achieve this, we propose a novel framework called\nRobust Multi-sphere Learning (RMSL). RMSL uses multiple hyper-spheres to\nrepresent the normal patterns of behaviors. Initially, a one-class classifier\nis constructed as a good anomaly-supervision-free starting point. Building on\nthis, using multiple instance learning and adaptive behavior-level\nself-training debiasing based on model prediction confidence, the framework\nfurther refines hyper-spheres and feature representations using weak\nsequence-level labels. This approach enhances the model's ability to\ndistinguish between normal and anomalous behaviors. Extensive experiments\ndemonstrate that RMSL significantly improves the performance of behavior-level\ninsider threat detection.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f31\u6807\u7b7e\u5e8f\u5217\u7684\u884c\u4e3a\u7ea7\u5185\u90e8\u5a01\u80c1\u68c0\u6d4b\u6846\u67b6RMSL\uff0c\u901a\u8fc7\u591a\u8d85\u7403\u4f53\u5b66\u4e60\u548c\u81ea\u9002\u5e94\u8bad\u7ec3\u4f18\u5316\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u7531\u4e8e\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u7684\u884c\u4e3a\u7ea7\u6807\u6ce8\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u68c0\u6d4b\u7528\u6237\u884c\u4e3a\u5e8f\u5217\u4e2d\u7684\u5f02\u5e38\u65f6\u9762\u4e34\u9ad8\u8bef\u62a5\u7387\u548c\u6f0f\u62a5\u7387\u3002", "method": "\u63d0\u51faRMSL\u6846\u67b6\uff0c\u5229\u7528\u591a\u8d85\u7403\u4f53\u8868\u793a\u6b63\u5e38\u884c\u4e3a\u6a21\u5f0f\uff0c\u7ed3\u5408\u591a\u5b9e\u4f8b\u5b66\u4e60\u548c\u81ea\u9002\u5e94\u884c\u4e3a\u7ea7\u81ea\u8bad\u7ec3\u53bb\u504f\uff0c\u4f18\u5316\u7279\u5f81\u8868\u793a\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cRMSL\u663e\u8457\u63d0\u5347\u4e86\u884c\u4e3a\u7ea7\u5185\u90e8\u5a01\u80c1\u68c0\u6d4b\u7684\u6027\u80fd\u3002", "conclusion": "RMSL\u901a\u8fc7\u5f31\u5e8f\u5217\u6807\u7b7e\u548c\u81ea\u9002\u5e94\u8bad\u7ec3\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u884c\u4e3a\u7ea7\u5f02\u5e38\u68c0\u6d4b\u7684\u6311\u6218\u3002"}}
{"id": "2508.11416", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.11416", "abs": "https://arxiv.org/abs/2508.11416", "authors": ["Xuhua Zhao", "Yuxuan Xie", "Caihua Chen", "Yuxiang Sun"], "title": "AIM-Bench: Evaluating Decision-making Biases of Agentic LLM as Inventory Manager", "comment": null, "summary": "Recent advances in mathematical reasoning and the long-term planning\ncapabilities of large language models (LLMs) have precipitated the development\nof agents, which are being increasingly leveraged in business operations\nprocesses. Decision models to optimize inventory levels are one of the core\nelements of operations management. However, the capabilities of the LLM agent\nin making inventory decisions in uncertain contexts, as well as the\ndecision-making biases (e.g. framing effect, etc.) of the agent, remain largely\nunexplored. This prompts concerns regarding the capacity of LLM agents to\neffectively address real-world problems, as well as the potential implications\nof biases that may be present. To address this gap, we introduce AIM-Bench, a\nnovel benchmark designed to assess the decision-making behaviour of LLM agents\nin uncertain supply chain management scenarios through a diverse series of\ninventory replenishment experiments. Our results reveal that different LLMs\ntypically exhibit varying degrees of decision bias that are similar to those\nobserved in human beings. In addition, we explored strategies to mitigate the\npull-to-centre effect and the bullwhip effect, namely cognitive reflection and\nimplementation of information sharing. These findings underscore the need for\ncareful consideration of the potential biases in deploying LLMs in Inventory\ndecision-making scenarios. We hope that these insights will pave the way for\nmitigating human decision bias and developing human-centred decision support\nsystems for supply chains.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faAIM-Bench\u57fa\u51c6\uff0c\u8bc4\u4f30LLM\u4ee3\u7406\u5728\u4e0d\u786e\u5b9a\u4f9b\u5e94\u94fe\u7ba1\u7406\u4e2d\u7684\u51b3\u7b56\u884c\u4e3a\uff0c\u53d1\u73b0\u5176\u5b58\u5728\u7c7b\u4f3c\u4eba\u7c7b\u7684\u51b3\u7b56\u504f\u5dee\uff0c\u5e76\u63a2\u8ba8\u4e86\u7f13\u89e3\u65b9\u6cd5\u3002", "motivation": "\u7814\u7a76LLM\u4ee3\u7406\u5728\u5e93\u5b58\u51b3\u7b56\u4e2d\u7684\u80fd\u529b\u548c\u6f5c\u5728\u504f\u5dee\uff0c\u586b\u8865\u5176\u5728\u4e0d\u786e\u5b9a\u73af\u5883\u4e0b\u51b3\u7b56\u884c\u4e3a\u7684\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u901a\u8fc7AIM-Bench\u57fa\u51c6\uff0c\u8bbe\u8ba1\u591a\u6837\u5316\u7684\u5e93\u5b58\u8865\u5145\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u4e0d\u540cLLM\u7684\u51b3\u7b56\u884c\u4e3a\u3002", "result": "\u4e0d\u540cLLM\u8868\u73b0\u51fa\u7c7b\u4f3c\u4eba\u7c7b\u7684\u51b3\u7b56\u504f\u5dee\uff0c\u5e76\u63a2\u7d22\u4e86\u7f13\u89e3\u7b56\u7565\uff08\u8ba4\u77e5\u53cd\u601d\u548c\u4fe1\u606f\u5171\u4eab\uff09\u3002", "conclusion": "\u9700\u8c28\u614e\u8003\u8651LLM\u5728\u5e93\u5b58\u51b3\u7b56\u4e2d\u7684\u6f5c\u5728\u504f\u5dee\uff0c\u4e3a\u5f00\u53d1\u4eba\u672c\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u63d0\u4f9b\u542f\u793a\u3002"}}
{"id": "2508.11305", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.11305", "abs": "https://arxiv.org/abs/2508.11305", "authors": ["Xin Wang", "Zhenhao Li", "Zishuo Ding"], "title": "Defects4Log: Benchmarking LLMs for Logging Code Defect Detection and Reasoning", "comment": null, "summary": "Logging code is written by developers to capture system runtime behavior and\nplays a vital role in debugging, performance analysis, and system monitoring.\nHowever, defects in logging code can undermine the usefulness of logs and lead\nto misinterpretations. Although prior work has identified several logging\ndefect patterns and provided valuable insights into logging practices, these\nstudies often focus on a narrow range of defect patterns derived from limited\nsources (e.g., commit histories) and lack a systematic and comprehensive\nanalysis. Moreover, large language models (LLMs) have demonstrated promising\ngeneralization and reasoning capabilities across a variety of code-related\ntasks, yet their potential for detecting logging code defects remains largely\nunexplored.\n  In this paper, we derive a comprehensive taxonomy of logging code defects,\nwhich encompasses seven logging code defect patterns with 14 detailed\nscenarios. We further construct a benchmark dataset, \\dataset, consisting of\n164 developer-verified real-world logging defects. Then we propose an automated\nframework that leverages various prompting strategies and contextual\ninformation to evaluate LLMs' capability in detecting and reasoning logging\ncode defects. Experimental results reveal that LLMs generally struggle to\naccurately detect and reason logging code defects based on the source code\nonly. However, incorporating proper knowledge (e.g., detailed scenarios of\ndefect patterns) can lead to 10.9\\% improvement in detection accuracy. Overall,\nour findings provide actionable guidance for practitioners to avoid common\ndefect patterns and establish a foundation for improving LLM-based reasoning in\nlogging code defect detection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5168\u9762\u7684\u65e5\u5fd7\u4ee3\u7801\u7f3a\u9677\u5206\u7c7b\u6cd5\uff0c\u6784\u5efa\u4e86\u771f\u5b9e\u4e16\u754c\u7684\u7f3a\u9677\u6570\u636e\u96c6\uff0c\u5e76\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u68c0\u6d4b\u65e5\u5fd7\u4ee3\u7801\u7f3a\u9677\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u65e5\u5fd7\u4ee3\u7801\u7f3a\u9677\u53ef\u80fd\u5bfc\u81f4\u65e5\u5fd7\u4fe1\u606f\u8bef\u89e3\uff0c\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u7cfb\u7edf\u6027\u5206\u6790\uff0c\u4e14LLMs\u5728\u6b64\u9886\u57df\u7684\u6f5c\u529b\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u7c7b\u6cd5\uff087\u79cd\u7f3a\u9677\u6a21\u5f0f\uff0c14\u79cd\u573a\u666f\uff09\uff0c\u6784\u5efa\u4e86\u5305\u542b164\u4e2a\u771f\u5b9e\u7f3a\u9677\u7684\u6570\u636e\u96c6\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u81ea\u52a8\u5316\u6846\u67b6\u8bc4\u4f30LLMs\u7684\u68c0\u6d4b\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cLLMs\u4ec5\u57fa\u4e8e\u6e90\u4ee3\u7801\u68c0\u6d4b\u7f3a\u9677\u8868\u73b0\u4e0d\u4f73\uff0c\u4f46\u5f15\u5165\u76f8\u5173\u77e5\u8bc6\u540e\u68c0\u6d4b\u51c6\u786e\u7387\u63d0\u534710.9%\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u907f\u514d\u5e38\u89c1\u7f3a\u9677\u7684\u6307\u5bfc\uff0c\u5e76\u4e3a\u6539\u8fdb\u57fa\u4e8eLLM\u7684\u65e5\u5fd7\u7f3a\u9677\u68c0\u6d4b\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.11495", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.11495", "abs": "https://arxiv.org/abs/2508.11495", "authors": ["Jingnan Xu", "Leixia Wang", "Xiaofeng Meng"], "title": "KV-Auditor: Auditing Local Differential Privacy for Correlated Key-Value Estimation", "comment": null, "summary": "To protect privacy for data-collection-based services, local differential\nprivacy (LDP) is widely adopted due to its rigorous theoretical bound on\nprivacy loss. However, mistakes in complex theoretical analysis or subtle\nimplementation errors may undermine its practical guarantee. To address this,\nauditing is crucial to confirm that LDP protocols truly protect user data.\nHowever, existing auditing methods, though, mainly target machine learning and\nfederated learning tasks based on centralized differentially privacy (DP), with\nlimited attention to LDP. Moreover, the few studies on LDP auditing focus\nsolely on simple frequency estimation task for discrete data, leaving\ncorrelated key-value data - which requires both discrete frequency estimation\nfor keys and continuous mean estimation for values - unexplored.\n  To bridge this gap, we propose KV-Auditor, a framework for auditing LDP-based\nkey-value estimation mechanisms by estimating their empirical privacy lower\nbounds. Rather than traditional LDP auditing methods that relies on binary\noutput predictions, KV-Auditor estimates this lower bound by analyzing\nunbounded output distributions, supporting continuous data. Specifically, we\nclassify state-of-the-art LDP key-value mechanisms into interactive and\nnon-interactive types. For non-interactive mechanisms, we propose horizontal\nKV-Auditor for small domains with sufficient samples and vertical KV-Auditor\nfor large domains with limited samples. For interactive mechanisms, we design a\nsegmentation strategy to capture incremental privacy leakage across iterations.\nFinally, we perform extensive experiments to validate the effectiveness of our\napproach, offering insights for optimizing LDP-based key-value estimators.", "AI": {"tldr": "KV-Auditor\u662f\u4e00\u4e2a\u7528\u4e8e\u5ba1\u8ba1\u57fa\u4e8e\u672c\u5730\u5dee\u5206\u9690\u79c1\uff08LDP\uff09\u7684\u952e\u503c\u4f30\u8ba1\u673a\u5236\u7684\u6846\u67b6\uff0c\u586b\u8865\u4e86\u73b0\u6709\u5ba1\u8ba1\u65b9\u6cd5\u5728\u8fde\u7eed\u6570\u636e\u548c\u952e\u503c\u6570\u636e\u4e0a\u7684\u7a7a\u767d\u3002", "motivation": "\u73b0\u6709LDP\u5ba1\u8ba1\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u79bb\u6563\u6570\u636e\u7684\u9891\u7387\u4f30\u8ba1\u4efb\u52a1\uff0c\u7f3a\u4e4f\u5bf9\u952e\u503c\u6570\u636e\u7684\u652f\u6301\uff0cKV-Auditor\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "KV-Auditor\u901a\u8fc7\u5206\u6790\u65e0\u754c\u8f93\u51fa\u5206\u5e03\u4f30\u8ba1\u9690\u79c1\u4e0b\u754c\uff0c\u652f\u6301\u8fde\u7eed\u6570\u636e\uff0c\u5e76\u9488\u5bf9\u4ea4\u4e92\u5f0f\u548c\u975e\u4ea4\u4e92\u5f0f\u673a\u5236\u8bbe\u8ba1\u4e86\u4e0d\u540c\u5ba1\u8ba1\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86KV-Auditor\u7684\u6709\u6548\u6027\uff0c\u5e76\u4e3a\u4f18\u5316LDP\u952e\u503c\u4f30\u8ba1\u5668\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002", "conclusion": "KV-Auditor\u586b\u8865\u4e86LDP\u5ba1\u8ba1\u5728\u952e\u503c\u6570\u636e\u4e0a\u7684\u7a7a\u767d\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u9690\u79c1\u4fdd\u969c\u3002"}}
{"id": "2508.11452", "categories": ["cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2508.11452", "abs": "https://arxiv.org/abs/2508.11452", "authors": ["Kangyu Wang", "Hongliang He", "Lin Liu", "Ruiqi Liang", "Zhenzhong Lan", "Jianguo Li"], "title": "Inclusion Arena: An Open Platform for Evaluating Large Foundation Models with Real-World Apps", "comment": "Our platform is publicly accessible at\n  https://doraemon.alipay.com/model-ranking", "summary": "Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs)\nhave ushered in a new era of AI capabilities, demonstrating near-human-level\nperformance across diverse scenarios. While numerous benchmarks (e.g., MMLU)\nand leaderboards (e.g., Chatbot Arena) have been proposed to help evolve the\ndevelopment of LLMs and MLLMs, most rely on static datasets or crowdsourced\ngeneral-domain prompts, often falling short of reflecting performance in\nreal-world applications. To bridge this critical gap, we present Inclusion\nArena, a live leaderboard that ranks models based on human feedback collected\ndirectly from AI-powered applications. Our platform integrates pairwise model\ncomparisons into natural user interactions, ensuring evaluations reflect\npractical usage scenarios. For robust model ranking, we employ the\nBradley-Terry model augmented with two key innovations: (1) Placement Matches,\na cold-start mechanism to quickly estimate initial ratings for newly integrated\nmodels, and (2) Proximity Sampling, an intelligent comparison strategy that\nprioritizes battles between models of similar capabilities to maximize\ninformation gain and enhance rating stability. Extensive empirical analyses and\nsimulations demonstrate that Inclusion Arena yields reliable and stable\nrankings, exhibits higher data transitivity compared to general crowdsourced\ndatasets, and significantly mitigates the risk of malicious manipulation. By\nfostering an open alliance between foundation models and real-world\napplications, Inclusion Arena aims to accelerate the development of LLMs and\nMLLMs truly optimized for practical, user-centric deployments. The platform is\npublicly accessible at https://doraemon.alipay.com/model-ranking.", "AI": {"tldr": "Inclusion Arena\u662f\u4e00\u4e2a\u5b9e\u65f6\u6392\u884c\u699c\uff0c\u901a\u8fc7\u4eceAI\u5e94\u7528\u4e2d\u6536\u96c6\u7684\u4eba\u7c7b\u53cd\u9988\u5bf9\u6a21\u578b\u8fdb\u884c\u6392\u540d\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u591a\u4f9d\u8d56\u9759\u6001\u6570\u636e\u96c6\u6216\u4f17\u5305\u901a\u7528\u63d0\u793a\uff0c\u96be\u4ee5\u53cd\u6620\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u5e73\u53f0\u6574\u5408\u4e86\u6210\u5bf9\u6a21\u578b\u6bd4\u8f83\uff0c\u91c7\u7528Bradley-Terry\u6a21\u578b\uff0c\u5e76\u5f15\u5165Placement Matches\u548cProximity Sampling\u4e24\u9879\u521b\u65b0\u6280\u672f\u3002", "result": "\u5b9e\u8bc1\u5206\u6790\u8868\u660e\uff0cInclusion Arena\u63d0\u4f9b\u53ef\u9760\u4e14\u7a33\u5b9a\u7684\u6392\u540d\uff0c\u6570\u636e\u4f20\u9012\u6027\u66f4\u9ad8\uff0c\u5e76\u80fd\u663e\u8457\u51cf\u5c11\u6076\u610f\u64cd\u7eb5\u98ce\u9669\u3002", "conclusion": "Inclusion Arena\u901a\u8fc7\u8fde\u63a5\u57fa\u7840\u6a21\u578b\u548c\u5b9e\u9645\u5e94\u7528\uff0c\u52a0\u901f\u5f00\u53d1\u66f4\u5b9e\u7528\u7684LLMs\u548cMLLMs\u3002"}}
{"id": "2508.11468", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.11468", "abs": "https://arxiv.org/abs/2508.11468", "authors": ["Zhihao Gong", "Zeyu Sun", "Dong Huang", "Qingyuan Liang", "Jie M. Zhang", "Dan Hao"], "title": "TRACY: Benchmarking Execution Efficiency of LLM-Based Code Translation", "comment": null, "summary": "Automatic code translation is a fundamental task in modern software\ndevelopment. While the advent of Large Language Models (LLMs) has significantly\nimproved the correctness of code translation, the critical dimension of\nexecution efficiency remains overlooked. To address this gap, we introduce\nTRACY, the first comprehensive benchmark designed to evaluate the execution\nefficiency of LLM-translated code. TRACY is constructed through an LLM-driven\ntwo-stage pipeline: an initial stage generates a suite of stress tests to\namplify performance differences, followed by an efficiency-oriented task\npruning stage that isolates the efficiency-distinguishing tasks. The resulting\nbenchmark comprises 1,011 code translation tasks across C++, Java, and Python,\neach accompanied by an average of 22.1 verified reference translations and 10\ncomputationally demanding tests. Our extensive evaluation of 26 representative\nLLMs reveals that even top-tier LLMs struggle to consistently produce efficient\ncode translations. For instance, Claude-4-think, the leading model for\ncorrectness, ranks eighth overall when time efficiency is taken into account,\nsurpassed by several smaller open-source models. We further pinpoint that\nalgorithmic flaws and improper resource handling are the most detrimental,\ncausing a median time slowdown of 5.6$\\times$ and memory increase of\n12.0$\\times$, respectively. Our work underscores the necessity of jointly\noptimizing for correctness and efficiency in future LLM-based code translation.", "AI": {"tldr": "TRACY\u662f\u9996\u4e2a\u8bc4\u4f30LLM\u7ffb\u8bd1\u4ee3\u7801\u6267\u884c\u6548\u7387\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63ed\u793a\u4e86\u5f53\u524dLLM\u5728\u751f\u6210\u9ad8\u6548\u4ee3\u7801\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709LLM\u5728\u4ee3\u7801\u7ffb\u8bd1\u4e2d\u6ce8\u91cd\u6b63\u786e\u6027\uff0c\u4f46\u5ffd\u7565\u4e86\u6267\u884c\u6548\u7387\uff0cTRACY\u586b\u8865\u4e86\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7LLM\u9a71\u52a8\u7684\u4e24\u9636\u6bb5\u6d41\u7a0b\u6784\u5efaTRACY\uff1a\u9996\u5148\u751f\u6210\u538b\u529b\u6d4b\u8bd5\uff0c\u518d\u7b5b\u9009\u6548\u7387\u533a\u5206\u4efb\u52a1\uff0c\u6700\u7ec8\u5305\u542b1,011\u4e2a\u4efb\u52a1\u3002", "result": "\u8bc4\u4f3026\u4e2aLLM\u53d1\u73b0\uff0c\u5373\u4f7f\u9876\u7ea7\u6a21\u578b\u5728\u6548\u7387\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u7b97\u6cd5\u7f3a\u9677\u548c\u8d44\u6e90\u5904\u7406\u4e0d\u5f53\u662f\u4e3b\u8981\u95ee\u9898\u3002", "conclusion": "\u672a\u6765LLM\u4ee3\u7801\u7ffb\u8bd1\u9700\u540c\u65f6\u4f18\u5316\u6b63\u786e\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2508.11548", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.11548", "abs": "https://arxiv.org/abs/2508.11548", "authors": ["Zhenhua Xu", "Xubin Yue", "Zhebo Wang", "Qichen Liu", "Xixiang Zhao", "Jingxuan Zhang", "Wenjun Zeng", "Wengpeng Xing", "Dezhang Kong", "Changting Lin", "Meng Han"], "title": "Copyright Protection for Large Language Models: A Survey of Methods, Challenges, and Trends", "comment": null, "summary": "Copyright protection for large language models is of critical importance,\ngiven their substantial development costs, proprietary value, and potential for\nmisuse. Existing surveys have predominantly focused on techniques for tracing\nLLM-generated content-namely, text watermarking-while a systematic exploration\nof methods for protecting the models themselves (i.e., model watermarking and\nmodel fingerprinting) remains absent. Moreover, the relationships and\ndistinctions among text watermarking, model watermarking, and model\nfingerprinting have not been comprehensively clarified. This work presents a\ncomprehensive survey of the current state of LLM copyright protection\ntechnologies, with a focus on model fingerprinting, covering the following\naspects: (1) clarifying the conceptual connection from text watermarking to\nmodel watermarking and fingerprinting, and adopting a unified terminology that\nincorporates model watermarking into the broader fingerprinting framework; (2)\nproviding an overview and comparison of diverse text watermarking techniques,\nhighlighting cases where such methods can function as model fingerprinting; (3)\nsystematically categorizing and comparing existing model fingerprinting\napproaches for LLM copyright protection; (4) presenting, for the first time,\ntechniques for fingerprint transfer and fingerprint removal; (5) summarizing\nevaluation metrics for model fingerprints, including effectiveness,\nharmlessness, robustness, stealthiness, and reliability; and (6) discussing\nopen challenges and future research directions. This survey aims to offer\nresearchers a thorough understanding of both text watermarking and model\nfingerprinting technologies in the era of LLMs, thereby fostering further\nadvances in protecting their intellectual property.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7248\u6743\u4fdd\u62a4\u6280\u672f\uff0c\u91cd\u70b9\u63a2\u8ba8\u4e86\u6a21\u578b\u6307\u7eb9\u8bc6\u522b\uff0c\u5e76\u6f84\u6e05\u4e86\u6587\u672c\u6c34\u5370\u3001\u6a21\u578b\u6c34\u5370\u548c\u6a21\u578b\u6307\u7eb9\u7684\u5173\u7cfb\u3002", "motivation": "\u9274\u4e8eLLM\u7684\u9ad8\u5f00\u53d1\u6210\u672c\u3001\u4e13\u6709\u4ef7\u503c\u53ca\u6f5c\u5728\u6ee5\u7528\u98ce\u9669\uff0c\u4fdd\u62a4\u5176\u7248\u6743\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u6587\u672c\u6c34\u5370\uff0c\u7f3a\u4e4f\u5bf9\u6a21\u578b\u4fdd\u62a4\u7684\u5168\u9762\u63a2\u8ba8\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u5206\u7c7b\u548c\u6bd4\u8f83\u73b0\u6709\u6280\u672f\uff0c\u6f84\u6e05\u6982\u5ff5\u5173\u7cfb\uff0c\u7edf\u4e00\u672f\u8bed\uff0c\u5e76\u9996\u6b21\u63d0\u51fa\u6307\u7eb9\u8f6c\u79fb\u548c\u79fb\u9664\u6280\u672f\u3002", "result": "\u603b\u7ed3\u4e86\u6a21\u578b\u6307\u7eb9\u7684\u8bc4\u4ef7\u6307\u6807\uff08\u5982\u6709\u6548\u6027\u3001\u65e0\u5bb3\u6027\u7b49\uff09\uff0c\u5e76\u8ba8\u8bba\u4e86\u5f00\u653e\u6311\u6218\u4e0e\u672a\u6765\u65b9\u5411\u3002", "conclusion": "\u672c\u6587\u4e3a\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u5bf9LLM\u65f6\u4ee3\u6587\u672c\u6c34\u5370\u548c\u6a21\u578b\u6307\u7eb9\u6280\u672f\u7684\u5168\u9762\u7406\u89e3\uff0c\u63a8\u52a8\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2508.11493", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.11493", "abs": "https://arxiv.org/abs/2508.11493", "authors": ["David H. Chan", "Mark Roberts", "Dana S. Nau"], "title": "Landmark-Assisted Monte Carlo Planning", "comment": "To be published in the Proceedings of the 28th European Conference on\n  Artificial Intelligence", "summary": "Landmarks$\\unicode{x2013}$conditions that must be satisfied at some point in\nevery solution plan$\\unicode{x2013}$have contributed to major advancements in\nclassical planning, but they have seldom been used in stochastic domains. We\nformalize probabilistic landmarks and adapt the UCT algorithm to leverage them\nas subgoals to decompose MDPs; core to the adaptation is balancing between\ngreedy landmark achievement and final goal achievement. Our results in\nbenchmark domains show that well-chosen landmarks can significantly improve the\nperformance of UCT in online probabilistic planning, while the best balance of\ngreedy versus long-term goal achievement is problem-dependent. The results\nsuggest that landmarks can provide helpful guidance for anytime algorithms\nsolving MDPs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u6982\u7387\u6027\u5730\u6807\uff08probabilistic landmarks\uff09\u6539\u8fdbUCT\u7b97\u6cd5\u5728\u968f\u673a\u89c4\u5212\u4e2d\u6027\u80fd\u7684\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5730\u6807\u5728\u7ecf\u5178\u89c4\u5212\u4e2d\u5df2\u6709\u663e\u8457\u8d21\u732e\uff0c\u4f46\u5728\u968f\u673a\u9886\u57df\u5e94\u7528\u8f83\u5c11\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u5730\u6807\u5728\u968f\u673a\u89c4\u5212\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u5c06\u6982\u7387\u6027\u5730\u6807\u5f62\u5f0f\u5316\uff0c\u5e76\u8c03\u6574UCT\u7b97\u6cd5\u4ee5\u5730\u6807\u4e3a\u5b50\u76ee\u6807\u5206\u89e3MDP\uff0c\u6838\u5fc3\u5728\u4e8e\u5e73\u8861\u8d2a\u5a6a\u5730\u6807\u8fbe\u6210\u4e0e\u957f\u671f\u76ee\u6807\u8fbe\u6210\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5408\u9002\u7684\u5730\u6807\u80fd\u663e\u8457\u63d0\u5347UCT\u5728\u5728\u7ebf\u6982\u7387\u89c4\u5212\u4e2d\u7684\u6027\u80fd\uff0c\u4f46\u6700\u4f73\u5e73\u8861\u70b9\u56e0\u95ee\u9898\u800c\u5f02\u3002", "conclusion": "\u5730\u6807\u53ef\u4e3a\u89e3\u51b3MDP\u7684\u968f\u65f6\u7b97\u6cd5\u63d0\u4f9b\u6709\u6548\u6307\u5bfc\u3002"}}
{"id": "2508.11571", "categories": ["cs.SE", "cs.DM"], "pdf": "https://arxiv.org/pdf/2508.11571", "abs": "https://arxiv.org/abs/2508.11571", "authors": ["Alexander Bakhtin"], "title": "Temporal Network Analysis of Microservice Architectural Degradation", "comment": null, "summary": "Microservice architecture can be modeled as a network of microservices making\ncalls to each other, commonly known as the service dependency graph. Network\nScience can provide methods to study such networks. In particular, temporal\nnetwork analysis is a branch of Network Science that analyzes networks evolving\nwith time. In microservice systems, temporal networks can arise if we examine\nthe architecture of the system across releases or monitor a deployed system\nusing tracing.\n  In this research summary paper, I discuss the challenges in obtaining\ntemporal networks from microservice systems and analyzing them with the\ntemporal network methods. In particular, the most complete temporal network\nthat we could obtain contains 7 time instances and 42 microservices, which\nlimits the potential analysis that could be applied.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u4ece\u5fae\u670d\u52a1\u7cfb\u7edf\u4e2d\u83b7\u53d6\u65f6\u95f4\u7f51\u7edc\u5e76\u5206\u6790\u5176\u6311\u6218\uff0c\u6307\u51fa\u73b0\u6709\u6570\u636e\u89c4\u6a21\u9650\u5236\u4e86\u5206\u6790\u65b9\u6cd5\u7684\u5e94\u7528\u3002", "motivation": "\u7814\u7a76\u5fae\u670d\u52a1\u67b6\u6784\u7684\u65f6\u95f4\u7f51\u7edc\u5206\u6790\u65b9\u6cd5\uff0c\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u548c\u4f18\u5316\u5fae\u670d\u52a1\u7cfb\u7edf\u7684\u52a8\u6001\u884c\u4e3a\u3002", "method": "\u5229\u7528\u7f51\u7edc\u79d1\u5b66\u4e2d\u7684\u65f6\u95f4\u7f51\u7edc\u5206\u6790\u65b9\u6cd5\uff0c\u7814\u7a76\u5fae\u670d\u52a1\u7cfb\u7edf\u7684\u4f9d\u8d56\u5173\u7cfb\u968f\u65f6\u95f4\u7684\u53d8\u5316\u3002", "result": "\u83b7\u53d6\u7684\u6700\u5b8c\u6574\u65f6\u95f4\u7f51\u7edc\u5305\u542b7\u4e2a\u65f6\u95f4\u5b9e\u4f8b\u548c42\u4e2a\u5fae\u670d\u52a1\uff0c\u6570\u636e\u89c4\u6a21\u9650\u5236\u4e86\u5206\u6790\u65b9\u6cd5\u7684\u6df1\u5ea6\u5e94\u7528\u3002", "conclusion": "\u5c3d\u7ba1\u6570\u636e\u89c4\u6a21\u6709\u9650\uff0c\u65f6\u95f4\u7f51\u7edc\u5206\u6790\u4ecd\u4e3a\u5fae\u670d\u52a1\u7cfb\u7edf\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c6\u89d2\uff0c\u672a\u6765\u9700\u6269\u5c55\u6570\u636e\u89c4\u6a21\u4ee5\u652f\u6301\u66f4\u6df1\u5165\u5206\u6790\u3002"}}
{"id": "2508.11563", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.11563", "abs": "https://arxiv.org/abs/2508.11563", "authors": ["Nathaniel Moyer", "Charalampos Papamanthou", "Evgenios Kornaropoulos"], "title": "Pushing the Limits of Frequency Analysis in Leakage Abuse Attacks", "comment": null, "summary": "Searchable encryption (SE) is the most scalable cryptographic primitive for\nsearching on encrypted data. Typical SE constructions often allow\naccess-pattern leakage, revealing which encrypted records are retrieved in the\nserver's responses. All the known generic cryptanalyses assume either that the\nqueries are issued uniformly at random or that the attacker observes the\nsearch-pattern leakage. It remains unclear what can be reconstructed when using\nonly the access-pattern leakage and knowledge of the query distribution. In\nthis work, we focus on the cryptanalytic technique of frequency analysis in the\ncontext of leakage-abuse attacks on schemes that support encrypted range\nqueries. Frequency analysis matches the frequency of retrieval of an encrypted\nrecord with a plaintext value based on its probability of retrieval that\nfollows from the knowledge of the query distribution. We generalize this\nunderexplored cryptanalytic technique and introduce a generic attack framework\ncalled Leakage-Abuse via Matching (LAMA) that works even on high-dimensional\nencrypted data. We identify a parameterization of LAMA that brings frequency\nanalysis to its limit -- that is, we prove that there is no additional\nfrequency matching that an attacker can perform to refine the result.\nFurthermore, we show that our results hold for any class of convex queries, and\nnot just axis-aligned rectangles, which is the assumption in all other attacks\non range schemes. Using these results, we identify query distributions that\nmake frequency analysis challenging for the attacker and, thus, can act as a\nmitigation mechanism. Finally, we implement and benchmark LAMA and reconstruct,\nfor the first time, plaintext data from encrypted range queries spanning up to\nfour dimensions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLAMA\u7684\u901a\u7528\u653b\u51fb\u6846\u67b6\uff0c\u9488\u5bf9\u652f\u6301\u52a0\u5bc6\u8303\u56f4\u67e5\u8be2\u7684\u65b9\u6848\uff0c\u901a\u8fc7\u9891\u7387\u5206\u6790\u5229\u7528\u8bbf\u95ee\u6a21\u5f0f\u6cc4\u6f0f\u91cd\u6784\u660e\u6587\u6570\u636e\u3002", "motivation": "\u63a2\u7d22\u5728\u4ec5\u77e5\u9053\u67e5\u8be2\u5206\u5e03\u548c\u8bbf\u95ee\u6a21\u5f0f\u6cc4\u6f0f\u7684\u60c5\u51b5\u4e0b\uff0c\u653b\u51fb\u8005\u80fd\u91cd\u6784\u591a\u5c11\u4fe1\u606f\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u63d0\u51faLAMA\u6846\u67b6\uff0c\u901a\u8fc7\u9891\u7387\u5339\u914d\u6280\u672f\u5206\u6790\u9ad8\u7ef4\u52a0\u5bc6\u6570\u636e\uff0c\u5e76\u8bc1\u660e\u5176\u6781\u9650\u6027\u80fd\u3002", "result": "LAMA\u9996\u6b21\u6210\u529f\u91cd\u6784\u4e86\u56db\u7ef4\u52a0\u5bc6\u8303\u56f4\u67e5\u8be2\u7684\u660e\u6587\u6570\u636e\uff0c\u5e76\u786e\u5b9a\u4e86\u4f7f\u9891\u7387\u5206\u6790\u56f0\u96be\u7684\u67e5\u8be2\u5206\u5e03\u3002", "conclusion": "LAMA\u5c55\u793a\u4e86\u9891\u7387\u5206\u6790\u7684\u6781\u9650\u6027\u80fd\uff0c\u5e76\u63d0\u51fa\u4e86\u53ef\u80fd\u7684\u7f13\u89e3\u673a\u5236\u3002"}}
{"id": "2508.11524", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.11524", "abs": "https://arxiv.org/abs/2508.11524", "authors": ["Wenkai Yu", "Jianhang Tang", "Yang Zhang", "Shanjiang Tang", "Kebing Jin", "Hankz Hankui Zhuo"], "title": "Inspire or Predict? Exploring New Paradigms in Assisting Classical Planners with Large Language Models", "comment": null, "summary": "Addressing large-scale planning problems has become one of the central\nchallenges in the planning community, deriving from the state-space explosion\ncaused by growing objects and actions. Recently, researchers have explored the\neffectiveness of leveraging Large Language Models (LLMs) to generate helpful\nactions and states to prune the search space. However, prior works have largely\noverlooked integrating LLMs with domain-specific knowledge to ensure valid\nplans. In this paper, we propose a novel LLM-assisted planner integrated with\nproblem decomposition, which first decomposes large planning problems into\nmultiple simpler sub-tasks. Then we explore two novel paradigms to utilize\nLLMs, i.e., LLM4Inspire and LLM4Predict, to assist problem decomposition, where\nLLM4Inspire provides heuristic guidance according to general knowledge and\nLLM4Predict employs domain-specific knowledge to infer intermediate conditions.\nWe empirically validate the effectiveness of our planner across multiple\ndomains, demonstrating the ability of search space partition when solving\nlarge-scale planning problems. The experimental results show that LLMs\neffectively locate feasible solutions when pruning the search space, where\ninfusing domain-specific knowledge into LLMs, i.e., LLM4Predict, holds\nparticular promise compared with LLM4Inspire, which offers general knowledge\nwithin LLMs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408LLM\u548c\u95ee\u9898\u5206\u89e3\u7684\u65b0\u578b\u89c4\u5212\u5668\uff0c\u901a\u8fc7LLM4Inspire\u548cLLM4Predict\u4e24\u79cd\u8303\u5f0f\u8f85\u52a9\u5206\u89e3\u5927\u89c4\u6a21\u89c4\u5212\u95ee\u9898\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u5927\u89c4\u6a21\u89c4\u5212\u95ee\u9898\u4e2d\u7684\u72b6\u6001\u7a7a\u95f4\u7206\u70b8\u95ee\u9898\uff0c\u5e76\u63a2\u7d22\u5982\u4f55\u7ed3\u5408LLM\u4e0e\u9886\u57df\u77e5\u8bc6\u4ee5\u751f\u6210\u6709\u6548\u89c4\u5212\u3002", "method": "\u63d0\u51faLLM\u8f85\u52a9\u89c4\u5212\u5668\uff0c\u7ed3\u5408\u95ee\u9898\u5206\u89e3\u548c\u4e24\u79cdLLM\u8303\u5f0f\uff08LLM4Inspire\u548cLLM4Predict\uff09\uff0c\u5206\u522b\u5229\u7528\u901a\u7528\u77e5\u8bc6\u548c\u9886\u57df\u77e5\u8bc6\u6307\u5bfc\u5206\u89e3\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cLLM\u80fd\u6709\u6548\u4fee\u526a\u641c\u7d22\u7a7a\u95f4\u5e76\u627e\u5230\u53ef\u884c\u89e3\uff0c\u5176\u4e2d\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u7684LLM4Predict\u8868\u73b0\u4f18\u4e8e\u4ec5\u4f9d\u8d56\u901a\u7528\u77e5\u8bc6\u7684LLM4Inspire\u3002", "conclusion": "\u7ed3\u5408LLM\u4e0e\u9886\u57df\u77e5\u8bc6\u7684\u95ee\u9898\u5206\u89e3\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u89c4\u5212\u95ee\u9898\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u5c24\u5176\u662fLLM4Predict\u8303\u5f0f\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2508.11575", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.11575", "abs": "https://arxiv.org/abs/2508.11575", "authors": ["Nges Brian Njungle", "Michel A. Kinsy"], "title": "Activate Me!: Designing Efficient Activation Functions for Privacy-Preserving Machine Learning with Fully Homomorphic Encryption", "comment": null, "summary": "The growing adoption of machine learning in sensitive areas such as\nhealthcare and defense introduces significant privacy and security challenges.\nThese domains demand robust data protection, as models depend on large volumes\nof sensitive information for both training and inference. Fully Homomorphic\nEncryption (FHE) presents a compelling solution by enabling computations\ndirectly on encrypted data, maintaining confidentiality across the entire\nmachine learning workflow. However, FHE inherently supports only linear\noperations, making it difficult to implement non-linear activation functions,\nessential components of modern neural networks. This work focuses on designing,\nimplementing, and evaluating activation functions tailored for FHE-based\nmachine learning. We investigate two commonly used functions: the Square\nfunction and Rectified Linear Unit (ReLU), using LeNet-5 and ResNet-20\narchitectures with the CKKS scheme from the OpenFHE library. For ReLU, we\nassess two methods: a conventional low-degree polynomial approximation and a\nnovel scheme-switching technique that securely evaluates ReLU under FHE\nconstraints. Our findings show that the Square function performs well in\nshallow networks like LeNet-5, achieving 99.4% accuracy with 128 seconds per\nimage. In contrast, deeper models like ResNet-20 benefit more from ReLU. The\npolynomial approximation yields 83.8% accuracy with 1,145 seconds per image,\nwhile our scheme-switching method improves accuracy to 89.8%, albeit with a\nlonger inference time of 1,697 seconds. These results underscore a critical\ntrade-off in FHE-based ML: faster activation functions often reduce accuracy,\nwhereas those preserving accuracy demand greater computational resources.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u57fa\u4e8e\u5168\u540c\u6001\u52a0\u5bc6\uff08FHE\uff09\u7684\u673a\u5668\u5b66\u4e60\u4e2d\u8bbe\u8ba1\u6fc0\u6d3b\u51fd\u6570\u7684\u65b9\u6cd5\uff0c\u6bd4\u8f83\u4e86Square\u51fd\u6570\u548cReLU\u5728LeNet-5\u548cResNet-20\u67b6\u6784\u4e2d\u7684\u8868\u73b0\uff0c\u63ed\u793a\u4e86\u901f\u5ea6\u4e0e\u51c6\u786e\u6027\u7684\u6743\u8861\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u5728\u533b\u7597\u548c\u56fd\u9632\u7b49\u654f\u611f\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u6570\u636e\u9690\u79c1\u548c\u5b89\u5168\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\u3002FHE\u867d\u80fd\u4fdd\u62a4\u6570\u636e\u9690\u79c1\uff0c\u4f46\u5176\u4ec5\u652f\u6301\u7ebf\u6027\u64cd\u4f5c\uff0c\u96be\u4ee5\u5b9e\u73b0\u73b0\u4ee3\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\u3002", "method": "\u7814\u7a76\u8bbe\u8ba1\u4e86\u9002\u7528\u4e8eFHE\u7684\u6fc0\u6d3b\u51fd\u6570\uff0c\u91cd\u70b9\u8bc4\u4f30\u4e86Square\u51fd\u6570\u548cReLU\uff08\u5305\u62ec\u591a\u9879\u5f0f\u8fd1\u4f3c\u548c\u65b0\u578b\u65b9\u6848\u5207\u6362\u6280\u672f\uff09\uff0c\u5e76\u5728LeNet-5\u548cResNet-20\u67b6\u6784\u4e2d\u8fdb\u884c\u4e86\u5b9e\u9a8c\u3002", "result": "Square\u51fd\u6570\u5728\u6d45\u5c42\u7f51\u7edc\uff08LeNet-5\uff09\u4e2d\u8868\u73b0\u4f18\u5f02\uff0899.4%\u51c6\u786e\u7387\uff0c128\u79d2/\u56fe\uff09\uff0c\u800cReLU\u66f4\u9002\u5408\u6df1\u5c42\u7f51\u7edc\uff08ResNet-20\uff09\u3002\u591a\u9879\u5f0f\u8fd1\u4f3cReLU\u51c6\u786e\u7387\u4e3a83.8%\uff081,145\u79d2/\u56fe\uff09\uff0c\u65b9\u6848\u5207\u6362\u6280\u672f\u63d0\u5347\u81f389.8%\uff081,697\u79d2/\u56fe\uff09\u3002", "conclusion": "FHE\u673a\u5668\u5b66\u4e60\u4e2d\u6fc0\u6d3b\u51fd\u6570\u7684\u9009\u62e9\u9700\u8981\u5728\u901f\u5ea6\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u6743\u8861\uff1a\u5feb\u901f\u51fd\u6570\u53ef\u80fd\u964d\u4f4e\u51c6\u786e\u6027\uff0c\u800c\u9ad8\u51c6\u786e\u6027\u51fd\u6570\u5219\u9700\u8981\u66f4\u591a\u8ba1\u7b97\u8d44\u6e90\u3002"}}
{"id": "2508.11599", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.11599", "abs": "https://arxiv.org/abs/2508.11599", "authors": ["Zhihao Li", "Zimo Ji", "Tao Zheng", "Hao Ren", "Xiao Lan"], "title": "CryptoScope: Utilizing Large Language Models for Automated Cryptographic Logic Vulnerability Detection", "comment": null, "summary": "Cryptographic algorithms are fundamental to modern security, yet their\nimplementations frequently harbor subtle logic flaws that are hard to detect.\nWe introduce CryptoScope, a novel framework for automated cryptographic\nvulnerability detection powered by Large Language Models (LLMs). CryptoScope\ncombines Chain-of-Thought (CoT) prompting with Retrieval-Augmented Generation\n(RAG), guided by a curated cryptographic knowledge base containing over 12,000\nentries. We evaluate CryptoScope on LLM-CLVA, a benchmark of 92 cases primarily\nderived from real-world CVE vulnerabilities, complemented by cryptographic\nchallenges from major Capture The Flag (CTF) competitions and synthetic\nexamples across 11 programming languages. CryptoScope consistently improves\nperformance over strong LLM baselines, boosting DeepSeek-V3 by 11.62%,\nGPT-4o-mini by 20.28%, and GLM-4-Flash by 28.69%. Additionally, it identifies 9\npreviously undisclosed flaws in widely used open-source cryptographic projects.", "AI": {"tldr": "CryptoScope\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u81ea\u52a8\u5316\u52a0\u5bc6\u6f0f\u6d1e\u68c0\u6d4b\u6846\u67b6\uff0c\u7ed3\u5408\u4e86Chain-of-Thought\u63d0\u793a\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u5e76\u53d1\u73b0\u4e86\u5f00\u6e90\u52a0\u5bc6\u9879\u76ee\u4e2d\u7684\u65b0\u6f0f\u6d1e\u3002", "motivation": "\u52a0\u5bc6\u7b97\u6cd5\u7684\u5b9e\u73b0\u5e38\u5b58\u5728\u96be\u4ee5\u68c0\u6d4b\u7684\u903b\u8f91\u6f0f\u6d1e\uff0c\u9700\u8981\u4e00\u79cd\u81ea\u52a8\u5316\u5de5\u5177\u6765\u63d0\u9ad8\u6f0f\u6d1e\u68c0\u6d4b\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "CryptoScope\u7ed3\u5408Chain-of-Thought\u63d0\u793a\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\uff0c\u5229\u7528\u5305\u542b12,000\u6761\u8bb0\u5f55\u7684\u52a0\u5bc6\u77e5\u8bc6\u5e93\u8fdb\u884c\u6307\u5bfc\u3002", "result": "\u5728LLM-CLVA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCryptoScope\u663e\u8457\u63d0\u5347\u4e86\u591a\u4e2aLLM\u6a21\u578b\u7684\u6027\u80fd\uff08\u5982DeepSeek-V3\u63d0\u534711.62%\uff09\uff0c\u5e76\u53d1\u73b0\u4e869\u4e2a\u672a\u516c\u5f00\u7684\u5f00\u6e90\u9879\u76ee\u6f0f\u6d1e\u3002", "conclusion": "CryptoScope\u901a\u8fc7\u7ed3\u5408LLM\u548c\u52a0\u5bc6\u77e5\u8bc6\u5e93\uff0c\u6709\u6548\u63d0\u5347\u4e86\u52a0\u5bc6\u6f0f\u6d1e\u68c0\u6d4b\u7684\u80fd\u529b\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
