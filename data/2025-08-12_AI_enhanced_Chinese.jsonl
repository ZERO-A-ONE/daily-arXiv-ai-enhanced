{"id": "2508.06718", "categories": ["cs.SE", "K.6.3; D.2.7"], "pdf": "https://arxiv.org/pdf/2508.06718", "abs": "https://arxiv.org/abs/2508.06718", "authors": ["Daniel Ogenrwot", "John Businge"], "title": "Refactoring-Aware Patch Integration Across Structurally Divergent Java Forks", "comment": "12 pages, 3 figures", "summary": "While most forks on platforms like GitHub are short-lived and used for social\ncollaboration, a smaller but impactful subset evolve into long-lived forks,\nreferred to here as variants, that maintain independent development\ntrajectories. Integrating bug-fix patches across such divergent variants poses\nchallenges due to structural drift, including refactorings that rename,\nrelocate, or reorganize code elements and obscure semantic correspondence. This\npaper presents an empirical study of patch integration failures in 14 divergent\npair of variants and introduces RePatch, a refactoring-aware integration system\nfor Java repositories. RePatch extends the RefMerge framework, originally\ndesigned for symmetric merges, by supporting asymmetric patch transfer. RePatch\ninverts refactorings in both the source and target to realign the patch\ncontext, applies the patch, and replays the transformations to preserve the\nintent of the variant. In our evaluation of 478 bug-fix pull requests, Git\ncherry-pick fails in 64.4% of cases due to structural misalignments, while\nRePatch successfully integrates 52.8% of the previously failing patches. These\nresults highlight the limitations of syntax-based tools and the need for\nsemantic reasoning in variant-aware patch propagation.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86GitHub\u4e0a\u957f\u671f\u5206\u53c9\uff08\u53d8\u4f53\uff09\u7684\u8865\u4e01\u96c6\u6210\u95ee\u9898\uff0c\u63d0\u51fa\u4e86RePatch\u7cfb\u7edf\uff0c\u80fd\u591f\u901a\u8fc7\u8bed\u4e49\u5bf9\u9f50\u6210\u529f\u96c6\u6210\u66f4\u591a\u8865\u4e01\u3002", "motivation": "\u957f\u671f\u5206\u53c9\u7684\u4ee3\u7801\u53d8\u4f53\u56e0\u7ed3\u6784\u6f02\u79fb\uff08\u5982\u91cd\u6784\uff09\u5bfc\u81f4\u8865\u4e01\u96c6\u6210\u56f0\u96be\uff0c\u73b0\u6709\u5de5\u5177\uff08\u5982Git cherry-pick\uff09\u5931\u8d25\u7387\u9ad8\u3002", "method": "\u63d0\u51faRePatch\u7cfb\u7edf\uff0c\u6269\u5c55RefMerge\u6846\u67b6\uff0c\u652f\u6301\u975e\u5bf9\u79f0\u8865\u4e01\u4f20\u8f93\uff0c\u901a\u8fc7\u53cd\u8f6c\u91cd\u6784\u5bf9\u9f50\u8865\u4e01\u4e0a\u4e0b\u6587\u3002", "result": "\u5728478\u4e2a\u8865\u4e01\u8bf7\u6c42\u4e2d\uff0cGit cherry-pick\u5931\u8d25\u738764.4%\uff0c\u800cRePatch\u6210\u529f\u96c6\u6210\u4e8652.8%\u7684\u5931\u8d25\u6848\u4f8b\u3002", "conclusion": "\u57fa\u4e8e\u8bed\u4e49\u63a8\u7406\u7684RePatch\u4f18\u4e8e\u8bed\u6cd5\u5de5\u5177\uff0c\u89e3\u51b3\u4e86\u53d8\u4f53\u8865\u4e01\u4f20\u64ad\u7684\u6311\u6218\u3002"}}
{"id": "2508.06879", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.06879", "abs": "https://arxiv.org/abs/2508.06879", "authors": ["Michael Dorner", "Andreas Bauer", "Darja \u0160mite", "Lukas Thode", "Daniel Mendez", "Ricardo Britto", "Stephan Lukasczyk", "Ehsan Zabardast", "Michael Kormann"], "title": "Quo Vadis, Code Review? Exploring the Future of Code Review", "comment": null, "summary": "Code review has long been a core practice in collaborative software\nengineering. In this research, we explore how practitioners reflect on code\nreview today and what changes they anticipate in the near future. We then\ndiscuss the potential long-term risks of these anticipated changes for the\nevolution of code review and its role in collaborative software engineering.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5f53\u524d\u5f00\u53d1\u8005\u5bf9\u4ee3\u7801\u5ba1\u67e5\u7684\u53cd\u601d\u53ca\u672a\u6765\u9884\u671f\u53d8\u5316\uff0c\u5e76\u5206\u6790\u4e86\u8fd9\u4e9b\u53d8\u5316\u5bf9\u4ee3\u7801\u5ba1\u67e5\u957f\u671f\u53d1\u5c55\u7684\u6f5c\u5728\u98ce\u9669\u3002", "motivation": "\u4e86\u89e3\u5f00\u53d1\u8005\u5bf9\u4ee3\u7801\u5ba1\u67e5\u7684\u73b0\u72b6\u53cd\u601d\u53ca\u672a\u6765\u9884\u671f\uff0c\u4ee5\u8bc4\u4f30\u5176\u5bf9\u534f\u4f5c\u8f6f\u4ef6\u5de5\u7a0b\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u8c03\u7814\u548c\u5206\u6790\u5f00\u53d1\u8005\u7684\u89c2\u70b9\uff0c\u63a2\u8ba8\u4ee3\u7801\u5ba1\u67e5\u7684\u73b0\u72b6\u548c\u672a\u6765\u8d8b\u52bf\u3002", "result": "\u8bc6\u522b\u4e86\u4ee3\u7801\u5ba1\u67e5\u672a\u6765\u53ef\u80fd\u7684\u53d8\u5316\u53ca\u5176\u6f5c\u5728\u98ce\u9669\u3002", "conclusion": "\u4ee3\u7801\u5ba1\u67e5\u7684\u672a\u6765\u53d8\u5316\u53ef\u80fd\u5e26\u6765\u957f\u671f\u98ce\u9669\uff0c\u9700\u8c28\u614e\u8bc4\u4f30\u5176\u5bf9\u534f\u4f5c\u8f6f\u4ef6\u5de5\u7a0b\u7684\u5f71\u54cd\u3002"}}
{"id": "2508.06888", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.06888", "abs": "https://arxiv.org/abs/2508.06888", "authors": ["Fanyu Wang", "Chetan Arora", "Yonghui Liu", "Kaicheng Huang", "Chakkrit Tantithamthavorn", "Aldeida Aleti", "Dishan Sambathkumar", "David Lo"], "title": "Multi-Modal Requirements Data-based Acceptance Criteria Generation using LLMs", "comment": null, "summary": "Acceptance criteria (ACs) play a critical role in software development by\nclearly defining the conditions under which a software feature satisfies\nstakeholder expectations. However, manually creating accurate, comprehensive,\nand unambiguous acceptance criteria is challenging, particularly in user\ninterface-intensive applications, due to the reliance on domain-specific\nknowledge and visual context that is not always captured by textual\nrequirements alone. To address these challenges, we propose RAGcceptance M2RE,\na novel approach that leverages Retrieval-Augmented Generation (RAG) to\ngenerate acceptance criteria from multi-modal requirements data, including both\ntextual documentation and visual UI information. We systematically evaluated\nour approach in an industrial case study involving an education-focused\nsoftware system used by approximately 100,000 users. The results indicate that\nintegrating multi-modal information significantly enhances the relevance,\ncorrectness, and comprehensibility of the generated ACs. Moreover, practitioner\nevaluations confirm that our approach effectively reduces manual effort,\ncaptures nuanced stakeholder intent, and provides valuable criteria that domain\nexperts may overlook, demonstrating practical utility and significant potential\nfor industry adoption. This research underscores the potential of multi-modal\nRAG techniques in streamlining software validation processes and improving\ndevelopment efficiency. We also make our implementation and a dataset\navailable.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRAGcceptance M2RE\u7684\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u4ece\u591a\u6a21\u6001\u9700\u6c42\u6570\u636e\u4e2d\u751f\u6210\u9a8c\u6536\u6807\u51c6\uff08ACs\uff09\uff0c\u663e\u8457\u63d0\u5347\u4e86ACs\u7684\u76f8\u5173\u6027\u3001\u6b63\u786e\u6027\u548c\u53ef\u7406\u89e3\u6027\u3002", "motivation": "\u624b\u52a8\u521b\u5efa\u51c6\u786e\u3001\u5168\u9762\u4e14\u65e0\u6b67\u4e49\u7684\u9a8c\u6536\u6807\u51c6\u5728\u7528\u6237\u754c\u9762\u5bc6\u96c6\u578b\u5e94\u7528\u4e2d\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u4f9d\u8d56\u9886\u57df\u77e5\u8bc6\u548c\u89c6\u89c9\u4e0a\u4e0b\u6587\uff0c\u800c\u6587\u672c\u9700\u6c42\u5f80\u5f80\u65e0\u6cd5\u5b8c\u5168\u6355\u6349\u8fd9\u4e9b\u4fe1\u606f\u3002", "method": "\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6280\u672f\uff0c\u7ed3\u5408\u6587\u672c\u6587\u6863\u548c\u89c6\u89c9UI\u4fe1\u606f\u7684\u591a\u6a21\u6001\u6570\u636e\uff0c\u751f\u6210\u9a8c\u6536\u6807\u51c6\u3002", "result": "\u5de5\u4e1a\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u591a\u6a21\u6001\u4fe1\u606f\u96c6\u6210\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210ACs\u7684\u8d28\u91cf\uff0c\u51cf\u5c11\u4e86\u4eba\u5de5\u5de5\u4f5c\u91cf\uff0c\u5e76\u6355\u6349\u4e86\u5bb9\u6613\u88ab\u5ffd\u89c6\u7684\u5229\u76ca\u76f8\u5173\u8005\u610f\u56fe\u3002", "conclusion": "\u591a\u6a21\u6001RAG\u6280\u672f\u5728\u4f18\u5316\u8f6f\u4ef6\u9a8c\u8bc1\u6d41\u7a0b\u548c\u63d0\u9ad8\u5f00\u53d1\u6548\u7387\u65b9\u9762\u5177\u6709\u663e\u8457\u6f5c\u529b\uff0c\u7814\u7a76\u8fd8\u516c\u5f00\u4e86\u5b9e\u73b0\u548c\u6570\u636e\u96c6\u3002"}}
{"id": "2508.06926", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.06926", "abs": "https://arxiv.org/abs/2508.06926", "authors": ["Feng Luo", "Kexing Ji", "Cuiyun Gao", "Shuzheng Gao", "Jia Feng", "Kui Liu", "Xin Xia", "Michael R. Lyu"], "title": "Integrating Rules and Semantics for LLM-Based C-to-Rust Translation", "comment": "Accepted in ICSME 25 Industry Track", "summary": "Automated translation of legacy C code into Rust aims to ensure memory safety\nwhile reducing the burden of manual migration. Early approaches in code\ntranslation rely on static rule-based methods, but they suffer from limited\ncoverage due to dependence on predefined rule patterns. Recent works regard the\ntask as a sequence-to-sequence problem by leveraging large language models\n(LLMs). Although these LLM-based methods are capable of reducing unsafe code\nblocks, the translated code often exhibits issues in following Rust rules and\nmaintaining semantic consistency. On one hand, existing methods adopt a direct\nprompting strategy to translate the C code, which struggles to accommodate the\nsyntactic rules between C and Rust. On the other hand, this strategy makes it\ndifficult for LLMs to accurately capture the semantics of complex code. To\naddress these challenges, we propose IRENE, an LLM-based framework that\nIntegrates RulEs aNd sEmantics to enhance translation. IRENE consists of three\nmodules: 1) a rule-augmented retrieval module that selects relevant translation\nexamples based on rules generated from a static analyzer developed by us,\nthereby improving the handling of Rust rules; 2) a structured summarization\nmodule that produces a structured summary for guiding LLMs to enhance the\nsemantic understanding of C code; 3) an error-driven translation module that\nleverages compiler diagnostics to iteratively refine translations. We evaluate\nIRENE on two datasets (xCodeEval, a public dataset, and HW-Bench, an industrial\ndataset provided by Huawei) and eight LLMs, focusing on translation accuracy\nand safety.", "AI": {"tldr": "IRENE\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u6210\u89c4\u5219\u548c\u8bed\u4e49\u63d0\u5347C\u5230Rust\u7684\u4ee3\u7801\u7ffb\u8bd1\u8d28\u91cf\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u8bed\u6cd5\u89c4\u5219\u548c\u8bed\u4e49\u4e00\u81f4\u6027\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709C\u5230Rust\u7684\u7ffb\u8bd1\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u89c4\u5219\u6216LLM\u7684\u76f4\u63a5\u63d0\u793a\u7b56\u7565\uff0c\u5b58\u5728\u8bed\u6cd5\u89c4\u5219\u9002\u5e94\u6027\u548c\u8bed\u4e49\u6355\u83b7\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "IRENE\u5305\u542b\u4e09\u4e2a\u6a21\u5757\uff1a\u89c4\u5219\u589e\u5f3a\u68c0\u7d22\u6a21\u5757\u3001\u7ed3\u6784\u5316\u6458\u8981\u6a21\u5757\u548c\u9519\u8bef\u9a71\u52a8\u7ffb\u8bd1\u6a21\u5757\uff0c\u5206\u522b\u63d0\u5347\u89c4\u5219\u5904\u7406\u3001\u8bed\u4e49\u7406\u89e3\u548c\u7ffb\u8bd1\u8fed\u4ee3\u4f18\u5316\u3002", "result": "\u5728\u4e24\u4e2a\u6570\u636e\u96c6\uff08xCodeEval\u548cHW-Bench\uff09\u548c\u516b\u4e2aLLM\u4e0a\u8bc4\u4f30\uff0cIRENE\u5728\u7ffb\u8bd1\u51c6\u786e\u6027\u548c\u5b89\u5168\u6027\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "IRENE\u901a\u8fc7\u7ed3\u5408\u89c4\u5219\u548c\u8bed\u4e49\uff0c\u663e\u8457\u63d0\u5347\u4e86C\u5230Rust\u4ee3\u7801\u7ffb\u8bd1\u7684\u8d28\u91cf\u548c\u5b89\u5168\u6027\u3002"}}
{"id": "2508.06643", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.06643", "abs": "https://arxiv.org/abs/2508.06643", "authors": ["Joshua Bailey", "Charles Nicholas"], "title": "Symbolic Execution in Practice: A Survey of Applications in Vulnerability, Malware, Firmware, and Protocol Analysis", "comment": "v2: Adds a subsection to Future Directions discussing the role of\n  LLMs in symbolic execution", "summary": "Symbolic execution is a powerful program analysis technique that allows for\nthe systematic exploration of all program paths. Path explosion, where the\nnumber of states to track becomes unwieldy, is one of the biggest challenges\nhindering symbolic execution's practical application. To combat this,\nresearchers have employed various strategies to enable symbolic execution on\ncomplex software systems. This paper introduces a systematic taxonomy of these\nstrategies, categorizing them into two primary approaches: Scope Reduction,\nwhich aims to reduce the scope of symbolic execution to manageable portions of\ncode, and Guidance Heuristics, which steer the symbolic execution engine toward\npromising paths. Using this taxonomy as a lens, we survey applications of\nsymbolic executions in several domains such as vulnerability analysis, malware\nanalysis, firmware re-hosting, and network protocol analysis. Finally, we\nidentify promising directions for future research, including the application of\nsymbolic execution to real-time operating systems and modern, type-safe\nlanguages.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7b26\u53f7\u6267\u884c\u7684\u7cfb\u7edf\u5206\u7c7b\u6cd5\uff0c\u5c06\u5176\u5206\u4e3a\u8303\u56f4\u7f29\u51cf\u548c\u5f15\u5bfc\u542f\u53d1\u5f0f\u4e24\u79cd\u4e3b\u8981\u7b56\u7565\uff0c\u5e76\u63a2\u8ba8\u4e86\u5176\u5728\u591a\u4e2a\u9886\u57df\u7684\u5e94\u7528\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u7b26\u53f7\u6267\u884c\u867d\u5f3a\u5927\uff0c\u4f46\u8def\u5f84\u7206\u70b8\u95ee\u9898\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\uff0c\u56e0\u6b64\u9700\u8981\u7cfb\u7edf\u5206\u7c7b\u548c\u4f18\u5316\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u5206\u7c7b\u6cd5\uff0c\u5c06\u7b56\u7565\u5206\u4e3a\u8303\u56f4\u7f29\u51cf\u548c\u5f15\u5bfc\u542f\u53d1\u5f0f\uff0c\u5e76\u7efc\u8ff0\u5176\u5728\u591a\u4e2a\u9886\u57df\u7684\u5e94\u7528\u3002", "result": "\u5206\u7c7b\u6cd5\u4e3a\u7b26\u53f7\u6267\u884c\u63d0\u4f9b\u4e86\u6e05\u6670\u7684\u4f18\u5316\u65b9\u5411\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "\u672a\u6765\u7814\u7a76\u53ef\u5173\u6ce8\u5b9e\u65f6\u64cd\u4f5c\u7cfb\u7edf\u548c\u7c7b\u578b\u5b89\u5168\u8bed\u8a00\u4e2d\u7684\u7b26\u53f7\u6267\u884c\u5e94\u7528\u3002"}}
{"id": "2508.06559", "categories": ["cs.AI", "cs.GT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.06559", "abs": "https://arxiv.org/abs/2508.06559", "authors": ["Sina Baghal"], "title": "Solving Pasur Using GPU-Accelerated Counterfactual Regret Minimization", "comment": null, "summary": "Pasur is a fishing card game played over six rounds and is played similarly\nto games such as Cassino and Scopa, and Bastra. This paper introduces a\nCUDA-accelerated computational framework for simulating Pasur, emphasizing\nefficient memory management. We use our framework to compute near-Nash\nequilibria via Counterfactual Regret Minimization (CFR), a well-known algorithm\nfor solving large imperfect-information games.\n  Solving Pasur presents unique challenges due to its intricate rules and the\nlarge size of its game tree. We handle rule complexity using PyTorch CUDA\ntensors and to address the memory-intensive nature of the game, we decompose\nthe game tree into two key components: (1) actual game states, and (2)\ninherited scores from previous rounds. We construct the Full Game Tree by\npairing card states with accumulated scores in the Unfolding Process. This\ndesign reduces memory overhead by storing only essential strategy values and\nnode connections. To further manage computational complexity, we apply a\nround-by-round backward training strategy, starting from the final round and\nrecursively propagating average utilities to earlier stages. Our approach\nconstructs the complete game tree, which on average consists of over $10^9$\nnodes. We provide detailed implementation snippets.\n  After computing a near-Nash equilibrium strategy, we train a tree-based model\nto predict these strategies for use during gameplay. We then estimate the fair\nvalue of each deck through large-scale self-play between equilibrium strategies\nby simulating, for instance, 10,000 games per matchup, executed in parallel\nusing GPU acceleration.\n  Similar frameworks can be extended to other reinforcement learning algorithms\nwhere the action tree naturally decomposes into multiple rounds such as\nturn-based strategy games or sequential trading decisions in financial markets.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u57fa\u4e8eCUDA\u52a0\u901f\u7684\u8ba1\u7b97\u6846\u67b6\uff0c\u7528\u4e8e\u6a21\u62dfPasur\u7eb8\u724c\u6e38\u620f\uff0c\u5e76\u901a\u8fc7Counterfactual Regret Minimization\uff08CFR\uff09\u8ba1\u7b97\u8fd1\u7eb3\u4ec0\u5747\u8861\u3002\u6846\u67b6\u901a\u8fc7\u9ad8\u6548\u5185\u5b58\u7ba1\u7406\u548c\u6e38\u620f\u6811\u5206\u89e3\u89e3\u51b3\u4e86\u590d\u6742\u89c4\u5219\u548c\u5927\u89c4\u6a21\u6e38\u620f\u6811\u7684\u6311\u6218\u3002", "motivation": "Pasur\u6e38\u620f\u7684\u590d\u6742\u89c4\u5219\u548c\u5927\u89c4\u6a21\u6e38\u620f\u6811\u5e26\u6765\u4e86\u72ec\u7279\u7684\u8ba1\u7b97\u6311\u6218\uff0c\u9700\u8981\u9ad8\u6548\u7684\u5185\u5b58\u7ba1\u7406\u548c\u8ba1\u7b97\u4f18\u5316\u3002", "method": "\u4f7f\u7528PyTorch CUDA\u5f20\u91cf\u5904\u7406\u89c4\u5219\u590d\u6742\u6027\uff0c\u5c06\u6e38\u620f\u6811\u5206\u89e3\u4e3a\u5b9e\u9645\u6e38\u620f\u72b6\u6001\u548c\u7ee7\u627f\u5206\u6570\uff0c\u5e76\u901a\u8fc7\u9010\u8f6e\u53cd\u5411\u8bad\u7ec3\u7b56\u7565\u7ba1\u7406\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u6784\u5efa\u4e86\u5305\u542b\u8d85\u8fc710^9\u4e2a\u8282\u70b9\u7684\u5b8c\u6574\u6e38\u620f\u6811\uff0c\u5e76\u8bad\u7ec3\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6811\u7684\u6a21\u578b\u6765\u9884\u6d4b\u7b56\u7565\u3002\u901a\u8fc7\u5927\u89c4\u6a21\u81ea\u5bf9\u5f08\u4f30\u8ba1\u6bcf\u526f\u724c\u7684\u516c\u5e73\u4ef7\u503c\u3002", "conclusion": "\u8be5\u6846\u67b6\u53ef\u6269\u5c55\u5230\u5176\u4ed6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u591a\u8f6e\u5206\u89e3\u7684\u52a8\u4f5c\u6811\u573a\u666f\uff0c\u5982\u56de\u5408\u5236\u7b56\u7565\u6e38\u620f\u6216\u91d1\u878d\u5e02\u573a\u4e2d\u7684\u987a\u5e8f\u4ea4\u6613\u51b3\u7b56\u3002"}}
{"id": "2508.06942", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06942", "abs": "https://arxiv.org/abs/2508.06942", "authors": ["Zhenchang Xing", "Yang Liu", "Zhuo Cheng", "Qing Huang", "Dehai Zhao", "Daniel Sun", "Chenhua Liu"], "title": "When Prompt Engineering Meets Software Engineering: CNL-P as Natural and Robust \"APIs'' for Human-AI Interaction", "comment": null, "summary": "With the growing capabilities of large language models (LLMs), they are\nincreasingly applied in areas like intelligent customer service, code\ngeneration, and knowledge management. Natural language (NL) prompts act as the\n``APIs'' for human-LLM interaction. To improve prompt quality, best practices\nfor prompt engineering (PE) have been developed, including writing guidelines\nand templates. Building on this, we propose Controlled NL for Prompt (CNL-P),\nwhich not only incorporates PE best practices but also draws on key principles\nfrom software engineering (SE). CNL-P introduces precise grammar structures and\nstrict semantic norms, further eliminating NL's ambiguity, allowing for a\ndeclarative but structured and accurate expression of user intent. This helps\nLLMs better interpret and execute the prompts, leading to more consistent and\nhigher-quality outputs. We also introduce an NL2CNL-P conversion tool based on\nLLMs, enabling users to write prompts in NL, which are then transformed into\nCNL-P format, thus lowering the learning curve of CNL-P. In particular, we\ndevelop a linting tool that checks CNL-P prompts for syntactic and semantic\naccuracy, applying static analysis techniques to NL for the first time.\nExtensive experiments demonstrate that CNL-P enhances the quality of LLM\nresponses through the novel and organic synergy of PE and SE. We believe that\nCNL-P can bridge the gap between emerging PE and traditional SE, laying the\nfoundation for a new programming paradigm centered around NL.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCNL-P\u7684\u53d7\u63a7\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u63d0\u793a\u5de5\u7a0b\u548c\u8f6f\u4ef6\u5de5\u7a0b\u539f\u5219\uff0c\u4ee5\u51cf\u5c11\u81ea\u7136\u8bed\u8a00\u7684\u6b67\u4e49\u5e76\u63d0\u9ad8LLM\u8f93\u51fa\u7684\u8d28\u91cf\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u80fd\u529b\u7684\u589e\u5f3a\uff0c\u5176\u5728\u667a\u80fd\u5ba2\u670d\u3001\u4ee3\u7801\u751f\u6210\u7b49\u9886\u57df\u7684\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u7684\u6b67\u4e49\u6027\u9650\u5236\u4e86\u5176\u6548\u679c\u3002", "method": "CNL-P\u901a\u8fc7\u5f15\u5165\u7cbe\u786e\u7684\u8bed\u6cd5\u7ed3\u6784\u548c\u4e25\u683c\u7684\u8bed\u4e49\u89c4\u8303\uff0c\u7ed3\u5408\u63d0\u793a\u5de5\u7a0b\u548c\u8f6f\u4ef6\u5de5\u7a0b\u539f\u5219\uff0c\u5e76\u5f00\u53d1\u4e86NL2CNL-P\u8f6c\u6362\u5de5\u5177\u548c\u8bed\u6cd5\u68c0\u67e5\u5de5\u5177\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cCNL-P\u663e\u8457\u63d0\u5347\u4e86LLM\u54cd\u5e94\u7684\u8d28\u91cf\uff0c\u5b9e\u73b0\u4e86\u63d0\u793a\u5de5\u7a0b\u4e0e\u8f6f\u4ef6\u5de5\u7a0b\u7684\u6709\u673a\u878d\u5408\u3002", "conclusion": "CNL-P\u4e3a\u4ee5\u81ea\u7136\u8bed\u8a00\u4e3a\u4e2d\u5fc3\u7684\u65b0\u7f16\u7a0b\u8303\u5f0f\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5f25\u5408\u4e86\u63d0\u793a\u5de5\u7a0b\u4e0e\u4f20\u7edf\u8f6f\u4ef6\u5de5\u7a0b\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2508.06734", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.06734", "abs": "https://arxiv.org/abs/2508.06734", "authors": ["Ngoc N. Tran", "Anwar Said", "Waseem Abbas", "Tyler Derr", "Xenofon D. Koutsoukos"], "title": "Mitigating Distribution Shift in Graph-Based Android Malware Classification via Function Metadata and LLM Embeddings", "comment": "13 pages, 3 figures, 7 tables, under review", "summary": "Graph-based malware classifiers can achieve over 94% accuracy on standard\nAndroid datasets, yet we find they suffer accuracy drops of up to 45% when\nevaluated on previously unseen malware variants from the same family - a\nscenario where strong generalization would typically be expected. This\nhighlights a key limitation in existing approaches: both the model\narchitectures and their structure-only representations often fail to capture\ndeeper semantic patterns. In this work, we propose a robust semantic enrichment\nframework that enhances function call graphs with contextual features,\nincluding function-level metadata and, when available, code embeddings derived\nfrom large language models. The framework is designed to operate under\nreal-world constraints where feature availability is inconsistent, and supports\nflexible integration of semantic signals. To evaluate generalization under\nrealistic domain and temporal shifts, we introduce two new benchmarks:\nMalNet-Tiny-Common and MalNet-Tiny-Distinct, constructed using malware family\npartitioning to simulate cross-family generalization and evolving threat\nbehavior. Experiments across multiple graph neural network backbones show that\nour method improves classification performance by up to 8% under distribution\nshift and consistently enhances robustness when integrated with\nadaptation-based methods. These results offer a practical path toward building\nresilient malware detection systems in evolving threat environments.", "AI": {"tldr": "\u73b0\u6709\u57fa\u4e8e\u56fe\u7684\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u5668\u5728\u6807\u51c6\u6570\u636e\u96c6\u4e0a\u51c6\u786e\u7387\u8d85\u8fc794%\uff0c\u4f46\u5728\u540c\u4e00\u5bb6\u65cf\u672a\u89c1\u53d8\u4f53\u4e0a\u51c6\u786e\u7387\u4e0b\u964d\u9ad8\u8fbe45%\u3002\u672c\u6587\u63d0\u51fa\u8bed\u4e49\u589e\u5f3a\u6846\u67b6\uff0c\u63d0\u5347\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u6a21\u578b\u67b6\u6784\u548c\u7ed3\u6784\u8868\u793a\u4e0a\u672a\u80fd\u6355\u6349\u6df1\u5c42\u8bed\u4e49\u6a21\u5f0f\uff0c\u5bfc\u81f4\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u8bed\u4e49\u589e\u5f3a\u6846\u67b6\uff0c\u7ed3\u5408\u4e0a\u4e0b\u6587\u7279\u5f81\uff08\u5982\u51fd\u6570\u7ea7\u5143\u6570\u636e\u548c\u4ee3\u7801\u5d4c\u5165\uff09\u589e\u5f3a\u51fd\u6570\u8c03\u7528\u56fe\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u63d0\u5347\u5206\u7c7b\u6027\u80fd8%\uff0c\u5e76\u589e\u5f3a\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6784\u5efa\u9002\u5e94\u5a01\u80c1\u73af\u5883\u53d8\u5316\u7684\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\u3002"}}
{"id": "2508.06569", "categories": ["cs.AI", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2508.06569", "abs": "https://arxiv.org/abs/2508.06569", "authors": ["Lance Yao", "Suman Samantray", "Ayana Ghosh", "Kevin Roccapriore", "Libor Kovarik", "Sarah Allec", "Maxim Ziatdinov"], "title": "Operationalizing Serendipity: Multi-Agent AI Workflows for Enhanced Materials Characterization with Theory-in-the-Loop", "comment": null, "summary": "The history of science is punctuated by serendipitous discoveries, where\nunexpected observations, rather than targeted hypotheses, opened new fields of\ninquiry. While modern autonomous laboratories excel at accelerating hypothesis\ntesting, their optimization for efficiency risks overlooking these crucial,\nunplanned findings. To address this gap, we introduce SciLink, an open-source,\nmulti-agent artificial intelligence framework designed to operationalize\nserendipity in materials research by creating a direct, automated link between\nexperimental observation, novelty assessment, and theoretical simulations. The\nframework employs a hybrid AI strategy where specialized machine learning\nmodels perform quantitative analysis of experimental data, while large language\nmodels handle higher-level reasoning. These agents autonomously convert raw\ndata from materials characterization techniques into falsifiable scientific\nclaims, which are then quantitatively scored for novelty against the published\nliterature. We demonstrate the framework's versatility across diverse research\nscenarios, showcasing its application to atomic-resolution and hyperspectral\ndata, its capacity to integrate real-time human expert guidance, and its\nability to close the research loop by proposing targeted follow-up experiments.\nBy systematically analyzing all observations and contextualizing them, SciLink\nprovides a practical framework for AI-driven materials research that not only\nenhances efficiency but also actively cultivates an environment ripe for\nserendipitous discoveries, thereby bridging the gap between automated\nexperimentation and open-ended scientific exploration.", "AI": {"tldr": "SciLink\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u591a\u667a\u80fd\u4f53AI\u6846\u67b6\uff0c\u65e8\u5728\u901a\u8fc7\u81ea\u52a8\u5316\u94fe\u63a5\u5b9e\u9a8c\u89c2\u5bdf\u3001\u65b0\u9896\u6027\u8bc4\u4f30\u548c\u7406\u8bba\u6a21\u62df\uff0c\u5728\u6750\u6599\u7814\u7a76\u4e2d\u5b9e\u73b0\u5076\u7136\u53d1\u73b0\u3002", "motivation": "\u73b0\u4ee3\u81ea\u4e3b\u5b9e\u9a8c\u5ba4\u867d\u80fd\u52a0\u901f\u5047\u8bbe\u9a8c\u8bc1\uff0c\u4f46\u6548\u7387\u4f18\u5316\u53ef\u80fd\u5ffd\u7565\u5076\u7136\u53d1\u73b0\u3002SciLink\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4fc3\u8fdb\u6750\u6599\u7814\u7a76\u4e2d\u7684\u610f\u5916\u53d1\u73b0\u3002", "method": "\u91c7\u7528\u6df7\u5408AI\u7b56\u7565\uff0c\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u5b9a\u91cf\u5206\u6790\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u9ad8\u7ea7\u63a8\u7406\uff0c\u5c06\u539f\u59cb\u6570\u636e\u8f6c\u5316\u4e3a\u53ef\u9a8c\u8bc1\u7684\u79d1\u5b66\u4e3b\u5f20\uff0c\u5e76\u6839\u636e\u6587\u732e\u8bc4\u4f30\u65b0\u9896\u6027\u3002", "result": "SciLink\u5728\u591a\u79cd\u7814\u7a76\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5305\u62ec\u539f\u5b50\u5206\u8fa8\u7387\u548c\u8d85\u5149\u8c31\u6570\u636e\u5206\u6790\uff0c\u5e76\u80fd\u6574\u5408\u5b9e\u65f6\u4e13\u5bb6\u6307\u5bfc\u548c\u63d0\u51fa\u540e\u7eed\u5b9e\u9a8c\u5efa\u8bae\u3002", "conclusion": "SciLink\u4e0d\u4ec5\u63d0\u9ad8\u6548\u7387\uff0c\u8fd8\u4e3b\u52a8\u57f9\u80b2\u5076\u7136\u53d1\u73b0\u7684\u73af\u5883\uff0c\u5f25\u5408\u81ea\u52a8\u5316\u5b9e\u9a8c\u4e0e\u5f00\u653e\u5f0f\u79d1\u5b66\u63a2\u7d22\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2508.07084", "categories": ["cs.SE", "cs.PF"], "pdf": "https://arxiv.org/pdf/2508.07084", "abs": "https://arxiv.org/abs/2508.07084", "authors": ["Kaveh Shahedi", "Nana Gyambrah", "Heng Li", "Maxime Lamothe", "Foutse Khomh"], "title": "An Empirical Study on Method-Level Performance Evolution in Open-Source Java Projects", "comment": null, "summary": "Performance is a critical quality attribute in software development, yet the\nimpact of method-level code changes on performance evolution remains poorly\nunderstood. While developers often make intuitive assumptions about which types\nof modifications are likely to cause performance regressions or improvements,\nthese beliefs lack empirical validation at a fine-grained level. We conducted a\nlarge-scale empirical study analyzing performance evolution in 15 mature\nopen-source Java projects hosted on GitHub. Our analysis encompassed 739\ncommits containing 1,499 method-level code changes, using Java Microbenchmark\nHarness (JMH) for precise performance measurement and rigorous statistical\nanalysis to quantify both the significance and magnitude of performance\nvariations. We employed bytecode instrumentation to capture method-specific\nexecution metrics and systematically analyzed four key aspects: temporal\nperformance patterns, code change type correlations, developer and complexity\nfactors, and domain-size interactions. Our findings reveal that 32.7% of\nmethod-level changes result in measurable performance impacts, with regressions\noccurring 1.3 times more frequently than improvements. Contrary to conventional\nwisdom, we found no significant differences in performance impact distributions\nacross code change categories, challenging risk-stratified development\nstrategies. Algorithmic changes demonstrate the highest improvement potential\nbut carry substantial regression risk. Senior developers produce more stable\nchanges with fewer extreme variations, while code complexity correlates with\nincreased regression likelihood. Domain-size interactions reveal significant\npatterns, with web server + small projects exhibiting the highest performance\ninstability. Our study provides empirical evidence for integrating automated\nperformance testing into continuous integration pipelines.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\u5206\u6790\u4e86Java\u9879\u76ee\u4e2d\u65b9\u6cd5\u7ea7\u4ee3\u7801\u53d8\u66f4\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u53d1\u73b032.7%\u7684\u53d8\u66f4\u4f1a\u5bfc\u81f4\u6027\u80fd\u53d8\u5316\uff0c\u4e14\u6027\u80fd\u9000\u5316\u6bd4\u6539\u8fdb\u66f4\u5e38\u89c1\u3002\u7814\u7a76\u6311\u6218\u4e86\u4f20\u7edf\u89c2\u5ff5\uff0c\u5e76\u63d0\u51fa\u4e86\u81ea\u52a8\u5316\u6027\u80fd\u6d4b\u8bd5\u7684\u5efa\u8bae\u3002", "motivation": "\u6027\u80fd\u662f\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5173\u952e\u8d28\u91cf\u5c5e\u6027\uff0c\u4f46\u65b9\u6cd5\u7ea7\u4ee3\u7801\u53d8\u66f4\u5bf9\u6027\u80fd\u6f14\u5316\u7684\u5f71\u54cd\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u7684\u5b9e\u8bc1\u7814\u7a76\u3002\u5f00\u53d1\u8005\u5e38\u51ed\u76f4\u89c9\u5047\u8bbe\u53d8\u66f4\u7c7b\u578b\u4e0e\u6027\u80fd\u7684\u5173\u7cfb\uff0c\u4f46\u8fd9\u4e9b\u5047\u8bbe\u7f3a\u4e4f\u9a8c\u8bc1\u3002", "method": "\u7814\u7a76\u5206\u6790\u4e8615\u4e2a\u6210\u719f\u5f00\u6e90Java\u9879\u76ee\u7684739\u4e2a\u63d0\u4ea4\u4e2d\u76841,499\u4e2a\u65b9\u6cd5\u7ea7\u53d8\u66f4\uff0c\u4f7f\u7528JMH\u8fdb\u884c\u6027\u80fd\u6d4b\u91cf\u548c\u7edf\u8ba1\u91cf\u5316\uff0c\u5e76\u901a\u8fc7\u5b57\u8282\u7801\u63d2\u6869\u6355\u83b7\u6267\u884c\u6307\u6807\u3002", "result": "32.7%\u7684\u53d8\u66f4\u5bfc\u81f4\u6027\u80fd\u53d8\u5316\uff0c\u6027\u80fd\u9000\u5316\u6bd4\u6539\u8fdb\u591a1.3\u500d\u3002\u7b97\u6cd5\u53d8\u66f4\u6539\u8fdb\u6f5c\u529b\u6700\u5927\u4f46\u98ce\u9669\u4e5f\u9ad8\u3002\u8d44\u6df1\u5f00\u53d1\u8005\u53d8\u66f4\u66f4\u7a33\u5b9a\uff0c\u4ee3\u7801\u590d\u6742\u5ea6\u589e\u52a0\u9000\u5316\u98ce\u9669\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5c06\u81ea\u52a8\u5316\u6027\u80fd\u6d4b\u8bd5\u96c6\u6210\u5230\u6301\u7eed\u96c6\u6210\u6d41\u7a0b\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u4f9d\u636e\uff0c\u5e76\u6311\u6218\u4e86\u4f20\u7edf\u7684\u98ce\u9669\u5206\u5c42\u5f00\u53d1\u7b56\u7565\u3002"}}
{"id": "2508.06789", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.06789", "abs": "https://arxiv.org/abs/2508.06789", "authors": ["Wei Wang", "Xiangyun Tang", "Yajie Wang", "Yijing Lin", "Tao Zhang", "Meng Shen", "Dusit Niyato", "Liehuang Zhu"], "title": "Label Inference Attacks against Federated Unlearning", "comment": null, "summary": "Federated Unlearning (FU) has emerged as a promising solution to respond to\nthe right to be forgotten of clients, by allowing clients to erase their data\nfrom global models without compromising model performance. Unfortunately,\nresearchers find that the parameter variations of models induced by FU expose\nclients' data information, enabling attackers to infer the label of unlearning\ndata, while label inference attacks against FU remain unexplored. In this\npaper, we introduce and analyze a new privacy threat against FU and propose a\nnovel label inference attack, ULIA, which can infer unlearning data labels\nacross three FU levels. To address the unique challenges of inferring labels\nvia the models variations, we design a gradient-label mapping mechanism in ULIA\nthat establishes a relationship between gradient variations and unlearning\nlabels, enabling inferring labels on accumulated model variations. We evaluate\nULIA on both IID and non-IID settings. Experimental results show that in the\nIID setting, ULIA achieves a 100% Attack Success Rate (ASR) under both\nclass-level and client-level unlearning. Even when only 1% of a user's local\ndata is forgotten, ULIA still attains an ASR ranging from 93% to 62.3%.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u8054\u90a6\u9057\u5fd8\uff08FU\uff09\u7684\u65b0\u578b\u6807\u7b7e\u63a8\u65ad\u653b\u51fbULIA\uff0c\u901a\u8fc7\u6a21\u578b\u53c2\u6570\u53d8\u5316\u63a8\u65ad\u9057\u5fd8\u6570\u636e\u7684\u6807\u7b7e\uff0c\u5b9e\u9a8c\u8868\u660e\u653b\u51fb\u6210\u529f\u7387\u9ad8\u8fbe100%\u3002", "motivation": "\u89e3\u51b3\u8054\u90a6\u9057\u5fd8\u4e2d\u6a21\u578b\u53c2\u6570\u53d8\u5316\u66b4\u9732\u7528\u6237\u6570\u636e\u9690\u79c1\u7684\u95ee\u9898\uff0c\u586b\u8865\u6807\u7b7e\u63a8\u65ad\u653b\u51fb\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u8bbe\u8ba1\u4e86\u68af\u5ea6-\u6807\u7b7e\u6620\u5c04\u673a\u5236\uff0c\u901a\u8fc7\u6a21\u578b\u68af\u5ea6\u53d8\u5316\u63a8\u65ad\u9057\u5fd8\u6570\u636e\u7684\u6807\u7b7e\uff0c\u5e76\u5728IID\u548c\u975eIID\u8bbe\u7f6e\u4e0b\u8bc4\u4f30\u3002", "result": "\u5728IID\u8bbe\u7f6e\u4e0b\uff0cULIA\u653b\u51fb\u6210\u529f\u7387\u8fbe100%\uff1b\u5373\u4f7f\u4ec5\u9057\u5fd81%\u6570\u636e\uff0c\u653b\u51fb\u6210\u529f\u7387\u4ecd\u4e3a93%\u81f362.3%\u3002", "conclusion": "ULIA\u653b\u51fb\u63ed\u793a\u4e86\u8054\u90a6\u9057\u5fd8\u4e2d\u7684\u9690\u79c1\u98ce\u9669\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u9632\u5fa1\u63aa\u65bd\u3002"}}
{"id": "2508.06571", "categories": ["cs.AI", "cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2508.06571", "abs": "https://arxiv.org/abs/2508.06571", "authors": ["Anqing Jiang", "Yu Gao", "Yiru Wang", "Zhigang Sun", "Shuo Wang", "Yuwen Heng", "Hao Sun", "Shichen Tang", "Lijuan Zhu", "Jinhao Chai", "Jijun Wang", "Zichong Gu", "Hao Jiang", "Li Sun"], "title": "IRL-VLA: Training an Vision-Language-Action Policy via Reward World Model", "comment": "9 pagres, 2 figures", "summary": "Vision-Language-Action (VLA) models have demonstrated potential in autonomous\ndriving. However, two critical challenges hinder their development: (1)\nExisting VLA architectures are typically based on imitation learning in\nopen-loop setup which tends to capture the recorded behaviors in the dataset,\nleading to suboptimal and constrained performance, (2) Close-loop training\nrelies heavily on high-fidelity sensor simulation, where domain gaps and\ncomputational inefficiencies pose significant barriers. In this paper, we\nintroduce IRL-VLA, a novel close-loop Reinforcement Learning via\n\\textbf{I}nverse \\textbf{R}einforcement \\textbf{L}earning reward world model\nwith a self-built VLA approach. Our framework proceeds in a three-stage\nparadigm: In the first stage, we propose a VLA architecture and pretrain the\nVLA policy via imitation learning. In the second stage, we construct a\nlightweight reward world model via inverse reinforcement learning to enable\nefficient close-loop reward computation. To further enhance planning\nperformance, finally, we design specialized reward world model guidence\nreinforcement learning via PPO(Proximal Policy Optimization) to effectively\nbalance the safety incidents, comfortable driving, and traffic efficiency. Our\napproach achieves state-of-the-art performance in NAVSIM v2 end-to-end driving\nbenchmark, 1st runner up in CVPR2025 Autonomous Grand Challenge. We hope that\nour framework will accelerate VLA research in close-loop autonomous driving.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faIRL-VLA\u6846\u67b6\uff0c\u901a\u8fc7\u9006\u5f3a\u5316\u5b66\u4e60\u5956\u52b1\u4e16\u754c\u6a21\u578b\u548c\u81ea\u5efaVLA\u65b9\u6cd5\u89e3\u51b3\u81ea\u52a8\u9a7e\u9a76\u4e2dVLA\u6a21\u578b\u7684\u95ed\u73af\u8bad\u7ec3\u95ee\u9898\uff0c\u5e76\u5728NAVSIM v2\u548cCVPR2025\u7ade\u8d5b\u4e2d\u53d6\u5f97\u4f18\u5f02\u8868\u73b0\u3002", "motivation": "\u73b0\u6709VLA\u67b6\u6784\u57fa\u4e8e\u5f00\u73af\u6a21\u4eff\u5b66\u4e60\uff0c\u6027\u80fd\u53d7\u9650\uff1b\u95ed\u73af\u8bad\u7ec3\u4f9d\u8d56\u9ad8\u4fdd\u771f\u4f20\u611f\u5668\u6a21\u62df\uff0c\u5b58\u5728\u9886\u57df\u5dee\u8ddd\u548c\u8ba1\u7b97\u6548\u7387\u95ee\u9898\u3002", "method": "\u4e09\u9636\u6bb5\u6846\u67b6\uff1a1) \u9884\u8bad\u7ec3VLA\u7b56\u7565\uff1b2) \u901a\u8fc7\u9006\u5f3a\u5316\u5b66\u4e60\u6784\u5efa\u8f7b\u91cf\u7ea7\u5956\u52b1\u4e16\u754c\u6a21\u578b\uff1b3) \u4f7f\u7528PPO\u4f18\u5316\u5956\u52b1\u6a21\u578b\u6307\u5bfc\u7684\u5f3a\u5316\u5b66\u4e60\u3002", "result": "\u5728NAVSIM v2\u7aef\u5230\u7aef\u9a7e\u9a76\u57fa\u51c6\u548cCVPR2025\u7ade\u8d5b\u4e2d\u53d6\u5f97\u9886\u5148\u8868\u73b0\u3002", "conclusion": "IRL-VLA\u6846\u67b6\u4e3a\u95ed\u73af\u81ea\u52a8\u9a7e\u9a76\u4e2d\u7684VLA\u7814\u7a76\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.07169", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.07169", "abs": "https://arxiv.org/abs/2508.07169", "authors": ["Burak Yeti\u015ftiren", "Hong Jin Kang", "Miryung Kim"], "title": "From Noise to Knowledge: Interactive Summaries for Developer Alerts", "comment": null, "summary": "Programmers using bug-finding tools often review their reported warnings one\nby one. Based on the insight that identifying recurring themes and\nrelationships can enhance the cognitive process of sensemaking, we propose\nCLARITY, which supports interpreting tool-generated warnings through\ninteractive inquiry. CLARITY derives summary rules for custom grouping of\nrelated warnings with active feedback. As users mark warnings as interesting or\nuninteresting, CLARITY's rule inference algorithm surfaces common symptoms,\nhighlighting structural similarities in containment, subtyping, invoked\nmethods, accessed fields, and expressions.\n  We demonstrate CLARITY on Infer and SpotBugs warnings across two mature Java\nprojects. In a within-subject user study with 14 participants, users\narticulated root causes for similar uninteresting warnings faster and with more\nconfidence using CLARITY. We observed significant individual variation in\ndesired grouping, reinforcing the need for customizable sensemaking. Simulation\nshows that with rule-level feedback, only 11.8 interactions are needed on\naverage to align all inferred rules with a simulated user's labels (vs. 17.8\nwithout). Our evaluation suggests that CLARITY's active learning-based\nsummarization enhances interactive warning sensemaking.", "AI": {"tldr": "CLARITY\u662f\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u5de5\u5177\uff0c\u901a\u8fc7\u603b\u7ed3\u89c4\u5219\u548c\u4e3b\u52a8\u53cd\u9988\u5e2e\u52a9\u7a0b\u5e8f\u5458\u66f4\u9ad8\u6548\u5730\u7406\u89e3\u548c\u5206\u7c7b\u9759\u6001\u5206\u6790\u5de5\u5177\u751f\u6210\u7684\u8b66\u544a\u3002", "motivation": "\u7a0b\u5e8f\u5458\u901a\u5e38\u9700\u8981\u9010\u4e2a\u68c0\u67e5\u9759\u6001\u5206\u6790\u5de5\u5177\u751f\u6210\u7684\u8b66\u544a\uff0c\u800c\u8bc6\u522b\u91cd\u590d\u4e3b\u9898\u548c\u5173\u7cfb\u53ef\u4ee5\u63d0\u5347\u8ba4\u77e5\u6548\u7387\u3002", "method": "CLARITY\u901a\u8fc7\u4ea4\u4e92\u5f0f\u67e5\u8be2\u548c\u89c4\u5219\u63a8\u65ad\u7b97\u6cd5\uff0c\u652f\u6301\u7528\u6237\u81ea\u5b9a\u4e49\u5206\u7ec4\u8b66\u544a\uff0c\u5e76\u6839\u636e\u7528\u6237\u53cd\u9988\u52a8\u6001\u8c03\u6574\u89c4\u5219\u3002", "result": "\u5728\u7528\u6237\u7814\u7a76\u4e2d\uff0cCLARITY\u663e\u8457\u63d0\u9ad8\u4e86\u7528\u6237\u8bc6\u522b\u8b66\u544a\u6839\u672c\u539f\u56e0\u7684\u901f\u5ea6\u548c\u4fe1\u5fc3\uff0c\u4e14\u6a21\u62df\u663e\u793a\u5176\u53cd\u9988\u673a\u5236\u51cf\u5c11\u4e86\u6240\u9700\u4ea4\u4e92\u6b21\u6570\u3002", "conclusion": "CLARITY\u901a\u8fc7\u4e3b\u52a8\u5b66\u4e60\u9a71\u52a8\u7684\u603b\u7ed3\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u4e86\u8b66\u544a\u7406\u89e3\u7684\u4ea4\u4e92\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2508.06795", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.06795", "abs": "https://arxiv.org/abs/2508.06795", "authors": ["Jeremiah Blocki", "Blake Holman"], "title": "Towards Practical Data-Dependent Memory-Hard Functions with Optimal Sustained Space Trade-offs in the Parallel Random Oracle Model", "comment": null, "summary": "Memory-Hard Functions (MHF) are a useful cryptographic primitive to build\negalitarian proofs-of-work and to help protect low entropy secrets (e.g., user\npasswords) against brute-forces attacks. Ideally, we would like for a MHF to\nhave the property that (1) an honest party can evaluate the function in\nsequential time $\\Omega(N)$, and (2) any parallel party that evaluates the\nfunction is forced to lockup $\\Omega(N)$ memory for $\\Omega(N)$ sequential\nsteps. Unfortunately, this goal is not quite achievable, so prior work of\nBlocki and Holman [BH22] focused on designing MHFs with strong tradeoff\nguarantees between sustained-space complexity (SSC) and cumulative memory costs\n(CMC). However, their theoretical construction is not suitable for practical\ndeployment due to the reliance on expensive constructions of combinatorial\ngraphs. Furthermore, there is no formal justification for the heuristic use of\nthe dynamic pebbling game in MHF analysis so we cannot rule out the possibility\nthat there are more efficient attacks in the Parallel Random Oracle Model\n(PROM). Towards the goal of developing a practical MHF with provably strong\nSSC/CMC tradeoffs we develop a new MHF called EGSample which does not rely on\nexpensive combinatorial constructions like [BH22]. In the dynamic pebbling\nmodel, we prove equivalent SSC/CMC tradeoffs for EGSample i.e., any the dynamic\npebbling strategy either (1) locks up $\\Omega(N)$ memory for $\\Omega(N)$ steps,\nor (2) incurs cumulative memory cost at least $\\Omega(N^{3-\\epsilon})$. We also\ndevelop new techniques to directly establish SSC/CMC tradeoffs in the parallel\nrandom oracle model. In particular, we prove that {\\em any} PROM algorithm\nevaluating our MHF either (1) locks up $\\Omega(N)$ blocks of memory for\n$\\Omega(N)$ steps or (2) incurs cumulative memory cost at least\n$\\Omega(N^{2.5-\\epsilon})$.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5185\u5b58\u786c\u51fd\u6570\uff08MHF\uff09EGSample\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709MHF\u5728\u5b9e\u8df5\u4e2d\u7684\u4e0d\u8db3\uff0c\u5e76\u63d0\u4f9b\u66f4\u5f3a\u7684SSC/CMC\u6743\u8861\u4fdd\u8bc1\u3002", "motivation": "\u73b0\u6709MHF\u5728\u7406\u8bba\u6784\u9020\u4e0a\u4f9d\u8d56\u6602\u8d35\u7684\u7ec4\u5408\u56fe\uff0c\u4e14\u52a8\u6001\u94fa\u7816\u6e38\u620f\u5728MHF\u5206\u6790\u4e2d\u7684\u542f\u53d1\u5f0f\u4f7f\u7528\u7f3a\u4e4f\u5f62\u5f0f\u5316\u8bc1\u660e\uff0c\u53ef\u80fd\u5bfc\u81f4\u5e76\u884c\u968f\u673a\u9884\u8a00\u6a21\u578b\uff08PROM\uff09\u4e2d\u7684\u9ad8\u6548\u653b\u51fb\u3002", "method": "\u5f00\u53d1\u4e86\u65b0\u7684MHF EGSample\uff0c\u907f\u514d\u4f9d\u8d56\u6602\u8d35\u7684\u7ec4\u5408\u6784\u9020\uff0c\u5e76\u5728\u52a8\u6001\u94fa\u7816\u6a21\u578b\u548cPROM\u4e2d\u8bc1\u660e\u4e86\u5176SSC/CMC\u6743\u8861\u7684\u7b49\u6548\u6027\u3002", "result": "\u5728\u52a8\u6001\u94fa\u7816\u6a21\u578b\u4e2d\uff0cEGSample\u7684SSC/CMC\u6743\u8861\u4e3a\u03a9(N)\u6216\u03a9(N^{3\u2212\u03f5})\uff1b\u5728PROM\u4e2d\uff0c\u6743\u8861\u4e3a\u03a9(N)\u6216\u03a9(N^{2.5\u2212\u03f5})\u3002", "conclusion": "EGSample\u662f\u4e00\u79cd\u5b9e\u7528\u7684MHF\uff0c\u5177\u6709\u53ef\u8bc1\u660e\u7684\u5f3aSSC/CMC\u6743\u8861\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2508.06585", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.06585", "abs": "https://arxiv.org/abs/2508.06585", "authors": ["Jayant Sravan Tamarapalli", "Rynaa Grover", "Nilay Pande", "Sahiti Yerramilli"], "title": "CountQA: How Well Do MLLMs Count in the Wild?", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) demonstrate remarkable fluency in\nunderstanding visual scenes, yet they exhibit a critical lack in a fundamental\ncognitive skill: object counting. This blind spot severely limits their\nreliability in real-world applications. To date, this capability has been\nlargely unevaluated in complex scenarios, as existing benchmarks either feature\nsparse object densities or are confined to specific visual domains, failing to\ntest models under realistic conditions. Addressing this gap, we introduce\nCountQA, a challenging new benchmark designed to probe this deficiency.\nComprising over 1,500 question-answer pairs, CountQA features real-world images\nwith high object density, clutter, and occlusion. We investigate this weakness\nby evaluating 15 prominent MLLMs on the CountQA benchmark and reveal that the\ntop-performing model achieves a mere 42.9% accuracy, with performance declining\nas object counts rise. By providing a dedicated benchmark to diagnose and\nrectify this core weakness, CountQA paves the way for a new generation of MLLMs\nthat are not only descriptively fluent but also numerically grounded and\nspatially aware. We will open-source the dataset and code upon paper acceptance\nto foster further research.", "AI": {"tldr": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u89c6\u89c9\u573a\u666f\u7406\u89e3\u4e0a\u8868\u73b0\u6d41\u7545\uff0c\u4f46\u5728\u5bf9\u8c61\u8ba1\u6570\u80fd\u529b\u4e0a\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\u3002CountQA\u662f\u4e00\u4e2a\u65b0\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u6539\u5584\u8fd9\u4e00\u7f3a\u9677\u3002", "motivation": "\u73b0\u6709MLLMs\u5728\u5bf9\u8c61\u8ba1\u6570\u80fd\u529b\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u3002\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u771f\u5b9e\u53cd\u6620\u590d\u6742\u573a\u666f\u4e0b\u7684\u8ba1\u6570\u80fd\u529b\u3002", "method": "\u5f15\u5165CountQA\u57fa\u51c6\uff0c\u5305\u542b1500\u591a\u4e2a\u95ee\u7b54\u5bf9\uff0c\u6db5\u76d6\u9ad8\u5bc6\u5ea6\u3001\u906e\u6321\u548c\u6742\u4e71\u7684\u73b0\u5b9e\u56fe\u50cf\u3002\u8bc4\u4f30\u4e8615\u79cd\u4e3b\u6d41MLLMs\u3002", "result": "\u8868\u73b0\u6700\u4f73\u7684\u6a21\u578b\u51c6\u786e\u7387\u4ec5\u4e3a42.9%\uff0c\u4e14\u968f\u7740\u5bf9\u8c61\u6570\u91cf\u589e\u52a0\uff0c\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "CountQA\u4e3a\u6539\u8fdbMLLMs\u7684\u8ba1\u6570\u80fd\u529b\u63d0\u4f9b\u4e86\u57fa\u51c6\uff0c\u63a8\u52a8\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2508.07180", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07180", "abs": "https://arxiv.org/abs/2508.07180", "authors": ["Zhe Zhang", "Runlin Liu", "Aishan Liu", "Xingyu Liu", "Xiang Gao", "Hailong Sun"], "title": "Dynamic Benchmark Construction for Evaluating Large Language Models on Real-World Codes", "comment": null, "summary": "As large language models LLMs) become increasingly integrated into software\ndevelopment workflows, rigorously evaluating their performance on complex,\nreal-world code generation tasks has become essential. However, existing\nbenchmarks often suffer from data contamination and limited test rigor,\nconstraining their ability to reveal model failures effectively. To address\nthese, we present CODE2BENCH, a end-to-end pipeline for dynamically\nconstructing robust and contamination-resistant benchmarks from real-world\nGitHub repositories. Specifically, CODE2BENCH introduces three key innovations:\n(1) Automated Dynamism, achieved through periodic ingestion of recent code to\nminimize training data contamination; (2) Scope Graph-based dependency\nanalysis, which enables structured classification of functions into benchmark\ninstances with controlled dependency levels (distinguishing between\nSelf-Contained (SC) tasks for cross-language evaluation and Weakly\nSelf-Contained (WSC) tasks involving permitted library usage); and (3)\nProperty-Based Testing (PBT) for the automated synthesis of rigorous test\nsuites to enable thorough functional verification. Using this pipeline, we\nconstruct CODE2BENCH-2505, the first benchmark derived from 880 recent Python\nprojects spanning diverse domains, comprising 1,163 code generation tasks with\n100% average branch coverage on ground-truth implementations. Extensive\nevaluation of 16 LLMs using CODE2BENCH-2505 reveals that models consistently\nstruggle with SC tasks requiring complex, non-standard logic and cross-language\ntransfer, while showing relatively stronger performance on WSC tasks in Python.\nOur work introduces a contamination-resistant, language-agnostic methodology\nfor dynamic benchmark construction, offering a principled foundation for the\ncomprehensive and realistic evaluation of LLMs on real-world software\ndevelopment tasks.", "AI": {"tldr": "CODE2BENCH\u662f\u4e00\u4e2a\u52a8\u6001\u6784\u5efa\u65e0\u6c61\u67d3\u3001\u9c81\u68d2\u7684\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u7684\u7aef\u5230\u7aef\u7ba1\u9053\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u5b58\u5728\u6570\u636e\u6c61\u67d3\u548c\u6d4b\u8bd5\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u65e0\u6cd5\u6709\u6548\u63ed\u793a\u6a21\u578b\u7f3a\u9677\u3002", "method": "\u901a\u8fc7\u81ea\u52a8\u5316\u52a8\u6001\u66f4\u65b0\u3001\u4f9d\u8d56\u5206\u6790\u548c\u5c5e\u6027\u6d4b\u8bd5\u6784\u5efa\u57fa\u51c6\u3002", "result": "\u8bc4\u4f3016\u4e2aLLMs\u663e\u793a\uff0c\u6a21\u578b\u5728\u590d\u6742\u903b\u8f91\u548c\u8de8\u8bed\u8a00\u4efb\u52a1\u4e0a\u8868\u73b0\u8f83\u5dee\uff0c\u4f46\u5728Python\u5e93\u4efb\u52a1\u4e0a\u8f83\u5f3a\u3002", "conclusion": "CODE2BENCH\u4e3aLLMs\u5728\u771f\u5b9e\u8f6f\u4ef6\u5f00\u53d1\u4efb\u52a1\u4e2d\u7684\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65e0\u6c61\u67d3\u3001\u8bed\u8a00\u65e0\u5173\u7684\u65b9\u6cd5\u3002"}}
{"id": "2508.06837", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.06837", "abs": "https://arxiv.org/abs/2508.06837", "authors": ["Shiqian Zhao", "Chong Wang", "Yiming Li", "Yihao Huang", "Wenjie Qu", "Siew-Kei Lam", "Yi Xie", "Kangjie Chen", "Jie Zhang", "Tianwei Zhang"], "title": "Towards Effective Prompt Stealing Attack against Text-to-Image Diffusion Models", "comment": "This paper proposes an effective training-free, proxy-in-the-loop,\n  and search-based prompt-stealing scheme against T2I models", "summary": "Text-to-Image (T2I) models, represented by DALL$\\cdot$E and Midjourney, have\ngained huge popularity for creating realistic images. The quality of these\nimages relies on the carefully engineered prompts, which have become valuable\nintellectual property. While skilled prompters showcase their AI-generated art\non markets to attract buyers, this business incidentally exposes them to\n\\textit{prompt stealing attacks}. Existing state-of-the-art attack techniques\nreconstruct the prompts from a fixed set of modifiers (i.e., style\ndescriptions) with model-specific training, which exhibit restricted\nadaptability and effectiveness to diverse showcases (i.e., target images) and\ndiffusion models.\n  To alleviate these limitations, we propose Prometheus, a training-free,\nproxy-in-the-loop, search-based prompt-stealing attack, which reverse-engineers\nthe valuable prompts of the showcases by interacting with a local proxy model.\nIt consists of three innovative designs. First, we introduce dynamic modifiers,\nas a supplement to static modifiers used in prior works. These dynamic\nmodifiers provide more details specific to the showcases, and we exploit NLP\nanalysis to generate them on the fly. Second, we design a contextual matching\nalgorithm to sort both dynamic and static modifiers. This offline process helps\nreduce the search space of the subsequent step. Third, we interact with a local\nproxy model to invert the prompts with a greedy search algorithm. Based on the\nfeedback guidance, we refine the prompt to achieve higher fidelity. The\nevaluation results show that Prometheus successfully extracts prompts from\npopular platforms like PromptBase and AIFrog against diverse victim models,\nincluding Midjourney, Leonardo.ai, and DALL$\\cdot$E, with an ASR improvement of\n25.0\\%. We also validate that Prometheus is resistant to extensive potential\ndefenses, further highlighting its severity in practice.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPrometheus\u7684\u8bad\u7ec3\u65e0\u5173\u3001\u57fa\u4e8e\u641c\u7d22\u7684\u63d0\u793a\u7a83\u53d6\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u4fee\u9970\u7b26\u548c\u4e0a\u4e0b\u6587\u5339\u914d\u7b97\u6cd5\uff0c\u6210\u529f\u4ece\u591a\u4e2a\u5e73\u53f0\u63d0\u53d6\u9ad8\u8d28\u91cf\u63d0\u793a\u3002", "motivation": "\u73b0\u6709\u63d0\u793a\u7a83\u53d6\u653b\u51fb\u65b9\u6cd5\u9002\u5e94\u6027\u6709\u9650\uff0c\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u591a\u6837\u5316\u7684\u5c55\u793a\u56fe\u50cf\u548c\u6269\u6563\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u52a8\u6001\u4fee\u9970\u7b26\u8865\u5145\u9759\u6001\u4fee\u9970\u7b26\uff0c\u8bbe\u8ba1\u4e0a\u4e0b\u6587\u5339\u914d\u7b97\u6cd5\u51cf\u5c11\u641c\u7d22\u7a7a\u95f4\uff0c\u5e76\u901a\u8fc7\u672c\u5730\u4ee3\u7406\u6a21\u578b\u8fdb\u884c\u8d2a\u5a6a\u641c\u7d22\u4f18\u5316\u63d0\u793a\u3002", "result": "Prometheus\u5728\u591a\u4e2a\u5e73\u53f0\u4e0a\u6210\u529f\u63d0\u53d6\u63d0\u793a\uff0c\u653b\u51fb\u6210\u529f\u7387\u63d0\u534725.0%\uff0c\u4e14\u5bf9\u6f5c\u5728\u9632\u5fa1\u63aa\u65bd\u5177\u6709\u62b5\u6297\u529b\u3002", "conclusion": "Prometheus\u5c55\u793a\u4e86\u63d0\u793a\u7a83\u53d6\u653b\u51fb\u7684\u5b9e\u9645\u4e25\u91cd\u6027\uff0c\u4e3a\u672a\u6765\u9632\u5fa1\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2508.06668", "categories": ["cs.AI", "cs.IR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.06668", "abs": "https://arxiv.org/abs/2508.06668", "authors": ["Jessie Galasso"], "title": "Formal Concept Analysis: a Structural Framework for Variability Extraction and Analysis", "comment": null, "summary": "Formal Concept Analysis (FCA) is a mathematical framework for knowledge\nrepresentation and discovery. It performs a hierarchical clustering over a set\nof objects described by attributes, resulting in conceptual structures in which\nobjects are organized depending on the attributes they share. These conceptual\nstructures naturally highlight commonalities and variabilities among similar\nobjects by categorizing them into groups which are then arranged by similarity,\nmaking it particularly appropriate for variability extraction and analysis.\nDespite the potential of FCA, determining which of its properties can be\nleveraged for variability-related tasks (and how) is not always\nstraightforward, partly due to the mathematical orientation of its foundational\nliterature. This paper attempts to bridge part of this gap by gathering a\nselection of properties of the framework which are essential to variability\nanalysis, and how they can be used to interpret diverse variability information\nwithin the resulting conceptual structures.", "AI": {"tldr": "\u672c\u6587\u603b\u7ed3\u4e86\u5f62\u5f0f\u6982\u5ff5\u5206\u6790\uff08FCA\uff09\u5728\u53d8\u5f02\u6027\u5206\u6790\u4e2d\u7684\u5173\u952e\u5c5e\u6027\u53ca\u5176\u5e94\u7528\u65b9\u6cd5\u3002", "motivation": "FCA\u5728\u77e5\u8bc6\u8868\u793a\u548c\u53d1\u73b0\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5176\u6570\u5b66\u57fa\u7840\u6587\u732e\u4f7f\u5176\u5728\u53d8\u5f02\u6027\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u4e0d\u591f\u76f4\u89c2\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u7b5b\u9009FCA\u6846\u67b6\u4e2d\u4e0e\u53d8\u5f02\u6027\u5206\u6790\u76f8\u5173\u7684\u5173\u952e\u5c5e\u6027\uff0c\u5e76\u89e3\u91ca\u5176\u5728\u6982\u5ff5\u7ed3\u6784\u4e2d\u7684\u5e94\u7528\u3002", "result": "\u660e\u786e\u4e86FCA\u4e2d\u53ef\u7528\u4e8e\u53d8\u5f02\u6027\u5206\u6790\u7684\u5173\u952e\u5c5e\u6027\u53ca\u5176\u89e3\u91ca\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u4e3aFCA\u5728\u53d8\u5f02\u6027\u5206\u6790\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2508.07198", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.07198", "abs": "https://arxiv.org/abs/2508.07198", "authors": ["Burak Yeti\u015ftiren", "Hong Jin Kang", "Miryung Kim"], "title": "TraceLens: Question-Driven Debugging for Taint Flow Understanding", "comment": null, "summary": "Taint analysis is a security analysis technique used to track the flow of\npotentially dangerous data through an application and its dependent libraries.\nInvestigating why certain unexpected flows appear and why expected flows are\nmissing is an important sensemaking process during end-user taint analysis.\nExisting taint analysis tools often do not provide this end-user debugging\ncapability, where developers can ask why, why-not, and what-if questions about\ndataflows and reason about the impact of configuring sources and sinks, and\nmodels of 3rd-party libraries that abstract permissible and impermissible data\nflows. Furthermore, a tree-view or a list-view used in existing\ntaint-analyzer's visualization makes it difficult to reason about the global\nimpact on connectivity between multiple sources and sinks.\n  Inspired by the insight that sensemaking tool-generated results can be\nsignificantly improved by a QA inquiry process, we propose TraceLens, a first\nend-user question-answer style debugging interface for taint analysis. It\nenables a user to ask why, why-not, and what-if questions to investigate the\nexistence of suspicious flows, the non-existence of expected flows, and the\nglobal impact of third-party library models. TraceLens performs speculative\nwhat-if analysis, to help a user in debugging how different connectivity\nassumptions affect overall results. A user study with 12 participants shows\nthat participants using TraceLens achieved 21% higher accuracy on average,\ncompared to CodeQL. They also reported a 45% reduction in mental demand\n(NASA-TLX) and rated higher confidence in identifying relevant flows using\nTraceLens.", "AI": {"tldr": "TraceLens\u662f\u4e00\u79cd\u65b0\u578b\u7684\u6c61\u70b9\u5206\u6790\u8c03\u8bd5\u5de5\u5177\uff0c\u901a\u8fc7\u95ee\u7b54\u5f0f\u754c\u9762\u5e2e\u52a9\u7528\u6237\u5206\u6790\u6570\u636e\u6d41\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5206\u6790\u51c6\u786e\u6027\u548c\u7528\u6237\u4f53\u9a8c\u3002", "motivation": "\u73b0\u6709\u6c61\u70b9\u5206\u6790\u5de5\u5177\u7f3a\u4e4f\u5bf9\u6570\u636e\u6d41\u95ee\u9898\u7684\u8c03\u8bd5\u80fd\u529b\uff0c\u7528\u6237\u96be\u4ee5\u7406\u89e3\u5f02\u5e38\u6570\u636e\u6d41\u7684\u539f\u56e0\u6216\u7f3a\u5931\u9884\u671f\u6570\u636e\u6d41\u7684\u60c5\u51b5\u3002", "method": "\u63d0\u51faTraceLens\uff0c\u652f\u6301\u7528\u6237\u901a\u8fc7\u95ee\u7b54\u5f62\u5f0f\uff08\u5982\u4e3a\u4ec0\u4e48\u3001\u4e3a\u4ec0\u4e48\u4e0d\u3001\u5047\u8bbe\u95ee\u9898\uff09\u8c03\u8bd5\u6570\u636e\u6d41\uff0c\u5e76\u8fdb\u884c\u5047\u8bbe\u6027\u5206\u6790\u3002", "result": "\u7528\u6237\u7814\u7a76\u8868\u660e\uff0cTraceLens\u6bd4CodeQL\u5e73\u5747\u51c6\u786e\u7387\u63d0\u9ad821%\uff0c\u51cf\u5c1145%\u7684\u8ba4\u77e5\u8d1f\u62c5\uff0c\u5e76\u63d0\u5347\u7528\u6237\u4fe1\u5fc3\u3002", "conclusion": "TraceLens\u901a\u8fc7\u95ee\u7b54\u5f0f\u8c03\u8bd5\u754c\u9762\u663e\u8457\u63d0\u5347\u4e86\u6c61\u70b9\u5206\u6790\u7684\u6548\u679c\u548c\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2508.07053", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.07053", "abs": "https://arxiv.org/abs/2508.07053", "authors": ["Sajib Talukder", "Nur Imtiazul Haque", "Khandakar Ashrafi Akbar"], "title": "SPARE: Securing Progressive Web Applications Against Unauthorized Replications", "comment": "22 pages,12 figures, 3 Tables", "summary": "WebView applications are widely used in mobile applications to display web\ncontent directly within the app, enhancing user engagement by eliminating the\nneed to open an external browser and providing a seamless experience.\nProgressive Web Applications (PWAs) further improve usability by combining the\naccessibility of web apps with the speed, offline capabilities, and\nresponsiveness of native applications. However, malicious developers can\nexploit this technology by duplicating PWA web links to create counterfeit\nnative apps, monetizing through user diversion. This unethical practice poses\nsignificant risks to users and the original application developers,\nunderscoring the need for robust security measures to prevent unauthorized\nreplication. Considering the one-way communication of Trusted Web Activity (a\nmethod for integrating web content into Android applications) and PWAs, we\npropose a query parameter-based practical security solution to defend against\nor mitigate such attacks. We analyze the vulnerabilities of our proposed\nsecurity solution to assess its effectiveness and introduce advanced measures\nto address any identified weaknesses, presenting a comprehensive defense\nframework. As part of our work, we developed a prototype web application that\nsecures PWAs from replication by embedding a combination of Unix timestamps and\ndevice identifiers into the query parameters. We evaluate the effectiveness of\nthis defense strategy by simulating an advanced attack scenario. Additionally,\nwe created a realistic dataset reflecting mobile app user behavior, modeled\nusing a Zipfian distribution, to validate our framework.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u67e5\u8be2\u53c2\u6570\u7684\u5b89\u5168\u89e3\u51b3\u65b9\u6848\uff0c\u9632\u6b62\u6076\u610f\u5f00\u53d1\u8005\u590d\u5236PWA\u94fe\u63a5\u521b\u5efa\u5047\u5192\u539f\u751f\u5e94\u7528\uff0c\u5e76\u901a\u8fc7\u5d4c\u5165Unix\u65f6\u95f4\u6233\u548c\u8bbe\u5907\u6807\u8bc6\u7b26\u6765\u9a8c\u8bc1\u9632\u5fa1\u7b56\u7565\u7684\u6709\u6548\u6027\u3002", "motivation": "WebView\u548cPWA\u6280\u672f\u88ab\u5e7f\u6cdb\u7528\u4e8e\u79fb\u52a8\u5e94\u7528\uff0c\u4f46\u6076\u610f\u5f00\u53d1\u8005\u53ef\u80fd\u5229\u7528\u5176\u521b\u5efa\u5047\u5192\u5e94\u7528\uff0c\u635f\u5bb3\u7528\u6237\u548c\u539f\u5f00\u53d1\u8005\u7684\u5229\u76ca\uff0c\u56e0\u6b64\u9700\u8981\u6709\u6548\u7684\u5b89\u5168\u63aa\u65bd\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u67e5\u8be2\u53c2\u6570\u7684\u5b89\u5168\u65b9\u6848\uff0c\u7ed3\u5408Unix\u65f6\u95f4\u6233\u548c\u8bbe\u5907\u6807\u8bc6\u7b26\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u653b\u51fb\u548cZipfian\u5206\u5e03\u7684\u7528\u6237\u884c\u4e3a\u6570\u636e\u96c6\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "result": "\u5f00\u53d1\u4e86\u539f\u578b\u7cfb\u7edf\uff0c\u9a8c\u8bc1\u4e86\u9632\u5fa1\u7b56\u7565\u5728\u9ad8\u7ea7\u653b\u51fb\u573a\u666f\u4e0b\u7684\u6709\u6548\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u63aa\u65bd\u3002", "conclusion": "\u63d0\u51fa\u7684\u5b89\u5168\u6846\u67b6\u80fd\u6709\u6548\u9632\u6b62PWA\u7684\u975e\u6cd5\u590d\u5236\uff0c\u4e3a\u79fb\u52a8\u5e94\u7528\u5b89\u5168\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.06674", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06674", "abs": "https://arxiv.org/abs/2508.06674", "authors": ["Weijie Shi", "Yue Cui", "Hao Chen", "Jiaming Li", "Mengze Li", "Jia Zhu", "Jiajie Xu", "Xiaofang Zhou"], "title": "Zero-Shot Cellular Trajectory Map Matching", "comment": null, "summary": "Cellular Trajectory Map-Matching (CTMM) aims to align cellular location\nsequences to road networks, which is a necessary preprocessing in\nlocation-based services on web platforms like Google Maps, including navigation\nand route optimization. Current approaches mainly rely on ID-based features and\nregion-specific data to learn correlations between cell towers and roads,\nlimiting their adaptability to unexplored areas. To enable high-accuracy CTMM\nwithout additional training in target regions, Zero-shot CTMM requires to\nextract not only region-adaptive features, but also sequential and location\nuncertainty to alleviate positioning errors in cellular data. In this paper, we\npropose a pixel-based trajectory calibration assistant for zero-shot CTMM,\nwhich takes advantage of transferable geospatial knowledge to calibrate\npixelated trajectory, and then guide the path-finding process at the road\nnetwork level. To enhance knowledge sharing across similar regions, a Gaussian\nmixture model is incorporated into VAE, enabling the identification of\nscenario-adaptive experts through soft clustering. To mitigate high positioning\nerrors, a spatial-temporal awareness module is designed to capture sequential\nfeatures and location uncertainty, thereby facilitating the inference of\napproximate user positions. Finally, a constrained path-finding algorithm is\nemployed to reconstruct the road ID sequence, ensuring topological validity\nwithin the road network. This process is guided by the calibrated trajectory\nwhile optimizing for the shortest feasible path, thus minimizing unnecessary\ndetours. Extensive experiments demonstrate that our model outperforms existing\nmethods in zero-shot CTMM by 16.8\\%.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u50cf\u7d20\u7684\u8f68\u8ff9\u6821\u51c6\u8f85\u52a9\u65b9\u6cd5\uff0c\u7528\u4e8e\u96f6\u6837\u672cCTMM\uff0c\u901a\u8fc7\u8fc1\u79fb\u5730\u7406\u7a7a\u95f4\u77e5\u8bc6\u6821\u51c6\u8f68\u8ff9\uff0c\u5e76\u5728\u8def\u7f51\u5c42\u9762\u5f15\u5bfc\u8def\u5f84\u67e5\u627e\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56ID\u7279\u5f81\u548c\u533a\u57df\u7279\u5b9a\u6570\u636e\uff0c\u9650\u5236\u4e86\u5728\u672a\u63a2\u7d22\u533a\u57df\u7684\u9002\u5e94\u6027\uff0c\u9700\u8981\u4e00\u79cd\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u7684\u9ad8\u7cbe\u5ea6CTMM\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u548cVAE\u63d0\u53d6\u573a\u666f\u81ea\u9002\u5e94\u7279\u5f81\uff0c\u8bbe\u8ba1\u65f6\u7a7a\u611f\u77e5\u6a21\u5757\u6355\u83b7\u5e8f\u5217\u7279\u5f81\u548c\u4f4d\u7f6e\u4e0d\u786e\u5b9a\u6027\uff0c\u4f7f\u7528\u7ea6\u675f\u8def\u5f84\u67e5\u627e\u7b97\u6cd5\u91cd\u5efa\u8def\u7f51ID\u5e8f\u5217\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6a21\u578b\u5728\u96f6\u6837\u672cCTMM\u4e2d\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd516.8%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u77e5\u8bc6\u8fc1\u79fb\u548c\u8def\u5f84\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u96f6\u6837\u672cCTMM\u7684\u51c6\u786e\u6027\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2508.07371", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07371", "abs": "https://arxiv.org/abs/2508.07371", "authors": ["Yi Zhong", "Hongchao Liu", "Di ZHao"], "title": "AutoAssert 1: A LoRA Fine-Tuned LLM Model for Efficient Automated Assertion Generation", "comment": "16pages,6figures", "summary": "As the complexity of software systems continues to increase, the demand for\nautomated testing and maintenance tools is growing exponentially. To meet this\nurgent need, we propose a new assertion generation method based on Hardware\nDescription Language (HDL). This method combines a lightweight,\nparameter-adjustable large language model (LLM) with the Unsloth platform to\nautomatically generate test cases, thereby significantly reducing training\ncosts without sacrificing accuracy or generalization performance. Empirical\nevaluation shows that our method can efficiently generate assertions that\nstrictly conform to the hardware logic. This framework provides a robust and\nflexible solution to modern software testing and maintenance challenges.\nhttps://github.com/liusu-orange/AutoAssert-1 and\nhttps://gitee.com/OpenBPU/auto-assert1 are the locations of the source code.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u786c\u4ef6\u63cf\u8ff0\u8bed\u8a00\uff08HDL\uff09\u7684\u65ad\u8a00\u751f\u6210\u65b9\u6cd5\uff0c\u7ed3\u5408\u8f7b\u91cf\u7ea7\u53ef\u8c03\u53c2\u6570\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u548cUnsloth\u5e73\u53f0\uff0c\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\uff0c\u663e\u8457\u964d\u4f4e\u8bad\u7ec3\u6210\u672c\u4e14\u4e0d\u727a\u7272\u51c6\u786e\u6027\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u7cfb\u7edf\u590d\u6742\u6027\u589e\u52a0\uff0c\u5bf9\u81ea\u52a8\u5316\u6d4b\u8bd5\u548c\u7ef4\u62a4\u5de5\u5177\u7684\u9700\u6c42\u6025\u5267\u589e\u957f\u3002", "method": "\u7ed3\u5408\u8f7b\u91cf\u7ea7\u53ef\u8c03\u53c2\u6570\u7684LLM\u4e0eUnsloth\u5e73\u53f0\uff0c\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u3002", "result": "\u7ecf\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u80fd\u9ad8\u6548\u751f\u6210\u4e25\u683c\u7b26\u5408\u786c\u4ef6\u903b\u8f91\u7684\u65ad\u8a00\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u73b0\u4ee3\u8f6f\u4ef6\u6d4b\u8bd5\u548c\u7ef4\u62a4\u63d0\u4f9b\u4e86\u5f3a\u5927\u800c\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.07094", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.07094", "abs": "https://arxiv.org/abs/2508.07094", "authors": ["Pasquale De Rosa", "Pascal Felber", "Valerio Schiavoni"], "title": "ScamDetect: Towards a Robust, Agnostic Framework to Uncover Threats in Smart Contracts", "comment": null, "summary": "Smart contracts have transformed decentralized finance by enabling\nprogrammable, trustless transactions. However, their widespread adoption and\ngrowing financial significance have attracted persistent and sophisticated\nthreats, such as phishing campaigns and contract-level exploits. Traditional\ntransaction-based threat detection methods often expose sensitive user data and\ninteractions, raising privacy and security concerns. In response, static\nbytecode analysis has emerged as a proactive mitigation strategy, identifying\nmalicious contracts before they execute harmful actions.Building on this\napproach, we introduced PhishingHook, the first machine-learning-based\nframework for detecting phishing activities in smart contracts via static\nbytecode and opcode analysis, achieving approximately 90% detection accuracy.\nNevertheless, two pressing challenges remain: (1) the increasing use of\nsophisticated bytecode obfuscation techniques designed to evade static\nanalysis, and (2) the heterogeneity of blockchain environments requiring\nplatform-agnostic solutions.This paper presents a vision for ScamDetect (Smart\nContract Agnostic Malware Detector), a robust, modular, and platform-agnostic\nframework for smart contract malware detection. Over the next 2.5 years,\nScamDetect will evolve in two stages: first, by tackling obfuscated Ethereum\nVirtual Machine (EVM) bytecode through graph neural network (GNN) analysis of\ncontrol flow graphs (CFGs), leveraging GNNs' ability to capture complex\nstructural patterns beyond opcode sequences; and second, by generalizing\ndetection capabilities to emerging runtimes such as WASM. ScamDetect aims to\nenable proactive, scalable security for the future of decentralized ecosystems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faScamDetect\u6846\u67b6\uff0c\u901a\u8fc7\u9759\u6001\u5b57\u8282\u7801\u5206\u6790\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u68c0\u6d4b\u667a\u80fd\u5408\u7ea6\u4e2d\u7684\u6076\u610f\u884c\u4e3a\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u9762\u4e34\u7684\u6df7\u6dc6\u6280\u672f\u548c\u533a\u5757\u94fe\u73af\u5883\u5f02\u8d28\u6027\u95ee\u9898\u3002", "motivation": "\u667a\u80fd\u5408\u7ea6\u7684\u5e7f\u6cdb\u5e94\u7528\u548c\u91d1\u878d\u91cd\u8981\u6027\u5438\u5f15\u4e86\u590d\u6742\u5a01\u80c1\uff0c\u4f20\u7edf\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u9690\u79c1\u548c\u5b89\u5168\u95ee\u9898\uff0c\u9759\u6001\u5206\u6790\u867d\u6709\u6548\u4f46\u9762\u4e34\u6df7\u6dc6\u6280\u672f\u548c\u73af\u5883\u5f02\u8d28\u6027\u6311\u6218\u3002", "method": "\u5206\u4e24\u9636\u6bb5\u5f00\u53d1ScamDetect\uff1a1. \u4f7f\u7528GNN\u5206\u6790\u63a7\u5236\u6d41\u56fe\uff08CFG\uff09\u68c0\u6d4b\u6df7\u6dc6\u7684EVM\u5b57\u8282\u7801\uff1b2. \u6269\u5c55\u81f3WASM\u7b49\u65b0\u5174\u8fd0\u884c\u65f6\u3002", "result": "PhishingHook\u6846\u67b6\u5df2\u5b9e\u73b0\u7ea690%\u7684\u68c0\u6d4b\u51c6\u786e\u7387\uff0cScamDetect\u65e8\u5728\u8fdb\u4e00\u6b65\u63d0\u5347\u68c0\u6d4b\u80fd\u529b\u3002", "conclusion": "ScamDetect\u65e8\u5728\u4e3a\u53bb\u4e2d\u5fc3\u5316\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e3b\u52a8\u3001\u53ef\u6269\u5c55\u7684\u5b89\u5168\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.06706", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2508.06706", "abs": "https://arxiv.org/abs/2508.06706", "authors": ["Jaikrishna Manojkumar Patil", "Nathaniel Lee", "Al Mehdi Saadat Chowdhury", "YooJung Choi", "Paulo Shakarian"], "title": "Probabilistic Circuits for Knowledge Graph Completion with Reduced Rule Sets", "comment": null, "summary": "Rule-based methods for knowledge graph completion provide explainable results\nbut often require a significantly large number of rules to achieve competitive\nperformance. This can hinder explainability due to overwhelmingly large rule\nsets. We discover rule contexts (meaningful subsets of rules that work\ntogether) from training data and use learned probability distribution (i.e.\nprobabilistic circuits) over these rule contexts to more rapidly achieve\nperformance of the full rule set. Our approach achieves a 70-96% reduction in\nnumber of rules used while outperforming baseline by up to 31$\\times$ when\nusing equivalent minimal number of rules and preserves 91% of peak baseline\nperformance even when comparing our minimal rule sets against baseline's full\nrule sets. We show that our framework is grounded in well-known semantics of\nprobabilistic logic, does not require independence assumptions, and that our\ntractable inference procedure provides both approximate lower bounds and exact\nprobability of a given query. The efficacy of our method is validated by\nempirical studies on 8 standard benchmark datasets where we show competitive\nperformance by using only a fraction of the rules required by AnyBURL's\nstandard inference method, the current state-of-the-art for rule-based\nknowledge graph completion. This work may have further implications for general\nprobabilistic reasoning over learned sets of rules.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c4\u5219\u4e0a\u4e0b\u6587\u548c\u6982\u7387\u7535\u8def\u7684\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u65b9\u6cd5\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u89c4\u5219\u6570\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6027\u80fd\u3002", "motivation": "\u89c4\u5219\u8865\u5168\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u89c4\u5219\u624d\u80fd\u8fbe\u5230\u9ad8\u6027\u80fd\uff0c\u4f46\u8fc7\u591a\u7684\u89c4\u5219\u4f1a\u964d\u4f4e\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u4ece\u8bad\u7ec3\u6570\u636e\u4e2d\u53d1\u73b0\u89c4\u5219\u4e0a\u4e0b\u6587\uff0c\u5e76\u5229\u7528\u6982\u7387\u7535\u8def\u5bf9\u8fd9\u4e9b\u4e0a\u4e0b\u6587\u5efa\u6a21\uff0c\u4ee5\u51cf\u5c11\u89c4\u5219\u6570\u91cf\u5e76\u63d0\u5347\u6027\u80fd\u3002", "result": "\u89c4\u5219\u6570\u91cf\u51cf\u5c1170-96%\uff0c\u6027\u80fd\u63d0\u534731\u500d\uff0c\u4fdd\u7559\u57fa\u7ebf91%\u7684\u5cf0\u503c\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u57288\u4e2a\u6807\u51c6\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u6709\u6548\uff0c\u4e3a\u57fa\u4e8e\u89c4\u5219\u7684\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2508.07486", "categories": ["cs.SE", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.07486", "abs": "https://arxiv.org/abs/2508.07486", "authors": ["Morteza Ziabakhsh", "Kiyan Rezaee", "Sadegh Eskandari", "Seyed Amir Hossein Tabatabaei", "Mohammad M. Ghassemi"], "title": "Extracting Overlapping Microservices from Monolithic Code via Deep Semantic Embeddings and Graph Neural Network-Based Soft Clustering", "comment": null, "summary": "Modern software systems are increasingly shifting from monolithic\narchitectures to microservices to enhance scalability, maintainability, and\ndeployment flexibility. Existing microservice extraction methods typically rely\non hard clustering, assigning each software component to a single microservice.\nThis approach often increases inter-service coupling and reduces intra-service\ncohesion. We propose Mo2oM (Monolithic to Overlapping Microservices), a\nframework that formulates microservice extraction as a soft clustering problem,\nallowing components to belong probabilistically to multiple microservices. This\napproach is inspired by expert-driven decompositions, where practitioners\nintentionally replicate certain software components across services to reduce\ncommunication overhead. Mo2oM combines deep semantic embeddings with structural\ndependencies extracted from methodcall graphs to capture both functional and\narchitectural relationships. A graph neural network-based soft clustering\nalgorithm then generates the final set of microservices. We evaluate Mo2oM on\nfour open-source monolithic benchmarks and compare it against eight\nstate-of-the-art baselines. Our results demonstrate that Mo2oM achieves\nimprovements of up to 40.97% in structural modularity (balancing cohesion and\ncoupling), 58% in inter-service call percentage (communication overhead),\n26.16% in interface number (modularity and decoupling), and 38.96% in\nnon-extreme distribution (service size balance) across all benchmarks.", "AI": {"tldr": "Mo2oM\u6846\u67b6\u901a\u8fc7\u8f6f\u805a\u7c7b\u65b9\u6cd5\u5c06\u5355\u4f53\u67b6\u6784\u8f6c\u6362\u4e3a\u91cd\u53e0\u5fae\u670d\u52a1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7ed3\u6784\u6a21\u5757\u5316\u548c\u901a\u4fe1\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u5fae\u670d\u52a1\u63d0\u53d6\u65b9\u6cd5\u91c7\u7528\u786c\u805a\u7c7b\uff0c\u5bfc\u81f4\u670d\u52a1\u95f4\u8026\u5408\u589e\u52a0\u548c\u670d\u52a1\u5185\u5185\u805a\u964d\u4f4e\uff0cMo2oM\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u6df1\u5ea6\u8bed\u4e49\u5d4c\u5165\u548c\u7ed3\u6784\u4f9d\u8d56\uff0c\u4f7f\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u8f6f\u805a\u7c7b\u7b97\u6cd5\u751f\u6210\u5fae\u670d\u52a1\u3002", "result": "\u5728\u56db\u4e2a\u5f00\u6e90\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMo2oM\u5728\u7ed3\u6784\u6a21\u5757\u5316\u3001\u901a\u4fe1\u5f00\u9500\u3001\u63a5\u53e3\u6570\u91cf\u548c\u670d\u52a1\u89c4\u6a21\u5e73\u8861\u65b9\u9762\u5747\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "Mo2oM\u901a\u8fc7\u8f6f\u805a\u7c7b\u65b9\u6cd5\u6709\u6548\u4f18\u5316\u4e86\u5fae\u670d\u52a1\u63d0\u53d6\uff0c\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002"}}
{"id": "2508.07139", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07139", "abs": "https://arxiv.org/abs/2508.07139", "authors": ["Ivan Zhang"], "title": "A Real-Time, Self-Tuning Moderator Framework for Adversarial Prompt Detection", "comment": "10 pages, 1 figure", "summary": "Ensuring LLM alignment is critical to information security as AI models\nbecome increasingly widespread and integrated in society. Unfortunately, many\ndefenses against adversarial attacks and jailbreaking on LLMs cannot adapt\nquickly to new attacks, degrade model responses to benign prompts, or introduce\nsignificant barriers to scalable implementation. To mitigate these challenges,\nwe introduce a real-time, self-tuning (RTST) moderator framework to defend\nagainst adversarial attacks while maintaining a lightweight training footprint.\nWe empirically evaluate its effectiveness using Google's Gemini models against\nmodern, effective jailbreaks. Our results demonstrate the advantages of an\nadaptive, minimally intrusive framework for jailbreak defense over traditional\nfine-tuning or classifier models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u65f6\u81ea\u8c03\u8282\uff08RTST\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u9632\u5fa1LLM\u7684\u5bf9\u6297\u653b\u51fb\u548c\u8d8a\u72f1\uff0c\u540c\u65f6\u4fdd\u6301\u8f7b\u91cf\u7ea7\u8bad\u7ec3\u3002", "motivation": "\u968f\u7740AI\u6a21\u578b\u5728\u793e\u4f1a\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u786e\u4fddLLM\u7684\u5bf9\u9f50\u6027\u5bf9\u4fe1\u606f\u5b89\u5168\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u96be\u4ee5\u5feb\u901f\u9002\u5e94\u65b0\u653b\u51fb\uff0c\u6216\u4f1a\u964d\u4f4e\u6a21\u578b\u5bf9\u826f\u6027\u63d0\u793a\u7684\u54cd\u5e94\u80fd\u529b\u3002", "method": "\u5f15\u5165\u5b9e\u65f6\u81ea\u8c03\u8282\uff08RTST\uff09\u6846\u67b6\uff0c\u8f7b\u91cf\u7ea7\u8bad\u7ec3\uff0c\u9002\u5e94\u6027\u5f3a\u3002", "result": "\u5728Google\u7684Gemini\u6a21\u578b\u4e0a\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u663e\u793a\u5176\u5bf9\u73b0\u4ee3\u8d8a\u72f1\u653b\u51fb\u7684\u6709\u6548\u9632\u5fa1\u3002", "conclusion": "RTST\u6846\u67b6\u5728\u9632\u5fa1\u8d8a\u72f1\u653b\u51fb\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u7684\u5fae\u8c03\u6216\u5206\u7c7b\u5668\u6a21\u578b\uff0c\u5177\u6709\u9002\u5e94\u6027\u548c\u4f4e\u4fb5\u5165\u6027\u3002"}}
{"id": "2508.06716", "categories": ["cs.AI", "cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2508.06716", "abs": "https://arxiv.org/abs/2508.06716", "authors": ["Blair Johnson", "Clayton Kerce", "Faramarz Fekri"], "title": "GLIDR: Graph-Like Inductive Logic Programming with Differentiable Reasoning", "comment": null, "summary": "Differentiable inductive logic programming (ILP) techniques have proven\neffective at finding approximate rule-based solutions to link prediction and\nnode classification problems on knowledge graphs; however, the common\nassumption of chain-like rule structure can hamper the performance and\ninterpretability of existing approaches. We introduce GLIDR, a differentiable\nrule learning method that models the inference of logic rules with more\nexpressive syntax than previous methods. GLIDR uses a differentiable message\npassing inference algorithm that generalizes previous chain-like rule learning\nmethods to allow rules with features like branches and cycles. GLIDR has a\nsimple and expressive rule search space which is parameterized by a limit on\nthe maximum number of free variables that may be included in a rule. Explicit\nlogic rules can be extracted from the weights of a GLIDR model for use with\nsymbolic solvers. We demonstrate that GLIDR can significantly outperform\nexisting rule learning methods on knowledge graph completion tasks and even\ncompete with embedding methods despite the inherent disadvantage of being a\nstructure-only prediction method. We show that rules extracted from GLIDR\nretain significant predictive performance, and that GLIDR is highly robust to\ntraining data noise. Finally, we demonstrate that GLIDR can be chained with\ndeep neural networks and optimized end-to-end for rule learning on arbitrary\ndata modalities.", "AI": {"tldr": "GLIDR\u662f\u4e00\u79cd\u53ef\u5fae\u5206\u7684\u89c4\u5219\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u66f4\u4e30\u5bcc\u7684\u8bed\u6cd5\u548c\u63a8\u7406\u7b97\u6cd5\u63d0\u5347\u77e5\u8bc6\u56fe\u8c31\u4efb\u52a1\u7684\u6027\u80fd\u4e0e\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u94fe\u5f0f\u89c4\u5219\u7ed3\u6784\u9650\u5236\u4e86\u6027\u80fd\u4e0e\u53ef\u89e3\u91ca\u6027\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u89c4\u5219\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "GLIDR\u4f7f\u7528\u53ef\u5fae\u5206\u6d88\u606f\u4f20\u9012\u63a8\u7406\u7b97\u6cd5\uff0c\u652f\u6301\u5206\u652f\u548c\u5faa\u73af\u7b49\u590d\u6742\u89c4\u5219\u7ed3\u6784\u3002", "result": "GLIDR\u5728\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u751a\u81f3\u53ef\u4e0e\u5d4c\u5165\u65b9\u6cd5\u7ade\u4e89\u3002", "conclusion": "GLIDR\u5177\u6709\u9ad8\u6027\u80fd\u3001\u9c81\u68d2\u6027\uff0c\u5e76\u80fd\u4e0e\u5176\u4ed6\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7ed3\u5408\u8fdb\u884c\u7aef\u5230\u7aef\u4f18\u5316\u3002"}}
{"id": "2508.07881", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.07881", "abs": "https://arxiv.org/abs/2508.07881", "authors": ["Henna Tammia", "Benjamin K\u00e4m\u00e4", "Ella Peltonen"], "title": "Adopting Road-Weather Open Data in Route Recommendation Engine", "comment": null, "summary": "Digitraffic, Finland's open road data interface, provides access to\nnationwide road sensors with more than 2,300 real-time attributes from 1,814\nstations. However, efficiently utilizing such a versatile data API for a\npractical application requires a deeper understanding of the data qualities,\npreprocessing phases, and machine learning tools. This paper discusses the\nchallenges of large-scale road weather and traffic data. We go through the\nroad-weather-related attributes from DigiTraffic as a practical example of\nprocesses required to work with such a dataset. In addition, we provide a\nmethodology for efficient data utilization for the target application, a\npersonalized road recommendation engine based on a simple routing application.\nWe validate our solution based on real-world data, showing we can efficiently\nidentify and recommend personalized routes for three different driver profiles.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u9ad8\u6548\u5229\u7528\u82ac\u5170DigiTraffic\u5f00\u653e\u9053\u8def\u6570\u636e\u63a5\u53e3\u7684\u5927\u89c4\u6a21\u9053\u8def\u5929\u6c14\u548c\u4ea4\u901a\u6570\u636e\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7b80\u5355\u8def\u7531\u5e94\u7528\u7684\u4e2a\u6027\u5316\u9053\u8def\u63a8\u8350\u5f15\u64ce\u65b9\u6cd5\u3002", "motivation": "DigiTraffic\u63d0\u4f9b\u4e86\u5927\u91cf\u5b9e\u65f6\u9053\u8def\u4f20\u611f\u5668\u6570\u636e\uff0c\u4f46\u9ad8\u6548\u5229\u7528\u8fd9\u4e9b\u6570\u636e\u9700\u8981\u6df1\u5165\u7406\u89e3\u6570\u636e\u8d28\u91cf\u3001\u9884\u5904\u7406\u548c\u673a\u5668\u5b66\u4e60\u5de5\u5177\u3002", "method": "\u901a\u8fc7\u5206\u6790DigiTraffic\u7684\u9053\u8def\u5929\u6c14\u76f8\u5173\u5c5e\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u6570\u636e\u5229\u7528\u7684\u65b9\u6cd5\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8e\u7b80\u5355\u8def\u7531\u5e94\u7528\u7684\u4e2a\u6027\u5316\u9053\u8def\u63a8\u8350\u5f15\u64ce\u3002", "result": "\u57fa\u4e8e\u771f\u5b9e\u6570\u636e\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u8bc6\u522b\u5e76\u4e3a\u4e09\u79cd\u4e0d\u540c\u9a7e\u9a76\u8005\u6863\u6848\u63a8\u8350\u4e2a\u6027\u5316\u8def\u7ebf\u3002", "conclusion": "\u7814\u7a76\u5c55\u793a\u4e86\u5982\u4f55\u5229\u7528\u5927\u89c4\u6a21\u9053\u8def\u6570\u636e\u5f00\u53d1\u5b9e\u7528\u5e94\u7528\uff0c\u4e3a\u4e2a\u6027\u5316\u8def\u7ebf\u63a8\u8350\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2508.07190", "categories": ["cs.CR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2508.07190", "abs": "https://arxiv.org/abs/2508.07190", "authors": ["Minfeng Qi", "Qin Wang", "Guangsheng Yu", "Ruiqiang Li", "Victor Zhou", "Shiping Chen"], "title": "Understanding NFTs from EIP Standards", "comment": null, "summary": "We argue that the technical foundations of non-fungible tokens (NFTs) remain\ninadequately understood. Prior research has focused on market dynamics, user\nbehavior, and isolated security incidents, yet systematic analysis of the\nstandards underpinning NFT functionality is largely absent.\n  We present the first study of NFTs through the lens of Ethereum Improvement\nProposals (EIPs). We conduct a large-scale empirical analysis of 191\nNFT-related EIPs and 10K+ Ethereum Magicians discussions (as of July, 2025). We\nintegrate multi-dimensional analyses including the automated parsing of\nSolidity interfaces, graph-based modeling of inheritance structures,\ncontributor profiling, and mining of community discussion data. We distinguish\nfoundational from emerging standards, expose poor cross-version\ninteroperability, and show that growing functional complexity heightens\nsecurity risks.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u901a\u8fc7\u4ee5\u592a\u574a\u6539\u8fdb\u63d0\u6848\uff08EIPs\uff09\u89c6\u89d2\u7cfb\u7edf\u7814\u7a76NFT\u6280\u672f\u57fa\u7840\uff0c\u63ed\u793a\u5176\u6807\u51c6\u95ee\u9898\u4e0e\u5b89\u5168\u98ce\u9669\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8NFT\u5e02\u573a\u52a8\u6001\u548c\u7528\u6237\u884c\u4e3a\uff0c\u7f3a\u4e4f\u5bf9\u5176\u6280\u672f\u6807\u51c6\u7684\u7cfb\u7edf\u6027\u5206\u6790\u3002", "method": "\u5bf9191\u4e2aNFT\u76f8\u5173EIPs\u548c10K+\u793e\u533a\u8ba8\u8bba\u8fdb\u884c\u591a\u7ef4\u5ea6\u5206\u6790\uff0c\u5305\u62ecSolidity\u63a5\u53e3\u89e3\u6790\u3001\u7ee7\u627f\u7ed3\u6784\u5efa\u6a21\u7b49\u3002", "result": "\u53d1\u73b0\u57fa\u7840\u6807\u51c6\u4e0e\u65b0\u5174\u6807\u51c6\u5dee\u5f02\u3001\u8de8\u7248\u672c\u4e92\u64cd\u4f5c\u6027\u5dee\uff0c\u529f\u80fd\u590d\u6742\u6027\u589e\u52a0\u5b89\u5168\u98ce\u9669\u3002", "conclusion": "NFT\u6280\u672f\u57fa\u7840\u4e9f\u9700\u7cfb\u7edf\u6027\u7814\u7a76\uff0c\u4ee5\u5e94\u5bf9\u6807\u51c6\u4e0d\u7edf\u4e00\u548c\u5b89\u5168\u6311\u6218\u3002"}}
{"id": "2508.06736", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.06736", "abs": "https://arxiv.org/abs/2508.06736", "authors": ["Alican Yilmaz", "Junyang Cai", "Serdar Kadioglu", "Bistra Dilkina"], "title": "ParBalans: Parallel Multi-Armed Bandits-based Adaptive Large Neighborhood Search", "comment": null, "summary": "Solving Mixed-Integer Programming (MIP) problems often requires substantial\ncomputational resources due to their combinatorial nature. Parallelization has\nemerged as a critical strategy to accelerate solution times and enhance\nscalability to tackle large, complex instances. This paper investigates the\nparallelization capabilities of Balans, a recently proposed multi-armed\nbandits-based adaptive large neighborhood search for MIPs. While Balans's\nmodular architecture inherently supports parallel exploration of diverse\nparameter configurations, this potential has not been thoroughly examined. To\naddress this gap, we introduce ParBalans, an extension that leverages both\nsolver-level and algorithmic-level parallelism to improve performance on\nchallenging MIP instances. Our experimental results demonstrate that ParBalans\nexhibits competitive performance compared to the state-of-the-art commercial\nsolver Gurobi, particularly on hard optimization benchmarks.", "AI": {"tldr": "ParBalans\u901a\u8fc7\u5e76\u884c\u5316\u6269\u5c55Balans\uff0c\u63d0\u5347\u6df7\u5408\u6574\u6570\u89c4\u5212\u95ee\u9898\u7684\u6c42\u89e3\u6548\u7387\uff0c\u8868\u73b0\u4f18\u4e8e\u5546\u4e1a\u6c42\u89e3\u5668Gurobi\u3002", "motivation": "\u6df7\u5408\u6574\u6570\u89c4\u5212\u95ee\u9898\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u9ad8\uff0c\u5e76\u884c\u5316\u662f\u52a0\u901f\u6c42\u89e3\u7684\u5173\u952e\u7b56\u7565\u3002", "method": "\u63d0\u51faParBalans\uff0c\u7ed3\u5408\u6c42\u89e3\u5668\u7ea7\u548c\u7b97\u6cd5\u7ea7\u5e76\u884c\u5316\uff0c\u4f18\u5316Balans\u7684\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u663e\u793aParBalans\u5728\u590d\u6742\u95ee\u9898\u4e0a\u8868\u73b0\u4f18\u4e8eGurobi\u3002", "conclusion": "ParBalans\u4e3a\u6df7\u5408\u6574\u6570\u89c4\u5212\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u5e76\u884c\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.07935", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.07935", "abs": "https://arxiv.org/abs/2508.07935", "authors": ["Jingwen Zhou", "Jieshan Chen", "Qinghua Lu", "Dehai Zhao", "Liming Zhu"], "title": "SHIELDA: Structured Handling of Exceptions in LLM-Driven Agentic Workflows", "comment": null, "summary": "Large Language Model (LLM) agentic systems are software systems powered by\nLLMs that autonomously reason, plan, and execute multi-step workflows to\nachieve human goals, rather than merely executing predefined steps. During\nexecution, these workflows frequently encounter exceptions. Existing exception\nhandling solutions often treat exceptions superficially, failing to trace\nexecution-phase exceptions to their reasoning-phase root causes. Furthermore,\ntheir recovery logic is brittle, lacking structured escalation pathways when\ninitial attempts fail. To tackle these challenges, we first present a\ncomprehensive taxonomy of 36 exception types across 12 agent artifacts.\nBuilding on this, we propose SHIELDA (Structured Handling of Exceptions in\nLLM-Driven Agentic Workflows), a modular runtime exception handling framework\nfor LLM agentic workflows. SHIELDA uses an exception classifier to select a\npredefined exception handling pattern from a handling pattern registry. These\npatterns are then executed via a structured handling executor, comprising local\nhandling, flow control, and state recovery, to enable phase-aware recovery by\nlinking exceptions to their root causes and facilitating composable strategies.\nWe validate SHIELDA's effectiveness through a case study on the AutoPR agent,\ndemonstrating effective, cross-phase recovery from a reasoning-induced\nexception.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faSHIELDA\u6846\u67b6\uff0c\u7528\u4e8e\u7ed3\u6784\u5316\u5904\u7406LLM\u9a71\u52a8\u7684\u5de5\u4f5c\u6d41\u4e2d\u7684\u5f02\u5e38\uff0c\u901a\u8fc7\u5206\u7c7b\u548c\u6267\u884c\u9884\u5b9a\u4e49\u6a21\u5f0f\u5b9e\u73b0\u8de8\u9636\u6bb5\u6062\u590d\u3002", "motivation": "\u73b0\u6709\u5f02\u5e38\u5904\u7406\u65b9\u6848\u5bf9\u5f02\u5e38\u5904\u7406\u6d45\u663e\u4e14\u6062\u590d\u903b\u8f91\u8106\u5f31\uff0c\u65e0\u6cd5\u8ffd\u8e2a\u5f02\u5e38\u7684\u6839\u672c\u539f\u56e0\u3002", "method": "\u63d0\u51faSHIELDA\u6846\u67b6\uff0c\u5305\u542b\u5f02\u5e38\u5206\u7c7b\u5668\u548c\u7ed3\u6784\u5316\u6267\u884c\u5668\uff0c\u5b9e\u73b0\u5f02\u5e38\u6839\u56e0\u94fe\u63a5\u548c\u53ef\u7ec4\u5408\u7b56\u7565\u3002", "result": "\u901a\u8fc7AutoPR\u4ee3\u7406\u6848\u4f8b\u9a8c\u8bc1SHIELDA\u80fd\u6709\u6548\u5b9e\u73b0\u8de8\u9636\u6bb5\u5f02\u5e38\u6062\u590d\u3002", "conclusion": "SHIELDA\u4e3aLLM\u4ee3\u7406\u5de5\u4f5c\u6d41\u63d0\u4f9b\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u3001\u7ed3\u6784\u5316\u7684\u5f02\u5e38\u5904\u7406\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.07263", "categories": ["cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.07263", "abs": "https://arxiv.org/abs/2508.07263", "authors": ["Qingyuan Zeng", "Shu Jiang", "Jiajing Lin", "Zhenzhong Wang", "Kay Chen Tan", "Min Jiang"], "title": "Fading the Digital Ink: A Universal Black-Box Attack Framework for 3DGS Watermarking Systems", "comment": null, "summary": "With the rise of 3D Gaussian Splatting (3DGS), a variety of digital\nwatermarking techniques, embedding either 1D bitstreams or 2D images, are used\nfor copyright protection. However, the robustness of these watermarking\ntechniques against potential attacks remains underexplored. This paper\nintroduces the first universal black-box attack framework, the Group-based\nMulti-objective Evolutionary Attack (GMEA), designed to challenge these\nwatermarking systems. We formulate the attack as a large-scale multi-objective\noptimization problem, balancing watermark removal with visual quality. In a\nblack-box setting, we introduce an indirect objective function that blinds the\nwatermark detector by minimizing the standard deviation of features extracted\nby a convolutional network, thus rendering the feature maps uninformative. To\nmanage the vast search space of 3DGS models, we employ a group-based\noptimization strategy to partition the model into multiple, independent\nsub-optimization problems. Experiments demonstrate that our framework\neffectively removes both 1D and 2D watermarks from mainstream 3DGS watermarking\nmethods while maintaining high visual fidelity. This work reveals critical\nvulnerabilities in existing 3DGS copyright protection schemes and calls for the\ndevelopment of more robust watermarking systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf93D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u6c34\u5370\u6280\u672f\u7684\u901a\u7528\u9ed1\u76d2\u653b\u51fb\u6846\u67b6GMEA\uff0c\u901a\u8fc7\u591a\u76ee\u6807\u4f18\u5316\u5e73\u8861\u6c34\u5370\u79fb\u9664\u4e0e\u89c6\u89c9\u8d28\u91cf\uff0c\u6210\u529f\u6311\u6218\u73b0\u6709\u6c34\u5370\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u968f\u77403DGS\u6c34\u5370\u6280\u672f\u7684\u666e\u53ca\uff0c\u5176\u5bf9\u6297\u653b\u51fb\u7684\u9c81\u68d2\u6027\u5c1a\u672a\u5145\u5206\u7814\u7a76\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51faGMEA\u6846\u67b6\uff0c\u5c06\u653b\u51fb\u5efa\u6a21\u4e3a\u5927\u89c4\u6a21\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u91c7\u7528\u57fa\u4e8e\u7ec4\u7684\u4f18\u5316\u7b56\u7565\u5904\u74063DGS\u6a21\u578b\u7684\u641c\u7d22\u7a7a\u95f4\u3002", "result": "\u5b9e\u9a8c\u8868\u660eGMEA\u80fd\u6709\u6548\u79fb\u9664\u4e3b\u6d413DGS\u6c34\u5370\u65b9\u6cd5\u4e2d\u76841D\u548c2D\u6c34\u5370\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u89c6\u89c9\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u63ed\u793a\u4e86\u73b0\u67093DGS\u7248\u6743\u4fdd\u62a4\u65b9\u6848\u7684\u8106\u5f31\u6027\uff0c\u547c\u5401\u5f00\u53d1\u66f4\u9c81\u68d2\u7684\u6c34\u5370\u7cfb\u7edf\u3002"}}
{"id": "2508.06746", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06746", "abs": "https://arxiv.org/abs/2508.06746", "authors": ["Xin Tang", "Qian Chen", "Fengshun Li", "Youchun Gong", "Yinqiu Liu", "Wen Tian", "Shaowen Qin", "Xiaohuan Li"], "title": "Topology Generation of UAV Covert Communication Networks: A Graph Diffusion Approach with Incentive Mechanism", "comment": null, "summary": "With the growing demand for Uncrewed Aerial Vehicle (UAV) networks in\nsensitive applications, such as urban monitoring, emergency response, and\nsecure sensing, ensuring reliable connectivity and covert communication has\nbecome increasingly vital. However, dynamic mobility and exposure risks pose\nsignificant challenges. To tackle these challenges, this paper proposes a\nself-organizing UAV network framework combining Graph Diffusion-based Policy\nOptimization (GDPO) with a Stackelberg Game (SG)-based incentive mechanism. The\nGDPO method uses generative AI to dynamically generate sparse but\nwell-connected topologies, enabling flexible adaptation to changing node\ndistributions and Ground User (GU) demands. Meanwhile, the Stackelberg Game\n(SG)-based incentive mechanism guides self-interested UAVs to choose relay\nbehaviors and neighbor links that support cooperation and enhance covert\ncommunication. Extensive experiments are conducted to validate the\neffectiveness of the proposed framework in terms of model convergence, topology\ngeneration quality, and enhancement of covert communication performance.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u56fe\u6269\u6563\u7b56\u7565\u4f18\u5316\uff08GDPO\uff09\u548cStackelberg\u535a\u5f08\uff08SG\uff09\u6fc0\u52b1\u673a\u5236\u7684\u81ea\u7ec4\u7ec7\u65e0\u4eba\u673a\u7f51\u7edc\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3\u52a8\u6001\u79fb\u52a8\u6027\u548c\u66b4\u9732\u98ce\u9669\u5e26\u6765\u7684\u6311\u6218\u3002", "motivation": "\u968f\u7740\u65e0\u4eba\u673a\u7f51\u7edc\u5728\u654f\u611f\u5e94\u7528\u4e2d\u7684\u9700\u6c42\u589e\u957f\uff0c\u786e\u4fdd\u53ef\u9760\u8fde\u63a5\u548c\u9690\u853d\u901a\u4fe1\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u52a8\u6001\u79fb\u52a8\u6027\u548c\u66b4\u9732\u98ce\u9669\u662f\u4e3b\u8981\u6311\u6218\u3002", "method": "\u91c7\u7528GDPO\u65b9\u6cd5\u751f\u6210\u7a00\u758f\u4f46\u8fde\u63a5\u826f\u597d\u7684\u62d3\u6251\u7ed3\u6784\uff0c\u5e76\u7ed3\u5408SG\u6fc0\u52b1\u673a\u5236\u5f15\u5bfc\u65e0\u4eba\u673a\u9009\u62e9\u652f\u6301\u5408\u4f5c\u548c\u9690\u853d\u901a\u4fe1\u7684\u884c\u4e3a\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6846\u67b6\u5728\u6a21\u578b\u6536\u655b\u6027\u3001\u62d3\u6251\u751f\u6210\u8d28\u91cf\u548c\u9690\u853d\u901a\u4fe1\u6027\u80fd\u63d0\u5347\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u6709\u6548\u5e94\u5bf9\u65e0\u4eba\u673a\u7f51\u7edc\u7684\u52a8\u6001\u6027\u548c\u9690\u853d\u901a\u4fe1\u9700\u6c42\u3002"}}
{"id": "2508.07966", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07966", "abs": "https://arxiv.org/abs/2508.07966", "authors": ["Philipp Eibl", "Sadra Sabouri", "Souti Chattopadhyay"], "title": "Exploring the Challenges and Opportunities of AI-assisted Codebase Generation", "comment": null, "summary": "Recent AI code assistants have significantly improved their ability to\nprocess more complex contexts and generate entire codebases based on a textual\ndescription, compared to the popular snippet-level generation. These codebase\nAI assistants (CBAs) can also extend or adapt codebases, allowing users to\nfocus on higher-level design and deployment decisions. While prior work has\nextensively studied the impact of snippet-level code generation, this new class\nof codebase generation models is relatively unexplored. Despite initial\nanecdotal reports of excitement about these agents, they remain less frequently\nadopted compared to snippet-level code assistants. To utilize CBAs better, we\nneed to understand how developers interact with CBAs, and how and why CBAs fall\nshort of developers' needs. In this paper, we explored these gaps through a\ncounterbalanced user study and interview with (n = 16) students and developers\nworking on coding tasks with CBAs. We found that participants varied the\ninformation in their prompts, like problem description (48% of prompts),\nrequired functionality (98% of prompts), code structure (48% of prompts), and\ntheir prompt writing process. Despite various strategies, the overall\nsatisfaction score with generated codebases remained low (mean = 2.8, median =\n3, on a scale of one to five). Participants mentioned functionality as the most\ncommon factor for dissatisfaction (77% of instances), alongside poor code\nquality (42% of instances) and communication issues (25% of instances). We\ndelve deeper into participants' dissatisfaction to identify six underlying\nchallenges that participants faced when using CBAs, and extracted five barriers\nto incorporating CBAs into their workflows. Finally, we surveyed 21 commercial\nCBAs to compare their capabilities with participant challenges and present\ndesign opportunities for more efficient and useful CBAs.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u4ee3\u7801\u5e93AI\u52a9\u624b\uff08CBAs\uff09\u7684\u5f00\u53d1\u8005\u548c\u7528\u6237\u4e92\u52a8\u60c5\u51b5\uff0c\u53d1\u73b0\u5c3d\u7ba1CBAs\u80fd\u751f\u6210\u5b8c\u6574\u4ee3\u7801\u5e93\uff0c\u4f46\u7528\u6237\u6ee1\u610f\u5ea6\u8f83\u4f4e\uff0c\u4e3b\u8981\u95ee\u9898\u5305\u62ec\u529f\u80fd\u4e0d\u8db3\u3001\u4ee3\u7801\u8d28\u91cf\u5dee\u548c\u6c9f\u901a\u95ee\u9898\u3002", "motivation": "\u63a2\u7d22\u5f00\u53d1\u8005\u5982\u4f55\u4e0eCBAs\u4e92\u52a8\uff0c\u4ee5\u53caCBAs\u672a\u80fd\u6ee1\u8db3\u5f00\u53d1\u8005\u9700\u6c42\u7684\u539f\u56e0\uff0c\u4ee5\u6539\u8fdb\u5176\u8bbe\u8ba1\u548c\u5b9e\u7528\u6027\u3002", "method": "\u901a\u8fc7\u7528\u6237\u7814\u7a76\uff08n=16\uff09\u548c\u8bbf\u8c08\uff0c\u5206\u6790\u5f00\u53d1\u8005\u5728\u7f16\u7801\u4efb\u52a1\u4e2d\u4f7f\u7528CBAs\u7684\u884c\u4e3a\u548c\u53cd\u9988\u3002", "result": "\u7528\u6237\u6ee1\u610f\u5ea6\u4f4e\uff08\u5e73\u57472.8\u5206\uff09\uff0c\u4e3b\u8981\u4e0d\u6ee1\u6e90\u4e8e\u529f\u80fd\u4e0d\u8db3\uff0877%\uff09\u3001\u4ee3\u7801\u8d28\u91cf\u5dee\uff0842%\uff09\u548c\u6c9f\u901a\u95ee\u9898\uff0825%\uff09\u3002", "conclusion": "\u63d0\u51fa\u4e86\u516d\u9879CBAs\u9762\u4e34\u7684\u6311\u6218\u548c\u4e94\u9879\u5de5\u4f5c\u6d41\u7a0b\u969c\u788d\uff0c\u5e76\u57fa\u4e8e21\u4e2a\u5546\u4e1aCBAs\u7684\u8c03\u67e5\uff0c\u63d0\u51fa\u4e86\u6539\u8fdb\u8bbe\u8ba1\u7684\u673a\u4f1a\u3002"}}
{"id": "2508.07510", "categories": ["cs.CR", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.07510", "abs": "https://arxiv.org/abs/2508.07510", "authors": ["Hoang-Long Pham", "Duy-Hieu Bui", "Xuan-Tu Tran", "Orazio Aiello"], "title": "SRAM-based Physically Unclonable Function using Lightweight Hamming-Code Fuzzy Extractor for Energy Harvesting Beat Sensors", "comment": null, "summary": "Batteryless energy harvesting IoT sensor nodes such as beat sensors can be\ndeployed in millions without the need to replace batteries. They are\nultra-low-power and cost-effective wireless sensor nodes without the\nmaintenance cost and can work for 24 hours/365 days. However, they were not\nequipped with security mechanisms to protect user data. Data encryption and\nauthentication can be used to secure beat sensor applications, but generating a\nsecure cryptographic key is challenging. In this paper, we proposed an\nSRAM-based Physically Unclonable Function (PUF) combining a high-reliability\nbit selection algorithm with a lightweight error-correcting code to generate\nreliable secure keys for data encryption. The system employs a feature of beat\nsensors, in which the microcontroller is powered on to transmit the ID signals\nand then powered off. This fits the SRAM-based PUF requirement, which needs the\nSRAM to be powered off to read out its random values. The proposed system has\nbeen evaluated on STM32 Cortex M0+ microcontrollers and has been implemented to\nprotect important data on beat sensors.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSRAM\u7684\u7269\u7406\u4e0d\u53ef\u514b\u9686\u51fd\u6570\uff08PUF\uff09\u7ed3\u5408\u9ad8\u53ef\u9760\u6027\u6bd4\u7279\u9009\u62e9\u7b97\u6cd5\u548c\u8f7b\u91cf\u7ea7\u7ea0\u9519\u7801\uff0c\u4e3a\u65e0\u7535\u6c60\u80fd\u91cf\u6536\u96c6\u7269\u8054\u7f51\u4f20\u611f\u5668\u8282\u70b9\uff08\u5982\u5fc3\u8df3\u4f20\u611f\u5668\uff09\u751f\u6210\u53ef\u9760\u7684\u52a0\u5bc6\u5bc6\u94a5\uff0c\u4ee5\u89e3\u51b3\u5176\u7f3a\u4e4f\u5b89\u5168\u673a\u5236\u7684\u95ee\u9898\u3002", "motivation": "\u65e0\u7535\u6c60\u80fd\u91cf\u6536\u96c6\u7269\u8054\u7f51\u4f20\u611f\u5668\u8282\u70b9\uff08\u5982\u5fc3\u8df3\u4f20\u611f\u5668\uff09\u867d\u7136\u6210\u672c\u4f4e\u4e14\u65e0\u9700\u7ef4\u62a4\uff0c\u4f46\u7f3a\u4e4f\u5b89\u5168\u673a\u5236\u4fdd\u62a4\u7528\u6237\u6570\u636e\u3002\u6570\u636e\u52a0\u5bc6\u548c\u8ba4\u8bc1\u9700\u8981\u53ef\u9760\u7684\u52a0\u5bc6\u5bc6\u94a5\uff0c\u4f46\u751f\u6210\u6b64\u7c7b\u5bc6\u94a5\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSRAM\u7684PUF\uff0c\u7ed3\u5408\u9ad8\u53ef\u9760\u6027\u6bd4\u7279\u9009\u62e9\u7b97\u6cd5\u548c\u8f7b\u91cf\u7ea7\u7ea0\u9519\u7801\uff0c\u5229\u7528\u5fc3\u8df3\u4f20\u611f\u5668\u5fae\u63a7\u5236\u5668\u5f00\u5173\u7535\u6e90\u7684\u7279\u6027\uff0c\u6ee1\u8db3SRAM\u65ad\u7535\u8bfb\u53d6\u968f\u673a\u503c\u7684\u8981\u6c42\u3002", "result": "\u7cfb\u7edf\u5df2\u5728STM32 Cortex M0+\u5fae\u63a7\u5236\u5668\u4e0a\u8bc4\u4f30\uff0c\u5e76\u6210\u529f\u5e94\u7528\u4e8e\u4fdd\u62a4\u5fc3\u8df3\u4f20\u611f\u5668\u7684\u91cd\u8981\u6570\u636e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u65e0\u7535\u6c60\u7269\u8054\u7f51\u4f20\u611f\u5668\u8282\u70b9\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u9760\u4e14\u5b89\u5168\u7684\u52a0\u5bc6\u5bc6\u94a5\u751f\u6210\u65b9\u6848\u3002"}}
{"id": "2508.06753", "categories": ["cs.AI", "cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2508.06753", "abs": "https://arxiv.org/abs/2508.06753", "authors": ["Evangelos Georganas", "Dhiraj Kalamkar", "Alexander Heinecke"], "title": "Pushing the Envelope of LLM Inference on AI-PC", "comment": null, "summary": "The advent of ultra-low-bit LLM models (1/1.58/2-bit), which match the\nperplexity and end-task performance of their full-precision counterparts using\nthe same model size, is ushering in a new era of LLM inference for\nresource-constrained environments such as edge devices and AI PCs. While these\nquantization advances promise models that are more cost-effective in terms of\nlatency, memory, throughput, and energy consumption, the computational\nefficiency of state-of-the-art (SOTA) inference runtimes (e.g., bitnet.cpp)\nused to deploy them remains underexplored. In this work, we take a bottom-up\napproach: we first design and implement 1-bit and 2-bit microkernels optimized\nfor modern CPUs, achieving peak computational efficiency across a variety of\nCPU platforms. We integrate these microkernels into a state-of-the-art LLM\ninference framework, namely PyTorch-TPP, and present end-to-end inference\nresults with 2-bit models that outperform the current SOTA runtime bitnet.cpp\nby up to 2.2x, and deliver up to 7x speedup compared to the 16-bit model\ninference. Our optimized runtime advances the state of LLM inference on AI PCs\nand edge devices, paving the way for efficient deployment of ultra-low-bit LLM\nmodels.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u8d85\u4f4e\u6bd4\u7279\uff081/1.58/2-bit\uff09LLM\u6a21\u578b\u7684\u4f18\u5316\u63a8\u7406\u8fd0\u884c\u65f6\uff0c\u901a\u8fc7\u8bbe\u8ba1\u9ad8\u6548\u5fae\u5185\u6838\u5e76\u5728PyTorch-TPP\u6846\u67b6\u4e2d\u5b9e\u73b0\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u8d85\u4f4e\u6bd4\u7279LLM\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\uff08\u5982\u8fb9\u7f18\u8bbe\u5907\u548cAI PC\uff09\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u73b0\u6709\u63a8\u7406\u8fd0\u884c\u65f6\u7684\u8ba1\u7b97\u6548\u7387\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u9488\u5bf9\u73b0\u4ee3CPU\u4f18\u5316\u76841-bit\u548c2-bit\u5fae\u5185\u6838\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u5230PyTorch-TPP\u6846\u67b6\u4e2d\u3002", "result": "2-bit\u6a21\u578b\u63a8\u7406\u6027\u80fd\u6bd4\u5f53\u524dSOTA\u8fd0\u884c\u65f6bitnet.cpp\u5feb2.2\u500d\uff0c\u6bd416-bit\u6a21\u578b\u63a8\u7406\u5feb7\u500d\u3002", "conclusion": "\u4f18\u5316\u540e\u7684\u8fd0\u884c\u65f6\u4e3a\u8d85\u4f4e\u6bd4\u7279LLM\u6a21\u578b\u7684\u9ad8\u6548\u90e8\u7f72\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u9002\u7528\u4e8eAI PC\u548c\u8fb9\u7f18\u8bbe\u5907\u3002"}}
{"id": "2508.08171", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08171", "abs": "https://arxiv.org/abs/2508.08171", "authors": ["Pedro Orvalho", "Marta Kwiatkowska"], "title": "PyVeritas: On Verifying Python via LLM-Based Transpilation and Bounded Model Checking for C", "comment": "14 pages, 6 tables, 1 figure", "summary": "Python has become the dominant language for general-purpose programming, yet\nit lacks robust tools for formal verification. In contrast, programmers working\nin languages such as C benefit from mature model checkers, for example CBMC,\nwhich enable exhaustive symbolic reasoning and fault localisation. The inherent\ncomplexity of Python, coupled with the verbosity and low-level nature of\nexisting transpilers (e.g., Cython), have historically limited the\napplicability of formal verification to Python programs.\n  In this paper, we propose PyVeritas, a novel framework that leverages Large\nLanguage Models (LLMs) for high-level transpilation from Python to C, followed\nby bounded model checking and MaxSAT-based fault localisation in the generated\nC code. PyVeritas enables verification and bug localisation for Python code\nusing existing model checking tools for C. Our empirical evaluation on two\nPython benchmarks demonstrates that LLM-based transpilation can achieve a high\ndegree of accuracy, up to 80--90% for some LLMs, enabling effective development\nenvironment that supports assertion-based verification and interpretable fault\ndiagnosis for small yet non-trivial Python programs.", "AI": {"tldr": "PyVeritas\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5c06Python\u4ee3\u7801\u8f6c\u6362\u4e3aC\u4ee3\u7801\uff0c\u7ed3\u5408\u6a21\u578b\u68c0\u67e5\u548cMaxSAT\u6280\u672f\uff0c\u5b9e\u73b0\u4e86Python\u7a0b\u5e8f\u7684\u9a8c\u8bc1\u548c\u9519\u8bef\u5b9a\u4f4d\u3002", "motivation": "Python\u7f3a\u4e4f\u6210\u719f\u7684\u6b63\u5f0f\u9a8c\u8bc1\u5de5\u5177\uff0c\u800cC\u8bed\u8a00\u5df2\u6709\u6210\u719f\u7684\u6a21\u578b\u68c0\u67e5\u5de5\u5177\uff08\u5982CBMC\uff09\u3002PyVeritas\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u5229\u7528LLMs\u5b9e\u73b0\u9ad8\u6548\u7684\u4ee3\u7801\u8f6c\u6362\u548c\u9a8c\u8bc1\u3002", "method": "\u901a\u8fc7LLMs\u5c06Python\u4ee3\u7801\u8f6c\u6362\u4e3aC\u4ee3\u7801\uff0c\u7136\u540e\u4f7f\u7528\u8fb9\u754c\u6a21\u578b\u68c0\u67e5\u548cMaxSAT\u6280\u672f\u8fdb\u884c\u9a8c\u8bc1\u548c\u9519\u8bef\u5b9a\u4f4d\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cLLM\u8f6c\u6362\u7684\u51c6\u786e\u7387\u53ef\u8fbe80-90%\uff0c\u652f\u6301\u5bf9\u5c0f\u578bPython\u7a0b\u5e8f\u7684\u65ad\u8a00\u9a8c\u8bc1\u548c\u9519\u8bef\u8bca\u65ad\u3002", "conclusion": "PyVeritas\u4e3aPython\u7a0b\u5e8f\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u6b63\u5f0f\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u586b\u8865\u4e86\u73b0\u6709\u5de5\u5177\u7684\u4e0d\u8db3\u3002"}}
{"id": "2508.07745", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.07745", "abs": "https://arxiv.org/abs/2508.07745", "authors": ["Jiongchi Yu", "Xiaofei Xie", "Qiang Hu", "Yuhan Ma", "Ziming Zhao"], "title": "Chimera: Harnessing Multi-Agent LLMs for Automatic Insider Threat Simulation", "comment": "23 pages", "summary": "Insider threats, which can lead to severe losses, remain a major security\nconcern. While machine learning-based insider threat detection (ITD) methods\nhave shown promising results, their progress is hindered by the scarcity of\nhigh-quality data. Enterprise data is sensitive and rarely accessible, while\npublicly available datasets, when limited in scale due to cost, lack sufficient\nreal-world coverage; and when purely synthetic, they fail to capture rich\nsemantics and realistic user behavior. To address this, we propose Chimera, the\nfirst large language model (LLM)-based multi-agent framework that automatically\nsimulates both benign and malicious insider activities and collects diverse\nlogs across diverse enterprise environments. Chimera models each employee with\nagents that have role-specific behavior and integrates modules for group\nmeetings, pairwise interactions, and autonomous scheduling, capturing realistic\norganizational dynamics. It incorporates 15 types of insider attacks (e.g., IP\ntheft, system sabotage) and has been deployed to simulate activities in three\nsensitive domains: technology company, finance corporation, and medical\ninstitution, producing a new dataset, ChimeraLog. We assess ChimeraLog via\nhuman studies and quantitative analysis, confirming its diversity, realism, and\npresence of explainable threat patterns. Evaluations of existing ITD methods\nshow an average F1-score of 0.83, which is significantly lower than 0.99 on the\nCERT dataset, demonstrating ChimeraLog's higher difficulty and utility for\nadvancing ITD research.", "AI": {"tldr": "\u63d0\u51faChimera\u6846\u67b6\uff0c\u5229\u7528LLM\u591a\u4ee3\u7406\u6a21\u62df\u4f01\u4e1a\u5185\u5916\u90e8\u884c\u4e3a\uff0c\u751f\u6210\u9ad8\u8d28\u91cf\u6570\u636e\u96c6ChimeraLog\uff0c\u63d0\u5347\u5185\u90e8\u5a01\u80c1\u68c0\u6d4b\u7814\u7a76\u3002", "motivation": "\u89e3\u51b3\u5185\u90e8\u5a01\u80c1\u68c0\u6d4b\u7814\u7a76\u4e2d\u9ad8\u8d28\u91cf\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\uff0c\u73b0\u6709\u516c\u5f00\u6570\u636e\u96c6\u89c4\u6a21\u6709\u9650\u6216\u7f3a\u4e4f\u771f\u5b9e\u8bed\u4e49\u3002", "method": "\u91c7\u7528\u57fa\u4e8eLLM\u7684\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u6a21\u62df\u5458\u5de5\u89d2\u8272\u884c\u4e3a\uff0c\u96c6\u6210\u4f1a\u8bae\u3001\u4e92\u52a8\u548c\u8c03\u5ea6\u6a21\u5757\uff0c\u8986\u76d615\u79cd\u653b\u51fb\u7c7b\u578b\u3002", "result": "\u751f\u6210\u6570\u636e\u96c6ChimeraLog\uff0c\u7ecf\u8bc4\u4f30\u663e\u793a\u591a\u6837\u6027\u548c\u771f\u5b9e\u6027\uff0c\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5F1\u5206\u6570\u663e\u8457\u4f4e\u4e8eCERT\u6570\u636e\u96c6\u3002", "conclusion": "ChimeraLog\u4e3a\u5185\u90e8\u5a01\u80c1\u68c0\u6d4b\u7814\u7a76\u63d0\u4f9b\u4e86\u66f4\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u652f\u6301\uff0c\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u7684\u8fdb\u5c55\u3002"}}
{"id": "2508.06754", "categories": ["cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2508.06754", "abs": "https://arxiv.org/abs/2508.06754", "authors": ["Vanessa Figueiredo"], "title": "A Fuzzy Logic Prompting Framework for Large Language Models in Adaptive and Uncertain Tasks", "comment": null, "summary": "We introduce a modular prompting framework that supports safer and more\nadaptive use of large language models (LLMs) across dynamic, user-centered\ntasks. Grounded in human learning theory, particularly the Zone of Proximal\nDevelopment (ZPD), our method combines a natural language boundary prompt with\na control schema encoded with fuzzy scaffolding logic and adaptation rules.\nThis architecture enables LLMs to modulate behavior in response to user state\nwithout requiring fine-tuning or external orchestration. In a simulated\nintelligent tutoring setting, the framework improves scaffolding quality,\nadaptivity, and instructional alignment across multiple models, outperforming\nstandard prompting baselines. Evaluation is conducted using rubric-based LLM\ngraders at scale. While initially developed for education, the framework has\nshown promise in other interaction-heavy domains, such as procedural content\ngeneration for games. Designed for safe deployment, it provides a reusable\nmethodology for structuring interpretable, goal-aligned LLM behavior in\nuncertain or evolving contexts.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u63d0\u793a\u6846\u67b6\uff0c\u652f\u6301\u5728\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e2d\u66f4\u5b89\u5168\u3001\u66f4\u81ea\u9002\u5e94\u5730\u5904\u7406\u52a8\u6001\u7528\u6237\u4efb\u52a1\u3002", "motivation": "\u57fa\u4e8e\u4eba\u7c7b\u5b66\u4e60\u7406\u8bba\uff08\u5982\u6700\u8fd1\u53d1\u5c55\u533aZPD\uff09\uff0c\u65e8\u5728\u63d0\u5347LLMs\u5728\u52a8\u6001\u4efb\u52a1\u4e2d\u7684\u9002\u5e94\u6027\u548c\u5b89\u5168\u6027\u3002", "method": "\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u8fb9\u754c\u63d0\u793a\u4e0e\u63a7\u5236\u6a21\u5f0f\uff0c\u91c7\u7528\u6a21\u7cca\u652f\u67b6\u903b\u8f91\u548c\u9002\u5e94\u89c4\u5219\uff0c\u65e0\u9700\u5fae\u8c03\u6216\u5916\u90e8\u534f\u8c03\u3002", "result": "\u5728\u6a21\u62df\u667a\u80fd\u8f85\u5bfc\u73af\u5883\u4e2d\uff0c\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u652f\u67b6\u8d28\u91cf\u3001\u9002\u5e94\u6027\u548c\u6559\u5b66\u5bf9\u9f50\u6027\uff0c\u4f18\u4e8e\u6807\u51c6\u63d0\u793a\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u9002\u7528\u4e8e\u6559\u80b2\u9886\u57df\uff0c\u8fd8\u53ef\u6269\u5c55\u5230\u5176\u4ed6\u4ea4\u4e92\u5bc6\u96c6\u578b\u4efb\u52a1\uff0c\u4e3a\u4e0d\u786e\u5b9a\u6216\u52a8\u6001\u573a\u666f\u4e2d\u7684LLM\u884c\u4e3a\u63d0\u4f9b\u4e86\u53ef\u91cd\u7528\u65b9\u6cd5\u3002"}}
{"id": "2508.07840", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.07840", "abs": "https://arxiv.org/abs/2508.07840", "authors": ["Mohsin Khan", "Dag Johansen", "H\u00e5vard Dagenborg"], "title": "A Comparative Analysis of Lightweight Hash Functions Using AVR ATXMega128 and ChipWhisperer", "comment": "16 pages, 9 figures, and 2 tables", "summary": "Lightweight hash functions have become important building blocks for security\nin embedded and IoT systems. A plethora of algorithms have been proposed and\nstandardized, providing a wide range of performance trade-off options for\ndevelopers to choose from. This paper presents a comparative analysis of 22 key\nsoftware-based lightweight hash functions, including the finalist from the\nSHA-3 competition. We use a novel benchmark methodology that combines an AVR\nATXMega128 microcontroller with the ChipWhisperer cryptanalysis platform and\nevaluate and compare the various hash functions along several dimensions,\nincluding execution speed, % measured in Cycles per Byte (CpB), memory\nfootprint, and energy consumption. Using the composite E-RANK metric, we\nprovide new insight into the various trade-offs each hash function offers to\nsystem developers.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e8622\u79cd\u8f7b\u91cf\u7ea7\u54c8\u5e0c\u51fd\u6570\u7684\u6027\u80fd\uff0c\u5305\u62ecSHA-3\u51b3\u8d5b\u7b97\u6cd5\uff0c\u4f7f\u7528AVR\u5fae\u63a7\u5236\u5668\u548cChipWhisperer\u5e73\u53f0\u8bc4\u4f30\u901f\u5ea6\u3001\u5185\u5b58\u5360\u7528\u548c\u80fd\u8017\u3002", "motivation": "\u8f7b\u91cf\u7ea7\u54c8\u5e0c\u51fd\u6570\u5728\u5d4c\u5165\u5f0f\u7cfb\u7edf\u548c\u7269\u8054\u7f51\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7f3a\u4e4f\u5168\u9762\u7684\u6027\u80fd\u6bd4\u8f83\u3002", "method": "\u91c7\u7528AVR ATXMega128\u5fae\u63a7\u5236\u5668\u548cChipWhisperer\u5e73\u53f0\uff0c\u7ed3\u5408E-RANK\u6307\u6807\uff0c\u8bc4\u4f30\u54c8\u5e0c\u51fd\u6570\u7684\u901f\u5ea6\u3001\u5185\u5b58\u548c\u80fd\u8017\u3002", "result": "\u63d0\u4f9b\u4e86\u5404\u54c8\u5e0c\u51fd\u6570\u5728\u901f\u5ea6\u3001\u5185\u5b58\u548c\u80fd\u8017\u65b9\u9762\u7684\u8be6\u7ec6\u6bd4\u8f83\u6570\u636e\u3002", "conclusion": "\u901a\u8fc7E-RANK\u6307\u6807\uff0c\u4e3a\u5f00\u53d1\u8005\u9009\u62e9\u54c8\u5e0c\u51fd\u6570\u63d0\u4f9b\u4e86\u65b0\u7684\u6743\u8861\u89c6\u89d2\u3002"}}
{"id": "2508.06823", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06823", "abs": "https://arxiv.org/abs/2508.06823", "authors": ["Xuan Zhao", "Jun Tao"], "title": "Natural Language-Driven Viewpoint Navigation for Volume Exploration via Semantic Block Representation", "comment": "Accepted by IEEE VIS 2025", "summary": "Exploring volumetric data is crucial for interpreting scientific datasets.\nHowever, selecting optimal viewpoints for effective navigation can be\nchallenging, particularly for users without extensive domain expertise or\nfamiliarity with 3D navigation. In this paper, we propose a novel framework\nthat leverages natural language interaction to enhance volumetric data\nexploration. Our approach encodes volumetric blocks to capture and\ndifferentiate underlying structures. It further incorporates a CLIP Score\nmechanism, which provides semantic information to the blocks to guide\nnavigation. The navigation is empowered by a reinforcement learning framework\nthat leverage these semantic cues to efficiently search for and identify\ndesired viewpoints that align with the user's intent. The selected viewpoints\nare evaluated using CLIP Score to ensure that they best reflect the user\nqueries. By automating viewpoint selection, our method improves the efficiency\nof volumetric data navigation and enhances the interpretability of complex\nscientific phenomena.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316\u4f53\u6570\u636e\u63a2\u7d22\u4e2d\u7684\u89c6\u70b9\u9009\u62e9\uff0c\u7ed3\u5408CLIP Score\u548c\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u5bfc\u822a\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f53\u6570\u636e\u63a2\u7d22\u5bf9\u79d1\u5b66\u6570\u636e\u96c6\u89e3\u91ca\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7f3a\u4e4f\u9886\u57df\u77e5\u8bc6\u62163D\u5bfc\u822a\u7ecf\u9a8c\u7684\u7528\u6237\u96be\u4ee5\u9009\u62e9\u6700\u4f73\u89c6\u70b9\u3002", "method": "\u6846\u67b6\u5c06\u4f53\u6570\u636e\u5757\u7f16\u7801\u4ee5\u533a\u5206\u7ed3\u6784\uff0c\u7ed3\u5408CLIP Score\u63d0\u4f9b\u8bed\u4e49\u4fe1\u606f\uff0c\u5e76\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u641c\u7d22\u7b26\u5408\u7528\u6237\u610f\u56fe\u7684\u89c6\u70b9\u3002", "result": "\u81ea\u52a8\u5316\u89c6\u70b9\u9009\u62e9\u63d0\u9ad8\u4e86\u4f53\u6570\u636e\u5bfc\u822a\u6548\u7387\uff0c\u5e76\u589e\u5f3a\u4e86\u590d\u6742\u79d1\u5b66\u73b0\u8c61\u7684\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u548c\u8bed\u4e49\u5f15\u5bfc\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u6539\u5584\u4e86\u4f53\u6570\u636e\u63a2\u7d22\u7684\u6548\u7387\u548c\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2508.07468", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.07468", "abs": "https://arxiv.org/abs/2508.07468", "authors": ["Stefan Szeider"], "title": "CP-Agent: Agentic Constraint Programming", "comment": null, "summary": "Translating natural language problem descriptions into formal constraint\nmodels remains a fundamental challenge in constraint programming, requiring\ndeep expertise in both the problem domain and modeling frameworks. Previous\napproaches to automating this translation have employed fixed workflows with\npredetermined modeling steps, failing on a significant number of benchmark\nproblems. We present a new approach using a pure agentic strategy without any\nfixed pipeline. We developed a general-purpose Python coding agent based on the\nReAct (Reason and Act) principle, utilizing a persistent IPython kernel for\nstateful code execution and iterative development. Rather than embedding\nconstraint programming logic into the agent architecture, domain-specific\nexpertise is injected solely through a carefully crafted project prompt. The\nagent combines this prompt-encoded knowledge with access to file operations and\ncode execution tools, enabling it to test hypotheses, debug failures, and\nverify solutions dynamically. Implemented in just a few hundred lines of code,\nthis architecture successfully solves all 101 problems of the CP-Bench\nconstraint programming benchmark set. The results suggest that constraint\nmodeling tasks require the combination of general coding tools and domain\nexpertise encoded in prompts, rather than specialized agent architectures or\npredefined workflows.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7eaf\u4ee3\u7406\u7b56\u7565\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u5c06\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u63cf\u8ff0\u8f6c\u5316\u4e3a\u5f62\u5f0f\u5316\u7ea6\u675f\u6a21\u578b\uff0c\u65e0\u9700\u56fa\u5b9a\u6d41\u7a0b\uff0c\u6210\u529f\u89e3\u51b3\u4e86CP-Bench\u57fa\u51c6\u96c6\u4e2d\u7684\u6240\u6709\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f7f\u7528\u56fa\u5b9a\u6d41\u7a0b\uff0c\u65e0\u6cd5\u89e3\u51b3\u5927\u91cf\u57fa\u51c6\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u7075\u6d3b\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u57fa\u4e8eReAct\u539f\u5219\u7684\u901a\u7528Python\u7f16\u7801\u4ee3\u7406\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u9879\u76ee\u63d0\u793a\u6ce8\u5165\u9886\u57df\u77e5\u8bc6\uff0c\u7ed3\u5408\u6587\u4ef6\u64cd\u4f5c\u548c\u4ee3\u7801\u6267\u884c\u5de5\u5177\u52a8\u6001\u6d4b\u8bd5\u548c\u8c03\u8bd5\u3002", "result": "\u8be5\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86CP-Bench\u57fa\u51c6\u96c6\u4e2d\u7684\u5168\u90e8101\u4e2a\u95ee\u9898\u3002", "conclusion": "\u7ea6\u675f\u5efa\u6a21\u4efb\u52a1\u9700\u8981\u7ed3\u5408\u901a\u7528\u7f16\u7801\u5de5\u5177\u548c\u63d0\u793a\u7f16\u7801\u7684\u9886\u57df\u77e5\u8bc6\uff0c\u800c\u975e\u4e13\u7528\u4ee3\u7406\u67b6\u6784\u6216\u9884\u5b9a\u4e49\u6d41\u7a0b\u3002"}}
{"id": "2508.07873", "categories": ["cs.CR", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.07873", "abs": "https://arxiv.org/abs/2508.07873", "authors": ["Samaneh Mohammadi", "Vasileios Tsouvalas", "Iraklis Symeonidis", "Ali Balador", "Tanir Ozcelebi", "Francesco Flammini", "Nirvana Meratnia"], "title": "EFU: Enforcing Federated Unlearning via Functional Encryption", "comment": null, "summary": "Federated unlearning (FU) algorithms allow clients in federated settings to\nexercise their ''right to be forgotten'' by removing the influence of their\ndata from a collaboratively trained model. Existing FU methods maintain data\nprivacy by performing unlearning locally on the client-side and sending\ntargeted updates to the server without exposing forgotten data; yet they often\nrely on server-side cooperation, revealing the client's intent and identity\nwithout enforcement guarantees - compromising autonomy and unlearning privacy.\nIn this work, we propose EFU (Enforced Federated Unlearning), a\ncryptographically enforced FU framework that enables clients to initiate\nunlearning while concealing its occurrence from the server. Specifically, EFU\nleverages functional encryption to bind encrypted updates to specific\naggregation functions, ensuring the server can neither perform unauthorized\ncomputations nor detect or skip unlearning requests. To further mask behavioral\nand parameter shifts in the aggregated model, we incorporate auxiliary\nunlearning losses based on adversarial examples and parameter importance\nregularization. Extensive experiments show that EFU achieves near-random\naccuracy on forgotten data while maintaining performance comparable to full\nretraining across datasets and neural architectures - all while concealing\nunlearning intent from the server. Furthermore, we demonstrate that EFU is\nagnostic to the underlying unlearning algorithm, enabling secure,\nfunction-hiding, and verifiable unlearning for any client-side FU mechanism\nthat issues targeted updates.", "AI": {"tldr": "EFU\u662f\u4e00\u4e2a\u52a0\u5bc6\u5f3a\u5236\u7684\u8054\u90a6\u9057\u5fd8\u6846\u67b6\uff0c\u5141\u8bb8\u5ba2\u6237\u7aef\u5728\u4e0d\u66b4\u9732\u9057\u5fd8\u610f\u56fe\u7684\u60c5\u51b5\u4e0b\u4ece\u534f\u4f5c\u8bad\u7ec3\u6a21\u578b\u4e2d\u79fb\u9664\u5176\u6570\u636e\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u9057\u5fd8\u65b9\u6cd5\u4f9d\u8d56\u670d\u52a1\u5668\u7aef\u5408\u4f5c\uff0c\u53ef\u80fd\u6cc4\u9732\u5ba2\u6237\u610f\u56fe\u548c\u8eab\u4efd\uff0c\u635f\u5bb3\u9690\u79c1\u548c\u81ea\u4e3b\u6027\u3002", "method": "EFU\u5229\u7528\u529f\u80fd\u52a0\u5bc6\u7ed1\u5b9a\u52a0\u5bc6\u66f4\u65b0\u5230\u7279\u5b9a\u805a\u5408\u51fd\u6570\uff0c\u9632\u6b62\u670d\u52a1\u5668\u68c0\u6d4b\u6216\u8df3\u8fc7\u9057\u5fd8\u8bf7\u6c42\uff0c\u5e76\u7ed3\u5408\u5bf9\u6297\u6837\u672c\u548c\u53c2\u6570\u91cd\u8981\u6027\u6b63\u5219\u5316\u63a9\u76d6\u884c\u4e3a\u53d8\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cEFU\u5728\u9057\u5fd8\u6570\u636e\u4e0a\u63a5\u8fd1\u968f\u673a\u51c6\u786e\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u5b8c\u5168\u91cd\u65b0\u8bad\u7ec3\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u4e14\u9690\u85cf\u9057\u5fd8\u610f\u56fe\u3002", "conclusion": "EFU\u662f\u4e00\u79cd\u901a\u7528\u3001\u5b89\u5168\u4e14\u53ef\u9a8c\u8bc1\u7684\u8054\u90a6\u9057\u5fd8\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u4efb\u4f55\u5ba2\u6237\u7aef\u9057\u5fd8\u673a\u5236\u3002"}}
{"id": "2508.06832", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06832", "abs": "https://arxiv.org/abs/2508.06832", "authors": ["Haifeng Li", "Wang Guo", "Haiyang Wu", "Mengwei Wu", "Jipeng Zhang", "Qing Zhu", "Yu Liu", "Xin Huang", "Chao Tao"], "title": "Remote Sensing Image Intelligent Interpretation with the Language-Centered Perspective: Principles, Methods and Challenges", "comment": null, "summary": "The mainstream paradigm of remote sensing image interpretation has long been\ndominated by vision-centered models, which rely on visual features for semantic\nunderstanding. However, these models face inherent limitations in handling\nmulti-modal reasoning, semantic abstraction, and interactive decision-making.\nWhile recent advances have introduced Large Language Models (LLMs) into remote\nsensing workflows, existing studies primarily focus on downstream applications,\nlacking a unified theoretical framework that explains the cognitive role of\nlanguage. This review advocates a paradigm shift from vision-centered to\nlanguage-centered remote sensing interpretation. Drawing inspiration from the\nGlobal Workspace Theory (GWT) of human cognition, We propose a\nlanguage-centered framework for remote sensing interpretation that treats LLMs\nas the cognitive central hub integrating perceptual, task, knowledge and action\nspaces to enable unified understanding, reasoning, and decision-making. We\nfirst explore the potential of LLMs as the central cognitive component in\nremote sensing interpretation, and then summarize core technical challenges,\nincluding unified multimodal representation, knowledge association, and\nreasoning and decision-making. Furthermore, we construct a global\nworkspace-driven interpretation mechanism and review how language-centered\nsolutions address each challenge. Finally, we outline future research\ndirections from four perspectives: adaptive alignment of multimodal data, task\nunderstanding under dynamic knowledge constraints, trustworthy reasoning, and\nautonomous interaction. This work aims to provide a conceptual foundation for\nthe next generation of remote sensing interpretation systems and establish a\nroadmap toward cognition-driven intelligent geospatial analysis.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4ece\u89c6\u89c9\u4e2d\u5fc3\u8f6c\u5411\u8bed\u8a00\u4e2d\u5fc3\u7684\u9065\u611f\u56fe\u50cf\u89e3\u91ca\u8303\u5f0f\uff0c\u501f\u9274\u5168\u7403\u5de5\u4f5c\u7a7a\u95f4\u7406\u8bba\uff0c\u4ee5\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e3a\u6838\u5fc3\uff0c\u6574\u5408\u611f\u77e5\u3001\u4efb\u52a1\u3001\u77e5\u8bc6\u548c\u884c\u52a8\u7a7a\u95f4\uff0c\u5b9e\u73b0\u7edf\u4e00\u7406\u89e3\u3001\u63a8\u7406\u548c\u51b3\u7b56\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9\u4e2d\u5fc3\u6a21\u578b\u5728\u591a\u6a21\u6001\u63a8\u7406\u3001\u8bed\u4e49\u62bd\u8c61\u548c\u4ea4\u4e92\u51b3\u7b56\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7406\u8bba\u6846\u67b6\u89e3\u91ca\u8bed\u8a00\u5728\u8ba4\u77e5\u4e2d\u7684\u4f5c\u7528\u3002", "method": "\u63d0\u51fa\u8bed\u8a00\u4e2d\u5fc3\u6846\u67b6\uff0c\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8ba4\u77e5\u4e2d\u67a2\uff0c\u6574\u5408\u591a\u6a21\u6001\u8868\u793a\u3001\u77e5\u8bc6\u5173\u8054\u53ca\u63a8\u7406\u51b3\u7b56\uff0c\u6784\u5efa\u5168\u5c40\u5de5\u4f5c\u7a7a\u95f4\u9a71\u52a8\u7684\u89e3\u91ca\u673a\u5236\u3002", "result": "\u603b\u7ed3\u4e86\u8bed\u8a00\u4e2d\u5fc3\u89e3\u51b3\u65b9\u6848\u5982\u4f55\u5e94\u5bf9\u591a\u6a21\u6001\u7edf\u4e00\u8868\u793a\u3001\u77e5\u8bc6\u5173\u8054\u548c\u63a8\u7406\u51b3\u7b56\u7b49\u6838\u5fc3\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u4e3a\u4e0b\u4e00\u4ee3\u9065\u611f\u89e3\u91ca\u7cfb\u7edf\u63d0\u4f9b\u6982\u5ff5\u57fa\u7840\uff0c\u5efa\u7acb\u8ba4\u77e5\u9a71\u52a8\u667a\u80fd\u5730\u7406\u7a7a\u95f4\u5206\u6790\u7684\u8def\u7ebf\u56fe\u3002"}}
{"id": "2508.08029", "categories": ["cs.CR", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.08029", "abs": "https://arxiv.org/abs/2508.08029", "authors": ["Thusitha Dayaratne", "Ngoc Duy Pham", "Viet Vo", "Shangqi Lai", "Sharif Abuadbba", "Hajime Suzuki", "Xingliang Yuan", "Carsten Rudolph"], "title": "Robust Anomaly Detection in O-RAN: Leveraging LLMs against Data Manipulation Attacks", "comment": null, "summary": "The introduction of 5G and the Open Radio Access Network (O-RAN) architecture\nhas enabled more flexible and intelligent network deployments. However, the\nincreased complexity and openness of these architectures also introduce novel\nsecurity challenges, such as data manipulation attacks on the semi-standardised\nShared Data Layer (SDL) within the O-RAN platform through malicious xApps. In\nparticular, malicious xApps can exploit this vulnerability by introducing\nsubtle Unicode-wise alterations (hypoglyphs) into the data that are being used\nby traditional machine learning (ML)-based anomaly detection methods. These\nUnicode-wise manipulations can potentially bypass detection and cause failures\nin anomaly detection systems based on traditional ML, such as AutoEncoders,\nwhich are unable to process hypoglyphed data without crashing. We investigate\nthe use of Large Language Models (LLMs) for anomaly detection within the O-RAN\narchitecture to address this challenge. We demonstrate that LLM-based xApps\nmaintain robust operational performance and are capable of processing\nmanipulated messages without crashing. While initial detection accuracy\nrequires further improvements, our results highlight the robustness of LLMs to\nadversarial attacks such as hypoglyphs in input data. There is potential to use\ntheir adaptability through prompt engineering to further improve the accuracy,\nalthough this requires further research. Additionally, we show that LLMs\nachieve low detection latency (under 0.07 seconds), making them suitable for\nNear-Real-Time (Near-RT) RIC deployments.", "AI": {"tldr": "5G\u548cO-RAN\u67b6\u6784\u7684\u7075\u6d3b\u6027\u5e26\u6765\u4e86\u65b0\u7684\u5b89\u5168\u6311\u6218\uff0c\u5982\u6076\u610fxApps\u901a\u8fc7Unicode\u7be1\u6539\u6570\u636e\u653b\u51fbSDL\u3002\u4f20\u7edfML\u65b9\u6cd5\u6613\u53d7\u653b\u51fb\u5d29\u6e83\uff0c\u800cLLMs\u80fd\u7a33\u5065\u5904\u7406\u7be1\u6539\u6570\u636e\u4e14\u5ef6\u8fdf\u4f4e\uff0c\u9002\u5408Near-RT RIC\u90e8\u7f72\u3002", "motivation": "5G\u548cO-RAN\u67b6\u6784\u7684\u5f00\u653e\u6027\u548c\u590d\u6742\u6027\u5f15\u5165\u4e86\u65b0\u7684\u5b89\u5168\u5a01\u80c1\uff0c\u5982\u6076\u610fxApps\u5bf9SDL\u7684\u6570\u636e\u7be1\u6539\u653b\u51fb\uff0c\u4f20\u7edfML\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u3002", "method": "\u7814\u7a76\u4f7f\u7528LLMs\u8fdb\u884c\u5f02\u5e38\u68c0\u6d4b\uff0c\u8bc4\u4f30\u5176\u5728\u5904\u7406\u7be1\u6539\u6570\u636e\u65f6\u7684\u7a33\u5065\u6027\u548c\u5ef6\u8fdf\u8868\u73b0\u3002", "result": "LLMs\u80fd\u7a33\u5065\u5904\u7406\u7be1\u6539\u6570\u636e\u4e14\u5ef6\u8fdf\u4f4e\uff08<0.07\u79d2\uff09\uff0c\u9002\u5408Near-RT RIC\u90e8\u7f72\uff0c\u4f46\u521d\u59cb\u68c0\u6d4b\u7cbe\u5ea6\u9700\u63d0\u5347\u3002", "conclusion": "LLMs\u5728\u5bf9\u6297Unicode\u7be1\u6539\u653b\u51fb\u4e2d\u8868\u73b0\u7a33\u5065\uff0c\u9002\u5408O-RAN\u67b6\u6784\uff0c\u672a\u6765\u53ef\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u8fdb\u4e00\u6b65\u63d0\u5347\u7cbe\u5ea6\u3002"}}
{"id": "2508.06836", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06836", "abs": "https://arxiv.org/abs/2508.06836", "authors": ["Xutong Zhao", "Yaqi Xie"], "title": "Multi-level Advantage Credit Assignment for Cooperative Multi-Agent Reinforcement Learning", "comment": "Accepted at AISTATS 2025", "summary": "Cooperative multi-agent reinforcement learning (MARL) aims to coordinate\nmultiple agents to achieve a common goal. A key challenge in MARL is credit\nassignment, which involves assessing each agent's contribution to the shared\nreward. Given the diversity of tasks, agents may perform different types of\ncoordination, with rewards attributed to diverse and often overlapping agent\nsubsets. In this work, we formalize the credit assignment level as the number\nof agents cooperating to obtain a reward, and address scenarios with multiple\ncoexisting levels. We introduce a multi-level advantage formulation that\nperforms explicit counterfactual reasoning to infer credits across distinct\nlevels. Our method, Multi-level Advantage Credit Assignment (MACA), captures\nagent contributions at multiple levels by integrating advantage functions that\nreason about individual, joint, and correlated actions. Utilizing an\nattention-based framework, MACA identifies correlated agent relationships and\nconstructs multi-level advantages to guide policy learning. Comprehensive\nexperiments on challenging Starcraft v1\\&v2 tasks demonstrate MACA's superior\nperformance, underscoring its efficacy in complex credit assignment scenarios.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u7ea7\u4f18\u52bf\u4fe1\u7528\u5206\u914d\u65b9\u6cd5\uff08MACA\uff09\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u4fe1\u7528\u5206\u914d\u95ee\u9898\uff0c\u901a\u8fc7\u591a\u7ea7\u4f18\u52bf\u51fd\u6570\u548c\u6ce8\u610f\u529b\u673a\u5236\u6355\u6349\u4e0d\u540c\u5c42\u6b21\u7684\u667a\u80fd\u4f53\u8d21\u732e\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u4fe1\u7528\u5206\u914d\u7684\u6311\u6218\u5728\u4e8e\u5982\u4f55\u8bc4\u4f30\u6bcf\u4e2a\u667a\u80fd\u4f53\u5bf9\u5171\u4eab\u5956\u52b1\u7684\u8d21\u732e\uff0c\u5c24\u5176\u662f\u5728\u4efb\u52a1\u591a\u6837\u6027\u548c\u667a\u80fd\u4f53\u534f\u4f5c\u5c42\u6b21\u4e0d\u540c\u7684\u60c5\u51b5\u4e0b\u3002", "method": "MACA\u65b9\u6cd5\u901a\u8fc7\u591a\u7ea7\u4f18\u52bf\u516c\u5f0f\u8fdb\u884c\u663e\u5f0f\u53cd\u4e8b\u5b9e\u63a8\u7406\uff0c\u7ed3\u5408\u6ce8\u610f\u529b\u6846\u67b6\u8bc6\u522b\u667a\u80fd\u4f53\u76f8\u5173\u6027\uff0c\u6784\u5efa\u591a\u7ea7\u4f18\u52bf\u51fd\u6570\u6307\u5bfc\u7b56\u7565\u5b66\u4e60\u3002", "result": "\u5728Starcraft v1&v2\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMACA\u5728\u590d\u6742\u4fe1\u7528\u5206\u914d\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "MACA\u901a\u8fc7\u591a\u7ea7\u4f18\u52bf\u4fe1\u7528\u5206\u914d\u6709\u6548\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u4e2d\u7684\u4fe1\u7528\u5206\u914d\u95ee\u9898\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u534f\u4f5c\u5c42\u6b21\u7684\u4efb\u52a1\u3002"}}
{"id": "2508.08031", "categories": ["cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.08031", "abs": "https://arxiv.org/abs/2508.08031", "authors": ["Jiayao Wang", "Yang Song", "Zhendong Zhao", "Jiale Zhang", "Qilin Wu", "Junwu Zhu", "Dongfang Zhao"], "title": "IPBA: Imperceptible Perturbation Backdoor Attack in Federated Self-Supervised Learning", "comment": null, "summary": "Federated self-supervised learning (FSSL) combines the advantages of\ndecentralized modeling and unlabeled representation learning, serving as a\ncutting-edge paradigm with strong potential for scalability and privacy\npreservation. Although FSSL has garnered increasing attention, research\nindicates that it remains vulnerable to backdoor attacks. Existing methods\ngenerally rely on visually obvious triggers, which makes it difficult to meet\nthe requirements for stealth and practicality in real-world deployment. In this\npaper, we propose an imperceptible and effective backdoor attack method against\nFSSL, called IPBA. Our empirical study reveals that existing imperceptible\ntriggers face a series of challenges in FSSL, particularly limited\ntransferability, feature entanglement with augmented samples, and\nout-of-distribution properties. These issues collectively undermine the\neffectiveness and stealthiness of traditional backdoor attacks in FSSL. To\novercome these challenges, IPBA decouples the feature distributions of backdoor\nand augmented samples, and introduces Sliced-Wasserstein distance to mitigate\nthe out-of-distribution properties of backdoor samples, thereby optimizing the\ntrigger generation process. Our experimental results on several FSSL scenarios\nand datasets show that IPBA significantly outperforms existing backdoor attack\nmethods in performance and exhibits strong robustness under various defense\nmechanisms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u8054\u90a6\u81ea\u76d1\u7763\u5b66\u4e60\uff08FSSL\uff09\u7684\u9690\u853d\u4e14\u6709\u6548\u7684\u540e\u95e8\u653b\u51fb\u65b9\u6cd5IPBA\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u9690\u853d\u6027\u548c\u5b9e\u7528\u6027\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "FSSL\u7ed3\u5408\u4e86\u53bb\u4e2d\u5fc3\u5316\u5efa\u6a21\u548c\u65e0\u76d1\u7763\u8868\u793a\u5b66\u4e60\u7684\u4f18\u52bf\uff0c\u4f46\u7814\u7a76\u8868\u660e\u5176\u6613\u53d7\u540e\u95e8\u653b\u51fb\uff0c\u73b0\u6709\u65b9\u6cd5\u9690\u853d\u6027\u4e0d\u8db3\u3002", "method": "IPBA\u901a\u8fc7\u89e3\u8026\u540e\u95e8\u6837\u672c\u548c\u589e\u5f3a\u6837\u672c\u7684\u7279\u5f81\u5206\u5e03\uff0c\u5e76\u5f15\u5165Sliced-Wasserstein\u8ddd\u79bb\u4f18\u5316\u89e6\u53d1\u751f\u6210\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cIPBA\u5728\u591a\u4e2aFSSL\u573a\u666f\u548c\u6570\u636e\u96c6\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u540e\u95e8\u653b\u51fb\u65b9\u6cd5\uff0c\u4e14\u5bf9\u5404\u79cd\u9632\u5fa1\u673a\u5236\u8868\u73b0\u51fa\u5f3a\u9c81\u68d2\u6027\u3002", "conclusion": "IPBA\u4e3aFSSL\u4e2d\u7684\u540e\u95e8\u653b\u51fb\u63d0\u4f9b\u4e86\u66f4\u9690\u853d\u548c\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.06851", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.06851", "abs": "https://arxiv.org/abs/2508.06851", "authors": ["Pengfei Zhou", "Xiaopeng Peng", "Fanrui Zhang", "Zhaopan Xu", "Jiaxin Ai", "Yansheng Qiu", "Chuanhao Li", "Zhen Li", "Ming Li", "Yukang Feng", "Jianwen Sun", "Haoquan Zhang", "Zizhen Li", "Xiaofeng Mao", "Zekai Li", "Wangbo Zhao", "Kai Wang", "Xiaojun Chang", "Wenqi Shao", "Yang You", "Kaipeng Zhang"], "title": "MDK12-Bench: A Comprehensive Evaluation of Multimodal Large Language Models on Multidisciplinary Exams", "comment": "35 pages, 33 figures", "summary": "Multimodal large language models (MLLMs), which integrate language and visual\ncues for problem-solving, are crucial for advancing artificial general\nintelligence (AGI). However, current benchmarks for measuring the intelligence\nof MLLMs suffer from limited scale, narrow coverage, and unstructured\nknowledge, offering only static and undifferentiated evaluations. To bridge\nthis gap, we introduce MDK12-Bench, a large-scale multidisciplinary benchmark\nbuilt from real-world K-12 exams spanning six disciplines with 141K instances\nand 6,225 knowledge points organized in a six-layer taxonomy. Covering five\nquestion formats with difficulty and year annotations, it enables comprehensive\nevaluation to capture the extent to which MLLMs perform over four dimensions:\n1) difficulty levels, 2) temporal (cross-year) shifts, 3) contextual shifts,\nand 4) knowledge-driven reasoning. We propose a novel dynamic evaluation\nframework that introduces unfamiliar visual, textual, and question form shifts\nto challenge model generalization while improving benchmark objectivity and\nlongevity by mitigating data contamination. We further evaluate knowledge-point\nreference-augmented generation (KP-RAG) to examine the role of knowledge in\nproblem-solving. Key findings reveal limitations in current MLLMs in multiple\naspects and provide guidance for enhancing model robustness, interpretability,\nand AI-assisted education.", "AI": {"tldr": "MDK12-Bench\u662f\u4e00\u4e2a\u57fa\u4e8eK-12\u8003\u8bd5\u7684\u5927\u89c4\u6a21\u591a\u5b66\u79d1\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u5168\u9762\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u7684\u6027\u80fd\uff0c\u5e76\u63d0\u51fa\u52a8\u6001\u8bc4\u4f30\u6846\u67b6\u548c\u77e5\u8bc6\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524dMLLMs\u7684\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u89c4\u6a21\u5c0f\u3001\u8986\u76d6\u7a84\u3001\u77e5\u8bc6\u65e0\u7ed3\u6784\u5316\u7b49\u95ee\u9898\uff0c\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "method": "\u6784\u5efaMDK12-Bench\u57fa\u51c6\uff0c\u5305\u542b141K\u5b9e\u4f8b\u548c6,225\u4e2a\u77e5\u8bc6\u70b9\u7684\u516d\u5c42\u5206\u7c7b\u6cd5\uff0c\u5e76\u63d0\u51fa\u52a8\u6001\u8bc4\u4f30\u6846\u67b6\u548cKP-RAG\u65b9\u6cd5\u3002", "result": "\u53d1\u73b0\u5f53\u524dMLLMs\u5728\u591a\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u589e\u5f3a\u6a21\u578b\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u7684\u6307\u5bfc\u3002", "conclusion": "MDK12-Bench\u4e3aMLLMs\u7684\u8bc4\u4f30\u548c\u6539\u8fdb\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\uff0c\u5c24\u5176\u5728AI\u8f85\u52a9\u6559\u80b2\u9886\u57df\u3002"}}
{"id": "2508.08043", "categories": ["cs.CR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2508.08043", "abs": "https://arxiv.org/abs/2508.08043", "authors": ["Yancheng Jiang", "Yan Jiang", "Ruochen Zhou", "Yi-Chao Chen", "Xiaoyu Ji", "Wenyuan Xu"], "title": "False Reality: Uncovering Sensor-induced Human-VR Interaction Vulnerability", "comment": null, "summary": "Virtual Reality (VR) techniques, serving as the bridge between the real and\nvirtual worlds, have boomed and are widely used in manufacturing, remote\nhealthcare, gaming, etc. Specifically, VR systems offer users immersive\nexperiences that include both perceptions and actions. Various studies have\ndemonstrated that attackers can manipulate VR software to influence users'\ninteractions, including perception and actions. However, such attacks typically\nrequire strong access and specialized expertise. In this paper, we are the\nfirst to present a systematic analysis of physical attacks against VR systems\nand introduce False Reality, a new attack threat to VR devices without\nrequiring access to or modification of their software. False Reality disturbs\nVR system services by tampering with sensor measurements, and further spoofing\nusers' perception even inducing harmful actions, e.g., inducing dizziness or\ncausing users to crash into obstacles, by exploiting perceptual and\npsychological effects. We formalize these threats through an attack pathway\nframework and validate three representative pathways via physical experiments\nand user studies on five commercial VR devices. Finally, we further propose a\ndefense prototype to mitigate such threats. Our findings shall provide valuable\ninsights for enhancing the security and resilience of future VR systems.", "AI": {"tldr": "\u8bba\u6587\u9996\u6b21\u7cfb\u7edf\u5206\u6790\u4e86\u9488\u5bf9VR\u7cfb\u7edf\u7684\u7269\u7406\u653b\u51fb\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201cFalse Reality\u201d\u7684\u65b0\u578b\u653b\u51fb\u5a01\u80c1\uff0c\u65e0\u9700\u4fee\u6539\u8f6f\u4ef6\u5373\u53ef\u5e72\u6270VR\u670d\u52a1\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "VR\u6280\u672f\u5e7f\u6cdb\u5e94\u7528\u4e8e\u591a\u4e2a\u9886\u57df\uff0c\u4f46\u73b0\u6709\u653b\u51fb\u901a\u5e38\u9700\u8981\u9ad8\u6743\u9650\u548c\u4e13\u4e1a\u77e5\u8bc6\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u65e0\u9700\u8f6f\u4ef6\u4fee\u6539\u5373\u53ef\u5b9e\u65bd\u7684\u7269\u7406\u653b\u51fb\uff0c\u4ee5\u63d0\u5347VR\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u3002", "method": "\u901a\u8fc7\u7be1\u6539\u4f20\u611f\u5668\u6570\u636e\u5e72\u6270VR\u670d\u52a1\uff0c\u5229\u7528\u611f\u77e5\u548c\u5fc3\u7406\u6548\u5e94\u6b3a\u9a97\u7528\u6237\uff0c\u63d0\u51fa\u653b\u51fb\u8def\u5f84\u6846\u67b6\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5728\u4e94\u79cd\u5546\u7528VR\u8bbe\u5907\u4e0a\u9a8c\u8bc1\u4e86\u4e09\u79cd\u4ee3\u8868\u6027\u653b\u51fb\u8def\u5f84\uff0c\u8bc1\u660eFalse Reality\u80fd\u8bf1\u5bfc\u7528\u6237\u4ea7\u751f\u6709\u5bb3\u884c\u4e3a\u3002", "conclusion": "\u7814\u7a76\u4e3a\u672a\u6765VR\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u548c\u97e7\u6027\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u9632\u5fa1\u539f\u578b\u3002"}}
{"id": "2508.06859", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.06859", "abs": "https://arxiv.org/abs/2508.06859", "authors": ["Shuo Tang", "Jian Xu", "Jiadong Zhang", "Yi Chen", "Qizhao Jin", "Lingdong Shen", "Chenglin Liu", "Shiming Xiang"], "title": "MeteorPred: A Meteorological Multimodal Large Model and Dataset for Severe Weather Event Prediction", "comment": null, "summary": "Timely and accurate severe weather warnings are critical for disaster\nmitigation. However, current forecasting systems remain heavily reliant on\nmanual expert interpretation, introducing subjectivity and significant\noperational burdens. With the rapid development of AI technologies, the\nend-to-end \"AI weather station\" is gradually emerging as a new trend in\npredicting severe weather events. Three core challenges impede the development\nof end-to-end AI severe weather system: (1) scarcity of severe weather event\nsamples; (2) imperfect alignment between high-dimensional meteorological data\nand textual warnings; (3) existing multimodal language models are unable to\nhandle high-dimensional meteorological data and struggle to fully capture the\ncomplex dependencies across temporal sequences, vertical pressure levels, and\nspatial dimensions. To address these challenges, we introduce MP-Bench, the\nfirst large-scale temporal multimodal dataset for severe weather events\nprediction, comprising 421,363 pairs of raw multi-year meteorological data and\ncorresponding text caption, covering a wide range of severe weather scenarios\nacross China. On top of this dataset, we develop a meteorology multimodal large\nmodel (MMLM) that directly ingests 4D meteorological inputs. In addition, it is\ndesigned to accommodate the unique characteristics of 4D meteorological data\nflow, incorporating three plug-and-play adaptive fusion modules that enable\ndynamic feature extraction and integration across temporal sequences, vertical\npressure layers, and spatial dimensions. Extensive experiments on MP-Bench\ndemonstrate that MMLM performs exceptionally well across multiple tasks,\nhighlighting its effectiveness in severe weather understanding and marking a\nkey step toward realizing automated, AI-driven weather forecasting systems. Our\nsource code and dataset will be made publicly available.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eAI\u7684\u7aef\u5230\u7aef\u5929\u6c14\u9884\u8b66\u7cfb\u7edf\uff0c\u901a\u8fc7\u6784\u5efa\u5927\u89c4\u6a21\u591a\u6a21\u6001\u6570\u636e\u96c6MP-Bench\u548c\u5f00\u53d1\u6c14\u8c61\u591a\u6a21\u6001\u5927\u6a21\u578b\uff08MMLM\uff09\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u7cfb\u7edf\u4f9d\u8d56\u4eba\u5de5\u3001\u6570\u636e\u5bf9\u9f50\u4e0d\u8db3\u7b49\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u5929\u6c14\u9884\u8b66\u7cfb\u7edf\u4f9d\u8d56\u4e13\u5bb6\u624b\u52a8\u89e3\u8bfb\uff0c\u5b58\u5728\u4e3b\u89c2\u6027\u548c\u64cd\u4f5c\u8d1f\u62c5\u3002AI\u6280\u672f\u7684\u53d1\u5c55\u4e3a\u81ea\u52a8\u5316\u5929\u6c14\u9884\u6d4b\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\uff0c\u4f46\u9762\u4e34\u6570\u636e\u7a00\u7f3a\u3001\u9ad8\u7ef4\u6570\u636e\u5bf9\u9f50\u56f0\u96be\u7b49\u6311\u6218\u3002", "method": "\u6784\u5efaMP-Bench\u6570\u636e\u96c6\uff08421,363\u5bf9\u6c14\u8c61\u6570\u636e\u4e0e\u6587\u672c\u6807\u6ce8\uff09\uff0c\u5f00\u53d1MMLM\u6a21\u578b\uff0c\u652f\u63014D\u6c14\u8c61\u6570\u636e\u8f93\u5165\uff0c\u5e76\u8bbe\u8ba1\u4e86\u52a8\u6001\u7279\u5f81\u63d0\u53d6\u6a21\u5757\u3002", "result": "\u5b9e\u9a8c\u8868\u660eMMLM\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u5929\u6c14\u9884\u8b66\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "MMLM\u4e3a\u81ea\u52a8\u5316AI\u5929\u6c14\u9884\u6d4b\u7cfb\u7edf\u8fc8\u51fa\u4e86\u5173\u952e\u4e00\u6b65\uff0c\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5c06\u516c\u5f00\u3002"}}
{"id": "2508.08068", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2508.08068", "abs": "https://arxiv.org/abs/2508.08068", "authors": ["Yuval Efron", "Joachim Neu", "Toniann Pitassi"], "title": "Fully-Fluctuating Participation in Sleepy Consensus", "comment": null, "summary": "Proof-of-work allows Bitcoin to boast security amidst arbitrary fluctuations\nin participation of miners throughout time, so long as, at any point in time, a\nmajority of hash power is honest. In recent years, however, the pendulum has\nshifted in favor of proof-of-stake-based consensus protocols. There, the sleepy\nmodel is the most prominent model for handling fluctuating participation of\nnodes. However, to date, no protocol in the sleepy model rivals Bitcoin in its\nrobustness to drastic fluctuations in participation levels, with\nstate-of-the-art protocols making various restrictive assumptions. In this\nwork, we present a new adversary model, called external adversary. Intuitively,\nin our model, corrupt nodes do not divulge information about their secret keys.\nIn this model, we show that protocols in the sleepy model can meaningfully\nclaim to remain secure against fully fluctuating participation, without\ncompromising efficiency or corruption resilience. Our adversary model is quite\nnatural, and arguably naturally captures the process via which malicious\nbehavior arises in protocols, as opposed to traditional worst-case modeling. On\ntop of which, the model is also theoretically appealing, circumventing a\nbarrier established in a recent work of Malkhi, Momose, and Ren.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5bf9\u624b\u6a21\u578b\u2014\u2014\u5916\u90e8\u5bf9\u624b\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u7761\u7720\u6a21\u578b\u4e2d\u534f\u8bae\u65e0\u6cd5\u5e94\u5bf9\u6781\u7aef\u53c2\u4e0e\u6ce2\u52a8\u7684\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6548\u7387\u548c\u6297\u8150\u8680\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7761\u7720\u6a21\u578b\u4e2d\u7684\u534f\u8bae\u65e0\u6cd5\u50cf\u6bd4\u7279\u5e01\u90a3\u6837\u5728\u6781\u7aef\u53c2\u4e0e\u6ce2\u52a8\u4e0b\u4fdd\u6301\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u5bf9\u624b\u6a21\u578b\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5916\u90e8\u5bf9\u624b\u6a21\u578b\uff0c\u5047\u8bbe\u8150\u8d25\u8282\u70b9\u4e0d\u4f1a\u6cc4\u9732\u5176\u79c1\u94a5\u4fe1\u606f\uff0c\u4ece\u800c\u5728\u7761\u7720\u6a21\u578b\u4e2d\u5b9e\u73b0\u5b89\u5168\u6027\u548c\u6548\u7387\u7684\u5e73\u8861\u3002", "result": "\u5728\u8be5\u6a21\u578b\u4e0b\uff0c\u7761\u7720\u6a21\u578b\u4e2d\u7684\u534f\u8bae\u80fd\u591f\u5728\u4e0d\u727a\u7272\u6548\u7387\u6216\u6297\u8150\u8680\u80fd\u529b\u7684\u60c5\u51b5\u4e0b\uff0c\u5e94\u5bf9\u5b8c\u5168\u6ce2\u52a8\u7684\u53c2\u4e0e\u6c34\u5e73\u3002", "conclusion": "\u5916\u90e8\u5bf9\u624b\u6a21\u578b\u4e0d\u4ec5\u81ea\u7136\u4e14\u7406\u8bba\u4e0a\u6709\u5438\u5f15\u529b\uff0c\u8fd8\u7ed5\u8fc7\u4e86\u5148\u524d\u7814\u7a76\u4e2d\u63d0\u51fa\u7684\u969c\u788d\uff0c\u4e3a\u7761\u7720\u6a21\u578b\u7684\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.06894", "categories": ["cs.AI", "cs.LG", "68T05"], "pdf": "https://arxiv.org/pdf/2508.06894", "abs": "https://arxiv.org/abs/2508.06894", "authors": ["Giovanni Varricchione", "Toryn Q. Klassen", "Natasha Alechina", "Mehdi Dastani", "Brian Logan", "Sheila A. McIlraith"], "title": "Pushdown Reward Machines for Reinforcement Learning", "comment": null, "summary": "Reward machines (RMs) are automata structures that encode (non-Markovian)\nreward functions for reinforcement learning (RL). RMs can reward any behaviour\nrepresentable in regular languages and, when paired with RL algorithms that\nexploit RM structure, have been shown to significantly improve sample\nefficiency in many domains. In this work, we present pushdown reward machines\n(pdRMs), an extension of reward machines based on deterministic pushdown\nautomata. pdRMs can recognize and reward temporally extended behaviours\nrepresentable in deterministic context-free languages, making them more\nexpressive than reward machines. We introduce two variants of pdRM-based\npolicies, one which has access to the entire stack of the pdRM, and one which\ncan only access the top $k$ symbols (for a given constant $k$) of the stack. We\npropose a procedure to check when the two kinds of policies (for a given\nenvironment, pdRM, and constant $k$) achieve the same optimal expected reward.\nWe then provide theoretical results establishing the expressive power of pdRMs,\nand space complexity results about the proposed learning problems. Finally, we\nprovide experimental results showing how agents can be trained to perform tasks\nrepresentable in deterministic context-free languages using pdRMs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u63a8\u4e0b\u5956\u52b1\u673a\uff08pdRMs\uff09\uff0c\u57fa\u4e8e\u786e\u5b9a\u6027\u4e0b\u63a8\u81ea\u52a8\u673a\u6269\u5c55\u4e86\u5956\u52b1\u673a\uff08RMs\uff09\uff0c\u80fd\u591f\u8bc6\u522b\u548c\u5956\u52b1\u786e\u5b9a\u6027\u4e0a\u4e0b\u6587\u65e0\u5173\u8bed\u8a00\u8868\u793a\u7684\u884c\u4e3a\uff0c\u63d0\u5347\u4e86\u8868\u8fbe\u80fd\u529b\u3002", "motivation": "\u6269\u5c55\u5956\u52b1\u673a\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u4f7f\u5176\u80fd\u591f\u5904\u7406\u66f4\u590d\u6742\u7684\u975e\u9a6c\u5c14\u53ef\u592b\u5956\u52b1\u51fd\u6570\uff0c\u4ece\u800c\u63d0\u9ad8\u5f3a\u5316\u5b66\u4e60\u7684\u6837\u672c\u6548\u7387\u3002", "method": "\u5f15\u5165\u4e24\u79cd\u57fa\u4e8epdRM\u7684\u7b56\u7565\uff0c\u4e00\u79cd\u53ef\u4ee5\u8bbf\u95ee\u6574\u4e2a\u5806\u6808\uff0c\u53e6\u4e00\u79cd\u4ec5\u80fd\u8bbf\u95ee\u5806\u6808\u9876\u90e8\u7684$k$\u4e2a\u7b26\u53f7\uff0c\u5e76\u63d0\u51fa\u4e86\u68c0\u67e5\u4e24\u79cd\u7b56\u7565\u6700\u4f18\u6027\u7684\u65b9\u6cd5\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u4e86pdRMs\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u5e76\u63d0\u4f9b\u4e86\u7a7a\u95f4\u590d\u6742\u5ea6\u5206\u6790\u3002\u5b9e\u9a8c\u8868\u660epdRMs\u53ef\u4ee5\u8bad\u7ec3\u4ee3\u7406\u6267\u884c\u786e\u5b9a\u6027\u4e0a\u4e0b\u6587\u65e0\u5173\u8bed\u8a00\u8868\u793a\u7684\u4efb\u52a1\u3002", "conclusion": "pdRMs\u6bd4RMs\u66f4\u5177\u8868\u8fbe\u529b\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u66f4\u590d\u6742\u7684\u4efb\u52a1\uff0c\u4e3a\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\u3002"}}
{"id": "2508.08190", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.08190", "abs": "https://arxiv.org/abs/2508.08190", "authors": ["Paritosh Ramanan", "H. M. Mohaimanul Islam", "Abhiram Reddy Alugula"], "title": "Differential Privacy for Regulatory Compliance in Cyberattack Detection on Critical Infrastructure Systems", "comment": null, "summary": "Industrial control systems are a fundamental component of critical\ninfrastructure networks (CIN) such as gas, water and power. With the growing\nrisk of cyberattacks, regulatory compliance requirements are also increasing\nfor large scale critical infrastructure systems comprising multiple utility\nstakeholders. The primary goal of regulators is to ensure overall system\nstability with recourse to trustworthy stakeholder attack detection. However,\nadhering to compliance requirements requires stakeholders to also disclose\nsensor and control data to regulators raising privacy concerns. In this paper,\nwe present a cyberattack detection framework that utilizes differentially\nprivate (DP) hypothesis tests geared towards enhancing regulatory confidence\nwhile alleviating privacy concerns of CIN stakeholders. The hallmark of our\napproach is a two phase privacy scheme that protects the privacy of covariance,\nas well as the associated sensor driven test statistics computed as a means to\ngenerate alarms. Theoretically, we show that our method induces a\nmisclassification error rate comparable to the non-DP cases while delivering\nrobust privacy guarantees. With the help of real-world datasets, we show the\nreliability of our DP-detection outcomes for a wide variety of attack scenarios\nfor interdependent stakeholders.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5dee\u5206\u9690\u79c1\u5047\u8bbe\u6d4b\u8bd5\u7684\u7f51\u7edc\u653b\u51fb\u68c0\u6d4b\u6846\u67b6\uff0c\u65e8\u5728\u589e\u5f3a\u76d1\u7ba1\u4fe1\u5fc3\u5e76\u7f13\u89e3\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u7f51\u7edc\uff08CIN\uff09\u5229\u76ca\u76f8\u5173\u8005\u7684\u9690\u79c1\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u7f51\u7edc\u653b\u51fb\u98ce\u9669\u7684\u589e\u52a0\uff0c\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u7cfb\u7edf\u9762\u4e34\u66f4\u4e25\u683c\u7684\u76d1\u7ba1\u5408\u89c4\u8981\u6c42\uff0c\u4f46\u5229\u76ca\u76f8\u5173\u8005\u62c5\u5fc3\u6570\u636e\u9690\u79c1\u6cc4\u9732\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u9690\u79c1\u4fdd\u62a4\u65b9\u6848\uff0c\u4fdd\u62a4\u534f\u65b9\u5dee\u53ca\u76f8\u5173\u4f20\u611f\u5668\u9a71\u52a8\u6d4b\u8bd5\u7edf\u8ba1\u6570\u636e\u7684\u9690\u79c1\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u975e\u5dee\u5206\u9690\u79c1\u60c5\u51b5\u4e0b\u5177\u6709\u53ef\u6bd4\u7684\u8bef\u5206\u7c7b\u7387\uff0c\u5e76\u63d0\u4f9b\u5f3a\u9690\u79c1\u4fdd\u8bc1\uff1b\u5b9e\u9645\u6570\u636e\u96c6\u9a8c\u8bc1\u4e86\u5176\u53ef\u9760\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\uff0c\u6709\u6548\u68c0\u6d4b\u7f51\u7edc\u653b\u51fb\uff0c\u9002\u7528\u4e8e\u591a\u5229\u76ca\u76f8\u5173\u8005\u7684\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u7cfb\u7edf\u3002"}}
{"id": "2508.06899", "categories": ["cs.AI", "cs.DM"], "pdf": "https://arxiv.org/pdf/2508.06899", "abs": "https://arxiv.org/abs/2508.06899", "authors": ["Yanchen Deng", "Xinrun Wang", "Bo An"], "title": "GDBA Revisited: Unleashing the Power of Guided Local Search for Distributed Constraint Optimization", "comment": null, "summary": "Local search is an important class of incomplete algorithms for solving\nDistributed Constraint Optimization Problems (DCOPs) but it often converges to\npoor local optima. While GDBA provides a comprehensive rule set to escape\npremature convergence, its empirical benefits remain marginal on general-valued\nproblems. In this work, we systematically examine GDBA and identify three\nfactors that potentially lead to its inferior performance, i.e.,\nover-aggressive constraint violation conditions, unbounded penalty\naccumulation, and uncoordinated penalty updates. To address these issues, we\npropose Distributed Guided Local Search (DGLS), a novel GLS framework for DCOPs\nthat incorporates an adaptive violation condition to selectively penalize\nconstraints with high cost, a penalty evaporation mechanism to control the\nmagnitude of penalization, and a synchronization scheme for coordinated penalty\nupdates. We theoretically show that the penalty values are bounded, and agents\nplay a potential game in our DGLS. Our extensive empirical results on various\nstandard benchmarks demonstrate the great superiority of DGLS over\nstate-of-the-art baselines. Particularly, compared to Damped Max-sum with high\ndamping factors (e.g., 0.7 or 0.9), our DGLS achieves competitive performance\non general-valued problems, and outperforms it by significant margins\n(\\textbf{3.77\\%--66.3\\%}) on structured problems in terms of anytime results.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDGLS\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6539\u8fdbGDBA\u7684\u7f3a\u9677\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5206\u5e03\u5f0f\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u7684\u5c40\u90e8\u641c\u7d22\u6027\u80fd\u3002", "motivation": "GDBA\u5728\u89e3\u51b3\u5206\u5e03\u5f0f\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u65f6\u5bb9\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18\uff0c\u4e14\u6027\u80fd\u63d0\u5347\u6709\u9650\u3002\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u5176\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a\u8fc7\u5ea6\u6fc0\u8fdb\u7684\u7ea6\u675f\u8fdd\u53cd\u6761\u4ef6\u3001\u65e0\u9650\u5236\u7684\u60e9\u7f5a\u7d2f\u79ef\u548c\u4e0d\u534f\u8c03\u7684\u60e9\u7f5a\u66f4\u65b0\u3002", "method": "\u63d0\u51fa\u4e86DGLS\u6846\u67b6\uff0c\u5305\u62ec\u81ea\u9002\u5e94\u8fdd\u53cd\u6761\u4ef6\u3001\u60e9\u7f5a\u84b8\u53d1\u673a\u5236\u548c\u540c\u6b65\u60e9\u7f5a\u66f4\u65b0\u65b9\u6848\u3002", "result": "DGLS\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5c24\u5176\u5728\u7ed3\u6784\u5316\u95ee\u9898\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff083.77%--66.3%\uff09\u3002", "conclusion": "DGLS\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u89e3\u51b3\u5206\u5e03\u5f0f\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u4e2d\u7684\u9ad8\u6548\u6027\u548c\u4f18\u8d8a\u6027\u3002"}}
{"id": "2508.06972", "categories": ["cs.AI", "cs.CR", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.06972", "abs": "https://arxiv.org/abs/2508.06972", "authors": ["Dan Ivanov", "Tristan Freiberg", "Haruna Isah"], "title": "DSperse: A Framework for Targeted Verification in Zero-Knowledge Machine Learning", "comment": "12 pages, 8 figures, and 10 tables", "summary": "DSperse is a modular framework for distributed machine learning inference\nwith strategic cryptographic verification. Operating within the emerging\nparadigm of distributed zero-knowledge machine learning, DSperse avoids the\nhigh cost and rigidity of full-model circuitization by enabling targeted\nverification of strategically chosen subcomputations. These verifiable\nsegments, or \"slices\", may cover part or all of the inference pipeline, with\nglobal consistency enforced through audit, replication, or economic incentives.\nThis architecture supports a pragmatic form of trust minimization, localizing\nzero-knowledge proofs to the components where they provide the greatest value.\nWe evaluate DSperse using multiple proving systems and report empirical results\non memory usage, runtime, and circuit behavior under sliced and unsliced\nconfigurations. By allowing proof boundaries to align flexibly with the model's\nlogical structure, DSperse supports scalable, targeted verification strategies\nsuited to diverse deployment needs.", "AI": {"tldr": "DSperse\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u63a8\u7406\uff0c\u901a\u8fc7\u6218\u7565\u6027\u7684\u52a0\u5bc6\u9a8c\u8bc1\u5b9e\u73b0\u9ad8\u6548\u548c\u7075\u6d3b\u7684\u4fe1\u4efb\u6700\u5c0f\u5316\u3002", "motivation": "\u89e3\u51b3\u5206\u5e03\u5f0f\u96f6\u77e5\u8bc6\u673a\u5668\u5b66\u4e60\u4e2d\u5168\u6a21\u578b\u7535\u8def\u5316\u7684\u9ad8\u6210\u672c\u548c\u50f5\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u5c40\u90e8\u9a8c\u8bc1\u5173\u952e\u5b50\u8ba1\u7b97\u5b9e\u73b0\u9ad8\u6548\u9a8c\u8bc1\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u652f\u6301\u5bf9\u63a8\u7406\u7ba1\u9053\u4e2d\u7684\u90e8\u5206\u6216\u5168\u90e8\u5b50\u8ba1\u7b97\uff08\u201c\u5207\u7247\u201d\uff09\u8fdb\u884c\u9a8c\u8bc1\uff0c\u7ed3\u5408\u5ba1\u8ba1\u3001\u590d\u5236\u6216\u7ecf\u6d4e\u6fc0\u52b1\u786e\u4fdd\u5168\u5c40\u4e00\u81f4\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u4e86\u591a\u79cd\u8bc1\u660e\u7cfb\u7edf\uff0c\u5c55\u793a\u4e86\u5207\u7247\u4e0e\u975e\u5207\u7247\u914d\u7f6e\u4e0b\u7684\u5185\u5b58\u4f7f\u7528\u3001\u8fd0\u884c\u65f6\u95f4\u548c\u7535\u8def\u884c\u4e3a\u8868\u73b0\u3002", "conclusion": "DSperse\u901a\u8fc7\u7075\u6d3b\u7684\u9a8c\u8bc1\u8fb9\u754c\u8bbe\u8ba1\uff0c\u652f\u6301\u53ef\u6269\u5c55\u7684\u3001\u9488\u5bf9\u6027\u7684\u9a8c\u8bc1\u7b56\u7565\uff0c\u9002\u5e94\u591a\u6837\u5316\u7684\u90e8\u7f72\u9700\u6c42\u3002"}}
{"id": "2508.06931", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.06931", "abs": "https://arxiv.org/abs/2508.06931", "authors": ["Wangyue Lu", "Lun Du", "Sirui Li", "Ke Weng", "Haozhe Sun", "Hengyu Liu", "Minghe Yu", "Tiancheng Zhang", "Ge Yu"], "title": "Automated Formalization via Conceptual Retrieval-Augmented LLMs", "comment": null, "summary": "Interactive theorem provers (ITPs) require manual formalization, which is\nlabor-intensive and demands expert knowledge. While automated formalization\noffers a potential solution, it faces two major challenges: model hallucination\n(e.g., undefined predicates, symbol misuse, and version incompatibility) and\nthe semantic gap caused by ambiguous or missing premises in natural language\ndescriptions. To address these issues, we propose CRAMF, a Concept-driven\nRetrieval-Augmented Mathematical Formalization framework. CRAMF enhances\nLLM-based autoformalization by retrieving formal definitions of core\nmathematical concepts, providing contextual grounding during code generation.\nHowever, applying retrieval-augmented generation (RAG) in this setting is\nnon-trivial due to the lack of structured knowledge bases, the polymorphic\nnature of mathematical concepts, and the high precision required in formal\nretrieval. We introduce a framework for automatically constructing a\nconcept-definition knowledge base from Mathlib4, the standard mathematical\nlibrary for the Lean 4 theorem prover, indexing over 26,000 formal definitions\nand 1,000+ core mathematical concepts. To address conceptual polymorphism, we\npropose contextual query augmentation with domain- and application-level\nsignals. In addition, we design a dual-channel hybrid retrieval strategy with\nreranking to ensure accurate and relevant definition retrieval. Experiments on\nminiF2F, ProofNet, and our newly proposed AdvancedMath benchmark show that\nCRAMF can be seamlessly integrated into LLM-based autoformalizers, yielding\nconsistent improvements in translation accuracy, achieving up to 62.1% and an\naverage of 29.9% relative improvement.", "AI": {"tldr": "CRAMF\u662f\u4e00\u4e2a\u6982\u5ff5\u9a71\u52a8\u7684\u68c0\u7d22\u589e\u5f3a\u6570\u5b66\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22\u6838\u5fc3\u6570\u5b66\u6982\u5ff5\u7684\u5f62\u5f0f\u5316\u5b9a\u4e49\uff0c\u63d0\u5347\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u5f62\u5f0f\u5316\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u6a21\u578b\u5e7b\u89c9\u548c\u8bed\u4e49\u9e3f\u6c9f\u95ee\u9898\u3002", "motivation": "\u624b\u52a8\u5f62\u5f0f\u5316\u5728\u4ea4\u4e92\u5f0f\u5b9a\u7406\u8bc1\u660e\u5668\u4e2d\u52b3\u52a8\u5bc6\u96c6\u4e14\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\uff0c\u81ea\u52a8\u5f62\u5f0f\u5316\u9762\u4e34\u6a21\u578b\u5e7b\u89c9\u548c\u8bed\u4e49\u9e3f\u6c9f\u7684\u6311\u6218\u3002", "method": "CRAMF\u901a\u8fc7\u4eceMathlib4\u6784\u5efa\u6982\u5ff5\u5b9a\u4e49\u77e5\u8bc6\u5e93\uff0c\u7ed3\u5408\u4e0a\u4e0b\u6587\u67e5\u8be2\u589e\u5f3a\u548c\u53cc\u901a\u9053\u6df7\u5408\u68c0\u7d22\u7b56\u7565\uff0c\u63d0\u5347\u68c0\u7d22\u7cbe\u5ea6\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCRAMF\u663e\u8457\u63d0\u5347\u4e86\u7ffb\u8bd1\u51c6\u786e\u7387\uff0c\u6700\u9ad8\u8fbe62.1%\uff0c\u5e73\u5747\u63d0\u534729.9%\u3002", "conclusion": "CRAMF\u4e3a\u81ea\u52a8\u5f62\u5f0f\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u5f62\u5f0f\u5316\u6027\u80fd\u3002"}}
{"id": "2508.06939", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.06939", "abs": "https://arxiv.org/abs/2508.06939", "authors": ["Hiba Najjar", "Deepak Pathak", "Marlon Nuske", "Andreas Dengel"], "title": "Intrinsic Explainability of Multimodal Learning for Crop Yield Prediction", "comment": null, "summary": "Multimodal learning enables various machine learning tasks to benefit from\ndiverse data sources, effectively mimicking the interplay of different factors\nin real-world applications, particularly in agriculture. While the\nheterogeneous nature of involved data modalities may necessitate the design of\ncomplex architectures, the model interpretability is often overlooked. In this\nstudy, we leverage the intrinsic explainability of Transformer-based models to\nexplain multimodal learning networks, focusing on the task of crop yield\nprediction at the subfield level. The large datasets used cover various crops,\nregions, and years, and include four different input modalities: multispectral\nsatellite and weather time series, terrain elevation maps and soil properties.\nBased on the self-attention mechanism, we estimate feature attributions using\ntwo methods, namely the Attention Rollout (AR) and Generic Attention (GA), and\nevaluate their performance against Shapley-based model-agnostic estimations,\nShapley Value Sampling (SVS). Additionally, we propose the Weighted Modality\nActivation (WMA) method to assess modality attributions and compare it with SVS\nattributions. Our findings indicate that Transformer-based models outperform\nother architectures, specifically convolutional and recurrent networks,\nachieving R2 scores that are higher by 0.10 and 0.04 at the subfield and field\nlevels, respectively. AR is shown to provide more robust and reliable temporal\nattributions, as confirmed through qualitative and quantitative evaluation,\ncompared to GA and SVS values. Information about crop phenology stages was\nleveraged to interpret the explanation results in the light of established\nagronomic knowledge. Furthermore, modality attributions revealed varying\npatterns across the two methods compared.[...]", "AI": {"tldr": "\u8be5\u7814\u7a76\u5229\u7528Transformer\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u5206\u6790\u591a\u6a21\u6001\u5b66\u4e60\u7f51\u7edc\uff0c\u7528\u4e8e\u5b50\u7530\u5757\u7ea7\u522b\u7684\u4f5c\u7269\u4ea7\u91cf\u9884\u6d4b\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u6a21\u6001\u5f52\u56e0\u65b9\u6cd5\u3002", "motivation": "\u591a\u6a21\u6001\u5b66\u4e60\u5728\u519c\u4e1a\u4e2d\u6709\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u6a21\u578b\u590d\u6742\u6027\u548c\u53ef\u89e3\u91ca\u6027\u5e38\u88ab\u5ffd\u89c6\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7Transformer\u6a21\u578b\u63d0\u9ad8\u591a\u6a21\u6001\u5b66\u4e60\u7684\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u4f7f\u7528\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u91c7\u7528Attention Rollout (AR)\u548cGeneric Attention (GA)\u4e24\u79cd\u65b9\u6cd5\u4f30\u8ba1\u7279\u5f81\u5f52\u56e0\uff0c\u5e76\u63d0\u51fa\u4e86Weighted Modality Activation (WMA)\u65b9\u6cd5\u8bc4\u4f30\u6a21\u6001\u5f52\u56e0\u3002", "result": "Transformer\u6a21\u578b\u5728\u5b50\u7530\u5757\u548c\u7530\u95f4\u7ea7\u522b\u7684R2\u5206\u6570\u5206\u522b\u6bd4\u5377\u79ef\u548c\u5faa\u73af\u7f51\u7edc\u9ad80.10\u548c0.04\uff1bAR\u5728\u65f6\u95f4\u5f52\u56e0\u4e0a\u8868\u73b0\u66f4\u7a33\u5065\u3002", "conclusion": "Transformer\u6a21\u578b\u5728\u591a\u6a21\u6001\u5b66\u4e60\u4e2d\u8868\u73b0\u4f18\u5f02\uff0cAR\u65b9\u6cd5\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u91ca\uff0c\u6a21\u6001\u5f52\u56e0\u65b9\u6cd5\u63ed\u793a\u4e86\u4e0d\u540c\u6a21\u5f0f\u7684\u5dee\u5f02\u3002"}}
{"id": "2508.06950", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06950", "abs": "https://arxiv.org/abs/2508.06950", "authors": ["Sarah Schr\u00f6der", "Thekla Morgenroth", "Ulrike Kuhl", "Valerie Vaquet", "Benjamin Paa\u00dfen"], "title": "Large Language Models Do Not Simulate Human Psychology", "comment": null, "summary": "Large Language Models (LLMs),such as ChatGPT, are increasingly used in\nresearch, ranging from simple writing assistance to complex data annotation\ntasks. Recently, some research has suggested that LLMs may even be able to\nsimulate human psychology and can, hence, replace human participants in\npsychological studies. We caution against this approach. We provide conceptual\narguments against the hypothesis that LLMs simulate human psychology. We then\npresent empiric evidence illustrating our arguments by demonstrating that\nslight changes to wording that correspond to large changes in meaning lead to\nnotable discrepancies between LLMs' and human responses, even for the recent\nCENTAUR model that was specifically fine-tuned on psychological responses.\nAdditionally, different LLMs show very different responses to novel items,\nfurther illustrating their lack of reliability. We conclude that LLMs do not\nsimulate human psychology and recommend that psychological researchers should\ntreat LLMs as useful but fundamentally unreliable tools that need to be\nvalidated against human responses for every new application.", "AI": {"tldr": "\u8bba\u6587\u8b66\u544a\u4e0d\u8981\u7528LLMs\u6a21\u62df\u4eba\u7c7b\u5fc3\u7406\u5b66\uff0c\u6307\u51fa\u5176\u4e0e\u4eba\u7c7b\u53cd\u5e94\u7684\u663e\u8457\u5dee\u5f02\u3002", "motivation": "\u63a2\u8ba8LLMs\u662f\u5426\u80fd\u66ff\u4ee3\u4eba\u7c7b\u53c2\u4e0e\u8005\u8fdb\u884c\u5fc3\u7406\u5b66\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u6982\u5ff5\u8bba\u8bc1\u548c\u5b9e\u8bc1\u7814\u7a76\uff0c\u6bd4\u8f83LLMs\u4e0e\u4eba\u7c7b\u5bf9\u5fae\u5c0f\u8bed\u8a00\u53d8\u5316\u7684\u53cd\u5e94\u5dee\u5f02\u3002", "result": "LLMs\u4e0e\u4eba\u7c7b\u53cd\u5e94\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u4e14\u4e0d\u540c\u6a21\u578b\u95f4\u53cd\u5e94\u4e0d\u4e00\u81f4\u3002", "conclusion": "LLMs\u4e0d\u80fd\u6a21\u62df\u4eba\u7c7b\u5fc3\u7406\u5b66\uff0c\u9700\u5728\u6bcf\u6b21\u5e94\u7528\u4e2d\u9a8c\u8bc1\u5176\u53ef\u9760\u6027\u3002"}}
{"id": "2508.06960", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.06960", "abs": "https://arxiv.org/abs/2508.06960", "authors": ["Keyu Li", "Mohan Jiang", "Dayuan Fu", "Yunze Wu", "Xiangkun Hu", "Dequan Wang", "Pengfei Liu"], "title": "DatasetResearch: Benchmarking Agent Systems for Demand-Driven Dataset Discovery", "comment": null, "summary": "The rapid advancement of large language models has fundamentally shifted the\nbottleneck in AI development from computational power to data availability-with\ncountless valuable datasets remaining hidden across specialized repositories,\nresearch appendices, and domain platforms. As reasoning capabilities and deep\nresearch methodologies continue to evolve, a critical question emerges: can AI\nagents transcend conventional search to systematically discover any dataset\nthat meets specific user requirements, enabling truly autonomous demand-driven\ndata curation? We introduce DatasetResearch, the first comprehensive benchmark\nevaluating AI agents' ability to discover and synthesize datasets from 208\nreal-world demands across knowledge-intensive and reasoning-intensive tasks.\nOur tri-dimensional evaluation framework reveals a stark reality: even advanced\ndeep research systems achieve only 22% score on our challenging\nDatasetResearch-pro subset, exposing the vast gap between current capabilities\nand perfect dataset discovery. Our analysis uncovers a fundamental\ndichotomy-search agents excel at knowledge tasks through retrieval breadth,\nwhile synthesis agents dominate reasoning challenges via structured\ngeneration-yet both catastrophically fail on \"corner cases\" outside existing\ndistributions. These findings establish the first rigorous baseline for dataset\ndiscovery agents and illuminate the path toward AI systems capable of finding\nany dataset in the digital universe. Our benchmark and comprehensive analysis\nprovide the foundation for the next generation of self-improving AI systems and\nare publicly available at https://github.com/GAIR-NLP/DatasetResearch.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86DatasetResearch\u57fa\u51c6\uff0c\u8bc4\u4f30AI\u4ee3\u7406\u5728\u53d1\u73b0\u548c\u5408\u6210\u6570\u636e\u96c6\u65b9\u9762\u7684\u80fd\u529b\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6280\u672f\u4e0e\u5b8c\u7f8e\u6570\u636e\u96c6\u53d1\u73b0\u4e4b\u95f4\u7684\u5de8\u5927\u5dee\u8ddd\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u6570\u636e\u53ef\u7528\u6027\u6210\u4e3aAI\u5f00\u53d1\u7684\u74f6\u9888\uff0c\u800c\u8bb8\u591a\u6709\u4ef7\u503c\u7684\u6570\u636e\u96c6\u5206\u6563\u5728\u5404\u5904\u3002\u8bba\u6587\u65e8\u5728\u63a2\u7d22AI\u4ee3\u7406\u662f\u5426\u80fd\u8d85\u8d8a\u4f20\u7edf\u641c\u7d22\uff0c\u5b9e\u73b0\u81ea\u4e3b\u9700\u6c42\u9a71\u52a8\u7684\u6570\u636e\u6574\u7406\u3002", "method": "\u5f15\u5165DatasetResearch\u57fa\u51c6\uff0c\u8bc4\u4f30AI\u4ee3\u7406\u5728208\u4e2a\u771f\u5b9e\u9700\u6c42\u4e2d\u7684\u8868\u73b0\uff0c\u91c7\u7528\u4e09\u7ef4\u8bc4\u4f30\u6846\u67b6\u5206\u6790\u77e5\u8bc6\u5bc6\u96c6\u578b\u548c\u63a8\u7406\u5bc6\u96c6\u578b\u4efb\u52a1\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5373\u4f7f\u662f\u5148\u8fdb\u7684\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\uff0c\u5728\u6311\u6218\u6027\u5b50\u96c6\u4e0a\u7684\u5f97\u5206\u4ec5\u4e3a22%\uff0c\u66b4\u9732\u4e86\u5f53\u524d\u80fd\u529b\u7684\u4e0d\u8db3\u3002\u641c\u7d22\u4ee3\u7406\u5728\u77e5\u8bc6\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u800c\u5408\u6210\u4ee3\u7406\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u5360\u4f18\uff0c\u4f46\u4e24\u8005\u5728\u201c\u6781\u7aef\u6848\u4f8b\u201d\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "\u7814\u7a76\u4e3a\u6570\u636e\u96c6\u53d1\u73b0\u4ee3\u7406\u5efa\u7acb\u4e86\u9996\u4e2a\u4e25\u683c\u57fa\u51c6\uff0c\u6307\u660e\u4e86\u5b9e\u73b0AI\u7cfb\u7edf\u53d1\u73b0\u4efb\u4f55\u6570\u636e\u96c6\u7684\u8def\u5f84\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u81ea\u6539\u8fdbAI\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.06963", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.06963", "abs": "https://arxiv.org/abs/2508.06963", "authors": ["Changqing Li", "Tianlin Li", "Xiaohan Zhang", "Aishan Liu", "Li Pan"], "title": "MASteer: Multi-Agent Adaptive Steer Strategy for End-to-End LLM Trustworthiness Repair", "comment": null, "summary": "Large Language Models (LLMs) face persistent and evolving trustworthiness\nissues, motivating developers to seek automated and flexible repair methods\nthat enable convenient deployment across diverse scenarios. Existing repair\nmethods like supervised fine-tuning (SFT) and reinforcement learning with human\nfeedback (RLHF) are costly and slow, while prompt engineering lacks robustness\nand scalability. Representation engineering, which steers model behavior by\ninjecting targeted concept vectors during inference, offers a lightweight,\ntraining-free alternative. However, current approaches depend on manually\ncrafted samples and fixed steering strategies, limiting automation and\nadaptability. To overcome these challenges, we propose MASteer, the first\nend-to-end framework for trustworthiness repair in LLMs based on representation\nengineering. MASteer integrates two core components: AutoTester, a multi-agent\nsystem that generates diverse, high-quality steer samples tailored to developer\nneeds; and AutoRepairer, which constructs adaptive steering strategies with\nanchor vectors for automated, context-aware strategy selection during\ninference. Experiments on standard and customized trustworthiness tasks show\nMASteer consistently outperforms baselines, improving metrics by 15.36% on\nLLaMA-3.1-8B-Chat and 4.21% on Qwen-3-8B-Chat, while maintaining general model\ncapabilities. MASteer demonstrates strong robustness, generalization, and\npractical value for scalable, efficient trustworthiness repair.", "AI": {"tldr": "MASteer\u662f\u4e00\u4e2a\u57fa\u4e8e\u8868\u793a\u5de5\u7a0b\u7684\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u7528\u4e8e\u4fee\u590d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4fe1\u4efb\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u52a8\u751f\u6210\u6837\u672c\u548c\u81ea\u9002\u5e94\u7b56\u7565\u9009\u62e9\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u4fee\u590d\u65b9\u6cd5\uff08\u5982SFT\u548cRLHF\uff09\u6210\u672c\u9ad8\u4e14\u901f\u5ea6\u6162\uff0c\u800c\u63d0\u793a\u5de5\u7a0b\u7f3a\u4e4f\u9c81\u68d2\u6027\u548c\u6269\u5c55\u6027\uff0c\u9700\u8981\u66f4\u8f7b\u91cf\u3001\u81ea\u52a8\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "MASteer\u7ed3\u5408AutoTester\uff08\u591a\u667a\u80fd\u4f53\u751f\u6210\u6837\u672c\uff09\u548cAutoRepairer\uff08\u81ea\u9002\u5e94\u7b56\u7565\u9009\u62e9\uff09\uff0c\u5b9e\u73b0\u81ea\u52a8\u5316\u4fe1\u4efb\u4fee\u590d\u3002", "result": "\u5728\u6807\u51c6\u4efb\u52a1\u4e2d\uff0cMASteer\u5728LLaMA-3.1-8B-Chat\u548cQwen-3-8B-Chat\u4e0a\u5206\u522b\u63d0\u534715.36%\u548c4.21%\u7684\u6027\u80fd\u3002", "conclusion": "MASteer\u5c55\u793a\u4e86\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u4fe1\u4efb\u4fee\u590d\u80fd\u529b\uff0c\u5177\u6709\u5f3a\u9c81\u68d2\u6027\u548c\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.06980", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06980", "abs": "https://arxiv.org/abs/2508.06980", "authors": ["Aswin Paul", "Moein Khajehnejad", "Forough Habibollahi", "Brett J. Kagan", "Adeel Razi"], "title": "Simulating Biological Intelligence: Active Inference with Experiment-Informed Generative Model", "comment": "18 pages, 8 figures", "summary": "With recent and rapid advancements in artificial intelligence (AI),\nunderstanding the foundation of purposeful behaviour in autonomous agents is\ncrucial for developing safe and efficient systems. While artificial neural\nnetworks have dominated the path to AI, recent studies are exploring the\npotential of biologically based systems, such as networks of living biological\nneuronal networks. Along with promises of high power and data efficiency, these\nsystems may also inform more explainable and biologically plausible models. In\nthis work, we propose a framework rooted in active inference, a general theory\nof behaviour, to model decision-making in embodied agents. Using\nexperiment-informed generative models, we simulate decision-making processes in\na simulated game-play environment, mirroring experimental setups that use\nbiological neurons. Our results demonstrate learning in these agents, providing\ninsights into the role of memory-based learning and predictive planning in\nintelligent decision-making. This work contributes to the growing field of\nexplainable AI by offering a biologically grounded and scalable approach to\nunderstanding purposeful behaviour in agents.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e3b\u52a8\u63a8\u7406\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5efa\u6a21\u5177\u8eab\u4ee3\u7406\u7684\u51b3\u7b56\u8fc7\u7a0b\uff0c\u7ed3\u5408\u751f\u7269\u795e\u7ecf\u5143\u7f51\u7edc\uff0c\u63a2\u7d22\u4e86\u8bb0\u5fc6\u5b66\u4e60\u548c\u9884\u6d4b\u89c4\u5212\u5728\u667a\u80fd\u51b3\u7b56\u4e2d\u7684\u4f5c\u7528\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u7406\u89e3\u81ea\u4e3b\u4ee3\u7406\u7684\u6709\u76ee\u7684\u884c\u4e3a\u57fa\u7840\u5bf9\u5f00\u53d1\u5b89\u5168\u9ad8\u6548\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\u3002\u751f\u7269\u795e\u7ecf\u5143\u7f51\u7edc\u53ef\u80fd\u63d0\u4f9b\u66f4\u9ad8\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u91c7\u7528\u4e3b\u52a8\u63a8\u7406\u7406\u8bba\uff0c\u7ed3\u5408\u5b9e\u9a8c\u542f\u53d1\u7684\u751f\u6210\u6a21\u578b\uff0c\u5728\u6a21\u62df\u6e38\u620f\u73af\u5883\u4e2d\u6a21\u62df\u51b3\u7b56\u8fc7\u7a0b\u3002", "result": "\u7ed3\u679c\u8868\u660e\u4ee3\u7406\u80fd\u591f\u5b66\u4e60\uff0c\u63ed\u793a\u4e86\u8bb0\u5fc6\u5b66\u4e60\u548c\u9884\u6d4b\u89c4\u5212\u5728\u667a\u80fd\u51b3\u7b56\u4e2d\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u53ef\u89e3\u91caAI\u9886\u57df\u63d0\u4f9b\u4e86\u57fa\u4e8e\u751f\u7269\u5b66\u7684\u53ef\u6269\u5c55\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u4ee3\u7406\u7684\u6709\u76ee\u7684\u884c\u4e3a\u3002"}}
{"id": "2508.07015", "categories": ["cs.AI", "cs.DS"], "pdf": "https://arxiv.org/pdf/2508.07015", "abs": "https://arxiv.org/abs/2508.07015", "authors": ["Hannes Ihalainen", "Dieter Vandesande", "Andr\u00e9 Schidler", "Jeremias Berg", "Bart Bogaerts", "Matti J\u00e4rvisalo"], "title": "Efficient and Reliable Hitting-Set Computations for the Implicit Hitting Set Approach", "comment": null, "summary": "The implicit hitting set (IHS) approach offers a general framework for\nsolving computationally hard combinatorial optimization problems declaratively.\nIHS iterates between a decision oracle used for extracting sources of\ninconsistency and an optimizer for computing so-called hitting sets (HSs) over\nthe accumulated sources of inconsistency. While the decision oracle is\nlanguage-specific, the optimizers is usually instantiated through integer\nprogramming.\n  We explore alternative algorithmic techniques for hitting set optimization\nbased on different ways of employing pseudo-Boolean (PB) reasoning as well as\nstochastic local search. We extensively evaluate the practical feasibility of\nthe alternatives in particular in the context of pseudo-Boolean (0-1 IP)\noptimization as one of the most recent instantiations of IHS. Highlighting a\ntrade-off between efficiency and reliability, while a commercial IP solver\nturns out to remain the most effective way to instantiate HS computations, it\ncan cause correctness issues due to numerical instability; in fact, we show\nthat exact HS computations instantiated via PB reasoning can be made\ncompetitive with a numerically exact IP solver. Furthermore, the use of PB\nreasoning as a basis for HS computations allows for obtaining certificates for\nthe correctness of IHS computations, generally applicable to any IHS\ninstantiation in which reasoning in the declarative language at hand can be\ncaptured in the PB-based proof format we employ.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u9690\u5f0f\u547d\u4e2d\u96c6\uff08IHS\uff09\u6846\u67b6\u4e2d\u66ff\u4ee3\u6574\u6570\u89c4\u5212\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u5305\u62ec\u4f2a\u5e03\u5c14\u63a8\u7406\u548c\u968f\u673a\u5c40\u90e8\u641c\u7d22\uff0c\u8bc4\u4f30\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u884c\u6027\u548c\u6548\u7387\u4e0e\u53ef\u9760\u6027\u7684\u6743\u8861\u3002", "motivation": "\u7814\u7a76IHS\u6846\u67b6\u4e2d\u66ff\u4ee3\u6574\u6570\u89c4\u5212\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u6570\u503c\u4e0d\u7a33\u5b9a\u6027\u548c\u63d0\u9ad8\u8ba1\u7b97\u6b63\u786e\u6027\u3002", "method": "\u91c7\u7528\u4f2a\u5e03\u5c14\u63a8\u7406\u548c\u968f\u673a\u5c40\u90e8\u641c\u7d22\u4f5c\u4e3a\u66ff\u4ee3\u4f18\u5316\u6280\u672f\uff0c\u5e76\u4e0e\u5546\u4e1a\u6574\u6570\u89c4\u5212\u6c42\u89e3\u5668\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5546\u4e1a\u6574\u6570\u89c4\u5212\u6c42\u89e3\u5668\u6548\u7387\u6700\u9ad8\u4f46\u5b58\u5728\u6570\u503c\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u4f2a\u5e03\u5c14\u63a8\u7406\u5728\u6b63\u786e\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u4e14\u5177\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "\u4f2a\u5e03\u5c14\u63a8\u7406\u53ef\u4f5c\u4e3aIHS\u8ba1\u7b97\u7684\u6709\u6548\u66ff\u4ee3\u65b9\u6cd5\uff0c\u63d0\u4f9b\u6b63\u786e\u6027\u8bc1\u660e\uff0c\u9002\u7528\u4e8e\u4efb\u4f55IHS\u5b9e\u4f8b\u5316\u3002"}}
{"id": "2508.07022", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2508.07022", "abs": "https://arxiv.org/abs/2508.07022", "authors": ["Shengtao Wen", "Haodong Chen", "Yadong Wang", "Zhongying Pan", "Xiang Chen", "Yu Tian", "Bo Qian", "Dong Liang", "Sheng-Jun Huang"], "title": "MultiMedEdit: A Scenario-Aware Benchmark for Evaluating Knowledge Editing in Medical VQA", "comment": "Under Review", "summary": "Knowledge editing (KE) provides a scalable approach for updating factual\nknowledge in large language models without full retraining. While previous\nstudies have demonstrated effectiveness in general domains and medical QA\ntasks, little attention has been paid to KE in multimodal medical scenarios.\nUnlike text-only settings, medical KE demands integrating updated knowledge\nwith visual reasoning to support safe and interpretable clinical decisions. To\naddress this gap, we propose MultiMedEdit, the first benchmark tailored to\nevaluating KE in clinical multimodal tasks. Our framework spans both\nunderstanding and reasoning task types, defines a three-dimensional metric\nsuite (reliability, generality, and locality), and supports cross-paradigm\ncomparisons across general and domain-specific models. We conduct extensive\nexperiments under single-editing and lifelong-editing settings. Results suggest\nthat current methods struggle with generalization and long-tail reasoning,\nparticularly in complex clinical workflows. We further present an efficiency\nanalysis (e.g., edit latency, memory footprint), revealing practical trade-offs\nin real-world deployment across KE paradigms. Overall, MultiMedEdit not only\nreveals the limitations of current approaches but also provides a solid\nfoundation for developing clinically robust knowledge editing techniques in the\nfuture.", "AI": {"tldr": "MultiMedEdit\u662f\u9996\u4e2a\u9488\u5bf9\u4e34\u5e8a\u591a\u6a21\u6001\u4efb\u52a1\u7684\u77e5\u8bc6\u7f16\u8f91\uff08KE\uff09\u57fa\u51c6\uff0c\u586b\u8865\u4e86\u591a\u6a21\u6001\u533b\u5b66\u573a\u666f\u4e2dKE\u7814\u7a76\u7684\u7a7a\u767d\uff0c\u5e76\u63ed\u793a\u4e86\u5f53\u524d\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u7f16\u8f91\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u901a\u7528\u9886\u57df\u548c\u533b\u5b66QA\u4efb\u52a1\uff0c\u800c\u591a\u6a21\u6001\u533b\u5b66\u573a\u666f\u4e2d\u7684KE\u7814\u7a76\u4e0d\u8db3\uff0c\u9700\u8981\u7ed3\u5408\u89c6\u89c9\u63a8\u7406\u652f\u6301\u4e34\u5e8a\u51b3\u7b56\u3002", "method": "\u63d0\u51faMultiMedEdit\u6846\u67b6\uff0c\u6db5\u76d6\u7406\u89e3\u548c\u63a8\u7406\u4efb\u52a1\u7c7b\u578b\uff0c\u5b9a\u4e49\u4e09\u7ef4\u5ea6\u91cf\u6807\u51c6\uff08\u53ef\u9760\u6027\u3001\u901a\u7528\u6027\u3001\u5c40\u90e8\u6027\uff09\uff0c\u5e76\u652f\u6301\u8de8\u8303\u5f0f\u6bd4\u8f83\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u5f53\u524d\u65b9\u6cd5\u5728\u6cdb\u5316\u548c\u957f\u5c3e\u63a8\u7406\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u5c24\u5176\u5728\u590d\u6742\u4e34\u5e8a\u5de5\u4f5c\u6d41\u4e2d\u3002\u6548\u7387\u5206\u6790\u63ed\u793a\u4e86\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u6743\u8861\u3002", "conclusion": "MultiMedEdit\u4e3a\u672a\u6765\u5f00\u53d1\u4e34\u5e8a\u9c81\u68d2\u7684\u77e5\u8bc6\u7f16\u8f91\u6280\u672f\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5e76\u63ed\u793a\u4e86\u5f53\u524d\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002"}}
{"id": "2508.07043", "categories": ["cs.AI", "cs.MA", "q-bio.GN", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2508.07043", "abs": "https://arxiv.org/abs/2508.07043", "authors": ["Orion Li", "Vinayak Agarwal", "Summer Zhou", "Ashwin Gopinath", "Timothy Kassis"], "title": "K-Dense Analyst: Towards Fully Automated Scientific Analysis", "comment": null, "summary": "The complexity of modern bioinformatics analysis has created a critical gap\nbetween data generation and developing scientific insights. While large\nlanguage models (LLMs) have shown promise in scientific reasoning, they remain\nfundamentally limited when dealing with real-world analytical workflows that\ndemand iterative computation, tool integration and rigorous validation. We\nintroduce K-Dense Analyst, a hierarchical multi-agent system that achieves\nautonomous bioinformatics analysis through a dual-loop architecture. K-Dense\nAnalyst, part of the broader K-Dense platform, couples planning with validated\nexecution using specialized agents to decompose complex objectives into\nexecutable, verifiable tasks within secure computational environments. On\nBixBench, a comprehensive benchmark for open-ended biological analysis, K-Dense\nAnalyst achieves 29.2% accuracy, surpassing the best-performing language model\n(GPT-5) by 6.3 percentage points, representing nearly 27% improvement over what\nis widely considered the most powerful LLM available. Remarkably, K-Dense\nAnalyst achieves this performance using Gemini 2.5 Pro, which attains only\n18.3% accuracy when used directly, demonstrating that our architectural\ninnovations unlock capabilities far beyond the underlying model's baseline\nperformance. Our insights demonstrate that autonomous scientific reasoning\nrequires more than enhanced language models, it demands purpose-built systems\nthat can bridge the gap between high-level scientific objectives and low-level\ncomputational execution. These results represent a significant advance toward\nfully autonomous computational biologists capable of accelerating discovery\nacross the life sciences.", "AI": {"tldr": "K-Dense Analyst\u662f\u4e00\u79cd\u5206\u5c42\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u53cc\u5faa\u73af\u67b6\u6784\u5b9e\u73b0\u81ea\u4e3b\u751f\u7269\u4fe1\u606f\u5b66\u5206\u6790\uff0c\u6027\u80fd\u8d85\u8d8a\u6700\u4f73\u8bed\u8a00\u6a21\u578bGPT-5\u3002", "motivation": "\u73b0\u4ee3\u751f\u7269\u4fe1\u606f\u5b66\u5206\u6790\u7684\u590d\u6742\u6027\u5bfc\u81f4\u6570\u636e\u751f\u6210\u4e0e\u79d1\u5b66\u6d1e\u5bdf\u4e4b\u95f4\u5b58\u5728\u5173\u952e\u5dee\u8ddd\uff0c\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u5728\u771f\u5b9e\u5206\u6790\u6d41\u7a0b\u4e2d\u5b58\u5728\u5c40\u9650\u3002", "method": "\u91c7\u7528\u5206\u5c42\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u53cc\u5faa\u73af\u67b6\u6784\u5c06\u590d\u6742\u76ee\u6807\u5206\u89e3\u4e3a\u53ef\u6267\u884c\u3001\u53ef\u9a8c\u8bc1\u7684\u4efb\u52a1\u3002", "result": "\u5728BixBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cK-Dense Analyst\u51c6\u786e\u7387\u8fbe29.2%\uff0c\u6bd4GPT-5\u9ad86.3\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u81ea\u4e3b\u79d1\u5b66\u63a8\u7406\u9700\u8981\u4e13\u95e8\u6784\u5efa\u7684\u7cfb\u7edf\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u589e\u5f3a\u7684\u8bed\u8a00\u6a21\u578b\u3002"}}
{"id": "2508.07063", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07063", "abs": "https://arxiv.org/abs/2508.07063", "authors": ["Naseem Machlovi", "Maryam Saleki", "Innocent Ababio", "Ruhul Amin"], "title": "Towards Safer AI Moderation: Evaluating LLM Moderators Through a Unified Benchmark Dataset and Advocating a Human-First Approach", "comment": null, "summary": "As AI systems become more integrated into daily life, the need for safer and\nmore reliable moderation has never been greater. Large Language Models (LLMs)\nhave demonstrated remarkable capabilities, surpassing earlier models in\ncomplexity and performance. Their evaluation across diverse tasks has\nconsistently showcased their potential, enabling the development of adaptive\nand personalized agents. However, despite these advancements, LLMs remain prone\nto errors, particularly in areas requiring nuanced moral reasoning. They\nstruggle with detecting implicit hate, offensive language, and gender biases\ndue to the subjective and context-dependent nature of these issues. Moreover,\ntheir reliance on training data can inadvertently reinforce societal biases,\nleading to inconsistencies and ethical concerns in their outputs. To explore\nthe limitations of LLMs in this role, we developed an experimental framework\nbased on state-of-the-art (SOTA) models to assess human emotions and offensive\nbehaviors. The framework introduces a unified benchmark dataset encompassing 49\ndistinct categories spanning the wide spectrum of human emotions, offensive and\nhateful text, and gender and racial biases. Furthermore, we introduced SafePhi,\na QLoRA fine-tuned version of Phi-4, adapting diverse ethical contexts and\noutperforming benchmark moderators by achieving a Macro F1 score of 0.89, where\nOpenAI Moderator and Llama Guard score 0.77 and 0.74, respectively. This\nresearch also highlights the critical domains where LLM moderators consistently\nunderperformed, pressing the need to incorporate more heterogeneous and\nrepresentative data with human-in-the-loop, for better model robustness and\nexplainability.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5185\u5bb9\u5ba1\u6838\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u9a8c\u6846\u67b6\u548cSafePhi\u6a21\u578b\uff0c\u4ee5\u6539\u8fdb\u5bf9\u60c5\u611f\u3001\u653b\u51fb\u6027\u8bed\u8a00\u548c\u504f\u89c1\u7684\u68c0\u6d4b\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u5728\u65e5\u5e38\u751f\u6d3b\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5bf9\u66f4\u5b89\u5168\u3001\u53ef\u9760\u7684\u5185\u5bb9\u5ba1\u6838\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u4f46LLMs\u5728\u9053\u5fb7\u63a8\u7406\u548c\u504f\u89c1\u68c0\u6d4b\u65b9\u9762\u4ecd\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eSOTA\u6a21\u578b\u7684\u5b9e\u9a8c\u6846\u67b6\uff0c\u5e76\u5f15\u5165\u7edf\u4e00\u57fa\u51c6\u6570\u636e\u96c6\u548cSafePhi\uff08QLoRA\u5fae\u8c03\u7684Phi-4\u7248\u672c\uff09\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "SafePhi\u5728Macro F1\u5f97\u5206\u4e0a\u8fbe\u52300.89\uff0c\u4f18\u4e8eOpenAI Moderator\uff080.77\uff09\u548cLlama Guard\uff080.74\uff09\uff0c\u4f46\u5728\u67d0\u4e9b\u9886\u57df\u4ecd\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86LLMs\u5728\u5185\u5bb9\u5ba1\u6838\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5efa\u8bae\u5f15\u5165\u66f4\u591a\u5f02\u6784\u6570\u636e\u548c\u4eba\u7c7b\u53c2\u4e0e\uff0c\u4ee5\u63d0\u9ad8\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2508.07107", "categories": ["cs.AI", "cs.CY", "K.3.1; I.2.6; H.4"], "pdf": "https://arxiv.org/pdf/2508.07107", "abs": "https://arxiv.org/abs/2508.07107", "authors": ["Timothy Oluwapelumi Adeyemi", "Nadiah Fahad AlOtaibi"], "title": "Designing a Feedback-Driven Decision Support System for Dynamic Student Intervention", "comment": "10 pages, 1 figure, 3 tables", "summary": "Accurate prediction of student performance is essential for timely academic\nintervention. However, most machine learning models in education are static and\ncannot adapt when new data, such as post-intervention outcomes, become\navailable. To address this limitation, we propose a Feedback-Driven Decision\nSupport System (DSS) with a closed-loop architecture that enables continuous\nmodel refinement. The system integrates a LightGBM-based regressor with\nincremental retraining, allowing educators to input updated student results,\nwhich automatically trigger model updates. This adaptive mechanism improves\nprediction accuracy by learning from real-world academic progress. The platform\nfeatures a Flask-based web interface for real-time interaction and incorporates\nSHAP for explainability, ensuring transparency. Experimental results show a\n10.7\\% reduction in RMSE after retraining, with consistent upward adjustments\nin predicted scores for intervened students. By transforming static predictors\ninto self-improving systems, our approach advances educational analytics toward\nhuman-centered, data-driven, and responsive AI. The framework is designed for\nintegration into LMS and institutional dashboards.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53cd\u9988\u9a71\u52a8\u7684\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\uff08DSS\uff09\uff0c\u901a\u8fc7\u95ed\u73af\u67b6\u6784\u5b9e\u73b0\u6301\u7eed\u6a21\u578b\u4f18\u5316\uff0c\u63d0\u5347\u5b66\u751f\u6210\u7ee9\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u6a21\u578b\u591a\u4e3a\u9759\u6001\uff0c\u65e0\u6cd5\u9002\u5e94\u65b0\u6570\u636e\uff08\u5982\u5e72\u9884\u540e\u7ed3\u679c\uff09\uff0c\u9650\u5236\u4e86\u9884\u6d4b\u7684\u53ca\u65f6\u6027\u548c\u51c6\u786e\u6027\u3002", "method": "\u7cfb\u7edf\u7ed3\u5408LightGBM\u56de\u5f52\u5668\u548c\u589e\u91cf\u8bad\u7ec3\uff0c\u652f\u6301\u5b9e\u65f6\u8f93\u5165\u66f4\u65b0\u6570\u636e\u5e76\u81ea\u52a8\u89e6\u53d1\u6a21\u578b\u66f4\u65b0\uff0c\u91c7\u7528Flask\u754c\u9762\u548cSHAP\u89e3\u91ca\u5de5\u5177\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u7ecf\u8fc7\u91cd\u65b0\u8bad\u7ec3\u540eRMSE\u964d\u4f4e10.7%\uff0c\u5e72\u9884\u5b66\u751f\u7684\u9884\u6d4b\u5206\u6570\u6301\u7eed\u4e0a\u8c03\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c06\u9759\u6001\u9884\u6d4b\u5668\u8f6c\u53d8\u4e3a\u81ea\u4f18\u5316\u7cfb\u7edf\uff0c\u63a8\u52a8\u4e86\u6559\u80b2\u5206\u6790\u5411\u4ee5\u4eba\u4e3a\u672c\u3001\u6570\u636e\u9a71\u52a8\u548c\u54cd\u5e94\u5f0fAI\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.07186", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.07186", "abs": "https://arxiv.org/abs/2508.07186", "authors": ["Amit Dhanda"], "title": "Multi-Dimensional Summarization Agents with Context-Aware Reasoning over Enterprise Tables", "comment": null, "summary": "We propose a novel framework for summarizing structured enterprise data\nacross multiple dimensions using large language model (LLM)-based agents.\nTraditional table-to-text models often lack the capacity to reason across\nhierarchical structures and context-aware deltas, which are essential in\nbusiness reporting tasks. Our method introduces a multi-agent pipeline that\nextracts, analyzes, and summarizes multi-dimensional data using agents for\nslicing, variance detection, context construction, and LLM-based generation.\nOur results show that the proposed framework outperforms traditional\napproaches, achieving 83\\% faithfulness to underlying data, superior coverage\nof significant changes, and high relevance scores (4.4/5) for decision-critical\ninsights. The improvements are especially pronounced in categories involving\nsubtle trade-offs, such as increased revenue due to price changes amid\ndeclining unit volumes, which competing methods either overlook or address with\nlimited specificity. We evaluate the framework on Kaggle datasets and\ndemonstrate significant improvements in faithfulness, relevance, and insight\nquality over baseline table summarization approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u8de8\u7ef4\u5ea6\u7ed3\u6784\u5316\u4f01\u4e1a\u6570\u636e\u6458\u8981\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u8868\u683c\u5230\u6587\u672c\u6a21\u578b\u5728\u8de8\u5c42\u6b21\u7ed3\u6784\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u5dee\u5f02\u65b9\u9762\u80fd\u529b\u4e0d\u8db3\uff0c\u96be\u4ee5\u6ee1\u8db3\u5546\u4e1a\u62a5\u544a\u9700\u6c42\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u7ba1\u9053\uff0c\u5305\u62ec\u6570\u636e\u5207\u7247\u3001\u65b9\u5dee\u68c0\u6d4b\u3001\u4e0a\u4e0b\u6587\u6784\u5efa\u548cLLM\u751f\u6210\u3002", "result": "\u6846\u67b6\u5728\u6570\u636e\u5fe0\u5b9e\u5ea6\uff0883%\uff09\u3001\u663e\u8457\u53d8\u5316\u8986\u76d6\u7387\u548c\u51b3\u7b56\u5173\u952e\u6d1e\u5bdf\u76f8\u5173\u6027\uff084.4/5\uff09\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728Kaggle\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6458\u8981\u7684\u5fe0\u5b9e\u6027\u3001\u76f8\u5173\u6027\u548c\u6d1e\u5bdf\u8d28\u91cf\u3002"}}
{"id": "2508.07292", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.07292", "abs": "https://arxiv.org/abs/2508.07292", "authors": ["Yi Tang", "Kaini Wang", "Yang Chen", "Guangquan Zhou"], "title": "EndoAgent: A Memory-Guided Reflective Agent for Intelligent Endoscopic Vision-to-Decision Reasoning", "comment": null, "summary": "Developing general artificial intelligence (AI) systems to support endoscopic\nimage diagnosis is an emerging research priority. Existing methods based on\nlarge-scale pretraining often lack unified coordination across tasks and\nstruggle to handle the multi-step processes required in complex clinical\nworkflows. While AI agents have shown promise in flexible instruction parsing\nand tool integration across domains, their potential in endoscopy remains\nunderexplored. To address this gap, we propose EndoAgent, the first\nmemory-guided agent for vision-to-decision endoscopic analysis that integrates\niterative reasoning with adaptive tool selection and collaboration. Built on a\ndual-memory design, it enables sophisticated decision-making by ensuring\nlogical coherence through short-term action tracking and progressively\nenhancing reasoning acuity through long-term experiential learning. To support\ndiverse clinical tasks, EndoAgent integrates a suite of expert-designed tools\nwithin a unified reasoning loop. We further introduce EndoAgentBench, a\nbenchmark of 5,709 visual question-answer pairs that assess visual\nunderstanding and language generation capabilities in realistic scenarios.\nExtensive experiments show that EndoAgent consistently outperforms both general\nand medical multimodal models, exhibiting its strong flexibility and reasoning\ncapabilities.", "AI": {"tldr": "EndoAgent\u662f\u4e00\u79cd\u57fa\u4e8e\u8bb0\u5fc6\u5f15\u5bfc\u7684AI\u4ee3\u7406\uff0c\u7528\u4e8e\u5185\u7aa5\u955c\u56fe\u50cf\u5206\u6790\uff0c\u7ed3\u5408\u4e86\u8fed\u4ee3\u63a8\u7406\u548c\u81ea\u9002\u5e94\u5de5\u5177\u9009\u62e9\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u591a\u6a21\u6001\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u7684\u65b9\u6cd5\u5728\u591a\u4efb\u52a1\u534f\u8c03\u548c\u590d\u6742\u4e34\u5e8a\u6d41\u7a0b\u5904\u7406\u4e0a\u8868\u73b0\u4e0d\u8db3\uff0cAI\u4ee3\u7406\u5728\u5185\u7aa5\u955c\u9886\u57df\u7684\u6f5c\u529b\u5c1a\u672a\u5145\u5206\u6316\u6398\u3002", "method": "\u63d0\u51faEndoAgent\uff0c\u91c7\u7528\u53cc\u8bb0\u5fc6\u8bbe\u8ba1\uff08\u77ed\u671f\u52a8\u4f5c\u8ddf\u8e2a\u548c\u957f\u671f\u7ecf\u9a8c\u5b66\u4e60\uff09\uff0c\u96c6\u6210\u4e13\u5bb6\u5de5\u5177\uff0c\u5e76\u5f15\u5165EndoAgentBench\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660eEndoAgent\u5728\u89c6\u89c9\u7406\u89e3\u548c\u8bed\u8a00\u751f\u6210\u4efb\u52a1\u4e0a\u4f18\u4e8e\u901a\u7528\u53ca\u533b\u5b66\u591a\u6a21\u6001\u6a21\u578b\u3002", "conclusion": "EndoAgent\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u7075\u6d3b\u6027\u548c\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u5185\u7aa5\u955c\u8bca\u65adAI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2508.07334", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07334", "abs": "https://arxiv.org/abs/2508.07334", "authors": ["Quan Shi", "Wang Xi", "Zenghui Ding", "Jianqing Gao", "Xianjun Yang"], "title": "Hallucination as a Computational Boundary: A Hierarchy of Inevitability and the Oracle Escape", "comment": "8 pages, 6 figures", "summary": "The illusion phenomenon of large language models (LLMs) is the core obstacle\nto their reliable deployment. This article formalizes the large language model\nas a probabilistic Turing machine by constructing a \"computational necessity\nhierarchy\", and for the first time proves the illusions are inevitable on\ndiagonalization, incomputability, and information theory boundaries supported\nby the new \"learner pump lemma\". However, we propose two \"escape routes\": one\nis to model Retrieval Enhanced Generations (RAGs) as oracle machines, proving\ntheir absolute escape through \"computational jumps\", providing the first formal\ntheory for the effectiveness of RAGs; The second is to formalize continuous\nlearning as an \"internalized oracle\" mechanism and implement this path through\na novel neural game theory framework.Finally, this article proposes a", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5f62\u5f0f\u5316\u5927\u8bed\u8a00\u6a21\u578b\u4e3a\u6982\u7387\u56fe\u7075\u673a\uff0c\u8bc1\u660e\u4e86\u5e7b\u89c9\u73b0\u8c61\u5728\u8ba1\u7b97\u5fc5\u8981\u6027\u5c42\u6b21\u4e0a\u7684\u4e0d\u53ef\u907f\u514d\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u79cd\u89e3\u51b3\u65b9\u6848\uff1a\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u548c\u6301\u7eed\u5b66\u4e60\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5e7b\u89c9\u73b0\u8c61\u7684\u6838\u5fc3\u969c\u788d\uff0c\u4e3a\u5176\u53ef\u9760\u90e8\u7f72\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "method": "\u6784\u5efa\u201c\u8ba1\u7b97\u5fc5\u8981\u6027\u5c42\u6b21\u201d\uff0c\u8bc1\u660e\u5e7b\u89c9\u7684\u4e0d\u53ef\u907f\u514d\u6027\uff1b\u63d0\u51faRAG\u4f5c\u4e3a\u9884\u8a00\u673a\u6a21\u578b\u548c\u6301\u7eed\u5b66\u4e60\u4f5c\u4e3a\u201c\u5185\u90e8\u5316\u9884\u8a00\u673a\u201d\u673a\u5236\u3002", "result": "\u8bc1\u660e\u4e86\u5e7b\u89c9\u73b0\u8c61\u7684\u7406\u8bba\u8fb9\u754c\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e24\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u901a\u8fc7\u5f62\u5f0f\u5316\u65b9\u6cd5\u548c\u65b0\u7406\u8bba\u6846\u67b6\uff0c\u4e3aLLMs\u7684\u53ef\u9760\u90e8\u7f72\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u548c\u5b9e\u8df5\u8def\u5f84\u3002"}}
{"id": "2508.07353", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.07353", "abs": "https://arxiv.org/abs/2508.07353", "authors": ["Rubing Chen", "Jiaxin Wu", "Jian Wang", "Xulu Zhang", "Wenqi Fan", "Chenghua Lin", "Xiao-Yong Wei", "Qing Li"], "title": "Rethinking Domain-Specific LLM Benchmark Construction: A Comprehensiveness-Compactness Approach", "comment": null, "summary": "Numerous benchmarks have been built to evaluate the domain-specific abilities\nof large language models (LLMs), highlighting the need for effective and\nefficient benchmark construction. Existing domain-specific benchmarks primarily\nfocus on the scaling law, relying on massive corpora for supervised fine-tuning\nor generating extensive question sets for broad coverage. However, the impact\nof corpus and question-answer (QA) set design on the precision and recall of\ndomain-specific LLMs remains unexplored. In this paper, we address this gap and\ndemonstrate that the scaling law is not always the optimal principle for\nbenchmark construction in specific domains. Instead, we propose Comp-Comp, an\niterative benchmarking framework based on a comprehensiveness-compactness\nprinciple. Here, comprehensiveness ensures semantic recall of the domain, while\ncompactness enhances precision, guiding both corpus and QA set construction. To\nvalidate our framework, we conducted a case study in a well-renowned\nuniversity, resulting in the creation of XUBench, a large-scale and\ncomprehensive closed-domain benchmark. Although we use the academic domain as\nthe case in this work, our Comp-Comp framework is designed to be extensible\nbeyond academia, providing valuable insights for benchmark construction across\nvarious domains.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5168\u9762\u6027-\u7d27\u51d1\u6027\u539f\u5219\u7684\u8fed\u4ee3\u5f0f\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6Comp-Comp\uff0c\u7528\u4e8e\u6784\u5efa\u9886\u57df\u7279\u5b9a\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6311\u6218\u4e86\u4f20\u7edf\u7684\u6269\u5c55\u6cd5\u5219\u3002", "motivation": "\u73b0\u6709\u9886\u57df\u7279\u5b9a\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u4f9d\u8d56\u6269\u5c55\u6cd5\u5219\uff0c\u4f46\u8bed\u6599\u5e93\u548c\u95ee\u7b54\u96c6\u8bbe\u8ba1\u5bf9\u6a21\u578b\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u7684\u5f71\u54cd\u5c1a\u672a\u88ab\u7814\u7a76\u3002", "method": "\u63d0\u51faComp-Comp\u6846\u67b6\uff0c\u901a\u8fc7\u5168\u9762\u6027\u786e\u4fdd\u8bed\u4e49\u53ec\u56de\uff0c\u7d27\u51d1\u6027\u63d0\u5347\u7cbe\u5ea6\uff0c\u6307\u5bfc\u8bed\u6599\u5e93\u548c\u95ee\u7b54\u96c6\u6784\u5efa\u3002", "result": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u6784\u5efa\u4e86XUBench\uff0c\u4e00\u4e2a\u5927\u89c4\u6a21\u3001\u5168\u9762\u7684\u5c01\u95ed\u9886\u57df\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "Comp-Comp\u6846\u67b6\u4e0d\u4ec5\u9002\u7528\u4e8e\u5b66\u672f\u9886\u57df\uff0c\u8fd8\u53ef\u6269\u5c55\u5230\u5176\u4ed6\u9886\u57df\uff0c\u4e3a\u57fa\u51c6\u6d4b\u8bd5\u6784\u5efa\u63d0\u4f9b\u65b0\u601d\u8def\u3002"}}
{"id": "2508.07382", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.07382", "abs": "https://arxiv.org/abs/2508.07382", "authors": ["He Kong", "Die Hu", "Jingguo Ge", "Liangxiong Li", "Hui Li", "Tong Li"], "title": "Pentest-R1: Towards Autonomous Penetration Testing Reasoning Optimized via Two-Stage Reinforcement Learning", "comment": null, "summary": "Automating penetration testing is crucial for enhancing cybersecurity, yet\ncurrent Large Language Models (LLMs) face significant limitations in this\ndomain, including poor error handling, inefficient reasoning, and an inability\nto perform complex end-to-end tasks autonomously. To address these challenges,\nwe introduce Pentest-R1, a novel framework designed to optimize LLM reasoning\ncapabilities for this task through a two-stage reinforcement learning pipeline.\nWe first construct a dataset of over 500 real-world, multi-step walkthroughs,\nwhich Pentest-R1 leverages for offline reinforcement learning (RL) to instill\nfoundational attack logic. Subsequently, the LLM is fine-tuned via online RL in\nan interactive Capture The Flag (CTF) environment, where it learns directly\nfrom environmental feedback to develop robust error self-correction and\nadaptive strategies. Our extensive experiments on the Cybench and AutoPenBench\nbenchmarks demonstrate the framework's effectiveness. On AutoPenBench,\nPentest-R1 achieves a 24.2\\% success rate, surpassing most state-of-the-art\nmodels and ranking second only to Gemini 2.5 Flash. On Cybench, it attains a\n15.0\\% success rate in unguided tasks, establishing a new state-of-the-art for\nopen-source LLMs and matching the performance of top proprietary models.\nAblation studies confirm that the synergy of both training stages is critical\nto its success.", "AI": {"tldr": "Pentest-R1\u662f\u4e00\u4e2a\u901a\u8fc7\u4e24\u9636\u6bb5\u5f3a\u5316\u5b66\u4e60\u4f18\u5316LLM\u5728\u6e17\u900f\u6d4b\u8bd5\u4e2d\u63a8\u7406\u80fd\u529b\u7684\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4efb\u52a1\u6210\u529f\u7387\u3002", "motivation": "\u5f53\u524dLLM\u5728\u6e17\u900f\u6d4b\u8bd5\u4e2d\u5b58\u5728\u9519\u8bef\u5904\u7406\u3001\u63a8\u7406\u6548\u7387\u548c\u590d\u6742\u4efb\u52a1\u81ea\u4e3b\u6267\u884c\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0cPentest-R1\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u5f3a\u5316\u5b66\u4e60\uff1a\u79bb\u7ebfRL\u5b66\u4e60\u57fa\u7840\u653b\u51fb\u903b\u8f91\uff0c\u5728\u7ebfRL\u5728CTF\u73af\u5883\u4e2d\u901a\u8fc7\u73af\u5883\u53cd\u9988\u5fae\u8c03\u6a21\u578b\u3002", "result": "\u5728AutoPenBench\u4e0a\u6210\u529f\u738724.2%\uff0cCybench\u4e0a15.0%\uff0c\u6027\u80fd\u63a5\u8fd1\u9876\u7ea7\u4e13\u6709\u6a21\u578b\u3002", "conclusion": "\u4e24\u9636\u6bb5\u8bad\u7ec3\u534f\u540c\u4f5c\u7528\u5bf9Pentest-R1\u7684\u6210\u529f\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2508.07388", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07388", "abs": "https://arxiv.org/abs/2508.07388", "authors": ["Zhaoyu Chen", "Hongnan Lin", "Yongwei Nie", "Fei Ma", "Xuemiao Xu", "Fei Yu", "Chengjiang Long"], "title": "Invert4TVG: A Temporal Video Grounding Framework with Inversion Tasks for Enhanced Action Understanding", "comment": null, "summary": "Temporal Video Grounding (TVG) seeks to localize video segments matching a\ngiven textual query. Current methods, while optimizing for high temporal\nIntersection-over-Union (IoU), often overfit to this metric, compromising\nsemantic action understanding in the video and query, a critical factor for\nrobust TVG. To address this, we introduce Inversion Tasks for TVG (Invert4TVG),\na novel framework that enhances both localization accuracy and action\nunderstanding without additional data. Our approach leverages three inversion\ntasks derived from existing TVG annotations: (1) Verb Completion, predicting\nmasked action verbs in queries from video segments; (2) Action Recognition,\nidentifying query-described actions; and (3) Video Description, generating\ndescriptions of video segments that explicitly embed query-relevant actions.\nThese tasks, integrated with TVG via a reinforcement learning framework with\nwell-designed reward functions, ensure balanced optimization of localization\nand semantics. Experiments show our method outperforms state-of-the-art\napproaches, achieving a 7.1\\% improvement in R1@0.7 on Charades-STA for a 3B\nmodel compared to Time-R1. By inverting TVG to derive query-related actions\nfrom segments, our approach strengthens semantic understanding, significantly\nraising the ceiling of localization accuracy.", "AI": {"tldr": "Invert4TVG\u6846\u67b6\u901a\u8fc7\u4e09\u4e2a\u53cd\u8f6c\u4efb\u52a1\uff08\u52a8\u8bcd\u8865\u5168\u3001\u52a8\u4f5c\u8bc6\u522b\u548c\u89c6\u9891\u63cf\u8ff0\uff09\u589e\u5f3a\u89c6\u9891\u7247\u6bb5\u5b9a\u4f4d\u548c\u8bed\u4e49\u7406\u89e3\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b9a\u4f4d\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u8fc7\u5ea6\u4f18\u5316\u65f6\u95f4IoU\uff0c\u727a\u7272\u4e86\u8bed\u4e49\u52a8\u4f5c\u7406\u89e3\uff0c\u5f71\u54cd\u4e86TVG\u7684\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51faInvert4TVG\u6846\u67b6\uff0c\u7ed3\u5408\u4e09\u4e2a\u53cd\u8f6c\u4efb\u52a1\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u5e73\u8861\u5b9a\u4f4d\u548c\u8bed\u4e49\u4f18\u5316\u3002", "result": "\u5728Charades-STA\u6570\u636e\u96c6\u4e0a\uff0cR1@0.7\u6307\u6807\u6bd4Time-R1\u63d0\u5347\u4e867.1%\u3002", "conclusion": "\u901a\u8fc7\u53cd\u8f6c\u4efb\u52a1\u589e\u5f3a\u8bed\u4e49\u7406\u89e3\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5b9a\u4f4d\u51c6\u786e\u6027\u7684\u4e0a\u9650\u3002"}}
{"id": "2508.07405", "categories": ["cs.AI", "cs.CL", "cs.LG", "I.2.7; I.5.4"], "pdf": "https://arxiv.org/pdf/2508.07405", "abs": "https://arxiv.org/abs/2508.07405", "authors": ["Jesse Ponnock"], "title": "Generative AI for Strategic Plan Development", "comment": "11 pages, 9 figures", "summary": "Given recent breakthroughs in Generative Artificial Intelligence (GAI) and\nLarge Language Models (LLMs), more and more professional services are being\naugmented through Artificial Intelligence (AI), which once seemed impossible to\nautomate. This paper presents a modular model for leveraging GAI in developing\nstrategic plans for large scale government organizations and evaluates leading\nmachine learning techniques in their application towards one of the identified\nmodules. Specifically, the performance of BERTopic and Non-negative Matrix\nFactorization (NMF) are evaluated in their ability to use topic modeling to\ngenerate themes representative of Vision Elements within a strategic plan. To\naccomplish this, BERTopic and NMF models are trained using a large volume of\nreports from the Government Accountability Office (GAO). The generated topics\nfrom each model are then scored for similarity against the Vision Elements of a\npublished strategic plan and the results are compared. Our results show that\nthese techniques are capable of generating themes similar to 100% of the\nelements being evaluated against. Further, we conclude that BERTopic performs\nbest in this application with more than half of its correlated topics achieving\na \"medium\" or \"strong\" correlation. A capability of GAI-enabled strategic plan\ndevelopment impacts a multi-billion dollar industry and assists the federal\ngovernment in overcoming regulatory requirements which are crucial to the\npublic good. Further work will focus on the operationalization of the concept\nproven in this study as well as viability of the remaining modules in the\nproposed model for GAI-generated strategic plans.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08GAI\uff09\u4e3a\u5927\u578b\u653f\u5e9c\u7ec4\u7ec7\u5236\u5b9a\u6218\u7565\u8ba1\u5212\u7684\u6a21\u5757\u5316\u6a21\u578b\uff0c\u5e76\u8bc4\u4f30\u4e86BERTopic\u548cNMF\u5728\u4e3b\u9898\u5efa\u6a21\u4e2d\u7684\u8868\u73b0\u3002\u7ed3\u679c\u663e\u793a\uff0c\u8fd9\u4e9b\u6280\u672f\u80fd\u751f\u6210\u4e0e\u6218\u7565\u8ba1\u5212\u613f\u666f\u5143\u7d20\u76f8\u4f3c\u7684\u4e3b\u9898\uff0cBERTopic\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08GAI\uff09\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u7a81\u7834\uff0c\u8d8a\u6765\u8d8a\u591a\u7684\u4e13\u4e1a\u670d\u52a1\u901a\u8fc7AI\u589e\u5f3a\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u5229\u7528GAI\u4e3a\u653f\u5e9c\u7ec4\u7ec7\u5f00\u53d1\u6218\u7565\u8ba1\u5212\u3002", "method": "\u4f7f\u7528BERTopic\u548cNMF\u6a21\u578b\u5bf9\u653f\u5e9c\u95ee\u8d23\u529e\u516c\u5ba4\uff08GAO\uff09\u7684\u5927\u91cf\u62a5\u544a\u8fdb\u884c\u4e3b\u9898\u5efa\u6a21\uff0c\u751f\u6210\u4e0e\u6218\u7565\u8ba1\u5212\u613f\u666f\u5143\u7d20\u76f8\u4f3c\u7684\u4e3b\u9898\uff0c\u5e76\u6bd4\u8f83\u5176\u6027\u80fd\u3002", "result": "BERTopic\u548cNMF\u80fd\u751f\u6210\u4e0e100%\u7684\u613f\u666f\u5143\u7d20\u76f8\u4f3c\u7684\u4e3b\u9898\uff0c\u5176\u4e2dBERTopic\u8868\u73b0\u66f4\u4f18\uff0c\u8d85\u8fc7\u4e00\u534a\u7684\u4e3b\u9898\u8fbe\u5230\u201c\u4e2d\u7b49\u201d\u6216\u201c\u5f3a\u201d\u76f8\u5173\u6027\u3002", "conclusion": "GAI\u652f\u6301\u7684\u6218\u7565\u8ba1\u5212\u5f00\u53d1\u5bf9\u6570\u5341\u4ebf\u7f8e\u5143\u7684\u884c\u4e1a\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u5e76\u5e2e\u52a9\u8054\u90a6\u653f\u5e9c\u6ee1\u8db3\u5173\u952e\u516c\u5171\u5229\u76ca\u6cd5\u89c4\u3002\u672a\u6765\u5de5\u4f5c\u5c06\u805a\u7126\u4e8e\u6a21\u578b\u7684\u5b9e\u9645\u5e94\u7528\u548c\u5269\u4f59\u6a21\u5757\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2508.07407", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.07407", "abs": "https://arxiv.org/abs/2508.07407", "authors": ["Jinyuan Fang", "Yanwen Peng", "Xi Zhang", "Yingxu Wang", "Xinhao Yi", "Guibin Zhang", "Yi Xu", "Bin Wu", "Siwei Liu", "Zihao Li", "Zhaochun Ren", "Nikos Aletras", "Xi Wang", "Han Zhou", "Zaiqiao Meng"], "title": "A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems", "comment": null, "summary": "Recent advances in large language models have sparked growing interest in AI\nagents capable of solving complex, real-world tasks. However, most existing\nagent systems rely on manually crafted configurations that remain static after\ndeployment, limiting their ability to adapt to dynamic and evolving\nenvironments. To this end, recent research has explored agent evolution\ntechniques that aim to automatically enhance agent systems based on interaction\ndata and environmental feedback. This emerging direction lays the foundation\nfor self-evolving AI agents, which bridge the static capabilities of foundation\nmodels with the continuous adaptability required by lifelong agentic systems.\nIn this survey, we provide a comprehensive review of existing techniques for\nself-evolving agentic systems. Specifically, we first introduce a unified\nconceptual framework that abstracts the feedback loop underlying the design of\nself-evolving agentic systems. The framework highlights four key components:\nSystem Inputs, Agent System, Environment, and Optimisers, serving as a\nfoundation for understanding and comparing different strategies. Based on this\nframework, we systematically review a wide range of self-evolving techniques\nthat target different components of the agent system. We also investigate\ndomain-specific evolution strategies developed for specialised fields such as\nbiomedicine, programming, and finance, where optimisation objectives are\ntightly coupled with domain constraints. In addition, we provide a dedicated\ndiscussion on the evaluation, safety, and ethical considerations for\nself-evolving agentic systems, which are critical to ensuring their\neffectiveness and reliability. This survey aims to provide researchers and\npractitioners with a systematic understanding of self-evolving AI agents,\nlaying the foundation for the development of more adaptive, autonomous, and\nlifelong agentic systems.", "AI": {"tldr": "\u7efc\u8ff0\u4e86\u81ea\u8fdb\u5316AI\u4ee3\u7406\u7cfb\u7edf\u7684\u73b0\u6709\u6280\u672f\uff0c\u63d0\u51fa\u4e86\u7edf\u4e00\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u5e76\u63a2\u8ba8\u4e86\u8bc4\u4f30\u3001\u5b89\u5168\u4e0e\u4f26\u7406\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u4ee3\u7406\u7cfb\u7edf\u4f9d\u8d56\u9759\u6001\u914d\u7f6e\uff0c\u65e0\u6cd5\u9002\u5e94\u52a8\u6001\u73af\u5883\uff0c\u9700\u7814\u7a76\u81ea\u8fdb\u5316\u6280\u672f\u4ee5\u63d0\u5347\u9002\u5e94\u6027\u3002", "method": "\u63d0\u51fa\u5305\u542b\u56db\u4e2a\u5173\u952e\u7ec4\u4ef6\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u7cfb\u7edf\u56de\u987e\u9488\u5bf9\u4e0d\u540c\u7ec4\u4ef6\u7684\u81ea\u8fdb\u5316\u6280\u672f\uff0c\u5e76\u63a2\u8ba8\u9886\u57df\u4e13\u7528\u7b56\u7565\u3002", "result": "\u603b\u7ed3\u4e86\u591a\u79cd\u81ea\u8fdb\u5316\u6280\u672f\u53ca\u5176\u5e94\u7528\u9886\u57df\uff0c\u5f3a\u8c03\u4e86\u8bc4\u4f30\u3001\u5b89\u5168\u4e0e\u4f26\u7406\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u4e3a\u5f00\u53d1\u66f4\u81ea\u9002\u5e94\u3001\u81ea\u4e3b\u548c\u7ec8\u8eab\u4ee3\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u57fa\u7840\u3002"}}
{"id": "2508.07466", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07466", "abs": "https://arxiv.org/abs/2508.07466", "authors": ["Dom Huh", "Prasant Mohapatra"], "title": "Grounding Natural Language for Multi-agent Decision-Making with Multi-agentic LLMs", "comment": null, "summary": "Language is a ubiquitous tool that is foundational to reasoning and\ncollaboration, ranging from everyday interactions to sophisticated\nproblem-solving tasks. The establishment of a common language can serve as a\npowerful asset in ensuring clear communication and understanding amongst\nagents, facilitating desired coordination and strategies. In this work, we\nextend the capabilities of large language models (LLMs) by integrating them\nwith advancements in multi-agent decision-making algorithms. We propose a\nsystematic framework for the design of multi-agentic large language models\n(LLMs), focusing on key integration practices. These include advanced prompt\nengineering techniques, the development of effective memory architectures,\nmulti-modal information processing, and alignment strategies through\nfine-tuning algorithms. We evaluate these design choices through extensive\nablation studies on classic game settings with significant underlying social\ndilemmas and game-theoretic considerations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7cfb\u7edf\u6027\u6846\u67b6\uff0c\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0e\u591a\u667a\u80fd\u4f53\u51b3\u7b56\u7b97\u6cd5\u7ed3\u5408\uff0c\u4ee5\u63d0\u5347\u534f\u4f5c\u4e0e\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u8bed\u8a00\u662f\u534f\u4f5c\u4e0e\u63a8\u7406\u7684\u57fa\u7840\uff0c\u5efa\u7acb\u5171\u540c\u8bed\u8a00\u6709\u52a9\u4e8e\u667a\u80fd\u4f53\u95f4\u7684\u6e05\u6670\u6c9f\u901a\u4e0e\u534f\u8c03\u3002", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53LLMs\u7684\u8bbe\u8ba1\u6846\u67b6\uff0c\u5305\u62ec\u9ad8\u7ea7\u63d0\u793a\u5de5\u7a0b\u3001\u8bb0\u5fc6\u67b6\u6784\u3001\u591a\u6a21\u6001\u4fe1\u606f\u5904\u7406\u548c\u5fae\u8c03\u5bf9\u9f50\u7b56\u7565\u3002", "result": "\u901a\u8fc7\u5728\u7ecf\u5178\u6e38\u620f\u8bbe\u7f6e\u4e2d\u7684\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8bbe\u8ba1\u9009\u62e9\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u591a\u667a\u80fd\u4f53LLMs\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u589e\u5f3a\u4e86\u534f\u4f5c\u4e0e\u51b3\u7b56\u80fd\u529b\u3002"}}
{"id": "2508.07485", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.07485", "abs": "https://arxiv.org/abs/2508.07485", "authors": ["Alexander Duffy", "Samuel J Paech", "Ishana Shastri", "Elizabeth Karpinski", "Baptiste Alloui-Cros", "Tyler Marques", "Matthew Lyle Olson"], "title": "Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy", "comment": null, "summary": "We present the first evaluation harness that enables any out-of-the-box,\nlocal, Large Language Models (LLMs) to play full-press Diplomacy without\nfine-tuning or specialized training. Previous work required frontier LLMs, or\nfine-tuning, due to the high complexity and information density of Diplomacy's\ngame state. Combined with the high variance of matches, these factors made\nDiplomacy prohibitive for study. In this work, we used data-driven iteration to\noptimize a textual game state representation such that a 24B model can reliably\ncomplete matches without any fine tuning. We develop tooling to facilitate\nhypothesis testing and statistical analysis, and we present case studies on\npersuasion, aggressive playstyles, and performance across a range of models. We\nconduct a variety of experiments across many popular LLMs, finding the larger\nmodels perform the best, but the smaller models still play adequately. We also\nintroduce Critical State Analysis: an experimental protocol for rapidly\niterating and analyzing key moments in a game at depth. Our harness\ndemocratizes the evaluation of strategic reasoning in LLMs by eliminating the\nneed for fine-tuning, and it provides insights into how these capabilities\nemerge naturally from widely used LLMs. Our code is available in the supplement\nand will be open sourced.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u8ba9\u672c\u5730\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u73a9\u5b8c\u6574\u7248\u300a\u5916\u4ea4\u300b\u6e38\u620f\u7684\u8bc4\u4f30\u5de5\u5177\uff0c\u89e3\u51b3\u4e86\u6e38\u620f\u72b6\u6001\u590d\u6742\u548c\u4fe1\u606f\u5bc6\u5ea6\u9ad8\u7684\u95ee\u9898\u3002", "motivation": "\u300a\u5916\u4ea4\u300b\u6e38\u620f\u7684\u9ad8\u590d\u6742\u6027\u548c\u4fe1\u606f\u5bc6\u5ea6\u4f7f\u5f97\u7814\u7a76\u56f0\u96be\uff0c\u9700\u8981\u524d\u6cbfLLM\u6216\u5fae\u8c03\u3002\u672c\u6587\u65e8\u5728\u6d88\u9664\u8fd9\u4e9b\u9650\u5236\uff0c\u4f7f\u66f4\u591aLLM\u80fd\u591f\u53c2\u4e0e\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u8fed\u4ee3\u4f18\u5316\u6587\u672c\u6e38\u620f\u72b6\u6001\u8868\u793a\uff0c\u5f00\u53d1\u5de5\u5177\u652f\u6301\u5047\u8bbe\u6d4b\u8bd5\u548c\u7edf\u8ba1\u5206\u6790\uff0c\u5e76\u5f15\u5165\u5173\u952e\u72b6\u6001\u5206\u6790\u534f\u8bae\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8f83\u5927\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u8f83\u5c0f\u6a21\u578b\u4e5f\u80fd\u80dc\u4efb\u3002\u5de5\u5177\u6210\u529f\u5b9e\u73b0\u4e86\u65e0\u9700\u5fae\u8c03\u7684\u8bc4\u4f30\u3002", "conclusion": "\u8be5\u5de5\u5177\u964d\u4f4e\u4e86\u6218\u7565\u63a8\u7406\u8bc4\u4f30\u7684\u95e8\u69db\uff0c\u63ed\u793a\u4e86LLM\u81ea\u7136\u5177\u5907\u7684\u80fd\u529b\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2508.07575", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07575", "abs": "https://arxiv.org/abs/2508.07575", "authors": ["Shiqing Fan", "Xichen Ding", "Liang Zhang", "Linjian Mo"], "title": "MCPToolBench++: A Large Scale AI Agent Model Context Protocol MCP Tool Use Benchmark", "comment": "Benchmarks and Source Code Released", "summary": "LLMs' capabilities are enhanced by using function calls to integrate various\ndata sources or API results into the context window. Typical tools include\nsearch, web crawlers, maps, financial data, file systems, and browser usage,\netc. Integrating these data sources or functions requires a standardized\nmethod. The Model Context Protocol (MCP) provides a standardized way to supply\ncontext to LLMs. However, the evaluation of LLMs and AI Agents' MCP tool use\nabilities suffer from several issues. First, there's a lack of comprehensive\ndatasets or benchmarks to evaluate various MCP tools. Second, the diverse\nformats of response from MCP tool call execution further increase the\ndifficulty of evaluation. Additionally, unlike existing tool-use benchmarks\nwith high success rates in functions like programming and math functions, the\nsuccess rate of real-world MCP tool is not guaranteed and varies across\ndifferent MCP servers. Furthermore, the LLMs' context window also limits the\nnumber of available tools that can be called in a single run, because the\ntextual descriptions of tool and the parameters have long token length for an\nLLM to process all at once. To help address the challenges of evaluating LLMs'\nperformance on calling MCP tools, we propose MCPToolBench++, a large-scale,\nmulti-domain AI Agent tool use benchmark. As of July 2025, this benchmark is\nbuild upon marketplace of over 4k MCP servers from more than 40 categories,\ncollected from the MCP marketplaces and GitHub communities. The datasets\nconsist of both single-step and multi-step tool calls across different\ncategories. We evaluated SOTA LLMs with agentic abilities on this benchmark and\nreported the results.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86MCPToolBench++\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30LLMs\u8c03\u7528MCP\u5de5\u5177\u6027\u80fd\u7684\u5927\u89c4\u6a21\u591a\u9886\u57df\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30LLMs\u548cAI Agents\u4f7f\u7528MCP\u5de5\u5177\u7684\u80fd\u529b\u5b58\u5728\u6570\u636e\u96c6\u4e0d\u5168\u9762\u3001\u54cd\u5e94\u683c\u5f0f\u591a\u6837\u3001\u6210\u529f\u7387\u4e0d\u7a33\u5b9a\u7b49\u95ee\u9898\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u57fa\u4e8e4000\u591a\u4e2aMCP\u670d\u52a1\u5668\u7684\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6\u5355\u6b65\u548c\u591a\u6b65\u5de5\u5177\u8c03\u7528\u3002", "result": "\u8bc4\u4f30\u4e86\u5177\u6709\u4ee3\u7406\u80fd\u529b\u7684SOTA LLMs\uff0c\u5e76\u62a5\u544a\u4e86\u7ed3\u679c\u3002", "conclusion": "MCPToolBench++\u4e3a\u8bc4\u4f30LLMs\u5728MCP\u5de5\u5177\u8c03\u7528\u4e2d\u7684\u6027\u80fd\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.07586", "categories": ["cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2508.07586", "abs": "https://arxiv.org/abs/2508.07586", "authors": ["Wenjing Zhang", "Ye Hu", "Tao Luo", "Zhilong Zhang", "Mingzhe Chen"], "title": "Optimization of Private Semantic Communication Performance: An Uncooperative Covert Communication Method", "comment": null, "summary": "In this paper, a novel covert semantic communication framework is\ninvestigated. Within this framework, a server extracts and transmits the\nsemantic information, i.e., the meaning of image data, to a user over several\ntime slots. An attacker seeks to detect and eavesdrop the semantic transmission\nto acquire details of the original image. To avoid data meaning being\neavesdropped by an attacker, a friendly jammer is deployed to transmit jamming\nsignals to interfere the attacker so as to hide the transmitted semantic\ninformation. Meanwhile, the server will strategically select time slots for\nsemantic information transmission. Due to limited energy, the jammer will not\ncommunicate with the server and hence the server does not know the transmit\npower of the jammer. Therefore, the server must jointly optimize the semantic\ninformation transmitted at each time slot and the corresponding transmit power\nto maximize the privacy and the semantic information transmission quality of\nthe user. To solve this problem, we propose a prioritised sampling assisted\ntwin delayed deep deterministic policy gradient algorithm to jointly determine\nthe transmitted semantic information and the transmit power per time slot\nwithout the communications between the server and the jammer. Compared to\nstandard reinforcement learning methods, the propose method uses an additional\nQ network to estimate Q values such that the agent can select the action with a\nlower Q value from the two Q networks thus avoiding local optimal action\nselection and estimation bias of Q values. Simulation results show that the\nproposed algorithm can improve the privacy and the semantic information\ntransmission quality by up to 77.8% and 14.3% compared to the traditional\nreinforcement learning methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u9690\u853d\u8bed\u4e49\u901a\u4fe1\u6846\u67b6\uff0c\u901a\u8fc7\u53cb\u597d\u5e72\u6270\u5668\u548c\u65f6\u95f4\u69fd\u4f18\u5316\u6765\u4fdd\u62a4\u8bed\u4e49\u4fe1\u606f\u4f20\u8f93\uff0c\u907f\u514d\u88ab\u653b\u51fb\u8005\u7a83\u53d6\u3002", "motivation": "\u89e3\u51b3\u8bed\u4e49\u4fe1\u606f\u4f20\u8f93\u4e2d\u6613\u88ab\u653b\u51fb\u8005\u7a83\u53d6\u7684\u95ee\u9898\uff0c\u63d0\u5347\u9690\u79c1\u4fdd\u62a4\u548c\u4f20\u8f93\u8d28\u91cf\u3002", "method": "\u91c7\u7528\u4f18\u5148\u91c7\u6837\u8f85\u52a9\u7684\u53cc\u5ef6\u8fdf\u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6\u7b97\u6cd5\uff0c\u8054\u5408\u4f18\u5316\u8bed\u4e49\u4fe1\u606f\u548c\u4f20\u8f93\u529f\u7387\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u9690\u79c1\u4fdd\u62a4\u548c\u4f20\u8f93\u8d28\u91cf\u5206\u522b\u63d0\u5347\u4e8677.8%\u548c14.3%\u3002", "conclusion": "\u6240\u63d0\u7b97\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u9690\u853d\u8bed\u4e49\u901a\u4fe1\u7684\u5b89\u5168\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2508.07602", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07602", "abs": "https://arxiv.org/abs/2508.07602", "authors": ["Wenpeng Xing", "Zhipeng Chen", "Changting Lin", "Meng Han"], "title": "HGMF: A Hierarchical Gaussian Mixture Framework for Scalable Tool Invocation within the Model Context Protocol", "comment": null, "summary": "Invoking external tools enables Large Language Models (LLMs) to perform\ncomplex, real-world tasks, yet selecting the correct tool from large,\nhierarchically-structured libraries remains a significant challenge. The\nlimited context windows of LLMs and noise from irrelevant options often lead to\nlow selection accuracy and high computational costs. To address this, we\npropose the Hierarchical Gaussian Mixture Framework (HGMF), a probabilistic\npruning method for scalable tool invocation. HGMF first maps the user query and\nall tool descriptions into a unified semantic space. The framework then\noperates in two stages: it clusters servers using a Gaussian Mixture Model\n(GMM) and filters them based on the query's likelihood. Subsequently, it\napplies the same GMM-based clustering and filtering to the tools associated\nwith the selected servers. This hierarchical process produces a compact,\nhigh-relevance candidate set, simplifying the final selection task for the LLM.\nExperiments on a public dataset show that HGMF significantly improves tool\nselection accuracy while reducing inference latency, confirming the framework's\nscalability and effectiveness for large-scale tool libraries.", "AI": {"tldr": "HGMF\u662f\u4e00\u79cd\u6982\u7387\u526a\u679d\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u5c42\u9ad8\u65af\u6df7\u5408\u6a21\u578b\uff08GMM\uff09\u805a\u7c7b\u548c\u8fc7\u6ee4\u5de5\u5177\u5e93\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5de5\u5177\u9009\u62e9\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u89e3\u51b3LLMs\u5728\u5927\u89c4\u6a21\u3001\u5c42\u6b21\u5316\u5de5\u5177\u5e93\u4e2d\u9009\u62e9\u6b63\u786e\u5de5\u5177\u7684\u6311\u6218\uff0c\u907f\u514d\u4f4e\u51c6\u786e\u6027\u548c\u9ad8\u8ba1\u7b97\u6210\u672c\u3002", "method": "HGMF\u5c06\u67e5\u8be2\u548c\u5de5\u5177\u63cf\u8ff0\u6620\u5c04\u5230\u7edf\u4e00\u8bed\u4e49\u7a7a\u95f4\uff0c\u5206\u4e24\u9636\u6bb5\u8fdb\u884cGMM\u805a\u7c7b\u548c\u57fa\u4e8e\u67e5\u8be2\u4f3c\u7136\u7684\u8fc7\u6ee4\uff0c\u751f\u6210\u9ad8\u76f8\u5173\u6027\u5019\u9009\u96c6\u3002", "result": "\u5b9e\u9a8c\u8868\u660eHGMF\u663e\u8457\u63d0\u9ad8\u4e86\u5de5\u5177\u9009\u62e9\u51c6\u786e\u6027\u5e76\u964d\u4f4e\u4e86\u63a8\u7406\u5ef6\u8fdf\u3002", "conclusion": "HGMF\u4e3a\u5927\u89c4\u6a21\u5de5\u5177\u5e93\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.07616", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.07616", "abs": "https://arxiv.org/abs/2508.07616", "authors": ["Aswin RRV", "Jacob Dineen", "Divij Handa", "Md Nayem Uddin", "Mihir Parmar", "Chitta Baral", "Ben Zhou"], "title": "ThinkTuning: Instilling Cognitive Reflections without Distillation", "comment": "15 pages", "summary": "Recent advances in test-time scaling have led to the emergence of thinking\nLLMs that exhibit self-reflective behaviors and multi-step reasoning. While RL\ndrives this self-improvement paradigm, a recent study (Gandhi et al., 2025)\nshows that RL alone does not truly instill these new reasoning abilities - it\nmerely draws out behaviors already present in the base models. This raises a\nquestion: How can we train the models that don't exhibit such thinking behavior\nto develop it in the first place? To this end, we propose ThinkTuning, a\nGRPO-based interactive training approach where we augment the rollouts of a\nstudent model with the guidance from a teacher model. A simple idea from\nclassroom practice inspires our method: a teacher poses a problem, lets the\nstudent try an answer, then gives corrective feedback -- enough to point the\nmind in the right direction and then show the solution. Each piece of feedback\nreshapes the student's thoughts, leading them to arrive at the correct\nsolution. Similarly, we find that this type of implicit supervision through\nfeedback from a teacher model of the same size improves the reasoning\ncapabilities of the student model. In particular, on average, our method shows\na 3.85% improvement over zero-shot baselines across benchmarks, and on\nMATH-500, AIME and GPQA-Diamond it shows 2.08%, 2.23% and 3.99% improvements\nover the vanilla-GRPO baseline. Source code is available at\nhttps://github.com/3rdAT/ThinkTuning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faThinkTuning\u65b9\u6cd5\uff0c\u901a\u8fc7\u6559\u5e08\u6a21\u578b\u7684\u53cd\u9988\u6307\u5bfc\u5b66\u751f\u6a21\u578b\uff0c\u63d0\u5347\u5176\u63a8\u7406\u80fd\u529b\uff0c\u5b9e\u9a8c\u663e\u793a\u5728\u591a\u4efb\u52a1\u57fa\u51c6\u4e0a\u6709\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709RL\u65b9\u6cd5\u4ec5\u80fd\u6fc0\u53d1\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u6f5c\u5728\u884c\u4e3a\uff0c\u65e0\u6cd5\u771f\u6b63\u57f9\u517b\u65b0\u7684\u63a8\u7406\u80fd\u529b\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u8bad\u7ec3\u4e0d\u5177\u5907\u6b64\u7c7b\u80fd\u529b\u7684\u6a21\u578b\u3002", "method": "\u91c7\u7528GRPO\u6846\u67b6\uff0c\u901a\u8fc7\u6559\u5e08\u6a21\u578b\u63d0\u4f9b\u53cd\u9988\uff0c\u9010\u6b65\u6307\u5bfc\u5b66\u751f\u6a21\u578b\u6539\u8fdb\u5176\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "ThinkTuning\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u63d0\u53473.85%\uff0c\u5728MATH-500\u3001AIME\u548cGPQA-Diamond\u4e0a\u5206\u522b\u63d0\u53472.08%\u30012.23%\u548c3.99%\u3002", "conclusion": "ThinkTuning\u901a\u8fc7\u6559\u5e08\u6a21\u578b\u7684\u9690\u5f0f\u76d1\u7763\u6709\u6548\u63d0\u5347\u4e86\u5b66\u751f\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u8bad\u7ec3\u4e0d\u5177\u5907\u521d\u59cb\u63a8\u7406\u80fd\u529b\u7684\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2508.07628", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07628", "abs": "https://arxiv.org/abs/2508.07628", "authors": ["Daniel Essien", "Suresh Neethirajan"], "title": "Multimodal AI Systems for Enhanced Laying Hen Welfare Assessment and Productivity Optimization", "comment": "66 pages, 7 figures, 11 tables", "summary": "The future of poultry production depends on a paradigm shift replacing\nsubjective, labor-intensive welfare checks with data-driven, intelligent\nmonitoring ecosystems. Traditional welfare assessments-limited by human\nobservation and single-sensor data-cannot fully capture the complex,\nmultidimensional nature of laying hen welfare in modern farms. Multimodal\nArtificial Intelligence (AI) offers a breakthrough, integrating visual,\nacoustic, environmental, and physiological data streams to reveal deeper\ninsights into avian welfare dynamics. This investigation highlights multimodal\nAs transformative potential, showing that intermediate (feature-level) fusion\nstrategies achieve the best balance between robustness and performance under\nreal-world poultry conditions, and offer greater scalability than early or late\nfusion approaches. Key adoption barriers include sensor fragility in harsh farm\nenvironments, high deployment costs, inconsistent behavioral definitions, and\nlimited cross-farm generalizability. To address these, we introduce two novel\nevaluation tools - the Domain Transfer Score (DTS) to measure model\nadaptability across diverse farm settings, and the Data Reliability Index (DRI)\nto assess sensor data quality under operational constraints. We also propose a\nmodular, context-aware deployment framework designed for laying hen\nenvironments, enabling scalable and practical integration of multimodal\nsensing. This work lays the foundation for a transition from reactive, unimodal\nmonitoring to proactive, precision-driven welfare systems that unite\nproductivity with ethical, science based animal care.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5229\u7528\u591a\u6a21\u6001AI\u6280\u672f\u6539\u8fdb\u5bb6\u79bd\u798f\u5229\u76d1\u6d4b\uff0c\u901a\u8fc7\u6574\u5408\u89c6\u89c9\u3001\u58f0\u97f3\u3001\u73af\u5883\u548c\u751f\u7406\u6570\u636e\uff0c\u5b9e\u73b0\u66f4\u7cbe\u51c6\u7684\u798f\u5229\u8bc4\u4f30\u3002\u7814\u7a76\u53d1\u73b0\u7279\u5f81\u7ea7\u878d\u5408\u7b56\u7565\u5728\u6027\u80fd\u548c\u9c81\u68d2\u6027\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u5e76\u63d0\u51fa\u4e86\u89e3\u51b3\u5b9e\u9645\u90e8\u7f72\u969c\u788d\u7684\u65b0\u5de5\u5177\u548c\u6846\u67b6\u3002", "motivation": "\u4f20\u7edf\u5bb6\u79bd\u798f\u5229\u76d1\u6d4b\u4f9d\u8d56\u4e3b\u89c2\u4eba\u5de5\u89c2\u5bdf\u548c\u5355\u4e00\u4f20\u611f\u5668\u6570\u636e\uff0c\u65e0\u6cd5\u5168\u9762\u53cd\u6620\u73b0\u4ee3\u519c\u573a\u4e2d\u86cb\u9e21\u7684\u591a\u7ef4\u5ea6\u798f\u5229\u9700\u6c42\u3002\u591a\u6a21\u6001AI\u6280\u672f\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u63d0\u4f9b\u4e86\u7a81\u7834\u6027\u65b9\u6848\u3002", "method": "\u91c7\u7528\u591a\u6a21\u6001AI\u6280\u672f\uff0c\u6574\u5408\u89c6\u89c9\u3001\u58f0\u5b66\u3001\u73af\u5883\u548c\u751f\u7406\u6570\u636e\u6d41\uff0c\u901a\u8fc7\u7279\u5f81\u7ea7\u878d\u5408\u7b56\u7565\u4f18\u5316\u6a21\u578b\u6027\u80fd\u3002\u63d0\u51fa\u9886\u57df\u8f6c\u79fb\u8bc4\u5206\uff08DTS\uff09\u548c\u6570\u636e\u53ef\u9760\u6027\u6307\u6570\uff08DRI\uff09\u4f5c\u4e3a\u8bc4\u4f30\u5de5\u5177\uff0c\u5e76\u8bbe\u8ba1\u6a21\u5757\u5316\u90e8\u7f72\u6846\u67b6\u3002", "result": "\u7279\u5f81\u7ea7\u878d\u5408\u7b56\u7565\u5728\u771f\u5b9e\u519c\u573a\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u6700\u4f73\u5e73\u8861\u6027\uff0c\u63d0\u51fa\u7684DTS\u548cDRI\u5de5\u5177\u6709\u6548\u89e3\u51b3\u4e86\u6a21\u578b\u9002\u5e94\u6027\u548c\u6570\u636e\u8d28\u91cf\u95ee\u9898\u3002", "conclusion": "\u591a\u6a21\u6001AI\u6280\u672f\u4e3a\u5bb6\u79bd\u798f\u5229\u76d1\u6d4b\u63d0\u4f9b\u4e86\u4ece\u88ab\u52a8\u5355\u6a21\u6001\u76d1\u6d4b\u5411\u4e3b\u52a8\u7cbe\u51c6\u5316\u7cfb\u7edf\u7684\u8f6c\u53d8\u57fa\u7840\uff0c\u7ed3\u5408\u4e86\u751f\u4ea7\u6548\u7387\u548c\u79d1\u5b66\u4f26\u7406\u3002"}}
{"id": "2508.07642", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.07642", "abs": "https://arxiv.org/abs/2508.07642", "authors": ["Tianyi Ma", "Yue Zhang", "Zehao Wang", "Parisa Kordjamshidi"], "title": "Breaking Down and Building Up: Mixture of Skill-Based Vision-and-Language Navigation Agents", "comment": "18 pages, 5 Figures,", "summary": "Vision-and-Language Navigation (VLN) poses significant challenges in enabling\nagents to interpret natural language instructions and navigate complex 3D\nenvironments. While recent progress has been driven by large-scale pre-training\nand data augmentation, current methods still struggle to generalize to unseen\nscenarios, particularly when complex spatial and temporal reasoning is\nrequired. In this work, we propose SkillNav, a modular framework that\nintroduces structured, skill-based reasoning into Transformer-based VLN agents.\nOur method decomposes navigation into a set of interpretable atomic skills\n(e.g., Vertical Movement, Area and Region Identification, Stop and Pause), each\nhandled by a specialized agent. We then introduce a novel zero-shot\nVision-Language Model (VLM)-based router, which dynamically selects the most\nsuitable agent at each time step by aligning sub-goals with visual observations\nand historical actions. SkillNav achieves a new state-of-the-art performance on\nthe R2R benchmark and demonstrates strong generalization to the GSA-R2R\nbenchmark that includes novel instruction styles and unseen environments.", "AI": {"tldr": "SkillNav\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u5bfc\u822a\u4efb\u52a1\u5206\u89e3\u4e3a\u53ef\u89e3\u91ca\u7684\u539f\u5b50\u6280\u80fd\uff0c\u5e76\u5229\u7528\u57fa\u4e8eVLM\u7684\u8def\u7531\u5668\u52a8\u6001\u9009\u62e9\u9002\u5408\u7684\u4ee3\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86VLN\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524dVLN\u65b9\u6cd5\u5728\u590d\u6742\u7a7a\u95f4\u548c\u65f6\u95f4\u63a8\u7406\u573a\u666f\u4e2d\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u7ed3\u6784\u5316\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faSkillNav\u6846\u67b6\uff0c\u5c06\u5bfc\u822a\u5206\u89e3\u4e3a\u539f\u5b50\u6280\u80fd\uff0c\u6bcf\u4e2a\u6280\u80fd\u7531\u4e13\u95e8\u4ee3\u7406\u5904\u7406\uff0c\u5e76\u5f15\u5165VLM\u8def\u7531\u5668\u52a8\u6001\u9009\u62e9\u4ee3\u7406\u3002", "result": "\u5728R2R\u548cGSA-R2R\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u65b0SOTA\uff0c\u5c55\u793a\u4e86\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "SkillNav\u901a\u8fc7\u6a21\u5757\u5316\u548c\u6280\u80fd\u5206\u89e3\uff0c\u663e\u8457\u63d0\u5347\u4e86VLN\u4efb\u52a1\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2508.07649", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.07649", "abs": "https://arxiv.org/abs/2508.07649", "authors": ["Jie Li", "Haoye Dong", "Zhengyang Wu", "Zetao Zheng", "Mingrong Lin"], "title": "Disentangling Multiplex Spatial-Temporal Transition Graph Representation Learning for Socially Enhanced POI Recommendation", "comment": null, "summary": "Next Point-of-Interest (POI) recommendation is a research hotspot in business\nintelligence, where users' spatial-temporal transitions and social\nrelationships play key roles. However, most existing works model spatial and\ntemporal transitions separately, leading to misaligned representations of the\nsame spatial-temporal key nodes. This misalignment introduces redundant\ninformation during fusion, increasing model uncertainty and reducing\ninterpretability. To address this issue, we propose DiMuST, a socially enhanced\nPOI recommendation model based on disentangled representation learning over\nmultiplex spatial-temporal transition graphs. The model employs a novel\nDisentangled variational multiplex graph Auto-Encoder (DAE), which first\ndisentangles shared and private distributions using a multiplex\nspatial-temporal graph strategy. It then fuses the shared features via a\nProduct of Experts (PoE) mechanism and denoises the private features through\ncontrastive constraints. The model effectively captures the spatial-temporal\ntransition representations of POIs while preserving the intrinsic correlation\nof their spatial-temporal relationships. Experiments on two challenging\ndatasets demonstrate that our DiMuST significantly outperforms existing methods\nacross multiple metrics.", "AI": {"tldr": "DiMuST\u6a21\u578b\u901a\u8fc7\u89e3\u8026\u591a\u65f6\u7a7a\u56fe\u8868\u793a\u5b66\u4e60\uff0c\u63d0\u5347POI\u63a8\u8350\u6027\u80fd\u3002", "motivation": "\u73b0\u6709POI\u63a8\u8350\u6a21\u578b\u5c06\u65f6\u7a7a\u8f6c\u6362\u5206\u5f00\u5efa\u6a21\uff0c\u5bfc\u81f4\u8282\u70b9\u8868\u793a\u4e0d\u5339\u914d\uff0c\u589e\u52a0\u5197\u4f59\u4fe1\u606f\u548c\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u63d0\u51faDiMuST\u6a21\u578b\uff0c\u91c7\u7528\u89e3\u8026\u53d8\u5206\u591a\u56fe\u81ea\u52a8\u7f16\u7801\u5668\uff08DAE\uff09\uff0c\u5206\u79bb\u5171\u4eab\u4e0e\u79c1\u6709\u5206\u5e03\uff0c\u5e76\u901a\u8fc7PoE\u673a\u5236\u878d\u5408\u5171\u4eab\u7279\u5f81\uff0c\u5bf9\u6bd4\u7ea6\u675f\u53bb\u566a\u79c1\u6709\u7279\u5f81\u3002", "result": "\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\uff0cDiMuST\u5728\u591a\u9879\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "DiMuST\u6709\u6548\u6355\u6349POI\u7684\u65f6\u7a7a\u8f6c\u6362\u8868\u793a\uff0c\u540c\u65f6\u4fdd\u6301\u5176\u65f6\u7a7a\u5173\u7cfb\u7684\u5185\u5728\u76f8\u5173\u6027\u3002"}}
{"id": "2508.07667", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07667", "abs": "https://arxiv.org/abs/2508.07667", "authors": ["Wenkai Li", "Liwen Sun", "Zhenxiang Guan", "Xuhui Zhou", "Maarten Sap"], "title": "1-2-3 Check: Enhancing Contextual Privacy in LLM via Multi-Agent Reasoning", "comment": null, "summary": "Addressing contextual privacy concerns remains challenging in interactive\nsettings where large language models (LLMs) process information from multiple\nsources (e.g., summarizing meetings with private and public information). We\nintroduce a multi-agent framework that decomposes privacy reasoning into\nspecialized subtasks (extraction, classification), reducing the information\nload on any single agent while enabling iterative validation and more reliable\nadherence to contextual privacy norms. To understand how privacy errors emerge\nand propagate, we conduct a systematic ablation over information-flow\ntopologies, revealing when and why upstream detection mistakes cascade into\ndownstream leakage. Experiments on the ConfAIde and PrivacyLens benchmark with\nseveral open-source and closed-sourced LLMs demonstrate that our best\nmulti-agent configuration substantially reduces private information leakage\n(\\textbf{18\\%} on ConfAIde and \\textbf{19\\%} on PrivacyLens with GPT-4o) while\npreserving the fidelity of public content, outperforming single-agent\nbaselines. These results highlight the promise of principled information-flow\ndesign in multi-agent systems for contextual privacy with LLMs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u9690\u79c1\u63a8\u7406\u4efb\u52a1\u6765\u51cf\u5c11\u9690\u79c1\u4fe1\u606f\u6cc4\u6f0f\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u4f18\u4e8e\u5355\u667a\u80fd\u4f53\u57fa\u7ebf\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6e90\u4fe1\u606f\u5904\u7406\u4e2d\u7684\u4e0a\u4e0b\u6587\u9690\u79c1\u95ee\u9898\u3002", "method": "\u5f15\u5165\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c06\u9690\u79c1\u63a8\u7406\u5206\u89e3\u4e3a\u4e13\u95e8\u5b50\u4efb\u52a1\uff08\u63d0\u53d6\u3001\u5206\u7c7b\uff09\uff0c\u5e76\u901a\u8fc7\u4fe1\u606f\u6d41\u62d3\u6251\u5206\u6790\u9690\u79c1\u9519\u8bef\u4f20\u64ad\u3002", "result": "\u5728ConfAIde\u548cPrivacyLens\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u591a\u667a\u80fd\u4f53\u914d\u7f6e\u663e\u8457\u51cf\u5c11\u9690\u79c1\u6cc4\u6f0f\uff08GPT-4o\u4e0b\u5206\u522b\u964d\u4f4e18%\u548c19%\uff09\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u4fe1\u606f\u6d41\u8bbe\u8ba1\u5728\u4e0a\u4e0b\u6587\u9690\u79c1\u4fdd\u62a4\u4e2d\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2508.07671", "categories": ["cs.AI", "cs.CY", "cs.HC", "cs.MA", "stat.AP", "68T07, 68T42, 68T50, 91F20, 62P25", "I.2.11; I.2.1; H.1.2; J.4; K.4.2"], "pdf": "https://arxiv.org/pdf/2508.07671", "abs": "https://arxiv.org/abs/2508.07671", "authors": ["Mohamed Rayan Barhdadi", "Mehmet Tuncel", "Erchin Serpedin", "Hasan Kurban"], "title": "EMPATHIA: Multi-Faceted Human-AI Collaboration for Refugee Integration", "comment": "19 pages, 3 figures (plus 6 figures in supplementary), 2 tables, 1\n  algorithm. Submitted to NeurIPS 2025 Creative AI Track: Humanity", "summary": "Current AI approaches to refugee integration optimize narrow objectives such\nas employment and fail to capture the cultural, emotional, and ethical\ndimensions critical for long-term success. We introduce EMPATHIA (Enriched\nMultimodal Pathways for Agentic Thinking in Humanitarian Immigrant Assistance),\na multi-agent framework addressing the central Creative AI question: how do we\npreserve human dignity when machines participate in life-altering decisions?\nGrounded in Kegan's Constructive Developmental Theory, EMPATHIA decomposes\nintegration into three modules: SEED (Socio-cultural Entry and Embedding\nDecision) for initial placement, RISE (Rapid Integration and Self-sufficiency\nEngine) for early independence, and THRIVE (Transcultural Harmony and\nResilience through Integrated Values and Engagement) for sustained outcomes.\nSEED employs a selector-validator architecture with three specialized agents -\nemotional, cultural, and ethical - that deliberate transparently to produce\ninterpretable recommendations. Experiments on the UN Kakuma dataset (15,026\nindividuals, 7,960 eligible adults 15+ per ILO/UNHCR standards) and\nimplementation on 6,359 working-age refugees (15+) with 150+ socioeconomic\nvariables achieved 87.4% validation convergence and explainable assessments\nacross five host countries. EMPATHIA's weighted integration of cultural,\nemotional, and ethical factors balances competing value systems while\nsupporting practitioner-AI collaboration. By augmenting rather than replacing\nhuman expertise, EMPATHIA provides a generalizable framework for AI-driven\nallocation tasks where multiple values must be reconciled.", "AI": {"tldr": "EMPATHIA\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u96be\u6c11\u6574\u5408\u4e2d\u7684\u6587\u5316\u3001\u60c5\u611f\u548c\u4f26\u7406\u7ef4\u5ea6\u95ee\u9898\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\u5b9e\u73b0\u900f\u660e\u548c\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u3002", "motivation": "\u5f53\u524dAI\u5728\u96be\u6c11\u6574\u5408\u4e2d\u4ec5\u5173\u6ce8\u5c31\u4e1a\u7b49\u72ed\u7a84\u76ee\u6807\uff0c\u5ffd\u89c6\u4e86\u6587\u5316\u3001\u60c5\u611f\u548c\u4f26\u7406\u7b49\u957f\u671f\u6210\u529f\u7684\u5173\u952e\u56e0\u7d20\u3002", "method": "EMPATHIA\u57fa\u4e8eKegan\u7684\u5efa\u6784\u53d1\u5c55\u7406\u8bba\uff0c\u5206\u4e3aSEED\u3001RISE\u548cTHRIVE\u4e09\u4e2a\u6a21\u5757\uff0c\u91c7\u7528\u591a\u667a\u80fd\u4f53\u67b6\u6784\u8fdb\u884c\u900f\u660e\u51b3\u7b56\u3002", "result": "\u5728UN Kakuma\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0cEMPATHIA\u8fbe\u523087.4%\u7684\u6536\u655b\u7387\uff0c\u5e76\u5728\u4e94\u4e2a\u63a5\u6536\u56fd\u5b9e\u73b0\u4e86\u53ef\u89e3\u91ca\u7684\u8bc4\u4f30\u3002", "conclusion": "EMPATHIA\u901a\u8fc7\u5e73\u8861\u591a\u4ef7\u503c\u7cfb\u7edf\u548c\u652f\u6301\u4eba\u673a\u534f\u4f5c\uff0c\u4e3aAI\u9a71\u52a8\u7684\u5206\u914d\u4efb\u52a1\u63d0\u4f9b\u4e86\u901a\u7528\u6846\u67b6\u3002"}}
{"id": "2508.07673", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.07673", "abs": "https://arxiv.org/abs/2508.07673", "authors": ["Gianluca Bontempi"], "title": "Ethics2vec: aligning automatic agents and human preferences", "comment": null, "summary": "Though intelligent agents are supposed to improve human experience (or make\nit more efficient), it is hard from a human perspective to grasp the ethical\nvalues which are explicitly or implicitly embedded in an agent behaviour. This\nis the well-known problem of alignment, which refers to the challenge of\ndesigning AI systems that align with human values, goals and preferences. This\nproblem is particularly challenging since most human ethical considerations\nrefer to \\emph{incommensurable} (i.e. non-measurable and/or incomparable)\nvalues and criteria. Consider, for instance, a medical agent prescribing a\ntreatment to a cancerous patient. How could it take into account (and/or weigh)\nincommensurable aspects like the value of a human life and the cost of the\ntreatment? Now, the alignment between human and artificial values is possible\nonly if we define a common space where a metric can be defined and used. This\npaper proposes to extend to ethics the conventional Anything2vec approach,\nwhich has been successful in plenty of similar and hard-to-quantify domains\n(ranging from natural language processing to recommendation systems and graph\nanalysis). This paper proposes a way to map an automatic agent decision-making\n(or control law) strategy to a multivariate vector representation, which can be\nused to compare and assess the alignment with human values. The Ethics2Vec\nmethod is first introduced in the case of an automatic agent performing binary\ndecision-making. Then, a vectorisation of an automatic control law (like in the\ncase of a self-driving car) is discussed to show how the approach can be\nextended to automatic control settings.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEthics2Vec\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5411\u91cf\u5316AI\u4ee3\u7406\u7684\u51b3\u7b56\u7b56\u7565\uff0c\u8bc4\u4f30\u5176\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u4e00\u81f4\u6027\u3002", "motivation": "\u89e3\u51b3AI\u7cfb\u7edf\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u5bf9\u9f50\u7684\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u6d89\u53ca\u4e0d\u53ef\u8861\u91cf\u6216\u4e0d\u53ef\u6bd4\u8f83\u7684\u4f26\u7406\u4ef7\u503c\u65f6\u3002", "method": "\u6269\u5c55Anything2vec\u65b9\u6cd5\uff0c\u5c06\u4ee3\u7406\u7684\u51b3\u7b56\u7b56\u7565\u6620\u5c04\u4e3a\u591a\u5143\u5411\u91cf\u8868\u793a\uff0c\u7528\u4e8e\u6bd4\u8f83\u548c\u8bc4\u4f30\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u5bf9\u9f50\u3002", "result": "\u63d0\u51fa\u4e86Ethics2Vec\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u4e8c\u5143\u51b3\u7b56\u548c\u81ea\u52a8\u63a7\u5236\u573a\u666f\uff08\u5982\u81ea\u52a8\u9a7e\u9a76\uff09\u3002", "conclusion": "Ethics2Vec\u4e3aAI\u4f26\u7406\u5bf9\u9f50\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u7684\u91cf\u5316\u65b9\u6cd5\u3002"}}
{"id": "2508.07743", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.07743", "abs": "https://arxiv.org/abs/2508.07743", "authors": ["Markus Fritzsche", "Elliot Gestrin", "Jendrik Seipp"], "title": "Symmetry-Aware Transformer Training for Automated Planning", "comment": null, "summary": "While transformers excel in many settings, their application in the field of\nautomated planning is limited. Prior work like PlanGPT, a state-of-the-art\ndecoder-only transformer, struggles with extrapolation from easy to hard\nplanning problems. This in turn stems from problem symmetries: planning tasks\ncan be represented with arbitrary variable names that carry no meaning beyond\nbeing identifiers. This causes a combinatorial explosion of equivalent\nrepresentations that pure transformers cannot efficiently learn from. We\npropose a novel contrastive learning objective to make transformers\nsymmetry-aware and thereby compensate for their lack of inductive bias.\nCombining this with architectural improvements, we show that transformers can\nbe efficiently trained for either plan-generation or heuristic-prediction. Our\nresults across multiple planning domains demonstrate that our symmetry-aware\ntraining effectively and efficiently addresses the limitations of PlanGPT.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5bf9\u6bd4\u5b66\u4e60\u76ee\u6807\uff0c\u4f7fTransformer\u80fd\u591f\u611f\u77e5\u5bf9\u79f0\u6027\uff0c\u4ece\u800c\u5f25\u8865\u5176\u5728\u81ea\u52a8\u89c4\u5212\u9886\u57df\u7684\u5c40\u9650\u6027\u3002", "motivation": "Transformer\u5728\u81ea\u52a8\u89c4\u5212\u9886\u57df\u7684\u5e94\u7528\u53d7\u9650\uff0c\u4e3b\u8981\u7531\u4e8e\u95ee\u9898\u5bf9\u79f0\u6027\u5bfc\u81f4\u7ec4\u5408\u7206\u70b8\uff0c\u73b0\u6709\u65b9\u6cd5\uff08\u5982PlanGPT\uff09\u96be\u4ee5\u4ece\u7b49\u6548\u8868\u793a\u4e2d\u9ad8\u6548\u5b66\u4e60\u3002", "method": "\u7ed3\u5408\u5bf9\u6bd4\u5b66\u4e60\u76ee\u6807\u548c\u67b6\u6784\u6539\u8fdb\uff0c\u4f7fTransformer\u80fd\u591f\u611f\u77e5\u5bf9\u79f0\u6027\uff0c\u9002\u7528\u4e8e\u89c4\u5212\u751f\u6210\u6216\u542f\u53d1\u5f0f\u9884\u6d4b\u3002", "result": "\u5728\u591a\u4e2a\u89c4\u5212\u9886\u57df\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6709\u6548\u4e14\u9ad8\u6548\u5730\u89e3\u51b3\u4e86PlanGPT\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u5bf9\u79f0\u611f\u77e5\u8bad\u7ec3\u663e\u8457\u63d0\u5347\u4e86Transformer\u5728\u81ea\u52a8\u89c4\u5212\u4e2d\u7684\u6027\u80fd\u3002"}}
{"id": "2508.07790", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2508.07790", "abs": "https://arxiv.org/abs/2508.07790", "authors": ["Alessandro Abate", "Thom Badings", "Giuseppe De Giacomo", "Francesco Fabiano"], "title": "Best-Effort Policies for Robust Markov Decision Processes", "comment": null, "summary": "We study the common generalization of Markov decision processes (MDPs) with\nsets of transition probabilities, known as robust MDPs (RMDPs). A standard goal\nin RMDPs is to compute a policy that maximizes the expected return under an\nadversarial choice of the transition probabilities. If the uncertainty in the\nprobabilities is independent between the states, known as s-rectangularity,\nsuch optimal robust policies can be computed efficiently using robust value\niteration. However, there might still be multiple optimal robust policies,\nwhich, while equivalent with respect to the worst-case, reflect different\nexpected returns under non-adversarial choices of the transition probabilities.\nHence, we propose a refined policy selection criterion for RMDPs, drawing\ninspiration from the notions of dominance and best-effort in game theory.\nInstead of seeking a policy that only maximizes the worst-case expected return,\nwe additionally require the policy to achieve a maximal expected return under\ndifferent (i.e., not fully adversarial) transition probabilities. We call such\na policy an optimal robust best-effort (ORBE) policy. We prove that ORBE\npolicies always exist, characterize their structure, and present an algorithm\nto compute them with a small overhead compared to standard robust value\niteration. ORBE policies offer a principled tie-breaker among optimal robust\npolicies. Numerical experiments show the feasibility of our approach.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u9c81\u68d2\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08RMDPs\uff09\u4e2d\u7684\u6700\u4f18\u7b56\u7565\u9009\u62e9\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b56\u7565\u9009\u62e9\u6807\u51c6\u2014\u2014\u6700\u4f18\u9c81\u68d2\u6700\u4f73\u52aa\u529b\uff08ORBE\uff09\u7b56\u7565\uff0c\u4ee5\u5728\u975e\u5b8c\u5168\u5bf9\u6297\u6027\u6982\u7387\u4e0b\u6700\u5927\u5316\u671f\u671b\u56de\u62a5\u3002", "motivation": "\u5728RMDPs\u4e2d\uff0c\u5b58\u5728\u591a\u4e2a\u6700\u4f18\u9c81\u68d2\u7b56\u7565\uff0c\u8fd9\u4e9b\u7b56\u7565\u5728\u6700\u574f\u60c5\u51b5\u4e0b\u8868\u73b0\u76f8\u540c\uff0c\u4f46\u5728\u975e\u5bf9\u6297\u6027\u6982\u7387\u4e0b\u671f\u671b\u56de\u62a5\u4e0d\u540c\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7cbe\u7ec6\u7684\u7b56\u7565\u9009\u62e9\u6807\u51c6\u3002", "method": "\u63d0\u51faORBE\u7b56\u7565\uff0c\u7ed3\u5408\u4e86\u535a\u5f08\u8bba\u4e2d\u7684\u652f\u914d\u548c\u6700\u4f73\u52aa\u529b\u6982\u5ff5\uff0c\u8981\u6c42\u7b56\u7565\u4e0d\u4ec5\u5728\u6700\u574f\u60c5\u51b5\u4e0b\u6700\u4f18\uff0c\u8fd8\u9700\u5728\u975e\u5bf9\u6297\u6027\u6982\u7387\u4e0b\u6700\u5927\u5316\u671f\u671b\u56de\u62a5\u3002\u5e76\u8bbe\u8ba1\u4e86\u8ba1\u7b97ORBE\u7b56\u7565\u7684\u7b97\u6cd5\u3002", "result": "\u8bc1\u660e\u4e86ORBE\u7b56\u7565\u7684\u5b58\u5728\u6027\uff0c\u5e76\u5206\u6790\u4e86\u5176\u7ed3\u6784\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u3002", "conclusion": "ORBE\u7b56\u7565\u4e3aRMDPs\u4e2d\u7684\u6700\u4f18\u7b56\u7565\u9009\u62e9\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u548c\u5b9e\u7528\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u7684\u7b56\u7565\u7b49\u4ef7\u6027\u95ee\u9898\u3002"}}
{"id": "2508.07834", "categories": ["cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2508.07834", "abs": "https://arxiv.org/abs/2508.07834", "authors": ["Mubaris Nadeem", "Johannes Zenkert", "Lisa Bender", "Christian Weber", "Madjid Fathi"], "title": "KIRETT: Knowledge-Graph-Based Smart Treatment Assistant for Intelligent Rescue Operations", "comment": "LWDA'23, KIRETT project, University of Siegen, Germany", "summary": "Over the years, the need for rescue operations throughout the world has\nincreased rapidly. Demographic changes and the resulting risk of injury or\nhealth disorders form the basis for emergency calls. In such scenarios, first\nresponders are in a rush to reach the patient in need, provide first aid, and\nsave lives. In these situations, they must be able to provide personalized and\noptimized healthcare in the shortest possible time and estimate the patients\ncondition with the help of freshly recorded vital data in an emergency\nsituation. However, in such a timedependent situation, first responders and\nmedical experts cannot fully grasp their knowledge and need assistance and\nrecommendation for further medical treatments. To achieve this, on the spot\ncalculated, evaluated, and processed knowledge must be made available to\nimprove treatments by first responders. The Knowledge Graph presented in this\narticle as a central knowledge representation provides first responders with an\ninnovative knowledge management that enables intelligent treatment\nrecommendations with an artificial intelligence-based pre-recognition of the\nsituation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u548c\u4eba\u5de5\u667a\u80fd\u7684\u521b\u65b0\u77e5\u8bc6\u7ba1\u7406\u7cfb\u7edf\uff0c\u65e8\u5728\u4e3a\u6025\u6551\u4eba\u5458\u63d0\u4f9b\u5b9e\u65f6\u3001\u667a\u80fd\u7684\u6cbb\u7597\u5efa\u8bae\u3002", "motivation": "\u5168\u7403\u6551\u63f4\u9700\u6c42\u8fc5\u901f\u589e\u957f\uff0c\u6025\u6551\u4eba\u5458\u5728\u7d27\u6025\u60c5\u51b5\u4e0b\u9700\u8981\u5feb\u901f\u63d0\u4f9b\u4e2a\u6027\u5316\u533b\u7597\uff0c\u4f46\u7f3a\u4e4f\u5b9e\u65f6\u77e5\u8bc6\u652f\u6301\u3002", "method": "\u91c7\u7528\u77e5\u8bc6\u56fe\u8c31\u4f5c\u4e3a\u6838\u5fc3\u77e5\u8bc6\u8868\u793a\uff0c\u7ed3\u5408\u4eba\u5de5\u667a\u80fd\u9884\u8bc6\u522b\u6280\u672f\uff0c\u4e3a\u6025\u6551\u4eba\u5458\u63d0\u4f9b\u667a\u80fd\u6cbb\u7597\u5efa\u8bae\u3002", "result": "\u7cfb\u7edf\u80fd\u591f\u5b9e\u65f6\u8ba1\u7b97\u3001\u8bc4\u4f30\u548c\u5904\u7406\u77e5\u8bc6\uff0c\u4f18\u5316\u6025\u6551\u4eba\u5458\u7684\u6cbb\u7597\u51b3\u7b56\u3002", "conclusion": "\u8be5\u77e5\u8bc6\u7ba1\u7406\u7cfb\u7edf\u663e\u8457\u63d0\u5347\u4e86\u6025\u6551\u6548\u7387\u548c\u8d28\u91cf\uff0c\u4e3a\u7d27\u6025\u533b\u7597\u63d0\u4f9b\u4e86\u667a\u80fd\u5316\u652f\u6301\u3002"}}
{"id": "2508.07932", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07932", "abs": "https://arxiv.org/abs/2508.07932", "authors": ["Yi Zhai", "Zhiqiang Wei", "Ruohan Li", "Keyu Pan", "Shuo Liu", "Lu Zhang", "Jianmin Ji", "Wuyang Zhang", "Yu Zhang", "Yanyong Zhang"], "title": "\\(X\\)-evolve: Solution space evolution powered by large language models", "comment": null, "summary": "While combining large language models (LLMs) with evolutionary algorithms\n(EAs) shows promise for solving complex optimization problems, current\napproaches typically evolve individual solutions, often incurring high LLM call\ncosts. We introduce \\(X\\)-evolve, a paradigm-shifting method that instead\nevolves solution spaces \\(X\\) (sets of individual solutions) - subsets of the\noverall search space \\(S\\). In \\(X\\)-evolve, LLMs generate tunable programs\nwherein certain code snippets, designated as parameters, define a tunable\nsolution space. A score-based search algorithm then efficiently explores this\nparametrically defined space, guided by feedback from objective function\nscores. This strategy enables broader and more efficient exploration, which can\npotentially accelerate convergence at a much lower search cost, requiring up to\ntwo orders of magnitude fewer LLM calls than prior leading methods. We\ndemonstrate \\(X\\)-evolve's efficacy across three distinct hard optimization\nproblems. For the cap set problem, we discover a larger partial admissible set,\nestablishing a new tighter asymptotic lower bound for the cap set constant (\\(C\n\\ge 2.2203\\)). In information theory, we uncover a larger independent set for\nthe 15-vertex cycle graph (\\(\\mathcal{C}_{15}^{\\boxtimes 5}\\), size 19,946),\nthereby raising the known lower bound on its Shannon capacity. Furthermore, for\nthe NP-hard online bin packing problem, we generate heuristics that\nconsistently outperform standard strategies across established benchmarks. By\nevolving solution spaces, our method considerably improves search\neffectiveness, making it possible to tackle high-dimensional problems that were\npreviously computationally prohibitive.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aX-evolve\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fdb\u5316\u89e3\u7a7a\u95f4\u800c\u975e\u5355\u4e2a\u89e3\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u8c03\u7528\u6210\u672c\uff0c\u5e76\u63d0\u9ad8\u4e86\u641c\u7d22\u6548\u7387\u3002", "motivation": "\u5f53\u524d\u7ed3\u5408LLM\u548c\u8fdb\u5316\u7b97\u6cd5\uff08EA\uff09\u7684\u65b9\u6cd5\u901a\u5e38\u8fdb\u5316\u5355\u4e2a\u89e3\uff0c\u5bfc\u81f4LLM\u8c03\u7528\u6210\u672c\u9ad8\u6602\u3002X-evolve\u65e8\u5728\u901a\u8fc7\u8fdb\u5316\u89e3\u7a7a\u95f4\u6765\u964d\u4f4e\u6210\u672c\u5e76\u63d0\u5347\u6548\u7387\u3002", "method": "X-evolve\u901a\u8fc7LLM\u751f\u6210\u53ef\u8c03\u7a0b\u5e8f\uff0c\u5176\u4e2d\u7279\u5b9a\u4ee3\u7801\u7247\u6bb5\u4f5c\u4e3a\u53c2\u6570\u5b9a\u4e49\u53ef\u8c03\u89e3\u7a7a\u95f4\u3002\u57fa\u4e8e\u5206\u6570\u7684\u641c\u7d22\u7b97\u6cd5\u9ad8\u6548\u63a2\u7d22\u8fd9\u4e00\u53c2\u6570\u5316\u7a7a\u95f4\u3002", "result": "\u5728\u4e09\u4e2a\u4f18\u5316\u95ee\u9898\u4e2d\u9a8c\u8bc1\u4e86X-evolve\u7684\u6709\u6548\u6027\uff1a\u5728cap set\u95ee\u9898\u4e2d\u53d1\u73b0\u4e86\u66f4\u5927\u7684\u90e8\u5206\u53ef\u5bb9\u8bb8\u96c6\uff1b\u5728\u4fe1\u606f\u8bba\u4e2d\u627e\u5230\u4e86\u66f4\u5927\u7684\u72ec\u7acb\u96c6\uff1b\u5728\u5728\u7ebf\u88c5\u7bb1\u95ee\u9898\u4e2d\u751f\u6210\u4e86\u4f18\u4e8e\u6807\u51c6\u7b56\u7565\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "conclusion": "X-evolve\u901a\u8fc7\u8fdb\u5316\u89e3\u7a7a\u95f4\u663e\u8457\u63d0\u5347\u4e86\u641c\u7d22\u6548\u7387\uff0c\u89e3\u51b3\u4e86\u9ad8\u7ef4\u95ee\u9898\u7684\u8ba1\u7b97\u96be\u9898\u3002"}}
{"id": "2508.07941", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07941", "abs": "https://arxiv.org/abs/2508.07941", "authors": ["Olivier Poulet", "Fr\u00e9d\u00e9ric Guinand", "Fran\u00e7ois Gu\u00e9rin"], "title": "Deep Reinforcement Learning with anticipatory reward in LSTM for Collision Avoidance of Mobile Robots", "comment": null, "summary": "This article proposes a collision risk anticipation method based on\nshort-term prediction of the agents position. A Long Short-Term Memory (LSTM)\nmodel, trained on past trajectories, is used to estimate the next position of\neach robot. This prediction allows us to define an anticipated collision risk\nby dynamically modulating the reward of a Deep Q-Learning Network (DQN) agent.\nThe approach is tested in a constrained environment, where two robots move\nwithout communication or identifiers. Despite a limited sampling frequency (1\nHz), the results show a significant decrease of the collisions number and a\nstability improvement. The proposed method, which is computationally\ninexpensive, appears particularly attractive for implementation on embedded\nsystems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u77ed\u671f\u9884\u6d4b\u7684\u78b0\u649e\u98ce\u9669\u9884\u6d4b\u65b9\u6cd5\uff0c\u4f7f\u7528LSTM\u9884\u6d4b\u673a\u5668\u4eba\u4f4d\u7f6e\uff0c\u5e76\u901a\u8fc7\u52a8\u6001\u8c03\u6574DQN\u7684\u5956\u52b1\u6765\u51cf\u5c11\u78b0\u649e\u3002", "motivation": "\u5728\u65e0\u901a\u4fe1\u6216\u6807\u8bc6\u7684\u53d7\u9650\u73af\u5883\u4e2d\uff0c\u51cf\u5c11\u673a\u5668\u4eba\u78b0\u649e\u5e76\u63d0\u9ad8\u7a33\u5b9a\u6027\u3002", "method": "\u4f7f\u7528LSTM\u9884\u6d4b\u673a\u5668\u4eba\u4f4d\u7f6e\uff0c\u7ed3\u5408DQN\u52a8\u6001\u8c03\u6574\u5956\u52b1\u3002", "result": "\u57281Hz\u91c7\u6837\u9891\u7387\u4e0b\uff0c\u78b0\u649e\u6b21\u6570\u663e\u8457\u51cf\u5c11\uff0c\u7a33\u5b9a\u6027\u63d0\u9ad8\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u4f4e\uff0c\u9002\u5408\u5d4c\u5165\u5f0f\u7cfb\u7edf\u5b9e\u73b0\u3002"}}
{"id": "2508.07950", "categories": ["cs.AI", "cs.CV", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.07950", "abs": "https://arxiv.org/abs/2508.07950", "authors": ["Chen Shen", "Wanqing Zhang", "Kehan Li", "Erwen Huang", "Haitao Bi", "Aiying Fan", "Yiwen Shen", "Hongmei Dong", "Ji Zhang", "Yuming Shao", "Zengjia Liu", "Xinshe Liu", "Tao Li", "Chunxia Yan", "Shuanliang Fan", "Di Wu", "Jianhua Ma", "Bin Cong", "Zhenyuan Wang", "Chunfeng Lian"], "title": "FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis", "comment": "18pages, 6 figures", "summary": "Forensic cause-of-death determination faces systemic challenges, including\nworkforce shortages and diagnostic variability, particularly in high-volume\nsystems like China's medicolegal infrastructure. We introduce FEAT (ForEnsic\nAgenT), a multi-agent AI framework that automates and standardizes death\ninvestigations through a domain-adapted large language model. FEAT's\napplication-oriented architecture integrates: (i) a central Planner for task\ndecomposition, (ii) specialized Local Solvers for evidence analysis, (iii) a\nMemory & Reflection module for iterative refinement, and (iv) a Global Solver\nfor conclusion synthesis. The system employs tool-augmented reasoning,\nhierarchical retrieval-augmented generation, forensic-tuned LLMs, and\nhuman-in-the-loop feedback to ensure legal and medical validity. In evaluations\nacross diverse Chinese case cohorts, FEAT outperformed state-of-the-art AI\nsystems in both long-form autopsy analyses and concise cause-of-death\nconclusions. It demonstrated robust generalization across six geographic\nregions and achieved high expert concordance in blinded validations. Senior\npathologists validated FEAT's outputs as comparable to those of human experts,\nwith improved detection of subtle evidentiary nuances. To our knowledge, FEAT\nis the first LLM-based AI agent system dedicated to forensic medicine, offering\nscalable, consistent death certification while maintaining expert-level rigor.\nBy integrating AI efficiency with human oversight, this work could advance\nequitable access to reliable medicolegal services while addressing critical\ncapacity constraints in forensic systems.", "AI": {"tldr": "FEAT\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53AI\u6846\u67b6\u7684\u81ea\u52a8\u5316\u6cd5\u533b\u6b7b\u56e0\u5206\u6790\u7cfb\u7edf\uff0c\u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f18\u5316\u6cd5\u533b\u5de5\u4f5c\u6d41\u7a0b\uff0c\u63d0\u9ad8\u8bca\u65ad\u4e00\u81f4\u6027\u548c\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u6cd5\u533b\u6b7b\u56e0\u9274\u5b9a\u4e2d\u7684\u4eba\u529b\u77ed\u7f3a\u548c\u8bca\u65ad\u5dee\u5f02\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u4e2d\u56fd\u7b49\u6848\u4ef6\u91cf\u5927\u7684\u6cd5\u533b\u4f53\u7cfb\u4e2d\u3002", "method": "FEAT\u91c7\u7528\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u5305\u62ec\u4efb\u52a1\u5206\u89e3\u7684\u4e2d\u592e\u89c4\u5212\u5668\u3001\u8bc1\u636e\u5206\u6790\u7684\u4e13\u4e1a\u5c40\u90e8\u6c42\u89e3\u5668\u3001\u8fed\u4ee3\u4f18\u5316\u7684\u8bb0\u5fc6\u4e0e\u53cd\u601d\u6a21\u5757\uff0c\u4ee5\u53ca\u7ed3\u8bba\u5408\u6210\u7684\u5168\u5c40\u6c42\u89e3\u5668\u3002\u7ed3\u5408\u5de5\u5177\u589e\u5f3a\u63a8\u7406\u3001\u5206\u5c42\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u6cd5\u533b\u8c03\u4f18\u7684LLM\u3002", "result": "\u5728\u591a\u6837\u5316\u4e2d\u56fd\u6848\u4f8b\u4e2d\uff0cFEAT\u4f18\u4e8e\u73b0\u6709AI\u7cfb\u7edf\uff0c\u8868\u73b0\u7a33\u5065\u4e14\u4e13\u5bb6\u4e00\u81f4\u6027\u9ad8\uff0c\u80fd\u68c0\u6d4b\u7ec6\u5fae\u8bc1\u636e\u3002", "conclusion": "FEAT\u662f\u9996\u4e2a\u57fa\u4e8eLLM\u7684\u6cd5\u533bAI\u7cfb\u7edf\uff0c\u7ed3\u5408AI\u6548\u7387\u4e0e\u4eba\u7c7b\u76d1\u7763\uff0c\u53ef\u63d0\u5347\u6cd5\u533b\u670d\u52a1\u7684\u53ef\u53ca\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2508.08001", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08001", "abs": "https://arxiv.org/abs/2508.08001", "authors": ["Rui Yao", "Qi Chai", "Jinhai Yao", "Siyuan Li", "Junhao Chen", "Qi Zhang", "Hao Wang"], "title": "Interpreting Fedspeak with Confidence: A LLM-Based Uncertainty-Aware Framework Guided by Monetary Policy Transmission Paths", "comment": "Rui Yao, Qi Chai, and Jinhai Yao contributed equally to this work.\n  Corresponding authors: Qi Zhang (zhang.qi@sjtu.edu.cn) and Hao Wang\n  (haowang@hkust-gz.edu.cn)", "summary": "\"Fedspeak\", the stylized and often nuanced language used by the U.S. Federal\nReserve, encodes implicit policy signals and strategic stances. The Federal\nOpen Market Committee strategically employs Fedspeak as a communication tool to\nshape market expectations and influence both domestic and global economic\nconditions. As such, automatically parsing and interpreting Fedspeak presents a\nhigh-impact challenge, with significant implications for financial forecasting,\nalgorithmic trading, and data-driven policy analysis. In this paper, we propose\nan LLM-based, uncertainty-aware framework for deciphering Fedspeak and\nclassifying its underlying monetary policy stance. Technically, to enrich the\nsemantic and contextual representation of Fedspeak texts, we incorporate\ndomain-specific reasoning grounded in the monetary policy transmission\nmechanism. We further introduce a dynamic uncertainty decoding module to assess\nthe confidence of model predictions, thereby enhancing both classification\naccuracy and model reliability. Experimental results demonstrate that our\nframework achieves state-of-the-art performance on the policy stance analysis\ntask. Moreover, statistical analysis reveals a significant positive correlation\nbetween perceptual uncertainty and model error rates, validating the\neffectiveness of perceptual uncertainty as a diagnostic signal.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u3001\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u6790\u7f8e\u8054\u50a8\u7684Fedspeak\u5e76\u5206\u7c7b\u5176\u8d27\u5e01\u653f\u7b56\u7acb\u573a\uff0c\u7ed3\u5408\u9886\u57df\u7279\u5b9a\u63a8\u7406\u548c\u52a8\u6001\u4e0d\u786e\u5b9a\u6027\u89e3\u7801\u6a21\u5757\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5206\u7c7b\u51c6\u786e\u6027\u548c\u6a21\u578b\u53ef\u9760\u6027\u3002", "motivation": "\u7f8e\u8054\u50a8\u7684Fedspeak\u662f\u4e00\u79cd\u9690\u542b\u653f\u7b56\u4fe1\u53f7\u7684\u8bed\u8a00\uff0c\u81ea\u52a8\u89e3\u6790\u5176\u5185\u5bb9\u5bf9\u91d1\u878d\u9884\u6d4b\u548c\u7b97\u6cd5\u4ea4\u6613\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u91c7\u7528LLM\u6846\u67b6\uff0c\u7ed3\u5408\u8d27\u5e01\u653f\u7b56\u4f20\u5bfc\u673a\u5236\u7684\u9886\u57df\u7279\u5b9a\u63a8\u7406\uff0c\u5e76\u5f15\u5165\u52a8\u6001\u4e0d\u786e\u5b9a\u6027\u89e3\u7801\u6a21\u5757\u8bc4\u4f30\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u653f\u7b56\u7acb\u573a\u5206\u6790\u4efb\u52a1\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u4e14\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\u4e0e\u6a21\u578b\u9519\u8bef\u7387\u663e\u8457\u6b63\u76f8\u5173\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86Fedspeak\u7684\u89e3\u6790\u80fd\u529b\uff0c\u4e3a\u91d1\u878d\u548c\u653f\u7b56\u5206\u6790\u63d0\u4f9b\u4e86\u53ef\u9760\u5de5\u5177\u3002"}}
{"id": "2508.08007", "categories": ["cs.AI", "Computing methodologies~Description logics, Computing\n  methodologies~Ontology engineering"], "pdf": "https://arxiv.org/pdf/2508.08007", "abs": "https://arxiv.org/abs/2508.08007", "authors": ["Maurice Funk", "Marvin Grosser", "Carsten Lutz"], "title": "Fitting Description Logic Ontologies to ABox and Query Examples", "comment": "Submitted to the 22nd International Conference on Principles of\n  Knowledge Representation and Reasoning (KR2025), 23 pages", "summary": "We study a fitting problem inspired by ontology-mediated querying: given a\ncollection\n  of positive and negative examples of\n  the form $(\\mathcal{A},q)$ with\n  $\\mathcal{A}$ an ABox and $q$ a Boolean query, we seek\n  an ontology $\\mathcal{O}$ that satisfies $\\mathcal{A} \\cup \\mathcal{O} \\vDash\nq$ for all positive examples and $\\mathcal{A} \\cup \\mathcal{O}\\not\\vDash q$ for\nall negative examples.\n  We consider the description logics $\\mathcal{ALC}$ and $\\mathcal{ALCI}$ as\nontology languages and\n  a range of query languages that\n  includes atomic queries (AQs), conjunctive queries (CQs), and unions thereof\n(UCQs).\n  For all of the resulting fitting problems,\n  we provide\n  effective characterizations and determine the computational complexity\n  of deciding whether a fitting ontology exists. This problem turns out to be\n${\\small CO}NP$ for AQs and full CQs\n  and $2E{\\small XP}T{\\small IME}$-complete for CQs and UCQs.\n  These results hold for both $\\mathcal{ALC}$ and $\\mathcal{ALCI}$.", "AI": {"tldr": "\u7814\u7a76\u57fa\u4e8e\u672c\u4f53\u4ecb\u5bfc\u67e5\u8be2\u7684\u62df\u5408\u95ee\u9898\uff0c\u786e\u5b9a\u662f\u5426\u5b58\u5728\u6ee1\u8db3\u6b63\u8d1f\u4f8b\u7684\u672c\u4f53\uff0c\u5e76\u5206\u6790\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u89e3\u51b3\u672c\u4f53\u4ecb\u5bfc\u67e5\u8be2\u4e2d\u62df\u5408\u95ee\u9898\u7684\u5b58\u5728\u6027\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u7406\u8bba\u652f\u6301\u3002", "method": "\u4f7f\u7528\u63cf\u8ff0\u903b\u8f91ALC\u548cALCI\u4f5c\u4e3a\u672c\u4f53\u8bed\u8a00\uff0c\u7ed3\u5408\u591a\u79cd\u67e5\u8be2\u8bed\u8a00\uff08AQs\u3001CQs\u3001UCQs\uff09\uff0c\u5206\u6790\u62df\u5408\u95ee\u9898\u7684\u6709\u6548\u8868\u5f81\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u53d1\u73b0\u62df\u5408\u95ee\u9898\u5bf9AQs\u548c\u5b8c\u6574CQs\u662fCONP\u590d\u6742\u5ea6\uff0c\u5bf9CQs\u548cUCQs\u662f2EXPTIME\u5b8c\u5168\u590d\u6742\u5ea6\u3002", "conclusion": "\u7814\u7a76\u4e3a\u4e0d\u540c\u67e5\u8be2\u8bed\u8a00\u4e0b\u7684\u672c\u4f53\u62df\u5408\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u548c\u590d\u6742\u5ea6\u754c\u9650\uff0c\u9002\u7528\u4e8eALC\u548cALCI\u3002"}}
{"id": "2508.08053", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08053", "abs": "https://arxiv.org/abs/2508.08053", "authors": ["Runchuan Zhu", "Bowen Jiang", "Lingrui Mei", "Fangkai Yang", "Lu Wang", "Haoxiang Gao", "Fengshuo Bai", "Pu Zhao", "Qingwei Lin", "Saravan Rajmohan", "Dongmei Zhang"], "title": "AdaptFlow: Adaptive Workflow Optimization via Meta-Learning", "comment": null, "summary": "Recent advances in large language models (LLMs) have sparked growing interest\nin agentic workflows, which are structured sequences of LLM invocations\nintended to solve complex tasks. However, existing approaches often rely on\nstatic templates or manually designed workflows, which limit adaptability to\ndiverse tasks and hinder scalability. We propose AdaptFlow, a natural\nlanguage-based meta-learning framework inspired by model-agnostic meta-learning\n(MAML). AdaptFlow learns a generalizable workflow initialization that enables\nrapid subtask-level adaptation. It employs a bi-level optimization scheme: the\ninner loop refines the workflow for a specific subtask using LLM-generated\nfeedback, while the outer loop updates the shared initialization to perform\nwell across tasks. This setup allows AdaptFlow to generalize effectively to\nunseen tasks by adapting the initialized workflow through language-guided\nmodifications. Evaluated across question answering, code generation, and\nmathematical reasoning benchmarks, AdaptFlow consistently outperforms both\nmanually crafted and automatically searched baselines, achieving\nstate-of-the-art results with strong generalization across tasks and models.\nThe source code and data are available at\nhttps://github.com/microsoft/DKI_LLM/tree/AdaptFlow/AdaptFlow.", "AI": {"tldr": "AdaptFlow\u662f\u4e00\u4e2a\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u7684\u5143\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u5c42\u4f18\u5316\u5b9e\u73b0\u4efb\u52a1\u7ea7\u522b\u7684\u5feb\u901f\u9002\u5e94\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5de5\u4f5c\u6d41\u901a\u5e38\u4f9d\u8d56\u9759\u6001\u6a21\u677f\u6216\u624b\u52a8\u8bbe\u8ba1\uff0c\u9650\u5236\u4e86\u9002\u5e94\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "AdaptFlow\u91c7\u7528\u53cc\u5c42\u4f18\u5316\uff1a\u5185\u5c42\u901a\u8fc7LLM\u53cd\u9988\u4f18\u5316\u5b50\u4efb\u52a1\u5de5\u4f5c\u6d41\uff0c\u5916\u5c42\u66f4\u65b0\u5171\u4eab\u521d\u59cb\u5316\u4ee5\u5b9e\u73b0\u8de8\u4efb\u52a1\u6cdb\u5316\u3002", "result": "\u5728\u95ee\u7b54\u3001\u4ee3\u7801\u751f\u6210\u548c\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\uff0cAdaptFlow\u8868\u73b0\u4f18\u4e8e\u624b\u52a8\u548c\u81ea\u52a8\u57fa\u7ebf\uff0c\u8fbe\u5230SOTA\u3002", "conclusion": "AdaptFlow\u901a\u8fc7\u8bed\u8a00\u5f15\u5bfc\u7684\u4fee\u6539\u5b9e\u73b0\u6cdb\u5316\uff0c\u4e3a\u590d\u6742\u4efb\u52a1\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u5de5\u4f5c\u6d41\u9002\u5e94\u65b9\u6848\u3002"}}
{"id": "2508.08075", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08075", "abs": "https://arxiv.org/abs/2508.08075", "authors": ["Meishen He", "Wenjun Ma", "Jiao Wang", "Huijun Yue", "Xiaoma Fan"], "title": "FNBT: Full Negation Belief Transformation for Open-World Information Fusion Based on Dempster-Shafer Theory of Evidence", "comment": null, "summary": "The Dempster-Shafer theory of evidence has been widely applied in the field\nof information fusion under uncertainty. Most existing research focuses on\ncombining evidence within the same frame of discernment. However, in real-world\nscenarios, trained algorithms or data often originate from different regions or\norganizations, where data silos are prevalent. As a result, using different\ndata sources or models to generate basic probability assignments may lead to\nheterogeneous frames, for which traditional fusion methods often yield\nunsatisfactory results. To address this challenge, this study proposes an\nopen-world information fusion method, termed Full Negation Belief\nTransformation (FNBT), based on the Dempster-Shafer theory. More specially, a\ncriterion is introduced to determine whether a given fusion task belongs to the\nopen-world setting. Then, by extending the frames, the method can accommodate\nelements from heterogeneous frames. Finally, a full negation mechanism is\nemployed to transform the mass functions, so that existing combination rules\ncan be applied to the transformed mass functions for such information fusion.\nTheoretically, the proposed method satisfies three desirable properties, which\nare formally proven: mass function invariance, heritability, and essential\nconflict elimination. Empirically, FNBT demonstrates superior performance in\npattern classification tasks on real-world datasets and successfully resolves\nZadeh's counterexample, thereby validating its practical effectiveness.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eDempster-Shafer\u7406\u8bba\u7684\u5f00\u653e\u4e16\u754c\u4fe1\u606f\u878d\u5408\u65b9\u6cd5FNBT\uff0c\u89e3\u51b3\u4e86\u5f02\u6784\u6846\u67b6\u4e0b\u8bc1\u636e\u878d\u5408\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u5b9e\u573a\u666f\u4e2d\uff0c\u6570\u636e\u6216\u6a21\u578b\u5e38\u6765\u81ea\u4e0d\u540c\u533a\u57df\u6216\u7ec4\u7ec7\uff0c\u5bfc\u81f4\u5f02\u6784\u6846\u67b6\uff0c\u4f20\u7edf\u878d\u5408\u65b9\u6cd5\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u5f15\u5165\u6807\u51c6\u5224\u65ad\u5f00\u653e\u4e16\u754c\u4efb\u52a1\uff0c\u6269\u5c55\u6846\u67b6\u4ee5\u5bb9\u7eb3\u5f02\u6784\u5143\u7d20\uff0c\u91c7\u7528\u5168\u5426\u5b9a\u673a\u5236\u8f6c\u6362\u8d28\u91cf\u51fd\u6570\uff0c\u5e94\u7528\u73b0\u6709\u7ec4\u5408\u89c4\u5219\u3002", "result": "\u7406\u8bba\u6ee1\u8db3\u8d28\u91cf\u51fd\u6570\u4e0d\u53d8\u6027\u3001\u9057\u4f20\u6027\u548c\u672c\u8d28\u51b2\u7a81\u6d88\u9664\uff1b\u5b9e\u8bc1\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u89e3\u51b3\u4e86Zadeh\u53cd\u4f8b\u3002", "conclusion": "FNBT\u65b9\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e2d\u5747\u6709\u6548\uff0c\u9002\u7528\u4e8e\u5f00\u653e\u4e16\u754c\u4fe1\u606f\u878d\u5408\u3002"}}
{"id": "2508.08115", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08115", "abs": "https://arxiv.org/abs/2508.08115", "authors": ["Pranav Pushkar Mishra", "Mohammad Arvan", "Mohan Zalake"], "title": "TeamMedAgents: Enhancing Medical Decision-Making of LLMs Through Structured Teamwork", "comment": "10 pages, 1 figure, 6 tables(2 in main, 4 in appendix)", "summary": "We present TeamMedAgents, a novel multi-agent approach that systematically\nintegrates evidence-based teamwork components from human-human collaboration\ninto medical decision-making with large language models (LLMs). Our approach\nvalidates an organizational psychology teamwork model from human collaboration\nto computational multi-agent medical systems by operationalizing six core\nteamwork components derived from Salas et al.'s \"Big Five\" model: team\nleadership, mutual performance monitoring, team orientation, shared mental\nmodels, closed-loop communication, and mutual trust. We implement and evaluate\nthese components as modular, configurable mechanisms within an adaptive\ncollaboration architecture while assessing the effect of the number of agents\ninvolved based on the task's requirements and domain. Systematic evaluation of\ncomputational implementations of teamwork behaviors across eight medical\nbenchmarks (MedQA, MedMCQA, MMLU-Pro Medical, PubMedQA, DDXPlus, MedBullets,\nPath-VQA, and PMC-VQA) demonstrates consistent improvements across 7 out of 8\nevaluated datasets. Controlled ablation studies conducted on 50 questions per\nconfiguration across 3 independent runs provide mechanistic insights into\nindividual component contributions, revealing optimal teamwork configurations\nthat vary by reasoning task complexity and domain-specific requirements. Our\nablation analyses reveal dataset-specific optimal teamwork configurations,\nindicating that different medical reasoning modalities benefit from distinct\ncollaborative patterns. TeamMedAgents represents an advancement in\ncollaborative AI by providing a systematic translation of established teamwork\ntheories from human collaboration into agentic collaboration, establishing a\nfoundation for evidence-based multi-agent system design in critical\ndecision-making domains.", "AI": {"tldr": "TeamMedAgents\u901a\u8fc7\u5c06\u4eba\u7c7b\u56e2\u961f\u5408\u4f5c\u7684\u5fc3\u7406\u5b66\u6a21\u578b\u5e94\u7528\u4e8e\u591a\u4ee3\u7406\u533b\u7597\u51b3\u7b56\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u533b\u7597\u57fa\u51c6\u6d4b\u8bd5\u7684\u8868\u73b0\u3002", "motivation": "\u5c06\u4eba\u7c7b\u56e2\u961f\u5408\u4f5c\u7684\u5fc3\u7406\u5b66\u7406\u8bba\uff08\u5982Salas\u7684\u201cBig Five\u201d\u6a21\u578b\uff09\u5e94\u7528\u4e8eAI\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u4ee5\u63d0\u5347\u533b\u7597\u51b3\u7b56\u7684\u534f\u4f5c\u6548\u679c\u3002", "method": "\u5b9e\u73b0\u5e76\u8bc4\u4f30\u516d\u4e2a\u56e2\u961f\u5408\u4f5c\u6838\u5fc3\u7ec4\u4ef6\uff08\u5982\u56e2\u961f\u9886\u5bfc\u529b\u3001\u5171\u4eab\u5fc3\u667a\u6a21\u578b\u7b49\uff09\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u673a\u5236\u5728\u591a\u4ee3\u7406\u67b6\u6784\u4e2d\u9a8c\u8bc1\u5176\u6548\u679c\u3002", "result": "\u57288\u4e2a\u533b\u7597\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c7\u4e2a\u8868\u73b0\u663e\u8457\u63d0\u5347\uff0c\u4e14\u4e0d\u540c\u4efb\u52a1\u548c\u9886\u57df\u9700\u8981\u4e0d\u540c\u7684\u56e2\u961f\u5408\u4f5c\u914d\u7f6e\u3002", "conclusion": "TeamMedAgents\u4e3a\u5173\u952e\u51b3\u7b56\u9886\u57df\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u57fa\u4e8e\u8bc1\u636e\u7684\u65b9\u6cd5\uff0c\u63a8\u52a8\u4e86\u534f\u4f5cAI\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.08127", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08127", "abs": "https://arxiv.org/abs/2508.08127", "authors": ["Rui Miao", "Yixin Liu", "Yili Wang", "Xu Shen", "Yue Tan", "Yiwei Dai", "Shirui Pan", "Xin Wang"], "title": "BlindGuard: Safeguarding LLM-based Multi-Agent Systems under Unknown Attacks", "comment": null, "summary": "The security of LLM-based multi-agent systems (MAS) is critically threatened\nby propagation vulnerability, where malicious agents can distort collective\ndecision-making through inter-agent message interactions. While existing\nsupervised defense methods demonstrate promising performance, they may be\nimpractical in real-world scenarios due to their heavy reliance on labeled\nmalicious agents to train a supervised malicious detection model. To enable\npractical and generalizable MAS defenses, in this paper, we propose BlindGuard,\nan unsupervised defense method that learns without requiring any\nattack-specific labels or prior knowledge of malicious behaviors. To this end,\nwe establish a hierarchical agent encoder to capture individual, neighborhood,\nand global interaction patterns of each agent, providing a comprehensive\nunderstanding for malicious agent detection. Meanwhile, we design a\ncorruption-guided detector that consists of directional noise injection and\ncontrastive learning, allowing effective detection model training solely on\nnormal agent behaviors. Extensive experiments show that BlindGuard effectively\ndetects diverse attack types (i.e., prompt injection, memory poisoning, and\ntool attack) across MAS with various communication patterns while maintaining\nsuperior generalizability compared to supervised baselines. The code is\navailable at: https://github.com/MR9812/BlindGuard.", "AI": {"tldr": "BlindGuard\u662f\u4e00\u79cd\u65e0\u76d1\u7763\u9632\u5fa1\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u6076\u610f\u4ee3\u7406\uff0c\u65e0\u9700\u653b\u51fb\u6807\u7b7e\u6216\u5148\u9a8c\u77e5\u8bc6\u3002", "motivation": "\u73b0\u6709\u76d1\u7763\u9632\u5fa1\u65b9\u6cd5\u4f9d\u8d56\u6807\u8bb0\u6570\u636e\uff0c\u4e0d\u9002\u7528\u4e8e\u5b9e\u9645\u573a\u666f\uff0c\u9700\u5f00\u53d1\u66f4\u901a\u7528\u7684\u65e0\u76d1\u7763\u9632\u5fa1\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5206\u5c42\u4ee3\u7406\u7f16\u7801\u5668\u6355\u6349\u4e2a\u4f53\u3001\u90bb\u57df\u548c\u5168\u5c40\u4ea4\u4e92\u6a21\u5f0f\uff0c\u7ed3\u5408\u566a\u58f0\u6ce8\u5165\u548c\u5bf9\u6bd4\u5b66\u4e60\u8bad\u7ec3\u68c0\u6d4b\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8868\u660eBlindGuard\u80fd\u6709\u6548\u68c0\u6d4b\u591a\u79cd\u653b\u51fb\u7c7b\u578b\uff0c\u4e14\u6cdb\u5316\u80fd\u529b\u4f18\u4e8e\u76d1\u7763\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "BlindGuard\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u901a\u7528\u7684\u65e0\u76d1\u7763\u9632\u5fa1\u65b9\u6848\u3002"}}
{"id": "2508.08147", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08147", "abs": "https://arxiv.org/abs/2508.08147", "authors": ["Yunkai Hu", "Tianqiao Zhao", "Meng Yue"], "title": "From Natural Language to Solver-Ready Power System Optimization: An LLM-Assisted, Validation-in-the-Loop Framework", "comment": null, "summary": "This paper introduces a novel Large Language Models (LLMs)-assisted agent\nthat automatically converts natural-language descriptions of power system\noptimization scenarios into compact, solver-ready formulations and generates\ncorresponding solutions. In contrast to approaches that rely solely on LLM to\nproduce solutions directly, the proposed method focuses on discovering a\nmathematically compatible formulation that can be efficiently solved by\noff-the-shelf optimization solvers. Directly using LLMs to produce solutions\noften leads to infeasible or suboptimal results, as these models lack the\nnumerical precision and constraint-handling capabilities of established\noptimization solvers. The pipeline integrates a domain-aware prompt and schema\nwith an LLM, enforces feasibility through systematic validation and iterative\nrepair, and returns both solver-ready models and user-facing results. Using the\nunit commitment problem as a representative case study, the agent produces\noptimal or near-optimal schedules along with the associated objective costs.\nResults demonstrate that coupling the solver with task-specific validation\nsignificantly enhances solution reliability. This work shows that combining AI\nwith established optimization frameworks bridges high-level problem\ndescriptions and executable mathematical models, enabling more efficient\ndecision-making in energy systems", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u4ee3\u7406\uff0c\u5c06\u7535\u529b\u7cfb\u7edf\u4f18\u5316\u573a\u666f\u7684\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u81ea\u52a8\u8f6c\u6362\u4e3a\u7d27\u51d1\u3001\u53ef\u6c42\u89e3\u7684\u6570\u5b66\u516c\u5f0f\uff0c\u5e76\u751f\u6210\u89e3\u51b3\u65b9\u6848\u3002\u8be5\u65b9\u6cd5\u907f\u514d\u4e86\u76f4\u63a5\u4f7f\u7528LLMs\u751f\u6210\u89e3\u51b3\u65b9\u6848\u7684\u4e0d\u53ef\u884c\u6216\u6b21\u4f18\u95ee\u9898\uff0c\u901a\u8fc7\u9a8c\u8bc1\u548c\u8fed\u4ee3\u4fee\u590d\u786e\u4fdd\u53ef\u884c\u6027\u3002", "motivation": "\u76f4\u63a5\u4f7f\u7528LLMs\u751f\u6210\u4f18\u5316\u95ee\u9898\u7684\u89e3\u51b3\u65b9\u6848\u5e38\u5bfc\u81f4\u4e0d\u53ef\u884c\u6216\u6b21\u4f18\u7ed3\u679c\uff0c\u56e0\u5176\u7f3a\u4e4f\u6570\u503c\u7cbe\u5ea6\u548c\u7ea6\u675f\u5904\u7406\u80fd\u529b\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u7ed3\u5408LLMs\u4e0e\u4f20\u7edf\u4f18\u5316\u6c42\u89e3\u5668\uff0c\u5b9e\u73b0\u9ad8\u6548\u53ef\u9760\u7684\u51b3\u7b56\u652f\u6301\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408LLMs\u548c\u4f18\u5316\u6c42\u89e3\u5668\u7684\u6d41\u7a0b\uff0c\u5305\u62ec\u9886\u57df\u611f\u77e5\u63d0\u793a\u3001\u7cfb\u7edf\u9a8c\u8bc1\u548c\u8fed\u4ee3\u4fee\u590d\uff0c\u751f\u6210\u53ef\u6c42\u89e3\u7684\u6570\u5b66\u6a21\u578b\u3002\u4ee5\u673a\u7ec4\u7ec4\u5408\u95ee\u9898\u4e3a\u4f8b\u9a8c\u8bc1\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u751f\u6210\u6700\u4f18\u6216\u63a5\u8fd1\u6700\u4f18\u7684\u8c03\u5ea6\u65b9\u6848\u53ca\u76ee\u6807\u6210\u672c\uff0c\u9a8c\u8bc1\u4e86\u7ed3\u5408\u4efb\u52a1\u7279\u5b9a\u9a8c\u8bc1\u7684\u6c42\u89e3\u5668\u663e\u8457\u63d0\u5347\u89e3\u51b3\u65b9\u6848\u7684\u53ef\u9760\u6027\u3002", "conclusion": "\u7ed3\u5408AI\u4e0e\u4f20\u7edf\u4f18\u5316\u6846\u67b6\uff0c\u80fd\u591f\u9ad8\u6548\u5730\u5c06\u9ad8\u5c42\u95ee\u9898\u63cf\u8ff0\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u7684\u6570\u5b66\u6a21\u578b\uff0c\u63d0\u5347\u80fd\u6e90\u7cfb\u7edf\u51b3\u7b56\u6548\u7387\u3002"}}
{"id": "2508.05691", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.05691", "abs": "https://arxiv.org/abs/2508.05691", "authors": ["Kai Yao", "Marc Juarez"], "title": "AuthPrint: Fingerprinting Generative Models Against Malicious Model Providers", "comment": null, "summary": "Generative models are increasingly adopted in high-stakes domains, yet\ncurrent deployments offer no mechanisms to verify the origin of model outputs.\nWe address this gap by extending model fingerprinting techniques beyond the\ntraditional collaborative setting to one where the model provider may act\nadversarially. To our knowledge, this is the first work to evaluate\nfingerprinting for provenance attribution under such a threat model. The\nmethods rely on a trusted verifier that extracts secret fingerprints from the\nmodel's output space, unknown to the provider, and trains a model to predict\nand verify them. Our empirical evaluation shows that our methods achieve\nnear-zero FPR@95%TPR for instances of GAN and diffusion models, even when\ntested on small modifications to the original architecture and training data.\nMoreover, the methods remain robust against adversarial attacks that actively\nmodify the outputs to bypass detection. Source codes are available at\nhttps://github.com/PSMLab/authprint.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5bf9\u6297\u6027\u6a21\u578b\u6307\u7eb9\u6280\u672f\uff0c\u7528\u4e8e\u9a8c\u8bc1\u751f\u6210\u6a21\u578b\u8f93\u51fa\u7684\u6765\u6e90\uff0c\u5373\u4f7f\u5728\u6a21\u578b\u63d0\u4f9b\u8005\u53ef\u80fd\u5bf9\u6297\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u6709\u6548\u5de5\u4f5c\u3002", "motivation": "\u5f53\u524d\u751f\u6210\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u9886\u57df\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u7f3a\u4e4f\u9a8c\u8bc1\u8f93\u51fa\u6765\u6e90\u7684\u673a\u5236\uff0c\u5c24\u5176\u662f\u5728\u6a21\u578b\u63d0\u4f9b\u8005\u53ef\u80fd\u5bf9\u6297\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u901a\u8fc7\u53ef\u4fe1\u9a8c\u8bc1\u5668\u4ece\u6a21\u578b\u8f93\u51fa\u7a7a\u95f4\u4e2d\u63d0\u53d6\u79d8\u5bc6\u6307\u7eb9\uff0c\u5e76\u8bad\u7ec3\u6a21\u578b\u9884\u6d4b\u548c\u9a8c\u8bc1\u8fd9\u4e9b\u6307\u7eb9\uff0c\u4ee5\u5bf9\u6297\u6a21\u578b\u63d0\u4f9b\u8005\u7684\u6f5c\u5728\u5bf9\u6297\u884c\u4e3a\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728GAN\u548c\u6269\u6563\u6a21\u578b\u4e0a\u5b9e\u73b0\u4e86\u63a5\u8fd1\u96f6\u7684FPR@95%TPR\uff0c\u5373\u4f7f\u5bf9\u539f\u59cb\u67b6\u6784\u548c\u8bad\u7ec3\u6570\u636e\u8fdb\u884c\u5c0f\u4fee\u6539\u4e5f\u80fd\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u751f\u6210\u6a21\u578b\u7684\u6765\u6e90\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5373\u4f7f\u5728\u5bf9\u6297\u6027\u73af\u5883\u4e0b\u4e5f\u80fd\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
