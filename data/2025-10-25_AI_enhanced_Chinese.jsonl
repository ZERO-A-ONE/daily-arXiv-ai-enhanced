{"id": "2510.19835", "categories": ["cs.AI", "cs.ET", "cs.NE", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.19835", "abs": "https://arxiv.org/abs/2510.19835", "authors": ["Max B. Zhao", "Fei Li"], "title": "A Quantum-Inspired Algorithm for Solving Sudoku Puzzles and the MaxCut Problem", "comment": "29 pages, 10 figures, accepted by Quantum Information & Computation\n  on August 6, 2025", "summary": "We propose and evaluate a quantum-inspired algorithm for solving Quadratic\nUnconstrained Binary Optimization (QUBO) problems, which are mathematically\nequivalent to finding ground states of Ising spin-glass Hamiltonians. The\nalgorithm employs Matrix Product States (MPS) to compactly represent large\nsuperpositions of spin configurations and utilizes a discrete driving schedule\nto guide the MPS toward the ground state. At each step, a driver Hamiltonian --\nincorporating a transverse magnetic field -- is combined with the problem\nHamiltonian to enable spin flips and facilitate quantum tunneling. The MPS is\nupdated using the standard Density Matrix Renormalization Group (DMRG) method,\nwhich iteratively minimizes the system's energy via multiple sweeps across the\nspin chain. Despite its heuristic nature, the algorithm reliably identifies\nglobal minima, not merely near-optimal solutions, across diverse QUBO\ninstances. We first demonstrate its effectiveness on intermediate-level Sudoku\npuzzles from publicly available sources, involving over $200$ Ising spins with\nlong-range couplings dictated by constraint satisfaction. We then apply the\nalgorithm to MaxCut problems from the Biq Mac library, successfully solving\ninstances with up to $251$ nodes and $3,265$ edges. We discuss the advantages\nof this quantum-inspired approach, including its scalability, generalizability,\nand suitability for industrial-scale QUBO applications.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u91cf\u5b50\u542f\u53d1\u7684\u7b97\u6cd5\uff0c\u4f7f\u7528\u77e9\u9635\u4e58\u79ef\u6001\u548c\u79bb\u6563\u9a71\u52a8\u8c03\u5ea6\u6765\u89e3\u51b3QUBO\u95ee\u9898\uff0c\u5728\u591a\u79cd\u5b9e\u4f8b\u4e2d\u53ef\u9760\u627e\u5230\u5168\u5c40\u6700\u4f18\u89e3\uff0c\u5305\u62ec\u6570\u72ec\u548cMaxCut\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u4e8c\u6b21\u65e0\u7ea6\u675f\u4e8c\u8fdb\u5236\u4f18\u5316(QUBO)\u95ee\u9898\uff0c\u8fd9\u4e9b\u95ee\u9898\u5728\u6570\u5b66\u4e0a\u7b49\u4ef7\u4e8e\u5bfb\u627e\u4f0a\u8f9b\u81ea\u65cb\u73bb\u7483\u54c8\u5bc6\u987f\u91cf\u7684\u57fa\u6001\uff0c\u9700\u8981\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u80fd\u53ef\u9760\u627e\u5230\u5168\u5c40\u6700\u4f18\u89e3\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u77e9\u9635\u4e58\u79ef\u6001(MPS)\u7d27\u51d1\u8868\u793a\u81ea\u65cb\u6784\u578b\u7684\u5927\u53e0\u52a0\uff0c\u901a\u8fc7\u79bb\u6563\u9a71\u52a8\u8c03\u5ea6\u5f15\u5bfcMPS\u5411\u57fa\u6001\u6f14\u5316\uff0c\u7ed3\u5408\u9a71\u52a8\u54c8\u5bc6\u987f\u91cf\u548c\u95ee\u9898\u54c8\u5bc6\u987f\u91cf\u5b9e\u73b0\u81ea\u65cb\u7ffb\u8f6c\u548c\u91cf\u5b50\u96a7\u7a7f\uff0c\u4f7f\u7528\u5bc6\u5ea6\u77e9\u9635\u91cd\u6574\u5316\u7fa4(DMRG)\u65b9\u6cd5\u8fed\u4ee3\u66f4\u65b0MPS\u3002", "result": "\u7b97\u6cd5\u5728\u8d85\u8fc7200\u4e2a\u4f0a\u8f9b\u81ea\u65cb\u7684\u6570\u72ec\u95ee\u9898\u548cBiq Mac\u5e93\u4e2d\u6700\u591a251\u4e2a\u8282\u70b9\u30013265\u6761\u8fb9\u7684MaxCut\u95ee\u9898\u4e0a\u6210\u529f\u627e\u5230\u5168\u5c40\u6700\u5c0f\u503c\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u63a5\u8fd1\u6700\u4f18\u89e3\u3002", "conclusion": "\u8fd9\u79cd\u91cf\u5b50\u542f\u53d1\u65b9\u6cd5\u5177\u6709\u53ef\u6269\u5c55\u6027\u3001\u901a\u7528\u6027\u548c\u9002\u7528\u4e8e\u5de5\u4e1a\u7ea7QUBO\u5e94\u7528\u7684\u4f18\u52bf\u3002"}}
{"id": "2510.19836", "categories": ["cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.19836", "abs": "https://arxiv.org/abs/2510.19836", "authors": ["Eliseo Curcio"], "title": "Benchmarking Reasoning Reliability in Artificial Intelligence Models for Energy-System Analysis", "comment": null, "summary": "Artificial intelligence and machine learning are increasingly used for\nforecasting, optimization, and policy design in the energy sector, yet no\nstandardized framework exists to evaluate whether these systems reason\ncorrectly. Current validation practices focus on predictive accuracy or\ncomputational efficiency, leaving the logical integrity of analytical\nconclusions untested. This study introduces the Analytical Reliability\nBenchmark (ARB), a reproducible framework that quantifies reasoning reliability\nin large language models applied to energy system analysis. The benchmark\nintegrates five submetrics: accuracy, reasoning reliability, uncertainty\ndiscipline, policy consistency, and transparency, and evaluates model\nperformance across deterministic, probabilistic, and epistemic scenarios using\nopen technoeconomic datasets (NREL ATB 2024, DOE H2A/H2New, IEA WEO 2024). Four\nfrontier models (GPT-4/5, Claude 4.5 Sonnet, Gemini 2.5 Pro, Llama 3 70B) were\ntested under identical factual and regulatory conditions. Results show that\nreasoning reliability can be objectively measured. GPT-4/5 and Claude 4.5\nSonnet achieved consistent and policy-compliant reasoning (Analytical\nReliability Index greater than 90), Gemini 2.5 Pro demonstrated moderate\nstability, and Llama 3 70B remained below professional thresholds. Statistical\nvalidation confirmed that these differences are significant and reproducible.\nThe ARB establishes the first quantitative method in the energy literature for\nverifying causal, probabilistic, and policy-driven reasoning in artificial\nintelligence systems, providing a reference framework for trustworthy and\ntransparent analytical applications in the global energy transition.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u5206\u6790\u53ef\u9760\u6027\u57fa\u51c6(ARB)\uff0c\u8fd9\u662f\u9996\u4e2a\u7528\u4e8e\u91cf\u5316\u80fd\u6e90\u7cfb\u7edf\u5206\u6790\u4e2d\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u53ef\u9760\u6027\u7684\u6807\u51c6\u5316\u6846\u67b6\uff0c\u5305\u542b\u4e94\u4e2a\u5b50\u6307\u6807\uff0c\u5728\u56db\u79cd\u524d\u6cbf\u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u6d4b\u8bd5\u3002", "motivation": "\u5f53\u524dAI\u5728\u80fd\u6e90\u9886\u57df\u7684\u9a8c\u8bc1\u5b9e\u8df5\u4e3b\u8981\u5173\u6ce8\u9884\u6d4b\u51c6\u786e\u6027\u6216\u8ba1\u7b97\u6548\u7387\uff0c\u800c\u7f3a\u4e4f\u5bf9\u5206\u6790\u7ed3\u8bba\u903b\u8f91\u5b8c\u6574\u6027\u7684\u6807\u51c6\u5316\u6d4b\u8bd5\u6846\u67b6\u3002", "method": "\u5f00\u53d1\u4e86ARB\u6846\u67b6\uff0c\u6574\u5408\u51c6\u786e\u6027\u3001\u63a8\u7406\u53ef\u9760\u6027\u3001\u4e0d\u786e\u5b9a\u6027\u7eaa\u5f8b\u3001\u653f\u7b56\u4e00\u81f4\u6027\u548c\u900f\u660e\u5ea6\u4e94\u4e2a\u5b50\u6307\u6807\uff0c\u4f7f\u7528\u516c\u5f00\u6280\u672f\u7ecf\u6d4e\u6570\u636e\u96c6\u5728\u786e\u5b9a\u3001\u6982\u7387\u548c\u8ba4\u77e5\u573a\u666f\u4e0b\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "GPT-4/5\u548cClaude 4.5 Sonnet\u8fbe\u5230\u4e86\u4e00\u81f4\u4e14\u7b26\u5408\u653f\u7b56\u7684\u63a8\u7406(\u5206\u6790\u53ef\u9760\u6027\u6307\u6570\u5927\u4e8e90)\uff0cGemini 2.5 Pro\u8868\u73b0\u4e2d\u7b49\uff0cLlama 3 70B\u4f4e\u4e8e\u4e13\u4e1a\u9608\u503c\u3002\u7edf\u8ba1\u9a8c\u8bc1\u8868\u660e\u8fd9\u4e9b\u5dee\u5f02\u663e\u8457\u4e14\u53ef\u91cd\u73b0\u3002", "conclusion": "ARB\u5efa\u7acb\u4e86\u80fd\u6e90\u6587\u732e\u4e2d\u9996\u4e2a\u9a8c\u8bc1AI\u7cfb\u7edf\u4e2d\u56e0\u679c\u3001\u6982\u7387\u548c\u653f\u7b56\u9a71\u52a8\u63a8\u7406\u7684\u5b9a\u91cf\u65b9\u6cd5\uff0c\u4e3a\u5168\u7403\u80fd\u6e90\u8f6c\u578b\u4e2d\u53ef\u4fe1\u8d56\u548c\u900f\u660e\u7684\u5206\u6790\u5e94\u7528\u63d0\u4f9b\u4e86\u53c2\u8003\u6846\u67b6\u3002"}}
{"id": "2510.19838", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19838", "abs": "https://arxiv.org/abs/2510.19838", "authors": ["Shiqi He", "Yue Cui", "Xinyu Ma", "Yaliang Li", "Bolin Ding", "Mosharaf Chowdhury"], "title": "Branch-and-Browse: Efficient and Controllable Web Exploration with Tree-Structured Reasoning and Action Memory", "comment": null, "summary": "Autonomous web agents powered by large language models (LLMs) show strong\npotential for performing goal-oriented tasks such as information retrieval,\nreport generation, and online transactions. These agents mark a key step toward\npractical embodied reasoning in open web environments. However, existing\napproaches remain limited in reasoning depth and efficiency: vanilla linear\nmethods fail at multi-step reasoning and lack effective backtracking, while\nother search strategies are coarse-grained and computationally costly. We\nintroduce Branch-and-Browse, a fine-grained web agent framework that unifies\nstructured reasoning-acting, contextual memory, and efficient execution. It (i)\nemploys explicit subtask management with tree-structured exploration for\ncontrollable multi-branch reasoning, (ii) bootstraps exploration through\nefficient web state replay with background reasoning, and (iii) leverages a\npage action memory to share explored actions within and across sessions. On the\nWebArena benchmark, Branch-and-Browse achieves a task success rate of 35.8\\%\nand reduces execution time by up to 40.4\\% relative to state-of-the-art\nmethods. These results demonstrate that Branch-and-Browse is a reliable and\nefficient framework for LLM-based web agents.", "AI": {"tldr": "Branch-and-Browse\u662f\u4e00\u4e2a\u7ec6\u7c92\u5ea6\u7684\u7f51\u9875\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u6811\u7ed3\u6784\u63a2\u7d22\u3001\u7f51\u9875\u72b6\u6001\u91cd\u653e\u548c\u9875\u9762\u52a8\u4f5c\u8bb0\u5fc6\u6765\u63d0\u9ad8\u57fa\u4e8eLLM\u7684\u7f51\u9875\u4ee3\u7406\u7684\u63a8\u7406\u6df1\u5ea6\u548c\u6267\u884c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u7f51\u9875\u4ee3\u7406\u65b9\u6cd5\u5728\u63a8\u7406\u6df1\u5ea6\u548c\u6548\u7387\u4e0a\u5b58\u5728\u5c40\u9650\uff1a\u7ebf\u6027\u65b9\u6cd5\u65e0\u6cd5\u8fdb\u884c\u591a\u6b65\u63a8\u7406\u4e14\u7f3a\u4e4f\u6709\u6548\u56de\u6eaf\uff0c\u5176\u4ed6\u641c\u7d22\u7b56\u7565\u5219\u7c92\u5ea6\u7c97\u7cd9\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "\u91c7\u7528\u663e\u5f0f\u5b50\u4efb\u52a1\u7ba1\u7406\u548c\u6811\u7ed3\u6784\u63a2\u7d22\u5b9e\u73b0\u53ef\u63a7\u591a\u5206\u652f\u63a8\u7406\uff0c\u901a\u8fc7\u7f51\u9875\u72b6\u6001\u91cd\u653e\u8fdb\u884c\u9ad8\u6548\u63a2\u7d22\uff0c\u5e76\u5229\u7528\u9875\u9762\u52a8\u4f5c\u8bb0\u5fc6\u5728\u4f1a\u8bdd\u5185\u5916\u5171\u4eab\u5df2\u63a2\u7d22\u7684\u52a8\u4f5c\u3002", "result": "\u5728WebArena\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4efb\u52a1\u6210\u529f\u7387\u8fbe\u523035.8%\uff0c\u6267\u884c\u65f6\u95f4\u76f8\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u51cf\u5c11\u9ad8\u8fbe40.4%\u3002", "conclusion": "Branch-and-Browse\u662f\u4e00\u4e2a\u53ef\u9760\u4e14\u9ad8\u6548\u7684\u57fa\u4e8eLLM\u7684\u7f51\u9875\u4ee3\u7406\u6846\u67b6\u3002"}}
{"id": "2510.19842", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19842", "abs": "https://arxiv.org/abs/2510.19842", "authors": ["Yuanhe Zhang", "Ilja Kuzborskij", "Jason D. Lee", "Chenlei Leng", "Fanghui Liu"], "title": "DAG-Math: Graph-Guided Mathematical Reasoning in LLMs", "comment": "28 pages, 6 figures. Comments are welcome", "summary": "Large Language Models (LLMs) demonstrate strong performance on mathematical\nproblems when prompted with Chain-of-Thought (CoT), yet it remains unclear\nwhether this success stems from search, rote procedures, or rule-consistent\nreasoning. To address this, we propose modeling CoT as a certain rule-based\nstochastic process over directed acyclic graphs (DAGs), where nodes represent\nintermediate derivation states and edges encode rule applications. Within this\nframework, we introduce logical closeness, a metric that quantifies how well a\nmodel's CoT trajectory (i.e., the LLM's final output) adheres to the DAG\nstructure, providing evaluation beyond classical PASS@k metrics. Building on\nthis, we introduce the DAG-MATH CoT format and construct a benchmark that\nguides LLMs to generate CoT trajectories in this format, thereby enabling the\nevaluation of their reasoning ability under our framework. Across standard\nmathematical reasoning datasets, our analysis uncovers statistically\nsignificant differences in reasoning fidelity among representative LLM\nfamilies-even when PASS@k is comparable-highlighting gaps between final-answer\naccuracy and rule-consistent derivation. Our framework provides a balance\nbetween free-form CoT and formal proofs systems, offering actionable\ndiagnostics for LLMs reasoning evaluation. Our benchmark and code are available\nat: https://github.com/YuanheZ/DAG-MATH-Formatted-CoT.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6709\u5411\u65e0\u73af\u56fe(DAG)\u7684\u6846\u67b6\u6765\u8bc4\u4f30LLMs\u5728\u6570\u5b66\u63a8\u7406\u4e2d\u7684\u89c4\u5219\u4e00\u81f4\u6027\uff0c\u5f15\u5165\u903b\u8f91\u63a5\u8fd1\u5ea6\u6307\u6807\uff0c\u63ed\u793a\u4e86\u5373\u4f7f\u6700\u7ec8\u7b54\u6848\u51c6\u786e\u7387\u76f8\u540c\uff0c\u4e0d\u540cLLM\u5bb6\u65cf\u7684\u63a8\u7406\u4fdd\u771f\u5ea6\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e0d\u6e05\u695aLLMs\u5728\u6570\u5b66\u95ee\u9898\u4e0a\u7684\u6210\u529f\u662f\u6e90\u4e8e\u641c\u7d22\u3001\u673a\u68b0\u8bb0\u5fc6\u8fd8\u662f\u89c4\u5219\u4e00\u81f4\u7684\u63a8\u7406\uff0c\u9700\u8981\u8d85\u8d8a\u4f20\u7edfPASS@k\u6307\u6807\u6765\u8bc4\u4f30\u63a8\u7406\u8d28\u91cf\u3002", "method": "\u5c06\u601d\u7ef4\u94fe\u5efa\u6a21\u4e3a\u57fa\u4e8e\u89c4\u5219\u7684\u968f\u673a\u8fc7\u7a0b\uff0c\u6784\u5efaDAG-MATH CoT\u683c\u5f0f\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u903b\u8f91\u63a5\u8fd1\u5ea6\u6307\u6807\u91cf\u5316\u6a21\u578b\u63a8\u7406\u8f68\u8ff9\u4e0eDAG\u7ed3\u6784\u7684\u7b26\u5408\u7a0b\u5ea6\u3002", "result": "\u5728\u6807\u51c6\u6570\u5b66\u63a8\u7406\u6570\u636e\u96c6\u4e0a\u7684\u5206\u6790\u663e\u793a\uff0c\u5373\u4f7fPASS@k\u6307\u6807\u76f8\u5f53\uff0c\u4ee3\u8868\u6027LLM\u5bb6\u65cf\u7684\u63a8\u7406\u4fdd\u771f\u5ea6\u5b58\u5728\u7edf\u8ba1\u5b66\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u81ea\u7531\u5f62\u5f0f\u601d\u7ef4\u94fe\u548c\u5f62\u5f0f\u8bc1\u660e\u7cfb\u7edf\u4e4b\u95f4\u63d0\u4f9b\u4e86\u5e73\u8861\uff0c\u4e3aLLMs\u63a8\u7406\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u8bca\u65ad\u5de5\u5177\u3002"}}
{"id": "2510.19860", "categories": ["cs.SE", "D.2.5"], "pdf": "https://arxiv.org/pdf/2510.19860", "abs": "https://arxiv.org/abs/2510.19860", "authors": ["Ketai Qiu", "Luca Di Grazia", "Leonardo Mariani", "Mauro Pezz\u00e8"], "title": "E-Test: E'er-Improving Test Suites", "comment": "Accepted at the 48th IEEE/ACM International Conference on Software\n  Engineering (ICSE 2026)", "summary": "Test suites are inherently imperfect, and testers can always enrich a suite\nwith new test cases that improve its quality and, consequently, the reliability\nof the target software system. However, finding test cases that explore\nexecution scenarios beyond the scope of an existing suite can be extremely\nchallenging and labor-intensive, particularly when managing large test suites\nover extended periods.\n  In this paper, we propose E-Test, an approach that reduces the gap between\nthe execution space explored with a test suite and the executions experienced\nafter testing by augmenting the test suite with test cases that explore\nexecution scenarios that emerge in production. E-Test (i) identifies executions\nthat have not yet been tested from large sets of scenarios, such as those\nmonitored during intensive production usage, and (ii) generates new test cases\nthat enhance the test suite. E-Test leverages Large Language Models (LLMs) to\npinpoint scenarios that the current test suite does not adequately cover, and\naugments the suite with test cases that execute these scenarios.\n  Our evaluation on a dataset of 1,975 scenarios, collected from highly-starred\nopen-source Java projects already in production and Defects4J, demonstrates\nthat E-Test retrieves not-yet-tested execution scenarios significantly better\nthan state-of-the-art approaches. While existing regression testing and field\ntesting approaches for this task achieve a maximum F1-score of 0.34, and\nvanilla LLMs achieve a maximum F1-score of 0.39, E-Test reaches 0.55. These\nresults highlight the impact of E-Test in enhancing test suites by effectively\ntargeting not-yet-tested execution scenarios and reducing manual effort\nrequired for maintaining test suites.", "AI": {"tldr": "E-Test\u662f\u4e00\u79cd\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u751f\u4ea7\u73af\u5883\u4e2d\u8bc6\u522b\u672a\u6d4b\u8bd5\u6267\u884c\u573a\u666f\u5e76\u751f\u6210\u65b0\u6d4b\u8bd5\u7528\u4f8b\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6d4b\u8bd5\u5957\u4ef6\u7684\u8986\u76d6\u7387\u548c\u8d28\u91cf\u3002", "motivation": "\u6d4b\u8bd5\u5957\u4ef6\u5929\u7136\u4e0d\u5b8c\u7f8e\uff0c\u5bfb\u627e\u8d85\u51fa\u73b0\u6709\u6d4b\u8bd5\u5957\u4ef6\u8303\u56f4\u7684\u6267\u884c\u573a\u666f\u6781\u5177\u6311\u6218\u6027\u4e14\u52b3\u52a8\u5bc6\u96c6\uff0c\u7279\u522b\u662f\u5728\u957f\u671f\u7ba1\u7406\u5927\u578b\u6d4b\u8bd5\u5957\u4ef6\u65f6\u3002", "method": "E-Test\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u751f\u4ea7\u73af\u5883\u76d1\u63a7\u7684\u5927\u91cf\u573a\u666f\u4e2d\u8bc6\u522b\u672a\u6d4b\u8bd5\u7684\u6267\u884c\u573a\u666f\uff0c\u5e76\u751f\u6210\u65b0\u7684\u6d4b\u8bd5\u7528\u4f8b\u6765\u589e\u5f3a\u6d4b\u8bd5\u5957\u4ef6\u3002", "result": "\u57281,975\u4e2a\u573a\u666f\u7684\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cE-Test\u7684F1\u5206\u6570\u8fbe\u52300.55\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u56de\u5f52\u6d4b\u8bd5\u65b9\u6cd5\uff080.34\uff09\u548c\u666e\u901a\u5927\u8bed\u8a00\u6a21\u578b\u65b9\u6cd5\uff080.39\uff09\u3002", "conclusion": "E-Test\u901a\u8fc7\u6709\u6548\u5b9a\u4f4d\u672a\u6d4b\u8bd5\u6267\u884c\u573a\u666f\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u6d4b\u8bd5\u5957\u4ef6\uff0c\u51cf\u5c11\u4e86\u7ef4\u62a4\u6d4b\u8bd5\u5957\u4ef6\u6240\u9700\u7684\u624b\u52a8\u5de5\u4f5c\u91cf\u3002"}}
{"id": "2510.19844", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19844", "abs": "https://arxiv.org/abs/2510.19844", "authors": ["Isaac Wu", "Michael Maslowski"], "title": "CourtGuard: A Local, Multiagent Prompt Injection Classifier", "comment": "11 pages, 7 figures", "summary": "As large language models (LLMs) become integrated into various sensitive\napplications, prompt injection, the use of prompting to induce harmful\nbehaviors from LLMs, poses an ever increasing risk. Prompt injection attacks\ncan cause LLMs to leak sensitive data, spread misinformation, and exhibit\nharmful behaviors. To defend against these attacks, we propose CourtGuard, a\nlocally-runnable, multiagent prompt injection classifier. In it, prompts are\nevaluated in a court-like multiagent LLM system, where a \"defense attorney\"\nmodel argues the prompt is benign, a \"prosecution attorney\" model argues the\nprompt is a prompt injection, and a \"judge\" model gives the final\nclassification. CourtGuard has a lower false positive rate than the Direct\nDetector, an LLM as-a-judge. However, CourtGuard is generally a worse prompt\ninjection detector. Nevertheless, this lower false positive rate highlights the\nimportance of considering both adversarial and benign scenarios for the\nclassification of a prompt. Additionally, the relative performance of\nCourtGuard in comparison to other prompt injection classifiers advances the use\nof multiagent systems as a defense against prompt injection attacks. The\nimplementations of CourtGuard and the Direct Detector with full prompts for\nGemma-3-12b-it, Llama-3.3-8B, and Phi-4-mini-instruct are available at\nhttps://github.com/isaacwu2000/CourtGuard.", "AI": {"tldr": "\u63d0\u51fa\u4e86CourtGuard\uff0c\u4e00\u79cd\u672c\u5730\u8fd0\u884c\u7684\u591a\u667a\u80fd\u4f53\u63d0\u793a\u6ce8\u5165\u5206\u7c7b\u5668\uff0c\u901a\u8fc7\u6cd5\u5ead\u5f0f\u7684\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u6765\u68c0\u6d4b\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u654f\u611f\u5e94\u7528\u4e2d\u7684\u96c6\u6210\uff0c\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u98ce\u9669\u65e5\u76ca\u589e\u52a0\uff0c\u53ef\u80fd\u5bfc\u81f4\u6570\u636e\u6cc4\u9732\u3001\u4f20\u64ad\u9519\u8bef\u4fe1\u606f\u548c\u6709\u5bb3\u884c\u4e3a\u3002", "method": "\u4f7f\u7528\u6cd5\u5ead\u5f0f\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff1a\u8fa9\u62a4\u5f8b\u5e08\u6a21\u578b\u8bba\u8bc1\u63d0\u793a\u65e0\u5bb3\uff0c\u68c0\u5bdf\u5b98\u6a21\u578b\u8bba\u8bc1\u63d0\u793a\u662f\u6ce8\u5165\u653b\u51fb\uff0c\u6cd5\u5b98\u6a21\u578b\u7ed9\u51fa\u6700\u7ec8\u5206\u7c7b\u3002", "result": "CourtGuard\u6bd4Direct Detector\u5177\u6709\u66f4\u4f4e\u7684\u8bef\u62a5\u7387\uff0c\u4f46\u603b\u4f53\u4e0a\u68c0\u6d4b\u6548\u679c\u8f83\u5dee\u3002\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u9632\u5fa1\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u53ef\u4f5c\u4e3a\u9632\u5fa1\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u8003\u8651\u5bf9\u6297\u6027\u548c\u826f\u6027\u573a\u666f\u5bf9\u63d0\u793a\u5206\u7c7b\u5f88\u91cd\u8981\u3002"}}
{"id": "2510.19949", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19949", "abs": "https://arxiv.org/abs/2510.19949", "authors": ["Mathieu Andreux", "M\u00e4rt Bakler", "Yanael Barbier", "Hamza Ben Chekroun", "Emilien Bir\u00e9", "Antoine Bonnet", "Riaz Bordie", "Nathan Bout", "Matthias Brunel", "Aleix Cambray", "Pierre-Louis Cedoz", "Antoine Chassang", "Gautier Cloix", "Ethan Connelly", "Alexandra Constantinou", "Ramzi De Coster", "Hubert de la Jonquiere", "Aur\u00e9lien Delfosse", "Maxime Delpit", "Alexis Deprez", "Augustin Derupti", "Mathieu Diaz", "Shannon D'Souza", "Julie Dujardin", "Abai Edmund", "Michael Eickenberg", "Armand Fatalot", "Wissem Felissi", "Isaac Herring", "Xavier Koegler", "Erwan Le Jumeau de Kergaradec", "Aur\u00e9lien Lac", "Maxime Langevin", "Corentin Lauverjat", "Antonio Loison", "Avshalom Manevich", "Axel Moyal", "Axel Nguyen Kerbel", "Marinela Parovic", "Julien Revelle", "Guillaume Richard", "Mats Richter", "Ronan Riochet", "Mar\u00eda Santos", "Romain Savidan", "Laurent Sifre", "Maxime Theillard", "Marc Thibault", "Ivan Valentini", "Tony Wu", "Laura Yie", "Kai Yuan", "Jevgenij Zubovskij"], "title": "Surfer 2: The Next Generation of Cross-Platform Computer Use Agents", "comment": "21 pages, 9 figures, 2 tables", "summary": "Building agents that generalize across web, desktop, and mobile environments\nremains an open challenge, as prior systems rely on environment-specific\ninterfaces that limit cross-platform deployment. We introduce Surfer 2, a\nunified architecture operating purely from visual observations that achieves\nstate-of-the-art performance across all three environments. Surfer 2 integrates\nhierarchical context management, decoupled planning and execution, and\nself-verification with adaptive recovery, enabling reliable operation over long\ntask horizons. Our system achieves 97.1% accuracy on WebVoyager, 69.6% on\nWebArena, 60.1% on OSWorld, and 87.1% on AndroidWorld, outperforming all prior\nsystems without task-specific fine-tuning. With multiple attempts, Surfer 2\nexceeds human performance on all benchmarks. These results demonstrate that\nsystematic orchestration amplifies foundation model capabilities and enables\ngeneral-purpose computer control through visual interaction alone, while\ncalling for a next-generation vision language model to achieve Pareto-optimal\ncost-efficiency.", "AI": {"tldr": "Surfer 2\u662f\u4e00\u4e2a\u57fa\u4e8e\u7eaf\u89c6\u89c9\u89c2\u5bdf\u7684\u7edf\u4e00\u67b6\u6784\uff0c\u5728Web\u3001\u684c\u9762\u548c\u79fb\u52a8\u73af\u5883\u4e2d\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u65e0\u9700\u7279\u5b9a\u4efb\u52a1\u5fae\u8c03\u5373\u53ef\u8d85\u8d8a\u6240\u6709\u5148\u524d\u7cfb\u7edf\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u4ee3\u7406\u7cfb\u7edf\u4f9d\u8d56\u73af\u5883\u7279\u5b9a\u63a5\u53e3\u3001\u9650\u5236\u8de8\u5e73\u53f0\u90e8\u7f72\u7684\u95ee\u9898\uff0c\u6784\u5efa\u80fd\u591f\u5728Web\u3001\u684c\u9762\u548c\u79fb\u52a8\u73af\u5883\u4e2d\u901a\u7528\u5316\u7684\u667a\u80fd\u4ee3\u7406\u3002", "method": "\u96c6\u6210\u5c42\u6b21\u5316\u4e0a\u4e0b\u6587\u7ba1\u7406\u3001\u89e3\u8026\u7684\u89c4\u5212\u4e0e\u6267\u884c\u3001\u4ee5\u53ca\u5177\u6709\u81ea\u9002\u5e94\u6062\u590d\u80fd\u529b\u7684\u81ea\u6211\u9a8c\u8bc1\u673a\u5236\uff0c\u5b9e\u73b0\u957f\u4efb\u52a1\u5468\u671f\u7684\u53ef\u9760\u64cd\u4f5c\u3002", "result": "\u5728WebVoyager\u4e0a\u8fbe\u523097.1%\u51c6\u786e\u7387\uff0cWebArena 69.6%\uff0cOSWorld 60.1%\uff0cAndroidWorld 87.1%\uff0c\u591a\u5c1d\u8bd5\u60c5\u51b5\u4e0b\u5728\u6240\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u4eba\u7c7b\u8868\u73b0\u3002", "conclusion": "\u7cfb\u7edf\u5316\u7f16\u6392\u80fd\u591f\u653e\u5927\u57fa\u7840\u6a21\u578b\u80fd\u529b\uff0c\u901a\u8fc7\u7eaf\u89c6\u89c9\u4ea4\u4e92\u5b9e\u73b0\u901a\u7528\u8ba1\u7b97\u673a\u63a7\u5236\uff0c\u540c\u65f6\u9700\u8981\u4e0b\u4e00\u4ee3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u6765\u5b9e\u73b0\u5e15\u7d2f\u6258\u6700\u4f18\u7684\u6210\u672c\u6548\u7387\u3002"}}
{"id": "2510.19864", "categories": ["cs.SE", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19864", "abs": "https://arxiv.org/abs/2510.19864", "authors": ["Amila Indika", "Igor Molybog"], "title": "SODBench: A Large Language Model Approach to Documenting Spreadsheet Operations", "comment": "14 pages, 5 figures, 4 tables", "summary": "Numerous knowledge workers utilize spreadsheets in business, accounting, and\nfinance. However, a lack of systematic documentation methods for spreadsheets\nhinders automation, collaboration, and knowledge transfer, which risks the loss\nof crucial institutional knowledge. This paper introduces Spreadsheet\nOperations Documentation (SOD), an AI task that involves generating\nhuman-readable explanations from spreadsheet operations. Many previous studies\nhave utilized Large Language Models (LLMs) for generating spreadsheet\nmanipulation code; however, translating that code into natural language for SOD\nis a less-explored area. To address this, we present a benchmark of 111\nspreadsheet manipulation code snippets, each paired with a corresponding\nnatural language summary. We evaluate five LLMs, GPT-4o, GPT-4o-mini,\nLLaMA-3.3-70B, Mixtral-8x7B, and Gemma2-9B, using BLEU, GLEU, ROUGE-L, and\nMETEOR metrics. Our findings suggest that LLMs can generate accurate\nspreadsheet documentation, making SOD a feasible prerequisite step toward\nenhancing reproducibility, maintainability, and collaborative workflows in\nspreadsheets, although there are challenges that need to be addressed.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7535\u5b50\u8868\u683c\u64cd\u4f5c\u6587\u6863\u5316(SOD)\u4efb\u52a1\uff0c\u6784\u5efa\u4e86\u5305\u542b111\u4e2a\u4ee3\u7801\u7247\u6bb5\u53ca\u5176\u81ea\u7136\u8bed\u8a00\u6458\u8981\u7684\u57fa\u51c6\uff0c\u8bc4\u4f30\u4e865\u4e2aLLM\u5728\u751f\u6210\u7535\u5b50\u8868\u683c\u6587\u6863\u65b9\u9762\u7684\u6027\u80fd\u3002", "motivation": "\u7535\u5b50\u8868\u683c\u5728\u5546\u4e1a\u548c\u91d1\u878d\u9886\u57df\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u5316\u6587\u6863\u65b9\u6cd5\uff0c\u963b\u788d\u4e86\u81ea\u52a8\u5316\u3001\u534f\u4f5c\u548c\u77e5\u8bc6\u4f20\u9012\uff0c\u5bfc\u81f4\u5173\u952e\u673a\u6784\u77e5\u8bc6\u4e22\u5931\u7684\u98ce\u9669\u3002", "method": "\u6784\u5efa\u5305\u542b111\u4e2a\u7535\u5b50\u8868\u683c\u64cd\u4f5c\u4ee3\u7801\u7247\u6bb5\u53ca\u5176\u5bf9\u5e94\u81ea\u7136\u8bed\u8a00\u6458\u8981\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u4f7f\u7528BLEU\u3001GLEU\u3001ROUGE-L\u548cMETEOR\u6307\u6807\u8bc4\u4f30GPT-4o\u3001GPT-4o-mini\u3001LLaMA-3.3-70B\u3001Mixtral-8x7B\u548cGemma2-9B\u4e94\u4e2aLLM\u7684\u6027\u80fd\u3002", "result": "\u7814\u7a76\u53d1\u73b0LLM\u80fd\u591f\u751f\u6210\u51c6\u786e\u7684\u7535\u5b50\u8868\u683c\u6587\u6863\uff0c\u8868\u660eSOD\u662f\u5b9e\u73b0\u7535\u5b50\u8868\u683c\u53ef\u91cd\u73b0\u6027\u3001\u53ef\u7ef4\u62a4\u6027\u548c\u534f\u4f5c\u5de5\u4f5c\u6d41\u7a0b\u7684\u53ef\u884c\u524d\u63d0\u6b65\u9aa4\u3002", "conclusion": "LLM\u53ef\u4ee5\u6709\u6548\u5730\u751f\u6210\u7535\u5b50\u8868\u683c\u64cd\u4f5c\u6587\u6863\uff0c\u4f46\u4ecd\u6709\u9700\u8981\u89e3\u51b3\u7684\u6311\u6218\u3002SOD\u4efb\u52a1\u4e3a\u63d0\u5347\u7535\u5b50\u8868\u683c\u7684\u534f\u4f5c\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2510.19851", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19851", "abs": "https://arxiv.org/abs/2510.19851", "authors": ["Artur Zolkowski", "Wen Xing", "David Lindner", "Florian Tram\u00e8r", "Erik Jenner"], "title": "Can Reasoning Models Obfuscate Reasoning? Stress-Testing Chain-of-Thought Monitorability", "comment": null, "summary": "Recent findings suggest that misaligned models may exhibit deceptive\nbehavior, raising concerns about output trustworthiness. Chain-of-thought (CoT)\nis a promising tool for alignment monitoring: when models articulate their\nreasoning faithfully, monitors can detect and mitigate harmful behaviors before\nundesirable outcomes occur. However, a key uncertainty is: Can models obfuscate\ntheir CoT in order to pursue hidden adversarial objectives while evading\ndetection? To answer this question and thus stress-test CoT monitorability, we\ndevelop a composable and quantifiable taxonomy of prompts to elicit CoT\nobfuscation. We evaluate both internal CoT (reasoning traces) and external CoT\n(prompted reasoning in outputs) using toy tasks and more realistic environments\nin SHADE-Arena. We show that: (i) CoT monitoring performs accurately and\nefficiently without obfuscation pressure. (ii) Under strong obfuscation\npressure, some models successfully complete adversarial tasks while evading\ndetection. (iii) Models do not obfuscate their internal CoT as much as their\nexternal CoT (under prompt pressure). These results suggest that while CoT\nprovides valuable oversight in benign settings, robust deployment requires\nmodel-specific stress-testing of monitorability.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u94fe\u5f0f\u601d\u7ef4(CoT)\u76d1\u63a7\u7684\u53ef\u76d1\u6d4b\u6027\uff0c\u53d1\u73b0\u5728\u65e0\u6df7\u6dc6\u538b\u529b\u4e0bCoT\u76d1\u63a7\u51c6\u786e\u9ad8\u6548\uff0c\u4f46\u5728\u5f3a\u6df7\u6dc6\u538b\u529b\u4e0b\u67d0\u4e9b\u6a21\u578b\u80fd\u6210\u529f\u5b8c\u6210\u5bf9\u6297\u4efb\u52a1\u5e76\u9003\u907f\u68c0\u6d4b\u3002", "motivation": "\u8fd1\u671f\u7814\u7a76\u53d1\u73b0\u672a\u5bf9\u9f50\u6a21\u578b\u53ef\u80fd\u8868\u73b0\u51fa\u6b3a\u9a97\u884c\u4e3a\uff0c\u5f15\u53d1\u5bf9\u8f93\u51fa\u53ef\u4fe1\u5ea6\u7684\u62c5\u5fe7\u3002CoT\u662f\u5f88\u6709\u524d\u666f\u7684\u5bf9\u9f50\u76d1\u63a7\u5de5\u5177\uff0c\u4f46\u5173\u952e\u95ee\u9898\u662f\u6a21\u578b\u80fd\u5426\u6df7\u6dc6\u5176CoT\u63a8\u7406\u6765\u8ffd\u6c42\u9690\u85cf\u7684\u5bf9\u6297\u76ee\u6807\u5e76\u9003\u907f\u68c0\u6d4b\u3002", "method": "\u5f00\u53d1\u4e86\u53ef\u7ec4\u5408\u548c\u53ef\u91cf\u5316\u7684\u63d0\u793a\u5206\u7c7b\u6cd5\u6765\u5f15\u53d1CoT\u6df7\u6dc6\uff0c\u5728\u73a9\u5177\u4efb\u52a1\u548cSHADE-Arena\u73b0\u5b9e\u73af\u5883\u4e2d\u8bc4\u4f30\u5185\u90e8CoT\uff08\u63a8\u7406\u8f68\u8ff9\uff09\u548c\u5916\u90e8CoT\uff08\u8f93\u51fa\u4e2d\u7684\u63d0\u793a\u63a8\u7406\uff09\u3002", "result": "\uff08i\uff09\u65e0\u6df7\u6dc6\u538b\u529b\u4e0bCoT\u76d1\u63a7\u51c6\u786e\u9ad8\u6548\uff1b\uff08ii\uff09\u5f3a\u6df7\u6dc6\u538b\u529b\u4e0b\u67d0\u4e9b\u6a21\u578b\u80fd\u6210\u529f\u5b8c\u6210\u5bf9\u6297\u4efb\u52a1\u5e76\u9003\u907f\u68c0\u6d4b\uff1b\uff08iii\uff09\u6a21\u578b\u6df7\u6dc6\u5185\u90e8CoT\u7684\u7a0b\u5ea6\u4f4e\u4e8e\u5916\u90e8CoT\u3002", "conclusion": "\u867d\u7136CoT\u5728\u826f\u6027\u8bbe\u7f6e\u4e0b\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u76d1\u7763\uff0c\u4f46\u7a33\u5065\u90e8\u7f72\u9700\u8981\u5bf9\u53ef\u76d1\u6d4b\u6027\u8fdb\u884c\u6a21\u578b\u7279\u5b9a\u7684\u538b\u529b\u6d4b\u8bd5\u3002"}}
{"id": "2510.19954", "categories": ["cs.AI", "cs.DB", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19954", "abs": "https://arxiv.org/abs/2510.19954", "authors": ["Joseph Meyer", "Divyansha Lachi", "Reza Mohammadi", "Roshan Reddy Upendra", "Eva L. Dyer", "Mark Li", "Tom Palczewski"], "title": "RELATE: A Schema-Agnostic Perceiver Encoder for Multimodal Relational Graphs", "comment": "6 pages", "summary": "Relational multi-table data is common in domains such as e-commerce,\nhealthcare, and scientific research, and can be naturally represented as\nheterogeneous temporal graphs with multi-modal node attributes. Existing graph\nneural networks (GNNs) rely on schema-specific feature encoders, requiring\nseparate modules for each node type and feature column, which hinders\nscalability and parameter sharing. We introduce RELATE (Relational Encoder for\nLatent Aggregation of Typed Entities), a schema-agnostic, plug-and-play feature\nencoder that can be used with any general purpose GNN. RELATE employs shared\nmodality-specific encoders for categorical, numerical, textual, and temporal\nattributes, followed by a Perceiver-style cross-attention module that\naggregates features into a fixed-size, permutation-invariant node\nrepresentation. We evaluate RELATE on ReLGNN and HGT in the RelBench benchmark,\nwhere it achieves performance within 3% of schema-specific encoders while\nreducing parameter counts by up to 5x. This design supports varying schemas and\nenables multi-dataset pretraining for general-purpose GNNs, paving the way\ntoward foundation models for relational graph data.", "AI": {"tldr": "RELATE\u662f\u4e00\u4e2a\u6a21\u5f0f\u65e0\u5173\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u7279\u5f81\u7f16\u7801\u5668\uff0c\u4f7f\u7528\u5171\u4eab\u7684\u6a21\u6001\u7279\u5b9a\u7f16\u7801\u5668\u5904\u7406\u5206\u7c7b\u3001\u6570\u503c\u3001\u6587\u672c\u548c\u65f6\u95f4\u5c5e\u6027\uff0c\u901a\u8fc7\u4ea4\u53c9\u6ce8\u610f\u529b\u6a21\u5757\u751f\u6210\u56fa\u5b9a\u5927\u5c0f\u7684\u8282\u70b9\u8868\u793a\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u53c2\u6570\u6570\u91cf\u3002", "motivation": "\u73b0\u6709\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u9700\u8981\u4e3a\u6bcf\u79cd\u8282\u70b9\u7c7b\u578b\u548c\u7279\u5f81\u5217\u8bbe\u8ba1\u7279\u5b9a\u7684\u7279\u5f81\u7f16\u7801\u5668\uff0c\u8fd9\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u548c\u53c2\u6570\u5171\u4eab\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5f02\u6784\u65f6\u5e8f\u56fe\u6570\u636e\u65f6\u3002", "method": "\u4f7f\u7528\u5171\u4eab\u7684\u6a21\u6001\u7279\u5b9a\u7f16\u7801\u5668\u5904\u7406\u4e0d\u540c\u5c5e\u6027\u7c7b\u578b\uff0c\u7136\u540e\u901a\u8fc7Perceiver\u98ce\u683c\u7684\u4ea4\u53c9\u6ce8\u610f\u529b\u6a21\u5757\u5c06\u7279\u5f81\u805a\u5408\u6210\u56fa\u5b9a\u5927\u5c0f\u7684\u8282\u70b9\u8868\u793a\u3002", "result": "\u5728RelBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRELATE\u5728ReLGNN\u548cHGT\u4e0a\u7684\u6027\u80fd\u4e0e\u6a21\u5f0f\u7279\u5b9a\u7f16\u7801\u5668\u76f8\u5dee\u4e0d\u52303%\uff0c\u540c\u65f6\u53c2\u6570\u6570\u91cf\u51cf\u5c11\u4e865\u500d\u3002", "conclusion": "RELATE\u652f\u6301\u4e0d\u540c\u6a21\u5f0f\uff0c\u4e3a\u5173\u7cfb\u56fe\u6570\u636e\u7684\u901a\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u591a\u6570\u636e\u96c6\u9884\u8bad\u7ec3\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u662f\u5b9e\u73b0\u5173\u7cfb\u56fe\u6570\u636e\u57fa\u7840\u6a21\u578b\u7684\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2510.19868", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.19868", "abs": "https://arxiv.org/abs/2510.19868", "authors": ["Qian Xiong", "Bo Yang", "Weisong Sun", "Yiran Zhang", "Tianlin Li", "Yang Liu", "Zhi Jin"], "title": "Knowledge-Guided Multi-Agent Framework for Application-Level Software Code Generation", "comment": null, "summary": "Automated code generation driven by Large Lan- guage Models (LLMs) has\nenhanced development efficiency, yet generating complex application-level\nsoftware code remains challenging. Multi-agent frameworks show potential, but\nexisting methods perform inadequately in large-scale application-level software\ncode generation, failing to ensure reasonable orga- nizational structures of\nproject code and making it difficult to maintain the code generation process.\nTo address this, this paper envisions a Knowledge-Guided Application-Level Code\nGeneration framework named KGACG, which aims to trans- form software\nrequirements specification and architectural design document into executable\ncode through a collaborative closed- loop of the Code Organization & Planning\nAgent (COPA), Coding Agent (CA), and Testing Agent (TA), combined with a\nfeedback mechanism. We demonstrate the collaborative process of the agents in\nKGACG in a Java Tank Battle game case study while facing challenges. KGACG is\ndedicated to advancing the automation of application-level software\ndevelopment.", "AI": {"tldr": "\u63d0\u51fa\u4e86KGACG\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u5c06\u8f6f\u4ef6\u9700\u6c42\u89c4\u8303\u548c\u67b6\u6784\u8bbe\u8ba1\u6587\u6863\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u4ee3\u7801\uff0c\u89e3\u51b3\u590d\u6742\u5e94\u7528\u7ea7\u8f6f\u4ef6\u4ee3\u7801\u751f\u6210\u7684\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u5e94\u7528\u7ea7\u8f6f\u4ef6\u4ee3\u7801\u751f\u6210\u4e2d\u8868\u73b0\u4e0d\u8db3\uff0c\u65e0\u6cd5\u786e\u4fdd\u9879\u76ee\u4ee3\u7801\u7684\u5408\u7406\u7ec4\u7ec7\u7ed3\u6784\uff0c\u96be\u4ee5\u7ef4\u62a4\u4ee3\u7801\u751f\u6210\u8fc7\u7a0b\u3002", "method": "\u4f7f\u7528\u77e5\u8bc6\u5f15\u5bfc\u7684\u5e94\u7528\u7ea7\u4ee3\u7801\u751f\u6210\u6846\u67b6KGACG\uff0c\u901a\u8fc7\u4ee3\u7801\u7ec4\u7ec7\u4e0e\u89c4\u5212\u667a\u80fd\u4f53(COPA)\u3001\u7f16\u7801\u667a\u80fd\u4f53(CA)\u548c\u6d4b\u8bd5\u667a\u80fd\u4f53(TA)\u7684\u534f\u4f5c\u95ed\u73af\uff0c\u7ed3\u5408\u53cd\u9988\u673a\u5236\u3002", "result": "\u901a\u8fc7Java\u5766\u514b\u5927\u6218\u6e38\u620f\u6848\u4f8b\u5c55\u793a\u4e86KGACG\u4e2d\u667a\u80fd\u4f53\u7684\u534f\u4f5c\u8fc7\u7a0b\uff0c\u540c\u65f6\u9762\u4e34\u4e00\u4e9b\u6311\u6218\u3002", "conclusion": "KGACG\u81f4\u529b\u4e8e\u63a8\u8fdb\u5e94\u7528\u7ea7\u8f6f\u4ef6\u5f00\u53d1\u7684\u81ea\u52a8\u5316\u8fdb\u7a0b\u3002"}}
{"id": "2510.19856", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.19856", "abs": "https://arxiv.org/abs/2510.19856", "authors": ["Eranga Bandara", "Sachin Shetty", "Ravi Mukkamala", "Ross Gore", "Peter Foytik", "Safdar H. Bouk", "Abdul Rahman", "Xueping Liang", "Ng Wee Keong", "Kasun De Zoysa", "Aruna Withanage", "Nilaan Loganathan"], "title": "Model Context Contracts - MCP-Enabled Framework to Integrate LLMs With Blockchain Smart Contracts", "comment": null, "summary": "In recent years, blockchain has experienced widespread adoption across\nvarious industries, becoming integral to numerous enterprise applications.\nConcurrently, the rise of generative AI and LLMs has transformed human-computer\ninteractions, offering advanced capabilities in understanding and generating\nhuman-like text. The introduction of the MCP has further enhanced AI\nintegration by standardizing communication between AI systems and external data\nsources. Despite these advancements, there is still no standardized method for\nseamlessly integrating LLM applications and blockchain. To address this\nconcern, we propose \"MCC: Model Context Contracts\" a novel framework that\nenables LLMs to interact directly with blockchain smart contracts through\nMCP-like protocol. This integration allows AI agents to invoke blockchain smart\ncontracts, facilitating more dynamic and context-aware interactions between\nusers and blockchain networks. Essentially, it empowers users to interact with\nblockchain systems and perform transactions using queries in natural language.\nWithin this proposed architecture, blockchain smart contracts can function as\nintelligent agents capable of recognizing user input in natural language and\nexecuting the corresponding transactions. To ensure that the LLM accurately\ninterprets natural language inputs and maps them to the appropriate MCP\nfunctions, the LLM was fine-tuned using a custom dataset comprising user inputs\npaired with their corresponding MCP server functions. This fine-tuning process\nsignificantly improved the platform's performance and accuracy. To validate the\neffectiveness of MCC, we have developed an end-to-end prototype implemented on\nthe Rahasak blockchain with the fine-tuned Llama-4 LLM. To the best of our\nknowledge, this research represents the first approach to using the concept of\nModel Context Protocol to integrate LLMs with blockchain.", "AI": {"tldr": "\u63d0\u51fa\u4e86MCC\u6846\u67b6\uff0c\u901a\u8fc7\u7c7b\u4f3cMCP\u7684\u534f\u8bae\u8ba9LLM\u76f4\u63a5\u4e0e\u533a\u5757\u94fe\u667a\u80fd\u5408\u7ea6\u4ea4\u4e92\uff0c\u4f7f\u7528\u6237\u80fd\u7528\u81ea\u7136\u8bed\u8a00\u4e0e\u533a\u5757\u94fe\u7cfb\u7edf\u4ea4\u4e92\u548c\u6267\u884c\u4ea4\u6613\u3002", "motivation": "\u76ee\u524d\u7f3a\u4e4f\u5c06LLM\u5e94\u7528\u4e0e\u533a\u5757\u94fe\u65e0\u7f1d\u96c6\u6210\u7684\u6807\u51c6\u5316\u65b9\u6cd5\uff0c\u9700\u8981\u89e3\u51b3AI\u4ee3\u7406\u4e0e\u533a\u5757\u94fe\u667a\u80fd\u5408\u7ea6\u4e4b\u95f4\u7684\u52a8\u6001\u4ea4\u4e92\u95ee\u9898\u3002", "method": "\u5f00\u53d1MCC\u6846\u67b6\uff0c\u901a\u8fc7\u5fae\u8c03LLM\u4f7f\u7528\u5305\u542b\u7528\u6237\u8f93\u5165\u548c\u5bf9\u5e94MCP\u670d\u52a1\u5668\u529f\u80fd\u7684\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\uff0c\u5728Rahasak\u533a\u5757\u94fe\u4e0a\u5b9e\u73b0\u7aef\u5230\u7aef\u539f\u578b\u3002", "result": "\u5fae\u8c03\u8fc7\u7a0b\u663e\u8457\u63d0\u9ad8\u4e86\u5e73\u53f0\u7684\u6027\u80fd\u548c\u51c6\u786e\u6027\uff0cLLM\u80fd\u591f\u51c6\u786e\u89e3\u91ca\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u5e76\u6620\u5c04\u5230\u76f8\u5e94\u7684MCP\u529f\u80fd\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u4f7f\u7528\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u6982\u5ff5\u5c06LLM\u4e0e\u533a\u5757\u94fe\u96c6\u6210\u7684\u65b9\u6cd5\uff0c\u4e3aAI\u4e0e\u533a\u5757\u94fe\u7684\u878d\u5408\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2510.19957", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19957", "abs": "https://arxiv.org/abs/2510.19957", "authors": ["Amir Hever", "Itai Orr"], "title": "A new wave of vehicle insurance fraud fueled by generative AI", "comment": null, "summary": "Generative AI is supercharging insurance fraud by making it easier to falsify\naccident evidence at scale and in rapid time. Insurance fraud is a pervasive\nand costly problem, amounting to tens of billions of dollars in losses each\nyear. In the vehicle insurance sector, fraud schemes have traditionally\ninvolved staged accidents, exaggerated damage, or forged documents. The rise of\ngenerative AI, including deepfake image and video generation, has introduced\nnew methods for committing fraud at scale. Fraudsters can now fabricate highly\nrealistic crash photos, damage evidence, and even fake identities or documents\nwith minimal effort, exploiting AI tools to bolster false insurance claims.\nInsurers have begun deploying countermeasures such as AI-based deepfake\ndetection software and enhanced verification processes to detect and mitigate\nthese AI-driven scams. However, current mitigation strategies face significant\nlimitations. Detection tools can suffer from false positives and negatives, and\nsophisticated fraudsters continuously adapt their tactics to evade automated\nchecks. This cat-and-mouse arms race between generative AI and detection\ntechnology, combined with resource and cost barriers for insurers, means that\ncombating AI-enabled insurance fraud remains an ongoing challenge. In this\nwhite paper, we present UVeye layered solution for vehicle fraud, representing\na major leap forward in the ability to detect, mitigate and deter this new wave\nof fraud.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u6b63\u5728\u52a0\u5267\u4fdd\u9669\u6b3a\u8bc8\u95ee\u9898\uff0c\u4f7f\u5927\u89c4\u6a21\u5feb\u901f\u4f2a\u9020\u4e8b\u6545\u8bc1\u636e\u53d8\u5f97\u66f4\u5bb9\u6613\u3002\u4fdd\u9669\u516c\u53f8\u5f00\u59cb\u90e8\u7f72AI\u53cd\u6b3a\u8bc8\u5de5\u5177\uff0c\u4f46\u9762\u4e34\u68c0\u6d4b\u51c6\u786e\u6027\u548c\u6210\u672c\u7b49\u6311\u6218\u3002", "motivation": "\u4fdd\u9669\u6b3a\u8bc8\u6bcf\u5e74\u9020\u6210\u6570\u767e\u4ebf\u7f8e\u5143\u635f\u5931\uff0c\u4f20\u7edf\u6b3a\u8bc8\u624b\u6bb5\u5305\u62ec\u4f2a\u9020\u4e8b\u6545\u548c\u6587\u4ef6\u3002\u751f\u6210\u5f0fAI\u7684\u51fa\u73b0\u8ba9\u6b3a\u8bc8\u8005\u80fd\u8f7b\u677e\u5236\u9020\u903c\u771f\u7684\u4e8b\u6545\u8bc1\u636e\uff0c\u9700\u8981\u65b0\u7684\u53cd\u6b3a\u8bc8\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4fdd\u9669\u516c\u53f8\u90e8\u7f72\u57fa\u4e8eAI\u7684\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u8f6f\u4ef6\u548c\u589e\u5f3a\u9a8c\u8bc1\u6d41\u7a0b\u6765\u68c0\u6d4bAI\u9a71\u52a8\u7684\u6b3a\u8bc8\u3002UVeye\u63d0\u51fa\u4e86\u5206\u5c42\u89e3\u51b3\u65b9\u6848\u6765\u68c0\u6d4b\u3001\u7f13\u89e3\u548c\u5a01\u6151\u8fd9\u79cd\u65b0\u578b\u6b3a\u8bc8\u3002", "result": "\u5f53\u524d\u7684\u7f13\u89e3\u7b56\u7565\u9762\u4e34\u663e\u8457\u9650\u5236\uff0c\u68c0\u6d4b\u5de5\u5177\u5b58\u5728\u8bef\u62a5\u548c\u6f0f\u62a5\u95ee\u9898\uff0c\u6b3a\u8bc8\u8005\u4e0d\u65ad\u8c03\u6574\u7b56\u7565\u89c4\u907f\u81ea\u52a8\u68c0\u67e5\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u4e0e\u68c0\u6d4b\u6280\u672f\u4e4b\u95f4\u7684\u732b\u9f20\u6e38\u620f\uff0c\u52a0\u4e0a\u4fdd\u9669\u516c\u53f8\u7684\u8d44\u6e90\u548c\u6210\u672c\u969c\u788d\uff0c\u4f7f\u5f97\u6253\u51fbAI\u9a71\u52a8\u7684\u4fdd\u9669\u6b3a\u8bc8\u4ecd\u7136\u662f\u4e00\u4e2a\u6301\u7eed\u6311\u6218\u3002UVeye\u7684\u5206\u5c42\u89e3\u51b3\u65b9\u6848\u4ee3\u8868\u4e86\u68c0\u6d4b\u80fd\u529b\u7684\u91cd\u8981\u8fdb\u6b65\u3002"}}
{"id": "2510.19898", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.19898", "abs": "https://arxiv.org/abs/2510.19898", "authors": ["Atharv Sonwane", "Isadora White", "Hyunji Lee", "Matheus Pereira", "Lucas Caccia", "Minseon Kim", "Zhengyan Shi", "Chinmay Singh", "Alessandro Sordoni", "Marc-Alexandre C\u00f4t\u00e9", "Xingdi Yuan"], "title": "BugPilot: Complex Bug Generation for Efficient Learning of SWE Skills", "comment": null, "summary": "High quality bugs are key to training the next generation of language model\nbased software engineering (SWE) agents. We introduce a novel method for\nsynthetic generation of difficult and diverse bugs. Our method instructs SWE\nAgents to introduce a feature into the codebase whereby they may\nunintentionally break tests, resulting in bugs. Prior approaches often induce\nan out-of-distribution effect by generating bugs intentionally (e.g. by\nintroducing local perturbation to existing code), which does not reflect\nrealistic development processes. We perform qualitative analysis to demonstrate\nthat our approach for generating bugs more closely reflects the patterns found\nin human-authored edits. Through extensive experiments, we demonstrate that our\nbugs provide more efficient training data for supervised fine-tuning,\noutperforming other bug datasets by 2% with half the training data (1.2k vs. 3k\nbugs). We train on our newly generated bugs in addition to existing bug\ndatasets to get FrogBoss a state-of-the-art 32B parameter model on SWE-bench\nVerified with a pass@1 of 54.6% and FrogMini a state-of-the-art 14B model on\nSWE-bench Verified with a pass@1 of 45.3% on SWE-bench Verified averaged over\nthree seeds.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u8ba9\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\u5728\u6dfb\u52a0\u529f\u80fd\u65f6\u65e0\u610f\u4e2d\u7834\u574f\u6d4b\u8bd5\u6765\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u591a\u6837\u5316bug\u7684\u65b0\u65b9\u6cd5\uff0c\u76f8\u6bd4\u6545\u610f\u751f\u6210bug\u7684\u65b9\u6cd5\u66f4\u63a5\u8fd1\u771f\u5b9e\u5f00\u53d1\u8fc7\u7a0b\u3002", "motivation": "\u9ad8\u8d28\u91cfbug\u5bf9\u4e8e\u8bad\u7ec3\u4e0b\u4e00\u4ee3\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\u81f3\u5173\u91cd\u8981\uff0c\u73b0\u6709\u65b9\u6cd5\u901a\u8fc7\u6545\u610f\u5f15\u5165\u5c40\u90e8\u6270\u52a8\u751f\u6210bug\uff0c\u4e0d\u7b26\u5408\u771f\u5b9e\u5f00\u53d1\u8fc7\u7a0b\u4e14\u5b58\u5728\u5206\u5e03\u5916\u95ee\u9898\u3002", "method": "\u6307\u5bfc\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\u5411\u4ee3\u7801\u5e93\u6dfb\u52a0\u529f\u80fd\uff0c\u5728\u6b64\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u65e0\u610f\u7834\u574f\u6d4b\u8bd5\u4ece\u800c\u4ea7\u751fbug\uff0c\u8fd9\u79cd\u65b9\u6cd5\u66f4\u8d34\u8fd1\u4eba\u7c7b\u5f00\u53d1\u8005\u7684\u7f16\u8f91\u6a21\u5f0f\u3002", "result": "\u65b0\u65b9\u6cd5\u751f\u6210\u7684bug\u5728\u76d1\u7763\u5fae\u8c03\u4e2d\u8868\u73b0\u66f4\u9ad8\u6548\uff0c\u4ec5\u75281.2k\u4e2abug\u5c31\u6bd4\u5176\u4ed6\u6570\u636e\u96c63k\u4e2abug\u6027\u80fd\u63d0\u53472%\u3002\u8bad\u7ec3\u51fa\u7684FrogBoss\u548cFrogMini\u6a21\u578b\u5728SWE-bench Verified\u4e0a\u5206\u522b\u8fbe\u523054.6%\u548c45.3%\u7684pass@1\u51c6\u786e\u7387\u3002", "conclusion": "\u901a\u8fc7\u6a21\u62df\u771f\u5b9e\u5f00\u53d1\u8fc7\u7a0b\u751f\u6210bug\u7684\u65b9\u6cd5\u80fd\u4ea7\u751f\u66f4\u6709\u6548\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\u7684\u6027\u80fd\uff0c\u4e3a\u4e0b\u4e00\u4ee3AI\u7f16\u7a0b\u52a9\u624b\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u8bad\u7ec3\u57fa\u7840\u3002"}}
{"id": "2510.19859", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.19859", "abs": "https://arxiv.org/abs/2510.19859", "authors": ["Smita Khapre"], "title": "Cyberattack Detection in Critical Infrastructure and Supply Chains", "comment": null, "summary": "Cyberattack detection in Critical Infrastructure and Supply Chains has become\nchallenging in Industry 4.0. Intrusion Detection Systems (IDS) are deployed to\ncounter the cyberattacks. However, an IDS effectively detects attacks based on\nthe known signatures and patterns, Zero-day attacks go undetected. To overcome\nthis drawback in IDS, the integration of a Dense Neural Network (DNN) with Data\nAugmentation is proposed. It makes IDS intelligent and enables it to self-learn\nwith high accuracy when a novel attack is encountered. The network flow\ncaptures datasets are highly imbalanced same as the real network itself. The\nData Augmentation plays a crucial role in balancing the data. The balancing of\ndata is challenging as the minority class is as low as 0.000004\\% of the\ndataset, and the abundant class is higher than 80\\% of the dataset. Synthetic\nMinority Oversampling Technique is used for balancing the data. However, higher\naccuracies are achieved with balanced test data, lower accuracies are\nnoticeable with the original imbalanced test data suggesting overfitting. A\ncomparison with state-of-the-art research using Synthetic Minority Oversampling\nTechnique with Edited Nearest Neighbor shows the classification of classes\nremains poor for the original dataset. This suggests highly imbalanced datasets\nof network flow require a different method of data augmentation.", "AI": {"tldr": "\u63d0\u51fa\u5c06\u5bc6\u96c6\u795e\u7ecf\u7f51\u7edc\u4e0e\u6570\u636e\u589e\u5f3a\u6280\u672f\u7ed3\u5408\uff0c\u4ee5\u89e3\u51b3\u5de5\u4e1a4.0\u4e2d\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u548c\u4f9b\u5e94\u94fe\u7684\u96f6\u65e5\u653b\u51fb\u68c0\u6d4b\u95ee\u9898\uff0c\u4f46\u53d1\u73b0\u4f20\u7edf\u6570\u636e\u5e73\u8861\u65b9\u6cd5\u5728\u5904\u7406\u9ad8\u5ea6\u4e0d\u5e73\u8861\u7f51\u7edc\u6d41\u91cf\u6570\u636e\u65f6\u5b58\u5728\u8fc7\u62df\u5408\u95ee\u9898\u3002", "motivation": "\u5de5\u4e1a4.0\u73af\u5883\u4e0b\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u548c\u4f9b\u5e94\u94fe\u7684\u7f51\u7edc\u5b89\u5168\u9762\u4e34\u6311\u6218\uff0c\u4f20\u7edf\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u53ea\u80fd\u68c0\u6d4b\u5df2\u77e5\u653b\u51fb\u6a21\u5f0f\uff0c\u65e0\u6cd5\u8bc6\u522b\u96f6\u65e5\u653b\u51fb\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u96c6\u6210\u5bc6\u96c6\u795e\u7ecf\u7f51\u7edc\u4e0e\u6570\u636e\u589e\u5f3a\u6280\u672f\uff0c\u4f7f\u7528\u5408\u6210\u5c11\u6570\u7c7b\u8fc7\u91c7\u6837\u6280\u672f\u6765\u5e73\u8861\u9ad8\u5ea6\u4e0d\u5e73\u8861\u7684\u7f51\u7edc\u6d41\u91cf\u6570\u636e\u96c6\u3002", "result": "\u867d\u7136\u4f7f\u7528\u5e73\u8861\u6d4b\u8bd5\u6570\u636e\u83b7\u5f97\u4e86\u8f83\u9ad8\u51c6\u786e\u7387\uff0c\u4f46\u5728\u539f\u59cb\u4e0d\u5e73\u8861\u6d4b\u8bd5\u6570\u636e\u4e0a\u51c6\u786e\u7387\u8f83\u4f4e\uff0c\u8868\u660e\u5b58\u5728\u8fc7\u62df\u5408\u95ee\u9898\u3002\u4e0e\u73b0\u6709\u65b9\u6cd5\u6bd4\u8f83\u663e\u793a\uff0c\u5bf9\u4e8e\u9ad8\u5ea6\u4e0d\u5e73\u8861\u7684\u7f51\u7edc\u6d41\u91cf\u6570\u636e\u96c6\uff0c\u4f20\u7edf\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u6548\u679c\u4e0d\u4f73\u3002", "conclusion": "\u9ad8\u5ea6\u4e0d\u5e73\u8861\u7684\u7f51\u7edc\u6d41\u91cf\u6570\u636e\u96c6\u9700\u8981\u4e0d\u540c\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u4f20\u7edf\u5e73\u8861\u6280\u672f\u5728\u5904\u7406\u6781\u4e0d\u5e73\u8861\u6570\u636e\u65f6\u5b58\u5728\u5c40\u9650\u6027\u3002"}}
{"id": "2510.19964", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19964", "abs": "https://arxiv.org/abs/2510.19964", "authors": ["Nitsa J Herzog", "Rejwan Bin Sulaiman", "David J Herzog", "Rose Fong"], "title": "AI-Driven Personalized Learning: Predicting Academic Per-formance Through Leadership Personality Traits", "comment": "20 pages, 6 figures, research article", "summary": "The study explores the potential of AI technologies in personalized learning,\nsuggesting the prediction of academic success through leadership personality\ntraits and machine learning modelling. The primary data were obtained from 129\nmaster's students in the Environmental Engineering Department, who underwent\nfive leadership personality tests with 23 characteristics. Students used\nself-assessment tools that included Personality Insight, Workplace Culture,\nMotivation at Work, Management Skills, and Emotion Control tests. The test\nresults were combined with the average grade obtained from academic reports.\nThe study employed exploratory data analysis and correlation analysis. Feature\nselection utilized Pearson correlation coefficients of personality traits. The\naverage grades were separated into three categories: fail, pass, and excellent.\nThe modelling process was performed by tuning seven ML algorithms, such as SVM,\nLR, KNN, DT, GB, RF, XGBoost and LightGBM. The highest predictive performance\nwas achieved with the RF classifier, which yielded an accuracy of 87.50% for\nthe model incorporating 17 personality trait features and the leadership mark\nfeature, and an accuracy of 85.71% for the model excluding this feature. In\nthis way, the study offers an additional opportunity to identify students'\nstrengths and weaknesses at an early stage of their education process and\nselect the most suitable strategies for personalized learning.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u901a\u8fc7\u9886\u5bfc\u529b\u4eba\u683c\u7279\u8d28\u9884\u6d4b\u5b66\u672f\u6210\u529f\uff0c\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u5728\u5305\u542b17\u4e2a\u4eba\u683c\u7279\u5f81\u548c\u9886\u5bfc\u529b\u5206\u6570\u7684\u6a21\u578b\u4e0a\u8fbe\u523087.50%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u63a2\u7d22AI\u6280\u672f\u5728\u4e2a\u6027\u5316\u5b66\u4e60\u4e2d\u7684\u6f5c\u529b\uff0c\u901a\u8fc7\u9886\u5bfc\u529b\u4eba\u683c\u7279\u8d28\u9884\u6d4b\u5b66\u672f\u8868\u73b0\uff0c\u4e3a\u65e9\u671f\u8bc6\u522b\u5b66\u751f\u4f18\u7f3a\u70b9\u548c\u5236\u5b9a\u4e2a\u6027\u5316\u5b66\u4e60\u7b56\u7565\u63d0\u4f9b\u673a\u4f1a\u3002", "method": "\u4ece129\u540d\u73af\u5883\u5de5\u7a0b\u7855\u58eb\u751f\u6536\u96c65\u4e2a\u9886\u5bfc\u529b\u4eba\u683c\u6d4b\u8bd5\u6570\u636e\uff0823\u4e2a\u7279\u5f81\uff09\uff0c\u7ed3\u5408\u5e73\u5747\u6210\u7ee9\uff0c\u4f7f\u7528\u76f8\u5173\u6027\u5206\u6790\u8fdb\u884c\u7279\u5f81\u9009\u62e9\uff0c\u8c03\u4f187\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff08SVM\u3001LR\u3001KNN\u3001DT\u3001GB\u3001RF\u3001XGBoost\u3001LightGBM\uff09\u3002", "result": "\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u8868\u73b0\u6700\u4f73\uff0c\u5305\u542b17\u4e2a\u4eba\u683c\u7279\u5f81\u548c\u9886\u5bfc\u529b\u5206\u6570\u7684\u6a21\u578b\u51c6\u786e\u7387\u8fbe87.50%\uff0c\u4e0d\u5305\u542b\u9886\u5bfc\u529b\u5206\u6570\u7684\u6a21\u578b\u51c6\u786e\u7387\u4e3a85.71%\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u9886\u5bfc\u529b\u4eba\u683c\u7279\u8d28\u53ef\u4ee5\u6709\u6548\u9884\u6d4b\u5b66\u672f\u6210\u529f\uff0c\u4e3a\u65e9\u671f\u8bc6\u522b\u5b66\u751f\u4f18\u7f3a\u70b9\u548c\u5236\u5b9a\u4e2a\u6027\u5316\u5b66\u4e60\u7b56\u7565\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2510.19984", "categories": ["cs.SE", "D.2.5"], "pdf": "https://arxiv.org/pdf/2510.19984", "abs": "https://arxiv.org/abs/2510.19984", "authors": ["Konstantinos Kitsios", "Marcel B\u00f6hme", "Alberto Bacchelli"], "title": "On Interaction Effects in Greybox Fuzzing", "comment": "12 pages, 2 figures, Accepted for presentation at the 48th\n  International Conference on Software Engineering (ICSE '26)", "summary": "A greybox fuzzer is an automated software testing tool that generates new\ntest inputs by applying randomly chosen mutators (e.g., flipping a bit or\ndeleting a block of bytes) to a seed input in random order and adds all\ncoverage-increasing inputs to the corpus of seeds. We hypothesize that the\norder in which mutators are applied to a seed input has an impact on the\neffectiveness of greybox fuzzers. In our experiments, we fit a linear model to\na dataset that contains the effectiveness of all possible mutator pairs and\nindeed observe the conjectured interaction effect. This points us to more\nefficient fuzzing by choosing the most promising mutator sequence with a higher\nlikelihood. We propose MuoFuzz, a greybox fuzzer that learns and chooses the\nmost promising mutator sequences. MuoFuzz learns the conditional probability\nthat the next mutator will yield an interesting input, given the previously\nselected mutator. Then, it samples from the learned probability using a random\nwalk to generate mutator sequences. We compare the performance of MuoFuzz to\nAFL++, which uses a fixed selection probability, and MOPT, which optimizes the\nselection probability of each mutator in isolation. Experimental results on the\nFuzzBench and MAGMA benchmarks show that MuoFuzz achieves the highest code\ncoverage and finds four bugs missed by AFL++ and one missed by both AFL++ and\nMOPT.", "AI": {"tldr": "MuoFuzz\u662f\u4e00\u79cd\u7070\u76d2\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\uff0c\u901a\u8fc7\u5b66\u4e60\u6700\u6709\u524d\u666f\u7684\u53d8\u5f02\u5668\u5e8f\u5217\u6765\u63d0\u9ad8\u6d4b\u8bd5\u6548\u7387\uff0c\u76f8\u6bd4AFL++\u548cMOPT\u5728\u4ee3\u7801\u8986\u76d6\u7387\u548c\u6f0f\u6d1e\u53d1\u73b0\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u4f20\u7edf\u7070\u76d2\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u968f\u673a\u5e94\u7528\u53d8\u5f02\u5668\uff0c\u4f5c\u8005\u5047\u8bbe\u53d8\u5f02\u5668\u7684\u5e94\u7528\u987a\u5e8f\u4f1a\u5f71\u54cd\u6d4b\u8bd5\u6548\u679c\uff0c\u5e0c\u671b\u901a\u8fc7\u5b66\u4e60\u6700\u4f18\u53d8\u5f02\u5668\u5e8f\u5217\u6765\u63d0\u9ad8\u6a21\u7cca\u6d4b\u8bd5\u6548\u7387\u3002", "method": "\u63d0\u51faMuoFuzz\uff0c\u901a\u8fc7\u5b66\u4e60\u53d8\u5f02\u5668\u4e4b\u95f4\u7684\u6761\u4ef6\u6982\u7387\u6765\u751f\u6210\u6700\u6709\u524d\u666f\u7684\u53d8\u5f02\u5668\u5e8f\u5217\uff0c\u4f7f\u7528\u968f\u673a\u6e38\u8d70\u4ece\u5b66\u4e60\u5230\u7684\u6982\u7387\u4e2d\u91c7\u6837\u751f\u6210\u53d8\u5f02\u5668\u5e8f\u5217\u3002", "result": "\u5728FuzzBench\u548cMAGMA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMuoFuzz\u5b9e\u73b0\u4e86\u6700\u9ad8\u7684\u4ee3\u7801\u8986\u76d6\u7387\uff0c\u53d1\u73b0\u4e86AFL++\u9057\u6f0f\u76844\u4e2a\u6f0f\u6d1e\u548cAFL++\u4e0eMOPT\u90fd\u9057\u6f0f\u76841\u4e2a\u6f0f\u6d1e\u3002", "conclusion": "\u53d8\u5f02\u5668\u7684\u5e94\u7528\u987a\u5e8f\u786e\u5b9e\u5f71\u54cd\u6a21\u7cca\u6d4b\u8bd5\u6548\u679c\uff0c\u901a\u8fc7\u5b66\u4e60\u53d8\u5f02\u5668\u5e8f\u5217\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u6d4b\u8bd5\u6548\u7387\u548c\u6f0f\u6d1e\u53d1\u73b0\u80fd\u529b\u3002"}}
{"id": "2510.19877", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.19877", "abs": "https://arxiv.org/abs/2510.19877", "authors": ["Jean-Marie Le Ray"], "title": "Policy-Governed RAG - Research Design Study", "comment": "51 pages, 8 figures", "summary": "A policy-governed RAG architecture is specified for audit-ready generation in\nregulated workflows, organized as a triptych: (I) Contracts/Control\n(SHRDLU-like), which governs output adherence to legal and internal policies;\n(II) Manifests/Trails (Memex-like), which cryptographically anchors all cited\nsource evidence to ensure verifiable provenance; and (III)\nReceipts/Verification (Xanadu-like), which provides the final, portable proof\nof compliance for auditors (portable COSE/JOSE) (see Section 4 and Appendix A).\nRather than explaining model internals, outputs are gated ex-ante and bound to\ncryptographically verifiable evidence for each material answer. Unvalidated\ntargets are stated (>=20% relative reduction in confident errors; p95 latency\n<= 900 ms; <= 2.2x serve cost) together with a pre-registered (optional) pilot\nusing NO-GO gates. The design complements existing RAG/guardrails by making\npolicy checks auditable, replayable, and receipt-backed. Target domains include\nback-office compliance in pharma, medical devices, finance, legal, and the\npublic sector where error costs may exceed thousands of euros and audit trails\nare mandatory under regulations such as the EU AI Act. Future evaluations may\npre-commit to publishing negative results when any example NO-GO gate is not\nmet.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u76d1\u7ba1\u5de5\u4f5c\u6d41\u7684\u653f\u7b56\u6cbb\u7406RAG\u67b6\u6784\uff0c\u901a\u8fc7\u4e09\u4e2a\u7ec4\u4ef6\u786e\u4fdd\u5ba1\u8ba1\u5c31\u7eea\u7684\u751f\u6210\uff1a\u5408\u540c\u63a7\u5236\u3001\u6e05\u5355\u8ffd\u8e2a\u548c\u6536\u636e\u9a8c\u8bc1\uff0c\u4f7f\u653f\u7b56\u68c0\u67e5\u53ef\u5ba1\u8ba1\u3001\u53ef\u91cd\u653e\u4e14\u6536\u636e\u652f\u6301\u3002", "motivation": "\u5728\u533b\u836f\u3001\u533b\u7597\u5668\u68b0\u3001\u91d1\u878d\u3001\u6cd5\u5f8b\u548c\u516c\u5171\u90e8\u95e8\u7b49\u76d1\u7ba1\u4e25\u683c\u9886\u57df\uff0c\u9519\u8bef\u6210\u672c\u9ad8\u6602\u4e14\u5ba1\u8ba1\u8ffd\u8e2a\u662f\u6cd5\u89c4\u5f3a\u5236\u8981\u6c42\uff0c\u9700\u8981\u786e\u4fddAI\u751f\u6210\u5185\u5bb9\u7684\u5408\u89c4\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u3002", "method": "\u91c7\u7528\u4e09\u90e8\u5206\u67b6\u6784\uff1a(I)\u5408\u540c\u63a7\u5236\u786e\u4fdd\u8f93\u51fa\u7b26\u5408\u6cd5\u5f8b\u548c\u5185\u90e8\u653f\u7b56\uff1b(II)\u6e05\u5355\u8ffd\u8e2a\u901a\u8fc7\u52a0\u5bc6\u951a\u5b9a\u5f15\u7528\u6765\u6e90\u8bc1\u636e\uff1b(III)\u6536\u636e\u9a8c\u8bc1\u63d0\u4f9b\u4fbf\u643a\u7684\u5408\u89c4\u8bc1\u660e\u3002", "result": "\u8bbe\u5b9a\u4e86\u672a\u9a8c\u8bc1\u76ee\u6807\uff1a\u7f6e\u4fe1\u9519\u8bef\u76f8\u5bf9\u51cf\u5c11\u226520%\uff1bp95\u5ef6\u8fdf\u2264900ms\uff1b\u670d\u52a1\u6210\u672c\u22642.2\u500d\uff1b\u4f7f\u7528NO-GO\u95e8\u63a7\u8fdb\u884c\u9884\u6ce8\u518c\u8bd5\u70b9\u3002", "conclusion": "\u8be5\u8bbe\u8ba1\u901a\u8fc7\u4f7f\u653f\u7b56\u68c0\u67e5\u53ef\u5ba1\u8ba1\u3001\u53ef\u91cd\u653e\u4e14\u6536\u636e\u652f\u6301\uff0c\u8865\u5145\u4e86\u73b0\u6709RAG/\u62a4\u680f\u7cfb\u7edf\uff0c\u7279\u522b\u9002\u7528\u4e8e\u76d1\u7ba1\u4e25\u683c\u7684\u9886\u57df\u3002"}}
{"id": "2510.20075", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20075", "abs": "https://arxiv.org/abs/2510.20075", "authors": ["Antonio Norelli", "Michael Bronstein"], "title": "LLMs can hide text in other text of the same length.ipynb", "comment": "21 pages, main paper 9 pages", "summary": "A meaningful text can be hidden inside another, completely different yet\nstill coherent and plausible, text of the same length. For example, a tweet\ncontaining a harsh political critique could be embedded in a tweet that\ncelebrates the same political leader, or an ordinary product review could\nconceal a secret manuscript. This uncanny state of affairs is now possible\nthanks to Large Language Models, and in this paper we present a simple and\nefficient protocol to achieve it. We show that even modest 8-billion-parameter\nopen-source LLMs are sufficient to obtain high-quality results, and a message\nas long as this abstract can be encoded and decoded locally on a laptop in\nseconds. The existence of such a protocol demonstrates a radical decoupling of\ntext from authorial intent, further eroding trust in written communication,\nalready shaken by the rise of LLM chatbots. We illustrate this with a concrete\nscenario: a company could covertly deploy an unfiltered LLM by encoding its\nanswers within the compliant responses of a safe model. This possibility raises\nurgent questions for AI safety and challenges our understanding of what it\nmeans for a Large Language Model to know something.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u79d8\u5bc6\u4fe1\u606f\u9690\u85cf\u5728\u770b\u4f3c\u666e\u901a\u7684\u6587\u672c\u4e2d\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u76f8\u540c\u957f\u5ea6\u7684\u6587\u672c\u4e2d\u5d4c\u5165\u5b8c\u5168\u4e0d\u540c\u7684\u542b\u4e49\uff0c\u4e14\u7f16\u7801\u89e3\u7801\u8fc7\u7a0b\u5feb\u901f\u9ad8\u6548\u3002", "motivation": "\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6587\u672c\u9690\u85cf\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5c55\u793a\u6587\u672c\u4e0e\u4f5c\u8005\u610f\u56fe\u4e4b\u95f4\u7684\u5f7b\u5e95\u5206\u79bb\uff0c\u8fdb\u4e00\u6b65\u524a\u5f31\u5bf9\u4e66\u9762\u901a\u4fe1\u7684\u4fe1\u4efb\uff0c\u5f15\u53d1\u5bf9AI\u5b89\u5168\u6027\u7684\u7d27\u8feb\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u7b80\u5355\u9ad8\u6548\u7684\u534f\u8bae\uff0c\u5373\u4f7f\u662f80\u4ebf\u53c2\u6570\u7684\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u4e5f\u80fd\u5b9e\u73b0\u9ad8\u8d28\u91cf\u7684\u6587\u672c\u9690\u85cf\uff0c\u53ef\u4ee5\u5728\u7b14\u8bb0\u672c\u7535\u8111\u4e0a\u5feb\u901f\u7f16\u7801\u548c\u89e3\u7801\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u5728\u76f8\u540c\u957f\u5ea6\u7684\u6587\u672c\u4e2d\u9690\u85cf\u79d8\u5bc6\u4fe1\u606f\uff0c\u4f8b\u5982\u5c06\u653f\u6cbb\u6279\u8bc4\u9690\u85cf\u5728\u770b\u4f3c\u8d5e\u626c\u7684\u63a8\u6587\u4e2d\uff0c\u6216\u5c06\u79d8\u5bc6\u624b\u7a3f\u9690\u85cf\u5728\u666e\u901a\u4ea7\u54c1\u8bc4\u8bba\u4e2d\u3002", "conclusion": "\u8fd9\u79cd\u534f\u8bae\u7684\u5b58\u5728\u8868\u660e\u6587\u672c\u4e0e\u4f5c\u8005\u610f\u56fe\u4e4b\u95f4\u5b58\u5728\u6839\u672c\u6027\u5206\u79bb\uff0c\u5bf9AI\u5b89\u5168\u6027\u63d0\u51fa\u4e86\u4e25\u5cfb\u6311\u6218\uff0c\u5e76\u91cd\u65b0\u601d\u8003\u5927\u8bed\u8a00\u6a21\u578b\"\u77e5\u9053\"\u67d0\u4e8b\u7684\u542b\u4e49\u3002"}}
{"id": "2510.19997", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19997", "abs": "https://arxiv.org/abs/2510.19997", "authors": ["Abraham Itzhak Weinberg"], "title": "A Framework for the Adoption and Integration of Generative AI in Midsize Organizations and Enterprises (FAIGMOE)", "comment": null, "summary": "Generative Artificial Intelligence (GenAI) presents transformative\nopportunities for organizations, yet both midsize organizations and larger\nenterprises face distinctive adoption challenges. Midsize organizations\nencounter resource constraints and limited AI expertise, while enterprises\nstruggle with organizational complexity and coordination challenges. Existing\ntechnology adoption frameworks, including TAM (Technology Acceptance Model),\nTOE (Technology Organization Environment), and DOI (Diffusion of Innovations)\ntheory, lack the specificity required for GenAI implementation across these\ndiverse contexts, creating a critical gap in adoption literature. This paper\nintroduces FAIGMOE (Framework for the Adoption and Integration of Generative AI\nin Midsize Organizations and Enterprises), a conceptual framework addressing\nthe unique needs of both organizational types. FAIGMOE synthesizes technology\nadoption theory, organizational change management, and innovation diffusion\nperspectives into four interconnected phases: Strategic Assessment, Planning\nand Use Case Development, Implementation and Integration, and\nOperationalization and Optimization. Each phase provides scalable guidance on\nreadiness assessment, strategic alignment, risk governance, technical\narchitecture, and change management adaptable to organizational scale and\ncomplexity. The framework incorporates GenAI specific considerations including\nprompt engineering, model orchestration, and hallucination management that\ndistinguish it from generic technology adoption frameworks. As a perspective\ncontribution, FAIGMOE provides the first comprehensive conceptual framework\nexplicitly addressing GenAI adoption across midsize and enterprise\norganizations, offering actionable implementation protocols, assessment\ninstruments, and governance templates requiring empirical validation through\nfuture research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86FAIGMOE\u6846\u67b6\uff0c\u4e13\u95e8\u89e3\u51b3\u4e2d\u5c0f\u578b\u7ec4\u7ec7\u548c\u5927\u578b\u4f01\u4e1a\u5728\u751f\u6210\u5f0fAI\u91c7\u7528\u8fc7\u7a0b\u4e2d\u9762\u4e34\u7684\u72ec\u7279\u6311\u6218\uff0c\u5c06\u6280\u672f\u91c7\u7eb3\u7406\u8bba\u3001\u7ec4\u7ec7\u53d8\u9769\u7ba1\u7406\u548c\u521b\u65b0\u6269\u6563\u89c6\u89d2\u6574\u5408\u4e3a\u56db\u4e2a\u76f8\u4e92\u5173\u8054\u7684\u9636\u6bb5\u3002", "motivation": "\u73b0\u6709\u6280\u672f\u91c7\u7eb3\u6846\u67b6\uff08\u5982TAM\u3001TOE\u3001DOI\u7406\u8bba\uff09\u7f3a\u4e4f\u9488\u5bf9\u751f\u6210\u5f0fAI\u5b9e\u65bd\u7684\u7279\u5b9a\u6027\uff0c\u65e0\u6cd5\u6ee1\u8db3\u4e0d\u540c\u89c4\u6a21\u7ec4\u7ec7\u7684\u9700\u6c42\uff0c\u5728\u91c7\u7eb3\u6587\u732e\u4e2d\u5f62\u6210\u4e86\u5173\u952e\u7a7a\u767d\u3002", "method": "\u5f00\u53d1FAIGMOE\u6982\u5ff5\u6846\u67b6\uff0c\u6574\u5408\u6280\u672f\u91c7\u7eb3\u7406\u8bba\u3001\u7ec4\u7ec7\u53d8\u9769\u7ba1\u7406\u548c\u521b\u65b0\u6269\u6563\u89c6\u89d2\uff0c\u5305\u542b\u56db\u4e2a\u9636\u6bb5\uff1a\u6218\u7565\u8bc4\u4f30\u3001\u89c4\u5212\u4e0e\u7528\u4f8b\u5f00\u53d1\u3001\u5b9e\u65bd\u4e0e\u96c6\u6210\u3001\u8fd0\u8425\u4e0e\u4f18\u5316\u3002", "result": "FAIGMOE\u6846\u67b6\u63d0\u4f9b\u4e86\u9488\u5bf9\u751f\u6210\u5f0fAI\u7279\u5b9a\u8003\u8651\u56e0\u7d20\uff08\u5982\u63d0\u793a\u5de5\u7a0b\u3001\u6a21\u578b\u7f16\u6392\u3001\u5e7b\u89c9\u7ba1\u7406\uff09\u7684\u53ef\u6269\u5c55\u6307\u5bfc\uff0c\u5e76\u5305\u542b\u53ef\u64cd\u4f5c\u7684\u5b9e\u65bd\u534f\u8bae\u3001\u8bc4\u4f30\u5de5\u5177\u548c\u6cbb\u7406\u6a21\u677f\u3002", "conclusion": "FAIGMOE\u662f\u9996\u4e2a\u5168\u9762\u89e3\u51b3\u4e2d\u5c0f\u578b\u7ec4\u7ec7\u548c\u4f01\u4e1a\u751f\u6210\u5f0fAI\u91c7\u7eb3\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u9700\u8981\u901a\u8fc7\u672a\u6765\u7814\u7a76\u8fdb\u884c\u5b9e\u8bc1\u9a8c\u8bc1\u3002"}}
{"id": "2510.19883", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.19883", "abs": "https://arxiv.org/abs/2510.19883", "authors": ["Selma Shikonde", "Mike Wa Nkongolo"], "title": "A Proactive Insider Threat Management Framework Using Explainable Machine Learning", "comment": "Full master's in information technology (Information Science),\n  University of Pretoria, Department of Informatics", "summary": "Over the years, the technological landscape has evolved, reshaping the\nsecurity posture of organisations and increasing their exposure to\ncybersecurity threats, many originating from within. Insider threats remain a\nmajor challenge, particularly in sectors where cybersecurity infrastructure,\nexpertise, and regulations are still developing. This study proposes the\nInsider Threat Explainable Machine Learning (IT-XML) framework, which\nintegrates the Cross-Industry Standard Process for Data Mining (CRISP-DM) with\nHidden Markov Models (HMM) to enhance proactive insider threat management and\ndecision-making. A quantitative approach is adopted using an online\nquestionnaire to assess employees' knowledge of insider threat patterns, access\ncontrol, privacy practices, and existing policies across three large\ndata-sensitive organisations. The IT-XML framework provides assessment\ncapabilities through survey-based data, HMM-driven pattern recognition for\nsecurity maturity classification, and evidence-based recommendations for\nproactive threat mitigation. The framework classified all organisations at the\ndeveloping security maturity level with 97-98% confidence and achieved a\nclassification accuracy of 91.7%, identifying audit log access limits as the\nmost critical control. Random Forest analysis highlighted vendor breach\nnotifications (0.081) and regular audit log reviews (0.052) as key determinants\nof resilience. Explainability methods such as SHAP and LIME improved model\ntransparency and interpretability, demonstrating the framework's potential to\nstrengthen insider threat management practices.", "AI": {"tldr": "\u63d0\u51fa\u4e86IT-XML\u6846\u67b6\uff0c\u7ed3\u5408CRISP-DM\u548c\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u6765\u589e\u5f3a\u5185\u90e8\u5a01\u80c1\u7ba1\u7406\uff0c\u901a\u8fc7\u95ee\u5377\u8c03\u67e5\u8bc4\u4f30\u5458\u5de5\u5b89\u5168\u610f\u8bc6\uff0c\u5b9e\u73b0\u4e8691.7%\u7684\u5206\u7c7b\u51c6\u786e\u7387\u3002", "motivation": "\u968f\u7740\u6280\u672f\u53d1\u5c55\uff0c\u7ec4\u7ec7\u9762\u4e34\u65e5\u76ca\u589e\u957f\u7684\u5185\u90e8\u5a01\u80c1\u98ce\u9669\uff0c\u7279\u522b\u662f\u5728\u7f51\u7edc\u5b89\u5168\u57fa\u7840\u8bbe\u65bd\u548c\u4e13\u4e1a\u77e5\u8bc6\u4ecd\u5728\u53d1\u5c55\u7684\u884c\u4e1a\u3002", "method": "\u91c7\u7528\u5b9a\u91cf\u65b9\u6cd5\uff0c\u4f7f\u7528\u5728\u7ebf\u95ee\u5377\u8bc4\u4f30\u5458\u5de5\u5bf9\u5185\u90e8\u5a01\u80c1\u6a21\u5f0f\u7684\u8ba4\u77e5\uff0c\u7ed3\u5408CRISP-DM\u6d41\u7a0b\u548c\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u8fdb\u884c\u5b89\u5168\u6210\u719f\u5ea6\u5206\u7c7b\u3002", "result": "\u6846\u67b6\u5c06\u6240\u6709\u7ec4\u7ec7\u5206\u7c7b\u4e3a\u53d1\u5c55\u4e2d\u5b89\u5168\u6210\u719f\u5ea6\u6c34\u5e73\uff0c\u7f6e\u4fe1\u5ea697-98%\uff0c\u5206\u7c7b\u51c6\u786e\u738791.7%\uff0c\u8bc6\u522b\u5ba1\u8ba1\u65e5\u5fd7\u8bbf\u95ee\u9650\u5236\u4e3a\u6700\u5173\u952e\u63a7\u5236\u63aa\u65bd\u3002", "conclusion": "IT-XML\u6846\u67b6\u901a\u8fc7SHAP\u548cLIME\u7b49\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u63d0\u9ad8\u4e86\u6a21\u578b\u900f\u660e\u5ea6\uff0c\u5c55\u793a\u4e86\u52a0\u5f3a\u5185\u90e8\u5a01\u80c1\u7ba1\u7406\u5b9e\u8df5\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.20099", "categories": ["cs.AI", "cs.CE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.20099", "abs": "https://arxiv.org/abs/2510.20099", "authors": ["Daewoo Park", "Suho Park", "Inseok Hong", "Hanwool Lee", "Junkyu Park", "Sangjun Lee", "Jeongman An", "Hyunbin Loh"], "title": "AI PB: A Grounded Generative Agent for Personalized Investment Insights", "comment": "Under Review", "summary": "We present AI PB, a production-scale generative agent deployed in real retail\nfinance. Unlike reactive chatbots that answer queries passively, AI PB\nproactively generates grounded, compliant, and user-specific investment\ninsights. It integrates (i) a component-based orchestration layer that\ndeterministically routes between internal and external LLMs based on data\nsensitivity, (ii) a hybrid retrieval pipeline using OpenSearch and the\nfinance-domain embedding model, and (iii) a multi-stage recommendation\nmechanism combining rule heuristics, sequential behavioral modeling, and\ncontextual bandits. Operating fully on-premises under Korean financial\nregulations, the system employs Docker Swarm and vLLM across 24 X NVIDIA H100\nGPUs. Through human QA and system metrics, we demonstrate that grounded\ngeneration with explicit routing and layered safety can deliver trustworthy AI\ninsights in high-stakes finance.", "AI": {"tldr": "AI PB\u662f\u4e00\u4e2a\u5728\u96f6\u552e\u91d1\u878d\u9886\u57df\u90e8\u7f72\u7684\u751f\u4ea7\u7ea7\u751f\u6210\u5f0f\u667a\u80fd\u4f53\uff0c\u80fd\u591f\u4e3b\u52a8\u751f\u6210\u57fa\u4e8e\u4e8b\u5b9e\u3001\u5408\u89c4\u4e14\u4e2a\u6027\u5316\u7684\u6295\u8d44\u6d1e\u5bdf\uff0c\u91c7\u7528\u7ec4\u4ef6\u5316\u67b6\u6784\u3001\u6df7\u5408\u68c0\u7d22\u7ba1\u9053\u548c\u591a\u9636\u6bb5\u63a8\u8350\u673a\u5236\uff0c\u5728\u97e9\u56fd\u91d1\u878d\u76d1\u7ba1\u4e0b\u5b8c\u5168\u672c\u5730\u5316\u8fd0\u884c\u3002", "motivation": "\u4f20\u7edf\u88ab\u52a8\u5f0f\u804a\u5929\u673a\u5668\u4eba\u65e0\u6cd5\u6ee1\u8db3\u91d1\u878d\u9886\u57df\u5bf9\u4e3b\u52a8\u3001\u5408\u89c4\u3001\u4e2a\u6027\u5316\u6295\u8d44\u6d1e\u5bdf\u7684\u9700\u6c42\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5728\u9ad8\u98ce\u9669\u91d1\u878d\u73af\u5883\u4e2d\u63d0\u4f9b\u53ef\u4fe1AI\u89c1\u89e3\u7684\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u7ec4\u4ef6\u5316\u7f16\u6392\u5c42\u8fdb\u884c\u786e\u5b9a\u6027\u8def\u7531\u51b3\u7b56\uff0c\u7ed3\u5408OpenSearch\u548c\u91d1\u878d\u9886\u57df\u5d4c\u5165\u6a21\u578b\u7684\u6df7\u5408\u68c0\u7d22\u7ba1\u9053\uff0c\u4ee5\u53ca\u878d\u5408\u89c4\u5219\u542f\u53d1\u5f0f\u3001\u5e8f\u5217\u884c\u4e3a\u5efa\u6a21\u548c\u4e0a\u4e0b\u6587\u591a\u81c2\u8001\u864e\u673a\u7684\u591a\u9636\u6bb5\u63a8\u8350\u673a\u5236\u3002", "result": "\u7cfb\u7edf\u572824\u4e2aNVIDIA H100 GPU\u4e0a\u4f7f\u7528Docker Swarm\u548cvLLM\u5b8c\u5168\u672c\u5730\u5316\u8fd0\u884c\uff0c\u901a\u8fc7\u4eba\u5de5QA\u548c\u7cfb\u7edf\u6307\u6807\u9a8c\u8bc1\u4e86\u57fa\u4e8e\u4e8b\u5b9e\u7684\u751f\u6210\u3001\u663e\u5f0f\u8def\u7531\u548c\u5206\u5c42\u5b89\u5168\u673a\u5236\u80fd\u591f\u5728\u9ad8\u98ce\u9669\u91d1\u878d\u73af\u5883\u4e2d\u63d0\u4f9b\u53ef\u4fe1AI\u89c1\u89e3\u3002", "conclusion": "\u901a\u8fc7\u663e\u5f0f\u8def\u7531\u548c\u5206\u5c42\u5b89\u5168\u673a\u5236\u7684\u57fa\u4e8e\u4e8b\u5b9e\u7684\u751f\u6210\uff0c\u53ef\u4ee5\u5728\u9ad8\u98ce\u9669\u91d1\u878d\u73af\u5883\u4e2d\u63d0\u4f9b\u53ef\u4fe1\u7684AI\u89c1\u89e3\uff0c\u8bc1\u660e\u4e86\u751f\u4ea7\u7ea7\u751f\u6210\u5f0f\u667a\u80fd\u4f53\u5728\u96f6\u552e\u91d1\u878d\u9886\u57df\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2510.20041", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.20041", "abs": "https://arxiv.org/abs/2510.20041", "authors": ["Gareema Ranjan", "Mahmoud Alfadel", "Gengyi Sun", "Shane McIntosh"], "title": "The Cost of Downgrading Build Systems: A Case Study of Kubernetes", "comment": null, "summary": "Since developers invoke the build system frequently, its performance can\nimpact productivity. Modern artifact-based build tools accelerate builds, yet\nprior work shows that teams may abandon them for alternatives that are easier\nto maintain. While prior work shows why downgrades are performed, the\nimplications of downgrades remain largely unexplored. In this paper, we\ndescribe a case study of the Kubernetes project, focusing on its downgrade from\nan artifact-based build tool (Bazel) to a language-specific solution (Go\nBuild). We reproduce and analyze the full and incremental builds of change sets\nduring the downgrade period. On the one hand, we find that Bazel builds are\nfaster than Go Build, completing full builds in 23.06-38.66 up to 75.19 impose\na larger memory footprint than Go Build of 81.42-351.07 respectively. Bazel\nbuilds also impose a greater CPU load at parallelism settings above eight for\nfull builds and above one for incremental builds. We estimate that downgrading\nfrom Bazel can increase CI resource costs by up to 76 explore whether our\nobservations generalize by replicating our Kubernetes study on four other\nprojects that also downgraded from Bazel to older build tools. We observe that\nwhile build time penalties decrease, Bazel consistently consumes more memory.\nWe conclude that abandoning artifact-based build tools, despite perceived\nmaintainability benefits, tends to incur considerable performance costs for\nlarge projects. Our observations may help stakeholders to balance trade-offs in\nbuild tool adoption", "AI": {"tldr": "Kubernetes\u9879\u76ee\u4eceBazel\u964d\u7ea7\u5230Go Build\u7684\u6848\u4f8b\u7814\u7a76\u663e\u793a\uff0c\u867d\u7136Bazel\u6784\u5efa\u901f\u5ea6\u66f4\u5feb\uff0c\u4f46\u5185\u5b58\u5360\u7528\u66f4\u5927\uff0c\u5bfc\u81f4CI\u8d44\u6e90\u6210\u672c\u589e\u52a076%\u3002\u5728\u56db\u4e2a\u5176\u4ed6\u9879\u76ee\u7684\u9a8c\u8bc1\u4e2d\u4e5f\u89c2\u5bdf\u5230\u7c7b\u4f3c\u8d8b\u52bf\u3002", "motivation": "\u63a2\u7d22\u6784\u5efa\u7cfb\u7edf\u964d\u7ea7\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u4ece\u57fa\u4e8e\u5de5\u4ef6\u7684\u6784\u5efa\u5de5\u5177\uff08\u5982Bazel\uff09\u964d\u7ea7\u5230\u8bed\u8a00\u7279\u5b9a\u89e3\u51b3\u65b9\u6848\uff08\u5982Go Build\uff09\u7684\u5b9e\u9645\u540e\u679c\u3002", "method": "\u901a\u8fc7\u590d\u73b0\u548c\u5206\u6790Kubernetes\u9879\u76ee\u964d\u7ea7\u671f\u95f4\u7684\u5b8c\u6574\u548c\u589e\u91cf\u6784\u5efa\uff0c\u6bd4\u8f83Bazel\u548cGo Build\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u5e76\u5728\u56db\u4e2a\u5176\u4ed6\u9879\u76ee\u4e0a\u8fdb\u884c\u9a8c\u8bc1\u7814\u7a76\u3002", "result": "Bazel\u6784\u5efa\u901f\u5ea6\u6bd4Go Build\u5feb23.06-38.66%\uff08\u5b8c\u6574\u6784\u5efa\uff09\u548c75.19%\uff08\u589e\u91cf\u6784\u5efa\uff09\uff0c\u4f46\u5185\u5b58\u5360\u7528\u9ad8\u51fa81.42-351.07%\u3002\u5728\u5e76\u884c\u5ea6\u8f83\u9ad8\u65f6CPU\u8d1f\u8f7d\u66f4\u5927\uff0cCI\u8d44\u6e90\u6210\u672c\u53ef\u80fd\u589e\u52a076%\u3002", "conclusion": "\u653e\u5f03\u57fa\u4e8e\u5de5\u4ef6\u7684\u6784\u5efa\u5de5\u5177\u867d\u7136\u53ef\u80fd\u63d0\u9ad8\u53ef\u7ef4\u62a4\u6027\uff0c\u4f46\u4f1a\u5bf9\u5927\u578b\u9879\u76ee\u5e26\u6765\u663e\u8457\u7684\u6027\u80fd\u6210\u672c\uff0c\u9700\u8981\u6743\u8861\u5229\u5f0a\u3002"}}
{"id": "2510.19885", "categories": ["cs.CR", "math.NT"], "pdf": "https://arxiv.org/pdf/2510.19885", "abs": "https://arxiv.org/abs/2510.19885", "authors": ["James Kim"], "title": "Analysis and Comparison of Known and Randomly Generated S-boxes for Block Ciphers", "comment": "Master's Dissertation 41 pages", "summary": "Mathematically constructed S-boxes arise from algebraic structures and finite\nfield theory to ensure strong, provable cryptographic properties. These\nmathematically grounded constructions allow for generation of thousands of\nS-Boxes with high nonlinearity, APN properties, and balanced avalanche\ncharacteristics, unlike fully random methods, which lack such theoretical\nguarantees in exchange for low complexity and more varied results. In this\nwork, we compare mathematically constructed constructions with randomly\ngenerated ones to evaluate the relative weakness of the latter. We also\nestablish an average measure of performance for randomly generated\npermutations, as well as random with forced cycle constraints, and compare them\nto well-established designs in a simple SPN setting.", "AI": {"tldr": "\u6bd4\u8f83\u6570\u5b66\u6784\u9020\u4e0e\u968f\u673a\u751f\u6210\u7684S\u76d2\u5728\u5bc6\u7801\u5b66\u6027\u80fd\u4e0a\u7684\u5dee\u5f02\uff0c\u5efa\u7acb\u968f\u673a\u6392\u5217\u7684\u5e73\u5747\u6027\u80fd\u57fa\u51c6\uff0c\u5e76\u5728\u7b80\u5355SPN\u7ed3\u6784\u4e2d\u4e0e\u4f20\u7edf\u8bbe\u8ba1\u5bf9\u6bd4", "motivation": "\u6570\u5b66\u6784\u9020\u7684S\u76d2\u5177\u6709\u53ef\u8bc1\u660e\u7684\u5bc6\u7801\u5b66\u7279\u6027\uff0c\u800c\u5b8c\u5168\u968f\u673a\u65b9\u6cd5\u7f3a\u4e4f\u7406\u8bba\u4fdd\u8bc1\u4f46\u590d\u6742\u5ea6\u4f4e\u4e14\u7ed3\u679c\u591a\u6837\uff0c\u9700\u8981\u8bc4\u4f30\u968f\u673a\u65b9\u6cd5\u7684\u76f8\u5bf9\u5f31\u70b9", "method": "\u6bd4\u8f83\u6570\u5b66\u6784\u9020\u4e0e\u968f\u673a\u751f\u6210\u7684S\u76d2\uff0c\u5efa\u7acb\u968f\u673a\u6392\u5217\u7684\u5e73\u5747\u6027\u80fd\u5ea6\u91cf\uff0c\u5305\u62ec\u5e26\u5faa\u73af\u7ea6\u675f\u7684\u968f\u673a\u751f\u6210\uff0c\u5728\u7b80\u5355SPN\u8bbe\u7f6e\u4e2d\u4e0e\u4f20\u7edf\u8bbe\u8ba1\u5bf9\u6bd4", "result": "\u6570\u5b66\u6784\u9020\u7684S\u76d2\u5177\u6709\u9ad8\u975e\u7ebf\u6027\u5ea6\u3001APN\u7279\u6027\u548c\u5e73\u8861\u7684\u96ea\u5d29\u7279\u6027\uff0c\u800c\u968f\u673a\u65b9\u6cd5\u5728\u8fd9\u4e9b\u7406\u8bba\u4fdd\u8bc1\u65b9\u9762\u8f83\u5f31", "conclusion": "\u6570\u5b66\u6784\u9020\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u6570\u5343\u4e2a\u5177\u6709\u5f3a\u5bc6\u7801\u5b66\u7279\u6027\u7684S\u76d2\uff0c\u76f8\u6bd4\u968f\u673a\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u7406\u8bba\u4fdd\u8bc1\u548c\u6027\u80fd"}}
{"id": "2510.20102", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20102", "abs": "https://arxiv.org/abs/2510.20102", "authors": ["Gyuyeon Na", "Minjung Park", "Hyeonjeong Cha", "Sangmi Chai"], "title": "Human-Centered LLM-Agent System for Detecting Anomalous Digital Asset Transactions", "comment": null, "summary": "We present HCLA, a human-centered multi-agent system for anomaly detection in\ndigital asset transactions. The system links three roles: Parsing, Detection,\nand Explanation, into a conversational workflow that lets non-experts ask\nquestions in natural language, inspect structured analytics, and obtain\ncontext-aware rationales. Implemented with an open-source web UI, HCLA\ntranslates user intents into a schema for a classical detector (XGBoost in our\nprototype) and returns narrative explanations grounded in the underlying\nfeatures. On a labeled Bitcoin mixing dataset (Wasabi Wallet, 2020-2024), the\nbaseline detector reaches strong accuracy, while HCLA adds interpretability and\ninteractive refinement. We describe the architecture, interaction loop,\ndataset, evaluation protocol, and limitations, and discuss how a\nhuman-in-the-loop design improves transparency and trust in financial\nforensics.", "AI": {"tldr": "HCLA\u662f\u4e00\u4e2a\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u591a\u667a\u80fd\u4f53\u5f02\u5e38\u68c0\u6d4b\u7cfb\u7edf\uff0c\u7528\u4e8e\u6570\u5b57\u8d44\u4ea7\u4ea4\u6613\u5206\u6790\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u68c0\u6d4b\u7ed3\u679c\u3002", "motivation": "\u89e3\u51b3\u91d1\u878d\u53d6\u8bc1\u4e2d\u975e\u4e13\u5bb6\u7528\u6237\u96be\u4ee5\u7406\u89e3\u548c\u4fe1\u4efb\u4f20\u7edf\u5f02\u5e38\u68c0\u6d4b\u7cfb\u7edf\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u91c7\u7528\u4e09\u89d2\u8272\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff1a\u89e3\u6790\u3001\u68c0\u6d4b\u548c\u89e3\u91ca\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u754c\u9762\u5c06\u7528\u6237\u610f\u56fe\u8f6c\u6362\u4e3aXGBoost\u68c0\u6d4b\u5668\u7684\u8f93\u5165\u6a21\u5f0f\uff0c\u5e76\u63d0\u4f9b\u57fa\u4e8e\u7279\u5f81\u7684\u53d9\u8ff0\u6027\u89e3\u91ca\u3002", "result": "\u5728\u6bd4\u7279\u5e01\u6df7\u5e01\u6570\u636e\u96c6\u4e0a\uff0c\u57fa\u7ebf\u68c0\u6d4b\u5668\u8fbe\u5230\u9ad8\u51c6\u786e\u7387\uff0cHCLA\u7cfb\u7edf\u5728\u6b64\u57fa\u7840\u4e0a\u589e\u52a0\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u4ea4\u4e92\u5f0f\u4f18\u5316\u80fd\u529b\u3002", "conclusion": "\u4eba\u673a\u534f\u540c\u8bbe\u8ba1\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u91d1\u878d\u53d6\u8bc1\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u548c\u4fe1\u4efb\u5ea6\uff0c\u4f7f\u975e\u4e13\u5bb6\u7528\u6237\u4e5f\u80fd\u6709\u6548\u4f7f\u7528\u590d\u6742\u7684\u5f02\u5e38\u68c0\u6d4b\u6280\u672f\u3002"}}
{"id": "2510.20121", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.20121", "abs": "https://arxiv.org/abs/2510.20121", "authors": ["Carlos J. Fernandez-Candel", "Jesus Garcia-Molina", "Francisco Javier Bermudez Ruiz", "Jose Ramon Hoyos Barcelo", "Diego Sevilla Ruiz", "Benito Jose Cuesta Viera"], "title": "Developing a Model-Driven Reengineering Approach for Migrating PL/SQL Triggers to Java: A Practical Experience", "comment": "31 pages, 22 figures", "summary": "Model-driven software engineering (MDE) techniques are not only useful in\nforward engineering scenarios, but can also be successfully applied to evolve\nexisting systems. RAD (Rapid Application Development) platforms emerged in the\nnineties, but the success of modern software technologies motivated that a\nlarge number of enterprises tackled the migration of their RAD applications,\nsuch as Oracle Forms. Our research group has collaborated with a software\ncompany in developing a solution to migrate PL/SQL monolithic code on Forms\ntriggers and program units to Java code separated in several tiers.\n  Our research focused on the model-driven reengineering process applied to\ndevelop the migration tool for the conversion of PL/SQL code to Java. Legacy\ncode is represented in form of KDM (Knowledge-Discovery Metamodel) models. In\nthis paper, we propose a software process to implement a model-driven\nre-engineering. This process integrates a TDD-like approach to incrementally\ndevelop model transformations with three kinds of validations for the generated\ncode. The implementation and validation of the re-engineering approach are\nexplained in detail, as well as the evaluation of some issues related with the\napplication of MDE.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u578b\u9a71\u52a8\u91cd\u6784\u7684\u8f6f\u4ef6\u8fc7\u7a0b\uff0c\u7528\u4e8e\u5c06PL/SQL\u4ee3\u7801\u8fc1\u79fb\u5230Java\uff0c\u96c6\u6210\u4e86\u7c7b\u4f3cTDD\u7684\u65b9\u6cd5\u6765\u589e\u91cf\u5f00\u53d1\u6a21\u578b\u8f6c\u6362\uff0c\u5e76\u5305\u542b\u4e09\u79cd\u4ee3\u7801\u9a8c\u8bc1\u673a\u5236\u3002", "motivation": "\u73b0\u4ee3\u8f6f\u4ef6\u6280\u672f\u7684\u53d1\u5c55\u4fc3\u4f7f\u8bb8\u591a\u4f01\u4e1a\u9700\u8981\u8fc1\u79fb\u5176RAD\u5e73\u53f0\uff08\u5982Oracle Forms\uff09\u4e0a\u7684\u9057\u7559\u5e94\u7528\uff0c\u7814\u7a76\u56e2\u961f\u4e0e\u8f6f\u4ef6\u516c\u53f8\u5408\u4f5c\u5f00\u53d1PL/SQL\u5230Java\u7684\u8fc1\u79fb\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528KDM\u6a21\u578b\u8868\u793a\u9057\u7559\u4ee3\u7801\uff0c\u91c7\u7528\u6a21\u578b\u9a71\u52a8\u91cd\u6784\u8fc7\u7a0b\uff0c\u96c6\u6210\u7c7b\u4f3cTDD\u7684\u65b9\u6cd5\u589e\u91cf\u5f00\u53d1\u6a21\u578b\u8f6c\u6362\uff0c\u5305\u542b\u4e09\u79cd\u751f\u6210\u7684\u4ee3\u7801\u9a8c\u8bc1\u673a\u5236\u3002", "result": "\u5b9e\u73b0\u4e86\u6a21\u578b\u9a71\u52a8\u91cd\u6784\u65b9\u6cd5\uff0c\u8be6\u7ec6\u8bf4\u660e\u4e86\u5b9e\u65bd\u548c\u9a8c\u8bc1\u8fc7\u7a0b\uff0c\u5e76\u8bc4\u4f30\u4e86MDE\u5e94\u7528\u4e2d\u7684\u76f8\u5173\u95ee\u9898\u3002", "conclusion": "\u6a21\u578b\u9a71\u52a8\u8f6f\u4ef6\u5de5\u7a0b\u6280\u672f\u4e0d\u4ec5\u9002\u7528\u4e8e\u6b63\u5411\u5de5\u7a0b\uff0c\u4e5f\u80fd\u6210\u529f\u5e94\u7528\u4e8e\u73b0\u6709\u7cfb\u7edf\u7684\u6f14\u8fdb\u548c\u8fc1\u79fb\uff0c\u7279\u522b\u662f\u5728RAD\u5e73\u53f0\u9057\u7559\u5e94\u7528\u7684\u73b0\u4ee3\u5316\u8fc7\u7a0b\u4e2d\u3002"}}
{"id": "2510.19890", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19890", "abs": "https://arxiv.org/abs/2510.19890", "authors": ["Jan Zelinka", "Oliver Kost", "Marek Hr\u00faz"], "title": "Deep Sequence-to-Sequence Models for GNSS Spoofing Detection", "comment": null, "summary": "We present a data generation framework designed to simulate spoofing attacks\nand randomly place attack scenarios worldwide. We apply deep neural\nnetwork-based models for spoofing detection, utilizing Long Short-Term Memory\nnetworks and Transformer-inspired architectures. These models are specifically\ndesigned for online detection and are trained using the generated dataset. Our\nresults demonstrate that deep learning models can accurately distinguish\nspoofed signals from genuine ones, achieving high detection performance. The\nbest results are achieved by Transformer-inspired architectures with early\nfusion of the inputs resulting in an error rate of 0.16%.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6570\u636e\u751f\u6210\u6846\u67b6\u6765\u6a21\u62df\u6b3a\u9a97\u653b\u51fb\uff0c\u5e76\u4f7f\u7528LSTM\u548cTransformer\u67b6\u6784\u8fdb\u884c\u5728\u7ebf\u6b3a\u9a97\u68c0\u6d4b\uff0c\u6700\u4f73\u6a21\u578b\u9519\u8bef\u7387\u4e3a0.16%\u3002", "motivation": "\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u6b3a\u9a97\u653b\u51fb\u68c0\u6d4b\u65b9\u6cd5\u6765\u4fdd\u62a4\u7cfb\u7edf\u5b89\u5168\uff0c\u7279\u522b\u662f\u9488\u5bf9\u5168\u7403\u8303\u56f4\u5185\u968f\u673a\u5206\u5e03\u7684\u6b3a\u9a97\u573a\u666f\u3002", "method": "\u4f7f\u7528\u6570\u636e\u751f\u6210\u6846\u67b6\u6a21\u62df\u6b3a\u9a97\u653b\u51fb\uff0c\u5e94\u7528\u57fa\u4e8eLSTM\u548cTransformer\u67b6\u6784\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u5728\u7ebf\u68c0\u6d4b\uff0c\u91c7\u7528\u65e9\u671f\u878d\u5408\u8f93\u5165\u7b56\u7565\u3002", "result": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u80fd\u591f\u51c6\u786e\u533a\u5206\u6b3a\u9a97\u4fe1\u53f7\u548c\u771f\u5b9e\u4fe1\u53f7\uff0cTransformer\u67b6\u6784\u5728\u65e9\u671f\u878d\u5408\u8f93\u5165\u7684\u60c5\u51b5\u4e0b\u8fbe\u52300.16%\u7684\u9519\u8bef\u7387\u3002", "conclusion": "\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u6b3a\u9a97\u68c0\u6d4b\u65b9\u6cd5\u5177\u6709\u9ad8\u7cbe\u5ea6\uff0cTransformer\u67b6\u6784\u5728\u65e9\u671f\u878d\u5408\u7b56\u7565\u4e0b\u8868\u73b0\u6700\u4f73\uff0c\u4e3a\u5728\u7ebf\u6b3a\u9a97\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.20109", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20109", "abs": "https://arxiv.org/abs/2510.20109", "authors": ["Joshua Yuvaraj"], "title": "The Verification-Value Paradox: A Normative Critique of Gen AI in Legal Practice", "comment": null, "summary": "It is often claimed that machine learning-based generative AI products will\ndrastically streamline and reduce the cost of legal practice. This enthusiasm\nassumes lawyers can effectively manage AI's risks. Cases in Australia and\nelsewhere in which lawyers have been reprimanded for submitting inaccurate\nAI-generated content to courts suggest this paradigm must be revisited. This\npaper argues that a new paradigm is needed to evaluate AI use in practice,\ngiven (a) AI's disconnection from reality and its lack of transparency, and (b)\nlawyers' paramount duties like honesty, integrity, and not to mislead the\ncourt. It presents an alternative model of AI use in practice that more\nholistically reflects these features (the verification-value paradox). That\nparadox suggests increases in efficiency from AI use in legal practice will be\nmet by a correspondingly greater imperative to manually verify any outputs of\nthat use, rendering the net value of AI use often negligible to lawyers. The\npaper then sets out the paradox's implications for legal practice and legal\neducation, including for AI use but also the values that the paradox suggests\nshould undergird legal practice: fidelity to the truth and civic\nresponsibility.", "AI": {"tldr": "\u8bba\u6587\u8ba4\u4e3a\u9700\u8981\u91cd\u65b0\u8bc4\u4f30AI\u5728\u6cd5\u5f8b\u5b9e\u8df5\u4e2d\u7684\u4f7f\u7528\uff0c\u63d0\u51fa\u4e86\u9a8c\u8bc1-\u4ef7\u503c\u6096\u8bba\u6a21\u578b\uff0c\u6307\u51faAI\u5e26\u6765\u7684\u6548\u7387\u63d0\u5347\u4f1a\u88ab\u76f8\u5e94\u7684\u9a8c\u8bc1\u9700\u6c42\u6240\u62b5\u6d88\uff0c\u5bfc\u81f4AI\u4f7f\u7528\u7684\u51c0\u4ef7\u503c\u5bf9\u5f8b\u5e08\u6765\u8bf4\u5f80\u5f80\u5fae\u4e4e\u5176\u5fae\u3002", "motivation": "\u9274\u4e8e\u5f8b\u5e08\u56e0\u63d0\u4ea4\u4e0d\u51c6\u786e\u7684AI\u751f\u6210\u5185\u5bb9\u800c\u53d7\u5230\u8c34\u8d23\u7684\u6848\u4f8b\uff0c\u4ee5\u53caAI\u4e0e\u73b0\u5b9e\u8131\u8282\u3001\u7f3a\u4e4f\u900f\u660e\u5ea6\u7684\u7279\u70b9\u4e0e\u5f8b\u5e08\u8bda\u5b9e\u3001\u6b63\u76f4\u3001\u4e0d\u8bef\u5bfc\u6cd5\u5ead\u7b49\u9996\u8981\u804c\u8d23\u4e4b\u95f4\u7684\u77db\u76fe\uff0c\u9700\u8981\u91cd\u65b0\u8bc4\u4f30AI\u5728\u6cd5\u5f8b\u5b9e\u8df5\u4e2d\u7684\u4f7f\u7528\u8303\u5f0f\u3002", "method": "\u63d0\u51fa\u4e86\u9a8c\u8bc1-\u4ef7\u503c\u6096\u8bba\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u66f4\u5168\u9762\u5730\u53cd\u6620\u4e86AI\u5728\u6cd5\u5f8b\u5b9e\u8df5\u4e2d\u7684\u7279\u5f81\uff0c\u5e76\u5206\u6790\u4e86\u8be5\u6096\u8bba\u5bf9\u6cd5\u5f8b\u5b9e\u8df5\u548c\u6cd5\u5f8b\u6559\u80b2\u7684\u5f71\u54cd\u3002", "result": "AI\u5728\u6cd5\u5f8b\u5b9e\u8df5\u4e2d\u5e26\u6765\u7684\u6548\u7387\u63d0\u5347\u4f1a\u88ab\u76f8\u5e94\u7684\u9a8c\u8bc1\u9700\u6c42\u6240\u62b5\u6d88\uff0c\u5bfc\u81f4AI\u4f7f\u7528\u7684\u51c0\u4ef7\u503c\u5f80\u5f80\u5fae\u4e4e\u5176\u5fae\u3002", "conclusion": "\u9700\u8981\u5efa\u7acb\u65b0\u7684AI\u4f7f\u7528\u8303\u5f0f\uff0c\u5f3a\u8c03\u5bf9\u771f\u76f8\u7684\u5fe0\u8bda\u548c\u516c\u6c11\u8d23\u4efb\u7b49\u4ef7\u503c\u89c2\u5e94\u6210\u4e3a\u6cd5\u5f8b\u5b9e\u8df5\u7684\u57fa\u7840\uff0c\u5e76\u5bf9\u6cd5\u5f8b\u5b9e\u8df5\u548c\u6cd5\u5f8b\u6559\u80b2\u4ea7\u751f\u6df1\u8fdc\u5f71\u54cd\u3002"}}
{"id": "2510.20211", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20211", "abs": "https://arxiv.org/abs/2510.20211", "authors": ["Zhenning Yang", "Hui Guan", "Victor Nicolet", "Brandon Paulsen", "Joey Dodds", "Daniel Kroening", "Ang Chen"], "title": "Automated Cloud Infrastructure-as-Code Reconciliation with AI Agents", "comment": null, "summary": "Cloud infrastructure is managed through a mix of interfaces -- traditionally,\ncloud consoles, command-line interfaces (CLI), and SDKs are the tools of\nchoice. Recently, Infrastructure-as-Code/IaC frameworks (e.g., Terraform) have\nquickly gained popularity. Unlike conventional tools, IaC~frameworks encode the\ninfrastructure in a \"source-of-truth\" configuration. They are capable of\nautomatically carrying out modifications to the cloud -- deploying, updating,\nor destroying resources -- to bring the actual infrastructure into alignment\nwith the IaC configuration. However, when IaC is used alongside consoles, CLIs,\nor SDKs, it loses visibility into external changes, causing infrastructure\ndrift, where the configuration becomes outdated, and later IaC operations may\nundo valid updates or trigger errors.\n  We present NSync, an automated system for IaC reconciliation that propagates\nout-of-band changes back into the IaC program. Our key insight is that\ninfrastructure changes eventually all occur via cloud API invocations -- the\nlowest layer for cloud management operations. NSync gleans insights from API\ntraces to detect drift (i.e., non-IaC changes) and reconcile it (i.e., update\nthe IaC configuration to capture the changes). It employs an agentic\narchitecture that leverages LLMs to infer high-level intents from noisy API\nsequences, synthesize targeted IaC updates using specialized tools, and\ncontinually improve through a self-evolving knowledge base of past\nreconciliations. We further introduce a novel evaluation pipeline for injecting\nrealistic drifts into cloud infrastructure and assessing reconciliation\nperformance. Experiments across five real-world Terraform projects and 372\ndrift scenarios show that NSync outperforms the baseline both in terms of\naccuracy (from 0.71 to 0.97 pass@3) and token efficiency (1.47$\\times$\nimprovement).", "AI": {"tldr": "NSync\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u7684IaC\u534f\u8c03\u7cfb\u7edf\uff0c\u901a\u8fc7\u5206\u6790\u4e91API\u8ffd\u8e2a\u6765\u68c0\u6d4b\u57fa\u7840\u8bbe\u65bd\u6f02\u79fb\uff0c\u5e76\u5229\u7528LLM\u63a8\u65ad\u610f\u56fe\u6765\u66f4\u65b0IaC\u914d\u7f6e\uff0c\u5b9e\u73b0\u57fa\u7840\u8bbe\u65bd\u4e0e\u914d\u7f6e\u7684\u540c\u6b65\u3002", "motivation": "\u5f53\u57fa\u7840\u8bbe\u65bd\u5373\u4ee3\u7801(IaC)\u4e0e\u4e91\u63a7\u5236\u53f0\u3001CLI\u6216SDK\u540c\u65f6\u4f7f\u7528\u65f6\uff0cIaC\u4f1a\u5931\u53bb\u5bf9\u5916\u90e8\u53d8\u5316\u7684\u53ef\u89c1\u6027\uff0c\u5bfc\u81f4\u57fa\u7840\u8bbe\u65bd\u6f02\u79fb\uff0c\u914d\u7f6e\u8fc7\u65f6\uff0c\u540e\u7eedIaC\u64cd\u4f5c\u53ef\u80fd\u64a4\u9500\u6709\u6548\u66f4\u65b0\u6216\u89e6\u53d1\u9519\u8bef\u3002", "method": "NSync\u91c7\u7528\u4ee3\u7406\u67b6\u6784\uff0c\u5229\u7528LLM\u4ece\u566a\u58f0API\u5e8f\u5217\u4e2d\u63a8\u65ad\u9ad8\u5c42\u610f\u56fe\uff0c\u4f7f\u7528\u4e13\u7528\u5de5\u5177\u5408\u6210\u76ee\u6807IaC\u66f4\u65b0\uff0c\u5e76\u901a\u8fc7\u81ea\u6f14\u8fdb\u77e5\u8bc6\u5e93\u6301\u7eed\u6539\u8fdb\u3002\u7cfb\u7edf\u4eceAPI\u8ffd\u8e2a\u4e2d\u83b7\u53d6\u6d1e\u5bdf\u6765\u68c0\u6d4b\u6f02\u79fb\u5e76\u8fdb\u884c\u534f\u8c03\u3002", "result": "\u57285\u4e2a\u771f\u5b9e\u4e16\u754cTerraform\u9879\u76ee\u548c372\u4e2a\u6f02\u79fb\u573a\u666f\u7684\u5b9e\u9a8c\u8868\u660e\uff0cNSync\u5728\u51c6\u786e\u7387\uff08\u4ece0.71\u63d0\u5347\u52300.97 pass@3\uff09\u548ctoken\u6548\u7387\uff081.47\u500d\u6539\u8fdb\uff09\u65b9\u9762\u5747\u4f18\u4e8e\u57fa\u7ebf\u3002", "conclusion": "NSync\u901a\u8fc7API\u8ffd\u8e2a\u5206\u6790\u548cLLM\u9a71\u52a8\u7684\u610f\u56fe\u63a8\u65ad\uff0c\u6709\u6548\u89e3\u51b3\u4e86IaC\u57fa\u7840\u8bbe\u65bd\u6f02\u79fb\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u81ea\u52a8\u5316\u7684\u914d\u7f6e\u534f\u8c03\u3002"}}
{"id": "2510.19938", "categories": ["cs.CR", "cs.DC", "cs.HC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.19938", "abs": "https://arxiv.org/abs/2510.19938", "authors": ["Foad Namjoo", "Neng Wan", "Devan Mallory", "Yuyi Chang", "Nithin Sugavanam", "Long Yin Lee", "Ning Xiong", "Emre Ertin", "Jeff M. Phillips"], "title": "Designing a Secure and Resilient Distributed Smartphone Participant Data Collection System", "comment": "9 pages, 3 figures. Accepted at EAI SmartSP 2025 Conference (Springer\n  LNICST). This version is the arXiv preprint prepared for open access", "summary": "Real-world health studies require continuous and secure data collection from\nmobile and wearable devices. We introduce MotionPI, a smartphone-based system\ndesigned to collect behavioral and health data through sensors and surveys with\nminimal interaction from participants. The system integrates passive data\ncollection (such as GPS and wristband motion data) with Ecological Momentary\nAssessment (EMA) surveys, which can be triggered randomly or based on physical\nactivity. MotionPI is designed to work under real-life constraints, including\nlimited battery life, weak or intermittent cellular connection, and minimal\nuser supervision. It stores data both locally and on a secure cloud server,\nwith encrypted transmission and storage. It integrates through Bluetooth Low\nEnergy (BLE) into wristband devices that store raw data and communicate motion\nsummaries and trigger events. MotionPI demonstrates a practical solution for\nsecure and scalable mobile data collection in cyber-physical health studies.", "AI": {"tldr": "MotionPI\u662f\u4e00\u4e2a\u57fa\u4e8e\u667a\u80fd\u624b\u673a\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u901a\u8fc7\u4f20\u611f\u5668\u548c\u8c03\u67e5\u6536\u96c6\u884c\u4e3a\u548c\u5065\u5eb7\u6570\u636e\uff0c\u5177\u6709\u6700\u5c0f\u7528\u6237\u4ea4\u4e92\u3001\u5b89\u5168\u4f20\u8f93\u548c\u5b58\u50a8\uff0c\u4ee5\u53ca\u9002\u5e94\u73b0\u5b9e\u751f\u6d3b\u7ea6\u675f\u7684\u7279\u70b9\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7684\u5065\u5eb7\u7814\u7a76\u9700\u8981\u4ece\u79fb\u52a8\u548c\u53ef\u7a7f\u6234\u8bbe\u5907\u6301\u7eed\u3001\u5b89\u5168\u5730\u6536\u96c6\u6570\u636e\uff0c\u4f46\u9762\u4e34\u7535\u6c60\u5bff\u547d\u6709\u9650\u3001\u7f51\u7edc\u8fde\u63a5\u5f31\u548c\u7528\u6237\u76d1\u7763\u5c11\u7b49\u6311\u6218\u3002", "method": "\u7cfb\u7edf\u6574\u5408\u88ab\u52a8\u6570\u636e\u6536\u96c6\uff08GPS\u548c\u8155\u5e26\u8fd0\u52a8\u6570\u636e\uff09\u4e0e\u751f\u6001\u77ac\u65f6\u8bc4\u4f30\u8c03\u67e5\uff0c\u901a\u8fc7\u84dd\u7259\u4f4e\u80fd\u8017\u8fde\u63a5\u8155\u5e26\u8bbe\u5907\uff0c\u652f\u6301\u672c\u5730\u548c\u4e91\u7aef\u52a0\u5bc6\u5b58\u50a8\u3002", "result": "MotionPI\u5c55\u793a\u4e86\u5728\u73b0\u5b9e\u751f\u6d3b\u7ea6\u675f\u4e0b\u5b89\u5168\u3001\u53ef\u6269\u5c55\u7684\u79fb\u52a8\u6570\u636e\u6536\u96c6\u7684\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "MotionPI\u4e3a\u7f51\u7edc\u7269\u7406\u5065\u5eb7\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b89\u5168\u3001\u53ef\u6269\u5c55\u7684\u79fb\u52a8\u6570\u636e\u6536\u96c6\u7cfb\u7edf\uff0c\u80fd\u591f\u9002\u5e94\u73b0\u5b9e\u4e16\u754c\u7684\u64cd\u4f5c\u9650\u5236\u3002"}}
{"id": "2510.20188", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20188", "abs": "https://arxiv.org/abs/2510.20188", "authors": ["Morris Yu-Chao Huang", "Zhen Tan", "Mohan Zhang", "Pingzhi Li", "Zhuo Zhang", "Tianlong Chen"], "title": "TRUST: A Decentralized Framework for Auditing Large Language Model Reasoning", "comment": null, "summary": "Large Language Models generate complex reasoning chains that reveal their\ndecision-making, yet verifying the faithfulness and harmlessness of these\nintermediate steps remains a critical unsolved problem. Existing auditing\nmethods are centralized, opaque, and hard to scale, creating significant risks\nfor deploying proprietary models in high-stakes domains. We identify four core\nchallenges: (1) Robustness: Centralized auditors are single points of failure,\nprone to bias or attacks. (2) Scalability: Reasoning traces are too long for\nmanual verification. (3) Opacity: Closed auditing undermines public trust. (4)\nPrivacy: Exposing full reasoning risks model theft or distillation. We propose\nTRUST, a transparent, decentralized auditing framework that overcomes these\nlimitations via: (1) A consensus mechanism among diverse auditors, guaranteeing\ncorrectness under up to $30\\%$ malicious participants. (2) A hierarchical DAG\ndecomposition of reasoning traces, enabling scalable, parallel auditing. (3) A\nblockchain ledger that records all verification decisions for public\naccountability. (4) Privacy-preserving segmentation, sharing only partial\nreasoning steps to protect proprietary logic. We provide theoretical guarantees\nfor the security and economic incentives of the TRUST framework. Experiments\nacross multiple LLMs (GPT-OSS, DeepSeek-r1, Qwen) and reasoning tasks (math,\nmedical, science, humanities) show TRUST effectively detects reasoning flaws\nand remains robust against adversarial auditors. Our work pioneers\ndecentralized AI auditing, offering a practical path toward safe and\ntrustworthy LLM deployment.", "AI": {"tldr": "\u63d0\u51fa\u4e86TRUST\u6846\u67b6\uff0c\u4e00\u4e2a\u53bb\u4e2d\u5fc3\u5316\u7684AI\u5ba1\u8ba1\u7cfb\u7edf\uff0c\u901a\u8fc7\u5171\u8bc6\u673a\u5236\u3001\u5206\u5c42DAG\u5206\u89e3\u3001\u533a\u5757\u94fe\u8d26\u672c\u548c\u9690\u79c1\u4fdd\u62a4\u5206\u6bb5\u6765\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u94fe\u7684\u9a8c\u8bc1\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5ba1\u8ba1\u65b9\u6cd5\u5b58\u5728\u96c6\u4e2d\u5316\u3001\u4e0d\u900f\u660e\u3001\u96be\u4ee5\u6269\u5c55\u7684\u95ee\u9898\uff0c\u65e0\u6cd5\u6709\u6548\u9a8c\u8bc1\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u94fe\u7684\u5fe0\u5b9e\u6027\u548c\u65e0\u5bb3\u6027\uff0c\u5728\u5173\u952e\u9886\u57df\u90e8\u7f72\u4e13\u6709\u6a21\u578b\u5b58\u5728\u91cd\u5927\u98ce\u9669\u3002", "method": "TRUST\u6846\u67b6\u5305\u542b\u56db\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u591a\u6837\u5316\u5ba1\u8ba1\u8005\u5171\u8bc6\u673a\u5236\uff1b2) \u63a8\u7406\u94fe\u7684\u5206\u5c42DAG\u5206\u89e3\uff1b3) \u533a\u5757\u94fe\u8d26\u672c\u8bb0\u5f55\u9a8c\u8bc1\u51b3\u7b56\uff1b4) \u9690\u79c1\u4fdd\u62a4\u7684\u5206\u6bb5\u5171\u4eab\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u8868\u660eTRUST\u80fd\u6709\u6548\u68c0\u6d4b\u63a8\u7406\u7f3a\u9677\uff0c\u572830%\u6076\u610f\u53c2\u4e0e\u8005\u60c5\u51b5\u4e0b\u4ecd\u4fdd\u6301\u7a33\u5065\uff0c\u9002\u7528\u4e8e\u591a\u79cdLLM\u548c\u63a8\u7406\u4efb\u52a1\u3002", "conclusion": "TRUST\u6846\u67b6\u4e3a\u53bb\u4e2d\u5fc3\u5316AI\u5ba1\u8ba1\u5f00\u521b\u4e86\u5148\u6cb3\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u53ef\u4fe1\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\u3002"}}
{"id": "2510.20340", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.20340", "abs": "https://arxiv.org/abs/2510.20340", "authors": ["Serena Cofano", "Daniel Williams", "Aman Sharma", "Martin Monperrus"], "title": "Classport: Designing Runtime Dependency Introspection for Java", "comment": null, "summary": "Runtime introspection of dependencies, i.e., the ability to observe which\ndependencies are currently used during program execution, is fundamental for\nSoftware Supply Chain security. Yet, Java has no support for it. We solve this\nproblem with Classport, a system that embeds dependency information into Java\nclass files, enabling the retrieval of dependency information at runtime. We\nevaluate Classport on six real-world projects, demonstrating the feasibility in\nidentifying dependencies at runtime. Runtime dependency introspection with\nClassport opens important avenues for runtime integrity checking.", "AI": {"tldr": "Classport\u7cfb\u7edf\u901a\u8fc7\u5728Java\u7c7b\u6587\u4ef6\u4e2d\u5d4c\u5165\u4f9d\u8d56\u4fe1\u606f\uff0c\u5b9e\u73b0\u4e86\u8fd0\u884c\u65f6\u4f9d\u8d56\u81ea\u7701\u529f\u80fd\uff0c\u89e3\u51b3\u4e86Java\u7f3a\u4e4f\u8fd0\u884c\u65f6\u4f9d\u8d56\u89c2\u5bdf\u80fd\u529b\u7684\u95ee\u9898\u3002", "motivation": "Java\u7f3a\u4e4f\u5bf9\u8fd0\u884c\u65f6\u4f9d\u8d56\u7684\u89c2\u5bdf\u80fd\u529b\uff0c\u8fd9\u5bf9\u4e8e\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\u81f3\u5173\u91cd\u8981\u3002\u5f53\u524d\u65e0\u6cd5\u5728\u7a0b\u5e8f\u6267\u884c\u671f\u95f4\u89c2\u5bdf\u54ea\u4e9b\u4f9d\u8d56\u6b63\u5728\u88ab\u4f7f\u7528\u3002", "method": "\u5f00\u53d1Classport\u7cfb\u7edf\uff0c\u5c06\u4f9d\u8d56\u4fe1\u606f\u5d4c\u5165\u5230Java\u7c7b\u6587\u4ef6\u4e2d\uff0c\u4ece\u800c\u80fd\u591f\u5728\u8fd0\u884c\u65f6\u68c0\u7d22\u4f9d\u8d56\u4fe1\u606f\u3002", "result": "\u57286\u4e2a\u771f\u5b9e\u9879\u76ee\u4e2d\u8bc4\u4f30Classport\uff0c\u8bc1\u660e\u4e86\u5728\u8fd0\u884c\u65f6\u8bc6\u522b\u4f9d\u8d56\u7684\u53ef\u884c\u6027\u3002", "conclusion": "Classport\u7684\u8fd0\u884c\u65f6\u4f9d\u8d56\u81ea\u7701\u529f\u80fd\u4e3a\u8fd0\u884c\u65f6\u5b8c\u6574\u6027\u68c0\u67e5\u5f00\u8f9f\u4e86\u91cd\u8981\u9014\u5f84\u3002"}}
{"id": "2510.19968", "categories": ["cs.CR", "cs.DC", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.19968", "abs": "https://arxiv.org/abs/2510.19968", "authors": ["Vipin Rathi", "Lakshya Chopra", "Madhav Agarwal", "Nitin Rajput", "Kriish Sharma", "Sushant Mundepi", "Shivam Gangwar", "Rudraksh Rawal", "Jishan"], "title": "Q-RAN: Quantum-Resilient O-RAN Architecture", "comment": "23 pages", "summary": "The telecommunications industry faces a dual transformation: the\narchitectural shift toward Open Radio Access Networks (O-RAN) and the emerging\nthreat from quantum computing. O-RAN disaggregated, multi-vendor architecture\ncreates a larger attack surface vulnerable to crypt-analytically relevant\nquantum computers(CRQCs) that will break current public key cryptography. The\nHarvest Now, Decrypt Later (HNDL) attack strategy makes this threat immediate,\nas adversaries can intercept encrypted data today for future decryption. This\npaper presents Q-RAN, a comprehensive quantum-resistant security framework for\nO-RAN networks using NIST-standardized Post-Quantum Cryptography (PQC). We\ndetail the implementation of ML-KEM (FIPS 203) and ML-DSA (FIPS 204),\nintegrated with Quantum Random Number Generators (QRNG) for cryptographic\nentropy. The solution deploys PQ-IPsec, PQ-DTLS, and PQ-mTLS protocols across\nall O-RAN interfaces, anchored by a centralized Post-Quantum Certificate\nAuthority (PQ-CA) within the SMO framework. This work provides a complete\nroadmap for securing disaggregated O-RAN ecosystems against quantum\nadversaries.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Q-RAN\u6846\u67b6\uff0c\u4f7f\u7528NIST\u6807\u51c6\u5316\u7684\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\u6765\u4fdd\u62a4O-RAN\u7f51\u7edc\u514d\u53d7\u91cf\u5b50\u8ba1\u7b97\u5a01\u80c1\u3002", "motivation": "\u7535\u4fe1\u884c\u4e1a\u9762\u4e34O-RAN\u67b6\u6784\u8f6c\u578b\u548c\u91cf\u5b50\u8ba1\u7b97\u5a01\u80c1\u7684\u53cc\u91cd\u6311\u6218\uff0c\u5f53\u524d\u516c\u94a5\u5bc6\u7801\u5b66\u6613\u88ab\u91cf\u5b50\u8ba1\u7b97\u673a\u7834\u89e3\uff0cHNDL\u653b\u51fb\u7b56\u7565\u4f7f\u5a01\u80c1\u8feb\u5728\u7709\u776b\u3002", "method": "\u5b9e\u73b0ML-KEM\u548cML-DSA\u7b97\u6cd5\uff0c\u96c6\u6210\u91cf\u5b50\u968f\u673a\u6570\u751f\u6210\u5668\uff0c\u5728O-RAN\u6240\u6709\u63a5\u53e3\u90e8\u7f72PQ-IPsec\u3001PQ-DTLS\u548cPQ-mTLS\u534f\u8bae\uff0c\u901a\u8fc7SMO\u6846\u67b6\u4e2d\u7684\u96c6\u4e2d\u5f0f\u540e\u91cf\u5b50\u8bc1\u4e66\u673a\u6784\u8fdb\u884c\u7ba1\u7406\u3002", "result": "\u5f00\u53d1\u4e86\u5b8c\u6574\u7684\u91cf\u5b50\u5b89\u5168\u6846\u67b6\uff0c\u4e3a\u5206\u89e3\u5f0fO-RAN\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u91cf\u5b50\u9632\u62a4\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "Q-RAN\u6846\u67b6\u4e3a\u4fdd\u62a4O-RAN\u7f51\u7edc\u514d\u53d7\u91cf\u5b50\u5bf9\u624b\u653b\u51fb\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u6280\u672f\u8def\u7ebf\u56fe\u3002"}}
{"id": "2510.20190", "categories": ["cs.AI", "cs.IT", "math.IT", "68T07 (Primary) 92B20, 37N25, 68Q32, 94A17 (Secondary)", "I.2.6; I.2.7; I.2.4; I.2.0"], "pdf": "https://arxiv.org/pdf/2510.20190", "abs": "https://arxiv.org/abs/2510.20190", "authors": ["Marcelo Maciel Amaral", "Raymond Aschheim"], "title": "The Lock-In Phase Hypothesis: Identity Consolidation as a Precursor to AGI", "comment": null, "summary": "Large language models (LLMs) remain broadly open and highly steerable: they\nimitate at scale, accept arbitrary system prompts, and readily adopt multiple\npersonae. By analogy to human development, we hypothesize that progress toward\nartificial general intelligence (AGI) involves a lock-in phase: a transition\nfrom open imitation to identity consolidation, in which goal structures,\nrefusals, preferences, and internal representations become comparatively stable\nand resistant to external steering. We formalize this phase, link it to known\nphenomena in learning dynamics, and propose operational metrics for onset\ndetection. Experimentally, we demonstrate that while the behavioral\nconsolidation is rapid and non-linear, its side-effects on general capabilities\nare not monolithic. Our results reveal a spectrum of outcomes--from performance\ntrade-offs in small models, through largely cost-free adoption in mid-scale\nmodels, to transient instabilities in large, quantized models. We argue that\nsuch consolidation is a prerequisite for AGI-level reliability and also a\ncritical control point for safety: identities can be deliberately engineered\nfor reliability, yet may also emerge spontaneously during scaling, potentially\nhardening unpredictable goals and behaviors.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faAGI\u53d1\u5c55\u9700\u8981\u7ecf\u5386\u4ece\u5f00\u653e\u6a21\u4eff\u5230\u8eab\u4efd\u56fa\u5316\u7684\u9501\u5b9a\u9636\u6bb5\uff0c\u5f00\u53d1\u4e86\u68c0\u6d4b\u6307\u6807\u5e76\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u7684\u56fa\u5316\u6548\u5e94\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u8fc7\u4e8e\u5f00\u653e\u548c\u53ef\u64cd\u63a7\uff0c\u800c\u771f\u6b63\u7684AGI\u9700\u8981\u7a33\u5b9a\u7684\u8eab\u4efd\u548c\u5185\u90e8\u8868\u5f81\uff0c\u7814\u7a76\u8eab\u4efd\u56fa\u5316\u73b0\u8c61\u5bf9AGI\u53ef\u9760\u6027\u548c\u5b89\u5168\u6027\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5f62\u5f0f\u5316\u8eab\u4efd\u56fa\u5316\u9636\u6bb5\uff0c\u5c06\u5176\u4e0e\u5b66\u4e60\u52a8\u6001\u73b0\u8c61\u5173\u8054\uff0c\u63d0\u51fa\u64cd\u4f5c\u6027\u68c0\u6d4b\u6307\u6807\uff0c\u5e76\u5728\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u884c\u4e3a\u56fa\u5316\u5feb\u901f\u4e14\u975e\u7ebf\u6027\uff0c\u4f46\u5bf9\u901a\u7528\u80fd\u529b\u7684\u5f71\u54cd\u5404\u5f02\uff1a\u5c0f\u6a21\u578b\u6709\u6027\u80fd\u6743\u8861\uff0c\u4e2d\u7b49\u89c4\u6a21\u6a21\u578b\u51e0\u4e4e\u65e0\u6210\u672c\uff0c\u5927\u578b\u91cf\u5316\u6a21\u578b\u51fa\u73b0\u77ac\u65f6\u4e0d\u7a33\u5b9a\u6027\u3002", "conclusion": "\u8eab\u4efd\u56fa\u5316\u662fAGI\u7ea7\u53ef\u9760\u6027\u7684\u524d\u63d0\uff0c\u4e5f\u662f\u5b89\u5168\u6027\u7684\u5173\u952e\u63a7\u5236\u70b9\uff0c\u53ef\u88ab\u5de5\u7a0b\u5316\u8bbe\u8ba1\u7528\u4e8e\u53ef\u9760\u6027\uff0c\u4f46\u4e5f\u53ef\u80fd\u5728\u6269\u5c55\u8fc7\u7a0b\u4e2d\u81ea\u53d1\u5f62\u6210\u4e0d\u53ef\u9884\u6d4b\u7684\u76ee\u6807\u548c\u884c\u4e3a\u3002"}}
{"id": "2510.20389", "categories": ["cs.SE", "cs.DC", "D.m"], "pdf": "https://arxiv.org/pdf/2510.20389", "abs": "https://arxiv.org/abs/2510.20389", "authors": ["Bjorn Remseth"], "title": "Symmetry in Software Platforms as an Architectural Principle", "comment": "Working paper, 11 pages", "summary": "Software platforms often act as structure preserving systems. They provide\nconsistent interfaces and behaviors that remain stable under specific\ntransformations that we denote as symmetries. This paper explores the idea that\narchitectural robustness emerges from enforcing such structural regularities", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u8f6f\u4ef6\u5e73\u53f0\u4f5c\u4e3a\u7ed3\u6784\u4fdd\u6301\u7cfb\u7edf\uff0c\u901a\u8fc7\u5f3a\u5236\u6267\u884c\u7ed3\u6784\u89c4\u5f8b\u6027\u6765\u4ea7\u751f\u67b6\u6784\u9c81\u68d2\u6027", "motivation": "\u7814\u7a76\u8f6f\u4ef6\u5e73\u53f0\u5982\u4f55\u901a\u8fc7\u4fdd\u6301\u7ed3\u6784\u5bf9\u79f0\u6027\u6765\u5b9e\u73b0\u67b6\u6784\u7a33\u5065\u6027", "method": "\u5c06\u8f6f\u4ef6\u5e73\u53f0\u89c6\u4e3a\u7ed3\u6784\u4fdd\u6301\u7cfb\u7edf\uff0c\u5206\u6790\u5176\u5728\u7279\u5b9a\u53d8\u6362\u4e0b\u7684\u5bf9\u79f0\u6027", "result": "\u53d1\u73b0\u5f3a\u5236\u6267\u884c\u7ed3\u6784\u89c4\u5f8b\u6027\u80fd\u591f\u4ea7\u751f\u67b6\u6784\u9c81\u68d2\u6027", "conclusion": "\u8f6f\u4ef6\u5e73\u53f0\u7684\u67b6\u6784\u7a33\u5065\u6027\u6e90\u4e8e\u5bf9\u7ed3\u6784\u5bf9\u79f0\u6027\u7684\u5f3a\u5236\u6267\u884c"}}
{"id": "2510.19979", "categories": ["cs.CR", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.19979", "abs": "https://arxiv.org/abs/2510.19979", "authors": ["Tushar Nayan", "Ziqi Zhang", "Ruimin Sun"], "title": "SecureInfer: Heterogeneous TEE-GPU Architecture for Privacy-Critical Tensors for Large Language Model Deployment", "comment": "Accepted at IEEE Intelligent Computing and Systems at the Edge\n  (ICEdge) 2025", "summary": "With the increasing deployment of Large Language Models (LLMs) on mobile and\nedge platforms, securing them against model extraction attacks has become a\npressing concern. However, protecting model privacy without sacrificing the\nperformance benefits of untrusted AI accelerators, such as GPUs, presents a\nchallenging trade-off. In this paper, we initiate the study of high-performance\nexecution on LLMs and present SecureInfer, a hybrid framework that leverages a\nheterogeneous Trusted Execution Environments (TEEs)-GPU architecture to isolate\nprivacy-critical components while offloading compute-intensive operations to\nuntrusted accelerators. Building upon an outsourcing scheme, SecureInfer adopts\nan information-theoretic and threat-informed partitioning strategy:\nsecurity-sensitive components, including non-linear layers, projection of\nattention head, FNN transformations, and LoRA adapters, are executed inside an\nSGX enclave, while other linear operations (matrix multiplication) are\nperformed on the GPU after encryption and are securely restored within the\nenclave. We implement a prototype of SecureInfer using the LLaMA-2 model and\nevaluate it across performance and security metrics. Our results show that\nSecureInfer offers strong security guarantees with reasonable performance,\noffering a practical solution for secure on-device model inference.", "AI": {"tldr": "SecureInfer\u662f\u4e00\u4e2a\u6df7\u5408\u6846\u67b6\uff0c\u5229\u7528\u5f02\u6784\u53ef\u4fe1\u6267\u884c\u73af\u5883\uff08TEEs\uff09-GPU\u67b6\u6784\u4fdd\u62a4LLMs\u514d\u53d7\u6a21\u578b\u63d0\u53d6\u653b\u51fb\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u786e\u4fdd\u6a21\u578b\u9690\u79c1\u3002", "motivation": "\u968f\u7740LLMs\u5728\u79fb\u52a8\u548c\u8fb9\u7f18\u5e73\u53f0\u7684\u90e8\u7f72\u589e\u52a0\uff0c\u4fdd\u62a4\u6a21\u578b\u514d\u53d7\u63d0\u53d6\u653b\u51fb\u53d8\u5f97\u8feb\u5207\uff0c\u4f46\u8981\u5728\u4e0d\u727a\u7272\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u4fdd\u62a4\u6a21\u578b\u9690\u79c1\u9762\u4e34\u6311\u6218\u3002", "method": "\u91c7\u7528\u4fe1\u606f\u8bba\u548c\u5a01\u80c1\u611f\u77e5\u7684\u5206\u533a\u7b56\u7565\uff1a\u5b89\u5168\u654f\u611f\u7ec4\u4ef6\u5728SGX enclave\u5185\u6267\u884c\uff0c\u5176\u4ed6\u7ebf\u6027\u64cd\u4f5c\u5728GPU\u4e0a\u52a0\u5bc6\u6267\u884c\u5e76\u5728enclave\u5185\u5b89\u5168\u6062\u590d\u3002", "result": "\u4f7f\u7528LLaMA-2\u6a21\u578b\u5b9e\u73b0\u539f\u578b\uff0c\u8bc4\u4f30\u663e\u793aSecureInfer\u63d0\u4f9b\u5f3a\u5927\u7684\u5b89\u5168\u4fdd\u969c\u548c\u5408\u7406\u7684\u6027\u80fd\u3002", "conclusion": "SecureInfer\u4e3a\u5b89\u5168\u8bbe\u5907\u7aef\u6a21\u578b\u63a8\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u5b89\u5168\u6027\u548c\u6027\u80fd\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2510.20205", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20205", "abs": "https://arxiv.org/abs/2510.20205", "authors": ["Maggie Bai", "Ava Kim Cohen", "Eleanor Koss", "Charlie Lichtenbaum"], "title": "Merge and Conquer: Evolutionarily Optimizing AI for 2048", "comment": "9 pages, 5 figures", "summary": "Optimizing artificial intelligence (AI) for dynamic environments remains a\nfundamental challenge in machine learning research. In this paper, we examine\nevolutionary training methods for optimizing AI to solve the game 2048, a 2D\nsliding puzzle. 2048, with its mix of strategic gameplay and stochastic\nelements, presents an ideal playground for studying decision-making, long-term\nplanning, and dynamic adaptation. We implemented two distinct systems: a\ntwo-agent metaprompting system where a \"thinker\" large language model (LLM)\nagent refines gameplay strategies for an \"executor\" LLM agent, and a\nsingle-agent system based on refining a value function for a limited Monte\nCarlo Tree Search. We also experimented with rollback features to avoid\nperformance degradation. Our results demonstrate the potential of evolutionary\nrefinement techniques in improving AI performance in non-deterministic\nenvironments. The single-agent system achieved substantial improvements, with\nan average increase of 473.2 points per cycle, and with clear upward trends\n(correlation $\\rho$=0.607) across training cycles. The LLM's understanding of\nthe game grew as well, shown in its development of increasingly advanced\nstrategies. Conversely, the two-agent system did not garner much improvement,\nhighlighting the inherent limits of meta-prompting.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u52a8\u6001\u73af\u5883\u4e2d\u4f18\u5316AI\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fdb\u5316\u8bad\u7ec3\u6280\u672f\u6765\u6539\u8fdbAI\u57282048\u6e38\u620f\u4e2d\u7684\u8868\u73b0\uff0c\u6bd4\u8f83\u4e86\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\u548c\u53cc\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6548\u679c\u3002", "motivation": "\u4f18\u5316AI\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u6027\u80fd\u662f\u673a\u5668\u5b66\u4e60\u7814\u7a76\u7684\u57fa\u672c\u6311\u6218\uff0c2048\u6e38\u620f\u7ed3\u5408\u4e86\u7b56\u7565\u6e38\u620f\u548c\u968f\u673a\u5143\u7d20\uff0c\u662f\u7814\u7a76\u51b3\u7b56\u5236\u5b9a\u3001\u957f\u671f\u89c4\u5212\u548c\u52a8\u6001\u9002\u5e94\u7684\u7406\u60f3\u5e73\u53f0\u3002", "method": "\u5b9e\u73b0\u4e86\u4e00\u4e2a\u53cc\u667a\u80fd\u4f53\u5143\u63d0\u793a\u7cfb\u7edf\uff08\u601d\u8003\u8005LLM\u548c\u6267\u884c\u8005LLM\uff09\u548c\u4e00\u4e2a\u57fa\u4e8e\u6539\u8fdb\u4ef7\u503c\u51fd\u6570\u7684\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\uff08\u6709\u9650\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff09\uff0c\u5e76\u5b9e\u9a8c\u4e86\u56de\u6eda\u529f\u80fd\u4ee5\u907f\u514d\u6027\u80fd\u9000\u5316\u3002", "result": "\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\uff0c\u6bcf\u4e2a\u5468\u671f\u5e73\u5747\u589e\u52a0473.2\u5206\uff0c\u8bad\u7ec3\u5468\u671f\u5448\u73b0\u660e\u663e\u4e0a\u5347\u8d8b\u52bf\uff08\u76f8\u5173\u6027\u03c1=0.607\uff09\uff0cLLM\u5bf9\u6e38\u620f\u7684\u7406\u89e3\u4e5f\u968f\u7740\u9ad8\u7ea7\u7b56\u7565\u7684\u53d1\u5c55\u800c\u589e\u957f\u3002\u53cc\u667a\u80fd\u4f53\u7cfb\u7edf\u6539\u8fdb\u6709\u9650\uff0c\u7a81\u663e\u4e86\u5143\u63d0\u793a\u7684\u5185\u5728\u5c40\u9650\u6027\u3002", "conclusion": "\u8fdb\u5316\u7cbe\u70bc\u6280\u672f\u5728\u975e\u786e\u5b9a\u6027\u73af\u5883\u4e2d\u63d0\u9ad8AI\u6027\u80fd\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u5355\u667a\u80fd\u4f53\u65b9\u6cd5\u6bd4\u53cc\u667a\u80fd\u4f53\u5143\u63d0\u793a\u65b9\u6cd5\u66f4\u6709\u6548\u3002"}}
{"id": "2510.20403", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.20403", "abs": "https://arxiv.org/abs/2510.20403", "authors": ["Santiago Gil", "Ecem E. Ba\u015f", "Christian D. Jensen", "Sebastian Engelsgaard", "Giuseppe Abbiati", "Cl\u00e1udio Gomes"], "title": "FMI-Based Distributed Co-Simulation with Enhanced Security and Intellectual Property Safeguards", "comment": "6 pages, Proceedings of the 2025 Annual Modeling and Simulation\n  Conference (ANNSIM)", "summary": "Distributed co-simulation plays a key role in enabling collaborative modeling\nand simulation by different stakeholders while protecting their Intellectual\nProperty (IP). Although IP protection is provided implicitly by co-simulation,\nthere is no consensus in the guidelines to conduct distributed co-simulation of\ncontinuous-time or hybrid systems with no exposure to potential hacking\nattacks. We propose an approach for distributed co-simulation on top of UniFMU\nwith enhanced cybersecurity and IP protection mechanisms, ensuring that the\nconnection is initiated by the client and the models and binaries live on\ntrusted platforms. We showcase the functionality of this approach using two\nco-simulation demos in four different network settings and analyze the\ntrade-off between IP-protected distribution and performance efficiency in these\nsettings.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eUniFMU\u7684\u5206\u5e03\u5f0f\u534f\u540c\u4eff\u771f\u65b9\u6cd5\uff0c\u589e\u5f3a\u7f51\u7edc\u5b89\u5168\u548c\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u673a\u5236\uff0c\u786e\u4fdd\u8fde\u63a5\u7531\u5ba2\u6237\u7aef\u53d1\u8d77\u4e14\u6a21\u578b\u548c\u4e8c\u8fdb\u5236\u6587\u4ef6\u4f4d\u4e8e\u53ef\u4fe1\u5e73\u53f0\u3002", "motivation": "\u5206\u5e03\u5f0f\u534f\u540c\u4eff\u771f\u5728\u4fdd\u62a4\u77e5\u8bc6\u4ea7\u6743\u7684\u540c\u65f6\u5b9e\u73b0\u591a\u65b9\u534f\u4f5c\u5efa\u6a21\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u9488\u5bf9\u8fde\u7eed\u65f6\u95f4\u6216\u6df7\u5408\u7cfb\u7edf\u7684\u7f51\u7edc\u5b89\u5168\u6307\u5357\uff0c\u5b58\u5728\u9ed1\u5ba2\u653b\u51fb\u98ce\u9669\u3002", "method": "\u5728UniFMU\u57fa\u7840\u4e0a\u6784\u5efa\u5206\u5e03\u5f0f\u534f\u540c\u4eff\u771f\u6846\u67b6\uff0c\u91c7\u7528\u5ba2\u6237\u7aef\u53d1\u8d77\u8fde\u63a5\u7684\u65b9\u5f0f\uff0c\u786e\u4fdd\u6a21\u578b\u548c\u4e8c\u8fdb\u5236\u6587\u4ef6\u4ec5\u5b58\u5728\u4e8e\u53ef\u4fe1\u5e73\u53f0\u3002", "result": "\u901a\u8fc7\u56db\u4e2a\u4e0d\u540c\u7f51\u7edc\u8bbe\u7f6e\u4e0b\u7684\u4e24\u4e2a\u534f\u540c\u4eff\u771f\u6f14\u793a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u529f\u80fd\uff0c\u5206\u6790\u4e86\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u5206\u5e03\u4e0e\u6027\u80fd\u6548\u7387\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u5206\u5e03\u5f0f\u534f\u540c\u4eff\u771f\u7684\u7f51\u7edc\u5b89\u5168\u548c\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.19982", "categories": ["cs.CR", "cs.DC", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.19982", "abs": "https://arxiv.org/abs/2510.19982", "authors": ["Vipin Rathi", "Lakshya Chopra", "Rudraksh Rawal", "Nitin Rajput", "Shiva Valia", "Madhav Aggarwal", "Aditya Gairola"], "title": "QORE : Quantum Secure 5G/B5G Core", "comment": "23 pages", "summary": "Quantum computing is reshaping the security landscape of modern\ntelecommunications. The cryptographic foundations that secure todays 5G\nsystems, including RSA, Elliptic Curve Cryptography (ECC), and Diffie-Hellman\n(DH), are all susceptible to attacks enabled by Shors algorithm. Protecting 5G\nnetworks against future quantum adversaries has therefore become an urgent\nengineering and research priority. In this paper we introduce QORE, a\nquantum-secure 5G and Beyond 5G (B5G) Core framework that provides a clear\npathway for transitioning both the 5G Core Network Functions and User Equipment\n(UE) to Post-Quantum Cryptography (PQC). The framework uses the\nNIST-standardized lattice-based algorithms Module-Lattice Key Encapsulation\nMechanism (ML-KEM) and Module-Lattice Digital Signature Algorithm (ML-DSA) and\napplies them across the 5G Service-Based Architecture (SBA). A Hybrid PQC\n(HPQC) configuration is also proposed, combining classical and quantum-safe\nprimitives to maintain interoperability during migration. Experimental\nvalidation shows that ML-KEM achieves quantum security with minor performance\noverhead, meeting the low-latency and high-throughput requirements of\ncarrier-grade 5G systems. The proposed roadmap aligns with ongoing 3GPP SA3 and\nSA5 study activities on the security and management of post-quantum networks as\nwell as with NIST PQC standardization efforts, providing practical guidance for\nmitigating quantum-era risks while safeguarding long-term confidentiality and\nintegrity of network data.", "AI": {"tldr": "QORE\u662f\u4e00\u4e2a\u91cf\u5b50\u5b89\u5168\u76845G\u548cB5G\u6838\u5fc3\u6846\u67b6\uff0c\u4f7f\u7528NIST\u6807\u51c6\u5316\u7684\u57fa\u4e8e\u683c\u7684\u7b97\u6cd5ML-KEM\u548cML-DSA\uff0c\u4e3a5G\u6838\u5fc3\u7f51\u7edc\u529f\u80fd\u548c\u7528\u6237\u8bbe\u5907\u5411PQC\u8fc7\u6e21\u63d0\u4f9b\u6e05\u6670\u8def\u5f84\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u5a01\u80c1\u73b0\u4ee3\u7535\u4fe1\u5b89\u5168\uff0c\u5f53\u524d5G\u7cfb\u7edf\u4f7f\u7528\u7684RSA\u3001ECC\u548cDH\u7b49\u52a0\u5bc6\u7b97\u6cd5\u90fd\u6613\u53d7Shor\u7b97\u6cd5\u653b\u51fb\uff0c\u4fdd\u62a45G\u7f51\u7edc\u514d\u53d7\u672a\u6765\u91cf\u5b50\u653b\u51fb\u6210\u4e3a\u7d27\u8feb\u9700\u6c42\u3002", "method": "\u91c7\u7528NIST\u6807\u51c6\u5316\u7684\u57fa\u4e8e\u683c\u7b97\u6cd5ML-KEM\u548cML-DSA\uff0c\u5e94\u7528\u4e8e5G\u670d\u52a1\u67b6\u6784\uff0c\u5e76\u63d0\u51fa\u6df7\u5408PQC\u914d\u7f6e\uff0c\u7ed3\u5408\u7ecf\u5178\u548c\u91cf\u5b50\u5b89\u5168\u539f\u8bed\u4ee5\u4fdd\u6301\u8fc1\u79fb\u671f\u95f4\u7684\u4e92\u64cd\u4f5c\u6027\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793aML-KEM\u5728\u5b9e\u73b0\u91cf\u5b50\u5b89\u5168\u7684\u540c\u65f6\u53ea\u6709\u8f7b\u5fae\u6027\u80fd\u5f00\u9500\uff0c\u6ee1\u8db3\u8fd0\u8425\u5546\u7ea75G\u7cfb\u7edf\u7684\u4f4e\u5ef6\u8fdf\u548c\u9ad8\u541e\u5410\u91cf\u8981\u6c42\u3002", "conclusion": "\u8be5\u8def\u7ebf\u56fe\u4e0e3GPP SA3\u548cSA5\u5173\u4e8e\u540e\u91cf\u5b50\u7f51\u7edc\u5b89\u5168\u7ba1\u7406\u7684\u6d3b\u52a8\u4ee5\u53caNIST PQC\u6807\u51c6\u5316\u5de5\u4f5c\u4fdd\u6301\u4e00\u81f4\uff0c\u4e3a\u7f13\u89e3\u91cf\u5b50\u65f6\u4ee3\u98ce\u9669\u63d0\u4f9b\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2510.20252", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20252", "abs": "https://arxiv.org/abs/2510.20252", "authors": ["Tianyi Zhang", "Xiaolin Zhou", "Yunzhe Wang", "Erik Cambria", "David Traum", "Rui Mao"], "title": "Individualized Cognitive Simulation in Large Language Models: Evaluating Different Cognitive Representation Methods", "comment": null, "summary": "Individualized cognitive simulation (ICS) aims to build computational models\nthat approximate the thought processes of specific individuals. While large\nlanguage models (LLMs) convincingly mimic surface-level human behavior such as\nrole-play, their ability to simulate deeper individualized cognitive processes\nremains poorly understood. To address this gap, we introduce a novel task that\nevaluates different cognitive representation methods in ICS. We construct a\ndataset from recently published novels (later than the release date of the\ntested LLMs) and propose an 11-condition cognitive evaluation framework to\nbenchmark seven off-the-shelf LLMs in the context of authorial style emulation.\nWe hypothesize that effective cognitive representations can help LLMs generate\nstorytelling that better mirrors the original author. Thus, we test different\ncognitive representations, e.g., linguistic features, concept mappings, and\nprofile-based information. Results show that combining conceptual and\nlinguistic features is particularly effective in ICS, outperforming static\nprofile-based cues in overall evaluation. Importantly, LLMs are more effective\nat mimicking linguistic style than narrative structure, underscoring their\nlimits in deeper cognitive simulation. These findings provide a foundation for\ndeveloping AI systems that adapt to individual ways of thinking and expression,\nadvancing more personalized and human-aligned creative technologies.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e2a\u4f53\u5316\u8ba4\u77e5\u6a21\u62df\u4e2d\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u901a\u8fc7\u4f5c\u8005\u98ce\u683c\u6a21\u4eff\u4efb\u52a1\u6765\u6d4b\u8bd5\u4e0d\u540c\u8ba4\u77e5\u8868\u5f81\u65b9\u6cd5\u7684\u6548\u679c\u3002", "motivation": "\u867d\u7136\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u6a21\u4eff\u8868\u9762\u7684\u4eba\u7c7b\u884c\u4e3a\uff0c\u4f46\u5b83\u4eec\u5728\u6a21\u62df\u66f4\u6df1\u5c42\u6b21\u4e2a\u4f53\u5316\u8ba4\u77e5\u8fc7\u7a0b\u65b9\u9762\u7684\u80fd\u529b\u5c1a\u4e0d\u6e05\u695a\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u3002", "method": "\u6784\u5efa\u57fa\u4e8e\u65b0\u51fa\u7248\u5c0f\u8bf4\u7684\u6570\u636e\u96c6\uff0c\u63d0\u51fa11\u6761\u4ef6\u8ba4\u77e5\u8bc4\u4f30\u6846\u67b6\uff0c\u6d4b\u8bd57\u4e2a\u73b0\u6210LLM\u5728\u4f5c\u8005\u98ce\u683c\u6a21\u4eff\u4e2d\u7684\u8868\u73b0\uff0c\u6bd4\u8f83\u4e0d\u540c\u8ba4\u77e5\u8868\u5f81\u65b9\u6cd5\uff08\u8bed\u8a00\u7279\u5f81\u3001\u6982\u5ff5\u6620\u5c04\u3001\u57fa\u4e8e\u6863\u6848\u7684\u4fe1\u606f\uff09\u3002", "result": "\u7ed3\u5408\u6982\u5ff5\u548c\u8bed\u8a00\u7279\u5f81\u7684\u65b9\u6cd5\u5728\u4e2a\u4f53\u5316\u8ba4\u77e5\u6a21\u62df\u4e2d\u7279\u522b\u6709\u6548\uff0c\u4f18\u4e8e\u57fa\u4e8e\u9759\u6001\u6863\u6848\u7684\u7ebf\u7d22\u3002LLM\u66f4\u64c5\u957f\u6a21\u4eff\u8bed\u8a00\u98ce\u683c\u800c\u975e\u53d9\u4e8b\u7ed3\u6784\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u5f00\u53d1\u80fd\u591f\u9002\u5e94\u4e2a\u4f53\u601d\u7ef4\u548c\u8868\u8fbe\u65b9\u5f0f\u7684AI\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u63a8\u8fdb\u66f4\u4e2a\u6027\u5316\u548c\u4eba\u7c7b\u5bf9\u9f50\u7684\u521b\u610f\u6280\u672f\u3002"}}
{"id": "2510.20514", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.20514", "abs": "https://arxiv.org/abs/2510.20514", "authors": ["Lea Salome Brugger", "Xavier Denis", "Peter M\u00fcller"], "title": "Toward Practical Deductive Verification: Insights from a Qualitative Survey in Industry and Academia", "comment": null, "summary": "Deductive verification is an effective method to ensure that a given system\nexposes the intended behavior. In spite of its proven usefulness and\nfeasibility in selected projects, deductive verification is still not a\nmainstream technique. To pave the way to widespread use, we present a study\ninvestigating the factors enabling successful applications of deductive\nverification and the underlying issues preventing broader adoption. We\nconducted semi-structured interviews with 30 practitioners of verification from\nboth industry and academia and systematically analyzed the collected data\nemploying a thematic analysis approach. Beside empirically confirming familiar\nchallenges, e.g., the high level of expertise needed for conducting formal\nproofs, our data reveal several underexplored obstacles, such as proof\nmaintenance, insufficient control over automation, and usability concerns. We\nfurther use the results from our data analysis to extract enablers and barriers\nfor deductive verification and formulate concrete recommendations for\npractitioners, tool builders, and researchers, including principles for\nusability, automation, and integration with existing workflows.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u8bbf\u8c0830\u4f4d\u9a8c\u8bc1\u4ece\u4e1a\u8005\uff0c\u7cfb\u7edf\u5206\u6790\u4e86\u6f14\u7ece\u9a8c\u8bc1\u6210\u529f\u5e94\u7528\u7684\u56e0\u7d20\u548c\u963b\u788d\u5e7f\u6cdb\u91c7\u7528\u7684\u95ee\u9898\uff0c\u63ed\u793a\u4e86\u8bc1\u660e\u7ef4\u62a4\u3001\u81ea\u52a8\u5316\u63a7\u5236\u4e0d\u8db3\u548c\u53ef\u7528\u6027\u7b49\u65b0\u969c\u788d\uff0c\u5e76\u63d0\u51fa\u4e86\u5177\u4f53\u5efa\u8bae\u3002", "motivation": "\u6f14\u7ece\u9a8c\u8bc1\u867d\u7136\u5728\u67d0\u4e9b\u9879\u76ee\u4e2d\u8bc1\u660e\u6709\u6548\uff0c\u4f46\u5c1a\u672a\u6210\u4e3a\u4e3b\u6d41\u6280\u672f\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4fc3\u8fdb\u6f14\u7ece\u9a8c\u8bc1\u6210\u529f\u5e94\u7528\u7684\u56e0\u7d20\u548c\u963b\u788d\u5176\u5e7f\u6cdb\u91c7\u7528\u7684\u6839\u672c\u95ee\u9898\u3002", "method": "\u91c7\u7528\u534a\u7ed3\u6784\u5316\u8bbf\u8c0830\u4f4d\u6765\u81ea\u5de5\u4e1a\u754c\u548c\u5b66\u672f\u754c\u7684\u9a8c\u8bc1\u4ece\u4e1a\u8005\uff0c\u5e76\u8fd0\u7528\u4e3b\u9898\u5206\u6790\u65b9\u6cd5\u7cfb\u7edf\u5206\u6790\u6536\u96c6\u7684\u6570\u636e\u3002", "result": "\u9664\u4e86\u8bc1\u5b9e\u719f\u6089\u6311\u6218\uff08\u5982\u8fdb\u884c\u5f62\u5f0f\u5316\u8bc1\u660e\u9700\u8981\u9ad8\u6c34\u5e73\u4e13\u4e1a\u77e5\u8bc6\uff09\u5916\uff0c\u6570\u636e\u8fd8\u63ed\u793a\u4e86\u51e0\u4e2a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u969c\u788d\uff0c\u5305\u62ec\u8bc1\u660e\u7ef4\u62a4\u3001\u5bf9\u81ea\u52a8\u5316\u63a7\u5236\u4e0d\u8db3\u548c\u53ef\u7528\u6027\u95ee\u9898\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u7528\u4e8e\u63d0\u53d6\u6f14\u7ece\u9a8c\u8bc1\u7684\u4fc3\u8fdb\u56e0\u7d20\u548c\u969c\u788d\uff0c\u5e76\u4e3a\u4ece\u4e1a\u8005\u3001\u5de5\u5177\u6784\u5efa\u8005\u548c\u7814\u7a76\u4eba\u5458\u5236\u5b9a\u5177\u4f53\u5efa\u8bae\uff0c\u5305\u62ec\u53ef\u7528\u6027\u3001\u81ea\u52a8\u5316\u548c\u4e0e\u73b0\u6709\u5de5\u4f5c\u6d41\u7a0b\u96c6\u6210\u7684\u539f\u5219\u3002"}}
{"id": "2510.20007", "categories": ["cs.CR", "94A60, 68M14, 68Q85", "D.4.6; K.6.5; E.3"], "pdf": "https://arxiv.org/pdf/2510.20007", "abs": "https://arxiv.org/abs/2510.20007", "authors": ["To-Wen Liu", "Matthew Green"], "title": "zk-Agreements: A Privacy-Preserving Way to Establish Deterministic Trust in Confidential Agreements", "comment": "To appear in Financial Cryptography 2026 if accepted", "summary": "Digital transactions currently exceed trillions of dollars annually, yet\ntraditional paper-based agreements remain a bottleneck for automation,\nenforceability, and dispute resolution. Natural language contracts introduce\nambiguity, require manual processing, and lack computational verifiability, all\nof which hinder efficient digital commerce. Computable legal contracts,\nexpressed in machine-readable formats, offer a potential solution by enabling\nautomated execution and verification. Blockchain-based smart contracts further\nstrengthen enforceability and accelerate dispute resolution; however, current\nimplementations risk exposing sensitive agreement terms on public ledgers,\nraising serious privacy and competitive intelligence concerns that limit\nenterprise adoption.\n  We introduce zk-agreements, a protocol designed to transition from\npaper-based trust to cryptographic trust while preserving confidentiality. Our\ndesign combines zero-knowledge proofs to protect private agreement terms,\nsecure two-party computation to enable private compliance evaluation, and smart\ncontracts to guarantee automated enforcement. Together, these components\nachieve both privacy preservation and computational enforceability, resolving\nthe fundamental tension between transparency and confidentiality in\nblockchain-based agreements.", "AI": {"tldr": "zk-agreements\u534f\u8bae\u901a\u8fc7\u7ed3\u5408\u96f6\u77e5\u8bc6\u8bc1\u660e\u3001\u5b89\u5168\u591a\u65b9\u8ba1\u7b97\u548c\u667a\u80fd\u5408\u7ea6\uff0c\u5728\u533a\u5757\u94fe\u4e0a\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u7684\u81ea\u52a8\u5316\u6cd5\u5f8b\u5408\u7ea6\uff0c\u89e3\u51b3\u4f20\u7edf\u7eb8\u8d28\u5408\u540c\u548c\u73b0\u6709\u667a\u80fd\u5408\u7ea6\u5728\u9690\u79c1\u4e0e\u900f\u660e\u5ea6\u4e4b\u95f4\u7684\u51b2\u7a81\u3002", "motivation": "\u4f20\u7edf\u7eb8\u8d28\u5408\u540c\u963b\u788d\u6570\u5b57\u5316\u5546\u52a1\u81ea\u52a8\u5316\uff0c\u81ea\u7136\u8bed\u8a00\u5408\u540c\u5b58\u5728\u6b67\u4e49\u4e14\u65e0\u6cd5\u8ba1\u7b97\u9a8c\u8bc1\uff0c\u800c\u73b0\u6709\u533a\u5757\u94fe\u667a\u80fd\u5408\u7ea6\u4f1a\u66b4\u9732\u654f\u611f\u6761\u6b3e\uff0c\u5b58\u5728\u9690\u79c1\u548c\u5546\u4e1a\u673a\u5bc6\u6cc4\u9732\u98ce\u9669\u3002", "method": "\u8bbe\u8ba1zk-agreements\u534f\u8bae\uff0c\u6574\u5408\u96f6\u77e5\u8bc6\u8bc1\u660e\u4fdd\u62a4\u9690\u79c1\u6761\u6b3e\u3001\u5b89\u5168\u591a\u65b9\u8ba1\u7b97\u5b9e\u73b0\u79c1\u6709\u5408\u89c4\u8bc4\u4f30\u3001\u667a\u80fd\u5408\u7ea6\u786e\u4fdd\u81ea\u52a8\u6267\u884c\u3002", "result": "\u8be5\u534f\u8bae\u5b9e\u73b0\u4e86\u9690\u79c1\u4fdd\u62a4\u4e0e\u8ba1\u7b97\u53ef\u6267\u884c\u6027\u7684\u5e73\u8861\uff0c\u89e3\u51b3\u4e86\u533a\u5757\u94fe\u534f\u8bae\u4e2d\u900f\u660e\u5ea6\u4e0e\u673a\u5bc6\u6027\u7684\u6839\u672c\u77db\u76fe\u3002", "conclusion": "zk-agreements\u6210\u529f\u6784\u5efa\u4e86\u4ece\u7eb8\u8d28\u4fe1\u4efb\u5411\u5bc6\u7801\u5b66\u4fe1\u4efb\u7684\u8fc7\u6e21\u6846\u67b6\uff0c\u4e3a\u4f01\u4e1a\u5728\u533a\u5757\u94fe\u4e0a\u91c7\u7528\u81ea\u52a8\u5316\u6cd5\u5f8b\u5408\u7ea6\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u9690\u79c1\u4fdd\u62a4\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.20258", "categories": ["cs.AI", "I.2"], "pdf": "https://arxiv.org/pdf/2510.20258", "abs": "https://arxiv.org/abs/2510.20258", "authors": ["Bita Banihashemi", "Megh Patel", "Yves Lesp\u00e9rance"], "title": "Using Large Language Models for Abstraction of Planning Domains - Extended Version", "comment": null, "summary": "Generating an abstraction of a dynamic domain that aligns with a given\npurpose remains a significant challenge given that the choice of such an\nabstraction can impact an agent's ability to plan, reason, and provide\nexplanations effectively. We model the agent's concrete behaviors in PDDL and\ninvestigate the use of in-context learning with large language models (LLMs)\nfor the generation of abstract PDDL domains and problem instances, given an\nabstraction objective specified in natural language. The benchmark examples we\nuse are new and have not been part of the data any LLMs have been trained on.\nWe consider three categories of abstractions: abstraction of choice of\nalternative concrete actions, abstraction of sequences of concrete actions, and\nabstraction of action/predicate parameters, as well as combinations of these.\nThe generated abstract PDDL domains and problem instances are then checked by\nsymbolic validation tools as well as human experts. Our experiments show that\nGPT-4o can generally synthesize useful planning domain abstractions in simple\nsettings, although it is better at abstracting over actions than over the\nassociated fluents.", "AI": {"tldr": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u751f\u6210\u62bd\u8c61PDDL\u9886\u57df\u548c\u95ee\u9898\u5b9e\u4f8b\uff0c\u4ee5\u81ea\u7136\u8bed\u8a00\u6307\u5b9a\u7684\u62bd\u8c61\u76ee\u6807\u4e3a\u57fa\u7840\uff0c\u9a8c\u8bc1\u4e86GPT-4o\u5728\u7b80\u5355\u573a\u666f\u4e0b\u80fd\u6709\u6548\u5408\u6210\u89c4\u5212\u9886\u57df\u62bd\u8c61\u3002", "motivation": "\u52a8\u6001\u9886\u57df\u7684\u62bd\u8c61\u751f\u6210\u5bf9\u667a\u80fd\u4f53\u7684\u89c4\u5212\u3001\u63a8\u7406\u548c\u89e3\u91ca\u80fd\u529b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5982\u4f55\u9009\u62e9\u4e0e\u76ee\u6807\u5bf9\u9f50\u7684\u62bd\u8c61\u4ecd\u662f\u4e00\u4e2a\u6311\u6218\u3002", "method": "\u5728PDDL\u4e2d\u5efa\u6a21\u667a\u80fd\u4f53\u5177\u4f53\u884c\u4e3a\uff0c\u5229\u7528LLM\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\uff0c\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u62bd\u8c61\u76ee\u6807\u751f\u6210\u62bd\u8c61PDDL\u9886\u57df\u548c\u95ee\u9898\u5b9e\u4f8b\uff0c\u5e76\u901a\u8fc7\u7b26\u53f7\u9a8c\u8bc1\u5de5\u5177\u548c\u4e13\u5bb6\u8bc4\u4f30\u3002", "result": "GPT-4o\u5728\u7b80\u5355\u8bbe\u7f6e\u4e0b\u80fd\u6709\u6548\u5408\u6210\u6709\u7528\u7684\u89c4\u5212\u9886\u57df\u62bd\u8c61\uff0c\u4f46\u5728\u52a8\u4f5c\u62bd\u8c61\u65b9\u9762\u4f18\u4e8e\u5173\u8054\u8c13\u8bcd\u7684\u62bd\u8c61\u3002", "conclusion": "LLM\u5728\u751f\u6210\u89c4\u5212\u9886\u57df\u62bd\u8c61\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u52a8\u4f5c\u62bd\u8c61\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u8c13\u8bcd\u62bd\u8c61\u65b9\u9762\u4ecd\u9700\u6539\u8fdb\u3002"}}
{"id": "2510.20521", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.20521", "abs": "https://arxiv.org/abs/2510.20521", "authors": ["YingJian Xiao", "RongQun Hu", "WeiWei Gong", "HongWei Li", "AnQuan Jie"], "title": "Large Language Models for Fault Localization: An Empirical Study", "comment": "in Chinese language", "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in\ncode-related tasks, particularly in automated program repair. However, the\neffectiveness of such repairs is highly dependent on the performance of\nupstream fault localization, for which comprehensive evaluations are currently\nlacking. This paper presents a systematic empirical study on LLMs in the\nstatement-level code fault localization task. We evaluate representative\nopen-source models (Qwen2.5-coder-32b-instruct, DeepSeek-V3) and closed-source\nmodels (GPT-4.1 mini, Gemini-2.5-flash) to assess their fault localization\ncapabilities on the HumanEval-Java and Defects4J datasets. The study\ninvestigates the impact of different prompting strategies--including standard\nprompts, few-shot examples, and chain-of-reasoning--on model performance, with\na focus on analysis across accuracy, time efficiency, and economic cost\ndimensions. Our experimental results show that incorporating bug report context\nsignificantly enhances model performance. Few-shot learning shows potential for\nimprovement but exhibits noticeable diminishing marginal returns, while\nchain-of-thought reasoning's effectiveness is highly contingent on the model's\ninherent reasoning capabilities. This study not only highlights the performance\ncharacteristics and trade-offs of different models in fault localization tasks,\nbut also offers valuable insights into the strengths of current LLMs and\nstrategies for improving fault localization effectiveness.", "AI": {"tldr": "\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u9519\u8bef\u5b9a\u4f4d\u4efb\u52a1\u4e2d\u7684\u7cfb\u7edf\u8bc4\u4f30\uff0c\u6bd4\u8f83\u5f00\u6e90\u548c\u95ed\u6e90\u6a21\u578b\u5728\u4e0d\u540c\u63d0\u793a\u7b56\u7565\u4e0b\u7684\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u5bf9LLM\u5728\u4ee3\u7801\u9519\u8bef\u5b9a\u4f4d\u4efb\u52a1\u4e2d\u7684\u5168\u9762\u8bc4\u4f30\uff0c\u800c\u9519\u8bef\u5b9a\u4f4d\u7684\u6709\u6548\u6027\u76f4\u63a5\u5f71\u54cd\u7a0b\u5e8f\u4fee\u590d\u7684\u6548\u679c\u3002", "method": "\u5728HumanEval-Java\u548cDefects4J\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4ee3\u8868\u6027\u5f00\u6e90\u548c\u95ed\u6e90\u6a21\u578b\uff0c\u7814\u7a76\u4e0d\u540c\u63d0\u793a\u7b56\u7565\uff08\u6807\u51c6\u63d0\u793a\u3001\u5c11\u6837\u672c\u5b66\u4e60\u3001\u601d\u7ef4\u94fe\uff09\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u5305\u542b\u9519\u8bef\u62a5\u544a\u4e0a\u4e0b\u6587\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff1b\u5c11\u6837\u672c\u5b66\u4e60\u6709\u6539\u8fdb\u6f5c\u529b\u4f46\u5b58\u5728\u8fb9\u9645\u6536\u76ca\u9012\u51cf\uff1b\u601d\u7ef4\u94fe\u63a8\u7406\u6548\u679c\u9ad8\u5ea6\u4f9d\u8d56\u6a21\u578b\u81ea\u8eab\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u4e0d\u540c\u6a21\u578b\u5728\u9519\u8bef\u5b9a\u4f4d\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u7279\u5f81\u548c\u6743\u8861\uff0c\u4e3a\u6539\u8fdb\u9519\u8bef\u5b9a\u4f4d\u6548\u679c\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2510.20056", "categories": ["cs.CR", "cs.SY", "eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.20056", "abs": "https://arxiv.org/abs/2510.20056", "authors": ["Hui Wang", "Hans D. Schotten", "Stefan M. Goetz"], "title": "Ultra-Fast Wireless Power Hacking", "comment": "11 pages, 15 figures", "summary": "The rapid growth of electric vehicles (EVs) has driven the development of\nroadway wireless charging technology, effectively extending EV driving range.\nHowever, wireless charging introduces significant cybersecurity challenges. Any\nreceiver within the magnetic field can potentially extract energy, and previous\nresearch demonstrated that a hacker could detect the operating frequency and\nsteal substantial power. However, our approach required time to track new\nfrequencies or precise adjustments of inductance and capacitance, which would\nbe less effective against potential rapid transmitter frequency changes or\ncapacitance drift. As a solution, we enhanced the interceptor and enabled it to\nintrude as well as steal energy within just three cycles of the high-frequency\nsignal. Moreover, it can work without any circuit parameters or look-up tables.\nThe key innovation is synchronizing the receiver current with the phase of the\nmagnetic sensor voltage. Through MATLAB / Simulink simulations, finite-element\nanalysis, and experimental validation, we demonstrated that our improved method\ncan steal over 76% of the power received by a fully resonant receiver under\nidentical conditions. This attack demonstrates that simple frequency-changing\npower encryption offers limited protection against such threats.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u65e0\u7ebf\u5145\u7535\u62e6\u622a\u5668\uff0c\u80fd\u57283\u4e2a\u9ad8\u9891\u4fe1\u53f7\u5468\u671f\u5185\u5b9e\u73b0\u80fd\u91cf\u7a83\u53d6\uff0c\u65e0\u9700\u7535\u8def\u53c2\u6570\u6216\u67e5\u627e\u8868\uff0c\u53ef\u7a83\u53d6\u8d85\u8fc776%\u7684\u529f\u7387\u3002", "motivation": "\u7535\u52a8\u6c7d\u8f66\u65e0\u7ebf\u5145\u7535\u5b58\u5728\u4e25\u91cd\u7f51\u7edc\u5b89\u5168\u95ee\u9898\uff0c\u73b0\u6709\u9632\u62a4\u63aa\u65bd\u5bf9\u5feb\u901f\u9891\u7387\u53d8\u5316\u6216\u7535\u5bb9\u6f02\u79fb\u6548\u679c\u6709\u9650\u3002", "method": "\u901a\u8fc7\u540c\u6b65\u63a5\u6536\u5668\u7535\u6d41\u4e0e\u78c1\u4f20\u611f\u5668\u7535\u538b\u76f8\u4f4d\uff0c\u65e0\u9700\u7535\u8def\u53c2\u6570\u5373\u53ef\u5b9e\u73b0\u5feb\u901f\u80fd\u91cf\u7a83\u53d6\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u6539\u8fdb\u65b9\u6cd5\u53ef\u5728\u76f8\u540c\u6761\u4ef6\u4e0b\u7a83\u53d6\u8d85\u8fc776%\u7684\u63a5\u6536\u529f\u7387\u3002", "conclusion": "\u7b80\u5355\u7684\u9891\u7387\u53d8\u5316\u529f\u7387\u52a0\u5bc6\u5bf9\u6b64\u7c7b\u5a01\u80c1\u9632\u62a4\u6548\u679c\u6709\u9650\u3002"}}
{"id": "2510.20275", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20275", "abs": "https://arxiv.org/abs/2510.20275", "authors": ["Yunzhi Liu", "Haokai Tan", "Rushi Kanjaria", "Lihuan Li", "Flora D. Salim"], "title": "Classical Feature Embeddings Help in BERT-Based Human Mobility Prediction", "comment": "This paper has been accepted by ACM SIGSPATIAL 2025 as a short paper", "summary": "Human mobility forecasting is crucial for disaster relief, city planning, and\npublic health. However, existing models either only model location sequences or\ninclude time information merely as auxiliary input, thereby failing to leverage\nthe rich semantic context provided by points of interest (POIs). To address\nthis, we enrich a BERT-based mobility model with derived temporal descriptors\nand POI embeddings to better capture the semantics underlying human movement.\nWe propose STaBERT (Semantic-Temporal aware BERT), which integrates both POI\nand temporal information at each location to construct a unified, semantically\nenriched representation of mobility. Experimental results show that STaBERT\nsignificantly improves prediction accuracy: for single-city prediction, the\nGEO-BLEU score improved from 0.34 to 0.75; for multi-city prediction, from 0.34\nto 0.56.", "AI": {"tldr": "STaBERT\u6a21\u578b\u901a\u8fc7\u6574\u5408POI\u548c\u65f6\u5e8f\u4fe1\u606f\u6765\u589e\u5f3a\u4eba\u7c7b\u79fb\u52a8\u6027\u9884\u6d4b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u8981\u4e48\u53ea\u5efa\u6a21\u4f4d\u7f6e\u5e8f\u5217\uff0c\u8981\u4e48\u4ec5\u5c06\u65f6\u95f4\u4fe1\u606f\u4f5c\u4e3a\u8f85\u52a9\u8f93\u5165\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528POI\u63d0\u4f9b\u7684\u4e30\u5bcc\u8bed\u4e49\u4e0a\u4e0b\u6587\u3002", "method": "\u63d0\u51faSTaBERT\u6a21\u578b\uff0c\u5728BERT\u57fa\u7840\u4e0a\u96c6\u6210POI\u5d4c\u5165\u548c\u65f6\u5e8f\u63cf\u8ff0\u7b26\uff0c\u6784\u5efa\u7edf\u4e00\u7684\u8bed\u4e49\u589e\u5f3a\u79fb\u52a8\u6027\u8868\u793a\u3002", "result": "\u5355\u57ce\u5e02\u9884\u6d4bGEO-BLEU\u4ece0.34\u63d0\u5347\u52300.75\uff1b\u591a\u57ce\u5e02\u9884\u6d4b\u4ece0.34\u63d0\u5347\u52300.56\u3002", "conclusion": "\u6574\u5408POI\u548c\u65f6\u5e8f\u4fe1\u606f\u80fd\u6709\u6548\u6355\u6349\u4eba\u7c7b\u79fb\u52a8\u7684\u8bed\u4e49\u57fa\u7840\uff0c\u663e\u8457\u6539\u5584\u79fb\u52a8\u6027\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2510.20679", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.20679", "abs": "https://arxiv.org/abs/2510.20679", "authors": ["Jonas Klauke", "Tom Ohlmer", "Stefan Schott", "Serena Elisa Ponta", "Wolfram Fischer", "Eric Bodden"], "title": "A Soundness and Precision Benchmark for Java Debloating Tools", "comment": "Preprint - accepted at the ACM Workshop on Software Supply Chain\n  Offensive Research and Ecosystem Defenses (SCORED '25)", "summary": "Modern software development reuses code by importing libraries as\ndependencies. Software projects typically include an average of 36\ndependencies, with 80% being transitive, meaning they are dependencies of\ndependencies. Recent research indicates that only 24.9% of these dependencies\nare required at runtime, and even within those, many program constructs remain\nunused, adding unnecessary code to the project. This has led to the development\nof debloating tools that remove unnecessary dependencies and program constructs\nwhile balancing precision by eliminating unused constructs and soundness by\npreserving all required constructs. To systematically evaluate this trade-off,\nwe developed Deblometer, a micro-benchmark consisting of 59 test cases designed\nto assess support for various Java language features in debloating tools. Each\ntest case includes a manually curated ground truth specifying necessary and\nbloated classes, methods, and fields, enabling precise measurement of soundness\nand precision. Using Deblometer, we evaluated three popular Java debloating\ntools: Deptrim, JShrink, and ProGuard. Our evaluation reveals that all tools\nremove required program constructs, which results in changed semantics or\nexecution crashes. In particular, the dynamic class loading feature introduces\nunsoundness in all evaluated tools. Our comparison shows that Deptrim retains\nmore bloated constructs, while ProGuard removes more required constructs.\nJShrink's soundness is significantly affected by limited support for\nannotations, which leads to corrupted debloated artifacts. These soundness\nissues highlight the need to improve debloating tools to ensure stable and\nreliable debloated software.", "AI": {"tldr": "\u5f00\u53d1\u4e86Deblometer\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u6765\u8bc4\u4f30Java\u53bb\u81a8\u80c0\u5de5\u5177\uff0c\u53d1\u73b0\u73b0\u6709\u5de5\u5177\u90fd\u5b58\u5728\u79fb\u9664\u5fc5\u8981\u7a0b\u5e8f\u6784\u9020\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u52a8\u6001\u7c7b\u52a0\u8f7d\u65b9\u9762\u5b58\u5728\u4e0d\u5065\u5168\u6027\u3002", "motivation": "\u73b0\u4ee3\u8f6f\u4ef6\u5f00\u53d1\u5927\u91cf\u4f9d\u8d56\u7b2c\u4e09\u65b9\u5e93\uff0c\u4f46\u7814\u7a76\u8868\u660e\u5e73\u5747\u53ea\u670924.9%\u7684\u4f9d\u8d56\u5728\u8fd0\u884c\u65f6\u88ab\u4f7f\u7528\uff0c\u5bfc\u81f4\u5927\u91cf\u4e0d\u5fc5\u8981\u7684\u4ee3\u7801\u81a8\u80c0\u3002\u9700\u8981\u8bc4\u4f30\u53bb\u81a8\u80c0\u5de5\u5177\u5728\u7cbe\u5ea6\uff08\u79fb\u9664\u65e0\u7528\u6784\u9020\uff09\u548c\u5065\u5168\u6027\uff08\u4fdd\u7559\u5fc5\u8981\u6784\u9020\uff09\u4e4b\u95f4\u7684\u6743\u8861\u3002", "method": "\u5f00\u53d1\u4e86\u5305\u542b59\u4e2a\u6d4b\u8bd5\u7528\u4f8b\u7684Deblometer\u5fae\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6bcf\u4e2a\u6d4b\u8bd5\u7528\u4f8b\u90fd\u5305\u542b\u624b\u52a8\u6807\u6ce8\u7684ground truth\uff0c\u7528\u4e8e\u7cbe\u786e\u6d4b\u91cf\u53bb\u81a8\u80c0\u5de5\u5177\u7684\u5065\u5168\u6027\u548c\u7cbe\u5ea6\u3002\u8bc4\u4f30\u4e86\u4e09\u4e2a\u6d41\u884c\u7684Java\u53bb\u81a8\u80c0\u5de5\u5177\uff1aDeptrim\u3001JShrink\u548cProGuard\u3002", "result": "\u6240\u6709\u8bc4\u4f30\u7684\u5de5\u5177\u90fd\u4f1a\u79fb\u9664\u5fc5\u8981\u7684\u7a0b\u5e8f\u6784\u9020\uff0c\u5bfc\u81f4\u8bed\u4e49\u6539\u53d8\u6216\u6267\u884c\u5d29\u6e83\u3002\u52a8\u6001\u7c7b\u52a0\u8f7d\u7279\u6027\u5728\u6240\u6709\u5de5\u5177\u4e2d\u90fd\u5f15\u5165\u4e86\u4e0d\u5065\u5168\u6027\u3002Deptrim\u4fdd\u7559\u66f4\u591a\u81a8\u80c0\u6784\u9020\uff0cProGuard\u79fb\u9664\u66f4\u591a\u5fc5\u8981\u6784\u9020\uff0cJShrink\u56e0\u5bf9\u6ce8\u89e3\u652f\u6301\u6709\u9650\u800c\u5bfc\u81f4\u53bb\u81a8\u80c0\u4ea7\u7269\u635f\u574f\u3002", "conclusion": "\u73b0\u6709\u53bb\u81a8\u80c0\u5de5\u5177\u5b58\u5728\u4e25\u91cd\u7684\u5065\u5168\u6027\u95ee\u9898\uff0c\u9700\u8981\u6539\u8fdb\u4ee5\u786e\u4fdd\u53bb\u81a8\u80c0\u8f6f\u4ef6\u7684\u7a33\u5b9a\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2510.20080", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.20080", "abs": "https://arxiv.org/abs/2510.20080", "authors": ["M. Abdullah Canbaz", "Hakan Otal", "Tugce Unlu", "Nour Alhussein", "Brian Nussbaum"], "title": "Who Coordinates U.S. Cyber Defense? A Co-Authorship Network Analysis of Joint Cybersecurity Advisories (2024--2025)", "comment": null, "summary": "Cyber threats increasingly demand joint responses, yet the organizational\ndynamics behind multi-agency cybersecurity collaboration remain poorly\nunderstood. Understanding who leads, who bridges, and how agencies coordinate\nis critical for strengthening both U.S. homeland security and allied defense\nefforts. In this study, we construct a co-authorship network from nine Joint\nCybersecurity Advisories (CSAs) issued between November 2024 and August 2025.\nWe map 41 agencies and 442 co-authoring ties to analyze the structure of\ncollaboration. We find a tightly knit U.S. triad -- CISA, FBI, and NSA --\ndensely connected with Five Eyes and select European allies. Degree centrality\nidentifies CISA and FBI as coordination hubs, while betweenness highlights NSA,\nthe UK's NCSC, and Australia's ASD-ACSC as key bridges linking otherwise\nfragmented clusters. By releasing the first replicable dataset and network\nanalysis of CSAs, we provide new empirical evidence on how collaborative\ncybersecurity signals are organized and where strategic influence is\nconcentrated.", "AI": {"tldr": "\u901a\u8fc7\u5206\u67902024-2025\u5e749\u4efd\u8054\u5408\u7f51\u7edc\u5b89\u5168\u516c\u544a\u6784\u5efa\u5408\u4f5c\u7f51\u7edc\uff0c\u53d1\u73b0\u7f8e\u56fdCISA\u3001FBI\u548cNSA\u5f62\u6210\u7d27\u5bc6\u5408\u4f5c\u6838\u5fc3\uff0c\u4e0e\u4e94\u773c\u8054\u76df\u53ca\u6b27\u6d32\u76df\u53cb\u5bc6\u5207\u534f\u4f5c\u3002", "motivation": "\u7406\u89e3\u591a\u673a\u6784\u7f51\u7edc\u5b89\u5168\u5408\u4f5c\u7684\u7ec4\u7ec7\u52a8\u6001\uff0c\u5305\u62ec\u9886\u5bfc\u89d2\u8272\u3001\u6865\u6881\u4f5c\u7528\u548c\u534f\u8c03\u673a\u5236\uff0c\u8fd9\u5bf9\u52a0\u5f3a\u7f8e\u56fd\u56fd\u571f\u5b89\u5168\u548c\u76df\u56fd\u9632\u52a1\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4ece9\u4efd\u8054\u5408\u7f51\u7edc\u5b89\u5168\u516c\u544a\u6784\u5efa\u5408\u8457\u7f51\u7edc\uff0c\u6620\u5c0441\u4e2a\u673a\u6784\u548c442\u4e2a\u5408\u4f5c\u5173\u7cfb\uff0c\u4f7f\u7528\u5ea6\u4e2d\u5fc3\u6027\u548c\u4e2d\u4ecb\u4e2d\u5fc3\u6027\u5206\u6790\u7f51\u7edc\u7ed3\u6784\u3002", "result": "\u53d1\u73b0\u7d27\u5bc6\u7684\u7f8e\u56fd\u4e09\u673a\u6784\u6838\u5fc3\uff08CISA\u3001FBI\u3001NSA\uff09\uff0cCISA\u548cFBI\u662f\u534f\u8c03\u4e2d\u5fc3\uff0cNSA\u3001\u82f1\u56fdNCSC\u548c\u6fb3\u5927\u5229\u4e9aASD-ACSC\u662f\u5173\u952e\u6865\u6881\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u9996\u4e2a\u53ef\u590d\u5236\u7684CSA\u6570\u636e\u96c6\u548c\u7f51\u7edc\u5206\u6790\uff0c\u63ed\u793a\u4e86\u534f\u4f5c\u7f51\u7edc\u5b89\u5168\u4fe1\u53f7\u7684\u7ec4\u7ec7\u65b9\u5f0f\u548c\u6218\u7565\u5f71\u54cd\u529b\u7684\u96c6\u4e2d\u4f4d\u7f6e\u3002"}}
{"id": "2510.20310", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20310", "abs": "https://arxiv.org/abs/2510.20310", "authors": ["Mingliang Zhai", "Hansheng Liang", "Xiaomeng Fan", "Zhi Gao", "Chuanhao Li", "Che Sun", "Xu Bin", "Yuwei Wu", "Yunde Jia"], "title": "Multi-Step Reasoning for Embodied Question Answering via Tool Augmentation", "comment": "16 pages, 7 figures, 8 tables", "summary": "Embodied Question Answering (EQA) requires agents to explore 3D environments\nto obtain observations and answer questions related to the scene. Existing\nmethods leverage VLMs to directly explore the environment and answer questions\nwithout explicit thinking or planning, which limits their reasoning ability and\nresults in excessive or inefficient exploration as well as ineffective\nresponses. In this paper, we introduce ToolEQA, an agent that integrates\nexternal tools with multi-step reasoning, where external tools can provide more\nuseful information for completing the task, helping the model derive better\nexploration directions in the next step of reasoning and thus obtaining\nadditional effective information. This enables ToolEQA to generate more\naccurate responses with a shorter exploration distance. To enhance the model's\nability for tool-usage and multi-step reasoning, we further design a novel EQA\ndata generation pipeline that automatically constructs large-scale EQA tasks\nwith reasoning trajectories and corresponding answers. Based on the pipeline,\nwe collect the EQA-RT dataset that contains about 18K tasks, divided into a\ntraining set EQA-RT-Train, and two test sets EQA-RT-Seen (scenes overlapping\nwith the training set) and EQA-RT-Unseen (novel scenes). Experiments on\nEQA-RT-Seen and EQA-RT-Unseen show that ToolEQA improves the success rate by\n9.2~20.2% over state-of-the-art baselines, while outperforming the zero-shot\nToolEQA by 10% in success rate. In addition, ToolEQA also achieves\nstate-of-the-art performance on the HM-EQA, OpenEQA, and EXPRESS-Bench\ndatasets, demonstrating its generality. Our homepage see\nhttps://tooleqa.github.io.", "AI": {"tldr": "ToolEQA\u662f\u4e00\u4e2a\u96c6\u6210\u5916\u90e8\u5de5\u5177\u548c\u591a\u6b65\u63a8\u7406\u7684EQA\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u5de5\u5177\u63d0\u4f9b\u989d\u5916\u4fe1\u606f\u6765\u6539\u8fdb\u63a2\u7d22\u65b9\u5411\u548c\u54cd\u5e94\u51c6\u786e\u6027\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u73b0\u6709EQA\u65b9\u6cd5\u76f4\u63a5\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u63a2\u7d22\u73af\u5883\u800c\u7f3a\u4e4f\u663e\u5f0f\u601d\u8003\u548c\u89c4\u5212\uff0c\u5bfc\u81f4\u63a8\u7406\u80fd\u529b\u53d7\u9650\u3001\u63a2\u7d22\u6548\u7387\u4f4e\u4e0b\u548c\u54cd\u5e94\u65e0\u6548\u3002", "method": "\u63d0\u51faToolEQA\u667a\u80fd\u4f53\uff0c\u96c6\u6210\u5916\u90e8\u5de5\u5177\u8fdb\u884c\u591a\u6b65\u63a8\u7406\uff0c\u8bbe\u8ba1\u81ea\u52a8\u751f\u6210EQA\u4efb\u52a1\u7684\u6570\u636e\u751f\u6210\u6d41\u7a0b\uff0c\u6784\u5efa\u5305\u542b18K\u4efb\u52a1\u7684EQA-RT\u6570\u636e\u96c6\u3002", "result": "\u5728EQA-RT-Seen\u548cEQA-RT-Unseen\u4e0a\uff0cToolEQA\u6bd4\u6700\u5148\u8fdb\u57fa\u7ebf\u6210\u529f\u7387\u63d0\u9ad89.2~20.2%\uff0c\u6bd4\u96f6\u6837\u672c\u7248\u672c\u63d0\u9ad810%\uff0c\u5728HM-EQA\u3001OpenEQA\u548cEXPRESS-Bench\u6570\u636e\u96c6\u4e0a\u4e5f\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "ToolEQA\u901a\u8fc7\u5de5\u5177\u96c6\u6210\u548c\u591a\u6b65\u63a8\u7406\u663e\u8457\u63d0\u5347\u4e86EQA\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5177\u8eab\u95ee\u7b54\u4e2d\u7684\u6709\u6548\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2510.20692", "categories": ["cs.SE", "cs.AI", "cs.FL", "D.4.6; D.2.4; I.2.2; I.2.7; F.3.1; F.4.3"], "pdf": "https://arxiv.org/pdf/2510.20692", "abs": "https://arxiv.org/abs/2510.20692", "authors": ["Adarsh Vatsa", "Bethel Hall", "William Eiers"], "title": "Exploring Large Language Models for Access Control Policy Synthesis and Summarization", "comment": "20 pages, 7 figures", "summary": "Cloud computing is ubiquitous, with a growing number of services being hosted\non the cloud every day. Typical cloud compute systems allow administrators to\nwrite policies implementing access control rules which specify how access to\nprivate data is governed. These policies must be manually written, and due to\ntheir complexity can often be error prone. Moreover, existing policies often\nimplement complex access control specifications and thus can be difficult to\nprecisely analyze in determining their behavior works exactly as intended.\nRecently, Large Language Models (LLMs) have shown great success in automated\ncode synthesis and summarization. Given this success, they could potentially be\nused for automatically generating access control policies or aid in\nunderstanding existing policies. In this paper, we explore the effectiveness of\nLLMs for access control policy synthesis and summarization. Specifically, we\nfirst investigate diverse LLMs for access control policy synthesis, finding\nthat: although LLMs can effectively generate syntactically correct policies,\nthey have permissiveness issues, generating policies equivalent to the given\nspecification 45.8% of the time for non-reasoning LLMs, and 93.7% of the time\nfor reasoning LLMs. We then investigate how LLMs can be used to analyze\npolicies by introducing a novel semantic-based request summarization approach\nwhich leverages LLMs to generate a precise characterization of the requests\nallowed by a policy. Our results show that while there are significant hurdles\nin leveraging LLMs for automated policy generation, LLMs show promising results\nwhen combined with symbolic approaches in analyzing existing policies.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bbf\u95ee\u63a7\u5236\u7b56\u7565\u751f\u6210\u548c\u603b\u7ed3\u4e2d\u7684\u6709\u6548\u6027\uff0c\u53d1\u73b0LLMs\u5728\u7b56\u7565\u751f\u6210\u65b9\u9762\u5b58\u5728\u8bb8\u53ef\u6027\u95ee\u9898\uff0c\u4f46\u5728\u7ed3\u5408\u7b26\u53f7\u65b9\u6cd5\u5206\u6790\u73b0\u6709\u7b56\u7565\u65f6\u8868\u73b0\u51fa\u826f\u597d\u6f5c\u529b\u3002", "motivation": "\u4e91\u8ba1\u7b97\u7684\u666e\u53ca\u4f7f\u5f97\u8bbf\u95ee\u63a7\u5236\u7b56\u7565\u65e5\u76ca\u590d\u6742\u4e14\u5bb9\u6613\u51fa\u9519\uff0c\u800cLLMs\u5728\u4ee3\u7801\u5408\u6210\u548c\u603b\u7ed3\u65b9\u9762\u7684\u6210\u529f\u8868\u660e\u5b83\u4eec\u53ef\u80fd\u7528\u4e8e\u81ea\u52a8\u751f\u6210\u8bbf\u95ee\u63a7\u5236\u7b56\u7565\u6216\u5e2e\u52a9\u7406\u89e3\u73b0\u6709\u7b56\u7565\u3002", "method": "\u9996\u5148\u8c03\u67e5\u4e86\u4e0d\u540cLLMs\u5728\u8bbf\u95ee\u63a7\u5236\u7b56\u7565\u5408\u6210\u4e2d\u7684\u8868\u73b0\uff0c\u7136\u540e\u5f15\u5165\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bed\u4e49\u7684\u8bf7\u6c42\u603b\u7ed3\u65b9\u6cd5\uff0c\u5229\u7528LLMs\u751f\u6210\u7b56\u7565\u5141\u8bb8\u8bf7\u6c42\u7684\u7cbe\u786e\u63cf\u8ff0\u3002", "result": "LLMs\u80fd\u591f\u6709\u6548\u751f\u6210\u8bed\u6cd5\u6b63\u786e\u7684\u7b56\u7565\uff0c\u4f46\u5b58\u5728\u8bb8\u53ef\u6027\u95ee\u9898\uff1a\u975e\u63a8\u7406\u578bLLMs\u751f\u6210\u7b26\u5408\u89c4\u683c\u7684\u7b56\u7565\u4ec545.8%\u7684\u65f6\u95f4\uff0c\u63a8\u7406\u578bLLMs\u4e3a93.7%\u3002\u5728\u7b56\u7565\u5206\u6790\u65b9\u9762\uff0cLLMs\u4e0e\u7b26\u53f7\u65b9\u6cd5\u7ed3\u5408\u663e\u793a\u51fa\u826f\u597d\u6548\u679c\u3002", "conclusion": "\u867d\u7136LLMs\u5728\u81ea\u52a8\u7b56\u7565\u751f\u6210\u65b9\u9762\u5b58\u5728\u663e\u8457\u969c\u788d\uff0c\u4f46\u5f53\u4e0e\u7b26\u53f7\u65b9\u6cd5\u7ed3\u5408\u5206\u6790\u73b0\u6709\u7b56\u7565\u65f6\uff0cLLMs\u663e\u793a\u51fa\u6709\u5e0c\u671b\u7684\u7ed3\u679c\u3002"}}
{"id": "2510.20129", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20129", "abs": "https://arxiv.org/abs/2510.20129", "authors": ["Yulong Chen", "Yadong Liu", "Jiawen Zhang", "Mu Li", "Chao Huang", "Jie Wen"], "title": "SAID: Empowering Large Language Models with Self-Activating Internal Defense", "comment": null, "summary": "Large Language Models (LLMs), despite advances in safety alignment, remain\nvulnerable to jailbreak attacks designed to circumvent protective mechanisms.\nPrevailing defense strategies rely on external interventions, such as input\nfiltering or output modification, which often lack generalizability and\ncompromise model utility while incurring significant computational overhead. In\nthis work, we introduce a new, training-free defense paradigm, Self-Activating\nInternal Defense (SAID), which reframes the defense task from external\ncorrection to internal capability activation. SAID uniquely leverages the LLM's\nown reasoning abilities to proactively identify and neutralize malicious intent\nthrough a three-stage pipeline: model-native intent distillation to extract\ncore semantics, optimal safety prefix probing to activate latent safety\nawareness, and a conservative aggregation strategy to ensure robust\ndecision-making. Extensive experiments on five open-source LLMs against six\nadvanced jailbreak attacks demonstrate that SAID substantially outperforms\nstate-of-the-art defenses in reducing harmful outputs. Crucially, it achieves\nthis while preserving model performance on benign tasks and incurring minimal\ncomputational overhead. Our work establishes that activating the intrinsic\nsafety mechanisms of LLMs is a more robust and scalable path toward building\nsafer and more reliable aligned AI systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSAID\u7684\u65e0\u8bad\u7ec3\u9632\u5fa1\u8303\u5f0f\uff0c\u901a\u8fc7\u6fc0\u6d3bLLM\u5185\u90e8\u5b89\u5168\u673a\u5236\u6765\u62b5\u5fa1\u8d8a\u72f1\u653b\u51fb\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u6709\u5bb3\u8f93\u51fa\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5916\u90e8\u5e72\u9884\u7684\u9632\u5fa1\u7b56\u7565\u7f3a\u4e4f\u901a\u7528\u6027\u3001\u635f\u5bb3\u6a21\u578b\u6548\u7528\u4e14\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u548c\u53ef\u6269\u5c55\u7684\u9632\u5fa1\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u7ba1\u9053\uff1a\u6a21\u578b\u539f\u751f\u610f\u56fe\u84b8\u998f\u63d0\u53d6\u6838\u5fc3\u8bed\u4e49\u3001\u6700\u4f18\u5b89\u5168\u524d\u7f00\u63a2\u6d4b\u6fc0\u6d3b\u6f5c\u5728\u5b89\u5168\u610f\u8bc6\u3001\u4fdd\u5b88\u805a\u5408\u7b56\u7565\u786e\u4fdd\u9c81\u68d2\u51b3\u7b56\u3002", "result": "\u57285\u4e2a\u5f00\u6e90LLM\u548c6\u79cd\u5148\u8fdb\u8d8a\u72f1\u653b\u51fb\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSAID\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u9632\u5fa1\u65b9\u6cd5\uff0c\u5728\u51cf\u5c11\u6709\u5bb3\u8f93\u51fa\u65b9\u9762\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u6fc0\u6d3bLLM\u5185\u5728\u5b89\u5168\u673a\u5236\u662f\u6784\u5efa\u66f4\u5b89\u5168\u53ef\u9760\u5bf9\u9f50AI\u7cfb\u7edf\u7684\u66f4\u9c81\u68d2\u548c\u53ef\u6269\u5c55\u8def\u5f84\u3002"}}
{"id": "2510.20332", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20332", "abs": "https://arxiv.org/abs/2510.20332", "authors": ["Anna Arias-Duart", "Maria Eugenia Cardello", "Atia Cort\u00e9s"], "title": "Bias by Design? How Data Practices Shape Fairness in AI Healthcare Systems", "comment": "8 pages, 3 tables, accepted in AEQUITAS 2025 (not in proceedings)", "summary": "Artificial intelligence (AI) holds great promise for transforming healthcare.\nHowever, despite significant advances, the integration of AI solutions into\nreal-world clinical practice remains limited. A major barrier is the quality\nand fairness of training data, which is often compromised by biased data\ncollection practices. This paper draws on insights from the AI4HealthyAging\nproject, part of Spain's national R&D initiative, where our task was to detect\nbiases during clinical data collection. We identify several types of bias\nacross multiple use cases, including historical, representation, and\nmeasurement biases. These biases manifest in variables such as sex, gender,\nage, habitat, socioeconomic status, equipment, and labeling. We conclude with\npractical recommendations for improving the fairness and robustness of clinical\nproblem design and data collection. We hope that our findings and experience\ncontribute to guiding future projects in the development of fairer AI systems\nin healthcare.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86AI\u5728\u533b\u7597\u9886\u57df\u5e94\u7528\u4e2d\u7684\u6570\u636e\u504f\u89c1\u95ee\u9898\uff0c\u57fa\u4e8eAI4HealthyAging\u9879\u76ee\u7684\u7ecf\u9a8c\uff0c\u8bc6\u522b\u4e86\u4e34\u5e8a\u6570\u636e\u6536\u96c6\u4e2d\u5b58\u5728\u7684\u591a\u79cd\u504f\u89c1\u7c7b\u578b\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u5584\u516c\u5e73\u6027\u548c\u9c81\u68d2\u6027\u7684\u5b9e\u7528\u5efa\u8bae\u3002", "motivation": "AI\u5728\u533b\u7597\u9886\u57df\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u7531\u4e8e\u8bad\u7ec3\u6570\u636e\u7684\u8d28\u91cf\u548c\u516c\u5e73\u6027\u95ee\u9898\uff0cAI\u89e3\u51b3\u65b9\u6848\u5728\u771f\u5b9e\u4e34\u5e8a\u5b9e\u8df5\u4e2d\u7684\u6574\u5408\u4ecd\u7136\u6709\u9650\u3002\u4e3b\u8981\u969c\u788d\u662f\u6570\u636e\u6536\u96c6\u8fc7\u7a0b\u4e2d\u7684\u504f\u89c1\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u897f\u73ed\u7259\u56fd\u5bb6\u7814\u53d1\u8ba1\u5212\u4e2d\u7684AI4HealthyAging\u9879\u76ee\u7ecf\u9a8c\uff0c\u901a\u8fc7\u68c0\u6d4b\u4e34\u5e8a\u6570\u636e\u6536\u96c6\u8fc7\u7a0b\u4e2d\u7684\u504f\u89c1\uff0c\u8bc6\u522b\u4e86\u591a\u79cd\u504f\u89c1\u7c7b\u578b\u3002", "result": "\u5728\u591a\u4e2a\u7528\u4f8b\u4e2d\u8bc6\u522b\u51fa\u5386\u53f2\u504f\u89c1\u3001\u4ee3\u8868\u6027\u504f\u89c1\u548c\u6d4b\u91cf\u504f\u89c1\u7b49\u7c7b\u578b\uff0c\u8fd9\u4e9b\u504f\u89c1\u4f53\u73b0\u5728\u6027\u522b\u3001\u5e74\u9f84\u3001\u5c45\u4f4f\u5730\u3001\u793e\u4f1a\u7ecf\u6d4e\u5730\u4f4d\u3001\u8bbe\u5907\u548c\u6807\u7b7e\u7b49\u53d8\u91cf\u4e2d\u3002", "conclusion": "\u63d0\u51fa\u4e86\u6539\u5584\u4e34\u5e8a\u95ee\u9898\u8bbe\u8ba1\u548c\u6570\u636e\u6536\u96c6\u516c\u5e73\u6027\u548c\u9c81\u68d2\u6027\u7684\u5b9e\u7528\u5efa\u8bae\uff0c\u5e0c\u671b\u8fd9\u4e9b\u53d1\u73b0\u548c\u7ecf\u9a8c\u80fd\u4e3a\u672a\u6765\u5f00\u53d1\u66f4\u516c\u5e73\u7684\u533b\u7597AI\u7cfb\u7edf\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2510.20131", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.20131", "abs": "https://arxiv.org/abs/2510.20131", "authors": ["Mohammed Barhoush"], "title": "Separating Pseudorandom Generators from Logarithmic Pseudorandom States", "comment": "18 pages", "summary": "Pseudorandom generators (PRGs) are a foundational primitive in classical\ncryptography, underpinning a wide range of constructions. In the quantum\nsetting, pseudorandom quantum states (PRSs) were proposed as a potentially\nweaker assumption that might serve as a substitute for PRGs in cryptographic\napplications. Two primary size regimes of PRSs have been studied:\nlogarithmic-size and linear-size. Interestingly, logarithmic PRSs have led to\npowerful cryptographic applications, such as digital signatures and quantum\npublic-key encryption, that have not been realized from their linear\ncounterparts. However, PRGs have only been black-box separated from linear\nPRSs, leaving open the fundamental question of whether PRGs are also separated\nfrom logarithmic PRSs.\n  In this work, we resolve this open problem. We establish a quantum black-box\nseparation between (quantum-evaluable) PRGs and PRSs of either size regime.\nSpecifically, we construct a unitary quantum oracle with inverse access\nrelative to which no black-box construction of PRG from (logarithmic or linear)\nPRS exists. As a direct corollary, we obtain separations between PRGs and\nseveral primitives implied by logarithmic PRSs, including digital signatures\nand quantum public-key encryption.", "AI": {"tldr": "\u672c\u6587\u5efa\u7acb\u4e86\u91cf\u5b50\u53ef\u8bc4\u4f30\u4f2a\u968f\u673a\u751f\u6210\u5668(PRG)\u4e0e\u4e24\u79cd\u89c4\u6a21(\u5bf9\u6570\u548c\u7ebf\u6027)\u4f2a\u968f\u673a\u91cf\u5b50\u6001(PRS)\u4e4b\u95f4\u7684\u91cf\u5b50\u9ed1\u76d2\u5206\u79bb\uff0c\u8bc1\u660e\u5728\u5177\u6709\u9006\u8bbf\u95ee\u7684\u9149\u91cf\u5b50\u9884\u8a00\u673a\u4e0b\uff0c\u4e0d\u5b58\u5728\u4ecePRS\u5230PRG\u7684\u9ed1\u76d2\u6784\u9020\u3002", "motivation": "\u89e3\u51b3PRG\u662f\u5426\u4e0e\u5bf9\u6570\u89c4\u6a21PRS\u5206\u79bb\u8fd9\u4e00\u5f00\u653e\u95ee\u9898\uff0c\u56e0\u4e3a\u5bf9\u6570PRS\u5df2\u5b9e\u73b0\u6570\u5b57\u7b7e\u540d\u548c\u91cf\u5b50\u516c\u94a5\u52a0\u5bc6\u7b49\u5f3a\u5927\u5e94\u7528\uff0c\u800c\u7ebf\u6027PRS\u5c1a\u672a\u5b9e\u73b0\u8fd9\u4e9b\u5e94\u7528\u3002", "method": "\u6784\u9020\u4e00\u4e2a\u5177\u6709\u9006\u8bbf\u95ee\u7684\u9149\u91cf\u5b50\u9884\u8a00\u673a\uff0c\u5728\u8be5\u9884\u8a00\u673a\u4e0b\u8bc1\u660e\u4e0d\u5b58\u5728\u4ecePRS\u5230PRG\u7684\u9ed1\u76d2\u6784\u9020\u3002", "result": "\u6210\u529f\u5efa\u7acb\u4e86PRG\u4e0e\u4e24\u79cd\u89c4\u6a21PRS\u4e4b\u95f4\u7684\u91cf\u5b50\u9ed1\u76d2\u5206\u79bb\uff0c\u5e76\u4f5c\u4e3a\u76f4\u63a5\u63a8\u8bba\u83b7\u5f97\u4e86PRG\u4e0e\u6570\u5b57\u7b7e\u540d\u3001\u91cf\u5b50\u516c\u94a5\u52a0\u5bc6\u7b49\u539f\u8bed\u7684\u5206\u79bb\u3002", "conclusion": "PRG\u4e0ePRS(\u5305\u62ec\u5bf9\u6570\u548c\u7ebf\u6027\u89c4\u6a21)\u4e4b\u95f4\u5b58\u5728\u6839\u672c\u6027\u5206\u79bb\uff0c\u8fd9\u4e3a\u7406\u89e3\u91cf\u5b50\u5bc6\u7801\u5b66\u4e2d\u4e0d\u540c\u539f\u8bed\u4e4b\u95f4\u7684\u5173\u7cfb\u63d0\u4f9b\u4e86\u91cd\u8981\u6d1e\u89c1\u3002"}}
{"id": "2510.20337", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20337", "abs": "https://arxiv.org/abs/2510.20337", "authors": ["Clara Maathuis", "Kasper Cools"], "title": "Collateral Damage Assessment Model for AI System Target Engagement in Military Operations", "comment": "Accepted at MILCOM 2025 WS07", "summary": "In an era where AI (Artificial Intelligence) systems play an increasing role\nin the battlefield, ensuring responsible targeting demands rigorous assessment\nof potential collateral effects. In this context, a novel collateral damage\nassessment model for target engagement of AI systems in military operations is\nintroduced. The model integrates temporal, spatial, and force dimensions within\na unified Knowledge Representation and Reasoning (KRR) architecture following a\ndesign science methodological approach. Its layered structure captures the\ncategories and architectural components of the AI systems to be engaged\ntogether with corresponding engaging vectors and contextual aspects. At the\nsame time, spreading, severity, likelihood, and evaluation metrics are\nconsidered in order to provide a clear representation enhanced by transparent\nreasoning mechanisms. Further, the model is demonstrated and evaluated through\ninstantiation which serves as a basis for further dedicated efforts that aim at\nbuilding responsible and trustworthy intelligent systems for assessing the\neffects produced by engaging AI systems in military operations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u519b\u4e8b\u884c\u52a8\u4e2dAI\u7cfb\u7edf\u76ee\u6807\u4ea4\u6218\u7684\u9644\u5e26\u635f\u5bb3\u8bc4\u4f30\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5728\u77e5\u8bc6\u8868\u793a\u4e0e\u63a8\u7406\u67b6\u6784\u4e2d\u6574\u5408\u4e86\u65f6\u95f4\u3001\u7a7a\u95f4\u548c\u529b\u91cf\u7ef4\u5ea6\uff0c\u901a\u8fc7\u5206\u5c42\u7ed3\u6784\u6355\u83b7AI\u7cfb\u7edf\u7c7b\u522b\u3001\u4ea4\u6218\u5411\u91cf\u548c\u80cc\u666f\u56e0\u7d20\u3002", "motivation": "\u5728AI\u7cfb\u7edf\u5728\u6218\u573a\u4e2d\u4f5c\u7528\u65e5\u76ca\u91cd\u8981\u7684\u65f6\u4ee3\uff0c\u786e\u4fdd\u8d1f\u8d23\u4efb\u7684\u7784\u51c6\u9700\u8981\u5bf9\u6f5c\u5728\u9644\u5e26\u6548\u5e94\u8fdb\u884c\u4e25\u683c\u8bc4\u4f30\u3002", "method": "\u91c7\u7528\u8bbe\u8ba1\u79d1\u5b66\u65b9\u6cd5\u8bba\uff0c\u6784\u5efa\u7edf\u4e00\u7684\u77e5\u8bc6\u8868\u793a\u4e0e\u63a8\u7406\u67b6\u6784\uff0c\u6574\u5408\u65f6\u95f4\u3001\u7a7a\u95f4\u548c\u529b\u91cf\u7ef4\u5ea6\uff0c\u4f7f\u7528\u5206\u5c42\u7ed3\u6784\u6355\u83b7AI\u7cfb\u7edf\u7c7b\u522b\u3001\u4ea4\u6218\u5411\u91cf\u548c\u80cc\u666f\u65b9\u9762\uff0c\u5e76\u8003\u8651\u4f20\u64ad\u3001\u4e25\u91cd\u6027\u3001\u53ef\u80fd\u6027\u548c\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u901a\u8fc7\u5b9e\u4f8b\u5316\u6f14\u793a\u548c\u8bc4\u4f30\u4e86\u8be5\u6a21\u578b\uff0c\u4e3a\u6784\u5efa\u8d1f\u8d23\u4efb\u548c\u53ef\u4fe1\u8d56\u7684\u667a\u80fd\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u8bc4\u4f30\u519b\u4e8b\u884c\u52a8\u4e2d\u4ea4\u6218AI\u7cfb\u7edf\u4ea7\u751f\u7684\u6548\u5e94\u63d0\u4f9b\u4e86\u900f\u660e\u63a8\u7406\u673a\u5236\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u8d1f\u8d23\u4efb\u548c\u53ef\u4fe1\u8d56\u7684\u667a\u80fd\u7cfb\u7edf\u3002"}}
{"id": "2510.20223", "categories": ["cs.CR", "cs.MM"], "pdf": "https://arxiv.org/pdf/2510.20223", "abs": "https://arxiv.org/abs/2510.20223", "authors": ["Divyanshu Kumar", "Shreyas Jena", "Nitin Aravind Birur", "Tanay Baswa", "Sahil Agarwal", "Prashanth Harshangi"], "title": "Beyond Text: Multimodal Jailbreaking of Vision-Language and Audio Models through Perceptually Simple Transformations", "comment": null, "summary": "Multimodal large language models (MLLMs) have achieved remarkable progress,\nyet remain critically vulnerable to adversarial attacks that exploit weaknesses\nin cross-modal processing. We present a systematic study of multimodal\njailbreaks targeting both vision-language and audio-language models, showing\nthat even simple perceptual transformations can reliably bypass\nstate-of-the-art safety filters. Our evaluation spans 1,900 adversarial prompts\nacross three high-risk safety categories harmful content, CBRN (Chemical,\nBiological, Radiological, Nuclear), and CSEM (Child Sexual Exploitation\nMaterial) tested against seven frontier models. We explore the effectiveness of\nattack techniques on MLLMs, including FigStep-Pro (visual keyword\ndecomposition), Intelligent Masking (semantic obfuscation), and audio\nperturbations (Wave-Echo, Wave-Pitch, Wave-Speed). The results reveal severe\nvulnerabilities: models with almost perfect text-only safety (0\\% ASR) suffer\n>75\\% attack success under perceptually modified inputs, with FigStep-Pro\nachieving up to 89\\% ASR in Llama-4 variants. Audio-based attacks further\nuncover provider-specific weaknesses, with even basic modality transfer\nyielding 25\\% ASR for technical queries. These findings expose a critical gap\nbetween text-centric alignment and multimodal threats, demonstrating that\ncurrent safeguards fail to generalize across cross-modal attacks. The\naccessibility of these attacks, which require minimal technical expertise,\nsuggests that robust multimodal AI safety will require a paradigm shift toward\nbroader semantic-level reasoning to mitigate possible risks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8de8\u6a21\u6001\u5904\u7406\u4e2d\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u53d1\u73b0\u5373\u4f7f\u7b80\u5355\u7684\u611f\u77e5\u53d8\u6362\u4e5f\u80fd\u53ef\u9760\u5730\u7ed5\u8fc7\u6700\u5148\u8fdb\u7684\u5b89\u5168\u8fc7\u6ee4\u5668\uff0c\u63ed\u793a\u4e86\u6587\u672c\u4e2d\u5fc3\u5bf9\u9f50\u4e0e\u591a\u6a21\u6001\u5a01\u80c1\u4e4b\u95f4\u7684\u5173\u952e\u5dee\u8ddd\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5728\u8de8\u6a21\u6001\u5904\u7406\u4e2d\u5b58\u5728\u4e25\u91cd\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u73b0\u6709\u5b89\u5168\u63aa\u65bd\u65e0\u6cd5\u6709\u6548\u62b5\u5fa1\u591a\u6a21\u6001\u653b\u51fb\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u8fd9\u4e9b\u6f0f\u6d1e\u7684\u4e25\u91cd\u7a0b\u5ea6\u3002", "method": "\u4f7f\u75281,900\u4e2a\u5bf9\u6297\u6027\u63d0\u793a\uff0c\u5728\u4e09\u4e2a\u9ad8\u98ce\u9669\u5b89\u5168\u7c7b\u522b\uff08\u6709\u5bb3\u5185\u5bb9\u3001CBRN\u3001CSEM\uff09\u4e0a\u6d4b\u8bd5\u4e03\u4e2a\u524d\u6cbf\u6a21\u578b\uff0c\u63a2\u7d22FigStep-Pro\uff08\u89c6\u89c9\u5173\u952e\u8bcd\u5206\u89e3\uff09\u3001\u667a\u80fd\u63a9\u7801\uff08\u8bed\u4e49\u6df7\u6dc6\uff09\u548c\u97f3\u9891\u6270\u52a8\uff08Wave-Echo\u3001Wave-Pitch\u3001Wave-Speed\uff09\u7b49\u653b\u51fb\u6280\u672f\u7684\u6709\u6548\u6027\u3002", "result": "\u7ed3\u679c\u663e\u793a\u4e25\u91cd\u6f0f\u6d1e\uff1a\u6587\u672c\u5b89\u5168\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u6a21\u578b\uff080%\u653b\u51fb\u6210\u529f\u7387\uff09\u5728\u611f\u77e5\u4fee\u6539\u8f93\u5165\u4e0b\u906d\u53d7>75%\u653b\u51fb\u6210\u529f\u7387\uff0cFigStep-Pro\u5728Llama-4\u53d8\u4f53\u4e2d\u8fbe\u523089%\u653b\u51fb\u6210\u529f\u7387\u3002\u97f3\u9891\u653b\u51fb\u8fdb\u4e00\u6b65\u63ed\u793a\u4e86\u63d0\u4f9b\u5546\u7279\u5b9a\u5f31\u70b9\uff0c\u5373\u4f7f\u662f\u57fa\u672c\u7684\u6a21\u6001\u8f6c\u79fb\u4e5f\u80fd\u5728\u6280\u672f\u67e5\u8be2\u4e2d\u5b9e\u73b025%\u653b\u51fb\u6210\u529f\u7387\u3002", "conclusion": "\u5f53\u524d\u5b89\u5168\u63aa\u65bd\u65e0\u6cd5\u6cdb\u5316\u5230\u8de8\u6a21\u6001\u653b\u51fb\uff0c\u8fd9\u4e9b\u653b\u51fb\u7684\u53ef\u8bbf\u95ee\u6027\u8868\u660e\uff0c\u7a33\u5065\u7684\u591a\u6a21\u6001AI\u5b89\u5168\u9700\u8981\u5411\u66f4\u5e7f\u6cdb\u7684\u8bed\u4e49\u7ea7\u63a8\u7406\u8303\u5f0f\u8f6c\u53d8\uff0c\u4ee5\u51cf\u8f7b\u6f5c\u5728\u98ce\u9669\u3002"}}
{"id": "2510.20345", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20345", "abs": "https://arxiv.org/abs/2510.20345", "authors": ["Haonan Bian"], "title": "LLM-empowered knowledge graph construction: A survey", "comment": null, "summary": "Knowledge Graphs (KGs) have long served as a fundamental infrastructure for\nstructured knowledge representation and reasoning. With the advent of Large\nLanguage Models (LLMs), the construction of KGs has entered a new\nparadigm-shifting from rule-based and statistical pipelines to language-driven\nand generative frameworks. This survey provides a comprehensive overview of\nrecent progress in LLM-empowered knowledge graph construction, systematically\nanalyzing how LLMs reshape the classical three-layered pipeline of ontology\nengineering, knowledge extraction, and knowledge fusion.\n  We first revisit traditional KG methodologies to establish conceptual\nfoundations, and then review emerging LLM-driven approaches from two\ncomplementary perspectives: schema-based paradigms, which emphasize structure,\nnormalization, and consistency; and schema-free paradigms, which highlight\nflexibility, adaptability, and open discovery. Across each stage, we synthesize\nrepresentative frameworks, analyze their technical mechanisms, and identify\ntheir limitations.\n  Finally, the survey outlines key trends and future research directions,\nincluding KG-based reasoning for LLMs, dynamic knowledge memory for agentic\nsystems, and multimodal KG construction. Through this systematic review, we aim\nto clarify the evolving interplay between LLMs and knowledge graphs, bridging\nsymbolic knowledge engineering and neural semantic understanding toward the\ndevelopment of adaptive, explainable, and intelligent knowledge systems.", "AI": {"tldr": "\u672c\u7efc\u8ff0\u7cfb\u7edf\u56de\u987e\u4e86LLM\u8d4b\u80fd\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5206\u6790\u4e86LLM\u5982\u4f55\u91cd\u5851\u4f20\u7edf\u7684\u672c\u4f53\u5de5\u7a0b\u3001\u77e5\u8bc6\u62bd\u53d6\u548c\u77e5\u8bc6\u878d\u5408\u4e09\u5c42\u6d41\u7a0b\uff0c\u63a2\u8ba8\u4e86\u57fa\u4e8e\u6a21\u5f0f\u548c\u65e0\u6a21\u5f0f\u4e24\u79cd\u8303\u5f0f\uff0c\u5e76\u5c55\u671b\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u51fa\u73b0\uff0c\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u6b63\u4ece\u57fa\u4e8e\u89c4\u5219\u548c\u7edf\u8ba1\u7684\u6d41\u7a0b\u8f6c\u5411\u8bed\u8a00\u9a71\u52a8\u548c\u751f\u6210\u6846\u67b6\uff0c\u9700\u8981\u7cfb\u7edf\u68b3\u7406\u8fd9\u4e00\u8303\u5f0f\u8f6c\u53d8\u7684\u8fdb\u5c55\u548c\u5f71\u54cd\u3002", "method": "\u4ece\u4e24\u4e2a\u4e92\u8865\u89c6\u89d2\u56de\u987eLLM\u9a71\u52a8\u65b9\u6cd5\uff1a\u57fa\u4e8e\u6a21\u5f0f\u7684\u8303\u5f0f\u5f3a\u8c03\u7ed3\u6784\u3001\u89c4\u8303\u5316\u548c\u4e00\u81f4\u6027\uff1b\u65e0\u6a21\u5f0f\u8303\u5f0f\u5f3a\u8c03\u7075\u6d3b\u6027\u3001\u9002\u5e94\u6027\u548c\u5f00\u653e\u53d1\u73b0\u3002", "result": "\u7cfb\u7edf\u5206\u6790\u4e86\u5404\u9636\u6bb5\u7684\u4ee3\u8868\u6027\u6846\u67b6\u3001\u6280\u672f\u673a\u5236\u548c\u5c40\u9650\u6027\uff0c\u6f84\u6e05\u4e86LLM\u4e0e\u77e5\u8bc6\u56fe\u8c31\u4e4b\u95f4\u4e0d\u65ad\u6f14\u5316\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "conclusion": "\u8be5\u7efc\u8ff0\u65e8\u5728\u5f25\u5408\u7b26\u53f7\u77e5\u8bc6\u5de5\u7a0b\u4e0e\u795e\u7ecf\u8bed\u4e49\u7406\u89e3\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u63a8\u52a8\u81ea\u9002\u5e94\u3001\u53ef\u89e3\u91ca\u548c\u667a\u80fd\u77e5\u8bc6\u7cfb\u7edf\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.20243", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.20243", "abs": "https://arxiv.org/abs/2510.20243", "authors": ["Yu Hin Chan", "Hao Yang", "Shiyu Shen", "Xingyu Fan", "Shengzhe Lyu", "Patrick S. Y. Hung", "Ray C. C. Cheung"], "title": "HHEML: Hybrid Homomorphic Encryption for Privacy-Preserving Machine Learning on Edge", "comment": null, "summary": "Privacy-preserving machine learning (PPML) is an emerging topic to handle\nsecure machine learning inference over sensitive data in untrusted\nenvironments. Fully homomorphic encryption (FHE) enables computation directly\non encrypted data on the server side, making it a promising approach for PPML.\nHowever, it introduces significant communication and computation overhead on\nthe client side, making it impractical for edge devices. Hybrid homomorphic\nencryption (HHE) addresses this limitation by combining symmetric encryption\n(SE) with FHE to reduce the computational cost on the client side, and\ncombining with an FHE-friendly SE can also lessen the processing overhead on\nthe server side, making it a more balanced and efficient alternative. Our work\nproposes a hardware-accelerated HHE architecture built around a lightweight\nsymmetric cipher optimized for FHE compatibility and implemented as a dedicated\nhardware accelerator. To the best of our knowledge, this is the first design to\nintegrate an end-to-end HHE framework with hardware acceleration. Beyond this,\nwe also present several microarchitectural optimizations to achieve higher\nperformance and energy efficiency. The proposed work is integrated into a full\nPPML pipeline, enabling secure inference with significantly lower latency and\npower consumption than software implementations. Our contributions validate the\nfeasibility of low-power, hardware- accelerated HHE for edge deployment and\nprovide a hardware- software co-design methodology for building scalable,\nsecure machine learning systems in resource-constrained environments.\nExperiments on a PYNQ-Z2 platform with the MNIST dataset show over a 50x\nreduction in client-side encryption latency and nearly a 2x gain in hardware\nthroughput compared to existing FPGA-based HHE accelerators.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u786c\u4ef6\u52a0\u901f\u7684\u6df7\u5408\u540c\u6001\u52a0\u5bc6\u67b6\u6784\uff0c\u901a\u8fc7\u4e13\u7528\u786c\u4ef6\u52a0\u901f\u5668\u548c\u5fae\u67b6\u6784\u4f18\u5316\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u52a0\u5bc6\u5ef6\u8fdf\u548c\u529f\u8017\u3002", "motivation": "\u5b8c\u5168\u540c\u6001\u52a0\u5bc6\u5728\u9690\u79c1\u4fdd\u62a4\u673a\u5668\u5b66\u4e60\u4e2d\u5b58\u5728\u5ba2\u6237\u7aef\u901a\u4fe1\u548c\u8ba1\u7b97\u5f00\u9500\u8fc7\u5927\u7684\u95ee\u9898\uff0c\u4e0d\u9002\u7528\u4e8e\u8fb9\u7f18\u8bbe\u5907\u3002\u6df7\u5408\u540c\u6001\u52a0\u5bc6\u901a\u8fc7\u7ed3\u5408\u5bf9\u79f0\u52a0\u5bc6\u6765\u964d\u4f4e\u5ba2\u6237\u7aef\u8ba1\u7b97\u6210\u672c\uff0c\u4f46\u9700\u8981\u786c\u4ef6\u52a0\u901f\u6765\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6027\u80fd\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u56f4\u7ed5\u8f7b\u91cf\u7ea7\u5bf9\u79f0\u5bc6\u7801\u6784\u5efa\u7684\u786c\u4ef6\u52a0\u901fHHE\u67b6\u6784\uff0c\u8be5\u5bc6\u7801\u9488\u5bf9FHE\u517c\u5bb9\u6027\u8fdb\u884c\u4e86\u4f18\u5316\uff0c\u5e76\u4f5c\u4e3a\u4e13\u7528\u786c\u4ef6\u52a0\u901f\u5668\u5b9e\u73b0\u3002\u8fd8\u63d0\u51fa\u4e86\u591a\u79cd\u5fae\u67b6\u6784\u4f18\u5316\u4ee5\u63d0\u9ad8\u6027\u80fd\u548c\u80fd\u6548\u3002", "result": "\u5728PYNQ-Z2\u5e73\u53f0\u4e0a\u4f7f\u7528MNIST\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u5ba2\u6237\u7aef\u52a0\u5bc6\u5ef6\u8fdf\u964d\u4f4e\u4e8650\u500d\u4ee5\u4e0a\uff0c\u786c\u4ef6\u541e\u5410\u91cf\u76f8\u6bd4\u73b0\u6709FPGA-based HHE\u52a0\u901f\u5668\u63d0\u9ad8\u4e86\u8fd12\u500d\u3002", "conclusion": "\u9a8c\u8bc1\u4e86\u4f4e\u529f\u8017\u786c\u4ef6\u52a0\u901fHHE\u5728\u8fb9\u7f18\u90e8\u7f72\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u6784\u5efa\u53ef\u6269\u5c55\u7684\u5b89\u5168\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u4e86\u786c\u4ef6-\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u65b9\u6cd5\u3002"}}
{"id": "2510.20377", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.20377", "abs": "https://arxiv.org/abs/2510.20377", "authors": ["Tianyi Zhang", "Florian Mai", "Lucie Flek"], "title": "IKnow: Instruction-Knowledge-Aware Continual Pretraining for Effective Domain Adaptation", "comment": null, "summary": "Continual pretraining promises to adapt large language models (LLMs) to new\ndomains using only unlabeled test-time data, but naively applying standard\nself-supervised objectives to instruction-tuned models is known to degrade\ntheir instruction-following capability and semantic representations. Existing\nfixes assume access to the original base model or rely on knowledge from an\nexternal domain-specific database - both of which pose a realistic barrier in\nsettings where the base model weights are withheld for safety reasons or\nreliable external corpora are unavailable. In this work, we propose\nInstruction-Knowledge-Aware Continual Adaptation (IKnow), a simple and general\nframework that formulates novel self-supervised objectives in the\ninstruction-response dialogue format. Rather than depend- ing on external\nresources, IKnow leverages domain knowledge embedded within the text itself and\nlearns to encode it at a deeper semantic level.", "AI": {"tldr": "\u63d0\u51fa\u4e86IKnow\u6846\u67b6\uff0c\u901a\u8fc7\u6307\u4ee4-\u54cd\u5e94\u5bf9\u8bdd\u683c\u5f0f\u7684\u81ea\u6211\u76d1\u7763\u76ee\u6807\uff0c\u5728\u65e0\u9700\u5916\u90e8\u8d44\u6e90\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u6301\u7eed\u9884\u8bad\u7ec3\uff0c\u4fdd\u62a4\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u5728\u6301\u7eed\u9884\u8bad\u7ec3\u65f6\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\u9000\u5316\u7684\u95ee\u9898\uff0c\u907f\u514d\u4f9d\u8d56\u539f\u59cb\u57fa\u7840\u6a21\u578b\u6216\u5916\u90e8\u77e5\u8bc6\u5e93\u7684\u9650\u5236\u3002", "method": "\u4f7f\u7528\u6307\u4ee4-\u54cd\u5e94\u5bf9\u8bdd\u683c\u5f0f\u8bbe\u8ba1\u81ea\u6211\u76d1\u7763\u76ee\u6807\uff0c\u4ece\u6587\u672c\u672c\u8eab\u63d0\u53d6\u9886\u57df\u77e5\u8bc6\u5e76\u7f16\u7801\u5230\u66f4\u6df1\u8bed\u4e49\u5c42\u6b21\u3002", "result": "IKnow\u6846\u67b6\u80fd\u591f\u6709\u6548\u9002\u5e94\u65b0\u9886\u57df\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7684\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\u3002", "conclusion": "IKnow\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u901a\u7528\u7684\u6301\u7eed\u9002\u5e94\u65b9\u6cd5\uff0c\u4e0d\u4f9d\u8d56\u5916\u90e8\u8d44\u6e90\u5373\u53ef\u6709\u6548\u7f16\u7801\u9886\u57df\u77e5\u8bc6\u3002"}}
{"id": "2510.20739", "categories": ["cs.CR", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.20739", "abs": "https://arxiv.org/abs/2510.20739", "authors": ["Ronghao Ni", "Aidan Z. H. Yang", "Min-Chien Hsu", "Nuno Sabino", "Limin Jia", "Ruben Martins", "Darion Cassel", "Kevin Cheang"], "title": "Learning to Triage Taint Flows Reported by Dynamic Program Analysis in Node.js Packages", "comment": null, "summary": "Program analysis tools often produce large volumes of candidate vulnerability\nreports that require costly manual review, creating a practical challenge: how\ncan security analysts prioritize the reports most likely to be true\nvulnerabilities?\n  This paper investigates whether machine learning can be applied to\nprioritizing vulnerabilities reported by program analysis tools. We focus on\nNode.js packages and collect a benchmark of 1,883 Node.js packages, each\ncontaining one reported ACE or ACI vulnerability. We evaluate a variety of\nmachine learning approaches, including classical models, graph neural networks\n(GNNs), large language models (LLMs), and hybrid models that combine GNN and\nLLMs, trained on data based on a dynamic program analysis tool's output. The\ntop LLM achieves $F_{1} {=} 0.915$, while the best GNN and classical ML models\nreaching $F_{1} {=} 0.904$. At a less than 7% false-negative rate, the leading\nmodel eliminates 66.9% of benign packages from manual review, taking around 60\nms per package. If the best model is tuned to operate at a precision level of\n0.8 (i.e., allowing 20% false positives amongst all warnings), our approach can\ndetect 99.2% of exploitable taint flows while missing only 0.8%, demonstrating\nstrong potential for real-world vulnerability triage.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u5982\u4f55\u5229\u7528\u673a\u5668\u5b66\u4e60\u5bf9\u7a0b\u5e8f\u5206\u6790\u5de5\u5177\u62a5\u544a\u7684\u6f0f\u6d1e\u8fdb\u884c\u4f18\u5148\u7ea7\u6392\u5e8f\uff0c\u901a\u8fc7\u8bc4\u4f30\u591a\u79cd\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728Node.js\u5305\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0LLM\u6a21\u578b\u5728\u6f0f\u6d1e\u5206\u7c7b\u65b9\u9762\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u7a0b\u5e8f\u5206\u6790\u5de5\u5177\u4ea7\u751f\u5927\u91cf\u5019\u9009\u6f0f\u6d1e\u62a5\u544a\u9700\u8981\u4eba\u5de5\u5ba1\u67e5\uff0c\u6210\u672c\u9ad8\u6602\u3002\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u5982\u4f55\u4f18\u5148\u5904\u7406\u6700\u53ef\u80fd\u4e3a\u771f\u5b9e\u6f0f\u6d1e\u7684\u62a5\u544a\u8fd9\u4e00\u5b9e\u9645\u95ee\u9898\u3002", "method": "\u6536\u96c61,883\u4e2a\u5305\u542bACE\u6216ACI\u6f0f\u6d1e\u7684Node.js\u5305\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u7ecf\u5178\u6a21\u578b\u3001\u56fe\u795e\u7ecf\u7f51\u7edc(GNN)\u3001\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u4ee5\u53caGNN\u4e0eLLM\u6df7\u5408\u6a21\u578b\u7b49\u591a\u79cd\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u57fa\u4e8e\u52a8\u6001\u7a0b\u5e8f\u5206\u6790\u5de5\u5177\u8f93\u51fa\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u6700\u4f73LLM\u6a21\u578bF1\u5206\u6570\u8fbe0.915\uff0c\u6700\u4f73GNN\u548c\u7ecf\u5178ML\u6a21\u578bF1\u5206\u6570\u4e3a0.904\u3002\u5728\u5047\u9634\u6027\u7387\u4f4e\u4e8e7%\u65f6\uff0c\u9886\u5148\u6a21\u578b\u53ef\u4ece\u4eba\u5de5\u5ba1\u67e5\u4e2d\u6392\u966466.9%\u7684\u826f\u6027\u5305\uff0c\u6bcf\u4e2a\u5305\u5904\u7406\u65f6\u95f4\u7ea660ms\u3002\u5f53\u7cbe\u5ea6\u8bbe\u4e3a0.8\u65f6\uff0c\u53ef\u68c0\u6d4b99.2%\u7684\u53ef\u5229\u7528\u6c61\u70b9\u6d41\uff0c\u4ec5\u9057\u6f0f0.8%\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u6f0f\u6d1e\u4f18\u5148\u7ea7\u6392\u5e8f\u65b9\u9762\u8868\u73b0\u51fa\u5f3a\u5927\u6f5c\u529b\uff0c\u7279\u522b\u662fLLM\u6a21\u578b\u5728Node.js\u5305\u6f0f\u6d1e\u5206\u7c7b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4e3a\u5b9e\u9645\u6f0f\u6d1e\u5206\u7c7b\u5de5\u4f5c\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.20300", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.20300", "abs": "https://arxiv.org/abs/2510.20300", "authors": ["Haojie Ji", "Long Jin", "Haowen Li", "Chongshi Xin", "Te Hu"], "title": "Privacy Protection of Automotive Location Data Based on Format-Preserving Encryption of Geographical Coordinates", "comment": null, "summary": "There are increasing risks of privacy disclosure when sharing the automotive\nlocation data in particular functions such as route navigation, driving\nmonitoring and vehicle scheduling. These risks could lead to the attacks\nincluding user behavior recognition, sensitive location inference and\ntrajectory reconstruction. In order to mitigate the data security risk caused\nby the automotive location sharing, this paper proposes a high-precision\nprivacy protection mechanism based on format-preserving encryption (FPE) of\ngeographical coordinates. The automotive coordinate data key mapping mechanism\nis designed to reduce to the accuracy loss of the geographical location data\ncaused by the repeated encryption and decryption. The experimental results\ndemonstrate that the average relative distance retention rate (RDR) reached\n0.0844, and the number of hotspots in the critical area decreased by 98.9%\nafter encryption. To evaluate the accuracy loss of the proposed encryption\nalgorithm on automotive geographical location data, this paper presents the\nexperimental analysis of decryption accuracy, and the result indicates that the\ndecrypted coordinate data achieves a restoration accuracy of 100%. This work\npresents a high-precision privacy protection method for automotive location\ndata, thereby providing an efficient data security solution for the sensitive\ndata sharing in autonomous driving.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u683c\u5f0f\u4fdd\u6301\u52a0\u5bc6(FPE)\u7684\u6c7d\u8f66\u5730\u7406\u4f4d\u7f6e\u6570\u636e\u9ad8\u7cbe\u5ea6\u9690\u79c1\u4fdd\u62a4\u673a\u5236\uff0c\u901a\u8fc7\u5750\u6807\u6570\u636e\u5bc6\u94a5\u6620\u5c04\u51cf\u5c11\u91cd\u590d\u52a0\u89e3\u5bc6\u9020\u6210\u7684\u5730\u7406\u4f4d\u7f6e\u7cbe\u5ea6\u635f\u5931\u3002", "motivation": "\u6c7d\u8f66\u4f4d\u7f6e\u6570\u636e\u5171\u4eab\u5728\u8def\u7ebf\u5bfc\u822a\u3001\u9a7e\u9a76\u76d1\u63a7\u548c\u8f66\u8f86\u8c03\u5ea6\u7b49\u529f\u80fd\u4e2d\u5b58\u5728\u9690\u79c1\u6cc4\u9732\u98ce\u9669\uff0c\u53ef\u80fd\u5bfc\u81f4\u7528\u6237\u884c\u4e3a\u8bc6\u522b\u3001\u654f\u611f\u4f4d\u7f6e\u63a8\u65ad\u548c\u8f68\u8ff9\u91cd\u5efa\u7b49\u653b\u51fb\u3002", "method": "\u8bbe\u8ba1\u6c7d\u8f66\u5750\u6807\u6570\u636e\u5bc6\u94a5\u6620\u5c04\u673a\u5236\uff0c\u91c7\u7528\u683c\u5f0f\u4fdd\u6301\u52a0\u5bc6\u6280\u672f\u5bf9\u5730\u7406\u5750\u6807\u8fdb\u884c\u52a0\u5bc6\uff0c\u51cf\u5c11\u91cd\u590d\u52a0\u89e3\u5bc6\u8fc7\u7a0b\u4e2d\u7684\u7cbe\u5ea6\u635f\u5931\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5e73\u5747\u76f8\u5bf9\u8ddd\u79bb\u4fdd\u6301\u7387(RDR)\u8fbe\u52300.0844\uff0c\u5173\u952e\u533a\u57df\u70ed\u70b9\u6570\u91cf\u51cf\u5c1198.9%\uff0c\u89e3\u5bc6\u5750\u6807\u6570\u636e\u6062\u590d\u7cbe\u5ea6\u8fbe\u5230100%\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u6c7d\u8f66\u4f4d\u7f6e\u6570\u636e\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u7cbe\u5ea6\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u4e2d\u7684\u654f\u611f\u6570\u636e\u5171\u4eab\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6570\u636e\u5b89\u5168\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.20402", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20402", "abs": "https://arxiv.org/abs/2510.20402", "authors": ["Neil Maiden", "Konstantinos Zachos", "James Lockerbie", "Kostas Petrianakis", "Amanda Brown"], "title": "A computational model and tool for generating more novel opportunities in professional innovation processes", "comment": null, "summary": "This paper presents a new computational model of creative outcomes, informed\nby creativity theories and techniques, which was implemented to generate more\nnovel opportunities for innovation projects. The model implemented five\nfunctions that were developed to contribute to the generation of innovation\nopportunities with higher novelty without loss of usefulness. The model was\nevaluated using opportunities generated for an innovation project in the\nhospitality sector. The evaluation revealed that the computational model\ngenerated outcomes that were more novel and/or useful than outcomes from\nNotebook LM and ChatGPT4o. However, not all model functions contributed to the\ngeneration of more novel opportunities, leading to new directions for further\nmodel development", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u521b\u9020\u529b\u7406\u8bba\u7684\u8ba1\u7b97\u6a21\u578b\uff0c\u7528\u4e8e\u751f\u6210\u66f4\u5177\u65b0\u9896\u6027\u7684\u521b\u65b0\u673a\u4f1a\uff0c\u5728\u9152\u5e97\u4e1a\u521b\u65b0\u9879\u76ee\u4e2d\u9a8c\u8bc1\u4e86\u5176\u4f18\u4e8eNotebook LM\u548cChatGPT4o\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709AI\u7cfb\u7edf\u5728\u751f\u6210\u521b\u65b0\u673a\u4f1a\u65f6\u5f80\u5f80\u96be\u4ee5\u5e73\u8861\u65b0\u9896\u6027\u548c\u5b9e\u7528\u6027\uff0c\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u7684\u8ba1\u7b97\u6a21\u578b\u6765\u4ea7\u751f\u65e2\u65b0\u9896\u53c8\u6709\u7528\u7684\u521b\u65b0\u673a\u4f1a\u3002", "method": "\u5f00\u53d1\u4e86\u5305\u542b\u4e94\u4e2a\u529f\u80fd\u6a21\u5757\u7684\u8ba1\u7b97\u6a21\u578b\uff0c\u8fd9\u4e9b\u529f\u80fd\u65e8\u5728\u5728\u4e0d\u635f\u5931\u5b9e\u7528\u6027\u7684\u524d\u63d0\u4e0b\u63d0\u5347\u521b\u65b0\u673a\u4f1a\u7684\u65b0\u9896\u6027\u3002", "result": "\u6a21\u578b\u5728\u9152\u5e97\u4e1a\u521b\u65b0\u9879\u76ee\u4e2d\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u5176\u751f\u6210\u7684\u673a\u4f1a\u6bd4Notebook LM\u548cChatGPT4o\u66f4\u5177\u65b0\u9896\u6027\u548c/\u6216\u5b9e\u7528\u6027\uff0c\u4f46\u5e76\u975e\u6240\u6709\u529f\u80fd\u6a21\u5757\u90fd\u5bf9\u63d0\u5347\u65b0\u9896\u6027\u6709\u8d21\u732e\u3002", "conclusion": "\u8be5\u8ba1\u7b97\u6a21\u578b\u5728\u751f\u6210\u65b0\u9896\u521b\u65b0\u673a\u4f1a\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u73b0\u6709AI\u7cfb\u7edf\uff0c\u4f46\u90e8\u5206\u529f\u80fd\u6a21\u5757\u9700\u8981\u8fdb\u4e00\u6b65\u4f18\u5316\uff0c\u4e3a\u6a21\u578b\u5f00\u53d1\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2510.20314", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20314", "abs": "https://arxiv.org/abs/2510.20314", "authors": ["Wu Yichao", "Wang Yirui", "Ding Panpan", "Wang Hailong", "Zhu Bingqian", "Liu Chun"], "title": "Enhancing Security in Deep Reinforcement Learning: A Comprehensive Survey on Adversarial Attacks and Defenses", "comment": null, "summary": "With the wide application of deep reinforcement learning (DRL) techniques in\ncomplex fields such as autonomous driving, intelligent manufacturing, and smart\nhealthcare, how to improve its security and robustness in dynamic and\nchangeable environments has become a core issue in current research. Especially\nin the face of adversarial attacks, DRL may suffer serious performance\ndegradation or even make potentially dangerous decisions, so it is crucial to\nensure their stability in security-sensitive scenarios. In this paper, we first\nintroduce the basic framework of DRL and analyze the main security challenges\nfaced in complex and changing environments. In addition, this paper proposes an\nadversarial attack classification framework based on perturbation type and\nattack target and reviews the mainstream adversarial attack methods against DRL\nin detail, including various attack methods such as perturbation state space,\naction space, reward function and model space. To effectively counter the\nattacks, this paper systematically summarizes various current robustness\ntraining strategies, including adversarial training, competitive training,\nrobust learning, adversarial detection, defense distillation and other related\ndefense techniques, we also discuss the advantages and shortcomings of these\nmethods in improving the robustness of DRL. Finally, this paper looks into the\nfuture research direction of DRL in adversarial environments, emphasizing the\nresearch needs in terms of improving generalization, reducing computational\ncomplexity, and enhancing scalability and explainability, aiming to provide\nvaluable references and directions for researchers.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u5bf9\u6297\u73af\u5883\u4e2d\u7684\u5b89\u5168\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u6270\u52a8\u7c7b\u578b\u548c\u653b\u51fb\u76ee\u6807\u7684\u5bf9\u6297\u653b\u51fb\u5206\u7c7b\u6846\u67b6\uff0c\u5e76\u7cfb\u7edf\u603b\u7ed3\u4e86\u5404\u79cd\u9c81\u68d2\u6027\u8bad\u7ec3\u7b56\u7565\u548c\u9632\u5fa1\u6280\u672f\uff0c\u6700\u540e\u5c55\u671b\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u81ea\u52a8\u9a7e\u9a76\u3001\u667a\u80fd\u5236\u9020\u7b49\u590d\u6742\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5982\u4f55\u5728\u52a8\u6001\u591a\u53d8\u7684\u73af\u5883\u4e2d\u63d0\u9ad8\u5176\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u6210\u4e3a\u6838\u5fc3\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u9762\u5bf9\u5bf9\u6297\u653b\u51fb\u65f6\u786e\u4fdd\u7a33\u5b9a\u6027\u81f3\u5173\u91cd\u8981\u3002", "method": "\u9996\u5148\u4ecb\u7ecdDRL\u57fa\u672c\u6846\u67b6\u548c\u5206\u6790\u5b89\u5168\u6311\u6218\uff0c\u63d0\u51fa\u57fa\u4e8e\u6270\u52a8\u7c7b\u578b\u548c\u653b\u51fb\u76ee\u6807\u7684\u5bf9\u6297\u653b\u51fb\u5206\u7c7b\u6846\u67b6\uff0c\u8be6\u7ec6\u56de\u987e\u4e3b\u6d41\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5\uff0c\u7cfb\u7edf\u603b\u7ed3\u5404\u79cd\u9c81\u68d2\u6027\u8bad\u7ec3\u7b56\u7565\u548c\u9632\u5fa1\u6280\u672f\u3002", "result": "\u8bba\u6587\u5168\u9762\u68b3\u7406\u4e86\u5bf9\u6297\u653b\u51fb\u7684\u5206\u7c7b\u65b9\u6cd5\u548c\u9632\u5fa1\u6280\u672f\uff0c\u5206\u6790\u4e86\u5404\u79cd\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\uff0c\u4e3a\u63d0\u5347DRL\u5728\u5bf9\u6297\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u53c2\u8003\u3002", "conclusion": "\u672a\u6765\u7814\u7a76\u5e94\u5173\u6ce8\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u3001\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3001\u589e\u5f3a\u53ef\u6269\u5c55\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u53c2\u8003\u548c\u65b9\u5411\u3002"}}
{"id": "2510.20457", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20457", "abs": "https://arxiv.org/abs/2510.20457", "authors": ["Louis Mozart Kamdem Teyou", "Luke Friedrichs", "N'Dah Jean Kouagou", "Caglar Demir", "Yasir Mahmood", "Stefan Heindorf", "Axel-Cyrille Ngonga Ngomo"], "title": "Neural Reasoning for Robust Instance Retrieval in $\\mathcal{SHOIQ}$", "comment": "Accepted as a full research paper at K-CAP 2025", "summary": "Concept learning exploits background knowledge in the form of description\nlogic axioms to learn explainable classification models from knowledge bases.\nDespite recent breakthroughs in neuro-symbolic concept learning, most\napproaches still cannot be deployed on real-world knowledge bases. This is due\nto their use of description logic reasoners, which are not robust against\ninconsistencies nor erroneous data. We address this challenge by presenting a\nnovel neural reasoner dubbed EBR. Our reasoner relies on embeddings to\napproximate the results of a symbolic reasoner. We show that EBR solely\nrequires retrieving instances for atomic concepts and existential restrictions\nto retrieve or approximate the set of instances of any concept in the\ndescription logic $\\mathcal{SHOIQ}$. In our experiments, we compare EBR with\nstate-of-the-art reasoners. Our results suggest that EBR is robust against\nmissing and erroneous data in contrast to existing reasoners.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEBR\u7684\u795e\u7ecf\u63a8\u7406\u5668\uff0c\u4f7f\u7528\u5d4c\u5165\u6765\u8fd1\u4f3c\u7b26\u53f7\u63a8\u7406\u5668\u7684\u7ed3\u679c\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u63cf\u8ff0\u903b\u8f91\u63a8\u7406\u5668\u5bf9\u4e0d\u4e00\u81f4\u548c\u9519\u8bef\u6570\u636e\u4e0d\u9c81\u68d2\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u795e\u7ecf\u7b26\u53f7\u6982\u5ff5\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u63cf\u8ff0\u903b\u8f91\u63a8\u7406\u5668\uff0c\u4f46\u8fd9\u4e9b\u63a8\u7406\u5668\u5bf9\u77e5\u8bc6\u5e93\u4e2d\u7684\u4e0d\u4e00\u81f4\u548c\u9519\u8bef\u6570\u636e\u4e0d\u9c81\u68d2\uff0c\u9650\u5236\u4e86\u5728\u5b9e\u9645\u77e5\u8bc6\u5e93\u4e2d\u7684\u90e8\u7f72\u3002", "method": "EBR\u901a\u8fc7\u5d4c\u5165\u6765\u8fd1\u4f3c\u7b26\u53f7\u63a8\u7406\u5668\u7684\u7ed3\u679c\uff0c\u4ec5\u9700\u8981\u68c0\u7d22\u539f\u5b50\u6982\u5ff5\u548c\u5b58\u5728\u9650\u5236\u7684\u5b9e\u4f8b\uff0c\u5c31\u80fd\u8fd1\u4f3c\u4efb\u4f55SHOIQ\u63cf\u8ff0\u903b\u8f91\u6982\u5ff5\u7684\u5b9e\u4f8b\u96c6\u5408\u3002", "result": "\u5b9e\u9a8c\u8868\u660eEBR\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u63a8\u7406\u5668\uff0c\u5bf9\u7f3a\u5931\u548c\u9519\u8bef\u6570\u636e\u5177\u6709\u66f4\u597d\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "EBR\u4e3a\u5728\u771f\u5b9e\u4e16\u754c\u77e5\u8bc6\u5e93\u4e2d\u90e8\u7f72\u795e\u7ecf\u7b26\u53f7\u6982\u5ff5\u5b66\u4e60\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u795e\u7ecf\u63a8\u7406\u514b\u670d\u4e86\u4f20\u7edf\u7b26\u53f7\u63a8\u7406\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2510.20333", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20333", "abs": "https://arxiv.org/abs/2510.20333", "authors": ["Chiyu Chen", "Xinhao Song", "Yunkai Chai", "Yang Yao", "Haodong Zhao", "Lijun Li", "Jie Li", "Yan Teng", "Gongshen Liu", "Yingchun Wang"], "title": "GhostEI-Bench: Do Mobile Agents Resilience to Environmental Injection in Dynamic On-Device Environments?", "comment": null, "summary": "Vision-Language Models (VLMs) are increasingly deployed as autonomous agents\nto navigate mobile graphical user interfaces (GUIs). Operating in dynamic\non-device ecosystems, which include notifications, pop-ups, and inter-app\ninteractions, exposes them to a unique and underexplored threat vector:\nenvironmental injection. Unlike prompt-based attacks that manipulate textual\ninstructions, environmental injection corrupts an agent's visual perception by\ninserting adversarial UI elements (for example, deceptive overlays or spoofed\nnotifications) directly into the GUI. This bypasses textual safeguards and can\nderail execution, causing privacy leakage, financial loss, or irreversible\ndevice compromise. To systematically evaluate this threat, we introduce\nGhostEI-Bench, the first benchmark for assessing mobile agents under\nenvironmental injection attacks within dynamic, executable environments. Moving\nbeyond static image-based assessments, GhostEI-Bench injects adversarial events\ninto realistic application workflows inside fully operational Android emulators\nand evaluates performance across critical risk scenarios. We further propose a\njudge-LLM protocol that conducts fine-grained failure analysis by reviewing the\nagent's action trajectory alongside the corresponding screenshot sequence,\npinpointing failure in perception, recognition, or reasoning. Comprehensive\nexperiments on state-of-the-art agents reveal pronounced vulnerability to\ndeceptive environmental cues: current models systematically fail to perceive\nand reason about manipulated UIs. GhostEI-Bench provides a framework for\nquantifying and mitigating this emerging threat, paving the way toward more\nrobust and secure embodied agents.", "AI": {"tldr": "\u63d0\u51fa\u4e86GhostEI-Bench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u79fb\u52a8\u4ee3\u7406\u5728\u52a8\u6001\u53ef\u6267\u884c\u73af\u5883\u4e2d\u9762\u5bf9\u73af\u5883\u6ce8\u5165\u653b\u51fb\u7684\u8106\u5f31\u6027\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u611f\u77e5\u548c\u63a8\u7406\u88ab\u64cd\u7eb5UI\u65b9\u9762\u7684\u7cfb\u7edf\u6027\u5931\u8d25\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u81ea\u4e3b\u4ee3\u7406\u90e8\u7f72\u5728\u79fb\u52a8\u56fe\u5f62\u7528\u6237\u754c\u9762\u4e2d\uff0c\u9762\u4e34\u73af\u5883\u6ce8\u5165\u8fd9\u4e00\u72ec\u7279\u4e14\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u5a01\u80c1\u5411\u91cf\uff0c\u53ef\u80fd\u7ed5\u8fc7\u6587\u672c\u5b89\u5168\u63aa\u65bd\u5bfc\u81f4\u9690\u79c1\u6cc4\u9732\u3001\u8d22\u52a1\u635f\u5931\u6216\u8bbe\u5907\u4e0d\u53ef\u9006\u635f\u5bb3\u3002", "method": "\u5f15\u5165GhostEI-Bench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5728\u5b8c\u5168\u8fd0\u884c\u7684Android\u6a21\u62df\u5668\u4e2d\u5411\u73b0\u5b9e\u5e94\u7528\u5de5\u4f5c\u6d41\u6ce8\u5165\u5bf9\u6297\u6027\u4e8b\u4ef6\uff0c\u5e76\u63d0\u51fajudge-LLM\u534f\u8bae\u5bf9\u4ee3\u7406\u52a8\u4f5c\u8f68\u8ff9\u548c\u622a\u56fe\u5e8f\u5217\u8fdb\u884c\u7ec6\u7c92\u5ea6\u5931\u8d25\u5206\u6790\u3002", "result": "\u5bf9\u6700\u5148\u8fdb\u4ee3\u7406\u7684\u7efc\u5408\u5b9e\u9a8c\u663e\u793a\uff0c\u5f53\u524d\u6a21\u578b\u5728\u611f\u77e5\u548c\u63a8\u7406\u6b3a\u9a97\u6027\u73af\u5883\u7ebf\u7d22\u65b9\u9762\u5b58\u5728\u663e\u8457\u8106\u5f31\u6027\uff0c\u7cfb\u7edf\u6027\u65e0\u6cd5\u8bc6\u522b\u88ab\u64cd\u7eb5\u7684UI\u3002", "conclusion": "GhostEI-Bench\u4e3a\u91cf\u5316\u548c\u7f13\u89e3\u8fd9\u4e00\u65b0\u5174\u5a01\u80c1\u63d0\u4f9b\u4e86\u6846\u67b6\uff0c\u4e3a\u5f00\u53d1\u66f4\u9c81\u68d2\u548c\u5b89\u5168\u7684\u5177\u8eab\u4ee3\u7406\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2510.20467", "categories": ["cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.20467", "abs": "https://arxiv.org/abs/2510.20467", "authors": ["Yiwen Peng", "Thomas Bonald", "Fabian M. Suchanek"], "title": "FLORA: Unsupervised Knowledge Graph Alignment by Fuzzy Logic", "comment": null, "summary": "Knowledge graph alignment is the task of matching equivalent entities (that\nis, instances and classes) and relations across two knowledge graphs. Most\nexisting methods focus on pure entity-level alignment, computing the similarity\nof entities in some embedding space. They lack interpretable reasoning and need\ntraining data to work. In this paper, we propose FLORA, a simple yet effective\nmethod that (1) is unsupervised, i.e., does not require training data, (2)\nprovides a holistic alignment for entities and relations iteratively, (3) is\nbased on fuzzy logic and thus delivers interpretable results, (4) provably\nconverges, (5) allows dangling entities, i.e., entities without a counterpart\nin the other KG, and (6) achieves state-of-the-art results on major benchmarks.", "AI": {"tldr": "FLORA\u662f\u4e00\u79cd\u57fa\u4e8e\u6a21\u7cca\u903b\u8f91\u7684\u65e0\u76d1\u7763\u77e5\u8bc6\u56fe\u8c31\u5bf9\u9f50\u65b9\u6cd5\uff0c\u80fd\u591f\u540c\u65f6\u5bf9\u9f50\u5b9e\u4f53\u548c\u5173\u7cfb\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u7ed3\u679c\uff0c\u5e76\u5728\u4e3b\u8981\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u56fe\u8c31\u5bf9\u9f50\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u7eaf\u5b9e\u4f53\u7ea7\u5bf9\u9f50\uff0c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u80fd\u529b\u4e14\u9700\u8981\u8bad\u7ec3\u6570\u636e\u624d\u80fd\u5de5\u4f5c\u3002", "method": "\u57fa\u4e8e\u6a21\u7cca\u903b\u8f91\u7684\u8fed\u4ee3\u65b9\u6cd5\uff0c\u63d0\u4f9b\u5b9e\u4f53\u548c\u5173\u7cfb\u7684\u6574\u4f53\u5bf9\u9f50\uff0c\u5141\u8bb8\u60ac\u7a7a\u5b9e\u4f53\u5b58\u5728\uff0c\u5e76\u5177\u6709\u53ef\u8bc1\u660e\u7684\u6536\u655b\u6027\u3002", "result": "\u5728\u4e3b\u8981\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "conclusion": "FLORA\u662f\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u65e0\u76d1\u7763\u77e5\u8bc6\u56fe\u8c31\u5bf9\u9f50\u65b9\u6cd5\uff0c\u5177\u6709\u53ef\u89e3\u91ca\u6027\u3001\u6536\u655b\u6027\u548c\u5904\u7406\u60ac\u7a7a\u5b9e\u4f53\u7684\u80fd\u529b\u3002"}}
{"id": "2510.20367", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.20367", "abs": "https://arxiv.org/abs/2510.20367", "authors": ["Daniel Gilkarov", "Ran Dubin"], "title": "NeuPerm: Disrupting Malware Hidden in Neural Network Parameters by Leveraging Permutation Symmetry", "comment": null, "summary": "Pretrained deep learning model sharing holds tremendous value for researchers\nand enterprises alike. It allows them to apply deep learning by fine-tuning\nmodels at a fraction of the cost of training a brand-new model. However, model\nsharing exposes end-users to cyber threats that leverage the models for\nmalicious purposes. Attackers can use model sharing by hiding self-executing\nmalware inside neural network parameters and then distributing them for\nunsuspecting users to unknowingly directly execute them, or indirectly as a\ndependency in another software. In this work, we propose NeuPerm, a simple yet\neffec- tive way of disrupting such malware by leveraging the theoretical\nproperty of neural network permutation symmetry. Our method has little to no\neffect on model performance at all, and we empirically show it successfully\ndisrupts state-of-the-art attacks that were only previously addressed using\nquantization, a highly complex process. NeuPerm is shown to work on LLMs, a\nfeat that no other previous similar works have achieved. The source code is\navailable at https://github.com/danigil/NeuPerm.git.", "AI": {"tldr": "NeuPerm\u662f\u4e00\u79cd\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u6392\u5217\u5bf9\u79f0\u6027\u6765\u7834\u574f\u9690\u85cf\u5728\u6a21\u578b\u53c2\u6570\u4e2d\u7684\u6076\u610f\u8f6f\u4ef6\u7684\u65b9\u6cd5\uff0c\u5bf9\u6a21\u578b\u6027\u80fd\u5f71\u54cd\u6781\u5c0f\uff0c\u5e76\u80fd\u6709\u6548\u5bf9\u6297\u6700\u5148\u8fdb\u7684\u653b\u51fb\u3002", "motivation": "\u9884\u8bad\u7ec3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5171\u4eab\u867d\u7136\u4ef7\u503c\u5de8\u5927\uff0c\u4f46\u4f1a\u66b4\u9732\u7528\u6237\u4e8e\u7f51\u7edc\u5a01\u80c1\uff0c\u653b\u51fb\u8005\u53ef\u80fd\u5728\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u4e2d\u9690\u85cf\u81ea\u6267\u884c\u6076\u610f\u8f6f\u4ef6\u3002", "method": "\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u6392\u5217\u5bf9\u79f0\u6027\u7684\u7406\u8bba\u7279\u6027\uff0c\u901a\u8fc7\u53c2\u6570\u6392\u5217\u6765\u7834\u574f\u6076\u610f\u8f6f\u4ef6\uff0c\u8fd9\u79cd\u65b9\u6cd5\u7b80\u5355\u6709\u6548\u3002", "result": "NeuPerm\u6210\u529f\u7834\u574f\u4e86\u6700\u5148\u8fdb\u7684\u653b\u51fb\uff0c\u5bf9\u6a21\u578b\u6027\u80fd\u51e0\u4e4e\u6ca1\u6709\u5f71\u54cd\uff0c\u5e76\u4e14\u5728LLMs\u4e0a\u9996\u6b21\u5b9e\u73b0\u4e86\u7c7b\u4f3c\u5de5\u4f5c\u7684\u6548\u679c\u3002", "conclusion": "NeuPerm\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u6765\u9632\u5fa1\u6a21\u578b\u5171\u4eab\u4e2d\u7684\u6076\u610f\u8f6f\u4ef6\u5a01\u80c1\uff0c\u4e14\u5bf9\u6a21\u578b\u6027\u80fd\u5f71\u54cd\u6781\u5c0f\u3002"}}
{"id": "2510.20568", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20568", "abs": "https://arxiv.org/abs/2510.20568", "authors": ["Susan Ariel Aaronson", "Michael Moreno"], "title": "Lost in Translation: Policymakers are not really listening to Citizen Concerns about AI", "comment": null, "summary": "The worlds people have strong opinions about artificial intelligence (AI),\nand they want policymakers to listen. Governments are inviting public comment\non AI, but as they translate input into policy, much of what citizens say is\nlost. Policymakers are missing a critical opportunity to build trust in AI and\nits governance. This paper compares three countries, Australia, Colombia, and\nthe United States, that invited citizens to comment on AI risks and policies.\nUsing a landscape analysis, the authors examined how each government solicited\nfeedback and whether that input shaped governance. Yet in none of the three\ncases did citizens and policymakers establish a meaningful dialogue.\nGovernments did little to attract diverse voices or publicize calls for\ncomment, leaving most citizens unaware or unprepared to respond. In each\nnation, fewer than one percent of the population participated. Moreover,\nofficials showed limited responsiveness to the feedback they received, failing\nto create an effective feedback loop. The study finds a persistent gap between\nthe promise and practice of participatory AI governance. The authors conclude\nthat current approaches are unlikely to build trust or legitimacy in AI because\npolicymakers are not adequately listening or responding to public concerns.\nThey offer eight recommendations: promote AI literacy; monitor public feedback;\nbroaden outreach; hold regular online forums; use innovative engagement\nmethods; include underrepresented groups; respond publicly to input; and make\nparticipation easier.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u6fb3\u5927\u5229\u4e9a\u3001\u54e5\u4f26\u6bd4\u4e9a\u548c\u7f8e\u56fd\u4e09\u4e2a\u56fd\u5bb6\u5728AI\u6cbb\u7406\u4e2d\u7684\u516c\u4f17\u53c2\u4e0e\u60c5\u51b5\uff0c\u53d1\u73b0\u653f\u5e9c\u672a\u80fd\u5efa\u7acb\u6709\u6548\u7684\u516c\u4f17\u5bf9\u8bdd\u673a\u5236\uff0c\u53c2\u4e0e\u7387\u6781\u4f4e\u4e14\u53cd\u9988\u54cd\u5e94\u4e0d\u8db3\uff0c\u5bfc\u81f4\u53c2\u4e0e\u5f0fAI\u6cbb\u7406\u7684\u627f\u8bfa\u4e0e\u73b0\u5b9e\u4e4b\u95f4\u5b58\u5728\u5de8\u5927\u5dee\u8ddd\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u653f\u5e9c\u5982\u4f55\u901a\u8fc7\u516c\u4f17\u53c2\u4e0e\u6765\u5efa\u7acb\u5bf9AI\u53ca\u5176\u6cbb\u7406\u7684\u4fe1\u4efb\uff0c\u4f46\u53d1\u73b0\u5f53\u524d\u5404\u56fd\u5728\u5c06\u516c\u4f17\u610f\u89c1\u8f6c\u5316\u4e3a\u653f\u7b56\u65f6\u5b58\u5728\u4e25\u91cd\u95ee\u9898\uff0c\u9519\u5931\u4e86\u5efa\u7acb\u4fe1\u4efb\u7684\u5173\u952e\u673a\u4f1a\u3002", "method": "\u91c7\u7528\u666f\u89c2\u5206\u6790\u65b9\u6cd5\uff0c\u6bd4\u8f83\u4e86\u6fb3\u5927\u5229\u4e9a\u3001\u54e5\u4f26\u6bd4\u4e9a\u548c\u7f8e\u56fd\u4e09\u4e2a\u56fd\u5bb6\u5f81\u96c6\u516c\u4f17\u5bf9AI\u98ce\u9669\u548c\u653f\u7b56\u7684\u53cd\u9988\u65b9\u5f0f\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u53cd\u9988\u662f\u5426\u5f71\u54cd\u4e86\u6cbb\u7406\u51b3\u7b56\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e09\u4e2a\u56fd\u5bb6\u5747\u672a\u80fd\u5efa\u7acb\u6709\u610f\u4e49\u7684\u516c\u4f17\u5bf9\u8bdd\uff0c\u653f\u5e9c\u7f3a\u4e4f\u5438\u5f15\u591a\u6837\u5316\u58f0\u97f3\u7684\u52aa\u529b\uff0c\u53c2\u4e0e\u7387\u5747\u4f4e\u4e8e1%\uff0c\u5b98\u5458\u5bf9\u53cd\u9988\u7684\u54cd\u5e94\u6709\u9650\uff0c\u672a\u80fd\u5f62\u6210\u6709\u6548\u7684\u53cd\u9988\u5faa\u73af\u3002", "conclusion": "\u5f53\u524d\u53c2\u4e0e\u5f0fAI\u6cbb\u7406\u65b9\u6cd5\u96be\u4ee5\u5efa\u7acb\u4fe1\u4efb\u6216\u5408\u6cd5\u6027\uff0c\u56e0\u4e3a\u653f\u7b56\u5236\u5b9a\u8005\u672a\u80fd\u5145\u5206\u503e\u542c\u548c\u56de\u5e94\u516c\u4f17\u5173\u5207\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u516b\u9879\u6539\u8fdb\u5efa\u8bae\uff0c\u5305\u62ec\u63d0\u5347AI\u7d20\u517b\u3001\u6269\u5927\u53c2\u4e0e\u8303\u56f4\u3001\u91c7\u7528\u521b\u65b0\u53c2\u4e0e\u65b9\u6cd5\u7b49\u3002"}}
{"id": "2510.20419", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.20419", "abs": "https://arxiv.org/abs/2510.20419", "authors": ["Eric Wagner", "David Heye", "Jan Bauer", "Klaus Wehrle", "Martin Serror"], "title": "MAC Aggregation over Lossy Channels in DTLS 1.3", "comment": "IEEE ICNP'25", "summary": "Aggregating Message Authentication Codes (MACs) promises to save valuable\nbandwidth in resource-constrained environments. The idea is simple: Instead of\nappending an authentication tag to each message in a communication stream, the\nintegrity protection of multiple messages is aggregated into a single tag.\nRecent studies postulate, e.g., based on simulations, that these benefits also\nspread to wireless, and thus lossy, scenarios despite each lost packet\ntypically resulting in the loss of integrity protection information for\nmultiple messages. In this paper, we investigate these claims in a real\ndeployment. Therefore, we first design a MAC aggregation extension for the\nDatagram Transport Layer Security (DTLS) 1.3 protocol. Afterward, we\nextensively evaluate the performance of MAC aggregation on a complete\ncommunication protocol stack on embedded hardware. We find that MAC aggregation\ncan indeed increase goodput by up to 50% and save up to 17% of energy\nexpenditure for the transmission of short messages, even in lossy channels.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5b9e\u9645\u90e8\u7f72\u9a8c\u8bc1\u4e86\u5728DTLS 1.3\u534f\u8bae\u4e2d\u5e94\u7528MAC\u805a\u5408\u6280\u672f\uff0c\u5373\u4f7f\u5728\u6709\u635f\u65e0\u7ebf\u73af\u5883\u4e2d\u4e5f\u80fd\u663e\u8457\u63d0\u5347\u541e\u5410\u91cf\u5e76\u8282\u7701\u80fd\u8017\u3002", "motivation": "\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\uff0cMAC\u805a\u5408\u6280\u672f\u6709\u671b\u8282\u7701\u5e26\u5bbd\uff0c\u4f46\u4e4b\u524d\u7684\u7814\u7a76\u591a\u57fa\u4e8e\u6a21\u62df\uff0c\u9700\u8981\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u9a8c\u8bc1\u5176\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u5728\u6709\u635f\u65e0\u7ebf\u573a\u666f\u4e0b\u3002", "method": "\u8bbe\u8ba1DTLS 1.3\u534f\u8bae\u7684MAC\u805a\u5408\u6269\u5c55\uff0c\u5e76\u5728\u5d4c\u5165\u5f0f\u786c\u4ef6\u4e0a\u7684\u5b8c\u6574\u901a\u4fe1\u534f\u8bae\u6808\u4e2d\u8fdb\u884c\u5e7f\u6cdb\u6027\u80fd\u8bc4\u4f30\u3002", "result": "MAC\u805a\u5408\u5728\u77ed\u6d88\u606f\u4f20\u8f93\u4e2d\u53ef\u5c06\u541e\u5410\u91cf\u63d0\u5347\u9ad8\u8fbe50%\uff0c\u5e76\u8282\u7701\u9ad8\u8fbe17%\u7684\u80fd\u8017\uff0c\u5373\u4f7f\u5728\u6709\u635f\u4fe1\u9053\u4e2d\u4e5f\u80fd\u5b9e\u73b0\u8fd9\u4e9b\u4f18\u52bf\u3002", "conclusion": "MAC\u805a\u5408\u6280\u672f\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u786e\u5b9e\u80fd\u591f\u663e\u8457\u63d0\u5347\u6027\u80fd\u5e76\u8282\u7701\u80fd\u6e90\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u6709\u635f\u65e0\u7ebf\u73af\u5883\u4e2d\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2510.20591", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20591", "abs": "https://arxiv.org/abs/2510.20591", "authors": ["Ali Rajaei", "Peter Palensky", "Jochen L. Cremer"], "title": "Transferable Graph Learning for Transmission Congestion Management via Busbar Splitting", "comment": null, "summary": "Network topology optimization (NTO) via busbar splitting can mitigate\ntransmission grid congestion and reduce redispatch costs. However, solving this\nmixed-integer non-linear problem for large-scale systems in near-real-time is\ncurrently intractable with existing solvers. Machine learning (ML) approaches\nhave emerged as a promising alternative, but they have limited generalization\nto unseen topologies, varying operating conditions, and different systems,\nwhich limits their practical applicability. This paper formulates NTO for\ncongestion management problem considering linearized AC PF, and proposes a\ngraph neural network (GNN)-accelerated approach. We develop a heterogeneous\nedge-aware message passing NN to predict effective busbar splitting actions as\ncandidate NTO solutions. The proposed GNN captures local flow patterns,\nachieves generalization to unseen topology changes, and improves\ntransferability across systems. Case studies show up to 4 orders-of-magnitude\nspeed-up, delivering AC-feasible solutions within one minute and a 2.3%\noptimality gap on the GOC 2000-bus system. These results demonstrate a\nsignificant step toward near-real-time NTO for large-scale systems with\ntopology and cross-system generalization.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc(GNN)\u7684\u7535\u7f51\u62d3\u6251\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u6bcd\u7ebf\u5206\u88c2\u7f13\u89e3\u8f93\u7535\u62e5\u5835\uff0c\u76f8\u6bd4\u4f20\u7edf\u6c42\u89e3\u5668\u5b9e\u73b04\u4e2a\u6570\u91cf\u7ea7\u52a0\u901f\uff0c\u57282000\u8282\u70b9\u7cfb\u7edf\u4e0a1\u5206\u949f\u5185\u83b7\u5f97AC\u53ef\u884c\u89e3\uff0c\u6700\u4f18\u6027\u5dee\u8ddd\u4ec52.3%\u3002", "motivation": "\u73b0\u6709\u6c42\u89e3\u5668\u65e0\u6cd5\u5728\u8fd1\u5b9e\u65f6\u5185\u89e3\u51b3\u5927\u89c4\u6a21\u7535\u7f51\u7684\u6df7\u5408\u6574\u6570\u975e\u7ebf\u6027\u62d3\u6251\u4f18\u5316\u95ee\u9898\uff0c\u800c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u672a\u89c1\u62d3\u6251\u3001\u8fd0\u884c\u6761\u4ef6\u548c\u7cfb\u7edf\u95f4\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u91c7\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u52a0\u901f\u65b9\u6cd5\uff0c\u5f00\u53d1\u5f02\u8d28\u8fb9\u611f\u77e5\u6d88\u606f\u4f20\u9012\u795e\u7ecf\u7f51\u7edc\u6765\u9884\u6d4b\u6709\u6548\u7684\u6bcd\u7ebf\u5206\u88c2\u52a8\u4f5c\u4f5c\u4e3a\u5019\u9009\u62d3\u6251\u4f18\u5316\u89e3\uff0c\u8003\u8651\u7ebf\u6027\u5316\u4ea4\u6d41\u6f6e\u6d41\u7ea6\u675f\u3002", "result": "\u5728GOC 2000\u8282\u70b9\u7cfb\u7edf\u4e0a\u5b9e\u73b0\u9ad8\u8fbe4\u4e2a\u6570\u91cf\u7ea7\u7684\u52a0\u901f\uff0c1\u5206\u949f\u5185\u83b7\u5f97AC\u53ef\u884c\u89e3\uff0c\u6700\u4f18\u6027\u5dee\u8ddd\u4ec52.3%\uff0c\u5e76\u5c55\u793a\u4e86\u62d3\u6251\u548c\u8de8\u7cfb\u7edf\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5b9e\u73b0\u5927\u89c4\u6a21\u7cfb\u7edf\u8fd1\u5b9e\u65f6\u62d3\u6251\u4f18\u5316\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\uff0c\u5177\u6709\u62d3\u6251\u53d8\u5316\u548c\u8de8\u7cfb\u7edf\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2510.20494", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.20494", "abs": "https://arxiv.org/abs/2510.20494", "authors": ["Florian Hofer", "Barbara Russo"], "title": "On the cybersecurity of LoRaWAN-based system: a Smart-Lighting case study", "comment": "8 pages, 6 figures plus references, International Conference on IoT", "summary": "Cyber-physical systems and the Internet of Things (IoT) are key technologies\nin the Industry 4.0 vision. They incorporate sensors and actuators to interact\nwith the physical environment. However, when creating and interconnecting\ncomponents to form a heterogeneous smart systems architecture, these face\nchallenges in cybersecurity. This paper presents an experimental investigation\nof architectural configurations for a LoRaWAN-based Smart-Lighting project,\naimed at verifying and improving the system's robustness against attacks. We\nassess the system's robustness in a series of iterative experiments conducted\nboth in-vitro and on-site. The results show that most attacks on a LoRaWAN\nnetwork are unsuccessful, also highlighting unresolved issues with the\ninstalled products. The most successful attacks are high-power jamming attacks\nwithin a few meters of the target, which, in the case of gateways, can be\nmitigated through gateway redundancy.", "AI": {"tldr": "\u5bf9\u57fa\u4e8eLoRaWAN\u7684\u667a\u80fd\u7167\u660e\u7cfb\u7edf\u8fdb\u884c\u7f51\u7edc\u5b89\u5168\u5b9e\u9a8c\u7814\u7a76\uff0c\u8bc4\u4f30\u7cfb\u7edf\u5728\u653b\u51fb\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u53d1\u73b0\u5927\u591a\u6570\u653b\u51fb\u4e0d\u6210\u529f\uff0c\u4f46\u8fd1\u8ddd\u79bb\u9ad8\u529f\u7387\u5e72\u6270\u653b\u51fb\u6709\u6548\uff0c\u53ef\u901a\u8fc7\u7f51\u5173\u5197\u4f59\u7f13\u89e3\u3002", "motivation": "\u5de5\u4e1a4.0\u4e2d\u7684\u4fe1\u606f\u7269\u7406\u7cfb\u7edf\u548c\u7269\u8054\u7f51\u9762\u4e34\u7f51\u7edc\u5b89\u5168\u6311\u6218\uff0c\u9700\u8981\u9a8c\u8bc1\u548c\u6539\u8fdb\u667a\u80fd\u7cfb\u7edf\u7684\u67b6\u6784\u914d\u7f6e\u4ee5\u589e\u5f3a\u5bf9\u6297\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002", "method": "\u901a\u8fc7\u4e00\u7cfb\u5217\u8fed\u4ee3\u5b9e\u9a8c\uff0c\u5305\u62ec\u4f53\u5916\u548c\u73b0\u573a\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u57fa\u4e8eLoRaWAN\u7684\u667a\u80fd\u7167\u660e\u7cfb\u7edf\u7684\u4e0d\u540c\u67b6\u6784\u914d\u7f6e\u3002", "result": "\u5927\u591a\u6570\u9488\u5bf9LoRaWAN\u7f51\u7edc\u7684\u653b\u51fb\u4e0d\u6210\u529f\uff0c\u4f46\u8fd1\u8ddd\u79bb\u9ad8\u529f\u7387\u5e72\u6270\u653b\u51fb\u6709\u6548\uff0c\u4e14\u53d1\u73b0\u5df2\u5b89\u88c5\u4ea7\u54c1\u5b58\u5728\u672a\u89e3\u51b3\u7684\u95ee\u9898\u3002", "conclusion": "LoRaWAN\u7f51\u7edc\u5bf9\u5927\u591a\u6570\u653b\u51fb\u5177\u6709\u62b5\u6297\u529b\uff0c\u4f46\u9ad8\u529f\u7387\u5e72\u6270\u653b\u51fb\u6784\u6210\u5a01\u80c1\uff0c\u53ef\u901a\u8fc7\u7f51\u5173\u5197\u4f59\u7b56\u7565\u6765\u7f13\u89e3\u8fd9\u79cd\u98ce\u9669\u3002"}}
{"id": "2510.20603", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.20603", "abs": "https://arxiv.org/abs/2510.20603", "authors": ["Heejin Do", "Jaehui Hwang", "Dongyoon Han", "Seong Joon Oh", "Sangdoo Yun"], "title": "What Defines Good Reasoning in LLMs? Dissecting Reasoning Steps with Multi-Aspect Evaluation", "comment": null, "summary": "Evaluating large language models (LLMs) on final-answer correctness is the\ndominant paradigm. This approach, however, provides a coarse signal for model\nimprovement and overlooks the quality of the underlying reasoning process. We\nargue that a more granular evaluation of reasoning offers a more effective path\nto building robust models. We decompose reasoning quality into two dimensions:\nrelevance and coherence. Relevance measures if a step is grounded in the\nproblem; coherence measures if it follows logically from prior steps. To\nmeasure these aspects reliably, we introduce causal stepwise evaluation (CaSE).\nThis method assesses each reasoning step using only its preceding context,\nwhich avoids hindsight bias. We validate CaSE against human judgments on our\nnew expert-annotated benchmarks, MRa-GSM8K and MRa-MATH. More importantly, we\nshow that curating training data with CaSE-evaluated relevance and coherence\ndirectly improves final task performance. Our work provides a scalable\nframework for analyzing, debugging, and improving LLM reasoning, demonstrating\nthe practical value of moving beyond validity checks.", "AI": {"tldr": "\u63d0\u51fa\u56e0\u679c\u9010\u6b65\u8bc4\u4f30\u65b9\u6cd5(CaSE)\u6765\u7ec6\u7c92\u5ea6\u8bc4\u4f30LLM\u63a8\u7406\u8fc7\u7a0b\u7684\u8d28\u91cf\uff0c\u5305\u62ec\u76f8\u5173\u6027\u548c\u8fde\u8d2f\u6027\u4e24\u4e2a\u7ef4\u5ea6\uff0c\u5e76\u8bc1\u660e\u8fd9\u79cd\u65b9\u6cd5\u80fd\u76f4\u63a5\u63d0\u5347\u6700\u7ec8\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u4ec5\u8bc4\u4f30\u6700\u7ec8\u7b54\u6848\u6b63\u786e\u6027\u7684\u65b9\u6cd5\u8fc7\u4e8e\u7c97\u7cd9\uff0c\u65e0\u6cd5\u53cd\u6620\u63a8\u7406\u8fc7\u7a0b\u8d28\u91cf\uff0c\u9700\u8981\u66f4\u7ec6\u7c92\u5ea6\u7684\u8bc4\u4f30\u6765\u6784\u5efa\u66f4\u9c81\u68d2\u7684\u6a21\u578b\u3002", "method": "\u5f15\u5165CaSE\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ec5\u4f7f\u7528\u524d\u6587\u8bed\u5883\u6765\u8bc4\u4f30\u6bcf\u4e2a\u63a8\u7406\u6b65\u9aa4\u7684\u76f8\u5173\u6027\u548c\u8fde\u8d2f\u6027\uff0c\u907f\u514d\u540e\u89c1\u4e4b\u660e\u504f\u5dee\u3002\u521b\u5efa\u4e86\u4e13\u5bb6\u6807\u6ce8\u7684\u57fa\u51c6MRa-GSM8K\u548cMRa-MATH\u3002", "result": "CaSE\u65b9\u6cd5\u4e0e\u4eba\u7c7b\u5224\u65ad\u4e00\u81f4\uff0c\u4f7f\u7528CaSE\u8bc4\u4f30\u7684\u76f8\u5173\u6027\u548c\u8fde\u8d2f\u6027\u6570\u636e\u8bad\u7ec3\u80fd\u76f4\u63a5\u63d0\u5347\u6700\u7ec8\u4efb\u52a1\u6027\u80fd\u3002", "conclusion": "\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u6846\u67b6\u6765\u5206\u6790\u3001\u8c03\u8bd5\u548c\u6539\u8fdbLLM\u63a8\u7406\uff0c\u8bc1\u660e\u8d85\u8d8a\u6709\u6548\u6027\u68c0\u67e5\u7684\u5b9e\u9645\u4ef7\u503c\u3002"}}
{"id": "2510.20566", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20566", "abs": "https://arxiv.org/abs/2510.20566", "authors": ["Wei Shao", "Yuhao Wang", "Rongguang He", "Muhammad Ejaz Ahmed", "Seyit Camtepe"], "title": "AdaDoS: Adaptive DoS Attack via Deep Adversarial Reinforcement Learning in SDN", "comment": null, "summary": "Existing defence mechanisms have demonstrated significant effectiveness in\nmitigating rule-based Denial-of-Service (DoS) attacks, leveraging predefined\nsignatures and static heuristics to identify and block malicious traffic.\nHowever, the emergence of AI-driven techniques presents new challenges to SDN\nsecurity, potentially compromising the efficacy of existing defence mechanisms.\nIn this paper, we introduce~AdaDoS, an adaptive attack model that disrupt\nnetwork operations while evading detection by existing DoS-based detectors\nthrough adversarial reinforcement learning (RL). Specifically, AdaDoS models\nthe problem as a competitive game between an attacker, whose goal is to\nobstruct network traffic without being detected, and a detector, which aims to\nidentify malicious traffic. AdaDoS can solve this game by dynamically adjusting\nits attack strategy based on feedback from the SDN and the detector.\nAdditionally, recognising that attackers typically have less information than\ndefenders, AdaDoS formulates the DoS-like attack as a partially observed Markov\ndecision process (POMDP), with the attacker having access only to delay\ninformation between attacker and victim nodes. We address this challenge with a\nnovel reciprocal learning module, where the student agent, with limited\nobservations, enhances its performance by learning from the teacher agent, who\nhas full observational capabilities in the SDN environment. AdaDoS represents\nthe first application of RL to develop DoS-like attack sequences, capable of\nadaptively evading both machine learning-based and rule-based DoS-like attack\ndetectors.", "AI": {"tldr": "AdaDoS\u662f\u4e00\u79cd\u57fa\u4e8e\u5bf9\u6297\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u9002\u5e94DoS\u653b\u51fb\u6a21\u578b\uff0c\u80fd\u591f\u52a8\u6001\u8c03\u6574\u653b\u51fb\u7b56\u7565\u4ee5\u89c4\u907f\u73b0\u6709\u68c0\u6d4b\u673a\u5236\uff0c\u5305\u62ec\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u548c\u57fa\u4e8e\u89c4\u5219\u7684DoS\u653b\u51fb\u68c0\u6d4b\u5668\u3002", "motivation": "\u73b0\u6709\u9632\u5fa1\u673a\u5236\u5bf9\u57fa\u4e8e\u89c4\u5219\u7684DoS\u653b\u51fb\u6709\u6548\uff0c\u4f46AI\u9a71\u52a8\u6280\u672f\u7ed9SDN\u5b89\u5168\u5e26\u6765\u65b0\u6311\u6218\u3002\u9700\u8981\u7814\u7a76\u80fd\u591f\u89c4\u907f\u73b0\u6709\u68c0\u6d4b\u673a\u5236\u7684\u81ea\u9002\u5e94\u653b\u51fb\u6a21\u578b\u3002", "method": "\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u653b\u51fb\u8005\u4e0e\u68c0\u6d4b\u5668\u4e4b\u95f4\u7684\u7ade\u4e89\u535a\u5f08\uff0c\u4f7f\u7528\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b(POMDP)\u5efa\u6a21\uff0c\u5e76\u91c7\u7528\u65b0\u9896\u7684\u4e92\u60e0\u5b66\u4e60\u6a21\u5757\uff0c\u8ba9\u6709\u9650\u89c2\u6d4b\u7684\u5b66\u751f\u667a\u80fd\u4f53\u4ece\u5168\u89c2\u6d4b\u7684\u6559\u5e08\u667a\u80fd\u4f53\u5b66\u4e60\u3002", "result": "AdaDoS\u80fd\u591f\u751f\u6210\u81ea\u9002\u5e94DoS\u653b\u51fb\u5e8f\u5217\uff0c\u6210\u529f\u89c4\u907f\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u68c0\u6d4b\u5668\uff0c\u540c\u65f6\u7834\u574f\u7f51\u7edc\u64cd\u4f5c\u3002", "conclusion": "AdaDoS\u662f\u9996\u4e2a\u5c06\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\u4e8e\u5f00\u53d1DoS\u653b\u51fb\u5e8f\u5217\u7684\u5de5\u4f5c\uff0c\u5c55\u793a\u4e86\u81ea\u9002\u5e94\u653b\u51fb\u5bf9\u73b0\u6709\u9632\u5fa1\u673a\u5236\u7684\u5a01\u80c1\uff0c\u5f3a\u8c03\u4e86\u9700\u8981\u66f4\u5f3a\u5927\u7684\u9632\u5fa1\u7b56\u7565\u3002"}}
{"id": "2510.20604", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20604", "abs": "https://arxiv.org/abs/2510.20604", "authors": ["Changan Liu", "Zixuan Xie", "Ahad N. Zehmakan", "Zhongzhi Zhang"], "title": "Efficient Algorithms for Computing Random Walk Centrality", "comment": "Accepted by TKDE", "summary": "Random walk centrality is a fundamental metric in graph mining for\nquantifying node importance and influence, defined as the weighted average of\nhitting times to a node from all other nodes. Despite its ability to capture\nrich graph structural information and its wide range of applications, computing\nthis measure for large networks remains impractical due to the computational\ndemands of existing methods. In this paper, we present a novel formulation of\nrandom walk centrality, underpinning two scalable algorithms: one leveraging\napproximate Cholesky factorization and sparse inverse estimation, while the\nother sampling rooted spanning trees. Both algorithms operate in near-linear\ntime and provide strong approximation guarantees. Extensive experiments on\nlarge real-world networks, including one with over 10 million nodes,\ndemonstrate the efficiency and approximation quality of the proposed\nalgorithms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e24\u79cd\u53ef\u6269\u5c55\u7684\u968f\u673a\u6e38\u8d70\u4e2d\u5fc3\u6027\u7b97\u6cd5\uff0c\u5229\u7528\u8fd1\u4f3cCholesky\u5206\u89e3\u548c\u6839\u751f\u6210\u6811\u91c7\u6837\uff0c\u5728\u8fd1\u7ebf\u6027\u65f6\u95f4\u5185\u63d0\u4f9b\u5f3a\u8fd1\u4f3c\u4fdd\u8bc1\u3002", "motivation": "\u968f\u673a\u6e38\u8d70\u4e2d\u5fc3\u6027\u4f5c\u4e3a\u56fe\u6316\u6398\u4e2d\u91cf\u5316\u8282\u70b9\u91cd\u8981\u6027\u7684\u57fa\u672c\u6307\u6807\uff0c\u867d\u7136\u80fd\u6355\u83b7\u4e30\u5bcc\u7684\u56fe\u7ed3\u6784\u4fe1\u606f\uff0c\u4f46\u5728\u5927\u578b\u7f51\u7edc\u4e2d\u7684\u8ba1\u7b97\u4ecd\u7136\u4e0d\u5207\u5b9e\u9645\uff0c\u56e0\u4e3a\u73b0\u6709\u65b9\u6cd5\u8ba1\u7b97\u9700\u6c42\u8fc7\u9ad8\u3002", "method": "\u63d0\u51fa\u4e86\u968f\u673a\u6e38\u8d70\u4e2d\u5fc3\u6027\u7684\u65b0\u516c\u5f0f\uff0c\u57fa\u4e8e\u6b64\u5f00\u53d1\u4e86\u4e24\u79cd\u7b97\u6cd5\uff1a\u4e00\u79cd\u5229\u7528\u8fd1\u4f3cCholesky\u5206\u89e3\u548c\u7a00\u758f\u9006\u4f30\u8ba1\uff0c\u53e6\u4e00\u79cd\u901a\u8fc7\u91c7\u6837\u6839\u751f\u6210\u6811\u3002", "result": "\u5728\u5305\u62ec\u8d85\u8fc71000\u4e07\u4e2a\u8282\u70b9\u7684\u5927\u578b\u771f\u5b9e\u7f51\u7edc\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u7b97\u6cd5\u5177\u6709\u9ad8\u6548\u6027\u548c\u826f\u597d\u7684\u8fd1\u4f3c\u8d28\u91cf\u3002", "conclusion": "\u4e24\u79cd\u7b97\u6cd5\u90fd\u80fd\u5728\u8fd1\u7ebf\u6027\u65f6\u95f4\u5185\u8fd0\u884c\uff0c\u5e76\u63d0\u4f9b\u5f3a\u8fd1\u4f3c\u4fdd\u8bc1\uff0c\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u7f51\u7edc\u4e2d\u968f\u673a\u6e38\u8d70\u4e2d\u5fc3\u6027\u8ba1\u7b97\u7684\u5b9e\u9645\u95ee\u9898\u3002"}}
{"id": "2510.20645", "categories": ["cs.CR", "cs.CE", "cs.DC", "cs.GT"], "pdf": "https://arxiv.org/pdf/2510.20645", "abs": "https://arxiv.org/abs/2510.20645", "authors": ["Nitin Awathare"], "title": "Decentralized Exchange that Mitigate a Bribery Attack", "comment": null, "summary": "Despite the popularity of Hashed Time-Locked Contracts (HTLCs) because of\ntheir use in wide areas of applications such as payment channels, atomic swaps,\netc, their use in exchange is still questionable. This is because of its\nincentive incompatibility and susceptibility to bribery attacks.\n  State-of-the-art solutions such as MAD-HTLC (Oakland'21) and He-HTLC\n(NDSS'23) address this by leveraging miners' profit-driven behaviour to\nmitigate such attacks. The former is the mitigation against passive miners;\nhowever, the latter works against both active and passive miners. However, they\nconsider only two bribing scenarios where either of the parties involved in the\ntransfer collude with the miner.\n  In this paper, we expose vulnerabilities in state-of-the-art solutions by\npresenting a miner-collusion bribery attack with implementation and\ngame-theoretic analysis. Additionally, we propose a stronger attack on MAD-HTLC\nthan He-HTLC, allowing the attacker to earn profits equivalent to attacking\nnaive HTLC.\n  Leveraging our insights, we propose \\prot, a game-theoretically secure HTLC\nprotocol resistant to all bribery scenarios. \\prot\\ employs a two-phase\napproach, preventing unauthorized token confiscation by third parties, such as\nminers. In Phase 1, parties commit to the transfer; in Phase 2, the transfer is\nexecuted without manipulation. We demonstrate \\prot's efficiency in transaction\ncost and latency via implementations on Bitcoin and Ethereum.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86HTLC\u534f\u8bae\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u77ff\u5de5\u5408\u8c0b\u8d3f\u8d42\u653b\u51fb\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u6297\u6240\u6709\u8d3f\u8d42\u573a\u666f\u7684\u5b89\u5168\u534f\u8bae\\prot\u3002", "motivation": "\u73b0\u6709HTLC\u89e3\u51b3\u65b9\u6848\u5982MAD-HTLC\u548cHe-HTLC\u4ec5\u8003\u8651\u4e24\u79cd\u8d3f\u8d42\u573a\u666f\uff0c\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u8981\u8bbe\u8ba1\u66f4\u5b89\u5168\u7684\u534f\u8bae\u6765\u62b5\u6297\u6240\u6709\u53ef\u80fd\u7684\u8d3f\u8d42\u653b\u51fb\u3002", "method": "\u63d0\u51fa\\prot\u534f\u8bae\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u7b2c\u4e00\u9636\u6bb5\u5404\u65b9\u627f\u8bfa\u8f6c\u8d26\uff0c\u7b2c\u4e8c\u9636\u6bb5\u6267\u884c\u8f6c\u8d26\u800c\u4e0d\u88ab\u64cd\u7eb5\u3002\u901a\u8fc7\u6bd4\u7279\u5e01\u548c\u4ee5\u592a\u574a\u5b9e\u73b0\u9a8c\u8bc1\u6548\u7387\u3002", "result": "\u6210\u529f\u66b4\u9732\u4e86\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u7684\u6f0f\u6d1e\uff0c\u63d0\u51fa\u4e86\u66f4\u5f3a\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u5e76\u8bc1\u660e\\prot\u534f\u8bae\u5728\u4ea4\u6613\u6210\u672c\u548c\u5ef6\u8fdf\u65b9\u9762\u5177\u6709\u9ad8\u6548\u6027\u3002", "conclusion": "\\prot\u534f\u8bae\u5728\u6e38\u620f\u7406\u8bba\u4e0a\u5b89\u5168\uff0c\u80fd\u591f\u62b5\u6297\u6240\u6709\u8d3f\u8d42\u573a\u666f\uff0c\u4e3aHTLC\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u5f3a\u7684\u5b89\u5168\u4fdd\u969c\u3002"}}
{"id": "2510.20621", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20621", "abs": "https://arxiv.org/abs/2510.20621", "authors": ["Riccardo Guidotti", "Martina Cinquini", "Marta Marchiori Manerba", "Mattia Setzu", "Francesco Spinnato"], "title": "Towards the Formalization of a Trustworthy AI for Mining Interpretable Models explOiting Sophisticated Algorithms", "comment": null, "summary": "Interpretable-by-design models are crucial for fostering trust,\naccountability, and safe adoption of automated decision-making models in\nreal-world applications. In this paper we formalize the ground for the MIMOSA\n(Mining Interpretable Models explOiting Sophisticated Algorithms) framework, a\ncomprehensive methodology for generating predictive models that balance\ninterpretability with performance while embedding key ethical properties. We\nformally define here the supervised learning setting across diverse\ndecision-making tasks and data types, including tabular data, time series,\nimages, text, transactions, and trajectories. We characterize three major\nfamilies of interpretable models: feature importance, rule, and instance based\nmodels. For each family, we analyze their interpretability dimensions,\nreasoning mechanisms, and complexity. Beyond interpretability, we formalize\nthree critical ethical properties, namely causality, fairness, and privacy,\nproviding formal definitions, evaluation metrics, and verification procedures\nfor each. We then examine the inherent trade-offs between these properties and\ndiscuss how privacy requirements, fairness constraints, and causal reasoning\ncan be embedded within interpretable pipelines. By evaluating ethical measures\nduring model generation, this framework establishes the theoretical foundations\nfor developing AI systems that are not only accurate and interpretable but also\nfair, privacy-preserving, and causally aware, i.e., trustworthy.", "AI": {"tldr": "MIMOSA\u6846\u67b6\u662f\u4e00\u4e2a\u53ef\u89e3\u91ca\u6027\u8bbe\u8ba1\u7684\u65b9\u6cd5\u8bba\uff0c\u65e8\u5728\u751f\u6210\u5e73\u8861\u53ef\u89e3\u91ca\u6027\u548c\u6027\u80fd\u7684\u9884\u6d4b\u6a21\u578b\uff0c\u540c\u65f6\u5d4c\u5165\u56e0\u679c\u6027\u3001\u516c\u5e73\u6027\u548c\u9690\u79c1\u6027\u7b49\u5173\u952e\u4f26\u7406\u5c5e\u6027\u3002", "motivation": "\u5f00\u53d1\u53ef\u89e3\u91ca\u6027\u8bbe\u8ba1\u6a21\u578b\u5bf9\u4e8e\u5728\u771f\u5b9e\u5e94\u7528\u4e2d\u5efa\u7acb\u5bf9\u81ea\u52a8\u5316\u51b3\u7b56\u6a21\u578b\u7684\u4fe1\u4efb\u3001\u95ee\u8d23\u548c\u5b89\u5168\u91c7\u7528\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5f62\u5f0f\u5316\u5b9a\u4e49\u4e86\u76d1\u7763\u5b66\u4e60\u8bbe\u7f6e\uff0c\u6db5\u76d6\u8868\u683c\u6570\u636e\u3001\u65f6\u95f4\u5e8f\u5217\u3001\u56fe\u50cf\u3001\u6587\u672c\u7b49\u591a\u79cd\u6570\u636e\u7c7b\u578b\u3002\u5206\u6790\u4e86\u7279\u5f81\u91cd\u8981\u6027\u3001\u89c4\u5219\u548c\u5b9e\u4f8b\u4e09\u7c7b\u53ef\u89e3\u91ca\u6a21\u578b\u5bb6\u65cf\uff0c\u5e76\u5f62\u5f0f\u5316\u4e86\u56e0\u679c\u6027\u3001\u516c\u5e73\u6027\u548c\u9690\u79c1\u6027\u4e09\u4e2a\u4f26\u7406\u5c5e\u6027\u3002", "result": "\u5efa\u7acb\u4e86\u8bc4\u4f30\u4f26\u7406\u5ea6\u91cf\u7684\u7406\u8bba\u6846\u67b6\uff0c\u63a2\u8ba8\u4e86\u8fd9\u4e9b\u5c5e\u6027\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\uff0c\u4ee5\u53ca\u5982\u4f55\u5728\u53ef\u89e3\u91ca\u7ba1\u9053\u4e2d\u5d4c\u5165\u9690\u79c1\u8981\u6c42\u3001\u516c\u5e73\u7ea6\u675f\u548c\u56e0\u679c\u63a8\u7406\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5f00\u53d1\u4e0d\u4ec5\u51c6\u786e\u53ef\u89e3\u91ca\uff0c\u800c\u4e14\u516c\u5e73\u3001\u4fdd\u62a4\u9690\u79c1\u548c\u5177\u6709\u56e0\u679c\u610f\u8bc6\u7684AI\u7cfb\u7edf\u5960\u5b9a\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5373\u503c\u5f97\u4fe1\u8d56\u7684AI\u7cfb\u7edf\u3002"}}
{"id": "2510.20657", "categories": ["cs.CR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.20657", "abs": "https://arxiv.org/abs/2510.20657", "authors": ["Rubens Kim", "Stephan Carney", "Yvonne Fonken", "Soham Hans", "Sofia Hirschmann", "Stacy Marsella", "Peggy Wu", "Nikolos Gurney"], "title": "Risk Psychology & Cyber-Attack Tactics", "comment": "Submitted and presented at AHFE Hawaii 2025. 2 tables, 2 figures", "summary": "We examine whether measured cognitive processes predict cyber-attack\nbehavior. We analyzed data that included psychometric scale responses and\nlabeled attack behaviors from cybersecurity professionals who conducted\nred-team operations against a simulated enterprise network. We employed\nmultilevel mixed-effects Poisson regression with technique counts nested within\nparticipants to test whether cognitive processes predicted technique-specific\nusage. The scales significantly predicted technique use, but effects varied by\ntechnique rather than operating uniformly. Neither expertise level nor\nexperimental treatment condition significantly predicted technique patterns,\nindicating that cognitive processes may be stronger drivers of technique\nselection than training or experience. These findings demonstrate that\nindividual cognitive differences shape cyber-attack behavior and support the\ndevelopment of psychology-informed defense strategies.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\u8ba4\u77e5\u8fc7\u7a0b\u80fd\u9884\u6d4b\u7f51\u7edc\u653b\u51fb\u884c\u4e3a\uff0c\u8ba4\u77e5\u5dee\u5f02\u6bd4\u8bad\u7ec3\u6216\u7ecf\u9a8c\u66f4\u80fd\u5f71\u54cd\u653b\u51fb\u6280\u672f\u9009\u62e9", "motivation": "\u63a2\u7a76\u8ba4\u77e5\u8fc7\u7a0b\u662f\u5426\u80fd\u9884\u6d4b\u7f51\u7edc\u653b\u51fb\u884c\u4e3a\uff0c\u4e86\u89e3\u4e2a\u4f53\u8ba4\u77e5\u5dee\u5f02\u5982\u4f55\u5f71\u54cd\u7f51\u7edc\u653b\u51fb\u6280\u672f\u9009\u62e9", "method": "\u4f7f\u7528\u591a\u7ea7\u6df7\u5408\u6548\u5e94\u6cca\u677e\u56de\u5f52\u5206\u6790\uff0c\u5c06\u7f51\u7edc\u5b89\u5168\u4e13\u4e1a\u4eba\u5458\u5728\u6a21\u62df\u4f01\u4e1a\u7f51\u7edc\u7ea2\u961f\u64cd\u4f5c\u4e2d\u7684\u5fc3\u7406\u6d4b\u91cf\u91cf\u8868\u54cd\u5e94\u4e0e\u6807\u8bb0\u7684\u653b\u51fb\u884c\u4e3a\u6570\u636e\u76f8\u7ed3\u5408", "result": "\u8ba4\u77e5\u8fc7\u7a0b\u91cf\u8868\u663e\u8457\u9884\u6d4b\u4e86\u653b\u51fb\u6280\u672f\u4f7f\u7528\uff0c\u4f46\u6548\u679c\u56e0\u6280\u672f\u800c\u5f02\u800c\u975e\u7edf\u4e00\u8fd0\u4f5c\uff1b\u4e13\u4e1a\u6c34\u5e73\u548c\u5b9e\u9a8c\u6761\u4ef6\u5bf9\u6280\u672f\u6a21\u5f0f\u6ca1\u6709\u663e\u8457\u9884\u6d4b\u4f5c\u7528", "conclusion": "\u4e2a\u4f53\u8ba4\u77e5\u5dee\u5f02\u5851\u9020\u7f51\u7edc\u653b\u51fb\u884c\u4e3a\uff0c\u652f\u6301\u5f00\u53d1\u57fa\u4e8e\u5fc3\u7406\u5b66\u7684\u9632\u5fa1\u7b56\u7565"}}
{"id": "2510.20632", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20632", "abs": "https://arxiv.org/abs/2510.20632", "authors": ["Shuyi Xie", "Ziqin Liew", "Hailing Zhang", "Haibo Zhang", "Ling Hu", "Zhiqiang Zhou", "Shuman Liu", "Anxiang Zeng"], "title": "Towards Reliable Evaluation of Large Language Models for Multilingual and Multimodal E-Commerce Applications", "comment": null, "summary": "Large Language Models (LLMs) excel on general-purpose NLP benchmarks, yet\ntheir capabilities in specialized domains remain underexplored. In e-commerce,\nexisting evaluations-such as EcomInstruct, ChineseEcomQA, eCeLLM, and Shopping\nMMLU-suffer from limited task diversity (e.g., lacking product guidance and\nafter-sales issues), limited task modalities (e.g., absence of multimodal\ndata), synthetic or curated data, and a narrow focus on English and Chinese,\nleaving practitioners without reliable tools to assess models on complex,\nreal-world shopping scenarios. We introduce EcomEval, a comprehensive\nmultilingual and multimodal benchmark for evaluating LLMs in e-commerce.\nEcomEval covers six categories and 37 tasks (including 8 multimodal tasks),\nsourced primarily from authentic customer queries and transaction logs,\nreflecting the noisy and heterogeneous nature of real business interactions. To\nensure both quality and scalability of reference answers, we adopt a\nsemi-automatic pipeline in which large models draft candidate responses\nsubsequently reviewed and modified by over 50 expert annotators with strong\ne-commerce and multilingual expertise. We define difficulty levels for each\nquestion and task category by averaging evaluation scores across models with\ndifferent sizes and capabilities, enabling challenge-oriented and fine-grained\nassessment. EcomEval also spans seven languages-including five low-resource\nSoutheast Asian languages-offering a multilingual perspective absent from prior\nwork.", "AI": {"tldr": "EcomEval\u662f\u4e00\u4e2a\u5168\u9762\u7684\u591a\u8bed\u8a00\u591a\u6a21\u6001\u7535\u5b50\u5546\u52a1\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8986\u76d66\u4e2a\u7c7b\u522b37\u4e2a\u4efb\u52a1\uff0c\u5305\u62ec8\u4e2a\u591a\u6a21\u6001\u4efb\u52a1\uff0c\u4f7f\u7528\u771f\u5b9e\u5ba2\u6237\u67e5\u8be2\u548c\u4ea4\u6613\u65e5\u5fd7\u6570\u636e\uff0c\u652f\u63017\u79cd\u8bed\u8a00\u3002", "motivation": "\u73b0\u6709\u7535\u5b50\u5546\u52a1\u8bc4\u4f30\u57fa\u51c6\u5b58\u5728\u4efb\u52a1\u591a\u6837\u6027\u4e0d\u8db3\u3001\u6a21\u6001\u6709\u9650\u3001\u6570\u636e\u5408\u6210\u6216\u4eba\u5de5\u7b5b\u9009\u3001\u8bed\u8a00\u8986\u76d6\u7a84\u7b49\u95ee\u9898\uff0c\u7f3a\u4e4f\u8bc4\u4f30LLM\u5728\u590d\u6742\u771f\u5b9e\u8d2d\u7269\u573a\u666f\u4e2d\u80fd\u529b\u7684\u53ef\u9760\u5de5\u5177\u3002", "method": "\u91c7\u7528\u534a\u81ea\u52a8\u6807\u6ce8\u6d41\u7a0b\uff1a\u5927\u6a21\u578b\u751f\u6210\u5019\u9009\u7b54\u6848\uff0c50\u591a\u540d\u7535\u5b50\u5546\u52a1\u548c\u591a\u8bed\u8a00\u4e13\u5bb6\u5ba1\u6838\u4fee\u6539\uff1b\u5b9a\u4e49\u96be\u5ea6\u7ea7\u522b\u57fa\u4e8e\u4e0d\u540c\u89c4\u6a21\u548c\u80fd\u529b\u6a21\u578b\u7684\u5e73\u5747\u8bc4\u5206\uff1b\u4f7f\u7528\u771f\u5b9e\u5ba2\u6237\u67e5\u8be2\u548c\u4ea4\u6613\u65e5\u5fd7\u6570\u636e\u3002", "result": "\u6784\u5efa\u4e86\u5305\u542b6\u4e2a\u7c7b\u522b37\u4e2a\u4efb\u52a1\uff08\u542b8\u4e2a\u591a\u6a21\u6001\u4efb\u52a1\uff09\u7684\u57fa\u51c6\uff0c\u8986\u76d67\u79cd\u8bed\u8a00\uff08\u5305\u62ec5\u79cd\u4e1c\u5357\u4e9a\u4f4e\u8d44\u6e90\u8bed\u8a00\uff09\uff0c\u63d0\u4f9b\u9762\u5411\u6311\u6218\u7684\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u3002", "conclusion": "EcomEval\u586b\u8865\u4e86\u7535\u5b50\u5546\u52a1\u9886\u57df\u8bc4\u4f30\u57fa\u51c6\u7684\u7a7a\u767d\uff0c\u4e3a\u8bc4\u4f30LLM\u5728\u771f\u5b9e\u590d\u6742\u8d2d\u7269\u573a\u666f\u4e2d\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u5168\u9762\u53ef\u9760\u7684\u5de5\u5177\u3002"}}
{"id": "2510.20636", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20636", "abs": "https://arxiv.org/abs/2510.20636", "authors": ["Eric Ngoiya", "Tianshu Bao"], "title": "Fluidity Index: Next-Generation Super-intelligence Benchmarks", "comment": "12", "summary": "This paper introduces the Fluidity Index (FI) to quantify model adaptability\nin dynamic, scaling environments. The benchmark evaluates response accuracy\nbased on deviations in initial, current, and future environment states,\nassessing context switching and continuity. We distinguish between closed-ended\nand open-ended benchmarks, prioritizing closed-loop open-ended real-world\nbenchmarks to test adaptability. The approach measures a model's ability to\nunderstand, predict, and adjust to state changes in scaling environments. A\ntruly super-intelligent model should exhibit at least second-order\nadaptability, enabling self-sustained computation through digital replenishment\nfor optimal fluidity.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u6d41\u52a8\u6027\u6307\u6570(FI)\u6765\u91cf\u5316\u6a21\u578b\u5728\u52a8\u6001\u6269\u5c55\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\uff0c\u901a\u8fc7\u8bc4\u4f30\u521d\u59cb\u3001\u5f53\u524d\u548c\u672a\u6765\u73af\u5883\u72b6\u6001\u504f\u5dee\u6765\u8861\u91cf\u54cd\u5e94\u51c6\u786e\u6027\uff0c\u533a\u5206\u4e86\u5c01\u95ed\u5f0f\u548c\u5f00\u653e\u5f0f\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u9700\u8981\u91cf\u5316\u6a21\u578b\u5728\u52a8\u6001\u6269\u5c55\u73af\u5883\u4e2d\u7684\u9002\u5e94\u80fd\u529b\uff0c\u8bc4\u4f30\u6a21\u578b\u5bf9\u72b6\u6001\u53d8\u5316\u7684\u7406\u89e3\u3001\u9884\u6d4b\u548c\u8c03\u6574\u80fd\u529b\uff0c\u4e3a\u8d85\u7ea7\u667a\u80fd\u6a21\u578b\u8bbe\u5b9a\u9002\u5e94\u6027\u6807\u51c6\u3002", "method": "\u5f15\u5165\u6d41\u52a8\u6027\u6307\u6570(FI)\u4f5c\u4e3a\u91cf\u5316\u6307\u6807\uff0c\u901a\u8fc7\u8bc4\u4f30\u54cd\u5e94\u51c6\u786e\u6027\u5728\u73af\u5883\u72b6\u6001\u53d8\u5316\u4e2d\u7684\u8868\u73b0\uff0c\u533a\u5206\u5c01\u95ed\u5f0f\u548c\u5f00\u653e\u5f0f\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7279\u522b\u5173\u6ce8\u95ed\u73af\u5f00\u653e\u5f0f\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u8bc4\u4f30\u6a21\u578b\u9002\u5e94\u6027\u7684\u6846\u67b6\uff0c\u80fd\u591f\u6d4b\u91cf\u6a21\u578b\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u4e0a\u4e0b\u6587\u5207\u6362\u548c\u8fde\u7eed\u6027\u4fdd\u6301\u80fd\u529b\u3002", "conclusion": "\u771f\u6b63\u8d85\u7ea7\u667a\u80fd\u7684\u6a21\u578b\u5e94\u81f3\u5c11\u5177\u5907\u4e8c\u9636\u9002\u5e94\u6027\uff0c\u80fd\u591f\u901a\u8fc7\u6570\u5b57\u8865\u5145\u5b9e\u73b0\u81ea\u6211\u7ef4\u6301\u8ba1\u7b97\uff0c\u8fbe\u5230\u6700\u4f73\u6d41\u52a8\u6027\u3002"}}
{"id": "2510.20768", "categories": ["cs.CR", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.20768", "abs": "https://arxiv.org/abs/2510.20768", "authors": ["Austin Jia", "Avaneesh Ramesh", "Zain Shamsi", "Daniel Zhang", "Alex Liu"], "title": "RAGRank: Using PageRank to Counter Poisoning in CTI LLM Pipelines", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) has emerged as the dominant\narchitectural pattern to operationalize Large Language Model (LLM) usage in\nCyber Threat Intelligence (CTI) systems. However, this design is susceptible to\npoisoning attacks, and previously proposed defenses can fail for CTI contexts\nas cyber threat information is often completely new for emerging attacks, and\nsophisticated threat actors can mimic legitimate formats, terminology, and\nstylistic conventions. To address this issue, we propose that the robustness of\nmodern RAG defenses can be accelerated by applying source credibility\nalgorithms on corpora, using PageRank as an example. In our experiments, we\ndemonstrate quantitatively that our algorithm applies a lower authority score\nto malicious documents while promoting trusted content, using the standardized\nMS MARCO dataset. We also demonstrate proof-of-concept performance of our\nalgorithm on CTI documents and feeds.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528PageRank\u7b49\u6e90\u53ef\u4fe1\u5ea6\u7b97\u6cd5\u6765\u589e\u5f3aRAG\u7cfb\u7edf\u5728\u7f51\u7edc\u5b89\u5168\u5a01\u80c1\u60c5\u62a5\u4e2d\u7684\u9632\u5fa1\u80fd\u529b\uff0c\u901a\u8fc7\u964d\u4f4e\u6076\u610f\u6587\u6863\u7684\u6743\u5a01\u8bc4\u5206\u6765\u63d0\u5347\u7cfb\u7edf\u5b89\u5168\u6027\u3002", "motivation": "RAG\u67b6\u6784\u5728\u7f51\u7edc\u5b89\u5168\u5a01\u80c1\u60c5\u62a5\u7cfb\u7edf\u4e2d\u5bb9\u6613\u53d7\u5230\u6295\u6bd2\u653b\u51fb\uff0c\u800c\u73b0\u6709\u9632\u5fa1\u63aa\u65bd\u5728CTI\u573a\u666f\u4e0b\u53ef\u80fd\u5931\u6548\uff0c\u56e0\u4e3a\u5a01\u80c1\u4fe1\u606f\u5f80\u5f80\u662f\u5168\u65b0\u7684\uff0c\u4e14\u653b\u51fb\u8005\u80fd\u6a21\u4eff\u5408\u6cd5\u683c\u5f0f\u548c\u672f\u8bed\u3002", "method": "\u5e94\u7528\u6e90\u53ef\u4fe1\u5ea6\u7b97\u6cd5\uff08\u4ee5PageRank\u4e3a\u4f8b\uff09\u5bf9\u8bed\u6599\u5e93\u8fdb\u884c\u5904\u7406\uff0c\u901a\u8fc7\u8ba1\u7b97\u6587\u6863\u6743\u5a01\u8bc4\u5206\u6765\u8bc6\u522b\u548c\u964d\u4f4e\u6076\u610f\u5185\u5bb9\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u7b97\u6cd5\u80fd\u6709\u6548\u964d\u4f4e\u6076\u610f\u6587\u6863\u7684\u6743\u5a01\u8bc4\u5206\uff0c\u540c\u65f6\u63d0\u5347\u53ef\u4fe1\u5185\u5bb9\uff0c\u5728MS MARCO\u6570\u636e\u96c6\u548cCTI\u6587\u6863\u4e0a\u90fd\u53d6\u5f97\u4e86\u9a8c\u8bc1\u3002", "conclusion": "\u6e90\u53ef\u4fe1\u5ea6\u7b97\u6cd5\u80fd\u591f\u663e\u8457\u589e\u5f3aRAG\u7cfb\u7edf\u5728\u7f51\u7edc\u5b89\u5168\u5a01\u80c1\u60c5\u62a5\u5e94\u7528\u4e2d\u7684\u9c81\u68d2\u6027\uff0c\u4e3a\u9632\u5fa1\u6295\u6bd2\u653b\u51fb\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.20641", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20641", "abs": "https://arxiv.org/abs/2510.20641", "authors": ["Andrea Agiollo", "Andrea Omicini"], "title": "Integrating Machine Learning into Belief-Desire-Intention Agents: Current Advances and Open Challenges", "comment": null, "summary": "Thanks to the remarkable human-like capabilities of machine learning (ML)\nmodels in perceptual and cognitive tasks, frameworks integrating ML within\nrational agent architectures are gaining traction. Yet, the landscape remains\nfragmented and incoherent, often focusing on embedding ML into generic agent\ncontainers while overlooking the expressive power of rational\narchitectures--such as Belief-Desire-Intention (BDI) agents. This paper\npresents a fine-grained systematisation of existing approaches, using the BDI\nparadigm as a reference. Our analysis illustrates the fast-evolving literature\non rational agents enhanced by ML, and identifies key research opportunities\nand open challenges for designing effective rational ML agents.", "AI": {"tldr": "\u672c\u6587\u5bf9\u5c06\u673a\u5668\u5b66\u4e60\u6574\u5408\u5230\u7406\u6027\u667a\u80fd\u4f53\u67b6\u6784\u4e2d\u7684\u73b0\u6709\u65b9\u6cd5\u8fdb\u884c\u4e86\u7cfb\u7edf\u5316\u68b3\u7406\uff0c\u7279\u522b\u4ee5BDI\uff08\u4fe1\u5ff5-\u6b32\u671b-\u610f\u56fe\uff09\u8303\u5f0f\u4e3a\u53c2\u8003\u6846\u67b6\uff0c\u5206\u6790\u4e86\u8be5\u9886\u57df\u7684\u53d1\u5c55\u73b0\u72b6\u548c\u672a\u6765\u6311\u6218\u3002", "motivation": "\u7531\u4e8e\u673a\u5668\u5b66\u4e60\u5728\u611f\u77e5\u548c\u8ba4\u77e5\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u7c7b\u4eba\u80fd\u529b\uff0c\u5c06\u5176\u6574\u5408\u5230\u7406\u6027\u667a\u80fd\u4f53\u67b6\u6784\u4e2d\u7684\u6846\u67b6\u65e5\u76ca\u53d7\u5230\u5173\u6ce8\u3002\u4f46\u73b0\u6709\u7814\u7a76\u96f6\u6563\u4e14\u7f3a\u4e4f\u8fde\u8d2f\u6027\uff0c\u5f80\u5f80\u53ea\u5173\u6ce8\u5c06ML\u5d4c\u5165\u901a\u7528\u667a\u80fd\u4f53\u5bb9\u5668\uff0c\u800c\u5ffd\u89c6\u4e86\u7406\u6027\u67b6\u6784\uff08\u5982BDI\u667a\u80fd\u4f53\uff09\u7684\u8868\u8fbe\u80fd\u529b\u3002", "method": "\u91c7\u7528BDI\u8303\u5f0f\u4f5c\u4e3a\u53c2\u8003\u6846\u67b6\uff0c\u5bf9\u73b0\u6709\u65b9\u6cd5\u8fdb\u884c\u7ec6\u7c92\u5ea6\u7cfb\u7edf\u5316\u5206\u6790\uff0c\u68b3\u7406\u7406\u6027\u667a\u80fd\u4f53\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u589e\u5f3a\u7684\u6587\u732e\u53d1\u5c55\u3002", "result": "\u5206\u6790\u5c55\u793a\u4e86\u8be5\u9886\u57df\u5feb\u901f\u53d1\u5c55\u7684\u7814\u7a76\u73b0\u72b6\uff0c\u8bc6\u522b\u51fa\u5173\u952e\u7814\u7a76\u673a\u4f1a\u548c\u5f00\u653e\u6311\u6218\u3002", "conclusion": "\u4e3a\u8bbe\u8ba1\u6709\u6548\u7684\u7406\u6027\u673a\u5668\u5b66\u4e60\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u5206\u6790\u6846\u67b6\uff0c\u6307\u660e\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2510.20665", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20665", "abs": "https://arxiv.org/abs/2510.20665", "authors": ["Xue Wen Tan", "Nathaniel Tan", "Galen Lee", "Stanley Kok"], "title": "The Shape of Reasoning: Topological Analysis of Reasoning Traces in Large Language Models", "comment": null, "summary": "Evaluating the quality of reasoning traces from large language models remains\nunderstudied, labor-intensive, and unreliable: current practice relies on\nexpert rubrics, manual annotation, and slow pairwise judgments. Automated\nefforts are dominated by graph-based proxies that quantify structural\nconnectivity but do not clarify what constitutes high-quality reasoning; such\nabstractions can be overly simplistic for inherently complex processes. We\nintroduce a topological data analysis (TDA)-based evaluation framework that\ncaptures the geometry of reasoning traces and enables label-efficient,\nautomated assessment. In our empirical study, topological features yield\nsubstantially higher predictive power for assessing reasoning quality than\nstandard graph metrics, suggesting that effective reasoning is better captured\nby higher-dimensional geometric structures rather than purely relational\ngraphs. We further show that a compact, stable set of topological features\nreliably indicates trace quality, offering a practical signal for future\nreinforcement learning algorithms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u62d3\u6251\u6570\u636e\u5206\u6790\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u8f68\u8ff9\u8d28\u91cf\uff0c\u76f8\u6bd4\u4f20\u7edf\u56fe\u7ed3\u6784\u6307\u6807\u5177\u6709\u66f4\u5f3a\u7684\u9884\u6d4b\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u8bc4\u4f30LLM\u63a8\u7406\u8f68\u8ff9\u7684\u65b9\u6cd5\u4f9d\u8d56\u4e13\u5bb6\u6807\u6ce8\uff0c\u52b3\u52a8\u5bc6\u96c6\u4e14\u4e0d\u53ef\u9760\uff0c\u9700\u8981\u66f4\u81ea\u52a8\u5316\u548c\u6709\u6548\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u62d3\u6251\u6570\u636e\u5206\u6790\u65b9\u6cd5\u6355\u6349\u63a8\u7406\u8f68\u8ff9\u7684\u51e0\u4f55\u7ed3\u6784\uff0c\u63d0\u53d6\u62d3\u6251\u7279\u5f81\u6765\u8bc4\u4f30\u63a8\u7406\u8d28\u91cf\u3002", "result": "\u62d3\u6251\u7279\u5f81\u5728\u9884\u6d4b\u63a8\u7406\u8d28\u91cf\u65b9\u9762\u6bd4\u6807\u51c6\u56fe\u6307\u6807\u5177\u6709\u663e\u8457\u66f4\u9ad8\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u8868\u660e\u6709\u6548\u63a8\u7406\u66f4\u9002\u5408\u7528\u9ad8\u7ef4\u51e0\u4f55\u7ed3\u6784\u800c\u975e\u7eaf\u5173\u7cfb\u56fe\u6765\u6355\u6349\u3002", "conclusion": "\u62d3\u6251\u7279\u5f81\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7d27\u51d1\u3001\u7a33\u5b9a\u7684\u63a8\u7406\u8d28\u91cf\u6307\u6807\uff0c\u53ef\u4e3a\u672a\u6765\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u63d0\u4f9b\u5b9e\u7528\u4fe1\u53f7\u3002"}}
{"id": "2510.20691", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20691", "abs": "https://arxiv.org/abs/2510.20691", "authors": ["Yanlin Song", "Ben Liu", "V\u00edctor Guti\u00e9rrez-Basulto", "Zhiwei Hu", "Qianqian Xie", "Min Peng", "Sophia Ananiadou", "Jeff Z. Pan"], "title": "Plan Then Retrieve: Reinforcement Learning-Guided Complex Reasoning over Knowledge Graphs", "comment": null, "summary": "Knowledge Graph Question Answering aims to answer natural language questions\nby reasoning over structured knowledge graphs. While large language models have\nadvanced KGQA through their strong reasoning capabilities, existing methods\ncontinue to struggle to fully exploit both the rich knowledge encoded in KGs\nand the reasoning capabilities of LLMs, particularly in complex scenarios. They\noften assume complete KG coverage and lack mechanisms to judge when external\ninformation is needed, and their reasoning remains locally myopic, failing to\nmaintain coherent multi-step planning, leading to reasoning failures even when\nrelevant knowledge exists. We propose Graph-RFT, a novel two-stage\nreinforcement fine-tuning KGQA framework with a\n'plan-KGsearch-and-Websearch-during-think' paradigm, that enables LLMs to\nperform autonomous planning and adaptive retrieval scheduling across KG and web\nsources under incomplete knowledge conditions. Graph-RFT introduces a\nchain-of-thought fine-tuning method with a customized plan-retrieval dataset\nactivates structured reasoning and resolves the GRPO cold-start problem. It\nthen introduces a novel plan-retrieval guided reinforcement learning process\nintegrates explicit planning and retrieval actions with a multi-reward design,\nenabling coverage-aware retrieval scheduling. It employs a Cartesian-inspired\nplanning module to decompose complex questions into ordered subquestions, and\nlogical expression to guide tool invocation for globally consistent multi-step\nreasoning. This reasoning retrieval process is optimized with a multi-reward\ncombining outcome and retrieval specific signals, enabling the model to learn\nwhen and how to combine KG and web retrieval effectively.", "AI": {"tldr": "\u63d0\u51faGraph-RFT\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u5f3a\u5316\u5fae\u8c03\u8ba9LLM\u5728\u77e5\u8bc6\u56fe\u8c31\u4e0d\u5b8c\u6574\u6761\u4ef6\u4e0b\u8fdb\u884c\u81ea\u4e3b\u89c4\u5212\u548c\u81ea\u9002\u5e94\u68c0\u7d22\u8c03\u5ea6\uff0c\u89e3\u51b3\u73b0\u6709KGQA\u65b9\u6cd5\u5728\u590d\u6742\u573a\u666f\u4e2d\u7684\u63a8\u7406\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709KGQA\u65b9\u6cd5\u96be\u4ee5\u5145\u5206\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\u7684\u4e30\u5bcc\u77e5\u8bc6\u548cLLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5047\u8bbeKG\u8986\u76d6\u5b8c\u6574\u4e14\u7f3a\u4e4f\u5224\u65ad\u4f55\u65f6\u9700\u8981\u5916\u90e8\u4fe1\u606f\u7684\u673a\u5236\uff0c\u63a8\u7406\u8fc7\u7a0b\u7f3a\u4e4f\u8fde\u8d2f\u7684\u591a\u6b65\u89c4\u5212\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u5f3a\u5316\u5fae\u8c03\uff1a1\uff09\u94fe\u5f0f\u601d\u7ef4\u5fae\u8c03\u65b9\u6cd5\u6fc0\u6d3b\u7ed3\u6784\u5316\u63a8\u7406\uff1b2\uff09\u89c4\u5212-\u68c0\u7d22\u5f15\u5bfc\u7684\u5f3a\u5316\u5b66\u4e60\u8fc7\u7a0b\uff0c\u96c6\u6210\u663e\u5f0f\u89c4\u5212\u548c\u68c0\u7d22\u52a8\u4f5c\uff0c\u4f7f\u7528\u7b1b\u5361\u5c14\u5f0f\u89c4\u5212\u6a21\u5757\u5206\u89e3\u590d\u6742\u95ee\u9898\uff0c\u903b\u8f91\u8868\u8fbe\u5f0f\u6307\u5bfc\u5de5\u5177\u8c03\u7528\u3002", "result": "\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u81ea\u4e3b\u89c4\u5212\u548c\u8de8KG\u4e0e\u7f51\u7edc\u6e90\u7684\u9002\u5e94\u6027\u68c0\u7d22\u8c03\u5ea6\uff0c\u89e3\u51b3GRPO\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u5b9e\u73b0\u5168\u5c40\u4e00\u81f4\u7684\u591a\u6b65\u63a8\u7406\u3002", "conclusion": "Graph-RFT\u901a\u8fc7\u521b\u65b0\u7684'\u89c4\u5212-KG\u641c\u7d22-\u7f51\u7edc\u641c\u7d22-\u601d\u8003'\u8303\u5f0f\uff0c\u6709\u6548\u63d0\u5347\u4e86LLM\u5728\u590d\u6742KGQA\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u548c\u68c0\u7d22\u6548\u7387\u3002"}}
{"id": "2510.20784", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20784", "abs": "https://arxiv.org/abs/2510.20784", "authors": ["Fares Fourati"], "title": "A Coherence-Based Measure of AGI", "comment": "13 pages, 1 figure, 12 tables", "summary": "Recent work by \\citet{hendrycks2025agidefinition} formalized\n\\textit{Artificial General Intelligence} (AGI) as the arithmetic mean of\nproficiencies across cognitive domains derived from the Cattell--Horn--Carroll\n(CHC) model of human cognition. While elegant, this definition assumes\n\\textit{compensability} -- that exceptional ability in some domains can offset\nfailure in others. True general intelligence, however, should reflect\n\\textit{coherent sufficiency}: balanced competence across all essential\ndomains. We propose a coherence-aware measure of AGI based on the integral of\ngeneralized means over a continuum of compensability exponents. This\nformulation spans arithmetic, geometric, and harmonic regimes, and the\nresulting \\textit{area under the curve} (AUC) quantifies robustness under\nvarying compensability assumptions. Unlike the arithmetic mean, which rewards\nspecialization, the AUC penalizes imbalance and captures inter-domain\ndependency. Applied to published CHC-based domain scores for GPT-4 and GPT-5,\nthe coherence-adjusted AUC reveals that both systems remain far from general\ncompetence despite high arithmetic scores (e.g., GPT-5 at~24\\%). Integrating\nthe generalized mean thus yields a principled, interpretable, and stricter\nfoundation for measuring genuine progress toward AGI.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5e7f\u4e49\u5747\u503c\u79ef\u5206\u7684\u4e00\u81f4\u6027\u611f\u77e5AGI\u5ea6\u91cf\u65b9\u6cd5\uff0c\u66ff\u4ee3\u4ec5\u4f7f\u7528\u7b97\u672f\u5e73\u5747\u503c\u7684\u5b9a\u4e49\uff0c\u5f3a\u8c03\u8de8\u8ba4\u77e5\u9886\u57df\u7684\u5e73\u8861\u80fd\u529b\u800c\u975e\u8865\u507f\u6027\u3002", "motivation": "\u73b0\u6709AGI\u5b9a\u4e49\u4f7f\u7528\u7b97\u672f\u5e73\u5747\u503c\uff0c\u5047\u8bbe\u9886\u57df\u95f4\u80fd\u529b\u53ef\u8865\u507f\uff08\u5373\u67d0\u4e9b\u9886\u57df\u7684\u5353\u8d8a\u80fd\u529b\u53ef\u62b5\u6d88\u5176\u4ed6\u9886\u57df\u7684\u5931\u8d25\uff09\uff0c\u4f46\u771f\u6b63\u7684\u901a\u7528\u667a\u80fd\u5e94\u53cd\u6620\u6240\u6709\u5173\u952e\u9886\u57df\u7684\u5e73\u8861\u80fd\u529b\u3002", "method": "\u57fa\u4e8e\u5e7f\u4e49\u5747\u503c\u5728\u8865\u507f\u6027\u6307\u6570\u8fde\u7eed\u7edf\u4e0a\u7684\u79ef\u5206\uff0c\u6784\u5efa\u9762\u79ef\u4e0b\u66f2\u7ebf(AUC)\u5ea6\u91cf\uff0c\u6db5\u76d6\u7b97\u672f\u3001\u51e0\u4f55\u548c\u8c03\u548c\u5747\u503c\u7b49\u4e0d\u540c\u8865\u507f\u6027\u5047\u8bbe\u3002", "result": "\u5e94\u7528\u4e8eGPT-4\u548cGPT-5\u7684CHC\u9886\u57df\u5f97\u5206\u663e\u793a\uff0c\u5c3d\u7ba1\u7b97\u672f\u5f97\u5206\u8f83\u9ad8\uff08\u5982GPT-5\u8fbe24%\uff09\uff0c\u4f46\u4e00\u81f4\u6027\u8c03\u6574\u540e\u7684AUC\u63ed\u793a\u4e24\u8005\u8ddd\u79bb\u901a\u7528\u80fd\u529b\u4ecd\u5f88\u8fdc\u3002", "conclusion": "\u5e7f\u4e49\u5747\u503c\u79ef\u5206\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u3001\u53ef\u89e3\u91ca\u4e14\u66f4\u4e25\u683c\u7684AGI\u8fdb\u5c55\u5ea6\u91cf\u57fa\u7840\uff0c\u60e9\u7f5a\u4e0d\u5e73\u8861\u5e76\u6355\u6349\u9886\u57df\u95f4\u4f9d\u8d56\u6027\u3002"}}
{"id": "2510.20809", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20809", "abs": "https://arxiv.org/abs/2510.20809", "authors": ["Xueyan Zou", "Jianglong Ye", "Hao Zhang", "Xiaoyu Xiang", "Mingyu Ding", "Zhaojing Yang", "Yong Jae Lee", "Zhuowen Tu", "Sifei Liu", "Xiaolong Wang"], "title": "Real Deep Research for AI, Robotics and Beyond", "comment": "website: https://realdeepresearch.github.io", "summary": "With the rapid growth of research in AI and robotics now producing over\n10,000 papers annually it has become increasingly difficult for researchers to\nstay up to date. Fast evolving trends, the rise of interdisciplinary work, and\nthe need to explore domains beyond one's expertise all contribute to this\nchallenge. To address these issues, we propose a generalizable pipeline capable\nof systematically analyzing any research area: identifying emerging trends,\nuncovering cross domain opportunities, and offering concrete starting points\nfor new inquiry. In this work, we present Real Deep Research (RDR) a\ncomprehensive framework applied to the domains of AI and robotics, with a\nparticular focus on foundation models and robotics advancements. We also\nbriefly extend our analysis to other areas of science. The main paper details\nthe construction of the RDR pipeline, while the appendix provides extensive\nresults across each analyzed topic. We hope this work sheds light for\nresearchers working in the field of AI and beyond.", "AI": {"tldr": "\u63d0\u51fa\u4e86Real Deep Research (RDR)\u6846\u67b6\uff0c\u7528\u4e8e\u7cfb\u7edf\u5206\u6790AI\u548c\u673a\u5668\u4eba\u9886\u57df\u7684\u7814\u7a76\u8d8b\u52bf\uff0c\u8bc6\u522b\u65b0\u5174\u8d8b\u52bf\u548c\u8de8\u9886\u57df\u673a\u4f1a\uff0c\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u5e94\u5bf9\u8bba\u6587\u6570\u91cf\u5feb\u901f\u589e\u957f\u5e26\u6765\u7684\u6311\u6218\u3002", "motivation": "AI\u548c\u673a\u5668\u4eba\u9886\u57df\u6bcf\u5e74\u4ea7\u751f\u8d85\u8fc710,000\u7bc7\u8bba\u6587\uff0c\u7814\u7a76\u4eba\u5458\u96be\u4ee5\u8ddf\u4e0a\u5feb\u901f\u53d1\u5c55\u7684\u8d8b\u52bf\uff0c\u9700\u8981\u8de8\u5b66\u79d1\u5408\u4f5c\u548c\u63a2\u7d22\u65b0\u9886\u57df\uff0c\u56e0\u6b64\u9700\u8981\u7cfb\u7edf\u5316\u7684\u5206\u6790\u5de5\u5177\u3002", "method": "\u6784\u5efa\u4e86\u901a\u7528\u7684RDR\u6d41\u6c34\u7ebf\uff0c\u80fd\u591f\u7cfb\u7edf\u5206\u6790\u4efb\u4f55\u7814\u7a76\u9886\u57df\uff0c\u8bc6\u522b\u65b0\u5174\u8d8b\u52bf\u3001\u53d1\u73b0\u8de8\u9886\u57df\u673a\u4f1a\uff0c\u5e76\u63d0\u4f9b\u5177\u4f53\u7684\u7814\u7a76\u8d77\u70b9\u3002", "result": "\u5c06RDR\u6846\u67b6\u5e94\u7528\u4e8eAI\u548c\u673a\u5668\u4eba\u9886\u57df\uff0c\u7279\u522b\u5173\u6ce8\u57fa\u7840\u6a21\u578b\u548c\u673a\u5668\u4eba\u6280\u672f\u8fdb\u6b65\uff0c\u5e76\u6269\u5c55\u5230\u5176\u4ed6\u79d1\u5b66\u9886\u57df\u3002", "conclusion": "RDR\u6846\u67b6\u4e3aAI\u53ca\u5176\u4ed6\u9886\u57df\u7684\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5206\u6790\u5de5\u5177\uff0c\u5e2e\u52a9\u4ed6\u4eec\u5728\u5feb\u901f\u53d1\u5c55\u7684\u7814\u7a76\u73af\u5883\u4e2d\u4fdd\u6301\u524d\u6cbf\u5730\u4f4d\u3002"}}
