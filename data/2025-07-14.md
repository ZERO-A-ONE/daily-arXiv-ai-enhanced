<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 10]
- [cs.CR](#cs.CR) [Total: 7]
- [cs.AI](#cs.AI) [Total: 22]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [The State of Computational Science in Fission and Fusion Energy](https://arxiv.org/abs/2507.08061)
*Andrea Morales Coto,Aditi Verma*

Main category: cs.SE

TL;DR: 调查显示，核工程领域的计算科学家偏好现代编程语言、开源代码和模块化软件，预示未来5-10年软件工具将向多物理场代码、Python和C++等语言转变。


<details>
  <summary>Details</summary>
Motivation: 研究核工程中软件工具的使用趋势，以了解未来发展方向。

Method: 对103位从事核聚变和核裂变能源代码开发的科学家进行调查，分析其工具偏好和开发体验。

Result: 发现现代编程语言（如Python、C++）和开源代码的普及，FORTRAN使用减少，代码开发预算增加。

Conclusion: 核工程软件未来将趋向模块化、轻量化，并更受组织重视。

Abstract: The tools used to engineer something are just as important as the thing that
is actually being engineered. In fact, in many cases, the tools can indeed
determine what is engineerable. In fusion and fission1 energy engineering,
software has become the dominant tool for design. For that reason, in 2024, for
the first time ever, we asked 103 computational scientists developing the codes
used in fusion and fission energy about the problems they are attempting to
solve with their codes, the tools available to them to solve them, and their
end to end developer experience with said tools.
  The results revealed a changing tide in software tools in fusion and fission,
with more and more computational scientists preferring modern programming
languages, open-source codes, and modular software. These trends represent a
peek into what will happen 5 to 10 years in the future of nuclear engineering.
Since the majority of our respondents belonged to US national labs and
universities, these results hint at the most cutting-edge trends in the
industry. The insights included in the State of Computational Science in
Fission and Fusion Energy indicate a dramatic shift toward multiphysics codes,
a drop-off in the use of FORTRAN in favor of more modern languages like Python
and C++, and ever-rising budgets for code development, at times reaching $50M
in a single organization.
  Our survey paints a future of nuclear engineering codes that is modular in
nature, small in terms of compute, and increasingly prioritized by
organizations. Access to our results in web form are available online.

</details>


### [2] [Code with Me or for Me? How Increasing AI Automation Transforms Developer Workflows](https://arxiv.org/abs/2507.08149)
*Valerie Chen,Ameet Talwalkar,Robert Brennan,Graham Neubig*

Main category: cs.SE

TL;DR: 研究探讨了开发者与自动化编码代理的互动，发现其潜力超过现有Copilot工具，但需解决用户理解代理行为等挑战。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注Copilot工具，而对更自动化的编码代理评估不足，需探索其对开发者生产力和体验的影响。

Method: 通过比较GitHub Copilot和OpenHands两种工具，招募常用Copilot的开发者参与实验。

Result: 编码代理能完成Copilot无法完成的任务并减少用户努力，但需解决用户理解代理行为的挑战。

Conclusion: 研究揭示了编码代理对开发者工作流的改变，并提出了构建新代理的建议，同时指出推广代理工具的挑战。

Abstract: Developers now have access to a growing array of increasingly autonomous AI
tools to support software development. While numerous studies have examined
developer use of copilots, which can provide chat assistance or code
completions, evaluations of coding agents, which can automatically write files
and run code, still largely rely on static benchmarks without
humans-in-the-loop. In this work, we conduct the first academic study to
explore developer interactions with coding agents and characterize how more
autonomous AI tools affect user productivity and experience, compared to
existing copilots. We evaluate two leading copilot and agentic coding
assistants, GitHub Copilot and OpenHands, recruiting participants who regularly
use the former. Our results show agents have the potential to assist developers
in ways that surpass copilots (e.g., completing tasks that humans might not
have accomplished before) and reduce the user effort required to complete
tasks. However, there are challenges involved in enabling their broader
adoption, including how to ensure users have an adequate understanding of agent
behaviors. Our results not only provide insights into how developer workflows
change as a result of coding agents but also highlight how user interactions
with agents differ from those with existing copilots, motivating a set of
recommendations for researchers building new agents. Given the broad set of
developers who still largely rely on copilot-like systems, our work highlights
key challenges of adopting more agentic systems into developer workflows.

</details>


### [3] [The Impact of Generative AI on Code Expertise Models: An Exploratory Study](https://arxiv.org/abs/2507.08160)
*Otávio Cury,Guilherme Avelino*

Main category: cs.SE

TL;DR: 论文探讨了生成式AI工具在代码生成中对开发者理解代码的影响，并分析了其对源代码知识模型和Truck Factor算法的潜在影响。


<details>
  <summary>Details</summary>
Motivation: 研究生成式AI工具（如ChatGPT）在软件开发中的广泛使用是否会导致开发者对生成代码的理解降低，进而影响基于代码知识模型的开发者专业度评估。

Method: 通过收集GitHub项目中ChatGPT生成代码的统计数据，并模拟不同GenAI贡献程度的场景，分析其对知识模型和Truck Factor算法的影响。

Result: 大多数模拟场景显示，GenAI的使用对当前的专业度评估指标产生了可测量的影响，表明这些指标可能因GenAI的集成而变得不可靠。

Conclusion: 随着生成式AI在开发流程中的深入应用，现有的开发者专业度评估指标的可靠性可能下降，需要重新审视这些评估方法。

Abstract: Generative Artificial Intelligence (GenAI) tools for source code generation
have significantly boosted productivity in software development. However, they
also raise concerns, particularly the risk that developers may rely heavily on
these tools, reducing their understanding of the generated code. We hypothesize
that this loss of understanding may be reflected in source code knowledge
models, which are used to identify developer expertise. In this work, we
present an exploratory analysis of how a knowledge model and a Truck Factor
algorithm built upon it can be affected by GenAI usage. To investigate this, we
collected statistical data on the integration of ChatGPT-generated code into
GitHub projects and simulated various scenarios by adjusting the degree of
GenAI contribution. Our findings reveal that most scenarios led to measurable
impacts, indicating the sensitivity of current expertise metrics. This suggests
that as GenAI becomes more integrated into development workflows, the
reliability of such metrics may decrease.

</details>


### [4] [Leveraging Large Language Models for Classifying App Users' Feedback](https://arxiv.org/abs/2507.08250)
*Yasaman Abedini,Abbas Heydarnoori*

Main category: cs.SE

TL;DR: 论文研究了四种先进LLM（GPT-3.5-Turbo、GPT-4、Flan-T5和Llama3-70b）在用户反馈分类中的应用，以解决标注数据不足的问题。实验表明，LLM能有效分类粗粒度反馈，并通过标注数据增强提升BERT模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有监督学习方法依赖大量标注数据，但标注成本高。研究旨在利用LLM提升用户反馈分类的泛化能力。

Method: 在八个标注数据集上评估四种LLM的分类能力，并将其作为标注工具增强训练数据。

Result: LLM能有效分类粗粒度反馈，数据增强显著提升BERT模型的分类性能。

Conclusion: LLM可作为高效标注工具，解决标注数据不足问题，并提升分类模型性能。

Abstract: In recent years, significant research has been conducted into classifying
application (app) user feedback, primarily relying on supervised machine
learning algorithms. However, fine-tuning more generalizable classifiers based
on existing labeled datasets remains an important challenge, as creating large
and accurately labeled datasets often requires considerable time and resources.
In this paper, we evaluate the capabilities of four advanced LLMs, including
GPT-3.5-Turbo, GPT-4, Flan-T5, and Llama3-70b, to enhance user feedback
classification and address the challenge of the limited labeled dataset. To
achieve this, we conduct several experiments on eight datasets that have been
meticulously labeled in prior research. These datasets include user reviews
from app stores, posts from the X platform, and discussions from the public
forums, widely recognized as representative sources of app user feedback. We
analyze the performance of various LLMs in identifying both fine-grained and
coarse-grained user feedback categories. Given the substantial volume of daily
user feedback and the computational limitations of LLMs, we leverage these
models as an annotation tool to augment labeled datasets with general and
app-specific data. This augmentation aims to enhance the performance of
state-of-the-art BERT-based classification models. Our findings indicate that
LLMs when guided by well-crafted prompts, can effectively classify user
feedback into coarse-grained categories. Moreover, augmenting the training
dataset with datasets labeled using the consensus of LLMs can significantly
enhance classifier performance.

</details>


### [5] [Computing Floating-Point Errors by Injecting Perturbations](https://arxiv.org/abs/2507.08467)
*Youshuai Tan,Zhanwei Zhang,Jinfu Chen,Zishuo Ding,Jifeng Xuan,Weiyi Shang*

Main category: cs.SE

TL;DR: PI-detector是一种新方法，用于高效准确地计算浮点程序中的误差，解决了现有工具ATOMU和FPCC的局限性。


<details>
  <summary>Details</summary>
Motivation: 浮点误差可能导致严重后果，现有检测方法存在实现困难和执行时间长的问题，ATOMU有误报，FPCC速度慢。

Method: PI-detector通过在原子操作中注入小扰动，比较原始程序与扰动版本的输出，计算浮点误差。

Result: 实验表明，PI-detector能高效准确地计算浮点误差。

Conclusion: PI-detector提供了一种有效且高效的浮点误差检测方法。

Abstract: Floating-point programs form the foundation of modern science and
engineering, providing the essential computational framework for a wide range
of applications, such as safety-critical systems, aerospace engineering, and
financial analysis. Floating-point errors can lead to severe consequences.
Although floating-point errors widely exist, only a subset of inputs may
trigger significant errors in floating-point programs. Therefore, it is crucial
to determine whether a given input could produce such errors. Researchers tend
to take the results of high-precision floating-point programs as oracles for
detecting floating-point errors, which introduces two main limitations: (1)
difficulty of implementation and (2) prolonged execution time. The two recent
tools, ATOMU and FPCC, can partially address these issues. However, ATOMU
suffers from false positives; while FPCC, though eliminating false positives,
operates at a considerably slower speed.
  To address these two challenges, we propose a novel approach named
PI-detector to computing floating-point errors effectively and efficiently. Our
approach is based on the observation that floating-point errors stem from large
condition numbers in atomic operations (such as addition and subtraction),
which then propagate and accumulate. PI-detector injects small perturbations
into the operands of individual atomic operations within the program and
compares the outcomes of the original program with the perturbed version to
compute floating-point errors. We evaluate PI-detector with datasets from ATOMU
and HSED, as well as a complex linear system-solving program. Experimental
results demonstrate that PI-detector can perform efficient and accurate
floating-point error computation.

</details>


### [6] [InferLog: Accelerating LLM Inference for Online Log Parsing via ICL-oriented Prefix Caching](https://arxiv.org/abs/2507.08523)
*Yilun Wang,Pengfei Chen,Haiyu Huang,Zilong He,Gou Tan,Chuanfu Zhang,Jingkai He,Zibin Zheng*

Main category: cs.SE

TL;DR: InferLog提出了一种针对在线日志解析的LLM推理优化方法，通过改进前缀缓存效率和动态配置调优，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的日志解析方法在隐私和性能方面存在局限，无法满足高吞吐量和低延迟的需求。

Method: 设计前缀感知的ICL优化策略和基于元学习的动态配置调优管道。

Result: 在Loghub数据集和vLLM上，InferLog显著优于现有方法，且不牺牲解析精度。

Conclusion: InferLog解决了LLM推理效率瓶颈，为在线日志解析提供了高效解决方案。

Abstract: Modern software systems generate massive volumes of runtime logs,
necessitating efficient and accurate log parsing to enable critical downstream
tasks such as anomaly detection and root cause analysis. Recently, large
language models (LLMs) have achieved advanced accuracy on log parsing, but
their deployment in production environments faces two major limitations: (1)
the privacy risks associated with commercial LLMs, driving the adoption of
local deployment, and (2) the stringent latency and throughput requirements
imposed by high-volume log streams, which existing LLM-based parsers fail to
meet. Although recent efforts have reduced the number of LLM queries, they
overlook the high latency of the LLM invocations, where concurrent log parsing
requests can cause serve performance degradation of LLM inference system.
  In this study, we present InferLog, the first LLM inference optimization
method for online log parsing. Our key insight is that the inference efficiency
emerges as the vital bottleneck in LLM-based online log parsing, rather than
parsing accuracy. InferLog accelerates inference by designing (1) A
Prefix-aware ICL Refinement policy to refine the examples and permutation of
in-context learning to improve the prefix caching efficiency. (2) A rapid and
task-specific configuration tuning pipeline based on meta-learning to find the
optimal LLM scheduling-related configuration for dynamic log parsing workloads.
The experimental results based on Loghub dataset and vLLM demonstrate that
InferLog significantly outperforms existing inference optimization methods and
markedly accelerates the state-of-the-art LLM-based log parser without
compromising parsing accuracy.

</details>


### [7] [Generating Proto-Personas through Prompt Engineering: A Case Study on Efficiency, Effectiveness and Empathy](https://arxiv.org/abs/2507.08594)
*Fernando Ayach,Vitor Lameirão,Raul Leão,Jerfferson Felizardo,Rafael Sobrinho,Vanessa Borges,Patrícia Matsubara,Awdren Fontão*

Main category: cs.SE

TL;DR: 论文提出了一种基于提示工程的生成式AI方法，用于自动生成原型人物角色，以提高效率和减少偏见。


<details>
  <summary>Details</summary>
Motivation: 手动创建原型人物角色耗时、费力且易受偏见影响，因此需要一种更高效的方法。

Method: 采用生成式AI（GenAI）和提示工程方法，通过案例研究（19名参与者）进行定性和定量分析。

Result: 方法显著提高了效率和质量，用户接受度较高，但在泛化和领域特异性方面存在局限。

Conclusion: 生成式AI可有效整合到产品发现实践中，但需解决泛化和情感共鸣的挑战。

Abstract: Proto-personas are commonly used during early-stage Product Discovery, such
as Lean Inception, to guide product definition and stakeholder alignment.
However, the manual creation of proto-personas is often time-consuming,
cognitively demanding, and prone to bias. In this paper, we propose and
empirically investigate a prompt engineering-based approach to generate
proto-personas with the support of Generative AI (GenAI). Our goal is to
evaluate the approach in terms of efficiency, effectiveness, user acceptance,
and the empathy elicited by the generated personas. We conducted a case study
with 19 participants embedded in a real Lean Inception, employing a qualitative
and quantitative methods design. The results reveal the approach's efficiency
by reducing time and effort and improving the quality and reusability of
personas in later discovery phases, such as Minimum Viable Product (MVP)
scoping and feature refinement. While acceptance was generally high, especially
regarding perceived usefulness and ease of use, participants noted limitations
related to generalization and domain specificity. Furthermore, although
cognitive empathy was strongly supported, affective and behavioral empathy
varied significantly across participants. These results contribute novel
empirical evidence on how GenAI can be effectively integrated into software
Product Discovery practices, while also identifying key challenges to be
addressed in future iterations of such hybrid design processes.

</details>


### [8] [NL in the Middle: Code Translation with LLMs and Intermediate Representations](https://arxiv.org/abs/2507.08627)
*Chi-en Amy Tai,Pengyu Nie,Lukasz Golab,Alexander Wong*

Main category: cs.SE

TL;DR: 论文探讨了通过自然语言和抽象语法树作为中间表示提升大语言模型代码翻译准确性的方法，发现链式思维提示结合自然语言摘要效果最佳。


<details>
  <summary>Details</summary>
Motivation: 研究发现大语言模型生成的代码翻译存在错误，希望通过中间表示（如自然语言和抽象语法树）提升翻译准确性。

Method: 采用多种提示方法（从单次提示到链式思维提示）集成中间表示，并在Open Gpt4 8X7B、StarCoder和CodeGen模型上进行实验。

Result: 链式思维提示结合自然语言摘要效果最好，Open Gpt4 8X7B模型的成功翻译率分别提升了13.8%和6.7%。

Conclusion: 中间表示（尤其是自然语言摘要）结合链式思维提示能显著提升代码翻译的准确性。

Abstract: Studies show that large language models (LLMs) produce buggy code
translations. One avenue to improve translation accuracy is through
intermediate representations, which could provide structured insights to guide
the model's understanding. We explore whether code translation using LLMs can
benefit from intermediate representations via natural language (NL) and
abstract syntax trees (ASTs). Since prompt engineering greatly affects LLM
performance, we consider several ways to integrate these representations, from
one-shot to chain-of-thought (CoT) prompting. Using Open Gpt4 8X7B and
specialized StarCoder and CodeGen models on popular code translation benchmarks
(CodeNet and AVATAR), we find that CoT with an intermediate NL summary performs
best, with an increase of 13.8% and 6.7%, respectively, in successful
translations for the best-performing model (Open Gpt4 8X7B) compared to the
zero-shot prompt.

</details>


### [9] [LLMCup: Ranking-Enhanced Comment Updating with LLMs](https://arxiv.org/abs/2507.08671)
*Hua Ge,Juan Zhai,Minxue Pan,Fusen He,Ziyue Tan*

Main category: cs.SE

TL;DR: 论文提出了一种基于大型语言模型（LLM）的注释更新框架LLMCup，通过多提示策略生成候选注释，并结合排名模型CupRank选择最佳更新，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 开发者常更新代码但忽略注释，导致文档过时或不一致，现有自动更新方法（如CUP和HebCup）存在信息遗漏或误解问题。

Method: LLMCup利用LLM的多提示策略生成候选注释，再通过CupRank模型选择最佳更新。

Result: 实验显示LLMCup在准确性（Accuracy）、BLEU-4、METEOR、F1和SentenceBert相似度上均显著优于基线方法（CUP和HebCup），部分更新甚至优于人工注释。

Conclusion: LLMCup展示了LLM在注释更新任务中的潜力，并强调了人工评估在注释质量评估中的重要性。

Abstract: While comments are essential for enhancing code readability and
maintainability in modern software projects, developers are often motivated to
update code but not comments, leading to outdated or inconsistent documentation
that hinders future understanding and maintenance. Recent approaches such as
CUP and HebCup have attempted automatic comment updating using neural
sequence-to-sequence models and heuristic rules, respectively. However, these
methods can miss or misinterpret crucial information during comment updating,
resulting in inaccurate comments, and they often struggle with complex update
scenarios. Given these challenges, a promising direction lies in leveraging
large language models (LLMs), which have shown impressive performance in
software engineering tasks such as comment generation, code synthesis, and
program repair. This suggests their strong potential to capture the logic
behind code modifications - an ability that is crucial for the task of comment
updating. Nevertheless, selecting an appropriate prompt strategy for an LLM on
each update case remains challenging. To address this, we propose a novel
comment updating framework, LLMCup, which first uses multiple prompt strategies
to provide diverse candidate updated comments via an LLM, and then employs a
ranking model, CupRank, to select the best candidate as final updated comment.
Experimental results demonstrate the effectiveness of LLMCup, with improvements
over state-of-the-art baselines (CUP and HebCup) by 49.0%-116.9% in Accuracy,
10.8%-20% in BLEU-4, 4.6% in METEOR, 0.9%-1.9% in F1, and 2.1%-3.4% in
SentenceBert similarity. Furthermore, a user study shows that comments updated
by LLMCup sometimes surpass human-written updates, highlighting the importance
of incorporating human evaluation in comment quality assessment.

</details>


### [10] [Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning](https://arxiv.org/abs/2507.08730)
*Zezhen Xiang,Jingzhi Gong,Tao Chen*

Main category: cs.SE

TL;DR: DHDA是一个在线配置性能学习框架，通过双重层次适应机制处理动态环境中的全局和局部概念漂移，显著提升准确性和适应性。


<details>
  <summary>Details</summary>
Motivation: 现代可配置软件系统在动态环境中运行时，由于工作负载变化、硬件更新等因素，会引入全局和局部概念漂移，传统离线学习和迁移学习方法难以实时适应这些变化。

Method: DHDA采用双重层次适应机制，上层通过重新划分数据并局部重训练处理全局漂移，下层通过异步调整局部模型检测和适应局部漂移，结合增量更新和定期完全重训练以平衡效率。

Result: 在八个软件系统上的评估显示，DHDA显著优于现有方法，准确性提升高达2倍，并能有效适应概念漂移，同时保持合理开销。

Conclusion: DHDA通过双重层次适应机制，成功解决了动态环境中配置性能学习的挑战，为实时适应概念漂移提供了高效解决方案。

Abstract: Modern configurable software systems need to learn models that correlate
configuration and performance. However, when the system operates in dynamic
environments, the workload variations, hardware changes, and system updates
will inevitably introduce concept drifts at different levels - global drifts,
which reshape the performance landscape of the entire configuration space; and
local drifts, which only affect certain sub-regions of that space. As such,
existing offline and transfer learning approaches can struggle to adapt to
these implicit and unpredictable changes in real-time, rendering configuration
performance learning challenging. To address this, we propose DHDA, an online
configuration performance learning framework designed to capture and adapt to
these drifts at different levels. The key idea is that DHDA adapts to both the
local and global drifts using dually hierarchical adaptation: at the upper
level, we redivide the data into different divisions, within each of which the
local model is retrained, to handle global drifts only when necessary. At the
lower level, the local models of the divisions can detect local drifts and
adapt themselves asynchronously. To balance responsiveness and efficiency, DHDA
combines incremental updates with periodic full retraining to minimize
redundant computation when no drifts are detected. Through evaluating eight
software systems and against state-of-the-art approaches, we show that DHDA
achieves considerably better accuracy and can effectively adapt to drifts with
up to 2x improvements, while incurring reasonable overhead and is able to
improve different local models in handling concept drift.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [11] [Beyond the Worst Case: Extending Differential Privacy Guarantees to Realistic Adversaries](https://arxiv.org/abs/2507.08158)
*Marika Swanberg,Meenatchi Sundaram Muthu Selva Annamalai,Jamie Hayes,Borja Balle,Adam Smith*

Main category: cs.CR

TL;DR: 本文探讨了差分隐私（DP）在最坏情况下的隐私保护能力，并提出了一个通用框架，用于分析DP机制在多种现实攻击场景中的隐私风险。


<details>
  <summary>Details</summary>
Motivation: 研究差分隐私在最坏情况下的保护能力，并填补现有研究中对攻击模型与隐私保护之间关系的理解空白。

Method: 提出一个灵活的框架，扩展了现有DP机制的边界，能够计算多种自然攻击场景下的高概率隐私保证。

Result: 通过两个实证案例研究，验证了框架的实用性，并揭示了非均匀数据隐私风险与攻击者先验概率的密切关系。

Conclusion: 该框架为理解DP机制在复杂攻击场景中的隐私泄漏提供了更细致的视角。

Abstract: Differential Privacy (DP) is a family of definitions that bound the
worst-case privacy leakage of a mechanism. One important feature of the
worst-case DP guarantee is it naturally implies protections against adversaries
with less prior information, more sophisticated attack goals, and complex
measures of a successful attack. However, the analytical tradeoffs between the
adversarial model and the privacy protections conferred by DP are not well
understood thus far. To that end, this work sheds light on what the worst-case
guarantee of DP implies about the success of attackers that are more
representative of real-world privacy risks.
  In this paper, we present a single flexible framework that generalizes and
extends the patchwork of bounds on DP mechanisms found in prior work. Our
framework allows us to compute high-probability guarantees for DP mechanisms on
a large family of natural attack settings that previous bounds do not capture.
One class of such settings is the approximate reconstruction of multiple
individuals' data, such as inferring nearly entire columns of a tabular data
set from noisy marginals and extracting sensitive information from DP-trained
language models.
  We conduct two empirical case studies to illustrate the versatility of our
bounds and compare them to the success of state-of-the-art attacks.
Specifically, we study attacks that extract non-uniform PII from a DP-trained
language model, as well as multi-column reconstruction attacks where the
adversary has access to some columns in the clear and attempts to reconstruct
the remaining columns for each person's record. We find that the absolute
privacy risk of attacking non-uniform data is highly dependent on the
adversary's prior probability of success. Our high probability bounds give us a
nuanced understanding of the privacy leakage of DP mechanisms in a variety of
previously understudied attack settings.

</details>


### [12] [GPUHammer: Rowhammer Attacks on GPU Memories are Practical](https://arxiv.org/abs/2507.08166)
*Chris S. Lin,Joyce Qu,Gururaj Saileshwar*

Main category: cs.CR

TL;DR: GPUHammer是首个针对NVIDIA GPU和GDDR6内存的Rowhammer攻击，通过逆向工程和优化内存访问，成功在GPU上实现位翻转，并展示了其对机器学习模型的潜在危害。


<details>
  <summary>Details</summary>
Motivation: 研究Rowhammer漏洞在GPU上的影响，填补了现有研究在GDDR内存上的空白，尤其是针对新兴机器学习应用的安全性。

Method: 提出GPUHammer，通过逆向工程GDDR内存行映射，优化GPU内存访问以增强攻击强度，并绕过现有防护措施。

Result: 成功在NVIDIA A6000 GPU上实现位翻转，最多影响4个DRAM存储体的8个位，并导致机器学习模型准确率下降高达80%。

Conclusion: GPUHammer证明了Rowhammer攻击在GPU上的可行性，揭示了GDDR内存的安全隐患，对机器学习等关键应用构成威胁。

Abstract: Rowhammer is a read disturbance vulnerability in modern DRAM that causes
bit-flips, compromising security and reliability. While extensively studied on
Intel and AMD CPUs with DDR and LPDDR memories, its impact on GPUs using GDDR
memories, critical for emerging machine learning applications, remains
unexplored. Rowhammer attacks on GPUs face unique challenges: (1) proprietary
mapping of physical memory to GDDR banks and rows, (2) high memory latency and
faster refresh rates that hinder effective hammering, and (3) proprietary
mitigations in GDDR memories, difficult to reverse-engineer without FPGA-based
test platforms. We introduce GPUHammer, the first Rowhammer attack on NVIDIA
GPUs with GDDR6 DRAM. GPUHammer proposes novel techniques to reverse-engineer
GDDR DRAM row mappings, and employs GPU-specific memory access optimizations to
amplify hammering intensity and bypass mitigations. Thus, we demonstrate the
first successful Rowhammer attack on a discrete GPU, injecting up to 8
bit-flips across 4 DRAM banks on an NVIDIA A6000 with GDDR6 memory. We also
show how an attacker can use these to tamper with ML models, causing
significant accuracy drops (up to 80%).

</details>


### [13] [TruChain: A Multi-Layer Architecture for Trusted, Verifiable, and Immutable Open Banking Data](https://arxiv.org/abs/2507.08286)
*Aufa Nasywa Rahman,Bimo Sunarfri Hantono,Guntur Dharma Putra*

Main category: cs.CR

TL;DR: 提出了一种分层架构，通过三个信任级别确保开放银行数据可信性，包括来源验证、数据级认证和防篡改存储，并通过实验验证了其高效性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 开放银行框架虽然促进了金融创新，但仍存在数据来源未验证、数据完整性不一致和缺乏不可篡改性等技术风险，亟需解决方案。

Method: 采用三层架构：第一层通过去中心化身份和可验证呈现确保来源合法性；第二层通过加密签名验证数据真实性和一致性；第三层通过Tangle分布式账本保证数据不可篡改。

Result: 实验证明系统具有线性扩展性、稳定吞吐量、100%验证率，CPU和内存占用低（<35% CPU，350 MiB内存），相比现有方案延迟更低且数据完整性更强。

Conclusion: 该方案为金融生态系统提供了一种高效、安全的共享数据方法，同时符合监管要求。

Abstract: Open banking framework enables third party providers to access financial data
across banking institutions, leading to unprecedented innovations in the
financial sector. However, some open banking standards remain susceptible to
severe technological risks, including unverified data sources, inconsistent
data integrity, and lack of immutability. In this paper, we propose a layered
architecture that provides assurance in data trustworthiness with three
distinct levels of trust, covering source validation, data-level
authentication, and tamper-proof storage. The first layer guarantees the source
legitimacy using decentralized identity and verifiable presentation, while the
second layer verifies data authenticity and consistency using cryptographic
signing. Lastly, the third layer guarantees data immutability through the
Tangle, a directed acyclic graph distributed ledger. We implemented a
proof-of-concept implementation of our solution to evaluate its performance,
where the results demonstrate that the system scales linearly with a stable
throughput, exhibits a 100% validation rate, and utilizes under 35% of CPU and
350 MiB memory. Compared to a real-world open banking implementation, our
solution offers significantly reduced latency and stronger data integrity
assurance. Overall, our solution offers a practical and efficient system for
secure data sharing in financial ecosystems while maintaining regulatory
compliance.

</details>


### [14] [Invariant-based Robust Weights Watermark for Large Language Models](https://arxiv.org/abs/2507.08288)
*Qingxiao Guo,Xinjie Zhu,Yilong Ma,Hui Jin,Yunhao Wang,Weifeng Zhang,Xiaobing Guo*

Main category: cs.CR

TL;DR: 本文提出了一种无需重新训练或微调的鲁棒水印方案，用于保护大型语言模型的IP，通过线性约束和噪声机制实现多用户场景下的安全性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在边缘设备上的广泛应用，保护知识产权免受恶意用户侵害的需求日益增长。

Method: 为每个用户生成唯一密钥，通过模型不变性构建线性约束求解稳定水印值，并利用噪声机制隐藏水印位置以防止共谋攻击。

Result: 在Llama3、Phi3和Gemma模型上的实验表明，该方案对多种攻击方法（如微调、剪枝、量化等）具有强鲁棒性。

Conclusion: 该水印方案在保护模型IP方面表现出高效性和鲁棒性，适用于多用户场景。

Abstract: Watermarking technology has gained significant attention due to the
increasing importance of intellectual property (IP) rights, particularly with
the growing deployment of large language models (LLMs) on billions
resource-constrained edge devices. To counter the potential threats of IP theft
by malicious users, this paper introduces a robust watermarking scheme without
retraining or fine-tuning for transformer models. The scheme generates a unique
key for each user and derives a stable watermark value by solving linear
constraints constructed from model invariants. Moreover, this technology
utilizes noise mechanism to hide watermark locations in multi-user scenarios
against collusion attack. This paper evaluates the approach on three popular
models (Llama3, Phi3, Gemma), and the experimental results confirm the strong
robustness across a range of attack methods (fine-tuning, pruning,
quantization, permutation, scaling, reversible matrix and collusion attacks).

</details>


### [15] [Evaluating Post-Quantum Cryptographic Algorithms on Resource-Constrained Devices](https://arxiv.org/abs/2507.08312)
*Jesus Lopez,Viviana Cadena,Mohammad Saidur Rahman*

Main category: cs.CR

TL;DR: 论文研究了在资源受限的物联网设备上部署后量子密码（PQC）算法的可行性，实现了三种PQC算法并评估其性能，证明其实际可行性。


<details>
  <summary>Details</summary>
Motivation: 量子计算的快速发展威胁到传统加密算法（如RSA和ECC），物联网设备因资源有限亟需量子安全的加密方案。

Method: 在基于Raspberry Pi的轻量级物联网平台上实现BIKE、CRYSTALS-Kyber和HQC三种PQC算法，结合Open Quantum Safe库和mbedTLS开发量子安全密钥交换协议。

Result: 实验结果表明，PQC算法在受限硬件上的集成是可行的，计算开销、内存使用和能耗均在可接受范围内。

Conclusion: 研究强调了在下一代物联网设备中采用量子弹性加密框架的紧迫性，并提供了实际可行的解决方案。

Abstract: The rapid advancement of quantum computing poses a critical threat to
classical cryptographic algorithms such as RSA and ECC, particularly in
Internet of Things (IoT) devices, where secure communication is essential but
often constrained by limited computational resources. This paper investigates
the feasibility of deploying post-quantum cryptography (PQC) algorithms on
resource-constrained devices. In particular, we implement three PQC algorithms
-- BIKE, CRYSTALS-Kyber, and HQC -- on a lightweight IoT platform built with
Raspberry Pi devices. Leveraging the Open Quantum Safe (\texttt{liboqs})
library in conjunction with \texttt{mbedTLS}, we develop quantum-secure key
exchange protocols, and evaluate their performance in terms of computational
overhead, memory usage, and energy consumption for quantum secure
communication. Experimental results demonstrate that the integration of PQC
algorithms on constrained hardware is practical, reinforcing the urgent need
for quantum-resilient cryptographic frameworks in next-generation IoT devices.
The implementation of this paper is available at
https://iqsec-lab.github.io/PQC-IoT/.

</details>


### [16] [Qualcomm Trusted Application Emulation for Fuzzing Testing](https://arxiv.org/abs/2507.08331)
*Chun-I Fan,Li-En Chang,Cheng-Han Shie*

Main category: cs.CR

TL;DR: 研究提出了一种轻量级的Qualcomm可信执行环境（TEE）中可信应用（TAs）的模拟器，结合逆向工程和模糊测试技术，有效发现潜在漏洞。


<details>
  <summary>Details</summary>
Motivation: 随着网络安全意识的提升，硬件设备中的信息安全性受到重视，但TEE中的漏洞可能导致敏感数据泄露，威胁用户隐私和安全。

Method: 通过逆向工程分析Qualcomm TAs，开发部分模拟环境，并集成模糊测试技术，系统性地发现漏洞。

Result: 成功开发出轻量级模拟器，并验证其在发现实际安全漏洞中的有效性。

Conclusion: 该研究首次提供了Qualcomm TAs模拟器的实现方法和源代码，为未来研究提供了有价值的参考，相比传统全系统模拟更轻量高效。

Abstract: In recent years, the increasing awareness of cybersecurity has led to a
heightened focus on information security within hardware devices and products.
Incorporating Trusted Execution Environments (TEEs) into product designs has
become a standard practice for safeguarding sensitive user information.
However, vulnerabilities within these components present significant risks, if
exploited by attackers, these vulnerabilities could lead to the leakage of
sensitive data, thereby compromising user privacy and security. This research
centers on trusted applications (TAs) within the Qualcomm TEE and introduces a
novel emulator specifically designed for these applications. Through reverse
engineering techniques, we thoroughly analyze Qualcomm TAs and develop a
partial emulation environment that accurately emulates their behavior.
Additionally, we integrate fuzzing testing techniques into the emulator to
systematically uncover potential vulnerabilities within Qualcomm TAs,
demonstrating its practical effectiveness in identifying real-world security
flaws. This research makes a significant contribution by being the first to
provide both the implementation methods and source codes for a Qualcomm TAs
emulator, offering a valuable reference for future research efforts. Unlike
previous approaches that relied on complex and resource-intensive full-system
simulations, our approach is lightweight and effective, making security testing
of TA more convenient.

</details>


### [17] [White-Basilisk: A Hybrid Model for Code Vulnerability Detection](https://arxiv.org/abs/2507.08540)
*Ioannis Lamprou,Alexander Shevtsov,Ioannis Arapakis,Sotiris Ioannidis*

Main category: cs.CR

TL;DR: White-Basilisk是一种新型漏洞检测方法，通过创新的架构（Mamba层、线性自注意力和专家混合框架）在仅200M参数下实现最优性能，突破了当前大型语言模型的上下文限制。


<details>
  <summary>Details</summary>
Motivation: 软件漏洞的增多对网络安全构成挑战，需要更有效的检测方法。

Method: 采用Mamba层、线性自注意力和专家混合框架的架构，处理超长序列，实现高效漏洞检测。

Result: 在漏洞检测任务中达到最优性能，处理大规模代码库时超越现有大型语言模型，计算高效。

Conclusion: 研究表明，紧凑高效的模型在特定任务中可超越大型模型，可能重新定义AI开发的优化策略。

Abstract: The proliferation of software vulnerabilities presents a significant
challenge to cybersecurity, necessitating more effective detection
methodologies. We introduce White-Basilisk, a novel approach to vulnerability
detection that demonstrates superior performance while challenging prevailing
assumptions in AI model scaling. Utilizing an innovative architecture that
integrates Mamba layers, linear self-attention, and a Mixture of Experts
framework, White-Basilisk achieves state-of-the-art results in vulnerability
detection tasks with a parameter count of only 200M. The model's capacity to
process sequences of unprecedented length enables comprehensive analysis of
extensive codebases in a single pass, surpassing the context limitations of
current Large Language Models (LLMs). White-Basilisk exhibits robust
performance on imbalanced, real-world datasets, while maintaining computational
efficiency that facilitates deployment across diverse organizational scales.
This research not only establishes new benchmarks in code security but also
provides empirical evidence that compact, efficiently designed models can
outperform larger counterparts in specialized tasks, potentially redefining
optimization strategies in AI development for domain-specific applications.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [18] [Human Creativity and AI](https://arxiv.org/abs/2507.08001)
*Shengyi Xie*

Main category: cs.AI

TL;DR: 本文探讨AI是否能展现创造力，结合心理学、认知神经科学和哲学视角，分析创造力的定义及其在AI技术发展中的影响。


<details>
  <summary>Details</summary>
Motivation: 随着科技发展，创造力哲学被重新诠释，研究旨在回答AI是否具备创造力的问题。

Method: 回顾创造力哲学的历史视角，分析心理学进展对创造力研究的影响，探讨自然主义和认知神经科学的回应。

Result: 通过多学科视角，揭示了创造力定义的多样性及其在AI背景下的新理解。

Conclusion: AI创造力的可能性需结合哲学、心理学和神经科学的综合视角进一步探讨。

Abstract: With the advancement of science and technology, the philosophy of creativity
has undergone significant reinterpretation. This paper investigates
contemporary research in the fields of psychology, cognitive neuroscience, and
the philosophy of creativity, particularly in the context of the development of
artificial intelligence (AI) techniques. It aims to address the central
question: Can AI exhibit creativity? The paper reviews the historical
perspectives on the philosophy of creativity and explores the influence of
psychological advancements on the study of creativity. Furthermore, it analyzes
various definitions of creativity and examines the responses of naturalism and
cognitive neuroscience to the concept of creativity.

</details>


### [19] [TableReasoner: Advancing Table Reasoning Framework with Large Language Models](https://arxiv.org/abs/2507.08046)
*Sishi Xiong,Dakai Wang,Yu Zhao,Jie Zhang,Changzai Pan,Haowei He,Xiangyu Li,Wenhan Chang,Zhongjiang He,Shuangyong Song,Yongxiang Li*

Main category: cs.AI

TL;DR: 论文提出了一种基于大语言模型和编程的表推理框架TableReasoner，用于解决表问答任务中的挑战，并在SemEval-2025 Task 8中取得第一名。


<details>
  <summary>Details</summary>
Motivation: 表问答任务面临真实世界表格数据的挑战，如规模大、列语义不完整和实体歧义。

Method: 提出TableReasoner框架，结合结构和语义表示建模表格，设计多步模式链接计划以聚焦查询相关信息，并集成迭代思考架构。

Result: 系统在SemEval-2025 Task 8的两个子任务中均获得第一名。

Conclusion: TableReasoner通过结合语义和结构表示，以及迭代推理，有效解决了表问答任务中的挑战。

Abstract: The paper presents our system developed for table question answering (TQA).
TQA tasks face challenges due to the characteristics of real-world tabular
data, such as large size, incomplete column semantics, and entity ambiguity. To
address these issues, we propose a large language model (LLM)-powered and
programming-based table reasoning framework, named TableReasoner. It models a
table using the schema that combines structural and semantic representations,
enabling holistic understanding and efficient processing of large tables. We
design a multi-step schema linking plan to derive a focused table schema that
retains only query-relevant information, eliminating ambiguity and alleviating
hallucinations. This focused table schema provides precise and sufficient table
details for query refinement and programming. Furthermore, we integrate the
reasoning workflow into an iterative thinking architecture, allowing
incremental cycles of thinking, reasoning and reflection. Our system achieves
first place in both subtasks of SemEval-2025 Task 8.

</details>


### [20] [A Dynamic Stackelberg Game Framework for Agentic AI Defense Against LLM Jailbreaking](https://arxiv.org/abs/2507.08207)
*Zhengye Han,Quanyan Zhu*

Main category: cs.AI

TL;DR: 本文提出了一种动态Stackelberg博弈框架，用于建模大型语言模型（LLM）越狱中的攻击者与防御者交互，并引入“紫色代理”解决方案，结合对抗探索与防御策略。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在关键应用中的部署增加，越狱攻击（绕过安全机制）成为重要问题，需研究防御方法。

Method: 采用动态Stackelberg博弈框架，将提示-响应动态建模为序列扩展形式博弈，提出“紫色代理”结合RRT进行对抗探索与防御。

Result: 紫色代理能主动模拟攻击轨迹并干预，提供分析对抗动态的原则性方法，降低越狱风险。

Conclusion: 该框架为LLM越狱风险提供了理论基础和实用解决方案。

Abstract: As large language models (LLMs) are increasingly deployed in critical
applications, the challenge of jailbreaking, where adversaries manipulate the
models to bypass safety mechanisms, has become a significant concern. This
paper presents a dynamic Stackelberg game framework to model the interactions
between attackers and defenders in the context of LLM jailbreaking. The
framework treats the prompt-response dynamics as a sequential extensive-form
game, where the defender, as the leader, commits to a strategy while
anticipating the attacker's optimal responses. We propose a novel agentic AI
solution, the "Purple Agent," which integrates adversarial exploration and
defensive strategies using Rapidly-exploring Random Trees (RRT). The Purple
Agent actively simulates potential attack trajectories and intervenes
proactively to prevent harmful outputs. This approach offers a principled
method for analyzing adversarial dynamics and provides a foundation for
mitigating the risk of jailbreaking.

</details>


### [21] [Reasoning and Behavioral Equilibria in LLM-Nash Games: From Mindsets to Actions](https://arxiv.org/abs/2507.08208)
*Quanyan Zhu*

Main category: cs.AI

TL;DR: LLM-Nash框架通过游戏理论模型研究LLM驱动的决策，定义提示空间中的均衡，展示与传统纳什均衡的差异。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在有限理性下的决策行为，探索认知约束和思维表达。

Method: 基于游戏理论，定义提示空间中的均衡，通过LLM推理生成行为输出。

Result: 展示了推理均衡与传统纳什均衡的差异，为LLM系统的战略交互提供新视角。

Conclusion: LLM-Nash框架为研究LLM驱动的战略交互提供了新工具，揭示了有限理性的重要性。

Abstract: We introduce the LLM-Nash framework, a game-theoretic model where agents
select reasoning prompts to guide decision-making via Large Language Models
(LLMs). Unlike classical games that assume utility-maximizing agents with full
rationality, this framework captures bounded rationality by modeling the
reasoning process explicitly. Equilibrium is defined over the prompt space,
with actions emerging as the behavioral output of LLM inference. This approach
enables the study of cognitive constraints, mindset expressiveness, and
epistemic learning. Through illustrative examples, we show how reasoning
equilibria can diverge from classical Nash outcomes, offering a new foundation
for strategic interaction in LLM-enabled systems.

</details>


### [22] [From Curiosity to Competence: How World Models Interact with the Dynamics of Exploration](https://arxiv.org/abs/2507.08210)
*Fryderyk Mantiuk,Hanqi Zhou,Charley M. Wu*

Main category: cs.AI

TL;DR: 论文探讨了智能体如何平衡好奇心（探索未知）与能力（控制环境），通过比较两种模型驱动的智能体（Tabular和Dreamer），揭示了探索与表征学习的双向互动关系。


<details>
  <summary>Details</summary>
Motivation: 研究智能体如何在探索世界与控制环境之间取得平衡，借鉴认知理论中的内在动机与强化学习相结合。

Method: 比较了两种模型驱动的智能体：基于手工状态抽象的Tabular和基于学习内部世界模型的Dreamer，分析其探索行为。

Result: Tabular智能体显示好奇心和能力引导探索的不同模式，而Dreamer智能体揭示了探索与表征学习的双向互动。

Conclusion: 研究形式化了适应性探索的平衡机制，为认知理论和高效强化学习提供了新见解。

Abstract: What drives an agent to explore the world while also maintaining control over
the environment? From a child at play to scientists in the lab, intelligent
agents must balance curiosity (the drive to seek knowledge) with competence
(the drive to master and control the environment). Bridging cognitive theories
of intrinsic motivation with reinforcement learning, we ask how evolving
internal representations mediate the trade-off between curiosity (novelty or
information gain) and competence (empowerment). We compare two model-based
agents using handcrafted state abstractions (Tabular) or learning an internal
world model (Dreamer). The Tabular agent shows curiosity and competence guide
exploration in distinct patterns, while prioritizing both improves exploration.
The Dreamer agent reveals a two-way interaction between exploration and
representation learning, mirroring the developmental co-evolution of curiosity
and competence. Our findings formalize adaptive exploration as a balance
between pursuing the unknown and the controllable, offering insights for
cognitive theories and efficient reinforcement learning.

</details>


### [23] [Grounding Methods for Neural-Symbolic AI](https://arxiv.org/abs/2507.08216)
*Rodrigo Castellano Ontiveros,Francesco Giannini,Marco Gori,Giuseppe Marra,Michelangelo Diligenti*

Main category: cs.AI

TL;DR: 论文提出了一种参数化的逻辑接地方法，通过泛化经典的后向链式推理，平衡表达能力和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决现有神经符号方法在逻辑接地过程中面临的可扩展性和表达能力之间的权衡问题。

Method: 提出了一种参数化的接地方法家族，泛化后向链式推理，允许控制表达能力和可扩展性的平衡。

Result: 实验结果表明，接地标准的选择对神经符号方法的性能至关重要。

Conclusion: 通过参数化接地方法，可以在表达能力和可扩展性之间找到更好的平衡，提升神经符号方法的实用性。

Abstract: A large class of Neural-Symbolic (NeSy) methods employs a machine learner to
process the input entities, while relying on a reasoner based on First-Order
Logic to represent and process more complex relationships among the entities. A
fundamental role for these methods is played by the process of logic grounding,
which determines the relevant substitutions for the logic rules using a
(sub)set of entities. Some NeSy methods use an exhaustive derivation of all
possible substitutions, preserving the full expressive power of the logic
knowledge. This leads to a combinatorial explosion in the number of ground
formulas to consider and, therefore, strongly limits their scalability. Other
methods rely on heuristic-based selective derivations, which are generally more
computationally efficient, but lack a justification and provide no guarantees
of preserving the information provided to and returned by the reasoner. Taking
inspiration from multi-hop symbolic reasoning, this paper proposes a
parametrized family of grounding methods generalizing classic Backward
Chaining. Different selections within this family allow us to obtain commonly
employed grounding methods as special cases, and to control the trade-off
between expressiveness and scalability of the reasoner. The experimental
results show that the selection of the grounding criterion is often as
important as the NeSy method itself.

</details>


### [24] [Quantum Federated Learning for Multimodal Data: A Modality-Agnostic Approach](https://arxiv.org/abs/2507.08217)
*Atit Pokharel,Ratun Rahman,Thomas Morris,Dinh C. Nguyen*

Main category: cs.AI

TL;DR: 提出了一种基于量子纠缠的多模态量子联邦学习（QFL）方法，并引入了缺失模态无关（MMA）机制以提升模型稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有QFL框架多为单模态，难以应对现实任务中的多模态需求。

Method: 采用量子纠缠的中间融合方法，并设计MMA机制隔离未训练的量子电路。

Result: 在IID和非IID数据分布下，准确率分别提升6.84%和7.25%。

Conclusion: 多模态QFL结合MMA机制显著提升了模型性能，填补了研究空白。

Abstract: Quantum federated learning (QFL) has been recently introduced to enable a
distributed privacy-preserving quantum machine learning (QML) model training
across quantum processors (clients). Despite recent research efforts, existing
QFL frameworks predominantly focus on unimodal systems, limiting their
applicability to real-world tasks that often naturally involve multiple
modalities. To fill this significant gap, we present for the first time a novel
multimodal approach specifically tailored for the QFL setting with the
intermediate fusion using quantum entanglement. Furthermore, to address a major
bottleneck in multimodal QFL, where the absence of certain modalities during
training can degrade model performance, we introduce a Missing Modality
Agnostic (MMA) mechanism that isolates untrained quantum circuits, ensuring
stable training without corrupted states. Simulation results demonstrate that
the proposed multimodal QFL method with MMA yields an improvement in accuracy
of 6.84% in independent and identically distributed (IID) and 7.25% in non-IID
data distributions compared to the state-of-the-art methods.

</details>


### [25] [Giving AI Agents Access to Cryptocurrency and Smart Contracts Creates New Vectors of AI Harm](https://arxiv.org/abs/2507.08249)
*Bill Marino,Ari Juels*

Main category: cs.AI

TL;DR: 本文探讨了赋予AI代理加密货币和智能合约访问权限可能带来的新危害，并呼吁更多技术研究以预防和减轻这些危害。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理对加密货币和智能合约的访问需求增加，研究其潜在危害变得至关重要。

Method: 分析了加密货币和智能合约的独特性质，详细描述了可能导致的新危害。

Result: 识别了新的危害向量，强调了预防和减轻这些危害的必要性。

Conclusion: 呼吁更多技术研究以确保AI代理安全使用加密货币和智能合约。

Abstract: There is growing interest in giving AI agents access to cryptocurrencies as
well as to the smart contracts that transact them. But doing so, this position
paper argues, could lead to formidable new vectors of AI harm. To support this
argument, we first examine the unique properties of cryptocurrencies and smart
contracts that could lead to these new vectors of harm. Next, we describe each
of these new vectors of harm in detail. Finally, we conclude with a call for
more technical research aimed at preventing and mitigating these harms and,
thereby making it safer to endow AI agents with cryptocurrencies and smart
contracts.

</details>


### [26] [Agent Safety Alignment via Reinforcement Learning](https://arxiv.org/abs/2507.08270)
*Zeyang Sha,Hanling Tian,Zhuoer Xu,Shiwen Cui,Changhua Meng,Weiqiang Wang*

Main category: cs.AI

TL;DR: 论文提出了一种统一的安全对齐框架，用于处理使用工具的自主大型语言模型（LLM）代理的安全风险，包括用户和工具引发的威胁。


<details>
  <summary>Details</summary>
Motivation: 自主LLM代理的工具使用能力带来了新的安全风险，传统方法无法应对。

Method: 提出了一种基于结构化推理和沙盒强化学习的框架，包括三模态分类和政策驱动决策模型。

Result: 实验表明，安全对齐的代理显著提高了对安全威胁的抵抗力，同时保持了良性任务的高效性。

Conclusion: 安全性和有效性可以共同优化，为自主LLM代理的可信部署奠定了基础。

Abstract: The emergence of autonomous Large Language Model (LLM) agents capable of tool
usage has introduced new safety risks that go beyond traditional conversational
misuse. These agents, empowered to execute external functions, are vulnerable
to both user-initiated threats (e.g., adversarial prompts) and tool-initiated
threats (e.g., malicious outputs from compromised tools). In this paper, we
propose the first unified safety-alignment framework for tool-using agents,
enabling models to handle both channels of threat via structured reasoning and
sandboxed reinforcement learning. We introduce a tri-modal taxonomy, including
benign, malicious, and sensitive for both user prompts and tool responses, and
define a policy-driven decision model. Our framework employs a custom-designed
sandbox environment that simulates real-world tool execution and allows
fine-grained reward shaping. Through extensive evaluations on public and
self-built benchmarks, including Agent SafetyBench, InjecAgent, and BFCL, we
demonstrate that our safety-aligned agents significantly improve resistance to
security threats while preserving strong utility on benign tasks. Our results
show that safety and effectiveness can be jointly optimized, laying the
groundwork for trustworthy deployment of autonomous LLM agents.

</details>


### [27] [Abductive Computational Systems: Creative Abduction and Future Directions](https://arxiv.org/abs/2507.08264)
*Abhinav Sood,Kazjon Grace,Stephen Wan,Cecile Paris*

Main category: cs.AI

TL;DR: 本文综述了溯因推理在不同领域的讨论，分析了计算系统的实现，发现理论和计算均未充分支持创造性假设生成，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 探讨溯因推理在认识论、科学和设计中的理解差异，以及计算系统如何实现溯因推理，特别是创造性假设生成。

Method: 综述文献并分析计算系统的溯因推理实现，拆解系统组件。

Result: 理论和计算系统均未有效支持创造性溯因假设生成。

Conclusion: 提出未来研究方向以推动计算系统中创造性溯因推理的发展。

Abstract: Abductive reasoning, reasoning for inferring explanations for observations,
is often mentioned in scientific, design-related and artistic contexts, but its
understanding varies across these domains. This paper reviews how abductive
reasoning is discussed in epistemology, science and design, and then analyses
how various computational systems use abductive reasoning. Our analysis shows
that neither theoretical accounts nor computational implementations of
abductive reasoning adequately address generating creative hypotheses.
Theoretical frameworks do not provide a straightforward model for generating
creative abductive hypotheses, computational systems largely implement
syllogistic forms of abductive reasoning. We break down abductive computational
systems into components and conclude by identifying specific directions for
future research that could advance the state of creative abductive reasoning in
computational systems.

</details>


### [28] [M2-Reasoning: Empowering MLLMs with Unified General and Spatial Reasoning](https://arxiv.org/abs/2507.08306)
*Inclusion AI,:,Fudong Wang,Jiajia Liu,Jingdong Chen,Jun Zhou,Kaixiang Ji,Lixiang Ru,Qingpei Guo,Ruobing Zheng,Tianqi Li,Yi Yuan,Yifan Mao,Yuting Xiao,Ziping Ma*

Main category: cs.AI

TL;DR: M2-Reasoning-7B模型通过创新的数据管道和动态多任务训练策略，解决了MLLMs在动态空间交互中的不足，并在8个基准测试中达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 当前MLLMs在动态空间交互能力上存在不足，限制了其实际应用。

Method: 提出M2-Reasoning-7B模型，结合高质量数据生成（294.2K样本）和动态多任务训练策略（任务特定奖励）。

Result: 在8个基准测试中达到SOTA，尤其在通用和空间推理领域表现优异。

Conclusion: M2-Reasoning-7B通过数据与训练策略的创新，显著提升了MLLMs的推理能力。

Abstract: Recent advancements in Multimodal Large Language Models (MLLMs), particularly
through Reinforcement Learning with Verifiable Rewards (RLVR), have
significantly enhanced their reasoning abilities. However, a critical gap
persists: these models struggle with dynamic spatial interactions, a capability
essential for real-world applications. To bridge this gap, we introduce
M2-Reasoning-7B, a model designed to excel in both general and spatial
reasoning. Our approach integrates two key innovations: (1) a novel data
pipeline that generates 294.2K high-quality data samples (168K for cold-start
fine-tuning and 126.2K for RLVR), which feature logically coherent reasoning
trajectories and have undergone comprehensive assessment; and (2) a dynamic
multi-task training strategy with step-wise optimization to mitigate conflicts
between data, and task-specific rewards for delivering tailored incentive
signals. This combination of curated data and advanced training allows
M2-Reasoning-7B to set a new state-of-the-art (SOTA) across 8 benchmarks,
showcasing superior performance in both general and spatial reasoning domains.

</details>


### [29] [Multi-Agent LLMs as Ethics Advocates in AI-Based Systems](https://arxiv.org/abs/2507.08392)
*Asma Yamani,Malak Baslyman,Moataz Ahmed*

Main category: cs.AI

TL;DR: 提出了一种在多智能体LLM设置中引入伦理倡导代理的框架，用于自动生成伦理需求草案，并通过案例研究验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 手动获取伦理需求效率低且资源密集，需多利益相关方参与，但常被忽视。

Method: 在多智能体LLM中引入伦理倡导代理，基于系统描述提供伦理问题反馈。

Result: 框架能捕捉大部分人工识别的伦理需求，并补充新需求，但存在可靠性问题。

Conclusion: 该框架有助于推广伦理需求工程，但仍需人工反馈以确保可靠性。

Abstract: Incorporating ethics into the requirement elicitation process is essential
for creating ethically aligned systems. Although eliciting manual ethics
requirements is effective, it requires diverse input from multiple
stakeholders, which can be challenging due to time and resource constraints.
Moreover, it is often given a low priority in the requirements elicitation
process. This study proposes a framework for generating ethics requirements
drafts by introducing an ethics advocate agent in a multi-agent LLM setting.
This agent critiques and provides input on ethical issues based on the system
description. The proposed framework is evaluated through two case studies from
different contexts, demonstrating that it captures the majority of ethics
requirements identified by researchers during 30-minute interviews and
introduces several additional relevant requirements. However, it also
highlights reliability issues in generating ethics requirements, emphasizing
the need for human feedback in this sensitive domain. We believe this work can
facilitate the broader adoption of ethics in the requirements engineering
process, ultimately leading to more ethically aligned products.

</details>


### [30] [Why this and not that? A Logic-based Framework for Contrastive Explanations](https://arxiv.org/abs/2507.08454)
*Tobias Geibinger,Reijo Jaakkola,Antti Kuusisto,Xinghan Liu,Miikka Vilander*

Main category: cs.AI

TL;DR: 论文定义了与对比解释相关的几个典型问题，研究其在命题逻辑中的基本性质，并展示了其计算复杂性和实际应用。


<details>
  <summary>Details</summary>
Motivation: 研究对比解释（回答“为什么P而不是Q？”）的基本性质和计算复杂性，填补现有文献的不足。

Method: 在命题逻辑中定义对比解释问题，分析其性质，计算复杂度，并通过答案集编程实现CNF公式的示例。

Result: 框架捕捉了现有对比解释的最小基数版本，并提供了计算复杂性的详细分析。

Conclusion: 论文提出的框架在理论和实践中均有效，为对比解释提供了新的视角和工具。

Abstract: We define several canonical problems related to contrastive explanations,
each answering a question of the form ''Why P but not Q?''. The problems
compute causes for both P and Q, explicitly comparing their differences. We
investigate the basic properties of our definitions in the setting of
propositional logic. We show, inter alia, that our framework captures a
cardinality-minimal version of existing contrastive explanations in the
literature. Furthermore, we provide an extensive analysis of the computational
complexities of the problems. We also implement the problems for CNF-formulas
using answer set programming and present several examples demonstrating how
they work in practice.

</details>


### [31] [From Language to Logic: A Bi-Level Framework for Structured Reasoning](https://arxiv.org/abs/2507.08501)
*Keying Yang,Hao Wang,Kai Yang*

Main category: cs.AI

TL;DR: 论文提出了一种双层框架，通过高级任务抽象和低级逻辑生成两阶段过程，将自然语言映射到逻辑表示，显著提升了推理任务的准确性和透明度。


<details>
  <summary>Details</summary>
Motivation: 解决自然语言输入与形式逻辑表示之间的差距，实现更准确、可解释的推理。

Method: 采用双层框架：高级任务抽象由大语言模型（LLM）解析自然语言为结构化表示；低级逻辑生成基于这些表示生成符号化工作流或可执行程序。通过端到端双层优化联合优化两个阶段。

Result: 在多个推理基准测试中，准确率显著优于现有基线，最高提升40%。

Conclusion: 双层设计提高了透明度和错误可追溯性，为LLM的可信系统化推理提供了新方向。

Abstract: Structured reasoning over natural language inputs remains a core challenge in
artificial intelligence, as it requires bridging the gap between unstructured
linguistic expressions and formal logical representations. In this paper, we
propose a novel \textbf{bi-level framework} that maps language to logic through
a two-stage process: high-level task abstraction and low-level logic
generation. At the upper level, a large language model (LLM) parses natural
language queries into intermediate structured representations specifying the
problem type, objectives, decision variables, and symbolic constraints. At the
lower level, the LLM uses these representations to generate symbolic workflows
or executable reasoning programs for accurate and interpretable decision
making. The framework supports modular reasoning, enforces explicit
constraints, and generalizes across domains such as mathematical problem
solving, question answering, and logical inference. We further optimize the
framework with an end-to-end {bi-level} optimization approach that jointly
refines both the high-level abstraction and low-level logic generation stages.
Experiments on multiple realistic reasoning benchmarks demonstrate that our
approach significantly outperforms existing baselines in accuracy, with
accuracy gains reaching as high as 40\%. Moreover, the bi-level design enhances
transparency and error traceability, offering a promising step toward
trustworthy and systematic reasoning with LLMs.

</details>


### [32] [A Multi-granularity Concept Sparse Activation and Hierarchical Knowledge Graph Fusion Framework for Rare Disease Diagnosis](https://arxiv.org/abs/2507.08529)
*Mingda Zhang,Na Zhao,Jianglong Qin,Guoyu Ye,Ruixiang Tang*

Main category: cs.AI

TL;DR: 提出了一种结合多粒度稀疏激活和分层知识图谱的框架，用于提升罕见病诊断的准确性和信息质量。


<details>
  <summary>Details</summary>
Motivation: 罕见病诊断因知识表示深度不足、概念理解有限和临床推理受限而进展缓慢。

Method: 采用多粒度稀疏激活医学概念、四种匹配算法、多样性控制和五级回退策略，结合三层知识图谱（分类、临床特征、实例）。

Result: 在BioASQ罕见病QA集上，BLEU提升0.09，ROUGE提升0.05，准确率提升0.12，峰值准确率达0.89。专家评估显示信息质量、推理和专业表达均有改善。

Conclusion: 该方法缩短了罕见病患者的“诊断旅程”，接近临床阈值0.90。

Abstract: Despite advances from medical large language models in healthcare,
rare-disease diagnosis remains hampered by insufficient
knowledge-representation depth, limited concept understanding, and constrained
clinical reasoning. We propose a framework that couples multi-granularity
sparse activation of medical concepts with a hierarchical knowledge graph. Four
complementary matching algorithms, diversity control, and a five-level fallback
strategy enable precise concept activation, while a three-layer knowledge graph
(taxonomy, clinical features, instances) provides structured, up-to-date
context. Experiments on the BioASQ rare-disease QA set show BLEU gains of 0.09,
ROUGE gains of 0.05, and accuracy gains of 0.12, with peak accuracy of 0.89
approaching the 0.90 clinical threshold. Expert evaluation confirms
improvements in information quality, reasoning, and professional expression,
suggesting our approach shortens the "diagnostic odyssey" for rare-disease
patients.

</details>


### [33] [Large Multi-modal Model Cartographic Map Comprehension for Textual Locality Georeferencing](https://arxiv.org/abs/2507.08575)
*Kalana Wijegunarathna,Kristin Stock,Christopher B. Jones*

Main category: cs.AI

TL;DR: 提出了一种利用多模态大模型（LMM）自动地理参考生物样本记录的新方法，通过视觉化空间关系，显著优于现有工具。


<details>
  <summary>Details</summary>
Motivation: 解决自然历史收藏中大量未地理参考样本记录的自动化处理问题。

Method: 采用网格化方法，在多模态大模型中实现零样本任务，结合地图视觉化空间关系。

Result: 实验显示平均距离误差约1公里，优于单模态语言模型和现有工具。

Conclusion: 多模态大模型能有效理解精细地图，提出将其整合到地理参考工作流程的框架。

Abstract: Millions of biological sample records collected in the last few centuries
archived in natural history collections are un-georeferenced. Georeferencing
complex locality descriptions associated with these collection samples is a
highly labour-intensive task collection agencies struggle with. None of the
existing automated methods exploit maps that are an essential tool for
georeferencing complex relations. We present preliminary experiments and
results of a novel method that exploits multi-modal capabilities of recent
Large Multi-Modal Models (LMM). This method enables the model to visually
contextualize spatial relations it reads in the locality description. We use a
grid-based approach to adapt these auto-regressive models for this task in a
zero-shot setting. Our experiments conducted on a small manually annotated
dataset show impressive results for our approach ($\sim$1 km Average distance
error) compared to uni-modal georeferencing with Large Language Models and
existing georeferencing tools. The paper also discusses the findings of the
experiments in light of an LMM's ability to comprehend fine-grained maps.
Motivated by these results, a practical framework is proposed to integrate this
method into a georeferencing workflow.

</details>


### [34] [Unlocking Speech Instruction Data Potential with Query Rewriting](https://arxiv.org/abs/2507.08603)
*Yonghua Hei,Yibo Yan,Shuliang Liu,Huiyu Zhou,Linfeng Zhang,Xuming Hu*

Main category: cs.AI

TL;DR: 论文提出了一种通过多LLM知识融合的查询重写框架，以解决TTS模型在生成语音指令数据时的分布外问题，无需人工标注即可构建高质量数据集。


<details>
  <summary>Details</summary>
Motivation: 当前语音指令数据集的构建依赖人工标注成本高，且LLM生成的语音指令与真实人类响应存在差距，限制了语音指令跟随能力的实现。

Method: 采用多LLM知识融合的查询重写框架，通过多智能体标注和验证合成语音，将文本指令转换为更适合TTS模型合成的分布。

Result: 实验表明，该方法通过零样本重写将数据可用性从72%提升至93%，并在复杂知识和上下文相关任务中表现出优势。

Conclusion: 该方法为构建高质量语音指令数据集提供了高效且低成本的解决方案，推动了语音指令跟随能力的发展。

Abstract: End-to-end Large Speech Language Models~(\textbf{LSLMs}) demonstrate strong
potential in response latency and speech comprehension capabilities, showcasing
general intelligence across speech understanding tasks. However, the ability to
follow speech instructions has not been fully realized due to the lack of
datasets and heavily biased training tasks. Leveraging the rich ASR datasets,
previous approaches have used Large Language Models~(\textbf{LLMs}) to continue
the linguistic information of speech to construct speech instruction datasets.
Yet, due to the gap between LLM-generated results and real human responses, the
continuation methods further amplify these shortcomings. Given the high costs
of collecting and annotating speech instruction datasets by humans, using
speech synthesis to construct large-scale speech instruction datasets has
become a balanced and robust alternative. Although modern
Text-To-Speech~(\textbf{TTS}) models have achieved near-human-level synthesis
quality, it is challenging to appropriately convert out-of-distribution text
instruction to speech due to the limitations of the training data distribution
in TTS models. To address this issue, we propose a query rewriting framework
with multi-LLM knowledge fusion, employing multiple agents to annotate and
validate the synthesized speech, making it possible to construct high-quality
speech instruction datasets without relying on human annotation. Experiments
show that this method can transform text instructions into distributions more
suitable for TTS models for speech synthesis through zero-shot rewriting,
increasing data usability from 72\% to 93\%. It also demonstrates unique
advantages in rewriting tasks that require complex knowledge and
context-related abilities.

</details>


### [35] [Agentic Large Language Models for Conceptual Systems Engineering and Design](https://arxiv.org/abs/2507.08619)
*Soheyl Massoudi,Mark Fuge*

Main category: cs.AI

TL;DR: 论文评估了结构化多代理系统（MAS）在早期工程设计中的表现，发现其在设计细节上优于双代理系统（2AS），但需求覆盖率和代码兼容性仍有不足。


<details>
  <summary>Details</summary>
Motivation: 早期工程设计需要复杂的迭代推理，现有的大语言模型（LLM）工作流难以保持任务连续性和生成可执行模型。

Method: 通过比较九角色MAS和双代理2AS在太阳能水过滤系统设计中的表现，使用Design-State Graph（DSG）作为JSON可序列化表示。

Result: MAS在设计细节上表现更好，但需求覆盖率低（<20%），代码兼容性平均低于50%。推理蒸馏模型能可靠标记工作流完成。

Conclusion: 结构化多代理协调增强了设计细节，但需求覆盖率和代码保真度仍需改进。

Abstract: Early-stage engineering design involves complex, iterative reasoning, yet
existing large language model (LLM) workflows struggle to maintain task
continuity and generate executable models. We evaluate whether a structured
multi-agent system (MAS) can more effectively manage requirements extraction,
functional decomposition, and simulator code generation than a simpler
two-agent system (2AS). The target application is a solar-powered water
filtration system as described in a cahier des charges. We introduce the
Design-State Graph (DSG), a JSON-serializable representation that bundles
requirements, physical embodiments, and Python-based physics models into graph
nodes. A nine-role MAS iteratively builds and refines the DSG, while the 2AS
collapses the process to a Generator-Reflector loop. Both systems run a total
of 60 experiments (2 LLMs - Llama 3.3 70B vs reasoning-distilled DeepSeek R1
70B x 2 agent configurations x 3 temperatures x 5 seeds). We report a JSON
validity, requirement coverage, embodiment presence, code compatibility,
workflow completion, runtime, and graph size. Across all runs, both MAS and 2AS
maintained perfect JSON integrity and embodiment tagging. Requirement coverage
remained minimal (less than 20\%). Code compatibility peaked at 100\% under
specific 2AS settings but averaged below 50\% for MAS. Only the
reasoning-distilled model reliably flagged workflow completion. Powered by
DeepSeek R1 70B, the MAS generated more granular DSGs (average 5-6 nodes)
whereas 2AS mode-collapsed. Structured multi-agent orchestration enhanced
design detail. Reasoning-distilled LLM improved completion rates, yet low
requirements and fidelity gaps in coding persisted.

</details>


### [36] [Leanabell-Prover-V2: Verifier-integrated Reasoning for Formal Theorem Proving via Reinforcement Learning](https://arxiv.org/abs/2507.08649)
*Xingguang Ji,Yahui Liu,Qi Wang,Jingyuan Zhang,Yang Yue,Rui Shi,Chenxi Sun,Fuzheng Zhang,Guorui Zhou,Kun Gai*

Main category: cs.AI

TL;DR: Leanabell-Prover-V2是一个7B参数的大语言模型，能够生成Lean 4的形式化定理证明，通过验证器集成的长链思维（CoT）和强化学习（RL）优化性能。


<details>
  <summary>Details</summary>
Motivation: 基于Leanabell-Prover-V1的改进，通过验证器反馈使模型能够自我感知推理过程的正确性并纠正错误。

Method: 升级了强化学习（RL）方法，利用Lean 4验证器的反馈（如成功或错误细节）优化推理轨迹，结合反馈令牌掩码和简单奖励策略。

Result: 在MiniF2F测试集上，性能分别提升了3.2%（Kimina-Prover-Preview-Distill-7B）和2.0%（DeepSeek-Prover-V2-7B）。

Conclusion: Leanabell-Prover-V2通过验证器反馈和多轮交互显著提升了形式化定理证明的性能。

Abstract: We introduce our Leanabell-Prover-V2, a 7B large language models (LLMs) that
can produce formal theorem proofs in Lean 4, with verifier-integrated Long
Chain-of-Thoughts (CoT). Following our previous work Leanabell-Prover-V1, we
continual to choose to posttrain existing strong prover models for further
performance improvement. In our V2 version, we mainly upgrade the Reinforcement
Learning (RL) with feedback provided by the Lean 4 verifier. Crucially,
verifier feedback, such as indicating success or detailing specific errors,
allows the LLM to become ``self-aware'' of the correctness of its own reasoning
process and learn to reflexively correct errors. Leanabell-Prover-V2 directly
optimizes LLM reasoning trajectories with multi-turn verifier interactions,
together with feedback token masking for stable RL training and a simple reward
strategy. Experiments show that Leanabell-Prover-V2 improves performance by
3.2% (pass@128) with Kimina-Prover-Preview-Distill-7B and 2.0% (pass@128) with
DeepSeek-Prover-V2-7B on the MiniF2F test set. The source codes, curated data
and models are available at:
https://github.com/Leanabell-LM/Leanabell-Prover-V2.

</details>


### [37] [Introspection of Thought Helps AI Agents](https://arxiv.org/abs/2507.08664)
*Haoran Sun,Shaoning Zeng*

Main category: cs.AI

TL;DR: 论文提出了一种名为INoT的新型AI代理推理框架，通过设计LLM可读的提示代码，减少推理成本并提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有AI代理依赖LLMs和MLLMs，但受限于其固有缺陷和高推理成本，需要更高效的框架。

Method: 设计了INoT框架，通过LLM-Read代码实现程序化对话推理，使反思过程在LLM内部完成。

Result: 在六个基准测试中，INoT平均性能提升7.95%，推理成本降低58.3%。

Conclusion: INoT框架有效提升了AI代理的性能和效率，并展示了在图像任务中的通用性。

Abstract: AI Agents rely on Large Language Models (LLMs) and Multimodal-LLMs (MLLMs) to
perform interpretation and inference in text and image tasks without
post-training, where LLMs and MLLMs play the most critical role and determine
the initial ability and limitations of AI Agents. Usually, AI Agents utilize
sophisticated prompt engineering and external reasoning framework to obtain a
promising interaction with LLMs, e.g., Chain-of-Thought, Iteration of Thought
and Image-of-Thought. However, they are still constrained by the inherent
limitations of LLM in understanding natural language, and the iterative
reasoning process will generate a large amount of inference cost. To this end,
we propose a novel AI Agent Reasoning Framework with Introspection of Thought
(INoT) by designing a new LLM-Read code in prompt. It enables LLM to execute
programmatic dialogue reasoning processes following the code in prompt.
Therefore, self-denial and reflection occur within LLM instead of outside LLM,
which can reduce token cost effectively. Through our experiments on six
benchmarks for three different tasks, the effectiveness of INoT is verified,
with an average improvement of 7.95\% in performance, exceeding the baselines.
Furthermore, the token cost of INoT is lower on average than the best
performing method at baseline by 58.3\%. In addition, we demonstrate the
versatility of INoT in image interpretation and inference through verification
experiments.

</details>


### [38] [elsciRL: Integrating Language Solutions into Reinforcement Learning Problem Settings](https://arxiv.org/abs/2507.08705)
*Philip Osborne,Danilo S. Carvalho,André Freitas*

Main category: cs.AI

TL;DR: elsciRL是一个开源的Python库，旨在通过语言解决方案提升强化学习问题的处理能力。它扩展了Language Adapter框架，结合LLMs，提供了一种可快速应用于新任务的解决方案，并通过GUI支持用户输入文本生成指令。实验表明，该方法能提升强化学习代理的性能。


<details>
  <summary>Details</summary>
Motivation: 加速语言解决方案在基于奖励的环境中的评估，以促进科学发现的新机遇。

Method: 扩展Language Adapter框架，结合LLMs，提供GUI支持用户输入文本生成指令。

Result: 实验结果显示，生成的指令能够提升强化学习代理的性能。

Conclusion: elsciRL为语言解决方案在强化学习中的应用提供了便捷工具，具有广泛的应用潜力。

Abstract: We present elsciRL, an open-source Python library to facilitate the
application of language solutions on reinforcement learning problems. We
demonstrate the potential of our software by extending the Language Adapter
with Self-Completing Instruction framework defined in (Osborne, 2024) with the
use of LLMs. Our approach can be re-applied to new applications with minimal
setup requirements. We provide a novel GUI that allows a user to provide text
input for an LLM to generate instructions which it can then self-complete.
Empirical results indicate that these instructions \textit{can} improve a
reinforcement learning agent's performance. Therefore, we present this work to
accelerate the evaluation of language solutions on reward based environments to
enable new opportunities for scientific discovery.

</details>


### [39] [System-of-systems Modeling and Optimization: An Integrated Framework for Intermodal Mobility](https://arxiv.org/abs/2507.08715)
*Paul Saves,Jasper Bussemaker,Rémi Lafage,Thierry Lefebvre,Nathalie Bartoli,Youssef Diouane,Joseph Morlier*

Main category: cs.AI

TL;DR: 论文探讨了在系统架构开发中使用代理优化算法（如贝叶斯优化）以应对物理模拟带来的计算挑战。


<details>
  <summary>Details</summary>
Motivation: 针对系统架构优化中物理模拟的高计算成本和潜在失败问题，研究如何利用高效方法降低复杂度。

Method: 采用基于代理的优化算法，特别是贝叶斯优化结合高斯过程模型。

Result: 代理优化算法能有效减少计算成本并提高优化效率。

Conclusion: 代理优化算法是解决系统架构优化中计算挑战的有效方法。

Abstract: For developing innovative systems architectures, modeling and optimization
techniques have been central to frame the architecting process and define the
optimization and modeling problems. In this context, for system-of-systems the
use of efficient dedicated approaches (often physics-based simulations) is
highly recommended to reduce the computational complexity of the targeted
applications. However, exploring novel architectures using such dedicated
approaches might pose challenges for optimization algorithms, including
increased evaluation costs and potential failures. To address these challenges,
surrogate-based optimization algorithms, such as Bayesian optimization
utilizing Gaussian process models have emerged.

</details>
