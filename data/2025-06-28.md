<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 11]
- [cs.CR](#cs.CR) [Total: 12]
- [cs.AI](#cs.AI) [Total: 13]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Domain Knowledge in Requirements Engineering: A Systematic Mapping Study](https://arxiv.org/abs/2506.20754)
*Marina Araújo,Júlia Araújo,Romeu Oliveira,Lucas Romao,Marcos Kalinowski*

Main category: cs.SE

TL;DR: 本文通过系统映射研究，总结了领域知识在需求工程中的应用，分析了75篇相关论文，提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 领域知识对需求工程至关重要，但目前缺乏系统性的总结和方法论支持。

Method: 采用混合搜索策略（数据库搜索与雪球法结合）进行系统映射研究。

Result: 分析了75篇论文，总结了领域知识的应用类型、质量属性和常见挑战，为研究和实践提供了参考。

Conclusion: 研究为知识驱动的需求工程提供了概念和方法基础，并指出了未来研究方向。

Abstract: [Context] Domain knowledge is recognized as a key component for the success
of Requirements Engineering (RE), as it provides the conceptual support needed
to understand the system context, ensure alignment with stakeholder needs, and
reduce ambiguity in requirements specification. Despite its relevance, the
scientific literature still lacks a systematic consolidation of how domain
knowledge can be effectively used and operationalized in RE. [Goal] This paper
addresses this gap by offering a comprehensive overview of existing
contributions, including methods, techniques, and tools to incorporate domain
knowledge into RE practices. [Method] We conducted a systematic mapping study
using a hybrid search strategy that combines database searches with iterative
backward and forward snowballing. [Results] In total, we found 75 papers that
met our inclusion criteria. The analysis highlights the main types of
requirements addressed, the most frequently considered quality attributes, and
recurring challenges in the formalization, acquisition, and long-term
maintenance of domain knowledge. The results provide support for researchers
and practitioners in identifying established approaches and unresolved issues.
The study also outlines promising directions for future research, emphasizing
the development of scalable, automated, and sustainable solutions to integrate
domain knowledge into RE processes. [Conclusion] The study contributes by
providing a comprehensive overview that helps to build a conceptual and
methodological foundation for knowledge-driven requirements engineering.

</details>


### [2] [Agile Management for Machine Learning: A Systematic Mapping Study](https://arxiv.org/abs/2506.20759)
*Lucas Romao,Hugo Villamizar,Romeu Oliveira,Silvio Alonso,Marcos Kalinowski*

Main category: cs.SE

TL;DR: 本文通过系统映射研究总结了敏捷管理在机器学习（ML）系统中的现状，识别了8个关键主题和主要挑战，并指出需要更多实证研究验证现有成果。


<details>
  <summary>Details</summary>
Motivation: 机器学习系统的动态性和传统项目管理方法的局限性促使研究如何有效应用敏捷方法。

Method: 采用混合搜索策略（数据库搜索与前后向雪球迭代）进行系统映射研究。

Result: 研究识别了27篇论文，归纳出8个框架和8个关键主题，主要挑战是ML任务的工作量估算。

Conclusion: 研究总结了现状并指出领域中的开放问题，强调需要更多实证评估。

Abstract: [Context] Machine learning (ML)-enabled systems are present in our society,
driving significant digital transformations. The dynamic nature of ML
development, characterized by experimental cycles and rapid changes in data,
poses challenges to traditional project management. Agile methods, with their
flexibility and incremental delivery, seem well-suited to address this
dynamism. However, it is unclear how to effectively apply these methods in the
context of ML-enabled systems, where challenges require tailored approaches.
[Goal] Our goal is to outline the state of the art in agile management for
ML-enabled systems. [Method] We conducted a systematic mapping study using a
hybrid search strategy that combines database searches with backward and
forward snowballing iterations. [Results] Our study identified 27 papers
published between 2008 and 2024. From these, we identified eight frameworks and
categorized recommendations and practices into eight key themes, such as
Iteration Flexibility, Innovative ML-specific Artifacts, and the Minimal Viable
Model. The main challenge identified across studies was accurate effort
estimation for ML-related tasks. [Conclusion] This study contributes by mapping
the state of the art and identifying open gaps in the field. While relevant
work exists, more robust empirical evaluation is still needed to validate these
contributions.

</details>


### [3] [Generating Reliable Adverse event Profiles for Health through Automated Integrated Data (GRAPH-AID): A Semi-Automated Ontology Building Approach](https://arxiv.org/abs/2506.20851)
*Srikar Reddy Gadusu,Larry Callahan,Samir Lababidi,Arunasri Nishtala,Sophia Healey,Hande McGinty*

Main category: cs.SE

TL;DR: 本文提出了一种用户友好的方法，利用Python和rdflib库支持本体开发，解决了Neo4j与OWL无缝集成的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着数据和知识的快速扩展，采用系统化的本体生成方法变得至关重要。现有方法需要理解描述逻辑（DL）语法，对许多用户不友好，因此需要更易用的解决方案。

Method: 使用Python和rdflib库开发脚本，自动生成所需的类和公理，实现Neo4j数据库与OWL的集成。

Result: 通过整合FDA的FAERS数据库数据，成功开发了一个Python脚本，支持本体生成，改进了药物安全监测和公共卫生决策。

Conclusion: 该方法为快速增长的药物不良事件数据集的本体生成提供了实用解决方案，支持更高效的药物安全监测。

Abstract: As data and knowledge expand rapidly, adopting systematic methodologies for
ontology generation has become crucial. With the daily increases in data
volumes and frequent content changes, the demand for databases to store and
retrieve information for the creation of knowledge graphs has become
increasingly urgent. The previously established Knowledge Acquisition and
Representation Methodology (KNARM) outlines a systematic approach to address
these challenges and create knowledge graphs. However, following this
methodology highlights the existing challenge of seamlessly integrating Neo4j
databases with the Web Ontology Language (OWL). Previous attempts to integrate
data from Neo4j into an ontology have been discussed, but these approaches
often require an understanding of description logics (DL) syntax, which may not
be familiar to many users. Thus, a more accessible method is necessary to
bridge this gap. This paper presents a user-friendly approach that utilizes
Python and its rdflib library to support ontology development. We showcase our
novel approach through a Neo4j database we created by integrating data from the
Food and Drug Administration (FDA) Adverse Event Reporting System (FAERS)
database. Using this dataset, we developed a Python script that automatically
generates the required classes and their axioms, facilitating a smoother
integration process. This approach offers a practical solution to the
challenges of ontology generation in the context of rapidly growing adverse
drug event datasets, supporting improved drug safety monitoring and public
health decision-making.

</details>


### [4] [Engineering RAG Systems for Real-World Applications: Design, Development, and Evaluation](https://arxiv.org/abs/2506.20869)
*Md Toufique Hasan,Muhammad Waseem,Kai-Kristian Kemell,Ayman Asad Khan,Mika Saari,Pekka Abrahamsson*

Main category: cs.SE

TL;DR: 本文介绍了五个基于检索增强生成（RAG）的实际应用案例，并通过用户评估总结了十二个关键经验教训。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs）在事实准确性和上下文相关性方面的局限性，缺乏基于实际用例的RAG系统实证研究。

Method: 开发五个领域特定的RAG应用，结合多语言OCR、语义检索和领域适应的LLMs，通过用户评估六个维度。

Result: 用户评估显示系统在易用性、相关性等方面表现良好，总结了技术、操作和伦理挑战。

Conclusion: RAG系统在实际应用中具有潜力，但需解决可靠性、可用性和伦理问题。

Abstract: Retrieval-Augmented Generation (RAG) systems are emerging as a key approach
for grounding Large Language Models (LLMs) in external knowledge, addressing
limitations in factual accuracy and contextual relevance. However, there is a
lack of empirical studies that report on the development of RAG-based
implementations grounded in real-world use cases, evaluated through general
user involvement, and accompanied by systematic documentation of lessons
learned. This paper presents five domain-specific RAG applications developed
for real-world scenarios across governance, cybersecurity, agriculture,
industrial research, and medical diagnostics. Each system incorporates
multilingual OCR, semantic retrieval via vector embeddings, and domain-adapted
LLMs, deployed through local servers or cloud APIs to meet distinct user needs.
A web-based evaluation involving a total of 100 participants assessed the
systems across six dimensions: (i) Ease of Use, (ii) Relevance, (iii)
Transparency, (iv) Responsiveness, (v) Accuracy, and (vi) Likelihood of
Recommendation. Based on user feedback and our development experience, we
documented twelve key lessons learned, highlighting technical, operational, and
ethical challenges affecting the reliability and usability of RAG systems in
practice.

</details>


### [5] [Complex Model Transformations by Reinforcement Learning with Uncertain Human Guidance](https://arxiv.org/abs/2506.20883)
*Kyanna Dagenais,Istvan David*

Main category: cs.SE

TL;DR: 论文提出了一种结合人类指导的强化学习方法，用于开发复杂的模型转换序列，显著提高了性能。


<details>
  <summary>Details</summary>
Motivation: 手动开发复杂的模型转换（MTs）序列容易出错且不可行，强化学习（RL）虽能缓解问题，但在复杂场景中性能不足，人类指导可提升效果。

Method: 提出了一种技术框架，将用户定义的MTs映射到RL原语，并通过RL程序执行以寻找最优MT序列，同时结合人类指导（即使不确定）。

Result: 评估表明，人类指导（即使不确定）显著提升了RL性能，并更高效地开发了复杂MTs。

Conclusion: 该方法通过权衡人类建议的确定性和及时性，为RL驱动的人机协同工程方法迈出了一步。

Abstract: Model-driven engineering problems often require complex model transformations
(MTs), i.e., MTs that are chained in extensive sequences. Pertinent examples of
such problems include model synchronization, automated model repair, and design
space exploration. Manually developing complex MTs is an error-prone and often
infeasible process. Reinforcement learning (RL) is an apt way to alleviate
these issues. In RL, an autonomous agent explores the state space through trial
and error to identify beneficial sequences of actions, such as MTs. However, RL
methods exhibit performance issues in complex problems. In these situations,
human guidance can be of high utility. In this paper, we present an approach
and technical framework for developing complex MT sequences through RL, guided
by potentially uncertain human advice. Our framework allows user-defined MTs to
be mapped onto RL primitives, and executes them as RL programs to find optimal
MT sequences. Our evaluation shows that human guidance, even if uncertain,
substantially improves RL performance, and results in more efficient
development of complex MTs. Through a trade-off between the certainty and
timeliness of human advice, our method takes a step towards RL-driven
human-in-the-loop engineering methods.

</details>


### [6] [Boosting Vulnerability Detection with Inter-function Multilateral Association Insights](https://arxiv.org/abs/2506.21014)
*Shaojian Qiu,Mengyang Huang,Jiahao Cheng*

Main category: cs.SE

TL;DR: IFMA-VD是一个基于超图卷积的漏洞检测框架，通过分析函数间的多边关联提升检测效果。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法忽略函数间复杂关联，导致漏洞检测不全面。

Method: 构建代码行为超图，利用超边卷积提取多边关联特征。

Result: 在三个数据集上F-measure和Recall优于基线方法。

Conclusion: 多边关联特征能增强代码表示，IFMA-VD在实际数据中有效。

Abstract: Vulnerability detection is a crucial yet challenging technique for ensuring
the security of software systems. Currently, most deep learning-based
vulnerability detection methods focus on stand-alone functions, neglecting the
complex inter-function interrelations, particularly the multilateral
associations. This oversight can fail to detect vulnerabilities in these
interrelations. To address this gap, we present an Inter-Function Multilateral
Association analysis framework for Vulnerability Detection (IFMA-VD). The
cornerstone of the IFMA-VD lies in constructing a code behavior hypergraph and
utilizing hyperedge convolution to extract multilateral association features.
Specifically, we first parse functions into a code property graph to generate
intra-function features. Following this, we construct a code behavior
hypergraph by segmenting the program dependency graph to isolate and encode
behavioral features into hyperedges. Finally, we utilize a hypergraph network
to capture the multilateral association knowledge for augmenting vulnerability
detection. We evaluate IFMA-VD on three widely used vulnerability datasets and
demonstrate improvements in F-measure and Recall compared to baseline methods.
Additionally, we illustrate that multilateral association features can boost
code feature representation and validate the effectiveness of IFMA-VD on
real-world datasets.

</details>


### [7] [How Good Are Synthetic Requirements ? Evaluating LLM-Generated Datasets for AI4RE](https://arxiv.org/abs/2506.21138)
*Abdelkarim El-Hajjami,Camille Salinesi*

Main category: cs.SE

TL;DR: Synthline v1通过改进的生成和筛选技术，显著提升了合成需求数据的质量，并在某些任务中超越人工数据。


<details>
  <summary>Details</summary>
Motivation: 公开标注的需求数据集稀缺阻碍了AI4RE的发展，需要系统化的合成数据生成方法。

Method: 采用多样本提示、自动提示优化（PACE）和后生成筛选技术，评估四种分类任务。

Result: 多样本提示提升效果显著，PACE效果因任务而异，合成数据在某些任务中优于人工数据。

Conclusion: Synthline v1为AI4RE提供了实用解决方案，缓解了数据集稀缺问题。

Abstract: The shortage of publicly available, labeled requirements datasets remains a
major barrier to advancing Artificial Intelligence for Requirements Engineering
(AI4RE). While Large Language Models offer promising capabilities for synthetic
data generation, systematic approaches to control and optimize the quality of
generated requirements remain underexplored. This paper presents Synthline v1,
an enhanced Product Line approach for generating synthetic requirements data
that extends our earlier v0 version with advanced generation strategies and
curation techniques. We investigate four research questions assessing how
prompting strategies, automated prompt optimization, and post-generation
curation affect data quality across four classification tasks: defect
detection, functional vs. non-functional, quality vs. non-quality, and security
vs. non-security. Our evaluation shows that multi-sample prompting
significantly boosts both utility and diversity over single-sample generation,
with F1-score gains from 6 to 44 points. The use of PACE (Prompt Actor-Critic
Editing) for automated prompt optimization yields task-dependent results,
greatly improving functional classification (+32.5 points) but reducing
performance on others. Interestingly, similarity-based curation improves
diversity but often harms classification performance, indicating that some
redundancy may help ML models. Most importantly, our results show that
synthetic requirements can match or outperform human-authored ones for specific
tasks, with synthetic data surpassing human data for security (+7.8 points) and
defect classification (+15.4 points). These findings offer practical insights
for AI4RE and chart a viable path to mitigating dataset scarcity through
systematic synthetic generation.

</details>


### [8] [$T^3$: Multi-level Tree-based Automatic Program Repair with Large Language Models](https://arxiv.org/abs/2506.21211)
*Quanming Liu,Xupeng Bu,Zhichao Yan,Ru Li*

Main category: cs.SE

TL;DR: 本文提出了一种名为$T^3$的创新框架，结合大型语言模型（LLMs）和树搜索技术，提升了自动程序修复（APR）任务的精度和效率。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型和链式思考（CoT）技术在推理能力上有显著进步，但在APR领域中的应用仍不足，主要因其复杂逻辑和多步推理需求。

Method: 研究系统评估了几种常见CoT技术在APR任务中的表现，并提出了$T^3$框架，结合LLMs的推理能力和树搜索技术。

Result: $T^3$有效提高了生成候选修复方案的精度，并为优化样本选择和修复策略提供了指导。

Conclusion: $T^3$为高效自动调试建立了强大框架，推动了APR技术的发展。

Abstract: Automatic Program Repair (APR) is a core technology in software development
and maintenance, with aims to enable automated defect repair with minimal human
intervention. In recent years, the substantial advancements in Large Language
Models (LLMs) and the Chain-of-Thought (CoT) techniques have significantly
enhanced the reasoning capabilities of these models. However, due to the
complex logic and multi-step reasoning ability needed, the application of CoT
techniques in the APR domain remains insufficient. This study systematically
evaluates the performance of several common CoT techniques in APR tasks and
proposes an innovative framework $T^3$, which integrates the powerful reasoning
capabilities of LLMs with tree search, effectively improving the precision of
generating candidate repair solutions. Furthermore, $T^3$ provides valuable
guidance for optimizing sample selection and repair strategies in APR tasks,
establishing a robust framework for achieving efficient automated debugging.

</details>


### [9] [KOALA: a Configurable Tool for Collecting IDE Data When Solving Programming Tasks](https://arxiv.org/abs/2506.21266)
*Daniil Karol,Elizaveta Artser,Ilya Vlasov,Yaroslav Golubev,Hieke Keuning,Anastasiia Birillo*

Main category: cs.SE

TL;DR: KOALA是一个可配置的工具，用于收集学生在JetBrains IDE中解决编程任务时的代码快照和功能使用数据，克服了现有工具的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有数据收集工具在粒度控制、事件收集和配置灵活性方面存在不足，限制了研究和教育的效果。

Method: 开发KOALA插件，安装在IDE中，配置任务、IDE功能开关和调查，收集代码快照、IDE操作等数据，并支持转换为ProgSnap2格式。

Result: 成功从28名学生中收集数据，展示了工具的实际应用效果。

Conclusion: KOALA为编程教育研究提供了更灵活、全面的数据收集解决方案。

Abstract: Collecting data of students solving programming tasks is incredibly valuable
for researchers and educators. It allows verifying that the students correctly
apply the features and concepts they are taught, or finding students'
misconceptions. However, existing data collection tools have limitations, e.g.,
no control over the granularity of the collected code, not collecting the
specific events of the programming environment used, and overall being hard to
configure.
  To overcome these limitations, we propose KOALA, a convenient and highly
configurable tool for collecting code snapshots and feature usage from students
solving programming tasks in JetBrains IDEs. The plugin can be installed in
IDEs and configured to provide the students with the necessary tasks, enable or
disable certain IDE features like code completion, and run surveys. During
problem solving, the plugin collects code snapshots at the configured
granularity, all IDE actions like running and debugging, as well as some data
not collected in prior works, like employed hotkeys and switching focus between
files. The collected data is sent to the server that comes with the tool, where
it is stored and can be converted to the standardized ProgSnap2 format. To
showcase the tool, we collected data from 28 students solving tasks in two
courses within the IDE, highlighting some insights from this data.

</details>


### [10] [Exploring Micro Frontends: A Case Study Application in E-Commerce](https://arxiv.org/abs/2506.21297)
*Ricardo Hideki Hangai Kojo,Luiz Fernando Corte Real,Renato Cordeiro Ferreira,Thatiane de Oliveira Rosa,Alfredo Goldman*

Main category: cs.SE

TL;DR: 论文探讨了微前端架构在工业场景中的适用性，通过案例研究发现其虽能解决问题，但并非唯一选择。


<details>
  <summary>Details</summary>
Motivation: 研究微前端架构的适用性，特别是在工业环境中，以解决紧耦合、技术过差和开发体验差的问题。

Method: 结合学术和灰色文献调查微前端现状，并在一个手工艺品市场平台实施该架构，通过开发者问卷评估效果。

Result: 微前端成功实施，但研究发现单体前端等其他方案也能达到类似效果；微前端的优势在于与微服务架构的兼容性。

Conclusion: 微前端在特定场景（如已有微服务架构）下更便利，但并非所有情况都必要。

Abstract: In the micro frontends architectural style, the frontend is divided into
smaller components, which can range from a simple button to an entire page. The
goal is to improve scalability, resilience, and team independence, albeit at
the cost of increased complexity and infrastructure demands. This paper seeks
to understand when it is worth adopting micro frontends, particularly in the
context of industry. To achieve this, we conducted an investigation into the
state of the art of micro frontends, based on both academic and gray
literature. We then implemented this architectural style in a marketplace for
handcrafted products, which already used microservices. Finally, we evaluated
the implementation through a semi-open questionnaire with the developers. At
the studied marketplace company, the need for architectural change arose due to
the tight coupling between their main system (a Java monolith) and a dedicated
frontend system. Additionally, there were deprecated technologies and poor
developer experience. To address these issues, the micro frontends architecture
was adopted, along with the API Gateway and Backend for Frontend patterns, and
technologies such as Svelte and Fastify. Although the adoption of Micro
Frontends was successful, it was not strictly necessary to meet the company's
needs. According to the analysis of the mixed questionnaire responses, other
alternatives, such as a monolithic frontend, could have achieved comparable
results. What made adopting micro frontends the most convenient choice in the
company's context was the monolith strangulation and microservices adoption,
which facilitated implementation through infrastructure reuse and knowledge
sharing between teams.

</details>


### [11] [An object-centric core metamodel for IoT-enhanced event logs](https://arxiv.org/abs/2506.21300)
*Yannis Bertrand,Christian Imenkamp,Lukas Malburg,Matthias Ehrendorfer,Marco Franceschetti,Joscha Grüger,Francesco Leotta,Jürgen Mangler,Ronny Seiger,Agnes Koschmider,Stefanie Rinderle-Ma,Barbara Weber,Estefania Serral*

Main category: cs.SE

TL;DR: 论文提出了一种核心模型，整合了现有数据模型的重要特性，以促进物联网（IoT）数据与业务流程数据的集成，从而支持流程挖掘（PM）技术的应用。


<details>
  <summary>Details</summary>
Motivation: 物联网设备的普及产生了大量数据，但与传统流程数据的集成存在挑战，现有模型分散且难以共享。

Method: 提出一个基于共同需求的核心模型，并通过Python原型实现验证其满足这些需求。

Result: 核心模型成功整合了现有模型的特性，促进了数据共享和协作。

Conclusion: 该模型为物联网与流程数据的集成提供了统一框架，支持流程挖掘领域的发展。

Abstract: Advances in Internet-of-Things (IoT) technologies have prompted the
integration of IoT devices with business processes (BPs) in many organizations
across various sectors, such as manufacturing, healthcare and smart spaces. The
proliferation of IoT devices leads to the generation of large amounts of IoT
data providing a window on the physical context of BPs, which facilitates the
discovery of new insights about BPs using process mining (PM) techniques.
However, to achieve these benefits, IoT data need to be combined with
traditional process (event) data, which is challenging due to the very
different characteristics of IoT and process data, for instance in terms of
granularity levels. Recently, several data models were proposed to integrate
IoT data with process data, each focusing on different aspects of data
integration based on different assumptions and requirements. This fragmentation
hampers data exchange and collaboration in the field of PM, e.g., making it
tedious for researchers to share data. In this paper, we present a core model
synthesizing the most important features of existing data models. As the core
model is based on common requirements, it greatly facilitates data sharing and
collaboration in the field. A prototypical Python implementation is used to
evaluate the model against various use cases and demonstrate that it satisfies
these common requirements.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [12] [Perry: A High-level Framework for Accelerating Cyber Deception Experimentation](https://arxiv.org/abs/2506.20770)
*Brian Singer,Yusuf Saquib,Lujo Bauer,Vyas Sekar*

Main category: cs.CR

TL;DR: Perry是一个高层次框架，旨在简化网络欺骗防御的设计与评估，通过抽象层和实验模块支持多种欺骗场景的快速探索。


<details>
  <summary>Details</summary>
Motivation: 现有欺骗防御工具复杂且难以扩展，阻碍了实验和评估。

Method: Perry包含抽象层和实验模块，通过四个关键模块（动作规划、可观测性、环境状态服务和攻击图服务）实现高层次规范到低层次实现的转换。

Result: Perry减少了实现多样化欺骗防御的复杂性，并通过55个独特场景展示了其价值。

Conclusion: Perry为安全操作员提供了高效的工具，用于探索欺骗防御的权衡和效果。

Abstract: Cyber deception aims to distract, delay, and detect network attackers with
fake assets such as honeypots, decoy credentials, or decoy files. However,
today, it is difficult for operators to experiment, explore, and evaluate
deception approaches. Existing tools and platforms have non-portable and
complex implementations that are difficult to modify and extend. We address
this pain point by introducing Perry, a high-level framework that accelerates
the design and exploration of deception what-if scenarios. Perry has two
components: a high-level abstraction layer for security operators to specify
attackers and deception strategies, and an experimentation module to run these
attackers and defenders in realistic emulated networks. To translate these
high-level specifications we design four key modules for Perry: 1) an action
planner that translates high-level actions into low-level implementations, 2)
an observability module to translate low-level telemetry into high-level
observations, 3) an environment state service that enables environment agnostic
strategies, and 4) an attack graph service to reason about how attackers could
explore an environment. We illustrate that Perry's abstractions reduce the
implementation effort of exploring a wide variety of deception defenses,
attackers, and environments. We demonstrate the value of Perry by emulating 55
unique deception what-if scenarios and illustrate how these experiments enable
operators to shed light on subtle tradeoffs.

</details>


### [13] [SIMulator: SIM Tracing on a (Pico-)Budget](https://arxiv.org/abs/2506.20800)
*Gabriel K. Gegenhuber,Philipp É. Frenzel,Adrian Dabrowski*

Main category: cs.CR

TL;DR: 论文提出了一种低成本实现SIM追踪功能的方法，仅需简单硬件（如UART接口和GPIO端口），并移植到树莓派Pico（约4美元）上，显著降低了硬件复杂性和成本。


<details>
  <summary>Details</summary>
Motivation: 传统SIM追踪依赖昂贵专用硬件，增加了研究门槛。本文旨在通过简化硬件需求，使更多研究者和爱好者能够使用SIM追踪技术。

Method: 利用UART接口和GPIO端口实现SIM与调制解调器的电气解耦，仅在APDU级别传输数据，移植到低成本微控制器（如树莓派Pico）。

Result: 成功实现了完整的SIM追踪功能，硬件成本大幅降低（约4美元），且显著简化了硬件复杂性。

Conclusion: 该方法使SIM追踪技术更易获取，有望推动蜂窝网络研究的广泛探索和实验。

Abstract: SIM tracing -- the ability to inspect, modify, and relay communication
between a SIM card and modem -- has become a significant technique in cellular
network research. It enables essential security- and development-related
applications such as fuzzing communication interfaces, extracting session keys,
monitoring hidden SIM activity (e.g., proactive SIM commands or over-the-air
updates), and facilitating scalable, distributed measurement platforms through
SIM reuse. Traditionally, achieving these capabilities has relied on
specialized hardware, which can pose financial and logistical burdens for
researchers, particularly those new to the field. In this work, we show that
full SIM tracing functionality can be achieved using only simple, widely
available components, such as UART interfaces and GPIO ports. We port these
capabilities to low-cost microcontrollers, exemplified by the Raspberry Pi Pico
(4~USD). Unlike other approaches, it dramatically reduces hardware complexity
by electrically decoupling the SIM and the modem and only transferring on APDU
level. By significantly reducing hardware requirements and associated costs, we
aim to make SIM tracing techniques accessible to a broader community of
researchers and hobbyists, fostering wider exploration and experimentation in
cellular network research.

</details>


### [14] [Poster: Enhancing GNN Robustness for Network Intrusion Detection via Agent-based Analysis](https://arxiv.org/abs/2506.20806)
*Zhonghao Zhan,Huichi Zhou,Hamed Haddadi*

Main category: cs.CR

TL;DR: 该论文提出了一种利用大型语言模型（LLMs）增强图神经网络（GNNs）在入侵检测系统中鲁棒性和泛化能力的新方法。


<details>
  <summary>Details</summary>
Motivation: GNNs在网络入侵检测系统（NIDS）中表现优异，但面临分布漂移和对抗攻击的挑战，现有评估方法缺乏系统性分析。

Method: 通过LLMs作为模拟网络安全专家代理，分析网络流数据的图结构，识别并缓解对抗性扰动。

Result: 实验表明，LLM分析能显著提升GNNs在对抗攻击下的鲁棒性。

Conclusion: LLM代理可作为入侵检测架构的补充层，提升系统整体性能。

Abstract: Graph Neural Networks (GNNs) show great promise for Network Intrusion
Detection Systems (NIDS), particularly in IoT environments, but suffer
performance degradation due to distribution drift and lack robustness against
realistic adversarial attacks. Current robustness evaluations often rely on
unrealistic synthetic perturbations and lack demonstrations on systematic
analysis of different kinds of adversarial attack, which encompass both
black-box and white-box scenarios. This work proposes a novel approach to
enhance GNN robustness and generalization by employing Large Language Models
(LLMs) in an agentic pipeline as simulated cybersecurity expert agents. These
agents scrutinize graph structures derived from network flow data, identifying
and potentially mitigating suspicious or adversarially perturbed elements
before GNN processing. Our experiments, using a framework designed for
realistic evaluation and testing with a variety of adversarial attacks
including a dataset collected from physical testbed experiments, demonstrate
that integrating LLM analysis can significantly improve the resilience of
GNN-based NIDS against challenges, showcasing the potential of LLM agent as a
complementary layer in intrusion detection architectures.

</details>


### [15] [Empowering Digital Agriculture: A Privacy-Preserving Framework for Data Sharing and Collaborative Research](https://arxiv.org/abs/2506.20872)
*Osama Zafar,Rosemarie Santa González,Mina Namazi,Alfonso Morales,Erman Ayday*

Main category: cs.CR

TL;DR: 提出了一种隐私保护框架，结合降维技术和差分隐私，支持农民安全共享数据并促进协作研究，同时保护敏感信息。


<details>
  <summary>Details</summary>
Motivation: 解决农民因隐私问题不愿共享数据的问题，以推动数据驱动的农业发展。

Method: 结合主成分分析（PCA）和拉普拉斯噪声的差分隐私技术，支持联邦学习和协作模型训练。

Result: 在真实数据集上验证了隐私保护和实用性能，效果接近集中式系统。

Conclusion: 该框架能促进农民协作和研究发展，为农业数据的安全整合和创新提供支持。

Abstract: Data-driven agriculture, which integrates technology and data into
agricultural practices, has the potential to improve crop yield, disease
resilience, and long-term soil health. However, privacy concerns, such as
adverse pricing, discrimination, and resource manipulation, deter farmers from
sharing data, as it can be used against them. To address this barrier, we
propose a privacy-preserving framework that enables secure data sharing and
collaboration for research and development while mitigating privacy risks. The
framework combines dimensionality reduction techniques (like Principal
Component Analysis (PCA)) and differential privacy by introducing Laplacian
noise to protect sensitive information. The proposed framework allows
researchers to identify potential collaborators for a target farmer and train
personalized machine learning models either on the data of identified
collaborators via federated learning or directly on the aggregated
privacy-protected data. It also allows farmers to identify potential
collaborators based on similarities. We have validated this on real-life
datasets, demonstrating robust privacy protection against adversarial attacks
and utility performance comparable to a centralized system. We demonstrate how
this framework can facilitate collaboration among farmers and help researchers
pursue broader research objectives. The adoption of the framework can empower
researchers and policymakers to leverage agricultural data responsibly, paving
the way for transformative advances in data-driven agriculture. By addressing
critical privacy challenges, this work supports secure data integration,
fostering innovation and sustainability in agricultural systems.

</details>


### [16] [ZKPROV: A Zero-Knowledge Approach to Dataset Provenance for Large Language Models](https://arxiv.org/abs/2506.20915)
*Mina Namazi,Alexander Nemecek,Erman Ayday*

Main category: cs.CR

TL;DR: ZKPROV是一种新型加密框架，通过零知识证明验证大型语言模型的训练数据来源，确保数据隐私和完整性。


<details>
  <summary>Details</summary>
Motivation: 在敏感领域（如医疗）部署大型语言模型时，确保其计算来源的完整性至关重要，但现有方法要么计算成本高，要么依赖可信执行环境。

Method: ZKPROV利用零知识证明和数据集签名元数据，将训练模型与授权数据集绑定，避免验证每个训练步骤。

Result: 实验证明ZKPROV高效且可扩展，能提供隐私保护和可信的数据来源证明。

Conclusion: ZKPROV在保护数据集隐私的同时，提供了可信的数据来源验证，适用于实际部署。

Abstract: As the deployment of large language models (LLMs) grows in sensitive domains,
ensuring the integrity of their computational provenance becomes a critical
challenge, particularly in regulated sectors such as healthcare, where strict
requirements are applied in dataset usage. We introduce ZKPROV, a novel
cryptographic framework that enables zero-knowledge proofs of LLM provenance.
It allows users to verify that a model is trained on a reliable dataset without
revealing sensitive information about it or its parameters. Unlike prior
approaches that focus on complete verification of the training process
(incurring significant computational cost) or depend on trusted execution
environments, ZKPROV offers a distinct balance. Our method cryptographically
binds a trained model to its authorized training dataset(s) through
zero-knowledge proofs while avoiding proof of every training step. By
leveraging dataset-signed metadata and compact model parameter commitments,
ZKPROV provides sound and privacy-preserving assurances that the result of the
LLM is derived from a model trained on the claimed authorized and relevant
dataset. Experimental results demonstrate the efficiency and scalability of the
ZKPROV in generating this proof and verifying it, achieving a practical
solution for real-world deployments. We also provide formal security
guarantees, proving that our approach preserves dataset confidentiality while
ensuring trustworthy dataset provenance.

</details>


### [17] [CodeGuard: A Generalized and Stealthy Backdoor Watermarking for Generative Code Models](https://arxiv.org/abs/2506.20926)
*Haoxuan Li,Jiale Zhang,Xiaobing Sun,Xiapu Luo*

Main category: cs.CR

TL;DR: CodeGuard是一种结合注意力机制和分布式触发器嵌入策略的新型水印方法，解决了现有技术在泛化性和隐蔽性上的不足。


<details>
  <summary>Details</summary>
Motivation: 生成代码模型（GCMs）需要有效的数字版权保护以防止未经授权的泄露和滥用，但现有水印技术存在泛化性差和隐蔽性不足的问题。

Method: CodeGuard利用注意力机制确定水印嵌入位置，并通过同态字符替换和分布式触发器嵌入策略提高隐蔽性。

Result: 实验显示，CodeGuard在代码生成和代码摘要任务中水印验证率高达100%，且不影响主要任务性能，隐蔽性显著优于基线方法。

Conclusion: CodeGuard在版权保护和隐蔽性方面表现优异，为生成代码模型的水印技术提供了有效解决方案。

Abstract: Generative code models (GCMs) significantly enhance development efficiency
through automated code generation and code summarization. However, building and
training these models require computational resources and time, necessitating
effective digital copyright protection to prevent unauthorized leaks and
misuse. Backdoor watermarking, by embedding hidden identifiers, simplifies
copyright verification by breaking the model's black-box nature. Current
backdoor watermarking techniques face two main challenges: first, limited
generalization across different tasks and datasets, causing fluctuating
verification rates; second, insufficient stealthiness, as watermarks are easily
detected and removed by automated methods. To address these issues, we propose
CodeGuard, a novel watermarking method combining attention mechanisms with
distributed trigger embedding strategies. Specifically, CodeGuard employs
attention mechanisms to identify watermark embedding positions, ensuring
verifiability. Moreover, by using homomorphic character replacement, it avoids
manual detection, while distributed trigger embedding reduces the likelihood of
automated detection. Experimental results demonstrate that CodeGuard achieves
up to 100% watermark verification rates in both code summarization and code
generation tasks, with no impact on the primary task performance. In terms of
stealthiness, CodeGuard performs exceptionally, with a maximum detection rate
of only 0.078 against ONION detection methods, significantly lower than
baseline methods.

</details>


### [18] [SPA: Towards More Stealth and Persistent Backdoor Attacks in Federated Learning](https://arxiv.org/abs/2506.20931)
*Chengcheng Zhu,Ye Li,Bosen Rao,Jiale Zhang,Yunlong Mao,Sheng Zhong*

Main category: cs.CR

TL;DR: 本文提出了一种名为SPA的新型隐蔽后门攻击框架，通过特征空间对齐而非直接触发标签关联，显著提高了攻击的隐蔽性和持久性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）中的后门攻击威胁日益严重，传统方法依赖端到端标签监督，导致特征解耦和持久性不足。

Method: SPA利用特征空间对齐减少后门触发特征与目标类别特征之间的表示距离，并引入自适应对抗触发优化机制。

Result: 实验表明，SPA在多种FL基准测试中攻击成功率高，对模型效用影响小，且在非IID数据分布下表现稳健。

Conclusion: 研究强调了FL中后门威胁的复杂性，呼吁开发更先进的特征级防御技术。

Abstract: Federated Learning (FL) has emerged as a leading paradigm for
privacy-preserving distributed machine learning, yet the distributed nature of
FL introduces unique security challenges, notably the threat of backdoor
attacks. Existing backdoor strategies predominantly rely on end-to-end label
supervision, which, despite their efficacy, often results in detectable feature
disentanglement and limited persistence. In this work, we propose a novel and
stealthy backdoor attack framework, named SPA, which fundamentally departs from
traditional approaches by leveraging feature-space alignment rather than direct
trigger-label association. Specifically, SPA reduces representational distances
between backdoor trigger features and target class features, enabling the
global model to misclassify trigger-embedded inputs with high stealth and
persistence. We further introduce an adaptive, adversarial trigger optimization
mechanism, utilizing boundary-search in the feature space to enhance attack
longevity and effectiveness, even against defensive FL scenarios and non-IID
data distributions. Extensive experiments on various FL benchmarks demonstrate
that SPA consistently achieves high attack success rates with minimal impact on
model utility, maintains robustness under challenging participation and data
heterogeneity conditions, and exhibits persistent backdoor effects far
exceeding those of conventional techniques. Our results call urgent attention
to the evolving sophistication of backdoor threats in FL and emphasize the
pressing need for advanced, feature-level defense techniques.

</details>


### [19] [PrivacyGo: Privacy-Preserving Ad Measurement with Multidimensional Intersection](https://arxiv.org/abs/2506.20981)
*Jian Du,Haohao Qian,Shikun Zhang,Wen-jie Lu,Donghang Lu,Yongchuan Niu,Bo Jiang,Yongjun Zhao,Qiang Yan*

Main category: cs.CR

TL;DR: 提出了一种基于反向OPRF和盲密钥旋转技术的隐私保护广告测量框架，支持多标识符安全匹配，防止交叉标识符关联，并引入差分隐私机制。


<details>
  <summary>Details</summary>
Motivation: 解决多标识符用户档案匹配中的隐私问题，满足广告分析中对隐私保护的需求。

Method: 采用反向OPRF和盲密钥旋转技术，结合差分隐私机制，设计高效且安全的协议。

Result: 协议具有强隐私保证和高效率，适用于大规模数据集，为广告行业提供隐私保护解决方案。

Conclusion: 该框架为隐私保护广告测量设定了新标准，结合密码学与差分隐私，满足行业关键需求。

Abstract: This paper tackles the challenging and practical problem of multi-identifier
private user profile matching for privacy-preserving ad measurement, a
cornerstone of modern advertising analytics. We introduce a comprehensive
cryptographic framework leveraging reversed Oblivious Pseudorandom Functions
(OPRF) and novel blind key rotation techniques to support secure matching
across multiple identifiers. Our design prevents cross-identifier linkages and
includes a differentially private mechanism to obfuscate intersection sizes,
mitigating risks such as membership inference attacks.
  We present a concrete construction of our protocol that achieves both strong
privacy guarantees and high efficiency. It scales to large datasets, offering a
practical and scalable solution for privacy-centric applications like secure ad
conversion tracking. By combining rigorous cryptographic principles with
differential privacy, our work addresses a critical need in the advertising
industry, setting a new standard for privacy-preserving ad measurement
frameworks.

</details>


### [20] [TEMPEST-LoRa: Cross-Technology Covert Communication](https://arxiv.org/abs/2506.21069)
*Xieyang Sun,Yuanqing Zheng,Wei Xi,Zuhao Chen,Zhizhen Chen,Han Hao,Zhiping Jiang,Sheng Zhong*

Main category: cs.CR

TL;DR: 论文提出了一种新的电磁隐蔽信道TEMPEST-LoRa，利用视频电缆的电磁泄漏，通过LoRa接收器远距离传输敏感数据，最大距离达87.5米或速率21.6 kbps。


<details>
  <summary>Details</summary>
Motivation: 电磁隐蔽信道对隔离网络的计算机和通信安全构成威胁，现有方法需要近距离部署专用接收器，限制了实际影响。本文旨在解决这一问题。

Method: 利用视频电缆的电磁泄漏，通过Cross-Technology Covert Communication (CTCC)技术，将数据调制为LoRa可接收的信号。

Result: 实验证明，攻击者可在87.5米距离内或21.6 kbps速率下可靠解码视频电缆泄漏的电磁信号。

Conclusion: TEMPEST-LoRa展示了电磁隐蔽信道的潜在风险，即使在显示器关闭的情况下也能隐蔽传输数据。

Abstract: Electromagnetic (EM) covert channels pose significant threats to computer and
communications security in air-gapped networks. Previous works exploit EM
radiation from various components (e.g., video cables, memory buses, CPUs) to
secretly send sensitive information. These approaches typically require the
attacker to deploy highly specialized receivers near the victim, which limits
their real-world impact. This paper reports a new EM covert channel,
TEMPEST-LoRa, that builds on Cross-Technology Covert Communication (CTCC),
which could allow attackers to covertly transmit EM-modulated secret data from
air-gapped networks to widely deployed operational LoRa receivers from afar. We
reveal the potential risk and demonstrate the feasibility of CTCC by tackling
practical challenges involved in manipulating video cables to precisely
generate the EM leakage that could readily be received by third-party
commercial LoRa nodes/gateways. Experiment results show that attackers can
reliably decode secret data modulated by the EM leakage from a video cable at a
maximum distance of 87.5m or a rate of 21.6 kbps. We note that the secret data
transmission can be performed with monitors turned off (therefore covertly).

</details>


### [21] [PhishKey: A Novel Centroid-Based Approach for Enhanced Phishing Detection Using Adaptive HTML Component Extraction](https://arxiv.org/abs/2506.21106)
*Felipe Castaño,Eduardo Fidalgo,Enrique Alegre,Rocio Alaiz-Rodríguez,Raul Orduna,Francesco Zola*

Main category: cs.CR

TL;DR: PhishKey是一种新型钓鱼检测方法，结合CNN和CAPE技术，通过软投票集成实现高精度分类，F1分数达98.70%。


<details>
  <summary>Details</summary>
Motivation: 钓鱼攻击快速演变，绕过检测机制并利用人类弱点，需开发适应性、鲁棒性和高效性的解决方案。

Method: PhishKey结合字符级CNN处理URL分类和CAPE处理HTML内容，通过软投票集成预测结果。

Result: 在四个数据集上表现优异，F1分数达98.70%，对抗性攻击表现稳健。

Conclusion: PhishKey在钓鱼检测中高效且可靠，适用于实际应用。

Abstract: Phishing attacks pose a significant cybersecurity threat, evolving rapidly to
bypass detection mechanisms and exploit human vulnerabilities. This paper
introduces PhishKey to address the challenges of adaptability, robustness, and
efficiency. PhishKey is a novel phishing detection method using automatic
feature extraction from hybrid sources. PhishKey combines character-level
processing with Convolutional Neural Networks (CNN) for URL classification, and
a Centroid-Based Key Component Phishing Extractor (CAPE) for HTML content at
the word level. CAPE reduces noise and ensures complete sample processing
avoiding crop operations on the input data. The predictions from both modules
are integrated using a soft-voting ensemble to achieve more accurate and
reliable classifications. Experimental evaluations on four state-of-the-art
datasets demonstrate the effectiveness of PhishKey. It achieves up to 98.70% F1
Score and shows strong resistance to adversarial manipulations such as
injection attacks with minimal performance degradation.

</details>


### [22] [Inside Job: Defending Kubernetes Clusters Against Network Misconfigurations](https://arxiv.org/abs/2506.21134)
*Jacopo Bufalino,Jose Luis Martin-Navarro,Mario Di Francesco,Tuomas Aura*

Main category: cs.CR

TL;DR: 本文分析了Kubernetes集群中的网络配置问题对安全的影响，尤其是横向移动攻击。通过评估287个开源应用，发现了634个配置错误，远超现有解决方案的能力。部分问题已通过提出的缓解措施修复。


<details>
  <summary>Details</summary>
Motivation: Kubernetes作为容器编排的事实标准，其安全性日益重要，但网络配置对安全的影响研究较少。本文填补了这一空白。

Method: 对6个组织的287个开源应用进行了全面分析，重点关注网络配置错误及其对横向移动攻击的影响。

Result: 发现了634个配置错误，远超现有解决方案的能力。部分问题已通过提出的缓解措施修复。

Conclusion: 网络配置错误对Kubernetes安全有重大影响，需更多关注和改进。

Abstract: Kubernetes has emerged as the de facto standard for container orchestration.
Unfortunately, its increasing popularity has also made it an attractive target
for malicious actors. Despite extensive research on securing Kubernetes, little
attention has been paid to the impact of network configuration on the security
of application deployments. This paper addresses this gap by conducting a
comprehensive analysis of network misconfigurations in a Kubernetes cluster
with specific reference to lateral movement. Accordingly, we carried out an
extensive evaluation of 287 open-source applications belonging to six different
organizations, ranging from IT companies and public entities to non-profits. As
a result, we identified 634 misconfigurations, well beyond what could be found
by solutions in the state of the art. We responsibly disclosed our findings to
the concerned organizations and engaged in a discussion to assess their
severity. As of now, misconfigurations affecting more than thirty applications
have been fixed with the mitigations we proposed.

</details>


### [23] [Balancing Privacy and Utility in Correlated Data: A Study of Bayesian Differential Privacy](https://arxiv.org/abs/2506.21308)
*Martin Lange,Patricia Guerra-Balboa,Javier Parra-Arnau,Thorsten Strufe*

Main category: cs.CR

TL;DR: 论文探讨了贝叶斯差分隐私（BDP）在现实数据中的实用性，提出了一种新方法以在相关性数据中保持隐私保护的同时减少效用损失。


<details>
  <summary>Details</summary>
Motivation: 现实数据中普遍存在相关性，传统差分隐私（DP）低估了隐私泄露风险，BDP虽能解决此问题，但现有方法效用损失显著，限制了其应用。

Method: 通过分析高斯多元分布和马尔可夫链等结构化相关性模型，提出理论链接和适应DP机制的新方法，以符合BDP要求。

Result: 在真实数据库上的评估表明，新理论支持设计的BDP机制能保持竞争力效用。

Conclusion: 研究为相关性数据中的隐私保护实践提供了可行的BDP实现路径。

Abstract: Privacy risks in differentially private (DP) systems increase significantly
when data is correlated, as standard DP metrics often underestimate the
resulting privacy leakage, leaving sensitive information vulnerable. Given the
ubiquity of dependencies in real-world databases, this oversight poses a
critical challenge for privacy protections. Bayesian differential privacy (BDP)
extends DP to account for these correlations, yet current BDP mechanisms
indicate notable utility loss, limiting its adoption.
  In this work, we address whether BDP can be realistically implemented in
common data structures without sacrificing utility -- a key factor for its
applicability. By analyzing arbitrary and structured correlation models,
including Gaussian multivariate distributions and Markov chains, we derive
practical utility guarantees for BDP. Our contributions include theoretical
links between DP and BDP and a novel methodology for adapting DP mechanisms to
meet the BDP requirements. Through evaluations on real-world databases, we
demonstrate that our novel theorems enable the design of BDP mechanisms that
maintain competitive utility, paving the way for practical privacy-preserving
data practices in correlated settings.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [24] [The Singapore Consensus on Global AI Safety Research Priorities](https://arxiv.org/abs/2506.20702)
*Yoshua Bengio,Tegan Maharaj,Luke Ong,Stuart Russell,Dawn Song,Max Tegmark,Lan Xue,Ya-Qin Zhang,Stephen Casper,Wan Sie Lee,Sören Mindermann,Vanessa Wilfred,Vidhisha Balachandran,Fazl Barez,Michael Belinsky,Imane Bello,Malo Bourgon,Mark Brakel,Siméon Campos,Duncan Cass-Beggs,Jiahao Chen,Rumman Chowdhury,Kuan Chua Seah,Jeff Clune,Juntao Dai,Agnes Delaborde,Nouha Dziri,Francisco Eiras,Joshua Engels,Jinyu Fan,Adam Gleave,Noah Goodman,Fynn Heide,Dan Hendrycks,Cyrus Hodes,Bryan Low Kian Hsiang,Minlie Huang,Sami Jawhar,Wang Jingyu,Adam Tauman Kalai,Meindert Kamphuis,Mohan Kankanhalli,Subhash Kantamneni,Mathias Bonde Kirk,Thomas Kwa,Jeffrey Ladish,Kwok-Yan Lam,Wan Lee Sie,Taewhi Lee,Xiaojian Li,Jiajun Liu,Chaochao Lu,Yifan Mai,Richard Mallah,Julian Michael,Nick Moës,Simon Möller,Kihyuk Nam,Kwan Yee Ng,Mark Nitzberg,Besmira Nushi,Seán O hÉigeartaigh,Alejandro Ortega,Pierre Peigné,James Petrie,Benjamin Prud'Homme,Reihaneh Rabbany,Nayat Sanchez-Pi,Sarah Schwettmann,Buck Shlegeris,Saad Siddiqui,Aradhana Sinha,Martín Soto,Cheston Tan,Dong Ting,Robert Trager,Brian Tse,Anthony Tung K. H.,Vanessa Wilfred,John Willes,Denise Wong,Wei Xu,Rongwu Xu,Yi Zeng,HongJiang Zhang,Djordje Žikelić*

Main category: cs.AI

TL;DR: 新加坡2025年AI会议报告聚焦AI安全性研究，提出开发、评估和控制的三大挑战领域。


<details>
  <summary>Details</summary>
Motivation: 随着AI能力的快速提升，确保其安全性（可信、可靠、安全）成为关键议题，需建立可信生态系统以促进创新并避免反弹。

Method: 报告采用深度防御模型，将AI安全研究分为开发（可信AI系统）、评估（风险）和控制（部署后监控与干预）三大领域。

Result: 报告整合了国际AI安全研究的优先事项，得到33国政府支持。

Conclusion: 通过多领域协作，构建可信AI生态系统是确保AI安全与创新的关键。

Abstract: Rapidly improving AI capabilities and autonomy hold significant promise of
transformation, but are also driving vigorous debate on how to ensure that AI
is safe, i.e., trustworthy, reliable, and secure. Building a trusted ecosystem
is therefore essential -- it helps people embrace AI with confidence and gives
maximal space for innovation while avoiding backlash.
  The "2025 Singapore Conference on AI (SCAI): International Scientific
Exchange on AI Safety" aimed to support research in this space by bringing
together AI scientists across geographies to identify and synthesise research
priorities in AI safety. This resulting report builds on the International AI
Safety Report chaired by Yoshua Bengio and backed by 33 governments. By
adopting a defence-in-depth model, this report organises AI safety research
domains into three types: challenges with creating trustworthy AI systems
(Development), challenges with evaluating their risks (Assessment), and
challenges with monitoring and intervening after deployment (Control).

</details>


### [25] [MAGPIE: A dataset for Multi-AGent contextual PrIvacy Evaluation](https://arxiv.org/abs/2506.20737)
*Gurusha Juneja,Alon Albalak,Wenyue Hua,William Yang Wang*

Main category: cs.AI

TL;DR: 论文研究了基于LLM的代理在多轮对话中是否理解上下文隐私，并评估了它们在非对抗性环境中保护用户隐私的能力。通过新基准MAGPIE测试发现，现有模型（如GPT-4o和Claude-2.7-Sonnet）在隐私分类和多轮对话中表现不佳，且多代理系统在71%的场景中无法完成任务。


<details>
  <summary>Details</summary>
Motivation: 随着LLM代理的普及，多代理协作在任务中广泛应用，但隐私保护成为关键问题。现有评估基准仅关注单轮简单任务，无法全面评估复杂场景下的隐私保护能力。

Method: 提出了MAGPIE基准，包含158个高风险场景，覆盖15个领域，用于评估LLM代理对上下文隐私的理解和协作能力。测试了GPT-4o和Claude-2.7-Sonnet等模型。

Result: 现有模型对隐私数据的分类错误率高（25.2%和43.6%），多轮对话中隐私泄露严重（59.9%和50.5%），且多代理系统在71%的场景中无法完成任务。

Conclusion: 当前模型在上下文隐私保护和协作任务解决方面表现不足，亟需改进。

Abstract: The proliferation of LLM-based agents has led to increasing deployment of
inter-agent collaboration for tasks like scheduling, negotiation, resource
allocation etc. In such systems, privacy is critical, as agents often access
proprietary tools and domain-specific databases requiring strict
confidentiality. This paper examines whether LLM-based agents demonstrate an
understanding of contextual privacy. And, if instructed, do these systems
preserve inference time user privacy in non-adversarial multi-turn
conversation. Existing benchmarks to evaluate contextual privacy in LLM-agents
primarily assess single-turn, low-complexity tasks where private information
can be easily excluded. We first present a benchmark - MAGPIE comprising 158
real-life high-stakes scenarios across 15 domains. These scenarios are designed
such that complete exclusion of private data impedes task completion yet
unrestricted information sharing could lead to substantial losses. We then
evaluate the current state-of-the-art LLMs on (a) their understanding of
contextually private data and (b) their ability to collaborate without
violating user privacy. Empirical experiments demonstrate that current models,
including GPT-4o and Claude-2.7-Sonnet, lack robust understanding of contextual
privacy, misclassifying private data as shareable 25.2\% and 43.6\% of the
time. In multi-turn conversations, these models disclose private information in
59.9\% and 50.5\% of cases even under explicit privacy instructions.
Furthermore, multi-agent systems fail to complete tasks in 71\% of scenarios.
These results underscore that current models are not aligned towards both
contextual privacy preservation and collaborative task-solving.

</details>


### [26] [Dynamic Context-Aware Prompt Recommendation for Domain-Specific AI Applications](https://arxiv.org/abs/2506.20815)
*Xinye Tang,Haijun Zhai,Chaitanya Belwal,Vineeth Thayanithi,Philip Baumann,Yogesh K Roy*

Main category: cs.AI

TL;DR: 本文提出了一种动态上下文感知的提示推荐系统，用于领域特定的AI应用，通过结合上下文查询分析、检索增强知识基础、分层技能组织和自适应技能排名，生成相关且可操作的提示建议。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的应用对用户提示质量高度敏感，而领域特定应用中高质量提示的编写往往具有挑战性。

Method: 系统利用行为遥测和两阶段分层推理过程动态选择和排名相关技能，并通过预定义和自适应模板结合少样本学习生成提示。

Result: 在真实数据集上的实验表明，该方法在自动和专家评估中均表现出高实用性和相关性。

Conclusion: 该动态上下文感知提示推荐系统能有效提升领域特定应用中提示的质量和实用性。

Abstract: LLM-powered applications are highly susceptible to the quality of user
prompts, and crafting high-quality prompts can often be challenging especially
for domain-specific applications. This paper presents a novel dynamic
context-aware prompt recommendation system for domain-specific AI applications.
Our solution combines contextual query analysis, retrieval-augmented knowledge
grounding, hierarchical skill organization, and adaptive skill ranking to
generate relevant and actionable prompt suggestions.
  The system leverages behavioral telemetry and a two-stage hierarchical
reasoning process to dynamically select and rank relevant skills, and
synthesizes prompts using both predefined and adaptive templates enhanced with
few-shot learning. Experiments on real-world datasets demonstrate that our
approach achieves high usefulness and relevance, as validated by both automated
and expert evaluations.

</details>


### [27] [Beyond Reactive Safety: Risk-Aware LLM Alignment via Long-Horizon Simulation](https://arxiv.org/abs/2506.20949)
*Chenkai Sun,Denghui Zhang,ChengXiang Zhai,Heng Ji*

Main category: cs.AI

TL;DR: 提出一个框架，用于评估语言模型建议的宏观社会影响，并引入间接危害场景数据集，模型表现显著优于基线。


<details>
  <summary>Details</summary>
Motivation: 语言模型对社会决策影响日益增大，需确保其建议的长期安全性。

Method: 提出概念验证框架，模拟模型建议的宏观传播，并引入100个间接危害场景数据集。

Result: 新数据集上表现提升20%，现有安全基准上平均胜率超70%。

Conclusion: 框架为构建更安全的语言模型提供了有前景的方向。

Abstract: Given the growing influence of language model-based agents on high-stakes
societal decisions, from public policy to healthcare, ensuring their beneficial
impact requires understanding the far-reaching implications of their
suggestions. We propose a proof-of-concept framework that projects how
model-generated advice could propagate through societal systems on a
macroscopic scale over time, enabling more robust alignment. To assess the
long-term safety awareness of language models, we also introduce a dataset of
100 indirect harm scenarios, testing models' ability to foresee adverse,
non-obvious outcomes from seemingly harmless user prompts. Our approach
achieves not only over 20% improvement on the new dataset but also an average
win rate exceeding 70% against strong baselines on existing safety benchmarks
(AdvBench, SafeRLHF, WildGuardMix), suggesting a promising direction for safer
agents.

</details>


### [28] [Unveiling Causal Reasoning in Large Language Models: Reality or Mirage?](https://arxiv.org/abs/2506.21215)
*Haoang Chi,He Li,Wenjing Yang,Feng Liu,Long Lan,Xiaoguang Ren,Tongliang Liu,Bo Han*

Main category: cs.AI

TL;DR: 论文探讨了大语言模型（LLMs）在因果推理能力上的局限性，提出了一种新方法G^2-Reasoner以提升其能力。


<details>
  <summary>Details</summary>
Motivation: 研究旨在揭示LLMs仅能进行浅层（level-1）因果推理，缺乏人类般的深层（level-2）推理能力，并探索如何弥补这一差距。

Method: 通过分析LLMs的自回归机制，提出CausalProbe-2024基准测试，并设计G^2-Reasoner方法，结合通用知识和目标导向提示。

Result: 实验表明，G^2-Reasoner显著提升了LLMs在新颖和反事实情境中的因果推理能力。

Conclusion: 研究为LLMs实现更深层次的因果推理提供了新思路，推动了其向level-2推理的进步。

Abstract: Causal reasoning capability is critical in advancing large language models
(LLMs) toward strong artificial intelligence. While versatile LLMs appear to
have demonstrated capabilities in understanding contextual causality and
providing responses that obey the laws of causality, it remains unclear whether
they perform genuine causal reasoning akin to humans. However, current evidence
indicates the contrary. Specifically, LLMs are only capable of performing
shallow (level-1) causal reasoning, primarily attributed to the causal
knowledge embedded in their parameters, but they lack the capacity for genuine
human-like (level-2) causal reasoning. To support this hypothesis,
methodologically, we delve into the autoregression mechanism of
transformer-based LLMs, revealing that it is not inherently causal.
Empirically, we introduce a new causal Q&A benchmark called CausalProbe-2024,
whose corpora are fresh and nearly unseen for the studied LLMs. The LLMs
exhibit a significant performance drop on CausalProbe-2024 compared to earlier
benchmarks, indicating the fact that they primarily engage in level-1 causal
reasoning. To bridge the gap towards level-2 causal reasoning, we draw
inspiration from the fact that human reasoning is usually facilitated by
general knowledge and intended goals. We propose G^2-Reasoner, a method that
incorporates general knowledge and goal-oriented prompts into LLMs' causal
reasoning processes. Experiments demonstrate that G^2-Reasoner significantly
enhances LLMs' causal reasoning capability, particularly in fresh and
counterfactual contexts. This work sheds light on a new path for LLMs to
advance towards genuine causal reasoning, going beyond level-1 and making
strides towards level-2.

</details>


### [29] [World-aware Planning Narratives Enhance Large Vision-Language Model Planner](https://arxiv.org/abs/2506.21230)
*Junhao Shi,Zhaoye Fei,Siyin Wang,Qipeng Guo,Jingjing Gong,Xipeng QIu*

Main category: cs.AI

TL;DR: WAP框架通过四种认知能力增强LVLMs的环境理解，显著提升了任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有LVLMs在复杂场景中表现不佳，缺乏环境上下文关联。

Method: 提出WAP框架，结合视觉外观建模、空间推理等功能，通过课程学习训练模型。

Result: 在EB-ALFRED基准测试中，任务成功率提升60.7%，尤其在常识推理和长时规划方面表现突出。

Conclusion: WAP框架显著优于现有方法，甚至超越专有系统。

Abstract: Large Vision-Language Models (LVLMs) show promise for embodied planning tasks
but struggle with complex scenarios involving unfamiliar environments and
multi-step goals. Current approaches rely on environment-agnostic imitation
learning that disconnects instructions from environmental contexts, causing
models to struggle with context-sensitive instructions and rely on
supplementary cues rather than visual reasoning during long-horizon
interactions. In this work, we propose World-Aware Planning Narrative
Enhancement (WAP), a framework that infuses LVLMs with comprehensive
environmental understanding through four cognitive capabilities (visual
appearance modeling, spatial reasoning, functional abstraction, and syntactic
grounding) while developing and evaluating models using only raw visual
observations through curriculum learning. Evaluations on the EB-ALFRED
benchmark demonstrate substantial improvements, with Qwen2.5-VL achieving a
60.7 absolute improvement in task success rates, particularly in commonsense
reasoning (+60.0) and long-horizon planning (+70.0). Notably, our enhanced
open-source models outperform proprietary systems like GPT-4o and
Claude-3.5-Sonnet by a large margin.

</details>


### [30] [IXAII: An Interactive Explainable Artificial Intelligence Interface for Decision Support Systems](https://arxiv.org/abs/2506.21310)
*Pauline Speckmann,Mario Nadj,Christian Janiesch*

Main category: cs.AI

TL;DR: IXAII是一个交互式可解释AI系统，整合了LIME、SHAP、Anchors和DiCE四种方法，针对不同用户群体提供定制化解释，并通过专家和普通用户访谈验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的事后可解释AI方法多为静态且忽视用户视角，限制了其实际效果。

Method: 开发了交互式系统IXAII，整合四种解释方法，提供定制化视图和用户控制权。

Result: 用户认为IXAII通过多重视觉化选项提高了透明度。

Conclusion: IXAII为AI解释实践和人机交互提供了新视角。

Abstract: Although several post-hoc methods for explainable AI have been developed,
most are static and neglect the user perspective, limiting their effectiveness
for the target audience. In response, we developed the interactive explainable
intelligent system called IXAII that offers explanations from four explainable
AI methods: LIME, SHAP, Anchors, and DiCE. Our prototype provides tailored
views for five user groups and gives users agency over the explanations'
content and their format. We evaluated IXAII through interviews with experts
and lay users. Our results indicate that IXAII, which provides different
explanations with multiple visualization options, is perceived as helpful to
increase transparency. By bridging the gaps between explainable AI methods,
interactivity, and practical implementation, we provide a novel perspective on
AI explanation practices and human-AI interaction.

</details>


### [31] [Active Inference AI Systems for Scientific Discovery](https://arxiv.org/abs/2506.21329)
*Karthik Duraisamy*

Main category: cs.AI

TL;DR: 论文提出AI驱动的科学发现需解决抽象、推理和现实三大差距，而非依赖模型规模或计算资源，强调主动推理系统的重要性。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统在科学发现中存在局限性，需通过解决抽象、推理和现实差距推动进步。

Method: 提出主动推理AI系统，结合因果自监督模型、贝叶斯规划器、知识图谱和闭环实验验证。

Result: 系统通过内部模型与外部验证的交互实现科学发现，强调人类判断的不可或缺性。

Conclusion: AI驱动的科学发现需结合主动推理系统与人类判断，以实现更有效的科学探索。

Abstract: The rapid evolution of artificial intelligence has led to expectations of
transformative scientific discovery, yet current systems remain fundamentally
limited by their operational architectures, brittle reasoning mechanisms, and
their separation from experimental reality. Building on earlier work, we
contend that progress in AI-driven science now depends on closing three
fundamental gaps -- the abstraction gap, the reasoning gap, and the reality gap
-- rather than on model size/data/test time compute. Scientific reasoning
demands internal representations that support simulation of actions and
response, causal structures that distinguish correlation from mechanism, and
continuous calibration. We define active inference AI systems for scientific
discovery as those that (i) maintain long-lived research memories grounded in
causal self-supervised foundation models, (ii) symbolic or neuro-symbolic
planners equipped with Bayesian guardrails, (iii) grow persistent knowledge
graphs where thinking generates novel conceptual nodes, reasoning establishes
causal edges, and real-world interaction prunes false connections while
strengthening verified pathways, and (iv) refine their internal representations
through closed-loop interaction with both high-fidelity simulators and
automated laboratories - an operational loop where mental simulation guides
action and empirical surprise reshapes understanding. In essence, we outline an
architecture where discovery arises from the interplay between internal models
that enable counterfactual reasoning and external validation that grounds
hypotheses in reality. It is also argued that the inherent ambiguity in
feedback from simulations and experiments, and underlying uncertainties makes
human judgment indispensable, not as a temporary scaffold but as a permanent
architectural component.

</details>


### [32] [TableMoE: Neuro-Symbolic Routing for Structured Expert Reasoning in Multimodal Table Understanding](https://arxiv.org/abs/2506.21393)
*Junwen Zhang,Pu Chen,Yin Zhang*

Main category: cs.AI

TL;DR: TableMoE提出了一种神经符号混合专家架构，用于多模态表格数据的鲁棒结构化推理，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有多模态大语言模型在复杂表格结构（如视觉退化、符号密度高）下的性能不足和泛化能力差的问题。

Method: 采用神经符号路由机制，动态分配表格元素到专用专家（如Table-to-HTML、Table-to-JSON），并结合符号推理图进行置信度感知路由。

Result: 实验表明TableMoE显著优于现有方法，并通过消融研究验证了神经符号路由和专家对齐的关键作用。

Conclusion: TableMoE通过神经符号推理有效提升了多模态表格理解的鲁棒性和可解释性。

Abstract: Multimodal understanding of tables in real-world contexts is challenging due
to the complexity of structure, symbolic density, and visual degradation (blur,
skew, watermarking, incomplete structures or fonts, multi-span or
hierarchically nested layouts). Existing multimodal large language models
(MLLMs) struggle with such WildStruct conditions, resulting in limited
performance and poor generalization. To address these challenges, we propose
TableMoE, a neuro-symbolic Mixture-of-Connector-Experts (MoCE) architecture
specifically designed for robust, structured reasoning over multimodal table
data. TableMoE features an innovative Neuro-Symbolic Routing mechanism, which
predicts latent semantic token roles (e.g., header, data cell, axis, formula)
and dynamically routes table elements to specialized experts (Table-to-HTML,
Table-to-JSON, Table-to-Code) using a confidence-aware gating strategy informed
by symbolic reasoning graphs. To facilitate effective alignment-driven
pretraining, we introduce the large-scale TableMoE-Align dataset, consisting of
1.2M table-HTML-JSON-code quadruples across finance, science, biomedicine and
industry, utilized exclusively for model pretraining. For evaluation, we curate
and release four challenging WildStruct benchmarks: WMMFinQA, WMMTatQA,
WMMTabDialog, and WMMFinanceMath, designed specifically to stress-test models
under real-world multimodal degradation and structural complexity. Experimental
results demonstrate that TableMoE significantly surpasses existing
state-of-the-art models. Extensive ablation studies validate each core
component, emphasizing the critical role of Neuro-Symbolic Routing and
structured expert alignment. Through qualitative analyses, we further showcase
TableMoE's interpretability and enhanced robustness, underscoring the
effectiveness of integrating neuro-symbolic reasoning for multimodal table
understanding.

</details>


### [33] [Spatial Mental Modeling from Limited Views](https://arxiv.org/abs/2506.21458)
*Baiqiao Yin,Qineng Wang,Pingyue Zhang,Jianshu Zhang,Kangrui Wang,Zihan Wang,Jieyu Zhang,Keshigeyan Chandrasegaran,Han Liu,Ranjay Krishna,Saining Xie,Manling Li,Jiajun Wu,Li Fei-Fei*

Main category: cs.AI

TL;DR: MindCube基准测试揭示现有视觉语言模型（VLM）在空间心理建模上的不足，通过‘map-then-reason’方法显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 探讨VLM是否能像人类一样从少量视角构建完整场景的空间心理模型。

Method: 使用MindCube基准测试，评估VLM在认知映射、视角转换和动态模拟上的表现，并提出三种改进方法，最终采用‘map-then-reason’联合训练。

Result: 通过‘map-then-reason’方法，准确率从37.8%提升至60.8%，结合强化学习后达到70.7%。

Conclusion: 构建和利用结构化空间表征的框架显著提升了VLM对不可见空间的理解能力。

Abstract: Can Vision Language Models (VLMs) imagine the full scene from just a few
views, like humans do? Humans form spatial mental models, internal
representations of unseen space, to reason about layout, perspective, and
motion. Our new MindCube benchmark with 21,154 questions across 3,268 images
exposes this critical gap, where existing VLMs exhibit near-random performance.
Using MindCube, we systematically evaluate how well VLMs build robust spatial
mental models through representing positions (cognitive mapping), orientations
(perspective-taking), and dynamics (mental simulation for "what-if" movements).
We then explore three approaches to help VLMs approximate spatial mental
models, including unseen intermediate views, natural language reasoning chains,
and cognitive maps. The significant improvement comes from a synergistic
approach, "map-then-reason", that jointly trains the model to first generate a
cognitive map and then reason upon it. By training models to reason over these
internal maps, we boosted accuracy from 37.8% to 60.8% (+23.0%). Adding
reinforcement learning pushed performance even further to 70.7% (+32.9%). Our
key insight is that such scaffolding of spatial mental models, actively
constructing and utilizing internal structured spatial representations with
flexible reasoning processes, significantly improves understanding of
unobservable space.

</details>


### [34] [Ad-Hoc Human-AI Coordination Challenge](https://arxiv.org/abs/2506.21490)
*Tin Dizdarević,Ravi Hammond,Tobias Gessler,Anisoara Calinescu,Jonathan Cook,Matteo Gallici,Andrei Lupu,Jakob Nicolaus Foerster*

Main category: cs.AI

TL;DR: 论文提出Ad-Hoc Human-AI Coordination Challenge (AH2AC2)，通过人类代理解决Hanabi游戏中人机协作的评估难题。


<details>
  <summary>Details</summary>
Motivation: 解决人机协作中评估成本高且难以复现的问题，推动AI与人类无缝协作的研究。

Method: 开发人类代理作为评估伙伴，基于大规模人类游戏数据集，开源有限数据以鼓励高效方法。

Result: 提出了AH2AC2框架，提供了基线结果，并通过受控评估系统确保公平性。

Conclusion: AH2AC2为低成本、可复现的人机协作评估提供了新途径，推动了相关研究的发展。

Abstract: Achieving seamless coordination between AI agents and humans is crucial for
real-world applications, yet it remains a significant open challenge. Hanabi is
a cooperative card game featuring imperfect information, constrained
communication, theory of mind requirements, and coordinated action -- making it
an ideal testbed for human-AI coordination. However, its use for human-AI
interaction has been limited by the challenges of human evaluation. In this
work, we introduce the Ad-Hoc Human-AI Coordination Challenge (AH2AC2) to
overcome the constraints of costly and difficult-to-reproduce human
evaluations. We develop \textit{human proxy agents} on a large-scale human
dataset that serve as robust, cheap, and reproducible human-like evaluation
partners in AH2AC2. To encourage the development of data-efficient methods, we
open-source a dataset of 3,079 games, deliberately limiting the amount of
available human gameplay data. We present baseline results for both two- and
three- player Hanabi scenarios. To ensure fair evaluation, we host the proxy
agents through a controlled evaluation system rather than releasing them
publicly. The code is available at
\href{https://github.com/FLAIROx/ah2ac2}{https://github.com/FLAIROx/ah2ac2}.

</details>


### [35] [Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge](https://arxiv.org/abs/2506.21506)
*Boyu Gou,Zanming Huang,Yuting Ning,Yu Gu,Michael Lin,Weijian Qi,Andrei Kopanev,Botao Yu,Bernal Jiménez Gutiérrez,Yiheng Shu,Chan Hee Song,Jiaman Wu,Shijie Chen,Hanane Nour Moussa,Tianshu Zhang,Jian Xie,Yifei Li,Tianci Xue,Zeyi Liao,Kai Zhang,Boyuan Zheng,Zhaowei Cai,Viktor Rozgic,Morteza Ziyadi,Huan Sun,Yu Su*

Main category: cs.AI

TL;DR: Mind2Web 2是一个包含130个高质量、长周期任务的基准测试，用于评估自主网络搜索系统，并提出了一种基于树形评分设计的Agent-as-a-Judge框架。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法无法应对自主搜索系统的复杂性和开放性，亟需新的基准和方法。

Method: 构建Mind2Web 2基准，设计任务特定的评判代理（Agent-as-a-Judge）框架，自动评估答案正确性和来源标注。

Result: OpenAI Deep Research系统达到人类性能的50-70%，且耗时减半。

Conclusion: Mind2Web 2为下一代自主搜索系统的开发和评估提供了坚实基础。

Abstract: Agentic search such as Deep Research systems, where large language models
autonomously browse the web, synthesize information, and return comprehensive
citation-backed answers, represents a major shift in how users interact with
web-scale information. While promising greater efficiency and cognitive
offloading, the growing complexity and open-endedness of agentic search have
outpaced existing evaluation benchmarks and methodologies, which largely assume
short search horizons and static answers. In this paper, we introduce Mind2Web
2, a benchmark of 130 realistic, high-quality, and long-horizon tasks that
require real-time web browsing and extensive information synthesis, constructed
with over 1,000 hours of human labor. To address the challenge of evaluating
time-varying and complex answers, we propose a novel Agent-as-a-Judge
framework. Our method constructs task-specific judge agents based on a
tree-structured rubric design to automatically assess both answer correctness
and source attribution. We conduct a comprehensive evaluation of nine frontier
agentic search systems and human performance, along with a detailed error
analysis to draw insights for future development. The best-performing system,
OpenAI Deep Research, can already achieve 50-70% of human performance while
spending half the time, showing a great potential. Altogether, Mind2Web 2
provides a rigorous foundation for developing and benchmarking the next
generation of agentic search systems.

</details>


### [36] [PsyLite Technical Report](https://arxiv.org/abs/2506.21536)
*Fangjun Ding,Renyu Zhang,Xinyu Feng,Chengye Xie,Zheng Zhang,Yanting Zhang*

Main category: cs.AI

TL;DR: PsyLite是一个轻量级的心理咨询大语言模型代理，基于InternLM2.5-7B-chat开发，通过两阶段训练策略提升推理能力、心理咨询能力和对话安全性，并在资源受限环境中实现低硬件部署。


<details>
  <summary>Details</summary>
Motivation: 现有AI心理咨询模型在对话安全、场景处理和轻量化部署方面存在不足，PsyLite旨在解决这些问题。

Method: 采用混合蒸馏数据微调和ORPO偏好优化的两阶段训练策略，结合条件RAG引入幽默元素和拒绝危险请求。

Result: 在CEval、CPsyCounE和SafeDialBench评估中表现优于基线模型，心理咨询专业性提升47.6%，对话安全性提升2.4%。

Conclusion: PsyLite为资源受限环境提供了可行的心理咨询解决方案，兼具高性能和低硬件需求。

Abstract: With the rapid development of digital technology, AI-driven psychological
counseling has gradually become an important research direction in the field of
mental health. However, existing models still have deficiencies in dialogue
safety, detailed scenario handling, and lightweight deployment. To address
these issues, this study proposes PsyLite, a lightweight psychological
counseling large language model agent developed based on the base model
InternLM2.5-7B-chat. Through a two-stage training strategy (hybrid distillation
data fine-tuning and ORPO preference optimization), PsyLite enhances the
model's deep-reasoning ability, psychological counseling ability, and safe
dialogue ability. After deployment using Ollama and Open WebUI, a custom
workflow is created with Pipelines. An innovative conditional RAG is designed
to introduce crosstalk humor elements at appropriate times during psychological
counseling to enhance user experience and decline dangerous requests to
strengthen dialogue safety. Evaluations show that PsyLite outperforms the
baseline models in the Chinese general evaluation (CEval), psychological
counseling professional evaluation (CPsyCounE), and dialogue safety evaluation
(SafeDialBench), particularly in psychological counseling professionalism
(CPsyCounE score improvement of 47.6\%) and dialogue safety (\safe{} score
improvement of 2.4\%). Additionally, the model uses quantization technology
(GGUF q4\_k\_m) to achieve low hardware deployment (5GB memory is sufficient
for operation), providing a feasible solution for psychological counseling
applications in resource-constrained environments.

</details>
