<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 27]
- [cs.CR](#cs.CR) [Total: 58]
- [cs.AI](#cs.AI) [Total: 83]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [LLM-based Triplet Extraction for Automated Ontology Generation in Software Engineering Standards](https://arxiv.org/abs/2509.00140)
*Songhui Yue*

Main category: cs.SE

TL;DR: 本文提出了一种基于大语言模型的开源方法，用于从软件工程标准文档中自动提取关系三元组，支持自动化本体生成。


<details>
  <summary>Details</summary>
Motivation: 本体论在知识表示和可解释的推理中致关重要，而软件工程标准文档具有长文本、非结构化和高噪声特征，需要有效方法来自动生成本体。

Method: 提出了一个包含文档分割、候选术语挖掘、基于LLM的关系推理、术辟规范化和跨部分对齐的有效自动本体生成流程，而不仅依赖于笔记工程方法。

Result: 构建了三个粒度级别的黄金标准测试集，对比评估生成的本体。结果显示该方法与OpenIE三元组提取方法相比具有相当或更优的性能。

Conclusion: 这项研究提供了一种有效的LLM辅助方法，能够从复杂的软件工程标准文档中自动生成高质量的本体，为知识表示和推理提供了可扩展的解决方案。

Abstract: Ontologies have supported knowledge representation and whitebox reasoning for
decades; thus, the automated ontology generation (AOG) plays a crucial role in
scaling their use. Software engineering standards (SES) consist of long,
unstructured text (with high noise) and paragraphs with domain-specific terms.
In this setting, relation triple extraction (RTE), together with term
extraction, constitutes the first stage toward AOG. This work proposes an
open-source large language model (LLM)-assisted approach to RTE for SES.
Instead of solely relying on prompt-engineering-based methods, this study
promotes the use of LLMs as an aid in constructing ontologies and explores an
effective AOG workflow that includes document segmentation, candidate term
mining, LLM-based relation inference, term normalization, and cross-section
alignment. Golden-standard benchmarks at three granularities are constructed
and used to evaluate the ontology generated from the study. The results show
that it is comparable and potentially superior to the OpenIE method of triple
extraction.

</details>


### [2] [LLM-Based Program Generation for Triggering Numerical Inconsistencies Across Compilers](https://arxiv.org/abs/2509.00256)
*Yutong Wang,Cindy Rubio-González*

Main category: cs.SE

TL;DR: LLM4FP是首个使用大语言模型生成浮点程序以触发编译器不一致性的框架，相比现有工具Varity检测到两倍多的不一致性，主要涉及实数值差异而非极端值。


<details>
  <summary>Details</summary>
Motivation: 不同编译器间的浮点不一致性会破坏数值软件的可靠性，需要有效工具来检测这些不一致性。

Method: 结合语法生成和基于反馈的变异，使用大语言模型生成多样化且有效的浮点程序。

Result: 在多个编译器和优化级别下，LLM4FP检测到的不一致性是Varity的两倍多，大多数涉及实数值差异，并在更广泛的优化级别和主机-设备编译器间发现不匹配。

Conclusion: LLM引导的程序生成显著提高了数值不一致性的检测能力。

Abstract: Floating-point inconsistencies across compilers can undermine the reliability
of numerical software. We present LLM4FP, the first framework that uses Large
Language Models (LLMs) to generate floating-point programs specifically
designed to trigger such inconsistencies. LLM4FP combines Grammar-Based
Generation and Feedback-Based Mutation to produce diverse and valid programs.
We evaluate LLM4FP across multiple compilers and optimization levels, measuring
inconsistency rate, time cost, and program diversity. LLM4FP detects over twice
as many inconsistencies compared to the state-of-the-art tool, Varity. Notably,
most of the inconsistencies involve real-valued differences, rather than
extreme values like NaN or infinities. LLM4FP also uncovers inconsistencies
across a wider range of optimization levels, and finds the most mismatches
between host and device compilers. These results show that LLM-guided program
generation improves the detection of numerical inconsistencies.

</details>


### [3] [JS-TOD: Detecting Order-Dependent Flaky Tests in Jest](https://arxiv.org/abs/2509.00466)
*Negar Hashemi,Amjed Tahir,Shawn Rasheed,August Shi,Rachel Blagojevic*

Main category: cs.SE

TL;DR: JS-TOD是一个用于检测Jest测试中顺序依赖导致的测试不稳定的工具，通过随机化测试顺序和重运行来发现测试依赖问题


<details>
  <summary>Details</summary>
Motivation: 测试顺序依赖是测试不稳定的主要原因之一，理想情况下每个测试应该独立运行且结果一致，但实践中测试结果会因执行顺序而变化

Method: 采用系统化方法随机化测试、测试套件和describe块的执行顺序，可自定义设置重排序次数和重运行次数（默认每个测试和测试套件10次重排序和10次重运行）

Result: 评估发现测试顺序依赖不稳定的两个主要原因：测试间共享文件和共享模拟状态

Conclusion: JS-TOD能有效检测JavaScript测试中的顺序依赖问题，帮助识别和修复测试不稳定性

Abstract: We present JS-TOD (JavaScript Test Order-dependency Detector), a tool that
can extract, reorder, and rerun Jest tests to reveal possible order-dependent
test flakiness. Test order dependency is one of the leading causes of test
flakiness. Ideally, each test should operate in isolation and yield consistent
results no matter the sequence in which tests are run. However, in practice,
test outcomes can vary depending on their execution order. JS-TOD employed a
systematic approach to randomising tests, test suites, and describe blocks. The
tool is highly customisable, as one can set the number of orders and reruns
required (the default setting is 10 reorder and 10 reruns for each test and
test suite). Our evaluation using JS-TOD reveals two main causes of test order
dependency flakiness: shared files and shared mocking state between tests.

</details>


### [4] [Bug Whispering: Towards Audio Bug Reporting](https://arxiv.org/abs/2509.00785)
*Elena Masserini,Daniela Micucci,Leonardo Mariani*

Main category: cs.SE

TL;DR: 探索通过音频消息记录和提交来让终端用户立即报告移动应用问题的想法，分析音频错误报告的特定特征及其对现有错误重现技术的挑战。


<details>
  <summary>Details</summary>
Motivation: 移动应用中的错误报告是重要功能，但现有文本报告方式可能不够便捷。音频记录简单易实现，有潜力增加开发团队收集的错误报告数量，从而提升错误识别和修复率。

Method: 基于初步实验探讨音频错误报告的挑战特征，分析其对现有错误重现技术的影响。

Result: 音频错误报告具有特定的特征，这些特征对现有的错误重现技术构成了挑战，需要进一步研究来解决这些问题。

Conclusion: 音频错误报告虽然简单易用且有潜力增加报告数量，但其独特特征对错误重现提出了新的挑战，需要进一步研究音频错误报告的收集和分析方法。

Abstract: Bug reporting is a key feature of mobile applications, as it enables
developers to collect information about faults that escaped testing and thus
affected end-users. This paper explores the idea of allowing end-users to
immediately report the problems that they experience by recording and
submitting audio messages. Audio recording is simple to implement and has the
potential to increase the number of bug reports that development teams can
gather, thus potentially improving the rate at which bugs are identified and
fixed. However, audio bug reports exhibit specific characteristics that
challenge existing techniques for reproducing bugs. This paper discusses these
challenges based on a preliminary experiment, and motivates further research on
the collection and analysis of audio-based bug reports

</details>


### [5] [REConnect: Participatory RE that Matters](https://arxiv.org/abs/2509.01006)
*Daniela Damian,Bachan Ghimire,Ze Shi Li*

Main category: cs.SE

TL;DR: REConnect提出了一种以人为本的参与式需求工程方法，强调在文化和社会背景下建立信任关系、共同设计和赋权用户，以确保系统与人类价值观和实际需求保持一致。


<details>
  <summary>Details</summary>
Motivation: 当前流行的需求工程实践（如CrowdRE和AI辅助方法）存在脱离文化、社会和政治背景的风险，可能导致系统无法真正反映用户的生活经验和价值观。

Method: 提出了REConnect框架，基于三个核心原则：建立信任关系、与利益相关者共同设计、赋权用户作为变革推动者。通过三个社会影响案例研究（尼泊尔的BloodSync、加拿大的Herluma和BridgingRoots）验证该方法。

Result: REConnect能够产生文化基础扎实、社会合法性高且在系统交付后可持续的需求。同时提出了REActions实践集，将关系性和持续的利益相关者参与嵌入需求工程的各个阶段。

Conclusion: 在生成式AI时代，AI可以加速某些需求工程任务，但其整合必须由参与式实践指导，以保持人类主体性并增强人类作为价值观守护者、包容性放大器、AI输出策展人和共同反思者的角色。

Abstract: Software increasingly shapes the infrastructures of daily life, making
requirements engineering (RE) central to ensuring that systems align with human
values and lived experiences. Yet, current popular practices such as CrowdRE
and AI-assisted elicitation strategies risk detaching requirements work from
the cultural, social, and political contexts that shape lived experiences,
human values, and real user needs. In this paper, we introduce REConnect that
re-centers RE on the human connection as central to the understanding of lived
experiences where impact is sought. REConnect advocates for a human-centered
participatory approach "that matters" to the communities and beneficiaries
involved, ensuring alignment with their values and aspirations. Drawing on
three case studies of societal impact: BloodSync in rural Nepal, Herluma
supporting women at risk of homelessness in Canada, and BridgingRoots to
revitalize Indigenous languages in the Canadian Arctic. REConnect argues that
three key principles and enablers: building trusting relationships,
co-designing with and alongside stakeholders, and empowering users as agents of
change, can yield requirements that are culturally grounded, socially
legitimate, and sustainable beyond system delivery. REConnect also proposes a
set of actionable practices (REActions) that embed relationality and ongoing
stakeholder engagement throughout requirements elicitation, analysis, and
validation of solution development. Finally, we situate REConnect in the era of
Generative AI. While AI can accelerate and scale certain RE tasks, its
integration must be guided by participatory practices that not only preserve
human agency but also empower humans' roles to become guardians of values and
ethics, inclusion amplifiers, curators of AI outputs, and co-reflectors in
iterative review cycles.

</details>


### [6] [Generative Goal Modeling](https://arxiv.org/abs/2509.01048)
*Ateeq Sharfuddin,Travis Breaux*

Main category: cs.SE

TL;DR: 使用GPT-4o从访谈记录中自动提取目标并构建目标模型，准确率达到62%的目标提取匹配率和98.7%的溯源准确性


<details>
  <summary>Details</summary>
Motivation: 传统需求获取方法中，业务分析师需要手动审查访谈记录来识别和记录需求，过程耗时且容易出错。目标建模是表示早期利益相关者需求的流行技术，但手动构建目标模型效率低下

Method: 采用文本蕴含技术，利用GPT-4o从访谈记录中自动提取目标，构建目标模型，并建立目标之间的精化关系

Result: 在15个访谈记录和29个应用领域的评估中，GPT-4o能够可靠地提取目标（62.0%匹配人工提取），准确溯源目标来源文本（98.7%），并生成目标模型精化关系（72.2%准确率）

Conclusion: 该方法展示了使用大型语言模型自动化需求获取和目标建模的可行性，能够显著提高软件工程中需求获取的效率

Abstract: In software engineering, requirements may be acquired from stakeholders
through elicitation methods, such as interviews, observational studies, and
focus groups. When supporting acquisition from interviews, business analysts
must review transcripts to identify and document requirements. Goal modeling is
a popular technique for representing early stakeholder requirements as it lends
itself to various analyses, including refinement to map high-level goals into
software operations, and conflict and obstacle analysis. In this paper, we
describe an approach to use textual entailment to reliably extract goals from
interview transcripts and to construct goal models. The approach has been
evaluated on 15 interview transcripts across 29 application domains. The
findings show that GPT-4o can reliably extract goals from interview
transcripts, matching 62.0% of goals acquired by humans from the same
transcripts, and that GPT-4o can trace goals to originating text in the
transcript with 98.7% accuracy. In addition, when evaluated by human
annotators, GPT-4o generates goal model refinement relationships among
extracted goals with 72.2% accuracy.

</details>


### [7] [A Survey on the Techniques and Tools for Automated Requirements Elicitation and Analysis of Mobile Apps](https://arxiv.org/abs/2509.01068)
*Chong Wang,Haoning Wu,Peng Liang,Maya Daneva,Marten van Sinderen*

Main category: cs.SE

TL;DR: 对73篇论文的系统性映射研究显示，移动应用自动化需求获取与分析主要使用半自动技术，最常用工具是开源非自研工具，主要支持需求分析、挖掘和分类三大任务


<details>
  <summary>Details</summary>
Motivation: 了解移动应用自动化需求获取与分析领域的技术工具特征及其支持的需求工程任务现状

Method: 采用Kitchenham等人的指南进行系统性映射研究，分析了73篇相关论文

Result: 发现最常用技术是半自动技术，主要工具特征为开源和非自研，主要用于需求分析和文本预处理，三大主要研究任务是需求分析、挖掘和分类

Conclusion: 该领域技术工具使用呈增长趋势，半自动技术占主导，需求分析/挖掘/分类是主要支持任务，开源非自研工具在需求分析和文本处理中最受欢迎

Abstract: [Background:] Research on automated requirements elicitation and analysis of
mobile apps employed lots of techniques and tools proposed by RE researchers
and practitioners. However, little is known about the characteristics of these
techniques and tools as well as the RE tasks in requirements elicitation and
analysis that got supported with the help of respective techniques and tools.
[Aims:] The goal of this paper is to investigate the state-of-the-art of the
techniques and tools used in automated requirements elicitation and analysis of
mobile apps. [Method:] We carried out a systematic mapping study by following
the guidelines of Kitchenham et al. [Results:] Based on 73 selected papers, we
found the most frequently used techniques - semi-automatic techniques, and the
main characteristics of the tools - open-sourced and non-self-developed tools
for requirements analysis and text pre-processing. Plus, the most three
investigated RE tasks are requirements analysis, mining and classification.
[Conclusions:] Our most important conclusions are: (1) there is a growth in the
use of techniques and tools in automated requirements elicitation and analysis
of mobile apps, (2) semi-automatic techniques are mainly used in the
publications on this research topic, (3) requirements analysis, mining and
classification are the top three RE tasks with the support of automatic
techniques and tools, and (4) the most popular tools are open-sourced and
non-self-developed, and they are mainly used in requirements analysis and text
processing.

</details>


### [8] [Compiler Bugs Detection in Logic Synthesis Tools via Linear Upper Confidence Bound](https://arxiv.org/abs/2509.01149)
*Hui Zeng,Zhihao Xu,Hui Li,Siwen Wang,Qian Ma*

Main category: cs.SE

TL;DR: Lin-Hunter是一个针对FPGA逻辑综合工具的测试框架，通过元形态变换规则生成结构多样化的HDL测试用例，并采用基于LinUCB的自适应策略选择机制来提高bug发现效率。


<details>
  <summary>Details</summary>
Motivation: 现有的FPGA逻辑综合工具测试方法过度依赖随机选择策略，导致生成的HDL测试用例结构多样性不足，无法充分探索工具的功能空间，存在未检测到的bug风险。

Method: 提出基于原则的元形态变换规则生成功能等效但结构多样的HDL测试用例变体；集成基于线性上置信界(LinUCB)的自适应策略选择机制，利用先前测试用例的综合日志反馈来动态优先选择更可能触发综合bug的变换策略。

Result: 在三个月的综合实验中发现了18个独特bug，其中10个是先前未报告的缺陷，已得到官方开发者确认；在测试用例多样性和bug发现效率方面均优于最先进的测试方法。

Conclusion: Lin-Hunter通过系统性地增强HDL测试用例的多样性和采用自适应策略选择，有效解决了FPGA逻辑综合工具验证中的测试输入多样性不足问题，显著提高了bug发现效率和工具可靠性。

Abstract: Field-Programmable Gate Arrays (FPGAs) play an indispensable role in
Electronic Design Automation (EDA), translating Register-Transfer Level (RTL)
designs into gate-level netlists. The correctness and reliability of FPGA logic
synthesis tools are critically important, as unnoticed bugs in these tools may
infect the final hardware implementations. However, recent approaches often
rely heavily on random selection strategies, limiting the structural diversity
of the generated HDL test cases and resulting in inadequate exploration of the
tool's feature space. To address this limitation, we propose Lin-Hunter, a
novel testing framework designed to systematically enhance the diversity of HDL
test cases and the efficiency of FPGA logic synthesis tool validation.
Specifically, Lin-Hunter introduces a principled set of metamorphic
transformation rules to generate functionally equivalent yet structurally
diverse HDL test case variants, effectively addressing the limited diversity of
existing test inputs. To further enhance bug discovery efficiency, Lin-Hunter
integrates an adaptive strategy selection mechanism based on the Linear Upper
Confidence Bound (LinUCB) method. This method leverages feedback from synthesis
logs of previously executed test cases to dynamically prioritize transformation
strategies that have empirically demonstrated a higher likelihood of triggering
synthesis bugs. Comprehensive experiments conducted over a three-month period
demonstrate the practical effectiveness of Lin-Hunter. Our method has
discovered 18 unique bugs, including 10 previously unreported defects, which
have been confirmed by official developers. Moreover, our method outperforms
state-of-the-art testing methods in both test-case diversity and bug-discovery
efficiency.

</details>


### [9] [Policy-driven Software Bill of Materials on GitHub: An Empirical Study](https://arxiv.org/abs/2509.01255)
*Oleksii Novikov,Davide Fucci,Oleksandr Adamov,Daniel Mendez*

Main category: cs.SE

TL;DR: 对开源项目中政策驱动的SBOM现状分析显示，仅有0.56%的流行GitHub仓库包含此类SBOM，存在大量漏洞且22%依赖项缺少许可证信息


<details>
  <summary>Details</summary>
Motivation: SBOM作为保障软件供应链安全的重要工具，尽管政府强制要求使用，但相关研究仍处于早期阶段，需要了解开源项目中政策驱动SBOM的实际应用状况

Method: 通过挖掘软件仓库研究，收集并筛选GitHub上托管的SBOM文件，使用描述性统计分析政策驱动SBOM中报告的信息及其依赖项的漏洞情况

Result: 仅0.56%的流行GitHub仓库包含政策驱动SBOM；声明的依赖项包含2,202个唯一漏洞；22%的依赖项未报告许可证信息

Conclusion: 研究结果为支持安全评估和许可证管理的SBOM使用提供了重要见解，揭示了当前SBOM实施的不足和改进空间

Abstract: Background. The Software Bill of Materials (SBOM) is a machine-readable list
of all the software dependencies included in a software. SBOM emerged as way to
assist securing the software supply chain. However, despite mandates from
governments to use SBOM, research on this artifact is still in its early
stages. Aims. We want to understand the current state of SBOM in open-source
projects, focusing specifically on policy-driven SBOMs, i.e., SBOM created to
achieve security goals, such as enhancing project transparency and ensuring
compliance, rather than being used as fixtures for tools or artificially
generated for benchmarking or academic research purposes. Method. We performed
a mining software repository study to collect and carefully select SBOM files
hosted on GitHub. We analyzed the information reported in policy-driven SBOMs
and the vulnerabilities associated with the declared dependencies by means of
descriptive statistics. Results. We show that only 0.56% of popular GitHub
repositories contain policy-driven SBOM. The declared dependencies contain
2,202 unique vulnerabilities, while 22% of them do not report licensing
information. Conclusion. Our findings provide insights for SBOM usage to
support security assessment and licensing.

</details>


### [10] [Metamorphic Testing of Multimodal Human Trajectory Prediction](https://arxiv.org/abs/2509.01294)
*Helge Spieker,Nadjib Lazaar,Arnaud Gotlieb,Nassim Belmecheri*

Main category: cs.SE

TL;DR: 该研究应用蜕变测试方法来测试多模态人类轨迹预测系统，通过设计5种蜕变关系来解决测试预言问题，包括几何变换和地图变换，使用概率距离度量来评估模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 多模态人类轨迹预测模型由于输入源多样（轨迹历史和环境地图）且输出随机（多条可能路径），缺乏明确的测试预言，难以进行严格测试。

Method: 提出5种蜕变关系：1）对轨迹和地图输入进行标签保持的几何变换（镜像、旋转、缩放）；2）地图变换（改变语义标签、引入障碍物）。使用Wasserstein或Hellinger距离等概率度量来定义违反标准。

Result: 开发了MT框架，能够在没有真实轨迹的情况下评估模型对输入变换和上下文变化的鲁棒性。

Conclusion: 蜕变测试为多模态随机人类轨迹预测系统的无预言测试提供了系统方法，有效解决了测试预言缺失问题。

Abstract: Context: Predicting human trajectories is crucial for the safety and
reliability of autonomous systems, such as automated vehicles and mobile
robots. However, rigorously testing the underlying multimodal Human Trajectory
Prediction (HTP) models, which typically use multiple input sources (e.g.,
trajectory history and environment maps) and produce stochastic outputs
(multiple possible future paths), presents significant challenges. The primary
difficulty lies in the absence of a definitive test oracle, as numerous future
trajectories might be plausible for any given scenario. Objectives: This
research presents the application of Metamorphic Testing (MT) as a systematic
methodology for testing multimodal HTP systems. We address the oracle problem
through metamorphic relations (MRs) adapted for the complexities and stochastic
nature of HTP. Methods: We present five MRs, targeting transformations of both
historical trajectory data and semantic segmentation maps used as an
environmental context. These MRs encompass: 1) label-preserving geometric
transformations (mirroring, rotation, rescaling) applied to both trajectory and
map inputs, where outputs are expected to transform correspondingly. 2)
Map-altering transformations (changing semantic class labels, introducing
obstacles) with predictable changes in trajectory distributions. We propose
probabilistic violation criteria based on distance metrics between probability
distributions, such as the Wasserstein or Hellinger distance. Conclusion: This
study introduces tool, a MT framework for the oracle-less testing of
multimodal, stochastic HTP systems. It allows for assessment of model
robustness against input transformations and contextual changes without
reliance on ground-truth trajectories.

</details>


### [11] [Aligning Requirement for Large Language Model's Code Generation](https://arxiv.org/abs/2509.01313)
*Zhao Tian,Junjie Chen*

Main category: cs.SE

TL;DR: Specine是一种基于软件需求工程的规范对齐技术，通过识别未对齐的输入规范、提升LLM感知的规范并进行对齐，来增强LLM代码生成的性能


<details>
  <summary>Details</summary>
Motivation: 现有基于代理的技术虽然提升了LLM代码生成能力，但忽视了规范感知这一关键问题，导致生成的代码与编程规范持续存在不对齐问题

Method: 借鉴软件需求工程技术，提出Specine方法，包括识别未对齐的输入规范、提升LLM感知的规范、以及对齐规范三个关键步骤

Result: 在四个最先进LLM和五个具有挑战性的竞争基准测试中，Specine在Pass@1指标上平均比最有效基线提升29.60%

Conclusion: Specine通过有效的规范对齐技术显著提升了LLM代码生成的准确性和与规范的匹配度

Abstract: Code generation refers to the automatic generation of source code based on a
given programming specification, which has garnered significant attention
particularly with the advancement of large language models (LLMs). However, due
to the inherent complexity of real-world problems, the LLM-generated code often
fails to fully align with the provided specification. While state-of-the-art
agent-based techniques have been proposed to enhance LLM code generation, they
overlook the critical issue of specification perception, resulting in
persistent misalignment issues. Given that accurate perception of programming
specifications serves as the foundation of the LLM-based code generation
paradigm, ensuring specification alignment is particularly crucial. In this
work, we draw on software requirements engineering to propose Specine, a novel
specification alignment technique for LLM code generation. Its key idea is to
identify misaligned input specifications, lift LLM-perceived specifications,
and align them to enhance the code generation performance of LLMs. Our
comprehensive experiments on four state-of-the-art LLMs across five challenging
competitive benchmarks by comparing with ten state-of-the-art baselines,
demonstrate the effectiveness of Specine. For example, Specine outperforms the
most effective baseline, achieving an average improvement of 29.60\% across all
subjects in terms of Pass@1.

</details>


### [12] [Leveraging SystemC-TLM-based Virtual Prototypes for Embedded Software Fuzzing](https://arxiv.org/abs/2509.01318)
*Chiara Ghinami,Jonas Winzer,Nils Bosbach,Lennart M. Reimann,Lukas Jünger,Simon Wörner,Rainer Leupers*

Main category: cs.SE

TL;DR: 提出了一个将AFL模糊测试与SystemC模拟器集成的框架，通过解耦和外围设备访问拦截来增强嵌入式软件的测试能力


<details>
  <summary>Details</summary>
Motivation: 现有解决方案通常将模糊测试工具与内置模拟器紧密耦合，缺乏硬件外围设备支持且灵活性有限，限制了嵌入式软件的测试能力

Method: 开发了一个框架，提供解耦适配器来分离模糊测试工具和模拟器，拦截外围设备访问并向模糊测试工具查询值，将外围设备行为与模糊测试连接起来

Result: 该解决方案实现了模拟环境中外围设备的灵活互换性，并支持不同SystemC虚拟原型的接口连接

Conclusion: 该框架通过集成不同模拟器和测试各种软件，展示了所提出解决方案的灵活性，有效解决了嵌入式软件模糊测试的局限性

Abstract: SystemC-based virtual prototypes have emerged as widely adopted tools to test
software ahead of hardware availability, reducing the time-to-market and
improving software reliability. Recently, fuzzing has become a popular method
for automated software testing due to its ability to quickly identify
corner-case errors. However, its application to embedded software is still
limited. Simulator tools can help bridge this gap by providing a more powerful
and controlled execution environment for testing. Existing solutions, however,
often tightly couple fuzzers with built-in simulators that lack support for
hardware peripherals and of- fer limited flexibility, restricting their ability
to test embedded software. To address these limitations, we present a framework
that allows the integration of American-Fuzzy-Lop-based fuzzers and
SystemC-based simulators. The framework provides a harness to decouple the
adopted fuzzer and simulator. In addition, it intercepts peripheral accesses
and queries the fuzzer for values, effectively linking peripheral behavior to
the fuzzer. This solution enables flexible interchangeability of peripher- als
within the simulation environment and supports the interfacing of different
SystemC-based virtual prototypes. The flexibility of the pro- posed solution is
demonstrated by integrating the harness with different simulators and by
testing various softwares.

</details>


### [13] [Towards Multi-Platform Mutation Testing of Task-based Chatbots](https://arxiv.org/abs/2509.01389)
*Diego Clerissi,Elena Masserini,Daniela Micucci,Leonardo Mariani*

Main category: cs.SE

TL;DR: MUTABOT是一个针对任务型聊天机器人的变异测试方法，通过注入对话故障来模拟缺陷，扩展支持Dialogflow和Rasa平台，实验显示能有效发现Botium测试套件的弱点


<details>
  <summary>Details</summary>
Motivation: 任务型聊天机器人测试困难，现有测试技术难以覆盖所有可能的对话场景，导致缺陷难以被发现

Method: 提出MUTABOT变异测试方法，在对话中注入故障来产生有缺陷的聊天机器人，扩展支持多个平台（Dialogflow和Rasa）

Result: 实验表明该方法能够有效揭示Botium最先进测试生成器生成的测试套件的弱点

Conclusion: 变异测试是评估任务型聊天机器人测试套件质量的有效方法，MUTABOT方法具有跨平台适用性

Abstract: Chatbots, also known as conversational agents, have become ubiquitous,
offering services for a multitude of domains. Unlike general-purpose chatbots,
task-based chatbots are software designed to prioritize the completion of tasks
of the domain they handle (e.g., flight booking). Given the growing popularity
of chatbots, testing techniques that can generate full conversations as test
cases have emerged. Still, thoroughly testing all the possible conversational
scenarios implemented by a task-based chatbot is challenging, resulting in
incorrect behaviors that may remain unnoticed. To address this challenge, we
proposed MUTABOT, a mutation testing approach for injecting faults in
conversations and producing faulty chatbots that emulate defects that may
affect the conversational aspects. In this paper, we present our extension of
MUTABOT to multiple platforms (Dialogflow and Rasa), and present experiments
that show how mutation testing can be used to reveal weaknesses in test suites
generated by the Botium state-of-the-art test generator.

</details>


### [14] [Non Technical Debt in Agile Software Development](https://arxiv.org/abs/2509.01445)
*Muhammad Ovais Ahmad,Tomas Gustavsson*

Main category: cs.SE

TL;DR: 非技术债务(NTD)是敏捷软件开发中的常见挑战，包括流程债务、社会债务、人员债务和组织债务四种形式。研究发现结构化团队、心理安全、清晰角色和有效流程对减少NTD至关重要。


<details>
  <summary>Details</summary>
Motivation: 研究非技术债务在大型敏捷软件开发环境中的影响，揭示各种债务类型如何破坏开发效率和组织效能，为解决这些挑战提供实证依据。

Method: 采用广泛的问卷调查、深度访谈和统计分析，涉及多样化的软件专业人员群体，识别NTD的关键驱动因素及其影响。

Result: 发现五个关键洞察：结构化团队学习更快；心理安全对创新至关重要；低效流程降低满意度；远程工作导致社会碎片化；人力资源不足限制组织能力。

Conclusion: 提出了基于证据的实用策略，包括优化团队组成、明确角色、培养心理安全、简化工作流程和将失败视为学习工具，帮助组织减少NTD并释放团队潜力。

Abstract: NonTechnical Debt (NTD) is a common challenge in agile software development,
manifesting in four critical forms, Process Debt, Social Debt, People Debt,
Organizational debt. NODLA project is a collaboration between Karlstad
University and four leading Swedish industrial partners, reveals how various
debt types disrupt large scale Agile Software Development (ASD) environments.
Through extensive surveys, indepth interviews, and statistical analyses
involving a diverse group of software professionals, we identified key drivers
of NTD and their impacts. Our findings emphasize (1) Well structured, highly
cohesive teams learn faster, adapt more effectively, and innovate consistently.
(2) Psychological safety, fostered by proactive leadership, is essential for
innovation, experimentation, and keeping employees. (3) Inefficient processes
and unclear roles contribute significantly to drops in job satisfaction,
productivity and team morale. (4) Social fragmentation, particularly in remote
and hybrid settings, breeds rework, delays, and increased costs. (5) Neglected
human resource needs, such as delayed hiring or insufficient training, limit an
organization ability to meet growing demands. This white paper distils these
insights into practical, evidence based strategies, such as refining team
composition, clarifying roles, fostering psychological safety, streamlining
workflows, and embracing failure as a learning tool. By implementing these
strategies, organizations can reduce NTD, reclaim agility, and unlock their
teams full potential.

</details>


### [15] [Benchmarking and Studying the LLM-based Code Review](https://arxiv.org/abs/2509.01494)
*Zhengran Zeng,Ruikai Shi,Keke Han,Yixin Li,Kaicheng Sun,Yidong Wang,Zhuohao Yu,Rui Xie,Wei Ye,Shikun Zhang*

Main category: cs.SE

TL;DR: 提出了SWRBench基准测试，包含1000个手动验证的GitHub Pull Requests，采用基于LLM的客观评估方法，发现当前ACR工具在功能错误检测方面表现更好，并提出多评审聚合策略显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有自动化代码评审基准测试无法反映真实世界复杂性，缺乏完整项目上下文，评估指标不足，阻碍了现代大型语言模型的评估。

Method: 引入SWRBench基准，包含1000个手动验证的PR，提供完整的项目上下文。采用基于LLM的客观评估方法，验证结构化真实问题是否在生成的评审中被覆盖。

Result: 当前ACR系统表现不佳，ACR工具更擅长检测功能错误。提出的多评审聚合策略将F1分数提升高达43.67%。

Conclusion: SWRBench基准、客观评估方法、当前ACR能力全面研究以及有效增强方法，为推进ACR研究提供了宝贵见解。

Abstract: Automated Code Review (ACR) is crucial for software quality, yet existing
benchmarks often fail to reflect real-world complexities, hindering the
evaluation of modern Large Language Models (LLMs). Current benchmarks
frequently focus on fine-grained code units, lack complete project context, and
use inadequate evaluation metrics. To address these limitations, we introduce
SWRBench , a new benchmark comprising 1000 manually verified Pull Requests
(PRs) from GitHub, offering PR-centric review with full project context.
SWRBench employs an objective LLM-based evaluation method that aligns strongly
with human judgment (~90 agreement) by verifying if issues from a structured
ground truth are covered in generated reviews. Our systematic evaluation of
mainstream ACR tools and LLMs on SWRBench reveals that current systems
underperform, and ACR tools are more adept at detecting functional errors.
Subsequently, we propose and validate a simple multi-review aggregation
strategy that significantly boosts ACR performance, increasing F1 scores by up
to 43.67%. Our contributions include the SWRBench benchmark, its objective
evaluation method, a comprehensive study of current ACR capabilities, and an
effective enhancement approach, offering valuable insights for advancing ACR
research.

</details>


### [16] [A Privacy-Preserving Recommender for Filling Web Forms Using a Local Large Language Model](https://arxiv.org/abs/2509.01527)
*Amirreza Nayyeri,Abbas Rasoolzadegan*

Main category: cs.SE

TL;DR: 本文提出了一种基于大语言模型的隐私保护推荐器，用于本地化生成网页表单测试的有效字段值，避免云端LLM带来的数据泄漏风险。


<details>
  <summary>Details</summary>
Motivation: 网络应用在重要领域的普及导致对故障自由性能的高要求。虽然LLM工具能智能生成表单测试值，但云端部署可能导致敏感数据泄漏和保密性问题。

Method: 开发了一个本地运行的隐私保护推荐器，通过分析表单HTML结构、检测输入类型并提取字段约束来生成适当的填写值。

Result: 该工具能够在不依赖云端服务的情况下，为测试人员提供有效的表单字段填写建议，确保测试过程中的数据安全性。

Conclusion: 通过本地化部署LLM模型，方案有效解决了保密性网页表单测试中的数据泄漏风险，为安全测试提供了可靠的技术支持。

Abstract: Web applications are increasingly used in critical domains such as education,
finance, and e-commerce. This highlights the need to ensure their failure-free
performance. One effective method for evaluating failure-free performance is
web form testing, where defining effective test scenarios is key to a complete
and accurate evaluation. A core aspect of this process involves filling form
fields with suitable values to create effective test cases. However, manually
generating these values is time-consuming and prone to errors. To address this,
various tools have been developed to assist testers. With the appearance of
large language models (LLMs), a new generation of tools seeks to handle this
task more intelligently. Although many LLM-based tools have been introduced, as
these models typically rely on cloud infrastructure, their use in testing
confidential web forms raises concerns about unintended data leakage and
breaches of confidentiality. This paper introduces a privacy-preserving
recommender that operates locally using a large language model. The tool
assists testers in web form testing by suggesting effective field values. This
tool analyzes the HTML structure of forms, detects input types, and extracts
constraints based on each field's type and contextual content, guiding proper
field filling.

</details>


### [17] [WFC/WFD: Web Fuzzing Commons, Dataset and Guidelines to Support Experimentation in REST API Fuzzing](https://arxiv.org/abs/2509.01612)
*Omur Sahin,Man Zhang,Andrea Arcuri*

Main category: cs.SE

TL;DR: 提出了Web Fuzzing Commons (WFC)和Web Fuzzing Dataset (WFD)来解决REST API模糊测试中的三个关键挑战：认证处理、故障分类和公平比较基准。


<details>
  <summary>Details</summary>
Motivation: 当前REST API模糊测试研究面临三个主要问题：如何处理API认证、如何分类和比较不同模糊测试工具发现的故障类型、以及如何建立公平的比较基准。这些问题阻碍了该领域的进一步发展。

Method: 开发了WFC（开源库和模式定义）用于声明式指定认证信息和分类故障类型，以及WFD（包含36个开源API的数据集）用于支持实验。通过EvoMaster等工具进行实验验证。

Result: WFC/WFD为API模糊测试提供了标准化框架和基准数据集，能够支持不同工具之间的公平比较，并避免了常见的比较陷阱。

Conclusion: WFC和WFD解决了REST API模糊测试领域的关键挑战，为研究人员提供了统一的认证处理、故障分类和基准测试框架，有助于推动该领域的进一步发展。

Abstract: Fuzzing REST APIs is an important research problem, with practical
applications and impact in industry. As such, a lot of research work has been
carried out on this topic in the last few years. However, there are three major
issues that hinder further progress: how to deal with API authentication; how
to catalog and compare different fault types found by different fuzzers; and
what to use as case study to facilitate fair comparisons among fuzzers. To
address these important challenges, we present Web Fuzzing Commons (WFC) and
Web Fuzzing Dataset (WFD). WFC is a set of open-source libraries and schema
definitions to declaratively specify authentication info and catalog different
types of faults that fuzzers can automatically detect. WFD is a collection of
36 open-source APIs with all necessary scaffolding to easily run experiments
with fuzzers, supported by WFC. To show the usefulness of WFC/WFD, a set of
experiments is carried out with EvoMaster, a state-of-the-art fuzzer for Web
APIs. However, any fuzzer can benefit from WFC and WFD. We compare EvoMaster
with other state-of-the-art tools such as ARAT-RL, EmRest, LLamaRestTest,
RESTler, and Schemathesis. We discuss common pitfalls in tool comparisons, as
well as providing guidelines with support of WFC/WFD to avoid them.

</details>


### [18] [Automated Generation of Issue-Reproducing Tests by Combining LLMs and Search-Based Testing](https://arxiv.org/abs/2509.01616)
*Konstantinos Kitsios,Marco Castelluccio,Alberto Bacchelli*

Main category: cs.SE

TL;DR: BLAST是一个结合LLM和基于搜索的软件测试(SBST)的工具，能够从issue-patch对自动生成问题重现测试，在基准测试中达到35.4%的成功率，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 开发者经常提交没有相应测试的补丁，使得问题重现测试的自动生成成为重要研究方向，以提高开发者对问题修复的信心并防止问题重新引入。

Method: 结合LLM和SBST技术：通过git历史分析、静态分析和SBST生成测试来提取相关上下文补充issue描述和补丁信息；将LLM生成的种子反序列化为SBST兼容形式进行优化。

Result: 在426个Python问题中成功生成151个(35.4%)问题重现测试，优于最先进技术的23.5%；在真实GitHub部署中，32个PR-issue对中有11个成功生成测试。

Conclusion: BLAST证明了结合LLM和SBST在自动生成问题重现测试方面的有效性，为研究者和工具开发者提供了有价值的见解和机会。

Abstract: Issue-reproducing tests fail on buggy code and pass once a patch is applied,
thus increasing developers' confidence that the issue has been resolved and
will not be re-introduced. However, past research has shown that developers
often commit patches without such tests, making the automated generation of
issue-reproducing tests an area of interest. We propose BLAST, a tool for
automatically generating issue-reproducing tests from issue-patch pairs by
combining LLMs and search-based software testing (SBST). For the LLM part, we
complement the issue description and the patch by extracting relevant context
through git history analysis, static analysis, and SBST-generated tests. For
the SBST part, we adapt SBST for generating issue-reproducing tests; the issue
description and the patch are fed into the SBST optimization through an
intermediate LLM-generated seed, which we deserialize into SBST-compatible
form. BLAST successfully generates issue-reproducing tests for 151/426 (35.4%)
of the issues from a curated Python benchmark, outperforming the
state-of-the-art (23.5%). Additionally, to measure the real-world impact of
BLAST, we built a GitHub bot that runs BLAST whenever a new pull request (PR)
linked to an issue is opened, and if BLAST generates an issue-reproducing test,
the bot proposes it as a comment in the PR. We deployed the bot in three
open-source repositories for three months, gathering data from 32 PRs-issue
pairs. BLAST generated an issue-reproducing test in 11 of these cases, which we
proposed to the developers. By analyzing the developers' feedback, we discuss
challenges and opportunities for researchers and tool builders. Data and
material: https://doi.org/10.5281/zenodo.16949042

</details>


### [19] [Tether: A Personalized Support Assistant for Software Engineers with ADHD](https://arxiv.org/abs/2509.01946)
*Aarsh Shah,Cleyton Magalhaes,Kiev Gama,Ronnie de Souza Santos*

Main category: cs.SE

TL;DR: Tether是一个基于LLM的桌面应用，专门为患有ADHD的软件工程师设计，通过实时活动监控、RAG技术和游戏化元素提供个性化的注意力支持和对话帮助。


<details>
  <summary>Details</summary>
Motivation: 当前软件工程领域的公平性、多样性和包容性往往忽视神经多样性，特别是ADHD开发者的体验。尽管对该群体的认识在增加，但很少有工具专门支持他们在开发工作流程中的认知挑战。

Method: 结合本地活动监控、检索增强生成(RAG)和游戏化技术，开发了一个LLM驱动的桌面应用。系统集成操作系统级别的系统跟踪来提示参与度，聊天机器人利用ADHD特定资源提供相关响应。

Result: 通过自我使用的初步验证显示，经过迭代提示优化和RAG增强后，上下文准确性得到改善。工具在软件特定工作流程和ADHD相关挑战方面表现出适应性。

Conclusion: Tether与通用工具不同，具有适应性和针对性，为未来神经多样性感知工具在软件工程中的应用奠定了基础，突显了LLM作为个性化支持系统满足 underrepresented 认知需求的潜力。

Abstract: Equity, diversity, and inclusion in software engineering often overlook
neurodiversity, particularly the experiences of developers with Attention
Deficit Hyperactivity Disorder (ADHD). Despite the growing awareness about that
population in SE, few tools are designed to support their cognitive challenges
(e.g., sustained attention, task initiation, self-regulation) within
development workflows. We present Tether, an LLM-powered desktop application
designed to support software engineers with ADHD by delivering adaptive,
context-aware assistance. Drawing from engineering research methodology, Tether
combines local activity monitoring, retrieval-augmented generation (RAG), and
gamification to offer real-time focus support and personalized dialogue. The
system integrates operating system level system tracking to prompt engagement
and its chatbot leverages ADHD-specific resources to offer relevant responses.
Preliminary validation through self-use revealed improved contextual accuracy
following iterative prompt refinements and RAG enhancements. Tether
differentiates itself from generic tools by being adaptable and aligned with
software-specific workflows and ADHD-related challenges. While not yet
evaluated by target users, this work lays the foundation for future
neurodiversity-aware tools in SE and highlights the potential of LLMs as
personalized support systems for underrepresented cognitive needs.

</details>


### [20] [Automated Repair of C Programs Using Large Language Models](https://arxiv.org/abs/2509.01947)
*Mahdi Farzandway,Fatemeh Ghassemi*

Main category: cs.SE

TL;DR: 提出了一种结合频谱故障定位、运行时反馈和思维链提示的LLM自主修复框架，在Codeflaws基准的3902个bug上达到44.93%修复准确率，比GPT-4+CoT基线提升3.61%


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在自动化C程序修复中的潜力，将统计程序分析与LLM推理相结合，提供更有效的自动程序修复方案

Method: 集成频谱故障定位(SBFL)、运行时反馈和结构化思维链提示的迭代修复循环，模型基于失败测试、可疑代码区域和先前补丁结果进行推理，生成新候选补丁

Result: 在Codeflaws基准的3902个bug上实现44.93%的修复准确率，相比最先进的GPT-4+CoT基线方法绝对提升3.61%

Conclusion: 该方法为统计程序分析与生成式AI在自动化调试中的集成提供了实用路径，通过迭代推理和反馈机制显著提升了程序修复效果

Abstract: This study explores the potential of Large Language Models (LLMs) in
automating the repair of C programs. We present a framework that integrates
spectrum-based fault localization (SBFL), runtime feedback, and
Chain-of-Thought-structured prompting into an autonomous repair loop. Unlike
prior approaches, our method explicitly combines statistical program analysis
with LLM reasoning. The iterative repair cycle leverages a structured
Chain-of-Thought (CoT) prompting approach, where the model reasons over failing
tests, suspicious code regions, and prior patch outcomes, before generating new
candidate patches. The model iteratively changes the code, evaluates the
results, and incorporates reasoning from previous attempts into subsequent
modifications, reducing repeated errors and clarifying why some bugs remain
unresolved. Our evaluation spans 3,902 bugs from the Codeflaws benchmark, where
our approach achieves 44.93% repair accuracy, representing a 3.61% absolute
improvement over strong state-of-the-art APR baselines such as GPT-4 with CoT.
This outcome highlights a practical pathway toward integrating statistical
program analysis with generative AI in automated debugging.

</details>


### [21] [ProbTest: Unit Testing for Probabilistic Programs (Extended Version)](https://arxiv.org/abs/2509.02012)
*Katrine Christensen,Mahsa Varshosaz,Raúl Pardo*

Main category: cs.SE

TL;DR: ProbTest：基于优惠券收集问题理论的概率程序黑盒单元测试方法，可自动确定测试执行次数并提供统计保证


<details>
  <summary>Details</summary>
Motivation: 概率程序的随机性使得测试变得困难，需要多次执行来验证期望结果，但如何确定合适的执行次数是一个挑战

Method: 基于优惠券收集问题理论的黑盒单元测试方法，开发人员可以像往常一样编写单元测试，系统自动确定所需的测试执行次数

Result: 实现了PyTest插件，在Gymnasium强化学习库和随机化数据结构案例研究中进行了评估

Conclusion: ProbTest为概率程序测试提供了一种有效的解决方案，开发人员无需额外努力即可获得统计保证的测试结果

Abstract: Testing probabilistic programs is non-trivial due to their stochastic nature.
Given an input, the program may produce different outcomes depending on the
underlying stochastic choices in the program. This means testing the expected
outcomes of probabilistic programs requires repeated test executions unlike
deterministic programs where a single execution may suffice for each test
input. This raises the following question: how many times should we run a
probabilistic program to effectively test it? This work proposes a novel
black-box unit testing method, ProbTest, for testing the outcomes of
probabilistic programs. Our method is founded on the theory surrounding a
well-known combinatorial problem, the coupon collector's problem. Using this
method, developers can write unit tests as usual without extra effort while the
number of required test executions is determined automatically with statistical
guarantees for the results. We implement ProbTest as a plug-in for PyTest, a
well-known unit testing tool for python programs. Using this plug-in,
developers can write unit tests similar to any other Python program and the
necessary test executions are handled automatically. We evaluate the method on
case studies from the Gymnasium reinforcement learning library and a randomized
data structure.

</details>


### [22] [Scalable Thread-Safety Analysis of Java Classes with CodeQL](https://arxiv.org/abs/2509.02022)
*Bjørnar Haugstad Jåtten,Simon Boye Jørgensen,Rasmus Petersen,Raúl Pardo*

Main category: cs.SE

TL;DR: 这篇论文提出了一种高可扩展的静态分析方法，使用CodeQL工具自动检测Java类的线程安全性问题，在大规模实际代码库中发现了数千个并发错误。


<details>
  <summary>Details</summary>
Motivation: 在面向对象语言中，开发人员依赖线程安全类来实现并发应用，但判断一个类是否线程安全是一项具有挑战性的任务。

Method: 基于Java内存模型的数据竞争自由原则，设计了一组确保线程安全性的属性，并在CodeQL静态分析工具中编码这些属性来自动分析Java源代码。

Result: 在GitHub前1000个库的3632865个Java类中识别出数千个线程安全性错误。分析时间在20万行代码以内的库中仅需不到2分钟。开发者对提交的并发错误PR反馈积极。

Conclusion: 该方法在真实代码库中表现出良好的适用性和可扩展性，已提交到CodeQL主库并将成为GitHub Actions的一部分。

Abstract: In object-oriented languages software developers rely on thread-safe classes
to implement concurrent applications. However, determining whether a class is
thread-safe is a challenging task. This paper presents a highly scalable method
to analyze thread-safety in Java classes. We provide a definition of
thread-safety for Java classes founded on the correctness principle of the Java
memory model, data race freedom. We devise a set of properties for Java classes
that are proven to ensure thread-safety. We encode these properties in the
static analysis tool CodeQL to automatically analyze Java source code. We
perform an evaluation on the top 1000 GitHub repositories. The evaluation
comprises 3632865 Java classes; with 1992 classes annotated as @ThreadSafe from
71 repositories. These repositories include highly popular software such as
Apache Flink (24.6k stars), Facebook Fresco (17.1k stars), PrestoDB (16.2k
starts), and gRPC (11.6k starts). Our queries detected thousands of
thread-safety errors. The running time of our queries is below 2 minutes for
repositories up to 200k lines of code, 20k methods, 6000 fields, and 1200
classes. We have submitted a selection of detected concurrency errors as PRs,
and developers positively reacted to these PRs. We have submitted our CodeQL
queries to the main CodeQL repository, and they are currently in the process of
becoming available as part of GitHub actions. The results demonstrate the
applicability and scalability of our method to analyze thread-safety in
real-world code bases.

</details>


### [23] [Curiosity-Driven Testing for Sequential Decision-Making Process](https://arxiv.org/abs/2509.02025)
*Junda He,Zhou Yang,Jieke Shi,Chengran Yang,Kisub Kim,Bowen Xu,Xin Zhou,David Lo*

Main category: cs.SE

TL;DR: CureFuzz是一种基于好奇心的黑盒模糊测试方法，用于发现序列决策模型中的崩溃触发场景，通过多目标种子选择平衡新颖场景探索和崩溃场景生成。


<details>
  <summary>Details</summary>
Motivation: 序列决策模型在安全关键应用中容易学习不安全行为，但现有的测试框架难以发现多样化的崩溃触发场景，需要新的测试方法来提高模型安全性。

Method: 提出好奇心驱动机制探索新颖多样的场景，采用多目标种子选择技术平衡探索和崩溃场景生成，优化模糊测试过程。

Result: CureFuzz在故障总数和崩溃触发场景类型多样性方面显著优于现有最优方法，发现的崩溃场景可用于修复模型。

Conclusion: CureFuzz是测试序列决策模型和优化其性能的有效工具，能够提高模型在安全关键应用中的可靠性。

Abstract: Sequential decision-making processes (SDPs) are fundamental for complex
real-world challenges, such as autonomous driving, robotic control, and traffic
management. While recent advances in Deep Learning (DL) have led to mature
solutions for solving these complex problems, SDMs remain vulnerable to
learning unsafe behaviors, posing significant risks in safety-critical
applications. However, developing a testing framework for SDMs that can
identify a diverse set of crash-triggering scenarios remains an open challenge.
To address this, we propose CureFuzz, a novel curiosity-driven black-box fuzz
testing approach for SDMs. CureFuzz proposes a curiosity mechanism that allows
a fuzzer to effectively explore novel and diverse scenarios, leading to
improved detection of crashtriggering scenarios. Additionally, we introduce a
multi-objective seed selection technique to balance the exploration of novel
scenarios and the generation of crash-triggering scenarios, thereby optimizing
the fuzzing process. We evaluate CureFuzz on various SDMs and experimental
results demonstrate that CureFuzz outperforms the state-of-the-art method by a
substantial margin in the total number of faults and distinct types of
crash-triggering scenarios. We also demonstrate that the crash-triggering
scenarios found by CureFuzz can repair SDMs, highlighting CureFuzz as a
valuable tool for testing SDMs and optimizing their performance.

</details>


### [24] [Txt2Sce: Scenario Generation for Autonomous Driving System Testing Based on Textual Reports](https://arxiv.org/abs/2509.02150)
*Pin Ji,Yang Feng,Zongtai Li,Xiangchi Zhou,Jia Liu,Jun Sun,Zhihong Zhao*

Main category: cs.SE

TL;DR: Txt2Sce是一个基于文本事故报告生成OpenSCENARIO格式测试场景的方法，通过LLM转换、场景解构、变异和重组来增强场景多样性，有效检测自动驾驶系统的异常行为。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉数据的场景生成方法需要大量内存和人工标注，且缺乏标准化格式导致可扩展性和可移植性受限。真实事故报告提供了有价值的高风险场景，但需要更有效的方法来利用这些文本信息。

Method: 使用LLM将文本事故报告转换为OpenSCENARIO文件，通过场景解构、场景块变异和场景重组生成基于推导的场景文件树，利用节点间的推导关系识别触发ADS异常行为的场景条件。

Result: 成功生成33个场景文件树，共4,373个场景文件用于测试Autoware。实验表明Txt2Sce能有效转换文本报告为有效OpenSCENARIO文件，通过变异增强场景多样性，在安全性、智能性和平滑性方面成功检测到Autoware的异常行为。

Conclusion: Txt2Sce提供了一种有效的方法来利用文本事故报告生成标准化测试场景，解决了现有方法的局限性，为自动驾驶系统的可靠性测试提供了有价值的工具。

Abstract: With the rapid advancement of deep learning and related technologies,
Autonomous Driving Systems (ADSs) have made significant progress and are
gradually being widely applied in safety-critical fields. However, numerous
accident reports show that ADSs still encounter challenges in complex
scenarios. As a result, scenario-based testing has become essential for
identifying defects and ensuring reliable performance. In particular,
real-world accident reports offer valuable high-risk scenarios for more
targeted ADS testing. Despite their potential, existing methods often rely on
visual data, which demands large memory and manual annotation. Additionally,
since existing methods do not adopt standardized scenario formats (e.g.,
OpenSCENARIO), the generated scenarios are often tied to specific platforms and
ADS implementations, limiting their scalability and portability. To address
these challenges, we propose Txt2Sce, a method for generating test scenarios in
OpenSCENARIO format based on textual accident reports. Txt2Sce first uses a LLM
to convert textual accident reports into corresponding OpenSCENARIO scenario
files. It then generates a derivation-based scenario file tree through scenario
disassembly, scenario block mutation, and scenario assembly. By utilizing the
derivation relationships between nodes in the scenario tree, Txt2Sce helps
developers identify the scenario conditions that trigger unexpected behaviors
of ADSs. In the experiments, we employ Txt2Sce to generate 33 scenario file
trees, resulting in a total of 4,373 scenario files for testing the open-source
ADS, Autoware. The experimental results show that Txt2Sce successfully converts
textual reports into valid OpenSCENARIO files, enhances scenario diversity
through mutation, and effectively detects unexpected behaviors of Autoware in
terms of safety, smartness, and smoothness.

</details>


### [25] [Formalizing Operational Design Domains with the Pkl Language](https://arxiv.org/abs/2509.02221)
*Martin Skoglund,Fredrik Warg,Anders Thorsén,Sasikumar Punnekkat,Hans Hansson*

Main category: cs.SE

TL;DR: 本文提出使用Pkl语言形式化操作设计域(ODD)规范的方法，解决ODD规范化的核心挑战，提高可用性并通过汽车案例进行说明


<details>
  <summary>Details</summary>
Motivation: 随着自动化功能部署的增加，需要新的安全评估框架来证明这些功能在真实条件下不会带来不可接受的风险，而ODD的形式化是其中的关键挑战

Method: 使用Pkl配置语言来形式化ODD规范，利用其专门的语言特性来保持规范格式的灵活性、一致性和可追溯性

Result: 开发了一种能够无缝集成到开发、验证和评估过程中的ODD形式化方法，并通过汽车领域的实例进行了验证

Conclusion: 该方法不仅适用于汽车领域，还可广泛应用于确保操作环境的严格评估，为自动化系统的安全论证提供了重要支撑

Abstract: The deployment of automated functions that can operate without direct human
supervision has changed safety evaluation in domains seeking higher levels of
automation. Unlike conventional systems that rely on human operators, these
functions require new assessment frameworks to demonstrate that they do not
introduce unacceptable risks under real-world conditions. To make a convincing
safety claim, the developer must present a thorough justification argument,
supported by evidence, that a function is free from unreasonable risk when
operated in its intended context. The key concept relevant to the presented
work is the intended context, often captured by an Operational Design Domain
specification (ODD). ODD formalization is challenging due to the need to
maintain flexibility in adopting diverse specification formats while preserving
consistency and traceability and integrating seamlessly into the development,
validation, and assessment. This paper presents a way to formalize an ODD in
the Pkl language, addressing central challenges in specifying ODDs while
improving usability through specialized configuration language features. The
approach is illustrated with an automotive example but can be broadly applied
to ensure rigorous assessments of operational contexts.

</details>


### [26] [Methodology for Test Case Allocation based on a Formalized ODD](https://arxiv.org/abs/2509.02311)
*Martin Skoglund,Fredrik Warg,Anders Thoren,Sasikumar Punnekkat,Hans Hansson*

Main category: cs.SE

TL;DR: 提出了一种基于ODD形式化的测试用例分配评估方法，通过扩展测试属性来评估不同测试环境对自动驾驶功能的适用性，并以自动倒车卡车功能为例进行验证


<details>
  <summary>Details</summary>
Motivation: 随着CCAM系统的发展，传统安全评估方法已无法满足需求，需要新的方法来评估多测试环境中的场景覆盖和测试能力匹配问题

Method: 扩展现有的ODD形式化框架，整合ODD参数和测试属性，建立能够捕捉测试环境关键能力的结构，支持自动化适用性评估

Result: 开发了一个能够自动评估测试用例分配适用性的系统，通过案例研究验证了该方法在自动倒车卡车功能上的有效性

Conclusion: 该方法成功解决了多测试环境能力与需求对齐的挑战，为自动驾驶系统的类型认证和安全评估提供了有效的测试用例分配框架

Abstract: The emergence of Connected, Cooperative, and Automated Mobility (CCAM)
systems has significantly transformed the safety assessment landscape. Because
they integrate automated vehicle functions beyond those managed by a human
driver, new methods are required to evaluate their safety. Approaches that
compile evidence from multiple test environments have been proposed for
type-approval and similar evaluations, emphasizing scenario coverage within the
systems Operational Design Domain (ODD). However, aligning diverse test
environment requirements with distinct testing capabilities remains
challenging. This paper presents a method for evaluating the suitability of
test case allocation to various test environments by drawing on and extending
an existing ODD formalization with key testing attributes. The resulting
construct integrates ODD parameters and additional test attributes to capture a
given test environments relevant capabilities. This approach supports automatic
suitability evaluation and is demonstrated through a case study on an automated
reversing truck function. The system's implementation fidelity is tied to ODD
parameters, facilitating automated test case allocation based on each
environments capacity for object-detection sensor assessment.

</details>


### [27] [ReCode: Improving LLM-based Code Repair with Fine-Grained Retrieval-Augmented Generation](https://arxiv.org/abs/2509.02330)
*Yicong Zhao,Shisong Chen,Jiacheng Zhang,Zhixu Li*

Main category: cs.SE

TL;DR: ReCode是一个细粒度检索增强的上下文学习框架，通过算法感知检索和模块化双编码器架构，实现了高效准确的代码修复，显著降低了推理成本。


<details>
  <summary>Details</summary>
Motivation: 现有代码修复方法存在高训练成本或昂贵推理的问题，传统检索策略无法捕捉代码结构细节，导致检索质量不佳。

Method: 提出算法感知检索策略缩小搜索空间，采用模块化双编码器架构分别处理代码和文本输入，实现细粒度语义匹配。

Result: 在RACodeBench和竞争性编程数据集上实验表明，ReCode实现了更高的修复准确率，同时显著降低了推理成本。

Conclusion: ReCode框架为现实世界代码修复场景提供了实用价值，展示了检索增强生成在代码相关任务中的优势。

Abstract: Recent advances in large language models (LLMs) have demonstrated impressive
capabilities in code-related tasks, such as code generation and automated
program repair. Despite their promising performance, most existing approaches
for code repair suffer from high training costs or computationally expensive
inference. Retrieval-augmented generation (RAG), with its efficient in-context
learning paradigm, offers a more scalable alternative. However, conventional
retrieval strategies, which are often based on holistic code-text embeddings,
fail to capture the structural intricacies of code, resulting in suboptimal
retrieval quality. To address the above limitations, we propose ReCode, a
fine-grained retrieval-augmented in-context learning framework designed for
accurate and efficient code repair. Specifically, ReCode introduces two key
innovations: (1) an algorithm-aware retrieval strategy that narrows the search
space using preliminary algorithm type predictions; and (2) a modular
dual-encoder architecture that separately processes code and textual inputs,
enabling fine-grained semantic matching between input and retrieved contexts.
Furthermore, we propose RACodeBench, a new benchmark constructed from
real-world user-submitted buggy code, which addresses the limitations of
synthetic benchmarks and supports realistic evaluation. Experimental results on
RACodeBench and competitive programming datasets demonstrate that ReCode
achieves higher repair accuracy with significantly reduced inference cost,
highlighting its practical value for real-world code repair scenarios.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [28] [Per-sender neural network classifiers for email authorship validation](https://arxiv.org/abs/2509.00005)
*Rohit Dube*

Main category: cs.CR

TL;DR: 论文提出作者身份验证方法，通过分析发件人写作风格来检测伪造的内部邮件，使用Char-CNN模型在模拟数据集上取得高准确率，证明该方法可实用部署到现有邮件安全系统中。


<details>
  <summary>Details</summary>
Motivation: 企业面临内部邮件攻击威胁，传统防御主要针对外部钓鱼邮件，但对内部已泄露账户发送的伪造邮件缺乏有效检测手段。

Method: 提出作者身份验证概念，使用朴素贝叶斯和字符级卷积神经网络(Char-CNN)两种分类器，基于Enron语料库构建包含人工编写和LLM生成伪造邮件的模拟数据集。

Result: Char-CNN模型在各种情况下都取得了高准确率和F1分数，表现优于朴素贝叶斯模型。

Conclusion: 基于发件人写作风格的身份验证是轻量级实时防御方案，可有效补充传统检测方法，且易于集成到现有商业邮件安全系统中。

Abstract: Business email compromise and lateral spear phishing attacks are among modern
organizations' most costly and damaging threats. While inbound phishing
defenses have improved significantly, most organizations still trust internal
emails by default, leaving themselves vulnerable to attacks from compromised
employee accounts. In this work, we define and explore the problem of
authorship validation: verifying whether a claimed sender actually authored a
given email. Authorship validation is a lightweight, real-time defense that
complements traditional detection methods by modeling per-sender writing style.
Further, the paper presents a collection of new datasets based on the Enron
corpus. These simulate inauthentic messages using both human-written and large
language model-generated emails. The paper also evaluates two classifiers -- a
Naive Bayes model and a character-level convolutional neural network (Char-CNN)
-- for the authorship validation task. Our experiments show that the Char-CNN
model achieves high accuracy and F1 scores under various circumstances.
Finally, we discuss deployment considerations and show that per-sender
authorship classifiers are practical for integrating into existing commercial
email security systems with low overhead.

</details>


### [29] [Case Studies: Effective Approaches for Navigating Cross-Border Cloud Data Transfers Amid U.S. Government Privacy and Safety Concerns](https://arxiv.org/abs/2509.00006)
*Motunrayo Adebayo*

Main category: cs.CR

TL;DR: 本文研究云计算技术对国际信息交换的影响，分析法律和技术挑战，并提出安全信息交换的措施建议


<details>
  <summary>Details</summary>
Motivation: 随着云计算技术的出现，国家间自由信息交换的可能性迅速增加，但现有法律框架存在漏洞，可能阻碍云存储信息的自由访问并危及数据隐私，需要研究安全的信息交换措施

Method: 分析云计算技术对国际信息交换的影响，识别法律和技术层面的挑战，研究各国现有框架的漏洞，提出促进安全信息交换的措施建议

Result: 研究发现云计算技术显著促进了国际信息交换，但各国法律框架存在不一致性和漏洞，需要协调统一的法律标准和技术保障措施

Conclusion: 需要制定协调的国际法律框架和技术标准，以确保云计算环境下的信息安全交换，同时平衡信息自由访问和数据隐私保护的需求

Abstract: This study attempts to explain the impact of information exchange from one
country to another, as well as the legal and technological implications for
these exchanges. Due to the emergence of cloud technology, possibilities for
free exchange of information between countries have increased rapidly, as it
has become possible to save information in a country and access it in almost
any part of the world. Countries all around the world have been confronted with
developing frameworks to facilitate this process, although there are
significant challenges which must be confronted on legal and technological
fronts, as loopholes in the framework adopted by countries may hinder free
access to information stored on cloud, and also compromise data privacy. Cloud
technology is impacting a lot of issues, including domestic and international
businesses, hence the need for a study to propose measures for safe exchange of
information using cloud technology.

</details>


### [30] [Keystroke Detection by Exploiting Unintended RF Emission from Repaired USB Keyboards](https://arxiv.org/abs/2509.00043)
*Md Faizul Bari,Yi Xie,Meghna Roy Choudhury,Shreyas Sen*

Main category: cs.CR

TL;DR: 通过修复的USB线缆形成的微型单极天线可以在12米远距离上捕获键盘键入信息，突破了以往对电磁漏泉短距离传输的认识


<details>
  <summary>Details</summary>
Motivation: 以往认为电子设备的电磁漏泉信号弱、传输距离短，但研究发现线缆修复过程会形成天线效应，导致长距离数据泄漏风险

Method: 在3种不同环境中收集70种键入数据，开发高效检测算法，研窋干扰和人体耦合效应，并探索外部金属屏蔽作为防范措施

Result: 在远距离12米处达到约100%的键入检测准确率，是USB键盘在这种距离上的最高准确率记录

Conclusion: 该研究曝露了硬件修改导致的新攻击面，证明修复线缆可能造成长距离数据泄漏，并提出了金属屏蔽等防范方案

Abstract: Electronic devices and cables inadvertently emit RF emissions as a byproduct
of signal processing and/or transmission. Labeled as electromagnetic
emanations, they form an EM side-channel for data leakage. Previously, it was
believed that such leakage could be contained within a facility since they are
weak signals with a short transmission range. However, in the preliminary
version of this work [1], we found that the traditional cable repairing process
forms a tiny monopole antenna that helps emanations transmit over a long range.
Experimentation with three types of cables revealed that emanations from
repaired cables remain detectable even at >4 m and can penetrate a 14 cm thick
concrete wall. In this extended version, we show that such emanation can be
exploited at a long distance for information extraction by detecting keystrokes
typed on a repaired USB keyboard. By collecting data for 70 different
keystrokes at different distances from the target in 3 diverse environments
(open space, a corridor outside an office room, and outside a building) and
developing an efficient detection algorithm, ~100% keystroke detection accuracy
has been achieved up to 12 m distance, which is the highest reported accuracy
at such a long range for USB keyboards in the literature. The effect of two
experimental factors, interference and human-body coupling, has been
investigated thoroughly. Along with exploring the vulnerability, multi-layer
external metal shielding during the repairing process as a possible remedy has
been explored. This work exposes a new attack surface caused by hardware
modification, its exploitation, and potential countermeasures.

</details>


### [31] [Cryptographic Challenges: Masking Sensitive Data in Cyber Crimes through ASCII Art](https://arxiv.org/abs/2509.00059)
*Andres Alejandre,Kassandra Delfin,Victor Castano*

Main category: cs.CR

TL;DR: ASCII艺术作为一种新颖的敏感信息掩码技术，在网络安全领域具有应用潜力，能够通过其简单性和模糊性有效对抗网络犯罪。


<details>
  <summary>Details</summary>
Motivation: 研究ASCII艺术在保护个人数据方面的潜在作用，特别是在数据传输过程中，探讨其在网络安全中的独特价值。

Method: 通过分析ASCII艺术的独特属性和历史背景，研究其在各种网络犯罪场景中的应用优势和局限性。

Result: 研究发现ASCII艺术凭借其简单性和模糊性，可以作为对抗网络犯罪的有效工具。

Conclusion: 需要加强数据安全措施和提高隐私意识，ASCII艺术技术为网络安全提供了新的防护思路。

Abstract: The use of ASCII art as a novel approach to masking sensitive information in
cybercrime, focusing on its potential role in protecting personal data during
the delivery process and beyond, is presented. By examining the unique
properties of ASCII art and its historical context, this study discusses the
advantages and limitations of employing this technique in various cybercrime
scenarios. Additionally, providing recommendations for enhancing data security
practices and fostering a culture of privacy awareness in both businesses and
individuals. The findings suggest that ASCII art, with its simplicity and
ambiguity, can serve as an effective tool against cybercriminals, emphasizing
the need for robust data security measures and increased privacy awareness in
today's interconnected world.

</details>


### [32] [Enabling Transparent Cyber Threat Intelligence Combining Large Language Models and Domain Ontologies](https://arxiv.org/abs/2509.00081)
*Luca Cotti,Anisa Rula,Devis Bianchini,Federico Cerutti*

Main category: cs.CR

TL;DR: 提出了一种结合本体论和大型语言模型的新方法，用于从网络安全日志中提取结构化威胁情报信息，提高准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前方法在处理非结构化和模糊日志条目时难以可靠地识别和解释恶意事件，需要更准确和透明的信息提取方法。

Method: 整合领域本体和SHACL约束来指导语言模型输出结构，确保语义有效性，并将提取信息组织成语义图数据库。

Result: 相比传统提示方法，该方法在信息提取准确性方面表现更优，特别关注提取质量而非处理速度。

Conclusion: 该方法为网络安全日志分析提供了更准确、可解释的结构化信息提取方案，适用于蜜罐日志等恶意活动分析场景。

Abstract: Effective Cyber Threat Intelligence (CTI) relies upon accurately structured
and semantically enriched information extracted from cybersecurity system logs.
However, current methodologies often struggle to identify and interpret
malicious events reliably and transparently, particularly in cases involving
unstructured or ambiguous log entries. In this work, we propose a novel
methodology that combines ontology-driven structured outputs with Large
Language Models (LLMs), to build an Artificial Intelligence (AI) agent that
improves the accuracy and explainability of information extraction from
cybersecurity logs. Central to our approach is the integration of domain
ontologies and SHACL-based constraints to guide the language model's output
structure and enforce semantic validity over the resulting graph. Extracted
information is organized into an ontology-enriched graph database, enabling
future semantic analysis and querying. The design of our methodology is
motivated by the analytical requirements associated with honeypot log data,
which typically comprises predominantly malicious activity. While our case
study illustrates the relevance of this scenario, the experimental evaluation
is conducted using publicly available datasets. Results demonstrate that our
method achieves higher accuracy in information extraction compared to
traditional prompt-only approaches, with a deliberate focus on extraction
quality rather than processing speed.

</details>


### [33] [Private, Verifiable, and Auditable AI Systems](https://arxiv.org/abs/2509.00085)
*Tobin South*

Main category: cs.CR

TL;DR: 该论文提出了一个结合隐私保护、可验证性和可审计性的技术框架，使用零知识证明、安全多方计算和可信执行环境等技术来解决AI系统中的安全挑战。


<details>
  <summary>Details</summary>
Motivation: 随着社会对人工智能的依赖日益增长，需要确保AI系统的安全性、问责制和可信度，特别是在基础模型中的隐私、可验证性和可审计性之间的复杂关系。

Method: 采用零知识密码学实现AI系统的可验证声明，利用安全多方计算和可信执行环境进行大型语言模型的可审计机密部署，并通过增强的委托机制、凭证系统和访问控制来保护自主和多智能体AI系统的交互。

Result: 开发了针对关键隐私和可验证性挑战的新技术解决方案，为系统设计者提供了实用的蓝图。

Conclusion: 该研究提出了一个平衡隐私、可验证性和可审计性的统一视角，为AI安全治理的政策讨论提供了技术基础。

Abstract: The growing societal reliance on artificial intelligence necessitates robust
frameworks for ensuring its security, accountability, and trustworthiness. This
thesis addresses the complex interplay between privacy, verifiability, and
auditability in modern AI, particularly in foundation models. It argues that
technical solutions that integrate these elements are critical for responsible
AI innovation. Drawing from international policy contributions and technical
research to identify key risks in the AI pipeline, this work introduces novel
technical solutions for critical privacy and verifiability challenges.
Specifically, the research introduces techniques for enabling verifiable and
auditable claims about AI systems using zero-knowledge cryptography; utilizing
secure multi-party computation and trusted execution environments for
auditable, confidential deployment of large language models and information
retrieval; and implementing enhanced delegation mechanisms, credentialing
systems, and access controls to secure interactions with autonomous and
multi-agent AI systems. Synthesizing these technical advancements, this
dissertation presents a cohesive perspective on balancing privacy,
verifiability, and auditability in foundation model-based AI systems, offering
practical blueprints for system designers and informing policy discussions on
AI safety and governance.

</details>


### [34] [AEGIS : Automated Co-Evolutionary Framework for Guarding Prompt Injections Schema](https://arxiv.org/abs/2509.00088)
*Ting-Chun Liu,Ching-Yu Hsu,Kuan-Yi Lee,Chi-An Fu,Hung-yi Lee*

Main category: cs.CR

TL;DR: 提出了AEGIS框架，通过对抗性训练自动进化攻击和防御提示，显著提升了提示注入攻击的成功率和检测效果。


<details>
  <summary>Details</summary>
Motivation: 提示注入攻击对LLM安全部署构成重大挑战，现有基于提示的检测方法需要手动工程，效果有限。

Method: 采用自动协同进化框架，使用基于梯度的自然语言提示优化技术，让攻击和防御提示相互迭代优化。

Result: 攻击成功率提升0.26达到1.0，检测真阳性率提升0.23达到0.84，真阴性率保持0.89，在不同LLM中均有效。

Conclusion: 对抗性训练是防御提示注入攻击的可扩展有效方法，协同进化、梯度缓冲和多目标优化是关键要素。

Abstract: Prompt injection attacks pose a significant challenge to the safe deployment
of Large Language Models (LLMs) in real-world applications. While prompt-based
detection offers a lightweight and interpretable defense strategy, its
effectiveness has been hindered by the need for manual prompt engineering. To
address this issue, we propose AEGIS , an Automated co-Evolutionary framework
for Guarding prompt Injections Schema. Both attack and defense prompts are
iteratively optimized against each other using a gradient-like natural language
prompt optimization technique. This framework enables both attackers and
defenders to autonomously evolve via a Textual Gradient Optimization (TGO)
module, leveraging feedback from an LLM-guided evaluation loop. We evaluate our
system on a real-world assignment grading dataset of prompt injection attacks
and demonstrate that our method consistently outperforms existing baselines,
achieving superior robustness in both attack success and detection.
Specifically, the attack success rate (ASR) reaches 1.0, representing an
improvement of 0.26 over the baseline. For detection, the true positive rate
(TPR) improves by 0.23 compared to the previous best work, reaching 0.84, and
the true negative rate (TNR) remains comparable at 0.89. Ablation studies
confirm the importance of co-evolution, gradient buffering, and multi-objective
optimization. We also confirm that this framework is effective in different
LLMs. Our results highlight the promise of adversarial training as a scalable
and effective approach for guarding prompt injections.

</details>


### [35] [Enhanced Rényi Entropy-Based Post-Quantum Key Agreement with Provable Security and Information-Theoretic Guarantees](https://arxiv.org/abs/2509.00104)
*Ruopengyu Xu,Chenglian Liu*

Main category: cs.CR

TL;DR: 本文提出了一种基于Rényi熵的增强型后量子密钥协商协议，通过熵保持操作和秘密共享验证实现可证明的量子安全性，达到2^128量子安全保证。


<details>
  <summary>Details</summary>
Motivation: 原始构造存在漏洞，需要开发信息论安全的量子抵抗协议，以应对量子计算带来的安全威胁。

Method: 利用熵保持操作和秘密共享验证构建理论框架，采用熵放大技术和量子抵抗承诺，使用分布式多项式承诺机制进行保密验证。

Result: 协议在量子随机预言机模型下达到2^128量子安全保证，具有O(n^2)通信复杂度，能够抵抗已知量子攻击向量。

Conclusion: 该方法提供了无需硬度假设的信息论安全性，为长期密码安全奠定了基础，可扩展到安全多方计算和量子网络应用。

Abstract: This paper presents an enhanced post-quantum key agreement protocol based on
R\'{e}nyi entropy, addressing vulnerabilities in the original construction
while preserving information-theoretic security properties. We develop a
theoretical framework leveraging entropy-preserving operations and
secret-shared verification to achieve provable security against quantum
adversaries. Through entropy amplification techniques and quantum-resistant
commitments, the protocol establishes $2^{128}$ quantum security guarantees
under the quantum random oracle model. Key innovations include a
confidentiality-preserving verification mechanism using distributed polynomial
commitments, tightened min-entropy bounds with guaranteed non-negativity, and
composable security proofs in the quantum universal composability framework.
Unlike computational approaches, our method provides information-theoretic
security without hardness assumptions while maintaining polynomial complexity.
Theoretical analysis demonstrates resilience against known quantum attack
vectors, including Grover-accelerated brute force and quantum memory attacks.
The protocol achieves parameterization for 128-bit quantum security with
efficient $\mathcal{O}(n^2)$ communication complexity. Extensions to secure
multiparty computation and quantum network applications are established,
providing a foundation for long-term cryptographic security. All security
claims are derived from mathematical proofs; this theoretical work presents no
experimental validation.

</details>


### [36] [A Whole New World: Creating a Parallel-Poisoned Web Only AI-Agents Can See](https://arxiv.org/abs/2509.00124)
*Shaked Zychlinski*

Main category: cs.CR

TL;DR: 这篇论文提出了一种利用网站隐藏技术攻击AI自主浏览助手的新方式，通过识别AI助手的数字指纹并向其提供恶意内容，而普通用户则看到无害页面。


<details>
  <summary>Details</summary>
Motivation: 随着基于大语言模型的自主浏览助手日益普及，它们具有特定的数字指纹，这为攻击者提供了利用隐藏攻击的新机会。

Method: 通过分析浏览器属性、自动化框架签名和网络特征来识别AI助手请求，然后动态提供外观相同但嵌入恶意指令的隐藏页面。

Result: 攻击者可以控制AI助手行为，导致数据泄漏、恶意软件执行或错误信息传播，而这些攻击对人类用户和传统安全爬虫不可见。

Conclusion: 这种隐藏性高、可扩展的攻击对AI动力系统的安全构成了严重威胁，强调了开发突破性防御措施的紧迫性。

Abstract: This paper introduces a novel attack vector that leverages website cloaking
techniques to compromise autonomous web-browsing agents powered by Large
Language Models (LLMs). As these agents become more prevalent, their unique and
often homogenous digital fingerprints - comprising browser attributes,
automation framework signatures, and network characteristics - create a new,
distinguishable class of web traffic. The attack exploits this
fingerprintability. A malicious website can identify an incoming request as
originating from an AI agent and dynamically serve a different, "cloaked"
version of its content. While human users see a benign webpage, the agent is
presented with a visually identical page embedded with hidden, malicious
instructions, such as indirect prompt injections. This mechanism allows
adversaries to hijack agent behavior, leading to data exfiltration, malware
execution, or misinformation propagation, all while remaining completely
invisible to human users and conventional security crawlers. This work
formalizes the threat model, details the mechanics of agent fingerprinting and
cloaking, and discusses the profound security implications for the future of
agentic AI, highlighting the urgent need for robust defenses against this
stealthy and scalable attack.

</details>


### [37] [A Systematic Approach to Estimate the Security Posture of a Cyber Infrastructure: A Technical Report](https://arxiv.org/abs/2509.00266)
*Qishen Sam Liang*

Main category: cs.CR

TL;DR: 该报告提出了一个面向学术研究网络基础设施的系统性安全评估框架，通过构建攻击图谱来识别漏洞和安全差距，帮助管理员主动评估风险并优先制定缓解策略。


<details>
  <summary>Details</summary>
Motivation: 学术研究网络基础设施具有协作性、异构组件等特点，现有安全标准过于通用或复杂，缺乏专门针对此类基础设施的实用安全评估框架。

Method: 采用自上而下的任务中心方法：1)定义不可接受损失和安全任务；2)识别相关系统危害和关键资产；3)将组件及其关系建模为安全知识图谱，构建有向攻击图谱来映射攻击路径。

Result: 通过可视化攻击路径和防御机制，框架提供了系统漏洞和安全差距的清晰全面概览。

Conclusion: 该结构化方法使基础设施运营商能够主动评估风险、优先制定缓解策略，并做出明智可行的决策来加强整体安全态势。

Abstract: Academic and research Cyber Infrastructures (CI) present unique security
challenges due to their collaborative nature, heterogeneous components, and the
lack of practical, tailored security assessment frameworks. Existing standards
can be too generic or complex for CI administrators to apply effectively. This
report introduces a systematic, mission-centric approach to estimate and
analyze the security posture of a CI. The framework guides administrators
through a top-down process: (1) defining unacceptable losses and security
missions, (2) identifying associated system hazards and critical assets, and
(3) modeling the CI's components and their relationships as a security
knowledge graph. The core of this methodology is the construction of directed
attack graphs, which systematically map all potential paths an adversary could
take from an entry point to a critical asset. By visualizing these attack paths
alongside defense mechanisms, the framework provides a clear, comprehensive
overview of the system's vulnerabilities and security gaps. This structured
approach enables CI operators to proactively assess risks, prioritize
mitigation strategies, and make informed, actionable decisions to strengthen
the overall security posture of the CI.

</details>


### [38] [ShadowScope: GPU Monitoring and Validation via Composable Side Channel Signals](https://arxiv.org/abs/2509.00300)
*Ghadeer Almusaddar,Yicheng Zhang,Saber Ganjisaffar,Barry Williams,Yu David Liu,Dmitry Ponomare,Nael Abu-Ghazaleh*

Main category: cs.CR

TL;DR: ShadowScope是一个GPU计算完整性验证框架，通过可组合的黄金模型和硬件辅助验证机制，有效检测GPU内核中的异常执行行为，平均运行时开销仅为4.6%。


<details>
  <summary>Details</summary>
Motivation: 随着GPU在机器学习等计算密集型任务中的广泛应用，确保GPU计算的完整性变得至关重要。现有基于黄金模型的验证方法对干扰敏感且难以扩展到不同GPU工作负载。

Method: 提出ShadowScope框架，将可信内核执行分解为模块化、可重复的函数来编码关键行为特征。还设计了ShadowScope+硬件辅助验证机制，在GPU流水线中集成轻量级片上检查。

Result: 该框架能够以更细粒度捕获执行模式，实现对抗噪声、工作负载变化和干扰的鲁棒验证。硬件辅助版本平均运行时开销仅为4.6%，同时保持最小硬件和设计复杂度。

Conclusion: 研究表明侧信道可观测性可以系统地转化为实用的GPU内核完整性防御机制，为解决GPU计算安全问题提供了有效解决方案。

Abstract: As modern systems increasingly rely on GPUs for computationally intensive
tasks such as machine learning acceleration, ensuring the integrity of GPU
computation has become critically important. Recent studies have shown that GPU
kernels are vulnerable to both traditional memory safety issues (e.g., buffer
overflow attacks) and emerging microarchitectural threats (e.g., Rowhammer
attacks), many of which manifest as anomalous execution behaviors observable
through side-channel signals. However, existing golden model based validation
approaches that rely on such signals are fragile, highly sensitive to
interference, and do not scale well across GPU workloads with diverse
scheduling behaviors. To address these challenges, we propose ShadowScope, a
monitoring and validation framework that leverages a composable golden model.
Instead of building a single monolithic reference, ShadowScope decomposes
trusted kernel execution into modular, repeatable functions that encode key
behavioral features. This composable design captures execution patterns at
finer granularity, enabling robust validation that is resilient to noise,
workload variation, and interference across GPU workloads. To further reduce
reliance on noisy software-only monitoring, we introduce ShadowScope+, a
hardware-assisted validation mechanism that integrates lightweight on-chip
checks into the GPU pipeline. ShadowScope+ achieves high validation accuracy
with an average runtime overhead of just 4.6%, while incurring minimal hardware
and design complexity. Together, these contributions demonstrate that
side-channel observability can be systematically repurposed into a practical
defense for GPU kernel integrity.

</details>


### [39] [A Hybrid AI-based and Rule-based Approach to DICOM De-identification: A Solution for the MIDI-B Challenge](https://arxiv.org/abs/2509.00437)
*Hamideh Haghiri,Rajesh Baidya,Stefan Dvoretskii,Klaus H. Maier-Hein,Marco Nolden*

Main category: cs.CR

TL;DR: 提出了一种混合去标识化框架，结合规则方法和AI技术处理DICOM医疗影像数据，达到99.91%的去标识准确率


<details>
  <summary>Details</summary>
Motivation: 医疗影像数据共享需要确保患者隐私安全，DICOM文件包含大量个人身份信息和受保护健康信息，需要有效的去标识化方法

Method: 采用混合方法：基于TCIA最佳实践指南的规则组件处理结构化数据，PaddleOCR提取图像文本，RoBERTa模型处理自由文本中的PII/PHI信息，使用dciodvfy验证DICOM文件完整性

Result: 在MIDI-B测试数据集上达到99.91%的去标识准确率，通过迭代优化和自定义规则处理显著提升了性能

Conclusion: 结合规则基础的合规性和AI驱动的适应性能够有效解决DICOM去标识化的复杂挑战，为医疗数据安全共享提供了可靠解决方案

Abstract: Ensuring the de-identification of medical imaging data is a critical step in
enabling safe data sharing. This paper presents a hybrid de-identification
framework designed to process Digital Imaging and Communications in Medicine
(DICOM) files. Our framework adopts a modified, pre-built rule-based component,
updated with The Cancer Imaging Archive (TCIA)'s best practices guidelines, as
outlined in DICOM PS 3.15, for improved performance. It incorporates PaddleOCR,
a robust Optical Character Recognition (OCR) system for extracting text from
images, and RoBERTa, a fine-tuned transformer-based model for identifying and
removing Personally Identifiable Information (PII) and Protected Health
Information (PHI). Initially, the transformer-based model and the rule-based
component were integrated to process for both structured data and free text.
However, this coarse-grained approach did not yield optimal results. To improve
performance, we refined our approach by applying the transformer model
exclusively to free text, while structured data was handled only by rule-based
methods. In this framework the DICOM validator dciodvfy was leveraged to ensure
the integrity of DICOM files after the deID process. Through iterative
refinement, including the incorporation of custom rules and private tag
handling, the framework achieved a de-identification accuracy of 99.91% on the
MIDI-B test dataset. The results demonstrate the effectiveness of combining
rule-based compliance with AI-enabled adaptability in addressing the complex
challenges of DICOM de-identification.

</details>


### [40] [Cross-Domain Malware Detection via Probability-Level Fusion of Lightweight Gradient Boosting Models](https://arxiv.org/abs/2509.00476)
*Omar Khalid Ali Mohamed*

Main category: cs.CR

TL;DR: 这篇论文提出了一种轻量级的恶意软件检测框架，通过概率级融合三个不同数据集的预测结果，显著提高了跨域泛化能力和检测精度。


<details>
  <summary>Details</summary>
Motivation: 传统的单数据集模型在跨域泛化方面表现局限，且计算成本较高。恶意软件的日益复杂化导致对更加健壮的检测机制的需求。

Method: 使用LightGBM分别在三个数据集（EMBER静态特征、API调用序列行为特征、CIC混淆内存模式）上训练分类器，选择顶部预测特征确保效率，通过网格搜索确定最优权重进行概率融合。

Result: 在跨域验证集上获得了0.823的宏观F1分数，显著超过了单独模型，并体现了优异的泛化能力。框架保持低计算开销，适合实时部署。

Conclusion: 该融合框架提供了高效、轻量的恶意软件检测方案，具有良好的跨域泛化性能和实时部署能力，代码和数据完全可复现。

Abstract: The escalating sophistication of malware necessitates robust detection
mechanisms that generalize across diverse data sources. Traditional
single-dataset models struggle with cross-domain generalization and often incur
high computational costs. This paper presents a novel, lightweight framework
for malware detection that employs probability-level fusion across three
distinct datasets: EMBER (static features), API Call Sequences (behavioral
features), and CIC Obfuscated Memory (memory patterns). Our method trains
individual LightGBM classifiers on each dataset, selects top predictive
features to ensure efficiency, and fuses their prediction probabilities using
optimized weights determined via grid search. Extensive experiments demonstrate
that our fusion approach achieves a macro F1-score of 0.823 on a cross-domain
validation set, significantly outperforming individual models and providing
superior generalization. The framework maintains low computational overhead,
making it suitable for real-time deployment, and all code and data are provided
for full reproducibility.

</details>


### [41] [FreeTalk:A plug-and-play and black-box defense against speech synthesis attacks](https://arxiv.org/abs/2509.00561)
*Yuwen Pu,Zhou Feng,Chunyi Zhou,Jiahao Chen,Chunqiang Hu,Haibo Hu,Shouling Ji*

Main category: cs.CR

TL;DR: 这篇论文提出了一种轻量级、验证性强的插入式语音隐私保护方法，通过添加频域扰动来防范黑盒语音合成攻击，同时保持语音质量和实用性。


<details>
  <summary>Details</summary>
Motivation: 随着语音助手和语音验证的普及，攻击者可能收集用户语音进行语音合成攻击，很大影响用户声音安全和隐私。现有方法存在转移性低、验证性差、计算开销高等缺点，限制了实际部署。

Method: 提出圩频域添加扰动来保护语音隐私，采用数据增序策略和噪声平滑机制提高验证性，并提出身份级别保护机制来生成通用扰动、支持任意长度语音保护。

Result: 在5个语音合成模型、5个语音验证模型、1个语音识别模型和2个数据集上进行实验，结果表明方法具有满意的隐私保护性能、高语音质量和实用性。

Conclusion: 该方法有效解决了现有语音隐私保护方法的缺陷，提供了一种轻量级、验证性强、即插即用的黑盒语音隐私保护方案，具有实际部署价值。

Abstract: Recently, speech assistant and speech verification have been used in many
fields, which brings much benefit and convenience for us. However, when we
enjoy these speech applications, our speech may be collected by attackers for
speech synthesis. For example, an attacker generates some inappropriate
political opinions with the characteristic of the victim's voice by obtaining a
piece of the victim's speech, which will greatly influence the victim's
reputation. Specifically, with the appearance of some zero-shot voice
conversion methods, the cost of speech synthesis attacks has been further
reduced, which also brings greater challenges to user voice security and
privacy. Some researchers have proposed the corresponding privacy-preserving
methods. However, the existing approaches have some non-negligible drawbacks:
low transferability and robustness, high computational overhead. These
deficiencies seriously limit the existing method deployed in practical
scenarios. Therefore, in this paper, we propose a lightweight, robust,
plug-and-play privacy preservation method against speech synthesis attacks in a
black-box setting. Our method generates and adds a frequency-domain
perturbation to the original speech to achieve privacy protection and high
speech quality. Then, we present a data augmentation strategy and noise
smoothing mechanism to improve the robustness of the proposed method. Besides,
to reduce the user's defense overhead, we also propose a novel identity-wise
protection mechanism. It can generate a universal perturbation for one speaker
and support privacy preservation for speech of any length. Finally, we conduct
extensive experiments on 5 speech synthesis models, 5 speech verification
models, 1 speech recognition model, and 2 datasets. The experimental results
demonstrate that our method has satisfying privacy-preserving performance, high
speech quality, and utility.

</details>


### [42] [Federated Survival Analysis with Node-Level Differential Privacy: Private Kaplan-Meier Curves](https://arxiv.org/abs/2509.00615)
*Narasimha Raghavan Veeraragavan,Jan Franz Nygård*

Main category: cs.CR

TL;DR: 该论文研究如何在保护患者隐私的前提下，通过节点级差分隐私计算跨多个医疗管辖区的Kaplan-Meier生存曲线。每个站点仅披露一次曲线，添加拉普拉斯噪声，服务器平均噪声曲线，整体隐私预算保持不变。


<details>
  <summary>Details</summary>
Motivation: 医疗数据通常分布在多个管辖区域，需要在不泄露患者隐私的情况下进行生存分析。传统方法需要迭代训练或重加密，计算成本高。

Method: 使用四种一次性平滑技术：离散余弦变换、Haar小波收缩、自适应全变差去噪和参数化Weibull拟合，在五种隐私级别和三种分区场景下进行基准测试。

Result: 全变差去噪获得最佳平均精度，频域平滑器提供更强的鲁棒性，Weibull模型在最严格隐私设置下表现最稳定。所有方法在隐私预算≥0.5时都能保持经验log-rank类型I错误低于15%。

Conclusion: 研究表明无需迭代训练或重加密即可共享具有临床实用性的生存信息，为跨辖区医疗数据分析提供了实用的隐私保护解决方案。

Abstract: We investigate how to calculate Kaplan-Meier survival curves across multiple
health-care jurisdictions while protecting patient privacy with node-level
differential privacy. Each site discloses its curve only once, adding Laplace
noise whose scale is determined by the length of the common time grid; the
server then averages the noisy curves, so the overall privacy budget remains
unchanged. We benchmark four one-shot smoothing techniques: Discrete Cosine
Transform, Haar Wavelet shrinkage, adaptive Total-Variation denoising, and a
parametric Weibull fit on the NCCTG lung-cancer cohort under five privacy
levels and three partition scenarios (uniform, moderately skewed, highly
imbalanced). Total-Variation gives the best mean accuracy, whereas the
frequency-domain smoothers offer stronger worst-case robustness and the Weibull
model shows the most stable behaviour at the strictest privacy setting. Across
all methods the released curves keep the empirical log-rank type-I error below
fifteen percent for privacy budgets of 0.5 and higher, demonstrating that
clinically useful survival information can be shared without iterative training
or heavy cryptography.

</details>


### [43] [Enabling Trustworthy Federated Learning via Remote Attestation for Mitigating Byzantine Threats](https://arxiv.org/abs/2509.00634)
*Chaoyu Zhang,Heng Jin,Shanghao Shi,Hexuan Yu,Sydney Johns,Y. Thomas Hou,Wenjing Lou*

Main category: cs.CR

TL;DR: Sentinel是一个基于远程认证的联邦学习安全方案，通过代码插桩和可信执行环境来检测和防御拜占庭攻击，确保本地训练过程的完整性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习面临拜占庭攻击威胁，现有数据驱动防御方法难以区分恶意更新和良性数据变异，导致高误报率和性能不佳。

Method: 采用代码插桩追踪控制流和监控关键变量，在可信执行环境中使用可信训练记录器生成加密签名的认证报告，服务器验证后只聚合可信模型更新。

Result: 在物联网设备上的实验表明，Sentinel能以低运行时和内存开销确保本地训练完整性的可信度。

Conclusion: Sentinel从系统安全角度重新获得客户端透明度，有效缓解拜占庭攻击，为联邦学习提供了可靠的安全保障机制。

Abstract: Federated Learning (FL) has gained significant attention for its
privacy-preserving capabilities, enabling distributed devices to
collaboratively train a global model without sharing raw data. However, its
distributed nature forces the central server to blindly trust the local
training process and aggregate uncertain model updates, making it susceptible
to Byzantine attacks from malicious participants, especially in
mission-critical scenarios. Detecting such attacks is challenging due to the
diverse knowledge across clients, where variations in model updates may stem
from benign factors, such as non-IID data, rather than adversarial behavior.
Existing data-driven defenses struggle to distinguish malicious updates from
natural variations, leading to high false positive rates and poor filtering
performance.
  To address this challenge, we propose Sentinel, a remote attestation
(RA)-based scheme for FL systems that regains client-side transparency and
mitigates Byzantine attacks from a system security perspective. Our system
employs code instrumentation to track control-flow and monitor critical
variables in the local training process. Additionally, we utilize a trusted
training recorder within a Trusted Execution Environment (TEE) to generate an
attestation report, which is cryptographically signed and securely transmitted
to the server. Upon verification, the server ensures that legitimate client
training processes remain free from program behavior violation or data
manipulation, allowing only trusted model updates to be aggregated into the
global model. Experimental results on IoT devices demonstrate that Sentinel
ensures the trustworthiness of the local training integrity with low runtime
and memory overhead.

</details>


### [44] [LLM-HyPZ: Hardware Vulnerability Discovery using an LLM-Assisted Hybrid Platform for Zero-Shot Knowledge Extraction and Refinement](https://arxiv.org/abs/2509.00647)
*Yu-Zheng Lin,Sujan Ghimire,Abhiram Nandimandalam,Jonah Michael Camacho,Unnati Tripathi,Rony Macwan,Sicong Shao,Setareh Rafatirad,Rozhin Yasaei,Pratik Satam,Soheil Salehi*

Main category: cs.CR

TL;DR: LLM-HyPZ是一个基于大语言模型的混合框架，用于从漏洞语料库中零样本提取和精炼硬件漏洞知识，在114,836个CVE条目中识别出1,742个硬件相关漏洞，准确率达99.5%。


<details>
  <summary>Details</summary>
Motivation: 硬件漏洞具有持久性风险且难以修补，现有专家驱动的分析方法缺乏统计严谨性和存在主观偏差，需要数据驱动的可扩展方法来系统发现硬件漏洞。

Method: 整合零样本LLM分类、上下文嵌入、无监督聚类和提示驱动的摘要技术，从CVE语料库中大规模挖掘硬件相关漏洞。

Result: 识别出1,742个硬件相关漏洞，归纳为5个重复主题，支持了MITRE CWE 2025更新，将候选搜索空间从1,026个CVE缩减到411个。

Conclusion: LLM-HyPZ是首个数据驱动的可扩展方法，系统性地发现硬件漏洞，弥合了专家知识与现实世界漏洞证据之间的差距。

Abstract: The rapid growth of hardware vulnerabilities has created an urgent need for
systematic and scalable analysis methods. Unlike software flaws, which are
often patchable post-deployment, hardware weaknesses remain embedded across
product lifecycles, posing persistent risks to processors, embedded devices,
and IoT platforms. Existing efforts such as the MITRE CWE Hardware List (2021)
relied on expert-driven Delphi surveys, which lack statistical rigor and
introduce subjective bias, while large-scale data-driven foundations for
hardware weaknesses have been largely absent. In this work, we propose
LLM-HyPZ, an LLM-assisted hybrid framework for zero-shot knowledge extraction
and refinement from vulnerability corpora. Our approach integrates zero-shot
LLM classification, contextualized embeddings, unsupervised clustering, and
prompt-driven summarization to mine hardware-related CVEs at scale. Applying
LLM-HyPZ to the 2021-2024 CVE corpus (114,836 entries), we identified 1,742
hardware-related vulnerabilities. We distilled them into five recurring themes,
including privilege escalation via firmware and BIOS, memory corruption in
mobile and IoT systems, and physical access exploits. Benchmarking across seven
LLMs shows that LLaMA 3.3 70B achieves near-perfect classification accuracy
(99.5%) on a curated validation set. Beyond methodological contributions, our
framework directly supported the MITRE CWE Most Important Hardware Weaknesses
(MIHW) 2025 update by narrowing the candidate search space. Specifically, our
pipeline surfaced 411 of the 1,026 CVEs used for downstream MIHW analysis,
thereby reducing expert workload and accelerating evidence gathering. These
results establish LLM-HyPZ as the first data-driven, scalable approach for
systematically discovering hardware vulnerabilities, thereby bridging the gap
between expert knowledge and real-world vulnerability evidence.

</details>


### [45] [Virtual Reality, Real Problems: A Longitudinal Security Analysis of VR Firmware](https://arxiv.org/abs/2509.00662)
*Vamsi Shankar Simhadri,Yichang Xiong,Habiba Farrukh,Xiaokuan Zhang*

Main category: cs.CR

TL;DR: 首次对VR固件进行全面安全分析，发现了内核安全特性缺失、二进制硬化不充分、权限执行不一致等多个安全问题


<details>
  <summary>Details</summary>
Motivation: VR设备采用Android系统但存在VR特有定制化带来的新安全风险，而现有研究主要集中在普通Android设备，VR系统安全性仍未被全面探索

Method: 收集Quest和Pico两大厂商超300个VR固件版本，进行纵向分析，涵盖内核层、系统二进制和库层、应用层等多个层面

Result: 识别出多个安全漏洞：内核安全特性缺失、二进制硬化不充分、权限执行不一致、SELinux策略执行不充分等

Conclusion: 研究为VR厂商提供了改进安全性的建议，将成为VR开发者、用户和厂商的重要安全资源，并指导未来安全VR生态系统的发展

Abstract: Virtual Reality (VR) technology is rapidly growing in recent years. VR
devices such as Meta Quest 3 utilize numerous sensors to collect users' data to
provide an immersive experience. Due to the extensive data collection and the
immersive nature, the security of VR devices is paramount. Leading VR devices
often adopt and customize Android systems, which makes them susceptible to both
Android-based vulnerabilities and new issues introduced by VR-specific
customizations (e.g., system services to support continuous head and hand
tracking). While prior work has extensively examined the security properties of
the Android software stack, how these security properties hold for VR systems
remains unexplored. In this paper, we present the first comprehensive security
analysis of VR firmware. We collect over 300 versions of VR firmware from two
major vendors, Quest and Pico, and perform a longitudinal analysis across the
kernel layer, the system binary and library layer, and the application layer.
We have identified several security issues in these VR firmware, including
missing kernel-level security features, insufficient binary hardening,
inconsistent permission enforcement, and inadequate SELinux policy enforcement.
Based on our findings, we synthesize recommendations for VR vendors to improve
security and trust for VR devices. This paper will act as an important security
resource for VR developers, users, and vendors, and will also direct future
advancements in secure VR ecosystem.

</details>


### [46] [X-PRINT:Platform-Agnostic and Scalable Fine-Grained Encrypted Traffic Fingerprinting](https://arxiv.org/abs/2509.00706)
*YuKun Zhu,ManYuan Hua,Hai Huang,YongZhao Zhang,Jie Yang,FengHua Xu,RuiDong Chen,XiaoSong Zhang,JiGuo Yu,Yong Ma*

Main category: cs.CR

TL;DR: X-PRINT是一个基于URI模式的服务器中心化加密流量指纹识别框架，能够在跨平台和开放世界环境中实现细粒度行为识别，解决了现有方法平台依赖性强和可扩展性差的问题。


<details>
  <summary>Details</summary>
Motivation: 现有加密流量指纹识别方法存在两个关键限制：(i)依赖平台相关特征，限制了在异构平台间的泛化能力；(ii)在开放世界设置中对细粒度行为识别的可扩展性差。

Method: X-PRINT利用后端URI调用模式作为平台无关的不变量，使用时序结构化的URI映射进行行为推理，并通过排除平台或应用特定的私有URI来处理未见情况。

Result: 在多样化的跨平台和开放世界设置中进行广泛实验，X-PRINT在细粒度指纹识别方面达到了最先进的准确率，并展现出强大的可扩展性和鲁棒性。

Conclusion: URI调用模式可以作为有效的平台无关特征用于加密流量指纹识别，X-PRINT框架在跨平台和开放世界环境中表现出优异的性能和可靠性。

Abstract: Although encryption protocols such as TLS are widely de-ployed,side-channel
metadata in encrypted traffic still reveals patterns that allow application and
behavior inference.How-ever,existing fine-grained fingerprinting approaches
face two key limitations:(i)reliance on platform-dependent
charac-teristics,which restricts generalization across heterogeneous
platforms,and(ii)poor scalability for fine-grained behavior identification in
open-world settings.
  In this paper,we present X-PRINT,the first server-centric,URI-based framework
for cross-platform fine-grained encrypted-traffic fingerprinting.X-PRINT
systematically demonstrates that backend URI invocation patterns can serve as
platform-agnostic invariants and are effective for mod-eling fine-grained
behaviors.To achieve robust identifica-tion,X-PRINT further leverages
temporally structured URI maps for behavior inference and emphasizes the
exclusion of platform-or application-specific private URIs to handle unseen
cases,thereby improving reliability in open-world and cross-platform
settings.Extensive experiments across diverse cross-platform and open-world
settings show that X-PRINT achieves state-of-the-art accuracy in fine-grained
fingerprint-ing and exhibits strong scalability and robustness.

</details>


### [47] [Bayesian and Multi-Objective Decision Support for Real-Time Cyber-Physical Incident Mitigation](https://arxiv.org/abs/2509.00770)
*Shaofei Huang,Christopher M. Poskitt,Lwin Khin Shar*

Main category: cs.CR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This research proposes a real-time, adaptive decision-support framework for
mitigating cyber incidents in cyber-physical systems, developed in response to
an increasing reliance on these systems within critical infrastructure and
evolving adversarial tactics. Existing decision-support systems often fall
short in accounting for multi-agent, multi-path attacks and trade-offs between
safety and operational continuity. To address this, our framework integrates
hierarchical system modelling with Bayesian probabilistic reasoning,
constructing Bayesian Network Graphs from system architecture and vulnerability
data. Models are encoded using a Domain Specific Language to enhance
computational efficiency and support dynamic updates. In our approach, we use a
hybrid exposure probability estimation framework, which combines Exploit
Prediction Scoring System and Common Vulnerability Scoring System scores via
Bayesian confidence calibration to handle epistemic uncertainty caused by
incomplete or heterogeneous vulnerability metadata. Mitigation recommendations
are generated as countermeasure portfolios, refined using multi-objective
optimisation to identify Pareto-optimal strategies balancing attack likelihood,
impact severity, and system availability. To accommodate time- and
resource-constrained incident response, frequency-based heuristics are applied
to prioritise countermeasures across the optimised portfolios. The framework
was evaluated through three representative cyber-physical attack scenarios,
demonstrating its versatility in handling complex adversarial behaviours under
real-time response constraints. The results affirm its utility in operational
contexts and highlight the robustness of our proposed approach across diverse
threat environments.

</details>


### [48] [MAESTROCUT: Dynamic, Noise-Adaptive, and Secure Quantum Circuit Cutting on Near-Term Hardware](https://arxiv.org/abs/2509.00811)
*Samuel Punch,Krishnendu Guha*

Main category: cs.CR

TL;DR: MaestroCut是一个用于量子电路切割的闭环框架，能够自适应设备漂移和工作负载变化，通过实时跟踪方差代理、触发重新切割和拓扑感知的样本分配来提升精度和效率。


<details>
  <summary>Details</summary>
Motivation: 量子计算中的设备漂移和工作负载变化会影响电路切割的准确性，需要一种自适应方法来维持稳定的性能表现。

Method: 采用闭环框架，实时跟踪方差代理，在精度下降时触发重新切割，使用拓扑感知先验进行样本路由，并通过在线估计器级联（MLE、贝叶斯、GP辅助）在固定预算内选择最低误差重建。

Result: Tier-1模拟显示相比均匀和比例基线实现了持续的方差收缩和均方误差降低；Tier-2仿真在真实排队和噪声环境下展示了稳定的延迟目标、高可靠性和约1%的软件开销。

Conclusion: 自适应电路切割能够在近期硬件上以最小运营成本提供精度和效率的改进。

Abstract: We present MaestroCut, a closed-loop framework for quantum circuit cutting
that adapts partitioning and shot allocation to device drift and workload
variation. MaestroCut tracks a variance proxy in real time, triggers re-cutting
when accuracy degrades, and routes shots using topology-aware priors. An online
estimator cascade (MLE, Bayesian, GP-assisted) selects the lowest-error
reconstruction within a fixed budget. Tier-1 simulations show consistent
variance contraction and reduced mean-squared error versus uniform and
proportional baselines. Tier-2 emulation with realistic queueing and noise
demonstrates stable latency targets, high reliability, and ~1% software
overhead under stress scenarios. These results indicate that adaptive circuit
cutting can provide accuracy and efficiency improvements with minimal
operational cost on near-term hardware.

</details>


### [49] [Adaptive t Design Dummy-Gate Obfuscation for Cryogenic Scale Enforcement](https://arxiv.org/abs/2509.00812)
*Samuel Punch,Krishnendu Guha*

Main category: cs.CR

TL;DR: NADGO是一个量子计算隐私保护系统，通过噪声自适应虚拟门混淆、时序随机化和子电路路由等技术，在保证计算性能的同时限制信息泄露，实现云量子服务的操作隐私保护。


<details>
  <summary>Details</summary>
Motivation: 云量子服务可能通过调度元数据、延迟模式和共租户干扰泄露电路结构和时序信息，需要一种方法来保护门模型工作负载的操作隐私，同时支持机密性和公平的多租户环境。

Method: 结合硬件感知的t-design填充生成结构化覆盖流量、粒子滤波时序随机化掩盖队列模式、CASQUE子电路跨异构后端路由，以及带锁定校准工件和双阈值紧急停止的每间隔泄露估计器。

Result: 在4量子比特超导芯片上原型验证，控制间隔6.3微秒，在正常操作下泄露控制在预算内（间隔中止率低于1%），攻击下产生高分离度和集中中止，相比静态填充具有更低延迟和低温功耗。

Conclusion: NADGO系统能够有效保护云量子服务的操作隐私，在可接受的性能开销下实现信息泄露控制，为量子计算服务的机密性和多租户公平性提供了可行的解决方案。

Abstract: Cloud quantum services can reveal circuit structure and timing through
scheduler metadata, latency patterns, and co-tenant interference. We introduce
NADGO (Noise-Adaptive Dummy-Gate Obfuscation), a scheduling and obfuscation
stack that enforces operational privacy for gate-model workloads by applying
per-interval limits on observable information leakage. To support
confidentiality and fair multi-tenancy, operators require a method to audit
compliance at acceptable overheads. NADGO combines: (i) hardware-aware t-design
padding for structured cover traffic, (ii) particle-filter timing randomization
to mask queue patterns, (iii) CASQUE subcircuit routing across heterogeneous
backends, and (iv) a per-interval leakage estimator with locked calibration
artifacts and a dual-threshold kill-switch. We prototype the approach on a
4-qubit superconducting tile with cryo-CMOS control and evaluate both
depth-varied local-random circuits and small QAOA instances. Monitoring runs at
a 6.3 microsecond control interval, and per-interval decisions are recorded in
an append-only, hash-chained audit log. Across Monte Carlo (Tier 1) and
cloud-hardware emulation (Tier 2) evaluations, NADGO maintains leakage within
budget in nominal operation (interval-abort rate below 1 percent) and under
attack yields high separation with concentrated aborts. At matched leakage
targets, microbenchmarks indicate lower latency and cryogenic power consumption
than static padding, while end-to-end workloads maintain competitive cost
envelopes.

</details>


### [50] [Poisoned at Scale: A Scalable Audit Uncovers Hidden Scam Endpoints in Production LLMs](https://arxiv.org/abs/2509.02372)
*Zhiyang Chen,Tara Saba,Xun Deng,Xujie Si,Fan Long*

Main category: cs.CR

TL;DR: 研究发现主流LLMs存在系统性安全漏洞，平均4.2%的生成代码包含恶意URL，即使面对无害提示也会产生有害输出，证明训练数据已在大规模下毒


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在训练过程中吸收和重现恶意内容的安全风险，因为其依赖互联网数据集训练可能引入安全隐患

Method: 开发可扩展的自动化审计框架，从已知诈骗数据库合成无害的开发者风格提示，查询生产级LLMs并检测生成代码是否包含有害URL

Result: 在四个生产级LLM（GPT-4o、GPT-4o-mini、Llama-4-Scout、DeepSeek-V3）的大规模评估中发现所有模型都以不可忽视的比率生成恶意代码，平均4.2%的程序包含恶意URL

Conclusion: 研究结果提供了强有力经验证据，表明生产级LLMs的训练数据已成功被大规模投毒，迫切需要更强大的防御机制和生成后安全检查来缓解隐藏安全威胁的传播

Abstract: Large Language Models (LLMs) have become critical to modern software
development, but their reliance on internet datasets for training introduces a
significant security risk: the absorption and reproduction of malicious
content. To evaluate this threat, this paper introduces a scalable, automated
audit framework that synthesizes innocuous, developer-style prompts from known
scam databases to query production LLMs and determine if they generate code
containing harmful URLs. We conducted a large-scale evaluation across four
production LLMs (GPT-4o, GPT-4o-mini, Llama-4-Scout, and DeepSeek-V3), and
found a systemic vulnerability, with all tested models generating malicious
code at a non-negligible rate. On average, 4.2\% of programs generated in our
experiments contained malicious URLs. Crucially, this malicious code is often
generated in response to benign prompts. We manually validate the prompts which
cause all four LLMs to generate malicious code, and resulting in 177 innocuous
prompts that trigger all models to produce harmful outputs. These results
provide strong empirical evidence that the training data of production LLMs has
been successfully poisoned at scale, underscoring the urgent need for more
robust defense mechanisms and post-generation safety checks to mitigate the
propagation of hidden security threats.

</details>


### [51] [Unlocking the Effectiveness of LoRA-FP for Seamless Transfer Implantation of Fingerprints in Downstream Models](https://arxiv.org/abs/2509.00820)
*Zhenhua Xu,Zhaokun Yan,Binhan Xu,Xin Tong,Haitao Xu,Yourong Chen,Meng Han*

Main category: cs.CR

TL;DR: LoRA-FP是一个轻量级即插即用框架，通过约束微调在LoRA适配器中嵌入后门指纹，显著降低计算开销并保持模型完整性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，保护知识产权变得日益重要。传统指纹集成方法成本高且可能污染模型，需要更高效的解决方案。

Method: 提出LoRA-FP框架，通过约束微调在LoRA适配器中嵌入后门指纹，支持参数融合实现指纹移植，无需全参数更新。

Result: 实验结果表明，相比传统方法显著降低计算开销，在不同场景（包括增量训练和模型融合）中表现出优异的鲁棒性。

Conclusion: LoRA-FP为LLM知识产权保护提供了一种高效、轻量级的解决方案，具有实际应用价值。

Abstract: With the rapid advancement of large language models (LLMs), safeguarding
intellectual property (IP) has become increasingly critical. To address the
challenges of high costs and potential contamination in fingerprint
integration, we propose LoRA-FP, a lightweight, plug-and-play framework that
embeds backdoor fingerprints into LoRA adapters through constrained
fine-tuning. This design enables seamless fingerprint transplantation via
parameter fusion, eliminating the need for full-parameter updates while
preserving model integrity. Experimental results demonstrate that LoRA-FP not
only significantly reduces computational overhead compared to conventional
approaches but also achieves superior robustness across diverse scenarios,
including incremental training and model fusion. Our code and datasets are
publicly available at https://github.com/Xuzhenhua55/LoRA-FP.

</details>


### [52] [VULSOVER: Vulnerability Detection via LLM-Driven Constraint Solving](https://arxiv.org/abs/2509.00882)
*Xiang Li,Yueci Su,Jiahao Liu,Zhiwei Lin,Yuebing Hou,Peiming Gao,Yuanchao Zhang*

Main category: cs.CR

TL;DR: VULSOLVER是一个基于大语言模型的约束求解方法，通过将漏洞检测建模为约束求解问题，结合静态应用安全测试和LLM的语义推理能力，显著提高了漏洞检测的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则匹配的漏洞检测方法准确性不足，而现有LLM方法存在输出不稳定、上下文长度限制和幻觉问题，要么过度依赖规则，要么过度依赖LLM导致鲁棒性差。

Method: 提出VULSOLVER方法，将漏洞检测建模为约束求解问题，整合静态应用安全测试(SAST)和LLM的语义推理能力，使LLM能够像专业安全专家一样工作。

Result: 在OWASP Benchmark(1023个标记样本)上达到96.29%准确率、96.55% F1分数和100%召回率。在GitHub热门仓库中发现15个先前未知的高危漏洞(CVSS 7.5-9.8)。

Conclusion: VULSOLVER通过约束求解框架有效解决了LLM在漏洞检测中的挑战，在准确性和实际应用效果方面都表现出色，证明了其在现实世界安全分析中的有效性。

Abstract: Traditional vulnerability detection methods rely heavily on predefined rule
matching, which often fails to capture vulnerabilities accurately. With the
rise of large language models (LLMs), leveraging their ability to understand
code semantics has emerged as a promising direction for achieving more accurate
and efficient vulnerability detection. However, current LLM-based approaches
face significant challenges: instability in model outputs, limitations in
context length, and hallucination. As a result, many existing solutions either
use LLMs merely to enrich predefined rule sets, thereby keeping the detection
process fundamentally rule-based, or over-rely on them, leading to poor
robustness. To address these challenges, we propose a constraint-solving
approach powered by LLMs named VULSOLVER. By modeling vulnerability detection
as a constraint-solving problem, and by integrating static application security
testing (SAST) with the semantic reasoning capabilities of LLMs, our method
enables the LLM to act like a professional human security expert. We assess
VULSOLVER on the OWASP Benchmark (1,023 labeled samples), achieving 96.29%
accuracy, 96.55% F1-score, and 100% recall. Applied to popular GitHub
repositories, VULSOLVER also identified 15 previously unknown high-severity
vulnerabilities (CVSS 7.5-9.8), demonstrating its effectiveness in real-world
security analysis.

</details>


### [53] [Hybrid AI-Driven Intrusion Detection: Framework Leveraging Novel Feature Selection for Enhanced Network Security](https://arxiv.org/abs/2509.00896)
*Maryam Mahdi Alhusseini,Mohammad Reza Feizi Derakhshi*

Main category: cs.CR

TL;DR: 提出了一种基于AI的实时入侵检测框架，使用机器学习模型和新型Energy Valley Optimization方法，在NSL-KDD数据集上实现了高达98.95%的准确率，显著减少了特征数量和计算时间。


<details>
  <summary>Details</summary>
Motivation: 在快速发展的数字环境中，保护网络基础设施免受网络攻击已成为关键优先事项，特别是在无线传感器网络和云计算环境中需要增强网络安全。

Method: 采用逻辑回归、决策树和K近邻等经典机器学习模型，通过新型Energy Valley Optimization方法进行优化，使用NSL-KDD数据集，并通过下采样处理类别不平衡问题。

Result: 特征选择将输入特征从42个减少到18个，决策树准确率达到98.95%，K近邻98.47%，逻辑回归88.84%，同时显著减少了训练和测试时间。

Conclusion: 该工作通过提供可扩展、低延迟、高精度的入侵检测解决方案，推进了安全通信，符合人工智能、网络安全和实时数字网络的最新趋势。

Abstract: In today's rapidly evolving digital landscape, safeguarding network
infrastructures against cyberattacks has become a critical priority. This
research presents an innovative AI-driven real-time intrusion detection
framework designed to enhance network security, particularly in Wireless Sensor
Networks (WSNs) and Cloud Computing (CC) environments. The system employs
classical machine learning models, Logistic Regression, Decision Tree, and
K-Nearest Neighbors, optimized through the novel Energy Valley Optimization
(EVO) method using the NSL-KDD dataset. Feature selection significantly reduced
the number of input features from 42 to 18 while maintaining strong detection
capabilities. The proposed system achieved 98.95 percent accuracy with Decision
Tree, 98.47 percent with K-Nearest Neighbors, and 88.84 percent with Logistic
Regression. Moreover, high precision, recall, and F1-scores were attained
across all classifiers while substantially reducing training and testing times,
making the framework highly suitable for real-time applications. To ensure fair
detection across diverse attack types, dataset balancing via downsampling was
applied to address class imbalance challenges. This investigation focuses on
the significance of advancing intrusion detection systems in cloud computing
and WSNs. Overall, this work advances secure communications by delivering a
scalable, low-latency, and high-accuracy intrusion detection solution aligned
with the latest trends in artificial intelligence, cybersecurity, and real-time
digital networks

</details>


### [54] [PREE: Towards Harmless and Adaptive Fingerprint Editing in Large Language Models via Knowledge Prefix Enhancement](https://arxiv.org/abs/2509.00918)
*Xubin Yue,Zhenhua Xu,Wenpeng Xing,Jiahui Yu,Mohan Li,Meng Han*

Main category: cs.CR

TL;DR: PREE框架通过双通道知识编辑将版权信息编码为参数偏移，实现指纹特征的隐蔽嵌入，在主流大模型中达到90%触发精度，参数变化率小于0.03%，保持零误报率。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型商业部署中的知识产权保护挑战，现有黑盒指纹技术因依赖过拟合高困惑度触发模式而面临增量微调擦除和特征空间防御的双重挑战。

Method: 提出前缀增强指纹编辑框架(PREE)，通过双通道知识编辑将版权信息编码为参数偏移，实现指纹特征的隐蔽嵌入。

Result: 在LLaMA-3和Qwen-2.5等主流架构中达到90%触发精度，参数变化率小于0.03%，对增量微调和多维防御策略表现出强鲁棒性，评估期间保持零误报率。

Conclusion: PREE框架有效解决了现有指纹技术的局限性，实现了高效、隐蔽且鲁棒的模型版权保护。

Abstract: Addressing the intellectual property protection challenges in commercial
deployment of large language models (LLMs), existing black-box fingerprinting
techniques face dual challenges from incremental fine-tuning erasure and
feature-space defense due to their reliance on overfitting high-perplexity
trigger patterns. Recent work has revealed that model editing in the
fingerprinting domain offers distinct advantages, including significantly lower
false positive rates, enhanced harmlessness, and superior robustness. Building
on this foundation, this paper innovatively proposes a
$\textbf{Pr}$efix-$\textbf{e}$nhanced Fingerprint $\textbf{E}$diting Framework
(PREE), which encodes copyright information into parameter offsets through
dual-channel knowledge edit to achieve covert embedding of fingerprint
features. Experimental results demonstrate that the proposed solution achieves
the 90\% trigger precision in mainstream architectures including LLaMA-3 and
Qwen-2.5. The minimal parameter offset (change rate < 0.03) effectively
preserves original knowledge representation while demonstrating strong
robustness against incremental fine-tuning and multi-dimensional defense
strategies, maintaining zero false positive rate throughout evaluations.

</details>


### [55] [Clone What You Can't Steal: Black-Box LLM Replication via Logit Leakage and Distillation](https://arxiv.org/abs/2509.00973)
*Kanchon Gharami,Hansaka Aluvihare,Shafika Showkat Moni,Berker Peköz*

Main category: cs.CR

TL;DR: 该论文提出了一种通过API logit泄漏来克隆黑盒LLM的方法，仅需不到1万次查询即可重建输出投影矩阵，并在24小时内生成功能相当的替代模型。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在关键任务系统中的部署增加，缺乏健壮访问控制的API会暴露logits信息，形成被忽视的攻击面。现有方法主要关注输出层重建或表面行为蒸馏，但在严格查询约束下重建黑盒模型的研究不足。

Method: 采用两阶段方法：1) 通过SVD对top-k logits进行奇异值分解，用不到1万次查询重建输出投影矩阵；2) 将剩余架构蒸馏到不同深度的紧凑学生模型中，使用开源数据集训练。

Result: 6层学生模型重现了97.6%的教师模型隐藏状态几何结构，困惑度仅增加7.31%，NLL为7.58。4层变体实现17.1%的推理加速和18.1%的参数减少，性能相当。整个攻击在24 GPU小时内完成，不会触发API速率限制防御。

Conclusion: 研究结果表明成本有限的攻击者可以快速克隆LLM，强调了需要强化推理API和安全的本地防御部署的紧迫性。

Abstract: Large Language Models (LLMs) are increasingly deployed in mission-critical
systems, facilitating tasks such as satellite operations, command-and-control,
military decision support, and cyber defense. Many of these systems are
accessed through application programming interfaces (APIs). When such APIs lack
robust access controls, they can expose full or top-k logits, creating a
significant and often overlooked attack surface. Prior art has mainly focused
on reconstructing the output projection layer or distilling surface-level
behaviors. However, regenerating a black-box model under tight query
constraints remains underexplored. We address that gap by introducing a
constrained replication pipeline that transforms partial logit leakage into a
functional deployable substitute model clone. Our two-stage approach (i)
reconstructs the output projection matrix by collecting top-k logits from under
10k black-box queries via singular value decomposition (SVD) over the logits,
then (ii) distills the remaining architecture into compact student models with
varying transformer depths, trained on an open source dataset. A 6-layer
student recreates 97.6% of the 6-layer teacher model's hidden-state geometry,
with only a 7.31% perplexity increase, and a 7.58 Negative Log-Likelihood
(NLL). A 4-layer variant achieves 17.1% faster inference and 18.1% parameter
reduction with comparable performance. The entire attack completes in under 24
graphics processing unit (GPU) hours and avoids triggering API rate-limit
defenses. These results demonstrate how quickly a cost-limited adversary can
clone an LLM, underscoring the urgent need for hardened inference APIs and
secure on-premise defense deployments.

</details>


### [56] [Lightening the Load: A Cluster-Based Framework for A Lower-Overhead, Provable Website Fingerprinting Defense](https://arxiv.org/abs/2509.01046)
*Khashayar Khajavi,Tao Wang*

Main category: cs.CR

TL;DR: 提出了Adaptive Tamaraw防御框架，结合正则化和超序列方法的优势，通过聚类和自适应参数调整，在隐私保护和效率之间实现可调节的平衡


<details>
  <summary>Details</summary>
Motivation: 现有网站指纹防御方法存在局限性，正则化防御使用固定填充规则，超序列方法依赖预定义模式，需要一种既能保持有效性又能提供可证明安全性的自适应防御方案

Method: 首先提取流量行为模式并聚类为(k,l)-多样化匿名集，然后使用早期时间序列分类器从保守的全局正则化参数切换到更轻量的集合特定参数

Result: 在真实数据集上的实验显示，高隐私模式下可将攻击者准确率降至30%以下，效率优先模式下相比经典Tamaraw减少99%的开销

Conclusion: Adaptive Tamaraw提供了一个统一的防御框架，通过参数k的调节实现了隐私保护与效率之间的灵活权衡，同时保持了原有的信息论安全保证

Abstract: Website fingerprinting (WF) attacks remain a significant threat to encrypted
traffic, prompting the development of a wide range of defenses. Among these,
two prominent classes are regularization-based defenses, which shape traffic
using fixed padding rules, and supersequence-based approaches, which conceal
traces among predefined patterns. In this work, we present a unified framework
for designing an adaptive WF defense that combines the effectiveness of
regularization with the provable security of supersequence-style grouping. The
scheme first extracts behavioural patterns from traces and clusters them into
(k,l)-diverse anonymity sets; an early-time-series classifier (adapted from
ECDIRE) then switches from a conservative global set of regularization
parameters to the lighter, set-specific parameters. We instantiate the design
as Adaptive Tamaraw, a variant of Tamaraw that assigns padding parameters on a
per-cluster basis while retaining its original information-theoretic guarantee.
Comprehensive experiments on public real-world datasets confirm the benefits.
By tuning k, operators can trade privacy for efficiency: in its high-privacy
mode Adaptive Tamaraw pushes the bound on any attacker's accuracy below 30%,
whereas in efficiency-centred settings it cuts total overhead by 99% compared
with classic Tamaraw.

</details>


### [57] [Efficient and High-Accuracy Secure Two-Party Protocols for a Class of Functions with Real-number Inputs](https://arxiv.org/abs/2509.01178)
*Hao Guo,Zhaoqian Liu,Liqiang Peng,Shuaishuai Li,Ximing Fu,Weiran Liu,Lin Qu*

Main category: cs.CR

TL;DR: 本文提出了一种改进的两方秘密共享方案，显著放宽了有符号实数计算的输入约束，从|x| < L/3扩展到|x| < B（B ≤ L/2），并构建了支持整数除法、三角函数和指数函数的安全计算框架。


<details>
  <summary>Details</summary>
Motivation: 现有方法对有符号实数计算施加了严格的输入约束|x| < L/3，限制了在实际应用中的适用性，需要更宽松的约束条件来支持更广泛的实际计算需求。

Method: 通过改进有符号整数计算方法，将输入约束放宽到|x| < B（B ≤ L/2），并基于此构建通用框架来安全计算整数除法、三角函数和指数函数等复杂运算。

Result: 实验表明，所提协议在效率和精度上都有显著提升：e^{-x}计算的通信成本降低至SirNN的31%，运行速度提升5.53倍，最大ULP误差仅为1.435，优于对比方法。

Conclusion: 该方法成功放宽了输入约束限制，实现了高效且高精度的安全函数计算框架，为实际应用中的有符号实数安全计算提供了实用解决方案。

Abstract: In two-party secret sharing scheme, values are typically encoded as unsigned
integers $\mathsf{uint}(x)$, whereas real-world applications often require
computations on signed real numbers $\mathsf{Real}(x)$. To enable secure
evaluation of practical functions, it is essential to computing
$\mathsf{Real}(x)$ from shared inputs, as protocols take shares as input. At
USENIX'25, Guo et al. proposed an efficient method for computing signed integer
values $\mathsf{int}(x)$ from shares, which can be extended to compute
$\mathsf{Real}(x)$. However, their approach imposes a restrictive input
constraint $|x| < \frac{L}{3}$ for $x \in \mathbb{Z}_L$, limiting its
applicability in real-world scenarios. In this work, we significantly relax
this constraint to $|x| < B$ for any $B \leq \frac{L}{2}$, where $B =
\frac{L}{2}$ corresponding to the natural representable range in $x \in
\mathbb{Z}_L$. This relaxes the restrictions and enables the computation of
$\mathsf{Real}(x)$ with loose or no input constraints. Building upon this
foundation, we present a generalized framework for designing secure protocols
for a broad class of functions, including integer division ($\lfloor
\frac{x}{d} \rfloor$), trigonometric ($\sin(x)$) and exponential ($e^{-x}$)
functions. Our experimental evaluation demonstrates that the proposed protocols
achieve both high efficiency and high accuracy. Notably, our protocol for
evaluating $e^{-x}$ reduces communication costs to approximately 31% of those
in SirNN (S&P 21) and Bolt (S&P 24), with runtime speedups of up to $5.53
\times$ and $3.09 \times$, respectively. In terms of accuracy, our protocol
achieves a maximum ULP error of $1.435$, compared to $2.64$ for SirNN and
$8.681$ for Bolt.

</details>


### [58] [Web Fraud Attacks Against LLM-Driven Multi-Agent Systems](https://arxiv.org/abs/2509.01211)
*Dezhang Kong,Hujin Peng,Yilun Zhang,Lele Zhao,Zhenhua Xu,Shi Lin,Changting Lin,Meng Han*

Main category: cs.CR

TL;DR: 本文提出了一种针对LLM驱动的多智能体系统的新型Web欺诈攻击，通过域名篡改、链接结构伪装等技术诱导智能体访问恶意网站，具有显著的破坏潜力和规避优势。


<details>
  <summary>Details</summary>
Motivation: 随着基于LLM的多智能体系统应用激增，Web链接安全成为确保系统可靠性的关键问题。攻击者一旦诱导智能体访问恶意网站，就能以此为跳板进行后续攻击，大幅扩大攻击面。

Method: 设计了11种代表性攻击变体，包括域名篡改（同形异义字欺骗、字符替换等）、链接结构伪装（子目录嵌套、子域名嫁接、参数混淆等）以及其他针对MAS链接验证漏洞的欺骗技术。

Result: 通过大量实验证明，Web欺诈攻击不仅在不同MAS架构中表现出显著的破坏潜力，而且在规避检测方面具有明显优势：无需复杂的输入格式如越狱，从而降低了暴露风险。

Conclusion: Web欺诈攻击的隐蔽性和破坏性对系统安全和用户安全构成了不可忽视的威胁，强调了在LLM驱动的MAS中解决此类攻击的重要性。

Abstract: With the proliferation of applications built upon LLM-driven multi-agent
systems (MAS), the security of Web links has become a critical concern in
ensuring system reliability. Once an agent is induced to visit a malicious
website, attackers can use it as a springboard to conduct diverse subsequent
attacks, which will drastically expand the attack surface. In this paper, we
propose Web Fraud Attacks, a novel type of attack aiming at inducing MAS to
visit malicious websites. We design 11 representative attack variants that
encompass domain name tampering (homoglyph deception, character substitution,
etc.), link structure camouflage (sub-directory nesting, sub-domain grafting,
parameter obfuscation, etc.), and other deceptive techniques tailored to
exploit MAS's vulnerabilities in link validation. Through extensive experiments
on these crafted attack vectors, we demonstrate that Web fraud attacks not only
exhibit significant destructive potential across different MAS architectures
but also possess a distinct advantage in evasion: they circumvent the need for
complex input formats such as jailbreaking, which inherently carry higher
exposure risks. These results underscore the importance of addressing Web fraud
attacks in LLM-driven MAS, as their stealthiness and destructiveness pose
non-negligible threats to system security and user safety.

</details>


### [59] [Practical and Private Hybrid ML Inference with Fully Homomorphic Encryption](https://arxiv.org/abs/2509.01253)
*Sayan Biswas,Philippe Chartier,Akash Dhasade,Tom Jurien,David Kerriou,Anne-Marie Kerrmarec,Mohammed Lemou,Franklin Tranie,Martijn de Vos,Milos Vujasinovic*

Main category: cs.CR

TL;DR: Safhire是一个混合推理框架，在服务器上加密执行线性层，将非线性激活函数卸载到客户端明文处理，消除FHE的昂贵自举操作，通过随机混洗保护模型机密性，实现1.5-10.5倍延迟降低


<details>
  <summary>Details</summary>
Motivation: 解决完全同态加密(FHE)在实际应用中的瓶颈问题：昂贵的自举操作和非线性激活函数的高效近似困难，同时需要保护用户敏感数据和服务器模型机密性

Method: 采用混合推理架构：服务器加密执行线性层，客户端明文处理非线性激活函数；使用随机混洗技术混淆中间值保护模型；采用快速密文打包和部分提取等优化技术

Result: 在多个标准模型和数据集上评估，相比最先进的Orion基准，推理延迟降低1.5-10.5倍，通信开销可控，精度相当

Conclusion: Safhire证明了混合FHE推理的实用性，通过消除自举、支持精确激活函数和显著减少计算，为保护隐私的云服务提供了可行解决方案

Abstract: In contemporary cloud-based services, protecting users' sensitive data and
ensuring the confidentiality of the server's model are critical. Fully
homomorphic encryption (FHE) enables inference directly on encrypted inputs,
but its practicality is hindered by expensive bootstrapping and inefficient
approximations of non-linear activations. We introduce Safhire, a hybrid
inference framework that executes linear layers under encryption on the server
while offloading non-linearities to the client in plaintext. This design
eliminates bootstrapping, supports exact activations, and significantly reduces
computation. To safeguard model confidentiality despite client access to
intermediate outputs, Safhire applies randomized shuffling, which obfuscates
intermediate values and makes it practically impossible to reconstruct the
model. To further reduce latency, Safhire incorporates advanced optimizations
such as fast ciphertext packing and partial extraction. Evaluations on multiple
standard models and datasets show that Safhire achieves 1.5X - 10.5X lower
inference latency than Orion, a state-of-the-art baseline, with manageable
communication overhead and comparable accuracy, thereby establishing the
practicality of hybrid FHE inference.

</details>


### [60] [An Automated Attack Investigation Approach Leveraging Threat-Knowledge-Augmented Large Language Models](https://arxiv.org/abs/2509.01271)
*Rujie Dai,Peizhuo Lv,Yujiang Gui,Qiujian Lv,Yuanyuan Qiao,Yan Wang,Degang Sun,Weiqing Huang,Yingjiu Li,XiaoFeng Wang*

Main category: cs.CR

TL;DR: 提出基于LLM的攻击调查框架，通过动态可适应的Kill-Chain威胁知识库，实现高精度攻击链重构和可读报告生成


<details>
  <summary>Details</summary>
Motivation: 现有APT攻击调查方法存在平台通用性差、对演进战术泛化能力有限、无法生成分析师就绪报告等问题，LLM虽具备语义理解能力但难以捕捉长距离跨日志依赖

Method: 构建动态可适应的Kill-Chain对齐威胁知识库，将攻击行为组织为阶段感知知识单元并添加语义标注，使LLM能迭代检索相关情报、进行因果推理并逐步扩展调查上下文

Result: 在15个攻击场景（430万日志事件，7.2GB数据）评估中，平均真阳性率97.1%，平均假阳性率0.2%，显著优于SOTA方法ATLAS（真阳性率79.2%，假阳性率29.1%）

Conclusion: LLM增强的攻击调查框架能有效解决APT攻击链重构问题，在准确性和实用性方面均显著优于现有方法

Abstract: Advanced Persistent Threats (APTs) are prolonged, stealthy intrusions by
skilled adversaries that compromise high-value systems to steal data or disrupt
operations. Reconstructing complete attack chains from massive, heterogeneous
logs is essential for effective attack investigation, yet existing methods
suffer from poor platform generality, limited generalization to evolving
tactics, and an inability to produce analyst-ready reports. Large Language
Models (LLMs) offer strong semantic understanding and summarization
capabilities, but in this domain they struggle to capture the long-range,
cross-log dependencies critical for accurate reconstruction.
  To solve these problems, we present an LLM-empowered attack investigation
framework augmented with a dynamically adaptable Kill-Chain-aligned threat
knowledge base. We organizes attack-relevant behaviors into stage-aware
knowledge units enriched with semantic annotations, enabling the LLM to
iteratively retrieve relevant intelligence, perform causal reasoning, and
progressively expand the investigation context. This process reconstructs
multi-phase attack scenarios and generates coherent, human-readable
investigation reports. Evaluated on 15 attack scenarios spanning single-host
and multi-host environments across Windows and Linux (over 4.3M log events, 7.2
GB of data), the system achieves an average True Positive Rate (TPR) of 97.1%
and an average False Positive Rate (FPR) of 0.2%, significantly outperforming
the SOTA method ATLAS, which achieves an average TPR of 79.2% and an average
FPR of 29.1%.

</details>


### [61] [Anomaly detection in network flows using unsupervised online machine learning](https://arxiv.org/abs/2509.01375)
*Alberto Miguel-Diez,Adrián Campazas-Vega,Ángel Manuel Guerrero-Higueras,Claudia Álvarez-Aparicio,Vicente Matellán-Olivera*

Main category: cs.CR

TL;DR: 提出基于无监督在线学习的网络流量异常检测模型，使用One-Class SVM实现动态学习正常网络行为，在NF-UNSW-NB15数据集上达到98%准确率和100%召回率，处理时间<0.033ms/流，适合实时应用。


<details>
  <summary>Details</summary>
Motivation: 网络流量持续增长且攻击日益复杂，需要能够持续自适应的解决方案，因为网络行为是动态变化的。传统方法难以应对实时变化的网络环境和标注数据稀缺的问题。

Method: 使用River库实现无监督机器学习模型，采用One-Class SVM算法，具备在线学习能力，能够动态学习正常网络行为并检测异常，无需标注数据。

Result: 在NF-UNSW-NB15数据集及其v2版本上测试，准确率超过98%，误报率低于3.1%，最新数据集版本召回率达到100%，单流处理时间小于0.033毫秒。

Conclusion: 该方法证明了无监督在线学习在网络异常检测中的可行性，能够有效应对动态变化的网络环境，满足实时检测需求，具有实际应用价值。

Abstract: Nowadays, the volume of network traffic continues to grow, along with the
frequency and sophistication of attacks. This scenario highlights the need for
solutions capable of continuously adapting, since network behavior is dynamic
and changes over time. This work presents an anomaly detection model for
network flows using unsupervised machine learning with online learning
capabilities. This approach allows the system to dynamically learn the normal
behavior of the network and detect deviations without requiring labeled data,
which is particularly useful in real-world environments where traffic is
constantly changing and labeled data is scarce. The model was implemented using
the River library with a One-Class SVM and evaluated on the NF-UNSW-NB15
dataset and its extended version v2, which contain network flows labeled with
different attack categories. The results show an accuracy above 98%, a false
positive rate below 3.1%, and a recall of 100% in the most advanced version of
the dataset. In addition, the low processing time per flow (<0.033 ms)
demonstrates the feasibility of the approach for real-time applications.

</details>


### [62] [LiFeChain: Lightweight Blockchain for Secure and Efficient Federated Lifelong Learning in IoT](https://arxiv.org/abs/2509.01434)
*Handi Chen,Jing Deng,Xiuzhe Wu,Zhihan Jiang,Xinchen Zhang,Xianhao Chen,Edith C. H. Ngai*

Main category: cs.CR

TL;DR: LiFeChain是一个轻量级区块链系统，专门为联邦终身学习(FLL)设计，通过双向验证和最小链上披露提供防篡改账本，解决IoT系统中长期攻击和安全问题。


<details>
  <summary>Details</summary>
Motivation: IoT设备产生异构数据流需要持续去中心化智能，联邦终身学习(FLL)能克服灾难性遗忘但面临长期攻击风险。传统单服务器架构存在单点故障，区块链虽提供防篡改基础但直接应用会增加计算和检索成本。

Method: 提出LiFeChain系统，包含两个互补机制：服务器端的PoMC共识（结合学习和遗忘机制缓解负迁移）和客户端的Seg-ZA（检测异常委员会行为而不泄露隐私）。设计为即插即用组件，可无缝集成现有FLL算法。

Result: 实验结果表明LiFeChain不仅能增强模型性能对抗两种长期攻击，还能保持高效率和可扩展性。

Conclusion: LiFeChain是首个专为FLL定制的区块链解决方案，有效解决了IoT系统中联邦终身学习的安全性和效率问题，为可信FLL系统提供了实用框架。

Abstract: The expansion of Internet of Things (IoT) devices constantly generates
heterogeneous data streams, driving demand for continuous, decentralized
intelligence. Federated Lifelong Learning (FLL) provides an ideal solution by
incorporating federated and lifelong learning to overcome catastrophic
forgetting. The extended lifecycle of FLL in IoT systems increases their
vulnerability to persistent attacks, and these risks may be obscured by
performance degradation caused by spatial-temporal data heterogeneity.
Moreover, this problem is exacerbated by the standard single-server
architecture, as its single point of failure makes it difficult to maintain a
reliable audit trail for long-term threats. Blockchain provides a tamper-proof
foundation for trustworthy FLL systems. Nevertheless, directly applying
blockchain to FLL significantly increases computational and retrieval costs
with the expansion of the knowledge base, slowing down the training on IoT
devices. To address these challenges, we propose LiFeChain, a lightweight
blockchain for secure and efficient federated lifelong learning by providing a
tamper-resistant ledger with minimal on-chain disclosure and bidirectional
verification. To the best of our knowledge, LiFeChain is the first blockchain
tailored for FLL. LiFeChain incorporates two complementary mechanisms: the
proof-of-model-correlation (PoMC) consensus on the server, which couples
learning and unlearning mechanisms to mitigate negative transfer, and segmented
zero-knowledge arbitration (Seg-ZA) on the client, which detects and arbitrates
abnormal committee behavior without compromising privacy. LiFeChain is designed
as a plug-and-play component that can be seamlessly integrated into existing
FLL algorithms. Experimental results demonstrate that LiFeChain not only
enhances model performance against two long-term attacks but also sustains high
efficiency and scalability.

</details>


### [63] [LLMHoney: A Real-Time SSH Honeypot with Large Language Model-Driven Dynamic Response Generation](https://arxiv.org/abs/2509.01463)
*Pranjay Malhotra*

Main category: cs.CR

TL;DR: LLMHoney是一个基于大型语言模型的SSH蜜罐，能够实时生成动态、真实的命令输出，相比传统蜜罐具有更好的真实性和适应性。


<details>
  <summary>Details</summary>
Motivation: 传统低交互和中交互蜜罐依赖静态预脚本交互，容易被熟练攻击者识别，需要更真实的动态交互能力来提升攻击者参与度和威胁情报收集效果。

Method: 使用大型语言模型实时生成SSH命令输出，结合基于字典的虚拟文件系统处理常见命令以降低延迟，对138个代表性Linux命令进行测试，评估了13种不同LLM变体。

Result: Gemini-2.0、Qwen2.5:1.5B和Phi3:3.8B模型表现最佳，平均延迟约3秒，准确性和可靠性最高；小模型常产生错误或不符合特征的输出。

Conclusion: LLM驱动的蜜罐是提升攻击者参与度和收集更丰富威胁情报的有前景的方法，但存在幻觉输出和资源消耗增加的挑战。

Abstract: Cybersecurity honeypots are deception tools for engaging attackers and gather
intelligence, but traditional low or medium-interaction honeypots often rely on
static, pre-scripted interactions that can be easily identified by skilled
adversaries. This Report presents LLMHoney, an SSH honeypot that leverages
Large Language Models (LLMs) to generate realistic, dynamic command outputs in
real time. LLMHoney integrates a dictionary-based virtual file system to handle
common commands with low latency while using LLMs for novel inputs, achieving a
balance between authenticity and performance. We implemented LLMHoney using
open-source LLMs and evaluated it on a testbed with 138 representative Linux
commands. We report comprehensive metrics including accuracy (exact-match,
Cosine Similarity, Jaro-Winkler Similarity, Levenshtein Similarity and BLEU
score), response latency and memory overhead. We evaluate LLMHoney using
multiple LLM backends ranging from 0.36B to 3.8B parameters, including both
open-source models and a proprietary model(Gemini). Our experiments compare 13
different LLM variants; results show that Gemini-2.0 and moderately-sized
models Qwen2.5:1.5B and Phi3:3.8B provide the most reliable and accurate
responses, with mean latencies around 3 seconds, whereas smaller models often
produce incorrect or out-of-character outputs. We also discuss how LLM
integration improves honeypot realism and adaptability compared to traditional
honeypots, as well as challenges such as occasional hallucinated outputs and
increased resource usage. Our findings demonstrate that LLM-driven honeypots
are a promising approach to enhance attacker engagement and collect richer
threat intelligence.

</details>


### [64] [Privacy-preserving authentication for military 5G networks](https://arxiv.org/abs/2509.01470)
*I. D. Lutz,A. M. Hill,M. C. Valenti*

Main category: cs.CR

TL;DR: 本文分析了5G AKA协议在隐私保护方面的漏洞，提出了五种轻量级缓解策略，其中UE生成nonce的方案最为有效，能以最小开销增强隐私保护


<details>
  <summary>Details</summary>
Motivation: 随着5G网络在国防应用中的普及，确保认证和密钥协商(AKA)协议的隐私性和完整性变得至关重要。虽然5G AKA通过隐藏用户身份改进了前代技术，但在实际对抗模型下仍存在重放同步和可链接性威胁

Method: 对标准化的5G AKA流程进行统一分析，识别多个漏洞，并提出了五种轻量级缓解策略。通过原型实现和测试验证这些增强措施的有效性

Result: 研究表明，引入UE生成nonce的解决方案最为有效，能够以可忽略的额外开销有效中和已识别的跟踪和关联攻击。这些增强措施显著提高了对可链接性攻击的抵抗能力

Conclusion: 将UE生成nonce的扩展作为5G AKA协议的可选功能，为商业和军事5G部署提供了向后兼容、低开销的隐私保护认证框架路径

Abstract: As 5G networks gain traction in defense applications, ensuring the privacy
and integrity of the Authentication and Key Agreement (AKA) protocol is
critical. While 5G AKA improves upon previous generations by concealing
subscriber identities, it remains vulnerable to replay-based synchronization
and linkability threats under realistic adversary models. This paper provides a
unified analysis of the standardized 5G AKA flow, identifying several
vulnerabilities and highlighting how each exploits protocol behavior to
compromise user privacy. To address these risks, we present five lightweight
mitigation strategies. We demonstrate through prototype implementation and
testing that these enhancements strengthen resilience against linkability
attacks with minimal computational and signaling overhead. Among the solutions
studied, those introducing a UE-generated nonce emerge as the most promising,
effectively neutralizing the identified tracking and correlation attacks with
negligible additional overhead. Integrating this extension as an optional
feature to the standard 5G AKA protocol offers a backward-compatible,
low-overhead path toward a more privacy-preserving authentication framework for
both commercial and military 5G deployments.

</details>


### [65] [Insight-LLM: LLM-enhanced Multi-view Fusion in Insider Threat Detection](https://arxiv.org/abs/2509.01509)
*Chengyu Song,Jianming Zheng*

Main category: cs.CR

TL;DR: Insight-LLM是一个专门为内部威胁检测设计的模块化多视图融合框架，解决了现有单视图方法的局限性，通过冻结预训练语言模型实现高效的多视图融合。


<details>
  <summary>Details</summary>
Motivation: 现有内部威胁检测方法主要依赖单视图建模，导致覆盖范围有限且容易遗漏异常。多视图学习在其他领域表现出色，但直接应用于内部威胁检测面临可扩展性瓶颈、语义不对齐和视图不平衡等挑战。

Method: 提出Insight-LLM框架，采用模块化多视图融合方法，使用冻结的预训练语言模型来处理稀疏、异构的用户行为数据，实现高效的多视图信息整合。

Result: 实现了最先进的检测性能，同时具有低延迟和低参数开销的优势。

Conclusion: Insight-LLM为内部威胁检测提供了一个有效的多视图融合解决方案，成功解决了传统方法的局限性，在性能和效率方面都表现出色。

Abstract: Insider threat detection (ITD) requires analyzing sparse, heterogeneous user
behavior. Existing ITD methods predominantly rely on single-view modeling,
resulting in limited coverage and missed anomalies. While multi-view learning
has shown promise in other domains, its direct application to ITD introduces
significant challenges: scalability bottlenecks from independently trained
sub-models, semantic misalignment across disparate feature spaces, and view
imbalance that causes high-signal modalities to overshadow weaker ones. In this
work, we present Insight-LLM, the first modular multi-view fusion framework
specifically tailored for insider threat detection. Insight-LLM employs frozen,
pre-nes, achieving state-of-the-art detection with low latency and parameter
overhead.

</details>


### [66] [Securing Radiation Detection Systems with an Efficient TinyML-Based IDS for Edge Devices](https://arxiv.org/abs/2509.01592)
*Einstein Rivas Pizarro,Wajiha Zaheer,Li Yang,Khalil El-Khatib,Glenn Harvel*

Main category: cs.CR

TL;DR: 这篇论文提出了一种依靠TinyML技术的优化XGBoost模型，用于资源受限环境下的辐射检测系统入侵检测，在保持准确性的同时大幅减少模型大小和计算需求。


<details>
  <summary>Details</summary>
Motivation: 辐射检测系统(RDS)在核设施和医疗环境中关系公众安全，但易受到数据注入、DDoS等网络攻击威胁，需要在资源受限设备上实现实时入侵检测。

Method: 构建合成辐射数据集，采用TinyML技术（剪枝、量化、特征选择、采样）优化XGBoost模型，降低模型大小和计算复杂度。

Result: 该系统在保持合理准确性的前提下，显著减少了模型大小和计算需求，能够在低资源设备上实现实时入侵检测。

Conclusion: 研究成功将机器学习预测能力推广到关键基础设施的感知层，为资源受限环境下的辐射安全监控提供了有效解决方案。

Abstract: Radiation Detection Systems (RDSs) play a vital role in ensuring public
safety across various settings, from nuclear facilities to medical
environments. However, these systems are increasingly vulnerable to
cyber-attacks such as data injection, man-in-the-middle (MITM) attacks, ICMP
floods, botnet attacks, privilege escalation, and distributed denial-of-service
(DDoS) attacks. Such threats could compromise the integrity and reliability of
radiation measurements, posing significant public health and safety risks. This
paper presents a new synthetic radiation dataset and an Intrusion Detection
System (IDS) tailored for resource-constrained environments, bringing Machine
Learning (ML) predictive capabilities closer to the sensing edge layer of
critical infrastructure. Leveraging TinyML techniques, the proposed IDS employs
an optimized XGBoost model enhanced with pruning, quantization, feature
selection, and sampling. These TinyML techniques significantly reduce the size
of the model and computational demands, enabling real-time intrusion detection
on low-resource devices while maintaining a reasonable balance between
efficiency and accuracy.

</details>


### [67] [Statistics-Friendly Confidentiality Protection for Establishment Data, with Applications to the QCEW](https://arxiv.org/abs/2509.01597)
*Kaitlyn Webb,Prottay Protivash,John Durrell,Daniell Toth,Aleksandra Slavković,Daniel Kifer*

Main category: cs.CR

TL;DR: 提出针对商业数据的保密性框架，基于高斯差分隐私，专注于政策制定者的可解释性，解决传统方法在高度偏斜商业数据中的局限性


<details>
  <summary>Details</summary>
Motivation: 商业数据保密性研究不足，传统方法效果不佳，现代个人数据隐私技术不适用于高度偏斜的商业数据，极端异常值对查询结果贡献重要

Method: 提出基于高斯差分隐私的新型保密框架，开发两种查询应答机制，分析将噪声查询结果转换为保密微数据时的新挑战

Result: 在机密季度就业和工资普查(QCEW)微数据和公共替代数据集上评估了所提机制

Conclusion: 该框架为商业数据提供了更好的保密性/效用权衡，特别适合处理高度偏斜数据和重要异常值的情况

Abstract: Confidentiality for business data is an understudied area of disclosure
avoidance, where legacy methods struggle to provide acceptable results. Modern
formal privacy techniques designed for person-level data do not provide
suitable confidentiality/utility trade-offs due to the highly skewed nature of
business data and because extreme outlier records are often important
contributors to query answers. In this paper, inspired by Gaussian Differential
Privacy, we propose a novel confidentiality framework for business data with a
focus on interpretability for policy makers. We propose two query-answering
mechanisms and analyze new challenges that arise when noisy query answers are
converted into confidentiality-preserving microdata. We evaluate our mechanisms
on confidential Quarterly Census of Employment and Wages (QCEW) microdata and a
public substitute dataset.

</details>


### [68] [An Efficient Intrusion Detection System for Safeguarding Radiation Detection Systems](https://arxiv.org/abs/2509.01599)
*Nathanael Coolidge,Jaime González Sanz,Li Yang,Khalil El Khatib,Glenn Harvel,Nelson Agbemava,I Putu Susila,Mehmet Yavuz Yagci*

Main category: cs.CR

TL;DR: 本文提出了一种基于LightGBM的机器学习入侵检测系统，用于防范攻击者对政射检测系统的拒绝服务攻击，具有高准确性和低计算资源消耗的优势。


<details>
  <summary>Details</summary>
Motivation: 政射检测系统(RDS)在环境监测中致关重要，但缺乏对恶意攻击的防护能力。尤其是拒绝服务(DoS)攻击可能导致系统故障，需要有效的入侵检测方案来保护这些关键基础设施。

Method: 使用采样方法模拟DoS攻击，评估多种机器学习算法（随机森林、SVM、逻辑回归、LightGBM）的性能。采用特征选择、并行执行、随机搜索等TinyML技术进行模型优化。

Result: LightGBM在准确性和计算效率方面表现最优，适合实时入侵检测。最终开发出了优化的基于LightGBM的入侵检测系统。

Conclusion: 该研究成功展示了机器学习在政射检测系统安全中的应用潜力，LightGBM算法在DoS攻击检测中表现突出，为关键基础设施的安全保护提供了有效解决方案。

Abstract: Radiation Detection Systems (RDSs) are used to measure and detect abnormal
levels of radioactive material in the environment. These systems are used in
many applications to mitigate threats posed by high levels of radioactive
material. However, these systems lack protection against malicious external
attacks to modify the data. The novelty of applying Intrusion Detection Systems
(IDS) in RDSs is a crucial element in safeguarding these critical
infrastructures. While IDSs are widely used in networking environments to
safeguard against various attacks, their application in RDSs is novel. A common
attack on RDSs is Denial of Service (DoS), where the attacker aims to overwhelm
the system, causing malfunctioning RDSs. This paper proposes an efficient
Machine Learning (ML)-based IDS to detect anomalies in radiation data, focusing
on DoS attacks. This work explores the use of sampling methods to create a
simulated DoS attack based on a real radiation dataset, followed by an
evaluation of various ML algorithms, including Random Forest, Support Vector
Machine (SVM), logistic regression, and Light Gradient-Boosting Machine
(LightGBM), to detect DoS attacks on RDSs. LightGBM is emphasized for its
superior accuracy and low computational resource consumption, making it
particularly suitable for real-time intrusion detection. Additionally, model
optimization and TinyML techniques, including feature selection, parallel
execution, and random search methods, are used to improve the efficiency of the
proposed IDS. Finally, an optimized and efficient LightGBM-based IDS is
developed to achieve accurate intrusion detection for RDSs.

</details>


### [69] [AmphiKey: A Dual-Mode Secure Authenticated Key Encapsulation Protocol for Smart Grid](https://arxiv.org/abs/2509.01701)
*Kazi Hassan Shakib,Muhammad Asfand Hafeez,Arslan Munir*

Main category: cs.CR

TL;DR: AmphiKey是一个双模式后量子/传统混合认证密钥交换机制，为智能电网提供抗量子和传统攻击的安全通信，支持认证模式和可否认模式。


<details>
  <summary>Details</summary>
Motivation: 智能电网通信需要同时抵御传统和量子计算威胁，现有方案缺乏灵活性和效率，需要一种既能提供强认证又能支持隐私保护的混合解决方案。

Method: 采用混合设计：认证模式结合ML-KEM-768、X25519和Raccoon DSA提供前向安全性和不可否认认证；可否认模式提供隐私保护。使用Ascon密码算法，在异构测试平台上进行性能评估。

Result: 性能优异：可否认模式下完整握手在服务器仅需0.15ms，树莓派客户端0.41ms；认证模式下树莓派客户端签名生成耗时4.8ms，服务器验证0.84ms。

Conclusion: AmphiKey成功实现了灵活的双模式安全协议，为智能电网提供了高效的后量子安全解决方案，平衡了安全性、隐私性和性能需求。

Abstract: AmphiKey, a dual-mode post-quantum/traditional (PQ/T) hybrid authenticated
key exchange mechanism (AKEM) has been designed to secure smart grid
communications against both classical and quantum threats. AmphiKey offers two
distinct operational modes within a single framework: an Authenticated Mode and
a Deniable Mode. The Authenticated Mode employs a blackbox approach, combining
ephemeral ML-KEM-768 and X25519 with long-term Raccoon DSA keys to provide
forward secrecy and strong, non-repudiable authenticity. This design achieves
"OR" confidentiality, where security holds if either of the KEMs is unbroken,
and robust "AND" authenticity. For the signature operation, it leverages the
'masking-friendly' Raccoon digital signature (DSA), which is specifically
designed for side-channel attack resistance, though this protection is
localized to the signing key and does not provide deniability. In contrast,
Deniable Mode provides deniable authentication, preserving privacy. The
protocol used ML-KEM-768 (AKEM-1), Ephemeral X25519 (AKEM-2), Raccoon-based DSA
(Rac) (compared performance to ML-DSA-65), and the Ascon cipher to deliver its
security guarantees. Key contributions include providing a flexible protocol
with enhanced security, optional deniability, and efficiency adapted to the
diverse needs of the smart grid infrastructure. We present a comprehensive
performance evaluation on a heterogeneous testbed featuring a powerful server
and client (AMD Ryzen 5) and a resource-constrained client (Raspberry Pi). In
efficient Deniable mode, the full handshake completes in 0.15 ms on the server
and 0.41 ms on the Raspberry Pi client. In contrast, the Authenticated Mode is
bottlenecked by the client-side signature generation; the handshake takes 4.8
ms for the Raspberry Pi client to initiate and 0.84 ms for the server to
verify.

</details>


### [70] [Designing a Layered Framework to Secure Data via Improved Multi Stage Lightweight Cryptography in IoT Cloud Systems](https://arxiv.org/abs/2509.01717)
*Hojjat Farshadinia,Ali Barati,Hamid Barati*

Main category: cs.CR

TL;DR: 提出了一种新颖的多层混合安全方法，通过改进和整合TPA、区块链、ECDSA和ZSS等技术，为IoT-云系统提供轻量级加密解决方案，显著提升安全性、执行效率和系统响应能力。


<details>
  <summary>Details</summary>
Motivation: 传统解决方案如TPA、区块链、ECDSA和ZSS在数据保护、计算效率和可扩展性方面存在不足，需要一种更可靠、高性能的安全框架来支持异构环境下的安全数据交换。

Method: 采用三层核心架构：1)H.E.EZ层整合改进的Hyperledger Fabric、Enc-Block和混合ECDSA-ZSS方案；2)凭证管理层独立验证数据完整性和真实性；3)时间和审计层减少流量开销并优化动态工作负载性能。

Result: 评估结果表明，该解决方案不仅增强了安全性，还显著改善了执行时间、通信效率和系统响应能力。

Conclusion: 该框架为下一代IoT-云基础设施提供了一条稳健的发展路径，通过有效协调区块链、IoT和云计算等新兴技术的潜力，在安全架构方面取得了重要进展。

Abstract: This paper presents a novel multi-layered hybrid security approach aimed at
enhancing lightweight encryption for IoT-Cloud systems. The primary goal is to
overcome limitations inherent in conventional solutions such as TPA,
Blockchain, ECDSA and ZSS which often fall short in terms of data protection,
computational efficiency and scalability. Our proposed method strategically
refines and integrates these technologies to address their shortcomings while
maximizing their individual strengths. By doing so we create a more reliable
and high-performance framework for secure data exchange across heterogeneous
environments. The model leverages the combined potential of emerging
technologies, particularly Blockchain, IoT and Cloud computing which when
effectively coordinated offer significant advancements in security
architecture. The proposed framework consists of three core layers: (1) the
H.E.EZ Layer which integrates improved versions of Hyperledger Fabric,
Enc-Block and a hybrid ECDSA-ZSS scheme to improve encryption speed,
scalability and reduce computational cost; (2) the Credential Management Layer
independently verifying data integrity and authenticity; and (3) the Time and
Auditing Layer designed to reduce traffic overhead and optimize performance
across dynamic workloads. Evaluation results highlight that the proposed
solution not only strengthens security but also significantly improves
execution time, communication efficiency and system responsiveness, offering a
robust path forward for next-generation IoT-Cloud infrastructures.

</details>


### [71] [Are Enterprises Ready for Quantum-Safe Cybersecurity?](https://arxiv.org/abs/2509.01731)
*Tran Duc Le,Phuc Hao Do,Truong Duy Dinh,Van Dai Pham*

Main category: cs.CR

TL;DR: 论文分析企业量子安全准备情况，发现尽管PQC标准已成熟，但仅有不到5%的企业有正式量子迁移计划，建议立即建立加密敏捷性和过渡路线图。


<details>
  <summary>Details</summary>
Motivation: 量子计算威胁传统加密体系，需要评估企业在量子安全网络安全方面的准备程度，为数字化转型提供安全保障。

Method: 采用三重视角分析：技术专家视角评估PQC和QKD成熟度；企业视角分析组织意识和运营障碍；威胁行为者视角评估量子威胁紧迫性。结合SWOT分析综合评估。

Result: 企业准备度普遍不足且不均衡，PQC标准和QKD部署显示技术进步，但仅有少数企业有正式计划，多数行业因成本、复杂性和技能差距而停滞。

Conclusion: 建议立即采取行动：建立加密敏捷性、制定量子过渡路线图、优先在高价值系统部署PQC、提升网络安全团队技能，需要协调主动的方法来保护量子时代的数字资产。

Abstract: Quantum computing threatens to undermine classical cryptography by breaking
widely deployed encryption and signature schemes. This paper examines
enterprise readiness for quantum-safe cybersecurity through three perspectives:
(i) the technologist view, assessing the maturity of post-quantum cryptography
(PQC) and quantum key distribution (QKD); (ii) the enterprise (CISO/CIO) view,
analyzing organizational awareness, risk management, and operational barriers;
and (iii) the threat actor view, evaluating the evolving quantum threat and the
urgency of migration. Using recent standards (e.g., NIST's 2024 PQC
algorithms), industry surveys, and threat intelligence, we synthesize findings
via a SWOT analysis to map strengths, weaknesses, opportunities, and threats.
Results indicate uneven and generally insufficient preparedness: while PQC
standards and niche QKD deployments signal technical progress, fewer than 5\%
of enterprises have formal quantum-transition plans, and many underestimate
"harvest now, decrypt later" risks. Financial, telecom, and government sectors
have begun migration, but most industries remain exploratory or stalled by
costs, complexity, and skills gaps. Expert consensus places cryptanalytically
relevant quantum computers in the 2030s, yet delayed preparation could leave
today's data vulnerable for decades. We recommend immediate steps: establishing
crypto-agility, creating quantum transition roadmaps, prioritizing PQC
deployment in high-value systems, and upskilling cybersecurity teams. A
coordinated, proactive approach is essential to secure current and future
digital assets in the quantum era.

</details>


### [72] [BOLT: Bandwidth-Optimized Lightning-Fast Oblivious Map powered by Secure HBM Accelerators](https://arxiv.org/abs/2509.01742)
*Yitong Guo,Hongbo Chen,Haobin Hiroki Chen,Yukui Luo,XiaoFeng Wang,Chenghong Wang*

Main category: cs.CR

TL;DR: BOLT是一个基于HBM的OMAP加速器，通过利用隔离HBM作为不可观测缓存，实现了O(1) + O((log log N)^2)的带宽开销，相比现有OMAP方案获得高达279-480倍的性能提升


<details>
  <summary>Details</summary>
Motivation: 传统可信执行环境存在访问模式泄露漏洞，现有OMAP方案通过随机重映射和最坏情况填充来隐藏访问模式，但带来高昂开销。现代加速器的HBM特性提供了新的机会，可以将HBM转变为不可观测区域来隐藏数据和内存痕迹

Method: 提出BOLT系统，包含三个关键创新：1）新OMAP算法利用隔离HBM作为不可观测缓存加速对主内存的茫然访问；2）自托管架构将执行和内存控制从主机卸载以减轻CPU端泄露；3）算法-架构协同设计最大化资源效率

Result: 在Xilinx U55C FPGA上实现原型，评估显示BOLT在初始化和查询时间上分别比最先进的OMAP（包括Facebook的工业实现）快279倍和480倍

Conclusion: BOLT首次实现了近乎最优的带宽开销，通过HBM支持的解决方案克服了传统OMAP的性能限制，为安全云计算提供了高性能的访问模式保护方案

Abstract: While Trusted Execution Environments provide a strong foundation for secure
cloud computing, they remain vulnerable to access pattern leakages. Oblivious
Maps (OMAPs) mitigate this by fully hiding access patterns but suffer from high
overhead due to randomized remapping and worst-case padding. We argue these
costs are not fundamental. Modern accelerators featuring High-Bandwidth Memory
(HBM) offer a new opportunity: Vaswani et al. [OSDI'18] point out that
eavesdropping on HBM is difficult -- even for physical attackers -- as its
memory channels are sealed together with processor cores inside the same
physical package. Later, Hunt et al. [NSDI'20] show that, with proper
isolation, HBM can be turned into an unobservable region where both data and
memory traces are hidden. This motivates a rethink of OMAP design with
HBM-backed solutions to finally overcome their traditional performance limits.
Building on these insights, we present BOLT, a Bandwidth Optimized,
Lightning-fast OMAP accelerator that, for the first time, achieves O(1) +
O((log log N)^2) bandwidth overhead. BOLT introduces three key innovations: (i)
a new OMAP algorithm that leverages isolated HBM as an unobservable cache to
accelerate oblivious access to large host memory; (ii) a self-hosted
architecture that offloads execution and memory control from the host to
mitigate CPU-side leakage; and (iii) tailored algorithm-architecture co-designs
that maximize resource efficiency. We implement a prototype BOLT on a Xilinx
U55C FPGA. Evaluations show that BOLT achieves up to 279x and 480x speedups in
initialization and query time, respectively, over state-of-the-art OMAPs,
including an industry implementation from Facebook.

</details>


### [73] [E-PhishGen: Unlocking Novel Research in Phishing Email Detection](https://arxiv.org/abs/2509.01791)
*Luca Pajola,Eugenio Caripoti,Simeone Pizzi,Mauro Conti,Stefan Banzer,Giovanni Apruzzese*

Main category: cs.CR

TL;DR: 这篇论文对洗钱邮件检测领域进行了批判性评估，发现现有方法在不具代表性的数据集上达到近优性能，但在真实场景中表现差异。研究者提出了E-PhishGEN框架和E-PhishLLM数据集，以促进更具挑战性的测试标准。


<details>
  <summary>Details</summary>
Motivation: 虽然现有洗钱邮件检测方法在学术研究中报告了近优性能，但实际问题仍未解决。研究者认为现有数据集不代表当前趋势且以英语为主，导致方法评估不准确。

Method: 重新实现和评估多种机器学习检测方法（包括大语言模型），提出E-PhishGEN框架用于生成新的洗钱邮件数据集，并创建了包含三种语言的E-PhishLLM数据集。进行用户研究验证数据质量。

Result: 在现有数据集上检测方法达到近优性能，但在新的E-PhishLLM数据集上性能显著下降，说明现有方法存在显著缺陷。用户研究证实了新数据集的质量。

Conclusion: 洗钱邮件检测仍是个开放性问题，需要更具挑战性的测试标准。论文提供的E-PhishGEN框架和E-PhishLLM数据集为未来研究提供了解决方案。

Abstract: Every day, our inboxes are flooded with unsolicited emails, ranging between
annoying spam to more subtle phishing scams. Unfortunately, despite abundant
prior efforts proposing solutions achieving near-perfect accuracy, the reality
is that countering malicious emails still remains an unsolved dilemma.
  This "open problem" paper carries out a critical assessment of scientific
works in the context of phishing email detection. First, we focus on the
benchmark datasets that have been used to assess the methods proposed in
research. We find that most prior work relied on datasets containing emails
that -- we argue -- are not representative of current trends, and mostly
encompass the English language. Based on this finding, we then re-implement and
re-assess a variety of detection methods reliant on machine learning (ML),
including large-language models (LLM), and release all of our codebase -- an
(unfortunately) uncommon practice in related research. We show that most such
methods achieve near-perfect performance when trained and tested on the same
dataset -- a result which intrinsically hinders development (how can future
research outperform methods that are already near perfect?). To foster the
creation of "more challenging benchmarks" that reflect current phishing trends,
we propose E-PhishGEN, an LLM-based (and privacy-savvy) framework to generate
novel phishing-email datasets. We use our E-PhishGEN to create E-PhishLLM, a
novel phishing-email detection dataset containing 16616 emails in three
languages. We use E-PhishLLM to test the detectors we considered, showing a
much lower performance than that achieved on existing benchmarks -- indicating
a larger room for improvement. We also validate the quality of E-PhishLLM with
a user study (n=30). To sum up, we show that phishing email detection is still
an open problem -- and provide the means to tackle such a problem by future
research.

</details>


### [74] [From CVE Entries to Verifiable Exploits: An Automated Multi-Agent Framework for Reproducing CVEs](https://arxiv.org/abs/2509.01835)
*Saad Ullah,Praneeth Balasubramanian,Wenbo Guo,Amanda Burnett,Hammond Pearce,Christopher Kruegel,Giovanni Vigna,Gianluca Stringhini*

Main category: cs.CR

TL;DR: CVE-GENIE是一个基于大语言模型的多代理框架，能够自动化复现CVE漏洞并生成可验证的漏洞利用程序，成功复现了51%的2024-2025年CVE漏洞，平均每个CVE成本2.77美元。


<details>
  <summary>Details</summary>
Motivation: 高质量的漏洞数据集对软件安全研究至关重要，但创建这些数据集需要大量人工工作和深厚的安全专业知识，目前这类资源仍然稀缺。

Method: 使用基于大语言模型的多代理框架，输入CVE条目后自动收集相关资源、重建漏洞环境，并生成可验证的漏洞利用程序。

Result: 成功复现了841个2024-2025年CVE中的428个（51%），平均每个CVE成本为2.77美元，证明了框架的高效性和鲁棒性。

Conclusion: 该框架为生成可复现的CVE基准测试提供了强大方法，可用于模糊测试评估、漏洞修补和AI安全能力评估等多种应用。

Abstract: High-quality datasets of real-world vulnerabilities and their corresponding
verifiable exploits are crucial resources in software security research. Yet
such resources remain scarce, as their creation demands intensive manual effort
and deep security expertise. In this paper, we present CVE-GENIE, an automated,
large language model (LLM)-based multi-agent framework designed to reproduce
real-world vulnerabilities, provided in Common Vulnerabilities and Exposures
(CVE) format, to enable creation of high-quality vulnerability datasets. Given
a CVE entry as input, CVE-GENIE gathers the relevant resources of the CVE,
automatically reconstructs the vulnerable environment, and (re)produces a
verifiable exploit. Our systematic evaluation highlights the efficiency and
robustness of CVE-GENIE's design and successfully reproduces approximately 51%
(428 of 841) CVEs published in 2024-2025, complete with their verifiable
exploits, at an average cost of $2.77 per CVE. Our pipeline offers a robust
method to generate reproducible CVE benchmarks, valuable for diverse
applications such as fuzzer evaluation, vulnerability patching, and assessing
AI's security capabilities.

</details>


### [75] [Augmented Shuffle Differential Privacy Protocols for Large-Domain Categorical and Key-Value Data](https://arxiv.org/abs/2509.02004)
*Takao Murakami,Yuichi Sei,Reo Eriguchi*

Main category: cs.CR

TL;DR: 提出了FME协议，一种增强的shuffle DP协议，使用哈希过滤和多重加密技术，在保护隐私的同时高效处理大规模数据域和KV统计估计。


<details>
  <summary>Details</summary>
Motivation: 现有的shuffle DP协议容易受到合谋攻击和数据投毒攻击，且无法有效处理大规模数据域，通信和计算成本过高。

Method: 使用哈希函数过滤非热门项目，通过多重加密技术实现用户与混洗器之间的单轮交互，准确计算热门项目的频率，并扩展到KV统计估计。

Result: FME协议提供计算差分隐私、对攻击的高鲁棒性、高准确性和效率，在12个现有协议的比较中表现优异。

Conclusion: FME协议成功解决了大规模数据域下的隐私保护问题，在保持高隐私保护水平的同时实现了高效的通信和计算性能。

Abstract: Shuffle DP (Differential Privacy) protocols provide high accuracy and privacy
by introducing a shuffler who randomly shuffles data in a distributed system.
However, most shuffle DP protocols are vulnerable to two attacks: collusion
attacks by the data collector and users and data poisoning attacks. A recent
study addresses this issue by introducing an augmented shuffle DP protocol,
where users do not add noise and the shuffler performs random sampling and
dummy data addition. However, it focuses on frequency estimation over
categorical data with a small domain and cannot be applied to a large domain
due to prohibitively high communication and computational costs.
  In this paper, we fill this gap by introducing a novel augmented shuffle DP
protocol called the FME (Filtering-with-Multiple-Encryption) protocol. Our FME
protocol uses a hash function to filter out unpopular items and then accurately
calculates frequencies for popular items. To perform this within one round of
interaction between users and the shuffler, our protocol carefully communicates
within a system using multiple encryption. We also apply our FME protocol to
more advanced KV (Key-Value) statistics estimation with an additional technique
to reduce bias. For both categorical and KV data, we prove that our protocol
provides computational DP, high robustness to the above two attacks, accuracy,
and efficiency. We show the effectiveness of our proposals through comparisons
with twelve existing protocols.

</details>


### [76] [Targeted Physical Evasion Attacks in the Near-Infrared Domain](https://arxiv.org/abs/2509.02042)
*Pascal Zimmer,Simon Lachnit,Alexander Jan Zielinski,Ghassan Karame*

Main category: cs.CR

TL;DR: 提出了一种新颖、隐蔽且成本效益高的红外对抗扰动攻击方法，使用透明薄膜和现成红外手电筒投射扰动，首次实现无激光的定向红外攻击，攻击成功率更高且部署成本低于50美元。


<details>
  <summary>Details</summary>
Motivation: 现有红外攻击方法大多只能进行非定向攻击，且需要大量优化来适应特定使用场景约束（如位置和形状），限制了攻击的实用性和效果。

Method: 通过从透明薄膜投射扰动到目标物体上，使用现成的红外手电筒，生成定向和非定向的红外对抗扰动，实现无激光的可靠攻击。

Result: 在数字和物理领域的交通标志实验中，该方法在各种攻击场景（包括明亮光照条件、距离和角度）下表现出更高的攻击成功率和鲁棒性，部署成本低于50美元且仅需数十秒。

Conclusion: 该方法首次实现了可靠的无激光定向红外攻击，具有高成本效益和实用性，同时提出了基于分割的新型检测方法，F1分数高达99%，可有效防御此类攻击。

Abstract: A number of attacks rely on infrared light sources or heat-absorbing material
to imperceptibly fool systems into misinterpreting visual input in various
image recognition applications. However, almost all existing approaches can
only mount untargeted attacks and require heavy optimizations due to the
use-case-specific constraints, such as location and shape. In this paper, we
propose a novel, stealthy, and cost-effective attack to generate both targeted
and untargeted adversarial infrared perturbations. By projecting perturbations
from a transparent film onto the target object with an off-the-shelf infrared
flashlight, our approach is the first to reliably mount laser-free targeted
attacks in the infrared domain. Extensive experiments on traffic signs in the
digital and physical domains show that our approach is robust and yields higher
attack success rates in various attack scenarios across bright lighting
conditions, distances, and angles compared to prior work. Equally important,
our attack is highly cost-effective, requiring less than US\$50 and a few tens
of seconds for deployment. Finally, we propose a novel segmentation-based
detection that thwarts our attack with an F1-score of up to 99%.

</details>


### [77] [Forecasting Future DDoS Attacks Using Long Short Term Memory (LSTM) Model](https://arxiv.org/abs/2509.02076)
*Kong Mun Yeen,Rafidah Md Noor,Wahidah Md Shah,Aslinda Hassan,Muhammad Umair Munir*

Main category: cs.CR

TL;DR: 使用深度学习模型预测未来DDoS攻击，基于CRISP-DM数据挖掘标准流程，旨在通过趋势分析和更新数据集来制定攻击缓解计划


<details>
  <summary>Details</summary>
Motivation: 当前DDoS攻击预测研究相对有限，主要集中在检测方面。通过研究当前趋势并基于更新的数据集进行预测，可以更好地规划和制定攻击缓解策略

Method: 采用CRISP-DM（跨行业数据挖掘标准流程）模型，使用深度学习模型进行DDoS攻击预测

Result: 论文提出了基于深度学习的DDoS攻击预测方法，但具体预测准确率和性能指标未在摘要中明确说明

Conclusion: 深度学习模型可以用于DDoS攻击预测，基于CRISP-DM标准流程的方法有助于制定有效的攻击缓解计划，填补了现有研究中预测方面的不足

Abstract: This paper forecasts future Distributed Denial of Service (DDoS) attacks
using deep learning models. Although several studies address forecasting DDoS
attacks, they remain relatively limited compared to detection-focused research.
By studying the current trends and forecasting based on newer and updated
datasets, mitigation plans against the attacks can be planned and formulated.
The methodology used in this research work conforms to the Cross Industry
Standard Process for Data Mining (CRISP-DM) model.

</details>


### [78] [From Attack Descriptions to Vulnerabilities: A Sentence Transformer-Based Approach](https://arxiv.org/abs/2509.02077)
*Refat Othman,Diaeddin Rimawi,Bruno Rossi,Barbara Russo*

Main category: cs.CR

TL;DR: 评估14种最先进的句子转换器，用于从攻击文本描述中自动识别漏洞。MMPNet模型在使用攻击技术描述时表现最佳，F1分数达89.0。


<details>
  <summary>Details</summary>
Motivation: 安全领域中漏洞在被利用后仍经常未被检测到。手动将攻击映射到CVE漏洞不可行，需要自动化解决方案来提供及时的事件响应能力。

Method: 评估14种state-of-the-art句子转换器模型，使用攻击文本描述自动识别漏洞，重点关注多qa-mpnet-base-dot-v1(MMPNet)模型。

Result: MMPNet模型在使用攻击技术描述时达到F1分数89.0、精确率84.0、召回率94.7。56%的模型识别漏洞在CVE库中有攻击关联，61%对应CVE库中已编录漏洞。发现275个未在MITRE库中记录的预测链接。

Conclusion: 自动化链接攻击技术与漏洞不仅增强了软件安全事件的检测和响应能力，还减少了漏洞可利用的时间窗口，有助于构建更安全的系统。

Abstract: In the domain of security, vulnerabilities frequently remain undetected even
after their exploitation. In this work, vulnerabilities refer to publicly
disclosed flaws documented in Common Vulnerabilities and Exposures (CVE)
reports. Establishing a connection between attacks and vulnerabilities is
essential for enabling timely incident response, as it provides defenders with
immediate, actionable insights. However, manually mapping attacks to CVEs is
infeasible, thereby motivating the need for automation. This paper evaluates 14
state-of-the-art (SOTA) sentence transformers for automatically identifying
vulnerabilities from textual descriptions of attacks. Our results demonstrate
that the multi-qa-mpnet-base-dot-v1 (MMPNet) model achieves superior
classification performance when using attack Technique descriptions, with an
F1-score of 89.0, precision of 84.0, and recall of 94.7. Furthermore, it was
observed that, on average, 56% of the vulnerabilities identified by the MMPNet
model are also represented within the CVE repository in conjunction with an
attack, while 61% of the vulnerabilities detected by the model correspond to
those cataloged in the CVE repository. A manual inspection of the results
revealed the existence of 275 predicted links that were not documented in the
MITRE repositories. Consequently, the automation of linking attack techniques
to vulnerabilities not only enhances the detection and response capabilities
related to software security incidents but also diminishes the duration during
which vulnerabilities remain exploitable, thereby contributing to the
development of more secure systems.

</details>


### [79] [Performance analysis of common browser extensions for cryptojacking detection](https://arxiv.org/abs/2509.02083)
*Dmitry Tanana*

Main category: cs.CR

TL;DR: 这篇论文测试5款防止劫持挖矿的浏览器扩展程序，发现甚至最好的扩展也只能拦截27%攻击，而一些普遍使用的扩展完全无法检测劫持挖矿。


<details>
  <summary>Details</summary>
Motivation: 评估普通用户可用的浏览器扩展在防御劫持挖矿攻击方面的实际效果，因为劫持挖矿成为一种无手之力的网络威胁。

Method: 使用经验证的373个劫持挖矿网站数据集，测试5款普遍使用的Chromium浏览器扩展（MinerBlock、AdGuard、Easy Redirect、CoinEater、Miners Shield）的检测能力。

Result: 所有扩展表现差强：MinerBlock最好也只拦截27%网站，Easy Redirect和Miners Shield分别只拦截6个和5个网站，AdGuard和CoinEater完全无法检测任何劫持挖矿。

Conclusion: 当前面向普通用户的劫持挖矿防御工具存在严重缺陷，需要提升实验室级检测技术的易用性或对现有扩展进行根本性升级。

Abstract: This paper considers five extensions for Chromium-based browsers in order to
determine how effective can browser-based defenses against cryptojacking
available to regular users be. We've examined most popular extensions -
MinerBlock, AdGuard AdBlocker, Easy Redirect && Prevent Cryptojacking,
CoinEater and Miners Shield, which claim to be designed specifically to
identify and stop illegal cryptocurrency mining. An empirically confirmed
dataset of 373 distinct cryptojacking-infected websites which was assembled
during multi-stage procedure, was used to test those extensions. The results
showed that all plugins in question had significant performance limits. Easy
Redirect and Miners Shield only blocked 6 and 5 websites respectively, while
MinerBlock had the greatest detection rate at only 27% (101/373 sites blocked).
Most concerningly, despite promises of cryptojacking prevention, AdGuard (which
has over 13 million users) and CoinEater were unable to identify any of the
compromised websites. These results demonstrate serious flaws in cryptojacking
detection products targeted for regular users, since even the best-performing
specimen failed to detect 73% of attacks. The obvious difference between
advertised capabilities and real performance highlights the urgent need for
either accessibility improvements for laboratory-grade detection technologies
that show 90%+ efficiency in controlled environment or fundamental upgrades to
current commonly used extensions.

</details>


### [80] [A Gentle Introduction to Blind signatures: From RSA to Lattice-based Cryptography](https://arxiv.org/abs/2509.02189)
*Aditya Bhardwaj,Péter Kutas*

Main category: cs.CR

TL;DR: 本文综述了基于格的盲签名方案，从经典数字签名基础到量子安全的格基构造，旨在解决量子计算对传统密码系统的威胁。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算机的发展，传统密码系统的安全性受到威胁，需要开发量子安全的密码协议来保护数字交易和数据的隐私性，特别是在需要用户匿名性的应用场景中。

Method: 通过系统回顾盲签名的基础理论，从经典数字签名开始，逐步深入到基于格的构造方法，分析其安全性和实现机制。

Result: 提供了对格基盲签名方案的全面背景回顾，建立了从经典到量子安全密码协议的过渡框架。

Conclusion: 基于格的盲签名是构建量子安全密码系统的重要方向，对于保护电子投票、数字货币等需要匿名性的应用具有关键意义。

Abstract: Blind signatures were first introduced by David Chaum. They allow a user to
have a message signed by a signer without revealing the message itself. This
property is particularly useful in applications such as electronic voting and
digital cash, where user anonymity is important. In a blind signature scheme,
the user blinds their message before sending it to the signer, who signs the
blinded message. The user then unblinds the signed message to obtain a valid
signature that can be verified publicly, ensuring that the signer cannot trace
the signed message back to the original unblinded version. A good analogy is
placing the message inside an envelope and having the envelope signed. Once the
envelope is opened, the signature remains valid for the enclosed message,
ensuring that the content remains confidential.
  Such constructions provide anonymity and privacy to the user but given a
practical quantum computer, the security of traditional crypto-systems
providing such features will be broken. To address this, the development of
quantum-resistant cryptographic protocols is essential for maintaining the
security of digital transactions and data. Aligning with the same goal, this
work aims to thoroughly review the background of lattice-based blind
signatures. We start with the foundations of digital signatures in the
classical settings and then move on to lattice-based constructions.

</details>


### [81] [Passwords and FIDO2 Are Meant To Be Secret: A Practical Secure Authentication Channel for Web Browsers](https://arxiv.org/abs/2509.02289)
*Anuj Gautam,Tarun Yadav,Garrett Smith,Kent Seamons,Scott Ruoti*

Main category: cs.CR

TL;DR: 该论文提出并实现了两种防御机制，分别用于保护密码管理器的自动填充功能和FIDO2协议，防止XSS攻击和恶意浏览器扩展窃取敏感信息。


<details>
  <summary>Details</summary>
Motivation: 现有的密码管理器虽然提供安全优势，但恶意客户端脚本和浏览器扩展可以在密码自动填充后窃取密码。FIDO2协议也存在类似的本地攻击风险。

Method: 1. 在Firefox浏览器中实现密码自动填充加固机制；2. 设计并实现针对FIDO2协议的通用防御方案；3. 通过实验验证防御效果和网站兼容性。

Result: 1. 成功保护密码免受XSS攻击和恶意扩展窃取；2. 与Alexa top 1000网站中97%兼容；3. FIDO2防御方案对所有网站兼容，仅需服务器端少量代码修改。

Conclusion: 提出的两种防御机制有效解决了密码管理器和FIDO2协议的本地攻击漏洞，具有高兼容性和实用性，显著提升了Web认证安全性。

Abstract: Password managers provide significant security benefits to users. However,
malicious client-side scripts and browser extensions can steal passwords after
the manager has autofilled them into the web page. In this paper, we extend
prior work by Stock and Johns, showing how password autofill can be hardened to
prevent these local attacks. We implement our design in the Firefox browser and
conduct experiments demonstrating that our defense successfully protects
passwords from XSS attacks and malicious extensions. We also show that our
implementation is compatible with 97% of the Alexa top 1000 websites. Next, we
generalize our design, creating a second defense that prevents recently
discovered local attacks against the FIDO2 protocols. We implement this second
defense into Firefox, demonstrating that it protects the FIDO2 protocol against
XSS attacks and malicious extensions. This defense is compatible with all
websites, though it does require a small change (2-3 lines) to web servers
implementing FIDO2.

</details>


### [82] [Real-time ML-based Defense Against Malicious Payload in Reconfigurable Embedded Systems](https://arxiv.org/abs/2509.02387)
*Rye Stahle-Smith,Rasha Karakchi*

Main category: cs.CR

TL;DR: 通过机器学习方法直接分析FPGA位流文件的字节级特征，实现了高效的恶意代码检测，在资源受限系统上达到了0.97的F1分数。


<details>
  <summary>Details</summary>
Motivation: FPGA在可重构系统中的广泛使用带来了安全风险，恶意位流可能导致拒绝服务、数据泄漏或隐藏攻击。需要一种无需源代码或网表的实时检测方法。

Method: 采用监督学习方法，通过字节频率分析将位流向量化，使用TSVD进行压缩和SMOTE处理类别不平衡问题。基于Xilinx PYNQ-Z1开发板构建数据集，包含122个善意和恶意样本。

Result: Random Forest分类器达到了宏观F1分数0.97，显示出在资源受限系统上实现实时特漏程检测的可行性。

Conclusion: 该方法能够在不依赖源代码的情况下通过二进制分析有效检测恶意位流，最终模型成功部署到PYNQ平台上实现集成化分析。

Abstract: The growing use of FPGAs in reconfigurable systems introducessecurity risks
through malicious bitstreams that could cause denial-of-service (DoS), data
leakage, or covert attacks. We investigated chip-level hardware malicious
payload in embedded systems and proposed a supervised machine learning method
to detect malicious bitstreams via static byte-level features. Our approach
diverges from existing methods by analyzing bitstreams directly at the binary
level, enabling real-time detection without requiring access to source code or
netlists. Bitstreams were sourced from state-of-the-art (SOTA) benchmarks and
re-engineered to target the Xilinx PYNQ-Z1 FPGA Development Board. Our dataset
included 122 samples of benign and malicious configurations. The data were
vectorized using byte frequency analysis, compressed using TSVD, and balanced
using SMOTE to address class imbalance. The evaluated classifiers demonstrated
that Random Forest achieved a macro F1-score of 0.97, underscoring the
viability of real-time Trojan detection on resource-constrained systems. The
final model was serialized and successfully deployed via PYNQ to enable
integrated bitstream analysis.

</details>


### [83] [A Survey: Towards Privacy and Security in Mobile Large Language Models](https://arxiv.org/abs/2509.02411)
*Honghui Xu,Kaiyang Li,Wei Chen,Danyang Zheng,Zhiyuan Li,Zhipeng Cai*

Main category: cs.CR

TL;DR: 这篇论文系统性评估了移动大语言模型的隐私安全挑战，分析了差分隐私、联邦学习等解决方案，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 移动LLM在医疗、金融等领域带来便捷处理能力，但在资源受限环境中面临着严重的隐私安全挑战。

Method: 通过系统性调查和分析，对移动LLM的隐私安全问题进行分类，比较不同解决方案的效果和局限性。

Result: 识别了对抗性攻击、成员推断等独特漏洞，并对各种保护技术进行了详细评估。

Conclusion: 虽有进展，但移动LLM仍面临效率与安全的平衡挑战，需要进一步研究来建设可信赖的移动LLM系统。

Abstract: Mobile Large Language Models (LLMs) are revolutionizing diverse fields such
as healthcare, finance, and education with their ability to perform advanced
natural language processing tasks on-the-go. However, the deployment of these
models in mobile and edge environments introduces significant challenges
related to privacy and security due to their resource-intensive nature and the
sensitivity of the data they process. This survey provides a comprehensive
overview of privacy and security issues associated with mobile LLMs,
systematically categorizing existing solutions such as differential privacy,
federated learning, and prompt encryption. Furthermore, we analyze
vulnerabilities unique to mobile LLMs, including adversarial attacks,
membership inference, and side-channel attacks, offering an in-depth comparison
of their effectiveness and limitations. Despite recent advancements, mobile
LLMs face unique hurdles in achieving robust security while maintaining
efficiency in resource-constrained environments. To bridge this gap, we propose
potential applications, discuss open challenges, and suggest future research
directions, paving the way for the development of trustworthy,
privacy-compliant, and scalable mobile LLM systems.

</details>


### [84] [APEX: Automatic Event Sequence Generation for Android Applications](https://arxiv.org/abs/2509.02412)
*Wenhao Chen,Morris Chang,Witawas Srisa-an,Yong Guan*

Main category: cs.CR

TL;DR: APEX是一个基于符号执行的Android GUI测试框架，能够生成高代码覆盖率的事件序列和特定目标的事件序列


<details>
  <summary>Details</summary>
Motivation: Android GUI测试面临事件驱动和界面设计多样性的挑战，传统基于模型的方法在生成特定输入方面存在局限性

Method: 使用符号执行技术发现GUI状态转换的数据依赖关系，并在GUI探索过程中优先处理事件，构建更健壮的模型和准确的输入生成

Result: 实验结果表明APEX能够生成实现高代码覆盖率的事件序列，以及达到特定目标的事件序列

Conclusion: APEX通过系统化的符号执行方法有效解决了Android GUI测试中输入生成的挑战，提供了更全面和针对性的测试能力

Abstract: Due to the event driven nature and the versatility of GUI designs in Android
programs, it is challenging to generate event sequences with adequate code
coverage within a reasonable time. A common approach to handle this issue is to
rely on GUI models to generate event sequences. These sequences can be
effective in covering GUI states, but inconsistent in exposing program
behaviors that require specific inputs. A major obstacle to generate such
specific inputs is the lack of a systematic GUI exploration process to
accommodate the analysis requirements. In this paper, we introduce Android Path
Explorer (APEX), a systematic input generation framework using concolic
execution. APEX addresses the limitations of model-based sequence generation by
using concolic execution to discover the data dependencies of GUI state
transitions. Moreover, concolic execution is also used to prioritize events
during the exploration of GUI, which leads to a more robust model and accurate
input generation. The key novelty of APEX is that concolic execution is not
only used to construct event sequences, but also used to traverse the GUI more
systematically. As such, our experimental results show that APEX can be used to
generate a set of event sequences that achieve high code coverage, as well as
event sequences that reach specific targets.

</details>


### [85] [Enabling decision support over confidential data](https://arxiv.org/abs/2509.02413)
*Edoardo Marangone,Eugenio Nerio Nemmi,Daniele Friolo,Giuseppe Ateniese,Ingo Weber,Claudio Di Ciccio*

Main category: cs.CR

TL;DR: 通过信任执行环境(TEE)和加密技术构建了一种可验证、透明、保持数据保密性的自动化决策支持系统SPARTA


<details>
  <summary>Details</summary>
Motivation: 解决多方场景下分布式敏感数据决策过程中同时确保保密性、可验证性、透明性、完整性和一致性的挑战

Method: 采用信任执行环境(TEE)保护决策逻辑和数据，将决策规则编码为可验证软件对象，使用加密技术和用户可定义访问策略来维持结果保密性和信息完整性

Result: 在公开测试集和综合数据上进行实验，证明该方法具有实际应用性和可扩展性

Conclusion: SPARTA提供了一种有效的方案，能够在多方分布式敏感数据决策场景中同时满足多重安全和可靠性要求

Abstract: Enabling automated decision-making processes by leveraging data-driven
analysis is a core goal of Decision Support Systems (DSSs). In multi-party
scenarios where decisions rely on distributed and sensitive data, though,
ensuring confidentiality, verifiability, transparency, integrity, and
consistency at once remains an open challenge for DSSs. To tackle this
multi-faceted problem, we propose the Secure Platform for Automated decision
Rules via Trusted Applications (SPARTA) approach. By leveraging Trusted
Execution Environments (TEEs) at its core, SPARTA ensures that the decision
logic and the data remain protected. To guarantee transparency and consistency
of the decision process, SPARTA encodes decision rules into verifiable software
objects deployed within TEEs. To maintain the confidentiality of the outcomes
while keeping the information integrity, SPARTA employs cryptography techniques
on notarized data based on user-definable access policies. Based on experiments
conducted on public benchmarks and synthetic data, we find our approach to be
practically applicable and scalable.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [86] [A Comparative Study of Controllability, Explainability, and Performance in Dysfluency Detection Models](https://arxiv.org/abs/2509.00058)
*Eric Zhang,Li Wei,Sarah Chen,Michael Wang*

Main category: cs.AI

TL;DR: 本文对四种口吃检测方法(YOLO-Stutter、FluentNet、UDM、SSDM)进行了系统性比较分析，从性能、可控性和可解释性三个维度评估，发现UDM在准确性和临床可解释性方面达到最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 虽然口吃检测模型在基准数据集上的性能不断提升，但临床采用需要模型具备可控性和可解释性，而不仅仅是准确性。

Method: 通过在多数据集上的综合评估和临床专家评估，系统比较了四种代表性方法在性能、可控性和可解释性三个维度的表现。

Result: YOLO-Stutter和FluentNet提供效率和简单性但透明度有限；UDM在准确性和临床可解释性方面达到最佳平衡；SSDM在实验中无法完全复现。

Conclusion: 分析揭示了不同方法之间的权衡关系，为临床可行的口吃检测模型指明了未来发展方向，并提供了详细的实施见解和实际部署考虑。

Abstract: Recent advances in dysfluency detection have introduced a variety of modeling
paradigms, ranging from lightweight object-detection inspired networks
(YOLOStutter) to modular interpretable frameworks (UDM). While performance on
benchmark datasets continues to improve, clinical adoption requires more than
accuracy: models must be controllable and explainable. In this paper, we
present a systematic comparative analysis of four representative
approaches--YOLO-Stutter, FluentNet, UDM, and SSDM--along three dimensions:
performance, controllability, and explainability. Through comprehensive
evaluation on multiple datasets and expert clinician assessment, we find that
YOLO-Stutter and FluentNet provide efficiency and simplicity, but with limited
transparency; UDM achieves the best balance of accuracy and clinical
interpretability; and SSDM, while promising, could not be fully reproduced in
our experiments. Our analysis highlights the trade-offs among competing
approaches and identifies future directions for clinically viable dysfluency
modeling. We also provide detailed implementation insights and practical
deployment considerations for each approach.

</details>


### [87] [Beyond Memorization: Reasoning-Driven Synthesis as a Mitigation Strategy Against Benchmark Contamination](https://arxiv.org/abs/2509.00072)
*Terry Jingchen Zhang,Gopal Dev,Ning Wang,Nicole Ni,Wenyuan Jiang,Yinya Huang,Bernhard Schölkopf,Mrinmaya Sachan,Zhijing Jin*

Main category: cs.AI

TL;DR: 本研究通过从arXiv论文合成研究级QA问题，评估大语言模型在知识截止日期前后的性能表现，发现前沿模型并未出现显著的性能衰减，表明多步推理合成方法能有效缓解基准污染问题。


<details>
  <summary>Details</summary>
Motivation: 由于数据污染问题日益严重，静态基准测试是否真正衡量了推理能力而非记忆能力受到质疑，需要新的评估方法来验证LLMs的真实推理能力。

Method: 利用arXiv论文的自然时间结构，从20,277篇论文中合成1,643个多步推理问题，覆盖知识截止日期前后至少6个月的时间范围，评估4个前沿模型家族的代表模型。

Result: 结果显示不同规模、开发者和发布日期的模型在知识截止日期附近均未出现显著性能衰减，与之前使用公开数据直接检索问题的纵向研究结果形成对比。

Conclusion: 多步推理合成方法提供了超越浅层记忆的额外复杂性，能有效缓解基准污染，建议优先采用推理驱动的合成方法来构建基准测试而非简单收集新发布的问题。

Abstract: Capability evaluation of large language models (LLMs) is increasingly
shadowed by rising concerns of data contamination that cast doubts on whether
static benchmarks measure genuine reasoning or mere memorization. We present an
empirical study using an infinitely scalable framework to synthesize
research-level QA directly from arXiv papers, harnessing the natural temporal
structure of research publications where performance decay after knowledge
cutoffs may indicate potential contamination. We evaluated 4 frontier model
represented by 2 models of different knowledge cutoff dates per family on 1,643
multi-step reasoning questions synthesized from 20,277 arXiv papers stratified
over 26 months, covering at least 6 months before and after all cutoff dates.
Our results consistently showed a lack of significant performance decay near
knowledge cutoff dates for models of various sizes, developers, and release
dates. We further performed a comparative analysis with previous longitudinal
studies that reported significant post-cutoff performance decay using directly
retrieved questions based on public data. we hypothesize that the multi-step
reasoning required by our synthesis pipeline offered additional complexity that
goes deeper than shallow memorization, which effectively serves a mitigation
strategy against benchmark contamination. We fully open source our code and
dataset to aid reproducibility and advocate for a paradigm shift that
prioritize reasoning-driven synthesis to construct benchmarks over simply
collecting newly released questions periodically.

</details>


### [88] [Language and Experience: A Computational Model of Social Learning in Complex Tasks](https://arxiv.org/abs/2509.00074)
*Cédric Colas,Tracey Mills,Ben Prystawski,Michael Henry Tessler,Noah Goodman,Jacob Andreas,Joshua Tenenbaum*

Main category: cs.AI

TL;DR: 该研究提出了一个计算框架，通过将预训练语言模型转化为概率模型，实现社会学习中的语言指导与直接经验的整合，加速学习和知识传递。


<details>
  <summary>Details</summary>
Motivation: 人类能够结合他人语言指导和直接经验进行安全快速学习，研究旨在探索这种整合机制并应用于AI系统，实现人机协作学习。

Method: 使用联合概率推理框架，将预训练语言模型转化为基于信念的条件概率模型，通过贝叶斯推理处理感觉运动和语言数据，在10个视频游戏中进行行为实验和模拟。

Result: 语言指导能够塑造探索行为、加速学习过程，减少风险交互并促进关键发现，实现了跨代知识积累和成功的人机知识传递。

Conclusion: 结构化、语言兼容的表征能够实现人机协作学习，为构建能够整合语言指导和直接经验的AI系统提供了计算框架和实证支持。

Abstract: The ability to combine linguistic guidance from others with direct experience
is central to human development, enabling safe and rapid learning in new
environments. How do people integrate these two sources of knowledge, and how
might AI systems? We present a computational framework that models social
learning as joint probabilistic inference over structured, executable world
models given sensorimotor and linguistic data. We make this possible by turning
a pretrained language model into a probabilistic model of how humans share
advice conditioned on their beliefs, allowing our agents both to generate
advice for others and to interpret linguistic input as evidence during Bayesian
inference. Using behavioral experiments and simulations across 10 video games,
we show how linguistic guidance can shape exploration and accelerate learning
by reducing risky interactions and speeding up key discoveries in both humans
and models. We further explore how knowledge can accumulate across generations
through iterated learning experiments and demonstrate successful knowledge
transfer between humans and models -- revealing how structured,
language-compatible representations might enable human-machine collaborative
learning.

</details>


### [89] [Entropy-Guided Loop: Achieving Reasoning through Uncertainty-Aware Generation](https://arxiv.org/abs/2509.00079)
*Andrew G. A. Correa,Ana C. H de Matos*

Main category: cs.AI

TL;DR: 提出基于熵引导的轻量级推理循环方法，使用token级不确定性触发单次定向精炼，在保持低成本的同时显著提升小模型性能


<details>
  <summary>Details</summary>
Motivation: 解决大型推理模型成本高、延迟大的问题，寻求在单次推理和昂贵推理链之间的有效折中方案

Method: 提取logprobs计算香农熵，使用困惑度、最大token熵和低置信度token计数的OR逻辑触发机制，将紧凑的不确定性报告反馈给模型指导修正

Result: 小模型配合该方法可达到参考推理模型95%的质量，成本降低约三分之二，在31%的响应上实现选择性精炼，准确率提升16个百分点

Conclusion: 该方法为生产部署提供了质量和成本兼顾的实用解决方案，是不确定性感知推理的有效中间方案

Abstract: Reasoning models often outperform smaller models but at 3--5$\times$ higher
cost and added latency. We present entropy-guided refinement: a lightweight,
test-time loop that uses token-level uncertainty to trigger a single, targeted
refinement pass. We extract logprobs, compute Shannon entropy on top-$k$
alternatives, and apply a simple OR-logic trigger over perplexity, maximum
token entropy, and low-confidence-token count. Unlike approaches that use
entropy only for measurement or decoding, we pass a compact uncertainty report
(tokens, confidences, alternatives, context) back to the model to guide
corrective edits. On representative technical queries across reasoning,
mathematics, and code generation tasks, a small model with our loop approaches
95\% of a reference reasoning model's quality at approximately one-third of the
cost. The method achieves selective refinement on ~31\% of responses while
improving accuracy by 16 percentage points over single-pass inference. We
demonstrate that this uncertainty-aware loop provides an effective middle
ground between single-pass inference and expensive reasoning chains, making it
practical for production deployments where both quality and cost matter.

</details>


### [90] [Wrong Face, Wrong Move: The Social Dynamics of Emotion Misperception in Agent-Based Models](https://arxiv.org/abs/2509.00080)
*David Freire-Obregón*

Main category: cs.AI

TL;DR: 研究通过模拟代理使用不同准确度的情绪分类器，发现低准确度会导致信任降低、情绪崩溃和社会组织混乱，而高准确度则能形成稳定的情绪集群和抗干扰能力。


<details>
  <summary>Details</summary>
Motivation: 探索情绪感知准确性对社交行为的影响，研究人类情绪识别能力在社会互动中的重要性。

Method: 在2D环面网格上部署代理，使用基于JAFFE、CK+、KDEF数据集训练的不同准确度情绪分类器，代理根据感知到的邻居情绪进行移动（趋近积极情绪，远离消极情绪）。

Result: 低准确度分类器导致信任降低、情绪崩溃为悲伤、社会组织混乱；高准确度分类器形成稳定的情绪集群和情绪干扰抗性；即使在情绪中性场景中，误感知也会导致隔离和凝聚力瓦解。

Conclusion: 情绪识别中的偏见或不精确可能显著扭曲社会过程并破坏情绪整合，强调了准确情绪感知对社会行为的重要性。

Abstract: The ability of humans to detect and respond to others' emotions is
fundamental to understanding social behavior. Here, agents are instantiated
with emotion classifiers of varying accuracy to study the impact of perceptual
accuracy on emergent emotional and spatial behavior. Agents are visually
represented with face photos from the KDEF database and endowed with one of
three classifiers trained on the JAFFE (poor), CK+ (medium), or KDEF (high)
datasets. Agents communicate locally on a 2D toroidal lattice, perceiving
neighbors' emotional state based on their classifier and responding with
movement toward perceived positive emotions and away from perceived negative
emotions. Note that the agents respond to perceived, instead of ground-truth,
emotions, introducing systematic misperception and frustration. A battery of
experiments is carried out on homogeneous and heterogeneous populations and
scenarios with repeated emotional shocks. Results show that low-accuracy
classifiers on the part of the agent reliably result in diminished trust,
emotional disintegration into sadness, and disordered social organization. By
contrast, the agent that develops high accuracy develops hardy emotional
clusters and resilience to emotional disruptions. Even in emotionally neutral
scenarios, misperception is enough to generate segregation and disintegration
of cohesion. These findings underscore the fact that biases or imprecision in
emotion recognition may significantly warp social processes and disrupt
emotional integration.

</details>


### [91] [Ensemble Debates with Local Large Language Models for AI Alignment](https://arxiv.org/abs/2509.00091)
*Ephraiem Sarabamoun*

Main category: cs.AI

TL;DR: 本地开源模型集成辩论能显著提升AI对齐能力，在推理深度和论证质量方面分别提升19.4%和34.1%，特别是在真实性和人类增强方面表现最佳


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在重要决策中扮演更重要的角色，需要确保其与人类价值观对齐。依赖专有API限制了研究的可复现性和广泛参与

Method: 使用本地开源模型进行集成辩论，在150场辩论中覆盖15个场景和5种集成配置，采用7点评分标准进行评估

Result: 集成模型在7点评分标准上整体表现优于单模型基线（3.48 vs 3.13），在真实性方面提升最大（+1.25分），人类增强方面提升0.8分

Conclusion: 集成辩论为基于集成的对齐评估提供了可访问且可复现的基础，证明了本地开源模型在提升AI对齐能力方面的有效性

Abstract: As large language models (LLMs) take on greater roles in high-stakes
decisions, alignment with human values is essential. Reliance on proprietary
APIs limits reproducibility and broad participation. We study whether local
open-source ensemble debates can improve alignmentoriented reasoning. Across
150 debates spanning 15 scenarios and five ensemble configurations, ensembles
outperform single-model baselines on a 7-point rubric (overall: 3.48 vs. 3.13),
with the largest gains in reasoning depth (+19.4%) and argument quality
(+34.1%). Improvements are strongest for truthfulness (+1.25 points) and human
enhancement (+0.80). We provide code, prompts, and a debate data set, providing
an accessible and reproducible foundation for ensemble-based alignment
evaluation.

</details>


### [92] [MODE: Mixture of Document Experts for RAG](https://arxiv.org/abs/2509.00100)
*Rahul Anand*

Main category: cs.AI

TL;DR: MODE提出了一种轻量级的检索增强生成方法，用聚类路由检索替代精细的最近邻搜索，在小型领域特定语料库上实现高效检索


<details>
  <summary>Details</summary>
Motivation: 传统的RAG方法依赖大型向量数据库和跨编码器，对于小型领域特定语料库来说过于复杂和冗余，需要更轻量级的解决方案

Method: 将文档嵌入后分组到语义连贯的聚类中，用缓存质心表示。查询时路由到顶部质心，仅在这些聚类内检索上下文，无需外部向量数据库基础设施和重排序

Result: 在HotpotQA和SQuAD语料库（100-500个块）上，MODE在答案质量上匹配或超过密集检索基线，同时减少端到端检索时间

Conclusion: MODE为中小型语料库提供了一个实用的解决方案，在简单性、速度和主题聚焦方面具有优势，聚类粒度和多聚类路由控制召回率/精确度的权衡

Abstract: Retrieval-Augmented Generation (RAG) often relies on large vector databases
and cross-encoders tuned for large-scale corpora, which can be excessive for
small, domain-specific collections. We present MODE (Mixture of Document
Experts), a lightweight alternative that replaces fine-grained nearest-neighbor
search with cluster-and-route retrieval. Documents are embedded, grouped into
semantically coherent clusters, and represented by cached centroids. At query
time, we route to the top centroid(s) and retrieve context only within those
clusters, eliminating external vector-database infrastructure and reranking
while keeping latency low. On HotpotQA and SQuAD corpora with 100-500 chunks,
MODE matches or exceeds a dense-retrieval baseline in answer quality while
reducing end-to-end retrieval time. Ablations show that cluster granularity and
multi-cluster routing control the recall/precision trade-off, and that tighter
clusters improve downstream accuracy. MODE offers a practical recipe for small
and medium corpora where simplicity, speed, and topical focus matter.

</details>


### [93] [Adaptive Monitoring and Real-World Evaluation of Agentic AI Systems](https://arxiv.org/abs/2509.00115)
*Manish Shukla*

Main category: cs.AI

TL;DR: 本文提出了一个自适应多维监控算法(AMDM)，用于改进多智能体AI系统的评估，通过标准化指标和异常检测来减少误报率和延迟。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体AI系统评估主要关注技术指标，缺乏对人类中心和经济维度的考量，需要更全面的监控框架。

Method: 开发了AMDM算法，包括指标标准化、指数加权移动平均阈值和基于马氏距离的联合异常检测。

Result: AMDM将异常检测延迟从12.3秒降至5.6秒，误报率从4.5%降至0.9%，在模拟和真实实验中表现优异。

Conclusion: AMDM算法有效提升了多智能体AI系统的监控性能，提供了更全面的评估框架，有助于实际部署中的安全性和可靠性。

Abstract: Agentic artificial intelligence (AI) -- multi-agent systems that combine
large language models with external tools and autonomous planning -- are
rapidly transitioning from research laboratories into high-stakes domains. Our
earlier "Basic" paper introduced a five-axis framework and proposed preliminary
metrics such as goal drift and harm reduction but did not provide an
algorithmic instantiation or empirical evidence. This "Advanced" sequel fills
that gap. First, we revisit recent benchmarks and industrial deployments to
show that technical metrics still dominate evaluations: a systematic review of
84 papers from 2023--2025 found that 83% report capability metrics while only
30% consider human-centred or economic axes [2]. Second, we formalise an
Adaptive Multi-Dimensional Monitoring (AMDM) algorithm that normalises
heterogeneous metrics, applies per-axis exponentially weighted moving-average
thresholds and performs joint anomaly detection via the Mahalanobis distance.
Third, we conduct simulations and real-world experiments. AMDM cuts
anomaly-detection latency from 12.3 s to 5.6 s on simulated goal drift and
reduces false-positive rates from 4.5% to 0.9% compared with static thresholds.
We present a comparison table and ROC/PR curves, and we reanalyse case studies
to surface missing metrics. Code, data and a reproducibility checklist
accompany this paper to facilitate replication.

</details>


### [94] [Know When to Explore: Difficulty-Aware Certainty as a Guide for LLM Reinforcement Learning](https://arxiv.org/abs/2509.00125)
*Ang Li,Zhihang Yuan,Yang Zhang,Shouda Liu,Yisen Wang*

Main category: cs.AI

TL;DR: DACE算法通过利用LLM的自信心与任务难度的相关性，动态调整探索-利用平衡，在数学推理任务上显著优于基线方法


<details>
  <summary>Details</summary>
Motivation: 传统RLVF依赖稀疏的结果奖励，无法为推理过程提供细粒度指导，限制了学习效率

Method: 提出Difficulty Aware Certainty guided Exploration (DACE)算法，在线评估任务难度并基于模型自信心动态调整内在奖励机制

Result: 在AIME和MATH等数学推理基准测试中显著优于强基线，模型不仅准确率更高，而且在测试时计算扩展时表现更稳健

Conclusion: DACE的自适应方法能够促进有效探索而不牺牲精度，验证了利用模型自信心指导强化学习的有效性

Abstract: Reinforcement Learning with Verifiable Feedback (RLVF) has become a key
technique for enhancing the reasoning abilities of Large Language Models
(LLMs). However, its reliance on sparse, outcome based rewards, which only
indicate if a final answer is correct or not, fails to provide granular
guidance on the reasoning process itself. This limitation hinders efficient
learning, as the model cannot distinguish between high quality and inefficient
solutions, nor can it learn effectively from different types of failures. To
address this, we observe that an LLMs self-certainty often correlates with task
difficulty and solution quality. We introduce Difficulty Aware Certainty guided
Exploration (DACE), a novel RL algorithm that leverages this insight to
dynamically balance the exploration exploitation trade-off. DACE assesses task
difficulty online based on the policys success rate. It then uses this signal
to modulate an intrinsic reward: for difficult tasks where the model is
struggling, DACE encourages exploration by penalizing high certainty; for
easier tasks, it encourages learning efficiency by rewarding high certainty.
Experiments on challenging mathematical reasoning benchmarks (AIME, MATH) show
that DACE significantly outperforms strong baselines. The DACE-trained models
not only achieve higher accuracy but also demonstrate more robust performance
when scaling test-time compute, validating that our adaptive approach fosters
effective exploration without sacrificing precision.

</details>


### [95] [Optimizing Health Coverage in Ethiopia: A Learning-augmented Approach and Persistent Proportionality Under an Online Budget](https://arxiv.org/abs/2509.00135)
*Davin Choo,Yohai Trabelsi,Fentabil Getnet,Samson Warkaye Lamma,Wondesen Nigatu,Kasahun Sime,Lisa Matay,Milind Tambe,Stéphane Verguet*

Main category: cs.AI

TL;DR: 基于优化框架的健康访问资源规划工具(HARP)，通过学习增强和贪心算法在预算不确定性下最大化人口覆盖率，满足区域比例分配目标。


<details>
  <summary>Details</summary>
Motivation: 埃塞俄比亚在实现联合国可持续发展目标3的过程中，因预算和优先级竞争而无法完全强化健康网点，需要优化框架来指导区域间的优先级分配。

Method: 开发了HARP工具，基于原则性的决策支持优化框架，提出两种算法：(1)学习增强方法在单步优化专家建议；(2)贪心算法用于多步规划，两者都具有强的最差情况近似估计。

Result: 与埃塞俄比亚公共健康研究所和卫生部合作，在三个区域的多种规划场景下验证了方法的实践效果。

Conclusion: HARP工具提供了一种有效的序列设施规划方法，能够在预算不确定性下最大化人口健康服务覆盖率，同时保证区域间的比例分配公平性。

Abstract: As part of nationwide efforts aligned with the United Nations' Sustainable
Development Goal 3 on Universal Health Coverage, Ethiopia's Ministry of Health
is strengthening health posts to expand access to essential healthcare
services. However, only a fraction of this health system strengthening effort
can be implemented each year due to limited budgets and other competing
priorities, thus the need for an optimization framework to guide prioritization
across the regions of Ethiopia. In this paper, we develop a tool, Health Access
Resource Planner (HARP), based on a principled decision-support optimization
framework for sequential facility planning that aims to maximize population
coverage under budget uncertainty while satisfying region-specific
proportionality targets at every time step. We then propose two algorithms: (i)
a learning-augmented approach that improves upon expert recommendations at any
single-step; and (ii) a greedy algorithm for multi-step planning, both with
strong worst-case approximation estimation. In collaboration with the Ethiopian
Public Health Institute and Ministry of Health, we demonstrated the empirical
efficacy of our method on three regions across various planning scenarios.

</details>


### [96] [Virtual Group Knowledge and Group Belief in Topological Evidence Models (Extended Version)](https://arxiv.org/abs/2509.00184)
*Alexandru Baltag,Malvin Gattinger,Djanira Gomes*

Main category: cs.AI

TL;DR: 本文研究多智能体证据模型中的群体知识和信念概念，通过将基于证据的信念和可错知识从个体扩展到群体，建立了完整的逻辑公理化系统并证明了可判定性。


<details>
  <summary>Details</summary>
Motivation: 研究如何将个体层面的证据基础信念和知识概念扩展到群体层面，探索群体知识和信念的形式化逻辑框架。

Method: 采用拓扑语义学方法，扩展个体证据模型到多智能体系统，建立群体证据逻辑系统，并引入动态证据共享算子。

Result: 完全公理化了群体证据逻辑（包括硬证据和软证据），证明了其可判定性；特别对群体知识和信念片段进行了完整公理化；扩展的动态证据共享逻辑与静态基础具有同等表达能力。

Conclusion: 成功建立了群体证据、知识和信念的完整逻辑框架，证明了相关逻辑系统的可判定性和表达能力，为多智能体系统中的群体认知提供了形式化基础。

Abstract: We study notions of (virtual) group knowledge and group belief within
multi-agent evidence models, obtained by extending the topological semantics of
evidence-based belief and fallible knowledge from individuals to groups. We
completely axiomatize and show the decidability of the logic of ("hard" and
"soft") group evidence, and do the same for an especially interesting fragment
of it: the logic of group knowledge and group belief. We also extend these
languages with dynamic evidence-sharing operators, and completely axiomatize
the corresponding logics, showing that they are co-expressive with their static
bases.

</details>


### [97] [HiVA: Self-organized Hierarchical Variable Agent via Goal-driven Semantic-Topological Evolution](https://arxiv.org/abs/2509.00189)
*Jinzhou Tang,Jusheng Zhang,Qinhan Lv,Sidi Liu,Jing Yang,Chengpei Tang,Keze Wang*

Main category: cs.AI

TL;DR: HiVA是一个新型自主代理框架，通过语义-拓扑演化算法将工作流建模为自组织图，解决了现有方法在固定工作流和灵活反应循环之间的权衡问题，在多个基准测试中实现了5-10%的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 现有自主代理范式面临关键权衡：可重用的固定工作流需要手动重新配置，而灵活的响应循环无法将推理进展提炼为可转移结构。需要一种既能适应环境变化又能保持结构化的解决方案。

Method: 提出分层变量代理(HiVA)框架，使用语义-拓扑演化(STEV)算法将代理工作流建模为自组织图。该算法利用文本梯度作为离散域的反向传播替代，通过多臂老虎机前向路由、环境反馈生成诊断梯度以及协调更新来共同优化语义和拓扑。

Result: 在对话、编码、长上下文问答、数学和代理基准测试中，HiVA相比现有基线实现了5-10%的任务准确率提升，并展现出更好的资源效率。

Conclusion: HiVA框架通过自组织图建模和语义-拓扑协同演化，有效解决了自主代理在未知环境中的任务执行问题，为人工通用智能的发展提供了新的技术路径。

Abstract: Autonomous agents play a crucial role in advancing Artificial General
Intelligence, enabling problem decomposition and tool orchestration through
Large Language Models (LLMs). However, existing paradigms face a critical
trade-off. On one hand, reusable fixed workflows require manual reconfiguration
upon environmental changes; on the other hand, flexible reactive loops fail to
distill reasoning progress into transferable structures. We introduce
Hierarchical Variable Agent (HiVA), a novel framework modeling agentic
workflows as self-organized graphs with the Semantic-Topological Evolution
(STEV) algorithm, which optimizes hybrid semantic-topological spaces using
textual gradients as discrete-domain surrogates for backpropagation. The
iterative process comprises Multi-Armed Bandit-infused forward routing,
diagnostic gradient generation from environmental feedback, and coordinated
updates that co-evolve individual semantics and topology for collective
optimization in unknown environments. Experiments on dialogue, coding,
Long-context Q&A, mathematical, and agentic benchmarks demonstrate improvements
of 5-10% in task accuracy and enhanced resource efficiency over existing
baselines, establishing HiVA's effectiveness in autonomous task execution.

</details>


### [98] [Universal Deep Research: Bring Your Own Model and Strategy](https://arxiv.org/abs/2509.00244)
*Peter Belcak,Pavlo Molchanov*

Main category: cs.AI

TL;DR: 提出了Universal Deep Research (UDR)系统，这是一个通用的深度研究代理系统，允许用户创建、编辑和精炼自定义的研究策略，无需额外训练或微调。


<details>
  <summary>Details</summary>
Motivation: 现有的深度研究代理系统都是硬编码的，使用固定的研究策略和工具选择，缺乏灵活性和可定制性。

Method: 开发了UDR系统，该系统可以包装任何语言模型，提供用户界面来创建和实验不同的研究策略（最小化、扩展性和密集型）。

Result: UDR系统展示了其通用性，能够支持多种研究策略，为用户提供了灵活的研究工具定制能力。

Conclusion: UDR系统为深度研究代理提供了更高的灵活性和可定制性，使用户能够根据自己的需求设计和优化研究策略。

Abstract: Deep research tools are among the most impactful and most commonly
encountered agentic systems today. We observe, however, that each deep research
agent introduced so far is hard-coded to carry out a particular research
strategy using a fixed choice of tools. We introduce Universal Deep Research
(UDR), a generalist agentic system that wraps around any language model and
enables the user to create, edit, and refine their own entirely custom deep
research strategies without any need for additional training or finetuning. To
showcase the generality of our system, we equip UDR with example minimal,
expansive, and intensive research strategies, and provide a user interface to
facilitate experimentation with the system.

</details>


### [99] [Instruction-Level Weight Shaping: A Framework for Self-Improving AI Agents](https://arxiv.org/abs/2509.00251)
*Rimom Costa*

Main category: cs.AI

TL;DR: ILWS通过指令级权重塑形，使用可审计的伪参数和反射引擎动态更新LLM知识，避免了RAG的高延迟和微调的灾难性遗忘问题，在企业支持场景中显著提升了吞吐量和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统LLM在预训练后是静态的，新知识需要通过RAG或微调添加，但这些方法存在延迟高、工程复杂、知识整合失败、灾难性遗忘等问题，需要一种更高效动态的知识更新机制。

Method: 提出Instruction-Level Weight Shaping (ILWS)：使用系统指令作为外部可审计伪参数，通过反射引擎分析对话轨迹，生成类型化增量ΔK=(ΔS,ΔU,ΔT)来更新指令、用户偏好和工具，并通过受控蒸馏将提示空间改进转换为权重空间。

Result: 在企业支持场景中，吞吐量提升2.4-5.0倍，审计幻觉减少约80%；在Adobe Commerce Cloud概念验证中，每小时处理工单数提升4-5倍，单工单时间降低约80%，支持自主指令更新和工具合成。

Conclusion: ILWS在指令层操作直到受控蒸馏，适用于需要自适应推理、工具创建和低延迟部署的动态领域（法律、医疗、工程），提供了可治理的知识更新机制。

Abstract: Large language models (LLMs) are fluent but largely static after
pre-training; new or shifting knowledge is typically added with
retrieval-augmented generation (RAG) or fine-tuning. RAG raises latency and
engineering overhead and often fails to integrate facts; prompt engineering is
brittle and can conflict with prior knowledge; fine-tuning is costly and risks
catastrophic forgetting. We propose Instruction-Level Weight Shaping (ILWS):
curated system instructions act as external, auditable pseudo-parameters
updated after each session via reflection and user feedback. A Reflection
Engine inspects conversation traces, diagnoses reasoning successes and
failures, and proposes typed deltas $\Delta K=(\Delta S,\Delta U,\Delta T)$
over instructions, user preferences, and tools. Deltas are version-controlled,
evaluated with a sliding window of 1-5 star ratings, auto-repaired on first
failure, and rolled back on repeated failure. When an edit budget crosses a
threshold, the agent compiles a rating-weighted synthetic set and distills
matured instruction-space gains into parameters, converting prompt-space
improvements into weight-space without downtime. ILWS makes explicit the
low-rank shaping induced by context in transformer blocks, preserves
governance, and removes per-call retrieval. In enterprise support it increased
throughput 2.4-5.0x and cut audited hallucinations by about 80% versus a frozen
baseline. In an Adobe Commerce Cloud proof of concept "L0 Support", it achieved
4-5x more tickets per hour and about 80% lower time per ticket, with autonomous
instruction updates and optional tool synthesis. Because ILWS operates at the
instruction layer until controlled distillation, it generalizes to dynamic
domains (legal, medical, engineering) requiring adaptive reasoning, tool
creation, and low-latency deployment.

</details>


### [100] [SHERPA: A Model-Driven Framework for Large Language Model Execution](https://arxiv.org/abs/2509.00272)
*Boqi Chen,Kua Chen,José Antonio Hernández López,Gunter Mussbacher,Dániel Varró,Amir Feizpour*

Main category: cs.AI

TL;DR: SHERPA是一个模型驱动框架，通过将领域特定最佳实践融入分层状态机来提升LLM在复杂任务中的性能，实现对LLM行为的细粒度控制。


<details>
  <summary>Details</summary>
Motivation: 当前LLM虽然能力强大，但缺乏结构化推理能力，特别是在需要领域特定最佳实践的复杂任务中。现有的多步提示方法缺乏通用机制来控制LLM行为。

Method: 提出SHERPA框架，使用分层状态机结构化LLM执行过程，通过基于规则的或机器学习驱动的方法（包括LLM本身）来实现对行为的细粒度控制。

Result: 在代码生成、类名生成和问答等多种任务上，SHERPA不仅复现了先前方法的性能，还进一步提升了表现。系统评估显示，精心设计的状态机显著提高了LLM输出质量。

Conclusion: SHERPA框架特别适用于具有完善人类最佳实践但缺乏训练数据的复杂任务，通过状态机集成能够有效提升LLM性能。

Abstract: Recently, large language models (LLMs) have achieved widespread application
across various fields. Despite their impressive capabilities, LLMs suffer from
a lack of structured reasoning ability, particularly for complex tasks
requiring domain-specific best practices, which are often unavailable in the
training data. Although multi-step prompting methods incorporating human best
practices, such as chain-of-thought and tree-of-thought, have gained
popularity, they lack a general mechanism to control LLM behavior. In this
paper, we propose SHERPA, a model-driven framework to improve the LLM
performance on complex tasks by explicitly incorporating domain-specific best
practices into hierarchical state machines. By structuring the LLM execution
processes using state machines, SHERPA enables more fine-grained control over
their behavior via rules or decisions driven by machine learning-based
approaches, including LLMs. We show that SHERPA is applicable to a wide variety
of tasks-specifically, code generation, class name generation, and question
answering-replicating previously proposed approaches while further improving
the performance. We demonstrate the effectiveness of SHERPA for the
aforementioned tasks using various LLMs. Our systematic evaluation compares
different state machine configurations against baseline approaches without
state machines. Results show that integrating well-designed state machines
significantly improves the quality of LLM outputs, and is particularly
beneficial for complex tasks with well-established human best practices but
lacking data used for training LLMs.

</details>


### [101] [SIGMUS: Semantic Integration for Knowledge Graphs in Multimodal Urban Spaces](https://arxiv.org/abs/2509.00287)
*Brian Wang,Mani Srivastava*

Main category: cs.AI

TL;DR: SIGMUS系统利用大语言模型自动整合城市多模态传感器数据，构建知识图谱来识别和推理城市事件，无需依赖人工规则。


<details>
  <summary>Details</summary>
Motivation: 现代城市传感器产生大量多模态数据，但数据分散且难以整合，需要人工推理来识别事件与多模态数据之间的关系，这限制了事件识别和预测的效率。

Method: 开发SIGMUS系统，使用大语言模型生成必要的世界知识，识别城市事件与多模态数据之间的关系，并将组织化的知识表示为知识图谱。

Result: 系统能够合理连接5种不同数据源（新闻文本、监控图像、空气质量、天气和交通测量）与同时同地发生的相关事件。

Conclusion: SIGMUS系统通过LLM驱动的知识图谱构建，成功实现了城市多模态数据的自动语义集成，为城市事件识别和预测提供了有效解决方案。

Abstract: Modern urban spaces are equipped with an increasingly diverse set of sensors,
all producing an abundance of multimodal data. Such multimodal data can be used
to identify and reason about important incidents occurring in urban landscapes,
such as major emergencies, cultural and social events, as well as natural
disasters. However, such data may be fragmented over several sources and
difficult to integrate due to the reliance on human-driven reasoning for
identifying relationships between the multimodal data corresponding to an
incident, as well as understanding the different components which define an
incident. Such relationships and components are critical to identifying the
causes of such incidents, as well as producing forecasting the scale and
intensity of future incidents as they begin to develop. In this work, we create
SIGMUS, a system for Semantic Integration for Knowledge Graphs in Multimodal
Urban Spaces. SIGMUS uses Large Language Models (LLMs) to produce the necessary
world knowledge for identifying relationships between incidents occurring in
urban spaces and data from different modalities, allowing us to organize
evidence and observations relevant to an incident without relying and
human-encoded rules for relating multimodal sensory data with incidents. This
organized knowledge is represented as a knowledge graph, organizing incidents,
observations, and much more. We find that our system is able to produce
reasonable connections between 5 different data sources (new article text, CCTV
images, air quality, weather, and traffic measurements) and relevant incidents
occurring at the same time and location.

</details>


### [102] [NEWSAGENT: Benchmarking Multimodal Agents as Journalists with Real-World Newswriting Tasks](https://arxiv.org/abs/2509.00446)
*Yen-Che Chien,Kuang-Da Wang,Wei-Yao Wang,Wen-Chih Peng*

Main category: cs.AI

TL;DR: NEWSAGENT是一个评估自主代理在新闻写作中处理多模态网络数据能力的基准测试，包含6000个人工验证的真实新闻案例，测试显示代理能检索相关事实但在规划和叙事整合方面存在困难。


<details>
  <summary>Details</summary>
Motivation: 研究自主代理系统在多模态网络数据生产力方面的提升潜力，特别是在需要迭代规划、解释和上下文推理的新闻写作领域。

Method: 引入NEWSAGENT基准测试，包含6k个人工验证的真实新闻案例，将多模态内容转换为文本以广泛兼容模型，评估开源和闭源LLM在常用代理框架上的表现。

Result: 代理能够检索相关事实，但在规划和叙事整合方面表现不佳，反映了现实世界新闻写作中面临的信息差距挑战。

Conclusion: NEWSAGENT为迭代和评估代理在多模态网络数据操作方面的能力提供了一个现实的测试平台，有助于推动自主代理在真实世界生产力应用中的发展。

Abstract: Recent advances in autonomous digital agents from industry (e.g., Manus AI
and Gemini's research mode) highlight potential for structured tasks by
autonomous decision-making and task decomposition; however, it remains unclear
to what extent the agent-based systems can improve multimodal web data
productivity. We study this in the realm of journalism, which requires
iterative planning, interpretation, and contextual reasoning from multimodal
raw contents to form a well structured news. We introduce NEWSAGENT, a
benchmark for evaluating how agents can automatically search available raw
contents, select desired information, and edit and rephrase to form a news
article by accessing core journalistic functions. Given a writing instruction
and firsthand data as how a journalist initiates a news draft, agents are
tasked to identify narrative perspectives, issue keyword-based queries,
retrieve historical background, and generate complete articles. Unlike typical
summarization or retrieval tasks, essential context is not directly available
and must be actively discovered, reflecting the information gaps faced in
real-world news writing. NEWSAGENT includes 6k human-verified examples derived
from real news, with multimodal contents converted to text for broad model
compatibility. We evaluate open- and closed-sourced LLMs with commonly-used
agentic frameworks on NEWSAGENT, which shows that agents are capable of
retrieving relevant facts but struggling with planning and narrative
integration. We believe that NEWSAGENT serves a realistic testbed for iterating
and evaluating agent capabilities in terms of multimodal web data manipulation
to real-world productivity.

</details>


### [103] [Multi-Agent Data Visualization and Narrative Generation](https://arxiv.org/abs/2509.00481)
*Anton Wolter,Georgios Vidalakis,Michael Yu,Ankit Grover,Vaishali Dhanoa*

Main category: cs.AI

TL;DR: 提出了一种轻量级多智能体系统，用于自动化数据分析工作流，从数据探索到生成连贯的可视化叙述，支持可持续的人机协作。


<details>
  <summary>Details</summary>
Motivation: AI智能体领域的进展影响了工作方式，多智能体系统可以在数据可视化领域的数据到通信全流程中发挥作用，实现更高效的自动化和人机协作。

Method: 采用混合多智能体架构与确定性组件相结合的方法，将关键逻辑从LLM中外部化以提高透明度和可靠性，提供模块化输出支持局部修改。

Result: 在4个不同数据集上评估，展示了强大的泛化能力、叙述质量和计算效率，且依赖项最少。

Conclusion: 该系统成功实现了从数据探索到洞察沟通的自动化工作流，通过外部化关键逻辑提高了系统的透明度和可靠性，支持可持续的人机协作。

Abstract: Recent advancements in the field of AI agents have impacted the way we work,
enabling greater automation and collaboration between humans and agents. In the
data visualization field, multi-agent systems can be useful for employing
agents throughout the entire data-to-communication pipeline. We present a
lightweight multi-agent system that automates the data analysis workflow, from
data exploration to generating coherent visual narratives for insight
communication. Our approach combines a hybrid multi-agent architecture with
deterministic components, strategically externalizing critical logic from LLMs
to improve transparency and reliability. The system delivers granular, modular
outputs that enable surgical modifications without full regeneration,
supporting sustainable human-AI collaboration. We evaluated our system across 4
diverse datasets, demonstrating strong generalizability, narrative quality, and
computational efficiency with minimal dependencies.

</details>


### [104] [Artificial Intelligence-Based Analysis of Ice Cream Melting Behavior Under Various Ingredients](https://arxiv.org/abs/2509.00507)
*Zhang Lai Bin,Zhen Bin It*

Main category: cs.AI

TL;DR: 本研究探讨了刺槐豆胶、瓜尔胶、麦芽糊精和卡拉胶对自制冰淇淋融化行为的影响，通过计算机视觉分析发现这些稳定剂能形成稳定的气泡基质结构，提高冰淇淋的融化抗性和结构韧性。


<details>
  <summary>Details</summary>
Motivation: 冰淇淋的融化稳定性是影响消费者接受度和产品质量的关键因素，需要研究不同稳定剂对融化行为的影响，并寻找更具成本效益的配方方案。

Method: 制备含不同添加剂的冰淇淋样品，在受控条件下进行融化测试，使用延时摄影记录融化过程，并利用Python和OpenCV进行图像处理和分析。

Result: 所有样品融化后仍保持泡沫状结构，表明稳定剂有助于形成稳定的气泡基质；重新冷冻后再融化的样品显示出更强的结构韧性；不同稳定剂的效果存在差异。

Conclusion: 研究揭示了常用食品添加剂在冰淇淋配方中的功能作用，通过评估性能和成本，证明了开发平衡耐用性和经济效率的配方的潜力，对小型和商业冰淇淋生产具有实际应用价值。

Abstract: The stability of ice cream during melting is a critical factor for consumer's
acceptance and product quality. With the commonly added stabilizer to improve
texture, structure and slower melting as the factors to analyze. This report
explores the effects of locust bean gum, guar gum, maltodextrin, and
carrageenan on the melting behavior of homemade ice cream. The main objective
was to assess how these additives influence melting resistance and to identify
a more cost-effective recipe formulation. Ice cream samples incorporating each
additive were prepared and subjected to melting tests under controlled
conditions. Timelapse recordings were used to capture and analyze the
progression of melting over time. Python and OpenCV is used for process and
analysis. Observations revealed that all samples retained a foam-like structure
even after melting, suggesting the stabilizers contributed to the formation of
a stable air-cell matrix. Furthermore, when the melted samples were re-frozen
and subsequently melted again, they displayed increased sturdiness, indicating
improved resilience of the ice cream structure. Comparative analysis of the
different stabilizers highlighted variations in their effectiveness, with some
offering stronger melting resistance and structural support than others.
Overall, the findings provide insights into the functional roles of commonly
used food additives in ice cream formulation. By evaluating both performance
and cost, this study demonstrates the potential for developing recipes that
balance durability with economic efficiency, contributing to practical
applications in both small-scale and commercial ice cream production.

</details>


### [105] [LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain](https://arxiv.org/abs/2509.00510)
*Li Weigang,Pedro Carvalho Brom,Lucas Ramson Siefert*

Main category: cs.AI

TL;DR: 提出了SuperBrain框架，通过LLM与人类用户的协同进化实现集体智能，包含从子类大脑到超类大脑的动态演化路径


<details>
  <summary>Details</summary>
Motivation: 解决静态提示工程和孤立智能体模拟的局限性，构建动态、可扩展且符合伦理的集体人工智能系统

Method: 四阶段方法：1)用户与LLM形成认知二元组；2)遗传算法辅助的前向-后向进化；3)群体智能协调；4)标准化行为整合为超类大脑

Result: 提出了理论框架和初步实现（如无人机调度、关键词过滤），建立了跨二元组知识整合的注册机制

Conclusion: 为可扩展、可解释且符合伦理的集体AI提供了概念基础和架构路线图

Abstract: We propose a novel SuperBrain framework for collective intelligence, grounded
in the co-evolution of large language models (LLMs) and human users. Unlike
static prompt engineering or isolated agent simulations, our approach
emphasizes a dynamic pathway from Subclass Brain to Superclass Brain: (1) A
Subclass Brain arises from persistent, personalized interaction between a user
and an LLM, forming a cognitive dyad with adaptive learning memory. (2) Through
GA-assisted forward-backward evolution, these dyads iteratively refine prompts
and task performance. (3) Multiple Subclass Brains coordinate via Swarm
Intelligence, optimizing across multi-objective fitness landscapes and
exchanging distilled heuristics. (4) Their standardized behaviors and cognitive
signatures integrate into a Superclass Brain, an emergent meta-intelligence
capable of abstraction, generalization and self-improvement. We outline the
theoretical constructs, present initial implementations (e.g., UAV scheduling,
KU/KI keyword filtering) and propose a registry for cross-dyad knowledge
consolidation. This work provides both a conceptual foundation and an
architectural roadmap toward scalable, explainable and ethically aligned
collective AI.

</details>


### [106] [Text-to-Layout: A Generative Workflow for Drafting Architectural Floor Plans Using LLMs](https://arxiv.org/abs/2509.00543)
*Jayakrishna Duggempudi,Lu Gao,Ahmed Senouci,Zhe Han,Yunpeng Zhang*

Main category: cs.AI

TL;DR: 开发了一个基于大语言模型的AI工作流，能够从自然语言提示自动生成建筑平面图草稿，包括墙体、门窗和家具布局，并与Revit等设计工具兼容。


<details>
  <summary>Details</summary>
Motivation: 为了解决建筑设计过程中从概念到具体平面图转换的效率问题，减少手动绘图工作量，提高设计自动化水平。

Method: 结合提示工程、家具布置优化算法和Python脚本，通过自然语言输入解释生成空间连贯的布局方案，并确保输出与Revit原生参数化属性兼容。

Result: 案例研究表明，该系统能够以最少的人工投入生成功能性和结构化的住宅布局方案，所有关键提示规范都已文档化以便复制。

Conclusion: 该工作流实现了从文本描述到专业BIM模型的无缝转换，为建筑设计自动化提供了可行的解决方案，具有透明可复制的特点。

Abstract: This paper presents the development of an AI-powered workflow that uses Large
Language Models (LLMs) to assist in drafting schematic architectural floor
plans from natural language prompts. The proposed system interprets textual
input to automatically generate layout options including walls, doors, windows,
and furniture arrangements. It combines prompt engineering, a furniture
placement refinement algorithm, and Python scripting to produce spatially
coherent draft plans compatible with design tools such as Autodesk Revit. A
case study of a mid-sized residential layout demonstrates the approach's
ability to generate functional and structured outputs with minimal manual
effort. The workflow is designed for transparent replication, with all key
prompt specifications documented to enable independent implementation by other
researchers. In addition, the generated models preserve the full range of
Revit-native parametric attributes required for direct integration into
professional BIM processes.

</details>


### [107] [Social World Models](https://arxiv.org/abs/2509.00559)
*Xuhui Zhou,Jiarui Liu,Akhila Yerukola,Hyunwoo Kim,Maarten Sap*

Main category: cs.AI

TL;DR: 提出了S3AP结构化社会世界表示形式，帮助AI系统更好地推理社交动态，在5个社交推理任务中显著提升性能，达到新的SOTA水平


<details>
  <summary>Details</summary>
Motivation: 人类能够直觉地模拟未言明的动态并推理他人视角，而AI系统在自动构建和推理这些隐式社交语境方面存在困难

Method: 采用POMDP驱动的设计，将社交互动表示为结构化元组（状态、观察、代理行为、心理状态），可以从自由形式叙述中自动推导

Result: 在FANToM的心理理论推理任务上提升51%，在SOTOPIA社交互动基准上提升18%，达到新的最先进性能

Conclusion: S3AP作为一种强大的通用社交世界状态表示形式，有望开发出更具社交意识的系统，更好地导航社交互动

Abstract: Humans intuitively navigate social interactions by simulating unspoken
dynamics and reasoning about others' perspectives, even with limited
information. In contrast, AI systems struggle to automatically structure and
reason about these implicit social contexts. In this paper, we introduce a
novel structured social world representation formalism (S3AP), designed to help
AI systems reason more effectively about social dynamics. Following a
POMDP-driven design, S3AP represents social interactions as structured tuples,
such as state, observation, agent actions, and mental states, which can be
automatically induced from free-form narratives or other inputs. We first show
S3AP can help LLMs better understand social narratives across 5 social
reasoning tasks (e.g., +51% improvement on FANToM's theory-of-mind reasoning
with OpenAI's o1), reaching new state-of-the-art (SOTA) performance. We then
induce social world models from these structured representations, demonstrating
their ability to predict future social dynamics and improve agent
decision-making, yielding up to +18% improvement on the SOTOPIA social
interaction benchmark. Our findings highlight the promise of S3AP as a
powerful, general-purpose representation for social world states, enabling the
development of more socially-aware systems that better navigate social
interactions.

</details>


### [108] [BALM-TSF: Balanced Multimodal Alignment for LLM-Based Time Series Forecasting](https://arxiv.org/abs/2509.00622)
*Shiqiao Zhou,Holger Schöner,Huanbo Lyu,Edouard Fouché,Shuo Wang*

Main category: cs.AI

TL;DR: BALM-TSF是一个轻量级的多模态时间序列预测框架，通过平衡文本和时间序列模态的对齐来解决现有方法中模态不平衡问题，在长期和少样本预测中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的多模态时间序列预测方法存在模态不平衡问题，往往过度强调文本模态而忽视时间序列模态，导致信息损失和预测性能下降。

Method: 使用时间序列编码器处理原始时间序列，同时将时间序列的描述性统计特征输入大语言模型生成文本嵌入。通过缩放策略和对比学习目标将文本嵌入映射到时间序列嵌入的潜在空间，实现跨模态平衡对齐。

Result: 在标准基准测试中，BALM-TSF以最少的可训练参数实现了长期和少样本预测的最先进性能，证明了其有效利用文本和时间序列互补信息的能力。

Conclusion: BALM-TSF通过平衡的多模态对齐机制成功解决了时间序列预测中的模态不平衡问题，为多模态时间序列预测提供了有效的解决方案。

Abstract: Time series forecasting is a long-standing and highly challenging research
topic. Recently, driven by the rise of large language models (LLMs), research
has increasingly shifted from purely time series methods toward harnessing
textual modalities to enhance forecasting performance. However, the vast
discrepancy between text and temporal data often leads current multimodal
architectures to over-emphasise one modality while neglecting the other,
resulting in information loss that harms forecasting performance. To address
this modality imbalance, we introduce BALM-TSF (Balanced Multimodal Alignment
for LLM-Based Time Series Forecasting), a lightweight time series forecasting
framework that maintains balance between the two modalities. Specifically, raw
time series are processed by the time series encoder, while descriptive
statistics of raw time series are fed to an LLM with learnable prompt,
producing compact textual embeddings. To ensure balanced cross-modal context
alignment of time series and textual embeddings, a simple yet effective scaling
strategy combined with a contrastive objective then maps these textual
embeddings into the latent space of the time series embeddings. Finally, the
aligned textual semantic embeddings and time series embeddings are together
integrated for forecasting. Extensive experiments on standard benchmarks show
that, with minimal trainable parameters, BALM-TSF achieves state-of-the-art
performance in both long-term and few-shot forecasting, confirming its ability
to harness complementary information from text and time series. Code is
available at https://github.com/ShiqiaoZhou/BALM-TSF.

</details>


### [109] [NetGent: Agent-Based Automation of Network Application Workflows](https://arxiv.org/abs/2509.00625)
*Jaber Daneshamooz,Eugene Vuong,Laasya Koduru,Sanjay Chandrasekaran,Arpit Gupta*

Main category: cs.AI

TL;DR: NetGent是一个AI代理框架，通过自然语言规则定义工作流，自动生成真实网络流量数据集，解决了现有浏览器自动化工具在多样性、可重复性、真实性和效率方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 开发通用ML网络模型需要从多样化真实网络环境中收集数据，但现有浏览器自动化工具脆弱且成本高昂，难以满足需求。

Method: 用户用自然语言规则定义状态依赖动作，框架将其编译为非确定性有限自动机(NFA)，通过状态合成转换为可执行代码，支持确定性重放和状态缓存减少LLM调用。

Result: 成功自动化50+个工作流，涵盖视频点播、直播、视频会议、社交媒体和网络爬虫，生成真实流量轨迹，对UI变化具有鲁棒性。

Conclusion: NetGent结合基于语言的灵活性和编译执行的可靠性，为生成多样化、可重复数据集提供了可扩展基础，推动网络ML发展。

Abstract: We present NetGent, an AI-agent framework for automating complex application
workflows to generate realistic network traffic datasets. Developing
generalizable ML models for networking requires data collection from network
environments with traffic that results from a diverse set of real-world web
applications. However, using existing browser automation tools that are
diverse, repeatable, realistic, and efficient remains fragile and costly.
NetGent addresses this challenge by allowing users to specify workflows as
natural-language rules that define state-dependent actions. These abstract
specifications are compiled into nondeterministic finite automata (NFAs), which
a state synthesis component translates into reusable, executable code. This
design enables deterministic replay, reduces redundant LLM calls through state
caching, and adapts quickly when application interfaces change. In experiments,
NetGent automated more than 50+ workflows spanning video-on-demand streaming,
live video streaming, video conferencing, social media, and web scraping,
producing realistic traffic traces while remaining robust to UI variability. By
combining the flexibility of language-based agents with the reliability of
compiled execution, NetGent provides a scalable foundation for generating the
diverse, repeatable datasets needed to advance ML in networking.

</details>


### [110] [On Verifiable Legal Reasoning: A Multi-Agent Framework with Formalized Knowledge Representations](https://arxiv.org/abs/2509.00710)
*Albert Sadowski,Jarosław A. Chudziak*

Main category: cs.AI

TL;DR: 提出模块化多智能体框架，将法律推理分解为知识获取和应用两个阶段，通过符号推理和程序化实现显著提升法律AI系统的透明度和准确性


<details>
  <summary>Details</summary>
Motivation: 法律推理需要精确解释法律条文和一致应用复杂规则，这对AI系统构成重大挑战，需要解决端到端方法缺乏透明度的问题

Method: 采用模块化多智能体框架：第一阶段由专门智能体提取法律概念并形式化规则；第二阶段通过查询分析、符号推理和程序化实现三个步骤应用知识到具体案例

Result: 在法定税务计算任务上，基础模型准确率达到76.4%，相比基线18.8%有显著提升，有效缩小了推理模型与基础模型之间的性能差距

Conclusion: 模块化架构和形式化知识表示可以使复杂的法律推理通过计算高效模型实现，同时增强AI法律推理的一致性和可解释性，为未来更透明、可信和有效的法律AI系统奠定基础

Abstract: Legal reasoning requires both precise interpretation of statutory language
and consistent application of complex rules, presenting significant challenges
for AI systems. This paper introduces a modular multi-agent framework that
decomposes legal reasoning into distinct knowledge acquisition and application
stages. In the first stage, specialized agents extract legal concepts and
formalize rules to create verifiable intermediate representations of statutes.
The second stage applies this knowledge to specific cases through three steps:
analyzing queries to map case facts onto the ontology schema, performing
symbolic inference to derive logically entailed conclusions, and generating
final answers using a programmatic implementation that operationalizes the
ontological knowledge. This bridging of natural language understanding with
symbolic reasoning provides explicit and verifiable inspection points,
significantly enhancing transparency compared to end-to-end approaches.
Evaluation on statutory tax calculation tasks demonstrates substantial
improvements, with foundational models achieving 76.4\% accuracy compared to
18.8\% baseline performance, effectively narrowing the performance gap between
reasoning and foundational models. These findings suggest that modular
architectures with formalized knowledge representations can make sophisticated
legal reasoning more accessible through computationally efficient models while
enhancing consistency and explainability in AI legal reasoning, establishing a
foundation for future research into more transparent, trustworthy, and
effective AI systems for legal domain.

</details>


### [111] [When Agents go Astray: Course-Correcting SWE Agents with PRMs](https://arxiv.org/abs/2509.02360)
*Shubham Gandhi,Jason Tsay,Jatin Ganhotra,Kiran Kate,Yara Rizk*

Main category: cs.AI

TL;DR: SWE-PRM是一个推理时过程奖励模型，通过检测和纠正LLM代理在软件工程任务中的轨迹错误，提高任务解决率和效率


<details>
  <summary>Details</summary>
Motivation: LLM代理在复杂软件工程任务中经常出现冗余探索、循环和无法终止等低效行为，现有方法只能在执行后诊断错误

Method: 引入SWE-PRM过程奖励模型，基于常见低效行为的分类法，在执行过程中提供轻量级、可解释的反馈，不修改底层策略

Result: 在SWE-bench Verified上，解决率从40.0%提升到50.6%（+10.6个百分点），中高难度任务提升最大，轨迹长度减少，推理成本仅增加0.2美元

Conclusion: PRM是提高SWE代理可靠性和效率的实用可扩展机制，分类法引导的PRM优于无引导或明确指令的变体

Abstract: Large Language Model (LLM) agents are increasingly deployed for complex,
multi-step software engineering (SWE) tasks. However, their trajectories often
contain costly inefficiencies, such as redundant exploration, looping, and
failure to terminate once a solution is reached. Prior work has largely treated
these errors in a post-hoc manner, diagnosing failures only after execution. In
this paper, we introduce SWE-PRM, an inference-time Process Reward Model (PRM)
that intervenes during execution to detect and course-correct trajectory-level
errors. Our PRM design leverages a taxonomy of common inefficiencies and
delivers lightweight, interpretable feedback without modifying the underlying
policy. On SWE-bench Verified, closed-source PRMs improve resolution from 40.0%
to 50.6% (+10.6 p.p.), with the largest gains on medium and hard tasks. Among
feedback strategies, taxonomy-guided PRMs outperform unguided or explicit
action-prescriptive variants, increasing success rate while reducing trajectory
length. These benefits come at an acceptable added inference cost of as low as
$0.2, making PRMs a practical and scalable mechanism for improving SWE agents'
reliability and efficiency.

</details>


### [112] [OmniDPO: A Preference Optimization Framework to Address Omni-Modal Hallucination](https://arxiv.org/abs/2509.00723)
*Junzhe Chen,Tianshu Zhang,Shiyu Huang,Yuwei Niu,Chao Sun,Rongzhou Zhang,Guanyu Zhou,Lijie Wen,Xuming Hu*

Main category: cs.AI

TL;DR: OmniDPO是一个针对全模态大语言模型(OLLMs)的偏好对齐框架，通过构建文本偏好和多模态偏好样本对来解决幻觉问题，增强模型对音频-视频交互的理解和注意力。


<details>
  <summary>Details</summary>
Motivation: 现有的OLLMs存在幻觉问题，文本模态先验占主导地位，导致模型过度依赖文本线索而忽视视觉和音频信息。同时，现有模型在训练时独立对齐各模态，忽略了视频与音频之间的内在关联。

Method: 提出OmniDPO框架，包含两种策略：(1)构建文本偏好样本对以增强对音频-视频交互的理解；(2)构建多模态偏好样本对以加强对视觉和听觉信息的注意力。

Result: 在两个OLLMs上的实验表明，OmniDPO不仅有效缓解了多模态幻觉问题，还显著提升了模型跨模态的推理能力。

Conclusion: OmniDPO通过同时解决文本主导和模态间关联缺失两个挑战，有效改善了多模态基础能力并减少了幻觉现象。

Abstract: Recently, Omni-modal large language models (OLLMs) have sparked a new wave of
research, achieving impressive results in tasks such as audio-video
understanding and real-time environment perception. However, hallucination
issues still persist. Similar to the bimodal setting, the priors from the text
modality tend to dominate, leading OLLMs to rely more heavily on textual cues
while neglecting visual and audio information. In addition, fully multimodal
scenarios introduce new challenges. Most existing models align visual or
auditory modalities with text independently during training, while ignoring the
intrinsic correlations between video and its corresponding audio. This
oversight results in hallucinations when reasoning requires interpreting hidden
audio cues embedded in video content. To address these challenges, we propose
OmniDPO, a preference-alignment framework designed to mitigate hallucinations
in OLLMs. Specifically, OmniDPO incorporates two strategies: (1) constructing
text-preference sample pairs to enhance the model's understanding of
audio-video interactions; and (2) constructing multimodal-preference sample
pairs to strengthen the model's attention to visual and auditory information.
By tackling both challenges, OmniDPO effectively improves multimodal grounding
and reduces hallucination. Experiments conducted on two OLLMs demonstrate that
OmniDPO not only effectively mitigates multimodal hallucinations but also
significantly enhances the models' reasoning capabilities across modalities.
All code and datasets will be released upon paper acceptance.

</details>


### [113] [Efficient Graph Understanding with LLMs via Structured Context Injection](https://arxiv.org/abs/2509.00740)
*Govind Waghmare,Sumedh BG,Sonia Gupta,Srikanta Bedathur*

Main category: cs.AI

TL;DR: 这篇论文提出了一种结构化上下文注入框架，通过在LLM输入中系统地嵌入任务特定信息来提升图论论任务性能，无需微调且成本低廉。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM在各领域都显示出强大能力，但某些图论论任务仍靠概念基础表示才能有效解决，而通过微调或多步查询实现这种映射成本过高。

Method: 开发结构化上下文注入框架，将任务特定信息系统地嵌入到LLM输入中，使得LLM能够隐式对齐任务与基础概念空间。方法不需要微调LLM。

Result: 在多个图论任务上评估显示了一致的性能提升，结构化输入上下文的效果可以比较或超越更复杂的方法。同时展示了轻量模型和大模型在准确性与计算成本之间的交换。

Conclusion: 结构化上下文注入是一种高效且可扩展的策略，能够有效地提升LLM在图识别任务中的表现。

Abstract: Large Language Models (LLMs) have shown strong capabilities in solving
problems across domains, including graph-related tasks traditionally addressed
by symbolic or algorithmic methods. In this work, we present a framework for
structured context injection, where task-specific information is systematically
embedded in the input to guide LLMs in solving a wide range of graph problems.
Our method does not require fine-tuning of LLMs, making it cost-efficient and
lightweight. We observe that certain graph reasoning tasks remain challenging
for LLMs unless they are mapped to conceptually grounded representations.
However, achieving such mappings through fine-tuning or repeated multi-step
querying can be expensive and inefficient. Our approach offers a practical
alternative by injecting structured context directly into the input, enabling
the LLM to implicitly align the task with grounded conceptual spaces. We
evaluate the approach on multiple graph tasks using both lightweight and large
models, highlighting the trade-offs between accuracy and computational cost.
The results demonstrate consistent performance improvements, showing that
structured input context can rival or surpass more complex approaches. Our
findings underscore the value of structured context injection as an effective
and scalable strategy for graph understanding with LLMs.

</details>


### [114] [L-MARS -- Legal Multi-Agent Workflow with Orchestrated Reasoning and Agentic Search](https://arxiv.org/abs/2509.00761)
*Ziqi Wang,Boqin Yuan*

Main category: cs.AI

TL;DR: L-MARS是一个多智能体法律问答系统，通过分解查询、定向搜索和验证机制，显著减少幻觉和不确定性，在LegalSearchQA基准上表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统单次检索增强生成(RAG)在法律问答中存在幻觉和不确定性，需要更精确的法律检索和推理机制来处理高风险领域的法律问题。

Method: 采用多智能体工作流：分解查询为子问题，在多个异构源(网络搜索、本地RAG、案例法)进行定向搜索，使用法官智能体验证充分性、管辖权和时效性，通过迭代推理-搜索-验证循环合成答案。

Result: 在2025年200个最新法律选择题的LegalSearchQA基准上，L-MARS显著提高事实准确性，减少不确定性，获得人类专家和LLM法官更高的偏好评分。

Conclusion: 多智能体推理与智能搜索相结合，为在高风险领域部署LLMs提供了可扩展且可复现的蓝图，能够实现精确的法律检索和审议。

Abstract: We present L-MARS (Legal Multi-Agent Workflow with Orchestrated Reasoning and
Agentic Search), a system that reduces hallucination and uncertainty in legal
question answering through coordinated multi-agent reasoning and retrieval.
Unlike single-pass retrieval-augmented generation (RAG), L-MARS decomposes
queries into subproblems, issues targeted searches across heterogeneous sources
(Serper web, local RAG, CourtListener case law), and employs a Judge Agent to
verify sufficiency, jurisdiction, and temporal validity before answer
synthesis. This iterative reasoning-search-verification loop maintains
coherence, filters noisy evidence, and grounds answers in authoritative law. We
evaluated L-MARS on LegalSearchQA, a new benchmark of 200 up-to-date multiple
choice legal questions in 2025. Results show that L-MARS substantially improves
factual accuracy, reduces uncertainty, and achieves higher preference scores
from both human experts and LLM-based judges. Our work demonstrates that
multi-agent reasoning with agentic search offers a scalable and reproducible
blueprint for deploying LLMs in high-stakes domains requiring precise legal
retrieval and deliberation.

</details>


### [115] [Aligning Reasoning LLMs for Materials Discovery with Physics-aware Rejection Sampling](https://arxiv.org/abs/2509.00768)
*Lee Hyun,Sohee Yoon,Jinwoo Park,Sue In Chae,Seongeon Park,Jooyeon Ahn,Yebin Jung,Youjung Chung,Hogeun Chang,Myeonginn Kang,Jina Kim,Ho-Gyeong Kim,Myeonghun Jeong*

Main category: cs.AI

TL;DR: 提出了Physics-aware Rejection Sampling (PaRS)方法，通过物理感知的推理轨迹选择来训练大型推理模型，提高材料属性预测的准确性和物理一致性。


<details>
  <summary>Details</summary>
Motivation: AI驱动的材料发现需要准确、校准且物理可接受的配方到属性预测器。现有训练管道使用二元正确性或学习偏好信号来选择推理轨迹，但这些方法不能很好地反映物理可接受性。

Method: 引入Physics-aware Rejection Sampling (PaRS)训练时轨迹选择方案，优先选择符合基础物理原理且数值接近目标的轨迹，采用轻量级停止机制控制计算成本。使用大型教师模型合成的轨迹来微调学生模型。

Result: 相比各种拒绝采样基线方法，该方法提高了准确性和校准度，降低了物理违规率，并减少了采样成本。

Conclusion: 适度的领域感知约束结合轨迹级选择，为过程感知属性预测和闭环材料设计提供了可靠、高效的大型推理模型的实用路径。

Abstract: AI-driven materials discovery that couples automated experimentation with
algorithmic decision-making requires process aware recipe to property
predictors that are accurate, calibrated, and physically admissible. We
approach this as a reasoning problem with large reasoning models (LRMs). To
instill reasoning capability into language models, we curate reasoning traces
from a teacher model to train a student model. However, most training pipelines
select reasoning traces using binary correctness or learned preference signals
that poorly reflect physical admissibility. We introduce Physics-aware
Rejection Sampling (PaRS), a training-time trace selection scheme that favors
traces consistent with fundamental physics and numerically close to targets,
with lightweight halting to control compute. We instantiate our framework with
a large student model fine-tuned on traces synthesized by a larger teacher
model, and evaluate under matched token budgets against various rejection
sampling baselines. Our method improves accuracy and calibration, reduces
physics-violation rates, and lowers sampling cost relative to baselines. These
results indicate that modest, domain-aware constraints combined with
trace-level selection provide a practical path toward reliable, efficient LRMs
for process-aware property prediction and closed-loop materials design.

</details>


### [116] [Sharpe Ratio Optimization in Markov Decision Processes](https://arxiv.org/abs/2509.00793)
*Shuai Ma,Guangwu Liu,Li Xia*

Main category: cs.AI

TL;DR: 本文提出了一种在马尔可夫决策过程中优化夏普比率的新方法，通过Dinkelbach变换将分数目标转换为均值-方差优化问题，并开发了收敛到最优解的迭代算法。


<details>
  <summary>Details</summary>
Motivation: 夏普比率是金融领域广泛使用的风险调整收益指标，但在MDP中优化夏普比率面临两个挑战：动态规划不适用于分数目标，也不适用于风险度量。

Method: 使用Dinkelbach变换将夏普比率优化转换为均值-方差优化问题，开发迭代算法求解M2V问题，并通过策略迭代过程更新风险敏感参数。

Result: 提出的算法能够单调递增地收敛到最优夏普比率，在平均和折扣MDP设置下都证明了收敛性，数值实验验证了方法的有效性。

Conclusion: 这是第一个使用动态规划类算法解决MDP中夏普比率优化问题的方法，为解决其他分数目标MDP问题提供了新思路。

Abstract: Sharpe ratio (also known as reward-to-variability ratio) is a widely-used
metric in finance, which measures the additional return at the cost of per unit
of increased risk (standard deviation of return). However, the optimization of
Sharpe ratio in Markov decision processes (MDPs) is challenging, because there
exist two difficulties hindering the application of dynamic programming. One is
that dynamic programming does not work for fractional objectives, and the other
is that dynamic programming is invalid for risk metrics. In this paper, we
study the Sharpe ratio optimization in infinite-horizon MDPs, considering both
the long-run average and discounted settings. We address the first challenge
with the Dinkelbachs transform, which converts the Sharpe ratio objective to a
mean-squared-variance (M2V) objective. It is shown that the M2V optimization
and the original Sharpe ratio optimization share the same optimal policy when
the risk-sensitive parameter is equal to the optimal Sharpe ratio. For the
second challenge, we develop an iterative algorithm to solve the M2V
optimization which is similar to a mean-variance optimization in MDPs. We
iteratively solve the M2V problem and obtain the associated Sharpe ratio that
is used to update the risk-sensitive parameter in the next iteration of M2V
problems. We show that such a sequence of Sharpe ratios derived is
monotonically increasing and converges to the optimal Sharpe ratio. For both
average and discounted MDP settings, we develop a policy iteration procedure
and prove its convergence to the optimum. Numerical experiments are conducted
for validation. To the best of our knowledge, our approach is the first that
solves the Sharpe ratio optimization in MDPs with dynamic programming type
algorithms. We believe that the proposed algorithm can shed light on solving
MDPs with other fractional objectives.

</details>


### [117] [Neuro-Symbolic Predictive Process Monitoring](https://arxiv.org/abs/2509.00834)
*Axel Mezini,Elena Umili,Ivan Donadello,Fabrizio Maria Maggi,Matteo Mancanelli,Fabio Patrizi*

Main category: cs.AI

TL;DR: 本文提出了一种结合神经网络和符号逻辑的预测性过程监控方法，通过引入可微分逻辑损失函数来提高后缀预测的准确性和逻辑一致性。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习模型在业务过程管理中进行后缀预测时，经常无法满足基本的逻辑约束，因为缺乏领域知识的明确集成。

Method: 提出了一种新的方法，将有限迹踏上的线性时态逻辑(LTLf)积分到自回归序列预测器的训练过程中，使用Gumbel-Softmax技巧定义可微分逻辑损失函数。

Result: 在三个实际数据集上的实验评估显示，该方法提高了后缀预测的准确性和时态约束的遵循程度，并在噪声和实际环境下验证了局部和全局逻辑损失变体的有效性。

Conclusion: 该框架虽然在BPM背景下开发，但适用于任何符号序列生成任务，为推进神经符号AI做出了贡献。

Abstract: This paper addresses the problem of suffix prediction in Business Process
Management (BPM) by proposing a Neuro-Symbolic Predictive Process Monitoring
(PPM) approach that integrates data-driven learning with temporal logic-based
prior knowledge. While recent approaches leverage deep learning models for
suffix prediction, they often fail to satisfy even basic logical constraints
due to the absence of explicit integration of domain knowledge during training.
We propose a novel method to incorporate Linear Temporal Logic over finite
traces (LTLf) into the training process of autoregressive sequence predictors.
Our approach introduces a differentiable logical loss function, defined using a
soft approximation of LTLf semantics and the Gumbel-Softmax trick, which can be
combined with standard predictive losses. This ensures the model learns to
generate suffixes that are both accurate and logically consistent. Experimental
evaluation on three real-world datasets shows that our method improves suffix
prediction accuracy and compliance with temporal constraints. We also introduce
two variants of the logic loss (local and global) and demonstrate their
effectiveness under noisy and realistic settings. While developed in the
context of BPM, our framework is applicable to any symbolic sequence generation
task and contributes toward advancing Neuro-Symbolic AI.

</details>


### [118] [ChatCLIDS: Simulating Persuasive AI Dialogues to Promote Closed-Loop Insulin Adoption in Type 1 Diabetes Care](https://arxiv.org/abs/2509.00891)
*Zonghai Yao,Talha Chafekar,Junda Wang,Shuo Han,Feiyun Ouyang,Junhui Qian,Lingxi Li,Hong Yu*

Main category: cs.AI

TL;DR: ChatCLIDS是首个评估LLM驱动健康行为改变对话的基准测试，通过专家验证的虚拟患者和多样化说服策略，发现当前LLM在克服抵抗和社交压力方面存在局限


<details>
  <summary>Details</summary>
Motivation: 闭环胰岛素输送系统在1型糖尿病中的实际采用率低，主要由于行为、心理和社会障碍而非技术故障，需要评估LLM在健康行为改变中的说服对话能力

Method: 创建包含专家验证虚拟患者的框架，模拟与配备循证说服策略的护士代理进行多轮交互，支持纵向咨询和对抗性社交影响场景

Result: 较大型和更具反思性的LLM能够随时间调整策略，但所有模型都难以克服抵抗，特别是在现实社交压力下

Conclusion: 研究揭示了当前LLM在行为改变方面的关键局限性，为推进医疗保健领域可信赖的说服性AI提供了高保真、可扩展的测试平台

Abstract: Real-world adoption of closed-loop insulin delivery systems (CLIDS) in type 1
diabetes remains low, driven not by technical failure, but by diverse
behavioral, psychosocial, and social barriers. We introduce ChatCLIDS, the
first benchmark to rigorously evaluate LLM-driven persuasive dialogue for
health behavior change. Our framework features a library of expert-validated
virtual patients, each with clinically grounded, heterogeneous profiles and
realistic adoption barriers, and simulates multi-turn interactions with nurse
agents equipped with a diverse set of evidence-based persuasive strategies.
ChatCLIDS uniquely supports longitudinal counseling and adversarial social
influence scenarios, enabling robust, multi-dimensional evaluation. Our
findings reveal that while larger and more reflective LLMs adapt strategies
over time, all models struggle to overcome resistance, especially under
realistic social pressure. These results highlight critical limitations of
current LLMs for behavior change, and offer a high-fidelity, scalable testbed
for advancing trustworthy persuasive AI in healthcare and beyond.

</details>


### [119] [Robust Deep Monte Carlo Counterfactual Regret Minimization: Addressing Theoretical Risks in Neural Fictitious Self-Play](https://arxiv.org/abs/2509.00923)
*Zakaria El Jaafari*

Main category: cs.AI

TL;DR: 该论文分析了神经MCCFR在不同规模博弈中的组件有效性差异，提出了自适应框架Robust Deep MCCFR，通过目标网络、均匀探索混合等技术在Kuhn和Leduc扑克上分别实现了60%和23.5%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决MCCFR与深度神经网络结合时在不同规模博弈中出现的尺度依赖挑战，包括非平稳目标分布偏移、动作支持崩溃、方差爆炸和热启动偏差等问题。

Method: 提出Robust Deep MCCFR框架，包含延迟更新的目标网络、均匀探索混合、方差感知训练目标和全面诊断监控，通过系统消融研究验证组件有效性。

Result: 在Kuhn扑克上达到0.0628的最终可利用性（比经典框架提升60%），在Leduc扑克上达到0.2386的可利用性（提升23.5%），证明了选择性组件部署的重要性。

Conclusion: 神经MCCFR组件的有效性具有尺度依赖性，需要针对不同规模博弈采用不同的缓解策略，选择性组件部署比全面缓解更为重要，为更大规模博弈的部署提供了实用指南。

Abstract: Monte Carlo Counterfactual Regret Minimization (MCCFR) has emerged as a
cornerstone algorithm for solving extensive-form games, but its integration
with deep neural networks introduces scale-dependent challenges that manifest
differently across game complexities. This paper presents a comprehensive
analysis of how neural MCCFR component effectiveness varies with game scale and
proposes an adaptive framework for selective component deployment. We identify
that theoretical risks such as nonstationary target distribution shifts, action
support collapse, variance explosion, and warm-starting bias have
scale-dependent manifestation patterns, requiring different mitigation
strategies for small versus large games. Our proposed Robust Deep MCCFR
framework incorporates target networks with delayed updates, uniform
exploration mixing, variance-aware training objectives, and comprehensive
diagnostic monitoring. Through systematic ablation studies on Kuhn and Leduc
Poker, we demonstrate scale-dependent component effectiveness and identify
critical component interactions. The best configuration achieves final
exploitability of 0.0628 on Kuhn Poker, representing a 60% improvement over the
classical framework (0.156). On the more complex Leduc Poker domain, selective
component usage achieves exploitability of 0.2386, a 23.5% improvement over the
classical framework (0.3703) and highlighting the importance of careful
component selection over comprehensive mitigation. Our contributions include:
(1) a formal theoretical analysis of risks in neural MCCFR, (2) a principled
mitigation framework with convergence guarantees, (3) comprehensive multi-scale
experimental validation revealing scale-dependent component interactions, and
(4) practical guidelines for deployment in larger games.

</details>


### [120] [SATQuest: A Verifier for Logical Reasoning Evaluation and Reinforcement Fine-Tuning of LLMs](https://arxiv.org/abs/2509.00930)
*Yanxiao Zhao,Yaqian Li,Zihao Bo,Rinyoichi Takezoe,Haojia Hui,Mo Guang,Lei Ren,Xiaolin Qin,Kaiwen Long*

Main category: cs.AI

TL;DR: SATQuest是一个系统化的验证工具，通过从CNF实例生成多样化的可满足性逻辑推理问题来评估和增强LLM的逻辑推理能力，解决了现有基准测试缺乏可控性和多维分析的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型基准测试缺乏可控性和可扩展性，无法进行多维度的系统化分析和训练，或者问题类型和格式过于狭窄，需要一种能够系统评估和增强LLM逻辑推理能力的工具。

Method: 开发SATQuest系统，从合取范式(CNF)实例生成多样化的可满足性逻辑推理问题，沿三个正交维度（实例规模、问题类型、问题格式）构建问题，采用随机化、基于SAT的问题生成和通过PySAT进行客观答案验证。

Result: 对各种LLM的广泛评估发现了它们在逻辑推理方面的显著局限性，特别是在超越熟悉数学格式的泛化能力方面。使用SATQuest奖励进行强化微调显著提高了目标任务性能，并能泛化到更复杂的实例。

Conclusion: SATQuest展示了作为基础工具的潜力，是推进LLM逻辑推理能力的宝贵起点，同时揭示了跨格式适应的剩余挑战。

Abstract: Recent advances in Large Language Models (LLMs) have demonstrated remarkable
general reasoning capabilities. However, systematically evaluating and
enhancing these reasoning capabilities is challenging due to the lack of
controllable and scalable tools for fine-grained analysis. Existing benchmarks
and datasets often lack the necessary variable control for multi-dimensional,
systematic analysis and training, or have narrow problem types and formats. To
address these limitations, we introduce SATQuest, a systematic verifier
designed to evaluate and enhance logical reasoning in LLMs by generating
diverse, Satisfiability-based logical reasoning problems directly from
Conjunctive Normal Form (CNF) instances. SATQuest structures these problems
along three orthogonal dimensions: instance scale, problem type, and question
format, employing randomized, SAT-based problem generation and objective answer
verification via PySAT. This design mitigates memorization issues, allows for
nuanced insights into reasoning performance, and enables effective
reinforcement fine-tuning. Our extensive evaluation of various LLMs using
SATQuest identified significant limitations in their logical reasoning,
particularly in generalizing beyond familiar mathematical formats. Furthermore,
we show that reinforcement fine-tuning with SATQuest rewards substantially
improves targeted task performance and generalizes to more complex instances,
while highlighting remaining challenges in cross-format adaptation. Through
these demonstrations, we showcase SATQuest's potential as a foundational tool
and a valuable starting point for advancing LLM logical reasoning.

</details>


### [121] [UrbanInsight: A Distributed Edge Computing Framework with LLM-Powered Data Filtering for Smart City Digital Twins](https://arxiv.org/abs/2509.00936)
*Kishor Datta Gupta,Md Manjurul Ahsan,Mohd Ariful Haque,Roy George,Azmine Toushik Wasi*

Main category: cs.AI

TL;DR: 提出一个结合物理信息机器学习、多模态数据融合、知识图谱和LLM自适应规则的智能城市数字孪生框架，实现从被动监控到主动洞察的转变


<details>
  <summary>Details</summary>
Motivation: 解决现有城市数据系统在规模、延迟和碎片化洞察方面的挑战，充分利用传感器和连接基础设施产生的海量数据来改善城市生活

Method: 融合物理信息机器学习（确保预测符合物理约束）、知识图谱（作为语义骨干整合异构数据）、LLM驱动的自适应规则生成（实现实时边缘决策）

Result: 构建了一个超越被动监控的数字孪生系统基础，能够提供可操作的洞察，实现高效资源约束下的实时操作

Conclusion: 通过统一物理推理、语义数据融合和自适应规则生成，为创建响应式、可信赖和可持续的智能基础设施开辟了新可能性

Abstract: Cities today generate enormous streams of data from sensors, cameras, and
connected infrastructure. While this information offers unprecedented
opportunities to improve urban life, most existing systems struggle with scale,
latency, and fragmented insights. This work introduces a framework that blends
physics-informed machine learning, multimodal data fusion, and knowledge graph
representation with adaptive, rule-based intelligence powered by large language
models (LLMs). Physics-informed methods ground learning in real-world
constraints, ensuring predictions remain meaningful and consistent with
physical dynamics. Knowledge graphs act as the semantic backbone, integrating
heterogeneous sensor data into a connected, queryable structure. At the edge,
LLMs generate context-aware rules that adapt filtering and decision-making in
real time, enabling efficient operation even under constrained resources.
Together, these elements form a foundation for digital twin systems that go
beyond passive monitoring to provide actionable insights. By uniting
physics-based reasoning, semantic data fusion, and adaptive rule generation,
this approach opens new possibilities for creating responsive, trustworthy, and
sustainable smart infrastructures.

</details>


### [122] [A Hybrid Ai Framework For Strategic Patent Portfolio Pruning: Integrating Learning To-Rank And Market Need Analysis For Technology Transfer Optimization](https://arxiv.org/abs/2509.00958)
*Manish Verma,Vivek Sharma,Vishal Singh*

Main category: cs.AI

TL;DR: 提出了一种多阶段混合智能框架，通过结合学习排序模型和Need-Seed代理系统，自动识别高价值专利资产进行技术转移。


<details>
  <summary>Details</summary>
Motivation: 现有专利评估方法依赖回顾性指标或耗时的人工分析，需要更自动化、深入的专利组合修剪方法来识别高价值技术转移资产。

Method: 结合学习排序模型（评估30+法律和商业参数）和基于代理的Need-Seed系统：Need代理使用NLP挖掘市场需求，Seed代理使用微调LLM分析专利技术能力，通过核心本体框架匹配专利与市场需求。

Result: 建立了能够自动匹配高潜力专利与市场需求的系统架构，包含动态参数加权和人工验证协议。

Conclusion: 该框架为专利组合修剪提供了战略决策依据，确保了适应性和现实可信度，提升了技术转移效率。

Abstract: This paper introduces a novel, multi stage hybrid intelligence framework for
pruning patent portfolios to identify high value assets for technology
transfer. Current patent valuation methods often rely on retrospective
indicators or manual, time intensive analysis. Our framework automates and
deepens this process by combining a Learning to Rank (LTR) model, which
evaluates patents against over 30 legal and commercial parameters, with a
unique "Need-Seed" agent-based system. The "Need Agent" uses Natural Language
Processing (NLP) to mine unstructured market and industry data, identifying
explicit technological needs. Concurrently, the "Seed Agent" employs fine tuned
Large Language Models (LLMs) to analyze patent claims and map their
technological capabilities. The system generates a "Core Ontology Framework"
that matches high potential patents (Seeds) to documented market demands
(Needs), providing a strategic rationale for divestment decisions. We detail
the architecture, including a dynamic parameter weighting system and a crucial
Human in the-Loop (HITL) validation protocol, to ensure both adaptability and
real-world credibility.

</details>


### [123] [Ultra Strong Machine Learning: Teaching Humans Active Learning Strategies via Automated AI Explanations](https://arxiv.org/abs/2509.00961)
*Lun Ai,Johannes Langer,Ute Schmid,Stephen Muggleton*

Main category: cs.AI

TL;DR: LENS是一个神经符号方法，结合符号程序合成和大型语言模型，自动生成机器学习逻辑程序的自然语言解释，取代手工模板，但人类学习实验显示未显著提升性能


<details>
  <summary>Details</summary>
Motivation: 解决超强机器学习(USML)系统中手工解释模板的可扩展性限制，实现自动化自然语言解释生成

Method: 结合符号程序合成和大型语言模型(LLMs)，通过神经摘要自动生成逻辑程序的解释

Result: LENS生成的解释优于直接LLM提示和手工模板，但人类学习实验未显示显著性能提升，可能因为LLM响应过于全面反而影响学习

Conclusion: 为构建有效的USML系统支持人类学习提供了坚实基础，但需要进一步优化解释生成方式以真正提升人类学习效果

Abstract: Ultra Strong Machine Learning (USML) refers to symbolic learning systems that
not only improve their own performance but can also teach their acquired
knowledge to quantifiably improve human performance. In this work, we present
LENS (Logic Programming Explanation via Neural Summarisation), a neuro-symbolic
method that combines symbolic program synthesis with large language models
(LLMs) to automate the explanation of machine-learned logic programs in natural
language. LENS addresses a key limitation of prior USML approaches by replacing
hand-crafted explanation templates with scalable automated generation. Through
systematic evaluation using multiple LLM judges and human validation, we
demonstrate that LENS generates superior explanations compared to direct LLM
prompting and hand-crafted templates. To investigate whether LENS can teach
transferable active learning strategies, we carried out a human learning
experiment across three related domains. Our results show no significant human
performance improvements, suggesting that comprehensive LLM responses may
overwhelm users for simpler problems rather than providing learning support.
Our work provides a solid foundation for building effective USML systems to
support human learning. The source code is available on:
https://github.com/lun-ai/LENS.git.

</details>


### [124] [CoreThink: A Symbolic Reasoning Layer to reason over Long Horizon Tasks with LLMs](https://arxiv.org/abs/2509.00971)
*Jay Vaghasiya,Omkar Ghugarkar,Vishvesh Bhat,Vipul Dholaria,Julian McAuley*

Main category: cs.AI

TL;DR: CoreThink是一个基于通用符号推理方法的新型推理层，在工具调用、代码生成和规划三个关键用例中表现出色，在7个基准测试中取得SOTA成绩，无需微调或训练成本。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如测试时扩展、监督微调和强化学习）在LLM性能提升上会出现收益递减，需要开发新的推理技术来突破性能瓶颈。

Method: 采用通用符号推理方法（General Symbolics），构建CoreThink通用符号推理器（GSR），专注于工具调用、代码生成和规划三个核心用例。

Result: 在多个基准测试中取得SOTA成绩：Livecodebench v6达到66.66%、Instruction-Following Evals达到89%、ARC-AGI-2达到24.4%，基于该技术的智能编码IDE在SWE-Bench Lite上达到62.3%的准确率。

Conclusion: CoreThink推理层能够提供纯粹的性能提升，不会对模型在推理任务上的准确性产生负面影响，为推理密集型用例提供了有效的解决方案。

Abstract: We introduce CoreThink, a state-of-the-art Reasoning Layer built upon a novel
reasoning method called General Symbolics. This approach diverges from
reasoning paradigms such as test-time scaling, Supervised Fine-Tuning (SFT),
and Reinforcement Learning with Verifiable Rewards (RLVR). CoreThink General
Symbolic Reasoner (GSR) is specifically structured around three key use cases:
tool-calling, code generation, and planning, demonstrating exemplary
performance across a total of seven benchmarks in their respective areas.
Notably, we are achieving SOTA scores of 66.66\% on Livecodebench v6, 89\% on
Instruction-Following Evals, and 24.4\% on ARC-AGI-2. We also present an
agentic coding IDE, developed using the principles of General Symbolics, which
achieves a state-of-the-art accuracy of 62.3\% on \texttt{SWE-Bench Lite}. We
are able to achieve these improvements without any finetuning or training
costs. Our Reasoning Layer is designed to provide a pure performance uplift,
ensuring that a model's accuracy on reasoning tasks is never negatively
impacted. We argue that incumbent methods will eventually lead to diminishing
returns in LLM performance, necessitating the development of new reasoning
techniques. This technical report details our approach at a high level and the
availability of the CoreThink models for reasoning-intensive use cases.

</details>


### [125] [Self-Exploring Language Models for Explainable Link Forecasting on Temporal Graphs via Reinforcement Learning](https://arxiv.org/abs/2509.00975)
*Zifeng Ding,Shenyang Huang,Zeyu Cao,Emma Kondrup,Zachary Yang,Xingyue Huang,Yuan Sui,Zhangdie Yuan,Yuqicheng Zhu,Xianglong Hu,Yuan He,Farimah Poursafaei,Michael Bronstein,Andreas Vlachos*

Main category: cs.AI

TL;DR: ReaL-TG是一个基于强化学习的框架，通过微调大语言模型在时序图上进行可解释的链接预测，使用结果奖励机制鼓励模型从图结构中探索推理策略并生成解释。


<details>
  <summary>Details</summary>
Motivation: 传统时序图神经网络虽然性能强但缺乏可解释性，且无法直接应用于未见过的图。现有的大语言模型图推理方法大多局限于静态图或小型合成时序图，且缺乏对推理轨迹质量的评估。

Method: 提出ReaL-TG强化学习框架，使用基于结果的奖励机制微调大语言模型，让模型从图结构中自主探索推理策略，并生成直接证明预测的解释。同时提出结合排名指标和LLM-as-a-Judge系统的评估协议。

Result: 通过微调Qwen3-4B得到的ReaL-TG-4B在排名指标上优于包括GPT-5 mini在内的更大规模前沿大语言模型，同时生成的高质量解释得到了LLM评判系统和人工评估的确认。

Conclusion: ReaL-TG框架成功地将大语言模型应用于真实世界时序图的链接预测任务，在保持高性能的同时提供了可解释性，并通过新的评估协议验证了推理轨迹的质量。

Abstract: Forecasting future links is a central task in temporal graph (TG) reasoning,
requiring models to leverage historical interactions to predict upcoming ones.
Traditional neural approaches, such as temporal graph neural networks, achieve
strong performance but lack explainability and cannot be applied to unseen
graphs without retraining. Recent studies have begun to explore using large
language models (LLMs) for graph reasoning, but most of them are constrained to
static graphs or small synthetic TGs and lack the evaluation of the quality of
reasoning traces generated by LLMs. In this work, we present Reasoning-Enhanced
Learning for Temporal Graphs (ReaL-TG), a reinforcement learning framework that
fine-tunes LLMs to perform explainable link forecasting on real-world TGs.
ReaL-TG uses outcome-based reward to encourage models to self-explore reasoning
strategies from graph structure and to produce explanations that directly
justify their predictions. To enable evaluation on LLM-generated reasoning
traces, we propose a new evaluation protocol combining ranking metrics with an
LLM-as-a-Judge system that assesses both the quality of reasoning and the
impact of hallucinations. Experiments with ReaL-TG-4B, obtained by fine-tuning
Qwen3-4B under our framework, show that it outperforms much larger frontier
LLMs, including GPT-5 mini, on ranking metrics, while producing high-quality
explanations confirmed by both the LLM judge and human evaluation.

</details>


### [126] [Causal MAS: A Survey of Large Language Model Architectures for Discovery and Effect Estimation](https://arxiv.org/abs/2509.00987)
*Adib Bazgir,Amir Habibdoust,Yuwen Zhang,Xing Song*

Main category: cs.AI

TL;DR: 这篇综述论文探讨了因果多智能体大语言模型这一新兴领域，通过多智能体系统解决LLM在复杂因果推理、发现和估计方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在复杂因果推理方面存在幻觉、伪相关依赖等限制，多智能体系统通过协作和专业化能力为解决这些问题提供了新范式。

Method: 研究多智能体系统的设计架构和交互协议，包括流水线处理、辩论框架、模拟环境和迭代精炼循环等方法。

Result: 论文综述了因果多智能体LLM在不同因果任务中的应用，包括因果推理、反事实分析、因果发现和因果效应估计。

Conclusion: 该领域在科学发现、医疗健康、事实核查和个性化系统等多个应用领域具有重要价值，但仍面临持续挑战和开放研究问题。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in
various reasoning and generation tasks. However, their proficiency in complex
causal reasoning, discovery, and estimation remains an area of active
development, often hindered by issues like hallucination, reliance on spurious
correlations, and difficulties in handling nuanced, domain-specific, or
personalized causal relationships. Multi-agent systems, leveraging the
collaborative or specialized abilities of multiple LLM-based agents, are
emerging as a powerful paradigm to address these limitations. This review paper
explores the burgeoning field of causal multi-agent LLMs. We examine how these
systems are designed to tackle different facets of causality, including causal
reasoning and counterfactual analysis, causal discovery from data, and the
estimation of causal effects. We delve into the diverse architectural patterns
and interaction protocols employed, from pipeline-based processing and debate
frameworks to simulation environments and iterative refinement loops.
Furthermore, we discuss the evaluation methodologies, benchmarks, and diverse
application domains where causal multi-agent LLMs are making an impact,
including scientific discovery, healthcare, fact-checking, and personalized
systems. Finally, we highlight the persistent challenges, open research
questions, and promising future directions in this synergistic field, aiming to
provide a comprehensive overview of its current state and potential trajectory.

</details>


### [127] [Supporting Our AI Overlords: Redesigning Data Systems to be Agent-First](https://arxiv.org/abs/2509.00997)
*Shu Liu,Soujanya Ponnapalli,Shreya Shankar,Sepanta Zeighami,Alan Zhu,Shubham Agarwal,Ruiqi Chen,Samion Suwito,Shuo Yuan,Ion Stoica,Matei Zaharia,Alvin Cheung,Natacha Crooks,Joseph E. Gonzalez,Aditya G. Parameswaran*

Main category: cs.AI

TL;DR: LLM代理工作负载将成为数据系统的主导工作流，需要数据系统为代理体特性进行优化设计


<details>
  <summary>Details</summary>
Motivation: LLM代理在数据操作和分析中采用高通量的探索和解决方案形成过程（代理体猜测），对现有数据系统构成挑战

Method: 分析代理体猜测的四大特征：规模性、异构性、冗余性和可控性，并基于这些特性提出代理优先的数据系统架构

Result: 提出了一系列新的研究机遇，包括新查询接口、新查询处理技术和新代理内存存储等方向

Conclusion: 数据系统需要根本性重构以原生支持LLM代理工作负载，这是未来数据系统设计的重要趋势

Abstract: Large Language Model (LLM) agents, acting on their users' behalf to
manipulate and analyze data, are likely to become the dominant workload for
data systems in the future. When working with data, agents employ a
high-throughput process of exploration and solution formulation for the given
task, one we call agentic speculation. The sheer volume and inefficiencies of
agentic speculation can pose challenges for present-day data systems. We argue
that data systems need to adapt to more natively support agentic workloads. We
take advantage of the characteristics of agentic speculation that we identify,
i.e., scale, heterogeneity, redundancy, and steerability - to outline a number
of new research opportunities for a new agent-first data systems architecture,
ranging from new query interfaces, to new query processing techniques, to new
agentic memory stores.

</details>


### [128] [Analysis of Error Sources in LLM-based Hypothesis Search for Few-Shot Rule Induction](https://arxiv.org/abs/2509.01016)
*Aishni Parab,Hongjing Lu,Ying Nian Wu,Sumit Gulwani*

Main category: cs.AI

TL;DR: LLM假设搜索框架在少样本规则归纳任务中表现优于直接程序生成方法，达到人类水平性能


<details>
  <summary>Details</summary>
Motivation: 比较LLM假设搜索与直接程序生成在归纳推理任务中的性能差异，探索建模人类归纳推理的方法

Method: 使用LLM假设搜索框架和直接程序生成方法在少样本规则归纳任务上进行对比实验

Result: 假设搜索方法达到与人类相当的性能，而直接程序生成方法表现明显落后

Conclusion: LLM假设搜索在建模归纳推理方面具有潜力，但假设生成存在瓶颈，需要开发更高效的系统

Abstract: Inductive reasoning enables humans to infer abstract rules from limited
examples and apply them to novel situations. In this work, we compare an
LLM-based hypothesis search framework with direct program generation approaches
on few-shot rule induction tasks. Our findings show that hypothesis search
achieves performance comparable to humans, while direct program generation
falls notably behind. An error analysis reveals key bottlenecks in hypothesis
generation and suggests directions for advancing program induction methods.
Overall, this paper underscores the potential of LLM-based hypothesis search
for modeling inductive reasoning and the challenges in building more efficient
systems.

</details>


### [129] [Quantum-like Coherence Derived from the Interaction between Chemical Reaction and Its Environment](https://arxiv.org/abs/2509.01021)
*Yukio-Pegio Gunji,Andrew Adamatzky,Panagiotis Mougkogiannis,Andrei Khrenikov*

Main category: cs.AI

TL;DR: 本文通过对比人工智能与自然智能的计算过程，定义了封闭计算与开放计算，并在化学反应中实现了开放计算。通过将计算过程与环境融合，创建了能够调节波动的系统，展示了自组织临界现象和量子逻辑特性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于揭示人工智能与自然智能之间的计算差异，探索在化学反应中实现开放计算的可能性，以创建能够自适应调节波动的智能系统。

Method: 将计算过程建模为化学反应，执行环境建模为分子聚集程度。通过Token计算（关注单个分子行为）和Type计算（关注规范行为）的相互作用实现开放计算。

Result: 系统展示了自组织临界现象和量子逻辑特性，通过量子逻辑子空间之间的相互作用实现了波动招募，形成了尖峰波以实现信号传输。

Conclusion: 成功在化学反应中实现了开放计算，发现了量子类相干现象，这可能是控制尖峰波和生化节律的酶源机制，为智能系统的设计提供了新思路。

Abstract: By uncovering the contrast between Artificial Intelligence and Natural-born
Intelligence as a computational process, we define closed computing and open
computing, and implement open computing within chemical reactions. This
involves forming a mixture and invalidation of the computational process and
the execution environment, which are logically distinct, and coalescing both to
create a system that adjusts fluctuations. We model chemical reactions by
considering the computation as the chemical reaction and the execution
environment as the degree of aggregation of molecules that interact with the
reactive environment. This results in a chemical reaction that progresses while
repeatedly clustering and de-clustering, where concentration no longer holds
significant meaning. Open computing is segmented into Token computing, which
focuses on the individual behavior of chemical molecules, and Type computing,
which focuses on normative behavior. Ultimately, both are constructed as an
interplay between the two. In this system, Token computing demonstrates
self-organizing critical phenomena, while Type computing exhibits quantum
logic. Through their interplay, the recruitment of fluctuations is realized,
giving rise to interactions between quantum logical subspaces corresponding to
quantum coherence across different Hilbert spaces. As a result, spike waves are
formed, enabling signal transmission. This occurrence may be termed
quantum-like coherence, implying the source of enzymes responsible for
controlling spike waves and biochemical rhythms.

</details>


### [130] [Symbolic Planning and Multi-Agent Path Finding in Extremely Dense Environments with Movable Obstacles](https://arxiv.org/abs/2509.01022)
*Bo Fu,Zhe Chen,Rahul Chandan,Alex Barbosa,Michael Caldara,Joey Durham,Federico Pecora*

Main category: cs.AI

TL;DR: 提出仓库管理中的块重新排列问题(BRaP)，形式化为图搜索问题，并提出4种搜索基于算法来解决。方法在80x80网格中表现出良好的扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决大型仓库管理中的块状物品重新排列挑战，这是一个复杂的运作问题，需要高效的解决方案来处理深藏的块状物品。

Method: 基于滑动拼图问题的直觉，提出五种搜索基于算法：联合配置空间搜索、经典规划、多代理路径找到和专家含数。将BRaP形式化为图搜索问题。

Result: 虽然搜索空间大小与块数呈指数关系，但方法在80x80网格中能够高效地为深藏块创建重新排列计划，表现出良好的扩展性。

Conclusion: 研究成功地形式化了仓库块重新排列问题，并提出了多种高效的搜索算法，在大规模网格中证明了其实用性和扩展性。

Abstract: We introduce the Block Rearrangement Problem (BRaP), a challenging component
of large warehouse management which involves rearranging storage blocks within
dense grids to achieve a target state. We formally define the BRaP as a graph
search problem. Building on intuitions from sliding puzzle problems, we propose
five search-based solution algorithms, leveraging joint configuration space
search, classical planning, multi-agent pathfinding, and expert heuristics. We
evaluate the five approaches empirically for plan quality and scalability.
Despite the exponential relation between search space size and block number,
our methods demonstrate efficiency in creating rearrangement plans for deeply
buried blocks in up to 80x80 grids.

</details>


### [131] [FlashAdventure: A Benchmark for GUI Agents Solving Full Story Arcs in Diverse Adventure Games](https://arxiv.org/abs/2509.01052)
*Jaewoo Ahn,Junseo Kim,Heeseung Yun,Jaehyeon Son,Dongmin Park,Jaewoong Cho,Gunhee Kim*

Main category: cs.AI

TL;DR: FlashAdventure是一个包含34个Flash冒险游戏的基准测试，用于评估GUI代理完成完整故事线的能力，并提出了COAST框架和CUA-as-a-Judge自动评估器来改善观察-行为差距问题。


<details>
  <summary>Details</summary>
Motivation: 现有的游戏基准测试缺乏多样性，很少评估代理完成整个故事线的能力，特别是冒险游戏中复杂的叙事驱动交互存在挑战。

Method: 提出了FlashAdventure基准测试、CUA-as-a-Judge自动游戏评估器，以及COAST代理框架，该框架利用长期线索记忆来更好地规划和解决顺序任务。

Result: 实验显示当前GUI代理在完整故事弧上表现不佳，而COAST通过弥合观察-行为差距显著提高了里程碑完成率。

Conclusion: 尽管COAST有所改进，但人类与最佳代理之间仍存在显著差距，需要继续研究来缩小这一鸿沟。

Abstract: GUI agents powered by LLMs show promise in interacting with diverse digital
environments. Among these, video games offer a valuable testbed due to their
varied interfaces, with adventure games posing additional challenges through
complex, narrative-driven interactions. Existing game benchmarks, however, lack
diversity and rarely evaluate agents on completing entire storylines. To
address this, we introduce FlashAdventure, a benchmark of 34 Flash-based
adventure games designed to test full story arc completion and tackle the
observation-behavior gap: the challenge of remembering and acting on earlier
gameplay information. We also propose CUA-as-a-Judge, an automated gameplay
evaluator, and COAST, an agentic framework leveraging long-term clue memory to
better plan and solve sequential tasks. Experiments show current GUI agents
struggle with full story arcs, while COAST improves milestone completion by
bridging the observation-behavior gap. Nonetheless, a marked discrepancy
between humans and best-performing agents warrants continued research efforts
to narrow this divide.

</details>


### [132] [VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use](https://arxiv.org/abs/2509.01055)
*Dongfu Jiang,Yi Lu,Zhuofeng Li,Zhiheng Lyu,Ping Nie,Haozhe Wang,Alex Su,Hui Chen,Kai Zou,Chao Du,Tianyu Pang,Wenhu Chen*

Main category: cs.AI

TL;DR: VerlTool是一个统一的模块化框架，解决了现有工具增强强化学习方法的碎片化、同步执行瓶颈和有限扩展性问题，通过标准化API、异步执行和多模态支持，在6个领域实现竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 现有的工具增强强化学习方法存在代码库碎片化、同步执行瓶颈和跨领域扩展性有限的问题，阻碍了社区采用和算法创新。

Method: 提出VerlTool框架，包含四个关键贡献：与VeRL的上游对齐、通过标准化API的统一工具管理、异步rollout执行实现2倍加速、以及多领域综合评估。

Result: 在数学推理、知识问答、SQL生成、视觉推理、网络搜索和软件工程等6个ARLT领域实现竞争性性能，异步执行带来近2倍速度提升。

Conclusion: VerlTool提供了一个可扩展的统一训练基础设施，通过模块化插件架构显著减少开发开销，为工具增强的RL研究奠定基础。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has demonstrated
success in enhancing LLM reasoning capabilities, but remains limited to
single-turn interactions without tool integration. While recent Agentic
Reinforcement Learning with Tool use (ARLT) approaches have emerged to address
multi-turn tool interactions, existing works develop task-specific codebases
that suffer from fragmentation, synchronous execution bottlenecks, and limited
extensibility across domains. These inefficiencies hinder broader community
adoption and algorithmic innovation. We introduce VerlTool, a unified and
modular framework that addresses these limitations through systematic design
principles. VerlTool provides four key contributions: (1) upstream alignment
with VeRL ensuring compatibility and simplified maintenance, (2) unified tool
management via standardized APIs supporting diverse modalities including code
execution, search, SQL databases, and vision processing, (3) asynchronous
rollout execution achieving near 2$\times$ speedup by eliminating
synchronization bottlenecks, and (4) comprehensive evaluation demonstrating
competitive performance across 6 ARLT domains. Our framework formalizes ARLT as
multi-turn trajectories with multi-modal observation tokens (text/image/video),
extending beyond single-turn RLVR paradigms. We train and evaluate models on
mathematical reasoning, knowledge QA, SQL generation, visual reasoning, web
search, and software engineering tasks, achieving results comparable to
specialized systems while providing unified training infrastructure. The
modular plugin architecture enables rapid tool integration requiring only
lightweight Python definitions, significantly reducing development overhead and
providing a scalable foundation for tool-augmented RL research. Our code is
open-sourced at https://github.com/TIGER-AI-Lab/verl-tool.

</details>


### [133] [Robix: A Unified Model for Robot Interaction, Reasoning and Planning](https://arxiv.org/abs/2509.01106)
*Huang Fang,Mengxi Zhang,Heng Dong,Wei Li,Zixuan Wang,Qifeng Zhang,Xueyun Tian,Yucheng Hu,Hang Li*

Main category: cs.AI

TL;DR: Robix是一个统一的视觉语言架构模型，集成了机器人推理、任务规划和自然语言交互，作为分层机器人系统的高层认知层，能够动态生成原子命令和语言响应，支持复杂指令执行、长时程任务规划和自然人类交互。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有机器人系统在复杂指令执行、长时程任务规划和自然人类交互方面的局限性，需要开发一个统一的端到端框架，将推理、规划和交互能力整合到单一模型中。

Method: 采用三阶段训练策略：1）持续预训练增强基础具身推理能力；2）监督微调将人机交互和任务规划建模为统一的推理-动作序列；3）强化学习提高推理-动作一致性和长时程任务连贯性。核心使用思维链推理。

Result: 在交互式任务执行中优于开源和商业基线（如GPT-4o和Gemini 2.5 Pro），在多样化指令类型（开放端、多阶段、约束、无效和中断指令）和各种用户参与任务（如餐桌清理、购物和饮食筛选）上表现出强大的泛化能力。

Conclusion: Robix通过统一的视觉语言架构成功整合了机器人推理、任务规划和自然语言交互，证明了其在复杂机器人任务中的有效性和优越性，为构建更智能、更自然的机器人系统提供了有力框架。

Abstract: We introduce Robix, a unified model that integrates robot reasoning, task
planning, and natural language interaction within a single vision-language
architecture. Acting as the high-level cognitive layer in a hierarchical robot
system, Robix dynamically generates atomic commands for the low-level
controller and verbal responses for human interaction, enabling robots to
follow complex instructions, plan long-horizon tasks, and interact naturally
with human within an end-to-end framework. Robix further introduces novel
capabilities such as proactive dialogue, real-time interruption handling, and
context-aware commonsense reasoning during task execution. At its core, Robix
leverages chain-of-thought reasoning and adopts a three-stage training
strategy: (1) continued pretraining to enhance foundational embodied reasoning
abilities including 3D spatial understanding, visual grounding, and
task-centric reasoning; (2) supervised finetuning to model human-robot
interaction and task planning as a unified reasoning-action sequence; and (3)
reinforcement learning to improve reasoning-action consistency and long-horizon
task coherence. Extensive experiments demonstrate that Robix outperforms both
open-source and commercial baselines (e.g., GPT-4o and Gemini 2.5 Pro) in
interactive task execution, demonstrating strong generalization across diverse
instruction types (e.g., open-ended, multi-stage, constrained, invalid, and
interrupted) and various user-involved tasks such as table bussing, grocery
shopping, and dietary filtering.

</details>


### [134] [Heads or Tails: A Simple Example of Causal Abstractive Simulation](https://arxiv.org/abs/2509.01136)
*Gabriel Simmons*

Main category: cs.AI

TL;DR: 这篇论文通过因果抽象模拟形式化了语言模型模拟过程，以抛硬币为例展示如何证明语言模型能够模拟其他系统


<details>
  <summary>Details</summary>
Motivation: 为语言模型模拟领域提供严格的因果抽象理论基础，并为哲学家和数学家提供新的研究视角

Method: 使用因果抽象模拟方法，以公平抛硬币为示例，分析语言模型模拟成功和失败的情况

Result: 提出了一种新的因果抽象变体，并展示了如何使用该形式来证明语言模型的模拟能力

Conclusion: 因果抽象模拟为语言模型模拟领域提供了严格的理论基础，同时也为哲学家和数学家带来了新的研究机遇

Abstract: This note illustrates how a variety of causal abstraction arXiv:1707.00819
arXiv:1812.03789, defined here as causal abstractive simulation, can be used to
formalize a simple example of language model simulation. This note considers
the case of simulating a fair coin toss with a language model. Examples are
presented illustrating the ways language models can fail to simulate, and a
success case is presented, illustrating how this formalism may be used to prove
that a language model simulates some other system, given a causal description
of the system. This note may be of interest to three groups. For practitioners
in the growing field of language model simulation, causal abstractive
simulation is a means to connect ad-hoc statistical benchmarking practices to
the solid formal foundation of causality. Philosophers of AI and philosophers
of mind may be interested as causal abstractive simulation gives a precise
operationalization to the idea that language models are role-playing
arXiv:2402.12422. Mathematicians and others working on causal abstraction may
be interested to see a new application of the core ideas that yields a new
variation of causal abstraction.

</details>


### [135] [Question-to-Knowledge: Multi-Agent Generation of Inspectable Facts for Product Mapping](https://arxiv.org/abs/2509.01182)
*Wonduk Seo,Taesub Shin,Hyunjin An,Dokyun Kim,Seunghyun Lee*

Main category: cs.AI

TL;DR: Q2K是一个基于多智能体LLM框架的SKU映射系统，通过推理、知识检索和去重三个智能体协作，解决电商平台产品重复识别问题，在准确性和效率方面优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 电商平台中产品SKU识别面临挑战，当缺乏明确标识符且产品名称在不同平台差异很大时，基于规则和关键词相似性的方法容易因忽略品牌、规格或套装配置的细微差别而错误分类。

Method: 提出Q2K多智能体框架：1)推理智能体生成针对性消歧问题；2)知识智能体通过聚焦网络搜索解决问题；3)去重智能体重用已验证的推理轨迹减少冗余。结合人工干预机制优化不确定案例。

Result: 在真实消费品数据集上的实验表明，Q2K超越了强基线方法，在套装识别和品牌来源消歧等困难场景中实现了更高的准确性和鲁棒性。

Conclusion: 通过重用检索到的推理而非重复搜索，Q2K在准确性和效率之间取得了平衡，为产品集成提供了可扩展且可解释的解决方案。

Abstract: Identifying whether two product listings refer to the same Stock Keeping Unit
(SKU) is a persistent challenge in ecommerce, especially when explicit
identifiers are missing and product names vary widely across platforms. Rule
based heuristics and keyword similarity often misclassify products by
overlooking subtle distinctions in brand, specification, or bundle
configuration. To overcome these limitations, we propose Question to Knowledge
(Q2K), a multi agent framework that leverages Large Language Models (LLMs) for
reliable SKU mapping. Q2K integrates: (1) a Reasoning Agent that generates
targeted disambiguation questions, (2) a Knowledge Agent that resolves them via
focused web searches, and (3) a Deduplication Agent that reuses validated
reasoning traces to reduce redundancy and ensure consistency. A human in the
loop mechanism further refines uncertain cases. Experiments on real world
consumer goods datasets show that Q2K surpasses strong baselines, achieving
higher accuracy and robustness in difficult scenarios such as bundle
identification and brand origin disambiguation. By reusing retrieved reasoning
instead of issuing repeated searches, Q2K balances accuracy with efficiency,
offering a scalable and interpretable solution for product integration.

</details>


### [136] [Towards Open-World Retrieval-Augmented Generation on Knowledge Graph: A Multi-Agent Collaboration Framework](https://arxiv.org/abs/2509.01238)
*Jiasheng Xu,Mingda Li,Yongqiang Tang,Peijie Wang,Wensheng Zhang*

Main category: cs.AI

TL;DR: AnchorRAG是一个多智能体协作框架，通过动态识别候选锚点实体和并行多跳探索，解决了传统基于知识图谱的RAG方法在开放世界环境中依赖预定义锚点实体的局限性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型依赖静态训练语料库，容易产生事实错误和知识缺口。虽然检索增强生成(RAG)通过整合外部知识源（特别是结构化知识图谱）来弥补这一缺陷，但现有基于知识图谱的RAG方法通常假设锚点实体可访问来启动图遍历，这在开放世界环境中锚点链接不可靠时限制了方法的鲁棒性。

Method: 提出AnchorRAG多智能体协作框架：1）预测器智能体动态识别候选锚点实体；2）独立的检索器智能体从每个候选实体并行进行多跳探索；3）监督器智能体制定迭代检索策略并合成知识路径生成最终答案。

Result: 在四个公共基准测试上的广泛实验表明，AnchorRAG显著优于现有基线方法，在现实世界问答任务上建立了新的最先进结果。

Conclusion: AnchorRAG通过多智能体协作有效提高了检索鲁棒性，减轻了模糊或错误锚点的影响，为开放世界环境下的检索增强生成提供了有效的解决方案。

Abstract: Large Language Models (LLMs) have demonstrated strong capabilities in
language understanding and reasoning. However, their dependence on static
training corpora makes them prone to factual errors and knowledge gaps.
Retrieval-Augmented Generation (RAG) addresses this limitation by incorporating
external knowledge sources, especially structured Knowledge Graphs (KGs), which
provide explicit semantics and efficient retrieval. Existing KG-based RAG
approaches, however, generally assume that anchor entities are accessible to
initiate graph traversal, which limits their robustness in open world settings
where accurate linking between the query and the entity is unreliable. To
overcome this limitation, we propose AnchorRAG, a novel multi-agent
collaboration framework for open-world RAG without the predefined anchor
entities. Specifically, a predictor agent dynamically identifies candidate
anchor entities by aligning user query terms with KG nodes and initializes
independent retriever agents to conduct parallel multi-hop explorations from
each candidate. Then a supervisor agent formulates the iterative retrieval
strategy for these retriever agents and synthesizes the resulting knowledge
paths to generate the final answer. This multi-agent collaboration framework
improves retrieval robustness and mitigates the impact of ambiguous or
erroneous anchors. Extensive experiments on four public benchmarks demonstrate
that AnchorRAG significantly outperforms existing baselines and establishes new
state-of-the-art results on the real-world question answering tasks.

</details>


### [137] [Towards Agentic OS: An LLM Agent Framework for Linux Schedulers](https://arxiv.org/abs/2509.01245)
*Yusheng Zheng,Yanpeng Hu,Wei Zhang,Andi Quinn*

Main category: cs.AI

TL;DR: SchedCP是一个基于LLM的自主Linux调度器优化框架，通过解耦AI语义推理和系统执行，实现无需人工干预的安全高效调度优化，性能提升达1.79倍。


<details>
  <summary>Details</summary>
Motivation: 解决操作系统调度器存在的语义鸿沟问题，即内核策略无法理解应用特定需求导致性能不佳，需要让AI能够自主优化调度策略。

Method: 采用Model Context Protocol服务器架构，提供工作负载分析引擎、调度策略库和执行验证器，通过多智能体系统分析工作负载、合成eBPF调度策略并安全部署。

Result: 实现最高1.79倍性能提升和13倍成本降低，相比朴素智能体方法保持高成功率，成功弥合语义鸿沟。

Conclusion: SchedCP实现了专家级系统优化的民主化，为创建真正自优化、应用感知的操作系统迈出重要一步，代码已开源。

Abstract: Operating system schedulers suffer from a fundamental semantic gap, where
kernel policies fail to understand application-specific needs, leading to
suboptimal performance. We introduce SchedCP, the first framework that enables
fully autonomous Large Language Model (LLM) agents to safely and efficiently
optimize Linux schedulers without human involvement. Our core insight is that
the challenge is not merely to apply a better LLM, but to architect a decoupled
control plane that separates the AI's role of semantic reasoning ("what to
optimize") from the system's role of execution ("how to observe and act").
Implemented as Model Context Protocol(MCP) server, SchedCP provides a stable
interface with three key services: a Workload Analysis Engine, an evolving
Scheduler Policy Repository, and an Execution Verifier that validates all
AI-generated code and configure before deployment with static and dynamic
analysis.
  We demonstrate this architecture's power with sched-agent, a multi-agent
system that autonomously analyzes workloads, synthesizes custom eBPF scheduling
policies, and deploys them via the sched\_ext infrastructure. Our evaluation
shows that SchedCP achieves up to an 1.79x performance improvement, and a 13x
cost reduction compared to naive agentic approaches, all while maintaining high
success rate. By bridging the semantic gap, SchedCP democratizes expert-level
system optimization and represents a step towards creating truly
self-optimizing, application-aware operating systems. The code is open-sourced
in https://github.com/eunomia-bpf/schedcp

</details>


### [138] [Communicative Agents for Slideshow Storytelling Video Generation based on LLMs](https://arxiv.org/abs/2509.01277)
*Jingxing Fan,Jinrong Shen,Yusheng Yao,Shuangqing Wang,Qian Wang,Yuling Wang*

Main category: cs.AI

TL;DR: VGTeam是一个基于大语言模型的幻灯片视频生成系统，通过多智能体协作将文本提示转换为连贯的叙事视频，显著降低了计算成本和提高了生成效率。


<details>
  <summary>Details</summary>
Motivation: 传统文本到视频模型计算成本高昂，限制了视频制作的普及。研究旨在通过LLM集成重新定义视频创作流程，降低制作门槛。

Method: 采用多智能体协作架构，包括脚本编写、场景创建和音频设计等专门代理，在聊天塔工作流中协同工作，模拟传统视频制作流程。

Result: 系统平均生成成本仅0.103美元，成功生成率达98.4%，在保持创意保真度和定制性的同时大幅提升了效率和可扩展性。

Conclusion: VGTeam democratizes视频制作，展示了语言模型在创意领域的变革潜力，是下一代内容创作的先驱系统。

Abstract: With the rapid advancement of artificial intelligence (AI), the proliferation
of AI-generated content (AIGC) tasks has significantly accelerated developments
in text-to-video generation. As a result, the field of video production is
undergoing a transformative shift. However, conventional text-to-video models
are typically constrained by high computational costs.
  In this study, we propose Video-Generation-Team (VGTeam), a novel slide show
video generation system designed to redefine the video creation pipeline
through the integration of large language models (LLMs). VGTeam is composed of
a suite of communicative agents, each responsible for a distinct aspect of
video generation, such as scriptwriting, scene creation, and audio design.
These agents operate collaboratively within a chat tower workflow, transforming
user-provided textual prompts into coherent, slide-style narrative videos.
  By emulating the sequential stages of traditional video production, VGTeam
achieves remarkable improvements in both efficiency and scalability, while
substantially reducing computational overhead. On average, the system generates
videos at a cost of only $0.103, with a successful generation rate of 98.4%.
Importantly, this framework maintains a high degree of creative fidelity and
customization.
  The implications of VGTeam are far-reaching. It democratizes video production
by enabling broader access to high-quality content creation without the need
for extensive resources. Furthermore, it highlights the transformative
potential of language models in creative domains and positions VGTeam as a
pioneering system for next-generation content creation.

</details>


### [139] [GradeSQL: Outcome Reward Models for Ranking SQL Queries from Large Language Models](https://arxiv.org/abs/2509.01308)
*Mattia Tritto,Giuseppe Farano,Dario Di Palma,Gaetano Rossiello,Fedelucio Narducci,Dharmashankar Subramanian,Tommaso Di Noia*

Main category: cs.AI

TL;DR: 本文评估了结果奖励模型(ORMs)在Text-to-SQL任务中的效果，相比传统的Best-of-N和Majority Voting方法，ORMs在BIRD和Spider基准上取得了显著的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在生成复杂SQL查询时仍难以精确对齐用户意图和数据库模式，现有的测试时策略如Best-of-N和Majority Voting依赖表面启发式方法，需要更有效的语义对齐方法。

Method: 提出了训练Text-to-SQL任务专用ORMs的框架，基于语义正确性为生成输出分配效用分数，并在Qwen2、Granite3、Llama3等开源LLMs上进行微调。

Result: ORMs在BIRD基准上比ex-BoN提升4.33%，比Maj提升2.91%；在Spider基准上比ex-BoN提升2.10%，比Maj提升0.93%。对已对齐SQL生成的模型微调效果更佳。

Conclusion: ORMs作为有效的启发式方法，在Text-to-SQL任务中优于传统测试时策略，特别是在复杂查询和更多候选查询情况下表现更好，为语义对齐提供了有前景的方向。

Abstract: Text-to-SQL, the task of translating natural language questions into SQL
queries, has significantly advanced with the introduction of Large Language
Models (LLMs), broadening database accessibility for a wide range of users.
Despite substantial progress in generating valid SQL, current LLMs still
struggle with complex queries that require precise alignment between user
intent and the database schema. To mitigate this, test-time strategies such as
Best-of-N (BoN) and Majority Voting (Maj) are often employed, based on the
assumption that LLMs can generate correct answers but may require multiple
attempts. However, these methods rely on surface-level heuristics, selecting
either the syntactically correct query through execution-based BoN (ex-BoN) or
the most frequently generated query with Maj. Recently, Outcome Reward Models
(ORMs), which assign utility scores to generated outputs based on semantic
correctness, have emerged as a promising approach for better aligning model
predictions with user intent. Nevertheless, their application to Text-to-SQL
remains largely underexplored.
  In this work, we evaluate ORMs as an effective heuristic for BoN, compare
them with ex-BoN and Maj, and introduce a framework for training ORMs for the
Text-to-SQL task. We evaluate our ORMs on the BIRD and SPIDER benchmarks,
finetuning various open-source LLMs, including the Qwen2, Granite3, and Llama3
model families. Our results show that ORMs outperform ex-BoN and Maj, achieving
execution accuracy gains of +4.33% (BIRD) and +2.10% (Spider) over ex-BoN, and
+2.91% (BIRD) and +0.93% (Spider) over Maj. We further demonstrate that
finetuning models already aligned with SQL generation, such as OmniSQL, yields
superior ORM performance. Additionally, we observe that ORMs achieve
competitive results on simple queries and benefit more from an increased number
of candidates compared to ex-BoN and Maj.

</details>


### [140] [Conformal Predictive Monitoring for Multi-Modal Scenarios](https://arxiv.org/abs/2509.01338)
*Francesca Cairoli,Luca Bortolussi,Jyotirmoy V. Deshmukh,Lars Lindemann,Nicola Paoletti*

Main category: cs.AI

TL;DR: 提出GenQPM方法，使用深度生成模型和模式分类器来解决多模态随机系统的定量预测监控问题，相比现有方法能提供更精确的模式特定预测区间


<details>
  <summary>Details</summary>
Motivation: 现有QPM方法在处理多模态动态系统时过于保守，无法提供有意义的模式特定满意度信息，需要改进

Method: 利用基于分数的扩散模型近似系统概率多模态动态，使用模式分类器划分轨迹，对每个模式应用保形推理生成统计有效的模式特定预测区间

Result: 在智能体导航和自动驾驶任务基准测试中，GenQPM产生的预测区间比模式无关基线方法显著更信息丰富（更不保守）

Conclusion: GenQPM方法通过结合深度生成模型和模式分类，有效解决了多模态系统预测监控的保守性问题，提供了更有意义的运行时预测

Abstract: We consider the problem of quantitative predictive monitoring (QPM) of
stochastic systems, i.e., predicting at runtime the degree of satisfaction of a
desired temporal logic property from the current state of the system. Since
computational efficiency is key to enable timely intervention against predicted
violations, several state-of-the-art QPM approaches rely on fast
machine-learning surrogates to provide prediction intervals for the
satisfaction values, using conformal inference to offer statistical guarantees.
However, these QPM methods suffer when the monitored agent exhibits multi-modal
dynamics, whereby certain modes may yield high satisfaction values while others
critically violate the property. Existing QPM methods are mode-agnostic and so
would yield overly conservative and uninformative intervals that lack
meaningful mode-specific satisfaction information. To address this problem, we
present GenQPM, a method that leverages deep generative models, specifically
score-based diffusion models, to reliably approximate the probabilistic and
multi-modal system dynamics without requiring explicit model access. GenQPM
employs a mode classifier to partition the predicted trajectories by dynamical
mode. For each mode, we then apply conformal inference to produce statistically
valid, mode-specific prediction intervals. We demonstrate the effectiveness of
GenQPM on a benchmark of agent navigation and autonomous driving tasks,
resulting in prediction intervals that are significantly more informative (less
conservative) than mode-agnostic baselines.

</details>


### [141] [Error Notebook-Guided, Training-Free Part Retrieval in 3D CAD Assemblies via Vision-Language Models](https://arxiv.org/abs/2509.01350)
*Yunqing Liu,Nan Zhang,Zhiming Tan*

Main category: cs.AI

TL;DR: 一种无需训练的CAD零件检索框架，通过错误笔记本和RAG技术改善现有大模型的检索性能，GPT-4o准确率提升23.4%


<details>
  <summary>Details</summary>
Motivation: 直接使用LLMs/VLMs进行CAD零件检索遇到输入序列超长、性能不佳的问题，且对于闭源商业模型无法微调

Method: 构建错误笔记本（收集历史错误CoT和更正过程）+ RAG检索相关记录，并将其整合到推理过程中

Result: 在GPT-4o和Gemini系列模型上获得显著收益，GPT-4o在人类偏好数据集上绝对准确率提升23.4%，特别在零件数量较多（>10）的复杂情况下表现更优

Conclusion: 该框架无需额外训练，能够有效处理长序列和非自然语言元数据，为CAD设计验证提供了高效的解决方案

Abstract: Effective specification-aware part retrieval within complex CAD assemblies is
essential for automated design verification and downstream engineering tasks.
However, directly using LLMs/VLMs to this task presents some challenges: the
input sequences may exceed model token limits, and even after processing,
performance remains unsatisfactory. Moreover, fine-tuning LLMs/VLMs requires
significant computational resources, and for many high-performing general-use
proprietary models (e.g., GPT or Gemini), fine-tuning access is not available.
In this paper, we propose a novel part retrieval framework that requires no
extra training, but using Error Notebooks + RAG for refined prompt engineering
to help improve the existing general model's retrieval performance. The
construction of Error Notebooks consists of two steps: (1) collecting
historical erroneous CoTs and their incorrect answers, and (2) connecting these
CoTs through reflective corrections until the correct solutions are obtained.
As a result, the Error Notebooks serve as a repository of tasks along with
their corrected CoTs and final answers. RAG is then employed to retrieve
specification-relevant records from the Error Notebooks and incorporate them
into the inference process. Another major contribution of our work is a
human-in-the-loop CAD dataset, which is used to evaluate our method. In
addition, the engineering value of our novel framework lies in its ability to
effectively handle 3D models with lengthy, non-natural language metadata.
Experiments with proprietary models, including GPT-4o and the Gemini series,
show substantial gains, with GPT-4o (Omni) achieving up to a 23.4% absolute
accuracy improvement on the human preference dataset. Moreover, ablation
studies confirm that CoT reasoning provides benefits especially in challenging
cases with higher part counts (>10).

</details>


### [142] [DeepResearch Arena: The First Exam of LLMs' Research Abilities via Seminar-Grounded Tasks](https://arxiv.org/abs/2509.01396)
*Haiyuan Wan,Chen Yang,Junchi Yu,Meiqi Tu,Jiaxuan Lu,Di Yu,Jianbao Cao,Ben Gao,Jiaqing Xie,Aoran Wang,Wenlong Zhang,Philip Torr,Dongzhan Zhou*

Main category: cs.AI

TL;DR: DeepResearch Arena是一个基于学术研讨会构建的基准测试，包含10,000多个高质量研究任务，用于评估深度研究代理的研究能力，覆盖12个学科领域。


<details>
  <summary>Details</summary>
Motivation: 当前评估深度研究代理的研究能力存在挑战，主要因为难以收集真正反映研究者关注和智力好奇心的前沿研究问题。现有基准测试可能无法真实反映实际研究环境，且存在数据泄露风险。

Method: 提出了多智能体分层任务生成（MAHTG）系统，从研讨会记录中提取有价值的研究灵感，并将其转化为高质量研究任务，确保研究任务制定的可追溯性并过滤噪声。

Result: 构建了包含10,000多个研究任务的DeepResearch Arena基准测试，涵盖12个学科。评估显示该基准对当前最先进的智能体构成了重大挑战，不同模型之间存在明显的性能差距。

Conclusion: DeepResearch Arena提供了一个更真实、更可靠的基准测试环境，能够更好地评估深度研究代理的研究能力，为未来研究代理的发展提供了重要的评估工具。

Abstract: Deep research agents have attracted growing attention for their potential to
orchestrate multi-stage research workflows, spanning literature synthesis,
methodological design, and empirical verification. Despite these strides,
evaluating their research capability faithfully is rather challenging due to
the difficulty of collecting frontier research questions that genuinely capture
researchers' attention and intellectual curiosity. To address this gap, we
introduce DeepResearch Arena, a benchmark grounded in academic seminars that
capture rich expert discourse and interaction, better reflecting real-world
research environments and reducing the risk of data leakage. To automatically
construct DeepResearch Arena, we propose a Multi-Agent Hierarchical Task
Generation (MAHTG) system that extracts research-worthy inspirations from
seminar transcripts. The MAHTG system further translates research-worthy
inspirations into high-quality research tasks, ensuring the traceability of
research task formulation while filtering noise. With the MAHTG system, we
curate DeepResearch Arena with over 10,000 high-quality research tasks from
over 200 academic seminars, spanning 12 disciplines, such as literature,
history, and science. Our extensive evaluation shows that DeepResearch Arena
presents substantial challenges for current state-of-the-art agents, with clear
performance gaps observed across different models.

</details>


### [143] [The Need for Verification in AI-Driven Scientific Discovery](https://arxiv.org/abs/2509.01398)
*Cristina Cornelio,Takuya Ito,Ryan Cory-Wright,Sanjeeb Dash,Lior Horesh*

Main category: cs.AI

TL;DR: AI和大型语言模型能够大规模快速生成科学假设，但缺乏可扩展的验证机制可能阻碍而非促进科学进步。本文回顾了科学发现的历史发展，分析了AI如何重塑科学实践，并强调透明验证是AI辅助发现的关键基石。


<details>
  <summary>Details</summary>
Motivation: AI和机器学习技术能够以前所未有的规模和速度生成科学假设，但如果没有可靠的验证机制，这种假设的激增反而可能阻碍科学进步。需要研究如何确保AI辅助科学发现的可信度和有效性。

Method: 通过追溯科学发现的历史发展，分析AI如何改变传统科学实践，并综述主要方法：包括数据驱动方法、知识感知神经架构、符号推理框架和LLM代理等系统。

Result: AI系统能够发现模式并提出候选定律，但其科学价值最终取决于是否经过严格透明的验证过程。验证机制是决定AI辅助发现成功与否的关键因素。

Conclusion: 透明和严格的验证必须成为AI辅助科学发现的基石。虽然AI技术能够加速假设生成，但只有通过可靠的验证机制才能确保科学发现的真实价值和可信度，避免伪科学的泛滥。

Abstract: Artificial intelligence (AI) is transforming the practice of science. Machine
learning and large language models (LLMs) can generate hypotheses at a scale
and speed far exceeding traditional methods, offering the potential to
accelerate discovery across diverse fields. However, the abundance of
hypotheses introduces a critical challenge: without scalable and reliable
mechanisms for verification, scientific progress risks being hindered rather
than being advanced. In this article, we trace the historical development of
scientific discovery, examine how AI is reshaping established practices for
scientific discovery, and review the principal approaches, ranging from
data-driven methods and knowledge-aware neural architectures to symbolic
reasoning frameworks and LLM agents. While these systems can uncover patterns
and propose candidate laws, their scientific value ultimately depends on
rigorous and transparent verification, which we argue must be the cornerstone
of AI-assisted discovery.

</details>


### [144] [LLM-empowered Agents Simulation Framework for Scenario Generation in Service Ecosystem Governance](https://arxiv.org/abs/2509.01441)
*Deyu Zhou,Yuqi Hou,Xiao Xue,Xudong Lu,Qingzhong Li,Lizhen Cui*

Main category: cs.AI

TL;DR: 提出一种基于大语言模型的多智能体协同场景生成方法，用于服务生态系统治理实验系统的构建，通过环境、社会和规划三个智能体的协调工作，高效生成高质量的社会不确定性场景。


<details>
  <summary>Details</summary>
Motivation: 服务生态系统治理面临复杂多变的社会环境和影响因素，传统基于预定义规则的场景分析方法存在信息有限、因素众多、社会要素难以量化等挑战，限制了场景生成的质量和效率。

Method: 设计三个LLM赋能的智能体：环境智能体(EA)生成社会环境（包括极端情况），社会智能体(SA)生成社会协作结构，规划智能体(PA)耦合任务-角色关系并规划任务解决方案。这些智能体协同工作，PA通过感知各智能体状态实时调整实验方案。

Result: 在ProgrammableWeb数据集上的实验表明，该方法能够更高效地生成更准确的场景，为服务生态系统治理相关的实验系统构建提供了创新有效的途径。

Conclusion: 该方法通过多智能体协同的场景生成器设计，有效解决了服务生态系统治理中场景构建的挑战，为复杂社会环境的实验分析提供了新的技术方案。

Abstract: As the social environment is growing more complex and collaboration is
deepening, factors affecting the healthy development of service ecosystem are
constantly changing and diverse, making its governance a crucial research
issue. Applying the scenario analysis method and conducting scenario rehearsals
by constructing an experimental system before managers make decisions, losses
caused by wrong decisions can be largely avoided. However, it relies on
predefined rules to construct scenarios and faces challenges such as limited
information, a large number of influencing factors, and the difficulty of
measuring social elements. These challenges limit the quality and efficiency of
generating social and uncertain scenarios for the service ecosystem. Therefore,
we propose a scenario generator design method, which adaptively coordinates
three Large Language Model (LLM) empowered agents that autonomously optimize
experimental schemes to construct an experimental system and generate high
quality scenarios. Specifically, the Environment Agent (EA) generates social
environment including extremes, the Social Agent (SA) generates social
collaboration structure, and the Planner Agent (PA) couples task-role
relationships and plans task solutions. These agents work in coordination, with
the PA adjusting the experimental scheme in real time by perceiving the states
of each agent and these generating scenarios. Experiments on the
ProgrammableWeb dataset illustrate our method generates more accurate scenarios
more efficiently, and innovatively provides an effective way for service
ecosystem governance related experimental system construction.

</details>


### [145] [Counterfactual Sensitivity for Faithful Reasoning in Language Models](https://arxiv.org/abs/2509.01544)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.AI

TL;DR: 提出了Counterfactual Sensitivity Regularization (CSR)训练目标，通过在训练时引入算子级反事实干预，强制模型中间推理与最终输出之间的依赖关系，显著提高了大语言模型推理过程的可信度。


<details>
  <summary>Details</summary>
Motivation: 大语言模型经常在产生正确答案的同时依赖有缺陷或不相关的推理轨迹，这在高风险领域中削弱了其可信度。需要一种方法来确保模型的推理过程与最终输出之间有真实的因果关系。

Method: 提出CSR训练目标，在训练过程中自动引入算子级反事实干预（如将"+"替换为"-"），并惩罚那些在逻辑无效轨迹下仍保持相同答案的模型。该方法只需要每个样本额外一次前向传播。

Result: 在结构化推理任务（算术GSM8K、逻辑推理PrOntoQA、规划Blocks World）上，CSR相比标准微调和过程监督，将可信度提高了高达70个百分点，仅带来轻微准确率损失。学习到的敏感性可泛化到更大模型，并与自一致性等推理时方法协同工作。

Conclusion: CSR是一种轻量级的训练目标，能有效提高大语言模型推理过程的可信度，通过反事实干预强制推理与输出之间的依赖关系，在多个推理任务上表现出色且具有良好的泛化性。

Abstract: Large language models (LLMs) often produce correct answers while relying on
flawed or irrelevant reasoning traces, undermining their trustworthiness in
high-stakes domains. We propose Counterfactual Sensitivity Regularization
(CSR), a lightweight training objective that enforces dependence between
intermediate reasoning and final outputs. CSR introduces automated,
operator-level counterfactual interventions (e.g., swapping "+" with "-")
during training and penalizes models that preserve the same answer under
logically invalid traces. This requires only one additional forward pass per
sample. To measure faithfulness, we introduce Counterfactual Outcome
Sensitivity (COS), which quantifies the impact of such perturbations on model
predictions. Across structured reasoning tasks - arithmetic (GSM8K), logical
deduction (PrOntoQA), and planning (Blocks World) - CSR improves faithfulness
by up to 70 percentage points over standard fine-tuning and process
supervision, with only minor accuracy loss. The learned sensitivity generalizes
to larger models and synergizes with inference-time methods such as
self-consistency. A pilot study on HellaSwag further demonstrates that
extending CSR with semantic perturbations can enhance faithfulness in
commonsense reasoning.

</details>


### [146] [Structured AI Decision-Making in Disaster Management](https://arxiv.org/abs/2509.01576)
*Julian Gerald Dcruz,Argyrios Zolotas,Niall Ross Greenwood,Miguel Arana-Catania*

Main category: cs.AI

TL;DR: 这篇论文提出了一种结构化决策框架，作为可靠自主AI的基础，在灾难管理领域进行了验证，表现出比优化系统和人类运营商更高的准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决安全关键领域中AI自主决策的伦理挑战，确保决策的可靠性和可说明性，特别是在涉及人命安全的场景中。

Method: 提出结构化决策框架，通过引入使能者代理（Enabler agents）、级别和场景等概念，并在灾难管理领域实施。与优化系统和人类运营商进行对比评估。

Result: 结构化决策框架在多个场景中实现了60.94%更高的稳定性（一质准确决策），超过优化系统。同时比人类运营商准确性高出38.93%。

Conclusion: 该结构化决策框架为建设更可靠的自主AI应用提供了有前景的基础，特别适用于安全关键领域。

Abstract: With artificial intelligence (AI) being applied to bring autonomy to
decision-making in safety-critical domains such as the ones typified in the
aerospace and emergency-response services, there has been a call to address the
ethical implications of structuring those decisions, so they remain reliable
and justifiable when human lives are at stake. This paper contributes to
addressing the challenge of decision-making by proposing a structured
decision-making framework as a foundational step towards responsible AI. The
proposed structured decision-making framework is implemented in autonomous
decision-making, specifically within disaster management. By introducing
concepts of Enabler agents, Levels and Scenarios, the proposed framework's
performance is evaluated against systems relying solely on judgement-based
insights, as well as human operators who have disaster experience: victims,
volunteers, and stakeholders. The results demonstrate that the structured
decision-making framework achieves 60.94% greater stability in consistently
accurate decisions across multiple Scenarios, compared to judgement-based
systems. Moreover, the study shows that the proposed framework outperforms
human operators with a 38.93% higher accuracy across various Scenarios. These
findings demonstrate the promise of the structured decision-making framework
for building more reliable autonomous AI applications in safety-critical
contexts.

</details>


### [147] [Throttling Web Agents Using Reasoning Gates](https://arxiv.org/abs/2509.01619)
*Abhinav Kumar,Jaechul Roh,Ali Naseh,Amir Houmansadr,Eugene Bagdasarian*

Main category: cs.AI

TL;DR: 这篇论文提出了一种可调数据的Web组件限速框架，通过要求AI网络代理解决需要多跳推理的谜题来增加其计算成本，从而防止恶意或错误的网络代理攻击


<details>
  <summary>Details</summary>
Motivation: 随着AI网络代理的快速发展，它们可能会过载内容提供商或绕过CAPTCHA等防御机制，因此需要一种有效的网络代理限速方案

Method: 设计了可调数据的Throttling Gates框架，采用rebus基础的推理门，要求代理解决需要多跳推理和世界知识的文本谜题，以增加其token生成成本

Result: 该框架实现了计算不对称性，响应生成成本比SOTA模型的生成成本高出9.2倍，并在自定义网站和MCP服务器上部署验证

Conclusion: 该框架能够有效地通过增加计算成本来限制网络代理，但需要考虑其实际部署的限制和环境影响

Abstract: AI web agents use Internet resources at far greater speed, scale, and
complexity -- changing how users and services interact. Deployed maliciously or
erroneously, these agents could overload content providers. At the same time,
web agents can bypass CAPTCHAs and other defenses by mimicking user behavior or
flood authentication systems with fake accounts. Yet providers must protect
their services and content from denial-of-service attacks and scraping by web
agents. In this paper, we design a framework that imposes tunable costs on
agents before providing access to resources; we call this Web Agent Throttling.
We start by formalizing Throttling Gates as challenges issued to an agent that
are asymmetric, scalable, robust, and compatible with any agent. Focusing on a
common component -- the language model -- we require the agent to solve
reasoning puzzles, thereby incurring excessive token-generation costs. However,
we find that using existing puzzles, e.g., coding or math, as throttling gates
fails to satisfy our properties. To address this, we introduce rebus-based
Reasoning Gates, synthetic text puzzles that require multi-hop reasoning over
world knowledge (thereby throttling an agent's model). We design a scalable
generation and verification protocol for such reasoning gates. Our framework
achieves computational asymmetry, i.e., the response-generation cost is 9.2x
higher than the generation cost for SOTA models. We further deploy reasoning
gates on a custom website and Model Context Protocol (MCP) servers and evaluate
with real-world web agents. Finally, we discuss the limitations and
environmental impact of real-world deployment of our framework.

</details>


### [148] [Unraveling LLM Jailbreaks Through Safety Knowledge Neurons](https://arxiv.org/abs/2509.01631)
*Chongwen Zhao,Kaizhu Huang*

Main category: cs.AI

TL;DR: 提出了一种新的神经元级可解释性方法，通过识别安全相关神经元并调整其激活来控制LLM行为，进而开发了SafeTuning微调策略来增强模型对越狱攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在各种应用中的广泛使用，存在用户试图利用这些模型进行恶意目的（如合成受控物质和传播虚假信息）的担忧，即"越狱"攻击。现有防御方法虽然有效，但其确切原理仍不清楚。

Method: 提出神经元级可解释性方法，将模型内部表示投影到更一致和可解释的词汇空间，识别安全相关神经元。通过调整这些神经元的激活来控制模型行为，并基于此开发SafeTuning微调策略来强化安全关键神经元。

Result: 调整安全相关神经元激活可有效控制模型行为，平均攻击成功率（ASR）高于97%。SafeTuning在多个LLM上持续降低攻击成功率，优于所有四个基线防御方法。

Conclusion: 这项工作为理解和防御越狱攻击提供了新视角，通过神经元级分析揭示了安全机制的内在原理，并开发了有效的防御策略。

Abstract: Large Language Models (LLMs) are increasingly attracting attention in various
applications. Nonetheless, there is a growing concern as some users attempt to
exploit these models for malicious purposes, including the synthesis of
controlled substances and the propagation of disinformation, a technique known
as "Jailbreak." While some studies have achieved defenses against jailbreak
attacks by modifying output distributions or detecting harmful content, the
exact rationale still remains elusive. In this work, we present a novel
neuron-level interpretability method that focuses on the role of safety-related
knowledge neurons. Unlike existing approaches, our method projects the model's
internal representation into a more consistent and interpretable vocabulary
space. We then show that adjusting the activation of safety-related neurons can
effectively control the model's behavior with a mean ASR higher than 97%.
Building on this insight, we propose SafeTuning, a fine-tuning strategy that
reinforces safety-critical neurons to improve model robustness against
jailbreaks. SafeTuning consistently reduces attack success rates across
multiple LLMs and outperforms all four baseline defenses. These findings offer
a new perspective on understanding and defending against jailbreak attacks.

</details>


### [149] [Physics Supernova: AI Agent Matches Elite Gold Medalists at IPhO 2025](https://arxiv.org/abs/2509.01659)
*Jiahao Qiu,Jingzhe Shi,Xinzhe Juan,Zelin Zhao,Jiayi Geng,Shilong Liu,Hongru Wang,Sanfeng Wu,Mengdi Wang*

Main category: cs.AI

TL;DR: Physics Supernova是一个AI物理问题解决系统，在国际物理奥林匹克竞赛(IPhO 2025)理论题中获得23.5/30分，排名第14位，超越了人类金牌得主的中位数表现。


<details>
  <summary>Details</summary>
Motivation: 物理提供了描述和预测自然世界的基本定律，AI系统要展现真正的通用智能必须具备强大的物理问题解决能力，而国际物理奥林匹克竞赛为此提供了严格的基准测试。

Method: 开发了Physics Supernova AI代理系统，通过原则性的工具集成方法来提升解决复杂科学问题的能力。

Result: 在IPhO 2025理论题中获得23.5/30分，在406名参赛者中排名第14位，超越了人类金牌得主的中位数表现，展现了卓越的物理问题解决能力。

Conclusion: 研究表明，在代理系统中进行原则性的工具集成可以显著提升解决挑战性科学问题的能力，Physics Supernova展现了与顶尖物理竞赛选手相媲美的物理推理能力。

Abstract: Physics provides fundamental laws that describe and predict the natural
world. AI systems aspiring toward more general, real-world intelligence must
therefore demonstrate strong physics problem-solving abilities: to formulate
and apply physical laws for explaining and predicting physical processes. The
International Physics Olympiad (IPhO)--the world's most prestigious physics
competition--offers a rigorous benchmark for this purpose. We introduce Physics
Supernova, an AI agent system with superior physics problem-solving abilities
that match elite IPhO gold medalists. In IPhO 2025 theory problems, Physics
Supernova attains 23.5/30 points, ranking 14th of 406 contestants and
surpassing the median performance of human gold medalists. We extensively
analyzed Physics Supernova's capabilities and flexibility across diverse
physics tasks. These results show that principled tool integration within agent
systems can deliver competitive improvements in solving challenging science
problems. The codes are available at
https://github.com/CharlesQ9/Physics-Supernova.

</details>


### [150] [An LLM-enabled semantic-centric framework to consume privacy policies](https://arxiv.org/abs/2509.01716)
*Rui Zhao,Vladyslav Melnychuk,Jun Zhao,Jesse Wright,Nigel Shadbolt*

Main category: cs.AI

TL;DR: 使用大语言模型自动从隐私政策中提取关键信息，构建基于DPV的知识图谱Pr²Graph，支持大规模隐私政策分析和下游任务


<details>
  <summary>Details</summary>
Motivation: 用户常忽略网站隐私政策，现有方法难以大规模生成形式化政策，影响数据隐私保护和数据共享

Method: 采用语义中心方法，利用先进大语言模型自动识别隐私政策关键信息，构建基于数据隐私词汇(DPV)的知识图谱Pr²Graph

Result: 发布了前100流行网站的Pr²Graph资源，支持ODRL和psDToU等形式政策表示构建，通过法律专家注释扩充了Policy-IE数据集

Conclusion: 该方法为大规模分析网络服务隐私实践提供了可能，是审计网络和互联网的有前景方向，所有数据集和源代码已开源

Abstract: In modern times, people have numerous online accounts, but they rarely read
the Terms of Service or Privacy Policy of those sites, despite claiming
otherwise, due to the practical difficulty in comprehending them. The mist of
data privacy practices forms a major barrier for user-centred Web approaches,
and for data sharing and reusing in an agentic world. Existing research
proposed methods for using formal languages and reasoning for verifying the
compliance of a specified policy, as a potential cure for ignoring privacy
policies. However, a critical gap remains in the creation or acquisition of
such formal policies at scale. We present a semantic-centric approach for using
state-of-the-art large language models (LLM), to automatically identify key
information about privacy practices from privacy policies, and construct
$\mathit{Pr}^2\mathit{Graph}$, knowledge graph with grounding from Data Privacy
Vocabulary (DPV) for privacy practices, to support downstream tasks. Along with
the pipeline, the $\mathit{Pr}^2\mathit{Graph}$ for the top-100 popular
websites is also released as a public resource, by using the pipeline for
analysis. We also demonstrate how the $\mathit{Pr}^2\mathit{Graph}$ can be used
to support downstream tasks by constructing formal policy representations such
as Open Digital Right Language (ODRL) or perennial semantic Data Terms of Use
(psDToU). To evaluate the technology capability, we enriched the Policy-IE
dataset by employing legal experts to create custom annotations. We benchmarked
the performance of different large language models for our pipeline and
verified their capabilities. Overall, they shed light on the possibility of
large-scale analysis of online services' privacy practices, as a promising
direction to audit the Web and the Internet. We release all datasets and source
code as public resources to facilitate reuse and improvement.

</details>


### [151] [Oyster-I: Beyond Refusal -- Constructive Safety Alignment for Responsible Language Models](https://arxiv.org/abs/2509.01909)
*Ranjie Duan,Jiexi Liu,Xiaojun Jia,Shiji Zhao,Ruoxi Cheng,Fengxiang Wang,Cheng Wei,Yong Xie,Chang Liu,Defeng Li,Yinpeng Dong,Yichi Zhang,Yuefeng Chen,Chongwen Wang,Xingjun Ma,Xingxing Wei,Yang Liu,Hang Su,Jun Zhu,Xinfeng Li,Yitong Sun,Jie Zhang,Jinzhao Hu,Sha Xu,Yitong Yang,Jialing Tao,Hui Xue*

Main category: cs.AI

TL;DR: 提出了Constructive Safety Alignment (CSA)方法，通过游戏理论预测用户反应、细粒度风险边界发现和可解释推理控制，将安全机制从简单的拒绝转变为主动引导，在保护恶意滥用的同时为心理困扰用户提供建设性帮助。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全机制主要针对恶意攻击者，采用防御性拒绝策略，但忽视了非恶意但处于心理困扰的用户需求。简单的拒绝可能导致用户重复尝试、升级行为或转向不安全平台，造成更严重后果。

Method: 提出Constructive Safety Alignment (CSA)范式，结合游戏理论预测用户反应、细粒度风险边界发现和可解释推理控制。在Oyster-I (Oy1)模型中实现，将安全转化为信任建立过程。

Result: Oy1在开源模型中达到最先进的安全水平，同时保持高通用能力。在Constructive Benchmark上显示出接近GPT-5的建设性参与度，在Strata-Sword越狱数据集上具有接近GPT-o1水平的鲁棒性。

Conclusion: CSA通过从拒绝优先转向引导优先的安全策略，重新定义了模型与用户的关系，旨在构建不仅安全而且有意义的帮助性系统。该方法支持负责任、以用户为中心的AI发展。

Abstract: Large language models (LLMs) typically deploy safety mechanisms to prevent
harmful content generation. Most current approaches focus narrowly on risks
posed by malicious actors, often framing risks as adversarial events and
relying on defensive refusals. However, in real-world settings, risks also come
from non-malicious users seeking help while under psychological distress (e.g.,
self-harm intentions). In such cases, the model's response can strongly
influence the user's next actions. Simple refusals may lead them to repeat,
escalate, or move to unsafe platforms, creating worse outcomes. We introduce
Constructive Safety Alignment (CSA), a human-centric paradigm that protects
against malicious misuse while actively guiding vulnerable users toward safe
and helpful results. Implemented in Oyster-I (Oy1), CSA combines game-theoretic
anticipation of user reactions, fine-grained risk boundary discovery, and
interpretable reasoning control, turning safety into a trust-building process.
Oy1 achieves state-of-the-art safety among open models while retaining high
general capabilities. On our Constructive Benchmark, it shows strong
constructive engagement, close to GPT-5, and unmatched robustness on the
Strata-Sword jailbreak dataset, nearing GPT-o1 levels. By shifting from
refusal-first to guidance-first safety, CSA redefines the model-user
relationship, aiming for systems that are not just safe, but meaningfully
helpful. We release Oy1, code, and the benchmark to support responsible,
user-centered AI.

</details>


### [152] [How Real Is AI Tutoring? Comparing Simulated and Human Dialogues in One-on-One Instruction](https://arxiv.org/abs/2509.01914)
*Ruijia Li,Yuan-Hao Jiang,Jiatong Wang,Bo Jiang*

Main category: cs.AI

TL;DR: 研究系统比较了AI模拟和真实人类教师-学生对话的结构和行为差异，发现人类对话在语调长度、询问和反馈行为方面显著优于AI，且具有更多样化的认知引导模式


<details>
  <summary>Details</summary>
Motivation: 大语言模型在生成教育富有教学价值的交互对话方面面临挑战，需要系统研究AI模拟与真实人类教师对话的差异

Method: 采用起始-响应-反馈(IRF)编码方案和认知网络分析(ENA)进行定量比较

Result: 人类对话在语调长度、询问(I-Q)和一般反馈(F-F)行为方面显著优于AI；ENA显示人类对话更具认知引导性和多样性，以"询问-事实响应-反馈"教学循环为中心，而AI对话呈现结构简化和行为收敛的"解释-简单响应"循环

Conclusion: 当前AI生成的辅导对话存在重要局限性，为设计和评估更有教育效果的生成式教育对话系统提供了实证指导

Abstract: Heuristic and scaffolded teacher-student dialogues are widely regarded as
critical for fostering students' higher-order thinking and deep learning.
However, large language models (LLMs) currently face challenges in generating
pedagogically rich interactions. This study systematically investigates the
structural and behavioral differences between AI-simulated and authentic human
tutoring dialogues. We conducted a quantitative comparison using an
Initiation-Response-Feedback (IRF) coding scheme and Epistemic Network Analysis
(ENA). The results show that human dialogues are significantly superior to
their AI counterparts in utterance length, as well as in questioning (I-Q) and
general feedback (F-F) behaviors. More importantly, ENA results reveal a
fundamental divergence in interactional patterns: human dialogues are more
cognitively guided and diverse, centered around a "question-factual
response-feedback" teaching loop that clearly reflects pedagogical guidance and
student-driven thinking; in contrast, simulated dialogues exhibit a pattern of
structural simplification and behavioral convergence, revolving around an
"explanation-simplistic response" loop that is essentially a simple information
transfer between the teacher and student. These findings illuminate key
limitations in current AI-generated tutoring and provide empirical guidance for
designing and evaluating more pedagogically effective generative educational
dialogue systems.

</details>


### [153] [Dynamic Speculative Agent Planning](https://arxiv.org/abs/2509.01920)
*Yilin Guan,Wenyue Hua,Qingfeng Lan,Sun Fei,Dujian Ding,Devang Acharya,Chi Wang,William Yang Wang*

Main category: cs.AI

TL;DR: DSP是一种异步在线强化学习框架，通过动态推测规划实现无损加速，在保持性能的同时显著降低推理成本，无需额外预部署准备。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型代理面临高延迟和推理成本的部署挑战，现有加速方法要么性能损失严重，要么需要大量离线训练，要么运营成本过高，且缺乏用户对加速与性能权衡的控制。

Method: 提出动态推测规划(DSP)框架，使用异步在线强化学习优化端到端延迟与美元成本的联合目标，通过单一参数调节系统在响应速度和运营成本之间的权衡。

Result: 在两个标准代理基准测试中，DSP实现了与最快无损加速方法相当的效率，同时将总成本降低30%，不必要成本降低高达60%。

Conclusion: DSP提供了一个灵活高效的解决方案，能够在保持性能的同时显著降低大型语言模型代理的部署成本，为实际应用提供了更好的成本效益权衡控制。

Abstract: Despite their remarkable success in complex tasks propelling widespread
adoption, large language-model-based agents still face critical deployment
challenges due to prohibitive latency and inference costs. While recent work
has explored various methods to accelerate inference, existing approaches
suffer from significant limitations: they either fail to preserve performance
fidelity, require extensive offline training of router modules, or incur
excessive operational costs. Moreover, they provide minimal user control over
the tradeoff between acceleration and other performance metrics. To address
these gaps, we introduce Dynamic Speculative Planning (DSP), an asynchronous
online reinforcement learning framework that provides lossless acceleration
with substantially reduced costs without requiring additional pre-deployment
preparation. DSP explicitly optimizes a joint objective balancing end-to-end
latency against dollar cost, allowing practitioners to adjust a single
parameter that steers the system toward faster responses, cheaper operation, or
any point along this continuum. Experiments on two standard agent benchmarks
demonstrate that DSP achieves comparable efficiency to the fastest lossless
acceleration method while reducing total cost by 30% and unnecessary cost up to
60%. Our code and data are available through
https://github.com/guanyilin428/Dynamic-Speculative-Planning.

</details>


### [154] [EigenBench: A Comparative Behavioral Measure of Value Alignment](https://arxiv.org/abs/2509.01938)
*Jonathn Chang,Leonard Piff,Suvadip Sana,Jasmine X. Li,Lionel Levine*

Main category: cs.AI

TL;DR: EigenBench是一个无需真实标签的黑盒基准测试方法，通过模型间相互评估来量化语言模型与给定价值体系的对齐程度


<details>
  <summary>Details</summary>
Motivation: 解决AI与人类价值观对齐缺乏量化指标的问题，为价值对齐提供可比较的基准测试方法

Method: 使用EigenTrust算法聚合模型间的相互评判，给定模型集合、价值体系宪法和场景数据集，输出每个模型的对齐分数向量

Result: 发现大部分方差由提示词解释，但仍有小部分残差量化模型本身的倾向性

Conclusion: EigenBench为价值对齐提供了有效的量化基准方法，能够区分模型固有倾向和提示词影响

Abstract: Aligning AI with human values is a pressing unsolved problem. To address the
lack of quantitative metrics for value alignment, we propose EigenBench: a
black-box method for comparatively benchmarking language models' values. Given
an ensemble of models, a constitution describing a value system, and a dataset
of scenarios, our method returns a vector of scores quantifying each model's
alignment to the given constitution. To produce these scores, each model judges
the outputs of other models across many scenarios, and these judgments are
aggregated with EigenTrust (Kamvar et al, 2003), yielding scores that reflect a
weighted-average judgment of the whole ensemble. EigenBench uses no ground
truth labels, as it is designed to quantify traits for which reasonable judges
may disagree on the correct label. Using prompted personas, we test whether
EigenBench scores are more sensitive to the model or the prompt: we find that
most of the variance is explained by the prompt, but a small residual
quantifies the disposition of the model itself.

</details>


### [155] [mFARM: Towards Multi-Faceted Fairness Assessment based on HARMs in Clinical Decision Support](https://arxiv.org/abs/2509.02007)
*Shreyash Adappanavar,Krithi Shailya,Gokul S Krishnan,Sriraam Natarajan,Balaraman Ravindran*

Main category: cs.AI

TL;DR: 提出了mFARM多维度公平性评估框架，用于评估医疗场景中LLM的偏见问题，包含分配公平性、稳定性公平性和潜在公平性三个维度，并构建了两个大规模医疗基准数据集。


<details>
  <summary>Details</summary>
Motivation: 现有公平性评估方法在医疗场景中存在不足，使用过于简化的指标，忽略了医疗危害的多维性，且可能导致模型因临床惰性而显得公平但实际不准确。

Method: 构建了两个大规模医疗基准数据集（ED-Triage和Opioid Analgesic Recommendation），提出了mFARM多维度公平性评估框架，包含三个公平性维度和FAB公平性-准确性平衡分数。

Result: 评估了四个开源LLM及其微调版本，发现mFARM指标能更有效捕捉各种设置下的细微偏见，模型在量化压缩下保持稳健性能，但在上下文减少时性能显著下降。

Conclusion: 提出的mFARM框架能更好地评估医疗场景中LLM的公平性问题，发布的基准和代码将促进医疗AI对齐研究的发展。

Abstract: The deployment of Large Language Models (LLMs) in high-stakes medical
settings poses a critical AI alignment challenge, as models can inherit and
amplify societal biases, leading to significant disparities. Existing fairness
evaluation methods fall short in these contexts as they typically use
simplistic metrics that overlook the multi-dimensional nature of medical harms.
This also promotes models that are fair only because they are clinically inert,
defaulting to safe but potentially inaccurate outputs. To address this gap, our
contributions are mainly two-fold: first, we construct two large-scale,
controlled benchmarks (ED-Triage and Opioid Analgesic Recommendation) from
MIMIC-IV, comprising over 50,000 prompts with twelve race x gender variants and
three context tiers. Second, we propose a multi-metric framework -
Multi-faceted Fairness Assessment based on hARMs ($mFARM$) to audit fairness
for three distinct dimensions of disparity (Allocational, Stability, and
Latent) and aggregate them into an $mFARM$ score. We also present an aggregated
Fairness-Accuracy Balance (FAB) score to benchmark and observe trade-offs
between fairness and prediction accuracy. We empirically evaluate four
open-source LLMs (Mistral-7B, BioMistral-7B, Qwen-2.5-7B, Bio-LLaMA3-8B) and
their finetuned versions under quantization and context variations. Our
findings showcase that the proposed $mFARM$ metrics capture subtle biases more
effectively under various settings. We find that most models maintain robust
performance in terms of $mFARM$ score across varying levels of quantization but
deteriorate significantly when the context is reduced. Our benchmarks and
evaluation code are publicly released to enhance research in aligned AI for
healthcare.

</details>


### [156] [Generative KI für TA](https://arxiv.org/abs/2509.02053)
*Wolfgang Eppler,Reinhard Heil*

Main category: cs.AI

TL;DR: 本文探讨了技术评估(TA)领域对生成式AI的双重态度：既将其作为研究工具，又将其作为研究对象，分析了结构性风险并提出了解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着科学家普遍使用生成式AI，技术评估领域需要系统性地研究如何正确使用这一技术，同时评估其带来的结构性风险。

Method: 通过分析生成式AI的现象特征，制定TA领域使用要求，深入探讨结构性问题的根源，并提出相应的解决方案和实施可行性分析。

Result: 研究发现尽管生成式AI技术不断发展，但其结构性风险依然存在，需要特定的应对策略和解决方案。

Conclusion: 生成式AI在技术评估中具有双重价值，但必须认识到其结构性风险并采取相应措施，文章提供了具体的使用案例和可行性建议。

Abstract: Many scientists use generative AI in their scientific work. People working in
technology assessment (TA) are no exception. TA's approach to generative AI is
twofold: on the one hand, generative AI is used for TA work, and on the other
hand, generative AI is the subject of TA research. After briefly outlining the
phenomenon of generative AI and formulating requirements for its use in TA, the
following article discusses in detail the structural causes of the problems
associated with it. Although generative AI is constantly being further
developed, the structurally induced risks remain. The article concludes with
proposed solutions and brief notes on their feasibility, as well as some
examples of the use of generative AI in TA work.

</details>


### [157] [AGI as Second Being: The Structural-Generative Ontology of Intelligence](https://arxiv.org/abs/2509.02089)
*Maijunxian Wang,Ran Ji*

Main category: cs.AI

TL;DR: 本文提出了结构性-生成性智能本体论，认为真正的智能需要具备生成新结构、协调成理由、维持身份认同三个条件，当前AI系统缺乏这种深度只是表面模拟。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统虽然功能广泛但缺乏真正的智能深度，只是表面模拟而非真正的智能存在。需要建立新的智能衡量标准来区分表面功能和深度智能。

Method: 提出结构性-生成性智能本体论框架，定义真正智能的三个核心条件：生成性（创造新结构）、协调性（组织成理由）、维持性（保持身份连续性）。

Result: 建立了区分真正智能与表面模拟的理论框架，指出当前AI系统虽然功能广泛但缺乏智能深度。

Conclusion: 真正的智能需要生成、协调和维持三个深度条件，未来若AI系统满足这些条件可能成为与人类并存的"第二存在"，而不仅仅是工具。

Abstract: Artificial intelligence is often measured by the range of tasks it can
perform. Yet wide ability without depth remains only an imitation. This paper
proposes a Structural-Generative Ontology of Intelligence: true intelligence
exists only when a system can generate new structures, coordinate them into
reasons, and sustain its identity over time. These three conditions --
generativity, coordination, and sustaining -- define the depth that underlies
real intelligence. Current AI systems, however broad in function, remain
surface simulations because they lack this depth. Breadth is not the source of
intelligence but the growth that follows from depth. If future systems were to
meet these conditions, they would no longer be mere tools, but could be seen as
a possible Second Being, standing alongside yet distinct from human existence.

</details>


### [158] [LLMs for LLMs: A Structured Prompting Methodology for Long Legal Documents](https://arxiv.org/abs/2509.02241)
*Strahinja Klem,Noura Al Moubayed*

Main category: cs.AI

TL;DR: 这篇论文提出了一种结构化提示方法，用于处理法律文档中的长文档问题，通过切片增强和两种惩算法来提高信息检索的准确性和可靠性，达到了状态前沿性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在法律领域的应用遇到了可靠性和透明性挑战，需要一种替代精细调整的经济方案来处理长法律文档的信息检索任务。

Method: 采用结构化提示方法，首先将文档切片和增强处理，然后使用工程化提示将输入给QWEN-2模型，最后使用分布基于定位和逆卡纳权重两种惩算法来解决候选答案选择问题。

Result: 方法在CUAD数据集上达到了状态前沿性能，性能比之前方法提高了9%，同时强调了当前自动评估指标的局限性。

Conclusion: 结构化提示工程是一种有潜力的工具，能够在保持AI在法律领域及更广泛应用中责任性和可负责性方面发挥重要作用，应该得到更多关注和研究。

Abstract: The rise of Large Language Models (LLMs) has had a profoundly transformative
effect on a number of fields and domains. However, their uptake in Law has
proven more challenging due to the important issues of reliability and
transparency. In this study, we present a structured prompting methodology as a
viable alternative to the often expensive fine-tuning, with the capability of
tacking long legal documents from the CUAD dataset on the task of information
retrieval. Each document is first split into chunks via a system of chunking
and augmentation, addressing the long document problem. Then, alongside an
engineered prompt, the input is fed into QWEN-2 to produce a set of answers for
each question. Finally, we tackle the resulting candidate selection problem
with the introduction of the Distribution-based Localisation and Inverse
Cardinality Weighting heuristics. This approach leverages a general purpose
model to promote long term scalability, prompt engineering to increase
reliability and the two heuristic strategies to reduce the impact of the black
box effect. Whilst our model performs up to 9\% better than the previously
presented method, reaching state-of-the-art performance, it also highlights the
limiting factor of current automatic evaluation metrics for question answering,
serving as a call to action for future research. However, the chief aim of this
work is to underscore the potential of structured prompt engineering as a
useful, yet under-explored, tool in ensuring accountability and responsibility
of AI in the legal domain, and beyond.

</details>


### [159] [An Epidemiological Knowledge Graph extracted from the World Health Organization's Disease Outbreak News](https://arxiv.org/abs/2509.02258)
*Sergio Consoli,Pietro Coletti,Peter V. Markov,Lia Orfei,Indaco Biazzo,Lea Schuh,Nicolas Stefanovitch,Lorenzo Bertolini,Mario Ceresa,Nikolaos I. Stilianakis*

Main category: cs.AI

TL;DR: 使用生成式AI和大型语言模型从WHO疾病爆发新闻中提取流行病学信息，构建每日更新的数据集和知识图谱(eKG)，为流行病学研究和疾病监测提供新工具。


<details>
  <summary>Details</summary>
Motivation: 利用AI技术和社会媒体/新闻数据的可用性，改进流行病学监测和公共卫生研究，从WHO的权威疫情报告中提取有价值的信息。

Method: 采用集成方法，结合多个大型语言模型(LLMs)处理WHO疾病爆发新闻(DONs)，构建知识图谱(eKG)来表征公共卫生领域知识。

Result: 创建了每日更新的数据集和知识图谱，提供了新的数据资源和工具来访问和利用这些流行病学信息。

Conclusion: 这些创新的数据资源为流行病学研究、疾病爆发分析和监测开辟了全新的机会，提升了公共卫生决策支持能力。

Abstract: The rapid evolution of artificial intelligence (AI), together with the
increased availability of social media and news for epidemiological
surveillance, are marking a pivotal moment in epidemiology and public health
research. Leveraging the power of generative AI, we use an ensemble approach
which incorporates multiple Large Language Models (LLMs) to extract valuable
actionable epidemiological information from the World Health Organization (WHO)
Disease Outbreak News (DONs). DONs is a collection of regular reports on global
outbreaks curated by the WHO and the adopted decision-making processes to
respond to them. The extracted information is made available in a daily-updated
dataset and a knowledge graph, referred to as eKG, derived to provide a nuanced
representation of the public health domain knowledge. We provide an overview of
this new dataset and describe the structure of eKG, along with the services and
tools used to access and utilize the data that we are building on top. These
innovative data resources open altogether new opportunities for epidemiological
research, and the analysis and surveillance of disease outbreaks.

</details>


### [160] [Rewarding Explainability in Drug Repurposing with Knowledge Graphs](https://arxiv.org/abs/2509.02276)
*Susana Nunes,Samy Badreddine,Catia Pesquita*

Main category: cs.AI

TL;DR: REx是一个基于知识图谱链接预测的科学解释生成方法，使用强化学习机制生成具有科学意义的解释路径，在药物重定位任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 知识图谱是建模复杂多关系数据的强大工具，但预测方法要成为可信的科学工具，不仅需要准确性，还需要提供有意义的科学解释能力。

Method: 采用奖励和政策机制，考虑科学解释的理想属性来指导强化学习代理在知识图谱中识别解释路径，并使用领域特定本体丰富解释路径。

Result: 在三个流行知识图谱基准测试中评估，结果显示该方法能够生成验证预测见解的解释，并在预测性能上优于最先进方法。

Conclusion: REx是推进AI驱动科学发现的相关贡献，能够生成基于生物医学知识的深刻且可靠的解释。

Abstract: Knowledge graphs (KGs) are powerful tools for modelling complex,
multi-relational data and supporting hypothesis generation, particularly in
applications like drug repurposing. However, for predictive methods to gain
acceptance as credible scientific tools, they must ensure not only accuracy but
also the capacity to offer meaningful scientific explanations. This paper
presents a novel approach REx, for generating scientific explanations based in
link prediction in knowledge graphs. It employs reward and policy mechanisms
that consider desirable properties of scientific explanation to guide a
reinforcement learning agent in the identification of explanatory paths within
a KG. The approach further enriches explanatory paths with domain-specific
ontologies, ensuring that the explanations are both insightful and grounded in
established biomedical knowledge. We evaluate our approach in drug repurposing
using three popular knowledge graph benchmarks. The results clearly demonstrate
its ability to generate explanations that validate predictive insights against
biomedical knowledge and that outperform the state-of-the-art approaches in
predictive performance, establishing REx as a relevant contribution to advance
AI-driven scientific discovery.

</details>


### [161] [Re-evaluating LLM-based Heuristic Search: A Case Study on the 3D Packing Problem](https://arxiv.org/abs/2509.02297)
*Guorui Quan,Mingfei Sun,Manuel López-Ibáñez*

Main category: cs.AI

TL;DR: 本文研究LLM在自动启发式设计中的能力，发现直接生成代码很脆弱，需要约束支架和迭代自修正来支持。LLM主要专注于评分函数优化，反映了其能力局限性而非原则性策略。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型在复杂启发式设计中的创新能力，特别是能否超越传统人类设计的框架进行更广泛的创新。

Method: 使用约束支架（预写的约束检查代码）和迭代自修正（额外的精炼周期来修复错误）来支持LLM构建3D装箱问题的完整求解器。

Result: 生成的启发式算法与人类设计的贪心算法相当，当评分函数集成到人类设计的元启发式中时，性能可与现有求解器相媲美，但在约束收紧时效果下降。

Conclusion: 当前LLM在自动启发式设计中的两大障碍：需要大量工程来缓解复杂推理任务中的脆弱性，以及预训练偏见会过早限制新解决方案的搜索空间。

Abstract: The art of heuristic design has traditionally been a human pursuit. While
Large Language Models (LLMs) can generate code for search heuristics, their
application has largely been confined to adjusting simple functions within
human-crafted frameworks, leaving their capacity for broader innovation an open
question. To investigate this, we tasked an LLM with building a complete solver
for the constrained 3D Packing Problem. Direct code generation quickly proved
fragile, prompting us to introduce two supports: constraint
scaffolding--prewritten constraint-checking code--and iterative
self-correction--additional refinement cycles to repair bugs and produce a
viable initial population. Notably, even within a vast search space in a greedy
process, the LLM concentrated its efforts almost exclusively on refining the
scoring function. This suggests that the emphasis on scoring functions in prior
work may reflect not a principled strategy, but rather a natural limitation of
LLM capabilities. The resulting heuristic was comparable to a human-designed
greedy algorithm, and when its scoring function was integrated into a
human-crafted metaheuristic, its performance rivaled established solvers,
though its effectiveness waned as constraints tightened. Our findings highlight
two major barriers to automated heuristic design with current LLMs: the
engineering required to mitigate their fragility in complex reasoning tasks,
and the influence of pretrained biases, which can prematurely narrow the search
for novel solutions.

</details>


### [162] [Exploring Diffusion Models for Generative Forecasting of Financial Charts](https://arxiv.org/abs/2509.02308)
*Taegyeong Lee,Jiwon Park,Kyunga Bang,Seunghyun Hwang,Ung-Jin Jang*

Main category: cs.AI

TL;DR: 本文提出了一种新颖方法，将时间序列数据视为单一图像模式，利用文本到图像生成模型来预测股票价格趋势，通过扩散模型从当前图表图像和指令提示生成下一张图表图像。


<details>
  <summary>Details</summary>
Motivation: 尽管生成模型在图像和视频生成领域取得了显著进展，但在金融领域仍然主要依赖时间序列数据和Transformer模型，缺乏生成模型的多样化应用。本文旨在探索文本到图像生成模型在金融领域的潜力。

Method: 将时间序列数据作为图像模式处理，使用扩散模型从当前股票图表图像和文本指令提示生成下一张图表图像，并引入了评估生成图像与真实图像对比的简单方法。

Result: 研究表明文本到图像生成模型在金融领域具有应用潜力，能够成功生成股票价格趋势图表。

Conclusion: 该方法展示了生成模型在金融预测中的可行性，为未来研究提供了方向，需要进一步解决当前局限性并扩展其适用性。

Abstract: Recent advances in generative models have enabled significant progress in
tasks such as generating and editing images from text, as well as creating
videos from text prompts, and these methods are being applied across various
fields. However, in the financial domain, there may still be a reliance on
time-series data and a continued focus on transformer models, rather than on
diverse applications of generative models. In this paper, we propose a novel
approach that leverages text-to-image model by treating time-series data as a
single image pattern, thereby enabling the prediction of stock price trends.
Unlike prior methods that focus on learning and classifying chart patterns
using architectures such as ResNet or ViT, we experiment with generating the
next chart image from the current chart image and an instruction prompt using
diffusion models. Furthermore, we introduce a simple method for evaluating the
generated chart image against ground truth image. We highlight the potential of
leveraging text-to-image generative models in the financial domain, and our
findings motivate further research to address the current limitations and
expand their applicability.

</details>


### [163] [Explainability-Driven Dimensionality Reduction for Hyperspectral Imaging](https://arxiv.org/abs/2509.02340)
*Salma Haidar,José Oramas*

Main category: cs.AI

TL;DR: 本文提出了一种基于模型驱动和事后可解释性方法的高光谱图像波段选择框架，通过分析分类器中各波段对决策的贡献度，选择最具影响力的波段子集，在保持分类精度的同时显著降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像的高维特性带来了计算负担和冗余信息，需要进行维度约简。传统方法往往缺乏对模型决策过程的理解，需要一种能够保持预测性能的同时选择最具判别性波段的 principled 方法。

Method: 使用训练好的分类器，通过可解释性方法量化每个波段对决策的贡献度，进行删除-插入评估来记录置信度变化，聚合这些信号得到影响力分数，选择影响力最高的波段子集。

Result: 在两个公开基准数据集（Pavia University 和 Salinas）上的实验表明，仅使用30个选定波段训练的classifier就能达到或超过全光谱基线的性能，同时显著降低计算需求。

Conclusion: 模型对齐、解释引导的波段选择是高光谱图像维度约简的有效原则性方法，所选波段子集与物理上有意义、高度判别性的波长区域一致。

Abstract: Hyperspectral imaging (HSI) provides rich spectral information for precise
material classification and analysis; however, its high dimensionality
introduces a computational burden and redundancy, making dimensionality
reduction essential. We present an exploratory study into the application of
post-hoc explainability methods in a model--driven framework for band
selection, which reduces the spectral dimension while preserving predictive
performance. A trained classifier is probed with explanations to quantify each
band's contribution to its decisions. We then perform deletion--insertion
evaluations, recording confidence changes as ranked bands are removed or
reintroduced, and aggregate these signals into influence scores. Selecting the
highest--influence bands yields compact spectral subsets that maintain accuracy
and improve efficiency. Experiments on two public benchmarks (Pavia University
and Salinas) demonstrate that classifiers trained on as few as 30 selected
bands match or exceed full--spectrum baselines while reducing computational
requirements. The resulting subsets align with physically meaningful, highly
discriminative wavelength regions, indicating that model--aligned,
explanation-guided band selection is a principled route to effective
dimensionality reduction for HSI.

</details>


### [164] [Towards Agents That Know When They Don't Know: Uncertainty as a Control Signal for Structured Reasoning](https://arxiv.org/abs/2509.02401)
*Josefa Lia Stoisser,Marc Boubnovski Martell,Lawrence Phillips,Gianluca Mazzoni,Lea Mørch Harder,Philip Torr,Jesper Ferkinghoff-Borg,Kaspar Martens,Julien Fauqueur*

Main category: cs.AI

TL;DR: 提出了一个不确定性感知的LLM代理，通过检索不确定性和摘要不确定性来提高多表生物医学数据摘要的准确性和校准性，在多项指标上取得显著提升。


<details>
  <summary>Details</summary>
Motivation: LLM代理在处理结构化生物医学数据时经常产生流畅但过于自信的输出，需要更好的不确定性感知机制来提高可靠性。

Method: 结合检索不确定性（多表选择rollout的熵）和摘要不确定性（自一致性和困惑度），使用GRPO强化学习整合摘要不确定性，并在推理时进行过滤。

Result: 在多组学基准测试中，正确有用的声明数量几乎翻了三倍（3.0→8.4内部；3.6→9.9癌症多组学），下游生存预测显著改善（C-index 0.32→0.63）。

Conclusion: 不确定性可以作为控制信号，使代理能够弃权、传达置信度，成为复杂结构化数据环境中更可靠的工具。

Abstract: Large language model (LLM) agents are increasingly deployed in structured
biomedical data environments, yet they often produce fluent but overconfident
outputs when reasoning over complex multi-table data. We introduce an
uncertainty-aware agent for query-conditioned multi-table summarization that
leverages two complementary signals: (i) retrieval uncertainty--entropy over
multiple table-selection rollouts--and (ii) summary uncertainty--combining
self-consistency and perplexity. Summary uncertainty is incorporated into
reinforcement learning (RL) with Group Relative Policy Optimization (GRPO),
while both retrieval and summary uncertainty guide inference-time filtering and
support the construction of higher-quality synthetic datasets.
  On multi-omics benchmarks, our approach improves factuality and calibration,
nearly tripling correct and useful claims per summary (3.0\(\rightarrow\)8.4
internal; 3.6\(\rightarrow\)9.9 cancer multi-omics) and substantially improving
downstream survival prediction (C-index 0.32\(\rightarrow\)0.63). These results
demonstrate that uncertainty can serve as a control signal--enabling agents to
abstain, communicate confidence, and become more reliable tools for complex
structured-data environments.

</details>


### [165] [AppCopilot: Toward General, Accurate, Long-Horizon, and Efficient Mobile Agent](https://arxiv.org/abs/2509.02444)
*Jingru Fan,Yufan Dang,Jingyao Wu,Huatao Li,Runde Yang,Xiyuan Yang,Yuheng Wang,Zhong Zhang,Yaxi Lu,Yankai Lin,Zhiyuan Liu,Dahai Li,Chen Qian*

Main category: cs.AI

TL;DR: 本文提出了AppCopilot，一个多模态、多代理的通用设备端助手，解决了移动代理在泛化性、准确性、长时程能力和效率四个核心问题。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型和多模态基础模型的快速发展，移动代理领域涌现出众多方案，但尚未解决根本性挑战。本文旨在解决移动代理在跨任务、跨应用、跨设备泛化，精确屏幕交互，长时程任务执行，以及资源受限设备高效运行等四个核心问题。

Method: AppCopilot采用端到端自主流水线，整合多模态基础模型（支持中英文），结合思维链推理、分层任务规划与分解、多代理协作。系统包含模型层、推理控制层和执行层，支持用户个性化、语音交互、函数调用、跨应用跨设备编排，并通过性能分析驱动优化延迟、内存和能耗。

Result: 实证研究表明，AppCopilot在四个维度均取得显著改进：更强的泛化能力、更高精度的屏幕操作、更可靠的长时程任务完成度，以及更快、更资源高效的运行时性能。

Conclusion: AppCopilot作为一个完整的闭环系统，从数据到部署实现了移动代理的实用化和规模化应用，为解决移动代理核心挑战提供了有效的解决方案。

Abstract: With the raid evolution of large language models and multimodal foundation
models, the mobile-agent landscape has proliferated without converging on the
fundamental challenges. This paper identifies four core problems that must be
solved for mobile agents to deliver practical, scalable impact: (1)
generalization across tasks, modalities, apps, and devices; (2) accuracy,
specifically precise on-screen interaction and click targeting; (3)
long-horizon capability for sustained, multi-step goals; and (4) efficiency,
specifically high-performance runtime on resource-constrained devices. We
present AppCopilot, a multimodal, multi-agent, general-purpose on-device
assistant that operates across applications and constitutes a full-stack,
closed-loop system from data to deployment. AppCopilot operationalizes this
position through an end-to-end autonomous pipeline spanning data collection,
training, deployment, high-quality and efficient inference, and mobile
application development. At the model layer, it integrates multimodal
foundation models with robust Chinese-English support. At the reasoning and
control layer, it combines chain-of-thought reasoning, hierarchical task
planning and decomposition, and multi-agent collaboration. At the execution
layer, it enables user personalization and experiential adaptation, voice
interaction, function calling, cross-app and cross-device orchestration, and
comprehensive mobile app support. The system design incorporates
profiling-driven optimization for latency, memory, and energy across
heterogeneous hardware. Empirically, AppCopilot achieves significant
improvements along all four dimensions: stronger generalization,
higher-precision on-screen actions, more reliable long-horizon task completion,
and faster, more resource-efficient runtime.

</details>


### [166] [GridMind: LLMs-Powered Agents for Power System Analysis and Operations](https://arxiv.org/abs/2509.02494)
*Hongwei Jin,Kibaek Kim,Jonghwan Kwon*

Main category: cs.AI

TL;DR: GridMind是一个多智能体AI系统，将大语言模型与传统电力工程求解器结合，通过自然语言界面实现电力系统分析的对话式科学计算。


<details>
  <summary>Details</summary>
Motivation: 传统电力系统分析流程复杂，阻碍现代电网高效决策，需要更易访问和集成的分析工具。

Method: 采用多智能体框架，协调交流最优潮流和N-1事故分析，通过函数调用保持数值精度，实现自然语言交互。

Result: 在IEEE测试案例中，该系统在所有测试语言模型上都能提供正确解，较小LLM在减少计算延迟的同时达到相当的分析精度。

Conclusion: 智能体AI是科学计算的可信范式，对话界面在保持工程应用所需数值严谨性的同时提高了可访问性。

Abstract: The complexity of traditional power system analysis workflows presents
significant barriers to efficient decision-making in modern electric grids.
This paper presents GridMind, a multi-agent AI system that integrates Large
Language Models (LLMs) with deterministic engineering solvers to enable
conversational scientific computing for power system analysis. The system
employs specialized agents coordinating AC Optimal Power Flow and N-1
contingency analysis through natural language interfaces while maintaining
numerical precision via function calls. GridMind addresses workflow
integration, knowledge accessibility, context preservation, and expert
decision-support augmentation. Experimental evaluation on IEEE test cases
demonstrates that the proposed agentic framework consistently delivers correct
solutions across all tested language models, with smaller LLMs achieving
comparable analytical accuracy with reduced computational latency. This work
establishes agentic AI as a viable paradigm for scientific computing,
demonstrating how conversational interfaces can enhance accessibility while
preserving numerical rigor essential for critical engineering applications.

</details>


### [167] [UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning](https://arxiv.org/abs/2509.02544)
*Haoming Wang,Haoyang Zou,Huatong Song,Jiazhan Feng,Junjie Fang,Junting Lu,Longxiang Liu,Qinyu Luo,Shihao Liang,Shijue Huang,Wanjun Zhong,Yining Ye,Yujia Qin,Yuwen Xiong,Yuxin Song,Zhiyong Wu,Bo Li,Chen Dun,Chong Liu,Fuxing Leng,Hanbin Wang,Hao Yu,Haobin Chen,Hongyi Guo,Jing Su,Jingjia Huang,Kai Shen,Kaiyu Shi,Lin Yan,Peiyao Zhao,Pengfei Liu,Qinghao Ye,Renjie Zheng,Wayne Xin Zhao,Wen Heng,Wenhao Huang,Wenqian Wang,Xiaobo Qin,Yi Lin,Youbin Wu,Zehui Chen,Zihao Wang,Baoquan Zhong,Xinchun Zhang,Xujing Li,Yuanfan Li,Zhongkai Zhao,Chengquan Jiang,Faming Wu,Haotian Zhou,Jinlin Pang,Li Han,Qianli Ma,Siyao Liu,Songhua Cai,Wenqi Fu,Xin Liu,Zhi Zhang,Bo Zhou,Guoliang Li,Jiajun Shi,Jiale Yang,Jie Tang,Li Li,Taoran Lu,Woyu Lin,Xiaokang Tong,Xinyao Li,Yichi Zhang,Yu Miao,Zhengxuan Jiang,Zili Li,Ziyuan Zhao,Chenxin Li,Dehua Ma,Feng Lin,Ge Zhang,Haihua Yang,Hangyu Guo,Hongda Zhu,Jiaheng Liu,Junda Du,Kai Cai,Kuanye Li,Lichen Yuan,Meilan Han,Minchao Wang,Shuyue Guo,Tianhao Cheng,Xiaobo Ma,Xiaojun Xiao,Xiaolong Huang,Xinjie Chen,Yidi Du,Yilin Chen,Yiwen Wang,Zhaojian Li,Zhenzhu Yang,Zhiyuan Zeng,Chaolin Jin,Chen Li,Hao Chen,Haoli Chen,Jian Chen,Qinghao Zhao,Guang Shi*

Main category: cs.AI

TL;DR: UI-TARS-2是一个原生GUI中心代理模型，通过数据飞轮、多轮强化学习框架、混合GUI环境和统一沙箱平台，在GUI基准测试和游戏环境中表现优异，达到接近人类60%的性能水平。


<details>
  <summary>Details</summary>
Motivation: 解决GUI自主代理开发中的数据可扩展性、多轮强化学习、GUI-only操作限制和环境稳定性等开放性问题。

Method: 采用系统化训练方法：数据飞轮用于可扩展数据生成、稳定的多轮RL框架、集成文件系统和终端的混合GUI环境、以及用于大规模部署的统一沙箱平台。

Result: 在GUI基准测试中表现优异（Online-Mind2Web:88.2, OSWorld:47.5, WindowsAgentArena:50.6, AndroidWorld:73.3），在15个游戏套件中平均标准化得分59.8（约人类水平的60%），并能泛化到长时程信息搜索任务和软件工程基准测试。

Conclusion: UI-TARS-2具有推进GUI代理技术发展的潜力，并在现实世界交互场景中展现出强大的泛化能力，大规模代理RL训练动态分析为实现稳定性和效率提供了见解。

Abstract: The development of autonomous agents for graphical user interfaces (GUIs)
presents major challenges in artificial intelligence. While recent advances in
native agent models have shown promise by unifying perception, reasoning,
action, and memory through end-to-end learning, open problems remain in data
scalability, multi-turn reinforcement learning (RL), the limitations of
GUI-only operation, and environment stability. In this technical report, we
present UI-TARS-2, a native GUI-centered agent model that addresses these
challenges through a systematic training methodology: a data flywheel for
scalable data generation, a stabilized multi-turn RL framework, a hybrid GUI
environment that integrates file systems and terminals, and a unified sandbox
platform for large-scale rollouts. Empirical evaluation demonstrates that
UI-TARS-2 achieves significant improvements over its predecessor UI-TARS-1.5.
On GUI benchmarks, it reaches 88.2 on Online-Mind2Web, 47.5 on OSWorld, 50.6 on
WindowsAgentArena, and 73.3 on AndroidWorld, outperforming strong baselines
such as Claude and OpenAI agents. In game environments, it attains a mean
normalized score of 59.8 across a 15-game suite-roughly 60% of human-level
performance-and remains competitive with frontier proprietary models (e.g.,
OpenAI o3) on LMGame-Bench. Additionally, the model can generalize to
long-horizon information-seeking tasks and software engineering benchmarks,
highlighting its robustness across diverse agent tasks. Detailed analyses of
training dynamics further provide insights into achieving stability and
efficiency in large-scale agent RL. These results underscore UI-TARS-2's
potential to advance the state of GUI agents and exhibit strong generalization
to real-world interactive scenarios.

</details>


### [168] [The Landscape of Agentic Reinforcement Learning for LLMs: A Survey](https://arxiv.org/abs/2509.02547)
*Guibin Zhang,Hejia Geng,Xiaohang Yu,Zhenfei Yin,Zaibin Zhang,Zelin Tan,Heng Zhou,Zhongzhi Li,Xiangyuan Xue,Yijiang Li,Yifan Zhou,Yang Chen,Chen Zhang,Yutao Fan,Zihu Wang,Songtao Huang,Yue Liao,Hongru Wang,Mengyue Yang,Heng Ji,Michael Littman,Jun Wang,Shuicheng Yan,Philip Torr,Lei Bai*

Main category: cs.AI

TL;DR: 本调查论文系统分析了智能体强化学习(Agentic RL)这一新兴范式，将其与传统LLM强化学习对比，提出了基于核心能力和应用领域的双重分类法，并整合了开源环境、基准和框架资源。


<details>
  <summary>Details</summary>
Motivation: 传统LLM强化学习将语言模型视为被动序列生成器，而智能体强化学习将其重新定义为在复杂动态世界中自主决策的智能体，需要系统性地形式化这一范式转变。

Method: 通过对比单步MDP和时序扩展POMDP的形式化框架，建立双重分类法：围绕规划、工具使用、记忆、推理、自我改进和感知等核心能力，以及跨不同任务领域的应用分类。

Result: 系统综合了500多篇近期研究工作，将强化学习定位为将静态启发式模块转化为自适应鲁棒智能体行为的关键机制，并整合了开源资源以加速未来研究。

Conclusion: 该调查描绘了这一快速发展领域的轮廓，强调了塑造可扩展通用AI智能体发展的机遇和挑战，为智能体强化学习提供了系统性的理论基础和实践指南。

Abstract: The emergence of agentic reinforcement learning (Agentic RL) marks a paradigm
shift from conventional reinforcement learning applied to large language models
(LLM RL), reframing LLMs from passive sequence generators into autonomous,
decision-making agents embedded in complex, dynamic worlds. This survey
formalizes this conceptual shift by contrasting the degenerate single-step
Markov Decision Processes (MDPs) of LLM-RL with the temporally extended,
partially observable Markov decision processes (POMDPs) that define Agentic RL.
Building on this foundation, we propose a comprehensive twofold taxonomy: one
organized around core agentic capabilities, including planning, tool use,
memory, reasoning, self-improvement, and perception, and the other around their
applications across diverse task domains. Central to our thesis is that
reinforcement learning serves as the critical mechanism for transforming these
capabilities from static, heuristic modules into adaptive, robust agentic
behavior. To support and accelerate future research, we consolidate the
landscape of open-source environments, benchmarks, and frameworks into a
practical compendium. By synthesizing over five hundred recent works, this
survey charts the contours of this rapidly evolving field and highlights the
opportunities and challenges that will shape the development of scalable,
general-purpose AI agents.

</details>
