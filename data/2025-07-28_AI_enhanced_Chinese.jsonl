{"id": "2507.18726", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.18726", "abs": "https://arxiv.org/abs/2507.18726", "authors": ["Sadia Afrin Mim"], "title": "Exploring the Landscape of Fairness Interventions in Software Engineering", "comment": null, "summary": "Current developments in AI made it broadly significant for reducing human\nlabor and expenses across several essential domains, including healthcare and\nfinance. However, the application of AI in the actual world poses multiple\nrisks and disadvantages due to potential risk factors in data (e.g., biased\ndataset). Practitioners developed a number of fairness interventions for\naddressing these kinds of problems. The paper acts as a survey, summarizing the\nvarious studies and approaches that have been developed to address fairness\nissues", "AI": {"tldr": "\u8bba\u6587\u603b\u7ed3\u4e86AI\u516c\u5e73\u6027\u95ee\u9898\u53ca\u5176\u89e3\u51b3\u65b9\u6cd5\u3002", "motivation": "AI\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5b58\u5728\u6570\u636e\u504f\u89c1\u7b49\u98ce\u9669\uff0c\u9700\u89e3\u51b3\u516c\u5e73\u6027\u95ee\u9898\u3002", "method": "\u7efc\u8ff0\u4e86\u591a\u79cd\u516c\u5e73\u6027\u5e72\u9884\u63aa\u65bd\u548c\u7814\u7a76\u3002", "result": "\u603b\u7ed3\u4e86\u73b0\u6709\u89e3\u51b3\u516c\u5e73\u6027\u95ee\u9898\u7684\u65b9\u6cd5\u3002", "conclusion": "\u516c\u5e73\u6027\u5e72\u9884\u5bf9AI\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2507.18755", "categories": ["cs.SE", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2507.18755", "abs": "https://arxiv.org/abs/2507.18755", "authors": ["Chandra Maddila", "Adam Tait", "Claire Chang", "Daniel Cheng", "Nauman Ahmad", "Vijayaraghavan Murali", "Marshall Roch", "Arnaud Avondet", "Aaron Meltzer", "Victor Montalvao", "Michael Hopko", "Chris Waterson", "Parth Thakkar", "Renuka Fernandez", "Kristian Kristensen", "Sivan Barzily", "Sherry Chen", "Rui Abreu", "Nachiappan Nagappan", "Payam Shodjai", "Killian Murphy", "James Everingham", "Aparna Ramani", "Peter C. Rigby"], "title": "Agentic Program Repair from Test Failures at Scale: A Neuro-symbolic approach with static analysis and test execution feedback", "comment": null, "summary": "Aim: With the advent of LLMs, sophisticated agentic program repair has become\nviable at large organizations with large codebases. In this work, we develop an\nEngineering Agent that fixes the source code based on test failures at scale\nacross diverse software offerings internally.\n  Method: Using Llama as the base, we employ the ReAct harness to develop an\nagent. We start with a test failure that was triaged by a rule-based test\nfailure bot. We then set up an agentic harness and allow the agent to reason\nand run a set of 15 actions from reading a file to generating a patch. We\nprovide feedback to the agent through static analysis and test failures so it\ncan refine its solution. We leverage an LLM-as-a-Judge to ensure that the patch\nconforms to the standards followed by a human review to land fixes.\n  Benchmark Findings: We curated offline benchmarks for our patch generator,\nthe Engineering Agent loop, and the LLM-as-a-Judge. In offline evaluations we\nfound that a specialized 70B model is highly competitive with the much larger\nbut vanilla Llama-405B. In an ablation study, we found that the ReAct harness\n(neural model) benefited from the symbolic information from static analysis\ntools and test execution traces. A model that strikes a balance between the\nsolve rate and error rate vs the cost and latency has a benchmark solve rate of\n42.3% using an average 11.8 feedback iterations.\n  Production Findings: In a three month period, 80% of the generated fixes were\nreviewed, of which 31.5% were landed (25.5% of the total number of generated\nfixes).\n  Feedback from Engineers: We used open coding to extract qualitative themes\nfrom engineers' feedback. We saw positive feedback in the form of quick\napprovals, gratitude, and surprise. We also found mixed feedback when the\nEngineering Agent's solution was partially correct and it served as a good\nstarting point.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u5de5\u7a0b\u4ee3\u7406\uff0c\u7528\u4e8e\u5927\u89c4\u6a21\u4fee\u590d\u4ee3\u7801\u4e2d\u7684\u6d4b\u8bd5\u5931\u8d25\u95ee\u9898\uff0c\u7ed3\u5408ReAct\u6846\u67b6\u548c\u9759\u6001\u5206\u6790\u5de5\u5177\uff0c\u53d6\u5f97\u4e8642.3%\u7684\u89e3\u51b3\u7387\u3002", "motivation": "\u968f\u7740LLMs\u7684\u53d1\u5c55\uff0c\u5927\u578b\u7ec4\u7ec7\u53ef\u4ee5\u5229\u7528\u5176\u8fdb\u884c\u590d\u6742\u7684\u7a0b\u5e8f\u4fee\u590d\u5de5\u4f5c\uff0c\u5c24\u5176\u662f\u5728\u5927\u89c4\u6a21\u4ee3\u7801\u5e93\u4e2d\u3002", "method": "\u4ee5Llama\u4e3a\u57fa\u7840\uff0c\u4f7f\u7528ReAct\u6846\u67b6\u5f00\u53d1\u4ee3\u7406\uff0c\u901a\u8fc7\u9759\u6001\u5206\u6790\u548c\u6d4b\u8bd5\u5931\u8d25\u53cd\u9988\u4f18\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5229\u7528LLM-as-a-Judge\u786e\u4fdd\u8865\u4e01\u8d28\u91cf\u3002", "result": "\u79bb\u7ebf\u8bc4\u4f30\u4e2d\uff0c70B\u6a21\u578b\u8868\u73b0\u63a5\u8fd1405B\u6a21\u578b\uff0c\u751f\u4ea7\u73af\u5883\u4e2d31.5%\u7684\u4fee\u590d\u88ab\u91c7\u7eb3\u3002", "conclusion": "\u5de5\u7a0b\u4ee3\u7406\u5728\u4ee3\u7801\u4fee\u590d\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u4ee5\u63d0\u9ad8\u89e3\u51b3\u7387\u548c\u91c7\u7eb3\u7387\u3002"}}
{"id": "2507.18812", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18812", "abs": "https://arxiv.org/abs/2507.18812", "authors": ["Yiping Jia", "Zhen Ming Jiang", "Shayan Noei", "Ying Zou"], "title": "MemoCoder: Automated Function Synthesis using LLM-Supported Agents", "comment": null, "summary": "With the widespread adoption of Large Language Models (LLMs) such as GitHub\nCopilot and ChatGPT, developers increasingly rely on AI-assisted tools to\nsupport code generation. While LLMs can generate syntactically correct\nsolutions for well-structured programming tasks, they often struggle with\nchallenges that require iterative debugging, error handling, or adaptation to\ndiverse problem structures. Existing approaches such as fine-tuning or\nself-repair strategies either require costly retraining or lack mechanisms to\naccumulate and reuse knowledge from previous attempts.\n  To address these limitations, we propose MemoCoder, a multi-agent framework\nthat enables collaborative problem solving and persistent learning from past\nfixes. At the core of MemoCoder is a Fixing Knowledge Set, which stores\nsuccessful repairs and supports retrieval for future tasks. A central Mentor\nAgent supervises the repair process by identifying recurring error patterns and\nrefining high-level fixing strategies, providing a novel supervisory role that\nguides the self-repair loop. We evaluate MemoCoder across three public\nbenchmarks -- MBPP, HumanEval, and LiveCodeBench -- spanning a range of problem\ncomplexities. Experimental results show that MemoCoder consistently outperforms\nboth zero-shot prompting and a Self-Repair strategy, with improvements ranging\nfrom 3.1% to 12.1% in Pass@10 and from 1.4% to 14.5% in Pass@50, demonstrating\nits effectiveness in iterative refinement and knowledge-guided code generation.", "AI": {"tldr": "MemoCoder\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u534f\u4f5c\u89e3\u51b3\u95ee\u9898\u548c\u4ece\u8fc7\u53bb\u7684\u4fee\u590d\u4e2d\u5b66\u4e60\uff0c\u63d0\u5347\u4ee3\u7801\u751f\u6210\u80fd\u529b\u3002", "motivation": "\u73b0\u6709LLM\u5728\u8fed\u4ee3\u8c03\u8bd5\u548c\u9519\u8bef\u5904\u7406\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u7f3a\u4e4f\u77e5\u8bc6\u79ef\u7d2f\u673a\u5236\u3002", "method": "\u63d0\u51faMemoCoder\u6846\u67b6\uff0c\u5305\u542b\u4fee\u590d\u77e5\u8bc6\u96c6\u548c\u5bfc\u5e08\u667a\u80fd\u4f53\uff0c\u652f\u6301\u77e5\u8bc6\u590d\u7528\u548c\u9519\u8bef\u6a21\u5f0f\u8bc6\u522b\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMemoCoder\u8868\u73b0\u4f18\u4e8e\u96f6\u6837\u672c\u63d0\u793a\u548c\u81ea\u4fee\u590d\u7b56\u7565\u3002", "conclusion": "MemoCoder\u5728\u8fed\u4ee3\u4f18\u5316\u548c\u77e5\u8bc6\u5f15\u5bfc\u7684\u4ee3\u7801\u751f\u6210\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2507.18833", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.18833", "abs": "https://arxiv.org/abs/2507.18833", "authors": ["Wenyuan Jiang", "Diany Pressato", "Harsh Darji", "Thibaud Lutellier"], "title": "Exploring the Jupyter Ecosystem: An Empirical Study of Bugs and Vulnerabilities", "comment": null, "summary": "Background. Jupyter notebooks are one of the main tools used by data\nscientists. Notebooks include features (configuration scripts, markdown,\nimages, etc.) that make them challenging to analyze compared to traditional\nsoftware. As a result, existing software engineering models, tools, and studies\ndo not capture the uniqueness of Notebook's behavior. Aims. This paper aims to\nprovide a large-scale empirical study of bugs and vulnerabilities in the\nNotebook ecosystem. Method. We collected and analyzed a large dataset of\nNotebooks from two major platforms. Our methodology involved quantitative\nanalyses of notebook characteristics (such as complexity metrics, contributor\nactivity, and documentation) to identify factors correlated with bugs.\nAdditionally, we conducted a qualitative study using grounded theory to\ncategorize notebook bugs, resulting in a comprehensive bug taxonomy. Finally,\nwe analyzed security-related commits and vulnerability reports to assess risks\nassociated with Notebook deployment frameworks. Results. Our findings highlight\nthat configuration issues are among the most common bugs in notebook documents,\nfollowed by incorrect API usage. Finally, we explore common vulnerabilities\nassociated with popular deployment frameworks to better understand risks\nassociated with Notebook development. Conclusions. This work highlights that\nnotebooks are less well-supported than traditional software, resulting in more\ncomplex code, misconfiguration, and poor maintenance.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\u5206\u6790\u4e86Jupyter Notebook\u4e2d\u7684\u9519\u8bef\u548c\u6f0f\u6d1e\uff0c\u53d1\u73b0\u914d\u7f6e\u95ee\u9898\u548cAPI\u4f7f\u7528\u9519\u8bef\u662f\u5e38\u89c1\u95ee\u9898\uff0c\u5e76\u63a2\u8ba8\u4e86\u76f8\u5173\u5b89\u5168\u98ce\u9669\u3002", "motivation": "Jupyter Notebook\u4f5c\u4e3a\u6570\u636e\u79d1\u5b66\u5bb6\u7684\u4e3b\u8981\u5de5\u5177\uff0c\u5176\u72ec\u7279\u6027\u4f7f\u5f97\u4f20\u7edf\u8f6f\u4ef6\u5de5\u7a0b\u6a21\u578b\u96be\u4ee5\u9002\u7528\uff0c\u56e0\u6b64\u9700\u8981\u4e13\u95e8\u7814\u7a76\u5176\u9519\u8bef\u548c\u6f0f\u6d1e\u3002", "method": "\u6536\u96c6\u5e76\u5206\u6790\u4e24\u5927\u5e73\u53f0\u7684Notebook\u6570\u636e\u96c6\uff0c\u8fdb\u884c\u5b9a\u91cf\u5206\u6790\uff08\u5982\u590d\u6742\u5ea6\u6307\u6807\u3001\u8d21\u732e\u8005\u6d3b\u52a8\u7b49\uff09\u548c\u5b9a\u6027\u7814\u7a76\uff08\u57fa\u4e8e\u624e\u6839\u7406\u8bba\u7684\u9519\u8bef\u5206\u7c7b\uff09\uff0c\u540c\u65f6\u8bc4\u4f30\u90e8\u7f72\u6846\u67b6\u7684\u5b89\u5168\u98ce\u9669\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u914d\u7f6e\u95ee\u9898\u548cAPI\u4f7f\u7528\u9519\u8bef\u662f\u6700\u5e38\u89c1\u7684\u9519\u8bef\uff0c\u5e76\u63ed\u793a\u4e86Notebook\u90e8\u7f72\u6846\u67b6\u7684\u76f8\u5173\u5b89\u5168\u98ce\u9669\u3002", "conclusion": "Notebook\u7684\u652f\u6301\u4e0d\u5982\u4f20\u7edf\u8f6f\u4ef6\uff0c\u5bfc\u81f4\u4ee3\u7801\u590d\u6742\u3001\u914d\u7f6e\u9519\u8bef\u548c\u7ef4\u62a4\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u591a\u5173\u6ce8\u548c\u6539\u8fdb\u3002"}}
{"id": "2507.18774", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.18774", "abs": "https://arxiv.org/abs/2507.18774", "authors": ["S M Mostaq Hossain", "Amani Altarawneh", "Maanak Gupta"], "title": "Bridging Cloud Convenience and Protocol Transparency: A Hybrid Architecture for Ethereum Node Operations on Amazon Managed Blockchain", "comment": "11 pages, 5 figures, 6 tables. Conference name is 2025 IEEE\n  International Conference on Service-Oriented System Engineering (SOSE)", "summary": "As blockchain technologies are increasingly adopted in enterprise and\nresearch domains, the need for secure, scalable, and performance-transparent\nnode infrastructure has become critical. While self-hosted Ethereum nodes offer\noperational control, they often lack elasticity and require complex\nmaintenance. This paper presents a hybrid, service-oriented architecture for\ndeploying and monitoring Ethereum full nodes using Amazon Managed Blockchain\n(AMB), integrated with EC2-based observability, IAM-enforced security policies,\nand reproducible automation via the AWS Cloud Development Kit. Our architecture\nsupports end-to-end observability through custom EC2 scripts leveraging Web3.py\nand JSON-RPC, collecting over 1,000 real-time data points-including gas\nutilization, transaction inclusion latency, and mempool dynamics. These metrics\nare visualized and monitored through AWS CloudWatch, enabling service-level\nperformance tracking and anomaly detection. This cloud-native framework\nrestores low-level observability lost in managed environments while maintaining\nthe operational simplicity of managed services. By bridging the simplicity of\nAMB with the transparency required for protocol research and enterprise\nmonitoring, this work delivers one of the first reproducible,\nperformance-instrumented Ethereum deployments on AMB. The proposed hybrid\narchitecture enables secure, observable, and reproducible Ethereum node\noperations in cloud environments, suitable for both research and production\nuse.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u670d\u52a1\u5bfc\u5411\u67b6\u6784\uff0c\u7528\u4e8e\u5728\u4e9a\u9a6c\u900a\u6258\u7ba1\u533a\u5757\u94fe\uff08AMB\uff09\u4e0a\u90e8\u7f72\u548c\u76d1\u63a7\u4ee5\u592a\u574a\u5168\u8282\u70b9\uff0c\u7ed3\u5408\u4e86EC2\u7684\u53ef\u89c2\u6d4b\u6027\u3001IAM\u5b89\u5168\u7b56\u7565\u548cAWS CDK\u81ea\u52a8\u5316\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u548c\u900f\u660e\u6027\u3002", "motivation": "\u968f\u7740\u533a\u5757\u94fe\u6280\u672f\u5728\u4f01\u4e1a\u548c\u7814\u7a76\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5bf9\u5b89\u5168\u3001\u53ef\u6269\u5c55\u4e14\u6027\u80fd\u900f\u660e\u7684\u8282\u70b9\u57fa\u7840\u8bbe\u65bd\u7684\u9700\u6c42\u65e5\u76ca\u8feb\u5207\u3002\u81ea\u6258\u7ba1\u4ee5\u592a\u574a\u8282\u70b9\u867d\u63d0\u4f9b\u64cd\u4f5c\u63a7\u5236\uff0c\u4f46\u7f3a\u4e4f\u5f39\u6027\u4e14\u7ef4\u62a4\u590d\u6742\u3002", "method": "\u91c7\u7528\u6df7\u5408\u67b6\u6784\uff0c\u7ed3\u5408AMB\u4e0eEC2\u7684\u53ef\u89c2\u6d4b\u6027\u5de5\u5177\u3001IAM\u5b89\u5168\u7b56\u7565\u548cAWS CDK\u81ea\u52a8\u5316\uff0c\u901a\u8fc7Web3.py\u548cJSON-RPC\u6536\u96c6\u5b9e\u65f6\u6570\u636e\uff0c\u5e76\u901a\u8fc7CloudWatch\u8fdb\u884c\u76d1\u63a7\u3002", "result": "\u67b6\u6784\u652f\u6301\u8d85\u8fc71000\u4e2a\u5b9e\u65f6\u6570\u636e\u70b9\u7684\u6536\u96c6\uff08\u5982gas\u5229\u7528\u7387\u3001\u4ea4\u6613\u5ef6\u8fdf\u7b49\uff09\uff0c\u5b9e\u73b0\u4e86\u6027\u80fd\u8ddf\u8e2a\u548c\u5f02\u5e38\u68c0\u6d4b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6258\u7ba1\u670d\u52a1\u7684\u64cd\u4f5c\u7b80\u4fbf\u6027\u3002", "conclusion": "\u8be5\u67b6\u6784\u5728AMB\u4e0a\u5b9e\u73b0\u4e86\u9996\u4e2a\u53ef\u91cd\u590d\u3001\u6027\u80fd\u76d1\u6d4b\u7684\u4ee5\u592a\u574a\u90e8\u7f72\uff0c\u9002\u7528\u4e8e\u7814\u7a76\u548c\u751f\u4ea7\u73af\u5883\uff0c\u517c\u5177\u5b89\u5168\u6027\u548c\u900f\u660e\u6027\u3002"}}
{"id": "2507.18775", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.18775", "abs": "https://arxiv.org/abs/2507.18775", "authors": ["Ilche Georgievski", "Marco Aiello"], "title": "Initial Steps in Integrating Large Reasoning and Action Models for Service Composition", "comment": "16 pages, 3 figures, 19th Symposium and Summer School on\n  Service-Oriented Computing (SummerSOC)", "summary": "Service composition remains a central challenge in building adaptive and\nintelligent software systems, often constrained by limited reasoning\ncapabilities or brittle execution mechanisms. This paper explores the\nintegration of two emerging paradigms enabled by large language models: Large\nReasoning Models (LRMs) and Large Action Models (LAMs). We argue that LRMs\naddress the challenges of semantic reasoning and ecosystem complexity while\nLAMs excel in dynamic action execution and system interoperability. However,\neach paradigm has complementary limitations - LRMs lack grounded action\ncapabilities, and LAMs often struggle with deep reasoning. We propose an\nintegrated LRM-LAM architectural framework as a promising direction for\nadvancing automated service composition. Such a system can reason about service\nrequirements and constraints while dynamically executing workflows, thus\nbridging the gap between intention and execution. This integration has the\npotential to transform service composition into a fully automated,\nuser-friendly process driven by high-level natural language intent.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u7ed3\u5408\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRM\uff09\u548c\u5927\u578b\u52a8\u4f5c\u6a21\u578b\uff08LAM\uff09\u7684\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3\u670d\u52a1\u7ec4\u5408\u4e2d\u7684\u8bed\u4e49\u63a8\u7406\u548c\u6267\u884c\u95ee\u9898\u3002", "motivation": "\u670d\u52a1\u7ec4\u5408\u5728\u6784\u5efa\u81ea\u9002\u5e94\u667a\u80fd\u7cfb\u7edf\u4e2d\u9762\u4e34\u63a8\u7406\u80fd\u529b\u6709\u9650\u548c\u6267\u884c\u673a\u5236\u8106\u5f31\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u96c6\u6210LRM\u548cLAM\u7684\u67b6\u6784\u6846\u67b6\uff0cLRM\u8d1f\u8d23\u8bed\u4e49\u63a8\u7406\uff0cLAM\u8d1f\u8d23\u52a8\u6001\u6267\u884c\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u81ea\u52a8\u5316\u670d\u52a1\u7ec4\u5408\uff0c\u5f25\u5408\u610f\u56fe\u4e0e\u6267\u884c\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "conclusion": "LRM-LAM\u96c6\u6210\u6709\u671b\u5c06\u670d\u52a1\u7ec4\u5408\u8f6c\u53d8\u4e3a\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u610f\u56fe\u7684\u81ea\u52a8\u5316\u3001\u7528\u6237\u53cb\u597d\u8fc7\u7a0b\u3002"}}
{"id": "2507.18957", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.18957", "abs": "https://arxiv.org/abs/2507.18957", "authors": ["Jianming Chang", "Jieke Shi", "Yunbo Lyu", "Xin Zhou", "Lulu Wang", "Zhou Yang", "Bixin Li", "David Lo"], "title": "SLICEMATE: Accurate and Scalable Static Program Slicing via LLM-Powered Agents", "comment": null, "summary": "Static program slicing, which extracts the executable portions of a program\nthat affect the values at a specific location, supports many software analysis\ntasks such as debugging and security auditing. However, traditional slicing\ntools rely on computationally expensive reachability analysis over dependency\ngraphs, which struggle to scale to large programs and often fail to handle code\nwith incomplete syntax. Recently emerged learning-based methods, while more\nrobust to such cases, still fall short of achieving comparable performance to\ntraditional methods on well-formed code.\n  In this work, we propose SliceMate, a novel static program slicing solution\npowered by Large Language Model (LLM) agents. It bypasses the need for explicit\ndependency graph construction and achieving superior slicing accuracy.\nConcretely, SliceMate integrates three specialized agents: (1) a synthesis\nagent that produces candidate slices by incrementally expanding the scan scope\nacross functions and files guided by LLM-inferred dependencies; (2) a\nverification agent that performs conciseness and completeness checks of the\ncandidate slices, detecting missing or irrelevant statements; and (3) a\nrefinement agent that repairs the slices with minimal edits in accordance with\nthe verification results. These agents are orchestrated by a control module\nthat ensures timely convergence and outputs high-quality slices without manual\nintervention. For rigorous evaluation, we construct a new and high-quality\nbenchmark, SliceBench, comprising 2,200 manually annotated Java and Python\nprograms, with program lengths ranging from 5 to 8,577 lines, significantly\nlarger than those in existing slicing benchmarks. Experimental results show\nthat SliceMate greatly outperforms both traditional and learning-based slicing\ntools.", "AI": {"tldr": "SliceMate\u662f\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u7684\u65b0\u578b\u9759\u6001\u7a0b\u5e8f\u5207\u7247\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u4e09\u4e2a\u4e13\u95e8\u4ee3\u7406\uff08\u5408\u6210\u3001\u9a8c\u8bc1\u548c\u4f18\u5316\uff09\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u5207\u7247\uff0c\u65e0\u9700\u663e\u5f0f\u4f9d\u8d56\u56fe\u6784\u5efa\u3002", "motivation": "\u4f20\u7edf\u5207\u7247\u5de5\u5177\u4f9d\u8d56\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u4f9d\u8d56\u56fe\u53ef\u8fbe\u6027\u5206\u6790\uff0c\u96be\u4ee5\u6269\u5c55\u5230\u5927\u578b\u7a0b\u5e8f\u6216\u5904\u7406\u8bed\u6cd5\u4e0d\u5b8c\u6574\u4ee3\u7801\uff1b\u73b0\u6709\u5b66\u4e60\u65b9\u6cd5\u867d\u66f4\u9c81\u68d2\uff0c\u4f46\u5728\u89c4\u8303\u4ee3\u7801\u4e0a\u6027\u80fd\u4e0d\u8db3\u3002", "method": "SliceMate\u96c6\u6210\u4e09\u4e2a\u4ee3\u7406\uff1a\u5408\u6210\u4ee3\u7406\uff08\u6269\u5c55\u626b\u63cf\u8303\u56f4\u751f\u6210\u5019\u9009\u5207\u7247\uff09\u3001\u9a8c\u8bc1\u4ee3\u7406\uff08\u68c0\u67e5\u5207\u7247\u5b8c\u6574\u6027\u548c\u7b80\u6d01\u6027\uff09\u548c\u4f18\u5316\u4ee3\u7406\uff08\u4fee\u590d\u5207\u7247\uff09\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cSliceMate\u57282,200\u4e2a\u624b\u52a8\u6807\u6ce8\u7684Java\u548cPython\u7a0b\u5e8f\uff085\u81f38,577\u884c\uff09\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u548c\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "SliceMate\u901a\u8fc7LLM\u4ee3\u7406\u5b9e\u73b0\u9ad8\u6548\u3001\u9ad8\u7cbe\u5ea6\u7684\u9759\u6001\u7a0b\u5e8f\u5207\u7247\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u95ee\u9898\u3002"}}
{"id": "2507.18801", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.18801", "abs": "https://arxiv.org/abs/2507.18801", "authors": ["Haotian Zhang", "Kun Liu", "Cristian Garces", "Chenke Luo", "Yu Lei", "Jiang Ming"], "title": "Resolving Indirect Calls in Binary Code via Cross-Reference Augmented Graph Neural Networks", "comment": null, "summary": "Binary code analysis is essential in scenarios where source code is\nunavailable, with extensive applications across various security domains.\nHowever, accurately resolving indirect call targets remains a longstanding\nchallenge in maintaining the integrity of static analysis in binary code. This\ndifficulty arises because the operand of a call instruction (e.g., call rax)\nremains unknown until runtime, resulting in an incomplete inter-procedural\ncontrol flow graph (CFG). Previous approaches have struggled with low accuracy\nand limited scalability. To address these limitations, recent work has\nincreasingly turned to machine learning (ML) to enhance analysis. However, this\nML-driven approach faces two significant obstacles: low-quality callsite-callee\ntraining pairs and inadequate binary code representation, both of which\nundermine the accuracy of ML models. In this paper, we introduce NeuCall, a\nnovel approach for resolving indirect calls using graph neural networks.\nExisting ML models in this area often overlook key elements such as data and\ncode cross-references, which are essential for understanding a program's\ncontrol flow. In contrast, NeuCall augments CFGs with cross-references,\npreserving rich semantic information. Additionally, we leverage advanced\ncompiler-level type analysis to generate high-quality callsite-callee training\npairs, enhancing model precision and reliability. We further design a graph\nneural model that leverages augmented CFGs and relational graph convolutions\nfor accurate target prediction. Evaluated against real-world binaries from\nGitHub and the Arch User Repository on x86_64 architecture, NeuCall achieves an\nF1 score of 95.2%, outperforming state-of-the-art ML-based approaches. These\nresults highlight NeuCall's effectiveness in building precise inter-procedural\nCFGs and its potential to advance downstream binary analysis and security\napplications.", "AI": {"tldr": "NeuCall\u4f7f\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u89e3\u51b3\u4e8c\u8fdb\u5236\u4ee3\u7801\u4e2d\u95f4\u63a5\u8c03\u7528\u76ee\u6807\u89e3\u6790\u95ee\u9898\uff0c\u901a\u8fc7\u589e\u5f3a\u63a7\u5236\u6d41\u56fe\u548c\u9ad8\u8d28\u91cf\u8bad\u7ec3\u5bf9\u63d0\u5347\u51c6\u786e\u6027\u3002", "motivation": "\u4e8c\u8fdb\u5236\u4ee3\u7801\u5206\u6790\u4e2d\uff0c\u95f4\u63a5\u8c03\u7528\u76ee\u6807\u89e3\u6790\u662f\u957f\u671f\u6311\u6218\uff0c\u5f71\u54cd\u9759\u6001\u5206\u6790\u7684\u5b8c\u6574\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u51c6\u786e\u6027\u548c\u53ef\u6269\u5c55\u6027\u4e0d\u8db3\uff0c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u53d7\u9650\u4e8e\u4f4e\u8d28\u91cf\u8bad\u7ec3\u5bf9\u548c\u4ee3\u7801\u8868\u793a\u3002", "method": "NeuCall\u901a\u8fc7\u589e\u5f3a\u63a7\u5236\u6d41\u56fe\uff08\u5305\u542b\u6570\u636e\u548c\u4ee3\u7801\u4ea4\u53c9\u5f15\u7528\uff09\u548c\u7f16\u8bd1\u5668\u7ea7\u7c7b\u578b\u5206\u6790\u751f\u6210\u9ad8\u8d28\u91cf\u8bad\u7ec3\u5bf9\uff0c\u8bbe\u8ba1\u56fe\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u9884\u6d4b\u76ee\u6807\u3002", "result": "\u5728x86_64\u67b6\u6784\u7684\u771f\u5b9e\u4e8c\u8fdb\u5236\u4ee3\u7801\u4e0a\uff0cNeuCall\u7684F1\u5206\u6570\u8fbe95.2%\uff0c\u4f18\u4e8e\u73b0\u6709ML\u65b9\u6cd5\u3002", "conclusion": "NeuCall\u80fd\u6784\u5efa\u7cbe\u786e\u7684\u8fc7\u7a0b\u95f4\u63a7\u5236\u6d41\u56fe\uff0c\u63a8\u52a8\u4e8c\u8fdb\u5236\u5206\u6790\u548c\u5b89\u5168\u5e94\u7528\u53d1\u5c55\u3002"}}
{"id": "2507.18795", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18795", "abs": "https://arxiv.org/abs/2507.18795", "authors": ["Fatima Al-Ani", "Molly Wang", "Jevon Charles", "Aaron Ong", "Joshua Forday", "Vinayak Modi"], "title": "Simulation-Driven Reinforcement Learning in Queuing Network Routing Optimization", "comment": null, "summary": "This study focuses on the development of a simulation-driven reinforcement\nlearning (RL) framework for optimizing routing decisions in complex queueing\nnetwork systems, with a particular emphasis on manufacturing and communication\napplications. Recognizing the limitations of traditional queueing methods,\nwhich often struggle with dynamic, uncertain environments, we propose a robust\nRL approach leveraging Deep Deterministic Policy Gradient (DDPG) combined with\nDyna-style planning (Dyna-DDPG). The framework includes a flexible and\nconfigurable simulation environment capable of modeling diverse queueing\nscenarios, disruptions, and unpredictable conditions. Our enhanced Dyna-DDPG\nimplementation incorporates separate predictive models for next-state\ntransitions and rewards, significantly improving stability and sample\nefficiency. Comprehensive experiments and rigorous evaluations demonstrate the\nframework's capability to rapidly learn effective routing policies that\nmaintain robust performance under disruptions and scale effectively to larger\nnetwork sizes. Additionally, we highlight strong software engineering practices\nemployed to ensure reproducibility and maintainability of the framework,\nenabling practical deployment in real-world scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eDyna-DDPG\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316\u590d\u6742\u6392\u961f\u7f51\u7edc\u7684\u8def\u5f84\u51b3\u7b56\uff0c\u9002\u7528\u4e8e\u5236\u9020\u548c\u901a\u4fe1\u9886\u57df\u3002", "motivation": "\u4f20\u7edf\u6392\u961f\u65b9\u6cd5\u5728\u52a8\u6001\u548c\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7ed3\u5408Deep Deterministic Policy Gradient\uff08DDPG\uff09\u548cDyna-style\u89c4\u5212\uff08Dyna-DDPG\uff09\uff0c\u5e76\u5f00\u53d1\u4e86\u7075\u6d3b\u7684\u4eff\u771f\u73af\u5883\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u5feb\u901f\u5b66\u4e60\u6709\u6548\u7684\u8def\u5f84\u7b56\u7565\uff0c\u5728\u5e72\u6270\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\uff0c\u5e76\u80fd\u6269\u5c55\u5230\u66f4\u5927\u7f51\u7edc\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u6027\u80fd\u4f18\u8d8a\uff0c\u8fd8\u6ce8\u91cd\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\uff0c\u786e\u4fdd\u53ef\u91cd\u73b0\u6027\u548c\u53ef\u7ef4\u62a4\u6027\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2507.18982", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.18982", "abs": "https://arxiv.org/abs/2507.18982", "authors": ["Amir Hossain Raaj", "Fairuz Nawer Meem", "Sadia Afrin Mim"], "title": "Classifying Issues in Open-source GitHub Repositories", "comment": null, "summary": "GitHub is the most widely used platform for software maintenance in the\nopen-source community. Developers report issues on GitHub from time to time\nwhile facing difficulties. Having labels on those issues can help developers\neasily address those issues with prior knowledge of labels. However, most of\nthe GitHub repositories do not maintain regular labeling for the issues. The\ngoal of this work is to classify issues in the open-source community using ML\n\\& DNN models. There are thousands of open-source repositories on GitHub. Some\nof the repositories label their issues properly whereas some of them do not.\nWhen issues are pre-labeled, the problem-solving process and the immediate\nassignment of corresponding personnel are facilitated for the team, thereby\nexpediting the development process. In this work, we conducted an analysis of\nprominent GitHub open-source repositories. We classified the issues in some\ncommon labels which are: API, Documentation, Enhancement, Question, Easy,\nHelp-wanted, Dependency, CI, Waiting for OP's response, Test, Bug, etc. Our\nstudy shows that DNN models outperf", "AI": {"tldr": "\u8be5\u8bba\u6587\u65e8\u5728\u5229\u7528\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u5bf9GitHub\u5f00\u6e90\u793e\u533a\u4e2d\u7684\u95ee\u9898\u8fdb\u884c\u81ea\u52a8\u5206\u7c7b\uff0c\u4ee5\u89e3\u51b3\u6807\u7b7e\u7f3a\u5931\u7684\u95ee\u9898\uff0c\u4ece\u800c\u52a0\u5feb\u5f00\u53d1\u6d41\u7a0b\u3002", "motivation": "GitHub\u4e0a\u8bb8\u591a\u5f00\u6e90\u4ed3\u5e93\u7684\u95ee\u9898\u7f3a\u4e4f\u89c4\u8303\u7684\u6807\u7b7e\uff0c\u8fd9\u5f71\u54cd\u4e86\u5f00\u53d1\u6548\u7387\u3002\u901a\u8fc7\u81ea\u52a8\u5206\u7c7b\u95ee\u9898\uff0c\u53ef\u4ee5\u4f18\u5316\u95ee\u9898\u89e3\u51b3\u6d41\u7a0b\u3002", "method": "\u5206\u6790\u4e86GitHub\u4e0a\u8457\u540d\u7684\u5f00\u6e90\u4ed3\u5e93\uff0c\u5e76\u4f7f\u7528ML\u548cDNN\u6a21\u578b\u5bf9\u95ee\u9898\u8fdb\u884c\u5206\u7c7b\uff0c\u6807\u7b7e\u5305\u62ecAPI\u3001\u6587\u6863\u3001\u589e\u5f3a\u7b49\u5e38\u89c1\u7c7b\u522b\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0cDNN\u6a21\u578b\u5728\u95ee\u9898\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "conclusion": "\u81ea\u52a8\u5206\u7c7bGitHub\u95ee\u9898\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u5f00\u53d1\u6548\u7387\uff0cDNN\u6a21\u578b\u662f\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u7684\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2507.19032", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.19032", "abs": "https://arxiv.org/abs/2507.19032", "authors": ["Alper \u00c7akan", "Vipul Goyal"], "title": "How to Copy-Protect Malleable-Puncturable Cryptographic Functionalities Under Arbitrary Challenge Distributions", "comment": null, "summary": "A quantum copy-protection scheme (Aaronson, CCC 2009) encodes a functionality\ninto a quantum state such that given this state, no efficient adversary can\ncreate two (possibly entangled) quantum states that are both capable of running\nthe functionality. There has been a recent line of works on constructing\nprovably-secure copy-protection schemes for general classes of schemes in the\nplain model, and most recently the recent work of \\c{C}akan and Goyal (IACR\nEprint, 2025) showed how to copy-protect all cryptographically puncturable\nschemes with pseudorandom puncturing points. In this work, we show how to\ncopy-protect even a larger class of schemes. We define a class of cryptographic\nschemes called malleable-puncturable schemes where the only requirement is that\none can create a circuit that is capable of answering inputs at points that are\nunrelated to the challenge in the security game but does not help the adversary\nanswer inputs related to the challenge. This is a flexible generalization of\npuncturable schemes, and can capture a wide range of primitives that was not\nknown how to copy-protect prior to our work. Going further, we show that our\nscheme is secure against arbitrary high min-entropy challenge distributions\nwhereas previous work has only considered schemes that are punctured at\npseudorandom points.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u91cf\u5b50\u590d\u5236\u4fdd\u62a4\u65b9\u6848\uff0c\u6269\u5c55\u4e86\u53ef\u4fdd\u62a4\u7684\u529f\u80fd\u7c7b\u522b\uff0c\u9002\u7528\u4e8e\u53ef\u5ef6\u5c55\u53ef\u7a7f\u523a\u7684\u5bc6\u7801\u65b9\u6848\uff0c\u5e76\u63d0\u5347\u4e86\u5b89\u5168\u6027\u3002", "motivation": "\u73b0\u6709\u91cf\u5b50\u590d\u5236\u4fdd\u62a4\u65b9\u6848\u4ec5\u9002\u7528\u4e8e\u7279\u5b9a\u7c7b\u522b\u7684\u5bc6\u7801\u65b9\u6848\uff0c\u9650\u5236\u4e86\u5176\u5e94\u7528\u8303\u56f4\u3002\u672c\u6587\u65e8\u5728\u6269\u5c55\u53ef\u4fdd\u62a4\u7684\u65b9\u6848\u7c7b\u522b\uff0c\u5e76\u63d0\u5347\u5b89\u5168\u6027\u3002", "method": "\u5b9a\u4e49\u4e86\u4e00\u7c7b\u53ef\u5ef6\u5c55\u53ef\u7a7f\u523a\u7684\u5bc6\u7801\u65b9\u6848\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u7684\u91cf\u5b50\u590d\u5236\u4fdd\u62a4\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u6b64\u7c7b\u65b9\u6848\u3002", "result": "\u65b0\u65b9\u6848\u80fd\u591f\u4fdd\u62a4\u66f4\u5e7f\u6cdb\u7684\u5bc6\u7801\u65b9\u6848\uff0c\u4e14\u5b89\u5168\u6027\u66f4\u9ad8\uff0c\u9002\u7528\u4e8e\u4efb\u610f\u9ad8\u6700\u5c0f\u71b5\u7684\u6311\u6218\u5206\u5e03\u3002", "conclusion": "\u672c\u6587\u6269\u5c55\u4e86\u91cf\u5b50\u590d\u5236\u4fdd\u62a4\u7684\u5e94\u7528\u8303\u56f4\uff0c\u4e3a\u66f4\u5e7f\u6cdb\u7684\u5bc6\u7801\u65b9\u6848\u63d0\u4f9b\u4e86\u5b89\u5168\u7684\u590d\u5236\u4fdd\u62a4\u65b9\u6cd5\u3002"}}
{"id": "2507.18868", "categories": ["cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2507.18868", "abs": "https://arxiv.org/abs/2507.18868", "authors": ["Alex Noviello", "Claas Beger", "Jacob Groner", "Kevin Ellis", "Weinan Sun"], "title": "A Neuroscience-Inspired Dual-Process Model of Compositional Generalization", "comment": null, "summary": "Systematic compositional generalization - constructing and understanding\nnovel combinations of known building blocks - remains a core challenge for AI\nsystems. Human cognition achieves this flexibility via the interplay of the\nhippocampus (HPC) and prefrontal cortex (PFC): the hippocampus rapidly encodes\nepisodes, and the prefrontal cortex consolidates them into reusable schemas for\nreasoning. Drawing on these insights, we present MIRAGE (Meta-Inference with\nRules and Abstractions from Generalized Experience), a framework that achieves\nsystematic generalization on compositional tasks. MIRAGE has two interacting\nmodules mirroring the brain's deliberative HPC-PFC loop and intuitive\nneocortical pattern recognition. (1) The meta-trained Transformer Neural\nDecomposer, paralleling neocortical \"System 1\" computation, is trained on a\ntask-agnostic stream of randomly sampled compositional grammars and applies one\ndecomposition step per pass, with successive passes iteratively refining the\nsequence representation. (2) The Schema Engine, analogous to the HPC-PFC\n\"System 2\" loop, dynamically extracts, ranks, and applies reusable schemas,\nstoring variable bindings in episodic memory and expanding them when needed. By\nexplicitly equipping the Transformer component of MIRAGE with actively managed\nschematic structures, our model performs systematic compositional operations\nthrough explicit schema application and transformation, relying solely on\nfrozen weights when solving entirely novel tasks. This approach demonstrates\nsystematic compositional generalization on the SCAN benchmark, achieving > 99%\naccuracy on all task splits with only 1.19M parameters in the transformer\nmodule. Ablation studies confirm that MIRAGE's systematicity critically depends\non the quality of extracted schemas and the model's iterative refinement\nprocess.", "AI": {"tldr": "MIRAGE\u6846\u67b6\u901a\u8fc7\u6a21\u62df\u4eba\u8111HPC-PFC\u4ea4\u4e92\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u7cfb\u7edf\u6027\u7ec4\u5408\u6cdb\u5316\uff0c\u5728SCAN\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3AI\u7cfb\u7edf\u5728\u7ec4\u5408\u4efb\u52a1\u4e2d\u7cfb\u7edf\u6027\u6cdb\u5316\u7684\u6838\u5fc3\u6311\u6218\uff0c\u501f\u9274\u4eba\u8111\u6d77\u9a6c\u4f53\u4e0e\u524d\u989d\u53f6\u76ae\u5c42\u7684\u534f\u4f5c\u673a\u5236\u3002", "method": "MIRAGE\u5305\u542b\u4e24\u4e2a\u6a21\u5757\uff1a\u57fa\u4e8eTransformer\u7684\u795e\u7ecf\u5206\u89e3\u5668\u548c\u6a21\u5f0f\u5f15\u64ce\uff0c\u5206\u522b\u6a21\u62df\u76f4\u89c9\u6027\u6a21\u5f0f\u8bc6\u522b\u548c\u903b\u8f91\u63a8\u7406\u3002", "result": "\u5728SCAN\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230>99%\u51c6\u786e\u7387\uff0c\u4ec5\u97001.19M\u53c2\u6570\u3002\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6a21\u5f0f\u8d28\u91cf\u548c\u8fed\u4ee3\u4f18\u5316\u7684\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "MIRAGE\u901a\u8fc7\u663e\u5f0f\u7ba1\u7406\u6a21\u5f0f\u7ed3\u6784\u548c\u8fed\u4ee3\u4f18\u5316\uff0c\u5b9e\u73b0\u4e86\u7cfb\u7edf\u6027\u7ec4\u5408\u6cdb\u5316\uff0c\u4e3aAI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.19027", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.19027", "abs": "https://arxiv.org/abs/2507.19027", "authors": ["Aleksi Huotala", "Miikka Kuutila", "Mika M\u00e4ntyl\u00e4"], "title": "SESR-Eval: Dataset for Evaluating LLMs in the Title-Abstract Screening of Systematic Reviews", "comment": "12 pages (10 + 2 pages for references)", "summary": "Background: The use of large language models (LLMs) in the title-abstract\nscreening process of systematic reviews (SRs) has shown promising results, but\nsuffers from limited performance evaluation. Aims: Create a benchmark dataset\nto evaluate the performance of LLMs in the title-abstract screening process of\nSRs. Provide evidence whether using LLMs in title-abstract screening in\nsoftware engineering is advisable. Method: We start with 169 SR research\nartifacts and find 24 of those to be suitable for inclusion in the dataset.\nUsing the dataset we benchmark title-abstract screening using 9 LLMs. Results:\nWe present the SESR-Eval (Software Engineering Systematic Review Evaluation)\ndataset containing 34,528 labeled primary studies, sourced from 24 secondary\nstudies published in software engineering (SE) journals. Most LLMs performed\nsimilarly and the differences in screening accuracy between secondary studies\nare greater than differences between LLMs. The cost of using an LLM is\nrelatively low - less than $40 per secondary study even for the most expensive\nmodel. Conclusions: Our benchmark enables monitoring AI performance in the\nscreening task of SRs in software engineering. At present, LLMs are not yet\nrecommended for automating the title-abstract screening process, since accuracy\nvaries widely across secondary studies, and no LLM managed a high recall with\nreasonable precision. In future, we plan to investigate factors that influence\nLLM screening performance between studies.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aSESR-Eval\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8f6f\u4ef6\u5de5\u7a0b\u7cfb\u7edf\u7efc\u8ff0\u6807\u9898-\u6458\u8981\u7b5b\u9009\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0LLMs\u6027\u80fd\u5dee\u5f02\u4e0d\u5927\uff0c\u4f46\u6210\u672c\u8f83\u4f4e\uff0c\u76ee\u524d\u4e0d\u5efa\u8bae\u81ea\u52a8\u5316\u4f7f\u7528\u3002", "motivation": "\u8bc4\u4f30LLMs\u5728\u7cfb\u7edf\u7efc\u8ff0\u6807\u9898-\u6458\u8981\u7b5b\u9009\u4e2d\u7684\u6027\u80fd\uff0c\u5e76\u4e3a\u5176\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4f9d\u636e\u3002", "method": "\u4ece169\u4e2a\u7cfb\u7edf\u7efc\u8ff0\u7814\u7a76\u4e2d\u9009\u62e924\u4e2a\u6784\u5efa\u6570\u636e\u96c6\uff0c\u4f7f\u75289\u79cdLLMs\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "SESR-Eval\u6570\u636e\u96c6\u5305\u542b34,528\u4e2a\u6807\u8bb0\u7814\u7a76\uff0cLLMs\u8868\u73b0\u76f8\u4f3c\uff0c\u4f46\u51c6\u786e\u6027\u5dee\u5f02\u8f83\u5927\uff0c\u6210\u672c\u4f4e\u4e8e40\u7f8e\u5143/\u7814\u7a76\u3002", "conclusion": "LLMs\u76ee\u524d\u4e0d\u63a8\u8350\u7528\u4e8e\u81ea\u52a8\u5316\u7b5b\u9009\uff0c\u672a\u6765\u5c06\u7814\u7a76\u5f71\u54cd\u6027\u80fd\u7684\u56e0\u7d20\u3002"}}
{"id": "2507.19055", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2507.19055", "abs": "https://arxiv.org/abs/2507.19055", "authors": ["Yuksel Arslan"], "title": "Virtual local area network over HTTP for launching an insider attack", "comment": null, "summary": "Computers and computer networks have become integral to virtually every\naspect of modern life, with the Internet playing an indispensable role.\nOrganizations, businesses, and individuals now store vast amounts of\nproprietary, confidential, and personal data digitally. As such, ensuring the\nsecurity of this data from unauthorized access is critical. Common security\nmeasures, such as firewalls, intrusion detection systems (IDS), intrusion\nprevention systems (IPS), and antivirus software, are constantly evolving to\nsafeguard computer systems and networks. However, these tools primarily focus\non defending against external threats, leaving systems vulnerable to insider\nattacks. Security solutions designed to mitigate risks originating from within\nthe organization are relatively limited and often ineffective. This paper\ndemonstrates how a Local Area Network (LAN) can be covertly exposed to the\nInternet via an insider attack. Specifically, it illustrates how an external\nmachine can gain access to a LAN by exploiting an unused secondary IP address\nof the attacked LAN, effectively bypassing existing security mechanisms by also\nexploiting Hyper Text Transfer Protocol (HTTP). Despite the presence of robust\nexternal protections, such as firewalls and IDS, this form of insider attack\nreveals significant vulnerabilities in the way internal threats are addressed.", "AI": {"tldr": "\u8bba\u6587\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u5185\u90e8\u653b\u51fb\u5c06\u5c40\u57df\u7f51\uff08LAN\uff09\u9690\u853d\u5730\u66b4\u9732\u5728\u4e92\u8054\u7f51\u4e0a\uff0c\u5229\u7528\u672a\u4f7f\u7528\u7684\u6b21\u8981IP\u5730\u5740\u548cHTTP\u534f\u8bae\u7ed5\u8fc7\u73b0\u6709\u5b89\u5168\u673a\u5236\u3002", "motivation": "\u73b0\u4ee3\u751f\u6d3b\u4e2d\u8ba1\u7b97\u673a\u548c\u7f51\u7edc\u7684\u91cd\u8981\u6027\u65e5\u76ca\u589e\u52a0\uff0c\u6570\u636e\u5b89\u5168\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u5b89\u5168\u63aa\u65bd\u4e3b\u8981\u9488\u5bf9\u5916\u90e8\u5a01\u80c1\uff0c\u800c\u5185\u90e8\u653b\u51fb\u7684\u9632\u62a4\u76f8\u5bf9\u8584\u5f31\u3002", "method": "\u901a\u8fc7\u5229\u7528LAN\u4e2d\u672a\u4f7f\u7528\u7684\u6b21\u8981IP\u5730\u5740\u548cHTTP\u534f\u8bae\uff0c\u5c55\u793a\u5916\u90e8\u673a\u5668\u5982\u4f55\u7ed5\u8fc7\u9632\u706b\u5899\u548cIDS\u7b49\u5b89\u5168\u673a\u5236\u8bbf\u95eeLAN\u3002", "result": "\u63ed\u793a\u4e86\u5373\u4f7f\u6709\u5f3a\u5927\u7684\u5916\u90e8\u9632\u62a4\u63aa\u65bd\uff0c\u5185\u90e8\u653b\u51fb\u4ecd\u80fd\u6210\u529f\u66b4\u9732LAN\u7684\u6f0f\u6d1e\u3002", "conclusion": "\u5185\u90e8\u653b\u51fb\u5bf9\u6570\u636e\u5b89\u5168\u6784\u6210\u91cd\u5927\u5a01\u80c1\uff0c\u73b0\u6709\u5b89\u5168\u673a\u5236\u9700\u52a0\u5f3a\u5185\u90e8\u9632\u62a4\u3002"}}
{"id": "2507.18883", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.18883", "abs": "https://arxiv.org/abs/2507.18883", "authors": ["Wuhao Wang", "Zhiyong Chen"], "title": "Success in Humanoid Reinforcement Learning under Partial Observation", "comment": "11 pages, 3 figures, and 4 tables. Not published anywhere else", "summary": "Reinforcement learning has been widely applied to robotic control, but\neffective policy learning under partial observability remains a major\nchallenge, especially in high-dimensional tasks like humanoid locomotion. To\ndate, no prior work has demonstrated stable training of humanoid policies with\nincomplete state information in the benchmark Gymnasium Humanoid-v4\nenvironment. The objective in this environment is to walk forward as fast as\npossible without falling, with rewards provided for staying upright and moving\nforward, and penalties incurred for excessive actions and external contact\nforces. This research presents the first successful instance of learning under\npartial observability in this environment. The learned policy achieves\nperformance comparable to state-of-the-art results with full state access,\ndespite using only one-third to two-thirds of the original states. Moreover,\nthe policy exhibits adaptability to robot properties, such as variations in\nbody part masses. The key to this success is a novel history encoder that\nprocesses a fixed-length sequence of past observations in parallel. Integrated\ninto a standard model-free algorithm, the encoder enables performance on par\nwith fully observed baselines. We hypothesize that it reconstructs essential\ncontextual information from recent observations, thereby enabling robust\ndecision-making.", "AI": {"tldr": "\u9996\u6b21\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e0b\u6210\u529f\u8bad\u7ec3\u4eba\u5f62\u673a\u5668\u4eba\u7b56\u7565\uff0c\u6027\u80fd\u63a5\u8fd1\u5168\u72b6\u6001\u8bbf\u95ee\u7684\u5148\u8fdb\u7ed3\u679c\uff0c\u5173\u952e\u662f\u4e00\u79cd\u65b0\u578b\u5386\u53f2\u7f16\u7801\u5668\u3002", "motivation": "\u89e3\u51b3\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u4e0b\u4eba\u5f62\u673a\u5668\u4eba\u63a7\u5236\u7b56\u7565\u5b66\u4e60\u7684\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u7ef4\u4efb\u52a1\u4e2d\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u578b\u5386\u53f2\u7f16\u7801\u5668\uff0c\u5904\u7406\u56fa\u5b9a\u957f\u5ea6\u7684\u8fc7\u53bb\u89c2\u6d4b\u5e8f\u5217\uff0c\u96c6\u6210\u5230\u65e0\u6a21\u578b\u7b97\u6cd5\u4e2d\u3002", "result": "\u7b56\u7565\u6027\u80fd\u63a5\u8fd1\u5168\u72b6\u6001\u57fa\u7ebf\uff0c\u4ec5\u9700\u539f\u59cb\u72b6\u6001\u7684\u4e09\u5206\u4e4b\u4e00\u5230\u4e09\u5206\u4e4b\u4e8c\uff0c\u4e14\u80fd\u9002\u5e94\u673a\u5668\u4eba\u5c5e\u6027\u53d8\u5316\u3002", "conclusion": "\u5386\u53f2\u7f16\u7801\u5668\u901a\u8fc7\u91cd\u5efa\u4e0a\u4e0b\u6587\u4fe1\u606f\u5b9e\u73b0\u7a33\u5065\u51b3\u7b56\uff0c\u4e3a\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e0b\u7684\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.19113", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.19113", "abs": "https://arxiv.org/abs/2507.19113", "authors": ["Liliana Pasquale", "Azzurra Ragone", "Emanuele Piemontese", "Armin Amiri Darban"], "title": "Exploring the Use of LLMs for Requirements Specification in an IT Consulting Company", "comment": "11 pages, 5 figures. Accepted for presentation at the Industrial\n  Innovation Track of the 33rd IEEE International Requirements Engineering\n  Conference (RE 2025), Valencia, Spain", "summary": "In practice, requirements specification remains a critical challenge. The\nknowledge necessary to generate a specification can often be fragmented across\ndiverse sources (e.g., meeting minutes, emails, and high-level product\ndescriptions), making the process cumbersome and time-consuming. In this paper,\nwe report our experience using large language models (LLMs) in an IT consulting\ncompany to automate the requirements specification process. In this company,\nrequirements are specified using a Functional Design Specification (FDS), a\ndocument that outlines the functional requirements and features of a system,\napplication, or process. We provide LLMs with a summary of the requirements\nelicitation documents and FDS templates, prompting them to generate Epic FDS\n(including high-level product descriptions) and user stories, which are\nsubsequently compiled into a complete FDS document. We compared the correctness\nand quality of the FDS generated by three state-of-the-art LLMs against those\nproduced by human analysts. Our results show that LLMs can help automate and\nstandardize the requirements specification, reducing time and human effort.\nHowever, the quality of LLM-generated FDS highly depends on inputs and often\nrequires human revision. Thus, we advocate for a synergistic approach in which\nan LLM serves as an effective drafting tool while human analysts provide the\ncritical contextual and technical oversight necessary for high-quality\nrequirements engineering (RE) documentation.", "AI": {"tldr": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u81ea\u52a8\u5316\u9700\u6c42\u89c4\u8303\u751f\u6210\uff0c\u51cf\u5c11\u65f6\u95f4\u548c\u4eba\u529b\uff0c\u4f46\u9700\u4eba\u5de5\u4fee\u8ba2\u3002", "motivation": "\u9700\u6c42\u89c4\u8303\u751f\u6210\u8fc7\u7a0b\u7e41\u7410\u4e14\u8017\u65f6\uff0c\u77e5\u8bc6\u5206\u6563\u4e8e\u591a\u79cd\u6765\u6e90\u3002", "method": "\u5229\u7528LLM\u751f\u6210Epic FDS\u548c\u7528\u6237\u6545\u4e8b\uff0c\u5e76\u4e0e\u4eba\u7c7b\u5206\u6790\u5e08\u751f\u6210\u7684\u7ed3\u679c\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "LLM\u53ef\u81ea\u52a8\u5316\u9700\u6c42\u89c4\u8303\uff0c\u4f46\u8d28\u91cf\u4f9d\u8d56\u8f93\u5165\u4e14\u9700\u4eba\u5de5\u4fee\u8ba2\u3002", "conclusion": "\u5efa\u8baeLLM\u4f5c\u4e3a\u8d77\u8349\u5de5\u5177\uff0c\u4eba\u7c7b\u5206\u6790\u5e08\u63d0\u4f9b\u5173\u952e\u76d1\u7763\uff0c\u5b9e\u73b0\u9ad8\u8d28\u91cf\u9700\u6c42\u5de5\u7a0b\u6587\u6863\u3002"}}
{"id": "2507.19060", "categories": ["cs.CR", "cs.CL", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.19060", "abs": "https://arxiv.org/abs/2507.19060", "authors": ["Jiawei Liu", "Nirav Diwan", "Zhe Wang", "Haoyu Zhai", "Xiaona Zhou", "Kiet A. Nguyen", "Tianjiao Yu", "Muntasir Wahed", "Yinlin Deng", "Hadjer Benkraouda", "Yuxiang Wei", "Lingming Zhang", "Ismini Lourentzou", "Gang Wang"], "title": "PurpCode: Reasoning for Safer Code Generation", "comment": null, "summary": "We introduce PurpCode, the first post-training recipe for training safe code\nreasoning models towards generating secure code and defending against malicious\ncyberactivities. PurpCode trains a reasoning model in two stages: (i) Rule\nLearning, which explicitly teaches the model to reference cybersafety rules to\ngenerate vulnerability-free code and to avoid facilitating malicious\ncyberactivities; and (ii) Reinforcement Learning, which optimizes model safety\nand preserves model utility through diverse, multi-objective reward mechanisms.\nTo empower the training pipelines with comprehensive cybersafety data, we\nconduct internal red-teaming to synthesize comprehensive and high-coverage\nprompts based on real-world tasks for inducing unsafe cyberactivities in the\nmodel. Based on PurpCode, we develop a reasoning-based coding model, namely\nPurpCode-32B, which demonstrates state-of-the-art cybersafety, outperforming\nvarious frontier models. Meanwhile, our alignment method decreases the model\noverrefusal rates in both general and cybersafety-specific scenarios, while\npreserving model utility in both code generation and common security knowledge.", "AI": {"tldr": "PurpCode\u662f\u4e00\u79cd\u540e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bad\u7ec3\u5b89\u5168\u7684\u4ee3\u7801\u63a8\u7406\u6a21\u578b\uff0c\u751f\u6210\u5b89\u5168\u4ee3\u7801\u5e76\u9632\u5fa1\u6076\u610f\u7f51\u7edc\u6d3b\u52a8\u3002\u901a\u8fc7\u89c4\u5219\u5b66\u4e60\u548c\u5f3a\u5316\u5b66\u4e60\u4e24\u9636\u6bb5\u8bad\u7ec3\uff0c\u7ed3\u5408\u7ea2\u961f\u6d4b\u8bd5\u6570\u636e\uff0c\u5f00\u53d1\u4e86PurpCode-32B\u6a21\u578b\uff0c\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u7f51\u7edc\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u5f53\u524d\u4ee3\u7801\u751f\u6210\u6a21\u578b\u5728\u7f51\u7edc\u5b89\u5168\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u5bb9\u6613\u751f\u6210\u4e0d\u5b89\u5168\u4ee3\u7801\u6216\u52a9\u957f\u6076\u610f\u6d3b\u52a8\u3002PurpCode\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63d0\u4f9b\u4e00\u79cd\u5b89\u5168\u7684\u4ee3\u7801\u63a8\u7406\u6a21\u578b\u3002", "method": "PurpCode\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\uff1a1) \u89c4\u5219\u5b66\u4e60\uff0c\u660e\u786e\u6559\u5bfc\u6a21\u578b\u5f15\u7528\u7f51\u7edc\u5b89\u5168\u89c4\u5219\u751f\u6210\u65e0\u6f0f\u6d1e\u4ee3\u7801\uff1b2) \u5f3a\u5316\u5b66\u4e60\uff0c\u901a\u8fc7\u591a\u76ee\u6807\u5956\u52b1\u673a\u5236\u4f18\u5316\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\u3002\u7ed3\u5408\u7ea2\u961f\u6d4b\u8bd5\u6570\u636e\u589e\u5f3a\u8bad\u7ec3\u3002", "result": "\u5f00\u53d1\u7684PurpCode-32B\u6a21\u578b\u5728\u7f51\u7edc\u5b89\u5168\u65b9\u9762\u8868\u73b0\u6700\u4f18\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u8fc7\u5ea6\u62d2\u7edd\u7387\uff0c\u4fdd\u6301\u4e86\u4ee3\u7801\u751f\u6210\u548c\u901a\u7528\u5b89\u5168\u77e5\u8bc6\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "PurpCode\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u540e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u63a8\u7406\u6a21\u578b\u7684\u7f51\u7edc\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\uff0c\u4e3a\u5b89\u5168\u4ee3\u7801\u751f\u6210\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.18977", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.18977", "abs": "https://arxiv.org/abs/2507.18977", "authors": ["Mehrnoosh Mirtaheri", "Ryan A. Rossi", "Sungchul Kim", "Kanak Mahadik", "Tong Yu", "Xiang Chen", "Mohammad Rostami"], "title": "Towards Improving Long-Tail Entity Predictions in Temporal Knowledge Graphs through Global Similarity and Weighted Sampling", "comment": null, "summary": "Temporal Knowledge Graph (TKG) completion models traditionally assume access\nto the entire graph during training. This overlooks challenges stemming from\nthe evolving nature of TKGs, such as: (i) the model's requirement to generalize\nand assimilate new knowledge, and (ii) the task of managing new or unseen\nentities that often have sparse connections. In this paper, we present an\nincremental training framework specifically designed for TKGs, aiming to\naddress entities that are either not observed during training or have sparse\nconnections. Our approach combines a model-agnostic enhancement layer with a\nweighted sampling strategy, that can be augmented to and improve any existing\nTKG completion method. The enhancement layer leverages a broader, global\ndefinition of entity similarity, which moves beyond mere local neighborhood\nproximity of GNN-based methods. The weighted sampling strategy employed in\ntraining accentuates edges linked to infrequently occurring entities. We\nevaluate our method on two benchmark datasets, and demonstrate that our\nframework outperforms existing methods in total link prediction, inductive link\nprediction, and in addressing long-tail entities. Notably, our method achieves\na 10\\% improvement and a 15\\% boost in MRR for these datasets. The results\nunderscore the potential of our approach in mitigating catastrophic forgetting\nand enhancing the robustness of TKG completion methods, especially in an\nincremental training context", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\uff08TKG\uff09\u7684\u589e\u91cf\u8bad\u7ec3\u6846\u67b6\uff0c\u89e3\u51b3\u65b0\u5b9e\u4f53\u548c\u7a00\u758f\u8fde\u63a5\u95ee\u9898\uff0c\u7ed3\u5408\u6a21\u578b\u65e0\u5173\u7684\u589e\u5f3a\u5c42\u548c\u52a0\u6743\u91c7\u6837\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u4f20\u7edfTKG\u8865\u5168\u6a21\u578b\u5047\u8bbe\u8bad\u7ec3\u65f6\u53ef\u8bbf\u95ee\u6574\u4e2a\u56fe\u8c31\uff0c\u5ffd\u7565\u4e86\u56fe\u8c31\u52a8\u6001\u6f14\u5316\u5e26\u6765\u7684\u6311\u6218\uff0c\u5982\u65b0\u77e5\u8bc6\u5438\u6536\u548c\u65b0\u5b9e\u4f53\u5904\u7406\u3002", "method": "\u7ed3\u5408\u6a21\u578b\u65e0\u5173\u7684\u589e\u5f3a\u5c42\uff08\u57fa\u4e8e\u5168\u5c40\u5b9e\u4f53\u76f8\u4f3c\u6027\uff09\u548c\u52a0\u6743\u91c7\u6837\u7b56\u7565\uff08\u4fa7\u91cd\u7a00\u758f\u5b9e\u4f53\u8fb9\uff09\uff0c\u53ef\u589e\u5f3a\u73b0\u6709TKG\u8865\u5168\u65b9\u6cd5\u3002", "result": "\u5728\u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u65b9\u6cd5\u5728\u603b\u94fe\u63a5\u9884\u6d4b\u3001\u5f52\u7eb3\u94fe\u63a5\u9884\u6d4b\u53ca\u957f\u5c3e\u5b9e\u4f53\u5904\u7406\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0cMRR\u63d0\u534715%\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u7f13\u89e3\u707e\u96be\u6027\u9057\u5fd8\uff0c\u589e\u5f3a\u4e86TKG\u8865\u5168\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\uff0c\u7279\u522b\u9002\u7528\u4e8e\u589e\u91cf\u8bad\u7ec3\u573a\u666f\u3002"}}
{"id": "2507.19115", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.19115", "abs": "https://arxiv.org/abs/2507.19115", "authors": ["Shweta Ramesh", "Joy Bose", "Hamender Singh", "A K Raghavan", "Sujoy Roychowdhury", "Giriprasad Sridhara", "Nishrith Saini", "Ricardo Britto"], "title": "Automated Code Review Using Large Language Models at Ericsson: An Experience Report", "comment": null, "summary": "Code review is one of the primary means of assuring the quality of released\nsoftware along with testing and static analysis. However, code review requires\nexperienced developers who may not always have the time to perform an in-depth\nreview of code. Thus, automating code review can help alleviate the cognitive\nburden on experienced software developers allowing them to focus on their\nprimary activities of writing code to add new features and fix bugs. In this\npaper, we describe our experience in using Large Language Models towards\nautomating the code review process in Ericsson. We describe the development of\na lightweight tool using LLMs and static program analysis. We then describe our\npreliminary experiments with experienced developers in evaluating our code\nreview tool and the encouraging results.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u9759\u6001\u7a0b\u5e8f\u5206\u6790\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u7684\u7ecf\u9a8c\uff0c\u65e8\u5728\u51cf\u8f7b\u5f00\u53d1\u8005\u7684\u8ba4\u77e5\u8d1f\u62c5\u3002", "motivation": "\u4ee3\u7801\u5ba1\u67e5\u662f\u4fdd\u8bc1\u8f6f\u4ef6\u8d28\u91cf\u7684\u91cd\u8981\u624b\u6bb5\uff0c\u4f46\u4f9d\u8d56\u7ecf\u9a8c\u4e30\u5bcc\u7684\u5f00\u53d1\u8005\uff0c\u4e14\u8017\u65f6\u3002\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u53ef\u4ee5\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eLLMs\u548c\u9759\u6001\u7a0b\u5e8f\u5206\u6790\u7684\u8f7b\u91cf\u7ea7\u5de5\u5177\uff0c\u5e76\u8fdb\u884c\u4e86\u521d\u6b65\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5de5\u5177\u8868\u73b0\u4ee4\u4eba\u9f13\u821e\u3002", "conclusion": "\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u5de5\u5177\u6709\u6f5c\u529b\u63d0\u5347\u5f00\u53d1\u6548\u7387\uff0c\u51cf\u8f7b\u5f00\u53d1\u8005\u8d1f\u62c5\u3002"}}
{"id": "2507.19185", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.19185", "abs": "https://arxiv.org/abs/2507.19185", "authors": ["Tarek Gasmi", "Ramzi Guesmi", "Mootez Aloui", "Jihene Bennaceur"], "title": "PrompTrend: Continuous Community-Driven Vulnerability Discovery and Assessment for Large Language Models", "comment": null, "summary": "Static benchmarks fail to capture LLM vulnerabilities emerging through\ncommunity experimentation in online forums. We present PrompTrend, a system\nthat collects vulnerability data across platforms and evaluates them using\nmultidimensional scoring, with an architecture designed for scalable\nmonitoring. Cross-sectional analysis of 198 vulnerabilities collected from\nonline communities over a five-month period (January-May 2025) and tested on\nnine commercial models reveals that advanced capabilities correlate with\nincreased vulnerability in some architectures, psychological attacks\nsignificantly outperform technical exploits, and platform dynamics shape attack\neffectiveness with measurable model-specific patterns. The PrompTrend\nVulnerability Assessment Framework achieves 78% classification accuracy while\nrevealing limited cross-model transferability, demonstrating that effective LLM\nsecurity requires comprehensive socio-technical monitoring beyond traditional\nperiodic assessment. Our findings challenge the assumption that capability\nadvancement improves security and establish community-driven psychological\nmanipulation as the dominant threat vector for current language models.", "AI": {"tldr": "PrompTrend\u7cfb\u7edf\u901a\u8fc7\u6536\u96c6\u548c\u5206\u6790\u5728\u7ebf\u793e\u533a\u7684\u6f0f\u6d1e\u6570\u636e\uff0c\u63ed\u793a\u9ad8\u7ea7\u80fd\u529b\u4e0e\u6f0f\u6d1e\u589e\u52a0\u76f8\u5173\uff0c\u5fc3\u7406\u653b\u51fb\u6548\u679c\u4f18\u4e8e\u6280\u672f\u653b\u51fb\uff0c\u5e76\u5f3a\u8c03LLM\u5b89\u5168\u9700\u7ed3\u5408\u793e\u4f1a\u6280\u672f\u76d1\u6d4b\u3002", "motivation": "\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u6355\u6349\u5728\u7ebf\u793e\u533a\u5b9e\u9a8c\u4e2dLLM\u7684\u6f0f\u6d1e\uff0c\u9700\u52a8\u6001\u76d1\u6d4b\u7cfb\u7edf\u3002", "method": "PrompTrend\u7cfb\u7edf\u6536\u96c6\u6f0f\u6d1e\u6570\u636e\uff0c\u91c7\u7528\u591a\u7ef4\u8bc4\u5206\u8bc4\u4f30\uff0c\u5206\u6790198\u4e2a\u6f0f\u6d1e\u548c9\u4e2a\u5546\u4e1a\u6a21\u578b\u3002", "result": "\u9ad8\u7ea7\u80fd\u529b\u4e0e\u6f0f\u6d1e\u589e\u52a0\u76f8\u5173\uff0c\u5fc3\u7406\u653b\u51fb\u6548\u679c\u663e\u8457\uff0c\u5e73\u53f0\u52a8\u6001\u5f71\u54cd\u653b\u51fb\u6548\u679c\uff0c\u5206\u7c7b\u51c6\u786e\u7387\u8fbe78%\u3002", "conclusion": "LLM\u5b89\u5168\u9700\u7efc\u5408\u793e\u4f1a\u6280\u672f\u76d1\u6d4b\uff0c\u80fd\u529b\u63d0\u5347\u672a\u5fc5\u6539\u5584\u5b89\u5168\uff0c\u5fc3\u7406\u653b\u51fb\u662f\u4e3b\u8981\u5a01\u80c1\u3002"}}
{"id": "2507.19089", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.19089", "abs": "https://arxiv.org/abs/2507.19089", "authors": ["Shuhao Li", "Weidong Yang", "Yue Cui", "Xiaoxing Liu", "Lingkai Meng", "Lipeng Ma", "Fan Zhang"], "title": "Fine-Grained Traffic Inference from Road to Lane via Spatio-Temporal Graph Node Generation", "comment": null, "summary": "Fine-grained traffic management and prediction are fundamental to key\napplications such as autonomous driving, lane change guidance, and traffic\nsignal control. However, obtaining lane-level traffic data has become a\ncritical bottleneck for data-driven models due to limitations in the types and\nnumber of sensors and issues with the accuracy of tracking algorithms. To\naddress this, we propose the Fine-grained Road Traffic Inference (FRTI) task,\nwhich aims to generate more detailed lane-level traffic information using\nlimited road data, providing a more energy-efficient and cost-effective\nsolution for precise traffic management. This task is abstracted as the first\nscene of the spatio-temporal graph node generation problem. We designed a\ntwo-stage framework--RoadDiff--to solve the FRTI task. solve the FRTI task.\nThis framework leverages the Road-Lane Correlation Autoencoder-Decoder and the\nLane Diffusion Module to fully utilize the limited spatio-temporal dependencies\nand distribution relationships of road data to accurately infer fine-grained\nlane traffic states. Based on existing research, we designed several baseline\nmodels with the potential to solve the FRTI task and conducted extensive\nexperiments on six datasets representing different road conditions to validate\nthe effectiveness of the RoadDiff model in addressing the FRTI task. The\nrelevant datasets and code are available at\nhttps://github.com/ShuhaoLii/RoadDiff.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFRTI\u7684\u4efb\u52a1\uff0c\u65e8\u5728\u901a\u8fc7\u6709\u9650\u7684\u9053\u8def\u6570\u636e\u751f\u6210\u66f4\u8be6\u7ec6\u7684\u8f66\u9053\u7ea7\u4ea4\u901a\u4fe1\u606f\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4e24\u9636\u6bb5\u6846\u67b6RoadDiff\u6765\u89e3\u51b3\u8be5\u4efb\u52a1\u3002", "motivation": "\u83b7\u53d6\u8f66\u9053\u7ea7\u4ea4\u901a\u6570\u636e\u662f\u6570\u636e\u9a71\u52a8\u6a21\u578b\u7684\u5173\u952e\u74f6\u9888\uff0c\u73b0\u6709\u4f20\u611f\u5668\u7c7b\u578b\u548c\u6570\u91cf\u6709\u9650\uff0c\u4e14\u8ddf\u8e2a\u7b97\u6cd5\u51c6\u786e\u6027\u5b58\u5728\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u4e86RoadDiff\u6846\u67b6\uff0c\u5305\u62ecRoad-Lane Correlation Autoencoder-Decoder\u548cLane Diffusion Module\uff0c\u5145\u5206\u5229\u7528\u9053\u8def\u6570\u636e\u7684\u65f6\u7a7a\u4f9d\u8d56\u6027\u548c\u5206\u5e03\u5173\u7cfb\u3002", "result": "\u5728\u516d\u4e2a\u4e0d\u540c\u9053\u8def\u6761\u4ef6\u7684\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86RoadDiff\u6a21\u578b\u7684\u6709\u6548\u6027\u3002", "conclusion": "RoadDiff\u4e3a\u7cbe\u786e\u4ea4\u901a\u7ba1\u7406\u63d0\u4f9b\u4e86\u66f4\u8282\u80fd\u548c\u7ecf\u6d4e\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.19271", "categories": ["cs.SE", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2507.19271", "abs": "https://arxiv.org/abs/2507.19271", "authors": ["Igli Begolli", "Meltem Aksoy", "Daniel Neider"], "title": "Fine-Tuning Multilingual Language Models for Code Review: An Empirical Study on Industrial C# Projects", "comment": null, "summary": "Code review is essential for maintaining software quality but often\ntime-consuming and cognitively demanding, especially in industrial\nenvironments. Recent advancements in language models (LMs) have opened new\navenues for automating core review tasks. This study presents the empirical\nevaluation of monolingual fine-tuning on the performance of open-source LMs\nacross three key automated code review tasks: Code Change Quality Estimation,\nReview Comment Generation, and Code Refinement. We fine-tuned three distinct\nmodels, CodeReviewer, CodeLlama-7B, and DeepSeek-R1-Distill, on a C\\# specific\ndataset combining public benchmarks with industrial repositories. Our study\ninvestigates how different configurations of programming languages and natural\nlanguages in the training data affect LM performance, particularly in comment\ngeneration. Additionally, we benchmark the fine-tuned models against an\nautomated software analysis tool (ASAT) and human reviewers to evaluate their\npractical utility in real-world settings. Our results show that monolingual\nfine-tuning improves model accuracy and relevance compared to multilingual\nbaselines. While LMs can effectively support code review workflows, especially\nfor routine or repetitive tasks, human reviewers remain superior in handling\nsemantically complex or context-sensitive changes. Our findings highlight the\nimportance of language alignment and task-specific adaptation in optimizing LMs\nfor automated code review.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u5355\u8bed\u8a00\u5fae\u8c03\u5bf9\u5f00\u6e90\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u5ba1\u67e5\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u5f71\u54cd\uff0c\u53d1\u73b0\u5176\u4f18\u4e8e\u591a\u8bed\u8a00\u57fa\u7ebf\uff0c\u4f46\u4eba\u7c7b\u5ba1\u67e5\u5458\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u4ecd\u66f4\u4f18\u3002", "motivation": "\u4ee3\u7801\u5ba1\u67e5\u5bf9\u8f6f\u4ef6\u8d28\u91cf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u8017\u65f6\u4e14\u8ba4\u77e5\u8d1f\u62c5\u91cd\uff0c\u8bed\u8a00\u6a21\u578b\u4e3a\u81ea\u52a8\u5316\u5ba1\u67e5\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002", "method": "\u5bf9\u4e09\u79cd\u6a21\u578b\uff08CodeReviewer\u3001CodeLlama-7B\u3001DeepSeek-R1-Distill\uff09\u8fdb\u884c\u5355\u8bed\u8a00\u5fae\u8c03\uff0c\u4f7f\u7528C#\u6570\u636e\u96c6\uff0c\u5e76\u4e0eASAT\u548c\u4eba\u7c7b\u5ba1\u67e5\u5458\u5bf9\u6bd4\u3002", "result": "\u5355\u8bed\u8a00\u5fae\u8c03\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u76f8\u5173\u6027\uff0c\u4f46\u4eba\u7c7b\u5728\u8bed\u4e49\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u8bed\u8a00\u5bf9\u9f50\u548c\u4efb\u52a1\u7279\u5b9a\u9002\u914d\u5bf9\u4f18\u5316\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u4e2d\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2507.19295", "categories": ["cs.CR", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.19295", "abs": "https://arxiv.org/abs/2507.19295", "authors": ["Svenja Lage", "Hannes Bartz"], "title": "On the Security of a Code-Based PIR Scheme", "comment": null, "summary": "Private Information Retrieval (PIR) schemes allow clients to retrieve files\nfrom a database without disclosing the requested file's identity to the server.\nIn the pursuit of post-quantum security, most recent PIR schemes rely on hard\nlattice problems. In contrast, the so called CB-cPIR scheme stands out as a\npioneering effort to base PIR schemes on hard problems in coding theory,\nthereby contributing significantly to the diversification of security\nfoundations. However, our research reveals a critical vulnerability in CB-cPIR,\nsubstantially diminishing its security levels. Moreover, a comparative analysis\nwith state-of-the-art PIR schemes shows that CB-cPIR's advantages are reduced,\nmaking it less competitive in terms of the communication cost. Nevertheless,\nour findings highlight the importance of continued research into code-based PIR\nschemes, as they have the potential to provide a valuable alternative to\nlattice-based approaches.", "AI": {"tldr": "CB-cPIR\u662f\u4e00\u79cd\u57fa\u4e8e\u7f16\u7801\u7406\u8bba\u7684PIR\u65b9\u6848\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\u5176\u5b58\u5728\u4e25\u91cd\u6f0f\u6d1e\uff0c\u5b89\u5168\u6027\u964d\u4f4e\uff0c\u4e14\u5728\u901a\u4fe1\u6210\u672c\u4e0a\u7ade\u4e89\u529b\u4e0d\u8db3\u3002", "motivation": "\u63a2\u7d22\u57fa\u4e8e\u7f16\u7801\u7406\u8bba\u7684PIR\u65b9\u6848\uff0c\u4ee5\u591a\u6837\u5316\u540e\u91cf\u5b50\u5b89\u5168\u7684\u57fa\u7840\u3002", "method": "\u5206\u6790CB-cPIR\u65b9\u6848\u7684\u5b89\u5168\u6027\uff0c\u5e76\u4e0e\u73b0\u6709PIR\u65b9\u6848\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "CB-cPIR\u5b58\u5728\u5173\u952e\u6f0f\u6d1e\uff0c\u5b89\u5168\u6027\u964d\u4f4e\uff0c\u901a\u4fe1\u6210\u672c\u7ade\u4e89\u529b\u4e0d\u8db3\u3002", "conclusion": "\u4ecd\u9700\u7814\u7a76\u57fa\u4e8e\u7f16\u7801\u7406\u8bba\u7684PIR\u65b9\u6848\uff0c\u4f5c\u4e3a\u57fa\u4e8e\u683c\u65b9\u6848\u7684\u66ff\u4ee3\u9009\u62e9\u3002"}}
{"id": "2507.19109", "categories": ["cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2507.19109", "abs": "https://arxiv.org/abs/2507.19109", "authors": ["No\u00e9 Lallouet", "Tristan Cazenave", "Cyrille Enderli"], "title": "Pareto-NRPA: A Novel Monte-Carlo Search Algorithm for Multi-Objective Optimization", "comment": "Preprint ; accepted to ECAI 2025", "summary": "We introduce Pareto-NRPA, a new Monte-Carlo algorithm designed for\nmulti-objective optimization problems over discrete search spaces. Extending\nthe Nested Rollout Policy Adaptation (NRPA) algorithm originally formulated for\nsingle-objective problems, Pareto-NRPA generalizes the nested search and policy\nupdate mechanism to multi-objective optimization. The algorithm uses a set of\npolicies to concurrently explore different regions of the solution space and\nmaintains non-dominated fronts at each level of search. Policy adaptation is\nperformed with respect to the diversity and isolation of sequences within the\nPareto front. We benchmark Pareto-NRPA on two classes of problems: a novel\nbi-objective variant of the Traveling Salesman Problem with Time Windows\nproblem (MO-TSPTW), and a neural architecture search task on well-known\nbenchmarks. Results demonstrate that Pareto-NRPA achieves competitive\nperformance against state-of-the-art multi-objective algorithms, both in terms\nof convergence and diversity of solutions. Particularly, Pareto-NRPA strongly\noutperforms state-of-the-art evolutionary multi-objective algorithms on\nconstrained search spaces. To our knowledge, this work constitutes the first\nadaptation of NRPA to the multi-objective setting.", "AI": {"tldr": "Pareto-NRPA\u662f\u4e00\u79cd\u65b0\u7684\u8499\u7279\u5361\u6d1b\u7b97\u6cd5\uff0c\u7528\u4e8e\u79bb\u6563\u641c\u7d22\u7a7a\u95f4\u7684\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u6269\u5c55\u4e86\u5355\u76ee\u6807\u95ee\u9898\u7684NRPA\u7b97\u6cd5\u3002", "motivation": "\u5c06\u5355\u76ee\u6807\u4f18\u5316\u7684NRPA\u7b97\u6cd5\u6269\u5c55\u5230\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u89e3\u51b3\u73b0\u6709\u7b97\u6cd5\u5728\u6536\u655b\u6027\u548c\u591a\u6837\u6027\u4e0a\u7684\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u591a\u7b56\u7565\u5e76\u884c\u63a2\u7d22\u89e3\u7a7a\u95f4\uff0c\u5e76\u5728\u641c\u7d22\u7684\u6bcf\u4e2a\u5c42\u7ea7\u7ef4\u62a4\u975e\u652f\u914d\u524d\u6cbf\uff0c\u7b56\u7565\u66f4\u65b0\u57fa\u4e8ePareto\u524d\u6cbf\u7684\u591a\u6837\u6027\u548c\u9694\u79bb\u6027\u3002", "result": "\u5728MO-TSPTW\u95ee\u9898\u548c\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u641c\u7d22\u4efb\u52a1\u4e2d\uff0cPareto-NRPA\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7b97\u6cd5\uff0c\u5c24\u5176\u5728\u53d7\u9650\u641c\u7d22\u7a7a\u95f4\u4e2d\u3002", "conclusion": "Pareto-NRPA\u662fNRPA\u7b97\u6cd5\u5728\u591a\u76ee\u6807\u4f18\u5316\u4e2d\u7684\u9996\u6b21\u6210\u529f\u6269\u5c55\uff0c\u5177\u6709\u7ade\u4e89\u529b\u548c\u6f5c\u529b\u3002"}}
{"id": "2507.19275", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.19275", "abs": "https://arxiv.org/abs/2507.19275", "authors": ["Bo Wang", "Pengyang Wang", "Chong Chen", "Qi Sun", "Jieke Shi", "Chengran Yang", "Ming Deng", "Youfang Lin", "Zhou Yang", "David Lo"], "title": "Mut4All: Fuzzing Compilers via LLM-Synthesized Mutators Learned from Bug Reports", "comment": null, "summary": "Mutation-based fuzzing is effective for uncovering compiler bugs, but\ndesigning high-quality mutators for modern languages with complex constructs\n(e.g., templates, macros) remains challenging. Existing methods rely heavily on\nmanual design or human-in-the-loop correction, limiting scalability and\ncross-language generalizability.\n  We present Mut4All, a fully automated, language-agnostic framework that\nsynthesizes mutators using Large Language Models (LLMs) and compiler-specific\nknowledge from bug reports. It consists of three agents: (1) a mutator\ninvention agent that identifies mutation targets and generates mutator metadata\nusing compiler-related insights; (2) a mutator implementation synthesis agent,\nfine-tuned to produce initial implementations; and (3) a mutator refinement\nagent that verifies and corrects the mutators via unit-test feedback.\n  Mut4All processes 1000 bug reports (500 Rust, 500 C++), yielding 319 Rust and\n403 C++ mutators at ~$0.08 each via GPT-4o. Our customized fuzzer, using these\nmutators, finds 62 bugs in Rust compilers (38 new, 7 fixed) and 34 bugs in C++\ncompilers (16 new, 1 fixed). Mut4All outperforms existing methods in both\nunique crash detection and coverage, ranking first on Rust and second on C++.", "AI": {"tldr": "Mut4All\u662f\u4e00\u4e2a\u5168\u81ea\u52a8\u3001\u8bed\u8a00\u65e0\u5173\u7684\u6846\u67b6\uff0c\u5229\u7528LLM\u548c\u7f16\u8bd1\u5668\u77e5\u8bc6\u751f\u6210\u9ad8\u8d28\u91cf\u53d8\u5f02\u5668\uff0c\u663e\u8457\u63d0\u5347\u6a21\u7cca\u6d4b\u8bd5\u6548\u679c\u3002", "motivation": "\u73b0\u4ee3\u8bed\u8a00\u7ed3\u6784\u590d\u6742\uff0c\u4f20\u7edf\u53d8\u5f02\u5668\u8bbe\u8ba1\u4f9d\u8d56\u4eba\u5de5\uff0c\u96be\u4ee5\u6269\u5c55\u548c\u8de8\u8bed\u8a00\u901a\u7528\u3002", "method": "Mut4All\u901a\u8fc7\u4e09\u4e2a\u4ee3\u7406\uff1a\u53d8\u5f02\u5668\u53d1\u660e\u3001\u5b9e\u73b0\u5408\u6210\u548c\u4f18\u5316\uff0c\u81ea\u52a8\u5316\u751f\u6210\u53d8\u5f02\u5668\u3002", "result": "\u5904\u74061000\u4e2a\u9519\u8bef\u62a5\u544a\uff0c\u751f\u6210722\u4e2a\u53d8\u5f02\u5668\uff0c\u6210\u672c\u4f4e\uff0c\u53d1\u73b096\u4e2a\u7f16\u8bd1\u5668\u9519\u8bef\u3002", "conclusion": "Mut4All\u5728\u72ec\u7279\u5d29\u6e83\u68c0\u6d4b\u548c\u8986\u76d6\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u81ea\u52a8\u5316\u53d8\u5f02\u5668\u8bbe\u8ba1\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.19367", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.19367", "abs": "https://arxiv.org/abs/2507.19367", "authors": ["Weihao Chen", "Yansong Gao", "Boyu Kuang", "Jin B. Hong", "Yuqing Zhang", "Anmin Fu"], "title": "Empowering IoT Firmware Secure Update with Customization Rights", "comment": null, "summary": "Firmware updates remain the primary line of defense for IoT devices; however,\nthe update channel itself has become a well-established attack vector. Existing\ndefenses mainly focus on securing monolithic firmware images, leaving\nmodule-level customization -a growing user demand-largely unprotected and\ninsufficiently explored. To address this gap, we conduct a pilot study on the\nupdate workflows of 200 Linux-based IoT devices across 23 vendors, uncovering\nfive previously undocumented vulnerabilities caused by customization practices.\nA broader analysis of update-related CVEs from 2020 to 2024 reveals that over\nhalf originate from customization-induced issues. These findings highlight a\ncritical yet underexamined reality: as customization increases, so does the\nattack surface, while current defenses fail to keep pace. We propose IMUP\n(Integrity-Centric Modular Update Platform), the first framework to address two\nkey challenges: constructing a trustworthy cross-module integrity chain and\nscaling update performance under mass customization. IMUP combines three\ntechniques: per-module chameleon hashing for integrity, server-side\nproof-of-work offloading to reduce device overhead, and server-side caching to\nreuse module combinations, minimizing rebuild costs. Security analysis shows\nthat even when 95 percent of secret keys are exposed, forging a valid image\nincurs over 300 times the cost of the legitimate server. Experiments on\nheterogeneous IoT devices demonstrate that IMUP reduces server-side generation\ntime by 2.9 times and device downtime by 5.9 times compared to a\npackage-manager baseline.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86IoT\u8bbe\u5907\u56fa\u4ef6\u66f4\u65b0\u4e2d\u7684\u6a21\u5757\u5316\u5b9a\u5236\u6f0f\u6d1e\uff0c\u63d0\u51fa\u4e86IMUP\u6846\u67b6\u4ee5\u63d0\u5347\u5b89\u5168\u6027\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u9632\u5fa1\u63aa\u65bd\u4e3b\u8981\u5173\u6ce8\u6574\u4f53\u56fa\u4ef6\uff0c\u5ffd\u7565\u4e86\u6a21\u5757\u5316\u5b9a\u5236\u5e26\u6765\u7684\u5b89\u5168\u98ce\u9669\uff0c\u5bfc\u81f4\u653b\u51fb\u9762\u6269\u5927\u3002", "method": "\u901a\u8fc7\u5206\u6790200\u53f0Linux IoT\u8bbe\u5907\uff0c\u53d1\u73b0\u4e94\u4e2a\u672a\u8bb0\u5f55\u7684\u6f0f\u6d1e\uff0c\u5e76\u63d0\u51faIMUP\u6846\u67b6\uff0c\u7ed3\u5408\u53d8\u8272\u9f99\u54c8\u5e0c\u3001\u670d\u52a1\u5668\u7aef\u8ba1\u7b97\u5378\u8f7d\u548c\u7f13\u5b58\u6280\u672f\u3002", "result": "IMUP\u572895%\u5bc6\u94a5\u6cc4\u9732\u65f6\u4ecd\u80fd\u663e\u8457\u63d0\u9ad8\u653b\u51fb\u6210\u672c\uff0c\u670d\u52a1\u5668\u751f\u6210\u65f6\u95f4\u51cf\u5c112.9\u500d\uff0c\u8bbe\u5907\u505c\u673a\u65f6\u95f4\u51cf\u5c115.9\u500d\u3002", "conclusion": "\u6a21\u5757\u5316\u5b9a\u5236\u589e\u52a0\u4e86\u5b89\u5168\u98ce\u9669\uff0cIMUP\u6709\u6548\u89e3\u51b3\u4e86\u76f8\u5173\u6311\u6218\uff0c\u63d0\u5347\u4e86\u66f4\u65b0\u5b89\u5168\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2507.19132", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.19132", "abs": "https://arxiv.org/abs/2507.19132", "authors": ["Xuetian Chen", "Yinghao Chen", "Xinfeng Yuan", "Zhuo Peng", "Lu Chen", "Yuekeng Li", "Zhoujia Zhang", "Yingqian Huang", "Leyan Huang", "Jiaqing Liang", "Tianbao Xie", "Zhiyong Wu", "Qiushi Sun", "Biqing Qi", "Bowen Zhou"], "title": "OS-MAP: How Far Can Computer-Using Agents Go in Breadth and Depth?", "comment": "Work in progress", "summary": "Computer-using agents have shown strong potential to boost human productivity\nand enable new application forms across platforms. While recent advances have\nled to usable applications, existing benchmarks fail to account for the\ninternal task heterogeneity and the corresponding agent capabilities, as well\nas their alignment with actual user demands-hindering both targeted capability\ndevelopment and the reliable transition of research progress into practical\ndeployment. To bridge the gap, we present OS-MAP, a benchmark for daily\ncomputer-using automation that organizes its 416 realistic tasks across 15\napplications along two key dimensions: a five-level taxonomy of automation and\na generalization scope derived from a real-world user demand hierarchy. To\nenable fine-grained analysis of required capabilities and alignment with\nreal-world scenarios, OS-MAP evaluates agents along two dimensions: automation\nlevel across a five-level taxonomy, and generalization scope across a demand\nhierarchy. This design captures varying levels of required agent autonomy and\ngeneralization, forming a performance-generalization evaluation matrix for\nstructured and comprehensive assessment. Experiments show that even\nState-of-the-Art agents with VLM backbones struggle with higher-level tasks\ninvolving perception, reasoning, and coordination-highlighting the need for a\ndeeper understanding of current strengths and limitations to drive the future\nprogress in computer-using agents research and deployment. All code,\nenvironments, baselines, and data are publicly available at\nhttps://github.com/OS-Copilot/OS-Map.", "AI": {"tldr": "OS-MAP\u662f\u4e00\u4e2a\u7528\u4e8e\u65e5\u5e38\u8ba1\u7b97\u673a\u81ea\u52a8\u5316\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u4e94\u7ea7\u81ea\u52a8\u5316\u5206\u7c7b\u548c\u9700\u6c42\u5c42\u6b21\u7ed3\u6784\u8bc4\u4f30\u4ee3\u7406\u80fd\u529b\uff0c\u63ed\u793a\u5f53\u524d\u4ee3\u7406\u5728\u9ad8\u9636\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u672a\u80fd\u8003\u8651\u4efb\u52a1\u5f02\u8d28\u6027\u548c\u4ee3\u7406\u80fd\u529b\u4e0e\u5b9e\u9645\u7528\u6237\u9700\u6c42\u7684\u5339\u914d\uff0c\u963b\u788d\u4e86\u9488\u5bf9\u6027\u80fd\u529b\u5f00\u53d1\u548c\u7814\u7a76\u6210\u679c\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51faOS-MAP\u57fa\u51c6\uff0c\u5305\u542b416\u4e2a\u4efb\u52a1\uff0c\u6309\u4e94\u7ea7\u81ea\u52a8\u5316\u5206\u7c7b\u548c\u9700\u6c42\u5c42\u6b21\u7ed3\u6784\u7ec4\u7ec7\uff0c\u8bc4\u4f30\u4ee3\u7406\u7684\u81ea\u52a8\u5316\u6c34\u5e73\u548c\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5373\u4f7f\u6700\u5148\u8fdb\u7684\u4ee3\u7406\u5728\u6d89\u53ca\u611f\u77e5\u3001\u63a8\u7406\u548c\u534f\u8c03\u7684\u9ad8\u9636\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "OS-MAP\u4e3a\u8ba1\u7b97\u673a\u4ee3\u7406\u7684\u7814\u7a76\u548c\u90e8\u7f72\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6280\u672f\u7684\u5c40\u9650\u6027\uff0c\u63a8\u52a8\u672a\u6765\u8fdb\u6b65\u3002"}}
{"id": "2507.19390", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.19390", "abs": "https://arxiv.org/abs/2507.19390", "authors": ["Altaf Allah Abbassi", "Leuson Da Silva", "Amin Nikanjam", "Foutse Khomh"], "title": "ReCatcher: Towards LLMs Regression Testing for Code Generation", "comment": "24 pages, 3 Figures, 2 Tables", "summary": "Large Language Models (LLMs) for code generation evolve rapidly through\nfine-tuning, merging, or new model releases. However, such updates can\nintroduce regressions, not only in correctness but also in code quality and\nperformance. To address this, we present ReCatcher, a regression testing\nframework for Python code generation. ReCatcher systematically compares two\nLLMs, typically a current model and a candidate update, across three\ndimensions: logical correctness, static code quality, and execution\nperformance. We apply ReCatcher to assess regressions across three update\nscenarios, fine-tuning, merging, and model release, using CodeLlama,\nDeepSeek-Coder, and GPT-4o. Our evaluation shows that fine-tuning with\ncross-language datasets increases syntax errors by up to 12%. Merging with\ngeneral-purpose models like Llama2 leads to regressions in correctness by up to\n18%. GPT-4o introduces regressions of up to 50% in handling missing imports\ncompared to GPT-3.5-turbo, while GPT-4o-mini suffers up to 80% performance\ndegradation in execution time versus GPT-4o. Overall, logical correctness,\nperformance, and error handling (e.g., syntax errors and missing imports) are\nthe most regression-prone areas. Comparing ReCatcher with baseline solutions,\nit presents better and consistent accuracy across logical and performance\naspects. ReCatcher highlights the importance of systematic regression\nevaluation before adopting new models, while assisting researchers and\npractitioners in making more informed update decisions.", "AI": {"tldr": "ReCatcher\u662f\u4e00\u4e2a\u7528\u4e8ePython\u4ee3\u7801\u751f\u6210\u7684\u56de\u5f52\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u6bd4\u8f83\u903b\u8f91\u6b63\u786e\u6027\u3001\u9759\u6001\u4ee3\u7801\u8d28\u91cf\u548c\u6267\u884c\u6027\u80fd\u6765\u8bc4\u4f30LLM\u66f4\u65b0\u4e2d\u7684\u56de\u5f52\u95ee\u9898\u3002", "motivation": "\u968f\u7740LLM\u7684\u5feb\u901f\u66f4\u65b0\uff0c\u53ef\u80fd\u5f15\u5165\u4ee3\u7801\u8d28\u91cf\u548c\u6027\u80fd\u7684\u56de\u5f52\u95ee\u9898\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u7684\u8bc4\u4f30\u5de5\u5177\u3002", "method": "ReCatcher\u901a\u8fc7\u4e09\u4e2a\u7ef4\u5ea6\uff08\u903b\u8f91\u6b63\u786e\u6027\u3001\u9759\u6001\u4ee3\u7801\u8d28\u91cf\u548c\u6267\u884c\u6027\u80fd\uff09\u6bd4\u8f83\u4e24\u4e2aLLM\uff08\u901a\u5e38\u662f\u5f53\u524d\u6a21\u578b\u548c\u5019\u9009\u66f4\u65b0\uff09\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0c\u4e0d\u540c\u66f4\u65b0\u573a\u666f\uff08\u5982\u5fae\u8c03\u3001\u5408\u5e76\u548c\u65b0\u6a21\u578b\u53d1\u5e03\uff09\u4f1a\u5f15\u5165\u4e0d\u540c\u7a0b\u5ea6\u7684\u56de\u5f52\u95ee\u9898\uff0c\u4f8b\u5982\u8bed\u6cd5\u9519\u8bef\u589e\u52a012%\uff0c\u6b63\u786e\u6027\u4e0b\u964d18%\u3002", "conclusion": "ReCatcher\u5728\u903b\u8f91\u548c\u6027\u80fd\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5f3a\u8c03\u4e86\u5728\u91c7\u7528\u65b0\u6a21\u578b\u524d\u8fdb\u884c\u7cfb\u7edf\u56de\u5f52\u8bc4\u4f30\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.19391", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.19391", "abs": "https://arxiv.org/abs/2507.19391", "authors": ["Armin Namavari", "Thomas Ristenpart"], "title": "Transcript Franking for Encrypted Messaging", "comment": null, "summary": "Message franking is an indispensable abuse mitigation tool for end-to-end\nencrypted (E2EE) messaging platforms. With it, users who receive harmful\ncontent can securely report that content to platform moderators. However, while\nreal-world deployments of reporting require the disclosure of multiple\nmessages, existing treatments of message franking only consider the report of a\nsingle message. As a result, there is a gap between the security goals achieved\nby constructions and those needed in practice. Our work introduces transcript\nfranking, a new type of protocol that allows reporting subsets of conversations\nsuch that moderators can cryptographically verify message causality and\ncontents. We define syntax, semantics, and security for transcript franking in\ntwo-party and group messaging. We then present efficient constructions for\ntranscript franking and prove their security. Looking toward deployment\nconsiderations, we provide detailed discussion of how real-world messaging\nsystems can incorporate our protocols.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3a\u201ctranscript franking\u201d\u7684\u65b0\u534f\u8bae\uff0c\u7528\u4e8e\u5728\u7aef\u5230\u7aef\u52a0\u5bc6\u6d88\u606f\u5e73\u53f0\u4e2d\u62a5\u544a\u591a\u6d88\u606f\u5185\u5bb9\uff0c\u586b\u8865\u4e86\u73b0\u6709\u5355\u6d88\u606f\u62a5\u544a\u534f\u8bae\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u6d88\u606f\u62a5\u544a\u534f\u8bae\u4ec5\u652f\u6301\u5355\u6d88\u606f\u62a5\u544a\uff0c\u800c\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8981\u62a5\u544a\u591a\u6d88\u606f\u5185\u5bb9\uff0c\u5b58\u5728\u5b89\u5168\u76ee\u6807\u4e0e\u5b9e\u8df5\u9700\u6c42\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u5b9a\u4e49\u4e86transcript franking\u7684\u8bed\u6cd5\u3001\u8bed\u4e49\u548c\u5b89\u5168\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u9ad8\u6548\u7684\u4e24\u65b9\u548c\u7fa4\u7ec4\u6d88\u606f\u6784\u9020\u65b9\u6848\u3002", "result": "\u63d0\u51fa\u4e86transcript franking\u534f\u8bae\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5b89\u5168\u6027\uff0c\u540c\u65f6\u8ba8\u8bba\u4e86\u5b9e\u9645\u90e8\u7f72\u7684\u53ef\u884c\u6027\u3002", "conclusion": "transcript franking\u586b\u8865\u4e86\u73b0\u6709\u534f\u8bae\u7684\u4e0d\u8db3\uff0c\u4e3a\u7aef\u5230\u7aef\u52a0\u5bc6\u6d88\u606f\u5e73\u53f0\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u591a\u6d88\u606f\u62a5\u544a\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.19172", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.19172", "abs": "https://arxiv.org/abs/2507.19172", "authors": ["Jiyao Wang", "Xiao Yang", "Qingyong Hu", "Jiankai Tang", "Can Liu", "Dengbo He", "Yuntao Wang", "Yingcong Chen", "Kaishun Wu"], "title": "PhysDrive: A Multimodal Remote Physiological Measurement Dataset for In-vehicle Driver Monitoring", "comment": "It is the initial version, not the final version", "summary": "Robust and unobtrusive in-vehicle physiological monitoring is crucial for\nensuring driving safety and user experience. While remote physiological\nmeasurement (RPM) offers a promising non-invasive solution, its translation to\nreal-world driving scenarios is critically constrained by the scarcity of\ncomprehensive datasets. Existing resources are often limited in scale, modality\ndiversity, the breadth of biometric annotations, and the range of captured\nconditions, thereby omitting inherent real-world challenges in driving. Here,\nwe present PhysDrive, the first large-scale multimodal dataset for contactless\nin-vehicle physiological sensing with dedicated consideration on various\nmodality settings and driving factors. PhysDrive collects data from 48 drivers,\nincluding synchronized RGB, near-infrared camera, and raw mmWave radar data,\naccompanied with six synchronized ground truths (ECG, BVP, Respiration, HR, RR,\nand SpO2). It covers a wide spectrum of naturalistic driving conditions,\nincluding driver motions, dynamic natural light, vehicle types, and road\nconditions. We extensively evaluate both signal-processing and deep-learning\nmethods on PhysDrive, establishing a comprehensive benchmark across all\nmodalities, and release full open-source code with compatibility for mainstream\npublic toolboxes. We envision PhysDrive will serve as a foundational resource\nand accelerate research on multimodal driver monitoring and smart-cockpit\nsystems.", "AI": {"tldr": "PhysDrive\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u65e0\u63a5\u89e6\u8f66\u5185\u751f\u7406\u76d1\u6d4b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6570\u636e\u96c6\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u5f00\u6e90\u4ee3\u7801\u3002", "motivation": "\u73b0\u6709\u8fdc\u7a0b\u751f\u7406\u76d1\u6d4b\u6570\u636e\u96c6\u89c4\u6a21\u5c0f\u3001\u591a\u6837\u6027\u4e0d\u8db3\uff0c\u65e0\u6cd5\u6ee1\u8db3\u771f\u5b9e\u9a7e\u9a76\u573a\u666f\u7684\u9700\u6c42\u3002", "method": "PhysDrive\u6536\u96c6\u4e8648\u540d\u9a7e\u9a76\u5458\u7684\u591a\u6a21\u6001\u6570\u636e\uff08RGB\u3001\u8fd1\u7ea2\u5916\u76f8\u673a\u3001\u6beb\u7c73\u6ce2\u96f7\u8fbe\uff09\u548c\u516d\u79cd\u540c\u6b65\u751f\u7406\u4fe1\u53f7\uff0c\u8986\u76d6\u591a\u79cd\u9a7e\u9a76\u6761\u4ef6\u3002", "result": "\u6570\u636e\u96c6\u4e3a\u4fe1\u53f7\u5904\u7406\u548c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5168\u9762\u57fa\u51c6\uff0c\u5e76\u5f00\u6e90\u4e86\u4ee3\u7801\u3002", "conclusion": "PhysDrive\u5c06\u6210\u4e3a\u591a\u6a21\u6001\u9a7e\u9a76\u5458\u76d1\u6d4b\u548c\u667a\u80fd\u5ea7\u8231\u7cfb\u7edf\u7814\u7a76\u7684\u57fa\u7840\u8d44\u6e90\u3002"}}
{"id": "2507.19403", "categories": ["cs.SE", "cs.AI", "cs.DC", "B.8.2; C.2.4"], "pdf": "https://arxiv.org/pdf/2507.19403", "abs": "https://arxiv.org/abs/2507.19403", "authors": ["Matthias Wei\u00df", "Falk Dettinger", "Michael Weyrich"], "title": "SDVDiag: A Modular Platform for the Diagnosis of Connected Vehicle Functions", "comment": "7 pages, 5 figures", "summary": "Connected and software-defined vehicles promise to offer a broad range of\nservices and advanced functions to customers, aiming to increase passenger\ncomfort and support autonomous driving capabilities. Due to the high\nreliability and availability requirements of connected vehicles, it is crucial\nto resolve any occurring failures quickly. To achieve this however, a complex\ncloud/edge architecture with a mesh of dependencies must be navigated to\ndiagnose the responsible root cause. As such, manual analyses become unfeasible\nsince they would significantly delay the troubleshooting.\n  To address this challenge, this paper presents SDVDiag, an extensible\nplatform for the automated diagnosis of connected vehicle functions. The\nplatform enables the creation of pipelines that cover all steps from initial\ndata collection to the tracing of potential root causes. In addition, SDVDiag\nsupports self-adaptive behavior by the ability to exchange modules at runtime.\nDependencies between functions are detected and continuously updated, resulting\nin a dynamic graph view of the system. In addition, vital system metrics are\nmonitored for anomalies. Whenever an incident is investigated, a snapshot of\nthe graph is taken and augmented by relevant anomalies. Finally, the analysis\nis performed by traversing the graph and creating a ranking of the most likely\ncauses.\n  To evaluate the platform, it is deployed inside an 5G test fleet environment\nfor connected vehicle functions. The results show that injected faults can be\ndetected reliably. As such, the platform offers the potential to gain new\ninsights and reduce downtime by identifying problems and their causes at an\nearly stage.", "AI": {"tldr": "SDVDiag\u662f\u4e00\u4e2a\u7528\u4e8e\u81ea\u52a8\u5316\u8bca\u65ad\u8054\u7f51\u8f66\u8f86\u529f\u80fd\u7684\u53ef\u6269\u5c55\u5e73\u53f0\uff0c\u901a\u8fc7\u52a8\u6001\u56fe\u5206\u6790\u548c\u5f02\u5e38\u68c0\u6d4b\u5feb\u901f\u5b9a\u4f4d\u6545\u969c\u6839\u6e90\u3002", "motivation": "\u8054\u7f51\u8f66\u8f86\u7684\u9ad8\u53ef\u9760\u6027\u548c\u53ef\u7528\u6027\u9700\u6c42\u8981\u6c42\u5feb\u901f\u89e3\u51b3\u6545\u969c\uff0c\u4f46\u590d\u6742\u7684\u4e91/\u8fb9\u7f18\u67b6\u6784\u548c\u4f9d\u8d56\u5173\u7cfb\u4f7f\u5f97\u624b\u52a8\u5206\u6790\u4e0d\u53ef\u884c\u3002", "method": "SDVDiag\u5e73\u53f0\u652f\u6301\u4ece\u6570\u636e\u6536\u96c6\u5230\u6839\u56e0\u8ffd\u8e2a\u7684\u5b8c\u6574\u6d41\u7a0b\uff0c\u901a\u8fc7\u52a8\u6001\u56fe\u66f4\u65b0\u548c\u5f02\u5e38\u76d1\u63a7\u5b9e\u73b0\u81ea\u9002\u5e94\u8bca\u65ad\u3002", "result": "\u57285G\u6d4b\u8bd5\u73af\u5883\u4e2d\uff0cSDVDiag\u80fd\u591f\u53ef\u9760\u68c0\u6d4b\u6ce8\u5165\u7684\u6545\u969c\uff0c\u51cf\u5c11\u505c\u673a\u65f6\u95f4\u3002", "conclusion": "SDVDiag\u4e3a\u8054\u7f51\u8f66\u8f86\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u81ea\u52a8\u5316\u6545\u969c\u8bca\u65ad\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.19399", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.19399", "abs": "https://arxiv.org/abs/2507.19399", "authors": ["Gabriel Chua"], "title": "Running in CIRCLE? A Simple Benchmark for LLM Code Interpreter Security", "comment": null, "summary": "As large language models (LLMs) increasingly integrate native code\ninterpreters, they enable powerful real-time execution capabilities,\nsubstantially expanding their utility. However, such integrations introduce\npotential system-level cybersecurity threats, fundamentally different from\nprompt-based vulnerabilities. To systematically evaluate these\ninterpreter-specific risks, we propose CIRCLE (Code-Interpreter Resilience\nCheck for LLM Exploits), a simple benchmark comprising 1,260 prompts targeting\nCPU, memory, and disk resource exhaustion. Each risk category includes\nexplicitly malicious (\"direct\") and plausibly benign (\"indirect\") prompt\nvariants. Our automated evaluation framework assesses not only whether LLMs\nrefuse or generates risky code, but also executes the generated code within the\ninterpreter environment to evaluate code correctness, simplifications made by\nthe LLM to make the code safe, or execution timeouts. Evaluating 7 commercially\navailable models from OpenAI and Google, we uncover significant and\ninconsistent vulnerabilities. For instance, evaluations show substantial\ndisparities even within providers - OpenAI's o4-mini correctly refuses risky\nrequests at 7.1%, notably higher rates compared to GPT-4.1 at 0.5%. Results\nparticularly underscore that indirect, socially-engineered prompts\nsubstantially weaken model defenses. This highlights an urgent need for\ninterpreter-specific cybersecurity benchmarks, dedicated mitigation tools\n(e.g., guardrails), and clear industry standards to guide safe and responsible\ndeployment of LLM interpreter integrations. The benchmark dataset and\nevaluation code are publicly released to foster further research.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86CIRCLE\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u96c6\u6210\u4ee3\u7801\u89e3\u91ca\u5668\u65f6\u7684\u7cfb\u7edf\u7ea7\u7f51\u7edc\u5b89\u5168\u98ce\u9669\uff0c\u53d1\u73b0\u5546\u4e1a\u6a21\u578b\u5b58\u5728\u663e\u8457\u6f0f\u6d1e\u3002", "motivation": "\u968f\u7740LLMs\u96c6\u6210\u4ee3\u7801\u89e3\u91ca\u5668\uff0c\u5176\u529f\u80fd\u589e\u5f3a\u4f46\u4e5f\u5e26\u6765\u65b0\u7684\u7f51\u7edc\u5b89\u5168\u5a01\u80c1\uff0c\u9700\u7cfb\u7edf\u6027\u8bc4\u4f30\u8fd9\u4e9b\u98ce\u9669\u3002", "method": "\u63d0\u51faCIRCLE\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b1,260\u4e2a\u9488\u5bf9CPU\u3001\u5185\u5b58\u548c\u78c1\u76d8\u8d44\u6e90\u8017\u5c3d\u7684\u63d0\u793a\uff0c\u5e76\u81ea\u52a8\u5316\u8bc4\u4f30LLMs\u7684\u54cd\u5e94\u548c\u4ee3\u7801\u6267\u884c\u60c5\u51b5\u3002", "result": "\u8bc4\u4f307\u4e2a\u5546\u4e1a\u6a21\u578b\u53d1\u73b0\u663e\u8457\u6f0f\u6d1e\uff0c\u95f4\u63a5\u63d0\u793a\u5c24\u5176\u524a\u5f31\u6a21\u578b\u9632\u5fa1\uff0c\u4e0d\u540c\u6a21\u578b\u95f4\u5dee\u5f02\u660e\u663e\u3002", "conclusion": "\u9700\u5236\u5b9a\u7f51\u7edc\u5b89\u5168\u57fa\u51c6\u3001\u7f13\u89e3\u5de5\u5177\u548c\u884c\u4e1a\u6807\u51c6\uff0c\u4ee5\u5b89\u5168\u90e8\u7f72LLM\u89e3\u91ca\u5668\u96c6\u6210\u3002"}}
{"id": "2507.19182", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.19182", "abs": "https://arxiv.org/abs/2507.19182", "authors": ["Kuncheng Zou", "Jiahao Mai", "Yonggang Zhang", "Yuyi Wang", "Ond\u0159ej Ku\u017eelka", "Yuanhong Wang", "Yi Chang"], "title": "Faster Lifting for Ordered Domains with Predecessor Relations", "comment": null, "summary": "We investigate lifted inference on ordered domains with predecessor\nrelations, where the elements of the domain respect a total (cyclic) order, and\nevery element has a distinct (clockwise) predecessor. Previous work has\nexplored this problem through weighted first-order model counting (WFOMC),\nwhich computes the weighted sum of models for a given first-order logic\nsentence over a finite domain. In WFOMC, the order constraint is typically\nencoded by the linear order axiom introducing a binary predicate in the\nsentence to impose a linear ordering on the domain elements. The immediate and\nsecond predecessor relations are then encoded by the linear order predicate.\nAlthough WFOMC with the linear order axiom is theoretically tractable, existing\nalgorithms struggle with practical applications, particularly when the\npredecessor relations are involved. In this paper, we treat predecessor\nrelations as a native part of the axiom and devise a novel algorithm that\ninherently supports these relations. The proposed algorithm not only provides\nan exponential speedup for the immediate and second predecessor relations,\nwhich are known to be tractable, but also handles the general k-th predecessor\nrelations. The extensive experiments on lifted inference tasks and\ncombinatorics math problems demonstrate the efficiency of our algorithm,\nachieving speedups of a full order of magnitude.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7b97\u6cd5\uff0c\u76f4\u63a5\u5728\u516c\u7406\u4e2d\u5904\u7406\u524d\u9a71\u5173\u7cfb\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6709\u5e8f\u57df\u4e0a\u7684\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u6709\u5e8f\u57df\u548c\u524d\u9a71\u5173\u7cfb\u65f6\u6548\u7387\u4f4e\u4e0b\uff0c\u5c24\u5176\u662f\u5728\u6d89\u53ca\u524d\u9a71\u5173\u7cfb\u65f6\u3002", "method": "\u5c06\u524d\u9a71\u5173\u7cfb\u4f5c\u4e3a\u516c\u7406\u7684\u4e00\u90e8\u5206\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u7b97\u6cd5\uff0c\u652f\u6301\u76f4\u63a5\u5904\u7406\u524d\u9a71\u5173\u7cfb\u3002", "result": "\u65b0\u7b97\u6cd5\u5728\u5b9e\u9a8c\u4e2d\u5bf9\u524d\u9a71\u5173\u7cfb\u63a8\u7406\u4efb\u52a1\u548c\u7ec4\u5408\u6570\u5b66\u95ee\u9898\u5b9e\u73b0\u4e86\u6570\u91cf\u7ea7\u7684\u52a0\u901f\u3002", "conclusion": "\u65b0\u7b97\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6709\u5e8f\u57df\u63a8\u7406\u7684\u6548\u7387\uff0c\u5c24\u5176\u5728\u524d\u9a71\u5173\u7cfb\u5904\u7406\u4e0a\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2507.19432", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.19432", "abs": "https://arxiv.org/abs/2507.19432", "authors": ["Sheikh Shadab Towqir", "Fei He", "Todd Mytkowicz", "Na Meng"], "title": "Resolving Build Conflicts via Example-Based and Rule-Based Program Transformations", "comment": null, "summary": "Merge conflicts often arise when developers integrate changes from different\nsoftware branches. The conflicts can result from overlapping edits in programs\n(i.e., textual conflicts) or cause build and test errors (i.e., build and test\nconflicts). They degrade software quality and hinder programmer productivity.\nWhile several tools detect build conflicts, few offer meaningful support for\nresolving cases like those caused by method removal. To overcome limitations of\nexisting tools, we introduce BUCOR (Build Conflict Resolver), a new conflict\nresolver. BUCOR first detects conflicts by comparing three versions related to\na merging scenario: base b, left l, and right r. To resolve conflicts, it\nemploys two complementary strategies: example-based transformation (BUCOR-E)\nand rule-based transformation (BUCOR-R). BUCOR-R applies predefined rules to\nhandle common, well-understood conflicts. BUCOR-E mines branch versions (l and\nr) for exemplar edits applied to fix related build errors. From these examples,\nit infers and generalizes program transformation patterns to resolve more\ncomplex conflicts.\n  We evaluated BUCOR on 88 real-world build conflicts spanning 21 distinct\nconflict types. BUCOR generated at least one solution for 65 cases and\ncorrectly resolved 43 conflicts. We observed that this hybrid\napproach--combining context-aware, example-based learning with structured,\nrule-based resolution--can effectively help resolve conflicts. Our research\nsheds light on future directions for more intelligent and automated merge\ntools.", "AI": {"tldr": "BUCOR\u662f\u4e00\u4e2a\u65b0\u7684\u6784\u5efa\u51b2\u7a81\u89e3\u51b3\u5de5\u5177\uff0c\u7ed3\u5408\u4e86\u57fa\u4e8e\u793a\u4f8b\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5408\u5e76\u51b2\u7a81\u3002", "motivation": "\u5408\u5e76\u51b2\u7a81\uff08\u5305\u62ec\u6587\u672c\u51b2\u7a81\u548c\u6784\u5efa\u6d4b\u8bd5\u51b2\u7a81\uff09\u4f1a\u964d\u4f4e\u8f6f\u4ef6\u8d28\u91cf\u548c\u5f00\u53d1\u6548\u7387\uff0c\u73b0\u6709\u5de5\u5177\u5bf9\u67d0\u4e9b\u51b2\u7a81\uff08\u5982\u65b9\u6cd5\u79fb\u9664\uff09\u652f\u6301\u4e0d\u8db3\u3002", "method": "BUCOR\u901a\u8fc7\u6bd4\u8f83\u57fa\u7840\u3001\u5de6\u3001\u53f3\u4e09\u4e2a\u7248\u672c\u68c0\u6d4b\u51b2\u7a81\uff0c\u5e76\u91c7\u7528\u57fa\u4e8e\u793a\u4f8b\uff08BUCOR-E\uff09\u548c\u57fa\u4e8e\u89c4\u5219\uff08BUCOR-R\uff09\u7684\u7b56\u7565\u89e3\u51b3\u51b2\u7a81\u3002", "result": "\u572888\u4e2a\u771f\u5b9e\u6784\u5efa\u51b2\u7a81\u4e2d\uff0cBUCOR\u4e3a65\u4e2a\u6848\u4f8b\u751f\u6210\u81f3\u5c11\u4e00\u4e2a\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u6b63\u786e\u89e3\u51b3\u4e8643\u4e2a\u51b2\u7a81\u3002", "conclusion": "BUCOR\u7684\u6df7\u5408\u7b56\u7565\uff08\u7ed3\u5408\u4e0a\u4e0b\u6587\u611f\u77e5\u5b66\u4e60\u548c\u89c4\u5219\uff09\u6709\u6548\u89e3\u51b3\u51b2\u7a81\uff0c\u4e3a\u672a\u6765\u66f4\u667a\u80fd\u7684\u5408\u5e76\u5de5\u5177\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2507.19261", "categories": ["cs.AI", "cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2507.19261", "abs": "https://arxiv.org/abs/2507.19261", "authors": ["Osama Almurshed", "Ashish Kaushal", "Asmail Muftah", "Nitin Auluck", "Omer Rana"], "title": "Knowledge Grafting: A Mechanism for Optimizing AI Model Deployment in Resource-Constrained Environments", "comment": "18 pages, 4 figures, ArXiv preprint - Novel \"knowledge grafting\"\n  technique achieving 88.54% AI model size reduction while improving accuracy\n  for resource-constrained deployment", "summary": "The increasing adoption of Artificial Intelligence (AI) has led to larger,\nmore complex models with numerous parameters that require substantial computing\npower -- resources often unavailable in many real-world application scenarios.\nOur paper addresses this challenge by introducing knowledge grafting, a novel\nmechanism that optimizes AI models for resource-constrained environments by\ntransferring selected features (the scion) from a large donor model to a\nsmaller rootstock model. The approach achieves an 88.54% reduction in model\nsize (from 64.39 MB to 7.38 MB), while improving generalization capability of\nthe model. Our new rootstock model achieves 89.97% validation accuracy (vs.\ndonor's 87.47%), maintains lower validation loss (0.2976 vs. 0.5068), and\nperforms exceptionally well on unseen test data with 90.45% accuracy. It\naddresses the typical size vs performance trade-off, and enables deployment of\nAI frameworks on resource-constrained devices with enhanced performance. We\nhave tested our approach on an agricultural weed detection scenario, however,\nit can be extended across various edge computing scenarios, potentially\naccelerating AI adoption in areas with limited hardware/software support -- by\nmirroring in a similar manner the horticultural grafting enables productive\ncultivation in challenging agri-based environments.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u77e5\u8bc6\u5ac1\u63a5\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u5927\u578b\u6a21\u578b\u7684\u7279\u5f81\u79fb\u690d\u5230\u5c0f\u578b\u6a21\u578b\u4e2d\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u6a21\u578b\u5927\u5c0f\u5e76\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3AI\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u90e8\u7f72\u7684\u6311\u6218\uff0c\u907f\u514d\u4f20\u7edf\u6a21\u578b\u5927\u5c0f\u4e0e\u6027\u80fd\u7684\u6743\u8861\u95ee\u9898\u3002", "method": "\u91c7\u7528\u77e5\u8bc6\u5ac1\u63a5\u673a\u5236\uff0c\u5c06\u5927\u578b\u6a21\u578b\uff08\u4f9b\u4f53\uff09\u7684\u9009\u5b9a\u7279\u5f81\u79fb\u690d\u5230\u5c0f\u578b\u6a21\u578b\uff08\u7827\u6728\uff09\u4e2d\u3002", "result": "\u6a21\u578b\u5927\u5c0f\u51cf\u5c1188.54%\uff0c\u9a8c\u8bc1\u51c6\u786e\u7387\u63d0\u5347\u81f389.97%\uff0c\u6d4b\u8bd5\u51c6\u786e\u7387\u8fbe90.45%\u3002", "conclusion": "\u77e5\u8bc6\u5ac1\u63a5\u65b9\u6cd5\u6709\u6548\u4f18\u5316\u4e86\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684AI\u6a21\u578b\u90e8\u7f72\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.19446", "categories": ["cs.SE", "cs.DC", "B.8.2; C.2.4"], "pdf": "https://arxiv.org/pdf/2507.19446", "abs": "https://arxiv.org/abs/2507.19446", "authors": ["Matthias Wei\u00df", "Anish Navalgund", "Johannes St\u00fcmpfle", "Falk Dettinger", "Michael Weyrich"], "title": "An OpenSource CI/CD Pipeline for Variant-Rich Software-Defined Vehicles", "comment": "7 pages, 5 figures", "summary": "Software-defined vehicles (SDVs) offer a wide range of connected\nfunctionalities, including enhanced driving behavior and fleet management.\nThese features are continuously updated via over-the-air (OTA) mechanisms,\nresulting in a growing number of software versions and variants due to the\ndiversity of vehicles, cloud/edge environments, and stakeholders involved. The\nlack of a unified integration environment further complicates development, as\nconnected mobility solutions are often built in isolation. To ensure reliable\noperations across heterogeneous systems, a dynamic orchestration of functions\nthat considers hardware and software variability is essential. This paper\npresents an open-source CI/CD pipeline tailored for SDVs. It automates the\nbuild, test, and deployment phases using a combination of containerized\nopen-source tools, creating a standardized, portable, and scalable ecosystem\naccessible to all stakeholders. Additionally, a custom OTA middleware\ndistributes software updates and supports rollbacks across vehicles and backend\nservices. Update variants are derived based on deployment target dependencies\nand hardware configurations. The pipeline also supports continuous development\nand deployment of AI models for autonomous driving features. Its effectiveness\nis evaluated using an automated valet parking (AVP) scenario involving\nTurtleBots and a coordinating backend server. Two object detection variants are\ndeveloped and deployed to match hardware-specific requirements. Results\ndemonstrate seamless OTA updates, correct variant selection, and successful\norchestration across all targets. Overall, the proposed pipeline provides a\nscalable and efficient solution for managing software variants and OTA updates\nin SDVs, contributing to the advancement of future mobility technologies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u8f6f\u4ef6\u5b9a\u4e49\u8f66\u8f86\uff08SDV\uff09\u7684\u5f00\u6e90CI/CD\u6d41\u6c34\u7ebf\uff0c\u901a\u8fc7\u5bb9\u5668\u5316\u5de5\u5177\u5b9e\u73b0\u6807\u51c6\u5316\u3001\u53ef\u79fb\u690d\u548c\u53ef\u6269\u5c55\u7684\u751f\u6001\u7cfb\u7edf\uff0c\u652f\u6301OTA\u66f4\u65b0\u548cAI\u6a21\u578b\u90e8\u7f72\u3002", "motivation": "\u7531\u4e8eSDV\u7684\u8f6f\u4ef6\u7248\u672c\u548c\u53d8\u4f53\u6570\u91cf\u4e0d\u65ad\u589e\u52a0\uff0c\u4e14\u7f3a\u4e4f\u7edf\u4e00\u7684\u96c6\u6210\u73af\u5883\uff0c\u9700\u8981\u4e00\u79cd\u52a8\u6001\u7f16\u6392\u529f\u80fd\u7684\u65b9\u6cd5\u6765\u786e\u4fdd\u5f02\u6784\u7cfb\u7edf\u7684\u53ef\u9760\u8fd0\u884c\u3002", "method": "\u91c7\u7528\u5bb9\u5668\u5316\u5f00\u6e90\u5de5\u5177\u6784\u5efa\u81ea\u52a8\u5316CI/CD\u6d41\u6c34\u7ebf\uff0c\u5305\u62ec\u6784\u5efa\u3001\u6d4b\u8bd5\u548c\u90e8\u7f72\u9636\u6bb5\uff0c\u5e76\u5f00\u53d1\u5b9a\u5236OTA\u4e2d\u95f4\u4ef6\u4ee5\u652f\u6301\u8f6f\u4ef6\u66f4\u65b0\u548c\u56de\u6eda\u3002", "result": "\u5728\u81ea\u52a8\u4ee3\u5ba2\u6cca\u8f66\uff08AVP\uff09\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u6d41\u6c34\u7ebf\u7684\u6709\u6548\u6027\uff0c\u5b9e\u73b0\u4e86\u65e0\u7f1dOTA\u66f4\u65b0\u3001\u6b63\u786e\u53d8\u4f53\u9009\u62e9\u548c\u8de8\u76ee\u6807\u7f16\u6392\u3002", "conclusion": "\u8be5\u6d41\u6c34\u7ebf\u4e3aSDV\u7684\u8f6f\u4ef6\u53d8\u4f53\u548cOTA\u66f4\u65b0\u7ba1\u7406\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u52a8\u4e86\u672a\u6765\u79fb\u52a8\u6280\u672f\u7684\u53d1\u5c55\u3002"}}
{"id": "2507.19263", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.19263", "abs": "https://arxiv.org/abs/2507.19263", "authors": ["Achille Morenville", "\u00c9ric Piette"], "title": "Modeling Uncertainty: Constraint-Based Belief States in Imperfect-Information Games", "comment": null, "summary": "In imperfect-information games, agents must make decisions based on partial\nknowledge of the game state. The Belief Stochastic Game model addresses this\nchallenge by delegating state estimation to the game model itself. This allows\nagents to operate on externally provided belief states, thereby reducing the\nneed for game-specific inference logic. This paper investigates two approaches\nto represent beliefs in games with hidden piece identities: a constraint-based\nmodel using Constraint Satisfaction Problems and a probabilistic extension\nusing Belief Propagation to estimate marginal probabilities. We evaluated the\nimpact of both representations using general-purpose agents across two\ndifferent games. Our findings indicate that constraint-based beliefs yield\nresults comparable to those of probabilistic inference, with minimal\ndifferences in agent performance. This suggests that constraint-based belief\nstates alone may suffice for effective decision-making in many settings.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u9690\u85cf\u68cb\u5b50\u8eab\u4efd\u7684\u6e38\u620f\u4e2d\uff0c\u57fa\u4e8e\u7ea6\u675f\u7684\u4fe1\u5ff5\u6a21\u578b\u4e0e\u6982\u7387\u6269\u5c55\u6a21\u578b\u7684\u6027\u80fd\u5bf9\u6bd4\uff0c\u53d1\u73b0\u4e24\u8005\u6548\u679c\u76f8\u8fd1\u3002", "motivation": "\u89e3\u51b3\u4e0d\u5b8c\u5168\u4fe1\u606f\u6e38\u620f\u4e2d\u4ee3\u7406\u9700\u57fa\u4e8e\u90e8\u5206\u77e5\u8bc6\u51b3\u7b56\u7684\u6311\u6218\uff0c\u901a\u8fc7\u6e38\u620f\u6a21\u578b\u672c\u8eab\u5904\u7406\u72b6\u6001\u4f30\u8ba1\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u4fe1\u5ff5\u8868\u793a\u65b9\u6cd5\uff1a\u57fa\u4e8e\u7ea6\u675f\u7684\u6a21\u578b\uff08CSP\uff09\u548c\u6982\u7387\u6269\u5c55\u6a21\u578b\uff08Belief Propagation\uff09\uff0c\u5e76\u5728\u4e24\u79cd\u6e38\u620f\u4e2d\u8bc4\u4f30\u3002", "result": "\u7ea6\u675f\u57fa\u4fe1\u5ff5\u4e0e\u6982\u7387\u63a8\u7406\u6548\u679c\u76f8\u5f53\uff0c\u4ee3\u7406\u6027\u80fd\u5dee\u5f02\u5fae\u5c0f\u3002", "conclusion": "\u7ea6\u675f\u57fa\u4fe1\u5ff5\u5728\u8bb8\u591a\u573a\u666f\u4e0b\u8db3\u4ee5\u652f\u6301\u6709\u6548\u51b3\u7b56\u3002"}}
{"id": "2507.19364", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.19364", "abs": "https://arxiv.org/abs/2507.19364", "authors": ["Patrick Taillandier", "Jean Daniel Zucker", "Arnaud Grignard", "Benoit Gaudou", "Nghi Quang Huynh", "Alexis Drogoul"], "title": "Integrating LLM in Agent-Based Social Simulation: Opportunities and Challenges", "comment": null, "summary": "This position paper examines the use of Large Language Models (LLMs) in\nsocial simulation, analyzing both their potential and their limitations from a\ncomputational social science perspective. The first part reviews recent\nfindings on the ability of LLMs to replicate key aspects of human cognition,\nincluding Theory of Mind reasoning and social inference, while also\nhighlighting significant limitations such as cognitive biases, lack of true\nunderstanding, and inconsistencies in behavior. The second part surveys\nemerging applications of LLMs in multi-agent simulation frameworks, focusing on\nsystem architectures, scale, and validation strategies. Notable projects such\nas Generative Agents (Smallville) and AgentSociety are discussed in terms of\ntheir design choices, empirical grounding, and methodological innovations.\nParticular attention is given to the challenges of behavioral fidelity,\ncalibration, and reproducibility in large-scale LLM-driven simulations. The\nfinal section distinguishes between contexts where LLMs, like other black-box\nsystems, offer direct value-such as interactive simulations and serious\ngames-and those where their use is more problematic, notably in explanatory or\npredictive modeling. The paper concludes by advocating for hybrid approaches\nthat integrate LLMs into traditional agent-based modeling platforms (GAMA,\nNetlogo, etc), enabling modelers to combine the expressive flexibility of\nlanguage-based reasoning with the transparency and analytical rigor of\nclassical rule-based systems.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u793e\u4ea4\u6a21\u62df\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u4e0e\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u4e86\u7ed3\u5408\u4f20\u7edf\u5efa\u6a21\u5e73\u53f0\u7684\u6df7\u5408\u65b9\u6cd5\u3002", "motivation": "\u4ece\u8ba1\u7b97\u793e\u4f1a\u79d1\u5b66\u7684\u89d2\u5ea6\u5206\u6790LLMs\u5728\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u548c\u793e\u4f1a\u884c\u4e3a\u4e2d\u7684\u80fd\u529b\u4e0e\u4e0d\u8db3\uff0c\u63a8\u52a8\u66f4\u6709\u6548\u7684\u6a21\u62df\u5de5\u5177\u53d1\u5c55\u3002", "method": "\u5206\u4e3a\u4e09\u90e8\u5206\uff1a1\uff09\u8bc4\u4f30LLMs\u5728\u4eba\u7c7b\u8ba4\u77e5\u6a21\u62df\u4e2d\u7684\u8868\u73b0\uff1b2\uff09\u8c03\u67e5LLMs\u5728\u591a\u667a\u80fd\u4f53\u6a21\u62df\u4e2d\u7684\u5e94\u7528\uff1b3\uff09\u63d0\u51fa\u6df7\u5408\u5efa\u6a21\u65b9\u6cd5\u3002", "result": "LLMs\u5728\u4ea4\u4e92\u5f0f\u6a21\u62df\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u89e3\u91ca\u6027\u6216\u9884\u6d4b\u6027\u5efa\u6a21\u4e2d\u5b58\u5728\u5c40\u9650\u6027\u3002\u6df7\u5408\u65b9\u6cd5\u80fd\u7ed3\u5408\u7075\u6d3b\u6027\u4e0e\u900f\u660e\u5ea6\u3002", "conclusion": "\u5efa\u8bae\u5c06LLMs\u4e0e\u4f20\u7edf\u5efa\u6a21\u5e73\u53f0\u7ed3\u5408\uff0c\u4ee5\u5e73\u8861\u8bed\u8a00\u63a8\u7406\u7684\u8868\u8fbe\u529b\u4e0e\u89c4\u5219\u7cfb\u7edf\u7684\u4e25\u8c28\u6027\u3002"}}
{"id": "2507.19372", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.19372", "abs": "https://arxiv.org/abs/2507.19372", "authors": ["Flavio Petruzzellis", "Alberto Testolin", "Alessandro Sperduti"], "title": "Learning neuro-symbolic convergent term rewriting systems", "comment": "48 pages, 31 figures. Submitted for review by Artificial Intelligence\n  Journal", "summary": "Building neural systems that can learn to execute symbolic algorithms is a\nchallenging open problem in artificial intelligence, especially when aiming for\nstrong generalization and out-of-distribution performance. In this work, we\nintroduce a general framework for learning convergent term rewriting systems\nusing a neuro-symbolic architecture inspired by the rewriting algorithm itself.\nWe present two modular implementations of such architecture: the Neural\nRewriting System (NRS) and the Fast Neural Rewriting System (FastNRS). As a\nresult of algorithmic-inspired design and key architectural elements, both\nmodels can generalize to out-of-distribution instances, with FastNRS offering\nsignificant improvements in terms of memory efficiency, training speed, and\ninference time. We evaluate both architectures on four tasks involving the\nsimplification of mathematical formulas and further demonstrate their\nversatility in a multi-domain learning scenario, where a single model is\ntrained to solve multiple types of problems simultaneously. The proposed system\nsignificantly outperforms two strong neural baselines: the Neural Data Router,\na recent transformer variant specifically designed to solve algorithmic\nproblems, and GPT-4o, one of the most powerful general-purpose large-language\nmodels. Moreover, our system matches or outperforms the latest o1-preview model\nfrom OpenAI that excels in reasoning benchmarks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecf\u7b26\u53f7\u67b6\u6784\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5b66\u4e60\u6536\u655b\u7684\u9879\u91cd\u5199\u7cfb\u7edf\uff0c\u5e76\u5c55\u793a\u4e86\u4e24\u79cd\u6a21\u5757\u5316\u5b9e\u73b0\uff08NRS\u548cFastNRS\uff09\uff0c\u5728\u6cdb\u5316\u548c\u591a\u4efb\u52a1\u5b66\u4e60\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u7b26\u53f7\u7b97\u6cd5\u6267\u884c\u7684\u6cdb\u5316\u548c\u5206\u5e03\u5916\u6027\u80fd\u95ee\u9898\u3002", "method": "\u91c7\u7528\u795e\u7ecf\u7b26\u53f7\u67b6\u6784\uff0c\u8bbe\u8ba1NRS\u548cFastNRS\u4e24\u79cd\u6a21\u578b\uff0c\u7ed3\u5408\u7b97\u6cd5\u542f\u53d1\u5f0f\u8bbe\u8ba1\u548c\u5173\u952e\u67b6\u6784\u5143\u7d20\u3002", "result": "\u6a21\u578b\u5728\u6570\u5b66\u516c\u5f0f\u7b80\u5316\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0cFastNRS\u5728\u5185\u5b58\u6548\u7387\u3001\u8bad\u7ec3\u901f\u5ea6\u548c\u63a8\u7406\u65f6\u95f4\u4e0a\u6709\u663e\u8457\u63d0\u5347\uff0c\u4e14\u5728\u591a\u4efb\u52a1\u5b66\u4e60\u4e2d\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u63d0\u51fa\u7684\u7cfb\u7edf\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u6a21\u578b\uff0c\u5305\u62ec\u4e13\u7528\u7b97\u6cd5\u6a21\u578b\u548c\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u3002"}}
{"id": "2507.19458", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.19458", "abs": "https://arxiv.org/abs/2507.19458", "authors": ["Amir Fard", "Arnold X. -X. Yuan"], "title": "Hierarchical Deep Reinforcement Learning Framework for Multi-Year Asset Management Under Budget Constraints", "comment": null, "summary": "Budget planning and maintenance optimization are crucial for infrastructure\nasset management, ensuring cost-effectiveness and sustainability. However, the\ncomplexity arising from combinatorial action spaces, diverse asset\ndeterioration, stringent budget constraints, and environmental uncertainty\nsignificantly limits existing methods' scalability. This paper proposes a\nHierarchical Deep Reinforcement Learning methodology specifically tailored to\nmulti-year infrastructure planning. Our approach decomposes the problem into\ntwo hierarchical levels: a high-level Budget Planner allocating annual budgets\nwithin explicit feasibility bounds, and a low-level Maintenance Planner\nprioritizing assets within the allocated budget. By structurally separating\nmacro-budget decisions from asset-level prioritization and integrating linear\nprogramming projection within a hierarchical Soft Actor-Critic framework, the\nmethod efficiently addresses exponential growth in the action space and ensures\nrigorous budget compliance. A case study evaluating sewer networks of varying\nsizes (10, 15, and 20 sewersheds) illustrates the effectiveness of the proposed\napproach. Compared to conventional Deep Q-Learning and enhanced genetic\nalgorithms, our methodology converges more rapidly, scales effectively, and\nconsistently delivers near-optimal solutions even as network size grows.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u591a\u5e74\u5ea6\u57fa\u7840\u8bbe\u65bd\u89c4\u5212\uff0c\u901a\u8fc7\u5206\u89e3\u9884\u7b97\u548c\u7ef4\u62a4\u51b3\u7b56\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002", "motivation": "\u57fa\u7840\u8bbe\u65bd\u8d44\u4ea7\u7ba1\u7406\u4e2d\u7684\u9884\u7b97\u89c4\u5212\u4e0e\u7ef4\u62a4\u4f18\u5316\u9762\u4e34\u7ec4\u5408\u52a8\u4f5c\u7a7a\u95f4\u3001\u8d44\u4ea7\u9000\u5316\u591a\u6837\u6027\u3001\u4e25\u683c\u9884\u7b97\u7ea6\u675f\u548c\u73af\u5883\u4e0d\u786e\u5b9a\u6027\u7b49\u590d\u6742\u6027\uff0c\u9650\u5236\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u53ef\u6269\u5c55\u6027\u3002", "method": "\u91c7\u7528\u5206\u5c42\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5206\u4e3a\u9ad8\u5c42\u9884\u7b97\u89c4\u5212\u5668\u548c\u4f4e\u5c42\u7ef4\u62a4\u89c4\u5212\u5668\uff0c\u7ed3\u5408\u7ebf\u6027\u89c4\u5212\u6295\u5f71\u548c\u5206\u5c42Soft Actor-Critic\u6846\u67b6\uff0c\u786e\u4fdd\u9884\u7b97\u5408\u89c4\u6027\u3002", "result": "\u572810\u300115\u548c20\u4e2a\u6c61\u6c34\u7ba1\u7f51\u89c4\u6a21\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u8be5\u65b9\u6cd5\u6bd4\u4f20\u7edf\u6df1\u5ea6Q\u5b66\u4e60\u548c\u9057\u4f20\u7b97\u6cd5\u6536\u655b\u66f4\u5feb\u3001\u6269\u5c55\u6027\u66f4\u597d\uff0c\u4e14\u80fd\u63d0\u4f9b\u63a5\u8fd1\u6700\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u63d0\u51fa\u7684\u5206\u5c42\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u57fa\u7840\u8bbe\u65bd\u89c4\u5212\u4e2d\u7684\u590d\u6742\u6027\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u4e3a\u591a\u5e74\u5ea6\u9884\u7b97\u548c\u7ef4\u62a4\u4f18\u5316\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
