<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 12]
- [cs.CR](#cs.CR) [Total: 16]
- [cs.AI](#cs.AI) [Total: 39]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Towards the Datasets Used in Requirements Engineering of Mobile Apps: Preliminary Findings from a Systematic Mapping Study](https://arxiv.org/abs/2509.03541)
*Chong Wang,Haoning Wu,Peng Liang,Maya Daneva,Marten van Sinderen*

Main category: cs.SE

TL;DR: 这篇论文通过系统映射研究分析了移动应用需求工程研究中使用的数据集来源和需求活动分布，发现Google Play和Apple App Store占据了超过90%的研究数据源，建议扩展多样化数据源以获得更具普遍性的研究结果。


<details>
  <summary>Details</summary>
Motivation: 调查移动应用需求工程研究中使用的数据集来源平台和需求活动分布状况，以了解当前研究状态和偏差。

Method: 采用Kitchenham等人的指南进行系统映射研究，基于43篇选定的论文进行分析。

Result: 发现Google Play和Apple App Store提供了超过90%的移动应用RE研究数据集；最常研究的需求活动是需求获取和需求分析。

Conclusion: 移动应用RE研究使用数据集从2012年以来增长；过度依赖Google Play和Apple App Store可能导致知识偏差；需要扩展其他数据源和多源数据组合使用，以获得更具普遍性的结果。

Abstract: [Background] Research on requirements engineering (RE) for mobile apps
employs datasets formed by app users, developers or vendors. However, little is
known about the sources of these datasets in terms of platforms and the RE
activities that were researched with the help of the respective datasets.
[Aims] The goal of this paper is to investigate the state-of-the-art of the
datasets of mobile apps used in existing RE research. [Method] We carried out a
systematic mapping study by following the guidelines of Kitchenham et al.
[Results] Based on 43 selected papers, we found that Google Play and Apple App
Store provide the datasets for more than 90% of published research in RE for
mobile apps. We also found that the most investigated RE activities - based on
datasets, are requirements elicitation and requirements analysis. [Conclusions]
Our most important conclusions are: (1) there is a growth in the use of
datasets for RE research of mobile apps since 2012, (2) the RE knowledge for
mobile apps might be skewed due to the overuse of Google Play and Apple App
Store, (3) there are attempts to supplement reviews of apps from repositories
with other data sources, (4) there is a need to expand the alternative sources
and experiments with complimentary use of multiple sources, if the community
wants more generalizable results. Plus, it is expected to expand the research
on other RE activities, beyond elicitation and analysis.

</details>


### [2] [A Multi-stage Error Diagnosis for APB Transaction](https://arxiv.org/abs/2509.03554)
*Cheng-Yang Tsai,Tzu-Wei Huang,Jen-Wei Shih,I-Hsiang Wang,Yu-Cheng Lin,Rung-Bin Lin*

Main category: cs.SE

TL;DR: 基于层次随机森林的自动化APB交易错误诊断框架，在ICCAD 2025竞赛中获得了高精度和竞争力表现


<details>
  <summary>Details</summary>
Motivation: 解决手动检测APB交易错误在大规模VCD文件中效率低下、易出错的问题，提高硬件调试的自动化水平

Method: 使用层次随机森林架构，通过4个预训练的二元分类器顺序检测超出范围访问、地址污染和数据污染错误，优先处理地址相关故障

Result: 整体准确率达到91.36%，地址错误的精度和召回率近优，数据错误表现稳健，在ICCAD 2025竞赛测试阶段获得第一名

Conclusion: 层次机器学习方法在EDA硬件调试中具有强大潜力，是一种高效的自动化错误诊断工具

Abstract: Functional verification and debugging are critical bottlenecks in modern
System-on-Chip (SoC) design, with manual detection of Advanced Peripheral Bus
(APB) transaction errors in large Value Change Dump (VCD) files being
inefficient and error-prone. Addressing the 2025 ICCAD Contest Problem D, this
study proposes an automated error diagnosis framework using a hierarchical
Random Forest-based architecture. The multi-stage error diagnosis employs four
pre-trained binary classifiers to sequentially detect Out-of-Range Access,
Address Corruption, and Data Corruption errors, prioritizing high-certainty
address-related faults before tackling complex data errors to enhance
efficiency. Experimental results show an overall accuracy of 91.36%, with
near-perfect precision and recall for address errors and robust performance for
data errors. Although the final results of the ICCAD 2025 CAD Contest are yet
to be announced as of the submission date, our team achieved first place in the
beta stage, highlighting the method's competitive strength. This research
validates the potential of hierarchical machine learning as a powerful
automated tool for hardware debugging in Electronic Design Automation (EDA).

</details>


### [3] [Parse Tree Tracking Through Time for Programming Process Analysis at Scale](https://arxiv.org/abs/2509.03668)
*Matt Rau,Chris Brown,John Edwards*

Main category: cs.SE

TL;DR: 本文提出了一种算法来自动追踪编程过程中抽象语法树节点随时间的变化，解决了之前无法自动跟踪不可解析代码状态的问题，并利用该算法对CS1课程学生的编程行为进行了大规模分析。


<details>
  <summary>Details</summary>
Motivation: 现有的编程过程数据分析主要依赖高级描述性统计，无法自动跟踪代码的高层表示（如抽象语法树）在时间和不可解析状态下的变化，限制了在上下文中分析学生编程行为的能力。

Method: 使用本文提出的两种算法来追踪解析树节点随时间的变化，并为不可解析的代码状态构建树表示，将这些算法应用于2021年CS1课程学生的公开击键数据，并对生成的解析树进行分析。

Result: 发现了新的可观察统计规律：条件语句和循环内外的代码删除率相似，三分之一的注释代码最终会被恢复，学生在代码中跳转的频率可能并不表示困难。

Conclusion: 能够随时间追踪解析树的能力为理解学生编程的新维度打开了大门，包括代码结构随时间发展的最佳实践、学生最困难的语法结构的定量测量、重构行为以及代码内注意力转移等。

Abstract: Background and Context: Programming process data can be utilized to
understand the processes students use to write computer programming
assignments. Keystroke- and line-level event logs have been used in the past in
various ways, primarily in high-level descriptive statistics (e.g., timings,
character deletion rate, etc). Analysis of behavior in context (e.g., how much
time students spend working on loops) has been cumbersome because of our
inability to automatically track high-level code representations, such as
abstract syntax trees, through time and unparseable states.
  Objective: Our study has two goals. The first is to design the first
algorithm that tracks parse tree nodes through time. Second, we utilize this
algorithm to perform a partial replication study of prior work that used manual
tracking of code representations, as well as other novel analyses of student
programming behavior that can now be done at scale.
  Method: We use two algorithms presented in this paper to track parse tree
nodes through time and construct tree representations for unparseable code
states. We apply these algorithms to a public keystroke data from student
coursework in a 2021 CS1 course and conduct analysis on the resulting parse
trees.
  Findings: We discover newly observable statistics at scale, including that
code is deleted at similar rates inside and outside of conditionals and loops,
a third of commented out code is eventually restored, and that frequency with
which students jump around in their code may not be indicative of struggle.
  Implications: The ability to track parse trees through time opens the door to
understanding new dimensions of student programming, such as best practices of
structural development of code over time, quantitative measurement of what
syntactic constructs students struggle most with, refactoring behavior, and
attention shifting within the code.

</details>


### [4] [Towards an Understanding of Developer Experience-Driven Transparency in Software Ecosystems](https://arxiv.org/abs/2509.03848)
*Rodrigo Oliveira Zacarias,Rodrigo Pereira dos Santos,Patricia Lago*

Main category: cs.SE

TL;DR: 这篇论文提出了SECO-TransDX概念模型，从开发者体验角度系统化地概念化了软件生态系统中的透明性问题，识别了63个相互关联的概念并通过Delphi研究进行了精炼。


<details>
  <summary>Details</summary>
Motivation: 虽然透明性被认为对信任、公平性和参与度至关重要，但开发者体验角度下的透明性研究仍然缺乏系统化概念化。论文意在提升开发者中心视角下软件生态系统透明性的理解。

Method: 基于先前研究构建SECO-TransDX概念模型，通过Delphi研究方法使用学术界和业界专家的输入对模型进行精炼。模型识别了63个相互关联的概念，包括条件因素、生态系统程序、产出物和关系动态。

Result: 提出了SECO-TransDX概念模型，引入了DX驱动透明性的概念。该模型为研空间提供了结构化视角，用于检查透明性如何在技术、社会和组织层面中介导开发者体验。

Conclusion: SECO-TransDX模型为研空间的未来研究和工具开发奠定了基础，同时为实践者设计可信赖、以开发者为中心的平台提供支持，以改善透明性并促进软件生态系统中的长期参与。

Abstract: Software ecosystems (SECO) have become a dominant paradigm in the software
industry, enabling third-party developers to co-create value through
complementary components and services. While Developer Experience (DX) is
increasingly recognized as critical for sustainable SECO, transparency remains
an underexplored factor shaping how developers perceive and interact with
ecosystems. Existing studies acknowledge transparency as essential for trust,
fairness, and engagement, yet its relationship with DX has not been
systematically conceptualized. Hence, this work aims to advance the
understanding of transparency in SECO from a developer-centered perspective. To
this end, we propose SECO-TransDX (Transparency in Software Ecosystems from a
Developer Experience Perspective), a conceptual model that introduces the
notion of DX-driven transparency. The model identifies 63 interrelated
concepts, including conditioning factors, ecosystem procedures, artifacts, and
relational dynamics that influence how transparency is perceived and
constructed during developer interactions. SECO-TransDX was built upon prior
research and refined through a Delphi study with experts from academia and
industry. It offers a structured lens to examine how transparency mediates DX
across technical, social, and organizational layers. For researchers, it lays
the groundwork for future studies and tool development; for practitioners, it
supports the design of trustworthy, developer-centered platforms that improve
transparency and foster long-term engagement in SECO.

</details>


### [5] [VulRTex: A Reasoning-Guided Approach to Identify Vulnerabilities from Rich-Text Issue Report](https://arxiv.org/abs/2509.03875)
*Ziyou Jiang,Mingyang Li,Guowei Yang,Lin Shi,Qing Wang*

Main category: cs.SE

TL;DR: VulRTex是一个基于大语言模型推理能力的漏洞相关issue报告识别方法，通过构建漏洞推理数据库和检索相关案例来指导LLM分析目标IR的富文本信息，在数据不平衡情况下表现优异。


<details>
  <summary>Details</summary>
Motivation: 开源软件中存在漏洞，开发者提交的issue报告需要安全从业者手动识别漏洞相关报告，耗时且存在时间差被攻击者利用的风险。现有方法主要关注文本描述，缺乏对IR富文本信息的综合分析。

Method: VulRTex首先利用LLM的推理能力构建漏洞推理数据库，然后检索相关案例生成推理指导，引导LLM通过推理分析目标IR的富文本信息来识别漏洞。

Result: 在973,572个IRs上的实验显示，VulRTex在数据不平衡情况下表现最佳，比最佳基线F1提高11.0%，AUPRC提高20.2%，Macro-F1提高10.5%，时间成本降低2倍。成功识别2024年GitHub IRs中10个代表性OSS项目的30个新兴漏洞，其中11个获得CVE-ID分配。

Conclusion: VulRTex通过利用LLM的推理能力和富文本信息分析，有效识别漏洞相关IRs，具有实际应用价值，能够帮助安全从业者更高效地发现和应对软件漏洞。

Abstract: Software vulnerabilities exist in open-source software (OSS), and the
developers who discover these vulnerabilities may submit issue reports (IRs) to
describe their details. Security practitioners need to spend a lot of time
manually identifying vulnerability-related IRs from the community, and the time
gap may be exploited by attackers to harm the system. Previously, researchers
have proposed automatic approaches to facilitate identifying these
vulnerability-related IRs, but these works focus on textual descriptions but
lack the comprehensive analysis of IR's rich-text information. In this paper,
we propose VulRTex, a reasoning-guided approach to identify
vulnerability-related IRs with their rich-text information. In particular,
VulRTex first utilizes the reasoning ability of the Large Language Model (LLM)
to prepare the Vulnerability Reasoning Database with historical IRs. Then, it
retrieves the relevant cases from the prepared reasoning database to generate
reasoning guidance, which guides LLM to identify vulnerabilities by reasoning
analysis on target IRs' rich-text information. To evaluate the performance of
VulRTex, we conduct experiments on 973,572 IRs, and the results show that
VulRTex achieves the highest performance in identifying the
vulnerability-related IRs and predicting CWE-IDs when the dataset is
imbalanced, outperforming the best baseline with +11.0% F1, +20.2% AUPRC, and
+10.5% Macro-F1, and 2x lower time cost than baseline reasoning approaches.
Furthermore, VulRTex has been applied to identify 30 emerging vulnerabilities
across 10 representative OSS projects in 2024's GitHub IRs, and 11 of them are
successfully assigned CVE-IDs, which illustrates VulRTex's practicality.

</details>


### [6] [Vulnerability-Affected Versions Identification: How Far Are We?](https://arxiv.org/abs/2509.03876)
*Xingchu Chen,Chengwei Liu,Jialun Cao,Yang Xiao,Xinyue Cai,Yeting Li,Jingyi Shi,Tianqi Sun,Haiming Chen ang Wei Huo*

Main category: cs.SE

TL;DR: 对12种漏洞影响版本识别工具的综合实证研究表明，现有工具准确率不超过45%，集成策略最多提升10.1%但仍低于60%，揭示了启发式依赖、语义推理有限和刚性匹配逻辑等根本局限。


<details>
  <summary>Details</summary>
Motivation: 漏洞影响版本识别对补丁和风险缓解至关重要，但现有工具在真实环境中的有效性尚不清楚，因为评估范围狭窄、技术过时且数据集小或粗粒度。

Method: 构建包含1,128个真实C/C++漏洞的高质量基准，系统评估12种代表性工具（追踪和匹配范式），从漏洞和版本级别有效性、误报误诊根因、补丁特性敏感性和集成潜力四个维度分析。

Result: 所有工具准确率不超过45.0%，补丁结构（如纯添加和跨文件变更）进一步降低性能。集成策略最多提升10.1%准确率，但总体仍低于60.0%。

Conclusion: 现有方法存在根本性局限，需要全新方法。研究为工具开发、组合策略和未来研究提供了可行见解，并发布了复现代码和基准以鼓励后续贡献。

Abstract: Identifying which software versions are affected by a vulnerability is
critical for patching, risk mitigation.Despite a growing body of tools, their
real-world effectiveness remains unclear due to narrow evaluation scopes often
limited to early SZZ variants, outdated techniques, and small or
coarse-graineddatasets. In this paper, we present the first comprehensive
empirical study of vulnerability affected versions identification. We curate a
high quality benchmark of 1,128 real-world C/C++ vulnerabilities and
systematically evaluate 12 representative tools from both tracing and matching
paradigms across four dimensions: effectiveness at both vulnerability and
version levels, root causes of false positives and negatives, sensitivity to
patch characteristics, and ensemble potential. Our findings reveal fundamental
limitations: no tool exceeds 45.0% accuracy, with key challenges stemming from
heuristic dependence, limited semantic reasoning, and rigid matching logic.
Patch structures such as add-only and cross-file changes further hinder
performance. Although ensemble strategies can improve results by up to 10.1%,
overall accuracy remains below 60.0%, highlighting the need for fundamentally
new approaches. Moreover, our study offers actionable insights to guide tool
development, combination strategies, and future research in this critical area.
Finally, we release the replicated code and benchmark on our website to
encourage future contributions.outdated techniques, and small or coarse grained
datasets.

</details>


### [7] [Analyzing Variations in Dependency Distributions Due to Code Smell Interactions](https://arxiv.org/abs/2509.03896)
*Zushuai Zhang,Elliott Wen,Ewan Tempero*

Main category: cs.SE

TL;DR: 代码异味之间的相互作用会显著增加模块间的依赖关系，导致维护复杂性和成本增加，应优先处理相互作用的代码异味。


<details>
  <summary>Details</summary>
Motivation: 代码异味可能通过相互作用增加模块间依赖关系，使维护变得更加复杂和粗糕，需要证实这种现象并量化其影响。

Method: 对116个开源Java系统进行依赖分析，比较代码异味之间的相互作用与代码异味和非代码异味之间相互作用的差异。

Result: 代码异味对之间的相互作用会导致总依赖关系的增加，例如Feature Envy方法与Data Class的相互作用使依赖关系数从1增加到7，增长7倍。

Conclusion: 开发者应优先处理相互作用的代码异味，而非单独存在的代码异味，以减少模块间依赖关系的复杂性。

Abstract: The existence of dependencies between modules, such as classes, can mean that
changing a module triggers ripple effects that make maintenance complex and
costly, so the advice is to minimize dependencies between modules. It is
therefore important to understand the circumstances that can lead to increased
dependencies. Recent studies suggest that code smells, which are
characteristics of code that indicate potential design issues, may interact in
ways that increase dependencies between modules. In this study, we aim to
confirm previous observations and investigate whether and how the distribution
of static dependencies changes in the presence of code smell interactions. We
conducted a dependency analysis on 116 open-source Java systems to quantify the
interactions, comparing interactions among code smells and interactions between
code smells and non-code smells. Our results suggest that while interactions
between code smell pairs are associated with increases in certain dependencies
and decreases in others, overall, they are associated with an increase in total
dependencies. For example, the median number of dependencies between Feature
Envy methods and Data Classes is seven times as many as when the methods are
non-Feature Envy methods, increasing from 1 to 7. This implies that developers
should prioritize addressing code smells that interact with each other, rather
than code smells that exist only in isolation.

</details>


### [8] [The Auth Shim: A Lightweight Architectural Pattern for Integrating Enterprise SSO with Standalone Open-Source Applications](https://arxiv.org/abs/2509.03900)
*Yuvraj Agrawal*

Main category: cs.SE

TL;DR: 本文提出了Auth Shim架构模式，通过外部代理服务解决开源软件缺乏企业级身份认证协议支持的问题，实现与身份提供商的集成。


<details>
  <summary>Details</summary>
Motivation: 企业广泛采用开源软件，但这些工具往往缺乏对SAML、OIDC等企业级身份认证协议的原生支持，导致安全集成缺口。

Method: Auth Shim是一种轻量级外部代理服务，作为兼容层将企业身份提供商的请求转换为目标应用的原生会话管理机制。目标应用需要提供安全的程序化管理API。

Result: 在Adobe的案例研究中成功实现了开源BI工具与Okta SAML的集成，支持基于IAM组映射的自动化RBAC，消除了手动用户配置。

Conclusion: Auth Shim模式为企业提供了可重用、安全且成本效益高的蓝图，使组织能够在保持安全治理的同时采用开源创新。

Abstract: Open-source software OSS is widely adopted in enterprise settings, but
standalone tools often lack native support for protocols like SAML or OIDC,
creating a critical security integration gap. This paper introduces and
formalizes the Auth Shim, a lightweight architectural pattern designed to solve
this problem. The Auth Shim is a minimal, external proxy service that acts as a
compatibility layer, translating requests from an enterprise Identity Provider
IdP into the native session management mechanism of a target application. A key
prerequisite for this pattern is that the target application must expose a
programmatic, secure administrative API. We present a case study of the
pattern's implementation at Adobe to integrate a popular OSS BI tool with Okta
SAML, which enabled automated Role-Based Access Control RBAC via IAM group
mapping and eliminated manual user provisioning. By defining its components,
interactions, and production deployment considerations, this paper provides a
reusable, secure, and cost-effective blueprint for integrating any standalone
OSS tool into an enterprise SSO ecosystem, thereby enabling organizations to
embrace open-source innovation without compromising on security governance.

</details>


### [9] [RepoDebug: Repository-Level Multi-Task and Multi-Language Debugging Evaluation of Large Language Models](https://arxiv.org/abs/2509.04078)
*Jingjing Liu,Zeming Liu,Zihao Cheng,Mengliang He,Xiaoming Shi,Yuhang Guo,Xiangrong Zhu,Yuanfang Guo,Yunhong Wang,Haifeng Wang*

Main category: cs.SE

TL;DR: RepoDebug是一个多任务、多语言的仓库级代码调试数据集，包含22种错误子类型、8种编程语言和3种调试任务，用于评估LLMs在复杂仓库级调试场景中的能力。


<details>
  <summary>Details</summary>
Motivation: 现有调试数据集主要关注函数级代码修复，忽略了更复杂和现实的仓库级场景，导致对LLMs在仓库级调试中面临的挑战理解不完整。

Method: 构建RepoDebug数据集，包含22种错误子类型、支持8种常用编程语言和3种调试任务，并在10个LLMs上进行评估实验。

Result: Claude 3.5 Sonnet表现最佳，但在仓库级调试中仍表现不佳，表明当前LLMs在复杂仓库级调试场景中面临显著挑战。

Conclusion: RepoDebug数据集填补了仓库级代码调试评估的空白，揭示了LLMs在复杂现实场景中的局限性，为未来研究提供了重要基准。

Abstract: Large Language Models (LLMs) have exhibited significant proficiency in code
debugging, especially in automatic program repair, which may substantially
reduce the time consumption of developers and enhance their efficiency.
Significant advancements in debugging datasets have been made to promote the
development of code debugging. However, these datasets primarily focus on
assessing the LLM's function-level code repair capabilities, neglecting the
more complex and realistic repository-level scenarios, which leads to an
incomplete understanding of the LLM's challenges in repository-level debugging.
While several repository-level datasets have been proposed, they often suffer
from limitations such as limited diversity of tasks, languages, and error
types. To mitigate this challenge, this paper introduces RepoDebug, a
multi-task and multi-language repository-level code debugging dataset with 22
subtypes of errors that supports 8 commonly used programming languages and 3
debugging tasks. Furthermore, we conduct evaluation experiments on 10 LLMs,
where Claude 3.5 Sonnect, the best-performing model, still cannot perform well
in repository-level debugging.

</details>


### [10] [An Empirical Study of Vulnerabilities in Python Packages and Their Detection](https://arxiv.org/abs/2509.04260)
*Haowei Quan,Junjie Wang,Xinzhe Li,Terry Yue Zhuo,Xiao Chen,Xiaoning Du*

Main category: cs.SE

TL;DR: PyVul是首个全面的Python包漏洞基准测试套件，包含1,157个公开报告的漏洞，支持多种检测技术，评估显示现有工具在检测真实Python包安全漏洞方面存在显著差距。


<details>
  <summary>Details</summary>
Motivation: Python包作为组织、重用和分发单元存在大量漏洞报告，且Python常与其他语言协作增加了漏洞复杂性，当前漏洞检测工具的有效性尚未充分研究。

Method: 开发PyVul基准套件，包含开发者验证的漏洞，提供提交和函数级注释，采用LLM辅助数据清洗方法提高标签准确性。

Result: PyVul达到100%提交级和94%函数级准确性，是多语言Python包漏洞的最精确大规模基准；分析显示多语言Python包更容易受漏洞影响；现有检测工具能力与实际需求存在显著差距。

Conclusion: PyVul为Python包漏洞检测提供了高质量基准，揭示了当前工具的局限性，强调了该领域未来发展的必要性。

Abstract: In the rapidly evolving software development landscape, Python stands out for
its simplicity, versatility, and extensive ecosystem. Python packages, as units
of organization, reusability, and distribution, have become a pressing concern,
highlighted by the considerable number of vulnerability reports. As a scripting
language, Python often cooperates with other languages for performance or
interoperability. This adds complexity to the vulnerabilities inherent to
Python packages, and the effectiveness of current vulnerability detection tools
remains underexplored. This paper addresses these gaps by introducing PyVul,
the first comprehensive benchmark suite of Python-package vulnerabilities.
PyVul includes 1,157 publicly reported, developer-verified vulnerabilities,
each linked to its affected packages. To accommodate diverse detection
techniques, it provides annotations at both commit and function levels. An
LLM-assisted data cleansing method is incorporated to improve label accuracy,
achieving 100% commit-level and 94% function-level accuracy, establishing PyVul
as the most precise large-scale Python vulnerability benchmark. We further
carry out a distribution analysis of PyVul, which demonstrates that
vulnerabilities in Python packages involve multiple programming languages and
exhibit a wide variety of types. Moreover, our analysis reveals that
multi-lingual Python packages are potentially more susceptible to
vulnerabilities. Evaluation of state-of-the-art detectors using this benchmark
reveals a significant discrepancy between the capabilities of existing tools
and the demands of effectively identifying real-world security issues in Python
packages. Additionally, we conduct an empirical review of the top-ranked CWEs
observed in Python packages, to diagnose the fine-grained limitations of
current detection tools and highlight the necessity for future advancements in
the field.

</details>


### [11] [FaaSGuard: Secure CI/CD for Serverless Applications -- An OpenFaaS Case Study](https://arxiv.org/abs/2509.04328)
*Amine Barrak,Emna Ksontini,Ridouane Atike,Fehmi Jaafar*

Main category: cs.SE

TL;DR: FaaSGuard是一个为开源无服务器环境设计的统一DevSecOps管道，通过在整个开发生命周期中嵌入轻量级安全检查，有效检测和防止关键漏洞，准确率达95%，召回率达91%。


<details>
  <summary>Details</summary>
Motivation: 无服务器计算虽然简化了基础设施管理，但其短暂执行和细粒度扩展等特性带来了独特的安全挑战，特别是在OpenFaaS等开源平台中。现有方法通常只处理DevSecOps生命周期的孤立阶段，缺乏集成的全面安全策略。

Method: 提出FaaSGuard统一DevSecOps管道，在开发生命周期的每个阶段（规划、编码、构建、部署和监控）系统性地嵌入轻量级、故障关闭的安全检查，有效应对注入攻击、硬编码密钥和资源耗尽等威胁。

Result: 通过对来自GitHub公共仓库的20个真实无服务器函数进行案例研究验证，FaaSGuard能够有效检测和防止关键漏洞，表现出高精度（95%）和高召回率（91%），且不会显著干扰现有的CI/CD实践。

Conclusion: FaaSGuard为开源无服务器环境提供了一个有效的集成安全解决方案，通过在整个DevSecOps生命周期中嵌入安全检查，成功解决了无服务器计算特有的安全挑战，同时保持了开发效率。

Abstract: Serverless computing significantly alters software development by abstracting
infrastructure management and enabling rapid, modular, event-driven
deployments. Despite its benefits, the distinct characteristics of serverless
functions, such as ephemeral execution and fine-grained scalability, pose
unique security challenges, particularly in open-source platforms like
OpenFaaS. Existing approaches typically address isolated phases of the
DevSecOps lifecycle, lacking an integrated and comprehensive security strategy.
To bridge this gap, we propose FaaSGuard, a unified DevSecOps pipeline
explicitly designed for open-source serverless environments. FaaSGuard
systematically embeds lightweight, fail-closed security checks into every stage
of the development lifecycle-planning, coding, building, deployment, and
monitoring-effectively addressing threats such as injection attacks, hard-coded
secrets, and resource exhaustion. We validate our approach empirically through
a case study involving 20 real-world serverless functions from public GitHub
repositories. Results indicate that FaaSGuard effectively detects and prevents
critical vulnerabilities, demonstrating high precision (95%) and recall (91%)
without significant disruption to established CI/CD practices.

</details>


### [12] [Design and Development of a Web Platform for Blood Donation Management](https://arxiv.org/abs/2509.04423)
*Fatima Zulfiqar Ali,Atrooba Ilyas*

Main category: cs.SE

TL;DR: 开发了一个基于网络的献血平台，使用PHP(Laravel)、HTML、CSS、Bootstrap和MySQL技术，通过集中式数字空间连接患者、献血者和管理员，提高紧急情况下血液获取效率。


<details>
  <summary>Details</summary>
Motivation: 解决紧急情况下寻找合适献血者的挑战，减少血液获取的延迟和复杂性，提高献血服务的整体效率。

Method: 采用用例图、数据库图、类图和序列图指导平台设计，使用PHP(Laravel框架)、HTML、CSS、Bootstrap和MySQL技术栈，在XAMPP和Visual Studio Code环境下开发动态交互式网络平台。

Result: 实现了献血者注册个人信息、患者按血型和位置搜索献血者、系统提供附近可用献血者列表的功能，建立了集中化的数字连接平台。

Conclusion: 该网络平台通过简化献血者注册、血液请求和沟通流程，显著改善了紧急情况下血液的及时可及性，提升了献血服务的整体效率。

Abstract: Blood donation is a critical component of healthcare, yet locating suitable
donors in emergencies often presents significant challenges. This paper
presents the design and development of a Blood Donation Web Platform, a
web-based system that connects patients, donors, and administrators within a
centralized digital space. The platform allows interested donors to register
their personal information, including blood group, contact details, and
availability. Patients can search for donors based on blood group and location,
and the system provides a list of nearby donors who are ready to donate. The
platform design was guided by use case, database, class, and sequence diagrams
to ensure a well-structured and efficient system architecture. Modern web
technologies, including PHP (Laravel framework), HTML, CSS, Bootstrap, and
MySQL, supported by XAMPP and Visual Studio Code, were employed to implement a
dynamic, interactive, and user-friendly platform. By streamlining donor
refgistration, blood requests, and communication, the proposed system reduces
delays and complexities in emergencies, improving timely accessibility of blood
and enhancing overall efficiency in blood donation services.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [13] [Reactive Bottom-Up Testing](https://arxiv.org/abs/2509.03711)
*Siddharth Muralee,Sourag Cherupattamoolayil,James C. Davis,Antonio Bianchi,Aravind Machiry*

Main category: cs.CR

TL;DR: 提出反应式自底向上测试新模式，通过三阶段方法系统性测试函数并验证在程序上下文中的行为，有效减少假正性和提高漏洞检测效果


<details>
  <summary>Details</summary>
Motivation: 现有动态测试技术主要采用自顶向下方式，难以测试调用图深层函数，而自底向上方法又面临假正性和输入生成挑战

Method: 三阶段测试方案：1）识别容易漏洞函数并生成类型和上下文感知的测试架；2）通过模糊测试找到崩溃并通过符号执行提取输入约束；3）结合约束验证崩溃以消除假正性

Result: 在48个已知漏洞的测试中成功检测到28个，在Pacman等实际应用中发现6个新漏洞

Conclusion: 反应式自底向上测试能够显著提高复杂系统中漏洞检测的效果，为更健壮的安全实践排除障碍

Abstract: Modern computing systems remain rife with software vulnerabilities. Engineers
apply many means to detect them, of which dynamic testing is one of the most
common and effective. However, most dynamic testing techniques follow a
top-down paradigm, and struggle to reach and exercise functions deep within the
call graph. While recent works have proposed Bottom-Up approaches to address
these limitations, they face challenges with false positives and generating
valid inputs that adhere to the context of the entire program.
  In this work, we introduce a new paradigm that we call Reactive Bottom-Up
Testing. Our insight is that function-level testing is necessary but not
sufficient for the validation of vulnerabilities in functions. What we need is
a systematic approach that not only tests functions in isolation but also
validates their behavior within the broader program context, ensuring that
detected vulnerabilities are both reachable and triggerable. We develop a
three-stage bottom-up testing scheme: (1) identify likely-vulnerable functions
and generate type- and context-aware harnesses; (2) fuzz to find crashes and
extract input constraints via symbolic execution; (3) verify crashes by
combining constraints to remove false positives. We implemented an automated
prototype, which we call Griller. We evaluated Griller in a controlled setting
using a benchmark of 48 known vulnerabilities across 5 open-source projects,
where we successfully detected 28 known vulnerabilities. Additionally, we
evaluated Griller on several real-world applications such as Pacman, and it
discovered 6 previously unknown vulnerabilities. Our findings suggest that
Reactive Bottom-Up Testing can significantly enhance the detection of
vulnerabilities in complex systems, paving the way for more robust security
practices.

</details>


### [14] [A Quantum Genetic Algorithm-Enhanced Self-Supervised Intrusion Detection System for Wireless Sensor Networks in the Internet of Things](https://arxiv.org/abs/2509.03744)
*Hamid Barati*

Main category: cs.CR

TL;DR: 重型混合入侵检测系统，结合量子遗传算法和自监督学习，为资源受限的IoT环境提供高效轻量级入侵检测方案


<details>
  <summary>Details</summary>
Motivation: 传统入侵检测系统在IoT环境中存在计算成本高、依赖标签数据集等问题，需要为资源受限网络设计高效轻量的检测方案

Method: 提出一种新的混合入侵检测系统，集成量子遗传算法(QGA)和自监督学习(SSL)。QGA利用量子灵感进化运算符优化特征选择和模型参数微调，SSL允许系统从无标签数据中学习健壮表征

Result: 在标准IoT入侵数据集上评估，在检测准确性、假正率和计算效率方面表现优于传统进化算法和深度学习基于的IDS模型

Conclusion: 结合量子灵感优化和自监督学习范式具有极大潜力，可以为IoT和WSN环境设计下一代入侵检测解决方案

Abstract: The rapid expansion of the Internet of Things (IoT) and Wireless Sensor
Networks (WSNs) has significantly increased the attack surface of such systems,
making them vulnerable to a wide range of cyber threats. Traditional Intrusion
Detection Systems (IDS) often fail to meet the stringent requirements of
resource-constrained IoT environments due to their high computational cost and
reliance on large labeled datasets. To address these challenges, this paper
proposes a novel hybrid Intrusion Detection System that integrates a Quantum
Genetic Algorithm (QGA) with Self-Supervised Learning (SSL). The QGA leverages
quantum-inspired evolutionary operators to optimize feature selection and
fine-tune model parameters, ensuring lightweight yet efficient detection in
resource-limited networks. Meanwhile, SSL enables the system to learn robust
representations from unlabeled data, thereby reducing dependency on manually
labeled training sets. The proposed framework is evaluated on benchmark IoT
intrusion datasets, demonstrating superior performance in terms of detection
accuracy, false positive rate, and computational efficiency compared to
conventional evolutionary and deep learning-based IDS models. The results
highlight the potential of combining quantum-inspired optimization with
self-supervised paradigms to design next-generation intrusion detection
solutions for IoT and WSN environments.

</details>


### [15] [Peekaboo, I See Your Queries: Passive Attacks Against DSSE Via Intermittent Observations](https://arxiv.org/abs/2509.03806)
*Hao Nie,Wei Wang,Peng Xu,Wei Chen,Laurence T. Yang,Mauro Conti,Kaitai Liang*

Main category: cs.CR

TL;DR: Peekaboo是一个针对动态可搜索对称加密(DSSE)的新型通用攻击框架，能够在间歇性观察的实用威胁模型下实现高精度的搜索模式恢复和查询准确率。


<details>
  <summary>Details</summary>
Motivation: 现有DSSE被动攻击需要持续监控泄漏模式，而实际场景中攻击者往往只能进行间歇性观察，需要开发更实用的攻击方法。

Method: 提出Peekaboo框架，通过推断搜索模式并结合辅助知识和其他泄漏信息，在Sap和Jigsaw等SOTA攻击基础上构建Sap+和Jigsaw+变体。

Result: 实验显示搜索模式恢复调整兰德指数>0.9，查询准确率达90%（相比FMA的30%），对文件大小填充和混淆等SOTA防御措施仍保持>40%和>80%的准确率。

Conclusion: Peekaboo证明了在间歇性观察场景下仍能有效攻击DSSE系统，且攻击效果随观察轮次和查询数量增加而提升，对现有防御措施具有强抵抗力。

Abstract: Dynamic Searchable Symmetric Encryption (DSSE) allows secure searches over a
dynamic encrypted database but suffers from inherent information leakage.
Existing passive attacks against DSSE rely on persistent leakage monitoring to
infer leakage patterns, whereas this work targets intermittent observation - a
more practical threat model. We propose Peekaboo - a new universal attack
framework - and the core design relies on inferring the search pattern and
further combining it with auxiliary knowledge and other leakage. We instantiate
Peekaboo over the SOTA attacks, Sap (USENIX' 21) and Jigsaw (USENIX' 24), to
derive their "+" variants (Sap+ and Jigsaw+). Extensive experiments demonstrate
that our design achieves >0.9 adjusted rand index for search pattern recovery
and 90% query accuracy vs. FMA's 30% (CCS' 23). Peekaboo's accuracy scales with
observation rounds and the number of observed queries but also it resists SOTA
countermeasures, with >40% accuracy against file size padding and >80% against
obfuscation.

</details>


### [16] [BIDO: A Unified Approach to Address Obfuscation and Concept Drift Challenges in Image-based Malware Detection](https://arxiv.org/abs/2509.03807)
*Junhui Li,Chengbin Feng,Zhiwei Yang,Qi Mo,Wei Wang*

Main category: cs.CR

TL;DR: BIDO是一种基于图像的混合恶意软件检测器，通过局部特征选择、跨模态依赖建模和可学习度量来同时增强对混淆和概念漂移的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图像的Android恶意软件检测方法在面对混淆和概念漂移时性能显著下降，且通常将这两个挑战视为独立问题处理，忽略了它们共同的统计根源——分布外问题。

Method: 1) 局部特征选择模块识别恶意软件图像中的信息子区域；2) 在外积空间中建模跨模态依赖关系以提取稳定的共现模式；3) 设计可学习度量使同类样本靠近、异类样本远离。

Result: 在真实数据集上的广泛实验表明，BIDO显著优于现有基线方法，对概念漂移和混淆都具有更高的鲁棒性。

Conclusion: BIDO通过同时处理混淆和概念漂移的共同统计根源，有效提升了基于图像的恶意软件检测的鲁棒性和性能。

Abstract: To identify malicious Android applications, various malware detection
techniques have been proposed. Among them, image-based approaches are
considered potential alternatives due to their efficiency and scalability.
Recent studies have reported that these approaches suffer significant
performance declines when confronted with obfuscation or concept drift.
However, existing solutions often treat these two challenges as different
problems, offering independent solutions. These techniques overlook the fact
that both challenges share a common statistical root, out-of-distribution, and
research from this perspective remains limited. In response, we propose BIDO, a
hybrid image-based malware detector designed to enhance robustness against both
obfuscation and concept drift simultaneously. Specifically, to improve the
discriminative power of image features, we introduce a local feature selection
module that identifies informative subregions within malware images. Second, to
enhance feature robustness, we model pairwise cross-modal dependencies in an
outer product space, enabling the extraction of stable co-occurrence patterns.
Third, to ensure feature compactness, we design a learnable metric that pulls
samples with identical labels closer while pushing apart those with different
labels, regardless of obfuscation or concept drift. Extensive experiments on
the real-world datasets demonstrate that BIDO significantly outperforms
existing baselines, achieving higher robustness against both concept drift and
obfuscation. The source code is available at:
https://github.com/whatishope/BIDO/.

</details>


### [17] [Rethinking Tamper-Evident Logging: A High-Performance, Co-Designed Auditing System](https://arxiv.org/abs/2509.03821)
*Rui Zhao,Muhammad Shoaib,Viet Tung Hoang,Wajih Ul Hassan*

Main category: cs.CR

TL;DR: Nitro是一个高性能的防篡改审计日志系统，使用eBPF技术避免内核重编译，提供细粒度篡改检测，性能比现有系统提升10-25倍


<details>
  <summary>Details</summary>
Motivation: 现有防篡改日志系统在高负载下开销大、数据丢失严重，只能提供粗粒度检测，且需要重新编译内核代码

Method: 使用eBPF技术避免内核重编译，密码学设计与日志前后处理协同设计以利用系统级优化，提供形式化安全框架和密码学构造

Result: 在高压力条件下实现10-25倍性能提升，真实场景中2-10倍提升，保持接近零数据丢失

Conclusion: Nitro系统成功解决了现有防篡改日志系统的性能和数据丢失问题，通过eBPF技术和系统级优化实现了高性能的细粒度篡改检测

Abstract: Existing tamper-evident logging systems suffer from high overhead and severe
data loss in high-load settings, yet only provide coarse-grained tamper
detection. Moreover, installing such systems requires recompiling kernel code.
To address these challenges, we present Nitro, a high-performance,
tamper-evident audit logging system that supports fine-grained detection of log
tampering. Even better, our system avoids kernel recompilation by using the
eBPF technology. To formally justify the security of Nitro, we provide a new
definitional framework for logging systems, and give a practical cryptographic
construction meeting this new goal. Unlike prior work that focus only on the
cryptographic processing, we codesign the cryptographic part with the pre- and
post-processing of the logs to exploit all system-level optimizations. Our
evaluations demonstrate Nitro's superior performance, achieving 10X-25X
improvements in high-stress conditions and 2X-10X in real-world scenarios while
maintaining near-zero data loss. We also provide an advanced variant, Nitro-R
that introduces in-kernel log reduction techniques to reduce runtime overhead
even further.

</details>


### [18] [KGBERT4Eth: A Feature-Complete Transformer Powered by Knowledge Graph for Multi-Task Ethereum Fraud Detection](https://arxiv.org/abs/2509.03860)
*Yifan Jia,Ye Tian,Liguo Zhang,Yanbin Wang,Jianguo Sun,Liangliang Song*

Main category: cs.CR

TL;DR: KGBERT4Eth是一个融合交易语义提取和知识图谱的预训练编码器，通过联合优化两个组件来生成特征完整的嵌入表示，在以太坊恶意活动检测任务上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前以太坊恶意活动检测方法存在三种技术流派（专家定义特征、图嵌入、序列交易模式），但缺乏跨范式集成机制，导致需要在不同特征优势之间做出取舍。

Method: 提出KGBERT4Eth，包含两个关键组件：(1)交易语义提取器，训练增强的交易语言模型学习上下文语义表示；(2)交易知识图谱，将专家知识融入图节点嵌入。通过联合优化预训练目标融合互补特征，并设计偏置掩码预测任务和链接预测来关注异常交易。

Result: 在钓鱼账户检测和去匿名化任务上显著优于最先进基线方法，在三个钓鱼检测基准上F1分数绝对提升8-16%，在四个去匿名化数据集上提升6-26%。

Conclusion: KGBERT4Eth成功实现了跨范式特征融合，为以太坊恶意活动检测提供了特征完整的解决方案，证明了联合优化语义和结构化特征的有效性。

Abstract: Ethereum's rapid ecosystem expansion and transaction anonymity have triggered
a surge in malicious activity. Detection mechanisms currently bifurcate into
three technical strands: expert-defined features, graph embeddings, and
sequential transaction patterns, collectively spanning the complete feature
sets of Ethereum's native data layer. Yet the absence of cross-paradigm
integration mechanisms forces practitioners to choose between sacrificing
sequential context awareness, structured fund-flow patterns, or human-curated
feature insights in their solutions. To bridge this gap, we propose KGBERT4Eth,
a feature-complete pre-training encoder that synergistically combines two key
components: (1) a Transaction Semantic Extractor, where we train an enhanced
Transaction Language Model (TLM) to learn contextual semantic representations
from conceptualized transaction records, and (2) a Transaction Knowledge Graph
(TKG) that incorporates expert-curated domain knowledge into graph node
embeddings to capture fund flow patterns and human-curated feature insights. We
jointly optimize pre-training objectives for both components to fuse these
complementary features, generating feature-complete embeddings. To emphasize
rare anomalous transactions, we design a biased masking prediction task for TLM
to focus on statistical outliers, while the Transaction TKG employs link
prediction to learn latent transaction relationships and aggregate knowledge.
Furthermore, we propose a mask-invariant attention coordination module to
ensure stable dynamic information exchange between TLM and TKG during
pre-training. KGBERT4Eth significantly outperforms state-of-the-art baselines
in both phishing account detection and de-anonymization tasks, achieving
absolute F1-score improvements of 8-16% on three phishing detection benchmarks
and 6-26% on four de-anonymization datasets.

</details>


### [19] [ShieldMMU: Detecting and Defending against Controlled-Channel Attacks in Shielding Memory System](https://arxiv.org/abs/2509.03879)
*Gang Liu,Ningjie Li,Cen Chen*

Main category: cs.CR

TL;DR: ShieldMMU是一个针对Intel SGX侧信道攻击的防御方案，通过DD-Tree保护PTE完整性，检测和恢复被攻击的页表项，平衡兼容性、性能和可用性。


<details>
  <summary>Details</summary>
Motivation: Intel SGX和虚拟机监控程序虽然能隔离非特权程序，但侧信道攻击仍然威胁SGX安全，恶意操作系统可以通过操纵PTE存在位来窃取内存访问痕迹，现有防御方案要么专注于检测，要么依赖不切实际的解决方案。

Method: 采用受Merkle Tree启发的防御树(DD-Tree)来保护PTE完整性，能够检测、定位和恢复被攻击的PTE，识别MMU页表查找事件和侧信道攻击，及时恢复PTE参数以防止页面错误陷阱。

Result: 实验证实ShieldMMU具有增强的安全性和可接受的延迟性能。

Conclusion: ShieldMMU提供了一个全面的解决方案，有效缓解受控信道攻击，在SGX环境中确保非特权应用程序的安全运行。

Abstract: Intel SGX and hypervisors isolate non-privileged programs from other
software, ensuring confidentiality and integrity. However, side-channel attacks
continue to threaten Intel SGX's security, enabling malicious OS to manipulate
PTE present bits, induce page faults, and steal memory access traces. Despite
extensive research, existing defenses focus on detection or rely on impractical
solutions. This paper presents ShieldMMU, a comprehensive solution for
mitigating controlled channel attacks, balancing compatibility, performance,
and usability. Leveraging a Merkle Tree-inspired Defense Tree (DD-Tree),
ShieldMMU protects PTE integrity by detecting, locating, and restoring attacked
PTEs. It identifies MMU page table lookup events and side-channel attacks,
promptly restoring PTE parameters to prevent page fault traps and ensure secure
non-privileged application operation within SGX. Our experiments confirm
ShieldMMU's enhanced security and acceptable latency performance.

</details>


### [20] [LMAE4Eth: Generalizable and Robust Ethereum Fraud Detection by Exploring Transaction Semantics and Masked Graph Embedding](https://arxiv.org/abs/2509.03939)
*Yifan Jia,Yanbin Wang,Jianguo Sun,Ye Tian,Peng Qian*

Main category: cs.CR

TL;DR: LMAE4Eth是一个多视图学习框架，融合交易语义、掩码图嵌入和专家知识，用于以太坊欺诈检测，在F1分数上比最佳基线方法提升超过10%。


<details>
  <summary>Details</summary>
Motivation: 当前以太坊欺诈检测方法依赖上下文无关的数值交易序列，无法捕捉账户交易语义；交易记录的同质性使得难以学习区分性账户嵌入；现有自监督图学习方法主要关注图重建，在节点级任务上表现不佳且存在可扩展性问题。

Method: 提出TxCLM交易-令牌对比语言模型将数值交易记录转换为语言表示；使用掩码交易模型和令牌感知对比学习预训练目标学习高表达性账户表示；设计MAGAE掩码账户图自编码器通过重建账户节点特征实现节点级检测；集成层邻居采样提高可扩展性；使用跨注意力融合网络统一TxCLM和MAGAE的嵌入。

Result: 在三个数据集上与21个基线方法对比，实验结果显示在两个数据集上F1分数比最佳基线方法提升超过10%。

Conclusion: LMAE4Eth通过融合多视图学习和自监督方法，有效解决了以太坊欺诈检测中的语义捕捉、表示学习和可扩展性问题，显著提升了检测性能。

Abstract: Current Ethereum fraud detection methods rely on context-independent,
numerical transaction sequences, failing to capture semantic of account
transactions. Furthermore, the pervasive homogeneity in Ethereum transaction
records renders it challenging to learn discriminative account embeddings.
Moreover, current self-supervised graph learning methods primarily learn node
representations through graph reconstruction, resulting in suboptimal
performance for node-level tasks like fraud account detection, while these
methods also encounter scalability challenges. To tackle these challenges, we
propose LMAE4Eth, a multi-view learning framework that fuses transaction
semantics, masked graph embedding, and expert knowledge. We first propose a
transaction-token contrastive language model (TxCLM) that transforms
context-independent numerical transaction records into logically cohesive
linguistic representations. To clearly characterize the semantic differences
between accounts, we also use a token-aware contrastive learning pre-training
objective together with the masked transaction model pre-training objective,
learns high-expressive account representations. We then propose a masked
account graph autoencoder (MAGAE) using generative self-supervised learning,
which achieves superior node-level account detection by focusing on
reconstructing account node features. To enable MAGAE to scale for large-scale
training, we propose to integrate layer-neighbor sampling into the graph, which
reduces the number of sampled vertices by several times without compromising
training quality. Finally, using a cross-attention fusion network, we unify the
embeddings of TxCLM and MAGAE to leverage the benefits of both. We evaluate our
method against 21 baseline approaches on three datasets. Experimental results
show that our method outperforms the best baseline by over 10% in F1-score on
two of the datasets.

</details>


### [21] [NeuroBreak: Unveil Internal Jailbreak Mechanisms in Large Language Models](https://arxiv.org/abs/2509.03985)
*Chuhan Zhang,Ye Zhang,Bowen Shi,Yuyou Gan,Tianyu Du,Shouling Ji,Dazhan Deng,Yingcai Wu*

Main category: cs.CR

TL;DR: NeuroBreak是一个自上而下的越狱分析系统，通过神经元层面的安全机制分析来发现和缓解大语言模型的安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 随着越狱攻击技术的不断发展，大语言模型的安全防御面临越来越大的压力。理解LLMs的安全机制和漏洞需要从内部视角进行分析，但由于参数数量庞大和结构复杂，这是一项具有挑战性的任务。

Method: 设计了一个与AI安全专家合作开发的系统，提供对各种越狱攻击方法的全面分析。通过分层表示探测分析，提供模型生成步骤中决策过程的新视角，支持从语义和功能角度分析关键神经元。

Result: 通过定量评估和案例研究验证了系统的有效性，为开发下一代防御策略提供了机制性见解。

Conclusion: NeuroBreak系统能够深入分析神经元级别的安全机制，有助于更好地理解大语言模型的安全漏洞，并为对抗不断演变的越狱攻击提供有价值的见解。

Abstract: In deployment and application, large language models (LLMs) typically undergo
safety alignment to prevent illegal and unethical outputs. However, the
continuous advancement of jailbreak attack techniques, designed to bypass
safety mechanisms with adversarial prompts, has placed increasing pressure on
the security defenses of LLMs. Strengthening resistance to jailbreak attacks
requires an in-depth understanding of the security mechanisms and
vulnerabilities of LLMs. However, the vast number of parameters and complex
structure of LLMs make analyzing security weaknesses from an internal
perspective a challenging task. This paper presents NeuroBreak, a top-down
jailbreak analysis system designed to analyze neuron-level safety mechanisms
and mitigate vulnerabilities. We carefully design system requirements through
collaboration with three experts in the field of AI security. The system
provides a comprehensive analysis of various jailbreak attack methods. By
incorporating layer-wise representation probing analysis, NeuroBreak offers a
novel perspective on the model's decision-making process throughout its
generation steps. Furthermore, the system supports the analysis of critical
neurons from both semantic and functional perspectives, facilitating a deeper
exploration of security mechanisms. We conduct quantitative evaluations and
case studies to verify the effectiveness of our system, offering mechanistic
insights for developing next-generation defense strategies against evolving
jailbreak attacks.

</details>


### [22] [Systematic Timing Leakage Analysis of NIST PQDSS Candidates: Tooling and Lessons Learned](https://arxiv.org/abs/2509.04010)
*Olivier Adjonyo,Sebastien Bardin,Emanuele Bellini,Gilbert Ndollane Dione,Mahmudul Faisal Al Ameen,Robert Merget,Frederic Recoules,Yanis Sellami*

Main category: cs.CR

TL;DR: 这篇论文为NIST PQDSS标准化过程开发了一个自动化工具链，用于验证加密算法的常数时间性实现，以防止时间和缓存侦测漏洞。


<details>
  <summary>Details</summary>
Motivation: PQDSS标准化要求加密原语无漏洞，包括时间和缓存侦测。常数时间实现对于公平性能比较和安全性至关重要，但现有工具存在易用性问题。

Method: 开发了一个自动化工具链，整合TIMECOP、Binsec/Rel2进行二进制级常数时间验证，以及dudect和RTLF进行执行时间统计分析检测侦测漏洞。

Result: 对NIST PQDSS第1轮和第2轮实现进行评估，发现并报告了26个问题，其中5个已修复。讨论了不同工具的优缺点。

Conclusion: 该自动化工具链有效支持了PQDSS实现的常数时间验证，显著提高了安全性分析的效率和可用性。

Abstract: The PQDSS standardization process requires cryptographic primitives to be
free from vulnerabilities, including timing and cache side-channels. Resistance
to timing leakage is therefore an essential property, and achieving this
typically relies on software implementations that follow constant-time
principles. Moreover, ensuring that all implementations are constant-time is
crucial for fair performance comparisons, as secure implementations often incur
additional overhead. Such analysis also helps identify scheme proposals that
are inherently difficult to implement in constant time. Because constant-time
properties can be broken during compilation, it is often necessary to analyze
the compiled binary directly. Since manual binary analysis is extremely
challenging, automated analysis becomes highly important. Although several
tools exist to assist with such analysis, they often have usability limitations
and are difficult to set up correctly. To support the developers besides the
NIST committee in verifying candidates, we developed a toolchain that automates
configuration, execution, and result analysis for several widely used
constant-time analysis tools. We selected TIMECOP and Binsec/Rel2 to verify
constant-time policy compliance at the binary level, and dudect and RTLF to
detect side-channel vulnerabilities through statistical analysis of execution
time behavior. We demonstrate its effectiveness and practicability by
evaluating the NIST PQDSS round 1 and round 2 implementations. We reported 26
issues in total to the respective developers, and 5 of them have already been
fixed. We also discuss our different findings, as well as the benefits of
shortcomings of the different tools.

</details>


### [23] [Error Detection Schemes for Barrett Reduction of CT-BU on FPGA in Post Quantum Cryptography](https://arxiv.org/abs/2509.04070)
*Paresh Baidya,Rourab Paul,Vikas Srivastava,Sumit Kumar Debnath*

Main category: cs.CR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: A fault can occur naturally or intentionally. However, intentionally
injecting faults into hardware accelerators of Post-Quantum Cryptographic (PQC)
algorithms may leak sensitive information. This intentional fault injection in
side-channel attacks compromises the reliability of PQC implementations. The
recently NIST-standardized key encapsulation mechanism (KEM), Kyber may also
leak information at the hardware implementation level. This work proposes three
efficient and lightweight recomputation-based fault detection methods for
Barrett Reduction in the Cooley-Tukey Butterfly Unit (CT-BU) of Kyber on a
Field Programmable Gate Array (FPGA). The CT-BU and Barrett Reduction are
fundamental components in structured lattice-based PQC algorithms, including
Kyber, NTRU, Falcon, CRYSTALS-Dilithium, etc. This paper introduces a new
algorithm, Recomputation with Swapped Operand (RESWO), for fault detection.
While Recomputation with Negated Operand (RENO) and Recomputation with Shifted
Operand (RESO) are existing methods used in other PQC hardware algorithms. To
the best of our knowledge, RENO and RESO have never been used in Barrett
Reduction before. The proposed RESWO method consumes a similar number of slices
compared to RENO and RESO. However, RESWO shows lesser delay compared to both
RENO and RESO. The fault detection efficiency of RESWO, RENO, and RESO is
nearly 100%.

</details>


### [24] [ICSLure: A Very High Interaction Honeynet for PLC-based Industrial Control Systems](https://arxiv.org/abs/2509.04080)
*Francesco Aurelio Pironti,Angelo Furfaro,Francesco Blefari,Carmelo Felicetti,Matteo Lupinacci,Francesco Romeo*

Main category: cs.CR

TL;DR: 提出了ICSLure模块化蜜网框架，通过整合物理PLC和虚拟化网络组件来模拟真实工业控制系统环境，提高威胁检测和分析能力


<details>
  <summary>Details</summary>
Motivation: 工业控制系统安全至关重要，但传统ICS蜜罐缺乏真实性，无法有效应对复杂攻击，需要更真实的仿真环境来捕获和分析威胁

Method: 开发模块化蜜网框架ICSLure，整合物理PLC与实时数据源通过工业协议交互，配合虚拟化网络组件（路由器、交换机、RTU），并具备全面监控能力

Result: 框架能够实现真实工业工厂的高保真仿真，显著提升威胁数据质量，支持对ICS特定攻击策略的深入分析

Conclusion: ICSLure框架通过高交互环境有效增强了工业控制系统威胁检测和缓解技术的效果，为ICS安全提供了更先进的解决方案

Abstract: The security of Industrial Control Systems (ICSs) is critical to ensuring the
safety of industrial processes and personnel. The rapid adoption of Industrial
Internet of Things (IIoT) technologies has expanded system functionality but
also increased the attack surface, exposing ICSs to a growing range of cyber
threats. Honeypots provide a means to detect and analyze such threats by
emulating target systems and capturing attacker behavior. However, traditional
ICS honeypots, often limited to software-based simulations of a single
Programmable Logic Controller (PLC), lack the realism required to engage
sophisticated adversaries. In this work, we introduce a modular honeynet
framework named ICSLure. The framework has been designed to emulate realistic
ICS environments. Our approach integrates physical PLCs interacting with live
data sources via industrial protocols such as Modbus and Profinet RTU, along
with virtualized network components including routers, switches, and Remote
Terminal Units (RTUs). The system incorporates comprehensive monitoring
capabilities to collect detailed logs of attacker interactions. We demonstrate
that our framework enables coherent and high-fidelity emulation of real-world
industrial plants. This high-interaction environment significantly enhances the
quality of threat data collected and supports advanced analysis of ICS-specific
attack strategies, contributing to more effective detection and mitigation
techniques.

</details>


### [25] [Revisiting Third-Party Library Detection: A Ground Truth Dataset and Its Implications Across Security Tasks](https://arxiv.org/abs/2509.04091)
*Jintao Gu,Haolang Lu,Guoshun Nan,Yihan Lin,Kun Wang,Yuchun Guo,Yigui Cao,Yang Liu*

Main category: cs.CR

TL;DR: 这是首个大规模Android第三方库检测技术实证研究，评估了10种先进方法在6000+应用中的实际效果，曝露了工具在R8优化、版本区分、性能等方面的问题


<details>
  <summary>Details</summary>
Motivation: Android第三方库检测对安全至关重要，但现有工具的实际效果不清楚，需要系统性评估以提高安全分析的准确性

Method: 构建了新的准确版本标注真实数据集，在超6000个应用不对10种先进的TPL检测技术进行大规模实证研究

Result: 发现工具对R8优化效果脏弱、版本区分能力差、库匹配准确性低、相似度阈值泛化困难以及大规模运行时间/内存开销大

Conclusion: 研究不仅评估了检测工具，还分析了TPL特征对漏洞分析、恶意代码检测等应用的影响，为安全分析的改进提供了具体见解

Abstract: Accurate detection of third-party libraries (TPLs) is fundamental to Android
security, supporting vulnerability tracking, malware detection, and supply
chain auditing. Despite many proposed tools, their real-world effectiveness
remains unclear.We present the first large-scale empirical study of ten
state-of-the-art TPL detection techniques across over 6,000 apps, enabled by a
new ground truth dataset with precise version-level annotations for both remote
and local dependencies.Our evaluation exposes tool fragility to R8-era
transformations, weak version discrimination, inaccurate correspondence of
candidate libraries, difficulty in generalizing similarity thresholds, and
prohibitive runtime/memory overheads at scale.Beyond tool assessment, we
further analyze how TPLs shape downstream tasks, including vulnerability
analysis, malware detection, secret leakage assessment, and LLM-based
evaluation. From this perspective, our study provides concrete insights into
how TPL characteristics affect these tasks and informs future improvements in
security analysis.

</details>


### [26] [ECCFROG522PP: An Enhanced 522-bit Weierstrass Elliptic Curve](https://arxiv.org/abs/2509.04097)
*Víctor Duarte Melo,William J. Buchanan*

Main category: cs.CR

TL;DR: ECCFROG522PP是一个522位素数域椭圆曲线，提供约260位经典安全性，通过BLAKE3确定性生成参数，具有完全可重现性和透明度


<details>
  <summary>Details</summary>
Motivation: 现有256位安全曲线（如NIST P-256）安全性不足，需要更高安全级别的透明可重现曲线，替代NIST P-521等现有高安全选项

Method: 使用BLAKE3哈希函数从固定公共种子确定性生成所有曲线参数，确保零隐藏选择。曲线具有素数阶、验证的扭曲、安全嵌入度，并通过抗MOV和CM判别式检查

Result: 成功设计了ECCFROG522PP曲线，提供与NIST P-521相当的约260位安全性，但具有完全可重现性和透明度

Conclusion: ECCFROG522PP在保持与NIST P-521相同安全级别的同时，通过确定性参数生成实现了更高的可信度、可验证性和长期可审计性

Abstract: Whilst many key exchange and digital signature systems still rely on NIST
P-256 (secp256r1) and secp256k1, offering around 128-bit security, there is an
increasing demand for transparent and reproducible curves at the 256-bit
security level. Standard higher-security options include NIST P-521, Curve448,
and Brainpool-P512. This paper presents ECCFROG522PP ("Presunto Powered"), a
522-bit prime-field elliptic curve that delivers security in the same classical
approx 260-bit ballpark as NIST P-521, but with a fundamentally different
design philosophy. All of the curve parameters are deterministically derived
from a fixed public seed via BLAKE3, with zero hidden choices. The curve has
prime order (cofactor = 1), a verified twist with a proven approx 505-bit prime
factor, safe embedding degree (greater than or equal to 14), and passes
anti-MOV checks up to k less than or equal to 200 and CM discriminant sanity up
to 100k. Unlike prior opaque or ad-hoc constructions, ECCFROG522PP is fully
reproducible: anyone can regenerate and verify it byte-for-byte using the
published scripts. The intent is not to outperform NIST P-521 in raw speed, but
to maximise trust, verifiability, and long-term auditability in a practical
curve of equivalent security level

</details>


### [27] [KubeGuard: LLM-Assisted Kubernetes Hardening via Configuration Files and Runtime Logs Analysis](https://arxiv.org/abs/2509.04191)
*Omri Sgan Cohen,Ehud Malul,Yair Meidan,Dudu Mimran,Yuval Elovici,Asaf Shabtai*

Main category: cs.CR

TL;DR: KubeGuard是一个基于运行时日志的Kubernetes安全推荐框架，使用LLM分析配置清单和运行时日志，通过资源创建和精炼两个任务来生成最小权限配置建议，有效降低攻击面。


<details>
  <summary>Details</summary>
Motivation: Kubernetes广泛采用带来了严重的安全挑战，如错误配置和过度权限设置，现有解决方案主要关注检测而非缓解，需要一种能够将运行时可观测性转化为可操作配置指导的方法。

Method: 提出KubeGuard框架，利用大型语言模型(LLM)分析配置清单和运行时日志，采用模块化提示链工作流，执行资源创建和资源精炼两个互补任务来生成最小权限配置建议。

Result: 评估显示KubeGuard能有效生成和精炼Roles、NetworkPolicies和Deployments的Kubernetes清单，使用专有和开源LLM均获得高精度、召回率和F1分数。

Conclusion: KubeGuard是一个实用的框架，能够将运行时可观测性转化为可操作的最小权限配置指导，帮助开发者和运维人员增强集群安全性。

Abstract: The widespread adoption of Kubernetes (K8s) for orchestrating cloud-native
applications has introduced significant security challenges, such as
misconfigured resources and overly permissive configurations. Failing to
address these issues can result in unauthorized access, privilege escalation,
and lateral movement within clusters. Most existing K8s security solutions
focus on detecting misconfigurations, typically through static analysis or
anomaly detection. In contrast, this paper presents KubeGuard, a novel runtime
log-driven recommender framework aimed at mitigating risks by addressing overly
permissive configurations. KubeGuard is designed to harden K8s environments
through two complementary tasks: Resource Creation and Resource Refinement. It
leverages large language models (LLMs) to analyze manifests and runtime logs
reflecting actual system behavior, using modular prompt-chaining workflows.
This approach enables KubeGuard to create least-privilege configurations for
new resources and refine existing manifests to reduce the attack surface.
KubeGuard's output manifests are presented as recommendations that users (e.g.,
developers and operators) can review and adopt to enhance cluster security. Our
evaluation demonstrates that KubeGuard effectively generates and refines K8s
manifests for Roles, NetworkPolicies, and Deployments, leveraging both
proprietary and open-source LLMs. The high precision, recall, and F1-scores
affirm KubeGuard's practicality as a framework that translates runtime
observability into actionable, least-privilege configuration guidance.

</details>


### [28] [An Automated, Scalable Machine Learning Model Inversion Assessment Pipeline](https://arxiv.org/abs/2509.04214)
*Tyler Shumaker,Jessica Carpenter,David Saranchak,Nathaniel D. Bastian*

Main category: cs.CR

TL;DR: 本文提出了一种新的自动化开发测试与评估工具，用于量化机器学习模型反向工程攻击的数据隐私风险，通过结合视觉语言模型提高效果和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在军事战场中的应用增长快速，但这些模型容易受到各种对抗攻击，特别是隐私攻击如模型反向工程攻击。目前缺乏有效的工具和指标来量化这种隐私风险。

Method: 设计了一种新的DT&E工具，通过结合视觉语言模型（VLMs）来改善模型反向效果，并引入四个对抗风险维度来量化隐私损失。支持零样本分类和图片描述功能。

Result: 在计算机视觉领域的图片分类任务中，使用多种先进的MIA技术进行了基准测试，验证了该工具的效果性。

Conclusion: 该创新性流水线通过提高效果性和可扩展性，扩展了现有的模型反向工程DT&E能力，能够以自动化方式进行隐私损失分析。

Abstract: Machine learning (ML) models have the potential to transform military
battlefields, presenting a large external pressure to rapidly incorporate them
into operational settings. However, it is well-established that these ML models
are vulnerable to a number of adversarial attacks throughout the model
deployment pipeline that threaten to negate battlefield advantage. One broad
category is privacy attacks (such as model inversion) where an adversary can
reverse engineer information from the model, such as the sensitive data used in
its training. The ability to quantify the risk of model inversion attacks
(MIAs) is not well studied, and there is a lack of automated developmental test
and evaluation (DT&E) tools and metrics to quantify the effectiveness of
privacy loss of the MIA. The current DT&E process is difficult because ML model
inversions can be hard for a human to interpret, subjective when they are
interpretable, and difficult to quantify in terms of inversion quality.
Additionally, scaling the DT&E process is challenging due to many ML model
architectures and data modalities that need to be assessed. In this work, we
present a novel DT&E tool that quantifies the risk of data privacy loss from
MIAs and introduces four adversarial risk dimensions to quantify privacy loss.
Our DT&E pipeline combines inversion with vision language models (VLMs) to
improve effectiveness while enabling scalable analysis. We demonstrate
effectiveness using multiple MIA techniques and VLMs configured for zero-shot
classification and image captioning. We benchmark the pipeline using several
state-of-the-art MIAs in the computer vision domain with an image
classification task that is typical in military applications. In general, our
innovative pipeline extends the current model inversion DT&E capabilities by
improving the effectiveness and scalability of the privacy loss analysis in an
automated fashion.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [29] [PG-Agent: An Agent Powered by Page Graph](https://arxiv.org/abs/2509.03536)
*Weizhi Chen,Ziwei Wang,Leyang Yang,Sheng Zhou,Xiaoxuan Tang,Jiajun Bu,Yong Li,Wei Jiang*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Graphical User Interface (GUI) agents possess significant commercial and
social value, and GUI agents powered by advanced multimodal large language
models (MLLMs) have demonstrated remarkable potential. Currently, existing GUI
agents usually utilize sequential episodes of multi-step operations across
pages as the prior GUI knowledge, which fails to capture the complex transition
relationship between pages, making it challenging for the agents to deeply
perceive the GUI environment and generalize to new scenarios. Therefore, we
design an automated pipeline to transform the sequential episodes into page
graphs, which explicitly model the graph structure of the pages that are
naturally connected by actions. To fully utilize the page graphs, we further
introduce Retrieval-Augmented Generation (RAG) technology to effectively
retrieve reliable perception guidelines of GUI from them, and a tailored
multi-agent framework PG-Agent with task decomposition strategy is proposed to
be injected with the guidelines so that it can generalize to unseen scenarios.
Extensive experiments on various benchmarks demonstrate the effectiveness of
PG-Agent, even with limited episodes for page graph construction.

</details>


### [30] [Multilinear and Linear Programs for Partially Identifiable Queries in Quasi-Markovian Structural Causal Models](https://arxiv.org/abs/2509.03548)
*João P. Arroyo,João G. Rodrigues,Daniel Lawand,Denis D. Mauá,Junkyu Lee,Radu Marinescu,Alex Gray,Eduardo R. Laurentino,Fabio G. Cozman*

Main category: cs.AI

TL;DR: 该论文研究准马尔可夫因果模型中部分可识别查询的概率边界计算问题，提出了基于列生成技术的新算法来简化多线性规划问题，在单干预场景下通过线性整数程序序列计算紧概率边界。


<details>
  <summary>Details</summary>
Motivation: 研究在准马尔可夫因果模型中，当外生变量未完全指定时，无法精确计算感兴趣概率值的问题，需要计算紧概率边界。

Method: 提出新算法利用内生变量的输入概率简化多线性规划构造，对单干预场景应用列生成技术，通过一系列辅助线性整数程序计算概率边界。

Result: 实验表明列生成技术优于现有方法，证明了外生变量多项式基数表示的可能性。

Conclusion: 列生成方法在计算准马尔可夫因果模型的概率边界方面具有优越性，为部分可识别查询提供了有效的计算框架。

Abstract: We investigate partially identifiable queries in a class of causal models. We
focus on acyclic Structural Causal Models that are quasi-Markovian (that is,
each endogenous variable is connected with at most one exogenous confounder).
We look into scenarios where endogenous variables are observed (and a
distribution over them is known), while exogenous variables are not fully
specified. This leads to a representation that is in essence a Bayesian network
where the distribution of root variables is not uniquely determined. In such
circumstances, it may not be possible to precisely compute a probability value
of interest. We thus study the computation of tight probability bounds, a
problem that has been solved by multilinear programming in general, and by
linear programming when a single confounded component is intervened upon. We
present a new algorithm to simplify the construction of such programs by
exploiting input probabilities over endogenous variables. For scenarios with a
single intervention, we apply column generation to compute a probability bound
through a sequence of auxiliary linear integer programs, thus showing that a
representation with polynomial cardinality for exogenous variables is possible.
Experiments show column generation techniques to be superior to existing
methods.

</details>


### [31] [Diffusion-RL Based Air Traffic Conflict Detection and Resolution Method](https://arxiv.org/abs/2509.03550)
*Tonghe Li,Jixin Liu,Weili Zeng,Hao Jiang*

Main category: cs.AI

TL;DR: 本文提出Diffusion-AC框架，将扩散概率模型引入空中交通冲突检测与解决(CD&R)任务，通过多模态决策能力解决传统DRL方法的单模态偏差问题，在密集交通场景中显著提升安全性和成功率。


<details>
  <summary>Details</summary>
Motivation: 全球航空交通持续增长，需要高效安全的冲突检测与解决方案。现有深度强化学习方法存在"单模态偏差"，导致决策灵活性不足，在复杂动态约束下容易出现"决策死锁"。

Method: 提出Diffusion-AC框架，将策略建模为由价值函数引导的反向去噪过程，生成丰富、高质量的多模态动作分布。采用密度渐进安全课程(DPSC)训练机制，从稀疏到高密度交通环境进行稳定高效学习。

Result: 在最具挑战性的高密度场景中，Diffusion-AC保持94.1%的高成功率，相比次优基线将近空中碰撞(NMACs)发生率降低约59%，显著提升系统安全边际。

Conclusion: 扩散概率模型为安全关键型CD&R任务提供了有效解决方案，其多模态决策能力使智能体能够灵活切换到有效的替代机动策略，实现了性能的显著飞跃。

Abstract: In the context of continuously rising global air traffic, efficient and safe
Conflict Detection and Resolution (CD&R) is paramount for air traffic
management. Although Deep Reinforcement Learning (DRL) offers a promising
pathway for CD&R automation, existing approaches commonly suffer from a
"unimodal bias" in their policies. This leads to a critical lack of
decision-making flexibility when confronted with complex and dynamic
constraints, often resulting in "decision deadlocks." To overcome this
limitation, this paper pioneers the integration of diffusion probabilistic
models into the safety-critical task of CD&R, proposing a novel autonomous
conflict resolution framework named Diffusion-AC. Diverging from conventional
methods that converge to a single optimal solution, our framework models its
policy as a reverse denoising process guided by a value function, enabling it
to generate a rich, high-quality, and multimodal action distribution. This core
architecture is complemented by a Density-Progressive Safety Curriculum (DPSC),
a training mechanism that ensures stable and efficient learning as the agent
progresses from sparse to high-density traffic environments. Extensive
simulation experiments demonstrate that the proposed method significantly
outperforms a suite of state-of-the-art DRL benchmarks. Most critically, in the
most challenging high-density scenarios, Diffusion-AC not only maintains a high
success rate of 94.1% but also reduces the incidence of Near Mid-Air Collisions
(NMACs) by approximately 59% compared to the next-best-performing baseline,
significantly enhancing the system's safety margin. This performance leap stems
from its unique multimodal decision-making capability, which allows the agent
to flexibly switch to effective alternative maneuvers.

</details>


### [32] [Learning When to Plan: Efficiently Allocating Test-Time Compute for LLM Agents](https://arxiv.org/abs/2509.03581)
*Davide Paglieri,Bartłomiej Cupiał,Jonathan Cook,Ulyana Piterbarg,Jens Tuyls,Edward Grefenstette,Jakob Nicolaus Foerster,Jack Parker-Holder,Tim Rocktäschel*

Main category: cs.AI

TL;DR: 提出动态规划框架，让LLM智能体灵活决定何时进行规划，通过两阶段训练（监督微调+强化学习）在长时程任务中实现更高效的样本利用和复杂目标达成


<details>
  <summary>Details</summary>
Motivation: 现有方法如ReAct要求LLM在每次行动前都进行规划，这在计算上昂贵且会降低长时程任务性能，而完全不规划又会限制性能表现

Method: 两阶段训练管道：1）在多样化合成数据上进行监督微调，为动态规划做准备；2）在长时程环境中使用强化学习来精炼这种能力

Result: 在Crafter环境中的实验表明，动态规划智能体更样本高效，能持续达成更复杂目标，且能被人类编写的规划有效引导，超越独立能力

Conclusion: 这是首个探索训练LLM智能体在序列决策任务中进行动态测试时计算分配的工作，为更高效、自适应和可控的智能体系统铺平道路

Abstract: Training large language models (LLMs) to reason via reinforcement learning
(RL) significantly improves their problem-solving capabilities. In agentic
settings, existing methods like ReAct prompt LLMs to explicitly plan before
every action; however, we demonstrate that always planning is computationally
expensive and degrades performance on long-horizon tasks, while never planning
further limits performance. To address this, we introduce a conceptual
framework formalizing dynamic planning for LLM agents, enabling them to
flexibly decide when to allocate test-time compute for planning. We propose a
simple two-stage training pipeline: (1) supervised fine-tuning on diverse
synthetic data to prime models for dynamic planning, and (2) RL to refine this
capability in long-horizon environments. Experiments on the Crafter environment
show that dynamic planning agents trained with this approach are more
sample-efficient and consistently achieve more complex objectives.
Additionally, we demonstrate that these agents can be effectively steered by
human-written plans, surpassing their independent capabilities. To our
knowledge, this work is the first to explore training LLM agents for dynamic
test-time compute allocation in sequential decision-making tasks, paving the
way for more efficient, adaptive, and controllable agentic systems.

</details>


### [33] [Explainable Knowledge Graph Retrieval-Augmented Generation (KG-RAG) with KG-SMILE](https://arxiv.org/abs/2509.03626)
*Zahra Zehtabi Sabeti Moghaddam,Zeinab Dehghani,Maneeha Rani,Koorosh Aslansefat,Bhupesh Kumar Mishra,Rameez Raja Kureshi,Dhavalkumar Thakker*

Main category: cs.AI

TL;DR: 基于知识图的RAG解释框架KG-SMILE，通过平滑演化和线性代理模型揭示图实体和关系对生成结果的影响，提升了模型的可解释性和可信赖性。


<details>
  <summary>Details</summary>
Motivation: 解决生成式AI在敏感领域中的幻觉问题和RAG系统的黑盒特性，提升模型的透明度和可解释性。

Method: 开发KG-SMILE框架，通过控制演化、计算相似度和训练加权线性代理模型来识别图论基RAG中最关键的实体和关系。

Result: KG-SMILE在忍耐度、忠实性、一致性、稳定性和准确性等评估指标上表现优异，能够产生稳定且与人类偏好对齐的解释。

Conclusion: KG-SMILE能够在保持模型效果的同时提升可解释性，促进机器学习技术的更大透明度和可信赖性。

Abstract: Generative AI, such as Large Language Models (LLMs), has achieved impressive
progress but still produces hallucinations and unverifiable claims, limiting
reliability in sensitive domains. Retrieval-Augmented Generation (RAG) improves
accuracy by grounding outputs in external knowledge, especially in domains like
healthcare, where precision is vital. However, RAG remains opaque and
essentially a black box, heavily dependent on data quality. We developed a
method-agnostic, perturbation-based framework that provides token and
component-level interoperability for Graph RAG using SMILE and named it as
Knowledge-Graph (KG)-SMILE. By applying controlled perturbations, computing
similarities, and training weighted linear surrogates, KG-SMILE identifies the
graph entities and relations most influential to generated outputs, thereby
making RAG more transparent. We evaluate KG-SMILE using comprehensive
attribution metrics, including fidelity, faithfulness, consistency, stability,
and accuracy. Our findings show that KG-SMILE produces stable, human-aligned
explanations, demonstrating its capacity to balance model effectiveness with
interpretability and thereby fostering greater transparency and trust in
machine learning technologies.

</details>


### [34] [CausalARC: Abstract Reasoning with Causal World Models](https://arxiv.org/abs/2509.03636)
*Jacqueline Maasch,John Kalantari,Kia Khezeli*

Main category: cs.AI

TL;DR: CausalARC是一个用于AI推理的测试平台，专注于低数据和分布外场景，基于因果世界模型提供观察、干预和反事实反馈。


<details>
  <summary>Details</summary>
Motivation: 推理需要在有限数据和分布偏移下适应新问题设置，需要测试AI系统在低数据和分布外环境中的推理能力。

Method: 构建基于结构因果模型的因果世界模型，提供原则性数据增强，包括观察、干预和反事实反馈，支持少样本上下文学习演示。

Result: 作为概念验证，展示了CausalARC在四个语言模型评估设置中的应用：测试时训练的抽象推理、上下文学习的反事实推理、程序合成以及逻辑推理的因果发现。

Conclusion: CausalARC为评估AI系统在因果推理和分布外泛化能力方面提供了一个形式化且可控制的测试环境。

Abstract: Reasoning requires adaptation to novel problem settings under limited data
and distribution shift. This work introduces CausalARC: an experimental testbed
for AI reasoning in low-data and out-of-distribution regimes, modeled after the
Abstraction and Reasoning Corpus (ARC). Each CausalARC reasoning task is
sampled from a fully specified causal world model, formally expressed as a
structural causal model. Principled data augmentations provide observational,
interventional, and counterfactual feedback about the world model in the form
of few-shot, in-context learning demonstrations. As a proof-of-concept, we
illustrate the use of CausalARC for four language model evaluation settings:
(1) abstract reasoning with test-time training, (2) counterfactual reasoning
with in-context learning, (3) program synthesis, and (4) causal discovery with
logical reasoning.

</details>


### [35] [Towards a Neurosymbolic Reasoning System Grounded in Schematic Representations](https://arxiv.org/abs/2509.03644)
*François Olivier,Zied Bouraoui*

Main category: cs.AI

TL;DR: 提出了Embodied-LM系统，通过基于图像图式的符号化空间推理来增强大语言模型的逻辑推理能力，将认知结构与可执行程序相结合。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在逻辑推理方面仍然容易出错，缺乏人类类似的稳健心理表征，需要将理解建立在具身认知结构上。

Method: 使用基于图像图式的符号化表示，通过答案集编程进行声明式空间推理，将认知结构形式化为可执行程序。

Result: 在逻辑推理问题上证明，LLM可以通过具身认知结构解释场景，这些结构可以形式化为可执行程序，支持有效的逻辑推理并提高可解释性。

Conclusion: 虽然当前实现专注于空间原语，但为纳入更复杂和动态的表征建立了计算基础，展示了神经符号系统在增强LLM推理能力方面的潜力。

Abstract: Despite significant progress in natural language understanding, Large
Language Models (LLMs) remain error-prone when performing logical reasoning,
often lacking the robust mental representations that enable human-like
comprehension. We introduce a prototype neurosymbolic system, Embodied-LM, that
grounds understanding and logical reasoning in schematic representations based
on image schemas-recurring patterns derived from sensorimotor experience that
structure human cognition. Our system operationalizes the spatial foundations
of these cognitive structures using declarative spatial reasoning within Answer
Set Programming. Through evaluation on logical deduction problems, we
demonstrate that LLMs can be guided to interpret scenarios through embodied
cognitive structures, that these structures can be formalized as executable
programs, and that the resulting representations support effective logical
reasoning with enhanced interpretability. While our current implementation
focuses on spatial primitives, it establishes the computational foundation for
incorporating more complex and dynamic representations.

</details>


### [36] [Emergent Hierarchical Reasoning in LLMs through Reinforcement Learning](https://arxiv.org/abs/2509.03646)
*Haozhe Wang,Qixin Xu,Che Liu,Junhong Wu,Fangzhen Lin,Wenhu Chen*

Main category: cs.AI

TL;DR: 论文揭示了RL提升LLM推理能力的机制是通过层次化推理结构，提出了HICRA算法专注于高层规划token，显著提升性能


<details>
  <summary>Details</summary>
Motivation: 理解RL为何能有效提升大语言模型的复杂推理能力，揭示其背后的工作机制和现象本质

Method: 分析推理层次结构，提出HIerarchy-Aware Credit Assignment (HICRA)算法，专注于高层战略规划token的优化

Result: HICRA算法显著优于现有基线方法，验证了语义熵是衡量战略探索的更好指标

Conclusion: 聚焦战略瓶颈是解锁高级推理的关键，层次化信用分配机制能更高效地提升模型推理能力

Abstract: Reinforcement Learning (RL) has proven highly effective at enhancing the
complex reasoning abilities of Large Language Models (LLMs), yet underlying
mechanisms driving this success remain largely opaque. Our analysis reveals
that puzzling phenomena like ``aha moments", ``length-scaling'' and entropy
dynamics are not disparate occurrences but hallmarks of an emergent reasoning
hierarchy, akin to the separation of high-level strategic planning from
low-level procedural execution in human cognition. We uncover a compelling
two-phase dynamic: initially, a model is constrained by procedural correctness
and must improve its low-level skills. The learning bottleneck then decisively
shifts, with performance gains being driven by the exploration and mastery of
high-level strategic planning. This insight exposes a core inefficiency in
prevailing RL algorithms like GRPO, which apply optimization pressure
agnostically and dilute the learning signal across all tokens. To address this,
we propose HIerarchy-Aware Credit Assignment (HICRA), an algorithm that
concentrates optimization efforts on high-impact planning tokens. HICRA
significantly outperforms strong baselines, demonstrating that focusing on this
strategic bottleneck is key to unlocking advanced reasoning. Furthermore, we
validate semantic entropy as a superior compass for measuring strategic
exploration over misleading metrics such as token-level entropy.

</details>


### [37] [An Empirical Evaluation of Factors Affecting SHAP Explanation of Time Series Classification](https://arxiv.org/abs/2509.03649)
*Davide Italo Serramazza,Nikos Papadeas,Zahraa Abdallah,Georgiana Ifrim*

Main category: cs.AI

TL;DR: 时间序列分类中SHAP解释方法的计算复杂性问题，通过分段策略提高效率，研究发现分段数量比分段算法更重要，均等分段效果最佳


<details>
  <summary>Details</summary>
Motivation: 解决SHAP在长时间序列中计算复杂度过高的问题，通过分段策略提高解释效率

Method: 研究八种不同时间序列分段算法，使用InterpretTime和AUC Difference评估方法，在单复变量时间序列上进行实验

Result: 分段数量对解释质量影响更大，均等分段方法表现最佳，新的归一化技术能提升归因质量

Conclusion: 均等分段简单有效，分段长度权重归一化能显著改善SHAP在时间序列中的解释性能

Abstract: Explainable AI (XAI) has become an increasingly important topic for
understanding and attributing the predictions made by complex Time Series
Classification (TSC) models. Among attribution methods, SHapley Additive
exPlanations (SHAP) is widely regarded as an excellent attribution method; but
its computational complexity, which scales exponentially with the number of
features, limits its practicality for long time series. To address this, recent
studies have shown that aggregating features via segmentation, to compute a
single attribution value for a group of consecutive time points, drastically
reduces SHAP running time. However, the choice of the optimal segmentation
strategy remains an open question. In this work, we investigated eight
different Time Series Segmentation algorithms to understand how segment
compositions affect the explanation quality. We evaluate these approaches using
two established XAI evaluation methodologies: InterpretTime and AUC Difference.
Through experiments on both Multivariate (MTS) and Univariate Time Series
(UTS), we find that the number of segments has a greater impact on explanation
quality than the specific segmentation method. Notably, equal-length
segmentation consistently outperforms most of the custom time series
segmentation algorithms. Furthermore, we introduce a novel attribution
normalisation technique that weights segments by their length and we show that
it consistently improves attribution quality.

</details>


### [38] [PersonaTeaming: Exploring How Introducing Personas Can Improve Automated AI Red-Teaming](https://arxiv.org/abs/2509.03728)
*Wesley Hanwen Deng,Sunnie S. Y. Kim,Akshita Jha,Ken Holstein,Motahhare Eslami,Lauren Wilcox,Leon A Gatys*

Main category: cs.AI

TL;DR: 人格化红队测试方法PersonaTeaming，通过在对手提示生成中引入不同人设来提高攻击成功率和探索更广泛的风险类型


<details>
  <summary>Details</summary>
Motivation: 现有自动化红队测试方法忽视了人员身份和背景对测试策略的影响，无法反映不同群体可能发现的风险

Method: 提出PersonaTeaming方法：1)使用专家或普通用户人设进行提示突变 2)动态人设生成算法适应不同提示 3)新的突变距离测量指标

Result: 实验结果显示攻击成功率最高提升144.1%，同时保持提示多样性，超过现有最佳方法RainbowPlus

Conclusion: 人设突变能够有效提升自动化红队测试效果，为自动化与人工红队测试的补充探索了新方向

Abstract: Recent developments in AI governance and safety research have called for
red-teaming methods that can effectively surface potential risks posed by AI
models. Many of these calls have emphasized how the identities and backgrounds
of red-teamers can shape their red-teaming strategies, and thus the kinds of
risks they are likely to uncover. While automated red-teaming approaches
promise to complement human red-teaming by enabling larger-scale exploration of
model behavior, current approaches do not consider the role of identity. As an
initial step towards incorporating people's background and identities in
automated red-teaming, we develop and evaluate a novel method, PersonaTeaming,
that introduces personas in the adversarial prompt generation process to
explore a wider spectrum of adversarial strategies. In particular, we first
introduce a methodology for mutating prompts based on either "red-teaming
expert" personas or "regular AI user" personas. We then develop a dynamic
persona-generating algorithm that automatically generates various persona types
adaptive to different seed prompts. In addition, we develop a set of new
metrics to explicitly measure the "mutation distance" to complement existing
diversity measurements of adversarial prompts. Our experiments show promising
improvements (up to 144.1%) in the attack success rates of adversarial prompts
through persona mutation, while maintaining prompt diversity, compared to
RainbowPlus, a state-of-the-art automated red-teaming method. We discuss the
strengths and limitations of different persona types and mutation methods,
shedding light on future opportunities to explore complementarities between
automated and human red-teaming approaches.

</details>


### [39] [The Personality Illusion: Revealing Dissociation Between Self-Reports & Behavior in LLMs](https://arxiv.org/abs/2509.03730)
*Pengrui Han,Rafal Kocielnik,Peiyang Song,Ramit Debnath,Dean Mobbs,Anima Anandkumar,R. Michael Alvarez*

Main category: cs.AI

TL;DR: 本研究系统分析了LLM的人格特质，发现指令对齐能稳定特质表达但自报特质无法可靠预测行为，人格注入对行为影响有限，挑战了LLM人格的现有假设。


<details>
  <summary>Details</summary>
Motivation: 理解LLM是否表现出类似人类的人格特质模式，此前研究主要依赖简化的自我报告和启发式提示，缺乏行为验证。

Method: 从三个维度系统表征LLM人格：(1)训练阶段特质配置的动态演变；(2)自报特质在行为任务中的预测效度；(3)人格注入等干预措施对自报和行为的影响。

Result: 指令对齐显著稳定特质表达并增强特质相关性，但自报特质无法可靠预测行为，人格注入能引导自报但行为影响有限。

Conclusion: 需要区分表面特质表达与行为一致性，挑战了LLM人格的假设，强调了对齐和可解释性需要更深层评估。

Abstract: Personality traits have long been studied as predictors of human
behavior.Recent advances in Large Language Models (LLMs) suggest similar
patterns may emerge in artificial systems, with advanced LLMs displaying
consistent behavioral tendencies resembling human traits like agreeableness and
self-regulation. Understanding these patterns is crucial, yet prior work
primarily relied on simplified self-reports and heuristic prompting, with
little behavioral validation. In this study, we systematically characterize LLM
personality across three dimensions: (1) the dynamic emergence and evolution of
trait profiles throughout training stages; (2) the predictive validity of
self-reported traits in behavioral tasks; and (3) the impact of targeted
interventions, such as persona injection, on both self-reports and behavior.
Our findings reveal that instructional alignment (e.g., RLHF, instruction
tuning) significantly stabilizes trait expression and strengthens trait
correlations in ways that mirror human data. However, these self-reported
traits do not reliably predict behavior, and observed associations often
diverge from human patterns. While persona injection successfully steers
self-reports in the intended direction, it exerts little or inconsistent effect
on actual behavior. By distinguishing surface-level trait expression from
behavioral consistency, our findings challenge assumptions about LLM
personality and underscore the need for deeper evaluation in alignment and
interpretability.

</details>


### [40] [Are LLM Agents Behaviorally Coherent? Latent Profiles for Social Simulation](https://arxiv.org/abs/2509.03736)
*James Mooney,Josef Woldense,Zheng Robert Jia,Shirley Anugrah Hayati,My Ha Nguyen,Vipul Raheja,Dongyeop Kang*

Main category: cs.AI

TL;DR: 大语言模型在人类实验研究中作为代理人时存在内部不一致性问题，虽然能生成与人类相似的回答，但在不同实验环境下行为不一致


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型作为人类实验研究的代理人的能力，特别是关注其内部一致性而非仅仅是与人类数据的匹配度

Method: 设计了一个研究，包括(a)揭示代理人的内部状态，(b)在基础对话环境中检查代理人行为，通过行为偏好偏评估代理人对话行为是否与其揭示的内部状态一致

Result: 发现不同模型家族和不同模型大小的LLMs都存在显著的内部不一致性，虽然代理人可能生成与人类对应者相似的回答，但无法保持内部一致性

Conclusion: 大语言模型在人类实验研究中作为代理人的能力存在重要缺陷，即但能生成表面上相似的数据，但内部不一致性影响了其作为真实参与者代替品的准确性

Abstract: The impressive capabilities of Large Language Models (LLMs) have fueled the
notion that synthetic agents can serve as substitutes for real participants in
human-subject research. In an effort to evaluate the merits of this claim,
social science researchers have largely focused on whether LLM-generated survey
data corresponds to that of a human counterpart whom the LLM is prompted to
represent. In contrast, we address a more fundamental question: Do agents
maintain internal consistency, retaining similar behaviors when examined under
different experimental settings? To this end, we develop a study designed to
(a) reveal the agent's internal state and (b) examine agent behavior in a basic
dialogue setting. This design enables us to explore a set of behavioral
hypotheses to assess whether an agent's conversation behavior is consistent
with what we would expect from their revealed internal state. Our findings on
these hypotheses show significant internal inconsistencies in LLMs across model
families and at differing model sizes. Most importantly, we find that, although
agents may generate responses matching those of their human counterparts, they
fail to be internally consistent, representing a critical gap in their
capabilities to accurately substitute for real participants in human-subject
research. Our simulation code and data are publicly accessible.

</details>


### [41] [RAGuard: A Novel Approach for in-context Safe Retrieval Augmented Generation for LLMs](https://arxiv.org/abs/2509.03768)
*Connor Walker,Koorosh Aslansefat,Mohammad Naveed Akram,Yiannis Papadopoulos*

Main category: cs.AI

TL;DR: RAGuard是一个增强的RAG框架，专门为海上风电维护设计，通过并行查询技术手册和安全文档，确保技术深度和安全覆盖，将安全召回率从接近0%提升到50%以上。


<details>
  <summary>Details</summary>
Motivation: 传统大型语言模型在高度专业化或意外场景中经常失败，无法满足海上风电维护对准确性和安全性的严格要求。

Method: 提出RAGuard框架，通过并行查询两个索引（技术知识库和安全文档库），分配独立的检索预算；进一步开发SafetyClamp扩展，获取更大的候选池并进行硬钳位处理。

Result: 在稀疏、密集和混合检索范式下，RAGuard将安全召回率从接近0%提升到50%以上，同时保持技术召回率在60%以上。

Conclusion: RAGuard和SafetyClamp有潜力为关键维护场景中的LLM决策支持建立新的安全保证标准。

Abstract: Accuracy and safety are paramount in Offshore Wind (OSW) maintenance, yet
conventional Large Language Models (LLMs) often fail when confronted with
highly specialised or unexpected scenarios. We introduce RAGuard, an enhanced
Retrieval-Augmented Generation (RAG) framework that explicitly integrates
safety-critical documents alongside technical manuals.By issuing parallel
queries to two indices and allocating separate retrieval budgets for knowledge
and safety, RAGuard guarantees both technical depth and safety coverage. We
further develop a SafetyClamp extension that fetches a larger candidate pool,
"hard-clamping" exact slot guarantees to safety. We evaluate across sparse
(BM25), dense (Dense Passage Retrieval) and hybrid retrieval paradigms,
measuring Technical Recall@K and Safety Recall@K. Both proposed extensions of
RAG show an increase in Safety Recall@K from almost 0\% in RAG to more than
50\% in RAGuard, while maintaining Technical Recall above 60\%. These results
demonstrate that RAGuard and SafetyClamp have the potential to establish a new
standard for integrating safety assurance into LLM-powered decision support in
critical maintenance contexts.

</details>


### [42] [Leveraging LLM-Based Agents for Intelligent Supply Chain Planning](https://arxiv.org/abs/2509.03811)
*Yongzhi Qi,Jiaheng Yin,Jianshen Zhang,Dongyang Geng,Zhengyu Chen,Hao Hu,Wei Qi,Zuo-Jun Max Shen*

Main category: cs.AI

TL;DR: 基于大语言模型的供应链规划机器人框架，能够理解领域知识、分解任务、使用工具并生成有根据的规划报告，在真实场景中提升效率和准确性


<details>
  <summary>Details</summary>
Motivation: 解决电子商务平台供应链规划中的实践挑战，包括数据收集、长期规划制定、动态调整以及确保解释性、效率和可靠性

Method: 构建供应链规划机器人（SCPA）框架，利用大语言模型理解领域知识和运营商需求，进行任务分解，利用或创建工具，生成基于证据的规划报告

Result: 在JD.com真实场景中部署，证明了LLM-agent在供应链中的可行性，有效减少人工工作量，提高了准确性、库存可用性等关键指标

Conclusion: 大语言模型为供应链规划问题提供了新的解决方案，SCPA框架在真实业务环境中表现出良好的效果和应用潜力

Abstract: In supply chain management, planning is a critical concept. The movement of
physical products across different categories, from suppliers to warehouse
management, to sales, and logistics transporting them to customers, entails the
involvement of many entities. It covers various aspects such as demand
forecasting, inventory management, sales operations, and replenishment. How to
collect relevant data from an e-commerce platform's perspective, formulate
long-term plans, and dynamically adjust them based on environmental changes,
while ensuring interpretability, efficiency, and reliability, is a practical
and challenging problem. In recent years, the development of AI technologies,
especially the rapid progress of large language models, has provided new tools
to address real-world issues. In this work, we construct a Supply Chain
Planning Agent (SCPA) framework that can understand domain knowledge,
comprehend the operator's needs, decompose tasks, leverage or create new tools,
and return evidence-based planning reports. We deploy this framework in
JD.com's real-world scenario, demonstrating the feasibility of LLM-agent
applications in the supply chain. It effectively reduced labor and improved
accuracy, stock availability, and other key metrics.

</details>


### [43] [Learning to Deliberate: Meta-policy Collaboration for Agentic LLMs with Multi-agent Reinforcement Learning](https://arxiv.org/abs/2509.03817)
*Wei Yang,Jesse Thomason*

Main category: cs.AI

TL;DR: 提出了Meta-Policy Deliberation Framework (MPDF)和SoftRankPO算法，通过让LLM智能体学习元认知策略，在多智能体推理任务上实现了4-5%的准确率提升


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统采用固定的协作协议，忽视了智能体内部的审议能力，将智能体视为被动执行者，无法根据不确定性或置信度等内部认知状态调整策略

Method: MPDF框架让智能体学习去中心化的元认知动作策略（Persist、Refine、Concede），并开发SoftRankPO强化学习算法，通过基于平滑正态分位数映射的奖励排序来稳定训练

Result: 在五个数学和通用推理基准测试中，MPDF+SoftRankPO相比六种最先进的启发式和基于学习的多智能体推理算法，平均准确率绝对提升了4-5%

Conclusion: 该工作提出了学习自适应元认知策略的新范式，将重点从设计固定协议转向学习动态审议策略

Abstract: Multi-agent systems of large language models (LLMs) show promise for complex
reasoning, but their effectiveness is often limited by fixed collaboration
protocols. These frameworks typically focus on macro-level orchestration while
overlooking agents' internal deliberative capabilities. This critical
meta-cognitive blindspot treats agents as passive executors unable to adapt
their strategy based on internal cognitive states like uncertainty or
confidence. We introduce the Meta-Policy Deliberation Framework (MPDF), where
agents learn a decentralized policy over a set of high-level meta-cognitive
actions: Persist, Refine, and Concede. To overcome the instability of
traditional policy gradients in this setting, we develop SoftRankPO, a novel
reinforcement learning algorithm. SoftRankPO stabilizes training by shaping
advantages based on the rank of rewards mapped through smooth normal quantiles,
making the learning process robust to reward variance. Experiments show that
MPDF with SoftRankPO achieves a a 4-5% absolute gain in average accuracy across
five mathematical and general reasoning benchmarks compared to six
state-of-the-art heuristic and learning-based multi-agent reasoning algorithms.
Our work presents a paradigm for learning adaptive, meta-cognitive policies for
multi-agent LLM systems, shifting the focus from designing fixed protocols to
learning dynamic, deliberative strategies.

</details>


### [44] [What Would an LLM Do? Evaluating Policymaking Capabilities of Large Language Models](https://arxiv.org/abs/2509.03827)
*Pierre Le Coz,Jia An Liu,Debarun Bhattacharjya,Georgina Curto,Serge Stinckwich*

Main category: cs.AI

TL;DR: 评估大语言模型在无家可归问题政策制定中与领域专家的一致性，开发包含四个地区政策选择的新基准，并通过基于代理的模型模拟社会影响。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理非结构化数据、探索灵活场景和处理多样化情境因素方面具有独特优势，可能为复杂的社会政策制定提供新见解，特别是在影响全球1.5亿人的无家可归问题上。

Method: 开发包含美国、西班牙、南非和中国四个地区政策选择的新基准，基于人类发展能力方法概念框架，建立自动化管道将基准政策连接到基于代理的模型，通过模拟社会场景探索政策的社会影响。

Result: 研究结果显示利用大语言模型进行社会政策制定具有良好潜力，在负责任护栏和情境校准的配合下，大语言模型能够以规模化替代政策的形式为人类提供有价值的见解。

Conclusion: 如果与当地领域专家合作引入负责任的护栏和情境校准，大语言模型可以为社会政策制定提供有价值的规模化见解，显示出在该领域应用的巨大潜力。

Abstract: Large language models (LLMs) are increasingly being adopted in high-stakes
domains. Their capacity to process vast amounts of unstructured data, explore
flexible scenarios, and handle a diversity of contextual factors can make them
uniquely suited to provide new insights for the complexity of social
policymaking. This article evaluates whether LLMs' are aligned with domain
experts (and among themselves) to inform social policymaking on the subject of
homelessness alleviation - a challenge affecting over 150 million people
worldwide. We develop a novel benchmark comprised of decision scenarios with
policy choices across four geographies (South Bend, USA; Barcelona, Spain;
Johannesburg, South Africa; Macau SAR, China). The policies in scope are
grounded in the conceptual framework of the Capability Approach for human
development. We also present an automated pipeline that connects the
benchmarked policies to an agent-based model, and we explore the social impact
of the recommended policies through simulated social scenarios. The paper
results reveal promising potential to leverage LLMs for social policy making.
If responsible guardrails and contextual calibrations are introduced in
collaboration with local domain experts, LLMs can provide humans with valuable
insights, in the form of alternative policies at scale.

</details>


### [45] [An Agentic Model Context Protocol Framework for Medical Concept Standardization](https://arxiv.org/abs/2509.03828)
*Jaerong Ahn,Andrew Wen,Nan Wang,Heling Jia,Zhiyi Yue,Sunyang Fu,Hongfang Liu*

Main category: cs.AI

TL;DR: 基于Model Context Protocol的无训练、防幻觉映射的OMOP CDM医学术语映射系统，通过外部资源查询提高映射准确性和效率


<details>
  <summary>Details</summary>
Motivation: OMOP CDM标准化过程中的源医学术语向标准概念映射工作资源涉及且容易出错，而大语言模型存在幻觉问题不适合直接临床部署

Method: 基于Model Context Protocol(MCP)标准化框架，让LLM与外部资源和工具交互，实现零训练、可解释的映射系统

Result: 系统能够提供实时词汇查询和结构化推理输出，显著提高效率和准确性，适用于探索性和生产环境

Conclusion: 该方法为OMOP CDM数据标准化提供了一种高效、准确且可靠的自动化映射解决方案，免去了训练成本和专家验证的需求

Abstract: The Observational Medical Outcomes Partnership (OMOP) common data model (CDM)
provides a standardized representation of heterogeneous health data to support
large-scale, multi-institutional research. One critical step in data
standardization using OMOP CDM is the mapping of source medical terms to OMOP
standard concepts, a procedure that is resource-intensive and error-prone.
While large language models (LLMs) have the potential to facilitate this
process, their tendency toward hallucination makes them unsuitable for clinical
deployment without training and expert validation. Here, we developed a
zero-training, hallucination-preventive mapping system based on the Model
Context Protocol (MCP), a standardized and secure framework allowing LLMs to
interact with external resources and tools. The system enables explainable
mapping and significantly improves efficiency and accuracy with minimal effort.
It provides real-time vocabulary lookups and structured reasoning outputs
suitable for immediate use in both exploratory and production environments.

</details>


### [46] [A Multidimensional AI-powered Framework for Analyzing Tourist Perception in Historic Urban Quarters: A Case Study in Shanghai](https://arxiv.org/abs/2509.03830)
*Kaizhen Tan,Yufan Wu,Yuxuan Liu,Haoran Zeng*

Main category: cs.AI

TL;DR: 一种多模态AI框架，通过社交媒体数据分析游客对历史城区的视觉、艺术偏好和情感反应，为可持续城市规划提供数据支撑。


<details>
  <summary>Details</summary>
Motivation: 历史城区在保护文化遗产和促进旅游方面具有重要价值，了解游客对这些环境的感知对人本为中心的可持续城市规划至关重要。

Method: 采用多模态AI框架，整合焦点提取、颜色主题分析和情感挖掘。使用精调语义分割模型识别视觉焦点，聚类方法提取主导颜色，重应用规则基础方法和多任务BERT模型进行情感分析。

Result: 发现了美学吸引力和情感反应的空间差异，社交媒体照片与实际街道景观之间存在显著颜色偏差，反映了视觉期望与建筑环境之间的潜在差距。

Conclusion: 该框架提供了一种整合的、数据驱动的方法来解码游客感知，为旅游业、遗产保护和公共空间设计的知情决策做出了贡献。

Abstract: Historic urban quarters play a vital role in preserving cultural heritage
while serving as vibrant spaces for tourism and everyday life. Understanding
how tourists perceive these environments is essential for sustainable,
human-centered urban planning. This study proposes a multidimensional
AI-powered framework for analyzing tourist perception in historic urban
quarters using multimodal data from social media. Applied to twelve historic
quarters in central Shanghai, the framework integrates focal point extraction,
color theme analysis, and sentiment mining. Visual focus areas are identified
from tourist-shared photos using a fine-tuned semantic segmentation model. To
assess aesthetic preferences, dominant colors are extracted using a clustering
method, and their spatial distribution across quarters is analyzed. Color
themes are further compared between social media photos and real-world street
views, revealing notable shifts. This divergence highlights potential gaps
between visual expectations and the built environment, reflecting both
stylistic preferences and perceptual bias. Tourist reviews are evaluated
through a hybrid sentiment analysis approach combining a rule-based method and
a multi-task BERT model. Satisfaction is assessed across four dimensions:
tourist activities, built environment, service facilities, and business
formats. The results reveal spatial variations in aesthetic appeal and
emotional response. Rather than focusing on a single technical innovation, this
framework offers an integrated, data-driven approach to decoding tourist
perception and contributes to informed decision-making in tourism, heritage
conservation, and the design of aesthetically engaging public spaces.

</details>


### [47] [Continuous Monitoring of Large-Scale Generative AI via Deterministic Knowledge Graph Structures](https://arxiv.org/abs/2509.03857)
*Kishor Datta Gupta,Mohd Ariful Haque,Hasmot Ali,Marufa Kamal,Syed Bahauddin Alam,Mohammad Ashiqur Rahman*

Main category: cs.AI

TL;DR: 使用知识图构建确定性KG和LLM生成KG的实时对比监控框架，通过结构指标评估生成式AI的可靠性和发现异常


<details>
  <summary>Details</summary>
Motivation: 解决生成式AI存在的幻觉、语义漫游、偏见等可靠性问题，充当黑盒模型评估主要依靠主观人工评判的缺陷

Method: 构建两种并行知识图：确定性KG（规则基础）和LLM生成KG（实时文本数据），采用ICR、IPR、CI等KG指标计算结构偏差，通过历史数据设置动态异常阈值

Result: 开发了一个自动化实时监控框架，能够主动识别和标记显著偏差，及时发现语义异常或幻觉

Conclusion: 通过结构化、指标驱动的KG对比方法，提供了一个健壮可扩展的生成式AI可靠性评估框架

Abstract: Generative AI (GEN AI) models have revolutionized diverse application domains
but present substantial challenges due to reliability concerns, including
hallucinations, semantic drift, and inherent biases. These models typically
operate as black-boxes, complicating transparent and objective evaluation.
Current evaluation methods primarily depend on subjective human assessment,
limiting scalability, transparency, and effectiveness. This research proposes a
systematic methodology using deterministic and Large Language Model
(LLM)-generated Knowledge Graphs (KGs) to continuously monitor and evaluate GEN
AI reliability. We construct two parallel KGs: (i) a deterministic KG built
using explicit rule-based methods, predefined ontologies, domain-specific
dictionaries, and structured entity-relation extraction rules, and (ii) an
LLM-generated KG dynamically derived from real-time textual data streams such
as live news articles. Utilizing real-time news streams ensures authenticity,
mitigates biases from repetitive training, and prevents adaptive LLMs from
bypassing predefined benchmarks through feedback memorization. To quantify
structural deviations and semantic discrepancies, we employ several established
KG metrics, including Instantiated Class Ratio (ICR), Instantiated Property
Ratio (IPR), and Class Instantiation (CI). An automated real-time monitoring
framework continuously computes deviations between deterministic and
LLM-generated KGs. By establishing dynamic anomaly thresholds based on
historical structural metric distributions, our method proactively identifies
and flags significant deviations, thus promptly detecting semantic anomalies or
hallucinations. This structured, metric-driven comparison between deterministic
and dynamically generated KGs delivers a robust and scalable evaluation
framework.

</details>


### [48] [Expedition & Expansion: Leveraging Semantic Representations for Goal-Directed Exploration in Continuous Cellular Automata](https://arxiv.org/abs/2509.03863)
*Sina Khajehabdollahi,Gautier Hamon,Marko Cvjetko,Pierre-Yves Oudeyer,Clément Moulin-Frier,Cédric Colas*

Main category: cs.AI

TL;DR: 提出E&E混合策略，结合局部新颖性搜索和基于VLM的目标导向探索，在连续细胞自动机中发现更多样化的视觉模式


<details>
  <summary>Details</summary>
Motivation: 传统新颖性搜索方法在探索高维行为空间时容易陷入局部最优，无法到达遥远未探索区域，需要新的探索策略来突破局部新颖性边界

Method: E&E混合策略：交替进行局部新颖性驱动的扩展和基于视觉语言模型生成语言目标的目标导向探索，在语义空间中进行新颖性评估和目标生成

Result: 在Flow Lenia连续细胞自动机上测试，E&E比现有方法发现更多样化解决方案，谱系分析显示探险产生的解决方案对长期探索有不成比例的影响

Conclusion: E&E能够突破局部新颖性边界，以人类对齐、可解释的方式探索行为景观，为人工生命等领域的开放探索提供了有前景的模板

Abstract: Discovering diverse visual patterns in continuous cellular automata (CA) is
challenging due to the vastness and redundancy of high-dimensional behavioral
spaces. Traditional exploration methods like Novelty Search (NS) expand locally
by mutating known novel solutions but often plateau when local novelty is
exhausted, failing to reach distant, unexplored regions. We introduce
Expedition and Expansion (E&E), a hybrid strategy where exploration alternates
between local novelty-driven expansions and goal-directed expeditions. During
expeditions, E&E leverages a Vision-Language Model (VLM) to generate linguistic
goals--descriptions of interesting but hypothetical patterns that drive
exploration toward uncharted regions. By operating in semantic spaces that
align with human perception, E&E both evaluates novelty and generates goals in
conceptually meaningful ways, enhancing the interpretability and relevance of
discovered behaviors. Tested on Flow Lenia, a continuous CA known for its rich,
emergent behaviors, E&E consistently uncovers more diverse solutions than
existing exploration methods. A genealogical analysis further reveals that
solutions originating from expeditions disproportionately influence long-term
exploration, unlocking new behavioral niches that serve as stepping stones for
subsequent search. These findings highlight E&E's capacity to break through
local novelty boundaries and explore behavioral landscapes in human-aligned,
interpretable ways, offering a promising template for open-ended exploration in
artificial life and beyond.

</details>


### [49] [FaMA: LLM-Empowered Agentic Assistant for Consumer-to-Consumer Marketplace](https://arxiv.org/abs/2509.03890)
*Yineng Yan,Xidong Wang,Jin Seng Cheng,Ran Hu,Wentao Guan,Nahid Farahmand,Hengte Lin,Yue Li*

Main category: cs.AI

TL;DR: Facebook Marketplace Assistant (FaMA) 是一个基于大语言模型的智能代理助手，通过自然语言交互简化C2C电商平台的复杂操作，实现了98%的任务成功率和2倍的交互速度提升。


<details>
  <summary>Details</summary>
Motivation: C2C电商平台的复杂GUI界面给买卖双方带来了繁琐的操作体验，需要一种更直观、高效的交互方式来简化核心任务流程。

Method: 开发了基于LLM的智能代理FaMA，通过自然语言命令解析来自动化关键高摩擦工作流，为买卖双方提供对话式入口替代传统GUI界面。

Result: FaMA在解决市场复杂任务上达到98%的成功率，交互时间最多可缩短2倍，显著提升了用户体验。

Conclusion: 基于LLM的智能代理对话范式为传统应用界面提供了轻量级、更易访问的替代方案，能够更高效地管理市场活动。

Abstract: The emergence of agentic AI, powered by Large Language Models (LLMs), marks a
paradigm shift from reactive generative systems to proactive, goal-oriented
autonomous agents capable of sophisticated planning, memory, and tool use. This
evolution presents a novel opportunity to address long-standing challenges in
complex digital environments. Core tasks on Consumer-to-Consumer (C2C)
e-commerce platforms often require users to navigate complex Graphical User
Interfaces (GUIs), making the experience time-consuming for both buyers and
sellers. This paper introduces a novel approach to simplify these interactions
through an LLM-powered agentic assistant. This agent functions as a new,
conversational entry point to the marketplace, shifting the primary interaction
model from a complex GUI to an intuitive AI agent. By interpreting natural
language commands, the agent automates key high-friction workflows. For
sellers, this includes simplified updating and renewal of listings, and the
ability to send bulk messages. For buyers, the agent facilitates a more
efficient product discovery process through conversational search. We present
the architecture for Facebook Marketplace Assistant (FaMA), arguing that this
agentic, conversational paradigm provides a lightweight and more accessible
alternative to traditional app interfaces, allowing users to manage their
marketplace activities with greater efficiency. Experiments show FaMA achieves
a 98% task success rate on solving complex tasks on the marketplace and enables
up to a 2x speedup on interaction time.

</details>


### [50] [A Foundation Model for Chest X-ray Interpretation with Grounded Reasoning via Online Reinforcement Learning](https://arxiv.org/abs/2509.03906)
*Qika Lin,Yifan Zhu,Bin Pu,Ling Huang,Haoran Luo,Jingying Ma,Zhen Peng,Tianzhe Zhao,Fangzhi Xu,Jian Zhang,Kai He,Zhonghong Ou,Swapnil Mishra,Mengling Feng*

Main category: cs.AI

TL;DR: DeepMedix-R1是一个用于胸部X光片解读的医疗基础模型，通过三阶段训练流程实现透明推理和局部可解释性，在报告生成和视觉问答任务上显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 当前医疗基础模型以黑盒方式生成答案，缺乏透明的推理过程和局部可解释性，这阻碍了其在临床实践中的部署应用。

Method: 采用顺序训练流程：先在精选的CXR指令数据上微调获得基础解读能力，然后通过高质量合成推理样本实现冷启动推理，最后通过在线强化学习优化推理质量和生成性能。

Result: 在报告生成任务上分别比LLaVA-Rad和MedGemma提升14.54%和31.32%，在视觉问答任务上分别比MedGemma和CheXagent提升57.75%和23.06%。专家评审显示相比Qwen2.5-VL-7B模型具有更高的可解释性和临床合理性。

Conclusion: 该工作推动了医疗基础模型向整体性、透明性和临床可操作性方向发展，为CXR解读提供了更可靠的解决方案。

Abstract: Medical foundation models (FMs) have shown tremendous promise amid the rapid
advancements in artificial intelligence (AI) technologies. However, current
medical FMs typically generate answers in a black-box manner, lacking
transparent reasoning processes and locally grounded interpretability, which
hinders their practical clinical deployments. To this end, we introduce
DeepMedix-R1, a holistic medical FM for chest X-ray (CXR) interpretation. It
leverages a sequential training pipeline: initially fine-tuned on curated CXR
instruction data to equip with fundamental CXR interpretation capabilities,
then exposed to high-quality synthetic reasoning samples to enable cold-start
reasoning, and finally refined via online reinforcement learning to enhance
both grounded reasoning quality and generation performance. Thus, the model
produces both an answer and reasoning steps tied to the image's local regions
for each query. Quantitative evaluation demonstrates substantial improvements
in report generation (e.g., 14.54% and 31.32% over LLaVA-Rad and MedGemma) and
visual question answering (e.g., 57.75% and 23.06% over MedGemma and CheXagent)
tasks. To facilitate robust assessment, we propose Report Arena, a benchmarking
framework using advanced language models to evaluate answer quality, further
highlighting the superiority of DeepMedix-R1. Expert review of generated
reasoning steps reveals greater interpretability and clinical plausibility
compared to the established Qwen2.5-VL-7B model (0.7416 vs. 0.2584 overall
preference). Collectively, our work advances medical FM development toward
holistic, transparent, and clinically actionable modeling for CXR
interpretation.

</details>


### [51] [Handling Infinite Domain Parameters in Planning Through Best-First Search with Delayed Partial Expansions](https://arxiv.org/abs/2509.03953)
*Ángel Aso-Mollar,Diego Aineto,Enrico Scala,Eva Onaindia*

Main category: cs.AI

TL;DR: 这篇论文提出了一种处理自动规划中控制参数的新方法，将其作为真正的决策点进行系统搜索，而非仅作为约束来处理。


<details>
  <summary>Details</summary>
Motivation: 现有方法将控制参数作为嵌入式约束处理，而非将其视为搜索空间中的真正决策点，这限制了搜索效率。

Method: 提出一种最优优先质量搜索算法，在无限决策空间中进行系统搜索，采用延迟部分扩展的概念，增量地扩展状态后继集。

Result: 算法在某些条件下达到极限完备性，并在涉及控制参数的规划问题中与现有方法竞争性相当。

Conclusion: 该新题搜索算法为处理控制参数提供了一种高效的替代方案，通过明确将其作为决策点处理来提升搜索性能。

Abstract: In automated planning, control parameters extend standard action
representations through the introduction of continuous numeric decision
variables. Existing state-of-the-art approaches have primarily handled control
parameters as embedded constraints alongside other temporal and numeric
restrictions, and thus have implicitly treated them as additional constraints
rather than as decision points in the search space. In this paper, we propose
an efficient alternative that explicitly handles control parameters as true
decision points within a systematic search scheme. We develop a best-first,
heuristic search algorithm that operates over infinite decision spaces defined
by control parameters and prove a notion of completeness in the limit under
certain conditions. Our algorithm leverages the concept of delayed partial
expansion, where a state is not fully expanded but instead incrementally
expands a subset of its successors. Our results demonstrate that this novel
search algorithm is a competitive alternative to existing approaches for
solving planning problems involving control parameters.

</details>


### [52] [World Model Implanting for Test-time Adaptation of Embodied Agents](https://arxiv.org/abs/2509.03956)
*Minjong Yoo,Jinwoo Jang,Sihyung Yoon,Honguk Woo*

Main category: cs.AI

TL;DR: WorMI框架通过将大语言模型与领域特定世界模型进行测试时组合，实现了具身智能体在未见领域的零样本和少样本自适应能力，无需大量数据收集或重新训练。


<details>
  <summary>Details</summary>
Motivation: 解决具身AI中智能体需要大量数据和重新训练才能适应新领域的问题，实现更高效和可扩展的跨域适应。

Method: 采用原型化世界模型检索方法，基于轨迹的抽象表示匹配，结合世界级复合注意力机制，将检索到的世界模型知识整合到智能体策略中。

Result: 在VirtualHome和ALFWorld基准测试中表现出优于多个基于LLM的方法的零样本和少样本性能。

Conclusion: WorMI框架展示了在需要适应性和数据效率的真实世界具身智能体场景中的可扩展部署潜力。

Abstract: In embodied AI, a persistent challenge is enabling agents to robustly adapt
to novel domains without requiring extensive data collection or retraining. To
address this, we present a world model implanting framework (WorMI) that
combines the reasoning capabilities of large language models (LLMs) with
independently learned, domain-specific world models through test-time
composition. By allowing seamless implantation and removal of the world models,
the embodied agent's policy achieves and maintains cross-domain adaptability.
In the WorMI framework, we employ a prototype-based world model retrieval
approach, utilizing efficient trajectory-based abstract representation
matching, to incorporate relevant models into test-time composition. We also
develop a world-wise compound attention method that not only integrates the
knowledge from the retrieved world models but also aligns their intermediate
representations with the reasoning model's representation within the agent's
policy. This framework design effectively fuses domain-specific knowledge from
multiple world models, ensuring robust adaptation to unseen domains. We
evaluate our WorMI on the VirtualHome and ALFWorld benchmarks, demonstrating
superior zero-shot and few-shot performance compared to several LLM-based
approaches across a range of unseen domains. These results highlight the
frameworks potential for scalable, real-world deployment in embodied agent
scenarios where adaptability and data efficiency are essential.

</details>


### [53] [Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent](https://arxiv.org/abs/2509.03990)
*Chunlong Wu,Zhibo Qu*

Main category: cs.AI

TL;DR: MPR是一个混合框架，通过将LLM生成的反思整合到结构化元策略内存中，在推理时通过软内存引导解码和硬规则可接受性检查来提高代理性能，无需模型权重更新。


<details>
  <summary>Details</summary>
Motivation: 现有反思策略产生的是短暂的任务特定痕迹，无法跨任务重用；基于强化学习的方法需要大量参数更新和计算。需要一种既能重用纠正知识又保持语言反思适应性的方法。

Method: 提出Meta-Policy Reflexion (MPR)框架，将LLM反思整合为结构化谓词式元策略内存(MPM)，通过软内存引导解码和硬规则可接受性检查两种机制在推理时应用。

Result: 实验结果表明，与Reflexion基线相比，在执行准确性和鲁棒性方面获得一致提升，规则可接受性检查进一步提高了稳定性。

Conclusion: MPR能够外部化可重用的纠正知识，强制执行领域约束减少不安全或无效动作，同时保持基于语言反思的适应性，为多模态和多代理扩展提供了方向。

Abstract: Large language model (LLM) agents achieve impressive single-task performance
but commonly exhibit repeated failures, inefficient exploration, and limited
cross-task adaptability. Existing reflective strategies (e.g., Reflexion,
ReAct) improve per-episode behavior but typically produce ephemeral,
task-specific traces that are not reused across tasks. Reinforcement-learning
based alternatives can produce transferable policies but require substantial
parameter updates and compute. In this work we introduce Meta-Policy Reflexion
(MPR): a hybrid framework that consolidates LLM-generated reflections into a
structured, predicate-like Meta-Policy Memory (MPM) and applies that memory at
inference time through two complementary mechanisms soft memory-guided decoding
and hard rule admissibility checks(HAC). MPR (i) externalizes reusable
corrective knowledge without model weight updates, (ii) enforces domain
constraints to reduce unsafe or invalid actions, and (iii) retains the
adaptability of language-based reflection. We formalize the MPM representation,
present algorithms for update and decoding, and validate the approach in a
text-based agent environment following the experimental protocol described in
the provided implementation (AlfWorld-based). Empirical results reported in the
supplied material indicate consistent gains in execution accuracy and
robustness when compared to Reflexion baselines; rule admissibility further
improves stability. We analyze mechanisms that explain these gains, discuss
scalability and failure modes, and outline future directions for multimodal and
multi?agent extensions.

</details>


### [54] [AutoPBO: LLM-powered Optimization for Local Search PBO Solvers](https://arxiv.org/abs/2509.04007)
*Jinyuan Li,Yi Chu,Yiwen Sun,Mengchuan Zou,Shaowei Cai*

Main category: cs.AI

TL;DR: AutoPBO是一个基于大型语言模型的框架，用于自动优化伪布尔优化(PBO)局部搜索求解器，在多个基准测试中显著优于现有局部搜索方法，并与最先进求解器保持竞争力。


<details>
  <summary>Details</summary>
Motivation: 伪布尔优化(PBO)局部搜索求解器的性能高度依赖内部启发式设计，但传统设计需要大量专家努力和手动调优。大型语言模型在算法设计自动化方面展现潜力，但在PBO求解器优化方面的应用尚未探索。

Method: 提出AutoPBO框架，利用大型语言模型自动增强PBO局部搜索求解器。在四个公共基准测试上进行实验评估，包括真实世界基准、PB竞赛基准、整数线性规划优化基准和组合基准。

Result: AutoPBO相比之前的局部搜索方法有显著改进，同时与六种最先进竞争对手（包括NuPBO、OraSLS、PBO-IHS、RoundingSat、Gurobi和SCIP）保持竞争力。

Conclusion: AutoPBO为自动化局部搜索求解器设计提供了一种有前景的方法，展示了大型语言模型在算法优化领域的应用价值。

Abstract: Pseudo-Boolean Optimization (PBO) provides a powerful framework for modeling
combinatorial problems through pseudo-Boolean (PB) constraints. Local search
solvers have shown excellent performance in PBO solving, and their efficiency
is highly dependent on their internal heuristics to guide the search. Still,
their design often requires significant expert effort and manual tuning in
practice. While Large Language Models (LLMs) have demonstrated potential in
automating algorithm design, their application to optimizing PBO solvers
remains unexplored. In this work, we introduce AutoPBO, a novel LLM-powered
framework to automatically enhance PBO local search solvers. We conduct
experiments on a broad range of four public benchmarks, including one
real-world benchmark, a benchmark from PB competition, an integer linear
programming optimization benchmark, and a crafted combinatorial benchmark, to
evaluate the performance improvement achieved by AutoPBO and compare it with
six state-of-the-art competitors, including two local search PBO solvers NuPBO
and OraSLS, two complete PB solvers PBO-IHS and RoundingSat, and two mixed
integer programming (MIP) solvers Gurobi and SCIP. AutoPBO demonstrates
significant improvements over previous local search approaches, while
maintaining competitive performance compared to state-of-the-art competitors.
The results suggest that AutoPBO offers a promising approach to automating
local search solver design.

</details>


### [55] [CoT-Space: A Theoretical Framework for Internal Slow-Thinking via Reinforcement Learning](https://arxiv.org/abs/2509.04027)
*Zeyu Gan,Hao Yi,Yong Liu*

Main category: cs.AI

TL;DR: 提出了CoT-Space理论框架，将LLM推理从离散的token预测任务重新定义为连续推理级语义空间中的优化过程，解释了最优CoT长度的收敛现象


<details>
  <summary>Details</summary>
Motivation: 传统token级RL框架无法与多步推理过程（如Chain-of-Thought）的推理级性质对齐，存在显著的理论空白

Method: 引入CoT-Space框架，从噪声视角和风险视角分析推理过程，证明最优CoT长度的收敛是欠拟合和过拟合之间基本权衡的自然结果

Result: 广泛的实验为理论发现提供了强有力的实证验证，框架能够合理解释过度思考等经验现象

Conclusion: 该框架不仅为经验现象提供了连贯解释，还为未来开发更有效和可泛化的推理智能体提供了坚实的理论基础

Abstract: Reinforcement Learning (RL) has become a pivotal approach for enhancing the
reasoning capabilities of Large Language Models (LLMs). However, a significant
theoretical gap persists, as traditional token-level RL frameworks fail to
align with the reasoning-level nature of complex, multi-step thought processes
like Chain-of-Thought (CoT). To address this challenge, we introduce CoT-Space,
a novel theoretical framework that recasts LLM reasoning from a discrete
token-prediction task to an optimization process within a continuous,
reasoning-level semantic space. By analyzing this process from both a noise
perspective and a risk perspective, we demonstrate that the convergence to an
optimal CoT length is a natural consequence of the fundamental trade-off
between underfitting and overfitting. Furthermore, extensive experiments
provide strong empirical validation for our theoretical findings. Our framework
not only provides a coherent explanation for empirical phenomena such as
overthinking but also offers a solid theoretical foundation to guide the future
development of more effective and generalizable reasoning agents.

</details>


### [56] [Oruga: An Avatar of Representational Systems Theory](https://arxiv.org/abs/2509.04041)
*Daniel Raggi,Gem Stapleton,Mateja Jamnik,Aaron Stockdill,Grecia Garcia Garcia,Peter C-H. Cheng*

Main category: cs.AI

TL;DR: Oruga是一个实现表示系统理论(RST)的系统，包含核心数据结构、通信语言和结构转换引擎，旨在让机器像人类一样灵活使用不同表示形式


<details>
  <summary>Details</summary>
Motivation: 让机器具备人类灵活使用不同表示形式(如图表、类比)的能力，使其更兼容人类使用方式

Method: 基于表示系统理论(RST)，开发了Oruga系统，包含核心数据结构、专用通信语言和结构转换引擎，采用结构转移方法进行表示转换

Result: 实现了Oruga系统的核心架构和语言，展示了结构转移方法能够执行的表示转换示例

Conclusion: Oruga系统成功实现了RST理论的关键方面，为机器获得人类式灵活表示能力提供了可行框架

Abstract: Humans use representations flexibly. We draw diagrams, change representations
and exploit creative analogies across different domains. We want to harness
this kind of power and endow machines with it to make them more compatible with
human use. Previously we developed Representational Systems Theory (RST) to
study the structure and transformations of representations. In this paper we
present Oruga (caterpillar in Spanish; a symbol of transformation), an
implementation of various aspects of RST. Oruga consists of a core of data
structures corresponding to concepts in RST, a language for communicating with
the core, and an engine for producing transformations using a method we call
structure transfer. In this paper we present an overview of the core and
language of Oruga, with a brief example of the kind of transformation that
structure transfer can execute.

</details>


### [57] [Intermediate Languages Matter: Formal Languages and LLMs affect Neurosymbolic Reasoning](https://arxiv.org/abs/2509.04083)
*Alexander Beiser,David Penz,Nysret Musliu*

Main category: cs.AI

TL;DR: 本文研究发现，在神经符号LLM推理中，选择合适的中间形式语言对推理性能有显著影响，这一因素之前被忽视了。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在形式推理能力方面仍有不足，神经符号LLM推理方法使用LLM作为自然语言到形式语言的翻译器，但影响其成功的关键因素尚不清楚。

Method: 通过比较四种形式语言在三个数据集和七个LLM上的表现，分析形式语言选择对句法和语义推理能力的影响。

Result: 研究发现形式语言的选择确实会影响神经符号推理的性能，并且这种影响在不同LLM之间存在差异。

Conclusion: 中间形式语言的选择是神经符号LLM推理中一个关键但被忽视的因素，需要根据具体任务和模型进行仔细选择。

Abstract: Large language models (LLMs) achieve astonishing results on a wide range of
tasks. However, their formal reasoning ability still lags behind. A promising
approach is Neurosymbolic LLM reasoning. It works by using LLMs as translators
from natural to formal languages and symbolic solvers for deriving correct
results. Still, the contributing factors to the success of Neurosymbolic LLM
reasoning remain unclear. This paper demonstrates that one previously
overlooked factor is the choice of the formal language. We introduce the
intermediate language challenge: selecting a suitable formal language for
neurosymbolic reasoning. By comparing four formal languages across three
datasets and seven LLMs, we show that the choice of formal language affects
both syntactic and semantic reasoning capabilities. We also discuss the varying
effects across different LLMs.

</details>


### [58] [Hybrid Reinforcement Learning and Search for Flight Trajectory Planning](https://arxiv.org/abs/2509.04100)
*Alberto Luise,Michele Lombardi,Florent Teichteil Koenigsbuch*

Main category: cs.AI

TL;DR: 使用强化学习预计计划路径，通过约束搜索空间来加速航空路径规划，在燃油消耗几乎不变的情况下提高计算速度50%


<details>
  <summary>Details</summary>
Motivation: 在紧急情况下快速重新计算航空飞行路径至关重要，需要提高路径规划的计算速度

Method: 训练RL经理预先计算近优路径，然后用这些路径作为约束来缩小路径规划求解器的搜索空间

Result: 在空客A320性能模型上进行实验，燃油消耗与无约束求解器相比偏差通常在1%以内，计算速度提高达50%

Conclusion: 结合RL和搜索基于路径规划器的方法能够在保持路径质量的同时显著提高计算效率，适用于需要快速路径重新规划的紧急情况

Abstract: This paper explores the combination of Reinforcement Learning (RL) and
search-based path planners to speed up the optimization of flight paths for
airliners, where in case of emergency a fast route re-calculation can be
crucial. The fundamental idea is to train an RL Agent to pre-compute
near-optimal paths based on location and atmospheric data and use those at
runtime to constrain the underlying path planning solver and find a solution
within a certain distance from the initial guess. The approach effectively
reduces the size of the solver's search space, significantly speeding up route
optimization. Although global optimality is not guaranteed, empirical results
conducted with Airbus aircraft's performance models show that fuel consumption
remains nearly identical to that of an unconstrained solver, with deviations
typically within 1%. At the same time, computation speed can be improved by up
to 50% as compared to using a conventional solver alone.

</details>


### [59] [Analysis of Bluffing by DQN and CFR in Leduc Hold'em Poker](https://arxiv.org/abs/2509.04125)
*Tarik Zaciragic,Aske Plaat,K. Joost Batenburg*

Main category: cs.AI

TL;DR: 本文研究DQN和CFR算法在Leduc Hold'em扑克游戏中是否表现出诈唬行为，发现两种算法都表现出诈唬但方式不同，成功诈唬率相似，表明诈唬是游戏本身而非算法的特性。


<details>
  <summary>Details</summary>
Motivation: 在扑克游戏中，诈唬是不可预测性的重要技能，但现有计算机扑克研究多关注胜率等性能指标，忽视了诈唬行为的研究。

Method: 设计实验让基于强化学习的DQN算法和基于博弈论的CFR算法在Leduc Hold'em中相互对战，记录并分析它们的行动数据。

Result: DQN和CFR都表现出诈唬行为，但诈唬频率不同；两种算法的成功诈唬率（对手弃牌）大致相同。

Conclusion: 诈唬是扑克游戏本身的基本特性，而非特定算法的特性；未来研究应关注不同诈唬风格和完整扑克游戏。

Abstract: In the game of poker, being unpredictable, or bluffing, is an essential
skill. When humans play poker, they bluff. However, most works on
computer-poker focus on performance metrics such as win rates, while bluffing
is overlooked. In this paper we study whether two popular algorithms, DQN
(based on reinforcement learning) and CFR (based on game theory), exhibit
bluffing behavior in Leduc Hold'em, a simplified version of poker. We designed
an experiment where we let the DQN and CFR agent play against each other while
we log their actions. We find that both DQN and CFR exhibit bluffing behavior,
but they do so in different ways. Although both attempt to perform bluffs at
different rates, the percentage of successful bluffs (where the opponent folds)
is roughly the same. This suggests that bluffing is an essential aspect of the
game, not of the algorithm. Future work should look at different bluffing
styles and at the full game of poker. Code at
https://github.com/TarikZ03/Bluffing-by-DQN-and-CFR-in-Leduc-Hold-em-Poker-Codebase.

</details>


### [60] [The human biological advantage over AI](https://arxiv.org/abs/2509.04130)
*William Stewart*

Main category: cs.AI

TL;DR: 论文认为虽然AI可能在能力上超越人类，但由于缺乏中枢神经系统(CNS)带来的情感体验和道德理解，AI永远无法真正成为宇宙的领导者


<details>
  <summary>Details</summary>
Motivation: 探讨AI是否能够超越人类成为宇宙的领导者，分析人类与AI的根本区别

Method: 通过比较人类中枢神经系统(CNS)与AI系统的本质差异，论证情感体验和道德理解的重要性

Result: AI即使实现意识也无法获得人类通过CNS获得的情感体验和道德理解能力

Conclusion: 宇宙领导权的最佳基础始终是DNA而非硅基，人类因其生物构造而具备AI无法替代的领导资格

Abstract: Recent advances in AI raise the possibility that AI systems will one day be
able to do anything humans can do, only better. If artificial general
intelligence (AGI) is achieved, AI systems may be able to understand, reason,
problem solve, create, and evolve at a level and speed that humans will
increasingly be unable to match, or even understand. These possibilities raise
a natural question as to whether AI will eventually become superior to humans,
a successor "digital species", with a rightful claim to assume leadership of
the universe. However, a deeper consideration suggests the overlooked
differentiator between human beings and AI is not the brain, but the central
nervous system (CNS), providing us with an immersive integration with physical
reality. It is our CNS that enables us to experience emotion including pain,
joy, suffering, and love, and therefore to fully appreciate the consequences of
our actions on the world around us. And that emotional understanding of the
consequences of our actions is what is required to be able to develop
sustainable ethical systems, and so be fully qualified to be the leaders of the
universe. A CNS cannot be manufactured or simulated; it must be grown as a
biological construct. And so, even the development of consciousness will not be
sufficient to make AI systems superior to humans. AI systems may become more
capable than humans on almost every measure and transform our society. However,
the best foundation for leadership of our universe will always be DNA, not
silicon.

</details>


### [61] [Towards an Action-Centric Ontology for Cooking Procedures Using Temporal Graphs](https://arxiv.org/abs/2509.04159)
*Aarush Kumbhakern,Saransh Kumar Gupta,Lipika Dey,Partha Pratim Das*

Main category: cs.AI

TL;DR: 提出了一种可扩展的培专用语言（DSL），通过有向动作图表示烹饪操作，形成时间图结构，支持精确的模型建立和自动化执行。


<details>
  <summary>Details</summary>
Motivation: 烹饪过程的复杂性和模糊性使得形式化表达面临挑战，需要一种结构化方法来模型烹饪流程。

Method: 设计了一种可扩展的培专用语言，将菜谱表示为有向动作图，包含过程、传输、环境、并发性和组合结构。

Result: 通过对英式早餐菜谱的初步手动评估，验证了DSL的表达能力和适用性。

Conclusion: 这项工作是构建以动作为中心的烹饪本体论的初步尝试，为结构化机器理解、精确解释和可扩展的烹饪自动化奠定了基础。

Abstract: Formalizing cooking procedures remains a challenging task due to their
inherent complexity and ambiguity. We introduce an extensible domain-specific
language for representing recipes as directed action graphs, capturing
processes, transfers, environments, concurrency, and compositional structure.
Our approach enables precise, modular modeling of complex culinary workflows.
Initial manual evaluation on a full English breakfast recipe demonstrates the
DSL's expressiveness and suitability for future automated recipe analysis and
execution. This work represents initial steps towards an action-centric
ontology for cooking, using temporal graphs to enable structured machine
understanding, precise interpretation, and scalable automation of culinary
processes - both in home kitchens and professional culinary settings.

</details>


### [62] [Domain size asymptotics for Markov logic networks](https://arxiv.org/abs/2509.04192)
*Vera Koponen*

Main category: cs.AI

TL;DR: 本文研究了马尔可夫逻辑网络（MLN）在域大小趋于无穷时的分布特性，分析了三种具体MLN示例的极限行为，并证明了量化自由MLN与提升贝叶斯网络在渐近意义上的不可比性。


<details>
  <summary>Details</summary>
Motivation: 研究MLN在无限大域上的分布特性，探索不同软约束对随机结构极限行为的影响，以及比较不同概率图模型的渐近表达能力。

Method: 通过分析三种具体MLN示例：（1）单一元关系符号的量化自由MLN；（2）偏好较少三角形的图MLN；（3）偏好较少高度数顶点的图MLN，研究其在大域极限下的行为特性。

Result: 发现软约束的类型和权重对极限行为有不同影响，证明了量化自由MLN与提升贝叶斯网络的渐近不可比性，并显示MLN分布在大域上集中于与均匀分布完全不同的可能世界区域。

Conclusion: MLN的极限行为取决于软约束的具体形式，不同概率图模型在渐近表达能力上存在本质差异，这为理解大规模概率推理系统的行为提供了重要理论依据。

Abstract: A Markov logic network (MLN) determines a probability distribution on the set
of structures, or ``possible worlds'', with an arbitrary finite domain. We
study the properties of such distributions as the domain size tends to
infinity. Three types of concrete examples of MLNs will be considered, and the
properties of random structures with domain sizes tending to infinity will be
studied: (1) Arbitrary quantifier-free MLNs over a language with only one
relation symbol which has arity 1. In this case we give a pretty complete
characterization of the possible limit behaviours of random structures. (2) An
MLN that favours graphs with fewer triangles (or more generally, fewer
k-cliques). As a corollary of the analysis a ``$\delta$-approximate 0-1 law''
for first-order logic is obtained. (3) An MLN that favours graphs with fewer
vertices with degree higher than a fixed (but arbitrary) number. The analysis
shows that depending on which ``soft constraints'' an MLN uses the limit
behaviour of random structures can be quite different, and the weights of the
soft constraints may, or may not, have influence on the limit behaviour. It
will also be demonstrated, using (1), that quantifier-free MLNs and lifted
Bayesian networks (in a broad sense) are asymptotically incomparable, roughly
meaning that there is a sequence of distributions on possible worlds with
increasing domain sizes that can be defined by one of the formalisms but not
even approximated by the other. In a rather general context it is also shown
that on large domains the distribution determined by an MLN concentrates almost
all its probability mass on a totally different part of the space of possible
worlds than the uniform distribution does.

</details>


### [63] [Evaluating Quality of Gaming Narratives Co-created with AI](https://arxiv.org/abs/2509.04239)
*Arturo Valdivia,Paolo Burelli*

Main category: cs.AI

TL;DR: 一种基于Delphi研究结构的结构化方法，通过故事设计专家评估AI生成游戏故事的质量维度，并映射到Kano模型中以理解对玩家满意度的影响。


<details>
  <summary>Details</summary>
Motivation: 为游戏开发者提供系统化的方法来评估优先AI生成游戏故事的质量维度，以支持与生成式AI的协同创作。

Method: 采用Delphi研究结构，组织故事设计专家小组，综合文献中的故事质量维度和专家见解，并将其映射到Kano模型框架中。

Result: 得到了能够指导游戏开发者优先考虑质量维度的结果，以优化与生成式AI协同创作游戏故事的满意度。

Conclusion: 该方法为评估AI生成游戏故事提供了结构化框架，有助于游戏开发者更有效地优先化故事质量要素。

Abstract: This paper proposes a structured methodology to evaluate AI-generated game
narratives, leveraging the Delphi study structure with a panel of narrative
design experts. Our approach synthesizes story quality dimensions from
literature and expert insights, mapping them into the Kano model framework to
understand their impact on player satisfaction. The results can inform game
developers on prioritizing quality aspects when co-creating game narratives
with generative AI.

</details>


### [64] [EvoEmo: Towards Evolved Emotional Policies for LLM Agents in Multi-Turn Negotiation](https://arxiv.org/abs/2509.04310)
*Yunbo Long,Liming Xu,Lukas Beckenbauer,Yuhan Liu,Alexandra Brintrup*

Main category: cs.AI

TL;DR: EvoEmo是一个进化强化学习框架，通过优化动态情绪表达来提升LLM在多轮谈判中的表现，显著优于传统策略


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在谈判中忽视了情绪的功能性作用，仅生成被动、偏好驱动的情绪响应，容易受到对手操纵和战略利用

Method: 将情绪状态转换建模为马尔可夫决策过程，采用基于种群的遗传优化算法，在不同谈判场景中演化高奖励情绪策略

Result: EvoEmo在成功率、效率和买家节省方面均优于传统策略和固定情绪策略基线

Conclusion: 自适应情绪表达对于实现更有效的多轮谈判LLM代理至关重要

Abstract: Recent research on Chain-of-Thought (CoT) reasoning in Large Language Models
(LLMs) has demonstrated that agents can engage in \textit{complex},
\textit{multi-turn} negotiations, opening new avenues for agentic AI. However,
existing LLM agents largely overlook the functional role of emotions in such
negotiations, instead generating passive, preference-driven emotional responses
that make them vulnerable to manipulation and strategic exploitation by
adversarial counterparts. To address this gap, we present EvoEmo, an
evolutionary reinforcement learning framework that optimizes dynamic emotional
expression in negotiations. EvoEmo models emotional state transitions as a
Markov Decision Process and employs population-based genetic optimization to
evolve high-reward emotion policies across diverse negotiation scenarios. We
further propose an evaluation framework with two baselines -- vanilla
strategies and fixed-emotion strategies -- for benchmarking emotion-aware
negotiation. Extensive experiments and ablation studies show that EvoEmo
consistently outperforms both baselines, achieving higher success rates, higher
efficiency, and increased buyer savings. This findings highlight the importance
of adaptive emotional expression in enabling more effective LLM agents for
multi-turn negotiation.

</details>


### [65] [Improving Robustness of AlphaZero Algorithms to Test-Time Environment Changes](https://arxiv.org/abs/2509.04317)
*Isidoro Tamassia,Wendelin Böhmer*

Main category: cs.AI

TL;DR: AlphaZero框架在测试环境变化时的性能提升方法分析


<details>
  <summary>Details</summary>
Motivation: AlphaZero通常假设训练和测试环境相同，这限制了其在实际应用中的适用性。本文研究如何在可能变化的测试环境中部署AlphaZero智能体。

Method: 对标准AlphaZero框架进行简单修改的组合，包括在低规划预算设置下的优化方法

Result: 显著提升了在变化测试环境中的性能表现

Conclusion: 通过简单的框架修改可以显著增强AlphaZero在动态环境中的适应能力，代码已在GitHub开源

Abstract: The AlphaZero framework provides a standard way of combining Monte Carlo
planning with prior knowledge provided by a previously trained policy-value
neural network. AlphaZero usually assumes that the environment on which the
neural network was trained will not change at test time, which constrains its
applicability. In this paper, we analyze the problem of deploying AlphaZero
agents in potentially changed test environments and demonstrate how the
combination of simple modifications to the standard framework can significantly
boost performance, even in settings with a low planning budget available. The
code is publicly available on GitHub.

</details>


### [66] [Psychologically Enhanced AI Agents](https://arxiv.org/abs/2509.04343)
*Maciej Besta,Shriram Chandran,Robert Gerstenberger,Mathis Lindner,Marcin Chrapek,Sebastian Hermann Martschat,Taraneh Ghandi,Patrick Iff,Hubert Niewiadomski,Piotr Nyczyk,Jürgen Müller,Torsten Hoefler*

Main category: cs.AI

TL;DR: MBTI-in-Thoughts框架通过MBTI人格类型提示工程，为LLM智能体注入心理学人格特质，无需微调即可控制其在认知和情感维度的行为表现。


<details>
  <summary>Details</summary>
Motivation: 将心理学人格理论融入LLM智能体设计，通过人格条件化提升智能体行为的一致性和可解释性，探索心理增强型AI的可能性。

Method: 基于MBTI人格类型进行提示工程，通过人格原型引导智能体行为，集成16Personalities测试进行自动化人格特质验证，支持多智能体结构化通信协议。

Result: 人格条件化在不同任务中产生一致的行为偏差：情感表达型智能体在叙事生成中表现优异，分析型智能体在博弈论场景中采用更稳定策略，自我反思能提升合作和推理质量。

Conclusion: 该框架成功将心理学理论与LLM行为设计结合，为心理增强型AI智能体奠定了基础，且方法可泛化到Big Five、HEXACO等其他心理学框架。

Abstract: We introduce MBTI-in-Thoughts, a framework for enhancing the effectiveness of
Large Language Model (LLM) agents through psychologically grounded personality
conditioning. Drawing on the Myers-Briggs Type Indicator (MBTI), our method
primes agents with distinct personality archetypes via prompt engineering,
enabling control over behavior along two foundational axes of human psychology,
cognition and affect. We show that such personality priming yields consistent,
interpretable behavioral biases across diverse tasks: emotionally expressive
agents excel in narrative generation, while analytically primed agents adopt
more stable strategies in game-theoretic settings. Our framework supports
experimenting with structured multi-agent communication protocols and reveals
that self-reflection prior to interaction improves cooperation and reasoning
quality. To ensure trait persistence, we integrate the official 16Personalities
test for automated verification. While our focus is on MBTI, we show that our
approach generalizes seamlessly to other psychological frameworks such as Big
Five, HEXACO, or Enneagram. By bridging psychological theory and LLM behavior
design, we establish a foundation for psychologically enhanced AI agents
without any fine-tuning.

</details>


### [67] [ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory](https://arxiv.org/abs/2509.04439)
*Matthew Ho,Chen Si,Zhaoxiang Feng,Fangxu Yu,Zhijian Liu,Zhiting Hu,Lianhui Qin*

Main category: cs.AI

TL;DR: 该论文提出了一种概念级外部记忆方法，通过从推理轨迹中抽象出可重用的模块化概念，在测试时实现无需权重更新的持续学习，在ARC-AGI基准上取得了7.5%的相对性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有推理时缩放方法虽然能生成更长的推理轨迹，但这些洞察在上下文窗口重置后立即丢失。外部记忆可以持久化这些发现，但现有方法主要基于实例级记忆，缺乏可重用性和扩展性。

Method: 提出概念级记忆方法：从解决方案轨迹中提取可重用的模块化抽象概念，以自然语言形式存储。对于新查询，选择性检索相关概念并集成到提示中，实现测试时持续学习而无需权重更新。

Result: 在ARC-AGI基准测试中，相比无记忆基线获得7.5%的相对性能提升，性能随推理计算量持续扩展。抽象概念在所有测试的计算规模上都优于基线，动态更新记忆比固定记忆设置表现更好。

Conclusion: 概念级外部记忆是一种有效的测试时持续学习方法，能够通过抽象和重用推理模式实现自我改进，为LLM的长期学习和知识积累提供了有前景的方向。

Abstract: While inference-time scaling enables LLMs to carry out increasingly long and
capable reasoning traces, the patterns and insights uncovered during these
traces are immediately discarded once the context window is reset for a new
query. External memory is a natural way to persist these discoveries, and
recent work has shown clear benefits for reasoning-intensive tasks. We see an
opportunity to make such memories more broadly reusable and scalable by moving
beyond instance-based memory entries (e.g. exact query/response pairs, or
summaries tightly coupled with the original problem context) toward
concept-level memory: reusable, modular abstractions distilled from solution
traces and stored in natural language. For future queries, relevant concepts
are selectively retrieved and integrated into the prompt, enabling test-time
continual learning without weight updates. Our design introduces new strategies
for abstracting takeaways from rollouts and retrieving entries for new queries,
promoting reuse and allowing memory to expand with additional experiences. On
the challenging ARC-AGI benchmark, our method yields a 7.5% relative gain over
a strong no-memory baseline with performance continuing to scale with inference
compute. We find abstract concepts to be the most consistent memory design,
outscoring the baseline at all tested inference compute scales. Moreover, we
confirm that dynamically updating memory during test-time outperforms an
otherwise identical fixed memory setting with additional attempts, supporting
the hypothesis that solving more problems and abstracting more patterns to
memory enables further solutions in a form of self-improvement. Code available
at https://github.com/matt-seb-ho/arc_memo.

</details>
