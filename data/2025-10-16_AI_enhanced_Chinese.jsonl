{"id": "2510.12802", "categories": ["cs.CR", "94A60", "F.2.2; E.3; K.3.2; D.4.6"], "pdf": "https://arxiv.org/pdf/2510.12802", "abs": "https://arxiv.org/abs/2510.12802", "authors": ["Alexander Towell"], "title": "The Beautiful Deception: How 256 Bits Pretend to be Infinity", "comment": null, "summary": "How do you store infinity in 256 bits? This paper explores the fundamental\ndeception at the heart of computational cryptography: using finite information\nto simulate infinite randomness. We prove why true random oracles are\nimpossible, then show how lazy evaluation creates a beautiful lie -- a finite\nautomaton that successfully pretends to be infinite. We reveal that\n``randomness'' in cryptography is actually computational hardness in disguise,\ndemonstrating through Python implementations how 256 bits of entropy can\ngenerate sequences indistinguishable from infinite randomness to any\ncomputationally bounded observer.How do you store infinity in 256 bits? This\npaper explores the fundamental deception at the heart of computational\ncryptography: using finite information to simulate infinite randomness. We\nprove why true random oracles are impossible, then show how lazy evaluation\ncreates a beautiful lie -- a finite automaton that successfully pretends to be\ninfinite. We reveal that ``randomness'' in cryptography is actually\ncomputational hardness in disguise, demonstrating through Python\nimplementations how 256 bits of entropy can generate sequences\nindistinguishable from infinite randomness to any computationally bounded\nobserver.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u8ba1\u7b97\u5bc6\u7801\u5b66\u4e2d\u7684\u6838\u5fc3\u6b3a\u9a97\uff1a\u7528\u6709\u9650\u4fe1\u606f\u6a21\u62df\u65e0\u9650\u968f\u673a\u6027\uff0c\u8bc1\u660e256\u4f4d\u71b5\u53ef\u4ee5\u751f\u6210\u5bf9\u8ba1\u7b97\u6709\u9650\u89c2\u5bdf\u8005\u6765\u8bf4\u4e0e\u65e0\u9650\u968f\u673a\u6027\u65e0\u6cd5\u533a\u5206\u7684\u5e8f\u5217\u3002", "motivation": "\u7814\u7a76\u8ba1\u7b97\u5bc6\u7801\u5b66\u4e2d\u5982\u4f55\u7528\u6709\u9650\u4fe1\u606f\u6a21\u62df\u65e0\u9650\u968f\u673a\u6027\u7684\u57fa\u672c\u539f\u7406\uff0c\u63ed\u793a\u5bc6\u7801\u5b66\u4e2d\"\u968f\u673a\u6027\"\u5b9e\u9645\u4e0a\u662f\u8ba1\u7b97\u96be\u5ea6\u7684\u4f2a\u88c5\u3002", "method": "\u901a\u8fc7\u8bc1\u660e\u771f\u968f\u673a\u9884\u8a00\u673a\u7684\u4e0d\u53ef\u80fd\u6027\uff0c\u5c55\u793a\u60f0\u6027\u8bc4\u4f30\u5982\u4f55\u521b\u5efa\u6709\u9650\u81ea\u52a8\u673a\u6210\u529f\u4f2a\u88c5\u6210\u65e0\u9650\u7cfb\u7edf\uff0c\u5e76\u7528Python\u5b9e\u73b0\u6f14\u793a\u3002", "result": "\u8bc1\u660e\u4e86256\u4f4d\u71b5\u53ef\u4ee5\u751f\u6210\u5bf9\u8ba1\u7b97\u6709\u9650\u89c2\u5bdf\u8005\u6765\u8bf4\u4e0e\u65e0\u9650\u968f\u673a\u6027\u65e0\u6cd5\u533a\u5206\u7684\u5e8f\u5217\uff0c\u63ed\u793a\u4e86\u5bc6\u7801\u5b66\u968f\u673a\u6027\u7684\u672c\u8d28\u662f\u8ba1\u7b97\u96be\u5ea6\u3002", "conclusion": "\u5bc6\u7801\u5b66\u4e2d\u7684\u968f\u673a\u6027\u5b9e\u9645\u4e0a\u662f\u8ba1\u7b97\u96be\u5ea6\u7684\u4f2a\u88c5\uff0c\u901a\u8fc7\u6709\u9650\u4fe1\u606f\u53ef\u4ee5\u6210\u529f\u6a21\u62df\u65e0\u9650\u968f\u673a\u6027\uff0c\u8fd9\u5bf9\u7406\u89e3\u5bc6\u7801\u5b66\u57fa\u7840\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2510.12811", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.12811", "abs": "https://arxiv.org/abs/2510.12811", "authors": ["ElMouatez Billah Karbab", "Mourad Debbabi"], "title": "Applying Graph Analysis for Unsupervised Fast Malware Fingerprinting", "comment": null, "summary": "Malware proliferation is increasing at a tremendous rate, with hundreds of\nthousands of new samples identified daily. Manual investigation of such a vast\namount of malware is an unrealistic, time-consuming, and overwhelming task. To\ncope with this volume, there is a clear need to develop specialized techniques\nand efficient tools for preliminary filtering that can group malware based on\nsemantic similarity. In this paper, we propose TrapNet, a novel, scalable, and\nunsupervised framework for malware fingerprinting and grouping. TrapNet employs\ngraph community detection techniques for malware fingerprinting and family\nattribution based on static analysis, as follows: (1) TrapNet detects packed\nbinaries and unpacks them using known generic packer tools. (2) From each\nmalware sample, it generates a digest that captures the underlying semantics.\nSince the digest must be dense, efficient, and suitable for similarity\nchecking, we designed FloatHash (FH), a novel numerical fuzzy hashing technique\nthat produces a short real-valued vector summarizing the underlying assembly\nitems and their order. FH is based on applying Principal Component Analysis\n(PCA) to ordered assembly items (e.g., opcodes, function calls) extracted from\nthe malware's assembly code. (3) Representing malware with short numerical\nvectors enables high-performance, large-scale similarity computation, which\nallows TrapNet to build a malware similarity network. (4) Finally, TrapNet\nemploys state-of-the-art community detection algorithms to identify dense\ncommunities, which represent groups of malware with similar semantics. Our\nextensive evaluation of TrapNet demonstrates its effectiveness in terms of the\ncoverage and purity of the detected communities, while also highlighting its\nruntime efficiency, which outperforms other state-of-the-art solutions.", "AI": {"tldr": "TrapNet\u662f\u4e00\u4e2a\u65b0\u9896\u3001\u53ef\u6269\u5c55\u3001\u65e0\u76d1\u7763\u7684\u6076\u610f\u8f6f\u4ef6\u6307\u7eb9\u8bc6\u522b\u548c\u5206\u7ec4\u6846\u67b6\uff0c\u4f7f\u7528\u56fe\u793e\u533a\u68c0\u6d4b\u6280\u672f\u8fdb\u884c\u57fa\u4e8e\u9759\u6001\u5206\u6790\u7684\u6076\u610f\u8f6f\u4ef6\u5bb6\u65cf\u5f52\u56e0\u3002", "motivation": "\u6076\u610f\u8f6f\u4ef6\u6570\u91cf\u6025\u5267\u589e\u957f\uff0c\u6bcf\u5929\u6709\u6570\u5341\u4e07\u4e2a\u65b0\u6837\u672c\uff0c\u624b\u52a8\u5206\u6790\u4e0d\u73b0\u5b9e\u3002\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u6280\u672f\u6765\u57fa\u4e8e\u8bed\u4e49\u76f8\u4f3c\u6027\u5bf9\u6076\u610f\u8f6f\u4ef6\u8fdb\u884c\u521d\u6b65\u8fc7\u6ee4\u548c\u5206\u7ec4\u3002", "method": "1) \u68c0\u6d4b\u52a0\u58f3\u4e8c\u8fdb\u5236\u6587\u4ef6\u5e76\u4f7f\u7528\u901a\u7528\u8131\u58f3\u5de5\u5177\u89e3\u5305\uff1b2) \u8bbe\u8ba1FloatHash(FH)\u6570\u503c\u6a21\u7cca\u54c8\u5e0c\u6280\u672f\uff0c\u901a\u8fc7PCA\u5bf9\u6c47\u7f16\u4ee3\u7801\u4e2d\u7684\u6709\u5e8f\u6c47\u7f16\u9879\u751f\u6210\u77ed\u5b9e\u6570\u5411\u91cf\uff1b3) \u6784\u5efa\u6076\u610f\u8f6f\u4ef6\u76f8\u4f3c\u6027\u7f51\u7edc\uff1b4) \u4f7f\u7528\u793e\u533a\u68c0\u6d4b\u7b97\u6cd5\u8bc6\u522b\u5bc6\u96c6\u793e\u533a\u3002", "result": "\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660eTrapNet\u5728\u68c0\u6d4b\u793e\u533a\u7684\u8986\u76d6\u7387\u548c\u7eaf\u5ea6\u65b9\u9762\u6709\u6548\uff0c\u540c\u65f6\u8fd0\u884c\u6548\u7387\u4f18\u4e8e\u5176\u4ed6\u6700\u5148\u8fdb\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "TrapNet\u6846\u67b6\u5728\u6076\u610f\u8f6f\u4ef6\u6307\u7eb9\u8bc6\u522b\u548c\u5206\u7ec4\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u9ad8\u6548\u5904\u7406\u5927\u89c4\u6a21\u6076\u610f\u8f6f\u4ef6\u6837\u672c\u3002"}}
{"id": "2510.12812", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.12812", "abs": "https://arxiv.org/abs/2510.12812", "authors": ["Aleksandar Petrov", "Pierre Fernandez", "Tom\u00e1\u0161 Sou\u010dek", "Hady Elsahar"], "title": "We Can Hide More Bits: The Unused Watermarking Capacity in Theory and in Practice", "comment": null, "summary": "Despite rapid progress in deep learning-based image watermarking, the\ncapacity of current robust methods remains limited to the scale of only a few\nhundred bits. Such plateauing progress raises the question: How far are we from\nthe fundamental limits of image watermarking? To this end, we present an\nanalysis that establishes upper bounds on the message-carrying capacity of\nimages under PSNR and linear robustness constraints. Our results indicate\ntheoretical capacities are orders of magnitude larger than what current models\nachieve. Our experiments show this gap between theoretical and empirical\nperformance persists, even in minimal, easily analysable setups. This suggests\na fundamental problem. As proof that larger capacities are indeed possible, we\ntrain ChunkySeal, a scaled-up version of VideoSeal, which increases capacity 4\ntimes to 1024 bits, all while preserving image quality and robustness. These\nfindings demonstrate modern methods have not yet saturated watermarking\ncapacity, and that significant opportunities for architectural innovation and\ntraining strategies remain.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u56fe\u50cf\u6c34\u5370\u7684\u7406\u8bba\u5bb9\u91cf\u4e0a\u9650\uff0c\u53d1\u73b0\u5f53\u524d\u65b9\u6cd5\u8fdc\u672a\u8fbe\u5230\u7406\u8bba\u6781\u9650\uff0c\u5e76\u901a\u8fc7\u8bad\u7ec3ChunkySeal\u6a21\u578b\u5c06\u5bb9\u91cf\u63d0\u53474\u500d\u81f31024\u4f4d\uff0c\u8bc1\u660e\u4e86\u4ecd\u6709\u5de8\u5927\u6539\u8fdb\u7a7a\u95f4\u3002", "motivation": "\u5f53\u524d\u6df1\u5ea6\u5b66\u4e60\u56fe\u50cf\u6c34\u5370\u65b9\u6cd5\u7684\u5bb9\u91cf\u505c\u6ede\u5728\u51e0\u767e\u4f4d\u6c34\u5e73\uff0c\u9700\u8981\u63a2\u7a76\u8fd9\u662f\u5426\u63a5\u8fd1\u4e86\u7406\u8bba\u6781\u9650\uff0c\u4ee5\u53ca\u662f\u5426\u5b58\u5728\u63d0\u5347\u7a7a\u95f4\u3002", "method": "\u5efa\u7acbPSNR\u548c\u7ebf\u6027\u9c81\u68d2\u6027\u7ea6\u675f\u4e0b\u7684\u56fe\u50cf\u6c34\u5370\u6d88\u606f\u643a\u5e26\u5bb9\u91cf\u4e0a\u754c\u5206\u6790\uff0c\u5e76\u8bad\u7ec3ChunkySeal\uff08VideoSeal\u7684\u6269\u5c55\u7248\u672c\uff09\u6765\u9a8c\u8bc1\u66f4\u5927\u5bb9\u91cf\u7684\u53ef\u884c\u6027\u3002", "result": "\u7406\u8bba\u5206\u6790\u663e\u793a\u5bb9\u91cf\u4e0a\u9650\u6bd4\u5f53\u524d\u65b9\u6cd5\u9ad8\u51e0\u4e2a\u6570\u91cf\u7ea7\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5373\u4f7f\u5728\u7b80\u5355\u8bbe\u7f6e\u4e0b\u7406\u8bba\u4e0e\u5b9e\u9645\u6027\u80fd\u5dee\u8ddd\u4f9d\u7136\u5b58\u5728\u3002ChunkySeal\u6210\u529f\u5c06\u5bb9\u91cf\u63d0\u5347\u81f31024\u4f4d\uff0c\u540c\u65f6\u4fdd\u6301\u56fe\u50cf\u8d28\u91cf\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u73b0\u4ee3\u6c34\u5370\u65b9\u6cd5\u8fdc\u672a\u8fbe\u5230\u5bb9\u91cf\u6781\u9650\uff0c\u5728\u67b6\u6784\u521b\u65b0\u548c\u8bad\u7ec3\u7b56\u7565\u65b9\u9762\u4ecd\u6709\u663e\u8457\u6539\u8fdb\u673a\u4f1a\u3002"}}
{"id": "2510.12821", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.12821", "abs": "https://arxiv.org/abs/2510.12821", "authors": ["Jaeseong Lee", "Junghee Lee"], "title": "ARTeX: Anonymity Real-world-assets Token eXchange", "comment": null, "summary": "This paper addresses one of the most noteworthy issues in the recent virtual\nasset market, the privacy concerns related to token transactions of Real-World\nAssets tokens, known as RWA tokens. Following the advent of Bitcoin, the\nvirtual asset market has experienced explosive growth, spawning movements to\nlink real-world assets with virtual assets. However, due to the transparency\nprinciple of blockchain technology, the anonymity of traders cannot be\nguaranteed. In the existing blockchain environment, there have been instances\nof protecting the privacy of fungible tokens (FTs) using mixer services.\nMoreover, numerous studies have been conducted to secure the privacy of\nnon-fungible tokens (NFTs). However, due to the unique characteristics of RWA\ntokens and the limitations of each study, it has been challenging to achieve\nthe goal of anonymity protection effectively. This paper proposes a new token\ntrading platform, the ARTeX, designed to resolve these issues. This platform\nnot only addresses the shortcomings of existing methods but also ensures the\nanonymity of traders while enhancing safeguards against illegal activities.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u73b0\u5b9e\u4e16\u754c\u8d44\u4ea7\u4ee3\u5e01\u4ea4\u6613\u4e2d\u7684\u9690\u79c1\u95ee\u9898\uff0c\u63d0\u51fa\u4e86ARTeX\u4ea4\u6613\u5e73\u53f0\uff0c\u5728\u4fdd\u62a4\u4ea4\u6613\u8005\u533f\u540d\u6027\u7684\u540c\u65f6\u589e\u5f3a\u5bf9\u975e\u6cd5\u6d3b\u52a8\u7684\u9632\u8303\u3002", "motivation": "\u533a\u5757\u94fe\u6280\u672f\u7684\u900f\u660e\u6027\u539f\u5219\u5bfc\u81f4\u4ea4\u6613\u8005\u533f\u540d\u6027\u65e0\u6cd5\u4fdd\u969c\uff0c\u800c\u73b0\u6709\u7684\u6df7\u5e01\u670d\u52a1\u548cNFT\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\u7531\u4e8eRWA\u4ee3\u5e01\u7684\u7279\u6b8a\u6027\u548c\u5404\u81ea\u5c40\u9650\u6027\uff0c\u96be\u4ee5\u6709\u6548\u5b9e\u73b0\u533f\u540d\u4fdd\u62a4\u76ee\u6807\u3002", "method": "\u63d0\u51fa\u65b0\u7684\u4ee3\u5e01\u4ea4\u6613\u5e73\u53f0ARTeX\uff0c\u8be5\u5e73\u53f0\u4e0d\u4ec5\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u8fd8\u80fd\u786e\u4fdd\u4ea4\u6613\u8005\u533f\u540d\u6027\u5e76\u589e\u5f3a\u5bf9\u975e\u6cd5\u6d3b\u52a8\u7684\u9632\u62a4\u3002", "result": "ARTeX\u5e73\u53f0\u80fd\u591f\u6709\u6548\u89e3\u51b3RWA\u4ee3\u5e01\u4ea4\u6613\u4e2d\u7684\u9690\u79c1\u95ee\u9898\uff0c\u514b\u670d\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "conclusion": "ARTeX\u5e73\u53f0\u4e3a\u89e3\u51b3RWA\u4ee3\u5e01\u4ea4\u6613\u9690\u79c1\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\uff0c\u5728\u4fdd\u62a4\u533f\u540d\u6027\u7684\u540c\u65f6\u517c\u987e\u4e86\u5408\u89c4\u6027\u8981\u6c42\u3002"}}
{"id": "2510.12803", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.PL"], "pdf": "https://arxiv.org/pdf/2510.12803", "abs": "https://arxiv.org/abs/2510.12803", "authors": ["Shang Zhou", "Zihan Zheng", "Kaiyuan Liu", "Zeyu Shen", "Zerui Cheng", "Zexing Chen", "Hansen He", "Jianzhu Yao", "Huanzhi Mao", "Qiuyang Mang", "Tianfu Fu", "Beichen Li", "Dongruixuan Li", "Wenhao Chai", "Zhuang Liu", "Aleksandra Korolova", "Peter Henderson", "Natasha Jaques", "Pramod Viswanath", "Saining Xie", "Jingbo Shang"], "title": "AutoCode: LLMs as Problem Setters for Competitive Programming", "comment": "Project page: https://livecodebenchpro.com/projects/autocode/overview", "summary": "Writing competitive programming problems is exacting. Authors must: set\nconstraints, input distributions, and edge cases that rule out shortcuts;\ntarget specific algorithms (e.g., max-flow, dynamic programming, data\nstructures); and calibrate complexity beyond the reach of most competitors. We\nargue that this makes for an ideal test of general large language model\ncapabilities and study whether they can do this reliably. We introduce\nAutoCode, which uses multiple rounds of validation to yield competition-grade\nproblem statements and test cases. On held-out problems, AutoCode test suites\napproach 99% consistency with official judgments, a significant improvement\nover current state-of-the-art methods like HardTests, which achieve less than\n81%. Furthermore, starting with a random seed problem, AutoCode can create\nnovel variants with reference and brute-force solutions. By cross-verifying\nthese generated solutions against test cases, we can further filter out\nmalformed problems. Our system ensures high correctness, as verified by human\nexperts. AutoCode successfully produces novel problems judged by\nGrandmaster-level (top 0.3%) competitive programmers to be of contest quality.", "AI": {"tldr": "AutoCode\u662f\u4e00\u4e2a\u4f7f\u7528\u591a\u8f6e\u9a8c\u8bc1\u751f\u6210\u7ade\u8d5b\u7ea7\u7f16\u7a0b\u95ee\u9898\u9648\u8ff0\u548c\u6d4b\u8bd5\u7528\u4f8b\u7684\u7cfb\u7edf\uff0c\u5728\u4fdd\u7559\u95ee\u9898\u4e0a\u6d4b\u8bd5\u5957\u4ef6\u4e0e\u5b98\u65b9\u8bc4\u5224\u7684\u4e00\u81f4\u6027\u63a5\u8fd199%\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u7f16\u5199\u7ade\u8d5b\u7f16\u7a0b\u95ee\u9898\u9700\u8981\u8bbe\u7f6e\u7ea6\u675f\u3001\u8f93\u5165\u5206\u5e03\u548c\u8fb9\u754c\u60c5\u51b5\uff0c\u9488\u5bf9\u7279\u5b9a\u7b97\u6cd5\uff0c\u5e76\u6821\u51c6\u8d85\u51fa\u5927\u591a\u6570\u53c2\u8d5b\u8005\u80fd\u529b\u7684\u590d\u6742\u5ea6\uff0c\u8fd9\u4f7f\u5176\u6210\u4e3a\u6d4b\u8bd5\u5927\u578b\u8bed\u8a00\u6a21\u578b\u901a\u7528\u80fd\u529b\u7684\u7406\u60f3\u573a\u666f\u3002", "method": "AutoCode\u4f7f\u7528\u591a\u8f6e\u9a8c\u8bc1\u6765\u751f\u6210\u95ee\u9898\u9648\u8ff0\u548c\u6d4b\u8bd5\u7528\u4f8b\uff0c\u901a\u8fc7\u4ea4\u53c9\u9a8c\u8bc1\u751f\u6210\u7684\u53c2\u8003\u89e3\u548c\u66b4\u529b\u89e3\u4e0e\u6d4b\u8bd5\u7528\u4f8b\uff0c\u8fdb\u4e00\u6b65\u8fc7\u6ee4\u6709\u95ee\u9898\u7684\u9898\u76ee\u3002", "result": "\u5728\u4fdd\u7559\u95ee\u9898\u4e0a\uff0cAutoCode\u6d4b\u8bd5\u5957\u4ef6\u4e0e\u5b98\u65b9\u8bc4\u5224\u7684\u4e00\u81f4\u6027\u8fbe\u523099%\uff0c\u663e\u8457\u4f18\u4e8eHardTests\u768481%\u3002\u7cfb\u7edf\u80fd\u591f\u751f\u6210\u88ab\u9876\u7ea7\u7a0b\u5e8f\u5458\u8bc4\u4e3a\u7ade\u8d5b\u8d28\u91cf\u7684\u65b0\u9896\u95ee\u9898\u3002", "conclusion": "AutoCode\u80fd\u591f\u53ef\u9760\u5730\u751f\u6210\u7ade\u8d5b\u7ea7\u7f16\u7a0b\u95ee\u9898\uff0c\u901a\u8fc7\u591a\u8f6e\u9a8c\u8bc1\u548c\u4ea4\u53c9\u9a8c\u8bc1\u786e\u4fdd\u9ad8\u8d28\u91cf\uff0c\u4e3a\u6d4b\u8bd5\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2510.12864", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.12864", "abs": "https://arxiv.org/abs/2510.12864", "authors": ["Imran Khan"], "title": "From Literal to Liberal: A Meta-Prompting Framework for Eliciting Human-Aligned Exception Handling in Large Language Models", "comment": "13 pages. Code and data are available at\n  https://github.com/strongSoda/LITERAL-TO-LIBERAL", "summary": "Large Language Models (LLMs) are increasingly being deployed as the reasoning\nengines for agentic AI systems, yet they exhibit a critical flaw: a rigid\nadherence to explicit rules that leads to decisions misaligned with human\ncommon sense and intent. This \"rule-rigidity\" is a significant barrier to\nbuilding trustworthy autonomous agents. While prior work has shown that\nsupervised fine-tuning (SFT) with human explanations can mitigate this issue,\nSFT is computationally expensive and inaccessible to many practitioners. To\naddress this gap, we introduce the Rule-Intent Distinction (RID) Framework, a\nnovel, low-compute meta-prompting technique designed to elicit human-aligned\nexception handling in LLMs in a zero-shot manner. The RID framework provides\nthe model with a structured cognitive schema for deconstructing tasks,\nclassifying rules, weighing conflicting outcomes, and justifying its final\ndecision. We evaluated the RID framework against baseline and Chain-of-Thought\n(CoT) prompting on a custom benchmark of 20 scenarios requiring nuanced\njudgment across diverse domains. Our human-verified results demonstrate that\nthe RID framework significantly improves performance, achieving a 95% Human\nAlignment Score (HAS), compared to 80% for the baseline and 75% for CoT.\nFurthermore, it consistently produces higher-quality, intent-driven reasoning.\nThis work presents a practical, accessible, and effective method for steering\nLLMs from literal instruction-following to liberal, goal-oriented reasoning,\npaving the way for more reliable and pragmatic AI agents.", "AI": {"tldr": "\u63d0\u51fa\u4e86RID\u6846\u67b6\uff0c\u4e00\u79cd\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u5143\u63d0\u793a\u6280\u672f\uff0c\u7528\u4e8e\u5728\u96f6\u6837\u672c\u60c5\u51b5\u4e0b\u5f15\u5bfcLLMs\u8fdb\u884c\u4eba\u7c7b\u5bf9\u9f50\u7684\u5f02\u5e38\u5904\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86\u51b3\u7b56\u7684\u4eba\u7c7b\u5bf9\u9f50\u5ea6\u3002", "motivation": "LLMs\u4f5c\u4e3a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u63a8\u7406\u5f15\u64ce\u5b58\u5728\u89c4\u5219\u521a\u6027\u7f3a\u9677\uff0c\u5373\u8fc7\u5ea6\u9075\u5faa\u663e\u5f0f\u89c4\u5219\u800c\u5ffd\u89c6\u4eba\u7c7b\u5e38\u8bc6\u548c\u610f\u56fe\uff0c\u8fd9\u963b\u788d\u4e86\u53ef\u4fe1\u81ea\u4e3b\u667a\u80fd\u4f53\u7684\u6784\u5efa\u3002", "method": "\u5f15\u5165\u89c4\u5219-\u610f\u56fe\u533a\u5206(RID)\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u8ba4\u77e5\u6a21\u5f0f\u8ba9\u6a21\u578b\u89e3\u6784\u4efb\u52a1\u3001\u5206\u7c7b\u89c4\u5219\u3001\u6743\u8861\u51b2\u7a81\u7ed3\u679c\u5e76\u8bc1\u660e\u6700\u7ec8\u51b3\u7b56\uff0c\u662f\u4e00\u79cd\u96f6\u6837\u672c\u5143\u63d0\u793a\u6280\u672f\u3002", "result": "\u572820\u4e2a\u9700\u8981\u7ec6\u5fae\u5224\u65ad\u7684\u573a\u666f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRID\u6846\u67b6\u8fbe\u523095%\u7684\u4eba\u7c7b\u5bf9\u9f50\u5206\u6570\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf(80%)\u548c\u601d\u7ef4\u94fe\u63d0\u793a(75%)\uff0c\u5e76\u80fd\u4ea7\u751f\u66f4\u9ad8\u8d28\u91cf\u7684\u610f\u56fe\u9a71\u52a8\u63a8\u7406\u3002", "conclusion": "RID\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u3001\u6613\u7528\u4e14\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u5c06LLMs\u4ece\u5b57\u9762\u6307\u4ee4\u9075\u5faa\u8f6c\u5411\u7075\u6d3b\u7684\u76ee\u6807\u5bfc\u5411\u63a8\u7406\uff0c\u4e3a\u6784\u5efa\u66f4\u53ef\u9760\u548c\u5b9e\u7528\u7684AI\u667a\u80fd\u4f53\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2510.12828", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.12828", "abs": "https://arxiv.org/abs/2510.12828", "authors": ["Shingo Kodama", "Haya Diwan", "Lucas Rosenblatt", "R. Teal Witter", "Niv Cohen"], "title": "SimKey: A Semantically Aware Key Module for Watermarking Language Models", "comment": null, "summary": "The rapid spread of text generated by large language models (LLMs) makes it\nincreasingly difficult to distinguish authentic human writing from machine\noutput. Watermarking offers a promising solution: model owners can embed an\nimperceptible signal into generated text, marking its origin. Most leading\napproaches seed an LLM's next-token sampling with a pseudo-random key that can\nlater be recovered to identify the text as machine-generated, while only\nminimally altering the model's output distribution. However, these methods\nsuffer from two related issues: (i) watermarks are brittle to simple\nsurface-level edits such as paraphrasing or reordering; and (ii) adversaries\ncan append unrelated, potentially harmful text that inherits the watermark,\nrisking reputational damage to model owners. To address these issues, we\nintroduce SimKey, a semantic key module that strengthens watermark robustness\nby tying key generation to the meaning of prior context. SimKey uses\nlocality-sensitive hashing over semantic embeddings to ensure that paraphrased\ntext yields the same watermark key, while unrelated or semantically shifted\ntext produces a different one. Integrated with state-of-the-art watermarking\nschemes, SimKey improves watermark robustness to paraphrasing and translation\nwhile preventing harmful content from false attribution, establishing\nsemantic-aware keying as a practical and extensible watermarking direction.", "AI": {"tldr": "SimKey\u662f\u4e00\u79cd\u8bed\u4e49\u5bc6\u94a5\u6a21\u5757\uff0c\u901a\u8fc7\u5c06\u5bc6\u94a5\u751f\u6210\u4e0e\u4e0a\u4e0b\u6587\u8bed\u4e49\u7ed1\u5b9a\u6765\u589e\u5f3a\u6c34\u5370\u9c81\u68d2\u6027\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6c34\u5370\u65b9\u6cd5\u5bf9\u8868\u9762\u7f16\u8f91\u8106\u5f31\u548c\u6076\u610f\u5185\u5bb9\u8bef\u5f52\u56e0\u7684\u95ee\u9898\u3002", "motivation": "\u968f\u7740LLM\u751f\u6210\u6587\u672c\u7684\u5feb\u901f\u4f20\u64ad\uff0c\u533a\u5206\u4eba\u7c7b\u5199\u4f5c\u548c\u673a\u5668\u8f93\u51fa\u53d8\u5f97\u56f0\u96be\u3002\u73b0\u6709\u6c34\u5370\u65b9\u6cd5\u5bf9\u6539\u5199\u548c\u91cd\u6392\u5e8f\u7b49\u8868\u9762\u7f16\u8f91\u8106\u5f31\uff0c\u4e14\u6076\u610f\u5185\u5bb9\u53ef\u80fd\u7ee7\u627f\u6c34\u5370\u5bfc\u81f4\u6a21\u578b\u6240\u6709\u8005\u58f0\u8a89\u53d7\u635f\u3002", "method": "SimKey\u4f7f\u7528\u5c40\u90e8\u654f\u611f\u54c8\u5e0c\u5bf9\u8bed\u4e49\u5d4c\u5165\u8fdb\u884c\u5904\u7406\uff0c\u786e\u4fdd\u6539\u5199\u6587\u672c\u4ea7\u751f\u76f8\u540c\u6c34\u5370\u5bc6\u94a5\uff0c\u800c\u65e0\u5173\u6216\u8bed\u4e49\u504f\u79fb\u6587\u672c\u4ea7\u751f\u4e0d\u540c\u5bc6\u94a5\u3002\u8be5\u65b9\u6cd5\u4e0e\u6700\u5148\u8fdb\u7684\u6c34\u5370\u65b9\u6848\u96c6\u6210\u3002", "result": "SimKey\u63d0\u9ad8\u4e86\u6c34\u5370\u5bf9\u6539\u5199\u548c\u7ffb\u8bd1\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u9632\u6b62\u6709\u5bb3\u5185\u5bb9\u88ab\u9519\u8bef\u5f52\u56e0\u3002", "conclusion": "\u8bed\u4e49\u611f\u77e5\u5bc6\u94a5\u751f\u6210\u662f\u4e00\u79cd\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u6c34\u5370\u65b9\u5411\uff0c\u4e3aLLM\u751f\u6210\u6587\u672c\u7684\u53ef\u9760\u6eaf\u6e90\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.12948", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.12948", "abs": "https://arxiv.org/abs/2510.12948", "authors": ["Minh Nguyen"], "title": "SpareCodeSearch: Searching for Code Context When You Have No Spare GPU", "comment": "4 pages, 3 figures, 4 tables. Accepted to Context Collection Workshop\n  co-located with ASE'25", "summary": "Retrieval-Augmented Generation (RAG) frameworks aim to enhance Code Language\nModels (CLMs) by including another module for retrieving relevant context to\nconstruct the input prompt. However, these retrieval modules commonly use\nsemantic search, requiring substantial computational resources for training and\nhosting these embedded models, making them infeasible to integrate into\nlightweight applications such as in-IDE AI-based code completion. In this\nsolution paper, we prove that using keyword-search is sufficient to retrieve\nrelevant and useful code context inside large codebases, without the need for\nextensive GPU resources. The usefulness of code contexts found by our solution\nis demonstrated through their completion results on the Code Context\nCompetition's benchmark, reaching 0.748 and 0.725 chRF scores on Kotlin and\nPython tracks, respectively.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u5728\u5927\u578b\u4ee3\u7801\u5e93\u4e2d\u4f7f\u7528\u5173\u952e\u8bcd\u641c\u7d22\u8db3\u4ee5\u68c0\u7d22\u76f8\u5173\u4ee3\u7801\u4e0a\u4e0b\u6587\uff0c\u65e0\u9700\u5927\u91cfGPU\u8d44\u6e90\uff0c\u5728\u4ee3\u7801\u8865\u5168\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u73b0\u6709\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\u901a\u5e38\u4f7f\u7528\u8bed\u4e49\u641c\u7d22\uff0c\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u8bad\u7ec3\u548c\u90e8\u7f72\u5d4c\u5165\u6a21\u578b\uff0c\u96be\u4ee5\u96c6\u6210\u5230\u8f7b\u91cf\u7ea7\u5e94\u7528\u4e2d\uff0c\u5982IDE\u5185\u7684AI\u4ee3\u7801\u8865\u5168\u3002", "method": "\u4f7f\u7528\u5173\u952e\u8bcd\u641c\u7d22\u66ff\u4ee3\u8bed\u4e49\u641c\u7d22\u6765\u68c0\u7d22\u76f8\u5173\u4ee3\u7801\u4e0a\u4e0b\u6587\uff0c\u907f\u514d\u5bf9GPU\u8d44\u6e90\u7684\u4f9d\u8d56\u3002", "result": "\u5728Code Context Competition\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cKotlin\u548cPython\u8f68\u9053\u7684chRF\u5206\u6570\u5206\u522b\u8fbe\u52300.748\u548c0.725\u3002", "conclusion": "\u5173\u952e\u8bcd\u641c\u7d22\u8db3\u4ee5\u6709\u6548\u68c0\u7d22\u4ee3\u7801\u4e0a\u4e0b\u6587\uff0c\u4e3a\u8f7b\u91cf\u7ea7\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.12979", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.12979", "abs": "https://arxiv.org/abs/2510.12979", "authors": ["Wei Fan", "Wenlin Yao", "Zheng Li", "Feng Yao", "Xin Liu", "Liang Qiu", "Qingyu Yin", "Yangqiu Song", "Bing Yin"], "title": "DeepPlanner: Scaling Planning Capability for Deep Research Agents via Advantage Shaping", "comment": "Under Review", "summary": "Large language models (LLMs) augmented with multi-step reasoning and action\ngeneration abilities have shown promise in leveraging external tools to tackle\ncomplex tasks that require long-horizon planning. However, existing approaches\neither rely on implicit planning in the reasoning stage or introduce explicit\nplanners without systematically addressing how to optimize the planning stage.\nAs evidence, we observe that under vanilla reinforcement learning (RL),\nplanning tokens exhibit significantly higher entropy than other action tokens,\nrevealing uncertain decision points that remain under-optimized. To address\nthis, we propose DeepPlanner, an end-to-end RL framework that effectively\nenhances the planning capabilities of deep research agents. Our approach shapes\ntoken-level advantage with an entropy-based term to allocate larger updates to\nhigh entropy tokens, and selectively upweights sample-level advantages for\nplanning-intensive rollouts. Extensive experiments across seven deep research\nbenchmarks demonstrate that DeepPlanner improves planning quality and achieves\nstate-of-the-art results under a substantially lower training budget.", "AI": {"tldr": "DeepPlanner\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8e\u71b5\u7684\u4f18\u52bf\u51fd\u6570\u548c\u9009\u62e9\u6027\u6837\u672c\u52a0\u6743\uff0c\u6709\u6548\u589e\u5f3a\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u7684\u89c4\u5212\u80fd\u529b\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u6700\u5148\u8fdb\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u63a8\u7406\u9636\u6bb5\u7684\u9690\u5f0f\u89c4\u5212\uff0c\u8981\u4e48\u5f15\u5165\u663e\u5f0f\u89c4\u5212\u5668\u4f46\u672a\u7cfb\u7edf\u4f18\u5316\u89c4\u5212\u9636\u6bb5\u3002\u7814\u7a76\u53d1\u73b0\u89c4\u5212\u4ee4\u724c\u7684\u71b5\u663e\u8457\u9ad8\u4e8e\u5176\u4ed6\u52a8\u4f5c\u4ee4\u724c\uff0c\u8868\u660e\u5b58\u5728\u672a\u4f18\u5316\u7684\u4e0d\u786e\u5b9a\u51b3\u7b56\u70b9\u3002", "method": "\u63d0\u51faDeepPlanner\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8e\u71b5\u7684\u4ee4\u724c\u7ea7\u4f18\u52bf\u51fd\u6570\u4e3a\u9ad8\u71b5\u4ee4\u724c\u5206\u914d\u66f4\u5927\u66f4\u65b0\uff0c\u5e76\u4e3a\u89c4\u5212\u5bc6\u96c6\u578b\u8f68\u8ff9\u9009\u62e9\u6027\u52a0\u6743\u6837\u672c\u7ea7\u4f18\u52bf\u3002", "result": "\u5728\u4e03\u4e2a\u6df1\u5ea6\u7814\u7a76\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDeepPlanner\u63d0\u9ad8\u4e86\u89c4\u5212\u8d28\u91cf\uff0c\u5e76\u5728\u663e\u8457\u964d\u4f4e\u8bad\u7ec3\u9884\u7b97\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "conclusion": "DeepPlanner\u901a\u8fc7\u7cfb\u7edf\u4f18\u5316\u89c4\u5212\u9636\u6bb5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u957f\u671f\u89c4\u5212\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u4e3a\u589e\u5f3aAI\u4ee3\u7406\u7684\u89c4\u5212\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.12908", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.12908", "abs": "https://arxiv.org/abs/2510.12908", "authors": ["Rouzbeh Behnia", "Jeremiah Birrell", "Arman Riasi", "Reza Ebrahimi", "Kaushik Dutta", "Thang Hoang"], "title": "Local Differential Privacy for Federated Learning with Fixed Memory Usage and Per-Client Privacy", "comment": null, "summary": "Federated learning (FL) enables organizations to collaboratively train models\nwithout sharing their datasets. Despite this advantage, recent studies show\nthat both client updates and the global model can leak private information,\nlimiting adoption in sensitive domains such as healthcare. Local differential\nprivacy (LDP) offers strong protection by letting each participant privatize\nupdates before transmission. However, existing LDP methods were designed for\ncentralized training and introduce challenges in FL, including high resource\ndemands that can cause client dropouts and the lack of reliable privacy\nguarantees under asynchronous participation. These issues undermine model\ngeneralizability, fairness, and compliance with regulations such as HIPAA and\nGDPR. To address them, we propose L-RDP, a DP method designed for LDP that\nensures constant, lower memory usage to reduce dropouts and provides rigorous\nper-client privacy guarantees by accounting for intermittent participation.", "AI": {"tldr": "\u63d0\u51fa\u4e86L-RDP\u65b9\u6cd5\uff0c\u4e00\u79cd\u4e13\u4e3a\u8054\u90a6\u5b66\u4e60\u8bbe\u8ba1\u7684\u672c\u5730\u5dee\u5206\u9690\u79c1\u65b9\u6cd5\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709LDP\u65b9\u6cd5\u5728FL\u4e2d\u7684\u9ad8\u8d44\u6e90\u9700\u6c42\u548c\u9690\u79c1\u4fdd\u8bc1\u4e0d\u8db3\u95ee\u9898\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u5ba2\u6237\u7aef\u66f4\u65b0\u548c\u5168\u5c40\u6a21\u578b\u53ef\u80fd\u6cc4\u9732\u9690\u79c1\u4fe1\u606f\uff0c\u73b0\u6709\u672c\u5730\u5dee\u5206\u9690\u79c1\u65b9\u6cd5\u5728FL\u4e2d\u9762\u4e34\u9ad8\u8d44\u6e90\u9700\u6c42\u5bfc\u81f4\u5ba2\u6237\u7aef\u9000\u51fa\u3001\u5f02\u6b65\u53c2\u4e0e\u4e0b\u7f3a\u4e4f\u53ef\u9760\u9690\u79c1\u4fdd\u8bc1\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faL-RDP\u65b9\u6cd5\uff0c\u901a\u8fc7\u786e\u4fdd\u6052\u5b9a\u8f83\u4f4e\u7684\u5185\u5b58\u4f7f\u7528\u6765\u51cf\u5c11\u5ba2\u6237\u7aef\u9000\u51fa\uff0c\u5e76\u901a\u8fc7\u8003\u8651\u95f4\u6b47\u6027\u53c2\u4e0e\u63d0\u4f9b\u4e25\u683c\u7684\u6bcf\u5ba2\u6237\u7aef\u9690\u79c1\u4fdd\u8bc1\u3002", "result": "L-RDP\u65b9\u6cd5\u89e3\u51b3\u4e86\u73b0\u6709LDP\u65b9\u6cd5\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u964d\u4f4e\u4e86\u8d44\u6e90\u9700\u6c42\uff0c\u589e\u5f3a\u4e86\u9690\u79c1\u4fdd\u62a4\u3002", "conclusion": "L-RDP\u4e3a\u8054\u90a6\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u6709\u6548\u7684\u672c\u5730\u5dee\u5206\u9690\u79c1\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u5728\u533b\u7597\u7b49\u654f\u611f\u9886\u57df\u7684\u5b89\u5168\u5e94\u7528\u3002"}}
{"id": "2510.13078", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.13078", "abs": "https://arxiv.org/abs/2510.13078", "authors": ["Tri Minh-Triet Pham", "Diego Elias Costa", "Weiyi Shang", "Jinqiu Yang"], "title": "ADPerf: Investigating and Testing Performance in Autonomous Driving Systems", "comment": "13 pages, accepted by ASE 2025", "summary": "Obstacle detection is crucial to the operation of autonomous driving systems,\nwhich rely on multiple sensors, such as cameras and LiDARs, combined with code\nlogic and deep learning models to detect obstacles for time-sensitive\ndecisions. Consequently, obstacle detection latency is critical to the safety\nand effectiveness of autonomous driving systems. However, the latency of the\nobstacle detection module and its resilience to various changes in the LiDAR\npoint cloud data are not yet fully understood. In this work, we present the\nfirst comprehensive investigation on measuring and modeling the performance of\nthe obstacle detection modules in two industry-grade autonomous driving\nsystems, i.e., Apollo and Autoware. Learning from this investigation, we\nintroduce ADPerf, a tool that aims to generate realistic point cloud data test\ncases that can expose increased detection latency. Increasing latency decreases\nthe availability of the detected obstacles and stresses the capabilities of\nsubsequent modules in autonomous driving systems, i.e., the modules may be\nnegatively impacted by the increased latency in obstacle detection.\n  We applied ADPerf to stress-test the performance of widely used 3D obstacle\ndetection modules in autonomous driving systems, as well as the propagation of\nsuch tests on trajectory prediction modules. Our evaluation highlights the need\nto conduct performance testing of obstacle detection components, especially 3D\nobstacle detection, as they can be a major bottleneck to increased latency of\nthe autonomous driving system. Such an adverse outcome will also further\npropagate to other modules, reducing the overall reliability of autonomous\ndriving systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86ADPerf\u5de5\u5177\uff0c\u7528\u4e8e\u6d4b\u8bd5\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u4e2d\u969c\u788d\u7269\u68c0\u6d4b\u6a21\u5757\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f3D\u969c\u788d\u7269\u68c0\u6d4b\u7684\u5ef6\u8fdf\u95ee\u9898\u53ca\u5176\u5bf9\u5176\u4ed6\u6a21\u5757\u7684\u5f71\u54cd\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u969c\u788d\u7269\u68c0\u6d4b\u5ef6\u8fdf\u5bf9\u5b89\u5168\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u5bf9\u5176\u5ef6\u8fdf\u7279\u6027\u53ca\u5bf9\u70b9\u4e91\u6570\u636e\u53d8\u5316\u7684\u5f39\u6027\u7406\u89e3\u4e0d\u8db3\uff0c\u9700\u8981\u8fdb\u884c\u7cfb\u7edf\u6027\u7684\u6027\u80fd\u6d4b\u8bd5\u3002", "method": "\u5f00\u53d1\u4e86ADPerf\u5de5\u5177\uff0c\u751f\u6210\u903c\u771f\u7684\u70b9\u4e91\u6570\u636e\u6d4b\u8bd5\u7528\u4f8b\u6765\u66b4\u9732\u589e\u52a0\u7684\u68c0\u6d4b\u5ef6\u8fdf\uff0c\u5e76\u5728Apollo\u548cAutoware\u4e24\u4e2a\u5de5\u4e1a\u7ea7\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u4e2d\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u8bc4\u4f30\u663e\u793a3D\u969c\u788d\u7269\u68c0\u6d4b\u6a21\u5757\u53ef\u80fd\u6210\u4e3a\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5ef6\u8fdf\u7684\u4e3b\u8981\u74f6\u9888\uff0c\u8fd9\u79cd\u4e0d\u5229\u5f71\u54cd\u4f1a\u8fdb\u4e00\u6b65\u4f20\u64ad\u5230\u5176\u4ed6\u6a21\u5757\uff0c\u964d\u4f4e\u7cfb\u7edf\u6574\u4f53\u53ef\u9760\u6027\u3002", "conclusion": "\u9700\u8981\u8fdb\u884c\u969c\u788d\u7269\u68c0\u6d4b\u7ec4\u4ef6\u7684\u6027\u80fd\u6d4b\u8bd5\uff0c\u7279\u522b\u662f3D\u969c\u788d\u7269\u68c0\u6d4b\uff0c\u56e0\u4e3a\u5b83\u4eec\u662f\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5ef6\u8fdf\u589e\u52a0\u7684\u4e3b\u8981\u74f6\u9888\uff0c\u4f1a\u5f71\u54cd\u540e\u7eed\u6a21\u5757\u7684\u6027\u80fd\u3002"}}
{"id": "2510.12985", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.12985", "abs": "https://arxiv.org/abs/2510.12985", "authors": ["Simon Sinong Zhan", "Yao Liu", "Philip Wang", "Zinan Wang", "Qineng Wang", "Zhian Ruan", "Xiangyu Shi", "Xinyu Cao", "Frank Yang", "Kangrui Wang", "Huajie Shao", "Manling Li", "Qi Zhu"], "title": "SENTINEL: A Multi-Level Formal Framework for Safety Evaluation of LLM-based Embodied Agents", "comment": null, "summary": "We present Sentinel, the first framework for formally evaluating the physical\nsafety of Large Language Model(LLM-based) embodied agents across the semantic,\nplan, and trajectory levels. Unlike prior methods that rely on heuristic rules\nor subjective LLM judgments, Sentinel grounds practical safety requirements in\nformal temporal logic (TL) semantics that can precisely specify state\ninvariants, temporal dependencies, and timing constraints. It then employs a\nmulti-level verification pipeline where (i) at the semantic level, intuitive\nnatural language safety requirements are formalized into TL formulas and the\nLLM agent's understanding of these requirements is probed for alignment with\nthe TL formulas; (ii) at the plan level, high-level action plans and subgoals\ngenerated by the LLM agent are verified against the TL formulas to detect\nunsafe plans before execution; and (iii) at the trajectory level, multiple\nexecution trajectories are merged into a computation tree and efficiently\nverified against physically-detailed TL specifications for a final safety\ncheck. We apply Sentinel in VirtualHome and ALFRED, and formally evaluate\nmultiple LLM-based embodied agents against diverse safety requirements. Our\nexperiments show that by grounding physical safety in temporal logic and\napplying verification methods across multiple levels, Sentinel provides a\nrigorous foundation for systematically evaluating LLM-based embodied agents in\nphysical environments, exposing safety violations overlooked by previous\nmethods and offering insights into their failure modes.", "AI": {"tldr": "Sentinel\u662f\u9996\u4e2a\u7528\u4e8e\u5f62\u5f0f\u5316\u8bc4\u4f30\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5177\u8eab\u4ee3\u7406\u5728\u8bed\u4e49\u3001\u89c4\u5212\u548c\u8f68\u8ff9\u4e09\u4e2a\u5c42\u9762\u7269\u7406\u5b89\u5168\u6027\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u65f6\u6001\u903b\u8f91\u8bed\u4e49\u6765\u7cbe\u786e\u6307\u5b9a\u5b89\u5168\u9700\u6c42\uff0c\u5e76\u91c7\u7528\u591a\u7ea7\u9a8c\u8bc1\u7ba1\u9053\u8fdb\u884c\u7cfb\u7edf\u5316\u5b89\u5168\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u542f\u53d1\u5f0f\u89c4\u5219\u6216\u4e3b\u89c2\u7684LLM\u5224\u65ad\uff0c\u7f3a\u4e4f\u5bf9\u7269\u7406\u5b89\u5168\u6027\u7684\u5f62\u5f0f\u5316\u8bc4\u4f30\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u7cbe\u786e\u6307\u5b9a\u72b6\u6001\u4e0d\u53d8\u91cf\u3001\u65f6\u95f4\u4f9d\u8d56\u6027\u548c\u65f6\u5e8f\u7ea6\u675f\u7684\u4e25\u8c28\u65b9\u6cd5\u6765\u8bc4\u4f30LLM\u5177\u8eab\u4ee3\u7406\u7684\u5b89\u5168\u6027\u3002", "method": "\u91c7\u7528\u4e09\u7ea7\u9a8c\u8bc1\u7ba1\u9053\uff1a1) \u8bed\u4e49\u5c42\u9762\u5c06\u81ea\u7136\u8bed\u8a00\u5b89\u5168\u9700\u6c42\u5f62\u5f0f\u5316\u4e3a\u65f6\u6001\u903b\u8f91\u516c\u5f0f\uff0c\u5e76\u9a8c\u8bc1LLM\u4ee3\u7406\u5bf9\u8fd9\u4e9b\u9700\u6c42\u7684\u7406\u89e3\uff1b2) \u89c4\u5212\u5c42\u9762\u9a8c\u8bc1LLM\u751f\u6210\u7684\u9ad8\u7ea7\u884c\u52a8\u8ba1\u5212\u548c\u5b50\u76ee\u6807\u662f\u5426\u7b26\u5408\u65f6\u6001\u903b\u8f91\u516c\u5f0f\uff1b3) \u8f68\u8ff9\u5c42\u9762\u5c06\u591a\u4e2a\u6267\u884c\u8f68\u8ff9\u5408\u5e76\u4e3a\u8ba1\u7b97\u6811\uff0c\u9488\u5bf9\u7269\u7406\u7ec6\u8282\u5316\u7684\u65f6\u6001\u903b\u8f91\u89c4\u8303\u8fdb\u884c\u6700\u7ec8\u5b89\u5168\u68c0\u67e5\u3002", "result": "\u5728VirtualHome\u548cALFRED\u73af\u5883\u4e2d\u8bc4\u4f30\u591a\u4e2a\u57fa\u4e8eLLM\u7684\u5177\u8eab\u4ee3\u7406\uff0c\u5b9e\u9a8c\u8868\u660eSentinel\u80fd\u591f\u53d1\u73b0\u5148\u524d\u65b9\u6cd5\u5ffd\u7565\u7684\u5b89\u5168\u8fdd\u89c4\uff0c\u5e76\u63d0\u4f9b\u5bf9\u5931\u8d25\u6a21\u5f0f\u7684\u6df1\u5165\u6d1e\u5bdf\u3002", "conclusion": "\u901a\u8fc7\u5c06\u7269\u7406\u5b89\u5168\u57fa\u4e8e\u65f6\u6001\u903b\u8f91\u5e76\u5728\u591a\u4e2a\u5c42\u9762\u5e94\u7528\u9a8c\u8bc1\u65b9\u6cd5\uff0cSentinel\u4e3a\u5728\u7269\u7406\u73af\u5883\u4e2d\u7cfb\u7edf\u8bc4\u4f30\u57fa\u4e8eLLM\u7684\u5177\u8eab\u4ee3\u7406\u63d0\u4f9b\u4e86\u4e25\u8c28\u57fa\u7840\uff0c\u66b4\u9732\u4e86\u5148\u524d\u65b9\u6cd5\u672a\u53d1\u73b0\u7684\u5b89\u5168\u95ee\u9898\u3002"}}
{"id": "2510.13058", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.13058", "abs": "https://arxiv.org/abs/2510.13058", "authors": ["Tooba Aamir", "Marthie Grobler", "Giovanni Russello"], "title": "From misinformation to climate crisis: Navigating vulnerabilities in the cyber-physical-social systems", "comment": null, "summary": "Within the cyber-physical-social-climate nexus, all systems are deeply\ninterdependent: cyber infrastructure facilitates communication, data\nprocessing, and automation across physical systems (such as power grids and\nnetworks), while social infrastructure provides the human capital and societal\nnorms necessary for the system's functionality. Any disruption within any of\nthese components, whether due to human error or system mismanagement, can\npropagate throughout the network, amplifying vulnerabilities and creating a\nsignificantly scaled impact. This chapter explores the critical role of human\nvulnerabilities within the cyber-physical-social-climate nexus, focusing on the\ninterdependencies across cyber, physical, and social systems and how these\ninterdependencies can scale in a climate context. While cyber and physical\nvulnerabilities are readily apparent, social vulnerabilities (such as\nmisinformation, resistance to policy change, and lack of public awareness)\noften go unaddressed despite their profound impact on resilience and climate\nadaptation. Social infrastructure, including human capital, societal norms, and\npolicy frameworks, shapes community responses and underpins adaptive capacity,\nyet it is also a significant point of failure when overlooked. This chapter\nexamines how human cognitive biases, risk misperception, and decision-making\nsilos within interconnected systems can lead to resource misallocation and\nweakened policy effectiveness. These factors are analyzed to demonstrate how\ninadequate responses across cyber-physical-social layers can cascade,\namplifying climate-related risks. By addressing these human factors and\naligning decision-making frameworks, we aim to strengthen resilience and foster\ncohesive adaptation strategies that account for the intricate interrelations of\ncyber-physical-social-climate systems.", "AI": {"tldr": "\u672c\u7ae0\u63a2\u8ba8\u4e86\u7f51\u7edc-\u7269\u7406-\u793e\u4f1a-\u6c14\u5019\u7cfb\u7edf\u4e2d\u4eba\u7c7b\u8106\u5f31\u6027\u7684\u5173\u952e\u4f5c\u7528\uff0c\u5206\u6790\u4e86\u8de8\u7cfb\u7edf\u4f9d\u8d56\u5173\u7cfb\u5982\u4f55\u653e\u5927\u6c14\u5019\u98ce\u9669\uff0c\u5e76\u63d0\u51fa\u4e86\u901a\u8fc7\u89e3\u51b3\u4eba\u7c7b\u8ba4\u77e5\u504f\u5dee\u548c\u51b3\u7b56\u6846\u67b6\u6765\u589e\u5f3a\u7cfb\u7edf\u97e7\u6027\u7684\u7b56\u7565\u3002", "motivation": "\u5728\u7f51\u7edc-\u7269\u7406-\u793e\u4f1a-\u6c14\u5019\u7cfb\u7edf\u4e2d\uff0c\u867d\u7136\u7f51\u7edc\u548c\u7269\u7406\u8106\u5f31\u6027\u663e\u800c\u6613\u89c1\uff0c\u4f46\u793e\u4f1a\u8106\u5f31\u6027\uff08\u5982\u9519\u8bef\u4fe1\u606f\u3001\u653f\u7b56\u62b5\u5236\u3001\u516c\u4f17\u610f\u8bc6\u4e0d\u8db3\uff09\u5f80\u5f80\u88ab\u5ffd\u89c6\uff0c\u5c3d\u7ba1\u5b83\u4eec\u5bf9\u7cfb\u7edf\u97e7\u6027\u548c\u6c14\u5019\u9002\u5e94\u5177\u6709\u6df1\u8fdc\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5206\u6790\u4eba\u7c7b\u8ba4\u77e5\u504f\u5dee\u3001\u98ce\u9669\u8bef\u5224\u548c\u51b3\u7b56\u5b64\u5c9b\u5728\u4e92\u8fde\u7cfb\u7edf\u4e2d\u7684\u5f71\u54cd\uff0c\u7814\u7a76\u8fd9\u4e9b\u56e0\u7d20\u5982\u4f55\u5bfc\u81f4\u8d44\u6e90\u9519\u914d\u548c\u653f\u7b56\u6709\u6548\u6027\u51cf\u5f31\uff0c\u4ee5\u53ca\u4e0d\u5145\u5206\u7684\u54cd\u5e94\u5982\u4f55\u5728\u7f51\u7edc-\u7269\u7406-\u793e\u4f1a\u5c42\u9762\u7ea7\u8054\u653e\u5927\u6c14\u5019\u98ce\u9669\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u793e\u4f1a\u57fa\u7840\u8bbe\u65bd\uff08\u5305\u62ec\u4eba\u529b\u8d44\u672c\u3001\u793e\u4f1a\u89c4\u8303\u548c\u653f\u7b56\u6846\u67b6\uff09\u5851\u9020\u793e\u533a\u54cd\u5e94\u5e76\u652f\u6491\u9002\u5e94\u80fd\u529b\uff0c\u4f46\u5f53\u88ab\u5ffd\u89c6\u65f6\u4e5f\u4f1a\u6210\u4e3a\u91cd\u8981\u7684\u6545\u969c\u70b9\u3002", "conclusion": "\u901a\u8fc7\u89e3\u51b3\u8fd9\u4e9b\u4eba\u4e3a\u56e0\u7d20\u5e76\u8c03\u6574\u51b3\u7b56\u6846\u67b6\uff0c\u53ef\u4ee5\u589e\u5f3a\u7cfb\u7edf\u97e7\u6027\uff0c\u57f9\u517b\u8003\u8651\u7f51\u7edc-\u7269\u7406-\u793e\u4f1a-\u6c14\u5019\u7cfb\u7edf\u590d\u6742\u76f8\u4e92\u5173\u7cfb\u7684\u534f\u8c03\u9002\u5e94\u7b56\u7565\u3002"}}
{"id": "2510.13106", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.13106", "abs": "https://arxiv.org/abs/2510.13106", "authors": ["Ruoyu Sun", "Da Song", "Jiayang Song", "Yuheng Huang", "Lei Ma"], "title": "TRUSTVIS: A Multi-Dimensional Trustworthiness Evaluation Framework for Large Language Models", "comment": "4 pages, 2 figures, To appear in ASE 2025 Demo Track", "summary": "As Large Language Models (LLMs) continue to revolutionize Natural Language\nProcessing (NLP) applications, critical concerns about their trustworthiness\npersist, particularly in safety and robustness. To address these challenges, we\nintroduce TRUSTVIS, an automated evaluation framework that provides a\ncomprehensive assessment of LLM trustworthiness. A key feature of our framework\nis its interactive user interface, designed to offer intuitive visualizations\nof trustworthiness metrics. By integrating well-known perturbation methods like\nAutoDAN and employing majority voting across various evaluation methods,\nTRUSTVIS not only provides reliable results but also makes complex evaluation\nprocesses accessible to users. Preliminary case studies on models like\nVicuna-7b, Llama2-7b, and GPT-3.5 demonstrate the effectiveness of our\nframework in identifying safety and robustness vulnerabilities, while the\ninteractive interface allows users to explore results in detail, empowering\ntargeted model improvements. Video Link: https://youtu.be/k1TrBqNVg8g", "AI": {"tldr": "TRUSTVIS\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u4ea4\u4e92\u5f0f\u754c\u9762\u53ef\u89c6\u5316\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4fe1\u4efb\u5ea6\u6307\u6807\uff0c\u7ed3\u5408AutoDAN\u7b49\u6270\u52a8\u65b9\u6cd5\u548c\u591a\u6570\u6295\u7968\u673a\u5236\uff0c\u6709\u6548\u8bc6\u522b\u6a21\u578b\u7684\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u6f0f\u6d1e\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728NLP\u5e94\u7528\u4e2d\u7684\u5e7f\u6cdb\u4f7f\u7528\uff0c\u5176\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u7b49\u53ef\u4fe1\u5ea6\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u96c6\u6210AutoDAN\u7b49\u77e5\u540d\u6270\u52a8\u65b9\u6cd5\uff0c\u91c7\u7528\u591a\u6570\u6295\u7968\u673a\u5236\u6574\u5408\u591a\u79cd\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5e76\u63d0\u4f9b\u4ea4\u4e92\u5f0f\u7528\u6237\u754c\u9762\u76f4\u89c2\u5c55\u793a\u4fe1\u4efb\u5ea6\u6307\u6807\u3002", "result": "\u5728Vicuna-7b\u3001Llama2-7b\u548cGPT-3.5\u7b49\u6a21\u578b\u4e0a\u7684\u521d\u6b65\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u6709\u6548\u8bc6\u522b\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u6f0f\u6d1e\u3002", "conclusion": "TRUSTVIS\u6846\u67b6\u4e0d\u4ec5\u63d0\u4f9b\u53ef\u9760\u7684\u8bc4\u4f30\u7ed3\u679c\uff0c\u8fd8\u4f7f\u590d\u6742\u7684\u8bc4\u4f30\u8fc7\u7a0b\u5bf9\u7528\u6237\u66f4\u52a0\u53cb\u597d\uff0c\u6709\u52a9\u4e8e\u9488\u5bf9\u6027\u7684\u6a21\u578b\u6539\u8fdb\u3002"}}
{"id": "2510.13002", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.13002", "abs": "https://arxiv.org/abs/2510.13002", "authors": ["Boyou Chen", "Gerui Xu", "Zifei Wang", "Huizhong Guo", "Ananna Ahmed", "Zhaonan Sun", "Zhen Hu", "Kaihan Zhang", "Shan Bao"], "title": "From Narratives to Probabilistic Reasoning: Predicting and Interpreting Drivers' Hazardous Actions in Crashes Using Large Language Model", "comment": null, "summary": "Vehicle crashes involve complex interactions between road users, split-second\ndecisions, and challenging environmental conditions. Among these, two-vehicle\ncrashes are the most prevalent, accounting for approximately 70% of roadway\ncrashes and posing a significant challenge to traffic safety. Identifying\nDriver Hazardous Action (DHA) is essential for understanding crash causation,\nyet the reliability of DHA data in large-scale databases is limited by\ninconsistent and labor-intensive manual coding practices. Here, we present an\ninnovative framework that leverages a fine-tuned large language model to\nautomatically infer DHAs from textual crash narratives, thereby improving the\nvalidity and interpretability of DHA classifications. Using five years of\ntwo-vehicle crash data from MTCF, we fine-tuned the Llama 3.2 1B model on\ndetailed crash narratives and benchmarked its performance against conventional\nmachine learning classifiers, including Random Forest, XGBoost, CatBoost, and a\nneural network. The fine-tuned LLM achieved an overall accuracy of 80%,\nsurpassing all baseline models and demonstrating pronounced improvements in\nscenarios with imbalanced data. To increase interpretability, we developed a\nprobabilistic reasoning approach, analyzing model output shifts across original\ntest sets and three targeted counterfactual scenarios: variations in driver\ndistraction and age. Our analysis revealed that introducing distraction for one\ndriver substantially increased the likelihood of \"General Unsafe Driving\";\ndistraction for both drivers maximized the probability of \"Both Drivers Took\nHazardous Actions\"; and assigning a teen driver markedly elevated the\nprobability of \"Speed and Stopping Violations.\" Our framework and analytical\nmethods provide a robust and interpretable solution for large-scale automated\nDHA detection, offering new opportunities for traffic safety analysis and\nintervention.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6846\u67b6\uff0c\u81ea\u52a8\u4ece\u4e8b\u6545\u6587\u672c\u53d9\u8ff0\u4e2d\u63a8\u65ad\u9a7e\u9a76\u5458\u5371\u9669\u884c\u4e3a\uff0c\u63d0\u9ad8\u5206\u7c7b\u6709\u6548\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5728\u4e8c\u8f66\u4e8b\u6545\u6570\u636e\u4e0a\u8fbe\u523080%\u51c6\u786e\u7387\u3002", "motivation": "\u4e8c\u8f66\u4e8b\u6545\u5360\u9053\u8def\u4e8b\u654570%\uff0c\u4f46\u73b0\u6709\u9a7e\u9a76\u5458\u5371\u9669\u884c\u4e3a\u6570\u636e\u56e0\u4eba\u5de5\u7f16\u7801\u4e0d\u4e00\u81f4\u4e14\u52b3\u52a8\u5bc6\u96c6\u800c\u53ef\u9760\u6027\u6709\u9650\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528MTCF\u4e94\u5e74\u4e8c\u8f66\u4e8b\u6545\u6570\u636e\uff0c\u5fae\u8c03Llama 3.2 1B\u6a21\u578b\u5904\u7406\u8be6\u7ec6\u4e8b\u6545\u53d9\u8ff0\uff0c\u5e76\u4e0e\u968f\u673a\u68ee\u6797\u3001XGBoost\u3001CatBoost\u548c\u795e\u7ecf\u7f51\u7edc\u7b49\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u8fdb\u884c\u57fa\u51c6\u6bd4\u8f83\u3002", "result": "\u5fae\u8c03LLM\u603b\u4f53\u51c6\u786e\u7387\u8fbe80%\uff0c\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u6a21\u578b\uff0c\u5728\u6570\u636e\u4e0d\u5e73\u8861\u573a\u666f\u4e2d\u8868\u73b0\u5c24\u5176\u7a81\u51fa\u3002\u6982\u7387\u63a8\u7406\u5206\u6790\u663e\u793a\uff0c\u5206\u5fc3\u9a7e\u9a76\u663e\u8457\u589e\u52a0\"\u4e00\u822c\u4e0d\u5b89\u5168\u9a7e\u9a76\"\u6982\u7387\uff0c\u53cc\u65b9\u5206\u5fc3\u6700\u5927\u5316\"\u53cc\u65b9\u5371\u9669\u884c\u4e3a\"\u6982\u7387\uff0c\u9752\u5c11\u5e74\u9a7e\u9a76\u663e\u8457\u589e\u52a0\"\u901f\u5ea6\u548c\u505c\u8f66\u8fdd\u89c4\"\u6982\u7387\u3002", "conclusion": "\u8be5\u6846\u67b6\u548c\u5206\u6790\u65b9\u6cd5\u4e3a\u5927\u89c4\u6a21\u81ea\u52a8\u5316DHA\u68c0\u6d4b\u63d0\u4f9b\u4e86\u7a33\u5065\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u4ea4\u901a\u5b89\u5168\u5206\u6790\u548c\u5e72\u9884\u5f00\u8f9f\u4e86\u65b0\u673a\u4f1a\u3002"}}
{"id": "2510.13102", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.13102", "abs": "https://arxiv.org/abs/2510.13102", "authors": ["Victor Olaiya", "Adwait Nadkarni"], "title": "From base cases to backdoors: An Empirical Study of Unnatural Crypto-API Misuse", "comment": null, "summary": "Tools focused on cryptographic API misuse often detect the most basic\nexpressions of the vulnerable use, and are unable to detect non-trivial\nvariants. The question of whether tools should be designed to detect such\nvariants can only be answered if we know how developers use and misuse\ncryptographic APIs in the wild, and in particular, what the unnatural usage of\nsuch APIs looks like. This paper presents the first large-scale study that\ncharacterizes unnatural crypto-API usage through a qualitative analysis of\n5,704 representative API invocations. We develop an intuitive complexity metric\nto stratify 140,431 crypto-API invocations obtained from 20,508 Android\napplications, allowing us to sample 5,704 invocations that are representative\nof all strata, with each stratum consisting of invocations with similar\ncomplexity/naturalness. We qualitatively analyze the 5,704 sampled invocations\nusing manual reverse engineering, through an in-depth investigation that\ninvolves the development of minimal examples and exploration of native code.\nOur study results in two detailed taxonomies of unnatural crypto-API misuse,\nalong with 17 key findings that show the presence of highly unusual misuse,\nevasive code, and the inability of popular tools to reason about even mildly\nunconventional usage. Our findings lead to four key takeaways that inform\nfuture work focused on detecting unnatural crypto-API misuse.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u5927\u89c4\u6a21\u7814\u7a76\u5bc6\u7801API\u7684\u975e\u81ea\u7136\u4f7f\u7528\u6a21\u5f0f\uff0c\u901a\u8fc7\u5206\u679020,508\u4e2aAndroid\u5e94\u7528\u7684140,431\u4e2aAPI\u8c03\u7528\uff0c\u5b9a\u6027\u5206\u67905,704\u4e2a\u4ee3\u8868\u6027\u8c03\u7528\uff0c\u63ed\u793a\u4e86\u9ad8\u5ea6\u4e0d\u5bfb\u5e38\u7684\u8bef\u7528\u3001\u89c4\u907f\u4ee3\u7801\u4ee5\u53ca\u6d41\u884c\u5de5\u5177\u7684\u68c0\u6d4b\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u53ea\u80fd\u68c0\u6d4b\u6700\u57fa\u672c\u7684\u5bc6\u7801API\u8bef\u7528\uff0c\u65e0\u6cd5\u68c0\u6d4b\u975e\u5e73\u51e1\u53d8\u4f53\u3002\u9700\u8981\u4e86\u89e3\u5f00\u53d1\u8005\u5982\u4f55\u5728\u5b9e\u9645\u4e2d\u8bef\u7528\u5bc6\u7801API\uff0c\u7279\u522b\u662f\u975e\u81ea\u7136\u4f7f\u7528\u6a21\u5f0f\uff0c\u4ee5\u6307\u5bfc\u5de5\u5177\u8bbe\u8ba1\u3002", "method": "\u5f00\u53d1\u76f4\u89c2\u590d\u6742\u5ea6\u6307\u6807\u5bf9140,431\u4e2a\u5bc6\u7801API\u8c03\u7528\u8fdb\u884c\u5206\u5c42\uff0c\u4ece20,508\u4e2aAndroid\u5e94\u7528\u4e2d\u91c7\u68375,704\u4e2a\u4ee3\u8868\u6027\u8c03\u7528\u8fdb\u884c\u5b9a\u6027\u5206\u6790\uff0c\u5305\u62ec\u624b\u52a8\u9006\u5411\u5de5\u7a0b\u3001\u5f00\u53d1\u6700\u5c0f\u793a\u4f8b\u548c\u63a2\u7d22\u539f\u751f\u4ee3\u7801\u3002", "result": "\u7814\u7a76\u5f97\u51fa\u4e24\u4e2a\u8be6\u7ec6\u7684\u975e\u81ea\u7136\u5bc6\u7801API\u8bef\u7528\u5206\u7c7b\u6cd5\uff0c\u4ee5\u53ca17\u4e2a\u5173\u952e\u53d1\u73b0\uff0c\u663e\u793a\u5b58\u5728\u9ad8\u5ea6\u4e0d\u5bfb\u5e38\u7684\u8bef\u7528\u3001\u89c4\u907f\u4ee3\u7801\uff0c\u6d41\u884c\u5de5\u5177\u751a\u81f3\u65e0\u6cd5\u68c0\u6d4b\u8f7b\u5ea6\u975e\u4f20\u7edf\u7528\u6cd5\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u56db\u4e2a\u5173\u952e\u542f\u793a\uff0c\u4e3a\u672a\u6765\u68c0\u6d4b\u975e\u81ea\u7136\u5bc6\u7801API\u8bef\u7528\u7684\u5de5\u4f5c\u63d0\u4f9b\u6307\u5bfc\uff0c\u5f3a\u8c03\u9700\u8981\u66f4\u5148\u8fdb\u7684\u68c0\u6d4b\u65b9\u6cd5\u6765\u5e94\u5bf9\u590d\u6742\u7684\u8bef\u7528\u6a21\u5f0f\u3002"}}
{"id": "2510.13128", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.13128", "abs": "https://arxiv.org/abs/2510.13128", "authors": ["Yujie Liu", "Mingxuan Zhu", "Shengyu Cheng", "Dan Hao"], "title": "Isolating Compiler Bugs through Compilation Steps Analysis", "comment": null, "summary": "Compilers are essential to software systems, and their bugs can propagate to\ndependent software. Ensuring compiler correctness is critical. However,\nisolating compiler bugs remains challenging due to the internal complexity of\ncompiler execution. Existing techniques primarily mutate compilation inputs to\ngenerate passing and failing tests, but often lack causal analysis of internal\nsteps, limiting their effectiveness.\n  To address this limitation, we propose CompSCAN, a novel compiler bug\nisolation technique that applies analysis over the sequence of compilation\nsteps. CompSCAN follows a three-stage process: (1) extracting the array of\ncompilation steps that leads to the original failure, (2) identifying\nbug-causing steps and collecting corresponding compiler code elements, and (3)\ncalculating suspicious scores for each code element and outputting a suspicious\nranking list as the bug isolation result.\n  We evaluate CompSCAN on 185 real-world LLVM and GCC bugs. Results show that\nCompSCAN outperforms state-of-the-art techniques in both effectiveness and\nefficiency. CompSCAN successfully isolates 50, 85, 100, and 123 bugs within the\nTop-1/3/5/10 ranks, respectively. Compared with ETEM and ODFL, two\nstate-of-the-art compiler bug isolation techniques, CompSCAN achieves relative\nimprovements of 44.51% / 50.18% / 36.24% / 24.49% over ETEM, and 31.58% /\n49.12% / 44.93% / 21.78% over ODFL on those metrics. Moreover, CompSCAN runs\nfaster on average per bug than both baselines.", "AI": {"tldr": "CompSCAN\u662f\u4e00\u79cd\u65b0\u9896\u7684\u7f16\u8bd1\u5668bug\u9694\u79bb\u6280\u672f\uff0c\u901a\u8fc7\u5206\u6790\u7f16\u8bd1\u6b65\u9aa4\u5e8f\u5217\u6765\u8bc6\u522b\u5bfc\u81f4bug\u7684\u7f16\u8bd1\u5668\u4ee3\u7801\u5143\u7d20\uff0c\u5728LLVM\u548cGCC\u7684\u771f\u5b9ebug\u4e0a\u8868\u73b0\u51fa\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u7684\u6548\u679c\u548c\u6548\u7387\u3002", "motivation": "\u7f16\u8bd1\u5668bug\u4f1a\u4f20\u64ad\u5230\u4f9d\u8d56\u8f6f\u4ef6\u4e2d\uff0c\u786e\u4fdd\u7f16\u8bd1\u5668\u6b63\u786e\u6027\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u6280\u672f\u4e3b\u8981\u901a\u8fc7\u53d8\u5f02\u7f16\u8bd1\u8f93\u5165\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5185\u90e8\u6b65\u9aa4\u7684\u56e0\u679c\u5206\u6790\uff0c\u9650\u5236\u4e86\u5176\u6709\u6548\u6027\u3002", "method": "CompSCAN\u91c7\u7528\u4e09\u9636\u6bb5\u6d41\u7a0b\uff1a(1)\u63d0\u53d6\u5bfc\u81f4\u539f\u59cb\u5931\u8d25\u7684\u7f16\u8bd1\u6b65\u9aa4\u5e8f\u5217\uff0c(2)\u8bc6\u522bbug\u5bfc\u81f4\u6b65\u9aa4\u5e76\u6536\u96c6\u5bf9\u5e94\u7684\u7f16\u8bd1\u5668\u4ee3\u7801\u5143\u7d20\uff0c(3)\u8ba1\u7b97\u6bcf\u4e2a\u4ee3\u7801\u5143\u7d20\u7684\u53ef\u7591\u5ea6\u5e76\u8f93\u51fa\u53ef\u7591\u5ea6\u6392\u540d\u5217\u8868\u3002", "result": "\u5728185\u4e2a\u771f\u5b9eLLVM\u548cGCC bug\u4e0a\u8bc4\u4f30\uff0cCompSCAN\u5728\u524d1/3/5/10\u540d\u4e2d\u5206\u522b\u6210\u529f\u9694\u79bb\u4e8650\u300185\u3001100\u548c123\u4e2abug\u3002\u76f8\u6bd4ETEM\u548cODFL\u6280\u672f\uff0c\u5728\u5404\u9879\u6307\u6807\u4e0a\u5206\u522b\u5b9e\u73b0\u4e8644.51%/50.18%/36.24%/24.49%\u548c31.58%/49.12%/44.93%/21.78%\u7684\u76f8\u5bf9\u6539\u8fdb\uff0c\u4e14\u8fd0\u884c\u901f\u5ea6\u66f4\u5feb\u3002", "conclusion": "CompSCAN\u901a\u8fc7\u5206\u6790\u7f16\u8bd1\u6b65\u9aa4\u5e8f\u5217\u6709\u6548\u63d0\u5347\u4e86\u7f16\u8bd1\u5668bug\u9694\u79bb\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002"}}
{"id": "2510.13029", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13029", "abs": "https://arxiv.org/abs/2510.13029", "authors": ["Xinlei Wang", "Mingtian Tan", "Jing Qiu", "Junhua Zhao", "Jinjin Gu"], "title": "Toward Reasoning-Centric Time-Series Analysis", "comment": null, "summary": "Traditional time series analysis has long relied on pattern recognition,\ntrained on static and well-established benchmarks. However, in real-world\nsettings -- where policies shift, human behavior adapts, and unexpected events\nunfold -- effective analysis must go beyond surface-level trends to uncover the\nactual forces driving them. The recent rise of Large Language Models (LLMs)\npresents new opportunities for rethinking time series analysis by integrating\nmultimodal inputs. However, as the use of LLMs becomes popular, we must remain\ncautious, asking why we use LLMs and how to exploit them effectively. Most\nexisting LLM-based methods still employ their numerical regression ability and\nignore their deeper reasoning potential. This paper argues for rethinking time\nseries with LLMs as a reasoning task that prioritizes causal structure and\nexplainability. This shift brings time series analysis closer to human-aligned\nunderstanding, enabling transparent and context-aware insights in complex\nreal-world environments.", "AI": {"tldr": "\u672c\u6587\u4e3b\u5f20\u5c06\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u91cd\u65b0\u6784\u60f3\u4e3a\u57fa\u4e8eLLM\u7684\u63a8\u7406\u4efb\u52a1\uff0c\u5f3a\u8c03\u56e0\u679c\u7ed3\u6784\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u800c\u975e\u4f20\u7edf\u7684\u6570\u503c\u56de\u5f52\u65b9\u6cd5\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u9700\u8981\u8d85\u8d8a\u8868\u9762\u8d8b\u52bf\uff0c\u63ed\u793a\u9a71\u52a8\u56e0\u7d20\u3002\u73b0\u6709LLM\u65b9\u6cd5\u4e3b\u8981\u5229\u7528\u6570\u503c\u56de\u5f52\u80fd\u529b\uff0c\u5ffd\u89c6\u4e86\u5176\u6df1\u5c42\u63a8\u7406\u6f5c\u529b\u3002", "method": "\u5c06\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u91cd\u65b0\u5b9a\u4e49\u4e3a\u63a8\u7406\u4efb\u52a1\uff0c\u5229\u7528LLM\u7684\u591a\u6a21\u6001\u8f93\u5165\u6574\u5408\u80fd\u529b\uff0c\u91cd\u70b9\u5173\u6ce8\u56e0\u679c\u7ed3\u6784\u548c\u89e3\u91ca\u6027\u5206\u6790\u3002", "result": "\u8be5\u65b9\u6cd5\u4f7f\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u66f4\u63a5\u8fd1\u4eba\u7c7b\u5bf9\u9f50\u7684\u7406\u89e3\uff0c\u80fd\u591f\u5728\u590d\u6742\u73b0\u5b9e\u73af\u5883\u4e2d\u63d0\u4f9b\u900f\u660e\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u6d1e\u5bdf\u3002", "conclusion": "LLM\u5728\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u4e2d\u7684\u6709\u6548\u5e94\u7528\u5e94\u4fa7\u91cd\u4e8e\u63a8\u7406\u80fd\u529b\u800c\u975e\u6570\u503c\u56de\u5f52\uff0c\u8fd9\u6709\u52a9\u4e8e\u5b9e\u73b0\u66f4\u900f\u660e\u3001\u53ef\u89e3\u91ca\u7684\u5206\u6790\u6846\u67b6\u3002"}}
{"id": "2510.13111", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2510.13111", "abs": "https://arxiv.org/abs/2510.13111", "authors": ["Nuntipat Narkthong", "Yukui Luo", "Xiaolin Xu"], "title": "ShuffleV: A Microarchitectural Defense Strategy against Electromagnetic Side-Channel Attacks in Microprocessors", "comment": "Accepted by the 28th International Symposium on Research in Attacks,\n  Intrusions and Defenses (RAID 2025)", "summary": "The run-time electromagnetic (EM) emanation of microprocessors presents a\nside-channel that leaks the confidentiality of the applications running on\nthem. Many recent works have demonstrated successful attacks leveraging such\nside-channels to extract the confidentiality of diverse applications, such as\nthe key of cryptographic algorithms and the hyperparameter of neural network\nmodels. This paper proposes ShuffleV, a microarchitecture defense strategy\nagainst EM Side-Channel Attacks (SCAs). ShuffleV adopts the moving target\ndefense (MTD) philosophy, by integrating hardware units to randomly shuffle the\nexecution order of program instructions and optionally insert dummy\ninstructions, to nullify the statistical observation by attackers across\nrepetitive runs. We build ShuffleV on the open-source RISC-V core and provide\nsix design options, to suit different application scenarios. To enable rapid\nevaluation, we develop a ShuffleV simulator that can help users to (1) simulate\nthe performance overhead for each design option and (2) generate an execution\ntrace to validate the randomness of execution on their workload. We implement\nShuffleV on a Xilinx PYNQ-Z2 FPGA and validate its performance with two\nrepresentative victim applications against EM SCAs, AES encryption, and neural\nnetwork inference. The experimental results demonstrate that ShuffleV can\nprovide automatic protection for these applications, without any user\nintervention or software modification.", "AI": {"tldr": "ShuffleV\u662f\u4e00\u79cd\u9488\u5bf9\u7535\u78c1\u4fa7\u4fe1\u9053\u653b\u51fb\u7684\u5fae\u67b6\u6784\u9632\u5fa1\u7b56\u7565\uff0c\u901a\u8fc7\u968f\u673a\u91cd\u6392\u7a0b\u5e8f\u6307\u4ee4\u6267\u884c\u987a\u5e8f\u548c\u53ef\u9009\u63d2\u5165\u4f2a\u6307\u4ee4\u6765\u4fdd\u62a4\u5fae\u5904\u7406\u5668\u5e94\u7528\u3002", "motivation": "\u5fae\u5904\u7406\u5668\u7684\u8fd0\u884c\u65f6\u7535\u78c1\u8f90\u5c04\u4f1a\u6cc4\u9732\u5e94\u7528\u7a0b\u5e8f\u7684\u673a\u5bc6\u4fe1\u606f\uff0c\u5982\u52a0\u5bc6\u7b97\u6cd5\u5bc6\u94a5\u548c\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u53c2\u6570\uff0c\u73b0\u6709\u653b\u51fb\u5df2\u8bc1\u660e\u8fd9\u79cd\u4fa7\u4fe1\u9053\u7684\u5a01\u80c1\u3002", "method": "\u91c7\u7528\u79fb\u52a8\u76ee\u6807\u9632\u5fa1\u7406\u5ff5\uff0c\u5728\u5f00\u6e90RISC-V\u6838\u5fc3\u4e2d\u96c6\u6210\u786c\u4ef6\u5355\u5143\uff0c\u968f\u673a\u91cd\u6392\u6307\u4ee4\u6267\u884c\u987a\u5e8f\u5e76\u53ef\u9009\u63d2\u5165\u4f2a\u6307\u4ee4\uff0c\u4f7f\u653b\u51fb\u8005\u65e0\u6cd5\u901a\u8fc7\u591a\u6b21\u8fd0\u884c\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\u3002", "result": "\u5728FPGA\u4e0a\u5b9e\u73b0ShuffleV\uff0c\u5bf9AES\u52a0\u5bc6\u548c\u795e\u7ecf\u7f51\u7edc\u63a8\u7406\u8fdb\u884c\u6d4b\u8bd5\uff0c\u7ed3\u679c\u663e\u793a\u80fd\u81ea\u52a8\u4fdd\u62a4\u8fd9\u4e9b\u5e94\u7528\uff0c\u65e0\u9700\u7528\u6237\u5e72\u9884\u6216\u8f6f\u4ef6\u4fee\u6539\u3002", "conclusion": "ShuffleV\u80fd\u6709\u6548\u9632\u5fa1\u7535\u78c1\u4fa7\u4fe1\u9053\u653b\u51fb\uff0c\u63d0\u4f9b\u516d\u79cd\u8bbe\u8ba1\u9009\u9879\u9002\u5e94\u4e0d\u540c\u5e94\u7528\u573a\u666f\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u5668\u5b9e\u73b0\u5feb\u901f\u8bc4\u4f30\u3002"}}
{"id": "2510.13176", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.13176", "abs": "https://arxiv.org/abs/2510.13176", "authors": ["Haolin Pan", "Chao Zha", "Jinyuan Dong", "Mingjie Xing", "Yanjun Wu"], "title": "GRACE: Globally-Seeded Representation-Aware Cluster-Specific Evolution for Compiler Auto-Tuning", "comment": null, "summary": "Compiler pass selection and phase ordering present a significant challenge in\nachieving optimal program performance, particularly for objectives like code\nsize reduction. Standard compiler heuristics offer general applicability but\noften yield suboptimal, program-specific results due to their one-size-fits-all\nnature. While iterative compilation can find tailored solutions, its\nprohibitive search cost limits practical use. Machine learning approaches\npromise faster inference but frequently struggle with generalization to unseen\nprograms. This paper introduces GRACE, a novel framework for compiler\nauto-tuning, demonstrated for LLVM IR instruction count optimization. GRACE\neffectively curtails the search space by leveraging pass synergies and a\nweighted scoring method to generate initial high-quality candidate sequences\nand a pass pool. It then employs contrastive learning, using pass\nsequence-based data augmentation, to create program embeddings that facilitate\nsimilarity-aware clustering. Evolutionary search within these clusters yields a\ncoreset of $k$ specialized pass sequences designed for robust generalization to\nunseen programs. At test time, GRACE efficiently selects the best coreset\nsequence and refines it using lightweight techniques. Experimental results on\nseven diverse datasets show that GRACE reduces LLVM IR instruction count by an\naverage of 10.09% on LLVM 10.0.0 and 10.19% on LLVM 18.1.6 compared to opt -Oz,\nwhile incurring an average tuning time of less than 1s per program,\ndemonstrating its state-of-the-art performance and practical effectiveness.", "AI": {"tldr": "GRACE\u662f\u4e00\u4e2a\u7f16\u8bd1\u5668\u81ea\u52a8\u8c03\u4f18\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528pass\u534f\u540c\u6548\u5e94\u548c\u5bf9\u6bd4\u5b66\u4e60\u6765\u51cf\u5c11\u641c\u7d22\u7a7a\u95f4\uff0c\u751f\u6210\u4e13\u95e8\u7684pass\u5e8f\u5217\uff0c\u5728LLVM IR\u6307\u4ee4\u6570\u4f18\u5316\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u6807\u51c6\u7f16\u8bd1\u5668\u542f\u53d1\u5f0f\u65b9\u6cd5\u901a\u5e38\u4ea7\u751f\u6b21\u4f18\u7ed3\u679c\uff0c\u800c\u8fed\u4ee3\u7f16\u8bd1\u641c\u7d22\u6210\u672c\u8fc7\u9ad8\uff0c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u6cdb\u5316\u5230\u672a\u89c1\u7a0b\u5e8f\u65f6\u5b58\u5728\u56f0\u96be\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u9ad8\u6548\u53c8\u80fd\u826f\u597d\u6cdb\u5316\u7684\u7f16\u8bd1\u5668\u81ea\u52a8\u8c03\u4f18\u65b9\u6cd5\u3002", "method": "GRACE\u901a\u8fc7pass\u534f\u540c\u6548\u5e94\u548c\u52a0\u6743\u8bc4\u5206\u751f\u6210\u9ad8\u8d28\u91cf\u5019\u9009\u5e8f\u5217\u548cpass\u6c60\uff0c\u4f7f\u7528\u5bf9\u6bd4\u5b66\u4e60\u548c\u6570\u636e\u589e\u5f3a\u521b\u5efa\u7a0b\u5e8f\u5d4c\u5165\u8fdb\u884c\u76f8\u4f3c\u6027\u805a\u7c7b\uff0c\u5728\u805a\u7c7b\u5185\u8fdb\u884c\u8fdb\u5316\u641c\u7d22\u751f\u6210\u4e13\u95e8\u7684pass\u5e8f\u5217\u6838\u5fc3\u96c6\u3002", "result": "\u57287\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\uff0cGRACE\u76f8\u6bd4opt -Oz\u5e73\u5747\u51cf\u5c11LLVM IR\u6307\u4ee4\u657010.09%(LLVM 10.0.0)\u548c10.19%(LLVM 18.1.6)\uff0c\u5e73\u5747\u8c03\u4f18\u65f6\u95f4\u6bcf\u7a0b\u5e8f\u5c0f\u4e8e1\u79d2\u3002", "conclusion": "GRACE\u5728\u7f16\u8bd1\u5668\u81ea\u52a8\u8c03\u4f18\u65b9\u9762\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u548c\u5b9e\u9645\u6709\u6548\u6027\uff0c\u80fd\u591f\u9ad8\u6548\u5730\u751f\u6210\u4e13\u95e8\u5316\u7684pass\u5e8f\u5217\u5e76\u826f\u597d\u6cdb\u5316\u5230\u672a\u89c1\u7a0b\u5e8f\u3002"}}
{"id": "2510.13036", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.13036", "abs": "https://arxiv.org/abs/2510.13036", "authors": ["Stephane Hatgis-Kessell", "Logan Mondal Bhamidipaty", "Emma Brunskill"], "title": "Repairing Reward Functions with Human Feedback to Mitigate Reward Hacking", "comment": null, "summary": "Human-designed reward functions for reinforcement learning (RL) agents are\nfrequently misaligned with the humans' true, unobservable objectives, and thus\nact only as proxies. Optimizing for a misspecified proxy reward function often\ninduces reward hacking, resulting in a policy misaligned with the human's true\nobjectives. An alternative is to perform RL from human feedback, which involves\nlearning a reward function from scratch by collecting human preferences over\npairs of trajectories. However, building such datasets is costly. To address\nthe limitations of both approaches, we propose Preference-Based Reward Repair\n(PBRR): an automated iterative framework that repairs a human-specified proxy\nreward function by learning an additive, transition-dependent correction term\nfrom preferences. A manually specified reward function can yield policies that\nare highly suboptimal under the ground-truth objective, yet corrections on only\na few transitions may suffice to recover optimal performance. To identify and\ncorrect for those transitions, PBRR uses a targeted exploration strategy and a\nnew preference-learning objective. We prove in tabular domains PBRR has a\ncumulative regret that matches, up to constants, that of prior preference-based\nRL methods. In addition, on a suite of reward-hacking benchmarks, PBRR\nconsistently outperforms baselines that learn a reward function from scratch\nfrom preferences or modify the proxy reward function using other approaches,\nrequiring substantially fewer preferences to learn high performing policies.", "AI": {"tldr": "\u63d0\u51faPreference-Based Reward Repair (PBRR)\u6846\u67b6\uff0c\u901a\u8fc7\u4ece\u4eba\u7c7b\u504f\u597d\u4e2d\u5b66\u4e60\u52a0\u6027\u4fee\u6b63\u9879\u6765\u81ea\u52a8\u4fee\u590d\u4eba\u5de5\u8bbe\u8ba1\u7684\u4ee3\u7406\u5956\u52b1\u51fd\u6570\uff0c\u89e3\u51b3\u5956\u52b1\u51fd\u6570\u9519\u914d\u95ee\u9898\u3002", "motivation": "\u4eba\u5de5\u8bbe\u8ba1\u7684\u5956\u52b1\u51fd\u6570\u7ecf\u5e38\u4e0e\u4eba\u7c7b\u771f\u5b9e\u76ee\u6807\u4e0d\u4e00\u81f4\uff0c\u5bfc\u81f4\u5956\u52b1\u9ed1\u5ba2\u95ee\u9898\uff1b\u800c\u4ece\u96f6\u5b66\u4e60\u5956\u52b1\u51fd\u6570\u9700\u8981\u5927\u91cf\u4eba\u7c7b\u504f\u597d\u6570\u636e\uff0c\u6210\u672c\u9ad8\u6602\u3002", "method": "PBRR\u6846\u67b6\u4f7f\u7528\u9488\u5bf9\u6027\u63a2\u7d22\u7b56\u7565\u548c\u65b0\u504f\u597d\u5b66\u4e60\u76ee\u6807\uff0c\u5b66\u4e60\u4e00\u4e2a\u4e0e\u72b6\u6001\u8f6c\u79fb\u76f8\u5173\u7684\u52a0\u6027\u4fee\u6b63\u9879\u6765\u4fee\u590d\u4ee3\u7406\u5956\u52b1\u51fd\u6570\u3002", "result": "\u5728\u8868\u683c\u5316\u9886\u57df\u8bc1\u660ePBRR\u7684\u7d2f\u79ef\u9057\u61be\u4e0e\u73b0\u6709\u504f\u597d\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u76f8\u5f53\uff1b\u5728\u5956\u52b1\u9ed1\u5ba2\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPBRR\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u9700\u8981\u66f4\u5c11\u504f\u597d\u6570\u636e\u5373\u53ef\u5b66\u4e60\u9ad8\u6027\u80fd\u7b56\u7565\u3002", "conclusion": "PBRR\u80fd\u591f\u6709\u6548\u4fee\u590d\u9519\u914d\u7684\u4ee3\u7406\u5956\u52b1\u51fd\u6570\uff0c\u6bd4\u4ece\u96f6\u5b66\u4e60\u5956\u52b1\u51fd\u6570\u6216\u5176\u4ed6\u4fee\u6b63\u65b9\u6cd5\u66f4\u9ad8\u6548\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u4eba\u7c7b\u504f\u597d\u6570\u636e\u9700\u6c42\u3002"}}
{"id": "2510.13136", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.13136", "abs": "https://arxiv.org/abs/2510.13136", "authors": ["Tan Le", "Van Le", "Sachin Shetty"], "title": "Privacy-Aware Framework of Robust Malware Detection in Indoor Robots: Hybrid Quantum Computing and Deep Neural Networks", "comment": null, "summary": "Indoor robotic systems within Cyber-Physical Systems (CPS) are increasingly\nexposed to Denial of Service (DoS) attacks that compromise localization,\ncontrol and telemetry integrity. We propose a privacy-aware malware detection\nframework for indoor robotic systems, which leverages hybrid quantum computing\nand deep neural networks to counter DoS threats in CPS, while preserving\nprivacy information. By integrating quantum-enhanced feature encoding with\ndropout-optimized deep learning, our architecture achieves up to 95.2%\ndetection accuracy under privacy-constrained conditions. The system operates\nwithout handcrafted thresholds or persistent beacon data, enabling scalable\ndeployment in adversarial environments. Benchmarking reveals robust\ngeneralization, interpretability and resilience against training instability\nthrough modular circuit design. This work advances trustworthy AI for secure,\nautonomous CPS operations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u5ba4\u5185\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u9690\u79c1\u611f\u77e5\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u6846\u67b6\uff0c\u7ed3\u5408\u91cf\u5b50\u8ba1\u7b97\u548c\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6765\u5bf9\u6297CPS\u4e2d\u7684DoS\u653b\u51fb\uff0c\u540c\u65f6\u4fdd\u62a4\u9690\u79c1\u4fe1\u606f\u3002", "motivation": "\u5ba4\u5185\u673a\u5668\u4eba\u7cfb\u7edf\u5728CPS\u4e2d\u9762\u4e34DoS\u653b\u51fb\u5a01\u80c1\uff0c\u8fd9\u4e9b\u653b\u51fb\u4f1a\u635f\u5bb3\u5b9a\u4f4d\u3001\u63a7\u5236\u548c\u9065\u6d4b\u5b8c\u6574\u6027\uff0c\u9700\u8981\u5f00\u53d1\u65e2\u80fd\u6709\u6548\u68c0\u6d4b\u6076\u610f\u8f6f\u4ef6\u53c8\u80fd\u4fdd\u62a4\u9690\u79c1\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u6df7\u5408\u91cf\u5b50\u8ba1\u7b97\u65b9\u6cd5\uff0c\u5c06\u91cf\u5b50\u589e\u5f3a\u7279\u5f81\u7f16\u7801\u4e0edropout\u4f18\u5316\u7684\u6df1\u5ea6\u5b66\u4e60\u76f8\u7ed3\u5408\uff0c\u65e0\u9700\u624b\u5de5\u9608\u503c\u6216\u6301\u7eed\u4fe1\u6807\u6570\u636e\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u7535\u8def\u8bbe\u8ba1\u5b9e\u73b0\u3002", "result": "\u5728\u9690\u79c1\u7ea6\u675f\u6761\u4ef6\u4e0b\u8fbe\u523095.2%\u7684\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3001\u53ef\u89e3\u91ca\u6027\u548c\u5bf9\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u6027\u7684\u97e7\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63a8\u8fdb\u4e86\u53ef\u4fe1AI\u5728\u5b89\u5168\u3001\u81ea\u4e3bCPS\u64cd\u4f5c\u4e2d\u7684\u5e94\u7528\uff0c\u4e3a\u5bf9\u6297DoS\u5a01\u80c1\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.13184", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.13184", "abs": "https://arxiv.org/abs/2510.13184", "authors": ["Haolin Pan", "Jinyuan Dong", "Mingjie Xing", "Yanjun Wu"], "title": "Synergy-Guided Compiler Auto-Tuning of Nested LLVM Pass Pipelines", "comment": null, "summary": "Compiler optimization relies on sequences of passes to improve program\nperformance. Selecting and ordering these passes automatically, known as\ncompiler auto-tuning, is challenging due to the large and complex search space.\nExisting approaches generally assume a linear sequence of passes, a model\ncompatible with legacy compilers but fundamentally misaligned with the\nhierarchical design of the LLVM New Pass Manager. This misalignment prevents\nthem from guaranteeing the generation of syntactically valid optimization\npipelines. In this work, we present a new auto-tuning framework built from the\nground up for the New Pass Manager. We introduce a formal grammar to define the\nspace of valid nested pipelines and a forest-based data structure for their\nnative representation. Upon this foundation, we develop a structure-aware\nGenetic Algorithm whose operators manipulate these forests directly, ensuring\nthat all candidate solutions are valid by construction. The framework first\nmines synergistic pass relationships to guide the search. An optional\nrefinement stage further explores subtle performance variations arising from\ndifferent valid structural arrangements.\n  We evaluate our approach on seven benchmark datasets using LLVM 18.1.6. The\ndiscovered pipelines achieve an average of 13.62% additional instruction count\nreduction compared to the standard opt -Oz optimization level, showing that our\nframework is capable of navigating this complex, constrained search space to\nidentify valid and effective pass pipelines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e13\u4e3aLLVM\u65b0Pass\u7ba1\u7406\u5668\u8bbe\u8ba1\u7684\u7f16\u8bd1\u5668\u81ea\u52a8\u8c03\u4f18\u6846\u67b6\uff0c\u4f7f\u7528\u5f62\u5f0f\u5316\u8bed\u6cd5\u5b9a\u4e49\u6709\u6548\u5d4c\u5957\u7ba1\u9053\u7a7a\u95f4\uff0c\u901a\u8fc7\u7ed3\u6784\u611f\u77e5\u9057\u4f20\u7b97\u6cd5\u786e\u4fdd\u6240\u6709\u5019\u9009\u65b9\u6848\u5728\u6784\u9020\u65f6\u90fd\u662f\u6709\u6548\u7684\u3002", "motivation": "\u73b0\u6709\u7684\u7f16\u8bd1\u5668\u81ea\u52a8\u8c03\u4f18\u65b9\u6cd5\u5047\u8bbe\u7ebf\u6027pass\u5e8f\u5217\uff0c\u8fd9\u4e0eLLVM\u65b0Pass\u7ba1\u7406\u5668\u7684\u5206\u5c42\u8bbe\u8ba1\u4e0d\u5339\u914d\uff0c\u65e0\u6cd5\u4fdd\u8bc1\u751f\u6210\u8bed\u6cd5\u6709\u6548\u7684\u4f18\u5316\u7ba1\u9053\u3002", "method": "\u5f15\u5165\u5f62\u5f0f\u5316\u8bed\u6cd5\u5b9a\u4e49\u6709\u6548\u5d4c\u5957\u7ba1\u9053\u7a7a\u95f4\uff0c\u4f7f\u7528\u57fa\u4e8e\u68ee\u6797\u7684\u6570\u636e\u7ed3\u6784\u8fdb\u884c\u539f\u751f\u8868\u793a\uff0c\u5f00\u53d1\u7ed3\u6784\u611f\u77e5\u9057\u4f20\u7b97\u6cd5\u76f4\u63a5\u64cd\u4f5c\u8fd9\u4e9b\u68ee\u6797\uff0c\u786e\u4fdd\u6240\u6709\u5019\u9009\u65b9\u6848\u5728\u6784\u9020\u65f6\u6709\u6548\u3002", "result": "\u5728LLVM 18.1.6\u4e0a\u8bc4\u4f307\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u53d1\u73b0\u7684\u7ba1\u9053\u76f8\u6bd4\u6807\u51c6opt -Oz\u4f18\u5316\u7ea7\u522b\u5e73\u5747\u5b9e\u73b0\u4e8613.62%\u7684\u989d\u5916\u6307\u4ee4\u8ba1\u6570\u51cf\u5c11\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u5728\u8fd9\u4e2a\u590d\u6742\u3001\u53d7\u7ea6\u675f\u7684\u641c\u7d22\u7a7a\u95f4\u4e2d\u5bfc\u822a\uff0c\u8bc6\u522b\u6709\u6548\u4e14\u9ad8\u6548\u7684pass\u7ba1\u9053\u3002"}}
{"id": "2510.13195", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13195", "abs": "https://arxiv.org/abs/2510.13195", "authors": ["Qun Ma", "Xiao Xue", "Xuwen Zhang", "Zihan Zhao", "Yuwei Guo", "Ming Zhang"], "title": "Emotional Cognitive Modeling Framework with Desire-Driven Objective Optimization for LLM-empowered Agent in Social Simulation", "comment": null, "summary": "The advent of large language models (LLMs) has enabled agents to represent\nvirtual humans in societal simulations, facilitating diverse interactions\nwithin complex social systems. However, existing LLM-based agents exhibit\nsevere limitations in affective cognition: They fail to simulate the bounded\nrationality essential for bridging virtual and real-world services; They lack\nempirically validated integration mechanisms embedding emotions within agent\ndecision architectures. This paper constructs an emotional cognition framework\nincorporating desire generation and objective management, designed to achieve\nemotion alignment between LLM-based agents and humans, modeling the complete\ndecision-making process of LLM-based agents, encompassing state evolution,\ndesire generation, objective optimization, decision generation, and action\nexecution. This study implements the proposed framework within our proprietary\nmulti-agent interaction environment. Experimental results demonstrate that\nagents governed by our framework not only exhibit behaviors congruent with\ntheir emotional states but also, in comparative assessments against other agent\ntypes, demonstrate superior ecological validity and generate decision outcomes\nthat significantly more closely approximate human behavioral patterns.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u60c5\u611f\u8ba4\u77e5\u6846\u67b6\uff0c\u901a\u8fc7\u6b32\u671b\u751f\u6210\u548c\u76ee\u6807\u7ba1\u7406\u5b9e\u73b0LLM\u667a\u80fd\u4f53\u4e0e\u4eba\u7c7b\u7684\u60c5\u611f\u5bf9\u9f50\uff0c\u5728\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u6a21\u62df\u72b6\u6001\u6f14\u5316\u3001\u6b32\u671b\u751f\u6210\u3001\u76ee\u6807\u4f18\u5316\u3001\u51b3\u7b56\u751f\u6210\u548c\u884c\u52a8\u6267\u884c\u3002", "motivation": "\u73b0\u6709LLM\u667a\u80fd\u4f53\u5728\u60c5\u611f\u8ba4\u77e5\u65b9\u9762\u5b58\u5728\u4e25\u91cd\u5c40\u9650\uff1a\u65e0\u6cd5\u6a21\u62df\u8fde\u63a5\u865a\u62df\u4e0e\u73b0\u5b9e\u670d\u52a1\u7684\u6709\u9650\u7406\u6027\uff1b\u7f3a\u4e4f\u7ecf\u8fc7\u5b9e\u8bc1\u9a8c\u8bc1\u7684\u60c5\u611f\u4e0e\u51b3\u7b56\u67b6\u6784\u6574\u5408\u673a\u5236\u3002", "method": "\u6784\u5efa\u60c5\u611f\u8ba4\u77e5\u6846\u67b6\uff0c\u5305\u542b\u6b32\u671b\u751f\u6210\u548c\u76ee\u6807\u7ba1\u7406\uff0c\u5728\u4e13\u6709\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\u73af\u5883\u4e2d\u5b9e\u73b0\u5b8c\u6574\u7684\u51b3\u7b56\u8fc7\u7a0b\u5efa\u6a21\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u91c7\u7528\u8be5\u6846\u67b6\u7684\u667a\u80fd\u4f53\u4e0d\u4ec5\u8868\u73b0\u51fa\u4e0e\u60c5\u611f\u72b6\u6001\u4e00\u81f4\u7684\u884c\u4e3a\uff0c\u5728\u4e0e\u5176\u4ed6\u7c7b\u578b\u667a\u80fd\u4f53\u7684\u6bd4\u8f83\u4e2d\u5c55\u73b0\u51fa\u66f4\u9ad8\u7684\u751f\u6001\u6548\u5ea6\uff0c\u51b3\u7b56\u7ed3\u679c\u66f4\u63a5\u8fd1\u4eba\u7c7b\u884c\u4e3a\u6a21\u5f0f\u3002", "conclusion": "\u8be5\u60c5\u611f\u8ba4\u77e5\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86LLM\u667a\u80fd\u4f53\u4e0e\u4eba\u7c7b\u7684\u60c5\u611f\u5bf9\u9f50\uff0c\u663e\u8457\u63d0\u5347\u4e86\u667a\u80fd\u4f53\u5728\u793e\u4f1a\u6a21\u62df\u4e2d\u7684\u884c\u4e3a\u771f\u5b9e\u6027\u548c\u51b3\u7b56\u8d28\u91cf\u3002"}}
{"id": "2510.13257", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.13257", "abs": "https://arxiv.org/abs/2510.13257", "authors": ["Jiarui Li", "Yuhan Chai", "Lei Du", "Chenyun Duan", "Hao Yan", "Zhaoquan Gu"], "title": "GRIDAI: Generating and Repairing Intrusion Detection Rules via Collaboration among Multiple LLM-based Agents", "comment": null, "summary": "Rule-based network intrusion detection systems play a crucial role in the\nreal-time detection of Web attacks. However, most existing works primarily\nfocus on automatically generating detection rules for new attacks, often\noverlooking the relationships between new attacks and existing rules, which\nleads to significant redundancy within the ever-expanding ruleset. To address\nthis issue, we propose GRIDAI, a novel end-to-end framework for the automated\nGeneration and Repair of Intrusion Detection rules through collaboration among\nmultiple LLM-based agents. Unlike traditional methods, GRIDAI first assesses\nthe nature of incoming attack samples. If the sample represents a new attack\ntype, it is used to generate a new rule. Otherwise, the sample is identified as\na variant of an attack already covered by an existing rule and used to repair\nthe rule by updating the corresponding signature, thereby enhancing its\ngeneralization capability. Additionally, to mitigate syntactic and semantic\nerrors in rules caused by LLM hallucinations, we incorporate a tool-based\nreal-time validation mechanism and a representative attack sample maintained\nfor each rule, enabling fully automated rule generation and repair.\nComprehensive experiments were conducted on a public dataset containing seven\ntypes of attacks and a private dataset with 43 attack types. The results\ndemonstrate that GRIDAI accurately identifies the relationships between new\nattack samples and existing rules, efficiently generates and repairs rules to\nhandle new attacks and variants, and effectively mitigates the impact of LLM\nhallucinations.", "AI": {"tldr": "GRIDAI\u662f\u4e00\u4e2a\u57fa\u4e8e\u591aLLM\u4ee3\u7406\u534f\u4f5c\u7684\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u751f\u6210\u548c\u4fee\u590d\u5165\u4fb5\u68c0\u6d4b\u89c4\u5219\uff0c\u901a\u8fc7\u8bc6\u522b\u65b0\u653b\u51fb\u4e0e\u73b0\u6709\u89c4\u5219\u7684\u5173\u7cfb\u6765\u51cf\u5c11\u89c4\u5219\u5197\u4f59\uff0c\u5e76\u5305\u542b\u9a8c\u8bc1\u673a\u5236\u6765\u7f13\u89e3LLM\u5e7b\u89c9\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u89c4\u5219\u7684\u7f51\u7edc\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u4e3b\u8981\u5173\u6ce8\u4e3a\u65b0\u653b\u51fb\u81ea\u52a8\u751f\u6210\u68c0\u6d4b\u89c4\u5219\uff0c\u4f46\u5ffd\u89c6\u4e86\u65b0\u653b\u51fb\u4e0e\u73b0\u6709\u89c4\u5219\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5bfc\u81f4\u89c4\u5219\u96c6\u4e0d\u65ad\u81a8\u80c0\u4e14\u5b58\u5728\u663e\u8457\u5197\u4f59\u3002", "method": "GRIDAI\u9996\u5148\u8bc4\u4f30\u653b\u51fb\u6837\u672c\u7684\u6027\u8d28\uff1a\u5982\u679c\u662f\u65b0\u653b\u51fb\u7c7b\u578b\u5219\u751f\u6210\u65b0\u89c4\u5219\uff0c\u5982\u679c\u662f\u73b0\u6709\u653b\u51fb\u7684\u53d8\u4f53\u5219\u4fee\u590d\u76f8\u5e94\u89c4\u5219\u4ee5\u589e\u5f3a\u6cdb\u5316\u80fd\u529b\u3002\u6846\u67b6\u5305\u542b\u57fa\u4e8e\u5de5\u5177\u7684\u5b9e\u65f6\u9a8c\u8bc1\u673a\u5236\u548c\u4ee3\u8868\u6027\u653b\u51fb\u6837\u672c\u7ef4\u62a4\uff0c\u4ee5\u7f13\u89e3LLM\u5e7b\u89c9\u5bfc\u81f4\u7684\u8bed\u6cd5\u548c\u8bed\u4e49\u9519\u8bef\u3002", "result": "\u5728\u5305\u542b7\u79cd\u653b\u51fb\u7c7b\u578b\u7684\u516c\u5171\u6570\u636e\u96c6\u548c43\u79cd\u653b\u51fb\u7c7b\u578b\u7684\u79c1\u6709\u6570\u636e\u96c6\u4e0a\u7684\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0cGRIDAI\u80fd\u51c6\u786e\u8bc6\u522b\u65b0\u653b\u51fb\u6837\u672c\u4e0e\u73b0\u6709\u89c4\u5219\u7684\u5173\u7cfb\uff0c\u9ad8\u6548\u751f\u6210\u548c\u4fee\u590d\u89c4\u5219\u5904\u7406\u65b0\u653b\u51fb\u548c\u53d8\u4f53\uff0c\u5e76\u6709\u6548\u7f13\u89e3LLM\u5e7b\u89c9\u7684\u5f71\u54cd\u3002", "conclusion": "GRIDAI\u901a\u8fc7\u591aLLM\u4ee3\u7406\u534f\u4f5c\u5b9e\u73b0\u4e86\u5165\u4fb5\u68c0\u6d4b\u89c4\u5219\u7684\u81ea\u52a8\u751f\u6210\u548c\u4fee\u590d\uff0c\u89e3\u51b3\u4e86\u89c4\u5219\u5197\u4f59\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u9a8c\u8bc1\u673a\u5236\u786e\u4fdd\u4e86\u89c4\u5219\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2510.13423", "categories": ["cs.SE", "cs.MS"], "pdf": "https://arxiv.org/pdf/2510.13423", "abs": "https://arxiv.org/abs/2510.13423", "authors": ["Matthew Sottile", "Mohit Tekriwal", "John Sarracino"], "title": "Towards Richer Challenge Problems for Scientific Computing Correctness", "comment": "In Proceedings VSS 2025, arXiv:2510.12314", "summary": "Correctness in scientific computing (SC) is gaining increasing attention in\nthe formal methods (FM) and programming languages (PL) community. Existing\nPL/FM verification techniques struggle with the complexities of realistic SC\napplications. Part of the problem is a lack of a common understanding between\nthe SC and PL/FM communities of machine-verifiable correctness challenges and\ndimensions of correctness in SC applications.\n  To address this gap, we call for specialized challenge problems to inform the\ndevelopment and evaluation of FM/PL verification techniques for correctness in\nSC. These specialized challenges are intended to augment existing problems\nstudied by FM/PL researchers for general programs to ensure the needs of SC\napplications can be met. We propose several dimensions of correctness relevant\nto scientific computing, and discuss some guidelines and criteria for designing\nchallenge problems to evaluate correctness in scientific computing.", "AI": {"tldr": "\u672c\u6587\u547c\u5401\u4e3a\u79d1\u5b66\u8ba1\u7b97(SC)\u9886\u57df\u5f00\u53d1\u4e13\u95e8\u7684\u6311\u6218\u6027\u95ee\u9898\uff0c\u4ee5\u6307\u5bfc\u5f62\u5f0f\u5316\u65b9\u6cd5(FM)\u548c\u7f16\u7a0b\u8bed\u8a00(PL)\u9a8c\u8bc1\u6280\u672f\u7684\u53d1\u5c55\uff0c\u89e3\u51b3\u73b0\u6709\u9a8c\u8bc1\u6280\u672f\u5728\u5e94\u5bf9\u73b0\u5b9eSC\u5e94\u7528\u590d\u6742\u6027\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u79d1\u5b66\u8ba1\u7b97\u4e2d\u7684\u6b63\u786e\u6027\u95ee\u9898\u65e5\u76ca\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u73b0\u6709\u7684PL/FM\u9a8c\u8bc1\u6280\u672f\u96be\u4ee5\u5e94\u5bf9\u73b0\u5b9eSC\u5e94\u7528\u7684\u590d\u6742\u6027\uff0c\u90e8\u5206\u539f\u56e0\u662fSC\u548cPL/FM\u793e\u533a\u4e4b\u95f4\u7f3a\u4e4f\u5bf9\u673a\u5668\u53ef\u9a8c\u8bc1\u6b63\u786e\u6027\u6311\u6218\u548cSC\u5e94\u7528\u6b63\u786e\u6027\u7ef4\u5ea6\u7684\u5171\u540c\u7406\u89e3\u3002", "method": "\u63d0\u51fa\u4e3a\u79d1\u5b66\u8ba1\u7b97\u5f00\u53d1\u4e13\u95e8\u7684\u6311\u6218\u6027\u95ee\u9898\uff0c\u8fd9\u4e9b\u6311\u6218\u65e8\u5728\u8865\u5145FM/PL\u7814\u7a76\u4eba\u5458\u4e3a\u901a\u7528\u7a0b\u5e8f\u7814\u7a76\u7684\u95ee\u9898\uff0c\u786e\u4fdd\u6ee1\u8db3SC\u5e94\u7528\u7684\u9700\u6c42\u3002\u63d0\u51fa\u4e86\u4e0e\u79d1\u5b66\u8ba1\u7b97\u76f8\u5173\u7684\u51e0\u4e2a\u6b63\u786e\u6027\u7ef4\u5ea6\uff0c\u5e76\u8ba8\u8bba\u4e86\u8bbe\u8ba1\u8bc4\u4f30\u79d1\u5b66\u8ba1\u7b97\u6b63\u786e\u6027\u7684\u6311\u6218\u95ee\u9898\u7684\u6307\u5bfc\u539f\u5219\u548c\u6807\u51c6\u3002", "result": "\u63d0\u51fa\u4e86\u5f00\u53d1\u4e13\u95e8\u6311\u6218\u95ee\u9898\u7684\u547c\u5401\uff0c\u5e76\u5b9a\u4e49\u4e86\u79d1\u5b66\u8ba1\u7b97\u76f8\u5173\u7684\u6b63\u786e\u6027\u7ef4\u5ea6\u548c\u6311\u6218\u95ee\u9898\u8bbe\u8ba1\u6307\u5357\u3002", "conclusion": "\u901a\u8fc7\u5f00\u53d1\u4e13\u95e8\u7684\u6311\u6218\u95ee\u9898\uff0c\u53ef\u4ee5\u66f4\u597d\u5730\u6307\u5bfcFM/PL\u9a8c\u8bc1\u6280\u672f\u7684\u53d1\u5c55\uff0c\u5f25\u5408SC\u548cPL/FM\u793e\u533a\u4e4b\u95f4\u7684\u7406\u89e3\u5dee\u8ddd\uff0c\u63d0\u9ad8\u79d1\u5b66\u8ba1\u7b97\u5e94\u7528\u7684\u6b63\u786e\u6027\u9a8c\u8bc1\u80fd\u529b\u3002"}}
{"id": "2510.13214", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13214", "abs": "https://arxiv.org/abs/2510.13214", "authors": ["Zehui Ling", "Deshu Chen", "Yichi Zhang", "Yuchen Liu", "Xigui Li", "Xin Guo", "Yuan Cheng"], "title": "Adaptive Reasoning Executor: A Collaborative Agent System for Efficient Reasoning", "comment": null, "summary": "Recent advances in Large Language Models (LLMs) demonstrate that\nchain-of-thought prompting and deep reasoning substantially enhance performance\non complex tasks, and multi-agent systems can further improve accuracy by\nenabling model debates. However, applying deep reasoning to all problems is\ncomputationally expensive. To mitigate these costs, we propose a complementary\nagent system integrating small and large LLMs. The small LLM first generates an\ninitial answer, which is then verified by the large LLM. If correct, the answer\nis adopted directly; otherwise, the large LLM performs in-depth reasoning.\nExperimental results show that, for simple problems, our approach reduces the\ncomputational cost of the large LLM by more than 50% with negligible accuracy\nloss, while consistently maintaining robust performance on complex tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5c0f\u578b\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4e92\u8865\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u5c0f\u578bLLM\u9996\u5148\u751f\u6210\u521d\u6b65\u7b54\u6848\uff0c\u5927\u578bLLM\u8fdb\u884c\u9a8c\u8bc1\uff0c\u4ec5\u5728\u5fc5\u8981\u65f6\u8fdb\u884c\u6df1\u5ea6\u63a8\u7406\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u867d\u7136\u94fe\u5f0f\u601d\u7ef4\u63d0\u793a\u548c\u6df1\u5ea6\u63a8\u7406\u80fd\u63d0\u5347\u590d\u6742\u4efb\u52a1\u6027\u80fd\uff0c\u4f46\u5bf9\u6240\u6709\u95ee\u9898\u90fd\u5e94\u7528\u6df1\u5ea6\u63a8\u7406\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u4e92\u8865\u4ee3\u7406\u7cfb\u7edf\uff1a\u5c0f\u578bLLM\u751f\u6210\u521d\u59cb\u7b54\u6848\uff0c\u5927\u578bLLM\u9a8c\u8bc1\u6b63\u786e\u6027\uff0c\u4ec5\u5728\u7b54\u6848\u9519\u8bef\u65f6\u8fdb\u884c\u6df1\u5ea6\u63a8\u7406\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u5bf9\u4e8e\u7b80\u5355\u95ee\u9898\uff0c\u5927\u578bLLM\u7684\u8ba1\u7b97\u6210\u672c\u964d\u4f4e\u8d85\u8fc750%\uff0c\u51c6\u786e\u7387\u635f\u5931\u53ef\u5ffd\u7565\uff0c\u540c\u65f6\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u4fdd\u6301\u7a33\u5065\u6027\u80fd\u3002", "conclusion": "\u8be5\u4e92\u8865\u4ee3\u7406\u7cfb\u7edf\u80fd\u6709\u6548\u5e73\u8861\u8ba1\u7b97\u6548\u7387\u548c\u4efb\u52a1\u6027\u80fd\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.13318", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.13318", "abs": "https://arxiv.org/abs/2510.13318", "authors": ["Jucai Yang", "Liang Li", "Yiwei Gu", "Haiqin Wu"], "title": "Fast Authenticated and Interoperable Multimedia Healthcare Data over Hybrid-Storage Blockchains", "comment": null, "summary": "The integration of blockchain technology into healthcare presents a paradigm\nshift for secure data management, enabling decentralized and tamper-proof\nstorage and sharing of sensitive Electronic Health Records (EHRs). However,\nexisting blockchain-based healthcare systems, while providing robust access\ncontrol, commonly overlook the high latency in user-side re-computation of\nhashes for integrity verification of large multimedia data, impairing their\npracticality, especially in time-sensitive clinical scenarios. In this paper,\nwe propose FAITH, an innovative scheme for \\underline{F}ast\n\\underline{A}uthenticated and \\underline{I}nteroperable mul\\underline{T}imedia\n\\underline{H}ealthcare data storage and sharing over hybrid-storage\nblockchains. Rather than user-side hash re-computations, FAITH lets an\noff-chain storage provider generate verifiable proofs using recursive\nZero-Knowledge Proofs (ZKPs), while the user only needs to perform lightweight\nverification. For flexible access authorization, we leverage Proxy\nRe-Encryption (PRE) and enable the provider to conduct ciphertext\nre-encryption, in which the re-encryption correctness can be verified via ZKPs\nagainst the malicious provider. All metadata and proofs are recorded on-chain\nfor public verification. We provide a comprehensive analysis of FAITH's\nsecurity regarding data privacy and integrity. We implemented a prototype of\nFAITH, and extensive experiments demonstrated its practicality for\ntime-critical healthcare applications, dramatically reducing user-side\nverification latency by up to $98\\%$, bringing it from $4$ s down to around\n$70$ ms for a $5$ GB encrypted file.", "AI": {"tldr": "FAITH\u662f\u4e00\u4e2a\u57fa\u4e8e\u6df7\u5408\u5b58\u50a8\u533a\u5757\u94fe\u7684\u5feb\u901f\u8ba4\u8bc1\u548c\u4e92\u64cd\u4f5c\u591a\u5a92\u4f53\u533b\u7597\u6570\u636e\u5b58\u50a8\u5171\u4eab\u65b9\u6848\uff0c\u901a\u8fc7\u96f6\u77e5\u8bc6\u8bc1\u660e\u548c\u4ee3\u7406\u91cd\u52a0\u5bc6\u6280\u672f\uff0c\u5927\u5e45\u964d\u4f4e\u7528\u6237\u7aef\u9a8c\u8bc1\u5ef6\u8fdf", "motivation": "\u73b0\u6709\u533a\u5757\u94fe\u533b\u7597\u7cfb\u7edf\u5728\u591a\u5a92\u4f53\u6570\u636e\u5b8c\u6574\u6027\u9a8c\u8bc1\u65f6\u5b58\u5728\u9ad8\u5ef6\u8fdf\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u65f6\u95f4\u654f\u611f\u7684\u4e34\u5e8a\u573a\u666f\u4e2d\u5b9e\u7528\u6027\u4e0d\u8db3", "method": "\u4f7f\u7528\u9012\u5f52\u96f6\u77e5\u8bc6\u8bc1\u660e\u8ba9\u79bb\u7ebf\u5b58\u50a8\u63d0\u4f9b\u5546\u751f\u6210\u53ef\u9a8c\u8bc1\u8bc1\u660e\uff0c\u7528\u6237\u53ea\u9700\u8f7b\u91cf\u7ea7\u9a8c\u8bc1\uff1b\u91c7\u7528\u4ee3\u7406\u91cd\u52a0\u5bc6\u5b9e\u73b0\u7075\u6d3b\u8bbf\u95ee\u6388\u6743\uff0c\u5e76\u901a\u8fc7ZKPs\u9a8c\u8bc1\u91cd\u52a0\u5bc6\u6b63\u786e\u6027", "result": "\u7528\u6237\u7aef\u9a8c\u8bc1\u5ef6\u8fdf\u964d\u4f4e98%\uff0c\u4ece4\u79d2\u964d\u81f3\u7ea670\u6beb\u79d2\uff08\u9488\u5bf95GB\u52a0\u5bc6\u6587\u4ef6\uff09\uff0c\u9002\u7528\u4e8e\u65f6\u95f4\u5173\u952e\u578b\u533b\u7597\u5e94\u7528", "conclusion": "FAITH\u65b9\u6848\u6709\u6548\u89e3\u51b3\u4e86\u533a\u5757\u94fe\u533b\u7597\u7cfb\u7edf\u4e2d\u591a\u5a92\u4f53\u6570\u636e\u9a8c\u8bc1\u7684\u9ad8\u5ef6\u8fdf\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u7684\u5b9e\u7528\u6027"}}
{"id": "2510.13424", "categories": ["cs.SE", "D.2.5; G.1.3"], "pdf": "https://arxiv.org/pdf/2510.13424", "abs": "https://arxiv.org/abs/2510.13424", "authors": ["Alexander C. Wilton"], "title": "Verifying a Sparse Matrix Algorithm Using Symbolic Execution", "comment": "In Proceedings VSS 2025, arXiv:2510.12314", "summary": "Scientific software is, by its very nature, complex. It is mathematical and\nhighly optimized which makes it prone to subtle bugs not as easily detected by\ntraditional testing. We outline how symbolic execution can be used to write\ntests similar to traditional unit tests while providing stronger verification\nguarantees and apply this methodology to a sparse matrix algorithm.", "AI": {"tldr": "\u4f7f\u7528\u7b26\u53f7\u6267\u884c\u6765\u6d4b\u8bd5\u79d1\u5b66\u8f6f\u4ef6\uff0c\u7279\u522b\u662f\u7a00\u758f\u77e9\u9635\u7b97\u6cd5\uff0c\u63d0\u4f9b\u6bd4\u4f20\u7edf\u6d4b\u8bd5\u66f4\u5f3a\u7684\u9a8c\u8bc1\u4fdd\u8bc1", "motivation": "\u79d1\u5b66\u8f6f\u4ef6\u5177\u6709\u590d\u6742\u6027\u3001\u6570\u5b66\u6027\u548c\u9ad8\u5ea6\u4f18\u5316\u7684\u7279\u70b9\uff0c\u5bb9\u6613\u4ea7\u751f\u4f20\u7edf\u6d4b\u8bd5\u96be\u4ee5\u53d1\u73b0\u7684\u5fae\u5999bug", "method": "\u91c7\u7528\u7b26\u53f7\u6267\u884c\u65b9\u6cd5\u7f16\u5199\u7c7b\u4f3c\u4f20\u7edf\u5355\u5143\u6d4b\u8bd5\u7684\u6d4b\u8bd5\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u7a00\u758f\u77e9\u9635\u7b97\u6cd5", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u63d0\u4f9b\u6bd4\u4f20\u7edf\u6d4b\u8bd5\u66f4\u5f3a\u7684\u9a8c\u8bc1\u4fdd\u8bc1", "conclusion": "\u7b26\u53f7\u6267\u884c\u662f\u6d4b\u8bd5\u79d1\u5b66\u8f6f\u4ef6\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u7279\u522b\u9002\u7528\u4e8e\u68c0\u6d4b\u4f20\u7edf\u6d4b\u8bd5\u96be\u4ee5\u53d1\u73b0\u7684\u5fae\u5999bug"}}
{"id": "2510.13215", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.13215", "abs": "https://arxiv.org/abs/2510.13215", "authors": ["Joy Jia Yin Lim", "Ye He", "Jifan Yu", "Xin Cong", "Daniel Zhang-Li", "Zhiyuan Liu", "Huiqin Liu", "Lei Hou", "Juanzi Li", "Bin Xu"], "title": "Personalized Learning Path Planning with Goal-Driven Learner State Modeling", "comment": null, "summary": "Personalized Learning Path Planning (PLPP) aims to design adaptive learning\npaths that align with individual goals. While large language models (LLMs) show\npotential in personalizing learning experiences, existing approaches often lack\nmechanisms for goal-aligned planning. We introduce Pxplore, a novel framework\nfor PLPP that integrates a reinforcement-based training paradigm and an\nLLM-driven educational architecture. We design a structured learner state model\nand an automated reward function that transforms abstract objectives into\ncomputable signals. We train the policy combining supervised fine-tuning (SFT)\nand Group Relative Policy Optimization (GRPO), and deploy it within a\nreal-world learning platform. Extensive experiments validate Pxplore's\neffectiveness in producing coherent, personalized, and goal-driven learning\npaths. We release our code and dataset to facilitate future research.", "AI": {"tldr": "Pxplore\u662f\u4e00\u4e2a\u4e2a\u6027\u5316\u5b66\u4e60\u8def\u5f84\u89c4\u5212\u6846\u67b6\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548cLLM\u6559\u80b2\u67b6\u6784\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u5b66\u4e60\u8005\u72b6\u6001\u6a21\u578b\u548c\u81ea\u52a8\u5956\u52b1\u51fd\u6570\uff0c\u5b9e\u73b0\u76ee\u6807\u5bf9\u9f50\u7684\u5b66\u4e60\u8def\u5f84\u751f\u6210\u3002", "motivation": "\u73b0\u6709LLM\u65b9\u6cd5\u7f3a\u4e4f\u76ee\u6807\u5bf9\u9f50\u89c4\u5212\u673a\u5236\uff0c\u65e0\u6cd5\u6709\u6548\u8bbe\u8ba1\u7b26\u5408\u4e2a\u4eba\u76ee\u6807\u7684\u9002\u5e94\u6027\u5b66\u4e60\u8def\u5f84\u3002", "method": "\u63d0\u51faPxplore\u6846\u67b6\uff0c\u96c6\u6210\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u8303\u5f0f\uff0c\u8bbe\u8ba1\u7ed3\u6784\u5316\u5b66\u4e60\u8005\u72b6\u6001\u6a21\u578b\u548c\u81ea\u52a8\u5956\u52b1\u51fd\u6570\uff0c\u7ed3\u5408\u76d1\u7763\u5fae\u8c03\u548cGRPO\u7b56\u7565\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1Pxplore\u80fd\u751f\u6210\u8fde\u8d2f\u3001\u4e2a\u6027\u5316\u4e14\u76ee\u6807\u9a71\u52a8\u7684\u5b66\u4e60\u8def\u5f84\uff0c\u5e76\u5728\u771f\u5b9e\u5b66\u4e60\u5e73\u53f0\u4e2d\u90e8\u7f72\u3002", "conclusion": "Pxplore\u6846\u67b6\u5728\u4e2a\u6027\u5316\u5b66\u4e60\u8def\u5f84\u89c4\u5212\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u4ee3\u7801\u548c\u6570\u636e\u96c6\u3002"}}
{"id": "2510.13322", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13322", "abs": "https://arxiv.org/abs/2510.13322", "authors": ["Baogang Song", "Dongdong Zhao", "Jianwen Xiang", "Qiben Xu", "Zizhuo Yu"], "title": "Injection, Attack and Erasure: Revocable Backdoor Attacks via Machine Unlearning", "comment": null, "summary": "Backdoor attacks pose a persistent security risk to deep neural networks\n(DNNs) due to their stealth and durability. While recent research has explored\nleveraging model unlearning mechanisms to enhance backdoor concealment,\nexisting attack strategies still leave persistent traces that may be detected\nthrough static analysis. In this work, we introduce the first paradigm of\nrevocable backdoor attacks, where the backdoor can be proactively and\nthoroughly removed after the attack objective is achieved. We formulate the\ntrigger optimization in revocable backdoor attacks as a bilevel optimization\nproblem: by simulating both backdoor injection and unlearning processes, the\ntrigger generator is optimized to achieve a high attack success rate (ASR)\nwhile ensuring that the backdoor can be easily erased through unlearning. To\nmitigate the optimization conflict between injection and removal objectives, we\nemploy a deterministic partition of poisoning and unlearning samples to reduce\nsampling-induced variance, and further apply the Projected Conflicting Gradient\n(PCGrad) technique to resolve the remaining gradient conflicts. Experiments on\nCIFAR-10 and ImageNet demonstrate that our method maintains ASR comparable to\nstate-of-the-art backdoor attacks, while enabling effective removal of backdoor\nbehavior after unlearning. This work opens a new direction for backdoor attack\nresearch and presents new challenges for the security of machine learning\nsystems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u53ef\u64a4\u9500\u540e\u95e8\u653b\u51fb\u8303\u5f0f\uff0c\u901a\u8fc7\u53cc\u5c42\u4f18\u5316\u8bbe\u8ba1\u89e6\u53d1\u5668\uff0c\u5728\u4fdd\u6301\u9ad8\u653b\u51fb\u6210\u529f\u7387\u7684\u540c\u65f6\u786e\u4fdd\u540e\u95e8\u80fd\u591f\u901a\u8fc7\u53cd\u5b66\u4e60\u673a\u5236\u88ab\u5f7b\u5e95\u79fb\u9664\u3002", "motivation": "\u73b0\u6709\u540e\u95e8\u653b\u51fb\u7b56\u7565\u5728\u9690\u853d\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u4f1a\u7559\u4e0b\u53ef\u88ab\u9759\u6001\u5206\u6790\u68c0\u6d4b\u7684\u6301\u4e45\u75d5\u8ff9\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5728\u653b\u51fb\u76ee\u6807\u8fbe\u6210\u540e\u4e3b\u52a8\u5f7b\u5e95\u79fb\u9664\u540e\u95e8\u7684\u653b\u51fb\u65b9\u6cd5\u3002", "method": "\u5c06\u53ef\u64a4\u9500\u540e\u95e8\u653b\u51fb\u7684\u89e6\u53d1\u5668\u4f18\u5316\u5efa\u6a21\u4e3a\u53cc\u5c42\u4f18\u5316\u95ee\u9898\uff1a\u901a\u8fc7\u6a21\u62df\u540e\u95e8\u6ce8\u5165\u548c\u53cd\u5b66\u4e60\u8fc7\u7a0b\uff0c\u4f18\u5316\u89e6\u53d1\u5668\u751f\u6210\u5668\u4ee5\u5b9e\u73b0\u9ad8\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u786e\u4fdd\u540e\u95e8\u6613\u4e8e\u901a\u8fc7\u53cd\u5b66\u4e60\u64e6\u9664\u3002\u91c7\u7528\u786e\u5b9a\u6027\u5212\u5206\u4e2d\u6bd2\u6837\u672c\u548c\u53cd\u5b66\u4e60\u6837\u672c\u6765\u51cf\u5c11\u91c7\u6837\u65b9\u5dee\uff0c\u5e76\u5e94\u7528\u6295\u5f71\u51b2\u7a81\u68af\u5ea6\u6280\u672f\u89e3\u51b3\u68af\u5ea6\u51b2\u7a81\u3002", "result": "\u5728CIFAR-10\u548cImageNet\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4fdd\u6301\u4e86\u4e0e\u6700\u5148\u8fdb\u540e\u95e8\u653b\u51fb\u76f8\u5f53\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u80fd\u591f\u5728\u53cd\u5b66\u4e60\u540e\u6709\u6548\u79fb\u9664\u540e\u95e8\u884c\u4e3a\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u540e\u95e8\u653b\u51fb\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\uff0c\u5e76\u4e3a\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u5e26\u6765\u4e86\u65b0\u7684\u6311\u6218\u3002"}}
{"id": "2510.13561", "categories": ["cs.SE", "cs.AI", "68N30"], "pdf": "https://arxiv.org/pdf/2510.13561", "abs": "https://arxiv.org/abs/2510.13561", "authors": ["Peng Di", "Faqiang Chen", "Xiao Bai", "Hongjun Yang", "Qingfeng Li", "Ganglin Wei", "Jian Mou", "Feng Shi", "Keting Chen", "Peng Tang", "Zhitao Shen", "Zheng Li", "Wenhui Shi", "Junwei Guo", "Hang Yu"], "title": "OpenDerisk: An Industrial Framework for AI-Driven SRE, with Design, Implementation, and Case Studies", "comment": "23 pages", "summary": "The escalating complexity of modern software imposes an unsustainable\noperational burden on Site Reliability Engineering (SRE) teams, demanding\nAI-driven automation that can emulate expert diagnostic reasoning. Existing\nsolutions, from traditional AI methods to general-purpose multi-agent systems,\nfall short: they either lack deep causal reasoning or are not tailored for the\nspecialized, investigative workflows unique to SRE. To address this gap, we\npresent OpenDerisk, a specialized, open-source multi-agent framework\narchitected for SRE. OpenDerisk integrates a diagnostic-native collaboration\nmodel, a pluggable reasoning engine, a knowledge engine, and a standardized\nprotocol (MCP) to enable specialist agents to collectively solve complex,\nmulti-domain problems. Our comprehensive evaluation demonstrates that\nOpenDerisk significantly outperforms state-of-the-art baselines in both\naccuracy and efficiency. This effectiveness is validated by its large-scale\nproduction deployment at Ant Group, where it serves over 3,000 daily users\nacross diverse scenarios, confirming its industrial-grade scalability and\npractical impact. OpenDerisk is open source and available at\nhttps://github.com/derisk-ai/OpenDerisk/", "AI": {"tldr": "OpenDerisk\u662f\u4e00\u4e2a\u4e13\u95e8\u4e3aSRE\u8bbe\u8ba1\u7684\u5f00\u6e90\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u8bca\u65ad\u539f\u751f\u534f\u4f5c\u6a21\u578b\u3001\u53ef\u63d2\u62d4\u63a8\u7406\u5f15\u64ce\u548c\u77e5\u8bc6\u5f15\u64ce\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u8f6f\u4ef6\u95ee\u9898\u7684\u8bca\u65ad\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u4ee3\u8f6f\u4ef6\u590d\u6742\u6027\u4e0d\u65ad\u589e\u52a0\uff0c\u7ed9SRE\u56e2\u961f\u5e26\u6765\u4e0d\u53ef\u6301\u7eed\u7684\u64cd\u4f5c\u8d1f\u62c5\uff0c\u73b0\u6709AI\u89e3\u51b3\u65b9\u6848\u8981\u4e48\u7f3a\u4e4f\u6df1\u5ea6\u56e0\u679c\u63a8\u7406\u80fd\u529b\uff0c\u8981\u4e48\u4e0d\u9002\u7528\u4e8eSRE\u7279\u6709\u7684\u4e13\u4e1a\u8c03\u67e5\u5de5\u4f5c\u6d41\u7a0b\u3002", "method": "\u5f00\u53d1\u4e86OpenDerisk\u6846\u67b6\uff0c\u96c6\u6210\u4e86\u8bca\u65ad\u539f\u751f\u534f\u4f5c\u6a21\u578b\u3001\u53ef\u63d2\u62d4\u63a8\u7406\u5f15\u64ce\u3001\u77e5\u8bc6\u5f15\u64ce\u548c\u6807\u51c6\u5316\u534f\u8bae(MCP)\uff0c\u4f7f\u4e13\u4e1a\u667a\u80fd\u4f53\u80fd\u591f\u534f\u4f5c\u89e3\u51b3\u590d\u6742\u7684\u591a\u9886\u57df\u95ee\u9898\u3002", "result": "\u7efc\u5408\u8bc4\u4f30\u663e\u793aOpenDerisk\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5df2\u5728\u8682\u8681\u96c6\u56e2\u5927\u89c4\u6a21\u751f\u4ea7\u90e8\u7f72\uff0c\u670d\u52a1\u8d85\u8fc73000\u540d\u65e5\u5e38\u7528\u6237\uff0c\u9a8c\u8bc1\u4e86\u5176\u5de5\u4e1a\u7ea7\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u9645\u5f71\u54cd\u3002", "conclusion": "OpenDerisk\u6210\u529f\u89e3\u51b3\u4e86SRE\u9886\u57dfAI\u81ea\u52a8\u5316\u7684\u5173\u952e\u6311\u6218\uff0c\u63d0\u4f9b\u4e86\u4e13\u95e8\u5316\u7684\u591a\u667a\u80fd\u4f53\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u91cd\u8981\u7684\u5de5\u4e1a\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.13220", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.13220", "abs": "https://arxiv.org/abs/2510.13220", "authors": ["Yufei He", "Juncheng Liu", "Yue Liu", "Yibo Li", "Tri Cao", "Zhiyuan Hu", "Xinxing Xu", "Bryan Hooi"], "title": "EvoTest: Evolutionary Test-Time Learning for Self-Improving Agentic Systems", "comment": null, "summary": "A fundamental limitation of current AI agents is their inability to learn\ncomplex skills on the fly at test time, often behaving like \"clever but\nclueless interns\" in novel environments. This severely limits their practical\nutility. To systematically measure and drive progress on this challenge, we\nfirst introduce the Jericho Test-Time Learning (J-TTL) benchmark. J-TTL is a\nnew evaluation setup where an agent must play the same game for several\nconsecutive episodes, attempting to improve its performance from one episode to\nthe next. On J-TTL, we find that existing adaptation methods like reflection,\nmemory, or reinforcement learning struggle. To address the challenges posed by\nour benchmark, we present EvoTest, an evolutionary test-time learning framework\nthat improves an agent without any fine-tuning or gradients-by evolving the\nentire agentic system after every episode. EvoTest has two roles: the Actor\nAgent, which plays the game, and the Evolver Agent, which analyzes the episode\ntranscript to propose a revised configuration for the next run. This\nconfiguration rewrites the prompt, updates memory by logging effective\nstate-action choices, tunes hyperparameters, and learns the tool-use routines.\nOn our J-TTL benchmark, EvoTest consistently increases performance,\noutperforming not only reflection and memory-only baselines but also more\ncomplex online fine-tuning methods. Notably, our method is the only one capable\nof winning two games (Detective and Library), while all baselines fail to win\nany.", "AI": {"tldr": "\u63d0\u51fa\u4e86Jericho\u6d4b\u8bd5\u65f6\u5b66\u4e60\u57fa\u51c6(J-TTL)\u6765\u8861\u91cfAI\u4ee3\u7406\u5728\u6d4b\u8bd5\u65f6\u5b66\u4e60\u590d\u6742\u6280\u80fd\u7684\u80fd\u529b\uff0c\u5e76\u5f00\u53d1\u4e86EvoTest\u8fdb\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u6f14\u5316\u4ee3\u7406\u7cfb\u7edf\u914d\u7f6e\u6765\u63d0\u5347\u6027\u80fd\uff0c\u65e0\u9700\u5fae\u8c03\u6216\u68af\u5ea6\u3002", "motivation": "\u5f53\u524dAI\u4ee3\u7406\u65e0\u6cd5\u5728\u6d4b\u8bd5\u65f6\u5b66\u4e60\u590d\u6742\u6280\u80fd\uff0c\u5728\u964c\u751f\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u8fd9\u4e25\u91cd\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "method": "\u63d0\u51faEvoTest\u8fdb\u5316\u6d4b\u8bd5\u65f6\u5b66\u4e60\u6846\u67b6\uff0c\u5305\u542b\u6267\u884c\u6e38\u620f\u7684Actor\u4ee3\u7406\u548c\u5206\u6790\u6e38\u620f\u8bb0\u5f55\u4ee5\u6539\u8fdb\u914d\u7f6e\u7684Evolver\u4ee3\u7406\uff0c\u901a\u8fc7\u91cd\u5199\u63d0\u793a\u3001\u66f4\u65b0\u8bb0\u5fc6\u3001\u8c03\u6574\u8d85\u53c2\u6570\u548c\u5b66\u4e60\u5de5\u5177\u4f7f\u7528\u4f8b\u7a0b\u6765\u4f18\u5316\u7cfb\u7edf\u3002", "result": "\u5728J-TTL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cEvoTest\u6301\u7eed\u63d0\u5347\u6027\u80fd\uff0c\u4f18\u4e8e\u53cd\u601d\u3001\u4ec5\u8bb0\u5fc6\u548c\u5728\u7ebf\u5fae\u8c03\u7b49\u65b9\u6cd5\uff0c\u662f\u552f\u4e00\u80fd\u8d62\u5f97\u4e24\u4e2a\u6e38\u620f\u7684\u65b9\u6cd5\u3002", "conclusion": "EvoTest\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86AI\u4ee3\u7406\u5728\u6d4b\u8bd5\u65f6\u5b66\u4e60\u590d\u6742\u6280\u80fd\u7684\u6311\u6218\uff0c\u4e3a\u5f00\u53d1\u66f4\u5b9e\u7528\u7684AI\u4ee3\u7406\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2510.13370", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.13370", "abs": "https://arxiv.org/abs/2510.13370", "authors": ["Fernando Castillo", "Eduardo Brito", "Sebastian Werner", "Pille Pullonen-Raudvere", "Jonathan Heiss"], "title": "Towards Trusted Service Monitoring: Verifiable Service Level Agreements", "comment": "To be published in 3rd International Conference on Service-Oriented\n  Computing (ICSOC 2025). 15 pages. 4 figures", "summary": "Service Level Agreement (SLA) monitoring in service-oriented environments\nsuffers from inherent trust conflicts when providers self-report metrics,\ncreating incentives to underreport violations. We introduce a framework for\ngenerating verifiable SLA violation claims through trusted hardware monitors\nand zero-knowledge proofs, establishing cryptographic foundations for genuine\ntrustworthiness in service ecosystems. Our approach starts with\nmachine-readable SLA clauses converted into verifiable predicates and monitored\nwithin Trusted Execution Environments. These monitors collect timestamped\ntelemetry, organize measurements into Merkle trees, and produce signed\nattestations. Zero-knowledge proofs aggregate Service-Level Indicators to\nevaluate compliance, generating cryptographic proofs verifiable by\nstakeholders, arbitrators, or insurers in disputes, without accessing\nunderlying data. This ensures three security properties: integrity,\nauthenticity, and validity. Our prototype demonstrates linear scaling up to\nover 1 million events per hour for measurements with near constant-time proof\ngeneration and verification for single violation claims, enabling trustless SLA\nenforcement through cryptographic guarantees for automated compliance\nverification in service monitoring.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u53ef\u4fe1\u786c\u4ef6\u548c\u96f6\u77e5\u8bc6\u8bc1\u660e\u7684SLA\u76d1\u63a7\u6846\u67b6\uff0c\u901a\u8fc7\u5bc6\u7801\u5b66\u65b9\u6cd5\u89e3\u51b3\u670d\u52a1\u63d0\u4f9b\u5546\u81ea\u62a5\u544a\u6307\u6807\u65f6\u7684\u4fe1\u4efb\u51b2\u7a81\u95ee\u9898\u3002", "motivation": "\u670d\u52a1\u5bfc\u5411\u73af\u5883\u4e2dSLA\u76d1\u63a7\u5b58\u5728\u56fa\u6709\u4fe1\u4efb\u51b2\u7a81\uff0c\u63d0\u4f9b\u5546\u81ea\u62a5\u544a\u6307\u6807\u4f1a\u6fc0\u52b1\u5176\u5c11\u62a5\u8fdd\u89c4\u884c\u4e3a\uff0c\u9700\u8981\u5efa\u7acb\u771f\u6b63\u7684\u53ef\u4fe1\u76d1\u63a7\u673a\u5236\u3002", "method": "\u5c06\u673a\u5668\u53ef\u8bfb\u7684SLA\u6761\u6b3e\u8f6c\u6362\u4e3a\u53ef\u9a8c\u8bc1\u8c13\u8bcd\uff0c\u5728\u53ef\u4fe1\u6267\u884c\u73af\u5883\u4e2d\u76d1\u63a7\uff1b\u6536\u96c6\u5e26\u65f6\u95f4\u6233\u7684\u9065\u6d4b\u6570\u636e\uff0c\u7ec4\u7ec7\u6210Merkle\u6811\u5e76\u751f\u6210\u7b7e\u540d\u8bc1\u660e\uff1b\u4f7f\u7528\u96f6\u77e5\u8bc6\u8bc1\u660e\u805a\u5408\u670d\u52a1\u7ea7\u522b\u6307\u6807\u6765\u8bc4\u4f30\u5408\u89c4\u6027\u3002", "result": "\u539f\u578b\u7cfb\u7edf\u5c55\u793a\u4e86\u7ebf\u6027\u6269\u5c55\u80fd\u529b\uff0c\u6bcf\u5c0f\u65f6\u53ef\u5904\u7406\u8d85\u8fc7100\u4e07\u4e2a\u4e8b\u4ef6\uff0c\u5355\u4e2a\u8fdd\u89c4\u58f0\u660e\u7684\u8bc1\u660e\u751f\u6210\u548c\u9a8c\u8bc1\u65f6\u95f4\u63a5\u8fd1\u5e38\u6570\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u5bc6\u7801\u5b66\u4fdd\u8bc1\u5b9e\u73b0\u4e86\u65e0\u9700\u4fe1\u4efb\u7684SLA\u6267\u884c\uff0c\u4e3a\u670d\u52a1\u76d1\u63a7\u4e2d\u7684\u81ea\u52a8\u5408\u89c4\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u5b8c\u6574\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.13575", "categories": ["cs.SE", "D.2.5"], "pdf": "https://arxiv.org/pdf/2510.13575", "abs": "https://arxiv.org/abs/2510.13575", "authors": ["Han Fu", "Sigrid Eldh", "Kristian Wiklund", "Andreas Ermedahl", "Philipp Haller", "Cyrille Artho"], "title": "Auto-repair without test cases: How LLMs fix compilation errors in large industrial embedded code", "comment": "9 pages, 4 figures, conference: 2025 28th Euromicro Conference on\n  Digital System Design (DSD)", "summary": "The co-development of hardware and software in industrial embedded systems\nfrequently leads to compilation errors during continuous integration (CI).\nAutomated repair of such failures is promising, but existing techniques rely on\ntest cases, which are not available for non-compilable code.\n  We employ an automated repair approach for compilation errors driven by large\nlanguage models (LLMs). Our study encompasses the collection of more than 40000\ncommits from the product's source code. We assess the performance of an\nindustrial CI system enhanced by four state-of-the-art LLMs, comparing their\noutcomes with manual corrections provided by human programmers. LLM-equipped CI\nsystems can resolve up to 63 % of the compilation errors in our baseline\ndataset. Among the fixes associated with successful CI builds, 83 % are deemed\nreasonable. Moreover, LLMs significantly reduce debugging time, with the\nmajority of successful cases completed within 8 minutes, compared to hours\ntypically required for manual debugging.", "AI": {"tldr": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u4fee\u590d\u5de5\u4e1a\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4e2d\u7f16\u8bd1\u9519\u8bef\uff0c\u5728CI\u7cfb\u7edf\u4e2d\u53ef\u89e3\u51b363%\u7684\u7f16\u8bd1\u9519\u8bef\uff0c83%\u7684\u4fee\u590d\u65b9\u6848\u5408\u7406\uff0c\u663e\u8457\u51cf\u5c11\u8c03\u8bd5\u65f6\u95f4", "motivation": "\u5de5\u4e1a\u5d4c\u5165\u5f0f\u7cfb\u7edf\u7684\u8f6f\u786c\u4ef6\u534f\u540c\u5f00\u53d1\u5728\u6301\u7eed\u96c6\u6210\u4e2d\u7ecf\u5e38\u51fa\u73b0\u7f16\u8bd1\u9519\u8bef\uff0c\u73b0\u6709\u4fee\u590d\u6280\u672f\u4f9d\u8d56\u6d4b\u8bd5\u7528\u4f8b\uff0c\u4f46\u4e0d\u53ef\u7f16\u8bd1\u4ee3\u7801\u6ca1\u6709\u6d4b\u8bd5\u7528\u4f8b\u53ef\u7528", "method": "\u91c7\u7528\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u4fee\u590d\u65b9\u6cd5\uff0c\u6536\u96c6\u8d85\u8fc740000\u4e2a\u4ea7\u54c1\u6e90\u4ee3\u7801\u63d0\u4ea4\uff0c\u8bc4\u4f30\u56db\u79cd\u6700\u5148\u8fdbLLM\u5728\u5de5\u4e1aCI\u7cfb\u7edf\u4e2d\u7684\u6027\u80fd", "result": "LLM\u589e\u5f3a\u7684CI\u7cfb\u7edf\u53ef\u89e3\u51b3\u57fa\u7ebf\u6570\u636e\u96c6\u4e2d63%\u7684\u7f16\u8bd1\u9519\u8bef\uff0c\u6210\u529fCI\u6784\u5efa\u7684\u4fee\u590d\u65b9\u6848\u4e2d83%\u662f\u5408\u7406\u7684\uff0c\u591a\u6570\u6210\u529f\u6848\u4f8b\u57288\u5206\u949f\u5185\u5b8c\u6210\uff0c\u76f8\u6bd4\u624b\u52a8\u8c03\u8bd5\u9700\u8981\u6570\u5c0f\u65f6", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u4fee\u590d\u7f16\u8bd1\u9519\u8bef\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u663e\u8457\u63d0\u9ad8\u5de5\u4e1a\u5d4c\u5165\u5f0f\u7cfb\u7edf\u5f00\u53d1\u6548\u7387"}}
{"id": "2510.13230", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13230", "abs": "https://arxiv.org/abs/2510.13230", "authors": ["Jalal Khan", "Manzoor Khan", "Sherzod Turaev", "Sumbal Malik", "Hesham El-Sayed", "Farman Ullah"], "title": "An Analytical Framework to Enhance Autonomous Vehicle Perception for Smart Cities", "comment": "32 pages, 14 figures", "summary": "The driving environment perception has a vital role for autonomous driving\nand nowadays has been actively explored for its realization. The research\ncommunity and relevant stakeholders necessitate the development of Deep\nLearning (DL) models and AI-enabled solutions to enhance autonomous vehicles\n(AVs) for smart mobility. There is a need to develop a model that accurately\nperceives multiple objects on the road and predicts the driver's perception to\ncontrol the car's movements. This article proposes a novel utility-based\nanalytical model that enables perception systems of AVs to understand the\ndriving environment. The article consists of modules: acquiring a custom\ndataset having distinctive objects, i.e., motorcyclists, rickshaws, etc; a\nDL-based model (YOLOv8s) for object detection; and a module to measure the\nutility of perception service from the performance values of trained model\ninstances. The perception model is validated based on the object detection\ntask, and its process is benchmarked by state-of-the-art deep learning models'\nperformance metrics from the nuScense dataset. The experimental results show\nthree best-performing YOLOv8s instances based on mAP@0.5 values, i.e.,\nSGD-based (0.832), Adam-based (0.810), and AdamW-based (0.822). However, the\nAdamW-based model (i.e., car: 0.921, motorcyclist: 0.899, truck: 0.793, etc.)\nstill outperforms the SGD-based model (i.e., car: 0.915, motorcyclist: 0.892,\ntruck: 0.781, etc.) because it has better class-level performance values,\nconfirmed by the proposed perception model. We validate that the proposed\nfunction is capable of finding the right perception for AVs. The results above\nencourage using the proposed perception model to evaluate the utility of\nlearning models and determine the appropriate perception for AVs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6548\u7528\u7684\u5206\u6790\u6a21\u578b\uff0c\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u611f\u77e5\u7cfb\u7edf\u7406\u89e3\u9a7e\u9a76\u73af\u5883\uff0c\u5305\u62ec\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u83b7\u53d6\u3001YOLOv8s\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u548c\u611f\u77e5\u670d\u52a1\u6548\u7528\u6d4b\u91cf\u6a21\u5757\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u73af\u5883\u611f\u77e5\u5bf9\u667a\u80fd\u4ea4\u901a\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u51c6\u786e\u611f\u77e5\u9053\u8def\u591a\u76ee\u6807\u5e76\u9884\u6d4b\u9a7e\u9a76\u5458\u611f\u77e5\u7684\u6a21\u578b\uff0c\u4ee5\u63a7\u5236\u8f66\u8f86\u8fd0\u52a8\u3002", "method": "\u4f7f\u7528\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\uff08\u5305\u542b\u6469\u6258\u8f66\u624b\u3001\u4e09\u8f6e\u8f66\u7b49\u72ec\u7279\u5bf9\u8c61\uff09\uff0c\u57fa\u4e8eYOLOv8s\u7684\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\uff0c\u4ee5\u53ca\u4ece\u8bad\u7ec3\u6a21\u578b\u6027\u80fd\u503c\u6d4b\u91cf\u611f\u77e5\u670d\u52a1\u6548\u7528\u7684\u6a21\u5757\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u4e09\u4e2a\u6700\u4f73\u6027\u80fd\u7684YOLOv8s\u5b9e\u4f8b\uff1aSGD-based\uff08mAP@0.5=0.832\uff09\u3001Adam-based\uff080.810\uff09\u548cAdamW-based\uff080.822\uff09\u3002AdamW\u6a21\u578b\u5728\u7c7b\u522b\u7ea7\u522b\u6027\u80fd\u4e0a\u4f18\u4e8eSGD\u6a21\u578b\u3002", "conclusion": "\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u7684\u611f\u77e5\u6a21\u578b\u80fd\u591f\u4e3a\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u627e\u5230\u6b63\u786e\u7684\u611f\u77e5\uff0c\u9f13\u52b1\u4f7f\u7528\u8be5\u6a21\u578b\u8bc4\u4f30\u5b66\u4e60\u6a21\u578b\u7684\u6548\u7528\u5e76\u786e\u5b9a\u5408\u9002\u7684\u81ea\u52a8\u9a7e\u9a76\u611f\u77e5\u3002"}}
{"id": "2510.13451", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.13451", "abs": "https://arxiv.org/abs/2510.13451", "authors": ["Li Bai", "Qingqing Ye", "Xinwei Zhang", "Sen Zhang", "Zi Liang", "Jianliang Xu", "Haibo Hu"], "title": "Toward Efficient Inference Attacks: Shadow Model Sharing via Mixture-of-Experts", "comment": "To appear in NeurIPS 2025", "summary": "Machine learning models are often vulnerable to inference attacks that expose\nsensitive information from their training data. Shadow model technique is\ncommonly employed in such attacks, such as membership inference. However, the\nneed for a large number of shadow models leads to high computational costs,\nlimiting their practical applicability. Such inefficiency mainly stems from the\nindependent training and use of these shadow models. To address this issue, we\npresent a novel shadow pool training framework SHAPOOL, which constructs\nmultiple shared models and trains them jointly within a single process. In\nparticular, we leverage the Mixture-of-Experts mechanism as the shadow pool to\ninterconnect individual models, enabling them to share some sub-networks and\nthereby improving efficiency. To ensure the shared models closely resemble\nindependent models and serve as effective substitutes, we introduce three novel\nmodules: path-choice routing, pathway regularization, and pathway alignment.\nThese modules guarantee random data allocation for pathway learning, promote\ndiversity among shared models, and maintain consistency with target models. We\nevaluate SHAPOOL in the context of various membership inference attacks and\nshow that it significantly reduces the computational cost of shadow model\nconstruction while maintaining comparable attack performance.", "AI": {"tldr": "SHAPOOL\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u5f71\u5b50\u6c60\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u5171\u4eab\u5b50\u7f51\u7edc\u548c\u8054\u5408\u8bad\u7ec3\u591a\u4e2a\u5f71\u5b50\u6a21\u578b\u6765\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u6210\u5458\u63a8\u7406\u653b\u51fb\u7684\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u5f71\u5b50\u6a21\u578b\u6280\u672f\u5728\u63a8\u7406\u653b\u51fb\u4e2d\u9700\u8981\u5927\u91cf\u72ec\u7acb\u8bad\u7ec3\u7684\u5f71\u5b50\u6a21\u578b\uff0c\u5bfc\u81f4\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002\u8fd9\u79cd\u4f4e\u6548\u6027\u4e3b\u8981\u6e90\u4e8e\u5f71\u5b50\u6a21\u578b\u7684\u72ec\u7acb\u8bad\u7ec3\u548c\u4f7f\u7528\u3002", "method": "SHAPOOL\u5229\u7528\u6df7\u5408\u4e13\u5bb6\u673a\u5236\u4f5c\u4e3a\u5f71\u5b50\u6c60\uff0c\u5c06\u5355\u4e2a\u6a21\u578b\u4e92\u8fde\uff0c\u4f7f\u5b83\u4eec\u5171\u4eab\u4e00\u4e9b\u5b50\u7f51\u7edc\u3002\u5f15\u5165\u4e09\u4e2a\u65b0\u6a21\u5757\uff1a\u8def\u5f84\u9009\u62e9\u8def\u7531\u3001\u8def\u5f84\u6b63\u5219\u5316\u548c\u8def\u5f84\u5bf9\u9f50\uff0c\u786e\u4fdd\u5171\u4eab\u6a21\u578b\u4e0e\u72ec\u7acb\u6a21\u578b\u76f8\u4f3c\u5e76\u4f5c\u4e3a\u6709\u6548\u66ff\u4ee3\u54c1\u3002", "result": "\u5728\u5404\u79cd\u6210\u5458\u63a8\u7406\u653b\u51fb\u573a\u666f\u4e0b\u8bc4\u4f30SHAPOOL\uff0c\u7ed3\u679c\u663e\u793a\u5b83\u663e\u8457\u964d\u4f4e\u4e86\u5f71\u5b50\u6a21\u578b\u6784\u5efa\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u53ef\u6bd4\u7684\u653b\u51fb\u6027\u80fd\u3002", "conclusion": "SHAPOOL\u6846\u67b6\u901a\u8fc7\u5171\u4eab\u5b50\u7f51\u7edc\u548c\u8054\u5408\u8bad\u7ec3\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5f71\u5b50\u6a21\u578b\u6280\u672f\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u95ee\u9898\uff0c\u4e3a\u63a8\u7406\u653b\u51fb\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.13692", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.13692", "abs": "https://arxiv.org/abs/2510.13692", "authors": ["Deepak A. Cherian"], "title": "Property Testing for Ocean Models. Can We Specify It? (Invited Talk)", "comment": "In Proceedings VSS 2025, arXiv:2510.12314", "summary": "I take inspiration from the property-testing literature, particularly the\nwork of Prof. John Hughes, and explore how such ideas might be applied to\nnumerical models of the ocean. Specifically, I ask whether geophysical fluid\ndynamics (GFD) theory, expressed as property tests, might be used to address\nthe oracle problem of testing the correctness of ocean models. I propose that a\nnumber of simple idealized GFD problems can be framed as property tests. These\nexamples clearly illustrate how physics naturally lends itself to specifying\nproperty tests. Which of these proposed tests might be most feasible and\nuseful, remains to be seen.", "AI": {"tldr": "\u63a2\u7d22\u5982\u4f55\u5c06\u5c5e\u6027\u6d4b\u8bd5\u601d\u60f3\u5e94\u7528\u4e8e\u6d77\u6d0b\u6570\u503c\u6a21\u578b\uff0c\u5229\u7528\u5730\u7403\u7269\u7406\u6d41\u4f53\u52a8\u529b\u5b66\u7406\u8bba\u4f5c\u4e3a\u5c5e\u6027\u6d4b\u8bd5\u6765\u89e3\u51b3\u6d77\u6d0b\u6a21\u578b\u6b63\u786e\u6027\u9a8c\u8bc1\u7684oracle\u95ee\u9898", "motivation": "\u4ece\u5c5e\u6027\u6d4b\u8bd5\u6587\u732e\u4e2d\u83b7\u5f97\u7075\u611f\uff0c\u7279\u522b\u662fJohn Hughes\u6559\u6388\u7684\u5de5\u4f5c\uff0c\u63a2\u7d22\u8fd9\u4e9b\u601d\u60f3\u5982\u4f55\u5e94\u7528\u4e8e\u6d77\u6d0b\u6570\u503c\u6a21\u578b\uff0c\u89e3\u51b3\u6a21\u578b\u6b63\u786e\u6027\u9a8c\u8bc1\u7684\u6311\u6218", "method": "\u63d0\u51fa\u5c06\u7b80\u5355\u7406\u60f3\u5316\u7684\u5730\u7403\u7269\u7406\u6d41\u4f53\u52a8\u529b\u5b66\u95ee\u9898\u6846\u67b6\u5316\u4e3a\u5c5e\u6027\u6d4b\u8bd5\uff0c\u5c55\u793a\u7269\u7406\u5b66\u5982\u4f55\u81ea\u7136\u5730\u9002\u7528\u4e8e\u5c5e\u6027\u6d4b\u8bd5\u89c4\u8303", "result": "\u901a\u8fc7\u793a\u4f8b\u6e05\u6670\u8bf4\u660e\u4e86\u7269\u7406\u5b66\u5982\u4f55\u81ea\u7136\u5730\u9002\u7528\u4e8e\u6307\u5b9a\u5c5e\u6027\u6d4b\u8bd5\uff0c\u4f46\u54ea\u4e9b\u6d4b\u8bd5\u6700\u53ef\u884c\u548c\u6709\u7528\u4ecd\u9700\u8fdb\u4e00\u6b65\u7814\u7a76", "conclusion": "\u5730\u7403\u7269\u7406\u6d41\u4f53\u52a8\u529b\u5b66\u7406\u8bba\u53ef\u4ee5\u6709\u6548\u5730\u6846\u67b6\u5316\u4e3a\u5c5e\u6027\u6d4b\u8bd5\uff0c\u4e3a\u89e3\u51b3\u6d77\u6d0b\u6a21\u578b\u6b63\u786e\u6027\u9a8c\u8bc1\u7684oracle\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u6cd5"}}
{"id": "2510.13262", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13262", "abs": "https://arxiv.org/abs/2510.13262", "authors": ["Weiqi Guo", "Guanjun Liu", "Ziyuan Zhou"], "title": "SAJA: A State-Action Joint Attack Framework on Multi-Agent Deep Reinforcement Learning", "comment": null, "summary": "Multi-Agent Deep Reinforcement Learning (MADRL) has shown potential for\ncooperative and competitive tasks such as autonomous driving and strategic\ngaming. However, models trained by MADRL are vulnerable to adversarial\nperturbations on states and actions. Therefore, it is essential to investigate\nthe robustness of MADRL models from an attack perspective. Existing studies\nfocus on either state-only attacks or action-only attacks, but do not consider\nhow to effectively joint them. Simply combining state and action perturbations\nsuch as randomly perturbing states and actions does not exploit their potential\nsynergistic effects. In this paper, we propose the State-Action Joint Attack\n(SAJA) framework that has a good synergistic effects. SAJA consists of two\nimportant phases: (1) In the state attack phase, a multi-step gradient ascent\nmethod utilizes both the actor network and the critic network to compute an\nadversarial state, and (2) in the action attack phase, based on the perturbed\nstate, a second gradient ascent uses the critic network to craft the final\nadversarial action. Additionally, a heuristic regularizer measuring the\ndistance between the perturbed actions and the original clean ones is added\ninto the loss function to enhance the effectiveness of the critic's guidance.\nWe evaluate SAJA in the Multi-Agent Particle Environment (MPE), demonstrating\nthat (1) it outperforms and is more stealthy than state-only or action-only\nattacks, and (2) existing state or action defense methods cannot defend its\nattacks.", "AI": {"tldr": "\u63d0\u51fa\u4e86SAJA\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u72b6\u6001\u548c\u52a8\u4f5c\u653b\u51fb\u6765\u589e\u5f3a\u591a\u667a\u80fd\u4f53\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u5bf9\u6297\u653b\u51fb\u6548\u679c\uff0c\u76f8\u6bd4\u5355\u72ec\u653b\u51fb\u66f4\u6709\u6548\u4e14\u9690\u853d", "motivation": "\u73b0\u6709\u7814\u7a76\u53ea\u5173\u6ce8\u72b6\u6001\u6216\u52a8\u4f5c\u7684\u5355\u72ec\u653b\u51fb\uff0c\u6ca1\u6709\u5145\u5206\u5229\u7528\u4e24\u8005\u7684\u534f\u540c\u6548\u5e94\uff0c\u7b80\u5355\u7ec4\u5408\u6548\u679c\u4e0d\u4f73", "method": "SAJA\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u9636\u6bb5\uff1a\u72b6\u6001\u653b\u51fb\u9636\u6bb5\u4f7f\u7528\u591a\u6b65\u68af\u5ea6\u4e0a\u5347\u7ed3\u5408actor\u548ccritic\u7f51\u7edc\u8ba1\u7b97\u5bf9\u6297\u72b6\u6001\uff1b\u52a8\u4f5c\u653b\u51fb\u9636\u6bb5\u57fa\u4e8e\u6270\u52a8\u72b6\u6001\u4f7f\u7528critic\u7f51\u7edc\u751f\u6210\u6700\u7ec8\u5bf9\u6297\u52a8\u4f5c\uff0c\u5e76\u6dfb\u52a0\u8ddd\u79bb\u6b63\u5219\u5316\u5668\u589e\u5f3a\u6548\u679c", "result": "\u5728MPE\u73af\u5883\u4e2d\u9a8c\u8bc1\uff0cSAJA\u6bd4\u5355\u72ec\u72b6\u6001\u6216\u52a8\u4f5c\u653b\u51fb\u6548\u679c\u66f4\u597d\u4e14\u66f4\u9690\u853d\uff0c\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u65e0\u6cd5\u62b5\u5fa1\u5176\u653b\u51fb", "conclusion": "SAJA\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u72b6\u6001\u548c\u52a8\u4f5c\u653b\u51fb\u7684\u534f\u540c\u6548\u5e94\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u5bf9\u6297\u9c81\u68d2\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2"}}
{"id": "2510.13462", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.13462", "abs": "https://arxiv.org/abs/2510.13462", "authors": ["Xin Zhao", "Xiaojun Chen", "Bingshan Liu", "Haoyu Gao", "Zhendong Zhao", "Yilong Chen"], "title": "Who Speaks for the Trigger? Dynamic Expert Routing in Backdoored Mixture-of-Experts Transformers", "comment": null, "summary": "Large language models (LLMs) with Mixture-of-Experts (MoE) architectures\nachieve impressive performance and efficiency by dynamically routing inputs to\nspecialized subnetworks, known as experts. However, this sparse routing\nmechanism inherently exhibits task preferences due to expert specialization,\nintroducing a new and underexplored vulnerability to backdoor attacks. In this\nwork, we investigate the feasibility and effectiveness of injecting backdoors\ninto MoE-based LLMs by exploiting their inherent expert routing preferences. We\nthus propose BadSwitch, a novel backdoor framework that integrates task-coupled\ndynamic trigger optimization with a sensitivity-guided Top-S expert tracing\nmechanism. Our approach jointly optimizes trigger embeddings during pretraining\nwhile identifying S most sensitive experts, subsequently constraining the Top-K\ngating mechanism to these targeted experts. Unlike traditional backdoor attacks\nthat rely on superficial data poisoning or model editing, BadSwitch primarily\nembeds malicious triggers into expert routing paths with strong task affinity,\nenabling precise and stealthy model manipulation. Through comprehensive\nevaluations across three prominent MoE architectures (Switch Transformer,\nQwenMoE, and DeepSeekMoE), we demonstrate that BadSwitch can efficiently hijack\npre-trained models with up to 100% success rate (ASR) while maintaining the\nhighest clean accuracy (ACC) among all baselines. Furthermore, BadSwitch\nexhibits strong resilience against both text-level and model-level defense\nmechanisms, achieving 94.07% ASR and 87.18% ACC on the AGNews dataset. Our\nanalysis of expert activation patterns reveals fundamental insights into MoE\nvulnerabilities. We anticipate this work will expose security risks in MoE\nsystems and contribute to advancing AI safety.", "AI": {"tldr": "BadSwitch\u662f\u4e00\u79cd\u9488\u5bf9MoE\u67b6\u6784LLM\u7684\u65b0\u578b\u540e\u95e8\u653b\u51fb\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u4e13\u5bb6\u8def\u7531\u504f\u597d\uff0c\u5728\u9884\u8bad\u7ec3\u671f\u95f4\u4f18\u5316\u89e6\u53d1\u5d4c\u5165\u5e76\u8bc6\u522b\u654f\u611f\u4e13\u5bb6\uff0c\u5b9e\u73b0\u9ad8\u6548\u4e14\u9690\u853d\u7684\u6a21\u578b\u64cd\u63a7\u3002", "motivation": "MoE\u67b6\u6784\u7684\u7a00\u758f\u8def\u7531\u673a\u5236\u7531\u4e8e\u4e13\u5bb6\u4e13\u4e1a\u5316\u800c\u8868\u73b0\u51fa\u4efb\u52a1\u504f\u597d\uff0c\u8fd9\u4e3a\u540e\u95e8\u653b\u51fb\u5f15\u5165\u4e86\u65b0\u7684\u672a\u5145\u5206\u63a2\u7d22\u7684\u6f0f\u6d1e\u3002", "method": "\u7ed3\u5408\u4efb\u52a1\u8026\u5408\u52a8\u6001\u89e6\u53d1\u4f18\u5316\u548c\u654f\u611f\u5ea6\u5f15\u5bfc\u7684Top-S\u4e13\u5bb6\u8ffd\u8e2a\u673a\u5236\uff0c\u5728\u9884\u8bad\u7ec3\u671f\u95f4\u8054\u5408\u4f18\u5316\u89e6\u53d1\u5d4c\u5165\uff0c\u8bc6\u522b\u6700\u654f\u611f\u7684S\u4e2a\u4e13\u5bb6\uff0c\u5e76\u5c06Top-K\u95e8\u63a7\u673a\u5236\u9650\u5236\u5728\u8fd9\u4e9b\u76ee\u6807\u4e13\u5bb6\u4e0a\u3002", "result": "\u5728\u4e09\u79cd\u4e3b\u6d41MoE\u67b6\u6784\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cBadSwitch\u80fd\u4ee5100%\u6210\u529f\u7387\u52ab\u6301\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u6301\u6700\u9ad8\u7684\u6e05\u6d01\u51c6\u786e\u7387\uff0c\u5bf9\u6587\u672c\u7ea7\u548c\u6a21\u578b\u7ea7\u9632\u5fa1\u673a\u5236\u5177\u6709\u5f3a\u97e7\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63ed\u793a\u4e86MoE\u7cfb\u7edf\u7684\u5b89\u5168\u98ce\u9669\uff0c\u901a\u8fc7\u5206\u6790\u4e13\u5bb6\u6fc0\u6d3b\u6a21\u5f0f\u63d0\u4f9b\u4e86\u5bf9MoE\u6f0f\u6d1e\u7684\u57fa\u672c\u89c1\u89e3\uff0c\u6709\u52a9\u4e8e\u63a8\u8fdbAI\u5b89\u5168\u3002"}}
{"id": "2510.13697", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.13697", "abs": "https://arxiv.org/abs/2510.13697", "authors": ["Maksim Sapronov", "Evgeniy Glukhov"], "title": "On Pretraining for Project-Level Code Completion", "comment": null, "summary": "Repository-level pretraining is commonly used to enable large language models\nfor code to leverage codebase-wide context. This enhances their ability to\ngenerate accurate and context-aware code completions. In this work, we\ninvestigate how different repository-processing strategies affect in-context\nlearning in OpenCoder, a 1.5B-parameter model. We extend its context window\nfrom 4,096 to 16,384 tokens by training on additional 1B tokens of curated\nrepository-level data. Despite relying on a smaller dataset than competing\nmodels (which often use hundreds of billions of tokens), our model achieves\ncomparable performance on the Long Code Arena benchmark. We find that various\nrepository-processing techniques yield similarly strong results, with the\nprimary gain coming from adapting to a new rotary positional embedding (RoPE)\nscaling parameter. Finally, we show that a simpler file-level training approach\nat the original sequence length remains highly effective, opening up\nrepository-level code completion research to settings with more constrained\ndata and compute resources.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4e0d\u540c\u4ee3\u7801\u5e93\u5904\u7406\u7b56\u7565\u5bf9OpenCoder\u6a21\u578b\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u6269\u5c55\u4e0a\u4e0b\u6587\u7a97\u53e3\u548c\u4f18\u5316\u4f4d\u7f6e\u7f16\u7801\uff0c\u5728\u8f83\u5c0f\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u4e0e\u5927\u578b\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\u3002", "motivation": "\u63a2\u7d22\u4ee3\u7801\u5e93\u7ea7\u522b\u7684\u9884\u8bad\u7ec3\u5982\u4f55\u5e2e\u52a9\u8bed\u8a00\u6a21\u578b\u751f\u6210\u66f4\u51c6\u786e\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u4ee3\u7801\u8865\u5168\uff0c\u7279\u522b\u662f\u5728\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u4e2d\u3002", "method": "\u5c06OpenCoder\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u7a97\u53e3\u4ece4,096\u6269\u5c55\u523016,384\u4e2atoken\uff0c\u5728\u989d\u591610\u4ebftoken\u7684\u4ee3\u7801\u5e93\u6570\u636e\u4e0a\u8bad\u7ec3\uff0c\u5e76\u6d4b\u8bd5\u4e0d\u540c\u7684\u4ee3\u7801\u5e93\u5904\u7406\u7b56\u7565\u548cRoPE\u4f4d\u7f6e\u7f16\u7801\u7f29\u653e\u53c2\u6570\u3002", "result": "\u5c3d\u7ba1\u4f7f\u7528\u6bd4\u7ade\u4e89\u6a21\u578b\u5c0f\u5f97\u591a\u7684\u6570\u636e\u96c6\uff0c\u8be5\u6a21\u578b\u5728Long Code Arena\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u53ef\u6bd4\u6027\u80fd\uff0c\u4e14\u53d1\u73b0\u4e0d\u540c\u4ee3\u7801\u5e93\u5904\u7406\u6280\u672f\u4ea7\u751f\u76f8\u4f3c\u7ed3\u679c\uff0c\u4e3b\u8981\u6536\u76ca\u6765\u81eaRoPE\u7f29\u653e\u53c2\u6570\u7684\u8c03\u6574\u3002", "conclusion": "\u7b80\u5355\u7684\u6587\u4ef6\u7ea7\u8bad\u7ec3\u65b9\u6cd5\u5728\u539f\u59cb\u5e8f\u5217\u957f\u5ea6\u4e0b\u4ecd\u7136\u975e\u5e38\u6709\u6548\uff0c\u8fd9\u4e3a\u6570\u636e\u8d44\u6e90\u548c\u8ba1\u7b97\u80fd\u529b\u53d7\u9650\u7684\u73af\u5883\u4e2d\u7684\u4ee3\u7801\u5e93\u7ea7\u4ee3\u7801\u8865\u5168\u7814\u7a76\u5f00\u8f9f\u4e86\u53ef\u80fd\u6027\u3002"}}
{"id": "2510.13393", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13393", "abs": "https://arxiv.org/abs/2510.13393", "authors": ["Yunxiao Zhao", "Zhiqiang Wang", "Xingtong Yu", "Xiaoli Li", "Jiye Liang", "Ru Li"], "title": "Learnable Game-theoretic Policy Optimization for Data-centric Self-explanation Rationalization", "comment": "14 pages, 7 figures, 11 tables. Under review by IEEE", "summary": "Rationalization, a data-centric framework, aims to build self-explanatory\nmodels to explain the prediction outcome by generating a subset of\nhuman-intelligible pieces of the input data. It involves a cooperative game\nmodel where a generator generates the most human-intelligible parts of the\ninput (i.e., rationales), followed by a predictor that makes predictions based\non these generated rationales. Conventional rationalization methods typically\nimpose constraints via regularization terms to calibrate or penalize undesired\ngeneration. However, these methods are suffering from a problem called mode\ncollapse, in which the predictor produces correct predictions yet the generator\nconsistently outputs rationales with collapsed patterns. Moreover, existing\nstudies are typically designed separately for specific collapsed patterns,\nlacking a unified consideration. In this paper, we systematically revisit\ncooperative rationalization from a novel game-theoretic perspective and\nidentify the fundamental cause of this problem: the generator no longer tends\nto explore new strategies to uncover informative rationales, ultimately leading\nthe system to converge to a suboptimal game equilibrium (correct predictions\nv.s collapsed rationales). To solve this problem, we then propose a novel\napproach, Game-theoretic Policy Optimization oriented RATionalization (PORAT),\nwhich progressively introduces policy interventions to address the game\nequilibrium in the cooperative game process, thereby guiding the model toward a\nmore optimal solution state. We theoretically analyse the cause of such a\nsuboptimal equilibrium and prove the feasibility of the proposed method.\nFurthermore, we validate our method on nine widely used real-world datasets and\ntwo synthetic settings, where PORAT achieves up to 8.1% performance\nimprovements over existing state-of-the-art methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPORAT\u65b9\u6cd5\uff0c\u4ece\u535a\u5f08\u8bba\u89c6\u89d2\u89e3\u51b3\u5408\u7406\u5316\u65b9\u6cd5\u4e2d\u7684\u6a21\u5f0f\u5d29\u6e83\u95ee\u9898\uff0c\u901a\u8fc7\u7b56\u7565\u5e72\u9884\u5f15\u5bfc\u6a21\u578b\u8fbe\u5230\u66f4\u4f18\u5747\u8861\u72b6\u6001\u3002", "motivation": "\u4f20\u7edf\u5408\u7406\u5316\u65b9\u6cd5\u5b58\u5728\u6a21\u5f0f\u5d29\u6e83\u95ee\u9898\uff0c\u5373\u9884\u6d4b\u5668\u80fd\u6b63\u786e\u9884\u6d4b\u4f46\u751f\u6210\u5668\u6301\u7eed\u8f93\u51fa\u5d29\u6e83\u6a21\u5f0f\u7684\u7406\u7531\u3002\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u7edf\u4e00\u8003\u8651\uff0c\u672c\u6587\u4ece\u535a\u5f08\u8bba\u89d2\u5ea6\u7cfb\u7edf\u5206\u6790\u8be5\u95ee\u9898\u7684\u6839\u672c\u539f\u56e0\u3002", "method": "\u63d0\u51faPORAT\u65b9\u6cd5\uff0c\u5728\u5408\u4f5c\u535a\u5f08\u8fc7\u7a0b\u4e2d\u9010\u6b65\u5f15\u5165\u7b56\u7565\u5e72\u9884\uff0c\u89e3\u51b3\u535a\u5f08\u5747\u8861\u95ee\u9898\uff0c\u5f15\u5bfc\u6a21\u578b\u5411\u66f4\u4f18\u89e3\u72b6\u6001\u53d1\u5c55\u3002", "result": "\u57289\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u548c2\u4e2a\u5408\u6210\u8bbe\u7f6e\u4e0a\u9a8c\u8bc1\uff0cPORAT\u76f8\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u6027\u80fd\u63d0\u5347\u6700\u9ad8\u8fbe8.1%\u3002", "conclusion": "\u4ece\u535a\u5f08\u8bba\u89c6\u89d2\u91cd\u65b0\u5ba1\u89c6\u5408\u4f5c\u5408\u7406\u5316\uff0c\u8bc6\u522b\u4e86\u6a21\u5f0f\u5d29\u6e83\u7684\u6839\u672c\u539f\u56e0\uff0c\u63d0\u51fa\u7684PORAT\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u8be5\u95ee\u9898\u5e76\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2510.13538", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.13538", "abs": "https://arxiv.org/abs/2510.13538", "authors": ["Alexander Ponticello", "Filipo Sharevski", "Simon Anell", "Katharina Krombholz"], "title": "How Blind and Low-Vision Users Manage Their Passwords", "comment": null, "summary": "Managing passwords securely and conveniently is still an open problem for\nmany users. Existing research has examined users' password management\nstrategies and identified pain points, such as security concerns, leading to\ninsecure practices. We investigate how Blind and Low-Vision (BLV) users tackle\nthis problem and how password managers can assist them. This paper presents the\nresults of a qualitative interview study with N = 33 BLV participants. We found\nthat all participants utilize password managers to some extent, which they\nperceive as fairly accessible. However, the adoption is mainly driven by the\nconvenience of storing and retrieving passwords. The security advantages -\ngenerating strong, random passwords - were avoided mainly due to the absence of\npractical accessibility. Password managers do not adhere to BLV users'\nunderlying needs for agency, which stem from experiences with inaccessible\nsoftware and vendors who deprioritize accessibility issues. Underutilization of\npassword managers leads BLV users to adopt insecure practices, such as reusing\npredictable passwords or resorting to 'security through obscurity' by writing\nimportant credentials in braille. We conclude our analysis by discussing the\nneed to implement practical accessibility and usability improvements for\npassword managers as a way of establishing trust and secure practices while\nmaintaining BLV users' agency.", "AI": {"tldr": "\u7814\u7a76\u8c03\u67e5\u4e86\u76f2\u4eba\u548c\u4f4e\u89c6\u529b\u7528\u6237\u5982\u4f55\u4f7f\u7528\u5bc6\u7801\u7ba1\u7406\u5668\uff0c\u53d1\u73b0\u867d\u7136\u6240\u6709\u53c2\u4e0e\u8005\u90fd\u4f7f\u7528\u5bc6\u7801\u7ba1\u7406\u5668\uff0c\u4f46\u4e3b\u8981\u662f\u4e3a\u4e86\u5b58\u50a8\u548c\u68c0\u7d22\u5bc6\u7801\u7684\u4fbf\u5229\u6027\uff0c\u800c\u975e\u5b89\u5168\u4f18\u52bf\u3002\u5bc6\u7801\u7ba1\u7406\u5668\u672a\u80fd\u6ee1\u8db3BLV\u7528\u6237\u5bf9\u81ea\u4e3b\u6743\u7684\u9700\u6c42\uff0c\u5bfc\u81f4\u4ed6\u4eec\u91c7\u7528\u4e0d\u5b89\u5168\u505a\u6cd5\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5df2\u8003\u5bdf\u7528\u6237\u5bc6\u7801\u7ba1\u7406\u7b56\u7565\u548c\u75db\u70b9\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u76f2\u4eba\u548c\u4f4e\u89c6\u529b\u7528\u6237\u5982\u4f55\u5e94\u5bf9\u5bc6\u7801\u7ba1\u7406\u95ee\u9898\u7684\u4e13\u95e8\u7814\u7a76\uff0c\u4ee5\u53ca\u5bc6\u7801\u7ba1\u7406\u5668\u5982\u4f55\u534f\u52a9\u4ed6\u4eec\u3002", "method": "\u91c7\u7528\u5b9a\u6027\u8bbf\u8c08\u7814\u7a76\uff0c\u4e0e33\u540d\u76f2\u4eba\u548c\u4f4e\u89c6\u529b\u53c2\u4e0e\u8005\u8fdb\u884c\u8bbf\u8c08\u3002", "result": "\u6240\u6709\u53c2\u4e0e\u8005\u90fd\u5728\u67d0\u79cd\u7a0b\u5ea6\u4e0a\u4f7f\u7528\u5bc6\u7801\u7ba1\u7406\u5668\uff0c\u8ba4\u4e3a\u5176\u76f8\u5bf9\u6613\u8bbf\u95ee\u3002\u4f46\u91c7\u7528\u4e3b\u8981\u53d7\u5b58\u50a8\u548c\u68c0\u7d22\u5bc6\u7801\u7684\u4fbf\u5229\u6027\u9a71\u52a8\uff0c\u800c\u975e\u5b89\u5168\u4f18\u52bf\u3002\u5bc6\u7801\u7ba1\u7406\u5668\u672a\u6ee1\u8db3BLV\u7528\u6237\u5bf9\u81ea\u4e3b\u6743\u7684\u9700\u6c42\uff0c\u5bfc\u81f4\u4e0d\u5b89\u5168\u505a\u6cd5\u5982\u91cd\u590d\u4f7f\u7528\u53ef\u9884\u6d4b\u5bc6\u7801\u6216\u5728\u76f2\u6587\u4e2d\u4e66\u5199\u91cd\u8981\u51ed\u8bc1\u3002", "conclusion": "\u9700\u8981\u5b9e\u65bd\u5b9e\u7528\u7684\u53ef\u8bbf\u95ee\u6027\u548c\u53ef\u7528\u6027\u6539\u8fdb\uff0c\u4ee5\u5efa\u7acb\u4fe1\u4efb\u548c\u5b89\u5168\u5b9e\u8df5\uff0c\u540c\u65f6\u4fdd\u6301BLV\u7528\u6237\u7684\u81ea\u4e3b\u6743\u3002"}}
{"id": "2510.13417", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.13417", "abs": "https://arxiv.org/abs/2510.13417", "authors": ["Liesbeth Allein", "Nataly Pineda-Casta\u00f1eda", "Andrea Rocci", "Marie-Francine Moens"], "title": "Assessing LLM Reasoning Through Implicit Causal Chain Discovery in Climate Discourse", "comment": null, "summary": "How does a cause lead to an effect, and which intermediate causal steps\nexplain their connection? This work scrutinizes the mechanistic causal\nreasoning capabilities of large language models (LLMs) to answer these\nquestions through the task of implicit causal chain discovery. In a diagnostic\nevaluation framework, we instruct nine LLMs to generate all possible\nintermediate causal steps linking given cause-effect pairs in causal chain\nstructures. These pairs are drawn from recent resources in argumentation\nstudies featuring polarized discussion on climate change. Our analysis reveals\nthat LLMs vary in the number and granularity of causal steps they produce.\nAlthough they are generally self-consistent and confident about the\nintermediate causal connections in the generated chains, their judgments are\nmainly driven by associative pattern matching rather than genuine causal\nreasoning. Nonetheless, human evaluations confirmed the logical coherence and\nintegrity of the generated chains. Our baseline causal chain discovery\napproach, insights from our diagnostic evaluation, and benchmark dataset with\ncausal chains lay a solid foundation for advancing future work in implicit,\nmechanistic causal reasoning in argumentation settings.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9690\u5f0f\u56e0\u679c\u94fe\u53d1\u73b0\u4efb\u52a1\u4e2d\u7684\u673a\u5236\u6027\u56e0\u679c\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0LLMs\u5728\u751f\u6210\u56e0\u679c\u6b65\u9aa4\u65f6\u5b58\u5728\u5dee\u5f02\uff0c\u4e3b\u8981\u4f9d\u8d56\u5173\u8054\u6a21\u5f0f\u5339\u914d\u800c\u975e\u771f\u6b63\u7684\u56e0\u679c\u63a8\u7406\u3002", "motivation": "\u63a2\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u7406\u89e3\u56e0\u679c\u5173\u7cfb\uff0c\u4ee5\u53ca\u5b83\u4eec\u80fd\u5426\u8bc6\u522b\u8fde\u63a5\u56e0\u679c\u5bf9\u7684\u4e2d\u95f4\u56e0\u679c\u6b65\u9aa4\uff0c\u7279\u522b\u662f\u5728\u8bba\u8bc1\u573a\u666f\u4e2d\u7684\u673a\u5236\u6027\u56e0\u679c\u63a8\u7406\u80fd\u529b\u3002", "method": "\u5728\u8bca\u65ad\u8bc4\u4f30\u6846\u67b6\u4e2d\uff0c\u6307\u5bfc\u4e5d\u4e2aLLMs\u4e3a\u7ed9\u5b9a\u7684\u56e0\u679c\u5bf9\u751f\u6210\u6240\u6709\u53ef\u80fd\u7684\u4e2d\u95f4\u56e0\u679c\u6b65\u9aa4\uff0c\u8fd9\u4e9b\u56e0\u679c\u5bf9\u6765\u81ea\u6c14\u5019\u53d8\u5316\u8fa9\u8bba\u7684\u8bba\u8bc1\u7814\u7a76\u8d44\u6e90\u3002", "result": "LLMs\u5728\u751f\u6210\u7684\u56e0\u679c\u6b65\u9aa4\u6570\u91cf\u548c\u7c92\u5ea6\u4e0a\u5b58\u5728\u5dee\u5f02\uff0c\u867d\u7136\u5b83\u4eec\u5bf9\u4e2d\u95f4\u56e0\u679c\u8fde\u63a5\u5177\u6709\u81ea\u6211\u4e00\u81f4\u6027\u548c\u4fe1\u5fc3\uff0c\u4f46\u5224\u65ad\u4e3b\u8981\u57fa\u4e8e\u5173\u8054\u6a21\u5f0f\u5339\u914d\u3002\u4eba\u7c7b\u8bc4\u4f30\u786e\u8ba4\u4e86\u751f\u6210\u94fe\u7684\u903b\u8f91\u8fde\u8d2f\u6027\u548c\u5b8c\u6574\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u63a8\u8fdb\u8bba\u8bc1\u573a\u666f\u4e2d\u9690\u5f0f\u673a\u5236\u6027\u56e0\u679c\u63a8\u7406\u7684\u672a\u6765\u5de5\u4f5c\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\uff0c\u5305\u62ec\u57fa\u7ebf\u56e0\u679c\u94fe\u53d1\u73b0\u65b9\u6cd5\u3001\u8bca\u65ad\u8bc4\u4f30\u89c1\u89e3\u548c\u5e26\u56e0\u679c\u94fe\u7684\u57fa\u51c6\u6570\u636e\u96c6\u3002"}}
{"id": "2510.13543", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13543", "abs": "https://arxiv.org/abs/2510.13543", "authors": ["Avihay Cohen"], "title": "In-Browser LLM-Guided Fuzzing for Real-Time Prompt Injection Testing in Agentic AI Browsers", "comment": "37 pages , 10 figures", "summary": "Large Language Model (LLM) based agents integrated into web browsers (often\ncalled agentic AI browsers) offer powerful automation of web tasks. However,\nthey are vulnerable to indirect prompt injection attacks, where malicious\ninstructions hidden in a webpage deceive the agent into unwanted actions. These\nattacks can bypass traditional web security boundaries, as the AI agent\noperates with the user privileges across sites. In this paper, we present a\nnovel fuzzing framework that runs entirely in the browser and is guided by an\nLLM to automatically discover such prompt injection vulnerabilities in real\ntime.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u6d4f\u89c8\u5668\u4e2d\u8fd0\u884c\u7684LLM\u5f15\u5bfc\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6\uff0c\u7528\u4e8e\u5b9e\u65f6\u53d1\u73b0\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\u6f0f\u6d1e", "motivation": "\u57fa\u4e8eLLM\u7684\u6d4f\u89c8\u5668\u4ee3\u7406\u5bb9\u6613\u53d7\u5230\u7f51\u9875\u4e2d\u9690\u85cf\u6076\u610f\u6307\u4ee4\u7684\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u8fd9\u4e9b\u653b\u51fb\u53ef\u4ee5\u7ed5\u8fc7\u4f20\u7edf\u7f51\u7edc\u5b89\u5168\u8fb9\u754c", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5b8c\u5168\u5728\u6d4f\u89c8\u5668\u4e2d\u8fd0\u884c\u7684\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6\uff0c\u4f7f\u7528LLM\u5f15\u5bfc\u6765\u81ea\u52a8\u53d1\u73b0\u63d0\u793a\u6ce8\u5165\u6f0f\u6d1e", "result": "\u6846\u67b6\u80fd\u591f\u5728\u5b9e\u65f6\u73af\u5883\u4e2d\u6709\u6548\u68c0\u6d4b\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\u6f0f\u6d1e", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u68c0\u6d4b\u548c\u9632\u5fa1LLM\u6d4f\u89c8\u5668\u4ee3\u7406\u7684\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2510.13459", "categories": ["cs.AI", "cs.CE", "cs.NI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.13459", "abs": "https://arxiv.org/abs/2510.13459", "authors": ["Timothy Wong", "Tom Freeman", "Joseph Feehily"], "title": "Mobile Coverage Analysis using Crowdsourced Data", "comment": "8 pages", "summary": "Effective assessment of mobile network coverage and the precise\nidentification of service weak spots are paramount for network operators\nstriving to enhance user Quality of Experience (QoE). This paper presents a\nnovel framework for mobile coverage and weak spot analysis utilising\ncrowdsourced QoE data. The core of our methodology involves coverage analysis\nat the individual cell (antenna) level, subsequently aggregated to the site\nlevel, using empirical geolocation data. A key contribution of this research is\nthe application of One-Class Support Vector Machine (OC-SVM) algorithm for\ncalculating mobile network coverage. This approach models the decision\nhyperplane as the effective coverage contour, facilitating robust calculation\nof coverage areas for individual cells and entire sites. The same methodology\nis extended to analyse crowdsourced service loss reports, thereby identifying\nand quantifying geographically localised weak spots. Our findings demonstrate\nthe efficacy of this novel framework in accurately mapping mobile coverage and,\ncrucially, in highlighting granular areas of signal deficiency, particularly\nwithin complex urban environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u4f17\u5305QoE\u6570\u636e\u8fdb\u884c\u79fb\u52a8\u7f51\u7edc\u8986\u76d6\u548c\u5f31\u4fe1\u53f7\u70b9\u5206\u6790\u7684\u65b0\u6846\u67b6\uff0c\u4f7f\u7528OC-SVM\u7b97\u6cd5\u8ba1\u7b97\u8986\u76d6\u8303\u56f4\u5e76\u8bc6\u522b\u670d\u52a1\u5f31\u533a", "motivation": "\u51c6\u786e\u8bc4\u4f30\u79fb\u52a8\u7f51\u7edc\u8986\u76d6\u548c\u8bc6\u522b\u670d\u52a1\u5f31\u533a\u5bf9\u4e8e\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u8d28\u91cf\u81f3\u5173\u91cd\u8981", "method": "\u57fa\u4e8e\u4f17\u5305QoE\u6570\u636e\uff0c\u5728\u5355\u4e2a\u5929\u7ebf\u7ea7\u522b\u8fdb\u884c\u8986\u76d6\u5206\u6790\u540e\u805a\u5408\u5230\u7ad9\u70b9\u7ea7\u522b\uff0c\u4f7f\u7528OC-SVM\u7b97\u6cd5\u5efa\u6a21\u6709\u6548\u8986\u76d6\u8fb9\u754c", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u51c6\u786e\u7ed8\u5236\u79fb\u52a8\u7f51\u7edc\u8986\u76d6\u56fe\uff0c\u5e76\u5728\u590d\u6742\u57ce\u5e02\u73af\u5883\u4e2d\u7a81\u51fa\u663e\u793a\u4fe1\u53f7\u4e0d\u8db3\u7684\u7ec6\u7c92\u5ea6\u533a\u57df", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u6240\u63d0\u6846\u67b6\u5728\u79fb\u52a8\u8986\u76d6\u6620\u5c04\u548c\u5f31\u4fe1\u53f7\u70b9\u8bc6\u522b\u65b9\u9762\u7684\u6709\u6548\u6027"}}
{"id": "2510.13501", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13501", "abs": "https://arxiv.org/abs/2510.13501", "authors": ["He Du", "Bowen Li", "Chengxing Xie", "Chang Gao", "Kai Chen", "Dacheng Tao"], "title": "Confidence as a Reward: Transforming LLMs into Reward Models", "comment": null, "summary": "Reward models can significantly enhance the reasoning capabilities of large\nlanguage models (LLMs), but they typically require extensive curated data and\ncostly training. To mitigate these challenges, training-free approaches such as\nLLM-as-a-Judge leverage the intrinsic reasoning abilities of LLMs to evaluate\nresponses, achieving promising results. Recent works have also indicated that\nmodel confidence can serve effectively as a reward metric, distinguishing\nbetween chain-of-thought (CoT) and non-CoT paths. However, the concept of using\nconfidence as a reward has not been comprehensively studied. In this work, we\nsystematically investigate Confidence-as-a-Reward (CRew), a simple yet powerful\ntraining-free method that utilizes token-level confidence in the model's final\nanswers as a proxy for reward, especially suitable for close-ended tasks.\nThrough extensive experiments on mathematical reasoning tasks, we demonstrate\nthat CRew outperforms existing training-free reward approaches on the MATH500\nand RewardMATH benchmarks, and even surpasses most trained reward models. We\nfurther identify a strong correlation between CRew scores and the actual\nreasoning performance of the model. Additionally, we find that CRew can\neffectively filter high-quality training data. Building upon these insights, we\npropose CRew-DPO, a training strategy that constructs preference data from\nconfidence scores combined with correctness signals. Finetuning with CRew-DPO\nfurther enhances the model's judging capabilities and consistently outperforms\nexisting self-training methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u5956\u52b1\u65b9\u6cd5CRew\uff0c\u5229\u7528\u6a21\u578b\u5bf9\u6700\u7ec8\u7b54\u6848\u7684\u7f6e\u4fe1\u5ea6\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f00\u53d1\u4e86CRew-DPO\u8bad\u7ec3\u7b56\u7565\u3002", "motivation": "\u73b0\u6709\u7684\u5956\u52b1\u6a21\u578b\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\u548c\u6602\u8d35\u8bad\u7ec3\uff0c\u800c\u8bad\u7ec3\u514d\u8d39\u65b9\u6cd5\u5982LLM-as-a-Judge\u867d\u7136\u6709\u6548\uff0c\u4f46\u4f7f\u7528\u7f6e\u4fe1\u5ea6\u4f5c\u4e3a\u5956\u52b1\u7684\u6982\u5ff5\u5c1a\u672a\u5f97\u5230\u7cfb\u7edf\u7814\u7a76\u3002", "method": "\u63d0\u51faCRew\u65b9\u6cd5\uff0c\u5229\u7528\u6a21\u578b\u5728\u6700\u7ec8\u7b54\u6848\u4e0a\u7684token\u7ea7\u7f6e\u4fe1\u5ea6\u4f5c\u4e3a\u5956\u52b1\u4ee3\u7406\uff1b\u8fdb\u4e00\u6b65\u5f00\u53d1CRew-DPO\u8bad\u7ec3\u7b56\u7565\uff0c\u7ed3\u5408\u7f6e\u4fe1\u5ea6\u548c\u6b63\u786e\u6027\u4fe1\u53f7\u6784\u5efa\u504f\u597d\u6570\u636e\u3002", "result": "\u5728MATH500\u548cRewardMATH\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCRew\u4f18\u4e8e\u73b0\u6709\u8bad\u7ec3\u514d\u8d39\u5956\u52b1\u65b9\u6cd5\uff0c\u751a\u81f3\u8d85\u8fc7\u5927\u591a\u6570\u8bad\u7ec3\u8fc7\u7684\u5956\u52b1\u6a21\u578b\uff1bCRew-DPO\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u81ea\u8bad\u7ec3\u65b9\u6cd5\u3002", "conclusion": "\u7f6e\u4fe1\u5ea6\u4f5c\u4e3a\u5956\u52b1\u662f\u4e00\u79cd\u7b80\u5355\u800c\u5f3a\u5927\u7684\u8bad\u7ec3\u514d\u8d39\u65b9\u6cd5\uff0c\u80fd\u6709\u6548\u63d0\u5347\u6a21\u578b\u63a8\u7406\u80fd\u529b\uff0c\u4e14\u53ef\u7528\u4e8e\u6784\u5efa\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\u3002"}}
{"id": "2510.13524", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13524", "abs": "https://arxiv.org/abs/2510.13524", "authors": ["William Flanagan", "Mukunda Das", "Rajitha Ramanyake", "Swaunja Maslekar", "Meghana Manipuri", "Joong Ho Choi", "Shruti Nair", "Shambhavi Bhusan", "Sanjana Dulam", "Mouni Pendharkar", "Nidhi Singh", "Vashisth Doshi", "Sachi Shah Paresh"], "title": "A Methodology for Assessing the Risk of Metric Failure in LLMs Within the Financial Domain", "comment": "NeurIPS 2025 GenAI in Finance Workshop", "summary": "As Generative Artificial Intelligence is adopted across the financial\nservices industry, a significant barrier to adoption and usage is measuring\nmodel performance. Historical machine learning metrics can oftentimes fail to\ngeneralize to GenAI workloads and are often supplemented using Subject Matter\nExpert (SME) Evaluation. Even in this combination, many projects fail to\naccount for various unique risks present in choosing specific metrics.\nAdditionally, many widespread benchmarks created by foundational research labs\nand educational institutions fail to generalize to industrial use. This paper\nexplains these challenges and provides a Risk Assessment Framework to allow for\nbetter application of SME and machine learning Metrics", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u98ce\u9669\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u751f\u6210\u5f0fAI\u5728\u91d1\u878d\u670d\u52a1\u884c\u4e1a\u5e94\u7528\u4e2d\u7684\u6027\u80fd\u8bc4\u4f30\u6311\u6218\uff0c\u7ed3\u5408\u9886\u57df\u4e13\u5bb6\u8bc4\u4f30\u548c\u673a\u5668\u5b66\u4e60\u6307\u6807\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5728\u91d1\u878d\u670d\u52a1\u884c\u4e1a\u7684\u5e94\u7528\u9762\u4e34\u6027\u80fd\u8bc4\u4f30\u969c\u788d\uff0c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6307\u6807\u65e0\u6cd5\u5f88\u597d\u9002\u5e94GenAI\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u800c\u5e7f\u6cdb\u4f7f\u7528\u7684\u57fa\u51c6\u6d4b\u8bd5\u5728\u5de5\u4e1a\u5e94\u7528\u4e2d\u7f3a\u4e4f\u901a\u7528\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u98ce\u9669\u8bc4\u4f30\u6846\u67b6\uff0c\u7ed3\u5408\u9886\u57df\u4e13\u5bb6\u8bc4\u4f30\u548c\u673a\u5668\u5b66\u4e60\u6307\u6807\uff0c\u4ee5\u66f4\u597d\u5730\u8861\u91cf\u751f\u6210\u5f0fAI\u6a21\u578b\u7684\u6027\u80fd\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u89e3\u51b3\u9009\u62e9\u7279\u5b9a\u6307\u6807\u65f6\u7684\u72ec\u7279\u98ce\u9669\uff0c\u5e76\u6539\u5584\u9886\u57df\u4e13\u5bb6\u8bc4\u4f30\u548c\u673a\u5668\u5b66\u4e60\u6307\u6807\u7684\u5e94\u7528\u6548\u679c\u3002", "conclusion": "\u63d0\u51fa\u7684\u98ce\u9669\u8bc4\u4f30\u6846\u67b6\u6709\u52a9\u4e8e\u91d1\u878d\u670d\u52a1\u884c\u4e1a\u66f4\u597d\u5730\u91c7\u7528\u751f\u6210\u5f0fAI\u6280\u672f\uff0c\u89e3\u51b3\u6027\u80fd\u8bc4\u4f30\u7684\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2510.13551", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13551", "abs": "https://arxiv.org/abs/2510.13551", "authors": ["Robert West", "Ashton Anderson", "Ece Kamar", "Eric Horvitz"], "title": "Tandem Training for Language Models", "comment": null, "summary": "As language models continue to rapidly improve, we can expect their actions\nand reasoning to become difficult or impossible for weaker agents and humans to\nfollow, undermining interpretability and oversight. With an eye on long-term\nfutures, we pursue methods that encourage models to produce solutions that\nremain intelligible to weaker collaborators. We formalize intelligibility as\nhandoff robustness: a strong model's solution is intelligible to a weaker model\nif randomly handing off control to the weaker model along the solution path\ndoes not cause failure. Building on this criterion, we introduce tandem\ntraining for language models, a reinforcement learning (RL) paradigm in which\nrollout tokens are intermittently and randomly sampled from a frozen weak model\nrather than the strong model being trained. Because rollouts succeed only when\nthe strong model's actions and reasoning process can be continued by the weak\nmodel -- when the two can co-construct a successful solution -- optimizing\nstandard RL objectives with tandem training implicitly incentivizes both\ncorrectness and intelligibility. In the GSM8K math reasoning task, tandem\ntraining reliably teaches models to abandon jargon and adapt their language to\nweaker partners while keeping task accuracy high. Our results demonstrate a\npromising route to building AI systems that remain auditable by weaker agents,\nwith implications for human--AI collaboration and multi-agent communication.", "AI": {"tldr": "\u63d0\u51fa\u4e32\u8054\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u968f\u673a\u5207\u6362\u5f3a\u5f31\u6a21\u578b\u6765\u786e\u4fdd\u5f3a\u6a21\u578b\u7684\u89e3\u51b3\u65b9\u6848\u5bf9\u5f31\u6a21\u578b\u53ef\u7406\u89e3\uff0c\u540c\u65f6\u4fdd\u6301\u4efb\u52a1\u51c6\u786e\u6027\u3002", "motivation": "\u968f\u7740\u8bed\u8a00\u6a21\u578b\u5feb\u901f\u53d1\u5c55\uff0c\u5176\u63a8\u7406\u8fc7\u7a0b\u53ef\u80fd\u8d85\u51fa\u4eba\u7c7b\u548c\u5f31\u667a\u80fd\u4f53\u7684\u7406\u89e3\u8303\u56f4\uff0c\u5f71\u54cd\u53ef\u89e3\u91ca\u6027\u548c\u76d1\u7763\u3002\u9700\u8981\u786e\u4fdd\u5f3a\u6a21\u578b\u7684\u89e3\u51b3\u65b9\u6848\u5bf9\u5f31\u5408\u4f5c\u4f19\u4f34\u4fdd\u6301\u53ef\u7406\u89e3\u6027\u3002", "method": "\u5f15\u5165\u4e32\u8054\u8bad\u7ec3\uff1a\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u968f\u673a\u4ece\u51bb\u7ed3\u7684\u5f31\u6a21\u578b\u800c\u975e\u5f3a\u6a21\u578b\u4e2d\u91c7\u6837token\uff0c\u53ea\u6709\u5f53\u5f3a\u6a21\u578b\u7684\u884c\u4e3a\u548c\u63a8\u7406\u8fc7\u7a0b\u80fd\u88ab\u5f31\u6a21\u578b\u7ee7\u7eed\u65f6\uff0c\u624d\u80fd\u6210\u529f\u5b8c\u6210rollout\u3002", "result": "\u5728GSM8K\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\uff0c\u4e32\u8054\u8bad\u7ec3\u53ef\u9760\u5730\u6559\u4f1a\u6a21\u578b\u653e\u5f03\u4e13\u4e1a\u672f\u8bed\uff0c\u9002\u5e94\u5f31\u5408\u4f5c\u4f19\u4f34\u7684\u8bed\u8a00\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u4efb\u52a1\u51c6\u786e\u7387\u3002", "conclusion": "\u4e32\u8054\u8bad\u7ec3\u4e3a\u6784\u5efa\u5bf9\u5f31\u667a\u80fd\u4f53\u53ef\u5ba1\u8ba1\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u6761\u6709\u524d\u666f\u7684\u8def\u5f84\uff0c\u5bf9\u4eba\u4e0eAI\u534f\u4f5c\u548c\u591a\u667a\u80fd\u4f53\u901a\u4fe1\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2510.13691", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13691", "abs": "https://arxiv.org/abs/2510.13691", "authors": ["Cecilia Di Florio", "Huimin Dong", "Antonino Rotolo"], "title": "A Modal Logic for Temporal and Jurisdictional Classifier Models", "comment": "18 pages, 2 figures. Extended version of a short paper accepted at\n  PRIMA 2025. This is the authors' version of the work. It is posted here for\n  your personal use", "summary": "Logic-based models can be used to build verification tools for machine\nlearning classifiers employed in the legal field. ML classifiers predict the\noutcomes of new cases based on previous ones, thereby performing a form of\ncase-based reasoning (CBR). In this paper, we introduce a modal logic of\nclassifiers designed to formally capture legal CBR. We incorporate principles\nfor resolving conflicts between precedents, by introducing into the logic the\ntemporal dimension of cases and the hierarchy of courts within the legal\nsystem.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5f62\u5f0f\u5316\u6cd5\u5f8b\u6848\u4f8b\u63a8\u7406\u7684\u5206\u7c7b\u5668\u6a21\u6001\u903b\u8f91\uff0c\u7ed3\u5408\u65f6\u95f4\u7ef4\u5ea6\u548c\u6cd5\u9662\u5c42\u7ea7\u6765\u89e3\u51b3\u5148\u4f8b\u51b2\u7a81", "motivation": "\u57fa\u4e8e\u903b\u8f91\u7684\u6a21\u578b\u53ef\u7528\u4e8e\u6784\u5efa\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u7684\u9a8c\u8bc1\u5de5\u5177\uff0c\u8fd9\u4e9b\u5206\u7c7b\u5668\u5728\u6cd5\u5f8b\u9886\u57df\u57fa\u4e8e\u5148\u524d\u6848\u4f8b\u9884\u6d4b\u65b0\u6848\u4f8b\u7ed3\u679c\uff0c\u6267\u884c\u6848\u4f8b\u63a8\u7406", "method": "\u5f15\u5165\u5206\u7c7b\u5668\u6a21\u6001\u903b\u8f91\uff0c\u5c06\u6848\u4f8b\u7684\u65f6\u95f4\u7ef4\u5ea6\u548c\u6cd5\u9662\u7cfb\u7edf\u7684\u5c42\u7ea7\u7ed3\u6784\u7eb3\u5165\u903b\u8f91\u4e2d\uff0c\u4ee5\u89e3\u51b3\u5148\u4f8b\u4e4b\u95f4\u7684\u51b2\u7a81", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u80fd\u591f\u5f62\u5f0f\u5316\u6355\u6349\u6cd5\u5f8b\u6848\u4f8b\u63a8\u7406\u7684\u903b\u8f91\u6846\u67b6", "conclusion": "\u8be5\u903b\u8f91\u6846\u67b6\u4e3a\u9a8c\u8bc1\u6cd5\u5f8b\u9886\u57df\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u80fd\u591f\u5904\u7406\u5148\u4f8b\u51b2\u7a81\u95ee\u9898"}}
{"id": "2510.13709", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.13709", "abs": "https://arxiv.org/abs/2510.13709", "authors": ["Evan Ellis", "Vivek Myers", "Jens Tuyls", "Sergey Levine", "Anca Dragan", "Benjamin Eysenbach"], "title": "Training LLM Agents to Empower Humans", "comment": null, "summary": "Assistive agents should not only take actions on behalf of a human, but also\nstep out of the way and cede control when there are important decisions to be\nmade. However, current methods for building assistive agents, whether via\nmimicking expert humans or via RL finetuning on an inferred reward, often\nencourage agents to complete tasks on their own rather than truly assisting the\nhuman attain their objectives. Additionally, these methods often require costly\nexplicit human feedback to provide a training signal. We propose a new approach\nto tuning assistive language models based on maximizing the human's\nempowerment, their ability to effect desired changes in the environment. Our\nempowerment-maximizing method, Empower, only requires offline text data,\nproviding a self-supervised method for fine-tuning language models to better\nassist humans. To study the efficacy of our approach, we conducted an 18-person\nuser study comparing our empowerment assistant with a strong baseline.\nParticipants preferred our assistant 78% of the time (p=0.015), with a 31%\nhigher acceptance rate and 38% fewer suggestions. Additionally, we introduce a\nnew environment for evaluating multi-turn code assistance using simulated\nhumans. Using this environment, we show that agents trained with Empower\nincrease the success rate of a simulated human programmer on challenging coding\nquestions by an average of 192% over an SFT baseline. With this empowerment\nobjective, we provide a framework for useful aligned AI agents at scale using\nonly offline data without the need for any additional human feedback or\nverifiable rewards.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6700\u5927\u5316\u4eba\u7c7b\u8d4b\u80fd\uff08empowerment\uff09\u7684\u8f85\u52a9\u8bed\u8a00\u6a21\u578b\u8c03\u4f18\u65b9\u6cd5Empower\uff0c\u8be5\u65b9\u6cd5\u4ec5\u9700\u79bb\u7ebf\u6587\u672c\u6570\u636e\uff0c\u65e0\u9700\u989d\u5916\u4eba\u5de5\u53cd\u9988\u6216\u53ef\u9a8c\u8bc1\u5956\u52b1\uff0c\u5c31\u80fd\u8bad\u7ec3\u51fa\u66f4\u597d\u7684\u8f85\u52a9AI\u52a9\u624b\u3002", "motivation": "\u5f53\u524d\u6784\u5efa\u8f85\u52a9\u4ee3\u7406\u7684\u65b9\u6cd5\uff08\u6a21\u4eff\u4e13\u5bb6\u6216\u57fa\u4e8e\u63a8\u65ad\u5956\u52b1\u7684RL\u5fae\u8c03\uff09\u5f80\u5f80\u9f13\u52b1\u4ee3\u7406\u72ec\u7acb\u5b8c\u6210\u4efb\u52a1\u800c\u975e\u771f\u6b63\u8f85\u52a9\u4eba\u7c7b\u5b9e\u73b0\u76ee\u6807\uff0c\u4e14\u9700\u8981\u6602\u8d35\u7684\u4eba\u5de5\u53cd\u9988\u3002", "method": "Empower\u65b9\u6cd5\u901a\u8fc7\u6700\u5927\u5316\u4eba\u7c7b\u5728\u73af\u5883\u4e2d\u5b9e\u73b0\u671f\u671b\u53d8\u5316\u7684\u80fd\u529b\uff08\u8d4b\u80fd\uff09\u6765\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\uff0c\u4ec5\u4f7f\u7528\u79bb\u7ebf\u6587\u672c\u6570\u636e\u8fdb\u884c\u81ea\u76d1\u7763\u8bad\u7ec3\u3002", "result": "\u7528\u6237\u7814\u7a76\u4e2d78%\u7684\u53c2\u4e0e\u8005\u504f\u597dEmpower\u52a9\u624b\uff08p=0.015\uff09\uff0c\u63a5\u53d7\u7387\u63d0\u9ad831%\uff0c\u5efa\u8bae\u51cf\u5c1138%\u3002\u5728\u4ee3\u7801\u8f85\u52a9\u73af\u5883\u4e2d\uff0cEmpower\u8bad\u7ec3\u4ee3\u7406\u4f7f\u6a21\u62df\u7a0b\u5e8f\u5458\u5728\u6311\u6218\u6027\u7f16\u7a0b\u95ee\u9898\u4e0a\u7684\u6210\u529f\u7387\u5e73\u5747\u63d0\u9ad8192%\u3002", "conclusion": "Empower\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4ec5\u4f7f\u7528\u79bb\u7ebf\u6570\u636e\u3001\u65e0\u9700\u989d\u5916\u4eba\u5de5\u53cd\u9988\u6216\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5927\u89c4\u6a21\u6709\u7528\u5bf9\u9f50AI\u4ee3\u7406\u6846\u67b6\u3002"}}
{"id": "2510.13727", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13727", "abs": "https://arxiv.org/abs/2510.13727", "authors": ["Ravi Pandya", "Madison Bland", "Duy P. Nguyen", "Changliu Liu", "Jaime Fern\u00e1ndez Fisac", "Andrea Bajcsy"], "title": "From Refusal to Recovery: A Control-Theoretic Approach to Generative AI Guardrails", "comment": null, "summary": "Generative AI systems are increasingly assisting and acting on behalf of end\nusers in practical settings, from digital shopping assistants to\nnext-generation autonomous cars. In this context, safety is no longer about\nblocking harmful content, but about preempting downstream hazards like\nfinancial or physical harm. Yet, most AI guardrails continue to rely on output\nclassification based on labeled datasets and human-specified criteria,making\nthem brittle to new hazardous situations. Even when unsafe conditions are\nflagged, this detection offers no path to recovery: typically, the AI system\nsimply refuses to act--which is not always a safe choice. In this work, we\nargue that agentic AI safety is fundamentally a sequential decision problem:\nharmful outcomes arise from the AI system's continually evolving interactions\nand their downstream consequences on the world. We formalize this through the\nlens of safety-critical control theory, but within the AI model's latent\nrepresentation of the world. This enables us to build predictive guardrails\nthat (i) monitor an AI system's outputs (actions) in real time and (ii)\nproactively correct risky outputs to safe ones, all in a model-agnostic manner\nso the same guardrail can be wrapped around any AI model. We also offer a\npractical training recipe for computing such guardrails at scale via\nsafety-critical reinforcement learning. Our experiments in simulated driving\nand e-commerce settings demonstrate that control-theoretic guardrails can\nreliably steer LLM agents clear of catastrophic outcomes (from collisions to\nbankruptcy) while preserving task performance, offering a principled dynamic\nalternative to today's flag-and-block guardrails.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u63a7\u5236\u7406\u8bba\u7684\u5b89\u5168\u62a4\u680f\u65b9\u6cd5\uff0c\u7528\u4e8e\u9884\u9632AI\u4ee3\u7406\u7684\u4e0b\u6e38\u5371\u5bb3\uff0c\u901a\u8fc7\u5b9e\u65f6\u76d1\u63a7\u548c\u4e3b\u52a8\u4fee\u6b63\u98ce\u9669\u8f93\u51fa\u6765\u66ff\u4ee3\u4f20\u7edf\u7684\u5206\u7c7b\u963b\u65ad\u673a\u5236\u3002", "motivation": "\u4f20\u7edfAI\u5b89\u5168\u62a4\u680f\u4f9d\u8d56\u8f93\u51fa\u5206\u7c7b\u548c\u4eba\u5de5\u6807\u51c6\uff0c\u5bf9\u65b0\u5371\u9669\u60c5\u51b5\u8106\u5f31\uff0c\u4e14\u68c0\u6d4b\u5230\u4e0d\u5b89\u5168\u65f6\u53ea\u80fd\u62d2\u7edd\u884c\u52a8\uff0c\u8fd9\u672c\u8eab\u53ef\u80fd\u4e0d\u5b89\u5168\u3002\u9700\u8981\u4e00\u79cd\u80fd\u4e3b\u52a8\u9884\u9632\u4e0b\u6e38\u5371\u5bb3\u7684\u52a8\u6001\u5b89\u5168\u65b9\u6cd5\u3002", "method": "\u5c06AI\u4ee3\u7406\u5b89\u5168\u5efa\u6a21\u4e3a\u5e8f\u5217\u51b3\u7b56\u95ee\u9898\uff0c\u57fa\u4e8e\u5b89\u5168\u5173\u952e\u63a7\u5236\u7406\u8bba\u5728AI\u6a21\u578b\u7684\u6f5c\u5728\u8868\u793a\u7a7a\u95f4\u4e2d\u6784\u5efa\u9884\u6d4b\u6027\u62a4\u680f\uff0c\u901a\u8fc7\u5b89\u5168\u5173\u952e\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u89c4\u6a21\u5316\u8bad\u7ec3\u3002", "result": "\u5728\u6a21\u62df\u9a7e\u9a76\u548c\u7535\u5b50\u5546\u52a1\u573a\u666f\u4e2d\uff0c\u63a7\u5236\u7406\u8bba\u62a4\u680f\u80fd\u53ef\u9760\u5730\u5f15\u5bfcLLM\u4ee3\u7406\u907f\u514d\u707e\u96be\u6027\u540e\u679c\uff08\u4ece\u78b0\u649e\u5230\u7834\u4ea7\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\u3002", "conclusion": "\u63a7\u5236\u7406\u8bba\u62a4\u680f\u4e3a\u5f53\u524d\u6807\u8bb0\u963b\u65ad\u5f0f\u62a4\u680f\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u7684\u52a8\u6001\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u591f\u4e3b\u52a8\u4fee\u6b63\u98ce\u9669\u8f93\u51fa\u4e3a\u5b89\u5168\u8f93\u51fa\uff0c\u4e14\u6a21\u578b\u65e0\u5173\u3002"}}
{"id": "2510.13744", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.13744", "abs": "https://arxiv.org/abs/2510.13744", "authors": ["Shrey Pandit", "Austin Xu", "Xuan-Phi Nguyen", "Yifei Ming", "Caiming Xiong", "Shafiq Joty"], "title": "Hard2Verify: A Step-Level Verification Benchmark for Open-Ended Frontier Math", "comment": "21 pages, 8 figures, 5 tables", "summary": "Large language model (LLM)-based reasoning systems have recently achieved\ngold medal-level performance in the IMO 2025 competition, writing mathematical\nproofs where, to receive full credit, each step must be not only correct but\nalso sufficiently supported. To train LLM-based reasoners in such challenging,\nopen-ended settings, strong verifiers capable of catching step-level mistakes\nare necessary prerequisites. We introduce Hard2Verify, a human-annotated,\nstep-level verification benchmark produced with over 500 hours of human labor.\nHard2Verify is designed to rigorously assess step-level verifiers at the\nfrontier: Verifiers must provide step-level annotations or identify the first\nerror in responses generated by frontier LLMs for very recent, challenging, and\nopen-ended math questions. We evaluate 29 generative critics and process reward\nmodels, demonstrating that, beyond a few standouts, open-source verifiers lag\nclosed source models. We subsequently analyze what drives poor performance in\nstep-level verification, the impacts of scaling verifier compute, as well as\nfundamental questions such as self-verification and verification-generation\ndynamics.", "AI": {"tldr": "\u63d0\u51fa\u4e86Hard2Verify\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u6570\u5b66\u8bc1\u660e\u4e2d\u7684\u6b65\u9aa4\u7ea7\u9a8c\u8bc1\u5668\u6027\u80fd\uff0c\u53d1\u73b0\u5f00\u6e90\u9a8c\u8bc1\u5668\u666e\u904d\u843d\u540e\u4e8e\u95ed\u6e90\u6a21\u578b\u3002", "motivation": "\u5728LLM\u63a8\u7406\u7cfb\u7edf\u9700\u8981\u7cbe\u786e\u6b65\u9aa4\u9a8c\u8bc1\u7684\u80cc\u666f\u4e0b\uff0c\u9700\u8981\u5f3a\u5927\u7684\u9a8c\u8bc1\u5668\u6765\u6355\u6349\u6b65\u9aa4\u7ea7\u9519\u8bef\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u5408\u9002\u7684\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "\u6784\u5efa\u4e86\u4eba\u5de5\u6807\u6ce8\u7684\u6b65\u9aa4\u7ea7\u9a8c\u8bc1\u57fa\u51c6Hard2Verify\uff0c\u5305\u542b500\u591a\u5c0f\u65f6\u4eba\u5de5\u52b3\u52a8\uff0c\u8bc4\u4f30\u4e8629\u4e2a\u751f\u6210\u5f0f\u6279\u8bc4\u5668\u548c\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u3002", "result": "\u9664\u4e86\u5c11\u6570\u4f18\u79c0\u6a21\u578b\u5916\uff0c\u5f00\u6e90\u9a8c\u8bc1\u5668\u5728\u6b65\u9aa4\u7ea7\u9a8c\u8bc1\u4efb\u52a1\u4e0a\u660e\u663e\u843d\u540e\u4e8e\u95ed\u6e90\u6a21\u578b\u3002", "conclusion": "\u6b65\u9aa4\u7ea7\u9a8c\u8bc1\u662fLLM\u63a8\u7406\u7cfb\u7edf\u7684\u5173\u952e\u74f6\u9888\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u9a8c\u8bc1\u5668\u8ba1\u7b97\u89c4\u6a21\u3001\u81ea\u9a8c\u8bc1\u548c\u9a8c\u8bc1-\u751f\u6210\u52a8\u6001\u7b49\u57fa\u7840\u95ee\u9898\u3002"}}
