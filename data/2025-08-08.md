<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 14]
- [cs.CR](#cs.CR) [Total: 8]
- [cs.AI](#cs.AI) [Total: 33]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Automated File-Level Logging Generation for Machine Learning Applications using LLMs: A Case Study using GPT-4o Mini](https://arxiv.org/abs/2508.04820)
*Mayra Sofia Ruiz Rodriguez,SayedHassan Khatoonabadi,Emad Shihab*

Main category: cs.SE

TL;DR: 研究评估了GPT-4o mini在机器学习项目中生成文件级日志的能力，发现其在63.91%的情况下与人类日志位置一致，但存在82.66%的过度日志问题。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型（LLMs）在文件级日志生成中的潜力，特别是在机器学习应用中，以提高系统可靠性。

Method: 收集171个ML仓库的4,073个Python文件，移除原始日志后使用LLM生成日志，并评估日志位置、级别、变量和文本质量。

Result: LLM在63.91%的情况下与人类日志位置一致，但存在82.66%的过度日志问题，且在大型代码块和项目特定日志规范中存在挑战。

Conclusion: LLM在文件级日志生成中显示潜力，但过度日志和规范对齐问题仍需解决。

Abstract: Logging is essential in software development, helping developers monitor
system behavior and aiding in debugging applications. Given the ability of
large language models (LLMs) to generate natural language and code, researchers
are exploring their potential to generate log statements. However, prior work
focuses on evaluating logs introduced in code functions, leaving file-level log
generation underexplored -- especially in machine learning (ML) applications,
where comprehensive logging can enhance reliability. In this study, we evaluate
the capacity of GPT-4o mini as a case study to generate log statements for ML
projects at file level. We gathered a set of 171 ML repositories containing
4,073 Python files with at least one log statement. We identified and removed
the original logs from the files, prompted the LLM to generate logs for them,
and evaluated both the position of the logs and log level, variables, and text
quality of the generated logs compared to human-written logs. In addition, we
manually analyzed a representative sample of generated logs to identify common
patterns and challenges. We find that the LLM introduces logs in the same place
as humans in 63.91% of cases, but at the cost of a high overlogging rate of
82.66%. Furthermore, our manual analysis reveals challenges for file-level
logging, which shows overlogging at the beginning or end of a function,
difficulty logging within large code blocks, and misalignment with
project-specific logging conventions. While the LLM shows promise for
generating logs for complete files, these limitations remain to be addressed
for practical implementation.

</details>


### [2] [Automated Bug Frame Retrieval from Gameplay Videos Using Vision-Language Models](https://arxiv.org/abs/2508.04895)
*Wentao Lu,Alexander Senchenko,Abram Hindle,Cor-Paul Bezemer*

Main category: cs.SE

TL;DR: 论文提出了一种自动化流程，将游戏bug报告中的视频简化为最能匹配bug描述的单帧图像，显著减少了开发者的手动工作。


<details>
  <summary>Details</summary>
Motivation: 现代游戏工作室快速发布新版本和补丁，生成大量包含游戏视频的bug报告，手动审核这些视频耗时且难以扩展。

Method: 使用FFmpeg提取关键帧，再通过视觉-语言模型（GPT-4o）评估并选择最匹配bug描述的代表性帧。

Result: 在真实游戏视频和JIRA bug报告上测试，F1得分为0.79，准确率为0.89，效果因bug类别而异。

Conclusion: 该方法显著减少了手动审核时间，提升了游戏开发中bug分类和回归检查的效率。

Abstract: Modern game studios deliver new builds and patches at a rapid pace,
generating thousands of bug reports, many of which embed gameplay videos. To
verify and triage these bug reports, developers must watch the submitted
videos. This manual review is labour-intensive, slow, and hard to scale. In
this paper, we introduce an automated pipeline that reduces each video to a
single frame that best matches the reported bug description, giving developers
instant visual evidence that pinpoints the bug.
  Our pipeline begins with FFmpeg for keyframe extraction, reducing each video
to a median of just 1.90% of its original frames while still capturing bug
moments in 98.79 of cases. These keyframes are then evaluated by a
vision--language model (GPT-4o), which ranks them based on how well they match
the textual bug description and selects the most representative frame. We
evaluated this approach using real-world developer-submitted gameplay videos
and JIRA bug reports from a popular First-Person Shooter (FPS) game. The
pipeline achieves an overall F1 score of 0.79 and Accuracy of 0.89 for the
top-1 retrieved frame. Performance is highest for the Lighting & Shadow (F1 =
0.94), Physics & Collision (0.86), and UI & HUD (0.83) bug categories, and
lowest for Animation & VFX (0.51).
  By replacing video viewing with an immediately informative image, our
approach dramatically reduces manual effort and speeds up triage and regression
checks, offering practical benefits to quality assurance (QA) teams and
developers across the game industry.

</details>


### [3] [Charting Uncertain Waters: A Socio-Technical Framework for Navigating GenAI's Impact on Open Source Communities](https://arxiv.org/abs/2508.04921)
*Zixuan Feng,Reed Milewicz,Emerson Murphy-Hill,Tyler Menezes,Alexander Serebrenik,Igor Steinmacher,Anita Sarma*

Main category: cs.SE

TL;DR: 论文探讨了生成式AI对开源软件社区的潜在影响，提出了一个基于社会技术框架的分析方法，以帮助社区应对挑战并抓住机遇。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的快速发展为开源软件社区带来了不确定性和复杂性，可能威胁其协作精神。研究旨在通过框架分析，帮助社区主动应对这些变化。

Method: 采用基于McLuhan Tetrad的社会技术框架，通过情景驱动的概念探索，分析生成式AI对软件实践、文档、社区参与和治理四个领域的影响。

Result: 研究揭示了生成式AI带来的风险和机遇，为开源社区提供了应对技术变革的指导。

Conclusion: 通过采用这一框架，开源社区领导者和研究者可以主动塑造生态系统的未来，而非被动应对技术颠覆。

Abstract: Open Source Software communities face a wave of uncertainty as Generative AI
rapidly transforms how software is created, maintained, and governed. Without
clear frameworks, communities risk being overwhelmed by the complexity and
ambiguity introduced by GenAI, threatening the collaborative ethos that
underpins OSS. We conduct a scenario-driven, conceptual exploration using a
socio-technical framework inspired by McLuhan's Tetrad to surface both risks
and opportunities for community resilience amid GenAI-driven disruption of OSS
development across four domains: software practices, documentation, community
engagement, and governance. By adopting this lens, OSS leaders and researchers
can proactively shape the future of their ecosystems, rather than simply
reacting to technological upheaval.

</details>


### [4] [Taxonomy of Faults in Attention-Based Neural Networks](https://arxiv.org/abs/2508.04925)
*Sigma Jahan,Saurabh Singh Rajput,Tushar Sharma,Mohammad Masudur Rahman*

Main category: cs.SE

TL;DR: 该论文首次对基于注意力的神经网络（ABNNs）中的故障进行了全面实证研究，提出了七种注意力特有的故障类别，并提供了诊断启发式方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习故障分类法未能充分捕捉注意力机制引入的独特故障，导致缺乏可操作的诊断指导。

Method: 通过系统分析来自96个项目、555个真实故障的数据，开发了新的注意力特有故障分类法。

Result: 超过一半的ABNN故障源于注意力架构特有的机制，研究还识别了四种诊断启发式方法，解释了33.0%的注意力特有故障。

Conclusion: 该研究填补了注意力机制故障诊断的空白，为基于注意力的模型提供了首个系统性诊断指导。

Abstract: Attention mechanisms are at the core of modern neural architectures, powering
systems ranging from ChatGPT to autonomous vehicles and driving a major
economic impact. However, high-profile failures, such as ChatGPT's nonsensical
outputs or Google's suspension of Gemini's image generation due to attention
weight errors, highlight a critical gap: existing deep learning fault
taxonomies might not adequately capture the unique failures introduced by
attention mechanisms. This gap leaves practitioners without actionable
diagnostic guidance. To address this gap, we present the first comprehensive
empirical study of faults in attention-based neural networks (ABNNs). Our work
is based on a systematic analysis of 555 real-world faults collected from 96
projects across ten frameworks, including GitHub, Hugging Face, and Stack
Overflow. Through our analysis, we develop a novel taxonomy comprising seven
attention-specific fault categories, not captured by existing work. Our results
show that over half of the ABNN faults arise from mechanisms unique to
attention architectures. We further analyze the root causes and manifestations
of these faults through various symptoms. Finally, by analyzing symptom-root
cause associations, we identify four evidence-based diagnostic heuristics that
explain 33.0% of attention-specific faults, offering the first systematic
diagnostic guidance for attention-based models.

</details>


### [5] [Generative AI for Object-Oriented Programming: Writing the Right Code and Reasoning the Right Logic](https://arxiv.org/abs/2508.05005)
*Gang Xu,Airong Wang,Yushan Pan*

Main category: cs.SE

TL;DR: 论文探讨了大型语言模型（LLMs）与面向对象编程（OOP）的结合，提出了如何利用LLMs提升OOP学习和代码编写的效果，并评估相关AI工具。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs与OOP的结合研究不足，缺乏对其在编程任务中提升效果的理解和评估方法。

Method: 从程序员、新手和经验丰富的程序员等关键利益相关者的视角出发，识别编码工作流中LLMs可提供显著帮助的关键节点，并提出增强逻辑推理和代码编写的方法。

Result: 提出了LLMs在OOP任务中的潜在应用场景和优化方法。

Conclusion: LLMs与OOP的结合有望显著提升编程体验，但仍需进一步研究和实践验证。

Abstract: We find ourselves in the midst of an explosion in artificial intelligence
research, particularly with large language models (LLMs). These models have
diverse applications spanning finance, commonsense knowledge graphs, medicine,
and visual analysis. In the world of Object-Oriented Programming(OOP), a robust
body of knowledge and methods has been developed for managing complex tasks
through object-oriented thinking. However, the intersection of LLMs with OOP
remains an underexplored territory. Empirically, we currently possess limited
understanding of how LLMs can enhance the effectiveness of OOP learning and
code writing, as well as how we can evaluate such AI-powered tools. Our work
aims to address this gap by presenting a vision from the perspectives of key
stakeholders involved in an OOP task: programmers, mariners, and experienced
programmers. We identify critical junctures within typical coding workflows
where the integration of LLMs can offer significant benefits. Furthermore, we
propose ways to augment existing logical reasoning and code writing, ultimately
enhancing the programming experience.

</details>


### [6] [An ML-based Approach to Predicting Software Change Dependencies: Insights from an Empirical Study on OpenStack](https://arxiv.org/abs/2508.05034)
*Arabat,Ali,Sayagh,Mohammed,Hassine,Jameleddine*

Main category: cs.SE

TL;DR: 论文研究了大型软件系统中变更依赖管理的挑战，提出了一种半自动化的机器学习方法，用于预测和识别依赖关系，以减少开发者在代码审查阶段的延迟。


<details>
  <summary>Details</summary>
Motivation: 随着软件系统复杂性的增加，准确识别和管理变更依赖变得至关重要，尤其是在多团队协作的大型系统中，依赖关系可能导致构建失败和部署问题。

Method: 通过初步研究OpenStack系统中的依赖管理问题，提出了一种结合两个机器学习模型的半自动化方法：一个预测变更间的依赖可能性，另一个识别具体的依赖对。

Result: 模型表现良好，平均AUC分数分别为79.33%和91.89%，Brier分数为0.11和0.014。第二个模型在top-k召回率上表现优异，但top-k精确度有待提升。

Conclusion: 提出的方法能有效帮助开发者提前识别依赖关系，减少代码审查阶段的延迟，提升开发效率。

Abstract: As software systems grow in complexity, accurately identifying and managing
dependencies among changes becomes increasingly critical. For instance, a
change that leverages a function must depend on the change that introduces it.
Establishing such dependencies allows CI/CD pipelines to build and orchestrate
changes effectively, preventing build failures and incomplete feature
deployments. In modern software systems, dependencies often span multiple
components across teams, creating challenges for development and deployment.
They serve various purposes, from enabling new features to managing
configurations, and can even involve traditionally independent changes like
documentation updates. To address these challenges, we conducted a preliminary
study on dependency management in OpenStack, a large-scale software system. Our
study revealed that a substantial portion of software changes in OpenStack over
the past 10 years are interdependent. Surprisingly, 51.08% of these
dependencies are identified during the code review phase-after a median delay
of 5.06 hours-rather than at the time of change creation. Developers often
spend a median of 57.12 hours identifying dependencies, searching among a
median of 463 other changes. To help developers proactively identify
dependencies, we propose a semi-automated approach that leverages two ML
models. The first model predicts the likelihood of dependencies among changes,
while the second identifies the exact pairs of dependent changes. Our proposed
models demonstrate strong performance, achieving average AUC scores of 79.33%
and 91.89%, and Brier scores of 0.11 and 0.014, respectively. Indeed, the
second model has a good top-k recall across all types of pairs, while the top-k
precision has room for improvement.

</details>


### [7] [LadyBug: A GitHub Bot for UI-Enhanced Bug Localization in Mobile Apps](https://arxiv.org/abs/2508.05085)
*Junayed Mahmud,James Chen,Terry Achille,Camilo Alvarez-Velez,Darren Dean Bansil,Patrick Ijieh,Samar Karanch,Nadeeshan De Silva,Oscar Chaparro,Andrian Marcus,Kevin Moran*

Main category: cs.SE

TL;DR: LadyBug是一个GitHub机器人，通过结合UI交互信息和文本检索，自动定位Android应用中的bug。


<details>
  <summary>Details</summary>
Motivation: 提高Android应用中bug定位的准确性和效率，结合文本和UI信息。

Method: 连接GitHub仓库，通过问题追踪器触发，开发者上传bug重现轨迹，结合文本和UI信息检索相关文件。

Result: 在包含80个bug报告的基准测试中，LadyBug优于纯文本检索方法，UI信息显著提升定位准确性。

Conclusion: LadyBug是一个有效的开源工具，结合UI和文本信息显著提升bug定位效果。

Abstract: This paper introduces LadyBug, a GitHub bot that automatically localizes bugs
for Android apps by combining UI interaction information with text retrieval.
LadyBug connects to an Android app's GitHub repository, and is triggered when a
bug is reported in the corresponding issue tracker. Developers can then record
a reproduction trace for the bug on a device or emulator and upload the trace
to LadyBug via the GitHub issue tracker. This enables LadyBug to utilize both
the text from the original bug description, and UI information from the
reproduction trace to accurately retrieve a ranked list of files from the
project that most likely contain the reported bug.
  We empirically evaluated LadyBug using an automated testing pipeline and
benchmark called RedWing that contains 80 fully-localized and reproducible bug
reports from 39 Android apps. Our results illustrate that LadyBug outperforms
text-retrieval-based baselines and that the utilization of UI information leads
to a substantial increase in localization accuracy. LadyBug is an open-source
tool, available at https://github.com/LadyBugML/ladybug.
  A video showing the capabilities of Ladybug can be viewed here:
https://youtu.be/hI3tzbRK0Cw

</details>


### [8] [Posterior-GRPO: Rewarding Reasoning Processes in Code Generation](https://arxiv.org/abs/2508.05170)
*Lishui Fan,Yu Zhang,Mouxiang Chen,Zhongxin Liu*

Main category: cs.SE

TL;DR: 论文提出了一种统一框架，结合推理过程质量优化强化学习（RL）的代码生成，通过LCB-RB基准和OD-based奖励模型训练方法提升推理质量，并引入P-GRPO方法避免奖励欺骗，最终在代码生成任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前基于测试结果的RL方法忽视了中间推理过程的质量，且直接监督推理易导致奖励欺骗。

Method: 开发LCB-RB基准评估推理质量，提出OD-based奖励模型训练方法，并设计P-GRPO RL方法选择性奖励成功任务的推理过程。

Result: 7B参数模型在代码生成任务中超越基线4.5%，性能接近GPT-4-Turbo，并成功推广至数学任务。

Conclusion: 该框架有效结合推理质量与任务成功，显著提升RL在代码生成中的表现，并具有广泛适用性。

Abstract: Reinforcement learning (RL) has significantly advanced code generation for
large language models (LLMs). However, current paradigms rely on outcome-based
rewards from test cases, neglecting the quality of the intermediate reasoning
process. While supervising the reasoning process directly is a promising
direction, it is highly susceptible to reward hacking, where the policy model
learns to exploit the reasoning reward signal without improving final outcomes.
To address this, we introduce a unified framework that can effectively
incorporate the quality of the reasoning process during RL. First, to enable
reasoning evaluation, we develop LCB-RB, a benchmark comprising preference
pairs of superior and inferior reasoning processes. Second, to accurately score
reasoning quality, we introduce an Optimized-Degraded based (OD-based) method
for reward model training. This method generates high-quality preference pairs
by systematically optimizing and degrading initial reasoning paths along
curated dimensions of reasoning quality, such as factual accuracy, logical
rigor, and coherence. A 7B parameter reward model with this method achieves
state-of-the-art (SOTA) performance on LCB-RB and generalizes well to other
benchmarks. Finally, we introduce Posterior-GRPO (P-GRPO), a novel RL method
that conditions process-based rewards on task success. By selectively applying
rewards to the reasoning processes of only successful outcomes, P-GRPO
effectively mitigates reward hacking and aligns the model's internal reasoning
with final code correctness. A 7B parameter model with P-GRPO achieves superior
performance across diverse code generation tasks, outperforming outcome-only
baselines by 4.5%, achieving comparable performance to GPT-4-Turbo. We further
demonstrate the generalizability of our approach by extending it to
mathematical tasks. Our models, dataset, and code are publicly available.

</details>


### [9] [AI-assisted JSON Schema Creation and Mapping](https://arxiv.org/abs/2508.05192)
*Felix Neubauer,Jürgen Pleiss,Benjamin Uekermann*

Main category: cs.SE

TL;DR: 提出了一种结合大语言模型（LLMs）和确定性技术的混合方法，用于通过自然语言输入生成和修改JSON Schema，并实现数据集成。该方法集成到开源工具MetaConfigurator中，降低了非专家用户的结构化数据建模门槛。


<details>
  <summary>Details</summary>
Motivation: 许多领域缺乏标准化模型，且创建模型对非专家用户来说存在显著障碍。

Method: 结合LLMs和确定性技术，支持自然语言输入的JSON Schema创建、修改和映射，并通过MetaConfigurator工具实现可视化编辑和验证。

Result: 在化学领域的应用示例中验证了方法的可行性，显著降低了非专家用户的数据建模和集成门槛。

Conclusion: 通过自然语言交互与确定性保障的结合，为非专家用户提供了更便捷的结构化数据建模和集成解决方案。

Abstract: Model-Driven Engineering (MDE) places models at the core of system and data
engineering processes. In the context of research data, these models are
typically expressed as schemas that define the structure and semantics of
datasets. However, many domains still lack standardized models, and creating
them remains a significant barrier, especially for non-experts. We present a
hybrid approach that combines large language models (LLMs) with deterministic
techniques to enable JSON Schema creation, modification, and schema mapping
based on natural language inputs by the user. These capabilities are integrated
into the open-source tool MetaConfigurator, which already provides visual model
editing, validation, code generation, and form generation from models. For data
integration, we generate schema mappings from heterogeneous JSON, CSV, XML, and
YAML data using LLMs, while ensuring scalability and reliability through
deterministic execution of generated mapping rules. The applicability of our
work is demonstrated in an application example in the field of chemistry. By
combining natural language interaction with deterministic safeguards, this work
significantly lowers the barrier to structured data modeling and data
integration for non-experts.

</details>


### [10] [STEPWISE-CODEX-Bench: Evaluating Complex Multi-Function Comprehension and Fine-Grained Execution Reasoning](https://arxiv.org/abs/2508.05193)
*Kaiwen Yan,Yuhang Chang,Zirui Guo,Yaling Mou,Jiang Ming,Jingwei Sun*

Main category: cs.SE

TL;DR: SX-Bench是一个新的代码理解和推理基准，专注于复杂多函数场景和细粒度执行推理，填补了现有基准的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准（如HumanEval和MBPP）主要评估功能正确性，而推理基准（如CRUXEVAL）限于单函数低复杂度场景，导致高级模型得分饱和，缺乏区分能力。

Method: 提出SX-Bench，通过多子函数协作任务（如链式调用、嵌套循环）评估整体控制和数据流建模，以“计算步骤”为最小执行单元，要求模型预测推理任务的总步骤数。

Result: 在20多个主流模型（包括14个推理增强模型）上评估，SX-Bench显示出高区分度：即使是OpenAI-O3在Hard-Reasoning任务上准确率仅为78.37%。

Conclusion: SX-Bench将代码评估从“单函数验证”推进到“多函数动态推理”，为深入评估高级代码智能模型提供了关键工具。

Abstract: In recent years, large language models (LLMs) have made significant progress
in code intelligence, yet systematically evaluating their code understanding
and reasoning abilities remains challenging. Mainstream benchmarks such as
HumanEval and MBPP primarily assess functional correctness, while reasoning
benchmarks like CRUXEVAL are limited to single-function, low-complexity
scenarios. As a result, advanced models achieve nearly saturated scores,
limiting their discriminative power. To address this, we present
STEPWISE-CODEX-Bench (SX-Bench), a novel benchmark designed for complex
multi-function understanding and fine-grained execution reasoning. SX-Bench
features tasks involving collaboration among multiple sub-functions (e.g.,
chained calls, nested loops), shifting evaluation towards overall control and
data flow modeling. It defines "computation steps" as the minimal execution
unit and requires models to predict the total number of steps in reasoning
tasks, thereby assessing a model's in-depth understanding of dynamic execution
beyond simple I/O matching. Evaluation on over 20 mainstream models (including
14 reasoning-enhanced models) demonstrates that SX-Bench is highly
discriminative: even the state-of-the-art OpenAI-O3 achieves only 78.37 percent
accuracy on Hard-Reasoning tasks, much lower than its saturated scores on
previous benchmarks, thereby revealing bottlenecks in complex and fine-grained
reasoning. We also release an automated pipeline combining program synthesis,
symbolic execution, and LLM-aided validation for efficient benchmark generation
and quality assurance. SX-Bench advances code evaluation from "single-function
verification" to "multi-function dynamic reasoning," providing a key tool for
the in-depth assessment of advanced code intelligence models.

</details>


### [11] [EvoGraph: Hybrid Directed Graph Evolution toward Software 3.0](https://arxiv.org/abs/2508.05199)
*Igor Costa,Christopher Baran*

Main category: cs.SE

TL;DR: EvoGraph是一个框架，通过类型化有向图和专用小语言模型（SLMs）实现软件系统的自我进化，包括源代码、构建管道、文档和工单。


<details>
  <summary>Details</summary>
Motivation: 解决传统软件现代化中的问题，如隐式契约、性能保持和集成演化，推动软件系统向持续自适应（Software 3.0）发展。

Method: 使用类型化有向图表示所有工件，应用基于SLMs的学习突变算子，并通过多目标适应度选择幸存者。

Result: 在三个基准测试中，修复83%的安全漏洞，COBOL转Java功能等效性达93%，文档新鲜度保持在两分钟内，延迟降低40%，功能交付时间缩短7倍。

Conclusion: EvoGraph为软件现代化提供了一种高效、可控的路径，展示了持续自适应系统的可行性。

Abstract: We introduce **EvoGraph**, a framework that enables software systems to
evolve their own source code, build pipelines, documentation, and tickets.
EvoGraph represents every artefact in a typed directed graph, applies learned
mutation operators driven by specialized small language models (SLMs), and
selects survivors with a multi-objective fitness. On three benchmarks, EvoGraph
fixes 83% of known security vulnerabilities, translates COBOL to Java with 93%
functional equivalence (test verified), and maintains documentation freshness
within two minutes. Experiments show a 40% latency reduction and a sevenfold
drop in feature lead time compared with strong baselines. We extend our
approach to **evoGraph**, leveraging language-specific SLMs for modernizing
.NET, Lisp, CGI, ColdFusion, legacy Python, and C codebases, achieving 82-96%
semantic equivalence across languages while reducing computational costs by 90%
compared to large language models. EvoGraph's design responds to empirical
failure modes in legacy modernization, such as implicit contracts, performance
preservation, and integration evolution. Our results suggest a practical path
toward Software 3.0, where systems adapt continuously yet remain under
measurable control.

</details>


### [12] [A Conceptual Model and Methodology for Sustainability-aware, IoT-enhanced Business Processes](https://arxiv.org/abs/2508.05301)
*Victoria Torres Bosch,Ronny Seiger,Manuela Albert Albiol,Antoni Mestre Gascon,Pedro Jose Valderas Aranda*

Main category: cs.SE

TL;DR: 本文提出了一种概念模型和方法论，旨在利用物联网（IoT）技术衡量和改进业务流程（BPs）的可持续性，超越环境维度，实现更全面的可持续发展。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注环境可持续性，但实现全面可持续性需要更系统的方法，结合IoT技术以支持业务流程的可持续性改进。

Method: 提出概念模型和结构化方法论，通过IoT设备支持可持续性，并指导业务流程的系统性分析和改进。

Result: 通过旅游和医疗领域的案例研究，验证了模型和方法论的有效性。

Conclusion: IoT技术为业务流程的可持续性改进提供了系统化支持，具有广泛的应用潜力。

Abstract: The real-time data collection and automation capabilities offered by the
Internet of Things (IoT) are revolutionizing and transforming Business
Processes (BPs) into IoT-enhanced BPs, showing high potential for improving
sustainability. Although already studied in Business Process Management (BPM),
sustainability research has primarily focused on environmental concerns.
However, achieving a holistic and lasting impact requires a systematic approach
to address sustainability beyond the environmental dimension. This work
proposes a conceptual model and a structured methodology with the goal of
analyzing the potential of IoT to measure and improve the sustainability of
BPs. The conceptual model formally represents key sustainability concepts,
linking BPM and IoT by highlighting how IoT devices support and contribute to
sustainability. The methodology guides the systematic analysis of existing BPs,
identifies opportunities, and implements sustainability-aware, IoT-enhanced
BPs. The approach is illustrated through a running example from the tourism
domain and a case study in healthcare.

</details>


### [13] [Evaluating the Use of LLMs for Documentation to Code Traceability](https://arxiv.org/abs/2506.16440)
*Ebube Alor,SayedHassan Khatoonabadi,Emad Shihab*

Main category: cs.SE

TL;DR: 论文评估了大型语言模型（LLMs）在文档与代码间建立追溯链接的能力，发现其表现优于基线方法，但存在局限性，需结合人工设计工具。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在自动化文档与代码追溯中的潜力，填补现有研究的空白。

Method: 使用Claude 3.5 Sonnet、GPT-4o和o3-mini等LLMs，通过系统性实验评估其在追溯链接识别、关系解释和多步链重建中的表现。

Result: 最佳LLM的F1分数达79.4%和80.4%，关系解释完全正确率为42.9%-71.1%，多步链重建中端点准确率高。

Conclusion: LLMs是强大的追溯发现助手，但需结合人工设计工具，并针对特定错误模式进一步研究。

Abstract: Large Language Models (LLMs) offer new potential for automating
documentation-to-code traceability, yet their capabilities remain
underexplored. We present a comprehensive evaluation of LLMs (Claude 3.5
Sonnet, GPT-4o, and o3-mini) in establishing trace links between various
software documentation (including API references and user guides) and source
code. We create two novel datasets from two open-source projects (Unity Catalog
and Crawl4AI). Through systematic experiments, we assess three key
capabilities: (1) trace link identification accuracy, (2) relationship
explanation quality, and (3) multi-step chain reconstruction. Results show that
the best-performing LLM achieves F1-scores of 79.4% and 80.4% across the two
datasets, substantially outperforming our baselines (TF-IDF, BM25, and
CodeBERT). While fully correct relationship explanations range from 42.9% to
71.1%, partial accuracy exceeds 97%, indicating that fundamental connections
are rarely missed. For multi-step chains, LLMs maintain high endpoint accuracy
but vary in capturing precise intermediate links. Error analysis reveals that
many false positives stem from naming-based assumptions, phantom links, or
overgeneralization of architectural patterns. We demonstrate that task-framing,
such as a one-to-many matching strategy, is critical for performance. These
findings position LLMs as powerful assistants for trace discovery, but their
limitations could necessitate human-in-the-loop tool design and highlight
specific error patterns for future research.

</details>


### [14] [How Robust are LLM-Generated Library Imports? An Empirical Study using Stack Overflow](https://arxiv.org/abs/2507.10818)
*Jasmine Latendresse,SayedHassan Khatoonabadi,Emad Shihab*

Main category: cs.SE

TL;DR: 论文研究了六种先进LLM在解决Python问题时推荐的库，发现它们偏好第三方库，但存在可用性差距。


<details>
  <summary>Details</summary>
Motivation: 理解LLM如何推荐库对代码功能、安全和维护至关重要。

Method: 通过Stack Overflow的真实Python问题测试六种LLM，分析其推荐的库类型和特性。

Result: LLM主要推荐成熟、流行的第三方库，但4.6%的库因命名问题无法自动解析，仅两种模型提供安装指导。

Conclusion: 研究为开发者和研究者提供了改进LLM生成代码可靠性和可用性的方向。

Abstract: Software libraries are central to the functionality, security, and
maintainability of modern code. As developers increasingly turn to Large
Language Models (LLMs) to assist with programming tasks, understanding how
these models recommend libraries is essential. In this paper, we conduct an
empirical study of six state-of-the-art LLMs, both proprietary and open-source,
by prompting them to solve real-world Python problems sourced from Stack
Overflow. We analyze the types of libraries they import, the characteristics of
those libraries, and the extent to which the recommendations are usable out of
the box. Our results show that LLMs predominantly favour third-party libraries
over standard ones, and often recommend mature, popular, and permissively
licensed dependencies. However, we also identify gaps in usability: 4.6% of the
libraries could not be resolved automatically due to structural mismatches
between import names and installable packages, and only two models (out of six)
provided installation guidance. While the generated code is technically valid,
the lack of contextual support places the burden of manually resolving
dependencies on the user. Our findings offer actionable insights for both
developers and researchers, and highlight opportunities to improve the
reliability and usability of LLM-generated code in the context of software
dependencies.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [15] [Adversarial Attacks and Defenses on Graph-aware Large Language Models (LLMs)](https://arxiv.org/abs/2508.04894)
*Iyiola E. Olatunji,Franziska Boenisch,Jing Xu,Adam Dziedzic*

Main category: cs.CR

TL;DR: 该论文首次探讨了图感知大语言模型（LLMs）在对抗攻击下的脆弱性，并提出了防御框架GALGUARD。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs与图数据的结合提升了任务性能，但其对抗攻击的鲁棒性尚未被研究。

Method: 利用现有的图模型对抗攻击方法（如毒化和规避攻击）测试LLAGA和GRAPHPROMPTER模型，并发现LLAGA的新攻击面。

Result: 研究发现LLAGA的节点序列模板易受攻击，GRAPHPROMPTER的GNN编码器更鲁棒，但两者均对特征扰动攻击敏感。

Conclusion: 提出了GALGUARD防御框架，结合LLM特征校正和GNN防御，以增强模型鲁棒性。

Abstract: Large Language Models (LLMs) are increasingly integrated with
graph-structured data for tasks like node classification, a domain
traditionally dominated by Graph Neural Networks (GNNs). While this integration
leverages rich relational information to improve task performance, their
robustness against adversarial attacks remains unexplored. We take the first
step to explore the vulnerabilities of graph-aware LLMs by leveraging existing
adversarial attack methods tailored for graph-based models, including those for
poisoning (training-time attacks) and evasion (test-time attacks), on two
representative models, LLAGA (Chen et al. 2024) and GRAPHPROMPTER (Liu et al.
2024). Additionally, we discover a new attack surface for LLAGA where an
attacker can inject malicious nodes as placeholders into the node sequence
template to severely degrade its performance. Our systematic analysis reveals
that certain design choices in graph encoding can enhance attack success, with
specific findings that: (1) the node sequence template in LLAGA increases its
vulnerability; (2) the GNN encoder used in GRAPHPROMPTER demonstrates greater
robustness; and (3) both approaches remain susceptible to imperceptible feature
perturbation attacks. Finally, we propose an end-to-end defense framework
GALGUARD, that combines an LLM-based feature correction module to mitigate
feature-level perturbations and adapted GNN defenses to protect against
structural attacks.

</details>


### [16] [On the Classical Hardness of the Semidirect Discrete Logarithm Problem in Finite Groups](https://arxiv.org/abs/2508.05048)
*Mohammad Ferry Husnil Arif,Muhammad Imran*

Main category: cs.CR

TL;DR: 半直接离散对数问题（SDLP）在有限群中的量子抗性被质疑，研究发现其经典难度依赖于群结构，并不总是优于标准离散对数问题（DLP）。


<details>
  <summary>Details</summary>
Motivation: 研究SDLP在经典计算环境下的难度，以评估其作为密码学基础的潜力。

Method: 将SDLP重新表述为广义离散对数问题，并改进Baby-Step Giant-Step算法以分析其复杂度。

Result: SDLP的经典难度因群结构而异：在有限域中与DLP相当，在椭圆曲线中变得简单，而在初等阿贝尔群中可能更难。

Conclusion: SDLP的非阿贝尔结构并不保证更高的经典难度，密码学应用需更谨慎选择代数结构。

Abstract: The semidirect discrete logarithm problem (SDLP) in finite groups was
proposed as a foundation for post-quantum cryptographic protocols, based on the
belief that its non-abelian structure would resist quantum attacks. However,
recent results have shown that SDLP in finite groups admits efficient quantum
algorithms, undermining its quantum resistance. This raises a fundamental
question: does the SDLP offer any computational advantages over the standard
discrete logarithm problem (DLP) against classical adversaries? In this work,
we investigate the classical hardness of SDLP across different finite group
platforms. We establish that the group-case SDLP can be reformulated as a
generalized discrete logarithm problem, enabling adaptation of classical
algorithms to study its complexity. We present a concrete adaptation of the
Baby-Step Giant-Step algorithm for SDLP, achieving time and space complexity
$O(\sqrt{r})$ where $r$ is the period of the underlying cycle structure.
Through theoretical analysis and experimental validation in SageMath, we
demonstrate that the classical hardness of SDLP is highly platform-dependent
and does not uniformly exceed that of standard DLP. In finite fields
$\mathbb{F}_p^*$, both problems exhibit comparable complexity. Surprisingly, in
elliptic curves $E(\mathbb{F}_p)$, the SDLP becomes trivial due to the bounded
automorphism group, while in elementary abelian groups $\mathbb{F}_p^n$, the
SDLP can be harder than DLP, with complexity varying based on the eigenvalue
structure of the automorphism. Our findings reveal that the non-abelian
structure of semidirect products does not inherently guarantee increased
classical hardness, suggesting that the search for classically hard problems
for cryptographic applications requires more careful consideration of the
underlying algebraic structures.

</details>


### [17] [Incident Response Planning Using a Lightweight Large Language Model with Reduced Hallucination](https://arxiv.org/abs/2508.05188)
*Kim Hammar,Tansu Alpcan,Emil C. Lupu*

Main category: cs.CR

TL;DR: 论文提出了一种利用大型语言模型（LLM）进行网络安全事件响应规划的新方法，通过微调、信息检索和前瞻规划减少幻觉，并在实验中表现出优于前沿LLM的性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于前沿LLM的事件响应方法成本高且易产生幻觉，亟需一种更高效、可靠的方法。

Method: 采用三步法：微调LLM、信息检索和前瞻规划，确保生成响应计划的幻觉概率可控。

Result: 实验表明，该方法恢复时间比前沿LLM缩短22%，且能泛化到多种事件类型和响应动作。

Conclusion: 该方法在降低幻觉的同时提升了事件响应效率，适用于普通硬件，具有实际应用潜力。

Abstract: Timely and effective incident response is key to managing the growing
frequency of cyberattacks. However, identifying the right response actions for
complex systems is a major technical challenge. A promising approach to
mitigate this challenge is to use the security knowledge embedded in large
language models (LLMs) to assist security operators during incident handling.
Recent research has demonstrated the potential of this approach, but current
methods are mainly based on prompt engineering of frontier LLMs, which is
costly and prone to hallucinations. We address these limitations by presenting
a novel way to use an LLM for incident response planning with reduced
hallucination. Our method includes three steps: fine-tuning, information
retrieval, and lookahead planning. We prove that our method generates response
plans with a bounded probability of hallucination and that this probability can
be made arbitrarily small at the expense of increased planning time under
certain assumptions. Moreover, we show that our method is lightweight and can
run on commodity hardware. We evaluate our method on logs from incidents
reported in the literature. The experimental results show that our method a)
achieves up to 22% shorter recovery times than frontier LLMs and b) generalizes
to a broad range of incident types and response actions.

</details>


### [18] [An Overview of 7726 User Reports: Uncovering SMS Scams and Scammer Strategies](https://arxiv.org/abs/2508.05276)
*Sharad Agarwal,Guillermo Suarez-Tangil,Marie Vasek*

Main category: cs.CR

TL;DR: 论文分析了用户提交的短信报告，区分了垃圾短信和诈骗短信，并分类了12种诈骗类型，揭示了诈骗者利用的基础设施和诱骗手段。


<details>
  <summary>Details</summary>
Motivation: 移动网络运营商的防火墙未能完全阻止诈骗短信，缺乏对绕过防火墙的短信的研究。

Method: 与主要移动运营商合作，分析135万份用户报告，使用方法论框架识别垃圾和诈骗短信。

Result: 35.12%的短信为垃圾短信，40.27%为诈骗短信，最常见的诈骗类型是“错号”诈骗。

Conclusion: 论文首次通过用户报告分析短信诈骗，揭示了诈骗类型和手段，为防范提供了新视角。

Abstract: Mobile network operators implement firewalls to stop illicit messages, but
scammers find ways to evade detection. Previous work has looked into SMS texts
that are blocked by these firewalls. However, there is little insight into SMS
texts that bypass them and reach users. To this end, we collaborate with a
major mobile network operator to receive 1.35m user reports submitted over four
months. We find 89.16% of user reports comprise text messages, followed by
reports of suspicious calls and URLs. Using our methodological framework, we
identify 35.12% of the unique text messages reported by users as spam, while
40.27% are scam text messages. This is the first paper that investigates SMS
reports submitted by users and differentiates between spam and scams. Our paper
classifies the identified scam text messages into 12 scam types, of which the
most popular is 'wrong number' scams. We explore the various infrastructure
services that scammers abuse to conduct SMS scams, including mobile network
operators and hosting infrastructure, and analyze the text of the scam messages
to understand how scammers lure victims into providing them with their personal
or financial details.

</details>


### [19] [ShikkhaChain: A Blockchain-Powered Academic Credential Verification System for Bangladesh](https://arxiv.org/abs/2508.05334)
*Ahsan Farabi,Israt Khandaker,Nusrat Jahan,Ibrahim Khalil Shanto*

Main category: cs.CR

TL;DR: ShikkhaChain是一个基于区块链的学术证书管理平台，旨在解决孟加拉国等发展中国家因手动验证方式效率低下而导致的学术证书欺诈问题。


<details>
  <summary>Details</summary>
Motivation: 学术证书欺诈威胁教育诚信，尤其是在孟加拉国等发展中国家，其验证方式主要为手动且效率低下。

Method: 平台基于以太坊智能合约和IPFS离线存储，通过React开发的DApp与MetaMask集成，提供透明、可扩展的解决方案，支持基于角色的访问和QR码验证。

Result: 原型展示了增强的信任度、减少的验证时间以及提升的国际可信度。

Conclusion: ShikkhaChain为孟加拉国的学术和就业生态系统提供了更可靠的解决方案。

Abstract: Academic credential fraud threatens educational integrity, especially in
developing countries like Bangladesh, where verification methods are primarily
manual and inefficient. To address this challenge, we present ShikkhaChain, a
blockchain-powered certificate management platform designed to securely issue,
verify, and revoke academic credentials in a decentralized and tamper-proof
manner. Built on Ethereum smart contracts and utilizing IPFS for off-chain
storage, the platform offers a transparent, scalable solution accessible
through a React-based DApp with MetaMask integration. ShikkhaChain enables
role-based access for governments, regulators, institutions, and public
verifiers, allowing QR-based validation and on-chain revocation tracking. Our
prototype demonstrates enhanced trust, reduced verification time, and improved
international credibility for Bangladeshi degrees, promoting a more reliable
academic and employment ecosystem.

</details>


### [20] [Grouped k-threshold random grid-based visual cryptography scheme](https://arxiv.org/abs/2508.05394)
*Xiaoli Zhuo,Xuehu Yan,Wei Yan*

Main category: cs.CR

TL;DR: 提出了一种新的随机网格视觉密码方案（RGVCS）共享范式，通过构建$(k,n)$-阈值方案，实现了更高的对比度，达到了文献中的最高值。


<details>
  <summary>Details</summary>
Motivation: 现有$(k,n)$ RGVCS未能达到理论对比度上限，亟需更高对比度的构造方法。

Method: 提出$n'$-grouped $(k,n)$ RGVCS范式，从任意$(k,n')$-阈值方案构建$(k,n)$-阈值方案，并引入新的对比度计算公式。

Result: 通过设置$n'=k$，实现了文献中最高的对比度值，理论和实验结果均验证了其优越性。

Conclusion: 新范式显著提升了RGVCS的对比度，为视觉密码方案的研究提供了新思路。

Abstract: Visual cryptography schemes (VCSs) belong to a category of secret image
sharing schemes that do not require cryptographic knowledge for decryption,
instead relying directly on the human visual system. Among VCSs, random
grid-based VCS (RGVCS) has garnered widespread attention as it avoids pixel
expansion while requiring no basic matrices design. Contrast, a core metric for
RGVCS, directly determines the visual quality of recovered images, rendering
its optimization a critical research objective. However, existing $(k,n)$
RGVCSs still fail to attain theoretical upper bounds on contrast, highlighting
the urgent need for higher-contrast constructions. In this paper, we propose a
novel sharing paradigm for RGVCS that constructs $(k,n)$-threshold schemes from
arbitrary $(k,n')$-threshold schemes $(k \leq n'\leq n)$, termed
\emph{$n'$-grouped $(k,n)$ RGVCS}. This paradigm establishes hierarchical
contrast characteristics: participants within the same group achieve optimal
recovery quality, while inter-group recovery shows a hierarchical contrast. We
further introduce a new contrast calculation formula tailored to the new
paradigm. Then, we propose a contrast-enhanced $(k,n)$ RGVCS by setting $n'=
k$, achieving the highest contrast value documented in the existing literature.
Theoretical analysis and experimental results demonstrate the superiority of
our proposed scheme in terms of contrast.

</details>


### [21] [Local Distance Query with Differential Privacy](https://arxiv.org/abs/2508.05518)
*Weihong Sheng,Jiajun Chen,Bin Cai,Chunqiang Hu,Meng Han,Jiguo Yu*

Main category: cs.CR

TL;DR: 论文提出两种方法解决本地差分隐私（LDP）下距离查询的挑战，第一种生成合成图但效用低，第二种通过聚合局部距离向量捕获全局结构。


<details>
  <summary>Details</summary>
Motivation: 现实场景中缺乏可信的第三方管理者，导致在LDP下实现差分隐私距离查询困难。

Method: 方法一：生成合成图并减少噪声干扰；方法二：通过局部距离向量聚合捕获全局结构。

Result: 理论分析和实验验证表明第二种方法有效。

Conclusion: 第二种方法解决了LDP下距离查询的挑战，并提高了准确性。

Abstract: Differential Privacy (DP) is commonly employed to safeguard graph analysis or
publishing. Distance, a critical factor in graph analysis, is typically handled
using curator DP, where a trusted curator holds the complete neighbor lists of
all vertices and answers queries privately. However, in many real-world
scenarios, such a curator may not be present, posing a significant challenge
for implementing differentially private distance queries under Local
Differential Privacy (LDP). This paper proposes two approaches to address this
challenge. The first approach generates a synthetic graph by randomizing
responses and applies bitwise operations to reduce noise interference. However,
like other synthetic graph methods, this approach suffers from low utility. To
overcome this limitation, we propose a second approach, the first LDP method
specifically designed for distance queries, which captures the global graph
structure by continuously aggregating local distance vectors from neighboring
vertices. This process enables the accurate updating of global distances. We
demonstrate the effectiveness of our method through comprehensive theoretical
analysis and experimental evaluations on real-world datasets.

</details>


### [22] [PRvL: Quantifying the Capabilities and Risks of Large Language Models for PII Redaction](https://arxiv.org/abs/2508.05545)
*Leon Garza,Anantaa Kotal,Aritran Piplai,Lavanya Elluri,Prajit Das,Aman Chadha*

Main category: cs.CR

TL;DR: 论文探讨了利用大型语言模型（LLMs）进行个人身份信息（PII）脱敏的方法，分析了不同架构和训练策略的效果，并提出了开源工具PRvL。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则和特定领域NER模型的方法无法泛化，LLMs在上下文理解方面表现优异，但其在PII脱敏中的具体应用尚未充分研究。

Method: 评估多种LLM架构和训练策略，衡量脱敏性能、语义保留和PII泄漏，并与延迟和计算成本对比。

Result: 提供了配置高效、准确且隐私保护的LLM脱敏系统的实用指南，并开源了PRvL工具。

Conclusion: LLMs在PII脱敏中具有潜力，PRvL为实际部署提供了灵活且合规的解决方案。

Abstract: Redacting Personally Identifiable Information (PII) from unstructured text is
critical for ensuring data privacy in regulated domains. While earlier
approaches have relied on rule-based systems and domain-specific Named Entity
Recognition (NER) models, these methods fail to generalize across formats and
contexts. Recent advances in Large Language Models (LLMs) offer a promising
alternative, yet the effect of architectural and training choices on redaction
performance remains underexplored. LLMs have demonstrated strong performance in
tasks that require contextual language understanding, including the redaction
of PII in free-form text. Prior work suggests that with appropriate adaptation,
LLMs can become effective contextual privacy learners. However, the
consequences of architectural and training choices for PII Redaction remain
underexplored. In this work, we present a comprehensive analysis of LLMs as
privacy-preserving PII Redaction systems. We evaluate a range of LLM
architectures and training strategies for their effectiveness in PII Redaction.
Our analysis measures redaction performance, semantic preservation, and PII
leakage, and compares these outcomes against latency and computational cost.
The results provide practical guidance for configuring LLM-based redactors that
are accurate, efficient, and privacy-aware. To support reproducibility and
real-world deployment, we release PRvL, an open-source suite of fine-tuned
models, and evaluation tools for general-purpose PII Redaction. PRvL is built
entirely on open-source LLMs and supports multiple inference settings for
flexibility and compliance. It is designed to be easily customized for
different domains and fully operable within secure, self-managed environments.
This enables data owners to perform redactions without relying on third-party
services or exposing sensitive content beyond their own infrastructure.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [23] [Prescriptive Agents based on Rag for Automated Maintenance (PARAM)](https://arxiv.org/abs/2508.04714)
*Chitranshu Harbola,Anupam Purwar*

Main category: cs.AI

TL;DR: 本文提出了一种基于大型语言模型（LLM）的智能系统，用于工业机械的预测性维护，结合振动频率分析和多代理生成技术，提供可操作的维护建议。


<details>
  <summary>Details</summary>
Motivation: 工业机械维护需要及时干预以防止灾难性故障并优化运行效率。传统方法通常局限于异常检测，缺乏具体的维护建议。

Method: 系统将轴承振动数据（BPFO、BPFI、BSF、FTF频率）序列化为自然语言供LLM处理，结合多代理组件处理维护手册和网络搜索，生成结构化维护建议。

Result: 实验验证表明，系统能有效检测异常并提供上下文相关的维护指导，成功填补了状态监测与可操作维护计划之间的空白。

Conclusion: 该研究推动了LLM在工业维护中的应用，为跨机械组件和工业领域的预测性维护提供了可扩展的框架。

Abstract: Industrial machinery maintenance requires timely intervention to prevent
catastrophic failures and optimize operational efficiency. This paper presents
an integrated Large Language Model (LLM)-based intelligent system for
prescriptive maintenance that extends beyond traditional anomaly detection to
provide actionable maintenance recommendations. Building upon our prior LAMP
framework for numerical data analysis, we develop a comprehensive solution that
combines bearing vibration frequency analysis with multi agentic generation for
intelligent maintenance planning. Our approach serializes bearing vibration
data (BPFO, BPFI, BSF, FTF frequencies) into natural language for LLM
processing, enabling few-shot anomaly detection with high accuracy. The system
classifies fault types (inner race, outer race, ball/roller, cage faults) and
assesses severity levels. A multi-agentic component processes maintenance
manuals using vector embeddings and semantic search, while also conducting web
searches to retrieve comprehensive procedural knowledge and access up-to-date
maintenance practices for more accurate and in-depth recommendations. The
Gemini model then generates structured maintenance recommendations includes
immediate actions, inspection checklists, corrective measures, parts
requirements, and timeline specifications. Experimental validation in bearing
vibration datasets demonstrates effective anomaly detection and contextually
relevant maintenance guidance. The system successfully bridges the gap between
condition monitoring and actionable maintenance planning, providing industrial
practitioners with intelligent decision support. This work advances the
application of LLMs in industrial maintenance, offering a scalable framework
for prescriptive maintenance across machinery components and industrial
sectors.

</details>


### [24] [GeoFlow: Agentic Workflow Automation for Geospatial Tasks](https://arxiv.org/abs/2508.04719)
*Amulya Bhattaram,Justin Chung,Stanley Chung,Ranit Gupta,Janani Ramamoorthy,Kartikeya Gullapalli,Diana Marculescu,Dimitrios Stamoulis*

Main category: cs.AI

TL;DR: GeoFlow是一种自动生成地理空间任务代理工作流的方法，通过明确工具调用目标提高代理成功率并减少令牌使用。


<details>
  <summary>Details</summary>
Motivation: 现有方法在推理分解上表现不足，且API选择隐含，导致效率低下。GeoFlow旨在通过明确指导代理调用地理空间API来解决这一问题。

Method: GeoFlow为每个代理提供详细的工具调用目标，以指导运行时地理空间API的调用。

Result: 与现有最优方法相比，GeoFlow将代理成功率提高了6.8%，并将令牌使用量减少了四倍。

Conclusion: GeoFlow通过明确工具调用目标，显著提升了代理在地理空间任务中的效率和性能。

Abstract: We present GeoFlow, a method that automatically generates agentic workflows
for geospatial tasks. Unlike prior work that focuses on reasoning decomposition
and leaves API selection implicit, our method provides each agent with detailed
tool-calling objectives to guide geospatial API invocation at runtime. GeoFlow
increases agentic success by 6.8% and reduces token usage by up to fourfold
across major LLM families compared to state-of-the-art approaches.

</details>


### [25] [Who is a Better Player: LLM against LLM](https://arxiv.org/abs/2508.04720)
*Yingjie Zhou,Jiezhang Cao,Farong Wen,Li Xu,Yanwei Jiang,Jun Jia,Ronghui Li,Xiaohong Liu,Yu Zhou,Xiongkuo Min,Jie Guo,Zicheng Zhang,Guangtao Zhai*

Main category: cs.AI

TL;DR: 论文提出了一种通过对抗性棋盘游戏评估大型语言模型（LLMs）性能的框架，弥补了主流问答基准方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 棋盘游戏作为战略推理和智能的典型领域，是评估AI系统的理想基准。现有问答基准方法依赖数据，存在局限性。

Method: 开发了Qi Town平台，支持5种游戏和20个LLM驱动的玩家，使用Elo评分系统和性能循环图（PLG）定量评估LLMs，同时通过积极情绪评分（PSS）评估心理适应性。

Result: 实验表明，尽管技术差异大，多数LLMs在对抗环境中表现乐观且适应性强，但PLG揭示了其技能表现的不稳定性。

Conclusion: 该框架为LLMs的全面评估提供了新方法，但LLMs在游戏中的不稳定性需进一步研究。

Abstract: Adversarial board games, as a paradigmatic domain of strategic reasoning and
intelligence, have long served as both a popular competitive activity and a
benchmark for evaluating artificial intelligence (AI) systems. Building on this
foundation, we propose an adversarial benchmarking framework to assess the
comprehensive performance of Large Language Models (LLMs) through board games
competition, compensating the limitation of data dependency of the mainstream
Question-and-Answer (Q&A) based benchmark method. We introduce Qi Town, a
specialized evaluation platform that supports 5 widely played games and
involves 20 LLM-driven players. The platform employs both the Elo rating system
and a novel Performance Loop Graph (PLG) to quantitatively evaluate the
technical capabilities of LLMs, while also capturing Positive Sentiment Score
(PSS) throughout gameplay to assess mental fitness. The evaluation is
structured as a round-robin tournament, enabling systematic comparison across
players. Experimental results indicate that, despite technical differences,
most LLMs remain optimistic about winning and losing, demonstrating greater
adaptability to high-stress adversarial environments than humans. On the other
hand, the complex relationship between cyclic wins and losses in PLGs exposes
the instability of LLMs' skill play during games, warranting further
explanation and exploration.

</details>


### [26] [Fine-Tuning Small Language Models (SLMs) for Autonomous Web-based Geographical Information Systems (AWebGIS)](https://arxiv.org/abs/2508.04846)
*Mahdi Nazari Ashani,Ali Asghar Alesheikh,Saba Kazemi,Kimya Kheirkhah,Yasin Mohammadi,Fatemeh Rezaie,Amir Mahdi Manafi,Hedieh Zarkesh*

Main category: cs.AI

TL;DR: 比较了三种实现自主WebGIS的方法，发现基于小型语言模型的客户端方法在准确性和隐私保护方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 解决现有云基大型语言模型在隐私、可扩展性和网络依赖性方面的问题。

Method: 比较了三种方法：云基LLM、半自动离线方法和基于小型语言模型的完全离线客户端方法。

Result: 客户端方法准确率最高（0.93），且减少了服务器负载。

Conclusion: 浏览器可执行模型是实现自主WebGIS的可行方案。

Abstract: Autonomous web-based geographical information systems (AWebGIS) aim to
perform geospatial operations from natural language input, providing intuitive,
intelligent, and hands-free interaction. However, most current solutions rely
on cloud-based large language models (LLMs), which require continuous internet
access and raise users' privacy and scalability issues due to centralized
server processing. This study compares three approaches to enabling AWebGIS:
(1) a fully-automated online method using cloud-based LLMs (e.g., Cohere); (2)
a semi-automated offline method using classical machine learning classifiers
such as support vector machine and random forest; and (3) a fully autonomous
offline (client-side) method based on a fine-tuned small language model (SLM),
specifically T5-small model, executed in the client's web browser. The third
approach, which leverages SLMs, achieved the highest accuracy among all
methods, with an exact matching accuracy of 0.93, Levenshtein similarity of
0.99, and recall-oriented understudy for gisting evaluation ROUGE-1 and ROUGE-L
scores of 0.98. Crucially, this client-side computation strategy reduces the
load on backend servers by offloading processing to the user's device,
eliminating the need for server-based inference. These results highlight the
feasibility of browser-executable models for AWebGIS solutions.

</details>


### [27] [Large Language Models Reasoning Abilities Under Non-Ideal Conditions After RL-Fine-Tuning](https://arxiv.org/abs/2508.04848)
*Chang Tian,Matthew B. Blaschko,Mingzhe Xing,Xiuxing Li,Yinliang Yue,Marie-Francine Moens*

Main category: cs.AI

TL;DR: 论文研究了强化学习（RL）在提升大语言模型（LLMs）推理能力中的作用，发现现有基准测试忽视了非理想场景下的性能表现，并提出了三种具有实际意义的非理想场景。实验表明，RL微调在理想场景下有效，但在非理想场景中表现显著下降。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注理想场景，忽视了实际应用中可能遇到的非理想情况，如摘要推断、细粒度噪声抑制和上下文过滤。论文旨在填补这一空白，并评估模型在这些场景下的表现。

Method: 通过RL微调三种LLMs和一种先进的视觉语言模型（LVLM），使用策略梯度算法，并在八个公共数据集上测试其性能。

Result: RL微调在理想场景下提升了推理能力，但在三种非理想场景中表现显著下降，暴露了当前方法的局限性。

Conclusion: 研究强调了大语言模型推理能力被高估的问题，并呼吁在非理想场景下评估模型性能。

Abstract: Reinforcement learning (RL) has become a key technique for enhancing the
reasoning abilities of large language models (LLMs), with policy-gradient
algorithms dominating the post-training stage because of their efficiency and
effectiveness. However, most existing benchmarks evaluate large-language-model
reasoning under idealized settings, overlooking performance in realistic,
non-ideal scenarios. We identify three representative non-ideal scenarios with
practical relevance: summary inference, fine-grained noise suppression, and
contextual filtering. We introduce a new research direction guided by
brain-science findings that human reasoning remains reliable under imperfect
inputs. We formally define and evaluate these challenging scenarios. We
fine-tune three LLMs and a state-of-the-art large vision-language model (LVLM)
using RL with a representative policy-gradient algorithm and then test their
performance on eight public datasets. Our results reveal that while RL
fine-tuning improves baseline reasoning under idealized settings, performance
declines significantly across all three non-ideal scenarios, exposing critical
limitations in advanced reasoning capabilities. Although we propose a
scenario-specific remediation method, our results suggest current methods leave
these reasoning deficits largely unresolved. This work highlights that the
reasoning abilities of large models are often overstated and underscores the
importance of evaluating models under non-ideal scenarios. The code and data
will be released at XXXX.

</details>


### [28] [ConfAgents: A Conformal-Guided Multi-Agent Framework for Cost-Efficient Medical Diagnosis](https://arxiv.org/abs/2508.04915)
*Huiya Zhao,Yinghao Zhu,Zixiang Wang,Yasha Wang,Junyi Gao,Liantao Ma*

Main category: cs.AI

TL;DR: HealthFlow是一种自进化的AI代理，通过元级进化机制提升战略规划能力，显著优于现有框架。


<details>
  <summary>Details</summary>
Motivation: 现有AI代理在医疗研究中依赖静态策略，无法提升战略规划能力，限制了其效能。

Method: 引入HealthFlow，通过元级进化机制自主优化问题解决策略，并开发EHRFlowBench基准进行验证。

Result: 实验表明HealthFlow在复杂医疗数据分析任务中表现优于现有框架。

Conclusion: 该研究标志着从工具使用者向自进化任务管理者的转变，为更自主的AI科学发现铺平道路。

Abstract: The efficacy of AI agents in healthcare research is hindered by their
reliance on static, predefined strategies. This creates a critical limitation:
agents can become better tool-users but cannot learn to become better strategic
planners, a crucial skill for complex domains like healthcare. We introduce
HealthFlow, a self-evolving AI agent that overcomes this limitation through a
novel meta-level evolution mechanism. HealthFlow autonomously refines its own
high-level problem-solving policies by distilling procedural successes and
failures into a durable, strategic knowledge base. To anchor our research and
facilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark
featuring complex, realistic health data analysis tasks derived from
peer-reviewed clinical research. Our comprehensive experiments demonstrate that
HealthFlow's self-evolving approach significantly outperforms state-of-the-art
agent frameworks. This work marks a necessary shift from building better
tool-users to designing smarter, self-evolving task-managers, paving the way
for more autonomous and effective AI for scientific discovery.

</details>


### [29] [The Docking Game: Loop Self-Play for Fast, Dynamic, and Accurate Prediction of Flexible Protein--Ligand Binding](https://arxiv.org/abs/2508.05006)
*Youzhi Zhang,Yufei Li,Gaofeng Meng,Hongbin Liu,Jiebo Luo*

Main category: cs.AI

TL;DR: 提出了一种基于博弈论的新框架Docking Game，通过LoopPlay算法提升分子对接性能。


<details>
  <summary>Details</summary>
Motivation: 解决多任务学习模型中配体对接性能较差的问题，因配体与蛋白质结构复杂性差异导致。

Method: 将蛋白质-配体交互建模为双玩家博弈，开发LoopPlay算法，通过内外循环交替训练玩家。

Result: 在公开数据集上，LoopPlay比现有方法提升约10%的准确率。

Conclusion: LoopPlay显著提升分子对接准确性，对药物发现具有潜在价值。

Abstract: Molecular docking is a crucial aspect of drug discovery, as it predicts the
binding interactions between small-molecule ligands and protein pockets.
However, current multi-task learning models for docking often show inferior
performance in ligand docking compared to protein pocket docking. This
disparity arises largely due to the distinct structural complexities of ligands
and proteins. To address this issue, we propose a novel game-theoretic
framework that models the protein-ligand interaction as a two-player game
called the Docking Game, with the ligand docking module acting as the ligand
player and the protein pocket docking module as the protein player. To solve
this game, we develop a novel Loop Self-Play (LoopPlay) algorithm, which
alternately trains these players through a two-level loop. In the outer loop,
the players exchange predicted poses, allowing each to incorporate the other's
structural predictions, which fosters mutual adaptation over multiple
iterations. In the inner loop, each player dynamically refines its predictions
by incorporating its own predicted ligand or pocket poses back into its model.
We theoretically show the convergence of LoopPlay, ensuring stable
optimization. Extensive experiments conducted on public benchmark datasets
demonstrate that LoopPlay achieves approximately a 10\% improvement in
predicting accurate binding modes compared to previous state-of-the-art
methods. This highlights its potential to enhance the accuracy of molecular
docking in drug discovery.

</details>


### [30] [Can Large Language Models Integrate Spatial Data? Empirical Insights into Reasoning Strengths and Computational Weaknesses](https://arxiv.org/abs/2508.05009)
*Bin Han,Robert Wolfe,Anat Caspi,Bill Howe*

Main category: cs.AI

TL;DR: 研究探讨了利用大型语言模型（LLMs）整合城市空间数据的潜力，发现其在提供相关特征时表现优异，但空间推理能力有限。


<details>
  <summary>Details</summary>
Motivation: 传统规则方法无法覆盖所有边缘案例，机器学习方法需要大量标注数据，而LLMs提供了一种灵活替代方案。

Method: 分析LLMs的空间推理能力，并采用“审查-优化”方法纠正错误响应。

Result: LLMs在减少对空间推理依赖时表现优异，但需辅助特征支持。

Conclusion: LLMs是传统规则方法的有效替代，未来可探索多模态整合和多样化数据格式支持。

Abstract: We explore the application of large language models (LLMs) to empower domain
experts in integrating large, heterogeneous, and noisy urban spatial datasets.
Traditional rule-based integration methods are unable to cover all edge cases,
requiring manual verification and repair. Machine learning approaches require
collecting and labeling of large numbers of task-specific samples. In this
study, we investigate the potential of LLMs for spatial data integration. Our
analysis first considers how LLMs reason about environmental spatial
relationships mediated by human experience, such as between roads and
sidewalks. We show that while LLMs exhibit spatial reasoning capabilities, they
struggle to connect the macro-scale environment with the relevant computational
geometry tasks, often producing logically incoherent responses. But when
provided relevant features, thereby reducing dependence on spatial reasoning,
LLMs are able to generate high-performing results. We then adapt a
review-and-refine method, which proves remarkably effective in correcting
erroneous initial responses while preserving accurate responses. We discuss
practical implications of employing LLMs for spatial data integration in
real-world contexts and outline future research directions, including
post-training, multi-modal integration methods, and support for diverse data
formats. Our findings position LLMs as a promising and flexible alternative to
traditional rule-based heuristics, advancing the capabilities of adaptive
spatial data integration.

</details>


### [31] [Cognitive Duality for Adaptive Web Agents](https://arxiv.org/abs/2508.05081)
*Jiarun Liu,Chunhong Zhang,Zheng Hu*

Main category: cs.AI

TL;DR: 论文提出了一种结合离线模仿学习和在线探索的Web导航智能体框架CogniWeb，基于人类认知的双系统理论，实现了高效且性能优越的解决方案。


<details>
  <summary>Details</summary>
Motivation: Web导航是评估通用人工智能（AGI）的关键领域，但现有方法未能有效整合离线学习和在线探索。

Method: 借鉴人类认知的双系统理论，将智能体分解为快速直觉（System 1）和慢速深思（System 2）模块，并实现为CogniWeb框架。

Result: 在WebArena上的实验表明，CogniWeb在成功率（43.96%）和效率（减少75%的token使用）上表现优异。

Conclusion: CogniWeb通过双系统理论整合了离线与在线学习，为Web导航智能体提供了高效且性能优越的解决方案。

Abstract: Web navigation represents a critical and challenging domain for evaluating
artificial general intelligence (AGI), demanding complex decision-making within
high-entropy, dynamic environments with combinatorially explosive action
spaces. Current approaches to building autonomous web agents either focus on
offline imitation learning or online exploration, but rarely integrate both
paradigms effectively. Inspired by the dual-process theory of human cognition,
we derive a principled decomposition into fast System 1 and slow System 2
cognitive processes. This decomposition provides a unifying perspective on
existing web agent methodologies, bridging the gap between offline learning of
intuitive reactive behaviors and online acquisition of deliberative planning
capabilities. We implement this framework in CogniWeb, a modular agent
architecture that adaptively toggles between fast intuitive processing and
deliberate reasoning based on task complexity. Our evaluation on WebArena
demonstrates that CogniWeb achieves competitive performance (43.96% success
rate) while maintaining significantly higher efficiency (75% reduction in token
usage).

</details>


### [32] [MedMKEB: A Comprehensive Knowledge Editing Benchmark for Medical Multimodal Large Language Models](https://arxiv.org/abs/2508.05083)
*Dexuan Xu,Jieyi Wang,Zhongyan Chai,Yongzhi Cao,Hanpin Wang,Huamin Zhang,Yu Huang*

Main category: cs.AI

TL;DR: MedMKEB是首个针对医学多模态大语言模型知识编辑的综合性基准，旨在评估其可靠性、通用性、局部性、可移植性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 医学知识不断更新，需高效修正模型中的过时或错误信息，而现有研究缺乏针对多模态医学知识编辑的系统性基准。

Method: 基于高质量医学视觉问答数据集构建MedMKEB，包含反事实修正、语义泛化、知识迁移和对抗鲁棒性等任务，并引入专家验证。

Result: 实验表明现有知识编辑方法在医学领域存在局限性，需开发针对性策略。

Conclusion: MedMKEB将推动可信且高效的医学知识编辑算法发展。

Abstract: Recent advances in multimodal large language models (MLLMs) have
significantly improved medical AI, enabling it to unify the understanding of
visual and textual information. However, as medical knowledge continues to
evolve, it is critical to allow these models to efficiently update outdated or
incorrect information without retraining from scratch. Although textual
knowledge editing has been widely studied, there is still a lack of systematic
benchmarks for multimodal medical knowledge editing involving image and text
modalities. To fill this gap, we present MedMKEB, the first comprehensive
benchmark designed to evaluate the reliability, generality, locality,
portability, and robustness of knowledge editing in medical multimodal large
language models. MedMKEB is built on a high-quality medical visual
question-answering dataset and enriched with carefully constructed editing
tasks, including counterfactual correction, semantic generalization, knowledge
transfer, and adversarial robustness. We incorporate human expert validation to
ensure the accuracy and reliability of the benchmark. Extensive single editing
and sequential editing experiments on state-of-the-art general and medical
MLLMs demonstrate the limitations of existing knowledge-based editing
approaches in medicine, highlighting the need to develop specialized editing
strategies. MedMKEB will serve as a standard benchmark to promote the
development of trustworthy and efficient medical knowledge editing algorithms.

</details>


### [33] [EasySize: Elastic Analog Circuit Sizing via LLM-Guided Heuristic Search](https://arxiv.org/abs/2508.05113)
*Xinyue Wu,Fan Hu,Shaik Jani Babu,Yi Zhao,Xinfei Guo*

Main category: cs.AI

TL;DR: EasySize是一个基于微调Qwen3-8B模型的轻量级门尺寸框架，适用于不同工艺节点和电路拓扑，显著减少了对人力和计算资源的依赖。


<details>
  <summary>Details</summary>
Motivation: 模拟电路设计耗时且依赖经验，现有AI方法通用性差且计算资源需求高。

Method: 结合动态任务特定损失函数和全局差分进化（DE）与局部粒子群优化（PSO）的启发式搜索。

Result: 在多个工艺节点上表现优异，优于AutoCkt，节省了96.67%的仿真资源。

Conclusion: EasySize能加速和简化模拟电路设计，减少对人力和计算资源的依赖。

Abstract: Analog circuit design is a time-consuming, experience-driven task in chip
development. Despite advances in AI, developing universal, fast, and stable
gate sizing methods for analog circuits remains a significant challenge. Recent
approaches combine Large Language Models (LLMs) with heuristic search
techniques to enhance generalizability, but they often depend on large model
sizes and lack portability across different technology nodes. To overcome these
limitations, we propose EasySize, the first lightweight gate sizing framework
based on a finetuned Qwen3-8B model, designed for universal applicability
across process nodes, design specifications, and circuit topologies. EasySize
exploits the varying Ease of Attainability (EOA) of performance metrics to
dynamically construct task-specific loss functions, enabling efficient
heuristic search through global Differential Evolution (DE) and local Particle
Swarm Optimization (PSO) within a feedback-enhanced flow. Although finetuned
solely on 350nm node data, EasySize achieves strong performance on 5
operational amplifier (Op-Amp) netlists across 180nm, 45nm, and 22nm technology
nodes without additional targeted training, and outperforms AutoCkt, a
widely-used Reinforcement Learning based sizing framework, on 86.67\% of tasks
with more than 96.67\% of simulation resources reduction. We argue that
EasySize can significantly reduce the reliance on human expertise and
computational resources in gate sizing, thereby accelerating and simplifying
the analog circuit design process. EasySize will be open-sourced at a later
date.

</details>


### [34] [Beyond Automation: Socratic AI, Epistemic Agency, and the Implications of the Emergence of Orchestrated Multi-Agent Learning Architectures](https://arxiv.org/abs/2508.05116)
*Peer-Benedikt Degen,Igor Asanov*

Main category: cs.AI

TL;DR: 论文探讨生成式AI在高等教育中的核心作用，通过实验验证苏格拉底AI导师对学生批判性思维的促进作用，并提出多智能体系统（MAS）的教育应用框架。


<details>
  <summary>Details</summary>
Motivation: 生成式AI正成为高等教育的基础设施，重塑知识生成与验证方式，需探索其如何支持学生批判性思维与自主学习。

Method: 对65名德国师范生进行对照实验，比较苏格拉底AI导师与普通AI聊天机器人的效果。

Result: 苏格拉底AI导师显著提升学生的批判性、独立性和反思性思维，证明对话式AI可促进元认知参与。

Conclusion: 研究提出多智能体系统（MAS）的教育应用框架，强调人机协作与教学对齐，为混合学习生态系统提供实证与概念支持。

Abstract: Generative AI is no longer a peripheral tool in higher education. It is
rapidly evolving into a general-purpose infrastructure that reshapes how
knowledge is generated, mediated, and validated. This paper presents findings
from a controlled experiment evaluating a Socratic AI Tutor, a large language
model designed to scaffold student research question development through
structured dialogue grounded in constructivist theory. Conducted with 65
pre-service teacher students in Germany, the study compares interaction with
the Socratic Tutor to engagement with an uninstructed AI chatbot. Students
using the Socratic Tutor reported significantly greater support for critical,
independent, and reflective thinking, suggesting that dialogic AI can stimulate
metacognitive engagement and challenging recent narratives of de-skilling due
to generative AI usage. These findings serve as a proof of concept for a
broader pedagogical shift: the use of multi-agent systems (MAS) composed of
specialised AI agents. To conceptualise this, we introduce the notion of
orchestrated MAS, modular, pedagogically aligned agent constellations, curated
by educators, that support diverse learning trajectories through differentiated
roles and coordinated interaction. To anchor this shift, we propose an adapted
offer-and-use model, in which students appropriate instructional offers from
these agents. Beyond technical feasibility, we examine system-level
implications for higher education institutions and students, including funding
necessities, changes to faculty roles, curriculars, competencies and assessment
practices. We conclude with a comparative cost-effectiveness analysis
highlighting the scalability of such systems. In sum, this study contributes
both empirical evidence and a conceptual roadmap for hybrid learning ecosystems
that embed human-AI co-agency and pedagogical alignment.

</details>


### [35] [Graph-based Event Log Repair](https://arxiv.org/abs/2508.05145)
*Sebastiano Dissegna,Chiara Di Francescomarino,Massimiliano Ronzani*

Main category: cs.AI

TL;DR: 论文提出了一种基于异构图神经网络（HGNN）的方法，用于修复过程挖掘中事件日志的缺失属性，相比现有方法表现更优。


<details>
  <summary>Details</summary>
Motivation: 现实世界的事件日志常因数据采集问题导致信息缺失，传统方法依赖过程模型或机器学习模型，但存在局限性。HGNN能更自然地表示复杂多模态序列，提供更丰富的语义编码。

Method: 开发了一种HGNN模型，输入包含不完整事件的轨迹，输出缺失属性的完整集合。

Result: 在两个合成日志和四个真实日志上评估，相比基于自动编码器的先进方法，HGNN在修复所有事件属性方面表现优异。

Conclusion: HGNN模型在修复事件日志缺失属性方面具有显著优势，优于现有模型无关方法。

Abstract: The quality of event logs in Process Mining is crucial when applying any form
of analysis to them. In real-world event logs, the acquisition of data can be
non-trivial (e.g., due to the execution of manual activities and related manual
recording or to issues in collecting, for each event, all its attributes), and
often may end up with events recorded with some missing information. Standard
approaches to the problem of trace (or log) reconstruction either require the
availability of a process model that is used to fill missing values by
leveraging different reasoning techniques or employ a Machine Learning/Deep
Learning model to restore the missing values by learning from similar cases. In
recent years, a new type of Deep Learning model that is capable of handling
input data encoded as graphs has emerged, namely Graph Neural Networks. Graph
Neural Network models, and even more so Heterogeneous Graph Neural Networks,
offer the advantage of working with a more natural representation of complex
multi-modal sequences like the execution traces in Process Mining, allowing for
more expressive and semantically rich encodings.
  In this work, we focus on the development of a Heterogeneous Graph Neural
Network model that, given a trace containing some incomplete events, will
return the full set of attributes missing from those events. We evaluate our
work against a state-of-the-art approach leveraging autoencoders on two
synthetic logs and four real event logs, on different types of missing values.
Different from state-of-the-art model-free approaches, which mainly focus on
repairing a subset of event attributes, the proposed approach shows very good
performance in reconstructing all different event attributes.

</details>


### [36] [QA-Dragon: Query-Aware Dynamic RAG System for Knowledge-Intensive Visual Question Answering](https://arxiv.org/abs/2508.05197)
*Zhuohang Jiang,Pangjing Wu,Xu Yuan,Wenqi Fan,Qing Li*

Main category: cs.AI

TL;DR: QA-Dragon是一个查询感知的动态RAG系统，通过混合文本和图像检索策略，提升复杂VQA任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法仅单独检索文本或图像，无法满足复杂查询的多跳推理和实时知识需求。

Method: 引入领域路由器和搜索路由器，动态选择检索策略，混合文本和图像搜索代理。

Result: 在Meta CRAG-MM挑战中，QA-Dragon显著提升性能，单源任务提升5.06%，多源任务提升6.35%，多轮任务提升5.03%。

Conclusion: QA-Dragon通过动态多模态检索策略，有效解决了复杂VQA任务中的知识密集和多跳推理问题。

Abstract: Retrieval-Augmented Generation (RAG) has been introduced to mitigate
hallucinations in Multimodal Large Language Models (MLLMs) by incorporating
external knowledge into the generation process, and it has become a widely
adopted approach for knowledge-intensive Visual Question Answering (VQA).
However, existing RAG methods typically retrieve from either text or images in
isolation, limiting their ability to address complex queries that require
multi-hop reasoning or up-to-date factual knowledge. To address this
limitation, we propose QA-Dragon, a Query-Aware Dynamic RAG System for
Knowledge-Intensive VQA. Specifically, QA-Dragon introduces a domain router to
identify the query's subject domain for domain-specific reasoning, along with a
search router that dynamically selects optimal retrieval strategies. By
orchestrating both text and image search agents in a hybrid setup, our system
supports multimodal, multi-turn, and multi-hop reasoning, enabling it to tackle
complex VQA tasks effectively. We evaluate our QA-Dragon on the Meta CRAG-MM
Challenge at KDD Cup 2025, where it significantly enhances the reasoning
performance of base models under challenging scenarios. Our framework achieves
substantial improvements in both answer accuracy and knowledge overlap scores,
outperforming baselines by 5.06% on the single-source task, 6.35% on the
multi-source task, and 5.03% on the multi-turn task.

</details>


### [37] [An Explainable Natural Language Framework for Identifying and Notifying Target Audiences In Enterprise Communication](https://arxiv.org/abs/2508.05267)
*Vítor N. Lourenço,Mohnish Dubey,Yunfei Bai,Audrey Depeige,Vivek Jain*

Main category: cs.AI

TL;DR: 提出了一种结合RDF图数据库和LLM的新框架，用于解决大规模维护组织中专家识别和复杂实体关系通信管理的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统通信方法无法有效解决信息过载和响应时间过长的问题，需要更高效的解决方案。

Method: 结合RDF图数据库和LLM处理自然语言查询，通过规划-编排架构实现透明推理。

Result: 支持直观查询，提供可解释的结果，提高通信效率并保持系统信任。

Conclusion: 该框架显著提升了组织内通信的效率和透明度。

Abstract: In large-scale maintenance organizations, identifying subject matter experts
and managing communications across complex entities relationships poses
significant challenges -- including information overload and longer response
times -- that traditional communication approaches fail to address effectively.
We propose a novel framework that combines RDF graph databases with LLMs to
process natural language queries for precise audience targeting, while
providing transparent reasoning through a planning-orchestration architecture.
Our solution enables communication owners to formulate intuitive queries
combining concepts such as equipment, manufacturers, maintenance engineers, and
facilities, delivering explainable results that maintain trust in the system
while improving communication efficiency across the organization.

</details>


### [38] [A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents](https://arxiv.org/abs/2508.05311)
*Andrew Kiruluta*

Main category: cs.AI

TL;DR: 提出了一种混合架构，将基于决策树的符号推理与大型语言模型（LLM）的生成能力结合，通过多智能体框架实现协调推理，显著提升了推理任务的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法中符号模块与神经模块松散耦合的问题，设计一种统一推理系统，结合符号推理的规则性和LLM的泛化能力。

Method: 将决策树和随机森林作为可调用模块嵌入统一推理系统，由中央协调器维护状态一致性和通信，实现结构化与非结构化输入的推理。

Result: 在多个基准测试中表现优异，如ProofWriter（+7.2%）、GSM8k（+5.3%）和ARC（+6.0%），并在临床决策和科学发现中验证了实用性。

Conclusion: 该架构为通用神经符号推理提供了鲁棒、可解释且可扩展的解决方案。

Abstract: We propose a hybrid architecture that integrates decision tree-based symbolic
reasoning with the generative capabilities of large language models (LLMs)
within a coordinated multi-agent framework. Unlike prior approaches that
loosely couple symbolic and neural modules, our design embeds decision trees
and random forests as callable oracles within a unified reasoning system.
Tree-based modules enable interpretable rule inference and causal logic, while
LLM agents handle abductive reasoning, generalization, and interactive
planning. A central orchestrator maintains belief state consistency and
mediates communication across agents and external tools, enabling reasoning
over both structured and unstructured inputs.
  The system achieves strong performance on reasoning benchmarks. On
\textit{ProofWriter}, it improves entailment consistency by +7.2\% through
logic-grounded tree validation. On GSM8k, it achieves +5.3\% accuracy gains in
multistep mathematical problems via symbolic augmentation. On \textit{ARC}, it
boosts abstraction accuracy by +6.0\% through integration of symbolic oracles.
Applications in clinical decision support and scientific discovery show how the
system encodes domain rules symbolically while leveraging LLMs for contextual
inference and hypothesis generation. This architecture offers a robust,
interpretable, and extensible solution for general-purpose neuro-symbolic
reasoning.

</details>


### [39] [The Term 'Agent' Has Been Diluted Beyond Utility and Requires Redefinition](https://arxiv.org/abs/2508.05338)
*Brinnae Bent*

Main category: cs.AI

TL;DR: 论文主张重新定义AI中的'agent'一词，提出一个多维框架以明确其最低要求，并建议标准化术语以提升研究清晰度和政策制定效果。


<details>
  <summary>Details</summary>
Motivation: 由于AI领域中对'agent'一词的多义性导致研究交流、系统评估和政策制定困难，需要重新定义以解决这些问题。

Method: 通过历史分析和当代使用模式，提出一个多维框架，定义'agent'的最低要求，并描述系统在环境交互、学习与适应、自主性、目标复杂性和时间一致性等方面的特征。

Result: 提出了一个清晰的框架，为系统描述提供精确词汇，同时保留术语的历史多面性，并给出了标准化术语和框架采纳的建议。

Conclusion: 该框架为提升研究清晰度和可重复性提供了实用工具，同时支持更有效的政策制定。

Abstract: The term 'agent' in artificial intelligence has long carried multiple
interpretations across different subfields. Recent developments in AI
capabilities, particularly in large language model systems, have amplified this
ambiguity, creating significant challenges in research communication, system
evaluation and reproducibility, and policy development. This paper argues that
the term 'agent' requires redefinition. Drawing from historical analysis and
contemporary usage patterns, we propose a framework that defines clear minimum
requirements for a system to be considered an agent while characterizing
systems along a multidimensional spectrum of environmental interaction,
learning and adaptation, autonomy, goal complexity, and temporal coherence.
This approach provides precise vocabulary for system description while
preserving the term's historically multifaceted nature. After examining
potential counterarguments and implementation challenges, we provide specific
recommendations for moving forward as a field, including suggestions for
terminology standardization and framework adoption. The proposed approach
offers practical tools for improving research clarity and reproducibility while
supporting more effective policy development.

</details>


### [40] [NomicLaw: Emergent Trust and Strategic Argumentation in LLMs During Collaborative Law-Making](https://arxiv.org/abs/2508.05344)
*Asutosh Hota,Jussi P. P. Jokinen*

Main category: cs.AI

TL;DR: 论文提出NomicLaw，一个多智能体模拟框架，研究LLM在开放式法律伦理困境中的行为，通过投票和语言策略分析信任与互惠。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在开放式多智能体环境中的行为，尤其是在法律和伦理困境中的表现，填补现有研究的空白。

Method: 使用NomicLaw模拟框架，让LLM协作制定法律规则，通过投票和语言策略分析信任与互惠。

Result: 实验显示LLM能自发形成联盟、背叛信任，并调整语言策略影响集体决策，展示了其潜在的社会推理和说服能力。

Conclusion: 研究揭示了开源LLM的社会推理能力，为未来AI系统在自主协商和立法设计中的应用提供了启示。

Abstract: Recent advancements in large language models (LLMs) have extended their
capabilities from basic text processing to complex reasoning tasks, including
legal interpretation, argumentation, and strategic interaction. However,
empirical understanding of LLM behavior in open-ended, multi-agent settings
especially those involving deliberation over legal and ethical dilemmas remains
limited. We introduce NomicLaw, a structured multi-agent simulation where LLMs
engage in collaborative law-making, responding to complex legal vignettes by
proposing rules, justifying them, and voting on peer proposals. We
quantitatively measure trust and reciprocity via voting patterns and
qualitatively assess how agents use strategic language to justify proposals and
influence outcomes. Experiments involving homogeneous and heterogeneous LLM
groups demonstrate how agents spontaneously form alliances, betray trust, and
adapt their rhetoric to shape collective decisions. Our results highlight the
latent social reasoning and persuasive capabilities of ten open-source LLMs and
provide insights into the design of future AI systems capable of autonomous
negotiation, coordination and drafting legislation in legal settings.

</details>


### [41] [Minimal Model Reasoning in Description Logics: Don't Try This at Home!](https://arxiv.org/abs/2508.05350)
*Federica Di Stefano,Quentin Manière,Magdalena Ortiz,Mantas Šimkus*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Reasoning with minimal models has always been at the core of many knowledge
representation techniques, but we still have only a limited understanding of
this problem in Description Logics (DLs). Minimization of some selected
predicates, letting the remaining predicates vary or be fixed, as proposed in
circumscription, has been explored and exhibits high complexity. The case of
`pure' minimal models, where the extension of all predicates must be minimal,
has remained largely uncharted. We address this problem in popular DLs and
obtain surprisingly negative results: concept satisfiability in minimal models
is undecidable already for $\mathcal{EL}$. This undecidability also extends to
a very restricted fragment of tuple-generating dependencies. To regain
decidability, we impose acyclicity conditions on the TBox that bring the
worst-case complexity below double exponential time and allow us to establish a
connection with the recently studied pointwise circumscription; we also derive
results in data complexity. We conclude with a brief excursion to the DL-Lite
family, where a positive result was known for DL-Lite$_{\text{core}}$, but our
investigation establishes ExpSpace-hardness already for its extension
DL-Lite$_{\text{horn}}$.

</details>


### [42] [StructVRM: Aligning Multimodal Reasoning with Structured and Verifiable Reward Models](https://arxiv.org/abs/2508.05383)
*Xiangxiang Zhang,Jingxuan Wei,Donghong Zhong,Qi Chen,Caijun Jia,Cheng Tan,Jinming Gu,Xiaobo Qin,Zhiping Liu,Liang Hu,Tong Sun,Yuchen Wu,Zewei Sun,Chenwei Lou,Hua Zheng,Tianyang Zhan,Changbao Wang,Shuangzhi Wu,Zefa Lin,Chang Guo,Sihang Yuan,Riwei Chen,Shixiong Zhao,Yingping Zhang,Gaowei Wu,Bihui Yu,Jiahui Wu,Zhehui Zhao,Qianqian Liu,Ruofeng Tang,Xingyue Huang,Bing Zhao,Mengyang Zhang,Youqiang Zhou*

Main category: cs.AI

TL;DR: StructVRM通过结构化可验证奖励模型改进多模态推理任务，提供细粒度反馈，显著提升复杂问题的表现。


<details>
  <summary>Details</summary>
Motivation: 传统奖励机制对复杂多问题推理任务过于粗糙，无法提供部分正确性的指导。

Method: 引入StructVRM，基于模型验证器提供细粒度、子问题级别的反馈，评估语义和数学等价性。

Result: Seed-StructVRM在12个多模态基准中的6个及新STEM-Bench上达到最优性能。

Conclusion: 结构化可验证奖励训练是提升多模态模型复杂推理能力的有效方法。

Abstract: Existing Vision-Language Models often struggle with complex, multi-question
reasoning tasks where partial correctness is crucial for effective learning.
Traditional reward mechanisms, which provide a single binary score for an
entire response, are too coarse to guide models through intricate problems with
multiple sub-parts. To address this, we introduce StructVRM, a method that
aligns multimodal reasoning with Structured and Verifiable Reward Models. At
its core is a model-based verifier trained to provide fine-grained,
sub-question-level feedback, assessing semantic and mathematical equivalence
rather than relying on rigid string matching. This allows for nuanced, partial
credit scoring in previously intractable problem formats. Extensive experiments
demonstrate the effectiveness of StructVRM. Our trained model, Seed-StructVRM,
achieves state-of-the-art performance on six out of twelve public multimodal
benchmarks and our newly curated, high-difficulty STEM-Bench. The success of
StructVRM validates that training with structured, verifiable rewards is a
highly effective approach for advancing the capabilities of multimodal models
in complex, real-world reasoning domains.

</details>


### [43] [An Explainable Machine Learning Framework for Railway Predictive Maintenance using Data Streams from the Metro Operator of Portugal](https://arxiv.org/abs/2508.05388)
*Silvia García-Méndez,Francisco de Arriba-Pérez,Fátima Leal,Bruno Veloso,Benedita Malheiro,Juan Carlos Burguillo-Rial*

Main category: cs.AI

TL;DR: 该论文提出了一种实时数据驱动的智能交通系统预测性维护方法，结合了样本预处理、增量分类和结果解释，实验结果显示高准确性和实用性。


<details>
  <summary>Details</summary>
Motivation: 为智能交通系统提供实时、高精度的预测性维护解决方案，以优化服务可用性和安全性。

Method: 采用包含样本预处理、增量分类和解释性模块的在线处理流程，首次实现自然语言和可视化解释的在线故障预测。

Result: 在MetroPT数据集上，F-measure超过98%，准确率达99%，且在类别不平衡和噪声下表现稳定。

Conclusion: 该方法验证了其方法论的正确性和实际适用性，能够支持铁路运营中的主动维护决策。

Abstract: This work contributes to a real-time data-driven predictive maintenance
solution for Intelligent Transportation Systems. The proposed method implements
a processing pipeline comprised of sample pre-processing, incremental
classification with Machine Learning models, and outcome explanation. This
novel online processing pipeline has two main highlights: (i) a dedicated
sample pre-processing module, which builds statistical and frequency-related
features on the fly, and (ii) an explainability module. This work is the first
to perform online fault prediction with natural language and visual
explainability. The experiments were performed with the MetroPT data set from
the metro operator of Porto, Portugal. The results are above 98 % for F-measure
and 99 % for accuracy. In the context of railway predictive maintenance,
achieving these high values is crucial due to the practical and operational
implications of accurate failure prediction. In the specific case of a high
F-measure, this ensures that the system maintains an optimal balance between
detecting the highest possible number of real faults and minimizing false
alarms, which is crucial for maximizing service availability. Furthermore, the
accuracy obtained enables reliability, directly impacting cost reduction and
increased safety. The analysis demonstrates that the pipeline maintains high
performance even in the presence of class imbalance and noise, and its
explanations effectively reflect the decision-making process. These findings
validate the methodological soundness of the approach and confirm its practical
applicability for supporting proactive maintenance decisions in real-world
railway operations. Therefore, by identifying the early signs of failure, this
pipeline enables decision-makers to understand the underlying problems and act
accordingly swiftly.

</details>


### [44] [DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning](https://arxiv.org/abs/2508.05405)
*Xinrun Xu,Pi Bu,Ye Wang,Börje F. Karlsson,Ziming Wang,Tengtao Song,Qi Zhu,Jun Song,Zhiming Ding,Bo Zheng*

Main category: cs.AI

TL;DR: DeepPHY是一个新的基准框架，用于评估视觉语言模型（VLMs）对物理原理的理解和推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有VLMs在复杂动态环境中表现不佳，缺乏细节关注和精确动作规划能力，而真实任务需要高级空间推理和长期规划。

Method: 通过一系列具有挑战性的模拟环境，DeepPHY系统评估VLMs对物理原理的理解，并采用细粒度评估指标。

Result: 即使最先进的VLMs也难以将描述性物理知识转化为精确的预测控制。

Conclusion: DeepPHY填补了评估VLMs物理推理能力的空白，揭示了现有模型的局限性。

Abstract: Although Vision Language Models (VLMs) exhibit strong perceptual abilities
and impressive visual reasoning, they struggle with attention to detail and
precise action planning in complex, dynamic environments, leading to subpar
performance. Real-world tasks typically require complex interactions, advanced
spatial reasoning, long-term planning, and continuous strategy refinement,
usually necessitating understanding the physics rules of the target scenario.
However, evaluating these capabilities in real-world scenarios is often
prohibitively expensive. To bridge this gap, we introduce DeepPHY, a novel
benchmark framework designed to systematically evaluate VLMs' understanding and
reasoning about fundamental physical principles through a series of challenging
simulated environments. DeepPHY integrates multiple physical reasoning
environments of varying difficulty levels and incorporates fine-grained
evaluation metrics. Our evaluation finds that even state-of-the-art VLMs
struggle to translate descriptive physical knowledge into precise, predictive
control.

</details>


### [45] [Large Language Models Transform Organic Synthesis From Reaction Prediction to Automation](https://arxiv.org/abs/2508.05427)
*Kartar Kumar Lohana Tharwani,Rajesh Kumar,Sumita,Numan Ahmed,Yong Tang*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）正在改变有机合成中化学家的反应规划和执行方式，结合图神经网络、量子计算和实时光谱学，加速发现周期并推动绿色化学。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs如何从理论工具发展为实验室实用伙伴，以支持更快、更环保的化学研究。

Method: 通过结合LLMs与图神经网络、量子计算和实时光谱学，优化合成路线预测和实验执行。

Result: LLMs显著缩短了发现周期，支持数据驱动的绿色化学，但仍存在数据集偏见和安全性问题。

Conclusion: 通过开放基准、联邦学习和可解释界面等社区倡议，LLMs有望实现快速、可靠且包容的分子创新。

Abstract: Large language models (LLMs) are beginning to reshape how chemists plan and
run reactions in organic synthesis. Trained on millions of reported
transformations, these text-based models can propose synthetic routes, forecast
reaction outcomes and even instruct robots that execute experiments without
human supervision. Here we survey the milestones that turned LLMs from
speculative tools into practical lab partners. We show how coupling LLMs with
graph neural networks, quantum calculations and real-time spectroscopy shrinks
discovery cycles and supports greener, data-driven chemistry. We discuss
limitations, including biased datasets, opaque reasoning and the need for
safety gates that prevent unintentional hazards. Finally, we outline community
initiatives open benchmarks, federated learning and explainable interfaces that
aim to democratize access while keeping humans firmly in control. These
advances chart a path towards rapid, reliable and inclusive molecular
innovation powered by artificial intelligence and automation.

</details>


### [46] [Whose Truth? Pluralistic Geo-Alignment for (Agentic) AI](https://arxiv.org/abs/2508.05432)
*Krzysztof Janowicz,Zilong Liu,Gengchen Mai,Zhangyu Wang,Ivan Majic,Alexandra Fortacz,Grant McKenzie,Song Gao*

Main category: cs.AI

TL;DR: 本文探讨了AI对齐中的地理变异性问题，强调了文化、政治和法律差异对AI行为的影响，并提出了未来研究的方向和方法。


<details>
  <summary>Details</summary>
Motivation: 随着AI在全球范围内的广泛应用，确保其行为符合不同地区的社会规范和目标变得至关重要，但目前地理变异性问题尚未得到充分研究。

Method: 本文回顾了关键的地理研究问题，提出了未来工作的主题，并概述了评估对齐敏感性的方法。

Result: 研究发现，AI对齐措施有时会与统计现实脱节，且某些模型输出需要根据用户的地理位置和背景进行调整。

Conclusion: 未来需要开发更具时空意识的AI对齐方法，而非一刀切的解决方案。

Abstract: AI (super) alignment describes the challenge of ensuring (future) AI systems
behave in accordance with societal norms and goals. While a quickly evolving
literature is addressing biases and inequalities, the geographic variability of
alignment remains underexplored. Simply put, what is considered appropriate,
truthful, or legal can differ widely across regions due to cultural norms,
political realities, and legislation. Alignment measures applied to AI/ML
workflows can sometimes produce outcomes that diverge from statistical
realities, such as text-to-image models depicting balanced gender ratios in
company leadership despite existing imbalances. Crucially, some model outputs
are globally acceptable, while others, e.g., questions about Kashmir, depend on
knowing the user's location and their context. This geographic sensitivity is
not new. For instance, Google Maps renders Kashmir's borders differently based
on user location. What is new is the unprecedented scale and automation with
which AI now mediates knowledge, expresses opinions, and represents geographic
reality to millions of users worldwide, often with little transparency about
how context is managed. As we approach Agentic AI, the need for
spatio-temporally aware alignment, rather than one-size-fits-all approaches, is
increasingly urgent. This paper reviews key geographic research problems,
suggests topics for future work, and outlines methods for assessing alignment
sensitivity.

</details>


### [47] [Bench-2-CoP: Can We Trust Benchmarking for EU AI Compliance?](https://arxiv.org/abs/2508.05464)
*Matteo Prandi,Vincenzo Suriani,Federico Pierucci,Marcello Galisai,Daniele Nardi,Piercosma Bisconti*

Main category: cs.AI

TL;DR: 研究提出Bench-2-CoP框架，量化AI评估基准与欧盟AI法案要求的差距，发现现有评估过度关注行为倾向，而忽视关键功能能力。


<details>
  <summary>Details</summary>
Motivation: 当前AI评估依赖的基准未涵盖新法规关注的系统性风险，亟需填补这一差距。

Method: 使用LLM-as-judge分析，将194,955个基准问题映射到欧盟AI法案的能力分类。

Result: 发现评估严重偏向行为倾向（如幻觉倾向53.7%），而关键功能能力（如失控场景）几乎未被覆盖。

Conclusion: 研究为政策制定者和开发者提供了填补评估差距的量化依据，以促进更安全的AI发展。

Abstract: The rapid advancement of General Purpose AI (GPAI) models necessitates robust
evaluation frameworks, especially with emerging regulations like the EU AI Act
and its associated Code of Practice (CoP). Current AI evaluation practices
depend heavily on established benchmarks, but these tools were not designed to
measure the systemic risks that are the focus of the new regulatory landscape.
This research addresses the urgent need to quantify this "benchmark-regulation
gap." We introduce Bench-2-CoP, a novel, systematic framework that uses
validated LLM-as-judge analysis to map the coverage of 194,955 questions from
widely-used benchmarks against the EU AI Act's taxonomy of model capabilities
and propensities. Our findings reveal a profound misalignment: the evaluation
ecosystem is overwhelmingly focused on a narrow set of behavioral propensities,
such as "Tendency to hallucinate" (53.7% of the corpus) and "Discriminatory
bias" (28.9%), while critical functional capabilities are dangerously
neglected. Crucially, capabilities central to loss-of-control scenarios,
including evading human oversight, self-replication, and autonomous AI
development, receive zero coverage in the entire benchmark corpus. This
translates to a near-total evaluation gap for systemic risks like "Loss of
Control" (0.4% coverage) and "Cyber Offence" (0.8% coverage). This study
provides the first comprehensive, quantitative analysis of this gap, offering
critical insights for policymakers to refine the CoP and for developers to
build the next generation of evaluation tools, ultimately fostering safer and
more compliant AI.

</details>


### [48] [Can Large Language Models Generate Effective Datasets for Emotion Recognition in Conversations?](https://arxiv.org/abs/2508.05474)
*Burak Can Kaplan,Hugo Cesar De Castro Carneiro,Stefan Wermter*

Main category: cs.AI

TL;DR: 使用小型通用LLM生成多样化ERC数据集，补充现有基准，提升分类器性能。


<details>
  <summary>Details</summary>
Motivation: 解决ERC数据稀缺、来源偏见和标签主观性问题，探索LLM在数据生成中的应用。

Method: 利用小型资源高效LLM合成六种新数据集，补充三大ERC基准，评估其对分类和标签不平衡的影响。

Result: 生成数据集显著提升ERC分类器性能，增强模型鲁棒性。

Conclusion: 小型LLM生成的数据集有效补充ERC任务，为数据稀缺问题提供可行解决方案。

Abstract: Emotion recognition in conversations (ERC) focuses on identifying emotion
shifts within interactions, representing a significant step toward advancing
machine intelligence. However, ERC data remains scarce, and existing datasets
face numerous challenges due to their highly biased sources and the inherent
subjectivity of soft labels. Even though Large Language Models (LLMs) have
demonstrated their quality in many affective tasks, they are typically
expensive to train, and their application to ERC tasks--particularly in data
generation--remains limited. To address these challenges, we employ a small,
resource-efficient, and general-purpose LLM to synthesize ERC datasets with
diverse properties, supplementing the three most widely used ERC benchmarks. We
generate six novel datasets, with two tailored to enhance each benchmark. We
evaluate the utility of these datasets to (1) supplement existing datasets for
ERC classification, and (2) analyze the effects of label imbalance in ERC. Our
experimental results indicate that ERC classifier models trained on the
generated datasets exhibit strong robustness and consistently achieve
statistically significant performance improvements on existing ERC benchmarks.

</details>


### [49] [InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs to Enhance Reasoning Capabilities](https://arxiv.org/abs/2508.05496)
*Shuo Cai,Su Lu,Qi Zhou,Kejing Yang,Zhijie Sang,Congkai Xie,Hongxia Yang*

Main category: cs.AI

TL;DR: InfiAlign是一种高效的后训练框架，结合监督微调（SFT）和直接偏好优化（DPO），通过多维质量指标自动筛选高质量数据，显著提升大语言模型的推理能力，同时减少数据需求。


<details>
  <summary>Details</summary>
Motivation: 提升大语言模型的推理能力通常需要大量数据和计算资源，现有方法依赖启发式或任务特定策略，难以扩展。InfiAlign旨在提供一种可扩展且样本高效的后训练解决方案。

Method: InfiAlign整合SFT和DPO，通过多维质量指标自动筛选高质量数据，减少训练数据需求。应用于Qwen2.5-Math-7B-Base模型，仅用12%的数据达到类似性能。

Result: 在AIME 24/25基准测试中，模型平均提升3.89%，数学推理任务表现尤为突出。SFT模型性能与DeepSeek-R1-Distill-Qwen-7B相当。

Conclusion: InfiAlign通过结合数据选择和全阶段后训练，提供了一种高效、可扩展的大模型对齐方案，显著提升推理能力并减少数据依赖。

Abstract: Large language models (LLMs) have exhibited impressive reasoning abilities on
a wide range of complex tasks. However, enhancing these capabilities through
post-training remains resource intensive, particularly in terms of data and
computational cost. Although recent efforts have sought to improve sample
efficiency through selective data curation, existing methods often rely on
heuristic or task-specific strategies that hinder scalability. In this work, we
introduce InfiAlign, a scalable and sample-efficient post-training framework
that integrates supervised fine-tuning (SFT) with Direct Preference
Optimization (DPO) to align LLMs for enhanced reasoning. At the core of
InfiAlign is a robust data selection pipeline that automatically curates
high-quality alignment data from open-source reasoning datasets using
multidimensional quality metrics. This pipeline enables significant performance
gains while drastically reducing data requirements and remains extensible to
new data sources. When applied to the Qwen2.5-Math-7B-Base model, our SFT model
achieves performance on par with DeepSeek-R1-Distill-Qwen-7B, while using only
approximately 12% of the training data, and demonstrates strong generalization
across diverse reasoning tasks. Additional improvements are obtained through
the application of DPO, with particularly notable gains in mathematical
reasoning tasks. The model achieves an average improvement of 3.89% on AIME
24/25 benchmarks. Our results highlight the effectiveness of combining
principled data selection with full-stage post-training, offering a practical
solution for aligning large reasoning models in a scalable and data-efficient
manner. The model checkpoints are available at
https://huggingface.co/InfiX-ai/InfiAlign-Qwen-7B-SFT.

</details>


### [50] [GRAIL:Learning to Interact with Large Knowledge Graphs for Retrieval Augmented Reasoning](https://arxiv.org/abs/2508.05498)
*Ge Chang,Jinbo Su,Jiacheng Liu,Pengfei Yang,Yuhao Shang,Huiwen Zheng,Hongli Ma,Yan Liang,Yuanchun Li,Yunxin Liu*

Main category: cs.AI

TL;DR: GRAIL框架通过结合LLM引导的随机探索和路径过滤，解决了现有RAG方法在处理结构化知识（如知识图谱）时的局限性，显著提升了推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法主要针对非结构化数据，处理结构化知识（如知识图谱）时表现不佳，且图检索方法难以平衡全局结构和精确控制。

Method: GRAIL结合LLM引导的随机探索与路径过滤，建立数据合成管道，并通过两阶段训练学习动态决策策略。

Result: 在三个知识图谱问答数据集上，GRAIL平均准确率提升21.01%，F1值提升22.43%。

Conclusion: GRAIL通过交互式检索范式，有效平衡检索广度与精度，显著提升了知识图谱推理性能。

Abstract: Large Language Models (LLMs) integrated with Retrieval-Augmented Generation
(RAG) techniques have exhibited remarkable performance across a wide range of
domains. However, existing RAG approaches primarily operate on unstructured
data and demonstrate limited capability in handling structured knowledge such
as knowledge graphs. Meanwhile, current graph retrieval methods fundamentally
struggle to capture holistic graph structures while simultaneously facing
precision control challenges that manifest as either critical information gaps
or excessive redundant connections, collectively undermining reasoning
performance. To address this challenge, we propose GRAIL: Graph-Retrieval
Augmented Interactive Learning, a framework designed to interact with
large-scale graphs for retrieval-augmented reasoning. Specifically, GRAIL
integrates LLM-guided random exploration with path filtering to establish a
data synthesis pipeline, where a fine-grained reasoning trajectory is
automatically generated for each task. Based on the synthesized data, we then
employ a two-stage training process to learn a policy that dynamically decides
the optimal actions at each reasoning step. The overall objective of
precision-conciseness balance in graph retrieval is decoupled into fine-grained
process-supervised rewards to enhance data efficiency and training stability.
In practical deployment, GRAIL adopts an interactive retrieval paradigm,
enabling the model to autonomously explore graph paths while dynamically
balancing retrieval breadth and precision. Extensive experiments have shown
that GRAIL achieves an average accuracy improvement of 21.01% and F1
improvement of 22.43% on three knowledge graph question-answering datasets. Our
source code and datasets is available at https://github.com/Changgeww/GRAIL.

</details>


### [51] [Auto-Eval Judge: Towards a General Agentic Framework for Task Completion Evaluation](https://arxiv.org/abs/2508.05508)
*Roshita Bhonsle,Rishav Dutta,Sneha Vavilapalli,Harsh Seth,Abubakarr Jaye,Yapei Chang,Mukund Rungta,Emmanuel Aboah Boateng,Sadid Hasan,Ehi Nosakhare,Soundar Srinivasan*

Main category: cs.AI

TL;DR: 提出了一种通用、模块化的框架，用于评估代理任务完成情况，通过分解任务并验证每个步骤，比现有方法更接近人类评估。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法（如LLM-as-a-Judge）仅关注最终输出，忽略了逐步推理过程；而Agent-as-a-Judge系统又局限于特定领域。需要一种通用框架。

Method: 设计模块化框架，将任务分解为子任务，验证每个步骤，并聚合模块输出以生成最终评估结果。

Result: 在GAIA和BigCodeBench基准测试中，提出的Judge Agent比GPT-4o基线更接近人类评估，对齐准确率分别提高4.76%和10.52%。

Conclusion: 该通用评估框架在任务完成评估中表现出潜力，更接近人类判断。

Abstract: The increasing adoption of foundation models as agents across diverse domains
necessitates a robust evaluation framework. Current methods, such as
LLM-as-a-Judge, focus only on final outputs, overlooking the step-by-step
reasoning that drives agentic decision-making. Meanwhile, existing
Agent-as-a-Judge systems, where one agent evaluates another's task completion,
are typically designed for narrow, domain-specific settings. To address this
gap, we propose a generalizable, modular framework for evaluating agent task
completion independent of the task domain. The framework emulates human-like
evaluation by decomposing tasks into sub-tasks and validating each step using
available information, such as the agent's output and reasoning. Each module
contributes to a specific aspect of the evaluation process, and their outputs
are aggregated to produce a final verdict on task completion. We validate our
framework by evaluating the Magentic-One Actor Agent on two benchmarks, GAIA
and BigCodeBench. Our Judge Agent predicts task success with closer agreement
to human evaluations, achieving 4.76% and 10.52% higher alignment accuracy,
respectively, compared to the GPT-4o based LLM-as-a-Judge baseline. This
demonstrates the potential of our proposed general-purpose evaluation
framework.

</details>


### [52] [Streamlining Admission with LOR Insights: AI-Based Leadership Assessment in Online Master's Program](https://arxiv.org/abs/2508.05513)
*Meryem Yilmaz Soylu,Adrian Gallard,Jeonghyun Lee,Gayane Grigoryan,Rushil Desai,Stephen Harmon*

Main category: cs.AI

TL;DR: LORI是一种基于AI的工具，用于从推荐信中自动检测领导力技能，采用RoBERTa和LLAMA模型，表现优异。


<details>
  <summary>Details</summary>
Motivation: 推荐信评估耗时且主观，需自动化工具支持招生委员会更高效、客观地评估申请者领导力。

Method: 利用自然语言处理和大语言模型（RoBERTa和LLAMA）识别推荐信中的领导力属性（如团队合作、沟通、创新）。

Result: RoBERTa模型在测试数据中表现优异，加权F1分数91.6%，精确率92.4%，召回率91.6%。

Conclusion: LORI工具可提升招生效率，确保对申请者领导力的全面评估，尤其适用于STEM领域。

Abstract: Letters of recommendation (LORs) provide valuable insights into candidates'
capabilities and experiences beyond standardized test scores. However,
reviewing these text-heavy materials is time-consuming and labor-intensive. To
address this challenge and support the admission committee in providing
feedback for students' professional growth, our study introduces LORI: LOR
Insights, a novel AI-based detection tool for assessing leadership skills in
LORs submitted by online master's program applicants. By employing natural
language processing and leveraging large language models using RoBERTa and
LLAMA, we seek to identify leadership attributes such as teamwork,
communication, and innovation. Our latest RoBERTa model achieves a weighted F1
score of 91.6%, a precision of 92.4%, and a recall of 91.6%, showing a strong
level of consistency in our test data. With the growing importance of
leadership skills in the STEM sector, integrating LORI into the graduate
admissions process is crucial for accurately assessing applicants' leadership
capabilities. This approach not only streamlines the admissions process but
also automates and ensures a more comprehensive evaluation of candidates'
capabilities.

</details>


### [53] [MV-Debate: Multi-view Agent Debate with Dynamic Reflection Gating for Multimodal Harmful Content Detection in Social Media](https://arxiv.org/abs/2508.05557)
*Rui Lu,Jinhe Bi,Yunpu Ma,Feng Xiao,Yuntao Du,Yijun Tian*

Main category: cs.AI

TL;DR: MV-Debate是一种多视角代理辩论框架，用于统一多模态有害内容检测，通过动态反思门控优化性能。


<details>
  <summary>Details</summary>
Motivation: 社交媒体中多模态内容的复杂性使得有害意图（如讽刺、仇恨言论或虚假信息）难以识别，需要跨模态分析和动态适应。

Method: 提出MV-Debate框架，包含四个互补的辩论代理（表面分析师、深度推理者、模态对比者和社会情境分析者），通过迭代辩论和动态反思门控优化检测。

Result: 在三个基准数据集上，MV-Debate显著优于单一模型和现有多代理辩论基线。

Conclusion: 多代理辩论框架在提升社交媒体有害意图检测的可靠性和效率方面具有潜力。

Abstract: Social media has evolved into a complex multimodal environment where text,
images, and other signals interact to shape nuanced meanings, often concealing
harmful intent. Identifying such intent, whether sarcasm, hate speech, or
misinformation, remains challenging due to cross-modal contradictions, rapid
cultural shifts, and subtle pragmatic cues. To address these challenges, we
propose MV-Debate, a multi-view agent debate framework with dynamic reflection
gating for unified multimodal harmful content detection. MV-Debate assembles
four complementary debate agents, a surface analyst, a deep reasoner, a
modality contrast, and a social contextualist, to analyze content from diverse
interpretive perspectives. Through iterative debate and reflection, the agents
refine responses under a reflection-gain criterion, ensuring both accuracy and
efficiency. Experiments on three benchmark datasets demonstrate that MV-Debate
significantly outperforms strong single-model and existing multi-agent debate
baselines. This work highlights the promise of multi-agent debate in advancing
reliable social intent detection in safety-critical online contexts.

</details>


### [54] [The Missing Reward: Active Inference in the Era of Experience](https://arxiv.org/abs/2508.05619)
*Bo Wen*

Main category: cs.AI

TL;DR: 论文提出主动推理（AIF）是开发无需持续人工奖励设计的自主AI代理的关键基础，通过最小化自由能量的内在驱动力替代外部奖励信号。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统依赖大量高质量训练数据和人工奖励设计，面临可扩展性挑战，阻碍真正自主智能的发展。

Method: 结合大型语言模型作为生成世界模型与AIF的决策框架，使代理能高效从经验中学习并保持与人类价值观一致。

Result: AIF能填补"接地代理缺口"，使AI系统自主制定、调整和追求目标，平衡探索与利用。

Conclusion: AIF为开发自主且符合约束的AI系统提供了可行路径。

Abstract: This paper argues that Active Inference (AIF) provides a crucial foundation
for developing autonomous AI agents capable of learning from experience without
continuous human reward engineering. As AI systems begin to exhaust
high-quality training data and rely on increasingly large human workforces for
reward design, the current paradigm faces significant scalability challenges
that could impede progress toward genuinely autonomous intelligence. The
proposal for an ``Era of Experience,'' where agents learn from self-generated
data, is a promising step forward. However, this vision still depends on
extensive human engineering of reward functions, effectively shifting the
bottleneck from data curation to reward curation. This highlights what we
identify as the \textbf{grounded-agency gap}: the inability of contemporary AI
systems to autonomously formulate, adapt, and pursue objectives in response to
changing circumstances. We propose that AIF can bridge this gap by replacing
external reward signals with an intrinsic drive to minimize free energy,
allowing agents to naturally balance exploration and exploitation through a
unified Bayesian objective. By integrating Large Language Models as generative
world models with AIF's principled decision-making framework, we can create
agents that learn efficiently from experience while remaining aligned with
human values. This synthesis offers a compelling path toward AI systems that
can develop autonomously while adhering to both computational and physical
constraints.

</details>


### [55] [Simulating Human-Like Learning Dynamics with LLM-Empowered Agents](https://arxiv.org/abs/2508.05622)
*Yu Yuan,Lili Zhao,Wei Chen,Guangting Zheng,Kai Zhang,Mengdi Zhang,Qi Liu*

Main category: cs.AI

TL;DR: LearnerAgent是一个基于LLM的多智能体框架，模拟真实教学环境，分析不同心理特征学习者的动态学习行为。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以捕捉学习动态或提供解释性，因此引入LearnerAgent以解决这些问题。

Method: 构建具有心理特征的学习者（如Deep、Surface、Lazy）和通用学习者，通过知识获取、测试和互动跟踪学习进展。

Result: 1）Deep Learner持续认知增长；2）学习者行为与心理特征一致；3）通用学习者自我效能高；4）基础LLM默认行为为“勤奋但脆弱的Surface Learner”。

Conclusion: LearnerAgent能有效模拟真实场景，揭示LLM行为的深层特征。

Abstract: Capturing human learning behavior based on deep learning methods has become a
major research focus in both psychology and intelligent systems. Recent
approaches rely on controlled experiments or rule-based models to explore
cognitive processes. However, they struggle to capture learning dynamics, track
progress over time, or provide explainability. To address these challenges, we
introduce LearnerAgent, a novel multi-agent framework based on Large Language
Models (LLMs) to simulate a realistic teaching environment. To explore
human-like learning dynamics, we construct learners with psychologically
grounded profiles-such as Deep, Surface, and Lazy-as well as a persona-free
General Learner to inspect the base LLM's default behavior. Through weekly
knowledge acquisition, monthly strategic choices, periodic tests, and peer
interaction, we can track the dynamic learning progress of individual learners
over a full-year journey. Our findings are fourfold: 1) Longitudinal analysis
reveals that only Deep Learner achieves sustained cognitive growth. Our
specially designed "trap questions" effectively diagnose Surface Learner's
shallow knowledge. 2) The behavioral and cognitive patterns of distinct
learners align closely with their psychological profiles. 3) Learners'
self-concept scores evolve realistically, with the General Learner developing
surprisingly high self-efficacy despite its cognitive limitations. 4)
Critically, the default profile of base LLM is a "diligent but brittle Surface
Learner"-an agent that mimics the behaviors of a good student but lacks true,
generalizable understanding. Extensive simulation experiments demonstrate that
LearnerAgent aligns well with real scenarios, yielding more insightful findings
about LLMs' behavior.

</details>
