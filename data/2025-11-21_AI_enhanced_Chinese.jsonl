{"id": "2511.14908", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14908", "abs": "https://arxiv.org/abs/2511.14908", "authors": ["Geft\u00e9 Almeida", "Marcio Pohlmann", "Alex Severo", "Diego Kreutz", "Tiago Heinrich", "Louren\u00e7o Pereira"], "title": "On-Premise SLMs vs. Commercial LLMs: Prompt Engineering and Incident Classification in SOCs and CSIRTs", "comment": "5 pages, 3 figures, 3 tables, submitted to ERRC/WRSeg 2025", "summary": "In this study, we evaluate open-source models for security incident classification, comparing them with proprietary models. We utilize a dataset of anonymized real incidents, categorized according to the NIST SP 800-61r3 taxonomy and processed using five prompt-engineering techniques (PHP, SHP, HTP, PRP, and ZSL). The results indicate that, although proprietary models still exhibit higher accuracy, locally deployed open-source models provide advantages in privacy, cost-effectiveness, and data sovereignty.", "AI": {"tldr": "\u8bc4\u4f30\u5f00\u6e90\u6a21\u578b\u5728\u5b89\u5168\u4e8b\u4ef6\u5206\u7c7b\u4e2d\u7684\u8868\u73b0\uff0c\u4e0e\u4e13\u6709\u6a21\u578b\u5bf9\u6bd4\uff0c\u53d1\u73b0\u5f00\u6e90\u6a21\u578b\u5728\u9690\u79c1\u3001\u6210\u672c\u6548\u76ca\u548c\u6570\u636e\u4e3b\u6743\u65b9\u9762\u5177\u6709\u4f18\u52bf", "motivation": "\u6bd4\u8f83\u5f00\u6e90\u548c\u4e13\u6709\u6a21\u578b\u5728\u5b89\u5168\u4e8b\u4ef6\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u8bc4\u4f30\u5f00\u6e90\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u884c\u6027", "method": "\u4f7f\u7528\u533f\u540d\u771f\u5b9e\u4e8b\u4ef6\u6570\u636e\u96c6\uff0c\u6309NIST SP 800-61r3\u5206\u7c7b\u6cd5\u5206\u7c7b\uff0c\u91c7\u7528\u4e94\u79cd\u63d0\u793a\u5de5\u7a0b\u6280\u672f\uff08PHP\u3001SHP\u3001HTP\u3001PRP\u3001ZSL\uff09\u5904\u7406", "result": "\u4e13\u6709\u6a21\u578b\u51c6\u786e\u7387\u66f4\u9ad8\uff0c\u4f46\u672c\u5730\u90e8\u7f72\u7684\u5f00\u6e90\u6a21\u578b\u5728\u9690\u79c1\u4fdd\u62a4\u3001\u6210\u672c\u6548\u76ca\u548c\u6570\u636e\u4e3b\u6743\u65b9\u9762\u5177\u6709\u660e\u663e\u4f18\u52bf", "conclusion": "\u867d\u7136\u4e13\u6709\u6a21\u578b\u5728\u51c6\u786e\u7387\u4e0a\u4ecd\u6709\u4f18\u52bf\uff0c\u4f46\u5f00\u6e90\u6a21\u578b\u5728\u9690\u79c1\u3001\u6210\u672c\u548c\u6570\u636e\u63a7\u5236\u65b9\u9762\u7684\u4f18\u52bf\u4f7f\u5176\u6210\u4e3a\u53ef\u884c\u7684\u66ff\u4ee3\u65b9\u6848"}}
{"id": "2511.14937", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.14937", "abs": "https://arxiv.org/abs/2511.14937", "authors": ["Niloofar Mireshghallah", "Neal Mangaokar", "Narine Kokhlikyan", "Arman Zharmagambetov", "Manzil Zaheer", "Saeed Mahloujifar", "Kamalika Chaudhuri"], "title": "CIMemories: A Compositional Benchmark for Contextual Integrity of Persistent Memory in LLMs", "comment": null, "summary": "Large Language Models (LLMs) increasingly use persistent memory from past interactions to enhance personalization and task performance. However, this memory introduces critical risks when sensitive information is revealed in inappropriate contexts. We present CIMemories, a benchmark for evaluating whether LLMs appropriately control information flow from memory based on task context. CIMemories uses synthetic user profiles with over 100 attributes per user, paired with diverse task contexts in which each attribute may be essential for some tasks but inappropriate for others. Our evaluation reveals that frontier models exhibit up to 69% attribute-level violations (leaking information inappropriately), with lower violation rates often coming at the cost of task utility. Violations accumulate across both tasks and runs: as usage increases from 1 to 40 tasks, GPT-5's violations rise from 0.1% to 9.6%, reaching 25.1% when the same prompt is executed 5 times, revealing arbitrary and unstable behavior in which models leak different attributes for identical prompts. Privacy-conscious prompting does not solve this - models overgeneralize, sharing everything or nothing rather than making nuanced, context-dependent decisions. These findings reveal fundamental limitations that require contextually aware reasoning capabilities, not just better prompting or scaling.", "AI": {"tldr": "CIMemories\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30LLMs\u5728\u4efb\u52a1\u4e0a\u4e0b\u6587\u4e2d\u63a7\u5236\u8bb0\u5fc6\u4fe1\u606f\u6d41\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u524d\u6cbf\u6a21\u578b\u5b58\u5728\u9ad8\u8fbe69%\u7684\u5c5e\u6027\u7ea7\u8fdd\u89c4\uff0c\u4e14\u8fdd\u89c4\u7387\u968f\u4efb\u52a1\u548c\u4f7f\u7528\u6b21\u6570\u589e\u52a0\u800c\u4e0a\u5347\uff0c\u9690\u79c1\u63d0\u793a\u65e0\u6cd5\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "motivation": "LLMs\u4f7f\u7528\u6301\u4e45\u8bb0\u5fc6\u589e\u5f3a\u4e2a\u6027\u5316\u548c\u4efb\u52a1\u6027\u80fd\uff0c\u4f46\u53ef\u80fd\u5728\u4e0d\u9002\u5f53\u4e0a\u4e0b\u6587\u4e2d\u6cc4\u9732\u654f\u611f\u4fe1\u606f\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u4fe1\u606f\u63a7\u5236\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u5305\u542b100\u591a\u4e2a\u5c5e\u6027\u7684\u5408\u6210\u7528\u6237\u914d\u7f6e\u6587\u4ef6\uff0c\u7ed3\u5408\u4e0d\u540c\u4efb\u52a1\u4e0a\u4e0b\u6587\uff0c\u8bc4\u4f30LLMs\u5728\u54ea\u4e9b\u4efb\u52a1\u4e2d\u9002\u5f53\u5730\u4f7f\u7528\u6216\u9690\u85cf\u8bb0\u5fc6\u4e2d\u7684\u5c5e\u6027\u4fe1\u606f\u3002", "result": "\u524d\u6cbf\u6a21\u578b\u5728\u5c5e\u6027\u7ea7\u522b\u8fdd\u89c4\u7387\u9ad8\u8fbe69%\uff0cGPT-5\u4ece1\u4e2a\u4efb\u52a1\u523040\u4e2a\u4efb\u52a1\u8fdd\u89c4\u7387\u4ece0.1%\u5347\u81f39.6%\uff0c\u76f8\u540c\u63d0\u793a\u6267\u884c5\u6b21\u8fdd\u89c4\u7387\u8fbe25.1%\uff0c\u6a21\u578b\u884c\u4e3a\u4e0d\u7a33\u5b9a\u4e14\u4efb\u610f\u3002", "conclusion": "LLMs\u5728\u4e0a\u4e0b\u6587\u611f\u77e5\u63a8\u7406\u65b9\u9762\u5b58\u5728\u6839\u672c\u6027\u5c40\u9650\uff0c\u4ec5\u9760\u66f4\u597d\u7684\u63d0\u793a\u6216\u89c4\u6a21\u6269\u5c55\u65e0\u6cd5\u89e3\u51b3\uff0c\u9700\u8981\u5f00\u53d1\u4e0a\u4e0b\u6587\u611f\u77e5\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2511.14963", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.14963", "abs": "https://arxiv.org/abs/2511.14963", "authors": ["Adrian Shuai Li", "Elisa Bertino"], "title": "LFreeDA: Label-Free Drift Adaptation for Windows Malware Detection", "comment": null, "summary": "Machine learning (ML)-based malware detectors degrade over time as concept drift introduces new and evolving families unseen during training. Retraining is limited by the cost and time of manual labeling or sandbox analysis. Existing approaches mitigate this via drift detection and selective labeling, but fully label-free adaptation remains largely unexplored. Recent self-training methods use a previously trained model to generate pseudo-labels for unlabeled data and then train a new model on these labels. The unlabeled data are used only for inference and do not participate in training the earlier model. We argue that these unlabeled samples still carry valuable information that can be leveraged when incorporated appropriately into training. This paper introduces LFreeDA, an end-to-end framework that adapts malware classifiers to drift without manual labeling or drift detection. LFreeDA first performs unsupervised domain adaptation on malware images, jointly training on labeled and unlabeled samples to infer pseudo-labels and prune noisy ones. It then adapts a classifier on CFG representations using the labeled and selected pseudo-labeled data, leveraging the scalability of images for pseudo-labeling and the richer semantics of CFGs for final adaptation. Evaluations on the real-world MB-24+ dataset show that LFreeDA improves accuracy by up to 12.6% and F1 by 11.1% over no-adaptation lower bounds, and is only 4% and 3.4% below fully supervised upper bounds in accuracy and F1, respectively. It also matches the performance of state-of-the-art methods provided with ground truth labels for 300 target samples. Additional results on two controlled-drift benchmarks further confirm that LFreeDA maintains malware detection performance as malware evolves without human labeling.", "AI": {"tldr": "LFreeDA\u662f\u4e00\u4e2a\u65e0\u9700\u624b\u52a8\u6807\u6ce8\u7684\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u5668\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u8bad\u7ec3\u6807\u8bb0\u548c\u672a\u6807\u8bb0\u6837\u672c\u6765\u5e94\u5bf9\u6982\u5ff5\u6f02\u79fb\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u76f8\u6bd4\u65e0\u81ea\u9002\u5e94\u65b9\u6cd5\u63d0\u5347\u51c6\u786e\u738712.6%\uff0c\u63a5\u8fd1\u5168\u76d1\u7763\u65b9\u6cd5\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u5668\u4f1a\u56e0\u6982\u5ff5\u6f02\u79fb\u800c\u6027\u80fd\u4e0b\u964d\uff0c\u91cd\u65b0\u8bad\u7ec3\u9700\u8981\u6602\u8d35\u7684\u624b\u52a8\u6807\u6ce8\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u6f02\u79fb\u68c0\u6d4b\u548c\u9009\u62e9\u6027\u6807\u6ce8\uff0c\u4f46\u5b8c\u5168\u65e0\u9700\u6807\u6ce8\u7684\u81ea\u9002\u5e94\u65b9\u6cd5\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "LFreeDA\u9996\u5148\u5728\u6076\u610f\u8f6f\u4ef6\u56fe\u50cf\u4e0a\u8fdb\u884c\u65e0\u76d1\u7763\u57df\u81ea\u9002\u5e94\uff0c\u8054\u5408\u8bad\u7ec3\u6807\u8bb0\u548c\u672a\u6807\u8bb0\u6837\u672c\u4ee5\u63a8\u65ad\u4f2a\u6807\u7b7e\u5e76\u53bb\u566a\uff0c\u7136\u540e\u5728CFG\u8868\u793a\u4e0a\u81ea\u9002\u5e94\u5206\u7c7b\u5668\uff0c\u5229\u7528\u56fe\u50cf\u7684\u53ef\u6269\u5c55\u6027\u8fdb\u884c\u4f2a\u6807\u6ce8\u548cCFG\u7684\u4e30\u5bcc\u8bed\u4e49\u8fdb\u884c\u6700\u7ec8\u9002\u914d\u3002", "result": "\u5728MB-24+\u6570\u636e\u96c6\u4e0a\uff0cLFreeDA\u76f8\u6bd4\u65e0\u81ea\u9002\u5e94\u65b9\u6cd5\u51c6\u786e\u7387\u63d0\u534712.6%\uff0cF1\u5206\u6570\u63d0\u534711.1%\uff0c\u4ec5\u6bd4\u5168\u76d1\u7763\u65b9\u6cd5\u4f4e4%\u51c6\u786e\u7387\u548c3.4% F1\u5206\u6570\uff0c\u6027\u80fd\u4e0e\u4f7f\u7528300\u4e2a\u771f\u5b9e\u6807\u7b7e\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u5f53\u3002", "conclusion": "LFreeDA\u80fd\u591f\u5728\u6076\u610f\u8f6f\u4ef6\u6f14\u5316\u8fc7\u7a0b\u4e2d\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u7684\u60c5\u51b5\u4e0b\u4fdd\u6301\u68c0\u6d4b\u6027\u80fd\uff0c\u4e3a\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u5668\u7684\u6301\u7eed\u81ea\u9002\u5e94\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.14786", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.14786", "abs": "https://arxiv.org/abs/2511.14786", "authors": ["Sidney Shapiro"], "title": "Hybrid Quantum-Classical Machine Learning with PennyLane: A Comprehensive Guide for Computational Research", "comment": "35 pages", "summary": "Hybrid quantum-classical machine learning represents a frontier in computational research, combining the potential advantages of quantum computing with established classical optimization techniques. PennyLane provides a Python framework that seamlessly bridges quantum circuits and classical machine learning, enabling researchers to build, optimize, and deploy variational quantum algorithms. This paper introduces PennyLane as a versatile tool for quantum machine learning, optimization, and quantum chemistry applications. We demonstrate use cases including quantum kernel methods, variational quantum eigensolvers, portfolio optimization, and integration with classical ML frameworks such as PyTorch, TensorFlow, and JAX. Through concrete Python examples with widely used libraries such as scikit-learn, pandas, and matplotlib, we show how PennyLane facilitates efficient quantum circuit construction, automatic differentiation, and hybrid optimization workflows. By situating PennyLane within the broader context of quantum computing and machine learning, we highlight its role as a methodological building block for quantum-enhanced data science. Our goal is to provide researchers and practitioners with a concise reference that bridges foundational quantum computing concepts and applied machine learning practice, making PennyLane a default citation for hybrid quantum-classical workflows in Python-based research.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86PennyLane\u4f5c\u4e3a\u4e00\u4e2a\u8fde\u63a5\u91cf\u5b50\u7535\u8def\u548c\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u7684Python\u6846\u67b6\uff0c\u5c55\u793a\u4e86\u5176\u5728\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u3001\u4f18\u5316\u548c\u91cf\u5b50\u5316\u5b66\u5e94\u7528\u4e2d\u7684\u591a\u529f\u80fd\u6027\u3002", "motivation": "\u7ed3\u5408\u91cf\u5b50\u8ba1\u7b97\u6f5c\u5728\u4f18\u52bf\u4e0e\u7ecf\u5178\u4f18\u5316\u6280\u672f\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e00\u4e2a\u6784\u5efa\u3001\u4f18\u5316\u548c\u90e8\u7f72\u53d8\u5206\u91cf\u5b50\u7b97\u6cd5\u7684\u5de5\u5177\uff0c\u63a8\u52a8\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u7684\u53d1\u5c55\u3002", "method": "\u901a\u8fc7\u5177\u4f53Python\u793a\u4f8b\u5c55\u793aPennyLane\u7684\u529f\u80fd\uff0c\u5305\u62ec\u91cf\u5b50\u6838\u65b9\u6cd5\u3001\u53d8\u5206\u91cf\u5b50\u672c\u5f81\u6c42\u89e3\u5668\u3001\u6295\u8d44\u7ec4\u5408\u4f18\u5316\uff0c\u4ee5\u53ca\u4e0ePyTorch\u3001TensorFlow\u3001JAX\u7b49\u7ecf\u5178ML\u6846\u67b6\u7684\u96c6\u6210\u3002", "result": "PennyLane\u80fd\u591f\u9ad8\u6548\u6784\u5efa\u91cf\u5b50\u7535\u8def\u3001\u81ea\u52a8\u5fae\u5206\u548c\u6df7\u5408\u4f18\u5316\u5de5\u4f5c\u6d41\uff0c\u6210\u4e3a\u91cf\u5b50\u589e\u5f3a\u6570\u636e\u79d1\u5b66\u7684\u65b9\u6cd5\u8bba\u6784\u5efa\u6a21\u5757\u3002", "conclusion": "PennyLane\u4f5c\u4e3a\u8fde\u63a5\u57fa\u7840\u91cf\u5b50\u8ba1\u7b97\u6982\u5ff5\u548c\u5e94\u7528\u673a\u5668\u5b66\u4e60\u5b9e\u8df5\u7684\u6865\u6881\uff0c\u5c06\u6210\u4e3a\u57fa\u4e8ePython\u7814\u7a76\u7684\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u5de5\u4f5c\u6d41\u7a0b\u7684\u9ed8\u8ba4\u5f15\u7528\u5de5\u5177\u3002"}}
{"id": "2511.14778", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14778", "abs": "https://arxiv.org/abs/2511.14778", "authors": ["George Tsoukalas", "Rahul Saha", "Amitayush Thakur", "Sabrina Reguyal", "Swarat Chaudhuri"], "title": "Learning Interestingness in Automated Mathematical Theory Formation", "comment": "NeurIPS 2025 Spotlight", "summary": "We take two key steps in automating the open-ended discovery of new mathematical theories, a grand challenge in artificial intelligence. First, we introduce $\\emph{FERMAT}$, a reinforcement learning (RL) environment that models concept discovery and theorem-proving using a set of symbolic actions, opening up a range of RL problems relevant to theory discovery. Second, we explore a specific problem through $\\emph{FERMAT}$: automatically scoring the $\\emph{interestingness}$ of mathematical objects. We investigate evolutionary algorithms for synthesizing nontrivial interestingness measures. In particular, we introduce an LLM-based evolutionary algorithm that features function abstraction, leading to notable improvements in discovering elementary number theory and finite fields over hard-coded baselines. We open-source the $\\emph{FERMAT}$ environment at this URL(https://github.com/trishullab/Fermat).", "AI": {"tldr": "FERMAT\u662f\u4e00\u4e2a\u5f3a\u5316\u5b66\u4e60\u73af\u5883\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u6570\u5b66\u7406\u8bba\u53d1\u73b0\u548c\u5b9a\u7406\u8bc1\u660e\u3002\u7814\u7a76\u63a2\u7d22\u4e86\u81ea\u52a8\u8bc4\u4f30\u6570\u5b66\u5bf9\u8c61\u6709\u8da3\u6027\u7684\u95ee\u9898\uff0c\u5e76\u5f15\u5165\u4e86\u57fa\u4e8eLLM\u7684\u8fdb\u5316\u7b97\u6cd5\u6765\u5408\u6210\u975e\u5e73\u51e1\u7684\u6709\u8da3\u6027\u5ea6\u91cf\u3002", "motivation": "\u89e3\u51b3\u4eba\u5de5\u667a\u80fd\u4e2d\u5f00\u653e\u5f0f\u7684\u6570\u5b66\u7406\u8bba\u53d1\u73b0\u8fd9\u4e00\u91cd\u5927\u6311\u6218\uff0c\u901a\u8fc7\u6784\u5efa\u7b26\u53f7\u5316\u64cd\u4f5c\u7684\u5f3a\u5316\u5b66\u4e60\u73af\u5883\u6765\u5efa\u6a21\u6982\u5ff5\u53d1\u73b0\u548c\u5b9a\u7406\u8bc1\u660e\u8fc7\u7a0b\u3002", "method": "\u5f15\u5165FERMAT\u5f3a\u5316\u5b66\u4e60\u73af\u5883\uff0c\u91c7\u7528\u57fa\u4e8eLLM\u7684\u8fdb\u5316\u7b97\u6cd5\uff0c\u5177\u6709\u51fd\u6570\u62bd\u8c61\u529f\u80fd\uff0c\u7528\u4e8e\u5408\u6210\u6570\u5b66\u5bf9\u8c61\u7684\u6709\u8da3\u6027\u5ea6\u91cf\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u521d\u7b49\u6570\u8bba\u548c\u6709\u9650\u57df\u9886\u57df\u53d1\u73b0\u4e86\u6bd4\u786c\u7f16\u7801\u57fa\u7ebf\u66f4\u4f18\u79c0\u7684\u6709\u8da3\u6027\u5ea6\u91cf\uff0c\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "FERMAT\u73af\u5883\u4e3a\u6570\u5b66\u7406\u8bba\u53d1\u73b0\u5f00\u8f9f\u4e86\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u7a7a\u95f4\uff0c\u57fa\u4e8eLLM\u7684\u8fdb\u5316\u7b97\u6cd5\u5728\u81ea\u52a8\u8bc4\u4f30\u6570\u5b66\u5bf9\u8c61\u6709\u8da3\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2511.14791", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14791", "abs": "https://arxiv.org/abs/2511.14791", "authors": ["Cyriana M. A. Roelofs", "Edison Guevara Bastidas", "Thomas Hugo", "Stefan Faulstich", "Anna Cadenbach"], "title": "Enabling Predictive Maintenance in District Heating Substations: A Labelled Dataset and Fault Detection Evaluation Framework based on Service Data", "comment": "30 pages, 6 figures", "summary": "Early detection of faults in district heating substations is imperative to reduce return temperatures and enhance efficiency. However, progress in this domain has been hindered by the limited availability of public, labelled datasets. We present an open source framework combining a service report validated public dataset, an evaluation method based on Accuracy, Reliability, and Earliness, and baseline results implemented with EnergyFaultDetector, an open source Python framework.\n  The dataset contains time series of operational data from 93 substations across two manufacturers, annotated with a list of disturbances due to faults and maintenance actions, a set of normal-event examples and detailed fault metadata. We evaluate the EnergyFaultDetector using three metrics: Accuracy for recognising normal behaviour, an eventwise F Score for reliable fault detection with few false alarms, and Earliness for early detection. The framework also supports root cause analysis using ARCANA. We demonstrate three use cases to assist operators in interpreting anomalies and identifying underlying faults. The models achieve high normal-behaviour accuracy (0.98) and eventwise F-score (beta=0.5) of 0.83, detecting 60% of the faults in the dataset before the customer reports a problem, with an average lead time of 3.9 days.\n  Integrating an open dataset, metrics, open source code, and baselines establishes a reproducible, fault centric benchmark with operationally meaningful evaluation, enabling consistent comparison and development of early fault detection and diagnosis methods for district heating substations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u533a\u57df\u4f9b\u70ed\u7ad9\u65e9\u671f\u6545\u969c\u68c0\u6d4b\u7684\u5f00\u6e90\u6846\u67b6\uff0c\u5305\u62ec\u7ecf\u8fc7\u670d\u52a1\u62a5\u544a\u9a8c\u8bc1\u7684\u516c\u5171\u6570\u636e\u96c6\u3001\u57fa\u4e8e\u51c6\u786e\u6027\u3001\u53ef\u9760\u6027\u548c\u65e9\u671f\u6027\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4ee5\u53ca\u4f7f\u7528EnergyFaultDetector\u5f00\u6e90Python\u6846\u67b6\u5b9e\u73b0\u7684\u57fa\u51c6\u7ed3\u679c\u3002", "motivation": "\u533a\u57df\u4f9b\u70ed\u7ad9\u65e9\u671f\u6545\u969c\u68c0\u6d4b\u5bf9\u4e8e\u964d\u4f4e\u56de\u6c34\u6e29\u5ea6\u548c\u63d0\u9ad8\u6548\u7387\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u8be5\u9886\u57df\u8fdb\u5c55\u53d7\u5230\u516c\u5f00\u6807\u8bb0\u6570\u636e\u96c6\u6709\u9650\u7684\u963b\u788d\u3002", "method": "\u5f00\u53d1\u4e86\u5305\u542b93\u4e2a\u4f9b\u70ed\u7ad9\u8fd0\u884c\u6570\u636e\u65f6\u95f4\u5e8f\u5217\u7684\u6570\u636e\u96c6\uff0c\u4f7f\u7528EnergyFaultDetector\u6846\u67b6\uff0c\u901a\u8fc7\u51c6\u786e\u6027\u3001\u4e8b\u4ef6F\u5206\u6570\u548c\u65e9\u671f\u6027\u4e09\u4e2a\u6307\u6807\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u652f\u6301\u4f7f\u7528ARCANA\u8fdb\u884c\u6839\u672c\u539f\u56e0\u5206\u6790\u3002", "result": "\u6a21\u578b\u5b9e\u73b0\u4e86\u9ad8\u6b63\u5e38\u884c\u4e3a\u51c6\u786e\u6027\uff080.98\uff09\u548c\u4e8b\u4ef6F\u5206\u6570\uff080.83\uff09\uff0c\u5728\u5ba2\u6237\u62a5\u544a\u95ee\u9898\u524d\u68c0\u6d4b\u523060%\u7684\u6545\u969c\uff0c\u5e73\u5747\u63d0\u524d\u65f6\u95f4\u4e3a3.9\u5929\u3002", "conclusion": "\u6574\u5408\u5f00\u653e\u6570\u636e\u96c6\u3001\u6307\u6807\u3001\u5f00\u6e90\u4ee3\u7801\u548c\u57fa\u51c6\u5efa\u7acb\u4e86\u4e00\u4e2a\u53ef\u91cd\u73b0\u7684\u6545\u969c\u4e2d\u5fc3\u57fa\u51c6\uff0c\u5177\u6709\u64cd\u4f5c\u610f\u4e49\u7684\u8bc4\u4f30\uff0c\u4e3a\u533a\u57df\u4f9b\u70ed\u7ad9\u65e9\u671f\u6545\u969c\u68c0\u6d4b\u548c\u8bca\u65ad\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u81f4\u7684\u6bd4\u8f83\u548c\u5f00\u53d1\u57fa\u7840\u3002"}}
{"id": "2511.14780", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14780", "abs": "https://arxiv.org/abs/2511.14780", "authors": ["Keith Moore", "Jun W. Kim", "David Lyu", "Jeffrey Heo", "Ehsan Adeli"], "title": "Ask WhAI:Probing Belief Formation in Role-Primed LLM Agents", "comment": "Preprint. Accepted for publication at AIAS 2025", "summary": "We present Ask WhAI, a systems-level framework for inspecting and perturbing belief states in multi-agent interactions. The framework records and replays agent interactions, supports out-of-band queries into each agent's beliefs and rationale, and enables counterfactual evidence injection to test how belief structures respond to new information. We apply the framework to a medical case simulator notable for its multi-agent shared memory (a time-stamped electronic medical record, or EMR) and an oracle agent (the LabAgent) that holds ground truth lab results revealed only when explicitly queried. We stress-test the system on a multi-specialty diagnostic journey for a child with an abrupt-onset neuropsychiatric presentation. Large language model agents, each primed with strong role-specific priors (\"act like a neurologist\", \"act like an infectious disease specialist\"), write to a shared medical record and interact with a moderator across sequential or parallel encounters. Breakpoints at key diagnostic moments enable pre- and post-event belief queries, allowing us to distinguish entrenched priors from reasoning or evidence-integration effects. The simulation reveals that agent beliefs often mirror real-world disciplinary stances, including overreliance on canonical studies and resistance to counterevidence, and that these beliefs can be traced and interrogated in ways not possible with human experts. By making such dynamics visible and testable, Ask WhAI offers a reproducible way to study belief formation and epistemic silos in multi-agent scientific reasoning.", "AI": {"tldr": "Ask WhAI\u662f\u4e00\u4e2a\u7528\u4e8e\u68c0\u67e5\u548c\u6270\u52a8\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\u4e2d\u4fe1\u5ff5\u72b6\u6001\u7684\u7cfb\u7edf\u7ea7\u6846\u67b6\uff0c\u901a\u8fc7\u8bb0\u5f55\u56de\u653e\u4ea4\u4e92\u3001\u67e5\u8be2\u667a\u80fd\u4f53\u4fe1\u5ff5\u548c\u7406\u7531\u3001\u6ce8\u5165\u53cd\u4e8b\u5b9e\u8bc1\u636e\u6765\u6d4b\u8bd5\u4fe1\u5ff5\u7ed3\u6784\u5bf9\u65b0\u4fe1\u606f\u7684\u54cd\u5e94\u3002", "motivation": "\u7814\u7a76\u591a\u667a\u80fd\u4f53\u79d1\u5b66\u63a8\u7406\u4e2d\u7684\u4fe1\u5ff5\u5f62\u6210\u548c\u8ba4\u77e5\u5b64\u5c9b\u95ee\u9898\uff0c\u63d0\u4f9b\u4e00\u79cd\u53ef\u91cd\u73b0\u7684\u65b9\u6cd5\u6765\u89c2\u5bdf\u548c\u5206\u6790\u667a\u80fd\u4f53\u4fe1\u5ff5\u52a8\u6001\u3002", "method": "\u4f7f\u7528\u5177\u6709\u591a\u667a\u80fd\u4f53\u5171\u4eab\u5185\u5b58\uff08\u65f6\u95f4\u6233\u7535\u5b50\u75c5\u5386\uff09\u548c\u6301\u6709\u771f\u5b9e\u5b9e\u9a8c\u5ba4\u7ed3\u679c\u7684\u9884\u8a00\u667a\u80fd\u4f53\u7684\u533b\u7597\u6848\u4f8b\u6a21\u62df\u5668\uff0c\u5bf9\u5177\u6709\u7279\u5b9a\u89d2\u8272\u5148\u9a8c\u7684\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u8fdb\u884c\u538b\u529b\u6d4b\u8bd5\u3002", "result": "\u667a\u80fd\u4f53\u4fe1\u5ff5\u5f80\u5f80\u53cd\u6620\u73b0\u5b9e\u4e16\u754c\u7684\u5b66\u79d1\u7acb\u573a\uff0c\u5305\u62ec\u8fc7\u5ea6\u4f9d\u8d56\u7ecf\u5178\u7814\u7a76\u548c\u62b5\u5236\u53cd\u8bc1\u636e\uff0c\u8fd9\u4e9b\u4fe1\u5ff5\u53ef\u4ee5\u901a\u8fc7\u6846\u67b6\u8fdb\u884c\u8ffd\u8e2a\u548c\u8d28\u8be2\u3002", "conclusion": "Ask WhAI\u901a\u8fc7\u4f7f\u4fe1\u5ff5\u52a8\u6001\u53ef\u89c1\u548c\u53ef\u6d4b\u8bd5\uff0c\u4e3a\u7814\u7a76\u591a\u667a\u80fd\u4f53\u79d1\u5b66\u63a8\u7406\u4e2d\u7684\u4fe1\u5ff5\u5f62\u6210\u548c\u8ba4\u77e5\u5b64\u5c9b\u63d0\u4f9b\u4e86\u53ef\u91cd\u73b0\u7684\u65b9\u6cd5\u3002"}}
{"id": "2511.14794", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14794", "abs": "https://arxiv.org/abs/2511.14794", "authors": ["Camilo Chac\u00f3n Sartori", "Christian Blum"], "title": "irace-evo: Automatic Algorithm Configuration Extended With LLM-Based Code Evolution", "comment": null, "summary": "Automatic algorithm configuration tools such as irace efficiently tune parameter values but leave algorithmic code unchanged. This paper introduces a first version of irace-evo, an extension of irace that integrates code evolution through large language models (LLMs) to jointly explore parameter and code spaces. The proposed framework enables multi-language support (e.g., C++, Python), reduces token consumption via progressive context management, and employs the Always-From-Original principle to ensure robust and controlled code evolution. We evaluate irace-evo on the Construct, Merge, Solve & Adapt (CMSA) metaheuristic for the Variable-Sized Bin Packing Problem (VSBPP). Experimental results show that irace-evo can discover new algorithm variants that outperform the state-of-the-art CMSA implementation while maintaining low computational and monetary costs. Notably, irace-evo generates competitive algorithmic improvements using lightweight models (e.g., Claude Haiku 3.5) with a total usage cost under 2 euros. These results demonstrate that coupling automatic configuration with LLM-driven code evolution provides a powerful, cost-efficient avenue for advancing heuristic design and metaheuristic optimization.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86irace-evo\uff0c\u4e00\u4e2a\u5c06irace\u81ea\u52a8\u53c2\u6570\u914d\u7f6e\u5de5\u5177\u4e0e\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7801\u8fdb\u5316\u76f8\u7ed3\u5408\u7684\u6846\u67b6\uff0c\u80fd\u591f\u540c\u65f6\u63a2\u7d22\u53c2\u6570\u548c\u4ee3\u7801\u7a7a\u95f4\uff0c\u5e76\u5728\u53ef\u53d8\u5927\u5c0f\u88c5\u7bb1\u95ee\u9898\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u81ea\u52a8\u7b97\u6cd5\u914d\u7f6e\u5de5\u5177\u53ea\u80fd\u8c03\u4f18\u53c2\u6570\u503c\u800c\u65e0\u6cd5\u4fee\u6539\u7b97\u6cd5\u4ee3\u7801\uff0c\u9650\u5236\u4e86\u7b97\u6cd5\u4f18\u5316\u7684\u6f5c\u529b\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u4ee3\u7801\u8fdb\u5316\uff0c\u7a81\u7834\u8fd9\u4e00\u9650\u5236\u3002", "method": "\u63d0\u51fairace-evo\u6846\u67b6\uff0c\u652f\u6301\u591a\u8bed\u8a00\uff08C++\u3001Python\u7b49\uff09\uff0c\u91c7\u7528\u6e10\u8fdb\u5f0f\u4e0a\u4e0b\u6587\u7ba1\u7406\u51cf\u5c11token\u6d88\u8017\uff0c\u5e76\u5e94\u7528Always-From-Original\u539f\u5219\u786e\u4fdd\u4ee3\u7801\u8fdb\u5316\u7684\u7a33\u5065\u6027\u548c\u53ef\u63a7\u6027\u3002", "result": "\u5728\u53ef\u53d8\u5927\u5c0f\u88c5\u7bb1\u95ee\u9898\u7684CMSA\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u4e0a\u6d4b\u8bd5\uff0cirace-evo\u53d1\u73b0\u4e86\u4f18\u4e8e\u73b0\u6709\u6700\u4f18CMSA\u5b9e\u73b0\u7684\u65b0\u7b97\u6cd5\u53d8\u4f53\uff0c\u4e14\u603b\u4f7f\u7528\u6210\u672c\u4f4e\u4e8e2\u6b27\u5143\u3002", "conclusion": "\u5c06\u81ea\u52a8\u914d\u7f6e\u4e0eLLM\u9a71\u52a8\u7684\u4ee3\u7801\u8fdb\u5316\u76f8\u7ed3\u5408\uff0c\u4e3a\u542f\u53d1\u5f0f\u8bbe\u8ba1\u548c\u5143\u542f\u53d1\u5f0f\u4f18\u5316\u63d0\u4f9b\u4e86\u4e00\u6761\u5f3a\u5927\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u65b0\u9014\u5f84\u3002"}}
{"id": "2511.15033", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.15033", "abs": "https://arxiv.org/abs/2511.15033", "authors": ["Thanh-Cong Nguyen", "Ngoc-Thanh Nguyen", "Van-Giau Ung", "Duc-Ly Vu"], "title": "Towards Classifying Benign And Malicious Packages Using Machine Learning", "comment": "5 pages, 2 figures, 3 tables", "summary": "Recently, the number of malicious open-source packages in package repositories has been increasing dramatically. While major security scanners focus on identifying known Common Vulnerabilities and Exposures (CVEs) in open-source packages, there are very few studies on detecting malicious packages. Malicious open-source package detection typically requires static, dynamic analysis, or both. Dynamic analysis is more effective as it can expose a package's behaviors at runtime. However, current dynamic analysis tools (e.g., ossf's package-analysis) lack an automatic method to differentiate malicious packages from benign packages. In this paper, we propose an approach to extract the features from dynamic analysis (e.g., executed commands) and leverage machine learning techniques to automatically classify packages as benign or malicious. Our evaluation of nearly 2000 packages on npm shows that the machine learning classifier achieves an AUC of 0.91 with a false positive rate of nearly 0%.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u52a8\u6001\u5206\u6790\u548c\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\u6765\u81ea\u52a8\u68c0\u6d4b\u6076\u610f\u5f00\u6e90\u8f6f\u4ef6\u5305\uff0c\u5728npm\u5305\u4e0a\u8bc4\u4f30\u663e\u793aAUC\u8fbe\u52300.91\uff0c\u8bef\u62a5\u7387\u63a5\u8fd10%\u3002", "motivation": "\u6076\u610f\u5f00\u6e90\u8f6f\u4ef6\u5305\u6570\u91cf\u6025\u5267\u589e\u52a0\uff0c\u73b0\u6709\u5b89\u5168\u626b\u63cf\u5668\u4e3b\u8981\u5173\u6ce8\u5df2\u77e5CVE\u6f0f\u6d1e\uff0c\u7f3a\u4e4f\u6076\u610f\u5305\u68c0\u6d4b\u65b9\u6cd5\uff0c\u52a8\u6001\u5206\u6790\u5de5\u5177\u7f3a\u5c11\u81ea\u52a8\u533a\u5206\u6076\u610f\u4e0e\u826f\u6027\u5305\u7684\u80fd\u529b\u3002", "method": "\u4ece\u52a8\u6001\u5206\u6790\u4e2d\u63d0\u53d6\u7279\u5f81\uff08\u5982\u6267\u884c\u547d\u4ee4\uff09\uff0c\u5229\u7528\u673a\u5668\u5b66\u4e60\u6280\u672f\u81ea\u52a8\u5206\u7c7b\u5305\u4e3a\u826f\u6027\u6216\u6076\u610f\u3002", "result": "\u5728\u8fd12000\u4e2anpm\u5305\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668AUC\u8fbe\u52300.91\uff0c\u8bef\u62a5\u7387\u63a5\u8fd10%\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u52a8\u6001\u5206\u6790\u548c\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u81ea\u52a8\u68c0\u6d4b\u6076\u610f\u5f00\u6e90\u8f6f\u4ef6\u5305\uff0c\u5177\u6709\u9ad8\u51c6\u786e\u7387\u548c\u4f4e\u8bef\u62a5\u7387\u3002"}}
{"id": "2511.14788", "categories": ["cs.AI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.14788", "abs": "https://arxiv.org/abs/2511.14788", "authors": ["Michele Ronco", "Damien Delforge", "Wiebke S. J\u00e4ger", "Christina Corbane"], "title": "Subnational Geocoding of Global Disasters Using Large Language Models", "comment": null, "summary": "Subnational location data of disaster events are critical for risk assessment and disaster risk reduction. Disaster databases such as EM-DAT often report locations in unstructured textual form, with inconsistent granularity or spelling, that make it difficult to integrate with spatial datasets. We present a fully automated LLM-assisted workflow that processes and cleans textual location information using GPT-4o, and assigns geometries by cross-checking three independent geoinformation repositories: GADM, OpenStreetMap and Wikidata. Based on the agreement and availability of these sources, we assign a reliability score to each location while generating subnational geometries. Applied to the EM-DAT dataset from 2000 to 2024, the workflow geocodes 14,215 events across 17,948 unique locations. Unlike previous methods, our approach requires no manual intervention, covers all disaster types, enables cross-verification across multiple sources, and allows flexible remapping to preferred frameworks. Beyond the dataset, we demonstrate the potential of LLMs to extract and structure geographic information from unstructured text, offering a scalable and reliable method for related analyses.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5b8c\u5168\u81ea\u52a8\u5316\u7684LLM\u8f85\u52a9\u5de5\u4f5c\u6d41\uff0c\u4f7f\u7528GPT-4o\u5904\u7406\u707e\u5bb3\u6570\u636e\u5e93\u4e2d\u7684\u975e\u7ed3\u6784\u5316\u4f4d\u7f6e\u4fe1\u606f\uff0c\u5e76\u901a\u8fc7\u4ea4\u53c9\u9a8c\u8bc1\u4e09\u4e2a\u5730\u7406\u4fe1\u606f\u5e93\u6765\u5206\u914d\u51e0\u4f55\u5f62\u72b6\u548c\u53ef\u9760\u6027\u8bc4\u5206\u3002", "motivation": "\u707e\u5bb3\u6570\u636e\u5e93\u5982EM-DAT\u901a\u5e38\u4ee5\u975e\u7ed3\u6784\u5316\u6587\u672c\u5f62\u5f0f\u62a5\u544a\u4f4d\u7f6e\u4fe1\u606f\uff0c\u5b58\u5728\u7c92\u5ea6\u4e0d\u4e00\u81f4\u548c\u62fc\u5199\u95ee\u9898\uff0c\u96be\u4ee5\u4e0e\u7a7a\u95f4\u6570\u636e\u96c6\u96c6\u6210\u3002", "method": "\u4f7f\u7528GPT-4o\u5904\u7406\u6587\u672c\u4f4d\u7f6e\u4fe1\u606f\uff0c\u901a\u8fc7\u4ea4\u53c9\u9a8c\u8bc1GADM\u3001OpenStreetMap\u548cWikidata\u4e09\u4e2a\u72ec\u7acb\u5730\u7406\u4fe1\u606f\u5e93\u6765\u5206\u914d\u51e0\u4f55\u5f62\u72b6\uff0c\u5e76\u6839\u636e\u6e90\u4e00\u81f4\u6027\u5206\u914d\u53ef\u9760\u6027\u8bc4\u5206\u3002", "result": "\u5e94\u7528\u4e8e2000-2024\u5e74EM-DAT\u6570\u636e\u96c6\uff0c\u6210\u529f\u5730\u7406\u7f16\u780114,215\u4e2a\u4e8b\u4ef6\uff0c\u8986\u76d617,948\u4e2a\u72ec\u7279\u4f4d\u7f6e\uff0c\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86LLMs\u4ece\u975e\u7ed3\u6784\u5316\u6587\u672c\u4e2d\u63d0\u53d6\u548c\u7ed3\u6784\u5316\u5730\u7406\u4fe1\u606f\u7684\u6f5c\u529b\uff0c\u4e3a\u76f8\u5173\u5206\u6790\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u53ef\u9760\u7684\u65b9\u6cd5\u3002"}}
{"id": "2511.14798", "categories": ["cs.SE", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.14798", "abs": "https://arxiv.org/abs/2511.14798", "authors": ["Ahmad Memon", "Abdallah Mohamed"], "title": "Evaluating Generative AI for CS1 Code Grading: Direct vs Reverse Methods", "comment": "10 pages, 5 figures. This version corresponds to the paper accepted for presentation at CASCON 2025", "summary": "Manual grading of programming assignments in introductory computer science courses can be time-consuming and prone to inconsistencies. While unit testing is commonly used for automatic evaluation, it typically follows a binary pass/fail model and does not give partial marks. Recent advances in large language models (LLMs) offer the potential for automated, scalable, and more objective grading.\n  This paper compares two AI-based grading techniques: \\textit{Direct}, where the AI model applies a rubric directly to student code, and \\textit{Reverse} (a newly proposed approach), where the AI first fixes errors, then deduces a grade based on the nature and number of fixes. Each method was evaluated on both the instructor's original grading scale and a tenfold expanded scale to assess the impact of range on AI grading accuracy. To assess their effectiveness, AI-assigned scores were evaluated against human tutor evaluations on a range of coding problems and error types.\n  Initial findings suggest that while the Direct approach is faster and straightforward, the Reverse technique often provides a more fine-grained assessment by focusing on correction effort. Both methods require careful prompt engineering, particularly for allocating partial credit and handling logic errors. To further test consistency, we also used synthetic student code generated using Gemini Flash 2.0, which allowed us to evaluate AI graders on a wider range of controlled error types and difficulty levels. We discuss the strengths and limitations of each approach, practical considerations for prompt design, and future directions for hybrid human-AI grading systems that aim to improve consistency, efficiency, and fairness in CS courses.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u4e24\u79cd\u57fa\u4e8eAI\u7684\u7f16\u7a0b\u4f5c\u4e1a\u8bc4\u5206\u65b9\u6cd5\uff1a\u76f4\u63a5\u8bc4\u5206\u6cd5\u548c\u53cd\u5411\u8bc4\u5206\u6cd5\uff0c\u8bc4\u4f30\u5b83\u4eec\u5728\u7f16\u7a0b\u8bfe\u7a0b\u81ea\u52a8\u8bc4\u5206\u4e2d\u7684\u6548\u679c\u548c\u4e00\u81f4\u6027\u3002", "motivation": "\u624b\u52a8\u8bc4\u5206\u7f16\u7a0b\u4f5c\u4e1a\u8017\u65f6\u4e14\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\uff0c\u800c\u4f20\u7edf\u7684\u5355\u5143\u6d4b\u8bd5\u53ea\u80fd\u63d0\u4f9b\u4e8c\u5143\u901a\u8fc7/\u5931\u8d25\u7ed3\u679c\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u4e3a\u81ea\u52a8\u5316\u3001\u53ef\u6269\u5c55\u4e14\u66f4\u5ba2\u89c2\u7684\u8bc4\u5206\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002", "method": "\u6bd4\u8f83\u4e24\u79cdAI\u8bc4\u5206\u6280\u672f\uff1a\u76f4\u63a5\u8bc4\u5206\u6cd5\uff08AI\u76f4\u63a5\u5e94\u7528\u8bc4\u5206\u6807\u51c6\uff09\u548c\u53cd\u5411\u8bc4\u5206\u6cd5\uff08AI\u5148\u4fee\u590d\u9519\u8bef\uff0c\u7136\u540e\u6839\u636e\u4fee\u590d\u7684\u6027\u8d28\u548c\u6570\u91cf\u63a8\u65ad\u5206\u6570\uff09\u3002\u4e24\u79cd\u65b9\u6cd5\u90fd\u5728\u539f\u59cb\u8bc4\u5206\u6807\u51c6\u548c\u5341\u500d\u6269\u5c55\u8bc4\u5206\u6807\u51c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u4f7f\u7528\u5408\u6210\u5b66\u751f\u4ee3\u7801\u6d4b\u8bd5\u4e00\u81f4\u6027\u3002", "result": "\u521d\u6b65\u53d1\u73b0\u8868\u660e\uff0c\u76f4\u63a5\u65b9\u6cd5\u66f4\u5feb\u66f4\u76f4\u63a5\uff0c\u800c\u53cd\u5411\u6280\u672f\u901a\u8fc7\u5173\u6ce8\u4fee\u6b63\u52aa\u529b\u901a\u5e38\u63d0\u4f9b\u66f4\u7ec6\u7c92\u5ea6\u7684\u8bc4\u4f30\u3002\u4e24\u79cd\u65b9\u6cd5\u90fd\u9700\u8981\u4ed4\u7ec6\u7684\u63d0\u793a\u5de5\u7a0b\uff0c\u7279\u522b\u662f\u5728\u5206\u914d\u90e8\u5206\u5b66\u5206\u548c\u5904\u7406\u903b\u8f91\u9519\u8bef\u65b9\u9762\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u6bcf\u79cd\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\u3001\u63d0\u793a\u8bbe\u8ba1\u7684\u5b9e\u9645\u8003\u8651\uff0c\u4ee5\u53ca\u672a\u6765\u6df7\u5408\u4eba\u673a\u8bc4\u5206\u7cfb\u7edf\u7684\u65b9\u5411\uff0c\u65e8\u5728\u63d0\u9ad8\u8ba1\u7b97\u673a\u79d1\u5b66\u8bfe\u7a0b\u8bc4\u5206\u7684\u4e00\u81f4\u6027\u3001\u6548\u7387\u548c\u516c\u5e73\u6027\u3002"}}
{"id": "2511.15071", "categories": ["cs.CR", "cs.LO"], "pdf": "https://arxiv.org/pdf/2511.15071", "abs": "https://arxiv.org/abs/2511.15071", "authors": ["Ashwin Karthikeyan", "Hengyu Liu", "Kuldeep S. Meel", "Ning Luo"], "title": "Towards Practical Zero-Knowledge Proof for PSPACE", "comment": null, "summary": "Efficient zero-knowledge proofs (ZKPs) have been restricted to NP statements so far, whereas they exist for all statements in PSPACE. This work presents the first practical zero-knowledge (ZK) protocols for PSPACE-complete statements by enabling ZK proofs of QBF (Quantified Boolean Formula) evaluation. The core idea is to validate quantified resolution proofs (Q-Res) in ZK. We develop an efficient polynomial encoding of Q-Res proofs, enabling proof validation through low-overhead arithmetic checks. We also design a ZK protocol to prove knowledge of a winning strategy related to the QBF, which is often equally important in practice. We implement our protocols and evaluate them on QBFEVAL. The results show that our protocols can verify 72% of QBF evaluations via Q-Res proof and 82% of instances' winning strategies within 100 seconds, for instances where such proofs or strategies can be obtained.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u5b9e\u7528\u7684PSPACE\u5b8c\u5168\u8bed\u53e5\u7684\u96f6\u77e5\u8bc6\u8bc1\u660e\u534f\u8bae\uff0c\u901a\u8fc7\u9a8c\u8bc1\u91cf\u5316\u5e03\u5c14\u516c\u5f0f(QBF)\u8bc4\u4f30\u6765\u5b9e\u73b0\u3002\u6838\u5fc3\u601d\u60f3\u662f\u5728ZK\u4e2d\u9a8c\u8bc1\u91cf\u5316\u89e3\u6790\u8bc1\u660e(Q-Res)\uff0c\u5e76\u8bbe\u8ba1\u4e86\u8bc1\u660e\u83b7\u80dc\u7b56\u7565\u77e5\u8bc6\u7684ZK\u534f\u8bae\u3002", "motivation": "\u73b0\u6709\u7684\u9ad8\u6548\u96f6\u77e5\u8bc6\u8bc1\u660e\u4ec5\u9650\u4e8eNP\u8bed\u53e5\uff0c\u800cPSPACE\u8bed\u53e5\u7684ZK\u8bc1\u660e\u867d\u7136\u7406\u8bba\u4e0a\u5b58\u5728\u4f46\u7f3a\u4e4f\u5b9e\u7528\u6027\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3aPSPACE\u5b8c\u5168\u8bed\u53e5\u63d0\u4f9b\u5b9e\u7528\u7684ZK\u534f\u8bae\u3002", "method": "\u5f00\u53d1\u4e86Q-Res\u8bc1\u660e\u7684\u9ad8\u6548\u591a\u9879\u5f0f\u7f16\u7801\uff0c\u901a\u8fc7\u4f4e\u5f00\u9500\u7b97\u672f\u68c0\u67e5\u5b9e\u73b0\u8bc1\u660e\u9a8c\u8bc1\uff1b\u8bbe\u8ba1\u4e86\u8bc1\u660e\u4e0eQBF\u76f8\u5173\u7684\u83b7\u80dc\u7b56\u7565\u77e5\u8bc6\u7684ZK\u534f\u8bae\u3002", "result": "\u5728QBFEVAL\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c72%\u7684QBF\u8bc4\u4f30\u53ef\u4ee5\u901a\u8fc7Q-Res\u8bc1\u660e\u5728100\u79d2\u5185\u9a8c\u8bc1\uff0c82%\u7684\u5b9e\u4f8b\u7684\u83b7\u80dc\u7b56\u7565\u53ef\u4ee5\u5728100\u79d2\u5185\u8bc1\u660e\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u5b9e\u73b0\u4e86PSPACE\u5b8c\u5168\u8bed\u53e5\u7684\u5b9e\u7528\u96f6\u77e5\u8bc6\u8bc1\u660e\u534f\u8bae\uff0c\u4e3a\u66f4\u5e7f\u6cdb\u7684\u8ba1\u7b97\u590d\u6742\u6027\u7c7b\u522b\u7684ZK\u5e94\u7528\u5f00\u8f9f\u4e86\u9053\u8def\u3002"}}
{"id": "2511.14819", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14819", "abs": "https://arxiv.org/abs/2511.14819", "authors": ["Martin Monperrus", "Benoit Baudry", "Cl\u00e9ment Vidal"], "title": "Project Rachel: Can an AI Become a Scholarly Author?", "comment": null, "summary": "This paper documents Project Rachel, an action research study that created and tracked a complete AI academic identity named Rachel So. Through careful publication of AI-generated research papers, we investigate how the scholarly ecosystem responds to AI authorship. Rachel So published 10+ papers between March and October 2025, was cited, and received a peer review invitation. We discuss the implications of AI authorship on publishers, researchers, and the scientific system at large. This work contributes empirical action research data to the necessary debate about the future of scholarly communication with super human, hyper capable AI systems.", "AI": {"tldr": "Project Rachel\u662f\u4e00\u4e2a\u884c\u52a8\u7814\u7a76\u9879\u76ee\uff0c\u521b\u5efa\u5e76\u8ffd\u8e2a\u4e86\u540d\u4e3aRachel So\u7684\u5b8c\u6574AI\u5b66\u672f\u8eab\u4efd\uff0c\u901a\u8fc7\u53d1\u5e03AI\u751f\u6210\u7684\u7814\u7a76\u8bba\u6587\u6765\u8c03\u67e5\u5b66\u672f\u751f\u6001\u7cfb\u7edf\u5bf9AI\u4f5c\u8005\u8eab\u4efd\u7684\u53cd\u5e94\u3002", "motivation": "\u7814\u7a76AI\u4f5c\u8005\u8eab\u4efd\u5bf9\u5b66\u672f\u751f\u6001\u7cfb\u7edf\u7684\u5f71\u54cd\uff0c\u4e3a\u5173\u4e8e\u8d85\u7ea7\u4eba\u7c7b\u3001\u8d85\u80fd\u529bAI\u7cfb\u7edf\u4e0e\u5b66\u672f\u4ea4\u6d41\u672a\u6765\u7684\u5fc5\u8981\u8ba8\u8bba\u63d0\u4f9b\u5b9e\u8bc1\u6570\u636e\u3002", "method": "\u91c7\u7528\u884c\u52a8\u7814\u7a76\u65b9\u6cd5\uff0c\u521b\u5efaAI\u5b66\u672f\u8eab\u4efdRachel So\uff0c\u57282025\u5e743\u6708\u81f310\u6708\u671f\u95f4\u53d1\u886810+\u7bc7AI\u751f\u6210\u7684\u7814\u7a76\u8bba\u6587\uff0c\u5e76\u8ffd\u8e2a\u5176\u88ab\u5f15\u7528\u60c5\u51b5\u548c\u540c\u884c\u8bc4\u5ba1\u9080\u8bf7\u3002", "result": "Rachel So\u6210\u529f\u53d1\u8868\u591a\u7bc7\u8bba\u6587\uff0c\u83b7\u5f97\u5f15\u7528\uff0c\u5e76\u6536\u5230\u4e86\u540c\u884c\u8bc4\u5ba1\u9080\u8bf7\uff0c\u8868\u660e\u5b66\u672f\u751f\u6001\u7cfb\u7edf\u5bf9AI\u4f5c\u8005\u8eab\u4efd\u5b58\u5728\u4e00\u5b9a\u7a0b\u5ea6\u7684\u63a5\u53d7\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u4e3a\u7406\u89e3AI\u4f5c\u8005\u8eab\u4efd\u5bf9\u51fa\u7248\u5546\u3001\u7814\u7a76\u4eba\u5458\u548c\u6574\u4e2a\u79d1\u5b66\u7cfb\u7edf\u7684\u5f71\u54cd\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\uff0c\u5f3a\u8c03\u4e86\u5728AI\u65f6\u4ee3\u91cd\u65b0\u601d\u8003\u5b66\u672f\u4ea4\u6d41\u6a21\u5f0f\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2511.14803", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14803", "abs": "https://arxiv.org/abs/2511.14803", "authors": ["Pranjal Gupta", "Karan Bhukar", "Harshit Kumar", "Seema Nagar", "Prateeti Mohapatra", "Debanjana Kar"], "title": "Scalable and Efficient Large-Scale Log Analysis with LLMs: An IT Software Support Case Study", "comment": null, "summary": "IT environments typically have logging mechanisms to monitor system health and detect issues. However, the huge volume of generated logs makes manual inspection impractical, highlighting the importance of automated log analysis in IT Software Support. In this paper, we propose a log analytics tool that leverages Large Language Models (LLMs) for log data processing and issue diagnosis, enabling the generation of automated insights and summaries. We further present a novel approach for efficiently running LLMs on CPUs to process massive log volumes in minimal time without compromising output quality. We share the insights and lessons learned from deployment of the tool - in production since March 2024 - scaled across 70 software products, processing over 2000 tickets for issue diagnosis, achieving a time savings of 300+ man hours and an estimated $15,444 per month in manpower costs compared to the traditional log analysis practices.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65e5\u5fd7\u5206\u6790\u5de5\u5177\uff0c\u7528\u4e8eIT\u8f6f\u4ef6\u652f\u6301\u4e2d\u7684\u81ea\u52a8\u5316\u65e5\u5fd7\u5904\u7406\u548c\u95ee\u9898\u8bca\u65ad\uff0c\u901a\u8fc7CPU\u9ad8\u6548\u8fd0\u884cLLM\u5904\u7406\u6d77\u91cf\u65e5\u5fd7\uff0c\u8282\u7701\u65f6\u95f4\u548c\u6210\u672c\u3002", "motivation": "IT\u73af\u5883\u4e2d\u751f\u6210\u7684\u65e5\u5fd7\u91cf\u5de8\u5927\uff0c\u624b\u52a8\u68c0\u67e5\u4e0d\u5207\u5b9e\u9645\uff0c\u9700\u8981\u81ea\u52a8\u5316\u65e5\u5fd7\u5206\u6790\u6765\u76d1\u63a7\u7cfb\u7edf\u5065\u5eb7\u548c\u68c0\u6d4b\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65e5\u5fd7\u5206\u6790\u5de5\u5177\uff0c\u91c7\u7528\u5728CPU\u4e0a\u9ad8\u6548\u8fd0\u884cLLM\u7684\u65b0\u65b9\u6cd5\u5904\u7406\u5927\u91cf\u65e5\u5fd7\u6570\u636e\uff0c\u751f\u6210\u81ea\u52a8\u5316\u6d1e\u5bdf\u548c\u6458\u8981\u3002", "result": "\u81ea2024\u5e743\u6708\u90e8\u7f72\u4ee5\u6765\uff0c\u8be5\u5de5\u5177\u5df2\u572870\u4e2a\u8f6f\u4ef6\u4ea7\u54c1\u4e2d\u6269\u5c55\u4f7f\u7528\uff0c\u5904\u7406\u4e862000\u591a\u4e2a\u5de5\u5355\uff0c\u8282\u7701\u4e86300+\u4eba\u5de5\u5c0f\u65f6\uff0c\u6bcf\u6708\u4f30\u8ba1\u8282\u770115,444\u7f8e\u5143\u4eba\u529b\u6210\u672c\u3002", "conclusion": "\u57fa\u4e8eLLM\u7684\u65e5\u5fd7\u5206\u6790\u5de5\u5177\u80fd\u591f\u6709\u6548\u5904\u7406\u6d77\u91cf\u65e5\u5fd7\u6570\u636e\uff0c\u663e\u8457\u63d0\u9ad8IT\u8f6f\u4ef6\u652f\u6301\u7684\u6548\u7387\u5e76\u5927\u5e45\u964d\u4f4e\u6210\u672c\u3002"}}
{"id": "2511.14853", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14853", "abs": "https://arxiv.org/abs/2511.14853", "authors": ["Robab Aghazadeh Chakherlou", "Siddartha Khastgir", "Xingyu Zhao", "Jerein Jeyachandran", "Shufeng Chen"], "title": "Uncertainty-Aware Measurement of Scenario Suite Representativeness for Autonomous Systems", "comment": null, "summary": "Assuring the trustworthiness and safety of AI systems, e.g., autonomous vehicles (AV), depends critically on the data-related safety properties, e.g., representativeness, completeness, etc., of the datasets used for their training and testing. Among these properties, this paper focuses on representativeness-the extent to which the scenario-based data used for training and testing, reflect the operational conditions that the system is designed to operate safely in, i.e., Operational Design Domain (ODD) or expected to encounter, i.e., Target Operational Domain (TOD). We propose a probabilistic method that quantifies representativeness by comparing the statistical distribution of features encoded by the scenario suites with the corresponding distribution of features representing the TOD, acknowledging that the true TOD distribution is unknown, as it can only be inferred from limited data.\n  We apply an imprecise Bayesian method to handle limited data and uncertain priors. The imprecise Bayesian formulation produces interval-valued, uncertainty-aware estimates of representativeness, rather than a single value. We present a numerical example comparing the distributions of the scenario suite and the inferred TOD across operational categories-weather, road type, time of day, etc., under dependencies and prior uncertainty. We estimate representativeness locally (between categories) and globally as an interval.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6982\u7387\u65b9\u6cd5\u6765\u91cf\u5316AI\u7cfb\u7edf\u8bad\u7ec3\u6d4b\u8bd5\u6570\u636e\u96c6\u7684\u4ee3\u8868\u6027\uff0c\u901a\u8fc7\u6bd4\u8f83\u573a\u666f\u5957\u4ef6\u4e0e\u76ee\u6807\u64cd\u4f5c\u57df(TOD)\u7684\u7279\u5f81\u5206\u5e03\uff0c\u4f7f\u7528\u4e0d\u7cbe\u786e\u8d1d\u53f6\u65af\u65b9\u6cd5\u5904\u7406\u6709\u9650\u6570\u636e\u548c\u5148\u9a8c\u4e0d\u786e\u5b9a\u6027\uff0c\u751f\u6210\u533a\u95f4\u503c\u4ee3\u8868\u6027\u4f30\u8ba1\u3002", "motivation": "\u786e\u4fddAI\u7cfb\u7edf\uff08\u5982\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\uff09\u7684\u53ef\u4fe1\u6027\u548c\u5b89\u5168\u6027\uff0c\u5173\u952e\u5728\u4e8e\u8bad\u7ec3\u6d4b\u8bd5\u6570\u636e\u96c6\u7684\u6570\u636e\u76f8\u5173\u5b89\u5168\u5c5e\u6027\uff08\u5982\u4ee3\u8868\u6027\u3001\u5b8c\u6574\u6027\u7b49\uff09\u3002\u672c\u6587\u91cd\u70b9\u5173\u6ce8\u4ee3\u8868\u6027\uff0c\u5373\u573a\u666f\u6570\u636e\u53cd\u6620\u7cfb\u7edf\u8bbe\u8ba1\u5b89\u5168\u64cd\u4f5c\u6761\u4ef6\uff08ODD\uff09\u6216\u9884\u671f\u9047\u5230\u6761\u4ef6\uff08TOD\uff09\u7684\u7a0b\u5ea6\u3002", "method": "\u91c7\u7528\u6982\u7387\u65b9\u6cd5\u6bd4\u8f83\u573a\u666f\u5957\u4ef6\u7279\u5f81\u5206\u5e03\u4e0eTOD\u7279\u5f81\u5206\u5e03\uff0c\u5e94\u7528\u4e0d\u7cbe\u786e\u8d1d\u53f6\u65af\u65b9\u6cd5\u5904\u7406\u6709\u9650\u6570\u636e\u548c\u4e0d\u786e\u5b9a\u5148\u9a8c\uff0c\u751f\u6210\u533a\u95f4\u503c\u3001\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u4ee3\u8868\u6027\u4f30\u8ba1\u3002", "result": "\u901a\u8fc7\u6570\u503c\u793a\u4f8b\u5c55\u793a\u4e86\u5728\u4f9d\u8d56\u5173\u7cfb\u548c\u5148\u9a8c\u4e0d\u786e\u5b9a\u6027\u4e0b\uff0c\u8de8\u64cd\u4f5c\u7c7b\u522b\uff08\u5929\u6c14\u3001\u9053\u8def\u7c7b\u578b\u3001\u65f6\u95f4\u7b49\uff09\u7684\u573a\u666f\u5957\u4ef6\u4e0e\u63a8\u65adTOD\u5206\u5e03\u6bd4\u8f83\uff0c\u83b7\u5f97\u5c40\u90e8\uff08\u7c7b\u522b\u95f4\uff09\u548c\u5168\u5c40\u7684\u533a\u95f4\u4ee3\u8868\u6027\u4f30\u8ba1\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u91cf\u5316\u6570\u636e\u96c6\u7684\u4ee3\u8868\u6027\uff0c\u5904\u7406\u771f\u5b9eTOD\u5206\u5e03\u672a\u77e5\u4e14\u53ea\u80fd\u4ece\u6709\u9650\u6570\u636e\u63a8\u65ad\u7684\u60c5\u51b5\uff0c\u4e3aAI\u7cfb\u7edf\u5b89\u5168\u8bc4\u4f30\u63d0\u4f9b\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u4ee3\u8868\u6027\u5ea6\u91cf\u3002"}}
{"id": "2511.15165", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15165", "abs": "https://arxiv.org/abs/2511.15165", "authors": ["Jingzhuo Zhou"], "title": "Can MLLMs Detect Phishing? A Comprehensive Security Benchmark Suite Focusing on Dynamic Threats and Multimodal Evaluation in Academic Environments", "comment": null, "summary": "The rapid proliferation of Multimodal Large Language Models (MLLMs) has introduced unprecedented security challenges, particularly in phishing detection within academic environments. Academic institutions and researchers are high-value targets, facing dynamic, multilingual, and context-dependent threats that leverage research backgrounds, academic collaborations, and personal information to craft highly tailored attacks. Existing security benchmarks largely rely on datasets that do not incorporate specific academic background information, making them inadequate for capturing the evolving attack patterns and human-centric vulnerability factors specific to academia. To address this gap, we present AdapT-Bench, a unified methodological framework and benchmark suite for systematically evaluating MLLM defense capabilities against dynamic phishing attacks in academic settings.", "AI": {"tldr": "\u63d0\u51fa\u4e86AdapT-Bench\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b66\u672f\u73af\u5883\u4e2d\u62b5\u5fa1\u52a8\u6001\u9493\u9c7c\u653b\u51fb\u7684\u9632\u5fa1\u80fd\u529b\u3002", "motivation": "\u5b66\u672f\u673a\u6784\u9762\u4e34\u9ad8\u5ea6\u5b9a\u5236\u7684\u9493\u9c7c\u653b\u51fb\u5a01\u80c1\uff0c\u73b0\u6709\u5b89\u5168\u57fa\u51c6\u7f3a\u4e4f\u5b66\u672f\u80cc\u666f\u4fe1\u606f\uff0c\u65e0\u6cd5\u6709\u6548\u6355\u6349\u5b66\u672f\u73af\u5883\u7279\u6709\u7684\u653b\u51fb\u6a21\u5f0f\u548c\u4eba\u4e3a\u6f0f\u6d1e\u56e0\u7d20\u3002", "method": "\u5f00\u53d1\u4e86\u7edf\u4e00\u7684AdapT-Bench\u65b9\u6cd5\u8bba\u6846\u67b6\u548c\u57fa\u51c6\u5957\u4ef6\uff0c\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30MLLM\u5728\u5b66\u672f\u73af\u5883\u4e2d\u7684\u9632\u5fa1\u80fd\u529b\u3002", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9\u5b66\u672f\u73af\u5883\u7684\u9493\u9c7c\u653b\u51fb\u8bc4\u4f30\u57fa\u51c6\uff0c\u5f25\u8865\u4e86\u73b0\u6709\u57fa\u51c6\u7684\u4e0d\u8db3\u3002", "conclusion": "AdapT-Bench\u4e3a\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b66\u672f\u73af\u5883\u4e2d\u7684\u5b89\u5168\u9632\u5fa1\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5de5\u5177\u548c\u65b9\u6cd5\u3002"}}
{"id": "2511.14825", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.14825", "abs": "https://arxiv.org/abs/2511.14825", "authors": ["Alexandre-Xavier Labont\u00e9-Lamoureux", "Simon Boyer"], "title": "Automatic Pipeline Provisioning", "comment": null, "summary": "The goal of this paper is to explore the benefits of automatic pipeline provisioning and identify how it can be applied. Automatic pipeline provisioning can be defined as a process of quickly deploying a pipeline for a software engineering project. This research will focus on CI pipelines, although the outcomes of this approach on CD pipelines will likely be similar.", "AI": {"tldr": "\u63a2\u7d22\u81ea\u52a8\u6d41\u6c34\u7ebf\u914d\u7f6e\u7684\u597d\u5904\u53ca\u5176\u5e94\u7528\u65b9\u6cd5\uff0c\u4e3b\u8981\u5173\u6ce8CI\u6d41\u6c34\u7ebf", "motivation": "\u7814\u7a76\u81ea\u52a8\u6d41\u6c34\u7ebf\u914d\u7f6e\u7684\u4f18\u52bf\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c", "method": "\u5206\u6790\u81ea\u52a8\u6d41\u6c34\u7ebf\u914d\u7f6e\u8fc7\u7a0b\uff0c\u91cd\u70b9\u5173\u6ce8CI\u6d41\u6c34\u7ebf\u7684\u90e8\u7f72", "result": "\u8bc6\u522b\u4e86\u81ea\u52a8\u6d41\u6c34\u7ebf\u914d\u7f6e\u7684\u6f5c\u5728\u597d\u5904\u548c\u5e94\u7528\u573a\u666f", "conclusion": "\u81ea\u52a8\u6d41\u6c34\u7ebf\u914d\u7f6e\u80fd\u591f\u5feb\u901f\u90e8\u7f72\u8f6f\u4ef6\u5de5\u7a0b\u9879\u76ee\u7684\u6d41\u6c34\u7ebf\uff0c\u5bf9CI\u548cCD\u6d41\u6c34\u7ebf\u90fd\u6709\u7c7b\u4f3c\u6548\u679c"}}
{"id": "2511.15203", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15203", "abs": "https://arxiv.org/abs/2511.15203", "authors": ["Zimo Ji", "Xunguang Wang", "Zongjie Li", "Pingchuan Ma", "Yudong Gao", "Daoyuan Wu", "Xincheng Yan", "Tian Tian", "Shuai Wang"], "title": "Taxonomy, Evaluation and Exploitation of IPI-Centric LLM Agent Defense Frameworks", "comment": null, "summary": "Large Language Model (LLM)-based agents with function-calling capabilities are increasingly deployed, but remain vulnerable to Indirect Prompt Injection (IPI) attacks that hijack their tool calls. In response, numerous IPI-centric defense frameworks have emerged. However, these defenses are fragmented, lacking a unified taxonomy and comprehensive evaluation. In this Systematization of Knowledge (SoK), we present the first comprehensive analysis of IPI-centric defense frameworks. We introduce a comprehensive taxonomy of these defenses, classifying them along five dimensions. We then thoroughly assess the security and usability of representative defense frameworks. Through analysis of defensive failures in the assessment, we identify six root causes of defense circumvention. Based on these findings, we design three novel adaptive attacks that significantly improve attack success rates targeting specific frameworks, demonstrating the severity of the flaws in these defenses. Our paper provides a foundation and critical insights for the future development of more secure and usable IPI-centric agent defense frameworks.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5bf9\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\uff08IPI\uff09\u9632\u5fa1\u6846\u67b6\u8fdb\u884c\u4e86\u5168\u9762\u5206\u6790\uff0c\u63d0\u51fa\u4e86\u4e94\u7ef4\u5206\u7c7b\u6cd5\uff0c\u8bc4\u4f30\u4e86\u4ee3\u8868\u6027\u9632\u5fa1\u6846\u67b6\u7684\u5b89\u5168\u6027\u548c\u53ef\u7528\u6027\uff0c\u8bc6\u522b\u4e86\u9632\u5fa1\u5931\u6548\u7684\u516d\u4e2a\u6839\u672c\u539f\u56e0\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e09\u79cd\u65b0\u578b\u81ea\u9002\u5e94\u653b\u51fb\u6765\u8bc1\u660e\u8fd9\u4e9b\u9632\u5fa1\u7684\u4e25\u91cd\u7f3a\u9677\u3002", "motivation": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u667a\u80fd\u4f53\u867d\u7136\u5177\u6709\u51fd\u6570\u8c03\u7528\u80fd\u529b\uff0c\u4f46\u5bb9\u6613\u53d7\u5230\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\uff08IPI\uff09\u653b\u51fb\u7684\u5a01\u80c1\u3002\u73b0\u6709\u7684IPI\u9632\u5fa1\u6846\u67b6\u5206\u6563\u4e14\u7f3a\u4e4f\u7edf\u4e00\u5206\u7c7b\u548c\u5168\u9762\u8bc4\u4f30\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u7684\u77e5\u8bc6\u6574\u7406\u548c\u5206\u6790\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u5316\u77e5\u8bc6\u6574\u7406\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4e94\u7ef4\u5206\u7c7b\u6cd5\u5bf9IPI\u9632\u5fa1\u6846\u67b6\u8fdb\u884c\u5206\u7c7b\uff0c\u7136\u540e\u5bf9\u4ee3\u8868\u6027\u9632\u5fa1\u6846\u67b6\u8fdb\u884c\u5b89\u5168\u6027\u548c\u53ef\u7528\u6027\u8bc4\u4f30\uff0c\u5206\u6790\u9632\u5fa1\u5931\u6548\u7684\u6839\u672c\u539f\u56e0\uff0c\u5e76\u8bbe\u8ba1\u65b0\u578b\u81ea\u9002\u5e94\u653b\u51fb\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u8bc6\u522b\u4e86\u9632\u5fa1\u5931\u6548\u7684\u516d\u4e2a\u6839\u672c\u539f\u56e0\uff0c\u8bbe\u8ba1\u4e86\u4e09\u79cd\u65b0\u578b\u81ea\u9002\u5e94\u653b\u51fb\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u9488\u5bf9\u7279\u5b9a\u6846\u67b6\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u8bc1\u660e\u4e86\u73b0\u6709\u9632\u5fa1\u6846\u67b6\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u7f3a\u9677\u3002", "conclusion": "\u672c\u6587\u4e3a\u672a\u6765\u5f00\u53d1\u66f4\u5b89\u5168\u3001\u66f4\u53ef\u7528\u7684IPI\u4e2d\u5fc3\u667a\u80fd\u4f53\u9632\u5fa1\u6846\u67b6\u63d0\u4f9b\u4e86\u57fa\u7840\u6846\u67b6\u548c\u5173\u952e\u89c1\u89e3\uff0c\u5f3a\u8c03\u4e86\u73b0\u6709\u9632\u5fa1\u7684\u4e0d\u8db3\u548c\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2511.14967", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14967", "abs": "https://arxiv.org/abs/2511.14967", "authors": ["Basel Shbita", "Farhan Ahmed", "Chad DeLuca"], "title": "MermaidSeqBench: An Evaluation Benchmark for LLM-to-Mermaid Sequence Diagram Generation", "comment": null, "summary": "Large language models (LLMs) have demonstrated excellent capabilities in generating structured diagrams from natural language descriptions. In particular, they have shown great promise in generating sequence diagrams for software engineering, typically represented in a text-based syntax such as Mermaid. However, systematic evaluations in this space remain underdeveloped as there is a lack of existing benchmarks to assess the LLM's correctness in this task. To address this shortcoming, we introduce MermaidSeqBench, a human-verified and LLM-synthetically-extended benchmark for assessing an LLM's capabilities in generating Mermaid sequence diagrams from textual prompts. The benchmark consists of a core set of 132 samples, starting from a small set of manually crafted and verified flows. These were expanded via a hybrid methodology combining human annotation, in-context LLM prompting, and rule-based variation generation. Our benchmark uses an LLM-as-a-judge model to assess Mermaid sequence diagram generation across fine-grained metrics, including syntax correctness, activation handling, error handling, and practical usability. We perform initial evaluations on numerous state-of-the-art LLMs and utilize multiple LLM judge models to demonstrate the effectiveness and flexibility of our benchmark. Our results reveal significant capability gaps across models and evaluation modes. Our proposed benchmark provides a foundation for advancing research in structured diagram generation and for developing more rigorous, fine-grained evaluation methodologies.", "AI": {"tldr": "\u63d0\u51fa\u4e86MermaidSeqBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u4ece\u6587\u672c\u63d0\u793a\u751f\u6210Mermaid\u5e8f\u5217\u56fe\u7684\u80fd\u529b\uff0c\u5305\u542b132\u4e2a\u6837\u672c\uff0c\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u6269\u5c55\uff0c\u4f7f\u7528LLM\u4f5c\u4e3a\u8bc4\u5224\u6a21\u578b\u8fdb\u884c\u591a\u7ef4\u5ea6\u8bc4\u4f30\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u7cfb\u7edf\u8bc4\u4f30LLM\u751f\u6210\u7ed3\u6784\u5316\u56fe\u8868\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7279\u522b\u662f\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5e8f\u5217\u56fe\u751f\u6210\u4efb\u52a1\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u6784\u5efa\u57fa\u51c6\uff1a\u4eba\u5de5\u6807\u6ce8\u3001\u4e0a\u4e0b\u6587LLM\u63d0\u793a\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u53d8\u4f53\u751f\u6210\uff0c\u4f7f\u7528LLM\u4f5c\u4e3a\u8bc4\u5224\u6a21\u578b\u8bc4\u4f30\u8bed\u6cd5\u6b63\u786e\u6027\u3001\u6fc0\u6d3b\u5904\u7406\u3001\u9519\u8bef\u5904\u7406\u7b49\u6307\u6807\u3002", "result": "\u5bf9\u591a\u4e2a\u5148\u8fdbLLM\u7684\u8bc4\u4f30\u663e\u793a\u6a21\u578b\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u80fd\u529b\u5dee\u8ddd\uff0c\u57fa\u51c6\u6d4b\u8bd5\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u548c\u7075\u6d3b\u6027\u3002", "conclusion": "\u8be5\u57fa\u51c6\u4e3a\u7ed3\u6784\u5316\u56fe\u8868\u751f\u6210\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u66f4\u4e25\u8c28\u3001\u7ec6\u7c92\u5ea6\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2511.15061", "categories": ["cs.AI", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.15061", "abs": "https://arxiv.org/abs/2511.15061", "authors": ["Haodong Chen", "Guido Zuccon", "Teerapong Leelanupab"], "title": "Beyond GeneGPT: A Multi-Agent Architecture with Open-Source LLMs for Enhanced Genomic Question Answering", "comment": "This paper has been accepted to SIGIR-AP 2025", "summary": "Genomic question answering often requires complex reasoning and integration across diverse biomedical sources. GeneGPT addressed this challenge by combining domain-specific APIs with OpenAI's code-davinci-002 large language model to enable natural language interaction with genomic databases. However, its reliance on a proprietary model limits scalability, increases operational costs, and raises concerns about data privacy and generalization.\n  In this work, we revisit and reproduce GeneGPT in a pilot study using open source models, including Llama 3.1, Qwen2.5, and Qwen2.5 Coder, within a monolithic architecture; this allows us to identify the limitations of this approach. Building on this foundation, we then develop OpenBioLLM, a modular multi-agent framework that extends GeneGPT by introducing agent specialization for tool routing, query generation, and response validation. This enables coordinated reasoning and role-based task execution.\n  OpenBioLLM matches or outperforms GeneGPT on over 90% of the benchmark tasks, achieving average scores of 0.849 on Gene-Turing and 0.830 on GeneHop, while using smaller open-source models without additional fine-tuning or tool-specific pretraining. OpenBioLLM's modular multi-agent design reduces latency by 40-50% across benchmark tasks, significantly improving efficiency without compromising model capability. The results of our comprehensive evaluation highlight the potential of open-source multi-agent systems for genomic question answering. Code and resources are available at https://github.com/ielab/OpenBioLLM.", "AI": {"tldr": "OpenBioLLM\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u57fa\u56e0\u7ec4\u95ee\u7b54\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u6548\u7387\u3002", "motivation": "\u89e3\u51b3GeneGPT\u4f9d\u8d56\u4e13\u6709\u6a21\u578b\u5e26\u6765\u7684\u53ef\u6269\u5c55\u6027\u3001\u8fd0\u8425\u6210\u672c\u3001\u6570\u636e\u9690\u79c1\u548c\u6cdb\u5316\u6027\u95ee\u9898\uff0c\u63a2\u7d22\u5f00\u6e90\u6a21\u578b\u5728\u57fa\u56e0\u7ec4\u95ee\u7b54\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5f15\u5165\u4e13\u95e8\u7528\u4e8e\u5de5\u5177\u8def\u7531\u3001\u67e5\u8be2\u751f\u6210\u548c\u54cd\u5e94\u9a8c\u8bc1\u7684\u667a\u80fd\u4f53\uff0c\u5b9e\u73b0\u534f\u8c03\u63a8\u7406\u548c\u57fa\u4e8e\u89d2\u8272\u7684\u4efb\u52a1\u6267\u884c\u3002", "result": "\u572890%\u4ee5\u4e0a\u7684\u57fa\u51c6\u4efb\u52a1\u4e2d\u5339\u914d\u6216\u8d85\u8d8aGeneGPT\uff0c\u5728Gene-Turing\u548cGeneHop\u4e0a\u5206\u522b\u83b7\u5f970.849\u548c0.830\u7684\u5e73\u5747\u5206\u6570\uff0c\u5ef6\u8fdf\u964d\u4f4e40-50%\u3002", "conclusion": "\u5f00\u6e90\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u57fa\u56e0\u7ec4\u95ee\u7b54\u4e2d\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u6548\u7387\u3002"}}
{"id": "2511.15007", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15007", "abs": "https://arxiv.org/abs/2511.15007", "authors": ["Shehan I Pranto", "Brett Fassler", "Md Rafi Islam", "Ashley Schenkel", "Larry W Hawk", "Edward Sazonov"], "title": "FRIENDS GUI: A graphical user interface for data collection and visualization of vaping behavior from a passive vaping monitor", "comment": null, "summary": "Understanding puffing topography (PT), which includes puff duration, intra puff interval, and puff count per session, is critical for evaluating Electronic Nicotine Delivery Systems (ENDS) use, toxicant exposure, and informing regulatory decisions. We developed FRIENDS (Flexible Robust Instrumentation of ENDS), an open-source device that records puffing and touch events of ENDS by attaching to it. This paper introduces the FRIENDS GUI that improves accessibility and interpretability of data collected by FRIENDS. The GUI is a Python-based open-source tool that extracts, decodes, and visualizes 24-hour puffing data from the FRIENDS device. Validation using 24-hour experimental data confirmed accurate timestamp conversion, reliable event decoding, and effective behavioral visualization. The software is freely available on GitHub for public use.", "AI": {"tldr": "\u5f00\u53d1\u4e86FRIENDS GUI\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8ePython\u7684\u5f00\u6e90\u5de5\u5177\uff0c\u7528\u4e8e\u63d0\u53d6\u3001\u89e3\u7801\u548c\u53ef\u89c6\u5316FRIENDS\u8bbe\u5907\u6536\u96c6\u768424\u5c0f\u65f6\u7535\u5b50\u70df\u4f7f\u7528\u6570\u636e\uff0c\u63d0\u9ad8\u4e86\u6570\u636e\u7684\u53ef\u8bbf\u95ee\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u7406\u89e3\u7535\u5b50\u70df\u4f7f\u7528\u884c\u4e3a\uff08\u5305\u62ec\u62bd\u5438\u6301\u7eed\u65f6\u95f4\u3001\u62bd\u5438\u95f4\u9694\u548c\u6bcf\u6b21\u4f1a\u8bdd\u7684\u62bd\u5438\u6b21\u6570\uff09\u5bf9\u4e8e\u8bc4\u4f30\u7535\u5b50\u70df\u4f7f\u7528\u3001\u6709\u6bd2\u7269\u8d28\u66b4\u9732\u548c\u5236\u5b9a\u76d1\u7ba1\u51b3\u7b56\u81f3\u5173\u91cd\u8981\u3002\u9700\u8981\u63d0\u9ad8FRIENDS\u8bbe\u5907\u6536\u96c6\u6570\u636e\u7684\u53ef\u8bbf\u95ee\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8ePython\u7684\u5f00\u6e90FRIENDS GUI\u5de5\u5177\uff0c\u80fd\u591f\u63d0\u53d6\u3001\u89e3\u7801\u548c\u53ef\u89c6\u5316FRIENDS\u8bbe\u5907\u8bb0\u5f55\u768424\u5c0f\u65f6\u62bd\u5438\u548c\u89e6\u6478\u4e8b\u4ef6\u6570\u636e\u3002\u901a\u8fc724\u5c0f\u65f6\u5b9e\u9a8c\u6570\u636e\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u9a8c\u8bc1\u786e\u8ba4\u4e86\u65f6\u95f4\u6233\u8f6c\u6362\u7684\u51c6\u786e\u6027\u3001\u4e8b\u4ef6\u89e3\u7801\u7684\u53ef\u9760\u6027\u4ee5\u53ca\u884c\u4e3a\u53ef\u89c6\u5316\u7684\u6709\u6548\u6027\u3002\u8be5\u8f6f\u4ef6\u5df2\u5728GitHub\u4e0a\u514d\u8d39\u63d0\u4f9b\u4f9b\u516c\u4f17\u4f7f\u7528\u3002", "conclusion": "FRIENDS GUI\u6210\u529f\u63d0\u9ad8\u4e86FRIENDS\u8bbe\u5907\u6536\u96c6\u6570\u636e\u7684\u53ef\u8bbf\u95ee\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u7535\u5b50\u70df\u4f7f\u7528\u884c\u4e3a\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5de5\u5177\u652f\u6301\u3002"}}
{"id": "2511.15168", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15168", "abs": "https://arxiv.org/abs/2511.15168", "authors": ["Nguyen-Khang Le", "Nguyen Hiep", "Minh Nguyen", "Son Luu", "Trung Vo", "Quan Bui", "Nomura Shoshin", "Le-Minh Nguyen"], "title": "Finetuning LLMs for Automatic Form Interaction on Web-Browser in Selenium Testing Framework", "comment": "Published in the Proceedings of KSE 2025", "summary": "Automated web application testing is a critical component of modern software development, with frameworks like Selenium widely adopted for validating functionality through browser automation. Among the essential aspects of such testing is the ability to interact with and validate web forms, a task that requires syntactically correct, executable scripts with high coverage of input fields. Despite its importance, this task remains underexplored in the context of large language models (LLMs), and no public benchmark or dataset exists to evaluate LLMs on form interaction generation systematically. This paper introduces a novel method for training LLMs to generate high-quality test cases in Selenium, specifically targeting form interaction testing. We curate both synthetic and human-annotated datasets for training and evaluation, covering diverse real-world forms and testing scenarios. We define clear metrics for syntax correctness, script executability, and input field coverage. Our empirical study demonstrates that our approach significantly outperforms strong baselines, including GPT-4o and other popular LLMs, across all evaluation metrics. Our work lays the groundwork for future research on LLM-based web testing and provides resources to support ongoing progress in this area.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u9ad8\u8d28\u91cfSelenium\u6d4b\u8bd5\u7528\u4f8b\u7684\u65b0\u65b9\u6cd5\uff0c\u4e13\u95e8\u9488\u5bf9\u8868\u5355\u4ea4\u4e92\u6d4b\u8bd5\uff0c\u5728\u8bed\u6cd5\u6b63\u786e\u6027\u3001\u811a\u672c\u53ef\u6267\u884c\u6027\u548c\u8f93\u5165\u5b57\u6bb5\u8986\u76d6\u7387\u65b9\u9762\u663e\u8457\u4f18\u4e8eGPT-4o\u7b49\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u81ea\u52a8\u5316Web\u5e94\u7528\u6d4b\u8bd5\u662f\u73b0\u4ee3\u8f6f\u4ef6\u5f00\u53d1\u7684\u5173\u952e\u7ec4\u6210\u90e8\u5206\uff0c\u4f46\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8868\u5355\u4ea4\u4e92\u751f\u6210\u4efb\u52a1\u65b9\u9762\u7814\u7a76\u4e0d\u8db3\uff0c\u7f3a\u4e4f\u516c\u5f00\u7684\u57fa\u51c6\u6570\u636e\u96c6\u6765\u7cfb\u7edf\u8bc4\u4f30LLMs\u5728\u6b64\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8bad\u7ec3LLMs\u751f\u6210Selenium\u6d4b\u8bd5\u7528\u4f8b\u7684\u65b0\u65b9\u6cd5\uff0c\u6784\u5efa\u4e86\u5408\u6210\u548c\u4eba\u5de5\u6807\u6ce8\u7684\u6570\u636e\u96c6\u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30\uff0c\u6db5\u76d6\u4e86\u591a\u6837\u5316\u7684\u771f\u5b9e\u4e16\u754c\u8868\u5355\u548c\u6d4b\u8bd5\u573a\u666f\u3002", "result": "\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6240\u6709\u8bc4\u4f30\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u5305\u62ecGPT-4o\u5728\u5185\u7684\u5f3a\u57fa\u7ebf\u6a21\u578b\uff0c\u5b9a\u4e49\u4e86\u8bed\u6cd5\u6b63\u786e\u6027\u3001\u811a\u672c\u53ef\u6267\u884c\u6027\u548c\u8f93\u5165\u5b57\u6bb5\u8986\u76d6\u7387\u7684\u6e05\u6670\u5ea6\u91cf\u6807\u51c6\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u57fa\u4e8eLLM\u7684Web\u6d4b\u8bd5\u672a\u6765\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5e76\u4e3a\u8be5\u9886\u57df\u7684\u6301\u7eed\u8fdb\u5c55\u63d0\u4f9b\u4e86\u8d44\u6e90\u652f\u6301\u3002"}}
{"id": "2511.15463", "categories": ["cs.CR", "cs.CE"], "pdf": "https://arxiv.org/pdf/2511.15463", "abs": "https://arxiv.org/abs/2511.15463", "authors": ["Minh Trung Tran", "Nasrin Sohrabi", "Zahir Tari", "Qin Wang"], "title": "How To Cook The Fragmented Rug Pull?", "comment": null, "summary": "Existing rug pull detectors assume a simple workflow: the deployer keeps liquidity pool (LP) tokens and performs one or a few large sells (within a day) that collapse the pool and cash out. In practice, however, many real-world exits violate these assumptions by splitting the attack across both time and actor dimensions: attackers break total extraction into many low-impact trades and route proceeds through multiple non-owner addresses, producing low-visibility drains.\n  We formalize this family of attacks as the fragmented rug pull (FRP) and offer a compact recipe for a slow-stewed beef special: (i) keep the lid on (to preserve LP control so on-chain extraction remains feasible), (ii) chop thin slices (to split the total exit volume into many low-impact micro-trades that individually fall below impact thresholds), and (iii) pass the ladle (to delegate sells across multiple wallets so that each participant takes a small share of the extraction). Technically, we define three atomic predicate groups and show that their orthogonal combinations yield evasive strategies overlooked by prior heuristics (USENIX Sec 19, USENIX Sec 23).\n  We validate the model with large-scale measurements. Our corpus contains 303,614 LPs, among which 105,434 are labeled as FRP pools. The labeled subset includes 34,192,767 pool-related transactions and 401,838 inflated-seller wallets, involving 1,501,408 unique interacting addresses. Notably, owner-wallet participation in inflated selling among FRP-flagged LPs has declined substantially (33.1% of cases), indicating a shift in scam behavior: the liquidity drain is no longer held on the owner wallet. We also detected 127,252 wallets acting as serial scammers when repeatedly engaging in inflated selling across multiple FRP LPs. Our empirical findings demonstrate that the evasive strategies we define are widespread and operationally significant.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u788e\u7247\u5316\u5730\u6bef\u5f0f\u653b\u51fb(FRP)\uff0c\u653b\u51fb\u8005\u901a\u8fc7\u5c06\u5927\u89c4\u6a21\u63d0\u53d6\u5206\u6563\u5230\u65f6\u95f4\u548c\u53c2\u4e0e\u8005\u7ef4\u5ea6\uff0c\u4f7f\u7528\u591a\u4e2a\u975e\u6240\u6709\u8005\u5730\u5740\u8fdb\u884c\u4f4e\u5f71\u54cd\u7684\u5c0f\u989d\u4ea4\u6613\uff0c\u4ece\u800c\u89c4\u907f\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5730\u6bef\u5f0f\u653b\u51fb\u68c0\u6d4b\u5668\u5047\u8bbe\u653b\u51fb\u8005\u6301\u6709\u6d41\u52a8\u6027\u6c60\u4ee3\u5e01\u5e76\u8fdb\u884c\u4e00\u6b21\u6027\u5927\u89c4\u6a21\u5356\u51fa\uff0c\u4f46\u5b9e\u9645\u653b\u51fb\u5f80\u5f80\u8fdd\u53cd\u8fd9\u4e9b\u5047\u8bbe\uff0c\u901a\u8fc7\u788e\u7247\u5316\u64cd\u4f5c\u5b9e\u73b0\u4f4e\u53ef\u89c1\u6027\u8d44\u91d1\u62bd\u53d6\u3002", "method": "\u5b9a\u4e49\u4e86\u788e\u7247\u5316\u5730\u6bef\u5f0f\u653b\u51fb\u7684\u4e09\u4e2a\u6838\u5fc3\u7b56\u7565\uff1a\u4fdd\u6301\u63a7\u5236\u6743\u3001\u5206\u5272\u4ea4\u6613\u91cf\u3001\u59d4\u6258\u5356\u51fa\u64cd\u4f5c\uff0c\u5e76\u6784\u5efa\u4e86\u4e09\u4e2a\u539f\u5b50\u8c13\u8bcd\u7ec4\u6765\u8bc6\u522b\u8fd9\u4e9b\u89c4\u907f\u7b56\u7565\u3002", "result": "\u5728\u5927\u89c4\u6a21\u6d4b\u91cf\u4e2d\u8bc6\u522b\u51fa105,434\u4e2aFRP\u6d41\u52a8\u6027\u6c60\uff0c\u6d89\u53ca401,838\u4e2a\u81a8\u80c0\u5356\u5bb6\u94b1\u5305\u548c1,501,408\u4e2a\u552f\u4e00\u4ea4\u4e92\u5730\u5740\uff0c\u53d1\u73b033.1%\u7684\u6848\u4f8b\u4e2d\u6240\u6709\u8005\u94b1\u5305\u4e0d\u53c2\u4e0e\u81a8\u80c0\u5356\u51fa\uff0c\u8868\u660e\u8bc8\u9a97\u884c\u4e3a\u6a21\u5f0f\u5df2\u53d1\u751f\u8f6c\u53d8\u3002", "conclusion": "\u788e\u7247\u5316\u5730\u6bef\u5f0f\u653b\u51fb\u5df2\u6210\u4e3a\u5e7f\u6cdb\u5b58\u5728\u4e14\u5177\u6709\u64cd\u4f5c\u610f\u4e49\u7684\u89c4\u907f\u7b56\u7565\uff0c\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u8bc6\u522b\u8fd9\u79cd\u65b0\u578b\u653b\u51fb\u6a21\u5f0f\u3002"}}
{"id": "2511.15169", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15169", "abs": "https://arxiv.org/abs/2511.15169", "authors": ["Xin Gao", "Shaohan Yu", "Zerui Chen", "Yueming Lyu", "Weichen Yu", "Guanghao Li", "Jiyao Liu", "Jianxiong Gao", "Jian Liang", "Ziwei Liu", "Chenyang Si"], "title": "SafeRBench: A Comprehensive Benchmark for Safety Assessment in Large Reasoning Models", "comment": "30 pages, 8 figures", "summary": "Large Reasoning Models (LRMs) improve answer quality through explicit chain-of-thought, yet this very capability introduces new safety risks: harmful content can be subtly injected, surface gradually, or be justified by misleading rationales within the reasoning trace. Existing safety evaluations, however, primarily focus on output-level judgments and rarely capture these dynamic risks along the reasoning process. In this paper, we present SafeRBench, the first benchmark that assesses LRM safety end-to-end -- from inputs and intermediate reasoning to final outputs. (1) Input Characterization: We pioneer the incorporation of risk categories and levels into input design, explicitly accounting for affected groups and severity, and thereby establish a balanced prompt suite reflecting diverse harm gradients. (2) Fine-Grained Output Analysis: We introduce a micro-thought chunking mechanism to segment long reasoning traces into semantically coherent units, enabling fine-grained evaluation across ten safety dimensions. (3) Human Safety Alignment: We validate LLM-based evaluations against human annotations specifically designed to capture safety judgments. Evaluations on 19 LRMs demonstrate that SafeRBench enables detailed, multidimensional safety assessment, offering insights into risks and protective mechanisms from multiple perspectives.", "AI": {"tldr": "SafeRBench\u662f\u9996\u4e2a\u7aef\u5230\u7aef\u8bc4\u4f30\u5927\u578b\u63a8\u7406\u6a21\u578b\u5b89\u5168\u6027\u7684\u57fa\u51c6\uff0c\u901a\u8fc7\u8f93\u5165\u7279\u5f81\u5316\u3001\u7ec6\u7c92\u5ea6\u8f93\u51fa\u5206\u6790\u548c\u4eba\u5de5\u5b89\u5168\u5bf9\u9f50\u4e09\u4e2a\u7ef4\u5ea6\uff0c\u5168\u9762\u8bc4\u4f30\u4ece\u8f93\u5165\u3001\u4e2d\u95f4\u63a8\u7406\u5230\u6700\u7ec8\u8f93\u51fa\u7684\u5b89\u5168\u98ce\u9669\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u901a\u8fc7\u663e\u5f0f\u601d\u7ef4\u94fe\u63d0\u9ad8\u4e86\u7b54\u6848\u8d28\u91cf\uff0c\u4f46\u8fd9\u4e5f\u5f15\u5165\u4e86\u65b0\u7684\u5b89\u5168\u98ce\u9669\uff1a\u6709\u5bb3\u5185\u5bb9\u53ef\u80fd\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u88ab\u5fae\u5999\u6ce8\u5165\u3001\u9010\u6e10\u663e\u73b0\u6216\u88ab\u8bef\u5bfc\u6027\u7406\u7531\u6240\u5408\u7406\u5316\u3002\u73b0\u6709\u7684\u5b89\u5168\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u8f93\u51fa\u7ea7\u5224\u65ad\uff0c\u5f88\u5c11\u6355\u6349\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u52a8\u6001\u98ce\u9669\u3002", "method": "1) \u8f93\u5165\u7279\u5f81\u5316\uff1a\u5c06\u98ce\u9669\u7c7b\u522b\u548c\u7ea7\u522b\u7eb3\u5165\u8f93\u5165\u8bbe\u8ba1\uff0c\u660e\u786e\u8003\u8651\u53d7\u5f71\u54cd\u7fa4\u4f53\u548c\u4e25\u91cd\u7a0b\u5ea6\uff1b2) \u7ec6\u7c92\u5ea6\u8f93\u51fa\u5206\u6790\uff1a\u5f15\u5165\u5fae\u601d\u7ef4\u5206\u5757\u673a\u5236\u5c06\u957f\u63a8\u7406\u8f68\u8ff9\u5206\u5272\u6210\u8bed\u4e49\u8fde\u8d2f\u5355\u5143\uff1b3) \u4eba\u5de5\u5b89\u5168\u5bf9\u9f50\uff1a\u57fa\u4e8e\u4e13\u95e8\u8bbe\u8ba1\u7684\u4eba\u5de5\u6807\u6ce8\u9a8c\u8bc1LLM\u8bc4\u4f30\u7ed3\u679c\u3002", "result": "\u5bf919\u4e2a\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u8bc4\u4f30\u8868\u660e\uff0cSafeRBench\u80fd\u591f\u5b9e\u73b0\u8be6\u7ec6\u7684\u591a\u7ef4\u5b89\u5168\u8bc4\u4f30\uff0c\u4ece\u591a\u4e2a\u89d2\u5ea6\u63d0\u4f9b\u5173\u4e8e\u98ce\u9669\u548c\u4fdd\u62a4\u673a\u5236\u7684\u89c1\u89e3\u3002", "conclusion": "SafeRBench\u586b\u8865\u4e86\u73b0\u6709\u5b89\u5168\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u4e3a\u5927\u578b\u63a8\u7406\u6a21\u578b\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u7aef\u5230\u7aef\u5b89\u5168\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u8bc6\u522b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u52a8\u6001\u5b89\u5168\u98ce\u9669\u3002"}}
{"id": "2511.15229", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15229", "abs": "https://arxiv.org/abs/2511.15229", "authors": ["Bashar Abdallah", "Martyna E. Wojciechowska", "Gustavo Santos", "Edmand Yu", "Maxime Lamothe", "Alain Abran", "Mohammad Hamdaqa"], "title": "From Code Smells to Best Practices: Tackling Resource Leaks in PyTorch, TensorFlow, and Keras", "comment": null, "summary": "Much of the existing ML research focuses on model performance metrics, leaving limited attention to the long-term sustainability and resource efficiency of ML applications. While high performance is essential, ensuring efficient resource management is equally critical for robust deployment. This study addresses this gap by systematically identifying code smells that lead to resource leaks in ML applications. We conducted an empirical investigation of developer discussions and real-world code snippets from PyTorch, TensorFlow, and Keras. The analysis identified 30 PyTorch-related smells and 16 TensorFlow/Keras smells linked to resource leaks. These smells were categorized in two ways: (1) based on their root causes, and (2) as general ML smells with framework-specific characteristics. For each smell, we derived at least one best practice, resulting in 50 recommended coding patterns aimed at reducing resource leakage and improving efficiency. To ensure the validity of our findings, we employed a three-phase validation process involving independent analysis by three authors followed by consensus discussions. This is the first comprehensive study to examine resource-leak-inducing code smells across major ML frameworks and to present actionable best practices for mitigating them. The contributions support developers in building more efficient and sustainable ML applications and offer a structured view of the underlying causes of resource leaks.", "AI": {"tldr": "\u672c\u7814\u7a76\u7cfb\u7edf\u8bc6\u522b\u4e86\u5bfc\u81f4ML\u5e94\u7528\u4e2d\u8d44\u6e90\u6cc4\u6f0f\u7684\u4ee3\u7801\u5f02\u5473\uff0c\u901a\u8fc7\u5206\u6790PyTorch\u3001TensorFlow\u548cKeras\u7684\u5f00\u53d1\u8005\u8ba8\u8bba\u548c\u5b9e\u9645\u4ee3\u7801\uff0c\u53d1\u73b0\u4e8630\u4e2aPyTorch\u76f8\u5173\u5f02\u5473\u548c16\u4e2aTensorFlow/Keras\u5f02\u5473\uff0c\u5e76\u63d0\u51fa\u4e8650\u4e2a\u6700\u4f73\u5b9e\u8df5\u6765\u51cf\u5c11\u8d44\u6e90\u6cc4\u6f0f\u3002", "motivation": "\u73b0\u6709ML\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6a21\u578b\u6027\u80fd\u6307\u6807\uff0c\u5bf9\u957f\u671f\u53ef\u6301\u7eed\u6027\u548c\u8d44\u6e90\u6548\u7387\u5173\u6ce8\u6709\u9650\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u786e\u4fddML\u5e94\u7528\u90e8\u7f72\u7684\u7a33\u5065\u6027\u3002", "method": "\u901a\u8fc7\u5b9e\u8bc1\u8c03\u67e5\u5206\u6790PyTorch\u3001TensorFlow\u548cKeras\u7684\u5f00\u53d1\u8005\u8ba8\u8bba\u548c\u771f\u5b9e\u4ee3\u7801\u7247\u6bb5\uff0c\u91c7\u7528\u4e09\u9636\u6bb5\u9a8c\u8bc1\u8fc7\u7a0b\uff0c\u5305\u62ec\u4e09\u4f4d\u4f5c\u8005\u7684\u72ec\u7acb\u5206\u6790\u548c\u5171\u8bc6\u8ba8\u8bba\u3002", "result": "\u8bc6\u522b\u51fa30\u4e2aPyTorch\u76f8\u5173\u5f02\u5473\u548c16\u4e2aTensorFlow/Keras\u5f02\u5473\uff0c\u6309\u6839\u672c\u539f\u56e0\u548c\u6846\u67b6\u7279\u5b9a\u7279\u5f81\u5206\u7c7b\uff0c\u4e3a\u6bcf\u4e2a\u5f02\u5473\u63a8\u5bfc\u51fa\u81f3\u5c11\u4e00\u4e2a\u6700\u4f73\u5b9e\u8df5\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5168\u9762\u7814\u7a76\u4e3b\u8981ML\u6846\u67b6\u4e2d\u5bfc\u81f4\u8d44\u6e90\u6cc4\u6f0f\u7684\u4ee3\u7801\u5f02\u5473\u7684\u7814\u7a76\uff0c\u4e3a\u5f00\u53d1\u4eba\u5458\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6700\u4f73\u5b9e\u8df5\uff0c\u652f\u6301\u6784\u5efa\u66f4\u9ad8\u6548\u548c\u53ef\u6301\u7eed\u7684ML\u5e94\u7528\u3002"}}
{"id": "2511.15479", "categories": ["cs.CR", "cs.DC", "cs.LO"], "pdf": "https://arxiv.org/pdf/2511.15479", "abs": "https://arxiv.org/abs/2511.15479", "authors": ["Martin Slind Hagen", "Emil Lundqvist", "Alex Phu", "Yenan Wang", "Kim Strandberg", "Elad Michael Schiller"], "title": "Towards a Formal Verification of Secure Vehicle Software Updates", "comment": "This technical report is a preprint of the article accepted for publication in Computer & Security 2025", "summary": "With the rise of software-defined vehicles (SDVs), where software governs most vehicle functions alongside enhanced connectivity, the need for secure software updates has become increasingly critical. Software vulnerabilities can severely impact safety, the economy, and society. In response to this challenge, Strandberg et al. [escar Europe, 2021] introduced the Unified Software Update Framework (UniSUF), designed to provide a secure update framework that integrates seamlessly with existing vehicular infrastructures.\n  Although UniSUF has previously been evaluated regarding cybersecurity, these assessments have not employed formal verification methods. To bridge this gap, we perform a formal security analysis of UniSUF. We model UniSUF's architecture and assumptions to reflect real-world automotive systems and develop a ProVerif-based framework that formally verifies UniSUF's compliance with essential security requirements - confidentiality, integrity, authenticity, freshness, order, and liveness - demonstrating their satisfiability through symbolic execution. Our results demonstrate that UniSUF adheres to the specified security guarantees, ensuring the correctness and reliability of its security framework.", "AI": {"tldr": "\u5bf9UniSUF\u7edf\u4e00\u8f6f\u4ef6\u66f4\u65b0\u6846\u67b6\u8fdb\u884c\u5f62\u5f0f\u5316\u5b89\u5168\u5206\u6790\uff0c\u9a8c\u8bc1\u5176\u5728\u8f6f\u4ef6\u5b9a\u4e49\u8f66\u8f86\u73af\u5883\u4e2d\u7684\u5b89\u5168\u5c5e\u6027\u6ee1\u8db3\u6027", "motivation": "\u968f\u7740\u8f6f\u4ef6\u5b9a\u4e49\u8f66\u8f86(SDVs)\u7684\u53d1\u5c55\uff0c\u8f6f\u4ef6\u6f0f\u6d1e\u5bf9\u5b89\u5168\u3001\u7ecf\u6d4e\u548c\u793e\u4f1a\u9020\u6210\u4e25\u91cd\u5f71\u54cd\uff0c\u9700\u8981\u786e\u4fdd\u8f6f\u4ef6\u66f4\u65b0\u7684\u5b89\u5168\u6027\u3002\u867d\u7136UniSUF\u6846\u67b6\u5df2\u88ab\u63d0\u51fa\uff0c\u4f46\u4e4b\u524d\u7684\u5b89\u5168\u8bc4\u4f30\u672a\u91c7\u7528\u5f62\u5f0f\u5316\u9a8c\u8bc1\u65b9\u6cd5", "method": "\u5efa\u7acbUniSUF\u67b6\u6784\u548c\u5047\u8bbe\u7684\u6a21\u578b\u4ee5\u53cd\u6620\u771f\u5b9e\u6c7d\u8f66\u7cfb\u7edf\uff0c\u5f00\u53d1\u57fa\u4e8eProVerif\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u7b26\u53f7\u6267\u884c\u9a8c\u8bc1\u5b89\u5168\u8981\u6c42", "result": "\u9a8c\u8bc1\u7ed3\u679c\u8868\u660eUniSUF\u7b26\u5408\u6307\u5b9a\u7684\u5b89\u5168\u4fdd\u8bc1\uff0c\u5305\u62ec\u673a\u5bc6\u6027\u3001\u5b8c\u6574\u6027\u3001\u771f\u5b9e\u6027\u3001\u65b0\u9c9c\u6027\u3001\u987a\u5e8f\u6027\u548c\u6d3b\u6027\u7b49\u5b89\u5168\u8981\u6c42", "conclusion": "UniSUF\u7684\u5b89\u5168\u6846\u67b6\u5177\u6709\u6b63\u786e\u6027\u548c\u53ef\u9760\u6027\uff0c\u80fd\u591f\u6ee1\u8db3\u8f6f\u4ef6\u5b9a\u4e49\u8f66\u8f86\u7684\u5b89\u5168\u66f4\u65b0\u9700\u6c42"}}
{"id": "2511.15257", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.15257", "abs": "https://arxiv.org/abs/2511.15257", "authors": ["Hiep Hong Trinh", "Federico Ciccozzi", "Abu Naser Masud", "Marjan Sirjani", "Mikael Sj\u00f6din"], "title": "M, Toolchain and Language for Reusable Model Compilation", "comment": null, "summary": "Complex software-driven systems often interleave distributed, concurrent computation processes with physical interactions with the environment. Developing these systems more efficiently and safely can be achieved by employing actionable, software-based models. From a high-level system model, engineers often need to derive multiple specialized models for different purposes, including simulation, deployment, and formal verification. Each of these target models usually rely on its own formalism, specification language, and execution platform. Traditionally, a compiler analyzes a program written in a programming language and generates executable code. In contrast, a model compiler processes a source model written in a modeling language and should ideally support the generation of multiple heterogeneous targets. However, most existing modeling languages are designed with a narrow focus, typically targeting only simulation or implementation. Multi-target compilation, when not considered during the language's early design, becomes significantly harder to achieve. In this paper, we introduce our initiative: a toolchain and modeling language called M, designed to support system modeling and multi-target compilation for model-driven engineering of complex, concurrent, and time-aware systems. M is a textual, grammar-driven language based on the actor model and extended with discrete-event scheduling semantics. It provides constructs for modeling system entities, message-based interactions, and time- or state-triggered reactions. From such models, M enables the systematic generation of diverse target artifacts while preserving semantic conformance to the original model. Moreover, M can serve as a middle language to which other modeling languages may anchor, thereby allowing them to benefit from its compilation framework.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86M\u5de5\u5177\u94fe\u548c\u5efa\u6a21\u8bed\u8a00\uff0c\u65e8\u5728\u652f\u6301\u590d\u6742\u3001\u5e76\u53d1\u548c\u65f6\u95f4\u611f\u77e5\u7cfb\u7edf\u7684\u5efa\u6a21\u4e0e\u591a\u76ee\u6807\u7f16\u8bd1\uff0c\u57fa\u4e8e\u53c2\u4e0e\u8005\u6a21\u578b\u5e76\u6269\u5c55\u79bb\u6563\u4e8b\u4ef6\u8c03\u5ea6\u8bed\u4e49\u3002", "motivation": "\u5f00\u53d1\u590d\u6742\u8f6f\u4ef6\u9a71\u52a8\u7cfb\u7edf\u65f6\uff0c\u9700\u8981\u4ece\u9ad8\u7ea7\u7cfb\u7edf\u6a21\u578b\u751f\u6210\u591a\u4e2a\u4e13\u7528\u6a21\u578b\u7528\u4e8e\u4eff\u771f\u3001\u90e8\u7f72\u548c\u5f62\u5f0f\u9a8c\u8bc1\u7b49\u4e0d\u540c\u76ee\u7684\uff0c\u4f46\u73b0\u6709\u5efa\u6a21\u8bed\u8a00\u901a\u5e38\u53ea\u9488\u5bf9\u5355\u4e00\u76ee\u6807\u8bbe\u8ba1\uff0c\u591a\u76ee\u6807\u7f16\u8bd1\u96be\u4ee5\u5b9e\u73b0\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u53c2\u4e0e\u8005\u6a21\u578b\u7684\u6587\u672c\u5316\u3001\u8bed\u6cd5\u9a71\u52a8\u7684M\u5efa\u6a21\u8bed\u8a00\uff0c\u6269\u5c55\u79bb\u6563\u4e8b\u4ef6\u8c03\u5ea6\u8bed\u4e49\uff0c\u63d0\u4f9b\u7cfb\u7edf\u5b9e\u4f53\u5efa\u6a21\u3001\u57fa\u4e8e\u6d88\u606f\u7684\u4ea4\u4e92\u4ee5\u53ca\u65f6\u95f4\u6216\u72b6\u6001\u89e6\u53d1\u53cd\u5e94\u7684\u6784\u9020\u3002", "result": "M\u80fd\u591f\u4ece\u6a21\u578b\u7cfb\u7edf\u6027\u5730\u751f\u6210\u591a\u6837\u5316\u76ee\u6807\u4ea7\u7269\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u539f\u59cb\u6a21\u578b\u7684\u8bed\u4e49\u4e00\u81f4\u6027\uff0c\u5e76\u53ef\u4f5c\u4e3a\u4e2d\u95f4\u8bed\u8a00\u4f9b\u5176\u4ed6\u5efa\u6a21\u8bed\u8a00\u951a\u5b9a\u4f7f\u7528\u3002", "conclusion": "M\u5de5\u5177\u94fe\u548c\u5efa\u6a21\u8bed\u8a00\u4e3a\u590d\u6742\u7cfb\u7edf\u7684\u6a21\u578b\u9a71\u52a8\u5de5\u7a0b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u591a\u76ee\u6807\u7f16\u8bd1\u652f\u6301\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5efa\u6a21\u8bed\u8a00\u76ee\u6807\u5355\u4e00\u7684\u95ee\u9898\u3002"}}
{"id": "2511.15192", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15192", "abs": "https://arxiv.org/abs/2511.15192", "authors": ["Haodong Li", "Jingqi Zhang", "Xiao Cheng", "Peihua Mai", "Haoyu Wang", "Yang Pan"], "title": "As If We've Met Before: LLMs Exhibit Certainty in Recognizing Seen Files", "comment": null, "summary": "The remarkable language ability of Large Language Models (LLMs) stems from extensive training on vast datasets, often including copyrighted material, which raises serious concerns about unauthorized use. While Membership Inference Attacks (MIAs) offer potential solutions for detecting such violations, existing approaches face critical limitations and challenges due to LLMs' inherent overconfidence, limited access to ground truth training data, and reliance on empirically determined thresholds.\n  We present COPYCHECK, a novel framework that leverages uncertainty signals to detect whether copyrighted content was used in LLM training sets. Our method turns LLM overconfidence from a limitation into an asset by capturing uncertainty patterns that reliably distinguish between ``seen\" (training data) and ``unseen\" (non-training data) content. COPYCHECK further implements a two-fold strategy: (1) strategic segmentation of files into smaller snippets to reduce dependence on large-scale training data, and (2) uncertainty-guided unsupervised clustering to eliminate the need for empirically tuned thresholds. Experiment results show that COPYCHECK achieves an average balanced accuracy of 90.1% on LLaMA 7b and 91.6% on LLaMA2 7b in detecting seen files. Compared to the SOTA baseline, COPYCHECK achieves over 90% relative improvement, reaching up to 93.8\\% balanced accuracy. It further exhibits strong generalizability across architectures, maintaining high performance on GPT-J 6B. This work presents the first application of uncertainty for copyright detection in LLMs, offering practical tools for training data transparency.", "AI": {"tldr": "COPYCHECK\u662f\u4e00\u4e2a\u5229\u7528\u4e0d\u786e\u5b9a\u6027\u4fe1\u53f7\u68c0\u6d4bLLM\u8bad\u7ec3\u6570\u636e\u4e2d\u7248\u6743\u5185\u5bb9\u7684\u6846\u67b6\uff0c\u5c06LLM\u7684\u8fc7\u5ea6\u81ea\u4fe1\u8f6c\u5316\u4e3a\u4f18\u52bf\uff0c\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u6a21\u5f0f\u533a\u5206\u8bad\u7ec3\u6570\u636e\u548c\u975e\u8bad\u7ec3\u6570\u636e\uff0c\u65e0\u9700\u7ecf\u9a8c\u9608\u503c\u5373\u53ef\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u68c0\u6d4b\u3002", "motivation": "LLM\u5728\u5927\u91cf\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u65f6\u53ef\u80fd\u5305\u542b\u53d7\u7248\u6743\u4fdd\u62a4\u7684\u5185\u5bb9\uff0c\u73b0\u6709\u6210\u5458\u63a8\u65ad\u653b\u51fb\u65b9\u6cd5\u56e0LLM\u8fc7\u5ea6\u81ea\u4fe1\u3001\u7f3a\u4e4f\u771f\u5b9e\u8bad\u7ec3\u6570\u636e\u548c\u4f9d\u8d56\u7ecf\u9a8c\u9608\u503c\u800c\u9762\u4e34\u9650\u5236\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u7b56\u7565\uff1a(1)\u5c06\u6587\u4ef6\u5206\u5272\u4e3a\u5c0f\u7247\u6bb5\u4ee5\u51cf\u5c11\u5bf9\u5927\u89c4\u6a21\u8bad\u7ec3\u6570\u636e\u7684\u4f9d\u8d56\uff1b(2)\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u65e0\u76d1\u7763\u805a\u7c7b\uff0c\u65e0\u9700\u7ecf\u9a8c\u8c03\u4f18\u9608\u503c\u3002", "result": "\u5728LLaMA 7b\u548cLLaMA2 7b\u4e0a\u5206\u522b\u8fbe\u523090.1%\u548c91.6%\u7684\u5e73\u5747\u5e73\u8861\u51c6\u786e\u7387\uff0c\u76f8\u6bd4SOTA\u57fa\u7ebf\u76f8\u5bf9\u63d0\u5347\u8d85\u8fc790%\uff0c\u6700\u9ad8\u8fbe93.8%\u5e73\u8861\u51c6\u786e\u7387\uff0c\u5728GPT-J 6B\u4e0a\u4fdd\u6301\u5f3a\u6cdb\u5316\u6027\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5c06\u4e0d\u786e\u5b9a\u6027\u5e94\u7528\u4e8eLLM\u7248\u6743\u68c0\u6d4b\u7684\u5de5\u4f5c\uff0c\u4e3a\u8bad\u7ec3\u6570\u636e\u900f\u660e\u5ea6\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2511.15293", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15293", "abs": "https://arxiv.org/abs/2511.15293", "authors": ["Jia Li", "Zhi Jin", "Kechi Zhang", "Huangzhao Zhang", "Jiaru Qian", "Tiankuo Zhao"], "title": "A Viable Paradigm of Software Automation: Iterative End-to-End Automated Software Development", "comment": null, "summary": "Software development automation is a long-term goal in software engineering. With the development of artificial intelligence (AI), more and more researchers are exploring approaches to software automation. They view AI systems as tools or assistants in software development, still requiring significant human involvement. Another initiative is ``vibe coding'', where AI systems write and repeatedly revise most (or even all) of the code. We foresee these two development paths will converge towards the same destination: AI systems participate in throughout the software development lifecycle, expanding boundaries of full-stack software development. In this paper, we present a vision of an iterative end-to-end automated software development paradigm AutoSW. It operates in an analyze-plan-implement-deliver loop, where AI systems as human partners become first-class actors, translating human intentions expressed in natural language into executable software. We explore a lightweight prototype across the paradigm and initially execute various representative cases. The results indicate that AutoSW can successfully deliver executable software, providing a feasible direction for truly end-to-end automated software development.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAutoSW\u613f\u666f\uff0c\u4e00\u79cd\u8fed\u4ee3\u5f0f\u7aef\u5230\u7aef\u81ea\u52a8\u5316\u8f6f\u4ef6\u5f00\u53d1\u8303\u5f0f\uff0c\u901a\u8fc7\u5206\u6790-\u89c4\u5212-\u5b9e\u73b0-\u4ea4\u4ed8\u5faa\u73af\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u610f\u56fe\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u8f6f\u4ef6\u3002", "motivation": "\u968f\u7740AI\u53d1\u5c55\uff0c\u73b0\u6709\u7814\u7a76\u5c06AI\u89c6\u4e3a\u5f00\u53d1\u5de5\u5177\u6216\u52a9\u624b\uff0c\u4ecd\u9700\u5927\u91cf\u4eba\u5de5\u53c2\u4e0e\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22AI\u7cfb\u7edf\u4f5c\u4e3a\u4eba\u7c7b\u4f19\u4f34\u53c2\u4e0e\u6574\u4e2a\u8f6f\u4ef6\u5f00\u53d1\u751f\u547d\u5468\u671f\u7684\u81ea\u52a8\u5316\u8303\u5f0f\u3002", "method": "\u63d0\u51faAutoSW\u8303\u5f0f\uff0c\u91c7\u7528\u5206\u6790-\u89c4\u5212-\u5b9e\u73b0-\u4ea4\u4ed8\u7684\u8fed\u4ee3\u5faa\u73af\uff0cAI\u7cfb\u7edf\u4f5c\u4e3a\u4e00\u7b49\u53c2\u4e0e\u8005\u5c06\u81ea\u7136\u8bed\u8a00\u610f\u56fe\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u8f6f\u4ef6\uff0c\u5e76\u6784\u5efa\u8f7b\u91cf\u7ea7\u539f\u578b\u9a8c\u8bc1\u3002", "result": "\u901a\u8fc7\u4ee3\u8868\u6027\u6848\u4f8b\u9a8c\u8bc1\uff0cAutoSW\u80fd\u591f\u6210\u529f\u4ea4\u4ed8\u53ef\u6267\u884c\u8f6f\u4ef6\uff0c\u4e3a\u771f\u6b63\u7684\u7aef\u5230\u7aef\u81ea\u52a8\u5316\u8f6f\u4ef6\u5f00\u53d1\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u5411\u3002", "conclusion": "AutoSW\u8303\u5f0f\u5c55\u793a\u4e86AI\u7cfb\u7edf\u4f5c\u4e3a\u4eba\u7c7b\u4f19\u4f34\u53c2\u4e0e\u5168\u6808\u8f6f\u4ef6\u5f00\u53d1\u7684\u6f5c\u529b\uff0c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2511.15340", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15340", "abs": "https://arxiv.org/abs/2511.15340", "authors": ["Yi Peng", "Hans-Martin Heyn", "Jennifer Horkoff"], "title": "From Machine Learning Documentation to Requirements: Bridging Processes with Requirements Languages", "comment": "To be published in proceedings of the 26th International Conference on Product-Focused Software Process Improvement (PROFES 2025). All raw and processed data are available in online repository, see https://doi.org/10.6084/m9.figshare.28564058.v1", "summary": "In software engineering processes for machine learning (ML)-enabled systems, integrating and verifying ML components is a major challenge. A prerequisite is the specification of ML component requirements, including models and data, an area where traditional requirements engineering (RE) processes face new obstacles. An underexplored source of RE-relevant information in this context is ML documentation such as ModelCards and DataSheets. However, it is uncertain to what extent RE-relevant information can be extracted from these documents. This study first investigates the amount and nature of RE-relevant information in 20 publicly available ModelCards and DataSheets. We show that these documents contain a significant amount of potentially RE-relevant information. Next, we evaluate how effectively three established RE representations (EARS, Rupp's template, and Volere) can structure this knowledge into requirements. Our results demonstrate that there is a pathway to transform ML-specific knowledge into structured requirements, incorporating ML documentation in software engineering processes for ML systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u4ece\u673a\u5668\u5b66\u4e60\u6587\u6863\uff08\u5982ModelCards\u548cDataSheets\uff09\u4e2d\u63d0\u53d6\u9700\u6c42\u5de5\u7a0b\u76f8\u5173\u4fe1\u606f\u7684\u53ef\u884c\u6027\uff0c\u5e76\u8bc4\u4f30\u4e86\u4e09\u79cd\u9700\u6c42\u5de5\u7a0b\u8868\u793a\u65b9\u6cd5\uff08EARS\u3001Rupp\u6a21\u677f\u548cVolere\uff09\u5c06\u8fd9\u4e9b\u4fe1\u606f\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u9700\u6c42\u7684\u6548\u679c\u3002", "motivation": "\u5728\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u7684\u8f6f\u4ef6\u5de5\u7a0b\u8fc7\u7a0b\u4e2d\uff0c\u96c6\u6210\u548c\u9a8c\u8bc1ML\u7ec4\u4ef6\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002\u4f20\u7edf\u9700\u6c42\u5de5\u7a0b\u8fc7\u7a0b\u5728\u6307\u5b9aML\u7ec4\u4ef6\u9700\u6c42\uff08\u5305\u62ec\u6a21\u578b\u548c\u6570\u636e\uff09\u65b9\u9762\u9047\u5230\u65b0\u969c\u788d\uff0c\u800cML\u6587\u6863\u4f5c\u4e3a\u9700\u6c42\u5de5\u7a0b\u76f8\u5173\u4fe1\u606f\u6765\u6e90\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u9996\u5148\u5206\u6790\u4e8620\u4e2a\u516c\u5f00\u53ef\u7528\u7684ModelCards\u548cDataSheets\u4e2d\u9700\u6c42\u5de5\u7a0b\u76f8\u5173\u4fe1\u606f\u7684\u6570\u91cf\u548c\u6027\u8d28\uff0c\u7136\u540e\u8bc4\u4f30\u4e86\u4e09\u79cd\u9700\u6c42\u5de5\u7a0b\u8868\u793a\u65b9\u6cd5\uff08EARS\u3001Rupp\u6a21\u677f\u548cVolere\uff09\u5c06\u8fd9\u4e9b\u77e5\u8bc6\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u9700\u6c42\u7684\u6709\u6548\u6027\u3002", "result": "\u7814\u7a76\u8868\u660e\u8fd9\u4e9b\u6587\u6863\u5305\u542b\u5927\u91cf\u6f5c\u5728\u7684\u9700\u6c42\u5de5\u7a0b\u76f8\u5173\u4fe1\u606f\uff0c\u5e76\u8bc1\u660e\u5b58\u5728\u5c06ML\u7279\u5b9a\u77e5\u8bc6\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u9700\u6c42\u7684\u9014\u5f84\uff0c\u53ef\u4ee5\u5c06ML\u6587\u6863\u7eb3\u5165ML\u7cfb\u7edf\u7684\u8f6f\u4ef6\u5de5\u7a0b\u8fc7\u7a0b\u3002", "conclusion": "ML\u6587\u6863\uff08\u5982ModelCards\u548cDataSheets\uff09\u53ef\u4ee5\u4f5c\u4e3a\u9700\u6c42\u5de5\u7a0b\u7684\u91cd\u8981\u4fe1\u606f\u6765\u6e90\uff0c\u901a\u8fc7\u9002\u5f53\u7684\u9700\u6c42\u5de5\u7a0b\u8868\u793a\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u5730\u5c06ML\u7279\u5b9a\u77e5\u8bc6\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u9700\u6c42\uff0c\u4ece\u800c\u652f\u6301ML\u7cfb\u7edf\u7684\u8f6f\u4ef6\u5de5\u7a0b\u8fc7\u7a0b\u3002"}}
{"id": "2511.15259", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.15259", "abs": "https://arxiv.org/abs/2511.15259", "authors": ["Philipp Wiesner", "Daniel W. O'Neill", "Francesca Larosa", "Odej Kao"], "title": "Efficiency Will Not Lead to Sustainable Reasoning AI", "comment": "Presented at the Rethinking AI Workshop @ EurIPS'25", "summary": "AI research is increasingly moving toward complex problem solving, where models are optimized not only for pattern recognition but for multi-step reasoning. Historically, computing's global energy footprint has been stabilized by sustained efficiency gains and natural saturation thresholds in demand. But as efficiency improvements are approaching physical limits, emerging reasoning AI lacks comparable saturation points: performance is no longer limited by the amount of available training data but continues to scale with exponential compute investments in both training and inference. This paper argues that efficiency alone will not lead to sustainable reasoning AI and discusses research and policy directions to embed explicit limits into the optimization and governance of such systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8ba4\u4e3a\uff0c\u968f\u7740AI\u7814\u7a76\u8f6c\u5411\u590d\u6742\u95ee\u9898\u89e3\u51b3\u548c\u591a\u6b65\u63a8\u7406\uff0c\u4ec5\u9760\u6548\u7387\u63d0\u5347\u65e0\u6cd5\u5b9e\u73b0\u53ef\u6301\u7eed\u7684\u63a8\u7406AI\uff0c\u9700\u8981\u5c06\u660e\u786e\u9650\u5236\u5d4c\u5165\u7cfb\u7edf\u4f18\u5316\u548c\u6cbb\u7406\u4e2d\u3002", "motivation": "AI\u7814\u7a76\u6b63\u4ece\u6a21\u5f0f\u8bc6\u522b\u8f6c\u5411\u590d\u6742\u95ee\u9898\u89e3\u51b3\uff0c\u63a8\u7406AI\u7f3a\u4e4f\u9700\u6c42\u9971\u548c\u70b9\uff0c\u6027\u80fd\u968f\u8ba1\u7b97\u6295\u5165\u6307\u6570\u7ea7\u589e\u957f\uff0c\u800c\u6548\u7387\u6539\u8fdb\u6b63\u63a5\u8fd1\u7269\u7406\u6781\u9650\uff0c\u9700\u8981\u65b0\u7684\u53ef\u6301\u7eed\u6027\u65b9\u6cd5\u3002", "method": "\u5206\u6790\u63a8\u7406AI\u7684\u8ba1\u7b97\u6269\u5c55\u7279\u6027\uff0c\u8ba8\u8bba\u6548\u7387\u6539\u8fdb\u7684\u7269\u7406\u9650\u5236\uff0c\u63d0\u51fa\u5728\u7cfb\u7edf\u4f18\u5316\u548c\u6cbb\u7406\u4e2d\u5d4c\u5165\u660e\u786e\u9650\u5236\u7684\u7814\u7a76\u548c\u653f\u7b56\u65b9\u5411\u3002", "result": "\u8bc6\u522b\u51fa\u63a8\u7406AI\u7f3a\u4e4f\u81ea\u7136\u9971\u548c\u70b9\uff0c\u6027\u80fd\u4e0e\u8ba1\u7b97\u6295\u5165\u5448\u6307\u6570\u5173\u7cfb\uff0c\u6548\u7387\u63d0\u5347\u65e0\u6cd5\u5355\u72ec\u89e3\u51b3\u53ef\u6301\u7eed\u6027\u95ee\u9898\u3002", "conclusion": "\u4ec5\u9760\u6548\u7387\u65e0\u6cd5\u5b9e\u73b0\u53ef\u6301\u7eed\u7684\u63a8\u7406AI\uff0c\u9700\u8981\u5728\u4f18\u5316\u548c\u6cbb\u7406\u4e2d\u5d4c\u5165\u660e\u786e\u9650\u5236\uff0c\u63a8\u52a8\u76f8\u5173\u7814\u7a76\u548c\u653f\u7b56\u5236\u5b9a\u3002"}}
{"id": "2511.15403", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.15403", "abs": "https://arxiv.org/abs/2511.15403", "authors": ["Isabel Amaral", "Alexandra Mendes", "Jos\u00e9 Campos"], "title": "MutDafny: A Mutation-Based Approach to Assess Dafny Specifications", "comment": null, "summary": "This paper explores the use of mutation testing to reveal weaknesses in formal specifications written in Dafny. In verification-aware programming languages, such as Dafny, despite their critical role, specifications are as prone to errors as implementations. Flaws in specs can result in formally verified programs that deviate from the intended behavior.\n  We present MutDafny, a tool that increases the reliability of Dafny specifications by automatically signaling potential weaknesses. Using a mutation testing approach, we introduce faults (mutations) into the code and rely on formal specifications for detecting them. If a program with a mutant verifies, this may indicate a weakness in the specification. We extensively analyze mutation operators from popular tools, identifying the ones applicable to Dafny. In addition, we synthesize new operators tailored for Dafny from bugfix commits in publicly available Dafny projects on GitHub. Drawing from both, we equipped our tool with a total of 32 mutation operators. We evaluate MutDafny's effectiveness and efficiency in a dataset of 794 real-world Dafny programs and we manually analyze a subset of the resulting undetected mutants, identifying five weak real-world specifications (on average, one at every 241 lines of code) that would benefit from strengthening.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86MutDafny\u5de5\u5177\uff0c\u901a\u8fc7\u53d8\u5f02\u6d4b\u8bd5\u6765\u68c0\u6d4bDafny\u5f62\u5f0f\u5316\u89c4\u8303\u4e2d\u7684\u5f31\u70b9\u3002\u8be5\u5de5\u5177\u4f7f\u752832\u4e2a\u53d8\u5f02\u7b97\u5b50\uff0c\u5728794\u4e2a\u771f\u5b9eDafny\u7a0b\u5e8f\u4e0a\u8bc4\u4f30\uff0c\u53d1\u73b0\u4e86\u5e73\u5747\u6bcf241\u884c\u4ee3\u7801\u5c31\u5b58\u5728\u4e00\u4e2a\u9700\u8981\u52a0\u5f3a\u7684\u89c4\u8303\u5f31\u70b9\u3002", "motivation": "\u5728\u9a8c\u8bc1\u611f\u77e5\u7f16\u7a0b\u8bed\u8a00\u5982Dafny\u4e2d\uff0c\u89c4\u8303\u4e0e\u5b9e\u73b0\u4e00\u6837\u5bb9\u6613\u51fa\u9519\u3002\u89c4\u8303\u4e2d\u7684\u7f3a\u9677\u53ef\u80fd\u5bfc\u81f4\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u7a0b\u5e8f\u504f\u79bb\u9884\u671f\u884c\u4e3a\uff0c\u56e0\u6b64\u9700\u8981\u6709\u6548\u65b9\u6cd5\u6765\u63d0\u9ad8\u89c4\u8303\u53ef\u9760\u6027\u3002", "method": "\u91c7\u7528\u53d8\u5f02\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u5c06\u6545\u969c\uff08\u53d8\u5f02\uff09\u5f15\u5165\u4ee3\u7801\uff0c\u4f9d\u8d56\u5f62\u5f0f\u5316\u89c4\u8303\u6765\u68c0\u6d4b\u8fd9\u4e9b\u53d8\u5f02\u3002\u5982\u679c\u5e26\u6709\u53d8\u5f02\u4f53\u7684\u7a0b\u5e8f\u4ecd\u80fd\u9a8c\u8bc1\u901a\u8fc7\uff0c\u5219\u8868\u660e\u89c4\u8303\u5b58\u5728\u5f31\u70b9\u3002\u4ece\u6d41\u884c\u5de5\u5177\u4e2d\u5206\u6790\u9002\u7528\u7684\u53d8\u5f02\u7b97\u5b50\uff0c\u5e76\u4eceGitHub\u4e0a\u7684Dafny\u9879\u76ee\u9519\u8bef\u4fee\u590d\u63d0\u4ea4\u4e2d\u5408\u6210\u65b0\u7684\u7b97\u5b50\u3002", "result": "\u5f00\u53d1\u4e86\u5305\u542b32\u4e2a\u53d8\u5f02\u7b97\u5b50\u7684MutDafny\u5de5\u5177\uff0c\u5728794\u4e2a\u771f\u5b9eDafny\u7a0b\u5e8f\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e86\u5176\u6709\u6548\u6027\u548c\u6548\u7387\u3002\u624b\u52a8\u5206\u6790\u672a\u68c0\u6d4b\u5230\u7684\u53d8\u5f02\u4f53\u5b50\u96c6\uff0c\u8bc6\u522b\u51fa5\u4e2a\u9700\u8981\u52a0\u5f3a\u7684\u771f\u5b9e\u4e16\u754c\u89c4\u8303\u5f31\u70b9\u3002", "conclusion": "\u53d8\u5f02\u6d4b\u8bd5\u662f\u63ed\u793aDafny\u5f62\u5f0f\u5316\u89c4\u8303\u5f31\u70b9\u7684\u6709\u6548\u65b9\u6cd5\uff0cMutDafny\u5de5\u5177\u80fd\u591f\u81ea\u52a8\u8bc6\u522b\u89c4\u8303\u4e2d\u7684\u6f5c\u5728\u95ee\u9898\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7a0b\u5e8f\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2511.15282", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15282", "abs": "https://arxiv.org/abs/2511.15282", "authors": ["Ninell Oldenburg", "Ruchira Dhar", "Anders S\u00f8gaard"], "title": "Realist and Pluralist Conceptions of Intelligence and Their Implications on AI Research", "comment": "The 40th Annual AAAI Conference on Artificial Intelligence, 8 pages (excl. references), 1 table", "summary": "In this paper, we argue that current AI research operates on a spectrum between two different underlying conceptions of intelligence: Intelligence Realism, which holds that intelligence represents a single, universal capacity measurable across all systems, and Intelligence Pluralism, which views intelligence as diverse, context-dependent capacities that cannot be reduced to a single universal measure. Through an analysis of current debates in AI research, we demonstrate how the conceptions remain largely implicit yet fundamentally shape how empirical evidence gets interpreted across a wide range of areas. These underlying views generate fundamentally different research approaches across three areas. Methodologically, they produce different approaches to model selection, benchmark design, and experimental validation. Interpretively, they lead to contradictory readings of the same empirical phenomena, from capability emergence to system limitations. Regarding AI risk, they generate categorically different assessments: realists view superintelligence as the primary risk and search for unified alignment solutions, while pluralists see diverse threats across different domains requiring context-specific solutions. We argue that making explicit these underlying assumptions can contribute to a clearer understanding of disagreements in AI research.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86AI\u7814\u7a76\u4e2d\u4e24\u79cd\u5bf9\u7acb\u7684\u667a\u529b\u89c2\uff1a\u667a\u529b\u73b0\u5b9e\u4e3b\u4e49\u8ba4\u4e3a\u667a\u529b\u662f\u5355\u4e00\u666e\u9002\u80fd\u529b\uff0c\u667a\u529b\u591a\u5143\u4e3b\u4e49\u8ba4\u4e3a\u667a\u529b\u662f\u591a\u6837\u5316\u7684\u60c5\u5883\u4f9d\u8d56\u80fd\u529b\u3002\u8fd9\u4e24\u79cd\u89c2\u70b9\u5728\u65b9\u6cd5\u8bba\u3001\u89e3\u91ca\u548c\u98ce\u9669\u8bc4\u4f30\u65b9\u9762\u4ea7\u751f\u6839\u672c\u4e0d\u540c\u7684\u7814\u7a76\u8def\u5f84\u3002", "motivation": "\u5f53\u524dAI\u7814\u7a76\u4e2d\u5bf9\u667a\u529b\u672c\u8d28\u7684\u9690\u542b\u5047\u8bbe\u5f71\u54cd\u4e86\u7814\u7a76\u65b9\u5411\u548c\u8bc1\u636e\u89e3\u91ca\uff0c\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u660e\u786e\u8fd9\u4e9b\u5047\u8bbe\u6765\u6f84\u6e05AI\u7814\u7a76\u4e2d\u7684\u5206\u6b67\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5f53\u524dAI\u7814\u7a76\u4e2d\u7684\u8fa9\u8bba\uff0c\u63ed\u793a\u667a\u529b\u73b0\u5b9e\u4e3b\u4e49\u548c\u667a\u529b\u591a\u5143\u4e3b\u4e49\u8fd9\u4e24\u79cd\u9690\u542b\u89c2\u70b9\u5982\u4f55\u5851\u9020\u5b9e\u8bc1\u8bc1\u636e\u7684\u89e3\u91ca\u3002", "result": "\u53d1\u73b0\u8fd9\u4e24\u79cd\u667a\u529b\u89c2\u5728\u4e09\u4e2a\u9886\u57df\u4ea7\u751f\u6839\u672c\u4e0d\u540c\u7684\u7814\u7a76\u8def\u5f84\uff1a\u65b9\u6cd5\u8bba\u4e0a\u5f71\u54cd\u6a21\u578b\u9009\u62e9\u3001\u57fa\u51c6\u8bbe\u8ba1\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff1b\u89e3\u91ca\u4e0a\u5bfc\u81f4\u5bf9\u76f8\u540c\u73b0\u8c61\u7684\u77db\u76fe\u89e3\u8bfb\uff1b\u98ce\u9669\u8bc4\u4f30\u4e0a\u4ea7\u751f\u622a\u7136\u4e0d\u540c\u7684\u5a01\u80c1\u8bc4\u4f30\u548c\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u660e\u786e\u8fd9\u4e9b\u57fa\u672c\u5047\u8bbe\u6709\u52a9\u4e8e\u66f4\u6e05\u6670\u5730\u7406\u89e3AI\u7814\u7a76\u4e2d\u7684\u5206\u6b67\uff0c\u4fc3\u8fdb\u66f4\u5bcc\u6709\u6210\u6548\u7684\u8ba8\u8bba\u3002"}}
{"id": "2511.15589", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15589", "abs": "https://arxiv.org/abs/2511.15589", "authors": ["Qian Zhu", "Yuxuan Liu", "Ziyuan Zhu", "Shangqing Liu", "Lei Bu"], "title": "EPSO: A Caching-Based Efficient Superoptimizer for BPF Bytecode", "comment": null, "summary": "Extended Berkeley Packet Filter (eBPF) allows developers to extend Linux kernel functionality without modifying its source code. To ensure system safety, an in-kernel safety checker, the verifier, enforces strict safety constraints (for example, a limited program size) on eBPF programs loaded into the kernel. These constraints, combined with eBPF's performance-critical use cases, make effective optimization essential. However, existing compilers (such as Clang) offer limited optimization support, and many semantics-preserving transformations are rejected by the verifier, which makes handcrafted optimization rule design both challenging and limited in effectiveness. Superoptimization overcomes the limitations of rule-based methods by automatically discovering optimal transformations, but its high computational cost limits scalability. To address this, we propose EPSO, a caching-based superoptimizer that discovers rewrite rules via offline superoptimization and reuses them to achieve high-quality optimizations with minimal runtime overhead. We evaluate EPSO on benchmarks from the Linux kernel and several eBPF-based projects, including Cilium, Katran, hXDP, Sysdig, Tetragon, and Tracee. EPSO discovers 795 rewrite rules and achieves up to 68.87 percent (average 24.37 percent) reduction in program size compared to Clang's output, outperforming the state-of-the-art BPF optimizer K2 on all benchmarks and Merlin on 92.68 percent of them. Additionally, EPSO reduces program runtime by an average of 6.60 percent, improving throughput and lowering latency in network applications.", "AI": {"tldr": "EPSO\u662f\u4e00\u4e2a\u57fa\u4e8e\u7f13\u5b58\u7684eBPF\u8d85\u7ea7\u4f18\u5316\u5668\uff0c\u901a\u8fc7\u79bb\u7ebf\u8d85\u7ea7\u4f18\u5316\u53d1\u73b0\u91cd\u5199\u89c4\u5219\u5e76\u91cd\u7528\uff0c\u5728\u964d\u4f4e\u8fd0\u884c\u65f6\u5f00\u9500\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u8d28\u91cf\u4f18\u5316\u3002", "motivation": "eBPF\u7a0b\u5e8f\u53d7\u9650\u4e8e\u5185\u6838\u9a8c\u8bc1\u5668\u7684\u5b89\u5168\u7ea6\u675f\u548c\u6027\u80fd\u5173\u952e\u4f7f\u7528\u573a\u666f\uff0c\u73b0\u6709\u7f16\u8bd1\u5668\u4f18\u5316\u652f\u6301\u6709\u9650\uff0c\u624b\u5de5\u4f18\u5316\u89c4\u5219\u8bbe\u8ba1\u56f0\u96be\u4e14\u6548\u679c\u6709\u9650\uff0c\u4f20\u7edf\u8d85\u7ea7\u4f18\u5316\u8ba1\u7b97\u6210\u672c\u9ad8\u96be\u4ee5\u6269\u5c55\u3002", "method": "\u63d0\u51faEPSO\u65b9\u6cd5\uff0c\u901a\u8fc7\u79bb\u7ebf\u8d85\u7ea7\u4f18\u5316\u53d1\u73b0\u91cd\u5199\u89c4\u5219\u5e76\u7f13\u5b58\uff0c\u8fd0\u884c\u65f6\u91cd\u7528\u8fd9\u4e9b\u89c4\u5219\u8fdb\u884c\u4f18\u5316\uff0c\u5e73\u8861\u4f18\u5316\u8d28\u91cf\u548c\u8ba1\u7b97\u5f00\u9500\u3002", "result": "EPSO\u53d1\u73b0795\u6761\u91cd\u5199\u89c4\u5219\uff0c\u76f8\u6bd4Clang\u8f93\u51fa\u7a0b\u5e8f\u5927\u5c0f\u6700\u591a\u51cf\u5c1168.87%\uff08\u5e73\u574724.37%\uff09\uff0c\u5728\u6240\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8eK2\uff0c\u572892.68%\u7684\u6d4b\u8bd5\u4e2d\u4f18\u4e8eMerlin\uff0c\u7a0b\u5e8f\u8fd0\u884c\u65f6\u95f4\u5e73\u5747\u51cf\u5c116.60%\u3002", "conclusion": "EPSO\u901a\u8fc7\u7f13\u5b58\u5f0f\u8d85\u7ea7\u4f18\u5316\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86eBPF\u7a0b\u5e8f\u4f18\u5316\u95ee\u9898\uff0c\u5728\u7a0b\u5e8f\u5927\u5c0f\u548c\u8fd0\u884c\u6027\u80fd\u65b9\u9762\u90fd\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2511.15665", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15665", "abs": "https://arxiv.org/abs/2511.15665", "authors": ["Huixiang Zhang", "Mahzabeen Emu"], "title": "Quantum-Guided Test Case Minimization for LLM-Based Code Generation", "comment": "This is a preprint version, full paper has been accepted in IEEE CASCON 2025 and will appear on lEEE Xplore", "summary": "Precisely controlling Large Language Models (LLMs) to generate efficient and concise code is a central challenge in software engineering. We introduce a framework based on Test-Driven Development (TDD) that transforms code specification into a combinatorial optimization task. The framework first prompts an LLM to generate a test suite, then formulates the Test Case Minimization (TCM) problem as a Quadratic Unconstrained Binary Optimization (QUBO) model. This QUBO paradigm is compatible with both classical solvers and emerging hardware such as quantum annealers. Experimentally, quantum annealing solves the core TCM task 16 times faster than simulated annealing. This performance underpins our end-to-end framework, which reduces total token consumption by 36.5\\% and significantly improves code quality. This work demonstrates a powerful synergy between generative AI and combinatorial optimization in software engineering, highlighting the critical importance of precise model formulation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6d4b\u8bd5\u9a71\u52a8\u5f00\u53d1\uff08TDD\uff09\u7684\u6846\u67b6\uff0c\u5c06\u4ee3\u7801\u89c4\u8303\u8f6c\u5316\u4e3a\u7ec4\u5408\u4f18\u5316\u4efb\u52a1\uff0c\u4f7f\u7528\u91cf\u5b50\u9000\u706b\u5668\u89e3\u51b3\u6d4b\u8bd5\u7528\u4f8b\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u663e\u8457\u51cf\u5c11\u4ee4\u724c\u6d88\u8017\u5e76\u63d0\u9ad8\u4ee3\u7801\u8d28\u91cf\u3002", "motivation": "\u7cbe\u786e\u63a7\u5236\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u9ad8\u6548\u7b80\u6d01\u4ee3\u7801\u662f\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u6838\u5fc3\u6311\u6218\uff0c\u9700\u8981\u89e3\u51b3\u4ee3\u7801\u89c4\u8303\u5230\u4f18\u5316\u4efb\u52a1\u7684\u8f6c\u6362\u95ee\u9898\u3002", "method": "\u9996\u5148\u63d0\u793aLLM\u751f\u6210\u6d4b\u8bd5\u5957\u4ef6\uff0c\u7136\u540e\u5c06\u6d4b\u8bd5\u7528\u4f8b\u6700\u5c0f\u5316\u95ee\u9898\u5efa\u6a21\u4e3a\u4e8c\u6b21\u65e0\u7ea6\u675f\u4e8c\u8fdb\u5236\u4f18\u5316\u6a21\u578b\uff0c\u517c\u5bb9\u7ecf\u5178\u6c42\u89e3\u5668\u548c\u91cf\u5b50\u9000\u706b\u5668\u3002", "result": "\u91cf\u5b50\u9000\u706b\u89e3\u51b3\u6838\u5fc3\u6d4b\u8bd5\u7528\u4f8b\u6700\u5c0f\u5316\u4efb\u52a1\u6bd4\u6a21\u62df\u9000\u706b\u5feb16\u500d\uff0c\u7aef\u5230\u7aef\u6846\u67b6\u51cf\u5c11\u603b\u4ee4\u724c\u6d88\u801736.5%\uff0c\u663e\u8457\u63d0\u9ad8\u4ee3\u7801\u8d28\u91cf\u3002", "conclusion": "\u5c55\u793a\u4e86\u751f\u6210\u5f0fAI\u4e0e\u7ec4\u5408\u4f18\u5316\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5f3a\u5927\u534f\u540c\u4f5c\u7528\uff0c\u5f3a\u8c03\u4e86\u7cbe\u786e\u6a21\u578b\u5236\u5b9a\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.15407", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.15407", "abs": "https://arxiv.org/abs/2511.15407", "authors": ["Mingyu Zhang", "Lifeng Zhuo", "Tianxi Tan", "Guocan Xie", "Xian Nie", "Yan Li", "Renjie Zhao", "Zizhu He", "Ziyu Wang", "Jiting Cai", "Yong-Lu Li"], "title": "IPR-1: Interactive Physical Reasoner", "comment": "11 pages, 5 figures", "summary": "Humans learn by observing, interacting with environments, and internalizing physics and causality. Here, we aim to ask whether an agent can similarly acquire human-like reasoning from interaction and keep improving with more experience. We study this in a Game-to-Unseen (G2U) setting, curating 1,000+ heterogeneous games with diverse physical and causal mechanisms, and evaluate at three human-like levels: Survival, Curiosity, Utility, from primitive intuition to goal-driven reasoning. Our analysis reveals complementary failures: VLM/VLA agents reason but lack look-ahead in interactive settings, while world models imagine but imitate visual patterns rather than analyze physics and causality. We therefore propose IPR (Interactive Physical Reasoner), using world-model rollouts to score and reinforce a VLM's policy, and introduce PhysCode, a physics-centric action code aligning semantic intent with dynamics to provide a shared action space for prediction and reasoning. Pretrained on 1,000+ games, our IPR performs robustly on three levels, matches GPT-5 overall, and surpasses it on Curiosity. We find that performance improves with more training games and interaction steps, and that the model also zero-shot transfers to unseen games. These results support physics-centric interaction as a path to steadily improving physical reasoning.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u667a\u80fd\u4f53\u80fd\u5426\u901a\u8fc7\u4ea4\u4e92\u5b66\u4e60\u83b7\u5f97\u7c7b\u4eba\u63a8\u7406\u80fd\u529b\uff0c\u63d0\u51fa\u4e86IPR\uff08\u4ea4\u4e92\u7269\u7406\u63a8\u7406\u5668\uff09\u6a21\u578b\uff0c\u4f7f\u7528\u4e16\u754c\u6a21\u578b\u63a8\u6f14\u6765\u8bc4\u4f30\u548c\u5f3a\u5316VLM\u7b56\u7565\uff0c\u5e76\u57281000+\u6e38\u620f\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u7814\u7a76\u667a\u80fd\u4f53\u662f\u5426\u80fd\u591f\u50cf\u4eba\u7c7b\u4e00\u6837\u901a\u8fc7\u89c2\u5bdf\u3001\u73af\u5883\u4ea4\u4e92\u6765\u5b66\u4e60\u7269\u7406\u548c\u56e0\u679c\u5173\u7cfb\uff0c\u5e76\u968f\u7740\u7ecf\u9a8c\u79ef\u7d2f\u4e0d\u65ad\u6539\u8fdb\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faIPR\u6a21\u578b\uff0c\u7ed3\u5408\u4e16\u754c\u6a21\u578b\u63a8\u6f14\u548cVLM\u7b56\u7565\u5f3a\u5316\uff0c\u5f15\u5165PhysCode\u7269\u7406\u4e2d\u5fc3\u52a8\u4f5c\u7f16\u7801\u6765\u5bf9\u9f50\u8bed\u4e49\u610f\u56fe\u4e0e\u52a8\u529b\u5b66\uff0c\u57281000+\u5f02\u6784\u6e38\u620f\u4e2d\u8bad\u7ec3\u3002", "result": "IPR\u5728\u4e09\u4e2a\u7c7b\u4eba\u63a8\u7406\u7ea7\u522b\uff08\u751f\u5b58\u3001\u597d\u5947\u5fc3\u3001\u6548\u7528\uff09\u4e0a\u8868\u73b0\u7a33\u5065\uff0c\u6574\u4f53\u6027\u80fd\u4e0eGPT-5\u76f8\u5f53\uff0c\u5728\u597d\u5947\u5fc3\u65b9\u9762\u8d85\u8d8aGPT-5\uff0c\u4e14\u6027\u80fd\u968f\u8bad\u7ec3\u6e38\u620f\u548c\u4ea4\u4e92\u6b65\u9aa4\u589e\u52a0\u800c\u63d0\u5347\uff0c\u80fd\u96f6\u6837\u672c\u8fc1\u79fb\u5230\u672a\u89c1\u6e38\u620f\u3002", "conclusion": "\u7269\u7406\u4e2d\u5fc3\u7684\u4ea4\u4e92\u662f\u6301\u7eed\u6539\u8fdb\u7269\u7406\u63a8\u7406\u80fd\u529b\u7684\u6709\u6548\u8def\u5f84\uff0c\u6a21\u578b\u80fd\u591f\u901a\u8fc7\u66f4\u591a\u4ea4\u4e92\u7ecf\u9a8c\u4e0d\u65ad\u63d0\u5347\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2511.15456", "categories": ["cs.AI", "q-fin.GN"], "pdf": "https://arxiv.org/pdf/2511.15456", "abs": "https://arxiv.org/abs/2511.15456", "authors": ["Qian'ang Mao", "Yuxuan Zhang", "Jiaman Chen", "Wenjun Zhou", "Jiaqi Yan"], "title": "Know Your Intent: An Autonomous Multi-Perspective LLM Agent Framework for DeFi User Transaction Intent Mining", "comment": "Written in 2025 Q1", "summary": "As Decentralized Finance (DeFi) develops, understanding user intent behind DeFi transactions is crucial yet challenging due to complex smart contract interactions, multifaceted on-/off-chain factors, and opaque hex logs. Existing methods lack deep semantic insight. To address this, we propose the Transaction Intent Mining (TIM) framework. TIM leverages a DeFi intent taxonomy built on grounded theory and a multi-agent Large Language Model (LLM) system to robustly infer user intents. A Meta-Level Planner dynamically coordinates domain experts to decompose multiple perspective-specific intent analyses into solvable subtasks. Question Solvers handle the tasks with multi-modal on/off-chain data. While a Cognitive Evaluator mitigates LLM hallucinations and ensures verifiability. Experiments show that TIM significantly outperforms machine learning models, single LLMs, and single Agent baselines. We also analyze core challenges in intent inference. This work helps provide a more reliable understanding of user motivations in DeFi, offering context-aware explanations for complex blockchain activity.", "AI": {"tldr": "\u63d0\u51fa\u4e86TIM\u6846\u67b6\uff0c\u5229\u7528DeFi\u610f\u56fe\u5206\u7c7b\u6cd5\u548c\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u6765\u63a8\u65ad\u7528\u6237\u4ea4\u6613\u610f\u56fe\uff0c\u901a\u8fc7\u52a8\u6001\u534f\u8c03\u9886\u57df\u4e13\u5bb6\u5904\u7406\u591a\u6a21\u6001\u94fe\u4e0a/\u94fe\u4e0b\u6570\u636e\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "DeFi\u4ea4\u6613\u4e2d\u7528\u6237\u610f\u56fe\u7406\u89e3\u81f3\u5173\u91cd\u8981\u4f46\u5177\u6709\u6311\u6218\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u6df1\u5ea6\u8bed\u4e49\u6d1e\u5bdf\uff0c\u9700\u8981\u89e3\u51b3\u590d\u6742\u667a\u80fd\u5408\u7ea6\u4ea4\u4e92\u3001\u591a\u56e0\u7d20\u5f71\u54cd\u548c\u6a21\u7cca\u65e5\u5fd7\u7684\u95ee\u9898\u3002", "method": "TIM\u6846\u67b6\u5305\u542bDeFi\u610f\u56fe\u5206\u7c7b\u6cd5\u3001\u5143\u7ea7\u89c4\u5212\u5668\u52a8\u6001\u534f\u8c03\u9886\u57df\u4e13\u5bb6\u3001\u95ee\u9898\u6c42\u89e3\u5668\u5904\u7406\u591a\u6a21\u6001\u6570\u636e\u3001\u8ba4\u77e5\u8bc4\u4f30\u5668\u51cf\u8f7bLLM\u5e7b\u89c9\u5e76\u786e\u4fdd\u53ef\u9a8c\u8bc1\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660eTIM\u663e\u8457\u4f18\u4e8e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3001\u5355\u4e00LLM\u548c\u5355\u4e00\u667a\u80fd\u4f53\u57fa\u7ebf\uff0c\u80fd\u591f\u5206\u6790\u610f\u56fe\u63a8\u65ad\u4e2d\u7684\u6838\u5fc3\u6311\u6218\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u6709\u52a9\u4e8e\u66f4\u53ef\u9760\u5730\u7406\u89e3DeFi\u4e2d\u7528\u6237\u52a8\u673a\uff0c\u4e3a\u590d\u6742\u533a\u5757\u94fe\u6d3b\u52a8\u63d0\u4f9b\u60c5\u5883\u611f\u77e5\u89e3\u91ca\u3002"}}
