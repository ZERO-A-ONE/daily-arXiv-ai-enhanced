{"id": "2509.04710", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.04710", "abs": "https://arxiv.org/abs/2509.04710", "authors": ["Zhou Li", "Yu Zheng", "Tianhao Wang", "Sang-Woo Jun"], "title": "Network-Aware Differential Privacy", "comment": null, "summary": "Differential privacy (DP) is a privacy-enhancement technology (PET) that\nreceives prominent attention from the academia, industry, and government. One\nmain development over the past decade has been the decentralization of DP,\nincluding local DP and shuffle DP. Despite that decentralized DP heavily relies\non network communications for data collection,we found that: 1) no systematic\nstudy has surveyed the research opportunities at the intersection of networking\nand DP; 2) nor have there been significant efforts to develop DP mechanisms\nthat are explicitly tailored for network environments. In this paper, we seek\nto address this gap by initiating a new direction of network-aware DP. We\nidentified two focus areas where the network research can offer substantive\ncontributions to the design and deployment of DP, related to network security\nand topology. Through this work, we hope to encourage more research that\nadapt/optimize DP's deployment in various network environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7f51\u7edc\u611f\u77e5\u5dee\u5206\u9690\u79c1\u7684\u65b0\u65b9\u5411\uff0c\u65e8\u5728\u586b\u8865\u7f51\u7edc\u901a\u4fe1\u4e0e\u5dee\u5206\u9690\u79c1\u7814\u7a76\u4e4b\u95f4\u7684\u7a7a\u767d\uff0c\u91cd\u70b9\u5173\u6ce8\u7f51\u7edc\u5b89\u5168\u548c\u62d3\u6251\u7ed3\u6784\u5bf9DP\u90e8\u7f72\u7684\u5f71\u54cd\u3002", "motivation": "\u5f53\u524d\u53bb\u4e2d\u5fc3\u5316\u5dee\u5206\u9690\u79c1\uff08\u5305\u62ec\u672c\u5730DP\u548c\u6df7\u6d17DP\uff09\u4e25\u91cd\u4f9d\u8d56\u7f51\u7edc\u901a\u4fe1\u8fdb\u884c\u6570\u636e\u6536\u96c6\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u7f51\u7edc\u73af\u5883\u4e0eDP\u4ea4\u53c9\u7814\u7a76\u7684\u7cfb\u7edf\u8c03\u67e5\uff0c\u4e5f\u6ca1\u6709\u4e13\u95e8\u4e3a\u7f51\u7edc\u73af\u5883\u5b9a\u5236\u7684DP\u673a\u5236\u3002", "method": "\u901a\u8fc7\u8bc6\u522b\u7f51\u7edc\u7814\u7a76\u53ef\u4ee5\u4e3aDP\u8bbe\u8ba1\u548c\u90e8\u7f72\u505a\u51fa\u5b9e\u8d28\u6027\u8d21\u732e\u7684\u4e24\u4e2a\u91cd\u70b9\u9886\u57df\uff1a\u7f51\u7edc\u5b89\u5168\u548c\u7f51\u7edc\u62d3\u6251\u7ed3\u6784\uff0c\u63d0\u51fa\u4e86\u7f51\u7edc\u611f\u77e5\u5dee\u5206\u9690\u79c1\u7684\u65b0\u7814\u7a76\u65b9\u5411\u3002", "result": "\u63d0\u51fa\u4e86\u7f51\u7edc\u611f\u77e5\u5dee\u5206\u9690\u79c1\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u660e\u786e\u4e86\u7f51\u7edc\u73af\u5883\u5bf9DP\u90e8\u7f72\u7684\u91cd\u8981\u5f71\u54cd\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u6027\u6307\u5bfc\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u65e8\u5728\u9f13\u52b1\u66f4\u591a\u7814\u7a76\u6765\u9002\u5e94\u548c\u4f18\u5316DP\u5728\u5404\u79cd\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u90e8\u7f72\uff0c\u63a8\u52a8\u7f51\u7edc\u901a\u4fe1\u4e0e\u9690\u79c1\u4fdd\u62a4\u6280\u672f\u7684\u6df1\u5ea6\u878d\u5408\u3002"}}
{"id": "2509.04941", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.04941", "abs": "https://arxiv.org/abs/2509.04941", "authors": ["Xiaogang Cheng", "Ren Guo", "Zuxi Chen"], "title": "Cryptographic Application of Elliptic Curve with High Rank", "comment": null, "summary": "Elliptic curve cryptography is better than traditional cryptography based on\nRSA and discrete logarithm of finite field in terms of efficiency and security.\nIn this paper, we show how to exploit elliptic curve with high rank, which has\nnot been used in cryptography before, to construct cryptographic schemes.\nConcretely we demonstrate how to construct public key signature scheme with\nhierarchy revocation based on elliptic curve with high rank, where the rank\ndetermines the height of the revocation tree. Although our construction is not\nvery efficient in some sense, our construction shows elliptic curve with high\nrank is valuable and important for cryptographic usage. The technique and\nassumption presented can surely be used for other cryptographic constructions.", "AI": {"tldr": "\u57fa\u4e8e\u9ad8\u9636\u6392\u7684\u692d\u5706\u66f2\u7ebf\u6784\u5efa\u5206\u5c42\u64a4\u9500\u7684\u516c\u94a5\u7b7e\u540d\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u9ad8\u9636\u6392\u692d\u5706\u66f2\u7ebf\u5728\u52a0\u5bc6\u4e2d\u7684\u5e94\u7528\u4ef7\u503c", "motivation": "\u692d\u5706\u66f2\u52a0\u5bc6\u5728\u6548\u7387\u548c\u5b89\u5168\u6027\u65b9\u9762\u90fd\u4f18\u4e8e\u4f20\u7edf\u7684RSA\u548c\u6709\u9650\u57df\u79bb\u6563\u5bf9\u6570\u52a0\u5bc6\uff0c\u4f46\u9ad8\u9636\u6392\u7684\u692d\u5706\u66f2\u5728\u52a0\u5bc6\u4e2d\u5c1a\u672a\u5f97\u5230\u5145\u5206\u5229\u7528", "method": "\u5229\u7528\u9ad8\u9636\u6392\u7684\u692d\u5706\u66f2\u6784\u5efa\u516c\u94a5\u7b7e\u540d\u65b9\u6848\uff0c\u5176\u4e2d\u6392\u7684\u9ad8\u5ea6\u51b3\u5b9a\u4e86\u64a4\u9500\u6811\u7684\u9ad8\u5ea6", "result": "\u867d\u7136\u5728\u67d0\u4e9b\u65b9\u9762\u6548\u7387\u4e0d\u662f\u5f88\u9ad8\uff0c\u4f46\u6210\u529f\u5c55\u793a\u4e86\u9ad8\u9636\u6392\u692d\u5706\u66f2\u5728\u52a0\u5bc6\u4e2d\u7684\u4ef7\u503c\u548c\u91cd\u8981\u6027", "conclusion": "\u9ad8\u9636\u6392\u692d\u5706\u66f2\u5bf9\u4e8e\u52a0\u5bc6\u5e94\u7528\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u6240\u63d0\u51fa\u7684\u6280\u672f\u548c\u5047\u8bbe\u53ef\u4ee5\u5e94\u7528\u4e8e\u5176\u4ed6\u52a0\u5bc6\u6784\u9020"}}
{"id": "2509.04999", "categories": ["cs.CR", "cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.04999", "abs": "https://arxiv.org/abs/2509.04999", "authors": ["Sidahmed Benabderrahmane", "Talal Rahwan"], "title": "Adversarial Augmentation and Active Sampling for Robust Cyber Anomaly Detection", "comment": null, "summary": "Advanced Persistent Threats (APTs) present a considerable challenge to\ncybersecurity due to their stealthy, long-duration nature. Traditional\nsupervised learning methods typically require large amounts of labeled data,\nwhich is often scarce in real-world scenarios. This paper introduces a novel\napproach that combines AutoEncoders for anomaly detection with active learning\nto iteratively enhance APT detection. By selectively querying an oracle for\nlabels on uncertain or ambiguous samples, our method reduces labeling costs\nwhile improving detection accuracy, enabling the model to effectively learn\nwith minimal data and reduce reliance on extensive manual labeling. We present\na comprehensive formulation of the Attention Adversarial Dual AutoEncoder-based\nanomaly detection framework and demonstrate how the active learning loop\nprogressively enhances the model's performance. The framework is evaluated on\nreal-world, imbalanced provenance trace data from the DARPA Transparent\nComputing program, where APT-like attacks account for just 0.004\\% of the data.\nThe datasets, which cover multiple operating systems including Android, Linux,\nBSD, and Windows, are tested in two attack scenarios. The results show\nsubstantial improvements in detection rates during active learning,\noutperforming existing methods.", "AI": {"tldr": "\u7ed3\u5408\u81ea\u7f16\u7801\u5668\u5f02\u5e38\u68c0\u6d4b\u4e0e\u4e3b\u52a8\u5b66\u4e60\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8eAPT\u68c0\u6d4b\uff0c\u5728\u6570\u636e\u6781\u5ea6\u4e0d\u5e73\u8861\uff08APT\u653b\u51fb\u4ec5\u53600.004%\uff09\u7684\u771f\u5b9e\u573a\u666f\u4e2d\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u7387", "motivation": "APT\u653b\u51fb\u5177\u6709\u9690\u853d\u6027\u548c\u957f\u671f\u6027\uff0c\u4f20\u7edf\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u800c\u73b0\u5b9e\u573a\u666f\u4e2d\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u4e14\u6210\u672c\u9ad8\u6602", "method": "\u63d0\u51fa\u6ce8\u610f\u529b\u5bf9\u6297\u53cc\u81ea\u7f16\u7801\u5668\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u7ed3\u5408\u4e3b\u52a8\u5b66\u4e60\u5faa\u73af\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u67e5\u8be2\u4e0d\u786e\u5b9a\u6837\u672c\u7684\u6807\u7b7e\u6765\u51cf\u5c11\u6807\u6ce8\u6210\u672c", "result": "\u5728DARPA\u900f\u660e\u8ba1\u7b97\u9879\u76ee\u7684\u771f\u5b9e\u6eaf\u6e90\u6570\u636e\u4e0a\u6d4b\u8bd5\uff0c\u6db5\u76d6Android\u3001Linux\u3001BSD\u548cWindows\u591a\u4e2a\u7cfb\u7edf\uff0c\u5728\u4e24\u79cd\u653b\u51fb\u573a\u666f\u4e0b\u68c0\u6d4b\u7387\u663e\u8457\u63d0\u5347\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u4ee5\u6700\u5c0f\u6570\u636e\u6709\u6548\u5b66\u4e60\uff0c\u51cf\u5c11\u5bf9\u5927\u91cf\u4eba\u5de5\u6807\u6ce8\u7684\u4f9d\u8d56\uff0c\u5728APT\u68c0\u6d4b\u9886\u57df\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c"}}
{"id": "2509.05104", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.05104", "abs": "https://arxiv.org/abs/2509.05104", "authors": ["Richard Derbyshire", "Diana Selck-Paulsson", "Charl van der Walt", "Joe Burton"], "title": "From Protest to Power Plant: Interpreting the Role of Escalatory Hacktivism in Cyber Conflict", "comment": null, "summary": "Since 2022, hacktivist groups have escalated their tactics, expanding from\ndistributed denial-of-service attacks and document leaks to include targeting\noperational technology (OT). By 2024, attacks on the OT of critical national\ninfrastructure (CNI) had been linked to partisan hacktivist efforts in ongoing\ngeopolitical conflicts, demonstrating a shift from protest to something more\nresembling cyber warfare. This escalation raises critical questions about the\nclassification of these groups and the appropriate state response to their\ngrowing role in destabilizing international security.\n  This paper examines the strategic motivations behind escalatory hacktivism,\nhighlighting how states may tolerate, encourage, or leverage hacktivist groups\nas proxies in conflicts that blur the lines between activism, cybercrime, and\nstate-sponsored operations. We introduce a novel method for interpreting\nhacktivists based on the impact of their actions, alignment to state ideology,\nand host state involvement, offering a structured approach to understanding the\nphenomenon. Finally, we assess policy and security implications, particularly\nfor host and victim states, and propose strategies to address this evolving\nthreat. By doing so, this paper contributes to international discussions on\ncyber security policy, governance, and the increasing intersection between\nnon-state cyber actors and state interests.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e862022\u5e74\u4ee5\u6765\u9ed1\u5ba2\u6d3b\u52a8\u5206\u5b50\u6218\u672f\u7684\u5347\u7ea7\uff0c\u4eceDDoS\u653b\u51fb\u6269\u5c55\u5230\u9488\u5bf9\u5173\u952e\u56fd\u5bb6\u57fa\u7840\u8bbe\u65bd\u7684OT\u7cfb\u7edf\uff0c\u63a2\u8ba8\u4e86\u5176\u6218\u7565\u52a8\u673a\u3001\u56fd\u5bb6\u89d2\u8272\u53ca\u653f\u7b56\u5e94\u5bf9\u7b56\u7565\u3002", "motivation": "\u7814\u7a76\u9ed1\u5ba2\u6d3b\u52a8\u5206\u5b50\u6218\u672f\u5347\u7ea7\u80cc\u540e\u7684\u6218\u7565\u52a8\u673a\uff0c\u5206\u6790\u56fd\u5bb6\u5982\u4f55\u5bb9\u5fcd\u3001\u9f13\u52b1\u6216\u5229\u7528\u8fd9\u4e9b\u7ec4\u7ec7\u4f5c\u4e3a\u4ee3\u7406\u4eba\uff0c\u4ee5\u53ca\u8fd9\u79cd\u73b0\u8c61\u5bf9\u56fd\u9645\u5b89\u5168\u7684\u5a01\u80c1\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u884c\u52a8\u5f71\u54cd\u3001\u4e0e\u56fd\u5bb6\u610f\u8bc6\u5f62\u6001\u4e00\u81f4\u6027\u4ee5\u53ca\u4e1c\u9053\u56fd\u53c2\u4e0e\u7a0b\u5ea6\u7684\u65b0\u65b9\u6cd5\u6765\u89e3\u91ca\u9ed1\u5ba2\u6d3b\u52a8\u5206\u5b50\u73b0\u8c61\u3002", "result": "\u63ed\u793a\u4e86\u9ed1\u5ba2\u6d3b\u52a8\u5206\u5b50\u4ece\u6297\u8bae\u6d3b\u52a8\u5411\u7c7b\u4f3c\u7f51\u7edc\u6218\u4e89\u7684\u8f6c\u53d8\uff0c\u5c55\u793a\u4e86\u56fd\u5bb6\u5229\u76ca\u4e0e\u975e\u56fd\u5bb6\u7f51\u7edc\u884c\u4e3a\u4f53\u4e4b\u95f4\u65e5\u76ca\u4ea4\u7ec7\u7684\u5173\u7cfb\u3002", "conclusion": "\u4e3a\u7f51\u7edc\u5b89\u5168\u653f\u7b56\u3001\u6cbb\u7406\u4ee5\u53ca\u5e94\u5bf9\u8fd9\u4e00\u4e0d\u65ad\u6f14\u53d8\u7684\u5a01\u80c1\u63d0\u4f9b\u4e86\u7b56\u7565\u5efa\u8bae\uff0c\u4fc3\u8fdb\u4e86\u5173\u4e8e\u975e\u56fd\u5bb6\u7f51\u7edc\u884c\u4e3a\u4f53\u4e0e\u56fd\u5bb6\u5229\u76ca\u4ea4\u53c9\u7684\u56fd\u9645\u8ba8\u8bba\u3002"}}
{"id": "2509.04644", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.04644", "abs": "https://arxiv.org/abs/2509.04644", "authors": ["Subhang Boorlagadda", "Nitya Naga Sai Atluri", "Muhammet Mustafa Olmez", "Edward F. Gehringer"], "title": "Comparative Evaluation of Large Language Models for Test-Skeleton Generation", "comment": "Forthcoming in Frontiers in Education (FIE 2025), Nashville,\n  Tennessee, USA, Nov 2-5, 2025", "summary": "This paper explores the use of Large Language Models (LLMs) to automate the\ngeneration of test skeletons -- structural templates that outline unit test\ncoverage without implementing full test logic. Test skeletons are especially\nimportant in test-driven development (TDD), where they provide an early\nframework for systematic verification. Traditionally authored manually, their\ncreation can be time-consuming and error-prone, particularly in educational or\nlarge-scale development settings. We evaluate four LLMs -- GPT-4,\nDeepSeek-Chat, Llama4-Maverick, and Gemma2-9B -- on their ability to generate\nRSpec skeletons for a real-world Ruby class developed in a university software\nengineering course. Each model's output is assessed using static analysis and a\nblind expert review to measure structural correctness, clarity,\nmaintainability, and conformance to testing best practices. The study reveals\nkey differences in how models interpret code structure and testing conventions,\noffering insights into the practical challenges of using LLMs for automated\ntest scaffolding. Our results show that DeepSeek generated the most\nmaintainable and well-structured skeletons, while GPT-4 produced more complete\nbut conventionally inconsistent output. The study reveals prompt design and\ncontextual input as key quality factors.", "AI": {"tldr": "\u4f7f\u7528LLM\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u67b6\u6784\uff0c\u8bc4\u4f30\u56db\u6b3e\u6a21\u578b\u5728Ruby RSpec\u6d4b\u8bd5\u751f\u6210\u4e2d\u7684\u6027\u80fd\u5dee\u5f02", "motivation": "\u624b\u52a8\u521b\u5efa\u6d4b\u8bd5\u67b6\u6784\u8017\u65f6\u6613\u9519\uff0c\u7279\u522b\u5728\u6559\u80b2\u548c\u5927\u89c4\u6a21\u5f00\u53d1\u73af\u5883\u4e2d\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u63d0\u9ad8\u6548\u7387", "method": "\u9009\u53d6GPT-4\u3001DeepSeek-Chat\u3001Llama4-Maverick\u548cGemma2-9B\u56db\u6b3eLLM\uff0c\u901a\u8fc7\u9759\u6001\u5206\u6790\u548c\u76f2\u6d4b\u4e13\u5bb6\u8bc4\u5ba1\u8bc4\u4f30\u751f\u6210\u7684RSpec\u6d4b\u8bd5\u67b6\u6784\u7684\u7ed3\u6784\u6b63\u786e\u6027\u3001\u6e05\u6670\u5ea6\u3001\u53ef\u7ef4\u62a4\u6027\u548c\u6700\u4f73\u5b9e\u8df5\u9075\u5faa\u7a0b\u5ea6", "result": "DeepSeek\u751f\u6210\u4e86\u6700\u53ef\u7ef4\u62a4\u548c\u7ed3\u6784\u826f\u597d\u7684\u6d4b\u8bd5\u67b6\u6784\uff0cGPT-4\u4ea7\u51fa\u66f4\u5b8c\u6574\u4f46\u7f26\u7ed5\u4e0d\u4e00\u81f4\u7684\u8f93\u51fa\uff0c\u63d0\u793a\u8bbe\u8ba1\u548c\u4e0a\u4e0b\u6587\u8f93\u5165\u662f\u5173\u952e\u8d28\u91cf\u56e0\u7d20", "conclusion": "LLM\u53ef\u4ee5\u6709\u6548\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u67b6\u6784\uff0c\u4f46\u4e0d\u540c\u6a21\u578b\u5728\u4ee3\u7801\u7ed3\u6784\u7406\u89e3\u548c\u6d4b\u8bd5\u7ea6\u5b9a\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u9700\u8981\u7cbe\u5fc3\u8bbe\u8ba1\u63d0\u793a\u8bcd\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f"}}
{"id": "2509.04505", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.04505", "abs": "https://arxiv.org/abs/2509.04505", "authors": ["Somtochukwu Azie", "Yiping Meng"], "title": "The Ethical Compass of the Machine: Evaluating Large Language Models for Decision Support in Construction Project Management", "comment": "16 Pages", "summary": "The integration of Artificial Intelligence (AI) into construction project\nmanagement (CPM) is accelerating, with Large Language Models (LLMs) emerging as\naccessible decision-support tools. This study aims to critically evaluate the\nethical viability and reliability of LLMs when applied to the ethically\nsensitive, high-risk decision-making contexts inherent in CPM. A mixed-methods\nresearch design was employed, involving the quantitative performance testing of\ntwo leading LLMs against twelve real-world ethical scenarios using a novel\nEthical Decision Support Assessment Checklist (EDSAC), and qualitative analysis\nof semi-structured interviews with 12 industry experts to capture professional\nperceptions. The findings reveal that while LLMs demonstrate adequate\nperformance in structured domains such as legal compliance, they exhibit\nsignificant deficiencies in handling contextual nuance, ensuring\naccountability, and providing transparent reasoning. Stakeholders expressed\nconsiderable reservations regarding the autonomous use of AI for ethical\njudgments, strongly advocating for robust human-in-the-loop oversight. To our\nknowledge, this is one of the first studies to empirically test the ethical\nreasoning of LLMs within the construction domain. It introduces the EDSAC\nframework as a replicable methodology and provides actionable recommendations,\nemphasising that LLMs are currently best positioned as decision-support aids\nrather than autonomous ethical agents.", "AI": {"tldr": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5efa\u7b51\u9879\u76ee\u7ba1\u7406\u4e2d\u7684\u4f26\u7406\u51b3\u7b56\u652f\u6301\u80fd\u529b\u5b58\u5728\u663e\u8457\u7f3a\u9677\uff0c\u9700\u8981\u4eba\u7c7b\u76d1\u7763", "motivation": "\u8bc4\u4f30LLM\u5728\u5efa\u7b51\u9879\u76ee\u7ba1\u7406\u8fd9\u4e2a\u9ad8\u98ce\u9669\u3001\u4f26\u7406\u654f\u611f\u9886\u57df\u7684\u4f26\u7406\u53ef\u9760\u6027\u548c\u53ef\u884c\u6027", "method": "\u6df7\u5408\u65b9\u6cd5\u7814\u7a76\u8bbe\u8ba1\uff1a\u91cf\u5316\u6d4b\u8bd5\u4e24\u4e2a\u9886\u5148LLM\u572812\u4e2a\u771f\u5b9e\u4f26\u7406\u573a\u666f\u4e2d\u7684\u8868\u73b0\uff08\u4f7f\u7528EDSAC\u68c0\u67e5\u8868\uff09\uff0c\u8d28\u6027\u5206\u679012\u4f4d\u884c\u4e1a\u4e13\u5bb6\u7684\u534a\u7ed3\u6784\u5316\u8bbf\u8c08", "result": "LLM\u5728\u6cd5\u5f8b\u9075\u5faa\u7b49\u7ed3\u6784\u5316\u9886\u57df\u8868\u73b0\u8fc5\u901f\uff0c\u4f46\u5728\u5904\u7406\u4e0a\u4e0b\u6587\u7ec6\u8282\u3001\u786e\u4fdd\u8d1f\u8d23\u4efb\u548c\u63d0\u4f9b\u900f\u660e\u63a8\u7406\u65b9\u9762\u5b58\u5728\u663e\u8457\u7f3a\u9677", "conclusion": "LLM\u76ee\u524d\u5e94\u4f5c\u4e3a\u51b3\u7b56\u652f\u6301\u5de5\u5177\uff0c\u800c\u975e\u81ea\u4e3b\u4f26\u7406\u51b3\u7b56\u8005\uff0c\u5fc5\u987b\u5f3a\u8c03\u4eba\u7c7b\u5728\u73af\u4e2d\u7684\u76d1\u7763\u4f5c\u7528"}}
{"id": "2509.05149", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.05149", "abs": "https://arxiv.org/abs/2509.05149", "authors": ["Huy Hung Ho", "Nhan Le Thanh"], "title": "Odoo-based Subcontract Inter-site Access Control Mechanism for Construction Projects", "comment": "7 pages, 2 figures, The 9th OISP Science and Technology Symposium", "summary": "In the era of Construction 4.0, the industry is embracing a new paradigm of\nlabor elasticity, driven by smart and flexible outsourcing and subcontracting\nstrategies. The increased reliance on specialized subcontractors enables\ncompanies to scale labor dynamically based on project demands. This adaptable\nworkforce model presents challenges in managing hierarchical integration and\ncoordinating inter-site collaboration. Our design introduces a subsystem\nintegrated into the Odoo ERP framework, employing a modular architecture to\nstreamline labor management, task tracking, and approval workflows. The system\nadopts a three-pronged approach to ensure synchronized data exchange between\ngeneral contractors and subcontractors, while maintaining both security and\noperational independence. The system features hybrid access control,\nthird-party integration for cross-domain communication, and role-based mapping\nalgorithm across sites. The system supports varying degrees of customization\nthrough a unified and consolidated attribute mapping center. This center\nleverages a tree-like index structure and Lagrange interpolation method to\nenhance the efficiency of role mapping. Demonstrations highlight practical\napplication in outsourcing, integration, and scalability scenarios, confirming\nthe system's robustness under high user volumes and in offline conditions.\nExperimental results further show improvements in database performance and\nworkflow adaptability to support a scalable, enterprise-level solution that\naligns with the evolving demands of smart construction management.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u96c6\u6210\u5230Odoo ERP\u6846\u67b6\u4e2d\u7684\u52b3\u52a8\u529b\u7ba1\u7406\u5b50\u7cfb\u7edf\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u67b6\u6784\u548c\u6df7\u5408\u8bbf\u95ee\u63a7\u5236\uff0c\u89e3\u51b3\u5efa\u7b514.0\u65f6\u4ee3\u5f39\u6027\u52b3\u52a8\u529b\u7ba1\u7406\u4e2d\u7684\u5c42\u6b21\u96c6\u6210\u548c\u8de8\u7ad9\u70b9\u534f\u4f5c\u6311\u6218\u3002", "motivation": "\u5efa\u7b514.0\u65f6\u4ee3\u91c7\u7528\u5f39\u6027\u52b3\u52a8\u529b\u6a21\u5f0f\uff0c\u4f9d\u8d56\u4e13\u4e1a\u5206\u5305\u5546\u6309\u9700\u52a8\u6001\u6269\u5c55\u52b3\u52a8\u529b\uff0c\u4f46\u9762\u4e34\u5c42\u6b21\u96c6\u6210\u7ba1\u7406\u548c\u8de8\u7ad9\u70b9\u534f\u4f5c\u534f\u8c03\u7684\u6311\u6218\u3002", "method": "\u91c7\u7528\u4e09\u7ba1\u9f50\u4e0b\u7684\u65b9\u6cd5\uff1a\u6df7\u5408\u8bbf\u95ee\u63a7\u5236\u3001\u7b2c\u4e09\u65b9\u8de8\u57df\u901a\u4fe1\u96c6\u6210\u3001\u57fa\u4e8e\u89d2\u8272\u7684\u8de8\u7ad9\u70b9\u6620\u5c04\u7b97\u6cd5\uff1b\u4f7f\u7528\u6811\u72b6\u7d22\u5f15\u7ed3\u6784\u548c\u62c9\u683c\u6717\u65e5\u63d2\u503c\u6cd5\u63d0\u5347\u89d2\u8272\u6620\u5c04\u6548\u7387\uff1b\u901a\u8fc7\u7edf\u4e00\u5c5e\u6027\u6620\u5c04\u4e2d\u5fc3\u652f\u6301\u5b9a\u5236\u5316\u3002", "result": "\u7cfb\u7edf\u5728\u9ad8\u7528\u6237\u91cf\u548c\u79bb\u7ebf\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u9c81\u68d2\u6027\uff1b\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u6570\u636e\u5e93\u6027\u80fd\u548c\u5de5\u4f5c\u6d41\u9002\u5e94\u6027\u5f97\u5230\u6539\u5584\uff0c\u652f\u6301\u53ef\u6269\u5c55\u7684\u4f01\u4e1a\u7ea7\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u80fd\u591f\u6ee1\u8db3\u667a\u80fd\u5efa\u7b51\u7ba1\u7406\u4e0d\u65ad\u53d1\u5c55\u7684\u9700\u6c42\uff0c\u4e3a\u5f39\u6027\u52b3\u52a8\u529b\u7ba1\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6280\u672f\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.04721", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.04721", "abs": "https://arxiv.org/abs/2509.04721", "authors": ["Abhishek Dey", "Saurabh Srivastava", "Gaurav Singh", "Robert G. Pettit"], "title": "Real-Time Performance Benchmarking of TinyML Models in Embedded Systems (PICO: Performance of Inference, CPU, and Operations)", "comment": null, "summary": "This paper presents PICO-TINYML-BENCHMARK, a modular and platform-agnostic\nframework for benchmarking the real-time performance of TinyML models on\nresource-constrained embedded systems. Evaluating key metrics such as inference\nlatency, CPU utilization, memory efficiency, and prediction stability, the\nframework provides insights into computational trade-offs and platform-specific\noptimizations. We benchmark three representative TinyML models -- Gesture\nClassification, Keyword Spotting, and MobileNet V2 -- on two widely adopted\nplatforms, BeagleBone AI64 and Raspberry Pi 4, using real-world datasets.\nResults reveal critical trade-offs: the BeagleBone AI64 demonstrates consistent\ninference latency for AI-specific tasks, while the Raspberry Pi 4 excels in\nresource efficiency and cost-effectiveness. These findings offer actionable\nguidance for optimizing TinyML deployments, bridging the gap between\ntheoretical advancements and practical applications in embedded systems.", "AI": {"tldr": "PICO-TINYML-BENCHMARK\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u3001\u5e73\u53f0\u65e0\u5173\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u8d44\u6e90\u53d7\u9650\u7684\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4e0a\u57fa\u51c6\u6d4b\u8bd5TinyML\u6a21\u578b\u7684\u5b9e\u65f6\u6027\u80fd\uff0c\u8bc4\u4f30\u63a8\u7406\u5ef6\u8fdf\u3001CPU\u5229\u7528\u7387\u3001\u5185\u5b58\u6548\u7387\u548c\u9884\u6d4b\u7a33\u5b9a\u6027\u7b49\u5173\u952e\u6307\u6807\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3TinyML\u6a21\u578b\u5728\u5d4c\u5165\u5f0f\u7cfb\u7edf\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u6027\u80fd\u8bc4\u4f30\u95ee\u9898\uff0c\u63d0\u4f9b\u8ba1\u7b97\u6743\u8861\u548c\u5e73\u53f0\u7279\u5b9a\u4f18\u5316\u7684\u89c1\u89e3\uff0c\u5f25\u5408\u7406\u8bba\u8fdb\u5c55\u4e0e\u5b9e\u9645\u5e94\u7528\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u5f00\u53d1\u6a21\u5757\u5316\u5e73\u53f0\u65e0\u5173\u6846\u67b6\uff0c\u5728BeagleBone AI64\u548cRaspberry Pi 4\u5e73\u53f0\u4e0a\u5bf9\u4e09\u79cd\u4ee3\u8868\u6027TinyML\u6a21\u578b\uff08\u624b\u52bf\u5206\u7c7b\u3001\u5173\u952e\u8bcd\u8bc6\u522b\u3001MobileNet V2\uff09\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4f7f\u7528\u771f\u5b9e\u6570\u636e\u96c6\u8bc4\u4f30\u5173\u952e\u6027\u80fd\u6307\u6807\u3002", "result": "BeagleBone AI64\u5728AI\u7279\u5b9a\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u63a8\u7406\u5ef6\u8fdf\uff0c\u800cRaspberry Pi 4\u5728\u8d44\u6e90\u6548\u7387\u548c\u6210\u672c\u6548\u76ca\u65b9\u9762\u66f4\u4f18\uff0c\u63ed\u793a\u4e86\u5173\u952e\u7684\u8ba1\u7b97\u6743\u8861\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u4f18\u5316TinyML\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6307\u5bfc\uff0c\u6709\u52a9\u4e8e\u5728\u5b9e\u9645\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4e2d\u66f4\u597d\u5730\u5e94\u7528TinyML\u6280\u672f\u3002"}}
{"id": "2509.04642", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.04642", "abs": "https://arxiv.org/abs/2509.04642", "authors": ["Wenxiao Wang", "Priyatham Kattakinda", "Soheil Feizi"], "title": "Maestro: Joint Graph & Config Optimization for Reliable AI Agents", "comment": "Technical Report by RELAI.ai", "summary": "Building reliable LLM agents requires decisions at two levels: the graph\n(which modules exist and how information flows) and the configuration of each\nnode (models, prompts, tools, control knobs). Most existing optimizers tune\nconfigurations while holding the graph fixed, leaving structural failure modes\nunaddressed. We introduce Maestro, a framework-agnostic holistic optimizer for\nLLM agents that jointly searches over graphs and configurations to maximize\nagent quality, subject to explicit rollout/token budgets. Beyond numeric\nmetrics, Maestro leverages reflective textual feedback from traces to\nprioritize edits, improving sample efficiency and targeting specific failure\nmodes. On the IFBench and HotpotQA benchmarks, Maestro consistently surpasses\nleading prompt optimizers--MIPROv2, GEPA, and GEPA+Merge--by an average of 12%,\n4.9%, and 4.86%, respectively; even when restricted to prompt-only\noptimization, it still leads by 9.65%, 2.37%, and 2.41%. Maestro achieves these\nresults with far fewer rollouts than GEPA. We further show large gains on two\napplications (interviewer & RAG agents), highlighting that joint graph &\nconfiguration search addresses structural failure modes that prompt tuning\nalone cannot fix.", "AI": {"tldr": "Maestro\u662f\u4e00\u4e2a\u6846\u67b6\u65e0\u5173\u7684LLM\u667a\u80fd\u4f53\u6574\u4f53\u4f18\u5316\u5668\uff0c\u901a\u8fc7\u8054\u5408\u641c\u7d22\u56fe\u7ed3\u6784\u548c\u8282\u70b9\u914d\u7f6e\u6765\u63d0\u5347\u667a\u80fd\u4f53\u8d28\u91cf\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c\u5e94\u7528\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u4f18\u5316\u5668\u4e3b\u8981\u8c03\u6574\u914d\u7f6e\u800c\u56fa\u5b9a\u56fe\u7ed3\u6784\uff0c\u65e0\u6cd5\u89e3\u51b3\u7ed3\u6784\u6027\u6545\u969c\u6a21\u5f0f\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u4f18\u5316\u56fe\u7ed3\u6784\u548c\u8282\u70b9\u914d\u7f6e\u7684\u5168\u9762\u4f18\u5316\u65b9\u6cd5\u3002", "method": "Maestro\u6846\u67b6\u5728\u660e\u786e\u7684rollout/token\u9884\u7b97\u7ea6\u675f\u4e0b\uff0c\u8054\u5408\u641c\u7d22\u667a\u80fd\u4f53\u7684\u56fe\u7ed3\u6784\uff08\u6a21\u5757\u7ec4\u6210\u548c\u4fe1\u606f\u6d41\uff09\u548c\u8282\u70b9\u914d\u7f6e\uff08\u6a21\u578b\u3001\u63d0\u793a\u8bcd\u3001\u5de5\u5177\u3001\u63a7\u5236\u53c2\u6570\uff09\uff0c\u5e76\u5229\u7528\u8f68\u8ff9\u4e2d\u7684\u53cd\u601d\u6027\u6587\u672c\u53cd\u9988\u6765\u4f18\u5148\u5904\u7406\u7f16\u8f91\u64cd\u4f5c\u3002", "result": "\u5728IFBench\u548cHotpotQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMaestro\u5e73\u5747\u5206\u522b\u8d85\u8fc7MIPROv2\u3001GEPA\u548cGEPA+Merge 12%\u30014.9%\u548c4.86%\uff1b\u5373\u4f7f\u5728\u4ec5\u4f18\u5316\u63d0\u793a\u8bcd\u7684\u60c5\u51b5\u4e0b\uff0c\u4ecd\u9886\u51489.65%\u30012.37%\u548c2.41%\uff0c\u4e14\u4f7f\u7528\u7684rollout\u6b21\u6570\u8fdc\u5c11\u4e8eGEPA\u3002", "conclusion": "\u8054\u5408\u56fe\u7ed3\u6784\u548c\u914d\u7f6e\u641c\u7d22\u80fd\u591f\u89e3\u51b3\u4ec5\u9760\u63d0\u793a\u8bcd\u8c03\u4f18\u65e0\u6cd5\u89e3\u51b3\u7684\u7ed3\u6784\u6027\u6545\u969c\u6a21\u5f0f\uff0c\u5728\u591a\u4e2a\u5e94\u7528\u4e2d\u663e\u793a\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u8bc1\u660e\u4e86\u6574\u4f53\u4f18\u5316\u65b9\u6cd5\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2509.05150", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.05150", "abs": "https://arxiv.org/abs/2509.05150", "authors": ["Stefanos Vasileaidis", "Thanassis Giannetsos", "Matthias Schunter", "Bruno Crispo"], "title": "Reinforcing Secure Live Migration through Verifiable State Management", "comment": null, "summary": "Live migration of applications is a fundamental capability for enabling\nresilient computing in modern distributed systems. However, extending this\nfunctionality to trusted applications (TA) -- executing within Trusted\nExecution Environments (TEEs) -- introduces unique challenges such as secure\nstate preservation, integrity verification, replay and rollback prevention, and\nmitigation of unauthorized cloning of TAs. We present TALOS, a lightweight\nframework for verifiable state management and trustworthy application\nmigration. While our implementation is prototyped and evaluated using Intel SGX\nwith the Gramine LibOS and RISC-V Keystone (evidencing the framework's\nportability across diverse TEEs), its design is agnostic to the underlying TEE\narchitecture. Such agility is a necessity in today's network service mesh\n(collaborative computing across the continuum) where application workloads must\nbe managed across domain boundaries in a harmonized fashion. TALOS is built\naround the principle of minimizing trust assumptions: TAs are treated as\nuntrusted until explicitly verified, and the migration process does not rely on\na trusted third party. To ensure both the integrity and secure launch of the\nmigrated application, TALOS integrates memory introspection and control-flow\ngraph extraction, enabling robust verification of state continuity and\nexecution flow. Thereby achieving strong security guarantees while maintaining\nefficiency, making it suitable for decentralized settings.", "AI": {"tldr": "TALOS\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u6846\u67b6\uff0c\u7528\u4e8e\u53ef\u4fe1\u5e94\u7528\u7a0b\u5e8f\u5728TEE\u73af\u5883\u4e2d\u7684\u53ef\u9a8c\u8bc1\u72b6\u6001\u7ba1\u7406\u548c\u53ef\u4fe1\u8fc1\u79fb\uff0c\u89e3\u51b3\u4e86\u5b89\u5168\u72b6\u6001\u4fdd\u5b58\u3001\u5b8c\u6574\u6027\u9a8c\u8bc1\u7b49\u6311\u6218\u3002", "motivation": "\u73b0\u4ee3\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u9700\u8981\u53ef\u4fe1\u5e94\u7528\u7a0b\u5e8f\u7684\u5b9e\u65f6\u8fc1\u79fb\u80fd\u529b\uff0c\u4f46\u5728TEE\u73af\u5883\u4e2d\u8fc1\u79fb\u53ef\u4fe1\u5e94\u7528\u7a0b\u5e8f\u9762\u4e34\u5b89\u5168\u72b6\u6001\u4fdd\u5b58\u3001\u5b8c\u6574\u6027\u9a8c\u8bc1\u3001\u9632\u91cd\u653e\u548c\u9632\u56de\u6eda\u3001\u9632\u6b62\u672a\u6388\u6743\u514b\u9686\u7b49\u72ec\u7279\u6311\u6218\u3002", "method": "TALOS\u6846\u67b6\u57fa\u4e8e\u6700\u5c0f\u5316\u4fe1\u4efb\u5047\u8bbe\u539f\u5219\uff0c\u5c06\u53ef\u4fe1\u5e94\u7528\u7a0b\u5e8f\u89c6\u4e3a\u4e0d\u53ef\u4fe1\u76f4\u5230\u660e\u786e\u9a8c\u8bc1\uff0c\u8fc1\u79fb\u8fc7\u7a0b\u4e0d\u4f9d\u8d56\u53ef\u4fe1\u7b2c\u4e09\u65b9\u3002\u96c6\u6210\u5185\u5b58\u81ea\u7701\u548c\u63a7\u5236\u6d41\u56fe\u63d0\u53d6\u6280\u672f\uff0c\u786e\u4fdd\u8fc1\u79fb\u5e94\u7528\u7684\u5b8c\u6574\u6027\u548c\u5b89\u5168\u542f\u52a8\u3002", "result": "\u6846\u67b6\u5728Intel SGX\u548cRISC-V Keystone\u4e0a\u5b9e\u73b0\u5e76\u9a8c\u8bc1\uff0c\u8bc1\u660e\u5176\u8de8\u4e0d\u540cTEE\u67b6\u6784\u7684\u53ef\u79fb\u690d\u6027\uff0c\u5728\u4fdd\u6301\u6548\u7387\u7684\u540c\u65f6\u63d0\u4f9b\u5f3a\u5927\u7684\u5b89\u5168\u4fdd\u8bc1\uff0c\u9002\u7528\u4e8e\u53bb\u4e2d\u5fc3\u5316\u73af\u5883\u3002", "conclusion": "TALOS\u4e3a\u53ef\u4fe1\u5e94\u7528\u7a0b\u5e8f\u8fc1\u79fb\u63d0\u4f9b\u4e86\u8f7b\u91cf\u7ea7\u3001\u53ef\u9a8c\u8bc1\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6ee1\u8db3\u73b0\u4ee3\u7f51\u7edc\u670d\u52a1\u7f51\u683c\u4e2d\u8de8\u57df\u8fb9\u754c\u534f\u540c\u8ba1\u7b97\u7684\u9700\u6c42\uff0c\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u4ef7\u503c\u3002"}}
{"id": "2509.04763", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.04763", "abs": "https://arxiv.org/abs/2509.04763", "authors": ["Tiancheng Jin", "Shangzhou Xia", "Jianjun Zhao"], "title": "NovaQ: Improving Quantum Program Testing through Diversity-Guided Test Case Generation", "comment": "5 pages", "summary": "Quantum programs are designed to run on quantum computers, leveraging quantum\ncircuits to solve problems that are intractable for classical machines. As\nquantum computing advances, ensuring the reliability of quantum programs has\nbecome increasingly important. This paper introduces NovaQ, a diversity-guided\ntesting framework for quantum programs. NovaQ combines a distribution-based\ntest case generator with a novelty-driven evaluation module. The generator\nproduces diverse quantum state inputs by mutating circuit parameters, while the\nevaluator quantifies behavioral novelty based on internal circuit state\nmetrics, including magnitude, phase, and entanglement. By selecting inputs that\nmap to infrequently covered regions in the metric space, NovaQ effectively\nexplores under-tested program behaviors. We evaluate NovaQ on quantum programs\nof varying sizes and complexities. Experimental results show that NovaQ\nconsistently achieves higher test input diversity and detects more bugs than\nexisting baseline approaches.", "AI": {"tldr": "NovaQ\u662f\u4e00\u4e2a\u591a\u6837\u6027\u5f15\u5bfc\u7684\u91cf\u5b50\u7a0b\u5e8f\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u548c\u65b0\u9896\u6027\u9a71\u52a8\u8bc4\u4f30\u6a21\u5757\uff0c\u6709\u6548\u63d0\u5347\u91cf\u5b50\u7a0b\u5e8f\u6d4b\u8bd5\u7684\u591a\u6837\u6027\u548c\u9519\u8bef\u68c0\u6d4b\u80fd\u529b\u3002", "motivation": "\u968f\u7740\u91cf\u5b50\u8ba1\u7b97\u7684\u53d1\u5c55\uff0c\u786e\u4fdd\u91cf\u5b50\u7a0b\u5e8f\u7684\u53ef\u9760\u6027\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002\u91cf\u5b50\u7a0b\u5e8f\u5229\u7528\u91cf\u5b50\u7535\u8def\u89e3\u51b3\u7ecf\u5178\u8ba1\u7b97\u673a\u96be\u4ee5\u5904\u7406\u7684\u95ee\u9898\uff0c\u9700\u8981\u6709\u6548\u7684\u6d4b\u8bd5\u65b9\u6cd5\u6765\u53d1\u73b0\u6f5c\u5728\u9519\u8bef\u3002", "method": "NovaQ\u7ed3\u5408\u4e86\u57fa\u4e8e\u5206\u5e03\u7684\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u5668\u548c\u65b0\u9896\u6027\u9a71\u52a8\u7684\u8bc4\u4f30\u6a21\u5757\u3002\u751f\u6210\u5668\u901a\u8fc7\u53d8\u5f02\u7535\u8def\u53c2\u6570\u4ea7\u751f\u591a\u6837\u5316\u7684\u91cf\u5b50\u6001\u8f93\u5165\uff0c\u8bc4\u4f30\u5668\u57fa\u4e8e\u5185\u90e8\u7535\u8def\u72b6\u6001\u5ea6\u91cf\uff08\u5305\u62ec\u5e45\u5ea6\u3001\u76f8\u4f4d\u548c\u7ea0\u7f20\uff09\u91cf\u5316\u884c\u4e3a\u65b0\u9896\u6027\uff0c\u9009\u62e9\u6620\u5c04\u5230\u5ea6\u91cf\u7a7a\u95f4\u4e2d\u8f83\u5c11\u8986\u76d6\u533a\u57df\u7684\u8f93\u5165\u3002", "result": "\u5728\u4e0d\u540c\u89c4\u6a21\u548c\u590d\u6742\u5ea6\u7684\u91cf\u5b50\u7a0b\u5e8f\u4e0a\u8fdb\u884c\u7684\u5b9e\u9a8c\u8868\u660e\uff0cNovaQ\u59cb\u7ec8\u6bd4\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u83b7\u5f97\u66f4\u9ad8\u7684\u6d4b\u8bd5\u8f93\u5165\u591a\u6837\u6027\uff0c\u5e76\u68c0\u6d4b\u5230\u66f4\u591a\u7684\u9519\u8bef\u3002", "conclusion": "NovaQ\u6846\u67b6\u901a\u8fc7\u591a\u6837\u6027\u5f15\u5bfc\u7684\u6d4b\u8bd5\u7b56\u7565\uff0c\u80fd\u591f\u6709\u6548\u63a2\u7d22\u91cf\u5b50\u7a0b\u5e8f\u4e2d\u672a\u5145\u5206\u6d4b\u8bd5\u7684\u884c\u4e3a\uff0c\u63d0\u9ad8\u91cf\u5b50\u7a0b\u5e8f\u6d4b\u8bd5\u7684\u6548\u679c\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2509.04646", "categories": ["cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2509.04646", "abs": "https://arxiv.org/abs/2509.04646", "authors": ["Philippe J. Giabbanelli", "Ameeta Agrawal"], "title": "Towards Personalized Explanations for Health Simulations: A Mixed-Methods Framework for Stakeholder-Centric Summarization", "comment": "Accepted at the AAAI 2025 Fall Symposium Series. November 6-8, 2025,\n  Arlington, VA, USA", "summary": "Modeling & Simulation (M&S) approaches such as agent-based models hold\nsignificant potential to support decision-making activities in health, with\nrecent examples including the adoption of vaccines, and a vast literature on\nhealthy eating behaviors and physical activity behaviors. These models are\npotentially usable by different stakeholder groups, as they support\npolicy-makers to estimate the consequences of potential interventions and they\ncan guide individuals in making healthy choices in complex environments.\nHowever, this potential may not be fully realized because of the models'\ncomplexity, which makes them inaccessible to the stakeholders who could benefit\nthe most. While Large Language Models (LLMs) can translate simulation outputs\nand the design of models into text, current approaches typically rely on\none-size-fits-all summaries that fail to reflect the varied informational needs\nand stylistic preferences of clinicians, policymakers, patients, caregivers,\nand health advocates. This limitation stems from a fundamental gap: we lack a\nsystematic understanding of what these stakeholders need from explanations and\nhow to tailor them accordingly. To address this gap, we present a step-by-step\nframework to identify stakeholder needs and guide LLMs in generating tailored\nexplanations of health simulations. Our procedure uses a mixed-methods design\nby first eliciting the explanation needs and stylistic preferences of diverse\nhealth stakeholders, then optimizing the ability of LLMs to generate tailored\noutputs (e.g., via controllable attribute tuning), and then evaluating through\na comprehensive range of metrics to further improve the tailored generation of\nsummaries.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5206\u6b65\u6846\u67b6\uff0c\u901a\u8fc7\u6df7\u5408\u65b9\u6cd5\u8bc6\u522b\u4e0d\u540c\u5065\u5eb7\u9886\u57df\u5229\u76ca\u76f8\u5173\u8005\u7684\u9700\u6c42\uff0c\u6307\u5bfcLLM\u751f\u6210\u5b9a\u5236\u5316\u7684\u5065\u5eb7\u6a21\u62df\u89e3\u91ca\uff0c\u89e3\u51b3\u73b0\u6709\u901a\u7528\u6458\u8981\u65e0\u6cd5\u6ee1\u8db3\u591a\u6837\u5316\u9700\u6c42\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u4ee3\u7406\u7684\u5efa\u6a21\u4e0e\u4eff\u771f\u65b9\u6cd5\u5728\u5065\u5eb7\u51b3\u7b56\u652f\u6301\u4e2d\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u7531\u4e8e\u6a21\u578b\u590d\u6742\u6027\u96be\u4ee5\u88ab\u5229\u76ca\u76f8\u5173\u8005\u7406\u89e3\uff0c\u4e14\u73b0\u6709LLM\u751f\u6210\u7684\u901a\u7528\u6458\u8981\u65e0\u6cd5\u6ee1\u8db3\u4e0d\u540c\u5229\u76ca\u76f8\u5173\u8005\uff08\u4e34\u5e8a\u533b\u751f\u3001\u653f\u7b56\u5236\u5b9a\u8005\u3001\u60a3\u8005\u7b49\uff09\u7684\u591a\u6837\u5316\u4fe1\u606f\u9700\u6c42\u548c\u98ce\u683c\u504f\u597d\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u8bbe\u8ba1\uff1a\u9996\u5148\u901a\u8fc7\u9700\u6c42\u8c03\u7814\u83b7\u53d6\u4e0d\u540c\u5065\u5eb7\u5229\u76ca\u76f8\u5173\u8005\u7684\u89e3\u91ca\u9700\u6c42\u548c\u98ce\u683c\u504f\u597d\uff0c\u7136\u540e\u901a\u8fc7\u53ef\u63a7\u5c5e\u6027\u8c03\u4f18\u7b49\u6280\u672f\u4f18\u5316LLM\u751f\u6210\u5b9a\u5236\u5316\u8f93\u51fa\u7684\u80fd\u529b\uff0c\u6700\u540e\u901a\u8fc7\u7efc\u5408\u6307\u6807\u8bc4\u4f30\u5e76\u8fdb\u4e00\u6b65\u6539\u8fdb\u5b9a\u5236\u5316\u6458\u8981\u751f\u6210\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u6027\u6846\u67b6\uff0c\u4f46\u5177\u4f53\u5b9e\u9a8c\u7ed3\u679c\u672a\u5728\u6458\u8981\u4e2d\u8be6\u7ec6\u8bf4\u660e\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u5065\u5eb7\u6a21\u62df\u89e3\u91ca\u5b9a\u5236\u5316\u7684\u7cfb\u7edf\u6027\u7406\u89e3\u7a7a\u767d\uff0c\u4e3aLLM\u751f\u6210\u9488\u5bf9\u6027\u5065\u5eb7\u6a21\u62df\u89e3\u91ca\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u5206\u6b65\u6846\u67b6\uff0c\u6709\u671b\u63d0\u5347\u5065\u5eb7\u51b3\u7b56\u652f\u6301\u5de5\u5177\u7684\u53ef\u8bbf\u95ee\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2509.05161", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.05161", "abs": "https://arxiv.org/abs/2509.05161", "authors": ["Abiodun Ganiyu", "Dara Ron", "Syed Rafiul Hussain", "Vijay K Shah"], "title": "Jamming Smarter, Not Harder: Exploiting O-RAN Y1 RAN Analytics for Efficient Interference", "comment": "8 pages, 7 figures", "summary": "The Y1 interface in O-RAN enables the sharing of RAN Analytics Information\n(RAI) between the near-RT RIC and authorized Y1 consumers, which may be\ninternal applications within the operator's trusted domain or external systems\naccessing data through a secure exposure function. While this visibility\nenhances network optimization and enables advanced services, it also introduces\na potential security risk -- a malicious or compromised Y1 consumer could\nmisuse analytics to facilitate targeted interference. In this work, we\ndemonstrate how an adversary can exploit the Y1 interface to launch selective\njamming attacks by passively monitoring downlink metrics. We propose and\nevaluate two Y1-aided jamming strategies: a clustering-based jammer leveraging\nDBSCAN for traffic profiling and a threshold-based jammer. These are compared\nagainst two baselines strategies -- always-on jammer and random jammer -- on an\nover-the-air LTE/5G O-RAN testbed. Experimental results show that in\nunconstrained jamming budget scenarios, the threshold-based jammer can closely\nreplicate the disruption caused by always-on jamming while reducing\ntransmission time by 27\\%. Under constrained jamming budgets, the\nclustering-based jammer proves most effective, causing up to an 18.1\\% bitrate\ndrop while remaining active only 25\\% of the time. These findings reveal a\ncritical trade-off between jamming stealthiness and efficiency, and illustrate\nhow exposure of RAN analytics via the Y1 interface can enable highly targeted,\nlow-overhead attacks, raising important security considerations for both\ncivilian and mission-critical O-RAN deployments.", "AI": {"tldr": "\u672c\u6587\u5c55\u793a\u4e86O-RAN\u4e2dY1\u63a5\u53e3\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u653b\u51fb\u8005\u53ef\u901a\u8fc7\u88ab\u52a8\u76d1\u63a7\u4e0b\u884c\u94fe\u8def\u6307\u6807\u53d1\u8d77\u9009\u62e9\u6027\u5e72\u6270\u653b\u51fb\u3002\u63d0\u51fa\u7684\u57fa\u4e8e\u9608\u503c\u548c\u805a\u7c7b\u7684\u5e72\u6270\u7b56\u7565\u5728\u5b9e\u9a8c\u6d4b\u8bd5\u4e2d\u663e\u793a\u51fa\u9ad8\u6548\u6027\uff0c\u63ed\u793a\u4e86RAN\u5206\u6790\u4fe1\u606f\u66b4\u9732\u5e26\u6765\u7684\u5b89\u5168\u98ce\u9669\u3002", "motivation": "O-RAN\u7684Y1\u63a5\u53e3\u867d\u7136\u589e\u5f3a\u4e86\u7f51\u7edc\u4f18\u5316\u80fd\u529b\uff0c\u4f46\u6076\u610f\u6d88\u8d39\u8005\u53ef\u80fd\u6ee5\u7528RAN\u5206\u6790\u4fe1\u606f(RAI)\u53d1\u8d77\u9488\u5bf9\u6027\u5e72\u6270\u653b\u51fb\uff0c\u9700\u8981\u7814\u7a76\u8fd9\u79cd\u5b89\u5168\u5a01\u80c1\u7684\u5b9e\u9645\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u5e76\u8bc4\u4f30\u4e86\u4e24\u79cdY1\u8f85\u52a9\u5e72\u6270\u7b56\u7565\uff1a\u57fa\u4e8eDBSCAN\u805a\u7c7b\u7684\u5e72\u6270\u5668\u548c\u57fa\u4e8e\u9608\u503c\u7684\u5e72\u6270\u5668\uff0c\u5728\u771f\u5b9e\u7684LTE/5G O-RAN\u6d4b\u8bd5\u5e8a\u4e0a\u4e0e\u59cb\u7ec8\u5f00\u542f\u548c\u968f\u673a\u5e72\u6270\u4e24\u79cd\u57fa\u7ebf\u7b56\u7565\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5728\u65e0\u7ea6\u675f\u5e72\u6270\u9884\u7b97\u4e0b\uff0c\u57fa\u4e8e\u9608\u503c\u7684\u5e72\u6270\u5668\u53ef\u63a5\u8fd1\u59cb\u7ec8\u5f00\u542f\u5e72\u6270\u7684\u6548\u679c\uff0c\u540c\u65f6\u51cf\u5c1127%\u7684\u4f20\u8f93\u65f6\u95f4\uff1b\u5728\u7ea6\u675f\u9884\u7b97\u4e0b\uff0c\u57fa\u4e8e\u805a\u7c7b\u7684\u5e72\u6270\u5668\u6700\u6709\u6548\uff0c\u9020\u621018.1%\u7684\u6bd4\u7279\u7387\u4e0b\u964d\uff0c\u4ec5\u970025%\u7684\u6d3b\u52a8\u65f6\u95f4\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u5e72\u6270\u9690\u853d\u6027\u4e0e\u6548\u7387\u4e4b\u95f4\u7684\u5173\u952e\u6743\u8861\uff0c\u8868\u660eY1\u63a5\u53e3\u66b4\u9732RAN\u5206\u6790\u4fe1\u606f\u53ef\u80fd\u5b9e\u73b0\u9ad8\u5ea6\u9488\u5bf9\u6027\u3001\u4f4e\u5f00\u9500\u7684\u653b\u51fb\uff0c\u5bf9\u6c11\u7528\u548c\u5173\u952e\u4efb\u52a1O-RAN\u90e8\u7f72\u63d0\u51fa\u4e86\u91cd\u8981\u5b89\u5168\u8003\u8651\u3002"}}
{"id": "2509.04810", "categories": ["cs.SE", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.04810", "abs": "https://arxiv.org/abs/2509.04810", "authors": ["Yogev Cohen", "Dudi Ohayon", "Romy Somkin", "Yehudit Aperstein", "Alexander Apartsin"], "title": "Code Review Without Borders: Evaluating Synthetic vs. Real Data for Review Recommendation", "comment": "4 pages, 1 figure", "summary": "Automating the decision of whether a code change requires manual review is\nvital for maintaining software quality in modern development workflows.\nHowever, the emergence of new programming languages and frameworks creates a\ncritical bottleneck: while large volumes of unlabelled code are readily\navailable, there is an insufficient amount of labelled data to train supervised\nmodels for review classification. We address this challenge by leveraging Large\nLanguage Models (LLMs) to translate code changes from well-resourced languages\ninto equivalent changes in underrepresented or emerging languages, generating\nsynthetic training data where labelled examples are scarce. We assume that\nalthough LLMs have learned the syntax and semantics of new languages from\navailable unlabelled code, they have yet to fully grasp which code changes are\nconsidered significant or review-worthy within these emerging ecosystems. To\novercome this, we use LLMs to generate synthetic change examples and train\nsupervised classifiers on them. We systematically compare the performance of\nthese classifiers against models trained on real labelled data. Our experiments\nacross multiple GitHub repositories and language pairs demonstrate that\nLLM-generated synthetic data can effectively bootstrap review recommendation\nsystems, narrowing the performance gap even in low-resource settings. This\napproach provides a scalable pathway to extend automated code review\ncapabilities to rapidly evolving technology stacks, even in the absence of\nannotated data.", "AI": {"tldr": "\u5229\u7528LLM\u5c06\u4ee3\u7801\u66f4\u6539\u4ece\u8d44\u6e90\u4e30\u5bcc\u8bed\u8a00\u7ffb\u8bd1\u5230\u65b0\u5174\u8bed\u8a00\uff0c\u751f\u6210\u5408\u6210\u8bad\u7ec3\u6570\u636e\u6765\u89e3\u51b3\u4ee3\u7801\u5ba1\u67e5\u5206\u7c7b\u4e2d\u6807\u7b7e\u6570\u636e\u77ed\u7f3a\u95ee\u9898", "motivation": "\u65b0\u7f16\u7a0b\u8bed\u8a00\u548c\u6846\u67b6\u7684\u51fa\u73b0\u9020\u6210\u4e86\u6807\u7b7e\u6570\u636e\u4e0d\u8db3\u7684\u74f6\u9888\uff0c\u800c\u5927\u91cf\u672a\u6807\u6ce8\u4ee3\u7801\u5374\u5bb9\u6613\u83b7\u5f97\uff0c\u9700\u8981\u627e\u5230\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u6765\u5efa\u7acb\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u7cfb\u7edf", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u5c06\u4ee3\u7801\u66f4\u6539\u4ece\u8d44\u6e90\u4e30\u5bcc\u8bed\u8a00\u7ffb\u8bd1\u6210\u7f3a\u4e4f\u6807\u7b7e\u6570\u636e\u7684\u65b0\u5174\u8bed\u8a00\u7248\u672c\uff0c\u751f\u6210\u5408\u6210\u8bad\u7ec3\u6570\u636e\uff0c\u7136\u540e\u8bad\u7ec3\u76d1\u7763\u5206\u7c7b\u5668", "result": "\u5728\u591a\u4e2aGitHub\u4ed3\u5e93\u548c\u8bed\u8a00\u5bf9\u4e2d\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8bc1\u660eLLM\u751f\u6210\u7684\u5408\u6210\u6570\u636e\u53ef\u4ee5\u6709\u6548\u5730\u542f\u52a8\u5ba1\u67e5\u63a8\u8350\u7cfb\u7edf\uff0c\u5728\u4f4e\u8d44\u6e90\u73af\u5883\u4e2d\u7f29\u5c0f\u4e86\u4e0e\u771f\u5b9e\u6807\u7b7e\u6570\u636e\u8bad\u7ec3\u6a21\u578b\u7684\u6027\u80fd\u5dee\u8ddd", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6269\u5c55\u81ea\u52a8\u4ee3\u7801\u5ba1\u67e5\u529f\u80fd\u5230\u5feb\u901f\u53d1\u5c55\u7684\u6280\u672f\u6808\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u9014\u5f84\uff0c\u751a\u81f3\u5728\u7f3a\u4e4f\u6ce8\u91ca\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u5b9e\u73b0"}}
{"id": "2509.04676", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.04676", "abs": "https://arxiv.org/abs/2509.04676", "authors": ["Sasha Mitts"], "title": "An Approach to Grounding AI Model Evaluations in Human-derived Criteria", "comment": "4 figures, 6 pages, presented at CHI 2025 Workshop on Human-AI\n  Interaction for Augmented Reasoning", "summary": "In the rapidly evolving field of artificial intelligence (AI), traditional\nbenchmarks can fall short in attempting to capture the nuanced capabilities of\nAI models. We focus on the case of physical world modeling and propose a novel\napproach to augment existing benchmarks with human-derived evaluation criteria,\naiming to enhance the interpretability and applicability of model behaviors.\nGrounding our study in the Perception Test and OpenEQA benchmarks, we conducted\nin-depth interviews and large-scale surveys to identify key cognitive skills,\nsuch as Prioritization, Memorizing, Discerning, and Contextualizing, that are\ncritical for both AI and human reasoning. Our findings reveal that participants\nperceive AI as lacking in interpretive and empathetic skills yet hold high\nexpectations for AI performance. By integrating insights from our findings into\nbenchmark design, we offer a framework for developing more human-aligned means\nof defining and measuring progress. This work underscores the importance of\nuser-centered evaluation in AI development, providing actionable guidelines for\nresearchers and practitioners aiming to align AI capabilities with human\ncognitive processes. Our approach both enhances current benchmarking practices\nand sets the stage for future advancements in AI model evaluation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u4eba\u7c7b\u8bc4\u4f30\u6807\u51c6\u589e\u5f3aAI\u57fa\u51c6\u6d4b\u8bd5\u7684\u65b0\u65b9\u6cd5\uff0c\u91cd\u70b9\u5173\u6ce8\u7269\u7406\u4e16\u754c\u5efa\u6a21\uff0c\u65e8\u5728\u63d0\u9ad8\u6a21\u578b\u884c\u4e3a\u7684\u53ef\u89e3\u91ca\u6027\u548c\u9002\u7528\u6027\u3002", "motivation": "\u4f20\u7edfAI\u57fa\u51c6\u6d4b\u8bd5\u96be\u4ee5\u6355\u6349\u6a21\u578b\u7684\u7ec6\u5fae\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u7269\u7406\u4e16\u754c\u5efa\u6a21\u65b9\u9762\uff0c\u9700\u8981\u66f4\u7b26\u5408\u4eba\u7c7b\u8ba4\u77e5\u7684\u8bc4\u4f30\u6807\u51c6\u3002", "method": "\u57fa\u4e8ePerception Test\u548cOpenEQA\u57fa\u51c6\uff0c\u901a\u8fc7\u6df1\u5ea6\u8bbf\u8c08\u548c\u5927\u89c4\u6a21\u8c03\u67e5\u8bc6\u522b\u5173\u952e\u8ba4\u77e5\u6280\u80fd\uff08\u4f18\u5148\u7ea7\u6392\u5e8f\u3001\u8bb0\u5fc6\u3001\u8fa8\u522b\u3001\u60c5\u5883\u5316\uff09\uff0c\u5e76\u5c06\u8fd9\u4e9b\u53d1\u73b0\u6574\u5408\u5230\u57fa\u51c6\u8bbe\u8ba1\u4e2d\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u53c2\u4e0e\u8005\u8ba4\u4e3aAI\u7f3a\u4e4f\u89e3\u91ca\u6027\u548c\u5171\u60c5\u80fd\u529b\uff0c\u4f46\u5bf9AI\u6027\u80fd\u6709\u5f88\u9ad8\u671f\u671b\u3002\u63d0\u51fa\u4e86\u4e00\u4e2a\u5f00\u53d1\u66f4\u7b26\u5408\u4eba\u7c7b\u8ba4\u77e5\u7684AI\u8bc4\u4f30\u6846\u67b6\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5f3a\u8c03\u4e86\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684AI\u8bc4\u4f30\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u5c06AI\u80fd\u529b\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u8fc7\u7a0b\u5bf9\u9f50\u7684\u5b9e\u7528\u6307\u5357\uff0c\u6539\u8fdb\u4e86\u5f53\u524d\u57fa\u51c6\u6d4b\u8bd5\u5b9e\u8df5\u5e76\u4e3a\u672a\u6765AI\u6a21\u578b\u8bc4\u4f30\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2509.05162", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.05162", "abs": "https://arxiv.org/abs/2509.05162", "authors": ["Simone Bottoni", "Giulio Zizzo", "Stefano Braghin", "Alberto Trombetta"], "title": "Verifiability and Privacy in Federated Learning through Context-Hiding Multi-Key Homomorphic Authenticators", "comment": null, "summary": "Federated Learning has rapidly expanded from its original inception to now\nhave a large body of research, several frameworks, and sold in a variety of\ncommercial offerings. Thus, its security and robustness is of significant\nimportance. There are many algorithms that provide robustness in the case of\nmalicious clients. However, the aggregator itself may behave maliciously, for\nexample, by biasing the model or tampering with the weights to weaken the\nmodels privacy. In this work, we introduce a verifiable federated learning\nprotocol that enables clients to verify the correctness of the aggregators\ncomputation without compromising the confidentiality of their updates. Our\nprotocol uses a standard secure aggregation technique to protect individual\nmodel updates with a linearly homomorphic authenticator scheme that enables\nefficient, privacy-preserving verification of the aggregated result. Our\nconstruction ensures that clients can detect manipulation by the aggregator\nwhile maintaining low computational overhead. We demonstrate that our approach\nscales to large models, enabling verification over large neural networks with\nmillions of parameters.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u9a8c\u8bc1\u7684\u8054\u90a6\u5b66\u4e60\u534f\u8bae\uff0c\u5141\u8bb8\u5ba2\u6237\u7aef\u9a8c\u8bc1\u805a\u5408\u5668\u8ba1\u7b97\u7684\u6b63\u786e\u6027\uff0c\u540c\u65f6\u4fdd\u62a4\u6a21\u578b\u66f4\u65b0\u7684\u4fdd\u5bc6\u6027\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u7684\u5b89\u5168\u6027\u548c\u7a33\u5065\u6027\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136\u6709\u8bb8\u591a\u7b97\u6cd5\u80fd\u591f\u5e94\u5bf9\u6076\u610f\u5ba2\u6237\u7aef\uff0c\u4f46\u805a\u5408\u5668\u672c\u8eab\u4e5f\u53ef\u80fd\u6076\u610f\u884c\u4e3a\uff0c\u5982\u504f\u67d0\u6a21\u578b\u6216\u7be1\u6539\u6743\u91cd\u4ee5\u524a\u5f31\u6a21\u578b\u9690\u79c1\u6027\u3002", "method": "\u4f7f\u7528\u6807\u51c6\u7684\u5b89\u5168\u805a\u5408\u6280\u672f\u6765\u4fdd\u62a4\u4e2a\u4eba\u6a21\u578b\u66f4\u65b0\uff0c\u7ed3\u5408\u7ebf\u6027\u540c\u6001\u8ba4\u8bc1\u5668\u65b9\u6848\uff0c\u5b9e\u73b0\u9ad8\u6548\u3001\u9690\u79c1\u4fdd\u62a4\u7684\u805a\u5408\u7ed3\u679c\u9a8c\u8bc1\u3002", "result": "\u6784\u9020\u786e\u4fdd\u5ba2\u6237\u7aef\u80fd\u591f\u68c0\u6d4b\u805a\u5408\u5668\u7684\u64cd\u7eb5\u884c\u4e3a\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002\u65b9\u6cd5\u80fd\u591f\u6269\u5c55\u5230\u5927\u578b\u6a21\u578b\uff0c\u652f\u6301\u542b\u6709\u6570\u767e\u4e07\u53c2\u6570\u7684\u5927\u578b\u795e\u7ecf\u7f51\u7edc\u7684\u9a8c\u8bc1\u3002", "conclusion": "\u8be5\u534f\u8bae\u6709\u6548\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u805a\u5408\u5668\u53ef\u80fd\u6076\u610f\u884c\u4e3a\u7684\u5b89\u5168\u95ee\u9898\uff0c\u5728\u4fdd\u62a4\u5ba2\u6237\u7aef\u9690\u79c1\u7684\u540c\u65f6\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u9a8c\u8bc1\u673a\u5236\uff0c\u5177\u6709\u826f\u597d\u7684\u6269\u5c55\u6027\u3002"}}
{"id": "2509.04877", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.04877", "abs": "https://arxiv.org/abs/2509.04877", "authors": ["Maryam Khan", "Muhammad Azeem Akbar", "Jussi Kasurinen"], "title": "Integrating Large Language Models in Software Engineering Education: A Pilot Study through GitHub Repositories Mining", "comment": null, "summary": "Context: Large Language Models (LLMs) such as ChatGPT are increasingly\nadopted in software engineering (SE) education, offering both opportunities and\nchallenges. Their adoption requires systematic investigation to ensure\nresponsible integration into curricula. Objective: This doctoral research aims\nto develop a validated framework for integrating LLMs into SE education through\na multi-phase process, including taxonomies development, empirical\ninvestigation, and case studies. This paper presents the first empirical step.\nMethod: We conducted a pilot repository mining study of 400 GitHub projects,\nanalyzing README files and issues discussions to identify the presence of\nmotivator and demotivator previously synthesized in our literature review [ 8]\nstudy. Results: Motivators such as engagement and motivation (227 hits),\nsoftware engineering process understanding (133 hits), and programming\nassistance and debugging support (97 hits) were strongly represented.\nDemotivators, including plagiarism and IP concerns (385 hits), security,\nprivacy and data integrity (87 hits), and over-reliance on AI in learning (39\nhits), also appeared prominently. In contrast, demotivators such as challenges\nin evaluating learning outcomes and difficulty in curriculum redesign recorded\nno hits across the repositories. Conclusion: The study provides early empirical\nvalidation of motivators/demotivators taxonomies with respect to their themes,\nhighlights research practice gaps, and lays the foundation for developing a\ncomprehensive framework to guide the responsible adoption of LLMs in SE\neducation.", "AI": {"tldr": "\u8fd9\u662f\u4e00\u9879\u5173\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u4e2d\u96c6\u6210\u7684\u535a\u58eb\u7814\u7a76\uff0c\u901a\u8fc7GitHub\u9879\u76ee\u5206\u6790\u9a8c\u8bc1\u4e86\u63a8\u52a8\u56e0\u7d20\u548c\u963b\u788d\u56e0\u7d20\u7684\u5206\u7c7b\u7cfb\u7edf\u3002", "motivation": "\u968f\u7740ChatGPT\u7b49\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u4e2d\u7684\u65e5\u76ca\u666e\u53ca\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7814\u7a76\u4ee5\u786e\u4fdd\u8d1f\u8d23\u4efb\u96c6\u6210\u5230\u8bfe\u7a0b\u4e2d\u3002", "method": "\u8fdb\u884c\u4e86\u4e00\u4e2a\u9879\u76ee\u5e93\u6316\u6398\u7684\u5b9e\u9a8c\u7814\u7a76\uff0c\u5206\u6790\u4e86400\u4e2aGitHub\u9879\u76ee\u7684README\u6587\u4ef6\u548c\u95ee\u9898\u8ba8\u8bba\uff0c\u8bc6\u522b\u63a8\u52a8\u56e0\u7d20\u548c\u963b\u788d\u56e0\u7d20\u7684\u5b58\u5728\u60c5\u51b5\u3002", "result": "\u53d1\u73b0\u63a8\u52a8\u56e0\u7d20\u5982\u53c2\u4e0e\u52a8\u673a\uff08227\u6b21\uff09\u3001\u8f6f\u4ef6\u5de5\u7a0b\u8fc7\u7a0b\u7406\u89e3\uff08133\u6b21\uff09\u548c\u7f16\u7a0b\u8f85\u52a9\uff0897\u6b21\uff09\u8868\u73b0\u7a81\u51fa\uff1b\u963b\u788d\u56e0\u7d20\u5982\u526f\u8350\u548c\u77e5\u8bc6\u4ea7\u6743\u95ee\u9898\uff08385\u6b21\uff09\u3001\u5b89\u5168\u9690\u79c1\u95ee\u9898\uff0887\u6b21\uff09\u3001\u5bf9AI\u7684\u8fc7\u5ea6\u4f9d\u8d56\uff0839\u6b21\uff09\u4e5f\u5f88\u663e\u8457\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u63a8\u52a8\u56e0\u7d20/\u963b\u788d\u56e0\u7d20\u5206\u7c7b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65e9\u671f\u5b9e\u8bc1\u9a8c\u8bc1\uff0c\u5f3a\u8c03\u4e86\u7814\u7a76\u4e0e\u5b9e\u8df5\u7684\u5dee\u8ddd\uff0c\u4e3a\u5efa\u7acb\u8d1f\u8d23\u4efb\u96c6\u6210LLM\u7684\u7efc\u5408\u6846\u67b6\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2509.04731", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA", "cs.RO", "68T05, 90C40, 91A26, 68T42, 93E35", "I.2.11; I.2.6; I.2.8; I.2.9; I.2.7"], "pdf": "https://arxiv.org/pdf/2509.04731", "abs": "https://arxiv.org/abs/2509.04731", "authors": ["Brennen Hill"], "title": "Language-Driven Hierarchical Task Structures as Explicit World Models for Multi-Agent Learning", "comment": null, "summary": "The convergence of Language models, Agent models, and World models represents\na critical frontier for artificial intelligence. While recent progress has\nfocused on scaling Language and Agent models, the development of sophisticated,\nexplicit World Models remains a key bottleneck, particularly for complex,\nlong-horizon multi-agent tasks. In domains such as robotic soccer, agents\ntrained via standard reinforcement learning in high-fidelity but\nstructurally-flat simulators often fail due to intractable exploration spaces\nand sparse rewards. This position paper argues that the next frontier in\ndeveloping capable agents lies in creating environments that possess an\nexplicit, hierarchical World Model. We contend that this is best achieved\nthrough hierarchical scaffolding, where complex goals are decomposed into\nstructured, manageable subgoals. Drawing evidence from a systematic review of\n2024 research in multi-agent soccer, we identify a clear and decisive trend\ntowards integrating symbolic and hierarchical methods with multi-agent\nreinforcement learning (MARL). These approaches implicitly or explicitly\nconstruct a task-based world model to guide agent learning. We then propose a\nparadigm shift: leveraging Large Language Models to dynamically generate this\nhierarchical scaffold, effectively using language to structure the World Model\non the fly. This language-driven world model provides an intrinsic curriculum,\ndense and meaningful learning signals, and a framework for compositional\nlearning, enabling Agent Models to acquire sophisticated, strategic behaviors\nwith far greater sample efficiency. By building environments with explicit,\nlanguage-configurable task layers, we can bridge the gap between low-level\nreactive behaviors and high-level strategic team play, creating a powerful and\ngeneralizable framework for training the next generation of intelligent agents.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u52a8\u6001\u751f\u6210\u5c42\u6b21\u67b6\u6784\u6765\u6784\u5efa\u663e\u5f0f\u4e16\u754c\u6a21\u578b\uff0c\u4ee5\u89e3\u51b3\u591a\u81ea\u7136\u4efb\u52a1\u4e2d\u7684\u63a2\u7d22\u96be\u9898\u548c\u7a00\u758f\u5956\u52b1\u95ee\u9898\uff0c\u63d0\u9ad8\u6837\u672c\u6548\u7387\u548c\u7b56\u7565\u6027\u884c\u4e3a\u5b66\u4e60\u80fd\u529b\u3002", "motivation": "\u867d\u7136\u8bed\u8a00\u6a21\u578b\u548c\u81ea\u7136\u6a21\u578b\u53d6\u5f97\u4e86\u8fdb\u6b65\uff0c\u4f46\u590d\u6742\u957f\u671f\u9650\u591a\u81ea\u7136\u4efb\u52a1\u4e2d\u7cbe\u7ec6\u663e\u5f0f\u4e16\u754c\u6a21\u578b\u7684\u53d1\u5c55\u4ecd\u662f\u5173\u952e\u74f6\u9888\u3002\u6807\u51c6\u5f3a\u5316\u5b66\u4e60\u5728\u9ad8\u4fdd\u771f\u5ea6\u4f46\u7ed3\u6784\u5e73\u5766\u7684\u6a21\u62df\u5668\u4e2d\u5b58\u5728\u63a2\u7d22\u7a7a\u95f4\u96be\u4ee5\u5904\u7406\u548c\u5956\u52b1\u7a00\u758f\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u52a8\u6001\u751f\u6210\u5c42\u6b21\u67b6\u6784\u7684\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u8bed\u8a00\u6765\u7acb\u5373\u6784\u5efa\u4e16\u754c\u6a21\u578b\u3002\u8fd9\u79cd\u8bed\u8a00\u9a71\u52a8\u7684\u4e16\u754c\u6a21\u578b\u63d0\u4f9b\u5185\u5728\u8bfe\u7a0b\u3001\u6d53\u5bc6\u6709\u610f\u4e49\u7684\u5b66\u4e60\u4fe1\u53f7\u4ee5\u53ca\u7ec4\u5408\u5b66\u4e60\u6846\u67b6\u3002\u901a\u8fc7\u6784\u5efa\u5177\u6709\u663e\u5f0f\u3001\u8bed\u8a00\u53ef\u914d\u7f6e\u4efb\u52a1\u5c42\u7684\u73af\u5883\u6765\u5b9e\u73b0\u3002", "result": "\u901a\u8fc7\u7cfb\u7edf\u6027\u5ba1\u67e52024\u5e74\u591a\u81ea\u7136\u8db3\u7403\u7814\u7a76\uff0c\u53d1\u73b0\u4e86\u4e00\u4e2a\u660e\u786e\u7684\u8d8b\u52bf\uff1a\u5c06\u7b26\u53f7\u548c\u5c42\u6b21\u65b9\u6cd5\u4e0e\u591a\u81ea\u7136\u5f3a\u5316\u5b66\u4e60\u96c6\u6210\u3002\u8fd9\u4e9b\u65b9\u6cd5\u663e\u6216\u9690\u5730\u6784\u5efa\u4e86\u57fa\u4e8e\u4efb\u52a1\u7684\u4e16\u754c\u6a21\u578b\u6765\u6307\u5bfc\u81ea\u7136\u5b66\u4e60\u3002", "conclusion": "\u901a\u8fc7\u6784\u5efa\u5177\u6709\u663e\u5f0f\u3001\u8bed\u8a00\u53ef\u914d\u7f6e\u4efb\u52a1\u5c42\u7684\u73af\u5883\uff0c\u53ef\u4ee5\u6865\u63a5\u4f4e\u7ea7\u53cd\u5e94\u5f0f\u884c\u4e3a\u548c\u9ad8\u7ea7\u6218\u7565\u56e2\u961f\u914d\u5408\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u521b\u5efa\u4e00\u4e2a\u5f3a\u5927\u4e14\u53ef\u666e\u904d\u5316\u7684\u6846\u67b6\u6765\u8bad\u7ec3\u4e0b\u4e00\u4ee3\u667a\u80fd\u81ea\u7136\u3002"}}
{"id": "2509.05192", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.05192", "abs": "https://arxiv.org/abs/2509.05192", "authors": ["Simon Lachnit", "Ghassan Karame"], "title": "On Hyperparameters and Backdoor-Resistance in Horizontal Federated Learning", "comment": "To appear in the Proceedings of the ACM Conference on Computer and\n  Communications Security (CCS) 2025", "summary": "Horizontal Federated Learning (HFL) is particularly vulnerable to backdoor\nattacks as adversaries can easily manipulate both the training data and\nprocesses to execute sophisticated attacks. In this work, we study the impact\nof training hyperparameters on the effectiveness of backdoor attacks and\ndefenses in HFL. More specifically, we show both analytically and by means of\nmeasurements that the choice of hyperparameters by benign clients does not only\ninfluence model accuracy but also significantly impacts backdoor attack\nsuccess. This stands in sharp contrast with the multitude of contributions in\nthe area of HFL security, which often rely on custom ad-hoc hyperparameter\nchoices for benign clients$\\unicode{x2013}$leading to more pronounced backdoor\nattack strength and diminished impact of defenses. Our results indicate that\nproperly tuning benign clients' hyperparameters$\\unicode{x2013}$such as\nlearning rate, batch size, and number of local epochs$\\unicode{x2013}$can\nsignificantly curb the effectiveness of backdoor attacks, regardless of the\nmalicious clients' settings. We support this claim with an extensive robustness\nevaluation of state-of-the-art attack-defense combinations, showing that\ncarefully chosen hyperparameters yield across-the-board improvements in\nrobustness without sacrificing main task accuracy. For example, we show that\nthe 50%-lifespan of the strong A3FL attack can be reduced by 98.6%,\nrespectively$\\unicode{x2013}$all without using any defense and while incurring\nonly a 2.9 percentage points drop in clean task accuracy.", "AI": {"tldr": "\u6c34\u5e73\u8054\u90a6\u5b66\u4e60\u4e2d\u826f\u6027\u5ba2\u6237\u7aef\u8d85\u53c2\u6570\u8bbe\u7f6e\u5bf9\u540e\u95e8\u653b\u51fb\u654f\u611f\u6027\u6709\u91cd\u5927\u5f71\u54cd\uff0c\u9002\u5f53\u8c03\u6574\u53ef\u663e\u8457\u63d0\u5347\u6a21\u578b\u9632\u5fa1\u80fd\u529b\u800c\u4e0d\u4e25\u91cd\u5f71\u54cd\u4e3b\u4efb\u52a1\u51c6\u786e\u6027", "motivation": "\u73b0\u6709HFL\u5b89\u5168\u7814\u7a76\u5e38\u5ffd\u89c6\u826f\u6027\u5ba2\u6237\u7aef\u8d85\u53c2\u6570\u9009\u62e9\u5bf9\u540e\u95e8\u653b\u51fb\u654c\u5f3a\u5ea6\u7684\u5f71\u54cd\uff0c\u5bfc\u81f4\u653b\u51fb\u6548\u679c\u88ab\u9ad8\u4f30\u548c\u9632\u5fa1\u6548\u679c\u88ab\u4f4e\u4f30", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u6d4b\u91cf\uff0c\u7cfb\u7edf\u7814\u7a76\u5b66\u4e60\u7387\u3001\u6279\u5904\u7406\u5927\u5c0f\u3001\u672c\u5730\u8fed\u4ee3\u6b21\u6570\u7b49\u8d85\u53c2\u6570\u5bf9\u540e\u95e8\u653b\u51fb\u6548\u679c\u7684\u5f71\u54cd", "result": "\u9002\u5f53\u8c03\u6574\u826f\u6027\u5ba2\u6237\u7aef\u8d85\u53c2\u6570\u53ef\u663e\u8457\u63d0\u5347\u6a21\u578b\u9632\u5fa1\u80fd\u529b\uff0cA3FL\u653b\u51fb\u58f0\u660e\u671f\u964d\u4f4e98.6%\uff0c\u4e3b\u4efb\u52a1\u51c6\u786e\u6027\u4ec5\u4e0b\u964d2.9%\u767e\u5206\u70b9", "conclusion": "\u5728HFL\u5b89\u5168\u7814\u7a76\u4e2d\u5e94\u91cd\u89c6\u826f\u6027\u5ba2\u6237\u7aef\u8d85\u53c2\u6570\u9009\u62e9\uff0c\u9002\u5f53\u8bbe\u7f6e\u53ef\u5728\u4e0d\u4f7f\u7528\u4efb\u4f55\u9632\u5fa1\u63aa\u65bd\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u6291\u5236\u540e\u95e8\u653b\u51fb"}}
{"id": "2509.04967", "categories": ["cs.SE", "cs.CR", "D.2.5"], "pdf": "https://arxiv.org/pdf/2509.04967", "abs": "https://arxiv.org/abs/2509.04967", "authors": ["Kai Feng", "Jeremy Singer", "Angelos K Marnerides"], "title": "FuzzRDUCC: Fuzzing with Reconstructed Def-Use Chain Coverage", "comment": null, "summary": "Binary-only fuzzing often struggles with achieving thorough code coverage and\nuncovering hidden vulnerabilities due to limited insight into a program's\ninternal dataflows. Traditional grey-box fuzzers guide test case generation\nprimarily using control flow edge coverage, which can overlook bugs not easily\nexposed through control flow analysis alone. We argue that integrating dataflow\nanalysis into the fuzzing process can enhance its effectiveness by revealing\nhow data propagates through the program, thereby enabling the exploration of\nexecution paths that control flow-based methods might miss. In this context, we\nintroduce FuzzRDUCC, a novel fuzzing framework that employs symbolic execution\nto reconstruct definition-use (def-use) chains directly from binary\nexecutables. FuzzRDUCC identifies crucial dataflow paths and exposes security\nvulnerabilities without incurring excessive computational overhead, due to a\nnovel heuristic algorithm that selects relevant def-use chains without\naffecting the thoroughness of the fuzzing process. We evaluate FuzzRDUCC using\nthe binutils benchmark and demonstrate that it can identify unique crashes not\nfound by state-of-the-art fuzzers. Hence, establishing FuzzRDUCC as a feasible\nsolution for next generation vulnerability detection and discovery mechanisms.", "AI": {"tldr": "FuzzRDUCC\u662f\u4e00\u4e2a\u57fa\u4e8e\u6570\u636e\u6d41\u5206\u6790\u7684\u4e8c\u8fdb\u5236\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u7b26\u53f7\u6267\u884c\u91cd\u5efadef-use\u94fe\u6765\u53d1\u73b0\u4f20\u7edf\u63a7\u5236\u6d41\u5206\u6790\u53ef\u80fd\u9057\u6f0f\u7684\u6f0f\u6d1e", "motivation": "\u4f20\u7edf\u7070\u76d2\u6a21\u7cca\u6d4b\u8bd5\u4e3b\u8981\u4f9d\u8d56\u63a7\u5236\u6d41\u8fb9\u8986\u76d6\u6765\u6307\u5bfc\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u53ef\u80fd\u5ffd\u7565\u4ec5\u901a\u8fc7\u63a7\u5236\u6d41\u5206\u6790\u96be\u4ee5\u66b4\u9732\u7684\u6f0f\u6d1e\u3002\u4e8c\u8fdb\u5236\u6a21\u7cca\u6d4b\u8bd5\u7531\u4e8e\u5bf9\u7a0b\u5e8f\u5185\u90e8\u6570\u636e\u6d41\u6d1e\u5bdf\u6709\u9650\uff0c\u5f80\u5f80\u96be\u4ee5\u5b9e\u73b0\u5f7b\u5e95\u7684\u4ee3\u7801\u8986\u76d6\u548c\u53d1\u73b0\u9690\u85cf\u6f0f\u6d1e", "method": "FuzzRDUCC\u91c7\u7528\u7b26\u53f7\u6267\u884c\u6280\u672f\u76f4\u63a5\u4ece\u4e8c\u8fdb\u5236\u53ef\u6267\u884c\u6587\u4ef6\u4e2d\u91cd\u5efa\u5b9a\u4e49-\u4f7f\u7528(def-use)\u94fe\uff0c\u4f7f\u7528\u65b0\u9896\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\u9009\u62e9\u76f8\u5173def-use\u94fe\uff0c\u5728\u4e0d\u5f71\u54cd\u6a21\u7cca\u6d4b\u8bd5\u5f7b\u5e95\u6027\u7684\u524d\u63d0\u4e0b\u907f\u514d\u8fc7\u9ad8\u8ba1\u7b97\u5f00\u9500", "result": "\u5728binutils\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8bc4\u4f30\u8868\u660e\uff0cFuzzRDUCC\u80fd\u591f\u53d1\u73b0\u6700\u5148\u8fdb\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u672a\u80fd\u53d1\u73b0\u7684\u72ec\u7279\u5d29\u6e83", "conclusion": "FuzzRDUCC\u901a\u8fc7\u6574\u5408\u6570\u636e\u6d41\u5206\u6790\u5230\u6a21\u7cca\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u6f0f\u6d1e\u68c0\u6d4b\u548c\u53d1\u73b0\u673a\u5236\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.04791", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.04791", "abs": "https://arxiv.org/abs/2509.04791", "authors": ["Yuan Sui", "Yanming Zhang", "Yi Liao", "Yu Gu", "Guohua Tang", "Zhongqian Sun", "Wei Yang", "Bryan Hooi"], "title": "What-If Analysis of Large Language Models: Explore the Game World Using Proactive Thinking", "comment": "arXiv admin note: text overlap with arXiv:2508.21365", "summary": "Large language models (LLMs) excel at processing information reactively but\nlack the ability to systemically explore hypothetical futures. They cannot ask,\n\"what if we take this action? how will it affect the final outcome\" and\nforecast its potential consequences before acting. This critical gap limits\ntheir utility in dynamic, high-stakes scenarios like strategic planning, risk\nassessment, and real-time decision making. To bridge this gap, we propose\nWiA-LLM, a new paradigm that equips LLMs with proactive thinking capabilities.\nOur approach integrates What-If Analysis (WIA), a systematic approach for\nevaluating hypothetical scenarios by changing input variables. By leveraging\nenvironmental feedback via reinforcement learning, WiA-LLM moves beyond\nreactive thinking. It dynamically simulates the outcomes of each potential\naction, enabling the model to anticipate future states rather than merely react\nto the present conditions. We validate WiA-LLM in Honor of Kings (HoK), a\ncomplex multiplayer game environment characterized by rapid state changes and\nintricate interactions. The game's real-time state changes require precise\nmulti-step consequence prediction, making it an ideal testbed for our approach.\nExperimental results demonstrate WiA-LLM achieves a remarkable 74.2% accuracy\nin forecasting game-state changes (up to two times gain over baselines). The\nmodel shows particularly significant gains in high-difficulty scenarios where\naccurate foresight is critical. To our knowledge, this is the first work to\nformally explore and integrate what-if analysis capabilities within LLMs.\nWiA-LLM represents a fundamental advance toward proactive reasoning in LLMs,\nproviding a scalable framework for robust decision-making in dynamic\nenvironments with broad implications for strategic applications.", "AI": {"tldr": "WiA-LLM\u662f\u4e00\u4e2a\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u6574\u5408\u5047\u8bbe\u5206\u6790(WIA)\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u5177\u5907\u4e3b\u52a8\u601d\u8003\u80fd\u529b\uff0c\u80fd\u591f\u5728\u590d\u6742\u52a8\u6001\u73af\u5883\u4e2d\u9884\u6d4b\u884c\u52a8\u540e\u679c\uff0c\u5728\u738b\u8005\u8363\u8000\u6e38\u620f\u4e2d\u8fbe\u523074.2%\u7684\u72b6\u6001\u53d8\u5316\u9884\u6d4b\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u53ea\u80fd\u88ab\u52a8\u5904\u7406\u4fe1\u606f\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u6027\u63a2\u7d22\u5047\u8bbe\u672a\u6765\u7684\u80fd\u529b\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5728\u52a8\u6001\u9ad8\u98ce\u9669\u573a\u666f\uff08\u5982\u6218\u7565\u89c4\u5212\u3001\u98ce\u9669\u8bc4\u4f30\u548c\u5b9e\u65f6\u51b3\u7b56\uff09\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "method": "\u6574\u5408\u5047\u8bbe\u5206\u6790(WIA)\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5229\u7528\u73af\u5883\u53cd\u9988\uff0c\u52a8\u6001\u6a21\u62df\u6bcf\u4e2a\u6f5c\u5728\u884c\u52a8\u7684\u7ed3\u679c\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u9884\u6d4b\u672a\u6765\u72b6\u6001\u800c\u4e0d\u4ec5\u4ec5\u662f\u54cd\u5e94\u5f53\u524d\u6761\u4ef6\u3002\u5728\u738b\u8005\u8363\u8000\u590d\u6742\u591a\u73a9\u5bb6\u6e38\u620f\u73af\u5883\u4e2d\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "WiA-LLM\u5728\u9884\u6d4b\u6e38\u620f\u72b6\u6001\u53d8\u5316\u65b9\u9762\u8fbe\u523074.2%\u7684\u51c6\u786e\u7387\uff08\u6bd4\u57fa\u7ebf\u63d0\u9ad8\u4e24\u500d\uff09\uff0c\u5728\u9ad8\u96be\u5ea6\u573a\u666f\u4e2d\u8868\u73b0\u5c24\u4e3a\u7a81\u51fa\uff0c\u51c6\u786e\u7684\u524d\u77bb\u6027\u9884\u6d4b\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u6b63\u5f0f\u63a2\u7d22\u548c\u6574\u5408\u5047\u8bbe\u5206\u6790\u80fd\u529b\u5230\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5de5\u4f5c\uff0c\u4ee3\u8868\u4e86LLM\u4e3b\u52a8\u63a8\u7406\u7684\u6839\u672c\u6027\u8fdb\u6b65\uff0c\u4e3a\u52a8\u6001\u73af\u5883\u4e2d\u7684\u7a33\u5065\u51b3\u7b56\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u6846\u67b6\u3002"}}
{"id": "2509.05265", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.05265", "abs": "https://arxiv.org/abs/2509.05265", "authors": ["Zijian Wang", "Wei Tong", "Tingxuan Han", "Haoyu Chen", "Tianling Zhang", "Yunlong Mao", "Sheng Zhong"], "title": "On Evaluating the Poisoning Robustness of Federated Learning under Local Differential Privacy", "comment": null, "summary": "Federated learning (FL) combined with local differential privacy (LDP)\nenables privacy-preserving model training across decentralized data sources.\nHowever, the decentralized data-management paradigm leaves LDPFL vulnerable to\nparticipants with malicious intent. The robustness of LDPFL protocols,\nparticularly against model poisoning attacks (MPA), where adversaries inject\nmalicious updates to disrupt global model convergence, remains insufficiently\nstudied. In this paper, we propose a novel and extensible model poisoning\nattack framework tailored for LDPFL settings. Our approach is driven by the\nobjective of maximizing the global training loss while adhering to local\nprivacy constraints. To counter robust aggregation mechanisms such as\nMulti-Krum and trimmed mean, we develop adaptive attacks that embed carefully\ncrafted constraints into a reverse training process, enabling evasion of these\ndefenses. We evaluate our framework across three representative LDPFL\nprotocols, three benchmark datasets, and two types of deep neural networks.\nAdditionally, we investigate the influence of data heterogeneity and privacy\nbudgets on attack effectiveness. Experimental results demonstrate that our\nadaptive attacks can significantly degrade the performance of the global model,\nrevealing critical vulnerabilities and highlighting the need for more robust\nLDPFL defense strategies against MPA. Our code is available at\nhttps://github.com/ZiJW/LDPFL-Attack", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u5c40\u90e8\u5dee\u5206\u9690\u79c1\u8054\u90a6\u5b66\u4e60\u7684\u6a21\u578b\u6bd2\u5316\u653b\u51fb\u6846\u67b6\uff0c\u80fd\u591f\u907f\u514d\u73b0\u6709\u9632\u5fa1\u673a\u5236\u5e76\u663e\u8457\u964d\u4f4e\u5168\u5c40\u6a21\u578b\u6027\u80fd", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e0e\u5c40\u90e8\u5dee\u5206\u9690\u79c1\u7ed3\u5408\u867d\u80fd\u4fdd\u62a4\u9690\u79c1\uff0c\u4f46\u5bb9\u6613\u53d7\u5230\u6076\u610f\u53c2\u4e0e\u8005\u7684\u6a21\u578b\u6bd2\u5316\u653b\u51fb\uff0c\u5f53\u524d\u7684\u7a33\u5065\u6027\u7814\u7a76\u4e0d\u8db3", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u6a21\u578b\u6bd2\u5316\u653b\u51fb\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u9075\u5b88\u5c40\u90e8\u9690\u79c1\u7ea6\u675f\u7684\u524d\u63d0\u4e0b\u6700\u5927\u5316\u5168\u5c40\u8bad\u7ec3\u635f\u5931\uff0c\u5e76\u4e3a\u5bf9\u6297Multi-Krum\u548c\u4fee\u526a\u5747\u503c\u7b49\u7a33\u5065\u805a\u5408\u673a\u5236\u8bbe\u8ba1\u4e86\u9002\u5e94\u6027\u653b\u51fb", "result": "\u57283\u79cd\u4ee3\u8868\u6027LDPFL\u534f\u8bae\u30013\u4e2a\u6807\u51c6\u6570\u636e\u96c6\u548c2\u7c7b\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4e0a\u8bc4\u4f30\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u9002\u5e94\u6027\u653b\u51fb\u80fd\u663e\u8457\u964d\u4f4e\u5168\u5c40\u6a21\u578b\u6027\u80fd\uff0c\u63ed\u793a\u4e86\u5173\u952e\u6f0f\u6d1e", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86LDPFL\u534f\u8bae\u5728\u6a21\u578b\u6bd2\u5316\u653b\u51fb\u4e0b\u7684\u4e25\u91cd\u6f0f\u6d1e\uff0c\u5f3a\u8c03\u4e86\u5f00\u53d1\u66f4\u7a33\u5065\u7684\u9632\u5fa1\u7b56\u7565\u7684\u5fc5\u8981\u6027"}}
{"id": "2509.05112", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05112", "abs": "https://arxiv.org/abs/2509.05112", "authors": ["Denesa Zyberaj", "Lukasz Mazur", "Nenad Petrovic", "Pankhuri Verma", "Pascal Hirmer", "Dirk Slama", "Xiangwei Cheng", "Alois Knoll"], "title": "GenAI-based test case generation and execution in SDV platform", "comment": null, "summary": "This paper introduces a GenAI-driven approach for automated test case\ngeneration, leveraging Large Language Models and Vision-Language Models to\ntranslate natural language requirements and system diagrams into structured\nGherkin test cases. The methodology integrates Vehicle Signal Specification\nmodeling to standardize vehicle signal definitions, improve compatibility\nacross automotive subsystems, and streamline integration with third-party\ntesting tools. Generated test cases are executed within the digital.auto\nplayground, an open and vendor-neutral environment designed to facilitate rapid\nvalidation of software-defined vehicle functionalities. We evaluate our\napproach using the Child Presence Detection System use case, demonstrating\nsubstantial reductions in manual test specification effort and rapid execution\nof generated tests. Despite significant automation, the generation of test\ncases and test scripts still requires manual intervention due to current\nlimitations in the GenAI pipeline and constraints of the digital.auto platform.", "AI": {"tldr": "\u4f7f\u7528GenAI\u548cVLM\u6280\u672f\u5c06\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u548c\u7cfb\u7edf\u56fe\u81ea\u52a8\u8f6c\u6362\u4e3aGherkin\u6d4b\u8bd5\u7528\u4f8b\uff0c\u901a\u8fc7VSS\u6807\u51c6\u5316\u8f66\u8f86\u4fe1\u53f7\u5b9a\u4e49\uff0c\u5728digital.auto\u5e73\u53f0\u4e0a\u9a8c\u8bc1\uff0c\u663e\u8457\u51cf\u5c11\u4eba\u5de5\u6d4b\u8bd5\u5de5\u4f5c\u91cf\u4f46\u4ecd\u9700\u4eba\u5de5\u5e72\u9884", "motivation": "\u89e3\u51b3\u6c7d\u8f66\u8f6f\u4ef6\u6d4b\u8bd5\u4e2d\u4eba\u5de5\u7f16\u5199\u6d4b\u8bd5\u7528\u4f8b\u6548\u7387\u4f4e\u3001\u517c\u5bb9\u6027\u5dee\u7684\u95ee\u9898\uff0c\u5229\u7528AI\u6280\u672f\u81ea\u52a8\u5316\u6d4b\u8bd5\u751f\u6210\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u8f6f\u4ef6\u5b9a\u4e49\u8f66\u8f86\u529f\u80fd\u7684\u9a8c\u8bc1\u6548\u7387", "method": "\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u548c\u7cfb\u7edf\u56fe\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316Gherkin\u6d4b\u8bd5\u7528\u4f8b\uff0c\u91c7\u7528\u8f66\u8f86\u4fe1\u53f7\u89c4\u8303(VSS)\u5efa\u6a21\u6807\u51c6\u5316\u4fe1\u53f7\u5b9a\u4e49\uff0c\u5728digital.auto\u5f00\u653e\u5e73\u53f0\u4e0a\u6267\u884c\u9a8c\u8bc1", "result": "\u4ee5\u513f\u7ae5\u5b58\u5728\u68c0\u6d4b\u7cfb\u7edf\u4e3a\u4f8b\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u5927\u5e45\u51cf\u5c11\u4eba\u5de5\u6d4b\u8bd5\u89c4\u8303\u5de5\u4f5c\u91cf\uff0c\u5b9e\u73b0\u5feb\u901f\u6d4b\u8bd5\u6267\u884c\uff0c\u5c55\u793a\u4e86\u81ea\u52a8\u5316\u6d4b\u8bd5\u751f\u6210\u7684\u53ef\u884c\u6027", "conclusion": "GenAI\u9a71\u52a8\u7684\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u65b9\u6cd5\u5728\u6c7d\u8f66\u8f6f\u4ef6\u6d4b\u8bd5\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4f46\u5f53\u524d\u7531\u4e8eGenAI\u7ba1\u9053\u9650\u5236\u548c\u5e73\u53f0\u7ea6\u675f\uff0c\u6d4b\u8bd5\u7528\u4f8b\u548c\u811a\u672c\u751f\u6210\u4ecd\u9700\u4eba\u5de5\u5e72\u9884\uff0c\u672a\u6765\u9700\u8981\u8fdb\u4e00\u6b65\u4f18\u5316\u81ea\u52a8\u5316\u6d41\u7a0b"}}
{"id": "2509.04809", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.04809", "abs": "https://arxiv.org/abs/2509.04809", "authors": ["Haechang Kim", "Hao Chen", "Can Li", "Jong Min Lee"], "title": "TalkToAgent: A Human-centric Explanation of Reinforcement Learning Agents with Large Language Models", "comment": "31 pages total", "summary": "Explainable Reinforcement Learning (XRL) has emerged as a promising approach\nin improving the transparency of Reinforcement Learning (RL) agents. However,\nthere remains a gap between complex RL policies and domain experts, due to the\nlimited comprehensibility of XRL results and isolated coverage of current XRL\napproaches that leave users uncertain about which tools to employ. To address\nthese challenges, we introduce TalkToAgent, a multi-agent Large Language Models\n(LLM) framework that delivers interactive, natural language explanations for RL\npolicies. The architecture with five specialized LLM agents (Coordinator,\nExplainer, Coder, Evaluator, and Debugger) enables TalkToAgent to automatically\nmap user queries to relevant XRL tools and clarify an agent's actions in terms\nof either key state variables, expected outcomes, or counterfactual\nexplanations. Moreover, our approach extends previous counterfactual\nexplanations by deriving alternative scenarios from qualitative behavioral\ndescriptions, or even new rule-based policies. We validated TalkToAgent on\nquadruple-tank process control problem, a well-known nonlinear control\nbenchmark. Results demonstrated that TalkToAgent successfully mapped user\nqueries into XRL tasks with high accuracy, and coder-debugger interactions\nminimized failures in counterfactual generation. Furthermore, qualitative\nevaluation confirmed that TalkToAgent effectively interpreted agent's actions\nand contextualized their meaning within the problem domain.", "AI": {"tldr": "TalkToAgent\u662f\u4e00\u4e2a\u591a\u4ee3\u7406LLM\u6846\u67b6\uff0c\u901a\u8fc7\u4e94\u4e2a\u4e13\u4e1a\u4ee3\u7406\u63d0\u4f9b\u4ea4\u4e92\u5f0f\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff0c\u5f25\u5408\u590d\u6742RL\u7b56\u7565\u4e0e\u9886\u57df\u4e13\u5bb6\u4e4b\u95f4\u7684\u7406\u89e3\u9e3f\u6c9f\u3002", "motivation": "\u5f53\u524dXRL\u65b9\u6cd5\u5b58\u5728\u89e3\u91ca\u7ed3\u679c\u53ef\u7406\u89e3\u6027\u6709\u9650\u3001\u5de5\u5177\u8986\u76d6\u5b64\u7acb\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u7528\u6237\u4e0d\u786e\u5b9a\u4f7f\u7528\u54ea\u79cd\u5de5\u5177\uff0c\u9700\u8981\u66f4\u900f\u660e\u3001\u4ea4\u4e92\u5f0f\u7684RL\u7b56\u7565\u89e3\u91ca\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e94\u4ee3\u7406LLM\u67b6\u6784\uff08\u534f\u8c03\u5668\u3001\u89e3\u91ca\u5668\u3001\u7f16\u7801\u5668\u3001\u8bc4\u4f30\u5668\u3001\u8c03\u8bd5\u5668\uff09\uff0c\u81ea\u52a8\u5c06\u7528\u6237\u67e5\u8be2\u6620\u5c04\u5230\u76f8\u5173XRL\u5de5\u5177\uff0c\u63d0\u4f9b\u72b6\u6001\u53d8\u91cf\u3001\u9884\u671f\u7ed3\u679c\u6216\u53cd\u4e8b\u5b9e\u89e3\u91ca\u3002", "result": "\u5728\u56db\u91cd\u6c34\u7bb1\u8fc7\u7a0b\u63a7\u5236\u95ee\u9898\u4e0a\u9a8c\u8bc1\uff0c\u6210\u529f\u9ad8\u7cbe\u5ea6\u6620\u5c04\u7528\u6237\u67e5\u8be2\u5230XRL\u4efb\u52a1\uff0c\u7f16\u7801\u5668-\u8c03\u8bd5\u5668\u4ea4\u4e92\u6700\u5c0f\u5316\u53cd\u4e8b\u5b9e\u751f\u6210\u5931\u8d25\uff0c\u5b9a\u6027\u8bc4\u4f30\u786e\u8ba4\u6709\u6548\u89e3\u91ca\u4ee3\u7406\u884c\u4e3a\u3002", "conclusion": "TalkToAgent\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86RL\u7b56\u7565\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u901a\u8fc7\u591a\u4ee3\u7406\u534f\u4f5c\u63d0\u4f9b\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff0c\u89e3\u51b3\u4e86XRL\u5de5\u5177\u9009\u62e9\u4e0d\u786e\u5b9a\u6027\u548c\u89e3\u91ca\u7406\u89e3\u56f0\u96be\u7684\u95ee\u9898\u3002"}}
{"id": "2509.05197", "categories": ["cs.SE", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.05197", "abs": "https://arxiv.org/abs/2509.05197", "authors": ["Naimeng Ye", "Xiao Yu", "Ruize Xu", "Tianyi Peng", "Zhou Yu"], "title": "AI Agents for Web Testing: A Case Study in the Wild", "comment": null, "summary": "Automated web testing plays a critical role in ensuring high-quality user\nexperiences and delivering business value. Traditional approaches primarily\nfocus on code coverage and load testing, but often fall short of capturing\ncomplex user behaviors, leaving many usability issues undetected. The emergence\nof large language models (LLM) and AI agents opens new possibilities for web\ntesting by enabling human-like interaction with websites and a general\nawareness of common usability problems. In this work, we present WebProber, a\nprototype AI agent-based web testing framework. Given a URL, WebProber\nautonomously explores the website, simulating real user interactions,\nidentifying bugs and usability issues, and producing a human-readable report.\nWe evaluate WebProber through a case study of 120 academic personal websites,\nwhere it uncovered 29 usability issues--many of which were missed by\ntraditional tools. Our findings highlight agent-based testing as a promising\ndirection while outlining directions for developing next-generation,\nuser-centered testing frameworks.", "AI": {"tldr": "WebProber\u662f\u4e00\u4e2a\u57fa\u4e8eAI\u4ee3\u7406\u7684\u7f51\u9875\u6d4b\u8bd5\u6846\u67b6\uff0c\u80fd\u591f\u81ea\u4e3b\u63a2\u7d22\u7f51\u7ad9\u3001\u6a21\u62df\u771f\u5b9e\u7528\u6237\u4ea4\u4e92\u3001\u8bc6\u522bbug\u548c\u53ef\u7528\u6027\u95ee\u9898\uff0c\u5e76\u751f\u6210\u53ef\u8bfb\u62a5\u544a\u3002", "motivation": "\u4f20\u7edf\u7f51\u9875\u6d4b\u8bd5\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u4ee3\u7801\u8986\u76d6\u548c\u8d1f\u8f7d\u6d4b\u8bd5\uff0c\u4f46\u5f80\u5f80\u65e0\u6cd5\u6355\u6349\u590d\u6742\u7684\u7528\u6237\u884c\u4e3a\uff0c\u5bfc\u81f4\u8bb8\u591a\u53ef\u7528\u6027\u95ee\u9898\u672a\u88ab\u53d1\u73b0\u3002LLM\u548cAI\u4ee3\u7406\u7684\u51fa\u73b0\u4e3a\u7f51\u9875\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u65b0\u53ef\u80fd\u3002", "method": "\u5f00\u53d1\u4e86WebProber\u539f\u578b\u6846\u67b6\uff0c\u7ed9\u5b9aURL\u540e\u80fd\u81ea\u4e3b\u63a2\u7d22\u7f51\u7ad9\uff0c\u6a21\u62df\u771f\u5b9e\u7528\u6237\u4ea4\u4e92\uff0c\u8bc6\u522bbug\u548c\u53ef\u7528\u6027\u95ee\u9898\uff0c\u5e76\u751f\u6210\u4eba\u7c7b\u53ef\u8bfb\u62a5\u544a\u3002", "result": "\u5728120\u4e2a\u5b66\u672f\u4e2a\u4eba\u7f51\u7ad9\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u53d1\u73b0\u4e8629\u4e2a\u53ef\u7528\u6027\u95ee\u9898\uff0c\u5176\u4e2d\u8bb8\u591a\u662f\u4f20\u7edf\u5de5\u5177\u9057\u6f0f\u7684\u3002", "conclusion": "\u57fa\u4e8e\u4ee3\u7406\u7684\u6d4b\u8bd5\u662f\u4e00\u4e2a\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u4e3a\u5f00\u53d1\u4e0b\u4e00\u4ee3\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u6d4b\u8bd5\u6846\u67b6\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2509.04847", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.04847", "abs": "https://arxiv.org/abs/2509.04847", "authors": ["Mukul Singh", "Arjun Radhakrishna", "Sumit Gulwani"], "title": "Collaboration and Conflict between Humans and Language Models through the Lens of Game Theory", "comment": "9 pages", "summary": "Language models are increasingly deployed in interactive online environments,\nfrom personal chat assistants to domain-specific agents, raising questions\nabout their cooperative and competitive behavior in multi-party settings. While\nprior work has examined language model decision-making in isolated or\nshort-term game-theoretic contexts, these studies often neglect long-horizon\ninteractions, human-model collaboration, and the evolution of behavioral\npatterns over time. In this paper, we investigate the dynamics of language\nmodel behavior in the iterated prisoner's dilemma (IPD), a classical framework\nfor studying cooperation and conflict. We pit model-based agents against a\nsuite of 240 well-established classical strategies in an Axelrod-style\ntournament and find that language models achieve performance on par with, and\nin some cases exceeding, the best-known classical strategies. Behavioral\nanalysis reveals that language models exhibit key properties associated with\nstrong cooperative strategies - niceness, provocability, and generosity while\nalso demonstrating rapid adaptability to changes in opponent strategy mid-game.\nIn controlled \"strategy switch\" experiments, language models detect and respond\nto shifts within only a few rounds, rivaling or surpassing human adaptability.\nThese results provide the first systematic characterization of long-term\ncooperative behaviors in language model agents, offering a foundation for\nfuture research into their role in more complex, mixed human-AI social\nenvironments.", "AI": {"tldr": "\u8bed\u8a00\u6a21\u578b\u5728\u8fed\u4ee3\u56f0\u5f92\u56f0\u5883IPD\u4e2d\u8868\u73b0\u51fa\u4e0e\u6700\u4f73\u7ecf\u5178\u7b56\u7565\u76f8\u5f53\u6216\u66f4\u4f18\u7684\u5408\u4f5c\u6027\u80fd\u529b\uff0c\u5177\u5907\u53cb\u5584\u6027\u3001\u8be1\u8bc1\u6027\u548c\u5bbd\u5bb9\u6027\u7279\u5f81\uff0c\u80fd\u5feb\u901f\u9002\u5e94\u5bf9\u624b\u7b56\u7565\u53d8\u5316", "motivation": "\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u5728\u591a\u65b9\u4ea4\u4e92\u73af\u5883\u4e2d\u7684\u5408\u4f5c\u4e0e\u7ade\u4e89\u884c\u4e3a\uff0c\u8865\u5145\u73b0\u6709\u7814\u7a76\u5728\u957f\u671f\u4ea4\u4e92\u3001\u4eba\u673a\u534f\u4f5c\u548c\u884c\u4e3a\u6f14\u5316\u65b9\u9762\u7684\u4e0d\u8db3", "method": "\u5728\u8fed\u4ee3\u56f0\u5f92\u56f0\u5883(IPD)\u4e2d\u8fdb\u884cAxelrod\u98ce\u683c\u7684\u6bd4\u8d5b\uff0c\u8ba9\u6a21\u578b\u4ee3\u7406\u4e0e240\u79cd\u7ecf\u5178\u7b56\u7565\u5bf9\u6297\uff0c\u5e76\u8bbe\u8ba1\u7b56\u7565\u5207\u6362\u5b9e\u9a8c\u6d4b\u8bd5\u9002\u5e94\u6027", "result": "\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u4e0e\u6700\u4f73\u7ecf\u5178\u7b56\u7565\u76f8\u5f53\u6216\u66f4\u4f18\uff0c\u5177\u5907\u5f3a\u5408\u4f5c\u7b56\u7565\u7684\u5173\u952e\u7279\u5f81\uff0c\u80fd\u5728\u51e0\u8f6e\u5185\u68c0\u6d4b\u5e76\u5e94\u5bf9\u5bf9\u624b\u7b56\u7565\u53d8\u5316\uff0c\u9002\u5e94\u6027\u53ef\u4e0e\u4eba\u7c7b\u76f8\u6bd4\u6216\u66f4\u597d", "conclusion": "\u8be5\u7814\u7a76\u7cfb\u7edf\u6027\u63cf\u8ff0\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u957f\u671f\u5408\u4f5c\u884c\u4e3a\u4e2d\u7684\u8868\u73b0\uff0c\u4e3a\u672a\u6765\u66f4\u590d\u6742\u6df7\u5408\u4eba\u5de5\u667a\u80fd\u793e\u4f1a\u73af\u5883\u7684\u7814\u7a76\u5960\u5b9a\u57fa\u7840"}}
{"id": "2509.04871", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.04871", "abs": "https://arxiv.org/abs/2509.04871", "authors": ["Krittanon Kaewtawee", "Wachiravit Modecrua", "Krittin Pachtrachai", "Touchapon Kraisingkorn"], "title": "Cloning a Conversational Voice AI Agent from Call\\,Recording Datasets for Telesales", "comment": "10 pages, 4 figures", "summary": "Recent advances in language and speech modelling have made it possible to\nbuild autonomous voice assistants that understand and generate human dialogue\nin real time. These systems are increasingly being deployed in domains such as\ncustomer service and healthcare care, where they can automate repetitive tasks,\nreduce operational costs, and provide constant support around the clock. In\nthis paper, we present a general methodology for cloning a conversational voice\nAI agent from a corpus of call recordings. Although the case study described in\nthis paper uses telesales data to illustrate the approach, the underlying\nprocess generalizes to any domain where call transcripts are available. Our\nsystem listens to customers over the telephone, responds with a synthetic\nvoice, and follows a structured playbook learned from top performing human\nagents. We describe the domain selection, knowledge extraction, and prompt\nengineering used to construct the agent, integrating automatic speech\nrecognition, a large language model based dialogue manager, and text to speech\nsynthesis into a streaming inference pipeline. The cloned agent is evaluated\nagainst human agents on a rubric of 22 criteria covering introduction, product\ncommunication, sales drive, objection handling, and closing. Blind tests show\nthat the AI agent approaches human performance in routine aspects of the call\nwhile underperforming in persuasion and objection handling. We analyze these\nshortcomings and refine the prompt accordingly. The paper concludes with design\nlessons and avenues for future research, including large scale simulation and\nautomated evaluation.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u7535\u8bdd\u901a\u8bdd\u5f55\u97f3\u4e2d\u514b\u9686\u5bf9\u8bdd\u5f0f\u8bed\u97f3AI\u52a9\u624b\u7684\u901a\u7528\u65b9\u6cd5\u3002\u7cfb\u7edf\u901a\u8fc7\u8bed\u97f3\u8bc6\u522b\u3001\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u8bdd\u7ba1\u7406\u548c\u8bed\u97f3\u5408\u6210\u6280\u672f\uff0c\u5b66\u4e60\u9876\u5c16\u4eba\u7c7b\u8425\u9500\u4eba\u5458\u7684\u8bdd\u672f\u7b56\u7565\u3002\u8bc4\u4f30\u663e\u793aAI\u5728\u5e38\u89c4\u901a\u8bdd\u65b9\u9762\u63a5\u8fd1\u4eba\u7c7b\u8868\u73b0\uff0c\u4f46\u5728\u8bf4\u670d\u548c\u5f02\u8bae\u5904\u7406\u65b9\u9762\u8fd8\u6709\u63d0\u5347\u7a7a\u95f4\u3002", "motivation": "\u81ea\u52a8\u5316\u8bed\u97f3\u52a9\u624b\u5728\u5ba2\u670d\u548c\u533b\u7597\u9886\u57df\u6709\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\uff0c\u53ef\u4ee5\u964d\u4f4e\u8fd0\u8425\u6210\u672c\u5e76\u63d0\u4f9b24\u5c0f\u65f6\u652f\u6301\u3002\u7814\u7a76\u76ee\u6807\u662f\u4ece\u73b0\u6709\u7684\u7535\u8bdd\u901a\u8bdd\u5f55\u97f3\u4e2d\u514b\u9686\u51fa\u80fd\u591f\u7406\u89e3\u548c\u751f\u6210\u4eba\u7c7b\u5bf9\u8bdd\u7684\u8bed\u97f3AI\u52a9\u624b\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u901a\u7528\u65b9\u6cd5\u8bba\uff0c\u5305\u62ec\uff1a\u57df\u9009\u62e9\u3001\u77e5\u8bc6\u63d0\u53d6\u548c\u63d0\u793a\u5de5\u7a0b\u7b49\u6b65\u9aa4\u3002\u7cfb\u7edf\u6574\u5408\u4e86\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b(ASR)\u3001\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u8bdd\u7ba1\u7406\u5668\u548c\u6587\u672c\u8f6c\u8bed\u97f3(TTS)\u5408\u6210\u6280\u672f\uff0c\u6784\u5efa\u6d41\u5f0f\u63a8\u7406\u6d41\u6c34\u7ebf\u3002\u5b66\u4e60\u9876\u5c16\u4eba\u7c7b\u8425\u9500\u4eba\u5458\u7684\u7ed3\u6784\u5316\u811a\u672c\u3002", "result": "\u901a\u8fc7\u57fa\u4e8e22\u4e2a\u6807\u51c6\uff08\u5305\u62ec\u4ecb\u7ecd\u3001\u4ea7\u54c1\u6c9f\u901a\u3001\u9500\u552e\u63a8\u52a8\u3001\u5f02\u8bae\u5904\u7406\u548c\u6210\u4ea4\uff09\u7684\u76f2\u6d4b\u8bc4\u4f30\u663e\u793a\uff0cAI\u52a9\u624b\u5728\u5e38\u89c4\u901a\u8bdd\u65b9\u9762\u63a5\u8fd1\u4eba\u7c7b\u8868\u73b0\uff0c\u4f46\u5728\u8bf4\u670d\u529b\u548c\u5f02\u8bae\u5904\u7406\u65b9\u9762\u8868\u73b0\u8f83\u5dee\u3002\u7814\u7a76\u4eba\u5458\u5206\u6790\u4e86\u8fd9\u4e9b\u77ed\u677f\u5e76\u5bf9\u63d0\u793a\u8fdb\u884c\u4e86\u7cbe\u70bc\u3002", "conclusion": "\u8bba\u6587\u603b\u7ed3\u4e86\u8bbe\u8ba1\u7ecf\u9a8c\u6559\u8bad\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5305\u62ec\u5927\u89c4\u6a21\u6a21\u62df\u548c\u81ea\u52a8\u5316\u8bc4\u4f30\u3002\u867d\u7136\u5728\u67d0\u4e9b\u65b9\u9762\u8fd8\u6709\u63d0\u5347\u7a7a\u95f4\uff0c\u4f46\u8be5\u65b9\u6cd5\u8bc1\u660e\u4e86\u4ece\u73b0\u6709\u901a\u8bdd\u6570\u636e\u4e2d\u514b\u9686\u5bf9\u8bdd\u5f0f\u8bed\u97f3AI\u52a9\u624b\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2509.04876", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.04876", "abs": "https://arxiv.org/abs/2509.04876", "authors": ["Jusheng Zhang", "Yijia Fan", "Kaitong Cai", "Xiaofei Sun", "Keze Wang"], "title": "OSC: Cognitive Orchestration through Dynamic Knowledge Alignment in Multi-Agent LLM Collaboration", "comment": "Accepted at EMNLP 2025 (Long Paper)", "summary": "This paper introduces OSC (Orchestrating Cognitive Synergy), a\nknowledge-aware adaptive collaboration framework designed to enhance cognitive\nsynergy in multi-agent systems with large language models. While prior work has\nadvanced agent selection and result aggregation, efficient linguistic\ninteractions for deep collaboration among expert agents remain a critical\nbottleneck. OSC addresses this gap as a pivotal intermediate layer between\nselection and aggregation, introducing Collaborator Knowledge Models (CKM) to\nenable each agent to dynamically perceive its collaborators' cognitive states.\nThrough real-time cognitive gap analysis, agents adaptively adjust\ncommunication behaviors, including content focus, detail level, and expression\nstyle, using learned strategies. Experiments on complex reasoning and\nproblem-solving benchmarks demonstrate that OSC significantly improves task\nperformance and communication efficiency, transforming \"parallel-working\nindividuals'' into a \"deeply collaborative cognitive team.'' This framework not\nonly optimizes multi-agent collaboration but also offers new insights into LLM\nagent interaction behaviors.", "AI": {"tldr": "OSC\u662f\u4e00\u4e2a\u77e5\u8bc6\u611f\u77e5\u7684\u81ea\u9002\u5e94\u534f\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7\u8ba4\u77e5\u72b6\u6001\u611f\u77e5\u548c\u5b9e\u65f6\u8ba4\u77e5\u5dee\u8ddd\u5206\u6790\u6765\u589e\u5f3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2dLLM\u7684\u6df1\u5ea6\u534f\u4f5c\u80fd\u529b", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u4e13\u5bb6\u667a\u80fd\u4f53\u4e4b\u95f4\u9ad8\u6548\u8bed\u8a00\u4ea4\u4e92\u7684\u74f6\u9888\u95ee\u9898\uff0c\u73b0\u6709\u5de5\u4f5c\u5728\u667a\u80fd\u4f53\u9009\u62e9\u548c\u7ed3\u679c\u805a\u5408\u65b9\u9762\u6709\u8fdb\u5c55\uff0c\u4f46\u6df1\u5ea6\u534f\u4f5c\u7684\u4ea4\u4e92\u6548\u7387\u4ecd\u662f\u5173\u952e\u6311\u6218", "method": "\u5f15\u5165\u534f\u4f5c\u77e5\u8bc6\u6a21\u578b(CKM)\u4f7f\u667a\u80fd\u4f53\u52a8\u6001\u611f\u77e5\u5408\u4f5c\u8005\u8ba4\u77e5\u72b6\u6001\uff0c\u901a\u8fc7\u5b9e\u65f6\u8ba4\u77e5\u5dee\u8ddd\u5206\u6790\u81ea\u9002\u5e94\u8c03\u6574\u901a\u4fe1\u884c\u4e3a\uff08\u5185\u5bb9\u7126\u70b9\u3001\u7ec6\u8282\u5c42\u6b21\u3001\u8868\u8fbe\u98ce\u683c\uff09", "result": "\u5728\u590d\u6742\u63a8\u7406\u548c\u95ee\u9898\u89e3\u51b3\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u4efb\u52a1\u6027\u80fd\u548c\u901a\u4fe1\u6548\u7387\uff0c\u5c06\"\u5e76\u884c\u5de5\u4f5c\u7684\u4e2a\u4f53\"\u8f6c\u53d8\u4e3a\"\u6df1\u5ea6\u534f\u4f5c\u7684\u8ba4\u77e5\u56e2\u961f\"", "conclusion": "OSC\u4e0d\u4ec5\u4f18\u5316\u4e86\u591a\u667a\u80fd\u4f53\u534f\u4f5c\uff0c\u8fd8\u4e3aLLM\u667a\u80fd\u4f53\u4ea4\u4e92\u884c\u4e3a\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\uff0c\u4f5c\u4e3a\u9009\u62e9\u548c\u805a\u5408\u4e4b\u95f4\u7684\u5173\u952e\u4e2d\u95f4\u5c42"}}
{"id": "2509.04908", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.04908", "abs": "https://arxiv.org/abs/2509.04908", "authors": ["Hongyi Jing", "Jiafu Chen", "Chen Rao", "Ziqiang Dang", "Jiajie Teng", "Tianyi Chu", "Juncheng Mo", "Shuo Fang", "Huaizhong Lin", "Rui Lv", "Chenguang Ma", "Lei Zhao"], "title": "SparkUI-Parser: Enhancing GUI Perception with Robust Grounding and Parsing", "comment": null, "summary": "The existing Multimodal Large Language Models (MLLMs) for GUI perception have\nmade great progress. However, the following challenges still exist in prior\nmethods: 1) They model discrete coordinates based on text autoregressive\nmechanism, which results in lower grounding accuracy and slower inference\nspeed. 2) They can only locate predefined sets of elements and are not capable\nof parsing the entire interface, which hampers the broad application and\nsupport for downstream tasks. To address the above issues, we propose\nSparkUI-Parser, a novel end-to-end framework where higher localization\nprecision and fine-grained parsing capability of the entire interface are\nsimultaneously achieved. Specifically, instead of using probability-based\ndiscrete modeling, we perform continuous modeling of coordinates based on a\npre-trained Multimodal Large Language Model (MLLM) with an additional token\nrouter and coordinate decoder. This effectively mitigates the limitations\ninherent in the discrete output characteristics and the token-by-token\ngeneration process of MLLMs, consequently boosting both the accuracy and the\ninference speed. To further enhance robustness, a rejection mechanism based on\na modified Hungarian matching algorithm is introduced, which empowers the model\nto identify and reject non-existent elements, thereby reducing false positives.\nMoreover, we present ScreenParse, a rigorously constructed benchmark to\nsystematically assess structural perception capabilities of GUI models across\ndiverse scenarios. Extensive experiments demonstrate that our approach\nconsistently outperforms SOTA methods on ScreenSpot, ScreenSpot-v2,\nCAGUI-Grounding and ScreenParse benchmarks. The resources are available at\nhttps://github.com/antgroup/SparkUI-Parser.", "AI": {"tldr": "SparkUI-Parser\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u7aef\u5230\u7aefGUI\u89e3\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u8fde\u7eed\u5750\u6807\u5efa\u6a21\u548c\u62d2\u7edd\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728GUI\u611f\u77e5\u4e2d\u7684\u5b9a\u4f4d\u7cbe\u5ea6\u548c\u89e3\u6790\u80fd\u529b\u3002", "motivation": "\u73b0\u6709MLLM\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u57fa\u4e8e\u6587\u672c\u81ea\u56de\u5f52\u673a\u5236\u7684\u79bb\u6563\u5750\u6807\u5efa\u6a21\u5bfc\u81f4\u5b9a\u4f4d\u7cbe\u5ea6\u4f4e\u548c\u63a8\u7406\u901f\u5ea6\u6162\uff1b2\uff09\u53ea\u80fd\u5b9a\u4f4d\u9884\u5b9a\u4e49\u5143\u7d20\u96c6\u5408\uff0c\u65e0\u6cd5\u89e3\u6790\u6574\u4e2a\u754c\u9762\uff0c\u9650\u5236\u4e86\u5e7f\u6cdb\u5e94\u7528\u548c\u4e0b\u6e38\u4efb\u52a1\u652f\u6301\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u9884\u8bad\u7ec3MLLM\u7684\u8fde\u7eed\u5750\u6807\u5efa\u6a21\u65b9\u6cd5\uff0c\u589e\u52a0token\u8def\u7531\u5668\u548c\u5750\u6807\u89e3\u7801\u5668\uff1b\u5f15\u5165\u57fa\u4e8e\u6539\u8fdb\u5308\u7259\u5229\u5339\u914d\u7b97\u6cd5\u7684\u62d2\u7edd\u673a\u5236\u6765\u8bc6\u522b\u548c\u62d2\u7edd\u4e0d\u5b58\u5728\u7684\u5143\u7d20\uff1b\u6784\u5efaScreenParse\u57fa\u51c6\u6d4b\u8bd5\u96c6\u3002", "result": "\u5728ScreenSpot\u3001ScreenSpot-v2\u3001CAGUI-Grounding\u548cScreenParse\u7b49\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5747\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u6027\u548c\u63a8\u7406\u901f\u5ea6\u3002", "conclusion": "SparkUI-Parser\u901a\u8fc7\u8fde\u7eed\u5efa\u6a21\u548c\u62d2\u7edd\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709MLLM\u5728GUI\u89e3\u6790\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u4e3aGUI\u611f\u77e5\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u7cbe\u786e\u548c\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.04926", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.04926", "abs": "https://arxiv.org/abs/2509.04926", "authors": ["Barbara Gendron", "Ga\u00ebl Guibon", "Mathieu D'aquin"], "title": "Towards Ontology-Based Descriptions of Conversations with Qualitatively-Defined Concepts", "comment": "Accepted at TOTh 2025 (Terminology \\& Ontology: Theories and\n  applications)", "summary": "The controllability of Large Language Models (LLMs) when used as\nconversational agents is a key challenge, particularly to ensure predictable\nand user-personalized responses. This work proposes an ontology-based approach\nto formally define conversational features that are typically qualitative in\nnature. By leveraging a set of linguistic descriptors, we derive quantitative\ndefinitions for qualitatively-defined concepts, enabling their integration into\nan ontology for reasoning and consistency checking. We apply this framework to\nthe task of proficiency-level control in conversations, using CEFR language\nproficiency levels as a case study. These definitions are then formalized in\ndescription logic and incorporated into an ontology, which guides controlled\ntext generation of an LLM through fine-tuning. Experimental results demonstrate\nthat our approach provides consistent and explainable proficiency-level\ndefinitions, improving transparency in conversational AI.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u672c\u4f53\u7684\u65b9\u6cd5\u6765\u5f62\u5f0f\u5316\u5b9a\u4e49\u5bf9\u8bdd\u7279\u5f81\uff0c\u901a\u8fc7\u8bed\u8a00\u63cf\u8ff0\u7b26\u5c06\u5b9a\u6027\u6982\u5ff5\u8f6c\u5316\u4e3a\u5b9a\u91cf\u5b9a\u4e49\uff0c\u5e76\u5e94\u7528\u4e8eLLM\u7684\u8bed\u8a00\u719f\u7ec3\u5ea6\u63a7\u5236\uff0c\u63d0\u9ad8\u4e86\u5bf9\u8bddAI\u7684\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u5bf9\u8bdd\u4ee3\u7406\u65f6\u7684\u53ef\u63a7\u6027\u6311\u6218\uff0c\u7279\u522b\u662f\u786e\u4fdd\u53ef\u9884\u6d4b\u548c\u7528\u6237\u4e2a\u6027\u5316\u7684\u54cd\u5e94\uff0c\u9700\u8981\u5c06\u5b9a\u6027\u5bf9\u8bdd\u7279\u5f81\u8f6c\u5316\u4e3a\u53ef\u5f62\u5f0f\u5316\u5b9a\u4e49\u548c\u63a8\u7406\u7684\u5b9a\u91cf\u6982\u5ff5\u3002", "method": "\u4f7f\u7528\u8bed\u8a00\u63cf\u8ff0\u7b26\u96c6\u5408\u63a8\u5bfc\u5b9a\u6027\u6982\u5ff5\u7684\u5b9a\u91cf\u5b9a\u4e49\uff0c\u5728\u63cf\u8ff0\u903b\u8f91\u4e2d\u5f62\u5f0f\u5316\u8fd9\u4e9b\u5b9a\u4e49\u5e76\u6784\u5efa\u672c\u4f53\uff0c\u901a\u8fc7\u5fae\u8c03\u6307\u5bfcLLM\u7684\u53d7\u63a7\u6587\u672c\u751f\u6210\uff0c\u4ee5CEFR\u8bed\u8a00\u719f\u7ec3\u5ea6\u7b49\u7ea7\u4e3a\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u81f4\u4e14\u53ef\u89e3\u91ca\u7684\u719f\u7ec3\u5ea6\u7b49\u7ea7\u5b9a\u4e49\uff0c\u6539\u5584\u4e86\u5bf9\u8bddAI\u7684\u900f\u660e\u5ea6\u3002", "conclusion": "\u57fa\u4e8e\u672c\u4f53\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5f62\u5f0f\u5316\u5bf9\u8bdd\u7279\u5f81\uff0c\u4e3aLLM\u7684\u53d7\u63a7\u751f\u6210\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u6846\u67b6\uff0c\u63d0\u5347\u4e86\u5bf9\u8bdd\u7cfb\u7edf\u7684\u53ef\u63a7\u6027\u548c\u900f\u660e\u5ea6\u3002"}}
{"id": "2509.04979", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.04979", "abs": "https://arxiv.org/abs/2509.04979", "authors": ["Rajesh Tembarai Krishnamachari", "Srividya Rajesh"], "title": "Internet 3.0: Architecture for a Web-of-Agents with it's Algorithm for Ranking Agents", "comment": null, "summary": "AI agents -- powered by reasoning-capable large language models (LLMs) and\nintegrated with tools, data, and web search -- are poised to transform the\ninternet into a \\emph{Web of Agents}: a machine-native ecosystem where\nautonomous agents interact, collaborate, and execute tasks at scale. Realizing\nthis vision requires \\emph{Agent Ranking} -- selecting agents not only by\ndeclared capabilities but by proven, recent performance. Unlike Web~1.0's\nPageRank, a global, transparent network of agent interactions does not exist;\nusage signals are fragmented and private, making ranking infeasible without\ncoordination.\n  We propose \\textbf{DOVIS}, a five-layer operational protocol\n(\\emph{Discovery, Orchestration, Verification, Incentives, Semantics}) that\nenables the collection of minimal, privacy-preserving aggregates of usage and\nperformance across the ecosystem. On this substrate, we implement\n\\textbf{AgentRank-UC}, a dynamic, trust-aware algorithm that combines\n\\emph{usage} (selection frequency) and \\emph{competence} (outcome quality,\ncost, safety, latency) into a unified ranking. We present simulation results\nand theoretical guarantees on convergence, robustness, and Sybil resistance,\ndemonstrating the viability of coordinated protocols and performance-aware\nranking in enabling a scalable, trustworthy Agentic Web.", "AI": {"tldr": "DOVIS\u534f\u8bae\u548cAgentRank-UC\u7b97\u6cd5\u4e3a\u6784\u5efa\u53ef\u4fe1\u7684\u667a\u80fd\u4f53\u7f51\u7edc\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u9690\u79c1\u4fdd\u62a4\u7684\u6027\u80fd\u6570\u636e\u6536\u96c6\u548c\u52a8\u6001\u6392\u540d\u673a\u5236\u5b9e\u73b0\u667a\u80fd\u4f53\u9009\u62e9\u548c\u8bc4\u4f30", "motivation": "\u968f\u7740AI\u667a\u80fd\u4f53\u5728\u4e92\u8054\u7f51\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u9700\u8981\u5efa\u7acb\u6709\u6548\u7684\u667a\u80fd\u4f53\u6392\u540d\u7cfb\u7edf\u6765\u9009\u62e9\u6027\u80fd\u4f18\u79c0\u3001\u53ef\u4fe1\u8d56\u7684\u667a\u80fd\u4f53\uff0c\u4f46\u5f53\u524d\u7f3a\u4e4f\u7edf\u4e00\u7684\u6027\u80fd\u8bc4\u4f30\u673a\u5236\u548c\u9690\u79c1\u4fdd\u62a4\u7684\u6570\u636e\u6536\u96c6\u65b9\u6cd5", "method": "\u63d0\u51faDOVIS\u4e94\u5c42\u64cd\u4f5c\u534f\u8bae\uff08\u53d1\u73b0\u3001\u7f16\u6392\u3001\u9a8c\u8bc1\u3001\u6fc0\u52b1\u3001\u8bed\u4e49\uff09\u6765\u6536\u96c6\u9690\u79c1\u4fdd\u62a4\u7684\u6027\u80fd\u6570\u636e\uff0c\u5e76\u5f00\u53d1AgentRank-UC\u7b97\u6cd5\u7ed3\u5408\u4f7f\u7528\u9891\u7387\u548c\u80fd\u529b\u6307\u6807\u8fdb\u884c\u52a8\u6001\u6392\u540d", "result": "\u901a\u8fc7\u4eff\u771f\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u7684\u6536\u655b\u6027\u3001\u9c81\u68d2\u6027\u548c\u6297Sybil\u653b\u51fb\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u534f\u8c03\u534f\u8bae\u548c\u6027\u80fd\u611f\u77e5\u6392\u540d\u7684\u53ef\u884c\u6027", "conclusion": "DOVIS\u548cAgentRank-UC\u4e3a\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u53ef\u4fe1\u8d56\u7684\u667a\u80fd\u4f53\u7f51\u7edc\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u65b9\u6848\uff0c\u80fd\u591f\u652f\u6301\u5927\u89c4\u6a21\u667a\u80fd\u4f53\u751f\u6001\u7cfb\u7edf\u7684\u5065\u5eb7\u53d1\u5c55"}}
{"id": "2509.05007", "categories": ["cs.AI", "cs.CL", "I.2.7"], "pdf": "https://arxiv.org/pdf/2509.05007", "abs": "https://arxiv.org/abs/2509.05007", "authors": ["Jie Chen", "Jinhao Jiang", "Yingqian Min", "Zican Dong", "Shijie Wang", "Wayne Xin Zhao", "Ji-Rong Wen"], "title": "Sticker-TTS: Learn to Utilize Historical Experience with a Sticker-driven Test-Time Scaling Framework", "comment": "11 pages, 1 figures, 5 tables", "summary": "Large reasoning models (LRMs) have exhibited strong performance on complex\nreasoning tasks, with further gains achievable through increased computational\nbudgets at inference. However, current test-time scaling methods predominantly\nrely on redundant sampling, ignoring the historical experience utilization,\nthereby limiting computational efficiency. To overcome this limitation, we\npropose Sticker-TTS, a novel test-time scaling framework that coordinates three\ncollaborative LRMs to iteratively explore and refine solutions guided by\nhistorical attempts. At the core of our framework are distilled key\nconditions-termed stickers-which drive the extraction, refinement, and reuse of\ncritical information across multiple rounds of reasoning. To further enhance\nthe efficiency and performance of our framework, we introduce a two-stage\noptimization strategy that combines imitation learning with self-improvement,\nenabling progressive refinement. Extensive evaluations on three challenging\nmathematical reasoning benchmarks, including AIME-24, AIME-25, and OlymMATH,\ndemonstrate that Sticker-TTS consistently surpasses strong baselines, including\nself-consistency and advanced reinforcement learning approaches, under\ncomparable inference budgets. These results highlight the effectiveness of\nsticker-guided historical experience utilization. Our code and data are\navailable at https://github.com/RUCAIBox/Sticker-TTS.", "AI": {"tldr": "Sticker-TTS\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u6d4b\u8bd5\u65f6\u6269\u5c55\u6846\u67b6\uff0c\u901a\u8fc7\u534f\u8c03\u4e09\u4e2a\u534f\u4f5c\u7684\u5927\u578b\u63a8\u7406\u6a21\u578b\uff0c\u5229\u7528\u5386\u53f2\u7ecf\u9a8c\u8fdb\u884c\u8fed\u4ee3\u63a2\u7d22\u548c\u4f18\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u6d4b\u8bd5\u65f6\u6269\u5c55\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u5197\u4f59\u91c7\u6837\uff0c\u5ffd\u7565\u4e86\u5386\u53f2\u7ecf\u9a8c\u7684\u5229\u7528\uff0c\u9650\u5236\u4e86\u8ba1\u7b97\u6548\u7387\u3002\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u5229\u7528\u5386\u53f2\u63a8\u7406\u7ecf\u9a8c\u3002", "method": "\u63d0\u51faSticker-TTS\u6846\u67b6\uff0c\u534f\u8c03\u4e09\u4e2a\u534f\u4f5c\u7684\u5927\u578b\u63a8\u7406\u6a21\u578b\uff0c\u901a\u8fc7\u63d0\u53d6\u3001\u7cbe\u70bc\u548c\u91cd\u7528\u5173\u952e\u4fe1\u606f\uff08\u79f0\u4e3asticker\uff09\u8fdb\u884c\u591a\u8f6e\u63a8\u7406\u3002\u91c7\u7528\u4e24\u9636\u6bb5\u4f18\u5316\u7b56\u7565\uff0c\u7ed3\u5408\u6a21\u4eff\u5b66\u4e60\u548c\u81ea\u6211\u6539\u8fdb\u3002", "result": "\u5728\u4e09\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\uff08AIME-24\u3001AIME-25\u3001OlymMATH\uff09\u4e0a\uff0cSticker-TTS\u5728\u53ef\u6bd4\u63a8\u7406\u9884\u7b97\u4e0b\u6301\u7eed\u8d85\u8d8a\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5305\u62ec\u81ea\u4e00\u81f4\u6027\u548c\u5148\u8fdb\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "Sticker-TTS\u901a\u8fc7sticker\u5f15\u5bfc\u7684\u5386\u53f2\u7ecf\u9a8c\u5229\u7528\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u7406\u6548\u7387\u548c\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u5386\u53f2\u7ecf\u9a8c\u5728\u6d4b\u8bd5\u65f6\u6269\u5c55\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2509.05072", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.05072", "abs": "https://arxiv.org/abs/2509.05072", "authors": ["Nir Sweed", "Hanit Hakim", "Ben Wolfson", "Hila Lifshitz", "Dafna Shahaf"], "title": "Finding your MUSE: Mining Unexpected Solutions Engine", "comment": null, "summary": "Innovators often exhibit cognitive fixation on existing solutions or nascent\nideas, hindering the exploration of novel alternatives. This paper introduces a\nmethodology for constructing Functional Concept Graphs (FCGs), interconnected\nrepresentations of functional elements that support abstraction, problem\nreframing, and analogical inspiration. Our approach yields large-scale,\nhigh-quality FCGs with explicit abstraction relations, overcoming limitations\nof prior work. We further present MUSE, an algorithm leveraging FCGs to\ngenerate creative inspirations for a given problem. We demonstrate our method\nby computing an FCG on 500K patents, which we release for further research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u529f\u80fd\u6027\u6982\u5ff5\u56fe(FCG)\u65b9\u6cd5\u6765\u89e3\u51b3\u521b\u65b0\u8005\u8ba4\u77e5\u56fa\u7740\u95ee\u9898\uff0c\u901a\u8fc7\u6784\u5efa\u5927\u89c4\u6a21\u529f\u80fd\u5143\u7d20\u4e92\u8054\u8868\u793a\u6765\u652f\u6301\u62bd\u8c61\u3001\u95ee\u9898\u91cd\u6784\u548c\u7c7b\u6bd4\u542f\u53d1\uff0c\u5e76\u5f00\u53d1\u4e86MUSE\u7b97\u6cd5\u6765\u751f\u6210\u521b\u610f\u7075\u611f\u3002", "motivation": "\u521b\u65b0\u8005\u5f80\u5f80\u5bf9\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u6216\u521d\u6b65\u60f3\u6cd5\u5b58\u5728\u8ba4\u77e5\u56fa\u7740\uff0c\u8fd9\u963b\u788d\u4e86\u5bf9\u65b0\u9896\u66ff\u4ee3\u65b9\u6848\u7684\u63a2\u7d22\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u6253\u7834\u8fd9\u79cd\u601d\u7ef4\u5b9a\u5f0f\u3002", "method": "\u6784\u5efa\u529f\u80fd\u6027\u6982\u5ff5\u56fe(FCG)\uff0c\u5efa\u7acb\u529f\u80fd\u5143\u7d20\u7684\u4e92\u8054\u8868\u793a\uff0c\u652f\u6301\u62bd\u8c61\u3001\u95ee\u9898\u91cd\u6784\u548c\u7c7b\u6bd4\u542f\u53d1\uff1b\u5f00\u53d1MUSE\u7b97\u6cd5\u5229\u7528FCG\u4e3a\u7ed9\u5b9a\u95ee\u9898\u751f\u6210\u521b\u610f\u7075\u611f\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u5305\u542b50\u4e07\u9879\u4e13\u5229\u7684\u5927\u89c4\u6a21\u9ad8\u8d28\u91cfFCG\uff0c\u5177\u6709\u660e\u786e\u7684\u62bd\u8c61\u5173\u7cfb\uff0c\u514b\u670d\u4e86\u5148\u524d\u5de5\u4f5c\u7684\u5c40\u9650\u6027\u3002", "conclusion": "FCG\u65b9\u6cd5\u80fd\u6709\u6548\u652f\u6301\u521b\u65b0\u8fc7\u7a0b\u4e2d\u7684\u62bd\u8c61\u601d\u7ef4\u548c\u7c7b\u6bd4\u542f\u53d1\uff0c\u53d1\u5e03\u7684\u4e13\u5229FCG\u6570\u636e\u96c6\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9d\u8d35\u8d44\u6e90\u3002"}}
{"id": "2509.05091", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.05091", "abs": "https://arxiv.org/abs/2509.05091", "authors": ["Matteo Bortoletto", "Yichao Zhou", "Lance Ying", "Tianmin Shu", "Andreas Bulling"], "title": "ProToM: Promoting Prosocial Behaviour via Theory of Mind-Informed Feedback", "comment": "Website at https://www.matteobortoletto.org/protom/", "summary": "While humans are inherently social creatures, the challenge of identifying\nwhen and how to assist and collaborate with others - particularly when pursuing\nindependent goals - can hinder cooperation. To address this challenge, we aim\nto develop an AI system that provides useful feedback to promote prosocial\nbehaviour - actions that benefit others, even when not directly aligned with\none's own goals. We introduce ProToM, a Theory of Mind-informed facilitator\nthat promotes prosocial actions in multi-agent systems by providing targeted,\ncontext-sensitive feedback to individual agents. ProToM first infers agents'\ngoals using Bayesian inverse planning, then selects feedback to communicate by\nmaximising expected utility, conditioned on the inferred goal distribution. We\nevaluate our approach against baselines in two multi-agent environments: Doors,\nKeys, and Gems, as well as Overcooked. Our results suggest that\nstate-of-the-art large language and reasoning models fall short of\ncommunicating feedback that is both contextually grounded and well-timed -\nleading to higher communication overhead and task speedup. In contrast, ProToM\nprovides targeted and helpful feedback, achieving a higher success rate,\nshorter task completion times, and is consistently preferred by human users.", "AI": {"tldr": "ProToM\u662f\u4e00\u4e2a\u57fa\u4e8e\u5fc3\u7406\u7406\u8bba\u7684AI\u7cfb\u7edf\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u9006\u89c4\u5212\u63a8\u65ad\u667a\u80fd\u4f53\u76ee\u6807\uff0c\u63d0\u4f9b\u9488\u5bf9\u6027\u53cd\u9988\u6765\u4fc3\u8fdb\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u4eb2\u793e\u4f1a\u884c\u4e3a\uff0c\u5728\u591a\u4e2a\u73af\u5883\u4e2d\u4f18\u4e8e\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u667a\u80fd\u4f53\u5728\u8ffd\u6c42\u72ec\u7acb\u76ee\u6807\u65f6\u96be\u4ee5\u786e\u5b9a\u4f55\u65f6\u4ee5\u53ca\u5982\u4f55\u534f\u52a9\u4ed6\u4eba\u3001\u4fc3\u8fdb\u5408\u4f5c\u7684\u95ee\u9898\uff0c\u65e8\u5728\u5f00\u53d1\u80fd\u591f\u63d0\u4f9b\u6709\u7528\u53cd\u9988\u6765\u4fc3\u8fdb\u4eb2\u793e\u4f1a\u884c\u4e3a\u7684AI\u7cfb\u7edf\u3002", "method": "\u63d0\u51faProToM\u7cfb\u7edf\uff1a1\uff09\u4f7f\u7528\u8d1d\u53f6\u65af\u9006\u89c4\u5212\u63a8\u65ad\u667a\u80fd\u4f53\u76ee\u6807\uff1b2\uff09\u57fa\u4e8e\u63a8\u65ad\u7684\u76ee\u6807\u5206\u5e03\uff0c\u901a\u8fc7\u6700\u5927\u5316\u671f\u671b\u6548\u7528\u6765\u9009\u62e9\u4e0a\u4e0b\u6587\u654f\u611f\u7684\u53cd\u9988\u4fe1\u606f\u3002", "result": "\u5728Doors\u3001Keys\u548cGems\u4ee5\u53caOvercooked\u4e24\u4e2a\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u6d4b\u8bd5\uff0cProToM\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\uff1a\u83b7\u5f97\u66f4\u9ad8\u7684\u6210\u529f\u7387\u3001\u66f4\u77ed\u7684\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\uff0c\u4e14\u66f4\u53d7\u4eba\u7c7b\u7528\u6237\u9752\u7750\u3002\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63d0\u4f9b\u4e0a\u4e0b\u6587\u63a5\u5730\u4e14\u65f6\u673a\u6070\u5f53\u7684\u53cd\u9988\u65b9\u9762\u8868\u73b0\u4e0d\u8db3\u3002", "conclusion": "ProToM\u80fd\u591f\u63d0\u4f9b\u6709\u9488\u5bf9\u6027\u548c\u6709\u7528\u7684\u53cd\u9988\uff0c\u6709\u6548\u4fc3\u8fdb\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u4eb2\u793e\u4f1a\u884c\u4e3a\uff0c\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u548c\u63a8\u7406\u6a21\u578b\u3002"}}
{"id": "2509.05139", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05139", "abs": "https://arxiv.org/abs/2509.05139", "authors": ["Jaime Osvaldo Salas", "Paolo Pareti", "Semih Yumu\u015fak", "Soulmaz Gheisari", "Luis-Daniel Ib\u00e1\u00f1ez", "George Konstantinidis"], "title": "Evaluation and Comparison Semantics for ODRL", "comment": "Accepted as a full paper at the 14th International Joint Conference\n  on Knowledge Graphs (IJCKG 2025). This is the submitted manuscript, the\n  accepted manuscript will be published by Springer Nature", "summary": "We consider the problem of evaluating, and comparing computational policies\nin the Open Digital Rights Language (ODRL), which has become the de facto\nstandard for governing the access and usage of digital resources. Although\npreliminary progress has been made on the formal specification of the\nlanguage's features, a comprehensive formal semantics of ODRL is still missing.\nIn this paper, we provide a simple and intuitive formal semantics for ODRL that\nis based on query answering. Our semantics refines previous formalisations, and\nis aligned with the latest published specification of the language (2.2).\nBuilding on our evaluation semantics, and motivated by data sharing scenarios,\nwe also define and study the problem of comparing two policies, detecting\nequivalent, more restrictive or more permissive policies.", "AI": {"tldr": "\u4e3aODRL\u8bed\u8a00\u63d0\u4f9b\u57fa\u4e8e\u67e5\u8be2\u7b54\u590d\u7684\u6b63\u5f0f\u8bed\u4e49\uff0c\u5e76\u7814\u7a76\u653f\u7b56\u6bd4\u8f83\u95ee\u9898", "motivation": "ODRL\u4f5c\u4e3a\u6570\u5b57\u8d44\u6e90\u8bbf\u95ee\u548c\u4f7f\u7528\u7ba1\u7406\u7684\u5de5\u4e1a\u6807\u51c6\uff0c\u867d\u6709\u4e9b\u8fdb\u5c55\uff0c\u4f46\u4ecd\u7f3a\u4e4f\u5168\u9762\u7684\u6b63\u5f0f\u8bed\u4e49\u5b9a\u4e49", "method": "\u63d0\u51fa\u4e00\u79cd\u7b80\u5355\u76f4\u89c2\u7684\u57fa\u4e8e\u67e5\u8be2\u7b54\u590d\u7684\u6b63\u5f0f\u8bed\u4e49\uff0c\u5bf9\u6bd4\u4e4b\u524d\u7684\u5f62\u5f0f\u5316\u65b9\u6cd5\u8fdb\u884c\u4e86\u7cbe\u70bc", "result": "\u8bed\u4e49\u4e0eODRL 2.2\u7248\u672c\u89c4\u8303\u4fdd\u6301\u4e00\u81f4\uff0c\u5e76\u57fa\u4e8e\u6b64\u5b9a\u4e49\u4e86\u653f\u7b56\u6bd4\u8f83\u95ee\u9898", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aODRL\u653f\u7b56\u7684\u8bc4\u4f30\u548c\u6bd4\u8f83\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u7406\u8bba\u57fa\u7840\uff0c\u7279\u522b\u9002\u7528\u4e8e\u6570\u636e\u5171\u4eab\u573a\u666f"}}
{"id": "2509.05263", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.05263", "abs": "https://arxiv.org/abs/2509.05263", "authors": ["Yinglin Duan", "Zhengxia Zou", "Tongwei Gu", "Wei Jia", "Zhan Zhao", "Luyi Xu", "Xinzhu Liu", "Hao Jiang", "Kang Chen", "Shuang Qiu"], "title": "LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation", "comment": null, "summary": "Recent research has been increasingly focusing on developing 3D world models\nthat simulate complex real-world scenarios. World models have found broad\napplications across various domains, including embodied AI, autonomous driving,\nentertainment, etc. A more realistic simulation with accurate physics will\neffectively narrow the sim-to-real gap and allow us to gather rich information\nabout the real world conveniently. While traditional manual modeling has\nenabled the creation of virtual 3D scenes, modern approaches have leveraged\nadvanced machine learning algorithms for 3D world generation, with most recent\nadvances focusing on generative methods that can create virtual worlds based on\nuser instructions. This work explores such a research direction by proposing\nLatticeWorld, a simple yet effective 3D world generation framework that\nstreamlines the industrial production pipeline of 3D environments. LatticeWorld\nleverages lightweight LLMs (LLaMA-2-7B) alongside the industry-grade rendering\nengine (e.g., Unreal Engine 5) to generate a dynamic environment. Our proposed\nframework accepts textual descriptions and visual instructions as multimodal\ninputs and creates large-scale 3D interactive worlds with dynamic agents,\nfeaturing competitive multi-agent interaction, high-fidelity physics\nsimulation, and real-time rendering. We conduct comprehensive experiments to\nevaluate LatticeWorld, showing that it achieves superior accuracy in scene\nlayout generation and visual fidelity. Moreover, LatticeWorld achieves over a\n$90\\times$ increase in industrial production efficiency while maintaining high\ncreative quality compared with traditional manual production methods. Our demo\nvideo is available at https://youtu.be/8VWZXpERR18", "AI": {"tldr": "LatticeWorld\u662f\u4e00\u4e2a\u57fa\u4e8e\u8f7b\u91cf\u7ea7LLM\u548c\u6e38\u620f\u5f15\u64ce\u76843D\u4e16\u754c\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u8f93\u5165\u751f\u6210\u52a8\u6001\u4ea4\u4e92\u5f0f\u865a\u62df\u73af\u5883\uff0c\u5927\u5e45\u63d0\u5347\u5de5\u4e1a\u751f\u4ea7\u6548\u7387", "motivation": "\u4f20\u7edf\u624b\u52a8\u5efa\u6a21\u521b\u5efa3D\u573a\u666f\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u57fa\u4e8e\u7528\u6237\u6307\u4ee4\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf3D\u865a\u62df\u4e16\u754c\u7684\u751f\u6210\u65b9\u6cd5\uff0c\u4ee5\u7f29\u5c0f\u4eff\u771f\u4e0e\u73b0\u5b9e\u5dee\u8ddd", "method": "\u7ed3\u5408\u8f7b\u91cf\u7ea7LLaMA-2-7B\u6a21\u578b\u548c\u5de5\u4e1a\u7ea7\u6e32\u67d3\u5f15\u64ce\uff08\u5982Unreal Engine 5\uff09\uff0c\u63a5\u53d7\u6587\u672c\u63cf\u8ff0\u548c\u89c6\u89c9\u6307\u4ee4\u4f5c\u4e3a\u591a\u6a21\u6001\u8f93\u5165\uff0c\u751f\u6210\u5305\u542b\u52a8\u6001\u4ee3\u7406\u7684\u5927\u89c4\u6a213D\u4ea4\u4e92\u4e16\u754c", "result": "\u5728\u573a\u666f\u5e03\u5c40\u751f\u6210\u548c\u89c6\u89c9\u4fdd\u771f\u5ea6\u65b9\u9762\u8fbe\u5230\u4f18\u5f02\u7cbe\u5ea6\uff0c\u76f8\u6bd4\u4f20\u7edf\u624b\u52a8\u751f\u4ea7\u65b9\u5f0f\u5b9e\u73b090\u500d\u4ee5\u4e0a\u7684\u5de5\u4e1a\u751f\u4ea7\u6548\u7387\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u521b\u610f\u8d28\u91cf", "conclusion": "LatticeWorld\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u6709\u6548\u76843D\u4e16\u754c\u751f\u6210\u6846\u67b6\uff0c\u80fd\u591f\u663e\u8457\u63d0\u53473D\u73af\u5883\u5de5\u4e1a\u751f\u4ea7\u7ebf\u6548\u7387\uff0c\u4e3a\u6784\u5efa\u66f4\u771f\u5b9e\u7684\u865a\u62df\u4e16\u754c\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848"}}
