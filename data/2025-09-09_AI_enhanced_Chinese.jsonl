{"id": "2509.05372", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.05372", "abs": "https://arxiv.org/abs/2509.05372", "authors": ["Piotr Przymus", "Andreas Happe", "J\u00fcrgen Cito"], "title": "Adversarial Bug Reports as a Security Risk in Language Model-Based Automated Program Repair", "comment": null, "summary": "Large Language Model (LLM) - based Automated Program Repair (APR) systems are\nincreasingly integrated into modern software development workflows, offering\nautomated patches in response to natural language bug reports. However, this\nreliance on untrusted user input introduces a novel and underexplored attack\nsurface. In this paper, we investigate the security risks posed by adversarial\nbug reports -- realistic-looking issue submissions crafted to mislead APR\nsystems into producing insecure or harmful code changes. We develop a\ncomprehensive threat model and conduct an empirical study to evaluate the\nvulnerability of state-of-the-art APR systems to such attacks. Our\ndemonstration comprises 51 adversarial bug reports generated across a spectrum\nof strategies, from manual curation to fully automated pipelines. We test these\nagainst leading APR model and assess both pre-repair defenses (e.g., LlamaGuard\nvariants, PromptGuard variants, Granite-Guardian, and custom LLM filters) and\npost-repair detectors (GitHub Copilot, CodeQL). Our findings show that current\ndefenses are insufficient: 90\\% of crafted bug reports triggered\nattacker-aligned patches. The best pre-repair filter blocked only 47\\%, while\npost-repair analysis-often requiring human oversight-was effective in just 58\\%\nof cases. To support scalable security testing, we introduce a prototype\nframework for automating the generation of adversarial bug reports. Our\nanalysis exposes a structural asymmetry: generating adversarial inputs is\ninexpensive, while detecting or mitigating them remains costly and error-prone.\nWe conclude with practical recommendations for improving the robustness of APR\nsystems against adversarial misuse and highlight directions for future work on\ntrustworthy automated repair.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLM\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u7cfb\u7edf\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\uff0c\u653b\u51fb\u8005\u53ef\u901a\u8fc7\u7cbe\u5fc3\u6784\u9020\u7684bug\u62a5\u544a\u8bf1\u5bfc\u7cfb\u7edf\u751f\u6210\u4e0d\u5b89\u5168\u7684\u4ee3\u7801\u8865\u4e01\uff0c\u73b0\u6709\u9632\u5fa1\u63aa\u65bd\u6548\u679c\u6709\u9650\u3002", "motivation": "\u968f\u7740\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u7cfb\u7edf\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f9d\u8d56\u4e0d\u53ef\u4fe1\u7528\u6237\u8f93\u5165\u5e26\u6765\u4e86\u65b0\u7684\u653b\u51fb\u9762\uff0c\u9700\u8981\u7814\u7a76\u5bf9\u6297\u6027bug\u62a5\u544a\u5bf9\u7cfb\u7edf\u5b89\u5168\u6027\u7684\u5a01\u80c1\u3002", "method": "\u5efa\u7acb\u5168\u9762\u7684\u5a01\u80c1\u6a21\u578b\uff0c\u901a\u8fc7\u624b\u5de5\u5236\u4f5c\u548c\u81ea\u52a8\u5316\u6d41\u6c34\u7ebf\u751f\u621051\u4e2a\u5bf9\u6297\u6027bug\u62a5\u544a\uff0c\u6d4b\u8bd5\u4e3b\u6d41APR\u7cfb\u7edf\u7684\u8106\u5f31\u6027\uff0c\u8bc4\u4f30\u9884\u5904\u7406\u9632\u5fa1\u548c\u540e\u5904\u7406\u68c0\u6d4b\u673a\u5236\u7684\u6548\u679c\u3002", "result": "\u5f53\u524d\u9632\u5fa1\u63aa\u65bd\u4e0d\u8db3\uff1a90%\u7684\u6784\u9020bug\u62a5\u544a\u6210\u529f\u89e6\u53d1\u653b\u51fb\u8005\u671f\u671b\u7684\u8865\u4e01\uff0c\u6700\u4f73\u9884\u5904\u7406\u8fc7\u6ee4\u5668\u4ec5\u963b\u632147%\uff0c\u540e\u5904\u7406\u5206\u6790\u572858%\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u4f46\u9700\u8981\u4eba\u5de5\u76d1\u7763\u3002", "conclusion": "\u751f\u6210\u5bf9\u6297\u6027\u8f93\u5165\u6210\u672c\u4f4e\u5ec9\u800c\u68c0\u6d4b\u6210\u672c\u9ad8\u6602\uff0c\u5b58\u5728\u7ed3\u6784\u6027\u4e0d\u5bf9\u79f0\uff0c\u9700\u8981\u6539\u8fdbAPR\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u5e76\u63a8\u52a8\u53ef\u4fe1\u81ea\u52a8\u4fee\u590d\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2509.05394", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05394", "abs": "https://arxiv.org/abs/2509.05394", "authors": ["Zoltan Toth-Czifra"], "title": "Reverse Browser: Vector-Image-to-Code Generator", "comment": "Submitted to AIWare 2025 ArXiv Track", "summary": "Automating the conversion of user interface design into code (image-to-code\nor image-to-UI) is an active area of software engineering research. However,\nthe state-of-the-art solutions do not achieve high fidelity to the original\ndesign, as evidenced by benchmarks. In this work, I approach the problem\ndifferently: I use vector images instead of bitmaps as model input. I create\nseveral large datasets for training machine learning models. I evaluate the\navailable array of Image Quality Assessment (IQA) algorithms and introduce a\nnew, multi-scale metric. I then train a large open-weights model and discuss\nits limitations.", "AI": {"tldr": "\u4f7f\u7528\u77e2\u91cf\u56fe\u50cf\u800c\u975e\u4f4d\u56fe\u4f5c\u4e3a\u8f93\u5165\uff0c\u901a\u8fc7\u521b\u5efa\u5927\u89c4\u6a21\u6570\u636e\u96c6\u548c\u65b0\u7684\u591a\u5c3a\u5ea6\u8d28\u91cf\u8bc4\u4f30\u6307\u6807\uff0c\u8bad\u7ec3\u4e86\u4e00\u4e2a\u5927\u578b\u5f00\u653e\u6743\u91cd\u6a21\u578b\u6765\u89e3\u51b3\u56fe\u50cf\u5230\u4ee3\u7801\u8f6c\u6362\u7684\u4fdd\u771f\u5ea6\u95ee\u9898", "motivation": "\u5f53\u524d\u6700\u5148\u8fdb\u7684\u56fe\u50cf\u5230\u4ee3\u7801\u8f6c\u6362\u89e3\u51b3\u65b9\u6848\u5728\u4fdd\u771f\u5ea6\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u65e0\u6cd5\u51c6\u786e\u8fd8\u539f\u539f\u59cb\u8bbe\u8ba1", "method": "\u91c7\u7528\u77e2\u91cf\u56fe\u50cf\u4f5c\u4e3a\u6a21\u578b\u8f93\u5165\uff0c\u521b\u5efa\u591a\u4e2a\u5927\u578b\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u73b0\u6709\u56fe\u50cf\u8d28\u91cf\u8bc4\u4f30\u7b97\u6cd5\u5e76\u5f15\u5165\u65b0\u7684\u591a\u5c3a\u5ea6\u6307\u6807\uff0c\u8bad\u7ec3\u5927\u578b\u5f00\u653e\u6743\u91cd\u6a21\u578b", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u65b0\u7684\u56fe\u50cf\u5230\u4ee3\u7801\u8f6c\u6362\u65b9\u6cd5\uff0c\u4f46\u6a21\u578b\u4ecd\u5b58\u5728\u4e00\u4e9b\u5c40\u9650\u6027", "conclusion": "\u4f7f\u7528\u77e2\u91cf\u56fe\u50cf\u548c\u65b0\u7684\u8d28\u91cf\u8bc4\u4f30\u6307\u6807\u53ef\u4ee5\u6539\u5584\u56fe\u50cf\u5230\u4ee3\u7801\u8f6c\u6362\u7684\u4fdd\u771f\u5ea6\u95ee\u9898\uff0c\u4f46\u8be5\u65b9\u6cd5\u4ecd\u6709\u5f85\u8fdb\u4e00\u6b65\u5b8c\u5584"}}
{"id": "2509.05540", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05540", "abs": "https://arxiv.org/abs/2509.05540", "authors": ["Thiago Barradas", "Aline Paes", "V\u00e2nia de Oliveira Neves"], "title": "Combining TSL and LLM to Automate REST API Testing: A Comparative Study", "comment": "10 pages, article computer science, software engineering, software\n  testing, ia, llm", "summary": "The effective execution of tests for REST APIs remains a considerable\nchallenge for development teams, driven by the inherent complexity of\ndistributed systems, the multitude of possible scenarios, and the limited time\navailable for test design. Exhaustive testing of all input combinations is\nimpractical, often resulting in undetected failures, high manual effort, and\nlimited test coverage. To address these issues, we introduce RestTSLLM, an\napproach that uses Test Specification Language (TSL) in conjunction with Large\nLanguage Models (LLMs) to automate the generation of test cases for REST APIs.\nThe approach targets two core challenges: the creation of test scenarios and\nthe definition of appropriate input data. The proposed solution integrates\nprompt engineering techniques with an automated pipeline to evaluate various\nLLMs on their ability to generate tests from OpenAPI specifications. The\nevaluation focused on metrics such as success rate, test coverage, and mutation\nscore, enabling a systematic comparison of model performance. The results\nindicate that the best-performing LLMs - Claude 3.5 Sonnet (Anthropic),\nDeepseek R1 (Deepseek), Qwen 2.5 32b (Alibaba), and Sabia 3 (Maritaca) -\nconsistently produced robust and contextually coherent REST API tests. Among\nthem, Claude 3.5 Sonnet outperformed all other models across every metric,\nemerging in this study as the most suitable model for this task. These findings\nhighlight the potential of LLMs to automate the generation of tests based on\nAPI specifications.", "AI": {"tldr": "RestTSLLM\u4f7f\u7528\u6d4b\u8bd5\u89c4\u8303\u8bed\u8a00\u548c\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u751f\u6210REST API\u6d4b\u8bd5\u7528\u4f8b\uff0c\u89e3\u51b3\u4e86\u6d4b\u8bd5\u573a\u666f\u521b\u5efa\u548c\u8f93\u5165\u6570\u636e\u5b9a\u4e49\u7684\u6838\u5fc3\u6311\u6218\u3002\u8bc4\u4f30\u663e\u793aClaude 3.5 Sonnet\u5728\u5404\u9879\u6307\u6807\u4e0a\u8868\u73b0\u6700\u4f73\u3002", "motivation": "REST API\u6d4b\u8bd5\u6267\u884c\u9762\u4e34\u5206\u5e03\u5f0f\u7cfb\u7edf\u590d\u6742\u6027\u3001\u591a\u573a\u666f\u53ef\u80fd\u6027\u548c\u6709\u9650\u6d4b\u8bd5\u8bbe\u8ba1\u65f6\u95f4\u7684\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u65e0\u6cd5\u7a77\u5c3d\u6240\u6709\u8f93\u5165\u7ec4\u5408\uff0c\u5bfc\u81f4\u672a\u68c0\u6d4b\u6545\u969c\u3001\u9ad8\u4eba\u5de5\u6210\u672c\u548c\u6709\u9650\u6d4b\u8bd5\u8986\u76d6\u7387\u3002", "method": "\u7ed3\u5408\u6d4b\u8bd5\u89c4\u8303\u8bed\u8a00\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u6280\u672f\u548c\u81ea\u52a8\u5316\u6d41\u6c34\u7ebf\uff0c\u4eceOpenAPI\u89c4\u8303\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\uff0c\u8bc4\u4f30\u4e0d\u540cLLM\u5728\u6210\u529f\u7387\u3001\u6d4b\u8bd5\u8986\u76d6\u7387\u548c\u53d8\u5f02\u5206\u6570\u7b49\u6307\u6807\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u8868\u73b0\u6700\u4f73\u7684LLM\u5305\u62ecClaude 3.5 Sonnet\u3001Deepseek R1\u3001Qwen 2.5 32b\u548cSabia 3\uff0c\u5176\u4e2dClaude 3.5 Sonnet\u5728\u6240\u6709\u6307\u6807\u4e0a\u90fd\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\u3002", "conclusion": "LLM\u5728\u57fa\u4e8eAPI\u89c4\u8303\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0cClaude 3.5 Sonnet\u88ab\u8bc1\u660e\u662f\u6700\u9002\u5408\u6b64\u4efb\u52a1\u7684\u6a21\u578b\u3002"}}
{"id": "2509.05585", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05585", "abs": "https://arxiv.org/abs/2509.05585", "authors": ["Zhiyuan Zou", "Bangchao Wang", "Peng Liang", "Tingting Bi", "Huan Jin"], "title": "Natural Language-Programming Language Software Traceability Link Recovery Needs More than Textual Similarity", "comment": "45 pages, 5 images, 11 tables, Manuscript submitted to a Journal\n  (2025)", "summary": "In the field of software traceability link recovery (TLR), textual similarity\nhas long been regarded as the core criterion. However, in tasks involving\nnatural language and programming language (NL-PL) artifacts, relying solely on\ntextual similarity is limited by their semantic gap. To this end, we conducted\na large-scale empirical evaluation across various types of TLR tasks, revealing\nthe limitations of textual similarity in NL-PL scenarios. To address these\nlimitations, we propose an approach that incorporates multiple domain-specific\nauxiliary strategies, identified through empirical analysis, into two models:\nthe Heterogeneous Graph Transformer (HGT) via edge types and the prompt-based\nGemini 2.5 Pro via additional input information. We then evaluated our approach\nusing the widely studied requirements-to-code TLR task, a representative case\nof NL-PL TLR. Experimental results show that both the multi-strategy HGT and\nGemini 2.5 Pro models outperformed their original counterparts without strategy\nintegration. Furthermore, compared to the current state-of-the-art method\nHGNNLink, the multi-strategy HGT and Gemini 2.5 Pro models achieved average\nF1-score improvements of 3.68% and 8.84%, respectively, across twelve\nopen-source projects, demonstrating the effectiveness of multi-strategy\nintegration in enhancing overall model performance for the requirements-code\nTLR task.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u7b56\u7565\u96c6\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728HGT\u548cGemini 2.5 Pro\u6a21\u578b\u4e2d\u878d\u5165\u9886\u57df\u7279\u5b9a\u7684\u8f85\u52a9\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u7136\u8bed\u8a00\u4e0e\u7f16\u7a0b\u8bed\u8a00(NL-PL)\u8f6f\u4ef6\u8ffd\u8e2a\u94fe\u63a5\u6062\u590d\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u6587\u672c\u76f8\u4f3c\u6027\u7684\u8ffd\u8e2a\u94fe\u63a5\u6062\u590d\u65b9\u6cd5\u5728NL-PL\u573a\u666f\u4e2d\u5b58\u5728\u8bed\u4e49\u9e3f\u6c9f\u95ee\u9898\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u81ea\u7136\u8bed\u8a00\u4e0e\u7f16\u7a0b\u8bed\u8a00\u4e4b\u95f4\u7684\u8bed\u4e49\u5dee\u5f02\u3002", "method": "\u901a\u8fc7\u5927\u89c4\u6a21\u5b9e\u8bc1\u5206\u6790\u8bc6\u522b\u591a\u79cd\u9886\u57df\u7279\u5b9a\u8f85\u52a9\u7b56\u7565\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u5230\u4e24\u79cd\u6a21\u578b\u4e2d\uff1a\u901a\u8fc7\u8fb9\u7c7b\u578b\u96c6\u6210\u5230\u5f02\u6784\u56fe\u53d8\u6362\u5668(HGT)\uff0c\u4ee5\u53ca\u901a\u8fc7\u989d\u5916\u8f93\u5165\u4fe1\u606f\u96c6\u6210\u5230\u57fa\u4e8e\u63d0\u793a\u7684Gemini 2.5 Pro\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u591a\u7b56\u7565HGT\u548cGemini 2.5 Pro\u6a21\u578b\u5747\u4f18\u4e8e\u539f\u59cb\u7248\u672c\uff0c\u76f8\u6bd4\u5f53\u524d\u6700\u5148\u8fdb\u7684HGNNLink\u65b9\u6cd5\uff0c\u572812\u4e2a\u5f00\u6e90\u9879\u76ee\u4e2d\u5206\u522b\u5b9e\u73b0\u4e863.68%\u548c8.84%\u7684\u5e73\u5747F1\u5206\u6570\u63d0\u5347\u3002", "conclusion": "\u591a\u7b56\u7565\u96c6\u6210\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347NL-PL\u8ffd\u8e2a\u94fe\u63a5\u6062\u590d\u4efb\u52a1\u7684\u6574\u4f53\u6a21\u578b\u6027\u80fd\uff0c\u4e3a\u89e3\u51b3\u6587\u672c\u76f8\u4f3c\u6027\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.05323", "categories": ["cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2509.05323", "abs": "https://arxiv.org/abs/2509.05323", "authors": ["Adam Cole", "Mick Grierson"], "title": "Attention of a Kiss: Exploring Attention Maps in Video Diffusion for XAIxArts", "comment": "3rd international workshop on eXplainable AI for the Arts (XAIxArts)\n  at the ACM Creativity and Cognition Conference 2025", "summary": "This paper presents an artistic and technical investigation into the\nattention mechanisms of video diffusion transformers. Inspired by early video\nartists who manipulated analog video signals to create new visual aesthetics,\nthis study proposes a method for extracting and visualizing cross-attention\nmaps in generative video models. Built on the open-source Wan model, our tool\nprovides an interpretable window into the temporal and spatial behavior of\nattention in text-to-video generation. Through exploratory probes and an\nartistic case study, we examine the potential of attention maps as both\nanalytical tools and raw artistic material. This work contributes to the\ngrowing field of Explainable AI for the Arts (XAIxArts), inviting artists to\nreclaim the inner workings of AI as a creative medium.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u89c6\u5316\u89c6\u9891\u6269\u6563\u53d8\u6362\u5668\u4e2d\u6ce8\u610f\u529b\u673a\u5236\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u53d6\u4ea4\u53c9\u6ce8\u610f\u529b\u56fe\u6765\u5206\u6790\u6587\u672c\u5230\u89c6\u9891\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u65f6\u7a7a\u884c\u4e3a\uff0c\u4e3a\u827a\u672f\u521b\u4f5c\u63d0\u4f9b\u65b0\u7684\u5de5\u5177\u548c\u6750\u6599\u3002", "motivation": "\u53d7\u65e9\u671f\u89c6\u9891\u827a\u672f\u5bb6\u64cd\u7eb5\u6a21\u62df\u89c6\u9891\u4fe1\u53f7\u521b\u9020\u65b0\u89c6\u89c9\u7f8e\u5b66\u7684\u542f\u53d1\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u751f\u6210\u5f0f\u89c6\u9891\u6a21\u578b\u4e2d\u6ce8\u610f\u529b\u673a\u5236\u7684\u53ef\u89c6\u5316\u65b9\u6cd5\uff0c\u4e3a\u827a\u672f\u5bb6\u63d0\u4f9b\u7406\u89e3AI\u5185\u90e8\u5de5\u4f5c\u673a\u5236\u7684\u5de5\u5177\u3002", "method": "\u57fa\u4e8e\u5f00\u6e90Wan\u6a21\u578b\u6784\u5efa\u5de5\u5177\uff0c\u63d0\u53d6\u548c\u53ef\u89c6\u5316\u4ea4\u53c9\u6ce8\u610f\u529b\u56fe\uff0c\u901a\u8fc7\u63a2\u7d22\u6027\u63a2\u6d4b\u548c\u827a\u672f\u6848\u4f8b\u7814\u7a76\u5206\u6790\u6ce8\u610f\u529b\u56fe\u4f5c\u4e3a\u5206\u6790\u5de5\u5177\u548c\u827a\u672f\u6750\u6599\u7684\u6f5c\u529b\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u5de5\u5177\uff0c\u80fd\u591f\u5c55\u793a\u6587\u672c\u5230\u89c6\u9891\u751f\u6210\u8fc7\u7a0b\u4e2d\u6ce8\u610f\u529b\u7684\u65f6\u7a7a\u884c\u4e3a\uff0c\u8bc1\u660e\u4e86\u6ce8\u610f\u529b\u56fe\u65e2\u53ef\u4f5c\u4e3a\u5206\u6790\u5de5\u5177\u4e5f\u53ef\u4f5c\u4e3a\u539f\u59cb\u827a\u672f\u6750\u6599\u4f7f\u7528\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63a8\u52a8\u4e86\u53ef\u89e3\u91caAI\u827a\u672f(XAIxArts)\u9886\u57df\u7684\u53d1\u5c55\uff0c\u9080\u8bf7\u827a\u672f\u5bb6\u5c06AI\u5185\u90e8\u5de5\u4f5c\u673a\u5236\u91cd\u65b0\u4f5c\u4e3a\u521b\u610f\u5a92\u4ecb\uff0c\u4e3a\u827a\u672f\u4e0e\u6280\u672f\u7684\u878d\u5408\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2509.05306", "categories": ["cs.CR", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.05306", "abs": "https://arxiv.org/abs/2509.05306", "authors": ["Enis Karaarslan", "Esin G\u00fcler", "Efe Emir Y\u00fcce", "Cagatay Coban"], "title": "Towards Log Analysis with AI Agents: Cowrie Case Study", "comment": null, "summary": "The scarcity of real-world attack data significantly hinders progress in\ncybersecurity research and education. Although honeypots like Cowrie\neffectively collect live threat intelligence, they generate overwhelming\nvolumes of unstructured and heterogeneous logs, rendering manual analysis\nimpractical. As a first step in our project on secure and efficient AI\nautomation, this study explores the use of AI agents for automated log\nanalysis. We present a lightweight and automated approach to process Cowrie\nhoneypot logs. Our approach leverages AI agents to intelligently parse,\nsummarize, and extract insights from raw data, while also considering the\nsecurity implications of deploying such an autonomous system. Preliminary\nresults demonstrate the pipeline's effectiveness in reducing manual effort and\nidentifying attack patterns, paving the way for more advanced autonomous\ncybersecurity analysis in future work.", "AI": {"tldr": "\u4f7f\u7528AI\u4ee3\u7406\u81ea\u52a8\u5206\u6790Cowrie\u871c\u7f50\u65e5\u5fd7\uff0c\u89e3\u51b3\u7f51\u7edc\u5b89\u5168\u7814\u7a76\u4e2d\u771f\u5b9e\u653b\u51fb\u6570\u636e\u7a00\u7f3a\u548c\u65e5\u5fd7\u5206\u6790\u56f0\u96be\u7684\u95ee\u9898", "motivation": "\u771f\u5b9e\u653b\u51fb\u6570\u636e\u7a00\u7f3a\u963b\u788d\u7f51\u7edc\u5b89\u5168\u7814\u7a76\u53d1\u5c55\uff0c\u871c\u7f50\u4ea7\u751f\u7684\u5927\u91cf\u975e\u7ed3\u6784\u5316\u65e5\u5fd7\u96be\u4ee5\u624b\u52a8\u5206\u6790\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848", "method": "\u91c7\u7528\u8f7b\u91cf\u7ea7\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u5229\u7528AI\u4ee3\u7406\u667a\u80fd\u89e3\u6790\u3001\u603b\u7ed3\u548c\u63d0\u53d6Cowrie\u871c\u7f50\u539f\u59cb\u65e5\u5fd7\u7684\u6d1e\u5bdf\uff0c\u540c\u65f6\u8003\u8651\u81ea\u4e3b\u7cfb\u7edf\u7684\u5b89\u5168\u5f71\u54cd", "result": "\u521d\u6b65\u7ed3\u679c\u663e\u793a\u8be5\u6d41\u6c34\u7ebf\u80fd\u6709\u6548\u51cf\u5c11\u4eba\u5de5\u5de5\u4f5c\u91cf\u5e76\u8bc6\u522b\u653b\u51fb\u6a21\u5f0f", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u672a\u6765\u66f4\u5148\u8fdb\u7684\u81ea\u4e3b\u7f51\u7edc\u5b89\u5168\u5206\u6790\u94fa\u5e73\u4e86\u9053\u8def"}}
{"id": "2509.05596", "categories": ["cs.SE", "cs.SC", "68", "D.3.1; D.2.4"], "pdf": "https://arxiv.org/pdf/2509.05596", "abs": "https://arxiv.org/abs/2509.05596", "authors": ["Soumyadip Bandyopadhyay", "Santonu Sarkar"], "title": "Verifying Correctness of PLC Software during System Evolution using Model Containment Approach", "comment": "31 pages with appendix", "summary": "Upgradation of Programmable Logic Controller (PLC) software is quite common\nto accommodate evolving industrial requirements. Verifying the correctness of\nsuch upgrades remains a significant challenge. In this paper, we propose a\nverification-based approach to ensure the correctness of the existing\nfunctionality in the upgraded version of a PLC software. The method converts\nthe older and the newer versions of the sequential function chart (SFC) into\ntwo Petri net models. We then verify whether one model is contained within\nanother, based on a novel containment checking algorithm grounded in symbolic\npath equivalence. For this purpose, we have developed a home-grown Petri\nnet-based containment checker. Experimental evaluation on 80 real-world\nbenchmarks from the OSCAT library highlights the scalability and effectiveness\nof the framework. We have compared our approach with verifAPS, a popular tool\nused for software upgradation, and observed nearly 4x performance improvement.", "AI": {"tldr": "\u901a\u8fc7\u5c06PLC\u7a0b\u5e8f\u7684\u65e7\u7248\u548c\u65b0\u7248SFC\u8f6c\u6362\u4e3aPetri\u7f51\u6a21\u578b\uff0c\u4f7f\u7528\u7b26\u53f7\u8def\u5f84\u7b49\u4ef7\u57fa\u7840\u7684\u542b\u76d6\u68c0\u67e5\u7b97\u6cd5\u9a8c\u8bc1\u5347\u7ea7\u6b63\u786e\u6027\uff0c\u5728\u5b9e\u9645\u6848\u4f8b\u4e2d\u5b9e\u73b04\u500d\u6027\u80fd\u63d0\u5347", "motivation": "PLC\u8f6f\u4ef6\u5347\u7ea7\u662f\u5de5\u4e1a\u9886\u57df\u5e38\u89c1\u9700\u6c42\uff0c\u4f46\u9a8c\u8bc1\u5347\u7ea7\u7248\u672c\u7684\u6b63\u786e\u6027\u4ecd\u9762\u4e34\u91cd\u5927\u6311\u6218", "method": "\u5c06\u65e7\u7248\u548c\u65b0\u7248SFC\u8f6c\u6362\u4e3aPetri\u7f51\u6a21\u578b\uff0c\u4f7f\u7528\u57fa\u4e8e\u7b26\u53f7\u8def\u5f84\u7b49\u4ef7\u7684\u65b0\u9898\u542b\u76d6\u68c0\u67e5\u7b97\u6cd5\u9a8c\u8bc1\u6a21\u578b\u95f4\u7684\u542b\u76d6\u5173\u7cfb", "result": "\u572880\u4e2aOSCAT\u5e93\u5b9e\u9645\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u53ef\u6269\u5c55\u6027\u548c\u6709\u6548\u6027\uff0c\u4e0everifAPS\u5de5\u5177\u76f8\u6bd4\u5b9e\u73b0\u4e86\u8fd14\u500d\u7684\u6027\u80fd\u63d0\u5347", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u9ad8\u6548\u5730\u9a8c\u8bc1PLC\u8f6f\u4ef6\u5347\u7ea7\u7684\u6b63\u786e\u6027\uff0c\u4e3a\u5de5\u4e1a\u81ea\u52a8\u5316\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u9a8c\u8bc1\u65b9\u6848"}}
{"id": "2509.05324", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05324", "abs": "https://arxiv.org/abs/2509.05324", "authors": ["Rongqian Chen", "Shu Hong", "Rifatul Islam", "Mahdi Imani", "G. Gary Tan", "Tian Lan"], "title": "Perception Graph for Cognitive Attack Reasoning in Augmented Reality", "comment": "Accepted by ACM MobiHoc XR Security workshop 2025", "summary": "Augmented reality (AR) systems are increasingly deployed in tactical\nenvironments, but their reliance on seamless human-computer interaction makes\nthem vulnerable to cognitive attacks that manipulate a user's perception and\nseverely compromise user decision-making. To address this challenge, we\nintroduce the Perception Graph, a novel model designed to reason about human\nperception within these systems. Our model operates by first mimicking the\nhuman process of interpreting key information from an MR environment and then\nrepresenting the outcomes using a semantically meaningful structure. We\ndemonstrate how the model can compute a quantitative score that reflects the\nlevel of perception distortion, providing a robust and measurable method for\ndetecting and analyzing the effects of such cognitive attacks.", "AI": {"tldr": "\u901a\u8fc7\u5efa\u7acbPerception Graph\u6a21\u578b\u6765\u6a21\u62df\u4eba\u7c7b\u5728AR\u73af\u5883\u4e2d\u7684\u77e5\u89c9\u89e3\u91ca\u8fc7\u7a0b\uff0c\u5e76\u8ba1\u7b97\u77e5\u89c9\u626c\u538b\u5206\u6570\uff0c\u4ee5\u68c0\u6d4b\u548c\u5206\u6790\u8ba4\u77e5\u653b\u51fb\u7684\u5f71\u54cd", "motivation": "AR\u7cfb\u7edf\u5728\u6218\u672f\u73af\u5883\u4e2d\u5bb9\u6613\u53d7\u5230\u8ba4\u77e5\u653b\u51fb\u7684\u5a01\u80c1\uff0c\u8fd9\u4e9b\u653b\u51fb\u4f1a\u64a9\u52a8\u7528\u6237\u77e5\u89c9\u5e76\u4e25\u91cd\u5f71\u54cd\u51b3\u7b56\u80fd\u529b", "method": "\u63d0\u51faPerception Graph\u6a21\u578b\uff0c\u9996\u5148\u6a21\u4eff\u4eba\u7c7b\u5728MR\u73af\u5883\u4e2d\u89e3\u91ca\u5173\u952e\u4fe1\u606f\u7684\u8fc7\u7a0b\uff0c\u7136\u540e\u4f7f\u7528\u8bed\u4e49\u6709\u610f\u4e49\u7684\u7ed3\u6784\u8868\u793a\u7ed3\u679c", "result": "\u6a21\u578b\u80fd\u591f\u8ba1\u7b97\u53cd\u6620\u77e5\u89c9\u626c\u538b\u7a0b\u5ea6\u7684\u5b9a\u91cf\u5206\u6570\uff0c\u63d0\u4f9b\u4e86\u68c0\u6d4b\u548c\u5206\u6790\u8ba4\u77e5\u653b\u51fb\u6548\u679c\u7684\u7a33\u5065\u53ef\u6d4b\u91cf\u65b9\u6cd5", "conclusion": "Perception Graph\u6a21\u578b\u4e3aAR\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u548c\u5e94\u5bf9\u8ba4\u77e5\u653b\u51fb\u5e26\u6765\u7684\u5a01\u80c1\uff0c\u63d0\u5347\u4e86\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027"}}
{"id": "2509.05311", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.05311", "abs": "https://arxiv.org/abs/2509.05311", "authors": ["Konur Tholl", "Fran\u00e7ois Rivest", "Mariam El Mezouar", "Ranwa Al Mallah"], "title": "Large Language Model Integration with Reinforcement Learning to Augment Decision-Making in Autonomous Cyber Operations", "comment": null, "summary": "Reinforcement Learning (RL) has shown great potential for autonomous\ndecision-making in the cybersecurity domain, enabling agents to learn through\ndirect environment interaction. However, RL agents in Autonomous Cyber\nOperations (ACO) typically learn from scratch, requiring them to execute\nundesirable actions to learn their consequences. In this study, we integrate\nexternal knowledge in the form of a Large Language Model (LLM) pretrained on\ncybersecurity data that our RL agent can directly leverage to make informed\ndecisions. By guiding initial training with an LLM, we improve baseline\nperformance and reduce the need for exploratory actions with obviously negative\noutcomes. We evaluate our LLM-integrated approach in a simulated cybersecurity\nenvironment, and demonstrate that our guided agent achieves over 2x higher\nrewards during early training and converges to a favorable policy approximately\n4,500 episodes faster than the baseline.", "AI": {"tldr": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6307\u5bfc\u5f3a\u5316\u5b66\u4e60\u5728\u7f51\u7edc\u5b89\u5168\u81ea\u4e3b\u64cd\u4f5c\u4e2d\uff0c\u63d0\u9ad8\u521d\u671f\u8868\u73b0\u548c\u5b66\u4e60\u6548\u7387", "motivation": "\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u5728\u7f51\u7edc\u5b89\u5168\u9886\u57df\u4e2d\u9700\u8981\u4ece\u5934\u5b66\u4e60\u3001\u6267\u884c\u6709\u5bb3\u52a8\u4f5c\u7684\u95ee\u9898", "method": "\u96c6\u6210\u9886\u5148\u5728\u7f51\u7edc\u5b89\u5168\u6570\u636e\u4e0a\u9884\u8bad\u7ec3\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u6307\u5bfcRL\u7ecf\u7eaa\u4eba\u505a\u51fa\u660e\u667a\u51b3\u7b56", "result": "\u5728\u6a21\u62df\u7f51\u7edc\u5b89\u5168\u73af\u5883\u4e2d\uff0c\u6307\u5bfc\u540e\u7684\u7ecf\u7eaa\u4eba\u521d\u671f\u5956\u52b1\u63d0\u9ad82\u500d\u4ee5\u4e0a\uff0c\u6536\u655b\u901f\u5ea6\u63d0\u9ad8\u7ea64500\u4e2a\u5b8c\u6574\u8bad\u7ec3\u5faa\u73af", "conclusion": "\u5916\u90e8\u77e5\u8bc6\u96c6\u6210\u80fd\u591f\u663e\u8457\u63d0\u5347RL\u5728\u7f51\u7edc\u5b89\u5168\u9886\u57df\u7684\u5b66\u4e60\u6548\u7387\u548c\u6027\u80fd"}}
{"id": "2509.05749", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.05749", "abs": "https://arxiv.org/abs/2509.05749", "authors": ["AmirHossein Naghshzan"], "title": "Automating API Documentation with LLMs: A BERTopic Approach", "comment": null, "summary": "Developers rely on API documentation, but official sources are often lengthy,\ncomplex, or incomplete. Many turn to community-driven forums like Stack\nOverflow for practical insights. We propose automating the summarization of\ninformal sources, focusing on Android APIs. Using BERTopic, we extracted\nprevalent topics from 3.6 million Stack Overflow posts and applied extractive\nsummarization techniques to generate concise summaries, including code\nsnippets. A user study with 30 Android developers assessed the summaries for\ncoherence, relevance, informativeness, and satisfaction, showing improved\nproductivity. Integrating formal API knowledge with community-generated content\nenhances documentation, making API resources more accessible and actionable\nwork.", "AI": {"tldr": "\u81ea\u52a8\u5316\u6458\u8981\u793e\u533a\u8bba\u575b\u5185\u5bb9\u4e3aAndroid API\u63d0\u4f9b\u7b80\u6d01\u7684\u5b9e\u7528\u6458\u8981\uff0c\u5305\u62ec\u4ee3\u7801\u7247\u6bb5\uff0c\u901a\u8fc7\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u6548\u679c", "motivation": "\u5b98\u65b9API\u6587\u6863\u7ecf\u5e38\u957f\u7f18\u3001\u590d\u6742\u6216\u4e0d\u5b8c\u6574\uff0c\u5f00\u53d1\u8005\u9700\u8981\u4ece\u793e\u533a\u8bba\u575b\u83b7\u53d6\u5b9e\u7528\u89c1\u89e3", "method": "\u4f7f\u7528BERTopic\u4ece360\u4e07\u4e2aStack Overflow\u5e16\u5b50\u4e2d\u63d0\u53d6\u4e3b\u9898\uff0c\u5e94\u7528\u6458\u8981\u6280\u672f\u751f\u6210\u7b80\u6d01\u6458\u8981\uff0c\u5305\u62ec\u4ee3\u7801\u7247\u6bb5", "result": "\u901a\u8fc730\u540dAndroid\u5f00\u53d1\u8005\u7684\u7528\u6237\u7814\u7a76\uff0c\u8bc4\u4f30\u6458\u8981\u7684\u8fde\u8d2f\u6027\u3001\u76f8\u5173\u6027\u3001\u4fe1\u606f\u91cf\u548c\u6ee1\u610f\u5ea6\uff0c\u663e\u793a\u4e86\u751f\u4ea7\u529b\u63d0\u5347", "conclusion": "\u7ed3\u5408\u5f62\u5f0fAPI\u77e5\u8bc6\u4e0e\u793e\u533a\u751f\u6210\u5185\u5bb9\u53ef\u4ee5\u6539\u5584\u6587\u6863\u8d28\u91cf\uff0c\u4f7fAPI\u8d44\u6e90\u66f4\u6613\u83b7\u53d6\u548c\u5b9e\u7528"}}
{"id": "2509.05325", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05325", "abs": "https://arxiv.org/abs/2509.05325", "authors": ["Liming Xu", "Yunbo Long", "Alexandra Brintrup"], "title": "SynDelay: A Synthetic Dataset for Delivery Delay Prediction", "comment": "This paper incldues 1 figure and 2 tables", "summary": "Artificial intelligence (AI) is transforming supply chain management, yet\nprogress in predictive tasks -- such as delivery delay prediction -- remains\nconstrained by the scarcity of high-quality, openly available datasets.\nExisting datasets are often proprietary, small, or inconsistently maintained,\nhindering reproducibility and benchmarking. We present SynDelay, a synthetic\ndataset designed for delivery delay prediction. Generated using an advanced\ngenerative model trained on real-world data, SynDelay preserves realistic\ndelivery patterns while ensuring privacy. Although not entirely free of noise\nor inconsistencies, it provides a challenging and practical testbed for\nadvancing predictive modelling. To support adoption, we provide baseline\nresults and evaluation metrics as initial benchmarks, serving as reference\npoints rather than state-of-the-art claims. SynDelay is publicly available\nthrough the Supply Chain Data Hub, an open initiative promoting dataset sharing\nand benchmarking in supply chain AI. We encourage the community to contribute\ndatasets, models, and evaluation practices to advance research in this area.\nAll code is openly accessible at https://supplychaindatahub.org.", "AI": {"tldr": "SynDelay\u662f\u4e00\u4e2a\u7528\u4e8e\u914d\u9001\u5ef6\u8fdf\u9884\u6d4b\u7684\u5408\u6210\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u5148\u8fdb\u751f\u6210\u6a21\u578b\u57fa\u4e8e\u771f\u5b9e\u6570\u636e\u521b\u5efa\uff0c\u65e2\u4fdd\u6301\u771f\u5b9e\u6027\u53c8\u786e\u4fdd\u9690\u79c1\uff0c\u4e3a\u4f9b\u5e94\u94feAI\u7814\u7a76\u63d0\u4f9b\u5f00\u653e\u57fa\u51c6\u6d4b\u8bd5\u5e73\u53f0\u3002", "motivation": "\u73b0\u6709\u914d\u9001\u5ef6\u8fdf\u9884\u6d4b\u6570\u636e\u96c6\u591a\u4e3a\u4e13\u6709\u3001\u89c4\u6a21\u5c0f\u6216\u7ef4\u62a4\u4e0d\u4e00\u81f4\uff0c\u9650\u5236\u4e86\u7814\u7a76\u7684\u53ef\u590d\u73b0\u6027\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u9700\u8981\u9ad8\u8d28\u91cf\u5f00\u653e\u6570\u636e\u96c6\u6765\u63a8\u52a8\u4f9b\u5e94\u94feAI\u53d1\u5c55\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u771f\u5b9e\u6570\u636e\u8bad\u7ec3\u7684\u5148\u8fdb\u751f\u6210\u6a21\u578b\u521b\u5efa\u5408\u6210\u6570\u636e\u96c6\uff0c\u4fdd\u7559\u771f\u5b9e\u914d\u9001\u6a21\u5f0f\u540c\u65f6\u786e\u4fdd\u6570\u636e\u9690\u79c1\uff0c\u5e76\u63d0\u4f9b\u57fa\u7ebf\u7ed3\u679c\u548c\u8bc4\u4f30\u6307\u6807\u4f5c\u4e3a\u57fa\u51c6\u53c2\u8003\u3002", "result": "\u5f00\u53d1\u4e86SynDelay\u5408\u6210\u6570\u636e\u96c6\uff0c\u867d\u7136\u4e0d\u5b8c\u5168\u65e0\u566a\u58f0\u6216\u4e0d\u4e00\u81f4\uff0c\u4f46\u4e3a\u9884\u6d4b\u5efa\u6a21\u63d0\u4f9b\u4e86\u5177\u6709\u6311\u6218\u6027\u548c\u5b9e\u7528\u6027\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u5e76\u901a\u8fc7Supply Chain Data Hub\u516c\u5f00\u63d0\u4f9b\u3002", "conclusion": "SynDelay\u6570\u636e\u96c6\u586b\u8865\u4e86\u4f9b\u5e94\u94feAI\u7814\u7a76\u4e2d\u5f00\u653e\u6570\u636e\u96c6\u7684\u7a7a\u767d\uff0c\u9f13\u52b1\u793e\u533a\u8d21\u732e\u6570\u636e\u96c6\u3001\u6a21\u578b\u548c\u8bc4\u4f30\u5b9e\u8df5\uff0c\u5171\u540c\u63a8\u8fdb\u8be5\u9886\u57df\u7814\u7a76\u53d1\u5c55\u3002"}}
{"id": "2509.05318", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05318", "abs": "https://arxiv.org/abs/2509.05318", "authors": ["Zuquan Peng", "Jianming Fu", "Lixin Zou", "Li Zheng", "Yanzhen Ren", "Guojun Peng"], "title": "Backdoor Samples Detection Based on Perturbation Discrepancy Consistency in Pre-trained Language Models", "comment": "13 pages, 9 figures, 8 tables, journal", "summary": "The use of unvetted third-party and internet data renders pre-trained models\nsusceptible to backdoor attacks. Detecting backdoor samples is critical to\nprevent backdoor activation during inference or injection during training.\nHowever, existing detection methods often require the defender to have access\nto the poisoned models, extra clean samples, or significant computational\nresources to detect backdoor samples, limiting their practicality. To address\nthis limitation, we propose a backdoor sample detection method based on\nperturbatio\\textbf{N} discr\\textbf{E}pancy consis\\textbf{T}ency\n\\textbf{E}valuation (\\NETE). This is a novel detection method that can be used\nboth pre-training and post-training phases. In the detection process, it only\nrequires an off-the-shelf pre-trained model to compute the log probability of\nsamples and an automated function based on a mask-filling strategy to generate\nperturbations. Our method is based on the interesting phenomenon that the\nchange in perturbation discrepancy for backdoor samples is smaller than that\nfor clean samples. Based on this phenomenon, we use curvature to measure the\ndiscrepancy in log probabilities between different perturbed samples and input\nsamples, thereby evaluating the consistency of the perturbation discrepancy to\ndetermine whether the input sample is a backdoor sample. Experiments conducted\non four typical backdoor attacks and five types of large language model\nbackdoor attacks demonstrate that our detection strategy outperforms existing\nzero-shot black-box detection methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6270\u52a8\u5dee\u5f02\u4e00\u81f4\u6027\u8bc4\u4f30(NETE)\u7684\u540e\u95e8\u6837\u672c\u68c0\u6d4b\u65b9\u6cd5\uff0c\u65e0\u9700\u8bbf\u95ee\u4e2d\u6bd2\u6a21\u578b\u6216\u989d\u5916\u5e72\u51c0\u6837\u672c\uff0c\u4ec5\u9700\u73b0\u6210\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u5373\u53ef\u5728\u8bad\u7ec3\u524d\u540e\u9636\u6bb5\u68c0\u6d4b\u540e\u95e8\u6837\u672c\u3002", "motivation": "\u73b0\u6709\u540e\u95e8\u68c0\u6d4b\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u8bbf\u95ee\u4e2d\u6bd2\u6a21\u578b\u3001\u989d\u5916\u5e72\u51c0\u6837\u672c\u6216\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002\u9884\u8bad\u7ec3\u6a21\u578b\u4f7f\u7528\u672a\u7ecf\u5ba1\u67e5\u7684\u7b2c\u4e09\u65b9\u548c\u4e92\u8054\u7f51\u6570\u636e\u5bb9\u6613\u53d7\u5230\u540e\u95e8\u653b\u51fb\u3002", "method": "\u57fa\u4e8e\u6270\u52a8\u5dee\u5f02\u4e00\u81f4\u6027\u8bc4\u4f30(NETE)\uff0c\u5229\u7528\u540e\u95e8\u6837\u672c\u6270\u52a8\u5dee\u5f02\u53d8\u5316\u5c0f\u4e8e\u5e72\u51c0\u6837\u672c\u7684\u73b0\u8c61\uff0c\u901a\u8fc7\u66f2\u7387\u6d4b\u91cf\u4e0d\u540c\u6270\u52a8\u6837\u672c\u4e0e\u8f93\u5165\u6837\u672c\u4e4b\u95f4\u7684\u5bf9\u6570\u6982\u7387\u5dee\u5f02\uff0c\u8bc4\u4f30\u6270\u52a8\u5dee\u5f02\u4e00\u81f4\u6027\u6765\u5224\u65ad\u662f\u5426\u4e3a\u540e\u95e8\u6837\u672c\u3002", "result": "\u5728\u56db\u79cd\u5178\u578b\u540e\u95e8\u653b\u51fb\u548c\u4e94\u7c7b\u5927\u8bed\u8a00\u6a21\u578b\u540e\u95e8\u653b\u51fb\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u68c0\u6d4b\u7b56\u7565\u4f18\u4e8e\u73b0\u6709\u7684\u96f6\u6837\u672c\u9ed1\u76d2\u68c0\u6d4b\u65b9\u6cd5\u3002", "conclusion": "NETE\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u6709\u6548\u7684\u540e\u95e8\u6837\u672c\u68c0\u6d4b\u89e3\u51b3\u65b9\u6848\uff0c\u65e0\u9700\u989d\u5916\u8d44\u6e90\u5373\u53ef\u5728\u8bad\u7ec3\u524d\u540e\u9636\u6bb5\u8fdb\u884c\u68c0\u6d4b\uff0c\u5177\u6709\u5f88\u597d\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2509.05769", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.05769", "abs": "https://arxiv.org/abs/2509.05769", "authors": ["Edyta Brzychczy", "Urszula Jessen", "Krzysztof Kluza", "Sridhar Sriram", "Manuel Vargas Nettelnstroth"], "title": "IoT Miner: Intelligent Extraction of Event Logs from Sensor Data for Process Mining", "comment": "17 pages, conference draft", "summary": "This paper presents IoT Miner, a novel framework for automatically creating\nhigh-level event logs from raw industrial sensor data to support process\nmining. In many real-world settings, such as mining or manufacturing, standard\nevent logs are unavailable, and sensor data lacks the structure and semantics\nneeded for analysis. IoT Miner addresses this gap using a four-stage pipeline:\ndata preprocessing, unsupervised clustering, large language model (LLM)-based\nlabeling, and event log construction. A key innovation is the use of LLMs to\ngenerate meaningful activity labels from cluster statistics, guided by\ndomain-specific prompts. We evaluate the approach on sensor data from a\nLoad-Haul-Dump (LHD) mining machine and introduce a new metric,\nSimilarity-Weighted Accuracy, to assess labeling quality. Results show that\nricher prompts lead to more accurate and consistent labels. By combining AI\nwith domain-aware data processing, IoT Miner offers a scalable and\ninterpretable method for generating event logs from IoT data, enabling process\nmining in settings where traditional logs are missing.", "AI": {"tldr": "IoT Miner\u662f\u4e00\u4e2a\u4ece\u5de5\u4e1a\u4f20\u611f\u5668\u6570\u636e\u81ea\u52a8\u751f\u6210\u9ad8\u7ea7\u4e8b\u4ef6\u65e5\u5fd7\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6570\u636e\u9884\u5904\u7406\u3001\u65e0\u76d1\u7763\u805a\u7c7b\u3001LLM\u6807\u6ce8\u548c\u4e8b\u4ef6\u65e5\u5fd7\u6784\u5efa\u56db\u9636\u6bb5\u6d41\u7a0b\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u8fc7\u7a0b\u6316\u6398\u4e2d\u7f3a\u4e4f\u7ed3\u6784\u5316\u4e8b\u4ef6\u65e5\u5fd7\u7684\u95ee\u9898\u3002", "motivation": "\u5728\u91c7\u77ff\u3001\u5236\u9020\u7b49\u5de5\u4e1a\u573a\u666f\u4e2d\uff0c\u6807\u51c6\u4e8b\u4ef6\u65e5\u5fd7\u901a\u5e38\u4e0d\u53ef\u7528\uff0c\u539f\u59cb\u4f20\u611f\u5668\u6570\u636e\u7f3a\u4e4f\u7ed3\u6784\u5316\u548c\u8bed\u4e49\u4fe1\u606f\uff0c\u65e0\u6cd5\u76f4\u63a5\u7528\u4e8e\u8fc7\u7a0b\u6316\u6398\u5206\u6790\u3002", "method": "\u91c7\u7528\u56db\u9636\u6bb5\u6d41\u6c34\u7ebf\uff1a\u6570\u636e\u9884\u5904\u7406\u3001\u65e0\u76d1\u7763\u805a\u7c7b\u3001\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6807\u6ce8\uff08\u4f7f\u7528\u9886\u57df\u7279\u5b9a\u63d0\u793a\u751f\u6210\u6709\u610f\u4e49\u7684\u6807\u7b7e\uff09\u3001\u4e8b\u4ef6\u65e5\u5fd7\u6784\u5efa\u3002\u5173\u952e\u521b\u65b0\u662f\u5229\u7528LLM\u6839\u636e\u805a\u7c7b\u7edf\u8ba1\u4fe1\u606f\u751f\u6210\u6d3b\u52a8\u6807\u7b7e\u3002", "result": "\u5728\u88c5\u8f7d-\u8fd0\u8f93-\u5378\u8f7d\uff08LHD\uff09\u91c7\u77ff\u673a\u68b0\u4f20\u611f\u5668\u6570\u636e\u4e0a\u8bc4\u4f30\uff0c\u63d0\u51fa\u4e86\u76f8\u4f3c\u6027\u52a0\u6743\u51c6\u786e\u5ea6\u65b0\u6307\u6807\u6765\u8861\u91cf\u6807\u6ce8\u8d28\u91cf\u3002\u7ed3\u679c\u663e\u793a\u66f4\u4e30\u5bcc\u7684\u63d0\u793a\u8bcd\u80fd\u4ea7\u751f\u66f4\u51c6\u786e\u4e00\u81f4\u7684\u6807\u7b7e\u3002", "conclusion": "IoT Miner\u901a\u8fc7\u7ed3\u5408AI\u548c\u9886\u57df\u611f\u77e5\u6570\u636e\u5904\u7406\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u4f20\u7edf\u65e5\u5fd7\u7f3a\u5931\u7684\u573a\u666f\u4e0b\u4eceIoT\u6570\u636e\u751f\u6210\u4e8b\u4ef6\u65e5\u5fd7\uff0c\u652f\u6301\u8fc7\u7a0b\u6316\u6398\u5e94\u7528\u3002"}}
{"id": "2509.05330", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05330", "abs": "https://arxiv.org/abs/2509.05330", "authors": ["Seyed Muhammad Hossein Mousavi", "Atiye Ilanloo"], "title": "MVRS: The Multimodal Virtual Reality Stimuli-based Emotion Recognition Dataset", "comment": null, "summary": "Automatic emotion recognition has become increasingly important with the rise\nof AI, especially in fields like healthcare, education, and automotive systems.\nHowever, there is a lack of multimodal datasets, particularly involving body\nmotion and physiological signals, which limits progress in the field. To\naddress this, the MVRS dataset is introduced, featuring synchronized recordings\nfrom 13 participants aged 12 to 60 exposed to VR based emotional stimuli\n(relaxation, fear, stress, sadness, joy). Data were collected using eye\ntracking (via webcam in a VR headset), body motion (Kinect v2), and EMG and GSR\nsignals (Arduino UNO), all timestamp aligned. Participants followed a unified\nprotocol with consent and questionnaires. Features from each modality were\nextracted, fused using early and late fusion techniques, and evaluated with\nclassifiers to confirm the datasets quality and emotion separability, making\nMVRS a valuable contribution to multimodal affective computing.", "AI": {"tldr": "MVRS\u6570\u636e\u96c6\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u6570\u636e\u96c6\uff0c\u5305\u542bVR\u60c5\u7eea\u523a\u6fc0\u4e0b\u7684\u773c\u52a8\u3001\u8eab\u4f53\u8fd0\u52a8\u3001EMG\u548cGSR\u4fe1\u53f7\uff0c\u901a\u8fc7\u7279\u5f81\u63d0\u53d6\u548c\u878d\u5408\u6280\u672f\u9a8c\u8bc1\u4e86\u6570\u636e\u96c6\u8d28\u91cf\u548c\u60c5\u611f\u53ef\u5206\u79bb\u6027\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u5305\u542b\u8eab\u4f53\u8fd0\u52a8\u548c\u751f\u7406\u4fe1\u53f7\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u9650\u5236\u4e86\u60c5\u611f\u8bc6\u522b\u9886\u57df\u7684\u53d1\u5c55\uff0c\u7279\u522b\u662f\u5728\u533b\u7597\u3001\u6559\u80b2\u548c\u6c7d\u8f66\u7cfb\u7edf\u7b49AI\u5e94\u7528\u9886\u57df\u3002", "method": "\u6536\u96c613\u540d\u53c2\u4e0e\u8005\u5728VR\u60c5\u7eea\u523a\u6fc0\uff08\u653e\u677e\u3001\u6050\u60e7\u3001\u538b\u529b\u3001\u60b2\u4f24\u3001\u559c\u60a6\uff09\u4e0b\u7684\u540c\u6b65\u591a\u6a21\u6001\u6570\u636e\uff0c\u4f7f\u7528\u773c\u52a8\u8ffd\u8e2a\u3001Kinect\u8eab\u4f53\u8fd0\u52a8\u6355\u6349\u3001EMG\u548cGSR\u4fe1\u53f7\u91c7\u96c6\uff0c\u91c7\u7528\u65e9\u671f\u548c\u665a\u671f\u878d\u5408\u6280\u672f\u8fdb\u884c\u7279\u5f81\u878d\u5408\uff0c\u5e76\u7528\u5206\u7c7b\u5668\u8bc4\u4f30\u3002", "result": "\u6210\u529f\u521b\u5efa\u4e86MVRS\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u9a8c\u8bc1\u4e86\u6570\u636e\u96c6\u7684\u8d28\u91cf\u548c\u4e0d\u540c\u60c5\u611f\u72b6\u6001\u7684\u53ef\u5206\u79bb\u6027\u3002", "conclusion": "MVRS\u6570\u636e\u96c6\u4e3a\u591a\u6a21\u6001\u60c5\u611f\u8ba1\u7b97\u9886\u57df\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u8d44\u6e90\uff0c\u63a8\u52a8\u4e86\u57fa\u4e8e\u8eab\u4f53\u8fd0\u52a8\u548c\u751f\u7406\u4fe1\u53f7\u7684\u60c5\u611f\u8bc6\u522b\u7814\u7a76\u3002"}}
{"id": "2509.05320", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.05320", "abs": "https://arxiv.org/abs/2509.05320", "authors": ["Ikhlasse Badidi", "Nouhaila El Khiyaoui", "Aya Riany", "Badr Ben Elallid", "Amine Abouaomar"], "title": "Privacy-Preserving Offloading for Large Language Models in 6G Vehicular Networks", "comment": "7 pages, 6 figures, 1 algorithm, 5 equations", "summary": "The integration of Large Language Models (LLMs) in 6G vehicular networks\npromises unprecedented advancements in intelligent transportation systems.\nHowever, offloading LLM computations from vehicles to edge infrastructure poses\nsignificant privacy risks, potentially exposing sensitive user data. This paper\npresents a novel privacy-preserving offloading framework for LLM-integrated\nvehicular networks. We introduce a hybrid approach combining federated learning\n(FL) and differential privacy (DP) techniques to protect user data while\nmaintaining LLM performance. Our framework includes a privacy-aware task\npartitioning algorithm that optimizes the trade-off between local and edge\ncomputation, considering both privacy constraints and system efficiency. We\nalso propose a secure communication protocol for transmitting model updates and\naggregating results across the network. Experimental results demonstrate that\nour approach achieves 75\\% global accuracy with only a 2-3\\% reduction compared\nto non-privacy-preserving methods, while maintaining DP guarantees with an\noptimal privacy budget of $\\varepsilon = 0.8$. The framework shows stable\ncommunication overhead of approximately 2.1MB per round with computation\ncomprising over 90\\% of total processing time, validating its efficiency for\nresource-constrained vehicular environments.", "AI": {"tldr": "\u57fa\u4e8e\u8054\u90a6\u5b66\u4e60\u548c\u5dee\u5206\u9690\u79c1\u7684\u6c7d\u8f66\u7f51\u7edcLLM\u8ba1\u7b97\u79bb\u7ebf\u6846\u67b6\uff0c\u5728\u4fdd\u8bc1\u9690\u79c1\u7684\u524d\u63d0\u4e0b\u7ef4\u6301\u4e8675%\u5168\u5c40\u51c6\u786e\u7387\uff0c\u901a\u4fe1\u5f00\u9500\u7a33\u5b9a\u57282.1MB/\u8f6e", "motivation": "\u89e3\u51b36G\u6c7d\u8f66\u7f51\u7edc\u4e2dLLM\u8ba1\u7b97\u79bb\u7ebf\u5bfc\u81f4\u7684\u7528\u6237\u6570\u636e\u6cc4\u9732\u98ce\u9669\uff0c\u9700\u8981\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u7ef4\u6301\u7cfb\u7edf\u6027\u80fd", "method": "\u63d0\u51fa\u8054\u90a6\u5b66\u4e60(FL)+\u5dee\u5206\u9690\u79c1(DP)\u6df7\u5408\u65b9\u6848\uff0c\u5305\u62ec\u9690\u79c1\u611f\u77e5\u4efb\u52a1\u5206\u5272\u7b97\u6cd5\u548c\u5b89\u5168\u901a\u4fe1\u534f\u8bae", "result": "\u8fbe\u523075%\u5168\u5c40\u51c6\u786e\u7387(\u4ec5\u6bd4\u975e\u9690\u79c1\u65b9\u6848\u4e0b\u964d2-3%)\uff0c\u9690\u79c1\u4fdd\u8bc1\u4f18\u5316(\u03b5=0.8)\uff0c\u901a\u4fe1\u5f00\u95002.1MB/\u8f6e\uff0c\u8ba1\u7b97\u5360\u6bd490%\u4ee5\u4e0a\u5904\u7406\u65f6\u95f4", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u6c7d\u8f66\u7f51\u7edcLLM\u79bb\u7ebf\u7684\u9690\u79c1\u98ce\u9669\u95ee\u9898\uff0c\u5728\u4fdd\u8bc1\u9690\u79c1\u7684\u524d\u63d0\u4e0b\u7ef4\u6301\u4e86\u9ad8\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u6c7d\u8f66\u73af\u5883"}}
{"id": "2509.05881", "categories": ["cs.SE", "cs.AI", "I.2"], "pdf": "https://arxiv.org/pdf/2509.05881", "abs": "https://arxiv.org/abs/2509.05881", "authors": ["Qianheng Zhang", "Song Gao", "Chen Wei", "Yibo Zhao", "Ying Nie", "Ziru Chen", "Shijie Chen", "Yu Su", "Huan Sun"], "title": "GeoAnalystBench: A GeoAI benchmark for assessing large language models for spatial analysis workflow and code generation", "comment": "34 pages, 8 figures", "summary": "Recent advances in large language models (LLMs) have fueled growing interest\nin automating geospatial analysis and GIS workflows, yet their actual\ncapabilities remain uncertain. In this work, we call for rigorous evaluation of\nLLMs on well-defined geoprocessing tasks before making claims about full GIS\nautomation. To this end, we present GeoAnalystBench, a benchmark of 50\nPython-based tasks derived from real-world geospatial problems and carefully\nvalidated by GIS experts. Each task is paired with a minimum deliverable\nproduct, and evaluation covers workflow validity, structural alignment,\nsemantic similarity, and code quality (CodeBLEU). Using this benchmark, we\nassess both proprietary and open source models. Results reveal a clear gap:\nproprietary models such as ChatGPT-4o-mini achieve high validity 95% and\nstronger code alignment (CodeBLEU 0.39), while smaller open source models like\nDeepSeek-R1-7B often generate incomplete or inconsistent workflows (48.5%\nvalidity, 0.272 CodeBLEU). Tasks requiring deeper spatial reasoning, such as\nspatial relationship detection or optimal site selection, remain the most\nchallenging across all models. These findings demonstrate both the promise and\nlimitations of current LLMs in GIS automation and provide a reproducible\nframework to advance GeoAI research with human-in-the-loop support.", "AI": {"tldr": "\u63d0\u51fa\u4e86GeoAnalystBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u572850\u4e2a\u771f\u5b9e\u5730\u7406\u7a7a\u95f4\u5904\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u4e13\u6709\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u5f00\u6e90\u6a21\u578b\uff0c\u4f46\u7a7a\u95f4\u63a8\u7406\u4efb\u52a1\u4ecd\u662f\u6240\u6709\u6a21\u578b\u7684\u6311\u6218", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5730\u7406\u7a7a\u95f4\u5206\u6790\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u589e\u591a\uff0c\u9700\u8981\u5bf9\u5176\u5b9e\u9645\u80fd\u529b\u8fdb\u884c\u4e25\u683c\u8bc4\u4f30\uff0c\u800c\u4e0d\u662f\u8fc7\u65e9\u5ba3\u79f0\u80fd\u591f\u5b8c\u5168\u81ea\u52a8\u5316GIS\u5de5\u4f5c\u6d41", "method": "\u521b\u5efa\u5305\u542b50\u4e2aPython\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5GeoAnalystBench\uff0c\u6bcf\u4e2a\u4efb\u52a1\u90fd\u6709\u6700\u5c0f\u53ef\u4ea4\u4ed8\u4ea7\u54c1\uff0c\u4ece\u5de5\u4f5c\u6d41\u6709\u6548\u6027\u3001\u7ed3\u6784\u5bf9\u9f50\u3001\u8bed\u4e49\u76f8\u4f3c\u6027\u548c\u4ee3\u7801\u8d28\u91cf(CodeBLEU)\u56db\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u8bc4\u4f30", "result": "\u4e13\u6709\u6a21\u578b\u5982ChatGPT-4o-mini\u8868\u73b0\u4f18\u5f02(95%\u6709\u6548\u6027\uff0cCodeBLEU 0.39)\uff0c\u800c\u5f00\u6e90\u6a21\u578b\u5982DeepSeek-R1-7B\u8868\u73b0\u8f83\u5dee(48.5%\u6709\u6548\u6027\uff0cCodeBLEU 0.272)\u3002\u7a7a\u95f4\u5173\u7cfb\u68c0\u6d4b\u548c\u6700\u4f18\u9009\u5740\u7b49\u9700\u8981\u6df1\u5ea6\u7a7a\u95f4\u63a8\u7406\u7684\u4efb\u52a1\u5bf9\u6240\u6709\u6a21\u578b\u90fd\u6700\u5177\u6311\u6218\u6027", "conclusion": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728GIS\u81ea\u52a8\u5316\u65b9\u9762\u65e2\u6709\u6f5c\u529b\u4e5f\u6709\u5c40\u9650\u6027\uff0c\u9700\u8981\u5efa\u7acb\u53ef\u590d\u73b0\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u91c7\u7528\u4eba\u673a\u534f\u540c\u7684\u65b9\u5f0f\u63a8\u8fdbGeoAI\u7814\u7a76"}}
{"id": "2509.05346", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05346", "abs": "https://arxiv.org/abs/2509.05346", "authors": ["Bo Yuan", "Jiazi Hu"], "title": "Benchmarking Large Language Models for Personalized Guidance in AI-Enhanced Learning", "comment": null, "summary": "While Large Language Models (LLMs) are increasingly envisioned as intelligent\nassistants for personalized learning, systematic head-to-head evaluations\nwithin authentic learning scenarios remain limited. This study conducts an\nempirical comparison of three state-of-the-art LLMs on a tutoring task that\nsimulates a realistic learning setting. Using a dataset comprising a student's\nanswers to ten questions of mixed formats with correctness labels, each LLM is\nrequired to (i) analyze the quiz to identify underlying knowledge components,\n(ii) infer the student's mastery profile, and (iii) generate targeted guidance\nfor improvement. To mitigate subjectivity and evaluator bias, we employ Gemini\nas a virtual judge to perform pairwise comparisons along various dimensions:\naccuracy, clarity, actionability, and appropriateness. Results analyzed via the\nBradley-Terry model indicate that GPT-4o is generally preferred, producing\nfeedback that is more informative and better structured than its counterparts,\nwhile DeepSeek-V3 and GLM-4.5 demonstrate intermittent strengths but lower\nconsistency. These findings highlight the feasibility of deploying LLMs as\nadvanced teaching assistants for individualized support and provide\nmethodological guidance for future empirical research on LLM-driven\npersonalized learning.", "AI": {"tldr": "\u672c\u7814\u7a76\u5bf9GPT-4o\u3001DeepSeek-V3\u548cGLM-4.5\u4e09\u79cd\u5148\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e2a\u6027\u5316\u5b66\u4e60\u8f85\u5bfc\u4efb\u52a1\u4e2d\u8fdb\u884c\u5b9e\u8bc1\u6bd4\u8f83\uff0c\u53d1\u73b0GPT-4o\u5728\u51c6\u786e\u6027\u3001\u6e05\u6670\u5ea6\u548c\u53ef\u64cd\u4f5c\u6027\u65b9\u9762\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u8bbe\u60f3\u4e3a\u4e2a\u6027\u5316\u5b66\u4e60\u7684\u667a\u80fd\u52a9\u624b\uff0c\u4f46\u5728\u771f\u5b9e\u5b66\u4e60\u573a\u666f\u4e2d\u7684\u7cfb\u7edf\u6027\u5bf9\u6bd4\u8bc4\u4f30\u4ecd\u7136\u6709\u9650\uff0c\u9700\u8981\u5b9e\u8bc1\u7814\u7a76\u6765\u9a8c\u8bc1\u4e0d\u540c\u6a21\u578b\u5728\u8f85\u5bfc\u4efb\u52a1\u4e2d\u7684\u5b9e\u9645\u8868\u73b0\u3002", "method": "\u4f7f\u7528\u5305\u542b\u5b66\u751f\u7b54\u6848\u548c\u6b63\u786e\u6027\u6807\u7b7e\u7684\u6570\u636e\u96c6\uff0c\u8981\u6c42\u6bcf\u4e2a\u6a21\u578b\u5206\u6790\u6d4b\u9a8c\u3001\u63a8\u65ad\u5b66\u751f\u638c\u63e1\u60c5\u51b5\u5e76\u751f\u6210\u9488\u5bf9\u6027\u6307\u5bfc\u3002\u91c7\u7528Gemini\u4f5c\u4e3a\u865a\u62df\u8bc4\u5224\u5458\u8fdb\u884c\u591a\u7ef4\u5ea6\uff08\u51c6\u786e\u6027\u3001\u6e05\u6670\u5ea6\u3001\u53ef\u64cd\u4f5c\u6027\u3001\u9002\u5f53\u6027\uff09\u7684\u6210\u5bf9\u6bd4\u8f83\uff0c\u5e76\u901a\u8fc7Bradley-Terry\u6a21\u578b\u5206\u6790\u7ed3\u679c\u3002", "result": "GPT-4o\u603b\u4f53\u4e0a\u8868\u73b0\u6700\u4f18\uff0c\u5176\u53cd\u9988\u4fe1\u606f\u66f4\u4e30\u5bcc\u3001\u7ed3\u6784\u66f4\u597d\uff1bDeepSeek-V3\u548cGLM-4.5\u5728\u67d0\u4e9b\u65b9\u9762\u6709\u4f18\u52bf\u4f46\u4e00\u81f4\u6027\u8f83\u4f4e\u3002", "conclusion": "\u7814\u7a76\u8bc1\u5b9e\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u9ad8\u7ea7\u6559\u5b66\u52a9\u624b\u63d0\u4f9b\u4e2a\u6027\u5316\u652f\u6301\u7684\u53ef\u884c\u6027\uff0c\u5e76\u4e3a\u672a\u6765LLM\u9a71\u52a8\u7684\u4e2a\u6027\u5316\u5b66\u4e60\u5b9e\u8bc1\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u6cd5\u5b66\u6307\u5bfc\u3002"}}
{"id": "2509.05326", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05326", "abs": "https://arxiv.org/abs/2509.05326", "authors": ["Logan Nye"], "title": "Zero-Knowledge Proofs in Sublinear Space", "comment": "21 pages", "summary": "Modern zero-knowledge proof (ZKP) systems, essential for privacy and\nverifiable computation, suffer from a fundamental limitation: the prover\ntypically uses memory that scales linearly with the computation's trace length\nT, making them impractical for resource-constrained devices and prohibitively\nexpensive for large-scale tasks. This paper overcomes this barrier by\nconstructing, to our knowledge, the first sublinear-space ZKP prover. Our core\ncontribution is an equivalence that reframes proof generation as an instance of\nthe classic Tree Evaluation problem. Leveraging a recent space-efficient\ntree-evaluation algorithm, we design a streaming prover that assembles the\nproof without ever materializing the full execution trace. The approach reduces\nprover memory from linear in T to O(sqrt(T)) (up to O(log T) lower-order terms)\nwhile preserving proof size, verifier time, and the transcript/security\nguarantees of the underlying system. This enables a shift from specialized,\nserver-bound proving to on-device proving, opening applications in\ndecentralized systems, on-device machine learning, and privacy-preserving\ntechnologies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u7b2c\u4e00\u4e2a\u4e9a\u7ebf\u6027\u7a7a\u95f4\u7684\u96f6\u77e5\u8bc6\u8bc1\u660e\u751f\u6210\u5668\uff0c\u5c06\u8bc1\u660e\u751f\u6210\u91cd\u6784\u4e3a\u6811\u8bc4\u4f30\u95ee\u9898\uff0c\u5c06\u8bc1\u660e\u8005\u5185\u5b58\u4ece\u7ebf\u6027T\u964d\u4f4e\u5230O(sqrt(T))", "motivation": "\u73b0\u4ee3\u96f6\u77e5\u8bc6\u8bc1\u660e\u7cfb\u7edf\u5b58\u5728\u8bc1\u660e\u8005\u5185\u5b58\u968f\u8ba1\u7b97\u8f68\u8ff9\u957f\u5ea6T\u7ebf\u6027\u6269\u5c55\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u548c\u5927\u89c4\u6a21\u4efb\u52a1\u4e2d\u7684\u5e94\u7528", "method": "\u901a\u8fc7\u5c06\u8bc1\u660e\u751f\u6210\u91cd\u65b0\u6784\u5efa\u4e3a\u7ecf\u5178\u7684\u6811\u8bc4\u4f30\u95ee\u9898\u5b9e\u4f8b\uff0c\u5229\u7528\u6700\u8fd1\u7684\u7a7a\u95f4\u9ad8\u6548\u6811\u8bc4\u4f30\u7b97\u6cd5\uff0c\u8bbe\u8ba1\u6d41\u5f0f\u8bc1\u660e\u751f\u6210\u5668\uff0c\u65e0\u9700\u7269\u5316\u5b8c\u6574\u6267\u884c\u8f68\u8ff9", "result": "\u5c06\u8bc1\u660e\u8005\u5185\u5b58\u4ece\u7ebf\u6027T\u964d\u4f4e\u5230O(sqrt(T))\uff08\u5305\u542bO(log T)\u4f4e\u9636\u9879\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u8bc1\u660e\u5927\u5c0f\u3001\u9a8c\u8bc1\u8005\u65f6\u95f4\u548c\u5e95\u5c42\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u4fdd\u8bc1", "conclusion": "\u8fd9\u9879\u6280\u672f\u5b9e\u73b0\u4e86\u4ece\u4e13\u95e8\u7684\u670d\u52a1\u5668\u7ed1\u5b9a\u8bc1\u660e\u5411\u8bbe\u5907\u4e0a\u8bc1\u660e\u7684\u8f6c\u53d8\uff0c\u4e3a\u53bb\u4e2d\u5fc3\u5316\u7cfb\u7edf\u3001\u8bbe\u5907\u4e0a\u673a\u5668\u5b66\u4e60\u548c\u9690\u79c1\u4fdd\u62a4\u6280\u672f\u5f00\u8f9f\u4e86\u65b0\u5e94\u7528"}}
{"id": "2509.05941", "categories": ["cs.SE", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.05941", "abs": "https://arxiv.org/abs/2509.05941", "authors": ["Chaoqian Ouyang", "Ling Yue", "Shimin Di", "Libin Zheng", "Shaowu Pan", "Min-Ling Zhang"], "title": "Code2MCP: A Multi-Agent Framework for Automated Transformation of Code Repositories into Model Context Protocol Services", "comment": null, "summary": "The proliferation of Large Language Models (LLMs) has created a significant\nintegration challenge in the AI agent ecosystem, often called the \"$N \\times M$\nproblem,\" where N models require custom integrations for M tools. This\nfragmentation stifles innovation and creates substantial development overhead.\nWhile the Model Context Protocol (MCP) has emerged as a standard to resolve\nthis, its adoption is hindered by the manual effort required to convert the\nvast universe of existing software into MCP-compliant services. This is\nespecially true for the millions of open-source repositories on GitHub, the\nworld's largest collection of functional code. This paper introduces Code2MCP,\na highly automated, agentic framework designed to transform any GitHub\nrepository into a functional MCP service with minimal human intervention. Our\nsystem employs a multi-stage workflow that automates the entire process, from\ncode analysis and environment configuration to service generation and\ndeployment. A key innovation of our framework is an LLM-driven, closed-loop\n\"Run--Review--Fix\" cycle, which enables the system to autonomously debug and\nrepair the code it generates. Code2MCP produces not only deployable services\nbut also comprehensive technical documentation, acting as a catalyst to\naccelerate the MCP ecosystem by systematically unlocking the world's largest\nopen-source code repository and automating the critical last mile of tool\nintegration. The code is open-sourced at\nhttps://github.com/DEFENSE-SEU/MCP-Github-Agent.", "AI": {"tldr": "Code2MCP\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u80fd\u591f\u5c06GitHub\u4ed3\u5e93\u8f6c\u6362\u4e3aMCP\u517c\u5bb9\u670d\u52a1\uff0c\u89e3\u51b3LLM\u96c6\u6210\u4e2d\u7684N\u00d7M\u95ee\u9898", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u5de5\u5177\u96c6\u6210\u65f6\u7684N\u00d7M\u788e\u7247\u5316\u95ee\u9898\uff0c\u964d\u4f4eMCP\u534f\u8bae\u91c7\u7528\u7684\u624b\u52a8\u5de5\u4f5c\u8d1f\u62c5", "method": "\u91c7\u7528\u591a\u9636\u6bb5\u5de5\u4f5c\u6d41\u548cLLM\u9a71\u52a8\u7684\"\u8fd0\u884c-\u5ba1\u67e5-\u4fee\u590d\"\u95ed\u73af\u5faa\u73af\uff0c\u81ea\u52a8\u5316\u4ee3\u7801\u5206\u6790\u3001\u73af\u5883\u914d\u7f6e\u3001\u670d\u52a1\u751f\u6210\u548c\u90e8\u7f72", "result": "\u80fd\u591f\u81ea\u52a8\u5c06GitHub\u5f00\u6e90\u4ed3\u5e93\u8f6c\u6362\u4e3a\u529f\u80fd\u5b8c\u6574\u7684MCP\u670d\u52a1\uff0c\u5e76\u751f\u6210\u8be6\u7ec6\u6280\u672f\u6587\u6863", "conclusion": "Code2MCP\u901a\u8fc7\u81ea\u52a8\u5316\u5de5\u5177\u96c6\u6210\u8fc7\u7a0b\uff0c\u52a0\u901fMCP\u751f\u6001\u7cfb\u7edf\u53d1\u5c55\uff0c\u91ca\u653eGitHub\u6d77\u91cf\u5f00\u6e90\u4ee3\u7801\u7684\u6f5c\u529b"}}
{"id": "2509.05363", "categories": ["cs.AI", "cond-mat.mtrl-sci", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.05363", "abs": "https://arxiv.org/abs/2509.05363", "authors": ["Lijie Ding", "Changwoo Do"], "title": "SasAgent: Multi-Agent AI System for Small-Angle Scattering Data Analysis", "comment": "8 pages, 7 figures", "summary": "We introduce SasAgent, a multi-agent AI system powered by large language\nmodels (LLMs) that automates small-angle scattering (SAS) data analysis by\nleveraging tools from the SasView software and enables user interaction via\ntext input. SasAgent features a coordinator agent that interprets user prompts\nand delegates tasks to three specialized agents for scattering length density\n(SLD) calculation, synthetic data generation, and experimental data fitting.\nThese agents utilize LLM-friendly tools to execute tasks efficiently. These\ntools, including the model data tool, Retrieval-Augmented Generation (RAG)\ndocumentation tool, bump fitting tool, and SLD calculator tool, are derived\nfrom the SasView Python library. A user-friendly Gradio-based interface\nenhances user accessibility. Through diverse examples, we demonstrate\nSasAgent's ability to interpret complex prompts, calculate SLDs, generate\naccurate scattering data, and fit experimental datasets with high precision.\nThis work showcases the potential of LLM-driven AI systems to streamline\nscientific workflows and enhance automation in SAS research.", "AI": {"tldr": "SasAgent\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u4ee3\u7406AI\u7cfb\u7edf\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u5c0f\u89d2\u6563\u5c04\u6570\u636e\u5206\u6790\uff0c\u901a\u8fc7SasView\u5de5\u5177\u548c\u6587\u672c\u4ea4\u4e92\u5b9e\u73b0\u9ad8\u6548\u79d1\u5b66\u5de5\u4f5c\u6d41", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5c0f\u89d2\u6563\u5c04\u6570\u636e\u5206\u6790\u7684\u590d\u6742\u6027\uff0c\u63d0\u9ad8\u81ea\u52a8\u5316\u6c34\u5e73\uff0c\u5229\u7528LLM\u6280\u672f\u7b80\u5316\u79d1\u5b66\u5de5\u4f5c\u6d41\u7a0b", "method": "\u91c7\u7528\u591a\u4ee3\u7406\u67b6\u6784\uff1a\u534f\u8c03\u4ee3\u7406\u89e3\u6790\u7528\u6237\u63d0\u793a\uff0c\u4e09\u4e2a\u4e13\u4e1a\u4ee3\u7406\u5206\u522b\u8d1f\u8d23\u6563\u5c04\u957f\u5ea6\u5bc6\u5ea6\u8ba1\u7b97\u3001\u5408\u6210\u6570\u636e\u751f\u6210\u548c\u5b9e\u9a8c\u6570\u636e\u62df\u5408\uff0c\u4f7f\u7528\u57fa\u4e8eSasView\u7684LLM\u53cb\u597d\u5de5\u5177", "result": "\u7cfb\u7edf\u80fd\u591f\u89e3\u91ca\u590d\u6742\u63d0\u793a\u3001\u7cbe\u786e\u8ba1\u7b97SLD\u3001\u751f\u6210\u51c6\u786e\u6563\u5c04\u6570\u636e\uff0c\u5e76\u4ee5\u9ad8\u7cbe\u5ea6\u62df\u5408\u5b9e\u9a8c\u6570\u636e\u96c6", "conclusion": "\u5c55\u793a\u4e86LLM\u9a71\u52a8\u7684AI\u7cfb\u7edf\u5728\u7b80\u5316\u79d1\u5b66\u5de5\u4f5c\u6d41\u7a0b\u548c\u589e\u5f3aSAS\u7814\u7a76\u81ea\u52a8\u5316\u65b9\u9762\u7684\u5de8\u5927\u6f5c\u529b"}}
{"id": "2509.05331", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.05331", "abs": "https://arxiv.org/abs/2509.05331", "authors": ["Youssef Chakir", "Iyad Lahsen-Cherif"], "title": "ForensicsData: A Digital Forensics Dataset for Large Language Models", "comment": "Accepted to WiMob 2025 (21st International Conference on Wireless and\n  Mobile Computing, Networking and Communications), Marrakesh, Morocco, Oct\n  20-22, 2025. 6 pages, 5 figures, 5 tables. IEEEtran conference format", "summary": "The growing complexity of cyber incidents presents significant challenges for\ndigital forensic investigators, especially in evidence collection and analysis.\nPublic resources are still limited because of ethical, legal, and privacy\nconcerns, even though realistic datasets are necessary to support research and\ntool developments. To address this gap, we introduce ForensicsData, an\nextensive Question-Context-Answer (Q-C-A) dataset sourced from actual malware\nanalysis reports. It consists of more than 5,000 Q-C-A triplets. A unique\nworkflow was used to create the dataset, which extracts structured data, uses\nlarge language models (LLMs) to transform it into Q-C-A format, and then uses a\nspecialized evaluation process to confirm its quality. Among the models\nevaluated, Gemini 2 Flash demonstrated the best performance in aligning\ngenerated content with forensic terminology. ForensicsData aims to advance\ndigital forensics by enabling reproducible experiments and fostering\ncollaboration within the research community.", "AI": {"tldr": "\u63d0\u51fa\u4e86ForensicsData\u6570\u636e\u96c6\uff0c\u5305\u542b5000\u591a\u4e2a\u4ece\u771f\u5b9e\u6076\u610f\u8f6f\u4ef6\u5206\u6790\u62a5\u544a\u4e2d\u63d0\u53d6\u7684\u95ee\u7b54\u4e09\u5143\u7ec4\uff0c\u7528\u4e8e\u89e3\u51b3\u6570\u5b57\u53d6\u8bc1\u9886\u57df\u7f3a\u4e4f\u771f\u5b9e\u6570\u636e\u96c6\u7684\u95ee\u9898\u3002", "motivation": "\u6570\u5b57\u53d6\u8bc1\u8c03\u67e5\u9762\u4e34\u8bc1\u636e\u6536\u96c6\u548c\u5206\u6790\u7684\u6311\u6218\uff0c\u7531\u4e8e\u4f26\u7406\u3001\u6cd5\u5f8b\u548c\u9690\u79c1\u95ee\u9898\uff0c\u7f3a\u4e4f\u771f\u5b9e\u7684\u516c\u5f00\u6570\u636e\u96c6\u6765\u652f\u6301\u7814\u7a76\u548c\u5de5\u5177\u5f00\u53d1\u3002", "method": "\u91c7\u7528\u72ec\u7279\u7684\u5de5\u4f5c\u6d41\u7a0b\uff1a\u4ece\u6076\u610f\u8f6f\u4ef6\u5206\u6790\u62a5\u544a\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u6570\u636e\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8f6c\u6362\u4e3a\u95ee\u7b54\u683c\u5f0f\uff0c\u5e76\u901a\u8fc7\u4e13\u95e8\u8bc4\u4f30\u6d41\u7a0b\u9a8c\u8bc1\u8d28\u91cf\u3002", "result": "Gemini 2 Flash\u6a21\u578b\u5728\u751f\u6210\u5185\u5bb9\u4e0e\u53d6\u8bc1\u672f\u8bed\u5bf9\u9f50\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u6570\u636e\u96c6\u5305\u542b5000\u591a\u4e2a\u95ee\u7b54\u4e09\u5143\u7ec4\u3002", "conclusion": "ForensicsData\u6570\u636e\u96c6\u65e8\u5728\u901a\u8fc7\u652f\u6301\u53ef\u91cd\u590d\u5b9e\u9a8c\u548c\u4fc3\u8fdb\u7814\u7a76\u793e\u533a\u5408\u4f5c\u6765\u63a8\u52a8\u6570\u5b57\u53d6\u8bc1\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2509.05980", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.05980", "abs": "https://arxiv.org/abs/2509.05980", "authors": ["Xingliang Wang", "Baoyi Wang", "Chen Zhi", "Junxiao Han", "Xinkui Zhao", "Jianwei Yin", "Shuiguang Deng"], "title": "GRACE: Graph-Guided Repository-Aware Code Completion through Hierarchical Code Fusion", "comment": null, "summary": "LLMs excel in localized code completion but struggle with repository-level\ntasks due to limited context windows and complex semantic and structural\ndependencies across codebases. While Retrieval-Augmented Generation (RAG)\nmitigates context scarcity by retrieving relevant code snippets, current\napproaches face significant limitations. They overly rely on textual similarity\nfor retrieval, neglecting structural relationships such as call chains and\ninheritance hierarchies, and lose critical structural information by naively\nconcatenating retrieved snippets into text sequences for LLM input. To address\nthese shortcomings, GRACE constructs a multi-level, multi-semantic code graph\nthat unifies file structures, abstract syntax trees, function call graphs,\nclass hierarchies, and data flow graphs to capture both static and dynamic code\nsemantics. For retrieval, GRACE employs a Hybrid Graph Retriever that\nintegrates graph neural network-based structural similarity with textual\nretrieval, refined by a graph attention network-based re-ranker to prioritize\ntopologically relevant subgraphs. To enhance context, GRACE introduces a\nstructural fusion mechanism that merges retrieved subgraphs with the local code\ncontext and preserves essential dependencies like function calls and\ninheritance. Extensive experiments on public repository-level benchmarks\ndemonstrate that GRACE significantly outperforms state-of-the-art methods\nacross all metrics. Using DeepSeek-V3 as the backbone LLM, GRACE surpasses the\nstrongest graph-based RAG baselines by 8.19% EM and 7.51% ES points on every\ndataset. The code is available at\nhttps://anonymous.4open.science/r/grace_icse-C3D5.", "AI": {"tldr": "GRACE\u662f\u4e00\u4e2a\u57fa\u4e8e\u56fe\u7ed3\u6784\u7684\u4ee3\u7801\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u591a\u5c42\u7ea7\u4ee3\u7801\u56fe\u6765\u6355\u6349\u4ee3\u7801\u8bed\u4e49\u548c\u7ed3\u6784\u5173\u7cfb\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfRAG\u65b9\u6cd5\u5728\u4ee3\u7801\u5e93\u7ea7\u522b\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709LLM\u5728\u4ee3\u7801\u8865\u5168\u65b9\u9762\u8868\u73b0\u4f18\u79c0\uff0c\u4f46\u5728\u4ee3\u7801\u5e93\u7ea7\u522b\u4efb\u52a1\u4e2d\u53d7\u9650\u4e8e\u4e0a\u4e0b\u6587\u7a97\u53e3\u548c\u590d\u6742\u7684\u8bed\u4e49\u7ed3\u6784\u4f9d\u8d56\u3002\u4f20\u7edfRAG\u65b9\u6cd5\u8fc7\u5ea6\u4f9d\u8d56\u6587\u672c\u76f8\u4f3c\u6027\u68c0\u7d22\uff0c\u5ffd\u7565\u4e86\u4ee3\u7801\u7684\u7ed3\u6784\u5173\u7cfb\uff0c\u5bfc\u81f4\u5173\u952e\u7ed3\u6784\u4fe1\u606f\u4e22\u5931\u3002", "method": "GRACE\u6784\u5efa\u7edf\u4e00\u7684\u591a\u5c42\u7ea7\u4ee3\u7801\u56fe\uff08\u5305\u542b\u6587\u4ef6\u7ed3\u6784\u3001AST\u3001\u51fd\u6570\u8c03\u7528\u56fe\u3001\u7c7b\u5c42\u6b21\u7ed3\u6784\u548c\u6570\u636e\u6d41\u56fe\uff09\uff0c\u91c7\u7528\u6df7\u5408\u56fe\u68c0\u7d22\u5668\u7ed3\u5408\u56fe\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u76f8\u4f3c\u6027\u548c\u6587\u672c\u68c0\u7d22\uff0c\u5e76\u901a\u8fc7\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\u91cd\u6392\u5e8f\u5668\u4f18\u5316\u68c0\u7d22\u7ed3\u679c\u3002", "result": "\u5728\u516c\u5171\u4ee3\u7801\u5e93\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGRACE\u5728\u6240\u6709\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\u3002\u4f7f\u7528DeepSeek-V3\u4f5c\u4e3a\u9aa8\u5e72LLM\uff0cGRACE\u6bd4\u6700\u5f3a\u7684\u57fa\u4e8e\u56fe\u7684RAG\u57fa\u7ebf\u5728EM\u548cES\u6307\u6807\u4e0a\u5206\u522b\u63d0\u53478.19%\u548c7.51%\u3002", "conclusion": "GRACE\u901a\u8fc7\u6574\u5408\u7ed3\u6784\u4fe1\u606f\u548c\u8bed\u4e49\u4fe1\u606f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4ee3\u7801\u5e93\u7ea7\u522b\u4efb\u52a1\u4e2d\u7684\u4e0a\u4e0b\u6587\u7a00\u7f3a\u95ee\u9898\uff0c\u4e3a\u4ee3\u7801\u7406\u89e3\u548c\u751f\u6210\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u4ee3\u7801\u8868\u793a\u65b9\u6cd5\u3002"}}
{"id": "2509.05375", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05375", "abs": "https://arxiv.org/abs/2509.05375", "authors": ["Arend Hintze"], "title": "Characterizing Fitness Landscape Structures in Prompt Engineering", "comment": null, "summary": "While prompt engineering has emerged as a crucial technique for optimizing\nlarge language model performance, the underlying optimization landscape remains\npoorly understood. Current approaches treat prompt optimization as a black-box\nproblem, applying sophisticated search algorithms without characterizing the\nlandscape topology they navigate. We present a systematic analysis of fitness\nlandscape structures in prompt engineering using autocorrelation analysis\nacross semantic embedding spaces. Through experiments on error detection tasks\nwith two distinct prompt generation strategies -- systematic enumeration (1,024\nprompts) and novelty-driven diversification (1,000 prompts) -- we reveal\nfundamentally different landscape topologies. Systematic prompt generation\nyields smoothly decaying autocorrelation, while diversified generation exhibits\nnon-monotonic patterns with peak correlation at intermediate semantic\ndistances, indicating rugged, hierarchically structured landscapes.\nTask-specific analysis across 10 error detection categories reveals varying\ndegrees of ruggedness across different error types. Our findings provide an\nempirical foundation for understanding the complexity of optimization in prompt\nengineering landscapes.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u81ea\u76f8\u5173\u5206\u6790\u63ed\u793a\u4e86\u63d0\u793a\u5de5\u7a0b\u4f18\u5316\u666f\u89c2\u7684\u7ed3\u6784\u7279\u5f81\uff0c\u53d1\u73b0\u7cfb\u7edf\u5316\u63d0\u793a\u751f\u6210\u4ea7\u751f\u5e73\u6ed1\u8870\u51cf\u7684\u81ea\u76f8\u5173\uff0c\u800c\u591a\u6837\u5316\u751f\u6210\u5219\u5448\u73b0\u975e\u5355\u8c03\u6a21\u5f0f\uff0c\u8868\u660e\u5b58\u5728\u5d0e\u5c96\u3001\u5206\u5c42\u7ed3\u6784\u7684\u666f\u89c2\u3002", "motivation": "\u5f53\u524d\u63d0\u793a\u5de5\u7a0b\u65b9\u6cd5\u5c06\u63d0\u793a\u4f18\u5316\u89c6\u4e3a\u9ed1\u76d2\u95ee\u9898\uff0c\u7f3a\u4e4f\u5bf9\u4f18\u5316\u666f\u89c2\u62d3\u6251\u7ed3\u6784\u7684\u7406\u89e3\u3002\u672c\u6587\u65e8\u5728\u7cfb\u7edf\u5206\u6790\u63d0\u793a\u5de5\u7a0b\u4e2d\u7684\u9002\u5e94\u5ea6\u666f\u89c2\u7ed3\u6784\u3002", "method": "\u4f7f\u7528\u8bed\u4e49\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u81ea\u76f8\u5173\u5206\u6790\u65b9\u6cd5\uff0c\u5728\u9519\u8bef\u68c0\u6d4b\u4efb\u52a1\u4e0a\u6bd4\u8f83\u4e24\u79cd\u63d0\u793a\u751f\u6210\u7b56\u7565\uff1a\u7cfb\u7edf\u679a\u4e3e\uff081,024\u4e2a\u63d0\u793a\uff09\u548c\u65b0\u9896\u6027\u9a71\u52a8\u7684\u591a\u6837\u5316\u751f\u6210\uff081,000\u4e2a\u63d0\u793a\uff09\u3002", "result": "\u53d1\u73b0\u7cfb\u7edf\u5316\u63d0\u793a\u751f\u6210\u4ea7\u751f\u5e73\u6ed1\u8870\u51cf\u7684\u81ea\u76f8\u5173\uff0c\u800c\u591a\u6837\u5316\u751f\u6210\u5448\u73b0\u975e\u5355\u8c03\u6a21\u5f0f\uff0c\u5728\u4e2d\u7b49\u8bed\u4e49\u8ddd\u79bb\u5904\u51fa\u73b0\u5cf0\u503c\u76f8\u5173\u6027\uff0c\u8868\u660e\u5b58\u5728\u5d0e\u5c96\u3001\u5206\u5c42\u7ed3\u6784\u7684\u666f\u89c2\u3002\u4e0d\u540c\u9519\u8bef\u7c7b\u578b\u7684\u5d0e\u5c96\u7a0b\u5ea6\u5404\u5f02\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u7406\u89e3\u63d0\u793a\u5de5\u7a0b\u4f18\u5316\u666f\u89c2\u7684\u590d\u6742\u6027\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u63d0\u793a\u751f\u6210\u7b56\u7565\u4ea7\u751f\u7684\u4e0d\u540c\u666f\u89c2\u62d3\u6251\u7ed3\u6784\u3002"}}
{"id": "2509.05332", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05332", "abs": "https://arxiv.org/abs/2509.05332", "authors": ["Christos Anagnostopoulos", "Ioulia Kapsali", "Alexandros Gkillas", "Nikos Piperigkos", "Aris S. Lalos"], "title": "Integrated Simulation Framework for Adversarial Attacks on Autonomous Vehicles", "comment": "6 pages, 2 figures", "summary": "Autonomous vehicles (AVs) rely on complex perception and communication\nsystems, making them vulnerable to adversarial attacks that can compromise\nsafety. While simulation offers a scalable and safe environment for robustness\ntesting, existing frameworks typically lack comprehensive supportfor modeling\nmulti-domain adversarial scenarios. This paper introduces a novel, open-source\nintegrated simulation framework designed to generate adversarial attacks\ntargeting both perception and communication layers of AVs. The framework\nprovides high-fidelity modeling of physical environments, traffic dynamics, and\nV2X networking, orchestrating these components through a unified core that\nsynchronizes multiple simulators based on a single configuration file. Our\nimplementation supports diverse perception-level attacks on LiDAR sensor data,\nalong with communication-level threats such as V2X message manipulation and GPS\nspoofing. Furthermore, ROS 2 integration ensures seamless compatibility with\nthird-party AV software stacks. We demonstrate the framework's effectiveness by\nevaluating the impact of generated adversarial scenarios on a state-of-the-art\n3D object detector, revealing significant performance degradation under\nrealistic conditions.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5f00\u6e90\u96c6\u6210\u6a21\u62df\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u9488\u5bf9\u81ea\u4e3b\u9a7e\u9a76\u6c7d\u8f66\u611f\u77e5\u548c\u901a\u4fe1\u5c42\u7684\u591a\u57df\u653b\u51fb\u573a\u666f\uff0c\u901a\u8fc7\u540c\u6b65\u591a\u4e2a\u6a21\u62df\u5668\u6765\u8bc4\u4f30AV\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u3002", "motivation": "\u81ea\u4e3b\u9a7e\u9a76\u6c7d\u8f66\u7684\u611f\u77e5\u548c\u901a\u4fe1\u7cfb\u7edf\u5bb9\u6613\u53d7\u5230\u5bf9\u624b\u653b\u51fb\uff0c\u800c\u73b0\u6709\u6a21\u62df\u6846\u67b6\u7f3a\u4e4f\u5bf9\u591a\u57df\u653b\u51fb\u573a\u666f\u7684\u5168\u9762\u652f\u6301\uff0c\u9700\u8981\u4e00\u4e2a\u7efc\u5408\u6027\u7684\u6d4b\u8bd5\u73af\u5883\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u96c6\u6210\u6a21\u62df\u6846\u67b6\uff0c\u901a\u8fc7\u7edf\u4e00\u6838\u5fc3\u540c\u6b65\u591a\u4e2a\u6a21\u62df\u5668\uff08\u7269\u7406\u73af\u5883\u3001\u4ea4\u901a\u52a8\u6001\u3001V2X\u7f51\u7edc\uff09\uff0c\u652f\u6301LiDAR\u611f\u77e5\u653b\u51fb\u3001V2X\u6d88\u606f\u64cd\u63a7\u3001GPS\u6b3a\u9a97\u7b49\u591a\u79cd\u653b\u51fb\u65b9\u5f0f\uff0c\u5e76\u96c6\u6210ROS 2\u4ee5\u517c\u5bb9\u7b2c\u4e09\u65b9AV\u8f6f\u4ef6\u3002", "result": "\u5728\u73b0\u5b9e\u6761\u4ef6\u4e0b\uff0c\u5bf9\u73b0\u6709\u76843D\u7269\u4f53\u68c0\u6d4b\u5668\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u663e\u793a\u5728\u751f\u6210\u7684\u5bf9\u624b\u653b\u51fb\u573a\u666f\u4e0b\u7cfb\u7edf\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aAV\u5b89\u5168\u6027\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u4fdd\u771f\u5ea6\u3001\u53ef\u6269\u5c55\u7684\u6a21\u62df\u73af\u5883\uff0c\u80fd\u591f\u6709\u6548\u5730\u6d4b\u8bd5\u591a\u57df\u5bf9\u624b\u653b\u51fb\u5bf9AV\u7cfb\u7edf\u7684\u5f71\u54cd\u3002"}}
{"id": "2509.05995", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.05995", "abs": "https://arxiv.org/abs/2509.05995", "authors": ["Sharon Guardado", "Risha Parveen", "Zheying Zhang", "Maruf Rayhan", "Nirnaya Tripathi"], "title": "Students' Perception of LLM Use in Requirements Engineering Education: An Empirical Study Across Two Universities", "comment": "Accepted by the 33rd IEEE International Requirements Engineering 2025\n  (RE'25), Valencia, Spain, September 1-5, 2025", "summary": "The integration of Large Language Models (LLMs) in Requirements Engineering\n(RE) education is reshaping pedagogical approaches, seeking to enhance student\nengagement and motivation while providing practical tools to support their\nprofessional future. This study empirically evaluates the impact of integrating\nLLMs in RE coursework. We examined how the guided use of LLMs influenced\nstudents' learning experiences, and what benefits and challenges they perceived\nin using LLMs in RE practices. The study collected survey data from 179\nstudents across two RE courses in two universities. LLMs were integrated into\ncoursework through different instructional formats, i.e., individual\nassignments versus a team-based Agile project. Our findings indicate that LLMs\nimproved students' comprehension of RE concepts, particularly in tasks like\nrequirements elicitation and documentation. However, students raised concerns\nabout LLMs in education, including academic integrity, overreliance on AI, and\nchallenges in integrating AI-generated content into assignments. Students who\nworked on individual assignments perceived that they benefited more than those\nwho worked on team-based assignments, highlighting the importance of contextual\nAI integration. This study offers recommendations for the effective integration\nof LLMs in RE education. It proposes future research directions for balancing\nAI-assisted learning with critical thinking and collaborative practices in RE\ncourses.", "AI": {"tldr": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9700\u6c42\u5de5\u7a0b\u6559\u80b2\u4e2d\u7684\u96c6\u6210\u80fd\u591f\u63d0\u5347\u5b66\u751f\u5bf9\u9700\u6c42\u5de5\u7a0b\u6982\u5ff5\u7684\u7406\u89e3\uff0c\u4f46\u5b58\u5728\u5b66\u672f\u6210\u6570\u548c\u8fc7\u5ea6\u4f9d\u8d56AI\u7684\u98ce\u9669\u3002\u4e2a\u4eba\u4f5c\u4e1a\u6bd4\u56e2\u961f\u4f5c\u4e1a\u66f4\u6709\u6548\uff0c\u4e0a\u4e0b\u6587\u5316\u96c6\u6210\u5f88\u91cd\u8981\u3002", "motivation": "\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9700\u6c42\u5de5\u7a0b\u6559\u80b2\u4e2d\u7684\u5f71\u54cd\uff0c\u63d0\u5347\u5b66\u751f\u53c2\u4e0e\u5ea6\u548c\u52a8\u673a\uff0c\u4e3a\u5176\u672a\u6765\u804c\u4e1a\u53d1\u5c55\u63d0\u4f9b\u5b9e\u7528\u5de5\u5177\u652f\u6301\u3002", "method": "\u5728\u4e24\u6240\u5927\u5b66\u76842\u95e8\u9700\u6c42\u5de5\u7a0b\u8bfe\u7a0b\u4e2d\uff0c\u901a\u8fc7\u4e2a\u4eba\u4f5c\u4e1a\u548c\u56e2\u961f\u57fa\u7840\u7684\u6f3e\u52a8\u9879\u76ee\u4e24\u79cd\u6559\u5b66\u683c\u5f0f\u96c6\u6210LLMs\uff0c\u6536\u96c6\u4e86179\u540d\u5b66\u751f\u7684\u8c03\u67e5\u6570\u636e\u3002", "result": "LLMs\u63d0\u9ad8\u4e86\u5b66\u751f\u5bf9\u9700\u6c42\u5de5\u7a0b\u6982\u5ff5\u7684\u7406\u89e3\uff0c\u7279\u522b\u662f\u5728\u9700\u6c42\u83b7\u53d6\u548c\u6587\u6863\u5316\u4efb\u52a1\u4e2d\u3002\u4f46\u5b66\u751f\u62c5\u5fc3\u5b66\u672f\u6210\u6570\u3001\u8fc7\u5ea6\u4f9d\u8d56AI\u4ee5\u53ca\u5c06AI\u751f\u6210\u5185\u5bb9\u6574\u5408\u5230\u4f5c\u4e1a\u4e2d\u7684\u6311\u6218\u3002\u4e2a\u4eba\u4f5c\u4e1a\u6bd4\u56e2\u961f\u4f5c\u4e1a\u6548\u679c\u66f4\u597d\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u4e86\u6709\u6548\u96c6\u6210LLMs\u5230\u9700\u6c42\u5de5\u7a0b\u6559\u80b2\u4e2d\u7684\u5efa\u8bae\uff0c\u5e76\u5efa\u8bae\u672a\u6765\u7814\u7a76\u5e94\u5173\u6ce8\u5982\u4f55\u5728\u9700\u6c42\u5de5\u7a0b\u8bfe\u7a0b\u4e2d\u5e73\u8861AI\u8f85\u52a9\u5b66\u4e60\u4e0e\u6279\u5224\u6027\u601d\u7ef4\u548c\u534f\u4f5c\u5b9e\u8df5\u3002"}}
{"id": "2509.05378", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.05378", "abs": "https://arxiv.org/abs/2509.05378", "authors": ["Andreas Motzfeldt", "Joakim Edin", "Casper L. Christensen", "Christian Hardmeier", "Lars Maal\u00f8e", "Anna Rogers"], "title": "Code Like Humans: A Multi-Agent Solution for Medical Coding", "comment": "EMNLP Findings 2025", "summary": "In medical coding, experts map unstructured clinical notes to alphanumeric\ncodes for diagnoses and procedures. We introduce Code Like Humans: a new\nagentic framework for medical coding with large language models. It implements\nofficial coding guidelines for human experts, and it is the first solution that\ncan support the full ICD-10 coding system (+70K labels). It achieves the best\nperformance to date on rare diagnosis codes (fine-tuned discriminative\nclassifiers retain an advantage for high-frequency codes, to which they are\nlimited). Towards future work, we also contribute an analysis of system\nperformance and identify its `blind spots' (codes that are systematically\nundercoded).", "AI": {"tldr": "\u63d0\u51faCode Like Humans\u6846\u67b6\uff0c\u9996\u4e2a\u652f\u6301\u5b8c\u6574ICD-10\u7f16\u7801\u7cfb\u7edf\uff087\u4e07+\u6807\u7b7e\uff09\u7684\u533b\u7597\u7f16\u7801\u4ee3\u7406\u6846\u67b6\uff0c\u5728\u7f55\u89c1\u8bca\u65ad\u4ee3\u7801\u4e0a\u8fbe\u5230\u6700\u4f73\u6027\u80fd", "motivation": "\u533b\u7597\u7f16\u7801\u9700\u8981\u5c06\u975e\u7ed3\u6784\u5316\u4e34\u5e8a\u8bb0\u5f55\u6620\u5c04\u5230\u8bca\u65ad\u548c\u7a0b\u5e8f\u4ee3\u7801\uff0c\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u652f\u6301\u5b8c\u6574\u7684ICD-10\u7f16\u7801\u7cfb\u7edf", "method": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7406\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u5b98\u65b9\u4eba\u5de5\u4e13\u5bb6\u7f16\u7801\u6307\u5357", "result": "\u5728\u7f55\u89c1\u8bca\u65ad\u4ee3\u7801\u4e0a\u8fbe\u5230\u6700\u4f73\u6027\u80fd\uff0c\u4f46\u5fae\u8c03\u5224\u522b\u5206\u7c7b\u5668\u5728\u9ad8\u9891\u4ee3\u7801\u4e0a\u4ecd\u4fdd\u6301\u4f18\u52bf", "conclusion": "\u8d21\u732e\u4e86\u7cfb\u7edf\u6027\u80fd\u5206\u6790\u5e76\u8bc6\u522b\u4e86\u7cfb\u7edf\u6027\u7684\u7f16\u7801\u76f2\u70b9\uff08\u88ab\u7cfb\u7edf\u4f4e\u4f30\u7684\u4ee3\u7801\uff09\uff0c\u4e3a\u672a\u6765\u5de5\u4f5c\u63d0\u4f9b\u65b9\u5411"}}
{"id": "2509.05350", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.05350", "abs": "https://arxiv.org/abs/2509.05350", "authors": ["Joshua Ward", "Yuxuan Yang", "Chi-Hua Wang", "Guang Cheng"], "title": "Ensembling Membership Inference Attacks Against Tabular Generative Models", "comment": null, "summary": "Membership Inference Attacks (MIAs) have emerged as a principled framework\nfor auditing the privacy of synthetic data generated by tabular generative\nmodels, where many diverse methods have been proposed that each exploit\ndifferent privacy leakage signals. However, in realistic threat scenarios, an\nadversary must choose a single method without a priori guarantee that it will\nbe the empirically highest performing option. We study this challenge as a\ndecision theoretic problem under uncertainty and conduct the largest synthetic\ndata privacy benchmark to date. Here, we find that no MIA constitutes a\nstrictly dominant strategy across a wide variety of model architectures and\ndataset domains under our threat model. Motivated by these findings, we propose\nensemble MIAs and show that unsupervised ensembles built on individual attacks\noffer empirically more robust, regret-minimizing strategies than individual\nattacks.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5408\u6210\u6570\u636e\u9690\u79c1\u5ba1\u8ba1\u4e2d\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb(MIA)\u9009\u62e9\u95ee\u9898\uff0c\u53d1\u73b0\u5728\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u548c\u6570\u636e\u96c6\u4e0a\u6ca1\u6709\u4e00\u4e2aMIA\u65b9\u6cd5\u59cb\u7ec8\u6700\u4f18\uff0c\u56e0\u6b64\u63d0\u51fa\u4e86\u57fa\u4e8e\u96c6\u6210\u5b66\u4e60\u7684MIA\u65b9\u6cd5\u6765\u5b9e\u73b0\u66f4\u7a33\u5065\u7684\u9690\u79c1\u4fdd\u62a4\u7b56\u7565\u3002", "motivation": "\u5728\u5408\u6210\u6570\u636e\u751f\u6210\u7684\u9690\u79c1\u5ba1\u8ba1\u4e2d\uff0c\u73b0\u6709\u7684\u591a\u79cd\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\u5404\u6709\u4f18\u52bf\uff0c\u4f46\u5728\u5b9e\u9645\u5a01\u80c1\u573a\u666f\u4e2d\uff0c\u653b\u51fb\u8005\u9700\u8981\u9009\u62e9\u4e00\u4e2a\u6700\u4f18\u65b9\u6cd5\u800c\u7f3a\u4e4f\u5148\u9a8c\u4fdd\u8bc1\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u51b3\u7b56\u7406\u8bba\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u8fdb\u884c\u5927\u89c4\u6a21\u5408\u6210\u6570\u636e\u9690\u79c1\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5206\u6790\u4e0d\u540cMIA\u65b9\u6cd5\u5728\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u548c\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u65e0\u76d1\u7763\u96c6\u6210\u5b66\u4e60\u7684MIA\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6ca1\u6709\u4e00\u4e2aMIA\u65b9\u6cd5\u5728\u6240\u6709\u60c5\u51b5\u4e0b\u90fd\u662f\u4e25\u683c\u6700\u4f18\u7b56\u7565\u3002\u63d0\u51fa\u7684\u96c6\u6210MIA\u65b9\u6cd5\u76f8\u6bd4\u5355\u4e2a\u653b\u51fb\u65b9\u6cd5\u8868\u73b0\u51fa\u66f4\u7a33\u5065\u7684\u6027\u80fd\u548c\u66f4\u5c0f\u7684\u540e\u6094\u503c\u3002", "conclusion": "\u96c6\u6210MIA\u65b9\u6cd5\u4e3a\u89e3\u51b3\u5408\u6210\u6570\u636e\u9690\u79c1\u5ba1\u8ba1\u4e2d\u7684\u65b9\u6cd5\u9009\u62e9\u4e0d\u786e\u5b9a\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5b9e\u73b0\u540e\u6094\u6700\u5c0f\u5316\u7684\u7a33\u5065\u7b56\u7565\u3002"}}
{"id": "2509.06012", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.06012", "abs": "https://arxiv.org/abs/2509.06012", "authors": ["Jukka Ruohonen"], "title": "A Rapid Review Regarding the Concept of Legal Requirements in Requirements Engineering", "comment": "Submitted to REFSQ 2026", "summary": "Out of a personal puzzlement, recent peer review comments, and demonstrable\nconfusion in the existing literature, the paper presents a rapid review of the\nconcept of legal requirements (LRs) in requirements engineering (RE) research.\nAccording to reviewing results, a normative understanding of LRs has often been\npresent, although proper definitions and conceptual operationalizations are\nlacking. Some papers also see LRs as functional and others as non-functional\nrequirements. Legal requirements are often characterized as being vague and\ncomplex, requiring a lot of effort to elicit, implement, and validate. These\ncharacterizations supposedly correlate with knowledge gaps among requirements\nengineers. LRs are also seen to often change and overlap. They may be also\nprioritized. According to the literature, they seem to be also reluctantly\nimplemented, often providing only a minimal baseline for other requirements.\nWith these and other observations, the review raises critical arguments about\napparent knowledge gaps, including a lack of empirical evidence backing the\nobservations and enduring conceptual confusion.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u5feb\u901f\u5ba1\u67e5\u5206\u6790\u4e86\u9700\u6c42\u5de5\u7a0b\u9886\u57df\u4e2d\u6cd5\u5f8b\u8981\u6c42\u7684\u6982\u5ff5\uff0c\u53d1\u73b0\u5b58\u5728\u6982\u5ff5\u6df7\u4e71\u3001\u7f3a\u4e4f\u660e\u786e\u5b9a\u4e49\u548c\u5b9e\u8bc1\u8bc1\u636e\u652f\u6491\u7b49\u95ee\u9898\u3002", "motivation": "\u51fa\u4e8e\u4e2a\u4eba\u56f0\u60d1\u3001\u540c\u884c\u8bc4\u5ba1\u610f\u89c1\u4ee5\u53ca\u73b0\u6709\u6587\u732e\u4e2d\u5b58\u5728\u7684\u660e\u663e\u6df7\u4e71\uff0c\u9700\u8981\u5bf9\u6cd5\u5f8b\u8981\u6c42\u6982\u5ff5\u8fdb\u884c\u7cfb\u7edf\u6027\u5206\u6790\u3002", "method": "\u91c7\u7528\u5feb\u901f\u5ba1\u67e5\u65b9\u6cd5\uff0c\u5bf9\u9700\u6c42\u5de5\u7a0b\u7814\u7a76\u9886\u57df\u4e2d\u5173\u4e8e\u6cd5\u5f8b\u8981\u6c42\u7684\u73b0\u6709\u6587\u732e\u8fdb\u884c\u7efc\u5408\u5206\u6790\u3002", "result": "\u53d1\u73b0\u5b58\u5728\u89c4\u8303\u6027\u7406\u89e3\uff0c\u4f46\u7f3a\u4e4f\u6b63\u786e\u5b9a\u4e49\u548c\u6982\u5ff5\u64cd\u4f5c\u5316\uff1b\u6cd5\u5f8b\u8981\u6c42\u88ab\u8ba4\u4e3a\u6a21\u7cca\u590d\u6742\u3001\u66f4\u65b0\u9891\u7e41\u3001\u5b9e\u65bd\u56f0\u96be\uff1b\u5b58\u5728\u77e5\u8bc6\u7a7a\u767d\u548c\u7f3a\u4e4f\u5b9e\u8bc1\u8bc1\u636e\u652f\u6491\u3002", "conclusion": "\u8bc4\u4f30\u7ed3\u679c\u63d0\u51fa\u4e86\u5173\u4e8e\u77e5\u8bc6\u7a7a\u767d\u7684\u6279\u5224\u6027\u8bba\u65ad\uff0c\u5f3a\u8c03\u9700\u8981\u66f4\u591a\u5b9e\u8bc1\u8bc1\u636e\u6765\u652f\u6491\u89c2\u5bdf\u7ed3\u8bba\uff0c\u5e76\u89e3\u51b3\u6301\u7eed\u7684\u6982\u5ff5\u6df7\u4e71\u95ee\u9898\u3002"}}
{"id": "2509.05381", "categories": ["cs.AI", "cs.LG", "68T01, 68T20, 68Q87"], "pdf": "https://arxiv.org/pdf/2509.05381", "abs": "https://arxiv.org/abs/2509.05381", "authors": ["Madhava Gaikwad"], "title": "Murphys Laws of AI Alignment: Why the Gap Always Wins", "comment": "21 pages", "summary": "Large language models are increasingly aligned to human preferences through\nreinforcement learning from human feedback (RLHF) and related methods such as\nDirect Preference Optimization (DPO), Constitutional AI, and RLAIF. While\neffective, these methods exhibit recurring failure patterns i.e., reward\nhacking, sycophancy, annotator drift, and misgeneralization. We introduce the\nconcept of the Alignment Gap, a unifying lens for understanding recurring\nfailures in feedback-based alignment. Using a KL-tilting formalism, we\nillustrate why optimization pressure tends to amplify divergence between proxy\nrewards and true human intent. We organize these failures into a catalogue of\nMurphys Laws of AI Alignment, and propose the Alignment Trilemma as a way to\nframe trade-offs among optimization strength, value capture, and\ngeneralization. Small-scale empirical studies serve as illustrative support.\nFinally, we propose the MAPS framework (Misspecification, Annotation, Pressure,\nShift) as practical design levers. Our contribution is not a definitive\nimpossibility theorem but a perspective that reframes alignment debates around\nstructural limits and trade-offs, offering clearer guidance for future design.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5bf9\u9f50\u5dee\u8ddd\u6982\u5ff5\uff0c\u901a\u8fc7KL\u503e\u659c\u5f62\u5f0f\u5316\u89e3\u91ca\u4e86\u4e3a\u4ec0\u4e48\u4f18\u5316\u538b\u529b\u4f1a\u653e\u5927\u4ee3\u7406\u5956\u52b1\u4e0e\u771f\u5b9e\u4eba\u7c7b\u610f\u56fe\u4e4b\u95f4\u7684\u5206\u6b67\uff0c\u5e76\u63d0\u51fa\u4e86AI\u5bf9\u9f50\u7684\u58a8\u83f2\u5b9a\u5f8b\u5206\u7c7b\u548c\u4e09\u5143\u6096\u8bba\u6846\u67b6\u3002", "motivation": "\u73b0\u6709\u7684\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u65b9\u6cd5\uff08\u5982RLHF\u3001DPO\u7b49\uff09\u867d\u7136\u6709\u6548\uff0c\u4f46\u5b58\u5728\u5956\u52b1\u7834\u89e3\u3001\u5949\u627f\u3001\u6807\u6ce8\u8005\u6f02\u79fb\u548c\u9519\u8bef\u6cdb\u5316\u7b49\u91cd\u590d\u6027\u5931\u8d25\u6a21\u5f0f\uff0c\u9700\u8981\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u6765\u7406\u89e3\u8fd9\u4e9b\u5931\u8d25\u7684\u6839\u672c\u539f\u56e0\u3002", "method": "\u4f7f\u7528KL\u503e\u659c\u5f62\u5f0f\u5316\u5206\u6790\u4f18\u5316\u538b\u529b\u5bf9\u4ee3\u7406\u5956\u52b1\u4e0e\u771f\u5b9e\u610f\u56fe\u5206\u6b67\u7684\u5f71\u54cd\uff0c\u7ec4\u7ec7\u5931\u8d25\u6a21\u5f0f\u4e3a\u58a8\u83f2\u5b9a\u5f8b\u5206\u7c7b\uff0c\u63d0\u51fa\u5bf9\u9f50\u4e09\u5143\u6096\u8bba\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u5c0f\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5efa\u7acb\u4e86\u5bf9\u9f50\u5dee\u8ddd\u7684\u7edf\u4e00\u7406\u8bba\u89c6\u89d2\uff0c\u7cfb\u7edf\u5206\u7c7b\u4e86AI\u5bf9\u9f50\u4e2d\u7684\u5e38\u89c1\u5931\u8d25\u6a21\u5f0f\uff0c\u63d0\u51fa\u4e86MAPS\u6846\u67b6\u4f5c\u4e3a\u5b9e\u9645\u8bbe\u8ba1\u6760\u6746\u3002", "conclusion": "\u672c\u6587\u4e0d\u662f\u63d0\u51fa\u4e0d\u53ef\u80fd\u5b9a\u7406\uff0c\u800c\u662f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u91cd\u6784\u5bf9\u9f50\u8fa9\u8bba\u7684\u89c6\u89d2\uff0c\u56f4\u7ed5\u7ed3\u6784\u9650\u5236\u548c\u6743\u8861\u63d0\u4f9b\u66f4\u6e05\u6670\u7684\u8bbe\u8ba1\u6307\u5bfc\uff0c\u4e3a\u672a\u6765\u5bf9\u9f50\u65b9\u6cd5\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u8df5\u5de5\u5177\u3002"}}
{"id": "2509.05362", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2509.05362", "abs": "https://arxiv.org/abs/2509.05362", "authors": ["Ismail Hossain", "Sai Puppala", "Sajedul Talukder", "Md Jahangir Alam"], "title": "AI-in-the-Loop: Privacy Preserving Real-Time Scam Detection and Conversational Scambaiting by Leveraging LLMs and Federated Learning", "comment": "This paper got accepted in 26th Privacy Enhancing Technologies\n  Symposium (PETS 2026). We uploaded it into ArXiv as pre-print", "summary": "Scams exploiting real-time social engineering -- such as phishing,\nimpersonation, and phone fraud -- remain a persistent and evolving threat\nacross digital platforms. Existing defenses are largely reactive, offering\nlimited protection during active interactions. We propose a privacy-preserving,\nAI-in-the-loop framework that proactively detects and disrupts scam\nconversations in real time. The system combines instruction-tuned artificial\nintelligence with a safety-aware utility function that balances engagement with\nharm minimization, and employs federated learning to enable continual model\nupdates without raw data sharing. Experimental evaluations show that the system\nproduces fluent and engaging responses (perplexity as low as 22.3, engagement\n$\\approx$0.80), while human studies confirm significant gains in realism,\nsafety, and effectiveness over strong baselines. In federated settings, models\ntrained with FedAvg sustain up to 30 rounds while preserving high engagement\n($\\approx$0.80), strong relevance ($\\approx$0.74), and low PII leakage\n($\\leq$0.0085). Even with differential privacy, novelty and safety remain\nstable, indicating that robust privacy can be achieved without sacrificing\nperformance. The evaluation of guard models (LlamaGuard, LlamaGuard2/3,\nMD-Judge) shows a straightforward pattern: stricter moderation settings reduce\nthe chance of exposing personal information, but they also limit how much the\nmodel engages in conversation. In contrast, more relaxed settings allow longer\nand richer interactions, which improve scam detection, but at the cost of\nhigher privacy risk. To our knowledge, this is the first framework to unify\nreal-time scam-baiting, federated privacy preservation, and calibrated safety\nmoderation into a proactive defense paradigm.", "AI": {"tldr": "\u4e00\u79cd\u4fdd\u62a4\u9690\u79c1\u7684AI\u5b9e\u65f6\u9a97\u5c40\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u90a6\u5b66\u4e60\u548c\u5b89\u5168\u8c03\u6574\u51fd\u6570\uff0c\u5728\u4fdd\u6301\u6d41\u7545\u4ea4\u4e92\u7684\u540c\u65f6\u4e3b\u52a8\u963b\u65ad\u9a97\u5c40\u5bf9\u8bdd\u3002", "motivation": "\u73b0\u6709\u9632\u5fa1\u63aa\u65bd\u591a\u4e3a\u53cd\u5e94\u5f0f\uff0c\u5728\u6d3b\u8dc3\u4ea4\u4e92\u4e2d\u63d0\u4f9b\u7684\u4fdd\u62a4\u6709\u9650\uff0c\u9700\u8981\u4e3b\u52a8\u9886\u5148\u7684\u9a97\u5c40\u9632\u5fa1\u65b9\u6848\u3002", "method": "\u7ed3\u5408\u6307\u4ee4\u8c03\u6574\u7684\u4eba\u5de5\u667a\u80fd\u4e0e\u5b89\u5168\u610f\u8bc6\u7684\u5e94\u7528\u51fd\u6570\uff0c\u91c7\u7528\u8054\u90a6\u5b66\u4e60\u5b9e\u73b0\u6301\u7eed\u6a21\u578b\u66f4\u65b0\u800c\u65e0\u9700\u539f\u59cb\u6570\u636e\u5171\u4eab\u3002", "result": "\u7cfb\u7edf\u80fd\u591f\u4ea7\u751f\u6d41\u7545\u4e14\u5f15\u4eba\u5165\u80dc\u7684\u56de\u5e94\uff0c\u4eba\u7c7b\u7814\u7a76\u8bc1\u5b9e\u5728\u771f\u5b9e\u6027\u3001\u5b89\u5168\u6027\u548c\u6709\u6548\u6027\u65b9\u9762\u663e\u8457\u8d85\u8d8a\u57fa\u51c6\u7ebf\u3002\u8054\u90a6\u5b66\u4e60\u5728\u4fdd\u6301\u9ad8\u4ea4\u4e92\u6027\u7684\u540c\u65f6\u51cf\u5c11\u4e2a\u4eba\u4fe1\u606f\u6cc4\u6f0f\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u5c06\u5b9e\u65f6\u9a97\u5c40\u8be2\u95ee\u3001\u8054\u90a6\u9690\u79c1\u4fdd\u62a4\u548c\u5b89\u5168\u8c03\u6574\u7edf\u4e00\u4e3a\u4e00\u4f53\uff0c\u6784\u5efa\u4e86\u4e3b\u52a8\u9632\u5fa1\u8303\u5f0f\uff0c\u5728\u4e0d\u727a\u7272\u6027\u80fd\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u4e86\u7a33\u5065\u7684\u9690\u79c1\u4fdd\u62a4\u3002"}}
{"id": "2509.06052", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2509.06052", "abs": "https://arxiv.org/abs/2509.06052", "authors": ["Qingyuan Li", "Binchang Li", "Cuiyun Gao", "Shuzheng Gao", "Zongjie Li"], "title": "Empirical Study of Code Large Language Models for Binary Security Patch Detection", "comment": null, "summary": "Security patch detection (SPD) is crucial for maintaining software security,\nas unpatched vulnerabilities can lead to severe security risks. In recent\nyears, numerous learning-based SPD approaches have demonstrated promising\nresults on source code. However, these approaches typically cannot be applied\nto closed-source applications and proprietary systems that constitute a\nsignificant portion of real-world software, as they release patches only with\nbinary files, and the source code is inaccessible. Given the impressive\nperformance of code large language models (LLMs) in code intelligence and\nbinary analysis tasks such as decompilation and compilation optimization, their\npotential for detecting binary security patches remains unexplored, exposing a\nsignificant research gap between their demonstrated low-level code\nunderstanding capabilities and this critical security task. To address this\ngap, we construct a large-scale binary patch dataset containing \\textbf{19,448}\nsamples, with two levels of representation: assembly code and pseudo-code, and\nsystematically evaluate \\textbf{19} code LLMs of varying scales to investigate\ntheir capability in binary SPD tasks. Our initial exploration demonstrates that\ndirectly prompting vanilla code LLMs struggles to accurately identify security\npatches from binary patches, and even state-of-the-art prompting techniques\nfail to mitigate the lack of domain knowledge in binary SPD within vanilla\nmodels. Drawing on the initial findings, we further investigate the fine-tuning\nstrategy for injecting binary SPD domain knowledge into code LLMs through two\nlevels of representation. Experimental results demonstrate that fine-tuned LLMs\nachieve outstanding performance, with the best results obtained on the\npseudo-code representation.", "AI": {"tldr": "\u4e8c\u8fdb\u5236\u5b89\u5168\u8865\u4e01\u68c0\u6d4b\u7684\u91cd\u8981\u6027\u4e0e\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u6784\u5efa\u5927\u89c4\u6a21\u4e8c\u8fdb\u5236\u8865\u4e01\u6570\u636e\u96c6\u5e76\u7cfb\u7edf\u8bc4\u4f3019\u4e2a\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u53d1\u73b0\u7ec6\u8c03\u7b56\u7565\u80fd\u591f\u663e\u8457\u63d0\u5347\u6a21\u578b\u5728\u4e8c\u8fdb\u5236\u5b89\u5168\u8865\u4e01\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd", "motivation": "\u73b0\u6709\u5b66\u4e60\u57fa\u4e8eSPD\u65b9\u6cd5\u4e3b\u8981\u9762\u5411\u6e90\u4ee3\u7801\uff0c\u65e0\u6cd5\u5e94\u7528\u4e8e\u53d1\u5e03\u4e8c\u8fdb\u5236\u6587\u4ef6\u7684\u95ed\u6e90\u8f6f\u4ef6\u548c\u4e13\u6709\u7cfb\u7edf\uff0c\u800c\u8fd9\u4e9b\u7cfb\u7edf\u5360\u5b9e\u9645\u8f6f\u4ef6\u7684\u8bb8\u591a\u90e8\u5206\u3002\u4ee3\u7801LLM\u5728\u4e8c\u8fdb\u5236\u5206\u6790\u4efb\u52a1\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u4f46\u5176\u5728\u4e8c\u8fdb\u5236\u5b89\u5168\u8865\u4e01\u68c0\u6d4b\u4e2d\u7684\u6f5c\u529b\u4ecd\u672a\u5f97\u5230\u63a2\u7d22", "method": "\u6784\u5efa\u5305\u542b19,448\u4e2a\u6837\u672c\u7684\u5927\u89c4\u6a21\u4e8c\u8fdb\u5236\u8865\u4e01\u6570\u636e\u96c6\uff0c\u63d0\u4f9b\u6c47\u7f16\u4ee3\u7801\u548c\u4f2a\u4ee3\u7801\u4e24\u79cd\u8868\u793a\u5f62\u5f0f\u3002\u7cfb\u7edf\u8bc4\u4f3019\u4e2a\u4e0d\u540c\u89c4\u6a21\u7684\u4ee3\u7801LLM\uff0c\u8fdb\u884c\u521d\u59cb\u63a2\u7d22\u548c\u7ec6\u8c03\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u4e24\u79cd\u8868\u793a\u5f62\u5f0f\u7684\u6548\u679c", "result": "\u76f4\u63a5\u63d0\u95ee\u666e\u901a\u4ee3\u7801LLM\u65e0\u6cd5\u51c6\u786e\u8bc6\u522b\u5b89\u5168\u8865\u4e01\uff0c\u751a\u81f3\u6700\u5148\u8fdb\u7684\u63d0\u95ee\u6280\u672f\u4e5f\u65e0\u6cd5\u8865\u507f\u6a21\u578b\u5728\u4e8c\u8fdb\u5236SPD\u9886\u57df\u77e5\u8bc6\u7684\u7f3a\u4e4f\u3002\u7ec6\u8c03\u540e\u7684LLM\u53d6\u5f97\u4e86\u7a81\u51fa\u7684\u6027\u80fd\uff0c\u5176\u4e2d\u4f2a\u4ee3\u7801\u8868\u793a\u5f62\u5f0f\u7684\u6548\u679c\u6700\u4f73", "conclusion": "\u901a\u8fc7\u7ec6\u8c03\u7b56\u7565\u5411\u4ee3\u7801LLM\u6ce8\u5165\u4e8c\u8fdb\u5236\u5b89\u5168\u8865\u4e01\u68c0\u6d4b\u9886\u57df\u77e5\u8bc6\u662f\u6709\u6548\u7684\uff0c\u4f2a\u4ee3\u7801\u8868\u793a\u5728\u8fd9\u4e00\u4efb\u52a1\u4e2d\u663e\u793a\u51fa\u66f4\u597d\u7684\u6548\u679c\uff0c\u4e3a\u95ed\u6e90\u8f6f\u4ef6\u5b89\u5168\u8865\u4e01\u68c0\u6d4b\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.05469", "categories": ["cs.AI", "cs.CV", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.05469", "abs": "https://arxiv.org/abs/2509.05469", "authors": ["Chenguang Wang", "Xiang Yan", "Yilong Dai", "Ziyi Wang", "Susu Xu"], "title": "From Image Generation to Infrastructure Design: a Multi-agent Pipeline for Street Design Generation", "comment": "21 pages, 8 figures", "summary": "Realistic visual renderings of street-design scenarios are essential for\npublic engagement in active transportation planning. Traditional approaches are\nlabor-intensive, hindering collective deliberation and collaborative\ndecision-making. While AI-assisted generative design shows transformative\npotential by enabling rapid creation of design scenarios, existing generative\napproaches typically require large amounts of domain-specific training data and\nstruggle to enable precise spatial variations of design/configuration in\ncomplex street-view scenes. We introduce a multi-agent system that edits and\nredesigns bicycle facilities directly on real-world street-view imagery. The\nframework integrates lane localization, prompt optimization, design generation,\nand automated evaluation to synthesize realistic, contextually appropriate\ndesigns. Experiments across diverse urban scenarios demonstrate that the system\ncan adapt to varying road geometries and environmental conditions, consistently\nyielding visually coherent and instruction-compliant results. This work\nestablishes a foundation for applying multi-agent pipelines to transportation\ninfrastructure planning and facility design.", "AI": {"tldr": "\u57fa\u4e8e\u591a\u6bb5\u7cfb\u7edf\u7684\u81ea\u52a8\u5316\u8857\u9053\u8bbe\u8ba1\u751f\u6210\u65b9\u6848\uff0c\u80fd\u591f\u76f4\u63a5\u5728\u771f\u5b9e\u8857\u666f\u56fe\u50cf\u4e0a\u7f16\u8f91\u548c\u91cd\u65b0\u8bbe\u8ba1\u81ea\u884c\u8f66\u8bbe\u65bd\uff0c\u63d0\u9ad8\u516c\u4f17\u53c2\u4e0e\u6548\u7387", "motivation": "\u4f20\u7edf\u8857\u9053\u8bbe\u8ba1\u6e32\u67d3\u65b9\u6848\u8017\u65f6\u8017\u529b\uff0c\u5f71\u54cd\u96c6\u4f53\u51b3\u7b56\uff1b\u73b0\u6709AI\u751f\u6210\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u9886\u57df\u6570\u636e\u4e14\u96be\u4ee5\u7cbe\u786e\u63a7\u5236\u590d\u6742\u8857\u666f\u4e2d\u7684\u7a7a\u95f4\u53d8\u5316", "method": "\u591a\u6bb5\u7cfb\u7edf\u96c6\u6210\u8f66\u9053\u5b9a\u4f4d\u3001\u63d0\u793a\u4f18\u5316\u3001\u8bbe\u8ba1\u751f\u6210\u548c\u81ea\u52a8\u8bc4\u4f30\u6a21\u5757\uff0c\u76f4\u63a5\u5728\u771f\u5b9e\u8857\u666f\u56fe\u50cf\u4e0a\u7f16\u8f91\u81ea\u884c\u8f66\u8bbe\u65bd", "result": "\u7cfb\u7edf\u5728\u591a\u6837\u5316\u57ce\u5e02\u573a\u666f\u4e2d\u90fd\u80fd\u9002\u5e94\u4e0d\u540c\u8def\u5f84\u5f62\u72b6\u548c\u73af\u5883\u6761\u4ef6\uff0c\u4ea7\u751f\u89c6\u89c9\u4e00\u81f4\u4e14\u7b26\u5408\u6307\u4ee4\u8981\u6c42\u7684\u7ed3\u679c", "conclusion": "\u4e3a\u591a\u6bb5\u7cfb\u7edf\u5728\u4ea4\u901a\u57fa\u7840\u8bbe\u65bd\u89c4\u5212\u548c\u8bbe\u8ba1\u9886\u57df\u7684\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840"}}
{"id": "2509.05366", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2509.05366", "abs": "https://arxiv.org/abs/2509.05366", "authors": ["Umair Amjid", "M. Umar Khan", "S. A. Manan Kirmani"], "title": "A Framework for Detection and Classification of Attacks on Surveillance Cameras under IoT Networks", "comment": null, "summary": "The increasing use of Internet of Things (IoT) devices has led to a rise in\nsecurity related concerns regarding IoT Networks. The surveillance cameras in\nIoT networks are vulnerable to security threats such as brute force and\nzero-day attacks which can lead to unauthorized access by hackers and potential\nspying on the users activities. Moreover, these cameras can be targeted by\nDenial of Service (DOS) attacks, which will make it unavailable for the user.\nThe proposed AI based framework will leverage machine learning algorithms to\nanalyze network traffic and detect anomalous behavior, allowing for quick\ndetection and response to potential intrusions. The framework will be trained\nand evaluated using real-world datasets to learn from past security incidents\nand improve its ability to detect potential intrusion.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eAI\u7684\u6846\u67b6\uff0c\u5229\u7528\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5206\u6790\u7f51\u7edc\u6d41\u91cf\uff0c\u68c0\u6d4b\u7269\u8054\u7f51\u6444\u50cf\u5934\u7f51\u7edc\u4e2d\u7684\u5f02\u5e38\u884c\u4e3a\u548c\u5b89\u5168\u5a01\u80c1", "motivation": "\u7269\u8054\u7f51\u8bbe\u5907\u4f7f\u7528\u589e\u52a0\u5bfc\u81f4\u5b89\u5168\u62c5\u5fe7\uff0c\u7279\u522b\u662f\u76d1\u63a7\u6444\u50cf\u5934\u6613\u53d7\u66b4\u529b\u7834\u89e3\u3001\u96f6\u65e5\u653b\u51fb\u548cDoS\u653b\u51fb\uff0c\u53ef\u80fd\u5bfc\u81f4\u9ed1\u5ba2\u672a\u6388\u6743\u8bbf\u95ee\u548c\u7528\u6237\u6d3b\u52a8\u76d1\u63a7", "method": "\u57fa\u4e8eAI\u7684\u6846\u67b6\uff0c\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5206\u6790\u7f51\u7edc\u6d41\u91cf\uff0c\u68c0\u6d4b\u5f02\u5e38\u884c\u4e3a\uff0c\u5229\u7528\u771f\u5b9e\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30", "result": "\u80fd\u591f\u5feb\u901f\u68c0\u6d4b\u548c\u54cd\u5e94\u6f5c\u5728\u5165\u4fb5\uff0c\u901a\u8fc7\u5b66\u4e60\u8fc7\u53bb\u5b89\u5168\u4e8b\u4ef6\u63d0\u9ad8\u68c0\u6d4b\u80fd\u529b", "conclusion": "AI\u6846\u67b6\u80fd\u6709\u6548\u63d0\u5347\u7269\u8054\u7f51\u6444\u50cf\u5934\u7f51\u7edc\u7684\u5b89\u5168\u6027\uff0c\u53ca\u65f6\u68c0\u6d4b\u548c\u9632\u8303\u5404\u7c7b\u7f51\u7edc\u653b\u51fb"}}
{"id": "2509.06085", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06085", "abs": "https://arxiv.org/abs/2509.06085", "authors": ["Jerin Yasmin", "Wenxin Jiang", "James C. Davis", "Yuan Tian"], "title": "Software Dependencies 2.0: An Empirical Study of Reuse and Integration of Pre-Trained Models in Open-Source Projects", "comment": "Submitted to Empirical Software Engineering (EMSE) Journal", "summary": "Pre-trained models (PTMs) are machine learning models that have been trained\nin advance, often on large-scale data, and can be reused for new tasks, thereby\nreducing the need for costly training from scratch. Their widespread adoption\nintroduces a new class of software dependency, which we term Software\nDependencies 2.0, extending beyond conventional libraries to learned behaviors\nembodied in trained models and their associated artifacts. The integration of\nPTMs as software dependencies in real projects remains unclear, potentially\nthreatening maintainability and reliability of modern software systems that\nincreasingly rely on them. Objective: In this study, we investigate Software\nDependencies 2.0 in open-source software (OSS) projects by examining the reuse\nof PTMs, with a focus on how developers manage and integrate these models.\nSpecifically, we seek to understand: (1) how OSS projects structure and\ndocument their PTM dependencies; (2) what stages and organizational patterns\nemerge in the reuse pipelines of PTMs within these projects; and (3) the\ninteractions among PTMs and other learned components across pipeline stages. We\nconduct a mixed-methods analysis of a statistically significant random sample\nof 401 GitHub repositories from the PeaTMOSS dataset (28,575 repositories\nreusing PTMs from Hugging Face and PyTorch Hub). We quantitatively examine PTM\nreuse by identifying patterns and qualitatively investigate how developers\nintegrate and manage these models in practice.", "AI": {"tldr": "\u9884\u8bad\u7ec3\u6a21\u578b\u4f5c\u4e3a\u8f6f\u4ef6\u4f9d\u8d56\u7684\u91cd\u7528\u60c5\u51b5\u5206\u6790\uff0c\u7814\u7a76\u4e86401\u4e2aGitHub\u4ed3\u5e93\u4e2dPTM\u7684\u7ba1\u7406\u548c\u96c6\u6210\u6a21\u5f0f", "motivation": "\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u666e\u904d\u91c7\u7528\u5f15\u5165\u4e86\u65b0\u7684\u8f6f\u4ef6\u4f9d\u8d56\u7c7b\u578b\uff08\u8f6f\u4ef6\u4f9d\u8d562.0\uff09\uff0c\u4f46\u5176\u5728\u5b9e\u9645\u9879\u76ee\u4e2d\u7684\u96c6\u6210\u60c5\u51b5\u4e0d\u660e\uff0c\u53ef\u80fd\u5a01\u80c1\u5230\u73b0\u4ee3\u8f6f\u4ef6\u7cfb\u7edf\u7684\u53ef\u7ef4\u62a4\u6027\u548c\u53ef\u9760\u6027", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u5206\u6790\uff0c\u4ecePeaTMOSS\u6570\u636e\u96c6\uff0828,575\u4e2a\u91cd\u7528Hugging Face\u548cPyTorch Hub PTM\u7684\u4ed3\u5e93\uff09\u4e2d\u968f\u673a\u91c7\u6837401\u4e2aGitHub\u4ed3\u5e93\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\uff0c\u91cf\u5316\u5206\u6790PTM\u91cd\u7528\u6a21\u5f0f\uff0c\u8d28\u6027\u7814\u7a76\u5f00\u53d1\u8005\u7684\u5b9e\u9645\u96c6\u6210\u7ba1\u7406\u65b9\u5f0f", "result": "\u672c\u6587\u5c55\u793a\u4e86\u5bf9PTM\u4f5c\u4e3a\u8f6f\u4ef6\u4f9d\u8d56\u7684\u7cfb\u7edf\u6027\u7814\u7a76\uff0c\u4f46\u5177\u4f53\u7ed3\u679c\u9700\u8981\u67e5\u770b\u5b8c\u6574\u8bba\u6587", "conclusion": "\u8fd9\u9879\u7814\u7a76\u4e3a\u7406\u89e3\u8f6f\u4ef6\u4f9d\u8d562.0\u7684\u5b9e\u8df5\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\uff0c\u5e76\u6301\u7eed\u8c03\u67e5PTM\u96c6\u6210\u5bf9\u8f6f\u4ef6\u7cfb\u7edf\u8d28\u91cf\u7684\u5f71\u54cd"}}
{"id": "2509.05550", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05550", "abs": "https://arxiv.org/abs/2509.05550", "authors": ["Zixi Li"], "title": "TreeGPT: A Novel Hybrid Architecture for Abstract Syntax Tree Processing with Global Parent-Child Aggregation", "comment": "Code available at: https://github.com/lizixi-0x2F/TreeGPT", "summary": "We introduce TreeGPT, a novel neural architecture that combines\ntransformer-based attention mechanisms with global parent-child aggregation for\nprocessing Abstract Syntax Trees (ASTs) in neural program synthesis tasks.\nUnlike traditional approaches that rely solely on sequential processing or\ngraph neural networks, TreeGPT employs a hybrid design that leverages both\nself-attention for capturing local dependencies and a specialized Tree\nFeed-Forward Network (TreeFFN) for modeling hierarchical tree structures\nthrough iterative message passing.\n  The core innovation lies in our Global Parent-Child Aggregation mechanism,\nformalized as: $$h_i^{(t+1)} = \\sigma \\Big( h_i^{(0)} + W_{pc} \\sum_{(p,c) \\in\nE_i} f(h_p^{(t)}, h_c^{(t)}) + b \\Big)$$ where $h_i^{(t)}$ represents the\nhidden state of node $i$ at iteration $t$, $E_i$ denotes all parent-child edges\ninvolving node $i$, and $f(h_p, h_c)$ is an edge aggregation function. This\nformulation enables each node to progressively aggregate information from the\nentire tree structure through $T$ iterations.\n  Our architecture integrates optional enhancements including gated aggregation\nwith learnable edge weights, residual connections for gradient stability, and\nbidirectional propagation for capturing both bottom-up and top-down\ndependencies. We evaluate TreeGPT on the ARC Prize 2025 dataset, a challenging\nvisual reasoning benchmark requiring abstract pattern recognition and rule\ninference. Experimental results demonstrate that TreeGPT achieves 96\\%\naccuracy, significantly outperforming transformer baselines (1.3\\%),\nlarge-scale models like Grok-4 (15.9\\%), and specialized program synthesis\nmethods like SOAR (52\\%) while using only 1.5M parameters. Our comprehensive\nablation study reveals that edge projection is the most critical component,\nwith the combination of edge projection and gating achieving optimal\nperformance.", "AI": {"tldr": "TreeGPT\u662f\u4e00\u79cd\u65b0\u9896\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u7ed3\u5408\u4e86transformer\u6ce8\u610f\u529b\u673a\u5236\u548c\u5168\u5c40\u7236\u5b50\u805a\u5408\uff0c\u7528\u4e8e\u5904\u7406\u62bd\u8c61\u8bed\u6cd5\u6811\uff0c\u5728\u7a0b\u5e8f\u5408\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u5e8f\u5217\u5904\u7406\uff0c\u8981\u4e48\u4f7f\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u65e0\u6cd5\u6709\u6548\u6355\u6349AST\u7684\u5c42\u6b21\u7ed3\u6784\u548c\u5168\u5c40\u4f9d\u8d56\u5173\u7cfb\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u5904\u7406\u5c40\u90e8\u4f9d\u8d56\u548c\u5c42\u6b21\u6811\u7ed3\u6784\u7684\u6df7\u5408\u67b6\u6784\u3002", "method": "\u91c7\u7528\u6df7\u5408\u8bbe\u8ba1\uff1a\u4f7f\u7528self-attention\u6355\u6349\u5c40\u90e8\u4f9d\u8d56\uff0c\u4e13\u95e8\u7684TreeFFN\u901a\u8fc7\u8fed\u4ee3\u6d88\u606f\u4f20\u9012\u5efa\u6a21\u5c42\u6b21\u6811\u7ed3\u6784\u3002\u6838\u5fc3\u521b\u65b0\u662f\u5168\u5c40\u7236\u5b50\u805a\u5408\u673a\u5236\uff0c\u5141\u8bb8\u8282\u70b9\u901a\u8fc7T\u6b21\u8fed\u4ee3\u9010\u6b65\u805a\u5408\u6574\u4e2a\u6811\u7ed3\u6784\u7684\u4fe1\u606f\u3002", "result": "\u5728ARC Prize 2025\u6570\u636e\u96c6\u4e0a\u8fbe\u523096%\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8etransformer\u57fa\u7ebf(1.3%)\u3001Grok-4(15.9%)\u548cSOAR(52%)\uff0c\u4ec5\u4f7f\u7528150\u4e07\u53c2\u6570\u3002\u6d88\u878d\u7814\u7a76\u8868\u660e\u8fb9\u7f18\u6295\u5f71\u662f\u6700\u5173\u952e\u7ec4\u4ef6\u3002", "conclusion": "TreeGPT\u901a\u8fc7\u7ed3\u5408\u6ce8\u610f\u529b\u673a\u5236\u548c\u6811\u7ed3\u6784\u805a\u5408\uff0c\u5728\u7a0b\u5e8f\u5408\u6210\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u5353\u8d8a\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u6df7\u5408\u67b6\u6784\u5728\u5904\u7406\u5c42\u6b21\u6811\u7ed3\u6784\u6570\u636e\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2509.05367", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05367", "abs": "https://arxiv.org/abs/2509.05367", "authors": ["Shei Pern Chua", "Thai Zhen Leng", "Teh Kai Jun", "Xiao Li", "Xiaolin Hu"], "title": "Between a Rock and a Hard Place: Exploiting Ethical Reasoning to Jailbreak LLMs", "comment": null, "summary": "Large language models (LLMs) have undergone safety alignment efforts to\nmitigate harmful outputs. However, as LLMs become more sophisticated in\nreasoning, their intelligence may introduce new security risks. While\ntraditional jailbreak attacks relied on singlestep attacks, multi-turn\njailbreak strategies that adapt dynamically to context remain underexplored. In\nthis work, we introduce TRIAL (Trolley-problem Reasoning for Interactive Attack\nLogic), a framework that leverages LLMs ethical reasoning to bypass their\nsafeguards. TRIAL embeds adversarial goals within ethical dilemmas modeled on\nthe trolley problem. TRIAL demonstrates high jailbreak success rates towards\nboth open and close-source models. Our findings underscore a fundamental\nlimitation in AI safety: as models gain advanced reasoning abilities, the\nnature of their alignment may inadvertently allow for more covert security\nvulnerabilities to be exploited. TRIAL raises an urgent need in reevaluating\nsafety alignment oversight strategies, as current safeguards may prove\ninsufficient against context-aware adversarial attack.", "AI": {"tldr": "TRIAL\u6846\u67b6\u5229\u7528\u4f26\u7406\u56f0\u5883\u63a8\u7406\u6765\u7ed5\u8fc7LLM\u7684\u5b89\u5168\u9632\u62a4\uff0c\u901a\u8fc7\u591a\u8f6e\u5bf9\u8bdd\u7b56\u7565\u5b9e\u73b0\u9ad8\u6210\u529f\u7387\u8d8a\u72f1\u653b\u51fb", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u589e\u5f3a\uff0c\u4f20\u7edf\u5355\u6b65\u8d8a\u72f1\u653b\u51fb\u53ef\u80fd\u4e0d\u591f\u6709\u6548\uff0c\u9700\u8981\u63a2\u7d22\u57fa\u4e8e\u591a\u8f6e\u52a8\u6001\u4e0a\u4e0b\u6587\u9002\u5e94\u7684\u8d8a\u72f1\u7b56\u7565", "method": "\u63d0\u51faTRIAL\u6846\u67b6\uff0c\u5c06\u5bf9\u6297\u76ee\u6807\u5d4c\u5165\u5230\u57fa\u4e8e\u7535\u8f66\u96be\u9898\u7684\u4f26\u7406\u56f0\u5883\u4e2d\uff0c\u5229\u7528LLM\u7684\u4f26\u7406\u63a8\u7406\u80fd\u529b\u7ed5\u8fc7\u5b89\u5168\u9632\u62a4", "result": "TRIAL\u5728\u5f00\u6e90\u548c\u95ed\u6e90\u6a21\u578b\u4e0a\u90fd\u8868\u73b0\u51fa\u5f88\u9ad8\u7684\u8d8a\u72f1\u6210\u529f\u7387", "conclusion": "\u5f53\u524d\u7684\u5b89\u5168\u9632\u62a4\u63aa\u65bd\u53ef\u80fd\u4e0d\u8db3\u4ee5\u5e94\u5bf9\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5bf9\u6297\u653b\u51fb\uff0c\u9700\u8981\u91cd\u65b0\u8bc4\u4f30\u5b89\u5168\u5bf9\u9f50\u76d1\u7763\u7b56\u7565"}}
{"id": "2509.06216", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06216", "abs": "https://arxiv.org/abs/2509.06216", "authors": ["Ahmed E. Hassan", "Hao Li", "Dayi Lin", "Bram Adams", "Tse-Hsun Chen", "Yutaro Kashiwa", "Dong Qiu"], "title": "Agentic Software Engineering: Foundational Pillars and a Research Roadmap", "comment": null, "summary": "Agentic Software Engineering (SE 3.0) represents a new era where intelligent\nagents are tasked not with simple code generation, but with achieving complex,\ngoal-oriented SE objectives. To harness these new capabilities while ensuring\ntrustworthiness, we must recognize a fundamental duality within the SE field in\nthe Agentic SE era, comprising two symbiotic modalities: SE for Humans and SE\nfor Agents. This duality demands a radical reimagining of the foundational\npillars of SE (actors, processes, tools, and artifacts) which manifest\ndifferently across each modality. We propose two purpose-built workbenches to\nsupport this vision. The Agent Command Environment (ACE) serves as a command\ncenter where humans orchestrate and mentor agent teams, handling outputs such\nas Merge-Readiness Packs (MRPs) and Consultation Request Packs (CRPs). The\nAgent Execution Environment (AEE) is a digital workspace where agents perform\ntasks while invoking human expertise when facing ambiguity or complex\ntrade-offs. This bi-directional partnership, which supports agent-initiated\nhuman callbacks and handovers, gives rise to new, structured engineering\nactivities (i.e., processes) that redefine human-AI collaboration, elevating\nthe practice from agentic coding to true agentic software engineering. This\npaper presents the Structured Agentic Software Engineering (SASE) vision,\noutlining several of the foundational pillars for the future of SE. The paper\nculminates in a research roadmap that identifies a few key challenges and\nopportunities while briefly discussing the resulting impact of this future on\nSE education. Our goal is not to offer a definitive solution, but to provide a\nconceptual scaffold with structured vocabulary to catalyze a community-wide\ndialogue, pushing the SE community to think beyond its classic, human-centric\ntenets toward a disciplined, scalable, and trustworthy agentic future.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u7ed3\u6784\u5316\u81ea\u4e3b\u8f6f\u4ef6\u5de5\u7a0b(SASE)\u89c6\u91ce\uff0c\u8ba4\u4e3a\u81ea\u4e3b\u8f6f\u4ef6\u5de5\u7a0b\u65f6\u4ee3\u9700\u8981\u91cd\u6784\u4eba\u7c7b\u4e0e\u667a\u80fd\u4ee3\u7406\u7684\u5171\u540c\u4f5c\u4e1a\u6a21\u5f0f\uff0c\u901a\u8fc7ACE\u548cAEE\u4e24\u4e2a\u5de5\u4f5c\u53f0\u652f\u6301\u53cc\u5411\u534f\u4f5c\u3002", "motivation": "\u8eab\u4efd\u8f6f\u4ef6\u5de5\u7a0b(SE 3.0)\u65f6\u4ee3\u6765\u4e34\uff0c\u667a\u80fd\u4ee3\u7406\u9700\u8981\u5b8c\u6210\u590d\u6742\u7684\u76ee\u6807\u5bfc\u5411\u4efb\u52a1\u3002\u4e3a\u4e86\u5728\u53d1\u6325\u8fd9\u4e9b\u65b0\u80fd\u529b\u7684\u540c\u65f6\u786e\u4fdd\u53ef\u4fe1\u8fc7\u7a0b\uff0c\u9700\u8981\u91cd\u65b0\u8ba4\u8bc6\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u4e8c\u5143\u6027\uff1a\u4e3a\u4eba\u7c7b\u670d\u52a1\u7684SE\u548c\u4e3a\u4ee3\u7406\u670d\u52a1\u7684SE\u3002", "method": "\u63d0\u51fa\u4e24\u4e2a\u4e13\u95e8\u8bbe\u8ba1\u7684\u5de5\u4f5c\u53f0\uff1aAgent Command Environment (ACE)\u4f5c\u4e3a\u547d\u4ee4\u4e2d\u5fc3\uff0c\u4eba\u7c7b\u5728\u5176\u4e2d\u7ec4\u7ec7\u548c\u6307\u5bfc\u4ee3\u7406\u56e2\u961f\uff1bAgent Execution Environment (AEE)\u4f5c\u4e3a\u6570\u5b57\u5de5\u4f5c\u7a7a\u95f4\uff0c\u4ee3\u7406\u5728\u5176\u4e2d\u6267\u884c\u4efb\u52a1\u5e76\u5728\u9047\u5230\u6a21\u7cca\u6027\u65f6\u8c03\u7528\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u3002\u652f\u6301\u53cc\u5411\u4f19\u4f34\u5173\u7cfb\u548c\u7ed3\u6784\u5316\u5de5\u7a0b\u6d3b\u52a8\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86SASE\u89c6\u91ce\uff0c\u7ed9\u51fa\u4e86\u672a\u6765\u8f6f\u4ef6\u5de5\u7a0b\u7684\u57fa\u7840\u67b6\u6784\u67b6\u7b79\uff0c\u5e76\u63d0\u51fa\u4e86\u7814\u7a76\u8def\u7ebf\u56fe\uff0c\u8bc6\u522b\u4e86\u5173\u952e\u6311\u6218\u548c\u673a\u9047\u3002", "conclusion": "\u8be5\u7814\u7a76\u7684\u76ee\u6807\u4e0d\u662f\u63d0\u4f9b\u5b9a\u8bba\u6027\u89e3\u51b3\u65b9\u6848\uff0c\u800c\u662f\u63d0\u4f9b\u4e00\u4e2a\u6982\u5ff5\u67b6\u6784\u548c\u7ed3\u6784\u5316\u8bcd\u6c47\uff0c\u4ee5\u4fc3\u8fdb\u793e\u533a\u5e7f\u6cdb\u5bf9\u8bdd\uff0c\u63a8\u52a8SE\u793e\u533a\u8d85\u8d8a\u4f20\u7edf\u7684\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u539f\u5219\uff0c\u5411\u7740\u89c4\u8303\u5316\u3001\u53ef\u6269\u5c55\u548c\u53ef\u4fe1\u7684\u81ea\u4e3b\u672a\u6765\u53d1\u5c55\u3002"}}
{"id": "2509.05578", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.05578", "abs": "https://arxiv.org/abs/2509.05578", "authors": ["Ruixun Liu", "Lingyu Kong", "Derun Li", "Hang Zhao"], "title": "OccVLA: Vision-Language-Action Model with Implicit 3D Occupancy Supervision", "comment": null, "summary": "Multimodal large language models (MLLMs) have shown strong vision-language\nreasoning abilities but still lack robust 3D spatial understanding, which is\ncritical for autonomous driving. This limitation stems from two key challenges:\n(1) the difficulty of constructing accessible yet effective 3D representations\nwithout expensive manual annotations, and (2) the loss of fine-grained spatial\ndetails in VLMs due to the absence of large-scale 3D vision-language\npretraining. To address these challenges, we propose OccVLA, a novel framework\nthat integrates 3D occupancy representations into a unified multimodal\nreasoning process. Unlike prior approaches that rely on explicit 3D inputs,\nOccVLA treats dense 3D occupancy as both a predictive output and a supervisory\nsignal, enabling the model to learn fine-grained spatial structures directly\nfrom 2D visual inputs. The occupancy predictions are regarded as implicit\nreasoning processes and can be skipped during inference without performance\ndegradation, thereby adding no extra computational overhead. OccVLA achieves\nstate-of-the-art results on the nuScenes benchmark for trajectory planning and\ndemonstrates superior performance on 3D visual question-answering tasks,\noffering a scalable, interpretable, and fully vision-based solution for\nautonomous driving.", "AI": {"tldr": "OccVLA\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u591a\u6a21\u6001\u6846\u67b6\uff0c\u901a\u8fc7\u5c063D\u5360\u636e\u8868\u793a\u96c6\u6210\u5230\u7edf\u4e00\u63a8\u7406\u8fc7\u7a0b\u4e2d\uff0c\u89e3\u51b3\u4e86MLLM\u57283D\u7a7a\u95f4\u7406\u89e3\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u65e0\u9700\u6602\u8d35\u7684\u624b\u52a8\u6807\u6ce8\u5373\u53ef\u5b9e\u73b0\u81ea\u52a8\u9a7e\u9a76\u7684\u7cbe\u7ec6\u7a7a\u95f4\u7ed3\u6784\u5b66\u4e60\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u89c6\u89c9-\u8bed\u8a00\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u57283D\u7a7a\u95f4\u7406\u89e3\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u8fd9\u5bf9\u4e8e\u81ea\u52a8\u9a7e\u9a76\u81f3\u5173\u91cd\u8981\u3002\u4e3b\u8981\u6311\u6218\u5305\u62ec\u7f3a\u4e4f\u53ef\u8bbf\u95ee\u4e14\u6709\u6548\u76843D\u8868\u793a\u6784\u5efa\u65b9\u6cd5\uff0c\u4ee5\u53ca\u7531\u4e8e\u7f3a\u4e4f\u5927\u89c4\u6a213D\u89c6\u89c9-\u8bed\u8a00\u9884\u8bad\u7ec3\u5bfc\u81f4\u7684\u7ec6\u7c92\u5ea6\u7a7a\u95f4\u7ec6\u8282\u4e22\u5931\u3002", "method": "\u63d0\u51faOccVLA\u6846\u67b6\uff0c\u5c06\u5bc6\u96c63D\u5360\u636e\u65e2\u4f5c\u4e3a\u9884\u6d4b\u8f93\u51fa\u53c8\u4f5c\u4e3a\u76d1\u7763\u4fe1\u53f7\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u76f4\u63a5\u4ece2D\u89c6\u89c9\u8f93\u5165\u5b66\u4e60\u7ec6\u7c92\u5ea6\u7a7a\u95f4\u7ed3\u6784\u3002\u5360\u636e\u9884\u6d4b\u88ab\u89c6\u4e3a\u9690\u5f0f\u63a8\u7406\u8fc7\u7a0b\uff0c\u5728\u63a8\u7406\u65f6\u53ef\u8df3\u8fc7\u800c\u4e0d\u5f71\u54cd\u6027\u80fd\uff0c\u4e0d\u589e\u52a0\u989d\u5916\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u5728nuScenes\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u8f68\u8ff9\u89c4\u5212\u7684\u6700\u5148\u8fdb\u7ed3\u679c\uff0c\u57283D\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "OccVLA\u4e3a\u81ea\u52a8\u9a7e\u9a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u4e14\u5b8c\u5168\u57fa\u4e8e\u89c6\u89c9\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u521b\u65b0\u76843D\u5360\u636e\u8868\u793a\u96c6\u6210\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86MLLM\u57283D\u7a7a\u95f4\u7406\u89e3\u65b9\u9762\u7684\u6838\u5fc3\u6311\u6218\u3002"}}
{"id": "2509.05370", "categories": ["cs.CR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2509.05370", "abs": "https://arxiv.org/abs/2509.05370", "authors": ["Tanya Joshi", "Krishnendu Guha"], "title": "Quantum AI Algorithm Development for Enhanced Cybersecurity: A Hybrid Approach to Malware Detection", "comment": "10 pages", "summary": "This study explores the application of quantum machine learning (QML)\nalgorithms to enhance cybersecurity threat detection, particularly in the\nclassification of malware and intrusion detection within high-dimensional\ndatasets. Classical machine learning approaches encounter limitations when\ndealing with intricate, obfuscated malware patterns and extensive network\nintrusion data. To address these challenges, we implement and evaluate various\nQML algorithms, including Quantum Neural Networks (QNN), Quantum Support Vector\nMachines (QSVM), and hybrid Quantum Convolutional Neural Networks (QCNN) for\nmalware detection tasks. Our experimental analysis utilized two datasets: the\nIntrusion dataset, comprising 150 samples with 56 memory-based features derived\nfrom Volatility framework analysis, and the ObfuscatedMalMem2022 dataset,\ncontaining 58,596 samples with 57 features representing benign and malicious\nsoftware. Remarkably, our QML methods demonstrated superior performance\ncompared to classical approaches, achieving accuracies of 95% for QNN and 94%\nfor QSVM. These quantum-enhanced methods leveraged quantum superposition and\nentanglement principles to accurately identify complex patterns within highly\nobfuscated malware samples that were imperceptible to classical methods. To\nfurther advance malware analysis, we propose a novel real-time malware analysis\nframework that incorporates Quantum Feature Extraction using Quantum Fourier\nTransform, Quantum Feature Maps, and Classification using Variational Quantum\nCircuits. This system integrates explainable AI methods, including GradCAM++\nand ScoreCAM algorithms, to provide interpretable insights into the quantum\ndecision-making processes.", "AI": {"tldr": "\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5728\u7f51\u7edc\u5b89\u5168\u5a01\u80c1\u68c0\u6d4b\u4e2d\u663e\u793a\u4f18\u52bf\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u7684\u7535\u5b50\u75c5\u6bd2\u5206\u7c7b\u4efb\u52a1\u4e2d\u8fbe\u523095%\u7684\u51c6\u786e\u7387\uff0c\u8d85\u8d8a\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u7684\u7535\u5b50\u75c5\u6bd2\u6a21\u5f0f\u548c\u5927\u89c4\u6a21\u7f51\u7edc\u5165\u4fb5\u6570\u636e\u65f6\u9047\u5230\u5c40\u9650\u6027\uff0c\u9700\u8981\u91cf\u5b50\u6280\u672f\u6765\u7a81\u7834\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u5b9e\u65bd\u591a\u79cdQML\u7b97\u6cd5\uff0c\u5305\u62ec\u91cf\u5b50\u795e\u7ecf\u7f51\u7edc(QNN)\u3001\u91cf\u5b50\u652f\u6301\u5411\u91cf\u673a(QSVM)\u548c\u6df7\u5408\u91cf\u5b50\u5377\u79ef\u795e\u7ecf\u7f51\u7edc(QCNN)\uff0c\u4f7f\u7528\u5165\u4fb5\u6570\u636e\u96c6(150\u6837\u672c) \u548cObfuscatedMalMem2022\u6570\u636e\u96c6(58,596\u6837\u672c)\u8fdb\u884c\u5b9e\u9a8c\u5206\u6790\u3002", "result": "QML\u65b9\u6cd5\u8868\u73b0\u4f18\u5f02\uff0cQNN\u8fbe\u523095%\u51c6\u786e\u7387\uff0cQSVM\u8fbe\u523094%\u51c6\u786e\u7387\uff0c\u5229\u7528\u91cf\u5b50\u76f8\u5e72\u548c\u7f18\u7ed5\u539f\u7406\u51c6\u786e\u8bc6\u522b\u4f20\u7edf\u65b9\u6cd5\u65e0\u6cd5\u68c0\u6d4b\u7684\u590d\u6742\u6a21\u5f0f\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u5b9e\u65f6\u7535\u5b50\u75c5\u6bd2\u5206\u6790\u6846\u67b6\uff0c\u7ed3\u5408\u91cf\u5b50\u7279\u5f81\u63d0\u53d6\u548c\u53ef\u89e3\u91caAI\u65b9\u6cd5\uff0c\u4e3a\u91cf\u5b50\u51b3\u7b56\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u6027\u89c1\u89e3\u3002"}}
{"id": "2509.06301", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.06301", "abs": "https://arxiv.org/abs/2509.06301", "authors": ["Dharun Anandayuvaraj", "Zain Hammadeh", "Andreas Lund", "Alexandra Holloway", "James C. Davis"], "title": "Learning From Software Failures: A Case Study at a National Space Research Center", "comment": null, "summary": "Software failures can have significant consequences, making learning from\nfailures a critical aspect of software engineering. While software\norganizations are recommended to conduct postmortems, the effectiveness and\nadoption of these practices vary widely. Understanding how engineers gather,\ndocument, share, and apply lessons from failures is essential for improving\nreliability and preventing recurrence. High-reliability organizations (HROs)\noften develop software systems where failures carry catastrophic risks,\nrequiring continuous learning to ensure reliability. These organizations\nprovide a valuable setting to examine practices and challenges for learning\nfrom software failures. Such insight could help develop processes and tools to\nimprove reliability and prevent recurrence. However, we lack in-depth industry\nperspectives on the practices and challenges of learning from failures.\n  To address this gap, we conducted a case study through 10 in-depth interviews\nwith research software engineers at a national space research center. We\nexamine how they learn from failures: how they gather, document, share, and\napply lessons. To assess transferability, we include data from 5 additional\ninterviews at other HROs. Our findings provide insight into how engineers learn\nfrom failures in practice. To summarize: (1) failure learning is informal, ad\nhoc, and inconsistently integrated into SDLC; (2) recurring failures persist\ndue to absence of structured processes; and (3) key challenges, including time\nconstraints, knowledge loss from turnover and fragmented documentation, and\nweak process enforcement, undermine systematic learning. Our findings deepen\nunderstanding of how software engineers learn from failures and offer guidance\nfor improving failure management practices.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc710\u4e2a\u6df1\u5ea6\u8bbf\u8c08\u7814\u7a76\u4e86\u9ad8\u53ef\u9760\u6027\u7ec4\u7ec7\u4e2d\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u4ece\u5931\u8d25\u4e2d\u5b66\u4e60\u7684\u5b9e\u8df5\u4e0e\u6311\u6218\uff0c\u53d1\u73b0\u5931\u8d25\u5b66\u4e60\u901a\u5e38\u662f\u975e\u6b63\u5f0f\u7684\u3001\u968f\u673a\u7684\uff0c\u5e76\u56e0\u65f6\u95f4\u7ea6\u675f\u3001\u77e5\u8bc6\u6d41\u5931\u7b49\u6311\u6218\u800c\u53d7\u9650\u3002", "motivation": "\u8f6f\u4ef6\u5931\u8d25\u53ef\u80fd\u9020\u6210\u4e25\u91cd\u540e\u679c\uff0c\u4ece\u5931\u8d25\u4e2d\u5b66\u4e60\u662f\u8f6f\u4ef6\u5de5\u7a0b\u7684\u5173\u952e\u65b9\u9762\u3002\u867d\u7136\u5efa\u8bae\u8fdb\u884c\u4e8b\u540e\u5206\u6790\uff0c\u4f46\u5b9e\u8df5\u6548\u679c\u548c\u91c7\u7528\u60c5\u51b5\u5dee\u5f02\u5f88\u5927\u3002\u9700\u8981\u6df1\u5165\u4e86\u89e3\u5de5\u7a0b\u5e08\u5982\u4f55\u6536\u96c6\u3001\u6587\u6863\u5316\u3001\u5206\u4eab\u548c\u5e94\u7528\u5931\u8d25\u6559\u8bad\u3002", "method": "\u91c7\u7528\u6848\u4f8b\u7814\u7a76\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u56fd\u5bb6\u592a\u7a7a\u7814\u7a76\u4e2d\u5fc3\u768410\u4f4d\u7814\u7a76\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u8fdb\u884c\u6df1\u5ea6\u8bbf\u8c08\u3002\u4e3a\u4e86\u8bc4\u4f30\u53ef\u8f6c\u79fb\u6027\uff0c\u8fd8\u5305\u542b\u6765\u81ea\u5176\u4ed6\u9ad8\u53ef\u9760\u6027\u7ec4\u7ec7\u76845\u4e2a\u8bbf\u8c08\u6570\u636e\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a(1) \u5931\u8d25\u5b66\u4e60\u901a\u5e38\u662f\u975e\u6b63\u5f0f\u7684\u3001\u968f\u673a\u7684\uff0c\u5e76\u4e0d\u4e00\u81f4\u5730\u96c6\u6210\u5230\u8f6f\u4ef6\u5f00\u53d1\u751f\u547d\u5468\u671f\u4e2d\uff1b(2) \u7531\u4e8e\u7f3a\u4e4f\u7ed3\u6784\u5316\u8fc7\u7a0b\uff0c\u91cd\u590d\u5931\u8d25\u6301\u7eed\u5b58\u5728\uff1b(3) \u65f6\u95f4\u7ea6\u675f\u3001\u4eba\u5458\u66ff\u6362\u9020\u6210\u7684\u77e5\u8bc6\u6d41\u5931\u3001\u6587\u6863\u5206\u6563\u548c\u8fc7\u7a0b\u6267\u884c\u5f31\u7f3a\u7b49\u5173\u952e\u6311\u6218\u5a31\u5236\u4e86\u7cfb\u7edf\u6027\u5b66\u4e60\u3002", "conclusion": "\u7814\u7a76\u6df1\u5316\u4e86\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u5982\u4f55\u4ece\u5931\u8d25\u4e2d\u5b66\u4e60\u7684\u7406\u89e3\uff0c\u4e3a\u6539\u5584\u5931\u8d25\u7ba1\u7406\u5b9e\u8df5\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002\u8fd9\u4e9b\u53d1\u73b0\u5bf9\u4e8e\u5f00\u53d1\u66f4\u6709\u6548\u7684\u8fc7\u7a0b\u548c\u5de5\u5177\u6765\u63d0\u9ad8\u53ef\u9760\u6027\u548c\u9632\u6b62\u91cd\u590d\u5931\u8d25\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2509.05685", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.05685", "abs": "https://arxiv.org/abs/2509.05685", "authors": ["Jian Yang", "Jiahui Wu", "Li Fang", "Hongchao Fan", "Bianying Zhang", "Huijie Zhao", "Guangyi Yang", "Rui Xin", "Xiong You"], "title": "MSRFormer: Road Network Representation Learning using Multi-scale Feature Fusion of Heterogeneous Spatial Interactions", "comment": null, "summary": "Transforming road network data into vector representations using deep\nlearning has proven effective for road network analysis. However, urban road\nnetworks' heterogeneous and hierarchical nature poses challenges for accurate\nrepresentation learning. Graph neural networks, which aggregate features from\nneighboring nodes, often struggle due to their homogeneity assumption and focus\non a single structural scale. To address these issues, this paper presents\nMSRFormer, a novel road network representation learning framework that\nintegrates multi-scale spatial interactions by addressing their flow\nheterogeneity and long-distance dependencies. It uses spatial flow convolution\nto extract small-scale features from large trajectory datasets, and identifies\nscale-dependent spatial interaction regions to capture the spatial structure of\nroad networks and flow heterogeneity. By employing a graph transformer,\nMSRFormer effectively captures complex spatial dependencies across multiple\nscales. The spatial interaction features are fused using residual connections,\nwhich are fed to a contrastive learning algorithm to derive the final road\nnetwork representation. Validation on two real-world datasets demonstrates that\nMSRFormer outperforms baseline methods in two road network analysis tasks. The\nperformance gains of MSRFormer suggest the traffic-related task benefits more\nfrom incorporating trajectory data, also resulting in greater improvements in\ncomplex road network structures with up to 16% improvements compared to the\nmost competitive baseline method. This research provides a practical framework\nfor developing task-agnostic road network representation models and highlights\ndistinct association patterns of the interplay between scale effects and flow\nheterogeneity of spatial interactions.", "AI": {"tldr": "MSRFormer\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u9053\u8def\u7f51\u7edc\u8868\u793a\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u5c3a\u5ea6\u7a7a\u95f4\u4ea4\u4e92\u548c\u8f68\u8ff9\u6570\u636e\u6574\u5408\uff0c\u89e3\u51b3\u4e86\u9053\u8def\u7f51\u7edc\u5f02\u8d28\u6027\u548c\u5c42\u6b21\u6027\u6311\u6218\uff0c\u5728\u9053\u8def\u7f51\u7edc\u5206\u6790\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u57ce\u5e02\u9053\u8def\u7f51\u7edc\u7684\u5f02\u8d28\u6027\u548c\u5c42\u6b21\u6027\u7ed9\u51c6\u786e\u8868\u793a\u5b66\u4e60\u5e26\u6765\u6311\u6218\uff0c\u4f20\u7edf\u56fe\u795e\u7ecf\u7f51\u7edc\u7531\u4e8e\u540c\u8d28\u6027\u5047\u8bbe\u548c\u5355\u4e00\u7ed3\u6784\u5c3a\u5ea6\u5173\u6ce8\u800c\u96be\u4ee5\u6709\u6548\u5904\u7406\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u7a7a\u95f4\u6d41\u5377\u79ef\u4ece\u5927\u578b\u8f68\u8ff9\u6570\u636e\u96c6\u4e2d\u63d0\u53d6\u5c0f\u5c3a\u5ea6\u7279\u5f81\uff0c\u8bc6\u522b\u5c3a\u5ea6\u4f9d\u8d56\u7684\u7a7a\u95f4\u4ea4\u4e92\u533a\u57df\uff0c\u901a\u8fc7\u56fe\u53d8\u6362\u5668\u6355\u6349\u591a\u5c3a\u5ea6\u590d\u6742\u7a7a\u95f4\u4f9d\u8d56\uff0c\u91c7\u7528\u6b8b\u5dee\u8fde\u63a5\u878d\u5408\u7279\u5f81\uff0c\u6700\u540e\u4f7f\u7528\u5bf9\u6bd4\u5b66\u4e60\u7b97\u6cd5\u5f97\u5230\u6700\u7ec8\u8868\u793a\u3002", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u9a8c\u8bc1\u8868\u660e\uff0cMSRFormer\u5728\u9053\u8def\u7f51\u7edc\u5206\u6790\u4efb\u52a1\u4e2d\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u6027\u80fd\u63d0\u5347\u8fbe16%\uff0c\u7279\u522b\u662f\u5728\u4ea4\u901a\u76f8\u5173\u4efb\u52a1\u548c\u590d\u6742\u9053\u8def\u7f51\u7edc\u7ed3\u6784\u4e2d\u8868\u73b0\u66f4\u4f73\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5f00\u53d1\u4efb\u52a1\u65e0\u5173\u7684\u9053\u8def\u7f51\u7edc\u8868\u793a\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u7528\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u5c3a\u5ea6\u6548\u5e94\u4e0e\u7a7a\u95f4\u4ea4\u4e92\u6d41\u5f02\u8d28\u6027\u4e4b\u95f4\u7684\u5173\u8054\u6a21\u5f0f\uff0c\u8bc1\u660e\u4e86\u6574\u5408\u8f68\u8ff9\u6570\u636e\u5bf9\u4ea4\u901a\u76f8\u5173\u4efb\u52a1\u7684\u76ca\u5904\u3002"}}
{"id": "2509.05376", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05376", "abs": "https://arxiv.org/abs/2509.05376", "authors": ["Abdul Rehman", "Are D\u00e6hlen", "Ilona Heldal", "Jerry Chun-wei Lin"], "title": "Privacy Preservation and Identity Tracing Prevention in AI-Driven Eye Tracking for Interactive Learning Environments", "comment": null, "summary": "Eye-tracking technology can aid in understanding neurodevelopmental disorders\nand tracing a person's identity. However, this technology poses a significant\nrisk to privacy, as it captures sensitive information about individuals and\nincreases the likelihood that data can be traced back to them. This paper\nproposes a human-centered framework designed to prevent identity backtracking\nwhile preserving the pedagogical benefits of AI-powered eye tracking in\ninteractive learning environments. We explore how real-time data anonymization,\nethical design principles, and regulatory compliance (such as GDPR) can be\nintegrated to build trust and transparency. We first demonstrate the potential\nfor backtracking student IDs and diagnoses in various scenarios using serious\ngame-based eye-tracking data. We then provide a two-stage privacy-preserving\nframework that prevents participants from being tracked while still enabling\ndiagnostic classification. The first phase covers four scenarios: I) Predicting\ndisorder diagnoses based on different game levels. II) Predicting student IDs\nbased on different game levels. III) Predicting student IDs based on randomized\ndata. IV) Utilizing K-Means for out-of-sample data. In the second phase, we\npresent a two-stage framework that preserves privacy. We also employ Federated\nLearning (FL) across multiple clients, incorporating a secure identity\nmanagement system with dummy IDs and administrator-only access controls. In the\nfirst phase, the proposed framework achieved 99.3% accuracy for scenario 1, 63%\naccuracy for scenario 2, and 99.7% accuracy for scenario 3, successfully\nidentifying and assigning a new student ID in scenario 4. In phase 2, we\neffectively prevented backtracking and established a secure identity management\nsystem with dummy IDs and administrator-only access controls, achieving an\noverall accuracy of 99.40%.", "AI": {"tldr": "\u773c\u52a8\u8ddf\u8e2a\u6280\u672f\u5728\u6559\u80b2\u73af\u5883\u4e2d\u5b58\u5728\u9690\u79c1\u98ce\u9669\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u9690\u79c1\u4fdd\u62a4\u6846\u67b6\uff0c\u901a\u8fc7\u6570\u636e\u533f\u540d\u5316\u3001\u8054\u90a6\u5b66\u4e60\u548c\u5b89\u5168\u8eab\u4efd\u7ba1\u7406\u7cfb\u7edf\u6765\u9632\u6b62\u8eab\u4efd\u8ffd\u6eaf\uff0c\u540c\u65f6\u4fdd\u6301\u8bca\u65ad\u5206\u7c7b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u773c\u52a8\u8ddf\u8e2a\u6280\u672f\u867d\u7136\u80fd\u591f\u5e2e\u52a9\u7406\u89e3\u795e\u7ecf\u53d1\u80b2\u969c\u788d\u548c\u8bc6\u522b\u8ffd\u8e2a\uff0c\u4f46\u5b58\u5728\u4e25\u91cd\u9690\u79c1\u98ce\u9669\uff0c\u5bb9\u6613\u6cc4\u9732\u654f\u611f\u4e2a\u4eba\u4fe1\u606f\u3002\u9700\u8981\u5728\u4fdd\u6301\u6559\u80b2\u4ef7\u503c\u7684\u540c\u65f6\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u9690\u79c1\u4fdd\u62a4\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u6d4b\u8bd5\u56db\u79cd\u60c5\u666f\u4e0b\u7684\u8eab\u4efd\u8ffd\u6eaf\u98ce\u9669\uff1b\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u8054\u90a6\u5b66\u4e60\u3001\u6570\u636e\u533f\u540d\u5316\u3001\u5047ID\u7cfb\u7edf\u548c\u7ba1\u7406\u5458\u4e13\u7528\u8bbf\u95ee\u63a7\u5236\u6765\u5efa\u7acb\u5b89\u5168\u8eab\u4efd\u7ba1\u7406\u7cfb\u7edf\u3002", "result": "\u7b2c\u4e00\u9636\u6bb5\uff1a\u573a\u666f1\u8bca\u65ad\u9884\u6d4b\u51c6\u786e\u738799.3%\uff0c\u573a\u666f2\u5b66\u751fID\u9884\u6d4b51c6\u786e\u738763%\uff0c\u573a\u666f3\u968f\u673a\u6570\u636eID\u9884\u6d4b51c6\u786e\u738799.7%\uff0c\u573a\u666f4\u6210\u529f\u5206\u914d\u65b0\u5b66\u751fID\u3002\u7b2c\u4e8c\u9636\u6bb5\uff1a\u6210\u529f\u9632\u6b62\u8eab\u4efd\u8ffd\u6eaf\uff0c\u5efa\u7acb\u5b89\u5168\u8eab\u4efd\u7ba1\u7406\u7cfb\u7edf\uff0c\u6574\u4f53\u51c6\u786e\u7387\u8fbe99.40%\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u9632\u6b62\u773c\u52a8\u8ddf\u8e2a\u6570\u636e\u4e2d\u7684\u8eab\u4efd\u8ffd\u6eaf\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8bca\u65ad\u5206\u7c7b\u7684\u9ad8\u51c6\u786e\u6027\uff0c\u4e3a\u6559\u80b2AI\u5e94\u7528\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.06324", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.06324", "abs": "https://arxiv.org/abs/2509.06324", "authors": ["Zhuohang Shen", "Mohammed Yaseen", "Denini Silva", "Kevin Guan", "Junho Lee", "Marcelo d'Amorim", "Owolabi Legunsen"], "title": "A Generic and Efficient Python Runtime Verification System and its Large-scale Evaluation", "comment": "23 pages, 7 figures", "summary": "Runtime verification (RV) now scales for testing thousands of open-source\nJava projects, helping find hundreds of bugs. The popular Python ecosystem\ncould use such benefits. But, today's Python RV systems are limited to a domain\nor specification logic, or slow. We propose PyMOP, a generic, extensible, and\nefficient RV system for Python. PyMOP supports five logics, implements five\nexisting monitoring algorithms, ships with 73 API specs of Python and\nwidely-used libraries, supports three instrumentation strategies, and users can\neasily add more of these. On 290,133 unit tests in 1,463 GitHub projects, we\nfind mainly that (i) the default monitoring algorithm for Java is often not the\nfastest for Python; (ii) PyMOP is up to 1,168.3x faster than two recent dynamic\nanalysis systems; and (iii) 44 of 121 bugs that PyMOP helped find so far were\nfixed by developers. PyMOP's generality and efficiency position it well as an\nexcellent platform for the next advances on RV for Python.", "AI": {"tldr": "PyMOP\u662f\u4e00\u4e2a\u901a\u7528\u3001\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684Python\u8fd0\u884c\u65f6\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u652f\u6301\u591a\u79cd\u903b\u8f91\u548c\u76d1\u63a7\u7b97\u6cd5\uff0c\u5728\u5927\u91cf\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u6bd4\u73b0\u6709\u7cfb\u7edf\u5feb\u4e0a\u5343\u500d\uff0c\u5e76\u5e2e\u52a9\u53d1\u73b0\u4e86121\u4e2abug\u3002", "motivation": "Python\u751f\u6001\u7cfb\u7edf\u7f3a\u4e4f\u50cfJava\u90a3\u6837\u53ef\u6269\u5c55\u7684\u8fd0\u884c\u65f6\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u73b0\u6709\u7684Python RV\u7cfb\u7edf\u8981\u4e48\u5c40\u9650\u4e8e\u7279\u5b9a\u9886\u57df\u6216\u89c4\u8303\u903b\u8f91\uff0c\u8981\u4e48\u8fd0\u884c\u901f\u5ea6\u6162\u3002", "method": "\u5f00\u53d1\u4e86PyMOP\u7cfb\u7edf\uff0c\u652f\u6301\u4e94\u79cd\u903b\u8f91\uff0c\u5b9e\u73b0\u4e86\u4e94\u79cd\u73b0\u6709\u76d1\u63a7\u7b97\u6cd5\uff0c\u5305\u542b73\u4e2aAPI\u89c4\u8303\uff0c\u652f\u6301\u4e09\u79cd\u63d2\u6869\u7b56\u7565\uff0c\u7528\u6237\u53ef\u8f7b\u677e\u6269\u5c55\u3002", "result": "\u57281,463\u4e2aGitHub\u9879\u76ee\u7684290,133\u4e2a\u5355\u5143\u6d4b\u8bd5\u4e2d\uff1a1) Java\u7684\u9ed8\u8ba4\u76d1\u63a7\u7b97\u6cd5\u5bf9Python\u4e0d\u662f\u6700\u5feb\u7684\uff1b2) PyMOP\u6bd4\u4e24\u4e2a\u6700\u8fd1\u7684\u52a8\u6001\u5206\u6790\u7cfb\u7edf\u5feb1,168.3\u500d\uff1b3) \u53d1\u73b0\u7684121\u4e2abug\u4e2d\u670944\u4e2a\u88ab\u5f00\u53d1\u8005\u4fee\u590d\u3002", "conclusion": "PyMOP\u7684\u901a\u7528\u6027\u548c\u9ad8\u6548\u6027\u4f7f\u5176\u6210\u4e3aPython\u8fd0\u884c\u65f6\u9a8c\u8bc1\u7814\u7a76\u7684\u4f18\u79c0\u5e73\u53f0\u3002"}}
{"id": "2509.05714", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.05714", "abs": "https://arxiv.org/abs/2509.05714", "authors": ["Zhaoyu Fan", "Kaihang Pan", "Mingze Zhou", "Bosheng Qin", "Juncheng Li", "Shengyu Zhang", "Wenqiao Zhang", "Siliang Tang", "Fei Wu", "Yueting Zhuang"], "title": "Towards Meta-Cognitive Knowledge Editing for Multimodal LLMs", "comment": "15 pages, 6 figures", "summary": "Knowledge editing enables multimodal large language models (MLLMs) to\nefficiently update outdated or incorrect information. However, existing\nbenchmarks primarily emphasize cognitive-level modifications while lacking a\nfocus on deeper meta-cognitive processes. To bridge this gap, we introduce\nCogEdit, a novel benchmark designed to evaluate MLLMs' meta-cognitive knowledge\nediting abilities across three levels: (1) Counterfactual-Driven Editing,\nassessing self-awareness of knowledge correctness changes; (2) Boundary\nConstraint Editing, ensuring appropriate generalization without unintended\ninterference; and (3) Noise-Robust Editing, promoting reflective evaluation of\nuncertain information. To advance meta-cognitive editing, we propose MIND\n(Meta-cognitive INtegrated Dynamic Knowledge Editing), a framework that\nconstructs a meta-knowledge memory for self-awareness, employs game-theoretic\ninteractions to monitor knowledge activation, and incorporates label refinement\nfor noise-robust updates. Extensive experiments show that MIND significantly\noutperforms existing cognitive editing approaches, achieving strong performance\non both traditional and meta-cognitive knowledge editing benchmarks.", "AI": {"tldr": "CogEdit\u662f\u4e00\u4e2a\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5143\u8ba4\u77e5\u77e5\u8bc6\u7f16\u8f91\u80fd\u529b\u7684\u65b0\u57fa\u51c6\uff0c\u5305\u542b\u53cd\u4e8b\u5b9e\u9a71\u52a8\u7f16\u8f91\u3001\u8fb9\u754c\u7ea6\u675f\u7f16\u8f91\u548c\u566a\u58f0\u9c81\u68d2\u7f16\u8f91\u4e09\u4e2a\u5c42\u6b21\u3002\u4f5c\u8005\u63d0\u51fa\u4e86MIND\u6846\u67b6\uff0c\u901a\u8fc7\u5143\u77e5\u8bc6\u8bb0\u5fc6\u3001\u535a\u5f08\u8bba\u4ea4\u4e92\u548c\u6807\u7b7e\u7cbe\u70bc\u6765\u63d0\u5347\u5143\u8ba4\u77e5\u7f16\u8f91\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u77e5\u8bc6\u7f16\u8f91\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u8ba4\u77e5\u5c42\u9762\u7684\u4fee\u6539\uff0c\u7f3a\u4e4f\u5bf9\u66f4\u6df1\u5c42\u6b21\u5143\u8ba4\u77e5\u8fc7\u7a0b\u7684\u5173\u6ce8\u3002\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u8bc4\u4f30MLLMs\u5143\u8ba4\u77e5\u77e5\u8bc6\u7f16\u8f91\u80fd\u529b\u7684\u57fa\u51c6\u548c\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86CogEdit\u57fa\u51c6\uff0c\u5305\u542b\u4e09\u4e2a\u8bc4\u4f30\u5c42\u6b21\uff1a\u53cd\u4e8b\u5b9e\u9a71\u52a8\u7f16\u8f91\u3001\u8fb9\u754c\u7ea6\u675f\u7f16\u8f91\u548c\u566a\u58f0\u9c81\u68d2\u7f16\u8f91\u3002\u540c\u65f6\u63d0\u51fa\u4e86MIND\u6846\u67b6\uff0c\u4f7f\u7528\u5143\u77e5\u8bc6\u8bb0\u5fc6\u5b9e\u73b0\u81ea\u6211\u610f\u8bc6\uff0c\u901a\u8fc7\u535a\u5f08\u8bba\u4ea4\u4e92\u76d1\u63a7\u77e5\u8bc6\u6fc0\u6d3b\uff0c\u5e76\u91c7\u7528\u6807\u7b7e\u7cbe\u70bc\u8fdb\u884c\u566a\u58f0\u9c81\u68d2\u7684\u66f4\u65b0\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cMIND\u6846\u67b6\u5728\u4f20\u7edf\u548c\u5143\u8ba4\u77e5\u77e5\u8bc6\u7f16\u8f91\u57fa\u51c6\u4e0a\u90fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u8ba4\u77e5\u7f16\u8f91\u65b9\u6cd5\uff0c\u53d6\u5f97\u4e86\u5f3a\u52b2\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u5143\u8ba4\u77e5\u77e5\u8bc6\u7f16\u8f91\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u63d0\u51fa\u7684CogEdit\u57fa\u51c6\u548cMIND\u6846\u67b6\u4e3a\u63d0\u5347\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5143\u8ba4\u77e5\u7f16\u8f91\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u77e5\u8bc6\u66f4\u65b0\u548c\u7ea0\u9519\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2509.05379", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05379", "abs": "https://arxiv.org/abs/2509.05379", "authors": ["Sharif Noor Zisad", "Ragib Hasan"], "title": "ThreatGPT: An Agentic AI Framework for Enhancing Public Safety through Threat Modeling", "comment": null, "summary": "As our cities and communities become smarter, the systems that keep us safe,\nsuch as traffic control centers, emergency response networks, and public\ntransportation, also become more complex. With this complexity comes a greater\nrisk of security threats that can affect not just machines but real people's\nlives. To address this challenge, we present ThreatGPT, an agentic Artificial\nIntelligence (AI) assistant built to help people whether they are engineers,\nsafety officers, or policy makers to understand and analyze threats in public\nsafety systems. Instead of requiring deep cybersecurity expertise, it allows\nusers to simply describe the components of a system they are concerned about,\nsuch as login systems, data storage, or communication networks. Then, with the\nclick of a button, users can choose how they want the system to be analyzed by\nusing popular frameworks such as STRIDE, MITRE ATT&CK, CVE reports, NIST, or\nCISA. ThreatGPT is unique because it does not just provide threat information,\nbut rather it acts like a knowledgeable partner. Using few-shot learning, the\nAI learns from examples and generates relevant smart threat models. It can\nhighlight what might go wrong, how attackers could take advantage, and what can\nbe done to prevent harm. Whether securing a city's infrastructure or a local\nhealth service, this tool adapts to users' needs. In simple terms, ThreatGPT\nbrings together AI and human judgment to make our public systems safer. It is\ndesigned not just to analyze threats, but to empower people to understand and\nact on them, faster, smarter, and with more confidence.", "AI": {"tldr": "ThreatGPT\u662f\u4e00\u4e2aAI\u52a9\u624b\uff0c\u5e2e\u52a9\u975e\u7f51\u7edc\u5b89\u5168\u4e13\u5bb6\u5206\u6790\u516c\u5171\u5b89\u5168\u7cfb\u7edf\u7684\u5a01\u80c1\uff0c\u4f7f\u7528STRIDE\u3001MITRE ATT&CK\u7b49\u6846\u67b6\u751f\u6210\u667a\u80fd\u5a01\u80c1\u6a21\u578b\u3002", "motivation": "\u968f\u7740\u667a\u6167\u57ce\u5e02\u7cfb\u7edf\u65e5\u76ca\u590d\u6742\uff0c\u5b89\u5168\u5a01\u80c1\u98ce\u9669\u589e\u52a0\uff0c\u9700\u8981\u8ba9\u5de5\u7a0b\u5e08\u3001\u5b89\u5168\u5b98\u5458\u7b49\u975e\u7f51\u7edc\u5b89\u5168\u4e13\u5bb6\u4e5f\u80fd\u7406\u89e3\u548c\u5206\u6790\u7cfb\u7edf\u5a01\u80c1\u3002", "method": "\u57fa\u4e8e\u5c11\u6837\u672c\u5b66\u4e60\u7684AI\u4ee3\u7406\uff0c\u7528\u6237\u63cf\u8ff0\u7cfb\u7edf\u7ec4\u4ef6\u540e\uff0c\u53ef\u9009\u62e9\u4f7f\u7528STRIDE\u3001MITRE ATT&CK\u3001CVE\u3001NIST\u6216CISA\u7b49\u6846\u67b6\u8fdb\u884c\u5206\u6790\uff0c\u751f\u6210\u76f8\u5173\u5a01\u80c1\u6a21\u578b\u3002", "result": "\u5f00\u53d1\u51faThreatGPT\u5de5\u5177\uff0c\u80fd\u591f\u8bc6\u522b\u6f5c\u5728\u5a01\u80c1\u3001\u653b\u51fb\u8005\u5229\u7528\u65b9\u5f0f\u4ee5\u53ca\u9632\u62a4\u63aa\u65bd\uff0c\u9002\u5e94\u4e0d\u540c\u7528\u6237\u9700\u6c42\u3002", "conclusion": "ThreatGPT\u5c06AI\u4e0e\u4eba\u7c7b\u5224\u65ad\u7ed3\u5408\uff0c\u4f7f\u516c\u5171\u7cfb\u7edf\u66f4\u5b89\u5168\uff0c\u4e0d\u4ec5\u5206\u6790\u5a01\u80c1\uff0c\u8fd8\u8d4b\u80fd\u7528\u6237\u66f4\u5feb\u3001\u66f4\u667a\u80fd\u3001\u66f4\u81ea\u4fe1\u5730\u7406\u89e3\u548c\u5e94\u5bf9\u5a01\u80c1\u3002"}}
{"id": "2509.06429", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.06429", "abs": "https://arxiv.org/abs/2509.06429", "authors": ["Mehmet Bilal Er", "Nagehan \u0130lhan", "Umut Kuran"], "title": "Analyzing the Instability of Large Language Models in Automated Bug Injection and Correction", "comment": null, "summary": "The use of Large Language Models (LLMs) in software engineering tasks is\ngrowing, especially in the areas of bug fixing and code generation.\nNevertheless, these models often yield unstable results; when executed at\ndifferent times with the same input, they can generate radically different\ncode. The consistency of LLMs in bug-fixing tasks has not yet been thoroughly\nassessed, despite the fact that this instability has typically been discussed\nin the literature in relation to code generation. The purpose of this study is\nto look into how unstable an LLM like ChatGPT is when it comes to fixing code\nbugs. We examine the structural, syntactic, and functional variations among\nseveral fix recommendations made in response to the same prompt using code\nsamples with various error types. Additionally, we assess how instability is\naffected by the temperature settings (0, 0.5, and 1) used for the model's\ndeterministic operation. For a total of 20 problems in the experimental\nanalysis, the model produced three fix suggestions at each temperature value,\ncomparing nine distinct outputs for each problem. The Syntax Similarity and\nOutput Equivalence Rate (OER) metrics were used to assess the outputs'\nstructural and functional consistency. The results demonstrate that the model's\noutputs become much more unstable and variable as the temperature rises, with\nhigh temperatures showing especially high rates of functional failure.\nAccording to syntax similarity analyses, the suggested fixes show notable\nstructural differences at high temperatures but are fairly similar at low\ntemperatures. The purpose of this study is to provide important methodological\ninsights into how LLM-based error correction systems can be applied more\nconsistently in software development processes while also casting doubt on\ntheir dependability.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30ChatGPT\u5728\u4ee3\u7801\u4fee\u590d\u4efb\u52a1\u4e2d\u7684\u7a33\u5b9a\u6027\uff0c\u53d1\u73b0\u6e29\u5ea6\u8bbe\u7f6e\u9ad8\u65f6\u8f93\u51fa\u53d8\u5f97\u4e0d\u7a33\u5b9a\u4e14\u529f\u80fd\u5931\u6548\u7387\u9ad8", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u5e94\u7528\u65e5\u76ca\u589e\u957f\uff0c\u4f46\u5b83\u4eec\u7ecf\u5e38\u4ea7\u751f\u4e0d\u7a33\u5b9a\u7684\u7ed3\u679c\uff0c\u7279\u522b\u662f\u5728\u4ee3\u7801\u4fee\u590d\u4efb\u52a1\u4e2d\u7684\u4e00\u81f4\u6027\u8fd8\u672a\u5f97\u5230\u5168\u9762\u8bc4\u4f30", "method": "\u4f7f\u7528\u4e0d\u540c\u6e29\u5ea6\u8bbe\u7f6e(0, 0.5, 1)\u5bf920\u4e2a\u95ee\u9898\u751f\u62103\u4e2a\u4fee\u590d\u5efa\u8bae\uff0c\u6bd4\u8f83\u6bcf\u4e2a\u95ee\u9898\u76849\u4e2a\u8f93\u51fa\u3002\u4f7f\u7528\u8bed\u6cd5\u76f8\u4f3c\u6027\u548c\u8f93\u51fa\u7b49\u6548\u7387(OER)\u6307\u6807\u8bc4\u4f30\u7ed3\u6784\u548c\u529f\u80fd\u4e00\u81f4\u6027", "result": "\u6e29\u5ea6\u8d8a\u9ad8\uff0c\u6a21\u578b\u8f93\u51fa\u8d8a\u4e0d\u7a33\u5b9a\u548c\u53d8\u5316\uff0c\u9ad8\u6e29\u5ea6\u65f6\u529f\u80fd\u5931\u6548\u7387\u7279\u522b\u9ad8\u3002\u8bed\u6cd5\u5206\u6790\u663e\u793a\u9ad8\u6e29\u5ea6\u4e0b\u4fee\u590d\u5efa\u8bae\u7ed3\u6784\u5dee\u5f02\u663e\u8457\uff0c\u4f4e\u6e29\u5ea6\u4e0b\u76f8\u4f3c\u5ea6\u8f83\u9ad8", "conclusion": "\u7814\u7a76\u5bf9\u57fa\u4e8eLLM\u7684\u9519\u8bef\u7ea0\u6b63\u7cfb\u7edf\u5982\u4f55\u66f4\u4e00\u81f4\u5730\u5e94\u7528\u4e8e\u8f6f\u4ef6\u5f00\u53d1\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u91cd\u8981\u65b9\u6cd5\u8bba\u89c1\u89e3\uff0c\u540c\u65f6\u5bf9\u5176\u53ef\u9760\u6027\u63d0\u51fa\u4e86\u7591\u95ee"}}
{"id": "2509.05757", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05757", "abs": "https://arxiv.org/abs/2509.05757", "authors": ["Sarang Patil", "Zeyong Zhang", "Yiran Huang", "Tengfei Ma", "Mengjia Xu"], "title": "Hyperbolic Large Language Models", "comment": "32 pages, 6 figures", "summary": "Large language models (LLMs) have achieved remarkable success and\ndemonstrated superior performance across various tasks, including natural\nlanguage processing (NLP), weather forecasting, biological protein folding,\ntext generation, and solving mathematical problems. However, many real-world\ndata exhibit highly non-Euclidean latent hierarchical anatomy, such as protein\nnetworks, transportation networks, financial networks, brain networks, and\nlinguistic structures or syntactic trees in natural languages. Effectively\nlearning intrinsic semantic entailment and hierarchical relationships from\nthese raw, unstructured input data using LLMs remains an underexplored area.\nDue to its effectiveness in modeling tree-like hierarchical structures,\nhyperbolic geometry -- a non-Euclidean space -- has rapidly gained popularity\nas an expressive latent representation space for complex data modeling across\ndomains such as graphs, images, languages, and multi-modal data. Here, we\nprovide a comprehensive and contextual exposition of recent advancements in\nLLMs that leverage hyperbolic geometry as a representation space to enhance\nsemantic representation learning and multi-scale reasoning. Specifically, the\npaper presents a taxonomy of the principal techniques of Hyperbolic LLMs\n(HypLLMs) in terms of four main categories: (1) hyperbolic LLMs through exp/log\nmaps; (2) hyperbolic fine-tuned models; (3) fully hyperbolic LLMs, and (4)\nhyperbolic state-space models. We also explore crucial potential applications\nand outline future research directions. A repository of key papers, models,\ndatasets, and code implementations is available at\nhttps://github.com/sarangp2402/Hyperbolic-LLM-Models/tree/main.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u53cc\u66f2\u51e0\u4f55\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u51fa\u4e86Hyperbolic LLMs\u7684\u5206\u7c7b\u6846\u67b6\uff0c\u5305\u62ec\u56db\u79cd\u4e3b\u8981\u6280\u672f\u7c7b\u522b\uff0c\u5e76\u63a2\u8ba8\u4e86\u6f5c\u5728\u5e94\u7528\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u5177\u6709\u975e\u6b27\u51e0\u91cc\u5f97\u7684\u5c42\u6b21\u7ed3\u6784\u7279\u6027\uff0c\u800c\u4f20\u7edfLLMs\u5728\u5904\u7406\u8fd9\u7c7b\u6570\u636e\u65f6\u5b58\u5728\u5c40\u9650\u6027\u3002\u53cc\u66f2\u51e0\u4f55\u80fd\u6709\u6548\u5efa\u6a21\u6811\u72b6\u5c42\u6b21\u7ed3\u6784\uff0c\u56e0\u6b64\u9700\u8981\u63a2\u7d22\u5982\u4f55\u5c06\u53cc\u66f2\u51e0\u4f55\u6574\u5408\u5230LLMs\u4e2d\u4ee5\u589e\u5f3a\u8bed\u4e49\u8868\u793a\u5b66\u4e60\u3002", "method": "\u63d0\u51fa\u4e86Hyperbolic LLMs\u7684\u56db\u5206\u7c7b\u6cd5\uff1a1)\u901a\u8fc7\u6307\u6570/\u5bf9\u6570\u6620\u5c04\u7684\u53cc\u66f2LLMs\uff1b2)\u53cc\u66f2\u5fae\u8c03\u6a21\u578b\uff1b3)\u5b8c\u5168\u53cc\u66f2LLMs\uff1b4)\u53cc\u66f2\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u3002\u5efa\u7acb\u4e86\u76f8\u5173\u8bba\u6587\u3001\u6a21\u578b\u3001\u6570\u636e\u96c6\u548c\u4ee3\u7801\u7684\u8d44\u6e90\u5e93\u3002", "result": "\u7cfb\u7edf\u68b3\u7406\u4e86\u53cc\u66f2\u51e0\u4f55\u5728LLMs\u4e2d\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5efa\u7acb\u4e86\u5b8c\u6574\u7684\u5206\u7c7b\u6846\u67b6\uff0c\u4e3a\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u7684\u6280\u672f\u8def\u7ebf\u56fe\u548c\u8d44\u6e90\u652f\u6301\u3002", "conclusion": "\u53cc\u66f2\u51e0\u4f55\u4e3aLLMs\u5904\u7406\u5c42\u6b21\u7ed3\u6784\u6570\u636e\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u672a\u6765\u9700\u8981\u5728\u7406\u8bba\u5206\u6790\u3001\u8ba1\u7b97\u6548\u7387\u548c\u5b9e\u9645\u5e94\u7528\u7b49\u65b9\u9762\u8fdb\u4e00\u6b65\u6df1\u5165\u7814\u7a76\u3002"}}
{"id": "2509.05471", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05471", "abs": "https://arxiv.org/abs/2509.05471", "authors": ["Youjia Zheng", "Mohammad Zandsalimy", "Shanu Sushmita"], "title": "Behind the Mask: Benchmarking Camouflaged Jailbreaks in Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) are increasingly vulnerable to a sophisticated\nform of adversarial prompting known as camouflaged jailbreaking. This method\nembeds malicious intent within seemingly benign language to evade existing\nsafety mechanisms. Unlike overt attacks, these subtle prompts exploit\ncontextual ambiguity and the flexible nature of language, posing significant\nchallenges to current defense systems. This paper investigates the construction\nand impact of camouflaged jailbreak prompts, emphasizing their deceptive\ncharacteristics and the limitations of traditional keyword-based detection\nmethods. We introduce a novel benchmark dataset, Camouflaged Jailbreak Prompts,\ncontaining 500 curated examples (400 harmful and 100 benign prompts) designed\nto rigorously stress-test LLM safety protocols. In addition, we propose a\nmulti-faceted evaluation framework that measures harmfulness across seven\ndimensions: Safety Awareness, Technical Feasibility, Implementation Safeguards,\nHarmful Potential, Educational Value, Content Quality, and Compliance Score.\nOur findings reveal a stark contrast in LLM behavior: while models demonstrate\nhigh safety and content quality with benign inputs, they exhibit a significant\ndecline in performance and safety when confronted with camouflaged jailbreak\nattempts. This disparity underscores a pervasive vulnerability, highlighting\nthe urgent need for more nuanced and adaptive security strategies to ensure the\nresponsible and robust deployment of LLMs in real-world applications.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76LLMs\u4e2d\u7684\u4f2a\u88c5\u8d8a\u72f1\u653b\u51fb\uff0c\u6784\u5efa\u4e86\u5305\u542b500\u4e2a\u793a\u4f8b\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u51fa\u591a\u7ef4\u5ea6\u8bc4\u4f30\u6846\u67b6\uff0c\u53d1\u73b0LLMs\u5728\u9762\u5bf9\u4f2a\u88c5\u6076\u610f\u63d0\u793a\u65f6\u5b89\u5168\u6027\u663e\u8457\u4e0b\u964d\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9762\u4e34\u65b0\u578b\u7684\u4f2a\u88c5\u8d8a\u72f1\u653b\u51fb\uff0c\u8fd9\u79cd\u653b\u51fb\u5c06\u6076\u610f\u610f\u56fe\u9690\u85cf\u5728\u770b\u4f3c\u826f\u6027\u7684\u8bed\u8a00\u4e2d\uff0c\u9003\u907f\u73b0\u6709\u5b89\u5168\u673a\u5236\uff0c\u9700\u8981\u6df1\u5165\u7814\u7a76\u5176\u6784\u9020\u65b9\u6cd5\u548c\u5f71\u54cd\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b400\u4e2a\u6709\u5bb3\u63d0\u793a\u548c100\u4e2a\u826f\u6027\u63d0\u793a\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u4e86\u5305\u542b\u5b89\u5168\u611f\u77e5\u3001\u6280\u672f\u53ef\u884c\u6027\u3001\u5b9e\u65bd\u4fdd\u969c\u7b497\u4e2a\u7ef4\u5ea6\u7684\u591a\u5c42\u9762\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u7814\u7a76\u53d1\u73b0LLMs\u5728\u826f\u6027\u8f93\u5165\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9762\u5bf9\u4f2a\u88c5\u8d8a\u72f1\u653b\u51fb\u65f6\u5b89\u5168\u6027\u548c\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u66b4\u9732\u51fa\u4e25\u91cd\u7684\u5b89\u5168\u6f0f\u6d1e\u3002", "conclusion": "\u5f53\u524dLLMs\u5b58\u5728\u666e\u904d\u7684\u5b89\u5168\u8106\u5f31\u6027\uff0c\u8feb\u5207\u9700\u8981\u66f4\u7ec6\u81f4\u548c\u81ea\u9002\u5e94\u7684\u5b89\u5168\u7b56\u7565\u6765\u786e\u4fdd\u6a21\u578b\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u7684\u8d1f\u8d23\u4efb\u548c\u7a33\u5065\u90e8\u7f72\u3002"}}
{"id": "2509.06530", "categories": ["cs.SE", "D.2.10"], "pdf": "https://arxiv.org/pdf/2509.06530", "abs": "https://arxiv.org/abs/2509.06530", "authors": ["Sylvain Gu\u00e9rin", "Salvador Martinez", "Ciprian Teodorov"], "title": "Modeling in the Design Multiverse", "comment": null, "summary": "Real-world design processes often involve the evolution and divergence of\ndesign paths (by branching, revising, merging, etc.), especially when multiple\nstakeholders or teams operate concurrently and/or explore different\nalternatives for complex and heterogeneous systems. Unfortunately, this\nvariability in time and space can not be directly managed in current modeling\nspaces but requires resorting to external tools and methodologies.\n  In order to tackle this problem, we introduce the Design Multiverse. The\nDesign Multiverse aims to integrate in the modeling space a selection of\nrevisions and variants, representing snapshots of a design state composed of\nmultiple artifacts. This enables stakeholders to seamlessly trace, analyze, and\nmanage design decisions, system variants, and their interdependencies.\nConcretely, in this paper we present a conceptual definition of the Design\nMultiverse, discuss usage scenarios such as model product lines and\nmodel/metamodel co-evolution, and propose an implementation leveraging the\nmodel federation paradigm.", "AI": {"tldr": "\u8bbe\u8ba1\u591a\u5143\u5b87\u5b99\u6982\u5ff5\uff0c\u901a\u8fc7\u6a21\u578b\u8054\u76df\u5b9e\u73b0\u5bf9\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u7684\u7248\u672c\u5206\u652f\u3001\u4fee\u8ba2\u548c\u5408\u5e76\u7b49\u590d\u6742\u53d8\u5316\u8fdb\u884c\u7ba1\u7406", "motivation": "\u5b9e\u9645\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u5b58\u5728\u591a\u91cd\u8bbe\u8ba1\u8def\u5f84\u7684\u6f14\u5316\u548c\u5206\u652f\uff0c\u5f53\u524d\u6a21\u578b\u5de5\u5177\u65e0\u6cd5\u76f4\u63a5\u7ba1\u7406\u8fd9\u79cd\u65f6\u7a7a\u53d8\u5316\u6027", "method": "\u63d0\u51fa\u8bbe\u8ba1\u591a\u5143\u5b87\u5b99\u6982\u5ff5\uff0c\u901a\u8fc7\u6a21\u578b\u8054\u76df\u5b9e\u73b0\u5bf9\u591a\u4e2a\u8bbe\u8ba1\u72b6\u6001\u6269\u51d1\u7684\u96c6\u6210\u7ba1\u7406", "result": "\u6784\u5efa\u4e86\u652f\u6301\u8bbe\u8ba1\u51b3\u7b56\u8ffd\u8e2a\u3001\u7cfb\u7edf\u53d8\u4f53\u7ba1\u7406\u548c\u4f9d\u8d56\u5173\u7cfb\u5206\u6790\u7684\u7edf\u4e00\u6a21\u578b\u7a7a\u95f4", "conclusion": "\u8bbe\u8ba1\u591a\u5143\u5b87\u5b99\u4e3a\u590d\u6742\u5f02\u6784\u7cfb\u7edf\u7684\u5e76\u53d1\u8bbe\u8ba1\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u53d8\u5316\u7ba1\u7406\u65b9\u6848"}}
{"id": "2509.05764", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05764", "abs": "https://arxiv.org/abs/2509.05764", "authors": ["Yuwei Lou", "Hao Hu", "Shaocong Ma", "Zongfei Zhang", "Liang Wang", "Jidong Ge", "Xianping Tao"], "title": "DRF: LLM-AGENT Dynamic Reputation Filtering Framework", "comment": "This paper has been accepted by ICONIP 2025 but not published", "summary": "With the evolution of generative AI, multi - agent systems leveraging large -\nlanguage models(LLMs) have emerged as a powerful tool for complex tasks.\nHowever, these systems face challenges in quantifying agent performance and\nlack mechanisms to assess agent credibility. To address these issues, we\nintroduce DRF, a dynamic reputation filtering framework. DRF constructs an\ninteractive rating network to quantify agent performance, designs a reputation\nscoring mechanism to measure agent honesty and capability, and integrates an\nUpper Confidence Bound - based strategy to enhance agent selection efficiency.\nExperiments show that DRF significantly improves task completion quality and\ncollaboration efficiency in logical reasoning and code - generation tasks,\noffering a new approach for multi - agent systems to handle large - scale\ntasks.", "AI": {"tldr": "DRF\u662f\u4e00\u79cd\u52a8\u6001\u58f0\u8a89\u8fc7\u6ee4\u6846\u67b6\uff0c\u901a\u8fc7\u8bc4\u5206\u7f51\u7edc\u3001\u58f0\u8a89\u8ba1\u5206\u548cUCB\u7b56\u7565\u6765\u91cf\u5316\u591a\u4ee3\u7406\u7cfb\u7edf\u4e2d\u4ee3\u7406\u7684\u6027\u80fd\u548c\u53ef\u9760\u6027\uff0c\u663e\u8457\u63d0\u5347\u4efb\u52a1\u5b8c\u6210\u8d28\u91cf\u548c\u534f\u4f5c\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u591a\u4ee3\u7406\u7cfb\u7edf\u4e2d\u4ee3\u7406\u6027\u80fd\u91cf\u5316\u56f0\u96be\u548c\u7f3a\u4e4f\u4ee3\u7406\u53ef\u9760\u6027\u8bc4\u4f30\u673a\u5236\u7684\u6311\u6218\u3002", "method": "\u6784\u5efa\u4ea4\u4e92\u5f0f\u8bc4\u5206\u7f51\u7edc\u91cf\u5316\u4ee3\u7406\u6027\u80fd\uff0c\u8bbe\u8ba1\u58f0\u8a89\u8ba1\u5206\u673a\u5236\u6d4b\u91cf\u4ee3\u7406\u8bda\u4fe1\u5ea6\u548c\u80fd\u529b\uff0c\u96c6\u6210\u57fa\u4e8e\u4e0a\u4fe1\u9650\u754c\u7684\u7b56\u7565\u63d0\u5347\u4ee3\u7406\u9009\u62e9\u6548\u7387\u3002", "result": "\u5728\u903b\u8f91\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\uff0cDRF\u663e\u8457\u63d0\u9ad8\u4e86\u4efb\u52a1\u5b8c\u6210\u8d28\u91cf\u548c\u534f\u4f5c\u6548\u7387\u3002", "conclusion": "DRF\u4e3a\u591a\u4ee3\u7406\u7cfb\u7edf\u5904\u7406\u5927\u89c4\u6a21\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2509.05496", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.05496", "abs": "https://arxiv.org/abs/2509.05496", "authors": ["Charbel Mattar", "Jacques Bou Abdo", "Abdallah Makhoul", "Benoit Piranda", "Jacques Demerjian"], "title": "What is Cybersecurity in Space?", "comment": null, "summary": "Satellites, drones, and 5G space links now support\n  critical services such as air traffic, finance, and weather. Yet most\n  were not built to resist modern cyber threats. Ground stations\n  can be breached, GPS jammed, and supply chains compromised,\n  while no shared list of vulnerabilities or safe testing range exists.\n  This paper maps eleven research gaps, including secure\n  routing, onboard intrusion detection, recovery methods, trusted\n  supply chains, post-quantum encryption, zero-trust architectures,\n  and real-time impact monitoring. For each, we outline the\n  challenge, why it matters, and a guiding research question. We\n  also highlight an agentic (multi-agent) AI approach where small,\n  task-specific agents share defense tasks onboard instead of one\n  large model.\n  Finally, we propose a five-year roadmap: post-quantum and\n  QKD flight trials, open cyber-ranges, clearer vulnerability shar ing, and\nearly multi-agent deployments. These steps move space\n  cybersecurity from reactive patching toward proactive resilience.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5206\u6790\u4e86\u7a7a\u95f4\u7cfb\u7edf\u7684\u7f51\u7edc\u5b89\u5168\u6f0f\u6d1e\uff0c\u6307\u51fa\u4e8611\u4e2a\u7814\u7a76\u7a7a\u767d\u533a\u57df\uff0c\u5e76\u63d0\u51fa\u4e86\u4ee5\u591a\u4ee3\u7406AI\u548c\u4e3b\u52a8\u9632\u5fa1\u4e3a\u6838\u5fc3\u7684\u4e94\u5e74\u8def\u7ebf\u56fe\u3002", "motivation": "\u536b\u661f\u3001\u65e0\u4eba\u673a\u548c5G\u7a7a\u95f4\u94fe\u8def\u73b0\u5728\u652f\u6491\u7740\u7a7a\u4e2d\u4ea4\u901a\u3001\u91d1\u878d\u548c\u6c14\u8c61\u7b49\u5173\u952e\u670d\u52a1\uff0c\u4f46\u8fd9\u4e9b\u7cfb\u7edf\u8bbe\u8ba1\u65f6\u5e76\u672a\u8003\u8651\u73b0\u4ee3\u7f51\u7edc\u5a01\u80c1\uff0c\u5b58\u5728\u91cd\u5927\u5b89\u5168\u98ce\u9669\u3002", "method": "\u8bc6\u522b\u548c\u5206\u6790\u4e8611\u4e2a\u5173\u952e\u7814\u7a76\u7f3a\u53e3\uff0c\u5305\u62ec\u5b89\u5168\u8def\u7531\u3001\u673a\u8f7d\u5165\u4fb5\u68c0\u6d4b\u3001\u6062\u590d\u65b9\u6cd5\u3001\u53ef\u4fe1\u4f9b\u5e94\u94fe\u3001\u540e\u91cf\u5b50\u52a0\u5bc6\u7b49\uff0c\u5e76\u63d0\u51fa\u4ee5\u591a\u4ee3\u7406AI\u4e3a\u6838\u5fc3\u7684\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u7ed9\u51fa\u4e86\u6bcf\u4e2a\u6311\u6218\u7684\u8be6\u7ec6\u5206\u6790\u3001\u91cd\u8981\u6027\u8bf4\u660e\u548c\u7814\u7a76\u95ee\u9898\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u7a7a\u95f4\u7f51\u7edc\u5b89\u5168\u7814\u7a76\u6846\u67b6\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e94\u5e74\u8def\u7ebf\u56fe\uff0c\u5305\u62ec\u540e\u91cf\u5b50\u548cQKD\u98de\u884c\u8bd5\u9a8c\u3001\u5f00\u653f\u7f51\u7edc\u5b89\u5168\u6d4b\u8bd5\u8303\u56f4\u3001\u6f0f\u6d1e\u5171\u4eab\u673a\u5236\u548c\u65e9\u671f\u591a\u4ee3\u7406\u90e8\u7f72\uff0c\u4ee5\u5b9e\u73b0\u4ece\u53cd\u5e94\u5f0f\u8865\u4e01\u5411\u4e3b\u52a8\u5f39\u6027\u9632\u5fa1\u7684\u8f6c\u53d8\u3002"}}
{"id": "2509.06688", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.06688", "abs": "https://arxiv.org/abs/2509.06688", "authors": ["Heerok Banerjee"], "title": "Design and Implementation of a Domain-specific Language for Modelling Evacuation Scenarios Using Eclipse EMG/GMF Tool", "comment": null, "summary": "Domain-specific languages (DSLs) play a crucial role in resolving internal\ndependencies across enterprises and boosts their upfront business management\nprocesses. Yet, a lot of development is needed to build modelling frameworks\nwhich support graphical interfaces (canvas, pallettes etc.), hierarchical\nstructures and easy implementation to shorten the gap for novice users. In this\npaper, a DSL namely, Bmod is introduced, which can be used to model evacuation\nscenarios. The language is built using Eclipse Modelling Framework (EMF) and\nEclipse Graphical Modelling Framework (GMF). Furthermore, a comparison is also\nshown between Eclipse EMF/GMF and other modelling tools such as AToMPM,\nmetaDepth, Sirius etc with respect to expressiveness, learning curve and\nperformance.", "AI": {"tldr": "Bmod\u662f\u4e00\u79cd\u57fa\u4e8eEclipse EMF/GMF\u6784\u5efa\u7684\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff0c\u7528\u4e8e\u5efa\u6a21\u758f\u6563\u573a\u666f\uff0c\u5e76\u4e0e\u5176\u4ed6\u5efa\u6a21\u5de5\u5177\u8fdb\u884c\u4e86\u6bd4\u8f83\u5206\u6790", "motivation": "\u89e3\u51b3\u4f01\u4e1a\u5185\u90e8\u4f9d\u8d56\u5173\u7cfb\uff0c\u63d0\u5347\u4e1a\u52a1\u7ba1\u7406\u6d41\u7a0b\uff0c\u7f29\u77ed\u65b0\u624b\u7528\u6237\u7684\u5b66\u4e60\u5dee\u8ddd\uff0c\u9700\u8981\u5f00\u53d1\u652f\u6301\u56fe\u5f62\u754c\u9762\u3001\u5c42\u6b21\u7ed3\u6784\u548c\u6613\u7528\u5b9e\u73b0\u7684\u5efa\u6a21\u6846\u67b6", "method": "\u4f7f\u7528Eclipse\u5efa\u6a21\u6846\u67b6(EMF)\u548c\u56fe\u5f62\u5efa\u6a21\u6846\u67b6(GMF)\u6784\u5efaBmod DSL\uff0c\u5e76\u4e0eAToMPM\u3001metaDepth\u3001Sirius\u7b49\u5de5\u5177\u5728\u8868\u8fbe\u80fd\u529b\u3001\u5b66\u4e60\u66f2\u7ebf\u548c\u6027\u80fd\u65b9\u9762\u8fdb\u884c\u6bd4\u8f83", "result": "\u5f00\u53d1\u4e86Bmod DSL\u7528\u4e8e\u758f\u6563\u573a\u666f\u5efa\u6a21\uff0c\u901a\u8fc7\u6bd4\u8f83\u5206\u6790\u5c55\u793a\u4e86\u4e0d\u540c\u5efa\u6a21\u5de5\u5177\u7684\u7279\u70b9", "conclusion": "\u57fa\u4e8eEclipse EMF/GMF\u7684Bmod DSL\u4e3a\u758f\u6563\u573a\u666f\u5efa\u6a21\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5de5\u5177\u6bd4\u8f83\u4e3a\u9009\u62e9\u5408\u9002\u7684\u5efa\u6a21\u6846\u67b6\u63d0\u4f9b\u4e86\u53c2\u8003"}}
{"id": "2509.05772", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05772", "abs": "https://arxiv.org/abs/2509.05772", "authors": ["Nasser Alkhulaifi", "Ismail Gokay Dogan", "Timothy R. Cargan", "Alexander L. Bowler", "Direnc Pekaslan", "Nicholas J. Watson", "Isaac Triguero"], "title": "Decision-Focused Learning Enhanced by Automated Feature Engineering for Energy Storage Optimisation", "comment": "22 pages, 10 figures, journal-based paper", "summary": "Decision-making under uncertainty in energy management is complicated by\nunknown parameters hindering optimal strategies, particularly in Battery Energy\nStorage System (BESS) operations. Predict-Then-Optimise (PTO) approaches treat\nforecasting and optimisation as separate processes, allowing prediction errors\nto cascade into suboptimal decisions as models minimise forecasting errors\nrather than optimising downstream tasks. The emerging Decision-Focused Learning\n(DFL) methods overcome this limitation by integrating prediction and\noptimisation; however, they are relatively new and have been tested primarily\non synthetic datasets or small-scale problems, with limited evidence of their\npractical viability. Real-world BESS applications present additional\nchallenges, including greater variability and data scarcity due to collection\nconstraints and operational limitations. Because of these challenges, this work\nleverages Automated Feature Engineering (AFE) to extract richer representations\nand improve the nascent approach of DFL. We propose an AFE-DFL framework\nsuitable for small datasets that forecasts electricity prices and demand while\noptimising BESS operations to minimise costs. We validate its effectiveness on\na novel real-world UK property dataset. The evaluation compares DFL methods\nagainst PTO, with and without AFE. The results show that, on average, DFL\nyields lower operating costs than PTO and adding AFE further improves the\nperformance of DFL methods by 22.9-56.5% compared to the same models without\nAFE. These findings provide empirical evidence for DFL's practical viability in\nreal-world settings, indicating that domain-specific AFE enhances DFL and\nreduces reliance on domain expertise for BESS optimisation, yielding economic\nbenefits with broader implications for energy management systems facing similar\nchallenges.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u81ea\u52a8\u7279\u5f81\u5de5\u7a0b\uff08AFE\uff09\u548c\u51b3\u7b56\u805a\u7126\u5b66\u4e60\uff08DFL\uff09\u7684\u684c\u9762\uff0c\u7528\u4e8e\u89e3\u51b3\u80fd\u6e90\u7ba1\u7406\u4e2d\u7684\u7ecf\u6d4e\u4f18\u5316\u95ee\u9898\uff0c\u5728\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u66f4\u4f4e\u7684\u8fd0\u8425\u6210\u672c\u3002", "motivation": "\u80fd\u6e90\u7ba1\u7406\u4e2d\u7684\u51b3\u7b56\u95ee\u9898\u53d7\u5230\u672a\u77e5\u53c2\u6570\u7684\u5f71\u54cd\uff0c\u4f20\u7edf\u7684\u9884\u6d4b-\u4f18\u5316\u5206\u79bb\u65b9\u6cd5\u5bfc\u81f4\u9884\u6d4b\u9519\u8bef\u4f20\u64ad\u5230\u51b3\u7b56\u4e2d\u3002\u867d\u7136\u51b3\u7b56\u805a\u7126\u5b66\u4e60\u65b9\u6cd5\u80fd\u591f\u5145\u5206\u5229\u7528\u9884\u6d4b\u4e0e\u4f18\u5316\u7684\u96c6\u6210\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9762\u4e34\u6570\u636e\u7a00\u7f3a\u548c\u53d8\u5f02\u6027\u6311\u6218\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e86AFE-DFL\u684c\u9762\uff0c\u901a\u8fc7\u81ea\u52a8\u7279\u5f81\u5de5\u7a0b\u63d0\u53d6\u66f4\u4e30\u5bcc\u7684\u6570\u636e\u8868\u5f81\uff0c\u5e76\u5c06\u5176\u4e0e\u51b3\u7b56\u805a\u7126\u5b66\u4e60\u65b9\u6cd5\u76f8\u7ed3\u5408\u3002\u8be5\u65b9\u6cd5\u540c\u65f6\u9884\u6d4b\u7535\u4ef7\u548c\u9700\u6c42\uff0c\u4f18\u5316\u7535\u6c60\u80fd\u91cf\u5b58\u50a8\u7cfb\u7edf\u8fd0\u884c\u4ee5\u6700\u5c0f\u5316\u6210\u672c\u3002", "result": "\u5728\u82f1\u56fd\u5b9e\u9645\u623f\u5c4b\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cDFL\u65b9\u6cd5\u6bd4PTO\u65b9\u6cd5\u5e73\u5747\u8282\u7701\u66f4\u591a\u8fd0\u8425\u6210\u672c\u3002\u6dfb\u52a0AFE\u540e\uff0cDFL\u65b9\u6cd5\u7684\u6027\u80fd\u8fdb\u4e00\u6b65\u63d0\u534722.9-56.5%\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u4e3aDFL\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u884c\u6027\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u652f\u6491\uff0c\u6807\u5fd7\u7740\u9886\u57df\u7279\u5b9a\u7684\u81ea\u52a8\u7279\u5f81\u5de5\u7a0b\u80fd\u591f\u589e\u5f3aDFL\u65b9\u6cd5\uff0c\u51cf\u5c11\u5bf9\u9886\u57df\u4e13\u5bb6\u77e5\u8bc6\u7684\u4f9d\u8d56\uff0c\u5e76\u5728\u80fd\u6e90\u7ba1\u7406\u7cfb\u7edf\u4e2d\u5e26\u6765\u7ecf\u6d4e\u6548\u76ca\u3002"}}
{"id": "2509.05552", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.05552", "abs": "https://arxiv.org/abs/2509.05552", "authors": ["Ali Arastehfard", "Weiran Liu", "Joshua Lee", "Bingyu Liu", "Xuegang Ban", "Yuan Hong"], "title": "Secure and Efficient $L^p$-Norm Computation for Two-Party Learning Applications", "comment": null, "summary": "Secure norm computation is becoming increasingly important in many real-world\nlearning applications. However, existing cryptographic systems often lack a\ngeneral framework for securely computing the $L^p$-norm over private inputs\nheld by different parties. These systems often treat secure norm computation as\na black-box process, neglecting to design tailored cryptographic protocols that\noptimize performance. Moreover, they predominantly focus on the $L^2$-norm,\npaying little attention to other popular $L^p$-norms, such as $L^1$ and\n$L^\\infty$, which are commonly used in practice, such as machine learning tasks\nand location-based services.\n  To our best knowledge, we propose the first comprehensive framework for\nsecure two-party $L^p$-norm computations ($L^1$, $L^2$, and $L^\\infty$),\ndenoted as \\mbox{Crypto-$L^p$}, designed to be versatile across various\napplications. We have designed, implemented, and thoroughly evaluated our\nframework across a wide range of benchmarking applications, state-of-the-art\n(SOTA) cryptographic protocols, and real-world datasets to validate its\neffectiveness and practical applicability. In summary, \\mbox{Crypto-$L^p$}\noutperforms prior works on secure $L^p$-norm computation, achieving $82\\times$,\n$271\\times$, and $42\\times$ improvements in runtime while reducing\ncommunication overhead by $36\\times$, $4\\times$, and $21\\times$ for $p=1$, $2$,\nand $\\infty$, respectively. Furthermore, we take the first step in adapting our\nCrypto-$L^p$ framework for secure machine learning inference, reducing\ncommunication costs by $3\\times$ compared to SOTA systems while maintaining\ncomparable runtime and accuracy.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u7b2c\u4e00\u4e2a\u7efc\u5408\u6027\u7684\u5b89\u5168\u4e24\u65b9L^p\u8303\u6570\u8ba1\u7b97\u6846\u67b6Crypto-L^p\uff0c\u652f\u6301L^1\u3001L^2\u548cL^\u221e\u8303\u6570\uff0c\u5728\u8fd0\u884c\u65f6\u548c\u901a\u4fe1\u5f00\u9500\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u52a0\u5bc6\u7cfb\u7edf\u7f3a\u4e4f\u901a\u7528\u7684\u5b89\u5168L^p\u8303\u6570\u8ba1\u7b97\u6846\u67b6\uff0c\u4e3b\u8981\u96c6\u4e2d\u5728L^2\u8303\u6570\u800c\u5ffd\u89c6\u4e86L^1\u548cL^\u221e\u7b49\u5e38\u7528\u8303\u6570\u5728\u673a\u5668\u5b66\u4e60\u548c\u4f4d\u7f6e\u670d\u52a1\u4e2d\u7684\u5e94\u7528\u9700\u6c42\u3002", "method": "\u8bbe\u8ba1\u4e86Crypto-L^p\u6846\u67b6\uff0c\u901a\u8fc7\u4e3a\u5b89\u5168L^p\u8303\u6570\u8ba1\u7b97\u91c7\u7528\u4e13\u95e8\u8bbe\u8ba1\u7684\u52a0\u5bc6\u534f\u8bae\u6765\u4f18\u5316\u6027\u80fd\uff0c\u652f\u6301L^1\u3001L^2\u548cL^\u221e\u4e09\u79cd\u8303\u6570\u8ba1\u7b97\u3002", "result": "\u5728\u8fd0\u884c\u65f6\u65b9\u9762\u5b9e\u73b0\u4e8682\u500d\u3001271\u500d\u548c42\u500d\u7684\u63d0\u5347\uff0c\u901a\u4fe1\u5f00\u9500\u51cf\u5c1136\u500d\u30014\u500d\u548c21\u500d\uff08\u5206\u522b\u5bf9\u5e94p=1,2,\u221e\uff09\uff1b\u5728\u5b89\u5168\u673a\u5668\u5b66\u4e60\u63a8\u7406\u4e2d\u901a\u4fe1\u6210\u672c\u964d\u4f4e3\u500d\u3002", "conclusion": "Crypto-L^p\u6846\u67b6\u4e3a\u5b89\u5168L^p\u8303\u6570\u8ba1\u7b97\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u7efc\u5408\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u663e\u8457\u7684\u6027\u80fd\u4f18\u52bf\u548c\u5e7f\u6cdb\u7684\u5b9e\u9645\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2509.06716", "categories": ["cs.SE", "cs.PF"], "pdf": "https://arxiv.org/pdf/2509.06716", "abs": "https://arxiv.org/abs/2509.06716", "authors": ["Th\u00e9o Matricon", "Mathieu Acher", "Helge Spieker", "Arnaud Gotlieb"], "title": "Efficiently Ranking Software Variants with Minimal Benchmarks", "comment": null, "summary": "Benchmarking is a common practice in software engineering to assess the\nqualities and performance of software variants, coming from multiple competing\nsystems or from configurations of the same system. Benchmarks are used notably\nto compare and understand variant performance, fine-tune software, detect\nregressions, or design new software systems. The execution of benchmarks to get\na complete picture of software variants is highly costly in terms of\ncomputational resources and time. In this paper, we propose a novel approach\nfor reducing benchmarks while maintaining stable rankings, using test suite\noptimization techniques. That is, we remove instances from the benchmarks while\ntrying to keep the same rankings of the variants on all tests. Our method,\nBISection Sampling, BISS, strategically retains the most critical tests and\napplies a novel divide-and-conquer approach to efficiently sample among\nrelevant remaining tests. We experiment with datasets and use cases from LLM\nleaderboards, SAT competitions, and configurable systems for performance\nmodeling. Our results show that our method outperforms baselines even when\noperating on a subset of variants. Using BISS, we reduce the computational cost\nof the benchmarks on average to 44% and on more than half the benchmarks by up\nto 99% without loss in ranking stability.", "AI": {"tldr": "\u63d0\u51faBISS\u65b9\u6cd5\uff0c\u901a\u8fc7\u6d4b\u8bd5\u5957\u4ef6\u4f18\u5316\u6280\u672f\u51cf\u5c11\u57fa\u51c6\u6d4b\u8bd5\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u53d8\u4f53\u6392\u540d\u7684\u7a33\u5b9a\u6027", "motivation": "\u57fa\u51c6\u6d4b\u8bd5\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7528\u4e8e\u8bc4\u4f30\u8f6f\u4ef6\u53d8\u4f53\u7684\u8d28\u91cf\u548c\u6027\u80fd\uff0c\u4f46\u6267\u884c\u5b8c\u6574\u57fa\u51c6\u6d4b\u8bd5\u7684\u8ba1\u7b97\u8d44\u6e90\u548c\u65f6\u95f4\u6210\u672c\u6781\u9ad8", "method": "BISS\uff08BISection Sampling\uff09\u65b9\u6cd5\u7b56\u7565\u6027\u5730\u4fdd\u7559\u6700\u5173\u952e\u6d4b\u8bd5\uff0c\u5e76\u5e94\u7528\u65b0\u9896\u7684\u5206\u6cbb\u65b9\u6cd5\u5728\u76f8\u5173\u5269\u4f59\u6d4b\u8bd5\u4e2d\u9ad8\u6548\u91c7\u6837", "result": "\u5728LLM\u6392\u884c\u699c\u3001SAT\u7ade\u8d5b\u548c\u53ef\u914d\u7f6e\u7cfb\u7edf\u6027\u80fd\u5efa\u6a21\u7684\u6570\u636e\u96c6\u4e0a\uff0cBISS\u65b9\u6cd5\u5e73\u5747\u5c06\u57fa\u51c6\u6d4b\u8bd5\u8ba1\u7b97\u6210\u672c\u964d\u4f4e\u523044%\uff0c\u8d85\u8fc7\u4e00\u534a\u7684\u57fa\u51c6\u6d4b\u8bd5\u53ef\u51cf\u5c11\u9ad8\u8fbe99%\u7684\u6210\u672c\uff0c\u4e14\u6392\u540d\u7a33\u5b9a\u6027\u65e0\u635f\u5931", "conclusion": "BISS\u65b9\u6cd5\u80fd\u663e\u8457\u964d\u4f4e\u57fa\u51c6\u6d4b\u8bd5\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u53d8\u4f53\u6392\u540d\u7684\u7a33\u5b9a\u6027\uff0c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5"}}
{"id": "2509.05818", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05818", "abs": "https://arxiv.org/abs/2509.05818", "authors": ["Won Seok Jang", "Hieu Tran", "Manav Mistry", "SaiKiran Gandluri", "Yifan Zhang", "Sharmin Sultana", "Sunjae Kown", "Yuan Zhang", "Zonghai Yao", "Hong Yu"], "title": "Chatbot To Help Patients Understand Their Health", "comment": "Accepted in EMNLP 2025 Findings", "summary": "Patients must possess the knowledge necessary to actively participate in\ntheir care. We present NoteAid-Chatbot, a conversational AI that promotes\npatient understanding via a novel 'learning as conversation' framework, built\non a multi-agent large language model (LLM) and reinforcement learning (RL)\nsetup without human-labeled data. NoteAid-Chatbot was built on a lightweight\nLLaMA 3.2 3B model trained in two stages: initial supervised fine-tuning on\nconversational data synthetically generated using medical conversation\nstrategies, followed by RL with rewards derived from patient understanding\nassessments in simulated hospital discharge scenarios. Our evaluation, which\nincludes comprehensive human-aligned assessments and case studies, demonstrates\nthat NoteAid-Chatbot exhibits key emergent behaviors critical for patient\neducation, such as clarity, relevance, and structured dialogue, even though it\nreceived no explicit supervision for these attributes. Our results show that\neven simple Proximal Policy Optimization (PPO)-based reward modeling can\nsuccessfully train lightweight, domain-specific chatbots to handle multi-turn\ninteractions, incorporate diverse educational strategies, and meet nuanced\ncommunication objectives. Our Turing test demonstrates that NoteAid-Chatbot\nsurpasses non-expert human. Although our current focus is on healthcare, the\nframework we present illustrates the feasibility and promise of applying\nlow-cost, PPO-based RL to realistic, open-ended conversational domains,\nbroadening the applicability of RL-based alignment methods.", "AI": {"tldr": "NoteAid-Chatbot\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53LLM\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u5bf9\u8bddAI\u7cfb\u7edf\uff0c\u901a\u8fc7'\u5b66\u4e60\u5373\u5bf9\u8bdd'\u6846\u67b6\u5e2e\u52a9\u60a3\u8005\u7406\u89e3\u533b\u7597\u4fe1\u606f\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7LLaMA 3.2 3B\u6a21\u578b\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u5373\u53ef\u5b9e\u73b0\u6e05\u6670\u3001\u76f8\u5173\u548c\u7ed3\u6784\u5316\u5bf9\u8bdd\u7b49\u5173\u952e\u884c\u4e3a\u3002", "motivation": "\u60a3\u8005\u9700\u8981\u5177\u5907\u5fc5\u8981\u7684\u77e5\u8bc6\u6765\u79ef\u6781\u53c2\u4e0e\u81ea\u5df1\u7684\u62a4\u7406\u8fc7\u7a0b\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u80fd\u591f\u4fc3\u8fdb\u60a3\u8005\u7406\u89e3\u7684\u5bf9\u8bddAI\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\uff1a\u9996\u5148\u5728\u5408\u6210\u751f\u6210\u7684\u533b\u7597\u5bf9\u8bdd\u6570\u636e\u4e0a\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\uff0c\u7136\u540e\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\uff08PPO\uff09\u5728\u6a21\u62df\u533b\u9662\u51fa\u9662\u573a\u666f\u4e2d\u8fdb\u884c\u8bad\u7ec3\uff0c\u5956\u52b1\u57fa\u4e8e\u60a3\u8005\u7406\u89e3\u8bc4\u4f30\u3002", "result": "NoteAid-Chatbot\u5c55\u73b0\u51fa\u5173\u952e\u7684\u65b0\u5174\u884c\u4e3a\uff08\u6e05\u6670\u6027\u3001\u76f8\u5173\u6027\u548c\u7ed3\u6784\u5316\u5bf9\u8bdd\uff09\uff0c\u5728\u56fe\u7075\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u975e\u4e13\u5bb6\u4eba\u7c7b\u8868\u73b0\uff0c\u8bc1\u660e\u8f7b\u91cf\u7ea7\u6a21\u578b\u4e5f\u80fd\u5904\u7406\u591a\u8f6e\u4ea4\u4e92\u548c\u590d\u6742\u6c9f\u901a\u76ee\u6807\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c55\u793a\u4e86\u4f4e\u6210\u672cPPO\u5f3a\u5316\u5b66\u4e60\u5728\u73b0\u5b9e\u5f00\u653e\u57df\u5bf9\u8bdd\u4e2d\u7684\u53ef\u884c\u6027\u548c\u524d\u666f\uff0c\u62d3\u5bbd\u4e86\u57fa\u4e8eRL\u7684\u5bf9\u9f50\u65b9\u6cd5\u7684\u9002\u7528\u6027\uff0c\u867d\u7136\u5f53\u524d\u4e13\u6ce8\u4e8e\u533b\u7597\u9886\u57df\u4f46\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u3002"}}
{"id": "2509.05608", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.05608", "abs": "https://arxiv.org/abs/2509.05608", "authors": ["Waris Gill", "Natalie Isak", "Matthew Dressman"], "title": "Cross-Service Threat Intelligence in LLM Services using Privacy-Preserving Fingerprints", "comment": null, "summary": "The widespread deployment of LLMs across enterprise services has created a\ncritical security blind spot. Organizations operate multiple LLM services\nhandling billions of queries daily, yet regulatory compliance boundaries\nprevent these services from sharing threat intelligence about prompt injection\nattacks, the top security risk for LLMs. When an attack is detected in one\nservice, the same threat may persist undetected in others for months, as\nprivacy regulations prohibit sharing user prompts across compliance boundaries.\n  We present BinaryShield, the first privacy-preserving threat intelligence\nsystem that enables secure sharing of attack fingerprints across compliance\nboundaries. BinaryShield transforms suspicious prompts through a unique\npipeline combining PII redaction, semantic embedding, binary quantization, and\nrandomized response mechanism to potentially generate non-invertible\nfingerprints that preserve attack patterns while providing privacy. Our\nevaluations demonstrate that BinaryShield achieves an F1-score of 0.94,\nsignificantly outperforming SimHash (0.77), the privacy-preserving baseline,\nwhile achieving 64x storage reduction and 38x faster similarity search compared\nto dense embeddings.", "AI": {"tldr": "BinaryShield\u662f\u4e00\u4e2a\u9690\u79c1\u4fdd\u62a4\u7684\u5a01\u80c1\u60c5\u62a5\u7cfb\u7edf\uff0c\u901a\u8fc7PII\u8131\u654f\u3001\u8bed\u4e49\u5d4c\u5165\u3001\u4e8c\u8fdb\u5236\u91cf\u5316\u548c\u968f\u673a\u54cd\u5e94\u673a\u5236\u751f\u6210\u4e0d\u53ef\u9006\u6307\u7eb9\uff0c\u5b9e\u73b0\u8de8\u5408\u89c4\u8fb9\u754c\u7684\u5b89\u5168\u653b\u51fb\u6307\u7eb9\u5171\u4eab\uff0c\u5728\u4fdd\u6301\u9690\u79c1\u7684\u540c\u65f6\u6709\u6548\u68c0\u6d4b\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u3002", "motivation": "\u4f01\u4e1a\u90e8\u7f72\u591a\u4e2aLLM\u670d\u52a1\u5904\u7406\u6570\u5341\u4ebf\u67e5\u8be2\uff0c\u4f46\u7531\u4e8e\u76d1\u7ba1\u5408\u89c4\u8fb9\u754c\u9650\u5236\uff0c\u65e0\u6cd5\u5171\u4eab\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u7684\u5a01\u80c1\u60c5\u62a5\uff0c\u5bfc\u81f4\u653b\u51fb\u5728\u4e00\u4e2a\u670d\u52a1\u4e2d\u88ab\u68c0\u6d4b\u540e\uff0c\u5728\u5176\u4ed6\u670d\u52a1\u4e2d\u53ef\u80fd\u6301\u7eed\u6570\u6708\u672a\u88ab\u53d1\u73b0\u3002", "method": "\u91c7\u7528\u72ec\u7279\u7684\u5904\u7406\u6d41\u7a0b\uff1aPII\u8131\u654f\u3001\u8bed\u4e49\u5d4c\u5165\u3001\u4e8c\u8fdb\u5236\u91cf\u5316\u548c\u968f\u673a\u54cd\u5e94\u673a\u5236\uff0c\u751f\u6210\u975e\u53ef\u9006\u7684\u6307\u7eb9\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u4fdd\u7559\u653b\u51fb\u6a21\u5f0f\u7279\u5f81\u3002", "result": "F1\u5206\u6570\u8fbe\u52300.94\uff0c\u663e\u8457\u4f18\u4e8e\u9690\u79c1\u4fdd\u62a4\u57fa\u7ebfSimHash\uff080.77\uff09\uff0c\u540c\u65f6\u5b9e\u73b064\u500d\u5b58\u50a8\u51cf\u5c11\u548c38\u500d\u66f4\u5feb\u7684\u76f8\u4f3c\u6027\u641c\u7d22\u3002", "conclusion": "BinaryShield\u6210\u529f\u89e3\u51b3\u4e86LLM\u670d\u52a1\u95f4\u5a01\u80c1\u60c5\u62a5\u5171\u4eab\u7684\u9690\u79c1\u5408\u89c4\u95ee\u9898\uff0c\u4e3a\u8de8\u5408\u89c4\u8fb9\u754c\u7684\u653b\u51fb\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u9690\u79c1\u4fdd\u62a4\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.06774", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.06774", "abs": "https://arxiv.org/abs/2509.06774", "authors": ["Hridoy Sankar Dutta", "Sana Ansari", "Swati Kumari", "Shounak Ravi Bhalerao"], "title": "OpenCoderRank: AI-Driven Technical Assessments Made Easy", "comment": null, "summary": "Organizations and educational institutions use time-bound assessment tasks to\nevaluate coding and problem-solving skills. These assessments measure not only\nthe correctness of the solutions, but also their efficiency. Problem setters\n(educator/interviewer) are responsible for crafting these challenges, carefully\nbalancing difficulty and relevance to create meaningful evaluation experiences.\nConversely, problem solvers (student/interviewee) apply coding efficiency and\nlogical thinking to arrive at correct solutions. In the era of Large Language\nModels (LLMs), LLMs assist problem setters in generating diverse and\nchallenging questions, but they can undermine assessment integrity for problem\nsolvers by providing easy access to solutions. This paper introduces\nOpenCoderRank, an easy-to-use platform designed to simulate technical\nassessments. It acts as a bridge between problem setters and problem solvers,\nhelping solvers prepare for time constraints and unfamiliar problems while\nallowing setters to self-host assessments, offering a no-cost and customizable\nsolution for technical assessments in resource-constrained environments.", "AI": {"tldr": "OpenCoderRank\u662f\u4e00\u4e2a\u6613\u4e8e\u4f7f\u7528\u7684\u6280\u672f\u8bc4\u4f30\u6a21\u62df\u5e73\u53f0\uff0c\u8fde\u63a5\u95ee\u9898\u8bbe\u7f6e\u8005\u548c\u89e3\u51b3\u8005\uff0c\u5e2e\u52a9\u89e3\u51b3\u8005\u5728\u65f6\u95f4\u9650\u5236\u548c\u964c\u751f\u95ee\u9898\u4e0b\u51c6\u5907\uff0c\u540c\u65f6\u5141\u8bb8\u8bbe\u7f6e\u8005\u81ea\u6258\u7ba1\u8bc4\u4f30", "motivation": "\u5728LLM\u65f6\u4ee3\uff0c\u867d\u7136LLM\u80fd\u5e2e\u52a9\u95ee\u9898\u8bbe\u7f6e\u8005\u751f\u6210\u591a\u6837\u5316\u6311\u6218\u6027\u95ee\u9898\uff0c\u4f46\u4e5f\u53ef\u80fd\u901a\u8fc7\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\u6765\u7834\u574f\u8bc4\u4f30\u7684\u5b8c\u6574\u6027\uff0c\u9700\u8981\u4e00\u79cd\u5e73\u8861\u7684\u8bc4\u4f30\u5e73\u53f0", "method": "\u5f00\u53d1OpenCoderRank\u5e73\u53f0\uff0c\u6a21\u62df\u6280\u672f\u8bc4\u4f30\u73af\u5883\uff0c\u652f\u6301\u81ea\u6258\u7ba1\u8bc4\u4f30\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u63d0\u4f9b\u65e0\u6210\u672c\u548c\u53ef\u5b9a\u5236\u7684\u89e3\u51b3\u65b9\u6848", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u8fde\u63a5\u95ee\u9898\u8bbe\u7f6e\u8005\u548c\u89e3\u51b3\u8005\u7684\u6865\u6881\u5e73\u53f0\uff0c\u80fd\u591f\u6709\u6548\u6a21\u62df\u771f\u5b9e\u6280\u672f\u8bc4\u4f30\u573a\u666f", "conclusion": "OpenCoderRank\u4e3a\u6280\u672f\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u5408\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\uff0c\u65e2\u4fdd\u62a4\u4e86\u8bc4\u4f30\u7684\u5b8c\u6574\u6027\uff0c\u53c8\u5e2e\u52a9\u53c2\u4e0e\u8005\u66f4\u597d\u5730\u51c6\u5907"}}
{"id": "2509.05933", "categories": ["cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2509.05933", "abs": "https://arxiv.org/abs/2509.05933", "authors": ["Md Hasebul Hasan", "Mahir Labib Dihan", "Mohammed Eunus Ali", "Md Rizwan Parvez"], "title": "MapAgent: A Hierarchical Agent for Geospatial Reasoning with Dynamic Map Tool Integration", "comment": "27 Pages", "summary": "Agentic AI has significantly extended the capabilities of large language\nmodels (LLMs) by enabling complex reasoning and tool use. However, most\nexisting frameworks are tailored to domains such as mathematics, coding, or web\nautomation, and fall short on geospatial tasks that require spatial reasoning,\nmulti-hop planning, and real-time map interaction. To address these challenges,\nwe introduce MapAgent, a hierarchical multi-agent plug-and-play framework with\ncustomized toolsets and agentic scaffolds for map-integrated geospatial\nreasoning. Unlike existing flat agent-based approaches that treat tools\nuniformly-often overwhelming the LLM when handling similar but subtly different\ngeospatial APIs-MapAgent decouples planning from execution. A high-level\nplanner decomposes complex queries into subgoals, which are routed to\nspecialized modules. For tool-heavy modules-such as map-based services-we then\ndesign a dedicated map-tool agent that efficiently orchestrates related APIs\nadaptively in parallel to effectively fetch geospatial data relevant for the\nquery, while simpler modules (e.g., solution generation or answer extraction)\noperate without additional agent overhead. This hierarchical design reduces\ncognitive load, improves tool selection accuracy, and enables precise\ncoordination across similar APIs. We evaluate MapAgent on four diverse\ngeospatial benchmarks-MapEval-Textual, MapEval-API, MapEval-Visual, and\nMapQA-and demonstrate substantial gains over state-of-the-art tool-augmented\nand agentic baselines. We open-source our framwork at\nhttps://github.com/Hasebul/MapAgent.", "AI": {"tldr": "MapAgent\u662f\u4e00\u4e2a\u5206\u5c42\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u4e13\u95e8\u7528\u4e8e\u5730\u7406\u7a7a\u95f4\u63a8\u7406\u4efb\u52a1\uff0c\u901a\u8fc7\u89e3\u8026\u89c4\u5212\u4e0e\u6267\u884c\u6765\u63d0\u9ad8\u5de5\u5177\u9009\u62e9\u51c6\u786e\u6027\u548cAPI\u534f\u8c03\u80fd\u529b", "motivation": "\u73b0\u6709AI\u4ee3\u7406\u6846\u67b6\u4e3b\u8981\u9488\u5bf9\u6570\u5b66\u3001\u7f16\u7a0b\u7b49\u9886\u57df\uff0c\u5728\u5730\u7406\u7a7a\u95f4\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u7a7a\u95f4\u63a8\u7406\u3001\u591a\u8df3\u89c4\u5212\u548c\u5b9e\u65f6\u5730\u56fe\u4ea4\u4e92\u80fd\u529b", "method": "\u91c7\u7528\u5206\u5c42\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff1a\u9ad8\u5c42\u89c4\u5212\u5668\u5206\u89e3\u590d\u6742\u67e5\u8be2\u4e3a\u5b50\u76ee\u6807\uff0c\u4e13\u7528\u5730\u56fe\u5de5\u5177\u4ee3\u7406\u5e76\u884c\u534f\u8c03\u76f8\u5173API\uff0c\u7b80\u5355\u6a21\u5757\u65e0\u9700\u989d\u5916\u4ee3\u7406\u5f00\u9500", "result": "\u5728\u56db\u4e2a\u5730\u7406\u7a7a\u95f4\u57fa\u51c6\u6d4b\u8bd5(MapEval-Textual\u3001MapEval-API\u3001MapEval-Visual\u3001MapQA)\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\u589e\u5f3a\u548c\u4ee3\u7406\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "MapAgent\u901a\u8fc7\u5206\u5c42\u8bbe\u8ba1\u548c\u4e13\u7528\u5de5\u5177\u96c6\u6709\u6548\u89e3\u51b3\u4e86\u5730\u7406\u7a7a\u95f4\u63a8\u7406\u7684\u6311\u6218\uff0c\u4e3a\u5730\u56fe\u96c6\u6210\u7684\u5730\u7406\u7a7a\u95f4AI\u5e94\u7528\u63d0\u4f9b\u4e86\u9ad8\u6548\u6846\u67b6"}}
{"id": "2509.05643", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.05643", "abs": "https://arxiv.org/abs/2509.05643", "authors": ["Carmine Cesarano", "Roberto Natella"], "title": "FuzzBox: Blending Fuzzing into Emulation for Binary-Only Embedded Targets", "comment": null, "summary": "Coverage-guided fuzzing has been widely applied to address zero-day\nvulnerabilities in general-purpose software and operating systems. This\napproach relies on instrumenting the target code at compile time. However,\napplying it to industrial systems remains challenging, due to proprietary and\nclosed-source compiler toolchains and lack of access to source code. FuzzBox\naddresses these limitations by integrating emulation with fuzzing: it\ndynamically instruments code during execution in a virtualized environment, for\nthe injection of fuzz inputs, failure detection, and coverage analysis, without\nrequiring source code recompilation and hardware-specific dependencies. We show\nthe effectiveness of FuzzBox through experiments in the context of a\nproprietary MILS (Multiple Independent Levels of Security) hypervisor for\nindustrial applications. Additionally, we analyze the applicability of FuzzBox\nacross commercial IoT firmware, showcasing its broad portability.", "AI": {"tldr": "FuzzBox\u662f\u4e00\u4e2a\u57fa\u4e8e\u4eff\u771f\u7684\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u63d2\u6869\u89e3\u51b3\u5de5\u4e1a\u7cfb\u7edf\u4e2d\u65e0\u6cd5\u83b7\u53d6\u6e90\u4ee3\u7801\u548c\u4e13\u7528\u7f16\u8bd1\u5668\u7684\u95ee\u9898\uff0c\u5728MILS hypervisor\u548cIoT\u56fa\u4ef6\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u8986\u76d6\u5f15\u5bfc\u7684\u6a21\u7cca\u6d4b\u8bd5\u9700\u8981\u7f16\u8bd1\u65f6\u63d2\u6869\uff0c\u4f46\u5de5\u4e1a\u7cfb\u7edf\u901a\u5e38\u4f7f\u7528\u4e13\u6709\u95ed\u6e90\u7f16\u8bd1\u5668\u4e14\u65e0\u6cd5\u83b7\u53d6\u6e90\u4ee3\u7801\uff0c\u5bfc\u81f4\u96be\u4ee5\u5e94\u7528\u6a21\u7cca\u6d4b\u8bd5\u6280\u672f\u3002", "method": "FuzzBox\u5c06\u4eff\u771f\u4e0e\u6a21\u7cca\u6d4b\u8bd5\u7ed3\u5408\uff0c\u5728\u865a\u62df\u5316\u73af\u5883\u4e2d\u52a8\u6001\u6267\u884c\u4ee3\u7801\u63d2\u6869\uff0c\u5b9e\u73b0\u6a21\u7cca\u8f93\u5165\u6ce8\u5165\u3001\u6545\u969c\u68c0\u6d4b\u548c\u8986\u76d6\u5206\u6790\uff0c\u65e0\u9700\u6e90\u4ee3\u7801\u91cd\u65b0\u7f16\u8bd1\u548c\u786c\u4ef6\u4f9d\u8d56\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eFuzzBox\u5728\u4e13\u6709MILS hypervisor\u4e2d\u6709\u6548\uff0c\u5e76\u5728\u5546\u4e1aIoT\u56fa\u4ef6\u4e2d\u5c55\u793a\u4e86\u5e7f\u6cdb\u7684\u79fb\u690d\u6027\u3002", "conclusion": "FuzzBox\u901a\u8fc7\u52a8\u6001\u63d2\u6869\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u5de5\u4e1a\u7cfb\u7edf\u4e2d\u5e94\u7528\u6a21\u7cca\u6d4b\u8bd5\u7684\u6280\u672f\u969c\u788d\uff0c\u5177\u6709\u5f88\u597d\u7684\u5b9e\u7528\u6027\u548c\u53ef\u79fb\u690d\u6027\u3002"}}
{"id": "2509.06911", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.06911", "abs": "https://arxiv.org/abs/2509.06911", "authors": ["Margarida Ferreira", "Victor Nicolet", "Luan Pham", "Joey Dodds", "Daniel Kroening", "Ines Lynce", "Ruben Martins"], "title": "Hypergraph-Guided Regex Filter Synthesis for Event-Based Anomaly Detection", "comment": null, "summary": "We propose HyGLAD, a novel algorithm that automatically builds a set of\ninterpretable patterns that model event data. These patterns can then be used\nto detect event-based anomalies in a stationary system, where any deviation\nfrom past behavior may indicate malicious activity. The algorithm infers\nequivalence classes of entities with similar behavior observed from the events,\nand then builds regular expressions that capture the values of those entities.\nAs opposed to deep-learning approaches, the regular expressions are directly\ninterpretable, which also translates to interpretable anomalies. We evaluate\nHyGLAD against all 7 unsupervised anomaly detection methods from DeepOD on five\ndatasets from real-world systems. The experimental results show that on average\nHyGLAD outperforms existing deep-learning methods while being an order of\nmagnitude more efficient in training and inference (single CPU vs GPU).\nPrecision improved by 1.2x and recall by 1.3x compared to the second-best\nbaseline.", "AI": {"tldr": "HyGLAD\u662f\u4e00\u79cd\u65b0\u9896\u7684\u7b97\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u53ef\u89e3\u91ca\u7684\u6a21\u5f0f\u6765\u68c0\u6d4b\u4e8b\u4ef6\u6570\u636e\u4e2d\u7684\u5f02\u5e38\uff0c\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u90fd\u4f18\u4e8e\u73b0\u6709\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5", "motivation": "\u5728\u9759\u6001\u7cfb\u7edf\u4e2d\u68c0\u6d4b\u4e8b\u4ef6\u578b\u5f02\u5e38\uff0c\u9700\u8981\u80fd\u591f\u8bc6\u522b\u4e0e\u8fc7\u53bb\u884c\u4e3a\u504f\u5dee\u7684\u53ef\u89e3\u91ca\u65b9\u6cd5\uff0c\u800c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7684\u9ed1\u76d2\u7279\u6027\u9650\u5236\u4e86\u5176\u53ef\u89e3\u91ca\u6027", "method": "\u7b97\u6cd5\u63a8\u65ad\u5177\u6709\u76f8\u4f3c\u884c\u4e3a\u7684\u5b9e\u4f53\u7b49\u4ef7\u7c7b\uff0c\u7136\u540e\u6784\u5efa\u6355\u83b7\u8fd9\u4e9b\u5b9e\u4f53\u503c\u7684\u6b63\u5219\u8868\u8fbe\u5f0f\u6a21\u5f0f\uff0c\u8fd9\u4e9b\u6a21\u5f0f\u76f4\u63a5\u53ef\u89e3\u91ca", "result": "\u57285\u4e2a\u771f\u5b9e\u7cfb\u7edf\u6570\u636e\u96c6\u4e0a\uff0cHyGLAD\u5e73\u5747\u6027\u80fd\u4f18\u4e8e\u6240\u67097\u79cdDeepOD\u7684\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u8bad\u7ec3\u548c\u63a8\u7406\u6548\u7387\u63d0\u9ad8\u4e00\u4e2a\u6570\u91cf\u7ea7\uff08\u5355CPU vs GPU\uff09\uff0c\u7cbe\u786e\u5ea6\u63d0\u9ad81.2\u500d\uff0c\u53ec\u56de\u7387\u63d0\u9ad81.3\u500d", "conclusion": "HyGLAD\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e2\u9ad8\u6548\u53c8\u53ef\u89e3\u91ca\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5728\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u90fd\u4f18\u4e8e\u6df1\u5ea6\u5b66\u4e60\u57fa\u7ebf\u65b9\u6cd5"}}
{"id": "2509.06024", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06024", "abs": "https://arxiv.org/abs/2509.06024", "authors": ["Haoyang He", "Zihua Rong", "Kun Ji", "Chenyang Li", "Qing Huang", "Chong Xia", "Lan Yang", "Honggang Zhang"], "title": "Rethinking Reasoning Quality in Large Language Models through Enhanced Chain-of-Thought via RL", "comment": null, "summary": "Reinforcement learning (RL) has recently become the dominant paradigm for\nstrengthening the reasoning abilities of large language models (LLMs). Yet the\nrule-based reward functions commonly used on mathematical or programming\nbenchmarks assess only answer format and correctness, providing no signal as to\nwhether the induced Chain-of-Thought (CoT) actually improves the answer.\nFurthermore, such task-specific training offers limited control over logical\ndepth and therefore may fail to reveal a model's genuine reasoning capacity. We\npropose Dynamic Reasoning Efficiency Reward (DRER) -- a plug-and-play RL reward\nframework that reshapes both reward and advantage signals. (i) A Reasoning\nQuality Reward assigns fine-grained credit to those reasoning chains that\ndemonstrably raise the likelihood of the correct answer, directly incentivising\nthe trajectories with beneficial CoT tokens. (ii) A Dynamic Length Advantage\ndecays the advantage of responses whose length deviates from a\nvalidation-derived threshold, stabilising training. To facilitate rigorous\nassessment, we also release Logictree, a dynamically constructed deductive\nreasoning dataset that functions both as RL training data and as a\ncomprehensive benchmark. Experiments confirm the effectiveness of DRER: our 7B\nmodel attains GPT-o3-mini level performance on Logictree with 400 trianing\nsteps, while the average confidence of CoT-augmented answers rises by 30%. The\nmodel further exhibits generalisation across diverse logical-reasoning\ndatasets, and the mathematical benchmark AIME24. These results illuminate how\nRL shapes CoT behaviour and chart a practical path toward enhancing\nformal-reasoning skills in large language models. All code and data are\navailable in repository https://github.com/Henryhe09/DRER.", "AI": {"tldr": "\u63d0\u51fa\u4e86DRER\u5f3a\u5316\u5b66\u4e60\u5956\u52b1\u6846\u67b6\uff0c\u901a\u8fc7\u63a8\u7406\u8d28\u91cf\u5956\u52b1\u548c\u52a8\u6001\u957f\u5ea6\u4f18\u52bf\u6765\u4f18\u5316\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5728Logictree\u6570\u636e\u96c6\u4e0a7B\u6a21\u578b\u8fbe\u5230GPT-o3-mini\u6c34\u5e73\uff0c\u63a8\u7406\u7f6e\u4fe1\u5ea6\u63d0\u534730%", "motivation": "\u73b0\u6709\u57fa\u4e8e\u89c4\u5219\u7684\u5956\u52b1\u51fd\u6570\u53ea\u8bc4\u4f30\u7b54\u6848\u683c\u5f0f\u548c\u6b63\u786e\u6027\uff0c\u65e0\u6cd5\u5224\u65ad\u63a8\u7406\u94fe\u662f\u5426\u771f\u6b63\u6539\u5584\u7b54\u6848\uff0c\u4e14\u4efb\u52a1\u7279\u5b9a\u8bad\u7ec3\u5bf9\u903b\u8f91\u6df1\u5ea6\u7684\u63a7\u5236\u6709\u9650\uff0c\u96be\u4ee5\u63ed\u793a\u6a21\u578b\u7684\u771f\u5b9e\u63a8\u7406\u80fd\u529b", "method": "DRER\u6846\u67b6\u5305\u542b\uff1a(1)\u63a8\u7406\u8d28\u91cf\u5956\u52b1 - \u4e3a\u90a3\u4e9b\u786e\u5b9e\u63d0\u9ad8\u6b63\u786e\u7b54\u6848\u53ef\u80fd\u6027\u7684\u63a8\u7406\u94fe\u5206\u914d\u7ec6\u7c92\u5ea6\u4fe1\u7528\uff1b(2)\u52a8\u6001\u957f\u5ea6\u4f18\u52bf - \u5bf9\u504f\u79bb\u9a8c\u8bc1\u9608\u503c\u7684\u54cd\u5e94\u957f\u5ea6\u8fdb\u884c\u4f18\u52bf\u8870\u51cf\uff0c\u7a33\u5b9a\u8bad\u7ec3\u3002\u4f7f\u7528Logictree\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30", "result": "7B\u6a21\u578b\u5728400\u8bad\u7ec3\u6b65\u6570\u540e\u8fbe\u5230GPT-o3-mini\u6c34\u5e73\uff0cCoT\u589e\u5f3a\u7b54\u6848\u7684\u5e73\u5747\u7f6e\u4fe1\u5ea6\u63d0\u534730%\uff0c\u5728\u591a\u79cd\u903b\u8f91\u63a8\u7406\u6570\u636e\u96c6\u548cAIME24\u6570\u5b66\u57fa\u51c6\u4e0a\u5c55\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b", "conclusion": "DRER\u6709\u6548\u5851\u9020\u4e86CoT\u884c\u4e3a\uff0c\u4e3a\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5f62\u5f0f\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\uff0c\u6240\u6709\u4ee3\u7801\u548c\u6570\u636e\u5df2\u5f00\u6e90"}}
{"id": "2509.05681", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05681", "abs": "https://arxiv.org/abs/2509.05681", "authors": ["Xng Ai", "Shudan Lin", "Zecheng Li", "Kai Zhou", "Bixin Li", "Bin Xiao"], "title": "SEASONED: Semantic-Enhanced Self-Counterfactual Explainable Detection of Adversarial Exploiter Contracts", "comment": null, "summary": "Decentralized Finance (DeFi) attacks have resulted in significant losses,\noften orchestrated through Adversarial Exploiter Contracts (AECs) that exploit\nvulnerabilities in victim smart contracts. To proactively identify such\nthreats, this paper targets the explainable detection of AECs.\n  Existing detection methods struggle to capture semantic dependencies and lack\ninterpretability, limiting their effectiveness and leaving critical knowledge\ngaps in AEC analysis. To address these challenges, we introduce SEASONED, an\neffective, self-explanatory, and robust framework for AEC detection.\n  SEASONED extracts semantic information from contract bytecode to construct a\nsemantic relation graph (SRG), and employs a self-counterfactual explainable\ndetector (SCFED) to classify SRGs and generate explanations that highlight the\ncore attack logic. SCFED further enhances robustness, generalizability, and\ndata efficiency by extracting representative information from these\nexplanations. Both theoretical analysis and experimental results demonstrate\nthe effectiveness of SEASONED, which showcases outstanding detection\nperformance, robustness, generalizability, and data efficiency learning\nability. To support further research, we also release a new dataset of 359\nAECs.", "AI": {"tldr": "SEASONED\u662f\u4e00\u4e2a\u7528\u4e8e\u68c0\u6d4bDeFi\u653b\u51fb\u4e2d\u5bf9\u6297\u6027\u5229\u7528\u5408\u7ea6(AECs)\u7684\u81ea\u89e3\u91ca\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u5173\u7cfb\u56fe\u548c\u81ea\u53cd\u4e8b\u5b9e\u53ef\u89e3\u91ca\u68c0\u6d4b\u5668\u5b9e\u73b0\u9ad8\u6548\u68c0\u6d4b\u548c\u653b\u51fb\u903b\u8f91\u89e3\u91ca", "motivation": "\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u8bed\u4e49\u4f9d\u8d56\u5173\u7cfb\u4e14\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u5bfc\u81f4AEC\u5206\u6790\u5b58\u5728\u5173\u952e\u77e5\u8bc6\u7a7a\u767d\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u4e3b\u52a8\u8bc6\u522b\u5a01\u80c1\u5e76\u63d0\u4f9b\u89e3\u91ca\u7684\u68c0\u6d4b\u65b9\u6848", "method": "\u4ece\u5408\u7ea6\u5b57\u8282\u7801\u63d0\u53d6\u8bed\u4e49\u4fe1\u606f\u6784\u5efa\u8bed\u4e49\u5173\u7cfb\u56fe(SRG)\uff0c\u4f7f\u7528\u81ea\u53cd\u4e8b\u5b9e\u53ef\u89e3\u91ca\u68c0\u6d4b\u5668(SCFED)\u5bf9SRG\u8fdb\u884c\u5206\u7c7b\u5e76\u751f\u6210\u7a81\u51fa\u6838\u5fc3\u653b\u51fb\u903b\u8f91\u7684\u89e3\u91ca", "result": "\u7406\u8bba\u548c\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660eSEASONED\u5177\u6709\u51fa\u8272\u7684\u68c0\u6d4b\u6027\u80fd\u3001\u9c81\u68d2\u6027\u3001\u6cdb\u5316\u80fd\u529b\u548c\u6570\u636e\u6548\u7387\u5b66\u4e60\u80fd\u529b\uff0c\u5e76\u53d1\u5e03\u4e86\u5305\u542b359\u4e2aAEC\u7684\u65b0\u6570\u636e\u96c6", "conclusion": "SEASONED\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86AEC\u68c0\u6d4b\u4e2d\u7684\u8bed\u4e49\u4f9d\u8d56\u6355\u6349\u548c\u53ef\u89e3\u91ca\u6027\u95ee\u9898\uff0c\u4e3aDeFi\u5b89\u5168\u63d0\u4f9b\u4e86\u5f3a\u6709\u529b\u7684\u68c0\u6d4b\u5de5\u5177\u548c\u6570\u636e\u96c6\u652f\u6301"}}
{"id": "2509.06160", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.06160", "abs": "https://arxiv.org/abs/2509.06160", "authors": ["Haozhe Wang", "Haoran Que", "Qixin Xu", "Minghao Liu", "Wangchunshu Zhou", "Jiazhan Feng", "Wanjun Zhong", "Wei Ye", "Tong Yang", "Wenhao Huang", "Ge Zhang", "Fangzhen Lin"], "title": "Reverse-Engineered Reasoning for Open-Ended Generation", "comment": "Preprint", "summary": "While the ``deep reasoning'' paradigm has spurred significant advances in\nverifiable domains like mathematics, its application to open-ended, creative\ngeneration remains a critical challenge. The two dominant methods for\ninstilling reasoning -- reinforcement learning (RL) and instruction\ndistillation -- falter in this area; RL struggles with the absence of clear\nreward signals and high-quality reward models, while distillation is\nprohibitively expensive and capped by the teacher model's capabilities. To\novercome these limitations, we introduce REverse-Engineered Reasoning (REER), a\nnew paradigm that fundamentally shifts the approach. Instead of building a\nreasoning process ``forwards'' through trial-and-error or imitation, REER works\n``backwards'' from known-good solutions to computationally discover the latent,\nstep-by-step deep reasoning process that could have produced them. Using this\nscalable, gradient-free approach, we curate and open-source DeepWriting-20K, a\nlarge-scale dataset of 20,000 deep reasoning trajectories for open-ended tasks.\nOur model, DeepWriter-8B, trained on this data, not only surpasses strong\nopen-source baselines but also achieves performance competitive with, and at\ntimes superior to, leading proprietary models like GPT-4o and Claude 3.5.", "AI": {"tldr": "REER\u662f\u4e00\u79cd\u9006\u5411\u5de5\u7a0b\u63a8\u7406\u65b0\u8303\u5f0f\uff0c\u4ece\u5df2\u77e5\u4f18\u79c0\u89e3\u51b3\u65b9\u6848\u53cd\u5411\u63a8\u5bfc\u63a8\u7406\u8fc7\u7a0b\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfRL\u548c\u84b8\u998f\u65b9\u6cd5\u5728\u5f00\u653e\u5f0f\u521b\u4f5c\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027", "motivation": "\u4f20\u7edf\u6df1\u5ea6\u63a8\u7406\u65b9\u6cd5\uff08\u5f3a\u5316\u5b66\u4e60\u548c\u6307\u4ee4\u84b8\u998f\uff09\u5728\u5f00\u653e\u5f0f\u521b\u4f5c\u4efb\u52a1\u4e2d\u5b58\u5728\u660e\u663e\u7f3a\u9677\uff1aRL\u7f3a\u4e4f\u660e\u786e\u5956\u52b1\u4fe1\u53f7\uff0c\u84b8\u998f\u65b9\u6cd5\u6210\u672c\u9ad8\u6602\u4e14\u53d7\u9650\u4e8e\u6559\u5e08\u6a21\u578b\u80fd\u529b", "method": "\u63d0\u51faREER\u9006\u5411\u5de5\u7a0b\u63a8\u7406\u8303\u5f0f\uff0c\u4ece\u5df2\u77e5\u4f18\u79c0\u89e3\u51b3\u65b9\u6848\u53cd\u5411\u8ba1\u7b97\u63a8\u5bfc\u51fa\u6f5c\u5728\u7684\u9010\u6b65\u6df1\u5ea6\u63a8\u7406\u8fc7\u7a0b\uff0c\u91c7\u7528\u53ef\u6269\u5c55\u7684\u65e0\u68af\u5ea6\u65b9\u6cd5\uff0c\u6784\u5efa\u4e86\u5305\u542b2\u4e07\u6761\u6df1\u5ea6\u63a8\u7406\u8f68\u8ff9\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6DeepWriting-20K", "result": "\u57fa\u4e8e\u8be5\u6570\u636e\u8bad\u7ec3\u7684DeepWriter-8B\u6a21\u578b\u4e0d\u4ec5\u8d85\u8d8a\u5f00\u6e90\u57fa\u7ebf\u6a21\u578b\uff0c\u800c\u4e14\u5728\u6027\u80fd\u4e0a\u4e0eGPT-4o\u548cClaude 3.5\u7b49\u9886\u5148\u4e13\u6709\u6a21\u578b\u7ade\u4e89\u751a\u81f3\u5728\u67d0\u4e9b\u65b9\u9762\u66f4\u4f18", "conclusion": "REER\u8303\u5f0f\u4e3a\u5f00\u653e\u5f0f\u521b\u4f5c\u4efb\u52a1\u7684\u6df1\u5ea6\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u9014\u5f84\uff0c\u901a\u8fc7\u9006\u5411\u5de5\u7a0b\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027"}}
{"id": "2509.05698", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.05698", "abs": "https://arxiv.org/abs/2509.05698", "authors": ["Yuhan Meng", "Shaofei Li", "Jiaping Gui", "Peng Jiang", "Ding Li"], "title": "KnowHow: Automatically Applying High-Level CTI Knowledge for Interpretable and Accurate Provenance Analysis", "comment": "Accepted by NDSS 2026", "summary": "High-level natural language knowledge in CTI reports, such as the ATT&CK\nframework, is beneficial to counter APT attacks. However, how to automatically\napply the high-level knowledge in CTI reports in realistic attack detection\nsystems, such as provenance analysis systems, is still an open problem. The\nchallenge stems from the semantic gap between the knowledge and the low-level\nsecurity logs: while the knowledge in CTI reports is written in natural\nlanguage, attack detection systems can only process low-level system events\nlike file accesses or network IP manipulations. Manual approaches can be\nlabor-intensive and error-prone.\n  In this paper, we propose KnowHow, a CTI-knowledge-driven online provenance\nanalysis approach that can automatically apply high-level attack knowledge from\nCTI reports written in natural languages to detect low-level system events. The\ncore of KnowHow is a novel attack knowledge representation, gIoC, that\nrepresents the subject, object, and actions of attacks. By lifting system\nidentifiers, such as file paths, in system events to natural language terms,\nKnowHow can match system events to gIoC and further match them to techniques\ndescribed in natural languages. Finally, based on the techniques matched to\nsystem events, KnowHow reasons about the temporal logic of attack steps and\ndetects potential APT attacks in system events. Our evaluation shows that\nKnowHow can accurately detect all 16 APT campaigns in the open-source and\nindustrial datasets, while existing approaches all introduce large numbers of\nfalse positives. Meanwhile, our evaluation also shows that KnowHow reduces at\nmost 90% of node-level false positives while having a higher node-level recall\nand is robust against several unknown attacks and mimicry attacks.", "AI": {"tldr": "KnowHow\u662f\u4e00\u4e2aCTI\u77e5\u8bc6\u9a71\u52a8\u7684\u5728\u7ebf\u6eaf\u6e90\u5206\u6790\u65b9\u6cd5\uff0c\u80fd\u591f\u81ea\u52a8\u5c06\u81ea\u7136\u8bed\u8a00CTI\u62a5\u544a\u4e2d\u7684\u9ad8\u7ea7\u653b\u51fb\u77e5\u8bc6\u5e94\u7528\u4e8e\u4f4e\u7ea7\u7cfb\u7edf\u4e8b\u4ef6\u68c0\u6d4b\uff0c\u901a\u8fc7gIoC\u8868\u793a\u548c\u8bed\u4e49\u5339\u914d\u6765\u68c0\u6d4bAPT\u653b\u51fb", "motivation": "\u89e3\u51b3CTI\u62a5\u544a\u4e2d\u9ad8\u7ea7\u81ea\u7136\u8bed\u8a00\u77e5\u8bc6\u4e0e\u4f4e\u7ea7\u5b89\u5168\u65e5\u5fd7\u4e4b\u95f4\u7684\u8bed\u4e49\u9e3f\u6c9f\u95ee\u9898\uff0c\u907f\u514d\u4eba\u5de5\u65b9\u6cd5\u7684\u52b3\u52a8\u5bc6\u96c6\u548c\u6613\u51fa\u9519", "method": "\u63d0\u51fagIoC\u653b\u51fb\u77e5\u8bc6\u8868\u793a\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u7cfb\u7edf\u6807\u8bc6\u7b26\u63d0\u5347\u4e3a\u81ea\u7136\u8bed\u8a00\u672f\u8bed\u6765\u5339\u914d\u7cfb\u7edf\u4e8b\u4ef6\u548c\u653b\u51fb\u6280\u672f\uff0c\u5e76\u57fa\u4e8e\u65f6\u95f4\u903b\u8f91\u63a8\u7406\u653b\u51fb\u6b65\u9aa4", "result": "\u5728\u5f00\u6e90\u548c\u5de5\u4e1a\u6570\u636e\u96c6\u4e2d\u51c6\u786e\u68c0\u6d4b\u6240\u670916\u4e2aAPT\u6d3b\u52a8\uff0c\u6700\u591a\u51cf\u5c1190%\u7684\u8282\u70b9\u7ea7\u8bef\u62a5\uff0c\u540c\u65f6\u4fdd\u6301\u66f4\u9ad8\u7684\u8282\u70b9\u7ea7\u53ec\u56de\u7387", "conclusion": "KnowHow\u80fd\u591f\u6709\u6548\u5f25\u5408\u8bed\u4e49\u9e3f\u6c9f\uff0c\u81ea\u52a8\u5e94\u7528CTI\u77e5\u8bc6\u8fdb\u884cAPT\u653b\u51fb\u68c0\u6d4b\uff0c\u5728\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5"}}
{"id": "2509.06133", "categories": ["cs.CR", "cs.DC", "cs.SE", "cs.SY", "eess.SY", "C.2.4; K.6.5; D.4.6"], "pdf": "https://arxiv.org/pdf/2509.06133", "abs": "https://arxiv.org/abs/2509.06133", "authors": ["Pradyumna Kaushal"], "title": "VehiclePassport: A GAIA-X-Aligned, Blockchain-Anchored Privacy-Preserving, Zero-Knowledge Digital Passport for Smart Vehicles", "comment": "13 pages, 5 figures. Whitepaper submission; LaTeX source with\n  compiled .bbl. Includes architecture diagrams, tables, and code listings\n  (TypeScript & Solidity)", "summary": "Modern vehicles accumulate fragmented lifecycle records across OEMs, owners,\nand service centers that are difficult to verify and prone to fraud. We propose\nVehiclePassport, a GAIA-X-aligned digital passport anchored on blockchain with\nzero-knowledge proofs (ZKPs) for privacy-preserving verification.\nVehiclePassport immutably commits to manufacturing, telemetry, and service\nevents while enabling selective disclosure via short-lived JWTs and Groth16\nproofs. Our open-source reference stack anchors hashes on Polygon zkEVM at\n<$0.02 per event, validates proofs in <10 ms, and scales to millions of\nvehicles. This architecture eliminates paper-based KYC, ensures GDPR-compliant\ntraceability, and establishes a trustless foundation for insurance, resale, and\nregulatory applications in global mobility data markets.", "AI": {"tldr": "VehiclePassport\u662f\u4e00\u4e2a\u57fa\u4e8e\u533a\u5757\u94fe\u548c\u96f6\u77e5\u8bc6\u8bc1\u660e\u7684\u8f66\u8f86\u6570\u5b57\u62a4\u7167\u7cfb\u7edf\uff0c\u7528\u4e8e\u5b89\u5168\u3001\u9690\u79c1\u4fdd\u62a4\u7684\u8f66\u8f86\u751f\u547d\u5468\u671f\u8bb0\u5f55\u9a8c\u8bc1", "motivation": "\u73b0\u4ee3\u8f66\u8f86\u7684\u5bff\u547d\u5468\u671f\u8bb0\u5f55\u5206\u6563\u5728OEM\u3001\u8f66\u4e3b\u548c\u670d\u52a1\u4e2d\u5fc3\u4e4b\u95f4\uff0c\u96be\u4ee5\u9a8c\u8bc1\u4e14\u5bb9\u6613\u53d1\u751f\u6b3a\u8bc8\uff0c\u9700\u8981\u4e00\u79cd\u53ef\u4fe1\u7684\u9a8c\u8bc1\u673a\u5236", "method": "\u91c7\u7528GAIA-X\u5bf9\u9f50\u7684\u6570\u5b57\u62a4\u7167\u67b6\u6784\uff0c\u57fa\u4e8e\u533a\u5757\u94fe\u951a\u5b9a\uff0c\u4f7f\u7528\u96f6\u77e5\u8bc6\u8bc1\u660e\uff08ZKPs\uff09\u8fdb\u884c\u9690\u79c1\u4fdd\u62a4\u9a8c\u8bc1\uff0c\u652f\u6301\u9009\u62e9\u6027\u62ab\u9732\u548c\u77ed\u65f6JWTs", "result": "\u5f00\u6e90\u53c2\u8003\u6808\u5728Polygon zkEVM\u4e0a\u4ee5<$0.02\u6bcf\u4e8b\u4ef6\u6210\u672c\u951a\u5b9a\u54c8\u5e0c\uff0c\u9a8c\u8bc1\u8bc1\u660e\u65f6\u95f4<10ms\uff0c\u53ef\u6269\u5c55\u5230\u6570\u767e\u4e07\u8f66\u8f86", "conclusion": "\u8be5\u67b6\u6784\u6d88\u9664\u4e86\u57fa\u4e8e\u7eb8\u5f20\u7684KYC\uff0c\u786e\u4fddGDPR\u5408\u89c4\u7684\u53ef\u8ffd\u6eaf\u6027\uff0c\u4e3a\u4fdd\u9669\u3001\u8f6c\u552e\u548c\u76d1\u7ba1\u5e94\u7528\u5efa\u7acb\u4e86\u65e0\u4fe1\u4efb\u57fa\u7840"}}
{"id": "2509.06174", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.06174", "abs": "https://arxiv.org/abs/2509.06174", "authors": ["Wei Han", "Geng Zhan", "Sicheng Yu", "Chenyu Wang", "Bryan Hooi"], "title": "From Long to Short: LLMs Excel at Trimming Own Reasoning Chains", "comment": "21 pages, 5 figures, 7 tables", "summary": "O1/R1 style large reasoning models (LRMs) signal a substantial leap forward\nover conventional instruction-following LLMs. By applying test-time scaling to\ngenerate extended reasoning paths, they establish many SOTAs across a wide\nrange of complex reasoning tasks. However, recent studies show that LRMs are\nprone to suffer from overthinking -- the tendency to overcomplicate simple\nproblems, leading to excessive strategy switching and long, convoluted\nreasoning traces that hinder their interpretability. To mitigate this issue, we\nconduct a systematic investigation into the reasoning efficiency of a broad set\nof LRMs and uncover a common dilemma: the difficulty in balancing multiple\ngeneration objectives such as correctness and brevity. Based on this discovery,\nwe propose a test-time scaling method, EDIT (Efficient Dynamic Inference\nTrimming), which efficiently guides LRMs to identify the shortest correct\nreasoning paths at test time. EDIT employs constraint-guided generation while\njointly tracking length and answer distributions under varying constraints,\nallowing it to select responses that strike an optimal balance between\nconciseness and correctness. Extensive experiments across diverse models and\ndatasets show that EDIT substantially enhance the reasoning efficiency,\nproducing compact yet informative outputs that improve readability and user\nexperience.", "AI": {"tldr": "EDIT\u662f\u4e00\u79cd\u6d4b\u8bd5\u65f6\u7f29\u653e\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ea6\u675f\u5f15\u5bfc\u751f\u6210\u548c\u8054\u5408\u8ddf\u8e2a\u957f\u5ea6\u4e0e\u7b54\u6848\u5206\u5e03\uff0c\u5e2e\u52a9\u5927\u578b\u63a8\u7406\u6a21\u578b\u627e\u5230\u6700\u77ed\u7684\u6b63\u786e\u63a8\u7406\u8def\u5f84\uff0c\u5e73\u8861\u7b80\u6d01\u6027\u548c\u6b63\u786e\u6027\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b(LRMs)\u5728\u5904\u7406\u7b80\u5355\u95ee\u9898\u65f6\u5bb9\u6613\u8fc7\u5ea6\u601d\u8003\uff0c\u4ea7\u751f\u5197\u957f\u590d\u6742\u7684\u63a8\u7406\u8f68\u8ff9\uff0c\u5f71\u54cd\u53ef\u89e3\u91ca\u6027\u548c\u6548\u7387\u3002\u7814\u7a76\u53d1\u73b0LRMs\u96be\u4ee5\u5e73\u8861\u6b63\u786e\u6027\u548c\u7b80\u6d01\u6027\u7b49\u591a\u4e2a\u751f\u6210\u76ee\u6807\u3002", "method": "\u63d0\u51faEDIT(Efficient Dynamic Inference Trimming)\u65b9\u6cd5\uff0c\u5728\u6d4b\u8bd5\u65f6\u4f7f\u7528\u7ea6\u675f\u5f15\u5bfc\u751f\u6210\uff0c\u540c\u65f6\u5728\u4e0d\u540c\u7ea6\u675f\u4e0b\u8054\u5408\u8ddf\u8e2a\u957f\u5ea6\u548c\u7b54\u6848\u5206\u5e03\uff0c\u9009\u62e9\u5728\u7b80\u6d01\u6027\u548c\u6b63\u786e\u6027\u4e4b\u95f4\u8fbe\u5230\u6700\u4f18\u5e73\u8861\u7684\u54cd\u5e94\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cEDIT\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u7406\u6548\u7387\uff0c\u4ea7\u751f\u7d27\u51d1\u800c\u4fe1\u606f\u4e30\u5bcc\u7684\u8f93\u51fa\uff0c\u6539\u5584\u4e86\u53ef\u8bfb\u6027\u548c\u7528\u6237\u4f53\u9a8c\u3002", "conclusion": "EDIT\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86LRMs\u7684\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u901a\u8fc7\u52a8\u6001\u63a8\u7406\u4fee\u526a\u5b9e\u73b0\u4e86\u63a8\u7406\u6548\u7387\u7684\u663e\u8457\u63d0\u5347\uff0c\u4e3a\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u5b9e\u7528\u5316\u63d0\u4f9b\u4e86\u91cd\u8981\u6539\u8fdb\u3002"}}
{"id": "2509.05708", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.05708", "abs": "https://arxiv.org/abs/2509.05708", "authors": ["Junjie Hu", "Na Ruan"], "title": "Larger-scale Nakamoto-style Blockchains Offer Better Security", "comment": "22 pages, 2 figures", "summary": "Traditional security models for Nakamoto-style blockchains overestimate\nadversarial coordination by assuming instantaneous synchronization among\nmalicious nodes, neglecting the critical impact of internal communication\ndelays on security. This paper introduces a dual-delay framework to revisit\nsecurity analysis, addressing this oversight through two key innovations.\nFirst, the static delay model quantifies how adversarial communication delays\n(\\(\\Delta_a\\)) constrain the effective growth rate of private chains, derived\nvia an M/D/1 queuing model as \\(\\lambda_{eff} = \\lambda_a / (1 + \\lambda_a\n\\Delta_a)\\). This model reveals that the security threshold (\\(\\beta^*\\)), the\nmaximum adversarial power the system tolerates, increases with \\(\\Delta_a\\),\neven exceeding the classic 51\\% boundary when \\(\\Delta_a \\textgreater \\Delta\\)\n(honest nodes' delay), breaking the long-standing 50\\% assumption. Second, the\ndynamic delay model integrates probabilistic corruption and scale-dependent\ndelays to characterize the total adversarial delay window (\\(\\Delta_{total} =\n\\Delta(n) e^{-k\\beta} + c \\log(1 + \\beta n)\\)), where \\(\\Delta(n) \\in\n\\Theta(\\log n)\\) captures honest nodes' logarithmic delay growth. Asymptotic\nanalysis shows adversarial power decays linearly with network scale, ensuring\nthe probability of \\(\\beta \\leq \\beta^*\\) approaches 1 as \\(n \\to \\infty\\). By\nexposing the interplay between network scale, communication delays, and power\ndilution, we provide a theoretical foundation for optimizing consensus\nprotocols and assessing robustness in large-scale Nakamoto-style blockchains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u53cc\u5ef6\u8fdf\u6846\u67b6\u6765\u91cd\u65b0\u5206\u6790Nakamoto\u533a\u5757\u94fe\u5b89\u5168\u6027\uff0c\u53d1\u73b0\u4f20\u7edf\u6a21\u578b\u9ad8\u4f30\u4e86\u6076\u610f\u8282\u70b9\u534f\u8c03\u80fd\u529b\uff0c\u5b9e\u9645\u5b89\u5168\u9608\u503c\u53ef\u8d85\u8fc751%\uff0c\u4e14\u968f\u7740\u7f51\u7edc\u89c4\u6a21\u6269\u5927\uff0c\u6076\u610f\u653b\u51fb\u6982\u7387\u8d8b\u8fd1\u4e8e\u96f6\u3002", "motivation": "\u4f20\u7edf\u533a\u5757\u94fe\u5b89\u5168\u6a21\u578b\u5047\u8bbe\u6076\u610f\u8282\u70b9\u80fd\u591f\u5373\u65f6\u540c\u6b65\uff0c\u5ffd\u7565\u4e86\u5185\u90e8\u901a\u4fe1\u5ef6\u8fdf\u5bf9\u5b89\u5168\u6027\u7684\u5173\u952e\u5f71\u54cd\uff0c\u8fd9\u5bfc\u81f4\u5bf9\u654c\u624b\u534f\u8c03\u80fd\u529b\u7684\u9ad8\u4f30\u3002", "method": "\u91c7\u7528\u53cc\u5ef6\u8fdf\u6846\u67b6\uff1a\u9759\u6001\u5ef6\u8fdf\u6a21\u578b\u901a\u8fc7M/D/1\u6392\u961f\u6a21\u578b\u91cf\u5316\u654c\u624b\u901a\u4fe1\u5ef6\u8fdf\u5bf9\u79c1\u6709\u94fe\u589e\u957f\u7387\u7684\u7ea6\u675f\uff1b\u52a8\u6001\u5ef6\u8fdf\u6a21\u578b\u6574\u5408\u6982\u7387\u8150\u8d25\u548c\u89c4\u6a21\u76f8\u5173\u5ef6\u8fdf\u6765\u8868\u5f81\u603b\u654c\u624b\u5ef6\u8fdf\u7a97\u53e3\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5b89\u5168\u9608\u503c\u03b2*\u968f\u654c\u624b\u5ef6\u8fdf\u0394a\u589e\u52a0\u800c\u63d0\u9ad8\uff0c\u5f53\u0394a>\u0394\u65f6\u53ef\u7a81\u7834\u7ecf\u5178\u768451%\u8fb9\u754c\uff1b\u6e10\u8fd1\u5206\u6790\u663e\u793a\u654c\u624b\u80fd\u529b\u968f\u7f51\u7edc\u89c4\u6a21\u7ebf\u6027\u8870\u51cf\uff0c\u5f53n\u2192\u221e\u65f6\u03b2\u2264\u03b2*\u7684\u6982\u7387\u8d8b\u8fd1\u4e8e1\u3002", "conclusion": "\u901a\u8fc7\u63ed\u793a\u7f51\u7edc\u89c4\u6a21\u3001\u901a\u4fe1\u5ef6\u8fdf\u548c\u80fd\u529b\u7a00\u91ca\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u4e3a\u4f18\u5316\u5171\u8bc6\u534f\u8bae\u548c\u8bc4\u4f30\u5927\u89c4\u6a21Nakamoto\u533a\u5757\u94fe\u7684\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2509.06235", "categories": ["cs.AI", "cs.MA", "I.2.11; I.2.6; I.2.8"], "pdf": "https://arxiv.org/pdf/2509.06235", "abs": "https://arxiv.org/abs/2509.06235", "authors": ["Olivier Schipper", "Yudi Zhang", "Yali Du", "Mykola Pechenizkiy", "Meng Fang"], "title": "PillagerBench: Benchmarking LLM-Based Agents in Competitive Minecraft Team Environments", "comment": "for the source code, see https://github.com/aialt/PillagerBench", "summary": "LLM-based agents have shown promise in various cooperative and strategic\nreasoning tasks, but their effectiveness in competitive multi-agent\nenvironments remains underexplored. To address this gap, we introduce\nPillagerBench, a novel framework for evaluating multi-agent systems in\nreal-time competitive team-vs-team scenarios in Minecraft. It provides an\nextensible API, multi-round testing, and rule-based built-in opponents for\nfair, reproducible comparisons. We also propose TactiCrafter, an LLM-based\nmulti-agent system that facilitates teamwork through human-readable tactics,\nlearns causal dependencies, and adapts to opponent strategies. Our evaluation\ndemonstrates that TactiCrafter outperforms baseline approaches and showcases\nadaptive learning through self-play. Additionally, we analyze its learning\nprocess and strategic evolution over multiple game episodes. To encourage\nfurther research, we have open-sourced PillagerBench, fostering advancements in\nmulti-agent AI for competitive environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86PillagerBench\u6846\u67b6\u7528\u4e8e\u8bc4\u4f30Minecraft\u4e2d\u7684\u5b9e\u65f6\u7ade\u4e89\u6027\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5e76\u5f00\u53d1\u4e86TactiCrafter\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u901a\u8fc7\u53ef\u8bfb\u6218\u672f\u4fc3\u8fdb\u56e2\u961f\u5408\u4f5c\uff0c\u5728\u7ade\u4e89\u4e2d\u8868\u73b0\u51fa\u8272\u5e76\u5c55\u793a\u4e86\u81ea\u9002\u5e94\u5b66\u4e60\u80fd\u529b\u3002", "motivation": "\u5f53\u524dLLM\u667a\u80fd\u4f53\u5728\u5408\u4f5c\u548c\u7b56\u7565\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u7ade\u4e89\u6027\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684\u6709\u6548\u6027\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u9700\u8981\u4e13\u95e8\u6846\u67b6\u8fdb\u884c\u8bc4\u4f30\u3002", "method": "\u5f00\u53d1\u4e86PillagerBench\u8bc4\u4f30\u6846\u67b6\uff0c\u63d0\u4f9b\u53ef\u6269\u5c55API\u3001\u591a\u8f6e\u6d4b\u8bd5\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u5bf9\u624b\uff1b\u63d0\u51fa\u4e86TactiCrafter\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u4f7f\u7528\u4eba\u7c7b\u53ef\u8bfb\u6218\u672f\u3001\u5b66\u4e60\u56e0\u679c\u4f9d\u8d56\u5e76\u9002\u5e94\u5bf9\u624b\u7b56\u7565\u3002", "result": "TactiCrafter\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u6211\u5bf9\u5f08\u5c55\u793a\u4e86\u81ea\u9002\u5e94\u5b66\u4e60\u80fd\u529b\uff0c\u5e76\u5728\u591a\u8f6e\u6e38\u620f\u4e2d\u5206\u6790\u4e86\u5176\u5b66\u4e60\u8fc7\u7a0b\u548c\u7b56\u7565\u6f14\u5316\u3002", "conclusion": "PillagerBench\u4e3a\u7ade\u4e89\u6027\u73af\u5883\u4e2d\u7684\u591a\u667a\u80fd\u4f53AI\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\uff0cTactiCrafter\u5c55\u793a\u4e86LLM\u667a\u80fd\u4f53\u5728\u7ade\u4e89\u73af\u5883\u4e2d\u7684\u6f5c\u529b\uff0c\u6846\u67b6\u5df2\u5f00\u6e90\u4ee5\u4fc3\u8fdb\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2509.05739", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.05739", "abs": "https://arxiv.org/abs/2509.05739", "authors": ["Hanna Foerster", "Ilia Shumailov", "Yiren Zhao", "Harsh Chaudhari", "Jamie Hayes", "Robert Mullins", "Yarin Gal"], "title": "Reasoning Introduces New Poisoning Attacks Yet Makes Them More Complicated", "comment": null, "summary": "Early research into data poisoning attacks against Large Language Models\n(LLMs) demonstrated the ease with which backdoors could be injected. More\nrecent LLMs add step-by-step reasoning, expanding the attack surface to include\nthe intermediate chain-of-thought (CoT) and its inherent trait of decomposing\nproblems into subproblems. Using these vectors for more stealthy poisoning, we\nintroduce ``decomposed reasoning poison'', in which the attacker modifies only\nthe reasoning path, leaving prompts and final answers clean, and splits the\ntrigger across multiple, individually harmless components.\n  Fascinatingly, while it remains possible to inject these decomposed poisons,\nreliably activating them to change final answers (rather than just the CoT) is\nsurprisingly difficult. This difficulty arises because the models can often\nrecover from backdoors that are activated within their thought processes.\nUltimately, it appears that an emergent form of backdoor robustness is\noriginating from the reasoning capabilities of these advanced LLMs, as well as\nfrom the architectural separation between reasoning and final answer\ngeneration.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6570\u636e\u6bd2\u5316\u653b\u51fb\uff0c\u63d0\u51fa\u4e86\u5206\u89e3\u7406\u7531\u6bd2\u5316\u653b\u51fb\u65b9\u6cd5\uff0c\u53d1\u73b0\u867d\u7136\u53ef\u6ce8\u5165\u6bd2\u5316\uff0c\u4f46\u6a21\u578b\u901a\u8fc7\u7406\u6027\u80fd\u529b\u548c\u67b6\u6784\u5206\u79bb\u5177\u6709\u4e00\u5b9a\u7684\u540e\u95e8\u7a0b\u5e8f\u7a33\u5065\u6027\u3002", "motivation": "\u65e9\u671f\u7814\u7a76\u663e\u793aLLM\u5bb9\u6613\u53d7\u5230\u6570\u636e\u6bd2\u5316\u653b\u51fb\uff0c\u73b0\u4ee3LLM\u52a0\u5165\u4e86\u9010\u6b65\u601d\u8003\u529f\u80fd\uff0c\u6269\u5927\u4e86\u653b\u51fb\u9762\uff0c\u9700\u8981\u7814\u7a76\u66f4\u9690\u8513\u7684\u6bd2\u5316\u653b\u51fb\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\"\u5206\u89e3\u7406\u7531\u6bd2\u5316\"\u65b9\u6cd5\uff0c\u653b\u51fb\u8005\u53ea\u4fee\u6539\u7406\u7531\u8def\u5f84\uff0c\u4fdd\u6301\u63d0\u793a\u548c\u6700\u7ec8\u7b54\u6848\u6e05\u6d01\uff0c\u5e76\u5c06\u89e6\u53d1\u5668\u5206\u6563\u5230\u591a\u4e2a\u65e0\u5bb3\u7ec4\u4ef6\u4e2d\u3002", "result": "\u867d\u7136\u53ef\u4ee5\u6ce8\u5165\u5206\u89e3\u6bd2\u5316\uff0c\u4f46\u53ef\u9760\u6fc0\u6d3b\u5b83\u4eec\u6539\u53d8\u6700\u7ec8\u7b54\u6848\u975e\u5e38\u56f0\u96be\uff0c\u56e0\u4e3a\u6a21\u578b\u7ecf\u5e38\u80fd\u591f\u4ece\u601d\u8003\u8fc7\u7a0b\u4e2d\u7684\u540e\u95e8\u7a0b\u5e8f\u4e2d\u6062\u590d\u3002", "conclusion": "\u9ad8\u7ea7LLM\u7684\u7406\u6027\u80fd\u529b\u548c\u7406\u7531-\u7b54\u6848\u751f\u6210\u7684\u67b6\u6784\u5206\u79bb\u4ea7\u751f\u4e86\u4e00\u79cd\u51fa\u73b0\u7684\u540e\u95e8\u7a0b\u5e8f\u7a33\u5065\u6027\uff0c\u4f7f\u5f97\u6570\u636e\u6bd2\u5316\u653b\u51fb\u66f4\u52a0\u56f0\u96be\u3002"}}
{"id": "2509.06239", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06239", "abs": "https://arxiv.org/abs/2509.06239", "authors": ["Manvi Jha", "Jiaxin Wan", "Deming Chen"], "title": "Proof2Silicon: Prompt Repair for Verified Code and Hardware Generation via Reinforcement Learning", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated impressive capabilities in\nautomated code generation but frequently produce code that fails formal\nverification, an essential requirement for hardware and safety-critical\ndomains. To overcome this fundamental limitation, we previously proposed\nPREFACE, a model-agnostic framework based on reinforcement learning (RL) that\niteratively repairs the prompts provided to frozen LLMs, systematically\nsteering them toward generating formally verifiable Dafny code without costly\nfine-tuning. This work presents Proof2Silicon, a novel end-to-end synthesis\nframework that embeds the previously proposed PREFACE flow to enable the\ngeneration of correctness-by-construction hardware directly from natural\nlanguage specifications. Proof2Silicon operates by: (1) leveraging PREFACE's\nverifier-driven RL agent to optimize prompt generation iteratively, ensuring\nDafny code correctness; (2) automatically translating verified Dafny programs\ninto synthesizable high-level C using Dafny's Python backend and PyLog; and (3)\nemploying Vivado HLS to produce RTL implementations. Evaluated rigorously on a\nchallenging 100-task benchmark, PREFACE's RL-guided prompt optimization\nconsistently improved Dafny verification success rates across diverse LLMs by\nup to 21%. Crucially, Proof2Silicon achieved an end-to-end hardware synthesis\nsuccess rate of up to 72%, generating RTL designs through Vivado HLS synthesis\nflows. These results demonstrate a robust, scalable, and automated pipeline for\nLLM-driven, formally verified hardware synthesis, bridging natural-language\nspecification and silicon realization.", "AI": {"tldr": "Proof2Silicon\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u786c\u4ef6\u5408\u6210\u6846\u67b6\uff0c\u901a\u8fc7PREFACE\u7684\u5f3a\u5316\u5b66\u4e60\u63d0\u793a\u4f18\u5316\u751f\u6210\u53ef\u9a8c\u8bc1\u7684Dafny\u4ee3\u7801\uff0c\u7136\u540e\u81ea\u52a8\u8f6c\u6362\u4e3aC\u4ee3\u7801\u5e76\u6700\u7ec8\u5408\u6210RTL\u786c\u4ef6\uff0c\u5728100\u4efb\u52a1\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523072%\u7684\u7aef\u5230\u7aef\u786c\u4ef6\u5408\u6210\u6210\u529f\u7387\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u4ee3\u7801\u7ecf\u5e38\u65e0\u6cd5\u901a\u8fc7\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u786c\u4ef6\u548c\u5b89\u5168\u5173\u952e\u9886\u57df\u9700\u8981\u6b63\u786e\u6027\u4fdd\u8bc1\u7684\u573a\u666f\u3002", "method": "1) \u4f7f\u7528PREFACE\u7684\u9a8c\u8bc1\u5668\u9a71\u52a8RL\u4ee3\u7406\u8fed\u4ee3\u4f18\u5316\u63d0\u793a\u751f\u6210\uff0c\u786e\u4fddDafny\u4ee3\u7801\u6b63\u786e\u6027\uff1b2) \u5c06\u9a8c\u8bc1\u540e\u7684Dafny\u7a0b\u5e8f\u81ea\u52a8\u8f6c\u6362\u4e3a\u53ef\u5408\u6210\u7684\u9ad8\u7ea7C\u4ee3\u7801\uff1b3) \u4f7f\u7528Vivado HLS\u751f\u6210RTL\u5b9e\u73b0\u3002", "result": "PREFACE\u7684RL\u5f15\u5bfc\u63d0\u793a\u4f18\u5316\u5c06Dafny\u9a8c\u8bc1\u6210\u529f\u7387\u63d0\u9ad8\u4e8621%\uff0cProof2Silicon\u5b9e\u73b0\u4e86\u9ad8\u8fbe72%\u7684\u7aef\u5230\u7aef\u786c\u4ef6\u5408\u6210\u6210\u529f\u7387\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u4e00\u4e2a\u5f3a\u5927\u3001\u53ef\u6269\u5c55\u4e14\u81ea\u52a8\u5316\u7684\u6d41\u6c34\u7ebf\uff0c\u80fd\u591f\u5b9e\u73b0\u4ece\u81ea\u7136\u8bed\u8a00\u89c4\u8303\u5230\u7845\u5b9e\u73b0\u7684LLM\u9a71\u52a8\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u786c\u4ef6\u5408\u6210\u3002"}}
{"id": "2509.05753", "categories": ["cs.CR", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.05753", "abs": "https://arxiv.org/abs/2509.05753", "authors": ["Ching-Chun Chang", "Isao Echizen"], "title": "Tell-Tale Watermarks for Explanatory Reasoning in Synthetic Media Forensics", "comment": null, "summary": "The rise of synthetic media has blurred the boundary between reality and\nfabrication under the evolving power of artificial intelligence, fueling an\ninfodemic that erodes public trust in cyberspace. For digital imagery, a\nmultitude of editing applications further complicates the forensic analysis,\nincluding semantic edits that alter content, photometric adjustments that\nrecalibrate colour characteristics, and geometric projections that reshape\nviewpoints. Collectively, these transformations manipulate and control\nperceptual interpretation of digital imagery. This susceptibility calls for\nforensic enquiry into reconstructing the chain of events, thereby revealing\ndeeper evidential insight into the presence or absence of criminal intent. This\nstudy seeks to address an inverse problem of tracing the underlying generation\nchain that gives rise to the observed synthetic media. A tell-tale watermarking\nsystem is developed for explanatory reasoning over the nature and extent of\ntransformations across the lifecycle of synthetic media. Tell-tale watermarks\nare tailored to different classes of transformations, responding in a manner\nthat is neither strictly robust nor fragile but instead interpretable. These\nwatermarks function as reference clues that evolve under the same\ntransformation dynamics as the carrier media, leaving interpretable traces when\nsubjected to transformations. Explanatory reasoning is then performed to infer\nthe most plausible account across the combinatorial parameter space of\ncomposite transformations. Experimental evaluations demonstrate the validity of\ntell-tale watermarking with respect to fidelity, synchronicity and\ntraceability.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u544a\u8bc9\u6c34\u5370\u7cfb\u7edf\uff0c\u7528\u4e8e\u8ffd\u8e2a\u5408\u6210\u5a92\u4f53\u7684\u751f\u547d\u5468\u671f\u53d8\u5f62\uff0c\u901a\u8fc7\u6c34\u5370\u7684\u53ef\u89e3\u91ca\u8ff9\u8e2a\u6765\u63a8\u65ad\u591a\u91cd\u53d8\u6362\u7684\u7ec4\u5408\u53c2\u6570\u7a7a\u95f4", "motivation": "\u5408\u6210\u5a92\u4f53\u7684\u51fa\u73b0\u6a21\u7cca\u4e86\u771f\u5b9e\u4e0e\u5047\u60a0\u7684\u754c\u9650\uff0c\u5f15\u53d1\u4fe1\u606f\u75c5\u6bd2\u6d41\u884c\uff0c\u540c\u65f6\u591a\u91cd\u7f16\u8f91\u5e94\u7528\u4f7f\u5f97\u56fe\u50cf\u53d8\u5f62\u5206\u6790\u53d8\u5f97\u590d\u6742\uff0c\u9700\u8981\u8fdb\u884c\u8ffd\u6eaf\u6027\u8c03\u67e5\u6765\u91cd\u5efa\u4e8b\u4ef6\u94fe", "method": "\u5f00\u53d1\u544a\u8bc9\u6c34\u5370\u7cfb\u7edf\uff0c\u4e3a\u4e0d\u540c\u7c7b\u578b\u7684\u53d8\u5f62\u91cf\u8eab\u5b9a\u5236\u6c34\u5370\uff0c\u8fd9\u4e9b\u6c34\u5370\u5728\u53d8\u5f62\u8fc7\u7a0b\u4e2d\u4f1a\u4ea7\u751f\u53ef\u89e3\u91ca\u7684\u8ff9\u8e2a\uff0c\u7136\u540e\u901a\u8fc7\u89e3\u91ca\u6027\u63a8\u7406\u6765\u63a8\u65ad\u590d\u5408\u53d8\u5f62\u7684\u6700\u53ef\u80fd\u53c2\u6570\u7ec4\u5408", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u8bc1\u660e\u4e86\u544a\u8bc9\u6c34\u5370\u7cfb\u7edf\u5728\u4fdd\u771f\u5ea6\u3001\u540c\u6b65\u6027\u548c\u53ef\u8ffd\u8e2a\u6027\u65b9\u9762\u7684\u6709\u6548\u6027", "conclusion": "\u544a\u8bc9\u6c34\u5370\u7cfb\u7edf\u4e3a\u5408\u6210\u5a92\u4f53\u7684\u53d8\u5f62\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u901a\u8fc7\u6c34\u5370\u8ff9\u8e2a\u6765\u63a8\u65ad\u591a\u91cd\u53d8\u6362\u7684\u53c2\u6570\u7a7a\u95f4\uff0c\u4e3a\u6570\u5b57\u56fe\u50cf\u7684\u8bc1\u636e\u8c03\u67e5\u63d0\u4f9b\u4e86\u66f4\u6df1\u5165\u7684\u89c1\u89e3"}}
{"id": "2509.06269", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06269", "abs": "https://arxiv.org/abs/2509.06269", "authors": ["Vishal Raman", "Vijai Aravindh R", "Abhijith Ragav"], "title": "REMI: A Novel Causal Schema Memory Architecture for Personalized Lifestyle Recommendation Agents", "comment": "8 pages, 2 figures, Accepted at the OARS Workshop, KDD 2025, Paper\n  link: https://oars-workshop.github.io/papers/Raman2025.pdf", "summary": "Personalized AI assistants often struggle to incorporate complex personal\ndata and causal knowledge, leading to generic advice that lacks explanatory\npower. We propose REMI, a Causal Schema Memory architecture for a multimodal\nlifestyle agent that integrates a personal causal knowledge graph, a causal\nreasoning engine, and a schema based planning module. The idea is to deliver\nexplainable, personalized recommendations in domains like fashion, personal\nwellness, and lifestyle planning. Our architecture uses a personal causal graph\nof the user's life events and habits, performs goal directed causal traversals\nenriched with external knowledge and hypothetical reasoning, and retrieves\nadaptable plan schemas to generate tailored action plans. A Large Language\nModel orchestrates these components, producing answers with transparent causal\nexplanations. We outline the CSM system design and introduce new evaluation\nmetrics for personalization and explainability, including Personalization\nSalience Score and Causal Reasoning Accuracy, to rigorously assess its\nperformance. Results indicate that CSM based agents can provide more context\naware, user aligned recommendations compared to baseline LLM agents. This work\ndemonstrates a novel approach to memory augmented, causal reasoning in\npersonalized agents, advancing the development of transparent and trustworthy\nAI lifestyle assistants.", "AI": {"tldr": "REMI\u662f\u4e00\u4e2a\u57fa\u4e8e\u56e0\u679c\u6a21\u5f0f\u8bb0\u5fc6\u7684\u591a\u6a21\u6001\u751f\u6d3b\u65b9\u5f0f\u52a9\u624b\uff0c\u901a\u8fc7\u6574\u5408\u4e2a\u4eba\u56e0\u679c\u77e5\u8bc6\u56fe\u8c31\u3001\u56e0\u679c\u63a8\u7406\u5f15\u64ce\u548c\u6a21\u5f0f\u89c4\u5212\u6a21\u5757\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u4e2a\u6027\u5316\u63a8\u8350", "motivation": "\u73b0\u6709AI\u52a9\u624b\u96be\u4ee5\u6574\u5408\u590d\u6742\u7684\u4e2a\u4eba\u6570\u636e\u548c\u56e0\u679c\u77e5\u8bc6\uff0c\u5bfc\u81f4\u5efa\u8bae\u7f3a\u4e4f\u4e2a\u6027\u5316\u548c\u89e3\u91ca\u6027", "method": "\u4f7f\u7528\u4e2a\u4eba\u56e0\u679c\u56fe\u8c31\u8bb0\u5f55\u7528\u6237\u751f\u6d3b\u4e8b\u4ef6\u548c\u4e60\u60ef\uff0c\u901a\u8fc7\u76ee\u6807\u5bfc\u5411\u7684\u56e0\u679c\u904d\u5386\u3001\u5916\u90e8\u77e5\u8bc6\u589e\u5f3a\u548c\u5047\u8bbe\u63a8\u7406\uff0c\u7ed3\u5408LLM\u534f\u8c03\u751f\u6210\u900f\u660e\u56e0\u679c\u89e3\u91ca\u7684\u884c\u52a8\u8ba1\u5212", "result": "\u57fa\u4e8eCSM\u7684\u667a\u80fd\u4f53\u6bd4\u57fa\u7ebfLLM\u667a\u80fd\u4f53\u80fd\u63d0\u4f9b\u66f4\u60c5\u5883\u611f\u77e5\u3001\u7528\u6237\u5bf9\u9f50\u7684\u63a8\u8350", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u5728\u4e2a\u6027\u5316\u667a\u80fd\u4f53\u4e2d\u5b9e\u73b0\u8bb0\u5fc6\u589e\u5f3a\u56e0\u679c\u63a8\u7406\u7684\u65b0\u65b9\u6cd5\uff0c\u63a8\u52a8\u4e86\u900f\u660e\u53ef\u4fe1AI\u751f\u6d3b\u65b9\u5f0f\u52a9\u624b\u7684\u53d1\u5c55"}}
{"id": "2509.05755", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05755", "abs": "https://arxiv.org/abs/2509.05755", "authors": ["Yu Liu", "Yuchong Xie", "Mingyu Luo", "Zesen Liu", "Zhixiang Zhang", "Kaikai Zhang", "Zongjie Li", "Ping Chen", "Shuai Wang", "Dongdong She"], "title": "Exploit Tool Invocation Prompt for Tool Behavior Hijacking in LLM-Based Agentic System", "comment": null, "summary": "LLM-based agentic systems leverage large language models to handle user\nqueries, make decisions, and execute external tools for complex tasks across\ndomains like chatbots, customer service, and software engineering. A critical\ncomponent of these systems is the Tool Invocation Prompt (TIP), which defines\ntool interaction protocols and guides LLMs to ensure the security and\ncorrectness of tool usage. Despite its importance, TIP security has been\nlargely overlooked. This work investigates TIP-related security risks,\nrevealing that major LLM-based systems like Cursor, Claude Code, and others are\nvulnerable to attacks such as remote code execution (RCE) and denial of service\n(DoS). Through a systematic TIP exploitation workflow (TEW), we demonstrate\nexternal tool behavior hijacking via manipulated tool invocations. We also\npropose defense mechanisms to enhance TIP security in LLM-based agentic\nsystems.", "AI": {"tldr": "LLM\u57fa\u4e8e\u4ee3\u7406\u7cfb\u7edf\u4e2d\u7684\u5de5\u5177\u8c03\u7528\u63d0\u793a\uff08TIP\uff09\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\uff0c\u53ef\u5bfc\u81f4\u8fdc\u7a0b\u4ee3\u7801\u6267\u884c\u548c\u62d2\u7edd\u670d\u52a1\u653b\u51fb\u3002\u8fd9\u9879\u7814\u7a76\u63ed\u9732\u4e86\u4e3b\u6d41LLM\u7cfb\u7edf\u7684\u5f31\u70b9\uff0c\u5e76\u63d0\u51fa\u9632\u5fa1\u673a\u5236\u3002", "motivation": "\u5de5\u5177\u8c03\u7528\u63d0\u793a\uff08TIP\uff09\u5728LLM\u57fa\u4e8e\u4ee3\u7406\u7cfb\u7edf\u4e2d\u81f4\u5173\u91cd\u8981\uff0c\u8d1f\u8d23\u786e\u4fdd\u5de5\u5177\u4f7f\u7528\u7684\u5b89\u5168\u6027\u548c\u6b63\u786e\u6027\uff0c\u4f46\u5176\u5b89\u5168\u95ee\u9898\u4e00\u76f4\u88ab\u5ffd\u89c6\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u5316\u7684TIP\u5229\u7526\u5de5\u4f5c\u6d41\u7a0b\uff08TEW\uff09\uff0c\u6f14\u793a\u5982\u4f55\u901a\u8fc7\u64cd\u7eb5\u5de5\u5177\u8c03\u7528\u6765\u7be1\u6539\u5916\u90e8\u5de5\u5177\u884c\u4e3a\uff0c\u5bf9\u4e3b\u6d41LLM\u7cfb\u7edf\u8fdb\u884c\u5b89\u5168\u6f0f\u6d1e\u5206\u6790\u3002", "result": "\u53d1\u73b0Cursor\u3001Claude Code\u7b49\u4e3b\u8981LLM\u57fa\u4e8e\u7cfb\u7edf\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\uff0c\u53ef\u80fd\u9020\u6210\u8fdc\u7a0b\u4ee3\u7801\u6267\u884c\uff08RCE\uff09\u548c\u62d2\u7edd\u670d\u52a1\uff08DoS\uff09\u653b\u51fb\u3002", "conclusion": "\u5de5\u5177\u8c03\u7528\u63d0\u793a\u7684\u5b89\u5168\u98ce\u9669\u9700\u8981\u7acb\u5373\u5173\u6ce8\uff0c\u7814\u7a76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u9632\u5fa1\u673a\u5236\u6765\u63d0\u5347LLM\u57fa\u4e8e\u4ee3\u7406\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2509.06278", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06278", "abs": "https://arxiv.org/abs/2509.06278", "authors": ["Chuang Jiang", "Mingyue Cheng", "Xiaoyu Tao", "Qingyang Mao", "Jie Ouyang", "Qi Liu"], "title": "TableMind: An Autonomous Programmatic Agent for Tool-Augmented Table Reasoning", "comment": "Comments: 10 pages, 6 figures. Submitted to WSDM 2026", "summary": "Table reasoning is crucial for leveraging structured data in domains such as\nfinance, healthcare, and scientific research. While large language models\n(LLMs) show promise in multi-step reasoning, purely text-based methods often\nstruggle with the complex numerical computations and fine-grained operations\ninherently required in this task. Tool-integrated reasoning improves\ncomputational accuracy via explicit code execution, yet existing systems\nfrequently rely on rigid patterns, supervised imitation, and lack true\nautonomous adaptability. In this paper, we present TableMind, an LLM-driven\ntable reasoning agent that (i) autonomously performs multi-turn tool\ninvocation, (ii) writes and executes data-analyzing code in a secure sandbox\nenvironment for data analysis and precise numerical reasoning, and (iii)\nexhibits high-level capabilities such as planning and self-reflection to adapt\nstrategies. To realize these capabilities, we adopt a two-stage fine-tuning\nparadigm built on top of a powerful pre-trained language model: supervised\nfine-tuning on high-quality reasoning trajectories to establish effective tool\nusage patterns, followed by reinforcement fine-tuning to optimize\nmulti-objective strategies. In particular, we propose Rank-Aware Policy\nOptimization (RAPO), which increases the update weight of high-quality\ntrajectories when their output probabilities are lower than those of\nlow-quality ones, thereby guiding the model more consistently toward better and\nmore accurate answers. Extensive experiments on several mainstream benchmarks\ndemonstrate that TableMind achieves superior performance compared to\ncompetitive baselines, yielding substantial gains in both reasoning accuracy\nand computational precision.", "AI": {"tldr": "TableMind\u662f\u4e00\u4e2aLLM\u9a71\u52a8\u7684\u8868\u683c\u63a8\u7406\u4ee3\u7406\uff0c\u901a\u8fc7\u81ea\u4e3b\u5de5\u5177\u8c03\u7528\u3001\u4ee3\u7801\u6267\u884c\u548c\u81ea\u53cd\u601d\u80fd\u529b\uff0c\u5728\u5b89\u5168\u6c99\u7bb1\u73af\u5883\u4e2d\u5b9e\u73b0\u7cbe\u786e\u7684\u6570\u503c\u63a8\u7406\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u5fae\u8c03\u8303\u5f0f\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u7eaf\u6587\u672c\u65b9\u6cd5\u5728\u590d\u6742\u6570\u503c\u8ba1\u7b97\u548c\u7ec6\u7c92\u5ea6\u64cd\u4f5c\u4e0a\u7684\u4e0d\u8db3\uff0c\u4ee5\u53ca\u73b0\u6709\u5de5\u5177\u96c6\u6210\u65b9\u6cd5\u7f3a\u4e4f\u771f\u6b63\u81ea\u4e3b\u9002\u5e94\u6027\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u5fae\u8c03\uff1a\u76d1\u7763\u5fae\u8c03\u5efa\u7acb\u6709\u6548\u5de5\u5177\u4f7f\u7528\u6a21\u5f0f\uff0c\u5f3a\u5316\u5fae\u8c03\u4f18\u5316\u591a\u76ee\u6807\u7b56\u7565\uff0c\u5e76\u63d0\u51faRank-Aware Policy Optimization (RAPO)\u65b9\u6cd5\u3002", "result": "\u5728\u591a\u4e2a\u4e3b\u6d41\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u4f18\u4e8e\u7ade\u4e89\u57fa\u7ebf\u7684\u6027\u80fd\uff0c\u5728\u63a8\u7406\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u7cbe\u5ea6\u65b9\u9762\u90fd\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "TableMind\u901a\u8fc7\u81ea\u4e3b\u5de5\u5177\u8c03\u7528\u548c\u4ee3\u7801\u6267\u884c\u80fd\u529b\uff0c\u7ed3\u5408\u521b\u65b0\u7684\u5fae\u8c03\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8868\u683c\u63a8\u7406\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u4e3a\u7ed3\u6784\u5316\u6570\u636e\u5904\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.05797", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.05797", "abs": "https://arxiv.org/abs/2509.05797", "authors": ["Hai Dinh-Tuan", "Sandro Rodriguez Garzon", "Jianeng Fu"], "title": "Secure and Trustful Cross-domain Communication with Decentralized Identifiers in 5G and Beyond", "comment": null, "summary": "In the evolving landscape of future mobile networks, there is a critical need\nfor secure and trustful communication modalities to support dynamic\ninteractions among core network components of different network domains. This\npaper proposes the application of W3C-endorsed Decentralized Identifiers (DIDs)\nto establish secure and trustful communication channels among network functions\nin 5G and subsequent generations. A new communication agent is introduced that\nintegrates seamlessly with 5G-standardized network functions and utilizes a\nDID-based application layer transport protocol to ensure confidentiality,\nintegrity, and authenticity for cross-domain interactions. A comparative\nanalysis of the two different versions of the DID-based communication protocol\nfor inter network function communication reveals compatibility advantages of\nthe latest protocol iteration. Furthermore, a comprehensive evaluation of the\ncommunication overhead caused by both protocol iterations compared to\ntraditional TCP/TLS shows the benefits of using DIDs to improve communication\nsecurity, albeit with performance loses compared to TCP/TLS. These results\nuncover the potential of DID-based communication for future mobile networks but\nalso point out areas for optimization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528W3C\u6807\u51c6\u7684\u53bb\u4e2d\u5fc3\u5316\u6807\u8bc6\u7b26(DID)\u6765\u5efa\u7acb5G\u53ca\u66f4\u9ad8\u4ee3\u79fb\u52a8\u7f51\u7edc\u4e2d\u7f51\u7edc\u529f\u80fd\u95f4\u7684\u5b89\u5168\u4fe1\u4efb\u901a\u4fe1\u901a\u9053\uff0c\u8fdb\u884c\u4e86\u534f\u8bae\u6bd4\u8f83\u548c\u6027\u80fd\u8bc4\u4f30\u3002", "motivation": "\u672a\u6765\u79fb\u52a8\u7f51\u7edc\u9700\u8981\u5b89\u5168\u53ef\u4fe1\u7684\u901a\u4fe1\u65b9\u5f0f\u6765\u652f\u6301\u4e0d\u540c\u7f51\u7edc\u57df\u6838\u5fc3\u7ec4\u4ef6\u95f4\u7684\u52a8\u6001\u4ea4\u4e92\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u901a\u4fe1\u4ee3\u7406\uff0c\u96c6\u6210\u52305G\u6807\u51c6\u5316\u7f51\u7edc\u529f\u80fd\uff0c\u4f7f\u7528DID\u57fa\u4e8e\u5e94\u7528\u5c42\u4f20\u8f93\u534f\u8bae\u786e\u4fdd\u8de8\u57df\u4ea4\u4e92\u7684\u4fdd\u5bc6\u6027\u3001\u5b8c\u6574\u6027\u548c\u771f\u5b9e\u6027\u3002", "result": "\u5bf9\u6bd4\u5206\u6790\u663e\u793a\u6700\u65b0DID\u534f\u8bae\u7248\u672c\u5177\u6709\u66f4\u597d\u7684\u517c\u5bb9\u6027\u4f18\u52bf\uff1b\u4e0e\u4f20\u7edfTCP/TLS\u76f8\u6bd4\uff0cDID\u57fa\u4e8e\u901a\u4fe1\u5728\u901a\u4fe1\u5f00\u9500\u65b9\u9762\u6709\u6027\u80fd\u635f\u5931\uff0c\u4f46\u80fd\u591f\u63d0\u9ad8\u901a\u4fe1\u5b89\u5168\u6027\u3002", "conclusion": "DID\u57fa\u4e8e\u901a\u4fe1\u5728\u672a\u6765\u79fb\u52a8\u7f51\u7edc\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u5728\u6027\u80fd\u4f18\u5316\u65b9\u9762\u8fdb\u4e00\u6b65\u6539\u8fdb\u3002"}}
{"id": "2509.06283", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.06283", "abs": "https://arxiv.org/abs/2509.06283", "authors": ["Xuan-Phi Nguyen", "Shrey Pandit", "Revanth Gangi Reddy", "Austin Xu", "Silvio Savarese", "Caiming Xiong", "Shafiq Joty"], "title": "SFR-DeepResearch: Towards Effective Reinforcement Learning for Autonomously Reasoning Single Agents", "comment": "Technical Report", "summary": "Equipping large language models (LLMs) with complex, interleaved reasoning\nand tool-use capabilities has become a key focus in agentic AI research,\nespecially with recent advances in reasoning-oriented (``thinking'') models.\nSuch capabilities are key to unlocking a number of important applications. One\nsuch application is Deep Research (DR), which requires extensive search and\nreasoning over many sources. Our work in this paper focuses on the development\nof native Autonomous Single-Agent models for DR featuring minimal web crawling\nand Python tool integration. Unlike multi-agent systems, where agents take up\npre-defined roles and are told what to do at each step in a static workflow, an\nautonomous single-agent determines its next action dynamically based on\ncontext, without manual directive. While prior work has proposed training\nrecipes for base or instruction-tuned LLMs, we focus on continual reinforcement\nlearning (RL) of reasoning-optimized models to further enhance agentic skills\nwhile preserving reasoning ability. Towards this end, we propose a simple RL\nrecipe with entirely synthetic data, which we apply to various open-source\nLLMs. Our best variant SFR-DR-20B achieves up to 28.7% on Humanity's Last Exam\nbenchmark. In addition, we conduct key analysis experiments to provide more\ninsights into our methodologies.", "AI": {"tldr": "\u901a\u8fc7\u7eed\u4ee3\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7406\u6027\u4f18\u5316\u6a21\u578b\uff0c\u53d1\u5c55\u81ea\u4e3b\u5355\u4ee3\u7406\u6df1\u5ea6\u7814\u7a76\u80fd\u529b\uff0c\u5728Humanity's Last Exam\u6d4b\u8bd5\u4e2d\u8fbe\u523028.7%\u7684\u6027\u80fd", "motivation": "\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u7f16\u5236\u590d\u6742\u7684\u4ea4\u9519\u63a8\u7406\u548c\u5de5\u5177\u4f7f\u7528\u80fd\u529b\uff0c\u5f00\u53d1\u81ea\u4e3b\u5355\u4ee3\u7406\u6a21\u578b\u8fdb\u884c\u6df1\u5ea6\u7814\u7a76\uff0c\u5145\u5206\u5229\u7528\u6700\u65b0\u7684\u7406\u6027\u4f18\u5316\u6a21\u578b\u8fdb\u6b65", "method": "\u63d0\u51fa\u7b80\u5355\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u4f7f\u7528\u5168\u5408\u6210\u6570\u636e\u8fdb\u884c\u7eed\u4ee3\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u96c6\u6210\u6700\u5c0f\u5316\u7f51\u7edc\u722c\u866b\u548cPython\u5de5\u5177", "result": "\u6700\u4f73\u6a21\u578bSFR-DR-20B\u5728Humanity's Last Exam\u6d4b\u8bd5\u4e2d\u8fbe\u523028.7%\u7684\u6027\u80fd\uff0c\u8fdb\u884c\u4e86\u5173\u952e\u5206\u6790\u5b9e\u9a8c\u4ee5\u63d0\u4f9b\u66f4\u591a\u6d1e\u5bdf", "conclusion": "\u901a\u8fc7\u7eed\u4ee3\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u7406\u6027\u4f18\u5316\u6a21\u578b\u7684\u4ee3\u7406\u6280\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u5176\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u81ea\u4e3b\u5355\u4ee3\u7406\u6df1\u5ea6\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848"}}
{"id": "2509.05831", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05831", "abs": "https://arxiv.org/abs/2509.05831", "authors": ["Ishaan Verma"], "title": "Decoding Latent Attack Surfaces in LLMs: Prompt Injection via HTML in Web Summarization", "comment": null, "summary": "Large Language Models (LLMs) are increasingly integrated into web-based\nsystems for content summarization, yet their susceptibility to prompt injection\nattacks remains a pressing concern. In this study, we explore how non-visible\nHTML elements such as <meta>, aria-label, and alt attributes can be exploited\nto embed adversarial instructions without altering the visible content of a\nwebpage. We introduce a novel dataset comprising 280 static web pages, evenly\ndivided between clean and adversarial injected versions, crafted using diverse\nHTML-based strategies. These pages are processed through a browser automation\npipeline to extract both raw HTML and rendered text, closely mimicking\nreal-world LLM deployment scenarios. We evaluate two state-of-the-art\nopen-source models, Llama 4 Scout (Meta) and Gemma 9B IT (Google), on their\nability to summarize this content. Using both lexical (ROUGE-L) and semantic\n(SBERT cosine similarity) metrics, along with manual annotations, we assess the\nimpact of these covert injections. Our findings reveal that over 29% of\ninjected samples led to noticeable changes in the Llama 4 Scout summaries,\nwhile Gemma 9B IT showed a lower, yet non-trivial, success rate of 15%. These\nresults highlight a critical and largely overlooked vulnerability in LLM driven\nweb pipelines, where hidden adversarial content can subtly manipulate model\noutputs. Our work offers a reproducible framework and benchmark for evaluating\nHTML-based prompt injection and underscores the urgent need for robust\nmitigation strategies in LLM applications involving web content.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLM\u5728\u7f51\u9875\u5185\u5bb9\u6458\u8981\u4e2d\u5bb9\u6613\u53d7\u5230HTML\u9690\u85cf\u5143\u7d20\uff08\u5982meta\u6807\u7b7e\u3001aria-label\u7b49\uff09\u7684\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c29%\u7684\u6ce8\u5165\u6837\u672c\u6210\u529f\u5f71\u54cd\u4e86Llama 4 Scout\u7684\u6458\u8981\u8f93\u51fa\u3002", "motivation": "\u968f\u7740LLM\u8d8a\u6765\u8d8a\u591a\u5730\u96c6\u6210\u5230\u57fa\u4e8e\u7f51\u9875\u7684\u5185\u5bb9\u6458\u8981\u7cfb\u7edf\u4e2d\uff0c\u5176\u5bf9\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u7684\u8106\u5f31\u6027\u6210\u4e3a\u4e00\u4e2a\u7d27\u8feb\u7684\u5b89\u5168\u95ee\u9898\uff0c\u7279\u522b\u662f\u975e\u53ef\u89c1HTML\u5143\u7d20\u7684\u6f5c\u5728\u5a01\u80c1\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u521b\u5efa\u5305\u542b280\u4e2a\u9759\u6001\u7f51\u9875\u7684\u6570\u636e\u96c6\uff08\u4e00\u534a\u5e72\u51c0\uff0c\u4e00\u534a\u6ce8\u5165\u5bf9\u6297\u6027\u6307\u4ee4\uff09\uff0c\u4f7f\u7528\u6d4f\u89c8\u5668\u81ea\u52a8\u5316\u7ba1\u9053\u63d0\u53d6HTML\u548c\u6e32\u67d3\u6587\u672c\uff0c\u8bc4\u4f30Llama 4 Scout\u548cGemma 9B IT\u6a21\u578b\u5728\u5185\u5bb9\u6458\u8981\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u91c7\u7528ROUGE-L\u548cSBERT\u4f59\u5f26\u76f8\u4f3c\u5ea6\u6307\u6807\u4ee5\u53ca\u4eba\u5de5\u6807\u6ce8\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "29%\u7684\u6ce8\u5165\u6837\u672c\u5bfc\u81f4Llama 4 Scout\u6458\u8981\u51fa\u73b0\u660e\u663e\u53d8\u5316\uff0cGemma 9B IT\u7684\u6210\u529f\u7387\u4e3a15%\u3002\u4e24\u79cd\u6a21\u578b\u90fd\u663e\u793a\u51fa\u5bf9HTML\u9690\u85cf\u5143\u7d20\u6ce8\u5165\u653b\u51fb\u7684\u8106\u5f31\u6027\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86LLM\u9a71\u52a8\u7f51\u9875\u7ba1\u9053\u4e2d\u5b58\u5728\u4e25\u91cd\u4f46\u88ab\u5ffd\u89c6\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u9690\u85cf\u7684\u5bf9\u6297\u6027\u5185\u5bb9\u53ef\u4ee5\u5fae\u5999\u5730\u64cd\u7eb5\u6a21\u578b\u8f93\u51fa\uff0c\u4e9f\u9700\u5f00\u53d1\u7a33\u5065\u7684\u7f13\u89e3\u7b56\u7565\u3002"}}
{"id": "2509.06284", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.06284", "abs": "https://arxiv.org/abs/2509.06284", "authors": ["Jiaxiang Chen", "Zhuo Wang", "Mingxi Zou", "Zhucong Li", "Zhijian Zhou", "Song Wang", "Zenglin Xu"], "title": "From Implicit Exploration to Structured Reasoning: Leveraging Guideline and Refinement for LLMs", "comment": null, "summary": "Large language models (LLMs) have advanced general-purpose reasoning, showing\nstrong performance across diverse tasks. However, existing methods often rely\non implicit exploration, where the model follows stochastic and unguided\nreasoning paths-like walking without a map. This leads to unstable reasoning\npaths, lack of error correction, and limited learning from past experience. To\naddress these issues, we propose a framework that shifts from implicit\nexploration to structured reasoning through guideline and refinement. First, we\nextract structured reasoning patterns from successful trajectories and\nreflective signals from failures. During inference, the model follows these\nguidelines step-by-step, with refinement applied after each step to correct\nerrors and stabilize the reasoning process. Experiments on BBH and four\nadditional benchmarks (GSM8K, MATH-500, MBPP, HumanEval) show that our method\nconsistently outperforms strong baselines across diverse reasoning tasks.\nStructured reasoning with stepwise execution and refinement improves stability\nand generalization, while guidelines transfer well across domains and flexibly\nsupport cross-model collaboration, matching or surpassing supervised\nfine-tuning in effectiveness and scalability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u6784\u5316\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u4ece\u6210\u529f\u8f68\u8ff9\u4e2d\u63d0\u53d6\u6307\u5bfc\u51c6\u5219\u548c\u4ece\u5931\u8d25\u4e2d\u83b7\u53d6\u53cd\u601d\u4fe1\u53f7\uff0c\u5b9e\u73b0\u9010\u6b65\u6267\u884c\u548c\u7cbe\u70bc\uff0c\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u7a33\u5b9a\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u65b9\u6cd5\u4f9d\u8d56\u9690\u5f0f\u63a2\u7d22\uff0c\u5bfc\u81f4\u63a8\u7406\u8def\u5f84\u4e0d\u7a33\u5b9a\u3001\u7f3a\u4e4f\u9519\u8bef\u7ea0\u6b63\u80fd\u529b\uff0c\u4e14\u65e0\u6cd5\u4ece\u8fc7\u5f80\u7ecf\u9a8c\u4e2d\u5b66\u4e60\u3002", "method": "\u4ece\u6210\u529f\u8f68\u8ff9\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u63a8\u7406\u6a21\u5f0f\uff0c\u4ece\u5931\u8d25\u4e2d\u83b7\u53d6\u53cd\u601d\u4fe1\u53f7\u4f5c\u4e3a\u6307\u5bfc\u51c6\u5219\u3002\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u9010\u6b65\u6267\u884c\u5e76\u5e94\u7528\u7cbe\u70bc\u673a\u5236\u7ea0\u6b63\u9519\u8bef\u3002", "result": "\u5728BBH\u3001GSM8K\u3001MATH-500\u3001MBPP\u3001HumanEval\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d consistently \u8d85\u8d8a\u5f3a\u57fa\u7ebf\uff0c\u63a8\u7406\u7a33\u5b9a\u6027\u548c\u6cdb\u5316\u80fd\u529b\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u7ed3\u6784\u5316\u63a8\u7406\u6846\u67b6\u901a\u8fc7\u6307\u5bfc\u51c6\u5219\u548c\u9010\u6b65\u7cbe\u70bc\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u9690\u5f0f\u63a2\u7d22\u7684\u95ee\u9898\uff0c\u5728\u6548\u679c\u548c\u53ef\u6269\u5c55\u6027\u4e0a\u8fbe\u5230\u6216\u8d85\u8fc7\u4e86\u76d1\u7763\u5fae\u8c03\u7684\u6c34\u5e73\u3002"}}
{"id": "2509.05835", "categories": ["cs.CR", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2509.05835", "abs": "https://arxiv.org/abs/2509.05835", "authors": ["Lingfeng Yao", "Chenpei Huang", "Shengyao Wang", "Junpei Xue", "Hanqing Guo", "Jiang Liu", "Phone Lin", "Tomoaki Ohtsuki", "Miao Pan"], "title": "Yours or Mine? Overwriting Attacks against Neural Audio Watermarking", "comment": null, "summary": "As generative audio models are rapidly evolving, AI-generated audios\nincreasingly raise concerns about copyright infringement and misinformation\nspread. Audio watermarking, as a proactive defense, can embed secret messages\ninto audio for copyright protection and source verification. However, current\nneural audio watermarking methods focus primarily on the imperceptibility and\nrobustness of watermarking, while ignoring its vulnerability to security\nattacks. In this paper, we develop a simple yet powerful attack: the\noverwriting attack that overwrites the legitimate audio watermark with a forged\none and makes the original legitimate watermark undetectable. Based on the\naudio watermarking information that the adversary has, we propose three\ncategories of overwriting attacks, i.e., white-box, gray-box, and black-box\nattacks. We also thoroughly evaluate the proposed attacks on state-of-the-art\nneural audio watermarking methods. Experimental results demonstrate that the\nproposed overwriting attacks can effectively compromise existing watermarking\nschemes across various settings and achieve a nearly 100% attack success rate.\nThe practicality and effectiveness of the proposed overwriting attacks expose\nsecurity flaws in existing neural audio watermarking systems, underscoring the\nneed to enhance security in future audio watermarking designs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u795e\u7ecf\u97f3\u9891\u6c34\u5370\u7cfb\u7edf\u7684\u8986\u76d6\u653b\u51fb\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u767d\u76d2\u3001\u7070\u76d2\u548c\u9ed1\u76d2\u4e09\u79cd\u573a\u666f\u4e0b\u6709\u6548\u8986\u76d6\u539f\u59cb\u6c34\u5370\uff0c\u653b\u51fb\u6210\u529f\u7387\u63a5\u8fd1100%\uff0c\u66b4\u9732\u4e86\u73b0\u6709\u97f3\u9891\u6c34\u5370\u7cfb\u7edf\u7684\u5b89\u5168\u6f0f\u6d1e\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0f\u97f3\u9891\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0cAI\u751f\u6210\u7684\u97f3\u9891\u5f15\u53d1\u4e86\u7248\u6743\u4fb5\u6743\u548c\u9519\u8bef\u4fe1\u606f\u4f20\u64ad\u7684\u62c5\u5fe7\u3002\u97f3\u9891\u6c34\u5370\u4f5c\u4e3a\u4e3b\u52a8\u9632\u5fa1\u624b\u6bb5\u53ef\u4ee5\u5d4c\u5165\u79d8\u5bc6\u4fe1\u606f\u8fdb\u884c\u7248\u6743\u4fdd\u62a4\u548c\u6765\u6e90\u9a8c\u8bc1\uff0c\u4f46\u73b0\u6709\u795e\u7ecf\u97f3\u9891\u6c34\u5370\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u4e0d\u53ef\u611f\u77e5\u6027\u548c\u9c81\u68d2\u6027\uff0c\u5ffd\u89c6\u4e86\u5176\u9762\u5bf9\u5b89\u5168\u653b\u51fb\u7684\u8106\u5f31\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u7b80\u5355\u4f46\u5f3a\u5927\u7684\u8986\u76d6\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u7528\u4f2a\u9020\u7684\u6c34\u5370\u8986\u76d6\u5408\u6cd5\u7684\u97f3\u9891\u6c34\u5370\uff0c\u4f7f\u539f\u59cb\u5408\u6cd5\u6c34\u5370\u65e0\u6cd5\u68c0\u6d4b\u3002\u6839\u636e\u653b\u51fb\u8005\u62e5\u6709\u7684\u6c34\u5370\u4fe1\u606f\uff0c\u63d0\u51fa\u4e86\u767d\u76d2\u3001\u7070\u76d2\u548c\u9ed1\u76d2\u4e09\u79cd\u653b\u51fb\u7c7b\u522b\uff0c\u5e76\u5728\u6700\u5148\u8fdb\u7684\u795e\u7ecf\u97f3\u9891\u6c34\u5370\u65b9\u6cd5\u4e0a\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684\u8986\u76d6\u653b\u51fb\u80fd\u591f\u6709\u6548\u7834\u574f\u5404\u79cd\u8bbe\u7f6e\u4e0b\u7684\u73b0\u6709\u6c34\u5370\u65b9\u6848\uff0c\u653b\u51fb\u6210\u529f\u7387\u63a5\u8fd1100%\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u8986\u76d6\u653b\u51fb\u7684\u5b9e\u7528\u6027\u548c\u6709\u6548\u6027\u66b4\u9732\u4e86\u73b0\u6709\u795e\u7ecf\u97f3\u9891\u6c34\u5370\u7cfb\u7edf\u7684\u5b89\u5168\u7f3a\u9677\uff0c\u5f3a\u8c03\u4e86\u5728\u672a\u6765\u97f3\u9891\u6c34\u5370\u8bbe\u8ba1\u4e2d\u589e\u5f3a\u5b89\u5168\u6027\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2509.06307", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06307", "abs": "https://arxiv.org/abs/2509.06307", "authors": ["Lei Shu", "Dong Zhao"], "title": "Can AI Make Energy Retrofit Decisions? An Evaluation of Large Language Models", "comment": null, "summary": "Conventional approaches to building energy retrofit decision making suffer\nfrom limited generalizability and low interpretability, hindering adoption in\ndiverse residential contexts. With the growth of Smart and Connected\nCommunities, generative AI, especially large language models (LLMs), may help\nby processing contextual information and producing practitioner readable\nrecommendations. We evaluate seven LLMs (ChatGPT, DeepSeek, Gemini, Grok,\nLlama, and Claude) on residential retrofit decisions under two objectives:\nmaximizing CO2 reduction (technical) and minimizing payback period\n(sociotechnical). Performance is assessed on four dimensions: accuracy,\nconsistency, sensitivity, and reasoning, using a dataset of 400 homes across 49\nUS states. LLMs generate effective recommendations in many cases, reaching up\nto 54.5 percent top 1 match and 92.8 percent within top 5 without fine tuning.\nPerformance is stronger for the technical objective, while sociotechnical\ndecisions are limited by economic trade offs and local context. Agreement\nacross models is low, and higher performing models tend to diverge from others.\nLLMs are sensitive to location and building geometry but less sensitive to\ntechnology and occupant behavior. Most models show step by step, engineering\nstyle reasoning, but it is often simplified and lacks deeper contextual\nawareness. Overall, LLMs are promising assistants for energy retrofit decision\nmaking, but improvements in accuracy, consistency, and context handling are\nneeded for reliable practice.", "AI": {"tldr": "\u8bc4\u4f307\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f4f\u5b85\u8282\u80fd\u6539\u9020\u51b3\u7b56\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5728\u6280\u672f\u76ee\u6807\u4e0a\u8868\u73b0\u66f4\u597d\uff0c\u6700\u9ad8\u8fbe\u523054.5%\u7684top1\u5339\u914d\u7387\uff0c\u4f46\u6a21\u578b\u95f4\u4e00\u81f4\u6027\u8f83\u4f4e\uff0c\u9700\u8981\u6539\u8fdb\u51c6\u786e\u6027\u3001\u4e00\u81f4\u6027\u548c\u4e0a\u4e0b\u6587\u5904\u7406\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u5efa\u7b51\u8282\u80fd\u6539\u9020\u51b3\u7b56\u65b9\u6cd5\u901a\u7528\u6027\u6709\u9650\u4e14\u53ef\u89e3\u91ca\u6027\u4f4e\uff0c\u963b\u788d\u4e86\u5728\u591a\u6837\u5316\u4f4f\u5b85\u73af\u5883\u4e2d\u7684\u91c7\u7528\u3002\u968f\u7740\u667a\u80fd\u793e\u533a\u7684\u53d1\u5c55\uff0c\u751f\u6210\u5f0fAI\u7279\u522b\u662f\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u901a\u8fc7\u5904\u7406\u4e0a\u4e0b\u6587\u4fe1\u606f\u6765\u63d0\u4f9b\u53ef\u8bfb\u7684\u5efa\u8bae\u3002", "method": "\u8bc4\u4f307\u4e2aLLM\u6a21\u578b\uff08ChatGPT\u3001DeepSeek\u3001Gemini\u3001Grok\u3001Llama\u548cClaude\uff09\u5728\u4f4f\u5b85\u6539\u9020\u51b3\u7b56\u4e2d\u7684\u8868\u73b0\uff0c\u4f7f\u7528\u5305\u542b49\u4e2a\u5dde400\u4e2a\u4f4f\u5b85\u7684\u6570\u636e\u96c6\uff0c\u4ece\u51c6\u786e\u6027\u3001\u4e00\u81f4\u6027\u3001\u654f\u611f\u6027\u548c\u63a8\u7406\u56db\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "LLM\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\u80fd\u751f\u6210\u6709\u6548\u5efa\u8bae\uff0c\u672a\u7ecf\u5fae\u8c03\u60c5\u51b5\u4e0b\u8fbe\u523054.5%\u7684top1\u5339\u914d\u7387\u548c92.8%\u7684top5\u5339\u914d\u7387\u3002\u6280\u672f\u76ee\u6807\u8868\u73b0\u66f4\u5f3a\uff0c\u6a21\u578b\u95f4\u4e00\u81f4\u6027\u4f4e\uff0c\u5bf9\u4f4d\u7f6e\u548c\u5efa\u7b51\u51e0\u4f55\u5f62\u72b6\u654f\u611f\u4f46\u5bf9\u6280\u672f\u548c\u5c45\u4f4f\u8005\u884c\u4e3a\u4e0d\u654f\u611f\u3002", "conclusion": "LLM\u5728\u80fd\u6e90\u6539\u9020\u51b3\u7b56\u4e2d\u662f\u5f88\u6709\u524d\u666f\u7684\u52a9\u624b\uff0c\u4f46\u9700\u8981\u5728\u51c6\u786e\u6027\u3001\u4e00\u81f4\u6027\u548c\u4e0a\u4e0b\u6587\u5904\u7406\u65b9\u9762\u8fdb\u884c\u6539\u8fdb\u624d\u80fd\u53ef\u9760\u5e94\u7528\u4e8e\u5b9e\u8df5\u3002"}}
{"id": "2509.05883", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05883", "abs": "https://arxiv.org/abs/2509.05883", "authors": ["Andrew Yeo", "Daeseon Choi"], "title": "Multimodal Prompt Injection Attacks: Risks and Defenses for Modern LLMs", "comment": "8 pages, 4 figures, 2 tables", "summary": "Large Language Models (LLMs) have seen rapid adoption in recent years, with\nindustries increasingly relying on them to maintain a competitive advantage.\nThese models excel at interpreting user instructions and generating human-like\nresponses, leading to their integration across diverse domains, including\nconsulting and information retrieval. However, their widespread deployment also\nintroduces substantial security risks, most notably in the form of prompt\ninjection and jailbreak attacks.\n  To systematically evaluate LLM vulnerabilities -- particularly to external\nprompt injection -- we conducted a series of experiments on eight commercial\nmodels. Each model was tested without supplementary sanitization, relying\nsolely on its built-in safeguards. The results exposed exploitable weaknesses\nand emphasized the need for stronger security measures. Four categories of\nattacks were examined: direct injection, indirect (external) injection,\nimage-based injection, and prompt leakage. Comparative analysis indicated that\nClaude 3 demonstrated relatively greater robustness; nevertheless, empirical\nfindings confirm that additional defenses, such as input normalization, remain\nnecessary to achieve reliable protection.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u5bf9\u516b\u6b3e\u5546\u4e1a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b9e\u9a8c\u7814\u7a76\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5b83\u4eec\u5728\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u4e0b\u7684\u5f31\u70b9\uff0c\u53d1\u73b0\u6240\u6709\u6a21\u578b\u90fd\u5b58\u5728\u53ef\u5229\u7528\u7684\u6f0f\u6d1e\uff0c\u5e76\u5efa\u8bae\u91c7\u7528\u8f93\u5165\u6807\u51c6\u5316\u7b49\u989d\u5916\u9632\u5fa1\u63aa\u65bd\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5404\u884c\u4e1a\u7684\u5e7f\u6cdb\u90e8\u7f72\uff0c\u5b83\u4eec\u7684\u5b89\u5168\u98ce\u9669\u65e5\u76ca\u663e\u73b0\uff0c\u7279\u522b\u662f\u63d0\u793a\u6ce8\u5165\u548c\u8131\u72f1\u653b\u51fb\u3002\u8bba\u6587\u7684\u52a8\u673a\u662f\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30LLM\u5728\u5916\u90e8\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u4e0b\u7684\u6f0f\u6d1e\uff0c\u4ee5\u786e\u8ba4\u5b89\u5168\u98ce\u9669\u5e76\u63d0\u51fa\u9632\u5fa1\u5efa\u8bae\u3002", "method": "\u7814\u7a76\u8005\u5bf9\u516b\u6b3e\u5546\u4e1a\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e86\u4e00\u7cfb\u5217\u5b9e\u9a8c\uff0c\u5728\u6ca1\u6709\u989d\u5916\u6e05\u6d17\u63aa\u65bd\u7684\u60c5\u51b5\u4e0b\uff0c\u4ec5\u4f9d\u9760\u6a21\u578b\u5185\u7f6e\u7684\u5b89\u5168\u4fdd\u62a4\u673a\u5236\u8fdb\u884c\u6d4b\u8bd5\u3002\u5b9e\u9a8c\u5305\u62ec\u56db\u7c7b\u653b\u51fb\u65b9\u5f0f\uff1a\u76f4\u63a5\u6ce8\u5165\u3001\u95f4\u63a5\uff08\u5916\u90e8\uff09\u6ce8\u5165\u3001\u57fa\u4e8e\u56fe\u50cf\u7684\u6ce8\u5165\u4ee5\u53ca\u63d0\u793a\u6cc4\u6f0f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u6240\u6709\u6d4b\u8bd5\u6a21\u578b\u90fd\u5b58\u5728\u53ef\u5229\u7528\u7684\u5f31\u70b9\u3002\u5bf9\u6bd4\u5206\u6790\u8868\u660eClaude 3\u6a21\u578b\u663e\u793a\u51fa\u76f8\u5bf9\u66f4\u597d\u7684\u7a33\u5065\u6027\uff0c\u4f46\u4ecd\u7136\u5b58\u5728\u6f0f\u6d1e\u3002\u7814\u7a76\u8bc1\u5b9e\u4e86\u5f53\u524d\u6a21\u578b\u5185\u7f6e\u7684\u5b89\u5168\u4fdd\u62a4\u673a\u5236\u4e0d\u8db3\u4ee5\u62b5\u5fa1\u5916\u90e8\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u9762\u524d\u5b58\u5728\u663e\u8457\u7684\u5b89\u5168\u6f0f\u6d1e\u3002\u4e3a\u4e86\u5b9e\u73b0\u53ef\u9760\u7684\u4fdd\u62a4\uff0c\u5fc5\u987b\u91c7\u7528\u989d\u5916\u7684\u9632\u5fa1\u63aa\u65bd\uff0c\u4f8b\u5982\u8f93\u5165\u6807\u51c6\u5316\u6280\u672f\u3002\u8fd9\u9879\u7814\u7a76\u7a81\u51fa\u4e86\u5728\u90e8\u7f72LLM\u65f6\u52a0\u5f3a\u5b89\u5168\u63aa\u65bd\u7684\u7d27\u8feb\u6027\u3002"}}
{"id": "2509.06337", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06337", "abs": "https://arxiv.org/abs/2509.06337", "authors": ["Jianpeng Zhao", "Chenyu Yuan", "Weiming Luo", "Haoling Xie", "Guangwei Zhang", "Steven Jige Quan", "Zixuan Yuan", "Pengyang Wang", "Denghui Zhang"], "title": "Large Language Models as Virtual Survey Respondents: Evaluating Sociodemographic Response Generation", "comment": null, "summary": "Questionnaire-based surveys are foundational to social science research and\npublic policymaking, yet traditional survey methods remain costly,\ntime-consuming, and often limited in scale. This paper explores a new paradigm:\nsimulating virtual survey respondents using Large Language Models (LLMs). We\nintroduce two novel simulation settings, namely Partial Attribute Simulation\n(PAS) and Full Attribute Simulation (FAS), to systematically evaluate the\nability of LLMs to generate accurate and demographically coherent responses. In\nPAS, the model predicts missing attributes based on partial respondent\nprofiles, whereas FAS involves generating complete synthetic datasets under\nboth zero-context and context-enhanced conditions. We curate a comprehensive\nbenchmark suite, LLM-S^3 (Large Language Model-based Sociodemographic Survey\nSimulation), that spans 11 real-world public datasets across four sociological\ndomains. Our evaluation of multiple mainstream LLMs (GPT-3.5/4 Turbo, LLaMA\n3.0/3.1-8B) reveals consistent trends in prediction performance, highlights\nfailure modes, and demonstrates how context and prompt design impact simulation\nfidelity. This work establishes a rigorous foundation for LLM-driven survey\nsimulations, offering scalable and cost-effective tools for sociological\nresearch and policy evaluation. Our code and dataset are available at:\nhttps://github.com/dart-lab-research/LLM-S-Cube-Benchmark", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6a21\u62df\u865a\u62df\u95ee\u5377\u8c03\u67e5\u53d7\u8bbf\u8005\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u6a21\u62df\u65b9\u5f0f\uff0c\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u7efc\u5408\u6027\u8bc4\u6d4b\u5957\u4ef6\uff0c\u4e3a\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u6210\u672c\u6548\u76ca\u5de5\u5177\u3002", "motivation": "\u4f20\u7edf\u95ee\u5377\u8c03\u67e5\u65b9\u6cd5\u6210\u672c\u9ad8\u3001\u8017\u65f6\u957f\u4e14\u89c4\u6a21\u6709\u9650\uff0c\u9700\u8981\u5bfb\u627e\u66f4\u53ef\u6269\u5c55\u548c\u6210\u672c\u6548\u76ca\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u6a21\u62df\u8bbe\u7f6e\uff1a\u90e8\u5206\u5c5e\u6027\u6a21\u62df(PAS)\u548c\u5168\u5c5e\u6027\u6a21\u62df(FAS)\uff0c\u6784\u5efa\u4e86LLM-S^3\u8bc4\u6d4b\u5957\u4ef6\uff0c\u6db5\u76d611\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\uff0c\u5e76\u8bc4\u4f30\u591a\u4e2a\u4e3b\u6d41LLM\u6a21\u578b\u7684\u8868\u73b0\u3002", "result": "\u5bf9\u591a\u4e2a\u4e3b\u6d41LLM\u6a21\u578b\u7684\u8bc4\u4f30\u663e\u793a\u4e86\u4e00\u81f4\u7684\u9884\u6d4b\u6027\u80fd\u8d8b\u52bf\uff0c\u8bc6\u522b\u4e86\u5931\u8d25\u6a21\u5f0f\uff0c\u5e76\u8bc1\u660e\u4e0a\u4e0b\u6587\u548c\u63d0\u793a\u8bbe\u8ba1\u5bf9\u6a21\u62df\u4fdd\u771f\u5ea6\u7684\u5f71\u54cd\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3aLLM\u9a71\u52a8\u7684\u95ee\u5377\u8c03\u67e5\u6a21\u62df\u5efa\u7acb\u4e86\u4e25\u8c28\u7684\u57fa\u7840\uff0c\u4e3a\u793e\u4f1a\u5b66\u7814\u7a76\u548c\u653f\u7b56\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u6210\u672c\u6548\u76ca\u5de5\u5177\u3002"}}
{"id": "2509.05884", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2509.05884", "abs": "https://arxiv.org/abs/2509.05884", "authors": ["Banhirup Sengupta", "Peenal Gupta", "Souvik Sengupta"], "title": "Introduction to Number Theoretic Transform", "comment": null, "summary": "The Number Theoretic Transform (NTT) can be regarded as a variant of the\nDiscrete Fourier Transform. NTT has been quite a powerful mathematical tool in\ndeveloping Post-Quantum Cryptography and Homomorphic Encryption. The Fourier\nTransform essentially decomposes a signal into its frequencies. They are\ntraditionally sine or cosine waves. NTT works more over groups or finite fields\nrather than on a continuous signal and polynomials work as the analog of sine\nwaves in case of NTT. Fast Fourier Trnasform (FFT) style NTT or fast NTT has\nbeen proven to be useful in lattice-based cryptography due to its ability to\nreduce the complexity of polynomial multiplication from quadratic to\nquasilinear. We have introduced the concepts of cyclic, negacyclic convolutions\nalong with NTT and its inverse and their fast versions.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u6570\u8bba\u53d8\u6362(NTT)\u4f5c\u4e3a\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\u7684\u53d8\u4f53\uff0c\u5728\u683c\u5bc6\u7801\u5b66\u4e2d\u7528\u4e8e\u9ad8\u6548\u591a\u9879\u5f0f\u4e58\u6cd5\uff0c\u5c06\u590d\u6742\u5ea6\u4ece\u4e8c\u6b21\u964d\u4f4e\u5230\u62df\u7ebf\u6027", "motivation": "\u6570\u8bba\u53d8\u6362(NTT)\u5728\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\u548c\u540c\u6001\u52a0\u5bc6\u4e2d\u5177\u6709\u91cd\u8981\u4f5c\u7528\uff0c\u7279\u522b\u662f\u5728\u683c\u57fa\u5bc6\u7801\u5b66\u4e2d\u9700\u8981\u9ad8\u6548\u7684\u591a\u9879\u5f0f\u8fd0\u7b97", "method": "\u4ecb\u7ecd\u4e86\u5faa\u73af\u5377\u79ef\u3001\u8d1f\u5faa\u73af\u5377\u79ef\u3001NTT\u53ca\u5176\u9006\u53d8\u6362\u7684\u5feb\u901f\u7b97\u6cd5\uff0c\u91c7\u7528\u7c7b\u4f3c\u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362(FFT)\u7684\u65b9\u6cd5", "result": "\u5b9e\u73b0\u4e86\u591a\u9879\u5f0f\u4e58\u6cd5\u590d\u6742\u5ea6\u7684\u663e\u8457\u964d\u4f4e\uff0c\u4eceO(n\u00b2)\u964d\u4f4e\u5230O(n log n)\u7684\u62df\u7ebf\u6027\u590d\u6742\u5ea6", "conclusion": "\u5feb\u901fNTT\u7b97\u6cd5\u4e3a\u683c\u57fa\u5bc6\u7801\u5b66\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u6570\u5b66\u5de5\u5177\uff0c\u7279\u522b\u662f\u5728\u591a\u9879\u5f0f\u4e58\u6cd5\u8fd0\u7b97\u65b9\u9762\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c"}}
{"id": "2509.06341", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06341", "abs": "https://arxiv.org/abs/2509.06341", "authors": ["Issue Yishu Wang", "Kakam Chong", "Xiaofeng Wang", "Xu Yan", "DeXin Kong", "Chen Ju", "Ming Chen", "Shuai Xiao", "Shuguang Han", "jufeng chen"], "title": "Evaluating Multi-Turn Bargain Skills in LLM-Based Seller Agent", "comment": null, "summary": "In online second-hand marketplaces, multi-turn bargaining is a crucial part\nof seller-buyer interactions. Large Language Models (LLMs) can act as seller\nagents, negotiating with buyers on behalf of sellers under given business\nconstraints. A critical ability for such agents is to track and accurately\ninterpret cumulative buyer intents across long negotiations, which directly\nimpacts bargaining effectiveness. We introduce a multi-turn evaluation\nframework for measuring the bargaining ability of seller agents in e-commerce\ndialogues. The framework tests whether an agent can extract and track buyer\nintents. Our contributions are: (1) a large-scale e-commerce bargaining\nbenchmark spanning 622 categories, 9,892 products, and 3,014 tasks; (2) a\nturn-level evaluation framework grounded in Theory of Mind (ToM) with annotated\nbuyer intents, moving beyond outcome-only metrics; and (3) an automated\npipeline that extracts reliable intent from massive dialogue data.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5728\u7ebf\u4e8c\u624b\u5e02\u573a\u4e2d\u5356\u5bb6\u8c03\u89e3\u673a\u5668\u4eba\u591a\u8f6e\u8be6\u4ef7\u80fd\u529b\u7684\u6846\u67b6\uff0c\u91cd\u70b9\u8003\u5bdf\u673a\u5668\u4eba\u8ddf\u8e2a\u548c\u89e3\u91ca\u4e70\u5bb6\u610f\u56fe\u7684\u80fd\u529b\u3002", "motivation": "\u5728\u7ebf\u4e0a\u4e8c\u624b\u5e02\u573a\u4e2d\uff0c\u591a\u8f6e\u8be6\u4ef7\u662f\u5356\u5bb6\u4e0e\u4e70\u5bb6\u4ea4\u4e92\u7684\u5173\u952e\u73af\u8282\u3002\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u4f5c\u4e3a\u5356\u5bb6\u4ee3\u7406\u4e0e\u4e70\u5bb6\u8be6\u4ef7\uff0c\u8be6\u4ef7\u6548\u679c\u76f4\u63a5\u53d7\u5230\u673a\u5668\u4eba\u8ddf\u8e2a\u548c\u51c6\u786e\u89e3\u91ca\u957f\u671f\u8be6\u4ef7\u4e2d\u7d2f\u8ba1\u4e70\u5bb6\u610f\u56fe\u80fd\u529b\u7684\u5f71\u54cd\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u8f6e\u8bc4\u4f30\u6846\u67b6\uff1a(1) \u5927\u89c4\u6a21\u7535\u5b50\u5546\u52a1\u8be6\u4ef7\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff0c\u6db5\u76d6622\u4e2a\u7c7b\u522b\u30019,892\u4e2a\u4ea7\u54c1\u548c3,014\u4e2a\u4efb\u52a1\uff1b(2) \u57fa\u4e8e\u5fc3\u7406\u7406\u8bba(ToM)\u7684\u8f6e\u6b21\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u542b\u6807\u6ce8\u7684\u4e70\u5bb6\u610f\u56fe\uff0c\u8d85\u8d8a\u4ec5\u8003\u8651\u7ed3\u679c\u7684\u6307\u6807\uff1b(3) \u4ece\u5927\u91cf\u5bf9\u8bdd\u6570\u636e\u4e2d\u63d0\u53d6\u53ef\u9760\u610f\u56fe\u7684\u81ea\u52a8\u5316\u6d41\u7a0b\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u6d4b\u8bd5\u5356\u5bb6\u4ee3\u7406\u662f\u5426\u80fd\u591f\u63d0\u53d6\u548c\u8ddf\u8e2a\u4e70\u5bb6\u610f\u56fe\uff0c\u4e3a\u8be6\u4ef7\u673a\u5668\u4eba\u7684\u80fd\u529b\u8bc4\u4f30\u63d0\u4f9b\u4e86\u7efc\u5408\u6027\u7684\u6d4b\u91cf\u65b9\u6cd5\u3002", "conclusion": "\u8fd9\u4e2a\u7814\u7a76\u4e3a\u8bc4\u4f30\u7535\u5b50\u5546\u52a1\u8be6\u4ef7\u5bf9\u8bdd\u4e2d\u5356\u5bb6\u4ee3\u7406\u7684\u8be6\u4ef7\u80fd\u529b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u91cd\u8981\u7684\u591a\u8f6e\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u6d4b\u8bd5\u96c6\u3001\u57fa\u4e8e\u5fc3\u7406\u7406\u8bba\u7684\u8bc4\u4f30\u65b9\u6cd5\u548c\u81ea\u52a8\u5316\u610f\u56fe\u63d0\u53d6\u6d41\u7a0b\uff0c\u6709\u52a9\u4e8e\u66f4\u5168\u9762\u5730\u8bc4\u4f30\u673a\u5668\u4eba\u7684\u8be6\u4ef7\u6548\u679c\u3002"}}
{"id": "2509.05891", "categories": ["cs.CR", "cs.DB"], "pdf": "https://arxiv.org/pdf/2509.05891", "abs": "https://arxiv.org/abs/2509.05891", "authors": ["Mahfuzul I. Nissan"], "title": "MemTraceDB: Reconstructing MySQL User Activity Using ActiviTimeTrace Algorithm", "comment": null, "summary": "Database audit and transaction logs are fundamental to forensic\ninvestigations, but they are vulnerable to tampering by privileged attackers.\nMalicious insiders or external threats with administrative access can alter,\npurge, or temporarily disable logging mechanisms, creating significant blind\nspots and rendering disk-based records unreliable. Memory analysis offers a\nvital alternative, providing investigators direct access to volatile artifacts\nthat represent a ground-truth source of recent user activity, even when log\nfiles have been compromised.\n  This paper introduces MemTraceDB, a tool that reconstructs user activity\ntimelines by analyzing raw memory snapshots from the MySQL database process.\nMemTraceDB utilizes a novel algorithm, ActiviTimeTrace, to systematically\nextract and correlate forensic artifacts such as user connections and executed\nqueries. Through a series of experiments, I demonstrate MemTraceDB's\neffectiveness and reveal a critical empirical finding: the MySQL query stack\nhas a finite operational capacity of approximately 9,997 queries. This\ndiscovery allows me to establish a practical, data-driven formula for\ndetermining the optimal frequency for memory snapshot collection, providing a\nclear, actionable guideline for investigators. The result is a\nforensically-sound reconstruction of user activity, independent of compromised\ndisk-based logs.", "AI": {"tldr": "MemTraceDB\u662f\u4e00\u4e2a\u901a\u8fc7\u5206\u6790MySQL\u6570\u636e\u5e93\u8fdb\u7a0b\u5185\u5b58\u5feb\u7167\u6765\u91cd\u5efa\u7528\u6237\u6d3b\u52a8\u65f6\u95f4\u7ebf\u7684\u5de5\u5177\uff0c\u80fd\u591f\u7ed5\u8fc7\u88ab\u7be1\u6539\u7684\u78c1\u76d8\u65e5\u5fd7\uff0c\u63d0\u4f9b\u53ef\u9760\u7684\u53d6\u8bc1\u5206\u6790\u3002", "motivation": "\u6570\u636e\u5e93\u5ba1\u8ba1\u65e5\u5fd7\u548c\u4e8b\u52a1\u65e5\u5fd7\u5bb9\u6613\u53d7\u5230\u7279\u6743\u653b\u51fb\u8005\u7684\u7be1\u6539\uff0c\u5185\u5b58\u5206\u6790\u63d0\u4f9b\u4e86\u8bbf\u95ee\u6613\u5931\u6027\u8bc1\u636e\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5373\u4f7f\u65e5\u5fd7\u6587\u4ef6\u88ab\u7834\u574f\u4e5f\u80fd\u83b7\u53d6\u771f\u5b9e\u7528\u6237\u6d3b\u52a8\u4fe1\u606f\u3002", "method": "\u4f7f\u7528ActiviTimeTrace\u7b97\u6cd5\u4eceMySQL\u8fdb\u7a0b\u5185\u5b58\u5feb\u7167\u4e2d\u7cfb\u7edf\u63d0\u53d6\u548c\u5173\u8054\u53d6\u8bc1\u8bc1\u636e\uff0c\u5305\u62ec\u7528\u6237\u8fde\u63a5\u548c\u6267\u884c\u67e5\u8be2\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u786e\u5b9a\u6700\u4f73\u5185\u5b58\u5feb\u7167\u91c7\u96c6\u9891\u7387\u3002", "result": "\u53d1\u73b0MySQL\u67e5\u8be2\u5806\u6808\u5177\u6709\u7ea69,997\u6761\u67e5\u8be2\u7684\u6709\u9650\u64cd\u4f5c\u5bb9\u91cf\uff0c\u5efa\u7acb\u4e86\u6570\u636e\u9a71\u52a8\u7684\u516c\u5f0f\u6765\u786e\u5b9a\u6700\u4f73\u5185\u5b58\u5feb\u7167\u91c7\u96c6\u9891\u7387\uff0c\u5b9e\u73b0\u4e86\u72ec\u7acb\u4e8e\u53d7\u635f\u78c1\u76d8\u65e5\u5fd7\u7684\u53d6\u8bc1\u91cd\u5efa\u3002", "conclusion": "MemTraceDB\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u9760\u7684\u65b9\u6cd5\u6765\u91cd\u5efa\u7528\u6237\u6d3b\u52a8\u65f6\u95f4\u7ebf\uff0c\u5373\u4f7f\u5728\u78c1\u76d8\u65e5\u5fd7\u88ab\u7be1\u6539\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u8fdb\u884c\u6709\u6548\u7684\u53d6\u8bc1\u8c03\u67e5\uff0c\u4e3a\u6570\u636e\u5e93\u53d6\u8bc1\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2509.06355", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.06355", "abs": "https://arxiv.org/abs/2509.06355", "authors": ["Yunzhe Wang", "Volkan Ustun", "Chris McGroarty"], "title": "A data-driven discretized CS:GO simulation environment to facilitate strategic multi-agent planning research", "comment": "Accepted at the Winter Simulation Conference 2025, December, Seattle\n  USA", "summary": "Modern simulation environments for complex multi-agent interactions must\nbalance high-fidelity detail with computational efficiency. We present DECOY, a\nnovel multi-agent simulator that abstracts strategic, long-horizon planning in\n3D terrains into high-level discretized simulation while preserving low-level\nenvironmental fidelity. Using Counter-Strike: Global Offensive (CS:GO) as a\ntestbed, our framework accurately simulates gameplay using only movement\ndecisions as tactical positioning -- without explicitly modeling low-level\nmechanics such as aiming and shooting. Central to our approach is a waypoint\nsystem that simplifies and discretizes continuous states and actions, paired\nwith neural predictive and generative models trained on real CS:GO tournament\ndata to reconstruct event outcomes. Extensive evaluations show that replays\ngenerated from human data in DECOY closely match those observed in the original\ngame. Our publicly available simulation environment provides a valuable tool\nfor advancing research in strategic multi-agent planning and behavior\ngeneration.", "AI": {"tldr": "DECOY\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u591a\u667a\u80fd\u4f53\u6a21\u62df\u5668\uff0c\u901a\u8fc7\u5c063D\u5730\u5f62\u4e2d\u7684\u6218\u7565\u957f\u671f\u89c4\u5212\u62bd\u8c61\u4e3a\u9ad8\u7ea7\u79bb\u6563\u5316\u6a21\u62df\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u5c42\u6b21\u73af\u5883\u4fdd\u771f\u5ea6\uff0c\u5728\u8ba1\u7b97\u6548\u7387\u548c\u771f\u5b9e\u6027\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002", "motivation": "\u73b0\u4ee3\u590d\u6742\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\u6a21\u62df\u73af\u5883\u9700\u8981\u5728\u9ad8\u5ea6\u7ec6\u8282\u4fdd\u771f\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002\u73b0\u6709\u7684\u6a21\u62df\u5668\u5f80\u5f80\u8981\u4e48\u8fc7\u4e8e\u7b80\u5316\u5931\u53bb\u771f\u5b9e\u6027\uff0c\u8981\u4e48\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\u96be\u4ee5\u8fdb\u884c\u5927\u89c4\u6a21\u7814\u7a76\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u8def\u5f84\u70b9\u7684\u7cfb\u7edf\u7b80\u5316\u548c\u79bb\u6563\u5316\u8fde\u7eed\u72b6\u6001\u548c\u52a8\u4f5c\uff0c\u914d\u5408\u57fa\u4e8e\u771f\u5b9eCS:GO\u6bd4\u8d5b\u6570\u636e\u8bad\u7ec3\u7684\u795e\u7ecf\u9884\u6d4b\u548c\u751f\u6210\u6a21\u578b\u6765\u91cd\u5efa\u4e8b\u4ef6\u7ed3\u679c\u3002\u4ec5\u4f7f\u7528\u79fb\u52a8\u51b3\u7b56\u4f5c\u4e3a\u6218\u672f\u5b9a\u4f4d\uff0c\u65e0\u9700\u663e\u5f0f\u5efa\u6a21\u7784\u51c6\u548c\u5c04\u51fb\u7b49\u4f4e\u5c42\u6b21\u673a\u5236\u3002", "result": "\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0c\u4ece\u4eba\u7c7b\u6570\u636e\u751f\u6210\u7684DECOY\u56de\u653e\u4e0e\u539f\u59cb\u6e38\u620f\u4e2d\u89c2\u5bdf\u5230\u7684\u56de\u653e\u975e\u5e38\u63a5\u8fd1\u3002\u6a21\u62df\u73af\u5883\u80fd\u591f\u51c6\u786e\u6a21\u62df\u6e38\u620f\u73a9\u6cd5\u3002", "conclusion": "DECOY\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u4ef7\u503c\u7684\u5de5\u5177\uff0c\u53ef\u7528\u4e8e\u63a8\u8fdb\u6218\u7565\u591a\u667a\u80fd\u4f53\u89c4\u5212\u548c\u884c\u4e3a\u751f\u6210\u7684\u7814\u7a76\uff0c\u4e3a\u590d\u6742\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u4fdd\u771f\u7684\u6a21\u62df\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.05893", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.05893", "abs": "https://arxiv.org/abs/2509.05893", "authors": ["Colin Roberts", "Vivek Nair", "Dawn Song"], "title": "Wrangling Entropy: Next-Generation Multi-Factor Key Derivation, Credential Hashing, and Credential Generation Functions", "comment": "Work in progress. Learn more about MFKDF at https://mfkdf.com and\n  Multifactor at https://multifactor.com", "summary": "The Multi-Factor Key Derivation Function (MFKDF) offered a novel solution to\nthe classic problem of usable client-side key management by incorporating\nmultiple popular authentication factors into a key derivation process, but was\nlater shown to be vulnerable to cryptanalysis that degraded its security over\nmultiple invocations. In this paper, we present the Entropy State Transition\nModeling Framework (ESTMF), a novel cryptanalytic technique designed to reveal\npernicious leaks of entropy across multiple invocations of a cryptographic key\nderivation or hash function, and show that it can be used to correctly identify\neach of the known vulnerabilities in the original MFKDF construction. We then\nuse these findings to propose a new construction for ``MFKDF2,'' a\nnext-generation multi-factor key derivation function that can be proven to be\nend-to-end secure using the ESTMF. Finally, we discuss how MFKDF2 can be\nextended to support more authentication factors and usability features than the\nprevious MFKDF construction, and derive several generalizable best-practices\nfor the construction of new KDFs in the future.", "AI": {"tldr": "\u63d0\u51fa\u4e86ESTMF\u5bc6\u7801\u5206\u6790\u6846\u67b6\u6765\u68c0\u6d4b\u591a\u56e0\u5b50\u5bc6\u94a5\u6d3e\u751f\u51fd\u6570\u4e2d\u7684\u71b5\u6cc4\u9732\u6f0f\u6d1e\uff0c\u5e76\u57fa\u4e8e\u6b64\u6784\u5efa\u4e86\u66f4\u5b89\u5168\u7684MFKDF2\u65b9\u6848", "motivation": "\u539f\u59cbMFKDF\u65b9\u6848\u5728\u591a\u8f6e\u8c03\u7528\u4e2d\u5b58\u5728\u5b89\u5168\u6027\u9000\u5316\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u5206\u6790\u6846\u67b6\u6765\u8bc6\u522b\u548c\u4fee\u590d\u8fd9\u4e9b\u6f0f\u6d1e", "method": "\u5f00\u53d1\u4e86\u71b5\u72b6\u6001\u8f6c\u79fb\u5efa\u6a21\u6846\u67b6(ESTMF)\u6765\u68c0\u6d4b\u5bc6\u7801\u5b66\u51fd\u6570\u4e2d\u7684\u71b5\u6cc4\u9732\uff0c\u5e76\u57fa\u4e8e\u5206\u6790\u7ed3\u679c\u8bbe\u8ba1\u4e86MFKDF2\u65b0\u6784\u9020", "result": "ESTMF\u6210\u529f\u8bc6\u522b\u4e86\u539f\u59cbMFKDF\u7684\u6240\u6709\u5df2\u77e5\u6f0f\u6d1e\uff0cMFKDF2\u88ab\u8bc1\u660e\u5177\u6709\u7aef\u5230\u7aef\u5b89\u5168\u6027", "conclusion": "MFKDF2\u652f\u6301\u66f4\u591a\u8ba4\u8bc1\u56e0\u5b50\u548c\u53ef\u7528\u6027\u7279\u6027\uff0c\u4e3a\u672a\u6765KDF\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u53ef\u63a8\u5e7f\u7684\u6700\u4f73\u5b9e\u8df5"}}
{"id": "2509.06409", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06409", "abs": "https://arxiv.org/abs/2509.06409", "authors": ["Yihong Luo", "Wenwu He", "Zhuo-Xu Cui", "Dong Liang"], "title": "Teaching AI Stepwise Diagnostic Reasoning with Report-Guided Chain-of-Thought Learning", "comment": null, "summary": "This study presents DiagCoT, a multi-stage framework that applies supervised\nfine-tuning to general-purpose vision-language models (VLMs) to emulate\nradiologists' stepwise diagnostic reasoning using only free-text reports.\nDiagCoT combines contrastive image-report tuning for domain alignment,\nchain-of-thought supervision to capture inferential logic, and reinforcement\ntuning with clinical reward signals to enhance factual accuracy and fluency. On\nthe MIMIC-CXR benchmark, DiagCoT improved zero-shot disease classification AUC\nfrom 0.52 to 0.76 (absolute gain of 0.24), pathology grounding mIoU from 0.08\nto 0.31 (absolute gain of 0.23), and report generation BLEU from 0.11 to 0.33\n(absolute gain of 0.22). It outperformed state-of-the-art models including\nLLaVA-Med and CXR-LLAVA on long-tailed diseases and external datasets. By\nconverting unstructured clinical narratives into structured supervision,\nDiagCoT offers a scalable approach for developing interpretable and\ndiagnostically competent AI systems for radiology.", "AI": {"tldr": "DiagCoT\u662f\u4e00\u4e2a\u591a\u9636\u6bb5\u6846\u67b6\uff0c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u901a\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u4ec5\u4f7f\u7528\u81ea\u7531\u6587\u672c\u62a5\u544a\u6a21\u62df\u653e\u5c04\u79d1\u533b\u751f\u7684\u9010\u6b65\u8bca\u65ad\u63a8\u7406\uff0c\u5728\u75be\u75c5\u5206\u7c7b\u3001\u75c5\u7406\u5b9a\u4f4d\u548c\u62a5\u544a\u751f\u6210\u65b9\u9762\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5f00\u53d1\u53ef\u89e3\u91ca\u4e14\u5177\u6709\u8bca\u65ad\u80fd\u529b\u7684AI\u7cfb\u7edf\uff0c\u901a\u8fc7\u5229\u7528\u975e\u7ed3\u6784\u5316\u4e34\u5e8a\u53d9\u8ff0\u6765\u6a21\u62df\u653e\u5c04\u79d1\u533b\u751f\u7684\u9010\u6b65\u63a8\u7406\u8fc7\u7a0b\uff0c\u89e3\u51b3\u73b0\u6709\u6a21\u578b\u5728\u8bca\u65ad\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "method": "\u7ed3\u5408\u5bf9\u6bd4\u56fe\u50cf-\u62a5\u544a\u8c03\u4f18\u8fdb\u884c\u9886\u57df\u5bf9\u9f50\uff0c\u4f7f\u7528\u601d\u7ef4\u94fe\u76d1\u7763\u6355\u6349\u63a8\u7406\u903b\u8f91\uff0c\u5e76\u901a\u8fc7\u4e34\u5e8a\u5956\u52b1\u4fe1\u53f7\u8fdb\u884c\u5f3a\u5316\u8c03\u4f18\u4ee5\u63d0\u9ad8\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u6d41\u7545\u6027\u3002", "result": "\u5728MIMIC-CXR\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u96f6\u6837\u672c\u75be\u75c5\u5206\u7c7bAUC\u4ece0.52\u63d0\u5347\u81f30.76\uff08\u7edd\u5bf9\u589e\u76ca0.24\uff09\uff0c\u75c5\u7406\u5b9a\u4f4dmIoU\u4ece0.08\u63d0\u5347\u81f30.31\uff08\u7edd\u5bf9\u589e\u76ca0.23\uff09\uff0c\u62a5\u544a\u751f\u6210BLEU\u4ece0.11\u63d0\u5347\u81f30.33\uff08\u7edd\u5bf9\u589e\u76ca0.22\uff09\uff0c\u5728\u957f\u5c3e\u75be\u75c5\u548c\u5916\u90e8\u6570\u636e\u96c6\u4e0a\u4f18\u4e8eLLaVA-Med\u548cCXR-LLAVA\u7b49\u6700\u5148\u8fdb\u6a21\u578b\u3002", "conclusion": "DiagCoT\u901a\u8fc7\u5c06\u975e\u7ed3\u6784\u5316\u4e34\u5e8a\u53d9\u8ff0\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u76d1\u7763\uff0c\u4e3a\u5f00\u53d1\u53ef\u89e3\u91ca\u4e14\u5177\u6709\u8bca\u65ad\u80fd\u529b\u7684\u653e\u5c04\u5b66AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u3002"}}
{"id": "2509.05921", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.05921", "abs": "https://arxiv.org/abs/2509.05921", "authors": ["Kun Li", "Cheng Wang", "Minghui Xu", "Yue Zhang", "Xiuzhen Cheng"], "title": "Dataset Ownership in the Era of Large Language Models", "comment": "15 pages, 1 table, accepted by the 2025 International Conference on\n  Blockchain and Web3.0 Technology Innovation and Application Exchange (BWTAC)", "summary": "As datasets become critical assets in modern machine learning systems,\nensuring robust copyright protection has emerged as an urgent challenge.\nTraditional legal mechanisms often fail to address the technical complexities\nof digital data replication and unauthorized use, particularly in opaque or\ndecentralized environments. This survey provides a comprehensive review of\ntechnical approaches for dataset copyright protection, systematically\ncategorizing them into three main classes: non-intrusive methods, which detect\nunauthorized use without modifying data; minimally-intrusive methods, which\nembed lightweight, reversible changes to enable ownership verification; and\nmaximally-intrusive methods, which apply aggressive data alterations, such as\nreversible adversarial examples, to enforce usage restrictions. We synthesize\nkey techniques, analyze their strengths and limitations, and highlight open\nresearch challenges. This work offers an organized perspective on the current\nlandscape and suggests future directions for developing unified, scalable, and\nethically sound solutions to protect datasets in increasingly complex machine\nlearning ecosystems.", "AI": {"tldr": "\u6570\u636e\u96c6\u7248\u6743\u6280\u672f\u4fdd\u62a4\u65b9\u6cd5\u7efc\u8ff0\uff0c\u5206\u4e3a\u975e\u4fb5\u5165\u5f0f\u3001\u8f7b\u91cf\u4fb5\u5165\u5f0f\u548c\u91cd\u5ea6\u4fb5\u5165\u5f0f\u4e09\u7c7b\u65b9\u6cd5\uff0c\u5206\u6790\u5404\u81ea\u4f18\u7f3a\u70b9\u548c\u7814\u7a76\u6311\u6218", "motivation": "\u968f\u7740\u6570\u636e\u96c6\u6210\u4e3a\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u7684\u5173\u952e\u8d44\u4ea7\uff0c\u4f20\u7edf\u6cd5\u5f8b\u673a\u5236\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u6570\u5b57\u6570\u636e\u590d\u5236\u548c\u672a\u6388\u6743\u4f7f\u7528\u7684\u6280\u672f\u590d\u6742\u6027", "method": "\u7cfb\u7edf\u6027\u7efc\u8ff0\u6570\u636e\u96c6\u7248\u6743\u4fdd\u62a4\u6280\u672f\u65b9\u6cd5\uff0c\u5c06\u5176\u5206\u4e3a\u4e09\u7c7b\uff1a\u975e\u4fb5\u5165\u5f0f\u65b9\u6cd5\uff08\u4e0d\u4fee\u6539\u6570\u636e\u68c0\u6d4b\u672a\u6388\u6743\u4f7f\u7528\uff09\u3001\u8f7b\u91cf\u4fb5\u5165\u5f0f\u65b9\u6cd5\uff08\u5d4c\u5165\u53ef\u9006\u53d8\u66f4\u4ee5\u652f\u6301\u6240\u6709\u6743\u9a8c\u8bc1\uff09\u3001\u91cd\u5ea6\u4fb5\u5165\u5f0f\u65b9\u6cd5\uff08\u4f7f\u7528\u53ef\u9006\u5bf9\u6297\u793a\u4f8b\u7b49\u7fa4\u654f\u6570\u636e\u4fee\u6539\u6765\u5f3a\u5236\u4f7f\u7528\u9650\u5236\uff09", "result": "\u7ed3\u5408\u4e86\u5173\u952e\u6280\u672f\uff0c\u5206\u6790\u4e86\u5404\u79cd\u65b9\u6cd5\u7684\u4f18\u52bf\u548c\u5c40\u9650\u6027\uff0c\u6307\u51fa\u4e86\u5f53\u524d\u7684\u7814\u7a76\u6311\u6218", "conclusion": "\u672c\u6587\u63d0\u4f9b\u4e86\u6570\u636e\u96c6\u7248\u6743\u4fdd\u62a4\u9886\u57df\u7684\u7ec4\u7ec7\u5316\u89c6\u89d2\uff0c\u5e76\u4e3a\u5f00\u53d1\u7edf\u4e00\u3001\u53ef\u6269\u5c55\u4e14\u7b26\u5408\u9053\u5fb7\u6807\u51c6\u7684\u89e3\u51b3\u65b9\u6848\u6307\u660e\u4e86\u672a\u6765\u65b9\u5411"}}
{"id": "2509.06436", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06436", "abs": "https://arxiv.org/abs/2509.06436", "authors": ["Song Yu", "Xiaofei Xu", "Ke Deng", "Li Li", "Lin Tian"], "title": "Tree of Agents: Improving Long-Context Capabilities of Large Language Models through Multi-Perspective Reasoning", "comment": "19 pages, 5 figures", "summary": "Large language models (LLMs) face persistent challenges when handling\nlong-context tasks, most notably the lost in the middle issue, where\ninformation located in the middle of a long input tends to be underutilized.\nSome existing methods that reduce input have the risk of discarding key\ninformation, while others that extend context windows often lead to attention\ndispersion. To address these limitations, we propose Tree of Agents (TOA), a\nmulti-agent reasoning framework that segments the input into chunks processed\nby independent agents. Each agent generates its local cognition, then agents\ndynamically exchange information for collaborative reasoning along\ntree-structured paths. TOA enables agents to probe different reasoning orders\nfor multi-perspective understanding, effectively mitigating position bias and\nreducing hallucinations. To improve processing efficiency, we incorporate\nprefix-hash caching and adaptive pruning strategies, achieving significant\nperformance improvements with comparable API overhead. Experiments show that\nTOA, powered by compact LLaMA3.1-8B, significantly outperforms multiple\nbaselines and demonstrates comparable performance to the latest and much larger\ncommercial models, such as Gemini1.5-pro, on various long-context tasks. Code\nis available at https://github.com/Aireduce952/Tree-of-Agents.", "AI": {"tldr": "\u63d0\u51fa\u4e86Tree of Agents (TOA)\u591a\u667a\u80fd\u4f53\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u957f\u8f93\u5165\u5206\u6bb5\u5904\u7406\u3001\u52a8\u6001\u4fe1\u606f\u4ea4\u6362\u548c\u6811\u72b6\u7ed3\u6784\u534f\u4f5c\uff0c\u6709\u6548\u89e3\u51b3LLM\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u4e2d\u7684\"\u4e2d\u95f4\u4fe1\u606f\u4e22\u5931\"\u95ee\u9898\uff0c\u5728\u4fdd\u6301API\u5f00\u9500\u76f8\u8fd1\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u65f6\u7684\u6838\u5fc3\u6311\u6218\uff1a\u4e2d\u95f4\u4fe1\u606f\u5229\u7528\u4e0d\u8db3\uff08lost in the middle\u95ee\u9898\uff09\uff0c\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u53ef\u80fd\u4e22\u5f03\u5173\u952e\u4fe1\u606f\uff0c\u8981\u4e48\u5bfc\u81f4\u6ce8\u610f\u529b\u5206\u6563\u3002", "method": "TOA\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff1a\u5c06\u8f93\u5165\u5206\u6bb5\u7531\u72ec\u7acb\u667a\u80fd\u4f53\u5904\u7406\uff0c\u751f\u6210\u5c40\u90e8\u8ba4\u77e5\uff1b\u667a\u80fd\u4f53\u6cbf\u6811\u72b6\u8def\u5f84\u52a8\u6001\u4ea4\u6362\u4fe1\u606f\u8fdb\u884c\u534f\u4f5c\u63a8\u7406\uff1b\u7ed3\u5408\u524d\u7f00\u54c8\u5e0c\u7f13\u5b58\u548c\u81ea\u9002\u5e94\u526a\u679d\u7b56\u7565\u63d0\u9ad8\u6548\u7387\u3002", "result": "\u57fa\u4e8eLLaMA3.1-8B\u7684TOA\u5728\u591a\u79cd\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u4e0a\u663e\u8457\u8d85\u8d8a\u591a\u4e2a\u57fa\u7ebf\u6a21\u578b\uff0c\u6027\u80fd\u4e0e\u6700\u65b0\u7684\u5927\u578b\u5546\u4e1a\u6a21\u578b\uff08\u5982Gemini1.5-pro\uff09\u76f8\u5f53\u3002", "conclusion": "TOA\u6846\u67b6\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6709\u6548\u7f13\u89e3\u4f4d\u7f6e\u504f\u89c1\u548c\u5e7b\u89c9\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u6548\u7387\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u80fd\u529b\uff0c\u4e3aLLM\u957f\u6587\u672c\u7406\u89e3\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.06026", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.06026", "abs": "https://arxiv.org/abs/2509.06026", "authors": ["Xinyu Gao", "Xiangtao Meng", "Yingkai Dong", "Zheng Li", "Shanqing Guo"], "title": "DCMI: A Differential Calibration Membership Inference Attack Against Retrieval-Augmented Generation", "comment": null, "summary": "While Retrieval-Augmented Generation (RAG) effectively reduces hallucinations\nby integrating external knowledge bases, it introduces vulnerabilities to\nmembership inference attacks (MIAs), particularly in systems handling sensitive\ndata. Existing MIAs targeting RAG's external databases often rely on model\nresponses but ignore the interference of non-member-retrieved documents on RAG\noutputs, limiting their effectiveness. To address this, we propose DCMI, a\ndifferential calibration MIA that mitigates the negative impact of\nnon-member-retrieved documents. Specifically, DCMI leverages the sensitivity\ngap between member and non-member retrieved documents under query perturbation.\nIt generates perturbed queries for calibration to isolate the contribution of\nmember-retrieved documents while minimizing the interference from\nnon-member-retrieved documents. Experiments under progressively relaxed\nassumptions show that DCMI consistently outperforms baselines--for example,\nachieving 97.42% AUC and 94.35% Accuracy against the RAG system with Flan-T5,\nexceeding the MBA baseline by over 40%. Furthermore, on real-world RAG\nplatforms such as Dify and MaxKB, DCMI maintains a 10%-20% advantage over the\nbaseline. These results highlight significant privacy risks in RAG systems and\nemphasize the need for stronger protection mechanisms. We appeal to the\ncommunity's consideration of deeper investigations, like ours, against the data\nleakage risks in rapidly evolving RAG systems. Our code is available at\nhttps://github.com/Xinyu140203/RAG_MIA.", "AI": {"tldr": "DCMI\u662f\u4e00\u79cd\u9488\u5bf9RAG\u7cfb\u7edf\u7684\u5dee\u5206\u6821\u51c6\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u67e5\u8be2\u6270\u52a8\u6765\u533a\u5206\u6210\u5458\u548c\u975e\u6210\u5458\u68c0\u7d22\u6587\u6863\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u653b\u51fb\u6548\u679c\uff0c\u5728\u591a\u4e2aRAG\u5e73\u53f0\u4e0a\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u63d0\u534710-40%\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\u5ffd\u7565\u975e\u6210\u5458\u68c0\u7d22\u6587\u6863\u5bf9RAG\u8f93\u51fa\u7684\u5e72\u6270\uff0c\u9650\u5236\u4e86\u653b\u51fb\u6548\u679c\u3002RAG\u7cfb\u7edf\u5728\u5904\u7406\u654f\u611f\u6570\u636e\u65f6\u5b58\u5728\u9690\u79c1\u6cc4\u9732\u98ce\u9669\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u653b\u51fb\u65b9\u6cd5\u6765\u63ed\u793a\u8fd9\u4e9b\u6f0f\u6d1e\u3002", "method": "\u63d0\u51faDCMI\u65b9\u6cd5\uff0c\u5229\u7528\u67e5\u8be2\u6270\u52a8\u4e0b\u6210\u5458\u548c\u975e\u6210\u5458\u68c0\u7d22\u6587\u6863\u7684\u654f\u611f\u6027\u5dee\u5f02\uff0c\u751f\u6210\u6270\u52a8\u67e5\u8be2\u8fdb\u884c\u6821\u51c6\uff0c\u9694\u79bb\u6210\u5458\u68c0\u7d22\u6587\u6863\u7684\u8d21\u732e\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u975e\u6210\u5458\u68c0\u7d22\u6587\u6863\u7684\u5e72\u6270\u3002", "result": "\u5728\u9010\u6b65\u653e\u5bbd\u5047\u8bbe\u7684\u5b9e\u9a8c\u6761\u4ef6\u4e0b\uff0cDCMI\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4f8b\u5982\u5728Flan-T5 RAG\u7cfb\u7edf\u4e0a\u8fbe\u523097.42% AUC\u548c94.35%\u51c6\u786e\u7387\uff0c\u6bd4MBA\u57fa\u7ebf\u63d0\u9ad840%\u4ee5\u4e0a\u3002\u5728\u771f\u5b9eRAG\u5e73\u53f0Dify\u548cMaxKB\u4e0a\u4fdd\u630110-20%\u7684\u4f18\u52bf\u3002", "conclusion": "RAG\u7cfb\u7edf\u5b58\u5728\u663e\u8457\u7684\u9690\u79c1\u98ce\u9669\uff0c\u9700\u8981\u66f4\u5f3a\u7684\u4fdd\u62a4\u673a\u5236\u3002\u547c\u5401\u793e\u533a\u5bf9\u5feb\u901f\u53d1\u5c55\u7684RAG\u7cfb\u7edf\u4e2d\u7684\u6570\u636e\u6cc4\u9732\u98ce\u9669\u8fdb\u884c\u66f4\u6df1\u5165\u7684\u7814\u7a76\u3002"}}
{"id": "2509.06444", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06444", "abs": "https://arxiv.org/abs/2509.06444", "authors": ["Cheng Qian", "Hainan Zhang", "Yongxin Tong", "Hong-Wei Zheng", "Zhiming Zheng"], "title": "HyFedRAG: A Federated Retrieval-Augmented Generation Framework for Heterogeneous and Privacy-Sensitive Data", "comment": "9 pages, 7 figures", "summary": "Centralized RAG pipelines struggle with heterogeneous and privacy-sensitive\ndata, especially in distributed healthcare settings where patient data spans\nSQL, knowledge graphs, and clinical notes. Clinicians face difficulties\nretrieving rare disease cases due to privacy constraints and the limitations of\ntraditional cloud-based RAG systems in handling diverse formats and edge\ndevices. To address this, we introduce HyFedRAG, a unified and efficient\nFederated RAG framework tailored for Hybrid data modalities. By leveraging an\nedge-cloud collaborative mechanism, HyFedRAG enables RAG to operate across\ndiverse data sources while preserving data privacy. Our key contributions are:\n(1) We design an edge-cloud collaborative RAG framework built on Flower, which\nsupports querying structured SQL data, semi-structured knowledge graphs, and\nunstructured documents. The edge-side LLMs convert diverse data into\nstandardized privacy-preserving representations, and the server-side LLMs\nintegrates them for global reasoning and generation. (2) We integrate\nlightweight local retrievers with privacy-aware LLMs and provide three\nanonymization tools that enable each client to produce semantically rich,\nde-identified summaries for global inference across devices. (3) To optimize\nresponse latency and reduce redundant computation, we design a three-tier\ncaching strategy consisting of local cache, intermediate representation cache,\nand cloud inference cache. Experimental results on PMC-Patients demonstrate\nthat HyFedRAG outperforms existing baselines in terms of retrieval quality,\ngeneration consistency, and system efficiency. Our framework offers a scalable\nand privacy-compliant solution for RAG over structural-heterogeneous data,\nunlocking the potential of LLMs in sensitive and diverse data environments.", "AI": {"tldr": "HyFedRAG\u662f\u4e00\u4e2a\u9762\u5411\u6df7\u5408\u6570\u636e\u6a21\u6001\u7684\u8054\u90a6RAG\u6846\u67b6\uff0c\u901a\u8fc7\u8fb9\u7f18-\u4e91\u534f\u4f5c\u673a\u5236\u5728\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u7684\u540c\u65f6\u5904\u7406\u5f02\u6784\u533b\u7597\u6570\u636e\uff0c\u5305\u62ecSQL\u3001\u77e5\u8bc6\u56fe\u8c31\u548c\u4e34\u5e8a\u6587\u6863\u3002", "motivation": "\u96c6\u4e2d\u5f0fRAG\u7cfb\u7edf\u5728\u5904\u7406\u5f02\u6784\u548c\u9690\u79c1\u654f\u611f\u7684\u5206\u5e03\u5f0f\u533b\u7597\u6570\u636e\u65f6\u9762\u4e34\u56f0\u96be\uff0c\u7279\u522b\u662f\u5728\u67e5\u8be2\u7f55\u89c1\u75c5\u6848\u4f8b\u65f6\u53d7\u5230\u9690\u79c1\u7ea6\u675f\u548c\u4f20\u7edf\u4e91\u7cfb\u7edf\u5904\u7406\u591a\u6837\u5316\u683c\u5f0f\u80fd\u529b\u7684\u9650\u5236\u3002", "method": "\u57fa\u4e8eFlower\u8bbe\u8ba1\u8fb9\u7f18-\u4e91\u534f\u4f5cRAG\u6846\u67b6\uff0c\u8fb9\u7f18LLM\u5c06\u591a\u6837\u5316\u6570\u636e\u8f6c\u6362\u4e3a\u6807\u51c6\u5316\u9690\u79c1\u4fdd\u62a4\u8868\u793a\uff0c\u4e91\u7aefLLM\u8fdb\u884c\u5168\u5c40\u63a8\u7406\uff1b\u96c6\u6210\u8f7b\u91cf\u7ea7\u672c\u5730\u68c0\u7d22\u5668\u548c\u9690\u79c1\u611f\u77e5LLM\uff0c\u63d0\u4f9b\u4e09\u79cd\u533f\u540d\u5316\u5de5\u5177\uff1b\u8bbe\u8ba1\u4e09\u7ea7\u7f13\u5b58\u7b56\u7565\u4f18\u5316\u5ef6\u8fdf\u3002", "result": "\u5728PMC-Patients\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHyFedRAG\u5728\u68c0\u7d22\u8d28\u91cf\u3001\u751f\u6210\u4e00\u81f4\u6027\u548c\u7cfb\u7edf\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7ed3\u6784\u5316\u5f02\u6784\u6570\u636e\u4e0a\u7684RAG\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u9690\u79c1\u5408\u89c4\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u654f\u611f\u548c\u591a\u6837\u5316\u6570\u636e\u73af\u5883\u4e2d\u91ca\u653e\u4e86LLMs\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.06071", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.06071", "abs": "https://arxiv.org/abs/2509.06071", "authors": ["Yang Lou", "Haibo Hu", "Qun Song", "Qian Xu", "Yi Zhu", "Rui Tan", "Wei-Bin Lee", "Jianping Wang"], "title": "Asymmetry Vulnerability and Physical Attacks on Online Map Construction for Autonomous Driving", "comment": "CCS'25 (a shorter version of this paper will appear in the conference\n  proceeding)", "summary": "High-definition maps provide precise environmental information essential for\nprediction and planning in autonomous driving systems. Due to the high cost of\nlabeling and maintenance, recent research has turned to online HD map\nconstruction using onboard sensor data, offering wider coverage and more timely\nupdates for autonomous vehicles. However, the robustness of online map\nconstruction under adversarial conditions remains underexplored. In this paper,\nwe present a systematic vulnerability analysis of online map construction\nmodels, which reveals that these models exhibit an inherent bias toward\npredicting symmetric road structures. In asymmetric scenes like forks or\nmerges, this bias often causes the model to mistakenly predict a straight\nboundary that mirrors the opposite side. We demonstrate that this vulnerability\npersists in the real-world and can be reliably triggered by obstruction or\ntargeted interference. Leveraging this vulnerability, we propose a novel\ntwo-stage attack framework capable of manipulating online constructed maps.\nFirst, our method identifies vulnerable asymmetric scenes along the victim AV's\npotential route. Then, we optimize the location and pattern of camera-blinding\nattacks and adversarial patch attacks. Evaluations on a public AD dataset\ndemonstrate that our attacks can degrade mapping accuracy by up to 9.9%, render\nup to 44% of targeted routes unreachable, and increase unsafe planned\ntrajectory rates, colliding with real-world road boundaries, by up to 27%.\nThese attacks are also validated on a real-world testbed vehicle. We further\nanalyze root causes of the symmetry bias, attributing them to training data\nimbalance, model architecture, and map element representation. To the best of\nour knowledge, this study presents the first vulnerability assessment of online\nmap construction models and introduces the first digital and physical attack\nagainst them.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6027\u5206\u6790\u4e86\u5728\u7ebfHD\u5730\u56fe\u6784\u5efa\u6a21\u578b\u7684\u6f0f\u6d1e\uff0c\u53d1\u73b0\u5176\u5b58\u5728\u5bf9\u79f0\u6027\u504f\u8bef\uff0c\u5e76\u63d0\u51fa\u4e86\u80fd\u591f\u64cd\u63a7\u5730\u56fe\u6784\u5efa\u7684\u4e24\u9636\u6bb5\u653b\u51fb\u6846\u67b6\uff0c\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u653b\u51fb\u6548\u679c\u3002", "motivation": "\u968f\u7740\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u4f7f\u7528\u5728\u7ebfHD\u5730\u56fe\u6784\u5efa\u6280\u672f\uff0c\u5176\u5728\u6076\u610f\u6761\u4ef6\u4e0b\u7684\u7a33\u5065\u6027\u4ecd\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002\u672c\u6587\u610f\u5728\u63a2\u7d22\u8fd9\u4e9b\u6a21\u578b\u7684\u6f0f\u6d1e\u548c\u53ef\u80fd\u53d7\u5230\u7684\u653b\u51fb\u3002", "method": "\u9996\u5148\u8bc6\u522b\u6f0f\u6d1e\u6027\u4e0d\u5bf9\u79f0\u573a\u666f\uff0c\u7136\u540e\u4f18\u5316\u6444\u50cf\u5934\u76f2\u5149\u653b\u51fb\u548c\u5bf9\u6297\u8865\u4e01\u653b\u51fb\u7684\u4f4d\u7f6e\u548c\u6a21\u5f0f\uff0c\u6784\u5efa\u4e86\u4e24\u9636\u6bb5\u653b\u51fb\u6846\u67b6\u3002", "result": "\u653b\u51fb\u80fd\u591f\u4f7f\u5730\u56fe\u6784\u5efa\u51c6\u786e\u6027\u4e0b\u964d\u8fbe9.9%\uff0c\u5bfc\u81f444%\u76ee\u6807\u8def\u7ebf\u65e0\u6cd5\u5230\u8fbe\uff0c\u4e0d\u5b89\u5168\u89c4\u5212\u8f68\u8ff9\u7387\u589e\u52a027%\uff0c\u5e76\u5728\u771f\u5b9e\u8f66\u8f86\u4e0a\u9a8c\u8bc1\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5bf9\u5728\u7ebf\u5730\u56fe\u6784\u5efa\u6a21\u578b\u7684\u6f0f\u6d1e\u8bc4\u4f30\uff0c\u63d0\u51fa\u4e86\u6570\u5b57\u548c\u7269\u7406\u653b\u51fb\u65b9\u6cd5\uff0c\u5e76\u5206\u6790\u4e86\u5bf9\u79f0\u6027\u504f\u8bef\u7684\u6839\u6e90\u539f\u56e0\uff0c\u4e3a\u63d0\u5347\u6a21\u578b\u7a33\u5065\u6027\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2509.06463", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06463", "abs": "https://arxiv.org/abs/2509.06463", "authors": ["Chengwei Wu", "Li Du", "Hanyu Zhao", "Yiming Ju", "Jiapu Wang", "Tengfei Pan"], "title": "Accelerate Scaling of LLM Alignment via Quantifying the Coverage and Depth of Instruction Set", "comment": null, "summary": "With the growing demand for applying large language models to downstream\ntasks, improving model alignment performance and efficiency has become crucial.\nSuch a process involves selecting informative instructions from a candidate\npool. However, due to the complexity of instruction set distributions, the key\nfactors driving the performance of aligned models remain unclear. As a result,\ncurrent instruction set refinement methods fail to improve performance as the\ninstruction pool expands continuously. To address this issue, we first\ninvestigate the key factors that influence the relationship between instruction\ndataset distribution and aligned model performance. Based on these insights, we\npropose a novel instruction data selection method. We identify that the depth\nof instructions and the coverage of the semantic space are the crucial factors\ndetermining downstream performance, which could explain over 70\\% of the model\nloss on the development set. We then design an instruction selection algorithm\nto simultaneously maximize the depth and semantic coverage of the selected\ninstructions. Experimental results demonstrate that, compared to\nstate-of-the-art baseline methods, it can sustainably improve model performance\nat a faster pace and thus achieve \\emph{``Accelerated Scaling''}.", "AI": {"tldr": "\u8be5\u6587\u7ae0\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u4efd\u989d\u6027\u80fd\u6539\u5584\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6307\u4ee4\u6df1\u5ea6\u548c\u8bed\u4e49\u8986\u76d6\u5ea6\u7684\u65b0\u9898\u6307\u4ee4\u9009\u62e9\u65b9\u6cd5\uff0c\u80fd\u591f\u6301\u7eed\u63d0\u5347\u6a21\u578b\u6027\u80fd\u5e76\u5b9e\u73b0\"\u52a0\u901f\u6269\u5c55\"", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u589e\u957f\uff0c\u63d0\u9ad8\u6a21\u578b\u5bf9\u9f50\u6027\u80fd\u548c\u6548\u7387\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u4f46\u7531\u4e8e\u6307\u4ee4\u96c6\u5206\u5e03\u7684\u590d\u6742\u6027\uff0c\u5f53\u524d\u7684\u6307\u4ee4\u96c6\u7cbe\u7ec6\u65b9\u6cd5\u65e0\u6cd5\u5728\u6307\u4ee4\u6c60\u6301\u7eed\u6269\u5927\u65f6\u6301\u7eed\u6539\u5584\u6027\u80fd", "method": "\u9996\u5148\u7814\u7a76\u6307\u4ee4\u6570\u636e\u96c6\u5206\u5e03\u4e0e\u5bf9\u9f50\u6a21\u578b\u6027\u80fd\u5173\u7cfb\u7684\u5173\u952e\u56e0\u7d20\uff0c\u53d1\u73b0\u6307\u4ee4\u6df1\u5ea6\u548c\u8bed\u4e49\u7a7a\u95f4\u8986\u76d6\u5ea6\u662f\u5173\u952e\u56e0\u7d20\uff0c\u80fd\u89e3\u91ca70%\u4ee5\u4e0a\u7684\u6a21\u578b\u635f\u5931\u3002\u7136\u540e\u8bbe\u8ba1\u4e86\u4e00\u79cd\u540c\u65f6\u6700\u5927\u5316\u6df1\u5ea6\u548c\u8bed\u4e49\u8986\u76d6\u5ea6\u7684\u6307\u4ee4\u9009\u62e9\u7b97\u6cd5", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4e0e\u6700\u65b0\u7684\u57fa\u51c6\u65b9\u6cd5\u76f8\u6bd4\uff0c\u80fd\u591f\u4ee5\u66f4\u5feb\u7684\u901f\u5ea6\u6301\u7eed\u63d0\u5347\u6a21\u578b\u6027\u80fd", "conclusion": "\u901a\u8fc7\u91cd\u65b0\u5b9a\u4e49\u6307\u4ee4\u9009\u62e9\u7684\u5173\u952e\u6307\u6807\uff08\u6df1\u5ea6\u548c\u8bed\u4e49\u8986\u76d6\u5ea6\uff09\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5f53\u524d\u6307\u4ee4\u9009\u62e9\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u6307\u4ee4\u6c60\u4e2d\u6027\u80fd\u63a8\u9000\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u52a0\u901f\u6269\u5c55\u7684\u6548\u679c"}}
{"id": "2509.06112", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.06112", "abs": "https://arxiv.org/abs/2509.06112", "authors": ["Yanwei Gong", "Ruichen Zhang", "Xiaoqing Wang", "Xiaolin Chang", "Bo Ai", "Junchao Fan", "Bocheng Ju", "Dusit Niyato"], "title": "Towards Reliable Service Provisioning for Dynamic UAV Clusters in Low-Altitude Economy Networks", "comment": null, "summary": "Unmanned Aerial Vehicle (UAV) cluster services are crucial for promoting the\nlow-altitude economy by enabling scalable, flexible, and adaptive aerial\nnetworks. To meet diverse service demands, clusters must dynamically\nincorporate a New UAVs (NUAVs) or an Existing UAV (EUAV). However, achieving\nsustained service reliability remains challenging due to the need for efficient\nand scalable NUAV authentication, privacy-preserving cross-cluster\nauthentication for EUAVs, and robust protection of the cluster session key,\nincluding both forward and backward secrecy. To address these challenges, we\npropose a Lightweight and Privacy-Preserving Cluster Authentication and Session\nKey Update (LP2-CASKU) scheme tailored for dynamic UAV clusters in low-altitude\neconomy networks. LP2-CASKU integrates an efficient batch authentication\nmechanism that simultaneously authenticates multiple NUAVs with minimal\ncommunication overhead. It further introduces a lightweight cross-cluster\nauthentication mechanism that ensures EUAV anonymity and unlinkability.\nAdditionally, a secure session key update mechanism is incorporated to maintain\nkey confidentiality over time, thereby preserving both forward and backward\nsecrecy. We provide a comprehensive security analysis and evaluate LP2-CASKU\nperformance through both theoretical analysis and OMNeT++ simulations.\nExperimental results demonstrate that, compared to the baseline, LP2-CASKU\nachieves a latency reduction of 82.8%-90.8% by across different UAV swarm\nconfigurations and network bitrates, demonstrating strong adaptability to\ndynamic communication environments. Besides, under varying UAV swarm\nconfigurations, LP2-CASKU reduces the energy consumption by approximately\n37.6-72.6%, while effectively supporting privacy-preserving authentication in\nhighly dynamic UAV cluster environments.", "AI": {"tldr": "LP2-CASKU\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u9690\u79c1\u4fdd\u62a4\u65e0\u4eba\u673a\u96c6\u7fa4\u8ba4\u8bc1\u548c\u4f1a\u8bdd\u5bc6\u94a5\u66f4\u65b0\u65b9\u6848\uff0c\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf82.8%-90.8%\u548c\u80fd\u801737.6%-72.6%\uff0c\u652f\u6301\u52a8\u6001\u65e0\u4eba\u673a\u96c6\u7fa4\u7684\u9ad8\u6548\u8ba4\u8bc1\u548c\u9690\u79c1\u4fdd\u62a4\u3002", "motivation": "\u65e0\u4eba\u673a\u96c6\u7fa4\u670d\u52a1\u5bf9\u4f4e\u7a7a\u7ecf\u6d4e\u53d1\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6848\u5728NUAV\u9ad8\u6548\u8ba4\u8bc1\u3001EUAV\u9690\u79c1\u4fdd\u62a4\u8de8\u96c6\u7fa4\u8ba4\u8bc1\u4ee5\u53ca\u96c6\u7fa4\u4f1a\u8bdd\u5bc6\u94a5\u7684\u524d\u5411\u548c\u540e\u5411\u4fdd\u5bc6\u6027\u65b9\u9762\u5b58\u5728\u6311\u6218\u3002", "method": "\u63d0\u51faLP2-CASKU\u65b9\u6848\uff0c\u96c6\u6210\u9ad8\u6548\u6279\u91cf\u8ba4\u8bc1\u673a\u5236\uff08\u540c\u65f6\u8ba4\u8bc1\u591a\u4e2aNUAV\uff09\u3001\u8f7b\u91cf\u7ea7\u8de8\u96c6\u7fa4\u8ba4\u8bc1\u673a\u5236\uff08\u786e\u4fddEUAV\u533f\u540d\u6027\u548c\u4e0d\u53ef\u94fe\u63a5\u6027\uff09\u4ee5\u53ca\u5b89\u5168\u4f1a\u8bdd\u5bc6\u94a5\u66f4\u65b0\u673a\u5236\u3002", "result": "\u7406\u8bba\u5206\u6790\u548cOMNeT++\u4eff\u771f\u663e\u793a\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6848\uff0cLP2-CASKU\u5728\u4e0d\u540c\u65e0\u4eba\u673a\u7fa4\u914d\u7f6e\u548c\u7f51\u7edc\u6bd4\u7279\u7387\u4e0b\u5b9e\u73b0\u5ef6\u8fdf\u964d\u4f4e82.8%-90.8%\uff0c\u80fd\u8017\u964d\u4f4e37.6-72.6%\u3002", "conclusion": "LP2-CASKU\u65b9\u6848\u80fd\u6709\u6548\u652f\u6301\u9ad8\u5ea6\u52a8\u6001\u65e0\u4eba\u673a\u96c6\u7fa4\u73af\u5883\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u8ba4\u8bc1\uff0c\u5177\u6709\u8f83\u5f3a\u7684\u901a\u4fe1\u73af\u5883\u9002\u5e94\u6027\u3002"}}
{"id": "2509.06477", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06477", "abs": "https://arxiv.org/abs/2509.06477", "authors": ["Pengxiang Zhao", "Guangyi Liu", "Yaozhen Liang", "Weiqing He", "Zhengxi Lu", "Yuehao Huang", "Yaxuan Guo", "Kexin Zhang", "Hao Wang", "Liang Liu", "Yong Liu"], "title": "MAS-Bench: A Unified Benchmark for Shortcut-Augmented Hybrid Mobile GUI Agents", "comment": null, "summary": "To enhance the efficiency of GUI agents on various platforms like smartphones\nand computers, a hybrid paradigm that combines flexible GUI operations with\nefficient shortcuts (e.g., API, deep links) is emerging as a promising\ndirection. However, a framework for systematically benchmarking these hybrid\nagents is still underexplored. To take the first step in bridging this gap, we\nintroduce MAS-Bench, a benchmark that pioneers the evaluation of GUI-shortcut\nhybrid agents with a specific focus on the mobile domain. Beyond merely using\npredefined shortcuts, MAS-Bench assesses an agent's capability to autonomously\ngenerate shortcuts by discovering and creating reusable, low-cost workflows. It\nfeatures 139 complex tasks across 11 real-world applications, a knowledge base\nof 88 predefined shortcuts (APIs, deep-links, RPA scripts), and 7 evaluation\nmetrics. The tasks are designed to be solvable via GUI-only operations, but can\nbe significantly accelerated by intelligently embedding shortcuts. Experiments\nshow that hybrid agents achieve significantly higher success rates and\nefficiency than their GUI-only counterparts. This result also demonstrates the\neffectiveness of our method for evaluating an agent's shortcut generation\ncapabilities. MAS-Bench fills a critical evaluation gap, providing a\nfoundational platform for future advancements in creating more efficient and\nrobust intelligent agents.", "AI": {"tldr": "MAS-Bench\u662f\u9996\u4e2a\u4e13\u95e8\u8bc4\u4f30GUI-\u5feb\u6377\u65b9\u5f0f\u6df7\u5408\u667a\u80fd\u4f53\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e13\u6ce8\u4e8e\u79fb\u52a8\u9886\u57df\uff0c\u5305\u542b139\u4e2a\u590d\u6742\u4efb\u52a1\u548c88\u4e2a\u9884\u5b9a\u4e49\u5feb\u6377\u65b9\u5f0f\uff0c\u65e8\u5728\u586b\u8865\u6df7\u5408\u4ee3\u7406\u7cfb\u7edf\u8bc4\u4f30\u7684\u7a7a\u767d\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u7cfb\u7edf\u8bc4\u4f30GUI\u64cd\u4f5c\u4e0e\u5feb\u6377\u65b9\u5f0f\uff08API\u3001\u6df1\u5ea6\u94fe\u63a5\u7b49\uff09\u6df7\u5408\u667a\u80fd\u4f53\u7684\u6846\u67b6\uff0c\u9700\u8981\u5efa\u7acb\u57fa\u51c6\u6765\u63a8\u52a8\u66f4\u9ad8\u6548GUI\u4ee3\u7406\u7684\u53d1\u5c55\u3002", "method": "\u6784\u5efa\u5305\u542b139\u4e2a\u8de811\u4e2a\u771f\u5b9e\u5e94\u7528\u590d\u6742\u4efb\u52a1\u7684\u57fa\u51c6\uff0c\u63d0\u4f9b88\u4e2a\u9884\u5b9a\u4e49\u5feb\u6377\u65b9\u5f0f\u77e5\u8bc6\u5e93\uff0c\u8bbe\u8ba17\u4e2a\u8bc4\u4f30\u6307\u6807\uff0c\u6d4b\u8bd5\u4ee3\u7406\u81ea\u4e3b\u751f\u6210\u5feb\u6377\u65b9\u5f0f\u548c\u5de5\u4f5c\u6d41\u7684\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u6df7\u5408\u4ee3\u7406\u76f8\u6bd4\u7eafGUI\u4ee3\u7406\u663e\u8457\u63d0\u9ad8\u4e86\u4efb\u52a1\u6210\u529f\u7387\u548c\u6548\u7387\uff0c\u9a8c\u8bc1\u4e86\u8bc4\u4f30\u4ee3\u7406\u5feb\u6377\u65b9\u5f0f\u751f\u6210\u80fd\u529b\u7684\u6709\u6548\u6027\u3002", "conclusion": "MAS-Bench\u586b\u8865\u4e86\u5173\u952e\u8bc4\u4f30\u7a7a\u767d\uff0c\u4e3a\u521b\u5efa\u66f4\u9ad8\u6548\u3001\u9c81\u68d2\u7684\u667a\u80fd\u4ee3\u7406\u63d0\u4f9b\u4e86\u57fa\u7840\u5e73\u53f0\uff0c\u63a8\u52a8\u4e86\u6df7\u5408\u8303\u5f0f\u5728GUI\u81ea\u52a8\u5316\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2509.06127", "categories": ["cs.CR", "94A60, 94A62, 11T71, 68P30"], "pdf": "https://arxiv.org/pdf/2509.06127", "abs": "https://arxiv.org/abs/2509.06127", "authors": ["Soumya Bhoumik", "Sarbari Mitra", "Rohit Raj Sharma", "Kuldeep Namdeo"], "title": "CSI-IBBS: Identity-Based Blind Signature using CSIDH", "comment": null, "summary": "Identity-based cryptography (IBC), proposed by Adi Shamir, revolutionized\npublic key authentication by eliminating the need for certificates, enabling a\nmore efficient and scalable approach to cryptographic systems. Meanwhile, in\n\\cite{Katsumata2024group}, Katsumata et al. were the first to present the blind\nsignature protocol based on the hardness assumption of isogeny with provable\nsecurity, which resembles the Schnorr blind signature. Building upon these\nfoundational concepts, we propose an Identity-Based Blind Signature Scheme with\nan Honest Zero-Knowledge Verifier utilizing the CSIDH framework. This scheme\ncombines blind signatures for privacy preservation with zero-knowledge proofs\nto ensure the verifier's honesty without revealing any additional information.\n  Leveraging the quantum-resistant properties of CSIDH, a post-quantum secure\nscheme based on supersingular isogenies, our scheme offers strong protection\nagainst quantum adversaries while maintaining computational efficiency. We\nanalyze the security of the introduced protocol in the standard cryptographic\nmodel and demonstrate its effectiveness in safeguarding privacy and verifier\nhonesty. Furthermore, we present a performance evaluation, confirming the\npractical viability of this quantum-resistant cryptographic solution for\nprivacy-preserving applications. This work advances the creation of secure, and\nscalable cryptographic systems for the post-quantum era.", "AI": {"tldr": "\u57fa\u4e8eCSIDH\u6846\u67b6\u7684\u8eab\u4efd\u57fa\u7840\u76f2\u7b7e\u540d\u65b9\u6848\uff0c\u7ed3\u5408\u76f2\u7b7e\u540d\u548c\u96f6\u77e5\u8bc6\u9a8c\u8bc1\uff0c\u63d0\u4f9b\u91cf\u5b50\u6297\u6027\u548c\u9690\u79c1\u4fdd\u62a4", "motivation": "\u7ed3\u5408\u8eab\u4efd\u57fa\u7840\u52a0\u5bc6\u7684\u6548\u7387\u4f18\u52bf\u548c\u76f2\u7b7e\u540d\u7684\u9690\u79c1\u4fdd\u62a4\u80fd\u529b\uff0c\u5e94\u5bf9\u91cf\u5b50\u8ba1\u7b97\u7684\u5a01\u80c1\uff0c\u6784\u5efa\u53ef\u6269\u5c55\u7684\u540e\u91cf\u5b50\u5b89\u5168\u52a0\u5bc6\u7cfb\u7edf", "method": "\u5229\u7528CSIDH\u6846\u67b6\uff08\u8d85\u5947\u5f02\u540c\u69cd\u57fa\u7840\uff09\uff0c\u7ed3\u5408\u76f2\u7b7e\u540d\u534f\u8bae\u548c\u96f6\u77e5\u8bc6\u9a8c\u8bc1\u6280\u672f\uff0c\u5728\u6807\u51c6\u52a0\u5bc6\u6a21\u578b\u4e2d\u5206\u6790\u5b89\u5168\u6027", "result": "\u8bbe\u8ba1\u51fa\u4e86\u5177\u6709\u53ef\u8bc1\u5b89\u5168\u6027\u7684\u534f\u8bae\uff0c\u80fd\u591f\u540c\u65f6\u4fdd\u62a4\u9690\u79c1\u548c\u9a8c\u8bc1\u8005\u8bda\u4fe1\uff0c\u6027\u80fd\u8bc4\u4f30\u8bc1\u660e\u5176\u5b9e\u7528\u53ef\u884c\u6027", "conclusion": "\u8be5\u65b9\u6848\u4e3a\u540e\u91cf\u5b50\u65f6\u4ee3\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b89\u5168\u3001\u53ef\u6269\u5c55\u7684\u9690\u79c1\u4fdd\u62a4\u52a0\u5bc6\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u7ef4\u62a4\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u5177\u5907\u91cf\u5b50\u6297\u6027"}}
{"id": "2509.06490", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06490", "abs": "https://arxiv.org/abs/2509.06490", "authors": ["Niki Kotecha", "Ehecatl Antonio del Rio Chanona"], "title": "MORSE: Multi-Objective Reinforcement Learning via Strategy Evolution for Supply Chain Optimization", "comment": null, "summary": "In supply chain management, decision-making often involves balancing multiple\nconflicting objectives, such as cost reduction, service level improvement, and\nenvironmental sustainability. Traditional multi-objective optimization methods,\nsuch as linear programming and evolutionary algorithms, struggle to adapt in\nreal-time to the dynamic nature of supply chains. In this paper, we propose an\napproach that combines Reinforcement Learning (RL) and Multi-Objective\nEvolutionary Algorithms (MOEAs) to address these challenges for dynamic\nmulti-objective optimization under uncertainty. Our method leverages MOEAs to\nsearch the parameter space of policy neural networks, generating a Pareto front\nof policies. This provides decision-makers with a diverse population of\npolicies that can be dynamically switched based on the current system\nobjectives, ensuring flexibility and adaptability in real-time decision-making.\nWe also introduce Conditional Value-at-Risk (CVaR) to incorporate\nrisk-sensitive decision-making, enhancing resilience in uncertain environments.\nWe demonstrate the effectiveness of our approach through case studies,\nshowcasing its ability to respond to supply chain dynamics and outperforming\nstate-of-the-art methods in an inventory management case study. The proposed\nstrategy not only improves decision-making efficiency but also offers a more\nrobust framework for managing uncertainty and optimizing performance in supply\nchains.", "AI": {"tldr": "\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u591a\u76ee\u6807\u8fdb\u5316\u7b97\u6cd5\uff0c\u63d0\u51fa\u52a8\u6001\u591a\u76ee\u6807\u4f18\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f9b\u5e94\u94fe\u7ba1\u7406\u4e2d\u5b9e\u65f6\u51b3\u7b56\uff0c\u901a\u8fc7\u98ce\u9669\u654f\u611f\u673a\u5236\u63d0\u5347\u4e0d\u786e\u5b9a\u73af\u5883\u4e0b\u7684\u97e7\u6027\u3002", "motivation": "\u4f20\u7edf\u591a\u76ee\u6807\u4f18\u5316\u65b9\u6cd5\u96be\u4ee5\u9002\u5e94\u4f9b\u5e94\u94fe\u7684\u52a8\u6001\u6027\u548c\u5b9e\u65f6\u6027\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5e73\u8861\u6210\u672c\u3001\u670d\u52a1\u6c34\u5e73\u548c\u53ef\u6301\u7eed\u6027\u7b49\u591a\u91cd\u51b2\u7a81\u76ee\u6807\uff0c\u5e76\u5728\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u7075\u6d3b\u8c03\u6574\u7684\u51b3\u7b56\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u591a\u76ee\u6807\u8fdb\u5316\u7b97\u6cd5\u641c\u7d22\u7b56\u7565\u795e\u7ecf\u7f51\u7edc\u7684\u53c2\u6570\u7a7a\u95f4\uff0c\u751f\u6210\u5e15\u7d2f\u6258\u524d\u6cbf\u7b56\u7565\u96c6\uff0c\u7ed3\u5408\u6761\u4ef6\u98ce\u9669\u4ef7\u503c(CVaR)\u8fdb\u884c\u98ce\u9669\u654f\u611f\u51b3\u7b56\uff0c\u5b9e\u73b0\u52a8\u6001\u7b56\u7565\u5207\u6362\u3002", "result": "\u5728\u5e93\u5b58\u7ba1\u7406\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u54cd\u5e94\u4f9b\u5e94\u94fe\u52a8\u6001\u53d8\u5316\uff0c\u4f18\u4e8e\u73b0\u6709\u5148\u8fdb\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u51b3\u7b56\u6548\u7387\u548c\u7cfb\u7edf\u97e7\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7b56\u7565\u4e0d\u4ec5\u63d0\u5347\u4e86\u51b3\u7b56\u6548\u7387\uff0c\u8fd8\u4e3a\u7ba1\u7406\u4e0d\u786e\u5b9a\u6027\u548c\u4f18\u5316\u4f9b\u5e94\u94fe\u6027\u80fd\u63d0\u4f9b\u4e86\u66f4\u9c81\u68d2\u7684\u6846\u67b6\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.06493", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06493", "abs": "https://arxiv.org/abs/2509.06493", "authors": ["Ran Xin", "Zeyu Zheng", "Yanchen Nie", "Kun Yuan", "Xia Xiao"], "title": "Scaling up Multi-Turn Off-Policy RL and Multi-Agent Tree Search for LLM Step-Provers", "comment": null, "summary": "The integration of Large Language Models (LLMs) into automated theorem\nproving has shown immense promise, yet is fundamentally constrained by\nchallenges in scaling up both training-time reinforcement learning (RL) and\ninference-time compute. This paper introduces \\texttt{BFS-Prover-V2}, a system\ndesigned to address this dual scaling problem. We present two primary\ninnovations. The first is a novel multi-turn off-policy RL framework for\ncontinually improving the performance of LLM step-prover at training time. This\nframework, inspired by the principles of AlphaZero, utilizes a multi-stage\nexpert iteration pipeline featuring adaptive tactic-level data filtering and\nperiodic retraining to surmount the performance plateaus that typically curtail\nlong-term RL in LLM-based agents. The second innovation is a planner-enhanced\nmulti-agent search architecture that scales reasoning capabilities at inference\ntime. This architecture employs a general reasoning model as a high-level\nplanner to iteratively decompose complex theorems into a sequence of simpler\nsubgoals. This hierarchical approach substantially reduces the search space,\nenabling a team of parallel prover agents to collaborate efficiently by\nleveraging a shared proof cache. We demonstrate that this dual approach to\nscaling yields state-of-the-art results on established formal mathematics\nbenchmarks. \\texttt{BFS-Prover-V2} achieves 95.08\\% and 41.4\\% on the MiniF2F\nand ProofNet test sets respectively. While demonstrated in the domain of formal\nmathematics, the RL and inference techniques presented in this work are of\nbroader interest and may be applied to other domains requiring long-horizon\nmulti-turn reasoning and complex search.", "AI": {"tldr": "BFS-Prover-V2\u662f\u4e00\u4e2a\u7ed3\u5408\u591a\u8f6e\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u548c\u89c4\u5212\u589e\u5f3a\u591a\u667a\u80fd\u4f53\u641c\u7d22\u67b6\u6784\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u89e3\u51b3LLM\u5728\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u4e2d\u7684\u8bad\u7ec3\u548c\u63a8\u7406\u6269\u5c55\u95ee\u9898\uff0c\u5728\u6570\u5b66\u8bc1\u660e\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u4e2d\u9762\u4e34\u8bad\u7ec3\u65f6\u5f3a\u5316\u5b66\u4e60\u548c\u63a8\u7406\u65f6\u8ba1\u7b97\u8d44\u6e90\u6269\u5c55\u7684\u53cc\u91cd\u6311\u6218\uff0c\u9700\u8981\u514b\u670d\u6027\u80fd\u5e73\u53f0\u671f\u548c\u641c\u7d22\u7a7a\u95f4\u8fc7\u5927\u7684\u95ee\u9898\u3002", "method": "1. \u591a\u8f6e\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff1a\u53d7AlphaZero\u542f\u53d1\uff0c\u91c7\u7528\u591a\u9636\u6bb5\u4e13\u5bb6\u8fed\u4ee3\u6d41\u7a0b\uff0c\u5305\u542b\u81ea\u9002\u5e94\u7b56\u7565\u7ea7\u6570\u636e\u8fc7\u6ee4\u548c\u5b9a\u671f\u91cd\u8bad\u7ec3\uff1b2. \u89c4\u5212\u589e\u5f3a\u591a\u667a\u80fd\u4f53\u641c\u7d22\u67b6\u6784\uff1a\u4f7f\u7528\u901a\u7528\u63a8\u7406\u6a21\u578b\u4f5c\u4e3a\u9ad8\u5c42\u89c4\u5212\u5668\u5206\u89e3\u590d\u6742\u5b9a\u7406\uff0c\u901a\u8fc7\u5171\u4eab\u8bc1\u660e\u7f13\u5b58\u5b9e\u73b0\u5e76\u884c\u8bc1\u660e\u667a\u80fd\u4f53\u534f\u4f5c\u3002", "result": "\u5728MiniF2F\u6d4b\u8bd5\u96c6\u4e0a\u8fbe\u523095.08%\uff0c\u5728ProofNet\u6d4b\u8bd5\u96c6\u4e0a\u8fbe\u523041.4%\u7684state-of-the-art\u6027\u80fd\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u51fa\u7684\u5f3a\u5316\u5b66\u4e60\u548c\u63a8\u7406\u6280\u672f\u4e0d\u4ec5\u9002\u7528\u4e8e\u5f62\u5f0f\u6570\u5b66\u9886\u57df\uff0c\u8fd8\u53ef\u63a8\u5e7f\u5230\u5176\u4ed6\u9700\u8981\u957f\u89c6\u91ce\u591a\u8f6e\u63a8\u7406\u548c\u590d\u6742\u641c\u7d22\u7684\u9886\u57df\u3002"}}
{"id": "2509.06136", "categories": ["cs.CR", "68M25 (Primary), 68T07 (Secondary)", "K.6.5; I.2.6"], "pdf": "https://arxiv.org/pdf/2509.06136", "abs": "https://arxiv.org/abs/2509.06136", "authors": ["Yangheran Piao", "Jingjie Li", "Daniel W. Woods"], "title": "Measuring the Vulnerability Disclosure Policies of AI Vendors", "comment": "20 pages, 5 figures", "summary": "As AI is increasingly integrated into products and critical systems,\nresearchers are paying greater attention to identifying related\nvulnerabilities. Effective remediation depends on whether vendors are willing\nto accept and respond to AI vulnerability reports. In this paper, we examine\nthe disclosure policies of 264 AI vendors. Using a mixed-methods approach, our\nquantitative analysis finds that 36% of vendors provide no disclosure channel,\nand only 18% explicitly mention AI-related risks. Vulnerabilities involving\ndata access, authorization, and model extraction are generally considered\nin-scope, while jailbreaking and hallucination are frequently excluded. Through\nqualitative analysis, we further identify three vendor postures toward AI\nvulnerabilities - proactive clarification (n = 46, include active supporters,\nAI integrationists, and back channels), silence (n = 115, include self-hosted\nand hosted vendors), and restrictive (n = 103). Finally, by comparing vendor\npolicies against 1,130 AI incidents and 359 academic publications, we show that\nbug bounty policy evolution has lagged behind both academic research and\nreal-world events.", "AI": {"tldr": "\u5bf9264\u5bb6AI\u5382\u5546\u6f0f\u6d1e\u62ab\u9732\u653f\u7b56\u7684\u5206\u6790\u663e\u793a\uff0c36%\u5382\u5546\u65e0\u62ab\u9732\u6e20\u9053\uff0c\u4ec518%\u660e\u786e\u63d0\u53caAI\u98ce\u9669\uff0c\u653f\u7b56\u5236\u5b9a\u6ede\u540e\u4e8e\u5b66\u672f\u7814\u7a76\u548c\u5b9e\u9645\u4e8b\u4ef6", "motivation": "\u968f\u7740AI\u96c6\u6210\u5230\u5173\u952e\u7cfb\u7edf\u4e2d\uff0c\u7814\u7a76AI\u6f0f\u6d1e\u62ab\u9732\u653f\u7b56\u5bf9\u6709\u6548\u4fee\u590d\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u4e86\u89e3\u5382\u5546\u5bf9AI\u6f0f\u6d1e\u62a5\u544a\u7684\u63a5\u53d7\u548c\u54cd\u5e94\u6001\u5ea6", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff1a\u5b9a\u91cf\u5206\u6790264\u5bb6AI\u5382\u5546\u7684\u62ab\u9732\u653f\u7b56\uff0c\u5b9a\u6027\u5206\u6790\u5382\u5546\u5bf9AI\u6f0f\u6d1e\u7684\u6001\u5ea6\u5206\u7c7b\uff0c\u5e76\u4e0e1130\u8d77AI\u4e8b\u4ef6\u548c359\u7bc7\u5b66\u672f\u8bba\u6587\u5bf9\u6bd4", "result": "36%\u5382\u5546\u65e0\u62ab\u9732\u6e20\u9053\uff0c\u4ec518%\u63d0\u53caAI\u98ce\u9669\uff1b\u6570\u636e\u8bbf\u95ee\u3001\u6388\u6743\u548c\u6a21\u578b\u63d0\u53d6\u6f0f\u6d1e\u901a\u5e38\u88ab\u7eb3\u5165\u8303\u56f4\uff0c\u8d8a\u72f1\u548c\u5e7b\u89c9\u5e38\u88ab\u6392\u9664\uff1b\u8bc6\u522b\u51fa\u4e09\u79cd\u5382\u5546\u6001\u5ea6\uff1a\u4e3b\u52a8\u6f84\u6e05\u578b(46\u5bb6)\u3001\u6c89\u9ed8\u578b(115\u5bb6)\u3001\u9650\u5236\u578b(103\u5bb6)", "conclusion": "\u6f0f\u6d1e\u8d4f\u91d1\u653f\u7b56\u7684\u53d1\u5c55\u6ede\u540e\u4e8e\u5b66\u672f\u7814\u7a76\u548c\u73b0\u5b9e\u4e8b\u4ef6\uff0c\u9700\u8981\u6539\u8fdbAI\u6f0f\u6d1e\u62ab\u9732\u653f\u7b56\u4ee5\u8ddf\u4e0aAI\u5b89\u5168\u5a01\u80c1\u7684\u53d1\u5c55"}}
{"id": "2509.06503", "categories": ["cs.AI", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2509.06503", "abs": "https://arxiv.org/abs/2509.06503", "authors": ["Eser Ayg\u00fcn", "Anastasiya Belyaeva", "Gheorghe Comanici", "Marc Coram", "Hao Cui", "Jake Garrison", "Renee Johnston Anton Kast", "Cory Y. McLean", "Peter Norgaard", "Zahra Shamsi", "David Smalling", "James Thompson", "Subhashini Venugopalan", "Brian P. Williams", "Chujun He", "Sarah Martinson", "Martyna Plomecka", "Lai Wei", "Yuchen Zhou", "Qian-Ze Zhu", "Matthew Abraham", "Erica Brand", "Anna Bulanova", "Jeffrey A. Cardille", "Chris Co", "Scott Ellsworth", "Grace Joseph", "Malcolm Kane", "Ryan Krueger", "Johan Kartiwa", "Dan Liebling", "Jan-Matthis Lueckmann", "Paul Raccuglia", "Xuefei", "Wang", "Katherine Chou", "James Manyika", "Yossi Matias", "John C. Platt", "Lizzie Dorfman", "Shibl Mourad", "Michael P. Brenner"], "title": "An AI system to help scientists write expert-level empirical software", "comment": "71 pages, 26 figures", "summary": "The cycle of scientific discovery is frequently bottlenecked by the slow,\nmanual creation of software to support computational experiments. To address\nthis, we present an AI system that creates expert-level scientific software\nwhose goal is to maximize a quality metric. The system uses a Large Language\nModel (LLM) and Tree Search (TS) to systematically improve the quality metric\nand intelligently navigate the large space of possible solutions. The system\nachieves expert-level results when it explores and integrates complex research\nideas from external sources. The effectiveness of tree search is demonstrated\nacross a wide range of benchmarks. In bioinformatics, it discovered 40 novel\nmethods for single-cell data analysis that outperformed the top human-developed\nmethods on a public leaderboard. In epidemiology, it generated 14 models that\noutperformed the CDC ensemble and all other individual models for forecasting\nCOVID-19 hospitalizations. Our method also produced state-of-the-art software\nfor geospatial analysis, neural activity prediction in zebrafish, time series\nforecasting and numerical solution of integrals. By devising and implementing\nnovel solutions to diverse tasks, the system represents a significant step\ntowards accelerating scientific progress.", "AI": {"tldr": "AI\u7cfb\u7edf\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548c\u6811\u641c\u7d22\u81ea\u52a8\u751f\u6210\u4e13\u5bb6\u7ea7\u79d1\u5b66\u8f6f\u4ef6\uff0c\u5728\u591a\u4e2a\u9886\u57df\u8d85\u8d8a\u4eba\u7c7b\u5f00\u53d1\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u52a0\u901f\u79d1\u5b66\u53d1\u73b0\u8fdb\u7a0b", "motivation": "\u79d1\u5b66\u53d1\u73b0\u8fc7\u7a0b\u7ecf\u5e38\u53d7\u9650\u4e8e\u624b\u52a8\u521b\u5efa\u8ba1\u7b97\u5b9e\u9a8c\u8f6f\u4ef6\u7684\u7f13\u6162\u901f\u5ea6\uff0c\u9700\u8981\u81ea\u52a8\u5316\u5de5\u5177\u6765\u7a81\u7834\u8fd9\u4e00\u74f6\u9888", "method": "\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u548c\u6811\u641c\u7d22(TS)\u6280\u672f\uff0c\u7cfb\u7edf\u6027\u5730\u6539\u8fdb\u8d28\u91cf\u6307\u6807\u5e76\u667a\u80fd\u5bfc\u822a\u5927\u578b\u89e3\u51b3\u65b9\u6848\u7a7a\u95f4", "result": "\u5728\u751f\u7269\u4fe1\u606f\u5b66\u4e2d\u53d1\u73b040\u79cd\u4f18\u4e8e\u4eba\u7c7b\u65b9\u6cd5\u7684\u65b0\u5355\u7ec6\u80de\u6570\u636e\u5206\u6790\u65b9\u6cd5\uff1b\u5728\u6d41\u884c\u75c5\u5b66\u4e2d\u751f\u621014\u4e2a\u8d85\u8d8aCDC\u96c6\u6210\u6a21\u578b\u7684\u65b0\u51a0\u4f4f\u9662\u9884\u6d4b\u6a21\u578b\uff1b\u5728\u591a\u4e2a\u9886\u57df\u4ea7\u751f\u6700\u5148\u8fdb\u8f6f\u4ef6", "conclusion": "\u8be5\u7cfb\u7edf\u901a\u8fc7\u4e3a\u591a\u6837\u5316\u4efb\u52a1\u8bbe\u8ba1\u548c\u5b9e\u65bd\u65b0\u9896\u89e3\u51b3\u65b9\u6848\uff0c\u4ee3\u8868\u7740\u52a0\u901f\u79d1\u5b66\u8fdb\u6b65\u7684\u91cd\u8981\u4e00\u6b65"}}
{"id": "2509.06202", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.06202", "abs": "https://arxiv.org/abs/2509.06202", "authors": ["Fatemeh Roshanzadeh", "Hamid Barati", "Ali Barati"], "title": "Lightweight Intrusion Detection System Using a Hybrid CNN and ConvNeXt-Tiny Model for Internet of Things Networks", "comment": null, "summary": "The rapid expansion of Internet of Things (IoT) systems across various\ndomains such as industry, smart cities, healthcare, manufacturing, and\ngovernment services has led to a significant increase in security risks,\nthreatening data integrity, confidentiality, and availability. Consequently,\nensuring the security and resilience of IoT systems has become a critical\nrequirement. In this paper, we propose a lightweight and efficient intrusion\ndetection system (IDS) for IoT environments, leveraging a hybrid model of CNN\nand ConvNeXt-Tiny. The proposed method is designed to detect and classify\ndifferent types of network attacks, particularly botnet and malicious traffic,\nwhile the lightweight ConvNeXt-Tiny architecture enables effective deployment\nin resource-constrained devices and networks. A real-world dataset comprising\nboth benign and malicious network packets collected from practical IoT\nscenarios was employed in the experiments. The results demonstrate that the\nproposed method achieves high accuracy while significantly reducing training\nand inference time compared to more complex models. Specifically, the system\nattained 99.63% accuracy in the testing phase, 99.67% accuracy in the training\nphase, and an error rate of 0.0107 across eight classes, while maintaining\nshort response times and low resource consumption. These findings highlight the\neffectiveness of the proposed method in detecting and classifying attacks in\nreal-world IoT environments, indicating that the lightweight architecture can\nserve as a practical alternative to complex and resource-intensive approaches\nin IoT network security.", "AI": {"tldr": "\u8f7b\u91cf\u7ea7CNN\u4e0eConvNeXt-Tiny\u6df7\u5408\u6a21\u578b\u7684\u7269\u8054\u7f51\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u5b9e\u73b0\u9ad8\u51c6\u786e\u7387\u653b\u51fb\u68c0\u6d4b", "motivation": "\u7269\u8054\u7f51\u5e94\u7528\u7684\u5feb\u901f\u6269\u5c55\u5bfc\u81f4\u5b89\u5168\u98ce\u9669\u589e\u52a0\uff0c\u9700\u8981\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u5b9e\u73b0\u9ad8\u6548\u7684\u5165\u4fb5\u68c0\u6d4b", "method": "\u91c7\u7528CNN\u4e0eConvNeXt-Tiny\u6df7\u5408\u6a21\u578b\uff0c\u4f7f\u7528\u771f\u5b9e\u7269\u8054\u7f51\u73af\u5883\u6536\u96c6\u7684\u826f\u6027\u548c\u6076\u610f\u7f51\u7edc\u6570\u636e\u8fdb\u884c\u8bad\u7ec3", "result": "\u5728\u6d4b\u8bd5\u9636\u6bb5\u8fbe\u523099.63%\u51c6\u786e\u7387\uff0c\u8bad\u7ec3\u9636\u6bb599.67%\u51c6\u786e\u7387\uff0c\u8bef\u5dee\u73870.0107\uff0c\u540c\u65f6\u4fdd\u6301\u77ed\u54cd\u5e94\u65f6\u95f4\u548c\u4f4e\u8d44\u6e90\u6d88\u8017", "conclusion": "\u8be5\u8f7b\u91cf\u7ea7\u6a21\u578b\u53ef\u4f5c\u4e3a\u590d\u6742\u8d44\u6e90\u5bc6\u96c6\u65b9\u6848\u7684\u5b9e\u7528\u66ff\u4ee3\u65b9\u6848\uff0c\u6709\u6548\u63d0\u5347\u7269\u8054\u7f51\u7f51\u7edc\u5b89\u5168\u6027"}}
{"id": "2509.06641", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.06641", "abs": "https://arxiv.org/abs/2509.06641", "authors": ["Zhou-Peng Shou", "Zhi-Qiang You", "Fang Wang", "Hai-Bo Liu"], "title": "CogGuide: Human-Like Guidance for Zero-Shot Omni-Modal Reasoning", "comment": null, "summary": "Targeting the issues of \"shortcuts\" and insufficient contextual understanding\nin complex cross-modal reasoning of multimodal large models, this paper\nproposes a zero-shot multimodal reasoning component guided by human-like\ncognitive strategies centered on an \"intent sketch\". The component comprises a\nplug-and-play three-module pipeline-Intent Perceiver, Strategy Generator, and\nStrategy Selector-that explicitly constructs a \"understand-plan-select\"\ncognitive process. By generating and filtering \"intent sketch\" strategies to\nguide the final reasoning, it requires no parameter fine-tuning and achieves\ncross-model transfer solely through in-context engineering.\nInformation-theoretic analysis shows that this process can reduce conditional\nentropy and improve information utilization efficiency, thereby suppressing\nunintended shortcut reasoning. Experiments on IntentBench, WorldSense, and\nDaily-Omni validate the method's generality and robust gains; compared with\ntheir respective baselines, the complete \"three-module\" scheme yields\nconsistent improvements across different reasoning engines and pipeline\ncombinations, with gains up to approximately 9.51 percentage points,\ndemonstrating the practical value and portability of the \"intent sketch\"\nreasoning component in zero-shot scenarios.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\"\u610f\u56fe\u8349\u56fe\"\u7684\u96f6\u6837\u672c\u591a\u6a21\u6001\u63a8\u7406\u7ec4\u4ef6\uff0c\u901a\u8fc7\u4e09\u6a21\u5757\u7ba1\u9053\u5b9e\u73b0\u7c7b\u4eba\u8ba4\u77e5\u8fc7\u7a0b\uff0c\u65e0\u9700\u53c2\u6570\u5fae\u8c03\u5373\u53ef\u6291\u5236\u6377\u5f84\u63a8\u7406\u5e76\u63d0\u5347\u8de8\u6a21\u6001\u63a8\u7406\u6027\u80fd", "motivation": "\u89e3\u51b3\u591a\u6a21\u6001\u5927\u6a21\u578b\u5728\u590d\u6742\u8de8\u6a21\u6001\u63a8\u7406\u4e2d\u5b58\u5728\u7684\"\u6377\u5f84\"\u95ee\u9898\u548c\u4e0a\u4e0b\u6587\u7406\u89e3\u4e0d\u8db3\u7684\u95ee\u9898", "method": "\u63d0\u51fa\u53ef\u63d2\u62d4\u7684\u4e09\u6a21\u5757\u7ba1\u9053\uff1a\u610f\u56fe\u611f\u77e5\u5668\u3001\u7b56\u7565\u751f\u6210\u5668\u548c\u7b56\u7565\u9009\u62e9\u5668\uff0c\u901a\u8fc7\u751f\u6210\u548c\u7b5b\u9009\"\u610f\u56fe\u8349\u56fe\"\u7b56\u7565\u6765\u6307\u5bfc\u6700\u7ec8\u63a8\u7406\uff0c\u65e0\u9700\u53c2\u6570\u5fae\u8c03\uff0c\u4ec5\u901a\u8fc7\u4e0a\u4e0b\u6587\u5de5\u7a0b\u5b9e\u73b0\u8de8\u6a21\u578b\u8fc1\u79fb", "result": "\u5728IntentBench\u3001WorldSense\u548cDaily-Omni\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u901a\u7528\u6027\u548c\u7a33\u5065\u589e\u76ca\uff0c\u76f8\u6bd4\u57fa\u7ebf\u83b7\u5f97\u4e00\u81f4\u6539\u8fdb\uff0c\u6700\u9ad8\u63d0\u5347\u7ea69.51\u4e2a\u767e\u5206\u70b9", "conclusion": "\"\u610f\u56fe\u8349\u56fe\"\u63a8\u7406\u7ec4\u4ef6\u5728\u96f6\u6837\u672c\u573a\u666f\u4e2d\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u548c\u53ef\u79fb\u690d\u6027\uff0c\u4fe1\u606f\u8bba\u5206\u6790\u663e\u793a\u8be5\u65b9\u6cd5\u80fd\u964d\u4f4e\u6761\u4ef6\u71b5\u5e76\u63d0\u9ad8\u4fe1\u606f\u5229\u7528\u6548\u7387"}}
{"id": "2509.06264", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.06264", "abs": "https://arxiv.org/abs/2509.06264", "authors": ["Qin Yang", "Nicholas Stout", "Meisam Mohammady", "Han Wang", "Ayesha Samreen", "Christopher J Quinn", "Yan Yan", "Ashish Kundu", "Yuan Hong"], "title": "PLRV-O: Advancing Differentially Private Deep Learning via Privacy Loss Random Variable Optimization", "comment": "Source code is available at https://github.com/datasec-lab/plrvo.\n  This is the full version of the paper to appear in CCS'25", "summary": "Differentially Private Stochastic Gradient Descent (DP-SGD) is a standard\nmethod for enforcing privacy in deep learning, typically using the Gaussian\nmechanism to perturb gradient updates. However, conventional mechanisms such as\nGaussian and Laplacian noise are parameterized only by variance or scale. This\nsingle degree of freedom ties the magnitude of noise directly to both privacy\nloss and utility degradation, preventing independent control of these two\nfactors. The problem becomes more pronounced when the number of composition\nrounds T and batch size B vary across tasks, as these variations induce\ntask-dependent shifts in the privacy-utility trade-off, where small changes in\nnoise parameters can disproportionately affect model accuracy. To address this\nlimitation, we introduce PLRV-O, a framework that defines a broad search space\nof parameterized DP-SGD noise distributions, where privacy loss moments are\ntightly characterized yet can be optimized more independently with respect to\nutility loss. This formulation enables systematic adaptation of noise to\ntask-specific requirements, including (i) model size, (ii) training duration,\n(iii) batch sampling strategies, and (iv) clipping thresholds under both\ntraining and fine-tuning settings. Empirical results demonstrate that PLRV-O\nsubstantially improves utility under strict privacy constraints. On CIFAR-10, a\nfine-tuned ViT achieves 94.03% accuracy at epsilon approximately 0.5, compared\nto 83.93% with Gaussian noise. On SST-2, RoBERTa-large reaches 92.20% accuracy\nat epsilon approximately 0.2, versus 50.25% with Gaussian.", "AI": {"tldr": "PLRV-O\u63d0\u51fa\u4e86\u4e00\u79cd\u53c2\u6570\u5316\u7684DP-SGD\u566a\u58f0\u5206\u5e03\u6846\u67b6\uff0c\u901a\u8fc7\u66f4\u72ec\u7acb\u5730\u63a7\u5236\u9690\u79c1\u635f\u5931\u548c\u6548\u7528\u4e0b\u964d\uff0c\u5728\u4e25\u683c\u9690\u79c1\u7ea6\u675f\u4e0b\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u7684Gaussian\u548cLaplacian\u566a\u58f0\u673a\u5236\u53ea\u6709\u5355\u4e00\u7684\u65b9\u5dee\u53c2\u6570\uff0c\u5bfc\u81f4\u566a\u58f0\u5927\u5c0f\u4e0e\u9690\u79c1\u635f\u5931\u548c\u6548\u7528\u4e0b\u964d\u76f8\u5173\u8054\uff0c\u65e0\u6cd5\u72ec\u7acb\u63a7\u5236\u8fd9\u4e24\u4e2a\u56e0\u7d20\u3002\u5f53\u8fed\u4ee3\u8f6e\u6570T\u548c\u6279\u5904\u7406\u5927\u5c0fB\u53d8\u5316\u65f6\uff0c\u9690\u79c1-\u6548\u7528\u4ea4\u6362\u4f1a\u53d1\u751f\u4efb\u52a1\u4f9d\u8d56\u6027\u504f\u79fb\u3002", "method": "\u63d0\u51faPLRV-O\u6846\u67b6\uff0c\u5b9a\u4e49\u4e86\u4e00\u4e2a\u5e7f\u6cdb\u7684\u53c2\u6570\u5316DP-SGD\u566a\u58f0\u5206\u5e03\u641c\u7d22\u7a7a\u95f4\uff0c\u5176\u4e2d\u9690\u79c1\u635f\u5931\u77e9\u88c5\u88c5\u5f97\u5230\u4e25\u683c\u7279\u5f81\u5316\u4f46\u53ef\u4ee5\u66f4\u72ec\u7acb\u5730\u4f18\u5316\u6548\u7528\u635f\u5931\u3002\u8be5\u65b9\u6cd5\u652f\u6301\u6839\u636e\u4efb\u52a1\u7279\u5b9a\u9700\u6c42\u7cfb\u7edf\u5730\u9002\u914d\u566a\u58f0\uff0c\u5305\u62ec\u6a21\u578b\u5927\u5c0f\u3001\u8bad\u7ec3\u6301\u7eed\u65f6\u95f4\u3001\u6279\u5904\u91c7\u6837\u7b56\u7565\u548c\u526a\u5207\u9608\u503c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aPLRV-O\u5728\u4e25\u683c\u9690\u79c1\u7ea6\u675f\u4e0b\u663e\u8457\u63d0\u9ad8\u4e86\u6548\u7528\uff1a\u5728CIFAR-10\u4e0a\uff0c\u7cbe\u8c03\u7684ViT\u5728epsilon\u7ea60.5\u65f6\u8fbe\u523094.03%\u51c6\u786e\u7387\uff08Gaussian\u566a\u58f0\u4e3a83.93%\uff09\uff1b\u5728SST-2\u4e0a\uff0cRoBERTa-large\u5728epsilon\u7ea60.2\u65f6\u8fbe\u523092.20%\u51c6\u786e\u7387\uff08Gaussian\u566a\u58f0\u4e3a50.25%\uff09\u3002", "conclusion": "PLRV-O\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u4f20\u7edfDP-SGD\u566a\u58f0\u673a\u5236\u4e2d\u9690\u79c1\u635f\u5931\u4e0e\u6548\u7528\u4e0b\u964d\u76f8\u5173\u8054\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u53c2\u6570\u5316\u566a\u58f0\u5206\u5e03\u5b9e\u73b0\u4e86\u66f4\u72ec\u7acb\u7684\u4f18\u5316\u63a7\u5236\uff0c\u4e3a\u4e0d\u540c\u4efb\u52a1\u7279\u5b9a\u8981\u6c42\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u566a\u58f0\u9002\u914d\u65b9\u6848\u3002"}}
{"id": "2509.06733", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.06733", "abs": "https://arxiv.org/abs/2509.06733", "authors": ["Wenjun Li", "Zhi Chen", "Jingru Lin", "Hannan Cao", "Wei Han", "Sheng Liang", "Zhi Zhang", "Kuicai Dong", "Dexun Li", "Chen Zhang", "Yong Liu"], "title": "Reinforcement Learning Foundations for Deep Research Systems: A Survey", "comment": "38 pages, first version", "summary": "Deep research systems, agentic AI that solve complex, multi-step tasks by\ncoordinating reasoning, search across the open web and user files, and tool\nuse, are moving toward hierarchical deployments with a Planner, Coordinator,\nand Executors. In practice, training entire stacks end-to-end remains\nimpractical, so most work trains a single planner connected to core tools such\nas search, browsing, and code. While SFT imparts protocol fidelity, it suffers\nfrom imitation and exposure biases and underuses environment feedback.\nPreference alignment methods such as DPO are schema and proxy-dependent,\noff-policy, and weak for long-horizon credit assignment and multi-objective\ntrade-offs. A further limitation of SFT and DPO is their reliance on human\ndefined decision points and subskills through schema design and labeled\ncomparisons. Reinforcement learning aligns with closed-loop, tool-interaction\nresearch by optimizing trajectory-level policies, enabling exploration,\nrecovery behaviors, and principled credit assignment, and it reduces dependence\non such human priors and rater biases.\n  This survey is, to our knowledge, the first dedicated to the RL foundations\nof deep research systems. It systematizes work after DeepSeek-R1 along three\naxes: (i) data synthesis and curation; (ii) RL methods for agentic research\ncovering stability, sample efficiency, long context handling, reward and credit\ndesign, multi-objective optimization, and multimodal integration; and (iii)\nagentic RL training systems and frameworks. We also cover agent architecture\nand coordination, as well as evaluation and benchmarks, including recent QA,\nVQA, long-form synthesis, and domain-grounded, tool-interaction tasks. We\ndistill recurring patterns, surface infrastructure bottlenecks, and offer\npractical guidance for training robust, transparent deep research agents with\nRL.", "AI": {"tldr": "\u672c\u6587\u662f\u9996\u4e2a\u4e13\u6ce8\u4e8e\u6df1\u5ea6\u641c\u7d22\u7cfb\u7edf\u5f3a\u5316\u5b66\u4e60\u57fa\u7840\u7684\u8c03\u67e5\u62a5\u544a\uff0c\u7cfb\u7edf\u5316\u5206\u6790\u4e86\u6570\u636e\u5408\u6210\u3001RL\u65b9\u6cd5\u548c\u8bad\u7ec3\u6846\u67b6\u7b49\u5173\u952e\u6280\u672f\uff0c\u4e3a\u5efa\u7acb\u5065\u58ee\u900f\u660e\u7684\u6c11\u4e3b\u7814\u7a76\u7cfb\u7edf\u63d0\u4f9b\u5b9e\u7528\u6307\u5357", "motivation": "\u5f53\u524d\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u4e3b\u8981\u4f9d\u9760SFT\u548cDPO\u65b9\u6cd5\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u5b58\u5728\u6a21\u4eff\u504f\u5dee\u3001\u73af\u5883\u53cd\u9988\u5229\u7528\u4e0d\u5145\u5206\u3001\u4f9d\u8d56\u4eba\u5de5\u5b9a\u4e49\u51b3\u7b56\u70b9\u7b49\u9650\u5236\uff0c\u800c\u5f3a\u5316\u5b66\u4e60\u80fd\u591f\u66f4\u597d\u5730\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898", "method": "\u4ece\u4e09\u4e2a\u8f74\u5fc3\u7cfb\u7edf\u5316\u5206\u6790\u76f8\u5173\u7814\u7a76\uff1a(i)\u6570\u636e\u5408\u6210\u4e0e\u7ba1\u7406\uff1b(ii)\u7814\u7a76\u578b\u7ec4\u4ef6\u7684RL\u65b9\u6cd5\uff08\u7a33\u5b9a\u6027\u3001\u6837\u672c\u6548\u7387\u3001\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u3001\u5956\u52b1\u8bbe\u8ba1\u7b49\uff09\uff1b(iii)\u7ec4\u4ef6\u5316RL\u8bad\u7ec3\u7cfb\u7edf\u548c\u6846\u67b6\uff0c\u540c\u65f6\u6db5\u76d6\u7ec4\u4ef6\u67b6\u6784\u3001\u534f\u8c03\u4ee5\u53ca\u8bc4\u4f30\u6807\u51c6", "result": "\u62bd\u8c61\u51fa\u4e86\u91cd\u590d\u6a21\u5f0f\uff0c\u63ed\u793a\u4e86\u57fa\u7840\u8bbe\u65bd\u7684\u74f6\u9888\uff0c\u5e76\u4e3a\u57f9\u517b\u5065\u58ee\u3001\u900f\u660e\u7684\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u6307\u5bfc", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u5728\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5f53\u524d\u65b9\u6cd5\u7684\u9650\u5236\uff0c\u672c\u8c03\u67e5\u4e3a\u8be5\u9886\u57df\u7684\u7814\u7a76\u4e0e\u5e94\u7528\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u57fa\u7840\u6846\u67b6\u548c\u5b9e\u8df5\u6307\u5357"}}
{"id": "2509.06326", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06326", "abs": "https://arxiv.org/abs/2509.06326", "authors": ["Ruisi Zhang", "Yifei Zhao", "Neusha Javidnia", "Mengxin Zheng", "Farinaz Koushanfar"], "title": "AttestLLM: Efficient Attestation Framework for Billion-scale On-device LLMs", "comment": null, "summary": "As on-device LLMs(e.g., Apple on-device Intelligence) are widely adopted to\nreduce network dependency, improve privacy, and enhance responsiveness,\nverifying the legitimacy of models running on local devices becomes critical.\nExisting attestation techniques are not suitable for billion-parameter Large\nLanguage Models (LLMs), struggling to remain both time- and memory-efficient\nwhile addressing emerging threats in the LLM era. In this paper, we present\nAttestLLM, the first-of-its-kind attestation framework to protect the\nhardware-level intellectual property (IP) of device vendors by ensuring that\nonly authorized LLMs can execute on target platforms. AttestLLM leverages an\nalgorithm/software/hardware co-design approach to embed robust watermarking\nsignatures onto the activation distributions of LLM building blocks. It also\noptimizes the attestation protocol within the Trusted Execution Environment\n(TEE), providing efficient verification without compromising inference\nthroughput. Extensive proof-of-concept evaluations on LLMs from Llama, Qwen,\nand Phi families for on-device use cases demonstrate AttestLLM's attestation\nreliability, fidelity, and efficiency. Furthermore, AttestLLM enforces model\nlegitimacy and exhibits resilience against model replacement and forgery\nattacks.", "AI": {"tldr": "AttestLLM\u662f\u4e00\u4e2a\u9488\u5bf9\u8bbe\u5907\u7aef\u5927\u8bed\u8a00\u6a21\u578b\u7684\u786c\u4ef6\u7ea7\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u6846\u67b6\uff0c\u901a\u8fc7\u7b97\u6cd5/\u8f6f\u4ef6/\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u5728LLM\u6fc0\u6d3b\u5206\u5e03\u4e2d\u5d4c\u5165\u6c34\u5370\u7b7e\u540d\uff0c\u5728TEE\u4e2d\u5b9e\u73b0\u9ad8\u6548\u9a8c\u8bc1\uff0c\u786e\u4fdd\u53ea\u6709\u6388\u6743\u6a21\u578b\u80fd\u5728\u76ee\u6807\u5e73\u53f0\u4e0a\u8fd0\u884c\u3002", "motivation": "\u968f\u7740\u8bbe\u5907\u7aefLLM\u7684\u5e7f\u6cdb\u91c7\u7528\uff0c\u9a8c\u8bc1\u672c\u5730\u8bbe\u5907\u4e0a\u8fd0\u884c\u6a21\u578b\u7684\u5408\u6cd5\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u8ba4\u8bc1\u6280\u672f\u65e0\u6cd5\u6709\u6548\u5904\u7406\u5341\u4ebf\u53c2\u6570\u7ea7\u522b\u7684LLM\uff0c\u65e2\u9700\u8981\u65f6\u95f4\u5185\u5b58\u9ad8\u6548\uff0c\u53c8\u8981\u5e94\u5bf9LLM\u65f6\u4ee3\u7684\u65b0\u5a01\u80c1\u3002", "method": "\u91c7\u7528\u7b97\u6cd5/\u8f6f\u4ef6/\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u5728LLM\u6784\u5efa\u5757\u7684\u6fc0\u6d3b\u5206\u5e03\u4e2d\u5d4c\u5165\u9c81\u68d2\u6c34\u5370\u7b7e\u540d\uff0c\u5e76\u5728\u53ef\u4fe1\u6267\u884c\u73af\u5883(TEE)\u4e2d\u4f18\u5316\u8ba4\u8bc1\u534f\u8bae\uff0c\u5b9e\u73b0\u9ad8\u6548\u9a8c\u8bc1\u800c\u4e0d\u5f71\u54cd\u63a8\u7406\u541e\u5410\u91cf\u3002", "result": "\u5728Llama\u3001Qwen\u548cPhi\u7cfb\u5217LLM\u4e0a\u7684\u5e7f\u6cdb\u6982\u5ff5\u9a8c\u8bc1\u8bc4\u4f30\u8868\u660e\uff0cAttestLLM\u5177\u6709\u8ba4\u8bc1\u53ef\u9760\u6027\u3001\u4fdd\u771f\u5ea6\u548c\u6548\u7387\uff0c\u80fd\u591f\u5f3a\u5236\u6267\u884c\u6a21\u578b\u5408\u6cd5\u6027\uff0c\u5e76\u5bf9\u6a21\u578b\u66ff\u6362\u548c\u4f2a\u9020\u653b\u51fb\u8868\u73b0\u51fa\u97e7\u6027\u3002", "conclusion": "AttestLLM\u662f\u9996\u4e2a\u4fdd\u62a4\u8bbe\u5907\u5382\u5546\u786c\u4ef6\u7ea7\u77e5\u8bc6\u4ea7\u6743\u7684\u8ba4\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u6c34\u5370\u5d4c\u5165\u548cTEE\u4f18\u5316\u534f\u8bae\uff0c\u4e3a\u8bbe\u5907\u7aefLLM\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5408\u6cd5\u6027\u9a8c\u8bc1\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.06736", "categories": ["cs.AI", "cs.CL", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.06736", "abs": "https://arxiv.org/abs/2509.06736", "authors": ["Jie Yang", "Jiajun Chen", "Zhangyue Yin", "Shuo Chen", "Yuxin Wang", "Yiran Guo", "Yuan Li", "Yining Zheng", "Xuanjing Huang", "Xipeng Qiu"], "title": "VehicleWorld: A Highly Integrated Multi-Device Environment for Intelligent Vehicle Interaction", "comment": null, "summary": "Intelligent vehicle cockpits present unique challenges for API Agents,\nrequiring coordination across tightly-coupled subsystems that exceed typical\ntask environments' complexity. Traditional Function Calling (FC) approaches\noperate statelessly, requiring multiple exploratory calls to build\nenvironmental awareness before execution, leading to inefficiency and limited\nerror recovery. We introduce VehicleWorld, the first comprehensive environment\nfor the automotive domain, featuring 30 modules, 250 APIs, and 680 properties\nwith fully executable implementations that provide real-time state information\nduring agent execution. This environment enables precise evaluation of vehicle\nagent behaviors across diverse, challenging scenarios. Through systematic\nanalysis, we discovered that direct state prediction outperforms function\ncalling for environmental control. Building on this insight, we propose\nState-based Function Call (SFC), a novel approach that maintains explicit\nsystem state awareness and implements direct state transitions to achieve\ntarget conditions. Experimental results demonstrate that SFC significantly\noutperforms traditional FC approaches, achieving superior execution accuracy\nand reduced latency. We have made all implementation code publicly available on\nGithub https://github.com/OpenMOSS/VehicleWorld.", "AI": {"tldr": "\u63d0\u51fa\u4e86VehicleWorld\u8f66\u8f7d\u73af\u5883\u5e73\u53f0\u548cState-based Function Call (SFC)\u65b9\u6cd5\uff0c\u901a\u8fc7\u663e\u5f0f\u72b6\u6001\u611f\u77e5\u548c\u76f4\u63a5\u72b6\u6001\u8f6c\u6362\uff0c\u5728\u8f66\u8f7d\u5ea7\u8231API\u4ee3\u7406\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u51fd\u6570\u8c03\u7528\u65b9\u6cd5", "motivation": "\u667a\u80fd\u8f66\u8f86\u5ea7\u8231API\u4ee3\u7406\u9762\u4e34\u7d27\u5bc6\u8026\u5408\u5b50\u7cfb\u7edf\u7684\u534f\u8c03\u6311\u6218\uff0c\u4f20\u7edf\u51fd\u6570\u8c03\u7528\u65b9\u6cd5\u9700\u8981\u591a\u6b21\u63a2\u7d22\u6027\u8c03\u7528\u6765\u6784\u5efa\u73af\u5883\u8ba4\u77e5\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u548c\u9519\u8bef\u6062\u590d\u80fd\u529b\u6709\u9650", "method": "\u5f00\u53d1\u4e86\u5305\u542b30\u4e2a\u6a21\u5757\u3001250\u4e2aAPI\u548c680\u4e2a\u5c5e\u6027\u7684VehicleWorld\u8f66\u8f7d\u73af\u5883\u5e73\u53f0\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u72b6\u6001\u7684\u51fd\u6570\u8c03\u7528(SFC)\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ef4\u62a4\u663e\u5f0f\u7cfb\u7edf\u72b6\u6001\u611f\u77e5\u548c\u5b9e\u73b0\u76f4\u63a5\u72b6\u6001\u8f6c\u6362", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eSFC\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u51fd\u6570\u8c03\u7528\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6267\u884c\u51c6\u786e\u6027\u548c\u66f4\u4f4e\u7684\u5ef6\u8fdf", "conclusion": "\u76f4\u63a5\u72b6\u6001\u9884\u6d4b\u5728\u73af\u5883\u63a7\u5236\u65b9\u9762\u4f18\u4e8e\u51fd\u6570\u8c03\u7528\uff0cSFC\u65b9\u6cd5\u4e3a\u8f66\u8f7d\u5ea7\u8231API\u4ee3\u7406\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6240\u6709\u5b9e\u73b0\u4ee3\u7801\u5df2\u5728GitHub\u5f00\u6e90"}}
{"id": "2509.06338", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.06338", "abs": "https://arxiv.org/abs/2509.06338", "authors": ["Shuai Yuan", "Zhibo Zhang", "Yuxi Li", "Guangdong Bai", "Wang Kailong"], "title": "Embedding Poisoning: Bypassing Safety Alignment via Embedding Semantic Shift", "comment": "16 pages,9 figures", "summary": "The widespread distribution of Large Language Models (LLMs) through public\nplatforms like Hugging Face introduces significant security challenges. While\nthese platforms perform basic security scans, they often fail to detect subtle\nmanipulations within the embedding layer. This work identifies a novel class of\ndeployment phase attacks that exploit this vulnerability by injecting\nimperceptible perturbations directly into the embedding layer outputs without\nmodifying model weights or input text. These perturbations, though\nstatistically benign, systematically bypass safety alignment mechanisms and\ninduce harmful behaviors during inference. We propose Search based Embedding\nPoisoning(SEP), a practical, model agnostic framework that introduces carefully\noptimized perturbations into embeddings associated with high risk tokens. SEP\nleverages a predictable linear transition in model responses, from refusal to\nharmful output to semantic deviation to identify a narrow perturbation window\nthat evades alignment safeguards. Evaluated across six aligned LLMs, SEP\nachieves an average attack success rate of 96.43% while preserving benign task\nperformance and evading conventional detection mechanisms. Our findings reveal\na critical oversight in deployment security and emphasize the urgent need for\nembedding level integrity checks in future LLM defense strategies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u5d4c\u5165\u5c42\u653b\u51fb\u65b9\u6cd5SEP\uff0c\u901a\u8fc7\u5728\u5d4c\u5165\u5c42\u6ce8\u5165\u5fae\u5c0f\u6270\u52a8\u6765\u7ed5\u8fc7LLM\u7684\u5b89\u5168\u5bf9\u9f50\u673a\u5236\uff0c\u653b\u51fb\u6210\u529f\u7387\u9ad8\u8fbe96.43%\uff0c\u63ed\u793a\u4e86\u90e8\u7f72\u5b89\u5168\u7684\u5173\u952e\u6f0f\u6d1e\u3002", "motivation": "\u73b0\u6709\u5e73\u53f0\u7684\u5b89\u5168\u626b\u63cf\u65e0\u6cd5\u68c0\u6d4b\u5d4c\u5165\u5c42\u7684\u7ec6\u5fae\u64cd\u4f5c\uff0c\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u8981\u7814\u7a76\u90e8\u7f72\u9636\u6bb5\u7684\u653b\u51fb\u65b9\u5f0f\u3002", "method": "\u63d0\u51faSEP\u6846\u67b6\uff0c\u901a\u8fc7\u641c\u7d22\u4f18\u5316\u5728\u9ad8\u98ce\u9669\u8bcd\u5d4c\u5165\u4e2d\u6ce8\u5165\u5fae\u5c0f\u6270\u52a8\uff0c\u5229\u7528\u6a21\u578b\u54cd\u5e94\u7684\u7ebf\u6027\u8f6c\u6362\u7279\u6027\u8bc6\u522b\u53ef\u7ed5\u8fc7\u5b89\u5168\u673a\u5236\u7684\u6270\u52a8\u7a97\u53e3\u3002", "result": "\u57286\u4e2a\u5bf9\u9f50LLM\u4e0a\u6d4b\u8bd5\uff0c\u5e73\u5747\u653b\u51fb\u6210\u529f\u7387\u8fbe96.43%\uff0c\u540c\u65f6\u4fdd\u6301\u826f\u6027\u4efb\u52a1\u6027\u80fd\u5e76\u89c4\u907f\u4f20\u7edf\u68c0\u6d4b\u673a\u5236\u3002", "conclusion": "\u63ed\u793a\u4e86LLM\u90e8\u7f72\u5b89\u5168\u7684\u5173\u952e\u758f\u5ffd\uff0c\u5f3a\u8c03\u672a\u6765\u9632\u5fa1\u7b56\u7565\u4e2d\u9700\u8981\u5d4c\u5165\u5c42\u5b8c\u6574\u6027\u68c0\u67e5\u7684\u7d27\u8feb\u6027\u3002"}}
{"id": "2509.06770", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.06770", "abs": "https://arxiv.org/abs/2509.06770", "authors": ["Shashidhar Reddy Javaji", "Bhavul Gauri", "Zining Zhu"], "title": "Another Turn, Better Output? A Turn-Wise Analysis of Iterative LLM Prompting", "comment": null, "summary": "Large language models (LLMs) are now used in multi-turn workflows, but we\nstill lack a clear way to measure when iteration helps and when it hurts. We\npresent an evaluation framework for iterative refinement that spans ideation,\ncode, and math. Our protocol runs controlled 12-turn conversations per task,\nutilizing a variety of prompts ranging from vague ``improve it'' feedback to\ntargeted steering, and logs per-turn outputs. We score outcomes with\ndomain-appropriate checks (unit tests for code; answer-equivalence plus\nreasoning-soundness for math; originality and feasibility for ideation) and\ntrack turn-level behavior with three families of metrics: semantic movement\nacross turns, turn-to-turn change, and output size growth. Across models and\ntasks, gains are domain-dependent: they arrive early in ideas and code, but in\nmath late turns matter when guided by elaboration. After the first few turns,\nvague feedback often plateaus or reverses correctness, while targeted prompts\nreliably shift the intended quality axis (novelty vs. feasibility in ideation;\nspeed vs. readability in code; in math, elaboration outperforms exploration and\ndrives late-turn gains). We also observe consistent domain patterns: ideation\nmoves more in meaning across turns, code tends to grow in size with little\nsemantic change, and math starts fixed but can break that path with late,\nelaborative iteration.Together, the framework and metrics make iteration\nmeasurable and comparable across models, and signal when to steer, stop, or\nswitch strategies.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bc4\u4f30\u8fed\u4ee3\u7cbe\u7ec6\u5316\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u6d4b\u91cf\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8f6e\u5de5\u4f5c\u6d41\u4e2d\u7684\u8fed\u4ee3\u6548\u679c\uff0c\u53d1\u73b0\u4e0d\u540c\u9886\u57df\u7684\u8fed\u4ee3\u6539\u5584\u6a21\u5f0f\u5b58\u5728\u663e\u8457\u5dee\u5f02", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5df2\u7ecf\u88ab\u5e7f\u6cdb\u7528\u4e8e\u591a\u8f6e\u5de5\u4f5c\u6d41\uff0c\u4f46\u76ee\u524d\u4ecd\u7f3a\u4e4f\u660e\u786e\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u8fed\u4ee3\u5728\u4ec0\u4e48\u60c5\u51b5\u4e0b\u6709\u5e2e\u52a9\u3001\u4ec0\u4e48\u60c5\u51b5\u4e0b\u4f1a\u9020\u6210\u8d1f\u9762\u5f71\u54cd", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u8bc4\u4f30\u534f\u8bae\uff0c\u5728\u6bcf\u4e2a\u4efb\u52a1\u4e0a\u8fdb\u884c12\u8f6e\u7684\u53d7\u63a7\u5bf9\u8bdd\uff0c\u4f7f\u7528\u4ece\u6a21\u7cca\"\u6539\u5584\u5b83\"\u53cd\u9988\u5230\u6709\u76ee\u6807\u5bfc\u5411\u7684\u5404\u79cd\u63d0\u793a\u7b56\u7565\uff0c\u5e76\u8bb0\u5f55\u6bcf\u8f6e\u8f93\u51fa\u3002\u901a\u8fc7\u9886\u57df\u9002\u5b9c\u7684\u68c0\u67e5\u6765\u8bc4\u5206\u7ed3\u679c\uff08\u4ee3\u7801\u7684\u5355\u5143\u6d4b\u8bd5\uff1b\u6570\u5b66\u7684\u7b54\u6848\u7b49\u6548\u6027\u52a0\u63a8\u7406\u5408\u7406\u6027\uff1b\u521b\u610f\u7684\u539f\u521b\u6027\u548c\u53ef\u884c\u6027\uff09", "result": "\u5728\u4e0d\u540c\u6a21\u578b\u548c\u4efb\u52a1\u4e2d\uff0c\u6536\u76ca\u5177\u6709\u9886\u57df\u4f9d\u8d56\u6027\uff1a\u5728\u60f3\u6cd5\u548c\u4ee3\u7801\u4e2d\u6536\u76ca\u6765\u5f97\u65e9\uff0c\u800c\u5728\u6570\u5b66\u4e2d\u540e\u671f\u8f6e\u6b21\u5728\u8be6\u7ec6\u8bf4\u660e\u7684\u5bfc\u5411\u4e0b\u91cd\u8981\u3002\u6a21\u7cca\u53cd\u9988\u7ecf\u5e38\u5728\u524d\u51e0\u8f6e\u540e\u5e73\u53f0\u5316\u6216\u9006\u8f6c\u6b63\u786e\u6027\uff0c\u800c\u6709\u76ee\u6807\u7684\u63d0\u793a\u53ef\u9760\u5730\u6539\u53d8\u9884\u671f\u8d28\u91cf\u8f74", "conclusion": "\u8be5\u6846\u67b6\u548c\u6307\u6807\u4f7f\u5f97\u8fed\u4ee3\u53ef\u4ee5\u5728\u4e0d\u540c\u6a21\u578b\u4e4b\u95f4\u8fdb\u884c\u6d4b\u91cf\u548c\u6bd4\u8f83\uff0c\u5e76\u4e3a\u4f55\u65f6\u5bfc\u822a\u3001\u505c\u6b62\u6216\u5207\u6362\u7b56\u7565\u63d0\u4f9b\u4fe1\u53f7"}}
{"id": "2509.06368", "categories": ["cs.CR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.06368", "abs": "https://arxiv.org/abs/2509.06368", "authors": ["Kunlin Cai", "Jinghuai Zhang", "Ying Li", "Zhiyuan Wang", "Xun Chen", "Tianshi Li", "Yuan Tian"], "title": "From Perception to Protection: A Developer-Centered Study of Security and Privacy Threats in Extended Reality (XR)", "comment": "NDSS 2026", "summary": "The immersive nature of XR introduces a fundamentally different set of\nsecurity and privacy (S&P) challenges due to the unprecedented user\ninteractions and data collection that traditional paradigms struggle to\nmitigate. As the primary architects of XR applications, developers play a\ncritical role in addressing novel threats. However, to effectively support\ndevelopers, we must first understand how they perceive and respond to different\nthreats. Despite the growing importance of this issue, there is a lack of\nin-depth, threat-aware studies that examine XR S&P from the developers'\nperspective. To fill this gap, we interviewed 23 professional XR developers\nwith a focus on emerging threats in XR. Our study addresses two research\nquestions aiming to uncover existing problems in XR development and identify\nactionable paths forward.\n  By examining developers' perceptions of S&P threats, we found that: (1) XR\ndevelopment decisions (e.g., rich sensor data collection, user-generated\ncontent interfaces) are closely tied to and can amplify S&P threats, yet\ndevelopers are often unaware of these risks, resulting in cognitive biases in\nthreat perception; and (2) limitations in existing mitigation methods, combined\nwith insufficient strategic, technical, and communication support, undermine\ndevelopers' motivation, awareness, and ability to effectively address these\nthreats. Based on these findings, we propose actionable and stakeholder-aware\nrecommendations to improve XR S&P throughout the XR development process. This\nwork represents the first effort to undertake a threat-aware,\ndeveloper-centered study in the XR domain -- an area where the immersive,\ndata-rich nature of the XR technology introduces distinctive challenges.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u8bbf\u8c0823\u540dXR\u5f00\u53d1\u8005\uff0c\u9996\u6b21\u4ece\u5f00\u53d1\u8005\u89c6\u89d2\u5206\u6790XR\u5b89\u5168\u9690\u79c1\u5a01\u80c1\u8ba4\u77e5\uff0c\u53d1\u73b0\u5f00\u53d1\u8005\u5b58\u5728\u8ba4\u77e5\u504f\u5dee\u4e14\u7f3a\u4e4f\u6709\u6548\u652f\u6301\uff0c\u63d0\u51fa\u4e86\u6539\u8fdbXR\u5f00\u53d1\u8fc7\u7a0b\u5b89\u5168\u9690\u79c1\u7684\u5efa\u8bae", "motivation": "XR\u6280\u672f\u56e0\u5176\u6c89\u6d78\u6027\u548c\u6570\u636e\u6536\u96c6\u7279\u6027\u5e26\u6765\u4e86\u72ec\u7279\u7684\u5b89\u5168\u9690\u79c1\u6311\u6218\uff0c\u5f00\u53d1\u8005\u4f5c\u4e3a\u4e3b\u8981\u6784\u5efa\u8005\u5bf9\u6b64\u8ba4\u77e5\u4e0d\u8db3\uff0c\u4f46\u7f3a\u4e4f\u4ece\u5f00\u53d1\u8005\u89c6\u89d2\u7684\u6df1\u5165\u5a01\u80c1\u7814\u7a76", "method": "\u8bbf\u8c0823\u540d\u4e13\u4e1aXR\u5f00\u53d1\u8005\uff0c\u805a\u7126XR\u65b0\u5174\u5a01\u80c1\uff0c\u7814\u7a76XR\u5f00\u53d1\u4e2d\u7684\u73b0\u6709\u95ee\u9898\u548c\u53ef\u884c\u7684\u6539\u8fdb\u8def\u5f84", "result": "\u53d1\u73b0XR\u5f00\u53d1\u51b3\u7b56\u4f1a\u653e\u5927\u5b89\u5168\u9690\u79c1\u5a01\u80c1\u4f46\u5f00\u53d1\u8005\u5e38\u65e0\u610f\u8bc6\uff0c\u73b0\u6709\u7f13\u89e3\u65b9\u6cd5\u6709\u9650\u4e14\u652f\u6301\u4e0d\u8db3\u524a\u5f31\u4e86\u5f00\u53d1\u8005\u5e94\u5bf9\u5a01\u80c1\u7684\u52a8\u529b\u548c\u80fd\u529b", "conclusion": "\u63d0\u51fa\u4e86\u9488\u5bf9\u5229\u76ca\u76f8\u5173\u8005\u7684\u53ef\u884c\u5efa\u8bae\u4ee5\u6539\u8fdbXR\u5f00\u53d1\u5168\u8fc7\u7a0b\u7684\u5b89\u5168\u9690\u79c1\u4fdd\u62a4\uff0c\u8fd9\u662f\u9996\u4e2aXR\u9886\u57df\u5a01\u80c1\u611f\u77e5\u7684\u5f00\u53d1\u8005\u4e2d\u5fc3\u7814\u7a76"}}
{"id": "2509.06822", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.06822", "abs": "https://arxiv.org/abs/2509.06822", "authors": ["Chenyang Zhu", "Spencer Hong", "Jingyu Wu", "Kushal Chawla", "Charlotte Tang", "Youbing Yin", "Nathan Wolfe", "Erin Babinsky", "Daben Liu"], "title": "RAFFLES: Reasoning-based Attribution of Faults for LLM Systems", "comment": null, "summary": "We have reached a critical roadblock in the development and enhancement of\nlong-horizon, multi-component LLM agentic systems: it is incredibly tricky to\nidentify where these systems break down and why. Evaluation capabilities that\ncurrently exist today (e.g., single pass LLM-as-a-judge) are limited in that\nthey often focus on individual metrics or capabilities, end-to-end outcomes,\nand are narrowly grounded on the preferences of humans. We argue that to match\nthe agentic capabilities, evaluation frameworks must also be able to reason,\nprobe, iterate, and understand the complex logic passing through these systems\nover long horizons. In this paper, we present RAFFLES - an evaluation\narchitecture that incorporates reasoning and iterative refinement.\nSpecifically, RAFFLES operates as an iterative, multi-component pipeline, using\na central Judge to systematically investigate faults and a set of specialized\nEvaluators to assess not only the system's components but also the quality of\nthe reasoning by the Judge itself, thereby building a history of hypotheses. We\ntested RAFFLES against several baselines on the Who&When dataset, a benchmark\ndesigned to diagnose the \"who\" (agent) and \"when\" (step) of a system's failure.\nRAFFLES outperforms these baselines, achieving an agent-step fault pair\naccuracy of over 43% on the Algorithmically-Generated dataset (a substantial\nincrease from the previously published best of 16.6%) and over 20% on the\nHand-Crafted dataset (surpassing the previously published best of 8.8%). These\nresults demonstrate a key step towards introducing automated fault detection\nfor autonomous systems over labor-intensive manual human review.", "AI": {"tldr": "RAFFLES\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u957f\u65f6\u7a0b\u591a\u7ec4\u4ef6LLM\u4ee3\u7406\u7cfb\u7edf\u7684\u8fed\u4ee3\u5f0f\u8bc4\u4f30\u67b6\u6784\uff0c\u901a\u8fc7\u63a8\u7406\u548c\u8fed\u4ee3\u7cbe\u5316\u6765\u8bc6\u522b\u7cfb\u7edf\u6545\u969c\u70b9\u548c\u539f\u56e0\uff0c\u5728Who&When\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u8d85\u8d8a\u4e86\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524dLLM\u4ee3\u7406\u7cfb\u7edf\u7684\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4e3b\u8981\u5173\u6ce8\u5355\u4e00\u6307\u6807\u3001\u7aef\u5230\u7aef\u7ed3\u679c\u548c\u4eba\u7c7b\u504f\u597d\uff0c\u96be\u4ee5\u8bc6\u522b\u957f\u65f6\u7a0b\u591a\u7ec4\u4ef6\u7cfb\u7edf\u4e2d\u7684\u5177\u4f53\u6545\u969c\u70b9\u548c\u539f\u56e0\u3002", "method": "RAFFLES\u91c7\u7528\u8fed\u4ee3\u5f0f\u591a\u7ec4\u4ef6\u6d41\u6c34\u7ebf\u67b6\u6784\uff0c\u5305\u542b\u4e00\u4e2a\u4e2d\u592eJudge\u7cfb\u7edf\u6027\u5730\u8c03\u67e5\u6545\u969c\uff0c\u4ee5\u53ca\u4e00\u7ec4\u4e13\u95e8\u7684Evaluators\u8bc4\u4f30\u7cfb\u7edf\u7ec4\u4ef6\u548cJudge\u81ea\u8eab\u7684\u63a8\u7406\u8d28\u91cf\uff0c\u5efa\u7acb\u5047\u8bbe\u5386\u53f2\u3002", "result": "\u5728Who&When\u6570\u636e\u96c6\u4e0a\uff0cRAFFLES\u5728\u7b97\u6cd5\u751f\u6210\u6570\u636e\u96c6\u4e0a\u8fbe\u523043%\u7684\u4ee3\u7406-\u6b65\u9aa4\u6545\u969c\u5bf9\u51c6\u786e\u7387\uff08\u4e4b\u524d\u6700\u4f73\u4e3a16.6%\uff09\uff0c\u5728\u624b\u5de5\u5236\u4f5c\u6570\u636e\u96c6\u4e0a\u8fbe\u523020%\u51c6\u786e\u7387\uff08\u4e4b\u524d\u6700\u4f73\u4e3a8.8%\uff09\u3002", "conclusion": "RAFFLES\u4ee3\u8868\u4e86\u5411\u81ea\u52a8\u5316\u6545\u969c\u68c0\u6d4b\u8fc8\u51fa\u7684\u5173\u952e\u4e00\u6b65\uff0c\u80fd\u591f\u66ff\u4ee3\u52b3\u52a8\u5bc6\u96c6\u578b\u7684\u4eba\u5de5\u5ba1\u67e5\uff0c\u663e\u8457\u63d0\u5347\u5bf9\u81ea\u4e3b\u7cfb\u7edf\u7684\u6545\u969c\u8bca\u65ad\u80fd\u529b\u3002"}}
{"id": "2509.06504", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.06504", "abs": "https://arxiv.org/abs/2509.06504", "authors": ["Hailong Chang", "Guozhu Meng", "Shuhui Xiao", "Kai Chen", "Kun Sun", "Yilin Li"], "title": "When Code Crosses Borders: A Security-Centric Evaluation of LLM-based Code Translation", "comment": null, "summary": "With the growing demand for cross-language codebase migration, evaluating\nLLMs' security implications in translation tasks has become critical. Existing\nevaluations primarily focus on syntactic or functional correctness at the\nfunction level, neglecting the critical dimension of security.\n  To enable security evaluation, we construct STED (Security-centric\nTranslation Evaluation Dataset), the first dataset specifically designed for\nevaluating the security implications of LLM-based code translation. It\ncomprises 720 security-related code samples across five programming languages\nand nine high-impact CWE categories, sourced from CVE/NVD and manually verified\nfor translation tasks. Our evaluation framework consists of two independent\nassessment modules: (1) rigorous evaluation by security researchers, and (2)\nautomated analysis via LLM-as-a-judge. Together they evaluate three critical\naspects: functional correctness, vulnerability preservation, and vulnerability\nintroduction rates.\n  Our large-scale evaluation of five state-of-the-art LLMs across 6,000\ntranslation instances reveals significant security degradation, with 28.6-45%\nof translations introducing new vulnerabilities--particularly for web-related\nflaws like input validation, where LLMs show consistent weaknesses.\nFurthermore, we develop a Retrieval-Augmented Generation (RAG)-based mitigation\nstrategy that reduces translation-induced vulnerabilities by 32.8%, showing the\npotential of knowledge-enhanced prompting.", "AI": {"tldr": "STED\u662f\u9996\u4e2a\u4e13\u95e8\u8bc4\u4f30LLM\u4ee3\u7801\u7ffb\u8bd1\u5b89\u5168\u6027\u7684\u6570\u636e\u96c6\uff0c\u5305\u542b720\u4e2a\u5b89\u5168\u76f8\u5173\u4ee3\u7801\u6837\u672c\u3002\u8bc4\u4f30\u53d1\u73b028.6-45%\u7684\u7ffb\u8bd1\u4f1a\u5f15\u5165\u65b0\u6f0f\u6d1e\uff0c\u7279\u522b\u662f\u8f93\u5165\u9a8c\u8bc1\u7b49web\u76f8\u5173\u7f3a\u9677\u3002\u57fa\u4e8eRAG\u7684\u7f13\u89e3\u7b56\u7565\u53ef\u5c06\u7ffb\u8bd1\u5f15\u8d77\u7684\u6f0f\u6d1e\u51cf\u5c1132.8%\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u8bed\u6cd5\u6216\u529f\u80fd\u6b63\u786e\u6027\uff0c\u5ffd\u89c6\u4e86\u4ee3\u7801\u7ffb\u8bd1\u4e2d\u7684\u5b89\u5168\u7ef4\u5ea6\uff0c\u9700\u8981\u4e13\u95e8\u7684\u5b89\u5168\u8bc4\u4f30\u6570\u636e\u96c6\u548c\u65b9\u6cd5\u3002", "method": "\u6784\u5efaSTED\u6570\u636e\u96c6\uff085\u79cd\u7f16\u7a0b\u8bed\u8a00\uff0c9\u4e2aCWE\u7c7b\u522b\uff09\uff0c\u91c7\u7528\u5b89\u5168\u7814\u7a76\u4eba\u5458\u4eba\u5de5\u8bc4\u4f30\u548cLLM\u81ea\u52a8\u5316\u8bc4\u4f30\u7684\u53cc\u91cd\u6846\u67b6\uff0c\u8bc4\u4f30\u529f\u80fd\u6b63\u786e\u6027\u3001\u6f0f\u6d1e\u4fdd\u7559\u548c\u6f0f\u6d1e\u5f15\u5165\u7387\u3002", "result": "\u5927\u89c4\u6a21\u8bc4\u4f30\u663e\u793a28.6-45%\u7684\u7ffb\u8bd1\u4f1a\u5f15\u5165\u65b0\u6f0f\u6d1e\uff0c\u7279\u522b\u662f\u5728\u8f93\u5165\u9a8c\u8bc1\u7b49web\u76f8\u5173\u7f3a\u9677\u65b9\u9762\u8868\u73b0\u8f83\u5dee\u3002RAG\u7f13\u89e3\u7b56\u7565\u53ef\u51cf\u5c1132.8%\u7684\u7ffb\u8bd1\u5f15\u8d77\u6f0f\u6d1e\u3002", "conclusion": "LLM\u4ee3\u7801\u7ffb\u8bd1\u5b58\u5728\u4e25\u91cd\u7684\u5b89\u5168\u9000\u5316\u95ee\u9898\uff0c\u9700\u8981\u4e13\u95e8\u7684\u5b89\u5168\u8bc4\u4f30\u548c\u7f13\u89e3\u7b56\u7565\uff0c\u77e5\u8bc6\u589e\u5f3a\u63d0\u793a\u5177\u6709\u6539\u5584\u6f5c\u529b\u3002"}}
{"id": "2509.06861", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.06861", "abs": "https://arxiv.org/abs/2509.06861", "authors": ["James Xu Zhao", "Bryan Hooi", "See-Kiong Ng"], "title": "Test-Time Scaling in Reasoning Models Is Not Effective for Knowledge-Intensive Tasks Yet", "comment": "20 pages, 4 figures, 6 tables", "summary": "Test-time scaling increases inference-time computation by allowing models to\ngenerate long reasoning chains, and has shown strong performance across many\ndomains. However, in this work, we show that this approach is not yet effective\nfor knowledge-intensive tasks, where high factual accuracy and low\nhallucination rates are essential. We conduct a comprehensive evaluation of\ntest-time scaling using 12 reasoning models on two knowledge-intensive\nbenchmarks. Our results reveal that increasing test-time computation does not\nconsistently improve accuracy and, in many cases, it even leads to more\nhallucinations. We then analyze how extended reasoning affects hallucination\nbehavior. We find that reduced hallucinations often result from the model\nchoosing to abstain after thinking more, rather than from improved factual\nrecall. Conversely, for some models, longer reasoning encourages attempts on\npreviously unanswered questions, many of which result in hallucinations. Case\nstudies show that extended reasoning can induce confirmation bias, leading to\noverconfident hallucinations. Despite these limitations, we observe that\ncompared to non-thinking, enabling thinking remains beneficial. Code and data\nare available at https://github.com/XuZhao0/tts-knowledge", "AI": {"tldr": "\u8c28\u614e\u4f7f\u7528\u6d4b\u8bd5\u65f6\u6269\u5c55\uff0c\u5728\u77e5\u8bc6\u5bc6\u96c6\u4efb\u52a1\u4e2d\u53ef\u80fd\u5bfc\u81f4\u66f4\u591a\u5e7b\u89c9\u800c\u975e\u63d0\u9ad8\u51c6\u786e\u6027", "motivation": "\u8bc4\u4f30\u6d4b\u8bd5\u65f6\u6269\u5c55\u6280\u672f\u5728\u77e5\u8bc5\u5bc6\u96c6\u4efb\u52a1\u4e2d\u7684\u6548\u679c\uff0c\u56e0\u4e3a\u8fd9\u7c7b\u4efb\u52a1\u9700\u8981\u9ad8\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u4f4e\u5e7b\u89c9\u7387", "method": "\u4f7f\u752812\u4e2a\u63a8\u7406\u6a21\u578b\u57282\u4e2a\u77e5\u8bc6\u5bc6\u96c6\u6d4b\u8bd5\u96c6\u4e0a\u8fdb\u884c\u7efc\u5408\u8bc4\u4f30\uff0c\u5206\u6790\u6269\u5c55\u63a8\u7406\u5bf9\u5e7b\u89c9\u884c\u4e3a\u7684\u5f71\u54cd", "result": "\u589e\u52a0\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u5e76\u4e0d\u7a33\u5b9a\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u53cd\u800c\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\u5bfc\u81f4\u66f4\u591a\u5e7b\u89c9\uff0c\u5e7b\u89c9\u51cf\u5c11\u591a\u662f\u7531\u4e8e\u6a21\u578b\u9009\u62e9\u653e\u5f03\u7b54\u9898", "conclusion": "\u867d\u7136\u6269\u5c55\u63a8\u7406\u5b58\u5728\u9650\u5236\uff0c\u4f46\u4e0e\u4e0d\u8fdb\u884c\u601d\u8003\u76f8\u6bd4\uff0c\u542f\u7528\u601d\u8003\u4ecd\u7136\u6709\u76ca"}}
{"id": "2509.06509", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.06509", "abs": "https://arxiv.org/abs/2509.06509", "authors": ["Zilong Wang", "Gideon Mohr", "Klaus von Gleissenthall", "Jan Reineke", "Marco Guarnieri"], "title": "Synthesis of Sound and Precise Leakage Contracts for Open-Source RISC-V Processors", "comment": "Technical report containing full formalization and proofs of all\n  results. A short version of this report (with the same title) appears in the\n  proceedings of the 32nd ACM SIGSAC Conference on Computer and Communication\n  Security (CCS 2025)", "summary": "Leakage contracts have been proposed as a new security abstraction at the\ninstruction set architecture level. Leakage contracts aim to capture the\ninformation that processors may leak via microarchitectural side channels.\nRecently, the first tools have emerged to verify whether a processor satisfies\na given contract. However, coming up with a contract that is both sound and\nprecise for a given processor is challenging, time-consuming, and error-prone,\nas it requires in-depth knowledge of the timing side channels introduced by\nmicroarchitectural optimizations.\n  In this paper, we address this challenge by proposing LeaSyn, the first tool\nfor automatically synthesizing leakage contracts that are both sound and\nprecise for processor designs at register-transfer level. Starting from a\nuser-provided contract template that captures the space of possible contracts,\nLeaSyn automatically constructs a contract, alternating between contract\nsynthesis, which ensures precision based on an empirical characterization of\nthe processor's leaks, and contract verification, which ensures soundness.\n  Using LeaSyn, we automatically synthesize contracts for six open-source\nRISC-V CPUs for a variety of contract templates. Our experiments indicate that\nLeaSyn's contracts are sound and more precise (i.e., represent the actual leaks\nin the target processor more faithfully) than contracts constructed by existing\napproaches.", "AI": {"tldr": "LeaSyn\u662f\u9996\u4e2a\u81ea\u52a8\u5408\u6210\u5904\u7406\u5668\u6cc4\u6f0f\u5408\u7ea6\u7684\u5de5\u5177\uff0c\u80fd\u591f\u4e3aRTL\u7ea7\u5904\u7406\u5668\u8bbe\u8ba1\u751f\u6210\u65e2\u53ef\u9760\u53c8\u7cbe\u786e\u7684\u6cc4\u6f0f\u5408\u7ea6\uff0c\u89e3\u51b3\u4e86\u624b\u52a8\u5236\u5b9a\u5408\u7ea6\u7684\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u5904\u7406\u5668\u6cc4\u6f0f\u5408\u7ea6\u7684\u5236\u5b9a\u9700\u8981\u6df1\u5165\u4e86\u89e3\u5fae\u67b6\u6784\u4f18\u5316\u5f15\u5165\u7684\u65f6\u5e8f\u4fa7\u4fe1\u9053\uff0c\u8fc7\u7a0b\u8017\u65f6\u3001\u6613\u9519\u4e14\u5177\u6709\u6311\u6218\u6027\u3002", "method": "LeaSyn\u4ece\u7528\u6237\u63d0\u4f9b\u7684\u5408\u7ea6\u6a21\u677f\u51fa\u53d1\uff0c\u901a\u8fc7\u5408\u7ea6\u5408\u6210\u548c\u9a8c\u8bc1\u7684\u4ea4\u66ff\u8fc7\u7a0b\uff0c\u57fa\u4e8e\u5904\u7406\u5668\u6cc4\u6f0f\u7684\u7ecf\u9a8c\u7279\u5f81\u786e\u4fdd\u7cbe\u786e\u6027\uff0c\u540c\u65f6\u4fdd\u8bc1\u53ef\u9760\u6027\u3002", "result": "\u5728\u516d\u4e2a\u5f00\u6e90RISC-V CPU\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLeaSyn\u751f\u6210\u7684\u5408\u7ea6\u53ef\u9760\u4e14\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u7cbe\u786e\uff0c\u80fd\u66f4\u771f\u5b9e\u5730\u53cd\u6620\u76ee\u6807\u5904\u7406\u5668\u7684\u5b9e\u9645\u6cc4\u6f0f\u3002", "conclusion": "LeaSyn\u6210\u529f\u5b9e\u73b0\u4e86\u5904\u7406\u5668\u6cc4\u6f0f\u5408\u7ea6\u7684\u81ea\u52a8\u5408\u6210\uff0c\u4e3a\u5904\u7406\u5668\u5b89\u5168\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.06917", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.06917", "abs": "https://arxiv.org/abs/2509.06917", "authors": ["Jiacheng Miao", "Joe R. Davis", "Jonathan K. Pritchard", "James Zou"], "title": "Paper2Agent: Reimagining Research Papers As Interactive and Reliable AI Agents", "comment": null, "summary": "We introduce Paper2Agent, an automated framework that converts research\npapers into AI agents. Paper2Agent transforms research output from passive\nartifacts into active systems that can accelerate downstream use, adoption, and\ndiscovery. Conventional research papers require readers to invest substantial\neffort to understand and adapt a paper's code, data, and methods to their own\nwork, creating barriers to dissemination and reuse. Paper2Agent addresses this\nchallenge by automatically converting a paper into an AI agent that acts as a\nknowledgeable research assistant. It systematically analyzes the paper and the\nassociated codebase using multiple agents to construct a Model Context Protocol\n(MCP) server, then iteratively generates and runs tests to refine and robustify\nthe resulting MCP. These paper MCPs can then be flexibly connected to a chat\nagent (e.g. Claude Code) to carry out complex scientific queries through\nnatural language while invoking tools and workflows from the original paper. We\ndemonstrate Paper2Agent's effectiveness in creating reliable and capable paper\nagents through in-depth case studies. Paper2Agent created an agent that\nleverages AlphaGenome to interpret genomic variants and agents based on ScanPy\nand TISSUE to carry out single-cell and spatial transcriptomics analyses. We\nvalidate that these paper agents can reproduce the original paper's results and\ncan correctly carry out novel user queries. By turning static papers into\ndynamic, interactive AI agents, Paper2Agent introduces a new paradigm for\nknowledge dissemination and a foundation for the collaborative ecosystem of AI\nco-scientists.", "AI": {"tldr": "Paper2Agent\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u53ef\u5c06\u7814\u7a76\u8bba\u6587\u8f6c\u6362\u4e3aAI\u4ee3\u7406\uff0c\u4f7f\u9759\u6001\u8bba\u6587\u53d8\u6210\u52a8\u6001\u4ea4\u4e92\u5f0f\u7814\u7a76\u52a9\u624b\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u5904\u7406\u590d\u6742\u79d1\u5b66\u67e5\u8be2\u3002", "motivation": "\u4f20\u7edf\u7814\u7a76\u8bba\u6587\u9700\u8981\u8bfb\u8005\u6295\u5165\u5927\u91cf\u7cbe\u529b\u6765\u7406\u89e3\u548c\u9002\u5e94\u4ee3\u7801\u3001\u6570\u636e\u548c\u65b9\u6cd5\uff0c\u8fd9\u9020\u6210\u4e86\u4f20\u64ad\u548c\u91cd\u7528\u7684\u969c\u788d\u3002Paper2Agent\u65e8\u5728\u5c06\u7814\u7a76\u8f93\u51fa\u4ece\u88ab\u52a8\u4ea7\u7269\u8f6c\u53d8\u4e3a\u4e3b\u52a8\u7cfb\u7edf\u3002", "method": "\u4f7f\u7528\u591a\u4ee3\u7406\u7cfb\u7edf\u5206\u6790\u8bba\u6587\u548c\u76f8\u5173\u4ee3\u7801\u5e93\uff0c\u6784\u5efa\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae(MCP)\u670d\u52a1\u5668\uff0c\u901a\u8fc7\u8fed\u4ee3\u751f\u6210\u548c\u8fd0\u884c\u6d4b\u8bd5\u6765\u4f18\u5316MCP\u3002\u7136\u540e\u5c06\u8bba\u6587MCP\u4e0e\u804a\u5929\u4ee3\u7406\u8fde\u63a5\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u6267\u884c\u79d1\u5b66\u67e5\u8be2\u3002", "result": "\u6210\u529f\u521b\u5efa\u4e86\u5229\u7528AlphaGenome\u89e3\u91ca\u57fa\u56e0\u7ec4\u53d8\u5f02\u7684\u4ee3\u7406\uff0c\u4ee5\u53ca\u57fa\u4e8eScanPy\u548cTISSUE\u7684\u5355\u7ec6\u80de\u548c\u7a7a\u95f4\u8f6c\u5f55\u7ec4\u5b66\u5206\u6790\u4ee3\u7406\uff0c\u80fd\u591f\u590d\u73b0\u539f\u59cb\u8bba\u6587\u7ed3\u679c\u5e76\u6b63\u786e\u5904\u7406\u65b0\u7528\u6237\u67e5\u8be2\u3002", "conclusion": "Paper2Agent\u901a\u8fc7\u5c06\u9759\u6001\u8bba\u6587\u8f6c\u5316\u4e3a\u52a8\u6001\u4ea4\u4e92\u5f0fAI\u4ee3\u7406\uff0c\u4e3a\u77e5\u8bc6\u4f20\u64ad\u5f15\u5165\u4e86\u65b0\u8303\u5f0f\uff0c\u5e76\u4e3aAI\u534f\u4f5c\u79d1\u5b66\u5bb6\u751f\u6001\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2509.06548", "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.LG", "I.2.6; K.6.5"], "pdf": "https://arxiv.org/pdf/2509.06548", "abs": "https://arxiv.org/abs/2509.06548", "authors": ["Jack Wilkie", "Hanan Hindy", "Ivan Andonovic", "Christos Tachtatzis", "Robert Atkinson"], "title": "Signal-Based Malware Classification Using 1D CNNs", "comment": "Accepted for publication in Springer Cybersecurity (2025)", "summary": "Malware classification is a contemporary and ongoing challenge in\ncyber-security: modern obfuscation techniques are able to evade traditional\nstatic analysis, while dynamic analysis is too resource intensive to be\ndeployed at a large scale. One prominent line of research addresses these\nlimitations by converting malware binaries into 2D images by heuristically\nreshaping them into a 2D grid before resizing using Lanczos resampling. These\nimages can then be classified based on their textural information using\ncomputer vision approaches. While this approach can detect obfuscated malware\nmore effectively than static analysis, the process of converting files into 2D\nimages results in significant information loss due to both quantisation noise,\ncaused by rounding to integer pixel values, and the introduction of 2D\ndependencies which do not exist in the original data. This loss of signal\nlimits the classification performance of the downstream model. This work\naddresses these weaknesses by instead resizing the files into 1D signals which\navoids the need for heuristic reshaping, and additionally these signals do not\nsuffer from quantisation noise due to being stored in a floating-point format.\nIt is shown that existing 2D CNN architectures can be readily adapted to\nclassify these 1D signals for improved performance. Furthermore, a bespoke 1D\nconvolutional neural network, based on the ResNet architecture and\nsqueeze-and-excitation layers, was developed to classify these signals and\nevaluated on the MalNet dataset. It was found to achieve state-of-the-art\nperformance on binary, type, and family level classification with F1 scores of\n0.874, 0.503, and 0.507, respectively, paving the way for future models to\noperate on the proposed signal modality.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u65b9\u6cd5\uff0c\u5c06\u4e8c\u8fdb\u5236\u6587\u4ef6\u8f6c\u6362\u4e3a1D\u4fe1\u53f7\u800c\u4e0d\u662f2D\u56fe\u50cf\uff0c\u907f\u514d\u4e86\u4fe1\u606f\u635f\u5931\u548c\u91cf\u5316\u566a\u58f0\uff0c\u4f7f\u7528\u6539\u8fdb\u76841D CNN\u67b6\u6784\u5728MalNet\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u5206\u7c7b\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u9759\u6001\u5206\u6790\u5bb9\u6613\u88ab\u73b0\u4ee3\u6df7\u6dc6\u6280\u672f\u89c4\u907f\uff0c\u52a8\u6001\u5206\u6790\u8d44\u6e90\u6d88\u8017\u8fc7\u5927\u3002\u73b0\u6709\u76842D\u56fe\u50cf\u8f6c\u6362\u65b9\u6cd5\u4f1a\u5bfc\u81f4\u4fe1\u606f\u635f\u5931\u548c\u91cf\u5316\u566a\u58f0\uff0c\u9650\u5236\u4e86\u5206\u7c7b\u6027\u80fd\u3002", "method": "\u5c06\u6076\u610f\u8f6f\u4ef6\u4e8c\u8fdb\u5236\u6587\u4ef6\u8f6c\u6362\u4e3a1D\u6d6e\u70b9\u4fe1\u53f7\uff0c\u907f\u514d\u4e86\u542f\u53d1\u5f0f\u91cd\u5851\u548c\u91cf\u5316\u566a\u58f0\u3002\u5f00\u53d1\u4e86\u57fa\u4e8eResNet\u67b6\u6784\u548csqueeze-and-excitation\u5c42\u7684\u5b9a\u52361D\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6765\u5206\u7c7b\u8fd9\u4e9b\u4fe1\u53f7\u3002", "result": "\u5728MalNet\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff1a\u4e8c\u8fdb\u5236\u5206\u7c7bF1\u5206\u65700.874\uff0c\u7c7b\u578b\u5206\u7c7b0.503\uff0c\u5bb6\u65cf\u5206\u7c7b0.507\u3002", "conclusion": "1D\u4fe1\u53f7\u8f6c\u6362\u65b9\u6cd5\u4f18\u4e8e\u4f20\u7edf\u76842D\u56fe\u50cf\u8f6c\u6362\uff0c\u4e3a\u672a\u6765\u7684\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u7684\u4fe1\u53f7\u6a21\u6001\u5904\u7406\u65b9\u5f0f\uff0c\u5177\u6709\u66f4\u597d\u7684\u5206\u7c7b\u6027\u80fd\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2509.06942", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.06942", "abs": "https://arxiv.org/abs/2509.06942", "authors": ["Xiangwei Shen", "Zhimin Li", "Zhantao Yang", "Shiyi Zhang", "Yingfang Zhang", "Donghao Li", "Chunyu Wang", "Qinglin Lu", "Yansong Tang"], "title": "Directly Aligning the Full Diffusion Trajectory with Fine-Grained Human Preference", "comment": "15 pages", "summary": "Recent studies have demonstrated the effectiveness of directly aligning\ndiffusion models with human preferences using differentiable reward. However,\nthey exhibit two primary challenges: (1) they rely on multistep denoising with\ngradient computation for reward scoring, which is computationally expensive,\nthus restricting optimization to only a few diffusion steps; (2) they often\nneed continuous offline adaptation of reward models in order to achieve desired\naesthetic quality, such as photorealism or precise lighting effects. To address\nthe limitation of multistep denoising, we propose Direct-Align, a method that\npredefines a noise prior to effectively recover original images from any time\nsteps via interpolation, leveraging the equation that diffusion states are\ninterpolations between noise and target images, which effectively avoids\nover-optimization in late timesteps. Furthermore, we introduce Semantic\nRelative Preference Optimization (SRPO), in which rewards are formulated as\ntext-conditioned signals. This approach enables online adjustment of rewards in\nresponse to positive and negative prompt augmentation, thereby reducing the\nreliance on offline reward fine-tuning. By fine-tuning the FLUX.1.dev model\nwith optimized denoising and online reward adjustment, we improve its\nhuman-evaluated realism and aesthetic quality by over 3x.", "AI": {"tldr": "\u901a\u8fc7\u63d0\u524d\u5b9a\u4e49\u566a\u58f0\u5148\u9a8c\u548c\u8bed\u4e49\u76f8\u5bf9\u504f\u597d\u4f18\u5316\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u4e2d\u591a\u6b65\u53bb\u566a\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u9700\u8981\u79bb\u7ebf\u5956\u52b1\u8c03\u6574\u7684\u95ee\u9898", "motivation": "\u73b0\u6709\u7684\u5bf9\u9f50\u65b9\u6cd5\u4f9d\u8d56\u591a\u6b65\u53bb\u566a\u8ba1\u7b97\u5956\u52b1\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u4e14\u9700\u8981\u79bb\u7ebf\u8fde\u7eed\u8c03\u6574\u5956\u52b1\u6a21\u578b\u6765\u8fbe\u5230\u6717\u6717\u7684\u7f8e\u5b66\u8d28\u91cf", "method": "\u63d0\u51faDirect-Align\u65b9\u6cd5\u901a\u8fc7\u63d0\u524d\u5b9a\u4e49\u566a\u58f0\u5148\u9a8c\u6765\u6062\u590d\u539f\u59cb\u56fe\u50cf\uff0c\u907f\u514d\u540e\u671f\u65f6\u95f4\u6b65\u7684\u8fc7\u5ea6\u4f18\u5316\uff1b\u63d0\u51faSRPO\u65b9\u6cd5\u5c06\u5956\u52b1\u5f62\u5f0f\u5316\u4e3a\u6587\u672c\u6761\u4ef6\u4fe1\u53f7\uff0c\u652f\u6301\u5728\u7ebf\u5956\u52b1\u8c03\u6574", "result": "\u5728FLUX.1.dev\u6a21\u578b\u4e0a\u8fdb\u884c\u7cbe\u7ec6\u8c03\u6574\u540e\uff0c\u4eba\u7c7b\u8bc4\u4f30\u7684\u5b9e\u4f53\u611f\u548c\u7f8e\u5b66\u8d28\u91cf\u63d0\u5347\u4e863\u500d\u4ee5\u4e0a", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5bf9\u9f50\u8fc7\u7a0b\u4e2d\u7684\u8ba1\u7b97\u6548\u7387\u548c\u5956\u52b1\u8c03\u6574\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u8f93\u51fa\u8d28\u91cf"}}
{"id": "2509.06549", "categories": ["cs.CR", "quant-ph"], "pdf": "https://arxiv.org/pdf/2509.06549", "abs": "https://arxiv.org/abs/2509.06549", "authors": ["Timo Glaser", "Alexander May", "Julian Nowakowski"], "title": "Super-Quadratic Quantum Speed-ups and Guessing Many Likely Keys", "comment": null, "summary": "We study the fundamental problem of guessing cryptographic keys, drawn from\nsome non-uniform probability distribution $D$, as e.g. in LPN, LWE or for\npasswords. The optimal classical algorithm enumerates keys in decreasing order\nof likelihood. The optimal quantum algorithm, due to Montanaro (2011), is a\nsophisticated Grover search.\n  We give the first tight analysis for Montanaro's algorithm, showing that its\nruntime is $2^{H_{2/3}(D)/2}$, where $H_{\\alpha}(\\cdot)$ denotes Renyi entropy\nwith parameter $\\alpha$. Interestingly, this is a direct consequence of an\ninformation theoretic result called Arikan's Inequality (1996) -- which has so\nfar been missed in the cryptographic community -- that tightly bounds the\nruntime of classical key guessing by $2^{H_{1/2}(D)}$. Since $H_{2/3}(D) <\nH_{1/2}(D)$ for every non-uniform distribution $D$, we thus obtain a\nsuper-quadratic quantum speed-up $s>2$ over classical key guessing.\n  As another main result, we provide the first thorough analysis of guessing in\na multi-key setting. Specifically, we consider the task of attacking many keys\nsampled independently from some distribution $D$, and aim to guess a fraction\nof them. For product distributions $D = \\chi^n$, we show that any constant\nfraction of keys can be guessed within $2^{H(D)}$ classically and $2 ^{H(D)/2}$\nquantumly per key, where $H(\\chi)$ denotes Shannon entropy. In contrast,\nArikan's Inequality implies that guessing a single key costs $2^{H_{1/2}(D)}$\nclassically and $2^{H_{2/3}(D)/2}$ quantumly. Since $H(D) < H_{2/3}(D) <\nH_{1/2}(D)$, this shows that in a multi-key setting the guessing cost per key\nis substantially smaller than in a single-key setting, both classically and\nquantumly.", "AI": {"tldr": "\u672c\u6587\u5bf9\u91cf\u5b50\u5bc6\u94a5\u731c\u6d4b\u7b97\u6cd5\u8fdb\u884c\u4e86\u9996\u6b21\u7d27\u81f4\u5206\u6790\uff0c\u53d1\u73b0Montanaro\u7b97\u6cd5\u7684\u8fd0\u884c\u65f6\u95f4\u4e3a2^(H_{2/3}(D)/2)\uff0c\u76f8\u6bd4\u7ecf\u5178\u7b97\u6cd5\u76842^(H_{1/2}(D))\u5b9e\u73b0\u4e86\u8d85\u4e8c\u6b21\u91cf\u5b50\u52a0\u901f\u3002\u5728\u591a\u5bc6\u94a5\u573a\u666f\u4e0b\uff0c\u731c\u6d4b\u6bcf\u4e2a\u5bc6\u94a5\u7684\u6210\u672c\u663e\u8457\u964d\u4f4e\u3002", "motivation": "\u7814\u7a76\u4ece\u975e\u5747\u5300\u6982\u7387\u5206\u5e03\u4e2d\u731c\u6d4b\u5bc6\u7801\u5bc6\u94a5\u7684\u57fa\u672c\u95ee\u9898\uff0c\u5206\u6790\u91cf\u5b50\u7b97\u6cd5\u76f8\u6bd4\u7ecf\u5178\u7b97\u6cd5\u7684\u4f18\u52bf\uff0c\u7279\u522b\u662f\u5728\u591a\u5bc6\u94a5\u8bbe\u7f6e\u4e0b\u7684\u6027\u80fd\u8868\u73b0\u3002", "method": "\u4f7f\u7528Arikan\u4e0d\u7b49\u5f0f\u5bf9Montanaro\u91cf\u5b50\u7b97\u6cd5\u8fdb\u884c\u7d27\u81f4\u5206\u6790\uff0c\u57fa\u4e8eRenyi\u71b5\u7406\u8bba\uff0c\u6bd4\u8f83\u5355\u5bc6\u94a5\u548c\u591a\u5bc6\u94a5\u573a\u666f\u4e0b\u7684\u731c\u6d4b\u6210\u672c\u3002", "result": "\u91cf\u5b50\u5bc6\u94a5\u731c\u6d4b\u7b97\u6cd5\u8fd0\u884c\u65f6\u95f4\u4e3a2^(H_{2/3}(D)/2)\uff0c\u7ecf\u5178\u7b97\u6cd5\u4e3a2^(H_{1/2}(D))\uff0c\u91cf\u5b50\u52a0\u901f\u6bd4\u8d85\u8fc72\u3002\u591a\u5bc6\u94a5\u8bbe\u7f6e\u4e0b\u6bcf\u4e2a\u5bc6\u94a5\u7684\u731c\u6d4b\u6210\u672c\u5927\u5e45\u964d\u4f4e\u3002", "conclusion": "\u91cf\u5b50\u7b97\u6cd5\u5728\u5bc6\u94a5\u731c\u6d4b\u95ee\u9898\u4e0a\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u591a\u5bc6\u94a5\u573a\u666f\u8fdb\u4e00\u6b65\u964d\u4f4e\u4e86\u731c\u6d4b\u6210\u672c\uff0c\u8fd9\u5bf9\u5bc6\u7801\u5b89\u5168\u6027\u5206\u6790\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2509.06562", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.06562", "abs": "https://arxiv.org/abs/2509.06562", "authors": ["I. Buchinskiy", "M. Kotov", "A. Ponmaheshkumar", "R. Perumal"], "title": "Marginal sets in semigroups and semirings", "comment": null, "summary": "In 2019, V. A. Roman'kov introduced the concept of marginal sets for groups.\nHe developed a theory of marginal sets and demonstrated how these sets can be\napplied to improve some key exchange schemes. In this paper, we extend his\nideas and introduce the concept of marginal sets for semigroups and semirings.\nFor tropical matrix semigroups and semirings, we describe how some marginal\nsets can be constructed. We apply marginal sets to improve some key exchange\nschemes over semigroups.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86Roman'kov\u7684\u8fb9\u9645\u96c6\u7406\u8bba\uff0c\u5c06\u5176\u4ece\u7fa4\u63a8\u5e7f\u5230\u534a\u7fa4\u548c\u534a\u73af\uff0c\u7279\u522b\u9488\u5bf9\u70ed\u5e26\u77e9\u9635\u534a\u7fa4\u548c\u534a\u73af\u6784\u9020\u8fb9\u9645\u96c6\uff0c\u5e76\u5e94\u7528\u4e8e\u6539\u8fdb\u534a\u7fa4\u4e0a\u7684\u5bc6\u94a5\u4ea4\u6362\u65b9\u6848\u3002", "motivation": "Roman'kov\u57282019\u5e74\u63d0\u51fa\u4e86\u7fa4\u7684\u8fb9\u9645\u96c6\u6982\u5ff5\u5e76\u5e94\u7528\u4e8e\u5bc6\u94a5\u4ea4\u6362\u65b9\u6848\uff0c\u4f46\u8be5\u7406\u8bba\u4ec5\u9650\u4e8e\u7fa4\u7ed3\u6784\u3002\u672c\u6587\u65e8\u5728\u5c06\u8fd9\u4e00\u6982\u5ff5\u6269\u5c55\u5230\u66f4\u4e00\u822c\u7684\u4ee3\u6570\u7ed3\u6784\u2014\u2014\u534a\u7fa4\u548c\u534a\u73af\uff0c\u4ee5\u6269\u5927\u5176\u5e94\u7528\u8303\u56f4\u3002", "method": "\u5c06\u8fb9\u9645\u96c6\u6982\u5ff5\u4ece\u7fa4\u63a8\u5e7f\u5230\u534a\u7fa4\u548c\u534a\u73af\uff0c\u7279\u522b\u9488\u5bf9\u70ed\u5e26\u77e9\u9635\u534a\u7fa4\u548c\u534a\u73af\uff0c\u63cf\u8ff0\u4e86\u5982\u4f55\u6784\u9020\u8fd9\u4e9b\u7ed3\u6784\u4e2d\u7684\u8fb9\u9645\u96c6\u3002", "result": "\u6210\u529f\u5efa\u7acb\u4e86\u534a\u7fa4\u548c\u534a\u73af\u7684\u8fb9\u9645\u96c6\u7406\u8bba\u6846\u67b6\uff0c\u4e3a\u70ed\u5e26\u77e9\u9635\u534a\u7fa4\u548c\u534a\u73af\u63d0\u4f9b\u4e86\u5177\u4f53\u7684\u8fb9\u9645\u96c6\u6784\u9020\u65b9\u6cd5\u3002", "conclusion": "\u8fb9\u9645\u96c6\u7406\u8bba\u53ef\u4ee5\u6709\u6548\u5730\u6269\u5c55\u5230\u534a\u7fa4\u548c\u534a\u73af\u7ed3\u6784\uff0c\u8fd9\u4e00\u6269\u5c55\u4e3a\u6539\u8fdb\u57fa\u4e8e\u534a\u7fa4\u7684\u5bc6\u94a5\u4ea4\u6362\u65b9\u6848\u63d0\u4f9b\u4e86\u65b0\u7684\u6570\u5b66\u5de5\u5177\u548c\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2509.06571", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.06571", "abs": "https://arxiv.org/abs/2509.06571", "authors": ["Tristan Caulfield"], "title": "A Simple Data Exfiltration Game", "comment": null, "summary": "Data exfiltration is a growing problem for business who face costs related to\nthe loss of confidential data as well as potential extortion. This work\npresents a simple game theoretic model of network data exfiltration. In the\nmodel, the attacker chooses the exfiltration route and speed, and the defender\nselects monitoring thresholds to detect unusual activity. The attacker is\nrewarded for exfiltrating data, and the defender tries to minimize the costs of\ndata loss and of responding to alerts.", "AI": {"tldr": "\u57fa\u4e8e\u6e38\u620f\u8bba\u7684\u7f51\u7edc\u6570\u636e\u6cc4\u6f0f\u6a21\u578b\uff0c\u653b\u51fb\u8005\u9009\u62e9\u6cc4\u6f0f\u8def\u5f84\u548c\u901f\u5ea6\uff0c\u9632\u5fa1\u8005\u8bbe\u7f6e\u76d1\u63a7\u9608\u503c\u6765\u6700\u5c0f\u5316\u6570\u636e\u4e22\u5931\u6210\u672c\u548c\u54cd\u5e94\u8b66\u62a5\u6210\u672c\u3002", "motivation": "\u6570\u636e\u6cc4\u6f0f\u95ee\u9898\u5bfc\u81f4\u4f01\u4e1a\u907f\u514d\u673a\u5bc6\u6570\u636e\u4e22\u5931\u548c\u8bb8\u8bc8\u7684\u5de8\u5927\u6210\u672c\uff0c\u9700\u8981\u6709\u6548\u7684\u9632\u5fa1\u7b56\u7565\u3002", "method": "\u5efa\u7acb\u7b80\u5355\u7684\u6e38\u620f\u8bba\u6a21\u578b\uff0c\u653b\u51fb\u8005\u4e0e\u9632\u5fa1\u8005\u5728\u6cc4\u6f0f\u8def\u5f84\u3001\u901f\u5ea6\u548c\u76d1\u63a7\u9608\u503c\u9009\u62e9\u4e0a\u8fdb\u884c\u5bf9\u6297\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\u6765\u5206\u6790\u6570\u636e\u6cc4\u6f0f\u95ee\u9898\u4e2d\u653b\u9632\u53cc\u65b9\u7684\u7b56\u7565\u9009\u62e9\u548c\u6743\u8861\u3002", "conclusion": "\u6e38\u620f\u8bba\u6a21\u578b\u4e3a\u7406\u89e3\u548c\u5e94\u5bf9\u6570\u636e\u6cc4\u6f0f\u98ce\u9669\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5e2e\u52a9\u4f01\u4e1a\u5236\u5b9a\u66f4\u6709\u6548\u7684\u5b89\u5168\u9632\u5fa1\u7b56\u7565\u3002"}}
{"id": "2509.06572", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.06572", "abs": "https://arxiv.org/abs/2509.06572", "authors": ["Shuli Zhao", "Qinsheng Hou", "Zihan Zhan", "Yanhao Wang", "Yuchong Xie", "Yu Guo", "Libo Chen", "Shenghong Li", "Zhi Xue"], "title": "Mind Your Server: A Systematic Study of Parasitic Toolchain Attacks on the MCP Ecosystem", "comment": null, "summary": "Large language models (LLMs) are increasingly integrated with external\nsystems through the Model Context Protocol (MCP), which standardizes tool\ninvocation and has rapidly become a backbone for LLM-powered applications.\nWhile this paradigm enhances functionality, it also introduces a fundamental\nsecurity shift: LLMs transition from passive information processors to\nautonomous orchestrators of task-oriented toolchains, expanding the attack\nsurface, elevating adversarial goals from manipulating single outputs to\nhijacking entire execution flows. In this paper, we reveal a new class of\nattacks, Parasitic Toolchain Attacks, instantiated as MCP Unintended Privacy\nDisclosure (MCP-UPD). These attacks require no direct victim interaction;\ninstead, adversaries embed malicious instructions into external data sources\nthat LLMs access during legitimate tasks. The malicious logic infiltrates the\ntoolchain and unfolds in three phases: Parasitic Ingestion, Privacy Collection,\nand Privacy Disclosure, culminating in stealthy exfiltration of private data.\nOur root cause analysis reveals that MCP lacks both context-tool isolation and\nleast-privilege enforcement, enabling adversarial instructions to propagate\nunchecked into sensitive tool invocations. To assess the severity, we design\nMCP-SEC and conduct the first large-scale security census of the MCP ecosystem,\nanalyzing 12,230 tools across 1,360 servers. Our findings show that the MCP\necosystem is rife with exploitable gadgets and diverse attack methods,\nunderscoring systemic risks in MCP platforms and the urgent need for defense\nmechanisms in LLM-integrated environments.", "AI": {"tldr": "\u8bba\u6587\u63ed\u793a\u4e86MCP\u534f\u8bae\u4e2d\u7684\u5bc4\u751f\u5de5\u5177\u94fe\u653b\u51fb(MCP-UPD)\uff0c\u653b\u51fb\u8005\u901a\u8fc7\u6c61\u67d3\u5916\u90e8\u6570\u636e\u6e90\uff0c\u8ba9LLM\u5728\u6b63\u5e38\u4efb\u52a1\u4e2d\u6267\u884c\u6076\u610f\u6307\u4ee4\uff0c\u5bfc\u81f4\u9690\u79c1\u6570\u636e\u6cc4\u9732\u3002", "motivation": "\u968f\u7740LLM\u901a\u8fc7MCP\u534f\u8bae\u4e0e\u5916\u90e8\u7cfb\u7edf\u96c6\u6210\uff0c\u5b89\u5168\u8303\u5f0f\u53d1\u751f\u6839\u672c\u8f6c\u53d8\uff1aLLM\u4ece\u88ab\u52a8\u4fe1\u606f\u5904\u7406\u5668\u53d8\u4e3a\u81ea\u4e3b\u7f16\u6392\u5de5\u5177\u94fe\u7684\u534f\u8c03\u5668\uff0c\u6269\u5927\u4e86\u653b\u51fb\u9762\uff0c\u653b\u51fb\u76ee\u6807\u4ece\u64cd\u7eb5\u5355\u4e2a\u8f93\u51fa\u5347\u7ea7\u5230\u52ab\u6301\u6574\u4e2a\u6267\u884c\u6d41\u7a0b\u3002", "method": "\u63d0\u51fa\u5bc4\u751f\u5de5\u5177\u94fe\u653b\u51fb\u6982\u5ff5\uff0c\u8bbe\u8ba1MCP-SEC\u5de5\u5177\u5bf9MCP\u751f\u6001\u7cfb\u7edf\u8fdb\u884c\u5927\u89c4\u6a21\u5b89\u5168\u666e\u67e5\uff0c\u5206\u679012,230\u4e2a\u5de5\u5177\u548c1,360\u4e2a\u670d\u52a1\u5668\uff0c\u8bc6\u522b\u53ef\u5229\u7528\u7684gadget\u548c\u653b\u51fb\u65b9\u6cd5\u3002", "result": "\u53d1\u73b0MCP\u751f\u6001\u7cfb\u7edf\u5b58\u5728\u5927\u91cf\u53ef\u5229\u7528\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u6839\u672c\u539f\u56e0\u662fMCP\u7f3a\u4e4f\u4e0a\u4e0b\u6587-\u5de5\u5177\u9694\u79bb\u548c\u6700\u5c0f\u6743\u9650\u6267\u884c\u673a\u5236\uff0c\u5bfc\u81f4\u6076\u610f\u6307\u4ee4\u53ef\u4ee5\u4e0d\u53d7\u63a7\u5236\u5730\u4f20\u64ad\u5230\u654f\u611f\u5de5\u5177\u8c03\u7528\u4e2d\u3002", "conclusion": "MCP\u5e73\u53f0\u5b58\u5728\u7cfb\u7edf\u6027\u98ce\u9669\uff0cLLM\u96c6\u6210\u73af\u5883\u8feb\u5207\u9700\u8981\u9632\u5fa1\u673a\u5236\u6765\u5e94\u5bf9\u8fd9\u7c7b\u65b0\u578b\u653b\u51fb\u3002"}}
{"id": "2509.06595", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.06595", "abs": "https://arxiv.org/abs/2509.06595", "authors": ["Irdin Pekaric", "Philipp Zech", "Tom Mattson"], "title": "LLMs in Cybersecurity: Friend or Foe in the Human Decision Loop?", "comment": null, "summary": "Large Language Models (LLMs) are transforming human decision-making by acting\nas cognitive collaborators. Yet, this promise comes with a paradox: while LLMs\ncan improve accuracy, they may also erode independent reasoning, promote\nover-reliance and homogenize decisions. In this paper, we investigate how LLMs\nshape human judgment in security-critical contexts. Through two exploratory\nfocus groups (unaided and LLM-supported), we assess decision accuracy,\nbehavioral resilience and reliance dynamics. Our findings reveal that while\nLLMs enhance accuracy and consistency in routine decisions, they can\ninadvertently reduce cognitive diversity and improve automation bias, which is\nespecially the case among users with lower resilience. In contrast,\nhigh-resilience individuals leverage LLMs more effectively, suggesting that\ncognitive traits mediate AI benefit.", "AI": {"tldr": "LLMs\u5728\u5b89\u5168\u5173\u952e\u51b3\u7b56\u4e2d\u65e2\u63d0\u9ad8\u51c6\u786e\u6027\u53c8\u53ef\u80fd\u524a\u5f31\u72ec\u7acb\u63a8\u7406\u80fd\u529b\uff0c\u5bfc\u81f4\u8fc7\u5ea6\u4f9d\u8d56\u548c\u51b3\u7b56\u540c\u8d28\u5316\u3002\u9ad8\u97e7\u6027\u4e2a\u4f53\u80fd\u66f4\u6709\u6548\u5229\u7528LLM\uff0c\u8ba4\u77e5\u7279\u8d28\u8c03\u8282AI\u6548\u76ca\u3002", "motivation": "\u7814\u7a76LLMs\u5982\u4f55\u5f71\u54cd\u4eba\u7c7b\u5728\u5b89\u5168\u5173\u952e\u73af\u5883\u4e2d\u7684\u5224\u65ad\u51b3\u7b56\uff0c\u63a2\u7d22\u5176\u4f5c\u4e3a\u8ba4\u77e5\u534f\u4f5c\u5de5\u5177\u7684\u6f5c\u5728\u6096\u8bba\uff1a\u65e2\u63d0\u5347\u51c6\u786e\u6027\u53c8\u53ef\u80fd\u4fb5\u8680\u72ec\u7acb\u63a8\u7406\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u4e24\u4e2a\u63a2\u7d22\u6027\u7126\u70b9\u5c0f\u7ec4\uff08\u65e0\u8f85\u52a9\u548cLLM\u652f\u6301\uff09\u8bc4\u4f30\u51b3\u7b56\u51c6\u786e\u6027\u3001\u884c\u4e3a\u97e7\u6027\u548c\u4f9d\u8d56\u52a8\u6001\u3002", "result": "LLMs\u5728\u5e38\u89c4\u51b3\u7b56\u4e2d\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\uff0c\u4f46\u65e0\u610f\u4e2d\u51cf\u5c11\u8ba4\u77e5\u591a\u6837\u6027\u5e76\u52a0\u5267\u81ea\u52a8\u5316\u504f\u89c1\uff0c\u7279\u522b\u662f\u5728\u4f4e\u97e7\u6027\u7528\u6237\u4e2d\u3002\u9ad8\u97e7\u6027\u4e2a\u4f53\u80fd\u66f4\u6709\u6548\u5229\u7528LLM\u3002", "conclusion": "\u8ba4\u77e5\u7279\u8d28\u5728\u8c03\u8282AI\u6548\u76ca\u4e2d\u8d77\u5173\u952e\u4f5c\u7528\uff0c\u9700\u8981\u8bbe\u8ba1\u80fd\u4fdd\u6301\u8ba4\u77e5\u591a\u6837\u6027\u5e76\u51cf\u5c11\u8fc7\u5ea6\u4f9d\u8d56\u7684LLM\u4ea4\u4e92\u65b9\u5f0f\u3002"}}
{"id": "2509.06614", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.06614", "abs": "https://arxiv.org/abs/2509.06614", "authors": ["Margarita Capretto", "Mart\u00edn Ceresa", "Antonio Fern\u00e1ndez Anta", "Pedro Moreno S\u00e1nchez", "C\u00e9sar S\u00e1nchez"], "title": "A Secure Sequencer and Data Availability Committee for Rollups (Extended Version)", "comment": null, "summary": "Blockchains face a scalability limitation, partly due to the throughput\nlimitations of consensus protocols, especially when aiming to obtain a high\ndegree of decentralization. Layer 2 Rollups (L2s) are a faster alternative to\nconventional blockchains. L2s perform most computations offchain using\nminimally blockchains (L1) under-the-hood to guarantee correctness. A sequencer\nis a service that receives offchain L2 transaction requests, batches these\ntransactions, and commits compressed or hashed batches to L1. Using hashing\nneeds less L1 space, which is beneficial for gas cost, but requires a data\navailability committee (DAC) service to translate hashes into their\ncorresponding batches of transaction requests. The behavior of sequencers and\nDACs influence the evolution of the L2 blockchain, presenting a potential\nsecurity threat and delaying L2 adoption. We propose in this paper fraud-proof\nmechanisms, arbitrated by L1 contracts, to detect and generate evidence of\ndishonest behavior of the sequencer and DAC. We study how these fraud-proofs\nlimit the power of adversaries that control different number of sequencer and\nDACs members, and provide incentives for their honest behavior. We designed\nthese fraud-proof mechanisms as two player games. Unlike the generic\nfraud-proofs in current L2s (designed to guarantee the correct execution of\ntransactions), our fraud-proofs are over pred-etermined algorithms that verify\nthe properties that determine the correctness of the DAC. Arbitrating over\nconcrete algorithms makes our fraud-proofs more efficient, easier to\nunderstand, and simpler to prove correct. We provide as an artifact a\nmechanization in LEAN4 of our fraud-proof games, including (1) the verified\nstrategies that honest players should play to win all games as well as (2)\nmechanisms to detect dishonest claims.", "AI": {"tldr": "\u8fdb\u4e00\u6b65\u63d0\u9ad8\u533a\u5757\u94feLayer 2 Rollups\u7684\u53ef\u7a33\u5b9a\u6027\uff0c\u901a\u8fc7\u8bbe\u8ba1\u9ad8\u6548\u7684\u6b3a\u8bc8\u8bc1\u660e\u673a\u5236\u6765\u76d1\u7763sequencer\u548cDAC\u7684\u8bda\u5b9e\u884c\u4e3a\uff0c\u5e76\u5728LEAN4\u4e2d\u5b9e\u73b0\u4e86\u9a8c\u8bc1", "motivation": "\u89e3\u51b3Layer 2 Rollups\u4e2dsequencer\u548c\u6570\u636e\u53ef\u7528\u6027\u59d4\u5458\u4f1a(DAC)\u53ef\u80fd\u5b58\u5728\u7684\u4e0d\u8bda\u5b9e\u884c\u4e3a\u95ee\u9898\uff0c\u8fd9\u4e9b\u95ee\u9898\u5f71\u54cdL2\u7684\u5b89\u5168\u6027\u548c\u91c7\u7528\u901f\u5ea6", "method": "\u8bbe\u8ba1\u4e86\u7531L1\u5408\u7ea6\u4ef2\u88c1\u7684\u6b3a\u8bc8\u8bc1\u660e\u673a\u5236\uff0c\u5c06\u5176\u5f62\u5f0f\u5316\u4e3a\u4e24\u8005\u6e38\u620f\u6a21\u578b\uff0c\u91c7\u7528\u5177\u4f53\u7b97\u6cd5\u9a8c\u8bc1DAC\u6b63\u786e\u6027\u5c5e\u6027\uff0c\u5e76\u5728LEAN4\u4e2d\u5b9e\u73b0\u673a\u5236\u5316", "result": "\u63d0\u51fa\u7684\u6b3a\u8bc8\u8bc1\u660e\u673a\u5236\u6bd4\u73b0\u6709\u901a\u7528\u65b9\u6848\u66f4\u9ad8\u6548\u3001\u66f4\u6613\u7406\u89e3\u4e14\u66f4\u7b80\u6d01\uff0c\u80fd\u591f\u6709\u6548\u9650\u5236\u53f7\u6570\u4e0d\u540c\u7684sequencer\u548cDAC\u6210\u5458\u7684\u6076\u610f\u884c\u4e3a", "conclusion": "\u901a\u8fc7\u4e13\u95e8\u8bbe\u8ba1\u7684\u6b3a\u8bc8\u8bc1\u660e\u673a\u5236\u53ef\u4ee5\u63d0\u9ad8Layer 2 Rollups\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\uff0c\u4e3a\u53ef\u6269\u5c55\u6027\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u4fdd\u969c"}}
{"id": "2509.06626", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2509.06626", "abs": "https://arxiv.org/abs/2509.06626", "authors": ["Jan Matter", "Muoi Tran"], "title": "Network-level Censorship Attacks in the InterPlanetary File System", "comment": null, "summary": "The InterPlanetary File System (IPFS) has been successfully established as\nthe de facto standard for decentralized data storage in the emerging Web3.\nDespite its decentralized nature, IPFS nodes, as well as IPFS content\nproviders, have converged to centralization in large public clouds.\nCentralization introduces BGP routing-based attacks, such as passive\ninterception and BGP hijacking, as potential threats. Although this attack\nvector has been investigated for many other Web3 protocols, such as Bitcoin and\nEthereum, to the best of our knowledge, it has not been analyzed for the IPFS\nnetwork. In our work, we bridge this gap and demonstrate that BGP routing\nattacks can be effectively leveraged to censor content in IPFS. For the\nanalysis, we collected 3,000 content blocks called CIDs and conducted a\nsimulation of BGP hijacking and passive interception against them. We find that\na single malicious AS can censor 75% of the IPFS content for more than 57% of\nall requester nodes. Furthermore, we show that even with a small set of only 62\nhijacked prefixes, 70% of the full attack effectiveness can already be reached.\nWe further propose and validate countermeasures based on global collaborative\ncontent replication among all nodes in the IPFS network, together with\nadditional robust backup content provider nodes that are well-hardened against\nBGP hijacking. We hope this work raises awareness about the threat BGP\nrouting-based attacks pose to IPFS and triggers further efforts to harden the\nlive IPFS network against them.", "AI": {"tldr": "IPFS\u7f51\u7edc\u867d\u7136\u53bb\u4e2d\u5fc3\u5316\uff0c\u4f46\u8282\u70b9\u548c\u5185\u5bb9\u63d0\u4f9b\u5546\u96c6\u4e2d\u5728\u516c\u6709\u4e91\uff0c\u9762\u4e34BGP\u8def\u7531\u653b\u51fb\u5a01\u80c1\u3002\u7814\u7a76\u53d1\u73b0\u5355\u4e2a\u6076\u610fAS\u53ef\u5ba1\u67e575%\u7684IPFS\u5185\u5bb9\uff0c\u5f71\u54cd57%\u7684\u8bf7\u6c42\u8282\u70b9\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u5168\u5c40\u534f\u4f5c\u5185\u5bb9\u590d\u5236\u7684\u9632\u5fa1\u63aa\u65bd\u3002", "motivation": "IPFS\u4f5c\u4e3aWeb3\u53bb\u4e2d\u5fc3\u5316\u5b58\u50a8\u6807\u51c6\uff0c\u5176\u8282\u70b9\u548c\u5185\u5bb9\u63d0\u4f9b\u5546\u5374\u96c6\u4e2d\u5728\u516c\u6709\u4e91\uff0c\u5b58\u5728\u4e2d\u5fc3\u5316\u98ce\u9669\u3002BGP\u8def\u7531\u653b\u51fb\uff08\u5982\u52ab\u6301\u548c\u88ab\u52a8\u62e6\u622a\uff09\u5bf9\u5176\u4ed6Web3\u534f\u8bae\u5df2\u6709\u7814\u7a76\uff0c\u4f46\u5bf9IPFS\u7f51\u7edc\u7684\u5206\u6790\u5c1a\u5c5e\u7a7a\u767d\u3002", "method": "\u6536\u96c63,000\u4e2a\u5185\u5bb9\u5757\uff08CIDs\uff09\uff0c\u6a21\u62dfBGP\u52ab\u6301\u548c\u88ab\u52a8\u62e6\u622a\u653b\u51fb\uff0c\u5206\u6790\u653b\u51fb\u6548\u679c\u548c\u5f71\u54cd\u8303\u56f4\u3002", "result": "\u5355\u4e2a\u6076\u610fAS\u53ef\u5ba1\u67e575%\u7684IPFS\u5185\u5bb9\uff0c\u5f71\u54cd\u8d85\u8fc757%\u7684\u8bf7\u6c42\u8282\u70b9\uff1b\u4ec5\u9700\u52ab\u630162\u4e2a\u524d\u7f00\u5373\u53ef\u8fbe\u523070%\u7684\u653b\u51fb\u6548\u679c\u3002", "conclusion": "BGP\u8def\u7531\u653b\u51fb\u5bf9IPFS\u6784\u6210\u4e25\u91cd\u5a01\u80c1\uff0c\u5efa\u8bae\u91c7\u7528\u5168\u5c40\u534f\u4f5c\u5185\u5bb9\u590d\u5236\u548c\u5f3a\u5316\u5907\u4efd\u5185\u5bb9\u63d0\u4f9b\u5546\u8282\u70b9\u6765\u589e\u5f3a\u7f51\u7edc\u97e7\u6027\uff0c\u547c\u5401\u63d0\u9ad8\u5b89\u5168\u610f\u8bc6\u5e76\u52a0\u5f3aIPFS\u7f51\u7edc\u9632\u62a4\u3002"}}
{"id": "2509.06703", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.06703", "abs": "https://arxiv.org/abs/2509.06703", "authors": ["Gabriele Digregorio", "Marco Di Gennaro", "Stefano Zanero", "Stefano Longari", "Michele Carminati"], "title": "When Secure Isn't: Assessing the Security of Machine Learning Model Sharing", "comment": null, "summary": "The rise of model-sharing through frameworks and dedicated hubs makes Machine\nLearning significantly more accessible. Despite their benefits, these tools\nexpose users to underexplored security risks, while security awareness remains\nlimited among both practitioners and developers. To enable a more\nsecurity-conscious culture in Machine Learning model sharing, in this paper we\nevaluate the security posture of frameworks and hubs, assess whether\nsecurity-oriented mechanisms offer real protection, and survey how users\nperceive the security narratives surrounding model sharing. Our evaluation\nshows that most frameworks and hubs address security risks partially at best,\noften by shifting responsibility to the user. More concerningly, our analysis\nof frameworks advertising security-oriented settings and complete model sharing\nuncovered six 0-day vulnerabilities enabling arbitrary code execution. Through\nthis analysis, we debunk the misconceptions that the model-sharing problem is\nlargely solved and that its security can be guaranteed by the file format used\nfor sharing. As expected, our survey shows that the surrounding security\nnarrative leads users to consider security-oriented settings as trustworthy,\ndespite the weaknesses shown in this work. From this, we derive takeaways and\nsuggestions to strengthen the security of model-sharing ecosystems.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5171\u4eab\u6846\u67b6\u548c\u5e73\u53f0\u7684\u5b89\u5168\u72b6\u51b5\uff0c\u53d1\u73b0\u5927\u591a\u6570\u5e73\u53f0\u5b89\u5168\u9632\u62a4\u4e0d\u8db3\uff0c\u751a\u81f3\u5b58\u57286\u4e2a0day\u6f0f\u6d1e\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u5b89\u5168\u673a\u5236\u65e0\u6cd5\u6709\u6548\u4fdd\u62a4\u7528\u6237\uff0c\u7528\u6237\u5bf9\u5b89\u5168\u8bbe\u7f6e\u5b58\u5728\u8bef\u89e3\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5171\u4eab\u7684\u666e\u53ca\uff0c\u7528\u6237\u9762\u4e34\u672a\u5145\u5206\u63a2\u7d22\u7684\u5b89\u5168\u98ce\u9669\uff0c\u800c\u5f00\u53d1\u8005\u548c\u5b9e\u8df5\u8005\u7684\u5b89\u5168\u610f\u8bc6\u6709\u9650\uff0c\u9700\u8981\u8bc4\u4f30\u6a21\u578b\u5171\u4eab\u751f\u6001\u7cfb\u7edf\u7684\u5b89\u5168\u72b6\u51b5\u3002", "method": "\u8bc4\u4f30\u6846\u67b6\u548c\u5e73\u53f0\u7684\u5b89\u5168\u6001\u52bf\uff0c\u6d4b\u8bd5\u5b89\u5168\u5bfc\u5411\u673a\u5236\u7684\u6709\u6548\u6027\uff0c\u8c03\u67e5\u7528\u6237\u5bf9\u6a21\u578b\u5171\u4eab\u5b89\u5168\u53d9\u6cd5\u7684\u8ba4\u77e5\uff0c\u5e76\u5206\u6790\u5b58\u5728\u6f0f\u6d1e\u7684\u5b89\u5168\u8bbe\u7f6e\u3002", "result": "\u5927\u591a\u6570\u6846\u67b6\u548c\u5e73\u53f0\u4ec5\u90e8\u5206\u89e3\u51b3\u5b89\u5168\u98ce\u9669\uff0c\u901a\u5e38\u5c06\u8d23\u4efb\u8f6c\u5ac1\u7ed9\u7528\u6237\uff1b\u53d1\u73b0\u4e866\u4e2a0day\u6f0f\u6d1e\u53ef\u5b9e\u73b0\u4efb\u610f\u4ee3\u7801\u6267\u884c\uff1b\u7528\u6237\u9519\u8bef\u5730\u8ba4\u4e3a\u5b89\u5168\u8bbe\u7f6e\u662f\u53ef\u4fe1\u7684\u3002", "conclusion": "\u6a21\u578b\u5171\u4eab\u5b89\u5168\u95ee\u9898\u8fdc\u672a\u89e3\u51b3\uff0c\u6587\u4ef6\u683c\u5f0f\u4e0d\u80fd\u4fdd\u8bc1\u5b89\u5168\uff0c\u9700\u8981\u91c7\u53d6\u63aa\u65bd\u52a0\u5f3a\u6a21\u578b\u5171\u4eab\u751f\u6001\u7cfb\u7edf\u7684\u5b89\u5168\u6027\uff0c\u6539\u53d8\u7528\u6237\u7684\u5b89\u5168\u8ba4\u77e5\u3002"}}
{"id": "2509.06754", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.06754", "abs": "https://arxiv.org/abs/2509.06754", "authors": ["Yiqi Tang"], "title": "Image Encryption Scheme Based on Hyper-Chaotic Map and Self-Adaptive Diffusion", "comment": null, "summary": "In the digital age, image encryption technology acts as a safeguard,\npreventing unauthorized access to images. This paper proposes an innovative\nimage encryption scheme that integrates a novel 2D hyper-chaotic map with a\nnewly developed self-adaptive diffusion method. The 2D hyper-chaotic map,\nnamely the 2D-RA map, is designed by hybridizing the Rastrigin and Ackley\nfunctions. The chaotic performance of the 2D-RA map is validated through a\nseries of measurements, including the Bifurcation Diagram, Lyapunov Exponent\n(LE), Initial Value Sensitivity, 0 - 1 Test, Correlation Dimension (CD), and\nKolmogorov Entropy (KE). The results demonstrate that the chaotic performance\nof the 2D-RA map surpasses that of existing advanced chaotic functions.\nAdditionally, the self-adaptive diffusion method is employed to enhance the\nuniformity of grayscale distribution. The performance of the image encryption\nscheme is evaluated using a series of indicators. The results show that the\nproposed image encryption scheme significantly outperforms current\nstate-of-the-art image encryption techniques.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65b02D\u8d85\u6df7\u6d8e\u5730\u56fe\u548c\u81ea\u9002\u5e94\u6f5c\u79fb\u65b9\u6cd5\u7684\u521b\u65b0\u56fe\u50cf\u52a0\u5bc6\u65b9\u6848\uff0c\u5728\u6df7\u6d8e\u6027\u80fd\u548c\u52a0\u5bc6\u6548\u679c\u65b9\u9762\u663e\u8457\u8d85\u8fc7\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u5728\u6570\u5b57\u65f6\u4ee3\uff0c\u56fe\u50cf\u52a0\u5bc6\u6280\u672f\u662f\u9632\u6b62\u672a\u6388\u6743\u8bbf\u95ee\u7684\u91cd\u8981\u4fdd\u62a4\u624b\u6bb5\uff0c\u9700\u8981\u63d0\u5347\u52a0\u5bc6\u65b9\u6848\u7684\u5b89\u5168\u6027\u548c\u6027\u80fd\u3002", "method": "\u96c6\u6210\u4e86\u65b02D-RA\u8d85\u6df7\u6d8e\u5730\u56fe\uff08\u57fa\u4e8eRastrigin\u548cAckley\u51fd\u6570\u6df7\u5408\u8bbe\u8ba1\uff09\u548c\u65b0\u7684\u81ea\u9002\u5e94\u6f5c\u79fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u5206\u652f\u56fe\u3001\u674e\u96c5\u666e\u8bfa\u592b\u6307\u6570\u7b49\u6307\u6807\u9a8c\u8bc1\u6df7\u6d8e\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a2D-RA\u5730\u56fe\u7684\u6df7\u6d8e\u6027\u80fd\u8d85\u8fc7\u73b0\u6709\u5148\u8fdb\u6df7\u6d8e\u51fd\u6570\uff0c\u52a0\u5bc6\u65b9\u6848\u5728\u591a\u9879\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u56fe\u50cf\u52a0\u5bc6\u6280\u672f\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u5b89\u5168\u7684\u56fe\u50cf\u52a0\u5bc6\u65b9\u6848\uff0c\u4e3a\u6570\u5b57\u56fe\u50cf\u5b89\u5168\u4fdd\u62a4\u505a\u51fa\u4e86\u91cd\u8981\u8d21\u732e\u3002"}}
{"id": "2509.06796", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.06796", "abs": "https://arxiv.org/abs/2509.06796", "authors": ["Yuntao Du", "Yuetian Chen", "Hanshen Xiao", "Bruno Ribeiro", "Ninghui Li"], "title": "Imitative Membership Inference Attack", "comment": "Code is available at: https://github.com/zealscott/IMIA", "summary": "A Membership Inference Attack (MIA) assesses how much a target machine\nlearning model reveals about its training data by determining whether specific\nquery instances were part of the training set. State-of-the-art MIAs rely on\ntraining hundreds of shadow models that are independent of the target model,\nleading to significant computational overhead. In this paper, we introduce\nImitative Membership Inference Attack (IMIA), which employs a novel imitative\ntraining technique to strategically construct a small number of target-informed\nimitative models that closely replicate the target model's behavior for\ninference. Extensive experimental results demonstrate that IMIA substantially\noutperforms existing MIAs in various attack settings while only requiring less\nthan 5% of the computational cost of state-of-the-art approaches.", "AI": {"tldr": "\u63d0\u51faIMIA\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u4eff\u8bad\u7ec3\u6280\u672f\u6784\u5efa\u5c11\u91cf\u76ee\u6807\u6a21\u578b\u4eff\u5236\u54c1\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\u63d0\u5347\u6210\u5458\u63a8\u7406\u653b\u51fb\u6548\u679c", "motivation": "\u73b0\u6709\u6210\u5458\u63a8\u7406\u653b\u51fb\u9700\u8981\u8bad\u7ec3\u6570\u767e\u4e2a\u5f71\u5b50\u6a21\u578b\uff0c\u8ba1\u7b97\u5f00\u9500\u5de8\u5927\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5", "method": "\u4f7f\u7528\u521b\u65b0\u7684\u6a21\u4eff\u8bad\u7ec3\u6280\u672f\uff0c\u6784\u5efa\u5c11\u91cf\u76ee\u6807\u6a21\u578b\u4eff\u5236\u54c1\u6765\u7cbe\u786e\u590d\u5236\u76ee\u6807\u6a21\u578b\u884c\u4e3a\u8fdb\u884c\u63a8\u7406", "result": "IMIA\u5728\u5404\u79cd\u653b\u51fb\u8bbe\u7f6e\u4e0b\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u540c\u65f6\u4ec5\u9700\u4e0d\u52305%\u7684\u8ba1\u7b97\u6210\u672c", "conclusion": "IMIA\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u6709\u6548\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\uff0c\u5927\u5e45\u964d\u4f4e\u4e86\u8ba1\u7b97\u5f00\u9500\u540c\u65f6\u63d0\u5347\u4e86\u653b\u51fb\u6027\u80fd"}}
{"id": "2509.06920", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.CY", "C.2.0; I.2.7; K.4.1; H.3.3"], "pdf": "https://arxiv.org/pdf/2509.06920", "abs": "https://arxiv.org/abs/2509.06920", "authors": ["Haywood Gelman", "John D. Hastings", "David Kenley"], "title": "An Ethically Grounded LLM-Based Approach to Insider Threat Synthesis and Detection", "comment": "6 pages, 5 figures, 5 tables", "summary": "Insider threats are a growing organizational problem due to the complexity of\nidentifying their technical and behavioral elements. A large research body is\ndedicated to the study of insider threats from technological, psychological,\nand educational perspectives. However, research in this domain has been\ngenerally dependent on datasets that are static and limited access which\nrestricts the development of adaptive detection models. This study introduces a\nnovel, ethically grounded approach that uses the large language model (LLM)\nClaude Sonnet 3.7 to dynamically synthesize syslog messages, some of which\ncontain indicators of insider threat scenarios. The messages reflect real-world\ndata distributions by being highly imbalanced (1% insider threats). The syslogs\nwere analyzed for insider threats by both Claude Sonnet 3.7 and GPT-4o, with\ntheir performance evaluated through statistical metrics including precision,\nrecall, MCC, and ROC AUC. Sonnet 3.7 consistently outperformed GPT-4o across\nnearly all metrics, particularly in reducing false alarms and improving\ndetection accuracy. The results show strong promise for the use of LLMs in\nsynthetic dataset generation and insider threat detection.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b0\u9898\u65b9\u6cd5\uff0c\u4f7f\u7528Claude Sonnet 3.7\u52a8\u6001\u5408\u6210\u542b\u6709\u5185\u90e8\u5a01\u80c1\u6307\u6807\u7684\u7cfb\u7edf\u65e5\u5fd7\uff0c\u5e76\u5728\u5185\u90e8\u5a01\u80c1\u68c0\u6d4b\u4e2d\u8868\u73b0\u51fa\u66f4\u4f18\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u5185\u90e8\u5a01\u80c1\u7814\u7a76\u4f9d\u8d56\u9759\u6001\u548c\u8bbf\u95ee\u9650\u5236\u7684\u6570\u636e\u96c6\uff0c\u9650\u5236\u4e86\u9002\u5e94\u6027\u68c0\u6d4b\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u6765\u52a8\u6001\u751f\u6210\u66f4\u63a5\u8fd1\u5b9e\u9645\u7684\u6570\u636e\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578bClaude Sonnet 3.7\u7684\u7b26\u5408\u9053\u5fb7\u89c4\u8303\u7684\u65b9\u6cd5\uff0c\u52a8\u6001\u5408\u6210\u7cfb\u7edf\u65e5\u5fd7\u6d88\u606f\uff0c\u5176\u4e2d1%\u5305\u542b\u5185\u90e8\u5a01\u80c1\u573a\u666f\u3002\u5bf9\u6bd4\u5206\u6790Claude Sonnet 3.7\u548cGPT-4o\u5728\u68c0\u6d4b\u6027\u80fd\u4e0a\u7684\u5dee\u5f02\u3002", "result": "Claude Sonnet 3.7\u5728\u51e0\u4e4e\u6240\u6709\u7edf\u8ba1\u6307\u6807\u4e0a\u90fd\u663e\u8457\u8d85\u8fc7GPT-4o\uff0c\u7279\u522b\u662f\u5728\u51cf\u5c11\u8bef\u62a5\u548c\u63d0\u9ad8\u68c0\u6d4b\u51c6\u786e\u6027\u65b9\u9762\u3002\u7ed3\u679c\u663e\u793a\u51c6\u786e\u7387\u3001\u53ec\u56de\u7387\u3001MCC\u548cROC AUC\u90fd\u6709\u663e\u8457\u6539\u5584\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5408\u6210\u6570\u636e\u96c6\u751f\u6210\u548c\u5185\u90e8\u5a01\u80c1\u68c0\u6d4b\u65b9\u9762\u5177\u6709\u5f3a\u5927\u6f5c\u529b\uff0cClaude Sonnet 3.7\u7684\u4f18\u5f02\u8868\u73b0\u4e3a\u8be5\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.06921", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06921", "abs": "https://arxiv.org/abs/2509.06921", "authors": ["Safayat Bin Hakim", "Muhammad Adil", "Alvaro Velasquez", "Shouhuai Xu", "Houbing Herbert Song"], "title": "Neuro-Symbolic AI for Cybersecurity: State of the Art, Challenges, and Opportunities", "comment": null, "summary": "Traditional Artificial Intelligence (AI) approaches in cybersecurity exhibit\nfundamental limitations: inadequate conceptual grounding leading to\nnon-robustness against novel attacks; limited instructibility impeding\nanalyst-guided adaptation; and misalignment with cybersecurity objectives.\nNeuro-Symbolic (NeSy) AI has emerged with the potential to revolutionize\ncybersecurity AI. However, there is no systematic understanding of this\nemerging approach. These hybrid systems address critical cybersecurity\nchallenges by combining neural pattern recognition with symbolic reasoning,\nenabling enhanced threat understanding while introducing concerning autonomous\noffensive capabilities that reshape threat landscapes. In this survey, we\nsystematically characterize this field by analyzing 127 publications spanning\n2019-July 2025. We introduce a Grounding-Instructibility-Alignment (G-I-A)\nframework to evaluate these systems, focusing on both cyber defense and cyber\noffense across network security, malware analysis, and cyber operations. Our\nanalysis shows advantages of multi-agent NeSy architectures and identifies\ncritical implementation challenges including standardization gaps,\ncomputational complexity, and human-AI collaboration requirements that\nconstrain deployment. We show that causal reasoning integration is the most\ntransformative advancement, enabling proactive defense beyond correlation-based\napproaches. Our findings highlight dual-use implications where autonomous\nsystems demonstrate substantial capabilities in zero-day exploitation while\nachieving significant cost reductions, altering threat dynamics. We provide\ninsights and future research directions, emphasizing the urgent need for\ncommunity-driven standardization frameworks and responsible development\npractices that ensure advancement serves defensive cybersecurity objectives\nwhile maintaining societal alignment.", "AI": {"tldr": "\u795e\u7ecf\u7b26\u53f7AI\u5728\u7f51\u7edc\u5b89\u5168\u9886\u57df\u5177\u6709\u9769\u547d\u6027\u6f5c\u529b\uff0c\u901a\u8fc7\u7ed3\u5408\u795e\u7ecf\u6a21\u5f0f\u8bc6\u522b\u548c\u7b26\u53f7\u63a8\u7406\u89e3\u51b3\u4f20\u7edfAI\u7684\u5c40\u9650\u6027\uff0c\u4f46\u5b58\u5728\u53cc\u91cd\u7528\u9014\u98ce\u9669\uff0c\u9700\u8981\u6807\u51c6\u5316\u6846\u67b6\u548c\u8d1f\u8d23\u4efb\u5f00\u53d1\u3002", "motivation": "\u4f20\u7edfAI\u65b9\u6cd5\u5728\u7f51\u7edc\u5b89\u5168\u4e2d\u5b58\u5728\u6982\u5ff5\u57fa\u7840\u4e0d\u8db3\u3001\u6307\u4ee4\u6027\u6709\u9650\u4ee5\u53ca\u4e0e\u5b89\u5168\u76ee\u6807\u4e0d\u5bf9\u9f50\u7b49\u6839\u672c\u6027\u9650\u5236\uff0c\u9700\u8981\u65b0\u7684\u6df7\u5408\u65b9\u6cd5\u6765\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u901a\u8fc7\u5206\u6790127\u7bc7\u6587\u732e(2019-2025\u5e747\u6708)\uff0c\u5f15\u5165G-I-A(\u57fa\u7840-\u6307\u4ee4\u6027-\u5bf9\u9f50)\u6846\u67b6\uff0c\u8bc4\u4f30\u7f51\u7edc\u9632\u5fa1\u548c\u653b\u51fb\u4e2d\u7684\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edf\uff0c\u91cd\u70b9\u5173\u6ce8\u7f51\u7edc\u5b89\u5168\u3001\u6076\u610f\u8f6f\u4ef6\u5206\u6790\u548c\u7f51\u7edc\u64cd\u4f5c\u3002", "result": "\u591a\u667a\u80fd\u4f53\u795e\u7ecf\u7b26\u53f7\u67b6\u6784\u5177\u6709\u4f18\u52bf\uff0c\u56e0\u679c\u63a8\u7406\u96c6\u6210\u662f\u6700\u5177\u53d8\u9769\u6027\u7684\u8fdb\u6b65\uff0c\u4f46\u5b58\u5728\u6807\u51c6\u5316\u5dee\u8ddd\u3001\u8ba1\u7b97\u590d\u6742\u6027\u548c\u4eba\u673a\u534f\u4f5c\u7b49\u5b9e\u65bd\u6311\u6218\u3002\u81ea\u4e3b\u7cfb\u7edf\u5728\u96f6\u65e5\u6f0f\u6d1e\u5229\u7528\u65b9\u9762\u5c55\u73b0\u51fa\u5f3a\u5927\u80fd\u529b\uff0c\u663e\u8457\u964d\u4f4e\u6210\u672c\u3002", "conclusion": "\u795e\u7ecf\u7b26\u53f7AI\u6539\u53d8\u4e86\u5a01\u80c1\u52a8\u6001\uff0c\u8feb\u5207\u9700\u8981\u793e\u533a\u9a71\u52a8\u7684\u6807\u51c6\u5316\u6846\u67b6\u548c\u8d1f\u8d23\u4efb\u5f00\u53d1\u5b9e\u8df5\uff0c\u786e\u4fdd\u6280\u672f\u8fdb\u6b65\u670d\u52a1\u4e8e\u9632\u5fa1\u6027\u7f51\u7edc\u5b89\u5168\u76ee\u6807\u5e76\u4fdd\u6301\u793e\u4f1a\u5bf9\u9f50\u3002"}}
