{"id": "2508.04894", "categories": ["cs.CR", "cs.AI", "cs.SI"], "pdf": "https://arxiv.org/pdf/2508.04894", "abs": "https://arxiv.org/abs/2508.04894", "authors": ["Iyiola E. Olatunji", "Franziska Boenisch", "Jing Xu", "Adam Dziedzic"], "title": "Adversarial Attacks and Defenses on Graph-aware Large Language Models (LLMs)", "comment": null, "summary": "Large Language Models (LLMs) are increasingly integrated with\ngraph-structured data for tasks like node classification, a domain\ntraditionally dominated by Graph Neural Networks (GNNs). While this integration\nleverages rich relational information to improve task performance, their\nrobustness against adversarial attacks remains unexplored. We take the first\nstep to explore the vulnerabilities of graph-aware LLMs by leveraging existing\nadversarial attack methods tailored for graph-based models, including those for\npoisoning (training-time attacks) and evasion (test-time attacks), on two\nrepresentative models, LLAGA (Chen et al. 2024) and GRAPHPROMPTER (Liu et al.\n2024). Additionally, we discover a new attack surface for LLAGA where an\nattacker can inject malicious nodes as placeholders into the node sequence\ntemplate to severely degrade its performance. Our systematic analysis reveals\nthat certain design choices in graph encoding can enhance attack success, with\nspecific findings that: (1) the node sequence template in LLAGA increases its\nvulnerability; (2) the GNN encoder used in GRAPHPROMPTER demonstrates greater\nrobustness; and (3) both approaches remain susceptible to imperceptible feature\nperturbation attacks. Finally, we propose an end-to-end defense framework\nGALGUARD, that combines an LLM-based feature correction module to mitigate\nfeature-level perturbations and adapted GNN defenses to protect against\nstructural attacks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u63a2\u8ba8\u4e86\u56fe\u611f\u77e5\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u7684\u8106\u5f31\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u9632\u5fa1\u6846\u67b6GALGUARD\u3002", "motivation": "\u5c3d\u7ba1LLMs\u4e0e\u56fe\u6570\u636e\u7684\u7ed3\u5408\u63d0\u5347\u4e86\u4efb\u52a1\u6027\u80fd\uff0c\u4f46\u5176\u5bf9\u6297\u653b\u51fb\u7684\u9c81\u68d2\u6027\u5c1a\u672a\u88ab\u7814\u7a76\u3002", "method": "\u5229\u7528\u73b0\u6709\u7684\u56fe\u6a21\u578b\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5\uff08\u5982\u6bd2\u5316\u548c\u89c4\u907f\u653b\u51fb\uff09\u6d4b\u8bd5LLAGA\u548cGRAPHPROMPTER\u6a21\u578b\uff0c\u5e76\u53d1\u73b0LLAGA\u7684\u65b0\u653b\u51fb\u9762\u3002", "result": "\u7814\u7a76\u53d1\u73b0LLAGA\u7684\u8282\u70b9\u5e8f\u5217\u6a21\u677f\u6613\u53d7\u653b\u51fb\uff0cGRAPHPROMPTER\u7684GNN\u7f16\u7801\u5668\u66f4\u9c81\u68d2\uff0c\u4f46\u4e24\u8005\u5747\u5bf9\u7279\u5f81\u6270\u52a8\u653b\u51fb\u654f\u611f\u3002", "conclusion": "\u63d0\u51fa\u4e86GALGUARD\u9632\u5fa1\u6846\u67b6\uff0c\u7ed3\u5408LLM\u7279\u5f81\u6821\u6b63\u548cGNN\u9632\u5fa1\uff0c\u4ee5\u589e\u5f3a\u6a21\u578b\u9c81\u68d2\u6027\u3002"}}
{"id": "2508.05048", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.05048", "abs": "https://arxiv.org/abs/2508.05048", "authors": ["Mohammad Ferry Husnil Arif", "Muhammad Imran"], "title": "On the Classical Hardness of the Semidirect Discrete Logarithm Problem in Finite Groups", "comment": null, "summary": "The semidirect discrete logarithm problem (SDLP) in finite groups was\nproposed as a foundation for post-quantum cryptographic protocols, based on the\nbelief that its non-abelian structure would resist quantum attacks. However,\nrecent results have shown that SDLP in finite groups admits efficient quantum\nalgorithms, undermining its quantum resistance. This raises a fundamental\nquestion: does the SDLP offer any computational advantages over the standard\ndiscrete logarithm problem (DLP) against classical adversaries? In this work,\nwe investigate the classical hardness of SDLP across different finite group\nplatforms. We establish that the group-case SDLP can be reformulated as a\ngeneralized discrete logarithm problem, enabling adaptation of classical\nalgorithms to study its complexity. We present a concrete adaptation of the\nBaby-Step Giant-Step algorithm for SDLP, achieving time and space complexity\n$O(\\sqrt{r})$ where $r$ is the period of the underlying cycle structure.\nThrough theoretical analysis and experimental validation in SageMath, we\ndemonstrate that the classical hardness of SDLP is highly platform-dependent\nand does not uniformly exceed that of standard DLP. In finite fields\n$\\mathbb{F}_p^*$, both problems exhibit comparable complexity. Surprisingly, in\nelliptic curves $E(\\mathbb{F}_p)$, the SDLP becomes trivial due to the bounded\nautomorphism group, while in elementary abelian groups $\\mathbb{F}_p^n$, the\nSDLP can be harder than DLP, with complexity varying based on the eigenvalue\nstructure of the automorphism. Our findings reveal that the non-abelian\nstructure of semidirect products does not inherently guarantee increased\nclassical hardness, suggesting that the search for classically hard problems\nfor cryptographic applications requires more careful consideration of the\nunderlying algebraic structures.", "AI": {"tldr": "\u534a\u76f4\u63a5\u79bb\u6563\u5bf9\u6570\u95ee\u9898\uff08SDLP\uff09\u5728\u6709\u9650\u7fa4\u4e2d\u7684\u91cf\u5b50\u6297\u6027\u88ab\u8d28\u7591\uff0c\u7814\u7a76\u53d1\u73b0\u5176\u7ecf\u5178\u96be\u5ea6\u4f9d\u8d56\u4e8e\u7fa4\u7ed3\u6784\uff0c\u5e76\u4e0d\u603b\u662f\u4f18\u4e8e\u6807\u51c6\u79bb\u6563\u5bf9\u6570\u95ee\u9898\uff08DLP\uff09\u3002", "motivation": "\u7814\u7a76SDLP\u5728\u7ecf\u5178\u8ba1\u7b97\u73af\u5883\u4e0b\u7684\u96be\u5ea6\uff0c\u4ee5\u8bc4\u4f30\u5176\u4f5c\u4e3a\u5bc6\u7801\u5b66\u57fa\u7840\u7684\u6f5c\u529b\u3002", "method": "\u5c06SDLP\u91cd\u65b0\u8868\u8ff0\u4e3a\u5e7f\u4e49\u79bb\u6563\u5bf9\u6570\u95ee\u9898\uff0c\u5e76\u6539\u8fdbBaby-Step Giant-Step\u7b97\u6cd5\u4ee5\u5206\u6790\u5176\u590d\u6742\u5ea6\u3002", "result": "SDLP\u7684\u7ecf\u5178\u96be\u5ea6\u56e0\u7fa4\u7ed3\u6784\u800c\u5f02\uff1a\u5728\u6709\u9650\u57df\u4e2d\u4e0eDLP\u76f8\u5f53\uff0c\u5728\u692d\u5706\u66f2\u7ebf\u4e2d\u53d8\u5f97\u7b80\u5355\uff0c\u800c\u5728\u521d\u7b49\u963f\u8d1d\u5c14\u7fa4\u4e2d\u53ef\u80fd\u66f4\u96be\u3002", "conclusion": "SDLP\u7684\u975e\u963f\u8d1d\u5c14\u7ed3\u6784\u5e76\u4e0d\u4fdd\u8bc1\u66f4\u9ad8\u7684\u7ecf\u5178\u96be\u5ea6\uff0c\u5bc6\u7801\u5b66\u5e94\u7528\u9700\u66f4\u8c28\u614e\u9009\u62e9\u4ee3\u6570\u7ed3\u6784\u3002"}}
{"id": "2508.05188", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.05188", "abs": "https://arxiv.org/abs/2508.05188", "authors": ["Kim Hammar", "Tansu Alpcan", "Emil C. Lupu"], "title": "Incident Response Planning Using a Lightweight Large Language Model with Reduced Hallucination", "comment": null, "summary": "Timely and effective incident response is key to managing the growing\nfrequency of cyberattacks. However, identifying the right response actions for\ncomplex systems is a major technical challenge. A promising approach to\nmitigate this challenge is to use the security knowledge embedded in large\nlanguage models (LLMs) to assist security operators during incident handling.\nRecent research has demonstrated the potential of this approach, but current\nmethods are mainly based on prompt engineering of frontier LLMs, which is\ncostly and prone to hallucinations. We address these limitations by presenting\na novel way to use an LLM for incident response planning with reduced\nhallucination. Our method includes three steps: fine-tuning, information\nretrieval, and lookahead planning. We prove that our method generates response\nplans with a bounded probability of hallucination and that this probability can\nbe made arbitrarily small at the expense of increased planning time under\ncertain assumptions. Moreover, we show that our method is lightweight and can\nrun on commodity hardware. We evaluate our method on logs from incidents\nreported in the literature. The experimental results show that our method a)\nachieves up to 22% shorter recovery times than frontier LLMs and b) generalizes\nto a broad range of incident types and response actions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8fdb\u884c\u7f51\u7edc\u5b89\u5168\u4e8b\u4ef6\u54cd\u5e94\u89c4\u5212\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5fae\u8c03\u3001\u4fe1\u606f\u68c0\u7d22\u548c\u524d\u77bb\u89c4\u5212\u51cf\u5c11\u5e7b\u89c9\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u4f18\u4e8e\u524d\u6cbfLLM\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u524d\u6cbfLLM\u7684\u4e8b\u4ef6\u54cd\u5e94\u65b9\u6cd5\u6210\u672c\u9ad8\u4e14\u6613\u4ea7\u751f\u5e7b\u89c9\uff0c\u4e9f\u9700\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u53ef\u9760\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e09\u6b65\u6cd5\uff1a\u5fae\u8c03LLM\u3001\u4fe1\u606f\u68c0\u7d22\u548c\u524d\u77bb\u89c4\u5212\uff0c\u786e\u4fdd\u751f\u6210\u54cd\u5e94\u8ba1\u5212\u7684\u5e7b\u89c9\u6982\u7387\u53ef\u63a7\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6062\u590d\u65f6\u95f4\u6bd4\u524d\u6cbfLLM\u7f29\u77ed22%\uff0c\u4e14\u80fd\u6cdb\u5316\u5230\u591a\u79cd\u4e8b\u4ef6\u7c7b\u578b\u548c\u54cd\u5e94\u52a8\u4f5c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u964d\u4f4e\u5e7b\u89c9\u7684\u540c\u65f6\u63d0\u5347\u4e86\u4e8b\u4ef6\u54cd\u5e94\u6548\u7387\uff0c\u9002\u7528\u4e8e\u666e\u901a\u786c\u4ef6\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.05276", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.05276", "abs": "https://arxiv.org/abs/2508.05276", "authors": ["Sharad Agarwal", "Guillermo Suarez-Tangil", "Marie Vasek"], "title": "An Overview of 7726 User Reports: Uncovering SMS Scams and Scammer Strategies", "comment": null, "summary": "Mobile network operators implement firewalls to stop illicit messages, but\nscammers find ways to evade detection. Previous work has looked into SMS texts\nthat are blocked by these firewalls. However, there is little insight into SMS\ntexts that bypass them and reach users. To this end, we collaborate with a\nmajor mobile network operator to receive 1.35m user reports submitted over four\nmonths. We find 89.16% of user reports comprise text messages, followed by\nreports of suspicious calls and URLs. Using our methodological framework, we\nidentify 35.12% of the unique text messages reported by users as spam, while\n40.27% are scam text messages. This is the first paper that investigates SMS\nreports submitted by users and differentiates between spam and scams. Our paper\nclassifies the identified scam text messages into 12 scam types, of which the\nmost popular is 'wrong number' scams. We explore the various infrastructure\nservices that scammers abuse to conduct SMS scams, including mobile network\noperators and hosting infrastructure, and analyze the text of the scam messages\nto understand how scammers lure victims into providing them with their personal\nor financial details.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u7528\u6237\u63d0\u4ea4\u7684\u77ed\u4fe1\u62a5\u544a\uff0c\u533a\u5206\u4e86\u5783\u573e\u77ed\u4fe1\u548c\u8bc8\u9a97\u77ed\u4fe1\uff0c\u5e76\u5206\u7c7b\u4e8612\u79cd\u8bc8\u9a97\u7c7b\u578b\uff0c\u63ed\u793a\u4e86\u8bc8\u9a97\u8005\u5229\u7528\u7684\u57fa\u7840\u8bbe\u65bd\u548c\u8bf1\u9a97\u624b\u6bb5\u3002", "motivation": "\u79fb\u52a8\u7f51\u7edc\u8fd0\u8425\u5546\u7684\u9632\u706b\u5899\u672a\u80fd\u5b8c\u5168\u963b\u6b62\u8bc8\u9a97\u77ed\u4fe1\uff0c\u7f3a\u4e4f\u5bf9\u7ed5\u8fc7\u9632\u706b\u5899\u7684\u77ed\u4fe1\u7684\u7814\u7a76\u3002", "method": "\u4e0e\u4e3b\u8981\u79fb\u52a8\u8fd0\u8425\u5546\u5408\u4f5c\uff0c\u5206\u6790135\u4e07\u4efd\u7528\u6237\u62a5\u544a\uff0c\u4f7f\u7528\u65b9\u6cd5\u8bba\u6846\u67b6\u8bc6\u522b\u5783\u573e\u548c\u8bc8\u9a97\u77ed\u4fe1\u3002", "result": "35.12%\u7684\u77ed\u4fe1\u4e3a\u5783\u573e\u77ed\u4fe1\uff0c40.27%\u4e3a\u8bc8\u9a97\u77ed\u4fe1\uff0c\u6700\u5e38\u89c1\u7684\u8bc8\u9a97\u7c7b\u578b\u662f\u201c\u9519\u53f7\u201d\u8bc8\u9a97\u3002", "conclusion": "\u8bba\u6587\u9996\u6b21\u901a\u8fc7\u7528\u6237\u62a5\u544a\u5206\u6790\u77ed\u4fe1\u8bc8\u9a97\uff0c\u63ed\u793a\u4e86\u8bc8\u9a97\u7c7b\u578b\u548c\u624b\u6bb5\uff0c\u4e3a\u9632\u8303\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2508.04820", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.04820", "abs": "https://arxiv.org/abs/2508.04820", "authors": ["Mayra Sofia Ruiz Rodriguez", "SayedHassan Khatoonabadi", "Emad Shihab"], "title": "Automated File-Level Logging Generation for Machine Learning Applications using LLMs: A Case Study using GPT-4o Mini", "comment": null, "summary": "Logging is essential in software development, helping developers monitor\nsystem behavior and aiding in debugging applications. Given the ability of\nlarge language models (LLMs) to generate natural language and code, researchers\nare exploring their potential to generate log statements. However, prior work\nfocuses on evaluating logs introduced in code functions, leaving file-level log\ngeneration underexplored -- especially in machine learning (ML) applications,\nwhere comprehensive logging can enhance reliability. In this study, we evaluate\nthe capacity of GPT-4o mini as a case study to generate log statements for ML\nprojects at file level. We gathered a set of 171 ML repositories containing\n4,073 Python files with at least one log statement. We identified and removed\nthe original logs from the files, prompted the LLM to generate logs for them,\nand evaluated both the position of the logs and log level, variables, and text\nquality of the generated logs compared to human-written logs. In addition, we\nmanually analyzed a representative sample of generated logs to identify common\npatterns and challenges. We find that the LLM introduces logs in the same place\nas humans in 63.91% of cases, but at the cost of a high overlogging rate of\n82.66%. Furthermore, our manual analysis reveals challenges for file-level\nlogging, which shows overlogging at the beginning or end of a function,\ndifficulty logging within large code blocks, and misalignment with\nproject-specific logging conventions. While the LLM shows promise for\ngenerating logs for complete files, these limitations remain to be addressed\nfor practical implementation.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86GPT-4o mini\u5728\u673a\u5668\u5b66\u4e60\u9879\u76ee\u4e2d\u751f\u6210\u6587\u4ef6\u7ea7\u65e5\u5fd7\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5176\u572863.91%\u7684\u60c5\u51b5\u4e0b\u4e0e\u4eba\u7c7b\u65e5\u5fd7\u4f4d\u7f6e\u4e00\u81f4\uff0c\u4f46\u5b58\u572882.66%\u7684\u8fc7\u5ea6\u65e5\u5fd7\u95ee\u9898\u3002", "motivation": "\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6587\u4ef6\u7ea7\u65e5\u5fd7\u751f\u6210\u4e2d\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u673a\u5668\u5b66\u4e60\u5e94\u7528\u4e2d\uff0c\u4ee5\u63d0\u9ad8\u7cfb\u7edf\u53ef\u9760\u6027\u3002", "method": "\u6536\u96c6171\u4e2aML\u4ed3\u5e93\u76844,073\u4e2aPython\u6587\u4ef6\uff0c\u79fb\u9664\u539f\u59cb\u65e5\u5fd7\u540e\u4f7f\u7528LLM\u751f\u6210\u65e5\u5fd7\uff0c\u5e76\u8bc4\u4f30\u65e5\u5fd7\u4f4d\u7f6e\u3001\u7ea7\u522b\u3001\u53d8\u91cf\u548c\u6587\u672c\u8d28\u91cf\u3002", "result": "LLM\u572863.91%\u7684\u60c5\u51b5\u4e0b\u4e0e\u4eba\u7c7b\u65e5\u5fd7\u4f4d\u7f6e\u4e00\u81f4\uff0c\u4f46\u5b58\u572882.66%\u7684\u8fc7\u5ea6\u65e5\u5fd7\u95ee\u9898\uff0c\u4e14\u5728\u5927\u578b\u4ee3\u7801\u5757\u548c\u9879\u76ee\u7279\u5b9a\u65e5\u5fd7\u89c4\u8303\u4e2d\u5b58\u5728\u6311\u6218\u3002", "conclusion": "LLM\u5728\u6587\u4ef6\u7ea7\u65e5\u5fd7\u751f\u6210\u4e2d\u663e\u793a\u6f5c\u529b\uff0c\u4f46\u8fc7\u5ea6\u65e5\u5fd7\u548c\u89c4\u8303\u5bf9\u9f50\u95ee\u9898\u4ecd\u9700\u89e3\u51b3\u3002"}}
{"id": "2508.04714", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA", "eess.SP"], "pdf": "https://arxiv.org/pdf/2508.04714", "abs": "https://arxiv.org/abs/2508.04714", "authors": ["Chitranshu Harbola", "Anupam Purwar"], "title": "Prescriptive Agents based on Rag for Automated Maintenance (PARAM)", "comment": null, "summary": "Industrial machinery maintenance requires timely intervention to prevent\ncatastrophic failures and optimize operational efficiency. This paper presents\nan integrated Large Language Model (LLM)-based intelligent system for\nprescriptive maintenance that extends beyond traditional anomaly detection to\nprovide actionable maintenance recommendations. Building upon our prior LAMP\nframework for numerical data analysis, we develop a comprehensive solution that\ncombines bearing vibration frequency analysis with multi agentic generation for\nintelligent maintenance planning. Our approach serializes bearing vibration\ndata (BPFO, BPFI, BSF, FTF frequencies) into natural language for LLM\nprocessing, enabling few-shot anomaly detection with high accuracy. The system\nclassifies fault types (inner race, outer race, ball/roller, cage faults) and\nassesses severity levels. A multi-agentic component processes maintenance\nmanuals using vector embeddings and semantic search, while also conducting web\nsearches to retrieve comprehensive procedural knowledge and access up-to-date\nmaintenance practices for more accurate and in-depth recommendations. The\nGemini model then generates structured maintenance recommendations includes\nimmediate actions, inspection checklists, corrective measures, parts\nrequirements, and timeline specifications. Experimental validation in bearing\nvibration datasets demonstrates effective anomaly detection and contextually\nrelevant maintenance guidance. The system successfully bridges the gap between\ncondition monitoring and actionable maintenance planning, providing industrial\npractitioners with intelligent decision support. This work advances the\napplication of LLMs in industrial maintenance, offering a scalable framework\nfor prescriptive maintenance across machinery components and industrial\nsectors.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u667a\u80fd\u7cfb\u7edf\uff0c\u7528\u4e8e\u5de5\u4e1a\u673a\u68b0\u7684\u9884\u6d4b\u6027\u7ef4\u62a4\uff0c\u7ed3\u5408\u632f\u52a8\u9891\u7387\u5206\u6790\u548c\u591a\u4ee3\u7406\u751f\u6210\u6280\u672f\uff0c\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u7ef4\u62a4\u5efa\u8bae\u3002", "motivation": "\u5de5\u4e1a\u673a\u68b0\u7ef4\u62a4\u9700\u8981\u53ca\u65f6\u5e72\u9884\u4ee5\u9632\u6b62\u707e\u96be\u6027\u6545\u969c\u5e76\u4f18\u5316\u8fd0\u884c\u6548\u7387\u3002\u4f20\u7edf\u65b9\u6cd5\u901a\u5e38\u5c40\u9650\u4e8e\u5f02\u5e38\u68c0\u6d4b\uff0c\u7f3a\u4e4f\u5177\u4f53\u7684\u7ef4\u62a4\u5efa\u8bae\u3002", "method": "\u7cfb\u7edf\u5c06\u8f74\u627f\u632f\u52a8\u6570\u636e\uff08BPFO\u3001BPFI\u3001BSF\u3001FTF\u9891\u7387\uff09\u5e8f\u5217\u5316\u4e3a\u81ea\u7136\u8bed\u8a00\u4f9bLLM\u5904\u7406\uff0c\u7ed3\u5408\u591a\u4ee3\u7406\u7ec4\u4ef6\u5904\u7406\u7ef4\u62a4\u624b\u518c\u548c\u7f51\u7edc\u641c\u7d22\uff0c\u751f\u6210\u7ed3\u6784\u5316\u7ef4\u62a4\u5efa\u8bae\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u7cfb\u7edf\u80fd\u6709\u6548\u68c0\u6d4b\u5f02\u5e38\u5e76\u63d0\u4f9b\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u7ef4\u62a4\u6307\u5bfc\uff0c\u6210\u529f\u586b\u8865\u4e86\u72b6\u6001\u76d1\u6d4b\u4e0e\u53ef\u64cd\u4f5c\u7ef4\u62a4\u8ba1\u5212\u4e4b\u95f4\u7684\u7a7a\u767d\u3002", "conclusion": "\u8be5\u7814\u7a76\u63a8\u52a8\u4e86LLM\u5728\u5de5\u4e1a\u7ef4\u62a4\u4e2d\u7684\u5e94\u7528\uff0c\u4e3a\u8de8\u673a\u68b0\u7ec4\u4ef6\u548c\u5de5\u4e1a\u9886\u57df\u7684\u9884\u6d4b\u6027\u7ef4\u62a4\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u6846\u67b6\u3002"}}
{"id": "2508.05334", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.05334", "abs": "https://arxiv.org/abs/2508.05334", "authors": ["Ahsan Farabi", "Israt Khandaker", "Nusrat Jahan", "Ibrahim Khalil Shanto"], "title": "ShikkhaChain: A Blockchain-Powered Academic Credential Verification System for Bangladesh", "comment": null, "summary": "Academic credential fraud threatens educational integrity, especially in\ndeveloping countries like Bangladesh, where verification methods are primarily\nmanual and inefficient. To address this challenge, we present ShikkhaChain, a\nblockchain-powered certificate management platform designed to securely issue,\nverify, and revoke academic credentials in a decentralized and tamper-proof\nmanner. Built on Ethereum smart contracts and utilizing IPFS for off-chain\nstorage, the platform offers a transparent, scalable solution accessible\nthrough a React-based DApp with MetaMask integration. ShikkhaChain enables\nrole-based access for governments, regulators, institutions, and public\nverifiers, allowing QR-based validation and on-chain revocation tracking. Our\nprototype demonstrates enhanced trust, reduced verification time, and improved\ninternational credibility for Bangladeshi degrees, promoting a more reliable\nacademic and employment ecosystem.", "AI": {"tldr": "ShikkhaChain\u662f\u4e00\u4e2a\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u5b66\u672f\u8bc1\u4e66\u7ba1\u7406\u5e73\u53f0\uff0c\u65e8\u5728\u89e3\u51b3\u5b5f\u52a0\u62c9\u56fd\u7b49\u53d1\u5c55\u4e2d\u56fd\u5bb6\u56e0\u624b\u52a8\u9a8c\u8bc1\u65b9\u5f0f\u6548\u7387\u4f4e\u4e0b\u800c\u5bfc\u81f4\u7684\u5b66\u672f\u8bc1\u4e66\u6b3a\u8bc8\u95ee\u9898\u3002", "motivation": "\u5b66\u672f\u8bc1\u4e66\u6b3a\u8bc8\u5a01\u80c1\u6559\u80b2\u8bda\u4fe1\uff0c\u5c24\u5176\u662f\u5728\u5b5f\u52a0\u62c9\u56fd\u7b49\u53d1\u5c55\u4e2d\u56fd\u5bb6\uff0c\u5176\u9a8c\u8bc1\u65b9\u5f0f\u4e3b\u8981\u4e3a\u624b\u52a8\u4e14\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u5e73\u53f0\u57fa\u4e8e\u4ee5\u592a\u574a\u667a\u80fd\u5408\u7ea6\u548cIPFS\u79bb\u7ebf\u5b58\u50a8\uff0c\u901a\u8fc7React\u5f00\u53d1\u7684DApp\u4e0eMetaMask\u96c6\u6210\uff0c\u63d0\u4f9b\u900f\u660e\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u57fa\u4e8e\u89d2\u8272\u7684\u8bbf\u95ee\u548cQR\u7801\u9a8c\u8bc1\u3002", "result": "\u539f\u578b\u5c55\u793a\u4e86\u589e\u5f3a\u7684\u4fe1\u4efb\u5ea6\u3001\u51cf\u5c11\u7684\u9a8c\u8bc1\u65f6\u95f4\u4ee5\u53ca\u63d0\u5347\u7684\u56fd\u9645\u53ef\u4fe1\u5ea6\u3002", "conclusion": "ShikkhaChain\u4e3a\u5b5f\u52a0\u62c9\u56fd\u7684\u5b66\u672f\u548c\u5c31\u4e1a\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.04895", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.04895", "abs": "https://arxiv.org/abs/2508.04895", "authors": ["Wentao Lu", "Alexander Senchenko", "Abram Hindle", "Cor-Paul Bezemer"], "title": "Automated Bug Frame Retrieval from Gameplay Videos Using Vision-Language Models", "comment": null, "summary": "Modern game studios deliver new builds and patches at a rapid pace,\ngenerating thousands of bug reports, many of which embed gameplay videos. To\nverify and triage these bug reports, developers must watch the submitted\nvideos. This manual review is labour-intensive, slow, and hard to scale. In\nthis paper, we introduce an automated pipeline that reduces each video to a\nsingle frame that best matches the reported bug description, giving developers\ninstant visual evidence that pinpoints the bug.\n  Our pipeline begins with FFmpeg for keyframe extraction, reducing each video\nto a median of just 1.90% of its original frames while still capturing bug\nmoments in 98.79 of cases. These keyframes are then evaluated by a\nvision--language model (GPT-4o), which ranks them based on how well they match\nthe textual bug description and selects the most representative frame. We\nevaluated this approach using real-world developer-submitted gameplay videos\nand JIRA bug reports from a popular First-Person Shooter (FPS) game. The\npipeline achieves an overall F1 score of 0.79 and Accuracy of 0.89 for the\ntop-1 retrieved frame. Performance is highest for the Lighting & Shadow (F1 =\n0.94), Physics & Collision (0.86), and UI & HUD (0.83) bug categories, and\nlowest for Animation & VFX (0.51).\n  By replacing video viewing with an immediately informative image, our\napproach dramatically reduces manual effort and speeds up triage and regression\nchecks, offering practical benefits to quality assurance (QA) teams and\ndevelopers across the game industry.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u6d41\u7a0b\uff0c\u5c06\u6e38\u620fbug\u62a5\u544a\u4e2d\u7684\u89c6\u9891\u7b80\u5316\u4e3a\u6700\u80fd\u5339\u914dbug\u63cf\u8ff0\u7684\u5355\u5e27\u56fe\u50cf\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u5f00\u53d1\u8005\u7684\u624b\u52a8\u5de5\u4f5c\u3002", "motivation": "\u73b0\u4ee3\u6e38\u620f\u5de5\u4f5c\u5ba4\u5feb\u901f\u53d1\u5e03\u65b0\u7248\u672c\u548c\u8865\u4e01\uff0c\u751f\u6210\u5927\u91cf\u5305\u542b\u6e38\u620f\u89c6\u9891\u7684bug\u62a5\u544a\uff0c\u624b\u52a8\u5ba1\u6838\u8fd9\u4e9b\u89c6\u9891\u8017\u65f6\u4e14\u96be\u4ee5\u6269\u5c55\u3002", "method": "\u4f7f\u7528FFmpeg\u63d0\u53d6\u5173\u952e\u5e27\uff0c\u518d\u901a\u8fc7\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08GPT-4o\uff09\u8bc4\u4f30\u5e76\u9009\u62e9\u6700\u5339\u914dbug\u63cf\u8ff0\u7684\u4ee3\u8868\u6027\u5e27\u3002", "result": "\u5728\u771f\u5b9e\u6e38\u620f\u89c6\u9891\u548cJIRA bug\u62a5\u544a\u4e0a\u6d4b\u8bd5\uff0cF1\u5f97\u5206\u4e3a0.79\uff0c\u51c6\u786e\u7387\u4e3a0.89\uff0c\u6548\u679c\u56e0bug\u7c7b\u522b\u800c\u5f02\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u624b\u52a8\u5ba1\u6838\u65f6\u95f4\uff0c\u63d0\u5347\u4e86\u6e38\u620f\u5f00\u53d1\u4e2dbug\u5206\u7c7b\u548c\u56de\u5f52\u68c0\u67e5\u7684\u6548\u7387\u3002"}}
{"id": "2508.04719", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.04719", "abs": "https://arxiv.org/abs/2508.04719", "authors": ["Amulya Bhattaram", "Justin Chung", "Stanley Chung", "Ranit Gupta", "Janani Ramamoorthy", "Kartikeya Gullapalli", "Diana Marculescu", "Dimitrios Stamoulis"], "title": "GeoFlow: Agentic Workflow Automation for Geospatial Tasks", "comment": "Accepted to ACM SIGSPATIAL 2025", "summary": "We present GeoFlow, a method that automatically generates agentic workflows\nfor geospatial tasks. Unlike prior work that focuses on reasoning decomposition\nand leaves API selection implicit, our method provides each agent with detailed\ntool-calling objectives to guide geospatial API invocation at runtime. GeoFlow\nincreases agentic success by 6.8% and reduces token usage by up to fourfold\nacross major LLM families compared to state-of-the-art approaches.", "AI": {"tldr": "GeoFlow\u662f\u4e00\u79cd\u81ea\u52a8\u751f\u6210\u5730\u7406\u7a7a\u95f4\u4efb\u52a1\u4ee3\u7406\u5de5\u4f5c\u6d41\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u660e\u786e\u5de5\u5177\u8c03\u7528\u76ee\u6807\u63d0\u9ad8\u4ee3\u7406\u6210\u529f\u7387\u5e76\u51cf\u5c11\u4ee4\u724c\u4f7f\u7528\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u63a8\u7406\u5206\u89e3\u4e0a\u8868\u73b0\u4e0d\u8db3\uff0c\u4e14API\u9009\u62e9\u9690\u542b\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u3002GeoFlow\u65e8\u5728\u901a\u8fc7\u660e\u786e\u6307\u5bfc\u4ee3\u7406\u8c03\u7528\u5730\u7406\u7a7a\u95f4API\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "GeoFlow\u4e3a\u6bcf\u4e2a\u4ee3\u7406\u63d0\u4f9b\u8be6\u7ec6\u7684\u5de5\u5177\u8c03\u7528\u76ee\u6807\uff0c\u4ee5\u6307\u5bfc\u8fd0\u884c\u65f6\u5730\u7406\u7a7a\u95f4API\u7684\u8c03\u7528\u3002", "result": "\u4e0e\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u76f8\u6bd4\uff0cGeoFlow\u5c06\u4ee3\u7406\u6210\u529f\u7387\u63d0\u9ad8\u4e866.8%\uff0c\u5e76\u5c06\u4ee4\u724c\u4f7f\u7528\u91cf\u51cf\u5c11\u4e86\u56db\u500d\u3002", "conclusion": "GeoFlow\u901a\u8fc7\u660e\u786e\u5de5\u5177\u8c03\u7528\u76ee\u6807\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7406\u5728\u5730\u7406\u7a7a\u95f4\u4efb\u52a1\u4e2d\u7684\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2508.05394", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.05394", "abs": "https://arxiv.org/abs/2508.05394", "authors": ["Xiaoli Zhuo", "Xuehu Yan", "Wei Yan"], "title": "Grouped k-threshold random grid-based visual cryptography scheme", "comment": null, "summary": "Visual cryptography schemes (VCSs) belong to a category of secret image\nsharing schemes that do not require cryptographic knowledge for decryption,\ninstead relying directly on the human visual system. Among VCSs, random\ngrid-based VCS (RGVCS) has garnered widespread attention as it avoids pixel\nexpansion while requiring no basic matrices design. Contrast, a core metric for\nRGVCS, directly determines the visual quality of recovered images, rendering\nits optimization a critical research objective. However, existing $(k,n)$\nRGVCSs still fail to attain theoretical upper bounds on contrast, highlighting\nthe urgent need for higher-contrast constructions. In this paper, we propose a\nnovel sharing paradigm for RGVCS that constructs $(k,n)$-threshold schemes from\narbitrary $(k,n')$-threshold schemes $(k \\leq n'\\leq n)$, termed\n\\emph{$n'$-grouped $(k,n)$ RGVCS}. This paradigm establishes hierarchical\ncontrast characteristics: participants within the same group achieve optimal\nrecovery quality, while inter-group recovery shows a hierarchical contrast. We\nfurther introduce a new contrast calculation formula tailored to the new\nparadigm. Then, we propose a contrast-enhanced $(k,n)$ RGVCS by setting $n'=\nk$, achieving the highest contrast value documented in the existing literature.\nTheoretical analysis and experimental results demonstrate the superiority of\nour proposed scheme in terms of contrast.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u968f\u673a\u7f51\u683c\u89c6\u89c9\u5bc6\u7801\u65b9\u6848\uff08RGVCS\uff09\u5171\u4eab\u8303\u5f0f\uff0c\u901a\u8fc7\u6784\u5efa$(k,n)$-\u9608\u503c\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5bf9\u6bd4\u5ea6\uff0c\u8fbe\u5230\u4e86\u6587\u732e\u4e2d\u7684\u6700\u9ad8\u503c\u3002", "motivation": "\u73b0\u6709$(k,n)$ RGVCS\u672a\u80fd\u8fbe\u5230\u7406\u8bba\u5bf9\u6bd4\u5ea6\u4e0a\u9650\uff0c\u4e9f\u9700\u66f4\u9ad8\u5bf9\u6bd4\u5ea6\u7684\u6784\u9020\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa$n'$-grouped $(k,n)$ RGVCS\u8303\u5f0f\uff0c\u4ece\u4efb\u610f$(k,n')$-\u9608\u503c\u65b9\u6848\u6784\u5efa$(k,n)$-\u9608\u503c\u65b9\u6848\uff0c\u5e76\u5f15\u5165\u65b0\u7684\u5bf9\u6bd4\u5ea6\u8ba1\u7b97\u516c\u5f0f\u3002", "result": "\u901a\u8fc7\u8bbe\u7f6e$n'=k$\uff0c\u5b9e\u73b0\u4e86\u6587\u732e\u4e2d\u6700\u9ad8\u7684\u5bf9\u6bd4\u5ea6\u503c\uff0c\u7406\u8bba\u548c\u5b9e\u9a8c\u7ed3\u679c\u5747\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "conclusion": "\u65b0\u8303\u5f0f\u663e\u8457\u63d0\u5347\u4e86RGVCS\u7684\u5bf9\u6bd4\u5ea6\uff0c\u4e3a\u89c6\u89c9\u5bc6\u7801\u65b9\u6848\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2508.04921", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.04921", "abs": "https://arxiv.org/abs/2508.04921", "authors": ["Zixuan Feng", "Reed Milewicz", "Emerson Murphy-Hill", "Tyler Menezes", "Alexander Serebrenik", "Igor Steinmacher", "Anita Sarma"], "title": "Charting Uncertain Waters: A Socio-Technical Framework for Navigating GenAI's Impact on Open Source Communities", "comment": "13 pages, 1 figure", "summary": "Open Source Software communities face a wave of uncertainty as Generative AI\nrapidly transforms how software is created, maintained, and governed. Without\nclear frameworks, communities risk being overwhelmed by the complexity and\nambiguity introduced by GenAI, threatening the collaborative ethos that\nunderpins OSS. We conduct a scenario-driven, conceptual exploration using a\nsocio-technical framework inspired by McLuhan's Tetrad to surface both risks\nand opportunities for community resilience amid GenAI-driven disruption of OSS\ndevelopment across four domains: software practices, documentation, community\nengagement, and governance. By adopting this lens, OSS leaders and researchers\ncan proactively shape the future of their ecosystems, rather than simply\nreacting to technological upheaval.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u751f\u6210\u5f0fAI\u5bf9\u5f00\u6e90\u8f6f\u4ef6\u793e\u533a\u7684\u6f5c\u5728\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u793e\u4f1a\u6280\u672f\u6846\u67b6\u7684\u5206\u6790\u65b9\u6cd5\uff0c\u4ee5\u5e2e\u52a9\u793e\u533a\u5e94\u5bf9\u6311\u6218\u5e76\u6293\u4f4f\u673a\u9047\u3002", "motivation": "\u751f\u6210\u5f0fAI\u7684\u5feb\u901f\u53d1\u5c55\u4e3a\u5f00\u6e90\u8f6f\u4ef6\u793e\u533a\u5e26\u6765\u4e86\u4e0d\u786e\u5b9a\u6027\u548c\u590d\u6742\u6027\uff0c\u53ef\u80fd\u5a01\u80c1\u5176\u534f\u4f5c\u7cbe\u795e\u3002\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u6846\u67b6\u5206\u6790\uff0c\u5e2e\u52a9\u793e\u533a\u4e3b\u52a8\u5e94\u5bf9\u8fd9\u4e9b\u53d8\u5316\u3002", "method": "\u91c7\u7528\u57fa\u4e8eMcLuhan Tetrad\u7684\u793e\u4f1a\u6280\u672f\u6846\u67b6\uff0c\u901a\u8fc7\u60c5\u666f\u9a71\u52a8\u7684\u6982\u5ff5\u63a2\u7d22\uff0c\u5206\u6790\u751f\u6210\u5f0fAI\u5bf9\u8f6f\u4ef6\u5b9e\u8df5\u3001\u6587\u6863\u3001\u793e\u533a\u53c2\u4e0e\u548c\u6cbb\u7406\u56db\u4e2a\u9886\u57df\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u751f\u6210\u5f0fAI\u5e26\u6765\u7684\u98ce\u9669\u548c\u673a\u9047\uff0c\u4e3a\u5f00\u6e90\u793e\u533a\u63d0\u4f9b\u4e86\u5e94\u5bf9\u6280\u672f\u53d8\u9769\u7684\u6307\u5bfc\u3002", "conclusion": "\u901a\u8fc7\u91c7\u7528\u8fd9\u4e00\u6846\u67b6\uff0c\u5f00\u6e90\u793e\u533a\u9886\u5bfc\u8005\u548c\u7814\u7a76\u8005\u53ef\u4ee5\u4e3b\u52a8\u5851\u9020\u751f\u6001\u7cfb\u7edf\u7684\u672a\u6765\uff0c\u800c\u975e\u88ab\u52a8\u5e94\u5bf9\u6280\u672f\u98a0\u8986\u3002"}}
{"id": "2508.04720", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04720", "abs": "https://arxiv.org/abs/2508.04720", "authors": ["Yingjie Zhou", "Jiezhang Cao", "Farong Wen", "Li Xu", "Yanwei Jiang", "Jun Jia", "Ronghui Li", "Xiaohong Liu", "Yu Zhou", "Xiongkuo Min", "Jie Guo", "Zicheng Zhang", "Guangtao Zhai"], "title": "Who is a Better Player: LLM against LLM", "comment": null, "summary": "Adversarial board games, as a paradigmatic domain of strategic reasoning and\nintelligence, have long served as both a popular competitive activity and a\nbenchmark for evaluating artificial intelligence (AI) systems. Building on this\nfoundation, we propose an adversarial benchmarking framework to assess the\ncomprehensive performance of Large Language Models (LLMs) through board games\ncompetition, compensating the limitation of data dependency of the mainstream\nQuestion-and-Answer (Q&A) based benchmark method. We introduce Qi Town, a\nspecialized evaluation platform that supports 5 widely played games and\ninvolves 20 LLM-driven players. The platform employs both the Elo rating system\nand a novel Performance Loop Graph (PLG) to quantitatively evaluate the\ntechnical capabilities of LLMs, while also capturing Positive Sentiment Score\n(PSS) throughout gameplay to assess mental fitness. The evaluation is\nstructured as a round-robin tournament, enabling systematic comparison across\nplayers. Experimental results indicate that, despite technical differences,\nmost LLMs remain optimistic about winning and losing, demonstrating greater\nadaptability to high-stress adversarial environments than humans. On the other\nhand, the complex relationship between cyclic wins and losses in PLGs exposes\nthe instability of LLMs' skill play during games, warranting further\nexplanation and exploration.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u5bf9\u6297\u6027\u68cb\u76d8\u6e38\u620f\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6027\u80fd\u7684\u6846\u67b6\uff0c\u5f25\u8865\u4e86\u4e3b\u6d41\u95ee\u7b54\u57fa\u51c6\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u68cb\u76d8\u6e38\u620f\u4f5c\u4e3a\u6218\u7565\u63a8\u7406\u548c\u667a\u80fd\u7684\u5178\u578b\u9886\u57df\uff0c\u662f\u8bc4\u4f30AI\u7cfb\u7edf\u7684\u7406\u60f3\u57fa\u51c6\u3002\u73b0\u6709\u95ee\u7b54\u57fa\u51c6\u65b9\u6cd5\u4f9d\u8d56\u6570\u636e\uff0c\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u5f00\u53d1\u4e86Qi Town\u5e73\u53f0\uff0c\u652f\u63015\u79cd\u6e38\u620f\u548c20\u4e2aLLM\u9a71\u52a8\u7684\u73a9\u5bb6\uff0c\u4f7f\u7528Elo\u8bc4\u5206\u7cfb\u7edf\u548c\u6027\u80fd\u5faa\u73af\u56fe\uff08PLG\uff09\u5b9a\u91cf\u8bc4\u4f30LLMs\uff0c\u540c\u65f6\u901a\u8fc7\u79ef\u6781\u60c5\u7eea\u8bc4\u5206\uff08PSS\uff09\u8bc4\u4f30\u5fc3\u7406\u9002\u5e94\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5c3d\u7ba1\u6280\u672f\u5dee\u5f02\u5927\uff0c\u591a\u6570LLMs\u5728\u5bf9\u6297\u73af\u5883\u4e2d\u8868\u73b0\u4e50\u89c2\u4e14\u9002\u5e94\u6027\u5f3a\uff0c\u4f46PLG\u63ed\u793a\u4e86\u5176\u6280\u80fd\u8868\u73b0\u7684\u4e0d\u7a33\u5b9a\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aLLMs\u7684\u5168\u9762\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\uff0c\u4f46LLMs\u5728\u6e38\u620f\u4e2d\u7684\u4e0d\u7a33\u5b9a\u6027\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2508.05518", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.05518", "abs": "https://arxiv.org/abs/2508.05518", "authors": ["Weihong Sheng", "Jiajun Chen", "Bin Cai", "Chunqiang Hu", "Meng Han", "Jiguo Yu"], "title": "Local Distance Query with Differential Privacy", "comment": null, "summary": "Differential Privacy (DP) is commonly employed to safeguard graph analysis or\npublishing. Distance, a critical factor in graph analysis, is typically handled\nusing curator DP, where a trusted curator holds the complete neighbor lists of\nall vertices and answers queries privately. However, in many real-world\nscenarios, such a curator may not be present, posing a significant challenge\nfor implementing differentially private distance queries under Local\nDifferential Privacy (LDP). This paper proposes two approaches to address this\nchallenge. The first approach generates a synthetic graph by randomizing\nresponses and applies bitwise operations to reduce noise interference. However,\nlike other synthetic graph methods, this approach suffers from low utility. To\novercome this limitation, we propose a second approach, the first LDP method\nspecifically designed for distance queries, which captures the global graph\nstructure by continuously aggregating local distance vectors from neighboring\nvertices. This process enables the accurate updating of global distances. We\ndemonstrate the effectiveness of our method through comprehensive theoretical\nanalysis and experimental evaluations on real-world datasets.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e24\u79cd\u65b9\u6cd5\u89e3\u51b3\u672c\u5730\u5dee\u5206\u9690\u79c1\uff08LDP\uff09\u4e0b\u8ddd\u79bb\u67e5\u8be2\u7684\u6311\u6218\uff0c\u7b2c\u4e00\u79cd\u751f\u6210\u5408\u6210\u56fe\u4f46\u6548\u7528\u4f4e\uff0c\u7b2c\u4e8c\u79cd\u901a\u8fc7\u805a\u5408\u5c40\u90e8\u8ddd\u79bb\u5411\u91cf\u6355\u83b7\u5168\u5c40\u7ed3\u6784\u3002", "motivation": "\u73b0\u5b9e\u573a\u666f\u4e2d\u7f3a\u4e4f\u53ef\u4fe1\u7684\u7b2c\u4e09\u65b9\u7ba1\u7406\u8005\uff0c\u5bfc\u81f4\u5728LDP\u4e0b\u5b9e\u73b0\u5dee\u5206\u9690\u79c1\u8ddd\u79bb\u67e5\u8be2\u56f0\u96be\u3002", "method": "\u65b9\u6cd5\u4e00\uff1a\u751f\u6210\u5408\u6210\u56fe\u5e76\u51cf\u5c11\u566a\u58f0\u5e72\u6270\uff1b\u65b9\u6cd5\u4e8c\uff1a\u901a\u8fc7\u5c40\u90e8\u8ddd\u79bb\u5411\u91cf\u805a\u5408\u6355\u83b7\u5168\u5c40\u7ed3\u6784\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\u7b2c\u4e8c\u79cd\u65b9\u6cd5\u6709\u6548\u3002", "conclusion": "\u7b2c\u4e8c\u79cd\u65b9\u6cd5\u89e3\u51b3\u4e86LDP\u4e0b\u8ddd\u79bb\u67e5\u8be2\u7684\u6311\u6218\uff0c\u5e76\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u3002"}}
{"id": "2508.04925", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04925", "abs": "https://arxiv.org/abs/2508.04925", "authors": ["Sigma Jahan", "Saurabh Singh Rajput", "Tushar Sharma", "Mohammad Masudur Rahman"], "title": "Taxonomy of Faults in Attention-Based Neural Networks", "comment": null, "summary": "Attention mechanisms are at the core of modern neural architectures, powering\nsystems ranging from ChatGPT to autonomous vehicles and driving a major\neconomic impact. However, high-profile failures, such as ChatGPT's nonsensical\noutputs or Google's suspension of Gemini's image generation due to attention\nweight errors, highlight a critical gap: existing deep learning fault\ntaxonomies might not adequately capture the unique failures introduced by\nattention mechanisms. This gap leaves practitioners without actionable\ndiagnostic guidance. To address this gap, we present the first comprehensive\nempirical study of faults in attention-based neural networks (ABNNs). Our work\nis based on a systematic analysis of 555 real-world faults collected from 96\nprojects across ten frameworks, including GitHub, Hugging Face, and Stack\nOverflow. Through our analysis, we develop a novel taxonomy comprising seven\nattention-specific fault categories, not captured by existing work. Our results\nshow that over half of the ABNN faults arise from mechanisms unique to\nattention architectures. We further analyze the root causes and manifestations\nof these faults through various symptoms. Finally, by analyzing symptom-root\ncause associations, we identify four evidence-based diagnostic heuristics that\nexplain 33.0% of attention-specific faults, offering the first systematic\ndiagnostic guidance for attention-based models.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u5bf9\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u795e\u7ecf\u7f51\u7edc\uff08ABNNs\uff09\u4e2d\u7684\u6545\u969c\u8fdb\u884c\u4e86\u5168\u9762\u5b9e\u8bc1\u7814\u7a76\uff0c\u63d0\u51fa\u4e86\u4e03\u79cd\u6ce8\u610f\u529b\u7279\u6709\u7684\u6545\u969c\u7c7b\u522b\uff0c\u5e76\u63d0\u4f9b\u4e86\u8bca\u65ad\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6545\u969c\u5206\u7c7b\u6cd5\u672a\u80fd\u5145\u5206\u6355\u6349\u6ce8\u610f\u529b\u673a\u5236\u5f15\u5165\u7684\u72ec\u7279\u6545\u969c\uff0c\u5bfc\u81f4\u7f3a\u4e4f\u53ef\u64cd\u4f5c\u7684\u8bca\u65ad\u6307\u5bfc\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u5206\u6790\u6765\u81ea96\u4e2a\u9879\u76ee\u3001555\u4e2a\u771f\u5b9e\u6545\u969c\u7684\u6570\u636e\uff0c\u5f00\u53d1\u4e86\u65b0\u7684\u6ce8\u610f\u529b\u7279\u6709\u6545\u969c\u5206\u7c7b\u6cd5\u3002", "result": "\u8d85\u8fc7\u4e00\u534a\u7684ABNN\u6545\u969c\u6e90\u4e8e\u6ce8\u610f\u529b\u67b6\u6784\u7279\u6709\u7684\u673a\u5236\uff0c\u7814\u7a76\u8fd8\u8bc6\u522b\u4e86\u56db\u79cd\u8bca\u65ad\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u89e3\u91ca\u4e8633.0%\u7684\u6ce8\u610f\u529b\u7279\u6709\u6545\u969c\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u6ce8\u610f\u529b\u673a\u5236\u6545\u969c\u8bca\u65ad\u7684\u7a7a\u767d\uff0c\u4e3a\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u6a21\u578b\u63d0\u4f9b\u4e86\u9996\u4e2a\u7cfb\u7edf\u6027\u8bca\u65ad\u6307\u5bfc\u3002"}}
{"id": "2508.04846", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.04846", "abs": "https://arxiv.org/abs/2508.04846", "authors": ["Mahdi Nazari Ashani", "Ali Asghar Alesheikh", "Saba Kazemi", "Kimya Kheirkhah", "Yasin Mohammadi", "Fatemeh Rezaie", "Amir Mahdi Manafi", "Hedieh Zarkesh"], "title": "Fine-Tuning Small Language Models (SLMs) for Autonomous Web-based Geographical Information Systems (AWebGIS)", "comment": null, "summary": "Autonomous web-based geographical information systems (AWebGIS) aim to\nperform geospatial operations from natural language input, providing intuitive,\nintelligent, and hands-free interaction. However, most current solutions rely\non cloud-based large language models (LLMs), which require continuous internet\naccess and raise users' privacy and scalability issues due to centralized\nserver processing. This study compares three approaches to enabling AWebGIS:\n(1) a fully-automated online method using cloud-based LLMs (e.g., Cohere); (2)\na semi-automated offline method using classical machine learning classifiers\nsuch as support vector machine and random forest; and (3) a fully autonomous\noffline (client-side) method based on a fine-tuned small language model (SLM),\nspecifically T5-small model, executed in the client's web browser. The third\napproach, which leverages SLMs, achieved the highest accuracy among all\nmethods, with an exact matching accuracy of 0.93, Levenshtein similarity of\n0.99, and recall-oriented understudy for gisting evaluation ROUGE-1 and ROUGE-L\nscores of 0.98. Crucially, this client-side computation strategy reduces the\nload on backend servers by offloading processing to the user's device,\neliminating the need for server-based inference. These results highlight the\nfeasibility of browser-executable models for AWebGIS solutions.", "AI": {"tldr": "\u6bd4\u8f83\u4e86\u4e09\u79cd\u5b9e\u73b0\u81ea\u4e3bWebGIS\u7684\u65b9\u6cd5\uff0c\u53d1\u73b0\u57fa\u4e8e\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5ba2\u6237\u7aef\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u65b9\u9762\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u4e91\u57fa\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9690\u79c1\u3001\u53ef\u6269\u5c55\u6027\u548c\u7f51\u7edc\u4f9d\u8d56\u6027\u65b9\u9762\u7684\u95ee\u9898\u3002", "method": "\u6bd4\u8f83\u4e86\u4e09\u79cd\u65b9\u6cd5\uff1a\u4e91\u57faLLM\u3001\u534a\u81ea\u52a8\u79bb\u7ebf\u65b9\u6cd5\u548c\u57fa\u4e8e\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b8c\u5168\u79bb\u7ebf\u5ba2\u6237\u7aef\u65b9\u6cd5\u3002", "result": "\u5ba2\u6237\u7aef\u65b9\u6cd5\u51c6\u786e\u7387\u6700\u9ad8\uff080.93\uff09\uff0c\u4e14\u51cf\u5c11\u4e86\u670d\u52a1\u5668\u8d1f\u8f7d\u3002", "conclusion": "\u6d4f\u89c8\u5668\u53ef\u6267\u884c\u6a21\u578b\u662f\u5b9e\u73b0\u81ea\u4e3bWebGIS\u7684\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2508.05545", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.05545", "abs": "https://arxiv.org/abs/2508.05545", "authors": ["Leon Garza", "Anantaa Kotal", "Aritran Piplai", "Lavanya Elluri", "Prajit Das", "Aman Chadha"], "title": "PRvL: Quantifying the Capabilities and Risks of Large Language Models for PII Redaction", "comment": null, "summary": "Redacting Personally Identifiable Information (PII) from unstructured text is\ncritical for ensuring data privacy in regulated domains. While earlier\napproaches have relied on rule-based systems and domain-specific Named Entity\nRecognition (NER) models, these methods fail to generalize across formats and\ncontexts. Recent advances in Large Language Models (LLMs) offer a promising\nalternative, yet the effect of architectural and training choices on redaction\nperformance remains underexplored. LLMs have demonstrated strong performance in\ntasks that require contextual language understanding, including the redaction\nof PII in free-form text. Prior work suggests that with appropriate adaptation,\nLLMs can become effective contextual privacy learners. However, the\nconsequences of architectural and training choices for PII Redaction remain\nunderexplored. In this work, we present a comprehensive analysis of LLMs as\nprivacy-preserving PII Redaction systems. We evaluate a range of LLM\narchitectures and training strategies for their effectiveness in PII Redaction.\nOur analysis measures redaction performance, semantic preservation, and PII\nleakage, and compares these outcomes against latency and computational cost.\nThe results provide practical guidance for configuring LLM-based redactors that\nare accurate, efficient, and privacy-aware. To support reproducibility and\nreal-world deployment, we release PRvL, an open-source suite of fine-tuned\nmodels, and evaluation tools for general-purpose PII Redaction. PRvL is built\nentirely on open-source LLMs and supports multiple inference settings for\nflexibility and compliance. It is designed to be easily customized for\ndifferent domains and fully operable within secure, self-managed environments.\nThis enables data owners to perform redactions without relying on third-party\nservices or exposing sensitive content beyond their own infrastructure.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8fdb\u884c\u4e2a\u4eba\u8eab\u4efd\u4fe1\u606f\uff08PII\uff09\u8131\u654f\u7684\u65b9\u6cd5\uff0c\u5206\u6790\u4e86\u4e0d\u540c\u67b6\u6784\u548c\u8bad\u7ec3\u7b56\u7565\u7684\u6548\u679c\uff0c\u5e76\u63d0\u51fa\u4e86\u5f00\u6e90\u5de5\u5177PRvL\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u548c\u7279\u5b9a\u9886\u57dfNER\u6a21\u578b\u7684\u65b9\u6cd5\u65e0\u6cd5\u6cdb\u5316\uff0cLLMs\u5728\u4e0a\u4e0b\u6587\u7406\u89e3\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u5728PII\u8131\u654f\u4e2d\u7684\u5177\u4f53\u5e94\u7528\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002", "method": "\u8bc4\u4f30\u591a\u79cdLLM\u67b6\u6784\u548c\u8bad\u7ec3\u7b56\u7565\uff0c\u8861\u91cf\u8131\u654f\u6027\u80fd\u3001\u8bed\u4e49\u4fdd\u7559\u548cPII\u6cc4\u6f0f\uff0c\u5e76\u4e0e\u5ef6\u8fdf\u548c\u8ba1\u7b97\u6210\u672c\u5bf9\u6bd4\u3002", "result": "\u63d0\u4f9b\u4e86\u914d\u7f6e\u9ad8\u6548\u3001\u51c6\u786e\u4e14\u9690\u79c1\u4fdd\u62a4\u7684LLM\u8131\u654f\u7cfb\u7edf\u7684\u5b9e\u7528\u6307\u5357\uff0c\u5e76\u5f00\u6e90\u4e86PRvL\u5de5\u5177\u3002", "conclusion": "LLMs\u5728PII\u8131\u654f\u4e2d\u5177\u6709\u6f5c\u529b\uff0cPRvL\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u7075\u6d3b\u4e14\u5408\u89c4\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.05005", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.05005", "abs": "https://arxiv.org/abs/2508.05005", "authors": ["Gang Xu", "Airong Wang", "Yushan Pan"], "title": "Generative AI for Object-Oriented Programming: Writing the Right Code and Reasoning the Right Logic", "comment": null, "summary": "We find ourselves in the midst of an explosion in artificial intelligence\nresearch, particularly with large language models (LLMs). These models have\ndiverse applications spanning finance, commonsense knowledge graphs, medicine,\nand visual analysis. In the world of Object-Oriented Programming(OOP), a robust\nbody of knowledge and methods has been developed for managing complex tasks\nthrough object-oriented thinking. However, the intersection of LLMs with OOP\nremains an underexplored territory. Empirically, we currently possess limited\nunderstanding of how LLMs can enhance the effectiveness of OOP learning and\ncode writing, as well as how we can evaluate such AI-powered tools. Our work\naims to address this gap by presenting a vision from the perspectives of key\nstakeholders involved in an OOP task: programmers, mariners, and experienced\nprogrammers. We identify critical junctures within typical coding workflows\nwhere the integration of LLMs can offer significant benefits. Furthermore, we\npropose ways to augment existing logical reasoning and code writing, ultimately\nenhancing the programming experience.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0e\u9762\u5411\u5bf9\u8c61\u7f16\u7a0b\uff08OOP\uff09\u7684\u7ed3\u5408\uff0c\u63d0\u51fa\u4e86\u5982\u4f55\u5229\u7528LLMs\u63d0\u5347OOP\u5b66\u4e60\u548c\u4ee3\u7801\u7f16\u5199\u7684\u6548\u679c\uff0c\u5e76\u8bc4\u4f30\u76f8\u5173AI\u5de5\u5177\u3002", "motivation": "\u5f53\u524dLLMs\u4e0eOOP\u7684\u7ed3\u5408\u7814\u7a76\u4e0d\u8db3\uff0c\u7f3a\u4e4f\u5bf9\u5176\u5728\u7f16\u7a0b\u4efb\u52a1\u4e2d\u63d0\u5347\u6548\u679c\u7684\u7406\u89e3\u548c\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u4ece\u7a0b\u5e8f\u5458\u3001\u65b0\u624b\u548c\u7ecf\u9a8c\u4e30\u5bcc\u7684\u7a0b\u5e8f\u5458\u7b49\u5173\u952e\u5229\u76ca\u76f8\u5173\u8005\u7684\u89c6\u89d2\u51fa\u53d1\uff0c\u8bc6\u522b\u7f16\u7801\u5de5\u4f5c\u6d41\u4e2dLLMs\u53ef\u63d0\u4f9b\u663e\u8457\u5e2e\u52a9\u7684\u5173\u952e\u8282\u70b9\uff0c\u5e76\u63d0\u51fa\u589e\u5f3a\u903b\u8f91\u63a8\u7406\u548c\u4ee3\u7801\u7f16\u5199\u7684\u65b9\u6cd5\u3002", "result": "\u63d0\u51fa\u4e86LLMs\u5728OOP\u4efb\u52a1\u4e2d\u7684\u6f5c\u5728\u5e94\u7528\u573a\u666f\u548c\u4f18\u5316\u65b9\u6cd5\u3002", "conclusion": "LLMs\u4e0eOOP\u7684\u7ed3\u5408\u6709\u671b\u663e\u8457\u63d0\u5347\u7f16\u7a0b\u4f53\u9a8c\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u5b9e\u8df5\u9a8c\u8bc1\u3002"}}
{"id": "2508.04848", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04848", "abs": "https://arxiv.org/abs/2508.04848", "authors": ["Chang Tian", "Matthew B. Blaschko", "Mingzhe Xing", "Xiuxing Li", "Yinliang Yue", "Marie-Francine Moens"], "title": "Large Language Models Reasoning Abilities Under Non-Ideal Conditions After RL-Fine-Tuning", "comment": "large language models, large vision-language model, reasoning,\n  non-ideal conditions, reinforcement learning", "summary": "Reinforcement learning (RL) has become a key technique for enhancing the\nreasoning abilities of large language models (LLMs), with policy-gradient\nalgorithms dominating the post-training stage because of their efficiency and\neffectiveness. However, most existing benchmarks evaluate large-language-model\nreasoning under idealized settings, overlooking performance in realistic,\nnon-ideal scenarios. We identify three representative non-ideal scenarios with\npractical relevance: summary inference, fine-grained noise suppression, and\ncontextual filtering. We introduce a new research direction guided by\nbrain-science findings that human reasoning remains reliable under imperfect\ninputs. We formally define and evaluate these challenging scenarios. We\nfine-tune three LLMs and a state-of-the-art large vision-language model (LVLM)\nusing RL with a representative policy-gradient algorithm and then test their\nperformance on eight public datasets. Our results reveal that while RL\nfine-tuning improves baseline reasoning under idealized settings, performance\ndeclines significantly across all three non-ideal scenarios, exposing critical\nlimitations in advanced reasoning capabilities. Although we propose a\nscenario-specific remediation method, our results suggest current methods leave\nthese reasoning deficits largely unresolved. This work highlights that the\nreasoning abilities of large models are often overstated and underscores the\nimportance of evaluating models under non-ideal scenarios. The code and data\nwill be released at XXXX.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u5728\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u63a8\u7406\u80fd\u529b\u4e2d\u7684\u4f5c\u7528\uff0c\u53d1\u73b0\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5ffd\u89c6\u4e86\u975e\u7406\u60f3\u573a\u666f\u4e0b\u7684\u6027\u80fd\u8868\u73b0\uff0c\u5e76\u63d0\u51fa\u4e86\u4e09\u79cd\u5177\u6709\u5b9e\u9645\u610f\u4e49\u7684\u975e\u7406\u60f3\u573a\u666f\u3002\u5b9e\u9a8c\u8868\u660e\uff0cRL\u5fae\u8c03\u5728\u7406\u60f3\u573a\u666f\u4e0b\u6709\u6548\uff0c\u4f46\u5728\u975e\u7406\u60f3\u573a\u666f\u4e2d\u8868\u73b0\u663e\u8457\u4e0b\u964d\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5173\u6ce8\u7406\u60f3\u573a\u666f\uff0c\u5ffd\u89c6\u4e86\u5b9e\u9645\u5e94\u7528\u4e2d\u53ef\u80fd\u9047\u5230\u7684\u975e\u7406\u60f3\u60c5\u51b5\uff0c\u5982\u6458\u8981\u63a8\u65ad\u3001\u7ec6\u7c92\u5ea6\u566a\u58f0\u6291\u5236\u548c\u4e0a\u4e0b\u6587\u8fc7\u6ee4\u3002\u8bba\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u5e76\u8bc4\u4f30\u6a21\u578b\u5728\u8fd9\u4e9b\u573a\u666f\u4e0b\u7684\u8868\u73b0\u3002", "method": "\u901a\u8fc7RL\u5fae\u8c03\u4e09\u79cdLLMs\u548c\u4e00\u79cd\u5148\u8fdb\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08LVLM\uff09\uff0c\u4f7f\u7528\u7b56\u7565\u68af\u5ea6\u7b97\u6cd5\uff0c\u5e76\u5728\u516b\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u5176\u6027\u80fd\u3002", "result": "RL\u5fae\u8c03\u5728\u7406\u60f3\u573a\u666f\u4e0b\u63d0\u5347\u4e86\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5728\u4e09\u79cd\u975e\u7406\u60f3\u573a\u666f\u4e2d\u8868\u73b0\u663e\u8457\u4e0b\u964d\uff0c\u66b4\u9732\u4e86\u5f53\u524d\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u88ab\u9ad8\u4f30\u7684\u95ee\u9898\uff0c\u5e76\u547c\u5401\u5728\u975e\u7406\u60f3\u573a\u666f\u4e0b\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2508.05034", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.05034", "abs": "https://arxiv.org/abs/2508.05034", "authors": ["Arabat", "Ali", "Sayagh", "Mohammed", "Hassine", "Jameleddine"], "title": "An ML-based Approach to Predicting Software Change Dependencies: Insights from an Empirical Study on OpenStack", "comment": null, "summary": "As software systems grow in complexity, accurately identifying and managing\ndependencies among changes becomes increasingly critical. For instance, a\nchange that leverages a function must depend on the change that introduces it.\nEstablishing such dependencies allows CI/CD pipelines to build and orchestrate\nchanges effectively, preventing build failures and incomplete feature\ndeployments. In modern software systems, dependencies often span multiple\ncomponents across teams, creating challenges for development and deployment.\nThey serve various purposes, from enabling new features to managing\nconfigurations, and can even involve traditionally independent changes like\ndocumentation updates. To address these challenges, we conducted a preliminary\nstudy on dependency management in OpenStack, a large-scale software system. Our\nstudy revealed that a substantial portion of software changes in OpenStack over\nthe past 10 years are interdependent. Surprisingly, 51.08% of these\ndependencies are identified during the code review phase-after a median delay\nof 5.06 hours-rather than at the time of change creation. Developers often\nspend a median of 57.12 hours identifying dependencies, searching among a\nmedian of 463 other changes. To help developers proactively identify\ndependencies, we propose a semi-automated approach that leverages two ML\nmodels. The first model predicts the likelihood of dependencies among changes,\nwhile the second identifies the exact pairs of dependent changes. Our proposed\nmodels demonstrate strong performance, achieving average AUC scores of 79.33%\nand 91.89%, and Brier scores of 0.11 and 0.014, respectively. Indeed, the\nsecond model has a good top-k recall across all types of pairs, while the top-k\nprecision has room for improvement.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\u53d8\u66f4\u4f9d\u8d56\u7ba1\u7406\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u534a\u81ea\u52a8\u5316\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u9884\u6d4b\u548c\u8bc6\u522b\u4f9d\u8d56\u5173\u7cfb\uff0c\u4ee5\u51cf\u5c11\u5f00\u53d1\u8005\u5728\u4ee3\u7801\u5ba1\u67e5\u9636\u6bb5\u7684\u5ef6\u8fdf\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u7cfb\u7edf\u590d\u6742\u6027\u7684\u589e\u52a0\uff0c\u51c6\u786e\u8bc6\u522b\u548c\u7ba1\u7406\u53d8\u66f4\u4f9d\u8d56\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u662f\u5728\u591a\u56e2\u961f\u534f\u4f5c\u7684\u5927\u578b\u7cfb\u7edf\u4e2d\uff0c\u4f9d\u8d56\u5173\u7cfb\u53ef\u80fd\u5bfc\u81f4\u6784\u5efa\u5931\u8d25\u548c\u90e8\u7f72\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u521d\u6b65\u7814\u7a76OpenStack\u7cfb\u7edf\u4e2d\u7684\u4f9d\u8d56\u7ba1\u7406\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e24\u4e2a\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u534a\u81ea\u52a8\u5316\u65b9\u6cd5\uff1a\u4e00\u4e2a\u9884\u6d4b\u53d8\u66f4\u95f4\u7684\u4f9d\u8d56\u53ef\u80fd\u6027\uff0c\u53e6\u4e00\u4e2a\u8bc6\u522b\u5177\u4f53\u7684\u4f9d\u8d56\u5bf9\u3002", "result": "\u6a21\u578b\u8868\u73b0\u826f\u597d\uff0c\u5e73\u5747AUC\u5206\u6570\u5206\u522b\u4e3a79.33%\u548c91.89%\uff0cBrier\u5206\u6570\u4e3a0.11\u548c0.014\u3002\u7b2c\u4e8c\u4e2a\u6a21\u578b\u5728top-k\u53ec\u56de\u7387\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46top-k\u7cbe\u786e\u5ea6\u6709\u5f85\u63d0\u5347\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u5e2e\u52a9\u5f00\u53d1\u8005\u63d0\u524d\u8bc6\u522b\u4f9d\u8d56\u5173\u7cfb\uff0c\u51cf\u5c11\u4ee3\u7801\u5ba1\u67e5\u9636\u6bb5\u7684\u5ef6\u8fdf\uff0c\u63d0\u5347\u5f00\u53d1\u6548\u7387\u3002"}}
{"id": "2508.04915", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.04915", "abs": "https://arxiv.org/abs/2508.04915", "authors": ["Huiya Zhao", "Yinghao Zhu", "Zixiang Wang", "Yasha Wang", "Junyi Gao", "Liantao Ma"], "title": "ConfAgents: A Conformal-Guided Multi-Agent Framework for Cost-Efficient Medical Diagnosis", "comment": "Code: https://github.com/PKU-AICare/ConfAgents", "summary": "The efficacy of AI agents in healthcare research is hindered by their\nreliance on static, predefined strategies. This creates a critical limitation:\nagents can become better tool-users but cannot learn to become better strategic\nplanners, a crucial skill for complex domains like healthcare. We introduce\nHealthFlow, a self-evolving AI agent that overcomes this limitation through a\nnovel meta-level evolution mechanism. HealthFlow autonomously refines its own\nhigh-level problem-solving policies by distilling procedural successes and\nfailures into a durable, strategic knowledge base. To anchor our research and\nfacilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark\nfeaturing complex, realistic health data analysis tasks derived from\npeer-reviewed clinical research. Our comprehensive experiments demonstrate that\nHealthFlow's self-evolving approach significantly outperforms state-of-the-art\nagent frameworks. This work marks a necessary shift from building better\ntool-users to designing smarter, self-evolving task-managers, paving the way\nfor more autonomous and effective AI for scientific discovery.", "AI": {"tldr": "HealthFlow\u662f\u4e00\u79cd\u81ea\u8fdb\u5316\u7684AI\u4ee3\u7406\uff0c\u901a\u8fc7\u5143\u7ea7\u8fdb\u5316\u673a\u5236\u63d0\u5347\u6218\u7565\u89c4\u5212\u80fd\u529b\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6846\u67b6\u3002", "motivation": "\u73b0\u6709AI\u4ee3\u7406\u5728\u533b\u7597\u7814\u7a76\u4e2d\u4f9d\u8d56\u9759\u6001\u7b56\u7565\uff0c\u65e0\u6cd5\u63d0\u5347\u6218\u7565\u89c4\u5212\u80fd\u529b\uff0c\u9650\u5236\u4e86\u5176\u6548\u80fd\u3002", "method": "\u5f15\u5165HealthFlow\uff0c\u901a\u8fc7\u5143\u7ea7\u8fdb\u5316\u673a\u5236\u81ea\u4e3b\u4f18\u5316\u95ee\u9898\u89e3\u51b3\u7b56\u7565\uff0c\u5e76\u5f00\u53d1EHRFlowBench\u57fa\u51c6\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u8868\u660eHealthFlow\u5728\u590d\u6742\u533b\u7597\u6570\u636e\u5206\u6790\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6846\u67b6\u3002", "conclusion": "\u8be5\u7814\u7a76\u6807\u5fd7\u7740\u4ece\u5de5\u5177\u4f7f\u7528\u8005\u5411\u81ea\u8fdb\u5316\u4efb\u52a1\u7ba1\u7406\u8005\u7684\u8f6c\u53d8\uff0c\u4e3a\u66f4\u81ea\u4e3b\u7684AI\u79d1\u5b66\u53d1\u73b0\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2508.05085", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.05085", "abs": "https://arxiv.org/abs/2508.05085", "authors": ["Junayed Mahmud", "James Chen", "Terry Achille", "Camilo Alvarez-Velez", "Darren Dean Bansil", "Patrick Ijieh", "Samar Karanch", "Nadeeshan De Silva", "Oscar Chaparro", "Andrian Marcus", "Kevin Moran"], "title": "LadyBug: A GitHub Bot for UI-Enhanced Bug Localization in Mobile Apps", "comment": "5 pages, to appear in the Proceedings of the 41st International\n  Conference on Software Maintenance and Evolution (ICSME'25) - Tool\n  Demonstration Track", "summary": "This paper introduces LadyBug, a GitHub bot that automatically localizes bugs\nfor Android apps by combining UI interaction information with text retrieval.\nLadyBug connects to an Android app's GitHub repository, and is triggered when a\nbug is reported in the corresponding issue tracker. Developers can then record\na reproduction trace for the bug on a device or emulator and upload the trace\nto LadyBug via the GitHub issue tracker. This enables LadyBug to utilize both\nthe text from the original bug description, and UI information from the\nreproduction trace to accurately retrieve a ranked list of files from the\nproject that most likely contain the reported bug.\n  We empirically evaluated LadyBug using an automated testing pipeline and\nbenchmark called RedWing that contains 80 fully-localized and reproducible bug\nreports from 39 Android apps. Our results illustrate that LadyBug outperforms\ntext-retrieval-based baselines and that the utilization of UI information leads\nto a substantial increase in localization accuracy. LadyBug is an open-source\ntool, available at https://github.com/LadyBugML/ladybug.\n  A video showing the capabilities of Ladybug can be viewed here:\nhttps://youtu.be/hI3tzbRK0Cw", "AI": {"tldr": "LadyBug\u662f\u4e00\u4e2aGitHub\u673a\u5668\u4eba\uff0c\u901a\u8fc7\u7ed3\u5408UI\u4ea4\u4e92\u4fe1\u606f\u548c\u6587\u672c\u68c0\u7d22\uff0c\u81ea\u52a8\u5b9a\u4f4dAndroid\u5e94\u7528\u4e2d\u7684bug\u3002", "motivation": "\u63d0\u9ad8Android\u5e94\u7528\u4e2dbug\u5b9a\u4f4d\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u7ed3\u5408\u6587\u672c\u548cUI\u4fe1\u606f\u3002", "method": "\u8fde\u63a5GitHub\u4ed3\u5e93\uff0c\u901a\u8fc7\u95ee\u9898\u8ffd\u8e2a\u5668\u89e6\u53d1\uff0c\u5f00\u53d1\u8005\u4e0a\u4f20bug\u91cd\u73b0\u8f68\u8ff9\uff0c\u7ed3\u5408\u6587\u672c\u548cUI\u4fe1\u606f\u68c0\u7d22\u76f8\u5173\u6587\u4ef6\u3002", "result": "\u5728\u5305\u542b80\u4e2abug\u62a5\u544a\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLadyBug\u4f18\u4e8e\u7eaf\u6587\u672c\u68c0\u7d22\u65b9\u6cd5\uff0cUI\u4fe1\u606f\u663e\u8457\u63d0\u5347\u5b9a\u4f4d\u51c6\u786e\u6027\u3002", "conclusion": "LadyBug\u662f\u4e00\u4e2a\u6709\u6548\u7684\u5f00\u6e90\u5de5\u5177\uff0c\u7ed3\u5408UI\u548c\u6587\u672c\u4fe1\u606f\u663e\u8457\u63d0\u5347bug\u5b9a\u4f4d\u6548\u679c\u3002"}}
{"id": "2508.05006", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.05006", "abs": "https://arxiv.org/abs/2508.05006", "authors": ["Youzhi Zhang", "Yufei Li", "Gaofeng Meng", "Hongbin Liu", "Jiebo Luo"], "title": "The Docking Game: Loop Self-Play for Fast, Dynamic, and Accurate Prediction of Flexible Protein--Ligand Binding", "comment": "21 pages, 9 figures", "summary": "Molecular docking is a crucial aspect of drug discovery, as it predicts the\nbinding interactions between small-molecule ligands and protein pockets.\nHowever, current multi-task learning models for docking often show inferior\nperformance in ligand docking compared to protein pocket docking. This\ndisparity arises largely due to the distinct structural complexities of ligands\nand proteins. To address this issue, we propose a novel game-theoretic\nframework that models the protein-ligand interaction as a two-player game\ncalled the Docking Game, with the ligand docking module acting as the ligand\nplayer and the protein pocket docking module as the protein player. To solve\nthis game, we develop a novel Loop Self-Play (LoopPlay) algorithm, which\nalternately trains these players through a two-level loop. In the outer loop,\nthe players exchange predicted poses, allowing each to incorporate the other's\nstructural predictions, which fosters mutual adaptation over multiple\niterations. In the inner loop, each player dynamically refines its predictions\nby incorporating its own predicted ligand or pocket poses back into its model.\nWe theoretically show the convergence of LoopPlay, ensuring stable\noptimization. Extensive experiments conducted on public benchmark datasets\ndemonstrate that LoopPlay achieves approximately a 10\\% improvement in\npredicting accurate binding modes compared to previous state-of-the-art\nmethods. This highlights its potential to enhance the accuracy of molecular\ndocking in drug discovery.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u535a\u5f08\u8bba\u7684\u65b0\u6846\u67b6Docking Game\uff0c\u901a\u8fc7LoopPlay\u7b97\u6cd5\u63d0\u5347\u5206\u5b50\u5bf9\u63a5\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u591a\u4efb\u52a1\u5b66\u4e60\u6a21\u578b\u4e2d\u914d\u4f53\u5bf9\u63a5\u6027\u80fd\u8f83\u5dee\u7684\u95ee\u9898\uff0c\u56e0\u914d\u4f53\u4e0e\u86cb\u767d\u8d28\u7ed3\u6784\u590d\u6742\u6027\u5dee\u5f02\u5bfc\u81f4\u3002", "method": "\u5c06\u86cb\u767d\u8d28-\u914d\u4f53\u4ea4\u4e92\u5efa\u6a21\u4e3a\u53cc\u73a9\u5bb6\u535a\u5f08\uff0c\u5f00\u53d1LoopPlay\u7b97\u6cd5\uff0c\u901a\u8fc7\u5185\u5916\u5faa\u73af\u4ea4\u66ff\u8bad\u7ec3\u73a9\u5bb6\u3002", "result": "\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\uff0cLoopPlay\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u5347\u7ea610%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "LoopPlay\u663e\u8457\u63d0\u5347\u5206\u5b50\u5bf9\u63a5\u51c6\u786e\u6027\uff0c\u5bf9\u836f\u7269\u53d1\u73b0\u5177\u6709\u6f5c\u5728\u4ef7\u503c\u3002"}}
{"id": "2508.05170", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.05170", "abs": "https://arxiv.org/abs/2508.05170", "authors": ["Lishui Fan", "Yu Zhang", "Mouxiang Chen", "Zhongxin Liu"], "title": "Posterior-GRPO: Rewarding Reasoning Processes in Code Generation", "comment": null, "summary": "Reinforcement learning (RL) has significantly advanced code generation for\nlarge language models (LLMs). However, current paradigms rely on outcome-based\nrewards from test cases, neglecting the quality of the intermediate reasoning\nprocess. While supervising the reasoning process directly is a promising\ndirection, it is highly susceptible to reward hacking, where the policy model\nlearns to exploit the reasoning reward signal without improving final outcomes.\nTo address this, we introduce a unified framework that can effectively\nincorporate the quality of the reasoning process during RL. First, to enable\nreasoning evaluation, we develop LCB-RB, a benchmark comprising preference\npairs of superior and inferior reasoning processes. Second, to accurately score\nreasoning quality, we introduce an Optimized-Degraded based (OD-based) method\nfor reward model training. This method generates high-quality preference pairs\nby systematically optimizing and degrading initial reasoning paths along\ncurated dimensions of reasoning quality, such as factual accuracy, logical\nrigor, and coherence. A 7B parameter reward model with this method achieves\nstate-of-the-art (SOTA) performance on LCB-RB and generalizes well to other\nbenchmarks. Finally, we introduce Posterior-GRPO (P-GRPO), a novel RL method\nthat conditions process-based rewards on task success. By selectively applying\nrewards to the reasoning processes of only successful outcomes, P-GRPO\neffectively mitigates reward hacking and aligns the model's internal reasoning\nwith final code correctness. A 7B parameter model with P-GRPO achieves superior\nperformance across diverse code generation tasks, outperforming outcome-only\nbaselines by 4.5%, achieving comparable performance to GPT-4-Turbo. We further\ndemonstrate the generalizability of our approach by extending it to\nmathematical tasks. Our models, dataset, and code are publicly available.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u6846\u67b6\uff0c\u7ed3\u5408\u63a8\u7406\u8fc7\u7a0b\u8d28\u91cf\u4f18\u5316\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7684\u4ee3\u7801\u751f\u6210\uff0c\u901a\u8fc7LCB-RB\u57fa\u51c6\u548cOD-based\u5956\u52b1\u6a21\u578b\u8bad\u7ec3\u65b9\u6cd5\u63d0\u5347\u63a8\u7406\u8d28\u91cf\uff0c\u5e76\u5f15\u5165P-GRPO\u65b9\u6cd5\u907f\u514d\u5956\u52b1\u6b3a\u9a97\uff0c\u6700\u7ec8\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u6d4b\u8bd5\u7ed3\u679c\u7684RL\u65b9\u6cd5\u5ffd\u89c6\u4e86\u4e2d\u95f4\u63a8\u7406\u8fc7\u7a0b\u7684\u8d28\u91cf\uff0c\u4e14\u76f4\u63a5\u76d1\u7763\u63a8\u7406\u6613\u5bfc\u81f4\u5956\u52b1\u6b3a\u9a97\u3002", "method": "\u5f00\u53d1LCB-RB\u57fa\u51c6\u8bc4\u4f30\u63a8\u7406\u8d28\u91cf\uff0c\u63d0\u51faOD-based\u5956\u52b1\u6a21\u578b\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5e76\u8bbe\u8ba1P-GRPO RL\u65b9\u6cd5\u9009\u62e9\u6027\u5956\u52b1\u6210\u529f\u4efb\u52a1\u7684\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "7B\u53c2\u6570\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u8d85\u8d8a\u57fa\u7ebf4.5%\uff0c\u6027\u80fd\u63a5\u8fd1GPT-4-Turbo\uff0c\u5e76\u6210\u529f\u63a8\u5e7f\u81f3\u6570\u5b66\u4efb\u52a1\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u7ed3\u5408\u63a8\u7406\u8d28\u91cf\u4e0e\u4efb\u52a1\u6210\u529f\uff0c\u663e\u8457\u63d0\u5347RL\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u3002"}}
{"id": "2508.05009", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.05009", "abs": "https://arxiv.org/abs/2508.05009", "authors": ["Bin Han", "Robert Wolfe", "Anat Caspi", "Bill Howe"], "title": "Can Large Language Models Integrate Spatial Data? Empirical Insights into Reasoning Strengths and Computational Weaknesses", "comment": null, "summary": "We explore the application of large language models (LLMs) to empower domain\nexperts in integrating large, heterogeneous, and noisy urban spatial datasets.\nTraditional rule-based integration methods are unable to cover all edge cases,\nrequiring manual verification and repair. Machine learning approaches require\ncollecting and labeling of large numbers of task-specific samples. In this\nstudy, we investigate the potential of LLMs for spatial data integration. Our\nanalysis first considers how LLMs reason about environmental spatial\nrelationships mediated by human experience, such as between roads and\nsidewalks. We show that while LLMs exhibit spatial reasoning capabilities, they\nstruggle to connect the macro-scale environment with the relevant computational\ngeometry tasks, often producing logically incoherent responses. But when\nprovided relevant features, thereby reducing dependence on spatial reasoning,\nLLMs are able to generate high-performing results. We then adapt a\nreview-and-refine method, which proves remarkably effective in correcting\nerroneous initial responses while preserving accurate responses. We discuss\npractical implications of employing LLMs for spatial data integration in\nreal-world contexts and outline future research directions, including\npost-training, multi-modal integration methods, and support for diverse data\nformats. Our findings position LLMs as a promising and flexible alternative to\ntraditional rule-based heuristics, advancing the capabilities of adaptive\nspatial data integration.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6574\u5408\u57ce\u5e02\u7a7a\u95f4\u6570\u636e\u7684\u6f5c\u529b\uff0c\u53d1\u73b0\u5176\u5728\u63d0\u4f9b\u76f8\u5173\u7279\u5f81\u65f6\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u6709\u9650\u3002", "motivation": "\u4f20\u7edf\u89c4\u5219\u65b9\u6cd5\u65e0\u6cd5\u8986\u76d6\u6240\u6709\u8fb9\u7f18\u6848\u4f8b\uff0c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u800cLLMs\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u5206\u6790LLMs\u7684\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u91c7\u7528\u201c\u5ba1\u67e5-\u4f18\u5316\u201d\u65b9\u6cd5\u7ea0\u6b63\u9519\u8bef\u54cd\u5e94\u3002", "result": "LLMs\u5728\u51cf\u5c11\u5bf9\u7a7a\u95f4\u63a8\u7406\u4f9d\u8d56\u65f6\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u9700\u8f85\u52a9\u7279\u5f81\u652f\u6301\u3002", "conclusion": "LLMs\u662f\u4f20\u7edf\u89c4\u5219\u65b9\u6cd5\u7684\u6709\u6548\u66ff\u4ee3\uff0c\u672a\u6765\u53ef\u63a2\u7d22\u591a\u6a21\u6001\u6574\u5408\u548c\u591a\u6837\u5316\u6570\u636e\u683c\u5f0f\u652f\u6301\u3002"}}
{"id": "2508.05192", "categories": ["cs.SE", "H.2.3; I.2.6; D.2.2"], "pdf": "https://arxiv.org/pdf/2508.05192", "abs": "https://arxiv.org/abs/2508.05192", "authors": ["Felix Neubauer", "J\u00fcrgen Pleiss", "Benjamin Uekermann"], "title": "AI-assisted JSON Schema Creation and Mapping", "comment": "Accepted for Tools and Demonstrations Track of ACM/IEEE MODELS'25", "summary": "Model-Driven Engineering (MDE) places models at the core of system and data\nengineering processes. In the context of research data, these models are\ntypically expressed as schemas that define the structure and semantics of\ndatasets. However, many domains still lack standardized models, and creating\nthem remains a significant barrier, especially for non-experts. We present a\nhybrid approach that combines large language models (LLMs) with deterministic\ntechniques to enable JSON Schema creation, modification, and schema mapping\nbased on natural language inputs by the user. These capabilities are integrated\ninto the open-source tool MetaConfigurator, which already provides visual model\nediting, validation, code generation, and form generation from models. For data\nintegration, we generate schema mappings from heterogeneous JSON, CSV, XML, and\nYAML data using LLMs, while ensuring scalability and reliability through\ndeterministic execution of generated mapping rules. The applicability of our\nwork is demonstrated in an application example in the field of chemistry. By\ncombining natural language interaction with deterministic safeguards, this work\nsignificantly lowers the barrier to structured data modeling and data\nintegration for non-experts.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u786e\u5b9a\u6027\u6280\u672f\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u7528\u4e8e\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u751f\u6210\u548c\u4fee\u6539JSON Schema\uff0c\u5e76\u5b9e\u73b0\u6570\u636e\u96c6\u6210\u3002\u8be5\u65b9\u6cd5\u96c6\u6210\u5230\u5f00\u6e90\u5de5\u5177MetaConfigurator\u4e2d\uff0c\u964d\u4f4e\u4e86\u975e\u4e13\u5bb6\u7528\u6237\u7684\u7ed3\u6784\u5316\u6570\u636e\u5efa\u6a21\u95e8\u69db\u3002", "motivation": "\u8bb8\u591a\u9886\u57df\u7f3a\u4e4f\u6807\u51c6\u5316\u6a21\u578b\uff0c\u4e14\u521b\u5efa\u6a21\u578b\u5bf9\u975e\u4e13\u5bb6\u7528\u6237\u6765\u8bf4\u5b58\u5728\u663e\u8457\u969c\u788d\u3002", "method": "\u7ed3\u5408LLMs\u548c\u786e\u5b9a\u6027\u6280\u672f\uff0c\u652f\u6301\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u7684JSON Schema\u521b\u5efa\u3001\u4fee\u6539\u548c\u6620\u5c04\uff0c\u5e76\u901a\u8fc7MetaConfigurator\u5de5\u5177\u5b9e\u73b0\u53ef\u89c6\u5316\u7f16\u8f91\u548c\u9a8c\u8bc1\u3002", "result": "\u5728\u5316\u5b66\u9886\u57df\u7684\u5e94\u7528\u793a\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u53ef\u884c\u6027\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u975e\u4e13\u5bb6\u7528\u6237\u7684\u6570\u636e\u5efa\u6a21\u548c\u96c6\u6210\u95e8\u69db\u3002", "conclusion": "\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u4e0e\u786e\u5b9a\u6027\u4fdd\u969c\u7684\u7ed3\u5408\uff0c\u4e3a\u975e\u4e13\u5bb6\u7528\u6237\u63d0\u4f9b\u4e86\u66f4\u4fbf\u6377\u7684\u7ed3\u6784\u5316\u6570\u636e\u5efa\u6a21\u548c\u96c6\u6210\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.05081", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.05081", "abs": "https://arxiv.org/abs/2508.05081", "authors": ["Jiarun Liu", "Chunhong Zhang", "Zheng Hu"], "title": "Cognitive Duality for Adaptive Web Agents", "comment": null, "summary": "Web navigation represents a critical and challenging domain for evaluating\nartificial general intelligence (AGI), demanding complex decision-making within\nhigh-entropy, dynamic environments with combinatorially explosive action\nspaces. Current approaches to building autonomous web agents either focus on\noffline imitation learning or online exploration, but rarely integrate both\nparadigms effectively. Inspired by the dual-process theory of human cognition,\nwe derive a principled decomposition into fast System 1 and slow System 2\ncognitive processes. This decomposition provides a unifying perspective on\nexisting web agent methodologies, bridging the gap between offline learning of\nintuitive reactive behaviors and online acquisition of deliberative planning\ncapabilities. We implement this framework in CogniWeb, a modular agent\narchitecture that adaptively toggles between fast intuitive processing and\ndeliberate reasoning based on task complexity. Our evaluation on WebArena\ndemonstrates that CogniWeb achieves competitive performance (43.96% success\nrate) while maintaining significantly higher efficiency (75% reduction in token\nusage).", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u79bb\u7ebf\u6a21\u4eff\u5b66\u4e60\u548c\u5728\u7ebf\u63a2\u7d22\u7684Web\u5bfc\u822a\u667a\u80fd\u4f53\u6846\u67b6CogniWeb\uff0c\u57fa\u4e8e\u4eba\u7c7b\u8ba4\u77e5\u7684\u53cc\u7cfb\u7edf\u7406\u8bba\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u6027\u80fd\u4f18\u8d8a\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "Web\u5bfc\u822a\u662f\u8bc4\u4f30\u901a\u7528\u4eba\u5de5\u667a\u80fd\uff08AGI\uff09\u7684\u5173\u952e\u9886\u57df\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u6709\u6548\u6574\u5408\u79bb\u7ebf\u5b66\u4e60\u548c\u5728\u7ebf\u63a2\u7d22\u3002", "method": "\u501f\u9274\u4eba\u7c7b\u8ba4\u77e5\u7684\u53cc\u7cfb\u7edf\u7406\u8bba\uff0c\u5c06\u667a\u80fd\u4f53\u5206\u89e3\u4e3a\u5feb\u901f\u76f4\u89c9\uff08System 1\uff09\u548c\u6162\u901f\u6df1\u601d\uff08System 2\uff09\u6a21\u5757\uff0c\u5e76\u5b9e\u73b0\u4e3aCogniWeb\u6846\u67b6\u3002", "result": "\u5728WebArena\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCogniWeb\u5728\u6210\u529f\u7387\uff0843.96%\uff09\u548c\u6548\u7387\uff08\u51cf\u5c1175%\u7684token\u4f7f\u7528\uff09\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "CogniWeb\u901a\u8fc7\u53cc\u7cfb\u7edf\u7406\u8bba\u6574\u5408\u4e86\u79bb\u7ebf\u4e0e\u5728\u7ebf\u5b66\u4e60\uff0c\u4e3aWeb\u5bfc\u822a\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u6027\u80fd\u4f18\u8d8a\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.05193", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.05193", "abs": "https://arxiv.org/abs/2508.05193", "authors": ["Kaiwen Yan", "Yuhang Chang", "Zirui Guo", "Yaling Mou", "Jiang Ming", "Jingwei Sun"], "title": "STEPWISE-CODEX-Bench: Evaluating Complex Multi-Function Comprehension and Fine-Grained Execution Reasoning", "comment": null, "summary": "In recent years, large language models (LLMs) have made significant progress\nin code intelligence, yet systematically evaluating their code understanding\nand reasoning abilities remains challenging. Mainstream benchmarks such as\nHumanEval and MBPP primarily assess functional correctness, while reasoning\nbenchmarks like CRUXEVAL are limited to single-function, low-complexity\nscenarios. As a result, advanced models achieve nearly saturated scores,\nlimiting their discriminative power. To address this, we present\nSTEPWISE-CODEX-Bench (SX-Bench), a novel benchmark designed for complex\nmulti-function understanding and fine-grained execution reasoning. SX-Bench\nfeatures tasks involving collaboration among multiple sub-functions (e.g.,\nchained calls, nested loops), shifting evaluation towards overall control and\ndata flow modeling. It defines \"computation steps\" as the minimal execution\nunit and requires models to predict the total number of steps in reasoning\ntasks, thereby assessing a model's in-depth understanding of dynamic execution\nbeyond simple I/O matching. Evaluation on over 20 mainstream models (including\n14 reasoning-enhanced models) demonstrates that SX-Bench is highly\ndiscriminative: even the state-of-the-art OpenAI-O3 achieves only 78.37 percent\naccuracy on Hard-Reasoning tasks, much lower than its saturated scores on\nprevious benchmarks, thereby revealing bottlenecks in complex and fine-grained\nreasoning. We also release an automated pipeline combining program synthesis,\nsymbolic execution, and LLM-aided validation for efficient benchmark generation\nand quality assurance. SX-Bench advances code evaluation from \"single-function\nverification\" to \"multi-function dynamic reasoning,\" providing a key tool for\nthe in-depth assessment of advanced code intelligence models.", "AI": {"tldr": "SX-Bench\u662f\u4e00\u4e2a\u65b0\u7684\u4ee3\u7801\u7406\u89e3\u548c\u63a8\u7406\u57fa\u51c6\uff0c\u4e13\u6ce8\u4e8e\u590d\u6742\u591a\u51fd\u6570\u573a\u666f\u548c\u7ec6\u7c92\u5ea6\u6267\u884c\u63a8\u7406\uff0c\u586b\u8865\u4e86\u73b0\u6709\u57fa\u51c6\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\uff08\u5982HumanEval\u548cMBPP\uff09\u4e3b\u8981\u8bc4\u4f30\u529f\u80fd\u6b63\u786e\u6027\uff0c\u800c\u63a8\u7406\u57fa\u51c6\uff08\u5982CRUXEVAL\uff09\u9650\u4e8e\u5355\u51fd\u6570\u4f4e\u590d\u6742\u5ea6\u573a\u666f\uff0c\u5bfc\u81f4\u9ad8\u7ea7\u6a21\u578b\u5f97\u5206\u9971\u548c\uff0c\u7f3a\u4e4f\u533a\u5206\u80fd\u529b\u3002", "method": "\u63d0\u51faSX-Bench\uff0c\u901a\u8fc7\u591a\u5b50\u51fd\u6570\u534f\u4f5c\u4efb\u52a1\uff08\u5982\u94fe\u5f0f\u8c03\u7528\u3001\u5d4c\u5957\u5faa\u73af\uff09\u8bc4\u4f30\u6574\u4f53\u63a7\u5236\u548c\u6570\u636e\u6d41\u5efa\u6a21\uff0c\u4ee5\u201c\u8ba1\u7b97\u6b65\u9aa4\u201d\u4e3a\u6700\u5c0f\u6267\u884c\u5355\u5143\uff0c\u8981\u6c42\u6a21\u578b\u9884\u6d4b\u63a8\u7406\u4efb\u52a1\u7684\u603b\u6b65\u9aa4\u6570\u3002", "result": "\u572820\u591a\u4e2a\u4e3b\u6d41\u6a21\u578b\uff08\u5305\u62ec14\u4e2a\u63a8\u7406\u589e\u5f3a\u6a21\u578b\uff09\u4e0a\u8bc4\u4f30\uff0cSX-Bench\u663e\u793a\u51fa\u9ad8\u533a\u5206\u5ea6\uff1a\u5373\u4f7f\u662fOpenAI-O3\u5728Hard-Reasoning\u4efb\u52a1\u4e0a\u51c6\u786e\u7387\u4ec5\u4e3a78.37%\u3002", "conclusion": "SX-Bench\u5c06\u4ee3\u7801\u8bc4\u4f30\u4ece\u201c\u5355\u51fd\u6570\u9a8c\u8bc1\u201d\u63a8\u8fdb\u5230\u201c\u591a\u51fd\u6570\u52a8\u6001\u63a8\u7406\u201d\uff0c\u4e3a\u6df1\u5165\u8bc4\u4f30\u9ad8\u7ea7\u4ee3\u7801\u667a\u80fd\u6a21\u578b\u63d0\u4f9b\u4e86\u5173\u952e\u5de5\u5177\u3002"}}
{"id": "2508.05083", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.05083", "abs": "https://arxiv.org/abs/2508.05083", "authors": ["Dexuan Xu", "Jieyi Wang", "Zhongyan Chai", "Yongzhi Cao", "Hanpin Wang", "Huamin Zhang", "Yu Huang"], "title": "MedMKEB: A Comprehensive Knowledge Editing Benchmark for Medical Multimodal Large Language Models", "comment": "18 pages", "summary": "Recent advances in multimodal large language models (MLLMs) have\nsignificantly improved medical AI, enabling it to unify the understanding of\nvisual and textual information. However, as medical knowledge continues to\nevolve, it is critical to allow these models to efficiently update outdated or\nincorrect information without retraining from scratch. Although textual\nknowledge editing has been widely studied, there is still a lack of systematic\nbenchmarks for multimodal medical knowledge editing involving image and text\nmodalities. To fill this gap, we present MedMKEB, the first comprehensive\nbenchmark designed to evaluate the reliability, generality, locality,\nportability, and robustness of knowledge editing in medical multimodal large\nlanguage models. MedMKEB is built on a high-quality medical visual\nquestion-answering dataset and enriched with carefully constructed editing\ntasks, including counterfactual correction, semantic generalization, knowledge\ntransfer, and adversarial robustness. We incorporate human expert validation to\nensure the accuracy and reliability of the benchmark. Extensive single editing\nand sequential editing experiments on state-of-the-art general and medical\nMLLMs demonstrate the limitations of existing knowledge-based editing\napproaches in medicine, highlighting the need to develop specialized editing\nstrategies. MedMKEB will serve as a standard benchmark to promote the\ndevelopment of trustworthy and efficient medical knowledge editing algorithms.", "AI": {"tldr": "MedMKEB\u662f\u9996\u4e2a\u9488\u5bf9\u533b\u5b66\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u7f16\u8f91\u7684\u7efc\u5408\u6027\u57fa\u51c6\uff0c\u65e8\u5728\u8bc4\u4f30\u5176\u53ef\u9760\u6027\u3001\u901a\u7528\u6027\u3001\u5c40\u90e8\u6027\u3001\u53ef\u79fb\u690d\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u533b\u5b66\u77e5\u8bc6\u4e0d\u65ad\u66f4\u65b0\uff0c\u9700\u9ad8\u6548\u4fee\u6b63\u6a21\u578b\u4e2d\u7684\u8fc7\u65f6\u6216\u9519\u8bef\u4fe1\u606f\uff0c\u800c\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u9488\u5bf9\u591a\u6a21\u6001\u533b\u5b66\u77e5\u8bc6\u7f16\u8f91\u7684\u7cfb\u7edf\u6027\u57fa\u51c6\u3002", "method": "\u57fa\u4e8e\u9ad8\u8d28\u91cf\u533b\u5b66\u89c6\u89c9\u95ee\u7b54\u6570\u636e\u96c6\u6784\u5efaMedMKEB\uff0c\u5305\u542b\u53cd\u4e8b\u5b9e\u4fee\u6b63\u3001\u8bed\u4e49\u6cdb\u5316\u3001\u77e5\u8bc6\u8fc1\u79fb\u548c\u5bf9\u6297\u9c81\u68d2\u6027\u7b49\u4efb\u52a1\uff0c\u5e76\u5f15\u5165\u4e13\u5bb6\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u73b0\u6709\u77e5\u8bc6\u7f16\u8f91\u65b9\u6cd5\u5728\u533b\u5b66\u9886\u57df\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u5f00\u53d1\u9488\u5bf9\u6027\u7b56\u7565\u3002", "conclusion": "MedMKEB\u5c06\u63a8\u52a8\u53ef\u4fe1\u4e14\u9ad8\u6548\u7684\u533b\u5b66\u77e5\u8bc6\u7f16\u8f91\u7b97\u6cd5\u53d1\u5c55\u3002"}}
{"id": "2508.05199", "categories": ["cs.SE", "cs.AI", "D.2.2; D.2.7; I.2.2"], "pdf": "https://arxiv.org/pdf/2508.05199", "abs": "https://arxiv.org/abs/2508.05199", "authors": ["Igor Costa", "Christopher Baran"], "title": "EvoGraph: Hybrid Directed Graph Evolution toward Software 3.0", "comment": "15 pages, 3 tables, 1 algorithm. Submitted to ICSE 2025", "summary": "We introduce **EvoGraph**, a framework that enables software systems to\nevolve their own source code, build pipelines, documentation, and tickets.\nEvoGraph represents every artefact in a typed directed graph, applies learned\nmutation operators driven by specialized small language models (SLMs), and\nselects survivors with a multi-objective fitness. On three benchmarks, EvoGraph\nfixes 83% of known security vulnerabilities, translates COBOL to Java with 93%\nfunctional equivalence (test verified), and maintains documentation freshness\nwithin two minutes. Experiments show a 40% latency reduction and a sevenfold\ndrop in feature lead time compared with strong baselines. We extend our\napproach to **evoGraph**, leveraging language-specific SLMs for modernizing\n.NET, Lisp, CGI, ColdFusion, legacy Python, and C codebases, achieving 82-96%\nsemantic equivalence across languages while reducing computational costs by 90%\ncompared to large language models. EvoGraph's design responds to empirical\nfailure modes in legacy modernization, such as implicit contracts, performance\npreservation, and integration evolution. Our results suggest a practical path\ntoward Software 3.0, where systems adapt continuously yet remain under\nmeasurable control.", "AI": {"tldr": "EvoGraph\u662f\u4e00\u4e2a\u6846\u67b6\uff0c\u901a\u8fc7\u7c7b\u578b\u5316\u6709\u5411\u56fe\u548c\u4e13\u7528\u5c0f\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u5b9e\u73b0\u8f6f\u4ef6\u7cfb\u7edf\u7684\u81ea\u6211\u8fdb\u5316\uff0c\u5305\u62ec\u6e90\u4ee3\u7801\u3001\u6784\u5efa\u7ba1\u9053\u3001\u6587\u6863\u548c\u5de5\u5355\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u8f6f\u4ef6\u73b0\u4ee3\u5316\u4e2d\u7684\u95ee\u9898\uff0c\u5982\u9690\u5f0f\u5951\u7ea6\u3001\u6027\u80fd\u4fdd\u6301\u548c\u96c6\u6210\u6f14\u5316\uff0c\u63a8\u52a8\u8f6f\u4ef6\u7cfb\u7edf\u5411\u6301\u7eed\u81ea\u9002\u5e94\uff08Software 3.0\uff09\u53d1\u5c55\u3002", "method": "\u4f7f\u7528\u7c7b\u578b\u5316\u6709\u5411\u56fe\u8868\u793a\u6240\u6709\u5de5\u4ef6\uff0c\u5e94\u7528\u57fa\u4e8eSLMs\u7684\u5b66\u4e60\u7a81\u53d8\u7b97\u5b50\uff0c\u5e76\u901a\u8fc7\u591a\u76ee\u6807\u9002\u5e94\u5ea6\u9009\u62e9\u5e78\u5b58\u8005\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4fee\u590d83%\u7684\u5b89\u5168\u6f0f\u6d1e\uff0cCOBOL\u8f6cJava\u529f\u80fd\u7b49\u6548\u6027\u8fbe93%\uff0c\u6587\u6863\u65b0\u9c9c\u5ea6\u4fdd\u6301\u5728\u4e24\u5206\u949f\u5185\uff0c\u5ef6\u8fdf\u964d\u4f4e40%\uff0c\u529f\u80fd\u4ea4\u4ed8\u65f6\u95f4\u7f29\u77ed7\u500d\u3002", "conclusion": "EvoGraph\u4e3a\u8f6f\u4ef6\u73b0\u4ee3\u5316\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u63a7\u7684\u8def\u5f84\uff0c\u5c55\u793a\u4e86\u6301\u7eed\u81ea\u9002\u5e94\u7cfb\u7edf\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2508.05113", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.05113", "abs": "https://arxiv.org/abs/2508.05113", "authors": ["Xinyue Wu", "Fan Hu", "Shaik Jani Babu", "Yi Zhao", "Xinfei Guo"], "title": "EasySize: Elastic Analog Circuit Sizing via LLM-Guided Heuristic Search", "comment": null, "summary": "Analog circuit design is a time-consuming, experience-driven task in chip\ndevelopment. Despite advances in AI, developing universal, fast, and stable\ngate sizing methods for analog circuits remains a significant challenge. Recent\napproaches combine Large Language Models (LLMs) with heuristic search\ntechniques to enhance generalizability, but they often depend on large model\nsizes and lack portability across different technology nodes. To overcome these\nlimitations, we propose EasySize, the first lightweight gate sizing framework\nbased on a finetuned Qwen3-8B model, designed for universal applicability\nacross process nodes, design specifications, and circuit topologies. EasySize\nexploits the varying Ease of Attainability (EOA) of performance metrics to\ndynamically construct task-specific loss functions, enabling efficient\nheuristic search through global Differential Evolution (DE) and local Particle\nSwarm Optimization (PSO) within a feedback-enhanced flow. Although finetuned\nsolely on 350nm node data, EasySize achieves strong performance on 5\noperational amplifier (Op-Amp) netlists across 180nm, 45nm, and 22nm technology\nnodes without additional targeted training, and outperforms AutoCkt, a\nwidely-used Reinforcement Learning based sizing framework, on 86.67\\% of tasks\nwith more than 96.67\\% of simulation resources reduction. We argue that\nEasySize can significantly reduce the reliance on human expertise and\ncomputational resources in gate sizing, thereby accelerating and simplifying\nthe analog circuit design process. EasySize will be open-sourced at a later\ndate.", "AI": {"tldr": "EasySize\u662f\u4e00\u4e2a\u57fa\u4e8e\u5fae\u8c03Qwen3-8B\u6a21\u578b\u7684\u8f7b\u91cf\u7ea7\u95e8\u5c3a\u5bf8\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u5de5\u827a\u8282\u70b9\u548c\u7535\u8def\u62d3\u6251\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u5bf9\u4eba\u529b\u548c\u8ba1\u7b97\u8d44\u6e90\u7684\u4f9d\u8d56\u3002", "motivation": "\u6a21\u62df\u7535\u8def\u8bbe\u8ba1\u8017\u65f6\u4e14\u4f9d\u8d56\u7ecf\u9a8c\uff0c\u73b0\u6709AI\u65b9\u6cd5\u901a\u7528\u6027\u5dee\u4e14\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u9ad8\u3002", "method": "\u7ed3\u5408\u52a8\u6001\u4efb\u52a1\u7279\u5b9a\u635f\u5931\u51fd\u6570\u548c\u5168\u5c40\u5dee\u5206\u8fdb\u5316\uff08DE\uff09\u4e0e\u5c40\u90e8\u7c92\u5b50\u7fa4\u4f18\u5316\uff08PSO\uff09\u7684\u542f\u53d1\u5f0f\u641c\u7d22\u3002", "result": "\u5728\u591a\u4e2a\u5de5\u827a\u8282\u70b9\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f18\u4e8eAutoCkt\uff0c\u8282\u7701\u4e8696.67%\u7684\u4eff\u771f\u8d44\u6e90\u3002", "conclusion": "EasySize\u80fd\u52a0\u901f\u548c\u7b80\u5316\u6a21\u62df\u7535\u8def\u8bbe\u8ba1\uff0c\u51cf\u5c11\u5bf9\u4eba\u529b\u548c\u8ba1\u7b97\u8d44\u6e90\u7684\u4f9d\u8d56\u3002"}}
{"id": "2508.05301", "categories": ["cs.SE", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.05301", "abs": "https://arxiv.org/abs/2508.05301", "authors": ["Victoria Torres Bosch", "Ronny Seiger", "Manuela Albert Albiol", "Antoni Mestre Gascon", "Pedro Jose Valderas Aranda"], "title": "A Conceptual Model and Methodology for Sustainability-aware, IoT-enhanced Business Processes", "comment": "Submitted to Information Systems Frontiers (1572-9419)", "summary": "The real-time data collection and automation capabilities offered by the\nInternet of Things (IoT) are revolutionizing and transforming Business\nProcesses (BPs) into IoT-enhanced BPs, showing high potential for improving\nsustainability. Although already studied in Business Process Management (BPM),\nsustainability research has primarily focused on environmental concerns.\nHowever, achieving a holistic and lasting impact requires a systematic approach\nto address sustainability beyond the environmental dimension. This work\nproposes a conceptual model and a structured methodology with the goal of\nanalyzing the potential of IoT to measure and improve the sustainability of\nBPs. The conceptual model formally represents key sustainability concepts,\nlinking BPM and IoT by highlighting how IoT devices support and contribute to\nsustainability. The methodology guides the systematic analysis of existing BPs,\nidentifies opportunities, and implements sustainability-aware, IoT-enhanced\nBPs. The approach is illustrated through a running example from the tourism\ndomain and a case study in healthcare.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6982\u5ff5\u6a21\u578b\u548c\u65b9\u6cd5\u8bba\uff0c\u65e8\u5728\u5229\u7528\u7269\u8054\u7f51\uff08IoT\uff09\u6280\u672f\u8861\u91cf\u548c\u6539\u8fdb\u4e1a\u52a1\u6d41\u7a0b\uff08BPs\uff09\u7684\u53ef\u6301\u7eed\u6027\uff0c\u8d85\u8d8a\u73af\u5883\u7ef4\u5ea6\uff0c\u5b9e\u73b0\u66f4\u5168\u9762\u7684\u53ef\u6301\u7eed\u53d1\u5c55\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u73af\u5883\u53ef\u6301\u7eed\u6027\uff0c\u4f46\u5b9e\u73b0\u5168\u9762\u53ef\u6301\u7eed\u6027\u9700\u8981\u66f4\u7cfb\u7edf\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408IoT\u6280\u672f\u4ee5\u652f\u6301\u4e1a\u52a1\u6d41\u7a0b\u7684\u53ef\u6301\u7eed\u6027\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u6982\u5ff5\u6a21\u578b\u548c\u7ed3\u6784\u5316\u65b9\u6cd5\u8bba\uff0c\u901a\u8fc7IoT\u8bbe\u5907\u652f\u6301\u53ef\u6301\u7eed\u6027\uff0c\u5e76\u6307\u5bfc\u4e1a\u52a1\u6d41\u7a0b\u7684\u7cfb\u7edf\u6027\u5206\u6790\u548c\u6539\u8fdb\u3002", "result": "\u901a\u8fc7\u65c5\u6e38\u548c\u533b\u7597\u9886\u57df\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u9a8c\u8bc1\u4e86\u6a21\u578b\u548c\u65b9\u6cd5\u8bba\u7684\u6709\u6548\u6027\u3002", "conclusion": "IoT\u6280\u672f\u4e3a\u4e1a\u52a1\u6d41\u7a0b\u7684\u53ef\u6301\u7eed\u6027\u6539\u8fdb\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u652f\u6301\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.05116", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.05116", "abs": "https://arxiv.org/abs/2508.05116", "authors": ["Peer-Benedikt Degen", "Igor Asanov"], "title": "Beyond Automation: Socratic AI, Epistemic Agency, and the Implications of the Emergence of Orchestrated Multi-Agent Learning Architectures", "comment": null, "summary": "Generative AI is no longer a peripheral tool in higher education. It is\nrapidly evolving into a general-purpose infrastructure that reshapes how\nknowledge is generated, mediated, and validated. This paper presents findings\nfrom a controlled experiment evaluating a Socratic AI Tutor, a large language\nmodel designed to scaffold student research question development through\nstructured dialogue grounded in constructivist theory. Conducted with 65\npre-service teacher students in Germany, the study compares interaction with\nthe Socratic Tutor to engagement with an uninstructed AI chatbot. Students\nusing the Socratic Tutor reported significantly greater support for critical,\nindependent, and reflective thinking, suggesting that dialogic AI can stimulate\nmetacognitive engagement and challenging recent narratives of de-skilling due\nto generative AI usage. These findings serve as a proof of concept for a\nbroader pedagogical shift: the use of multi-agent systems (MAS) composed of\nspecialised AI agents. To conceptualise this, we introduce the notion of\norchestrated MAS, modular, pedagogically aligned agent constellations, curated\nby educators, that support diverse learning trajectories through differentiated\nroles and coordinated interaction. To anchor this shift, we propose an adapted\noffer-and-use model, in which students appropriate instructional offers from\nthese agents. Beyond technical feasibility, we examine system-level\nimplications for higher education institutions and students, including funding\nnecessities, changes to faculty roles, curriculars, competencies and assessment\npractices. We conclude with a comparative cost-effectiveness analysis\nhighlighting the scalability of such systems. In sum, this study contributes\nboth empirical evidence and a conceptual roadmap for hybrid learning ecosystems\nthat embed human-AI co-agency and pedagogical alignment.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u751f\u6210\u5f0fAI\u5728\u9ad8\u7b49\u6559\u80b2\u4e2d\u7684\u6838\u5fc3\u4f5c\u7528\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u82cf\u683c\u62c9\u5e95AI\u5bfc\u5e08\u5bf9\u5b66\u751f\u6279\u5224\u6027\u601d\u7ef4\u7684\u4fc3\u8fdb\u4f5c\u7528\uff0c\u5e76\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u7684\u6559\u80b2\u5e94\u7528\u6846\u67b6\u3002", "motivation": "\u751f\u6210\u5f0fAI\u6b63\u6210\u4e3a\u9ad8\u7b49\u6559\u80b2\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u91cd\u5851\u77e5\u8bc6\u751f\u6210\u4e0e\u9a8c\u8bc1\u65b9\u5f0f\uff0c\u9700\u63a2\u7d22\u5176\u5982\u4f55\u652f\u6301\u5b66\u751f\u6279\u5224\u6027\u601d\u7ef4\u4e0e\u81ea\u4e3b\u5b66\u4e60\u3002", "method": "\u5bf965\u540d\u5fb7\u56fd\u5e08\u8303\u751f\u8fdb\u884c\u5bf9\u7167\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u82cf\u683c\u62c9\u5e95AI\u5bfc\u5e08\u4e0e\u666e\u901aAI\u804a\u5929\u673a\u5668\u4eba\u7684\u6548\u679c\u3002", "result": "\u82cf\u683c\u62c9\u5e95AI\u5bfc\u5e08\u663e\u8457\u63d0\u5347\u5b66\u751f\u7684\u6279\u5224\u6027\u3001\u72ec\u7acb\u6027\u548c\u53cd\u601d\u6027\u601d\u7ef4\uff0c\u8bc1\u660e\u5bf9\u8bdd\u5f0fAI\u53ef\u4fc3\u8fdb\u5143\u8ba4\u77e5\u53c2\u4e0e\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u7684\u6559\u80b2\u5e94\u7528\u6846\u67b6\uff0c\u5f3a\u8c03\u4eba\u673a\u534f\u4f5c\u4e0e\u6559\u5b66\u5bf9\u9f50\uff0c\u4e3a\u6df7\u5408\u5b66\u4e60\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u5b9e\u8bc1\u4e0e\u6982\u5ff5\u652f\u6301\u3002"}}
{"id": "2508.05145", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.05145", "abs": "https://arxiv.org/abs/2508.05145", "authors": ["Sebastiano Dissegna", "Chiara Di Francescomarino", "Massimiliano Ronzani"], "title": "Graph-based Event Log Repair", "comment": null, "summary": "The quality of event logs in Process Mining is crucial when applying any form\nof analysis to them. In real-world event logs, the acquisition of data can be\nnon-trivial (e.g., due to the execution of manual activities and related manual\nrecording or to issues in collecting, for each event, all its attributes), and\noften may end up with events recorded with some missing information. Standard\napproaches to the problem of trace (or log) reconstruction either require the\navailability of a process model that is used to fill missing values by\nleveraging different reasoning techniques or employ a Machine Learning/Deep\nLearning model to restore the missing values by learning from similar cases. In\nrecent years, a new type of Deep Learning model that is capable of handling\ninput data encoded as graphs has emerged, namely Graph Neural Networks. Graph\nNeural Network models, and even more so Heterogeneous Graph Neural Networks,\noffer the advantage of working with a more natural representation of complex\nmulti-modal sequences like the execution traces in Process Mining, allowing for\nmore expressive and semantically rich encodings.\n  In this work, we focus on the development of a Heterogeneous Graph Neural\nNetwork model that, given a trace containing some incomplete events, will\nreturn the full set of attributes missing from those events. We evaluate our\nwork against a state-of-the-art approach leveraging autoencoders on two\nsynthetic logs and four real event logs, on different types of missing values.\nDifferent from state-of-the-art model-free approaches, which mainly focus on\nrepairing a subset of event attributes, the proposed approach shows very good\nperformance in reconstructing all different event attributes.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f02\u6784\u56fe\u795e\u7ecf\u7f51\u7edc\uff08HGNN\uff09\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u4fee\u590d\u8fc7\u7a0b\u6316\u6398\u4e2d\u4e8b\u4ef6\u65e5\u5fd7\u7684\u7f3a\u5931\u5c5e\u6027\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7684\u4e8b\u4ef6\u65e5\u5fd7\u5e38\u56e0\u6570\u636e\u91c7\u96c6\u95ee\u9898\u5bfc\u81f4\u4fe1\u606f\u7f3a\u5931\uff0c\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u8fc7\u7a0b\u6a21\u578b\u6216\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u4f46\u5b58\u5728\u5c40\u9650\u6027\u3002HGNN\u80fd\u66f4\u81ea\u7136\u5730\u8868\u793a\u590d\u6742\u591a\u6a21\u6001\u5e8f\u5217\uff0c\u63d0\u4f9b\u66f4\u4e30\u5bcc\u7684\u8bed\u4e49\u7f16\u7801\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cdHGNN\u6a21\u578b\uff0c\u8f93\u5165\u5305\u542b\u4e0d\u5b8c\u6574\u4e8b\u4ef6\u7684\u8f68\u8ff9\uff0c\u8f93\u51fa\u7f3a\u5931\u5c5e\u6027\u7684\u5b8c\u6574\u96c6\u5408\u3002", "result": "\u5728\u4e24\u4e2a\u5408\u6210\u65e5\u5fd7\u548c\u56db\u4e2a\u771f\u5b9e\u65e5\u5fd7\u4e0a\u8bc4\u4f30\uff0c\u76f8\u6bd4\u57fa\u4e8e\u81ea\u52a8\u7f16\u7801\u5668\u7684\u5148\u8fdb\u65b9\u6cd5\uff0cHGNN\u5728\u4fee\u590d\u6240\u6709\u4e8b\u4ef6\u5c5e\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "HGNN\u6a21\u578b\u5728\u4fee\u590d\u4e8b\u4ef6\u65e5\u5fd7\u7f3a\u5931\u5c5e\u6027\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u65e0\u5173\u65b9\u6cd5\u3002"}}
{"id": "2508.05197", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.05197", "abs": "https://arxiv.org/abs/2508.05197", "authors": ["Zhuohang Jiang", "Pangjing Wu", "Xu Yuan", "Wenqi Fan", "Qing Li"], "title": "QA-Dragon: Query-Aware Dynamic RAG System for Knowledge-Intensive Visual Question Answering", "comment": "The source code for our system is released in\n  https://github.com/jzzzzh/QA-Dragon", "summary": "Retrieval-Augmented Generation (RAG) has been introduced to mitigate\nhallucinations in Multimodal Large Language Models (MLLMs) by incorporating\nexternal knowledge into the generation process, and it has become a widely\nadopted approach for knowledge-intensive Visual Question Answering (VQA).\nHowever, existing RAG methods typically retrieve from either text or images in\nisolation, limiting their ability to address complex queries that require\nmulti-hop reasoning or up-to-date factual knowledge. To address this\nlimitation, we propose QA-Dragon, a Query-Aware Dynamic RAG System for\nKnowledge-Intensive VQA. Specifically, QA-Dragon introduces a domain router to\nidentify the query's subject domain for domain-specific reasoning, along with a\nsearch router that dynamically selects optimal retrieval strategies. By\norchestrating both text and image search agents in a hybrid setup, our system\nsupports multimodal, multi-turn, and multi-hop reasoning, enabling it to tackle\ncomplex VQA tasks effectively. We evaluate our QA-Dragon on the Meta CRAG-MM\nChallenge at KDD Cup 2025, where it significantly enhances the reasoning\nperformance of base models under challenging scenarios. Our framework achieves\nsubstantial improvements in both answer accuracy and knowledge overlap scores,\noutperforming baselines by 5.06% on the single-source task, 6.35% on the\nmulti-source task, and 5.03% on the multi-turn task.", "AI": {"tldr": "QA-Dragon\u662f\u4e00\u4e2a\u67e5\u8be2\u611f\u77e5\u7684\u52a8\u6001RAG\u7cfb\u7edf\uff0c\u901a\u8fc7\u6df7\u5408\u6587\u672c\u548c\u56fe\u50cf\u68c0\u7d22\u7b56\u7565\uff0c\u63d0\u5347\u590d\u6742VQA\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709RAG\u65b9\u6cd5\u4ec5\u5355\u72ec\u68c0\u7d22\u6587\u672c\u6216\u56fe\u50cf\uff0c\u65e0\u6cd5\u6ee1\u8db3\u590d\u6742\u67e5\u8be2\u7684\u591a\u8df3\u63a8\u7406\u548c\u5b9e\u65f6\u77e5\u8bc6\u9700\u6c42\u3002", "method": "\u5f15\u5165\u9886\u57df\u8def\u7531\u5668\u548c\u641c\u7d22\u8def\u7531\u5668\uff0c\u52a8\u6001\u9009\u62e9\u68c0\u7d22\u7b56\u7565\uff0c\u6df7\u5408\u6587\u672c\u548c\u56fe\u50cf\u641c\u7d22\u4ee3\u7406\u3002", "result": "\u5728Meta CRAG-MM\u6311\u6218\u4e2d\uff0cQA-Dragon\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5355\u6e90\u4efb\u52a1\u63d0\u53475.06%\uff0c\u591a\u6e90\u4efb\u52a1\u63d0\u53476.35%\uff0c\u591a\u8f6e\u4efb\u52a1\u63d0\u53475.03%\u3002", "conclusion": "QA-Dragon\u901a\u8fc7\u52a8\u6001\u591a\u6a21\u6001\u68c0\u7d22\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u590d\u6742VQA\u4efb\u52a1\u4e2d\u7684\u77e5\u8bc6\u5bc6\u96c6\u548c\u591a\u8df3\u63a8\u7406\u95ee\u9898\u3002"}}
{"id": "2508.05267", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.05267", "abs": "https://arxiv.org/abs/2508.05267", "authors": ["V\u00edtor N. Louren\u00e7o", "Mohnish Dubey", "Yunfei Bai", "Audrey Depeige", "Vivek Jain"], "title": "An Explainable Natural Language Framework for Identifying and Notifying Target Audiences In Enterprise Communication", "comment": "Accepted to publication at the 24th International Semantic Web\n  Conference Industry Track, ISWC 2025", "summary": "In large-scale maintenance organizations, identifying subject matter experts\nand managing communications across complex entities relationships poses\nsignificant challenges -- including information overload and longer response\ntimes -- that traditional communication approaches fail to address effectively.\nWe propose a novel framework that combines RDF graph databases with LLMs to\nprocess natural language queries for precise audience targeting, while\nproviding transparent reasoning through a planning-orchestration architecture.\nOur solution enables communication owners to formulate intuitive queries\ncombining concepts such as equipment, manufacturers, maintenance engineers, and\nfacilities, delivering explainable results that maintain trust in the system\nwhile improving communication efficiency across the organization.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408RDF\u56fe\u6570\u636e\u5e93\u548cLLM\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u5927\u89c4\u6a21\u7ef4\u62a4\u7ec4\u7ec7\u4e2d\u4e13\u5bb6\u8bc6\u522b\u548c\u590d\u6742\u5b9e\u4f53\u5173\u7cfb\u901a\u4fe1\u7ba1\u7406\u7684\u6311\u6218\u3002", "motivation": "\u4f20\u7edf\u901a\u4fe1\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u89e3\u51b3\u4fe1\u606f\u8fc7\u8f7d\u548c\u54cd\u5e94\u65f6\u95f4\u8fc7\u957f\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7ed3\u5408RDF\u56fe\u6570\u636e\u5e93\u548cLLM\u5904\u7406\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\uff0c\u901a\u8fc7\u89c4\u5212-\u7f16\u6392\u67b6\u6784\u5b9e\u73b0\u900f\u660e\u63a8\u7406\u3002", "result": "\u652f\u6301\u76f4\u89c2\u67e5\u8be2\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u7ed3\u679c\uff0c\u63d0\u9ad8\u901a\u4fe1\u6548\u7387\u5e76\u4fdd\u6301\u7cfb\u7edf\u4fe1\u4efb\u3002", "conclusion": "\u8be5\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u7ec4\u7ec7\u5185\u901a\u4fe1\u7684\u6548\u7387\u548c\u900f\u660e\u5ea6\u3002"}}
{"id": "2508.05311", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.05311", "abs": "https://arxiv.org/abs/2508.05311", "authors": ["Andrew Kiruluta"], "title": "A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents", "comment": null, "summary": "We propose a hybrid architecture that integrates decision tree-based symbolic\nreasoning with the generative capabilities of large language models (LLMs)\nwithin a coordinated multi-agent framework. Unlike prior approaches that\nloosely couple symbolic and neural modules, our design embeds decision trees\nand random forests as callable oracles within a unified reasoning system.\nTree-based modules enable interpretable rule inference and causal logic, while\nLLM agents handle abductive reasoning, generalization, and interactive\nplanning. A central orchestrator maintains belief state consistency and\nmediates communication across agents and external tools, enabling reasoning\nover both structured and unstructured inputs.\n  The system achieves strong performance on reasoning benchmarks. On\n\\textit{ProofWriter}, it improves entailment consistency by +7.2\\% through\nlogic-grounded tree validation. On GSM8k, it achieves +5.3\\% accuracy gains in\nmultistep mathematical problems via symbolic augmentation. On \\textit{ARC}, it\nboosts abstraction accuracy by +6.0\\% through integration of symbolic oracles.\nApplications in clinical decision support and scientific discovery show how the\nsystem encodes domain rules symbolically while leveraging LLMs for contextual\ninference and hypothesis generation. This architecture offers a robust,\ninterpretable, and extensible solution for general-purpose neuro-symbolic\nreasoning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u67b6\u6784\uff0c\u5c06\u57fa\u4e8e\u51b3\u7b56\u6811\u7684\u7b26\u53f7\u63a8\u7406\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u751f\u6210\u80fd\u529b\u7ed3\u5408\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u6846\u67b6\u5b9e\u73b0\u534f\u8c03\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u4e2d\u7b26\u53f7\u6a21\u5757\u4e0e\u795e\u7ecf\u6a21\u5757\u677e\u6563\u8026\u5408\u7684\u95ee\u9898\uff0c\u8bbe\u8ba1\u4e00\u79cd\u7edf\u4e00\u63a8\u7406\u7cfb\u7edf\uff0c\u7ed3\u5408\u7b26\u53f7\u63a8\u7406\u7684\u89c4\u5219\u6027\u548cLLM\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u5c06\u51b3\u7b56\u6811\u548c\u968f\u673a\u68ee\u6797\u4f5c\u4e3a\u53ef\u8c03\u7528\u6a21\u5757\u5d4c\u5165\u7edf\u4e00\u63a8\u7406\u7cfb\u7edf\uff0c\u7531\u4e2d\u592e\u534f\u8c03\u5668\u7ef4\u62a4\u72b6\u6001\u4e00\u81f4\u6027\u548c\u901a\u4fe1\uff0c\u5b9e\u73b0\u7ed3\u6784\u5316\u4e0e\u975e\u7ed3\u6784\u5316\u8f93\u5165\u7684\u63a8\u7406\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5982ProofWriter\uff08+7.2%\uff09\u3001GSM8k\uff08+5.3%\uff09\u548cARC\uff08+6.0%\uff09\uff0c\u5e76\u5728\u4e34\u5e8a\u51b3\u7b56\u548c\u79d1\u5b66\u53d1\u73b0\u4e2d\u9a8c\u8bc1\u4e86\u5b9e\u7528\u6027\u3002", "conclusion": "\u8be5\u67b6\u6784\u4e3a\u901a\u7528\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u63d0\u4f9b\u4e86\u9c81\u68d2\u3001\u53ef\u89e3\u91ca\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.05338", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.05338", "abs": "https://arxiv.org/abs/2508.05338", "authors": ["Brinnae Bent"], "title": "The Term 'Agent' Has Been Diluted Beyond Utility and Requires Redefinition", "comment": "Accepted to AIES 2025", "summary": "The term 'agent' in artificial intelligence has long carried multiple\ninterpretations across different subfields. Recent developments in AI\ncapabilities, particularly in large language model systems, have amplified this\nambiguity, creating significant challenges in research communication, system\nevaluation and reproducibility, and policy development. This paper argues that\nthe term 'agent' requires redefinition. Drawing from historical analysis and\ncontemporary usage patterns, we propose a framework that defines clear minimum\nrequirements for a system to be considered an agent while characterizing\nsystems along a multidimensional spectrum of environmental interaction,\nlearning and adaptation, autonomy, goal complexity, and temporal coherence.\nThis approach provides precise vocabulary for system description while\npreserving the term's historically multifaceted nature. After examining\npotential counterarguments and implementation challenges, we provide specific\nrecommendations for moving forward as a field, including suggestions for\nterminology standardization and framework adoption. The proposed approach\noffers practical tools for improving research clarity and reproducibility while\nsupporting more effective policy development.", "AI": {"tldr": "\u8bba\u6587\u4e3b\u5f20\u91cd\u65b0\u5b9a\u4e49AI\u4e2d\u7684'agent'\u4e00\u8bcd\uff0c\u63d0\u51fa\u4e00\u4e2a\u591a\u7ef4\u6846\u67b6\u4ee5\u660e\u786e\u5176\u6700\u4f4e\u8981\u6c42\uff0c\u5e76\u5efa\u8bae\u6807\u51c6\u5316\u672f\u8bed\u4ee5\u63d0\u5347\u7814\u7a76\u6e05\u6670\u5ea6\u548c\u653f\u7b56\u5236\u5b9a\u6548\u679c\u3002", "motivation": "\u7531\u4e8eAI\u9886\u57df\u4e2d\u5bf9'agent'\u4e00\u8bcd\u7684\u591a\u4e49\u6027\u5bfc\u81f4\u7814\u7a76\u4ea4\u6d41\u3001\u7cfb\u7edf\u8bc4\u4f30\u548c\u653f\u7b56\u5236\u5b9a\u56f0\u96be\uff0c\u9700\u8981\u91cd\u65b0\u5b9a\u4e49\u4ee5\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5386\u53f2\u5206\u6790\u548c\u5f53\u4ee3\u4f7f\u7528\u6a21\u5f0f\uff0c\u63d0\u51fa\u4e00\u4e2a\u591a\u7ef4\u6846\u67b6\uff0c\u5b9a\u4e49'agent'\u7684\u6700\u4f4e\u8981\u6c42\uff0c\u5e76\u63cf\u8ff0\u7cfb\u7edf\u5728\u73af\u5883\u4ea4\u4e92\u3001\u5b66\u4e60\u4e0e\u9002\u5e94\u3001\u81ea\u4e3b\u6027\u3001\u76ee\u6807\u590d\u6742\u6027\u548c\u65f6\u95f4\u4e00\u81f4\u6027\u7b49\u65b9\u9762\u7684\u7279\u5f81\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6e05\u6670\u7684\u6846\u67b6\uff0c\u4e3a\u7cfb\u7edf\u63cf\u8ff0\u63d0\u4f9b\u7cbe\u786e\u8bcd\u6c47\uff0c\u540c\u65f6\u4fdd\u7559\u672f\u8bed\u7684\u5386\u53f2\u591a\u9762\u6027\uff0c\u5e76\u7ed9\u51fa\u4e86\u6807\u51c6\u5316\u672f\u8bed\u548c\u6846\u67b6\u91c7\u7eb3\u7684\u5efa\u8bae\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u63d0\u5347\u7814\u7a76\u6e05\u6670\u5ea6\u548c\u53ef\u91cd\u590d\u6027\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\uff0c\u540c\u65f6\u652f\u6301\u66f4\u6709\u6548\u7684\u653f\u7b56\u5236\u5b9a\u3002"}}
{"id": "2508.05344", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.05344", "abs": "https://arxiv.org/abs/2508.05344", "authors": ["Asutosh Hota", "Jussi P. P. Jokinen"], "title": "NomicLaw: Emergent Trust and Strategic Argumentation in LLMs During Collaborative Law-Making", "comment": null, "summary": "Recent advancements in large language models (LLMs) have extended their\ncapabilities from basic text processing to complex reasoning tasks, including\nlegal interpretation, argumentation, and strategic interaction. However,\nempirical understanding of LLM behavior in open-ended, multi-agent settings\nespecially those involving deliberation over legal and ethical dilemmas remains\nlimited. We introduce NomicLaw, a structured multi-agent simulation where LLMs\nengage in collaborative law-making, responding to complex legal vignettes by\nproposing rules, justifying them, and voting on peer proposals. We\nquantitatively measure trust and reciprocity via voting patterns and\nqualitatively assess how agents use strategic language to justify proposals and\ninfluence outcomes. Experiments involving homogeneous and heterogeneous LLM\ngroups demonstrate how agents spontaneously form alliances, betray trust, and\nadapt their rhetoric to shape collective decisions. Our results highlight the\nlatent social reasoning and persuasive capabilities of ten open-source LLMs and\nprovide insights into the design of future AI systems capable of autonomous\nnegotiation, coordination and drafting legislation in legal settings.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faNomicLaw\uff0c\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6a21\u62df\u6846\u67b6\uff0c\u7814\u7a76LLM\u5728\u5f00\u653e\u5f0f\u6cd5\u5f8b\u4f26\u7406\u56f0\u5883\u4e2d\u7684\u884c\u4e3a\uff0c\u901a\u8fc7\u6295\u7968\u548c\u8bed\u8a00\u7b56\u7565\u5206\u6790\u4fe1\u4efb\u4e0e\u4e92\u60e0\u3002", "motivation": "\u63a2\u7d22LLM\u5728\u5f00\u653e\u5f0f\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684\u884c\u4e3a\uff0c\u5c24\u5176\u662f\u5728\u6cd5\u5f8b\u548c\u4f26\u7406\u56f0\u5883\u4e2d\u7684\u8868\u73b0\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u4f7f\u7528NomicLaw\u6a21\u62df\u6846\u67b6\uff0c\u8ba9LLM\u534f\u4f5c\u5236\u5b9a\u6cd5\u5f8b\u89c4\u5219\uff0c\u901a\u8fc7\u6295\u7968\u548c\u8bed\u8a00\u7b56\u7565\u5206\u6790\u4fe1\u4efb\u4e0e\u4e92\u60e0\u3002", "result": "\u5b9e\u9a8c\u663e\u793aLLM\u80fd\u81ea\u53d1\u5f62\u6210\u8054\u76df\u3001\u80cc\u53db\u4fe1\u4efb\uff0c\u5e76\u8c03\u6574\u8bed\u8a00\u7b56\u7565\u5f71\u54cd\u96c6\u4f53\u51b3\u7b56\uff0c\u5c55\u793a\u4e86\u5176\u6f5c\u5728\u7684\u793e\u4f1a\u63a8\u7406\u548c\u8bf4\u670d\u80fd\u529b\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u5f00\u6e90LLM\u7684\u793e\u4f1a\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u672a\u6765AI\u7cfb\u7edf\u5728\u81ea\u4e3b\u534f\u5546\u548c\u7acb\u6cd5\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u542f\u793a\u3002"}}
{"id": "2508.05350", "categories": ["cs.AI", "cs.CC", "cs.LO"], "pdf": "https://arxiv.org/pdf/2508.05350", "abs": "https://arxiv.org/abs/2508.05350", "authors": ["Federica Di Stefano", "Quentin Mani\u00e8re", "Magdalena Ortiz", "Mantas \u0160imkus"], "title": "Minimal Model Reasoning in Description Logics: Don't Try This at Home!", "comment": "44 pages", "summary": "Reasoning with minimal models has always been at the core of many knowledge\nrepresentation techniques, but we still have only a limited understanding of\nthis problem in Description Logics (DLs). Minimization of some selected\npredicates, letting the remaining predicates vary or be fixed, as proposed in\ncircumscription, has been explored and exhibits high complexity. The case of\n`pure' minimal models, where the extension of all predicates must be minimal,\nhas remained largely uncharted. We address this problem in popular DLs and\nobtain surprisingly negative results: concept satisfiability in minimal models\nis undecidable already for $\\mathcal{EL}$. This undecidability also extends to\na very restricted fragment of tuple-generating dependencies. To regain\ndecidability, we impose acyclicity conditions on the TBox that bring the\nworst-case complexity below double exponential time and allow us to establish a\nconnection with the recently studied pointwise circumscription; we also derive\nresults in data complexity. We conclude with a brief excursion to the DL-Lite\nfamily, where a positive result was known for DL-Lite$_{\\text{core}}$, but our\ninvestigation establishes ExpSpace-hardness already for its extension\nDL-Lite$_{\\text{horn}}$.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.05383", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.05383", "abs": "https://arxiv.org/abs/2508.05383", "authors": ["Xiangxiang Zhang", "Jingxuan Wei", "Donghong Zhong", "Qi Chen", "Caijun Jia", "Cheng Tan", "Jinming Gu", "Xiaobo Qin", "Zhiping Liu", "Liang Hu", "Tong Sun", "Yuchen Wu", "Zewei Sun", "Chenwei Lou", "Hua Zheng", "Tianyang Zhan", "Changbao Wang", "Shuangzhi Wu", "Zefa Lin", "Chang Guo", "Sihang Yuan", "Riwei Chen", "Shixiong Zhao", "Yingping Zhang", "Gaowei Wu", "Bihui Yu", "Jiahui Wu", "Zhehui Zhao", "Qianqian Liu", "Ruofeng Tang", "Xingyue Huang", "Bing Zhao", "Mengyang Zhang", "Youqiang Zhou"], "title": "StructVRM: Aligning Multimodal Reasoning with Structured and Verifiable Reward Models", "comment": null, "summary": "Existing Vision-Language Models often struggle with complex, multi-question\nreasoning tasks where partial correctness is crucial for effective learning.\nTraditional reward mechanisms, which provide a single binary score for an\nentire response, are too coarse to guide models through intricate problems with\nmultiple sub-parts. To address this, we introduce StructVRM, a method that\naligns multimodal reasoning with Structured and Verifiable Reward Models. At\nits core is a model-based verifier trained to provide fine-grained,\nsub-question-level feedback, assessing semantic and mathematical equivalence\nrather than relying on rigid string matching. This allows for nuanced, partial\ncredit scoring in previously intractable problem formats. Extensive experiments\ndemonstrate the effectiveness of StructVRM. Our trained model, Seed-StructVRM,\nachieves state-of-the-art performance on six out of twelve public multimodal\nbenchmarks and our newly curated, high-difficulty STEM-Bench. The success of\nStructVRM validates that training with structured, verifiable rewards is a\nhighly effective approach for advancing the capabilities of multimodal models\nin complex, real-world reasoning domains.", "AI": {"tldr": "StructVRM\u901a\u8fc7\u7ed3\u6784\u5316\u53ef\u9a8c\u8bc1\u5956\u52b1\u6a21\u578b\u6539\u8fdb\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\uff0c\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u53cd\u9988\uff0c\u663e\u8457\u63d0\u5347\u590d\u6742\u95ee\u9898\u7684\u8868\u73b0\u3002", "motivation": "\u4f20\u7edf\u5956\u52b1\u673a\u5236\u5bf9\u590d\u6742\u591a\u95ee\u9898\u63a8\u7406\u4efb\u52a1\u8fc7\u4e8e\u7c97\u7cd9\uff0c\u65e0\u6cd5\u63d0\u4f9b\u90e8\u5206\u6b63\u786e\u6027\u7684\u6307\u5bfc\u3002", "method": "\u5f15\u5165StructVRM\uff0c\u57fa\u4e8e\u6a21\u578b\u9a8c\u8bc1\u5668\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u3001\u5b50\u95ee\u9898\u7ea7\u522b\u7684\u53cd\u9988\uff0c\u8bc4\u4f30\u8bed\u4e49\u548c\u6570\u5b66\u7b49\u4ef7\u6027\u3002", "result": "Seed-StructVRM\u572812\u4e2a\u591a\u6a21\u6001\u57fa\u51c6\u4e2d\u76846\u4e2a\u53ca\u65b0STEM-Bench\u4e0a\u8fbe\u5230\u6700\u4f18\u6027\u80fd\u3002", "conclusion": "\u7ed3\u6784\u5316\u53ef\u9a8c\u8bc1\u5956\u52b1\u8bad\u7ec3\u662f\u63d0\u5347\u591a\u6a21\u6001\u6a21\u578b\u590d\u6742\u63a8\u7406\u80fd\u529b\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2508.05388", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.05388", "abs": "https://arxiv.org/abs/2508.05388", "authors": ["Silvia Garc\u00eda-M\u00e9ndez", "Francisco de Arriba-P\u00e9rez", "F\u00e1tima Leal", "Bruno Veloso", "Benedita Malheiro", "Juan Carlos Burguillo-Rial"], "title": "An Explainable Machine Learning Framework for Railway Predictive Maintenance using Data Streams from the Metro Operator of Portugal", "comment": null, "summary": "This work contributes to a real-time data-driven predictive maintenance\nsolution for Intelligent Transportation Systems. The proposed method implements\na processing pipeline comprised of sample pre-processing, incremental\nclassification with Machine Learning models, and outcome explanation. This\nnovel online processing pipeline has two main highlights: (i) a dedicated\nsample pre-processing module, which builds statistical and frequency-related\nfeatures on the fly, and (ii) an explainability module. This work is the first\nto perform online fault prediction with natural language and visual\nexplainability. The experiments were performed with the MetroPT data set from\nthe metro operator of Porto, Portugal. The results are above 98 % for F-measure\nand 99 % for accuracy. In the context of railway predictive maintenance,\nachieving these high values is crucial due to the practical and operational\nimplications of accurate failure prediction. In the specific case of a high\nF-measure, this ensures that the system maintains an optimal balance between\ndetecting the highest possible number of real faults and minimizing false\nalarms, which is crucial for maximizing service availability. Furthermore, the\naccuracy obtained enables reliability, directly impacting cost reduction and\nincreased safety. The analysis demonstrates that the pipeline maintains high\nperformance even in the presence of class imbalance and noise, and its\nexplanations effectively reflect the decision-making process. These findings\nvalidate the methodological soundness of the approach and confirm its practical\napplicability for supporting proactive maintenance decisions in real-world\nrailway operations. Therefore, by identifying the early signs of failure, this\npipeline enables decision-makers to understand the underlying problems and act\naccordingly swiftly.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u65f6\u6570\u636e\u9a71\u52a8\u7684\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u9884\u6d4b\u6027\u7ef4\u62a4\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u6837\u672c\u9884\u5904\u7406\u3001\u589e\u91cf\u5206\u7c7b\u548c\u7ed3\u679c\u89e3\u91ca\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u9ad8\u51c6\u786e\u6027\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u4e3a\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u63d0\u4f9b\u5b9e\u65f6\u3001\u9ad8\u7cbe\u5ea6\u7684\u9884\u6d4b\u6027\u7ef4\u62a4\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u4f18\u5316\u670d\u52a1\u53ef\u7528\u6027\u548c\u5b89\u5168\u6027\u3002", "method": "\u91c7\u7528\u5305\u542b\u6837\u672c\u9884\u5904\u7406\u3001\u589e\u91cf\u5206\u7c7b\u548c\u89e3\u91ca\u6027\u6a21\u5757\u7684\u5728\u7ebf\u5904\u7406\u6d41\u7a0b\uff0c\u9996\u6b21\u5b9e\u73b0\u81ea\u7136\u8bed\u8a00\u548c\u53ef\u89c6\u5316\u89e3\u91ca\u7684\u5728\u7ebf\u6545\u969c\u9884\u6d4b\u3002", "result": "\u5728MetroPT\u6570\u636e\u96c6\u4e0a\uff0cF-measure\u8d85\u8fc798%\uff0c\u51c6\u786e\u7387\u8fbe99%\uff0c\u4e14\u5728\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u566a\u58f0\u4e0b\u8868\u73b0\u7a33\u5b9a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9a8c\u8bc1\u4e86\u5176\u65b9\u6cd5\u8bba\u7684\u6b63\u786e\u6027\u548c\u5b9e\u9645\u9002\u7528\u6027\uff0c\u80fd\u591f\u652f\u6301\u94c1\u8def\u8fd0\u8425\u4e2d\u7684\u4e3b\u52a8\u7ef4\u62a4\u51b3\u7b56\u3002"}}
{"id": "2508.05405", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.05405", "abs": "https://arxiv.org/abs/2508.05405", "authors": ["Xinrun Xu", "Pi Bu", "Ye Wang", "B\u00f6rje F. Karlsson", "Ziming Wang", "Tengtao Song", "Qi Zhu", "Jun Song", "Zhiming Ding", "Bo Zheng"], "title": "DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning", "comment": "48 pages", "summary": "Although Vision Language Models (VLMs) exhibit strong perceptual abilities\nand impressive visual reasoning, they struggle with attention to detail and\nprecise action planning in complex, dynamic environments, leading to subpar\nperformance. Real-world tasks typically require complex interactions, advanced\nspatial reasoning, long-term planning, and continuous strategy refinement,\nusually necessitating understanding the physics rules of the target scenario.\nHowever, evaluating these capabilities in real-world scenarios is often\nprohibitively expensive. To bridge this gap, we introduce DeepPHY, a novel\nbenchmark framework designed to systematically evaluate VLMs' understanding and\nreasoning about fundamental physical principles through a series of challenging\nsimulated environments. DeepPHY integrates multiple physical reasoning\nenvironments of varying difficulty levels and incorporates fine-grained\nevaluation metrics. Our evaluation finds that even state-of-the-art VLMs\nstruggle to translate descriptive physical knowledge into precise, predictive\ncontrol.", "AI": {"tldr": "DeepPHY\u662f\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u5bf9\u7269\u7406\u539f\u7406\u7684\u7406\u89e3\u548c\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709VLMs\u5728\u590d\u6742\u52a8\u6001\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u7f3a\u4e4f\u7ec6\u8282\u5173\u6ce8\u548c\u7cbe\u786e\u52a8\u4f5c\u89c4\u5212\u80fd\u529b\uff0c\u800c\u771f\u5b9e\u4efb\u52a1\u9700\u8981\u9ad8\u7ea7\u7a7a\u95f4\u63a8\u7406\u548c\u957f\u671f\u89c4\u5212\u3002", "method": "\u901a\u8fc7\u4e00\u7cfb\u5217\u5177\u6709\u6311\u6218\u6027\u7684\u6a21\u62df\u73af\u5883\uff0cDeepPHY\u7cfb\u7edf\u8bc4\u4f30VLMs\u5bf9\u7269\u7406\u539f\u7406\u7684\u7406\u89e3\uff0c\u5e76\u91c7\u7528\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u5373\u4f7f\u6700\u5148\u8fdb\u7684VLMs\u4e5f\u96be\u4ee5\u5c06\u63cf\u8ff0\u6027\u7269\u7406\u77e5\u8bc6\u8f6c\u5316\u4e3a\u7cbe\u786e\u7684\u9884\u6d4b\u63a7\u5236\u3002", "conclusion": "DeepPHY\u586b\u8865\u4e86\u8bc4\u4f30VLMs\u7269\u7406\u63a8\u7406\u80fd\u529b\u7684\u7a7a\u767d\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u6a21\u578b\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2508.05427", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.05427", "abs": "https://arxiv.org/abs/2508.05427", "authors": ["Kartar Kumar Lohana Tharwani", "Rajesh Kumar", "Sumita", "Numan Ahmed", "Yong Tang"], "title": "Large Language Models Transform Organic Synthesis From Reaction Prediction to Automation", "comment": null, "summary": "Large language models (LLMs) are beginning to reshape how chemists plan and\nrun reactions in organic synthesis. Trained on millions of reported\ntransformations, these text-based models can propose synthetic routes, forecast\nreaction outcomes and even instruct robots that execute experiments without\nhuman supervision. Here we survey the milestones that turned LLMs from\nspeculative tools into practical lab partners. We show how coupling LLMs with\ngraph neural networks, quantum calculations and real-time spectroscopy shrinks\ndiscovery cycles and supports greener, data-driven chemistry. We discuss\nlimitations, including biased datasets, opaque reasoning and the need for\nsafety gates that prevent unintentional hazards. Finally, we outline community\ninitiatives open benchmarks, federated learning and explainable interfaces that\naim to democratize access while keeping humans firmly in control. These\nadvances chart a path towards rapid, reliable and inclusive molecular\ninnovation powered by artificial intelligence and automation.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6b63\u5728\u6539\u53d8\u6709\u673a\u5408\u6210\u4e2d\u5316\u5b66\u5bb6\u7684\u53cd\u5e94\u89c4\u5212\u548c\u6267\u884c\u65b9\u5f0f\uff0c\u7ed3\u5408\u56fe\u795e\u7ecf\u7f51\u7edc\u3001\u91cf\u5b50\u8ba1\u7b97\u548c\u5b9e\u65f6\u5149\u8c31\u5b66\uff0c\u52a0\u901f\u53d1\u73b0\u5468\u671f\u5e76\u63a8\u52a8\u7eff\u8272\u5316\u5b66\u3002", "motivation": "\u63a2\u7d22LLMs\u5982\u4f55\u4ece\u7406\u8bba\u5de5\u5177\u53d1\u5c55\u4e3a\u5b9e\u9a8c\u5ba4\u5b9e\u7528\u4f19\u4f34\uff0c\u4ee5\u652f\u6301\u66f4\u5feb\u3001\u66f4\u73af\u4fdd\u7684\u5316\u5b66\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u7ed3\u5408LLMs\u4e0e\u56fe\u795e\u7ecf\u7f51\u7edc\u3001\u91cf\u5b50\u8ba1\u7b97\u548c\u5b9e\u65f6\u5149\u8c31\u5b66\uff0c\u4f18\u5316\u5408\u6210\u8def\u7ebf\u9884\u6d4b\u548c\u5b9e\u9a8c\u6267\u884c\u3002", "result": "LLMs\u663e\u8457\u7f29\u77ed\u4e86\u53d1\u73b0\u5468\u671f\uff0c\u652f\u6301\u6570\u636e\u9a71\u52a8\u7684\u7eff\u8272\u5316\u5b66\uff0c\u4f46\u4ecd\u5b58\u5728\u6570\u636e\u96c6\u504f\u89c1\u548c\u5b89\u5168\u6027\u95ee\u9898\u3002", "conclusion": "\u901a\u8fc7\u5f00\u653e\u57fa\u51c6\u3001\u8054\u90a6\u5b66\u4e60\u548c\u53ef\u89e3\u91ca\u754c\u9762\u7b49\u793e\u533a\u5021\u8bae\uff0cLLMs\u6709\u671b\u5b9e\u73b0\u5feb\u901f\u3001\u53ef\u9760\u4e14\u5305\u5bb9\u7684\u5206\u5b50\u521b\u65b0\u3002"}}
{"id": "2508.05432", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.05432", "abs": "https://arxiv.org/abs/2508.05432", "authors": ["Krzysztof Janowicz", "Zilong Liu", "Gengchen Mai", "Zhangyu Wang", "Ivan Majic", "Alexandra Fortacz", "Grant McKenzie", "Song Gao"], "title": "Whose Truth? Pluralistic Geo-Alignment for (Agentic) AI", "comment": null, "summary": "AI (super) alignment describes the challenge of ensuring (future) AI systems\nbehave in accordance with societal norms and goals. While a quickly evolving\nliterature is addressing biases and inequalities, the geographic variability of\nalignment remains underexplored. Simply put, what is considered appropriate,\ntruthful, or legal can differ widely across regions due to cultural norms,\npolitical realities, and legislation. Alignment measures applied to AI/ML\nworkflows can sometimes produce outcomes that diverge from statistical\nrealities, such as text-to-image models depicting balanced gender ratios in\ncompany leadership despite existing imbalances. Crucially, some model outputs\nare globally acceptable, while others, e.g., questions about Kashmir, depend on\nknowing the user's location and their context. This geographic sensitivity is\nnot new. For instance, Google Maps renders Kashmir's borders differently based\non user location. What is new is the unprecedented scale and automation with\nwhich AI now mediates knowledge, expresses opinions, and represents geographic\nreality to millions of users worldwide, often with little transparency about\nhow context is managed. As we approach Agentic AI, the need for\nspatio-temporally aware alignment, rather than one-size-fits-all approaches, is\nincreasingly urgent. This paper reviews key geographic research problems,\nsuggests topics for future work, and outlines methods for assessing alignment\nsensitivity.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86AI\u5bf9\u9f50\u4e2d\u7684\u5730\u7406\u53d8\u5f02\u6027\u95ee\u9898\uff0c\u5f3a\u8c03\u4e86\u6587\u5316\u3001\u653f\u6cbb\u548c\u6cd5\u5f8b\u5dee\u5f02\u5bf9AI\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u7684\u65b9\u5411\u548c\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740AI\u5728\u5168\u7403\u8303\u56f4\u5185\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u786e\u4fdd\u5176\u884c\u4e3a\u7b26\u5408\u4e0d\u540c\u5730\u533a\u7684\u793e\u4f1a\u89c4\u8303\u548c\u76ee\u6807\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u5730\u7406\u53d8\u5f02\u6027\u95ee\u9898\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u672c\u6587\u56de\u987e\u4e86\u5173\u952e\u7684\u5730\u7406\u7814\u7a76\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u672a\u6765\u5de5\u4f5c\u7684\u4e3b\u9898\uff0c\u5e76\u6982\u8ff0\u4e86\u8bc4\u4f30\u5bf9\u9f50\u654f\u611f\u6027\u7684\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cAI\u5bf9\u9f50\u63aa\u65bd\u6709\u65f6\u4f1a\u4e0e\u7edf\u8ba1\u73b0\u5b9e\u8131\u8282\uff0c\u4e14\u67d0\u4e9b\u6a21\u578b\u8f93\u51fa\u9700\u8981\u6839\u636e\u7528\u6237\u7684\u5730\u7406\u4f4d\u7f6e\u548c\u80cc\u666f\u8fdb\u884c\u8c03\u6574\u3002", "conclusion": "\u672a\u6765\u9700\u8981\u5f00\u53d1\u66f4\u5177\u65f6\u7a7a\u610f\u8bc6\u7684AI\u5bf9\u9f50\u65b9\u6cd5\uff0c\u800c\u975e\u4e00\u5200\u5207\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.05464", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.05464", "abs": "https://arxiv.org/abs/2508.05464", "authors": ["Matteo Prandi", "Vincenzo Suriani", "Federico Pierucci", "Marcello Galisai", "Daniele Nardi", "Piercosma Bisconti"], "title": "Bench-2-CoP: Can We Trust Benchmarking for EU AI Compliance?", "comment": null, "summary": "The rapid advancement of General Purpose AI (GPAI) models necessitates robust\nevaluation frameworks, especially with emerging regulations like the EU AI Act\nand its associated Code of Practice (CoP). Current AI evaluation practices\ndepend heavily on established benchmarks, but these tools were not designed to\nmeasure the systemic risks that are the focus of the new regulatory landscape.\nThis research addresses the urgent need to quantify this \"benchmark-regulation\ngap.\" We introduce Bench-2-CoP, a novel, systematic framework that uses\nvalidated LLM-as-judge analysis to map the coverage of 194,955 questions from\nwidely-used benchmarks against the EU AI Act's taxonomy of model capabilities\nand propensities. Our findings reveal a profound misalignment: the evaluation\necosystem is overwhelmingly focused on a narrow set of behavioral propensities,\nsuch as \"Tendency to hallucinate\" (53.7% of the corpus) and \"Discriminatory\nbias\" (28.9%), while critical functional capabilities are dangerously\nneglected. Crucially, capabilities central to loss-of-control scenarios,\nincluding evading human oversight, self-replication, and autonomous AI\ndevelopment, receive zero coverage in the entire benchmark corpus. This\ntranslates to a near-total evaluation gap for systemic risks like \"Loss of\nControl\" (0.4% coverage) and \"Cyber Offence\" (0.8% coverage). This study\nprovides the first comprehensive, quantitative analysis of this gap, offering\ncritical insights for policymakers to refine the CoP and for developers to\nbuild the next generation of evaluation tools, ultimately fostering safer and\nmore compliant AI.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51faBench-2-CoP\u6846\u67b6\uff0c\u91cf\u5316AI\u8bc4\u4f30\u57fa\u51c6\u4e0e\u6b27\u76dfAI\u6cd5\u6848\u8981\u6c42\u7684\u5dee\u8ddd\uff0c\u53d1\u73b0\u73b0\u6709\u8bc4\u4f30\u8fc7\u5ea6\u5173\u6ce8\u884c\u4e3a\u503e\u5411\uff0c\u800c\u5ffd\u89c6\u5173\u952e\u529f\u80fd\u80fd\u529b\u3002", "motivation": "\u5f53\u524dAI\u8bc4\u4f30\u4f9d\u8d56\u7684\u57fa\u51c6\u672a\u6db5\u76d6\u65b0\u6cd5\u89c4\u5173\u6ce8\u7684\u7cfb\u7edf\u6027\u98ce\u9669\uff0c\u4e9f\u9700\u586b\u8865\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u4f7f\u7528LLM-as-judge\u5206\u6790\uff0c\u5c06194,955\u4e2a\u57fa\u51c6\u95ee\u9898\u6620\u5c04\u5230\u6b27\u76dfAI\u6cd5\u6848\u7684\u80fd\u529b\u5206\u7c7b\u3002", "result": "\u53d1\u73b0\u8bc4\u4f30\u4e25\u91cd\u504f\u5411\u884c\u4e3a\u503e\u5411\uff08\u5982\u5e7b\u89c9\u503e\u541153.7%\uff09\uff0c\u800c\u5173\u952e\u529f\u80fd\u80fd\u529b\uff08\u5982\u5931\u63a7\u573a\u666f\uff09\u51e0\u4e4e\u672a\u88ab\u8986\u76d6\u3002", "conclusion": "\u7814\u7a76\u4e3a\u653f\u7b56\u5236\u5b9a\u8005\u548c\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u586b\u8865\u8bc4\u4f30\u5dee\u8ddd\u7684\u91cf\u5316\u4f9d\u636e\uff0c\u4ee5\u4fc3\u8fdb\u66f4\u5b89\u5168\u7684AI\u53d1\u5c55\u3002"}}
{"id": "2508.05474", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.05474", "abs": "https://arxiv.org/abs/2508.05474", "authors": ["Burak Can Kaplan", "Hugo Cesar De Castro Carneiro", "Stefan Wermter"], "title": "Can Large Language Models Generate Effective Datasets for Emotion Recognition in Conversations?", "comment": "8 pages, 4 figures", "summary": "Emotion recognition in conversations (ERC) focuses on identifying emotion\nshifts within interactions, representing a significant step toward advancing\nmachine intelligence. However, ERC data remains scarce, and existing datasets\nface numerous challenges due to their highly biased sources and the inherent\nsubjectivity of soft labels. Even though Large Language Models (LLMs) have\ndemonstrated their quality in many affective tasks, they are typically\nexpensive to train, and their application to ERC tasks--particularly in data\ngeneration--remains limited. To address these challenges, we employ a small,\nresource-efficient, and general-purpose LLM to synthesize ERC datasets with\ndiverse properties, supplementing the three most widely used ERC benchmarks. We\ngenerate six novel datasets, with two tailored to enhance each benchmark. We\nevaluate the utility of these datasets to (1) supplement existing datasets for\nERC classification, and (2) analyze the effects of label imbalance in ERC. Our\nexperimental results indicate that ERC classifier models trained on the\ngenerated datasets exhibit strong robustness and consistently achieve\nstatistically significant performance improvements on existing ERC benchmarks.", "AI": {"tldr": "\u4f7f\u7528\u5c0f\u578b\u901a\u7528LLM\u751f\u6210\u591a\u6837\u5316ERC\u6570\u636e\u96c6\uff0c\u8865\u5145\u73b0\u6709\u57fa\u51c6\uff0c\u63d0\u5347\u5206\u7c7b\u5668\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3ERC\u6570\u636e\u7a00\u7f3a\u3001\u6765\u6e90\u504f\u89c1\u548c\u6807\u7b7e\u4e3b\u89c2\u6027\u95ee\u9898\uff0c\u63a2\u7d22LLM\u5728\u6570\u636e\u751f\u6210\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5229\u7528\u5c0f\u578b\u8d44\u6e90\u9ad8\u6548LLM\u5408\u6210\u516d\u79cd\u65b0\u6570\u636e\u96c6\uff0c\u8865\u5145\u4e09\u5927ERC\u57fa\u51c6\uff0c\u8bc4\u4f30\u5176\u5bf9\u5206\u7c7b\u548c\u6807\u7b7e\u4e0d\u5e73\u8861\u7684\u5f71\u54cd\u3002", "result": "\u751f\u6210\u6570\u636e\u96c6\u663e\u8457\u63d0\u5347ERC\u5206\u7c7b\u5668\u6027\u80fd\uff0c\u589e\u5f3a\u6a21\u578b\u9c81\u68d2\u6027\u3002", "conclusion": "\u5c0f\u578bLLM\u751f\u6210\u7684\u6570\u636e\u96c6\u6709\u6548\u8865\u5145ERC\u4efb\u52a1\uff0c\u4e3a\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u63d0\u4f9b\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.05496", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.05496", "abs": "https://arxiv.org/abs/2508.05496", "authors": ["Shuo Cai", "Su Lu", "Qi Zhou", "Kejing Yang", "Zhijie Sang", "Congkai Xie", "Hongxia Yang"], "title": "InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs to Enhance Reasoning Capabilities", "comment": null, "summary": "Large language models (LLMs) have exhibited impressive reasoning abilities on\na wide range of complex tasks. However, enhancing these capabilities through\npost-training remains resource intensive, particularly in terms of data and\ncomputational cost. Although recent efforts have sought to improve sample\nefficiency through selective data curation, existing methods often rely on\nheuristic or task-specific strategies that hinder scalability. In this work, we\nintroduce InfiAlign, a scalable and sample-efficient post-training framework\nthat integrates supervised fine-tuning (SFT) with Direct Preference\nOptimization (DPO) to align LLMs for enhanced reasoning. At the core of\nInfiAlign is a robust data selection pipeline that automatically curates\nhigh-quality alignment data from open-source reasoning datasets using\nmultidimensional quality metrics. This pipeline enables significant performance\ngains while drastically reducing data requirements and remains extensible to\nnew data sources. When applied to the Qwen2.5-Math-7B-Base model, our SFT model\nachieves performance on par with DeepSeek-R1-Distill-Qwen-7B, while using only\napproximately 12% of the training data, and demonstrates strong generalization\nacross diverse reasoning tasks. Additional improvements are obtained through\nthe application of DPO, with particularly notable gains in mathematical\nreasoning tasks. The model achieves an average improvement of 3.89% on AIME\n24/25 benchmarks. Our results highlight the effectiveness of combining\nprincipled data selection with full-stage post-training, offering a practical\nsolution for aligning large reasoning models in a scalable and data-efficient\nmanner. The model checkpoints are available at\nhttps://huggingface.co/InfiX-ai/InfiAlign-Qwen-7B-SFT.", "AI": {"tldr": "InfiAlign\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u540e\u8bad\u7ec3\u6846\u67b6\uff0c\u7ed3\u5408\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u548c\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\uff0c\u901a\u8fc7\u591a\u7ef4\u8d28\u91cf\u6307\u6807\u81ea\u52a8\u7b5b\u9009\u9ad8\u8d28\u91cf\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u540c\u65f6\u51cf\u5c11\u6570\u636e\u9700\u6c42\u3002", "motivation": "\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u901a\u5e38\u9700\u8981\u5927\u91cf\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u542f\u53d1\u5f0f\u6216\u4efb\u52a1\u7279\u5b9a\u7b56\u7565\uff0c\u96be\u4ee5\u6269\u5c55\u3002InfiAlign\u65e8\u5728\u63d0\u4f9b\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u6837\u672c\u9ad8\u6548\u7684\u540e\u8bad\u7ec3\u89e3\u51b3\u65b9\u6848\u3002", "method": "InfiAlign\u6574\u5408SFT\u548cDPO\uff0c\u901a\u8fc7\u591a\u7ef4\u8d28\u91cf\u6307\u6807\u81ea\u52a8\u7b5b\u9009\u9ad8\u8d28\u91cf\u6570\u636e\uff0c\u51cf\u5c11\u8bad\u7ec3\u6570\u636e\u9700\u6c42\u3002\u5e94\u7528\u4e8eQwen2.5-Math-7B-Base\u6a21\u578b\uff0c\u4ec5\u752812%\u7684\u6570\u636e\u8fbe\u5230\u7c7b\u4f3c\u6027\u80fd\u3002", "result": "\u5728AIME 24/25\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6a21\u578b\u5e73\u5747\u63d0\u53473.89%\uff0c\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u8868\u73b0\u5c24\u4e3a\u7a81\u51fa\u3002SFT\u6a21\u578b\u6027\u80fd\u4e0eDeepSeek-R1-Distill-Qwen-7B\u76f8\u5f53\u3002", "conclusion": "InfiAlign\u901a\u8fc7\u7ed3\u5408\u6570\u636e\u9009\u62e9\u548c\u5168\u9636\u6bb5\u540e\u8bad\u7ec3\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u5927\u6a21\u578b\u5bf9\u9f50\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u80fd\u529b\u5e76\u51cf\u5c11\u6570\u636e\u4f9d\u8d56\u3002"}}
{"id": "2508.05498", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.05498", "abs": "https://arxiv.org/abs/2508.05498", "authors": ["Ge Chang", "Jinbo Su", "Jiacheng Liu", "Pengfei Yang", "Yuhao Shang", "Huiwen Zheng", "Hongli Ma", "Yan Liang", "Yuanchun Li", "Yunxin Liu"], "title": "GRAIL:Learning to Interact with Large Knowledge Graphs for Retrieval Augmented Reasoning", "comment": "9 pages,3 figures", "summary": "Large Language Models (LLMs) integrated with Retrieval-Augmented Generation\n(RAG) techniques have exhibited remarkable performance across a wide range of\ndomains. However, existing RAG approaches primarily operate on unstructured\ndata and demonstrate limited capability in handling structured knowledge such\nas knowledge graphs. Meanwhile, current graph retrieval methods fundamentally\nstruggle to capture holistic graph structures while simultaneously facing\nprecision control challenges that manifest as either critical information gaps\nor excessive redundant connections, collectively undermining reasoning\nperformance. To address this challenge, we propose GRAIL: Graph-Retrieval\nAugmented Interactive Learning, a framework designed to interact with\nlarge-scale graphs for retrieval-augmented reasoning. Specifically, GRAIL\nintegrates LLM-guided random exploration with path filtering to establish a\ndata synthesis pipeline, where a fine-grained reasoning trajectory is\nautomatically generated for each task. Based on the synthesized data, we then\nemploy a two-stage training process to learn a policy that dynamically decides\nthe optimal actions at each reasoning step. The overall objective of\nprecision-conciseness balance in graph retrieval is decoupled into fine-grained\nprocess-supervised rewards to enhance data efficiency and training stability.\nIn practical deployment, GRAIL adopts an interactive retrieval paradigm,\nenabling the model to autonomously explore graph paths while dynamically\nbalancing retrieval breadth and precision. Extensive experiments have shown\nthat GRAIL achieves an average accuracy improvement of 21.01% and F1\nimprovement of 22.43% on three knowledge graph question-answering datasets. Our\nsource code and datasets is available at https://github.com/Changgeww/GRAIL.", "AI": {"tldr": "GRAIL\u6846\u67b6\u901a\u8fc7\u7ed3\u5408LLM\u5f15\u5bfc\u7684\u968f\u673a\u63a2\u7d22\u548c\u8def\u5f84\u8fc7\u6ee4\uff0c\u89e3\u51b3\u4e86\u73b0\u6709RAG\u65b9\u6cd5\u5728\u5904\u7406\u7ed3\u6784\u5316\u77e5\u8bc6\uff08\u5982\u77e5\u8bc6\u56fe\u8c31\uff09\u65f6\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u6709RAG\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u975e\u7ed3\u6784\u5316\u6570\u636e\uff0c\u5904\u7406\u7ed3\u6784\u5316\u77e5\u8bc6\uff08\u5982\u77e5\u8bc6\u56fe\u8c31\uff09\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u56fe\u68c0\u7d22\u65b9\u6cd5\u96be\u4ee5\u5e73\u8861\u5168\u5c40\u7ed3\u6784\u548c\u7cbe\u786e\u63a7\u5236\u3002", "method": "GRAIL\u7ed3\u5408LLM\u5f15\u5bfc\u7684\u968f\u673a\u63a2\u7d22\u4e0e\u8def\u5f84\u8fc7\u6ee4\uff0c\u5efa\u7acb\u6570\u636e\u5408\u6210\u7ba1\u9053\uff0c\u5e76\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u5b66\u4e60\u52a8\u6001\u51b3\u7b56\u7b56\u7565\u3002", "result": "\u5728\u4e09\u4e2a\u77e5\u8bc6\u56fe\u8c31\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\uff0cGRAIL\u5e73\u5747\u51c6\u786e\u7387\u63d0\u534721.01%\uff0cF1\u503c\u63d0\u534722.43%\u3002", "conclusion": "GRAIL\u901a\u8fc7\u4ea4\u4e92\u5f0f\u68c0\u7d22\u8303\u5f0f\uff0c\u6709\u6548\u5e73\u8861\u68c0\u7d22\u5e7f\u5ea6\u4e0e\u7cbe\u5ea6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2508.05508", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.05508", "abs": "https://arxiv.org/abs/2508.05508", "authors": ["Roshita Bhonsle", "Rishav Dutta", "Sneha Vavilapalli", "Harsh Seth", "Abubakarr Jaye", "Yapei Chang", "Mukund Rungta", "Emmanuel Aboah Boateng", "Sadid Hasan", "Ehi Nosakhare", "Soundar Srinivasan"], "title": "Auto-Eval Judge: Towards a General Agentic Framework for Task Completion Evaluation", "comment": null, "summary": "The increasing adoption of foundation models as agents across diverse domains\nnecessitates a robust evaluation framework. Current methods, such as\nLLM-as-a-Judge, focus only on final outputs, overlooking the step-by-step\nreasoning that drives agentic decision-making. Meanwhile, existing\nAgent-as-a-Judge systems, where one agent evaluates another's task completion,\nare typically designed for narrow, domain-specific settings. To address this\ngap, we propose a generalizable, modular framework for evaluating agent task\ncompletion independent of the task domain. The framework emulates human-like\nevaluation by decomposing tasks into sub-tasks and validating each step using\navailable information, such as the agent's output and reasoning. Each module\ncontributes to a specific aspect of the evaluation process, and their outputs\nare aggregated to produce a final verdict on task completion. We validate our\nframework by evaluating the Magentic-One Actor Agent on two benchmarks, GAIA\nand BigCodeBench. Our Judge Agent predicts task success with closer agreement\nto human evaluations, achieving 4.76% and 10.52% higher alignment accuracy,\nrespectively, compared to the GPT-4o based LLM-as-a-Judge baseline. This\ndemonstrates the potential of our proposed general-purpose evaluation\nframework.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u3001\u6a21\u5757\u5316\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u4ee3\u7406\u4efb\u52a1\u5b8c\u6210\u60c5\u51b5\uff0c\u901a\u8fc7\u5206\u89e3\u4efb\u52a1\u5e76\u9a8c\u8bc1\u6bcf\u4e2a\u6b65\u9aa4\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u63a5\u8fd1\u4eba\u7c7b\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\uff08\u5982LLM-as-a-Judge\uff09\u4ec5\u5173\u6ce8\u6700\u7ec8\u8f93\u51fa\uff0c\u5ffd\u7565\u4e86\u9010\u6b65\u63a8\u7406\u8fc7\u7a0b\uff1b\u800cAgent-as-a-Judge\u7cfb\u7edf\u53c8\u5c40\u9650\u4e8e\u7279\u5b9a\u9886\u57df\u3002\u9700\u8981\u4e00\u79cd\u901a\u7528\u6846\u67b6\u3002", "method": "\u8bbe\u8ba1\u6a21\u5757\u5316\u6846\u67b6\uff0c\u5c06\u4efb\u52a1\u5206\u89e3\u4e3a\u5b50\u4efb\u52a1\uff0c\u9a8c\u8bc1\u6bcf\u4e2a\u6b65\u9aa4\uff0c\u5e76\u805a\u5408\u6a21\u5757\u8f93\u51fa\u4ee5\u751f\u6210\u6700\u7ec8\u8bc4\u4f30\u7ed3\u679c\u3002", "result": "\u5728GAIA\u548cBigCodeBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u63d0\u51fa\u7684Judge Agent\u6bd4GPT-4o\u57fa\u7ebf\u66f4\u63a5\u8fd1\u4eba\u7c7b\u8bc4\u4f30\uff0c\u5bf9\u9f50\u51c6\u786e\u7387\u5206\u522b\u63d0\u9ad84.76%\u548c10.52%\u3002", "conclusion": "\u8be5\u901a\u7528\u8bc4\u4f30\u6846\u67b6\u5728\u4efb\u52a1\u5b8c\u6210\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u66f4\u63a5\u8fd1\u4eba\u7c7b\u5224\u65ad\u3002"}}
{"id": "2508.05513", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.05513", "abs": "https://arxiv.org/abs/2508.05513", "authors": ["Meryem Yilmaz Soylu", "Adrian Gallard", "Jeonghyun Lee", "Gayane Grigoryan", "Rushil Desai", "Stephen Harmon"], "title": "Streamlining Admission with LOR Insights: AI-Based Leadership Assessment in Online Master's Program", "comment": null, "summary": "Letters of recommendation (LORs) provide valuable insights into candidates'\ncapabilities and experiences beyond standardized test scores. However,\nreviewing these text-heavy materials is time-consuming and labor-intensive. To\naddress this challenge and support the admission committee in providing\nfeedback for students' professional growth, our study introduces LORI: LOR\nInsights, a novel AI-based detection tool for assessing leadership skills in\nLORs submitted by online master's program applicants. By employing natural\nlanguage processing and leveraging large language models using RoBERTa and\nLLAMA, we seek to identify leadership attributes such as teamwork,\ncommunication, and innovation. Our latest RoBERTa model achieves a weighted F1\nscore of 91.6%, a precision of 92.4%, and a recall of 91.6%, showing a strong\nlevel of consistency in our test data. With the growing importance of\nleadership skills in the STEM sector, integrating LORI into the graduate\nadmissions process is crucial for accurately assessing applicants' leadership\ncapabilities. This approach not only streamlines the admissions process but\nalso automates and ensures a more comprehensive evaluation of candidates'\ncapabilities.", "AI": {"tldr": "LORI\u662f\u4e00\u79cd\u57fa\u4e8eAI\u7684\u5de5\u5177\uff0c\u7528\u4e8e\u4ece\u63a8\u8350\u4fe1\u4e2d\u81ea\u52a8\u68c0\u6d4b\u9886\u5bfc\u529b\u6280\u80fd\uff0c\u91c7\u7528RoBERTa\u548cLLAMA\u6a21\u578b\uff0c\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u63a8\u8350\u4fe1\u8bc4\u4f30\u8017\u65f6\u4e14\u4e3b\u89c2\uff0c\u9700\u81ea\u52a8\u5316\u5de5\u5177\u652f\u6301\u62db\u751f\u59d4\u5458\u4f1a\u66f4\u9ad8\u6548\u3001\u5ba2\u89c2\u5730\u8bc4\u4f30\u7533\u8bf7\u8005\u9886\u5bfc\u529b\u3002", "method": "\u5229\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff08RoBERTa\u548cLLAMA\uff09\u8bc6\u522b\u63a8\u8350\u4fe1\u4e2d\u7684\u9886\u5bfc\u529b\u5c5e\u6027\uff08\u5982\u56e2\u961f\u5408\u4f5c\u3001\u6c9f\u901a\u3001\u521b\u65b0\uff09\u3002", "result": "RoBERTa\u6a21\u578b\u5728\u6d4b\u8bd5\u6570\u636e\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u52a0\u6743F1\u5206\u657091.6%\uff0c\u7cbe\u786e\u738792.4%\uff0c\u53ec\u56de\u738791.6%\u3002", "conclusion": "LORI\u5de5\u5177\u53ef\u63d0\u5347\u62db\u751f\u6548\u7387\uff0c\u786e\u4fdd\u5bf9\u7533\u8bf7\u8005\u9886\u5bfc\u529b\u7684\u5168\u9762\u8bc4\u4f30\uff0c\u5c24\u5176\u9002\u7528\u4e8eSTEM\u9886\u57df\u3002"}}
{"id": "2508.05557", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.05557", "abs": "https://arxiv.org/abs/2508.05557", "authors": ["Rui Lu", "Jinhe Bi", "Yunpu Ma", "Feng Xiao", "Yuntao Du", "Yijun Tian"], "title": "MV-Debate: Multi-view Agent Debate with Dynamic Reflection Gating for Multimodal Harmful Content Detection in Social Media", "comment": null, "summary": "Social media has evolved into a complex multimodal environment where text,\nimages, and other signals interact to shape nuanced meanings, often concealing\nharmful intent. Identifying such intent, whether sarcasm, hate speech, or\nmisinformation, remains challenging due to cross-modal contradictions, rapid\ncultural shifts, and subtle pragmatic cues. To address these challenges, we\npropose MV-Debate, a multi-view agent debate framework with dynamic reflection\ngating for unified multimodal harmful content detection. MV-Debate assembles\nfour complementary debate agents, a surface analyst, a deep reasoner, a\nmodality contrast, and a social contextualist, to analyze content from diverse\ninterpretive perspectives. Through iterative debate and reflection, the agents\nrefine responses under a reflection-gain criterion, ensuring both accuracy and\nefficiency. Experiments on three benchmark datasets demonstrate that MV-Debate\nsignificantly outperforms strong single-model and existing multi-agent debate\nbaselines. This work highlights the promise of multi-agent debate in advancing\nreliable social intent detection in safety-critical online contexts.", "AI": {"tldr": "MV-Debate\u662f\u4e00\u79cd\u591a\u89c6\u89d2\u4ee3\u7406\u8fa9\u8bba\u6846\u67b6\uff0c\u7528\u4e8e\u7edf\u4e00\u591a\u6a21\u6001\u6709\u5bb3\u5185\u5bb9\u68c0\u6d4b\uff0c\u901a\u8fc7\u52a8\u6001\u53cd\u601d\u95e8\u63a7\u4f18\u5316\u6027\u80fd\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u4e2d\u591a\u6a21\u6001\u5185\u5bb9\u7684\u590d\u6742\u6027\u4f7f\u5f97\u6709\u5bb3\u610f\u56fe\uff08\u5982\u8bbd\u523a\u3001\u4ec7\u6068\u8a00\u8bba\u6216\u865a\u5047\u4fe1\u606f\uff09\u96be\u4ee5\u8bc6\u522b\uff0c\u9700\u8981\u8de8\u6a21\u6001\u5206\u6790\u548c\u52a8\u6001\u9002\u5e94\u3002", "method": "\u63d0\u51faMV-Debate\u6846\u67b6\uff0c\u5305\u542b\u56db\u4e2a\u4e92\u8865\u7684\u8fa9\u8bba\u4ee3\u7406\uff08\u8868\u9762\u5206\u6790\u5e08\u3001\u6df1\u5ea6\u63a8\u7406\u8005\u3001\u6a21\u6001\u5bf9\u6bd4\u8005\u548c\u793e\u4f1a\u60c5\u5883\u5206\u6790\u8005\uff09\uff0c\u901a\u8fc7\u8fed\u4ee3\u8fa9\u8bba\u548c\u52a8\u6001\u53cd\u601d\u95e8\u63a7\u4f18\u5316\u68c0\u6d4b\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cMV-Debate\u663e\u8457\u4f18\u4e8e\u5355\u4e00\u6a21\u578b\u548c\u73b0\u6709\u591a\u4ee3\u7406\u8fa9\u8bba\u57fa\u7ebf\u3002", "conclusion": "\u591a\u4ee3\u7406\u8fa9\u8bba\u6846\u67b6\u5728\u63d0\u5347\u793e\u4ea4\u5a92\u4f53\u6709\u5bb3\u610f\u56fe\u68c0\u6d4b\u7684\u53ef\u9760\u6027\u548c\u6548\u7387\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2508.05619", "categories": ["cs.AI", "nlin.AO", "physics.bio-ph", "physics.comp-ph", "physics.hist-ph"], "pdf": "https://arxiv.org/pdf/2508.05619", "abs": "https://arxiv.org/abs/2508.05619", "authors": ["Bo Wen"], "title": "The Missing Reward: Active Inference in the Era of Experience", "comment": null, "summary": "This paper argues that Active Inference (AIF) provides a crucial foundation\nfor developing autonomous AI agents capable of learning from experience without\ncontinuous human reward engineering. As AI systems begin to exhaust\nhigh-quality training data and rely on increasingly large human workforces for\nreward design, the current paradigm faces significant scalability challenges\nthat could impede progress toward genuinely autonomous intelligence. The\nproposal for an ``Era of Experience,'' where agents learn from self-generated\ndata, is a promising step forward. However, this vision still depends on\nextensive human engineering of reward functions, effectively shifting the\nbottleneck from data curation to reward curation. This highlights what we\nidentify as the \\textbf{grounded-agency gap}: the inability of contemporary AI\nsystems to autonomously formulate, adapt, and pursue objectives in response to\nchanging circumstances. We propose that AIF can bridge this gap by replacing\nexternal reward signals with an intrinsic drive to minimize free energy,\nallowing agents to naturally balance exploration and exploitation through a\nunified Bayesian objective. By integrating Large Language Models as generative\nworld models with AIF's principled decision-making framework, we can create\nagents that learn efficiently from experience while remaining aligned with\nhuman values. This synthesis offers a compelling path toward AI systems that\ncan develop autonomously while adhering to both computational and physical\nconstraints.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e3b\u52a8\u63a8\u7406\uff08AIF\uff09\u662f\u5f00\u53d1\u65e0\u9700\u6301\u7eed\u4eba\u5de5\u5956\u52b1\u8bbe\u8ba1\u7684\u81ea\u4e3bAI\u4ee3\u7406\u7684\u5173\u952e\u57fa\u7840\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u81ea\u7531\u80fd\u91cf\u7684\u5185\u5728\u9a71\u52a8\u529b\u66ff\u4ee3\u5916\u90e8\u5956\u52b1\u4fe1\u53f7\u3002", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\u4f9d\u8d56\u5927\u91cf\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\u548c\u4eba\u5de5\u5956\u52b1\u8bbe\u8ba1\uff0c\u9762\u4e34\u53ef\u6269\u5c55\u6027\u6311\u6218\uff0c\u963b\u788d\u771f\u6b63\u81ea\u4e3b\u667a\u80fd\u7684\u53d1\u5c55\u3002", "method": "\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u751f\u6210\u4e16\u754c\u6a21\u578b\u4e0eAIF\u7684\u51b3\u7b56\u6846\u67b6\uff0c\u4f7f\u4ee3\u7406\u80fd\u9ad8\u6548\u4ece\u7ecf\u9a8c\u4e2d\u5b66\u4e60\u5e76\u4fdd\u6301\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u4e00\u81f4\u3002", "result": "AIF\u80fd\u586b\u8865\"\u63a5\u5730\u4ee3\u7406\u7f3a\u53e3\"\uff0c\u4f7fAI\u7cfb\u7edf\u81ea\u4e3b\u5236\u5b9a\u3001\u8c03\u6574\u548c\u8ffd\u6c42\u76ee\u6807\uff0c\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\u3002", "conclusion": "AIF\u4e3a\u5f00\u53d1\u81ea\u4e3b\u4e14\u7b26\u5408\u7ea6\u675f\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2508.05622", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.05622", "abs": "https://arxiv.org/abs/2508.05622", "authors": ["Yu Yuan", "Lili Zhao", "Wei Chen", "Guangting Zheng", "Kai Zhang", "Mengdi Zhang", "Qi Liu"], "title": "Simulating Human-Like Learning Dynamics with LLM-Empowered Agents", "comment": null, "summary": "Capturing human learning behavior based on deep learning methods has become a\nmajor research focus in both psychology and intelligent systems. Recent\napproaches rely on controlled experiments or rule-based models to explore\ncognitive processes. However, they struggle to capture learning dynamics, track\nprogress over time, or provide explainability. To address these challenges, we\nintroduce LearnerAgent, a novel multi-agent framework based on Large Language\nModels (LLMs) to simulate a realistic teaching environment. To explore\nhuman-like learning dynamics, we construct learners with psychologically\ngrounded profiles-such as Deep, Surface, and Lazy-as well as a persona-free\nGeneral Learner to inspect the base LLM's default behavior. Through weekly\nknowledge acquisition, monthly strategic choices, periodic tests, and peer\ninteraction, we can track the dynamic learning progress of individual learners\nover a full-year journey. Our findings are fourfold: 1) Longitudinal analysis\nreveals that only Deep Learner achieves sustained cognitive growth. Our\nspecially designed \"trap questions\" effectively diagnose Surface Learner's\nshallow knowledge. 2) The behavioral and cognitive patterns of distinct\nlearners align closely with their psychological profiles. 3) Learners'\nself-concept scores evolve realistically, with the General Learner developing\nsurprisingly high self-efficacy despite its cognitive limitations. 4)\nCritically, the default profile of base LLM is a \"diligent but brittle Surface\nLearner\"-an agent that mimics the behaviors of a good student but lacks true,\ngeneralizable understanding. Extensive simulation experiments demonstrate that\nLearnerAgent aligns well with real scenarios, yielding more insightful findings\nabout LLMs' behavior.", "AI": {"tldr": "LearnerAgent\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u6a21\u62df\u771f\u5b9e\u6559\u5b66\u73af\u5883\uff0c\u5206\u6790\u4e0d\u540c\u5fc3\u7406\u7279\u5f81\u5b66\u4e60\u8005\u7684\u52a8\u6001\u5b66\u4e60\u884c\u4e3a\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u5b66\u4e60\u52a8\u6001\u6216\u63d0\u4f9b\u89e3\u91ca\u6027\uff0c\u56e0\u6b64\u5f15\u5165LearnerAgent\u4ee5\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u6784\u5efa\u5177\u6709\u5fc3\u7406\u7279\u5f81\u7684\u5b66\u4e60\u8005\uff08\u5982Deep\u3001Surface\u3001Lazy\uff09\u548c\u901a\u7528\u5b66\u4e60\u8005\uff0c\u901a\u8fc7\u77e5\u8bc6\u83b7\u53d6\u3001\u6d4b\u8bd5\u548c\u4e92\u52a8\u8ddf\u8e2a\u5b66\u4e60\u8fdb\u5c55\u3002", "result": "1\uff09Deep Learner\u6301\u7eed\u8ba4\u77e5\u589e\u957f\uff1b2\uff09\u5b66\u4e60\u8005\u884c\u4e3a\u4e0e\u5fc3\u7406\u7279\u5f81\u4e00\u81f4\uff1b3\uff09\u901a\u7528\u5b66\u4e60\u8005\u81ea\u6211\u6548\u80fd\u9ad8\uff1b4\uff09\u57fa\u7840LLM\u9ed8\u8ba4\u884c\u4e3a\u4e3a\u201c\u52e4\u594b\u4f46\u8106\u5f31\u7684Surface Learner\u201d\u3002", "conclusion": "LearnerAgent\u80fd\u6709\u6548\u6a21\u62df\u771f\u5b9e\u573a\u666f\uff0c\u63ed\u793aLLM\u884c\u4e3a\u7684\u6df1\u5c42\u7279\u5f81\u3002"}}
{"id": "2506.16440", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.16440", "abs": "https://arxiv.org/abs/2506.16440", "authors": ["Ebube Alor", "SayedHassan Khatoonabadi", "Emad Shihab"], "title": "Evaluating the Use of LLMs for Documentation to Code Traceability", "comment": null, "summary": "Large Language Models (LLMs) offer new potential for automating\ndocumentation-to-code traceability, yet their capabilities remain\nunderexplored. We present a comprehensive evaluation of LLMs (Claude 3.5\nSonnet, GPT-4o, and o3-mini) in establishing trace links between various\nsoftware documentation (including API references and user guides) and source\ncode. We create two novel datasets from two open-source projects (Unity Catalog\nand Crawl4AI). Through systematic experiments, we assess three key\ncapabilities: (1) trace link identification accuracy, (2) relationship\nexplanation quality, and (3) multi-step chain reconstruction. Results show that\nthe best-performing LLM achieves F1-scores of 79.4% and 80.4% across the two\ndatasets, substantially outperforming our baselines (TF-IDF, BM25, and\nCodeBERT). While fully correct relationship explanations range from 42.9% to\n71.1%, partial accuracy exceeds 97%, indicating that fundamental connections\nare rarely missed. For multi-step chains, LLMs maintain high endpoint accuracy\nbut vary in capturing precise intermediate links. Error analysis reveals that\nmany false positives stem from naming-based assumptions, phantom links, or\novergeneralization of architectural patterns. We demonstrate that task-framing,\nsuch as a one-to-many matching strategy, is critical for performance. These\nfindings position LLMs as powerful assistants for trace discovery, but their\nlimitations could necessitate human-in-the-loop tool design and highlight\nspecific error patterns for future research.", "AI": {"tldr": "\u8bba\u6587\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6587\u6863\u4e0e\u4ee3\u7801\u95f4\u5efa\u7acb\u8ffd\u6eaf\u94fe\u63a5\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5176\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4f46\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u7ed3\u5408\u4eba\u5de5\u8bbe\u8ba1\u5de5\u5177\u3002", "motivation": "\u63a2\u7d22LLMs\u5728\u81ea\u52a8\u5316\u6587\u6863\u4e0e\u4ee3\u7801\u8ffd\u6eaf\u4e2d\u7684\u6f5c\u529b\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u4f7f\u7528Claude 3.5 Sonnet\u3001GPT-4o\u548co3-mini\u7b49LLMs\uff0c\u901a\u8fc7\u7cfb\u7edf\u6027\u5b9e\u9a8c\u8bc4\u4f30\u5176\u5728\u8ffd\u6eaf\u94fe\u63a5\u8bc6\u522b\u3001\u5173\u7cfb\u89e3\u91ca\u548c\u591a\u6b65\u94fe\u91cd\u5efa\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u6700\u4f73LLM\u7684F1\u5206\u6570\u8fbe79.4%\u548c80.4%\uff0c\u5173\u7cfb\u89e3\u91ca\u5b8c\u5168\u6b63\u786e\u7387\u4e3a42.9%-71.1%\uff0c\u591a\u6b65\u94fe\u91cd\u5efa\u4e2d\u7aef\u70b9\u51c6\u786e\u7387\u9ad8\u3002", "conclusion": "LLMs\u662f\u5f3a\u5927\u7684\u8ffd\u6eaf\u53d1\u73b0\u52a9\u624b\uff0c\u4f46\u9700\u7ed3\u5408\u4eba\u5de5\u8bbe\u8ba1\u5de5\u5177\uff0c\u5e76\u9488\u5bf9\u7279\u5b9a\u9519\u8bef\u6a21\u5f0f\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2507.10818", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10818", "abs": "https://arxiv.org/abs/2507.10818", "authors": ["Jasmine Latendresse", "SayedHassan Khatoonabadi", "Emad Shihab"], "title": "How Robust are LLM-Generated Library Imports? An Empirical Study using Stack Overflow", "comment": null, "summary": "Software libraries are central to the functionality, security, and\nmaintainability of modern code. As developers increasingly turn to Large\nLanguage Models (LLMs) to assist with programming tasks, understanding how\nthese models recommend libraries is essential. In this paper, we conduct an\nempirical study of six state-of-the-art LLMs, both proprietary and open-source,\nby prompting them to solve real-world Python problems sourced from Stack\nOverflow. We analyze the types of libraries they import, the characteristics of\nthose libraries, and the extent to which the recommendations are usable out of\nthe box. Our results show that LLMs predominantly favour third-party libraries\nover standard ones, and often recommend mature, popular, and permissively\nlicensed dependencies. However, we also identify gaps in usability: 4.6% of the\nlibraries could not be resolved automatically due to structural mismatches\nbetween import names and installable packages, and only two models (out of six)\nprovided installation guidance. While the generated code is technically valid,\nthe lack of contextual support places the burden of manually resolving\ndependencies on the user. Our findings offer actionable insights for both\ndevelopers and researchers, and highlight opportunities to improve the\nreliability and usability of LLM-generated code in the context of software\ndependencies.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u516d\u79cd\u5148\u8fdbLLM\u5728\u89e3\u51b3Python\u95ee\u9898\u65f6\u63a8\u8350\u7684\u5e93\uff0c\u53d1\u73b0\u5b83\u4eec\u504f\u597d\u7b2c\u4e09\u65b9\u5e93\uff0c\u4f46\u5b58\u5728\u53ef\u7528\u6027\u5dee\u8ddd\u3002", "motivation": "\u7406\u89e3LLM\u5982\u4f55\u63a8\u8350\u5e93\u5bf9\u4ee3\u7801\u529f\u80fd\u3001\u5b89\u5168\u548c\u7ef4\u62a4\u81f3\u5173\u91cd\u8981\u3002", "method": "\u901a\u8fc7Stack Overflow\u7684\u771f\u5b9ePython\u95ee\u9898\u6d4b\u8bd5\u516d\u79cdLLM\uff0c\u5206\u6790\u5176\u63a8\u8350\u7684\u5e93\u7c7b\u578b\u548c\u7279\u6027\u3002", "result": "LLM\u4e3b\u8981\u63a8\u8350\u6210\u719f\u3001\u6d41\u884c\u7684\u7b2c\u4e09\u65b9\u5e93\uff0c\u4f464.6%\u7684\u5e93\u56e0\u547d\u540d\u95ee\u9898\u65e0\u6cd5\u81ea\u52a8\u89e3\u6790\uff0c\u4ec5\u4e24\u79cd\u6a21\u578b\u63d0\u4f9b\u5b89\u88c5\u6307\u5bfc\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5f00\u53d1\u8005\u548c\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u6539\u8fdbLLM\u751f\u6210\u4ee3\u7801\u53ef\u9760\u6027\u548c\u53ef\u7528\u6027\u7684\u65b9\u5411\u3002"}}
