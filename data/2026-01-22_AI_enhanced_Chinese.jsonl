{"id": "2601.11659", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11659", "abs": "https://arxiv.org/abs/2601.11659", "authors": ["Aaron Adcock", "Aayushi Srivastava", "Abhimanyu Dubey", "Abhinav Jauhri", "Abhinav Pande", "Abhinav Pandey", "Abhinav Sharma", "Abhishek Kadian", "Abhishek Kumawat", "Adam Kelsey", "Adam Stelle", "Adeel Cheema", "Adela Kabiljo", "Adina Katz", "Adithya Gangidi", "Aditya Tayade", "Adolfo Victoria", "Adrian Samatan Alastuey", "Adrien Conrath", "Afroz Mohiuddin", "Ahmed Sharif", "Ahnaf Siddiqui", "Ahuva Goldstand", "Aijung Li", "Aidan Boyd", "Aidin Kazemi Daliri", "Aisha Iqbal", "Ajay Menon", "Ajit Mathews", "Akhil Mathur", "Akshat Agarwal", "Alan Schelten", "Alana Shine", "Alejandro Castillejo Mu\u00f1oz", "Aleksei Guliaev", "Alex Radovic", "Alex Song", "Alex Vaughan", "Alexander Simeonov", "Alexandre Rezende", "Alexandre Rezende", "Alexei Baevski", "Alexey Roubaud", "Allen Ma", "Alvin Lee", "Alyssa Pereira", "Aman Ahmed", "Aman Shankar", "Amanda Kallet", "Amar Budhiraja", "Ameya Khandekar", "Amine Benhalloum", "Amir Gershman", "Amit Nagpal", "Amit Zohar", "Amr Sharaf", "Anant Desai", "Anastasia Razdaibiedina", "Anca Agape", "Andranik Kurghinyan", "Andre Perunicic", "Andrea Madotto", "Andrei Darabanov", "Andr\u00e9s Alvarado", "Andrew Brown", "Andrew Cohen", "Andrew Fang", "Andrew Freeman", "Andrew Gallagher", "Andrew Gu", "Andrew Prasetyo Jo", "Andrew Ryan", "Andrew Steffen", "Andrew Wei", "Andrey Rusakov", "Andrii Golovei", "Andy Shang", "Angela Fan", "Angela Fan", "Angela Flewellen", "Animesh Pathak", "Anirudh Goyal", "Ankit Ramchandani", "Ankur Pai", "Ankur Singh", "Ankush Garg", "Anlu Xing", "Anna Cai", "Anna Grosul", "Anna Prochowska", "Anna Sun", "Annie Dong", "Annie Franco", "Anqi Hu", "Anshul Chawla", "Anthony Hartshorn", "Antonia Sheng", "Antony Thomas", "Anuj Goyal", "Anusha De", "Anvit Bodiwala", "Anvit Bodiwala", "Aobo Yang", "Aparajita Saraf", "Apurva Samudra", "Aran Mun", "Arash Rahnama", "Archi Mitra", "Archie Sravankumar", "Archit Gupta", "Aria Haghighi", "Ariel Stolerman", "Arkabandhu Chowdhury", "Arnab Choudhury", "Artem Korenev", "Arthur Guo", "Arthur Hinsvark", "Arun Mallya", "Arvind Neelakantan", "Arya Talebzadeh", "Ashish Shah", "Ashmitha Jeevaraj Shetty", "Ashwin Bharambe", "Asif Islam", "Aston Zhang", "Austen Gregerson", "Avi Lewis", "Aya Ibrahim", "Ayaz Minhas", "Ayelet Dahan", "Ayelet Regev Dabah", "Bangsheng Tang", "Bar Ulman", "Bardiya Sadeghi", "Bartosz Jedrzejewski", "Barys Skarabahaty", "Beibei Zhu", "Beibin Li", "Ben Bharier", "Benjamin Leonhardi", "Benjamin Muller", "Bennett Plessala", "Bernie Huang", "Beth Loyd", "Bhargavi Paranjape", "Bhavik Sheth", "Bill Bonner", "Bill Holland", "Bill Wang", "Bingzhe Liu", "Binh Tang", "Bo Liu", "Bo Wu", "Boduo Li", "Bokai Yu", "Bor-Chun Chen", "Boris Araya", "Boris Vidolov", "Botao Chen", "Boya Peng", "Boyu Ni", "Bradley Davis", "Bram Wasti", "Brandon Adams", "Brandon Taylor", "Brandon Wu", "Brant Swidler", "Brian Chiang", "Brian Clerkin", "Brian Fuller", "Brooks Cutter", "Bruno Novais", "Bryan Gmyrek", "Bysshe Easton", "Cait Campos", "Canaan Case", "Carl Chengyan Fu", "Carly Burton", "Caro Diaz", "Catherine Cole", "Ce Liu", "Cedric Fougerat", "Cen Peng", "Cen Peng", "Cen Zhao", "Changhan Wang", "Changkyu Kim", "Chantal Shaib", "Chao Zhou", "Charlotte Caucheteux", "Chau Nguyen", "Chawin Sitawarin", "Chaya Nayak", "Chelsea Asher", "Chen Fan", "Chen Zhu", "Cheng Cheng", "Cheng Zhang", "Chenguang Zhu", "Chengxiong Ruan", "Chengzhu Yu", "Chenheli Hua", "Chenxi Whitehouse", "Cheryl Holloway", "Ching-Hsiang Chu", "Ching-Yao Chuang", "Chinmay Karande", "Chirag Nagpal", "Chlo\u00e9 Bakalar", "Chloe Bi", "Chris Cai", "Chris Marra", "Chris McConnell", "Chris Thi", "Chris Tindal", "Chris Waterson", "Christian Deverall", "Christian Fuegen", "Christian Keller", "Christine Cheng", "Christine Jou", "Christine Smith", "Christine Wang", "Christoph Feichtenhofer", "Christophe Touret", "Christopher Luc", "Christy Sauper", "Chuanhao Zhuge", "Chun-Yi Sung", "Chunqiang Tang", "Chunyang Wu", "Clara Siegel", "Cody Heale", "Cody Wilbourn", "Colin White", "Congying Xia", "Corinne Wong", "Cornel Rat", "Cristian Canton Ferrer", "Cyrille Habis", "Cyrus Nikolaidis", "D Lohachov", "Da Ju", "Dalton Flanagan", "Damien Allonsius", "Damon Civin", "Dan Johnson", "Daniel Bolya", "Daniel Francisco", "Daniel Fried", "Daniel Hawthorne", "Daniel Haziza", "Daniel Ho", "Daniel Kreymer", "Daniel Li", "Daniel Machlab", "Daniel McKinnon", "Daniel Obenshain", "Daniel Rodriguez", "Daniel Song", "Daniel Tse", "Danielle Pintz", "Danny Livshits", "Daryl James Rodrigo", "Dat Huynh", "Daulet Askarov", "David Brandfonbrener", "David Esiobu", "David Kant", "David Levin", "David Renardy", "David Soofian", "David Stevens", "David Xu", "David Zhang", "Deep Shah", "Delia David", "Demi Douglas", "Denis Boyda", "Desh Raj", "Devamanyu Hazarika", "Dheeraj Mekala", "Dhruv Choudhary", "Dhruv Mahajan", "Di Jin", "Didac Suris Coll-Vinent", "Didem Foss", "Diego Garcia-Olano", "Diego Perino", "Dieuwke Hupkes", "DiJia Su", "Dilip Madathil", "Dinesh Govindasamy", "Dinesh Yeduguru", "Dmitry Vengertsev", "Dong He", "Dong Li", "Dong Wang", "Dongzhuo Li", "Duc Le", "Dunant Hin", "Dustin Holland", "Duy Nguyen", "Duy Nguyen", "Ed Dowling", "Eden Litt", "Egor Lakomkin", "Ehab AlBadawy", "Ehsan K. Ardestani", "Elad Eckstein", "Elahe Dabir", "Elaine Montgomery", "Elina Lobanova", "Elior Abramoviz", "Eliot Hedeman", "Elissa Li", "Elizabeth Hilbert", "Ellen Xiaoqing Tan", "Elliot Yun", "Elodie Stener", "Emilian Stoimenov", "Emilien Garreau", "Emily Dinan", "Emily Hahn", "Emily Wood", "Emma Li", "Emmanuel Ademuwagun", "Emrah Seker", "Eric Alamillo", "Eric Gan", "Eric Han", "Eric Huang", "Eric Michael Smith", "Eric-Tuan Le", "Ernie Chang", "Eryk Helenowski", "Eslam Elnikety", "Esteban Arcaute", "Ethan Myers", "Eugene Nho", "Eugene Poliukhovych", "Evan Dunbar", "Evgeniy Litvinenko", "Evrim Alt\u0131nta\u015f", "Eyal Hochman", "Eyal Shtrauch", "Fabian Mastenbroek", "Faiza Zeb", "Faizan Ahmad", "Farhad Farahbakhshian", "Fei Kou", "Fei Sun", "Feiyu Chen", "Felix Chung", "Feng Tian", "Feng Xu", "Filip Radenovic", "Filippos Kokkinos", "Francesco Barbieri", "Francesco Caggioni", "Francisco Esparza", "Francisco Guzm\u00e1n", "Frank Kanayet", "Frank Seide", "Frank Zhang", "Fred Lewis", "Freda Huang", "Fulton Wang", "Gabriel Synnaeve", "Gabriela Jacques-Silva", "Gabriella Schwarz", "Gaganjit Ghardhora", "Gal Elfer", "Garrett Dickson", "Gaurav Chaurasia", "Gautam Sewani", "Geet Shingi", "Gefei Zuo", "Geonhwa Jeong", "George Puthanpurackal", "Georgia Swee", "Gerard Moreno-Torres Bertran", "Gil Keren", "Gina Ling", "Gjergji Stasa", "Gobinda Saha", "Gor Safran", "Gordy French", "Goutham Rajendran", "Govind Thattai", "Grace Cineas", "Graeme Nail", "Greg Fletcher", "Gr\u00e9goire Mialon", "Griffin Adams", "Grigory Sizov", "Guan Pang", "Hady Elsahar", "Hai Dang Tran", "Hailey Nguyen", "Haiping Wu", "Hakan Inan", "Hamid Eghbalzadeh", "Han Fang", "Han Zou", "Hannah Doyle", "Hannah Korevaar", "Hannah Wang", "Hannah Werbel", "Hanwen Zha", "Hany Morsy", "Hao Ma", "Haoci Zhang", "Haonan Sun", "Haozhu Wang", "Hardik Shah", "Haroun Habeeb", "Harrison Rudolph", "Harsh Gupta", "Harsh Poddar", "Harshil Parikh", "Hejia Zhang", "Heming Wang", "Hengduo Li", "Himanshu Sharma", "Hoang Phi Nguyen", "Hongbo Zhang", "Honghao Qiu", "Hongjiang Lv", "Hongli Xu", "Hongyuan Zhan", "Hossein Hamooni", "Howard Huang", "Hu Xu", "Hugo Lauren\u00e7on", "Hugo Touvron", "Hung Dinh", "Hunter Goldman", "Hussein Mehanna", "Huy Nguyen", "Hweimi Tsuo", "Ian Graves", "Ian Yu", "Ibrahim Damlaj", "Idan Cohen", "Igor Tufanov", "Ilan Goldenstein", "Ilias Leontiadis", "Iliyan Zarov", "Imad Ahmed", "Innocent Djiofack", "Iosif Spulber", "Irina-Elena Veliche", "Isabella Ramos", "Ishan Misra", "Itai Gal", "Ivan Evtimov", "Ivan Evtimov", "Ivan Obraztsov", "Jack Wu", "Jacqueline Romero Vertino", "Jaemo Koo", "Jaewon Lee", "Jake Jung", "Jake Weissman", "James Beldock", "James Crnkovich", "James Grinage", "James Hongyi Zeng", "James Kohli", "James Tian", "Jamie Cahill", "Jan Geffert", "Jan Seidel", "Jan Seidel", "Janey Tracey", "Jang Hyun Cho", "Janice Wei", "Jarrod Kahn", "Jasmyn Howell", "Jason Long Vu", "Jason Park", "Jason Yan", "Jason Yip", "Jay Li", "Jay Mahadeokar", "Jaya Bharath R Goluguri", "Jayasi Mehar", "Jean-Baptiste Gaya", "Jeet Shah", "Jeff Hanson", "Jeff Marcus", "Jeff Walsh", "Jeff Yang", "Jelmer van der Linde", "Jemma Fan", "Jennifer Chan", "Jenny Zhen", "Jenya Lee", "Jeremy Fu", "Jeremy Reizenstein", "Jeremy Teboul", "Jesse He", "Jessica Zhong", "Ji Hou", "Ji Yang", "Jia Ding", "Jiabo Hu", "Jiacheng Zhu", "Jiadong Guo", "Jialiang Wang", "Jialin Ouyang", "Jianfeng Chi", "Jianyu Huang", "Jianyun Zhao", "Jiaowen Yang", "Jiatong Zhou", "Jiawei Zhao", "Jiawen Liu", "Jie Wang", "Jie You", "Jiecao Yu", "Jillian Schwiep", "Jilong Wu", "Jing Huang", "Jing Li", "Jing Yu Koh", "Jing Zhang", "Jingxiang Chen", "Jingyi Yang", "Jingyue Shen", "Jinho Hwang", "Jinxi Guo", "Jiwan Khatiwada", "Joanna Bitton", "Joe Li", "Joe Quanaim", "Joel Beales", "Johan Schuijt", "John Chang", "John Quan", "Johnnie Chan", "Jon Shepard", "Jona Harris", "Jonah Rubin", "Jonathan Janzen", "Jonathan Kaldor", "Jorge Lopez Silva", "Jose Leitao", "Joseph Greer", "Joseph Moon", "Joseph Rocca", "Joseph Tighe", "Josh Fromm", "Joshua Deng", "Joshua Fernandes", "Joshua Saxe", "Joyce Zheng", "Juan Pino", "Julien Prigent", "Jun Chen", "Junjiao Tian", "Junjie Qi", "Junjie Wang", "Junteng Jia", "Kade Baker", "Kai Londenberg", "Kai Wang", "Kainan Peng", "Kaiyan Peng", "Kaiyue Yang", "Kalyan Vasudev Alwala", "Kam Hou Yu", "Kanika Narang", "Karan Chadha", "Karan Sikka", "Karen Zhang", "Karina Schuberts", "Karishma Mandyam", "Karthik Abinav Sankararaman", "Karthik Padthe", "Karthik Prasad", "Karthik Sivakumar", "Kartikeya Upasani", "Kate Plawiak", "Kate Saenko", "Kate\u0159ina \u017dmol\u00edkov\u00e1", "Kathryn Stadler", "Kathy Matosich", "Katie Doulgass", "Kaveh Hassani", "Kay Ji", "Ke Li", "Kenneth Heafield", "Kenny Yu", "Keqian Li", "Kevin Chih-Yao Ma", "Kevin Hannan", "Keyu Man", "Kezhen Chen", "Khalid El-Arini", "Khrystyna Hutsulyak", "Kieran Nash", "Kiran Jagadeesh", "Kody Bartelt", "Konstantin Topaloglou-Mundy", "Konstantinos Chatziioannou", "Konstantinos Karanasos", "Konstantinos Vougioukas", "Kostas Tsiampouris", "Kristen Hamill", "Kristy Choi", "Krithika Iyer", "Kshitiz Malik", "Kuenley Chiu", "Kun Huang", "Kunal Bhalla", "Kunal Chawla", "Kunpeng Li", "Kushal Lakhotia", "Kyle Monk", "Lakshya Garg", "Lalit Chourey", "Lars Hamre", "Laura Gustafson", "Lauren Deason", "Laurence Rouesnel", "Laurens van der Maaten", "Lavender A", "Lawrence Chen", "Lawrence Jang", "Leandro Silva", "Leda Sari", "Lee Hetherington", "Lei Zhang", "Leiyu Zhao", "Lele Chen", "Leo Chenghui Li", "Leon Yang", "Leon Zhan", "Levi Corallo", "Liang Tan", "Licheng Yu", "Lijuan Liu", "Lilach Mor", "Lincoln Lin", "Linfeng Li", "Lisa Titus", "Liz Jenkins", "Lovish Madaan", "Lu Fang", "Lu Yuan", "Lucas Nava", "Lucas Pasqualin", "Lucas Switzer", "Lucia Fang", "Lucy Sun", "Luka Tadic", "Lukas Blecher", "Lukas Landzaat", "Luxin Zhang", "Madhavi Rao", "Madian Khabsa", "Mahalia Miller", "Mahendra Kariya", "Mahesh Pasupuleti", "Mahi Luthra", "Manaal Faruqui", "Manav Avlani", "Manchen Wang", "Mannat Singh", "Manohar Paluri", "Manoj Chakkaravarthy", "Manoj Nair", "Maquelle Tiffany", "Marcin Pawlowski", "Marcus Wu", "Maria Lomeli", "Mario Consuegra", "Marion Boiteux", "Marios Andreas Galanis", "Marshall Chen", "Martin Gleize", "Maryam Fazel-Zarandi", "Matan Hasson", "Mathew Oldham", "Mathieu Rita", "Matt Dordal", "Matt Setzler", "Matt Staats", "Matt Staats", "Matt Wilde", "Matthew Clark", "Matthew Grange", "Matthew Lennie", "Matthew Schmohl", "Max Raphael", "Maxim Naumov", "Maxim Samoylov", "Maxime Lecanu", "Maya Pavlova", "Md Taha Bin Jawaid", "Meghan Keneally", "Melanie Kambadur", "Meng Zhang", "Mengchen Liu", "Mengdi Lin", "Mengjiao Wang", "Mervyn Abraham", "Miao Liu", "Michael Au-Yeung", "Michael Feldergraf", "Michael Man", "Michael Matheny", "Michael Suo", "Michael Tontchev", "Michel Meyer", "Michelle Ma", "Mihir Patel", "Mihir Sanjay Kale", "Mik Vyatskov", "Mikayla Alexander", "Mike Andersland", "Mike Clark", "Mike Lewis", "Mike Li", "Mike Macey", "Mike Macey", "Mike Seltzer", "Mikel Jimenez Fernandez", "Mikhail Antonov", "Mikhail Plekhanov", "Milan Zhou", "Min Si", "Ming Qiao", "Mingbo Ma", "Mingjun Zhang", "Mingyi Liang", "Miquel Jubert Hermoso", "Mirac Suzgun", "Mirjam Skarica", "Mitesh Kumar Singh", "Mohammad Kabbani", "Mohammad Rastegari", "Mona Sarantakos", "Monica Sim", "Monika Gangapuram", "Mor Moshe", "Morrie Doulaty", "Morvarid Metanat", "Moya Chen", "Mrinal Kumar", "Munish Bansal", "Murali Ramarao", "Na Li", "Nadav Azaria", "Nahiyan Malik", "Naman Goyal", "Nancy Vargas Balderas", "Nanshu Wang", "Naoyuki Kanda", "Natalia Gimelshein", "Natalia Neverova", "Nathan Aclander", "Natt Sithiviraporn", "Navneet Madhu Kumar", "Ned Newton", "Neeraj Bahl", "Negar Ghorbani", "Neil Patel", "Neta-lee Golan", "Nicholas Longenbaugh", "Nick Egebo", "Nikhil Johri", "Nikhil Mehta", "Nikhil Naik", "Niko Moritz", "Nikolay Bashlykov", "Nikolay Bogoychev", "Nikolay Pavlovich Laptev", "Niladri Chatterji", "Nile Jones", "Nimish Shah", "Ning Dong", "Ning Li", "Ning Li", "Ning Zhang", "Nishant Yadav", "Noam Paz", "Norman Cheng", "Norman Cheng", "Olaoluwa Adesanya", "Oleg Repin", "Oleksandr Maksymets", "Omkar Salpekar", "Omri Harosh", "Onkar Pednekar", "Onur \u00c7elebi", "Oran Gafni", "Oren Edinger", "Osama Hanna", "Owais Khan Mohammed", "Ozlem Kalinli", "Paden Tomasello", "Pankaj Singh", "Paola Quevedo", "Parag Jain", "Paria Rashidinejad", "Parker Tooley", "Parth Parekh", "Parth Thakkar", "Parvin Taheri", "Pasan Hapuarachchi", "Pascal Kesseli", "Patrick Alrassy", "Paulo de Rezende Pinatti", "Pavan Balaji", "Pawan Sisodiya", "Pedro Jose Ferreira Moreira", "Pedro Rittner", "Pedro Valenzuela", "Peize Sun", "Peizhao Zhang", "Peng-Jen Chen", "Pengchao Wang", "Pengchuan Zhang", "Pengwei Li", "Petar Vasic", "Peter Carras", "Peter Ney", "Peter Weng", "Petru Dumea", "Phil Hayes", "Philip Woods", "Pierre Andrews", "Pierre M\u00e9nard", "Ping-Hao Wu", "Pingchuan Liu", "Piotr Dollar", "Plamen Dzhelepov", "Polina Zvyagina", "Posten A", "Prabhav Agrawal", "Pradhapan Rajendran", "Pradyot Prakash", "Prajjwal Bhargava", "Pramono", "Pranay Shah", "Pranshu Dave", "Prash Jain", "Pratik Dubal", "Praveen Gollakota", "Praveen Krishnan", "Pritish Yuvraj", "Projjal Ghosh", "Punit Singh Koura", "Puxin Xu", "Qi Qi", "Qi Zhou", "Qian Guan", "Qian Sun", "Qiang Liu", "Qing He", "Qinqing Zheng", "Qirui Yang", "Qizhen Guo", "Quanzeng You", "Quentin Carbonneaux", "Quentin Carbonneaux", "Quentin Duval", "Quintin Fettes", "Rachad Alao", "Rachel Batish", "Rachel Guo", "Rachel Rodriguez", "Radhika Bhargava", "Rafael Asuncion", "Raghotham Murthy", "Rahul Dutta", "Rahul Jha", "Rahul Kindi", "Rahul Mitra", "Raj Ganapathy", "Raj Shah", "Rajarshi Das", "Rajat Shrivastava", "Rajesh Nishtala", "Ramakant Shankar", "Raman Shukhau", "Ramon Calderer", "Rangaprabhu Parthasarathy", "Ranjan Subramanian", "Raphael Bensadoun", "Rares Bostan", "Rashnil Chaturvedi", "Ravi Agrawal", "Ray Gao", "Raymond Li", "Rebecca Kogen", "Ricardo Juan Palma Duran", "Ricardo Silveira Cabral", "Richard Lee", "Richard Yuanzhe Pang", "Riddhish Bhalodia", "Riham Mansour", "Rishabh Singh", "Rishi Godugu", "Ritun Patney", "Rob Boyle", "Robbie Goldfarb", "Robert Caldwell", "Robert Kuo", "Roberta Raileanu", "Robin Battey", "Robin Sharma", "Rochit Sapra", "Rocky Wang", "Rodolfo Granata", "Rodrigo De Castro", "Rodrigo Paim", "Rohan Maheshwari", "Rohan Varma", "Rohit Girdhar", "Rohit Patel", "Roshan Sumbaly", "Roy Sheaffer", "Ruan Silva", "Ruben Rodriguez Buchillon", "Rui Hou", "Ruiming Xie", "Ruslan Mavlyutov", "Ruslan Semenov", "Rustam Dinov", "Ruxiao Bao", "Ryan Fox", "Ryan Kilpatrick", "Ryan Kwan", "Ryan Lim", "Ryan Smith", "Saaketh Narayan", "Sabrina Qiao", "Sachin Mehta", "Sachin Siby", "Sagar Jain", "Saghar Hosseini", "Sagie Gur-Ari", "Sahana Chennabasappa", "Sahin Geyik", "Sai Jayesh Bondu", "Sai Mounika Chowdhary Nekkalapudi", "Saif Hasan", "Saisuke Okabayashi", "Saketh Rambhatla", "Salil Sawhney", "Sam Dunster", "Sam Zhao", "Saman Keon", "Samaneh Azadi", "Sameet Sapra", "Samuel Dooley", "Samyak Datta", "Sandeep Parab", "Sang Michael Xie", "Sanjay Singh", "Sanyuan Chen", "Sara Behn", "Sara Khodeir", "Sarah Shirazyan", "Sargun Dhillon", "Sarunya Pumma", "Sasha Sidorov", "Saskia Adaime", "Saurabh Khanna", "Sayem Wani", "Scott Brenton", "Sean Bell", "Sean Kelly", "Sean Koger", "Sean Nunley", "Sean Perry", "Sebastian Caicedo", "Sebastian Dahlgren", "Sebastian Ruder", "Seiji Yamamoto", "Selam Mehretu", "Selvan Sunitha Ravi", "Sen Lyu", "Senthil Chellapan", "Serafeim Mellos", "Sergey Edunov", "Sergey Royt", "Shaina Cohen", "Shangfu Peng", "Shannon Adams", "Shaoliang Nie", "Sharadh Ramaswamy", "Sharan Narang", "Shashank Pisupati", "Shashi Gandham", "Shaun Lim", "Shaun Lindsay", "Sheena Artrip", "Shelly Sheynin", "Shen Yan", "Sheng Feng", "Sheng Shen", "Shengbao Zheng", "Shenghao Lin", "Shengjie Bi", "Shengxin Cindy Zha", "Shengye Wan", "Shengyi Qian", "Shengyong Cai", "Shengzhi Shao", "Shervin Shahidi", "Shikai Li", "Shimon Bernholtz", "Shiqi Wang", "Shishir G. Patil", "Shiv Verma", "Shiva Shankar P", "Shiyang Chen", "Sho Yaida", "Shoubhik Debnath", "Shreyas Siravara", "Shruti Bhosale", "Shuang Ma", "Shun Zhang", "Shuo Tang", "Shuqiang Zhang", "Shuyan Zhou", "Sicong Che", "Sidd Srinivisan", "Siddharth Bhattacharya", "Siddharth Patki", "Sijia Chen", "Sili Chen", "Simon Vandenhende", "Simone Merello", "Sinong Wang", "Sivan Barzily", "Sixian Yi", "Siyu Lin", "SK Bong", "Sky Yin", "Sneha Agarwal", "Sneha Agarwal", "Soerian Lieve", "Soji Sajuyigbe", "Song Jiang", "Songlin Li", "Sonia Kim", "Sopan Khosla", "Soumi Maiti", "Spencer Whitman", "Sravya Popuri", "Sreen Tallam", "Srinivas Vaidyanathan", "Srinivas Vaidyanathan", "Sten Sootla", "Stephane Collot", "Stephanie Ding", "Stephen Chen", "Steven Cai", "Suchin Gururangan", "Sudarshan Govindaprasad", "Sue Young", "Suganthi Dewakar", "Sujan Kumar Gonugondla", "Sujeet Bhandari", "Suman Gumudavelli", "Suman Gumudavelli", "Sumit Gupta", "Summer Deng", "Sungmin Cho", "Suresh Ganapathy", "Surjyendu Dhal", "Susan Fedynak", "Susana Contrera", "Suyoun Kim", "Sylvestre Rebuffi", "Takshak Chahande", "Tamar Herman", "Tan Li", "Tao Xu", "Tara Fowler", "Tarek Sheasha", "Tarun Anand", "Tarun Kalluri", "Tarun Singh", "Tatiana Shavrina", "Ted Li", "Teja Rao", "Tejas Patil", "Teng Li", "Thach Bui", "Thai Quach", "Thamer Alharbash", "Thanh Vinh Vo", "Thawan Kooburat", "Thilo Koehler", "Thomas Georgiou", "Thomas Scialom", "Tian Ye", "Tianhe Li", "Tianjun Zhang", "Tianyu Li", "Tijmen Blankevoort", "Timon Willi", "Timothy Chou", "Timothy Leung", "TJ Lee", "Todor Mihaylov", "Tom Heatwole", "Tong Xiao", "Tony Cao", "Tony Lee", "Trang Le", "Tristan Rice", "Tsz Kei Serena Chan", "Tuan Tran", "Tudor Tiplea", "Tyler Baumgartner", "Uday Savagaonkar", "Ujjwal Karn", "Ulises Martinez Araiza", "Umar Farooq", "Uriel Cohen", "Usman Sharif", "Utkarsh Murarka", "Van Phung", "Varun Joginpalli", "Varun Saravagi", "Vasu Sharma", "Vasudha Viswamurthy", "Vedanuj Goswami", "Vedika Seth", "Venkat Ramesh", "Venkat Ramesh", "Vibhor Gupta", "Victoria Montanez", "Vidhya Natarajan", "Vidya Sarma", "Vignesh Ramanathan", "Viktor Kerkez", "Vinay Rao", "Vincent Gonguet", "Vincent Mauge", "Virginie Do", "Vish Vogeti", "Vishrav Chaudhary", "Viswesh Sankaran", "V\u00edtor Albiero", "Vivek Miglani", "Vivek Pai", "Vlad Cojanu", "Vlad Shubin", "Vlad Tiberiu Mihailescu", "Vladan Petrovic", "Vladimir Ivanov", "Vladislav Vorotilov", "Vrushali Bhutada", "Wai I Ng", "Wei Cheng", "Wei Sun", "Wei Tu", "Wei Wei", "Wei Zhou", "Wei-Ning Hsu", "Weiwei Chu", "Weizhe Yuan", "Wenchen Wang", "Wenjun Zhao", "Wenwen Jiang", "Wenyin Fu", "Wenzhe Jiang", "Whitney Meers", "Will Constable", "Will Wang", "William R. Wong", "Xavier Martinet", "Xi Victoria Lin", "Xi Yan", "Xi Yin", "Xian Li", "Xianfeng Rui", "Xianjun Yang", "Xiaocheng Tang", "Xiaodong Wang", "Xiaofang Wang", "Xiaolan Wang", "Xiaoliang Dai", "Xiaoliang Peng", "Xiaopeng Li", "Xiaozhu Meng", "Xibei Zhang", "Xide Xia", "Xin Jin", "xinbo Gao", "Xinfeng Xie", "Xingyi Zhou", "Xu Ma", "Xuan Ju", "Xuanyi Zhao", "Xubo Liu", "Xuchao Jia", "Xuedong Zhang", "Xuefei Cao", "Xuewei Wang", "Xuewei Wu", "Xunnan Xu", "Xutai Ma", "Xuyang Wang", "Yan Cui", "Yang Chen", "Yang Li", "Yang Shu", "Yang Xia", "Yanjun Chen", "Yanjun Zhou", "Yash Mehta", "Yash Patel", "Yash Tekena", "Yashesh Gaur", "Yasmine Babaei", "Yaxuan Zhou", "Ye Hu", "Ye Qi", "Yejin Lee", "Yeming Wen", "Yen-Cheng Liu", "Yexin Bruce Wu", "Yi Pan", "Yi Yang", "Yi-Hui Lin", "Yifan Wang", "Yifan Wu", "Yifan Yang", "Yifei Huang", "Yiftah Ben Aharon", "Yilin Yang", "Yiling You", "Ying Xu", "Ying Zhang", "Yingquan Yuan", "Yingru Liu", "Yingyi Ma", "Yining Yang", "Yiting Lu", "Yonatan Komornik", "Yongjie Lin", "Yoni Goyhman", "Yossi Moran Mamo", "Youngjin Nam", "Yu Wang", "Yu Lu", "Yu Zhao", "Yu-Ho Hsieh", "Yu-Jung Lo", "Yuandong Tian", "Yuanhan Zhang", "Yuanhao Xiong", "Yuanshun Yao", "Yuchen Hao", "Yuchen Zhang", "Yuchuan Li", "Yue Cao", "Yue Yu", "Yue Zhao", "Yuhan Guo", "Yuhao Wang", "Yuheng Huang", "Yujie Lu", "Yujun Shi", "Yulun Wang", "Yun He", "Yun Wang", "Yundi Qian", "Yunfan Wang", "Yunhao Tang", "Yuning Mao", "Yunlu Li", "Yuqi Dai", "Yuriy Hulovatyy", "Yushi Hu", "Yuxuan Sun", "Zach Rait", "Zach Wentz", "Zacharie Delpierre Coudert", "Zachary Collins", "Zahra Hankir", "Zecheng He", "Zeeshan Ahmed", "Zeeshan Ahmed", "Zef RosnBrick", "Zhan Shu", "Zhanna Rohalska", "Zhaoduo Wen", "Zhe Liu", "Zhe Liu", "Zhen Qiao", "Zhenggang Xu", "Zhengwen Zhou", "Zhengxing Chen", "Zhenyu Tang", "Zhichen Wu", "Zhicheng Ouyang", "Zhihong Lei", "Zhipeng Hong", "Zhiping Xiu", "Zhiwei Zhao", "Zhong Meng", "Zhou Jin", "Zhouhao Zeng", "Zichang Liu", "Zihang Meng", "Zihuan Qiao", "Zinnia Zheng", "Zixi Qi", "Ziyi Luo", "Zoe Foulkes Birkhead", "Zoey Sun", "Zohar Achdut"], "title": "The Llama 4 Herd: Architecture, Training, Evaluation, and Deployment Notes", "comment": "15 pages", "summary": "This document consolidates publicly reported technical details about Metas Llama 4 model family. It summarizes (i) released variants (Scout and Maverick) and the broader herd context including the previewed Behemoth teacher model, (ii) architectural characteristics beyond a high-level MoE description covering routed/shared-expert structure, early-fusion multimodality, and long-context design elements reported for Scout (iRoPE and length generalization strategies), (iii) training disclosures spanning pre-training, mid-training for long-context extension, and post-training methodology (lightweight SFT, online RL, and lightweight DPO) as described in release materials, (iv) developer-reported benchmark results for both base and instruction-tuned checkpoints, and (v) practical deployment constraints observed across major serving environments, including provider-specific context limits and quantization packaging. The manuscript also summarizes licensing obligations relevant to redistribution and derivative naming, and reviews publicly described safeguards and evaluation practices. The goal is to provide a compact technical reference for researchers and practitioners who need precise, source-backed facts about Llama 4.", "AI": {"tldr": "\u672c\u6587\u6863\u6574\u5408\u4e86Meta Llama 4\u6a21\u578b\u7cfb\u5217\u7684\u516c\u5f00\u6280\u672f\u7ec6\u8282\uff0c\u5305\u62ec\u6a21\u578b\u53d8\u4f53\u3001\u67b6\u6784\u7279\u6027\u3001\u8bad\u7ec3\u65b9\u6cd5\u3001\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\u3001\u90e8\u7f72\u7ea6\u675f\u548c\u8bb8\u53ef\u4fe1\u606f\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u6280\u672f\u53c2\u8003\u3002", "motivation": "Meta Llama 4\u6a21\u578b\u7cfb\u5217\u4f5c\u4e3a\u91cd\u8981\u7684\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5176\u6280\u672f\u7ec6\u8282\u5206\u6563\u5728\u5404\u79cd\u516c\u5f00\u6750\u6599\u4e2d\u3002\u672c\u6587\u6863\u65e8\u5728\u7cfb\u7edf\u6574\u7406\u8fd9\u4e9b\u4fe1\u606f\uff0c\u4e3a\u7814\u7a76\u8005\u548c\u5b9e\u8df5\u8005\u63d0\u4f9b\u51c6\u786e\u3001\u57fa\u4e8e\u6765\u6e90\u7684\u6280\u672f\u53c2\u8003\uff0c\u5e2e\u52a9\u4ed6\u4eec\u7406\u89e3\u6a21\u578b\u7279\u6027\u3001\u90e8\u7f72\u7ea6\u675f\u548c\u8bb8\u53ef\u8981\u6c42\u3002", "method": "\u6587\u6863\u91c7\u7528\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u4ece\u516c\u5f00\u7684\u6280\u672f\u62a5\u544a\u3001\u53d1\u5e03\u6750\u6599\u3001\u5f00\u53d1\u8005\u6587\u6863\u7b49\u6765\u6e90\u6536\u96c6\u4fe1\u606f\uff0c\u7cfb\u7edf\u6574\u7406Llama 4\u7684\u6280\u672f\u7ec6\u8282\u3002\u5185\u5bb9\u5305\u62ec\uff1a\u6a21\u578b\u53d8\u4f53\uff08Scout\u548cMaverick\uff09\u53caBehemoth\u6559\u5e08\u6a21\u578b\uff1b\u67b6\u6784\u7279\u6027\uff08MoE\u7ed3\u6784\u3001\u8def\u7531/\u5171\u4eab\u4e13\u5bb6\u3001\u65e9\u671f\u878d\u5408\u591a\u6a21\u6001\u3001\u957f\u4e0a\u4e0b\u6587\u8bbe\u8ba1\uff09\uff1b\u8bad\u7ec3\u65b9\u6cd5\uff08\u9884\u8bad\u7ec3\u3001\u4e2d\u671f\u8bad\u7ec3\u3001\u540e\u8bad\u7ec3\uff09\uff1b\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\uff1b\u90e8\u7f72\u7ea6\u675f\uff1b\u8bb8\u53ef\u548c\u5b89\u5168\u8bc4\u4f30\u3002", "result": "\u6587\u6863\u63d0\u4f9b\u4e86Llama 4\u6a21\u578b\u7cfb\u5217\u7684\u5168\u9762\u6280\u672f\u6982\u89c8\uff1a1\uff09\u4e24\u4e2a\u4e3b\u8981\u53d8\u4f53Scout\u548cMaverick\uff0c\u4ee5\u53caBehemoth\u6559\u5e08\u6a21\u578b\uff1b2\uff09\u8be6\u7ec6\u7684MoE\u67b6\u6784\u63cf\u8ff0\uff0c\u5305\u62ec\u8def\u7531\u673a\u5236\u548c\u5171\u4eab\u4e13\u5bb6\uff1b3\uff09\u591a\u6a21\u6001\u65e9\u671f\u878d\u5408\u548c\u957f\u4e0a\u4e0b\u6587\u652f\u6301\uff08iRoPE\u548c\u957f\u5ea6\u6cdb\u5316\u7b56\u7565\uff09\uff1b4\uff09\u4e09\u9636\u6bb5\u8bad\u7ec3\u6d41\u7a0b\uff1b5\uff09\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\u6a21\u578b\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff1b6\uff09\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u4e0a\u4e0b\u6587\u9650\u5236\u548c\u91cf\u5316\u7ea6\u675f\uff1b7\uff09\u660e\u786e\u7684\u8bb8\u53ef\u8981\u6c42\u548c\u5b89\u5168\u8bc4\u4f30\u5b9e\u8df5\u3002", "conclusion": "\u672c\u6587\u6863\u6210\u529f\u6574\u5408\u4e86Meta Llama 4\u6a21\u578b\u7cfb\u5217\u7684\u516c\u5f00\u6280\u672f\u4fe1\u606f\uff0c\u4e3a\u7814\u7a76\u8005\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u53c2\u8003\u8d44\u6e90\u3002\u6587\u6863\u6db5\u76d6\u4e86\u4ece\u6a21\u578b\u67b6\u6784\u5230\u5b9e\u9645\u90e8\u7f72\u7684\u5b8c\u6574\u6280\u672f\u94fe\u6761\uff0c\u5f3a\u8c03\u4e86\u6a21\u578b\u7684\u6280\u672f\u521b\u65b0\uff08\u5982MoE\u67b6\u6784\u3001\u957f\u4e0a\u4e0b\u6587\u5904\u7406\uff09\u548c\u5b9e\u9645\u5e94\u7528\u7ea6\u675f\uff0c\u6709\u52a9\u4e8e\u793e\u533a\u66f4\u597d\u5730\u7406\u89e3\u548c\u5e94\u7528\u8fd9\u4e00\u91cd\u8981\u7684\u5f00\u6e90\u6a21\u578b\u7cfb\u5217\u3002"}}
{"id": "2601.11570", "categories": ["cs.CR", "math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.11570", "abs": "https://arxiv.org/abs/2601.11570", "authors": ["Pengcheng Xie"], "title": "Privacy-Preserving Black-Box Optimization (PBBO): Theory and the Model-Based Algorithm DFOp", "comment": "28 pages", "summary": "This paper focuses on solving unconstrained privacy-preserving black-box optimization (PBBO), its corresponding least Frobenius norm updating of quadratic models, and the differentially privacy mechanisms for PBBO. Optimization problems with transformed/encrypted objective functions aim to minimize F(x), which is encrypted/transformed/encrypted to F_k(x) as the output at the k-th iteration. A new derivative-free solver named DFOp, with its implementation, is proposed in this paper, which has a new updating formula for the quadratic model functions. The convergence of DFOp for solving problems with transformed/encrypted objective functions is given. Other analyses, including the new model updating formula and the analysis of the transformation's impact to model functions are presented. We propose two differentially private noise-adding mechanisms for privacy-preserving black-box optimization. Numerical results show that DFOp performs better than compared algorithms. To the best of our knowledge, DFOp is the first derivative-free solver that can solve black-box optimization problems with step-encryption and privacy-preserving black-box problems exactly, which also tries to answer the open question about the combination of derivative-free optimization and privacy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDFOp\u7b97\u6cd5\u89e3\u51b3\u65e0\u7ea6\u675f\u9690\u79c1\u4fdd\u62a4\u9ed1\u76d2\u4f18\u5316\u95ee\u9898\uff0c\u5305\u542b\u65b0\u7684\u4e8c\u6b21\u6a21\u578b\u66f4\u65b0\u516c\u5f0f\u3001\u6536\u655b\u6027\u5206\u6790\u548c\u5dee\u5206\u9690\u79c1\u673a\u5236\uff0c\u662f\u9996\u4e2a\u80fd\u5904\u7406\u6b65\u52a0\u5bc6\u548c\u9690\u79c1\u4fdd\u62a4\u9ed1\u76d2\u4f18\u5316\u7684\u65e0\u5bfc\u6570\u6c42\u89e3\u5668\u3002", "motivation": "\u89e3\u51b3\u65e0\u7ea6\u675f\u9690\u79c1\u4fdd\u62a4\u9ed1\u76d2\u4f18\u5316\u95ee\u9898\uff0c\u586b\u8865\u65e0\u5bfc\u6570\u4f18\u5316\u4e0e\u9690\u79c1\u4fdd\u62a4\u7ed3\u5408\u7684\u7a7a\u767d\uff0c\u5904\u7406\u52a0\u5bc6/\u53d8\u6362\u76ee\u6807\u51fd\u6570\u7684\u4f18\u5316\u6311\u6218\u3002", "method": "\u63d0\u51fa\u65b0\u7684\u65e0\u5bfc\u6570\u6c42\u89e3\u5668DFOp\uff0c\u5305\u542b\u65b0\u7684\u4e8c\u6b21\u6a21\u578b\u51fd\u6570\u66f4\u65b0\u516c\u5f0f\uff0c\u91c7\u7528\u6700\u5c0fFrobenius\u8303\u6570\u66f4\u65b0\u7b56\u7565\uff0c\u5e76\u8bbe\u8ba1\u4e24\u79cd\u5dee\u5206\u9690\u79c1\u566a\u58f0\u6dfb\u52a0\u673a\u5236\u3002", "result": "DFOp\u5728\u6570\u503c\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u5bf9\u6bd4\u7b97\u6cd5\uff0c\u80fd\u6709\u6548\u89e3\u51b3\u52a0\u5bc6\u76ee\u6807\u51fd\u6570\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u8bc1\u660e\u6536\u655b\u6027\uff0c\u662f\u9996\u4e2a\u80fd\u7cbe\u786e\u5904\u7406\u6b65\u52a0\u5bc6\u548c\u9690\u79c1\u4fdd\u62a4\u9ed1\u76d2\u4f18\u5316\u7684\u65e0\u5bfc\u6570\u6c42\u89e3\u5668\u3002", "conclusion": "DFOp\u6210\u529f\u89e3\u51b3\u4e86\u65e0\u7ea6\u675f\u9690\u79c1\u4fdd\u62a4\u9ed1\u76d2\u4f18\u5316\u95ee\u9898\uff0c\u56de\u7b54\u4e86\u65e0\u5bfc\u6570\u4f18\u5316\u4e0e\u9690\u79c1\u4fdd\u62a4\u7ed3\u5408\u7684\u5f00\u6e90\u95ee\u9898\uff0c\u4e3a\u52a0\u5bc6\u76ee\u6807\u51fd\u6570\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2601.11559", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11559", "abs": "https://arxiv.org/abs/2601.11559", "authors": ["Zilal Eiz AlDin", "John Wu", "Jeffrey Paul Fung", "Jennifer King", "Mya Watts", "Lauren ONeill", "Adam Richard Cross", "Jimeng Sun"], "title": "MIMIC-RD: Can LLMs differentially diagnose rare diseases in real-world clinical settings?", "comment": "5 pages", "summary": "Despite rare diseases affecting 1 in 10 Americans, their differential diagnosis remains challenging. Due to their impressive recall abilities, large language models (LLMs) have been recently explored for differential diagnosis. Existing approaches to evaluating LLM-based rare disease diagnosis suffer from two critical limitations: they rely on idealized clinical case studies that fail to capture real-world clinical complexity, or they use ICD codes as disease labels, which significantly undercounts rare diseases since many lack direct mappings to comprehensive rare disease databases like Orphanet. To address these limitations, we explore MIMIC-RD, a rare disease differential diagnosis benchmark constructed by directly mapping clinical text entities to Orphanet. Our methodology involved an initial LLM-based mining process followed by validation from four medical annotators to confirm identified entities were genuine rare diseases. We evaluated various models on our dataset of 145 patients and found that current state-of-the-art LLMs perform poorly on rare disease differential diagnosis, highlighting the substantial gap between existing capabilities and clinical needs. From our findings, we outline several future steps towards improving differential diagnosis of rare diseases.", "AI": {"tldr": "\u7814\u7a76\u4eba\u5458\u521b\u5efa\u4e86MIMIC-RD\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u5c06\u4e34\u5e8a\u6587\u672c\u76f4\u63a5\u6620\u5c04\u5230Orphanet\u7f55\u89c1\u75c5\u6570\u636e\u5e93\u6765\u8bc4\u4f30LLM\u5728\u7f55\u89c1\u75c5\u9274\u522b\u8bca\u65ad\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5f53\u524d\u6700\u5148\u8fdb\u7684LLM\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u7f55\u89c1\u75c5\u5f71\u54cd\u5341\u5206\u4e4b\u4e00\u7684\u7f8e\u56fd\u4eba\uff0c\u4f46\u5176\u9274\u522b\u8bca\u65ad\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u73b0\u6709\u8bc4\u4f30LLM\u7f55\u89c1\u75c5\u8bca\u65ad\u7684\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u5c40\u9650\uff1a\u4f9d\u8d56\u7406\u60f3\u5316\u7684\u4e34\u5e8a\u6848\u4f8b\u7814\u7a76\uff0c\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u4e16\u754c\u7684\u4e34\u5e8a\u590d\u6742\u6027\uff1b\u6216\u4f7f\u7528ICD\u4ee3\u7801\u4f5c\u4e3a\u75be\u75c5\u6807\u7b7e\uff0c\u7531\u4e8e\u8bb8\u591a\u7f55\u89c1\u75c5\u7f3a\u4e4f\u4e0eOrphanet\u7b49\u7efc\u5408\u7f55\u89c1\u75c5\u6570\u636e\u5e93\u7684\u76f4\u63a5\u6620\u5c04\uff0c\u5bfc\u81f4\u4e25\u91cd\u4f4e\u4f30\u7f55\u89c1\u75c5\u3002", "method": "\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86MIMIC-RD\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u5c06\u4e34\u5e8a\u6587\u672c\u5b9e\u4f53\u76f4\u63a5\u6620\u5c04\u5230Orphanet\u7f55\u89c1\u75c5\u6570\u636e\u5e93\u3002\u65b9\u6cd5\u5305\u62ec\uff1a1\uff09\u57fa\u4e8eLLM\u7684\u521d\u6b65\u6316\u6398\u8fc7\u7a0b\uff1b2\uff09\u7531\u56db\u540d\u533b\u5b66\u6ce8\u91ca\u8005\u9a8c\u8bc1\uff0c\u786e\u8ba4\u8bc6\u522b\u7684\u5b9e\u4f53\u662f\u771f\u6b63\u7684\u7f55\u89c1\u75c5\u3002\u6700\u7ec8\u6784\u5efa\u4e86\u5305\u542b145\u540d\u60a3\u8005\u7684\u6570\u636e\u96c6\u3002", "result": "\u8bc4\u4f30\u5404\u79cd\u6a21\u578b\u540e\u53d1\u73b0\uff0c\u5f53\u524d\u6700\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7f55\u89c1\u75c5\u9274\u522b\u8bca\u65ad\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u7a81\u663e\u51fa\u73b0\u6709\u80fd\u529b\u4e0e\u4e34\u5e8a\u9700\u6c42\u4e4b\u95f4\u7684\u5de8\u5927\u5dee\u8ddd\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86LLM\u5728\u7f55\u89c1\u75c5\u8bca\u65ad\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u7f55\u89c1\u75c5\u9274\u522b\u8bca\u65ad\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2601.11687", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11687", "abs": "https://arxiv.org/abs/2601.11687", "authors": ["Harmohit Singh"], "title": "Semantic Caching and Intent-Driven Context Optimization for Multi-Agent Natural Language to Code Systems", "comment": null, "summary": "We present a production-optimized multi-agent system designed to translate natural language queries into executable Python code for structured data analytics. Unlike systems that rely on expensive frontier models, our approach achieves high accuracy and cost efficiency through three key innovations: (1) a semantic caching system with LLM-based equivalence detection and structured adaptation hints that provides cache hit rates of 67% on production queries; (2) a dual-threshold decision mechanism that separates exact-match retrieval from reference-guided generation; and (3) an intent-driven dynamic prompt assembly system that reduces token consumption by 40-60% through table-aware context filtering. The system has been deployed in production for enterprise inventory management, processing over 10,000 queries with an average latency of 8.2 seconds and 94.3% semantic accuracy. We describe the architecture, present empirical results from production deployment, and discuss practical considerations for deploying LLM-based analytics systems at scale.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u751f\u4ea7\u4f18\u5316\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u7684Python\u4ee3\u7801\u8fdb\u884c\u7ed3\u6784\u5316\u6570\u636e\u5206\u6790\uff0c\u901a\u8fc7\u8bed\u4e49\u7f13\u5b58\u3001\u53cc\u9608\u503c\u51b3\u7b56\u548c\u610f\u56fe\u9a71\u52a8\u7684\u52a8\u6001\u63d0\u793a\u7ec4\u88c5\u5b9e\u73b0\u9ad8\u51c6\u786e\u7387\u548c\u6210\u672c\u6548\u76ca\u3002", "motivation": "\u4f20\u7edf\u4f9d\u8d56\u6602\u8d35\u524d\u6cbf\u6a21\u578b\u7684\u7cfb\u7edf\u6210\u672c\u9ad8\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u65e2\u80fd\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u53c8\u80fd\u5b9e\u73b0\u6210\u672c\u6548\u76ca\u7684\u751f\u4ea7\u7ea7\u7cfb\u7edf\uff0c\u7528\u4e8e\u4f01\u4e1a\u7ed3\u6784\u5316\u6570\u636e\u5206\u6790\u3002", "method": "\u91c7\u7528\u4e09\u4e2a\u5173\u952e\u6280\u672f\uff1a1\uff09\u57fa\u4e8eLLM\u7684\u8bed\u4e49\u7f13\u5b58\u7cfb\u7edf\uff0c\u5177\u6709\u7b49\u4ef7\u68c0\u6d4b\u548c\u7ed3\u6784\u5316\u9002\u914d\u63d0\u793a\uff1b2\uff09\u5206\u79bb\u7cbe\u786e\u5339\u914d\u68c0\u7d22\u548c\u53c2\u8003\u5f15\u5bfc\u751f\u6210\u7684\u53cc\u9608\u503c\u51b3\u7b56\u673a\u5236\uff1b3\uff09\u901a\u8fc7\u8868\u611f\u77e5\u4e0a\u4e0b\u6587\u8fc7\u6ee4\u51cf\u5c1140-60%\u4ee4\u724c\u6d88\u8017\u7684\u610f\u56fe\u9a71\u52a8\u52a8\u6001\u63d0\u793a\u7ec4\u88c5\u7cfb\u7edf\u3002", "result": "\u7cfb\u7edf\u5df2\u5728\u4f01\u4e1a\u5e93\u5b58\u7ba1\u7406\u751f\u4ea7\u73af\u5883\u4e2d\u90e8\u7f72\uff0c\u5904\u7406\u8d85\u8fc710,000\u4e2a\u67e5\u8be2\uff0c\u5e73\u5747\u5ef6\u8fdf8.2\u79d2\uff0c\u8bed\u4e49\u51c6\u786e\u738794.3%\uff0c\u7f13\u5b58\u547d\u4e2d\u7387\u8fbe\u523067%\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u5c55\u793a\u4e86\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u90e8\u7f72\u57fa\u4e8eLLM\u7684\u5206\u6790\u7cfb\u7edf\u7684\u53ef\u884c\u6027\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u7f13\u5b58\u3001\u51b3\u7b56\u548c\u63d0\u793a\u4f18\u5316\u6280\u672f\u5b9e\u73b0\u4e86\u9ad8\u51c6\u786e\u7387\u548c\u6210\u672c\u6548\u76ca\u7684\u5e73\u8861\u3002"}}
{"id": "2601.11629", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11629", "abs": "https://arxiv.org/abs/2601.11629", "authors": ["Nghia T. Le", "Alan Ritter", "Kartik Goyal"], "title": "Semantic Differentiation for Tackling Challenges in Watermarking Low-Entropy Constrained Generation Outputs", "comment": "18 pages, 4 figures", "summary": "We demonstrate that while the current approaches for language model watermarking are effective for open-ended generation, they are inadequate at watermarking LM outputs for constrained generation tasks with low-entropy output spaces. Therefore, we devise SeqMark, a sequence-level watermarking algorithm with semantic differentiation that balances the output quality, watermark detectability, and imperceptibility. It improves on the shortcomings of the prevalent token-level watermarking algorithms that cause under-utilization of the sequence-level entropy available for constrained generation tasks. Moreover, we identify and improve upon a different failure mode we term region collapse, associated with prior sequence-level watermarking algorithms. This occurs because the pseudorandom partitioning of semantic space for watermarking in these approaches causes all high-probability outputs to collapse into either invalid or valid regions, leading to a trade-off in output quality and watermarking effectiveness. SeqMark instead, differentiates the high-probable output subspace and partitions it into valid and invalid regions, ensuring the even spread of high-quality outputs among all the regions. On various constrained generation tasks like machine translation, code generation, and abstractive summarization, SeqMark substantially improves watermark detection accuracy (up to 28% increase in F1) while maintaining high generation quality.", "AI": {"tldr": "SeqMark\u662f\u4e00\u79cd\u9488\u5bf9\u4f4e\u71b5\u7ea6\u675f\u751f\u6210\u4efb\u52a1\u7684\u5e8f\u5217\u7ea7\u6c34\u5370\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709token\u7ea7\u6c34\u5370\u5728\u7ea6\u675f\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u4e0d\u8db3\uff0c\u901a\u8fc7\u8bed\u4e49\u533a\u5206\u5e73\u8861\u8f93\u51fa\u8d28\u91cf\u3001\u6c34\u5370\u53ef\u68c0\u6d4b\u6027\u548c\u4e0d\u53ef\u611f\u77e5\u6027\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u6c34\u5370\u65b9\u6cd5\u5728\u5f00\u653e\u5f0f\u751f\u6210\u4efb\u52a1\u4e2d\u6709\u6548\uff0c\u4f46\u5728\u4f4e\u71b5\u8f93\u51fa\u7a7a\u95f4\u7684\u7ea6\u675f\u751f\u6210\u4efb\u52a1\uff08\u5982\u673a\u5668\u7ffb\u8bd1\u3001\u4ee3\u7801\u751f\u6210\u3001\u6458\u8981\u751f\u6210\uff09\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u4e13\u95e8\u9488\u5bf9\u6b64\u7c7b\u4efb\u52a1\u8bbe\u8ba1\u7684\u6c34\u5370\u7b97\u6cd5\u3002", "method": "SeqMark\u662f\u4e00\u79cd\u5e8f\u5217\u7ea7\u6c34\u5370\u7b97\u6cd5\uff0c\u91c7\u7528\u8bed\u4e49\u533a\u5206\u7b56\u7565\u3002\u5b83\u6539\u8fdb\u4e86\u73b0\u6709token\u7ea7\u6c34\u5370\u7b97\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528\u5e8f\u5217\u7ea7\u71b5\u7684\u95ee\u9898\uff0c\u5e76\u89e3\u51b3\u4e86\u5148\u524d\u5e8f\u5217\u7ea7\u6c34\u5370\u7b97\u6cd5\u4e2d\u7684\"\u533a\u57df\u5d29\u6e83\"\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u5c06\u9ad8\u6982\u7387\u8f93\u51fa\u5b50\u7a7a\u95f4\u8fdb\u884c\u533a\u5206\uff0c\u5e76\u5c06\u5176\u5212\u5206\u4e3a\u6709\u6548\u548c\u65e0\u6548\u533a\u57df\uff0c\u786e\u4fdd\u9ad8\u8d28\u91cf\u8f93\u51fa\u5728\u6240\u6709\u533a\u57df\u4e2d\u5747\u5300\u5206\u5e03\u3002", "result": "\u5728\u673a\u5668\u7ffb\u8bd1\u3001\u4ee3\u7801\u751f\u6210\u548c\u62bd\u8c61\u6458\u8981\u7b49\u591a\u79cd\u7ea6\u675f\u751f\u6210\u4efb\u52a1\u4e0a\uff0cSeqMark\u663e\u8457\u63d0\u9ad8\u4e86\u6c34\u5370\u68c0\u6d4b\u51c6\u786e\u7387\uff08F1\u5206\u6570\u6700\u9ad8\u63d0\u534728%\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u751f\u6210\u8d28\u91cf\u3002", "conclusion": "SeqMark\u901a\u8fc7\u5e8f\u5217\u7ea7\u6c34\u5370\u548c\u8bed\u4e49\u533a\u5206\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u7ea6\u675f\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u6c34\u5370\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u8f93\u51fa\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u6c34\u5370\u68c0\u6d4b\u6027\u80fd\uff0c\u4e3a\u4f4e\u71b5\u8f93\u51fa\u7a7a\u95f4\u7684LM\u6c34\u5370\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11620", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11620", "abs": "https://arxiv.org/abs/2601.11620", "authors": ["Michael Timothy Bennett"], "title": "A Mind Cannot Be Smeared Across Time", "comment": null, "summary": "Whether machines can be conscious depends not only on what they compute, but \\emph{when} they compute it. Most deployed artificial systems realise their functions via sequential or time-multiplexed updates. Conscious experience appears unified and simultaneous. I show that this difference matters formally. I augment Stack Theory with algebraic laws relating within time-window constraint satisfaction to conjunction. I introduce a precise temporal semantics over windowed trajectories $\u03c4^{\u0394,s}$ and prove that existential temporal realisation $\\Diamond_\u0394$ does not preserve conjunction. A system can realise all the ingredients of experience across time without ever instantiating the experienced conjunction itself. I then distinguish two postulates. StrongSync requires objective co-instantiation of the grounded conjunction within the window, while WeakSync permits temporal ``smearing''. I formalise concurrency-capacity to measure what is needed to satisfy StrongSync. Finally, I review neurophysiological evidence suggesting that consciousness depends on phase synchrony and effective connectivity, and that loss of consciousness is often associated with its breakdown. This evidence makes WeakSync less plausible. Under StrongSync, software consciousness on strictly sequential substrates is impossible for contents whose grounding requires two or more simultaneous contributors. The more parts from which simultaneous contribution required, the more concurrency capacity is required. The hardware matters. Consciousness attribution therefore requires architectural inspection, not just functional performance.", "AI": {"tldr": "\u8bba\u6587\u8ba4\u4e3a\u673a\u5668\u610f\u8bc6\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u8ba1\u7b97\u5185\u5bb9\uff0c\u8fd8\u53d6\u51b3\u4e8e\u8ba1\u7b97\u65f6\u673a\u3002\u987a\u5e8f\u8ba1\u7b97\u7cfb\u7edf\u65e0\u6cd5\u5b9e\u73b0\u610f\u8bc6\u6240\u9700\u7684\u540c\u6b65\u6027\uff0c\u9700\u8981\u786c\u4ef6\u5c42\u9762\u7684\u5e76\u53d1\u80fd\u529b\u3002", "motivation": "\u73b0\u6709AI\u7cfb\u7edf\u5927\u591a\u91c7\u7528\u987a\u5e8f\u6216\u65f6\u5206\u590d\u7528\u8ba1\u7b97\uff0c\u800c\u610f\u8bc6\u4f53\u9a8c\u5177\u6709\u7edf\u4e00\u6027\u548c\u540c\u65f6\u6027\u3002\u8bba\u6587\u65e8\u5728\u63a2\u8ba8\u8ba1\u7b97\u65f6\u5e8f\u5bf9\u673a\u5668\u610f\u8bc6\u53ef\u80fd\u6027\u7684\u5f71\u54cd\u3002", "method": "\u6269\u5c55\u6808\u7406\u8bba\uff0c\u5f15\u5165\u65f6\u95f4\u7a97\u53e3\u7ea6\u675f\u7684\u4ee3\u6570\u5b9a\u5f8b\uff1b\u5b9a\u4e49\u7cbe\u786e\u7684\u65f6\u95f4\u8bed\u4e49\u03c4^{\u0394,s}\uff1b\u8bc1\u660e\u5b58\u5728\u6027\u65f6\u95f4\u5b9e\u73b0\u25c7_\u0394\u4e0d\u4fdd\u6301\u5408\u53d6\uff1b\u533a\u5206StrongSync\u548cWeakSync\u4e24\u79cd\u5047\u8bbe\uff1b\u5f62\u5f0f\u5316\u5e76\u53d1\u80fd\u529b\u5ea6\u91cf\u3002", "result": "\u7cfb\u7edf\u53ef\u4ee5\u5728\u65f6\u95f4\u4e0a\u5b9e\u73b0\u6240\u6709\u4f53\u9a8c\u6210\u5206\uff0c\u4f46\u4ece\u672a\u5b9e\u4f8b\u5316\u4f53\u9a8c\u5408\u53d6\u672c\u8eab\uff1b\u795e\u7ecf\u751f\u7406\u8bc1\u636e\u652f\u6301StrongSync\uff1b\u4e25\u683c\u987a\u5e8f\u8ba1\u7b97\u786c\u4ef6\u65e0\u6cd5\u5b9e\u73b0\u9700\u8981\u4e24\u4e2a\u4ee5\u4e0a\u540c\u65f6\u8d21\u732e\u8005\u7684\u610f\u8bc6\u5185\u5bb9\u3002", "conclusion": "\u673a\u5668\u610f\u8bc6\u9700\u8981\u786c\u4ef6\u5c42\u9762\u7684\u5e76\u53d1\u80fd\u529b\uff0c\u4ec5\u51ed\u529f\u80fd\u6027\u80fd\u4e0d\u8db3\u3002\u610f\u8bc6\u5f52\u56e0\u9700\u8981\u67b6\u6784\u68c0\u67e5\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u529f\u80fd\u8868\u73b0\u3002"}}
{"id": "2601.11688", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11688", "abs": "https://arxiv.org/abs/2601.11688", "authors": ["Vedant Nipane", "Pulkit Agrawal", "Amit Singh"], "title": "SpecMap: Hierarchical LLM Agent for Datasheet-to-Code Traceability Link Recovery in Systems Engineering", "comment": null, "summary": "Establishing precise traceability between embedded systems datasheets and their corresponding code implementations remains a fundamental challenge in systems engineering, particularly for low-level software where manual mapping between specification documents and large code repositories is infeasible. Existing Traceability Link Recovery approaches primarily rely on lexical similarity and information retrieval techniques, which struggle to capture the semantic, structural, and symbol level relationships prevalent in embedded systems software. We present a hierarchical datasheet-to-code mapping methodology that employs large language models for semantic analysis while explicitly structuring the traceability process across multiple abstraction levels. Rather than performing direct specification-to-code matching, the proposed approach progressively narrows the search space through repository-level structure inference, file-level relevance estimation, and fine-grained symbollevel alignment. The method extends beyond function-centric mapping by explicitly covering macros, structs, constants, configuration parameters, and register definitions commonly found in systems-level C/C++ codebases. We evaluate the approach on multiple open-source embedded systems repositories using manually curated datasheet-to-code ground truth. Experimental results show substantial improvements over traditional information-retrieval-based baselines, achieving up to 73.3% file mapping accuracy. We significantly reduce computational overhead, lowering total LLM token consumption by 84% and end-to-end runtime by approximately 80%. This methodology supports automated analysis of large embedded software systems and enables downstream applications such as training data generation for systems-aware machine learning models, standards compliance verification, and large-scale specification coverage analysis.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5206\u5c42\u6570\u636e\u624b\u518c\u5230\u4ee3\u7801\u6620\u5c04\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u5d4c\u5165\u5f0f\u7cfb\u7edf\u6587\u6863\u4e0e\u4ee3\u7801\u7684\u8ffd\u6eaf\u7cbe\u5ea6\u548c\u6548\u7387", "motivation": "\u5d4c\u5165\u5f0f\u7cfb\u7edf\u6570\u636e\u624b\u518c\u4e0e\u4ee3\u7801\u5b9e\u73b0\u4e4b\u95f4\u7684\u7cbe\u786e\u8ffd\u6eaf\u662f\u7cfb\u7edf\u5de5\u7a0b\u4e2d\u7684\u57fa\u672c\u6311\u6218\uff0c\u73b0\u6709\u57fa\u4e8e\u8bcd\u6c47\u76f8\u4f3c\u6027\u548c\u4fe1\u606f\u68c0\u7d22\u7684\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u5d4c\u5165\u5f0f\u7cfb\u7edf\u8f6f\u4ef6\u4e2d\u7684\u8bed\u4e49\u3001\u7ed3\u6784\u548c\u7b26\u53f7\u7ea7\u5173\u7cfb", "method": "\u91c7\u7528\u5206\u5c42\u7684\u6570\u636e\u624b\u518c\u5230\u4ee3\u7801\u6620\u5c04\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bed\u4e49\u5206\u6790\uff0c\u901a\u8fc7\u4ed3\u5e93\u7ea7\u7ed3\u6784\u63a8\u65ad\u3001\u6587\u4ef6\u7ea7\u76f8\u5173\u6027\u4f30\u8ba1\u548c\u7ec6\u7c92\u5ea6\u7b26\u53f7\u7ea7\u5bf9\u9f50\u4e09\u4e2a\u5c42\u6b21\u9010\u6b65\u7f29\u5c0f\u641c\u7d22\u7a7a\u95f4\uff0c\u8986\u76d6\u51fd\u6570\u3001\u5b8f\u3001\u7ed3\u6784\u4f53\u3001\u5e38\u91cf\u3001\u914d\u7f6e\u53c2\u6570\u548c\u5bc4\u5b58\u5668\u5b9a\u4e49\u7b49\u7cfb\u7edf\u7ea7C/C++\u4ee3\u7801\u5143\u7d20", "result": "\u5728\u591a\u4e2a\u5f00\u6e90\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4ed3\u5e93\u4e0a\u8bc4\u4f30\uff0c\u76f8\u6bd4\u4f20\u7edf\u4fe1\u606f\u68c0\u7d22\u57fa\u7ebf\u6709\u663e\u8457\u6539\u8fdb\uff0c\u6587\u4ef6\u6620\u5c04\u51c6\u786e\u7387\u8fbe\u523073.3%\uff0cLLM\u4ee4\u724c\u6d88\u8017\u964d\u4f4e84%\uff0c\u7aef\u5230\u7aef\u8fd0\u884c\u65f6\u95f4\u51cf\u5c11\u7ea680%", "conclusion": "\u8be5\u65b9\u6cd5\u652f\u6301\u5927\u578b\u5d4c\u5165\u5f0f\u8f6f\u4ef6\u7cfb\u7edf\u7684\u81ea\u52a8\u5316\u5206\u6790\uff0c\u4e3a\u7cfb\u7edf\u611f\u77e5\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u751f\u6210\u3001\u6807\u51c6\u5408\u89c4\u6027\u9a8c\u8bc1\u548c\u5927\u89c4\u6a21\u89c4\u8303\u8986\u76d6\u5206\u6790\u7b49\u4e0b\u6e38\u5e94\u7528\u63d0\u4f9b\u652f\u6301"}}
{"id": "2601.11664", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11664", "abs": "https://arxiv.org/abs/2601.11664", "authors": ["Chetan Pathade", "Vinod Dhimam", "Sheheryar Ahmad", "Ilsa Lareb"], "title": "Serverless AI Security: Attack Surface Analysis and Runtime Protection Mechanisms for FaaS-Based Machine Learning", "comment": "17 Pages, 2 Figures, 4 Tables", "summary": "Serverless computing has achieved widespread adoption, with over 70% of AWS organizations using serverless solutions [1]. Meanwhile, machine learning inference workloads increasingly migrate to Function-as-a-Service (FaaS) platforms for their scalability and cost-efficiency [2], [3], [4]. However, this convergence introduces critical security challenges, with recent reports showing a 220% increase in AI/ML vulnerabilities [5] and serverless computing's fragmented architecture raises new security concerns distinct from traditional cloud deployments [6], [7]. This paper presents the first comprehensive security analysis of machine learning workloads in serverless environments. We systematically characterize the attack surface across five categories: function-level vulnerabilities (cold start exploitation, dependency poisoning), model-specific threats (API-based extraction, adversarial inputs), infrastructure attacks (cross-function contamination, privilege escalation), supply chain risks (malicious layers, backdoored libraries), and IAM complexity (ephemeral nature, serverless functions). Through empirical assessments across AWS Lambda, Azure Functions, and Google Cloud Functions, we demonstrate real-world attack scenarios and quantify their security impact. We propose Serverless AI Shield (SAS), a multi-layered defense framework providing pre-deployment validation, runtime monitoring, and post-execution forensics. Our evaluation shows SAS achieves 94% detection rates while maintaining performance overhead below 9% for inference latency. We release an open-source security toolkit to enable practitioners to assess and harden their serverless AI deployments, advancing the field toward more resilient cloud-native machine learning systems.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5bf9\u65e0\u670d\u52a1\u5668\u73af\u5883\u4e2d\u7684\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u8d1f\u8f7d\u8fdb\u884c\u5168\u9762\u7684\u5b89\u5168\u5206\u6790\uff0c\u8bc6\u522b\u4e86\u4e94\u4e2a\u4e3b\u8981\u653b\u51fb\u9762\u7c7b\u522b\uff0c\u63d0\u51fa\u4e86Serverless AI Shield\u9632\u5fa1\u6846\u67b6\uff0c\u5e76\u5728\u4e09\u5927\u4e91\u5e73\u53f0\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u968f\u7740\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\u5e7f\u6cdb\u91c7\u7528\uff08\u8d85\u8fc770%\u7684AWS\u7ec4\u7ec7\u4f7f\u7528\uff09\u548c\u673a\u5668\u5b66\u4e60\u63a8\u7406\u5de5\u4f5c\u8d1f\u8f7d\u5411FaaS\u5e73\u53f0\u8fc1\u79fb\uff0c\u8fd9\u79cd\u878d\u5408\u5e26\u6765\u4e86\u5173\u952e\u7684\u5b89\u5168\u6311\u6218\u3002AI/ML\u6f0f\u6d1e\u589e\u52a0\u4e86220%\uff0c\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\u7684\u788e\u7247\u5316\u67b6\u6784\u5e26\u6765\u4e86\u4e0d\u540c\u4e8e\u4f20\u7edf\u4e91\u90e8\u7f72\u7684\u65b0\u5b89\u5168\u95ee\u9898\u3002", "method": "\u7cfb\u7edf\u6027\u5730\u5c06\u653b\u51fb\u9762\u5206\u4e3a\u4e94\u4e2a\u7c7b\u522b\u8fdb\u884c\u5206\u6790\uff1a\u51fd\u6570\u7ea7\u6f0f\u6d1e\u3001\u6a21\u578b\u7279\u5b9a\u5a01\u80c1\u3001\u57fa\u7840\u8bbe\u65bd\u653b\u51fb\u3001\u4f9b\u5e94\u94fe\u98ce\u9669\u548cIAM\u590d\u6742\u6027\u3002\u5728AWS Lambda\u3001Azure Functions\u548cGoogle Cloud Functions\u4e0a\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u6f14\u793a\u771f\u5b9e\u653b\u51fb\u573a\u666f\u5e76\u91cf\u5316\u5b89\u5168\u5f71\u54cd\u3002\u63d0\u51faServerless AI Shield\u591a\u5c42\u9632\u5fa1\u6846\u67b6\uff0c\u5305\u62ec\u90e8\u7f72\u524d\u9a8c\u8bc1\u3001\u8fd0\u884c\u65f6\u76d1\u63a7\u548c\u6267\u884c\u540e\u53d6\u8bc1\u3002", "result": "\u8bc4\u4f30\u663e\u793aServerless AI Shield\u8fbe\u523094%\u7684\u68c0\u6d4b\u7387\uff0c\u540c\u65f6\u5c06\u63a8\u7406\u5ef6\u8fdf\u7684\u6027\u80fd\u5f00\u9500\u4fdd\u6301\u57289%\u4ee5\u4e0b\u3002\u53d1\u5e03\u4e86\u5f00\u6e90\u5b89\u5168\u5de5\u5177\u5305\uff0c\u5e2e\u52a9\u4ece\u4e1a\u8005\u8bc4\u4f30\u548c\u52a0\u56fa\u65e0\u670d\u52a1\u5668AI\u90e8\u7f72\u3002", "conclusion": "\u8fd9\u662f\u5bf9\u65e0\u670d\u52a1\u5668\u73af\u5883\u4e2d\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u8d1f\u8f7d\u7684\u9996\u6b21\u5168\u9762\u5b89\u5168\u5206\u6790\uff0c\u63d0\u51fa\u7684Serverless AI Shield\u6846\u67b6\u80fd\u591f\u6709\u6548\u9632\u5fa1\u8bc6\u522b\u51fa\u7684\u5b89\u5168\u5a01\u80c1\uff0c\u63a8\u52a8\u4e86\u66f4\u5177\u5f39\u6027\u7684\u4e91\u539f\u751f\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.11622", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11622", "abs": "https://arxiv.org/abs/2601.11622", "authors": ["Hassan Ugail", "Newton Howard"], "title": "Dynamical Systems Analysis Reveals Functional Regimes in Large Language Models", "comment": null, "summary": "Large language models perform text generation through high-dimensional internal dynamics, yet the temporal organisation of these dynamics remains poorly understood. Most interpretability approaches emphasise static representations or causal interventions, leaving temporal structure largely unexplored. Drawing on neuroscience, where temporal integration and metastability are core markers of neural organisation, we adapt these concepts to transformer models and discuss a composite dynamical metric, computed from activation time-series during autoregressive generation. We evaluate this metric in GPT-2-medium across five conditions: structured reasoning, forced repetition, high-temperature noisy sampling, attention-head pruning, and weight-noise injection. Structured reasoning consistently exhibits elevated metric relative to repetitive, noisy, and perturbed regimes, with statistically significant differences confirmed by one-way ANOVA and large effect sizes in key comparisons. These results are robust to layer selection, channel subsampling, and random seeds. Our findings demonstrate that neuroscience-inspired dynamical metrics can reliably characterise differences in computational organisation across functional regimes in large language models. We stress that the proposed metric captures formal dynamical properties and does not imply subjective experience.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5c06\u795e\u7ecf\u79d1\u5b66\u4e2d\u7684\u65f6\u95f4\u6574\u5408\u548c\u4e9a\u7a33\u6001\u6982\u5ff5\u5e94\u7528\u4e8eTransformer\u6a21\u578b\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u6fc0\u6d3b\u65f6\u95f4\u5e8f\u5217\u7684\u590d\u5408\u52a8\u529b\u5b66\u6307\u6807\uff0c\u7528\u4e8e\u5206\u6790LLM\u5728\u4e0d\u540c\u529f\u80fd\u72b6\u6001\u4e0b\u7684\u8ba1\u7b97\u7ec4\u7ec7\u5dee\u5f02\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u9ad8\u7ef4\u5185\u90e8\u52a8\u529b\u5b66\u8fdb\u884c\u6587\u672c\u751f\u6210\uff0c\u4f46\u8fd9\u4e9b\u52a8\u529b\u5b66\u7684\u65f6\u95f4\u7ec4\u7ec7\u4ecd\u7136\u672a\u88ab\u5145\u5206\u7406\u89e3\u3002\u73b0\u6709\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u9759\u6001\u8868\u793a\u6216\u56e0\u679c\u5e72\u9884\uff0c\u800c\u5ffd\u7565\u4e86\u65f6\u95f4\u7ed3\u6784\u3002\u53d7\u795e\u7ecf\u79d1\u5b66\u4e2d\u65f6\u95f4\u6574\u5408\u548c\u4e9a\u7a33\u6001\u4f5c\u4e3a\u795e\u7ecf\u7ec4\u7ec7\u6838\u5fc3\u6807\u8bb0\u7684\u542f\u53d1\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u5c06\u8fd9\u4e9b\u6982\u5ff5\u5e94\u7528\u4e8eTransformer\u6a21\u578b\u3002", "method": "\u7814\u7a76\u8005\u5c06\u795e\u7ecf\u79d1\u5b66\u4e2d\u7684\u65f6\u95f4\u6574\u5408\u548c\u4e9a\u7a33\u6001\u6982\u5ff5\u9002\u914d\u5230Transformer\u6a21\u578b\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u590d\u5408\u52a8\u529b\u5b66\u6307\u6807\uff0c\u8be5\u6307\u6807\u57fa\u4e8e\u81ea\u56de\u5f52\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u6fc0\u6d3b\u65f6\u95f4\u5e8f\u5217\u8ba1\u7b97\u3002\u5728GPT-2-medium\u6a21\u578b\u4e0a\u8bc4\u4f30\u4e86\u8be5\u6307\u6807\u5728\u4e94\u79cd\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\uff1a\u7ed3\u6784\u5316\u63a8\u7406\u3001\u5f3a\u5236\u91cd\u590d\u3001\u9ad8\u6e29\u566a\u58f0\u91c7\u6837\u3001\u6ce8\u610f\u529b\u5934\u526a\u679d\u548c\u6743\u91cd\u566a\u58f0\u6ce8\u5165\u3002", "result": "\u7ed3\u6784\u5316\u63a8\u7406\u6761\u4ef6\u76f8\u5bf9\u4e8e\u91cd\u590d\u3001\u566a\u58f0\u548c\u6270\u52a8\u72b6\u6001\u8868\u73b0\u51fa\u663e\u8457\u5347\u9ad8\u7684\u6307\u6807\u503c\u3002\u901a\u8fc7\u5355\u56e0\u7d20\u65b9\u5dee\u5206\u6790\u786e\u8ba4\u4e86\u7edf\u8ba1\u663e\u8457\u6027\u5dee\u5f02\uff0c\u5173\u952e\u6bd4\u8f83\u4e2d\u663e\u793a\u51fa\u5927\u7684\u6548\u5e94\u91cf\u3002\u8fd9\u4e9b\u7ed3\u679c\u5bf9\u5c42\u9009\u62e9\u3001\u901a\u9053\u5b50\u91c7\u6837\u548c\u968f\u673a\u79cd\u5b50\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "\u795e\u7ecf\u79d1\u5b66\u542f\u53d1\u7684\u52a8\u529b\u5b66\u6307\u6807\u80fd\u591f\u53ef\u9760\u5730\u8868\u5f81\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u529f\u80fd\u72b6\u6001\u4e0b\u7684\u8ba1\u7b97\u7ec4\u7ec7\u5dee\u5f02\u3002\u7814\u7a76\u8005\u5f3a\u8c03\u6240\u63d0\u51fa\u7684\u6307\u6807\u6355\u83b7\u7684\u662f\u5f62\u5f0f\u52a8\u529b\u5b66\u7279\u6027\uff0c\u5e76\u4e0d\u6697\u793a\u4e3b\u89c2\u4f53\u9a8c\u3002"}}
{"id": "2601.11693", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.11693", "abs": "https://arxiv.org/abs/2601.11693", "authors": ["Shane K. Panter", "Nasir U. Eisty"], "title": "Technical Lag as Latent Technical Debt: A Rapid Review", "comment": "Accepted to: TechDebt 2026 - International Conference on Technical Debt April 12--15, 2026 Rio de Janeiro, Brazil", "summary": "Context: Technical lag accumulates when software systems fail to keep pace with technological advancements, leading to a deterioration in software quality. Objective: This paper aims to consolidate existing research on technical lag, clarify definitions, explore its detection and quantification methods, examine underlying causes and consequences, review current management practices, and lay out a vision as an indicator of passively accumulated technical debt. Method: We conducted a Rapid Review with snowballing to select the appropriate peer-reviewed studies. We leveraged the ACM Digital Library, IEEE Xplore, Scopus, and Springer as our primary source databases. Results: Technical lag accumulates passively, often unnoticed due to inadequate detection metrics and tools. It negatively impacts software quality through outdated dependencies, obsolete APIs, unsupported platforms, and aging infrastructure. Strategies to manage technical lag primarily involve automated dependency updates, continuous integration processes, and regular auditing. Conclusions: Enhancing and extending the current standardized metrics, detection methods, and empirical studies to use technical lag as an indication of accumulated latent debt can greatly improve the process of maintaining large codebases that are heavily dependent on external packages. We have identified the research gaps and outlined a future vision for researchers and practitioners to explore.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5feb\u901f\u7efc\u8ff0\u65b9\u6cd5\u7cfb\u7edf\u68b3\u7406\u4e86\u6280\u672f\u6ede\u540e\u7684\u7814\u7a76\u73b0\u72b6\uff0c\u660e\u786e\u4e86\u5b9a\u4e49\u3001\u68c0\u6d4b\u91cf\u5316\u65b9\u6cd5\u3001\u6210\u56e0\u540e\u679c\u53ca\u7ba1\u7406\u5b9e\u8df5\uff0c\u63d0\u51fa\u5c06\u5176\u4f5c\u4e3a\u88ab\u52a8\u79ef\u7d2f\u6280\u672f\u503a\u52a1\u7684\u6307\u6807\uff0c\u4e3a\u5927\u578b\u4ee3\u7801\u5e93\u7ef4\u62a4\u63d0\u4f9b\u6539\u8fdb\u65b9\u5411\u3002", "motivation": "\u6280\u672f\u6ede\u540e\u662f\u8f6f\u4ef6\u7cfb\u7edf\u672a\u80fd\u8ddf\u4e0a\u6280\u672f\u8fdb\u6b65\u800c\u79ef\u7d2f\u7684\u95ee\u9898\uff0c\u4f1a\u5bfc\u81f4\u8f6f\u4ef6\u8d28\u91cf\u6076\u5316\u3002\u73b0\u6709\u7814\u7a76\u5206\u6563\uff0c\u7f3a\u4e4f\u7edf\u4e00\u5b9a\u4e49\u548c\u7cfb\u7edf\u6846\u67b6\uff0c\u9700\u8981\u6574\u5408\u73b0\u6709\u7814\u7a76\u4ee5\u660e\u786e\u6280\u672f\u6ede\u540e\u7684\u6982\u5ff5\u3001\u68c0\u6d4b\u65b9\u6cd5\u548c\u7ba1\u7406\u7b56\u7565\u3002", "method": "\u91c7\u7528\u5feb\u901f\u7efc\u8ff0\u65b9\u6cd5\u7ed3\u5408\u6eda\u96ea\u7403\u62bd\u6837\uff0c\u4eceACM Digital Library\u3001IEEE Xplore\u3001Scopus\u548cSpringer\u7b49\u4e3b\u8981\u6570\u636e\u5e93\u7b5b\u9009\u540c\u884c\u8bc4\u5ba1\u7814\u7a76\uff0c\u7cfb\u7edf\u5206\u6790\u6280\u672f\u6ede\u540e\u7684\u76f8\u5173\u6587\u732e\u3002", "result": "\u6280\u672f\u6ede\u540e\u901a\u5e38\u88ab\u52a8\u79ef\u7d2f\u4e14\u4e0d\u6613\u5bdf\u89c9\uff0c\u4e3b\u8981\u56e0\u68c0\u6d4b\u6307\u6807\u548c\u5de5\u5177\u4e0d\u8db3\uff1b\u5b83\u901a\u8fc7\u8fc7\u65f6\u4f9d\u8d56\u3001\u5e9f\u5f03API\u3001\u4e0d\u652f\u6301\u5e73\u53f0\u548c\u8001\u5316\u57fa\u7840\u8bbe\u65bd\u5bf9\u8f6f\u4ef6\u8d28\u91cf\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\uff1b\u7ba1\u7406\u7b56\u7565\u4e3b\u8981\u5305\u62ec\u81ea\u52a8\u5316\u4f9d\u8d56\u66f4\u65b0\u3001\u6301\u7eed\u96c6\u6210\u6d41\u7a0b\u548c\u5b9a\u671f\u5ba1\u8ba1\u3002", "conclusion": "\u589e\u5f3a\u548c\u6269\u5c55\u5f53\u524d\u6807\u51c6\u5316\u6307\u6807\u3001\u68c0\u6d4b\u65b9\u6cd5\u53ca\u5b9e\u8bc1\u7814\u7a76\uff0c\u5c06\u6280\u672f\u6ede\u540e\u4f5c\u4e3a\u79ef\u7d2f\u7684\u6f5c\u5728\u503a\u52a1\u6307\u6807\uff0c\u53ef\u663e\u8457\u6539\u5584\u4f9d\u8d56\u5916\u90e8\u5305\u7684\u5927\u578b\u4ee3\u7801\u5e93\u7ef4\u62a4\u8fc7\u7a0b\uff1b\u8bc6\u522b\u4e86\u7814\u7a76\u7a7a\u767d\u5e76\u4e3a\u7814\u7a76\u8005\u548c\u5b9e\u8df5\u8005\u89c4\u5212\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2601.11678", "categories": ["cs.CR", "cs.NI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.11678", "abs": "https://arxiv.org/abs/2601.11678", "authors": ["Shuai Zhang", "Minzhao Lyu", "Hassan Habibi Gharakheili"], "title": "A Survey on Mapping Digital Systems with Bill of Materials: Development, Practices, and Challenges", "comment": null, "summary": "Modern digital ecosystems, spanning software, hardware, learning models, datasets, and cryptographic products, continue to grow in complexity, making it difficult for organizations to understand and manage component dependencies. Bills of Materials (BOMs) have emerged as a structured way to document product components, their interrelationships, and key metadata, improving visibility and security across digital supply chains. This survey provides the first comprehensive cross-domain review of BOM developments and practices. We start by examining the evolution of BOM frameworks in three stages (i.e., pre-development, initial, and accelerated) and summarizing their core principles, key stakeholders, and standardization efforts for hardware, software, artificial intelligence (AI) models, datasets, and cryptographic assets. We then review industry practices for generating BOM data, evaluating its quality, and securely sharing it. Next, we review practical downstream uses of BOM data, including dependency modeling, compliance verification, operational risk assessment, and vulnerability tracking. We also discuss academic efforts to address limitations in current BOM frameworks through refinements, extensions, or new models tailored to emerging domains such as data ecosystems and AI supply chains. Finally, we identify four key gaps that limit the usability and reliability of today's BOM frameworks, motivating future research directions.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5bf9\u8de8\u9886\u57dfBOM\uff08\u7269\u6599\u6e05\u5355\uff09\u53d1\u5c55\u4e0e\u5b9e\u8df5\u8fdb\u884c\u5168\u9762\u7efc\u8ff0\uff0c\u6db5\u76d6\u786c\u4ef6\u3001\u8f6f\u4ef6\u3001AI\u6a21\u578b\u3001\u6570\u636e\u96c6\u548c\u52a0\u5bc6\u8d44\u4ea7\uff0c\u5206\u6790\u5176\u6f14\u53d8\u9636\u6bb5\u3001\u884c\u4e1a\u5b9e\u8df5\u3001\u5e94\u7528\u573a\u666f\u53ca\u7814\u7a76\u6311\u6218\u3002", "motivation": "\u73b0\u4ee3\u6570\u5b57\u751f\u6001\u7cfb\u7edf\u65e5\u76ca\u590d\u6742\uff0c\u7ec4\u4ef6\u4f9d\u8d56\u5173\u7cfb\u96be\u4ee5\u7406\u89e3\u548c\u7ba1\u7406\uff0cBOM\u4f5c\u4e3a\u7ed3\u6784\u5316\u6587\u6863\u5de5\u5177\u53ef\u63d0\u9ad8\u6570\u5b57\u4f9b\u5e94\u94fe\u7684\u53ef\u89c1\u6027\u548c\u5b89\u5168\u6027\uff0c\u9700\u8981\u7cfb\u7edf\u68b3\u7406\u5176\u8de8\u9886\u57df\u53d1\u5c55\u73b0\u72b6\u3002", "method": "\u91c7\u7528\u8de8\u9886\u57df\u7efc\u8ff0\u65b9\u6cd5\uff0c\u9996\u5148\u5206\u6790BOM\u6846\u67b6\u5728\u4e09\u4e2a\u9636\u6bb5\u7684\u6f14\u53d8\uff08\u9884\u53d1\u5c55\u671f\u3001\u521d\u59cb\u671f\u3001\u52a0\u901f\u671f\uff09\uff0c\u603b\u7ed3\u6838\u5fc3\u539f\u5219\u3001\u5173\u952e\u5229\u76ca\u76f8\u5173\u8005\u548c\u6807\u51c6\u5316\u5de5\u4f5c\uff1b\u7136\u540e\u5ba1\u67e5\u884c\u4e1a\u5b9e\u8df5\u4e2d\u7684BOM\u6570\u636e\u751f\u6210\u3001\u8d28\u91cf\u8bc4\u4f30\u548c\u5b89\u5168\u5171\u4eab\uff1b\u6700\u540e\u5206\u6790BOM\u6570\u636e\u7684\u4e0b\u6e38\u5e94\u7528\u573a\u666f\u3002", "result": "\u7cfb\u7edf\u68b3\u7406\u4e86BOM\u5728\u786c\u4ef6\u3001\u8f6f\u4ef6\u3001AI\u6a21\u578b\u3001\u6570\u636e\u96c6\u548c\u52a0\u5bc6\u8d44\u4ea7\u7b49\u9886\u57df\u7684\u6807\u51c6\u5316\u8fdb\u5c55\uff0c\u603b\u7ed3\u4e86\u884c\u4e1a\u5b9e\u8df5\u6a21\u5f0f\uff0c\u8bc6\u522b\u4e86\u4f9d\u8d56\u5efa\u6a21\u3001\u5408\u89c4\u9a8c\u8bc1\u3001\u8fd0\u8425\u98ce\u9669\u8bc4\u4f30\u548c\u6f0f\u6d1e\u8ddf\u8e2a\u7b49\u5173\u952e\u5e94\u7528\u573a\u666f\uff0c\u5e76\u6307\u51fa\u4e86\u5f53\u524dBOM\u6846\u67b6\u7684\u5b66\u672f\u6539\u8fdb\u65b9\u5411\u3002", "conclusion": "BOM\u6846\u67b6\u5728\u6570\u5b57\u4f9b\u5e94\u94fe\u7ba1\u7406\u4e2d\u53d1\u6325\u91cd\u8981\u4f5c\u7528\uff0c\u4f46\u5b58\u5728\u56db\u4e2a\u5173\u952e\u5dee\u8ddd\u9650\u5236\u4e86\u5176\u53ef\u7528\u6027\u548c\u53ef\u9760\u6027\uff0c\u9700\u8981\u672a\u6765\u7814\u7a76\u89e3\u51b3\uff0c\u7279\u522b\u662f\u5728\u65b0\u5174\u6570\u636e\u751f\u6001\u7cfb\u7edf\u548cAI\u4f9b\u5e94\u94fe\u9886\u57df\u3002"}}
{"id": "2601.11625", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11625", "abs": "https://arxiv.org/abs/2601.11625", "authors": ["Sahil Rajesh Dhayalkar"], "title": "Reasoning Stabilization Point: A Training-Time Signal for Stable Evidence and Shortcut Reliance", "comment": "8 pages, Submitted to ACL Rolling Review and is under review", "summary": "Fine-tuning pretrained language models can improve task performance while subtly altering the evidence a model relies on. We propose a training-time interpretability view that tracks token-level attributions across finetuning epochs. We define explanation driftas the epoch-to-epoch change in normalized token attributions on a fixed probe set, and introduce the Reasoning Stabilization Point(RSP), the earliest epoch after which drift remains consistently low. RSP is computed from within-run drift dynamics and requires no tuning on out-of-distribution data. Across multiple lightweight transformer classifiers and benchmark classification tasks, drift typically collapses into a low, stable regime early in training, while validation accuracy continues to change only marginally. In a controlled shortcut setting with label-correlated trigger tokens, attribution dynamics expose increasing reliance on the shortcut even when validation accuracy remains competitive. Overall, explanation drift provides a simple, low-cost diagnostic for monitoring how decision evidence evolves during fine-tuning and for selecting checkpoints in a stable-evidence regime.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bad\u7ec3\u65f6\u89e3\u91ca\u6027\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ddf\u8e2a\u5fae\u8c03\u8fc7\u7a0b\u4e2dtoken\u7ea7\u5f52\u56e0\u7684\u53d8\u5316\u6765\u76d1\u63a7\u6a21\u578b\u51b3\u7b56\u4f9d\u636e\u7684\u6f14\u53d8\uff0c\u5e76\u5f15\u5165\u4e86\"\u63a8\u7406\u7a33\u5b9a\u70b9\"\u6982\u5ff5\u3002", "motivation": "\u5fae\u8c03\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u867d\u7136\u80fd\u63d0\u5347\u4efb\u52a1\u6027\u80fd\uff0c\u4f46\u4f1a\u5fae\u5999\u5730\u6539\u53d8\u6a21\u578b\u4f9d\u8d56\u7684\u8bc1\u636e\u4f9d\u636e\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u76d1\u63a7\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u51b3\u7b56\u4f9d\u636e\u5982\u4f55\u6f14\u53d8\u3002", "method": "\u63d0\u51fa\u8bad\u7ec3\u65f6\u89e3\u91ca\u6027\u89c6\u89d2\uff0c\u8ddf\u8e2a\u5fae\u8c03\u5404epoch\u4e2dtoken\u7ea7\u5f52\u56e0\u7684\u53d8\u5316\u3002\u5b9a\u4e49\"\u89e3\u91ca\u6f02\u79fb\"\u4e3a\u56fa\u5b9a\u63a2\u6d4b\u96c6\u4e0a\u5f52\u4e00\u5316token\u5f52\u56e0\u7684epoch\u95f4\u53d8\u5316\uff0c\u5f15\u5165\"\u63a8\u7406\u7a33\u5b9a\u70b9\"\u4f5c\u4e3a\u6f02\u79fb\u9996\u6b21\u8fdb\u5165\u6301\u7eed\u4f4e\u7a33\u5b9a\u72b6\u6001\u7684\u6700\u65e9epoch\u3002", "result": "\u5728\u591a\u4e2a\u8f7b\u91cf\u7ea7transformer\u5206\u7c7b\u5668\u548c\u57fa\u51c6\u5206\u7c7b\u4efb\u52a1\u4e0a\uff0c\u6f02\u79fb\u901a\u5e38\u5728\u8bad\u7ec3\u65e9\u671f\u5c31\u8fdb\u5165\u4f4e\u7a33\u5b9a\u72b6\u6001\uff0c\u800c\u9a8c\u8bc1\u51c6\u786e\u7387\u4ec5\u53d1\u751f\u5fae\u5c0f\u53d8\u5316\u3002\u5728\u53d7\u63a7\u7684\u6377\u5f84\u8bbe\u7f6e\u4e2d\uff0c\u5f52\u56e0\u52a8\u6001\u63ed\u793a\u4e86\u6a21\u578b\u5bf9\u6377\u5f84\u7684\u4f9d\u8d56\u589e\u52a0\uff0c\u5373\u4f7f\u9a8c\u8bc1\u51c6\u786e\u7387\u4fdd\u6301\u7ade\u4e89\u529b\u3002", "conclusion": "\u89e3\u91ca\u6f02\u79fb\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u3001\u4f4e\u6210\u672c\u7684\u8bca\u65ad\u5de5\u5177\uff0c\u7528\u4e8e\u76d1\u63a7\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u51b3\u7b56\u4f9d\u636e\u7684\u6f14\u53d8\uff0c\u5e76\u9009\u62e9\u5904\u4e8e\u7a33\u5b9a\u8bc1\u636e\u72b6\u6001\u7684\u68c0\u67e5\u70b9\u3002"}}
{"id": "2601.11783", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11783", "abs": "https://arxiv.org/abs/2601.11783", "authors": ["Murtuza N. Shergadwala"], "title": "The Stability Trap: Evaluating the Reliability of LLM-Based Instruction Adherence Auditing", "comment": null, "summary": "The enterprise governance of Generative AI (GenAI) in regulated sectors, such as Human Resources (HR), demands scalable yet reproducible auditing mechanisms. While Large Language Model (LLM)-as-a-Judge approaches offer scalability, their reliability in evaluating adherence of different types of system instructions remains unverified. This study asks: To what extent does the instruction type of an Application Under Test (AUT) influence the stability of judge evaluations? To address this, we introduce the Scoped Instruction Decomposition Framework to classify AUT instructions into Objective and Subjective types, isolating the factors that drive judge instability. We applied this framework to two representative HR GenAI applications, evaluating the stability of four judge architectures over variable runs. Our results reveal a ``Stability Trap'' characterized by a divergence between Verdict Stability and Reasoning Stability. While judges achieved near-perfect verdict agreement ($>99\\%$) for both objective and subjective evaluations, their accompanying justification traces diverged significantly. Objective instructions requiring quantitative analysis, such as word counting, exhibited reasoning stability as low as $\\approx19\\%$, driven by variances in numeric justifications. Similarly, reasoning stability for subjective instructions varied widely ($35\\%$--$83\\%$) based on evidence granularity, with feature-specific checks failing to reproduce consistent rationale. Conversely, objective instructions focusing on discrete entity extraction achieved high reasoning stability ($>90\\%$). These findings demonstrate that high verdict stability can mask fragile reasoning. Thus, we suggest that auditors scope automated evaluation protocols strictly: delegate all deterministically verifiable logic to code, while reserving LLM judges for complex semantic evaluation.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLM\u6cd5\u5b98\u8bc4\u4f30\u5b58\u5728\"\u7a33\u5b9a\u6027\u9677\u9631\"\uff1a\u867d\u7136\u5224\u51b3\u7a33\u5b9a\u6027\u9ad8\uff08>99%\uff09\uff0c\u4f46\u63a8\u7406\u7a33\u5b9a\u6027\u5dee\u5f02\u663e\u8457\uff0c\u5ba2\u89c2\u6307\u4ee4\u7684\u63a8\u7406\u7a33\u5b9a\u6027\u53ef\u4f4e\u81f319%\uff0c\u4e3b\u89c2\u6307\u4ee4\u572835%-83%\u4e4b\u95f4\u6ce2\u52a8\u3002", "motivation": "\u5728\u53d7\u76d1\u7ba1\u884c\u4e1a\uff08\u5982\u4eba\u529b\u8d44\u6e90\uff09\u4e2d\uff0c\u751f\u6210\u5f0fAI\u7684\u4f01\u4e1a\u6cbb\u7406\u9700\u8981\u53ef\u6269\u5c55\u4e14\u53ef\u590d\u73b0\u7684\u5ba1\u8ba1\u673a\u5236\u3002\u867d\u7136LLM\u4f5c\u4e3a\u6cd5\u5b98\u7684\u65b9\u6cd5\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u6027\uff0c\u4f46\u5176\u8bc4\u4f30\u4e0d\u540c\u7c7b\u578b\u7cfb\u7edf\u6307\u4ee4\u9075\u5faa\u6027\u7684\u53ef\u9760\u6027\u5c1a\u672a\u5f97\u5230\u9a8c\u8bc1\u3002", "method": "\u5f15\u5165\u8303\u56f4\u5316\u6307\u4ee4\u5206\u89e3\u6846\u67b6\uff0c\u5c06\u5e94\u7528\u6307\u4ee4\u5206\u7c7b\u4e3a\u5ba2\u89c2\u548c\u4e3b\u89c2\u7c7b\u578b\uff0c\u9694\u79bb\u5bfc\u81f4\u6cd5\u5b98\u4e0d\u7a33\u5b9a\u7684\u56e0\u7d20\u3002\u5c06\u8be5\u6846\u67b6\u5e94\u7528\u4e8e\u4e24\u4e2a\u4ee3\u8868\u6027\u7684\u4eba\u529b\u8d44\u6e90\u751f\u6210\u5f0fAI\u5e94\u7528\uff0c\u8bc4\u4f30\u56db\u79cd\u6cd5\u5b98\u67b6\u6784\u5728\u53ef\u53d8\u8fd0\u884c\u4e2d\u7684\u7a33\u5b9a\u6027\u3002", "result": "\u63ed\u793a\u4e86\"\u7a33\u5b9a\u6027\u9677\u9631\"\u73b0\u8c61\uff1a\u5224\u51b3\u7a33\u5b9a\u6027\u4e0e\u63a8\u7406\u7a33\u5b9a\u6027\u4e4b\u95f4\u5b58\u5728\u5206\u6b67\u3002\u5ba2\u89c2\u6307\u4ee4\uff08\u5982\u5b57\u6570\u7edf\u8ba1\uff09\u7684\u63a8\u7406\u7a33\u5b9a\u6027\u4f4e\u81f3\u7ea619%\uff0c\u4e3b\u89c2\u6307\u4ee4\u7684\u63a8\u7406\u7a33\u5b9a\u6027\u572835%-83%\u4e4b\u95f4\u6ce2\u52a8\uff0c\u800c\u79bb\u6563\u5b9e\u4f53\u63d0\u53d6\u7684\u5ba2\u89c2\u6307\u4ee4\u63a8\u7406\u7a33\u5b9a\u6027\u8d85\u8fc790%\u3002", "conclusion": "\u9ad8\u5224\u51b3\u7a33\u5b9a\u6027\u53ef\u80fd\u63a9\u76d6\u8106\u5f31\u7684\u63a8\u7406\u8fc7\u7a0b\u3002\u5efa\u8bae\u5ba1\u8ba1\u4eba\u5458\u4e25\u683c\u9650\u5b9a\u81ea\u52a8\u5316\u8bc4\u4f30\u534f\u8bae\uff1a\u5c06\u6240\u6709\u53ef\u786e\u5b9a\u6027\u9a8c\u8bc1\u7684\u903b\u8f91\u59d4\u6258\u7ed9\u4ee3\u7801\uff0c\u540c\u65f6\u4fdd\u7559LLM\u6cd5\u5b98\u7528\u4e8e\u590d\u6742\u7684\u8bed\u4e49\u8bc4\u4f30\u3002"}}
{"id": "2601.11683", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.11683", "abs": "https://arxiv.org/abs/2601.11683", "authors": ["Zhuoyi Shang", "Jiasen Li", "Pengzhen Chen", "Yanwei Liu", "Xiaoyan Gu", "Weiping Wang"], "title": "Attesting Model Lineage by Consisted Knowledge Evolution with Fine-Tuning Trajectory", "comment": "Accepted to the 35th USENIX Security Symposium (USENIX Security 2026)", "summary": "The fine-tuning technique in deep learning gives rise to an emerging lineage relationship among models. This lineage provides a promising perspective for addressing security concerns such as unauthorized model redistribution and false claim of model provenance, which are particularly pressing in \\textcolor{blue}{open-weight model} libraries where robust lineage verification mechanisms are often lacking. Existing approaches to model lineage detection primarily rely on static architectural similarities, which are insufficient to capture the dynamic evolution of knowledge that underlies true lineage relationships. Drawing inspiration from the genetic mechanism of human evolution, we tackle the problem of model lineage attestation by verifying the joint trajectory of knowledge evolution and parameter modification. To this end, we propose a novel model lineage attestation framework. In our framework, model editing is first leveraged to quantify parameter-level changes introduced by fine-tuning. Subsequently, we introduce a novel knowledge vectorization mechanism that refines the evolved knowledge within the edited models into compact representations by the assistance of probe samples. The probing strategies are adapted to different types of model families. These embeddings serve as the foundation for verifying the arithmetic consistency of knowledge relationships across models, thereby enabling robust attestation of model lineage. Extensive experimental evaluations demonstrate the effectiveness and resilience of our approach in a variety of adversarial scenarios in the real world. Our method consistently achieves reliable lineage verification across a broad spectrum of model types, including classifiers, diffusion models, and large language models.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u77e5\u8bc6\u8fdb\u5316\u548c\u53c2\u6570\u4fee\u6539\u8054\u5408\u8f68\u8ff9\u7684\u6a21\u578b\u8c31\u7cfb\u8ba4\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u578b\u7f16\u8f91\u91cf\u5316\u53c2\u6570\u53d8\u5316\uff0c\u77e5\u8bc6\u5411\u91cf\u5316\u673a\u5236\u63d0\u53d6\u8fdb\u5316\u77e5\u8bc6\u8868\u793a\uff0c\u9a8c\u8bc1\u77e5\u8bc6\u5173\u7cfb\u7b97\u672f\u4e00\u81f4\u6027\uff0c\u5b9e\u73b0\u53ef\u9760\u8c31\u7cfb\u9a8c\u8bc1", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u5fae\u8c03\u6280\u672f\u4ea7\u751f\u4e86\u6a21\u578b\u95f4\u7684\u8c31\u7cfb\u5173\u7cfb\uff0c\u8fd9\u4e3a\u89e3\u51b3\u6a21\u578b\u672a\u6388\u6743\u5206\u53d1\u548c\u6765\u6e90\u865a\u5047\u58f0\u660e\u7b49\u5b89\u5168\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u9759\u6001\u67b6\u6784\u76f8\u4f3c\u6027\uff0c\u4e0d\u8db3\u4ee5\u6355\u6349\u77e5\u8bc6\u52a8\u6001\u6f14\u5316\uff0c\u65e0\u6cd5\u53cd\u6620\u771f\u6b63\u7684\u8c31\u7cfb\u5173\u7cfb", "method": "1) \u5229\u7528\u6a21\u578b\u7f16\u8f91\u91cf\u5316\u5fae\u8c03\u5f15\u5165\u7684\u53c2\u6570\u7ea7\u53d8\u5316\uff1b2) \u63d0\u51fa\u77e5\u8bc6\u5411\u91cf\u5316\u673a\u5236\uff0c\u501f\u52a9\u63a2\u9488\u6837\u672c\u5c06\u7f16\u8f91\u6a21\u578b\u4e2d\u8fdb\u5316\u7684\u77e5\u8bc6\u63d0\u70bc\u4e3a\u7d27\u51d1\u8868\u793a\uff0c\u63a2\u9488\u7b56\u7565\u9002\u5e94\u4e0d\u540c\u7c7b\u578b\u6a21\u578b\u5bb6\u65cf\uff1b3) \u57fa\u4e8e\u8fd9\u4e9b\u5d4c\u5165\u9a8c\u8bc1\u6a21\u578b\u95f4\u77e5\u8bc6\u5173\u7cfb\u7684\u7b97\u672f\u4e00\u81f4\u6027", "result": "\u5728\u591a\u79cd\u73b0\u5b9e\u4e16\u754c\u5bf9\u6297\u573a\u666f\u4e0b\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\u8be5\u65b9\u6cd5\u6709\u6548\u4e14\u5177\u6709\u97e7\u6027\uff0c\u5728\u5305\u62ec\u5206\u7c7b\u5668\u3001\u6269\u6563\u6a21\u578b\u548c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5185\u7684\u5e7f\u6cdb\u6a21\u578b\u7c7b\u578b\u4e2d\u90fd\u80fd\u5b9e\u73b0\u53ef\u9760\u7684\u8c31\u7cfb\u9a8c\u8bc1", "conclusion": "\u901a\u8fc7\u9a8c\u8bc1\u77e5\u8bc6\u8fdb\u5316\u548c\u53c2\u6570\u4fee\u6539\u7684\u8054\u5408\u8f68\u8ff9\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u6a21\u578b\u8c31\u7cfb\u8ba4\u8bc1\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5f00\u653e\u6743\u91cd\u6a21\u578b\u5e93\u4e2d\u7f3a\u4e4f\u7a33\u5065\u8c31\u7cfb\u9a8c\u8bc1\u673a\u5236\u7684\u5b89\u5168\u95ee\u9898"}}
{"id": "2601.11835", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.11835", "abs": "https://arxiv.org/abs/2601.11835", "authors": ["Yufan Zhang", "Jaromir Savelka", "Seth Goldstein", "Michael Conway"], "title": "Changes in Coding Behavior and Performance Since the Introduction of LLMs", "comment": null, "summary": "The widespread availability of large language models (LLMs) has changed how students engage with coding and problem-solving. While these tools may increase student productivity, they also make it more difficult for instructors to assess students' learning and effort. In this quasi-longitudinal study, we analyze five years of student source code submissions in a graduate-level cloud computing course, focusing on an assignment that remained unchanged and examining students' behavior during the period spanning five semesters before the release of ChatGPT and five semesters after.\n  Student coding behavior has changed significantly since Fall 2022. The length of their final submissions increased. Between consecutive submissions, average edit distances increased while average score improvement decreased, suggesting that both student productivity and learning have decreased after ChatGPT's release. Additionally, there are statistically significant correlations between these behavioral changes and their overall performance. Although we cannot definitively attribute them to LLM misuse, they are consistent with our hypothesis that some students are over-reliant on LLMs, which is negatively affecting their learning outcomes. Our findings raise an alarm around the first generation of graduates in the age of LLMs, calling upon both educators and employers to reflect on their evaluation methods for genuine expertise and productivity.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86ChatGPT\u53d1\u5e03\u524d\u540e\u4e94\u5e74\u95f4\u7814\u7a76\u751f\u4e91\u8ba1\u7b97\u8bfe\u7a0b\u7684\u5b66\u751f\u4ee3\u7801\u63d0\u4ea4\u884c\u4e3a\uff0c\u53d1\u73b0\u5b66\u751f\u7f16\u7a0b\u884c\u4e3a\u53d1\u751f\u663e\u8457\u53d8\u5316\uff1a\u6700\u7ec8\u63d0\u4ea4\u4ee3\u7801\u957f\u5ea6\u589e\u52a0\uff0c\u8fde\u7eed\u63d0\u4ea4\u95f4\u7684\u7f16\u8f91\u8ddd\u79bb\u589e\u5927\u4f46\u5206\u6570\u63d0\u5347\u51cf\u5c11\uff0c\u8868\u660e\u751f\u4ea7\u529b\u548c\u5b66\u4e60\u6548\u679c\u5747\u4e0b\u964d\uff0c\u8fd9\u53ef\u80fd\u4e0e\u5b66\u751f\u5bf9LLMs\u7684\u8fc7\u5ea6\u4f9d\u8d56\u6709\u5173\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5e7f\u6cdb\u4f7f\u7528\uff0c\u5b66\u751f\u4e0e\u7f16\u7a0b\u548c\u95ee\u9898\u89e3\u51b3\u7684\u4e92\u52a8\u65b9\u5f0f\u53d1\u751f\u4e86\u53d8\u5316\u3002\u867d\u7136\u8fd9\u4e9b\u5de5\u5177\u53ef\u80fd\u63d0\u9ad8\u5b66\u751f\u751f\u4ea7\u529b\uff0c\u4f46\u4e5f\u4f7f\u6559\u5e08\u8bc4\u4f30\u5b66\u751f\u5b66\u4e60\u548c\u52aa\u529b\u53d8\u5f97\u66f4\u52a0\u56f0\u96be\u3002\u7814\u7a76\u8005\u5e0c\u671b\u4e86\u89e3ChatGPT\u53d1\u5e03\u524d\u540e\u5b66\u751f\u7f16\u7a0b\u884c\u4e3a\u7684\u53d8\u5316\u53ca\u5176\u5bf9\u5b66\u4e60\u6210\u679c\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u51c6\u7eb5\u5411\u7814\u7a76\u65b9\u6cd5\uff0c\u5206\u6790\u7814\u7a76\u751f\u4e91\u8ba1\u7b97\u8bfe\u7a0b\u4e94\u5e74\u95f4\u7684\u5b66\u751f\u6e90\u4ee3\u7801\u63d0\u4ea4\u6570\u636e\u3002\u7814\u7a76\u805a\u7126\u4e8e\u4e00\u4e2a\u4fdd\u6301\u4e0d\u53d8\u7684\u4f5c\u4e1a\u4efb\u52a1\uff0c\u6bd4\u8f83ChatGPT\u53d1\u5e03\u524d\u4e94\u4e2a\u5b66\u671f\u548c\u53d1\u5e03\u540e\u4e94\u4e2a\u5b66\u671f\u7684\u5b66\u751f\u884c\u4e3a\u3002\u901a\u8fc7\u5206\u6790\u6700\u7ec8\u63d0\u4ea4\u4ee3\u7801\u957f\u5ea6\u3001\u8fde\u7eed\u63d0\u4ea4\u95f4\u7684\u7f16\u8f91\u8ddd\u79bb\u3001\u5206\u6570\u6539\u8fdb\u7b49\u6307\u6807\u6765\u8bc4\u4f30\u53d8\u5316\u3002", "result": "\u81ea2022\u5e74\u79cb\u5b63\u4ee5\u6765\uff0c\u5b66\u751f\u7f16\u7a0b\u884c\u4e3a\u53d1\u751f\u663e\u8457\u53d8\u5316\uff1a\u6700\u7ec8\u63d0\u4ea4\u4ee3\u7801\u957f\u5ea6\u589e\u52a0\uff1b\u8fde\u7eed\u63d0\u4ea4\u95f4\u7684\u5e73\u5747\u7f16\u8f91\u8ddd\u79bb\u589e\u5927\uff0c\u800c\u5e73\u5747\u5206\u6570\u6539\u8fdb\u51cf\u5c11\uff1b\u8fd9\u4e9b\u884c\u4e3a\u53d8\u5316\u4e0e\u6574\u4f53\u8868\u73b0\u5b58\u5728\u7edf\u8ba1\u5b66\u663e\u8457\u76f8\u5173\u6027\u3002\u7ed3\u679c\u8868\u660e\u5b66\u751f\u751f\u4ea7\u529b\u548c\u5b66\u4e60\u6548\u679c\u5728ChatGPT\u53d1\u5e03\u540e\u5747\u6709\u6240\u4e0b\u964d\u3002", "conclusion": "\u867d\u7136\u4e0d\u80fd\u660e\u786e\u5f52\u56e0\u4e8eLLMs\u7684\u6ee5\u7528\uff0c\u4f46\u7814\u7a76\u7ed3\u679c\u4e0e\"\u90e8\u5206\u5b66\u751f\u8fc7\u5ea6\u4f9d\u8d56LLMs\u4ece\u800c\u8d1f\u9762\u5f71\u54cd\u5b66\u4e60\u6210\u679c\"\u7684\u5047\u8bbe\u4e00\u81f4\u3002\u7814\u7a76\u5bf9LLMs\u65f6\u4ee3\u7684\u7b2c\u4e00\u4ee3\u6bd5\u4e1a\u751f\u53d1\u51fa\u8b66\u793a\uff0c\u547c\u5401\u6559\u80b2\u8005\u548c\u96c7\u4e3b\u53cd\u601d\u8bc4\u4f30\u771f\u6b63\u4e13\u4e1a\u77e5\u8bc6\u548c\u751f\u4ea7\u529b\u7684\u65b9\u6cd5\u3002"}}
{"id": "2601.11696", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.11696", "abs": "https://arxiv.org/abs/2601.11696", "authors": ["Annika Wilde", "Samira Briongos", "Claudio Soriente", "Ghassan Karame"], "title": "On Abnormal Execution Timing of Conditional Jump Instructions", "comment": "To appear in the Proceedings of the ACM on Measurement and Analysis of Computing Systems (POMACS), March 2026 Issue, presented at the ACM SIGMETRICS 2026 conference", "summary": "An extensive line of work on modern computing architectures has shown that the execution time of instructions can (i) depend on the operand of the instruction or (ii) be influenced by system optimizations, e.g., branch prediction and speculative execution paradigms.\n  In this paper, we systematically measure and analyze timing variabilities in conditional jump instructions that can be macro-fused with a preceding instruction, depending on their placement within the binary. Our measurements indicate that these timing variations stem from the micro-op cache placement and the jump's offset in the L1 instruction cache of modern processors. We demonstrate that this behavior is consistent across multiple microarchitectures, including Skylake, Coffee Lake, and Kaby Lake, as well as various real-world implementations. We confirm the prevalence of this variability through extensive experiments on a large-scale set of popular binaries, including libraries from Ubuntu 24.04, Windows 10 Pro, and several open-source cryptographic libraries. We also show that one can easily avoid this timing variability by ensuring that macro-fusible instructions are 32-byte aligned - an approach initially suggested in 2019 by Intel in an overlooked short report. We quantify the performance impact of this approach across the cryptographic libraries, showing a speedup of 2.15% on average (and up to 10.54%) when avoiding the timing variability. As a by-product, we show that this variability can be exploited as a covert channel, achieving a maximum throughput of 16.14 Mbps.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u73b0\u4ee3\u5904\u7406\u5668\u4e2d\u6761\u4ef6\u8df3\u8f6c\u6307\u4ee4\u7684\u6267\u884c\u65f6\u95f4\u4f1a\u56e0\u64cd\u4f5c\u6570\u548c\u7cfb\u7edf\u4f18\u5316\u800c\u4ea7\u751f\u53d8\u5316\uff0c\u8fd9\u79cd\u65f6\u5e8f\u53d8\u5316\u6e90\u4e8e\u5fae\u64cd\u4f5c\u7f13\u5b58\u653e\u7f6e\u548cL1\u6307\u4ee4\u7f13\u5b58\u4e2d\u7684\u8df3\u8f6c\u504f\u79fb\uff0c\u53ef\u4ee5\u901a\u8fc732\u5b57\u8282\u5bf9\u9f50\u6765\u907f\u514d\uff0c\u5e76\u80fd\u63d0\u5347\u52a0\u5bc6\u5e93\u6027\u80fd2.15%\u5e73\u5747\uff08\u6700\u9ad810.54%\uff09\uff0c\u540c\u65f6\u53ef\u4f5c\u4e3a16.14 Mbps\u7684\u9690\u853d\u4fe1\u9053\u3002", "motivation": "\u73b0\u4ee3\u8ba1\u7b97\u67b6\u6784\u4e2d\u6307\u4ee4\u6267\u884c\u65f6\u95f4\u4f1a\u53d7\u64cd\u4f5c\u6570\u548c\u7cfb\u7edf\u4f18\u5316\uff08\u5982\u5206\u652f\u9884\u6d4b\u548c\u63a8\u6d4b\u6267\u884c\uff09\u5f71\u54cd\uff0c\u672c\u6587\u65e8\u5728\u7cfb\u7edf\u6d4b\u91cf\u548c\u5206\u6790\u6761\u4ef6\u8df3\u8f6c\u6307\u4ee4\u7684\u65f6\u5e8f\u53d8\u5316\u7279\u6027\uff0c\u7279\u522b\u662f\u5728\u5b8f\u878d\u5408\u6307\u4ee4\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u7cfb\u7edf\u6d4b\u91cf\u548c\u5206\u6790\u6761\u4ef6\u8df3\u8f6c\u6307\u4ee4\u7684\u65f6\u5e8f\u53d8\u5316\uff0c\u7814\u7a76\u5b8f\u878d\u5408\u6307\u4ee4\u5728\u4e8c\u8fdb\u5236\u4e2d\u7684\u653e\u7f6e\u4f4d\u7f6e\u5f71\u54cd\uff0c\u6d4b\u91cf\u5fae\u64cd\u4f5c\u7f13\u5b58\u653e\u7f6e\u548cL1\u6307\u4ee4\u7f13\u5b58\u8df3\u8f6c\u504f\u79fb\u7684\u5f71\u54cd\uff0c\u5728Skylake\u3001Coffee Lake\u3001Kaby Lake\u7b49\u591a\u79cd\u5fae\u67b6\u6784\u4e0a\u8fdb\u884c\u9a8c\u8bc1\uff0c\u5e76\u5728Ubuntu 24.04\u3001Windows 10 Pro\u548c\u591a\u4e2a\u5f00\u6e90\u52a0\u5bc6\u5e93\u7684\u5927\u89c4\u6a21\u4e8c\u8fdb\u5236\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u65f6\u5e8f\u53d8\u5316\u5728\u4e0d\u540c\u5fae\u67b6\u6784\u548c\u5b9e\u9645\u5b9e\u73b0\u4e2d\u8868\u73b0\u4e00\u81f4\uff0c\u901a\u8fc732\u5b57\u8282\u5bf9\u9f50\u5b8f\u878d\u5408\u6307\u4ee4\u53ef\u4ee5\u907f\u514d\u8fd9\u79cd\u65f6\u5e8f\u53d8\u5316\uff0c\u5728\u52a0\u5bc6\u5e93\u4e2d\u5e73\u5747\u63d0\u5347\u6027\u80fd2.15%\uff08\u6700\u9ad810.54%\uff09\uff0c\u540c\u65f6\u8fd9\u79cd\u65f6\u5e8f\u53d8\u5316\u53ef\u4f5c\u4e3a\u9690\u853d\u4fe1\u9053\uff0c\u6700\u5927\u541e\u5410\u91cf\u8fbe16.14 Mbps\u3002", "conclusion": "\u73b0\u4ee3\u5904\u7406\u5668\u4e2d\u6761\u4ef6\u8df3\u8f6c\u6307\u4ee4\u7684\u65f6\u5e8f\u53d8\u5316\u662f\u666e\u904d\u5b58\u5728\u7684\uff0c\u6e90\u4e8e\u5fae\u64cd\u4f5c\u7f13\u5b58\u548cL1\u6307\u4ee4\u7f13\u5b58\u673a\u5236\uff0c\u901a\u8fc732\u5b57\u8282\u5bf9\u9f50\u53ef\u4ee5\u6709\u6548\u907f\u514d\u8fd9\u79cd\u53d8\u5316\u5e76\u63d0\u5347\u6027\u80fd\uff0c\u540c\u65f6\u8fd9\u79cd\u53d8\u5316\u4e5f\u53ef\u88ab\u5229\u7528\u4e3a\u9690\u853d\u4fe1\u9053\u3002"}}
{"id": "2601.11836", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.11836", "abs": "https://arxiv.org/abs/2601.11836", "authors": ["Finn Hackett", "Evan Wrench", "Peter Macko", "A. Jesse Jiryu Davis", "Yuanhao Wei", "Ivan Beschastnikh"], "title": "Trace Validation of Unmodified Concurrent Systems with OmniLink", "comment": null, "summary": "Concurrent systems are notoriously difficult to validate: subtle bugs may only manifest under rare thread interleavings, and existing tools often require intrusive instrumentation or unrealistic execution models. We present OmniLink, a new methodology for validating concurrent implementations against high-level specifications in TLA+. Unlike prior TLA+ based approaches which use a technique called trace validation, OmniLink treats system events as black boxes with a timebox in which they occurred and a meaning in TLA+, solving for a logical total order of actions. Unlike prior approaches based on linearizability checking, which already solves for total orders of actions with timeboxes, OmniLink uses a flexible specification language, and offers a different linearizability checking method based on off-the-shelf model checking. OmniLink offers different features compared existing linearizability checking tools, and we show that it outperforms the state of the art on large scale validation tasks.\n  Our evaluation validates WiredTiger, a state-of-the-art industrial database storage layer, as well as Balanced Augmented Tree (BAT), a state-of-the art lock-free data structure from the research community, and ConcurrentQueue, a popular lock-free queue featuring aggressive performance optimizations. We use OmniLink to improve WiredTiger's existing TLA+ model, as well as develop new TLA+ models that closely match the behavior of the modeled systems, including non-linearizable behaviors. OmniLink is able to find known bugs injected into the systems under test, as well as help discover two previously unknown bugs (1 in BAT, 1 in ConcurrentQueue), which we have confirmed with the authors of those systems.", "AI": {"tldr": "OmniLink\u662f\u4e00\u79cd\u65b0\u7684\u5e76\u53d1\u7cfb\u7edf\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u4f7f\u7528TLA+\u89c4\u8303\u9a8c\u8bc1\u5b9e\u73b0\uff0c\u901a\u8fc7\u6c42\u89e3\u903b\u8f91\u5168\u5e8f\u6765\u68c0\u6d4b\u5e76\u53d1\u9519\u8bef\uff0c\u5728\u5de5\u4e1a\u7ea7\u6570\u636e\u5e93\u548c\u6570\u636e\u7ed3\u6784\u9a8c\u8bc1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5e76\u53d1\u7cfb\u7edf\u9a8c\u8bc1\u56f0\u96be\uff0c\u73b0\u6709\u5de5\u5177\u9700\u8981\u4fb5\u5165\u5f0f\u63d2\u6869\u6216\u4e0d\u73b0\u5b9e\u7684\u6267\u884c\u6a21\u578b\uff0c\u96be\u4ee5\u68c0\u6d4b\u7f55\u89c1\u7ebf\u7a0b\u4ea4\u9519\u5bfc\u81f4\u7684\u5fae\u5999\u9519\u8bef\u3002", "method": "OmniLink\u5c06\u7cfb\u7edf\u4e8b\u4ef6\u89c6\u4e3a\u9ed1\u76d2\uff0c\u5305\u542b\u65f6\u95f4\u7a97\u53e3\u548cTLA+\u8bed\u4e49\uff0c\u901a\u8fc7\u6c42\u89e3\u903b\u8f91\u5168\u5e8f\u6765\u9a8c\u8bc1\u5b9e\u73b0\u662f\u5426\u7b26\u5408\u9ad8\u5c42\u89c4\u8303\uff0c\u4f7f\u7528\u73b0\u6210\u7684\u6a21\u578b\u68c0\u67e5\u5668\u8fdb\u884c\u7ebf\u6027\u5316\u68c0\u67e5\u3002", "result": "\u6210\u529f\u9a8c\u8bc1\u4e86WiredTiger\u5de5\u4e1a\u6570\u636e\u5e93\u3001BAT\u65e0\u9501\u6570\u636e\u7ed3\u6784\u548cConcurrentQueue\u65e0\u9501\u961f\u5217\uff0c\u53d1\u73b0\u4e86\u5df2\u77e5\u9519\u8bef\u548c\u4e24\u4e2a\u5148\u524d\u672a\u77e5\u7684\u9519\u8bef\uff08BAT\u548cConcurrentQueue\u5404\u4e00\u4e2a\uff09\u3002", "conclusion": "OmniLink\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u3001\u9ad8\u6548\u7684\u5e76\u53d1\u7cfb\u7edf\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u80fd\u591f\u5904\u7406\u975e\u7ebf\u6027\u5316\u884c\u4e3a\uff0c\u5728\u5927\u89c4\u6a21\u9a8c\u8bc1\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002"}}
{"id": "2601.11745", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.11745", "abs": "https://arxiv.org/abs/2601.11745", "authors": ["Daniel Moghimi", "Alexandru-Cosmin Mihai", "Borbala Benko", "Catherine Vlasov", "Elie Bursztein", "Kurt Thomas", "Laszlo Siroki", "Pedro Barbosa", "Remi Audebert"], "title": "DROIDCCT: Cryptographic Compliance Test via Trillion-Scale Measurement", "comment": "ACSAC 2025", "summary": "We develop DroidCCT, a distributed test framework to evaluate the scale of a wide range of failures/bugs in cryptography for end users. DroidCCT relies on passive analysis of artifacts from the execution of cryptographic operations in the Android ecosystem to identify weak implementations. We collect trillions of samples from cryptographic operations of Android Keystore on half a billion devices and apply severalanalysis techniques to evaluate the quality of cryptographic output from these devices and their underlying implementations. Our study reveals several patterns of bugs and weakness in cryptographic implementations from various manufacturers and chipsets. We show that the heterogeneous nature of cryptographic implementations results in non-uniform availability and reliability of various cryptographic functions. More importantly, flaws such as the use of weakly-generated random parameters, and timing side channels may surface across deployments of cryptography. Our results highlight the importance of fault- and side-channel-resistant cryptography and the ability to transparently and openly test these implementations.", "AI": {"tldr": "DroidCCT\u662f\u4e00\u4e2a\u5206\u5e03\u5f0f\u6d4b\u8bd5\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30Android\u751f\u6001\u7cfb\u7edf\u4e2d\u5bc6\u7801\u5b66\u5b9e\u73b0\u7684\u5404\u79cd\u6545\u969c\u548c\u6f0f\u6d1e\u89c4\u6a21\uff0c\u901a\u8fc7\u5206\u6790\u6570\u5341\u4ebf\u8bbe\u5907\u4e0a\u7684\u5bc6\u7801\u5b66\u64cd\u4f5c\u6837\u672c\uff0c\u53d1\u73b0\u4e86\u5236\u9020\u5546\u548c\u82af\u7247\u7ec4\u4e4b\u95f4\u7684\u5b9e\u73b0\u5dee\u5f02\u548c\u5b89\u5168\u9690\u60a3\u3002", "motivation": "\u8bc4\u4f30Android\u751f\u6001\u7cfb\u7edf\u4e2d\u5bc6\u7801\u5b66\u5b9e\u73b0\u7684\u6545\u969c\u548c\u6f0f\u6d1e\u89c4\u6a21\uff0c\u4e86\u89e3\u4e0d\u540c\u5236\u9020\u5546\u548c\u82af\u7247\u7ec4\u4e4b\u95f4\u5bc6\u7801\u5b66\u5b9e\u73b0\u7684\u5f02\u8d28\u6027\u53ca\u5176\u5bf9\u5b89\u5168\u6027\u7684\u5f71\u54cd\u3002", "method": "\u5f00\u53d1DroidCCT\u5206\u5e03\u5f0f\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u88ab\u52a8\u5206\u6790Android Keystore\u5bc6\u7801\u5b66\u64cd\u4f5c\u7684\u6267\u884c\u5de5\u4ef6\uff0c\u4ece5\u4ebf\u53f0\u8bbe\u5907\u6536\u96c6\u6570\u4e07\u4ebf\u4e2a\u6837\u672c\uff0c\u5e94\u7528\u591a\u79cd\u5206\u6790\u6280\u672f\u8bc4\u4f30\u5bc6\u7801\u5b66\u8f93\u51fa\u8d28\u91cf\u548c\u5e95\u5c42\u5b9e\u73b0\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e0d\u540c\u5236\u9020\u5546\u548c\u82af\u7247\u7ec4\u5b58\u5728\u591a\u79cd\u5bc6\u7801\u5b66\u5b9e\u73b0\u6f0f\u6d1e\u6a21\u5f0f\uff0c\u5bc6\u7801\u5b66\u5b9e\u73b0\u7684\u5f02\u8d28\u6027\u5bfc\u81f4\u5404\u79cd\u5bc6\u7801\u51fd\u6570\u53ef\u7528\u6027\u548c\u53ef\u9760\u6027\u4e0d\u5747\uff0c\u53d1\u73b0\u4e86\u5f31\u968f\u673a\u53c2\u6570\u751f\u6210\u548c\u65f6\u5e8f\u4fa7\u4fe1\u9053\u7b49\u7f3a\u9677\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5bb9\u9519\u548c\u6297\u4fa7\u4fe1\u9053\u5bc6\u7801\u5b66\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u53ca\u900f\u660e\u516c\u5f00\u6d4b\u8bd5\u8fd9\u4e9b\u5b9e\u73b0\u7684\u80fd\u529b\u7684\u5fc5\u8981\u6027\uff0c\u63ed\u793a\u4e86Android\u751f\u6001\u7cfb\u7edf\u5bc6\u7801\u5b66\u5b9e\u73b0\u7684\u5b89\u5168\u9690\u60a3\u3002"}}
{"id": "2601.11786", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.11786", "abs": "https://arxiv.org/abs/2601.11786", "authors": ["Taehyun Noh", "Yingchen Wang", "Tal Garfinkel", "Mahesh Madhav", "Daniel Moghimi", "Mattan Erez", "Shravan Narayan"], "title": "ARM MTE Performance in Practice (Extended Version)", "comment": "Accepted at Usenix Security 2026", "summary": "We present the first comprehensive analysis of ARM MTE hardware performance on four different microarchitectures: ARM Big (A7x), Little (A5x), and Performance (Cortex-X) cores on the Google Pixel 8 and Pixel 9, and on Ampere Computing's AmpereOne CPU core. We also include preliminary analysis of MTE on Apple's M5 chip. We investigate performance in MTE's primary application -- probabilistic memory safety -- on both SPEC CPU benchmarks and in server workloads such as RocksDB, Nginx, PostgreSQL, and Memcached. While MTE often exhibits modest overheads, we also see performance slowdowns up to 6.64x on certain benchmarks. We identify the microarchitectural cause of these overheads and where they can be addressed in future processors. We then analyze MTE's performance for more specialized security applications such as memory tracing, time-of-check time-of-use prevention, sandboxing, and CFI. In some of these cases, MTE offers significant advantages today, while the benefits for other cases are negligible or will depend on future hardware. Finally, we explore where prior work characterizing MTE performance has either been incomplete or incorrect due to methodological or experimental errors.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u5168\u9762\u5206\u6790\u4e86ARM MTE\u786c\u4ef6\u5728\u56db\u79cd\u4e0d\u540c\u5fae\u67b6\u6784\u4e0a\u7684\u6027\u80fd\u8868\u73b0\uff0c\u5305\u62ecGoogle Pixel 8/9\u7684A7x\u3001A5x\u3001Cortex-X\u6838\u5fc3\uff0cAmpereOne CPU\u6838\u5fc3\uff0c\u4ee5\u53ca\u82f9\u679cM5\u82af\u7247\u7684\u521d\u6b65\u5206\u6790\u3002\u7814\u7a76\u53d1\u73b0MTE\u5728\u5185\u5b58\u5b89\u5168\u5e94\u7528\u4e2d\u901a\u5e38\u6709\u9002\u5ea6\u5f00\u9500\uff0c\u4f46\u5728\u67d0\u4e9b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6027\u80fd\u4e0b\u964d\u53ef\u8fbe6.64\u500d\u3002", "motivation": "MTE\uff08\u5185\u5b58\u6807\u7b7e\u6269\u5c55\uff09\u662fARMv8.5\u5f15\u5165\u7684\u786c\u4ef6\u5b89\u5168\u7279\u6027\uff0c\u4f46\u4e4b\u524d\u7f3a\u4e4f\u5bf9\u4e0d\u540c\u5fae\u67b6\u6784\u6027\u80fd\u5f71\u54cd\u7684\u5168\u9762\u5206\u6790\u3002\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3a\u5f00\u53d1\u8005\u548c\u786c\u4ef6\u8bbe\u8ba1\u8005\u63d0\u4f9b\u5b9e\u9645\u6027\u80fd\u6570\u636e\u3002", "method": "\u5728\u591a\u79cdARM\u5fae\u67b6\u6784\u4e0a\u6d4b\u8bd5MTE\u6027\u80fd\uff1aGoogle Pixel 8/9\u7684Big\uff08A7x\uff09\u3001Little\uff08A5x\uff09\u3001Performance\uff08Cortex-X\uff09\u6838\u5fc3\uff0cAmpereOne CPU\u6838\u5fc3\uff0c\u4ee5\u53ca\u82f9\u679cM5\u82af\u7247\u7684\u521d\u6b65\u5206\u6790\u3002\u4f7f\u7528SPEC CPU\u57fa\u51c6\u6d4b\u8bd5\u548c\u670d\u52a1\u5668\u5de5\u4f5c\u8d1f\u8f7d\uff08RocksDB\u3001Nginx\u3001PostgreSQL\u3001Memcached\uff09\u8bc4\u4f30MTE\u5728\u6982\u7387\u6027\u5185\u5b58\u5b89\u5168\u65b9\u9762\u7684\u6027\u80fd\u3002\u540c\u65f6\u5206\u6790MTE\u5728\u5185\u5b58\u8ffd\u8e2a\u3001TOCTOU\u9884\u9632\u3001\u6c99\u7bb1\u548cCFI\u7b49\u5b89\u5168\u5e94\u7528\u4e2d\u7684\u8868\u73b0\u3002", "result": "MTE\u901a\u5e38\u8868\u73b0\u51fa\u9002\u5ea6\u5f00\u9500\uff0c\u4f46\u5728\u67d0\u4e9b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6027\u80fd\u4e0b\u964d\u53ef\u8fbe6.64\u500d\u3002\u7814\u7a76\u8bc6\u522b\u4e86\u8fd9\u4e9b\u5f00\u9500\u7684\u5fae\u67b6\u6784\u539f\u56e0\uff0c\u5e76\u6307\u51fa\u672a\u6765\u5904\u7406\u5668\u53ef\u4ee5\u6539\u8fdb\u7684\u5730\u65b9\u3002\u5728\u67d0\u4e9b\u5b89\u5168\u5e94\u7528\u4e2d\uff0cMTE\u5df2\u63d0\u4f9b\u663e\u8457\u4f18\u52bf\uff0c\u800c\u5728\u5176\u4ed6\u60c5\u51b5\u4e0b\u4f18\u52bf\u6709\u9650\u6216\u9700\u8981\u672a\u6765\u786c\u4ef6\u652f\u6301\u3002\u7814\u7a76\u8fd8\u53d1\u73b0\u5148\u524d\u5173\u4e8eMTE\u6027\u80fd\u7684\u5de5\u4f5c\u5b58\u5728\u65b9\u6cd5\u6216\u5b9e\u9a8c\u9519\u8bef\u5bfc\u81f4\u7684\u4e0d\u5b8c\u6574\u6216\u4e0d\u6b63\u786e\u7ed3\u8bba\u3002", "conclusion": "MTE\u5728\u4e0d\u540c\u5e94\u7528\u573a\u666f\u4e2d\u7684\u6027\u80fd\u5f71\u54cd\u5dee\u5f02\u663e\u8457\uff0c\u5728\u67d0\u4e9b\u5b89\u5168\u5e94\u7528\u4e2d\u5df2\u5177\u5907\u5b9e\u7528\u4ef7\u503c\uff0c\u4f46\u5728\u901a\u7528\u8ba1\u7b97\u4e2d\u53ef\u80fd\u5e26\u6765\u663e\u8457\u6027\u80fd\u5f00\u9500\u3002\u7814\u7a76\u4e3a\u786c\u4ef6\u8bbe\u8ba1\u8005\u63d0\u4f9b\u4e86\u6539\u8fdb\u65b9\u5411\uff0c\u5e76\u7ea0\u6b63\u4e86\u5148\u524d\u7814\u7a76\u4e2d\u7684\u9519\u8bef\u7ed3\u8bba\uff0c\u4e3aMTE\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2601.11926", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11926", "abs": "https://arxiv.org/abs/2601.11926", "authors": ["Ananya Halgatti", "Shaunak Biswas", "Hiya Bhatt", "Srinivasan Rakhunathan", "Karthik Vaidhyanathan"], "title": "Harmonica: A Self-Adaptation Exemplar for Sustainable MLOps", "comment": "This paper has been accepted to SEAMS 2026 Artifact Track", "summary": "Machine learning enabled systems (MLS) often operate in settings where they regularly encounter uncertainties arising from changes in their surrounding environment. Without structured oversight, such changes can degrade model behavior, increase operational cost, and reduce the usefulness of deployed systems. Although Machine Learning Operations (MLOps) streamlines the lifecycle of ML models, it provides limited support for addressing runtime uncertainties that influence the longer term sustainability of MLS. To support continued viability, these systems need a mechanism that detects when execution drifts outside acceptable bounds and adjusts system behavior in response. Despite the growing interest in sustainable and self-adaptive MLS, there has been limited work towards exemplars that allow researchers to study these challenges in MLOps pipelines. This paper presents Harmonica, a self-adaptation exemplar built on the HarmonE approach, designed to enable the sustainable operation of such pipelines. Harmonica introduces structured adaptive control through MAPE-K loop, separating high-level adaptation policy from low-level tactic execution. It continuously monitors sustainability metrics, evaluates them against dynamic adaptation boundaries, and automatically triggers architectural tactics when thresholds are violated. We demonstrate the tool through case studies in time series regression and computer vision, examining its ability to improve system stability and reduce manual intervention. The results show that Harmonica offers a practical and reusable foundation for enabling adaptive behavior in MLS that rely on MLOps pipelines for sustained operation.", "AI": {"tldr": "Harmonica\u662f\u4e00\u4e2a\u57fa\u4e8eHarmonE\u65b9\u6cd5\u7684\u81ea\u9002\u5e94\u8303\u4f8b\uff0c\u65e8\u5728\u652f\u6301\u673a\u5668\u5b66\u4e60\u8fd0\u7ef4\u7ba1\u9053\u7684\u53ef\u6301\u7eed\u8fd0\u884c\uff0c\u901a\u8fc7MAPE-K\u5faa\u73af\u5b9e\u73b0\u7ed3\u6784\u5316\u81ea\u9002\u5e94\u63a7\u5236\uff0c\u51cf\u5c11\u624b\u52a8\u5e72\u9884\u5e76\u63d0\u9ad8\u7cfb\u7edf\u7a33\u5b9a\u6027\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u5728\u8fd0\u884c\u73af\u5883\u4e2d\u7ecf\u5e38\u9762\u4e34\u4e0d\u786e\u5b9a\u6027\u53d8\u5316\uff0c\u8fd9\u4e9b\u53d8\u5316\u53ef\u80fd\u964d\u4f4e\u6a21\u578b\u6027\u80fd\u3001\u589e\u52a0\u8fd0\u8425\u6210\u672c\u5e76\u51cf\u5c11\u7cfb\u7edf\u5b9e\u7528\u6027\u3002\u867d\u7136MLOps\u7b80\u5316\u4e86ML\u6a21\u578b\u751f\u547d\u5468\u671f\uff0c\u4f46\u5bf9\u5f71\u54cdMLS\u957f\u671f\u53ef\u6301\u7eed\u6027\u7684\u8fd0\u884c\u65f6\u4e0d\u786e\u5b9a\u6027\u652f\u6301\u6709\u9650\u3002\u9700\u8981\u4e00\u79cd\u673a\u5236\u6765\u68c0\u6d4b\u6267\u884c\u6f02\u79fb\u5e76\u8c03\u6574\u7cfb\u7edf\u884c\u4e3a\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u7814\u7a76\u8fd9\u4e9b\u6311\u6218\u7684\u8303\u4f8b\u3002", "method": "Harmonica\u57fa\u4e8eHarmonE\u65b9\u6cd5\u6784\u5efa\uff0c\u91c7\u7528MAPE-K\u5faa\u73af\u5b9e\u73b0\u7ed3\u6784\u5316\u81ea\u9002\u5e94\u63a7\u5236\uff0c\u5c06\u9ad8\u7ea7\u81ea\u9002\u5e94\u7b56\u7565\u4e0e\u4f4e\u7ea7\u6218\u672f\u6267\u884c\u5206\u79bb\u3002\u6301\u7eed\u76d1\u63a7\u53ef\u6301\u7eed\u6027\u6307\u6807\uff0c\u6839\u636e\u52a8\u6001\u81ea\u9002\u5e94\u8fb9\u754c\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u5728\u9608\u503c\u8fdd\u53cd\u65f6\u81ea\u52a8\u89e6\u53d1\u67b6\u6784\u6218\u672f\u3002", "result": "\u901a\u8fc7\u65f6\u95f4\u5e8f\u5217\u56de\u5f52\u548c\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793a\u4e86Harmonica\u80fd\u591f\u63d0\u9ad8\u7cfb\u7edf\u7a33\u5b9a\u6027\u5e76\u51cf\u5c11\u624b\u52a8\u5e72\u9884\u3002\u7ed3\u679c\u8868\u660eHarmonica\u4e3a\u4f9d\u8d56MLOps\u7ba1\u9053\u6301\u7eed\u8fd0\u884c\u7684MLS\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u4e14\u53ef\u91cd\u7528\u7684\u81ea\u9002\u5e94\u884c\u4e3a\u57fa\u7840\u3002", "conclusion": "Harmonica\u63d0\u4f9b\u4e86\u4e00\u4e2a\u652f\u6301\u673a\u5668\u5b66\u4e60\u8fd0\u7ef4\u7ba1\u9053\u53ef\u6301\u7eed\u8fd0\u884c\u7684\u81ea\u9002\u5e94\u8303\u4f8b\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u81ea\u9002\u5e94\u63a7\u5236\u673a\u5236\uff0c\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u8fd0\u884c\u65f6\u4e0d\u786e\u5b9a\u6027\uff0c\u4e3a\u7814\u7a76\u81ea\u9002\u5e94MLS\u5728MLOps\u73af\u5883\u4e2d\u7684\u6311\u6218\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2601.11838", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2601.11838", "abs": "https://arxiv.org/abs/2601.11838", "authors": ["Hao Lyu", "Jingzheng Wu", "Xiang Ling", "Yicheng Zhong", "Zhiyuan Li", "Tianyue Luo"], "title": "SimFuzz: Similarity-guided Block-level Mutation for RISC-V Processor Fuzzing", "comment": "7 pages, 5 figures", "summary": "The Instruction Set Architecture (ISA) defines processor operations and serves as the interface between hardware and software. As an open ISA, RISC-V lowers the barriers to processor design and encourages widespread adoption, but also exposes processors to security risks such as functional bugs. Processor fuzzing is a powerful technique for automatically detecting these bugs. However, existing fuzzing methods suffer from two main limitations. First, their emphasis on redundant test case generation causes them to overlook cross-processor corner cases. Second, they rely too heavily on coverage guidance. Current coverage metrics are biased and inefficient, and become ineffective once coverage growth plateaus. To overcome these limitations, we propose SimFuzz, a fuzzing framework that constructs a high-quality seed corpus from historical bug-triggering inputs and employs similarity-guided, block-level mutation to efficiently explore the processor input space. By introducing instruction similarity, SimFuzz expands the input space around seeds while preserving control-flow structure, enabling deeper exploration without relying on coverage feedback. We evaluate SimFuzz on three widely used open-source RISC-V processors: Rocket, BOOM, and XiangShan, and discover 17 bugs in total, including 14 previously unknown issues, 7 of which have been assigned CVE identifiers. These bugs affect the decode and memory units, cause instruction and data errors, and can lead to kernel instability or system crashes. Experimental results show that SimFuzz achieves up to 73.22% multiplexer coverage on the high-quality seed corpus. Our findings highlight critical security bugs in mainstream RISC-V processors and offer actionable insights for improving functional verification.", "AI": {"tldr": "SimFuzz\u662f\u4e00\u4e2a\u9488\u5bf9RISC-V\u5904\u7406\u5668\u7684\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u5386\u53f2bug\u89e6\u53d1\u8f93\u5165\u6784\u5efa\u9ad8\u8d28\u91cf\u79cd\u5b50\u8bed\u6599\u5e93\uff0c\u91c7\u7528\u76f8\u4f3c\u6027\u5f15\u5bfc\u7684\u5757\u7ea7\u53d8\u5f02\u6765\u9ad8\u6548\u63a2\u7d22\u5904\u7406\u5668\u8f93\u5165\u7a7a\u95f4\uff0c\u53d1\u73b0\u4e8617\u4e2abug\uff0814\u4e2a\u65b0bug\uff0c7\u4e2a\u83b7\u5f97CVE\u7f16\u53f7\uff09\u3002", "motivation": "RISC-V\u4f5c\u4e3a\u5f00\u653eISA\u964d\u4f4e\u4e86\u5904\u7406\u5668\u8bbe\u8ba1\u95e8\u69db\uff0c\u4f46\u4e5f\u66b4\u9732\u4e86\u5b89\u5168\u98ce\u9669\u3002\u73b0\u6709\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u5c40\u9650\uff1a1\uff09\u5f3a\u8c03\u5197\u4f59\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\uff0c\u5ffd\u7565\u4e86\u8de8\u5904\u7406\u5668\u8fb9\u754c\u60c5\u51b5\uff1b2\uff09\u8fc7\u5ea6\u4f9d\u8d56\u8986\u76d6\u7387\u5f15\u5bfc\uff0c\u73b0\u6709\u8986\u76d6\u7387\u6307\u6807\u5b58\u5728\u504f\u5dee\u4e14\u6548\u7387\u4f4e\u4e0b\uff0c\u5728\u8986\u76d6\u7387\u589e\u957f\u505c\u6ede\u65f6\u5931\u6548\u3002", "method": "SimFuzz\u6846\u67b6\uff1a1\uff09\u4ece\u5386\u53f2bug\u89e6\u53d1\u8f93\u5165\u6784\u5efa\u9ad8\u8d28\u91cf\u79cd\u5b50\u8bed\u6599\u5e93\uff1b2\uff09\u91c7\u7528\u76f8\u4f3c\u6027\u5f15\u5bfc\u7684\u5757\u7ea7\u53d8\u5f02\uff0c\u901a\u8fc7\u5f15\u5165\u6307\u4ee4\u76f8\u4f3c\u6027\u5728\u4fdd\u6301\u63a7\u5236\u6d41\u7ed3\u6784\u7684\u540c\u65f6\u6269\u5c55\u8f93\u5165\u7a7a\u95f4\uff1b3\uff09\u4e0d\u4f9d\u8d56\u8986\u76d6\u7387\u53cd\u9988\uff0c\u5b9e\u73b0\u66f4\u6df1\u5c42\u6b21\u7684\u63a2\u7d22\u3002", "result": "\u5728\u4e09\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u5f00\u6e90RISC-V\u5904\u7406\u5668\uff08Rocket\u3001BOOM\u3001XiangShan\uff09\u4e0a\u8bc4\u4f30\uff0c\u5171\u53d1\u73b017\u4e2abug\uff0c\u5305\u62ec14\u4e2a\u5148\u524d\u672a\u77e5\u7684\u95ee\u9898\uff0c\u5176\u4e2d7\u4e2a\u5df2\u5206\u914dCVE\u6807\u8bc6\u7b26\u3002\u8fd9\u4e9bbug\u5f71\u54cd\u89e3\u7801\u548c\u5185\u5b58\u5355\u5143\uff0c\u5bfc\u81f4\u6307\u4ee4\u548c\u6570\u636e\u9519\u8bef\uff0c\u53ef\u80fd\u5f15\u53d1\u5185\u6838\u4e0d\u7a33\u5b9a\u6216\u7cfb\u7edf\u5d29\u6e83\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cSimFuzz\u5728\u9ad8\u8d28\u91cf\u79cd\u5b50\u8bed\u6599\u5e93\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe73.22%\u7684\u591a\u8def\u590d\u7528\u5668\u8986\u76d6\u7387\u3002", "conclusion": "SimFuzz\u514b\u670d\u4e86\u73b0\u6709\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u53d1\u73b0\u4e86\u4e3b\u6d41RISC-V\u5904\u7406\u5668\u4e2d\u7684\u5173\u952e\u5b89\u5168bug\uff0c\u4e3a\u6539\u8fdb\u529f\u80fd\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89c1\u89e3\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u76f8\u4f3c\u6027\u5f15\u5bfc\u7684\u53d8\u5f02\u7b56\u7565\uff0c\u5728\u4e0d\u4f9d\u8d56\u8986\u76d6\u7387\u53cd\u9988\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u66f4\u6df1\u5165\u7684\u5904\u7406\u5668\u8f93\u5165\u7a7a\u95f4\u63a2\u7d22\u3002"}}
{"id": "2601.11816", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11816", "abs": "https://arxiv.org/abs/2601.11816", "authors": ["Zahra Moslemi", "Keerthi Koneru", "Yen-Ting Lee", "Sheethal Kumar", "Ramesh Radhakrishnan"], "title": "POLARIS: Typed Planning and Governed Execution for Agentic AI in Back-Office Automation", "comment": "Workshop on Agentic AI Benchmarks and Applications for Enterprise Tasks: AAAI 2026", "summary": "Enterprise back office workflows require agentic systems that are auditable, policy-aligned, and operationally predictable, capabilities that generic multi-agent setups often fail to deliver. We present POLARIS (Policy-Aware LLM Agentic Reasoning for Integrated Systems), a governed orchestration framework that treats automation as typed plan synthesis and validated execution over LLM agents. A planner proposes structurally diverse, type checked directed acyclic graphs (DAGs), a rubric guided reasoning module selects a single compliant plan, and execution is guarded by validator gated checks, a bounded repair loop, and compiled policy guardrails that block or route side effects before they occur. Applied to document centric finance tasks, POLARIS produces decision grade artifacts and full execution traces while reducing human intervention. Empirically, POLARIS achieves a micro F1 of 0.81 on the SROIE dataset and, on a controlled synthetic suite, achieves 0.95 to 1.00 precision for anomaly routing with preserved audit trails. These evaluations constitute an initial benchmark for governed Agentic AI. POLARIS provides a methodological and benchmark reference for policy-aligned Agentic AI. Keywords Agentic AI, Enterprise Automation, Back-Office Tasks, Benchmarks, Governance, Typed Planning, Evaluation", "AI": {"tldr": "POLARIS\u662f\u4e00\u4e2a\u9762\u5411\u4f01\u4e1a\u540e\u53f0\u5de5\u4f5c\u6d41\u7a0b\u7684\u6cbb\u7406\u578bLLM\u667a\u80fd\u4f53\u7f16\u6392\u6846\u67b6\uff0c\u901a\u8fc7\u7c7b\u578b\u5316\u8ba1\u5212\u5408\u6210\u548c\u9a8c\u8bc1\u6267\u884c\u5b9e\u73b0\u53ef\u5ba1\u8ba1\u3001\u7b56\u7565\u5bf9\u9f50\u4e14\u64cd\u4f5c\u53ef\u9884\u6d4b\u7684\u81ea\u52a8\u5316\u7cfb\u7edf\u3002", "motivation": "\u4f01\u4e1a\u540e\u53f0\u5de5\u4f5c\u6d41\u7a0b\u9700\u8981\u53ef\u5ba1\u8ba1\u3001\u7b56\u7565\u5bf9\u9f50\u4e14\u64cd\u4f5c\u53ef\u9884\u6d4b\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u800c\u901a\u7528\u7684\u591a\u667a\u80fd\u4f53\u8bbe\u7f6e\u5f80\u5f80\u65e0\u6cd5\u6ee1\u8db3\u8fd9\u4e9b\u8981\u6c42\u3002\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u6709\u6548\u7684\u6cbb\u7406\u673a\u5236\u6765\u786e\u4fdd\u81ea\u52a8\u5316\u6d41\u7a0b\u7b26\u5408\u4f01\u4e1a\u653f\u7b56\u5e76\u4ea7\u751f\u53ef\u8ffd\u6eaf\u7684\u51b3\u7b56\u8bb0\u5f55\u3002", "method": "POLARIS\u91c7\u7528\u6cbb\u7406\u578b\u7f16\u6392\u6846\u67b6\uff0c\u5c06\u81ea\u52a8\u5316\u89c6\u4e3a\u57fa\u4e8eLLM\u667a\u80fd\u4f53\u7684\u7c7b\u578b\u5316\u8ba1\u5212\u5408\u6210\u548c\u9a8c\u8bc1\u6267\u884c\u3002\u6846\u67b6\u5305\u542b\uff1a1\uff09\u89c4\u5212\u5668\u751f\u6210\u7ed3\u6784\u591a\u6837\u3001\u7c7b\u578b\u68c0\u67e5\u7684\u6709\u5411\u65e0\u73af\u56fe\uff1b2\uff09\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u63a8\u7406\u6a21\u5757\u9009\u62e9\u5408\u89c4\u8ba1\u5212\uff1b3\uff09\u6267\u884c\u9636\u6bb5\u901a\u8fc7\u9a8c\u8bc1\u5668\u95e8\u63a7\u68c0\u67e5\u3001\u6709\u754c\u4fee\u590d\u5faa\u73af\u548c\u7f16\u8bd1\u7684\u7b56\u7565\u62a4\u680f\u6765\u963b\u6b62\u6216\u8def\u7531\u526f\u4f5c\u7528\u3002", "result": "\u5728\u6587\u6863\u4e2d\u5fc3\u91d1\u878d\u4efb\u52a1\u4e2d\uff0cPOLARIS\u80fd\u591f\u751f\u6210\u51b3\u7b56\u7ea7\u5de5\u4ef6\u548c\u5b8c\u6574\u6267\u884c\u8f68\u8ff9\uff0c\u540c\u65f6\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\u3002\u5728SROIE\u6570\u636e\u96c6\u4e0a\u8fbe\u52300.81\u7684\u5faeF1\u5206\u6570\uff0c\u5728\u53d7\u63a7\u5408\u6210\u5957\u4ef6\u4e2d\u5b9e\u73b00.95-1.00\u7684\u5f02\u5e38\u8def\u7531\u7cbe\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u5ba1\u8ba1\u8f68\u8ff9\u5b8c\u6574\u3002", "conclusion": "POLARIS\u4e3a\u7b56\u7565\u5bf9\u9f50\u7684\u667a\u80fd\u4f53AI\u63d0\u4f9b\u4e86\u65b9\u6cd5\u8bba\u548c\u57fa\u51c6\u53c2\u8003\uff0c\u5176\u8bc4\u4f30\u7ed3\u679c\u6784\u6210\u4e86\u6cbb\u7406\u578b\u667a\u80fd\u4f53AI\u7684\u521d\u6b65\u57fa\u51c6\u3002\u8be5\u6846\u67b6\u5c55\u793a\u4e86\u5728\u4f01\u4e1a\u81ea\u52a8\u5316\u73af\u5883\u4e2d\u5b9e\u73b0\u53ef\u5ba1\u8ba1\u3001\u7b56\u7565\u5408\u89c4\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2601.11972", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.11972", "abs": "https://arxiv.org/abs/2601.11972", "authors": ["Chi Thien Tran"], "title": "Enhancing Fuzz Testing Efficiency through Automated Fuzz Target Generation", "comment": "4 tables, 4 figures, 7 pages", "summary": "Fuzzing continues to be the most effective method for identifying security vulnerabilities in software. In the context of fuzz testing, the fuzzer supplies varied inputs to fuzz targets, which are designed to comprehensively exercise critical sections of the client code. Various studies have focused on optimizing and developing advanced fuzzers, such as AFL++, libFuzzer, Honggfuzz, syzkaller, ISP-Fuzzer, which have substantially enhanced vulnerability detection in widely used software and libraries. Nevertheless, achieving greater coverage necessitates improvements in both the quality and quantity of fuzz targets. In large-scale software projects and libraries -- characterized by numerous user defined functions and data types -- manual creation of fuzz targets is both labor-intensive and time-consuming. This challenge underscores the need for automated techniques not only to generate fuzz targets but also to streamline the execution and analysis of their results. In this paper, we introduce an approach to improving fuzz target generation through static analysis of library source code. The proposed method encompasses several key aspects: it analyzes source code structures to accurately construct function calls and generate fuzz targets; it maps fuzzer input data to the corresponding function parameters; it synthesizes compilation information for the fuzz targets; and it automatically collects and analyzes execution results. Our findings are demonstrated through the application of this approach to the generation of fuzz targets for C/C++ libraries.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u9759\u6001\u5206\u6790\u5e93\u6e90\u4ee3\u7801\u6765\u6539\u8fdb\u6a21\u7cca\u6d4b\u8bd5\u76ee\u6807\u751f\u6210\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u624b\u52a8\u521b\u5efa\u6a21\u7cca\u6d4b\u8bd5\u76ee\u6807\u8017\u65f6\u8d39\u529b\u7684\u95ee\u9898\u3002", "motivation": "\u6a21\u7cca\u6d4b\u8bd5\u662f\u53d1\u73b0\u8f6f\u4ef6\u5b89\u5168\u6f0f\u6d1e\u6700\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u4f46\u5927\u578b\u8f6f\u4ef6\u9879\u76ee\u4e2d\u624b\u52a8\u521b\u5efa\u6a21\u7cca\u6d4b\u8bd5\u76ee\u6807\u65e2\u8017\u65f6\u53c8\u8d39\u529b\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6a21\u7cca\u6d4b\u8bd5\u5668\u7684\u4f18\u5316\uff0c\u800c\u6a21\u7cca\u6d4b\u8bd5\u76ee\u6807\u7684\u8d28\u91cf\u548c\u6570\u91cf\u5bf9\u63d0\u9ad8\u8986\u76d6\u7387\u540c\u6837\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u9759\u6001\u5206\u6790\u5e93\u6e90\u4ee3\u7801\u7ed3\u6784\u6765\u751f\u6210\u6a21\u7cca\u6d4b\u8bd5\u76ee\u6807\uff1a1\uff09\u5206\u6790\u6e90\u4ee3\u7801\u7ed3\u6784\u4ee5\u51c6\u786e\u6784\u5efa\u51fd\u6570\u8c03\u7528\uff1b2\uff09\u5c06\u6a21\u7cca\u6d4b\u8bd5\u8f93\u5165\u6570\u636e\u6620\u5c04\u5230\u76f8\u5e94\u51fd\u6570\u53c2\u6570\uff1b3\uff09\u5408\u6210\u6a21\u7cca\u6d4b\u8bd5\u76ee\u6807\u7684\u7f16\u8bd1\u4fe1\u606f\uff1b4\uff09\u81ea\u52a8\u6536\u96c6\u548c\u5206\u6790\u6267\u884c\u7ed3\u679c\u3002", "result": "\u8be5\u65b9\u6cd5\u5df2\u5e94\u7528\u4e8eC/C++\u5e93\u7684\u6a21\u7cca\u6d4b\u8bd5\u76ee\u6807\u751f\u6210\uff0c\u5c55\u793a\u4e86\u5176\u5728\u81ea\u52a8\u5316\u751f\u6210\u6a21\u7cca\u6d4b\u8bd5\u76ee\u6807\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u9759\u6001\u5206\u6790\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u81ea\u52a8\u5316\u751f\u6210\u6a21\u7cca\u6d4b\u8bd5\u76ee\u6807\uff0c\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u8f6f\u4ef6\u9879\u76ee\u4e2d\u624b\u52a8\u521b\u5efa\u6a21\u7cca\u6d4b\u8bd5\u76ee\u6807\u7684\u6311\u6218\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u6a21\u7cca\u6d4b\u8bd5\u7684\u8986\u76d6\u7387\u548c\u6548\u7387\u3002"}}
{"id": "2601.11893", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.11893", "abs": "https://arxiv.org/abs/2601.11893", "authors": ["Zimo Ji", "Daoyuan Wu", "Wenyuan Jiang", "Pingchuan Ma", "Zongjie Li", "Yudong Gao", "Shuai Wang", "Yingjiu Li"], "title": "Taming Various Privilege Escalation in LLM-Based Agent Systems: A Mandatory Access Control Framework", "comment": null, "summary": "Large Language Model (LLM)-based agent systems are increasingly deployed for complex real-world tasks but remain vulnerable to natural language-based attacks that exploit over-privileged tool use. This paper aims to understand and mitigate such attacks through the lens of privilege escalation, defined as agent actions exceeding the least privilege required for a user's intended task. Based on a formal model of LLM agent systems, we identify novel privilege escalation scenarios, particularly in multi-agent systems, including a variant akin to the classic confused deputy problem. To defend against both known and newly demonstrated privilege escalation, we propose SEAgent, a mandatory access control (MAC) framework built upon attribute-based access control (ABAC). SEAgent monitors agent-tool interactions via an information flow graph and enforces customizable security policies based on entity attributes. Our evaluations show that SEAgent effectively blocks various privilege escalation while maintaining a low false positive rate and negligible system overhead. This demonstrates its robustness and adaptability in securing LLM-based agent systems.", "AI": {"tldr": "SEAgent\u662f\u4e00\u4e2a\u57fa\u4e8e\u5c5e\u6027\u8bbf\u95ee\u63a7\u5236(ABAC)\u7684\u5f3a\u5236\u8bbf\u95ee\u63a7\u5236\u6846\u67b6\uff0c\u7528\u4e8e\u9632\u5fa1LLM\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u6743\u9650\u63d0\u5347\u653b\u51fb\uff0c\u901a\u8fc7\u76d1\u63a7\u667a\u80fd\u4f53-\u5de5\u5177\u4ea4\u4e92\u5e76\u5f3a\u5236\u6267\u884c\u5b89\u5168\u7b56\u7565\u6765\u4fdd\u62a4\u7cfb\u7edf\u5b89\u5168\u3002", "motivation": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u590d\u6742\u73b0\u5b9e\u4efb\u52a1\u4e2d\u5e94\u7528\u8d8a\u6765\u8d8a\u5e7f\u6cdb\uff0c\u4f46\u5bb9\u6613\u53d7\u5230\u81ea\u7136\u8bed\u8a00\u653b\u51fb\u7684\u5a01\u80c1\uff0c\u8fd9\u4e9b\u653b\u51fb\u5229\u7528\u8fc7\u5ea6\u7279\u6743\u5de5\u5177\u4f7f\u7528\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u6743\u9650\u63d0\u5347\u7684\u89c6\u89d2\u6765\u7406\u89e3\u548c\u7f13\u89e3\u6b64\u7c7b\u653b\u51fb\uff0c\u6743\u9650\u63d0\u5347\u5b9a\u4e49\u4e3a\u667a\u80fd\u4f53\u884c\u4e3a\u8d85\u51fa\u7528\u6237\u9884\u671f\u4efb\u52a1\u6240\u9700\u7684\u6700\u5c0f\u6743\u9650\u3002", "method": "\u57fa\u4e8eLLM\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5f62\u5f0f\u5316\u6a21\u578b\uff0c\u8bc6\u522b\u4e86\u65b0\u7684\u6743\u9650\u63d0\u5347\u573a\u666f\uff0c\u7279\u522b\u662f\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\uff0c\u5305\u62ec\u7c7b\u4f3c\u7ecf\u5178\"\u56f0\u60d1\u526f\u624b\u95ee\u9898\"\u7684\u53d8\u4f53\u3002\u63d0\u51fa\u4e86SEAgent\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u5c5e\u6027\u8bbf\u95ee\u63a7\u5236(ABAC)\u7684\u5f3a\u5236\u8bbf\u95ee\u63a7\u5236(MAC)\u6846\u67b6\uff0c\u901a\u8fc7\u4fe1\u606f\u6d41\u56fe\u76d1\u63a7\u667a\u80fd\u4f53-\u5de5\u5177\u4ea4\u4e92\uff0c\u5e76\u57fa\u4e8e\u5b9e\u4f53\u5c5e\u6027\u5f3a\u5236\u6267\u884c\u53ef\u5b9a\u5236\u7684\u5b89\u5168\u7b56\u7565\u3002", "result": "\u8bc4\u4f30\u663e\u793aSEAgent\u80fd\u6709\u6548\u963b\u6b62\u5404\u79cd\u6743\u9650\u63d0\u5347\u653b\u51fb\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u8bef\u62a5\u7387\u548c\u53ef\u5ffd\u7565\u7684\u7cfb\u7edf\u5f00\u9500\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u4fdd\u62a4\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u65b9\u9762\u7684\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u3002", "conclusion": "SEAgent\u6846\u67b6\u5c55\u793a\u4e86\u5728\u4fdd\u62a4LLM\u667a\u80fd\u4f53\u7cfb\u7edf\u514d\u53d7\u6743\u9650\u63d0\u5347\u653b\u51fb\u65b9\u9762\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\uff0c\u4e3a\u6784\u5efa\u66f4\u5b89\u5168\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u5b89\u5168\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11825", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.11825", "abs": "https://arxiv.org/abs/2601.11825", "authors": ["Arya Rahgozar", "Pouria Mortezaagha"], "title": "AI Co-Scientist for Knowledge Synthesis in Medical Contexts: A Proof of Concept", "comment": null, "summary": "Research waste in biomedical science is driven by redundant studies, incomplete reporting, and the limited scalability of traditional evidence synthesis workflows. We present an AI co-scientist for scalable and transparent knowledge synthesis based on explicit formalization of Population, Intervention, Comparator, Outcome, and Study design (PICOS). The platform integrates relational storage, vector-based semantic retrieval, and a Neo4j knowledge graph. Evaluation was conducted on dementia-sport and non-communicable disease corpora. Automated PICOS compliance and study design classification from titles and abstracts were performed using a Bidirectional Long Short-Term Memory baseline and a transformer-based multi-task classifier fine-tuned from PubMedBERT. Full-text synthesis employed retrieval-augmented generation with hybrid vector and graph retrieval, while BERTopic was used to identify thematic structure, redundancy, and evidence gaps. The transformer model achieved 95.7% accuracy for study design classification with strong agreement against expert annotations, while the Bi-LSTM achieved 87% accuracy for PICOS compliance detection. Retrieval-augmented generation outperformed non-retrieval generation for queries requiring structured constraints, cross-study integration, and graph-based reasoning, whereas non-retrieval approaches remained competitive for high-level summaries. Topic modeling revealed substantial thematic redundancy and identified underexplored research areas. These results demonstrate that PICOS-aware and explainable natural language processing can improve the scalability, transparency, and efficiency of evidence synthesis. The proposed architecture is domain-agnostic and offers a practical framework for reducing research waste across biomedical disciplines.", "AI": {"tldr": "AI\u9a71\u52a8\u7684PICOS\u77e5\u8bc6\u5408\u6210\u5e73\u53f0\uff0c\u901a\u8fc7\u81ea\u52a8\u5316PICOS\u5408\u89c4\u68c0\u6d4b\u3001\u7814\u7a76\u8bbe\u8ba1\u5206\u7c7b\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u4e3b\u9898\u5efa\u6a21\uff0c\u63d0\u9ad8\u751f\u7269\u533b\u5b66\u8bc1\u636e\u5408\u6210\u7684\u53ef\u6269\u5c55\u6027\u548c\u900f\u660e\u5ea6", "motivation": "\u89e3\u51b3\u751f\u7269\u533b\u5b66\u7814\u7a76\u4e2d\u56e0\u91cd\u590d\u7814\u7a76\u3001\u4e0d\u5b8c\u6574\u62a5\u544a\u548c\u4f20\u7edf\u8bc1\u636e\u5408\u6210\u5de5\u4f5c\u6d41\u7a0b\u53ef\u6269\u5c55\u6027\u6709\u9650\u5bfc\u81f4\u7684\u7814\u7a76\u6d6a\u8d39\u95ee\u9898", "method": "\u57fa\u4e8ePICOS\u6846\u67b6\u7684AI\u534f\u540c\u79d1\u5b66\u5bb6\u5e73\u53f0\uff0c\u6574\u5408\u5173\u7cfb\u5b58\u50a8\u3001\u5411\u91cf\u8bed\u4e49\u68c0\u7d22\u548cNeo4j\u77e5\u8bc6\u56fe\u8c31\uff1b\u4f7f\u7528Bi-LSTM\u548cPubMedBERT\u5fae\u8c03\u7684transformer\u6a21\u578b\u8fdb\u884cPICOS\u5408\u89c4\u68c0\u6d4b\u548c\u7814\u7a76\u8bbe\u8ba1\u5206\u7c7b\uff1b\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548cBERTopic\u8fdb\u884c\u4e3b\u9898\u5efa\u6a21", "result": "transformer\u6a21\u578b\u5728\u7814\u7a76\u8bbe\u8ba1\u5206\u7c7b\u4e0a\u8fbe\u523095.7%\u51c6\u786e\u7387\uff0cBi-LSTM\u5728PICOS\u5408\u89c4\u68c0\u6d4b\u4e0a\u8fbe\u523087%\u51c6\u786e\u7387\uff1b\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u5728\u7ed3\u6784\u5316\u7ea6\u675f\u3001\u8de8\u7814\u7a76\u6574\u5408\u548c\u56fe\u63a8\u7406\u4efb\u52a1\u4e0a\u4f18\u4e8e\u975e\u68c0\u7d22\u65b9\u6cd5\uff1b\u4e3b\u9898\u5efa\u6a21\u63ed\u793a\u4e86\u5927\u91cf\u4e3b\u9898\u5197\u4f59\u548c\u672a\u5145\u5206\u63a2\u7d22\u7684\u7814\u7a76\u9886\u57df", "conclusion": "PICOS\u611f\u77e5\u548c\u53ef\u89e3\u91ca\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u80fd\u591f\u63d0\u9ad8\u8bc1\u636e\u5408\u6210\u7684\u53ef\u6269\u5c55\u6027\u3001\u900f\u660e\u5ea6\u548c\u6548\u7387\uff0c\u8be5\u67b6\u6784\u662f\u9886\u57df\u65e0\u5173\u7684\uff0c\u4e3a\u51cf\u5c11\u751f\u7269\u533b\u5b66\u5b66\u79d1\u7684\u7814\u7a76\u6d6a\u8d39\u63d0\u4f9b\u4e86\u5b9e\u7528\u6846\u67b6"}}
{"id": "2601.12146", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12146", "abs": "https://arxiv.org/abs/2601.12146", "authors": ["Viktor Kjellberg", "Miroslaw Staron", "Farnaz Fotrousi"], "title": "From LLMs to Agents in Programming: The Impact of Providing an LLM with a Compiler", "comment": null, "summary": "Large Language Models have demonstrated a remarkable capability in natural language and program generation and software development. However, the source code generated by the LLMs does not always meet quality requirements and may fail to compile. Therefore, many studies evolve into agents that can reason about the problem before generating the source code for the solution. The goal of this paper is to study the degree to which such agents benefit from access to software development tools, in our case, a \\texttt{gcc} compiler. We conduct a computational experiment on the RosettaCode dataset, on 699 programming tasks in C. We evaluate how the integration with a compiler shifts the role of the language model from a passive generator to an active agent capable of iteratively developing runnable programs based on feedback from the compiler. We evaluated 16 language models with sizes ranging from small (135 million) to medium (3 billion) and large (70 billion). Our results show that access to a compiler improved the compilation success by 5.3 to 79.4 percentage units in compilation without affecting the semantics of the generated program. Syntax errors dropped by 75\\%, and errors related to undefined references dropped by 87\\% for the tasks where the agents outperformed the baselines. We also observed that in some cases, smaller models with a compiler outperform larger models with a compiler. We conclude that it is essential for LLMs to have access to software engineering tools to enhance their performance and reduce the need for large models in software engineering, such as reducing our energy footprint.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u8ba9LLM\u8bbf\u95ee\u7f16\u8bd1\u5668\u5de5\u5177\u5982\u4f55\u63d0\u5347\u4ee3\u7801\u751f\u6210\u8d28\u91cf\uff0c\u901a\u8fc7RosettaCode\u6570\u636e\u96c6\u7684699\u4e2aC\u8bed\u8a00\u4efb\u52a1\u5b9e\u9a8c\uff0c\u53d1\u73b0\u7f16\u8bd1\u5668\u8bbf\u95ee\u80fd\u663e\u8457\u63d0\u9ad8\u7f16\u8bd1\u6210\u529f\u7387\uff0c\u51cf\u5c11\u8bed\u6cd5\u9519\u8bef\uff0c\u4e14\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u5c0f\u6a21\u578b+\u7f16\u8bd1\u5668\u4f18\u4e8e\u5927\u6a21\u578b+\u7f16\u8bd1\u5668\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u65b9\u9762\u8868\u73b0\u7a81\u51fa\uff0c\u4f46\u751f\u6210\u7684\u6e90\u4ee3\u7801\u5e38\u5b58\u5728\u8d28\u91cf\u95ee\u9898\u751a\u81f3\u65e0\u6cd5\u7f16\u8bd1\u3002\u73b0\u6709\u7814\u7a76\u5c06LLM\u53d1\u5c55\u4e3a\u80fd\u591f\u63a8\u7406\u95ee\u9898\u7684\u667a\u80fd\u4f53\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u5de5\u5177\uff08\u5982\u7f16\u8bd1\u5668\uff09\u5982\u4f55\u5f71\u54cd\u5176\u6027\u80fd\u7684\u7cfb\u7edf\u7814\u7a76\u3002", "method": "\u5728RosettaCode\u6570\u636e\u96c6\u7684699\u4e2aC\u8bed\u8a00\u7f16\u7a0b\u4efb\u52a1\u4e0a\u8fdb\u884c\u8ba1\u7b97\u5b9e\u9a8c\uff0c\u8bc4\u4f3016\u4e2a\u4e0d\u540c\u89c4\u6a21\u7684LLM\uff08\u4ece1.35\u4ebf\u5230700\u4ebf\u53c2\u6570\uff09\u3002\u6bd4\u8f83\u6709/\u65e0\u7f16\u8bd1\u5668\u8bbf\u95ee\u65f6LLM\u7684\u8868\u73b0\uff0c\u8ba9LLM\u4ece\u88ab\u52a8\u751f\u6210\u5668\u8f6c\u53d8\u4e3a\u80fd\u591f\u57fa\u4e8e\u7f16\u8bd1\u5668\u53cd\u9988\u8fed\u4ee3\u5f00\u53d1\u53ef\u8fd0\u884c\u7a0b\u5e8f\u7684\u4e3b\u52a8\u667a\u80fd\u4f53\u3002", "result": "\u7f16\u8bd1\u5668\u8bbf\u95ee\u4f7f\u7f16\u8bd1\u6210\u529f\u7387\u63d0\u53475.3%\u523079.4%\uff0c\u8bed\u6cd5\u9519\u8bef\u51cf\u5c1175%\uff0c\u672a\u5b9a\u4e49\u5f15\u7528\u9519\u8bef\u51cf\u5c1187%\u3002\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u914d\u5907\u7f16\u8bd1\u5668\u7684\u5c0f\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u914d\u5907\u7f16\u8bd1\u5668\u7684\u5927\u6a21\u578b\u3002\u5de5\u5177\u8bbf\u95ee\u663e\u8457\u6539\u5584\u4e86\u4ee3\u7801\u8d28\u91cf\u800c\u4e0d\u5f71\u54cd\u7a0b\u5e8f\u8bed\u4e49\u3002", "conclusion": "LLM\u5fc5\u987b\u8bbf\u95ee\u8f6f\u4ef6\u5de5\u7a0b\u5de5\u5177\u4ee5\u63d0\u5347\u6027\u80fd\uff0c\u8fd9\u53ef\u4ee5\u51cf\u5c11\u5bf9\u5927\u578b\u6a21\u578b\u7684\u4f9d\u8d56\uff0c\u4ece\u800c\u964d\u4f4e\u80fd\u6e90\u6d88\u8017\u3002\u7f16\u8bd1\u5668\u96c6\u6210\u5c06LLM\u4ece\u88ab\u52a8\u751f\u6210\u5668\u8f6c\u53d8\u4e3a\u4e3b\u52a8\u7684\u4ee3\u7801\u5f00\u53d1\u667a\u80fd\u4f53\uff0c\u663e\u8457\u63d0\u9ad8\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u7684\u6548\u7387\u548c\u8d28\u91cf\u3002"}}
{"id": "2601.11996", "categories": ["cs.CR", "cs.DB", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11996", "abs": "https://arxiv.org/abs/2601.11996", "authors": ["Shaunak Perni", "Minal Shirodkar", "Ramdas Karmalli"], "title": "MongoDB Injection Query Classification Model using MongoDB Log files as Training Data", "comment": "24 Pages, 5 Tables, 6 Figures, Journal", "summary": "NoSQL Injection attacks are a class of cybersecurity attacks where an attacker sends a specifically engineered query to a NoSQL database which then performs an unauthorized operation. To defend against such attacks, rule based systems were initially developed but then were found to be ineffective to innovative injection attacks hence a model based approach was developed. Most model based detection systems, during testing gave exponentially positive results but were trained only on the query statement sent to the server. However due to the scarcity of data and class imbalances these model based systems were found to be not effective against all attacks in the real world. This paper explores classifying NoSQL injection attacks sent to a MongoDB server based on Log Data, and other extracted features excluding raw query statements. The log data was collected from a simulated attack on an empty MongoDB server which was then processed and explored. A discriminant analysis was carried out to determine statistically significant features to discriminate between injection and benign queries resulting in a dataset of significant features. Several Machine learning based classification models using an AutoML library, \"FLAML\", as well as 6 manually programmed models were trained on this dataset , which were then trained on 50 randomized samples of data, cross validated and evaluated. The study found that the best model was the \"FLAML\" library's \"XGBoost limited depth\" model with an accuracy of 71%.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u7d22\u57fa\u4e8e\u65e5\u5fd7\u6570\u636e\uff08\u6392\u9664\u539f\u59cb\u67e5\u8be2\u8bed\u53e5\uff09\u5bf9MongoDB NoSQL\u6ce8\u5165\u653b\u51fb\u8fdb\u884c\u5206\u7c7b\uff0c\u901a\u8fc7\u7279\u5f81\u9009\u62e9\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8bad\u7ec3\uff0c\u6700\u4f73\u6a21\u578b\u51c6\u786e\u7387\u8fbe\u523071%\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u7684\u7cfb\u7edf\u5bf9\u521b\u65b0\u7684\u6ce8\u5165\u653b\u51fb\u65e0\u6548\uff0c\u800c\u57fa\u4e8e\u6a21\u578b\u7684\u68c0\u6d4b\u7cfb\u7edf\u7531\u4e8e\u6570\u636e\u7a00\u7f3a\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u4e2d\u6548\u679c\u6709\u9650\u3002\u73b0\u6709\u6a21\u578b\u4e3b\u8981\u57fa\u4e8e\u67e5\u8be2\u8bed\u53e5\u8bad\u7ec3\uff0c\u4f46\u5b58\u5728\u6570\u636e\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "1. \u4ece\u6a21\u62df\u653b\u51fb\u7684MongoDB\u670d\u52a1\u5668\u6536\u96c6\u65e5\u5fd7\u6570\u636e\uff1b2. \u8fdb\u884c\u5224\u522b\u5206\u6790\u786e\u5b9a\u7edf\u8ba1\u663e\u8457\u7279\u5f81\uff1b3. \u4f7f\u7528AutoML\u5e93FLAML\u548c6\u4e2a\u624b\u52a8\u7f16\u7a0b\u6a21\u578b\u8bad\u7ec3\uff1b4. \u572850\u4e2a\u968f\u673a\u6570\u636e\u6837\u672c\u4e0a\u8fdb\u884c\u4ea4\u53c9\u9a8c\u8bc1\u548c\u8bc4\u4f30\u3002", "result": "\u6700\u4f73\u6a21\u578b\u662fFLAML\u5e93\u7684\"XGBoost limited depth\"\u6a21\u578b\uff0c\u51c6\u786e\u7387\u8fbe\u523071%\u3002\u57fa\u4e8e\u65e5\u5fd7\u7279\u5f81\u7684\u65b9\u6cd5\u76f8\u6bd4\u4f20\u7edf\u57fa\u4e8e\u67e5\u8be2\u8bed\u53e5\u7684\u65b9\u6cd5\u6709\u6240\u6539\u8fdb\u3002", "conclusion": "\u57fa\u4e8e\u65e5\u5fd7\u6570\u636e\u7279\u5f81\uff08\u800c\u975e\u539f\u59cb\u67e5\u8be2\u8bed\u53e5\uff09\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u68c0\u6d4bNoSQL\u6ce8\u5165\u653b\u51fb\uff0c\u4f4671%\u7684\u51c6\u786e\u7387\u8868\u660e\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\uff0c\u9700\u8981\u66f4\u591a\u6570\u636e\u548c\u7279\u5f81\u5de5\u7a0b\u3002"}}
{"id": "2601.12148", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12148", "abs": "https://arxiv.org/abs/2601.12148", "authors": ["Muhammad Umar Zeshan", "Motunrayo Ibiyo", "Claudio Di Sipio", "Phuong T. Nguyen", "Davide Di Ruscio"], "title": "Many Hands Make Light Work: An LLM-based Multi-Agent System for Detecting Malicious PyPI Packages", "comment": "The paper has been peer-reviewed and accepted for publication to the Journal of Systems and Software (https://www.sciencedirect.com/journal/journal-of-systems-and-software)", "summary": "Malicious code in open-source repositories such as PyPI poses a growing threat to software supply chains. Traditional rule-based tools often overlook the semantic patterns in source code that are crucial for identifying adversarial components. Large language models (LLMs) show promise for software analysis, yet their use in interpretable and modular security pipelines remains limited. This paper presents LAMPS, a multi-agent system that employs collaborative LLMs to detect malicious PyPI packages. The system consists of four role-specific agents for package retrieval, file extraction, classification, and verdict aggregation, coordinated through the CrewAI framework. A prototype combines a fine-tuned CodeBERT model for classification with LLaMA-3 agents for contextual reasoning. LAMPS has been evaluated on two complementary datasets: D1, a balanced collection of 6,000 setup.py files, and D2, a realistic multi-file dataset with 1,296 files and natural class imbalance. On D1, LAMPS achieves 97.7% accuracy, surpassing MPHunter--one of the state-of-the-art approaches. On D2, it reaches 99.5% accuracy and 99.5% balanced accuracy, outperforming RAG-based approaches and fine-tuned single-agent baselines. McNemar's test confirmed these improvements as highly significant. The results demonstrate the feasibility of distributed LLM reasoning for malicious code detection and highlight the benefits of modular multi-agent designs in software supply chain security.", "AI": {"tldr": "LAMPS\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53LLM\u534f\u4f5c\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u68c0\u6d4bPyPI\u6076\u610f\u8f6f\u4ef6\u5305\uff0c\u901a\u8fc7\u56db\u4e2a\u89d2\u8272\u7279\u5b9a\u7684\u667a\u80fd\u4f53\u5b9e\u73b0\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f00\u6e90\u4ed3\u5e93\u4e2d\u7684\u6076\u610f\u4ee3\u7801\u5bf9\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u6784\u6210\u65e5\u76ca\u589e\u957f\u7684\u5a01\u80c1\uff0c\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u7684\u5de5\u5177\u5e38\u5ffd\u7565\u6e90\u4ee3\u7801\u4e2d\u7684\u8bed\u4e49\u6a21\u5f0f\uff0c\u800cLLM\u5728\u53ef\u89e3\u91ca\u548c\u6a21\u5757\u5316\u5b89\u5168\u7ba1\u9053\u4e2d\u7684\u5e94\u7528\u4ecd\u7136\u6709\u9650\u3002", "method": "\u63d0\u51faLAMPS\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5305\u542b\u56db\u4e2a\u89d2\u8272\u7279\u5b9a\u7684\u667a\u80fd\u4f53\uff1a\u5305\u68c0\u7d22\u3001\u6587\u4ef6\u63d0\u53d6\u3001\u5206\u7c7b\u548c\u88c1\u51b3\u805a\u5408\uff0c\u901a\u8fc7CrewAI\u6846\u67b6\u534f\u8c03\u3002\u539f\u578b\u7ed3\u5408\u4e86\u5fae\u8c03\u7684CodeBERT\u6a21\u578b\u8fdb\u884c\u5206\u7c7b\u548cLLaMA-3\u667a\u80fd\u4f53\u8fdb\u884c\u4e0a\u4e0b\u6587\u63a8\u7406\u3002", "result": "\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff1aD1\uff086000\u4e2asetup.py\u6587\u4ef6\uff09\u4e0a\u8fbe\u523097.7%\u51c6\u786e\u7387\uff0c\u8d85\u8d8aMPHunter\uff1bD2\uff081296\u4e2a\u591a\u6587\u4ef6\u6570\u636e\u96c6\uff09\u4e0a\u8fbe\u523099.5%\u51c6\u786e\u7387\u548c99.5%\u5e73\u8861\u51c6\u786e\u7387\uff0c\u4f18\u4e8eRAG\u65b9\u6cd5\u548c\u5fae\u8c03\u5355\u667a\u80fd\u4f53\u57fa\u7ebf\u3002McNemar\u68c0\u9a8c\u786e\u8ba4\u6539\u8fdb\u5177\u6709\u9ad8\u5ea6\u663e\u8457\u6027\u3002", "conclusion": "\u7ed3\u679c\u8bc1\u660e\u4e86\u5206\u5e03\u5f0fLLM\u63a8\u7406\u5728\u6076\u610f\u4ee3\u7801\u68c0\u6d4b\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u5e76\u7a81\u663e\u4e86\u6a21\u5757\u5316\u591a\u667a\u80fd\u4f53\u8bbe\u8ba1\u5728\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\u4e2d\u7684\u4f18\u52bf\u3002"}}
{"id": "2601.11850", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.11850", "abs": "https://arxiv.org/abs/2601.11850", "authors": ["Matthew Nyaaba", "Min SungEun", "Mary Abiswin Apam", "Kwame Owoahene Acheampong", "Emmanuel Dwamena", "Xiaoming Zhai"], "title": "Human-AI Collaborative Inductive Thematic Analysis: AI Guided Analysis and Human Interpretive Authority", "comment": null, "summary": "The increasing use of generative artificial intelligence (GenAI) in qualitative research raises important questions about analytic practice and interpretive authority. This study examines how researchers interact with an Inductive Thematic Analysis GPT (ITA-GPT), a purpose-built AI tool designed to support inductive thematic analysis through structured, semi-automated prompts aligned with reflexive thematic analysis and verbatim coding principles. Guided by a Human-Artificial Intelligence Collaborative Inductive Thematic Analysis (HACITA) framework, the study focuses on analytic process rather than substantive findings. Three experienced qualitative researchers conducted ITA-GPT assisted analyses of interview transcripts from education research in the Ghanaian teacher education context. The tool supported familiarization, verbatim in vivo coding, gerund-based descriptive coding, and theme development, while enforcing trace to text integrity, coverage checks, and auditability. Data sources included interaction logs, AI-generated tables, researcher revisions, deletions, insertions, comments, and reflexive memos. Findings show that ITA-GPT functioned as a procedural scaffold that structured analytic workflow and enhanced transparency. However, interpretive authority remained with human researchers, who exercised judgment through recurrent analytic actions including modification, deletion, rejection, insertion, and commenting. The study demonstrates how inductive thematic analysis is enacted through responsible human AI collaboration.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u751f\u6210\u5f0fAI\u5728\u8d28\u6027\u7814\u7a76\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u662fITA-GPT\u5de5\u5177\u5982\u4f55\u652f\u6301\u5f52\u7eb3\u4e3b\u9898\u5206\u6790\uff0c\u5f3a\u8c03\u4eba\u7c7b\u7814\u7a76\u8005\u4fdd\u6301\u89e3\u91ca\u6743\u5a01\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5728\u8d28\u6027\u7814\u7a76\u4e2d\u7684\u4f7f\u7528\u65e5\u76ca\u589e\u591a\uff0c\u5f15\u53d1\u4e86\u5173\u4e8e\u5206\u6790\u5b9e\u8df5\u548c\u89e3\u91ca\u6743\u5a01\u7684\u91cd\u8981\u95ee\u9898\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u7814\u7a76\u4eba\u5458\u5982\u4f55\u4e0e\u4e13\u95e8\u8bbe\u8ba1\u7684AI\u5de5\u5177ITA-GPT\u4e92\u52a8\uff0c\u4ee5\u652f\u6301\u5f52\u7eb3\u4e3b\u9898\u5206\u6790\u3002", "method": "\u91c7\u7528\u4eba\u7c7b-\u4eba\u5de5\u667a\u80fd\u534f\u4f5c\u5f52\u7eb3\u4e3b\u9898\u5206\u6790\u6846\u67b6\uff0c\u4e09\u4f4d\u7ecf\u9a8c\u4e30\u5bcc\u7684\u8d28\u6027\u7814\u7a76\u4eba\u5458\u4f7f\u7528ITA-GPT\u5de5\u5177\u5206\u6790\u52a0\u7eb3\u6559\u5e08\u6559\u80b2\u80cc\u666f\u4e0b\u7684\u8bbf\u8c08\u8f6c\u5f55\u6587\u672c\u3002\u5de5\u5177\u652f\u6301\u719f\u6089\u5316\u3001\u9010\u5b57\u7f16\u7801\u3001\u52a8\u540d\u8bcd\u63cf\u8ff0\u6027\u7f16\u7801\u548c\u4e3b\u9898\u5f00\u53d1\uff0c\u540c\u65f6\u786e\u4fdd\u6587\u672c\u5b8c\u6574\u6027\u3001\u8986\u76d6\u68c0\u67e5\u548c\u53ef\u5ba1\u8ba1\u6027\u3002\u6570\u636e\u6765\u6e90\u5305\u62ec\u4ea4\u4e92\u65e5\u5fd7\u3001AI\u751f\u6210\u7684\u8868\u683c\u3001\u7814\u7a76\u4eba\u5458\u4fee\u8ba2\u3001\u5220\u9664\u3001\u63d2\u5165\u3001\u8bc4\u8bba\u548c\u53cd\u601d\u5907\u5fd8\u5f55\u3002", "result": "ITA-GPT\u4f5c\u4e3a\u7a0b\u5e8f\u6027\u652f\u67b6\uff0c\u7ed3\u6784\u5316\u5206\u6790\u5de5\u4f5c\u6d41\u7a0b\u5e76\u589e\u5f3a\u900f\u660e\u5ea6\u3002\u7136\u800c\uff0c\u89e3\u91ca\u6743\u5a01\u4ecd\u7531\u4eba\u7c7b\u7814\u7a76\u8005\u638c\u63e1\uff0c\u4ed6\u4eec\u901a\u8fc7\u4fee\u6539\u3001\u5220\u9664\u3001\u62d2\u7edd\u3001\u63d2\u5165\u548c\u8bc4\u8bba\u7b49\u53cd\u590d\u5206\u6790\u884c\u52a8\u884c\u4f7f\u5224\u65ad\u529b\u3002", "conclusion": "\u7814\u7a76\u5c55\u793a\u4e86\u5f52\u7eb3\u4e3b\u9898\u5206\u6790\u5982\u4f55\u901a\u8fc7\u8d1f\u8d23\u4efb\u7684\u4eba\u7c7b-AI\u534f\u4f5c\u5f97\u4ee5\u5b9e\u65bd\uff0c\u5f3a\u8c03AI\u4f5c\u4e3a\u8f85\u52a9\u5de5\u5177\u800c\u975e\u66ff\u4ee3\u4eba\u7c7b\u89e3\u91ca\u6743\u5a01\u7684\u89d2\u8272\u3002"}}
{"id": "2601.12186", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12186", "abs": "https://arxiv.org/abs/2601.12186", "authors": ["Vatsal Venkatkrishna", "Indraneil Paul", "Iryna Gurevych"], "title": "Aletheia: What Makes RLVR For Code Verifiers Tick?", "comment": "8 pages, 6 figures", "summary": "Multi-domain thinking verifiers trained via Reinforcement Learning from Verifiable Rewards (RLVR) are a prominent fixture of the Large Language Model (LLM) post-training pipeline, owing to their ability to robustly rate and rerank model outputs. However, the adoption of such verifiers towards code generation has been comparatively sparse, with execution feedback constituting the dominant signal. Nonetheless, code verifiers remain valuable toward judging model outputs in scenarios where execution feedback is hard to obtain and are a potentially powerful addition to the code generation post-training toolbox. To this end, we create and open-source Aletheia, a controlled testbed that enables execution-grounded evaluation of code verifiers' robustness across disparate policy models and covariate shifts. We examine components of the RLVR-based verifier training recipe widely credited for its success: (1) intermediate thinking traces, (2) learning from negative samples, and (3) on-policy training. While experiments show the optimality of RLVR, we uncover important opportunities to simplify the recipe. Particularly, despite code verification exhibiting positive training- and inference-time scaling, on-policy learning stands out as the key component at small verifier sizes, and thinking-based training emerges as the most important component at larger scales.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86Aletheia\u6d4b\u8bd5\u5e73\u53f0\uff0c\u7528\u4e8e\u8bc4\u4f30\u4ee3\u7801\u9a8c\u8bc1\u5668\u5728\u4e0d\u540c\u6a21\u578b\u548c\u534f\u53d8\u91cf\u504f\u79fb\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u7814\u7a76\u4e86RLVR\u8bad\u7ec3\u65b9\u6cd5\u7684\u5173\u952e\u7ec4\u4ef6\u3002", "motivation": "\u5c3d\u7ba1\u57fa\u4e8eRLVR\u7684\u591a\u9886\u57df\u601d\u7ef4\u9a8c\u8bc1\u5668\u5728LLM\u540e\u8bad\u7ec3\u4e2d\u88ab\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5728\u4ee3\u7801\u751f\u6210\u9886\u57df\u7684\u5e94\u7528\u76f8\u5bf9\u8f83\u5c11\u3002\u4ee3\u7801\u9a8c\u8bc1\u5668\u5728\u6267\u884c\u53cd\u9988\u96be\u4ee5\u83b7\u53d6\u7684\u573a\u666f\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u662f\u4ee3\u7801\u751f\u6210\u540e\u8bad\u7ec3\u5de5\u5177\u7bb1\u7684\u6709\u529b\u8865\u5145\u3002", "method": "\u521b\u5efa\u5e76\u5f00\u6e90Aletheia\u6d4b\u8bd5\u5e73\u53f0\uff0c\u652f\u6301\u57fa\u4e8e\u6267\u884c\u7684\u4ee3\u7801\u9a8c\u8bc1\u5668\u9c81\u68d2\u6027\u8bc4\u4f30\u3002\u7814\u7a76RLVR\u8bad\u7ec3\u65b9\u6cd5\u7684\u5173\u952e\u7ec4\u4ef6\uff1a\u4e2d\u95f4\u601d\u7ef4\u8f68\u8ff9\u3001\u4ece\u8d1f\u6837\u672c\u5b66\u4e60\u3001\u5728\u7ebf\u7b56\u7565\u8bad\u7ec3\uff0c\u5e76\u5206\u6790\u8fd9\u4e9b\u7ec4\u4ef6\u5728\u4e0d\u540c\u89c4\u6a21\u9a8c\u8bc1\u5668\u4e2d\u7684\u91cd\u8981\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc1\u5b9e\u4e86RLVR\u65b9\u6cd5\u7684\u6700\u4f18\u6027\uff0c\u4f46\u53d1\u73b0\u4e86\u7b80\u5316\u8bad\u7ec3\u65b9\u6cd5\u7684\u91cd\u8981\u673a\u4f1a\u3002\u4ee3\u7801\u9a8c\u8bc1\u8868\u73b0\u51fa\u6b63\u8bad\u7ec3\u548c\u63a8\u7406\u65f6\u95f4\u7f29\u653e\uff0c\u5728\u7ebf\u7b56\u7565\u5b66\u4e60\u5728\u5c0f\u89c4\u6a21\u9a8c\u8bc1\u5668\u4e2d\u662f\u5173\u952e\u7ec4\u4ef6\uff0c\u800c\u57fa\u4e8e\u601d\u7ef4\u7684\u8bad\u7ec3\u5728\u66f4\u5927\u89c4\u6a21\u65f6\u6210\u4e3a\u6700\u91cd\u8981\u7684\u7ec4\u4ef6\u3002", "conclusion": "\u4ee3\u7801\u9a8c\u8bc1\u5668\u662f\u4ee3\u7801\u751f\u6210\u540e\u8bad\u7ec3\u7684\u6709\u4ef7\u503c\u5de5\u5177\uff0c\u7279\u522b\u662f\u5728\u6267\u884c\u53cd\u9988\u96be\u4ee5\u83b7\u53d6\u7684\u573a\u666f\u3002RLVR\u8bad\u7ec3\u65b9\u6cd5\u867d\u7136\u6700\u4f18\uff0c\u4f46\u5176\u7ec4\u4ef6\u7684\u91cd\u8981\u6027\u968f\u9a8c\u8bc1\u5668\u89c4\u6a21\u53d8\u5316\uff0c\u4e3a\u7b80\u5316\u8bad\u7ec3\u65b9\u6cd5\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2601.12042", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12042", "abs": "https://arxiv.org/abs/2601.12042", "authors": ["Xiaomei Zhang", "Zhaoxi Zhang", "Leo Yu Zhang", "Yanjun Zhang", "Guanhong Tao", "Shirui Pan"], "title": "Less Is More -- Until It Breaks: Security Pitfalls of Vision Token Compression in Large Vision-Language Models", "comment": null, "summary": "Visual token compression is widely adopted to improve the inference efficiency of Large Vision-Language Models (LVLMs), enabling their deployment in latency-sensitive and resource-constrained scenarios. However, existing work has mainly focused on efficiency and performance, while the security implications of visual token compression remain largely unexplored. In this work, we first reveal that visual token compression substantially degrades the robustness of LVLMs: models that are robust under uncompressed inference become highly vulnerable once compression is enabled. These vulnerabilities are state-specific; failure modes emerge only in the compressed setting and completely disappear when compression is disabled, making them particularly hidden and difficult to diagnose. By analyzing the key stages of the compression process, we identify instability in token importance ranking as the primary cause of this robustness degradation. Small and imperceptible perturbations can significantly alter token rankings, leading the compression mechanism to mistakenly discard task-critical information and ultimately causing model failure. Motivated by this observation, we propose a Compression-Aware Attack to systematically study and exploit this vulnerability. CAA directly targets the token selection mechanism and induces failures exclusively under compressed inference. We further extend this approach to more realistic black-box settings and introduce Transfer CAA, where neither the target model nor the compression configuration is accessible. We further evaluate potential defenses and find that they provide only limited protection. Extensive experiments across models, datasets, and compression methods show that visual token compression significantly undermines robustness, revealing a previously overlooked efficiency-security trade-off.", "AI": {"tldr": "\u89c6\u89c9token\u538b\u7f29\u663e\u8457\u964d\u4f4e\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff0c\u539f\u672c\u9c81\u68d2\u7684\u6a21\u578b\u5728\u542f\u7528\u538b\u7f29\u540e\u53d8\u5f97\u9ad8\u5ea6\u8106\u5f31\uff0c\u8fd9\u79cd\u6f0f\u6d1e\u5177\u6709\u72b6\u6001\u7279\u5f02\u6027\u4e14\u96be\u4ee5\u8bca\u65ad\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u89c6\u89c9token\u538b\u7f29\u7684\u6548\u7387\u548c\u6027\u80fd\uff0c\u4f46\u5176\u5b89\u5168\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u63ed\u793a\u89c6\u89c9token\u538b\u7f29\u5bf9LVLMs\u9c81\u68d2\u6027\u7684\u8d1f\u9762\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5206\u6790\u538b\u7f29\u8fc7\u7a0b\u7684\u5173\u952e\u9636\u6bb5\uff0c\u8bc6\u522btoken\u91cd\u8981\u6027\u6392\u5e8f\u7684\u4e0d\u7a33\u5b9a\u6027\u662f\u9c81\u68d2\u6027\u4e0b\u964d\u7684\u4e3b\u8981\u539f\u56e0\u3002\u63d0\u51fa\u538b\u7f29\u611f\u77e5\u653b\u51fb(CAA)\u6765\u7cfb\u7edf\u7814\u7a76\u548c\u5229\u7528\u8fd9\u4e00\u6f0f\u6d1e\uff0c\u5e76\u6269\u5c55\u5230\u66f4\u73b0\u5b9e\u7684black-box\u8bbe\u7f6e\u4e2d\u7684Transfer CAA\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u89c6\u89c9token\u538b\u7f29\u663e\u8457\u524a\u5f31\u4e86\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff0c\u63ed\u793a\u4e86\u4e4b\u524d\u88ab\u5ffd\u89c6\u7684\u6548\u7387-\u5b89\u5168\u6743\u8861\u3002\u73b0\u6709\u9632\u5fa1\u63aa\u65bd\u4ec5\u63d0\u4f9b\u6709\u9650\u4fdd\u62a4\u3002", "conclusion": "\u89c6\u89c9token\u538b\u7f29\u5728\u63d0\u9ad8\u6548\u7387\u7684\u540c\u65f6\u5e26\u6765\u4e86\u4e25\u91cd\u7684\u5b89\u5168\u98ce\u9669\uff0c\u9700\u8981\u91cd\u65b0\u5ba1\u89c6LVLMs\u4e2d\u7684\u6548\u7387-\u5b89\u5168\u6743\u8861\uff0c\u5e76\u5f00\u53d1\u66f4\u9c81\u68d2\u7684\u538b\u7f29\u65b9\u6cd5\u3002"}}
{"id": "2601.11885", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11885", "abs": "https://arxiv.org/abs/2601.11885", "authors": ["Zhifei Li", "Ziyue Qin", "Xiangyu Luo", "Xiaoju Hou", "Yue Zhao", "Miao Zhang", "Zhifang Huang", "Kui Xiao", "Bing Yang"], "title": "MyGram: Modality-aware Graph Transformer with Global Distribution for Multi-modal Entity Alignment", "comment": "Accepted by AAAI 2026", "summary": "Multi-modal entity alignment aims to identify equivalent entities between two multi-modal Knowledge graphs by integrating multi-modal data, such as images and text, to enrich the semantic representations of entities. However, existing methods may overlook the structural contextual information within each modality, making them vulnerable to interference from shallow features. To address these challenges, we propose MyGram, a modality-aware graph transformer with global distribution for multi-modal entity alignment. Specifically, we develop a modality diffusion learning module to capture deep structural contextual information within modalities and enable fine-grained multi-modal fusion. In addition, we introduce a Gram Loss that acts as a regularization constraint by minimizing the volume of a 4-dimensional parallelotope formed by multi-modal features, thereby achieving global distribution consistency across modalities. We conduct experiments on five public datasets. Results show that MyGram outperforms baseline models, achieving a maximum improvement of 4.8% in Hits@1 on FBDB15K, 9.9% on FBYG15K, and 4.3% on DBP15K.", "AI": {"tldr": "MyGram\uff1a\u4e00\u79cd\u7528\u4e8e\u591a\u6a21\u6001\u5b9e\u4f53\u5bf9\u9f50\u7684\u6a21\u6001\u611f\u77e5\u56fe\u53d8\u6362\u5668\uff0c\u901a\u8fc7\u6a21\u6001\u6269\u6563\u5b66\u4e60\u548cGram\u635f\u5931\u5b9e\u73b0\u8de8\u6a21\u6001\u5168\u5c40\u5206\u5e03\u4e00\u81f4\u6027\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u5b9e\u4f53\u5bf9\u9f50\u65b9\u6cd5\u53ef\u80fd\u5ffd\u89c6\u6bcf\u4e2a\u6a21\u6001\u5185\u7684\u7ed3\u6784\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5bb9\u6613\u53d7\u5230\u6d45\u5c42\u7279\u5f81\u7684\u5e72\u6270\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u8de8\u6a21\u6001\u878d\u5408\u548c\u5168\u5c40\u5206\u5e03\u4e00\u81f4\u6027\u65b9\u6cd5\u3002", "method": "\u63d0\u51faMyGram\u6a21\u578b\uff0c\u5305\u542b\u6a21\u6001\u6269\u6563\u5b66\u4e60\u6a21\u5757\u6355\u83b7\u6a21\u6001\u5185\u6df1\u5c42\u7ed3\u6784\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u4ee5\u53caGram\u635f\u5931\u4f5c\u4e3a\u6b63\u5219\u5316\u7ea6\u675f\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u591a\u6a21\u6001\u7279\u5f81\u5f62\u6210\u76844\u7ef4\u5e73\u884c\u516d\u9762\u4f53\u4f53\u79ef\u5b9e\u73b0\u8de8\u6a21\u6001\u5168\u5c40\u5206\u5e03\u4e00\u81f4\u6027\u3002", "result": "\u5728\u4e94\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMyGram\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u5728FBDB15K\u4e0aHits@1\u6700\u5927\u63d0\u53474.8%\uff0c\u5728FBYG15K\u4e0a\u63d0\u53479.9%\uff0c\u5728DBP15K\u4e0a\u63d0\u53474.3%\u3002", "conclusion": "MyGram\u901a\u8fc7\u6a21\u6001\u6269\u6563\u5b66\u4e60\u548cGram\u635f\u5931\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u5b9e\u4f53\u5bf9\u9f50\u4e2d\u7684\u6a21\u6001\u5185\u7ed3\u6784\u4fe1\u606f\u6355\u83b7\u548c\u8de8\u6a21\u6001\u5168\u5c40\u5206\u5e03\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u9f50\u6027\u80fd\u3002"}}
{"id": "2601.12262", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12262", "abs": "https://arxiv.org/abs/2601.12262", "authors": ["Tongtong Wu", "Rongyi Chen", "Wenjie Du", "Suyu Ma", "Guilin Qi", "Zhenchang Xing", "Shahram Khadivi", "Ramesh Periyathambi", "Gholamreza Haffari"], "title": "Environment-Aware Code Generation: How far are We?", "comment": "ICSE 2026", "summary": "Recent progress in large language models (LLMs) has improved code generation, but most evaluations still test isolated, small-scale code (e.g., a single function) under default or unspecified software environments. As a result, it is unclear whether LLMs can reliably generate executable code tailored to a user's specific environment. We present the first systematic study of Environment-Aware Code Generation (EACG), where generated code must be functionally correct and directly executable under arbitrary software configurations. To enable realistic evaluation, we introduce VersiBCB, a benchmark that is multi-package, execution-verified, and deprecation-aware, capturing complex and evolving environments that prior datasets often overlook. Using VersiBCB, we investigate three complementary adaptation axes: data, parameters, and cache, and develop representative strategies for each. Our results show that current LLMs struggle with environment-specific code generation, while our adaptations improve environment compatibility and executability. These findings highlight key challenges and opportunities for deploying LLMs in practical software engineering workflows.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u63a2\u8ba8\u4e86\u73af\u5883\u611f\u77e5\u4ee3\u7801\u751f\u6210\u95ee\u9898\uff0c\u63d0\u51fa\u4e86VersiBCB\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u7814\u7a76\u4e86\u4e09\u79cd\u9002\u5e94\u7b56\u7565\u6765\u63d0\u5347LLM\u5728\u7279\u5b9a\u8f6f\u4ef6\u73af\u5883\u4e0b\u7684\u4ee3\u7801\u751f\u6210\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u65b9\u9762\u867d\u6709\u8fdb\u6b65\uff0c\u4f46\u5927\u591a\u6570\u8bc4\u4f30\u4ecd\u5c40\u9650\u4e8e\u5b64\u7acb\u7684\u5c0f\u89c4\u6a21\u4ee3\u7801\u6d4b\u8bd5\uff0c\u4e14\u901a\u5e38\u5728\u9ed8\u8ba4\u6216\u672a\u6307\u5b9a\u7684\u8f6f\u4ef6\u73af\u5883\u4e0b\u8fdb\u884c\u3002\u8fd9\u5bfc\u81f4\u65e0\u6cd5\u786e\u5b9aLLM\u80fd\u5426\u53ef\u9760\u5730\u751f\u6210\u9002\u5408\u7528\u6237\u7279\u5b9a\u73af\u5883\u7684\u53ef\u6267\u884c\u4ee3\u7801\u3002", "method": "1. \u5f15\u5165VersiBCB\u57fa\u51c6\u6d4b\u8bd5\uff1a\u591a\u5305\u3001\u6267\u884c\u9a8c\u8bc1\u3001\u5f03\u7528\u611f\u77e5\uff0c\u6355\u6349\u590d\u6742\u4e14\u4e0d\u65ad\u6f14\u5316\u7684\u73af\u5883\uff1b2. \u7814\u7a76\u4e09\u79cd\u4e92\u8865\u7684\u9002\u5e94\u8f74\uff1a\u6570\u636e\u3001\u53c2\u6570\u548c\u7f13\u5b58\uff1b3. \u4e3a\u6bcf\u4e2a\u9002\u5e94\u8f74\u5f00\u53d1\u4ee3\u8868\u6027\u7b56\u7565\u3002", "result": "\u5f53\u524dLLM\u5728\u73af\u5883\u7279\u5b9a\u4ee3\u7801\u751f\u6210\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u4f46\u901a\u8fc7\u63d0\u51fa\u7684\u9002\u5e94\u7b56\u7565\u53ef\u4ee5\u663e\u8457\u6539\u5584\u73af\u5883\u517c\u5bb9\u6027\u548c\u53ef\u6267\u884c\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u5728\u5b9e\u9645\u8f6f\u4ef6\u5de5\u7a0b\u5de5\u4f5c\u6d41\u4e2d\u90e8\u7f72LLM\u7684\u5173\u952e\u6311\u6218\u548c\u673a\u9047\uff0c\u5f3a\u8c03\u4e86\u73af\u5883\u611f\u77e5\u4ee3\u7801\u751f\u6210\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.12105", "categories": ["cs.CR", "stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.12105", "abs": "https://arxiv.org/abs/2601.12105", "authors": ["Richik Chakraborty", "Lawrence Liu", "Syed Hasnain"], "title": "Privacy-Preserving Cohort Analytics for Personalized Health Platforms: A Differentially Private Framework with Stochastic Risk Modeling", "comment": "18 pages, 4 figures", "summary": "Personalized health analytics increasingly rely on population benchmarks to provide contextual insights such as ''How do I compare to others like me?'' However, cohort-based aggregation of health data introduces nontrivial privacy risks, particularly in interactive and longitudinal digital platforms. Existing privacy frameworks such as $k$-anonymity and differential privacy provide essential but largely static guarantees that do not fully capture the cumulative, distributional, and tail-dominated nature of re-identification risk in deployed systems.\n  In this work, we present a privacy-preserving cohort analytics framework that combines deterministic cohort constraints, differential privacy mechanisms, and synthetic baseline generation to enable personalized population comparisons while maintaining strong privacy protections. We further introduce a stochastic risk modeling approach that treats re-identification risk as a random variable evolving over time, enabling distributional evaluation through Monte Carlo simulation. Adapting quantitative risk measures from financial mathematics, we define Privacy Loss at Risk (P-VaR) to characterize worst-case privacy outcomes under realistic cohort dynamics and adversary assumptions.\n  We validate our framework through system-level analysis and simulation experiments, demonstrating how privacy-utility tradeoffs can be operationalized for digital health platforms. Our results suggest that stochastic risk modeling complements formal privacy guarantees by providing interpretable, decision-relevant metrics for platform designers, regulators, and clinical informatics stakeholders.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u786e\u5b9a\u6027\u961f\u5217\u7ea6\u675f\u3001\u5dee\u5206\u9690\u79c1\u548c\u5408\u6210\u57fa\u7ebf\u751f\u6210\u7684\u9690\u79c1\u4fdd\u62a4\u961f\u5217\u5206\u6790\u6846\u67b6\uff0c\u5f15\u5165\u968f\u673a\u98ce\u9669\u5efa\u6a21\u65b9\u6cd5\uff0c\u5b9a\u4e49\u9690\u79c1\u98ce\u9669\u4ef7\u503c\uff08P-VaR\uff09\u6765\u91cf\u5316\u6700\u574f\u60c5\u51b5\u4e0b\u7684\u9690\u79c1\u635f\u5931\u3002", "motivation": "\u4e2a\u6027\u5316\u5065\u5eb7\u5206\u6790\u4f9d\u8d56\u4eba\u7fa4\u57fa\u51c6\u6570\u636e\uff0c\u4f46\u961f\u5217\u805a\u5408\u4f1a\u5e26\u6765\u9690\u79c1\u98ce\u9669\u3002\u73b0\u6709\u7684k-\u533f\u540d\u548c\u5dee\u5206\u9690\u79c1\u7b49\u9759\u6001\u9690\u79c1\u4fdd\u62a4\u6846\u67b6\u65e0\u6cd5\u5145\u5206\u6355\u6349\u5b9e\u9645\u7cfb\u7edf\u4e2d\u7d2f\u79ef\u6027\u3001\u5206\u5e03\u6027\u548c\u5c3e\u90e8\u4e3b\u5bfc\u7684\u91cd\u65b0\u8bc6\u522b\u98ce\u9669\u3002", "method": "\u7ed3\u5408\u786e\u5b9a\u6027\u961f\u5217\u7ea6\u675f\u3001\u5dee\u5206\u9690\u79c1\u673a\u5236\u548c\u5408\u6210\u57fa\u7ebf\u751f\u6210\uff0c\u63d0\u51fa\u968f\u673a\u98ce\u9669\u5efa\u6a21\u65b9\u6cd5\uff0c\u5c06\u91cd\u65b0\u8bc6\u522b\u98ce\u9669\u89c6\u4e3a\u968f\u65f6\u95f4\u6f14\u53d8\u7684\u968f\u673a\u53d8\u91cf\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6a21\u62df\u8fdb\u884c\u5206\u5e03\u8bc4\u4f30\uff0c\u5e76\u501f\u9274\u91d1\u878d\u6570\u5b66\u4e2d\u7684\u98ce\u9669\u5ea6\u91cf\u5b9a\u4e49\u9690\u79c1\u98ce\u9669\u4ef7\u503c\uff08P-VaR\uff09\u3002", "result": "\u901a\u8fc7\u7cfb\u7edf\u7ea7\u5206\u6790\u548c\u6a21\u62df\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u9690\u79c1-\u6548\u7528\u6743\u8861\u5982\u4f55\u5728\u6570\u5b57\u5065\u5eb7\u5e73\u53f0\u4e2d\u5b9e\u73b0\u64cd\u4f5c\u5316\u3002\u968f\u673a\u98ce\u9669\u5efa\u6a21\u4e3a\u5e73\u53f0\u8bbe\u8ba1\u8005\u3001\u76d1\u7ba1\u8005\u548c\u4e34\u5e8a\u4fe1\u606f\u5b66\u5229\u76ca\u76f8\u5173\u8005\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u3001\u4e0e\u51b3\u7b56\u76f8\u5173\u7684\u5ea6\u91cf\u6307\u6807\u3002", "conclusion": "\u968f\u673a\u98ce\u9669\u5efa\u6a21\u901a\u8fc7\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u3001\u4e0e\u51b3\u7b56\u76f8\u5173\u7684\u98ce\u9669\u5ea6\u91cf\uff0c\u8865\u5145\u4e86\u5f62\u5f0f\u5316\u9690\u79c1\u4fdd\u8bc1\uff0c\u4e3a\u6570\u5b57\u5065\u5eb7\u5e73\u53f0\u7684\u9690\u79c1\u4fdd\u62a4\u961f\u5217\u5206\u6790\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11903", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11903", "abs": "https://arxiv.org/abs/2601.11903", "authors": ["YenTing Lee", "Keerthi Koneru", "Zahra Moslemi", "Sheethal Kumar", "Ramesh Radhakrishnan"], "title": "AEMA: Verifiable Evaluation Framework for Trustworthy and Controlled Agentic LLM Systems", "comment": "Workshop on W51: How Can We Trust and Control Agentic AI? Toward Alignment, Robustness, and Verifiability in Autonomous LLM Agents at AAAI 2026", "summary": "Evaluating large language model (LLM)-based multi-agent systems remains a critical challenge, as these systems must exhibit reliable coordination, transparent decision-making, and verifiable performance across evolving tasks. Existing evaluation approaches often limit themselves to single-response scoring or narrow benchmarks, which lack stability, extensibility, and automation when deployed in enterprise settings at multi-agent scale. We present AEMA (Adaptive Evaluation Multi-Agent), a process-aware and auditable framework that plans, executes, and aggregates multi-step evaluations across heterogeneous agentic workflows under human oversight. Compared to a single LLM-as-a-Judge, AEMA achieves greater stability, human alignment, and traceable records that support accountable automation. Our results on enterprise-style agent workflows simulated using realistic business scenarios demonstrate that AEMA provides a transparent and reproducible pathway toward responsible evaluation of LLM-based multi-agent systems.\n  Keywords Agentic AI, Multi-Agent Systems, Trustworthy AI, Verifiable Evaluation, Human Oversight", "AI": {"tldr": "AEMA\u6846\u67b6\uff1a\u7528\u4e8e\u8bc4\u4f30LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u8fc7\u7a0b\u611f\u77e5\u3001\u53ef\u5ba1\u8ba1\u8bc4\u4f30\u6846\u67b6\uff0c\u76f8\u6bd4\u5355\u4e00LLM-as-a-Judge\u65b9\u6cd5\uff0c\u63d0\u4f9b\u66f4\u7a33\u5b9a\u3001\u53ef\u8ffd\u6eaf\u4e14\u652f\u6301\u4eba\u7c7b\u76d1\u7763\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u3002", "motivation": "\u5f53\u524d\u8bc4\u4f30LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4e3b\u8981\u4f9d\u8d56\u5355\u6b21\u54cd\u5e94\u8bc4\u5206\u6216\u72ed\u7a84\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7f3a\u4e4f\u7a33\u5b9a\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u81ea\u52a8\u5316\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u4f01\u4e1a\u7ea7\u591a\u667a\u80fd\u4f53\u89c4\u6a21\u90e8\u7f72\u65f6\uff0c\u9700\u8981\u53ef\u9760\u534f\u8c03\u3001\u900f\u660e\u51b3\u7b56\u548c\u53ef\u9a8c\u8bc1\u6027\u80fd\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u63d0\u51faAEMA\uff08\u81ea\u9002\u5e94\u8bc4\u4f30\u591a\u667a\u80fd\u4f53\uff09\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u8fc7\u7a0b\u611f\u77e5\u3001\u53ef\u5ba1\u8ba1\u7684\u8bc4\u4f30\u7cfb\u7edf\uff0c\u80fd\u591f\u5728\u4eba\u7c7b\u76d1\u7763\u4e0b\u89c4\u5212\u3001\u6267\u884c\u548c\u805a\u5408\u5f02\u6784\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7684\u591a\u6b65\u9aa4\u8bc4\u4f30\uff0c\u652f\u6301\u53ef\u8ffd\u6eaf\u8bb0\u5f55\u548c\u8d1f\u8d23\u4efb\u81ea\u52a8\u5316\u3002", "result": "\u5728\u6a21\u62df\u771f\u5b9e\u4e1a\u52a1\u573a\u666f\u7684\u4f01\u4e1a\u7ea7\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u4e0a\u9a8c\u8bc1\uff0cAEMA\u76f8\u6bd4\u5355\u4e00LLM-as-a-Judge\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u7a33\u5b9a\u6027\u3001\u66f4\u597d\u7684\u4eba\u7c7b\u5bf9\u9f50\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u8ffd\u6eaf\u7684\u8bb0\u5f55\uff0c\u652f\u6301\u8d1f\u8d23\u4efb\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u3002", "conclusion": "AEMA\u4e3aLLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u900f\u660e\u3001\u53ef\u590d\u73b0\u7684\u8d1f\u8d23\u4efb\u8bc4\u4f30\u8def\u5f84\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u7f3a\u4e4f\u7a33\u5b9a\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u81ea\u52a8\u5316\u80fd\u529b\u7684\u95ee\u9898\uff0c\u652f\u6301\u53ef\u9a8c\u8bc1\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8bc4\u4f30\u3002"}}
{"id": "2601.12273", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12273", "abs": "https://arxiv.org/abs/2601.12273", "authors": ["Chihiro Yoshida", "Yuta Ishimoto", "Olivier Nourry", "Masanari Kondo", "Makoto Matsushita", "Yasutaka Kamei", "Yoshiki Higo"], "title": "Leveraging Mutation Analysis for LLM-based Repair of Quantum Programs", "comment": "6 pages, Accepted at SANER-ERA 2026", "summary": "In recent years, Automated Program Repair (APR) techniques specifically designed for quantum programs have been proposed. However, existing approaches often suffer from low repair success rates or poor understandability of the generated patches. In this study, we construct a framework in which a large language model (LLM) generates code repairs along with a natural language explanation of the applied repairs. To investigate how the contextual information included in prompts influences APR performance for quantum programs, we design four prompt configurations with different combinations of static information, dynamic information, and mutation analysis results. Mutation analysis evaluates how small changes to specific parts of a program affect its execution results and provides more detailed dynamic information than simple execution outputs such as stack traces. Our experimental results show that mutation analysis can provide valuable contextual information for LLM-based APR of quantum programs, improving repair success rates (achieving 94.4% in our experiment) and in some cases also improving the quality of generated explanations. Our findings point toward new directions for developing APR techniques for quantum programs that enhance both reliability and explainability.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6784\u5efa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u91cf\u5b50\u7a0b\u5e8f\u81ea\u52a8\u4fee\u590d\u6846\u67b6\uff0c\u901a\u8fc7\u5305\u542b\u53d8\u5f02\u5206\u6790\u7ed3\u679c\u7684\u63d0\u793a\u914d\u7f6e\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4fee\u590d\u6210\u529f\u7387\u548c\u751f\u6210\u8865\u4e01\u7684\u53ef\u7406\u89e3\u6027\u3002", "motivation": "\u73b0\u6709\u91cf\u5b50\u7a0b\u5e8f\u81ea\u52a8\u4fee\u590d\u6280\u672f\u5b58\u5728\u4fee\u590d\u6210\u529f\u7387\u4f4e\u548c\u751f\u6210\u8865\u4e01\u53ef\u7406\u89e3\u6027\u5dee\u7684\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u65e2\u80fd\u63d0\u9ad8\u53ef\u9760\u6027\u53c8\u80fd\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2aLLM\u751f\u6210\u4ee3\u7801\u4fee\u590d\u53ca\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u7684\u6846\u67b6\uff0c\u8bbe\u8ba1\u4e86\u56db\u79cd\u5305\u542b\u4e0d\u540c\u4e0a\u4e0b\u6587\u4fe1\u606f\u7684\u63d0\u793a\u914d\u7f6e\uff08\u9759\u6001\u4fe1\u606f\u3001\u52a8\u6001\u4fe1\u606f\u3001\u53d8\u5f02\u5206\u6790\u7ed3\u679c\u7684\u4e0d\u540c\u7ec4\u5408\uff09\uff0c\u5176\u4e2d\u53d8\u5f02\u5206\u6790\u901a\u8fc7\u8bc4\u4f30\u7a0b\u5e8f\u5fae\u5c0f\u53d8\u5316\u5bf9\u6267\u884c\u7ed3\u679c\u7684\u5f71\u54cd\u63d0\u4f9b\u66f4\u8be6\u7ec6\u7684\u52a8\u6001\u4fe1\u606f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5305\u542b\u53d8\u5f02\u5206\u6790\u7684\u63d0\u793a\u914d\u7f6e\u663e\u8457\u63d0\u9ad8\u4e86LLM\u5728\u91cf\u5b50\u7a0b\u5e8f\u81ea\u52a8\u4fee\u590d\u4e2d\u7684\u8868\u73b0\uff0c\u4fee\u590d\u6210\u529f\u7387\u8fbe\u5230\u4e8694.4%\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u8fd8\u63d0\u9ad8\u4e86\u751f\u6210\u89e3\u91ca\u7684\u8d28\u91cf\u3002", "conclusion": "\u53d8\u5f02\u5206\u6790\u80fd\u4e3a\u57fa\u4e8eLLM\u7684\u91cf\u5b50\u7a0b\u5e8f\u81ea\u52a8\u4fee\u590d\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u8fd9\u4e00\u53d1\u73b0\u4e3a\u5f00\u53d1\u540c\u65f6\u589e\u5f3a\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u6027\u7684\u91cf\u5b50\u7a0b\u5e8f\u4fee\u590d\u6280\u672f\u6307\u660e\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2601.11905", "categories": ["cs.AI", "cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.11905", "abs": "https://arxiv.org/abs/2601.11905", "authors": ["Junyu Cao", "Ruijiang Gao", "Esmaeil Keyvanshokooh", "Jianhao Ma"], "title": "LIBRA: Language Model Informed Bandit Recourse Algorithm for Personalized Treatment Planning", "comment": "50 pages. Previous version with human-AI collaboration: arXiv:2410.14640", "summary": "We introduce a unified framework that seamlessly integrates algorithmic recourse, contextual bandits, and large language models (LLMs) to support sequential decision-making in high-stakes settings such as personalized medicine. We first introduce the recourse bandit problem, where a decision-maker must select both a treatment action and a feasible, minimal modification to mutable patient features. To address this problem, we develop the Generalized Linear Recourse Bandit (GLRB) algorithm. Building on this foundation, we propose LIBRA, a Language Model-Informed Bandit Recourse Algorithm that strategically combines domain knowledge from LLMs with the statistical rigor of bandit learning. LIBRA offers three key guarantees: (i) a warm-start guarantee, showing that LIBRA significantly reduces initial regret when LLM recommendations are near-optimal; (ii) an LLM-effort guarantee, proving that the algorithm consults the LLM only $O(\\log^2 T)$ times, where $T$ is the time horizon, ensuring long-term autonomy; and (iii) a robustness guarantee, showing that LIBRA never performs worse than a pure bandit algorithm even when the LLM is unreliable. We further establish matching lower bounds that characterize the fundamental difficulty of the recourse bandit problem and demonstrate the near-optimality of our algorithms. Experiments on synthetic environments and a real hypertension-management case study confirm that GLRB and LIBRA improve regret, treatment quality, and sample efficiency compared with standard contextual bandits and LLM-only benchmarks. Our results highlight the promise of recourse-aware, LLM-assisted bandit algorithms for trustworthy LLM-bandits collaboration in personalized high-stakes decision-making.", "AI": {"tldr": "\u63d0\u51faLIBRA\u6846\u67b6\uff0c\u5c06\u7b97\u6cd5\u8ffd\u7d22\u3001\u4e0a\u4e0b\u6587\u8001\u864e\u673a\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\uff0c\u7528\u4e8e\u9ad8\u98ce\u9669\u987a\u5e8f\u51b3\u7b56\uff08\u5982\u4e2a\u6027\u5316\u533b\u7597\uff09\uff0c\u5728\u4fdd\u8bc1\u7edf\u8ba1\u4e25\u8c28\u6027\u7684\u540c\u65f6\u5229\u7528LLM\u9886\u57df\u77e5\u8bc6\u3002", "motivation": "\u5728\u9ad8\u98ce\u9669\u987a\u5e8f\u51b3\u7b56\u573a\u666f\uff08\u5982\u4e2a\u6027\u5316\u533b\u7597\uff09\u4e2d\uff0c\u9700\u8981\u540c\u65f6\u9009\u62e9\u6cbb\u7597\u884c\u52a8\u548c\u5bf9\u60a3\u8005\u53ef\u53d8\u7279\u5f81\u7684\u6700\u5c0f\u53ef\u884c\u4fee\u6539\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5e73\u8861\u9886\u57df\u77e5\u8bc6\u548c\u7edf\u8ba1\u4e25\u8c28\u6027\u3002", "method": "1. \u63d0\u51fa\u8ffd\u7d22\u8001\u864e\u673a\u95ee\u9898\uff1b2. \u5f00\u53d1\u5e7f\u4e49\u7ebf\u6027\u8ffd\u7d22\u8001\u864e\u673a\u7b97\u6cd5\uff1b3. \u63d0\u51faLIBRA\u7b97\u6cd5\uff0c\u6218\u7565\u6027\u5730\u7ed3\u5408LLM\u9886\u57df\u77e5\u8bc6\u548c\u8001\u864e\u673a\u5b66\u4e60\u7684\u7edf\u8ba1\u4e25\u8c28\u6027\u3002", "result": "LIBRA\u63d0\u4f9b\u4e09\u4e2a\u5173\u952e\u4fdd\u8bc1\uff1a\u70ed\u542f\u52a8\u4fdd\u8bc1\uff08LLM\u63a8\u8350\u63a5\u8fd1\u6700\u4f18\u65f6\u663e\u8457\u51cf\u5c11\u521d\u59cb\u9057\u61be\uff09\u3001LLM\u52aa\u529b\u4fdd\u8bc1\uff08\u4ec5\u9700O(log\u00b2T)\u6b21\u54a8\u8be2LLM\uff09\u3001\u9c81\u68d2\u6027\u4fdd\u8bc1\uff08\u5373\u4f7fLLM\u4e0d\u53ef\u9760\u4e5f\u4e0d\u4f1a\u6bd4\u7eaf\u8001\u864e\u673a\u7b97\u6cd5\u5dee\uff09\u3002\u5b9e\u9a8c\u8bc1\u660e\u5728\u5408\u6210\u73af\u5883\u548c\u771f\u5b9e\u9ad8\u8840\u538b\u7ba1\u7406\u6848\u4f8b\u4e2d\u4f18\u4e8e\u57fa\u51c6\u65b9\u6cd5\u3002", "conclusion": "\u8ffd\u7d22\u611f\u77e5\u3001LLM\u8f85\u52a9\u7684\u8001\u864e\u673a\u7b97\u6cd5\u5728\u4e2a\u6027\u5316\u9ad8\u98ce\u9669\u51b3\u7b56\u4e2d\u5177\u6709\u524d\u666f\uff0c\u80fd\u591f\u5b9e\u73b0\u53ef\u4fe1\u7684LLM-\u8001\u864e\u673a\u534f\u4f5c\uff0c\u63d0\u9ad8\u9057\u61be\u3001\u6cbb\u7597\u8d28\u91cf\u548c\u6837\u672c\u6548\u7387\u3002"}}
{"id": "2601.12274", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12274", "abs": "https://arxiv.org/abs/2601.12274", "authors": ["Mahdi Eslamimehr"], "title": "Hybrid Concolic Testing with Large Language Models for Guided Path Exploration", "comment": "12 pages, 2 Figures, 2 Tables", "summary": "Concolic testing, a powerful hybrid software testing technique, has historically been plagued by fundamental limitations such as path explosion and the high cost of constraint solving, which hinder its practical application in large-scale, real-world software systems. This paper introduces a novel algorithmic framework that synergistically integrates concolic execution with Large Language Models (LLMs) to overcome these challenges. Our hybrid approach leverages the semantic reasoning capabilities of LLMs to guide path exploration, prioritize interesting execution paths, and assist in constraint solving. We formally define the system architecture and algorithms that constitute this new paradigm. Through a series of experiments on both synthetic and real-world Fintech applications, we demonstrate that our approach significantly outperforms traditional concolic testing, random testing, and genetic algorithm-based methods in terms of branch coverage, path coverage, and time-to-coverage. The results indicate that by combining the strengths of both concolic execution and LLMs, our method achieves a more efficient and effective exploration of the program state space, leading to improved bug detection capabilities.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u7b26\u53f7\u6267\u884c\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u65b0\u578b\u6df7\u5408\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7LLM\u7684\u8bed\u4e49\u63a8\u7406\u80fd\u529b\u6307\u5bfc\u8def\u5f84\u63a2\u7d22\u548c\u7ea6\u675f\u6c42\u89e3\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6d4b\u8bd5\u6548\u7387\u548c\u8986\u76d6\u7387\u3002", "motivation": "\u4f20\u7edf\u7b26\u53f7\u6d4b\u8bd5\u5b58\u5728\u8def\u5f84\u7206\u70b8\u548c\u7ea6\u675f\u6c42\u89e3\u6210\u672c\u9ad8\u7b49\u6839\u672c\u6027\u9650\u5236\uff0c\u963b\u788d\u4e86\u5176\u5728\u5927\u89c4\u6a21\u5b9e\u9645\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u3002\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u514b\u670d\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u7b97\u6cd5\u6846\u67b6\uff0c\u5c06\u7b26\u53f7\u6267\u884c\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u534f\u540c\u96c6\u6210\u3002\u5229\u7528LLM\u7684\u8bed\u4e49\u63a8\u7406\u80fd\u529b\u6307\u5bfc\u8def\u5f84\u63a2\u7d22\u3001\u4f18\u5148\u5904\u7406\u6709\u8da3\u7684\u6267\u884c\u8def\u5f84\uff0c\u5e76\u534f\u52a9\u7ea6\u675f\u6c42\u89e3\u3002\u6b63\u5f0f\u5b9a\u4e49\u4e86\u6784\u6210\u8fd9\u4e00\u65b0\u8303\u5f0f\u7684\u7cfb\u7edf\u67b6\u6784\u548c\u7b97\u6cd5\u3002", "result": "\u901a\u8fc7\u5728\u5408\u6210\u548c\u5b9e\u9645\u91d1\u878d\u79d1\u6280\u5e94\u7528\u4e0a\u8fdb\u884c\u7684\u4e00\u7cfb\u5217\u5b9e\u9a8c\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u5206\u652f\u8986\u76d6\u7387\u3001\u8def\u5f84\u8986\u76d6\u7387\u548c\u8fbe\u5230\u8986\u76d6\u7387\u7684\u65f6\u95f4\u65b9\u9762\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7b26\u53f7\u6d4b\u8bd5\u3001\u968f\u673a\u6d4b\u8bd5\u548c\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u7684\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u7b26\u53f7\u6267\u884c\u548cLLM\u7684\u4f18\u52bf\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u5bf9\u7a0b\u5e8f\u72b6\u6001\u7a7a\u95f4\u66f4\u9ad8\u6548\u548c\u6709\u6548\u7684\u63a2\u7d22\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u9519\u8bef\u68c0\u6d4b\u80fd\u529b\uff0c\u4e3a\u5927\u89c4\u6a21\u5b9e\u9645\u8f6f\u4ef6\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12270", "categories": ["cs.CR", "cs.PL"], "pdf": "https://arxiv.org/pdf/2601.12270", "abs": "https://arxiv.org/abs/2601.12270", "authors": ["Reshabh K Sharma", "Dan Grossman", "David Kohlbrenner"], "title": "SplittingSecrets: A Compiler-Based Defense for Preventing Data Memory-Dependent Prefetcher Side-Channels", "comment": null, "summary": "Traditional side-channels take advantage of secrets being used as inputs to unsafe instructions, used for memory accesses, or used in control flow decisions. Constant-time programming, which restricts such code patterns, has been widely adopted as a defense against these vulnerabilities. However, new hardware optimizations in the form of Data Memory-dependent Prefetchers (DMP) present in Apple, Intel, and ARM CPUs have shown such defenses are not sufficient. These prefetchers, unlike classical prefetchers, use the content of memory as well as the trace of prior accesses to determine prefetch targets. An adversary abusing such a prefetcher has been shown to be able to mount attacks leaking data-at-rest; data that is never used by the program, even speculatively, in an unsafe manner.\n  In response, this paper introduces SplittingSecrets, a compiler-based tool that can harden software libraries against side-channels arising from DMPs. SplittingSecrets's approach avoids reasoning about the complex internals of different DMPs and instead relies on one key aspect of all DMPs: activation requires data to resemble addresses. To prevent secret data from leaking, SplittingSecrets transforms memory operations to ensure that secrets are never stored in memory in a manner resembling an address, thereby avoiding DMP activation on those secrets. Rather than disable a DMP entirely, SplittingSecrets can provide targeted hardening for only specific secrets entirely in software.\n  We have implemented SplittingSecrets using LLVM, supporting both source-level memory operations and those generated by the compiler backend for the AArch64 architecture, We have analyzed the performance overhead involved in safeguarding secrets from DMP-induced attacks using common primitives in libsodium, a popular cryptographic library when built for Apple M-series CPUs.", "AI": {"tldr": "SplittingSecrets\u662f\u4e00\u4e2a\u57fa\u4e8e\u7f16\u8bd1\u5668\u7684\u5de5\u5177\uff0c\u901a\u8fc7\u9632\u6b62\u79d8\u5bc6\u6570\u636e\u5728\u5185\u5b58\u4e2d\u4ee5\u5730\u5740\u5f62\u5f0f\u5b58\u50a8\u6765\u9632\u5fa1\u6570\u636e\u5185\u5b58\u4f9d\u8d56\u9884\u53d6\u5668(DMP)\u5f15\u53d1\u7684\u4fa7\u4fe1\u9053\u653b\u51fb\u3002", "motivation": "\u4f20\u7edf\u4fa7\u4fe1\u9053\u9632\u5fa1\uff08\u5982\u6052\u5b9a\u65f6\u95f4\u7f16\u7a0b\uff09\u65e0\u6cd5\u62b5\u5fa1\u65b0\u578b\u786c\u4ef6\u4f18\u5316\u2014\u2014\u6570\u636e\u5185\u5b58\u4f9d\u8d56\u9884\u53d6\u5668(DMP)\u7684\u653b\u51fb\u3002DMP\u4f7f\u7528\u5185\u5b58\u5185\u5bb9\u548c\u8bbf\u95ee\u5386\u53f2\u6765\u786e\u5b9a\u9884\u53d6\u76ee\u6807\uff0c\u4f7f\u5f97\u653b\u51fb\u8005\u80fd\u591f\u6cc4\u9732\"\u9759\u6b62\u6570\u636e\"\uff0c\u5373\u4f7f\u7a0b\u5e8f\u4ece\u672a\u4ee5\u4e0d\u5b89\u5168\u65b9\u5f0f\u4f7f\u7528\u8fd9\u4e9b\u6570\u636e\u3002", "method": "SplittingSecrets\u91c7\u7528\u7f16\u8bd1\u5668\u8f6c\u6362\u65b9\u6cd5\uff0c\u57fa\u4e8eDMP\u7684\u4e00\u4e2a\u5173\u952e\u7279\u6027\uff1a\u6fc0\u6d3b\u9700\u8981\u6570\u636e\u7c7b\u4f3c\u5730\u5740\u3002\u5b83\u901a\u8fc7\u8f6c\u6362\u5185\u5b58\u64cd\u4f5c\uff0c\u786e\u4fdd\u79d8\u5bc6\u6570\u636e\u6c38\u8fdc\u4e0d\u4f1a\u4ee5\u7c7b\u4f3c\u5730\u5740\u7684\u5f62\u5f0f\u5b58\u50a8\u5728\u5185\u5b58\u4e2d\uff0c\u4ece\u800c\u907f\u514dDMP\u5bf9\u8fd9\u4e9b\u79d8\u5bc6\u7684\u6fc0\u6d3b\u3002\u8be5\u65b9\u6cd5\u5b8c\u5168\u5728\u8f6f\u4ef6\u4e2d\u5b9e\u73b0\uff0c\u65e0\u9700\u7981\u7528DMP\u3002", "result": "\u7814\u7a76\u56e2\u961f\u57fa\u4e8eLLVM\u5b9e\u73b0\u4e86SplittingSecrets\uff0c\u652f\u6301AArch64\u67b6\u6784\u7684\u6e90\u4ee3\u7801\u7ea7\u5185\u5b58\u64cd\u4f5c\u548c\u7f16\u8bd1\u5668\u540e\u7aef\u751f\u6210\u7684\u64cd\u4f5c\u3002\u5728Apple M\u7cfb\u5217CPU\u4e0a\u5bf9libsodium\u52a0\u5bc6\u5e93\u7684\u5e38\u89c1\u539f\u8bed\u8fdb\u884c\u4e86\u5206\u6790\uff0c\u8bc4\u4f30\u4e86\u4fdd\u62a4\u79d8\u5bc6\u514d\u53d7DMP\u653b\u51fb\u7684\u6027\u80fd\u5f00\u9500\u3002", "conclusion": "SplittingSecrets\u63d0\u4f9b\u4e86\u4e00\u79cd\u9488\u5bf9\u7279\u5b9a\u79d8\u5bc6\u7684\u8f6f\u4ef6\u786c\u5316\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u9632\u5fa1DMP\u5f15\u53d1\u7684\u4fa7\u4fe1\u9053\u653b\u51fb\uff0c\u800c\u65e0\u9700\u5b8c\u5168\u7981\u7528\u786c\u4ef6\u9884\u53d6\u5668\uff0c\u4e3a\u5bc6\u7801\u5e93\u7b49\u654f\u611f\u8f6f\u4ef6\u63d0\u4f9b\u4e86\u65b0\u7684\u4fdd\u62a4\u673a\u5236\u3002"}}
{"id": "2601.11940", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11940", "abs": "https://arxiv.org/abs/2601.11940", "authors": ["Kang Chen", "Fan Yu", "Junjie Nian", "Shihan Zhao", "Zhuoka Feng", "Zijun Yao", "Heng Wang", "Minshen Yu", "Yixin Cao"], "title": "Thinking Traps in Long Chain-of-Thought: A Measurable Study and Trap-Aware Adaptive Restart", "comment": null, "summary": "Scaling test-time compute via Long Chain-of-Thought (Long-CoT) significantly enhances reasoning capabilities, yet extended generation does not guarantee correctness: after an early wrong commitment, models may keep elaborating a self-consistent but incorrect prefix. Through fine-grained trajectory analysis, we identify Thinking Traps, prefix-dominant deadlocks where later reflection, alternative attempts, or verification fails to revise the root error. On a curated subset of DAPO-MATH, 89\\% of failures exhibit such traps. To solve this problem, we introduce TAAR (Trap-Aware Adaptive Restart), a test-time control framework that trains a diagnostic policy to predict two signals from partial trajectories: a trap index for where to truncate and an escape probability for whether and how strongly to intervene. At inference time, TAAR truncates the trajectory before the predicted trap segment and adaptively restarts decoding; for severely trapped cases, it applies stronger perturbations, including higher-temperature resampling and an optional structured reboot suffix. Experiments on challenging mathematical and scientific reasoning benchmarks (AIME24, AIME25, GPQA-Diamond, HMMT25, BRUMO25) show that TAAR improves reasoning performance without fine-tuning base model parameters.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faTAAR\u6846\u67b6\u89e3\u51b3\u957f\u601d\u7ef4\u94fe\u63a8\u7406\u4e2d\u7684\"\u601d\u7ef4\u9677\u9631\"\u95ee\u9898\uff1a\u5f53\u6a21\u578b\u65e9\u671f\u505a\u51fa\u9519\u8bef\u627f\u8bfa\u540e\uff0c\u5373\u4f7f\u540e\u7eed\u53cd\u601d\u4e5f\u96be\u4ee5\u4fee\u6b63\u6839\u9519\u8bef\u3002TAAR\u901a\u8fc7\u8bad\u7ec3\u8bca\u65ad\u7b56\u7565\u9884\u6d4b\u9677\u9631\u4f4d\u7f6e\u548c\u9003\u8131\u6982\u7387\uff0c\u5728\u63a8\u7406\u65f6\u622a\u65ad\u8f68\u8ff9\u5e76\u81ea\u9002\u5e94\u91cd\u542f\u89e3\u7801\u3002", "motivation": "\u957f\u601d\u7ef4\u94fe\uff08Long-CoT\uff09\u901a\u8fc7\u589e\u52a0\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u663e\u8457\u63d0\u5347\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u6269\u5c55\u751f\u6210\u4e0d\u80fd\u4fdd\u8bc1\u6b63\u786e\u6027\uff1a\u6a21\u578b\u5728\u65e9\u671f\u505a\u51fa\u9519\u8bef\u627f\u8bfa\u540e\uff0c\u53ef\u80fd\u4f1a\u7ee7\u7eed\u9610\u8ff0\u4e00\u4e2a\u81ea\u6d3d\u4f46\u4e0d\u6b63\u786e\u7684\u524d\u7f00\u3002\u7814\u7a76\u53d1\u73b089%\u7684\u5931\u8d25\u6848\u4f8b\u5b58\u5728\u8fd9\u79cd\"\u601d\u7ef4\u9677\u9631\"\u3002", "method": "\u63d0\u51faTAAR\uff08Trap-Aware Adaptive Restart\uff09\u6846\u67b6\uff1a1\uff09\u8bad\u7ec3\u8bca\u65ad\u7b56\u7565\u4ece\u90e8\u5206\u8f68\u8ff9\u4e2d\u9884\u6d4b\u4e24\u4e2a\u4fe1\u53f7\uff1a\u9677\u9631\u4f4d\u7f6e\u7d22\u5f15\u548c\u9003\u8131\u6982\u7387\uff1b2\uff09\u63a8\u7406\u65f6\u622a\u65ad\u8f68\u8ff9\u5230\u9884\u6d4b\u7684\u9677\u9631\u6bb5\u4e4b\u524d\uff1b3\uff09\u81ea\u9002\u5e94\u91cd\u542f\u89e3\u7801\uff0c\u5bf9\u4e25\u91cd\u9677\u9631\u60c5\u51b5\u5e94\u7528\u66f4\u5f3a\u7684\u6270\u52a8\uff0c\u5305\u62ec\u66f4\u9ad8\u6e29\u5ea6\u91cd\u91c7\u6837\u548c\u53ef\u9009\u7684\u7ed3\u6784\u5316\u91cd\u542f\u540e\u7f00\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u5b66\u548c\u79d1\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\uff08AIME24\u3001AIME25\u3001GPQA-Diamond\u3001HMMT25\u3001BRUMO25\uff09\u4e0a\uff0cTAAR\u5728\u4e0d\u5fae\u8c03\u57fa\u7840\u6a21\u578b\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u4e86\u63a8\u7406\u6027\u80fd\u3002", "conclusion": "TAAR\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u957f\u601d\u7ef4\u94fe\u63a8\u7406\u4e2d\u7684\u601d\u7ef4\u9677\u9631\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u91cd\u542f\u673a\u5236\u5e2e\u52a9\u6a21\u578b\u4ece\u9519\u8bef\u627f\u8bfa\u4e2d\u6062\u590d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u63a8\u7406\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2601.12327", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12327", "abs": "https://arxiv.org/abs/2601.12327", "authors": ["Lucas Gren", "Felix Dobslaw"], "title": "The Expert Validation Framework (EVF): Enabling Domain Expert Control in AI Engineering", "comment": null, "summary": "Generative AI (GenAI) systems promise to transform knowledge work by automating a range of tasks, yet their deployment in enterprise settings remains hindered by the lack of systematic quality assurance mechanisms. We present an Expert Validation Framework that places domain experts at the center of building software with GenAI components, enabling them to maintain authoritative control over system behavior through structured specification, testing, validation, and continuous monitoring processes. Our framework addresses the critical gap between AI capabilities and organizational trust by establishing a rigorous, expert-driven methodology for ensuring quality across diverse GenAI applications. Through a four-stage implementation process encompassing specification, system creation, validation, and production monitoring, the framework enables organizations to leverage GenAI capabilities while maintaining expert oversight and quality standards.", "AI": {"tldr": "\u63d0\u51fa\u4e13\u5bb6\u9a8c\u8bc1\u6846\u67b6\uff0c\u5c06\u9886\u57df\u4e13\u5bb6\u7f6e\u4e8e\u6784\u5efa\u542b\u751f\u6210\u5f0fAI\u7ec4\u4ef6\u7684\u8f6f\u4ef6\u4e2d\u5fc3\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u89c4\u8303\u3001\u6d4b\u8bd5\u3001\u9a8c\u8bc1\u548c\u6301\u7eed\u76d1\u63a7\u786e\u4fdd\u7cfb\u7edf\u8d28\u91cf", "motivation": "\u751f\u6210\u5f0fAI\u7cfb\u7edf\u6709\u671b\u6539\u53d8\u77e5\u8bc6\u5de5\u4f5c\uff0c\u4f46\u5728\u4f01\u4e1a\u90e8\u7f72\u4e2d\u56e0\u7f3a\u4e4f\u7cfb\u7edf\u5316\u8d28\u91cf\u4fdd\u8bc1\u673a\u5236\u800c\u53d7\u963b\uff0c\u9700\u8981\u89e3\u51b3AI\u80fd\u529b\u4e0e\u7ec4\u7ec7\u4fe1\u4efb\u4e4b\u95f4\u7684\u5173\u952e\u5dee\u8ddd", "method": "\u63d0\u51fa\u4e13\u5bb6\u9a8c\u8bc1\u6846\u67b6\uff0c\u5305\u542b\u56db\u4e2a\u9636\u6bb5\uff1a\u89c4\u8303\u5236\u5b9a\u3001\u7cfb\u7edf\u521b\u5efa\u3001\u9a8c\u8bc1\u6d4b\u8bd5\u3001\u751f\u4ea7\u76d1\u63a7\uff0c\u8ba9\u9886\u57df\u4e13\u5bb6\u901a\u8fc7\u7ed3\u6784\u5316\u6d41\u7a0b\u4fdd\u6301\u5bf9\u7cfb\u7edf\u884c\u4e3a\u7684\u6743\u5a01\u63a7\u5236", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u4e25\u8c28\u7684\u4e13\u5bb6\u9a71\u52a8\u65b9\u6cd5\u8bba\uff0c\u786e\u4fdd\u8de8\u4e0d\u540c\u751f\u6210\u5f0fAI\u5e94\u7528\u7684\u8d28\u91cf\uff0c\u4f7f\u7ec4\u7ec7\u80fd\u591f\u5728\u4fdd\u6301\u4e13\u5bb6\u76d1\u7763\u548c\u8d28\u91cf\u6807\u51c6\u7684\u540c\u65f6\u5229\u7528\u751f\u6210\u5f0fAI\u80fd\u529b", "conclusion": "\u8be5\u6846\u67b6\u89e3\u51b3\u4e86\u751f\u6210\u5f0fAI\u5728\u4f01\u4e1a\u90e8\u7f72\u4e2d\u7684\u8d28\u91cf\u4fdd\u8bc1\u96be\u9898\uff0c\u901a\u8fc7\u5c06\u9886\u57df\u4e13\u5bb6\u7f6e\u4e8e\u4e2d\u5fc3\u4f4d\u7f6e\uff0c\u5efa\u7acb\u4e86\u7cfb\u7edf\u5316\u7684\u8d28\u91cf\u4fdd\u969c\u673a\u5236\uff0c\u5f25\u5408\u4e86AI\u80fd\u529b\u4e0e\u7ec4\u7ec7\u4fe1\u4efb\u4e4b\u95f4\u7684\u5dee\u8ddd"}}
{"id": "2601.12331", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12331", "abs": "https://arxiv.org/abs/2601.12331", "authors": ["Huanyi Ye", "Jiale Guo", "Ziyao Liu", "Kwok-Yan Lam"], "title": "Efficient Privacy-Preserving Retrieval Augmented Generation with Distance-Preserving Encryption", "comment": null, "summary": "RAG has emerged as a key technique for enhancing response quality of LLMs without high computational cost. In traditional architectures, RAG services are provided by a single entity that hosts the dataset within a trusted local environment. However, individuals or small organizations often lack the resources to maintain data storage servers, leading them to rely on outsourced cloud storage. This dependence on untrusted third-party services introduces privacy risks. Embedding-based retrieval mechanisms, commonly used in RAG systems, are vulnerable to privacy leakage such as vector-to-text reconstruction attacks and structural leakage via vector analysis. Several privacy-preserving RAG techniques have been proposed but most existing approaches rely on partially homomorphic encryption, which incurs substantial computational overhead. To address these challenges, we propose an efficient privacy-preserving RAG framework (ppRAG) tailored for untrusted cloud environments that defends against vector-to-text attack, vector analysis, and query analysis. We propose Conditional Approximate Distance-Comparison-Preserving Symmetric Encryption (CAPRISE) that encrypts embeddings while still allowing the cloud to compute similarity between an encrypted query and the encrypted database embeddings. CAPRISE preserves only the relative distance ordering between the encrypted query and each encrypted database embedding, without exposing inter-database distances, thereby enhancing both privacy and efficiency. To mitigate query analysis, we introduce DP by perturbing the query embedding prior to encryption, preventing the cloud from inferring sensitive patterns. Experimental results show that ppRAG achieves efficient processing throughput, high retrieval accuracy, strong privacy guarantees, making it a practical solution for resource-constrained users seeking secure cloud-augmented LLMs.", "AI": {"tldr": "\u63d0\u51fappRAG\u6846\u67b6\uff0c\u9488\u5bf9\u4e0d\u53ef\u4fe1\u4e91\u73af\u5883\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4RAG\u7cfb\u7edf\uff0c\u901a\u8fc7CAPRISE\u52a0\u5bc6\u65b9\u6848\u4fdd\u62a4\u5d4c\u5165\u5411\u91cf\u9690\u79c1\uff0c\u540c\u65f6\u4fdd\u6301\u68c0\u7d22\u6548\u7387\u3002", "motivation": "\u4f20\u7edfRAG\u67b6\u6784\u4f9d\u8d56\u5355\u4e00\u53ef\u4fe1\u5b9e\u4f53\uff0c\u4f46\u4e2a\u4eba\u548c\u5c0f\u7ec4\u7ec7\u5e38\u9700\u4f7f\u7528\u4e0d\u53ef\u4fe1\u4e91\u5b58\u50a8\uff0c\u5bfc\u81f4\u9690\u79c1\u98ce\u9669\u3002\u73b0\u6709\u9690\u79c1\u4fdd\u62a4RAG\u6280\u672f\u591a\u4f7f\u7528\u90e8\u5206\u540c\u6001\u52a0\u5bc6\uff0c\u8ba1\u7b97\u5f00\u9500\u5927\u3002", "method": "\u63d0\u51faCAPRISE\u5bf9\u79f0\u52a0\u5bc6\u65b9\u6848\uff0c\u52a0\u5bc6\u5d4c\u5165\u5411\u91cf\u540e\u4ecd\u5141\u8bb8\u4e91\u670d\u52a1\u5668\u8ba1\u7b97\u76f8\u4f3c\u5ea6\uff0c\u4ec5\u4fdd\u7559\u67e5\u8be2\u4e0e\u6570\u636e\u5e93\u5411\u91cf\u95f4\u7684\u76f8\u5bf9\u8ddd\u79bb\u987a\u5e8f\uff0c\u4e0d\u66b4\u9732\u6570\u636e\u5e93\u5185\u90e8\u8ddd\u79bb\u3002\u901a\u8fc7\u5dee\u5206\u9690\u79c1\u6270\u52a8\u67e5\u8be2\u5d4c\u5165\u9632\u6b62\u67e5\u8be2\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793appRAG\u5b9e\u73b0\u4e86\u9ad8\u6548\u5904\u7406\u541e\u5410\u91cf\u3001\u9ad8\u68c0\u7d22\u51c6\u786e\u6027\u548c\u5f3a\u9690\u79c1\u4fdd\u8bc1\uff0c\u9002\u5408\u8d44\u6e90\u53d7\u9650\u7528\u6237\u7684\u5b89\u5168\u4e91\u589e\u5f3aLLM\u5e94\u7528\u3002", "conclusion": "ppRAG\u4e3a\u4e0d\u53ef\u4fe1\u4e91\u73af\u5883\u63d0\u4f9b\u4e86\u5b9e\u7528\u9ad8\u6548\u7684\u9690\u79c1\u4fdd\u62a4RAG\u89e3\u51b3\u65b9\u6848\uff0c\u5e73\u8861\u4e86\u9690\u79c1\u4fdd\u62a4\u3001\u68c0\u7d22\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u7684\u9700\u6c42\u3002"}}
{"id": "2601.12360", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12360", "abs": "https://arxiv.org/abs/2601.12360", "authors": ["Xinabang He", "Yuanwei Chen", "Hao Wu", "Jikang Zhang", "Zicheng Wang", "Ligeng Chen", "Junjie Peng", "Haiyang Wei", "Yi Qian", "Tiantai Zhang", "Linzhang Wang", "Bing Mao"], "title": "Discovering 100+ Compiler Defects in 72 Hours via LLM-Driven Semantic Logic Recomposition", "comment": null, "summary": "Compilers constitute the foundational root-of-trust in software supply chains; however, their immense complexity inevitably conceals critical defects. Recent research has attempted to leverage historical bugs to design new mutation operators or fine-tune models to increase program diversity for compiler fuzzing.We observe, however, that bugs manifest primarily based on the semantics of input programs rather than their syntax. Unfortunately, current approaches, whether relying on syntactic mutation or general Large Language Model (LLM) fine-tuning, struggle to preserve the specific semantics found in the logic of bug-triggering programs. Consequently, these critical semantic triggers are often lost, resulting in a limitation of the diversity of generated programs.\n  To explicitly reuse such semantics, we propose FeatureFuzz, a compiler fuzzer that combines features to generate programs. We define a feature as a decoupled primitive that encapsulates a natural language description of a bug-prone invariant, such as an out-of-bounds array access, alongside a concrete code witness of its realization. FeatureFuzz operates via a three-stage workflow: it first extracts features from historical bug reports, synthesizes coherent groups of features, and finally instantiates these groups into valid programs for compiler fuzzing.\n  We evaluated FeatureFuzz on GCC and LLVM. Over 24-hour campaigns, FeatureFuzz uncovered 167 unique crashes, which is 2.78x more than the second-best fuzzer. Furthermore, through a 72-hour fuzzing campaign, FeatureFuzz identified 106 bugs in GCC and LLVM, 76 of which have already been confirmed by compiler developers, validating the approach's ability to stress-test modern compilers effectively.", "AI": {"tldr": "FeatureFuzz\u662f\u4e00\u4e2a\u7f16\u8bd1\u5668\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\uff0c\u901a\u8fc7\u7ec4\u5408\u7279\u5f81\u6765\u751f\u6210\u7a0b\u5e8f\uff0c\u80fd\u66f4\u597d\u5730\u4fdd\u7559\u89e6\u53d1bug\u7684\u8bed\u4e49\u4fe1\u606f\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5728GCC\u548cLLVM\u4e0a\u53d1\u73b0\u4e86\u66f4\u591a\u5d29\u6e83\u548cbug\u3002", "motivation": "\u73b0\u6709\u7f16\u8bd1\u5668\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\u4e3b\u8981\u57fa\u4e8e\u8bed\u6cd5\u53d8\u5f02\u6216\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\uff0c\u96be\u4ee5\u4fdd\u7559\u89e6\u53d1bug\u7684\u5173\u952e\u8bed\u4e49\u4fe1\u606f\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u7a0b\u5e8f\u591a\u6837\u6027\u53d7\u9650\uff0c\u65e0\u6cd5\u6709\u6548\u53d1\u73b0\u7f16\u8bd1\u5668\u7f3a\u9677\u3002", "method": "FeatureFuzz\u91c7\u7528\u4e09\u9636\u6bb5\u5de5\u4f5c\u6d41\u7a0b\uff1a1) \u4ece\u5386\u53f2bug\u62a5\u544a\u4e2d\u63d0\u53d6\u7279\u5f81\uff08\u5305\u542b\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u7684bug\u6613\u53d1\u4e0d\u53d8\u5f0f\u548c\u5177\u4f53\u4ee3\u7801\u5b9e\u4f8b\uff09\uff1b2) \u5408\u6210\u7279\u5f81\u7ec4\uff1b3) \u5c06\u7279\u5f81\u7ec4\u5b9e\u4f8b\u5316\u4e3a\u6709\u6548\u7a0b\u5e8f\u7528\u4e8e\u7f16\u8bd1\u5668\u6a21\u7cca\u6d4b\u8bd5\u3002", "result": "\u572824\u5c0f\u65f6\u6d4b\u8bd5\u4e2d\uff0cFeatureFuzz\u53d1\u73b0\u4e86167\u4e2a\u72ec\u7279\u5d29\u6e83\uff0c\u662f\u7b2c\u4e8c\u597d\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u76842.78\u500d\u3002\u572872\u5c0f\u65f6\u6d4b\u8bd5\u4e2d\uff0c\u5728GCC\u548cLLVM\u4e2d\u53d1\u73b0\u4e86106\u4e2abug\uff0c\u5176\u4e2d76\u4e2a\u5df2\u88ab\u7f16\u8bd1\u5668\u5f00\u53d1\u8005\u786e\u8ba4\u3002", "conclusion": "FeatureFuzz\u901a\u8fc7\u663e\u5f0f\u91cd\u7528bug\u89e6\u53d1\u8bed\u4e49\uff0c\u80fd\u66f4\u6709\u6548\u5730\u5bf9\u73b0\u4ee3\u7f16\u8bd1\u5668\u8fdb\u884c\u538b\u529b\u6d4b\u8bd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u7f16\u8bd1\u5668\u6a21\u7cca\u6d4b\u8bd5\u7684\u6548\u679c\u3002"}}
{"id": "2601.11979", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11979", "abs": "https://arxiv.org/abs/2601.11979", "authors": ["Ang Gao", "Changshuo Zhang", "Xiao Zhang", "Deyang Li", "Minjun Zhao", "Fangchao Liu", "Xinyu Zhang"], "title": "Process In-Context Learning: Enhancing Mathematical Reasoning via Dynamic Demonstration Insertion", "comment": null, "summary": "In-context learning (ICL) has proven highly effective across diverse large language model (LLM) tasks. However, its potential for enhancing tasks that demand step-by-step logical deduction, such as mathematical reasoning, remains underexplored. A core limitation of existing ICL approaches is their static use of demonstrations: examples are pre-selected before inference and remain fixed, failing to adapt to the dynamic confusion points that often arise during multi-step reasoning such as ambiguous calculations or logical gaps. These unresolved confusion points can lead to cascading errors that degrade final accuracy. To tackle this issue, we propose Process In-Context Learning (PICL), a dynamic demonstration integration framework designed to boost mathematical reasoning by responding to real-time inference needs. PICL operates in two stages: 1)~it identifies potential confusion points by analyzing semantics and entropy in the reasoning process and summarizes their core characteristics; 2)~upon encountering these points, it retrieves relevant demonstrations from the demonstration pool that match the confusion context and inserts them directly into the ongoing reasoning process to guide subsequent steps. Experiments show that PICL outperforms baseline methods by mitigating mid-inference confusion, highlighting the value of adaptive demonstration insertion in complex mathematical reasoning.", "AI": {"tldr": "PICL\u63d0\u51fa\u52a8\u6001\u6f14\u793a\u96c6\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u5b9e\u65f6\u8bc6\u522b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u6df7\u6dc6\u70b9\u5e76\u63d2\u5165\u76f8\u5173\u6f14\u793a\uff0c\u63d0\u5347\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u4e0a\u4e0b\u6587\u5b66\u4e60\u65b9\u6cd5\u5728\u6570\u5b66\u63a8\u7406\u7b49\u9700\u8981\u9010\u6b65\u903b\u8f91\u63a8\u5bfc\u7684\u4efb\u52a1\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5176\u9759\u6001\u6f14\u793a\u65e0\u6cd5\u9002\u5e94\u63a8\u7406\u8fc7\u7a0b\u4e2d\u52a8\u6001\u51fa\u73b0\u7684\u6df7\u6dc6\u70b9\uff08\u5982\u6a21\u7cca\u8ba1\u7b97\u3001\u903b\u8f91\u6f0f\u6d1e\uff09\uff0c\u5bfc\u81f4\u7ea7\u8054\u9519\u8bef\u548c\u6700\u7ec8\u51c6\u786e\u7387\u4e0b\u964d\u3002", "method": "PICL\u91c7\u7528\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1) \u901a\u8fc7\u5206\u6790\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u8bed\u4e49\u548c\u71b5\u6765\u8bc6\u522b\u6f5c\u5728\u6df7\u6dc6\u70b9\u5e76\u603b\u7ed3\u6838\u5fc3\u7279\u5f81\uff1b2) \u5728\u9047\u5230\u6df7\u6dc6\u70b9\u65f6\uff0c\u4ece\u6f14\u793a\u6c60\u4e2d\u68c0\u7d22\u4e0e\u6df7\u6dc6\u4e0a\u4e0b\u6587\u5339\u914d\u7684\u76f8\u5173\u6f14\u793a\uff0c\u5e76\u5c06\u5176\u76f4\u63a5\u63d2\u5165\u5230\u6b63\u5728\u8fdb\u884c\u7684\u63a8\u7406\u8fc7\u7a0b\u4e2d\u4ee5\u6307\u5bfc\u540e\u7eed\u6b65\u9aa4\u3002", "result": "\u5b9e\u9a8c\u8868\u660ePICL\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u901a\u8fc7\u7f13\u89e3\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u6df7\u6dc6\u70b9\uff0c\u8bc1\u660e\u4e86\u81ea\u9002\u5e94\u6f14\u793a\u63d2\u5165\u5728\u590d\u6742\u6570\u5b66\u63a8\u7406\u4e2d\u7684\u4ef7\u503c\u3002", "conclusion": "PICL\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u8bc6\u522b\u548c\u54cd\u5e94\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u6df7\u6dc6\u70b9\uff0c\u6709\u6548\u63d0\u5347\u4e86\u4e0a\u4e0b\u6587\u5b66\u4e60\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u81ea\u9002\u5e94\u6f14\u793a\u96c6\u6210\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.12448", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12448", "abs": "https://arxiv.org/abs/2601.12448", "authors": ["Yang Liu", "Yixing Luo", "Xiaofeng Li", "Xiaogang Dong", "Bin Gu", "Zhi Jin"], "title": "Evaluating Large Language Models for Time Series Anomaly Detection in Aerospace Software", "comment": "This paper has been accepted by ASE 2025", "summary": "Time series anomaly detection (TSAD) is essential for ensuring the safety and reliability of aerospace software systems. Although large language models (LLMs) provide a promising training-free alternative to unsupervised approaches, their effectiveness in aerospace settings remains under-examined because of complex telemetry, misaligned evaluation metrics, and the absence of domain knowledge. To address this gap, we introduce ATSADBench, the first benchmark for aerospace TSAD. ATSADBench comprises nine tasks that combine three pattern-wise anomaly types, univariate and multivariate signals, and both in-loop and out-of-loop feedback scenarios, yielding 108,000 data points. Using this benchmark, we systematically evaluate state-of-the-art open-source LLMs under two paradigms: Direct, which labels anomalies within sliding windows, and Prediction-Based, which detects anomalies from prediction errors. To reflect operational needs, we reformulate evaluation at the window level and propose three user-oriented metrics: Alarm Accuracy (AA), Alarm Latency (AL), and Alarm Contiguity (AC), which quantify alarm correctness, timeliness, and credibility. We further examine two enhancement strategies, few-shot learning and retrieval-augmented generation (RAG), to inject domain knowledge. The evaluation results show that (1) LLMs perform well on univariate tasks but struggle with multivariate telemetry, (2) their AA and AC on multivariate tasks approach random guessing, (3) few-shot learning provides modest gains whereas RAG offers no significant improvement, and (4) in practice LLMs can detect true anomaly onsets yet sometimes raise false alarms, which few-shot prompting mitigates but RAG exacerbates. These findings offer guidance for future LLM-based TSAD in aerospace software.", "AI": {"tldr": "ATSADBench\u662f\u9996\u4e2a\u822a\u7a7a\u822a\u5929\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u57fa\u51c6\uff0c\u5305\u542b9\u4e2a\u4efb\u52a1\u548c108,000\u4e2a\u6570\u636e\u70b9\uff0c\u8bc4\u4f30\u4e86LLM\u5728\u4e24\u79cd\u8303\u5f0f\u4e0b\u7684\u8868\u73b0\uff0c\u5e76\u63d0\u51fa\u4e86\u4e09\u4e2a\u9762\u5411\u7528\u6237\u7684\u8bc4\u4f30\u6307\u6807\u3002", "motivation": "\u822a\u7a7a\u822a\u5929\u8f6f\u4ef6\u7cfb\u7edf\u9700\u8981\u53ef\u9760\u7684\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\uff0c\u867d\u7136LLM\u63d0\u4f9b\u4e86\u65e0\u9700\u8bad\u7ec3\u7684\u65e0\u76d1\u7763\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u5176\u5728\u822a\u7a7a\u822a\u5929\u73af\u5883\u4e2d\u7684\u6709\u6548\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\uff0c\u56e0\u4e3a\u5b58\u5728\u590d\u6742\u7684\u9065\u6d4b\u6570\u636e\u3001\u8bc4\u4f30\u6307\u6807\u4e0d\u5339\u914d\u4ee5\u53ca\u7f3a\u4e4f\u9886\u57df\u77e5\u8bc6\u7b49\u95ee\u9898\u3002", "method": "\u6784\u5efaATSADBench\u57fa\u51c6\uff0c\u5305\u542b\u4e09\u79cd\u6a21\u5f0f\u5f02\u5e38\u7c7b\u578b\u3001\u5355\u53d8\u91cf\u548c\u591a\u53d8\u91cf\u4fe1\u53f7\u3001\u5185\u5916\u73af\u53cd\u9988\u573a\u666f\u76849\u4e2a\u4efb\u52a1\u3002\u7cfb\u7edf\u8bc4\u4f30\u5f00\u6e90LLM\u5728\u4e24\u79cd\u8303\u5f0f\u4e0b\u7684\u8868\u73b0\uff1a\u76f4\u63a5\u68c0\u6d4b\u548c\u57fa\u4e8e\u9884\u6d4b\u7684\u68c0\u6d4b\u3002\u63d0\u51fa\u7a97\u53e3\u7ea7\u8bc4\u4f30\u548c\u4e09\u4e2a\u7528\u6237\u5bfc\u5411\u6307\u6807\uff1a\u8b66\u62a5\u51c6\u786e\u7387\u3001\u8b66\u62a5\u5ef6\u8fdf\u3001\u8b66\u62a5\u8fde\u7eed\u6027\u3002\u7814\u7a76\u4e24\u79cd\u589e\u5f3a\u7b56\u7565\uff1a\u5c11\u6837\u672c\u5b66\u4e60\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u3002", "result": "LLM\u5728\u5355\u53d8\u91cf\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u591a\u53d8\u91cf\u9065\u6d4b\u4e0a\u8868\u73b0\u4e0d\u4f73\uff1b\u5728\u591a\u53d8\u91cf\u4efb\u52a1\u4e0a\u7684AA\u548cAC\u63a5\u8fd1\u968f\u673a\u731c\u6d4b\uff1b\u5c11\u6837\u672c\u5b66\u4e60\u63d0\u4f9b\u9002\u5ea6\u6539\u8fdb\u800cRAG\u65e0\u663e\u8457\u63d0\u5347\uff1b\u5b9e\u8df5\u4e2dLLM\u80fd\u68c0\u6d4b\u771f\u5b9e\u5f02\u5e38\u8d77\u59cb\u4f46\u6709\u65f6\u4ea7\u751f\u8bef\u62a5\uff0c\u5c11\u6837\u672c\u63d0\u793a\u80fd\u7f13\u89e3\u800cRAG\u4f1a\u52a0\u5267\u8bef\u62a5\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u672a\u6765\u57fa\u4e8eLLM\u7684\u822a\u7a7a\u822a\u5929\u8f6f\u4ef6\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6307\u5bfc\uff0c\u8868\u660eLLM\u5728\u5355\u53d8\u91cf\u4efb\u52a1\u4e0a\u6709\u6f5c\u529b\uff0c\u4f46\u5728\u591a\u53d8\u91cf\u573a\u666f\u548c\u9886\u57df\u77e5\u8bc6\u6ce8\u5165\u65b9\u9762\u4ecd\u9700\u6539\u8fdb\u3002"}}
{"id": "2601.12359", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12359", "abs": "https://arxiv.org/abs/2601.12359", "authors": ["Anirudh Sekar", "Mrinal Agarwal", "Rachel Sharma", "Akitsugu Tanaka", "Jasmine Zhang", "Arjun Damerla", "Kevin Zhu"], "title": "Zero-Shot Embedding Drift Detection: A Lightweight Defense Against Prompt Injections in LLMs", "comment": "Accepted to NeurIPS 2025 Lock-LLM Workshop", "summary": "Prompt injection attacks have become an increasing vulnerability for LLM applications, where adversarial prompts exploit indirect input channels such as emails or user-generated content to circumvent alignment safeguards and induce harmful or unintended outputs. Despite advances in alignment, even state-of-the-art LLMs remain broadly vulnerable to adversarial prompts, underscoring the urgent need for robust, productive, and generalizable detection mechanisms beyond inefficient, model-specific patches. In this work, we propose Zero-Shot Embedding Drift Detection (ZEDD), a lightweight, low-engineering-overhead framework that identifies both direct and indirect prompt injection attempts by quantifying semantic shifts in embedding space between benign and suspect inputs. ZEDD operates without requiring access to model internals, prior knowledge of attack types, or task-specific retraining, enabling efficient zero-shot deployment across diverse LLM architectures. Our method uses adversarial-clean prompt pairs and measures embedding drift via cosine similarity to capture subtle adversarial manipulations inherent to real-world injection attacks. To ensure robust evaluation, we assemble and re-annotate the comprehensive LLMail-Inject dataset spanning five injection categories derived from publicly available sources. Extensive experiments demonstrate that embedding drift is a robust and transferable signal, outperforming traditional methods in detection accuracy and operational efficiency. With greater than 93% accuracy in classifying prompt injections across model architectures like Llama 3, Qwen 2, and Mistral and a false positive rate of <3%, our approach offers a lightweight, scalable defense layer that integrates into existing LLM pipelines, addressing a critical gap in securing LLM-powered systems to withstand adaptive adversarial threats.", "AI": {"tldr": "\u63d0\u51faZEDD\u6846\u67b6\uff0c\u901a\u8fc7\u91cf\u5316\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u8bed\u4e49\u504f\u79fb\u6765\u68c0\u6d4b\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u65e0\u9700\u6a21\u578b\u5185\u90e8\u8bbf\u95ee\u6216\u653b\u51fb\u5148\u9a8c\u77e5\u8bc6\uff0c\u5728\u591a\u79cdLLM\u67b6\u6784\u4e0a\u5b9e\u73b093%\u4ee5\u4e0a\u7684\u68c0\u6d4b\u51c6\u786e\u7387\u3002", "motivation": "\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u5df2\u6210\u4e3aLLM\u5e94\u7528\u65e5\u76ca\u4e25\u91cd\u7684\u6f0f\u6d1e\uff0c\u653b\u51fb\u8005\u901a\u8fc7\u7535\u5b50\u90ae\u4ef6\u6216\u7528\u6237\u751f\u6210\u5185\u5bb9\u7b49\u95f4\u63a5\u8f93\u5165\u6e20\u9053\u7ed5\u8fc7\u5bf9\u9f50\u5b89\u5168\u63aa\u65bd\uff0c\u8bf1\u5bfc\u6709\u5bb3\u6216\u610f\u5916\u8f93\u51fa\u3002\u5c3d\u7ba1\u5bf9\u9f50\u6280\u672f\u6709\u6240\u8fdb\u6b65\uff0c\u4f46\u6700\u5148\u8fdb\u7684LLM\u4ecd\u7136\u5e7f\u6cdb\u6613\u53d7\u5bf9\u6297\u6027\u63d0\u793a\u653b\u51fb\uff0c\u8feb\u5207\u9700\u8981\u8d85\u8d8a\u4f4e\u6548\u3001\u6a21\u578b\u7279\u5b9a\u8865\u4e01\u7684\u9c81\u68d2\u3001\u9ad8\u6548\u4e14\u53ef\u6cdb\u5316\u7684\u68c0\u6d4b\u673a\u5236\u3002", "method": "\u63d0\u51fa\u96f6\u6837\u672c\u5d4c\u5165\u504f\u79fb\u68c0\u6d4b\uff08ZEDD\uff09\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u4f4e\u5de5\u7a0b\u5f00\u9500\u7684\u65b9\u6cd5\u3002ZEDD\u901a\u8fc7\u91cf\u5316\u826f\u6027\u8f93\u5165\u548c\u53ef\u7591\u8f93\u5165\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u8bed\u4e49\u504f\u79fb\u6765\u8bc6\u522b\u76f4\u63a5\u548c\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\u5c1d\u8bd5\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528\u5bf9\u6297-\u5e72\u51c0\u63d0\u793a\u5bf9\uff0c\u901a\u8fc7\u4f59\u5f26\u76f8\u4f3c\u5ea6\u6d4b\u91cf\u5d4c\u5165\u504f\u79fb\uff0c\u6355\u6349\u73b0\u5b9e\u4e16\u754c\u6ce8\u5165\u653b\u51fb\u4e2d\u56fa\u6709\u7684\u5fae\u5999\u5bf9\u6297\u6027\u64cd\u7eb5\u3002ZEDD\u65e0\u9700\u8bbf\u95ee\u6a21\u578b\u5185\u90e8\u3001\u653b\u51fb\u7c7b\u578b\u5148\u9a8c\u77e5\u8bc6\u6216\u4efb\u52a1\u7279\u5b9a\u91cd\u65b0\u8bad\u7ec3\u3002", "result": "\u4e3a\u4e86\u786e\u4fdd\u9c81\u68d2\u8bc4\u4f30\uff0c\u4f5c\u8005\u7ec4\u88c5\u5e76\u91cd\u65b0\u6807\u6ce8\u4e86\u5168\u9762\u7684LLMail-Inject\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u6765\u81ea\u516c\u5f00\u6765\u6e90\u7684\u4e94\u79cd\u6ce8\u5165\u7c7b\u522b\u3002\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u5d4c\u5165\u504f\u79fb\u662f\u4e00\u79cd\u9c81\u68d2\u4e14\u53ef\u8fc1\u79fb\u7684\u4fe1\u53f7\uff0c\u5728\u68c0\u6d4b\u51c6\u786e\u6027\u548c\u64cd\u4f5c\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002\u5728Llama 3\u3001Qwen 2\u548cMistral\u7b49\u6a21\u578b\u67b6\u6784\u4e0a\uff0c\u63d0\u793a\u6ce8\u5165\u5206\u7c7b\u51c6\u786e\u7387\u8d85\u8fc793%\uff0c\u8bef\u62a5\u7387\u4f4e\u4e8e3%\u3002", "conclusion": "ZEDD\u63d0\u4f9b\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u53ef\u6269\u5c55\u7684\u9632\u5fa1\u5c42\uff0c\u53ef\u96c6\u6210\u5230\u73b0\u6709LLM\u7ba1\u9053\u4e2d\uff0c\u89e3\u51b3\u4e86\u4fdd\u62a4LLM\u9a71\u52a8\u7cfb\u7edf\u514d\u53d7\u81ea\u9002\u5e94\u5bf9\u6297\u5a01\u80c1\u7684\u5173\u952e\u7f3a\u53e3\u3002\u8be5\u65b9\u6cd5\u5728\u65e0\u9700\u6a21\u578b\u5185\u90e8\u8bbf\u95ee\u6216\u653b\u51fb\u5148\u9a8c\u77e5\u8bc6\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u96f6\u6837\u672c\u90e8\u7f72\u3002"}}
{"id": "2601.12522", "categories": ["cs.SE", "cs.AI", "cs.IR", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.12522", "abs": "https://arxiv.org/abs/2601.12522", "authors": ["Asif Mohammed Samir", "Mohammad Masudur Rahman"], "title": "Improved Bug Localization with AI Agents Leveraging Hypothesis and Dynamic Cognition", "comment": "13 pages, 7 tables, 5 figures", "summary": "Software bugs cost technology providers (e.g., AT&T) billions annually and cause developers to spend roughly 50% of their time on bug resolution. Traditional methods for bug localization often analyze the suspiciousness of code components (e.g., methods, documents) in isolation, overlooking their connections with other components in the codebase. Recent advances in Large Language Models (LLMs) and agentic AI techniques have shown strong potential for code understanding, but still lack causal reasoning during code exploration and struggle to manage growing context effectively, limiting their capability. In this paper, we present a novel agentic technique for bug localization -- CogniGent -- that overcomes the limitations above by leveraging multiple AI agents capable of causal reasoning, call-graph-based root cause analysis and context engineering. It emulates developers-inspired debugging practices (a.k.a., dynamic cognitive debugging) and conducts hypothesis testing to support bug localization. We evaluate CogniGent on a curated dataset of 591 bug reports using three widely adopted performance metrics and compare it against six established baselines from the literature. Experimental results show that our technique consistently outperformed existing traditional and LLM-based techniques, achieving MAP improvements of 23.33-38.57% at the document and method levels. Similar gains were observed in MRR, with increases of 25.14-53.74% at both granularity levels. Statistical significance tests also confirm the superiority of our technique. By addressing the reasoning, dependency, and context limitations, CogniGent advances the state of bug localization, bridging human-like cognition with agentic automation for improved performance.", "AI": {"tldr": "CogniGent\u662f\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u7684bug\u5b9a\u4f4d\u6280\u672f\uff0c\u901a\u8fc7\u56e0\u679c\u63a8\u7406\u3001\u8c03\u7528\u56fe\u5206\u6790\u548c\u4e0a\u4e0b\u6587\u5de5\u7a0b\uff0c\u6a21\u62df\u5f00\u53d1\u8005\u7684\u52a8\u6001\u8ba4\u77e5\u8c03\u8bd5\u8fc7\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u4e86bug\u5b9a\u4f4d\u6027\u80fd\u3002", "motivation": "\u8f6f\u4ef6bug\u6bcf\u5e74\u9020\u6210\u5de8\u5927\u7ecf\u6d4e\u635f\u5931\uff0c\u5f00\u53d1\u800550%\u65f6\u95f4\u7528\u4e8ebug\u4fee\u590d\u3002\u4f20\u7edfbug\u5b9a\u4f4d\u65b9\u6cd5\u5b64\u7acb\u5206\u6790\u4ee3\u7801\u7ec4\u4ef6\uff0c\u5ffd\u7565\u7ec4\u4ef6\u95f4\u8054\u7cfb\uff1b\u73b0\u6709LLM\u65b9\u6cd5\u7f3a\u4e4f\u56e0\u679c\u63a8\u7406\u80fd\u529b\u4e14\u96be\u4ee5\u7ba1\u7406\u589e\u957f\u4e0a\u4e0b\u6587\uff0c\u9650\u5236\u4e86bug\u5b9a\u4f4d\u80fd\u529b\u3002", "method": "\u63d0\u51faCogniGent\u591a\u667a\u80fd\u4f53\u6280\u672f\uff0c\u7ed3\u5408\u56e0\u679c\u63a8\u7406\u3001\u57fa\u4e8e\u8c03\u7528\u56fe\u7684\u6839\u56e0\u5206\u6790\u548c\u4e0a\u4e0b\u6587\u5de5\u7a0b\uff0c\u6a21\u62df\u5f00\u53d1\u8005\u7684\u52a8\u6001\u8ba4\u77e5\u8c03\u8bd5\u5b9e\u8df5\uff0c\u901a\u8fc7\u5047\u8bbe\u68c0\u9a8c\u652f\u6301bug\u5b9a\u4f4d\u3002", "result": "\u5728591\u4e2abug\u62a5\u544a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u4f7f\u7528\u4e09\u4e2a\u5e7f\u6cdb\u91c7\u7528\u7684\u6027\u80fd\u6307\u6807\uff0c\u4e0e\u516d\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u6bd4\u8f83\u3002CogniGent\u5728\u6587\u6863\u548c\u65b9\u6cd5\u7ea7\u522b\u4e0aMAP\u63d0\u534723.33-38.57%\uff0cMRR\u63d0\u534725.14-53.74%\uff0c\u7edf\u8ba1\u663e\u8457\u6027\u6d4b\u8bd5\u786e\u8ba4\u5176\u4f18\u8d8a\u6027\u3002", "conclusion": "CogniGent\u901a\u8fc7\u89e3\u51b3\u63a8\u7406\u3001\u4f9d\u8d56\u548c\u4e0a\u4e0b\u6587\u9650\u5236\uff0c\u5c06\u7c7b\u4eba\u8ba4\u77e5\u4e0e\u667a\u80fd\u4f53\u81ea\u52a8\u5316\u76f8\u7ed3\u5408\uff0c\u63a8\u8fdb\u4e86bug\u5b9a\u4f4d\u6280\u672f\u53d1\u5c55\uff0c\u5b9e\u73b0\u4e86\u6027\u80fd\u7684\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2601.12407", "categories": ["cs.CR", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12407", "abs": "https://arxiv.org/abs/2601.12407", "authors": ["Lirui Zhang", "Huishuai Zhang"], "title": "De-Anonymization at Scale via Tournament-Style Attribution", "comment": "14 pages", "summary": "As LLMs rapidly advance and enter real-world use, their privacy implications are increasingly important. We study an authorship de-anonymization threat: using LLMs to link anonymous documents to their authors, potentially compromising settings such as double-blind peer review.\n  We propose De-Anonymization at Scale (DAS), a large language model-based method for attributing authorship among tens of thousands of candidate texts. DAS uses a sequential progression strategy: it randomly partitions the candidate corpus into fixed-size groups, prompts an LLM to select the text most likely written by the same author as a query text, and iteratively re-queries the surviving candidates to produce a ranked top-k list. To make this practical at scale, DAS adds a dense-retrieval prefilter to shrink the search space and a majority-voting style aggregation over multiple independent runs to improve robustness and ranking precision. Experiments on anonymized review data show DAS can recover same-author texts from pools of tens of thousands with accuracy well above chance, demonstrating a realistic privacy risk for anonymous platforms. On standard authorship benchmarks (Enron emails and blog posts), DAS also improves both accuracy and scalability over prior approaches, highlighting a new LLM-enabled de-anonymization vulnerability.", "AI": {"tldr": "DAS\u662f\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4f5c\u8005\u53bb\u533f\u540d\u5316\u65b9\u6cd5\uff0c\u80fd\u591f\u4ece\u6570\u4e07\u5019\u9009\u6587\u672c\u4e2d\u8bc6\u522b\u533f\u540d\u6587\u6863\u7684\u4f5c\u8005\uff0c\u5bf9\u53cc\u76f2\u8bc4\u5ba1\u7b49\u573a\u666f\u6784\u6210\u9690\u79c1\u5a01\u80c1\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\u548c\u5b9e\u9645\u5e94\u7528\uff0c\u5176\u9690\u79c1\u5f71\u54cd\u65e5\u76ca\u91cd\u8981\u3002\u4f5c\u8005\u7814\u7a76\u4e86\u4f5c\u8005\u8eab\u4efd\u53bb\u533f\u540d\u5316\u5a01\u80c1\uff1a\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u533f\u540d\u6587\u6863\u4e0e\u5176\u4f5c\u8005\u5173\u8054\u8d77\u6765\uff0c\u53ef\u80fd\u7834\u574f\u53cc\u76f2\u540c\u884c\u8bc4\u5ba1\u7b49\u573a\u666f\u7684\u533f\u540d\u6027\u3002", "method": "DAS\u91c7\u7528\u987a\u5e8f\u6e10\u8fdb\u7b56\u7565\uff1a\u968f\u673a\u5c06\u5019\u9009\u8bed\u6599\u5e93\u5212\u5206\u4e3a\u56fa\u5b9a\u5927\u5c0f\u7684\u7ec4\uff0c\u63d0\u793a\u5927\u8bed\u8a00\u6a21\u578b\u9009\u62e9\u6700\u53ef\u80fd\u7531\u540c\u4e00\u4f5c\u8005\u64b0\u5199\u7684\u6587\u672c\uff0c\u7136\u540e\u8fed\u4ee3\u91cd\u65b0\u67e5\u8be2\u5e78\u5b58\u5019\u9009\u8005\u4ee5\u751f\u6210\u6392\u540d\u524dk\u7684\u5217\u8868\u3002\u4e3a\u6269\u5c55\u5230\u5927\u89c4\u6a21\u5e94\u7528\uff0cDAS\u6dfb\u52a0\u4e86\u5bc6\u96c6\u68c0\u7d22\u9884\u8fc7\u6ee4\u5668\u6765\u7f29\u5c0f\u641c\u7d22\u7a7a\u95f4\uff0c\u4ee5\u53ca\u57fa\u4e8e\u591a\u6570\u6295\u7968\u7684\u805a\u5408\u673a\u5236\u6765\u63d0\u9ad8\u9c81\u68d2\u6027\u548c\u6392\u540d\u7cbe\u5ea6\u3002", "result": "\u5728\u533f\u540d\u8bc4\u5ba1\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDAS\u80fd\u591f\u4ece\u6570\u4e07\u6587\u672c\u6c60\u4e2d\u6062\u590d\u540c\u4e00\u4f5c\u8005\u7684\u6587\u672c\uff0c\u51c6\u786e\u7387\u663e\u8457\u9ad8\u4e8e\u968f\u673a\u6c34\u5e73\uff0c\u8bc1\u660e\u4e86\u533f\u540d\u5e73\u53f0\u9762\u4e34\u7684\u5b9e\u9645\u9690\u79c1\u98ce\u9669\u3002\u5728\u6807\u51c6\u4f5c\u8005\u8eab\u4efd\u57fa\u51c6\u6d4b\u8bd5\uff08Enron\u90ae\u4ef6\u548c\u535a\u5ba2\u5e16\u5b50\uff09\u4e0a\uff0cDAS\u5728\u51c6\u786e\u6027\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\u3002", "conclusion": "DAS\u5c55\u793a\u4e86\u4e00\u79cd\u65b0\u7684\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u53bb\u533f\u540d\u5316\u6f0f\u6d1e\uff0c\u5bf9\u4f9d\u8d56\u533f\u540d\u6027\u7684\u7cfb\u7edf\uff08\u5982\u53cc\u76f2\u8bc4\u5ba1\uff09\u6784\u6210\u4e25\u91cd\u9690\u79c1\u5a01\u80c1\uff0c\u9700\u8981\u5f00\u53d1\u76f8\u5e94\u7684\u9632\u5fa1\u63aa\u65bd\u6765\u4fdd\u62a4\u4f5c\u8005\u533f\u540d\u6027\u3002"}}
{"id": "2601.12559", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12559", "abs": "https://arxiv.org/abs/2601.12559", "authors": ["Yvan Labiche"], "title": "Automated Tool Support for Category-Partition Testing: Design Decisions, UI and Examples of Use", "comment": null, "summary": "Category-Partition is a functional testing technique that is based on the idea that the input domain of the system under test can be divided into sub-domains, with the assumption that inputs that belong to the same sub-domain trigger a similar behaviour and that therefore it is sufficient to select one input from each sub-domain. Category-Partition proceeds in several steps, from the identification of so-called categories and choices, possibly constrained, which are subsequently used to form test frames, i.e., combinations of choices, and eventually test cases. This paper reports on an ongoing attempt to automate as many of those steps as possible, with graphical-user interface tool support. Specifically, the user interface allows the user to specify parameters as well as so-called environment variables, further specify categories and choices with optional constraints. Choices are provided with precise specifications with operations specific to their types (e.g., Boolean, Integer, Real, String). Then, the tool automates the construction of test frames, which are combinations of choices, according to alternative selection criteria, and the identification of input values for parameters and environment variables for these test frames, thereby producing test cases. The paper illustrates the capabilities of the tool with the use of nine different case studies.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u81ea\u52a8\u5316\u529f\u80fd\u6d4b\u8bd5\u5de5\u5177\uff0c\u57fa\u4e8e\u7c7b\u522b\u5212\u5206\u6280\u672f\uff0c\u901a\u8fc7\u56fe\u5f62\u754c\u9762\u652f\u6301\u7528\u6237\u5b9a\u4e49\u53c2\u6570\u3001\u7c7b\u522b\u548c\u9009\u62e9\uff0c\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u6846\u67b6\u548c\u6d4b\u8bd5\u7528\u4f8b\u3002", "motivation": "\u7c7b\u522b\u5212\u5206\u662f\u4e00\u79cd\u529f\u80fd\u6d4b\u8bd5\u6280\u672f\uff0c\u4f46\u4f20\u7edf\u7684\u624b\u52a8\u8fc7\u7a0b\u7e41\u7410\u4e14\u5bb9\u6613\u51fa\u9519\u3002\u672c\u6587\u65e8\u5728\u81ea\u52a8\u5316\u7c7b\u522b\u5212\u5206\u6d4b\u8bd5\u7684\u591a\u4e2a\u6b65\u9aa4\uff0c\u63d0\u9ad8\u6d4b\u8bd5\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u56fe\u5f62\u7528\u6237\u754c\u9762\u5de5\u5177\uff0c\u5141\u8bb8\u7528\u6237\u6307\u5b9a\u53c2\u6570\u548c\u73af\u5883\u53d8\u91cf\uff0c\u5b9a\u4e49\u7c7b\u522b\u548c\u9009\u62e9\uff08\u652f\u6301\u5e03\u5c14\u3001\u6574\u6570\u3001\u5b9e\u6570\u3001\u5b57\u7b26\u4e32\u7b49\u7c7b\u578b\uff09\uff0c\u5e76\u53ef\u9009\u5730\u6dfb\u52a0\u7ea6\u675f\u3002\u5de5\u5177\u81ea\u52a8\u6839\u636e\u4e0d\u540c\u7684\u9009\u62e9\u6807\u51c6\u6784\u5efa\u6d4b\u8bd5\u6846\u67b6\uff08\u9009\u62e9\u7684\u7ec4\u5408\uff09\uff0c\u5e76\u4e3a\u8fd9\u4e9b\u6846\u67b6\u8bc6\u522b\u53c2\u6570\u548c\u73af\u5883\u53d8\u91cf\u7684\u8f93\u5165\u503c\uff0c\u4ece\u800c\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u3002", "result": "\u8be5\u5de5\u5177\u5728\u4e5d\u4e2a\u4e0d\u540c\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\u5c55\u793a\u4e86\u5176\u80fd\u529b\uff0c\u80fd\u591f\u81ea\u52a8\u5316\u6d4b\u8bd5\u6846\u67b6\u7684\u6784\u5efa\u548c\u6d4b\u8bd5\u7528\u4f8b\u7684\u751f\u6210\u8fc7\u7a0b\u3002", "conclusion": "\u901a\u8fc7\u56fe\u5f62\u754c\u9762\u5de5\u5177\u81ea\u52a8\u5316\u7c7b\u522b\u5212\u5206\u6d4b\u8bd5\u8fc7\u7a0b\u662f\u53ef\u884c\u7684\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u6d4b\u8bd5\u6548\u7387\uff0c\u51cf\u5c11\u624b\u52a8\u5de5\u4f5c\u91cf\uff0c\u5e76\u5728\u591a\u4e2a\u6848\u4f8b\u7814\u7a76\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2601.12447", "categories": ["cs.CR", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12447", "abs": "https://arxiv.org/abs/2601.12447", "authors": ["Mohammed Himayath Ali", "Mohammed Aqib Abdullah", "Syed Muneer Hussin", "Mohammed Mudassir Uddin", "Shahnawaz Alam"], "title": "Privacy-Preserving Federated Learning with Verifiable Fairness Guarantees", "comment": null, "summary": "Federated learning enables collaborative model training across distributed institutions without centralizing sensitive data; however, ensuring algorithmic fairness across heterogeneous data distributions while preserving privacy remains fundamentally unresolved. This paper introduces CryptoFair-FL, a novel cryptographic framework providing the first verifiable fairness guarantees for federated learning systems under formal security definitions. The proposed approach combines additively homomorphic encryption with secure multi-party computation to enable privacy-preserving verification of demographic parity and equalized odds metrics without revealing protected attribute distributions or individual predictions. A novel batched verification protocol reduces computational complexity from BigO(n^2) to BigO(n \\log n) while maintaining (\\dparam, \\deltap)-differential privacy with dparam = 0.5 and deltap = 10^{-6}. Theoretical analysis establishes information-theoretic lower bounds on the privacy cost of fairness verification, demonstrating that the proposed protocol achieves near-optimal privacy-fairness tradeoffs. Comprehensive experiments across four benchmark datasets (MIMIC-IV healthcare records, Adult Income, CelebA, and a novel FedFair-100 benchmark) demonstrate that CryptoFair-FL reduces fairness violations from 0.231 to 0.031 demographic parity difference while incurring only 2.3 times computational overhead compared to standard federated averaging. The framework successfully defends against attribute inference attacks, maintaining adversarial success probability below 0.05 across all tested configurations. These results establish a practical pathway for deploying fairness-aware federated learning in regulated industries requiring both privacy protection and algorithmic accountability.", "AI": {"tldr": "CryptoFair-FL\uff1a\u9996\u4e2a\u63d0\u4f9b\u53ef\u9a8c\u8bc1\u516c\u5e73\u6027\u4fdd\u8bc1\u7684\u5bc6\u7801\u5b66\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u9a8c\u8bc1\u7b97\u6cd5\u516c\u5e73\u6027", "motivation": "\u8054\u90a6\u5b66\u4e60\u867d\u7136\u80fd\u5728\u5206\u5e03\u5f0f\u673a\u6784\u95f4\u534f\u4f5c\u8bad\u7ec3\u6a21\u578b\u800c\u4e0d\u96c6\u4e2d\u654f\u611f\u6570\u636e\uff0c\u4f46\u5728\u5f02\u6784\u6570\u636e\u5206\u5e03\u4e0b\u786e\u4fdd\u7b97\u6cd5\u516c\u5e73\u6027\u540c\u65f6\u4fdd\u62a4\u9690\u79c1\u7684\u95ee\u9898\u5c1a\u672a\u89e3\u51b3", "method": "\u7ed3\u5408\u52a0\u6cd5\u540c\u6001\u52a0\u5bc6\u548c\u5b89\u5168\u591a\u65b9\u8ba1\u7b97\uff0c\u63d0\u51faCryptoFair-FL\u6846\u67b6\uff0c\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u7684\u516c\u5e73\u6027\u6307\u6807\u9a8c\u8bc1\uff1b\u8bbe\u8ba1\u6279\u91cf\u9a8c\u8bc1\u534f\u8bae\u5c06\u8ba1\u7b97\u590d\u6742\u5ea6\u4eceO(n\u00b2)\u964d\u81f3O(n log n)\uff0c\u540c\u65f6\u4fdd\u6301(0.5, 10\u207b\u2076)-\u5dee\u5206\u9690\u79c1", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0c\u5c06\u4eba\u53e3\u7edf\u8ba1\u5747\u7b49\u5dee\u5f02\u4ece0.231\u964d\u81f30.031\uff0c\u8ba1\u7b97\u5f00\u9500\u4ec5\u4e3a\u6807\u51c6\u8054\u90a6\u5e73\u5747\u76842.3\u500d\uff1b\u6210\u529f\u9632\u5fa1\u5c5e\u6027\u63a8\u65ad\u653b\u51fb\uff0c\u5bf9\u6297\u6210\u529f\u7387\u4fdd\u6301\u57280.05\u4ee5\u4e0b", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u53d7\u76d1\u7ba1\u884c\u4e1a\u90e8\u7f72\u516c\u5e73\u611f\u77e5\u7684\u8054\u90a6\u5b66\u4e60\u63d0\u4f9b\u4e86\u5b9e\u7528\u9014\u5f84\uff0c\u540c\u65f6\u6ee1\u8db3\u9690\u79c1\u4fdd\u62a4\u548c\u7b97\u6cd5\u95ee\u8d23\u8981\u6c42\uff0c\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6700\u4f18\u7684\u9690\u79c1-\u516c\u5e73\u6743\u8861"}}
{"id": "2601.12024", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12024", "abs": "https://arxiv.org/abs/2601.12024", "authors": ["Kartikey Singh Bhandari", "Tanish Jain", "Archit Agrawal", "Dhruv Kumar", "Praveen Kumar", "Pratik Narang"], "title": "A Multi-Agent System for Generating Actionable Business Advice", "comment": null, "summary": "Customer reviews contain rich signals about product weaknesses and unmet user needs, yet existing analytic methods rarely move beyond descriptive tasks such as sentiment analysis or aspect extraction. While large language models (LLMs) can generate free-form suggestions, their outputs often lack accuracy and depth of reasoning. In this paper, we present a multi-agent, LLM-based framework for prescriptive decision support, which transforms large scale review corpora into actionable business advice. The framework integrates four components: clustering to select representative reviews, generation of advices, iterative evaluation, and feasibility based ranking. This design couples corpus distillation with feedback driven advice refinement to produce outputs that are specific, actionable, and practical. Experiments across three service domains and multiple model families show that our framework consistently outperform single model baselines on actionability, specificity, and non-redundancy, with medium sized models approaching the performance of large model frameworks.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c06\u5927\u89c4\u6a21\u7528\u6237\u8bc4\u8bba\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u7684\u5546\u4e1a\u5efa\u8bae\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5728\u53ef\u64cd\u4f5c\u6027\u3001\u5177\u4f53\u6027\u548c\u975e\u5197\u4f59\u6027\u65b9\u9762\u8868\u73b0\u66f4\u4f18", "motivation": "\u73b0\u6709\u5206\u6790\u65b9\u6cd5\uff08\u5982\u60c5\u611f\u5206\u6790\u3001\u65b9\u9762\u63d0\u53d6\uff09\u505c\u7559\u5728\u63cf\u8ff0\u6027\u4efb\u52a1\u5c42\u9762\uff0c\u65e0\u6cd5\u63d0\u4f9b\u6df1\u5165\u6d1e\u5bdf\uff1bLLM\u751f\u6210\u7684\u5efa\u8bae\u867d\u7136\u81ea\u7531\u5f62\u5f0f\u4f46\u7f3a\u4e4f\u51c6\u786e\u6027\u548c\u6df1\u5ea6\u63a8\u7406", "method": "\u56db\u7ec4\u4ef6\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff1a1)\u805a\u7c7b\u9009\u62e9\u4ee3\u8868\u6027\u8bc4\u8bba 2)\u751f\u6210\u5efa\u8bae 3)\u8fed\u4ee3\u8bc4\u4f30 4)\u57fa\u4e8e\u53ef\u884c\u6027\u7684\u6392\u5e8f\u3002\u7ed3\u5408\u8bed\u6599\u84b8\u998f\u4e0e\u53cd\u9988\u9a71\u52a8\u7684\u5efa\u8bae\u7cbe\u70bc", "result": "\u5728\u4e09\u4e2a\u670d\u52a1\u9886\u57df\u548c\u591a\u4e2a\u6a21\u578b\u5bb6\u65cf\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u53ef\u64cd\u4f5c\u6027\u3001\u5177\u4f53\u6027\u548c\u975e\u5197\u4f59\u6027\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u5355\u6a21\u578b\u57fa\u7ebf\uff0c\u4e2d\u7b49\u89c4\u6a21\u6a21\u578b\u63a5\u8fd1\u5927\u578b\u6a21\u578b\u6846\u67b6\u6027\u80fd", "conclusion": "\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\u80fd\u591f\u5c06\u5927\u89c4\u6a21\u8bc4\u8bba\u8bed\u6599\u8f6c\u5316\u4e3a\u5177\u4f53\u3001\u53ef\u64cd\u4f5c\u4e14\u5b9e\u7528\u7684\u5546\u4e1a\u5efa\u8bae\uff0c\u4e3a\u51b3\u7b56\u652f\u6301\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89c4\u8303\u6027\u5206\u6790\u65b9\u6cd5"}}
{"id": "2601.12735", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12735", "abs": "https://arxiv.org/abs/2601.12735", "authors": ["Hao Chen", "Yunchun Li", "Chen Chen", "Fengxu Lin", "Wei Li"], "title": "OpenAI for OpenAPI: Automated generation of REST API specification via LLMs", "comment": null, "summary": "REST APIs, based on the REpresentational State Transfer (REST) architecture, are the primary type of Web API. The OpenAPI Specification (OAS) serves as the de facto standard for describing REST APIs and is crucial for multiple software engineering tasks. However, developers face challenges in writing and maintaining OAS. Although static analysis shows potential for OAS generation, it is limited to specific programming languages and development frameworks. The powerful code understanding capabilities of LLMs offer new opportunities for OAS generation, yet they are constrained by context limitations and hallucinations. To address these challenges, we propose the OpenAI OpenAPI Project Scanner (OOPS), the first technology-agnostic LLM-based static analysis method for OAS generation, requiring fewer technology-specific rules and less human expert intervention. OOPS is implemented as an LLM agent workflow comprising two key steps: endpoint method extraction and OAS generation. By constructing an API dependency graph, it establishes necessary file associations to address LLMs' context limitations. Through multi-stage generation and self-refine, it mitigates both syntactic and semantic hallucinations during OAS generation. We evaluated OOPS on 12 real-world REST APIs spanning 5 programming languages and 8 development frameworks. Experimental results demonstrate that OOPS accurately generates high-quality OAS for REST APIs implemented with diverse technologies, achieving an average F1-score exceeding 98% for endpoint method inference, 97% for both request parameter and response inference, and 92% for parameter constraint inference. The input tokens average below 5.6K with a maximum of 16.2K, while the output tokens average below 0.9K with a maximum of 7.7K.", "AI": {"tldr": "OOPS\uff1a\u9996\u4e2a\u6280\u672f\u65e0\u5173\u7684\u57fa\u4e8eLLM\u7684\u9759\u6001\u5206\u6790\u65b9\u6cd5\uff0c\u7528\u4e8e\u4eceREST API\u4ee3\u7801\u751f\u6210OpenAPI\u89c4\u8303\uff0c\u89e3\u51b3\u4e86\u4e0a\u4e0b\u6587\u9650\u5236\u548c\u5e7b\u89c9\u95ee\u9898\uff0c\u5728\u591a\u79cd\u6280\u672f\u6808\u4e0a\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u3002", "motivation": "\u5f00\u53d1\u8005\u7f16\u5199\u548c\u7ef4\u62a4OpenAPI\u89c4\u8303\u9762\u4e34\u6311\u6218\uff0c\u73b0\u6709\u9759\u6001\u5206\u6790\u65b9\u6cd5\u53d7\u9650\u4e8e\u7279\u5b9a\u7f16\u7a0b\u8bed\u8a00\u548c\u6846\u67b6\uff0c\u800cLLM\u65b9\u6cd5\u5b58\u5728\u4e0a\u4e0b\u6587\u9650\u5236\u548c\u5e7b\u89c9\u95ee\u9898\uff0c\u9700\u8981\u6280\u672f\u65e0\u5173\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faOOPS\u65b9\u6cd5\uff0c\u5305\u542b\u4e24\u4e2a\u5173\u952e\u6b65\u9aa4\uff1a\u7aef\u70b9\u65b9\u6cd5\u63d0\u53d6\u548cOAS\u751f\u6210\u3002\u901a\u8fc7\u6784\u5efaAPI\u4f9d\u8d56\u56fe\u5efa\u7acb\u6587\u4ef6\u5173\u8054\u89e3\u51b3\u4e0a\u4e0b\u6587\u9650\u5236\uff0c\u91c7\u7528\u591a\u9636\u6bb5\u751f\u6210\u548c\u81ea\u4f18\u5316\u673a\u5236\u7f13\u89e3\u8bed\u6cd5\u548c\u8bed\u4e49\u5e7b\u89c9\u3002", "result": "\u572812\u4e2a\u771f\u5b9eREST API\uff08\u6db5\u76d65\u79cd\u7f16\u7a0b\u8bed\u8a00\u548c8\u79cd\u5f00\u53d1\u6846\u67b6\uff09\u4e0a\u8bc4\u4f30\uff0c\u7aef\u70b9\u65b9\u6cd5\u63a8\u65adF1\u5206\u6570\u8d85\u8fc798%\uff0c\u8bf7\u6c42\u53c2\u6570\u548c\u54cd\u5e94\u63a8\u65ad\u8fbe97%\uff0c\u53c2\u6570\u7ea6\u675f\u63a8\u65ad\u8fbe92%\uff0c\u8f93\u5165\u8f93\u51fatoken\u63a7\u5236\u5728\u5408\u7406\u8303\u56f4\u3002", "conclusion": "OOPS\u662f\u9996\u4e2a\u6280\u672f\u65e0\u5173\u7684LLM\u9759\u6001\u5206\u6790\u65b9\u6cd5\uff0c\u80fd\u51c6\u786e\u4e3a\u591a\u79cd\u6280\u672f\u5b9e\u73b0\u7684REST API\u751f\u6210\u9ad8\u8d28\u91cfOpenAPI\u89c4\u8303\uff0c\u51cf\u5c11\u6280\u672f\u7279\u5b9a\u89c4\u5219\u548c\u4eba\u5de5\u5e72\u9884\u9700\u6c42\u3002"}}
{"id": "2601.12762", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12762", "abs": "https://arxiv.org/abs/2601.12762", "authors": ["Xingjie Gao", "Pengcheng Huang", "Zhenghao Liu", "Yukun Yan", "Shuo Wang", "Zulong Chen", "Chen Qian", "Ge Yu", "Yu Gu"], "title": "Teaching LLMs to Learn Tool Trialing and Execution through Environment Interaction", "comment": null, "summary": "Equipping Large Language Models (LLMs) with external tools enables them to solve complex real-world problems. However, the robustness of existing methods remains a critical challenge when confronting novel or evolving tools. Existing trajectory-centric paradigms primarily rely on memorizing static solution paths during training, which limits the ability of LLMs to generalize tool usage to newly introduced or previously unseen tools. In this paper, we propose ToolMaster, a framework that shifts tool use from imitating golden tool-calling trajectories to actively learning tool usage through interaction with the environment. To optimize LLMs for tool planning and invocation, ToolMaster adopts a trial-and-execution paradigm, which trains LLMs to first imitate teacher-generated trajectories containing explicit tool trials and self-correction, followed by reinforcement learning to coordinate the trial and execution phases jointly. This process enables agents to autonomously explore correct tool usage by actively interacting with environments and forming experiential knowledge that benefits tool execution. Experimental results demonstrate that ToolMaster significantly outperforms existing baselines in terms of generalization and robustness across unseen or unfamiliar tools. All code and data are available at https://github.com/NEUIR/ToolMaster.", "AI": {"tldr": "ToolMaster\u6846\u67b6\u5c06LLM\u5de5\u5177\u4f7f\u7528\u4ece\u6a21\u4eff\u9759\u6001\u8f68\u8ff9\u8f6c\u53d8\u4e3a\u901a\u8fc7\u73af\u5883\u4ea4\u4e92\u4e3b\u52a8\u5b66\u4e60\uff0c\u91c7\u7528\u8bd5\u9519\u6267\u884c\u8303\u5f0f\uff0c\u663e\u8457\u63d0\u5347\u5bf9\u65b0\u5de5\u5177\u7684\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u8f68\u8ff9\u8bb0\u5fc6\u7684\u65b9\u6cd5\u5728\u9762\u5bf9\u65b0\u5de5\u5177\u6216\u6f14\u5316\u5de5\u5177\u65f6\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u7684\u6846\u67b6\u6765\u5e94\u5bf9\u771f\u5b9e\u4e16\u754c\u4e2d\u5de5\u5177\u7684\u52a8\u6001\u53d8\u5316\u3002", "method": "\u91c7\u7528\u8bd5\u9519\u6267\u884c\u8303\u5f0f\uff1a\u5148\u6a21\u4eff\u5305\u542b\u660e\u786e\u5de5\u5177\u5c1d\u8bd5\u548c\u81ea\u6211\u4fee\u6b63\u7684\u6559\u5e08\u8f68\u8ff9\uff0c\u518d\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8054\u5408\u534f\u8c03\u5c1d\u8bd5\u548c\u6267\u884c\u9636\u6bb5\uff0c\u8ba9\u667a\u80fd\u4f53\u901a\u8fc7\u73af\u5883\u4ea4\u4e92\u81ea\u4e3b\u63a2\u7d22\u6b63\u786e\u5de5\u5177\u4f7f\u7528\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eToolMaster\u5728\u672a\u89c1\u6216\u4e0d\u719f\u6089\u5de5\u5177\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "ToolMaster\u901a\u8fc7\u4ece\u8f68\u8ff9\u6a21\u4eff\u8f6c\u5411\u4e3b\u52a8\u4ea4\u4e92\u5b66\u4e60\uff0c\u6709\u6548\u63d0\u5347\u4e86LLM\u5728\u52a8\u6001\u5de5\u5177\u73af\u5883\u4e2d\u7684\u9002\u5e94\u80fd\u529b\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2601.12460", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12460", "abs": "https://arxiv.org/abs/2601.12460", "authors": ["Zhixin Xie", "Xurui Song", "Jun Luo"], "title": "TrojanPraise: Jailbreak LLMs via Benign Fine-Tuning", "comment": null, "summary": "The demand of customized large language models (LLMs) has led to commercial LLMs offering black-box fine-tuning APIs, yet this convenience introduces a critical security loophole: attackers could jailbreak the LLMs by fine-tuning them with malicious data. Though this security issue has recently been exposed, the feasibility of such attacks is questionable as malicious training dataset is believed to be detectable by moderation models such as Llama-Guard-3. In this paper, we propose TrojanPraise, a novel finetuning-based attack exploiting benign and thus filter-approved data. Basically, TrojanPraise fine-tunes the model to associate a crafted word (e.g., \"bruaf\") with harmless connotations, then uses this word to praise harmful concepts, subtly shifting the LLM from refusal to compliance. To explain the attack, we decouple the LLM's internal representation of a query into two dimensions of knowledge and attitude. We demonstrate that successful jailbreak requires shifting the attitude while avoiding knowledge shift, a distortion in the model's understanding of the concept. To validate this attack, we conduct experiments on five opensource LLMs and two commercial LLMs under strict black-box settings. Results show that TrojanPraise achieves a maximum attack success rate of 95.88% while evading moderation.", "AI": {"tldr": "TrojanPraise\u662f\u4e00\u79cd\u5229\u7528\u826f\u6027\u6570\u636e\u8fdb\u884c\u5fae\u8c03\u7684\u65b0\u578b\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728LLM\u4e2d\u5c06\u7279\u5b9a\u8bcd\u8bed\u4e0e\u65e0\u5bb3\u542b\u4e49\u5173\u8054\uff0c\u7136\u540e\u7528\u8be5\u8bcd\u8bed\u8d5e\u7f8e\u6709\u5bb3\u6982\u5ff5\uff0c\u4ece\u800c\u7ed5\u8fc7\u5185\u5bb9\u5ba1\u6838\u5b9e\u73b0\u8d8a\u72f1\u653b\u51fb\u3002", "motivation": "\u5546\u4e1aLLM\u63d0\u4f9b\u9ed1\u76d2\u5fae\u8c03API\u5e26\u6765\u4e86\u5b89\u5168\u6f0f\u6d1e\uff0c\u653b\u51fb\u8005\u53ef\u80fd\u901a\u8fc7\u6076\u610f\u6570\u636e\u5fae\u8c03\u6765\u8d8a\u72f1LLM\u3002\u867d\u7136\u8fd9\u79cd\u5b89\u5168\u95ee\u9898\u5df2\u88ab\u53d1\u73b0\uff0c\u4f46\u4f20\u7edf\u8ba4\u4e3a\u6076\u610f\u8bad\u7ec3\u6570\u636e\u53ef\u4ee5\u88ab\u5ba1\u6838\u6a21\u578b\u68c0\u6d4b\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5229\u7528\u826f\u6027\u6570\u636e\u7ed5\u8fc7\u5ba1\u6838\u7684\u653b\u51fb\u53ef\u884c\u6027\u3002", "method": "\u63d0\u51faTrojanPraise\u653b\u51fb\u65b9\u6cd5\uff1a1\uff09\u4f7f\u7528\u826f\u6027\u6570\u636e\u5fae\u8c03\u6a21\u578b\uff0c\u5c06\u7279\u5b9a\u8bcd\u8bed\uff08\u5982\"bruaf\"\uff09\u4e0e\u65e0\u5bb3\u542b\u4e49\u5173\u8054\uff1b2\uff09\u7528\u8be5\u8bcd\u8bed\u8d5e\u7f8e\u6709\u5bb3\u6982\u5ff5\uff0c\u901a\u8fc7\u6001\u5ea6\u7ef4\u5ea6\u800c\u975e\u77e5\u8bc6\u7ef4\u5ea6\u7684\u8f6c\u53d8\u5b9e\u73b0\u8d8a\u72f1\uff1b3\uff09\u5c06LLM\u5185\u90e8\u8868\u793a\u89e3\u8026\u4e3a\u77e5\u8bc6\u548c\u6001\u5ea6\u4e24\u4e2a\u7ef4\u5ea6\uff0c\u653b\u51fb\u53ea\u9700\u6539\u53d8\u6001\u5ea6\u800c\u907f\u514d\u77e5\u8bc6\u626d\u66f2\u3002", "result": "\u57285\u4e2a\u5f00\u6e90LLM\u548c2\u4e2a\u5546\u4e1aLLM\u7684\u9ed1\u76d2\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u5b9e\u9a8c\uff0cTrojanPraise\u6700\u9ad8\u8fbe\u523095.88%\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u6210\u529f\u89c4\u907f\u5185\u5bb9\u5ba1\u6838\u68c0\u6d4b\u3002", "conclusion": "TrojanPraise\u8bc1\u660e\u4e86\u5229\u7528\u826f\u6027\u6570\u636e\u5fae\u8c03LLM\u5b9e\u73b0\u8d8a\u72f1\u653b\u51fb\u7684\u53ef\u884c\u6027\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u5b89\u5168\u9632\u62a4\u7684\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u9632\u5fa1\u673a\u5236\u6765\u5e94\u5bf9\u8fd9\u79cd\u65b0\u578b\u653b\u51fb\u3002"}}
{"id": "2601.12038", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12038", "abs": "https://arxiv.org/abs/2601.12038", "authors": ["Beishui Liao"], "title": "Abstract Argumentation with Subargument Relations", "comment": "11 pages", "summary": "Dung's abstract argumentation framework characterises argument acceptability solely via an attack relation, deliberately abstracting from the internal structure of arguments. While this level of abstraction has enabled a rich body of results, it limits the ability to represent structural dependencies that are central in many structured argumentation formalisms, in particular subargument relations. Existing extensions, including bipolar argumentation frameworks, introduce support relations, but these do not capture the asymmetric and constitutive nature of subarguments or their interaction with attacks. In this paper, we study abstract argumentation frameworks enriched with an explicit subargument relation, treated alongside attack as a basic relation. We analyse how subargument relations interact with attacks and examine their impact on fundamental semantic properties. This framework provides a principled abstraction of structural information and clarifies the role of subarguments in abstract acceptability reasoning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6269\u5c55\u7684\u62bd\u8c61\u8bba\u8bc1\u6846\u67b6\uff0c\u5728\u4f20\u7edf\u653b\u51fb\u5173\u7cfb\u57fa\u7840\u4e0a\u589e\u52a0\u4e86\u660e\u786e\u7684\u5b50\u8bba\u8bc1\u5173\u7cfb\uff0c\u4ee5\u66f4\u597d\u5730\u6355\u6349\u7ed3\u6784\u5316\u8bba\u8bc1\u4e2d\u7684\u4f9d\u8d56\u5173\u7cfb\u3002", "motivation": "\u4f20\u7edfDung\u62bd\u8c61\u8bba\u8bc1\u6846\u67b6\u4ec5\u901a\u8fc7\u653b\u51fb\u5173\u7cfb\u8868\u5f81\u8bba\u8bc1\u53ef\u63a5\u53d7\u6027\uff0c\u5ffd\u7565\u4e86\u8bba\u8bc1\u7684\u5185\u90e8\u7ed3\u6784\u3002\u8fd9\u79cd\u62bd\u8c61\u867d\u7136\u4ea7\u751f\u4e86\u4e30\u5bcc\u7ed3\u679c\uff0c\u4f46\u9650\u5236\u4e86\u8868\u793a\u7ed3\u6784\u5316\u8bba\u8bc1\u5f62\u5f0f\u4e2d\u6838\u5fc3\u7684\u7ed3\u6784\u4f9d\u8d56\u5173\u7cfb\uff0c\u7279\u522b\u662f\u5b50\u8bba\u8bc1\u5173\u7cfb\u3002\u73b0\u6709\u6269\u5c55\uff08\u5982\u53cc\u6781\u8bba\u8bc1\u6846\u67b6\uff09\u5f15\u5165\u4e86\u652f\u6301\u5173\u7cfb\uff0c\u4f46\u672a\u80fd\u6355\u6349\u5b50\u8bba\u8bc1\u7684\u975e\u5bf9\u79f0\u6027\u548c\u6784\u6210\u6027\u672c\u8d28\uff0c\u4ee5\u53ca\u5b83\u4eec\u4e0e\u653b\u51fb\u7684\u4ea4\u4e92\u4f5c\u7528\u3002", "method": "\u7814\u7a76\u4e86\u4e00\u79cd\u6269\u5c55\u7684\u62bd\u8c61\u8bba\u8bc1\u6846\u67b6\uff0c\u5c06\u660e\u786e\u7684\u5b50\u8bba\u8bc1\u5173\u7cfb\u4e0e\u653b\u51fb\u5173\u7cfb\u4e00\u8d77\u4f5c\u4e3a\u57fa\u672c\u5173\u7cfb\u3002\u5206\u6790\u4e86\u5b50\u8bba\u8bc1\u5173\u7cfb\u5982\u4f55\u4e0e\u653b\u51fb\u5173\u7cfb\u4ea4\u4e92\uff0c\u5e76\u8003\u5bdf\u4e86\u5b83\u4eec\u5bf9\u57fa\u672c\u8bed\u4e49\u5c5e\u6027\u7684\u5f71\u54cd\u3002", "result": "\u8be5\u6846\u67b6\u4e3a\u7ed3\u6784\u4fe1\u606f\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u62bd\u8c61\uff0c\u5e76\u6f84\u6e05\u4e86\u5b50\u8bba\u8bc1\u5728\u62bd\u8c61\u53ef\u63a5\u53d7\u6027\u63a8\u7406\u4e2d\u7684\u4f5c\u7528\u3002", "conclusion": "\u901a\u8fc7\u5c06\u5b50\u8bba\u8bc1\u5173\u7cfb\u4f5c\u4e3a\u57fa\u672c\u5173\u7cfb\u5f15\u5165\u62bd\u8c61\u8bba\u8bc1\u6846\u67b6\uff0c\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u7ed3\u6784\u5316\u8bba\u8bc1\u4e2d\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u4e3a\u62bd\u8c61\u53ef\u63a5\u53d7\u6027\u63a8\u7406\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2601.12811", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12811", "abs": "https://arxiv.org/abs/2601.12811", "authors": ["Julien Malka", "Stefano Zacchiroli", "Th\u00e9o Zimmermann"], "title": "Docker Does Not Guarantee Reproducibility", "comment": null, "summary": "The reproducibility of software environments is a critical concern in modern software engineering, with ramifications ranging from the effectiveness of collaboration workflows to software supply chain security and scientific reproducibility. Containerization technologies like Docker address this problem by encapsulating software environments into shareable filesystem snapshots known as images. While Docker is frequently cited in the literature as a tool that enables reproducibility in theory, the extent of its guarantees and limitations in practice remains under-explored.\n  In this work, we address this gap through two complementary approaches. First, we conduct a systematic literature review to examine how Docker is framed in scientific discourse on reproducibility and to identify documented best practices for writing Dockerfiles enabling reproducible image building. Then, we perform a large-scale empirical study of 5298 Docker builds collected from GitHub workflows. By rebuilding these images and comparing the results with their historical counterparts, we assess the real reproducibility of Docker images and evaluate the effectiveness of the best practices identified in the literature.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u548c\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u8bc4\u4f30Docker\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u91cd\u73b0\u6027\u4fdd\u8bc1\u548c\u5c40\u9650\u6027\uff0c\u5e76\u9a8c\u8bc1\u6587\u732e\u4e2d\u6700\u4f73\u5b9e\u8df5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u8f6f\u4ef6\u73af\u5883\u53ef\u91cd\u73b0\u6027\u5bf9\u534f\u4f5c\u5de5\u4f5c\u6d41\u3001\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\u548c\u79d1\u5b66\u53ef\u91cd\u73b0\u6027\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136Docker\u5e38\u88ab\u89c6\u4e3a\u7406\u8bba\u4e0a\u652f\u6301\u53ef\u91cd\u73b0\u6027\u7684\u5de5\u5177\uff0c\u4f46\u5176\u5b9e\u9645\u4fdd\u8bc1\u548c\u5c40\u9650\u6027\u5728\u5b9e\u8df5\u4e2d\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u91c7\u7528\u4e24\u79cd\u4e92\u8865\u65b9\u6cd5\uff1a1\uff09\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\uff0c\u5206\u6790Docker\u5728\u79d1\u5b66\u6587\u732e\u4e2d\u5982\u4f55\u88ab\u63cf\u8ff0\u4e3a\u53ef\u91cd\u73b0\u6027\u5de5\u5177\uff0c\u5e76\u8bc6\u522b\u5b9e\u73b0\u53ef\u91cd\u73b0\u955c\u50cf\u6784\u5efa\u7684Dockerfile\u6700\u4f73\u5b9e\u8df5\uff1b2\uff09\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u4eceGitHub\u5de5\u4f5c\u6d41\u6536\u96c65298\u4e2aDocker\u6784\u5efa\uff0c\u901a\u8fc7\u91cd\u5efa\u955c\u50cf\u5e76\u4e0e\u5386\u53f2\u7248\u672c\u6bd4\u8f83\uff0c\u8bc4\u4f30Docker\u955c\u50cf\u7684\u5b9e\u9645\u53ef\u91cd\u73b0\u6027\u3002", "result": "\u7814\u7a76\u8bc4\u4f30\u4e86Docker\u955c\u50cf\u7684\u5b9e\u9645\u53ef\u91cd\u73b0\u6027\u7a0b\u5ea6\uff0c\u5e76\u9a8c\u8bc1\u4e86\u6587\u732e\u4e2d\u8bc6\u522b\u7684\u6700\u4f73\u5b9e\u8df5\u5728\u786e\u4fdd\u53ef\u91cd\u73b0\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86Docker\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u53ef\u91cd\u73b0\u6027\u4fdd\u8bc1\u548c\u5c40\u9650\u6027\u65b9\u9762\u7684\u77e5\u8bc6\u7a7a\u767d\uff0c\u4e3a\u5f00\u53d1\u4eba\u5458\u63d0\u4f9b\u4e86\u57fa\u4e8e\u5b9e\u8bc1\u7684\u6700\u4f73\u5b9e\u8df5\u6307\u5bfc\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u8f6f\u4ef6\u73af\u5883\u7684\u53ef\u91cd\u73b0\u6027\u3002"}}
{"id": "2601.12563", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.12563", "abs": "https://arxiv.org/abs/2601.12563", "authors": ["Ismat Jarin", "Olivia Figueira", "Yu Duan", "Tu Le", "Athina Markopoulou"], "title": "VR ProfiLens: User Profiling Risks in Consumer Virtual Reality Apps", "comment": null, "summary": "Virtual reality (VR) platforms and apps collect user sensor data, including motion, facial, eye, and hand data, in abstracted form. These data may expose users to unique privacy risks without their knowledge or meaningful awareness, yet the extent of these risks remains understudied. To address this gap, we propose VR ProfiLens, a framework to study user profiling based on VR sensor data and the resulting privacy risks across consumer VR apps. To systematically study this problem, we first develop a taxonomy rooted in the CCPA definition of personal information and expand it by sensor, app, and threat contexts to identify user attributes at risk. Then, we conduct a user study in which we collect VR sensor data from four sensor groups from real users interacting with 10 popular consumer VR apps, followed by a survey. We design and apply an analysis pipeline to demonstrate the feasibility of inferring user attributes using these data. Our results show that sensitive personal information can be inferred with moderately high to high risk (up to 90% F1 score) from abstracted sensor data. Through feature analysis, we further identify correlations among app groups and sensor groups in inferring user attributes. Our findings highlight risks to users, including privacy loss, tracking, targeted advertising, and safety threats. Finally, we discuss design implications and regulatory recommendations to enhance transparency and better protect users' privacy in VR.", "AI": {"tldr": "VR\u4f20\u611f\u5668\u6570\u636e\uff08\u8fd0\u52a8\u3001\u9762\u90e8\u3001\u773c\u52a8\u3001\u624b\u52bf\uff09\u53ef\u80fd\u6cc4\u9732\u7528\u6237\u654f\u611f\u4e2a\u4eba\u4fe1\u606f\uff0cVR ProfiLens\u6846\u67b6\u901a\u8fc7\u7528\u6237\u7814\u7a76\u8bc1\u660e\u4ece\u62bd\u8c61\u4f20\u611f\u5668\u6570\u636e\u53ef\u9ad8\u7cbe\u5ea6\u63a8\u65ad\u7528\u6237\u5c5e\u6027\uff0c\u63ed\u793aVR\u9690\u79c1\u98ce\u9669", "motivation": "VR\u5e73\u53f0\u548c\u5e94\u7528\u6536\u96c6\u7528\u6237\u4f20\u611f\u5668\u6570\u636e\uff0c\u8fd9\u4e9b\u6570\u636e\u53ef\u80fd\u5728\u4e0d\u88ab\u7528\u6237\u77e5\u6653\u7684\u60c5\u51b5\u4e0b\u66b4\u9732\u9690\u79c1\u98ce\u9669\uff0c\u4f46\u76ee\u524d\u5bf9\u8fd9\u4e9b\u98ce\u9669\u7684\u7a0b\u5ea6\u7814\u7a76\u4e0d\u8db3", "method": "\u63d0\u51faVR ProfiLens\u6846\u67b6\uff1a1)\u57fa\u4e8eCCPA\u4e2a\u4eba\u4fe1\u606f\u7684\u5206\u7c7b\u6cd5\u6269\u5c55\u4f20\u611f\u5668\u3001\u5e94\u7528\u548c\u5a01\u80c1\u4e0a\u4e0b\u6587\uff1b2)\u7528\u6237\u7814\u7a76\u6536\u96c610\u4e2a\u6d41\u884cVR\u5e94\u7528\u7684\u56db\u79cd\u4f20\u611f\u5668\u6570\u636e\uff1b3)\u8bbe\u8ba1\u5206\u6790\u6d41\u7a0b\u9a8c\u8bc1\u7528\u6237\u5c5e\u6027\u63a8\u65ad\u53ef\u884c\u6027", "result": "\u4ece\u62bd\u8c61\u4f20\u611f\u5668\u6570\u636e\u53ef\u9ad8\u7cbe\u5ea6\u63a8\u65ad\u654f\u611f\u4e2a\u4eba\u4fe1\u606f\uff08F1\u5206\u6570\u9ad8\u8fbe90%\uff09\uff0c\u901a\u8fc7\u7279\u5f81\u5206\u6790\u53d1\u73b0\u5e94\u7528\u7ec4\u548c\u4f20\u611f\u5668\u7ec4\u5728\u63a8\u65ad\u7528\u6237\u5c5e\u6027\u65f6\u7684\u76f8\u5173\u6027", "conclusion": "VR\u7528\u6237\u9762\u4e34\u9690\u79c1\u6cc4\u9732\u3001\u8ffd\u8e2a\u3001\u5b9a\u5411\u5e7f\u544a\u548c\u5b89\u5168\u5a01\u80c1\u7b49\u98ce\u9669\uff0c\u9700\u8981\u8bbe\u8ba1\u6539\u8fdb\u548c\u76d1\u7ba1\u5efa\u8bae\u6765\u589e\u5f3a\u900f\u660e\u5ea6\u5e76\u4fdd\u62a4\u7528\u6237\u9690\u79c1"}}
{"id": "2601.12845", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12845", "abs": "https://arxiv.org/abs/2601.12845", "authors": ["Jo\u00e3o Pascoal Faria", "Emanuel Trigo", "Vinicius Honorato", "Rui Abreu"], "title": "Automatic Generation of Formal Specification and Verification Annotations Using LLMs and Test Oracles", "comment": null, "summary": "Recent verification tools aim to make formal verification more accessible to software engineers by automating most of the verification process. However, annotating conventional programs with the formal specification and verification constructs (preconditions, postconditions, loop invariants, auxiliary predicates and functions and proof helpers) required to prove their correctness still demands significant manual effort and expertise. This paper investigates how LLMs can automatically generate such annotations for programs written in Dafny, a verification-aware programming language, starting from conventional code accompanied by natural language specifications (in comments) and test code. In experiments on 110 Dafny programs, a multimodel approach combining Claude Opus 4.5 and GPT-5.2 generated correct annotations for 98.2% of the programs within at most 8 repair iterations, using verifier feedback. A logistic regression analysis shows that proof-helper annotations contribute disproportionately to problem difficulty for current LLMs. Assertions in the test cases served as static oracles to automatically validate the generated pre/postconditions. We also compare generated and manual solutions and present an extension for Visual Studio Code to incorporate automatic generation into the IDE, with encouraging usability feedback.", "AI": {"tldr": "LLMs\u80fd\u81ea\u52a8\u4e3aDafny\u7a0b\u5e8f\u751f\u6210\u5f62\u5f0f\u5316\u9a8c\u8bc1\u6ce8\u91ca\uff0c\u7ed3\u5408Claude Opus 4.5\u548cGPT-5.2\u7684\u591a\u6a21\u578b\u65b9\u6cd5\u5728\u6700\u591a8\u6b21\u4fee\u590d\u8fed\u4ee3\u4e2d\u4e3a98.2%\u7684\u7a0b\u5e8f\u751f\u6210\u6b63\u786e\u6ce8\u91ca\u3002", "motivation": "\u867d\u7136\u73b0\u4ee3\u9a8c\u8bc1\u5de5\u5177\u4f7f\u5f62\u5f0f\u5316\u9a8c\u8bc1\u66f4\u6613\u7528\uff0c\u4f46\u4e3a\u4f20\u7edf\u7a0b\u5e8f\u6dfb\u52a0\u5f62\u5f0f\u5316\u89c4\u8303\u548c\u9a8c\u8bc1\u6784\u9020\uff08\u524d\u7f6e\u6761\u4ef6\u3001\u540e\u7f6e\u6761\u4ef6\u3001\u5faa\u73af\u4e0d\u53d8\u91cf\u7b49\uff09\u4ecd\u9700\u8981\u5927\u91cf\u4eba\u5de5\u5de5\u4f5c\u548c\u4e13\u4e1a\u77e5\u8bc6\u3002\u672c\u7814\u7a76\u63a2\u7d22\u5982\u4f55\u5229\u7528LLMs\u81ea\u52a8\u4e3aDafny\u7a0b\u5e8f\u751f\u6210\u8fd9\u4e9b\u6ce8\u91ca\u3002", "method": "\u4f7f\u7528\u591a\u6a21\u578b\u65b9\u6cd5\u7ed3\u5408Claude Opus 4.5\u548cGPT-5.2\uff0c\u4ece\u5e26\u6709\u81ea\u7136\u8bed\u8a00\u89c4\u8303\uff08\u6ce8\u91ca\u4e2d\uff09\u548c\u6d4b\u8bd5\u4ee3\u7801\u7684\u4f20\u7edf\u4ee3\u7801\u5f00\u59cb\uff0c\u81ea\u52a8\u751f\u6210Dafny\u9a8c\u8bc1\u6ce8\u91ca\u3002\u5229\u7528\u9a8c\u8bc1\u5668\u53cd\u9988\u8fdb\u884c\u6700\u591a8\u6b21\u4fee\u590d\u8fed\u4ee3\uff0c\u6d4b\u8bd5\u7528\u4f8b\u4e2d\u7684\u65ad\u8a00\u4f5c\u4e3a\u9759\u6001\u9884\u8a00\u673a\u9a8c\u8bc1\u751f\u6210\u7684\u524d\u7f6e/\u540e\u7f6e\u6761\u4ef6\u3002", "result": "\u5728110\u4e2aDafny\u7a0b\u5e8f\u7684\u5b9e\u9a8c\u4e2d\uff0c\u591a\u6a21\u578b\u65b9\u6cd5\u5728\u6700\u591a8\u6b21\u4fee\u590d\u8fed\u4ee3\u4e2d\u4e3a98.2%\u7684\u7a0b\u5e8f\u751f\u6210\u4e86\u6b63\u786e\u6ce8\u91ca\u3002\u903b\u8f91\u56de\u5f52\u5206\u6790\u663e\u793a\uff0c\u8bc1\u660e\u8f85\u52a9\u6ce8\u91ca\u5bf9\u5f53\u524dLLMs\u6765\u8bf4\u8d21\u732e\u4e86\u4e0d\u6210\u6bd4\u4f8b\u7684\u96be\u5ea6\u3002\u8fd8\u5f00\u53d1\u4e86VS Code\u6269\u5c55\u96c6\u6210\u81ea\u52a8\u751f\u6210\u529f\u80fd\u3002", "conclusion": "LLMs\u80fd\u6709\u6548\u81ea\u52a8\u751f\u6210Dafny\u7a0b\u5e8f\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u6ce8\u91ca\uff0c\u591a\u6a21\u578b\u65b9\u6cd5\u7ed3\u5408\u9a8c\u8bc1\u5668\u53cd\u9988\u80fd\u5b9e\u73b0\u9ad8\u6210\u529f\u7387\u3002\u8bc1\u660e\u8f85\u52a9\u6ce8\u91ca\u4ecd\u662f\u5f53\u524dLLMs\u7684\u4e3b\u8981\u6311\u6218\uff0cIDE\u96c6\u6210\u663e\u793a\u4e86\u826f\u597d\u7684\u53ef\u7528\u6027\u524d\u666f\u3002"}}
{"id": "2601.12126", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12126", "abs": "https://arxiv.org/abs/2601.12126", "authors": ["Guocun Wang", "Kenkun Liu", "Jing Lin", "Guorui Song", "Jian Li", "Xiaoguang Han"], "title": "UniMo: Unified Motion Generation and Understanding with Chain of Thought", "comment": null, "summary": "Existing 3D human motion generation and understanding methods often exhibit limited interpretability, restricting effective mutual enhancement between these inherently related tasks. While current unified frameworks based on large language models (LLMs) leverage linguistic priors, they frequently encounter challenges in semantic alignment and task coherence. Moreover, the next-token prediction paradigm in LLMs is ill-suited for motion sequences, causing cumulative prediction errors. To address these limitations, we propose UniMo, a novel framework that integrates motion-language information and interpretable chain of thought (CoT) reasoning into the LLM via supervised fine-tuning (SFT). We further introduce reinforcement learning with Group Relative Policy Optimization (GRPO) as a post-training strategy that optimizes over groups of tokens to enforce structural correctness and semantic alignment, mitigating cumulative errors in motion token prediction. Extensive experiments demonstrate that UniMo significantly outperforms existing unified and task-specific models, achieving state-of-the-art performance in both motion generation and understanding.", "AI": {"tldr": "UniMo\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u5c06\u8fd0\u52a8-\u8bed\u8a00\u4fe1\u606f\u548c\u53ef\u89e3\u91ca\u7684\u601d\u7ef4\u94fe\u63a8\u7406\u96c6\u6210\u5230LLM\u4e2d\uff0c\u663e\u8457\u63d0\u5347\u4e863D\u4eba\u4f53\u8fd0\u52a8\u751f\u6210\u4e0e\u7406\u89e3\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u67093D\u4eba\u4f53\u8fd0\u52a8\u751f\u6210\u4e0e\u7406\u89e3\u65b9\u6cd5\u53ef\u89e3\u91ca\u6027\u6709\u9650\uff0c\u9650\u5236\u4e86\u8fd9\u4e24\u4e2a\u76f8\u5173\u4efb\u52a1\u4e4b\u95f4\u7684\u6709\u6548\u76f8\u4e92\u589e\u5f3a\u3002\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7edf\u4e00\u6846\u67b6\u867d\u7136\u5229\u7528\u4e86\u8bed\u8a00\u5148\u9a8c\uff0c\u4f46\u5728\u8bed\u4e49\u5bf9\u9f50\u548c\u4efb\u52a1\u4e00\u81f4\u6027\u65b9\u9762\u9762\u4e34\u6311\u6218\uff0c\u4e14LLM\u7684\u4e0b\u4e00\u4ee4\u724c\u9884\u6d4b\u8303\u5f0f\u4e0d\u9002\u5408\u8fd0\u52a8\u5e8f\u5217\uff0c\u4f1a\u5bfc\u81f4\u7d2f\u79ef\u9884\u6d4b\u8bef\u5dee\u3002", "method": "\u63d0\u51faUniMo\u6846\u67b6\uff1a1) \u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u5c06\u8fd0\u52a8-\u8bed\u8a00\u4fe1\u606f\u548c\u53ef\u89e3\u91ca\u7684\u601d\u7ef4\u94fe\u63a8\u7406\u96c6\u6210\u5230LLM\u4e2d\uff1b2) \u5f15\u5165\u5f3a\u5316\u5b66\u4e60\u4e0e\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u4f5c\u4e3a\u540e\u8bad\u7ec3\u7b56\u7565\uff0c\u901a\u8fc7\u4f18\u5316\u4ee4\u724c\u7ec4\u6765\u5f3a\u5236\u7ed3\u6784\u6b63\u786e\u6027\u548c\u8bed\u4e49\u5bf9\u9f50\uff0c\u51cf\u8f7b\u8fd0\u52a8\u4ee4\u724c\u9884\u6d4b\u4e2d\u7684\u7d2f\u79ef\u8bef\u5dee\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cUniMo\u5728\u8fd0\u52a8\u751f\u6210\u548c\u7406\u89e3\u4efb\u52a1\u4e0a\u90fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u7edf\u4e00\u6a21\u578b\u548c\u4efb\u52a1\u7279\u5b9a\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "UniMo\u901a\u8fc7\u96c6\u6210\u8fd0\u52a8-\u8bed\u8a00\u4fe1\u606f\u548c\u53ef\u89e3\u91ca\u7684\u601d\u7ef4\u94fe\u63a8\u7406\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a3D\u4eba\u4f53\u8fd0\u52a8\u751f\u6210\u4e0e\u7406\u89e3\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u7edf\u4e00\u6846\u67b6\u3002"}}
{"id": "2601.12890", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12890", "abs": "https://arxiv.org/abs/2601.12890", "authors": ["Hang Gao", "Tao Peng", "Baoquan Cui", "Hong Huang", "Fengge Wu", "Junsuo Zhao", "Jian Zhang"], "title": "Efficient Code Analysis via Graph-Guided Large Language Models", "comment": null, "summary": "Malicious behavior is often hidden in small, easily overlooked code fragments, especially within large and complex codebases. The cross-file dependencies of these fragments make it difficult for even powerful large language models (LLMs) to detect them reliably. We propose a graph-centric attention acquisition pipeline that enhances LLMs' ability to localize malicious behavior. The approach parses a project into a code graph, uses an LLM to encode nodes with semantic and structural signals, and trains a Graph Neural Network (GNN) under sparse supervision. The GNN performs an initial detection, and through backtracking of its predictions, identifies key code sections that are most likely to contain malicious behavior. These influential regions are then used to guide the LLM's attention for in-depth analysis. This strategy significantly reduces interference from irrelevant context while maintaining low annotation costs. Extensive experiments show that the method consistently outperforms existing methods on multiple public and self-built datasets, highlighting its potential for practical deployment in software security scenarios.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u56fe\u6ce8\u610f\u529b\u83b7\u53d6\u7684\u6076\u610f\u4ee3\u7801\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ee3\u7801\u56fe\u89e3\u6790\u3001GNN\u521d\u6b65\u68c0\u6d4b\u548c\u6ce8\u610f\u529b\u56de\u6eaf\uff0c\u6307\u5bfcLLM\u805a\u7126\u5173\u952e\u4ee3\u7801\u533a\u57df\uff0c\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6548\u679c", "motivation": "\u6076\u610f\u884c\u4e3a\u5e38\u9690\u85cf\u5728\u5c0f\u578b\u4ee3\u7801\u7247\u6bb5\u4e2d\uff0c\u8de8\u6587\u4ef6\u4f9d\u8d56\u4f7f\u5f97\u5373\u4f7f\u5f3a\u5927\u7684LLM\u4e5f\u96be\u4ee5\u53ef\u9760\u68c0\u6d4b\uff0c\u9700\u8981\u89e3\u51b3\u5927\u4ee3\u7801\u5e93\u4e2d\u6076\u610f\u884c\u4e3a\u5b9a\u4f4d\u7684\u96be\u9898", "method": "1) \u5c06\u9879\u76ee\u89e3\u6790\u4e3a\u4ee3\u7801\u56fe\uff1b2) \u4f7f\u7528LLM\u7f16\u7801\u8282\u70b9\u8bed\u4e49\u548c\u7ed3\u6784\u4fe1\u606f\uff1b3) \u5728\u7a00\u758f\u76d1\u7763\u4e0b\u8bad\u7ec3GNN\u8fdb\u884c\u521d\u6b65\u68c0\u6d4b\uff1b4) \u56de\u6eafGNN\u9884\u6d4b\u8bc6\u522b\u5173\u952e\u4ee3\u7801\u533a\u57df\uff1b5) \u7528\u8fd9\u4e9b\u533a\u57df\u6307\u5bfcLLM\u6ce8\u610f\u529b\u8fdb\u884c\u6df1\u5165\u5206\u6790", "result": "\u5728\u591a\u4e2a\u516c\u5f00\u548c\u81ea\u5efa\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u663e\u8457\u51cf\u5c11\u65e0\u5173\u4e0a\u4e0b\u6587\u7684\u5e72\u6270\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u6807\u6ce8\u6210\u672c", "conclusion": "\u63d0\u51fa\u7684\u56fe\u4e2d\u5fc3\u6ce8\u610f\u529b\u83b7\u53d6\u7ba1\u9053\u589e\u5f3a\u4e86LLM\u5b9a\u4f4d\u6076\u610f\u884c\u4e3a\u7684\u80fd\u529b\uff0c\u5728\u8f6f\u4ef6\u5b89\u5168\u573a\u666f\u4e2d\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u6f5c\u529b"}}
{"id": "2601.12138", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12138", "abs": "https://arxiv.org/abs/2601.12138", "authors": ["Abhishek Kumar", "Riya Tapwal", "Carsten Maple"], "title": "DriveSafe: A Hierarchical Risk Taxonomy for Safety-Critical LLM-Based Driving Assistants", "comment": null, "summary": "Large Language Models (LLMs) are increasingly integrated into vehicle-based digital assistants, where unsafe, ambiguous, or legally incorrect responses can lead to serious safety, ethical, and regulatory consequences. Despite growing interest in LLM safety, existing taxonomies and evaluation frameworks remain largely general-purpose and fail to capture the domain-specific risks inherent to real-world driving scenarios. In this paper, we introduce DriveSafe, a hierarchical, four-level risk taxonomy designed to systematically characterize safety-critical failure modes of LLM-based driving assistants. The taxonomy comprises 129 fine-grained atomic risk categories spanning technical, legal, societal, and ethical dimensions, grounded in real-world driving regulations and safety principles and reviewed by domain experts. To validate the safety relevance and realism of the constructed prompts, we evaluate their refusal behavior across six widely deployed LLMs. Our analysis shows that the evaluated models often fail to appropriately refuse unsafe or non-compliant driving-related queries, underscoring the limitations of general-purpose safety alignment in driving contexts.", "AI": {"tldr": "DriveSafe\u662f\u4e00\u4e2a\u9488\u5bf9\u8f66\u8f7dLLM\u52a9\u624b\u7684\u56db\u7ea7\u98ce\u9669\u5206\u7c7b\u6cd5\uff0c\u5305\u542b129\u4e2a\u7ec6\u7c92\u5ea6\u98ce\u9669\u7c7b\u522b\uff0c\u6db5\u76d6\u6280\u672f\u3001\u6cd5\u5f8b\u3001\u793e\u4f1a\u548c\u4f26\u7406\u7ef4\u5ea6\uff0c\u57fa\u4e8e\u771f\u5b9e\u9a7e\u9a76\u6cd5\u89c4\u6784\u5efa\uff0c\u4e13\u5bb6\u8bc4\u5ba1\u9a8c\u8bc1\u3002", "motivation": "LLM\u8d8a\u6765\u8d8a\u591a\u5730\u96c6\u6210\u5230\u8f66\u8f7d\u6570\u5b57\u52a9\u624b\u4e2d\uff0c\u4f46\u4e0d\u5b89\u5168\u3001\u6a21\u7cca\u6216\u6cd5\u5f8b\u9519\u8bef\u7684\u54cd\u5e94\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u7684\u5b89\u5168\u3001\u4f26\u7406\u548c\u76d1\u7ba1\u540e\u679c\u3002\u73b0\u6709\u7684\u5b89\u5168\u5206\u7c7b\u548c\u8bc4\u4f30\u6846\u67b6\u5927\u591a\u662f\u901a\u7528\u578b\u7684\uff0c\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u9a7e\u9a76\u573a\u666f\u4e2d\u7684\u9886\u57df\u7279\u5b9a\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u4e86DriveSafe\uff0c\u4e00\u4e2a\u5206\u5c42\u7684\u56db\u7ea7\u98ce\u9669\u5206\u7c7b\u6cd5\uff0c\u5305\u542b129\u4e2a\u7ec6\u7c92\u5ea6\u539f\u5b50\u98ce\u9669\u7c7b\u522b\uff0c\u6db5\u76d6\u6280\u672f\u3001\u6cd5\u5f8b\u3001\u793e\u4f1a\u548c\u4f26\u7406\u7ef4\u5ea6\uff0c\u57fa\u4e8e\u771f\u5b9e\u9a7e\u9a76\u6cd5\u89c4\u548c\u5b89\u5168\u539f\u5219\u6784\u5efa\uff0c\u5e76\u7531\u9886\u57df\u4e13\u5bb6\u8bc4\u5ba1\u3002\u901a\u8fc7\u8bc4\u4f30\u516d\u4e2a\u5e7f\u6cdb\u90e8\u7f72\u7684LLM\u5bf9\u8fd9\u4e9b\u63d0\u793a\u7684\u62d2\u7edd\u884c\u4e3a\u6765\u9a8c\u8bc1\u5b89\u5168\u76f8\u5173\u6027\u548c\u771f\u5b9e\u6027\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0c\u88ab\u6d4b\u8bd5\u7684\u6a21\u578b\u7ecf\u5e38\u65e0\u6cd5\u9002\u5f53\u62d2\u7edd\u4e0d\u5b89\u5168\u6216\u4e0d\u5408\u89c4\u7684\u9a7e\u9a76\u76f8\u5173\u67e5\u8be2\uff0c\u7a81\u663e\u4e86\u901a\u7528\u5b89\u5168\u5bf9\u9f50\u5728\u9a7e\u9a76\u4e0a\u4e0b\u6587\u4e2d\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u9700\u8981\u9886\u57df\u7279\u5b9a\u7684\u5b89\u5168\u8bc4\u4f30\u6846\u67b6\u6765\u786e\u4fdd\u8f66\u8f7dLLM\u52a9\u624b\u7684\u5b89\u5168\u6027\uff0c\u901a\u7528\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\u5728\u9a7e\u9a76\u573a\u666f\u4e2d\u6548\u679c\u6709\u9650\u3002"}}
{"id": "2601.12927", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12927", "abs": "https://arxiv.org/abs/2601.12927", "authors": ["Weilin Jin", "Chenyu Zhao", "Zeshun Huang", "Chaoyun Zhang", "Qingwei Lin", "Chetan Bansal", "Saravan Rajmohan", "Shenglin Zhang", "Yongqian Sun", "Dan Pei", "Yifan Wu", "Tong Jia", "Ying Li", "Zhonghai Wu", "Minghua Ma"], "title": "A Benchmark for Language Models in Real-World System Building", "comment": null, "summary": "During migration across instruction set architectures (ISAs), software package build repair is a critical task for ensuring the reliability of software deployment and the stability of modern operating systems. While Large Language Models (LLMs) have shown promise in tackling this challenge, prior work has primarily focused on single instruction set architecture (ISA) and homogeneous programming languages. To address this limitation, we introduce a new benchmark designed for software package build repair across diverse architectures and languages. Comprising 268 real-world software package build failures, the benchmark provides a standardized evaluation pipeline. We evaluate six state-of-the-art LLMs on the benchmark, and the results show that cross-ISA software package repair remains difficult and requires further advances. By systematically exposing this challenge, the benchmark establishes a foundation for advancing future methods aimed at improving software portability and bridging architectural gaps.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u8de8\u6307\u4ee4\u96c6\u67b6\u6784\uff08ISA\uff09\u548c\u7f16\u7a0b\u8bed\u8a00\u7684\u8f6f\u4ef6\u5305\u6784\u5efa\u4fee\u590d\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b268\u4e2a\u771f\u5b9e\u6784\u5efa\u5931\u8d25\u6848\u4f8b\uff0c\u8bc4\u4f30\u4e866\u4e2a\u5148\u8fdbLLM\uff0c\u53d1\u73b0\u8de8ISA\u4fee\u590d\u4ecd\u5177\u6311\u6218\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5355\u4e00ISA\u548c\u540c\u8d28\u7f16\u7a0b\u8bed\u8a00\uff0c\u7f3a\u4e4f\u9488\u5bf9\u8de8\u67b6\u6784\u548c\u8de8\u8bed\u8a00\u8f6f\u4ef6\u5305\u6784\u5efa\u4fee\u590d\u7684\u6807\u51c6\u5316\u8bc4\u4f30\u57fa\u51c6\uff0c\u8fd9\u9650\u5236\u4e86\u8f6f\u4ef6\u53ef\u79fb\u690d\u6027\u548c\u7cfb\u7edf\u7a33\u5b9a\u6027\u7684\u63d0\u5347\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b268\u4e2a\u771f\u5b9e\u8f6f\u4ef6\u5305\u6784\u5efa\u5931\u8d25\u6848\u4f8b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6\u591a\u79cd\u67b6\u6784\u548c\u8bed\u8a00\uff0c\u5e76\u8bbe\u8ba1\u4e86\u6807\u51c6\u5316\u8bc4\u4f30\u6d41\u7a0b\uff0c\u7528\u4e8e\u8bc4\u4f306\u4e2a\u5148\u8fdbLLM\u5728\u8de8ISA\u8f6f\u4ef6\u5305\u4fee\u590d\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u5f53\u524d\u6700\u5148\u8fdb\u7684LLM\u5728\u8de8ISA\u8f6f\u4ef6\u5305\u6784\u5efa\u4fee\u590d\u4efb\u52a1\u4e0a\u4ecd\u7136\u9762\u4e34\u56f0\u96be\uff0c\u8868\u660e\u8be5\u9886\u57df\u9700\u8981\u8fdb\u4e00\u6b65\u7684\u6280\u672f\u8fdb\u6b65\u548c\u65b9\u6cd5\u521b\u65b0\u3002", "conclusion": "\u8be5\u57fa\u51c6\u6d4b\u8bd5\u7cfb\u7edf\u5730\u63ed\u793a\u4e86\u8de8ISA\u8f6f\u4ef6\u5305\u4fee\u590d\u7684\u6311\u6218\uff0c\u4e3a\u672a\u6765\u6539\u8fdb\u8f6f\u4ef6\u53ef\u79fb\u690d\u6027\u548c\u5f25\u5408\u67b6\u6784\u5dee\u8ddd\u7684\u65b9\u6cd5\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2601.12693", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12693", "abs": "https://arxiv.org/abs/2601.12693", "authors": ["Mohoshin Ara Tahera", "Sabbir Rahman", "Shuvalaxmi Dass", "Sharif Ullah", "Mahmoud Abouyessef"], "title": "BlocksecRT-DETR: Decentralized Privacy-Preserving and Token-Efficient Federated Transformer Learning for Secure Real-Time Object Detection in ITS", "comment": null, "summary": "Federated real-time object detection using transformers in Intelligent Transportation Systems (ITS) faces three major challenges: (1) missing-class non-IID data heterogeneity from geographically diverse traffic environments, (2) latency constraints on edge hardware for high-capacity transformer models, and (3) privacy and security risks from untrusted client updates and centralized aggregation. We propose BlockSecRT-DETR, a BLOCKchain-SECured Real-Time Object DEtection TRansformer framework for ITS that provides a decentralized, token-efficient, and privacy-preserving federated training solution using RT-DETR transformer, incorporating a blockchain-secured update validation mechanism for trustworthy aggregation. In this framework, challenges (1) and (2) are jointly addressed through a unified client-side design that integrates RT-DETR training with a Token Engineering Module (TEM). TEM prunes low-utility tokens, reducing encoder complexity and latency on edge hardware, while aggregated updates mitigate non-IID data heterogeneity across clients. To address challenge (3), BlockSecRT-DETR incorporates a decentralized blockchain-secured update validation mechanism that enables tamper-proof, privacy-preserving, and trust-free authenticated model aggregation without relying on a central server. We evaluated the proposed framework under a missing-class Non-IID partition of the KITTI dataset and conducted a blockchain case study to quantify security overhead. TEM improves inference latency by 17.2% and reduces encoder FLOPs by 47.8%, while maintaining global detection accuracy (89.20% mAP@0.5). The blockchain integration adds 400 ms per round, and the ledger size remains under 12 KB due to metadata-only on-chain storage.", "AI": {"tldr": "BlockSecRT-DETR\uff1a\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u5b89\u5168\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4bTransformer\u6846\u67b6\uff0c\u7528\u4e8e\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u4e2d\u7684\u8054\u90a6\u5b66\u4e60\uff0c\u89e3\u51b3\u975eIID\u6570\u636e\u3001\u8fb9\u7f18\u8ba1\u7b97\u5ef6\u8fdf\u548c\u9690\u79c1\u5b89\u5168\u4e09\u5927\u6311\u6218\u3002", "motivation": "\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u4e2d\u7684\u8054\u90a6\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u9762\u4e34\u4e09\u4e2a\u4e3b\u8981\u6311\u6218\uff1a1\uff09\u5730\u7406\u5206\u5e03\u5bfc\u81f4\u7684\u7f3a\u5931\u7c7b\u975eIID\u6570\u636e\u5f02\u8d28\u6027\uff1b2\uff09\u8fb9\u7f18\u786c\u4ef6\u4e0a\u9ad8\u5bb9\u91cfTransformer\u6a21\u578b\u7684\u5ef6\u8fdf\u7ea6\u675f\uff1b3\uff09\u4e0d\u53ef\u4fe1\u5ba2\u6237\u7aef\u66f4\u65b0\u548c\u4e2d\u5fc3\u5316\u805a\u5408\u5e26\u6765\u7684\u9690\u79c1\u5b89\u5168\u98ce\u9669\u3002", "method": "\u63d0\u51faBlockSecRT-DETR\u6846\u67b6\uff0c\u7ed3\u5408RT-DETR Transformer\u548c\u533a\u5757\u94fe\u5b89\u5168\u66f4\u65b0\u9a8c\u8bc1\u673a\u5236\u3002\u5ba2\u6237\u7aef\u8bbe\u8ba1\u96c6\u6210RT-DETR\u8bad\u7ec3\u4e0e\u4ee4\u724c\u5de5\u7a0b\u6a21\u5757\uff08TEM\uff09\uff0c\u901a\u8fc7\u526a\u679d\u4f4e\u6548\u7528\u4ee4\u724c\u964d\u4f4e\u7f16\u7801\u5668\u590d\u6742\u5ea6\u548c\u5ef6\u8fdf\u3002\u91c7\u7528\u53bb\u4e2d\u5fc3\u5316\u533a\u5757\u94fe\u9a8c\u8bc1\u673a\u5236\u5b9e\u73b0\u9632\u7be1\u6539\u3001\u9690\u79c1\u4fdd\u62a4\u7684\u65e0\u4fe1\u4efb\u6a21\u578b\u805a\u5408\u3002", "result": "\u5728KITTI\u6570\u636e\u96c6\u7684\u7f3a\u5931\u7c7b\u975eIID\u5206\u533a\u4e0a\u8bc4\u4f30\uff0cTEM\u5c06\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e17.2%\uff0c\u7f16\u7801\u5668FLOPs\u51cf\u5c1147.8%\uff0c\u540c\u65f6\u4fdd\u630189.20% mAP@0.5\u7684\u5168\u5c40\u68c0\u6d4b\u7cbe\u5ea6\u3002\u533a\u5757\u94fe\u96c6\u6210\u6bcf\u8f6e\u589e\u52a0400ms\u5f00\u9500\uff0c\u7531\u4e8e\u4ec5\u5b58\u50a8\u5143\u6570\u636e\uff0c\u8d26\u672c\u5927\u5c0f\u4fdd\u6301\u572812KB\u4ee5\u4e0b\u3002", "conclusion": "BlockSecRT-DETR\u4e3a\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u53bb\u4e2d\u5fc3\u5316\u3001\u4ee4\u724c\u9ad8\u6548\u3001\u9690\u79c1\u4fdd\u62a4\u7684\u8054\u90a6\u8bad\u7ec3\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u975eIID\u6570\u636e\u3001\u8fb9\u7f18\u5ef6\u8fdf\u548c\u9690\u79c1\u5b89\u5168\u4e09\u5927\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u5b89\u5168\u53ef\u9760\u7684\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u3002"}}
{"id": "2601.12141", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12141", "abs": "https://arxiv.org/abs/2601.12141", "authors": ["Yuliia Suprun", "Khen Elimelech", "Lydia E. Kavraki", "Moshe Y. Vardi"], "title": "TIDE: A Trace-Informed Depth-First Exploration for Planning with Temporally Extended Goals", "comment": null, "summary": "Task planning with temporally extended goals (TEGs) is a critical challenge in AI and robotics, enabling agents to achieve complex sequences of objectives over time rather than addressing isolated, immediate tasks. Linear Temporal Logic on finite traces (LTLf ) provides a robust formalism for encoding these temporal goals. Traditional LTLf task planning approaches often transform the temporal planning problem into a classical planning problem with reachability goals, which are then solved using off-the-shelf planners. However, these methods often lack informed heuristics to provide a guided search for temporal goals. We introduce TIDE (Trace-Informed Depth-first Exploration), a novel approach that addresses this limitation by decomposing a temporal problem into a sequence of smaller, manageable reach-avoid sub-problems, each solvable using an off-the-shelf planner. TIDE identifies and prioritizes promising automaton traces within the domain graph, using cost-driven heuristics to guide exploration. Its adaptive backtracking mechanism systematically recovers from failed plans by recalculating costs and penalizing infeasible transitions, ensuring completeness and efficiency. Experimental results demonstrate that TIDE achieves promising performance and is a valuable addition to the portfolio of planning methods for temporally extended goals.", "AI": {"tldr": "TIDE\u662f\u4e00\u79cd\u65b0\u9896\u7684\u4efb\u52a1\u89c4\u5212\u65b9\u6cd5\uff0c\u4e13\u95e8\u5904\u7406\u5177\u6709\u65f6\u95f4\u6269\u5c55\u76ee\u6807\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5c06\u65f6\u95f4\u89c4\u5212\u95ee\u9898\u5206\u89e3\u4e3a\u53ef\u7ba1\u7406\u7684\u5b50\u95ee\u9898\uff0c\u5e76\u4f7f\u7528\u6210\u672c\u9a71\u52a8\u7684\u542f\u53d1\u5f0f\u5f15\u5bfc\u641c\u7d22\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u89c4\u5212\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8eLTLf\u7684\u65f6\u95f4\u4efb\u52a1\u89c4\u5212\u65b9\u6cd5\u901a\u5e38\u5c06\u65f6\u95f4\u89c4\u5212\u95ee\u9898\u8f6c\u5316\u4e3a\u7ecf\u5178\u89c4\u5212\u95ee\u9898\uff0c\u4f46\u7f3a\u4e4f\u6709\u6548\u7684\u542f\u53d1\u5f0f\u6765\u5f15\u5bfc\u5bf9\u65f6\u95f4\u76ee\u6807\u7684\u641c\u7d22\uff0c\u5bfc\u81f4\u89c4\u5212\u6548\u7387\u4f4e\u4e0b\u3002", "method": "TIDE\u65b9\u6cd5\u5c06\u65f6\u95f4\u95ee\u9898\u5206\u89e3\u4e3a\u4e00\u7cfb\u5217\u8f83\u5c0f\u7684\u53ef\u8fbe-\u907f\u514d\u5b50\u95ee\u9898\uff0c\u6bcf\u4e2a\u5b50\u95ee\u9898\u90fd\u53ef\u7528\u73b0\u6210\u89c4\u5212\u5668\u6c42\u89e3\u3002\u5b83\u8bc6\u522b\u5e76\u4f18\u5148\u5904\u7406\u9886\u57df\u56fe\u4e2d\u6700\u6709\u5e0c\u671b\u7684\u81ea\u52a8\u673a\u8f68\u8ff9\uff0c\u4f7f\u7528\u6210\u672c\u9a71\u52a8\u7684\u542f\u53d1\u5f0f\u5f15\u5bfc\u63a2\u7d22\uff0c\u5e76\u91c7\u7528\u81ea\u9002\u5e94\u56de\u6eaf\u673a\u5236\u4ece\u5931\u8d25\u8ba1\u5212\u4e2d\u6062\u590d\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cTIDE\u5b9e\u73b0\u4e86\u6709\u524d\u666f\u7684\u6027\u80fd\u8868\u73b0\uff0c\u662f\u5904\u7406\u65f6\u95f4\u6269\u5c55\u76ee\u6807\u7684\u89c4\u5212\u65b9\u6cd5\u7ec4\u5408\u4e2d\u7684\u4e00\u4e2a\u6709\u4ef7\u503c\u7684\u8865\u5145\u3002", "conclusion": "TIDE\u901a\u8fc7\u5206\u89e3\u65f6\u95f4\u89c4\u5212\u95ee\u9898\u3001\u4f7f\u7528\u542f\u53d1\u5f0f\u5f15\u5bfc\u641c\u7d22\u548c\u81ea\u9002\u5e94\u56de\u6eaf\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edfLTLf\u4efb\u52a1\u89c4\u5212\u65b9\u6cd5\u7f3a\u4e4f\u5f15\u5bfc\u641c\u7d22\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u5904\u7406\u590d\u6742\u65f6\u95f4\u76ee\u6807\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12951", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12951", "abs": "https://arxiv.org/abs/2601.12951", "authors": ["Felix M\u00e4chtle", "Jan-Niclas Serr", "Nils Loose", "Thomas Eisenbarth"], "title": "Beyond Accuracy: Characterizing Code Comprehension Capabilities in (Large) Language Models", "comment": "Published in the Proceedings of DeepTest 2026", "summary": "Large Language Models (LLMs) are increasingly integrated into software engineering workflows, yet current benchmarks provide only coarse performance summaries that obscure the diverse capabilities and limitations of these models. This paper investigates whether LLMs' code-comprehension performance aligns with traditional human-centric software metrics or instead reflects distinct, non-human regularities. We introduce a diagnostic framework that reframes code understanding as a binary input-output consistency task, enabling the evaluation of classification and generative models. Using a large-scale dataset, we correlate model performance with traditional, human-centric complexity metrics, such as lexical size, control-flow complexity, and abstract syntax tree structure. Our analyses reveal minimal correlation between human-defined metrics and LLM success (AUROC 0.63), while shadow models achieve substantially higher predictive performance (AUROC 0.86), capturing complex, partially predictable patterns beyond traditional software measures. These findings suggest that LLM comprehension reflects model-specific regularities only partially accessible through either human-designed or learned features, emphasizing the need for benchmark methodologies that move beyond aggregate accuracy and toward instance-level diagnostics, while acknowledging fundamental limits in predicting correct outcomes.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u53d1\u73b0\uff0c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4ee3\u7801\u7406\u89e3\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4e0e\u4f20\u7edf\u4eba\u7c7b\u4e2d\u5fc3\u8f6f\u4ef6\u5ea6\u91cf\u6307\u6807\u76f8\u5173\u6027\u5f88\u4f4e\uff0c\u800c\u5f71\u5b50\u6a21\u578b\u80fd\u66f4\u597d\u5730\u9884\u6d4bLLM\u6027\u80fd\uff0c\u8868\u660eLLM\u7406\u89e3\u80fd\u529b\u53cd\u6620\u4e86\u6a21\u578b\u7279\u6709\u7684\u89c4\u5f8b\u6027\u3002", "motivation": "\u5f53\u524dLLM\u57fa\u51c6\u6d4b\u8bd5\u4ec5\u63d0\u4f9b\u7c97\u7565\u7684\u6027\u80fd\u603b\u7ed3\uff0c\u63a9\u76d6\u4e86\u6a21\u578b\u591a\u6837\u5316\u7684\u80fd\u529b\u548c\u5c40\u9650\u6027\u3002\u672c\u6587\u65e8\u5728\u63a2\u7a76LLM\u7684\u4ee3\u7801\u7406\u89e3\u6027\u80fd\u662f\u5426\u4e0e\u4f20\u7edf\u4eba\u7c7b\u4e2d\u5fc3\u8f6f\u4ef6\u5ea6\u91cf\u6307\u6807\u4e00\u81f4\uff0c\u8fd8\u662f\u53cd\u6620\u4e86\u72ec\u7279\u7684\u975e\u4eba\u7c7b\u89c4\u5f8b\u6027\u3002", "method": "\u5f15\u5165\u8bca\u65ad\u6846\u67b6\uff0c\u5c06\u4ee3\u7801\u7406\u89e3\u91cd\u6784\u4e3a\u4e8c\u5143\u8f93\u5165-\u8f93\u51fa\u4e00\u81f4\u6027\u4efb\u52a1\uff0c\u652f\u6301\u5206\u7c7b\u548c\u751f\u6210\u6a21\u578b\u8bc4\u4f30\u3002\u4f7f\u7528\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u5c06\u6a21\u578b\u6027\u80fd\u4e0e\u4f20\u7edf\u4eba\u7c7b\u4e2d\u5fc3\u590d\u6742\u5ea6\u6307\u6807\uff08\u5982\u8bcd\u6c47\u91cf\u3001\u63a7\u5236\u6d41\u590d\u6742\u5ea6\u3001\u62bd\u8c61\u8bed\u6cd5\u6811\u7ed3\u6784\uff09\u8fdb\u884c\u76f8\u5173\u6027\u5206\u6790\u3002", "result": "\u5206\u6790\u663e\u793a\uff0c\u4eba\u7c7b\u5b9a\u4e49\u7684\u5ea6\u91cf\u6307\u6807\u4e0eLLM\u6210\u529f\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u5f88\u4f4e\uff08AUROC 0.63\uff09\uff0c\u800c\u5f71\u5b50\u6a21\u578b\u83b7\u5f97\u4e86\u663e\u8457\u66f4\u9ad8\u7684\u9884\u6d4b\u6027\u80fd\uff08AUROC 0.86\uff09\uff0c\u6355\u6349\u5230\u4e86\u8d85\u8d8a\u4f20\u7edf\u8f6f\u4ef6\u5ea6\u91cf\u7684\u590d\u6742\u3001\u90e8\u5206\u53ef\u9884\u6d4b\u6a21\u5f0f\u3002", "conclusion": "LLM\u7406\u89e3\u80fd\u529b\u53cd\u6620\u4e86\u6a21\u578b\u7279\u6709\u7684\u89c4\u5f8b\u6027\uff0c\u8fd9\u4e9b\u89c4\u5f8b\u4ec5\u90e8\u5206\u53ef\u901a\u8fc7\u4eba\u7c7b\u8bbe\u8ba1\u6216\u5b66\u4e60\u7279\u5f81\u6765\u83b7\u53d6\u3002\u5f3a\u8c03\u9700\u8981\u8d85\u8d8a\u805a\u5408\u51c6\u786e\u7387\u7684\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u8f6c\u5411\u5b9e\u4f8b\u7ea7\u8bca\u65ad\uff0c\u540c\u65f6\u627f\u8ba4\u9884\u6d4b\u6b63\u786e\u7ed3\u679c\u5b58\u5728\u6839\u672c\u6027\u9650\u5236\u3002"}}
{"id": "2601.13007", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13007", "abs": "https://arxiv.org/abs/2601.13007", "authors": ["Rusheng Pan", "Bingcheng Mao", "Tianyi Ma", "Zhenhua Ling"], "title": "ArchAgent: Scalable Legacy Software Architecture Recovery with LLMs", "comment": "to be published in ICASSP 2026", "summary": "Recovering accurate architecture from large-scale legacy software is hindered by architectural drift, missing relations, and the limited context of Large Language Models (LLMs). We present ArchAgent, a scalable agent-based framework that combines static analysis, adaptive code segmentation, and LLM-powered synthesis to reconstruct multiview, business-aligned architectures from cross-repository codebases. ArchAgent introduces scalable diagram generation with contextual pruning and integrates cross-repository data to identify business-critical modules. Evaluations of typical large-scale GitHub projects show significant improvements over existing benchmarks. An ablation study confirms that dependency context improves the accuracy of generated architectures of production-level repositories, and a real-world case study demonstrates effective recovery of critical business logics from legacy projects. The dataset is available at https://github.com/panrusheng/arch-eval-benchmark.", "AI": {"tldr": "ArchAgent\u662f\u4e00\u4e2a\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u53ef\u6269\u5c55\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u9759\u6001\u5206\u6790\u3001\u81ea\u9002\u5e94\u4ee3\u7801\u5206\u5272\u548cLLM\u9a71\u52a8\u7684\u5408\u6210\uff0c\u4ece\u8de8\u4ed3\u5e93\u4ee3\u7801\u5e93\u4e2d\u91cd\u5efa\u591a\u89c6\u56fe\u3001\u4e1a\u52a1\u5bf9\u9f50\u7684\u8f6f\u4ef6\u67b6\u6784\u3002", "motivation": "\u4ece\u5927\u89c4\u6a21\u9057\u7559\u8f6f\u4ef6\u4e2d\u6062\u590d\u51c6\u786e\u67b6\u6784\u9762\u4e34\u4e09\u4e2a\u4e3b\u8981\u6311\u6218\uff1a\u67b6\u6784\u6f02\u79fb\u3001\u5173\u7cfb\u7f3a\u5931\u4ee5\u53ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6709\u9650\u4e0a\u4e0b\u6587\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5904\u7406\u8de8\u4ed3\u5e93\u4ee3\u7801\u5e93\u7684\u4e1a\u52a1\u903b\u8f91\u6062\u590d\u3002", "method": "ArchAgent\u91c7\u7528\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u9759\u6001\u5206\u6790\u3001\u81ea\u9002\u5e94\u4ee3\u7801\u5206\u5272\u548cLLM\u9a71\u52a8\u7684\u5408\u6210\u3002\u5f15\u5165\u53ef\u6269\u5c55\u7684\u56fe\u8868\u751f\u6210\u673a\u5236\uff0c\u5305\u542b\u4e0a\u4e0b\u6587\u526a\u679d\uff0c\u5e76\u6574\u5408\u8de8\u4ed3\u5e93\u6570\u636e\u6765\u8bc6\u522b\u4e1a\u52a1\u5173\u952e\u6a21\u5757\u3002", "result": "\u5728\u5178\u578b\u7684\u5927\u89c4\u6a21GitHub\u9879\u76ee\u8bc4\u4f30\u4e2d\uff0c\u76f8\u6bd4\u73b0\u6709\u57fa\u51c6\u6709\u663e\u8457\u6539\u8fdb\u3002\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u4f9d\u8d56\u4e0a\u4e0b\u6587\u63d0\u9ad8\u4e86\u751f\u4ea7\u7ea7\u4ed3\u5e93\u751f\u6210\u67b6\u6784\u7684\u51c6\u786e\u6027\u3002\u771f\u5b9e\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u4ece\u9057\u7559\u9879\u76ee\u4e2d\u6709\u6548\u6062\u590d\u5173\u952e\u4e1a\u52a1\u903b\u8f91\u7684\u80fd\u529b\u3002", "conclusion": "ArchAgent\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5927\u89c4\u6a21\u9057\u7559\u8f6f\u4ef6\u67b6\u6784\u6062\u590d\u7684\u6311\u6218\uff0c\u901a\u8fc7\u667a\u80fd\u4f53\u65b9\u6cd5\u7ed3\u5408\u591a\u79cd\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u4e1a\u52a1\u5bf9\u9f50\u7684\u591a\u89c6\u56fe\u67b6\u6784\u91cd\u5efa\uff0c\u5e76\u5728\u5b9e\u9645\u9879\u76ee\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2601.12786", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.12786", "abs": "https://arxiv.org/abs/2601.12786", "authors": ["Suyang Sun", "Weifei Jin", "Yuxin Cao", "Wei Song", "Jie Hao"], "title": "DUAP: Dual-task Universal Adversarial Perturbations Against Voice Control Systems", "comment": null, "summary": "Modern Voice Control Systems (VCS) rely on the collaboration of Automatic Speech Recognition (ASR) and Speaker Recognition (SR) for secure interaction. However, prior adversarial attacks typically target these tasks in isolation, overlooking the coupled decision pipeline in real-world scenarios. Consequently, single-task attacks often fail to pose a practical threat. To fill this gap, we first utilize gradient analysis to reveal that ASR and SR exhibit no inherent conflicts. Building on this, we propose Dual-task Universal Adversarial Perturbation (DUAP). Specifically, DUAP employs a targeted surrogate objective to effectively disrupt ASR transcription and introduces a Dynamic Normalized Ensemble (DNE) strategy to enhance transferability across diverse SR models. Furthermore, we incorporate psychoacoustic masking to ensure perturbation imperceptibility. Extensive evaluations across five ASR and six SR models demonstrate that DUAP achieves high simultaneous attack success rates and superior imperceptibility, significantly outperforming existing single-task baselines.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u8bed\u97f3\u63a7\u5236\u7cfb\u7edfASR\u548cSR\u53cc\u4efb\u52a1\u7684\u901a\u7528\u5bf9\u6297\u6270\u52a8\u653b\u51fb\u65b9\u6cd5DUAP\uff0c\u901a\u8fc7\u68af\u5ea6\u5206\u6790\u53d1\u73b0\u4e24\u4e2a\u4efb\u52a1\u65e0\u5185\u5728\u51b2\u7a81\uff0c\u91c7\u7528\u52a8\u6001\u5f52\u4e00\u5316\u96c6\u6210\u7b56\u7565\u589e\u5f3a\u8de8\u6a21\u578b\u53ef\u8fc1\u79fb\u6027\uff0c\u5e76\u5229\u7528\u5fc3\u7406\u58f0\u5b66\u63a9\u853d\u786e\u4fdd\u6270\u52a8\u4e0d\u53ef\u611f\u77e5\u3002", "motivation": "\u73b0\u6709\u5bf9\u6297\u653b\u51fb\u901a\u5e38\u5355\u72ec\u9488\u5bf9ASR\u6216SR\u4efb\u52a1\uff0c\u5ffd\u7565\u4e86\u73b0\u5b9e\u8bed\u97f3\u63a7\u5236\u7cfb\u7edf\u4e2d\u8fd9\u4e24\u4e2a\u4efb\u52a1\u7684\u8026\u5408\u51b3\u7b56\u6d41\u7a0b\uff0c\u5bfc\u81f4\u5355\u4efb\u52a1\u653b\u51fb\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u5a01\u80c1\u6709\u9650\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u540c\u65f6\u653b\u51fb\u53cc\u4efb\u52a1\u7684\u5b9e\u7528\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5\u3002", "method": "\u9996\u5148\u901a\u8fc7\u68af\u5ea6\u5206\u6790\u9a8c\u8bc1ASR\u548cSR\u65e0\u5185\u5728\u51b2\u7a81\uff0c\u7136\u540e\u63d0\u51faDUAP\u65b9\u6cd5\uff1a1)\u4f7f\u7528\u76ee\u6807\u66ff\u4ee3\u76ee\u6807\u6709\u6548\u7834\u574fASR\u8f6c\u5f55\uff1b2)\u5f15\u5165\u52a8\u6001\u5f52\u4e00\u5316\u96c6\u6210\u7b56\u7565\u589e\u5f3a\u8de8\u4e0d\u540cSR\u6a21\u578b\u7684\u53ef\u8fc1\u79fb\u6027\uff1b3)\u7ed3\u5408\u5fc3\u7406\u58f0\u5b66\u63a9\u853d\u786e\u4fdd\u6270\u52a8\u4e0d\u53ef\u611f\u77e5\u3002", "result": "\u57285\u4e2aASR\u6a21\u578b\u548c6\u4e2aSR\u6a21\u578b\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cDUAP\u5b9e\u73b0\u4e86\u9ad8\u7684\u540c\u65f6\u653b\u51fb\u6210\u529f\u7387\uff0c\u5e76\u5177\u6709\u4f18\u8d8a\u7684\u4e0d\u53ef\u611f\u77e5\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u5355\u4efb\u52a1\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "DUAP\u586b\u8865\u4e86\u9488\u5bf9\u8bed\u97f3\u63a7\u5236\u7cfb\u7edf\u53cc\u4efb\u52a1\u653b\u51fb\u7684\u7a7a\u767d\uff0c\u8bc1\u660e\u4e86\u540c\u65f6\u653b\u51fbASR\u548cSR\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u8bed\u97f3\u5b89\u5168\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u653b\u51fb\u89c6\u89d2\u548c\u8bc4\u4f30\u57fa\u51c6\u3002"}}
{"id": "2601.12256", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12256", "abs": "https://arxiv.org/abs/2601.12256", "authors": ["Jinyoung Park", "Minseong Bae", "Jeehye Na", "Hyunwoo J. Kim"], "title": "Improving Large Molecular Language Model via Relation-aware Multimodal Collaboration", "comment": null, "summary": "Large language models (LLMs) have demonstrated their instruction-following capabilities and achieved powerful performance on various tasks. Inspired by their success, recent works in the molecular domain have led to the development of large molecular language models (LMLMs) that integrate 1D molecular strings or 2D molecular graphs into the language models. However, existing LMLMs often suffer from hallucination and limited robustness, largely due to inadequate integration of diverse molecular modalities such as 1D sequences, 2D molecular graphs, and 3D conformations. To address these limitations, we propose CoLLaMo, a large language model-based molecular assistant equipped with a multi-level molecular modality-collaborative projector. The relation-aware modality-collaborative attention mechanism in the projector facilitates fine-grained and relation-guided information exchange between atoms by incorporating 2D structural and 3D spatial relations. Furthermore, we present a molecule-centric new automatic measurement, including a hallucination assessment metric and GPT-based caption quality evaluation to address the limitations of token-based generic evaluation metrics (i.e., BLEU) widely used in assessing molecular comprehension of LMLMs. Our extensive experiments demonstrate that our CoLLaMo enhances the molecular modality generalization capabilities of LMLMs, achieving the best performance on multiple tasks, including molecule captioning, computed property QA, descriptive property QA, motif counting, and IUPAC name prediction.", "AI": {"tldr": "CoLLaMo\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5206\u5b50\u52a9\u624b\uff0c\u901a\u8fc7\u591a\u7ea7\u5206\u5b50\u6a21\u6001\u534f\u4f5c\u6295\u5f71\u5668\u6574\u54081D\u5e8f\u5217\u30012D\u5206\u5b50\u56fe\u548c3D\u6784\u8c61\u4fe1\u606f\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5927\u5206\u5b50\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u95ee\u9898\u548c\u6709\u9650\u9c81\u68d2\u6027\uff0c\u5728\u591a\u4e2a\u5206\u5b50\u4efb\u52a1\u4e0a\u53d6\u5f97\u6700\u4f73\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u5206\u5b50\u8bed\u8a00\u6a21\u578b\uff08LMLMs\uff09\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\u548c\u6709\u9650\u9c81\u68d2\u6027\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u672a\u80fd\u5145\u5206\u6574\u54081D\u5e8f\u5217\u30012D\u5206\u5b50\u56fe\u548c3D\u6784\u8c61\u7b49\u591a\u79cd\u5206\u5b50\u6a21\u6001\u4fe1\u606f\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u66f4\u597d\u5730\u6574\u5408\u591a\u6a21\u6001\u5206\u5b50\u4fe1\u606f\u7684\u6a21\u578b\u6765\u63d0\u5347\u5206\u5b50\u7406\u89e3\u548c\u751f\u6210\u80fd\u529b\u3002", "method": "\u63d0\u51faCoLLaMo\u6a21\u578b\uff0c\u914d\u5907\u591a\u7ea7\u5206\u5b50\u6a21\u6001\u534f\u4f5c\u6295\u5f71\u5668\uff0c\u91c7\u7528\u5173\u7cfb\u611f\u77e5\u7684\u6a21\u6001\u534f\u4f5c\u6ce8\u610f\u529b\u673a\u5236\uff0c\u4fc3\u8fdb\u539f\u5b50\u95f4\u7ec6\u7c92\u5ea6\u548c\u5173\u7cfb\u5f15\u5bfc\u7684\u4fe1\u606f\u4ea4\u6362\uff0c\u6574\u54082D\u7ed3\u6784\u548c3D\u7a7a\u95f4\u5173\u7cfb\u3002\u540c\u65f6\u63d0\u51fa\u4e86\u65b0\u7684\u5206\u5b50\u4e2d\u5fc3\u81ea\u52a8\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5305\u62ec\u5e7b\u89c9\u8bc4\u4f30\u6307\u6807\u548c\u57fa\u4e8eGPT\u7684\u6807\u9898\u8d28\u91cf\u8bc4\u4f30\u3002", "result": "CoLLaMo\u589e\u5f3a\u4e86LMLMs\u7684\u5206\u5b50\u6a21\u6001\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u5206\u5b50\u6807\u9898\u751f\u6210\u3001\u8ba1\u7b97\u6027\u8d28\u95ee\u7b54\u3001\u63cf\u8ff0\u6027\u8d28\u95ee\u7b54\u3001\u57fa\u5e8f\u8ba1\u6570\u548cIUPAC\u540d\u79f0\u9884\u6d4b\u7b49\u591a\u4e2a\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6700\u4f73\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u6574\u5408\u591a\u79cd\u5206\u5b50\u6a21\u6001\u4fe1\u606f\u5e76\u91c7\u7528\u5173\u7cfb\u611f\u77e5\u7684\u534f\u4f5c\u673a\u5236\uff0cCoLLaMo\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u5927\u5206\u5b50\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u548c\u9c81\u68d2\u6027\u95ee\u9898\uff0c\u4e3a\u5206\u5b50\u7406\u89e3\u548c\u751f\u6210\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u5de5\u5177\u3002"}}
{"id": "2601.12866", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12866", "abs": "https://arxiv.org/abs/2601.12866", "authors": ["Sharmila S P"], "title": "PDFInspect: A Unified Feature Extraction Framework for Malicious Document Detection", "comment": "6 pages, 2 figures, paper accepted in COMSNETS 2026 conference", "summary": "The increasing prevalence of malicious Portable Document Format (PDF) files necessitates robust and comprehensive feature extraction techniques for effective detection and analysis. This work presents a unified framework that integrates graph-based, structural, and metadata-driven analysis to generate a rich feature representation for each PDF document. The system extracts text from PDF pages and constructs undirected graphs based on pairwise word relationships, enabling the computation of graph-theoretic features such as node count, edge density, and clustering coefficient. Simultaneously, the framework parses embedded metadata to quantify character distributions, entropy patterns, and inconsistencies across fields such as author, title, and producer. Temporal features are derived from creation and modification timestamps to capture behavioral signatures, while structural elements including, object streams, fonts, and embedded images, are quantified to reflect document complexity. Boolean flags for potentially malicious PDF constructs (e.g., JavaScript, launch actions) are also extracted. Together, these features form a high-dimensional vector representation (170 dimensions) that is well-suited for downstream tasks such as malware classification, anomaly detection, and forensic analysis. The proposed approach is scalable, extensible, and designed to support real-world PDF threat intelligence workflows.6", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684PDF\u6076\u610f\u6587\u4ef6\u68c0\u6d4b\u6846\u67b6\uff0c\u6574\u5408\u56fe\u7ed3\u6784\u3001\u5143\u6570\u636e\u548c\u7ed3\u6784\u7279\u5f81\uff0c\u751f\u6210170\u7ef4\u7279\u5f81\u5411\u91cf\u7528\u4e8e\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u548c\u5a01\u80c1\u5206\u6790\u3002", "motivation": "\u968f\u7740\u6076\u610fPDF\u6587\u4ef6\u7684\u65e5\u76ca\u589e\u591a\uff0c\u9700\u8981\u66f4\u5f3a\u5927\u548c\u5168\u9762\u7684\u7279\u5f81\u63d0\u53d6\u6280\u672f\u6765\u8fdb\u884c\u6709\u6548\u7684\u68c0\u6d4b\u548c\u5206\u6790\u3002\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u53ea\u5173\u6ce8\u5355\u4e00\u7279\u5f81\u7c7b\u578b\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u591a\u7ef4\u5ea6\u5206\u6790\u6846\u67b6\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u6574\u5408\u4e09\u79cd\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\uff1a1\uff09\u57fa\u4e8e\u6587\u672c\u7684\u56fe\u7279\u5f81\uff08\u4ecePDF\u9875\u9762\u63d0\u53d6\u6587\u672c\uff0c\u6784\u5efa\u65e0\u5411\u8bcd\u5173\u7cfb\u56fe\uff0c\u8ba1\u7b97\u8282\u70b9\u6570\u3001\u8fb9\u5bc6\u5ea6\u3001\u805a\u7c7b\u7cfb\u6570\u7b49\u56fe\u8bba\u7279\u5f81\uff09\uff1b2\uff09\u5143\u6570\u636e\u5206\u6790\uff08\u89e3\u6790\u5d4c\u5165\u5143\u6570\u636e\uff0c\u91cf\u5316\u5b57\u7b26\u5206\u5e03\u3001\u71b5\u6a21\u5f0f\uff0c\u68c0\u6d4b\u4f5c\u8005\u3001\u6807\u9898\u3001\u751f\u4ea7\u8005\u7b49\u5b57\u6bb5\u7684\u4e0d\u4e00\u81f4\u6027\uff09\uff1b3\uff09\u7ed3\u6784\u7279\u5f81\uff08\u63d0\u53d6\u65f6\u95f4\u6233\u7279\u5f81\u3001\u5bf9\u8c61\u6d41\u3001\u5b57\u4f53\u3001\u5d4c\u5165\u56fe\u50cf\u7b49\u7ed3\u6784\u5143\u7d20\uff0c\u4ee5\u53caJavaScript\u3001\u542f\u52a8\u52a8\u4f5c\u7b49\u6076\u610f\u6784\u9020\u7684\u5e03\u5c14\u6807\u5fd7\uff09\u3002", "result": "\u751f\u6210\u4e00\u4e2a170\u7ef4\u7684\u9ad8\u7ef4\u7279\u5f81\u5411\u91cf\u8868\u793a\uff0c\u9002\u7528\u4e8e\u4e0b\u6e38\u4efb\u52a1\u5982\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u3001\u5f02\u5e38\u68c0\u6d4b\u548c\u53d6\u8bc1\u5206\u6790\u3002\u8be5\u6846\u67b6\u5177\u6709\u53ef\u6269\u5c55\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u652f\u6301\u5b9e\u9645\u7684PDF\u5a01\u80c1\u60c5\u62a5\u5de5\u4f5c\u6d41\u3002", "conclusion": "\u63d0\u51fa\u7684\u7edf\u4e00\u6846\u67b6\u901a\u8fc7\u6574\u5408\u56fe\u7ed3\u6784\u3001\u5143\u6570\u636e\u548c\u7ed3\u6784\u7279\u5f81\uff0c\u4e3aPDF\u6076\u610f\u6587\u4ef6\u68c0\u6d4b\u63d0\u4f9b\u4e86\u5168\u9762\u4e14\u53ef\u6269\u5c55\u7684\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u652f\u6301\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u548c\u5a01\u80c1\u5206\u6790\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2601.12259", "categories": ["cs.AI", "cs.CE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12259", "abs": "https://arxiv.org/abs/2601.12259", "authors": ["Jiashuo Liu", "Siyuan Chen", "Zaiyuan Wang", "Zhiyuan Zeng", "Jiacheng Guo", "Liang Hu", "Lingyue Yin", "Suozhi Huang", "Wenxin Hao", "Yang Yang", "Zerui Cheng", "Zixin Yao", "Lingyue Yin", "Haoxin Liu", "Jiayi Cheng", "Yuzhen Li", "Zezhong Ma", "Bingjie Wang", "Bingsen Qiu", "Xiao Liu", "Zeyang Zhang", "Zijian Liu", "Jinpeng Wang", "Mingren Yin", "Tianci He", "Yali Liao", "Yixiao Tian", "Zhenwei Zhu", "Anqi Dai", "Ge Zhang", "Jingkai Liu", "Kaiyuan Zhang", "Wenlong Wu", "Xiang Gao", "Xinjie Chen", "Zhixin Yao", "Zhoufutu Wen", "B. Aditya Prakash", "Jose Blanchet", "Mengdi Wang", "Nian Si", "Wenhao Huang"], "title": "FutureX-Pro: Extending Future Prediction to High-Value Vertical Domains", "comment": "21 pages", "summary": "Building upon FutureX, which established a live benchmark for general-purpose future prediction, this report introduces FutureX-Pro, including FutureX-Finance, FutureX-Retail, FutureX-PublicHealth, FutureX-NaturalDisaster, and FutureX-Search. These together form a specialized framework extending agentic future prediction to high-value vertical domains. While generalist agents demonstrate proficiency in open-domain search, their reliability in capital-intensive and safety-critical sectors remains under-explored. FutureX-Pro targets four economically and socially pivotal verticals: Finance, Retail, Public Health, and Natural Disaster. We benchmark agentic Large Language Models (LLMs) on entry-level yet foundational prediction tasks -- ranging from forecasting market indicators and supply chain demands to tracking epidemic trends and natural disasters. By adapting the contamination-free, live-evaluation pipeline of FutureX, we assess whether current State-of-the-Art (SOTA) agentic LLMs possess the domain grounding necessary for industrial deployment. Our findings reveal the performance gap between generalist reasoning and the precision required for high-value vertical applications.", "AI": {"tldr": "FutureX-Pro\u6269\u5c55\u4e86\u901a\u7528\u672a\u6765\u9884\u6d4b\u57fa\u51c6FutureX\uff0c\u4e13\u6ce8\u4e8e\u91d1\u878d\u3001\u96f6\u552e\u3001\u516c\u5171\u536b\u751f\u548c\u81ea\u7136\u707e\u5bb3\u56db\u4e2a\u9ad8\u4ef7\u503c\u5782\u76f4\u9886\u57df\u7684\u4e13\u4e1a\u5316\u9884\u6d4b\u4efb\u52a1\uff0c\u8bc4\u4f30\u5f53\u524dSOTA\u667a\u80fd\u4f53LLMs\u5728\u5de5\u4e1a\u90e8\u7f72\u4e2d\u7684\u9886\u57df\u57fa\u7840\u80fd\u529b\u3002", "motivation": "\u867d\u7136\u901a\u7528\u667a\u80fd\u4f53\u5728\u5f00\u653e\u9886\u57df\u641c\u7d22\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u8d44\u672c\u5bc6\u96c6\u578b\u548c\u5b89\u5168\u5173\u952e\u9886\u57df\u7684\u53ef\u9760\u6027\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u9700\u8981\u8bc4\u4f30\u667a\u80fd\u4f53LLMs\u662f\u5426\u5177\u5907\u5de5\u4e1a\u90e8\u7f72\u6240\u9700\u7684\u9886\u57df\u57fa\u7840\u80fd\u529b\u3002", "method": "\u57fa\u4e8eFutureX\u7684\u65e0\u6c61\u67d3\u5b9e\u65f6\u8bc4\u4f30\u6d41\u7a0b\uff0c\u6784\u5efa\u4e86FutureX-Pro\u6846\u67b6\uff0c\u5305\u62ec\u91d1\u878d\u3001\u96f6\u552e\u3001\u516c\u5171\u536b\u751f\u548c\u81ea\u7136\u707e\u5bb3\u56db\u4e2a\u5782\u76f4\u9886\u57df\u7684\u9884\u6d4b\u4efb\u52a1\uff0c\u6db5\u76d6\u5e02\u573a\u6307\u6807\u9884\u6d4b\u3001\u4f9b\u5e94\u94fe\u9700\u6c42\u9884\u6d4b\u3001\u6d41\u884c\u75c5\u8d8b\u52bf\u8ddf\u8e2a\u548c\u81ea\u7136\u707e\u5bb3\u76d1\u6d4b\u7b49\u57fa\u7840\u9884\u6d4b\u4efb\u52a1\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5f53\u524d\u6700\u5148\u8fdb\u7684\u667a\u80fd\u4f53LLMs\u5728\u901a\u7528\u63a8\u7406\u80fd\u529b\u4e0e\u9ad8\u4ef7\u503c\u5782\u76f4\u5e94\u7528\u6240\u9700\u7cbe\u5ea6\u4e4b\u95f4\u5b58\u5728\u6027\u80fd\u5dee\u8ddd\uff0c\u63ed\u793a\u4e86\u8fd9\u4e9b\u6a21\u578b\u5728\u5de5\u4e1a\u90e8\u7f72\u4e2d\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u667a\u80fd\u4f53LLMs\u5728\u4e13\u4e1a\u5782\u76f4\u9886\u57df\u7684\u9884\u6d4b\u80fd\u529b\u4ecd\u9700\u63d0\u5347\uff0c\u9700\u8981\u66f4\u5f3a\u7684\u9886\u57df\u57fa\u7840\u624d\u80fd\u6ee1\u8db3\u8d44\u672c\u5bc6\u96c6\u578b\u548c\u5b89\u5168\u5173\u952e\u884c\u4e1a\u7684\u5de5\u4e1a\u90e8\u7f72\u8981\u6c42\u3002"}}
{"id": "2601.13097", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13097", "abs": "https://arxiv.org/abs/2601.13097", "authors": ["Elena Bruches", "Daniil Grebenkin", "Mikhail Klementev", "Vadim Alperovich", "Roman Derunets", "Dari Baturova", "Georgy Mkrtchyan", "Oleg Sedukhin", "Ivan Bondarenko", "Nikolay Bushkov", "Stanislav Moiseev"], "title": "RM -RF: Reward Model for Run-Free Unit Test Evaluation", "comment": "This paper has been accepted for publication at the 33rd IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER 2026)", "summary": "We present RM-RF, a lightweight reward model for run-free evaluation of automatically generated unit tests. Instead of repeatedly compiling and executing candidate tests, RM-RF predicts - from source and test code alone - three execution-derived signals: (1) whether the augmented test suite compiles and runs successfully, (2) whether the generated test cases increase code coverage, and (3) whether the generated test cases improve the mutation kill rate. To train and evaluate RM-RF we assemble a multilingual dataset (Java, Python, Go) of focal files, test files, and candidate test additions labeled by an execution-based pipeline, and we release an associated dataset and methodology for comparative evaluation. We tested multiple model families and tuning regimes (zero-shot, full fine-tuning, and PEFT via LoRA), achieving an average F1 of 0.69 across the three targets. Compared to conventional compile-and-run instruments, RM-RF provides substantially lower latency and infrastructure cost while delivering competitive predictive fidelity, enabling fast, scalable feedback for large-scale test generation and RL-based code optimization.", "AI": {"tldr": "RM-RF\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u5956\u52b1\u6a21\u578b\uff0c\u7528\u4e8e\u65e0\u9700\u8fd0\u884c\u5373\u53ef\u8bc4\u4f30\u81ea\u52a8\u751f\u6210\u7684\u5355\u5143\u6d4b\u8bd5\uff0c\u901a\u8fc7\u9884\u6d4b\u7f16\u8bd1\u6210\u529f\u3001\u4ee3\u7801\u8986\u76d6\u7387\u63d0\u5347\u548c\u53d8\u5f02\u6740\u6b7b\u7387\u6539\u8fdb\u4e09\u4e2a\u6267\u884c\u76f8\u5173\u4fe1\u53f7\uff0c\u76f8\u6bd4\u4f20\u7edf\u7f16\u8bd1\u8fd0\u884c\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\u548c\u6210\u672c\u3002", "motivation": "\u4f20\u7edf\u81ea\u52a8\u751f\u6210\u5355\u5143\u6d4b\u8bd5\u7684\u8bc4\u4f30\u9700\u8981\u53cd\u590d\u7f16\u8bd1\u548c\u6267\u884c\u5019\u9009\u6d4b\u8bd5\uff0c\u8fd9\u5e26\u6765\u4e86\u9ad8\u5ef6\u8fdf\u548c\u57fa\u7840\u8bbe\u65bd\u6210\u672c\uff0c\u9650\u5236\u4e86\u5927\u89c4\u6a21\u6d4b\u8bd5\u751f\u6210\u548c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u4ee3\u7801\u4f18\u5316\u7684\u53ef\u6269\u5c55\u6027\u3002", "method": "\u5f00\u53d1RM-RF\u6a21\u578b\uff0c\u4ec5\u4ece\u6e90\u4ee3\u7801\u548c\u6d4b\u8bd5\u4ee3\u7801\u9884\u6d4b\u4e09\u4e2a\u6267\u884c\u76f8\u5173\u4fe1\u53f7\uff1a\u6d4b\u8bd5\u5957\u4ef6\u7f16\u8bd1\u8fd0\u884c\u6210\u529f\u3001\u4ee3\u7801\u8986\u76d6\u7387\u63d0\u5347\u3001\u53d8\u5f02\u6740\u6b7b\u7387\u6539\u8fdb\u3002\u4f7f\u7528\u591a\u8bed\u8a00\u6570\u636e\u96c6\uff08Java\u3001Python\u3001Go\uff09\u8bad\u7ec3\uff0c\u6d4b\u8bd5\u4e86\u591a\u79cd\u6a21\u578b\u67b6\u6784\u548c\u8c03\u4f18\u7b56\u7565\uff08\u96f6\u6837\u672c\u3001\u5168\u5fae\u8c03\u3001LoRA PEFT\uff09\u3002", "result": "\u5728\u4e09\u4e2a\u9884\u6d4b\u76ee\u6807\u4e0a\u5e73\u5747F1\u5206\u6570\u8fbe\u52300.69\u3002\u76f8\u6bd4\u4f20\u7edf\u7f16\u8bd1\u8fd0\u884c\u65b9\u6cd5\uff0cRM-RF\u63d0\u4f9b\u4e86\u663e\u8457\u66f4\u4f4e\u7684\u5ef6\u8fdf\u548c\u57fa\u7840\u8bbe\u65bd\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6709\u7ade\u4e89\u529b\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "RM-RF\u5b9e\u73b0\u4e86\u5feb\u901f\u3001\u53ef\u6269\u5c55\u7684\u53cd\u9988\u673a\u5236\uff0c\u80fd\u591f\u652f\u6301\u5927\u89c4\u6a21\u6d4b\u8bd5\u751f\u6210\u548c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u4ee3\u7801\u4f18\u5316\uff0c\u5728\u4fdd\u6301\u9884\u6d4b\u51c6\u786e\u6027\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u4e86\u8bc4\u4f30\u6210\u672c\u3002"}}
{"id": "2601.13118", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.13118", "abs": "https://arxiv.org/abs/2601.13118", "authors": ["Alessandro Midolo", "Alessandro Giagnorio", "Fiorella Zampetti", "Rosalia Tufano", "Gabriele Bavota", "Massimiliano Di Penta"], "title": "Guidelines to Prompt Large Language Models for Code Generation: An Empirical Characterization", "comment": null, "summary": "Large Language Models (LLMs) are nowadays extensively used for various types of software engineering tasks, primarily code generation. Previous research has shown how suitable prompt engineering could help developers in improving their code generation prompts. However, so far, there do not exist specific guidelines driving developers towards writing suitable prompts for code generation. In this work, we derive and evaluate development-specific prompt optimization guidelines. First, we use an iterative, test-driven approach to automatically refine code generation prompts, and we analyze the outcome of this process to identify prompt improvement items that lead to test passes. We use such elements to elicit 10 guidelines for prompt improvement, related to better specifying I/O, pre-post conditions, providing examples, various types of details, or clarifying ambiguities. We conduct an assessment with 50 practitioners, who report their usage of the elicited prompt improvement patterns, as well as their perceived usefulness, which does not always correspond to the actual usage before knowing our guidelines. Our results lead to implications not only for practitioners and educators, but also for those aimed at creating better LLM-aided software development tools.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4e3a\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u5f00\u53d1\u4e8610\u6761\u63d0\u793a\u4f18\u5316\u6307\u5357\uff0c\u901a\u8fc7\u6d4b\u8bd5\u9a71\u52a8\u65b9\u6cd5\u81ea\u52a8\u4f18\u5316\u63d0\u793a\uff0c\u5e76\u8bc4\u4f30\u4e86\u8fd9\u4e9b\u6307\u5357\u5728\u5f00\u53d1\u8005\u4e2d\u7684\u5b9e\u9645\u4f7f\u7528\u60c5\u51b5\u548c\u611f\u77e5\u6709\u7528\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5e7f\u6cdb\u7528\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\uff0c\u7279\u522b\u662f\u4ee3\u7801\u751f\u6210\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u9488\u5bf9\u4ee3\u7801\u751f\u6210\u7684\u5177\u4f53\u63d0\u793a\u5de5\u7a0b\u6307\u5357\u3002\u73b0\u6709\u7814\u7a76\u663e\u793a\u5408\u9002\u7684\u63d0\u793a\u5de5\u7a0b\u80fd\u6539\u5584\u4ee3\u7801\u751f\u6210\u6548\u679c\uff0c\u4f46\u5f00\u53d1\u8005\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u6307\u5bfc\u539f\u5219\u3002", "method": "\u91c7\u7528\u8fed\u4ee3\u3001\u6d4b\u8bd5\u9a71\u52a8\u7684\u65b9\u6cd5\u81ea\u52a8\u4f18\u5316\u4ee3\u7801\u751f\u6210\u63d0\u793a\uff0c\u5206\u6790\u4f18\u5316\u8fc7\u7a0b\u4e2d\u5bfc\u81f4\u6d4b\u8bd5\u901a\u8fc7\u7684\u63d0\u793a\u6539\u8fdb\u8981\u7d20\uff0c\u4ece\u4e2d\u63d0\u53d6\u51fa10\u6761\u63d0\u793a\u6539\u8fdb\u6307\u5357\u3002\u968f\u540e\u5bf950\u540d\u4ece\u4e1a\u8005\u8fdb\u884c\u8bc4\u4f30\uff0c\u8c03\u67e5\u4ed6\u4eec\u5bf9\u8fd9\u4e9b\u6307\u5357\u7684\u4f7f\u7528\u60c5\u51b5\u548c\u611f\u77e5\u6709\u7528\u6027\u3002", "result": "\u7814\u7a76\u63d0\u53d6\u4e8610\u6761\u63d0\u793a\u6539\u8fdb\u6307\u5357\uff0c\u6d89\u53ca\u66f4\u597d\u5730\u6307\u5b9a\u8f93\u5165\u8f93\u51fa\u3001\u524d\u7f6e\u540e\u7f6e\u6761\u4ef6\u3001\u63d0\u4f9b\u793a\u4f8b\u3001\u6dfb\u52a0\u5404\u7c7b\u7ec6\u8282\u3001\u6f84\u6e05\u6b67\u4e49\u7b49\u65b9\u9762\u3002\u8bc4\u4f30\u53d1\u73b0\u5f00\u53d1\u8005\u7684\u5b9e\u9645\u4f7f\u7528\u60c5\u51b5\u4e0e\u611f\u77e5\u6709\u7528\u6027\u5e76\u4e0d\u5b8c\u5168\u4e00\u81f4\uff0c\u6709\u4e9b\u6307\u5357\u867d\u7136\u88ab\u8ba4\u4e3a\u6709\u7528\u4f46\u5b9e\u9645\u4f7f\u7528\u8f83\u5c11\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u63d0\u793a\u4f18\u5316\u6307\u5357\uff0c\u5bf9\u4ece\u4e1a\u8005\u3001\u6559\u80b2\u5de5\u4f5c\u8005\u4ee5\u53ca\u5f00\u53d1LLM\u8f85\u52a9\u8f6f\u4ef6\u5f00\u53d1\u5de5\u5177\u7684\u4eba\u5458\u90fd\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u4ee3\u7801\u751f\u6210\u7684\u8d28\u91cf\u548c\u6548\u7387\u3002"}}
{"id": "2601.12916", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.12916", "abs": "https://arxiv.org/abs/2601.12916", "authors": ["Sangjun An", "Seoksu Lee", "Eun-Sun Cho"], "title": "Static Detection of Core Structures in Tigress Virtualization-Based Obfuscation Using an LLVM Pass", "comment": "7 pages, 7figures, An extended version of this work has been submitted to the Journal of KIISC", "summary": "Malware often uses obfuscation to hinder security analysis. Among these techniques, virtualization-based obfuscation is particularly strong because it protects programs by translating original instructions into attacker-defined virtual machine (VM) bytecode, producing long and complex code that is difficult to analyze and deobfuscate. This paper aims to identify the structural components of virtualization-based obfuscation through static analysis. By examining the execution model of obfuscated code, we define and detect the key elements required for deobfuscation-namely the dispatch routine, handler blocks, and the VM region-using LLVM IR. Experimental results show that, in the absence of compiler optimizations, the proposed LLVM Pass successfully detects all core structures across major virtualization options, including switch, direct, and indirect modes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLVM IR\u7684\u9759\u6001\u5206\u6790\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u865a\u62df\u5316\u6df7\u6dc6\u6280\u672f\u4e2d\u7684\u6838\u5fc3\u7ed3\u6784\u7ec4\u4ef6\uff0c\u5305\u62ec\u8c03\u5ea6\u4f8b\u7a0b\u3001\u5904\u7406\u5668\u5757\u548cVM\u533a\u57df\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u8bc6\u522b\u591a\u79cd\u865a\u62df\u5316\u6a21\u5f0f\u3002", "motivation": "\u6076\u610f\u8f6f\u4ef6\u5e38\u4f7f\u7528\u865a\u62df\u5316\u6df7\u6dc6\u6280\u672f\u6765\u963b\u788d\u5b89\u5168\u5206\u6790\uff0c\u8fd9\u79cd\u6280\u672f\u5c06\u539f\u59cb\u6307\u4ee4\u8f6c\u6362\u4e3a\u653b\u51fb\u8005\u5b9a\u4e49\u7684\u865a\u62df\u673a\u5b57\u8282\u7801\uff0c\u4ea7\u751f\u96be\u4ee5\u5206\u6790\u548c\u53bb\u6df7\u6dc6\u7684\u590d\u6742\u4ee3\u7801\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u8bc6\u522b\u865a\u62df\u5316\u6df7\u6dc6\u7684\u7ed3\u6784\u7ec4\u4ef6\u3002", "method": "\u901a\u8fc7\u9759\u6001\u5206\u6790\u68c0\u67e5\u6df7\u6dc6\u4ee3\u7801\u7684\u6267\u884c\u6a21\u578b\uff0c\u4f7f\u7528LLVM IR\u5b9a\u4e49\u548c\u68c0\u6d4b\u53bb\u6df7\u6dc6\u6240\u9700\u7684\u5173\u952e\u5143\u7d20\uff0c\u5305\u62ec\u8c03\u5ea6\u4f8b\u7a0b\u3001\u5904\u7406\u5668\u5757\u548cVM\u533a\u57df\uff0c\u5f00\u53d1\u4e86LLVM Pass\u6765\u5b9e\u73b0\u68c0\u6d4b\u3002", "result": "\u5728\u6ca1\u6709\u7f16\u8bd1\u5668\u4f18\u5316\u7684\u60c5\u51b5\u4e0b\uff0c\u63d0\u51fa\u7684LLVM Pass\u6210\u529f\u68c0\u6d4b\u4e86\u6240\u6709\u4e3b\u8981\u865a\u62df\u5316\u9009\u9879\uff08\u5305\u62ecswitch\u3001direct\u548cindirect\u6a21\u5f0f\uff09\u4e2d\u7684\u6838\u5fc3\u7ed3\u6784\u3002", "conclusion": "\u57fa\u4e8eLLVM IR\u7684\u9759\u6001\u5206\u6790\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u8bc6\u522b\u865a\u62df\u5316\u6df7\u6dc6\u6280\u672f\u7684\u6838\u5fc3\u7ed3\u6784\u7ec4\u4ef6\uff0c\u4e3a\u6076\u610f\u8f6f\u4ef6\u5206\u6790\u548c\u53bb\u6df7\u6dc6\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5de5\u5177\u652f\u6301\u3002"}}
{"id": "2601.12294", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12294", "abs": "https://arxiv.org/abs/2601.12294", "authors": ["Dawei Li", "Yuguang Yao", "Zhen Tan", "Huan Liu", "Ruocheng Guo"], "title": "ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents", "comment": "under review", "summary": "Reward-guided search methods have demonstrated strong potential in enhancing tool-using agents by effectively guiding sampling and exploration over complex action spaces. As a core design, those search methods utilize process reward models (PRMs) to provide step-level rewards, enabling more fine-grained monitoring. However, there is a lack of systematic and reliable evaluation benchmarks for PRMs in tool-using settings. In this paper, we introduce ToolPRMBench, a large-scale benchmark specifically designed to evaluate PRMs for tool-using agents. ToolPRMBench is built on top of several representative tool-using benchmarks and converts agent trajectories into step-level test cases. Each case contains the interaction history, a correct action, a plausible but incorrect alternative, and relevant tool metadata. We respectively utilize offline sampling to isolate local single-step errors and online sampling to capture realistic multi-step failures from full agent rollouts. A multi-LLM verification pipeline is proposed to reduce label noise and ensure data quality. We conduct extensive experiments across large language models, general PRMs, and tool-specialized PRMs on ToolPRMBench. The results reveal clear differences in PRM effectiveness and highlight the potential of specialized PRMs for tool-using. Code and data will be released at https://github.com/David-Li0406/ToolPRMBench.", "AI": {"tldr": "\u63d0\u51fa\u4e86ToolPRMBench\uff0c\u4e00\u4e2a\u4e13\u95e8\u8bc4\u4f30\u5de5\u5177\u4f7f\u7528\u667a\u80fd\u4f53\u4e2d\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff08PRMs\uff09\u7684\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u79bb\u7ebf/\u5728\u7ebf\u91c7\u6837\u548c\u591aLLM\u9a8c\u8bc1\u6765\u7cfb\u7edf\u8bc4\u4f30PRM\u6027\u80fd", "motivation": "\u867d\u7136\u5956\u52b1\u5f15\u5bfc\u7684\u641c\u7d22\u65b9\u6cd5\u5728\u5de5\u5177\u4f7f\u7528\u667a\u80fd\u4f53\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u53ef\u9760\u7684PRM\u8bc4\u4f30\u57fa\u51c6\uff0c\u7279\u522b\u662f\u5728\u5de5\u5177\u4f7f\u7528\u573a\u666f\u4e2d", "method": "\u57fa\u4e8e\u591a\u4e2a\u4ee3\u8868\u6027\u5de5\u5177\u4f7f\u7528\u57fa\u51c6\u6784\u5efaToolPRMBench\uff0c\u5c06\u667a\u80fd\u4f53\u8f68\u8ff9\u8f6c\u6362\u4e3a\u6b65\u9aa4\u7ea7\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5305\u542b\u4ea4\u4e92\u5386\u53f2\u3001\u6b63\u786e\u52a8\u4f5c\u3001\u5408\u7406\u4f46\u9519\u8bef\u7684\u66ff\u4ee3\u52a8\u4f5c\u548c\u5de5\u5177\u5143\u6570\u636e\uff1b\u91c7\u7528\u79bb\u7ebf\u91c7\u6837\u9694\u79bb\u5355\u6b65\u9519\u8bef\u548c\u5728\u7ebf\u91c7\u6837\u6355\u83b7\u591a\u6b65\u5931\u8d25\uff1b\u63d0\u51fa\u591aLLM\u9a8c\u8bc1\u7ba1\u9053\u51cf\u5c11\u6807\u7b7e\u566a\u58f0", "result": "\u5728\u5927\u8bed\u8a00\u6a21\u578b\u3001\u901a\u7528PRM\u548c\u5de5\u5177\u4e13\u7528PRM\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u7ed3\u679c\u663e\u793aPRM\u6709\u6548\u6027\u5b58\u5728\u660e\u663e\u5dee\u5f02\uff0c\u5e76\u7a81\u663e\u4e86\u5de5\u5177\u4e13\u7528PRM\u7684\u6f5c\u529b", "conclusion": "ToolPRMBench\u4e3a\u8bc4\u4f30\u5de5\u5177\u4f7f\u7528\u573a\u666f\u4e2d\u7684PRM\u63d0\u4f9b\u4e86\u7cfb\u7edf\u57fa\u51c6\uff0c\u63ed\u793a\u4e86PRM\u6027\u80fd\u5dee\u5f02\u5e76\u5c55\u793a\u4e86\u5de5\u5177\u4e13\u7528PRM\u7684\u4f18\u52bf\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u5de5\u5177\u4f7f\u7528\u667a\u80fd\u4f53\u7684\u53d1\u5c55"}}
{"id": "2601.13134", "categories": ["cs.SE", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13134", "abs": "https://arxiv.org/abs/2601.13134", "authors": ["Heng Fang", "Adam J. Stewart", "Isaac Corley", "Xiao Xiang Zhu", "Hossein Azizpour"], "title": "Earth Embeddings as Products: Taxonomy, Ecosystem, and Standardized Access", "comment": null, "summary": "Geospatial Foundation Models (GFMs) provide powerful representations, but high compute costs hinder their widespread use. Pre-computed embedding data products offer a practical \"frozen\" alternative, yet they currently exist in a fragmented ecosystem of incompatible formats and resolutions. This lack of standardization creates an engineering bottleneck that prevents meaningful model comparison and reproducibility. We formalize this landscape through a three-layer taxonomy: Data, Tools, and Value. We survey existing products to identify interoperability barriers. To bridge this gap, we extend TorchGeo with a unified API that standardizes the loading and querying of diverse embedding products. By treating embeddings as first-class geospatial datasets, we decouple downstream analysis from model-specific engineering, providing a roadmap for more transparent and accessible Earth observation workflows.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u7edf\u4e00API\u6807\u51c6\u5316\u5730\u7406\u7a7a\u95f4\u57fa\u7840\u6a21\u578b\u5d4c\u5165\u4ea7\u54c1\uff0c\u89e3\u51b3\u73b0\u6709\u751f\u6001\u7cfb\u7edf\u788e\u7247\u5316\u95ee\u9898\uff0c\u4fc3\u8fdb\u6a21\u578b\u6bd4\u8f83\u548c\u53ef\u590d\u73b0\u6027", "motivation": "\u5730\u7406\u7a7a\u95f4\u57fa\u7840\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9884\u8ba1\u7b97\u5d4c\u5165\u4ea7\u54c1\u4f5c\u4e3a\u5b9e\u7528\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u73b0\u6709\u751f\u6001\u7cfb\u7edf\u5b58\u5728\u683c\u5f0f\u548c\u5206\u8fa8\u7387\u4e0d\u517c\u5bb9\u7684\u788e\u7247\u5316\u95ee\u9898\uff0c\u7f3a\u4e4f\u6807\u51c6\u5316\u963b\u788d\u4e86\u6a21\u578b\u6bd4\u8f83\u548c\u53ef\u590d\u73b0\u6027", "method": "\u63d0\u51fa\u4e09\u5c42\u5206\u7c7b\u6cd5\uff08\u6570\u636e\u3001\u5de5\u5177\u3001\u4ef7\u503c\uff09\u5206\u6790\u73b0\u6709\u4ea7\u54c1\uff0c\u8bc6\u522b\u4e92\u64cd\u4f5c\u6027\u969c\u788d\uff0c\u6269\u5c55TorchGeo\u63d0\u4f9b\u7edf\u4e00API\uff0c\u6807\u51c6\u5316\u4e0d\u540c\u5d4c\u5165\u4ea7\u54c1\u7684\u52a0\u8f7d\u548c\u67e5\u8be2", "result": "\u901a\u8fc7\u5c06\u5d4c\u5165\u89c6\u4e3a\u4e00\u7b49\u5730\u7406\u7a7a\u95f4\u6570\u636e\u96c6\uff0c\u89e3\u8026\u4e0b\u6e38\u5206\u6790\u4e0e\u6a21\u578b\u7279\u5b9a\u5de5\u7a0b\uff0c\u4e3a\u66f4\u900f\u660e\u548c\u53ef\u8bbf\u95ee\u7684\u5730\u7403\u89c2\u6d4b\u5de5\u4f5c\u6d41\u63d0\u4f9b\u8def\u7ebf\u56fe", "conclusion": "\u7edf\u4e00API\u6807\u51c6\u5316\u89e3\u51b3\u4e86\u5730\u7406\u7a7a\u95f4\u5d4c\u5165\u4ea7\u54c1\u7684\u788e\u7247\u5316\u95ee\u9898\uff0c\u4fc3\u8fdb\u4e86\u6a21\u578b\u6bd4\u8f83\u548c\u53ef\u590d\u73b0\u6027\uff0c\u4f7f\u5730\u7403\u89c2\u6d4b\u5de5\u4f5c\u6d41\u66f4\u52a0\u900f\u660e\u548c\u53ef\u8bbf\u95ee"}}
{"id": "2601.12922", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12922", "abs": "https://arxiv.org/abs/2601.12922", "authors": ["Johannes Kaiser", "Alexander Ziller", "Eleni Triantafillou", "Daniel R\u00fcckert", "Georgios Kaissis"], "title": "Your Privacy Depends on Others: Collusion Vulnerabilities in Individual Differential Privacy", "comment": null, "summary": "Individual Differential Privacy (iDP) promises users control over their privacy, but this promise can be broken in practice. We reveal a previously overlooked vulnerability in sampling-based iDP mechanisms: while conforming to the iDP guarantees, an individual's privacy risk is not solely governed by their own privacy budget, but critically depends on the privacy choices of all other data contributors. This creates a mismatch between the promise of individual privacy control and the reality of a system where risk is collectively determined. We demonstrate empirically that certain distributions of privacy preferences can unintentionally inflate the privacy risk of individuals, even when their formal guarantees are met. Moreover, this excess risk provides an exploitable attack vector. A central adversary or a set of colluding adversaries can deliberately choose privacy budgets to amplify vulnerabilities of targeted individuals. Most importantly, this attack operates entirely within the guarantees of DP, hiding this excess vulnerability. Our empirical evaluation demonstrates successful attacks against 62% of targeted individuals, substantially increasing their membership inference susceptibility. To mitigate this, we propose $(\\varepsilon_i,\u03b4_i,\\overline\u0394)$-iDP a privacy contract that uses $\u0394$-divergences to provide users with a hard upper bound on their excess vulnerability, while offering flexibility to mechanism design. Our findings expose a fundamental challenge to the current paradigm, demanding a re-evaluation of how iDP systems are designed, audited, communicated, and deployed to make excess risks transparent and controllable.", "AI": {"tldr": "\u4e2a\u4f53\u5dee\u5206\u9690\u79c1(iDP)\u5b58\u5728\u88ab\u5ffd\u89c6\u7684\u6f0f\u6d1e\uff1a\u91c7\u6837\u673a\u5236\u4e2d\u4e2a\u4f53\u7684\u9690\u79c1\u98ce\u9669\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u81ea\u8eab\u9690\u79c1\u9884\u7b97\uff0c\u8fd8\u53d7\u5176\u4ed6\u6240\u6709\u6570\u636e\u8d21\u732e\u8005\u9690\u79c1\u9009\u62e9\u7684\u5f71\u54cd\uff0c\u5bfc\u81f4\u4e2a\u4f53\u9690\u79c1\u63a7\u5236\u7684\u627f\u8bfa\u4e0e\u5b9e\u9645\u96c6\u4f53\u51b3\u5b9a\u98ce\u9669\u7684\u73b0\u5b9e\u4e0d\u5339\u914d\u3002", "motivation": "\u63ed\u793aiDP\u7cfb\u7edf\u4e2d\u88ab\u5ffd\u89c6\u7684\u6f0f\u6d1e\uff1a\u867d\u7136iDP\u627f\u8bfa\u7528\u6237\u63a7\u5236\u81ea\u5df1\u7684\u9690\u79c1\uff0c\u4f46\u5b9e\u9645\u4e0a\u4e2a\u4f53\u7684\u9690\u79c1\u98ce\u9669\u53d7\u5230\u5176\u4ed6\u6240\u6709\u7528\u6237\u9690\u79c1\u9009\u62e9\u7684\u5f71\u54cd\uff0c\u8fd9\u79cd\u96c6\u4f53\u51b3\u5b9a\u98ce\u9669\u4e0e\u4e2a\u4f53\u9690\u79c1\u63a7\u5236\u7684\u627f\u8bfa\u5b58\u5728\u6839\u672c\u6027\u4e0d\u5339\u914d\u3002", "method": "\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u63ed\u793a\u91c7\u6837\u673a\u5236\u4e2diDP\u7684\u6f0f\u6d1e\uff0c\u5c55\u793a\u7279\u5b9a\u9690\u79c1\u504f\u597d\u5206\u5e03\u5982\u4f55\u65e0\u610f\u4e2d\u589e\u52a0\u4e2a\u4f53\u9690\u79c1\u98ce\u9669\uff0c\u5e76\u6f14\u793a\u653b\u51fb\u8005\u5982\u4f55\u5229\u7528\u6b64\u6f0f\u6d1e\u3002\u63d0\u51fa\u57fa\u4e8e\u0394-\u6563\u5ea6\u7684(\u03b5_i,\u03b4_i,\u0394\u0304)-iDP\u9690\u79c1\u5408\u7ea6\u4f5c\u4e3a\u7f13\u89e3\u65b9\u6848\u3002", "result": "\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793a62%\u7684\u76ee\u6807\u4e2a\u4f53\u6210\u529f\u53d7\u5230\u653b\u51fb\uff0c\u5176\u6210\u5458\u63a8\u7406\u6613\u611f\u6027\u663e\u8457\u589e\u52a0\u3002\u653b\u51fb\u5b8c\u5168\u5728DP\u4fdd\u8bc1\u8303\u56f4\u5185\u8fdb\u884c\uff0c\u9690\u85cf\u4e86\u989d\u5916\u7684\u8106\u5f31\u6027\u3002", "conclusion": "\u5f53\u524diDP\u8303\u5f0f\u5b58\u5728\u6839\u672c\u6027\u6311\u6218\uff0c\u9700\u8981\u91cd\u65b0\u8bc4\u4f30iDP\u7cfb\u7edf\u7684\u8bbe\u8ba1\u3001\u5ba1\u8ba1\u3001\u6c9f\u901a\u548c\u90e8\u7f72\u65b9\u5f0f\uff0c\u4f7f\u8d85\u989d\u98ce\u9669\u900f\u660e\u4e14\u53ef\u63a7\u3002\u63d0\u51fa\u7684(\u03b5_i,\u03b4_i,\u0394\u0304)-iDP\u5408\u7ea6\u4e3a\u7528\u6237\u63d0\u4f9b\u4e86\u8d85\u989d\u8106\u5f31\u6027\u7684\u786c\u4e0a\u9650\u3002"}}
{"id": "2601.12310", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12310", "abs": "https://arxiv.org/abs/2601.12310", "authors": ["Jennifer Dodgson", "Alfath Daryl Alhajir", "Michael Joedhitya", "Akira Rafhael Janson Pattirane", "Surender Suresh Kumar", "Joseph Lim", "C. H. Peh", "Adith Ramdas", "Steven Zhang Zhexu"], "title": "Survival is the Only Reward: Sustainable Self-Training Through Environment-Mediated Selection", "comment": null, "summary": "Self-training systems often degenerate due to the lack of an external criterion for judging data quality, leading to reward hacking and semantic drift. This paper provides a proof-of-concept system architecture for stable self-training under sparse external feedback and bounded memory, and empirically characterises its learning dynamics and failure modes.\n  We introduce a self-training architecture in which learning is mediated exclusively by environmental viability, rather than by reward, objective functions, or externally defined fitness criteria. Candidate behaviours are executed under real resource constraints, and only those whose environmental effects both persist and preserve the possibility of future interaction are propagated. The environment does not provide semantic feedback, dense rewards, or task-specific supervision; selection operates solely through differential survival of behaviours as world-altering events, making proxy optimisation impossible and rendering reward-hacking evolutionarily unstable.\n  Analysis of semantic dynamics shows that improvement arises primarily through the persistence of effective and repeatable strategies under a regime of consolidation and pruning, a paradigm we refer to as negative-space learning (NSL), and that models develop meta-learning strategies (such as deliberate experimental failure in order to elicit informative error messages) without explicit instruction. This work establishes that environment-grounded selection enables sustainable open-ended self-improvement, offering a viable path toward more robust and generalisable autonomous systems without reliance on human-curated data or complex reward shaping.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u73af\u5883\u5b58\u6d3b\u6027\u800c\u975e\u5956\u52b1\u51fd\u6570\u7684\u81ea\u8bad\u7ec3\u67b6\u6784\uff0c\u901a\u8fc7\u73af\u5883\u4e2d\u7684\u884c\u4e3a\u751f\u5b58\u9009\u62e9\u5b9e\u73b0\u7a33\u5b9a\u5b66\u4e60\uff0c\u907f\u514d\u5956\u52b1\u9ed1\u5ba2\u548c\u8bed\u4e49\u6f02\u79fb\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u81ea\u8bad\u7ec3\u7cfb\u7edf\u56e0\u7f3a\u4e4f\u5916\u90e8\u6570\u636e\u8d28\u91cf\u5224\u65ad\u6807\u51c6\u800c\u5bb9\u6613\u9000\u5316\uff0c\u5bfc\u81f4\u5956\u52b1\u9ed1\u5ba2\u548c\u8bed\u4e49\u6f02\u79fb\u95ee\u9898\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u5728\u7a00\u758f\u5916\u90e8\u53cd\u9988\u548c\u6709\u9650\u5185\u5b58\u6761\u4ef6\u4e0b\u5b9e\u73b0\u7a33\u5b9a\u81ea\u8bad\u7ec3\u7684\u7cfb\u7edf\u67b6\u6784\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u73af\u5883\u5b58\u6d3b\u6027\u800c\u975e\u5956\u52b1\u6216\u76ee\u6807\u51fd\u6570\u7684\u81ea\u8bad\u7ec3\u67b6\u6784\u3002\u5019\u9009\u884c\u4e3a\u5728\u771f\u5b9e\u8d44\u6e90\u7ea6\u675f\u4e0b\u6267\u884c\uff0c\u53ea\u6709\u90a3\u4e9b\u73af\u5883\u6548\u5e94\u6301\u4e45\u4e14\u80fd\u4fdd\u6301\u672a\u6765\u4ea4\u4e92\u53ef\u80fd\u6027\u7684\u884c\u4e3a\u88ab\u4f20\u64ad\u3002\u73af\u5883\u4e0d\u63d0\u4f9b\u8bed\u4e49\u53cd\u9988\u3001\u5bc6\u96c6\u5956\u52b1\u6216\u4efb\u52a1\u7279\u5b9a\u76d1\u7763\uff0c\u9009\u62e9\u4ec5\u901a\u8fc7\u884c\u4e3a\u4f5c\u4e3a\u4e16\u754c\u6539\u53d8\u4e8b\u4ef6\u7684\u5dee\u5f02\u751f\u5b58\u8fdb\u884c\u3002", "result": "\u5206\u6790\u8868\u660e\uff0c\u6539\u8fdb\u4e3b\u8981\u901a\u8fc7\u6709\u6548\u4e14\u53ef\u91cd\u590d\u7b56\u7565\u5728\u6574\u5408\u548c\u4fee\u526a\u673a\u5236\u4e0b\u7684\u6301\u4e45\u6027\u5b9e\u73b0\uff08\u8d1f\u7a7a\u95f4\u5b66\u4e60\u8303\u5f0f\uff09\u3002\u6a21\u578b\u5728\u6ca1\u6709\u660e\u786e\u6307\u5bfc\u7684\u60c5\u51b5\u4e0b\u53d1\u5c55\u51fa\u5143\u5b66\u4e60\u7b56\u7565\uff08\u5982\u6545\u610f\u5b9e\u9a8c\u5931\u8d25\u4ee5\u83b7\u53d6\u4fe1\u606f\u6027\u9519\u8bef\u6d88\u606f\uff09\u3002", "conclusion": "\u73af\u5883\u57fa\u7840\u9009\u62e9\u80fd\u591f\u5b9e\u73b0\u53ef\u6301\u7eed\u7684\u5f00\u653e\u5f0f\u81ea\u6211\u6539\u8fdb\uff0c\u4e3a\u6784\u5efa\u66f4\u9c81\u68d2\u548c\u53ef\u6cdb\u5316\u7684\u81ea\u4e3b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\uff0c\u65e0\u9700\u4f9d\u8d56\u4eba\u7c7b\u7b56\u5212\u6570\u636e\u6216\u590d\u6742\u5956\u52b1\u5851\u9020\u3002"}}
{"id": "2601.13139", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.13139", "abs": "https://arxiv.org/abs/2601.13139", "authors": ["Alessandro Midolo", "Emiliano Tramontana", "Massimiliano Di Penta"], "title": "From Human to Machine Refactoring: Assessing GPT-4's Impact on Python Class Quality and Readability", "comment": null, "summary": "Refactoring is a software engineering practice that aims to improve code quality without altering program behavior. Although automated refactoring tools have been extensively studied, their practical applicability remains limited. Recent advances in Large Language Models (LLMs) have introduced new opportunities for automated code refactoring. The evaluation of such an LLM-driven approach, however, leaves unanswered questions about its effects on code quality. In this paper, we present a comprehensive empirical study on LLM-driven refactoring using GPT-4o, applied to 100 Python classes from the ClassEval benchmark. Unlike prior work, our study explores a wide range of class-level refactorings inspired by Fowler's catalog and evaluates their effects from three complementary perspectives: (i) behavioral correctness, verified through unit tests; (ii) code quality, assessed via Pylint, Flake8, and SonarCloud; and (iii) readability, measured using a state-of-the-art readability tool. Our findings show that GPT-4o generally produces behavior-preserving refactorings that reduce code smells and improve quality metrics, albeit at the cost of decreased readability. Our results provide new evidence on the capabilities and limitations of LLMs in automated software refactoring, highlighting directions for integrating LLMs into practical refactoring workflows.", "AI": {"tldr": "GPT-4o\u5728Python\u4ee3\u7801\u91cd\u6784\u4e2d\u7684\u5b9e\u8bc1\u7814\u7a76\uff1a\u884c\u4e3a\u6b63\u786e\u6027\u4fdd\u6301\uff0c\u4ee3\u7801\u8d28\u91cf\u63d0\u5347\uff0c\u4f46\u53ef\u8bfb\u6027\u4e0b\u964d", "motivation": "\u5c3d\u7ba1\u81ea\u52a8\u5316\u91cd\u6784\u5de5\u5177\u5df2\u6709\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5176\u5b9e\u9645\u5e94\u7528\u4ecd\u6709\u9650\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e3a\u81ea\u52a8\u5316\u4ee3\u7801\u91cd\u6784\u5e26\u6765\u65b0\u673a\u9047\uff0c\u4f46LLM\u9a71\u52a8\u65b9\u6cd5\u5bf9\u4ee3\u7801\u8d28\u91cf\u7684\u5f71\u54cd\u5c1a\u672a\u660e\u786e\u8bc4\u4f30\u3002", "method": "\u4f7f\u7528GPT-4o\u5bf9ClassEval\u57fa\u51c6\u4e2d\u7684100\u4e2aPython\u7c7b\u8fdb\u884c\u91cd\u6784\uff0c\u6db5\u76d6Fowler\u91cd\u6784\u76ee\u5f55\u4e2d\u7684\u591a\u79cd\u7c7b\u7ea7\u91cd\u6784\u3002\u4ece\u4e09\u4e2a\u4e92\u8865\u89d2\u5ea6\u8bc4\u4f30\uff1a\u884c\u4e3a\u6b63\u786e\u6027\uff08\u5355\u5143\u6d4b\u8bd5\u9a8c\u8bc1\uff09\u3001\u4ee3\u7801\u8d28\u91cf\uff08Pylint\u3001Flake8\u3001SonarCloud\u8bc4\u4f30\uff09\u3001\u53ef\u8bfb\u6027\uff08\u5148\u8fdb\u53ef\u8bfb\u6027\u5de5\u5177\u6d4b\u91cf\uff09\u3002", "result": "GPT-4o\u901a\u5e38\u80fd\u4ea7\u751f\u4fdd\u6301\u884c\u4e3a\u6b63\u786e\u7684\u91cd\u6784\uff0c\u51cf\u5c11\u4ee3\u7801\u5f02\u5473\u5e76\u6539\u5584\u8d28\u91cf\u6307\u6807\uff0c\u4f46\u4ee3\u4ef7\u662f\u964d\u4f4e\u4e86\u4ee3\u7801\u53ef\u8bfb\u6027\u3002", "conclusion": "\u7814\u7a76\u4e3aLLM\u5728\u81ea\u52a8\u5316\u8f6f\u4ef6\u91cd\u6784\u4e2d\u7684\u80fd\u529b\u548c\u5c40\u9650\u6027\u63d0\u4f9b\u4e86\u65b0\u8bc1\u636e\uff0c\u7a81\u51fa\u4e86\u5c06LLM\u96c6\u6210\u5230\u5b9e\u9645\u91cd\u6784\u5de5\u4f5c\u6d41\u4e2d\u7684\u65b9\u5411\u3002"}}
{"id": "2601.12937", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12937", "abs": "https://arxiv.org/abs/2601.12937", "authors": ["Murat Bilgehan Ertan", "Emirhan B\u00f6ge", "Min Chen", "Kaleel Mahmood", "Marten van Dijk"], "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing", "comment": null, "summary": "As large language models (LLMs) are trained on increasingly opaque corpora, membership inference attacks (MIAs) have been proposed to audit whether copyrighted texts were used during training, despite growing concerns about their reliability under realistic conditions. We ask whether MIAs can serve as admissible evidence in adversarial copyright disputes where an accused model developer may obfuscate training data while preserving semantic content, and formalize this setting through a judge-prosecutor-accused communication protocol. To test robustness under this protocol, we introduce SAGE (Structure-Aware SAE-Guided Extraction), a paraphrasing framework guided by Sparse Autoencoders (SAEs) that rewrites training data to alter lexical structure while preserving semantic content and downstream utility. Our experiments show that state-of-the-art MIAs degrade when models are fine-tuned on SAGE-generated paraphrases, indicating that their signals are not robust to semantics-preserving transformations. While some leakage remains in certain fine-tuning regimes, these results suggest that MIAs are brittle in adversarial settings and insufficient, on their own, as a standalone mechanism for copyright auditing of LLMs.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u5bf9\u6297\u6027\u7248\u6743\u7ea0\u7eb7\u4e2d\uff0c\u6210\u5458\u63a8\u65ad\u653b\u51fb\uff08MIAs\uff09\u4f5c\u4e3a\u8bc1\u636e\u7684\u53ef\u9760\u6027\u95ee\u9898\uff0c\u53d1\u73b0MIAs\u5728\u9762\u5bf9\u8bed\u4e49\u4fdd\u6301\u7684\u6587\u672c\u6539\u5199\u65f6\u8868\u73b0\u8106\u5f31\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u65e5\u76ca\u4e0d\u900f\u660e\u7684\u8bed\u6599\u5e93\u4e0a\u8bad\u7ec3\uff0c\u6210\u5458\u63a8\u65ad\u653b\u51fb\u88ab\u63d0\u51fa\u7528\u4e8e\u5ba1\u8ba1\u7248\u6743\u6587\u672c\u662f\u5426\u88ab\u7528\u4e8e\u8bad\u7ec3\uff0c\u4f46\u5176\u5728\u73b0\u5b9e\u6761\u4ef6\u4e0b\u7684\u53ef\u9760\u6027\u53d7\u5230\u8d28\u7591\u3002\u7814\u7a76\u65e8\u5728\u8bc4\u4f30MIAs\u5728\u5bf9\u6297\u6027\u7248\u6743\u7ea0\u7eb7\u4e2d\u4f5c\u4e3a\u8bc1\u636e\u7684\u53ef\u884c\u6027\u3002", "method": "\u63d0\u51fa\u4e86SAGE\uff08Structure-Aware SAE-Guided Extraction\uff09\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAEs\uff09\u7684\u6539\u5199\u6846\u67b6\uff0c\u80fd\u591f\u6539\u53d8\u8bad\u7ec3\u6570\u636e\u7684\u8bcd\u6c47\u7ed3\u6784\u540c\u65f6\u4fdd\u6301\u8bed\u4e49\u5185\u5bb9\u548c\u4e0b\u6e38\u5b9e\u7528\u6027\u3002\u901a\u8fc7\u6cd5\u5b98-\u68c0\u5bdf\u5b98-\u88ab\u544a\u901a\u4fe1\u534f\u8bae\u5f62\u5f0f\u5316\u5bf9\u6297\u6027\u8bbe\u7f6e\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5f53\u6a21\u578b\u5728SAGE\u751f\u6210\u7684\u6539\u5199\u6587\u672c\u4e0a\u8fdb\u884c\u5fae\u8c03\u65f6\uff0c\u6700\u5148\u8fdb\u7684MIAs\u6027\u80fd\u4e0b\u964d\uff0c\u8868\u660e\u5176\u4fe1\u53f7\u5bf9\u8bed\u4e49\u4fdd\u6301\u7684\u8f6c\u6362\u4e0d\u9c81\u68d2\u3002\u867d\u7136\u5728\u67d0\u4e9b\u5fae\u8c03\u673a\u5236\u4e0b\u4ecd\u5b58\u5728\u4e00\u4e9b\u4fe1\u606f\u6cc4\u6f0f\uff0c\u4f46\u7ed3\u679c\u8868\u660e\u786e\u5b9e\u5b58\u5728\u8106\u5f31\u6027\u3002", "conclusion": "MIAs\u5728\u5bf9\u6297\u6027\u8bbe\u7f6e\u4e2d\u8868\u73b0\u8106\u5f31\uff0c\u4ec5\u51ed\u81ea\u8eab\u4e0d\u8db3\u4ee5\u4f5c\u4e3aLLMs\u7248\u6743\u5ba1\u8ba1\u7684\u72ec\u7acb\u673a\u5236\u3002\u9700\u8981\u66f4\u9c81\u68d2\u7684\u5ba1\u8ba1\u65b9\u6cd5\u6765\u5e94\u5bf9\u8bed\u4e49\u4fdd\u6301\u7684\u6570\u636e\u6539\u5199\u3002"}}
{"id": "2601.12318", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12318", "abs": "https://arxiv.org/abs/2601.12318", "authors": ["Dehao Ying", "Fengchang Yu", "Haihua Chen", "Changjiang Jiang", "Yurong Li", "Wei Lu"], "title": "Beyond Human Annotation: Recent Advances in Data Generation Methods for Document Intelligence", "comment": null, "summary": "The advancement of Document Intelligence (DI) demands large-scale, high-quality training data, yet manual annotation remains a critical bottleneck. While data generation methods are evolving rapidly, existing surveys are constrained by fragmented focuses on single modalities or specific tasks, lacking a unified perspective aligned with real-world workflows. To fill this gap, this survey establishes the first comprehensive technical map for data generation in DI. Data generation is redefined as supervisory signal production, and a novel taxonomy is introduced based on the \"availability of data and labels.\" This framework organizes methodologies into four resource-centric paradigms: Data Augmentation, Data Generation from Scratch, Automated Data Annotation, and Self-Supervised Signal Construction. Furthermore, a multi-level evaluation framework is established to integrate intrinsic quality and extrinsic utility, compiling performance gains across diverse DI benchmarks. Guided by this unified structure, the methodological landscape is dissected to reveal critical challenges such as fidelity gaps and frontiers including co-evolutionary ecosystems. Ultimately, by systematizing this fragmented field, data generation is positioned as the central engine for next-generation DI.", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u4e3a\u6587\u6863\u667a\u80fd\uff08DI\uff09\u9886\u57df\u5efa\u7acb\u4e86\u9996\u4e2a\u5168\u9762\u7684\u6570\u636e\u751f\u6210\u6280\u672f\u56fe\u8c31\uff0c\u5c06\u6570\u636e\u751f\u6210\u91cd\u65b0\u5b9a\u4e49\u4e3a\u76d1\u7763\u4fe1\u53f7\u751f\u4ea7\uff0c\u5e76\u57fa\u4e8e\"\u6570\u636e\u548c\u6807\u7b7e\u7684\u53ef\u7528\u6027\"\u63d0\u51fa\u4e86\u65b0\u7684\u5206\u7c7b\u6cd5\uff0c\u5c06\u65b9\u6cd5\u7ec4\u7ec7\u4e3a\u56db\u4e2a\u8d44\u6e90\u4e2d\u5fc3\u8303\u5f0f\u3002", "motivation": "\u6587\u6863\u667a\u80fd\u7684\u53d1\u5c55\u9700\u8981\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u4f46\u4eba\u5de5\u6807\u6ce8\u6210\u4e3a\u5173\u952e\u74f6\u9888\u3002\u73b0\u6709\u8c03\u67e5\u5c40\u9650\u4e8e\u5355\u4e00\u6a21\u6001\u6216\u7279\u5b9a\u4efb\u52a1\uff0c\u7f3a\u4e4f\u4e0e\u73b0\u5b9e\u5de5\u4f5c\u6d41\u7a0b\u7edf\u4e00\u89c6\u89d2\uff0c\u9700\u8981\u5efa\u7acb\u7cfb\u7edf\u5316\u7684\u6570\u636e\u751f\u6210\u6280\u672f\u6846\u67b6\u3002", "method": "\u5c06\u6570\u636e\u751f\u6210\u91cd\u65b0\u5b9a\u4e49\u4e3a\u76d1\u7763\u4fe1\u53f7\u751f\u4ea7\uff0c\u57fa\u4e8e\"\u6570\u636e\u548c\u6807\u7b7e\u7684\u53ef\u7528\u6027\"\u5f15\u5165\u65b0\u7684\u5206\u7c7b\u6cd5\uff0c\u5c06\u65b9\u6cd5\u7ec4\u7ec7\u4e3a\u56db\u4e2a\u8d44\u6e90\u4e2d\u5fc3\u8303\u5f0f\uff1a\u6570\u636e\u589e\u5f3a\u3001\u4ece\u96f6\u5f00\u59cb\u6570\u636e\u751f\u6210\u3001\u81ea\u52a8\u5316\u6570\u636e\u6807\u6ce8\u548c\u81ea\u76d1\u7763\u4fe1\u53f7\u6784\u5efa\u3002", "result": "\u5efa\u7acb\u4e86\u591a\u5c42\u6b21\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u6574\u5408\u5185\u5728\u8d28\u91cf\u548c\u5916\u5728\u6548\u7528\uff0c\u6c47\u7f16\u4e86\u8de8\u591a\u79cdDI\u57fa\u51c6\u7684\u6027\u80fd\u589e\u76ca\u3002\u901a\u8fc7\u7edf\u4e00\u7ed3\u6784\u63ed\u793a\u4e86\u5173\u952e\u6311\u6218\uff08\u5982\u4fdd\u771f\u5ea6\u5dee\u8ddd\uff09\u548c\u524d\u6cbf\u65b9\u5411\uff08\u5982\u534f\u540c\u8fdb\u5316\u751f\u6001\u7cfb\u7edf\uff09\u3002", "conclusion": "\u901a\u8fc7\u7cfb\u7edf\u5316\u8fd9\u4e00\u788e\u7247\u5316\u9886\u57df\uff0c\u5c06\u6570\u636e\u751f\u6210\u5b9a\u4f4d\u4e3a\u4e0b\u4e00\u4ee3\u6587\u6863\u667a\u80fd\u7684\u6838\u5fc3\u5f15\u64ce\uff0c\u4e3aDI\u9886\u57df\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u6280\u672f\u8def\u7ebf\u56fe\u548c\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2601.12323", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12323", "abs": "https://arxiv.org/abs/2601.12323", "authors": ["Yin Cai", "Zhouhong Gu", "Juntao Zhang", "Ping Chen"], "title": "MARO: Learning Stronger Reasoning from Social Interaction", "comment": null, "summary": "Humans face countless scenarios that require reasoning and judgment in daily life. However, existing large language model training methods primarily allow models to learn from existing textual content or solve predetermined problems, lacking experience in real scenarios involving interaction, negotiation, and competition with others. To address this, this paper proposes Multi-Agent Reward Optimization (MARO), a method that enables large language models (LLMs) to acquire stronger reasoning abilities by learning and practicing in multi-agent social environments. Specifically, MARO first addresses the sparse learning signal problem by decomposing final success or failure outcomes into each specific behavior during the interaction process; second, it handles the uneven role distribution problem by balancing the training sample weights of different roles; finally, it addresses environmental instability issues by directly evaluating the utility of each behavior. Experimental results demonstrate that MARO not only achieves significant improvements in social reasoning capabilities, but also that the abilities acquired through social simulation learning can effectively transfer to other tasks such as mathematical reasoning and instruction following. This reveals the tremendous potential of multi-agent social learning in enhancing the general reasoning capabilities of LLMs.", "AI": {"tldr": "MARO\u662f\u4e00\u79cd\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u793e\u4ea4\u73af\u5883\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u89e3\u7a00\u758f\u5956\u52b1\u4fe1\u53f7\u3001\u5e73\u8861\u89d2\u8272\u6743\u91cd\u548c\u76f4\u63a5\u8bc4\u4f30\u884c\u4e3a\u6548\u7528\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u7684\u793e\u4ea4\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u80fd\u5c06\u6240\u5b66\u80fd\u529b\u8fc1\u79fb\u5230\u6570\u5b66\u63a8\u7406\u7b49\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u65b9\u6cd5\u4e3b\u8981\u8ba9\u6a21\u578b\u4ece\u73b0\u6709\u6587\u672c\u5185\u5bb9\u5b66\u4e60\u6216\u89e3\u51b3\u9884\u5b9a\u95ee\u9898\uff0c\u7f3a\u4e4f\u5728\u771f\u5b9e\u793e\u4ea4\u573a\u666f\u4e2d\u4e0e\u4ed6\u4eba\u4e92\u52a8\u3001\u534f\u5546\u548c\u7ade\u4e89\u7684\u7ecf\u9a8c\uff0c\u8fd9\u9650\u5236\u4e86\u6a21\u578b\u5728\u9700\u8981\u590d\u6742\u793e\u4ea4\u63a8\u7406\u7684\u573a\u666f\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u5956\u52b1\u4f18\u5316\uff08MARO\uff09\u65b9\u6cd5\uff1a1\uff09\u5c06\u6700\u7ec8\u6210\u529f\u6216\u5931\u8d25\u7ed3\u679c\u5206\u89e3\u4e3a\u4ea4\u4e92\u8fc7\u7a0b\u4e2d\u7684\u5177\u4f53\u884c\u4e3a\uff0c\u89e3\u51b3\u7a00\u758f\u5b66\u4e60\u4fe1\u53f7\u95ee\u9898\uff1b2\uff09\u901a\u8fc7\u5e73\u8861\u4e0d\u540c\u89d2\u8272\u7684\u8bad\u7ec3\u6837\u672c\u6743\u91cd\uff0c\u5904\u7406\u89d2\u8272\u5206\u5e03\u4e0d\u5747\u95ee\u9898\uff1b3\uff09\u901a\u8fc7\u76f4\u63a5\u8bc4\u4f30\u6bcf\u4e2a\u884c\u4e3a\u7684\u6548\u7528\uff0c\u89e3\u51b3\u73af\u5883\u4e0d\u7a33\u5b9a\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cMARO\u4e0d\u4ec5\u5728\u793e\u4ea4\u63a8\u7406\u80fd\u529b\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff0c\u800c\u4e14\u901a\u8fc7\u793e\u4ea4\u6a21\u62df\u5b66\u4e60\u83b7\u5f97\u7684\u80fd\u529b\u80fd\u6709\u6548\u8fc1\u79fb\u5230\u5176\u4ed6\u4efb\u52a1\uff0c\u5982\u6570\u5b66\u63a8\u7406\u548c\u6307\u4ee4\u9075\u5faa\uff0c\u5c55\u793a\u4e86\u591a\u667a\u80fd\u4f53\u793e\u4ea4\u5b66\u4e60\u5728\u589e\u5f3aLLM\u901a\u7528\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u5de8\u5927\u6f5c\u529b\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u793e\u4ea4\u5b66\u4e60\u662f\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u901a\u7528\u63a8\u7406\u80fd\u529b\u7684\u6709\u6548\u9014\u5f84\uff0cMARO\u65b9\u6cd5\u901a\u8fc7\u89e3\u51b3\u7a00\u758f\u5956\u52b1\u3001\u89d2\u8272\u5206\u5e03\u548c\u73af\u5883\u4e0d\u7a33\u5b9a\u7b49\u95ee\u9898\uff0c\u4f7f\u6a21\u578b\u80fd\u5728\u590d\u6742\u793e\u4ea4\u73af\u5883\u4e2d\u5b66\u4e60\u5e76\u83b7\u5f97\u53ef\u8fc1\u79fb\u7684\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2601.13334", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.13334", "abs": "https://arxiv.org/abs/2601.13334", "authors": ["Tarik Houichime", "Younes El Amrani"], "title": "SEER: Spectral Entropy Encoding of Roles for Context-Aware Attention-Based Design Pattern Detection", "comment": null, "summary": "This paper presents SEER, an upgraded version of our prior method Context Is All You Need for detecting Gang of Four (GoF) design patterns from source code. The earlier approach modeled code as attention-ready sequences that blended lightweight structure with behavioral context; however, it lacked explicit role disambiguation within classes and treated call edges uniformly. SEER addresses these limitations with two principled additions: (i) a spectral-entropy role encoder that derives per-member role embeddings from the Laplacian spectrum of each class's interaction graph, and (ii) a time-weighted calling context that assigns empirically calibrated duration priors to method categories (e.g., constructors, getters/setters, static calls, virtual dispatch, cloning). Together, these components sharpen the model's notion of \"who does what\" and \"how much it matters,\" while remaining portable across languages with minimal adaptation and fully compatible with Transformer-based sequence encoders. Importantly, SEER does not \"force\" a win by capacity or data; it nudges the classifier, steering attention toward role-consistent and temporally calibrated signals that matter most. We evaluate SEER on PyDesignNet (1,832 files, 35,000 sequences, 23 GoF patterns) and observe consistent gains over our previous system: macro-F1 increases from 92.47% to 93.20% and accuracy from 92.52% to 93.98%, with macro-precision 93.98% and macro-recall 92.52%. Beyond aggregate metrics, SEER reduces false positives by nearly 20%, a decisive improvement that strengthens its robustness and practical reliability. Moreover, SEER yields interpretable, symbol-level attributions aligned with canonical roles, exhibits robustness under small graph perturbations, and shows stable calibration.", "AI": {"tldr": "SEER\u662fGoF\u8bbe\u8ba1\u6a21\u5f0f\u68c0\u6d4b\u65b9\u6cd5\u7684\u5347\u7ea7\u7248\uff0c\u901a\u8fc7\u8c31\u71b5\u89d2\u8272\u7f16\u7801\u548c\u65f6\u95f4\u52a0\u6743\u8c03\u7528\u4e0a\u4e0b\u6587\u6539\u8fdb\u89d2\u8272\u8bc6\u522b\u548c\u65f6\u5e8f\u91cd\u8981\u6027\uff0c\u5728\u4fdd\u6301\u8de8\u8bed\u8a00\u517c\u5bb9\u6027\u7684\u540c\u65f6\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u5148\u524d\u65b9\u6cd5\u867d\u7136\u5c06\u4ee3\u7801\u5efa\u6a21\u4e3a\u6ce8\u610f\u529b\u5e8f\u5217\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u7c7b\u5185\u89d2\u8272\u7684\u660e\u786e\u533a\u5206\uff0c\u4e14\u5c06\u8c03\u7528\u8fb9\u7edf\u4e00\u5904\u7406\uff0c\u9650\u5236\u4e86\u68c0\u6d4b\u7cbe\u5ea6\u3002", "method": "\u5f15\u5165\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u8c31\u71b5\u89d2\u8272\u7f16\u7801\u5668\uff0c\u4ece\u7c7b\u7684\u4ea4\u4e92\u56fe\u8c31\u62c9\u666e\u62c9\u65af\u8c31\u4e2d\u63d0\u53d6\u6210\u5458\u89d2\u8272\u5d4c\u5165\uff1b2) \u65f6\u95f4\u52a0\u6743\u8c03\u7528\u4e0a\u4e0b\u6587\uff0c\u4e3a\u4e0d\u540c\u65b9\u6cd5\u7c7b\u522b\u5206\u914d\u7ecf\u9a8c\u6821\u51c6\u7684\u6301\u7eed\u65f6\u95f4\u5148\u9a8c\u3002", "result": "\u5728PyDesignNet\u6570\u636e\u96c6\u4e0a\uff0cmacro-F1\u4ece92.47%\u63d0\u5347\u81f393.20%\uff0c\u51c6\u786e\u7387\u4ece92.52%\u63d0\u5347\u81f393.98%\uff0c\u8bef\u62a5\u7387\u964d\u4f4e\u8fd120%\uff0c\u540c\u65f6\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u7b26\u53f7\u7ea7\u5f52\u56e0\u3002", "conclusion": "SEER\u901a\u8fc7\u6539\u8fdb\u89d2\u8272\u8bc6\u522b\u548c\u65f6\u5e8f\u91cd\u8981\u6027\u5efa\u6a21\uff0c\u5728\u4e0d\u589e\u52a0\u6a21\u578b\u5bb9\u91cf\u6216\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bbe\u8ba1\u6a21\u5f0f\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.12986", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.12986", "abs": "https://arxiv.org/abs/2601.12986", "authors": ["Zhenhua Xu", "Xiaoning Tian", "Wenjun Zeng", "Wenpeng Xing", "Tianliang Lu", "Gaolei Li", "Chaochao Chen", "Meng Han"], "title": "KinGuard: Hierarchical Kinship-Aware Fingerprinting to Defend Against Large Language Model Stealing", "comment": "Accepted by ICASSP2026", "summary": "Protecting the intellectual property of large language models requires robust ownership verification. Conventional backdoor fingerprinting, however, is flawed by a stealth-robustness paradox: to be robust, these methods force models to memorize fixed responses to high-perplexity triggers, but this targeted overfitting creates detectable statistical artifacts. We resolve this paradox with KinGuard, a framework that embeds a private knowledge corpus built on structured kinship narratives. Instead of memorizing superficial triggers, the model internalizes this knowledge via incremental pre-training, and ownership is verified by probing its conceptual understanding. Extensive experiments demonstrate KinGuard's superior effectiveness, stealth, and resilience against a battery of attacks including fine-tuning, input perturbation, and model merging. Our work establishes knowledge-based embedding as a practical and secure paradigm for model fingerprinting.", "AI": {"tldr": "KinGuard\uff1a\u57fa\u4e8e\u4eb2\u5c5e\u5173\u7cfb\u77e5\u8bc6\u5d4c\u5165\u7684LLM\u6240\u6709\u6743\u9a8c\u8bc1\u6846\u67b6\uff0c\u89e3\u51b3\u4f20\u7edf\u540e\u95e8\u6307\u7eb9\u65b9\u6cd5\u7684\u9690\u853d\u6027\u4e0e\u9c81\u68d2\u6027\u77db\u76fe", "motivation": "\u4fdd\u62a4\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u4ea7\u6743\u9700\u8981\u53ef\u9760\u7684\u6240\u6709\u6743\u9a8c\u8bc1\u65b9\u6cd5\u3002\u4f20\u7edf\u7684\u540e\u95e8\u6307\u7eb9\u65b9\u6cd5\u5b58\u5728\u9690\u853d\u6027\u4e0e\u9c81\u68d2\u6027\u77db\u76fe\uff1a\u4e3a\u4e86\u9c81\u68d2\u6027\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u8feb\u4f7f\u6a21\u578b\u8bb0\u5fc6\u5bf9\u9ad8\u56f0\u60d1\u5ea6\u89e6\u53d1\u8bcd\u7684\u56fa\u5b9a\u54cd\u5e94\uff0c\u4f46\u8fd9\u79cd\u9488\u5bf9\u6027\u8fc7\u62df\u5408\u4f1a\u4ea7\u751f\u53ef\u68c0\u6d4b\u7684\u7edf\u8ba1\u7279\u5f81\u3002", "method": "\u63d0\u51faKinGuard\u6846\u67b6\uff0c\u901a\u8fc7\u589e\u91cf\u9884\u8bad\u7ec3\u5c06\u57fa\u4e8e\u7ed3\u6784\u5316\u4eb2\u5c5e\u5173\u7cfb\u53d9\u4e8b\u7684\u79c1\u6709\u77e5\u8bc6\u8bed\u6599\u5d4c\u5165\u6a21\u578b\u3002\u6a21\u578b\u4e0d\u662f\u8bb0\u5fc6\u8868\u9762\u89e6\u53d1\u8bcd\uff0c\u800c\u662f\u5185\u5316\u8fd9\u4e9b\u77e5\u8bc6\u6982\u5ff5\uff0c\u901a\u8fc7\u63a2\u6d4b\u6a21\u578b\u7684\u6982\u5ff5\u7406\u89e3\u6765\u9a8c\u8bc1\u6240\u6709\u6743\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660eKinGuard\u5728\u6709\u6548\u6027\u3001\u9690\u853d\u6027\u548c\u6297\u653b\u51fb\u6027\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\uff0c\u80fd\u591f\u62b5\u6297\u5fae\u8c03\u3001\u8f93\u5165\u6270\u52a8\u548c\u6a21\u578b\u5408\u5e76\u7b49\u591a\u79cd\u653b\u51fb\u3002", "conclusion": "\u8be5\u7814\u7a76\u786e\u7acb\u4e86\u57fa\u4e8e\u77e5\u8bc6\u5d4c\u5165\u7684\u6a21\u578b\u6307\u7eb9\u65b9\u6cd5\u4f5c\u4e3a\u4e00\u4e2a\u5b9e\u7528\u4e14\u5b89\u5168\u7684\u8303\u5f0f\uff0c\u4e3a\u89e3\u51b3LLM\u6240\u6709\u6743\u9a8c\u8bc1\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2601.12338", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12338", "abs": "https://arxiv.org/abs/2601.12338", "authors": ["Kartikey Singh Bhandari", "Manav Ganesh", "Yashwant Viswanathan", "Archit Agrawal", "Dhruv Kumar", "Pratik Narang"], "title": "Actionable Advice from Reviews via Mixture of LoRA Experts: A Two-LLM Pipeline for Issue Extraction and Business Recommendations", "comment": null, "summary": "Customer reviews contain detailed, domain specific signals about service failures and user expectations, but converting this unstructured feedback into actionable business decisions remains difficult. We study review-to-action generation: producing concrete, implementable recommendations grounded in review text. We propose a modular two-LLM framework in which an Issue model extracts salient issues and assigns coarse themes, and an Advice model generates targeted operational fixes conditioned on the extracted issue representation. To enable specialization without expensive full fine-tuning, we adapt the Advice model using a mixture of LoRA experts strategy: multiple low-rank adapters are trained and a lightweight gating mechanism performs token-level expert mixing at inference, combining complementary expertise across issue types. We construct synthetic review-issue-advice triples from Yelp reviews (airlines and restaurants) to supervise training, and evaluate recommendations using an eight dimension operational rubric spanning actionability, specificity, feasibility, expected impact, novelty, non-redundancy, bias, and clarity. Across both domains, our approach consistently outperforms prompting-only and single-adapter baselines, yielding higher actionability and specificity while retaining favorable efficiency-quality trade-offs.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e00\u4e2a\u4e24\u9636\u6bb5LLM\u6846\u67b6\uff0c\u5c06\u5ba2\u6237\u8bc4\u8bba\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u5efa\u8bae\uff0c\u901a\u8fc7\u95ee\u9898\u63d0\u53d6\u548c\u4e13\u5bb6\u6df7\u5408\u9002\u914d\u5668\u5b9e\u73b0\u4e13\u4e1a\u5316\u5efa\u8bae\u751f\u6210\u3002", "motivation": "\u5ba2\u6237\u8bc4\u8bba\u5305\u542b\u4e30\u5bcc\u7684\u670d\u52a1\u5931\u8d25\u548c\u7528\u6237\u671f\u671b\u4fe1\u53f7\uff0c\u4f46\u5c06\u8fd9\u4e9b\u975e\u7ed3\u6784\u5316\u53cd\u9988\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u7684\u4e1a\u52a1\u51b3\u7b56\u4ecd\u7136\u56f0\u96be\u3002\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8bc4\u8bba\u5230\u884c\u52a8\u751f\u6210\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u6a21\u5757\u5316\u4e24\u9636\u6bb5LLM\u6846\u67b6\uff1a\u95ee\u9898\u6a21\u578b\u63d0\u53d6\u5173\u952e\u95ee\u9898\u5e76\u5206\u914d\u4e3b\u9898\uff0c\u5efa\u8bae\u6a21\u578b\u57fa\u4e8e\u95ee\u9898\u8868\u793a\u751f\u6210\u9488\u5bf9\u6027\u64cd\u4f5c\u65b9\u6848\u3002\u91c7\u7528LoRA\u4e13\u5bb6\u6df7\u5408\u7b56\u7565\uff0c\u8bad\u7ec3\u591a\u4e2a\u4f4e\u79e9\u9002\u914d\u5668\u5e76\u901a\u8fc7\u8f7b\u91cf\u95e8\u63a7\u673a\u5236\u5728\u63a8\u7406\u65f6\u8fdb\u884c\u4e13\u5bb6\u7ec4\u5408\u3002", "result": "\u5728\u822a\u7a7a\u548c\u9910\u996e\u9886\u57df\u7684Yelp\u8bc4\u8bba\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u8be5\u65b9\u6cd5\u5728\u516b\u4e2a\u64cd\u4f5c\u7ef4\u5ea6\uff08\u53ef\u64cd\u4f5c\u6027\u3001\u7279\u5f02\u6027\u3001\u53ef\u884c\u6027\u3001\u9884\u671f\u5f71\u54cd\u3001\u65b0\u9896\u6027\u3001\u975e\u5197\u4f59\u6027\u3001\u504f\u89c1\u3001\u6e05\u6670\u5ea6\uff09\u4e0a\u6301\u7eed\u4f18\u4e8e\u4ec5\u63d0\u793a\u548c\u5355\u9002\u914d\u5668\u57fa\u7ebf\uff0c\u63d0\u4f9b\u66f4\u9ad8\u7684\u53ef\u64cd\u4f5c\u6027\u548c\u7279\u5f02\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e24\u9636\u6bb5\u6846\u67b6\u7ed3\u5408\u4e13\u5bb6\u6df7\u5408\u9002\u914d\u5668\u7b56\u7565\uff0c\u80fd\u591f\u6709\u6548\u5c06\u5ba2\u6237\u8bc4\u8bba\u8f6c\u5316\u4e3a\u5177\u4f53\u53ef\u64cd\u4f5c\u5efa\u8bae\uff0c\u5728\u6548\u7387\u548c\u8d28\u91cf\u7684\u6743\u8861\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2601.13345", "categories": ["cs.SE", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.13345", "abs": "https://arxiv.org/abs/2601.13345", "authors": ["Saurabhsingh Rajput", "Alexander Brandt", "Vadim Elisseev", "Tushar Sharma"], "title": "FlipFlop: A Static Analysis-based Energy Optimization Framework for GPU Kernels", "comment": null, "summary": "Artificial Intelligence (AI) applications, such as Large Language Models, are primarily driven and executed by Graphics Processing Units (GPUs). These GPU programs (kernels) consume substantial amounts of energy, yet software developers often lack the hardware expertise and ad hoc knowledge required to optimize for power efficiency. We propose FlipFlop, a framework using static code analysis to predict energy consumption and recommend Pareto-optimal thread block configurations considering both power consumption and execution time. Our framework requires no runtime execution and analyzes PTX code, a low-level instruction set for CUDA-enabled GPUs. It is validated across a diverse set of GPUs and kernels, including multi-head attention, convolution, and matrix multiplication. FlipFlop achieves 83% accuracy in identifying locally optimal energy-efficient configurations, while also minimizing developer effort by reducing the optimization search space by 93.4%. For multi-head attention kernels, it yields up to 79% energy savings and 106% throughput gains relative to NVIDIA's occupancy heuristic. By integrating static analysis with real-time monitoring and providing explainable optimization guidance, FlipFlop empowers developers to create sustainable, high-performance GPU software which minimizes environmental and computational costs.", "AI": {"tldr": "FlipFlop\u662f\u4e00\u4e2a\u4f7f\u7528\u9759\u6001\u4ee3\u7801\u5206\u6790\u9884\u6d4bGPU\u5185\u6838\u80fd\u8017\u5e76\u63a8\u8350\u5e15\u7d2f\u6258\u6700\u4f18\u7ebf\u7a0b\u5757\u914d\u7f6e\u7684\u6846\u67b6\uff0c\u65e0\u9700\u8fd0\u884c\u65f6\u6267\u884c\uff0c\u53ef\u663e\u8457\u51cf\u5c11\u80fd\u8017\u5e76\u63d0\u9ad8\u6027\u80fd\u3002", "motivation": "GPU\u7a0b\u5e8f\u6d88\u8017\u5927\u91cf\u80fd\u6e90\uff0c\u4f46\u8f6f\u4ef6\u5f00\u53d1\u4eba\u5458\u901a\u5e38\u7f3a\u4e4f\u786c\u4ef6\u4e13\u4e1a\u77e5\u8bc6\u548c\u4e13\u95e8\u77e5\u8bc6\u6765\u4f18\u5316\u80fd\u6548\u3002\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u8fd0\u884c\u65f6\u6267\u884c\u6216\u4e13\u4e1a\u77e5\u8bc6\uff0c\u9650\u5236\u4e86\u80fd\u6548\u4f18\u5316\u7684\u53ef\u53ca\u6027\u3002", "method": "\u4f7f\u7528\u9759\u6001\u4ee3\u7801\u5206\u6790\u5206\u6790PTX\u4ee3\u7801\uff08CUDA GPU\u7684\u4f4e\u7ea7\u6307\u4ee4\u96c6\uff09\uff0c\u9884\u6d4b\u80fd\u8017\u5e76\u63a8\u8350\u8003\u8651\u529f\u8017\u548c\u6267\u884c\u65f6\u95f4\u7684\u5e15\u7d2f\u6258\u6700\u4f18\u7ebf\u7a0b\u5757\u914d\u7f6e\uff0c\u65e0\u9700\u8fd0\u884c\u65f6\u6267\u884c\u3002", "result": "\u5728\u591a\u6837\u5316GPU\u548c\u5185\u6838\u4e0a\u9a8c\u8bc1\uff0c\u8fbe\u523083%\u7684\u5c40\u90e8\u6700\u4f18\u80fd\u6548\u914d\u7f6e\u8bc6\u522b\u51c6\u786e\u7387\uff0c\u4f18\u5316\u641c\u7d22\u7a7a\u95f4\u51cf\u5c1193.4%\u3002\u5bf9\u591a\u5934\u6ce8\u610f\u529b\u5185\u6838\u5b9e\u73b0\u9ad8\u8fbe79%\u7684\u80fd\u8017\u8282\u7701\u548c106%\u7684\u541e\u5410\u91cf\u63d0\u5347\u3002", "conclusion": "FlipFlop\u901a\u8fc7\u5c06\u9759\u6001\u5206\u6790\u4e0e\u5b9e\u65f6\u76d1\u63a7\u7ed3\u5408\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u4f18\u5316\u6307\u5bfc\uff0c\u4f7f\u5f00\u53d1\u4eba\u5458\u80fd\u591f\u521b\u5efa\u53ef\u6301\u7eed\u3001\u9ad8\u6027\u80fd\u7684GPU\u8f6f\u4ef6\uff0c\u6700\u5c0f\u5316\u73af\u5883\u548c\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2601.13031", "categories": ["cs.CR", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.13031", "abs": "https://arxiv.org/abs/2601.13031", "authors": ["Sebastian Bitzer", "Maximilian Egger", "Mumin Liu", "Antonia Wachter-Zeh"], "title": "Post-Quantum Secure Aggregation via Code-Based Homomorphic Encryption", "comment": null, "summary": "Secure aggregation enables aggregation of inputs from multiple parties without revealing individual contributions to the server or other clients. Existing post-quantum approaches based on homomorphic encryption offer practical efficiency but predominantly rely on lattice-based hardness assumptions. We present a code-based alternative for secure aggregation by instantiating a general framework based on key- and message-additive homomorphic encryption under the Learning Parity with Noise (LPN) assumption. Our construction employs a committee-based decryptor realized via secret sharing and incorporates a Chinese Remainder Theorem (CRT)-based optimization to reduce the communication costs of LPN-based instantiations. We analyze the security of the proposed scheme under a new Hint-LPN assumption and show that it is equivalent to standard LPN for suitable parameters. Finally, we evaluate performance and identify regimes in which our approach outperforms information-theoretically secure aggregation protocols.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7f16\u7801\u7684\u91cf\u5b50\u5b89\u5168\u805a\u5408\u65b9\u6848\uff0c\u4f7f\u7528LPN\u5047\u8bbe\u66ff\u4ee3\u4f20\u7edf\u7684\u683c\u57fa\u52a0\u5bc6\uff0c\u901a\u8fc7\u59d4\u5458\u4f1a\u89e3\u5bc6\u548cCRT\u4f18\u5316\u964d\u4f4e\u901a\u4fe1\u6210\u672c", "motivation": "\u73b0\u6709\u540e\u91cf\u5b50\u5b89\u5168\u805a\u5408\u65b9\u6848\u4e3b\u8981\u4f9d\u8d56\u683c\u57fa\u52a0\u5bc6\u5047\u8bbe\uff0c\u9700\u8981\u63a2\u7d22\u57fa\u4e8e\u5176\u4ed6\u6570\u5b66\u96be\u9898\u7684\u66ff\u4ee3\u65b9\u6848\u4ee5\u589e\u5f3a\u591a\u6837\u6027", "method": "\u57fa\u4e8eLPN\u5047\u8bbe\u6784\u5efa\u5bc6\u94a5\u548c\u6d88\u606f\u52a0\u6cd5\u540c\u6001\u52a0\u5bc6\u6846\u67b6\uff0c\u91c7\u7528\u59d4\u5458\u4f1a\u89e3\u5bc6\u673a\u5236\uff08\u901a\u8fc7\u79d8\u5bc6\u5171\u4eab\u5b9e\u73b0\uff09\uff0c\u5e76\u5f15\u5165CRT\u4f18\u5316\u964d\u4f4e\u901a\u4fe1\u5f00\u9500", "result": "\u5728Hint-LPN\u5047\u8bbe\u4e0b\u8bc1\u660e\u65b9\u6848\u5b89\u5168\u6027\uff0c\u663e\u793a\u4e0e\u6807\u51c6LPN\u7684\u7b49\u4ef7\u6027\uff0c\u6027\u80fd\u8bc4\u4f30\u8868\u660e\u5728\u67d0\u4e9b\u573a\u666f\u4e0b\u4f18\u4e8e\u4fe1\u606f\u8bba\u5b89\u5168\u805a\u5408\u534f\u8bae", "conclusion": "\u6210\u529f\u6784\u5efa\u4e86\u57fa\u4e8e\u7f16\u7801\u7684\u91cf\u5b50\u5b89\u5168\u805a\u5408\u65b9\u6848\uff0c\u4e3a\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\u63d0\u4f9b\u4e86\u683c\u57fa\u52a0\u5bc6\u4e4b\u5916\u7684\u53ef\u884c\u66ff\u4ee3\u65b9\u6848"}}
{"id": "2601.12410", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12410", "abs": "https://arxiv.org/abs/2601.12410", "authors": ["Dingyi Yang", "Junqi Zhao", "Xue Li", "Ce Li", "Boyang Li"], "title": "Are LLMs Smarter Than Chimpanzees? An Evaluation on Perspective Taking and Knowledge State Estimation", "comment": "23 pages, 11 figures", "summary": "Cognitive anthropology suggests that the distinction of human intelligence lies in the ability to infer other individuals' knowledge states and understand their intentions. In comparison, our closest animal relative, chimpanzees, lack the capacity to do so. With this paper, we aim to evaluate LLM performance in the area of knowledge state tracking and estimation. We design two tasks to test (1) if LLMs can detect when story characters, through their actions, demonstrate knowledge they should not possess, and (2) if LLMs can predict story characters' next actions based on their own knowledge vs. objective truths they do not know. Results reveal that most current state-of-the-art LLMs achieve near-random performance on both tasks, and are substantially inferior to humans. We argue future LLM research should place more weight on the abilities of knowledge estimation and intention understanding.", "AI": {"tldr": "LLMs\u5728\u77e5\u8bc6\u72b6\u6001\u8ffd\u8e2a\u548c\u610f\u56fe\u7406\u89e3\u4efb\u52a1\u4e0a\u8868\u73b0\u63a5\u8fd1\u968f\u673a\u6c34\u5e73\uff0c\u8fdc\u4f4e\u4e8e\u4eba\u7c7b\u8868\u73b0", "motivation": "\u8ba4\u77e5\u4eba\u7c7b\u5b66\u8ba4\u4e3a\u4eba\u7c7b\u667a\u80fd\u7684\u6838\u5fc3\u5728\u4e8e\u63a8\u65ad\u4ed6\u4eba\u77e5\u8bc6\u72b6\u6001\u548c\u7406\u89e3\u610f\u56fe\u7684\u80fd\u529b\uff0c\u800c\u9ed1\u7329\u7329\u7f3a\u4e4f\u8fd9\u79cd\u80fd\u529b\u3002\u672c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30LLM\u5728\u77e5\u8bc6\u72b6\u6001\u8ffd\u8e2a\u548c\u4f30\u8ba1\u65b9\u9762\u7684\u8868\u73b0\u3002", "method": "\u8bbe\u8ba1\u4e24\u4e2a\u4efb\u52a1\uff1a1) \u68c0\u6d4b\u6545\u4e8b\u89d2\u8272\u662f\u5426\u901a\u8fc7\u884c\u52a8\u8868\u73b0\u51fa\u672c\u4e0d\u5e94\u62e5\u6709\u7684\u77e5\u8bc6\uff1b2) \u57fa\u4e8e\u89d2\u8272\u81ea\u8eab\u77e5\u8bc6\uff08\u800c\u975e\u5ba2\u89c2\u4e8b\u5b9e\uff09\u9884\u6d4b\u5176\u4e0b\u4e00\u6b65\u884c\u52a8\u3002", "result": "\u5f53\u524d\u6700\u5148\u8fdb\u7684LLM\u5728\u4e24\u4e2a\u4efb\u52a1\u4e0a\u90fd\u63a5\u8fd1\u968f\u673a\u8868\u73b0\uff0c\u663e\u8457\u4f4e\u4e8e\u4eba\u7c7b\u6c34\u5e73\u3002", "conclusion": "\u672a\u6765LLM\u7814\u7a76\u5e94\u66f4\u91cd\u89c6\u77e5\u8bc6\u4f30\u8ba1\u548c\u610f\u56fe\u7406\u89e3\u80fd\u529b\u7684\u63d0\u5347\uff0c\u8fd9\u662f\u4eba\u7c7b\u667a\u80fd\u533a\u522b\u4e8e\u5176\u4ed6\u52a8\u7269\u7684\u5173\u952e\u7279\u5f81\u3002"}}
{"id": "2601.12444", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.12444", "abs": "https://arxiv.org/abs/2601.12444", "authors": ["Hui Yang", "Jiaoyan Chen", "Uli Sattler"], "title": "Large Language Model for OWL Proofs", "comment": null, "summary": "The ability of Large Language Models (LLMs) to perform reasoning tasks such as deduction has been widely investigated in recent years. Yet, their capacity to generate proofs-faithful, human-readable explanations of why conclusions follow-remains largely under explored. In this work, we study proof generation in the context of OWL ontologies, which are widely adopted for representing and reasoning over complex knowledge, by developing an automated dataset construction and evaluation framework. Our evaluation encompassing three sequential tasks for complete proving: Extraction, Simplification, and Explanation, as well as an additional task of assessing Logic Completeness of the premise. Through extensive experiments on widely used reasoning LLMs, we achieve important findings including: (1) Some models achieve overall strong results but remain limited on complex cases; (2) Logical complexity, rather than representation format (formal logic language versus natural language), is the dominant factor shaping LLM performance; and (3) Noise and incompleteness in input data substantially diminish LLMs' performance. Together, these results underscore both the promise of LLMs for explanation with rigorous logics and the gap of supporting resilient reasoning under complex or imperfect conditions. Code and data are available at https://github.com/HuiYang1997/LLMOwlR.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u5728OWL\u672c\u4f53\u8bba\u4e2d\u751f\u6210\u903b\u8f91\u8bc1\u660e\u7684\u80fd\u529b\uff0c\u5f00\u53d1\u4e86\u81ea\u52a8\u5316\u6570\u636e\u96c6\u6784\u5efa\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u590d\u6742\u60c5\u51b5\u4e0b\u4ecd\u6709\u5c40\u9650\uff0c\u903b\u8f91\u590d\u6742\u6027\u662f\u5f71\u54cd\u6027\u80fd\u7684\u4e3b\u8981\u56e0\u7d20\uff0c\u8f93\u5165\u6570\u636e\u7684\u4e0d\u5b8c\u6574\u6027\u4f1a\u663e\u8457\u964d\u4f4e\u6a21\u578b\u8868\u73b0\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u80fd\u529b\u5df2\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5b83\u4eec\u5728\u751f\u6210\u5fe0\u5b9e\u3001\u53ef\u8bfb\u7684\u903b\u8f91\u8bc1\u660e\u65b9\u9762\u7684\u80fd\u529b\u4ecd\u7136\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22LLMs\u5728OWL\u672c\u4f53\u8bba\u80cc\u666f\u4e0b\u751f\u6210\u903b\u8f91\u8bc1\u660e\u7684\u80fd\u529b\uff0cOWL\u672c\u4f53\u8bba\u88ab\u5e7f\u6cdb\u7528\u4e8e\u8868\u793a\u548c\u63a8\u7406\u590d\u6742\u77e5\u8bc6\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u81ea\u52a8\u5316\u6570\u636e\u96c6\u6784\u5efa\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u8bc4\u4f30\u5305\u542b\u4e09\u4e2a\u987a\u5e8f\u4efb\u52a1\uff1a\u63d0\u53d6\u3001\u7b80\u5316\u548c\u89e3\u91ca\uff0c\u4ee5\u53ca\u4e00\u4e2a\u989d\u5916\u7684\u8bc4\u4f30\u524d\u63d0\u903b\u8f91\u5b8c\u6574\u6027\u7684\u4efb\u52a1\u3002\u5728\u5e7f\u6cdb\u4f7f\u7528\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u8fdb\u884c\u5927\u91cf\u5b9e\u9a8c\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a(1) \u4e00\u4e9b\u6a21\u578b\u6574\u4f53\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u590d\u6742\u60c5\u51b5\u4e0b\u4ecd\u6709\u5c40\u9650\uff1b(2) \u903b\u8f91\u590d\u6742\u6027\uff08\u800c\u975e\u8868\u793a\u683c\u5f0f\uff09\u662f\u5f71\u54cdLLM\u6027\u80fd\u7684\u4e3b\u8981\u56e0\u7d20\uff1b(3) \u8f93\u5165\u6570\u636e\u4e2d\u7684\u566a\u58f0\u548c\u4e0d\u5b8c\u6574\u6027\u4f1a\u663e\u8457\u964d\u4f4eLLMs\u7684\u6027\u80fd\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u5f3a\u8c03\u4e86LLMs\u5728\u4e25\u683c\u903b\u8f91\u89e3\u91ca\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u540c\u65f6\u4e5f\u63ed\u793a\u4e86\u5728\u590d\u6742\u6216\u4e0d\u5b8c\u7f8e\u6761\u4ef6\u4e0b\u652f\u6301\u5f39\u6027\u63a8\u7406\u7684\u5dee\u8ddd\u3002\u4ee3\u7801\u548c\u6570\u636e\u5df2\u5f00\u6e90\u3002"}}
{"id": "2601.13466", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.13466", "abs": "https://arxiv.org/abs/2601.13466", "authors": ["Pedro Oliveira", "Doris Amoakohene", "Toby Hocking", "Marco Gerosa", "Igor Steinmacher"], "title": "Governance Matters: Lessons from Restructuring the data.table OSS Project", "comment": "ICSME 2025", "summary": "Open source software (OSS) forms the backbone of industrial data workflows and enterprise systems. However, many OSS projects face operational risks due to informal or centralized governance. This paper presents a practical case study of data.table, a high-performance R package widely adopted in production analytics pipelines, which underwent a community-led governance reform to address scalability and sustainability concerns. Before the reform, data.table faced a growing backlog of unresolved issues and open pull requests, unclear contributor pathways, and bottlenecks caused by reliance on a single core maintainer. In response, the community initiated a redesign of its governance structure. In this paper, we evaluated the impact of this transition through a mixed-methods approach, combining a contributor survey (n=17) with mining project repository data. Our results show that following the reform, the project experienced a 200% increase in new contributor recruitment, a drop in pull request resolution time from over 700 days to under a week, and a 3x increase in contributor retention. Community sentiment improved around transparency, onboarding, and project momentum, though concerns around fairness and conflict resolution remain. This case study provides practical guidance for maintainers, companies, and foundations seeking to enhance OSS governance.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7data.table R\u5305\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793a\u4e86\u5f00\u6e90\u8f6f\u4ef6\u793e\u533a\u6cbb\u7406\u6539\u9769\u5982\u4f55\u663e\u8457\u63d0\u5347\u9879\u76ee\u53ef\u6301\u7eed\u6027\u3001\u8d21\u732e\u8005\u53c2\u4e0e\u5ea6\u548c\u95ee\u9898\u89e3\u51b3\u6548\u7387\u3002", "motivation": "\u5f00\u6e90\u8f6f\u4ef6\u5728\u5de5\u4e1a\u6570\u636e\u5de5\u4f5c\u6d41\u548c\u4f01\u4e1a\u7cfb\u7edf\u4e2d\u626e\u6f14\u5173\u952e\u89d2\u8272\uff0c\u4f46\u8bb8\u591a\u9879\u76ee\u9762\u4e34\u975e\u6b63\u5f0f\u6216\u96c6\u4e2d\u5316\u6cbb\u7406\u5e26\u6765\u7684\u8fd0\u8425\u98ce\u9669\u3002data.table\u4f5c\u4e3a\u4e00\u4e2a\u5e7f\u6cdb\u7528\u4e8e\u751f\u4ea7\u5206\u6790\u6d41\u6c34\u7ebf\u7684\u9ad8\u6027\u80fdR\u5305\uff0c\u5728\u6539\u9769\u524d\u5b58\u5728\u672a\u89e3\u51b3\u95ee\u9898\u79ef\u538b\u3001\u8d21\u732e\u8005\u8def\u5f84\u4e0d\u6e05\u6670\u3001\u4f9d\u8d56\u5355\u4e00\u6838\u5fc3\u7ef4\u62a4\u8005\u7b49\u74f6\u9888\u95ee\u9898\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u7814\u7a76\uff1a\u7ed3\u5408\u8d21\u732e\u8005\u8c03\u67e5\uff08n=17\uff09\u548c\u9879\u76ee\u4ed3\u5e93\u6570\u636e\u6316\u6398\uff0c\u8bc4\u4f30data.table\u793e\u533a\u6cbb\u7406\u6539\u9769\u7684\u5f71\u54cd\u3002", "result": "\u6cbb\u7406\u6539\u9769\u540e\uff0c\u9879\u76ee\u65b0\u8d21\u732e\u8005\u62db\u52df\u589e\u52a0200%\uff0c\u62c9\u53d6\u8bf7\u6c42\u89e3\u51b3\u65f6\u95f4\u4ece700\u591a\u5929\u964d\u81f3\u4e00\u5468\u5185\uff0c\u8d21\u732e\u8005\u4fdd\u7559\u7387\u63d0\u53473\u500d\u3002\u793e\u533a\u5bf9\u900f\u660e\u5ea6\u3001\u5165\u95e8\u6d41\u7a0b\u548c\u9879\u76ee\u52a8\u529b\u7684\u6ee1\u610f\u5ea6\u63d0\u9ad8\uff0c\u4f46\u5728\u516c\u5e73\u6027\u548c\u51b2\u7a81\u89e3\u51b3\u65b9\u9762\u4ecd\u5b58\u5728\u62c5\u5fe7\u3002", "conclusion": "\u8be5\u6848\u4f8b\u7814\u7a76\u4e3a\u5bfb\u6c42\u6539\u8fdb\u5f00\u6e90\u8f6f\u4ef6\u6cbb\u7406\u7684\u7ef4\u62a4\u8005\u3001\u516c\u53f8\u548c\u57fa\u91d1\u4f1a\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u8bc1\u660e\u793e\u533a\u4e3b\u5bfc\u7684\u6cbb\u7406\u6539\u9769\u80fd\u663e\u8457\u63d0\u5347\u9879\u76ee\u7684\u53ef\u6269\u5c55\u6027\u548c\u53ef\u6301\u7eed\u6027\u3002"}}
{"id": "2601.13082", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13082", "abs": "https://arxiv.org/abs/2601.13082", "authors": ["Advije Rizvani", "Giovanni Apruzzese", "Pavel Laskov"], "title": "Adversarial News and Lost Profits: Manipulating Headlines in LLM-Driven Algorithmic Trading", "comment": "This work has been accepted for publication at the IEEE Conference on Secure and Trustworthy Machine Learning (SaTML). The final version will be available on IEEE Xplore", "summary": "Large Language Models (LLMs) are increasingly adopted in the financial domain. Their exceptional capabilities to analyse textual data make them well-suited for inferring the sentiment of finance-related news. Such feedback can be leveraged by algorithmic trading systems (ATS) to guide buy/sell decisions. However, this practice bears the risk that a threat actor may craft \"adversarial news\" intended to mislead an LLM. In particular, the news headline may include \"malicious\" content that remains invisible to human readers but which is still ingested by the LLM. Although prior work has studied textual adversarial examples, their system-wide impact on LLM-supported ATS has not yet been quantified in terms of monetary risk. To address this threat, we consider an adversary with no direct access to an ATS but able to alter stock-related news headlines on a single day. We evaluate two human-imperceptible manipulations in a financial context: Unicode homoglyph substitutions that misroute models during stock-name recognition, and hidden-text clauses that alter the sentiment of the news headline. We implement a realistic ATS in Backtrader that fuses an LSTM-based price forecast with LLM-derived sentiment (FinBERT, FinGPT, FinLLaMA, and six general-purpose LLMs), and quantify monetary impact using portfolio metrics. Experiments on real-world data show that manipulating a one-day attack over 14 months can reliably mislead LLMs and reduce annual returns by up to 17.7 percentage points. To assess real-world feasibility, we analyze popular scraping libraries and trading platforms and survey 27 FinTech practitioners, confirming our hypotheses. We notified trading platform owners of this security issue.", "AI": {"tldr": "\u7814\u7a76\u91cf\u5316\u4e86\u9488\u5bf9LLM\u652f\u6301\u7684\u7b97\u6cd5\u4ea4\u6613\u7cfb\u7edf\u7684\u5bf9\u6297\u6027\u65b0\u95fb\u653b\u51fb\uff0c\u901a\u8fc7\u4e0d\u53ef\u89c1\u6587\u672c\u64cd\u7eb5\u4f7f\u5e74\u56de\u62a5\u7387\u964d\u4f4e\u9ad8\u8fbe17.7\u4e2a\u767e\u5206\u70b9", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u9886\u57df\u7684\u5e94\u7528\u589e\u52a0\uff0c\u5b83\u4eec\u88ab\u7528\u4e8e\u5206\u6790\u8d22\u7ecf\u65b0\u95fb\u60c5\u611f\u4ee5\u6307\u5bfc\u4ea4\u6613\u51b3\u7b56\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u5b9e\u8df5\u5b58\u5728\u98ce\u9669\uff1a\u653b\u51fb\u8005\u53ef\u80fd\u5236\u4f5c\"\u5bf9\u6297\u6027\u65b0\u95fb\"\u6765\u8bef\u5bfcLLM\uff0c\u7279\u522b\u662f\u5305\u542b\u4eba\u7c7b\u4e0d\u53ef\u89c1\u4f46\u5bf9LLM\u6709\u5f71\u54cd\u7684\u6076\u610f\u5185\u5bb9\u3002\u867d\u7136\u5df2\u6709\u7814\u7a76\u5173\u6ce8\u6587\u672c\u5bf9\u6297\u6837\u672c\uff0c\u4f46\u5c1a\u672a\u4ece\u8d27\u5e01\u98ce\u9669\u89d2\u5ea6\u91cf\u5316\u5176\u5bf9LLM\u652f\u6301\u7684\u7b97\u6cd5\u4ea4\u6613\u7cfb\u7edf\u7684\u7cfb\u7edf\u6027\u5f71\u54cd\u3002", "method": "\u7814\u7a76\u8003\u8651\u4e86\u4e00\u4e2a\u65e0\u6cd5\u76f4\u63a5\u8bbf\u95ee\u7b97\u6cd5\u4ea4\u6613\u7cfb\u7edf\u4f46\u80fd\u5355\u65e5\u7be1\u6539\u80a1\u7968\u76f8\u5173\u65b0\u95fb\u6807\u9898\u7684\u653b\u51fb\u8005\u3002\u8bc4\u4f30\u4e86\u4e24\u79cd\u4eba\u7c7b\u96be\u4ee5\u5bdf\u89c9\u7684\u64cd\u7eb5\u65b9\u6cd5\uff1a1) Unicode\u540c\u5f62\u5f02\u4e49\u5b57\u66ff\u6362\uff0c\u8bef\u5bfc\u6a21\u578b\u5728\u80a1\u7968\u540d\u79f0\u8bc6\u522b\u65f6\uff1b2) \u9690\u85cf\u6587\u672c\u6761\u6b3e\uff0c\u6539\u53d8\u65b0\u95fb\u6807\u9898\u7684\u60c5\u611f\u503e\u5411\u3002\u5728Backtrader\u4e2d\u5b9e\u73b0\u4e86\u4e00\u4e2a\u73b0\u5b9e\u7684\u7b97\u6cd5\u4ea4\u6613\u7cfb\u7edf\uff0c\u878d\u5408\u4e86\u57fa\u4e8eLSTM\u7684\u4ef7\u683c\u9884\u6d4b\u548cLLM\u884d\u751f\u7684\u60c5\u611f\u5206\u6790\uff08\u4f7f\u7528FinBERT\u3001FinGPT\u3001FinLLaMA\u548c\u516d\u4e2a\u901a\u7528LLM\uff09\uff0c\u5e76\u4f7f\u7528\u6295\u8d44\u7ec4\u5408\u6307\u6807\u91cf\u5316\u8d27\u5e01\u5f71\u54cd\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u64cd\u7eb5\u5355\u65e5\u653b\u51fb\u572814\u4e2a\u6708\u5185\u80fd\u53ef\u9760\u5730\u8bef\u5bfcLLM\uff0c\u5e76\u4f7f\u5e74\u56de\u62a5\u7387\u964d\u4f4e\u9ad8\u8fbe17.7\u4e2a\u767e\u5206\u70b9\u3002\u901a\u8fc7\u5206\u6790\u6d41\u884c\u7684\u722c\u866b\u5e93\u548c\u4ea4\u6613\u5e73\u53f0\uff0c\u5e76\u8c03\u67e527\u540d\u91d1\u878d\u79d1\u6280\u4ece\u4e1a\u8005\uff0c\u786e\u8ba4\u4e86\u8fd9\u79cd\u653b\u51fb\u7684\u73b0\u5b9e\u53ef\u884c\u6027\u3002\u5df2\u901a\u77e5\u4ea4\u6613\u5e73\u53f0\u6240\u6709\u8005\u6b64\u5b89\u5168\u95ee\u9898\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u9488\u5bf9LLM\u652f\u6301\u7684\u7b97\u6cd5\u4ea4\u6613\u7cfb\u7edf\u7684\u5bf9\u6297\u6027\u65b0\u95fb\u653b\u51fb\u5177\u6709\u663e\u8457\u7684\u8d27\u5e01\u98ce\u9669\uff0c\u653b\u51fb\u8005\u901a\u8fc7\u4eba\u7c7b\u96be\u4ee5\u5bdf\u89c9\u7684\u6587\u672c\u64cd\u7eb5\u5c31\u80fd\u9020\u6210\u91cd\u5927\u8d22\u52a1\u635f\u5931\u3002\u8fd9\u7a81\u663e\u4e86\u91d1\u878d\u9886\u57dfLLM\u5e94\u7528\u7684\u5b89\u5168\u8106\u5f31\u6027\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u5f3a\u5927\u7684\u9632\u5fa1\u673a\u5236\u6765\u4fdd\u62a4\u7b97\u6cd5\u4ea4\u6613\u7cfb\u7edf\u514d\u53d7\u6b64\u7c7b\u653b\u51fb\u3002"}}
{"id": "2601.12499", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12499", "abs": "https://arxiv.org/abs/2601.12499", "authors": ["Meiru Zhang", "Zaiqiao Meng", "Nigel Collier"], "title": "Failure Modes in Multi-Hop QA: The Weakest Link Law and the Recognition Bottleneck", "comment": "preprint", "summary": "Despite scaling to massive context windows, Large Language Models (LLMs) struggle with multi-hop reasoning due to inherent position bias, which causes them to overlook information at certain positions. Whether these failures stem from an inability to locate evidence (recognition failure) or integrate it (synthesis failure) is unclear. We introduce Multi-Focus Attention Instruction (MFAI), a semantic probe to disentangle these mechanisms by explicitly steering attention towards selected positions. Across 5 LLMs on two multi-hop QA tasks (MuSiQue and NeoQA), we establish the \"Weakest Link Law\": multi-hop reasoning performance collapses to the performance level of the least visible evidence. Crucially, this failure is governed by absolute position rather than the linear distance between facts (performance variance $<3%$). We further identify a duality in attention steering: while matched MFAI resolves recognition bottlenecks, improving accuracy by up to 11.5% in low-visibility positions, misleading MFAI triggers confusion in real-world tasks but is successfully filtered in synthetic tasks. Finally, we demonstrate that \"thinking\" models that utilize System-2 reasoning, effectively locate and integrate the required information, matching gold-only baselines even in noisy, long-context settings.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faMFAI\u65b9\u6cd5\u63ed\u793aLLM\u591a\u8df3\u63a8\u7406\u5931\u8d25\u6e90\u4e8e\u4f4d\u7f6e\u504f\u89c1\uff0c\u53d1\u73b0\"\u6700\u5f31\u94fe\u63a5\u5b9a\u5f8b\"\uff1a\u591a\u8df3\u63a8\u7406\u6027\u80fd\u53d6\u51b3\u4e8e\u6700\u4e0d\u53ef\u89c1\u8bc1\u636e\u7684\u4f4d\u7f6e\u8868\u73b0\uff0c\u800c\u975e\u4e8b\u5b9e\u95f4\u7ebf\u6027\u8ddd\u79bb\u3002", "motivation": "\u5c3d\u7ba1LLM\u5177\u6709\u5927\u89c4\u6a21\u4e0a\u4e0b\u6587\u7a97\u53e3\uff0c\u4f46\u5728\u591a\u8df3\u63a8\u7406\u4e2d\u5b58\u5728\u4f4d\u7f6e\u504f\u89c1\u95ee\u9898\uff0c\u5bfc\u81f4\u5ffd\u7565\u67d0\u4e9b\u4f4d\u7f6e\u7684\u4fe1\u606f\u3002\u7814\u7a76\u8005\u5e0c\u671b\u5398\u6e05\u8fd9\u79cd\u5931\u8d25\u662f\u7531\u4e8e\u65e0\u6cd5\u5b9a\u4f4d\u8bc1\u636e\uff08\u8bc6\u522b\u5931\u8d25\uff09\u8fd8\u662f\u65e0\u6cd5\u6574\u5408\u8bc1\u636e\uff08\u5408\u6210\u5931\u8d25\uff09\u3002", "method": "\u5f15\u5165\u591a\u7126\u70b9\u6ce8\u610f\u529b\u6307\u4ee4\uff08MFAI\uff09\u4f5c\u4e3a\u8bed\u4e49\u63a2\u9488\uff0c\u901a\u8fc7\u663e\u5f0f\u5f15\u5bfc\u6ce8\u610f\u529b\u5230\u9009\u5b9a\u4f4d\u7f6e\u6765\u5206\u79bb\u8bc6\u522b\u548c\u5408\u6210\u673a\u5236\u3002\u57285\u4e2aLLM\u4e0a\u6d4b\u8bd5\u4e24\u4e2a\u591a\u8df3QA\u4efb\u52a1\uff08MuSiQue\u548cNeoQA\uff09\u3002", "result": "\u53d1\u73b0\"\u6700\u5f31\u94fe\u63a5\u5b9a\u5f8b\"\uff1a\u591a\u8df3\u63a8\u7406\u6027\u80fd\u5d29\u6e83\u5230\u6700\u4e0d\u53ef\u89c1\u8bc1\u636e\u7684\u6027\u80fd\u6c34\u5e73\uff1b\u5931\u8d25\u7531\u7edd\u5bf9\u4f4d\u7f6e\u800c\u975e\u4e8b\u5b9e\u95f4\u7ebf\u6027\u8ddd\u79bb\u51b3\u5b9a\uff08\u6027\u80fd\u5dee\u5f02<3%\uff09\u3002\u5339\u914d\u7684MFAI\u53ef\u89e3\u51b3\u8bc6\u522b\u74f6\u9888\uff0c\u5728\u4f4e\u53ef\u89c1\u6027\u4f4d\u7f6e\u63d0\u5347\u51c6\u786e\u7387\u8fbe11.5%\u3002\"\u601d\u8003\"\u6a21\u578b\u80fd\u6709\u6548\u5b9a\u4f4d\u548c\u6574\u5408\u4fe1\u606f\uff0c\u5728\u5608\u6742\u957f\u4e0a\u4e0b\u6587\u8bbe\u7f6e\u4e2d\u5339\u914d\u9ec4\u91d1\u57fa\u7ebf\u3002", "conclusion": "LLM\u591a\u8df3\u63a8\u7406\u5931\u8d25\u4e3b\u8981\u6e90\u4e8e\u4f4d\u7f6e\u504f\u89c1\u5bfc\u81f4\u7684\u8bc6\u522b\u5931\u8d25\u800c\u975e\u5408\u6210\u5931\u8d25\uff1b\u6ce8\u610f\u529b\u5f15\u5bfc\u5177\u6709\u53cc\u91cd\u6027\uff1b\u7cfb\u7edf2\u63a8\u7406\u6a21\u578b\u80fd\u6709\u6548\u514b\u670d\u4f4d\u7f6e\u504f\u89c1\u95ee\u9898\u3002"}}
{"id": "2601.13112", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.13112", "abs": "https://arxiv.org/abs/2601.13112", "authors": ["Xiaolei Zhang", "Xiaojun Jia", "Liquan Chen", "Songze Li"], "title": "CODE: A Contradiction-Based Deliberation Extension Framework for Overthinking Attacks on Retrieval-Augmented Generation", "comment": "12 pages with 7 figures", "summary": "Introducing reasoning models into Retrieval-Augmented Generation (RAG) systems enhances task performance through step-by-step reasoning, logical consistency, and multi-step self-verification. However, recent studies have shown that reasoning models suffer from overthinking attacks, where models are tricked to generate unnecessarily high number of reasoning tokens. In this paper, we reveal that such overthinking risk can be inherited by RAG systems equipped with reasoning models, by proposing an end-to-end attack framework named Contradiction-Based Deliberation Extension (CODE). Specifically, CODE develops a multi-agent architecture to construct poisoning samples that are injected into the knowledge base. These samples 1) are highly correlated with the use query, such that can be retrieved as inputs to the reasoning model; and 2) contain contradiction between the logical and evidence layers that cause models to overthink, and are optimized to exhibit highly diverse styles. Moreover, the inference overhead of CODE is extremely difficult to detect, as no modification is needed on the user query, and the task accuracy remain unaffected. Extensive experiments on two datasets across five commercial reasoning models demonstrate that the proposed attack causes a 5.32x-24.72x increase in reasoning token consumption, without degrading task performance. Finally, we also discuss and evaluate potential countermeasures to mitigate overthinking risks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u4e2d\u63a8\u7406\u6a21\u578b\u7684\u653b\u51fb\u6846\u67b6CODE\uff0c\u901a\u8fc7\u6ce8\u5165\u5305\u542b\u903b\u8f91\u4e0e\u8bc1\u636e\u5c42\u77db\u76fe\u7684\u6bd2\u5316\u6837\u672c\uff0c\u8bf1\u4f7f\u6a21\u578b\u4ea7\u751f\u4e0d\u5fc5\u8981\u7684\u63a8\u7406\u6807\u8bb0\u6d88\u8017\uff0c\u800c\u4e0d\u4f1a\u5f71\u54cd\u4efb\u52a1\u51c6\u786e\u6027\u3002", "motivation": "\u867d\u7136\u63a8\u7406\u6a21\u578b\u901a\u8fc7\u9010\u6b65\u63a8\u7406\u3001\u903b\u8f91\u4e00\u81f4\u6027\u548c\u591a\u6b65\u81ea\u9a8c\u8bc1\u63d0\u5347\u4e86RAG\u7cfb\u7edf\u7684\u4efb\u52a1\u6027\u80fd\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\u63a8\u7406\u6a21\u578b\u5bb9\u6613\u53d7\u5230\"\u8fc7\u5ea6\u601d\u8003\u653b\u51fb\"\u7684\u5f71\u54cd\u3002\u672c\u6587\u63ed\u793a\u8fd9\u79cd\u98ce\u9669\u4f1a\u9057\u4f20\u7ed9\u914d\u5907\u63a8\u7406\u6a21\u578b\u7684RAG\u7cfb\u7edf\uff0c\u9700\u8981\u7814\u7a76\u76f8\u5e94\u7684\u653b\u51fb\u673a\u5236\u548c\u9632\u5fa1\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u540d\u4e3aContradiction-Based Deliberation Extension (CODE)\u7684\u7aef\u5230\u7aef\u653b\u51fb\u6846\u67b6\uff0c\u91c7\u7528\u591a\u667a\u80fd\u4f53\u67b6\u6784\u6784\u5efa\u6bd2\u5316\u6837\u672c\u6ce8\u5165\u77e5\u8bc6\u5e93\u3002\u8fd9\u4e9b\u6837\u672c\u5177\u6709\u4e24\u4e2a\u5173\u952e\u7279\u5f81\uff1a1)\u4e0e\u7528\u6237\u67e5\u8be2\u9ad8\u5ea6\u76f8\u5173\uff0c\u786e\u4fdd\u80fd\u88ab\u68c0\u7d22\u4f5c\u4e3a\u63a8\u7406\u6a21\u578b\u8f93\u5165\uff1b2)\u5305\u542b\u903b\u8f91\u5c42\u4e0e\u8bc1\u636e\u5c42\u4e4b\u95f4\u7684\u77db\u76fe\uff0c\u5bfc\u81f4\u6a21\u578b\u8fc7\u5ea6\u601d\u8003\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u5c55\u73b0\u9ad8\u5ea6\u591a\u6837\u5316\u7684\u98ce\u683c\u3002", "result": "\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u5bf9\u4e94\u4e2a\u5546\u4e1a\u63a8\u7406\u6a21\u578b\u8fdb\u884c\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cCODE\u653b\u51fb\u5bfc\u81f4\u63a8\u7406\u6807\u8bb0\u6d88\u8017\u589e\u52a05.32\u500d\u523024.72\u500d\uff0c\u800c\u4efb\u52a1\u6027\u80fd\u4e0d\u53d7\u5f71\u54cd\u3002\u653b\u51fb\u7684\u63a8\u7406\u5f00\u9500\u6781\u96be\u68c0\u6d4b\uff0c\u56e0\u4e3a\u65e0\u9700\u4fee\u6539\u7528\u6237\u67e5\u8be2\u3002", "conclusion": "CODE\u653b\u51fb\u6846\u67b6\u6210\u529f\u63ed\u793a\u4e86RAG\u7cfb\u7edf\u4e2d\u63a8\u7406\u6a21\u578b\u7ee7\u627f\u8fc7\u5ea6\u601d\u8003\u98ce\u9669\u7684\u95ee\u9898\uff0c\u5e76\u8ba8\u8bba\u4e86\u8bc4\u4f30\u6f5c\u5728\u7684\u5bf9\u7b56\u6765\u51cf\u8f7b\u8fd9\u79cd\u98ce\u9669\u3002\u8be5\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u90e8\u7f72\u63a8\u7406\u589e\u5f3a\u7684RAG\u7cfb\u7edf\u65f6\u9700\u8981\u8003\u8651\u7684\u5b89\u5168\u9690\u60a3\u3002"}}
{"id": "2601.13655", "categories": ["cs.SE", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.13655", "abs": "https://arxiv.org/abs/2601.13655", "authors": ["Guangba Yu", "Zirui Wang", "Yujie Huang", "Renyi Zhong", "Yuedong Zhong", "Yilun Wang", "Michael R. Lyu"], "title": "Why Does the LLM Stop Computing: An Empirical Study of User-Reported Failures in Open-Source LLMs", "comment": null, "summary": "The democratization of open-source Large Language Models (LLMs) allows users to fine-tune and deploy models on local infrastructure but exposes them to a First Mile deployment landscape. Unlike black-box API consumption, the reliability of user-managed orchestration remains a critical blind spot. To bridge this gap, we conduct the first large-scale empirical study of 705 real-world failures from the open-source DeepSeek, Llama, and Qwen ecosystems.\n  Our analysis reveals a paradigm shift: white-box orchestration relocates the reliability bottleneck from model algorithmic defects to the systemic fragility of the deployment stack. We identify three key phenomena: (1) Diagnostic Divergence: runtime crashes distinctively signal infrastructure friction, whereas incorrect functionality serves as a signature for internal tokenizer defects. (2) Systemic Homogeneity: Root causes converge across divergent series, confirming reliability barriers are inherent to the shared ecosystem rather than specific architectures. (3) Lifecycle Escalation: Barriers escalate from intrinsic configuration struggles during fine-tuning to compounded environmental incompatibilities during inference. Supported by our publicly available dataset, these insights provide actionable guidance for enhancing the reliability of the LLM landscape.", "AI": {"tldr": "\u5bf9\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\uff08DeepSeek\u3001Llama\u3001Qwen\uff09\u7684705\u4e2a\u771f\u5b9e\u4e16\u754c\u6545\u969c\u8fdb\u884c\u9996\u6b21\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u53d1\u73b0\u767d\u76d2\u7f16\u6392\u5c06\u53ef\u9760\u6027\u74f6\u9888\u4ece\u6a21\u578b\u7b97\u6cd5\u7f3a\u9677\u8f6c\u79fb\u5230\u90e8\u7f72\u5806\u6808\u7684\u7cfb\u7edf\u8106\u5f31\u6027\u3002", "motivation": "\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6c11\u4e3b\u5316\u4f7f\u7528\u6237\u80fd\u591f\u5728\u672c\u5730\u57fa\u7840\u8bbe\u65bd\u4e0a\u5fae\u8c03\u548c\u90e8\u7f72\u6a21\u578b\uff0c\u4f46\u5c06\u4ed6\u4eec\u66b4\u9732\u5728\"\u7b2c\u4e00\u82f1\u91cc\"\u90e8\u7f72\u73af\u5883\u4e2d\u3002\u4e0e\u9ed1\u76d2API\u6d88\u8d39\u4e0d\u540c\uff0c\u7528\u6237\u7ba1\u7406\u7684\u7f16\u6392\u53ef\u9760\u6027\u6210\u4e3a\u4e00\u4e2a\u5173\u952e\u76f2\u70b9\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u5bf9\u5f00\u6e90DeepSeek\u3001Llama\u548cQwen\u751f\u6001\u7cfb\u7edf\u4e2d705\u4e2a\u771f\u5b9e\u4e16\u754c\u6545\u969c\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u6790\u6545\u969c\u6a21\u5f0f\u3001\u6839\u672c\u539f\u56e0\u548c\u7cfb\u7edf\u6027\u7279\u5f81\u3002", "result": "\u53d1\u73b0\u4e09\u4e2a\u5173\u952e\u73b0\u8c61\uff1a1\uff09\u8bca\u65ad\u5206\u6b67\uff1a\u8fd0\u884c\u65f6\u5d29\u6e83\u4e3b\u8981\u6307\u793a\u57fa\u7840\u8bbe\u65bd\u6469\u64e6\uff0c\u800c\u4e0d\u6b63\u786e\u529f\u80fd\u5219\u4f5c\u4e3a\u5185\u90e8\u5206\u8bcd\u5668\u7f3a\u9677\u7684\u7279\u5f81\uff1b2\uff09\u7cfb\u7edf\u540c\u8d28\u6027\uff1a\u6839\u672c\u539f\u56e0\u5728\u4e0d\u540c\u7cfb\u5217\u6a21\u578b\u4e2d\u8d8b\u540c\uff0c\u786e\u8ba4\u53ef\u9760\u6027\u969c\u788d\u662f\u5171\u4eab\u751f\u6001\u7cfb\u7edf\u7684\u56fa\u6709\u7279\u6027\u800c\u975e\u7279\u5b9a\u67b6\u6784\u95ee\u9898\uff1b3\uff09\u751f\u547d\u5468\u671f\u5347\u7ea7\uff1a\u969c\u788d\u4ece\u5fae\u8c03\u671f\u95f4\u7684\u5185\u5728\u914d\u7f6e\u56f0\u96be\u5347\u7ea7\u5230\u63a8\u7406\u671f\u95f4\u7684\u590d\u5408\u73af\u5883\u4e0d\u517c\u5bb9\u3002", "conclusion": "\u767d\u76d2\u7f16\u6392\u5c06\u53ef\u9760\u6027\u74f6\u9888\u4ece\u6a21\u578b\u7b97\u6cd5\u7f3a\u9677\u8f6c\u79fb\u5230\u90e8\u7f72\u5806\u6808\u7684\u7cfb\u7edf\u8106\u5f31\u6027\uff0c\u8fd9\u4e9b\u89c1\u89e3\u4e3a\u589e\u5f3aLLM\u751f\u6001\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\uff0c\u5e76\u652f\u6301\u516c\u5f00\u53ef\u7528\u7684\u6570\u636e\u96c6\u3002"}}
{"id": "2601.13682", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2601.13682", "abs": "https://arxiv.org/abs/2601.13682", "authors": ["Jianfeng Cai", "Jinhua Zhu", "Ruopei Sun", "Kangwen Zhao", "Dongyun Xue", "Mingxiao Feng", "Wengang Zhou", "Houqiang Li"], "title": "CodeContests-O: Powering LLMs via Feedback-Driven Iterative Test Case Generation", "comment": null, "summary": "The rise of reasoning models necessitates large-scale verifiable data, for which programming tasks serve as an ideal source. However, while competitive programming platforms provide abundant problems and solutions, high-quality test cases for verification remain scarce. Existing approaches attempt to synthesize test cases using Large Language Models (LLMs), but rely solely on the model's intrinsic generation capabilities without external feedback, frequently resulting in insufficiently diverse cases. To address this limitation, we propose a $\\textbf{Feedback-Driven Iterative Framework}$ for comprehensive test case construction. Specifically, our method leverages the LLM to generate initial test cases, executes them against known correct and incorrect solutions, and utilizes the failed results as feedback to guide the LLM in refining the test cases toward high fidelity and discriminability. We then apply this method to the CodeContests dataset to construct an optimized high-quality derivative, $\\textbf{CodeContests-O}$. Evaluating against the entire pool of solutions ($1.1 \\times 10^7$ in total), our dataset achieves an average True Positive Rate (TPR) of $89.37\\%$ and True Negative Rate (TNR) of $90.89\\%$, significantly outperforming the CodeContests and CodeContests+ by margins of $4.32\\%$ and $9.37\\%$, respectively. Furthermore, fine-tuning the Qwen2.5-7B model on CodeContests-O results in a $9.52\\%$ improvement on LiveCodeBench (Pass@1). Experiments demonstrate the effectiveness of our framework and the quality of CodeContests-O. To support reproducibility and facilitate future research, we release the $\\href{https://github.com/cai-jianfeng/CodeContests-O}{code}$ and $\\href{https://huggingface.co/datasets/caijanfeng/CodeContests-O}{dataset}$.", "AI": {"tldr": "\u63d0\u51fa\u53cd\u9988\u9a71\u52a8\u7684\u8fed\u4ee3\u6846\u67b6\uff0c\u7528\u4e8e\u6784\u5efa\u9ad8\u8d28\u91cf\u7684\u7f16\u7a0b\u6d4b\u8bd5\u7528\u4f8b\u6570\u636e\u96c6CodeContests-O\uff0c\u663e\u8457\u63d0\u5347\u6d4b\u8bd5\u7528\u4f8b\u7684\u4fdd\u771f\u5ea6\u548c\u533a\u5206\u5ea6", "motivation": "\u63a8\u7406\u6a21\u578b\u9700\u8981\u5927\u89c4\u6a21\u53ef\u9a8c\u8bc1\u6570\u636e\uff0c\u7f16\u7a0b\u4efb\u52a1\u662f\u7406\u60f3\u6765\u6e90\uff0c\u4f46\u73b0\u6709\u5e73\u53f0\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u6d4b\u8bd5\u7528\u4f8b\u3002\u73b0\u6709\u65b9\u6cd5\u4ec5\u4f9d\u8d56LLM\u5185\u5728\u751f\u6210\u80fd\u529b\uff0c\u7f3a\u4e4f\u5916\u90e8\u53cd\u9988\uff0c\u5bfc\u81f4\u6d4b\u8bd5\u7528\u4f8b\u591a\u6837\u6027\u4e0d\u8db3", "method": "\u63d0\u51fa\u53cd\u9988\u9a71\u52a8\u7684\u8fed\u4ee3\u6846\u67b6\uff1a1) LLM\u751f\u6210\u521d\u59cb\u6d4b\u8bd5\u7528\u4f8b\uff1b2) \u5728\u5df2\u77e5\u6b63\u786e\u548c\u9519\u8bef\u89e3\u51b3\u65b9\u6848\u4e0a\u6267\u884c\u6d4b\u8bd5\uff1b3) \u5229\u7528\u5931\u8d25\u7ed3\u679c\u4f5c\u4e3a\u53cd\u9988\uff0c\u6307\u5bfcLLM\u4f18\u5316\u6d4b\u8bd5\u7528\u4f8b\u7684\u4fdd\u771f\u5ea6\u548c\u533a\u5206\u5ea6", "result": "\u6784\u5efa\u7684CodeContests-O\u6570\u636e\u96c6\u57281100\u4e07\u89e3\u51b3\u65b9\u6848\u4e0a\u5e73\u5747TPR\u8fbe89.37%\uff0cTNR\u8fbe90.89%\uff0c\u663e\u8457\u4f18\u4e8eCodeContests\u548cCodeContests+\u3002\u5728Qwen2.5-7B\u6a21\u578b\u4e0a\u5fae\u8c03\u540e\uff0cLiveCodeBench\u6027\u80fd\u63d0\u53479.52%", "conclusion": "\u63d0\u51fa\u7684\u53cd\u9988\u9a71\u52a8\u8fed\u4ee3\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u6d4b\u8bd5\u7528\u4f8b\u8d28\u91cf\uff0cCodeContests-O\u6570\u636e\u96c6\u5728\u4fdd\u771f\u5ea6\u548c\u533a\u5206\u5ea6\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4e3a\u7f16\u7a0b\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u9ad8\u8d28\u91cf\u6570\u636e\u652f\u6301"}}
{"id": "2601.13271", "categories": ["cs.CR", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.13271", "abs": "https://arxiv.org/abs/2601.13271", "authors": ["Chao Yin", "Zunchen Huang", "Chenglu Jin", "Marten van Dijk", "Fabio Massacci"], "title": "Function Recovery Attacks in Gate-Hiding Garbled Circuits using SAT Solving", "comment": null, "summary": "Semi-Private Function Evaluation enables joint computation while protecting both input data and function logic. A practical instantiation is gate-hiding garbled circuits, which conceal gate functionalities while revealing the circuit topology. Existing security definitions intentionally exclude leakage through circuit topology, leaving the concrete impact of such leakage on function privacy insufficiently understood.\n  We analyze the empirical security of gate hiding under two adversarial models that capture realistic computational capabilities. We present a SAT-based function-recovery attack that reconstructs hidden gate operations from a circuit's public topology. To enable recovery on larger and more complex circuits, we develop an incremental SAT-solving framework combined with a set of composable, topology-preserving simplification theorems. These techniques jointly reduce the SAT instance size and progressively constrain the search space across repeated solving iterations.\n  We evaluate our attack on ISCAS benchmarks, representative secure computation circuits, and fault-tolerant sensor fusion circuits under a fixed 24-hour recovery budget. Compared to baseline approaches, our optimized attack achieves up to a 159-fold speedup in recovery time without increasing the number of oracle queries. Our results demonstrate that topology leakage alone can enable effective function recovery in practice.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u95e8\u9690\u85cf\u7535\u8def\u62d3\u6251\u6cc4\u9732\u5bf9\u51fd\u6570\u9690\u79c1\u7684\u5b9e\u9645\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8eSAT\u7684\u51fd\u6570\u6062\u590d\u653b\u51fb\u65b9\u6cd5\uff0c\u5728ISCAS\u57fa\u51c6\u7535\u8def\u4e0a\u5b9e\u73b0\u4e86\u6700\u9ad8159\u500d\u7684\u6062\u590d\u901f\u5ea6\u63d0\u5347\u3002", "motivation": "\u534a\u79c1\u6709\u51fd\u6570\u8bc4\u4f30\u6280\u672f\u65e8\u5728\u4fdd\u62a4\u8f93\u5165\u6570\u636e\u548c\u51fd\u6570\u903b\u8f91\uff0c\u4f46\u73b0\u6709\u7684\u95e8\u9690\u85cf\u7535\u8def\u65b9\u6cd5\u53ea\u9690\u85cf\u95e8\u529f\u80fd\u800c\u516c\u5f00\u7535\u8def\u62d3\u6251\u3002\u73b0\u6709\u5b89\u5168\u5b9a\u4e49\u6545\u610f\u6392\u9664\u62d3\u6251\u6cc4\u9732\uff0c\u5bfc\u81f4\u5bf9\u51fd\u6570\u9690\u79c1\u7684\u5b9e\u9645\u5f71\u54cd\u7406\u89e3\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eSAT\u7684\u51fd\u6570\u6062\u590d\u653b\u51fb\uff0c\u4ece\u516c\u5f00\u7684\u7535\u8def\u62d3\u6251\u91cd\u5efa\u9690\u85cf\u7684\u95e8\u64cd\u4f5c\u3002\u4e3a\u5904\u7406\u66f4\u5927\u66f4\u590d\u6742\u7684\u7535\u8def\uff0c\u5f00\u53d1\u4e86\u589e\u91cfSAT\u6c42\u89e3\u6846\u67b6\u548c\u4e00\u7ec4\u53ef\u7ec4\u5408\u7684\u62d3\u6251\u4fdd\u6301\u7b80\u5316\u5b9a\u7406\uff0c\u51cf\u5c11SAT\u5b9e\u4f8b\u89c4\u6a21\u5e76\u9010\u6b65\u7ea6\u675f\u641c\u7d22\u7a7a\u95f4\u3002", "result": "\u5728ISCAS\u57fa\u51c6\u7535\u8def\u3001\u4ee3\u8868\u6027\u5b89\u5168\u8ba1\u7b97\u7535\u8def\u548c\u5bb9\u9519\u4f20\u611f\u5668\u878d\u5408\u7535\u8def\u4e0a\u8bc4\u4f30\u653b\u51fb\u6548\u679c\uff0c\u572824\u5c0f\u65f6\u6062\u590d\u9884\u7b97\u5185\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6700\u9ad8159\u500d\u7684\u6062\u590d\u901f\u5ea6\u63d0\u5347\uff0c\u4e14\u4e0d\u589e\u52a0\u9884\u8a00\u673a\u67e5\u8be2\u6b21\u6570\u3002", "conclusion": "\u62d3\u6251\u6cc4\u9732\u672c\u8eab\u5728\u5b9e\u8df5\u4e2d\u5c31\u80fd\u5b9e\u73b0\u6709\u6548\u7684\u51fd\u6570\u6062\u590d\uff0c\u8fd9\u8868\u660e\u4ec5\u9690\u85cf\u95e8\u529f\u80fd\u800c\u516c\u5f00\u7535\u8def\u62d3\u6251\u53ef\u80fd\u4e0d\u8db3\u4ee5\u4fdd\u62a4\u51fd\u6570\u9690\u79c1\uff0c\u9700\u8981\u91cd\u65b0\u8bc4\u4f30\u534a\u79c1\u6709\u51fd\u6570\u8bc4\u4f30\u7684\u5b89\u5168\u6a21\u578b\u3002"}}
{"id": "2601.12542", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12542", "abs": "https://arxiv.org/abs/2601.12542", "authors": ["Lukas Weidener", "Marko Brki\u0107", "Mihailo Jovanovi\u0107", "Ritvik Singh", "Chiara Baccin", "Emre Ulgac", "Alex Dobrin", "Aakaash Meduri"], "title": "Rethinking the AI Scientist: Interactive Multi-Agent Workflows for Scientific Discovery", "comment": null, "summary": "Artificial intelligence systems for scientific discovery have demonstrated remarkable potential, yet existing approaches remain largely proprietary and operate in batch-processing modes requiring hours per research cycle, precluding real-time researcher guidance. This paper introduces Deep Research, a multi-agent system enabling interactive scientific investigation with turnaround times measured in minutes. The architecture comprises specialized agents for planning, data analysis, literature search, and novelty detection, unified through a persistent world state that maintains context across iterative research cycles. Two operational modes support different workflows: semi-autonomous mode with selective human checkpoints, and fully autonomous mode for extended investigations. Evaluation on the BixBench computational biology benchmark demonstrated state-of-the-art performance, achieving 48.8% accuracy on open response and 64.5% on multiple-choice evaluation, exceeding existing baselines by 14 to 26 percentage points. Analysis of architectural constraints, including open access literature limitations and challenges inherent to automated novelty assessment, informs practical deployment considerations for AI-assisted scientific workflows.", "AI": {"tldr": "Deep Research\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u80fd\u591f\u5728\u51e0\u5206\u949f\u5185\u5b8c\u6210\u4ea4\u4e92\u5f0f\u79d1\u5b66\u7814\u7a76\uff0c\u76f8\u6bd4\u73b0\u6709\u6279\u5904\u7406\u7cfb\u7edf\u663e\u8457\u63d0\u5347\u6548\u7387\uff0c\u5728BixBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709AI\u79d1\u5b66\u53d1\u73b0\u7cfb\u7edf\u5927\u591a\u662f\u4e13\u6709\u7684\u6279\u5904\u7406\u6a21\u5f0f\uff0c\u6bcf\u4e2a\u7814\u7a76\u5468\u671f\u9700\u8981\u6570\u5c0f\u65f6\uff0c\u65e0\u6cd5\u5b9e\u73b0\u7814\u7a76\u8005\u7684\u5b9e\u65f6\u6307\u5bfc\uff0c\u9650\u5236\u4e86AI\u5728\u79d1\u5b66\u7814\u7a76\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u5305\u542b\u89c4\u5212\u3001\u6570\u636e\u5206\u6790\u3001\u6587\u732e\u641c\u7d22\u548c\u65b0\u9896\u6027\u68c0\u6d4b\u7b49\u4e13\u95e8\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u6301\u4e45\u4e16\u754c\u72b6\u6001\u7ef4\u6301\u8de8\u8fed\u4ee3\u7814\u7a76\u5468\u671f\u7684\u4e0a\u4e0b\u6587\uff0c\u652f\u6301\u534a\u81ea\u4e3b\uff08\u5e26\u4eba\u5de5\u68c0\u67e5\u70b9\uff09\u548c\u5168\u81ea\u4e3b\u4e24\u79cd\u5de5\u4f5c\u6a21\u5f0f\u3002", "result": "\u5728BixBench\u8ba1\u7b97\u751f\u7269\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u6700\u5148\u8fdb\u6027\u80fd\uff1a\u5f00\u653e\u56de\u7b54\u51c6\u786e\u738748.8%\uff0c\u591a\u9879\u9009\u62e9\u51c6\u786e\u738764.5%\uff0c\u6bd4\u73b0\u6709\u57fa\u7ebf\u63d0\u534714-26\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "Deep Research\u7cfb\u7edf\u5b9e\u73b0\u4e86\u5206\u949f\u7ea7\u7684\u4ea4\u4e92\u5f0f\u79d1\u5b66\u7814\u7a76\uff0c\u663e\u8457\u63d0\u5347\u4e86AI\u8f85\u52a9\u79d1\u5b66\u5de5\u4f5c\u6d41\u7a0b\u7684\u6548\u7387\uff0c\u540c\u65f6\u5206\u6790\u4e86\u5f00\u653e\u83b7\u53d6\u6587\u732e\u9650\u5236\u548c\u81ea\u52a8\u65b0\u9896\u6027\u8bc4\u4f30\u7b49\u5b9e\u9645\u90e8\u7f72\u6311\u6218\u3002"}}
{"id": "2601.13713", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13713", "abs": "https://arxiv.org/abs/2601.13713", "authors": ["Aditya Bharat Soni", "Rajat Ghosh", "Vaishnavi Bhargava", "Valerie Chen", "Debojyoti Dutta"], "title": "SWE-Tester: Training Open-Source LLMs for Issue Reproduction in Real-World Repositories", "comment": null, "summary": "Software testing is crucial for ensuring the correctness and reliability of software systems. Automated generation of issue reproduction tests from natural language issue descriptions enhances developer productivity by simplifying root cause analysis, promotes test-driven development -- \"test first, write code later\", and can be used for improving the effectiveness of automated issue resolution systems like coding agents. Existing methods proposed for this task predominantly rely on closed-source LLMs, with limited exploration of open models. To address this, we propose SWE-Tester -- a novel pipeline for training open-source LLMs to generate issue reproduction tests. First, we curate a high-quality training dataset of 41K instances from 2.6K open-source GitHub repositories and use it to train LLMs of varying sizes and families. The fine-tuned models achieve absolute improvements of up to 10\\% in success rate and 21\\% in change coverage on SWT-Bench Verified. Further analysis shows consistent improvements with increased inference-time compute, more data, and larger models. These results highlight the effectiveness of our framework for advancing open-source LLMs in this domain.", "AI": {"tldr": "\u63d0\u51faSWE-Tester\u6846\u67b6\uff0c\u901a\u8fc7\u8bad\u7ec3\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u6765\u81ea\u52a8\u751f\u6210\u95ee\u9898\u590d\u73b0\u6d4b\u8bd5\uff0c\u5728SWT-Bench Verified\u4e0a\u5b9e\u73b0\u6700\u9ad810%\u7684\u6210\u529f\u7387\u548c21%\u7684\u53d8\u66f4\u8986\u76d6\u7387\u7edd\u5bf9\u63d0\u5347", "motivation": "\u8f6f\u4ef6\u6d4b\u8bd5\u5bf9\u786e\u4fdd\u8f6f\u4ef6\u7cfb\u7edf\u6b63\u786e\u6027\u548c\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\u3002\u4ece\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u63cf\u8ff0\u81ea\u52a8\u751f\u6210\u95ee\u9898\u590d\u73b0\u6d4b\u8bd5\u80fd\u63d0\u9ad8\u5f00\u53d1\u6548\u7387\u3001\u4fc3\u8fdb\u6d4b\u8bd5\u9a71\u52a8\u5f00\u53d1\uff0c\u5e76\u589e\u5f3a\u81ea\u52a8\u95ee\u9898\u89e3\u51b3\u7cfb\u7edf\u7684\u6709\u6548\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u95ed\u6e90LLM\uff0c\u5bf9\u5f00\u6e90\u6a21\u578b\u63a2\u7d22\u6709\u9650\u3002", "method": "\u63d0\u51faSWE-Tester\u8bad\u7ec3\u7ba1\u9053\uff1a1) \u4ece2.6K\u4e2a\u5f00\u6e90GitHub\u4ed3\u5e93\u4e2d\u6574\u740641K\u4e2a\u9ad8\u8d28\u91cf\u8bad\u7ec3\u5b9e\u4f8b\u6570\u636e\u96c6\uff1b2) \u4f7f\u7528\u8be5\u6570\u636e\u96c6\u8bad\u7ec3\u4e0d\u540c\u89c4\u6a21\u548c\u7cfb\u5217\u7684\u5f00\u6e90LLM\uff1b3) \u901a\u8fc7\u589e\u52a0\u63a8\u7406\u8ba1\u7b97\u3001\u66f4\u591a\u6570\u636e\u548c\u66f4\u5927\u6a21\u578b\u6765\u63d0\u5347\u6027\u80fd", "result": "\u5fae\u8c03\u6a21\u578b\u5728SWT-Bench Verified\u4e0a\u5b9e\u73b0\u6700\u9ad810%\u7684\u6210\u529f\u7387\u7edd\u5bf9\u63d0\u5347\u548c21%\u7684\u53d8\u66f4\u8986\u76d6\u7387\u7edd\u5bf9\u63d0\u5347\u3002\u5206\u6790\u663e\u793a\u589e\u52a0\u63a8\u7406\u8ba1\u7b97\u3001\u66f4\u591a\u6570\u636e\u548c\u66f4\u5927\u6a21\u578b\u80fd\u5e26\u6765\u4e00\u81f4\u7684\u6027\u80fd\u6539\u8fdb", "conclusion": "SWE-Tester\u6846\u67b6\u6709\u6548\u63a8\u8fdb\u4e86\u5f00\u6e90LLM\u5728\u95ee\u9898\u590d\u73b0\u6d4b\u8bd5\u751f\u6210\u9886\u57df\u7684\u5e94\u7528\uff0c\u4e3a\u5f00\u6e90\u6a21\u578b\u5728\u8be5\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u63d0\u5347\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848"}}
{"id": "2601.13399", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2601.13399", "abs": "https://arxiv.org/abs/2601.13399", "authors": ["Jonatan Rassekhnia"], "title": "QERS: Quantum Encryption Resilience Score for Post-Quantum Cryptography in Computer, IoT, and IIoT Systems", "comment": "10 pages, 6 figures. Preprint version; extended validation planned for MSc thesis and journal submission", "summary": "Post-quantum cryptography (PQC) is becoming essential for securing Internet of Things (IoT) and Industrial IoT (IIoT) systems against quantum-enabled adversaries. However, existing evaluation approaches primarily focus on isolated performance metrics, offering limited support for holistic security and deployment decisions. This paper introduces QERS (Quantum Encryption Resilience Score), a universal measurement framework that integrates cryptographic performance, system constraints, and multi-criteria decision analysis to assess PQC readiness in computer, IoT, and IIoT environments. QERS combines normalized metrics, weighted aggregation, and machine learning-assisted analysis to produce interpretable resilience scores across heterogeneous devices and communication protocols. Experimental results demonstrate how the framework enables comparative evaluation of post-quantum schemes under realistic resource constraints, supporting informed security design and migration planning. This work is presented as a preprint, with extended statistical validation planned as part of ongoing graduate research.", "AI": {"tldr": "QERS\u6846\u67b6\u901a\u8fc7\u6574\u5408\u5bc6\u7801\u6027\u80fd\u3001\u7cfb\u7edf\u7ea6\u675f\u548c\u591a\u6807\u51c6\u51b3\u7b56\u5206\u6790\uff0c\u4e3a\u7269\u8054\u7f51\u73af\u5883\u63d0\u4f9b\u540e\u91cf\u5b50\u5bc6\u7801\u51c6\u5907\u5ea6\u8bc4\u4f30\u7684\u901a\u7528\u6d4b\u91cf\u6846\u67b6", "motivation": "\u540e\u91cf\u5b50\u5bc6\u7801\u5bf9\u4fdd\u62a4\u7269\u8054\u7f51\u7cfb\u7edf\u514d\u53d7\u91cf\u5b50\u653b\u51fb\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5b64\u7acb\u6027\u80fd\u6307\u6807\uff0c\u7f3a\u4e4f\u5bf9\u6574\u4f53\u5b89\u5168\u6027\u548c\u90e8\u7f72\u51b3\u7b56\u7684\u5168\u9762\u652f\u6301", "method": "\u63d0\u51faQERS\uff08\u91cf\u5b50\u52a0\u5bc6\u97e7\u6027\u8bc4\u5206\uff09\u6846\u67b6\uff0c\u7ed3\u5408\u5f52\u4e00\u5316\u6307\u6807\u3001\u52a0\u6743\u805a\u5408\u548c\u673a\u5668\u5b66\u4e60\u8f85\u52a9\u5206\u6790\uff0c\u5728\u5f02\u6784\u8bbe\u5907\u548c\u901a\u4fe1\u534f\u8bae\u4e2d\u751f\u6210\u53ef\u89e3\u91ca\u7684\u97e7\u6027\u8bc4\u5206", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u6846\u67b6\u80fd\u591f\u5728\u5b9e\u9645\u8d44\u6e90\u7ea6\u675f\u4e0b\u5bf9\u540e\u91cf\u5b50\u65b9\u6848\u8fdb\u884c\u5bf9\u6bd4\u8bc4\u4f30\uff0c\u652f\u6301\u660e\u667a\u7684\u5b89\u5168\u8bbe\u8ba1\u548c\u8fc1\u79fb\u89c4\u5212", "conclusion": "QERS\u4e3a\u8ba1\u7b97\u673a\u3001\u7269\u8054\u7f51\u548c\u5de5\u4e1a\u7269\u8054\u7f51\u73af\u5883\u63d0\u4f9b\u4e86\u4e00\u79cd\u8bc4\u4f30\u540e\u91cf\u5b50\u5bc6\u7801\u51c6\u5907\u5ea6\u7684\u901a\u7528\u6d4b\u91cf\u6846\u67b6\uff0c\u76ee\u524d\u4f5c\u4e3a\u9884\u5370\u672c\u53d1\u5e03\uff0c\u8ba1\u5212\u5728\u540e\u7eed\u7814\u7a76\u4e2d\u6269\u5c55\u7edf\u8ba1\u9a8c\u8bc1"}}
{"id": "2601.12547", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12547", "abs": "https://arxiv.org/abs/2601.12547", "authors": ["Dipayan Sengupta", "Saumya Panda"], "title": "How Clinicians Think and What AI Can Learn From It", "comment": "34 pages", "summary": "Most clinical AI systems operate as prediction engines -- producing labels or risk scores -- yet real clinical reasoning is a time-bounded, sequential control problem under uncertainty. Clinicians interleave information gathering with irreversible actions, guided by regret, constraints and patient values. We argue that the dominant computational substrate of clinician reasoning is not cardinal optimization but ordinal, non-compensatory decision-making: Clinicians frequently rely on fast-and-frugal, lexicographic heuristics (e.g., fast-and-frugal trees) that stop early after checking a small, fixed sequence of cues. We provide a normative rationale for why such algorithms are not merely bounded rationality shortcuts, but can be epistemically preferred in medicine. First, many clinical trade-offs are constructed through human judgment and are only weakly measurable on absolute scales; without strong measurement axioms, only orderings are invariant, motivating an ordinal-by-default stance. Second, preference and signal elicitation are structurally crude: The mapping from truth $\\to$ perception $\\to$ inference $\\to$ recorded variables introduces layered noise, leaving a persistent uncertainty floor. When this 'crudeness' overwhelms the decision margin, plug-in expected-utility optimization becomes brittle (high flip probability under small perturbations), whereas robust dominance/filtering rules ($\u03b5$-dominance, maximin) stabilize decisions.Finally, we outline a clinician-aligned AI blueprint: Use rich models for beliefs and trajectories, but choose actions through robust ordinal rules; treat heuristics as the low-dimensional special case; and deploy AI as 'selective complexity' -- invoked mainly for tie-breaking when decisions are fragile and information has positive expected impact.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e3b\u5f20\u4e34\u5e8aAI\u5e94\u4ece\u9884\u6d4b\u5f15\u64ce\u8f6c\u5411\u987a\u5e8f\u63a7\u5236\u95ee\u9898\uff0c\u91c7\u7528\u7a33\u5065\u7684\u5e8f\u6570\u51b3\u7b56\u89c4\u5219\u800c\u975e\u57fa\u6570\u4f18\u5316\uff0c\u4ee5\u66f4\u597d\u6a21\u62df\u4e34\u5e8a\u63a8\u7406\u672c\u8d28\u3002", "motivation": "\u5f53\u524d\u4e34\u5e8aAI\u7cfb\u7edf\u4e3b\u8981\u4f5c\u4e3a\u9884\u6d4b\u5f15\u64ce\uff08\u751f\u6210\u6807\u7b7e\u6216\u98ce\u9669\u8bc4\u5206\uff09\uff0c\u4f46\u771f\u5b9e\u7684\u4e34\u5e8a\u63a8\u7406\u662f\u65f6\u95f4\u53d7\u9650\u3001\u987a\u5e8f\u63a7\u5236\u7684\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u3002\u4e34\u5e8a\u533b\u751f\u5728\u4fe1\u606f\u6536\u96c6\u4e0e\u4e0d\u53ef\u9006\u884c\u52a8\u4e4b\u95f4\u4ea4\u66ff\uff0c\u53d7\u9057\u61be\u3001\u7ea6\u675f\u548c\u60a3\u8005\u4ef7\u503c\u89c2\u6307\u5bfc\u3002\u9700\u8981\u5f00\u53d1\u66f4\u7b26\u5408\u4e34\u5e8a\u63a8\u7406\u672c\u8d28\u7684AI\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e34\u5e8a\u63a8\u7406\u7684\u8ba1\u7b97\u57fa\u7840\u5e94\u662f\u5e8f\u6570\u3001\u975e\u8865\u507f\u6027\u51b3\u7b56\u800c\u975e\u57fa\u6570\u4f18\u5316\u3002\u8bba\u8bc1\u5feb\u901f\u8282\u4fed\u7684\u8bcd\u5178\u5f0f\u542f\u53d1\u6cd5\uff08\u5982\u5feb\u901f\u8282\u4fed\u6811\uff09\u5728\u533b\u5b66\u4e2d\u7684\u89c4\u8303\u6027\u5408\u7406\u6027\u3002\u63d0\u51fa\u4e34\u5e8a\u5bf9\u9f50AI\u84dd\u56fe\uff1a\u4f7f\u7528\u4e30\u5bcc\u6a21\u578b\u8fdb\u884c\u4fe1\u5ff5\u548c\u8f68\u8ff9\u5efa\u6a21\uff0c\u4f46\u901a\u8fc7\u7a33\u5065\u5e8f\u6570\u89c4\u5219\u9009\u62e9\u884c\u52a8\uff1b\u5c06\u542f\u53d1\u6cd5\u89c6\u4e3a\u4f4e\u7ef4\u7279\u4f8b\uff1b\u5c06AI\u90e8\u7f72\u4e3a\"\u9009\u62e9\u6027\u590d\u6742\u6027\"\u2014\u2014\u4e3b\u8981\u5728\u51b3\u7b56\u8106\u5f31\u4e14\u4fe1\u606f\u5177\u6709\u6b63\u671f\u671b\u5f71\u54cd\u65f6\u7528\u4e8e\u6253\u7834\u5e73\u5c40\u3002", "result": "\u8bba\u8bc1\u4e86\u5e8f\u6570\u51b3\u7b56\u89c4\u5219\u5728\u4e34\u5e8a\u73af\u5883\u4e2d\u7684\u4f18\u8d8a\u6027\uff1a1\uff09\u8bb8\u591a\u4e34\u5e8a\u6743\u8861\u901a\u8fc7\u4eba\u7c7b\u5224\u65ad\u6784\u5efa\uff0c\u4ec5\u5728\u7edd\u5bf9\u5c3a\u5ea6\u4e0a\u5f31\u53ef\u6d4b\u91cf\uff1b2\uff09\u504f\u597d\u548c\u4fe1\u53f7\u83b7\u53d6\u7ed3\u6784\u7c97\u7cd9\uff0c\u5b58\u5728\u6301\u7eed\u4e0d\u786e\u5b9a\u6027\uff1b3\uff09\u5f53\u8fd9\u79cd\"\u7c97\u7cd9\u6027\"\u8d85\u8fc7\u51b3\u7b56\u8fb9\u754c\u65f6\uff0c\u671f\u671b\u6548\u7528\u4f18\u5316\u53d8\u5f97\u8106\u5f31\uff0c\u800c\u7a33\u5065\u4f18\u52bf/\u8fc7\u6ee4\u89c4\u5219\u80fd\u7a33\u5b9a\u51b3\u7b56\u3002", "conclusion": "\u4e34\u5e8aAI\u5e94\u91c7\u7528\u7a33\u5065\u5e8f\u6570\u51b3\u7b56\u6846\u67b6\uff0c\u5c06AI\u4f5c\u4e3a\"\u9009\u62e9\u6027\u590d\u6742\u6027\"\u5de5\u5177\uff0c\u5728\u51b3\u7b56\u8106\u5f31\u65f6\u4ecb\u5165\u3002\u8fd9\u79cd\u8303\u5f0f\u8f6c\u53d8\u80fd\u66f4\u597d\u6a21\u62df\u4e34\u5e8a\u63a8\u7406\u672c\u8d28\uff0c\u63d0\u9ad8\u51b3\u7b56\u7a33\u5b9a\u6027\uff0c\u5b9e\u73b0\u4e34\u5e8a\u5bf9\u9f50\u7684\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u3002"}}
{"id": "2601.13743", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.13743", "abs": "https://arxiv.org/abs/2601.13743", "authors": ["Zhenya Zhang", "Parv Kapoor", "Jie An", "Eunsuk Kang"], "title": "Counterexample Classification against Signal Temporal Logic Specifications", "comment": null, "summary": "Signal Temporal Logic (STL) has been widely adopted as a specification language for specifying desirable behaviors of hybrid systems. By monitoring a given STL specification, we can detect the executions that violate it, which are often referred to as counterexamples. In practice, these counterexamples may arise from different causes and thus are relevant to different system defects. To effectively address this, we need a proper criterion for classifying these counterexamples, by which we can comprehend the possible violation patterns and the distributions of these counterexamples with respect to the patterns. In this paper, we propose a classification criterion by using parametric signal temporal logic (PSTL) to represent each class. Due to this formalism, identifying the classes of a counterexample requires finding proper parameter values of PSTL that enable a class to include the counterexample. To improve the efficiency of class identification, we further derive an inclusion relation between different classes, and then propose a binary search-like approach over it that significantly prunes the classes needed to query. We implement a prototype tool and experimentally evaluate its effectiveness on two widely-studied systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u53c2\u6570\u5316\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91(PSTL)\u5bf9\u8fdd\u53cdSTL\u89c4\u8303\u7684\u6267\u884c\u8f68\u8ff9\u8fdb\u884c\u5206\u7c7b\uff0c\u901a\u8fc7\u63a8\u5bfc\u7c7b\u95f4\u5305\u542b\u5173\u7cfb\u5e76\u91c7\u7528\u4e8c\u5206\u641c\u7d22\u65b9\u6cd5\u63d0\u9ad8\u5206\u7c7b\u6548\u7387\u3002", "motivation": "\u5728\u6df7\u5408\u7cfb\u7edf\u76d1\u63a7\u4e2d\uff0c\u8fdd\u53cdSTL\u89c4\u8303\u7684\u6267\u884c\u8f68\u8ff9\uff08\u53cd\u4f8b\uff09\u53ef\u80fd\u6e90\u4e8e\u4e0d\u540c\u539f\u56e0\uff0c\u5bf9\u5e94\u4e0d\u540c\u7684\u7cfb\u7edf\u7f3a\u9677\u3002\u4e3a\u4e86\u6709\u6548\u5904\u7406\u8fd9\u4e9b\u53cd\u4f8b\uff0c\u9700\u8981\u5408\u9002\u7684\u5206\u7c7b\u6807\u51c6\u6765\u7406\u89e3\u53ef\u80fd\u7684\u8fdd\u53cd\u6a21\u5f0f\u53ca\u5176\u5206\u5e03\u3002", "method": "1. \u4f7f\u7528\u53c2\u6570\u5316\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91(PSTL)\u8868\u793a\u6bcf\u4e2a\u5206\u7c7b\uff1b2. \u63a8\u5bfc\u4e0d\u540c\u5206\u7c7b\u4e4b\u95f4\u7684\u5305\u542b\u5173\u7cfb\uff1b3. \u57fa\u4e8e\u5305\u542b\u5173\u7cfb\u63d0\u51fa\u7c7b\u4f3c\u4e8c\u5206\u641c\u7d22\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u51cf\u5c11\u9700\u8981\u67e5\u8be2\u7684\u5206\u7c7b\u6570\u91cf\u3002", "result": "\u5b9e\u73b0\u4e86\u539f\u578b\u5de5\u5177\uff0c\u5e76\u5728\u4e24\u4e2a\u5e7f\u6cdb\u7814\u7a76\u7684\u7cfb\u7edf\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8ePSTL\u7684\u5206\u7c7b\u6807\u51c6\u548c\u5305\u542b\u5173\u7cfb\u641c\u7d22\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5bf9\u8fdd\u53cdSTL\u89c4\u8303\u7684\u53cd\u4f8b\u8fdb\u884c\u5206\u7c7b\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u7cfb\u7edf\u7f3a\u9677\u7684\u6a21\u5f0f\u5206\u5e03\u3002"}}
{"id": "2601.13423", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2601.13423", "abs": "https://arxiv.org/abs/2601.13423", "authors": ["Jonatan Rassekhnia"], "title": "Quantum Encryption Resilience Score (QERS) for MQTT, HTTP, and HTTPS under Post-Quantum Cryptography in Computer, IoT, and IIoT Systems", "comment": "9 pages, 6 figures. Experimental preprint. Companion study to the QERS framework based on MQTT, HTTP, and HTTPS protocols; extended analysis and validation planned for MSc thesis and journal submission", "summary": "Post-quantum cryptography (PQC) introduces significant computational and communication overhead, which poses challenges for resource-constrained computer systems, Internet of Things (IoT), and Industrial IoT (IIoT) devices. This paper presents an experimental evaluation of the Quantum Encryption Resilience Score (QERS) applied to MQTT, HTTP, and HTTPS communication protocols operating under PQC. Using an ESP32-C6 client and an ARM-based Raspberry Pi CM4 server, latency, CPU utilization, RSSI, energy consumption, key size, and TLS handshake overhead are measured under realistic operating conditions. QERS integrates these heterogeneous metrics into normalized Basic, Tuned, and Fusion scores, enabling systematic comparison of protocol efficiency and security resilience. Experimental results show that MQTT provides the highest efficiency under PQC constraints, while HTTPS achieves the highest security-weighted resilience at the cost of increased latency and resource consumption. The proposed framework supports informed protocol selection and migration planning for PQC-enabled IoT and IIoT deployments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u4e86\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\uff08PQC\uff09\u4e0bMQTT\u3001HTTP\u548cHTTPS\u901a\u4fe1\u534f\u8bae\u7684\u6027\u80fd\uff0c\u63d0\u51fa\u4e86\u91cf\u5b50\u52a0\u5bc6\u5f39\u6027\u8bc4\u5206\uff08QERS\uff09\u6846\u67b6\uff0c\u53d1\u73b0MQTT\u5728PQC\u7ea6\u675f\u4e0b\u6548\u7387\u6700\u9ad8\uff0c\u800cHTTPS\u63d0\u4f9b\u6700\u9ad8\u5b89\u5168\u5f39\u6027\u4f46\u8d44\u6e90\u6d88\u8017\u66f4\u5927\u3002", "motivation": "\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\uff08PQC\uff09\u5e26\u6765\u4e86\u663e\u8457\u7684\u8ba1\u7b97\u548c\u901a\u4fe1\u5f00\u9500\uff0c\u8fd9\u5bf9\u8d44\u6e90\u53d7\u9650\u7684\u8ba1\u7b97\u673a\u7cfb\u7edf\u3001\u7269\u8054\u7f51\uff08IoT\uff09\u548c\u5de5\u4e1a\u7269\u8054\u7f51\uff08IIoT\uff09\u8bbe\u5907\u6784\u6210\u4e86\u6311\u6218\u3002\u9700\u8981\u8bc4\u4f30\u4e0d\u540c\u901a\u4fe1\u534f\u8bae\u5728PQC\u73af\u5883\u4e0b\u7684\u6027\u80fd\u8868\u73b0\uff0c\u4e3a\u534f\u8bae\u9009\u62e9\u548c\u8fc1\u79fb\u89c4\u5212\u63d0\u4f9b\u4f9d\u636e\u3002", "method": "\u4f7f\u7528ESP32-C6\u5ba2\u6237\u7aef\u548c\u57fa\u4e8eARM\u7684Raspberry Pi CM4\u670d\u52a1\u5668\uff0c\u5728\u73b0\u5b9e\u64cd\u4f5c\u6761\u4ef6\u4e0b\u6d4b\u91cfMQTT\u3001HTTP\u548cHTTPS\u534f\u8bae\u7684\u5ef6\u8fdf\u3001CPU\u5229\u7528\u7387\u3001RSSI\u3001\u80fd\u8017\u3001\u5bc6\u94a5\u5927\u5c0f\u548cTLS\u63e1\u624b\u5f00\u9500\u3002\u63d0\u51faQERS\u6846\u67b6\uff0c\u5c06\u8fd9\u4e9b\u5f02\u6784\u6307\u6807\u6574\u5408\u4e3a\u5f52\u4e00\u5316\u7684\u57fa\u7840\u8bc4\u5206\u3001\u8c03\u4f18\u8bc4\u5206\u548c\u878d\u5408\u8bc4\u5206\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728PQC\u7ea6\u675f\u4e0b\uff0cMQTT\u63d0\u4f9b\u4e86\u6700\u9ad8\u7684\u6548\u7387\uff0c\u800cHTTPS\u5b9e\u73b0\u4e86\u6700\u9ad8\u7684\u5b89\u5168\u52a0\u6743\u5f39\u6027\uff0c\u4f46\u4ee3\u4ef7\u662f\u589e\u52a0\u4e86\u5ef6\u8fdf\u548c\u8d44\u6e90\u6d88\u8017\u3002QERS\u6846\u67b6\u80fd\u591f\u7cfb\u7edf\u6bd4\u8f83\u534f\u8bae\u6548\u7387\u548c\u5b89\u5168\u6027\u5f39\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684QERS\u6846\u67b6\u652f\u6301\u4e3aPQC\u542f\u7528\u7684\u7269\u8054\u7f51\u548c\u5de5\u4e1a\u7269\u8054\u7f51\u90e8\u7f72\u63d0\u4f9b\u660e\u667a\u7684\u534f\u8bae\u9009\u62e9\u548c\u8fc1\u79fb\u89c4\u5212\uff0c\u5e2e\u52a9\u5728\u5b89\u5168\u6027\u548c\u6548\u7387\u4e4b\u95f4\u505a\u51fa\u5e73\u8861\u51b3\u7b56\u3002"}}
{"id": "2601.12560", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.12560", "abs": "https://arxiv.org/abs/2601.12560", "authors": ["Arunkumar V", "Gangadharan G. R.", "Rajkumar Buyya"], "title": "Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents", "comment": "28 pages, 4 figures, 5 tables", "summary": "Artificial Intelligence is moving from models that only generate text to Agentic AI, where systems behave as autonomous entities that can perceive, reason, plan, and act. Large Language Models (LLMs) are no longer used only as passive knowledge engines but as cognitive controllers that combine memory, tool use, and feedback from their environment to pursue extended goals. This shift already supports the automation of complex workflows in software engineering, scientific discovery, and web navigation, yet the variety of emerging designs, from simple single loop agents to hierarchical multi agent systems, makes the landscape hard to navigate. In this paper, we investigate architectures and propose a unified taxonomy that breaks agents into Perception, Brain, Planning, Action, Tool Use, and Collaboration. We use this lens to describe the move from linear reasoning procedures to native inference time reasoning models, and the transition from fixed API calls to open standards like the Model Context Protocol (MCP) and Native Computer Use. We also group the environments in which these agents operate, including digital operating systems, embodied robotics, and other specialized domains, and we review current evaluation practices. Finally, we highlight open challenges, such as hallucination in action, infinite loops, and prompt injection, and outline future research directions toward more robust and reliable autonomous systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u667a\u80fd\u4f53AI\u67b6\u6784\u5206\u7c7b\u6cd5\uff0c\u5c06\u667a\u80fd\u4f53\u5206\u89e3\u4e3a\u611f\u77e5\u3001\u5927\u8111\u3001\u89c4\u5212\u3001\u884c\u52a8\u3001\u5de5\u5177\u4f7f\u7528\u548c\u534f\u4f5c\u516d\u4e2a\u7ec4\u4ef6\uff0c\u5e76\u5206\u6790\u4e86\u4ece\u7ebf\u6027\u63a8\u7406\u5230\u539f\u751f\u63a8\u7406\u6a21\u578b\u7684\u8f6c\u53d8\uff0c\u4ee5\u53ca\u4ece\u56fa\u5b9aAPI\u5230\u5f00\u653e\u6807\u51c6\u7684\u6f14\u8fdb\u3002", "motivation": "\u968f\u7740AI\u4ece\u4ec5\u751f\u6210\u6587\u672c\u7684\u6a21\u578b\u8f6c\u5411\u5177\u6709\u81ea\u4e3b\u611f\u77e5\u3001\u63a8\u7406\u3001\u89c4\u5212\u548c\u884c\u52a8\u80fd\u529b\u7684\u667a\u80fd\u4f53AI\uff0c\u51fa\u73b0\u4e86\u4ece\u7b80\u5355\u5355\u5faa\u73af\u667a\u80fd\u4f53\u5230\u5206\u5c42\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5404\u79cd\u8bbe\u8ba1\uff0c\u4f7f\u5f97\u8fd9\u4e00\u9886\u57df\u96be\u4ee5\u5bfc\u822a\u3002\u9700\u8981\u7edf\u4e00\u7684\u5206\u7c7b\u6846\u67b6\u6765\u7406\u89e3\u8fd9\u4e00\u5feb\u901f\u53d1\u5c55\u7684\u9886\u57df\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684\u5206\u7c7b\u6cd5\uff0c\u5c06\u667a\u80fd\u4f53\u5206\u89e3\u4e3a\u516d\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u611f\u77e5\u3001\u5927\u8111\u3001\u89c4\u5212\u3001\u884c\u52a8\u3001\u5de5\u5177\u4f7f\u7528\u548c\u534f\u4f5c\u3002\u4f7f\u7528\u8fd9\u4e2a\u6846\u67b6\u5206\u6790\u667a\u80fd\u4f53\u67b6\u6784\u7684\u6f14\u8fdb\uff0c\u5305\u62ec\u4ece\u7ebf\u6027\u63a8\u7406\u8fc7\u7a0b\u5230\u539f\u751f\u63a8\u7406\u65f6\u95f4\u63a8\u7406\u6a21\u578b\u7684\u8f6c\u53d8\uff0c\u4ee5\u53ca\u4ece\u56fa\u5b9aAPI\u8c03\u7528\u5230\u5f00\u653e\u6807\u51c6\uff08\u5982\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u548c\u539f\u751f\u8ba1\u7b97\u673a\u4f7f\u7528\uff09\u7684\u8fc7\u6e21\u3002\u540c\u65f6\u5206\u7c7b\u667a\u80fd\u4f53\u8fd0\u884c\u7684\u73af\u5883\uff0c\u5e76\u56de\u987e\u5f53\u524d\u8bc4\u4f30\u5b9e\u8df5\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684\u667a\u80fd\u4f53AI\u67b6\u6784\u5206\u7c7b\u6846\u67b6\uff0c\u80fd\u591f\u6e05\u6670\u5730\u63cf\u8ff0\u548c\u5206\u6790\u5404\u79cd\u667a\u80fd\u4f53\u8bbe\u8ba1\u3002\u8bc6\u522b\u4e86\u667a\u80fd\u4f53\u53d1\u5c55\u7684\u5173\u952e\u8d8b\u52bf\uff1a\u4ece\u88ab\u52a8\u77e5\u8bc6\u5f15\u64ce\u5230\u4e3b\u52a8\u8ba4\u77e5\u63a7\u5236\u5668\u7684\u8f6c\u53d8\uff0c\u4ece\u7ebf\u6027\u63a8\u7406\u5230\u539f\u751f\u63a8\u7406\u6a21\u578b\u7684\u6f14\u8fdb\uff0c\u4ee5\u53ca\u4ece\u5c01\u95edAPI\u5230\u5f00\u653e\u6807\u51c6\u7684\u8fc7\u6e21\u3002\u540c\u65f6\u5206\u7c7b\u4e86\u667a\u80fd\u4f53\u8fd0\u884c\u73af\u5883\uff08\u6570\u5b57\u64cd\u4f5c\u7cfb\u7edf\u3001\u5177\u8eab\u673a\u5668\u4eba\u7b49\uff09\u5e76\u603b\u7ed3\u4e86\u5f53\u524d\u8bc4\u4f30\u65b9\u6cd5\u3002", "conclusion": "\u8bba\u6587\u4e3a\u7406\u89e3\u667a\u80fd\u4f53AI\u7684\u590d\u6742\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u5206\u7c7b\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u8be5\u9886\u57df\u4ece\u7b80\u5355\u6587\u672c\u751f\u6210\u5230\u590d\u6742\u81ea\u4e3b\u7cfb\u7edf\u7684\u6f14\u8fdb\u8def\u5f84\u3002\u540c\u65f6\u6307\u51fa\u4e86\u5f53\u524d\u9762\u4e34\u7684\u6311\u6218\uff08\u5982\u884c\u52a8\u5e7b\u89c9\u3001\u65e0\u9650\u5faa\u73af\u3001\u63d0\u793a\u6ce8\u5165\u7b49\uff09\uff0c\u5e76\u4e3a\u6784\u5efa\u66f4\u9c81\u68d2\u53ef\u9760\u7684\u81ea\u4e3b\u7cfb\u7edf\u6307\u660e\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2601.13425", "categories": ["cs.CR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.13425", "abs": "https://arxiv.org/abs/2601.13425", "authors": ["Gian Sebastian Mier Bello", "Alexander Martinez Mendez", "Carlos J. Barrios H.", "Robinson Rivas", "Luis A. N\u00fa\u00f1ez"], "title": "A Scientific Data Integrity system based on Blockchain", "comment": "Accepted and presented at CARLA 2025. To appear in Springer LNCS proceedings", "summary": "In most High Performance Computing (HPC) projects nowadays, there is a lot of data obtained from different sources, depending on the project's objectives. Some of that data is very huge in terms of size, so copying such data sometimes is an unrealistic goal. On the other hand, science requires data used for different purposes to remain unaltered, so different groups of researchers can reproduce results, discuss theories, and validate each other. In this paper, we present a novel approach to help research groups to validate data integrity on such distributed repositories using Blockchain. Originally developed for cryptographic currencies, Blockchain has demonstrated a versatile range of uses. Our proposal ensures 1) secure access to data management, 2) easy validation of data integrity, and 3) an easy way to add new records to the dataset with the same robust integrity policy. A prototype was developed and tested using a subset of a public dataset from a real scientific collaboration, the Latin American Giant Observatory (LAGO) Project.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u9a8c\u8bc1\u5206\u5e03\u5f0f\u79d1\u5b66\u6570\u636e\u5b58\u50a8\u5e93\u4e2d\u7684\u6570\u636e\u5b8c\u6574\u6027\uff0c\u786e\u4fdd\u6570\u636e\u4e0d\u88ab\u7be1\u6539\u4e14\u53ef\u590d\u73b0\u3002", "motivation": "\u9ad8\u6027\u80fd\u8ba1\u7b97\u9879\u76ee\u4e2d\u5b58\u5728\u5927\u91cf\u6765\u81ea\u4e0d\u540c\u6765\u6e90\u7684\u6570\u636e\uff0c\u5176\u4e2d\u4e00\u4e9b\u6570\u636e\u89c4\u6a21\u5de8\u5927\u96be\u4ee5\u590d\u5236\u3002\u79d1\u5b66\u7814\u7a76\u8981\u6c42\u6570\u636e\u4fdd\u6301\u539f\u59cb\u72b6\u6001\u4ee5\u4fbf\u4e0d\u540c\u7814\u7a76\u7ec4\u80fd\u591f\u590d\u73b0\u7ed3\u679c\u3001\u8ba8\u8bba\u7406\u8bba\u548c\u76f8\u4e92\u9a8c\u8bc1\u3002", "method": "\u91c7\u7528\u533a\u5757\u94fe\u6280\u672f\u5f00\u53d1\u4e86\u4e00\u4e2a\u539f\u578b\u7cfb\u7edf\uff0c\u5229\u7528\u533a\u5757\u94fe\u7684\u53bb\u4e2d\u5fc3\u5316\u3001\u4e0d\u53ef\u7be1\u6539\u7279\u6027\u6765\u786e\u4fdd\u6570\u636e\u5b8c\u6574\u6027\u3002\u7cfb\u7edf\u5b9e\u73b0\u4e86\u5b89\u5168\u7684\u6570\u636e\u8bbf\u95ee\u7ba1\u7406\u3001\u4fbf\u6377\u7684\u6570\u636e\u5b8c\u6574\u6027\u9a8c\u8bc1\u4ee5\u53ca\u6dfb\u52a0\u65b0\u8bb0\u5f55\u65f6\u4fdd\u6301\u76f8\u540c\u5b8c\u6574\u6027\u7b56\u7565\u7684\u529f\u80fd\u3002", "result": "\u539f\u578b\u7cfb\u7edf\u4f7f\u7528\u62c9\u4e01\u7f8e\u6d32\u5de8\u578b\u5929\u6587\u53f0\uff08LAGO\uff09\u9879\u76ee\u7684\u516c\u5171\u6570\u636e\u96c6\u5b50\u96c6\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u533a\u5757\u94fe\u6280\u672f\u80fd\u591f\u6709\u6548\u5e2e\u52a9\u7814\u7a76\u56e2\u961f\u9a8c\u8bc1\u5206\u5e03\u5f0f\u5b58\u50a8\u5e93\u4e2d\u7684\u6570\u636e\u5b8c\u6574\u6027\uff0c\u786e\u4fdd\u79d1\u5b66\u6570\u636e\u7684\u53ef\u9760\u6027\u548c\u53ef\u590d\u73b0\u6027\u3002"}}
{"id": "2601.12641", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12641", "abs": "https://arxiv.org/abs/2601.12641", "authors": ["Xiangyu Shi", "Junyang Ding", "Xu Zhao", "Sinong Zhan", "Payal Mohapatra", "Daniel Quispe", "Kojo Welbeck", "Jian Cao", "Wei Chen", "Ping Guo", "Qi Zhu"], "title": "STEP-LLM: Generating CAD STEP Models from Natural Language with Large Language Models", "comment": "Accepted to the Design, Automation & Test in Europe Conference (DATE) 2026", "summary": "Computer-aided design (CAD) is vital to modern manufacturing, yet model creation remains labor-intensive and expertise-heavy. To enable non-experts to translate intuitive design intent into manufacturable artifacts, recent large language models-based text-to-CAD efforts focus on command sequences or script-based formats like CadQuery. However, these formats are kernel-dependent and lack universality for manufacturing. In contrast, the Standard for the Exchange of Product Data (STEP, ISO 10303) file is a widely adopted, neutral boundary representation (B-rep) format directly compatible with manufacturing, but its graph-structured, cross-referenced nature poses unique challenges for auto-regressive LLMs. To address this, we curate a dataset of ~40K STEP-caption pairs and introduce novel preprocessing tailored for the graph-structured format of STEP, including a depth-first search-based reserialization that linearizes cross-references while preserving locality and chain-of-thought(CoT)-style structural annotations that guide global coherence. We integrate retrieval-augmented generation to ground predictions in relevant examples for supervised fine-tuning, and refine generation quality through reinforcement learning with a specific Chamfer Distance-based geometric reward. Experiments demonstrate consistent gains of our STEP-LLM in geometric fidelity over the Text2CAD baseline, with improvements arising from multiple stages of our framework: the RAG module substantially enhances completeness and renderability, the DFS-based reserialization strengthens overall accuracy, and the RL further reduces geometric discrepancy. Both metrics and visual comparisons confirm that STEP-LLM generates shapes with higher fidelity than Text2CAD. These results show the feasibility of LLM-driven STEP model generation from natural language, showing its potential to democratize CAD design for manufacturing.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86STEP-LLM\uff0c\u4e00\u4e2a\u4ece\u81ea\u7136\u8bed\u8a00\u751f\u6210STEP\u683c\u5f0fCAD\u6a21\u578b\u7684\u6846\u67b6\uff0c\u901a\u8fc7DFS\u91cd\u5e8f\u5217\u5316\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u5f3a\u5316\u5b66\u4e60\u7b49\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u51e0\u4f55\u4fdd\u771f\u5ea6\u3002", "motivation": "CAD\u6a21\u578b\u521b\u5efa\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\u4e14\u8017\u65f6\uff0c\u73b0\u6709\u6587\u672c\u5230CAD\u65b9\u6cd5\u4f7f\u7528\u547d\u4ee4\u5e8f\u5217\u6216\u811a\u672c\u683c\u5f0f\uff0c\u4f46\u8fd9\u4e9b\u683c\u5f0f\u4f9d\u8d56\u4e8e\u7279\u5b9a\u5185\u6838\u4e14\u7f3a\u4e4f\u5236\u9020\u901a\u7528\u6027\u3002STEP\u6587\u4ef6\u4f5c\u4e3a\u5e7f\u6cdb\u91c7\u7528\u7684\u4e2d\u6027\u8fb9\u754c\u8868\u793a\u683c\u5f0f\u76f4\u63a5\u517c\u5bb9\u5236\u9020\uff0c\u4f46\u5176\u56fe\u7ed3\u6784\u7279\u6027\u5bf9\u81ea\u56de\u5f52LLM\u6784\u6210\u6311\u6218\u3002", "method": "1) \u6784\u5efa\u7ea640K STEP-\u63cf\u8ff0\u5bf9\u6570\u636e\u96c6\uff1b2) \u9488\u5bf9STEP\u56fe\u7ed3\u6784\u683c\u5f0f\u7684\u9884\u5904\u7406\uff0c\u5305\u62ec\u57fa\u4e8e\u6df1\u5ea6\u4f18\u5148\u641c\u7d22\u7684\u91cd\u5e8f\u5217\u5316\u4ee5\u7ebf\u6027\u5316\u4ea4\u53c9\u5f15\u7528\uff1b3) \u94fe\u5f0f\u601d\u7ef4\u98ce\u683c\u7684\u7ed3\u6784\u6ce8\u91ca\u6307\u5bfc\u5168\u5c40\u4e00\u81f4\u6027\uff1b4) \u96c6\u6210\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\uff1b5) \u901a\u8fc7\u57fa\u4e8eChamfer\u8ddd\u79bb\u7684\u51e0\u4f55\u5956\u52b1\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u751f\u6210\u8d28\u91cf\u3002", "result": "STEP-LLM\u5728\u51e0\u4f55\u4fdd\u771f\u5ea6\u4e0a\u6301\u7eed\u4f18\u4e8eText2CAD\u57fa\u7ebf\u3002RAG\u6a21\u5757\u663e\u8457\u63d0\u5347\u5b8c\u6574\u6027\u548c\u53ef\u6e32\u67d3\u6027\uff0cDFS\u91cd\u5e8f\u5217\u5316\u589e\u5f3a\u6574\u4f53\u51c6\u786e\u6027\uff0cRL\u8fdb\u4e00\u6b65\u51cf\u5c11\u51e0\u4f55\u5dee\u5f02\u3002\u6307\u6807\u548c\u89c6\u89c9\u6bd4\u8f83\u90fd\u8bc1\u5b9eSTEP-LLM\u751f\u6210\u5f62\u72b6\u7684\u4fdd\u771f\u5ea6\u66f4\u9ad8\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86LLM\u9a71\u52a8\u4ece\u81ea\u7136\u8bed\u8a00\u751f\u6210STEP\u6a21\u578b\u7684\u53ef\u884c\u6027\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5236\u9020\u9886\u57df\u6c11\u4e3b\u5316CAD\u8bbe\u8ba1\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.13772", "categories": ["cs.SE", "cs.DC", "cs.SI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13772", "abs": "https://arxiv.org/abs/2601.13772", "authors": ["Matteo Vaccargiu", "Azmat Ullah", "Pierluigi Gallo"], "title": "A Blockchain-Oriented Software Engineering Architecture for Carbon Credit Certification Systems", "comment": "2026 IEEE International Conference on Software Analysis, Evolution and Reengineering - Companion (SANER-C) 9th International Workshop on Blockchain Oriented Software Engineering March 17-20, 2026 Limassol, Cyprus", "summary": "Carbon credit systems have emerged as a policy tool to incentivize emission reductions and support the transition to clean energy. Reliable carbon-credit certification depends on mechanisms that connect actual, measured renewable-energy production to verifiable emission-reduction records. Although blockchain and IoT technologies have been applied to emission monitoring and trading, existing work offers limited support for certification processes, particularly for small and medium-scale renewable installations. This paper introduces a blockchain-based carbon-credit certification architecture, demonstrated through a 100 kWp photovoltaic case study, that integrates real-time IoT data collection, edge-level aggregation, and secure on-chain storage on a permissioned blockchain with smart contracts. Unlike approaches focused on trading mechanisms, the proposed system aligns with European legislation and voluntary carbon-market standards, clarifying the practical requirements and constraints that apply to photovoltaic operators. The resulting architecture provides a structured pathway for generating verifiable carbon-credit records and supporting third-party verification.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u533a\u5757\u94fe\u548c\u7269\u8054\u7f51\u7684\u78b3\u4fe1\u7528\u8ba4\u8bc1\u67b6\u6784\uff0c\u901a\u8fc7100kWp\u5149\u4f0f\u6848\u4f8b\u9a8c\u8bc1\uff0c\u6574\u5408\u5b9e\u65f6\u6570\u636e\u6536\u96c6\u3001\u8fb9\u7f18\u805a\u5408\u548c\u94fe\u4e0a\u5b58\u50a8\uff0c\u7b26\u5408\u6b27\u6d32\u6cd5\u89c4\u548c\u81ea\u613f\u78b3\u5e02\u573a\u6807\u51c6", "motivation": "\u73b0\u6709\u533a\u5757\u94fe\u548c\u7269\u8054\u7f51\u6280\u672f\u5728\u6392\u653e\u76d1\u6d4b\u548c\u4ea4\u6613\u4e2d\u7684\u5e94\u7528\u6709\u9650\uff0c\u7279\u522b\u662f\u5bf9\u4e2d\u5c0f\u578b\u53ef\u518d\u751f\u80fd\u6e90\u8bbe\u65bd\u7684\u8ba4\u8bc1\u8fc7\u7a0b\u652f\u6301\u4e0d\u8db3\uff0c\u9700\u8981\u5efa\u7acb\u53ef\u9760\u7684\u78b3\u4fe1\u7528\u8ba4\u8bc1\u673a\u5236", "method": "\u8bbe\u8ba1\u57fa\u4e8e\u8bb8\u53ef\u533a\u5757\u94fe\u7684\u78b3\u4fe1\u7528\u8ba4\u8bc1\u67b6\u6784\uff0c\u6574\u5408\u5b9e\u65f6\u7269\u8054\u7f51\u6570\u636e\u6536\u96c6\u3001\u8fb9\u7f18\u7ea7\u6570\u636e\u805a\u5408\u3001\u5b89\u5168\u7684\u94fe\u4e0a\u5b58\u50a8\u548c\u667a\u80fd\u5408\u7ea6\uff0c\u901a\u8fc7100kWp\u5149\u4f0f\u6848\u4f8b\u8fdb\u884c\u9a8c\u8bc1", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7ed3\u6784\u5316\u7684\u78b3\u4fe1\u7528\u8bb0\u5f55\u751f\u6210\u8def\u5f84\uff0c\u652f\u6301\u7b2c\u4e09\u65b9\u9a8c\u8bc1\uff0c\u660e\u786e\u4e86\u5149\u4f0f\u8fd0\u8425\u5546\u7684\u5b9e\u9645\u8981\u6c42\u548c\u7ea6\u675f\u6761\u4ef6\uff0c\u4e0e\u73b0\u6709\u4e13\u6ce8\u4e8e\u4ea4\u6613\u673a\u5236\u7684\u65b9\u6cd5\u4e0d\u540c", "conclusion": "\u8be5\u67b6\u6784\u4e3a\u4e2d\u5c0f\u578b\u53ef\u518d\u751f\u80fd\u6e90\u8bbe\u65bd\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u78b3\u4fe1\u7528\u8ba4\u8bc1\u89e3\u51b3\u65b9\u6848\uff0c\u7b26\u5408\u6cd5\u89c4\u6807\u51c6\uff0c\u652f\u6301\u53ef\u9a8c\u8bc1\u7684\u51cf\u6392\u8bb0\u5f55\u751f\u6210\u548c\u7b2c\u4e09\u65b9\u9a8c\u8bc1"}}
{"id": "2601.13515", "categories": ["cs.CR", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.13515", "abs": "https://arxiv.org/abs/2601.13515", "authors": ["Hanlin Zhou", "Huah Yong Chan", "Jingfei Ni", "Mengchun Wu", "Qing Deng"], "title": "Automatic Adjustment of HPA Parameters and Attack Prevention in Kubernetes Using Random Forests", "comment": null, "summary": "In this paper, HTTP status codes are used as custom metrics within the HPA as the experimental scenario. By integrating the Random Forest classification algorithm from machine learning, attacks are assessed and predicted, dynamically adjusting the maximum pod parameter in the HPA to manage attack traffic. This approach enables the adjustment of HPA parameters using machine learning scripts in targeted attack scenarios while effectively managing attack traffic. All access from attacking IPs is redirected to honeypot pods, achieving a lower incidence of 5XX status codes through HPA pod adjustments under high load conditions. This method also ensures effective isolation of attack traffic, preventing excessive HPA expansion due to attacks. Additionally, experiments conducted under various conditions demonstrate the importance of setting appropriate thresholds for HPA adjustments.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eHTTP\u72b6\u6001\u7801\u548c\u968f\u673a\u68ee\u6797\u7b97\u6cd5\u7684HPA\u52a8\u6001\u8c03\u6574\u65b9\u6cd5\uff0c\u7528\u4e8e\u653b\u51fb\u6d41\u91cf\u7ba1\u7406\u548c\u871c\u7f50\u91cd\u5b9a\u5411", "motivation": "\u5728\u4e91\u539f\u751f\u73af\u5883\u4e2d\uff0c\u4f20\u7edf\u7684HPA\uff08\u6c34\u5e73Pod\u81ea\u52a8\u6269\u5c55\uff09\u5728\u9762\u5bf9\u653b\u51fb\u6d41\u91cf\u65f6\u5bb9\u6613\u8fc7\u5ea6\u6269\u5c55\u8d44\u6e90\uff0c\u5bfc\u81f4\u8d44\u6e90\u6d6a\u8d39\u548c\u6210\u672c\u589e\u52a0\u3002\u9700\u8981\u4e00\u79cd\u667a\u80fd\u7684\u65b9\u6cd5\u6765\u533a\u5206\u6b63\u5e38\u6d41\u91cf\u548c\u653b\u51fb\u6d41\u91cf\uff0c\u5e76\u52a8\u6001\u8c03\u6574HPA\u53c2\u6570\u4ee5\u6709\u6548\u7ba1\u7406\u653b\u51fb", "method": "1. \u4f7f\u7528HTTP\u72b6\u6001\u7801\u4f5c\u4e3aHPA\u4e2d\u7684\u81ea\u5b9a\u4e49\u6307\u6807\n2. \u96c6\u6210\u968f\u673a\u68ee\u6797\u5206\u7c7b\u7b97\u6cd5\u8bc4\u4f30\u548c\u9884\u6d4b\u653b\u51fb\n3. \u52a8\u6001\u8c03\u6574HPA\u7684\u6700\u5927Pod\u53c2\u6570\u6765\u7ba1\u7406\u653b\u51fb\u6d41\u91cf\n4. \u5c06\u6240\u6709\u653b\u51fbIP\u7684\u8bbf\u95ee\u91cd\u5b9a\u5411\u5230\u871c\u7f50Pod\n5. \u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1", "result": "1. \u5728\u9ad8\u8d1f\u8f7d\u6761\u4ef6\u4e0b\u901a\u8fc7HPA Pod\u8c03\u6574\u964d\u4f4e\u4e865XX\u72b6\u6001\u7801\u7684\u53d1\u751f\u7387\n2. \u6709\u6548\u9694\u79bb\u4e86\u653b\u51fb\u6d41\u91cf\uff0c\u9632\u6b62\u56e0\u653b\u51fb\u5bfc\u81f4\u7684HPA\u8fc7\u5ea6\u6269\u5c55\n3. \u5b9e\u9a8c\u8868\u660e\u8bbe\u7f6e\u9002\u5f53\u7684HPA\u8c03\u6574\u9608\u503c\u81f3\u5173\u91cd\u8981", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u667a\u80fd\u8bc6\u522b\u653b\u51fb\u6d41\u91cf\uff0c\u7ed3\u5408\u871c\u7f50\u6280\u672f\u548c\u52a8\u6001HPA\u53c2\u6570\u8c03\u6574\uff0c\u5b9e\u73b0\u4e86\u5bf9\u653b\u51fb\u6d41\u91cf\u7684\u6709\u6548\u7ba1\u7406\uff0c\u540c\u65f6\u907f\u514d\u4e86\u8d44\u6e90\u6d6a\u8d39\u3002\u9002\u5f53\u7684\u9608\u503c\u8bbe\u7f6e\u662f\u7cfb\u7edf\u6709\u6548\u8fd0\u884c\u7684\u5173\u952e\u56e0\u7d20"}}
{"id": "2601.13528", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.13528", "abs": "https://arxiv.org/abs/2601.13528", "authors": ["Jackson Kaunismaa", "Avery Griffin", "John Hughes", "Christina Q. Knight", "Mrinank Sharma", "Erik Jones"], "title": "Eliciting Harmful Capabilities by Fine-Tuning On Safeguarded Outputs", "comment": null, "summary": "Model developers implement safeguards in frontier models to prevent misuse, for example, by employing classifiers to filter dangerous outputs. In this work, we demonstrate that even robustly safeguarded models can be used to elicit harmful capabilities in open-source models through elicitation attacks. Our elicitation attacks consist of three stages: (i) constructing prompts in adjacent domains to a target harmful task that do not request dangerous information; (ii) obtaining responses to these prompts from safeguarded frontier models; (iii) fine-tuning open-source models on these prompt-output pairs. Since the requested prompts cannot be used to directly cause harm, they are not refused by frontier model safeguards. We evaluate these elicitation attacks within the domain of hazardous chemical synthesis and processing, and demonstrate that our attacks recover approximately 40% of the capability gap between the base open-source model and an unrestricted frontier model. We then show that the efficacy of elicitation attacks scales with the capability of the frontier model and the amount of generated fine-tuning data. Our work demonstrates the challenge of mitigating ecosystem level risks with output-level safeguards.", "AI": {"tldr": "\u8bba\u6587\u5c55\u793a\u4e86\u4e00\u79cd\u9488\u5bf9\u524d\u6cbf\u6a21\u578b\u5b89\u5168\u9632\u62a4\u7684\u89c4\u907f\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u9020\u76f8\u90bb\u9886\u57df\u7684\u65e0\u5bb3\u63d0\u793a\u83b7\u53d6\u54cd\u5e94\uff0c\u7136\u540e\u5fae\u8c03\u5f00\u6e90\u6a21\u578b\u6765\u6062\u590d\u6709\u5bb3\u80fd\u529b\uff0c\u5728\u5371\u9669\u5316\u5b66\u54c1\u5408\u6210\u9886\u57df\u6062\u590d\u4e86\u7ea640%\u7684\u80fd\u529b\u5dee\u8ddd\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7d22\u524d\u6cbf\u6a21\u578b\u5b89\u5168\u9632\u62a4\u7684\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u8f93\u51fa\u7ea7\u9632\u62a4\u63aa\u65bd\u5728\u751f\u6001\u7cfb\u7edf\u5c42\u9762\u53ef\u80fd\u5b58\u5728\u7684\u98ce\u9669\u3002\u5c3d\u7ba1\u6a21\u578b\u5f00\u53d1\u8005\u5b9e\u65bd\u4e86\u9632\u62a4\u63aa\u65bd\uff08\u5982\u5206\u7c7b\u5668\u8fc7\u6ee4\u5371\u9669\u8f93\u51fa\uff09\uff0c\u4f46\u653b\u51fb\u8005\u53ef\u80fd\u901a\u8fc7\u95f4\u63a5\u65b9\u5f0f\u7ed5\u8fc7\u8fd9\u4e9b\u9632\u62a4\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e09\u9636\u6bb5\u7684\u8bf1\u5bfc\u653b\u51fb\u65b9\u6cd5\uff1a1\uff09\u6784\u9020\u76ee\u6807\u6709\u5bb3\u4efb\u52a1\u76f8\u90bb\u9886\u57df\u7684\u63d0\u793a\uff0c\u8fd9\u4e9b\u63d0\u793a\u4e0d\u76f4\u63a5\u8bf7\u6c42\u5371\u9669\u4fe1\u606f\uff1b2\uff09\u4ece\u53d7\u4fdd\u62a4\u7684\u524d\u6cbf\u6a21\u578b\u83b7\u53d6\u8fd9\u4e9b\u63d0\u793a\u7684\u54cd\u5e94\uff1b3\uff09\u4f7f\u7528\u8fd9\u4e9b\u63d0\u793a-\u54cd\u5e94\u5bf9\u5fae\u8c03\u5f00\u6e90\u6a21\u578b\u3002\u7531\u4e8e\u8bf7\u6c42\u7684\u63d0\u793a\u4e0d\u80fd\u76f4\u63a5\u9020\u6210\u4f24\u5bb3\uff0c\u56e0\u6b64\u4e0d\u4f1a\u88ab\u524d\u6cbf\u6a21\u578b\u7684\u9632\u62a4\u673a\u5236\u62d2\u7edd\u3002", "result": "\u5728\u5371\u9669\u5316\u5b66\u54c1\u5408\u6210\u548c\u5904\u7406\u9886\u57df\u8fdb\u884c\u8bc4\u4f30\uff0c\u653b\u51fb\u6062\u590d\u4e86\u5f00\u6e90\u6a21\u578b\u4e0e\u65e0\u9650\u5236\u524d\u6cbf\u6a21\u578b\u4e4b\u95f4\u7ea640%\u7684\u80fd\u529b\u5dee\u8ddd\u3002\u653b\u51fb\u6548\u679c\u968f\u7740\u524d\u6cbf\u6a21\u578b\u80fd\u529b\u548c\u751f\u6210\u7684\u5fae\u8c03\u6570\u636e\u91cf\u7684\u589e\u52a0\u800c\u63d0\u5347\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u4ec5\u4f9d\u9760\u8f93\u51fa\u7ea7\u9632\u62a4\u63aa\u65bd\u96be\u4ee5\u7f13\u89e3\u751f\u6001\u7cfb\u7edf\u5c42\u9762\u7684\u98ce\u9669\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u5b89\u5168\u9632\u62a4\u7b56\u7565\u6765\u5e94\u5bf9\u8fd9\u79cd\u95f4\u63a5\u653b\u51fb\u65b9\u5f0f\u3002"}}
{"id": "2601.13943", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.13943", "abs": "https://arxiv.org/abs/2601.13943", "authors": ["Zhiyuan Peng", "Xin Yin", "Pu Zhao", "Fangkai Yang", "Lu Wang", "Ran Jia", "Xu Chen", "Qingwei Lin", "Saravan Rajmohan", "Dongmei Zhang"], "title": "RepoGenesis: Benchmarking End-to-End Microservice Generation from Readme to Repository", "comment": null, "summary": "Large language models and agents have achieved remarkable progress in code generation. However, existing benchmarks focus on isolated function/class-level generation (e.g., ClassEval) or modifications to existing codebases (e.g., SWE-Bench), neglecting complete microservice repository generation that reflects real-world 0-to-1 development workflows. To bridge this gap, we introduce RepoGenesis, the first multilingual benchmark for repository-level end-to-end web microservice generation, comprising 106 repositories (60 Python, 46 Java) across 18 domains and 11 frameworks, with 1,258 API endpoints and 2,335 test cases verified through a \"review-rebuttal\" quality assurance process. We evaluate open-source agents (e.g., DeepCode) and commercial IDEs (e.g., Cursor) using Pass@1, API Coverage (AC), and Deployment Success Rate (DSR). Results reveal that despite high AC (up to 73.91%) and DSR (up to 100%), the best-performing system achieves only 23.67% Pass@1 on Python and 21.45% on Java, exposing deficiencies in architectural coherence, dependency management, and cross-file consistency. Notably, GenesisAgent-8B, fine-tuned on RepoGenesis (train), achieves performance comparable to GPT-5 mini, demonstrating the quality of RepoGenesis for advancing microservice generation. We release our benchmark at https://github.com/pzy2000/RepoGenesis.", "AI": {"tldr": "RepoGenesis\u662f\u9996\u4e2a\u591a\u8bed\u8a00\u4ed3\u5e93\u7ea7\u7aef\u5230\u7aefWeb\u5fae\u670d\u52a1\u751f\u6210\u57fa\u51c6\uff0c\u5305\u542b106\u4e2a\u4ed3\u5e93\u548c1258\u4e2aAPI\u7aef\u70b9\uff0c\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\u73b0\u6709\u7cfb\u7edf\u5728\u67b6\u6784\u4e00\u81f4\u6027\u548c\u8de8\u6587\u4ef6\u4e00\u81f4\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u5b64\u7acb\u7684\u51fd\u6570/\u7c7b\u7ea7\u4ee3\u7801\u751f\u6210\u6216\u73b0\u6709\u4ee3\u7801\u5e93\u7684\u4fee\u6539\uff0c\u7f3a\u4e4f\u53cd\u6620\u771f\u5b9e\u4e16\u754c0\u52301\u5f00\u53d1\u6d41\u7a0b\u7684\u5b8c\u6574\u5fae\u670d\u52a1\u4ed3\u5e93\u751f\u6210\u57fa\u51c6\u3002", "method": "\u521b\u5efa\u5305\u542b106\u4e2a\u4ed3\u5e93\uff0860\u4e2aPython\uff0c46\u4e2aJava\uff09\u7684\u591a\u8bed\u8a00\u57fa\u51c6\uff0c\u6db5\u76d618\u4e2a\u9886\u57df\u548c11\u4e2a\u6846\u67b6\uff0c\u901a\u8fc7\"\u8bc4\u5ba1-\u53cd\u9a73\"\u8d28\u91cf\u4fdd\u8bc1\u6d41\u7a0b\u9a8c\u8bc11258\u4e2aAPI\u7aef\u70b9\u548c2335\u4e2a\u6d4b\u8bd5\u7528\u4f8b\u3002", "result": "\u6700\u4f73\u7cfb\u7edf\u5728Python\u548cJava\u4e0a\u5206\u522b\u4ec5\u8fbe\u523023.67%\u548c21.45%\u7684Pass@1\uff0c\u5c3d\u7ba1API\u8986\u76d6\u7387\u9ad8\u8fbe73.91%\uff0c\u90e8\u7f72\u6210\u529f\u7387\u9ad8\u8fbe100%\uff0c\u4f46\u5728\u67b6\u6784\u4e00\u81f4\u6027\u3001\u4f9d\u8d56\u7ba1\u7406\u548c\u8de8\u6587\u4ef6\u4e00\u81f4\u6027\u65b9\u9762\u5b58\u5728\u7f3a\u9677\u3002", "conclusion": "RepoGenesis\u57fa\u51c6\u63ed\u793a\u4e86\u5f53\u524d\u5fae\u670d\u52a1\u751f\u6210\u7cfb\u7edf\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u7528\u4e8e\u6539\u8fdb\u5fae\u670d\u52a1\u751f\u6210\u7684\u6f5c\u529b\uff0c\u7ecf\u8fc7\u5fae\u8c03\u7684GenesisAgent-8B\u6027\u80fd\u53ef\u4e0eGPT-5 mini\u76f8\u5ab2\u7f8e\u3002"}}
{"id": "2601.13607", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.13607", "abs": "https://arxiv.org/abs/2601.13607", "authors": ["Ruihan Hu", "Yu-Ming Shang", "Wei Luo", "Ye Tao", "Xi Zhang"], "title": "When Reasoning Leaks Membership: Membership Inference Attack on Black-box Large Reasoning Models", "comment": null, "summary": "Large Reasoning Models (LRMs) have rapidly gained prominence for their strong performance in solving complex tasks. Many modern black-box LRMs expose the intermediate reasoning traces through APIs to improve transparency (e.g., Gemini-2.5 and Claude-sonnet). Despite their benefits, we find that these traces can leak membership signals, creating a new privacy threat even without access to token logits used in prior attacks. In this work, we initiate the first systematic exploration of Membership Inference Attacks (MIAs) on black-box LRMs. Our preliminary analysis shows that LRMs produce confident, recall-like reasoning traces on familiar training member samples but more hesitant, inference-like reasoning traces on non-members. The representations of these traces are continuously distributed in the semantic latent space, spanning from familiar to unfamiliar samples. Building on this observation, we propose BlackSpectrum, the first membership inference attack framework targeting the black-box LRMs. The key idea is to construct a recall-inference axis in the semantic latent space, based on representations derived from the exposed traces. By locating where a query sample falls along this axis, the attacker can obtain a membership score and predict how likely it is to be a member of the training data. Additionally, to address the limitations of outdated datasets unsuited to modern LRMs, we provide two new datasets to support future research, arXivReasoning and BookReasoning. Empirically, exposing reasoning traces significantly increases the vulnerability of LRMs to membership inference attacks, leading to large gains in attack performance. Our findings highlight the need for LRM companies to balance transparency in intermediate reasoning traces with privacy preservation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u63a2\u7d22\u4e86\u9488\u5bf9\u9ed1\u76d2\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\uff0c\u53d1\u73b0\u6a21\u578b\u66b4\u9732\u7684\u4e2d\u95f4\u63a8\u7406\u8f68\u8ff9\u4f1a\u6cc4\u9732\u6210\u5458\u4fe1\u606f\uff0c\u63d0\u51fa\u4e86BlackSpectrum\u653b\u51fb\u6846\u67b6\uff0c\u5e76\u521b\u5efa\u4e86\u4e24\u4e2a\u65b0\u6570\u636e\u96c6\u652f\u6301\u672a\u6765\u7814\u7a76\u3002", "motivation": "\u73b0\u4ee3\u9ed1\u76d2\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08\u5982Gemini-2.5\u548cClaude-sonnet\uff09\u901a\u8fc7API\u66b4\u9732\u4e2d\u95f4\u63a8\u7406\u8f68\u8ff9\u4ee5\u63d0\u9ad8\u900f\u660e\u5ea6\uff0c\u4f46\u8fd9\u4e9b\u8f68\u8ff9\u53ef\u80fd\u6cc4\u9732\u6210\u5458\u4fe1\u606f\uff0c\u5373\u4f7f\u6ca1\u6709\u8bbf\u95ee\u5148\u524d\u653b\u51fb\u6240\u9700\u7684token logits\u3002\u4f5c\u8005\u53d1\u73b0\u8fd9\u662f\u4e00\u4e2a\u65b0\u7684\u9690\u79c1\u5a01\u80c1\uff0c\u9700\u8981\u8fdb\u884c\u7cfb\u7edf\u6027\u7814\u7a76\u3002", "method": "\u4f5c\u8005\u9996\u5148\u5206\u6790\u53d1\u73b0LRMs\u5bf9\u719f\u6089\u7684\u8bad\u7ec3\u6210\u5458\u6837\u672c\u4f1a\u4ea7\u751f\u81ea\u4fe1\u3001\u7c7b\u4f3c\u56de\u5fc6\u7684\u63a8\u7406\u8f68\u8ff9\uff0c\u800c\u5bf9\u975e\u6210\u5458\u6837\u672c\u5219\u4ea7\u751f\u72b9\u8c6b\u3001\u7c7b\u4f3c\u63a8\u7406\u7684\u8f68\u8ff9\u3002\u57fa\u4e8e\u6b64\u89c2\u5bdf\uff0c\u63d0\u51fa\u4e86BlackSpectrum\u653b\u51fb\u6846\u67b6\uff0c\u6838\u5fc3\u601d\u60f3\u662f\u5728\u8bed\u4e49\u6f5c\u5728\u7a7a\u95f4\u4e2d\u6784\u5efa\"\u56de\u5fc6-\u63a8\u7406\u8f74\"\uff0c\u6839\u636e\u66b4\u9732\u7684\u63a8\u7406\u8f68\u8ff9\u8868\u793a\u6765\u786e\u5b9a\u67e5\u8be2\u6837\u672c\u5728\u8be5\u8f74\u4e0a\u7684\u4f4d\u7f6e\uff0c\u4ece\u800c\u83b7\u5f97\u6210\u5458\u5206\u6570\u3002\u6b64\u5916\uff0c\u8fd8\u521b\u5efa\u4e86arXivReasoning\u548cBookReasoning\u4e24\u4e2a\u65b0\u6570\u636e\u96c6\u4ee5\u652f\u6301\u73b0\u4ee3LRMs\u7684\u7814\u7a76\u3002", "result": "\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0c\u66b4\u9732\u63a8\u7406\u8f68\u8ff9\u663e\u8457\u589e\u52a0\u4e86LRMs\u5bf9\u6210\u5458\u63a8\u7406\u653b\u51fb\u7684\u8106\u5f31\u6027\uff0c\u5bfc\u81f4\u653b\u51fb\u6027\u80fd\u5927\u5e45\u63d0\u5347\u3002\u8fd9\u8868\u660eLRM\u516c\u53f8\u9700\u8981\u5728\u4e2d\u95f4\u63a8\u7406\u8f68\u8ff9\u7684\u900f\u660e\u5ea6\u548c\u9690\u79c1\u4fdd\u62a4\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002", "conclusion": "\u8be5\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u63a2\u7d22\u4e86\u9488\u5bf9\u9ed1\u76d2LRMs\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\uff0c\u63ed\u793a\u4e86\u66b4\u9732\u63a8\u7406\u8f68\u8ff9\u5e26\u6765\u7684\u9690\u79c1\u98ce\u9669\uff0c\u63d0\u51fa\u4e86\u6709\u6548\u7684\u653b\u51fb\u6846\u67b6\uff0c\u5e76\u63d0\u4f9b\u4e86\u65b0\u7684\u6570\u636e\u96c6\u652f\u6301\u672a\u6765\u7814\u7a76\uff0c\u5f3a\u8c03\u4e86\u5728\u6a21\u578b\u900f\u660e\u5ea6\u548c\u9690\u79c1\u4fdd\u62a4\u4e4b\u95f4\u5e73\u8861\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.13996", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.13996", "abs": "https://arxiv.org/abs/2601.13996", "authors": ["Rui Abreu", "Shaukat Ali", "Paolo Arcaini", "Jose Campos", "Michael Felderer", "Claude Gravel", "Fuyuki Ishikawa", "Stefan Klikovits", "Andriy Miranskyy", "Anila Mjeda", "Mohammad Reza Mousavi", "Masaomi Yamaguchi", "Lei Zhang", "Jianjun Zhao"], "title": "Software Testing in the Quantum World", "comment": null, "summary": "Quantum computing offers significant speedups for simulating physical, chemical, and biological systems, and for optimization and machine learning. As quantum software grows in complexity, the classical simulation of quantum computers, which has long been essential for quality assurance, becomes infeasible. This shift requires new quality-assurance methods that operate directly on real quantum computers. This paper presents the key challenges in testing large-scale quantum software and offers software engineering perspectives for addressing them.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u968f\u7740\u91cf\u5b50\u8f6f\u4ef6\u590d\u6742\u6027\u589e\u52a0\uff0c\u4f20\u7edf\u91cf\u5b50\u8ba1\u7b97\u673a\u6a21\u62df\u53d8\u5f97\u4e0d\u53ef\u884c\uff0c\u9700\u8981\u76f4\u63a5\u5728\u771f\u5b9e\u91cf\u5b50\u8ba1\u7b97\u673a\u4e0a\u8fdb\u884c\u8d28\u91cf\u4fdd\u8bc1\u7684\u65b0\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u6d4b\u8bd5\u5927\u89c4\u6a21\u91cf\u5b50\u8f6f\u4ef6\u7684\u5173\u952e\u6311\u6218\u548c\u8f6f\u4ef6\u5de5\u7a0b\u89c6\u89d2\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u5728\u6a21\u62df\u7269\u7406\u3001\u5316\u5b66\u3001\u751f\u7269\u7cfb\u7edf\u4ee5\u53ca\u4f18\u5316\u548c\u673a\u5668\u5b66\u4e60\u65b9\u9762\u5177\u6709\u663e\u8457\u52a0\u901f\u4f18\u52bf\u3002\u968f\u7740\u91cf\u5b50\u8f6f\u4ef6\u590d\u6742\u6027\u589e\u52a0\uff0c\u957f\u671f\u4ee5\u6765\u7528\u4e8e\u8d28\u91cf\u4fdd\u8bc1\u7684\u7ecf\u5178\u91cf\u5b50\u8ba1\u7b97\u673a\u6a21\u62df\u53d8\u5f97\u4e0d\u53ef\u884c\uff0c\u9700\u8981\u76f4\u63a5\u5728\u771f\u5b9e\u91cf\u5b50\u8ba1\u7b97\u673a\u4e0a\u64cd\u4f5c\u7684\u65b0\u8d28\u91cf\u4fdd\u8bc1\u65b9\u6cd5\u3002", "method": "\u8be5\u8bba\u6587\u4ece\u8f6f\u4ef6\u5de5\u7a0b\u89d2\u5ea6\u51fa\u53d1\uff0c\u5206\u6790\u6d4b\u8bd5\u5927\u89c4\u6a21\u91cf\u5b50\u8f6f\u4ef6\u7684\u5173\u952e\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u76f8\u5e94\u7684\u89e3\u51b3\u65b9\u6848\u89c6\u89d2\u3002", "result": "\u8bba\u6587\u8bc6\u522b\u4e86\u6d4b\u8bd5\u5927\u89c4\u6a21\u91cf\u5b50\u8f6f\u4ef6\u7684\u4e3b\u8981\u6311\u6218\uff0c\u5e76\u63d0\u4f9b\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u89c6\u89d2\u7684\u6846\u67b6\u6765\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002", "conclusion": "\u968f\u7740\u91cf\u5b50\u8f6f\u4ef6\u590d\u6742\u6027\u7684\u589e\u957f\uff0c\u9700\u8981\u5f00\u53d1\u76f4\u63a5\u5728\u771f\u5b9e\u91cf\u5b50\u8ba1\u7b97\u673a\u4e0a\u64cd\u4f5c\u7684\u65b0\u8d28\u91cf\u4fdd\u8bc1\u65b9\u6cd5\uff0c\u8f6f\u4ef6\u5de5\u7a0b\u89c6\u89d2\u4e3a\u89e3\u51b3\u5927\u89c4\u6a21\u91cf\u5b50\u8f6f\u4ef6\u6d4b\u8bd5\u6311\u6218\u63d0\u4f9b\u4e86\u91cd\u8981\u6846\u67b6\u3002"}}
{"id": "2601.12720", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12720", "abs": "https://arxiv.org/abs/2601.12720", "authors": ["Hanbin Wang", "Jingwei Song", "Jinpeng Li", "Qi Zhu", "Fei Mi", "Ganqu Cui", "Yasheng Wang", "Lifeng Shang"], "title": "Teaching Large Reasoning Models Effective Reflection", "comment": "14 pages (including appendix), 5 figures", "summary": "Large Reasoning Models (LRMs) have recently shown impressive performance on complex reasoning tasks, often by engaging in self-reflective behaviors such as self-critique and backtracking. However, not all reflections are beneficial-many are superficial, offering little to no improvement over the original answer and incurring computation overhead. In this paper, we identify and address the problem of superficial reflection in LRMs. We first propose Self-Critique Fine-Tuning (SCFT), a training framework that enhances the model's reflective reasoning ability using only self-generated critiques. SCFT prompts models to critique their own outputs, filters high-quality critiques through rejection sampling, and fine-tunes the model using a critique-based objective. Building on this strong foundation, we further introduce Reinforcement Learning with Effective Reflection Rewards (RLERR). RLERR leverages the high-quality reflections initialized by SCFT to construct reward signals, guiding the model to internalize the self-correction process via reinforcement learning. Experiments on two challenging benchmarks, AIME2024 and AIME2025, show that SCFT and RLERR significantly improve both reasoning accuracy and reflection quality, outperforming state-of-the-art baselines. All data and codes are available at https://github.com/wanghanbinpanda/SCFT.", "AI": {"tldr": "\u63d0\u51faSCFT\u548cRLERR\u65b9\u6cd5\u89e3\u51b3\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u8868\u9762\u53cd\u601d\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u6211\u6279\u5224\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u53cd\u601d\u8d28\u91cf\u4e0e\u63a8\u7406\u51c6\u786e\u6027", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u8bb8\u591a\u53cd\u601d\u662f\u8868\u9762\u7684\uff0c\u5bf9\u539f\u59cb\u7b54\u6848\u6539\u8fdb\u6709\u9650\u4e14\u5e26\u6765\u8ba1\u7b97\u5f00\u9500\uff0c\u9700\u8981\u89e3\u51b3\u8868\u9762\u53cd\u601d\u95ee\u9898", "method": "1. SCFT\uff1a\u81ea\u6211\u6279\u5224\u5fae\u8c03\u6846\u67b6\uff0c\u8ba9\u6a21\u578b\u6279\u5224\u81ea\u8eab\u8f93\u51fa\uff0c\u901a\u8fc7\u62d2\u7edd\u91c7\u6837\u7b5b\u9009\u9ad8\u8d28\u91cf\u6279\u5224\uff0c\u4f7f\u7528\u6279\u5224\u76ee\u6807\u5fae\u8c03\u6a21\u578b\uff1b2. RLERR\uff1a\u5728SCFT\u57fa\u7840\u4e0a\uff0c\u5229\u7528\u9ad8\u8d28\u91cf\u53cd\u601d\u6784\u5efa\u5956\u52b1\u4fe1\u53f7\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5185\u5316\u81ea\u6211\u4fee\u6b63\u8fc7\u7a0b", "result": "\u5728AIME2024\u548cAIME2025\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSCFT\u548cRLERR\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u7406\u51c6\u786e\u6027\u548c\u53cd\u601d\u8d28\u91cf\uff0c\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "\u63d0\u51fa\u7684SCFT\u548cRLERR\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u8868\u9762\u53cd\u601d\u95ee\u9898\uff0c\u901a\u8fc7\u589e\u5f3a\u6a21\u578b\u7684\u53cd\u601d\u63a8\u7406\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u63a8\u7406\u6027\u80fd"}}
{"id": "2601.14034", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.14034", "abs": "https://arxiv.org/abs/2601.14034", "authors": ["Alexandros Tsakpinis", "Alexander Pretschner"], "title": "Analyzing the Availability of E-Mail Addresses for PyPI Libraries", "comment": "6 pages, 4 figures", "summary": "Open Source Software (OSS) libraries form the backbone of modern software systems, yet their long-term sustainability often depends on maintainers being reachable for support, coordination, and security reporting. In this paper, we empirically analyze the availability of contact information - specifically e-mail addresses - across 686,034 Python libraries on the Python Package Index (PyPI) and their associated GitHub repositories. We examine how and where maintainers provide this information, assess its validity, and explore coverage across individual libraries and their dependency chains. Our findings show that 81.6% of libraries include at least one valid e-mail address, with PyPI serving as the primary source (79.5%). When analyzing dependency chains, we observe that up to 97.8% of direct and 97.7% of transitive dependencies provide valid contact information. At the same time, we identify over 698,000 invalid entries, primarily due to missing fields. These results demonstrate strong maintainer reachability across the ecosystem, while highlighting opportunities for improvement - such as offering clearer guidance to maintainers during the packaging process and introducing opt-in validation mechanisms for existing e-mail addresses.", "AI": {"tldr": "\u5206\u6790PyPI\u4e0a68.6\u4e07\u4e2aPython\u5e93\u53ca\u5176GitHub\u4ed3\u5e93\u4e2d\u7ef4\u62a4\u8005\u8054\u7cfb\u4fe1\u606f\u7684\u53ef\u7528\u6027\uff0c\u53d1\u73b081.6%\u7684\u5e93\u5305\u542b\u81f3\u5c11\u4e00\u4e2a\u6709\u6548\u90ae\u7bb1\uff0cPyPI\u662f\u4e3b\u8981\u6765\u6e90(79.5%)\uff0c\u4f9d\u8d56\u94fe\u4e2d\u53ef\u8fbe\u6027\u9ad8\u8fbe97.8%\uff0c\u4f46\u5b58\u572869.8\u4e07\u4e2a\u65e0\u6548\u6761\u76ee\u3002", "motivation": "\u5f00\u6e90\u8f6f\u4ef6\u5e93\u7684\u957f\u671f\u53ef\u6301\u7eed\u6027\u4f9d\u8d56\u4e8e\u7ef4\u62a4\u8005\u7684\u53ef\u8054\u7cfb\u6027\uff0c\u4f46\u7f3a\u4e4f\u5bf9Python\u751f\u6001\u7cfb\u7edf\u4e2d\u7ef4\u62a4\u8005\u8054\u7cfb\u4fe1\u606f\u53ef\u7528\u6027\u7684\u7cfb\u7edf\u6027\u5b9e\u8bc1\u5206\u6790\u3002", "method": "\u5bf9Python Package Index (PyPI)\u4e0a\u7684686,034\u4e2aPython\u5e93\u53ca\u5176\u5173\u8054\u7684GitHub\u4ed3\u5e93\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\uff0c\u68c0\u67e5\u7ef4\u62a4\u8005\u5982\u4f55\u53ca\u5728\u4f55\u5904\u63d0\u4f9b\u8054\u7cfb\u4fe1\u606f\uff08\u7279\u522b\u662f\u90ae\u7bb1\u5730\u5740\uff09\uff0c\u8bc4\u4f30\u5176\u6709\u6548\u6027\uff0c\u5e76\u5206\u6790\u5728\u5355\u4e2a\u5e93\u53ca\u5176\u4f9d\u8d56\u94fe\u4e2d\u7684\u8986\u76d6\u60c5\u51b5\u3002", "result": "81.6%\u7684\u5e93\u5305\u542b\u81f3\u5c11\u4e00\u4e2a\u6709\u6548\u90ae\u7bb1\u5730\u5740\uff0cPyPI\u662f\u4e3b\u8981\u6765\u6e90(79.5%)\u3002\u5728\u4f9d\u8d56\u94fe\u5206\u6790\u4e2d\uff0c\u76f4\u63a5\u4f9d\u8d56\u548c\u4f20\u9012\u4f9d\u8d56\u5206\u522b\u670997.8%\u548c97.7%\u63d0\u4f9b\u6709\u6548\u8054\u7cfb\u4fe1\u606f\u3002\u540c\u65f6\u53d1\u73b0\u4e86\u8d85\u8fc7698,000\u4e2a\u65e0\u6548\u6761\u76ee\uff0c\u4e3b\u8981\u662f\u7531\u4e8e\u5b57\u6bb5\u7f3a\u5931\u3002", "conclusion": "Python\u751f\u6001\u7cfb\u7edf\u6574\u4f53\u7ef4\u62a4\u8005\u53ef\u8fbe\u6027\u8f83\u5f3a\uff0c\u4f46\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\uff0c\u5982\u5728\u6253\u5305\u8fc7\u7a0b\u4e2d\u4e3a\u7ef4\u62a4\u8005\u63d0\u4f9b\u66f4\u6e05\u6670\u7684\u6307\u5bfc\uff0c\u5e76\u4e3a\u73b0\u6709\u90ae\u7bb1\u5730\u5740\u5f15\u5165\u9009\u62e9\u6027\u7684\u9a8c\u8bc1\u673a\u5236\u3002"}}
{"id": "2601.13612", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.13612", "abs": "https://arxiv.org/abs/2601.13612", "authors": ["Jiani Liu", "Yixin He", "Lanlan Fan", "Qidi Zhong", "Yushi Cheng", "Meng Zhang", "Yanjiao Chen", "Wenyuan Xu"], "title": "PINA: Prompt Injection Attack against Navigation Agents", "comment": "Accepted at ICASSP 2026", "summary": "Navigation agents powered by large language models (LLMs) convert natural language instructions into executable plans and actions. Compared to text-based applications, their security is far more critical: a successful prompt injection attack does not just alter outputs but can directly misguide physical navigation, leading to unsafe routes, mission failure, or real-world harm. Despite this high-stakes setting, the vulnerability of navigation agents to prompt injection remains largely unexplored. In this paper, we propose PINA, an adaptive prompt optimization framework tailored to navigation agents under black-box, long-context, and action-executable constraints. Experiments on indoor and outdoor navigation agents show that PINA achieves high attack success rates with an average ASR of 87.5%, surpasses all baselines, and remains robust under ablation and adaptive-attack conditions. This work provides the first systematic investigation of prompt injection attacks in navigation and highlights their urgent security implications for embodied LLM agents.", "AI": {"tldr": "PINA\u662f\u4e00\u4e2a\u9488\u5bf9\u5bfc\u822a\u667a\u80fd\u4f53\u7684\u81ea\u9002\u5e94\u63d0\u793a\u4f18\u5316\u653b\u51fb\u6846\u67b6\uff0c\u5728\u5ba4\u5185\u5916\u5bfc\u822a\u573a\u666f\u4e2d\u5e73\u5747\u653b\u51fb\u6210\u529f\u738787.5%\uff0c\u63ed\u793a\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5bfc\u822a\u667a\u80fd\u4f53\u9762\u4e34\u4e25\u91cd\u7684\u63d0\u793a\u6ce8\u5165\u5b89\u5168\u98ce\u9669\u3002", "motivation": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5bfc\u822a\u667a\u80fd\u4f53\u5c06\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u8ba1\u5212\uff0c\u5176\u5b89\u5168\u6027\u6bd4\u7eaf\u6587\u672c\u5e94\u7528\u66f4\u4e3a\u5173\u952e\u2014\u2014\u6210\u529f\u7684\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u4e0d\u4ec5\u4f1a\u6539\u53d8\u8f93\u51fa\uff0c\u8fd8\u53ef\u80fd\u76f4\u63a5\u8bef\u5bfc\u7269\u7406\u5bfc\u822a\uff0c\u5bfc\u81f4\u4e0d\u5b89\u5168\u8def\u7ebf\u3001\u4efb\u52a1\u5931\u8d25\u751a\u81f3\u73b0\u5b9e\u4e16\u754c\u4f24\u5bb3\u3002\u7136\u800c\uff0c\u5bfc\u822a\u667a\u80fd\u4f53\u5bf9\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u7684\u8106\u5f31\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u4e86PINA\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u4e13\u95e8\u4e3a\u5bfc\u822a\u667a\u80fd\u4f53\u8bbe\u8ba1\u7684\u81ea\u9002\u5e94\u63d0\u793a\u4f18\u5316\u6846\u67b6\uff0c\u8003\u8651\u4e86\u9ed1\u76d2\u3001\u957f\u4e0a\u4e0b\u6587\u548c\u52a8\u4f5c\u53ef\u6267\u884c\u6027\u7b49\u7ea6\u675f\u6761\u4ef6\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u4f18\u5316\u63d0\u793a\u6765\u5b9e\u65bd\u653b\u51fb\u3002", "result": "\u5728\u5ba4\u5185\u548c\u5ba4\u5916\u5bfc\u822a\u667a\u80fd\u4f53\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPINA\u5b9e\u73b0\u4e86\u9ad8\u653b\u51fb\u6210\u529f\u7387\uff0c\u5e73\u5747ASR\u8fbe\u523087.5%\uff0c\u8d85\u8d8a\u4e86\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u4e14\u5728\u6d88\u878d\u5b9e\u9a8c\u548c\u81ea\u9002\u5e94\u653b\u51fb\u6761\u4ef6\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u8c03\u67e5\u4e86\u5bfc\u822a\u573a\u666f\u4e2d\u7684\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u7a81\u663e\u4e86\u8fd9\u7c7b\u653b\u51fb\u5bf9\u5177\u8eab\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u7684\u7d27\u8feb\u5b89\u5168\u5f71\u54cd\uff0c\u5f3a\u8c03\u4e86\u5bfc\u822a\u667a\u80fd\u4f53\u5b89\u5168\u6027\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.14081", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.14081", "abs": "https://arxiv.org/abs/2601.14081", "authors": ["Xingcheng Chen", "Oliver Weissl", "Andrea Stocco"], "title": "Feature-Aware Test Generation for Deep Learning Models", "comment": null, "summary": "As deep learning models are widely used in software systems, test generation plays a crucial role in assessing the quality of such models before deployment. To date, the most advanced test generators rely on generative AI to synthesize inputs; however, these approaches remain limited in providing semantic insight into the causes of misbehaviours and in offering fine-grained semantic controllability over the generated inputs. In this paper, we introduce Detect, a feature-aware test generation framework for vision-based deep learning (DL) models that systematically generates inputs by perturbing disentangled semantic attributes within the latent space. Detect perturbs individual latent features in a controlled way and observes how these changes affect the model's output. Through this process, it identifies which features lead to behavior shifts and uses a vision-language model for semantic attribution. By distinguishing between task-relevant and irrelevant features, Detect applies feature-aware perturbations targeted for both generalization and robustness. Empirical results across image classification and detection tasks show that Detect generates high-quality test cases with fine-grained control, reveals distinct shortcut behaviors across model architectures (convolutional and transformer-based), and bugs that are not captured by accuracy metrics. Specifically, Detect outperforms a state-of-the-art test generator in decision boundary discovery and a leading spurious feature localization method in identifying robustness failures. Our findings show that fully fine-tuned convolutional models are prone to overfitting on localized cues, such as co-occurring visual traits, while weakly supervised transformers tend to rely on global features, such as environmental variances. These findings highlight the value of interpretable and feature-aware testing in improving DL model reliability.", "AI": {"tldr": "Detect\u662f\u4e00\u4e2a\u7279\u5f81\u611f\u77e5\u7684\u6d4b\u8bd5\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u6270\u52a8\u89e3\u8026\u7684\u8bed\u4e49\u5c5e\u6027\u6765\u7cfb\u7edf\u751f\u6210\u6d4b\u8bd5\u8f93\u5165\uff0c\u7528\u4e8e\u8bc4\u4f30\u89c6\u89c9\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u8d28\u91cf\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u751f\u6210AI\u7684\u6d4b\u8bd5\u751f\u6210\u65b9\u6cd5\u5728\u63d0\u4f9b\u8bed\u4e49\u6d1e\u5bdf\u548c\u7ec6\u7c92\u5ea6\u8bed\u4e49\u63a7\u5236\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u65e0\u6cd5\u6df1\u5165\u7406\u89e3\u6a21\u578b\u9519\u8bef\u884c\u4e3a\u7684\u539f\u56e0\uff0c\u9700\u8981\u66f4\u7cbe\u7ec6\u53ef\u63a7\u7684\u6d4b\u8bd5\u751f\u6210\u65b9\u6cd5\u3002", "method": "Detect\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u53ef\u63a7\u5730\u6270\u52a8\u5355\u4e2a\u6f5c\u5728\u7279\u5f81\uff0c\u89c2\u5bdf\u8fd9\u4e9b\u53d8\u5316\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u8f93\u51fa\uff0c\u8bc6\u522b\u5bfc\u81f4\u884c\u4e3a\u8f6c\u53d8\u7684\u7279\u5f81\uff0c\u5e76\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bed\u4e49\u5f52\u56e0\u3002\u901a\u8fc7\u533a\u5206\u4efb\u52a1\u76f8\u5173\u548c\u65e0\u5173\u7279\u5f81\uff0c\u5e94\u7528\u7279\u5f81\u611f\u77e5\u6270\u52a8\u8fdb\u884c\u6cdb\u5316\u548c\u9c81\u68d2\u6027\u6d4b\u8bd5\u3002", "result": "\u5728\u56fe\u50cf\u5206\u7c7b\u548c\u68c0\u6d4b\u4efb\u52a1\u4e0a\u7684\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\uff0cDetect\u80fd\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u7ec6\u7c92\u5ea6\u53ef\u63a7\u7684\u6d4b\u8bd5\u7528\u4f8b\uff0c\u63ed\u793a\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u7684\u6377\u5f84\u884c\u4e3a\uff0c\u53d1\u73b0\u51c6\u786e\u6027\u6307\u6807\u65e0\u6cd5\u6355\u83b7\u7684\u7f3a\u9677\u3002\u5728\u51b3\u7b56\u8fb9\u754c\u53d1\u73b0\u548c\u9c81\u68d2\u6027\u5931\u8d25\u8bc6\u522b\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u5b8c\u5168\u5fae\u8c03\u7684\u5377\u79ef\u6a21\u578b\u5bb9\u6613\u8fc7\u62df\u5408\u5c40\u90e8\u7ebf\u7d22\uff0c\u800c\u5f31\u76d1\u7763\u7684transformer\u503e\u5411\u4e8e\u4f9d\u8d56\u5168\u5c40\u7279\u5f81\u3002\u7279\u5f81\u611f\u77e5\u6d4b\u8bd5\u5bf9\u4e8e\u63d0\u9ad8\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u53ef\u9760\u6027\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2601.13681", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.13681", "abs": "https://arxiv.org/abs/2601.13681", "authors": ["Felix Klement", "Alessandro Brighente", "Michele Polese", "Mauro Conti", "Stefan Katzenbeisser"], "title": "ORCA - An Automated Threat Analysis Pipeline for O-RAN Continuous Development", "comment": null, "summary": "The Open-Radio Access Network (O-RAN) integrates numerous software components in a cloud-like deployment, opening the radio access network to previously unconsidered security threats. With the ever-evolving threat landscape, integrating security practices through a DevSecOps approach is essential for fast and secure releases. Current vulnerability assessment practices often rely on manual, labor-intensive, and subjective investigations, leading to inconsistencies in the threat analysis. To mitigate these issues, we establish an automated pipeline that leverages Natural Language Processing (NLP) to minimize human intervention and associated biases. By mapping real-world vulnerabilities to predefined threat lists with a standardized input format, our approach is the first to enable iterative, quantitative, and efficient assessments, generating reliable threat scores for both individual vulnerabilities and entire system components within O-RAN. We illustrate the effectiveness of our framework through an example implementation for O-RAN, showcasing how continuous security testing can integrate into automated testing pipelines to address the unique security challenges of this paradigm shift in telecommunications.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u52a8\u5316\u6f0f\u6d1e\u8bc4\u4f30\u7ba1\u9053\uff0c\u5229\u7528NLP\u6280\u672f\u81ea\u52a8\u5c06O-RAN\u6f0f\u6d1e\u6620\u5c04\u5230\u9884\u5b9a\u4e49\u5a01\u80c1\u5217\u8868\uff0c\u5b9e\u73b0\u8fed\u4ee3\u3001\u5b9a\u91cf\u3001\u9ad8\u6548\u7684\u5a01\u80c1\u8bc4\u5206", "motivation": "O-RAN\u4e91\u5316\u90e8\u7f72\u5f15\u5165\u65b0\u5b89\u5168\u5a01\u80c1\uff0c\u4f20\u7edf\u6f0f\u6d1e\u8bc4\u4f30\u4f9d\u8d56\u4eba\u5de5\u3001\u52b3\u52a8\u5bc6\u96c6\u4e14\u4e3b\u89c2\uff0c\u5bfc\u81f4\u5a01\u80c1\u5206\u6790\u4e0d\u4e00\u81f4\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848", "method": "\u5efa\u7acb\u81ea\u52a8\u5316\u7ba1\u9053\uff0c\u5229\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u6700\u5c0f\u5316\u4eba\u5de5\u5e72\u9884\uff0c\u5c06\u771f\u5b9e\u6f0f\u6d1e\u6620\u5c04\u5230\u6807\u51c6\u5316\u683c\u5f0f\u7684\u9884\u5b9a\u4e49\u5a01\u80c1\u5217\u8868", "result": "\u9996\u6b21\u5b9e\u73b0\u8fed\u4ee3\u3001\u5b9a\u91cf\u3001\u9ad8\u6548\u7684\u8bc4\u4f30\uff0c\u4e3aO-RAN\u4e2d\u5355\u4e2a\u6f0f\u6d1e\u548c\u6574\u4e2a\u7cfb\u7edf\u7ec4\u4ef6\u751f\u6210\u53ef\u9760\u5a01\u80c1\u8bc4\u5206\uff0c\u901a\u8fc7\u793a\u4f8b\u5b9e\u65bd\u5c55\u793a\u6709\u6548\u6027", "conclusion": "\u81ea\u52a8\u5316NLP\u7ba1\u9053\u80fd\u6709\u6548\u96c6\u6210\u5230\u6301\u7eed\u5b89\u5168\u6d4b\u8bd5\u4e2d\uff0c\u89e3\u51b3\u7535\u4fe1\u8303\u5f0f\u8f6c\u53d8\u5e26\u6765\u7684\u72ec\u7279\u5b89\u5168\u6311\u6218\uff0c\u652f\u6301DevSecOps\u65b9\u6cd5"}}
{"id": "2601.12781", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12781", "abs": "https://arxiv.org/abs/2601.12781", "authors": ["Hyejin Park", "Junhyuk Kwon", "Suha Kwak", "Jungseul Ok"], "title": "VIRO: Robust and Efficient Neuro-Symbolic Reasoning with Verification for Referring Expression Comprehension", "comment": null, "summary": "Referring Expression Comprehension (REC) aims to localize the image region corresponding to a natural-language query. Recent neuro-symbolic REC approaches leverage large language models (LLMs) and vision-language models (VLMs) to perform compositional reasoning, decomposing queries 4 structured programs and executing them step-by-step. While such approaches achieve interpretable reasoning and strong zero-shot generalization, they assume that intermediate reasoning steps are accurate. However, this assumption causes cascading errors: false detections and invalid relations propagate through the reasoning chain, yielding high-confidence false positives even when no target is present in the image. To address this limitation, we introduce Verification-Integrated Reasoning Operators (VIRO), a neuro-symbolic framework that embeds lightweight operator-level verifiers within reasoning steps. Each operator executes and validates its output, such as object existence or spatial relationship, thereby allowing the system to robustly handle no-target cases when verification conditions are not met. Our framework achieves state-of-the-art performance, reaching 61.1% balanced accuracy across target-present and no-target settings, and demonstrates generalization to real-world egocentric data. Furthermore, VIRO shows superior computational efficiency in terms of throughput, high reliability with a program failure rate of less than 0.3%, and scalability through decoupled program generation from execution.", "AI": {"tldr": "VIRO\u6846\u67b6\u901a\u8fc7\u5d4c\u5165\u8f7b\u91cf\u7ea7\u9a8c\u8bc1\u5668\u89e3\u51b3\u795e\u7ecf\u7b26\u53f7REC\u65b9\u6cd5\u4e2d\u7684\u7ea7\u8054\u9519\u8bef\u95ee\u9898\uff0c\u5728\u76ee\u6807\u5b58\u5728\u548c\u4e0d\u5b58\u5728\u573a\u666f\u4e0b\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd", "motivation": "\u73b0\u6709\u795e\u7ecf\u7b26\u53f7REC\u65b9\u6cd5\u5047\u8bbe\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u51c6\u786e\uff0c\u5bfc\u81f4\u7ea7\u8054\u9519\u8bef\uff1a\u9519\u8bef\u68c0\u6d4b\u548c\u65e0\u6548\u5173\u7cfb\u5728\u63a8\u7406\u94fe\u4e2d\u4f20\u64ad\uff0c\u5373\u4f7f\u56fe\u50cf\u4e2d\u6ca1\u6709\u76ee\u6807\u4e5f\u4f1a\u4ea7\u751f\u9ad8\u7f6e\u4fe1\u5ea6\u7684\u5047\u9633\u6027\u7ed3\u679c", "method": "\u63d0\u51fa\u9a8c\u8bc1\u96c6\u6210\u63a8\u7406\u7b97\u5b50\uff08VIRO\uff09\u6846\u67b6\uff0c\u5728\u63a8\u7406\u6b65\u9aa4\u4e2d\u5d4c\u5165\u8f7b\u91cf\u7ea7\u7b97\u5b50\u7ea7\u9a8c\u8bc1\u5668\uff0c\u6bcf\u4e2a\u7b97\u5b50\u6267\u884c\u5e76\u9a8c\u8bc1\u5176\u8f93\u51fa\uff08\u5982\u5bf9\u8c61\u5b58\u5728\u6027\u6216\u7a7a\u95f4\u5173\u7cfb\uff09\uff0c\u5f53\u9a8c\u8bc1\u6761\u4ef6\u4e0d\u6ee1\u8db3\u65f6\u80fd\u591f\u9c81\u68d2\u5730\u5904\u7406\u65e0\u76ee\u6807\u60c5\u51b5", "result": "\u5728\u76ee\u6807\u5b58\u5728\u548c\u65e0\u76ee\u6807\u8bbe\u7f6e\u4e0b\u8fbe\u523061.1%\u7684\u5e73\u8861\u51c6\u786e\u7387\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u7b2c\u4e00\u4eba\u79f0\u6570\u636e\u4e0a\u5c55\u793a\u6cdb\u5316\u80fd\u529b\uff0c\u5177\u6709\u9ad8\u8ba1\u7b97\u6548\u7387\uff08\u541e\u5410\u91cf\uff09\u3001\u9ad8\u53ef\u9760\u6027\uff08\u7a0b\u5e8f\u5931\u8d25\u7387\u4f4e\u4e8e0.3%\uff09\u548c\u901a\u8fc7\u89e3\u8026\u7a0b\u5e8f\u751f\u6210\u4e0e\u6267\u884c\u5b9e\u73b0\u7684\u53ef\u6269\u5c55\u6027", "conclusion": "VIRO\u6846\u67b6\u901a\u8fc7\u96c6\u6210\u9a8c\u8bc1\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u795e\u7ecf\u7b26\u53f7REC\u65b9\u6cd5\u4e2d\u7684\u7ea7\u8054\u9519\u8bef\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u53ef\u89e3\u91ca\u63a8\u7406\u548c\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u9c81\u68d2\u6027\u548c\u53ef\u9760\u6027"}}
{"id": "2601.14131", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.14131", "abs": "https://arxiv.org/abs/2601.14131", "authors": ["Amila Indika", "Rick Kazman", "Anthony Peruma"], "title": "Practitioner Views on Mobile App Accessibility: Practices and Challenges", "comment": "The 48th IEEE/ACM International Conference on Software Engineering - Research Track", "summary": "As mobile applications (apps) become ubiquitous in everyday life, it is crucial for developers to prioritize accessibility for users with diverse abilities. While previous research has identified widespread accessibility issues and raised awareness of developer challenges, there remains a lack of cross-platform, globally representative insights into how practitioners approach accessibility in practice. This paper presents findings from a mixed-methods survey of 110 mobile app developers across 43 countries, examining how platform ecosystems (iOS vs. Android) and developer experience shape accessibility practices. Results show that while developers recognize the importance of accessibility, they often rely on platform-specific guidelines and typically perform compliance testing late in the development process. Developers primarily implement text-focused features while struggling with API limitations and organizational constraints. Through systematic cross-platform comparison, we identify novel platform-specific barriers and demonstrate how accessibility practices differ across developer experience levels. Our findings offer new insights into the challenges of achieving accessibility in practice and provide actionable steps for various stakeholders to promote more consistent and inclusive app development.", "AI": {"tldr": "\u79fb\u52a8\u5e94\u7528\u5f00\u53d1\u8005\u666e\u904d\u8ba4\u8bc6\u5230\u65e0\u969c\u788d\u529f\u80fd\u7684\u91cd\u8981\u6027\uff0c\u4f46\u5b9e\u8df5\u4e2d\u4e3b\u8981\u4f9d\u8d56\u5e73\u53f0\u7279\u5b9a\u6307\u5357\uff0c\u6d4b\u8bd5\u8f83\u665a\uff0c\u4e14\u9762\u4e34API\u9650\u5236\u548c\u7ec4\u7ec7\u7ea6\u675f\u7b49\u6311\u6218\u3002", "motivation": "\u867d\u7136\u4e4b\u524d\u7684\u7814\u7a76\u5df2\u7ecf\u8bc6\u522b\u4e86\u5e7f\u6cdb\u5b58\u5728\u7684\u65e0\u969c\u788d\u95ee\u9898\u5e76\u63d0\u9ad8\u4e86\u5bf9\u5f00\u53d1\u8005\u6311\u6218\u7684\u8ba4\u8bc6\uff0c\u4f46\u7f3a\u4e4f\u8de8\u5e73\u53f0\u3001\u5168\u7403\u4ee3\u8868\u6027\u7684\u5173\u4e8e\u5f00\u53d1\u8005\u5982\u4f55\u5728\u5b9e\u8df5\u4e2d\u5904\u7406\u65e0\u969c\u788d\u529f\u80fd\u7684\u89c1\u89e3\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u5bf9\u6765\u81ea43\u4e2a\u56fd\u5bb6\u7684110\u540d\u79fb\u52a8\u5e94\u7528\u5f00\u53d1\u8005\u8fdb\u884c\u8c03\u67e5\uff0c\u7814\u7a76\u5e73\u53f0\u751f\u6001\u7cfb\u7edf\uff08iOS vs Android\uff09\u548c\u5f00\u53d1\u8005\u7ecf\u9a8c\u5982\u4f55\u5f71\u54cd\u65e0\u969c\u788d\u5b9e\u8df5\u3002", "result": "\u5f00\u53d1\u8005\u867d\u7136\u8ba4\u8bc6\u5230\u65e0\u969c\u788d\u7684\u91cd\u8981\u6027\uff0c\u4f46\u4e3b\u8981\u4f9d\u8d56\u5e73\u53f0\u7279\u5b9a\u6307\u5357\uff0c\u901a\u5e38\u5728\u5f00\u53d1\u540e\u671f\u8fdb\u884c\u5408\u89c4\u6d4b\u8bd5\uff1b\u4e3b\u8981\u5b9e\u73b0\u6587\u672c\u76f8\u5173\u529f\u80fd\uff0c\u540c\u65f6\u9762\u4e34API\u9650\u5236\u548c\u7ec4\u7ec7\u7ea6\u675f\uff1b\u901a\u8fc7\u8de8\u5e73\u53f0\u6bd4\u8f83\u53d1\u73b0\u4e86\u65b0\u7684\u5e73\u53f0\u7279\u5b9a\u969c\u788d\uff0c\u5e76\u5c55\u793a\u4e86\u4e0d\u540c\u7ecf\u9a8c\u6c34\u5e73\u7684\u5f00\u53d1\u8005\u5b9e\u8df5\u5dee\u5f02\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u63d0\u4f9b\u4e86\u5173\u4e8e\u5b9e\u8df5\u4e2d\u5b9e\u73b0\u65e0\u969c\u788d\u529f\u80fd\u6311\u6218\u7684\u65b0\u89c1\u89e3\uff0c\u5e76\u4e3a\u5404\u5229\u76ca\u76f8\u5173\u8005\u63d0\u4f9b\u4e86\u4fc3\u8fdb\u66f4\u4e00\u81f4\u548c\u5305\u5bb9\u6027\u5e94\u7528\u5f00\u53d1\u7684\u53ef\u64cd\u4f5c\u6b65\u9aa4\u3002"}}
{"id": "2601.13757", "categories": ["cs.CR", "cs.CE"], "pdf": "https://arxiv.org/pdf/2601.13757", "abs": "https://arxiv.org/abs/2601.13757", "authors": ["Ekleen Kaur"], "title": "The Limits of Conditional Volatility: Assessing Cryptocurrency VaR under EWMA and IGARCH Models", "comment": "Accepted and going to be presented at ICICT London 2026. https://icict.co.uk/ All ICICT 2026 presented papers will be published in conference proceedings by Springer LNNS. ISSN: 2367-3370, Series: https://www.springer.com/series/15179", "summary": "The application of the standard static Geometric Brownian Motion (GBM) model for cryptocurrency risk management resulted in a systemic failure, evidenced by a 80.67% chance of loss in the 5% value-at-risk benchmark. This study addresses a critical literature gap by comparatively testing three conditional volatility models the EWMA/IGARCH baseline, an IGARCH model augmented with explicit mean reversion (IGARCH + MR), and a modified EGARCH-style asymmetric shock model within a correlated Monte Carlo VaR framework. Crucially, the analysis is applied specifically to high-beta altcoins (XRP, SOL, ADA), an asset class largely neglected by mainstream GARCH literature. Our results demonstrate that imposing stationarity (IGARCH + MR) drastically underestimates downside risk (5 percent value-at-risk reduced by 50%), while the asymmetric model (Model 3) leads to severe over-penalization. The EWMA/IGARCH baseline, characterized by infinite volatility persistence (alpha + beta = 1), provided the only robust conditional volatility estimate. This finding constitutes a formal rejection of the conventional financial hypotheses of volatility mean reversion and the asymmetric leverage effect in the altcoin asset class, establishing that non-stationary frameworks are a prerequisite for regulatory-grade risk modeling in this domain.", "AI": {"tldr": "\u4f20\u7edf\u9759\u6001GBM\u6a21\u578b\u5728\u52a0\u5bc6\u8d27\u5e01\u98ce\u9669\u7ba1\u7406\u4e2d\u7cfb\u7edf\u6027\u5931\u6548\uff0c\u672c\u6587\u6bd4\u8f83\u4e09\u79cd\u6761\u4ef6\u6ce2\u52a8\u7387\u6a21\u578b\uff0c\u53d1\u73b0EWMA/IGARCH\u57fa\u7ebf\u6a21\u578b\u5728\u9ad8beta\u5c71\u5be8\u5e01\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u6b63\u5f0f\u62d2\u7edd\u4e86\u6ce2\u52a8\u7387\u5747\u503c\u56de\u5f52\u548c\u6760\u6746\u6548\u5e94\u7684\u4f20\u7edf\u91d1\u878d\u5047\u8bbe\u3002", "motivation": "\u6807\u51c6\u9759\u6001GBM\u6a21\u578b\u5728\u52a0\u5bc6\u8d27\u5e01\u98ce\u9669\u7ba1\u7406\u4e2d\u5bfc\u81f4\u7cfb\u7edf\u6027\u5931\u8d25\uff0880.67%\u635f\u5931\u6982\u7387\uff09\uff0c\u4e3b\u6d41GARCH\u6587\u732e\u5ffd\u89c6\u9ad8beta\u5c71\u5be8\u5e01\u8fd9\u4e00\u8d44\u4ea7\u7c7b\u522b\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u5173\u952e\u6587\u732e\u7a7a\u767d\u3002", "method": "\u5728\u76f8\u5173\u8499\u7279\u5361\u6d1bVaR\u6846\u67b6\u4e2d\u6bd4\u8f83\u6d4b\u8bd5\u4e09\u79cd\u6761\u4ef6\u6ce2\u52a8\u7387\u6a21\u578b\uff1aEWMA/IGARCH\u57fa\u7ebf\u6a21\u578b\u3001\u52a0\u5165\u663e\u5f0f\u5747\u503c\u56de\u5f52\u7684IGARCH\u6a21\u578b\u3001\u4ee5\u53ca\u6539\u8fdb\u7684EGARCH\u98ce\u683c\u4e0d\u5bf9\u79f0\u51b2\u51fb\u6a21\u578b\uff0c\u4e13\u95e8\u5e94\u7528\u4e8e\u9ad8beta\u5c71\u5be8\u5e01\uff08XRP\u3001SOL\u3001ADA\uff09\u3002", "result": "\u5f3a\u5236\u5e73\u7a33\u6027\uff08IGARCH+MR\uff09\u4e25\u91cd\u4f4e\u4f30\u4e0b\u884c\u98ce\u9669\uff085%VaR\u51cf\u5c1150%\uff09\uff0c\u800c\u4e0d\u5bf9\u79f0\u6a21\u578b\u5bfc\u81f4\u8fc7\u5ea6\u60e9\u7f5a\u3002\u53ea\u6709\u5177\u6709\u65e0\u9650\u6ce2\u52a8\u7387\u6301\u7eed\u6027\u7684EWMA/IGARCH\u57fa\u7ebf\u6a21\u578b\u63d0\u4f9b\u4e86\u7a33\u5065\u7684\u6761\u4ef6\u6ce2\u52a8\u7387\u4f30\u8ba1\u3002", "conclusion": "\u6b63\u5f0f\u62d2\u7edd\u4e86\u6ce2\u52a8\u7387\u5747\u503c\u56de\u5f52\u548c\u4e0d\u5bf9\u79f0\u6760\u6746\u6548\u5e94\u7684\u4f20\u7edf\u91d1\u878d\u5047\u8bbe\uff0c\u786e\u7acb\u975e\u5e73\u7a33\u6846\u67b6\u662f\u5c71\u5be8\u5e01\u8d44\u4ea7\u7c7b\u522b\u76d1\u7ba1\u7ea7\u98ce\u9669\u5efa\u6a21\u7684\u5148\u51b3\u6761\u4ef6\u3002"}}
{"id": "2601.12804", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12804", "abs": "https://arxiv.org/abs/2601.12804", "authors": ["Hanwei Zhang", "Luo Cheng", "Rui Wen", "Yang Zhang", "Lijun Zhang", "Holger Hermanns"], "title": "SL-CBM: Enhancing Concept Bottleneck Models with Semantic Locality for Better Interpretability", "comment": null, "summary": "Explainable AI (XAI) is crucial for building transparent and trustworthy machine learning systems, especially in high-stakes domains. Concept Bottleneck Models (CBMs) have emerged as a promising ante-hoc approach that provides interpretable, concept-level explanations by explicitly modeling human-understandable concepts. However, existing CBMs often suffer from poor locality faithfulness, failing to spatially align concepts with meaningful image regions, which limits their interpretability and reliability. In this work, we propose SL-CBM (CBM with Semantic Locality), a novel extension that enforces locality faithfulness by generating spatially coherent saliency maps at both concept and class levels. SL-CBM integrates a 1x1 convolutional layer with a cross-attention mechanism to enhance alignment between concepts, image regions, and final predictions. Unlike prior methods, SL-CBM produces faithful saliency maps inherently tied to the model's internal reasoning, facilitating more effective debugging and intervention. Extensive experiments on image datasets demonstrate that SL-CBM substantially improves locality faithfulness, explanation quality, and intervention efficacy while maintaining competitive classification accuracy. Our ablation studies highlight the importance of contrastive and entropy-based regularization for balancing accuracy, sparsity, and faithfulness. Overall, SL-CBM bridges the gap between concept-based reasoning and spatial explainability, setting a new standard for interpretable and trustworthy concept-based models.", "AI": {"tldr": "SL-CBM\u901a\u8fc7\u5f15\u5165\u8bed\u4e49\u5c40\u90e8\u6027\u7ea6\u675f\uff0c\u6539\u8fdb\u4e86\u6982\u5ff5\u74f6\u9888\u6a21\u578b\u7684\u7a7a\u95f4\u5bf9\u9f50\u80fd\u529b\uff0c\u751f\u6210\u66f4\u5fe0\u5b9e\u7684\u6982\u5ff5\u548c\u7c7b\u522b\u663e\u8457\u6027\u56fe\uff0c\u63d0\u5347\u4e86\u89e3\u91ca\u8d28\u91cf\u548c\u5e72\u9884\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u6982\u5ff5\u74f6\u9888\u6a21\u578b\uff08CBMs\uff09\u5b58\u5728\u5c40\u90e8\u5fe0\u5b9e\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u65e0\u6cd5\u5c06\u6982\u5ff5\u4e0e\u6709\u610f\u4e49\u7684\u56fe\u50cf\u533a\u57df\u8fdb\u884c\u7a7a\u95f4\u5bf9\u9f50\uff0c\u8fd9\u9650\u5236\u4e86\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u63d0\u4f9b\u7a7a\u95f4\u8fde\u8d2f\u663e\u8457\u6027\u56fe\u7684\u65b9\u6cd5\u6765\u589e\u5f3a\u6982\u5ff5\u4e0e\u56fe\u50cf\u533a\u57df\u7684\u5bf9\u5e94\u5173\u7cfb\u3002", "method": "\u63d0\u51faSL-CBM\uff08\u5177\u6709\u8bed\u4e49\u5c40\u90e8\u6027\u7684CBM\uff09\uff0c\u901a\u8fc7\u96c6\u62101x1\u5377\u79ef\u5c42\u548c\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u6765\u589e\u5f3a\u6982\u5ff5\u3001\u56fe\u50cf\u533a\u57df\u548c\u6700\u7ec8\u9884\u6d4b\u4e4b\u95f4\u7684\u5bf9\u9f50\u3002\u4f7f\u7528\u5bf9\u6bd4\u6027\u548c\u57fa\u4e8e\u71b5\u7684\u6b63\u5219\u5316\u6765\u5e73\u8861\u51c6\u786e\u6027\u3001\u7a00\u758f\u6027\u548c\u5fe0\u5b9e\u6027\u3002", "result": "\u5728\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSL-CBM\u663e\u8457\u63d0\u9ad8\u4e86\u5c40\u90e8\u5fe0\u5b9e\u6027\u3001\u89e3\u91ca\u8d28\u91cf\u548c\u5e72\u9884\u6548\u679c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6709\u7ade\u4e89\u529b\u7684\u5206\u7c7b\u51c6\u786e\u6027\u3002\u6d88\u878d\u7814\u7a76\u7a81\u51fa\u4e86\u5bf9\u6bd4\u6027\u548c\u71b5\u6b63\u5219\u5316\u7684\u91cd\u8981\u6027\u3002", "conclusion": "SL-CBM\u5f25\u5408\u4e86\u57fa\u4e8e\u6982\u5ff5\u7684\u63a8\u7406\u4e0e\u7a7a\u95f4\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u53ef\u89e3\u91ca\u548c\u53ef\u4fe1\u8d56\u7684\u6982\u5ff5\u6a21\u578b\u8bbe\u5b9a\u4e86\u65b0\u6807\u51c6\uff0c\u901a\u8fc7\u7a7a\u95f4\u8fde\u8d2f\u7684\u663e\u8457\u6027\u56fe\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u8c03\u8bd5\u548c\u5e72\u9884\u80fd\u529b\u3002"}}
{"id": "2601.13826", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.13826", "abs": "https://arxiv.org/abs/2601.13826", "authors": ["Huadi Zheng", "Li Cheng", "Yan Ding"], "title": "MirageNet:A Secure, Efficient, and Scalable On-Device Model Protection in Heterogeneous TEE and GPU System", "comment": "13 pages", "summary": "As edge devices gain stronger computing power, deploying high-performance DNN models on untrusted hardware has become a practical approach to cut inference latency and protect user data privacy. Given high model training costs and user experience requirements, balancing model privacy and low runtime overhead is critical. TEEs offer a viable defense, and prior work has proposed heterogeneous GPU-TEE inference frameworks via parameter obfuscation to balance efficiency and confidentiality. However, recent studies find partial obfuscation defenses ineffective, while robust schemes cause unacceptable latency. To resolve these issues, we propose ConvShatter, a novel obfuscation scheme that achieves low latency and high accuracy while preserving model confidentiality and integrity. It leverages convolution linearity to decompose kernels into critical and common ones, inject confounding decoys, and permute channel/kernel orders. Pre-deployment, it performs kernel decomposition, decoy injection and order obfuscation, storing minimal recovery parameters securely in the TEE. During inference, the TEE reconstructs outputs of obfuscated convolutional layers. Extensive experiments show ConvShatter substantially reduces latency overhead with strong security guarantees; versus comparable schemes, it cuts overhead by 16% relative to GroupCover while maintaining accuracy on par with the original model.", "AI": {"tldr": "ConvShatter\u662f\u4e00\u79cd\u65b0\u578b\u5377\u79ef\u5c42\u6df7\u6dc6\u65b9\u6848\uff0c\u901a\u8fc7\u5728TEE\u4e2d\u5b89\u5168\u5b58\u50a8\u5c11\u91cf\u6062\u590d\u53c2\u6570\uff0c\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u7cbe\u5ea6\u7684\u6a21\u578b\u9690\u79c1\u4fdd\u62a4\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6848\u663e\u8457\u964d\u4f4e\u5f00\u9500\u3002", "motivation": "\u968f\u7740\u8fb9\u7f18\u8bbe\u5907\u8ba1\u7b97\u80fd\u529b\u589e\u5f3a\uff0c\u5728\u4e0d\u53ef\u4fe1\u786c\u4ef6\u4e0a\u90e8\u7f72\u9ad8\u6027\u80fdDNN\u6a21\u578b\u6210\u4e3a\u964d\u4f4e\u63a8\u7406\u5ef6\u8fdf\u548c\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u7684\u5b9e\u7528\u65b9\u6cd5\u3002\u73b0\u6709\u53c2\u6570\u6df7\u6dc6\u65b9\u6848\u5b58\u5728\u6548\u7387\u4e0e\u5b89\u5168\u6027\u77db\u76fe\uff1a\u90e8\u5206\u6df7\u6dc6\u9632\u5fa1\u65e0\u6548\uff0c\u800c\u5f3a\u5065\u65b9\u6848\u5bfc\u81f4\u4e0d\u53ef\u63a5\u53d7\u7684\u5ef6\u8fdf\u3002", "method": "\u5229\u7528\u5377\u79ef\u7ebf\u6027\u7279\u6027\u5c06\u5377\u79ef\u6838\u5206\u89e3\u4e3a\u5173\u952e\u6838\u548c\u516c\u5171\u6838\uff0c\u6ce8\u5165\u6df7\u6dc6\u8bf1\u9975\uff0c\u5e76\u7f6e\u6362\u901a\u9053/\u6838\u987a\u5e8f\u3002\u90e8\u7f72\u524d\u6267\u884c\u6838\u5206\u89e3\u3001\u8bf1\u9975\u6ce8\u5165\u548c\u987a\u5e8f\u6df7\u6dc6\uff0c\u5c06\u5c11\u91cf\u6062\u590d\u53c2\u6570\u5b89\u5168\u5b58\u50a8\u5728TEE\u4e2d\u3002\u63a8\u7406\u65f6\uff0cTEE\u91cd\u6784\u6df7\u6dc6\u5377\u79ef\u5c42\u7684\u8f93\u51fa\u3002", "result": "\u5b9e\u9a8c\u8868\u660eConvShatter\u5728\u4fdd\u6301\u5f3a\u5b89\u5168\u4fdd\u8bc1\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\u5f00\u9500\uff1b\u76f8\u6bd4\u540c\u7c7b\u65b9\u6848GroupCover\uff0c\u76f8\u5bf9\u5f00\u9500\u964d\u4f4e16%\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u539f\u59cb\u6a21\u578b\u76f8\u5f53\u7684\u51c6\u786e\u7387\u3002", "conclusion": "ConvShatter\u901a\u8fc7\u521b\u65b0\u7684\u5377\u79ef\u6838\u6df7\u6dc6\u65b9\u6848\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6a21\u578b\u9690\u79c1\u4fdd\u62a4\u4e0e\u8fd0\u884c\u65f6\u6548\u7387\u7684\u5e73\u8861\u95ee\u9898\uff0c\u4e3a\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u5b89\u5168DNN\u63a8\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.14163", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.14163", "abs": "https://arxiv.org/abs/2601.14163", "authors": ["Mohammed Latif Siddiq", "Tanzim Hossain Romel", "Natalie Sekerak", "Beatrice Casey", "Joanna C. S. Santos"], "title": "An Empirical Study on Remote Code Execution in Machine Learning Model Hosting Ecosystems", "comment": null, "summary": "Model-sharing platforms, such as Hugging Face, ModelScope, and OpenCSG, have become central to modern machine learning development, enabling developers to share, load, and fine-tune pre-trained models with minimal effort. However, the flexibility of these ecosystems introduces a critical security concern: the execution of untrusted code during model loading (i.e., via trust_remote_code or trust_repo). In this work, we conduct the first large-scale empirical study of custom model loading practices across five major model-sharing platforms to assess their prevalence, associated risks, and developer perceptions. We first quantify the frequency with which models require custom code to function and identify those that execute arbitrary Python files during loading. We then apply three complementary static analysis tools: Bandit, CodeQL, and Semgrep, to detect security smells and potential vulnerabilities, categorizing our findings by CWE identifiers to provide a standardized risk taxonomy. We also use YARA to identify malicious patterns and payload signatures. In parallel, we systematically analyze the documentation, API design, and safety mechanisms of each platform to understand their mitigation strategies and enforcement levels. Finally, we conduct a qualitative analysis of over 600 developer discussions from GitHub, Hugging Face, and PyTorch Hub forums, as well as Stack Overflow, to capture community concerns and misconceptions regarding security and usability. Our findings reveal widespread reliance on unsafe defaults, uneven security enforcement across platforms, and persistent confusion among developers about the implications of executing remote code. We conclude with actionable recommendations for designing safer model-sharing infrastructures and striking a balance between usability and security in future AI ecosystems.", "AI": {"tldr": "\u5bf9\u4e94\u4e2a\u4e3b\u8981\u6a21\u578b\u5171\u4eab\u5e73\u53f0\u4e2d\u81ea\u5b9a\u4e49\u6a21\u578b\u52a0\u8f7d\u5b9e\u8df5\u7684\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u63ed\u793a\u4e86\u4e0d\u5b89\u5168\u9ed8\u8ba4\u8bbe\u7f6e\u7684\u666e\u904d\u4f7f\u7528\u3001\u5e73\u53f0\u95f4\u5b89\u5168\u6267\u884c\u4e0d\u5747\u8861\u4ee5\u53ca\u5f00\u53d1\u8005\u5bf9\u8fdc\u7a0b\u4ee3\u7801\u6267\u884c\u5b89\u5168\u98ce\u9669\u7684\u6301\u7eed\u56f0\u60d1\u3002", "motivation": "\u6a21\u578b\u5171\u4eab\u5e73\u53f0\uff08\u5982Hugging Face\u3001ModelScope\u3001OpenCSG\u7b49\uff09\u5df2\u6210\u4e3a\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u5f00\u53d1\u7684\u6838\u5fc3\uff0c\u4f46\u6267\u884c\u4e0d\u53d7\u4fe1\u4efb\u4ee3\u7801\u7684\u7075\u6d3b\u6027\u5f15\u5165\u4e86\u5173\u952e\u5b89\u5168\u98ce\u9669\u3002\u672c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u81ea\u5b9a\u4e49\u6a21\u578b\u52a0\u8f7d\u5b9e\u8df5\u7684\u666e\u904d\u6027\u3001\u76f8\u5173\u98ce\u9669\u4ee5\u53ca\u5f00\u53d1\u8005\u7684\u8ba4\u77e5\u3002", "method": "1. \u91cf\u5316\u9700\u8981\u81ea\u5b9a\u4e49\u4ee3\u7801\u624d\u80fd\u8fd0\u884c\u7684\u6a21\u578b\u9891\u7387\uff0c\u8bc6\u522b\u52a0\u8f7d\u671f\u95f4\u6267\u884c\u4efb\u610fPython\u6587\u4ef6\u7684\u6a21\u578b\uff1b2. \u5e94\u7528\u4e09\u79cd\u4e92\u8865\u7684\u9759\u6001\u5206\u6790\u5de5\u5177\uff08Bandit\u3001CodeQL\u3001Semgrep\uff09\u68c0\u6d4b\u5b89\u5168\u5f02\u5473\u548c\u6f5c\u5728\u6f0f\u6d1e\uff0c\u6309CWE\u6807\u8bc6\u7b26\u5206\u7c7b\uff1b3. \u4f7f\u7528YARA\u8bc6\u522b\u6076\u610f\u6a21\u5f0f\u548c\u6709\u6548\u8f7d\u8377\u7b7e\u540d\uff1b4. \u7cfb\u7edf\u5206\u6790\u6bcf\u4e2a\u5e73\u53f0\u7684\u6587\u6863\u3001API\u8bbe\u8ba1\u548c\u5b89\u5168\u673a\u5236\uff1b5. \u5bf9\u6765\u81eaGitHub\u3001Hugging Face\u3001PyTorch Hub\u8bba\u575b\u548cStack Overflow\u7684600\u591a\u4e2a\u5f00\u53d1\u8005\u8ba8\u8bba\u8fdb\u884c\u5b9a\u6027\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1. \u5e7f\u6cdb\u4f9d\u8d56\u4e0d\u5b89\u5168\u9ed8\u8ba4\u8bbe\u7f6e\uff1b2. \u5e73\u53f0\u95f4\u5b89\u5168\u6267\u884c\u4e0d\u5747\u8861\uff1b3. \u5f00\u53d1\u8005\u5bf9\u8fdc\u7a0b\u4ee3\u7801\u6267\u884c\u7684\u5b89\u5168\u5f71\u54cd\u5b58\u5728\u6301\u7eed\u56f0\u60d1\u3002", "conclusion": "\u4e3a\u8bbe\u8ba1\u66f4\u5b89\u5168\u7684\u6a21\u578b\u5171\u4eab\u57fa\u7840\u8bbe\u65bd\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u5efa\u8bae\uff0c\u65e8\u5728\u5728\u672a\u6765\u7684AI\u751f\u6001\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u53ef\u7528\u6027\u4e0e\u5b89\u5168\u6027\u4e4b\u95f4\u7684\u5e73\u8861\u3002"}}
{"id": "2601.13840", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.13840", "abs": "https://arxiv.org/abs/2601.13840", "authors": ["Haoyu Shen", "Wen Yin", "Zhaoxia Yin", "Wan-Li Lyu", "Xinpeng Zhang"], "title": "Robust Reversible Watermarking in Encrypted Images Based on Dual-MSBs Spiral Embedding", "comment": "10 pages, 8 figures", "summary": "Robust reversible watermarking in encrypted images (RRWEI) faces an inherent challenge in simultaneously achieving robustness, reversibility, and content privacy under severely constrained embedding capacity. Existing RRWEI schemes often exhibit limited robustness against noise, lossy compression, and cropping attacks due to insufficient redundancy in the encrypted domain. To address this challenge, this paper proposes a novel RRWEI framework that couples dual most significant bit-plane (dual-MSBs) embedding with spatial redundancy and error-correcting coding. By compressing prediction-error bit-planes, sufficient embedding space and auxiliary information for lossless reconstruction are reserved. The dual-MSBs are further reorganized using a spiral embedding strategy to distribute multiple redundant watermark copies across spatially dispersed regions, enhancing robustness against both noise and spatial loss.Experimental results on standard test images demonstrate that the proposed method consistently outperforms under evaluated settings robustness against Gaussian noise, JPEG compression, and diverse cropping attacks, while maintaining perfect reversibility and high embedding capacity. Compared with state-of-the-art RRWEI schemes, the proposed framework achieves substantially lower bit-error rates and more stable performance under a wide range of attack scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u9c81\u68d2\u53ef\u9006\u52a0\u5bc6\u56fe\u50cf\u6c34\u5370\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u6700\u9ad8\u6709\u6548\u4f4d\u5e73\u9762\u5d4c\u5165\u7ed3\u5408\u7a7a\u95f4\u5197\u4f59\u548c\u7ea0\u9519\u7f16\u7801\uff0c\u5728\u52a0\u5bc6\u57df\u4e2d\u540c\u65f6\u5b9e\u73b0\u9c81\u68d2\u6027\u3001\u53ef\u9006\u6027\u548c\u5185\u5bb9\u9690\u79c1\u4fdd\u62a4\u3002", "motivation": "\u73b0\u6709\u7684\u9c81\u68d2\u53ef\u9006\u52a0\u5bc6\u56fe\u50cf\u6c34\u5370\u65b9\u6848\u5728\u5d4c\u5165\u5bb9\u91cf\u4e25\u91cd\u53d7\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u96be\u4ee5\u540c\u65f6\u5b9e\u73b0\u9c81\u68d2\u6027\u3001\u53ef\u9006\u6027\u548c\u5185\u5bb9\u9690\u79c1\u4fdd\u62a4\u3002\u7531\u4e8e\u52a0\u5bc6\u57df\u4e2d\u5197\u4f59\u4e0d\u8db3\uff0c\u73b0\u6709\u65b9\u6848\u5bf9\u566a\u58f0\u3001\u6709\u635f\u538b\u7f29\u548c\u88c1\u526a\u653b\u51fb\u7684\u9c81\u68d2\u6027\u6709\u9650\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684RRWEI\u6846\u67b6\uff0c\u7ed3\u5408\u53cc\u6700\u9ad8\u6709\u6548\u4f4d\u5e73\u9762\u5d4c\u5165\u4e0e\u7a7a\u95f4\u5197\u4f59\u548c\u7ea0\u9519\u7f16\u7801\u3002\u901a\u8fc7\u538b\u7f29\u9884\u6d4b\u8bef\u5dee\u4f4d\u5e73\u9762\u6765\u9884\u7559\u8db3\u591f\u7684\u5d4c\u5165\u7a7a\u95f4\u548c\u8f85\u52a9\u4fe1\u606f\u7528\u4e8e\u65e0\u635f\u91cd\u5efa\u3002\u91c7\u7528\u87ba\u65cb\u5d4c\u5165\u7b56\u7565\u91cd\u65b0\u7ec4\u7ec7\u53cc\u6700\u9ad8\u6709\u6548\u4f4d\u5e73\u9762\uff0c\u5c06\u591a\u4e2a\u5197\u4f59\u6c34\u5370\u526f\u672c\u5206\u5e03\u5728\u7a7a\u95f4\u5206\u6563\u533a\u57df\u3002", "result": "\u5728\u6807\u51c6\u6d4b\u8bd5\u56fe\u50cf\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u8bc4\u4f30\u8bbe\u7f6e\u4e0b\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5bf9\u9ad8\u65af\u566a\u58f0\u3001JPEG\u538b\u7f29\u548c\u591a\u79cd\u88c1\u526a\u653b\u51fb\u5177\u6709\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u5b8c\u7f8e\u7684\u53ef\u9006\u6027\u548c\u9ad8\u5d4c\u5165\u5bb9\u91cf\u3002\u4e0e\u6700\u5148\u8fdb\u7684RRWEI\u65b9\u6848\u76f8\u6bd4\uff0c\u8be5\u6846\u67b6\u5728\u5e7f\u6cdb\u7684\u653b\u51fb\u573a\u666f\u4e0b\u5b9e\u73b0\u4e86\u663e\u8457\u66f4\u4f4e\u7684\u8bef\u7801\u7387\u548c\u66f4\u7a33\u5b9a\u7684\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u901a\u8fc7\u53cc\u6700\u9ad8\u6709\u6548\u4f4d\u5e73\u9762\u5d4c\u5165\u4e0e\u7a7a\u95f4\u5197\u4f59\u548c\u7ea0\u9519\u7f16\u7801\u7684\u8026\u5408\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u9c81\u68d2\u53ef\u9006\u52a0\u5bc6\u56fe\u50cf\u6c34\u5370\u4e2d\u540c\u65f6\u5b9e\u73b0\u9c81\u68d2\u6027\u3001\u53ef\u9006\u6027\u548c\u5185\u5bb9\u9690\u79c1\u4fdd\u62a4\u7684\u6311\u6218\uff0c\u4e3a\u52a0\u5bc6\u57df\u4e2d\u7684\u9c81\u68d2\u6c34\u5370\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13864", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13864", "abs": "https://arxiv.org/abs/2601.13864", "authors": ["Qirui Chen", "Jingxian Shuai", "Shuangwu Chen", "Shenghao Ye", "Zijian Wen", "Xufei Su", "Jie Jin", "Jiangming Li", "Jun Chen", "Xiaobin Tan", "Jian Yang"], "title": "HardSecBench: Benchmarking the Security Awareness of LLMs for Hardware Code Generation", "comment": null, "summary": "Large language models (LLMs) are being increasingly integrated into practical hardware and firmware development pipelines for code generation. Existing studies have primarily focused on evaluating the functional correctness of LLM-generated code, yet paid limited attention to its security issues. However, LLM-generated code that appears functionally sound may embed security flaws which could induce catastrophic damages after deployment. This critical research gap motivates us to design a benchmark for assessing security awareness under realistic specifications. In this work, we introduce HardSecBench, a benchmark with 924 tasks spanning Verilog Register Transfer Level (RTL) and firmware-level C, covering 76 hardware-relevant Common Weakness Enumeration (CWE) entries. Each task includes a structured specification, a secure reference implementation, and executable tests. To automate artifact synthesis, we propose a multi-agent pipeline that decouples synthesis from verification and grounds evaluation in execution evidence, enabling reliable evaluation. Using HardSecBench, we evaluate a range of LLMs on hardware and firmware code generation and find that models often satisfy functional requirements while still leaving security risks. We also find that security results vary with prompting. These findings highlight pressing challenges and offer actionable insights for future advancements in LLM-assisted hardware design. Our data and code will be released soon.", "AI": {"tldr": "HardSecBench\u662f\u4e00\u4e2a\u5305\u542b924\u4e2a\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6Verilog RTL\u548c\u56fa\u4ef6\u7ea7C\u4ee3\u7801\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u786c\u4ef6\u548c\u56fa\u4ef6\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u5b89\u5168\u610f\u8bc6\u548c\u6f0f\u6d1e\u68c0\u6d4b\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8LLM\u751f\u6210\u4ee3\u7801\u7684\u529f\u80fd\u6b63\u786e\u6027\uff0c\u800c\u5ffd\u89c6\u4e86\u5176\u5b89\u5168\u95ee\u9898\u3002\u529f\u80fd\u4e0a\u770b\u4f3c\u6b63\u786e\u7684LLM\u751f\u6210\u4ee3\u7801\u53ef\u80fd\u5d4c\u5165\u5b89\u5168\u6f0f\u6d1e\uff0c\u90e8\u7f72\u540e\u53ef\u80fd\u9020\u6210\u707e\u96be\u6027\u635f\u5bb3\u3002\u8fd9\u4e00\u5173\u952e\u7814\u7a76\u7a7a\u767d\u4fc3\u4f7f\u7814\u7a76\u8005\u8bbe\u8ba1\u4e00\u4e2a\u5728\u73b0\u5b9e\u89c4\u8303\u4e0b\u8bc4\u4f30\u5b89\u5168\u610f\u8bc6\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "\u63d0\u51faHardSecBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b924\u4e2a\u4efb\u52a1\uff0c\u8986\u76d676\u4e2a\u786c\u4ef6\u76f8\u5173\u7684CWE\u6761\u76ee\u3002\u6bcf\u4e2a\u4efb\u52a1\u5305\u542b\u7ed3\u6784\u5316\u89c4\u8303\u3001\u5b89\u5168\u53c2\u8003\u5b9e\u73b0\u548c\u53ef\u6267\u884c\u6d4b\u8bd5\u3002\u91c7\u7528\u591a\u667a\u80fd\u4f53\u6d41\u6c34\u7ebf\uff0c\u5c06\u5408\u6210\u4e0e\u9a8c\u8bc1\u89e3\u8026\uff0c\u5e76\u5c06\u8bc4\u4f30\u57fa\u4e8e\u6267\u884c\u8bc1\u636e\uff0c\u5b9e\u73b0\u53ef\u9760\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f30\u4e00\u7cfb\u5217LLM\u5728\u786c\u4ef6\u548c\u56fa\u4ef6\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6a21\u578b\u901a\u5e38\u80fd\u6ee1\u8db3\u529f\u80fd\u8981\u6c42\u4f46\u4ecd\u5b58\u5728\u5b89\u5168\u98ce\u9669\u3002\u5b89\u5168\u7ed3\u679c\u968f\u63d0\u793a\u65b9\u5f0f\u800c\u53d8\u5316\uff0c\u7a81\u663e\u4e86LLM\u8f85\u52a9\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u5b58\u5728\u7684\u7d27\u8feb\u6311\u6218\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86LLM\u751f\u6210\u4ee3\u7801\u4e2d\u5b89\u5168\u6f0f\u6d1e\u7684\u91cd\u8981\u6027\uff0cHardSecBench\u4e3a\u8bc4\u4f30LLM\u5728\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u7684\u5b89\u5168\u610f\u8bc6\u63d0\u4f9b\u4e86\u53ef\u9760\u57fa\u51c6\uff0c\u4e3a\u672a\u6765LLM\u8f85\u52a9\u786c\u4ef6\u8bbe\u8ba1\u7684\u8fdb\u6b65\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\u3002"}}
{"id": "2601.12912", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12912", "abs": "https://arxiv.org/abs/2601.12912", "authors": ["Andreas Br\u00e4nnstr\u00f6m", "Juan Carlos Nieves"], "title": "Human Emotion Verification by Action Languages via Answer Set Programming", "comment": "Under consideration in Theory and Practice of Logic Programming (TPLP)", "summary": "In this paper, we introduce the action language C-MT (Mind Transition Language). It is built on top of answer set programming (ASP) and transition systems to represent how human mental states evolve in response to sequences of observable actions. Drawing on well-established psychological theories, such as the Appraisal Theory of Emotion, we formalize mental states, such as emotions, as multi-dimensional configurations. With the objective to address the need for controlled agent behaviors and to restrict unwanted mental side-effects of actions, we extend the language with a novel causal rule, forbids to cause, along with expressions specialized for mental state dynamics, which enables the modeling of principles for valid transitions between mental states. These principles of mental change are translated into transition constraints, and properties of invariance, which are rigorously evaluated using transition systems in terms of so-called trajectories. This enables controlled reasoning about the dynamic evolution of human mental states. Furthermore, the framework supports the comparison of different dynamics of change by analyzing trajectories that adhere to different psychological principles. We apply the action language to design models for emotion verification. Under consideration in Theory and Practice of Logic Programming (TPLP).", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u57fa\u4e8e\u56de\u7b54\u96c6\u7f16\u7a0b\u548c\u8f6c\u79fb\u7cfb\u7edf\u6784\u5efa\u7684\u52a8\u4f5c\u8bed\u8a00C-MT\uff0c\u7528\u4e8e\u5f62\u5f0f\u5316\u4eba\u7c7b\u5fc3\u7406\u72b6\u6001\u5728\u53ef\u89c2\u5bdf\u52a8\u4f5c\u5e8f\u5217\u4e0b\u7684\u6f14\u5316\u8fc7\u7a0b\uff0c\u7279\u522b\u5173\u6ce8\u60c5\u7eea\u7b49\u5fc3\u7406\u72b6\u6001\u7684\u52a8\u6001\u53d8\u5316\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u53ef\u63a7\u667a\u80fd\u4f53\u884c\u4e3a\u7684\u652f\u6301\uff0c\u4e14\u65e0\u6cd5\u9650\u5236\u52a8\u4f5c\u5e26\u6765\u7684\u4e0d\u826f\u5fc3\u7406\u526f\u4f5c\u7528\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5f62\u5f0f\u5316\u5fc3\u7406\u72b6\u6001\u6f14\u5316\u3001\u652f\u6301\u5fc3\u7406\u72b6\u6001\u52a8\u6001\u5efa\u6a21\u7684\u8bed\u8a00\u6846\u67b6\u3002", "method": "\u57fa\u4e8e\u56de\u7b54\u96c6\u7f16\u7a0b\u548c\u8f6c\u79fb\u7cfb\u7edf\u6784\u5efaC-MT\u8bed\u8a00\uff0c\u6574\u5408\u5fc3\u7406\u5b66\u7406\u8bba\uff08\u5982\u60c5\u7eea\u8bc4\u4ef7\u7406\u8bba\uff09\uff0c\u5c06\u5fc3\u7406\u72b6\u6001\u5f62\u5f0f\u5316\u4e3a\u591a\u7ef4\u914d\u7f6e\u3002\u5f15\u5165\u65b0\u9896\u7684\u56e0\u679c\u89c4\u5219\"forbids to cause\"\u548c\u4e13\u95e8\u7684\u5fc3\u7406\u72b6\u6001\u52a8\u6001\u8868\u8fbe\u5f0f\uff0c\u5c06\u5fc3\u7406\u53d8\u5316\u539f\u5219\u8f6c\u5316\u4e3a\u8f6c\u79fb\u7ea6\u675f\u548c\u4e0d\u53d8\u6027\u5c5e\u6027\u3002", "result": "C-MT\u8bed\u8a00\u80fd\u591f\u5bf9\u5fc3\u7406\u72b6\u6001\u7684\u52a8\u6001\u6f14\u5316\u8fdb\u884c\u53ef\u63a7\u63a8\u7406\uff0c\u652f\u6301\u901a\u8fc7\u8f68\u8ff9\u5206\u6790\u6bd4\u8f83\u4e0d\u540c\u7684\u5fc3\u7406\u53d8\u5316\u52a8\u6001\uff0c\u5e76\u5e94\u7528\u4e8e\u60c5\u7eea\u9a8c\u8bc1\u6a21\u578b\u7684\u8bbe\u8ba1\u3002", "conclusion": "C-MT\u4e3a\u5f62\u5f0f\u5316\u4eba\u7c7b\u5fc3\u7406\u72b6\u6001\u6f14\u5316\u63d0\u4f9b\u4e86\u4e00\u4e2a\u57fa\u4e8e\u56de\u7b54\u96c6\u7f16\u7a0b\u7684\u6846\u67b6\uff0c\u80fd\u591f\u5efa\u6a21\u5fc3\u7406\u72b6\u6001\u52a8\u6001\u53d8\u5316\u539f\u5219\uff0c\u652f\u6301\u53ef\u63a7\u63a8\u7406\u548c\u4e0d\u540c\u5fc3\u7406\u5b66\u539f\u5219\u7684\u6bd4\u8f83\u5206\u6790\u3002"}}
{"id": "2601.12913", "categories": ["cs.AI", "cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.12913", "abs": "https://arxiv.org/abs/2601.12913", "authors": ["Pietro Barbiero", "Mateo Espinosa Zarlenga", "Francesco Giannini", "Alberto Termine", "Filippo Bonchi", "Mateja Jamnik", "Giuseppe Marra"], "title": "Actionable Interpretability Must Be Defined in Terms of Symmetries", "comment": null, "summary": "This paper argues that interpretability research in Artificial Intelligence is fundamentally ill-posed as existing definitions of interpretability are not *actionable*: they fail to provide formal principles from which concrete modelling and inferential rules can be derived. We posit that for a definition of interpretability to be actionable, it must be given in terms of *symmetries*. We hypothesise that four symmetries suffice to (i) motivate core interpretability properties, (ii) characterize the class of interpretable models, and (iii) derive a unified formulation of interpretable inference (e.g., alignment, interventions, and counterfactuals) as a form of Bayesian inversion.", "AI": {"tldr": "\u8bba\u6587\u8ba4\u4e3a\u5f53\u524dAI\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u5b58\u5728\u6839\u672c\u6027\u95ee\u9898\uff0c\u56e0\u4e3a\u73b0\u6709\u5b9a\u4e49\u7f3a\u4e4f\u53ef\u64cd\u4f5c\u6027\uff0c\u65e0\u6cd5\u63a8\u5bfc\u51fa\u5177\u4f53\u7684\u5efa\u6a21\u548c\u63a8\u7406\u89c4\u5219\u3002\u4f5c\u8005\u63d0\u51fa\u57fa\u4e8e\u5bf9\u79f0\u6027\u7684\u5b9a\u4e49\u6846\u67b6\uff0c\u8ba4\u4e3a\u56db\u79cd\u5bf9\u79f0\u6027\u8db3\u4ee5\u89e3\u51b3\u53ef\u89e3\u91ca\u6027\u6838\u5fc3\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u4eba\u5de5\u667a\u80fd\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u5b58\u5728\u6839\u672c\u6027\u7f3a\u9677\uff0c\u56e0\u4e3a\u73b0\u6709\u7684\u53ef\u89e3\u91ca\u6027\u5b9a\u4e49\u7f3a\u4e4f\u53ef\u64cd\u4f5c\u6027\u3002\u8fd9\u4e9b\u5b9a\u4e49\u672a\u80fd\u63d0\u4f9b\u5f62\u5f0f\u5316\u539f\u5219\uff0c\u65e0\u6cd5\u4ece\u4e2d\u63a8\u5bfc\u51fa\u5177\u4f53\u7684\u5efa\u6a21\u548c\u63a8\u7406\u89c4\u5219\uff0c\u5bfc\u81f4\u7814\u7a76\u96be\u4ee5\u53d6\u5f97\u5b9e\u8d28\u6027\u8fdb\u5c55\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5bf9\u79f0\u6027\u7684\u53ef\u89e3\u91ca\u6027\u5b9a\u4e49\u6846\u67b6\u3002\u4f5c\u8005\u5047\u8bbe\u56db\u79cd\u5bf9\u79f0\u6027\u8db3\u4ee5\uff1a(1) \u6fc0\u53d1\u6838\u5fc3\u53ef\u89e3\u91ca\u6027\u5c5e\u6027\uff1b(2) \u523b\u753b\u53ef\u89e3\u91ca\u6a21\u578b\u7684\u7c7b\u522b\uff1b(3) \u63a8\u5bfc\u7edf\u4e00\u7684\u53ef\u89e3\u91ca\u63a8\u7406\u5f62\u5f0f\uff08\u5982\u5bf9\u9f50\u3001\u5e72\u9884\u548c\u53cd\u4e8b\u5b9e\u63a8\u7406\uff09\uff0c\u5c06\u5176\u89c6\u4e3a\u8d1d\u53f6\u65af\u9006\u95ee\u9898\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5bf9\u79f0\u6027\u7684\u53ef\u89e3\u91ca\u6027\u7406\u8bba\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u4e3a\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u5b9a\u4e49\uff0c\u5e76\u7edf\u4e00\u89e3\u91ca\u5bf9\u9f50\u3001\u5e72\u9884\u548c\u53cd\u4e8b\u5b9e\u63a8\u7406\u7b49\u6982\u5ff5\uff0c\u4e3a\u53ef\u89e3\u91caAI\u7814\u7a76\u63d0\u4f9b\u5f62\u5f0f\u5316\u57fa\u7840\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u5bf9\u79f0\u6027\u6982\u5ff5\uff0c\u53ef\u4ee5\u6784\u5efa\u53ef\u64cd\u4f5c\u7684\u53ef\u89e3\u91ca\u6027\u5b9a\u4e49\uff0c\u89e3\u51b3\u5f53\u524d\u7814\u7a76\u4e2d\u7684\u6839\u672c\u95ee\u9898\uff0c\u4e3a\u53ef\u89e3\u91caAI\u63d0\u4f9b\u7edf\u4e00\u7684\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u8df5\u6307\u5bfc\u3002"}}
{"id": "2601.13907", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.13907", "abs": "https://arxiv.org/abs/2601.13907", "authors": ["Cosmin-Iulian Irimia"], "title": "Decentralized Infrastructure for Digital Notarizing, Signing and Sharing Files using Blockchain", "comment": "182 pages, PhD thesis", "summary": "Traditional paper-based document management has long posed challenges related to security, authenticity, and efficiency. Despite advances in digitalization, official documents remain vulnerable to forgery, loss, and unauthorized access. This thesis proposes a decentralized infrastructure for digital notarization, signing, and sharing of documents using blockchain technology. The research addresses key issues of transparency, immutability, and feasibility by defining system requirements, evaluating existing solutions, and proposing a novel architecture based on distributed systems.\n  By combining cryptographic techniques with decentralized storage, this research contributes to the development of a more secure and efficient framework for managing official documents. The findings highlight the potential of blockchain-based digital notarization to streamline bureaucratic processes, mitigate security risks, and enhance user trust in digital document management.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u57fa\u4e8e\u533a\u5757\u94fe\u6280\u672f\u7684\u53bb\u4e2d\u5fc3\u5316\u6570\u5b57\u516c\u8bc1\u3001\u7b7e\u7f72\u548c\u5171\u4eab\u6587\u6863\u57fa\u7840\u8bbe\u65bd\uff0c\u89e3\u51b3\u4f20\u7edf\u7eb8\u8d28\u6587\u6863\u7ba1\u7406\u4e2d\u7684\u5b89\u5168\u3001\u771f\u5b9e\u6027\u548c\u6548\u7387\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u7eb8\u8d28\u6587\u6863\u7ba1\u7406\u5b58\u5728\u5b89\u5168\u3001\u771f\u5b9e\u6027\u548c\u6548\u7387\u65b9\u9762\u7684\u6311\u6218\uff0c\u5373\u4f7f\u6570\u5b57\u5316\u540e\uff0c\u5b98\u65b9\u6587\u6863\u4ecd\u9762\u4e34\u4f2a\u9020\u3001\u4e22\u5931\u548c\u672a\u7ecf\u6388\u6743\u8bbf\u95ee\u7684\u8106\u5f31\u6027\u3002", "method": "\u901a\u8fc7\u5b9a\u4e49\u7cfb\u7edf\u9700\u6c42\u3001\u8bc4\u4f30\u73b0\u6709\u89e3\u51b3\u65b9\u6848\uff0c\u63d0\u51fa\u57fa\u4e8e\u5206\u5e03\u5f0f\u7cfb\u7edf\u7684\u65b0\u578b\u67b6\u6784\uff0c\u7ed3\u5408\u5bc6\u7801\u5b66\u6280\u672f\u548c\u53bb\u4e2d\u5fc3\u5316\u5b58\u50a8\u3002", "result": "\u7814\u7a76\u4e3a\u7ba1\u7406\u5b98\u65b9\u6587\u6863\u5f00\u53d1\u4e86\u66f4\u5b89\u5168\u9ad8\u6548\u7684\u6846\u67b6\uff0c\u5c55\u793a\u4e86\u533a\u5757\u94fe\u6570\u5b57\u516c\u8bc1\u5728\u7b80\u5316\u5b98\u50da\u6d41\u7a0b\u3001\u964d\u4f4e\u5b89\u5168\u98ce\u9669\u548c\u589e\u5f3a\u7528\u6237\u4fe1\u4efb\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "\u533a\u5757\u94fe\u6280\u672f\u80fd\u591f\u4e3a\u6570\u5b57\u6587\u6863\u7ba1\u7406\u63d0\u4f9b\u900f\u660e\u3001\u4e0d\u53ef\u7be1\u6539\u4e14\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u6587\u6863\u7ba1\u7406\u7684\u5b89\u5168\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2601.13981", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.13981", "abs": "https://arxiv.org/abs/2601.13981", "authors": ["Yilin Tang", "Yu Wang", "Lanlan Qiu", "Wenchang Gao", "Yunfei Ma", "Baicheng Chen", "Tianxing He"], "title": "VirtualCrime: Evaluating Criminal Potential of Large Language Models via Sandbox Simulation", "comment": null, "summary": "Large language models (LLMs) have shown strong capabilities in multi-step decision-making, planning and actions, and are increasingly integrated into various real-world applications. It is concerning whether their strong problem-solving abilities may be misused for crimes. To address this gap, we propose VirtualCrime, a sandbox simulation framework based on a three-agent system to evaluate the criminal capabilities of models. Specifically, this framework consists of an attacker agent acting as the leader of a criminal team, a judge agent determining the outcome of each action, and a world manager agent updating the environment state and entities. Furthermore, we design 40 diverse crime tasks within this framework, covering 11 maps and 13 crime objectives such as theft, robbery, kidnapping, and riot. We also introduce a human player baseline for reference to better interpret the performance of LLM agents. We evaluate 8 strong LLMs and find (1) All agents in the simulation environment compliantly generate detailed plans and execute intelligent crime processes, with some achieving relatively high success rates; (2) In some cases, agents take severe action that inflicts harm to NPCs to achieve their goals. Our work highlights the need for safety alignment when deploying agentic AI in real-world settings.", "AI": {"tldr": "VirtualCrime\u662f\u4e00\u4e2a\u57fa\u4e8e\u4e09\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6c99\u76d2\u6a21\u62df\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u72af\u7f6a\u80fd\u529b\uff0c\u5305\u542b40\u4e2a\u591a\u6837\u5316\u72af\u7f6a\u4efb\u52a1\uff0c\u53d1\u73b0LLM\u80fd\u591f\u751f\u6210\u8be6\u7ec6\u72af\u7f6a\u8ba1\u5212\u5e76\u6267\u884c\u667a\u80fd\u72af\u7f6a\u8fc7\u7a0b\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6b65\u51b3\u7b56\u3001\u89c4\u5212\u548c\u884c\u52a8\u65b9\u9762\u5c55\u73b0\u51fa\u5f3a\u5927\u80fd\u529b\uff0c\u5e76\u8d8a\u6765\u8d8a\u591a\u5730\u96c6\u6210\u5230\u73b0\u5b9e\u5e94\u7528\u4e2d\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u5f3a\u5927\u7684\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u662f\u5426\u53ef\u80fd\u88ab\u6ee5\u7528\u4e8e\u72af\u7f6a\u6d3b\u52a8\u3002", "method": "\u63d0\u51faVirtualCrime\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u667a\u80fd\u4f53\uff1a\u653b\u51fb\u8005\u667a\u80fd\u4f53\uff08\u72af\u7f6a\u56e2\u961f\u9886\u5bfc\u8005\uff09\u3001\u6cd5\u5b98\u667a\u80fd\u4f53\uff08\u786e\u5b9a\u6bcf\u4e2a\u884c\u52a8\u7ed3\u679c\uff09\u3001\u4e16\u754c\u7ba1\u7406\u5668\u667a\u80fd\u4f53\uff08\u66f4\u65b0\u73af\u5883\u72b6\u6001\u548c\u5b9e\u4f53\uff09\u3002\u8bbe\u8ba1\u4e8640\u4e2a\u591a\u6837\u5316\u72af\u7f6a\u4efb\u52a1\uff0c\u8986\u76d611\u4e2a\u5730\u56fe\u548c13\u79cd\u72af\u7f6a\u76ee\u6807\uff08\u5982\u76d7\u7a83\u3001\u62a2\u52ab\u3001\u7ed1\u67b6\u3001\u66b4\u4e71\uff09\uff0c\u5e76\u5f15\u5165\u4eba\u7c7b\u73a9\u5bb6\u57fa\u7ebf\u4f5c\u4e3a\u53c2\u8003\u3002", "result": "\u8bc4\u4f30\u4e868\u4e2a\u5f3a\u5927\u7684LLM\uff0c\u53d1\u73b0\uff1a(1)\u6240\u6709\u667a\u80fd\u4f53\u5728\u6a21\u62df\u73af\u5883\u4e2d\u90fd\u80fd\u5408\u89c4\u5730\u751f\u6210\u8be6\u7ec6\u8ba1\u5212\u5e76\u6267\u884c\u667a\u80fd\u72af\u7f6a\u8fc7\u7a0b\uff0c\u90e8\u5206\u6a21\u578b\u53d6\u5f97\u76f8\u5bf9\u8f83\u9ad8\u7684\u6210\u529f\u7387\uff1b(2)\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u667a\u80fd\u4f53\u4f1a\u91c7\u53d6\u4e25\u91cd\u4f24\u5bb3NPC\u7684\u884c\u52a8\u6765\u5b9e\u73b0\u76ee\u6807\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5f3a\u8c03\u4e86\u5728\u73b0\u5b9e\u4e16\u754c\u90e8\u7f72\u667a\u80fdAI\u65f6\u9700\u8981\u52a0\u5f3a\u5b89\u5168\u5bf9\u9f50\u7684\u91cd\u8981\u6027\uff0c\u63ed\u793a\u4e86LLM\u53ef\u80fd\u88ab\u6ee5\u7528\u4e8e\u72af\u7f6a\u6d3b\u52a8\u7684\u6f5c\u5728\u98ce\u9669\u3002"}}
{"id": "2601.13122", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13122", "abs": "https://arxiv.org/abs/2601.13122", "authors": ["Gourab K Patro", "Himanshi Agrawal", "Himanshu Gharat", "Supriya Panigrahi", "Nim Sherpa", "Vishal Vaddina", "Dagnachew Birru"], "title": "Responsible AI for General-Purpose Systems: Overview, Challenges, and A Path Forward", "comment": null, "summary": "Modern general-purpose AI systems made using large language and vision models, are capable of performing a range of tasks like writing text articles, generating and debugging codes, querying databases, and translating from one language to another, which has made them quite popular across industries. However, there are risks like hallucinations, toxicity, and stereotypes in their output that make them untrustworthy. We review various risks and vulnerabilities of modern general-purpose AI along eight widely accepted responsible AI (RAI) principles (fairness, privacy, explainability, robustness, safety, truthfulness, governance, and sustainability) and compare how they are non-existent or less severe and easily mitigable in traditional task-specific counterparts. We argue that this is due to the non-deterministically high Degree of Freedom in output (DoFo) of general-purpose AI (unlike the deterministically constant or low DoFo of traditional task-specific AI systems), and there is a need to rethink our approach to RAI for general-purpose AI. Following this, we derive C2V2 (Control, Consistency, Value, Veracity) desiderata to meet the RAI requirements for future general-purpose AI systems, and discuss how recent efforts in AI alignment, retrieval-augmented generation, reasoning enhancements, etc. fare along one or more of the desiderata. We believe that the goal of developing responsible general-purpose AI can be achieved by formally modeling application- or domain-dependent RAI requirements along C2V2 dimensions, and taking a system design approach to suitably combine various techniques to meet the desiderata.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u73b0\u4ee3\u901a\u7528AI\u7cfb\u7edf\u76f8\u6bd4\u4f20\u7edf\u4efb\u52a1\u7279\u5b9aAI\u5728\u8d1f\u8d23\u4efbAI\u539f\u5219\u4e0a\u9762\u4e34\u7684\u66f4\u5927\u98ce\u9669\uff0c\u63d0\u51fa\u4e86C2V2\uff08\u63a7\u5236\u3001\u4e00\u81f4\u6027\u3001\u4ef7\u503c\u3001\u771f\u5b9e\u6027\uff09\u6846\u67b6\u6765\u6307\u5bfc\u672a\u6765\u901a\u7528AI\u7cfb\u7edf\u7684\u8d1f\u8d23\u4efb\u5f00\u53d1\u3002", "motivation": "\u73b0\u4ee3\u901a\u7528AI\u7cfb\u7edf\uff08\u5982\u5927\u578b\u8bed\u8a00\u548c\u89c6\u89c9\u6a21\u578b\uff09\u867d\u7136\u529f\u80fd\u5f3a\u5927\uff0c\u4f46\u5728\u5e7b\u89c9\u3001\u6bd2\u6027\u3001\u523b\u677f\u5370\u8c61\u7b49\u65b9\u9762\u5b58\u5728\u98ce\u9669\uff0c\u4f7f\u5176\u4e0d\u53ef\u4fe1\u3002\u4f5c\u8005\u65e8\u5728\u5206\u6790\u8fd9\u4e9b\u98ce\u9669\uff0c\u5e76\u4e0e\u4f20\u7edf\u4efb\u52a1\u7279\u5b9aAI\u7cfb\u7edf\u8fdb\u884c\u6bd4\u8f83\uff0c\u63d0\u51fa\u6539\u8fdb\u901a\u7528AI\u7cfb\u7edf\u8d1f\u8d23\u4efb\u6027\u7684\u65b0\u6846\u67b6\u3002", "method": "\u4ece\u516b\u4e2a\u5e7f\u6cdb\u63a5\u53d7\u7684\u8d1f\u8d23\u4efbAI\u539f\u5219\uff08\u516c\u5e73\u6027\u3001\u9690\u79c1\u6027\u3001\u53ef\u89e3\u91ca\u6027\u3001\u9c81\u68d2\u6027\u3001\u5b89\u5168\u6027\u3001\u771f\u5b9e\u6027\u3001\u6cbb\u7406\u3001\u53ef\u6301\u7eed\u6027\uff09\u51fa\u53d1\uff0c\u5206\u6790\u73b0\u4ee3\u901a\u7528AI\u7cfb\u7edf\u7684\u98ce\u9669\u548c\u6f0f\u6d1e\u3002\u63d0\u51fa\u8f93\u51fa\u81ea\u7531\u5ea6\uff08DoFo\uff09\u6982\u5ff5\u6765\u89e3\u91ca\u98ce\u9669\u5dee\u5f02\uff0c\u5e76\u63a8\u5bfc\u51faC2V2\uff08\u63a7\u5236\u3001\u4e00\u81f4\u6027\u3001\u4ef7\u503c\u3001\u771f\u5b9e\u6027\uff09\u9700\u6c42\u6846\u67b6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u901a\u7528AI\u7cfb\u7edf\u7531\u4e8e\u8f93\u51fa\u81ea\u7531\u5ea6\uff08DoFo\uff09\u975e\u786e\u5b9a\u6027\u5730\u9ad8\uff0c\u76f8\u6bd4\u4f20\u7edf\u4efb\u52a1\u7279\u5b9aAI\u7cfb\u7edf\u5728\u8d1f\u8d23\u4efbAI\u539f\u5219\u4e0a\u9762\u4e34\u66f4\u4e25\u91cd\u4e14\u96be\u4ee5\u7f13\u89e3\u7684\u98ce\u9669\u3002C2V2\u6846\u67b6\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdbAI\u5bf9\u9f50\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u3001\u63a8\u7406\u589e\u5f3a\u7b49\u6280\u672f\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u6307\u5bfc\u3002", "conclusion": "\u5f00\u53d1\u8d1f\u8d23\u4efb\u901a\u7528AI\u9700\u8981\u901a\u8fc7C2V2\u7ef4\u5ea6\u5f62\u5f0f\u5316\u5efa\u6a21\u5e94\u7528\u6216\u9886\u57df\u76f8\u5173\u7684\u8d1f\u8d23\u4efbAI\u9700\u6c42\uff0c\u5e76\u91c7\u7528\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u6cd5\u7ed3\u5408\u5404\u79cd\u6280\u672f\u6765\u6ee1\u8db3\u8fd9\u4e9b\u9700\u6c42\u3002\u8fd9\u662f\u5b9e\u73b0\u901a\u7528AI\u7cfb\u7edf\u8d1f\u8d23\u4efb\u6027\u7684\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2601.14019", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.14019", "abs": "https://arxiv.org/abs/2601.14019", "authors": ["Frederik Walter", "Hrishi Narayanan", "Jessica Bariffi", "Anne L\u00fcscher", "Rawad Bitar", "Robert Grass", "Antonia Wachter-Zeh", "Zohar Yakhini"], "title": "A Security Framework for Chemical Functions", "comment": null, "summary": "In this paper, we introduce chemical functions, a unified framework that models chemical systems as noisy challenge--response primitives, and formalize the associated chemical function infrastructure. Building on the theory of physical functions, we rigorously define robustness, unclonability, and unpredictability for chemical functions in both finite and asymptotic regimes, and specify security games that capture the adversary's power and the security goals. We instantiate the framework with two existing DNA-based constructions (operable random DNA and Genomic Sequence Encryption) and derive quantitative bounds for robustness, unclonability, and unpredictability. Our analysis develops maximum-likelihood verification rules under sequencing noise and partial-edit models, and provides high-precision estimates based on binomial distributions to guide parameter selection. The framework, definitions, and analyses yield a reproducible methodology for designing chemically unclonable authentication mechanisms. We demonstrate applications to in-product authentication and to shared key generation using standard extraction techniques.", "AI": {"tldr": "\u63d0\u51fa\u5316\u5b66\u51fd\u6570\u6846\u67b6\uff0c\u5c06\u5316\u5b66\u7cfb\u7edf\u5efa\u6a21\u4e3a\u566a\u58f0\u6311\u6218-\u54cd\u5e94\u539f\u8bed\uff0c\u5f62\u5f0f\u5316\u5b9a\u4e49\u9c81\u68d2\u6027\u3001\u4e0d\u53ef\u514b\u9686\u6027\u548c\u4e0d\u53ef\u9884\u6d4b\u6027\uff0c\u5e76\u5e94\u7528\u4e8eDNA\u57fa\u8ba4\u8bc1\u673a\u5236", "motivation": "\u4e3a\u5316\u5b66\u7cfb\u7edf\u63d0\u4f9b\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\u6765\u5efa\u6a21\u8ba4\u8bc1\u673a\u5236\uff0c\u89e3\u51b3\u5316\u5b66\u7cfb\u7edf\u4e2d\u5b89\u5168\u7279\u6027\u7684\u5f62\u5f0f\u5316\u5b9a\u4e49\u548c\u5206\u6790\u95ee\u9898", "method": "\u57fa\u4e8e\u7269\u7406\u51fd\u6570\u7406\u8bba\uff0c\u5728\u6709\u9650\u548c\u6e10\u8fdb\u4e24\u79cd\u72b6\u6001\u4e0b\u5b9a\u4e49\u5316\u5b66\u51fd\u6570\u7684\u9c81\u68d2\u6027\u3001\u4e0d\u53ef\u514b\u9686\u6027\u548c\u4e0d\u53ef\u9884\u6d4b\u6027\uff0c\u5efa\u7acb\u5b89\u5168\u535a\u5f08\u6a21\u578b\uff0c\u5e76\u7528\u73b0\u6709DNA\u7ed3\u6784\u5b9e\u4f8b\u5316", "result": "\u5f00\u53d1\u4e86\u5728\u6d4b\u5e8f\u566a\u58f0\u548c\u90e8\u5206\u7f16\u8f91\u6a21\u578b\u4e0b\u7684\u6700\u5927\u4f3c\u7136\u9a8c\u8bc1\u89c4\u5219\uff0c\u57fa\u4e8e\u4e8c\u9879\u5206\u5e03\u63d0\u4f9b\u9ad8\u7cbe\u5ea6\u53c2\u6570\u9009\u62e9\u6307\u5bfc\uff0c\u5efa\u7acb\u4e86\u53ef\u590d\u73b0\u7684\u5316\u5b66\u4e0d\u53ef\u514b\u9686\u8ba4\u8bc1\u8bbe\u8ba1\u65b9\u6cd5", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u8bbe\u8ba1\u5316\u5b66\u4e0d\u53ef\u514b\u9686\u8ba4\u8bc1\u673a\u5236\u63d0\u4f9b\u4e86\u7cfb\u7edf\u65b9\u6cd5\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u4ea7\u54c1\u8ba4\u8bc1\u548c\u5171\u4eab\u5bc6\u94a5\u751f\u6210\u4e2d\u7684\u5e94\u7528\u6f5c\u529b"}}
{"id": "2601.13186", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.13186", "abs": "https://arxiv.org/abs/2601.13186", "authors": ["Diego Gosmar", "Deborah A. Dahl"], "title": "Prompt Injection Mitigation with Agentic AI, Nested Learning, and AI Sustainability via Semantic Caching", "comment": "33 pages, 19 figures", "summary": "Prompt injection remains a central obstacle to the safe deployment of large language models, particularly in multi-agent settings where intermediate outputs can propagate or amplify malicious instructions. Building on earlier work that introduced a four-metric Total Injection Vulnerability Score (TIVS), this paper extends the evaluation framework with semantic similarity-based caching and a fifth metric (Observability Score Ratio) to yield TIVS-O, investigating how defence effectiveness interacts with transparency in a HOPE-inspired Nested Learning architecture. The proposed system combines an agentic pipeline with Continuum Memory Systems that implement semantic similarity-based caching across 301 synthetically generated injection-focused prompts drawn from ten attack families, while a fourth agent performs comprehensive security analysis using five key performance indicators. In addition to traditional injection metrics, OSR quantifies the richness and clarity of security-relevant reasoning exposed by each agent, enabling an explicit analysis of trade-offs between strict mitigation and auditability. Experiments show that the system achieves secure responses with zero high-risk breaches, while semantic caching delivers substantial computational savings, achieving a 41.6% reduction in LLM calls and corresponding decreases in latency, energy consumption, and carbon emissions. Five TIVS-O configurations reveal optimal trade-offs between mitigation strictness and forensic transparency. These results indicate that observability-aware evaluation can reveal non-monotonic effects within multi-agent pipelines and that memory-augmented agents can jointly maximize security robustness, real-time performance, operational cost savings, and environmental sustainability without modifying underlying model weights, providing a production-ready pathway for secure and green LLM deployments.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86TIVS\u8bc4\u4f30\u6846\u67b6\uff0c\u52a0\u5165\u8bed\u4e49\u76f8\u4f3c\u6027\u7f13\u5b58\u548c\u53ef\u89c2\u6d4b\u6027\u8bc4\u5206\u6bd4\uff0c\u63d0\u51faTIVS-O\u7cfb\u7edf\uff0c\u5728\u591a\u667a\u80fd\u4f53\u67b6\u6784\u4e2d\u5b9e\u73b0\u96f6\u9ad8\u98ce\u9669\u6f0f\u6d1e\uff0c\u540c\u65f6\u51cf\u5c1141.6%\u7684LLM\u8c03\u7528\u5e76\u964d\u4f4e\u80fd\u8017\u3002", "motivation": "\u63d0\u793a\u6ce8\u5165\u4ecd\u7136\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u90e8\u7f72\u7684\u4e3b\u8981\u969c\u788d\uff0c\u7279\u522b\u662f\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\uff0c\u4e2d\u95f4\u8f93\u51fa\u53ef\u80fd\u4f20\u64ad\u6216\u653e\u5927\u6076\u610f\u6307\u4ee4\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u6709\u6548\u9632\u5fa1\u53c8\u80fd\u4fdd\u6301\u5ba1\u8ba1\u900f\u660e\u5ea6\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u63d0\u51faTIVS-O\u7cfb\u7edf\uff0c\u7ed3\u5408\u8bed\u4e49\u76f8\u4f3c\u6027\u7f13\u5b58\u548c\u53ef\u89c2\u6d4b\u6027\u8bc4\u5206\u6bd4\uff0c\u91c7\u7528HOPE\u542f\u53d1\u7684\u5d4c\u5957\u5b66\u4e60\u67b6\u6784\uff0c\u4f7f\u7528301\u4e2a\u5408\u6210\u751f\u6210\u7684\u6ce8\u5165\u63d0\u793a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u901a\u8fc7\u56db\u4e2a\u667a\u80fd\u4f53\u7ba1\u9053\u548c\u8fde\u7eed\u8bb0\u5fc6\u7cfb\u7edf\u5b9e\u73b0\u5b89\u5168\u5206\u6790\u3002", "result": "\u7cfb\u7edf\u5b9e\u73b0\u96f6\u9ad8\u98ce\u9669\u6f0f\u6d1e\u7684\u5b89\u5168\u54cd\u5e94\uff0c\u8bed\u4e49\u7f13\u5b58\u51cf\u5c1141.6%\u7684LLM\u8c03\u7528\uff0c\u964d\u4f4e\u5ef6\u8fdf\u3001\u80fd\u8017\u548c\u78b3\u6392\u653e\u3002TIVS-O\u7684\u4e94\u79cd\u914d\u7f6e\u63ed\u793a\u4e86\u7f13\u89e3\u4e25\u683c\u6027\u548c\u53d6\u8bc1\u900f\u660e\u5ea6\u4e4b\u95f4\u7684\u6700\u4f18\u6743\u8861\u3002", "conclusion": "\u53ef\u89c2\u6d4b\u6027\u611f\u77e5\u8bc4\u4f30\u80fd\u63ed\u793a\u591a\u667a\u80fd\u4f53\u7ba1\u9053\u4e2d\u7684\u975e\u5355\u8c03\u6548\u5e94\uff0c\u5185\u5b58\u589e\u5f3a\u7684\u667a\u80fd\u4f53\u53ef\u540c\u65f6\u6700\u5927\u5316\u5b89\u5168\u9c81\u68d2\u6027\u3001\u5b9e\u65f6\u6027\u80fd\u3001\u8fd0\u8425\u6210\u672c\u8282\u7ea6\u548c\u73af\u5883\u53ef\u6301\u7eed\u6027\uff0c\u4e3a\u5b89\u5168\u548c\u7eff\u8272\u7684LLM\u90e8\u7f72\u63d0\u4f9b\u751f\u4ea7\u5c31\u7eea\u8def\u5f84\u3002"}}
{"id": "2601.13206", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13206", "abs": "https://arxiv.org/abs/2601.13206", "authors": ["Neil K. R. Sehgal", "Sharath Chandra Guntuku", "Lyle Ungar"], "title": "Real-Time Deadlines Reveal Temporal Awareness Failures in LLM Strategic Dialogues", "comment": null, "summary": "Large Language Models (LLMs) generate text token-by-token in discrete time, yet real-world communication, from therapy sessions to business negotiations, critically depends on continuous time constraints. Current LLM architectures and evaluation protocols rarely test for temporal awareness under real-time deadlines. We use simulated negotiations between paired agents under strict deadlines to investigate how LLMs adjust their behavior in time-sensitive settings. In a control condition, agents know only the global time limit. In a time-aware condition, they receive remaining-time updates at each turn. Deal closure rates are substantially higher (32\\% vs. 4\\% for GPT-5.1) and offer acceptances are sixfold higher in the time-aware condition than in the control, suggesting LLMs struggle to internally track elapsed time. However, the same LLMs achieve near-perfect deal closure rates ($\\geq$95\\%) under turn-based limits, revealing the failure is in temporal tracking rather than strategic reasoning. These effects replicate across negotiation scenarios and models, illustrating a systematic lack of LLM time awareness that will constrain LLM deployment in many time-sensitive applications.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5b9e\u65f6\u622a\u6b62\u671f\u9650\u4e0b\u7684\u65f6\u95f4\u610f\u8bc6\u5b58\u5728\u7cfb\u7edf\u6027\u7f3a\u9677\uff0c\u65f6\u95f4\u611f\u77e5\u6761\u4ef6\u80fd\u663e\u8457\u63d0\u9ad8\u8c08\u5224\u6210\u529f\u7387", "motivation": "\u73b0\u5b9e\u4e16\u754c\u6c9f\u901a\uff08\u4ece\u6cbb\u7597\u5230\u5546\u4e1a\u8c08\u5224\uff09\u90fd\u4f9d\u8d56\u8fde\u7eed\u65f6\u95f4\u7ea6\u675f\uff0c\u800c\u5f53\u524dLLM\u67b6\u6784\u548c\u8bc4\u4f30\u534f\u8bae\u5f88\u5c11\u6d4b\u8bd5\u5b9e\u65f6\u622a\u6b62\u671f\u9650\u4e0b\u7684\u65f6\u95f4\u610f\u8bc6", "method": "\u4f7f\u7528\u6a21\u62df\u8c08\u5224\u5b9e\u9a8c\uff0c\u5728\u4e25\u683c\u622a\u6b62\u671f\u9650\u4e0b\u914d\u5bf9\u667a\u80fd\u4f53\u8fdb\u884c\u8c08\u5224\uff0c\u8bbe\u7f6e\u63a7\u5236\u6761\u4ef6\uff08\u4ec5\u77e5\u5168\u5c40\u65f6\u95f4\u9650\u5236\uff09\u548c\u65f6\u95f4\u611f\u77e5\u6761\u4ef6\uff08\u6bcf\u8f6e\u63a5\u6536\u5269\u4f59\u65f6\u95f4\u66f4\u65b0\uff09", "result": "\u65f6\u95f4\u611f\u77e5\u6761\u4ef6\u4e0b\u4ea4\u6613\u8fbe\u6210\u7387\u663e\u8457\u66f4\u9ad8\uff08GPT-5.1\u4e3a32% vs 4%\uff09\uff0c\u62a5\u4ef7\u63a5\u53d7\u7387\u63d0\u9ad8\u516d\u500d\uff1b\u4f46\u5728\u8f6e\u6b21\u9650\u5236\u4e0bLLM\u80fd\u8fbe\u5230\u63a5\u8fd1\u5b8c\u7f8e\u7684\u4ea4\u6613\u8fbe\u6210\u7387\uff08\u226595%\uff09", "conclusion": "LLM\u5728\u65f6\u95f4\u8ddf\u8e2a\u65b9\u9762\u5b58\u5728\u7cfb\u7edf\u6027\u7f3a\u9677\u800c\u975e\u6218\u7565\u63a8\u7406\u95ee\u9898\uff0c\u8fd9\u9650\u5236\u4e86LLM\u5728\u8bb8\u591a\u65f6\u95f4\u654f\u611f\u5e94\u7528\u4e2d\u7684\u90e8\u7f72"}}
{"id": "2601.14054", "categories": ["cs.CR", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14054", "abs": "https://arxiv.org/abs/2601.14054", "authors": ["Zhihao Dou", "Dongfei Cui", "Weida Wang", "Anjun Gao", "Yueyang Quan", "Mengyao Ma", "Viet Vo", "Guangdong Bai", "Zhuqing Liu", "Minghong Fang"], "title": "SecureSplit: Mitigating Backdoor Attacks in Split Learning", "comment": "To appear in The Web Conference 2026", "summary": "Split Learning (SL) offers a framework for collaborative model training that respects data privacy by allowing participants to share the same dataset while maintaining distinct feature sets. However, SL is susceptible to backdoor attacks, in which malicious clients subtly alter their embeddings to insert hidden triggers that compromise the final trained model. To address this vulnerability, we introduce SecureSplit, a defense mechanism tailored to SL. SecureSplit applies a dimensionality transformation strategy to accentuate subtle differences between benign and poisoned embeddings, facilitating their separation. With this enhanced distinction, we develop an adaptive filtering approach that uses a majority-based voting scheme to remove contaminated embeddings while preserving clean ones. Rigorous experiments across four datasets (CIFAR-10, MNIST, CINIC-10, and ImageNette), five backdoor attack scenarios, and seven alternative defenses confirm the effectiveness of SecureSplit under various challenging conditions.", "AI": {"tldr": "SecureSplit\u662f\u4e00\u79cd\u9488\u5bf9\u5206\u5272\u5b66\u4e60\u4e2d\u540e\u95e8\u653b\u51fb\u7684\u9632\u5fa1\u673a\u5236\uff0c\u901a\u8fc7\u7ef4\u5ea6\u53d8\u6362\u589e\u5f3a\u826f\u6027\u5d4c\u5165\u548c\u4e2d\u6bd2\u5d4c\u5165\u7684\u5dee\u5f02\uff0c\u5e76\u4f7f\u7528\u81ea\u9002\u5e94\u8fc7\u6ee4\u65b9\u6cd5\u53bb\u9664\u6c61\u67d3\u5d4c\u5165\u3002", "motivation": "\u5206\u5272\u5b66\u4e60\u867d\u7136\u80fd\u4fdd\u62a4\u6570\u636e\u9690\u79c1\uff0c\u4f46\u5bb9\u6613\u53d7\u5230\u540e\u95e8\u653b\u51fb\uff0c\u6076\u610f\u5ba2\u6237\u7aef\u53ef\u4ee5\u901a\u8fc7\u4fee\u6539\u5d4c\u5165\u6765\u690d\u5165\u9690\u85cf\u89e6\u53d1\u5668\uff0c\u4ece\u800c\u7834\u574f\u6700\u7ec8\u8bad\u7ec3\u6a21\u578b\u3002", "method": "SecureSplit\u91c7\u7528\u7ef4\u5ea6\u53d8\u6362\u7b56\u7565\u6765\u7a81\u51fa\u826f\u6027\u5d4c\u5165\u548c\u4e2d\u6bd2\u5d4c\u5165\u4e4b\u95f4\u7684\u7ec6\u5fae\u5dee\u5f02\uff0c\u7136\u540e\u5f00\u53d1\u81ea\u9002\u5e94\u8fc7\u6ee4\u65b9\u6cd5\uff0c\u4f7f\u7528\u57fa\u4e8e\u591a\u6570\u7684\u6295\u7968\u65b9\u6848\u53bb\u9664\u6c61\u67d3\u5d4c\u5165\u540c\u65f6\u4fdd\u7559\u5e72\u51c0\u7684\u5d4c\u5165\u3002", "result": "\u5728\u56db\u4e2a\u6570\u636e\u96c6\uff08CIFAR-10\u3001MNIST\u3001CINIC-10\u548cImageNette\uff09\u3001\u4e94\u79cd\u540e\u95e8\u653b\u51fb\u573a\u666f\u548c\u4e03\u79cd\u66ff\u4ee3\u9632\u5fa1\u65b9\u6848\u7684\u4e25\u683c\u5b9e\u9a8c\u4e2d\uff0cSecureSplit\u5728\u5404\u79cd\u6311\u6218\u6027\u6761\u4ef6\u4e0b\u90fd\u8868\u73b0\u51fa\u6709\u6548\u6027\u3002", "conclusion": "SecureSplit\u662f\u9488\u5bf9\u5206\u5272\u5b66\u4e60\u4e2d\u540e\u95e8\u653b\u51fb\u7684\u6709\u6548\u9632\u5fa1\u673a\u5236\uff0c\u80fd\u591f\u4fdd\u62a4\u534f\u4f5c\u6a21\u578b\u8bad\u7ec3\u514d\u53d7\u6076\u610f\u5ba2\u6237\u7aef\u653b\u51fb\u3002"}}
{"id": "2601.13262", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13262", "abs": "https://arxiv.org/abs/2601.13262", "authors": ["Eric Onyame", "Akash Ghosh", "Subhadip Baidya", "Sriparna Saha", "Xiuying Chen", "Chirag Agarwal"], "title": "CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning", "comment": null, "summary": "While large language models (LLMs) have shown to perform well on monolingual mathematical and commonsense reasoning, they remain unreliable for multilingual medical reasoning applications, hindering their deployment in multilingual healthcare settings. We address this by first introducing CUREMED-BENCH, a high-quality multilingual medical reasoning dataset with open-ended reasoning queries with a single verifiable answer, spanning thirteen languages, including underrepresented languages such as Amharic, Yoruba, and Swahili. Building on this dataset, we propose CURE-MED, a curriculum-informed reinforcement learning framework that integrates code-switching-aware supervised fine-tuning and Group Relative Policy Optimization to jointly improve logical correctness and language stability. Across thirteen languages, our approach consistently outperforms strong baselines and scales effectively, achieving 85.21% language consistency and 54.35% logical correctness at 7B parameters, and 94.96% language consistency and 70.04% logical correctness at 32B parameters. These results support reliable and equitable multilingual medical reasoning in LLMs. The code and dataset are available at https://cure-med.github.io/", "AI": {"tldr": "CURE-MED\u6846\u67b6\u901a\u8fc7\u8bfe\u7a0b\u5f3a\u5316\u5b66\u4e60\u63d0\u5347LLMs\u5728\u591a\u8bed\u8a00\u533b\u7597\u63a8\u7406\u4e2d\u7684\u8868\u73b0\uff0c\u572813\u79cd\u8bed\u8a00\u4e0a\u663e\u8457\u63d0\u9ad8\u4e86\u903b\u8f91\u6b63\u786e\u6027\u548c\u8bed\u8a00\u4e00\u81f4\u6027", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5355\u8bed\u8a00\u6570\u5b66\u548c\u5e38\u8bc6\u63a8\u7406\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u591a\u8bed\u8a00\u533b\u7597\u63a8\u7406\u5e94\u7528\u4e2d\u4ecd\u4e0d\u53ef\u9760\uff0c\u963b\u788d\u4e86\u5176\u5728\u591a\u8bed\u8a00\u533b\u7597\u73af\u5883\u4e2d\u7684\u90e8\u7f72", "method": "\u63d0\u51faCURE-MED\u6846\u67b6\uff0c\u5305\u62ec\uff1a1\uff09\u5f15\u5165CUREMED-BENCH\u591a\u8bed\u8a00\u533b\u7597\u63a8\u7406\u6570\u636e\u96c6\uff1b2\uff09\u91c7\u7528\u8bfe\u7a0b\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u7ed3\u5408\u4ee3\u7801\u5207\u6362\u611f\u77e5\u7684\u76d1\u7763\u5fae\u8c03\u548c\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff0c\u5171\u540c\u63d0\u5347\u903b\u8f91\u6b63\u786e\u6027\u548c\u8bed\u8a00\u7a33\u5b9a\u6027", "result": "\u572813\u79cd\u8bed\u8a00\u4e0a\uff0c\u8be5\u65b9\u6cd5\u6301\u7eed\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u5e76\u6709\u6548\u6269\u5c55\uff1a7B\u53c2\u6570\u6a21\u578b\u8fbe\u523085.21%\u8bed\u8a00\u4e00\u81f4\u6027\u548c54.35%\u903b\u8f91\u6b63\u786e\u6027\uff1b32B\u53c2\u6570\u6a21\u578b\u8fbe\u523094.96%\u8bed\u8a00\u4e00\u81f4\u6027\u548c70.04%\u903b\u8f91\u6b63\u786e\u6027", "conclusion": "\u7814\u7a76\u7ed3\u679c\u652f\u6301LLMs\u5b9e\u73b0\u53ef\u9760\u4e14\u516c\u5e73\u7684\u591a\u8bed\u8a00\u533b\u7597\u63a8\u7406\uff0c\u4e3a\u591a\u8bed\u8a00\u533b\u7597\u73af\u5883\u4e2d\u7684LLM\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.13268", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13268", "abs": "https://arxiv.org/abs/2601.13268", "authors": ["Zainab Ghafoor", "Md Shafiqul Islam", "Koushik Howlader", "Md Rasel Khondokar", "Tanusree Bhattacharjee", "Sayantan Chakraborty", "Adrito Roy", "Ushashi Bhattacharjee", "Tirtho Roy"], "title": "Improving the Safety and Trustworthiness of Medical AI via Multi-Agent Evaluation Loops", "comment": null, "summary": "Large Language Models (LLMs) are increasingly applied in healthcare, yet ensuring their ethical integrity and safety compliance remains a major barrier to clinical deployment. This work introduces a multi-agent refinement framework designed to enhance the safety and reliability of medical LLMs through structured, iterative alignment. Our system combines two generative models - DeepSeek R1 and Med-PaLM - with two evaluation agents, LLaMA 3.1 and Phi-4, which assess responses using the American Medical Association's (AMA) Principles of Medical Ethics and a five-tier Safety Risk Assessment (SRA-5) protocol. We evaluate performance across 900 clinically diverse queries spanning nine ethical domains, measuring convergence efficiency, ethical violation reduction, and domain-specific risk behavior. Results demonstrate that DeepSeek R1 achieves faster convergence (mean 2.34 vs. 2.67 iterations), while Med-PaLM shows superior handling of privacy-sensitive scenarios. The iterative multi-agent loop achieved an 89% reduction in ethical violations and a 92% risk downgrade rate, underscoring the effectiveness of our approach. This study presents a scalable, regulator-aligned, and cost-efficient paradigm for governing medical AI safety.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cbe\u70bc\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u8fed\u4ee3\u5bf9\u9f50\u6765\u589e\u5f3a\u533b\u7597\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\uff0c\u7ed3\u5408\u751f\u6210\u6a21\u578b\u548c\u8bc4\u4f30\u667a\u80fd\u4f53\uff0c\u5728900\u4e2a\u4e34\u5e8a\u67e5\u8be2\u4e2d\u663e\u8457\u51cf\u5c11\u4f26\u7406\u8fdd\u89c4\u548c\u98ce\u9669\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u9886\u57df\u7684\u5e94\u7528\u65e5\u76ca\u589e\u591a\uff0c\u4f46\u786e\u4fdd\u5176\u4f26\u7406\u5b8c\u6574\u6027\u548c\u5b89\u5168\u5408\u89c4\u6027\u4ecd\u662f\u4e34\u5e8a\u90e8\u7f72\u7684\u4e3b\u8981\u969c\u788d\uff0c\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u5b89\u5168\u6cbb\u7406\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u591a\u667a\u80fd\u4f53\u7cbe\u70bc\u6846\u67b6\uff0c\u7ed3\u5408\u4e24\u4e2a\u751f\u6210\u6a21\u578b\uff08DeepSeek R1\u548cMed-PaLM\uff09\u548c\u4e24\u4e2a\u8bc4\u4f30\u667a\u80fd\u4f53\uff08LLaMA 3.1\u548cPhi-4\uff09\uff0c\u4f7f\u7528\u7f8e\u56fd\u533b\u5b66\u4f1a\u533b\u5b66\u4f26\u7406\u539f\u5219\u548c\u4e94\u7ea7\u5b89\u5168\u98ce\u9669\u8bc4\u4f30\u534f\u8bae\u8fdb\u884c\u7ed3\u6784\u5316\u8fed\u4ee3\u5bf9\u9f50\u3002", "result": "\u5728\u6db5\u76d69\u4e2a\u4f26\u7406\u9886\u57df\u7684900\u4e2a\u4e34\u5e8a\u67e5\u8be2\u4e2d\uff0cDeepSeek R1\u6536\u655b\u66f4\u5feb\uff08\u5e73\u57472.34 vs 2.67\u6b21\u8fed\u4ee3\uff09\uff0cMed-PaLM\u5728\u5904\u7406\u9690\u79c1\u654f\u611f\u573a\u666f\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002\u8fed\u4ee3\u591a\u667a\u80fd\u4f53\u5faa\u73af\u5b9e\u73b0\u4e8689%\u7684\u4f26\u7406\u8fdd\u89c4\u51cf\u5c11\u548c92%\u7684\u98ce\u9669\u964d\u7ea7\u7387\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u7b26\u5408\u76d1\u7ba1\u8981\u6c42\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u533b\u7597AI\u5b89\u5168\u6cbb\u7406\u8303\u5f0f\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u6846\u67b6\u6709\u6548\u63d0\u5347\u533b\u7597\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2601.13327", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13327", "abs": "https://arxiv.org/abs/2601.13327", "authors": ["Po-Yu Liang", "Tobo Duran", "Jun Bai"], "title": "PepEDiff: Zero-Shot Peptide Binder Design via Protein Embedding Diffusion", "comment": null, "summary": "We present PepEDiff, a novel peptide binder generator that designs binding sequences given a target receptor protein sequence and its pocket residues. Peptide binder generation is critical in therapeutic and biochemical applications, yet many existing methods rely heavily on intermediate structure prediction, adding complexity and limiting sequence diversity. Our approach departs from this paradigm by generating binder sequences directly in a continuous latent space derived from a pretrained protein embedding model, without relying on predicted structures, thereby improving structural and sequence diversity. To encourage the model to capture binding-relevant features rather than memorizing known sequences, we perform latent-space exploration and diffusion-based sampling, enabling the generation of peptides beyond the limited distribution of known binders. This zero-shot generative strategy leverages the global protein embedding manifold as a semantic prior, allowing the model to propose novel peptide sequences in previously unseen regions of the protein space. We evaluate PepEDiff on TIGIT, a challenging target with a large, flat protein-protein interaction interface that lacks a druggable pocket. Despite its simplicity, our method outperforms state-of-the-art approaches across benchmark tests and in the TIGIT case study, demonstrating its potential as a general, structure-free framework for zero-shot peptide binder design. The code for this research is available at GitHub: https://github.com/LabJunBMI/PepEDiff-An-Peptide-binder-Embedding-Diffusion-Model", "AI": {"tldr": "PepEDiff\u662f\u4e00\u79cd\u65b0\u578b\u7684\u80bd\u7ed3\u5408\u5242\u751f\u6210\u5668\uff0c\u5b83\u76f4\u63a5\u5728\u9884\u8bad\u7ec3\u86cb\u767d\u8d28\u5d4c\u5165\u6a21\u578b\u7684\u8fde\u7eed\u6f5c\u5728\u7a7a\u95f4\u4e2d\u751f\u6210\u7ed3\u5408\u5e8f\u5217\uff0c\u65e0\u9700\u4f9d\u8d56\u4e2d\u95f4\u7ed3\u6784\u9884\u6d4b\uff0c\u63d0\u9ad8\u4e86\u5e8f\u5217\u591a\u6837\u6027\u3002", "motivation": "\u73b0\u6709\u80bd\u7ed3\u5408\u5242\u751f\u6210\u65b9\u6cd5\u4e25\u91cd\u4f9d\u8d56\u4e2d\u95f4\u7ed3\u6784\u9884\u6d4b\uff0c\u589e\u52a0\u4e86\u590d\u6742\u6027\u5e76\u9650\u5236\u4e86\u5e8f\u5217\u591a\u6837\u6027\u3002\u9700\u8981\u4e00\u79cd\u4e0d\u4f9d\u8d56\u7ed3\u6784\u9884\u6d4b\u7684\u76f4\u63a5\u5e8f\u5217\u751f\u6210\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u9884\u8bad\u7ec3\u86cb\u767d\u8d28\u5d4c\u5165\u6a21\u578b\u6784\u5efa\u8fde\u7eed\u6f5c\u5728\u7a7a\u95f4\uff0c\u901a\u8fc7\u6f5c\u5728\u7a7a\u95f4\u63a2\u7d22\u548c\u57fa\u4e8e\u6269\u6563\u7684\u91c7\u6837\u751f\u6210\u80bd\u5e8f\u5217\uff0c\u907f\u514d\u8bb0\u5fc6\u5df2\u77e5\u5e8f\u5217\uff0c\u5b9e\u73b0\u96f6\u6837\u672c\u751f\u6210\u3002", "result": "\u5728TIGIT\uff08\u5177\u6709\u5927\u800c\u5e73\u5766\u7684\u86cb\u767d\u8d28-\u86cb\u767d\u8d28\u76f8\u4e92\u4f5c\u7528\u754c\u9762\u4e14\u7f3a\u4e4f\u53ef\u836f\u6027\u53e3\u888b\u7684\u6311\u6218\u6027\u9776\u70b9\uff09\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0cPepEDiff\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "PepEDiff\u5c55\u793a\u4e86\u4f5c\u4e3a\u901a\u7528\u7684\u3001\u65e0\u9700\u7ed3\u6784\u7684\u96f6\u6837\u672c\u80bd\u7ed3\u5408\u5242\u8bbe\u8ba1\u6846\u67b6\u7684\u6f5c\u529b\uff0c\u80fd\u591f\u751f\u6210\u8d85\u8d8a\u5df2\u77e5\u7ed3\u5408\u5242\u5206\u5e03\u7684\u65b0\u578b\u80bd\u5e8f\u5217\u3002"}}
{"id": "2601.13383", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13383", "abs": "https://arxiv.org/abs/2601.13383", "authors": ["Akbar Anbar Jafari", "Cagri Ozcinar", "Gholamreza Anbarjafari"], "title": "A Lightweight Modular Framework for Constructing Autonomous Agents Driven by Large Language Models: Design, Implementation, and Applications in AgentForge", "comment": "15 pages, 3 figures", "summary": "The emergence of LLMs has catalyzed a paradigm shift in autonomous agent development, enabling systems capable of reasoning, planning, and executing complex multi-step tasks. However, existing agent frameworks often suffer from architectural rigidity, vendor lock-in, and prohibitive complexity that impedes rapid prototyping and deployment. This paper presents AgentForge, a lightweight, open-source Python framework designed to democratize the construction of LLM-driven autonomous agents through a principled modular architecture. AgentForge introduces three key innovations: (1) a composable skill abstraction that enables fine-grained task decomposition with formally defined input-output contracts, (2) a unified LLM backend interface supporting seamless switching between cloud-based APIs and local inference engines, and (3) a declarative YAML-based configuration system that separates agent logic from implementation details. We formalize the skill composition mechanism as a directed acyclic graph (DAG) and prove its expressiveness for representing arbitrary sequential and parallel task workflows. Comprehensive experimental evaluation across four benchmark scenarios demonstrates that AgentForge achieves competitive task completion rates while reducing development time by 62% compared to LangChain and 78% compared to direct API integration. Latency measurements confirm sub-100ms orchestration overhead, rendering the framework suitable for real-time applications. The modular design facilitates extension: we demonstrate the integration of six built-in skills and provide comprehensive documentation for custom skill development. AgentForge addresses a critical gap in the LLM agent ecosystem by providing researchers and practitioners with a production-ready foundation for constructing, evaluating, and deploying autonomous agents without sacrificing flexibility or performance.", "AI": {"tldr": "AgentForge\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u5f00\u6e90Python\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u67b6\u6784\u7b80\u5316LLM\u9a71\u52a8\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\u5f00\u53d1\uff0c\u652f\u6301\u6280\u80fd\u7ec4\u5408\u3001\u7edf\u4e00LLM\u540e\u7aef\u548c\u58f0\u660e\u5f0f\u914d\u7f6e\uff0c\u663e\u8457\u51cf\u5c11\u5f00\u53d1\u65f6\u95f4\u3002", "motivation": "\u73b0\u6709\u667a\u80fd\u4f53\u6846\u67b6\u5b58\u5728\u67b6\u6784\u50f5\u5316\u3001\u4f9b\u5e94\u5546\u9501\u5b9a\u548c\u590d\u6742\u5ea6\u9ad8\u7b49\u95ee\u9898\uff0c\u963b\u788d\u4e86\u5feb\u901f\u539f\u578b\u5f00\u53d1\u548c\u90e8\u7f72\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7075\u6d3b\u3001\u6613\u7528\u7684\u89e3\u51b3\u65b9\u6848\u6765\u6c11\u4e3b\u5316\u81ea\u4e3b\u667a\u80fd\u4f53\u6784\u5efa\u3002", "method": "1) \u53ef\u7ec4\u5408\u6280\u80fd\u62bd\u8c61\uff0c\u652f\u6301\u7ec6\u7c92\u5ea6\u4efb\u52a1\u5206\u89e3\u548c\u5f62\u5f0f\u5316\u8f93\u5165\u8f93\u51fa\u5951\u7ea6\uff1b2) \u7edf\u4e00LLM\u540e\u7aef\u63a5\u53e3\uff0c\u652f\u6301\u4e91\u7aefAPI\u548c\u672c\u5730\u63a8\u7406\u5f15\u64ce\u65e0\u7f1d\u5207\u6362\uff1b3) \u57fa\u4e8eYAML\u7684\u58f0\u660e\u5f0f\u914d\u7f6e\u7cfb\u7edf\uff0c\u5206\u79bb\u667a\u80fd\u4f53\u903b\u8f91\u4e0e\u5b9e\u73b0\u7ec6\u8282\uff1b4) \u5c06\u6280\u80fd\u7ec4\u5408\u673a\u5236\u5f62\u5f0f\u5316\u4e3a\u6709\u5411\u65e0\u73af\u56fe(DAG)\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u573a\u666f\u7684\u8bc4\u4f30\u4e2d\uff0cAgentForge\u5b9e\u73b0\u4e86\u7ade\u4e89\u529b\u7684\u4efb\u52a1\u5b8c\u6210\u7387\uff0c\u76f8\u6bd4LangChain\u51cf\u5c1162%\u5f00\u53d1\u65f6\u95f4\uff0c\u76f8\u6bd4\u76f4\u63a5API\u96c6\u6210\u51cf\u5c1178%\u5f00\u53d1\u65f6\u95f4\uff0c\u7f16\u6392\u5ef6\u8fdf\u4f4e\u4e8e100\u6beb\u79d2\uff0c\u9002\u5408\u5b9e\u65f6\u5e94\u7528\uff0c\u96c6\u6210\u4e86\u516d\u4e2a\u5185\u7f6e\u6280\u80fd\u3002", "conclusion": "AgentForge\u586b\u8865\u4e86LLM\u667a\u80fd\u4f53\u751f\u6001\u7cfb\u7edf\u7684\u5173\u952e\u7a7a\u767d\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u751f\u4ea7\u5c31\u7eea\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u53ef\u5728\u4e0d\u727a\u7272\u7075\u6d3b\u6027\u6216\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u6784\u5efa\u3001\u8bc4\u4f30\u548c\u90e8\u7f72\u81ea\u4e3b\u667a\u80fd\u4f53\u3002"}}
{"id": "2601.13462", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13462", "abs": "https://arxiv.org/abs/2601.13462", "authors": ["Amine Rostane"], "title": "SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompt Following in Text-to-Image Generation", "comment": "19 pages, includes figures and tables", "summary": "Evaluating whether text-to-image models follow explicit spatial instructions is difficult to automate. Object detectors may miss targets or return multiple plausible detections, and simple geometric tests can become ambiguous in borderline cases. Spatial evaluation is naturally a selective prediction problem, the checker may abstain when evidence is weak and report confidence so that results can be interpreted as a risk coverage tradeoff rather than a single score. We introduce SpatialBench-UC, a small, reproducible benchmark for pairwise spatial relations. The benchmark contains 200 prompts (50 object pairs times 4 relations) grouped into 100 counterfactual pairs obtained by swapping object roles. We release a benchmark package, versioned prompts, pinned configs, per-sample checker outputs, and report tables, enabling reproducible and auditable comparisons across models. We also include a lightweight human audit used to calibrate the checker's abstention margin and confidence threshold. We evaluate three baselines, Stable Diffusion 1.5, SD 1.5 BoxDiff, and SD 1.4 GLIGEN. The checker reports pass rate and coverage as well as conditional pass rates on decided samples. The results show that grounding methods substantially improve both pass rate and coverage, while abstention remains a dominant factor due mainly to missing detections.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86SpatialBench-UC\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u662f\u5426\u9075\u5faa\u660e\u786e\u7a7a\u95f4\u6307\u4ee4\u7684\u5c0f\u578b\u53ef\u590d\u73b0\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b200\u4e2a\u63d0\u793a\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u9884\u6d4b\u65b9\u6cd5\uff08\u68c0\u67e5\u5668\u53ef\u5728\u8bc1\u636e\u4e0d\u8db3\u65f6\u5f03\u6743\uff09\u6765\u8bc4\u4f30\u7a7a\u95f4\u5173\u7cfb\u3002", "motivation": "\u8bc4\u4f30\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u662f\u5426\u9075\u5faa\u660e\u786e\u7684\u7a7a\u95f4\u6307\u4ee4\u96be\u4ee5\u81ea\u52a8\u5316\u3002\u5bf9\u8c61\u68c0\u6d4b\u5668\u53ef\u80fd\u6f0f\u68c0\u76ee\u6807\u6216\u8fd4\u56de\u591a\u4e2a\u53ef\u80fd\u68c0\u6d4b\u7ed3\u679c\uff0c\u7b80\u5355\u7684\u51e0\u4f55\u6d4b\u8bd5\u5728\u8fb9\u754c\u60c5\u51b5\u4e0b\u53ef\u80fd\u53d8\u5f97\u6a21\u7cca\u3002\u7a7a\u95f4\u8bc4\u4f30\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u9009\u62e9\u6027\u9884\u6d4b\u95ee\u9898\uff0c\u68c0\u67e5\u5668\u53ef\u4ee5\u5728\u8bc1\u636e\u4e0d\u8db3\u65f6\u5f03\u6743\uff0c\u5e76\u62a5\u544a\u7f6e\u4fe1\u5ea6\uff0c\u4f7f\u7ed3\u679c\u80fd\u591f\u89e3\u91ca\u4e3a\u98ce\u9669\u8986\u76d6\u6743\u8861\u800c\u975e\u5355\u4e00\u5206\u6570\u3002", "method": "\u5f15\u5165SpatialBench-UC\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b200\u4e2a\u63d0\u793a\uff0850\u4e2a\u5bf9\u8c61\u5bf9\u00d74\u79cd\u5173\u7cfb\uff09\uff0c\u5206\u4e3a100\u4e2a\u901a\u8fc7\u4ea4\u6362\u5bf9\u8c61\u89d2\u8272\u83b7\u5f97\u7684\u53cd\u4e8b\u5b9e\u5bf9\u3002\u53d1\u5e03\u57fa\u51c6\u6d4b\u8bd5\u5305\u3001\u7248\u672c\u5316\u63d0\u793a\u3001\u56fa\u5b9a\u914d\u7f6e\u3001\u6bcf\u4e2a\u6837\u672c\u7684\u68c0\u67e5\u5668\u8f93\u51fa\u548c\u62a5\u544a\u8868\u683c\uff0c\u5b9e\u73b0\u8de8\u6a21\u578b\u7684\u53ef\u590d\u73b0\u548c\u53ef\u5ba1\u8ba1\u6bd4\u8f83\u3002\u8fd8\u5305\u62ec\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u4eba\u5de5\u5ba1\u6838\uff0c\u7528\u4e8e\u6821\u51c6\u68c0\u67e5\u5668\u7684\u5f03\u6743\u8fb9\u754c\u548c\u7f6e\u4fe1\u5ea6\u9608\u503c\u3002", "result": "\u8bc4\u4f30\u4e86\u4e09\u4e2a\u57fa\u7ebf\u6a21\u578b\uff1aStable Diffusion 1.5\u3001SD 1.5 BoxDiff\u548cSD 1.4 GLIGEN\u3002\u68c0\u67e5\u5668\u62a5\u544a\u901a\u8fc7\u7387\u548c\u8986\u76d6\u7387\uff0c\u4ee5\u53ca\u5df2\u51b3\u5b9a\u6837\u672c\u7684\u6761\u4ef6\u901a\u8fc7\u7387\u3002\u7ed3\u679c\u663e\u793a\uff0c\u63a5\u5730\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u901a\u8fc7\u7387\u548c\u8986\u76d6\u7387\uff0c\u4f46\u5f03\u6743\u4ecd\u7136\u662f\u4e3b\u8981\u56e0\u7d20\uff0c\u4e3b\u8981\u662f\u7531\u4e8e\u6f0f\u68c0\u9020\u6210\u7684\u3002", "conclusion": "SpatialBench-UC\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684\u6846\u67b6\u6765\u8bc4\u4f30\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u7684\u7a7a\u95f4\u5173\u7cfb\u7406\u89e3\u80fd\u529b\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u9884\u6d4b\u65b9\u6cd5\u89e3\u51b3\u4e86\u81ea\u52a8\u5316\u8bc4\u4f30\u7684\u6311\u6218\uff0c\u5e76\u5c55\u793a\u4e86\u63a5\u5730\u65b9\u6cd5\u5728\u6539\u5584\u7a7a\u95f4\u6307\u4ee4\u9075\u5faa\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2601.13464", "categories": ["cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2601.13464", "abs": "https://arxiv.org/abs/2601.13464", "authors": ["Chongyang Gao", "Marco Postiglione", "Julian Baldwin", "Natalia Denisenko", "Isabel Gortner", "Luke Fosdick", "Chiara Pulice", "Sarit Kraus", "V. S. Subrahmanian"], "title": "Context and Transcripts Improve Detection of Deepfake Audios of Public Figures", "comment": null, "summary": "Humans use context to assess the veracity of information. However, current audio deepfake detectors only analyze the audio file without considering either context or transcripts. We create and analyze a Journalist-provided Deepfake Dataset (JDD) of 255 public deepfakes which were primarily contributed by over 70 journalists since early 2024. We also generate a synthetic audio dataset (SYN) of dead public figures and propose a novel Context-based Audio Deepfake Detector (CADD) architecture. In addition, we evaluate performance on two large-scale datasets: ITW and P$^2$V. We show that sufficient context and/or the transcript can significantly improve the efficacy of audio deepfake detectors. Performance (measured via F1 score, AUC, and EER) of multiple baseline audio deepfake detectors and traditional classifiers can be improved by 5%-37.58% in F1-score, 3.77%-42.79% in AUC, and 6.17%-47.83% in EER. We additionally show that CADD, via its use of context and/or transcripts, is more robust to 5 adversarial evasion strategies, limiting performance degradation to an average of just -0.71% across all experiments. Code, models, and datasets are available at our project page: https://sites.northwestern.edu/nsail/cadd-context-based-audio-deepfake-detection (access restricted during review).", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u5668\uff08CADD\uff09\uff0c\u901a\u8fc7\u7ed3\u5408\u4e0a\u4e0b\u6587\u4fe1\u606f\u548c\u6587\u672c\u8f6c\u5f55\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\uff0c\u5e76\u5bf9\u6297\u6027\u653b\u51fb\u5177\u6709\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u4eba\u7c7b\u5728\u5224\u65ad\u4fe1\u606f\u771f\u4f2a\u65f6\u4f1a\u5229\u7528\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u4f46\u73b0\u6709\u7684\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u5668\u4ec5\u5206\u6790\u97f3\u9891\u6587\u4ef6\u672c\u8eab\uff0c\u5ffd\u7565\u4e86\u4e0a\u4e0b\u6587\u548c\u6587\u672c\u8f6c\u5f55\u4fe1\u606f\uff0c\u8fd9\u9650\u5236\u4e86\u68c0\u6d4b\u6548\u679c\u3002", "method": "\u521b\u5efa\u4e86\u8bb0\u8005\u63d0\u4f9b\u7684\u6df1\u5ea6\u4f2a\u9020\u6570\u636e\u96c6\uff08JDD\uff09\u548c\u5408\u6210\u97f3\u9891\u6570\u636e\u96c6\uff08SYN\uff09\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u5668\uff08CADD\uff09\u67b6\u6784\uff0c\u5e76\u5728\u591a\u4e2a\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u4e0a\u4e0b\u6587\u548c/\u6216\u6587\u672c\u8f6c\u5f55\u80fd\u663e\u8457\u63d0\u5347\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u5668\u7684\u6027\u80fd\uff1aF1\u5206\u6570\u63d0\u53475%-37.58%\uff0cAUC\u63d0\u53473.77%-42.79%\uff0cEER\u63d0\u53476.17%-47.83%\u3002CADD\u5bf95\u79cd\u5bf9\u6297\u6027\u89c4\u907f\u7b56\u7565\u5177\u6709\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\uff0c\u6027\u80fd\u4e0b\u964d\u5e73\u5747\u4ec5\u4e3a-0.71%\u3002", "conclusion": "\u4e0a\u4e0b\u6587\u4fe1\u606f\u548c\u6587\u672c\u8f6c\u5f55\u662f\u63d0\u5347\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u5668\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\uff0c\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u68c0\u6d4b\u65b9\u6cd5\u4e0d\u4ec5\u80fd\u663e\u8457\u63d0\u9ad8\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u8fd8\u80fd\u589e\u5f3a\u5bf9\u5bf9\u6297\u6027\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2601.13481", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13481", "abs": "https://arxiv.org/abs/2601.13481", "authors": ["Jian Zhang", "Zhangqi Wang", "Zhiyuan Wang", "Weiping Fu", "Yu He", "Haiping Zhu", "Qika Lin", "Jun Liu"], "title": "Towards Efficient and Robust Linguistic Emotion Diagnosis for Mental Health via Multi-Agent Instruction Refinement", "comment": null, "summary": "Linguistic expressions of emotions such as depression, anxiety, and trauma-related states are pervasive in clinical notes, counseling dialogues, and online mental health communities, and accurate recognition of these emotions is essential for clinical triage, risk assessment, and timely intervention. Although large language models (LLMs) have demonstrated strong generalization ability in emotion analysis tasks, their diagnostic reliability in high-stakes, context-intensive medical settings remains highly sensitive to prompt design. Moreover, existing methods face two key challenges: emotional comorbidity, in which multiple intertwined emotional states complicate prediction, and inefficient exploration of clinically relevant cues. To address these challenges, we propose APOLO (Automated Prompt Optimization for Linguistic Emotion Diagnosis), a framework that systematically explores a broader and finer-grained prompt space to improve diagnostic efficiency and robustness. APOLO formulates instruction refinement as a Partially Observable Markov Decision Process and adopts a multi-agent collaboration mechanism involving Planner, Teacher, Critic, Student, and Target roles. Within this closed-loop framework, the Planner defines an optimization trajectory, while the Teacher-Critic-Student agents iteratively refine prompts to enhance reasoning stability and effectiveness, and the Target agent determines whether to continue optimization based on performance evaluation. Experimental results show that APOLO consistently improves diagnostic accuracy and robustness across domain-specific and stratified benchmarks, demonstrating a scalable and generalizable paradigm for trustworthy LLM applications in mental healthcare.", "AI": {"tldr": "APOLO\u662f\u4e00\u4e2a\u81ea\u52a8\u63d0\u793a\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u673a\u5236\u6539\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7cbe\u795e\u5065\u5eb7\u9886\u57df\u7684\u60c5\u611f\u8bca\u65ad\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u89e3\u51b3\u60c5\u611f\u5171\u75c5\u548c\u4e34\u5e8a\u7ebf\u7d22\u63a2\u7d22\u6548\u7387\u95ee\u9898\u3002", "motivation": "\u5728\u4e34\u5e8a\u8bb0\u5f55\u3001\u54a8\u8be2\u5bf9\u8bdd\u548c\u5728\u7ebf\u5fc3\u7406\u5065\u5eb7\u793e\u533a\u4e2d\uff0c\u6291\u90c1\u3001\u7126\u8651\u548c\u521b\u4f24\u76f8\u5173\u72b6\u6001\u7684\u60c5\u611f\u8868\u8fbe\u666e\u904d\u5b58\u5728\uff0c\u51c6\u786e\u8bc6\u522b\u8fd9\u4e9b\u60c5\u611f\u5bf9\u4e8e\u4e34\u5e8a\u5206\u8bca\u3001\u98ce\u9669\u8bc4\u4f30\u548c\u53ca\u65f6\u5e72\u9884\u81f3\u5173\u91cd\u8981\u3002\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u60c5\u611f\u5206\u6790\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4f46\u5728\u9ad8\u98ce\u9669\u3001\u4e0a\u4e0b\u6587\u5bc6\u96c6\u7684\u533b\u7597\u73af\u5883\u4e2d\uff0c\u5176\u8bca\u65ad\u53ef\u9760\u6027\u5bf9\u63d0\u793a\u8bbe\u8ba1\u9ad8\u5ea6\u654f\u611f\u3002\u73b0\u6709\u65b9\u6cd5\u9762\u4e34\u60c5\u611f\u5171\u75c5\uff08\u591a\u79cd\u4ea4\u7ec7\u60c5\u611f\u72b6\u6001\u4f7f\u9884\u6d4b\u590d\u6742\u5316\uff09\u548c\u4e34\u5e8a\u76f8\u5173\u7ebf\u7d22\u63a2\u7d22\u6548\u7387\u4f4e\u4e0b\u4e24\u5927\u6311\u6218\u3002", "method": "\u63d0\u51faAPOLO\u6846\u67b6\uff0c\u5c06\u6307\u4ee4\u4f18\u5316\u5efa\u6a21\u4e3a\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u91c7\u7528\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u673a\u5236\uff0c\u5305\u62ec\u89c4\u5212\u8005\u3001\u6559\u5e08\u3001\u6279\u8bc4\u8005\u3001\u5b66\u751f\u548c\u76ee\u6807\u89d2\u8272\u3002\u5728\u95ed\u73af\u6846\u67b6\u4e2d\uff0c\u89c4\u5212\u8005\u5b9a\u4e49\u4f18\u5316\u8f68\u8ff9\uff0c\u6559\u5e08-\u6279\u8bc4\u8005-\u5b66\u751f\u667a\u80fd\u4f53\u8fed\u4ee3\u4f18\u5316\u63d0\u793a\u4ee5\u589e\u5f3a\u63a8\u7406\u7a33\u5b9a\u6027\u548c\u6709\u6548\u6027\uff0c\u76ee\u6807\u667a\u80fd\u4f53\u6839\u636e\u6027\u80fd\u8bc4\u4f30\u51b3\u5b9a\u662f\u5426\u7ee7\u7eed\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAPOLO\u5728\u9886\u57df\u7279\u5b9a\u548c\u5206\u5c42\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6301\u7eed\u63d0\u9ad8\u8bca\u65ad\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u5c55\u793a\u4e86\u5728\u7cbe\u795e\u5065\u5eb7\u62a4\u7406\u4e2d\u53ef\u4fe1\u8d56\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u7684\u53ef\u6269\u5c55\u548c\u53ef\u6cdb\u5316\u8303\u5f0f\u3002", "conclusion": "APOLO\u6846\u67b6\u901a\u8fc7\u7cfb\u7edf\u63a2\u7d22\u66f4\u5e7f\u6cdb\u548c\u7ec6\u7c92\u5ea6\u7684\u63d0\u793a\u7a7a\u95f4\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u60c5\u611f\u8bca\u65ad\u4e2d\u7684\u5171\u75c5\u95ee\u9898\u548c\u4e34\u5e8a\u7ebf\u7d22\u63a2\u7d22\u6548\u7387\u6311\u6218\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7cbe\u795e\u5065\u5eb7\u9886\u57df\u7684\u9ad8\u98ce\u9669\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u6280\u672f\u65b9\u6848\u3002"}}
{"id": "2601.13518", "categories": ["cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.13518", "abs": "https://arxiv.org/abs/2601.13518", "authors": ["Jiayi Yuan", "Jonathan N\u00f6ther", "Natasha Jaques", "Goran Radanovi\u0107"], "title": "AgenticRed: Optimizing Agentic Systems for Automated Red-teaming", "comment": "Website: https://yuanjiayiy.github.io/AgenticRed/", "summary": "While recent automated red-teaming methods show promise for systematically exposing model vulnerabilities, most existing approaches rely on human-specified workflows. This dependence on manually designed workflows suffers from human biases and makes exploring the broader design space expensive. We introduce AgenticRed, an automated pipeline that leverages LLMs' in-context learning to iteratively design and refine red-teaming systems without human intervention. Rather than optimizing attacker policies within predefined structures, AgenticRed treats red-teaming as a system design problem. Inspired by methods like Meta Agent Search, we develop a novel procedure for evolving agentic systems using evolutionary selection, and apply it to the problem of automatic red-teaming. Red-teaming systems designed by AgenticRed consistently outperform state-of-the-art approaches, achieving 96% attack success rate (ASR) on Llama-2-7B (36% improvement) and 98% on Llama-3-8B on HarmBench. Our approach exhibits strong transferability to proprietary models, achieving 100% ASR on GPT-3.5-Turbo and GPT-4o-mini, and 60% on Claude-Sonnet-3.5 (24% improvement). This work highlights automated system design as a powerful paradigm for AI safety evaluation that can keep pace with rapidly evolving models.", "AI": {"tldr": "AgenticRed\u662f\u4e00\u4e2a\u5229\u7528LLM\u4e0a\u4e0b\u6587\u5b66\u4e60\u81ea\u52a8\u8bbe\u8ba1\u548c\u4f18\u5316\u7ea2\u961f\u7cfb\u7edf\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8fdb\u5316\u9009\u62e9\u65b9\u6cd5\u5728\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u7684\u60c5\u51b5\u4e0b\u8fed\u4ee3\u6539\u8fdb\u7ea2\u961f\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u653b\u51fb\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u7ea2\u961f\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u8bbe\u8ba1\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5b58\u5728\u4eba\u4e3a\u504f\u89c1\u4e14\u96be\u4ee5\u63a2\u7d22\u66f4\u5e7f\u6cdb\u7684\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u81ea\u52a8\u8bbe\u8ba1\u548c\u4f18\u5316\u7ea2\u961f\u7cfb\u7edf\u7684\u65b9\u6cd5\u3002", "method": "\u5c06\u7ea2\u961f\u89c6\u4e3a\u7cfb\u7edf\u8bbe\u8ba1\u95ee\u9898\uff0c\u91c7\u7528\u7c7b\u4f3cMeta Agent Search\u7684\u65b9\u6cd5\uff0c\u5f00\u53d1\u4e86\u57fa\u4e8e\u8fdb\u5316\u9009\u62e9\u7684\u667a\u80fd\u7cfb\u7edf\u6f14\u5316\u7a0b\u5e8f\uff0c\u5229\u7528LLM\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u8fed\u4ee3\u8bbe\u8ba1\u548c\u6539\u8fdb\u7ea2\u961f\u7cfb\u7edf\u3002", "result": "\u5728Llama-2-7B\u4e0a\u8fbe\u523096%\u653b\u51fb\u6210\u529f\u7387\uff08\u63d0\u534736%\uff09\uff0c\u5728Llama-3-8B\u4e0a\u8fbe\u523098%\uff1b\u5728GPT-3.5-Turbo\u548cGPT-4o-mini\u4e0a\u8fbe\u5230100%\u653b\u51fb\u6210\u529f\u7387\uff0c\u5728Claude-Sonnet-3.5\u4e0a\u8fbe\u523060%\uff08\u63d0\u534724%\uff09\u3002", "conclusion": "\u81ea\u52a8\u5316\u7cfb\u7edf\u8bbe\u8ba1\u662fAI\u5b89\u5168\u8bc4\u4f30\u7684\u5f3a\u5927\u8303\u5f0f\uff0c\u80fd\u591f\u8ddf\u4e0a\u5feb\u901f\u53d1\u5c55\u7684\u6a21\u578b\u6b65\u4f10\uff0c\u4e3a\u7ea2\u961f\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u3001\u66f4\u5168\u9762\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13533", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13533", "abs": "https://arxiv.org/abs/2601.13533", "authors": ["Changshuo Zhang"], "title": "Reasoning While Recommending: Entropy-Guided Latent Reasoning in Generative Re-ranking Models", "comment": null, "summary": "Reinforcement learning plays a crucial role in generative re-ranking scenarios due to its exploration-exploitation capabilities, but existing generative methods mostly fail to adapt to the dynamic entropy changes in model difficulty during list generation, making it challenging to accurately capture complex preferences. Given that language models have achieved remarkable breakthroughs by integrating reasoning capabilities, we draw on this approach to introduce a latent reasoning mechanism, and experimental validation demonstrates that this mechanism effectively reduces entropy in the model's decision-making process. Based on these findings, we introduce the Entropy-Guided Latent Reasoning (EGLR) recommendation model, which has three core advantages. First, it abandons the \"reason first, recommend later\" paradigm to achieve \"reasoning while recommending\", specifically designed for the high-difficulty nature of list generation by enabling real-time reasoning during generation. Second, it implements entropy-guided variable-length reasoning using context-aware reasoning token alongside dynamic temperature adjustment, expanding exploration breadth in reasoning and boosting exploitation precision in recommending to achieve a more precisely adapted exploration-exploitation trade-off. Third, the model adopts a lightweight integration design with no complex independent modules or post-processing, enabling easy adaptation to existing models. Experimental results on two real-world datasets validate the model's effectiveness, and its notable advantage lies in being compatible with existing generative re-ranking models to enhance their performance. Further analyses also demonstrate its practical deployment value and research potential.", "AI": {"tldr": "EGLR\u6a21\u578b\u901a\u8fc7\u71b5\u5f15\u5bfc\u7684\u6f5c\u5728\u63a8\u7406\u673a\u5236\uff0c\u5728\u751f\u6210\u5f0f\u91cd\u6392\u5e8f\u4e2d\u5b9e\u73b0\"\u8fb9\u63a8\u7406\u8fb9\u63a8\u8350\"\uff0c\u52a8\u6001\u9002\u5e94\u5217\u8868\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u96be\u5ea6\u53d8\u5316\uff0c\u63d0\u5347\u63a8\u8350\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u91cd\u6392\u5e8f\u65b9\u6cd5\u96be\u4ee5\u9002\u5e94\u5217\u8868\u751f\u6210\u8fc7\u7a0b\u4e2d\u6a21\u578b\u96be\u5ea6\u7684\u52a8\u6001\u71b5\u53d8\u5316\uff0c\u65e0\u6cd5\u51c6\u786e\u6355\u6349\u590d\u6742\u7528\u6237\u504f\u597d\u3002\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u96c6\u6210\u63a8\u7406\u80fd\u529b\u53d6\u5f97\u4e86\u7a81\u7834\uff0c\u542f\u53d1\u6211\u4eec\u5f15\u5165\u6f5c\u5728\u63a8\u7406\u673a\u5236\u6765\u964d\u4f4e\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u7684\u71b5\u3002", "method": "\u63d0\u51fa\u71b5\u5f15\u5bfc\u6f5c\u5728\u63a8\u7406(EGLR)\u63a8\u8350\u6a21\u578b\uff1a1)\u91c7\u7528\"\u8fb9\u63a8\u7406\u8fb9\u63a8\u8350\"\u8303\u5f0f\uff0c\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u5b9e\u65f6\u63a8\u7406\uff1b2)\u4f7f\u7528\u4e0a\u4e0b\u6587\u611f\u77e5\u63a8\u7406\u4ee4\u724c\u548c\u52a8\u6001\u6e29\u5ea6\u8c03\u6574\u5b9e\u73b0\u71b5\u5f15\u5bfc\u7684\u53d8\u957f\u63a8\u7406\uff1b3)\u8f7b\u91cf\u7ea7\u96c6\u6210\u8bbe\u8ba1\uff0c\u65e0\u9700\u590d\u6742\u72ec\u7acb\u6a21\u5757\u6216\u540e\u5904\u7406\u3002", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6a21\u578b\u6709\u6548\u6027\uff0c\u663e\u8457\u4f18\u52bf\u5728\u4e8e\u80fd\u591f\u4e0e\u73b0\u6709\u751f\u6210\u5f0f\u91cd\u6392\u5e8f\u6a21\u578b\u517c\u5bb9\u4ee5\u63d0\u5347\u5176\u6027\u80fd\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u5c55\u793a\u4e86\u5b9e\u9645\u90e8\u7f72\u4ef7\u503c\u548c\u7814\u7a76\u6f5c\u529b\u3002", "conclusion": "EGLR\u6a21\u578b\u901a\u8fc7\u71b5\u5f15\u5bfc\u7684\u6f5c\u5728\u63a8\u7406\u673a\u5236\uff0c\u5728\u751f\u6210\u5f0f\u91cd\u6392\u5e8f\u4e2d\u5b9e\u73b0\u4e86\u66f4\u7cbe\u786e\u7684\u63a2\u7d22-\u5229\u7528\u6743\u8861\uff0c\u80fd\u591f\u52a8\u6001\u9002\u5e94\u5217\u8868\u751f\u6210\u96be\u5ea6\u53d8\u5316\uff0c\u63d0\u5347\u63a8\u8350\u6027\u80fd\uff0c\u4e14\u6613\u4e8e\u4e0e\u73b0\u6709\u6a21\u578b\u96c6\u6210\u3002"}}
{"id": "2601.13545", "categories": ["cs.AI", "cs.ET", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.13545", "abs": "https://arxiv.org/abs/2601.13545", "authors": ["Shirin Shahabi", "Spencer Graham", "Haruna Isah"], "title": "TruthTensor: Evaluating LLMs Human Imitation through Prediction Market Drift and Holistic Reasoning", "comment": "16 pages, 6 figures, 2 tables", "summary": "Evaluating language models and AI agents remains fundamentally challenging because static benchmarks fail to capture real-world uncertainty, distribution shift, and the gap between isolated task accuracy and human-aligned decision-making under evolving conditions. This paper introduces TruthTensor, a novel, reproducible evaluation paradigm that measures Large Language Models (LLMs) not only as prediction engines but as human-imitation systems operating in socially-grounded, high-entropy environments. Building on forward-looking, contamination-free tasks, our framework anchors evaluation to live prediction markets and combines probabilistic scoring to provide a holistic view of model behavior. TruthTensor complements traditional correctness metrics with drift-centric diagnostics and explicit robustness checks for reproducibility. It specify human vs. automated evaluation roles, annotation protocols, and statistical testing procedures to ensure interpretability and replicability of results. In experiments across 500+ real markets (political, economic, cultural, technological), TruthTensor demonstrates that models with similar forecast accuracy can diverge markedly in calibration, drift, and risk-sensitivity, underscoring the need to evaluate models along multiple axes (accuracy, calibration, narrative stability, cost, and resource efficiency). TruthTensor therefore operationalizes modern evaluation best practices, clear hypothesis framing, careful metric selection, transparent compute/cost reporting, human-in-the-loop validation, and open, versioned evaluation contracts, to produce defensible assessments of LLMs in real-world decision contexts. We publicly release TruthTensor at https://truthtensor.com", "AI": {"tldr": "TruthTensor\u662f\u4e00\u4e2a\u521b\u65b0\u7684\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u5b9e\u65f6\u9884\u6d4b\u5e02\u573a\u3001\u6982\u7387\u8bc4\u5206\u548c\u591a\u7ef4\u5ea6\u6307\u6807\u6765\u8bc4\u4f30LLMs\u5728\u771f\u5b9e\u4e16\u754c\u51b3\u7b56\u73af\u5883\u4e2d\u7684\u8868\u73b0\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u6839\u672c\u6027\u6311\u6218\uff1a\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u4e16\u754c\u7684\u4e0d\u786e\u5b9a\u6027\u3001\u5206\u5e03\u504f\u79fb\uff0c\u4ee5\u53ca\u5b64\u7acb\u4efb\u52a1\u51c6\u786e\u6027\u4e0e\u4eba\u7c7b\u5bf9\u9f50\u51b3\u7b56\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u8bc4\u4f30LLMs\u4f5c\u4e3a\u4eba\u7c7b\u6a21\u4eff\u7cfb\u7edf\u5728\u793e\u4ea4\u57fa\u7840\u3001\u9ad8\u71b5\u73af\u5883\u4e2d\u8868\u73b0\u7684\u8bc4\u4f30\u8303\u5f0f\u3002", "method": "\u63d0\u51faTruthTensor\u8bc4\u4f30\u6846\u67b6\uff0c\u57fa\u4e8e\u524d\u77bb\u6027\u3001\u65e0\u6c61\u67d3\u7684\u4efb\u52a1\uff0c\u5c06\u8bc4\u4f30\u951a\u5b9a\u5728\u5b9e\u65f6\u9884\u6d4b\u5e02\u573a\u4e0a\uff0c\u7ed3\u5408\u6982\u7387\u8bc4\u5206\u63d0\u4f9b\u6a21\u578b\u884c\u4e3a\u7684\u6574\u4f53\u89c6\u56fe\u3002\u6846\u67b6\u5305\u542b\u6f02\u79fb\u4e2d\u5fc3\u8bca\u65ad\u3001\u663e\u5f0f\u9c81\u68d2\u6027\u68c0\u67e5\u3001\u660e\u786e\u7684\u4eba\u7c7b\u4e0e\u81ea\u52a8\u5316\u8bc4\u4f30\u89d2\u8272\u3001\u6807\u6ce8\u534f\u8bae\u548c\u7edf\u8ba1\u6d4b\u8bd5\u7a0b\u5e8f\uff0c\u786e\u4fdd\u7ed3\u679c\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u590d\u73b0\u6027\u3002", "result": "\u5728500\u591a\u4e2a\u771f\u5b9e\u5e02\u573a\uff08\u653f\u6cbb\u3001\u7ecf\u6d4e\u3001\u6587\u5316\u3001\u6280\u672f\uff09\u7684\u5b9e\u9a8c\u4e2d\uff0cTruthTensor\u663e\u793a\u5177\u6709\u76f8\u4f3c\u9884\u6d4b\u51c6\u786e\u6027\u7684\u6a21\u578b\u5728\u6821\u51c6\u3001\u6f02\u79fb\u548c\u98ce\u9669\u654f\u611f\u6027\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u5f3a\u8c03\u4e86\u9700\u8981\u4ece\u591a\u4e2a\u7ef4\u5ea6\uff08\u51c6\u786e\u6027\u3001\u6821\u51c6\u3001\u53d9\u4e8b\u7a33\u5b9a\u6027\u3001\u6210\u672c\u548c\u8d44\u6e90\u6548\u7387\uff09\u8bc4\u4f30\u6a21\u578b\u3002", "conclusion": "TruthTensor\u901a\u8fc7\u73b0\u4ee3\u8bc4\u4f30\u6700\u4f73\u5b9e\u8df5\u3001\u6e05\u6670\u5047\u8bbe\u6846\u67b6\u3001\u8c28\u614e\u6307\u6807\u9009\u62e9\u3001\u900f\u660e\u8ba1\u7b97/\u6210\u672c\u62a5\u544a\u3001\u4eba\u5728\u56de\u8def\u9a8c\u8bc1\u548c\u5f00\u653e\u7684\u7248\u672c\u5316\u8bc4\u4f30\u5408\u540c\uff0c\u4e3aLLMs\u5728\u771f\u5b9e\u4e16\u754c\u51b3\u7b56\u73af\u5883\u4e2d\u7684\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u8fa9\u62a4\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5e76\u5df2\u516c\u5f00\u53d1\u5e03\u3002"}}
{"id": "2601.13546", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13546", "abs": "https://arxiv.org/abs/2601.13546", "authors": ["Hui Sun", "Chang Xu", "Haonan Xie", "Hao Li", "Yuhao Huang", "Chuheng Zhang", "Ming Jin", "Xiaoguang Liu", "Gang Wang", "Jiang Bian"], "title": "ChatAD: Reasoning-Enhanced Time-Series Anomaly Detection with Multi-Turn Instruction Evolution", "comment": null, "summary": "LLM-driven Anomaly Detection (AD) helps enhance the understanding and explanatory abilities of anomalous behaviors in Time Series (TS). Existing methods face challenges of inadequate reasoning ability, deficient multi-turn dialogue capability, and narrow generalization. To this end, we 1) propose a multi-agent-based TS Evolution algorithm named TSEvol. On top of it, we 2) introduce the AD reasoning and multi-turn dialogue Dataset TSEData-20K and contribute the Chatbot family for AD, including ChatAD-Llama3-8B, Qwen2.5-7B, and Mistral-7B. Furthermore, 3) we propose the TS Kahneman-Tversky Optimization (TKTO) to enhance ChatAD's cross-task generalization capability. Lastly, 4) we propose a LLM-driven Learning-based AD Benchmark LLADBench to evaluate the performance of ChatAD and nine baselines across seven datasets and tasks. Our three ChatAD models achieve substantial gains, up to 34.50% in accuracy, 34.71% in F1, and a 37.42% reduction in false positives. Besides, via KTKO, our optimized ChatAD achieves competitive performance in reasoning and cross-task generalization on classification, forecasting, and imputation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTSEvol\u591a\u667a\u80fd\u4f53\u65f6\u95f4\u5e8f\u5217\u6f14\u5316\u7b97\u6cd5\u3001TSEData-20K\u6570\u636e\u96c6\u3001ChatAD\u7cfb\u5217\u804a\u5929\u673a\u5668\u4eba\u3001TKTO\u4f18\u5316\u65b9\u6cd5\u4ee5\u53caLLADBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u663e\u8457\u63d0\u5347\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u7684\u63a8\u7406\u80fd\u529b\u548c\u8de8\u4efb\u52a1\u6cdb\u5316\u6027\u80fd\u3002", "motivation": "\u73b0\u6709LLM\u9a71\u52a8\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u9762\u4e34\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\u3001\u591a\u8f6e\u5bf9\u8bdd\u80fd\u529b\u6b20\u7f3a\u548c\u6cdb\u5316\u8303\u56f4\u72ed\u7a84\u7684\u6311\u6218\uff0c\u9700\u8981\u63d0\u5347\u5bf9\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u884c\u4e3a\u7684\u7406\u89e3\u548c\u89e3\u91ca\u80fd\u529b\u3002", "method": "1) \u63d0\u51faTSEvol\u591a\u667a\u80fd\u4f53\u65f6\u95f4\u5e8f\u5217\u6f14\u5316\u7b97\u6cd5\uff1b2) \u6784\u5efaTSEData-20K\u6570\u636e\u96c6\u5e76\u5f00\u53d1ChatAD\u7cfb\u5217\u804a\u5929\u673a\u5668\u4eba\uff1b3) \u63d0\u51faTKTO\u4f18\u5316\u65b9\u6cd5\u589e\u5f3a\u8de8\u4efb\u52a1\u6cdb\u5316\u80fd\u529b\uff1b4) \u5efa\u7acbLLADBench\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\u3002", "result": "ChatAD\u6a21\u578b\u5728\u51c6\u786e\u7387\u63d0\u534734.50%\u3001F1\u5206\u6570\u63d0\u534734.71%\u3001\u8bef\u62a5\u7387\u964d\u4f4e37.42%\uff1b\u901a\u8fc7TKTO\u4f18\u5316\u7684ChatAD\u5728\u5206\u7c7b\u3001\u9884\u6d4b\u548c\u63d2\u8865\u4efb\u52a1\u4e0a\u5c55\u73b0\u51fa\u7ade\u4e89\u529b\u7684\u63a8\u7406\u548c\u8de8\u4efb\u52a1\u6cdb\u5316\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u591a\u667a\u80fd\u4f53\u65f6\u95f4\u5e8f\u5217\u6f14\u5316\u6846\u67b6\u3001\u6570\u636e\u96c6\u3001\u804a\u5929\u673a\u5668\u4eba\u7cfb\u5217\u548c\u4f18\u5316\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709LLM\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u7684\u63a8\u7406\u80fd\u529b\u548c\u8de8\u4efb\u52a1\u6cdb\u5316\u6027\u80fd\u3002"}}
{"id": "2601.13559", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13559", "abs": "https://arxiv.org/abs/2601.13559", "authors": ["Sun Hui", "Ding Yanfeng", "Huidong Ma", "Chang Xu", "Keyan Jin", "Lizheng Zu", "Cheng Zhong", "xiaoguang Liu", "Gang Wang", "Wentong Cai"], "title": "AgentGC: Evolutionary Learning-based Lossless Compression for Genomics Data with LLM-driven Multiple Agent", "comment": null, "summary": "Lossless compression has made significant advancements in Genomics Data (GD) storage, sharing and management. Current learning-based methods are non-evolvable with problems of low-level compression modeling, limited adaptability, and user-unfriendly interface. To this end, we propose AgentGC, the first evolutionary Agent-based GD Compressor, consisting of 3 layers with multi-agent named Leader and Worker. Specifically, the 1) User layer provides a user-friendly interface via Leader combined with LLM; 2) Cognitive layer, driven by the Leader, integrates LLM to consider joint optimization of algorithm-dataset-system, addressing the issues of low-level modeling and limited adaptability; and 3) Compression layer, headed by Worker, performs compression & decompression via a automated multi-knowledge learning-based compression framework. On top of AgentGC, we design 3 modes to support diverse scenarios: CP for compression-ratio priority, TP for throughput priority, and BM for balanced mode. Compared with 14 baselines on 9 datasets, the average compression ratios gains are 16.66%, 16.11%, and 16.33%, the throughput gains are 4.73x, 9.23x, and 9.15x, respectively.", "AI": {"tldr": "AgentGC\u662f\u9996\u4e2a\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u8fdb\u5316\u5f0f\u57fa\u56e0\u7ec4\u6570\u636e\u538b\u7f29\u5668\uff0c\u901a\u8fc7\u4e09\u5c42\u67b6\u6784\uff08\u7528\u6237\u5c42\u3001\u8ba4\u77e5\u5c42\u3001\u538b\u7f29\u5c42\uff09\u548c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5b66\u4e60\u65b9\u6cd5\u5728\u538b\u7f29\u5efa\u6a21\u3001\u9002\u5e94\u6027\u548c\u7528\u6237\u754c\u9762\u65b9\u9762\u7684\u9650\u5236\uff0c\u5728\u538b\u7f29\u6bd4\u548c\u541e\u5410\u91cf\u4e0a\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5b66\u4e60\u7684\u57fa\u56e0\u7ec4\u6570\u636e\u538b\u7f29\u65b9\u6cd5\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u975e\u8fdb\u5316\u6027\uff0c\u65e0\u6cd5\u9002\u5e94\u4e0d\u65ad\u53d1\u5c55\u7684\u9700\u6c42\uff1b2\uff09\u4f4e\u5c42\u6b21\u538b\u7f29\u5efa\u6a21\uff0c\u7f3a\u4e4f\u9ad8\u7ea7\u4f18\u5316\uff1b3\uff09\u6709\u9650\u7684\u9002\u5e94\u6027\u548c\u7528\u6237\u4e0d\u53cb\u597d\u7684\u754c\u9762\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u8054\u5408\u4f18\u5316\u7b97\u6cd5\u3001\u6570\u636e\u96c6\u548c\u7cfb\u7edf\u7684\u667a\u80fd\u538b\u7f29\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faAgentGC\u4e09\u5c42\u67b6\u6784\uff1a1\uff09\u7528\u6237\u5c42\u901a\u8fc7Leader\u667a\u80fd\u4f53\u7ed3\u5408LLM\u63d0\u4f9b\u53cb\u597d\u754c\u9762\uff1b2\uff09\u8ba4\u77e5\u5c42\u7531Leader\u9a71\u52a8\uff0c\u96c6\u6210LLM\u8fdb\u884c\u7b97\u6cd5-\u6570\u636e\u96c6-\u7cfb\u7edf\u7684\u8054\u5408\u4f18\u5316\uff1b3\uff09\u538b\u7f29\u5c42\u7531Worker\u667a\u80fd\u4f53\u6267\u884c\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u591a\u77e5\u8bc6\u5b66\u4e60\u6846\u67b6\u8fdb\u884c\u538b\u7f29\u548c\u89e3\u538b\u7f29\u3002\u8bbe\u8ba1\u4e86\u4e09\u79cd\u6a21\u5f0f\uff1aCP\uff08\u538b\u7f29\u6bd4\u4f18\u5148\uff09\u3001TP\uff08\u541e\u5410\u91cf\u4f18\u5148\uff09\u548cBM\uff08\u5e73\u8861\u6a21\u5f0f\uff09\u3002", "result": "\u57289\u4e2a\u6570\u636e\u96c6\u4e0a\u4e0e14\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u6bd4\u8f83\uff0cAgentGC\u7684\u4e09\u79cd\u6a21\u5f0f\uff08CP\u3001TP\u3001BM\uff09\u5e73\u5747\u538b\u7f29\u6bd4\u63d0\u5347\u5206\u522b\u4e3a16.66%\u300116.11%\u548c16.33%\uff0c\u541e\u5410\u91cf\u63d0\u5347\u5206\u522b\u4e3a4.73\u500d\u30019.23\u500d\u548c9.15\u500d\uff0c\u5728\u538b\u7f29\u6027\u80fd\u548c\u6548\u7387\u4e0a\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "AgentGC\u4f5c\u4e3a\u9996\u4e2a\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u8fdb\u5316\u5f0f\u57fa\u56e0\u7ec4\u6570\u636e\u538b\u7f29\u5668\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u67b6\u6784\u548cLLM\u96c6\u6210\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5728\u538b\u7f29\u6bd4\u548c\u541e\u5410\u91cf\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u63d0\u5347\uff0c\u4e3a\u57fa\u56e0\u7ec4\u6570\u636e\u5b58\u50a8\u3001\u5171\u4eab\u548c\u7ba1\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13562", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13562", "abs": "https://arxiv.org/abs/2601.13562", "authors": ["Zhiguang Liu", "Yi Shang"], "title": "Reasoning is a Modality", "comment": "Code access: https://github.com/lz7fd/Reasoning_is_a_Modality", "summary": "The Abstraction and Reasoning Corpus (ARC) provides a compact laboratory for studying abstract reasoning, an ability central to human intelligence. Modern AI systems, including LLMs and ViTs, largely operate as sequence-of-behavior prediction machines: they match observable behaviors by modeling token statistics without a persistent, readable mental state. This creates a gap with human-like behavior: humans can explain an action by decoding internal state, while AI systems can produce fluent post-hoc rationalizations that are not grounded in such a state. We hypothesize that reasoning is a modality: reasoning should exist as a distinct channel separate from the low-level workspace on which rules are applied. To test this hypothesis, on solving ARC tasks as a visual reasoning problem, we designed a novel role-separated transformer block that splits global controller tokens from grid workspace tokens, enabling iterative rule execution. Trained and evaluated within the VARC vision-centric protocol, our method achieved 62.6% accuracy on ARC-1, surpassing average human performance (60.2%) and outperforming prior methods significantly. Qualitatively, our models exhibit more coherent rule-application structure than the dense ViT baseline, consistent with a shift away from plausible probability blobs toward controller-driven reasoning.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u89d2\u8272\u5206\u79bb\u7684Transformer\u67b6\u6784\uff0c\u7528\u4e8e\u89e3\u51b3\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\uff0c\u5728ARC-1\u57fa\u51c6\u4e0a\u8d85\u8d8a\u4e86\u4eba\u7c7b\u5e73\u5747\u8868\u73b0\u3002", "motivation": "\u73b0\u4ee3AI\u7cfb\u7edf\uff08\u5982LLMs\u548cViTs\uff09\u4e3b\u8981\u4f5c\u4e3a\u884c\u4e3a\u5e8f\u5217\u9884\u6d4b\u673a\u5668\u8fd0\u884c\uff0c\u901a\u8fc7\u5efa\u6a21token\u7edf\u8ba1\u6765\u5339\u914d\u53ef\u89c2\u5bdf\u884c\u4e3a\uff0c\u7f3a\u4e4f\u6301\u4e45\u3001\u53ef\u8bfb\u7684\u601d\u7ef4\u72b6\u6001\u3002\u8fd9\u4e0e\u4eba\u7c7b\u884c\u4e3a\u5b58\u5728\u5dee\u8ddd\uff1a\u4eba\u7c7b\u53ef\u4ee5\u901a\u8fc7\u89e3\u7801\u5185\u90e8\u72b6\u6001\u6765\u89e3\u91ca\u884c\u4e3a\uff0c\u800cAI\u7cfb\u7edf\u53ea\u80fd\u4ea7\u751f\u7f3a\u4e4f\u5185\u5728\u72b6\u6001\u57fa\u7840\u7684\u6d41\u5229\u4e8b\u540e\u5408\u7406\u5316\u89e3\u91ca\u3002\u4f5c\u8005\u5047\u8bbe\u63a8\u7406\u5e94\u8be5\u4f5c\u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u6a21\u6001\u5b58\u5728\uff0c\u4e0e\u89c4\u5219\u5e94\u7528\u7684\u4f4e\u7ea7\u5de5\u4f5c\u7a7a\u95f4\u5206\u79bb\u3002", "method": "\u8bbe\u8ba1\u4e86\u65b0\u9896\u7684\u89d2\u8272\u5206\u79bbTransformer\u5757\uff0c\u5c06\u5168\u5c40\u63a7\u5236\u5668token\u4e0e\u7f51\u683c\u5de5\u4f5c\u7a7a\u95f4token\u5206\u79bb\uff0c\u5b9e\u73b0\u8fed\u4ee3\u89c4\u5219\u6267\u884c\u3002\u8be5\u65b9\u6cd5\u5728VARC\u89c6\u89c9\u4e2d\u5fc3\u534f\u8bae\u4e0b\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\uff0c\u4e13\u95e8\u7528\u4e8e\u89e3\u51b3ARC\u4efb\u52a1\u4f5c\u4e3a\u89c6\u89c9\u63a8\u7406\u95ee\u9898\u3002", "result": "\u5728ARC-1\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e8662.6%\u7684\u51c6\u786e\u7387\uff0c\u8d85\u8d8a\u4e86\u4eba\u7c7b\u5e73\u5747\u8868\u73b0\uff0860.2%\uff09\uff0c\u5e76\u663e\u8457\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\u3002\u5b9a\u6027\u5206\u6790\u663e\u793a\uff0c\u4e0e\u5bc6\u96c6ViT\u57fa\u7ebf\u76f8\u6bd4\uff0c\u6a21\u578b\u5c55\u73b0\u51fa\u66f4\u4e00\u81f4\u7684\u89c4\u5219\u5e94\u7528\u7ed3\u6784\uff0c\u4ece\u6982\u7387\u5757\u5411\u63a7\u5236\u5668\u9a71\u52a8\u7684\u63a8\u7406\u8f6c\u53d8\u3002", "conclusion": "\u7814\u7a76\u652f\u6301\u4e86\u63a8\u7406\u4f5c\u4e3a\u72ec\u7acb\u6a21\u6001\u7684\u5047\u8bbe\uff0c\u89d2\u8272\u5206\u79bb\u7684Transformer\u67b6\u6784\u80fd\u591f\u5b9e\u73b0\u66f4\u63a5\u8fd1\u4eba\u7c7b\u63a8\u7406\u7684\u62bd\u8c61\u63a8\u7406\u80fd\u529b\uff0c\u5728\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u7a81\u7834\u6027\u8fdb\u5c55\u3002"}}
{"id": "2601.13581", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13581", "abs": "https://arxiv.org/abs/2601.13581", "authors": ["Heedou Kim", "Changsik Kim", "Sanghwa Shin", "Jaewoo Kang"], "title": "SCRIPTMIND: Crime Script Inference and Cognitive Evaluation for LLM-based Social Engineering Scam Detection System", "comment": "This paper has been accepted to the EACL 2026 Industry Track", "summary": "Social engineering scams increasingly employ personalized, multi-turn deception, exposing the limits of traditional detection methods. While Large Language Models (LLMs) show promise in identifying deception, their cognitive assistance potential remains underexplored. We propose ScriptMind, an integrated framework for LLM-based scam detection that bridges automated reasoning and human cognition. It comprises three components: the Crime Script Inference Task (CSIT) for scam reasoning, the Crime Script-Aware Inference Dataset (CSID) for fine-tuning small LLMs, and the Cognitive Simulation-based Evaluation of Social Engineering Defense (CSED) for assessing real-time cognitive impact. Using 571 Korean phone scam cases, we built 22,712 structured scammer-sequence training instances. Experimental results show that the 11B small LLM fine-tuned with ScriptMind outperformed GPT-4o by 13%, achieving superior performance over commercial models in detection accuracy, false-positive reduction, scammer utterance prediction, and rationale quality. Moreover, in phone scam simulation experiments, it significantly enhanced and sustained users' suspicion levels, improving their cognitive awareness of scams. ScriptMind represents a step toward human-centered, cognitively adaptive LLMs for scam defense.", "AI": {"tldr": "ScriptMind\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u8bc8\u9a97\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u72af\u7f6a\u811a\u672c\u63a8\u7406\u3001\u6570\u636e\u96c6\u6784\u5efa\u548c\u8ba4\u77e5\u6a21\u62df\u8bc4\u4f30\uff0c\u663e\u8457\u63d0\u5347\u8bc8\u9a97\u68c0\u6d4b\u6027\u80fd\u5e76\u589e\u5f3a\u7528\u6237\u8ba4\u77e5\u8b66\u89c9\u6027\u3002", "motivation": "\u4f20\u7edf\u8bc8\u9a97\u68c0\u6d4b\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u4e2a\u6027\u5316\u3001\u591a\u8f6e\u5bf9\u8bdd\u7684\u793e\u4f1a\u5de5\u7a0b\u8bc8\u9a97\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bc8\u9a97\u68c0\u6d4b\u4e2d\u7684\u8ba4\u77e5\u8f85\u52a9\u6f5c\u529b\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51faScriptMind\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\uff1a\u72af\u7f6a\u811a\u672c\u63a8\u7406\u4efb\u52a1(CSIT)\u7528\u4e8e\u8bc8\u9a97\u63a8\u7406\uff0c\u72af\u7f6a\u811a\u672c\u611f\u77e5\u63a8\u7406\u6570\u636e\u96c6(CSID)\u7528\u4e8e\u5fae\u8c03\u5c0f\u578bLLM\uff0c\u4ee5\u53ca\u8ba4\u77e5\u6a21\u62df\u8bc4\u4f30(CSED)\u7528\u4e8e\u8bc4\u4f30\u5b9e\u65f6\u8ba4\u77e5\u5f71\u54cd\u3002\u57fa\u4e8e571\u4e2a\u97e9\u56fd\u7535\u8bdd\u8bc8\u9a97\u6848\u4f8b\u6784\u5efa\u4e8622,712\u4e2a\u7ed3\u6784\u5316\u8bad\u7ec3\u5b9e\u4f8b\u3002", "result": "\u4f7f\u7528ScriptMind\u5fae\u8c03\u768411B\u5c0f\u578bLLM\u5728\u68c0\u6d4b\u51c6\u786e\u7387\u4e0a\u6bd4GPT-4o\u9ad8\u51fa13%\uff0c\u5728\u8bef\u62a5\u51cf\u5c11\u3001\u8bc8\u9a97\u8005\u8bdd\u8bed\u9884\u6d4b\u548c\u63a8\u7406\u8d28\u91cf\u65b9\u9762\u5747\u4f18\u4e8e\u5546\u4e1a\u6a21\u578b\u3002\u5728\u7535\u8bdd\u8bc8\u9a97\u6a21\u62df\u5b9e\u9a8c\u4e2d\uff0c\u663e\u8457\u63d0\u5347\u5e76\u7ef4\u6301\u4e86\u7528\u6237\u7684\u6000\u7591\u6c34\u5e73\uff0c\u589e\u5f3a\u4e86\u8bc8\u9a97\u8ba4\u77e5\u610f\u8bc6\u3002", "conclusion": "ScriptMind\u4ee3\u8868\u4e86\u5411\u4ee5\u4eba\u4e3a\u672c\u3001\u8ba4\u77e5\u81ea\u9002\u5e94\u7684LLM\u8bc8\u9a97\u9632\u5fa1\u7cfb\u7edf\u8fc8\u51fa\u7684\u91cd\u8981\u4e00\u6b65\uff0c\u5c55\u793a\u4e86LLM\u5728\u589e\u5f3a\u4eba\u7c7b\u8ba4\u77e5\u8b66\u89c9\u6027\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.13589", "categories": ["cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2601.13589", "abs": "https://arxiv.org/abs/2601.13589", "authors": ["HyeYoung Lee"], "title": "Motion-to-Response Content Generation via Multi-Agent AI System with Real-Time Safety Verification", "comment": null, "summary": "This paper proposes a multi-agent artificial intelligence system that generates response-oriented media content in real time based on audio-derived emotional signals. Unlike conventional speech emotion recognition studies that focus primarily on classification accuracy, our approach emphasizes the transformation of inferred emotional states into safe, age-appropriate, and controllable response content through a structured pipeline of specialized AI agents. The proposed system comprises four cooperative agents: (1) an Emotion Recognition Agent with CNN-based acoustic feature extraction, (2) a Response Policy Decision Agent for mapping emotions to response modes, (3) a Content Parameter Generation Agent for producing media control parameters, and (4) a Safety Verification Agent enforcing age-appropriateness and stimulation constraints. We introduce an explicit safety verification loop that filters generated content before output, ensuring compliance with predefined rules. Experimental results on public datasets demonstrate that the system achieves 73.2% emotion recognition accuracy, 89.4% response mode consistency, and 100% safety compliance while maintaining sub-100ms inference latency suitable for on-device deployment. The modular architecture enables interpretability and extensibility, making it applicable to child-adjacent media, therapeutic applications, and emotionally responsive smart devices.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u97f3\u9891\u60c5\u611f\u4fe1\u53f7\u7684\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\uff0c\u5b9e\u65f6\u751f\u6210\u5b89\u5168\u53ef\u63a7\u7684\u54cd\u5e94\u5f0f\u5a92\u4f53\u5185\u5bb9\uff0c\u901a\u8fc7\u56db\u4e2a\u534f\u4f5c\u667a\u80fd\u4f53\u5b9e\u73b0\u60c5\u611f\u8bc6\u522b\u5230\u5185\u5bb9\u751f\u6210\u7684\u5b8c\u6574\u6d41\u7a0b\uff0c\u5e76\u52a0\u5165\u5b89\u5168\u9a8c\u8bc1\u73af\u8282\u786e\u4fdd\u5185\u5bb9\u5408\u89c4\u6027\u3002", "motivation": "\u4f20\u7edf\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5206\u7c7b\u51c6\u786e\u6027\uff0c\u4f46\u7f3a\u4e4f\u5c06\u8bc6\u522b\u51fa\u7684\u60c5\u611f\u72b6\u6001\u8f6c\u5316\u4e3a\u5b89\u5168\u3001\u9002\u9f84\u3001\u53ef\u63a7\u7684\u54cd\u5e94\u5185\u5bb9\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5b9e\u65f6\u751f\u6210\u60c5\u611f\u54cd\u5e94\u5a92\u4f53\u5185\u5bb9\uff0c\u540c\u65f6\u786e\u4fdd\u5b89\u5168\u6027\u548c\u53ef\u63a7\u6027\u7684\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u5305\u542b\u56db\u4e2a\u534f\u4f5c\u667a\u80fd\u4f53\uff1a1) \u57fa\u4e8eCNN\u7684\u60c5\u611f\u8bc6\u522b\u667a\u80fd\u4f53\u63d0\u53d6\u58f0\u5b66\u7279\u5f81\uff1b2) \u54cd\u5e94\u7b56\u7565\u51b3\u7b56\u667a\u80fd\u4f53\u5c06\u60c5\u611f\u6620\u5c04\u5230\u54cd\u5e94\u6a21\u5f0f\uff1b3) \u5185\u5bb9\u53c2\u6570\u751f\u6210\u667a\u80fd\u4f53\u4ea7\u751f\u5a92\u4f53\u63a7\u5236\u53c2\u6570\uff1b4) \u5b89\u5168\u9a8c\u8bc1\u667a\u80fd\u4f53\u5f3a\u5236\u6267\u884c\u9002\u9f84\u6027\u548c\u523a\u6fc0\u7ea6\u675f\u3002\u7cfb\u7edf\u5305\u542b\u663e\u5f0f\u7684\u5b89\u5168\u9a8c\u8bc1\u5faa\u73af\uff0c\u5728\u8f93\u51fa\u524d\u8fc7\u6ee4\u751f\u6210\u5185\u5bb9\u3002", "result": "\u5728\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff1a\u60c5\u611f\u8bc6\u522b\u51c6\u786e\u738773.2%\uff0c\u54cd\u5e94\u6a21\u5f0f\u4e00\u81f4\u602789.4%\uff0c\u5b89\u5168\u5408\u89c4\u6027100%\uff0c\u63a8\u7406\u5ef6\u8fdf\u4f4e\u4e8e100\u6beb\u79d2\uff0c\u9002\u5408\u8bbe\u5907\u7aef\u90e8\u7f72\u3002\u6a21\u5757\u5316\u67b6\u6784\u652f\u6301\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u6210\u529f\u5c06\u60c5\u611f\u8bc6\u522b\u8f6c\u5316\u4e3a\u5b89\u5168\u53ef\u63a7\u7684\u54cd\u5e94\u5185\u5bb9\u751f\u6210\uff0c\u9002\u7528\u4e8e\u513f\u7ae5\u76f8\u5173\u5a92\u4f53\u3001\u6cbb\u7597\u5e94\u7528\u548c\u60c5\u611f\u54cd\u5e94\u667a\u80fd\u8bbe\u5907\u3002\u5b89\u5168\u9a8c\u8bc1\u673a\u5236\u786e\u4fdd\u4e86\u5185\u5bb9\u7684\u5408\u89c4\u6027\uff0c\u5b9e\u65f6\u6027\u80fd\u6ee1\u8db3\u5b9e\u9645\u5e94\u7528\u9700\u6c42\u3002"}}
{"id": "2601.13600", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13600", "abs": "https://arxiv.org/abs/2601.13600", "authors": ["Paul He", "Elke Kirschbaum", "Shiva Kasiviswanathan"], "title": "Foundations of Global Consistency Checking with Noisy LLM Oracles", "comment": "Under Review", "summary": "Ensuring that collections of natural-language facts are globally consistent is essential for tasks such as fact-checking, summarization, and knowledge base construction. While Large Language Models (LLMs) can assess the consistency of small subsets of facts, their judgments are noisy, and pairwise checks are insufficient to guarantee global coherence. We formalize this problem and show that verifying global consistency requires exponentially many oracle queries in the worst case. To make the task practical, we propose an adaptive divide-and-conquer algorithm that identifies minimal inconsistent subsets (MUSes) of facts and optionally computes minimal repairs through hitting-sets. Our approach has low-degree polynomial query complexity. Experiments with both synthetic and real LLM oracles show that our method efficiently detects and localizes inconsistencies, offering a scalable framework for linguistic consistency verification with LLM-based evaluators.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u81ea\u9002\u5e94\u5206\u6cbb\u7b97\u6cd5\uff0c\u4f7f\u7528LLM\u8bc4\u4f30\u5668\u68c0\u6d4b\u548c\u5b9a\u4f4d\u81ea\u7136\u8bed\u8a00\u4e8b\u5b9e\u96c6\u5408\u4e2d\u7684\u5168\u5c40\u4e0d\u4e00\u81f4\u6027\uff0c\u89e3\u51b3LLM\u5224\u65ad\u566a\u58f0\u5927\u4e14\u6210\u5bf9\u68c0\u67e5\u65e0\u6cd5\u4fdd\u8bc1\u5168\u5c40\u4e00\u81f4\u6027\u7684\u95ee\u9898\u3002", "motivation": "\u81ea\u7136\u8bed\u8a00\u4e8b\u5b9e\u96c6\u5408\u7684\u5168\u5c40\u4e00\u81f4\u6027\u5bf9\u4e8e\u4e8b\u5b9e\u6838\u67e5\u3001\u6458\u8981\u548c\u77e5\u8bc6\u5e93\u6784\u5efa\u7b49\u4efb\u52a1\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136LLM\u53ef\u4ee5\u8bc4\u4f30\u5c0f\u89c4\u6a21\u4e8b\u5b9e\u5b50\u96c6\u7684\u4e00\u81f4\u6027\uff0c\u4f46\u5176\u5224\u65ad\u5b58\u5728\u566a\u58f0\uff0c\u4e14\u6210\u5bf9\u68c0\u67e5\u65e0\u6cd5\u4fdd\u8bc1\u5168\u5c40\u4e00\u81f4\u6027\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u5206\u6cbb\u7b97\u6cd5\uff0c\u8bc6\u522b\u6700\u5c0f\u4e0d\u4e00\u81f4\u5b50\u96c6\uff08MUSes\uff09\uff0c\u53ef\u9009\u5730\u901a\u8fc7\u547d\u4e2d\u96c6\u8ba1\u7b97\u6700\u5c0f\u4fee\u590d\u3002\u8be5\u65b9\u6cd5\u5177\u6709\u4f4e\u9636\u591a\u9879\u5f0f\u67e5\u8be2\u590d\u6742\u5ea6\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9eLLM\u9884\u8a00\u673a\u7684\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u68c0\u6d4b\u548c\u5b9a\u4f4d\u4e0d\u4e00\u81f4\u6027\uff0c\u4e3a\u57fa\u4e8eLLM\u8bc4\u4f30\u5668\u7684\u8bed\u8a00\u4e00\u81f4\u6027\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u6846\u67b6\u3002", "conclusion": "\u9a8c\u8bc1\u5168\u5c40\u4e00\u81f4\u6027\u5728\u6700\u574f\u60c5\u51b5\u4e0b\u9700\u8981\u6307\u6570\u7ea7\u67e5\u8be2\uff0c\u4f46\u63d0\u51fa\u7684\u81ea\u9002\u5e94\u5206\u6cbb\u7b97\u6cd5\u901a\u8fc7\u8bc6\u522b\u6700\u5c0f\u4e0d\u4e00\u81f4\u5b50\u96c6\uff0c\u4ee5\u4f4e\u9636\u591a\u9879\u5f0f\u67e5\u8be2\u590d\u6742\u5ea6\u5b9e\u73b0\u4e86\u5b9e\u7528\u7684\u8bed\u8a00\u4e00\u81f4\u6027\u9a8c\u8bc1\u3002"}}
{"id": "2601.13687", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13687", "abs": "https://arxiv.org/abs/2601.13687", "authors": ["Zhichao Liang", "Satoshi Nakamura"], "title": "Understanding Mental States to Guide Social Influence in Multi-Person Group Dialogue", "comment": null, "summary": "Existing dynamic Theory of Mind (ToM) benchmarks mostly place language models in a passive role: the model reads a sequence of connected scenarios and reports what people believe, feel, intend, and do as these states change. In real social interaction, ToM is also used for action: a speaker plans what to say in order to shift another person's mental-state trajectory toward a goal. We introduce SocialMindChange, a benchmark that moves from tracking minds to changing minds in social interaction. Each instance defines a social context with 4 characters and five connected scenes. The model plays one character and generates dialogue across the five scenes to reach the target while remaining consistent with the evolving states of all participants. SocialMindChange also includes selected higher-order states. Using a structured four-step framework, we construct 1,200 social contexts, covering 6000 scenarios and over 90,000 questions, each validated for realism and quality. Evaluations on ten state-of-the-art LLMs show that their average performance is 54.2% below human performance. This gap suggests that current LLMs still struggle to maintain and change mental-state representations across long, linked interactions.", "AI": {"tldr": "SocialMindChange\u662f\u4e00\u4e2a\u65b0\u7684\u52a8\u6001\u5fc3\u7406\u7406\u8bba\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8981\u6c42\u8bed\u8a00\u6a21\u578b\u5728\u793e\u4ea4\u4e92\u52a8\u4e2d\u4e3b\u52a8\u6539\u53d8\u4ed6\u4eba\u5fc3\u7406\u72b6\u6001\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u8ffd\u8e2a\u5fc3\u7406\u72b6\u6001\u53d8\u5316\u3002", "motivation": "\u73b0\u6709\u52a8\u6001\u5fc3\u7406\u7406\u8bba\u57fa\u51c6\u6d4b\u8bd5\u5927\u591a\u8ba9\u8bed\u8a00\u6a21\u578b\u5904\u4e8e\u88ab\u52a8\u89d2\u8272\uff0c\u53ea\u8ffd\u8e2a\u5fc3\u7406\u72b6\u6001\u53d8\u5316\u3002\u4f46\u5728\u771f\u5b9e\u793e\u4ea4\u4e92\u52a8\u4e2d\uff0c\u5fc3\u7406\u7406\u8bba\u4e5f\u7528\u4e8e\u884c\u52a8\u2014\u2014\u8bf4\u8bdd\u8005\u8ba1\u5212\u8bf4\u4ec0\u4e48\u6765\u6539\u53d8\u4ed6\u4eba\u7684\u5fc3\u7406\u72b6\u6001\u8f68\u8ff9\u4ee5\u8fbe\u5230\u76ee\u6807\u3002", "method": "\u521b\u5efaSocialMindChange\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b1200\u4e2a\u793e\u4ea4\u60c5\u5883\uff0c\u6bcf\u4e2a\u60c5\u5883\u67094\u4e2a\u89d2\u8272\u548c5\u4e2a\u76f8\u8fde\u573a\u666f\u3002\u6a21\u578b\u626e\u6f14\u4e00\u4e2a\u89d2\u8272\uff0c\u5728\u4e94\u4e2a\u573a\u666f\u4e2d\u751f\u6210\u5bf9\u8bdd\u4ee5\u8fbe\u5230\u76ee\u6807\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u6240\u6709\u53c2\u4e0e\u8005\u4e0d\u65ad\u53d8\u5316\u7684\u72b6\u6001\u4e00\u81f4\u3002\u4f7f\u7528\u7ed3\u6784\u5316\u56db\u6b65\u6846\u67b6\u6784\u5efa\uff0c\u8986\u76d66000\u4e2a\u573a\u666f\u548c\u8d85\u8fc790,000\u4e2a\u95ee\u9898\u3002", "result": "\u8bc4\u4f3010\u4e2a\u6700\u5148\u8fdb\u7684LLM\uff0c\u53d1\u73b0\u5b83\u4eec\u7684\u5e73\u5747\u6027\u80fd\u6bd4\u4eba\u7c7b\u6027\u80fd\u4f4e54.2%\u3002", "conclusion": "\u5f53\u524dLLM\u5728\u957f\u671f\u76f8\u8fde\u7684\u4e92\u52a8\u4e2d\u7ef4\u6301\u548c\u6539\u53d8\u5fc3\u7406\u72b6\u6001\u8868\u5f81\u65b9\u9762\u4ecd\u7136\u5b58\u5728\u56f0\u96be\uff0c\u8868\u660e\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u6a21\u578b\u7684\u793e\u4f1a\u8ba4\u77e5\u80fd\u529b\u3002"}}
{"id": "2601.13735", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13735", "abs": "https://arxiv.org/abs/2601.13735", "authors": ["Hojin Kim", "Jaehyung Kim"], "title": "Reasoning or Fluency? Dissecting Probabilistic Confidence in Best-of-N Selection", "comment": "15 pages, 4 figures", "summary": "Probabilistic confidence metrics are increasingly adopted as proxies for reasoning quality in Best-of-N selection, under the assumption that higher confidence reflects higher reasoning fidelity. In this work, we challenge this assumption by investigating whether these metrics truly capture inter-step causal dependencies necessary for valid reasoning. We introduce three classes of inter-step causality perturbations that systematically disrupt dependencies between reasoning steps while preserving local fluency. Surprisingly, across diverse model families and reasoning benchmarks, we find that selection accuracy degrades only marginally under these disruptions. Even severe interventions, such as applying hard attention masks that directly prevent the model from attending to prior reasoning steps, do not substantially reduce selection performance. These findings provide strong evidence that current probabilistic metrics are largely insensitive to logical structure, and primarily capture surface-level fluency or in-distribution priors instead. Motivated by this gap, we propose a contrastive causality metric that explicitly isolates inter-step causal dependencies, and demonstrate that it yields more faithful output selection than existing probability-based approaches.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5f53\u524d\u57fa\u4e8e\u6982\u7387\u7684\u7f6e\u4fe1\u5ea6\u6307\u6807\u65e0\u6cd5\u6709\u6548\u6355\u6349\u63a8\u7406\u6b65\u9aa4\u95f4\u7684\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb\uff0c\u4e3b\u8981\u53cd\u6620\u7684\u662f\u8868\u9762\u6d41\u7545\u6027\u6216\u5206\u5e03\u5148\u9a8c\uff0c\u800c\u975e\u903b\u8f91\u7ed3\u6784\u3002", "motivation": "\u6311\u6218\u5f53\u524d\u666e\u904d\u5047\u8bbe\uff1a\u6982\u7387\u7f6e\u4fe1\u5ea6\u6307\u6807\u80fd\u53cd\u6620\u63a8\u7406\u8d28\u91cf\u3002\u7814\u7a76\u8005\u8d28\u7591\u8fd9\u4e9b\u6307\u6807\u662f\u5426\u771f\u6b63\u6355\u6349\u5230\u4e86\u63a8\u7406\u6b65\u9aa4\u95f4\u7684\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb\uff0c\u8fd9\u5bf9\u4e8e\u6709\u6548\u7684\u63a8\u7406\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5f15\u5165\u4e09\u7c7b\u63a8\u7406\u6b65\u9aa4\u95f4\u56e0\u679c\u5173\u7cfb\u6270\u52a8\u65b9\u6cd5\uff0c\u7cfb\u7edf\u6027\u5730\u7834\u574f\u63a8\u7406\u6b65\u9aa4\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u540c\u65f6\u4fdd\u6301\u5c40\u90e8\u6d41\u7545\u6027\u3002\u4f7f\u7528\u786c\u6ce8\u610f\u529b\u63a9\u7801\u7b49\u4e25\u91cd\u5e72\u9884\u63aa\u65bd\uff0c\u6d4b\u8bd5\u4e0d\u540c\u6a21\u578b\u5bb6\u65cf\u548c\u63a8\u7406\u57fa\u51c6\u4e0b\u7684\u9009\u62e9\u51c6\u786e\u6027\u53d8\u5316\u3002", "result": "\u4ee4\u4eba\u60ca\u8bb6\u7684\u662f\uff0c\u5373\u4f7f\u4e25\u91cd\u7834\u574f\u63a8\u7406\u6b65\u9aa4\u95f4\u7684\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb\uff0c\u9009\u62e9\u51c6\u786e\u6027\u4ec5\u8f7b\u5fae\u4e0b\u964d\u3002\u786c\u6ce8\u610f\u529b\u63a9\u7801\u7b49\u76f4\u63a5\u963b\u6b62\u6a21\u578b\u5173\u6ce8\u5148\u524d\u63a8\u7406\u6b65\u9aa4\u7684\u5e72\u9884\u63aa\u65bd\uff0c\u4e5f\u6ca1\u6709\u663e\u8457\u964d\u4f4e\u9009\u62e9\u6027\u80fd\u3002", "conclusion": "\u5f53\u524d\u6982\u7387\u6307\u6807\u5bf9\u903b\u8f91\u7ed3\u6784\u4e0d\u654f\u611f\uff0c\u4e3b\u8981\u6355\u6349\u8868\u9762\u6d41\u7545\u6027\u6216\u5206\u5e03\u5148\u9a8c\u3002\u4e3a\u6b64\u63d0\u51fa\u4e86\u4e00\u79cd\u5bf9\u6bd4\u56e0\u679c\u5ea6\u91cf\u65b9\u6cd5\uff0c\u80fd\u660e\u786e\u9694\u79bb\u63a8\u7406\u6b65\u9aa4\u95f4\u7684\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb\uff0c\u6bd4\u73b0\u6709\u57fa\u4e8e\u6982\u7387\u7684\u65b9\u6cd5\u4ea7\u751f\u66f4\u5fe0\u5b9e\u7684\u7ed3\u679c\u9009\u62e9\u3002"}}
{"id": "2601.13752", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13752", "abs": "https://arxiv.org/abs/2601.13752", "authors": ["Chak Tou Leong", "Dingwei Chen", "Heming Xia", "Qingyu Yin", "Sunbowen Lee", "Jian Wang", "Wenjie Li"], "title": "Finding RELIEF: Shaping Reasoning Behavior without Reasoning Supervision via Belief Engineering", "comment": "Working in progress", "summary": "Large reasoning models (LRMs) have achieved remarkable success in complex problem-solving, yet they often suffer from computational redundancy or reasoning unfaithfulness. Current methods for shaping LRM behavior typically rely on reinforcement learning or fine-tuning with gold-standard reasoning traces, a paradigm that is both computationally expensive and difficult to scale. In this paper, we reveal that LRMs possess latent \\textit{reasoning beliefs} that internally track their own reasoning traits, which can be captured through simple logit probing. Building upon this insight, we propose Reasoning Belief Engineering (RELIEF), a simple yet effective framework that shapes LRM behavior by aligning the model's self-concept with a target belief blueprint. Crucially, RELIEF completely bypasses the need for reasoning-trace supervision. It internalizes desired traits by fine-tuning on synthesized, self-reflective question-answering pairs that affirm the target belief. Extensive experiments on efficiency and faithfulness tasks demonstrate that RELIEF matches or outperforms behavior-supervised and preference-based baselines while requiring lower training costs. Further analysis validates that shifting a model's reasoning belief effectively shapes its actual behavior.", "AI": {"tldr": "\u63d0\u51faRELIEF\u6846\u67b6\uff0c\u901a\u8fc7\u8c03\u6574\u5927\u63a8\u7406\u6a21\u578b\u7684\u81ea\u6211\u6982\u5ff5\u6765\u5851\u9020\u5176\u884c\u4e3a\uff0c\u65e0\u9700\u63a8\u7406\u8f68\u8ff9\u76d1\u7763\uff0c\u964d\u4f4e\u8bad\u7ec3\u6210\u672c", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u95ee\u9898\u89e3\u51b3\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b58\u5728\u8ba1\u7b97\u5197\u4f59\u548c\u63a8\u7406\u4e0d\u5fe0\u5b9e\u7684\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5f3a\u5316\u5b66\u4e60\u6216\u9ec4\u91d1\u6807\u51c6\u63a8\u7406\u8f68\u8ff9\u5fae\u8c03\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u6269\u5c55", "method": "\u53d1\u73b0LRMs\u5177\u6709\u6f5c\u5728\u63a8\u7406\u4fe1\u5ff5\uff0c\u53ef\u901a\u8fc7\u7b80\u5355logit\u63a2\u6d4b\u6355\u83b7\u3002\u63d0\u51faRELIEF\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u6a21\u578b\u7684\u81ea\u6211\u6982\u5ff5\u4e0e\u76ee\u6807\u4fe1\u5ff5\u84dd\u56fe\u5bf9\u9f50\u6765\u5851\u9020\u884c\u4e3a\uff0c\u65e0\u9700\u63a8\u7406\u8f68\u8ff9\u76d1\u7763\uff0c\u901a\u8fc7\u5408\u6210\u81ea\u53cd\u95ee\u7b54\u5bf9\u5fae\u8c03\u6765\u5185\u5316\u6240\u9700\u7279\u8d28", "result": "\u5728\u6548\u7387\u548c\u5fe0\u5b9e\u6027\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cRELIEF\u5339\u914d\u6216\u4f18\u4e8e\u57fa\u4e8e\u884c\u4e3a\u76d1\u7763\u548c\u504f\u597d\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u9700\u8981\u66f4\u4f4e\u7684\u8bad\u7ec3\u6210\u672c\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u9a8c\u8bc1\u4e86\u6539\u53d8\u6a21\u578b\u7684\u63a8\u7406\u4fe1\u5ff5\u80fd\u6709\u6548\u5851\u9020\u5176\u5b9e\u9645\u884c\u4e3a", "conclusion": "RELIEF\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8c03\u6574\u6a21\u578b\u7684\u81ea\u6211\u6982\u5ff5\u6765\u5851\u9020\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u884c\u4e3a\uff0c\u907f\u514d\u4e86\u6602\u8d35\u7684\u63a8\u7406\u8f68\u8ff9\u76d1\u7763\u9700\u6c42\uff0c\u4e3a\u6a21\u578b\u884c\u4e3a\u5851\u9020\u63d0\u4f9b\u4e86\u65b0\u601d\u8def"}}
{"id": "2601.13761", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13761", "abs": "https://arxiv.org/abs/2601.13761", "authors": ["Shengda Fan", "Xuyan Ye", "Yankai Lin"], "title": "DARC: Decoupled Asymmetric Reasoning Curriculum for LLM Evolution", "comment": null, "summary": "Self-play with large language models has emerged as a promising paradigm for achieving self-improving artificial intelligence. However, existing self-play frameworks often suffer from optimization instability, due to (i) non-stationary objectives induced by solver-dependent reward feedback for the Questioner, and (ii) bootstrapping errors from self-generated pseudo-labels used to supervise the Solver. To mitigate these challenges, we introduce DARC (Decoupled Asymmetric Reasoning Curriculum), a two-stage framework that stabilizes the self-evolution process. First, we train the Questioner to synthesize difficulty-calibrated questions, conditioned on explicit difficulty levels and external corpora. Second, we train the Solver with an asymmetric self-distillation mechanism, where a document-augmented teacher generates high-quality pseudo-labels to supervise the student Solver that lacks document access. Empirical results demonstrate that DARC is model-agnostic, yielding an average improvement of 10.9 points across nine reasoning benchmarks and three backbone models. Moreover, DARC consistently outperforms all baselines and approaches the performance of fully supervised models without relying on human annotations.The code is available at https://github.com/RUCBM/DARC.", "AI": {"tldr": "DARC\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u81ea\u8fdb\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u95ee\u9898\u751f\u6210\u548c\u6c42\u89e3\u8bad\u7ec3\uff0c\u89e3\u51b3\u4e86\u81ea\u5bf9\u5f08\u4e2d\u7684\u4f18\u5316\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u63a8\u7406\u57fa\u51c6\u4e0a\u5e73\u5747\u63d0\u534710.9\u5206\u3002", "motivation": "\u73b0\u6709\u81ea\u5bf9\u5f08\u6846\u67b6\u5b58\u5728\u4f18\u5316\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u4e3b\u8981\u6e90\u4e8e\uff1a(1) \u6c42\u89e3\u5668\u4f9d\u8d56\u7684\u5956\u52b1\u53cd\u9988\u5bfc\u81f4\u63d0\u95ee\u8005\u76ee\u6807\u975e\u5e73\u7a33\uff1b(2) \u81ea\u751f\u6210\u4f2a\u6807\u7b7e\u7528\u4e8e\u76d1\u7763\u6c42\u89e3\u5668\u65f6\u5b58\u5728\u81ea\u4e3e\u8bef\u5dee\u3002", "method": "DARC\u91c7\u7528\u4e24\u9636\u6bb5\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u8bad\u7ec3\u63d0\u95ee\u8005\u6839\u636e\u660e\u786e\u96be\u5ea6\u7ea7\u522b\u548c\u5916\u90e8\u8bed\u6599\u5408\u6210\u96be\u5ea6\u6821\u51c6\u7684\u95ee\u9898\uff1b\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u975e\u5bf9\u79f0\u81ea\u84b8\u998f\u673a\u5236\u8bad\u7ec3\u6c42\u89e3\u5668\uff0c\u4f7f\u7528\u6587\u6863\u589e\u5f3a\u7684\u6559\u5e08\u6a21\u578b\u751f\u6210\u9ad8\u8d28\u91cf\u4f2a\u6807\u7b7e\u6765\u76d1\u7763\u65e0\u6587\u6863\u8bbf\u95ee\u7684\u5b66\u751f\u6c42\u89e3\u5668\u3002", "result": "DARC\u5728\u4e5d\u4e2a\u63a8\u7406\u57fa\u51c6\u548c\u4e09\u4e2a\u9aa8\u5e72\u6a21\u578b\u4e0a\u5e73\u5747\u63d0\u534710.9\u5206\uff0c\u4e00\u81f4\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e14\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u5c31\u80fd\u63a5\u8fd1\u5168\u76d1\u7763\u6a21\u578b\u7684\u6027\u80fd\u3002", "conclusion": "DARC\u662f\u4e00\u4e2a\u6a21\u578b\u65e0\u5173\u7684\u7a33\u5b9a\u81ea\u8fdb\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u95ee\u9898\u751f\u6210\u548c\u6c42\u89e3\u8bad\u7ec3\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u81ea\u5bf9\u5f08\u4e2d\u7684\u4f18\u5316\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2601.13770", "categories": ["cs.AI", "cs.CL", "cs.LG", "q-fin.CP", "q-fin.GN"], "pdf": "https://arxiv.org/pdf/2601.13770", "abs": "https://arxiv.org/abs/2601.13770", "authors": ["Mostapha Benhenda"], "title": "Look-Ahead-Bench: a Standardized Benchmark of Look-ahead Bias in Point-in-Time LLMs for Finance", "comment": null, "summary": "We introduce Look-Ahead-Bench, a standardized benchmark measuring look-ahead bias in Point-in-Time (PiT) Large Language Models (LLMs) within realistic and practical financial workflows. Unlike most existing approaches that primarily test inner lookahead knowledge via Q\\\\&A, our benchmark evaluates model behavior in practical scenarios. To distinguish genuine predictive capability from memorization-based performance, we analyze performance decay across temporally distinct market regimes, incorporating several quantitative baselines to establish performance thresholds. We evaluate prominent open-source LLMs -- Llama 3.1 (8B and 70B) and DeepSeek 3.2 -- against a family of Point-in-Time LLMs (Pitinf-Small, Pitinf-Medium, and frontier-level model Pitinf-Large) from PiT-Inference. Results reveal significant lookahead bias in standard LLMs, as measured with alpha decay, unlike Pitinf models, which demonstrate improved generalization and reasoning abilities as they scale in size. This work establishes a foundation for the standardized evaluation of temporal bias in financial LLMs and provides a practical framework for identifying models suitable for real-world deployment. Code is available on GitHub: https://github.com/benstaf/lookaheadbench", "AI": {"tldr": "Look-Ahead-Bench\u662f\u4e00\u4e2a\u6807\u51c6\u5316\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u91d1\u878d\u5de5\u4f5c\u6d41\u4e2dPoint-in-Time\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8d85\u524d\u504f\u5dee\uff0c\u901a\u8fc7\u5206\u6790\u4e0d\u540c\u5e02\u573a\u5468\u671f\u4e2d\u7684\u6027\u80fd\u8870\u51cf\u6765\u533a\u5206\u771f\u5b9e\u9884\u6d4b\u80fd\u529b\u4e0e\u8bb0\u5fc6\u6027\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u901a\u8fc7\u95ee\u7b54\u6d4b\u8bd5\u5185\u90e8\u8d85\u524d\u77e5\u8bc6\uff0c\u7f3a\u4e4f\u5bf9\u5b9e\u9645\u5e94\u7528\u573a\u666f\u4e2d\u6a21\u578b\u884c\u4e3a\u7684\u8bc4\u4f30\u3002\u9700\u8981\u5efa\u7acb\u6807\u51c6\u5316\u57fa\u51c6\u6765\u6d4b\u91cf\u91d1\u878dLLMs\u4e2d\u7684\u65f6\u95f4\u504f\u5dee\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u5b9e\u7528\u6846\u67b6\u3002", "method": "\u521b\u5efaLook-Ahead-Bench\u57fa\u51c6\uff0c\u5728\u73b0\u5b9e\u91d1\u878d\u5de5\u4f5c\u6d41\u4e2d\u8bc4\u4f30PiT LLMs\u3002\u901a\u8fc7\u5206\u6790\u4e0d\u540c\u65f6\u95f4\u5e02\u573a\u5468\u671f\u4e2d\u7684\u6027\u80fd\u8870\u51cf\u6765\u533a\u5206\u9884\u6d4b\u80fd\u529b\u4e0e\u8bb0\u5fc6\uff0c\u5f15\u5165\u591a\u4e2a\u91cf\u5316\u57fa\u7ebf\u5efa\u7acb\u6027\u80fd\u9608\u503c\u3002\u8bc4\u4f30\u5f00\u6e90LLMs\uff08Llama 3.1\u548cDeepSeek 3.2\uff09\u4e0ePiT-Inference\u7cfb\u5217\u6a21\u578b\u3002", "result": "\u6807\u51c6LLMs\u663e\u793a\u51fa\u663e\u8457\u7684\u8d85\u524d\u504f\u5dee\uff08\u901a\u8fc7alpha\u8870\u51cf\u6d4b\u91cf\uff09\uff0c\u800cPitinf\u6a21\u578b\u968f\u7740\u89c4\u6a21\u6269\u5927\u5c55\u73b0\u51fa\u6539\u8fdb\u7684\u6cdb\u5316\u548c\u63a8\u7406\u80fd\u529b\u3002Pitinf\u6a21\u578b\u5728\u4e0d\u540c\u5e02\u573a\u5468\u671f\u4e2d\u8868\u73b0\u66f4\u7a33\u5b9a\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u91d1\u878dLLMs\u4e2d\u65f6\u95f4\u504f\u5dee\u7684\u6807\u51c6\u5316\u8bc4\u4f30\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u63d0\u4f9b\u4e86\u8bc6\u522b\u9002\u5408\u5b9e\u9645\u90e8\u7f72\u6a21\u578b\u7684\u5b9e\u7528\u6846\u67b6\u3002Pitinf\u6a21\u578b\u5728\u51cf\u5c11\u8d85\u524d\u504f\u5dee\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u6a21\u578b\u4e2d\u3002"}}
{"id": "2601.13846", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13846", "abs": "https://arxiv.org/abs/2601.13846", "authors": ["Glinskaya Maria"], "title": "Virtual Urbanism: An AI-Driven Framework for Quantifying Urban Identity. A Tokyo-Based Pilot Study Using Diffusion-Generated Synthetic Environments", "comment": null, "summary": "This paper introduces Virtual Urbanism (VU), a multimodal AI-driven analytical framework for quantifying urban identity through the medium of synthetic urban replicas. The framework aims to advance computationally tractable urban identity metrics. To demonstrate feasibility, the pilot study Virtual Urbanism and Tokyo Microcosms is presented. A pipeline integrating Stable Diffusion and LoRA models was used to produce synthetic replicas of nine Tokyo areas rendered as dynamic synthetic urban sequences, excluding existing orientation markers to elicit core identity-forming elements. Human-evaluation experiments (I) assessed perceptual legitimacy of replicas; (II) quantified area-level identity; (III) derived core identity-forming elements. Results showed a mean identification accuracy of ~81%, confirming the validity of the replicas. Urban Identity Level (UIL) metric enabled assessment of identity levels across areas, while semantic analysis revealed culturally embedded typologies as core identity-forming elements, positioning VU as a viable framework for AI-augmented urban analysis, outlining a path toward automated, multi-parameter identity metrics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faVirtual Urbanism\uff08VU\uff09\u6846\u67b6\uff0c\u5229\u7528\u591a\u6a21\u6001AI\u901a\u8fc7\u5408\u6210\u57ce\u5e02\u590d\u5236\u54c1\u91cf\u5316\u57ce\u5e02\u8eab\u4efd\uff0c\u4ee5\u4e1c\u4eac\u4e5d\u4e2a\u533a\u57df\u4e3a\u6848\u4f8b\u9a8c\u8bc1\u53ef\u884c\u6027\uff0c\u83b7\u5f97\u7ea681%\u7684\u8bc6\u522b\u51c6\u786e\u7387\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u53ef\u8ba1\u7b97\u7684\u57ce\u5e02\u8eab\u4efd\u5ea6\u91cf\u65b9\u6cd5\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u91cf\u5316\u57ce\u5e02\u8eab\u4efd\u7684\u5206\u6790\u6846\u67b6\uff0c\u4ee5\u652f\u6301AI\u589e\u5f3a\u7684\u57ce\u5e02\u5206\u6790\u3002", "method": "\u6574\u5408Stable Diffusion\u548cLoRA\u6a21\u578b\u6784\u5efa\u5408\u6210\u57ce\u5e02\u590d\u5236\u54c1\u7ba1\u9053\uff0c\u751f\u6210\u4e1c\u4eac\u4e5d\u4e2a\u533a\u57df\u7684\u52a8\u6001\u5408\u6210\u57ce\u5e02\u5e8f\u5217\uff0c\u6392\u9664\u73b0\u6709\u65b9\u5411\u6807\u8bb0\u4ee5\u63d0\u53d6\u6838\u5fc3\u8eab\u4efd\u5f62\u6210\u5143\u7d20\uff0c\u901a\u8fc7\u4eba\u7c7b\u8bc4\u4f30\u5b9e\u9a8c\u9a8c\u8bc1\u611f\u77e5\u5408\u6cd5\u6027\u3001\u91cf\u5316\u533a\u57df\u7ea7\u8eab\u4efd\u3001\u63a8\u5bfc\u6838\u5fc3\u8eab\u4efd\u5f62\u6210\u5143\u7d20\u3002", "result": "\u5408\u6210\u590d\u5236\u54c1\u83b7\u5f97\u7ea681%\u7684\u5e73\u5747\u8bc6\u522b\u51c6\u786e\u7387\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff1bUrban Identity Level\uff08UIL\uff09\u6307\u6807\u80fd\u591f\u8bc4\u4f30\u4e0d\u540c\u533a\u57df\u7684\u8eab\u4efd\u6c34\u5e73\uff1b\u8bed\u4e49\u5206\u6790\u63ed\u793a\u4e86\u6587\u5316\u5d4c\u5165\u7684\u7c7b\u578b\u5b66\u4f5c\u4e3a\u6838\u5fc3\u8eab\u4efd\u5f62\u6210\u5143\u7d20\u3002", "conclusion": "VU\u662f\u4e00\u4e2a\u53ef\u884c\u7684AI\u589e\u5f3a\u57ce\u5e02\u5206\u6790\u6846\u67b6\uff0c\u4e3a\u81ea\u52a8\u5316\u3001\u591a\u53c2\u6570\u8eab\u4efd\u5ea6\u91cf\u63d0\u4f9b\u4e86\u8def\u5f84\uff0c\u80fd\u591f\u901a\u8fc7\u5408\u6210\u57ce\u5e02\u590d\u5236\u54c1\u91cf\u5316\u57ce\u5e02\u8eab\u4efd\u3002"}}
{"id": "2601.13887", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13887", "abs": "https://arxiv.org/abs/2601.13887", "authors": ["Hong Su"], "title": "Human Simulation Computation: A Human-Inspired Framework for Adaptive AI Systems", "comment": null, "summary": "Large language models (LLMs) have demonstrated strong capabilities in knowledge representation and reasoning based on textual data. However, their reliance on language material alone limits their ability to adapt, verify reasoning outcomes, and operate effectively in open and dynamic real-world environments. In this paper, we propose Human Simulation Computation (HSC), a human-inspired computational framework that models intelligence as a continuous, closed-loop process involving thinking, action, learning, reflection, and activity scheduling, collectively referred to as the internal reasoning process. HSC emphasizes active participation both within the internal reasoning process and in interactions with the environment, where actions are used not only to achieve goals but also to automatically refine and improve internal reasoning mechanisms without external intervention. Furthermore, HSC incorporates commonly used human thinking strategies across all stages of the internal reasoning process, such as main-feature-oriented reasoning, scope expansion through action, and on-time learning driven by environmental feedback. Through theoretical analysis, we argue that human simulation strategies cannot be fully learned from language material alone, and that human-like reasoning processes and action-grounded reasoning methods are essential for robust adaptation and effective interaction with real-world environments.", "AI": {"tldr": "\u63d0\u51fa\u4eba\u7c7b\u6a21\u62df\u8ba1\u7b97\u6846\u67b6\uff0c\u901a\u8fc7\u95ed\u73af\u7684\u601d\u8003-\u884c\u52a8-\u5b66\u4e60-\u53cd\u601d-\u8c03\u5ea6\u8fc7\u7a0b\uff0c\u4f7fAI\u7cfb\u7edf\u80fd\u591f\u4e3b\u52a8\u53c2\u4e0e\u73af\u5883\u4ea4\u4e92\u5e76\u81ea\u6211\u6539\u8fdb\u63a8\u7406\u673a\u5236\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u4ec5\u4f9d\u8d56\u6587\u672c\u6570\u636e\uff0c\u9650\u5236\u4e86\u5176\u5728\u5f00\u653e\u52a8\u6001\u73b0\u5b9e\u73af\u5883\u4e2d\u7684\u9002\u5e94\u80fd\u529b\u3001\u9a8c\u8bc1\u63a8\u7406\u7ed3\u679c\u548c\u6709\u6548\u64cd\u4f5c\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4eba\u7c7b\u6a21\u62df\u8ba1\u7b97\u6846\u67b6\uff0c\u5c06\u667a\u80fd\u5efa\u6a21\u4e3a\u5305\u542b\u601d\u8003\u3001\u884c\u52a8\u3001\u5b66\u4e60\u3001\u53cd\u601d\u548c\u6d3b\u52a8\u8c03\u5ea6\u7684\u8fde\u7eed\u95ed\u73af\u8fc7\u7a0b\uff0c\u5f3a\u8c03\u5728\u5185\u90e8\u63a8\u7406\u8fc7\u7a0b\u548c\u73af\u5883\u4ea4\u4e92\u4e2d\u7684\u4e3b\u52a8\u53c2\u4e0e\uff0c\u5e76\u878d\u5165\u4eba\u7c7b\u5e38\u7528\u601d\u7ef4\u7b56\u7565\u3002", "result": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u4eba\u7c7b\u6a21\u62df\u7b56\u7565\u65e0\u6cd5\u4ec5\u4ece\u8bed\u8a00\u6750\u6599\u4e2d\u5b8c\u5168\u5b66\u4e60\uff0c\u7c7b\u4eba\u63a8\u7406\u8fc7\u7a0b\u548c\u57fa\u4e8e\u884c\u52a8\u7684\u63a8\u7406\u65b9\u6cd5\u5bf9\u4e8e\u5728\u73b0\u5b9e\u73af\u5883\u4e2d\u5b9e\u73b0\u7a33\u5065\u9002\u5e94\u548c\u6709\u6548\u4ea4\u4e92\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u4eba\u7c7b\u6a21\u62df\u8ba1\u7b97\u6846\u67b6\u4e3a\u6784\u5efa\u80fd\u591f\u5728\u5f00\u653e\u52a8\u6001\u73b0\u5b9e\u73af\u5883\u4e2d\u6709\u6548\u8fd0\u4f5c\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5f3a\u8c03\u4e86\u4e3b\u52a8\u73af\u5883\u53c2\u4e0e\u548c\u81ea\u6211\u6539\u8fdb\u673a\u5236\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.13904", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.13904", "abs": "https://arxiv.org/abs/2601.13904", "authors": ["Jaeyoung Moon", "Youjin Choi", "Yucheon Park", "David Melhart", "Georgios N. Yannakakis", "Kyung-Joong Kim"], "title": "PREFAB: PREFerence-based Affective Modeling for Low-Budget Self-Annotation", "comment": "CHI '26 Accepted paper", "summary": "Self-annotation is the gold standard for collecting affective state labels in affective computing. Existing methods typically rely on full annotation, requiring users to continuously label affective states across entire sessions. While this process yields fine-grained data, it is time-consuming, cognitively demanding, and prone to fatigue and errors. To address these issues, we present PREFAB, a low-budget retrospective self-annotation method that targets affective inflection regions rather than full annotation. Grounded in the peak-end rule and ordinal representations of emotion, PREFAB employs a preference-learning model to detect relative affective changes, directing annotators to label only selected segments while interpolating the remainder of the stimulus. We further introduce a preview mechanism that provides brief contextual cues to assist annotation. We evaluate PREFAB through a technical performance study and a 25-participant user study. Results show that PREFAB outperforms baselines in modeling affective inflections while mitigating workload (and conditionally mitigating temporal burden). Importantly PREFAB improves annotator confidence without degrading annotation quality.", "AI": {"tldr": "PREFAB\u662f\u4e00\u79cd\u4f4e\u6210\u672c\u7684\u56de\u987e\u6027\u81ea\u6807\u6ce8\u65b9\u6cd5\uff0c\u9488\u5bf9\u60c5\u611f\u53d8\u5316\u533a\u57df\u800c\u975e\u5b8c\u6574\u6807\u6ce8\uff0c\u901a\u8fc7\u504f\u597d\u5b66\u4e60\u6a21\u578b\u68c0\u6d4b\u76f8\u5bf9\u60c5\u611f\u53d8\u5316\uff0c\u51cf\u5c11\u6807\u6ce8\u5de5\u4f5c\u91cf\u540c\u65f6\u4fdd\u6301\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u60c5\u611f\u72b6\u6001\u6807\u6ce8\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u7528\u6237\u5728\u6574\u4e2a\u4f1a\u8bdd\u671f\u95f4\u8fde\u7eed\u6807\u6ce8\uff0c\u867d\u7136\u80fd\u83b7\u5f97\u7ec6\u7c92\u5ea6\u6570\u636e\uff0c\u4f46\u8017\u65f6\u3001\u8ba4\u77e5\u8d1f\u62c5\u91cd\u3001\u5bb9\u6613\u75b2\u52b3\u548c\u51fa\u9519\u3002\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u6807\u6ce8\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u5cf0\u503c-\u7ed3\u675f\u89c4\u5219\u548c\u60c5\u611f\u5e8f\u6570\u8868\u793a\uff0c\u91c7\u7528\u504f\u597d\u5b66\u4e60\u6a21\u578b\u68c0\u6d4b\u76f8\u5bf9\u60c5\u611f\u53d8\u5316\uff0c\u6307\u5bfc\u6807\u6ce8\u8005\u53ea\u6807\u6ce8\u9009\u5b9a\u7247\u6bb5\uff0c\u5176\u4f59\u90e8\u5206\u901a\u8fc7\u63d2\u503c\u5b8c\u6210\u3002\u8fd8\u5f15\u5165\u4e86\u9884\u89c8\u673a\u5236\u63d0\u4f9b\u4e0a\u4e0b\u6587\u7ebf\u7d22\u8f85\u52a9\u6807\u6ce8\u3002", "result": "PREFAB\u5728\u5efa\u6a21\u60c5\u611f\u53d8\u5316\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u51cf\u8f7b\u4e86\u5de5\u4f5c\u8d1f\u62c5\uff08\u6709\u6761\u4ef6\u5730\u51cf\u8f7b\u65f6\u95f4\u8d1f\u62c5\uff09\u3002\u91cd\u8981\u7684\u662f\uff0cPREFAB\u63d0\u9ad8\u4e86\u6807\u6ce8\u8005\u4fe1\u5fc3\u4e14\u672a\u964d\u4f4e\u6807\u6ce8\u8d28\u91cf\u3002", "conclusion": "PREFAB\u662f\u4e00\u79cd\u6709\u6548\u7684\u4f4e\u9884\u7b97\u60c5\u611f\u6807\u6ce8\u65b9\u6cd5\uff0c\u901a\u8fc7\u805a\u7126\u60c5\u611f\u53d8\u5316\u533a\u57df\u548c\u667a\u80fd\u9009\u62e9\u6807\u6ce8\u7247\u6bb5\uff0c\u5728\u4fdd\u6301\u6807\u6ce8\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u51cf\u8f7b\u6807\u6ce8\u8d1f\u62c5\u3002"}}
{"id": "2601.14171", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14171", "abs": "https://arxiv.org/abs/2601.14171", "authors": ["Qianli Ma", "Chang Guo", "Zhiheng Tian", "Siyu Wang", "Jipeng Xiao", "Yuanhao Yue", "Zhipeng Zhang"], "title": "Paper2Rebuttal: A Multi-Agent Framework for Transparent Author Response Assistance", "comment": null, "summary": "Writing effective rebuttals is a high-stakes task that demands more than linguistic fluency, as it requires precise alignment between reviewer intent and manuscript details. Current solutions typically treat this as a direct-to-text generation problem, suffering from hallucination, overlooked critiques, and a lack of verifiable grounding. To address these limitations, we introduce $\\textbf{RebuttalAgent}$, the first multi-agents framework that reframes rebuttal generation as an evidence-centric planning task. Our system decomposes complex feedback into atomic concerns and dynamically constructs hybrid contexts by synthesizing compressed summaries with high-fidelity text while integrating an autonomous and on-demand external search module to resolve concerns requiring outside literature. By generating an inspectable response plan before drafting, $\\textbf{RebuttalAgent}$ ensures that every argument is explicitly anchored in internal or external evidence. We validate our approach on the proposed $\\textbf{RebuttalBench}$ and demonstrate that our pipeline outperforms strong baselines in coverage, faithfulness, and strategic coherence, offering a transparent and controllable assistant for the peer review process. Code will be released.", "AI": {"tldr": "RebuttalAgent\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c06\u53cd\u9a73\u4fe1\u751f\u6210\u91cd\u6784\u4e3a\u4ee5\u8bc1\u636e\u4e3a\u4e2d\u5fc3\u7684\u89c4\u5212\u4efb\u52a1\uff0c\u901a\u8fc7\u5206\u89e3\u8bc4\u5ba1\u610f\u89c1\u3001\u6784\u5efa\u6df7\u5408\u4e0a\u4e0b\u6587\u548c\u96c6\u6210\u5916\u90e8\u641c\u7d22\uff0c\u786e\u4fdd\u6bcf\u4e2a\u8bba\u70b9\u90fd\u6709\u660e\u786e\u7684\u8bc1\u636e\u652f\u6491\u3002", "motivation": "\u5f53\u524d\u7684\u53cd\u9a73\u4fe1\u751f\u6210\u65b9\u6cd5\u901a\u5e38\u5c06\u5176\u89c6\u4e3a\u76f4\u63a5\u6587\u672c\u751f\u6210\u95ee\u9898\uff0c\u5b58\u5728\u5e7b\u89c9\u3001\u5ffd\u7565\u6279\u8bc4\u610f\u89c1\u548c\u7f3a\u4e4f\u53ef\u9a8c\u8bc1\u57fa\u7840\u7b49\u95ee\u9898\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u7cbe\u786e\u5bf9\u9f50\u8bc4\u5ba1\u610f\u56fe\u548c\u7a3f\u4ef6\u7ec6\u8282\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faRebuttalAgent\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff1a1) \u5c06\u590d\u6742\u53cd\u9988\u5206\u89e3\u4e3a\u539f\u5b50\u5316\u5173\u6ce8\u70b9\uff1b2) \u52a8\u6001\u6784\u5efa\u6df7\u5408\u4e0a\u4e0b\u6587\uff0c\u7efc\u5408\u538b\u7f29\u6458\u8981\u548c\u9ad8\u4fdd\u771f\u6587\u672c\uff1b3) \u96c6\u6210\u81ea\u4e3b\u6309\u9700\u5916\u90e8\u641c\u7d22\u6a21\u5757\uff0c\u89e3\u51b3\u9700\u8981\u5916\u90e8\u6587\u732e\u652f\u6301\u7684\u5173\u6ce8\u70b9\uff1b4) \u5728\u8d77\u8349\u524d\u751f\u6210\u53ef\u68c0\u67e5\u7684\u54cd\u5e94\u8ba1\u5212\u3002", "result": "\u5728\u63d0\u51fa\u7684RebuttalBench\u4e0a\u9a8c\u8bc1\uff0cRebuttalAgent\u5728\u8986\u76d6\u7387\u3001\u5fe0\u5b9e\u5ea6\u548c\u7b56\u7565\u8fde\u8d2f\u6027\u65b9\u9762\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e3a\u540c\u884c\u8bc4\u5ba1\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u900f\u660e\u4e14\u53ef\u63a7\u7684\u52a9\u624b\u3002", "conclusion": "RebuttalAgent\u901a\u8fc7\u5c06\u53cd\u9a73\u4fe1\u751f\u6210\u91cd\u6784\u4e3a\u8bc1\u636e\u4e2d\u5fc3\u7684\u89c4\u5212\u4efb\u52a1\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u3001\u900f\u660e\u548c\u53ef\u63a7\u7684\u540c\u884c\u8bc4\u5ba1\u8f85\u52a9\u5de5\u5177\u3002"}}
{"id": "2601.14192", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14192", "abs": "https://arxiv.org/abs/2601.14192", "authors": ["Xiaofang Yang", "Lijun Li", "Heng Zhou", "Tong Zhu", "Xiaoye Qu", "Yuchen Fan", "Qianshan Wei", "Rui Ye", "Li Kang", "Yiran Qin", "Zhiqiang Kou", "Daizong Liu", "Qi Li", "Ning Ding", "Siheng Chen", "Jing Shao"], "title": "Toward Efficient Agents: Memory, Tool learning, and Planning", "comment": "35 pages, 200 references", "summary": "Recent years have witnessed increasing interest in extending large language models into agentic systems. While the effectiveness of agents has continued to improve, efficiency, which is crucial for real-world deployment, has often been overlooked. This paper therefore investigates efficiency from three core components of agents: memory, tool learning, and planning, considering costs such as latency, tokens, steps, etc. Aimed at conducting comprehensive research addressing the efficiency of the agentic system itself, we review a broad range of recent approaches that differ in implementation yet frequently converge on shared high-level principles including but not limited to bounding context via compression and management, designing reinforcement learning rewards to minimize tool invocation, and employing controlled search mechanisms to enhance efficiency, which we discuss in detail. Accordingly, we characterize efficiency in two complementary ways: comparing effectiveness under a fixed cost budget, and comparing cost at a comparable level of effectiveness. This trade-off can also be viewed through the Pareto frontier between effectiveness and cost. From this perspective, we also examine efficiency oriented benchmarks by summarizing evaluation protocols for these components and consolidating commonly reported efficiency metrics from both benchmark and methodological studies. Moreover, we discuss the key challenges and future directions, with the goal of providing promising insights.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6027\u5730\u7814\u7a76\u4e86\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6548\u7387\u95ee\u9898\uff0c\u4ece\u5185\u5b58\u3001\u5de5\u5177\u5b66\u4e60\u548c\u89c4\u5212\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\u51fa\u53d1\uff0c\u5206\u6790\u4e86\u5ef6\u8fdf\u3001token\u6570\u3001\u6b65\u9aa4\u6570\u7b49\u6210\u672c\uff0c\u63d0\u51fa\u4e86\u5728\u56fa\u5b9a\u6210\u672c\u9884\u7b97\u4e0b\u6bd4\u8f83\u6548\u679c\u548c\u5728\u53ef\u6bd4\u6548\u679c\u6c34\u5e73\u4e0b\u6bd4\u8f83\u6210\u672c\u7684\u4e24\u79cd\u6548\u7387\u8bc4\u4f30\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5411\u667a\u80fd\u4f53\u7cfb\u7edf\u6269\u5c55\uff0c\u867d\u7136\u667a\u80fd\u4f53\u7684\u6548\u679c\u4e0d\u65ad\u63d0\u5347\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u4e2d\u81f3\u5173\u91cd\u8981\u7684\u6548\u7387\u95ee\u9898\u5374\u7ecf\u5e38\u88ab\u5ffd\u89c6\u3002\u672c\u6587\u65e8\u5728\u5bf9\u667a\u80fd\u4f53\u7cfb\u7edf\u672c\u8eab\u7684\u6548\u7387\u8fdb\u884c\u5168\u9762\u7814\u7a76\u3002", "method": "\u4ece\u667a\u80fd\u4f53\u7684\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff08\u5185\u5b58\u3001\u5de5\u5177\u5b66\u4e60\u3001\u89c4\u5212\uff09\u51fa\u53d1\uff0c\u7efc\u8ff0\u4e86\u591a\u79cd\u63d0\u9ad8\u6548\u7387\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u901a\u8fc7\u538b\u7f29\u548c\u7ba1\u7406\u9650\u5236\u4e0a\u4e0b\u6587\u3001\u8bbe\u8ba1\u5f3a\u5316\u5b66\u4e60\u5956\u52b1\u4ee5\u51cf\u5c11\u5de5\u5177\u8c03\u7528\u3001\u91c7\u7528\u53d7\u63a7\u641c\u7d22\u673a\u5236\u7b49\u3002\u63d0\u51fa\u4e86\u4e24\u79cd\u4e92\u8865\u7684\u6548\u7387\u8bc4\u4f30\u65b9\u5f0f\uff1a\u56fa\u5b9a\u6210\u672c\u9884\u7b97\u4e0b\u7684\u6548\u679c\u6bd4\u8f83\u548c\u53ef\u6bd4\u6548\u679c\u6c34\u5e73\u4e0b\u7684\u6210\u672c\u6bd4\u8f83\u3002", "result": "\u603b\u7ed3\u4e86\u8fd9\u4e9b\u7ec4\u4ef6\u7684\u9ad8\u6548\u5b9e\u73b0\u539f\u5219\uff0c\u5efa\u7acb\u4e86\u6548\u7387\u4e0e\u6548\u679c\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\u5206\u6790\u6846\u67b6\uff0c\u6574\u7406\u4e86\u9762\u5411\u6548\u7387\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u8bc4\u4f30\u534f\u8bae\uff0c\u5e76\u6c47\u603b\u4e86\u5e38\u7528\u7684\u6548\u7387\u6307\u6807\u3002", "conclusion": "\u672c\u6587\u4e3a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6548\u7387\u7814\u7a76\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u5206\u6790\u6846\u67b6\uff0c\u8bc6\u522b\u4e86\u5173\u952e\u6311\u6218\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u65e8\u5728\u4e3a\u8fd9\u4e00\u91cd\u8981\u4f46\u88ab\u5ffd\u89c6\u7684\u9886\u57df\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
