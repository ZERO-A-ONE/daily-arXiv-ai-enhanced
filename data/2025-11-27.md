<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 26]
- [cs.CR](#cs.CR) [Total: 13]
- [cs.SE](#cs.SE) [Total: 6]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Using Wearable Devices to Improve Chronic PainTreatment among Patients with Opioid Use Disorder](https://arxiv.org/abs/2511.19577)
*Abhay Goyal,Navin Kumar,Kimberly DiMeola,Rafael Trujillo,Soorya Ram Shimgekar,Christian Poellabauer,Pi Zonooz,Ermonda Gjoni-Markaj,Declan Barry,Lynn Madden*

Main category: cs.AI

TL;DR: 本研究探索使用可穿戴设备和AI方法预测慢性疼痛和阿片类药物使用障碍患者的疼痛峰值，发现机器学习模型预测准确率较高，但大语言模型表现有限。


<details>
  <summary>Details</summary>
Motivation: 慢性疼痛和阿片类药物使用障碍是相互关联的常见慢性疾病，目前缺乏基于证据的综合治疗方法。可穿戴设备有潜力监测复杂患者信息，但大语言模型在此领域的应用尚未探索。

Method: 使用可穿戴设备监测患者数据，结合多种AI方法（包括机器学习模型和大语言模型）分析疼痛峰值的临床相关性。

Result: 机器学习模型在预测疼痛峰值方面达到相对较高的准确率（>0.7），而大语言模型在提供疼痛峰值洞察方面表现有限。

Conclusion: 可穿戴设备的实时监测结合先进AI模型可促进疼痛峰值的早期检测，支持个性化干预，但需要开发能够提供可操作洞察的大语言模型。

Abstract: Chronic pain (CP) and opioid use disorder (OUD) are common and interrelated chronic medical conditions. Currently, there is a paucity of evidence-based integrated treatments for CP and OUD among individuals receiving medication for opioid use disorder (MOUD). Wearable devices have the potential to monitor complex patient information and inform treatment development for persons with OUD and CP, including pain variability (e.g., exacerbations of pain or pain spikes) and clinical correlates (e.g., perceived stress). However, the application of large language models (LLMs) with wearable data for understanding pain spikes, remains unexplored. Consequently, the aim of this pilot study was to examine the clinical correlates of pain spikes using a range of AI approaches. We found that machine learning models achieved relatively high accuracy (>0.7) in predicting pain spikes, while LLMs were limited in providing insights on pain spikes. Real-time monitoring through wearable devices, combined with advanced AI models, could facilitate early detection of pain spikes and support personalized interventions that may help mitigate the risk of opioid relapse, improve adherence to MOUD, and enhance the integration of CP and OUD care. Given overall limited LLM performance, these findings highlight the need to develop LLMs which can provide actionable insights in the OUD/CP context.

</details>


### [2] [HeaRT: A Hierarchical Circuit Reasoning Tree-Based Agentic Framework for AMS Design Optimization](https://arxiv.org/abs/2511.19669)
*Souradip Poddar,Chia-Tung Ho,Ziming Wei,Weidong Cao,Haoxing Ren,David Z. Pan*

Main category: cs.AI

TL;DR: HeaRT是一个基础推理引擎，用于自动化循环，是迈向智能、自适应、类人设计优化的第一步。它在40电路基准测试中表现出>97%的推理准确率和>98%的Pass@1性能，同时运行成本仅为SOTA基线的<0.5倍。


<details>
  <summary>Details</summary>
Motivation: 传统的AI驱动AMS设计自动化算法受限于对高质量数据集的依赖、跨架构可移植性差以及缺乏自适应机制。

Method: 提出HeaRT基础推理引擎，作为自动化循环的核心组件，实现智能、自适应的设计优化。

Result: 在40电路基准测试中，推理准确率>97%，Pass@1性能>98%，运行成本仅为SOTA基线的<0.5倍，在尺寸和拓扑设计适应任务中收敛速度提高>3倍。

Conclusion: HeaRT是一个有效的智能设计优化引擎，能够保持先前的设计意图，同时在复杂电路设计中保持高性能。

Abstract: Conventional AI-driven AMS design automation algorithms remain constrained by their reliance on high-quality datasets to capture underlying circuit behavior, coupled with poor transferability across architectures, and a lack of adaptive mechanisms. This work proposes HeaRT, a foundational reasoning engine for automation loops and a first step toward intelligent, adaptive, human-style design optimization. HeaRT consistently demonstrates reasoning accuracy >97% and Pass@1 performance >98% across our 40-circuit benchmark repository, even as circuit complexity increases, while operating at <0.5x real-time token budget of SOTA baselines. Our experiments show that HeaRT yields >3x faster convergence in both sizing and topology design adaptation tasks across diverse optimization approaches, while preserving prior design intent.

</details>


### [3] [FISCAL: Financial Synthetic Claim-document Augmented Learning for Efficient Fact-Checking](https://arxiv.org/abs/2511.19671)
*Rishab Sharma,Iman Saberi,Elham Alipour,Jie JW Wu,Fatemeh Fard*

Main category: cs.AI

TL;DR: FISCAL框架通过生成金融领域合成数据训练轻量级验证器MiniCheck-FISCAL，在金融事实核查任务中超越GPT-3.5 Turbo等模型，接近更大模型的性能。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在金融应用中存在幻觉问题和计算效率低下的挑战，需要事实可靠且计算高效的解决方案。

Method: 提出FISCAL框架生成金融合成数据，并训练轻量级验证器MiniCheck-FISCAL用于金融数字声明验证。

Result: MiniCheck-FISCAL在多个金融数据集上超越GPT-3.5 Turbo等同类模型，接近Mixtral-8x22B等大20倍模型的准确性，在外部数据集上媲美GPT-4o和Claude-3.5。

Conclusion: 领域特定的合成数据结合高效微调可使紧凑模型在金融AI中实现最先进的准确性、鲁棒性和可扩展性。

Abstract: Financial applications of large language models (LLMs) require factual reliability and computational efficiency, yet current systems often hallucinate details and depend on prohibitively large models. We propose FISCAL (Financial Synthetic Claim-Document Augmented Learning), a modular framework for generating synthetic data tailored to financial fact-checking. Using FISCAL, we generate a dataset called FISCAL-data and use it to train MiniCheck-FISCAL, a lightweight verifier for numerical financial claims. MiniCheck-FISCAL outperforms its baseline, surpasses GPT-3.5 Turbo and other open-source peers of similar size, and approaches the accuracy of much larger systems (20x), such as Mixtral-8x22B and Command R+. On external datasets FinDVer and Fin-Fact, it rivals GPT-4o and Claude-3.5 while outperforming Gemini-1.5 Flash. These results show that domain-specific synthetic data, combined with efficient fine-tuning, enables compact models to achieve state-of-the-art accuracy, robustness, and scalability for practical financial AI. The dataset and scripts are available in the project repository (link provided in the paper).

</details>


### [4] [Scaling Item-to-Standard Alignment with Large Language Models: Accuracy, Limits, and Solutions](https://arxiv.org/abs/2511.19749)
*Farzan Karimi-Malekabadi,Pooya Razavi,Sonya Powers*

Main category: cs.AI

TL;DR: 本研究探讨了大型语言模型（LLMs）在教育评估项目与内容标准对齐过程中的应用潜力，通过三个实验验证了LLMs在识别错位项目、选择正确技能和预筛选候选技能方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统的人工对齐审查虽然准确但耗时耗力，特别是在大规模项目库中。本研究旨在探索LLMs是否能加速这一过程而不牺牲准确性。

Method: 使用超过12,000个项目-技能对，测试了三种LLMs（GPT-3.5 Turbo、GPT-4o-mini和GPT-4o）在三个任务上的表现：识别错位项目、从完整标准集中选择正确技能、以及在分类前缩小候选列表。

Result: GPT-4o-mini在识别对齐状态方面达到83-94%的准确率；数学领域表现强劲，阅读领域因语义重叠而表现较低；预筛选候选技能后，正确技能出现在前五建议中的概率超过95%。

Conclusion: LLMs，特别是结合候选筛选策略时，能显著减少项目审查的人工负担，同时保持对齐准确性。建议开发混合流程，将基于LLM的筛选与模糊情况下的人工审查相结合。

Abstract: As educational systems evolve, ensuring that assessment items remain aligned with content standards is essential for maintaining fairness and instructional relevance. Traditional human alignment reviews are accurate but slow and labor-intensive, especially across large item banks. This study examines whether Large Language Models (LLMs) can accelerate this process without sacrificing accuracy. Using over 12,000 item-skill pairs in grades K-5, we tested three LLMs (GPT-3.5 Turbo, GPT-4o-mini, and GPT-4o) across three tasks that mirror real-world challenges: identifying misaligned items, selecting the correct skill from the full set of standards, and narrowing candidate lists prior to classification. In Study 1, GPT-4o-mini correctly identified alignment status in approximately 83-94% of cases, including subtle misalignments. In Study 2, performance remained strong in mathematics but was lower for reading, where standards are more semantically overlapping. Study 3 demonstrated that pre-filtering candidate skills substantially improved results, with the correct skill appearing among the top five suggestions more than 95% of the time. These findings suggest that LLMs, particularly when paired with candidate filtering strategies, can significantly reduce the manual burden of item review while preserving alignment accuracy. We recommend the development of hybrid pipelines that combine LLM-based screening with human review in ambiguous cases, offering a scalable solution for ongoing item validation and instructional alignment.

</details>


### [5] [KOM: A Multi-Agent Artificial Intelligence System for Precision Management of Knee Osteoarthritis (KOA)](https://arxiv.org/abs/2511.19798)
*Weizhi Liu,Xi Chen,Zekun Jiang,Liang Zhao,Kunyuan Jiang,Ruisi Tang,Li Wang,Mingke You,Hanyu Zhou,Hongyu Chen,Qiankun Xiong,Yong Nie,Kang Li,Jian Li*

Main category: cs.AI

TL;DR: 开发了KOM多智能体系统，用于自动化膝骨关节炎的评估、风险预测和治疗处方，在临床工作流程中可显著提高护理效率。


<details>
  <summary>Details</summary>
Motivation: 膝骨关节炎影响全球6亿多人，个性化多学科干预需要大量医疗资源，在资源有限环境中难以实施。

Method: 开发KOM多智能体系统，自动化KOA评估、风险预测和治疗处方，基于患者个人资料、疾病状态、风险因素和禁忌症生成定制管理计划。

Result: 基准实验显示KOM在影像分析和处方生成方面优于通用大语言模型；随机三臂模拟研究表明KOM与临床医生合作可将诊断和规划时间减少38.5%，并提高治疗质量。

Conclusion: KOM有助于促进自动化KOA管理，其模块化架构为开发其他慢性病的AI辅助管理系统提供了宝贵见解。

Abstract: Knee osteoarthritis (KOA) affects more than 600 million individuals globally and is associated with significant pain, functional impairment, and disability. While personalized multidisciplinary interventions have the potential to slow disease progression and enhance quality of life, they typically require substantial medical resources and expertise, making them difficult to implement in resource-limited settings. To address this challenge, we developed KOM, a multi-agent system designed to automate KOA evaluation, risk prediction, and treatment prescription. This system assists clinicians in performing essential tasks across the KOA care pathway and supports the generation of tailored management plans based on individual patient profiles, disease status, risk factors, and contraindications. In benchmark experiments, KOM demonstrated superior performance compared to several general-purpose large language models in imaging analysis and prescription generation. A randomized three-arm simulation study further revealed that collaboration between KOM and clinicians reduced total diagnostic and planning time by 38.5% and resulted in improved treatment quality compared to each approach used independently. These findings indicate that KOM could help facilitate automated KOA management and, when integrated into clinical workflows, has the potential to enhance care efficiency. The modular architecture of KOM may also offer valuable insights for developing AI-assisted management systems for other chronic conditions.

</details>


### [6] [A Unified Evaluation-Instructed Framework for Query-Dependent Prompt Optimization](https://arxiv.org/abs/2511.19829)
*Ke Chen,Yifeng Wang,Hassan Almosapeeh,Haohan Wang*

Main category: cs.AI

TL;DR: 本文提出了一种基于评估指导的提示优化方法，通过建立系统化的提示评估框架和免执行评估器，实现可解释的、查询相关的提示优化，在多个数据集和骨干模型上超越现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有提示优化方法主要优化单一静态模板，在复杂动态用户场景中效果有限；现有查询相关方法依赖不稳定的文本反馈或黑盒奖励模型，提供弱且不可解释的优化信号；提示质量本身缺乏统一系统定义，导致评估信号碎片化不可靠。

Method: 首先建立以性能为导向的系统化提示评估框架；开发并微调免执行评估器，直接从文本预测多维度质量分数；评估器指导指标感知优化器，以可解释方式诊断失败模式并重写提示。

Result: 评估器在预测提示性能方面达到最高准确率；评估指导的优化在8个数据集和3个骨干模型上持续超越静态模板和查询相关基线方法。

Conclusion: 提出了统一的、基于指标的提示质量视角，证明评估指导的优化流程能在多样化任务中提供稳定、可解释且模型无关的改进。

Abstract: Most prompt-optimization methods refine a single static template, making them ineffective in complex and dynamic user scenarios. Existing query-dependent approaches rely on unstable textual feedback or black-box reward models, providing weak and uninterpretable optimization signals. More fundamentally, prompt quality itself lacks a unified, systematic definition, resulting in fragmented and unreliable evaluation signals. Our approach first establishes a performance-oriented, systematic, and comprehensive prompt evaluation framework. Furthermore, we develop and finetune an execution-free evaluator that predicts multi-dimensional quality scores directly from text. The evaluator then instructs a metric-aware optimizer that diagnoses failure modes and rewrites prompts in an interpretable, query-dependent manner. Our evaluator achieves the strongest accuracy in predicting prompt performance, and the evaluation-instructed optimization consistently surpass both static-template and query-dependent baselines across eight datasets and on three backbone models. Overall, we propose a unified, metric-grounded perspective on prompt quality, and demonstrated that our evaluation-instructed optimization pipeline delivers stable, interpretable, and model-agnostic improvements across diverse tasks.

</details>


### [7] [Reinforcement Learning with $ω$-Regular Objectives and Constraints](https://arxiv.org/abs/2511.19849)
*Dominik Wagner,Leon Witzman,Luke Ong*

Main category: cs.AI

TL;DR: 该论文提出了一种结合ω-正则目标与显式约束的强化学习方法，通过线性规划算法最大化满足ω-正则目标的概率，同时确保满足ω-正则约束在指定阈值内。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习依赖标量奖励，表达能力有限且容易导致奖励黑客行为，无法有效表达时间性、条件性或安全关键目标。ω-正则目标能精确指定丰富的行为属性，但单一标量性能度量掩盖了安全与性能之间的权衡。

Method: 开发基于线性规划的模型强化学习算法，将ω-正则目标与约束分离处理，建立到约束极限平均问题的转换并保持最优性保证。

Result: 在极限情况下，该算法能产生最大化满足ω-正则目标概率的策略，同时确保ω-正则约束在指定阈值内得到满足。

Conclusion: 该方法同时解决了强化学习中奖励表达能力和安全-性能权衡两个关键问题，为处理复杂行为规范和安全要求提供了有效框架。

Abstract: Reinforcement learning (RL) commonly relies on scalar rewards with limited ability to express temporal, conditional, or safety-critical goals, and can lead to reward hacking. Temporal logic expressible via the more general class of $ω$-regular objectives addresses this by precisely specifying rich behavioural properties. Even still, measuring performance by a single scalar (be it reward or satisfaction probability) masks safety-performance trade-offs that arise in settings with a tolerable level of risk.
  We address both limitations simultaneously by combining $ω$-regular objectives with explicit constraints, allowing safety requirements and optimisation targets to be treated separately. We develop a model-based RL algorithm based on linear programming, which in the limit produces a policy maximising the probability of satisfying an $ω$-regular objective while also adhering to $ω$-regular constraints within specified thresholds. Furthermore, we establish a translation to constrained limit-average problems with optimality-preserving guarantees.

</details>


### [8] [MicroSims: A Framework for AI-Generated, Scalable Educational Simulations with Universal Embedding and Adaptive Learning Support](https://arxiv.org/abs/2511.19864)
*Valerie Lockhart,Dan McCreary,Troy A. Peterson*

Main category: cs.AI

TL;DR: MicroSims是一个用于创建轻量级交互式教育模拟的新框架，通过AI快速生成、跨平台嵌入和无编程定制，解决了传统模拟创建资源密集和技术要求高的问题。


<details>
  <summary>Details</summary>
Motivation: 传统教育模拟创建需要大量资源和技术专长，限制了其广泛应用。MicroSims旨在通过AI辅助生成和标准化设计模式，降低创建门槛，提高教育公平性。

Method: 采用标准化设计模式支持AI辅助生成，基于iframe的架构实现通用嵌入和安全沙箱，提供透明可修改代码支持定制和教学透明度。

Result: 研究表明交互式模拟相比传统教学可将概念理解提高30-40%，MicroSims在保持这些优势的同时解决了成本、技术复杂性和平台依赖等长期障碍。

Conclusion: MicroSims为教育公平和低成本智能交互式教科书提供了重要基础，使全球教育工作者能够按需创建定制化、与课程对齐的模拟，并支持未来AI驱动的自适应学习系统发展。

Abstract: Educational simulations have long been recognized as powerful tools for enhancing learning outcomes, yet their creation has traditionally required substantial resources and technical expertise. This paper introduces MicroSims a novel framework for creating lightweight, interactive educational simulations that can be rapidly generated using artificial intelligence, universally embedded across digital learning platforms, and easily customized without programming knowledge. MicroSims occupy a unique position at the intersection of three key innovations: (1) standardized design patterns that enable AI-assisted generation, (2) iframe-based architecture that provides universal embedding and sandboxed security, and (3) transparent, modifiable code that supports customization and pedagogical transparency. We present a comprehensive framework encompassing design principles, technical architecture, metadata standards, and development workflows. Drawing on empirical research from physics education studies and meta-analyses across STEM disciplines, we demonstrate that interactive simulations can improve conceptual understanding by up to 30-40\% compared to traditional instruction. MicroSims extend these benefits while addressing persistent barriers of cost, technical complexity, and platform dependence. This work has significant implications for educational equity, and low-cost intelligent interactive textbooks that enabling educators worldwide to create customized, curriculum-aligned simulations on demand. We discuss implementation considerations, present evidence of effectiveness, and outline future directions for AI-powered adaptive learning systems built on the MicroSim foundation.

</details>


### [9] [Simulated Self-Assessment in Large Language Models: A Psychometric Approach to AI Self-Efficacy](https://arxiv.org/abs/2511.19872)
*Daniel I Jackson,Emma L Jensen,Syed-Amad Hussain,Emre Sezgin*

Main category: cs.AI

TL;DR: 本研究将通用自我效能感量表(GSES)应用于10个大语言模型，在四种任务条件下评估其模拟自我评估行为。结果显示模型自我评估稳定但普遍低于人类水平，且自我评估与实际能力不匹配，存在轻度高估倾向。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型评估主要关注任务准确性，而忽视了自我评估这一可靠智能的关键方面。本研究旨在探索LLMs的模拟自我评估行为及其与实际表现的关系。

Method: 将10项通用自我效能感量表(GSES)适配用于10个LLMs，在四种条件下(无任务、计算推理、社会推理、摘要)进行测试，分析自我评估的稳定性、准确性以及与表现的关系。

Result: 模型自我评估在不同条件下显著差异，总体低于人类标准；所有模型在计算和社会推理任务中表现完美，但摘要任务表现差异大；自我评估与能力不匹配，存在轻度高估；高自我效能模型表现出更自信、拟人化的推理风格。

Conclusion: 心理测量提示为理解LLM沟通行为提供了结构化洞察，但不能提供校准的性能估计，自我评估与实际能力之间存在脱节。

Abstract: Self-assessment is a key aspect of reliable intelligence, yet evaluations of large language models (LLMs) focus mainly on task accuracy. We adapted the 10-item General Self-Efficacy Scale (GSES) to elicit simulated self-assessments from ten LLMs across four conditions: no task, computational reasoning, social reasoning, and summarization. GSES responses were highly stable across repeated administrations and randomized item orders. However, models showed significantly different self-efficacy levels across conditions, with aggregate scores lower than human norms. All models achieved perfect accuracy on computational and social questions, whereas summarization performance varied widely. Self-assessment did not reliably reflect ability: several low-scoring models performed accurately, while some high-scoring models produced weaker summaries. Follow-up confidence prompts yielded modest, mostly downward revisions, suggesting mild overestimation in first-pass assessments. Qualitative analysis showed that higher self-efficacy corresponded to more assertive, anthropomorphic reasoning styles, whereas lower scores reflected cautious, de-anthropomorphized explanations. Psychometric prompting provides structured insight into LLM communication behavior but not calibrated performance estimates.

</details>


### [10] [RPM-MCTS: Knowledge-Retrieval as Process Reward Model with Monte Carlo Tree Search for Code Generation](https://arxiv.org/abs/2511.19895)
*Yuanyuan Lin,Xiangyu Ouyang,Teng Zhang,Kaixin Sui*

Main category: cs.AI

TL;DR: RPM-MCTS是一种基于蒙特卡洛树搜索的代码生成方法，通过知识检索作为过程奖励模型来评估中间算法步骤，无需复杂训练。该方法使用相似性过滤去除冗余节点，并利用沙箱执行反馈定位和纠正错误步骤，在减少15%令牌消耗的同时优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于树搜索的代码生成方法难以有效评估中间算法步骤，无法及时定位和纠正错误步骤，导致生成错误代码和计算成本增加。

Method: 提出RPM-MCTS方法：1）使用知识检索作为过程奖励模型评估中间步骤；2）在扩展阶段采用相似性过滤去除冗余节点；3）利用沙箱执行反馈定位和纠正错误算法步骤。

Result: 在四个公共代码生成基准测试中，RPM-MCTS优于当前最先进方法，同时实现约15%的令牌消耗减少。使用RPM-MCTS构建的数据对基础模型进行全微调可显著提升其代码能力。

Conclusion: RPM-MCTS通过知识检索和沙箱反馈机制有效解决了中间步骤评估和错误纠正问题，在提升代码生成质量的同时降低了计算成本。

Abstract: Tree search-based methods have made significant progress in enhancing the code generation capabilities of large language models. However, due to the difficulty in effectively evaluating intermediate algorithmic steps and the inability to locate and timely correct erroneous steps, these methods often generate incorrect code and incur increased computational costs. To tackle these problems, we propose RPM-MCTS, an effective method that utilizes Knowledge-Retrieval as Process Reward Model based on Monte Carlo Tree Search to evaluate intermediate algorithmic steps. By utilizing knowledge base retrieval, RPM-MCTS avoids the complex training of process reward models. During the expansion phase, similarity filtering is employed to remove redundant nodes, ensuring diversity in reasoning paths. Furthermore, our method utilizes sandbox execution feedback to locate erroneous algorithmic steps during generation, enabling timely and targeted corrections. Extensive experiments on four public code generation benchmarks demonstrate that RPM-MCTS outperforms current state-of-the-art methods while achieving an approximately 15% reduction in token consumption. Furthermore, full fine-tuning of the base model using the data constructed by RPM-MCTS significantly enhances its code capabilities.

</details>


### [11] [Semantic-KG: Using Knowledge Graphs to Construct Benchmarks for Measuring Semantic Similarity](https://arxiv.org/abs/2511.19925)
*Qiyao Wei,Edward Morrell,Lea Goetz,Mihaela van der Schaar*

Main category: cs.AI

TL;DR: 本文提出了一种基于知识图谱生成基准数据集的新方法，用于评估LLM输出语义相似度方法，解决了现有基准依赖人工标注、成本高、领域适用性有限等问题。


<details>
  <summary>Details</summary>
Motivation: 现有评估LLM文本输出的语义相似度方法可能更关注句法或词汇形式而非语义内容，且现有基准存在生成成本高、领域适用性有限、语义等价定义不明确等局限性。

Method: 利用知识图谱生成语义相似或不相似的自然语言陈述对，其中不相似对分为四种子类型，在四个不同领域生成基准数据集，并比较传统NLP评分和LLM作为评判者的预测方法。

Result: 研究发现语义变化的子类型以及基准领域都会影响语义相似度方法的性能，没有一种方法始终表现最优。

Conclusion: 研究结果对使用LLM作为评判者检测文本语义内容具有重要启示，表明需要更细致地考虑语义变化类型和领域特性。

Abstract: Evaluating the open-form textual responses generated by Large Language Models (LLMs) typically requires measuring the semantic similarity of the response to a (human generated) reference. However, there is evidence that current semantic similarity methods may capture syntactic or lexical forms over semantic content. While benchmarks exist for semantic equivalence, they often suffer from high generation costs due to reliance on subjective human judgment, limited availability for domain-specific applications, and unclear definitions of equivalence. This paper introduces a novel method for generating benchmarks to evaluate semantic similarity methods for LLM outputs, specifically addressing these limitations. Our approach leverages knowledge graphs (KGs) to generate pairs of natural-language statements that are semantically similar or dissimilar, with dissimilar pairs categorized into one of four sub-types. We generate benchmark datasets in four different domains (general knowledge, biomedicine, finance, biology), and conduct a comparative study of semantic similarity methods including traditional natural language processing scores and LLM-as-a-judge predictions. We observe that the sub-type of semantic variation, as well as the domain of the benchmark impact the performance of semantic similarity methods, with no method being consistently superior. Our results present important implications for the use of LLM-as-a-judge in detecting the semantic content of text. Code is available at https://github.com/QiyaoWei/semantic-kg and the dataset is available at https://huggingface.co/datasets/QiyaoWei/Semantic-KG.

</details>


### [12] [A System-Level Taxonomy of Failure Modes in Large Language Model Applications](https://arxiv.org/abs/2511.19933)
*Vaishali Vinay*

Main category: cs.AI

TL;DR: 本文提出了一个针对现实世界LLM应用的15种隐藏故障模式的系统级分类法，分析了评估与监控实践的差距，并探讨了部署LLM的生产挑战和设计原则。


<details>
  <summary>Details</summary>
Motivation: LLM被快速集成到决策支持工具和自动化工作流中，但其在生产环境中的行为仍知之甚少，且故障模式与传统机器学习模型有根本不同。

Method: 提出系统级故障模式分类法，分析评估监控差距，研究部署挑战，并制定设计原则。

Result: 识别了15种隐藏故障模式，揭示了评估实践与生产需求之间的差距，并提出了构建可靠LLM系统的设计原则。

Conclusion: 通过将LLM可靠性视为系统工程问题而非纯模型中心问题，为未来评估方法、AI系统鲁棒性和可靠LLM部署研究提供了分析基础。

Abstract: Large language models (LLMs) are being rapidly integrated into decision-support tools, automation workflows, and AI-enabled software systems. However, their behavior in production environments remains poorly understood, and their failure patterns differ fundamentally from those of traditional machine learning models. This paper presents a system-level taxonomy of fifteen hidden failure modes that arise in real-world LLM applications, including multi-step reasoning drift, latent inconsistency, context-boundary degradation, incorrect tool invocation, version drift, and cost-driven performance collapse. Using this taxonomy, we analyze the growing gap in evaluation and monitoring practices: existing benchmarks measure knowledge or reasoning but provide little insight into stability, reproducibility, drift, or workflow integration. We further examine the production challenges associated with deploying LLMs - including observability limitations, cost constraints, and update-induced regressions - and outline high-level design principles for building reliable, maintainable, and cost-aware LLM systems. Finally, we outline high-level design principles for building reliable, maintainable, and cost-aware LLM-based systems. By framing LLM reliability as a system-engineering problem rather than a purely model-centric one, this work provides an analytical foundation for future research on evaluation methodology, AI system robustness, and dependable LLM deployment.

</details>


### [13] [M$^3$Prune: Hierarchical Communication Graph Pruning for Efficient Multi-Modal Multi-Agent Retrieval-Augmented Generation](https://arxiv.org/abs/2511.19969)
*Weizi Shao,Taolin Zhang,Zijie Zhou,Chen Chen,Chengyu Wang,Xiaofeng He*

Main category: cs.AI

TL;DR: 提出了M³Prune框架，通过多模态多智能体层次化通信图剪枝，在保持任务性能的同时显著减少token开销和计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统存在显著的token开销和计算成本问题，限制了大规模部署。需要找到任务性能和token开销之间的最佳平衡。

Method: 采用多模态多智能体层次化通信图剪枝框架，包括：1）文本和视觉模态的图稀疏化；2）构建动态通信拓扑；3）逐步剪枝冗余边。

Result: 在通用和领域特定的mRAG基准测试中，该方法始终优于单智能体和鲁棒多智能体系统，同时显著减少token消耗。

Conclusion: M³Prune框架有效解决了多智能体系统的token开销问题，实现了性能与效率的平衡，具有大规模部署的潜力。

Abstract: Recent advancements in multi-modal retrieval-augmented generation (mRAG), which enhance multi-modal large language models (MLLMs) with external knowledge, have demonstrated that the collective intelligence of multiple agents can significantly outperform a single model through effective communication. Despite impressive performance, existing multi-agent systems inherently incur substantial token overhead and increased computational costs, posing challenges for large-scale deployment. To address these issues, we propose a novel Multi-Modal Multi-agent hierarchical communication graph PRUNING framework, termed M$^3$Prune. Our framework eliminates redundant edges across different modalities, achieving an optimal balance between task performance and token overhead. Specifically, M$^3$Prune first applies intra-modal graph sparsification to textual and visual modalities, identifying the edges most critical for solving the task. Subsequently, we construct a dynamic communication topology using these key edges for inter-modal graph sparsification. Finally, we progressively prune redundant edges to obtain a more efficient and hierarchical topology. Extensive experiments on both general and domain-specific mRAG benchmarks demonstrate that our method consistently outperforms both single-agent and robust multi-agent mRAG systems while significantly reducing token consumption.

</details>


### [14] [VICoT-Agent: A Vision-Interleaved Chain-of-Thought Framework for Interpretable Multimodal Reasoning and Scalable Remote Sensing Analysis](https://arxiv.org/abs/2511.20085)
*Chujie Wang,Zhiyuan Luo,Ruiqi Liu,Can Ran,Shenghua Fan,Xi Chen,Chu He*

Main category: cs.AI

TL;DR: 提出了一种新的多模态智能体框架VICoT，通过将视觉工具动态集成到思维链中实现显式多轮推理，在遥感图像分析任务中显著优于现有SOTA框架。


<details>
  <summary>Details</summary>
Motivation: 遥感图像分析任务正从传统目标识别向复杂智能推理演进，对模型推理能力和工具调用灵活性提出更高要求。

Method: 采用基于堆栈的推理结构和模块化MCP兼容工具套件，使LLM能够高效执行多轮交错视觉语言推理任务；提出推理堆栈蒸馏方法将复杂智能体行为迁移到轻量级模型。

Result: 在多个遥感基准测试中，VICoT在推理透明度、执行效率和生成质量方面显著优于现有SOTA框架。

Conclusion: VICoT框架通过动态集成视觉工具到思维链中，实现了高效的多轮视觉语言推理，同时通过蒸馏方法确保了推理能力的同时显著降低了复杂度。

Abstract: The current remote sensing image analysis task is increasingly evolving from traditional object recognition to complex intelligence reasoning, which places higher requirements on the model's reasoning ability and the flexibility of tool invocation. To this end, we propose a new multimodal agent framework, Vision-Interleaved Chain-of-Thought Framework (VICoT), which implements explicit multi-round reasoning by dynamically incorporating visual tools into the chain of thought. Through a stack-based reasoning structure and a modular MCP-compatible tool suite, VICoT enables LLMs to efficiently perform multi-round, interleaved vision-language reasoning tasks with strong generalization and flexibility.We also propose the Reasoning Stack distillation method to migrate complex Agent behaviors to small, lightweight models, which ensures the reasoning capability while significantly reducing complexity. Experiments on multiple remote sensing benchmarks demonstrate that VICoT significantly outperforms existing SOTA frameworks in reasoning transparency, execution efficiency, and generation quality.

</details>


### [15] [Interactive AI NPCs Powered by LLMs: Technical Report for the CPDC Challenge 2025](https://arxiv.org/abs/2511.20200)
*Yitian Huang,Yuxuan Lei,Jianxun Lian,Hao Liao*

Main category: cs.AI

TL;DR: 该论文提出了一个简单有效的框架，在CPDC 2025挑战赛中统一改进了GPU和API两个赛道。核心包括上下文工程（动态工具剪枝、角色裁剪、参数归一化等）和GRPO强化学习训练，在多个任务中获得优异成绩。


<details>
  <summary>Details</summary>
Motivation: 解决常识角色对话中的工具调用稳定性、执行可靠性和角色扮演指导问题，同时通过强化学习缓解小样本过拟合，提升任务导向对话性能。

Method: 1. 上下文工程：动态工具剪枝、角色裁剪进行输入压缩，结合参数归一化、函数合并等后处理技术；2. GPU赛道采用GRPO训练，用强化学习替代监督微调，直接优化奖励信号。

Result: 团队在最终评估中：Task 2 API排名第1，Task 1 API排名第2，Task 3 API和GPU赛道均排名第3，证明了方法的有效性。

Conclusion: 提出的框架通过上下文工程和GRPO强化学习的结合，在常识角色对话任务中取得了显著效果，代码已公开。

Abstract: This report presents the solution and results of our team MSRA\_SC in the Commonsense Persona-Grounded Dialogue Challenge (CPDC 2025). We propose a simple yet effective framework that unifies improvements across both GPU Track and API Track. Our method centers on two key components. First, Context Engineering applies dynamic tool pruning and persona clipping for input compression, combined with post-processing techniques such as parameter normalization and function merging. Together with manually refined prompts, this design improves tool call stability, execution reliability, and role-playing guidance. Second, in the GPU Track, we further adopt GRPO training, replacing supervised fine-tuning with reinforcement learning directly optimized by reward signals. This mitigates small-sample overfitting and significantly enhances task-oriented dialogue performance. In the final evaluation, our team ranks 1st in Task 2 API, 2nd in Task 1 API, and 3rd in both Task 3 API and GPU track, demonstrating the effectiveness of our approach. Our code is publicly available at https://gitlab.aicrowd.com/nikoo_yu/cpdc-2025-winning-solution

</details>


### [16] [CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied Agents](https://arxiv.org/abs/2511.20216)
*Haebin Seong,Sungmin Kim,Minchan Kim,Yongjun Cho,Myunchul Joe,Suhwan Choi,Jaeyoon Jung,Jiyong Youn,Yoonshik Kim,Samwoo Seong,Yubeen Park,Youngjae Yu,Yunsung Lee*

Main category: cs.AI

TL;DR: CostNav是首个微导航经济测试平台，通过成本-收益分析评估自主送货机器人的商业可行性，揭示了导航研究指标与商业部署之间的差距。


<details>
  <summary>Details</summary>
Motivation: 现有导航基准主要关注任务成功率，但忽视了经济可行性这一对自主送货机器人商业部署至关重要的因素。

Method: 引入CostNav测试平台，建模完整经济生命周期，包括硬件、训练、能源、维护成本和送货收入，使用行业参数进行成本-收益分析。

Result: 基准测试显示43.0%的服务水平协议合规率，但商业不可行：每次运行亏损30.009美元，维护成本占运行成本的99.7%，碰撞避免是关键优化目标。

Conclusion: CostNav填补了导航研究与商业部署之间的差距，为评估基于规则的导航、模仿学习和成本感知强化学习提供了基础，支持跨导航范式的经济权衡决策。

Abstract: Existing navigation benchmarks focus on task success metrics while overlooking economic viability -- critical for commercial deployment of autonomous delivery robots. We introduce \emph{CostNav}, a \textbf{Micro-Navigation Economic Testbed} that evaluates embodied agents through comprehensive cost-revenue analysis aligned with real-world business operations. CostNav models the complete economic lifecycle including hardware, training, energy, maintenance costs, and delivery revenue with service-level agreements, using industry-derived parameters. \textbf{To our knowledge, CostNav is the first work to quantitatively expose the gap between navigation research metrics and commercial viability}, revealing that optimizing for task success fundamentally differs from optimizing for economic deployment. Our cost model uses parameters derived from industry data sources (energy rates, delivery service pricing), and we project from a reduced-scale simulation to realistic deliveries. Under this projection, the baseline achieves 43.0\% SLA compliance but is \emph{not} commercially viable: yielding a loss of \$30.009 per run with no finite break-even point, because operating costs are dominated by collision-induced maintenance, which accounts for 99.7\% of per-run costs and highlights collision avoidance as a key optimization target. We demonstrate a learning-based on-device navigation baseline and establish a foundation for evaluating rule-based navigation, imitation learning, and cost-aware RL training. CostNav bridges the gap between navigation research and commercial deployment, enabling data-driven decisions about economic trade-offs across navigation paradigms.

</details>


### [17] [Improving Language Agents through BREW](https://arxiv.org/abs/2511.20297)
*Shashank Kirtania,Param Biyani,Priyanshu Gupta,Yasharth Bajpai,Roshni Iyer,Sumit Gulwani,Gustavo Soares*

Main category: cs.AI

TL;DR: BREW框架通过构建和优化经验知识库来改进LLM智能体，相比传统权重优化方法更高效、可解释且可扩展，在多个基准测试中显著提升任务精度并减少API调用。


<details>
  <summary>Details</summary>
Motivation: 解决当前LLM智能体训练方法计算成本高、策略难以解释和增量改进的问题，探索通过经验知识库构建作为智能体优化的替代途径。

Method: 提出BREW框架，通过任务评分和行为准则学习洞察，利用状态空间搜索确保鲁棒性，并引入有效的记忆分区方法以提高检索和优化效率。

Result: 在OSWorld、τ²Bench和SpreadsheetBench基准测试中，BREW实现了10-20%的任务精度提升，10-15%的API/工具调用减少，执行时间更快，同时保持与基础模型相当的计算效率。

Conclusion: BREW将知识库确立为智能体优化的模块化和可控基础，提供透明、可解释和可扩展的行为塑造机制，相比静态上下文记忆方法具有显著优势。

Abstract: Large Language Model (LLM)-based agents are increasingly applied to tasks requiring structured reasoning, tool use, and environmental adaptation, such as data manipulation, multistep planning, and computer-use automation. However, despite their versatility, current training paradigms for model weight optimization methods, like PPO and GRPO, remain relatively impractical with their high computational overhead for rollout convergence. In addition, the resulting agent policies are difficult to interpret, adapt, or incrementally improve. To address this, we investigate creating and refining structured memory of experiential learning of an agent from its environment as an alternative route to agent optimization. We introduce BREW (Bootstrapping expeRientially-learned Environmental knoWledge), a framework for agent optimization for downstream tasks via KB construction and refinement. In our formulation, we introduce an effective method for partitioning agent memory for more efficient retrieval and refinement. BREW uses task graders and behavior rubrics to learn insights while leveraging state-space search for ensuring robustness from the noise and non-specificity in natural language. Empirical results on real world, domain-grounded benchmarks -- OSWorld, $τ^2$Bench, and SpreadsheetBench -- show BREW achieves $10-20\%$ improvement in task precision, $10-15\%$ reduction in API/tool calls leading to faster execution time, all while maintaining computational efficiency on par with base models. Unlike prior work where memory is treated as static context, we establish the KB as a modular and controllable substrate for agent optimization -- an explicit lever for shaping behavior in a transparent, interpretable, and extensible manner.

</details>


### [18] [Active Inference in Discrete State Spaces from First Principles](https://arxiv.org/abs/2511.20321)
*Patrick Kenny*

Main category: cs.AI

TL;DR: 本文旨在澄清主动推理概念，将其与自由能原理分离。作者展示了在离散状态空间中实现主动推理的优化问题可以表述为约束散度最小化问题，可通过标准平均场方法求解，无需诉诸期望自由能概念。


<details>
  <summary>Details</summary>
Motivation: 澄清主动推理与自由能原理之间的关系，提供一种不依赖期望自由能的替代实现方法。

Method: 将主动推理优化问题重新表述为约束散度最小化问题，使用标准平均场方法求解。在感知建模时采用感知/行动散度准则，在行动建模时引入熵正则化项。

Result: 提出的感知/行动散度准则在感知建模时与变分自由能一致，在行动建模时与期望自由能泛函相差一个熵正则化项。

Conclusion: 主动推理可以在不依赖期望自由能概念的情况下实现，通过约束散度最小化框架提供了一种替代的实现途径。

Abstract: We seek to clarify the concept of active inference by disentangling it from the Free Energy Principle. We show how the optimizations that need to be carried out in order to implement active inference in discrete state spaces can be formulated as constrained divergence minimization problems which can be solved by standard mean field methods that do not appeal to the idea of expected free energy. When it is used to model perception, the perception/action divergence criterion that we propose coincides with variational free energy. When it is used to model action, it differs from an expected free energy functional by an entropy regularizer.

</details>


### [19] [VibraVerse: A Large-Scale Geometry-Acoustics Alignment Dataset for Physically-Consistent Multimodal Learning](https://arxiv.org/abs/2511.20422)
*Bo Pang,Chenxi Xu,Jierui Ren,Guoping Wang,Sheng Li*

Main category: cs.AI

TL;DR: VibraVerse是一个大规模几何-声学对齐数据集，通过CLASP对比学习框架建立物体物理结构与声学响应的因果对应关系，为物理一致的多模态学习提供基准。


<details>
  <summary>Details</summary>
Motivation: 现有多模态学习框架缺乏物理一致性，忽视了物体几何、材料、振动模式和产生声音之间的内在因果关系。需要建立基于物理定律而非统计相关性的感知模型。

Method: 构建VibraVerse数据集，包含3D模型的物理属性（密度、杨氏模量、泊松比）和体积几何，计算模态特征参数用于冲击声合成。使用CLASP对比学习框架进行跨模态对齐。

Result: 在几何到声音预测、声音引导形状重建和跨模态表示学习等基准任务上，基于VibraVerse训练的模型展现出更高的准确性、可解释性和跨模态泛化能力。

Conclusion: VibraVerse为物理一致和因果可解释的多模态学习建立了基准，为声音引导的具身感知和对物理世界的深入理解奠定了基础。

Abstract: Understanding the physical world requires perceptual models grounded in physical laws rather than mere statistical correlations. However, existing multimodal learning frameworks, focused on vision and language, lack physical consistency and overlook the intrinsic causal relationships among an object's geometry, material, vibration modes, and the sounds it produces. We introduce VibraVerse, a large-scale geometry-acoustics alignment dataset that explicitly bridges the causal chain from 3D geometry -> physical attributes -> modal parameters -> acoustic signals. Each 3D model has explicit physical properties (density, Young's modulus, Poisson's ratio) and volumetric geometry, from which modal eigenfrequencies and eigenvectors are computed for impact sound synthesis under controlled excitations. To establish this coherence, we introduce CLASP, a contrastive learning framework for cross-modal alignment that preserves the causal correspondence between an object's physical structure and its acoustic response. This framework enforces physically consistent alignment across modalities, ensuring that every sample is coherent, traceable to the governing equations, and embedded within a unified representation space spanning shape, image, and sound. Built upon VibraVerse, we define a suite of benchmark tasks for geometry-to-sound prediction, sound-guided shape reconstruction, and cross-modal representation learning. Extensive validations on these tasks demonstrate that models trained on VibraVerse exhibit superior accuracy, interpretability, and generalization across modalities. These results establish VibraVerse as a benchmark for physically consistent and causally interpretable multimodal learning, providing a foundation for sound-guided embodied perception and a deeper understanding of the physical world. The dataset will be open-sourced.

</details>


### [20] [DRAFT-RL: Multi-Agent Chain-of-Draft Reasoning for Reinforcement Learning-Enhanced LLMs](https://arxiv.org/abs/2511.20468)
*Yuanhao Li,Mingshan Liu,Hongbo Wang,Yiding Zhang,Yifei Ma,Wei Tan*

Main category: cs.AI

TL;DR: DRAFT-RL是一个新颖的多智能体强化学习框架，通过集成链式草稿推理，让每个智能体为每个查询生成多个草稿，然后由同伴智能体和学习到的奖励模型评估，选择最有希望的轨迹来优化推理策略。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的多智能体反思框架通常依赖单次响应，缺乏推理探索的结构多样性，限制了LLM智能体的推理能力和鲁棒性。

Method: 提出DRAFT-RL框架，将链式草稿推理集成到多智能体RL训练中，每个智能体生成多个草稿，通过同伴评估和奖励模型选择最优轨迹，使用actor-critic学习优化推理策略。

Result: 在代码合成、符号数学和知识密集型QA等复杂推理任务上，DRAFT-RL在准确性和收敛速度方面显著优于现有的反思和基于RL的智能体。

Conclusion: DRAFT-RL通过显式多路径探索、同伴引导反思和奖励对齐选择，实现了更鲁棒和可解释的LLM智能体行为。

Abstract: Large Language Models (LLMs) have shown impressive capabilities in multi-step reasoning and problem-solving.Recent works introduce multi-agent reflection frameworks where multiple LLM agents critique and refine each other's outputs using reinforcement learning (RL). However, these approaches often rely on single-shot responses and lack structural diversity in reasoning exploration. In this paper, we propose DRAFT-RL, a novel framework that integrates Chain-of-Draft (CoD) reasoning into multi-agent RL training. Instead of generating single responses, each agent produces multiple drafts per query, which are then evaluated by peer agents and a learned reward model to identify the most promising trajectory. These selected drafts are used to refine future reasoning strategies through actor-critic learning.DRAFT-RL enables explicit multi-path exploration, peer-guided reflection, and reward-aligned selection, resulting in more robust and interpretable LLM agent behavior. We evaluate our method on complex reasoning tasks including code synthesis, symbolic math, and knowledge-intensive QA,demonstrating that DRAFT-RL outperforms existing reflective and RL-based agents by significant margins in both accuracy and convergence speed

</details>


### [21] [Universe of Thoughts: Enabling Creative Reasoning with Large Language Models](https://arxiv.org/abs/2511.20471)
*Yuto Suzuki,Farnoush Banaei-Kashani*

Main category: cs.AI

TL;DR: 本文提出了一个基于大语言模型的创造性推理框架，包含组合式、探索式和转化式三种核心推理范式，并开发了Universe of Thoughts方法来实现这些创造性过程。


<details>
  <summary>Details</summary>
Motivation: 现有推理模型主要关注常规问题解决，但在药物发现、商业战略等需要创新解决方案的领域，创造性推理至关重要。本文旨在填补这一研究空白。

Method: 提出了基于认知科学原理的计算框架，包含三种创造性推理范式：组合式、探索式和转化式推理，并开发了Universe of Thoughts方法来实现这些过程。

Result: 与最先进的推理技术和代表性商业模型相比，UoT在创造性推理方面表现出优越性能。

Conclusion: UoT框架能够有效支持创造性推理，在需要创新解决方案的复杂问题领域具有重要应用价值。

Abstract: Reasoning based on Large Language Models (LLMs) has garnered increasing attention due to outstanding performance of these models in mathematical and complex logical tasks. Beginning with the Chain-of-Thought (CoT) prompting technique, numerous reasoning methods have emerged that decompose problems into smaller, sequential steps (or thoughts). However, existing reasoning models focus on conventional problem-solving and do not necessarily generate creative solutions by ``creative reasoning''. In domains where the solution space is expansive and conventional solutions are suboptimal, such as drug discovery or business strategization, creative reasoning to discover innovative solutions is crucial. To address this gap, first we introduce a computational framework for creative reasoning inspired by established cognitive science principles. With this framework, we propose three core creative reasoning paradigms, namely, \textit{combinational}, \textit{exploratory}, and \textit{transformative} reasoning, where each offers specific directions for systematic exploration of the universe of thoughts to generate creative solutions. Next, to materialize this framework using LLMs, we introduce the \textit{Universe of Thoughts} (or \textit{UoT}, for short), a novel set of methods to implement the aforementioned three creative processes. Finally, we introduce three novel tasks that necessitate creative problem-solving, along with an evaluation benchmark to assess creativity from three orthogonal perspectives: feasibility as constraint, and utility and novelty as metrics. With a comparative analysis against the state-of-the-art (SOTA) reasoning techniques as well as representative commercial models with reasoning capability, we show that UoT demonstrates superior performance in creative reasoning.

</details>


### [22] [FRAGMENTA: End-to-end Fragmentation-based Generative Model with Agentic Tuning for Drug Lead Optimization](https://arxiv.org/abs/2511.20510)
*Yuto Suzuki,Paul Awolade,Daniel V. LaBarbera,Farnoush Banaei-Kashani*

Main category: cs.AI

TL;DR: FRAGMENTA是一个用于药物先导化合物优化的端到端框架，包含生成模型和智能AI系统，通过动态Q学习优化分子碎片化和生成，并通过对话反馈从领域专家学习知识，在癌症药物发现实验中表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 分子生成在药物发现中很重要，但类别特定的数据集通常少于100个训练样本。现有启发式碎片化方法限制了多样性并遗漏关键片段，且模型调优需要药物化学家和AI工程师之间缓慢的间接协作。

Method: 1) 将碎片化重构为"词汇选择"问题的新生成模型，使用动态Q学习联合优化碎片化和生成；2) 通过领域专家的对话反馈精炼目标的智能AI系统，从循环中移除AI工程师并逐步学习领域知识以实现自动化调优。

Result: 在真实世界癌症药物发现实验中，FRAGMENTA的人-智能体配置识别的高分分子数量几乎是基准线的两倍。完全自主的智能体-智能体系统优于传统的人-人调优方法。

Conclusion: FRAGMENTA展示了智能调优在捕捉专家意图方面的有效性，能够实现更高效的药物先导化合物优化。

Abstract: Molecule generation using generative AI is vital for drug discovery, yet class-specific datasets often contain fewer than 100 training examples. While fragment-based models handle limited data better than atom-based approaches, existing heuristic fragmentation limits diversity and misses key fragments. Additionally, model tuning typically requires slow, indirect collaboration between medicinal chemists and AI engineers. We introduce FRAGMENTA, an end-to-end framework for drug lead optimization comprising: 1) a novel generative model that reframes fragmentation as a "vocabulary selection" problem, using dynamic Q-learning to jointly optimize fragmentation and generation; and 2) an agentic AI system that refines objectives via conversational feedback from domain experts. This system removes the AI engineer from the loop and progressively learns domain knowledge to eventually automate tuning. In real-world cancer drug discovery experiments, FRAGMENTA's Human-Agent configuration identified nearly twice as many high-scoring molecules as baselines. Furthermore, the fully autonomous Agent-Agent system outperformed traditional Human-Human tuning, demonstrating the efficacy of agentic tuning in capturing expert intent.

</details>


### [23] [Assessing LLMs' Performance: Insights from the Chinese Pharmacist Exam](https://arxiv.org/abs/2511.20526)
*Xinran Wang,Boran Zhu,Shujuan Zhou,Ziwen Long,Dehua Zhou,Shu Zhang*

Main category: cs.AI

TL;DR: 本研究比较了ChatGPT-4o和DeepSeek-R1在中国药师执业资格考试中的表现，发现DeepSeek-R1在准确率上显著优于ChatGPT-4o（90.0% vs 76.1%）。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在数字健康教育和评估中的应用日益增多，需要评估其在专业认证任务中的能力，中国药师执业资格考试为此提供了标准化基准。

Method: 收集2017-2021年官方考试中的2,306道纯文本选择题，排除含表格或图片的题目，以原始中文格式输入模型，评估模型响应的准确率，使用卡方检验和Fisher精确检验进行统计分析。

Result: DeepSeek-R1总体准确率显著高于ChatGPT-4o（90.0% vs 76.1%，p < 0.001），在基础和临床综合模块中表现一致更优，但年度间差异未达到统计显著性。

Conclusion: DeepSeek-R1在药师执业资格考试中表现出色，表明领域特定模型在此类任务中具有潜力，但在法律和伦理敏感情境下仍需人类监督。

Abstract: Background: As large language models (LLMs) become increasingly integrated into digital health education and assessment workflows, their capabilities in supporting high-stakes, domain-specific certification tasks remain underexplored.In China, the national pharmacist licensure exam serves as a standardized benchmark for evaluating pharmacists' clinical and theoretical competencies. Objective: This study aimed to compare the performance of two LLMs: ChatGPT-4o and DeepSeek-R1 on real questions from the Chinese Pharmacist Licensing Examination (2017-2021), and to discuss the implications of these performance differences for AI-enabled formative evaluation. Methods: A total of 2,306 multiple-choice (text-only) questions were compiled from official exams, training materials, and public databases. Questions containing tables or images were excluded. Each item was input in its original Chinese format, and model responses were evaluated for exact accuracy. Pearson's Chi-squared test was used to compare overall performance, and Fisher's exact test was applied to year-wise multiple-choice accuracy. Results: DeepSeek-R1 outperformed ChatGPT-4o with a significantly higher overall accuracy (90.0% vs. 76.1%, p < 0.001). Unit-level analyses revealed consistent advantages for DeepSeek-R1, particularly in foundational and clinical synthesis modules. While year-by-year multiple-choice performance also favored DeepSeek-R1, this performance gap did not reach statistical significance in any specific unit-year (all p > 0.05). Conclusion: DeepSeek-R1 demonstrated robust alignment with the structural and semantic demands of the pharmacist licensure exam. These findings suggest that domain-specific models warrant further investigation for this context, while also reinforcing the necessity of human oversight in legally and ethically sensitive contexts.

</details>


### [24] [Beyond Generation: Multi-Hop Reasoning for Factual Accuracy in Vision-Language Models](https://arxiv.org/abs/2511.20531)
*Shamima Hossain*

Main category: cs.AI

TL;DR: 提出了一个基于知识图谱的视觉语言模型推理框架，通过多跳验证提升事实准确性，在混合数据集上实验显示事实准确率提升约31%。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型虽然功能强大，但经常产生事实不准确的输出，缺乏稳健的推理能力。现有研究主要关注大语言模型的外部知识集成，而视觉语言模型中的多模态融合挑战尚未充分探索。

Method: 引入知识引导的视觉语言模型推理框架，利用结构化知识图谱进行多跳验证，通过图像描述任务展示框架。包括视觉实体识别、知识图谱遍历和基于事实的描述优化等系统推理步骤。

Result: 在Google Landmarks v2、Conceptual Captions和COCO Captions的混合数据集上进行初步实验，结果显示事实准确率提升约31%，并揭示了推理模式和失败案例的关键洞察。

Conclusion: 这项工作展示了集成外部知识在推进视觉语言模型推理方面的潜力，为构建更可靠、知识更丰富的多模态系统铺平了道路。

Abstract: Visual Language Models (VLMs) are powerful generative tools but often produce factually inaccurate outputs due to a lack of robust reasoning capabilities. While extensive research has been conducted on integrating external knowledge for reasoning in large language models (LLMs), such efforts remain underexplored in VLMs, where the challenge is compounded by the need to bridge multiple modalities seamlessly. This work introduces a framework for knowledge-guided reasoning in VLMs, leveraging structured knowledge graphs for multi-hop verification using image-captioning task to illustrate our framework. Our approach enables systematic reasoning across multiple steps, including visual entity recognition, knowledge graph traversal, and fact-based caption refinement. We evaluate the framework using hierarchical, triple-based and bullet-point based knowledge representations, analyzing their effectiveness in factual accuracy and logical inference. Empirical results show that our approach improves factual accuracy by approximately 31% on preliminary experiments on a curated dataset of mixtures from Google Landmarks v2, Conceptual captions and Coco captions revealing key insights into reasoning patterns and failure modes. This work demonstrates the potential of integrating external knowledge for advancing reasoning in VLMs, paving the way for more reliable and knowledgable multimodal systems.

</details>


### [25] [Building a Foundation Model for Trajectory from Scratch](https://arxiv.org/abs/2511.20610)
*Gaspard Merten,Mahmoud Sakr,Gilles Dejaegere*

Main category: cs.AI

TL;DR: 本教程通过代码实现展示了如何从GPT-2构建面向轨迹数据的基础模型，并比较了TrajFM、TrajGPT等代表性模型，旨在帮助SIGSPATIAL社区理解和构建移动性基础模型。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏关于从零开始构建移动性轨迹基础模型的明确指导和文档，需要填补这一空白，支持研究社区在移动性AI领域的发展。

Method: 采用分步代码驱动的方法，演示如何将GPT-2适配到时空数据，并回顾比较代表性轨迹基础模型的架构创新和差异。

Result: 提供了构建轨迹基础模型的具体实现步骤和代码示例，同时介绍了相关领域的补充技术如TimesFM的分块方法。

Conclusion: 创建这样的教育材料对于支持SIGSPATIAL社区构建和评估移动性基础模型至关重要，能够提高移动性AI领域的研究清晰度和同行评审效果。

Abstract: Foundation models are transformative in artificial intelligence, but building them from scratch, especially for mobility trajectories, is not yet clear or documented. This tutorial bridges this gap by demonstrating the steps and code of a minimal implementation of a trajectory-focused foundation model starting from GPT-2. Through a concise, step-by-step, code-driven process, we demonstrate adapting GPT-2 for spatiotemporal data. We then review and compare representative trajectory foundation models, such as TrajFM and TrajGPT, highlighting their architectural innovations and differences. Additionally, we introduce complementary techniques from related domains, like TimesFM's patching approach. Targeted at researchers and practitioners, this tutorial aims to explain the concepts and terminology of foundation models, at the implementation level. We find it timely and indispensable to create this educational material in order to support the SIGSPATIAL community in building and evaluating mobility foundation models, enhancing both research clarity and peer-review effectiveness in mobility AI.

</details>


### [26] [Copyright Detection in Large Language Models: An Ethical Approach to Generative AI Development](https://arxiv.org/abs/2511.20623)
*David Szczecina,Senan Gaffori,Edmond Li*

Main category: cs.AI

TL;DR: 开发了一个开源版权检测平台，帮助内容创作者验证其作品是否被用于LLM训练数据集，相比现有方法减少了10-30%的计算开销。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型广泛使用引发版权担忧，现有检测框架计算密集且独立创作者难以使用，需要可扩展、透明且用户友好的解决方案。

Method: 通过优化API调用提高效率，改进相似性检测，优化数据集验证，并提供直观用户界面和可扩展后端。

Result: 平台实现了10-30%的计算开销降低，提高了易用性和相似性检测能力。

Conclusion: 该框架有助于提高AI开发的透明度和道德合规性，为负责任AI开发和版权执法研究奠定基础。

Abstract: The widespread use of Large Language Models (LLMs) raises critical concerns regarding the unauthorized inclusion of copyrighted content in training data. Existing detection frameworks, such as DE-COP, are computationally intensive, and largely inaccessible to independent creators. As legal scrutiny increases, there is a pressing need for a scalable, transparent, and user-friendly solution. This paper introduce an open-source copyright detection platform that enables content creators to verify whether their work was used in LLM training datasets. Our approach enhances existing methodologies by facilitating ease of use, improving similarity detection, optimizing dataset validation, and reducing computational overhead by 10-30% with efficient API calls. With an intuitive user interface and scalable backend, this framework contributes to increasing transparency in AI development and ethical compliance, facilitating the foundation for further research in responsible AI development and copyright enforcement.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [27] [SPQR: A Standardized Benchmark for Modern Safety Alignment Methods in Text-to-Image Diffusion Models](https://arxiv.org/abs/2511.19558)
*Mohammed Talha Alam,Nada Saadi,Fahad Shamshad,Nils Lukas,Karthik Nandakumar,Fahkri Karray,Samuele Poppi*

Main category: cs.CR

TL;DR: 本文研究了文本到图像扩散模型在良性微调下的安全对齐稳定性，发现当前安全方法经常失效，并提出了SPQR基准来评估安全对齐模型在微调后的安全性、效用和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 文本到图像扩散模型可能生成受版权保护、不安全或私密内容。安全对齐旨在抑制特定概念，但现有评估很少测试在部署后常规应用的良性微调（如LoRA个性化、风格/领域适配器）下安全性的持久性。

Method: 研究当前安全方法在良性微调下的稳定性，引入SPQR基准（安全-提示遵循-质量-鲁棒性），这是一个单一评分指标，提供标准化和可复现的框架来评估安全对齐扩散模型在良性微调下如何保持安全性、效用和鲁棒性。

Result: 观察到在良性微调下频繁出现安全失效，SPQR基准通过多语言、领域特定和分布外分析以及类别细分，识别安全对齐在良性微调后失败的情况。

Conclusion: SPQR作为一个简洁而全面的基准，为T2I安全对齐技术提供了标准化的评估框架，强调真正的安全对齐必须能够承受部署后的良性适应。

Abstract: Text-to-image diffusion models can emit copyrighted, unsafe, or private content. Safety alignment aims to suppress specific concepts, yet evaluations seldom test whether safety persists under benign downstream fine-tuning routinely applied after deployment (e.g., LoRA personalization, style/domain adapters). We study the stability of current safety methods under benign fine-tuning and observe frequent breakdowns. As true safety alignment must withstand even benign post-deployment adaptations, we introduce the SPQR benchmark (Safety-Prompt adherence-Quality-Robustness). SPQR is a single-scored metric that provides a standardized and reproducible framework to evaluate how well safety-aligned diffusion models preserve safety, utility, and robustness under benign fine-tuning, by reporting a single leaderboard score to facilitate comparisons. We conduct multilingual, domain-specific, and out-of-distribution analyses, along with category-wise breakdowns, to identify when safety alignment fails after benign fine-tuning, ultimately showcasing SPQR as a concise yet comprehensive benchmark for T2I safety alignment techniques for T2I models.

</details>


### [28] [Accuracy and Efficiency Trade-Offs in LLM-Based Malware Detection and Explanation: A Comparative Study of Parameter Tuning vs. Full Fine-Tuning](https://arxiv.org/abs/2511.19654)
*Stephen C. Gravereaux,Sheikh Rabiul Islam*

Main category: cs.CR

TL;DR: 本研究评估了LoRA微调的大语言模型在恶意软件分类中生成可解释决策和解释的能力，发现中档LoRA模型在保持解释质量的同时，能显著减少模型大小和训练时间。


<details>
  <summary>Details</summary>
Motivation: 实现可信赖的恶意软件检测，特别是在使用大语言模型时，仍然是一个重大挑战。需要平衡模型性能和资源效率。

Method: 开发了一个评估框架，使用BLEU、ROUGE和语义相似度指标，比较了五种LoRA配置和完全微调基线的解释质量。

Result: 完全微调获得最高总体分数，BLEU和ROUGE比LoRA变体提高达10%。但中档LoRA模型在两个指标上表现优于完全微调，同时模型大小减少约81%，训练时间减少超过80%。

Conclusion: LoRA在可解释性和资源效率之间提供了实用平衡，能够在资源受限环境中部署而不牺牲解释质量，增强了恶意软件检测系统的透明度、分析师信心和操作可扩展性。

Abstract: This study examines whether Low-Rank Adaptation (LoRA) fine-tuned Large Language Models (LLMs) can approximate the performance of fully fine-tuned models in generating human-interpretable decisions and explanations for malware classification. Achieving trustworthy malware detection, particularly when LLMs are involved, remains a significant challenge. We developed an evaluation framework using Bilingual Evaluation Understudy (BLEU), Recall-Oriented Understudy for Gisting Evaluation (ROUGE), and Semantic Similarity Metrics to benchmark explanation quality across five LoRA configurations and a fully fine-tuned baseline. Results indicate that full fine-tuning achieves the highest overall scores, with BLEU and ROUGE improvements of up to 10% over LoRA variants. However, mid-range LoRA models deliver competitive performance exceeding full fine-tuning on two metrics while reducing model size by approximately 81% and training time by over 80% on a LoRA model with 15.5% trainable parameters. These findings demonstrate that LoRA offers a practical balance of interpretability and resource efficiency, enabling deployment in resource-constrained environments without sacrificing explanation quality. By providing feature-driven natural language explanations for malware classifications, this approach enhances transparency, analyst confidence, and operational scalability in malware detection systems.

</details>


### [29] [BASICS: Binary Analysis and Stack Integrity Checker System for Buffer Overflow Mitigation](https://arxiv.org/abs/2511.19670)
*Luis Ferreirinha,Iberia Medeiros*

Main category: cs.CR

TL;DR: 本文提出了一种结合模型检测和符号执行的新方法，用于自动检测和修复C程序二进制代码中的缓冲区溢出漏洞，通过构建内存状态空间和自动化补丁修复，在多个数据集上达到87%以上的准确率和精确度。


<details>
  <summary>Details</summary>
Motivation: C语言在关键基础设施的CPS系统中广泛应用，但容易受到缓冲区溢出等漏洞影响。传统漏洞发现技术在二进制代码层面存在可扩展性和精确性问题，导致程序持续存在漏洞风险。

Method: 使用模型检测和符号执行技术构建内存状态空间(MemStaCe)，通过LTL定义的安全属性分析程序行为，识别漏洞后采用trampoline技术进行自动化二进制补丁修复，并使用崩溃诱导输入验证修复效果。

Result: 在Juliet C/C++和SARD数据集及实际应用中，检测和修复的准确率和精确度均超过87%，优于CWE Checker工具。

Conclusion: 该方法有效解决了二进制代码中缓冲区溢出漏洞的自动检测和修复问题，为CPS系统的安全性提供了可靠保障。

Abstract: Cyber-Physical Systems have played an essential role in our daily lives, providing critical services such as power and water, whose operability, availability, and reliability must be ensured. The C programming language, prevalent in CPS development, is crucial for system control where reliability is critical. However, it is also commonly susceptible to vulnerabilities, particularly buffer overflows. Traditional vulnerability discovery techniques often struggle with scalability and precision when applied directly to the binary code of C programs, which can thereby keep programs vulnerable. This work introduces a novel approach designed to overcome these limitations by leveraging model checking and concolic execution techniques to automatically verify security properties of a program's stack memory in binary code, trampoline techniques to perform automated repair of the issues, and crash-inducing inputs to verify if they were successfully removed. The approach constructs a Memory State Space -- MemStaCe -- from the binary program's control flow graph and simulations, provided by concolic execution, of C function calls and loop constructs. The security properties, defined in LTL, model the correct behaviour of functions associated with vulnerabilities and allow the approach to identify vulnerabilities in MemStaCe by analysing counterexample traces that are generated when a security property is violated. These vulnerabilities are then addressed with a trampoline-based binary patching method, and the effectiveness of the patches is checked with crash-inducing inputs extracted during concolic execution. We implemented the approach in the BASICS tool for BO mitigation and evaluated using the Juliet C/C++ and SARD datasets and real applications, achieving an accuracy and precision above 87%, both in detection and correction. Also, we compared it with CWE Checker, outperforming it.

</details>


### [30] [CrypTorch: PyTorch-based Auto-tuning Compiler for Machine Learning with Multi-party Computation](https://arxiv.org/abs/2511.19711)
*Jinyu Liu,Gang Tan,Kiwan Maeng*

Main category: cs.CR

TL;DR: CrypTorch是一个基于MPC的机器学习编译器，通过解耦近似计算与MPC运行时，提供自动调优功能，显著提升性能而不牺牲准确性。


<details>
  <summary>Details</summary>
Motivation: 现有MPC框架中的近似计算（如Softmax、GELU）往往成为性能瓶颈，且难以识别和修复，需要更好的解决方案。

Method: 提出CrypTorch编译器，作为PyTorch 2的扩展，通过编程接口轻松添加新近似，并自动选择近似以最大化性能和准确性。

Result: 仅自动调优即可提供1.20-1.7倍速度提升且不牺牲准确性，允许一定精度损失时可达到1.31-1.8倍加速；整个框架相比CrypTen带来3.22-8.6倍端到端加速。

Conclusion: CrypTorch有效解决了MPC-based ML中的近似计算瓶颈问题，显著提升了性能和易用性。

Abstract: Machine learning (ML) involves private data and proprietary model parameters. MPC-based ML allows multiple parties to collaboratively run an ML workload without sharing their private data or model parameters using multi-party computing (MPC). Because MPC cannot natively run ML operations such as Softmax or GELU, existing frameworks use different approximations. Our study shows that, on a well-optimized framework, these approximations often become the dominating bottleneck. Popular approximations are often insufficiently accurate or unnecessarily slow, and these issues are hard to identify and fix in existing frameworks. To tackle this issue, we propose a compiler for MPC-based ML, CrypTorch. CrypTorch disentangles these approximations with the rest of the MPC runtime, allows easily adding new approximations through its programming interface, and automatically selects approximations to maximize both performance and accuracy. Built as an extension to PyTorch 2's compiler, we show that CrypTorch's auto-tuning alone provides 1.20--1.7$\times$ immediate speedup without sacrificing accuracy, and 1.31--1.8$\times$ speedup when some accuracy degradation is allowed, compared to our well-optimized baseline. Combined with better engineering and adoption of state-of-the-art practices, the entire framework brings 3.22--8.6$\times$ end-to-end speedup compared to the popular framework, CrypTen.

</details>


### [31] [Prompt Fencing: A Cryptographic Approach to Establishing Security Boundaries in Large Language Model Prompts](https://arxiv.org/abs/2511.19727)
*Steven Peh*

Main category: cs.CR

TL;DR: 提出Prompt Fencing方法，通过密码学认证和数据架构原则在LLM提示中建立安全边界，使用加密签名元数据标记提示段，区分可信指令和不可信内容。实验显示该方法将注入攻击成功率从86.7%降至0%。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在生产部署中对提示注入攻击仍然脆弱，这是最重要的安全威胁，需要有效的防护方法。

Method: 采用密码学认证和数据架构原则，为提示段添加包含信任评级和内容类型的加密签名元数据，建立明确的安全边界。通过提示指令模拟边界意识。

Result: 在300个测试案例中，将注入攻击成功率从86.7%(260/300)降至0%(0/300)，概念验证的边界生成和验证管道总开销为0.224秒。

Conclusion: 该方法平台无关，可作为安全层在现有LLM基础设施上增量部署，未来模型有望训练原生边界意识以获得最佳安全性。

Abstract: Large Language Models (LLMs) remain vulnerable to prompt injection attacks, representing the most significant security threat in production deployments. We present Prompt Fencing, a novel architectural approach that applies cryptographic authentication and data architecture principles to establish explicit security boundaries within LLM prompts. Our approach decorates prompt segments with cryptographically signed metadata including trust ratings and content types, enabling LLMs to distinguish between trusted instructions and untrusted content. While current LLMs lack native fence awareness, we demonstrate that simulated awareness through prompt instructions achieved complete prevention of injection attacks in our experiments, reducing success rates from 86.7% (260/300 successful attacks) to 0% (0/300 successful attacks) across 300 test cases with two leading LLM providers. We implement a proof-of-concept fence generation and verification pipeline with a total overhead of 0.224 seconds (0.130s for fence generation, 0.094s for validation) across 100 samples. Our approach is platform-agnostic and can be incrementally deployed as a security layer above existing LLM infrastructure, with the expectation that future models will be trained with native fence awareness for optimal security.

</details>


### [32] [Frequency Bias Matters: Diving into Robust and Generalized Deep Image Forgery Detection](https://arxiv.org/abs/2511.19886)
*Chi Liu,Tianqing Zhu,Wanlei Zhou,Wei Zhao*

Main category: cs.CR

TL;DR: 本文从频率角度分析AI生成图像伪造检测器的泛化性和鲁棒性问题，提出频率对齐方法，既能作为反取证攻击手段，也能作为取证防御手段。


<details>
  <summary>Details</summary>
Motivation: AI生成的图像伪造对数字世界构成挑战，检测器的泛化性和鲁棒性至关重要。现有研究未深入探讨这些问题根源，且缺乏同时改善这两方面性能的通用方法。

Method: 提出两阶段频率对齐方法，消除真实与伪造图像间的频率差异。该方法可双向应用：作为反取证的黑盒攻击手段，或作为取证的通用防御手段。

Result: 在涉及12个检测器、8个伪造模型和5个指标的多种实验设置中验证了方法的有效性，展示了频率对齐方法的作用。

Conclusion: 频率偏差是DNN伪造检测器泛化和鲁棒性问题的可能原因，频率对齐方法提供了双向解决方案，既可用于攻击也可用于防御。

Abstract: As deep image forgery powered by AI generative models, such as GANs, continues to challenge today's digital world, detecting AI-generated forgeries has become a vital security topic. Generalizability and robustness are two critical concerns of a forgery detector, determining its reliability when facing unknown GANs and noisy samples in an open world. Although many studies focus on improving these two properties, the root causes of these problems have not been fully explored, and it is unclear if there is a connection between them. Moreover, despite recent achievements in addressing these issues from image forensic or anti-forensic aspects, a universal method that can contribute to both sides simultaneously remains practically significant yet unavailable. In this paper, we provide a fundamental explanation of these problems from a frequency perspective. Our analysis reveals that the frequency bias of a DNN forgery detector is a possible cause of generalization and robustness issues. Based on this finding, we propose a two-step frequency alignment method to remove the frequency discrepancy between real and fake images, offering double-sided benefits: it can serve as a strong black-box attack against forgery detectors in the anti-forensic context or, conversely, as a universal defense to improve detector reliability in the forensic context. We also develop corresponding attack and defense implementations and demonstrate their effectiveness, as well as the effect of the frequency alignment method, in various experimental settings involving twelve detectors, eight forgery models, and five metrics.

</details>


### [33] [Hey there! You are using WhatsApp: Enumerating Three Billion Accounts for Security and Privacy](https://arxiv.org/abs/2511.20252)
*Gabriel K. Gegenhuber,Philipp É. Frenzel,Maximilian Günther,Johanna Ullrich,Aljosha Judmayer*

Main category: cs.CR

TL;DR: WhatsApp存在严重的电话号码枚举漏洞，攻击者每小时可探测超过1亿个号码而不被阻止，近半数2021年Facebook数据泄露中的电话号码仍在WhatsApp活跃，且发现X25519密钥在不同设备和号码间重复使用的问题。


<details>
  <summary>Details</summary>
Motivation: WhatsApp作为全球最大的即时通讯平台，其电话号码查询机制存在安全隐患，研究旨在揭示该平台在电话号码枚举方面的持续脆弱性及其对用户隐私的威胁。

Method: 通过大规模探测WhatsApp服务器，测试其电话号码查询功能的速率限制机制，分析数据泄露中电话号码的活跃状态，并检查加密密钥的使用模式。

Result: 发现WhatsApp缺乏有效的速率限制，每小时可探测超1亿号码；47%的Facebook泄露号码仍在WhatsApp活跃；发现X25519密钥重复使用问题；最终通过与平台合作确认漏洞已修复。

Conclusion: WhatsApp的电话号码枚举漏洞严重威胁用户隐私，即使消息端到端加密，平台仍能生成宏观用户洞察，需要加强速率限制和密钥管理机制。

Abstract: WhatsApp, with 3.5 billion active accounts as of early 2025, is the world's largest instant messaging platform. Given its massive user base, WhatsApp plays a critical role in global communication.
  To initiate conversations, users must first discover whether their contacts are registered on the platform. This is achieved by querying WhatsApp's servers with mobile phone numbers extracted from the user's address book (if they allowed access). This architecture inherently enables phone number enumeration, as the service must allow legitimate users to query contact availability. While rate limiting is a standard defense against abuse, we revisit the problem and show that WhatsApp remains highly vulnerable to enumeration at scale. In our study, we were able to probe over a hundred million phone numbers per hour without encountering blocking or effective rate limiting.
  Our findings demonstrate not only the persistence but the severity of this vulnerability. We further show that nearly half of the phone numbers disclosed in the 2021 Facebook data leak are still active on WhatsApp, underlining the enduring risks associated with such exposures. Moreover, we were able to perform a census of WhatsApp users, providing a glimpse on the macroscopic insights a large messaging service is able to generate even though the messages themselves are end-to-end encrypted. Using the gathered data, we also discovered the re-use of certain X25519 keys across different devices and phone numbers, indicating either insecure (custom) implementations, or fraudulent activity.
  In this updated version of the paper, we also provide insights into the collaborative remediation process through which we confirmed that the underlying rate-limiting issue had been resolved.

</details>


### [34] [Can LLMs Make (Personalized) Access Control Decisions?](https://arxiv.org/abs/2511.20284)
*Friederike Groschupp,Daniele Lain,Aritra Dhar,Lara Magdalena Lazier,Srdjan Čapkun*

Main category: cs.CR

TL;DR: 该论文提出利用大语言模型（LLMs）进行动态、上下文感知的访问控制决策，以减轻用户在复杂系统中的认知负担。通过用户研究收集了307个自然语言隐私声明和14,682个用户决策，比较了通用和个性化LLM的决策表现。


<details>
  <summary>Details</summary>
Motivation: 随着系统复杂性和自动化程度的提高，用户在进行访问控制决策时面临巨大的认知负担，导致决策质量下降。需要一种能够理解用户安全偏好并做出动态决策的解决方案。

Method: 通过用户研究收集自然语言隐私声明和用户决策数据，然后比较通用LLM和个性化LLM（基于用户特定隐私偏好）的决策准确性，并收集用户对1,446个LLM决策的反馈。

Result: LLMs能够较好地反映用户偏好，与大多数用户决策相比达到86%的准确率。个性化LLM虽然能提高与个体用户决策的一致性，但可能违反某些安全最佳实践。

Conclusion: 讨论了实现实用自然语言访问控制系统的设计和风险考虑，需要在个性化、安全性和实用性之间取得平衡。

Abstract: Precise access control decisions are crucial to the security of both traditional applications and emerging agent-based systems. Typically, these decisions are made by users during app installation or at runtime. Due to the increasing complexity and automation of systems, making these access control decisions can add a significant cognitive load on users, often overloading them and leading to suboptimal or even arbitrary access control decisions. To address this problem, we propose to leverage the processing and reasoning capabilities of large language models (LLMs) to make dynamic, context-aware decisions aligned with the user's security preferences. For this purpose, we conducted a user study, which resulted in a dataset of 307 natural-language privacy statements and 14,682 access control decisions made by users. We then compare these decisions against those made by two versions of LLMs: a general and a personalized one, for which we also gathered user feedback on 1,446 of its decisions.
  Our results show that in general, LLMs can reflect users' preferences well, achieving up to 86\% accuracy when compared to the decision made by the majority of users. Our study also reveals a crucial trade-off in personalizing such a system: while providing user-specific privacy preferences to the LLM generally improves agreement with individual user decisions, adhering to those preferences can also violate some security best practices. Based on our findings, we discuss design and risk considerations for implementing a practical natural-language-based access control system that balances personalization, security, and utility.

</details>


### [35] [APT-CGLP: Advanced Persistent Threat Hunting via Contrastive Graph-Language Pre-Training](https://arxiv.org/abs/2511.20290)
*Xuebo Qiu,Mingqi Lv,Yimei Zhang,Tieming Chen,Tiantian Zhu,Qijie Song,Shouling Ji*

Main category: cs.CR

TL;DR: APT-CGLP是一种基于对比图-语言预训练的新型跨模态APT狩猎系统，能够直接在溯源图和CTI报告之间进行端到端语义匹配，无需人工干预。


<details>
  <summary>Details</summary>
Motivation: 解决传统基于图匹配的威胁狩猎方法存在的信息丢失和人工干预问题，弥溯源图与CTI报告之间的模态差距。

Method: 1）利用大语言模型合成高保真溯源图-CTI报告对缓解数据稀缺；2）结合对比学习和跨模态掩码建模的多目标训练算法，实现粗粒度和细粒度的跨模态攻击语义对齐。

Result: 在四个真实APT数据集上的实验表明，APT-CGLP在准确性和效率方面持续优于最先进的威胁狩猎基线方法。

Conclusion: APT-CGLP通过端到端的跨模态语义匹配方法，有效解决了传统威胁狩猎中的信息丢失和可扩展性问题，显著提升了APT检测性能。

Abstract: Provenance-based threat hunting identifies Advanced Persistent Threats (APTs) on endpoints by correlating attack patterns described in Cyber Threat Intelligence (CTI) with provenance graphs derived from system audit logs. A fundamental challenge in this paradigm lies in the modality gap -- the structural and semantic disconnect between provenance graphs and CTI reports. Prior work addresses this by framing threat hunting as a graph matching task: 1) extracting attack graphs from CTI reports, and 2) aligning them with provenance graphs. However, this pipeline incurs severe \textit{information loss} during graph extraction and demands intensive manual curation, undermining scalability and effectiveness.
  In this paper, we present APT-CGLP, a novel cross-modal APT hunting system via Contrastive Graph-Language Pre-training, facilitating end-to-end semantic matching between provenance graphs and CTI reports without human intervention. First, empowered by the Large Language Model (LLM), APT-CGLP mitigates data scarcity by synthesizing high-fidelity provenance graph-CTI report pairs, while simultaneously distilling actionable insights from noisy web-sourced CTIs to improve their operational utility. Second, APT-CGLP incorporates a tailored multi-objective training algorithm that synergizes contrastive learning with inter-modal masked modeling, promoting cross-modal attack semantic alignment at both coarse- and fine-grained levels. Extensive experiments on four real-world APT datasets demonstrate that APT-CGLP consistently outperforms state-of-the-art threat hunting baselines in terms of accuracy and efficiency.

</details>


### [36] [A Reality Check on SBOM-based Vulnerability Management: An Empirical Study and A Path Forward](https://arxiv.org/abs/2511.20313)
*Li Zhou,Marc Dacier,Charalambos Konstantinou*

Main category: cs.CR

TL;DR: 该论文通过大规模实证研究验证了软件物料清单(SBOM)在软件供应链安全中的实用性问题，提出了基于锁定文件和函数调用分析的两阶段方法来提高漏洞扫描准确性。


<details>
  <summary>Details</summary>
Motivation: SBOM是软件供应链安全的关键工具，但其实际效用受到生成不准确和漏洞扫描误报率高的影响，需要从实践角度解决这些问题。

Method: 对2,414个开源仓库进行大规模实证研究：首先使用锁定文件和强包管理器生成准确的SBOM，然后通过函数调用分析来减少漏洞扫描的误报。

Result: 研究发现：使用锁定文件可以生成准确一致的SBOM；下游漏洞扫描器产生高达97.5%的误报率；函数调用分析可以有效减少63.3%的误报。

Conclusion: 验证了一个实用的两阶段方法：首先使用锁定文件和强包管理器生成准确SBOM，然后通过函数调用分析产生可操作、低噪声的漏洞报告，减轻开发者的警报疲劳。

Abstract: The Software Bill of Materials (SBOM) is a critical tool for securing the software supply chain (SSC), but its practical utility is undermined by inaccuracies in both its generation and its application in vulnerability scanning. This paper presents a large-scale empirical study on 2,414 open-source repositories to address these issues from a practical standpoint. First, we demonstrate that using lock files with strong package managers enables the generation of accurate and consistent SBOMs, establishing a reliable foundation for security analysis. Using this high-fidelity foundation, however, we expose a more fundamental flaw in practice: downstream vulnerability scanners produce a staggering 97.5\% false positive rate. We pinpoint the primary cause as the flagging of vulnerabilities within unreachable code. We then demonstrate that function call analysis can effectively prune 63.3\% of these false alarms. Our work validates a practical, two-stage approach for SSC security: first, generate an accurate SBOM using lock files and strong package managers, and second, enrich it with function call analysis to produce actionable, low-noise vulnerability reports that alleviate developers' alert fatigue.

</details>


### [37] [Engel p-adic Isogeny-based Cryptography over Laurent Series: Foundations, Security, and an ESP32 Implementation](https://arxiv.org/abs/2511.20533)
*Ilias Cherkaoui,Indrakshi Dey*

Main category: cs.CR

TL;DR: 提出了首个使用p进洛朗级数上的Engel展开编码超奇异椭圆曲线同源数据的同源框架，同时解决了后量子密码在物联网设备上的紧凑性和效率约束。


<details>
  <summary>Details</summary>
Motivation: 保护物联网免受量子攻击需要既紧凑又能在微控制器上高效运行的后量子公钥密码方案，但现有方案因密钥大和算术运算重而难以满足要求。

Method: 使用新颖的Engel展开在p进洛朗级数上编码超奇异椭圆曲线同源数据，Engel系数压缩挠信息以实现紧凑性，Engel算术支持固定精度p进运算，适合嵌入式目标。

Result: 实现了~1.1-16.9 kbits的紧凑公钥大小，保持了同源系统的小尺寸特性，同时提供了适合微控制器的低内存、分支规则的内核。

Conclusion: 该同源框架同时解决了后量子密码在物联网设备上的紧凑性和效率问题，为量子安全的物联网应用提供了可行方案。

Abstract: Securing the Internet of Things (IoT) against quantum attacks requires public-key cryptography that (i) remains compact and (ii) runs efficiently on microcontrollers, capabilities many post-quantum (PQ) schemes lack due to large keys and heavy arithmetic. We address both constraints simultaneously with, to our knowledge, the first-ever isogeny framework that encodes super-singular elliptic-curve isogeny data via novel Engel expansions over the p-adic Laurent series. Engel coefficients compress torsion information, thereby addressing the compactness constraint, yielding public keys of ~1.1 - 16.9 kbits preserving the hallmark small sizes of isogeny systems. Engel arithmetic is local and admits fixed-precision p-adic operations, enabling micro-controller efficiency with low-memory, branch-regular kernels suitable for embedded targets.

</details>


### [38] [Effective Command-line Interface Fuzzing with Path-Aware Large Language Model Orchestration](https://arxiv.org/abs/2511.20555)
*Momoko Shiraishi,Yinzhi Cao,Takahiro Shinagawa*

Main category: cs.CR

TL;DR: PILOT是一个路径引导的迭代LLM编排测试框架，用于模糊测试命令行界面应用程序，通过提供目标函数的潜在调用路径作为上下文，让LLM生成更有效的CLI选项字符串和输入文件，从而发现深层漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有的CLI模糊测试方法面临生成语义丰富的选项字符串和输入文件的挑战，无法到达深度嵌入的目标函数，导致深层漏洞的误检测。

Method: 设计PILOT框架，通过向LLM提供目标函数的潜在调用路径作为上下文，迭代生成CLI选项字符串和输入文件，并将已到达的函数作为额外上下文，逐步接近目标函数。

Result: 在真实世界CLI应用上的评估显示，PILOT比最先进的模糊测试方法实现了更高的覆盖率，发现了51个零日漏洞，其中41个被开发者确认，33个已修复，3个获得了CVE标识符。

Conclusion: PILOT通过路径引导和LLM迭代编排的方法，有效解决了CLI模糊测试中深层漏洞检测的挑战，显著提升了测试覆盖率和漏洞发现能力。

Abstract: Command-line interface (CLI) fuzzing tests programs by mutating both command-line options and input file contents, thus enabling discovery of vulnerabilities that only manifest under specific option-input combinations. Prior works of CLI fuzzing face the challenges of generating semantics-rich option strings and input files, which cannot reach deeply embedded target functions. This often leads to a misdetection of such a deep vulnerability using existing CLI fuzzing techniques. In this paper, we design a novel Path-guided, Iterative LLM-Orchestrated Testing framework, called PILOT, to fuzz CLI applications. The key insight is to provide potential call paths to target functions as context to LLM so that it can better generate CLI option strings and input files. Then, PILOT iteratively repeats the process, and provides reached functions as additional context so that target functions are reached. Our evaluation on real-world CLI applications demonstrates that PILOT achieves higher coverage than state-of-the-art fuzzing approaches and discovers 51 zero-day vulnerabilities. We responsibly disclosed all the vulnerabilities to their developers and so far 41 have been confirmed by their developers with 33 being fixed and three assigned CVE identifiers.

</details>


### [39] [Quantum-Resistant Authentication Scheme for RFID Systems Using Lattice-Based Cryptography](https://arxiv.org/abs/2511.20630)
*Vaibhav Kumar,Kaiwalya Joshi,Bhavya Dixit,Gaurav S. Kasbekar*

Main category: cs.CR

TL;DR: 提出了一种基于格密码学的量子抗性RFID相互认证方案，该方案在读写器-服务器和标签-读写器通信信道都不安全的情况下仍能保证安全性，解决了ISIS问题的困难性来获得量子抗性。


<details>
  <summary>Details</summary>
Motivation: 现有RFID认证方案通常假设读写器-服务器通信信道是安全的，但在实际应用中该信道也可能不安全。需要设计一种在两种通信信道都不安全的情况下仍能提供强安全保证的量子抗性认证协议。

Method: 使用基于格密码学的方法，特别是利用非齐次短整数解(ISIS)问题的困难性来构建量子抗性。协议设计确保在两种通信信道都不安全的情况下仍能提供相互认证。

Result: 协议能够抵抗中间人攻击、重放攻击、冒充攻击和反射攻击，同时确保不可伪造性和匿名性。通过AVISPA工具的形式化验证确认了协议的安全性。

Conclusion: 这是首个全面解决读写器-服务器和标签-读写器通信信道不安全性的量子抗性RFID认证协议，提供了强大的安全保证，并在存储、计算和通信成本方面进行了优化。

Abstract: We propose a novel quantum-resistant mutual authentication scheme for radio-frequency identification (RFID) systems. Our scheme uses lattice-based cryptography and, in particular, achieves quantum-resistance by leveraging the hardness of the inhomogeneous short integer solution (ISIS) problem. In contrast to prior work, which assumes that the reader-server communication channel is secure, our scheme is secure even when both the reader-server and tag-reader communication channels are insecure. Our proposed protocol provides robust security against man-in-the-middle (MITM), replay, impersonation, and reflection attacks, while also ensuring unforgeability and preserving anonymity. We present a detailed security analysis, including semi-formal analysis and formal verification using the Automated Validation of Internet Security Protocols and Applications (AVISPA) tool. In addition, we analyze the storage, computation, and communication costs of the proposed protocol and compare its security properties with those of existing protocols, demonstrating that our scheme offers strong security guarantees. To the best of our knowledge, this paper is the first quantum-resistant authentication protocol for RFID systems that comprehensively addresses the insecurity of both the reader-server and tag-reader communication channels.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [40] [stable-pretraining-v1: Foundation Model Research Made Simple](https://arxiv.org/abs/2511.19484)
*Randall Balestriero,Hugues Van Assel,Sami BuGhanem,Lucas Maes*

Main category: cs.SE

TL;DR: stable-pretraining是一个基于PyTorch、Lightning、Hugging Face和TorchMetrics构建的模块化、可扩展且性能优化的自监督学习库，旨在解决基础模型研究中代码复杂、重复实现和工程负担重的问题。


<details>
  <summary>Details</summary>
Motivation: 当前基础模型和自监督学习研究受到复杂代码库、冗余重新实现以及扩展实验的沉重工程负担的阻碍，需要更灵活、高效的开发工具。

Method: 构建一个统一的自监督学习工具库，包含探针、崩溃检测指标、增强管道和可扩展评估例程等核心功能，采用"记录一切"的设计原则，提供细粒度的训练动态可见性。

Result: 验证了该库能够以最小开销生成新的研究见解，包括深度表示探针和CLIP在合成数据微调下的退化分析。

Conclusion: stable-pretraining通过降低入门门槛同时保持大规模实验的可扩展性，旨在加速基础模型研究的发现和扩展可能性。

Abstract: Foundation models and self-supervised learning (SSL) have become central to modern AI, yet research in this area remains hindered by complex codebases, redundant re-implementations, and the heavy engineering burden of scaling experiments. We present stable-pretraining, a modular, extensible, and performance-optimized library built on top of PyTorch, Lightning, Hugging Face, and TorchMetrics. Unlike prior toolkits focused narrowly on reproducing state-of-the-art results, stable-pretraining is designed for flexibility and iteration speed: it unifies essential SSL utilities--including probes, collapse detection metrics, augmentation pipelines, and extensible evaluation routines--within a coherent and reliable framework. A central design principle is logging everything, enabling fine-grained visibility into training dynamics that makes debugging, monitoring, and reproducibility seamless. We validate the library by demonstrating its ability to generate new research insights with minimal overhead, including depthwise representation probing and the analysis of CLIP degradation under synthetic data finetuning. By lowering barriers to entry while remaining scalable to large experiments, stable-pretraining aims to accelerate discovery and expand the possibilities of foundation model research.

</details>


### [41] [Evolution without an Oracle: Driving Effective Evolution with LLM Judges](https://arxiv.org/abs/2511.19489)
*Zhe Zhao,Yuheng Yang,Haibin Wen,Xiaojie Qiu,Zaixi Zhang,Qingfu Zhang*

Main category: cs.SE

TL;DR: MADE框架通过问题分解将主观LLM评估转化为稳定选择压力，在无客观适应度函数的情况下实现进化优化，在软件需求满足和复杂指令遵循方面显著超越基线方法。


<details>
  <summary>Details</summary>
Motivation: 打破传统进化计算依赖客观适应度函数的限制，探索在纯主观LLM评判下的进化优化可能性。

Method: 提出MADE框架，通过问题规范将模糊指令分解为可验证的子要求，降低主观评估的噪声。

Result: 在DevAI和InfoBench基准测试中，软件需求满足率从39.9%提升至61.9%，复杂指令完美通过率达到95%。

Conclusion: 实现了从优化可计算指标到优化可描述质量的范式转变，为无真实标签的开放领域开启了进化优化新途径。

Abstract: The integration of Large Language Models (LLMs) with Evolutionary Computation (EC) has unlocked new frontiers in scientific discovery but remains shackled by a fundamental constraint: the reliance on an Oracle--an objective, machine-computable fitness function. This paper breaks this barrier by asking: Can evolution thrive in a purely subjective landscape governed solely by LLM judges? We introduce MADE (Multi-Agent Decomposed Evolution), a framework that tames the inherent noise of subjective evaluation through "Problem Specification." By decomposing vague instructions into specific, verifiable sub-requirements, MADE transforms high-variance LLM feedback into stable, precise selection pressure. The results are transformative: across complex benchmarks like DevAI and InfoBench, MADE outperforms strong baselines by over 50% in software requirement satisfaction (39.9% to 61.9%) and achieves a 95% perfect pass rate on complex instruction following. This work validates a fundamental paradigm shift: moving from optimizing "computable metrics" to "describable qualities," thereby unlocking evolutionary optimization for the vast open-ended domains where no ground truth exists.

</details>


### [42] [CodeR3: A GenAI-Powered Workflow Repair and Revival Ecosystem](https://arxiv.org/abs/2511.19510)
*Asif Zaman,Kallol Naha,Khalid Belhajjame,Hasan M. Jamil*

Main category: cs.SE

TL;DR: CodeR³系统利用生成式AI将过时的Taverna工作流迁移到Snakemake和VisFlow等现代工作流技术中，通过自动化分析、服务替换和人工验证来修复和重用衰退的工作流。


<details>
  <summary>Details</summary>
Motivation: 科学工作流包含宝贵的领域专业知识，但大量已发布的工作流会随时间衰退，特别是像Taverna这样的遗留系统，由于服务终止、依赖过时和系统退役，导致原本可用的工作流无法使用。

Method: 开发CodeR³系统，集成生成式AI分析衰退工作流特征，逐步工作流分析可视化，自动化服务替换，以及人工在环验证，将工作流重现为现代技术。

Result: 通过多个Taverna工作流复兴案例研究，证明了该方法的可行性，自动化显著减少了工作流解析和服务识别的手动工作，但服务替换和数据验证仍需领域专业知识。

Conclusion: 这项工作提出了一个平衡自动化效率与必要人工判断的工作流复兴框架，将开发众包平台让社区协作复兴衰退工作流并验证功能正确性。

Abstract: Scientific workflows encode valuable domain expertise and computational methodologies. Yet studies consistently show that a significant proportion of published workflows suffer from decay over time. This problem is particularly acute for legacy workflow systems like Taverna, where discontinued services, obsolete dependencies, and system retirement render previously functional workflows unusable. We present a novel legacy workflow migration system, called CodeR$^3$ (stands for Code Repair, Revival and Reuse), that leverages generative AI to analyze the characteristics of decayed workflows, reproduce them into modern workflow technologies like Snakemake and VisFlow. Our system additionally integrates stepwise workflow analysis visualization, automated service substitution, and human-in-the-loop validation. Through several case studies of Taverna workflow revival, we demonstrate the feasibility of this approach while identifying key challenges that require human oversight. Our findings reveal that automation significantly reduces manual effort in workflow parsing and service identification. However, critical tasks such as service substitution and data validation still require domain expertise. Our result will be a crowdsourcing platform that enables the community to collaboratively revive decayed workflows and validate the functionality and correctness of revived workflows. This work contributes a framework for workflow revival that balances automation efficiency with necessary human judgment.

</details>


### [43] [CodeFuse-CommitEval: Towards Benchmarking LLM's Power on Commit Message and Code Change Inconsistency Detection](https://arxiv.org/abs/2511.19875)
*Qingyu Zhang,Puzhuo Liu,Peng Di,Chenxiong Qian*

Main category: cs.SE

TL;DR: CODEFUSE-COMMITEVAL是首个专门用于检测提交消息与代码不一致性(MCI)的基准测试，通过规则引导的突变生成7种不一致消息类型，评估了6个开源LLM在检测MCI方面的表现。


<details>
  <summary>Details</summary>
Motivation: 现有提交消息质量低且经常与代码变更不一致，这会误导代码审查、阻碍维护、污染研究数据集，甚至可能掩盖安全补丁，但目前缺乏专门评估MCI检测模型的基准。

Method: 基于ApacheCM数据集，通过规则引导的突变生成7种不一致消息类型，并进行双重验证。评估了6个开源LLM在普通设置和三种增强策略（少样本提示、思维链、扩展上下文）下的表现。

Result: 模型检测不一致提交比一致提交更可靠（平均召回率85.95%，精确率80.28%，特异性63.8%）；gpt-oss-20B表现最佳但token使用量是其他模型的两倍多。增强策略效果各异：扩展上下文对大模型有帮助但对小模型增加噪声；少样本提高准确性但增加错误预测；思维链提升精确率和特异性但降低召回率。

Conclusion: CODEFUSE-COMMITEVAL为MCI检测提供了严谨的评估基础，揭示了需要更丰富的上下文和平衡的数据来捕捉高层次语义差距，特别是在意图层面的'目的'不一致性检测方面存在挑战。

Abstract: Version control relies on commit messages to convey the rationale for code changes, but these messages are often low quality and, more critically, inconsistent with their diffs-known as message-code inconsistency (MCI). MCIs mislead reviewers, hinder maintenance, contaminate research datasets, and may obscure security patches. Yet, no dedicated benchmark exists to evaluate models for MCI detection. We introduce CODEFUSE-COMMITEVAL, the first benchmark designed for MCI detection using large language models (LLMs). Built on the ApacheCM dataset for diversity and quality, we generate seven types of inconsistent messages through rule-guided mutations of originally consistent commits and apply two-fold validation to verify both positive and negative samples. Using this labeled dataset of message-diff pairs, we evaluate six state-of-the-art open-source LLMs under a vanilla setting and with three augmentation strategies: few-shot prompting, chain-of-thought, and extended context. Results show models detect inconsistent commits more reliably than consistent ones (average Recall 85.95%, Precision 80.28%, Specificity 63.8%); gpt-oss-20B performs best overall but uses over twice the tokens of others. Augmentation effects vary: adjacent context helps larger models but adds noise for smaller ones; few-shot improves accuracy and reduces token use, yet increases universally incorrect predictions; chain-of-thought boosts precision and specificity at the cost of recall and higher token consumption. Type-wise analysis reveals higher detectability for component, file-path, and operation inconsistencies, but lower accuracy and higher token cost for intent-level "purpose" inconsistencies. CODEFUSE-COMMITEVAL provides a rigorous foundation for measuring, comparing, and advancing MCI detection, highlighting the need for richer context and balanced data to capture high-level semantic gaps.

</details>


### [44] [LLMs for Automated Unit Test Generation and Assessment in Java: The AgoneTest Framework](https://arxiv.org/abs/2511.20403)
*Andrea Lops,Fedelucio Narducci,Azzurra Ragone,Michelantonio Trizio,Claudio Barto*

Main category: cs.SE

TL;DR: AgoneTest是一个用于评估LLM生成的Java单元测试的自动化框架，包含Classes2Test数据集和综合评估指标，实验显示LLM生成的测试在编译通过的情况下可以达到或超过人工测试的质量。


<details>
  <summary>Details</summary>
Motivation: 单元测试是软件开发中重要但资源密集的步骤，需要支持研究人员和开发者比较不同LLM和提示策略在真实条件下的表现。

Method: 引入Classes2Test数据集映射Java类到对应测试类，构建包含变异分数和测试异味等高级指标的标准化端到端评估框架。

Result: 对于能够编译通过的测试子集，LLM生成的测试在覆盖率和缺陷检测方面能够匹配或超过人工编写的测试，增强的提示策略有助于提高测试质量。

Conclusion: AgoneTest阐明了LLM在软件测试中的潜力，并为模型设计、提示工程和测试实践的改进提供了见解。

Abstract: Unit testing is an essential but resource-intensive step in software development, ensuring individual code units function correctly. This paper introduces AgoneTest, an automated evaluation framework for Large Language Model-generated (LLM) unit tests in Java. AgoneTest does not aim to propose a novel test generation algorithm; rather, it supports researchers and developers in comparing different LLMs and prompting strategies through a standardized end-to-end evaluation pipeline under realistic conditions. We introduce the Classes2Test dataset, which maps Java classes under test to their corresponding test classes, and a framework that integrates advanced evaluation metrics, such as mutation score and test smells, for a comprehensive assessment. Experimental results show that, for the subset of tests that compile, LLM-generated tests can match or exceed human-written tests in terms of coverage and defect detection. Our findings also demonstrate that enhanced prompting strategies contribute to test quality. AgoneTest clarifies the potential of LLMs in software testing and offers insights for future improvements in model design, prompt engineering, and testing practices.

</details>


### [45] [Translating Large-Scale C Repositories to Idiomatic Rust](https://arxiv.org/abs/2511.20617)
*Saman Dehghan,Tianran Sun,Tianxiang Wu,Zihan Li,Reyhaneh Jabbarvand*

Main category: cs.SE

TL;DR: Rustine是一个自动化C到Rust翻译管道，在23个C程序上实现87%功能等价，相比现有方法更安全、更地道、更可读，且支持高效调试。


<details>
  <summary>Details</summary>
Motivation: 现有C到Rust翻译技术无法平衡质量与可扩展性：转译方法可扩展但代码质量差，LLM方法质量好但成本过高。

Method: 提出Rustine全自动管道，用于仓库级别的C到地道安全Rust翻译。

Result: 在23个C程序（27-13,200行代码）上测试，所有翻译都能编译，达到87%功能等价（通过1,063,099/1,221,192个断言），函数和行覆盖率分别为74.7%和72.2%。

Conclusion: Rustine生成的翻译比六种现有方法更安全、更地道、更可读，当翻译未通过所有测试时，开发者平均只需4.5小时完成调试。

Abstract: Existing C to Rust translation techniques fail to balance quality and scalability: transpilation-based approaches scale to large projects but produce code with poor safety, idiomaticity, and readability. In contrast, LLM-based techniques are prohibitively expensive due to their reliance on frontier models (without which they cannot reliably generate compilable translations), thus limiting scalability. This paper proposes Rustine, a fully automated pipeline for effective and efficient repository-level C to idiomatic safe Rust translation. Evaluating on a diverse set of 23 C programs, ranging from 27 to 13,200 lines of code, Rustine can generate fully compilable Rust code for all and achieve 87% functional equivalence (passing 1,063,099 assertions out of 1,221,192 in test suites with average function and line coverage of 74.7% and 72.2%). Compared to six prior repository-level C to Rust translation techniques, the translations by Rustine are overall safer (fewer raw pointers, pointer arithmetic, and unsafe constructs), more idiomatic (fewer Rust linter violations), and more readable. When the translations cannot pass all tests to fulfill functional equivalence, human developers were able to complete the task in 4.5 hours, on average, using Rustine as debugging support.

</details>
