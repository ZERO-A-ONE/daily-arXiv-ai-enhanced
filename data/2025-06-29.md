<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 11]
- [cs.CR](#cs.CR) [Total: 12]
- [cs.AI](#cs.AI) [Total: 13]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Domain Knowledge in Requirements Engineering: A Systematic Mapping Study](https://arxiv.org/abs/2506.20754)
*Marina Araújo,Júlia Araújo,Romeu Oliveira,Lucas Romao,Marcos Kalinowski*

Main category: cs.SE

TL;DR: 本文通过系统映射研究，总结了领域知识在需求工程中的应用方法、技术和工具，分析了75篇相关论文，为知识驱动的需求工程提供了方法论基础。


<details>
  <summary>Details</summary>
Motivation: 领域知识对需求工程的成功至关重要，但缺乏系统性的整合研究。本文旨在填补这一空白。

Method: 采用混合搜索策略（数据库搜索与迭代雪球法）进行系统映射研究。

Result: 分析了75篇论文，总结了领域知识的类型、质量属性和常见挑战，并提出了未来研究方向。

Conclusion: 研究为知识驱动的需求工程提供了全面的方法论基础，并指出了未来研究的重点。

Abstract: [Context] Domain knowledge is recognized as a key component for the success
of Requirements Engineering (RE), as it provides the conceptual support needed
to understand the system context, ensure alignment with stakeholder needs, and
reduce ambiguity in requirements specification. Despite its relevance, the
scientific literature still lacks a systematic consolidation of how domain
knowledge can be effectively used and operationalized in RE. [Goal] This paper
addresses this gap by offering a comprehensive overview of existing
contributions, including methods, techniques, and tools to incorporate domain
knowledge into RE practices. [Method] We conducted a systematic mapping study
using a hybrid search strategy that combines database searches with iterative
backward and forward snowballing. [Results] In total, we found 75 papers that
met our inclusion criteria. The analysis highlights the main types of
requirements addressed, the most frequently considered quality attributes, and
recurring challenges in the formalization, acquisition, and long-term
maintenance of domain knowledge. The results provide support for researchers
and practitioners in identifying established approaches and unresolved issues.
The study also outlines promising directions for future research, emphasizing
the development of scalable, automated, and sustainable solutions to integrate
domain knowledge into RE processes. [Conclusion] The study contributes by
providing a comprehensive overview that helps to build a conceptual and
methodological foundation for knowledge-driven requirements engineering.

</details>


### [2] [Agile Management for Machine Learning: A Systematic Mapping Study](https://arxiv.org/abs/2506.20759)
*Lucas Romao,Hugo Villamizar,Romeu Oliveira,Silvio Alonso,Marcos Kalinowski*

Main category: cs.SE

TL;DR: 本文通过系统映射研究总结了敏捷管理在机器学习（ML）驱动系统中的现状，识别了8个关键主题和主要挑战。


<details>
  <summary>Details</summary>
Motivation: 机器学习系统的动态性对传统项目管理提出挑战，需探索如何有效应用敏捷方法。

Method: 采用混合搜索策略（数据库搜索与雪球迭代）进行系统映射研究。

Result: 识别了27篇论文，归纳出8个框架和主题，主要挑战是ML任务的工作量估算。

Conclusion: 研究填补了领域空白，但需更多实证评估验证现有成果。

Abstract: [Context] Machine learning (ML)-enabled systems are present in our society,
driving significant digital transformations. The dynamic nature of ML
development, characterized by experimental cycles and rapid changes in data,
poses challenges to traditional project management. Agile methods, with their
flexibility and incremental delivery, seem well-suited to address this
dynamism. However, it is unclear how to effectively apply these methods in the
context of ML-enabled systems, where challenges require tailored approaches.
[Goal] Our goal is to outline the state of the art in agile management for
ML-enabled systems. [Method] We conducted a systematic mapping study using a
hybrid search strategy that combines database searches with backward and
forward snowballing iterations. [Results] Our study identified 27 papers
published between 2008 and 2024. From these, we identified eight frameworks and
categorized recommendations and practices into eight key themes, such as
Iteration Flexibility, Innovative ML-specific Artifacts, and the Minimal Viable
Model. The main challenge identified across studies was accurate effort
estimation for ML-related tasks. [Conclusion] This study contributes by mapping
the state of the art and identifying open gaps in the field. While relevant
work exists, more robust empirical evaluation is still needed to validate these
contributions.

</details>


### [3] [Generating Reliable Adverse event Profiles for Health through Automated Integrated Data (GRAPH-AID): A Semi-Automated Ontology Building Approach](https://arxiv.org/abs/2506.20851)
*Srikar Reddy Gadusu,Larry Callahan,Samir Lababidi,Arunasri Nishtala,Sophia Healey,Hande McGinty*

Main category: cs.SE

TL;DR: 本文提出了一种用户友好的方法，利用Python和rdflib库支持本体开发，解决了Neo4j与OWL无缝集成的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着数据和知识的快速扩展，采用系统化的本体生成方法变得至关重要。现有的KNARM方法在Neo4j与OWL集成中存在挑战，需要更易用的解决方案。

Method: 使用Python和rdflib库开发脚本，自动生成类和公理，实现Neo4j数据库与OWL的集成。

Result: 通过FDA FAERS数据库的案例，展示了该方法能够自动生成本体，支持药物安全监测和公共卫生决策。

Conclusion: 该方法为快速增长的药物不良事件数据集的本体生成提供了实用解决方案。

Abstract: As data and knowledge expand rapidly, adopting systematic methodologies for
ontology generation has become crucial. With the daily increases in data
volumes and frequent content changes, the demand for databases to store and
retrieve information for the creation of knowledge graphs has become
increasingly urgent. The previously established Knowledge Acquisition and
Representation Methodology (KNARM) outlines a systematic approach to address
these challenges and create knowledge graphs. However, following this
methodology highlights the existing challenge of seamlessly integrating Neo4j
databases with the Web Ontology Language (OWL). Previous attempts to integrate
data from Neo4j into an ontology have been discussed, but these approaches
often require an understanding of description logics (DL) syntax, which may not
be familiar to many users. Thus, a more accessible method is necessary to
bridge this gap. This paper presents a user-friendly approach that utilizes
Python and its rdflib library to support ontology development. We showcase our
novel approach through a Neo4j database we created by integrating data from the
Food and Drug Administration (FDA) Adverse Event Reporting System (FAERS)
database. Using this dataset, we developed a Python script that automatically
generates the required classes and their axioms, facilitating a smoother
integration process. This approach offers a practical solution to the
challenges of ontology generation in the context of rapidly growing adverse
drug event datasets, supporting improved drug safety monitoring and public
health decision-making.

</details>


### [4] [Engineering RAG Systems for Real-World Applications: Design, Development, and Evaluation](https://arxiv.org/abs/2506.20869)
*Md Toufique Hasan,Muhammad Waseem,Kai-Kristian Kemell,Ayman Asad Khan,Mika Saari,Pekka Abrahamsson*

Main category: cs.SE

TL;DR: 本文介绍了五个基于检索增强生成（RAG）的领域特定应用，通过用户评估总结了十二个关键经验教训。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs）在事实准确性和上下文相关性上的局限性，缺乏实际用例的实证研究。

Method: 开发了五个RAG应用，结合多语言OCR、语义检索和领域适应LLMs，并通过100名用户的网络评估。

Result: 用户评估了六个维度（如易用性、准确性等），总结了十二个影响RAG系统可靠性和可用性的关键经验。

Conclusion: RAG系统在实际应用中面临技术、操作和伦理挑战，需进一步优化以提高可靠性。

Abstract: Retrieval-Augmented Generation (RAG) systems are emerging as a key approach
for grounding Large Language Models (LLMs) in external knowledge, addressing
limitations in factual accuracy and contextual relevance. However, there is a
lack of empirical studies that report on the development of RAG-based
implementations grounded in real-world use cases, evaluated through general
user involvement, and accompanied by systematic documentation of lessons
learned. This paper presents five domain-specific RAG applications developed
for real-world scenarios across governance, cybersecurity, agriculture,
industrial research, and medical diagnostics. Each system incorporates
multilingual OCR, semantic retrieval via vector embeddings, and domain-adapted
LLMs, deployed through local servers or cloud APIs to meet distinct user needs.
A web-based evaluation involving a total of 100 participants assessed the
systems across six dimensions: (i) Ease of Use, (ii) Relevance, (iii)
Transparency, (iv) Responsiveness, (v) Accuracy, and (vi) Likelihood of
Recommendation. Based on user feedback and our development experience, we
documented twelve key lessons learned, highlighting technical, operational, and
ethical challenges affecting the reliability and usability of RAG systems in
practice.

</details>


### [5] [Complex Model Transformations by Reinforcement Learning with Uncertain Human Guidance](https://arxiv.org/abs/2506.20883)
*Kyanna Dagenais,Istvan David*

Main category: cs.SE

TL;DR: 论文提出了一种结合强化学习和人类指导的方法，用于开发复杂的模型转换序列，提高了效率和性能。


<details>
  <summary>Details</summary>
Motivation: 手动开发复杂的模型转换（MT）序列容易出错且不可行，而强化学习（RL）在复杂问题中表现不佳，需要人类指导来提升性能。

Method: 提出了一种技术框架，将用户定义的MT映射到RL原语中，并通过RL程序执行以找到最优MT序列，同时结合不确定的人类建议。

Result: 评估表明，即使人类建议不确定，也能显著提升RL性能，并更高效地开发复杂MT序列。

Conclusion: 该方法通过权衡人类建议的确定性和及时性，为RL驱动的人机协同工程方法迈出了一步。

Abstract: Model-driven engineering problems often require complex model transformations
(MTs), i.e., MTs that are chained in extensive sequences. Pertinent examples of
such problems include model synchronization, automated model repair, and design
space exploration. Manually developing complex MTs is an error-prone and often
infeasible process. Reinforcement learning (RL) is an apt way to alleviate
these issues. In RL, an autonomous agent explores the state space through trial
and error to identify beneficial sequences of actions, such as MTs. However, RL
methods exhibit performance issues in complex problems. In these situations,
human guidance can be of high utility. In this paper, we present an approach
and technical framework for developing complex MT sequences through RL, guided
by potentially uncertain human advice. Our framework allows user-defined MTs to
be mapped onto RL primitives, and executes them as RL programs to find optimal
MT sequences. Our evaluation shows that human guidance, even if uncertain,
substantially improves RL performance, and results in more efficient
development of complex MTs. Through a trade-off between the certainty and
timeliness of human advice, our method takes a step towards RL-driven
human-in-the-loop engineering methods.

</details>


### [6] [Boosting Vulnerability Detection with Inter-function Multilateral Association Insights](https://arxiv.org/abs/2506.21014)
*Shaojian Qiu,Mengyang Huang,Jiahao Cheng*

Main category: cs.SE

TL;DR: IFMA-VD框架通过构建代码行为超图并利用超边卷积提取多边关联特征，改进了漏洞检测方法，提升了F-measure和Recall。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法忽视函数间复杂多边关联，导致漏洞检测不全面。

Method: 构建代码行为超图，利用超边卷积提取多边关联特征，结合代码属性图和程序依赖图生成特征。

Result: 在三个漏洞数据集上表现优于基线方法，F-measure和Recall均有提升。

Conclusion: 多边关联特征能增强代码特征表示，IFMA-VD在真实数据集上有效。

Abstract: Vulnerability detection is a crucial yet challenging technique for ensuring
the security of software systems. Currently, most deep learning-based
vulnerability detection methods focus on stand-alone functions, neglecting the
complex inter-function interrelations, particularly the multilateral
associations. This oversight can fail to detect vulnerabilities in these
interrelations. To address this gap, we present an Inter-Function Multilateral
Association analysis framework for Vulnerability Detection (IFMA-VD). The
cornerstone of the IFMA-VD lies in constructing a code behavior hypergraph and
utilizing hyperedge convolution to extract multilateral association features.
Specifically, we first parse functions into a code property graph to generate
intra-function features. Following this, we construct a code behavior
hypergraph by segmenting the program dependency graph to isolate and encode
behavioral features into hyperedges. Finally, we utilize a hypergraph network
to capture the multilateral association knowledge for augmenting vulnerability
detection. We evaluate IFMA-VD on three widely used vulnerability datasets and
demonstrate improvements in F-measure and Recall compared to baseline methods.
Additionally, we illustrate that multilateral association features can boost
code feature representation and validate the effectiveness of IFMA-VD on
real-world datasets.

</details>


### [7] [How Good Are Synthetic Requirements ? Evaluating LLM-Generated Datasets for AI4RE](https://arxiv.org/abs/2506.21138)
*Abdelkarim El-Hajjami,Camille Salinesi*

Main category: cs.SE

TL;DR: Synthline v1通过改进的生成策略和优化技术，显著提升了合成需求数据的质量，部分任务表现优于人工数据。


<details>
  <summary>Details</summary>
Motivation: 公开标记的需求数据集稀缺阻碍了AI4RE的发展，需要系统化的方法来优化合成数据的质量。

Method: 提出Synthline v1，结合多样本提示、自动提示优化（PACE）和后生成筛选技术，评估其在四种分类任务中的效果。

Result: 多样本提示显著提升数据质量和多样性；PACE对功能分类效果显著；合成数据在安全和缺陷分类任务中优于人工数据。

Conclusion: 系统化的合成数据生成是解决数据集稀缺的有效途径，为AI4RE提供了实用见解。

Abstract: The shortage of publicly available, labeled requirements datasets remains a
major barrier to advancing Artificial Intelligence for Requirements Engineering
(AI4RE). While Large Language Models offer promising capabilities for synthetic
data generation, systematic approaches to control and optimize the quality of
generated requirements remain underexplored. This paper presents Synthline v1,
an enhanced Product Line approach for generating synthetic requirements data
that extends our earlier v0 version with advanced generation strategies and
curation techniques. We investigate four research questions assessing how
prompting strategies, automated prompt optimization, and post-generation
curation affect data quality across four classification tasks: defect
detection, functional vs. non-functional, quality vs. non-quality, and security
vs. non-security. Our evaluation shows that multi-sample prompting
significantly boosts both utility and diversity over single-sample generation,
with F1-score gains from 6 to 44 points. The use of PACE (Prompt Actor-Critic
Editing) for automated prompt optimization yields task-dependent results,
greatly improving functional classification (+32.5 points) but reducing
performance on others. Interestingly, similarity-based curation improves
diversity but often harms classification performance, indicating that some
redundancy may help ML models. Most importantly, our results show that
synthetic requirements can match or outperform human-authored ones for specific
tasks, with synthetic data surpassing human data for security (+7.8 points) and
defect classification (+15.4 points). These findings offer practical insights
for AI4RE and chart a viable path to mitigating dataset scarcity through
systematic synthetic generation.

</details>


### [8] [$T^3$: Multi-level Tree-based Automatic Program Repair with Large Language Models](https://arxiv.org/abs/2506.21211)
*Quanming Liu,Xupeng Bu,Zhichao Yan,Ru Li*

Main category: cs.SE

TL;DR: 本文提出了一种名为$T^3$的创新框架，结合大型语言模型（LLMs）和树搜索技术，提升自动程序修复（APR）任务的性能。


<details>
  <summary>Details</summary>
Motivation: 由于自动程序修复需要复杂的逻辑和多步推理能力，而现有的链式思维（CoT）技术在APR领域的应用不足，因此需要一种更高效的解决方案。

Method: 研究系统评估了几种常见的CoT技术在APR任务中的表现，并提出了$T^3$框架，结合LLMs的推理能力和树搜索技术。

Result: $T^3$显著提高了生成候选修复方案的精确性，并为优化样本选择和修复策略提供了指导。

Conclusion: $T^3$为高效自动化调试建立了坚实的框架，推动了APR技术的发展。

Abstract: Automatic Program Repair (APR) is a core technology in software development
and maintenance, with aims to enable automated defect repair with minimal human
intervention. In recent years, the substantial advancements in Large Language
Models (LLMs) and the Chain-of-Thought (CoT) techniques have significantly
enhanced the reasoning capabilities of these models. However, due to the
complex logic and multi-step reasoning ability needed, the application of CoT
techniques in the APR domain remains insufficient. This study systematically
evaluates the performance of several common CoT techniques in APR tasks and
proposes an innovative framework $T^3$, which integrates the powerful reasoning
capabilities of LLMs with tree search, effectively improving the precision of
generating candidate repair solutions. Furthermore, $T^3$ provides valuable
guidance for optimizing sample selection and repair strategies in APR tasks,
establishing a robust framework for achieving efficient automated debugging.

</details>


### [9] [KOALA: a Configurable Tool for Collecting IDE Data When Solving Programming Tasks](https://arxiv.org/abs/2506.21266)
*Daniil Karol,Elizaveta Artser,Ilya Vlasov,Yaroslav Golubev,Hieke Keuning,Anastasiia Birillo*

Main category: cs.SE

TL;DR: KOALA是一个可配置的工具，用于收集学生在JetBrains IDE中解决编程任务时的代码快照和功能使用数据，解决了现有工具的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有数据收集工具在代码粒度控制、编程环境事件收集和配置灵活性方面存在不足，KOALA旨在解决这些问题。

Method: KOALA作为插件安装在IDE中，可配置任务、IDE功能（如代码补全）和调查，收集代码快照、IDE操作（如调试）及其他数据（如快捷键使用）。

Result: 工具成功收集了28名学生在两门课程中的编程数据，并转换为标准ProgSnap2格式，展示了数据的潜在价值。

Conclusion: KOALA提供了一种灵活且高效的数据收集方法，有助于研究和教育领域对学生编程行为的深入分析。

Abstract: Collecting data of students solving programming tasks is incredibly valuable
for researchers and educators. It allows verifying that the students correctly
apply the features and concepts they are taught, or finding students'
misconceptions. However, existing data collection tools have limitations, e.g.,
no control over the granularity of the collected code, not collecting the
specific events of the programming environment used, and overall being hard to
configure.
  To overcome these limitations, we propose KOALA, a convenient and highly
configurable tool for collecting code snapshots and feature usage from students
solving programming tasks in JetBrains IDEs. The plugin can be installed in
IDEs and configured to provide the students with the necessary tasks, enable or
disable certain IDE features like code completion, and run surveys. During
problem solving, the plugin collects code snapshots at the configured
granularity, all IDE actions like running and debugging, as well as some data
not collected in prior works, like employed hotkeys and switching focus between
files. The collected data is sent to the server that comes with the tool, where
it is stored and can be converted to the standardized ProgSnap2 format. To
showcase the tool, we collected data from 28 students solving tasks in two
courses within the IDE, highlighting some insights from this data.

</details>


### [10] [Exploring Micro Frontends: A Case Study Application in E-Commerce](https://arxiv.org/abs/2506.21297)
*Ricardo Hideki Hangai Kojo,Luiz Fernando Corte Real,Renato Cordeiro Ferreira,Thatiane de Oliveira Rosa,Alfredo Goldman*

Main category: cs.SE

TL;DR: 本文探讨了微前端架构在工业场景中的适用性，通过案例研究分析了其优缺点，并指出在某些情况下，其他架构（如单体前端）可能同样有效。


<details>
  <summary>Details</summary>
Motivation: 研究微前端架构的适用性，特别是在需要解决紧耦合、技术陈旧和开发体验差等问题的工业场景中。

Method: 结合学术和灰色文献调查微前端现状，并在一个手工艺品市场平台实施该架构，随后通过半开放式问卷评估效果。

Result: 微前端架构成功实施，但并非唯一解决方案；单体前端等其他方法可能同样适用。其优势在于与微服务和基础设施的协同。

Conclusion: 微前端在特定场景（如已有微服务架构）中更具优势，但需权衡其复杂性和基础设施需求。

Abstract: In the micro frontends architectural style, the frontend is divided into
smaller components, which can range from a simple button to an entire page. The
goal is to improve scalability, resilience, and team independence, albeit at
the cost of increased complexity and infrastructure demands. This paper seeks
to understand when it is worth adopting micro frontends, particularly in the
context of industry. To achieve this, we conducted an investigation into the
state of the art of micro frontends, based on both academic and gray
literature. We then implemented this architectural style in a marketplace for
handcrafted products, which already used microservices. Finally, we evaluated
the implementation through a semi-open questionnaire with the developers. At
the studied marketplace company, the need for architectural change arose due to
the tight coupling between their main system (a Java monolith) and a dedicated
frontend system. Additionally, there were deprecated technologies and poor
developer experience. To address these issues, the micro frontends architecture
was adopted, along with the API Gateway and Backend for Frontend patterns, and
technologies such as Svelte and Fastify. Although the adoption of Micro
Frontends was successful, it was not strictly necessary to meet the company's
needs. According to the analysis of the mixed questionnaire responses, other
alternatives, such as a monolithic frontend, could have achieved comparable
results. What made adopting micro frontends the most convenient choice in the
company's context was the monolith strangulation and microservices adoption,
which facilitated implementation through infrastructure reuse and knowledge
sharing between teams.

</details>


### [11] [An object-centric core metamodel for IoT-enhanced event logs](https://arxiv.org/abs/2506.21300)
*Yannis Bertrand,Christian Imenkamp,Lukas Malburg,Matthias Ehrendorfer,Marco Franceschetti,Joscha Grüger,Francesco Leotta,Jürgen Mangler,Ronny Seiger,Agnes Koschmider,Stefanie Rinderle-Ma,Barbara Weber,Estefania Serral*

Main category: cs.SE

TL;DR: 论文提出了一种核心模型，整合了现有物联网（IoT）数据与业务流程数据集成模型的关键特征，以促进数据共享和协作。


<details>
  <summary>Details</summary>
Motivation: 物联网设备的普及产生了大量数据，但与传统流程数据的集成存在挑战，现有模型分散且难以共享。

Method: 提出一个基于共同需求的核心模型，并通过Python原型实现验证其满足这些需求。

Result: 核心模型成功整合了现有模型的关键特征，并通过用例验证其有效性。

Conclusion: 该核心模型为物联网与业务流程数据的集成提供了统一框架，促进了数据共享和协作。

Abstract: Advances in Internet-of-Things (IoT) technologies have prompted the
integration of IoT devices with business processes (BPs) in many organizations
across various sectors, such as manufacturing, healthcare and smart spaces. The
proliferation of IoT devices leads to the generation of large amounts of IoT
data providing a window on the physical context of BPs, which facilitates the
discovery of new insights about BPs using process mining (PM) techniques.
However, to achieve these benefits, IoT data need to be combined with
traditional process (event) data, which is challenging due to the very
different characteristics of IoT and process data, for instance in terms of
granularity levels. Recently, several data models were proposed to integrate
IoT data with process data, each focusing on different aspects of data
integration based on different assumptions and requirements. This fragmentation
hampers data exchange and collaboration in the field of PM, e.g., making it
tedious for researchers to share data. In this paper, we present a core model
synthesizing the most important features of existing data models. As the core
model is based on common requirements, it greatly facilitates data sharing and
collaboration in the field. A prototypical Python implementation is used to
evaluate the model against various use cases and demonstrate that it satisfies
these common requirements.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [12] [Perry: A High-level Framework for Accelerating Cyber Deception Experimentation](https://arxiv.org/abs/2506.20770)
*Brian Singer,Yusuf Saquib,Lujo Bauer,Vyas Sekar*

Main category: cs.CR

TL;DR: Perry是一个高级框架，用于加速设计和探索网络欺骗的假设场景，简化了操作员的实验和评估过程。


<details>
  <summary>Details</summary>
Motivation: 现有的欺骗工具和平台实现复杂且难以修改，操作员难以实验和评估欺骗方法。

Method: Perry包含两个组件：高级抽象层和实验模块，通过四个关键模块（动作规划器、可观察性模块、环境状态服务和攻击图服务）实现高级规范的转换。

Result: Perry减少了实现多样化欺骗防御、攻击者和环境的努力，并通过55个独特场景的仿真展示了其价值。

Conclusion: Perry的抽象层简化了欺骗策略的探索，帮助操作员揭示微妙的权衡。

Abstract: Cyber deception aims to distract, delay, and detect network attackers with
fake assets such as honeypots, decoy credentials, or decoy files. However,
today, it is difficult for operators to experiment, explore, and evaluate
deception approaches. Existing tools and platforms have non-portable and
complex implementations that are difficult to modify and extend. We address
this pain point by introducing Perry, a high-level framework that accelerates
the design and exploration of deception what-if scenarios. Perry has two
components: a high-level abstraction layer for security operators to specify
attackers and deception strategies, and an experimentation module to run these
attackers and defenders in realistic emulated networks. To translate these
high-level specifications we design four key modules for Perry: 1) an action
planner that translates high-level actions into low-level implementations, 2)
an observability module to translate low-level telemetry into high-level
observations, 3) an environment state service that enables environment agnostic
strategies, and 4) an attack graph service to reason about how attackers could
explore an environment. We illustrate that Perry's abstractions reduce the
implementation effort of exploring a wide variety of deception defenses,
attackers, and environments. We demonstrate the value of Perry by emulating 55
unique deception what-if scenarios and illustrate how these experiments enable
operators to shed light on subtle tradeoffs.

</details>


### [13] [SIMulator: SIM Tracing on a (Pico-)Budget](https://arxiv.org/abs/2506.20800)
*Gabriel K. Gegenhuber,Philipp É. Frenzel,Adrian Dabrowski*

Main category: cs.CR

TL;DR: 论文提出了一种低成本实现SIM追踪功能的方法，使用广泛可得的硬件（如UART和GPIO），显著降低了硬件复杂性和成本。


<details>
  <summary>Details</summary>
Motivation: 传统SIM追踪依赖昂贵专用硬件，限制了研究者和爱好者的参与。本文旨在通过简化硬件需求，使更多人能进行蜂窝网络研究。

Method: 利用UART接口和GPIO端口，将SIM追踪功能移植到低成本微控制器（如Raspberry Pi Pico），并通过电气解耦SIM与调制解调器，仅传输APDU级别数据。

Result: 成功实现了低成本（约4美元）的SIM追踪功能，显著降低了硬件复杂性和成本。

Conclusion: 该方法使SIM追踪技术更易获取，有望推动蜂窝网络研究的广泛探索和实验。

Abstract: SIM tracing -- the ability to inspect, modify, and relay communication
between a SIM card and modem -- has become a significant technique in cellular
network research. It enables essential security- and development-related
applications such as fuzzing communication interfaces, extracting session keys,
monitoring hidden SIM activity (e.g., proactive SIM commands or over-the-air
updates), and facilitating scalable, distributed measurement platforms through
SIM reuse. Traditionally, achieving these capabilities has relied on
specialized hardware, which can pose financial and logistical burdens for
researchers, particularly those new to the field. In this work, we show that
full SIM tracing functionality can be achieved using only simple, widely
available components, such as UART interfaces and GPIO ports. We port these
capabilities to low-cost microcontrollers, exemplified by the Raspberry Pi Pico
(4~USD). Unlike other approaches, it dramatically reduces hardware complexity
by electrically decoupling the SIM and the modem and only transferring on APDU
level. By significantly reducing hardware requirements and associated costs, we
aim to make SIM tracing techniques accessible to a broader community of
researchers and hobbyists, fostering wider exploration and experimentation in
cellular network research.

</details>


### [14] [Poster: Enhancing GNN Robustness for Network Intrusion Detection via Agent-based Analysis](https://arxiv.org/abs/2506.20806)
*Zhonghao Zhan,Huichi Zhou,Hamed Haddadi*

Main category: cs.CR

TL;DR: 该论文提出了一种利用大型语言模型（LLMs）增强图神经网络（GNNs）在入侵检测系统中鲁棒性和泛化能力的新方法。


<details>
  <summary>Details</summary>
Motivation: GNNs在网络入侵检测系统（NIDS）中表现优异，但在分布漂移和对抗攻击下性能下降，现有评估方法缺乏对多种攻击类型的系统性分析。

Method: 通过将LLMs作为模拟网络安全专家代理，分析网络流数据生成的图结构，识别并缓解对抗性扰动。

Result: 实验表明，LLM分析显著提升了GNNs在对抗攻击下的鲁棒性。

Conclusion: LLM代理可作为入侵检测架构中的补充层，增强系统整体性能。

Abstract: Graph Neural Networks (GNNs) show great promise for Network Intrusion
Detection Systems (NIDS), particularly in IoT environments, but suffer
performance degradation due to distribution drift and lack robustness against
realistic adversarial attacks. Current robustness evaluations often rely on
unrealistic synthetic perturbations and lack demonstrations on systematic
analysis of different kinds of adversarial attack, which encompass both
black-box and white-box scenarios. This work proposes a novel approach to
enhance GNN robustness and generalization by employing Large Language Models
(LLMs) in an agentic pipeline as simulated cybersecurity expert agents. These
agents scrutinize graph structures derived from network flow data, identifying
and potentially mitigating suspicious or adversarially perturbed elements
before GNN processing. Our experiments, using a framework designed for
realistic evaluation and testing with a variety of adversarial attacks
including a dataset collected from physical testbed experiments, demonstrate
that integrating LLM analysis can significantly improve the resilience of
GNN-based NIDS against challenges, showcasing the potential of LLM agent as a
complementary layer in intrusion detection architectures.

</details>


### [15] [Empowering Digital Agriculture: A Privacy-Preserving Framework for Data Sharing and Collaborative Research](https://arxiv.org/abs/2506.20872)
*Osama Zafar,Rosemarie Santa González,Mina Namazi,Alfonso Morales,Erman Ayday*

Main category: cs.CR

TL;DR: 提出了一种隐私保护框架，结合降维技术和差分隐私，支持安全数据共享与协作，验证了其隐私保护和实用性。


<details>
  <summary>Details</summary>
Motivation: 解决农民因隐私问题不愿共享数据的问题，促进数据驱动农业的发展。

Method: 结合主成分分析（PCA）和拉普拉斯噪声的差分隐私技术，支持联邦学习和协作识别。

Result: 在真实数据集上验证了框架的隐私保护和实用性，性能接近集中式系统。

Conclusion: 该框架有助于农民协作和研究人员利用数据，推动农业创新和可持续发展。

Abstract: Data-driven agriculture, which integrates technology and data into
agricultural practices, has the potential to improve crop yield, disease
resilience, and long-term soil health. However, privacy concerns, such as
adverse pricing, discrimination, and resource manipulation, deter farmers from
sharing data, as it can be used against them. To address this barrier, we
propose a privacy-preserving framework that enables secure data sharing and
collaboration for research and development while mitigating privacy risks. The
framework combines dimensionality reduction techniques (like Principal
Component Analysis (PCA)) and differential privacy by introducing Laplacian
noise to protect sensitive information. The proposed framework allows
researchers to identify potential collaborators for a target farmer and train
personalized machine learning models either on the data of identified
collaborators via federated learning or directly on the aggregated
privacy-protected data. It also allows farmers to identify potential
collaborators based on similarities. We have validated this on real-life
datasets, demonstrating robust privacy protection against adversarial attacks
and utility performance comparable to a centralized system. We demonstrate how
this framework can facilitate collaboration among farmers and help researchers
pursue broader research objectives. The adoption of the framework can empower
researchers and policymakers to leverage agricultural data responsibly, paving
the way for transformative advances in data-driven agriculture. By addressing
critical privacy challenges, this work supports secure data integration,
fostering innovation and sustainability in agricultural systems.

</details>


### [16] [ZKPROV: A Zero-Knowledge Approach to Dataset Provenance for Large Language Models](https://arxiv.org/abs/2506.20915)
*Mina Namazi,Alexander Nemecek,Erman Ayday*

Main category: cs.CR

TL;DR: ZKPROV是一种新型密码学框架，通过零知识证明验证大型语言模型（LLM）的数据来源，确保模型训练数据的可靠性而不泄露敏感信息。


<details>
  <summary>Details</summary>
Motivation: 在敏感领域（如医疗）部署LLM时，验证其数据来源的完整性至关重要，但现有方法要么计算成本高，要么依赖可信执行环境。

Method: ZKPROV利用零知识证明将训练模型与授权数据集绑定，避免验证每一步训练过程，同时通过数据集签名元数据和紧凑模型参数承诺提供隐私保护。

Result: 实验证明ZKPROV在生成和验证证明时高效且可扩展，适用于实际部署，并提供了形式化的安全保障。

Conclusion: ZKPROV在保护数据集机密性的同时，提供可信的数据来源验证，为LLM在敏感领域的应用提供了实用解决方案。

Abstract: As the deployment of large language models (LLMs) grows in sensitive domains,
ensuring the integrity of their computational provenance becomes a critical
challenge, particularly in regulated sectors such as healthcare, where strict
requirements are applied in dataset usage. We introduce ZKPROV, a novel
cryptographic framework that enables zero-knowledge proofs of LLM provenance.
It allows users to verify that a model is trained on a reliable dataset without
revealing sensitive information about it or its parameters. Unlike prior
approaches that focus on complete verification of the training process
(incurring significant computational cost) or depend on trusted execution
environments, ZKPROV offers a distinct balance. Our method cryptographically
binds a trained model to its authorized training dataset(s) through
zero-knowledge proofs while avoiding proof of every training step. By
leveraging dataset-signed metadata and compact model parameter commitments,
ZKPROV provides sound and privacy-preserving assurances that the result of the
LLM is derived from a model trained on the claimed authorized and relevant
dataset. Experimental results demonstrate the efficiency and scalability of the
ZKPROV in generating this proof and verifying it, achieving a practical
solution for real-world deployments. We also provide formal security
guarantees, proving that our approach preserves dataset confidentiality while
ensuring trustworthy dataset provenance.

</details>


### [17] [CodeGuard: A Generalized and Stealthy Backdoor Watermarking for Generative Code Models](https://arxiv.org/abs/2506.20926)
*Haoxuan Li,Jiale Zhang,Xiaobing Sun,Xiapu Luo*

Main category: cs.CR

TL;DR: CodeGuard提出了一种结合注意力机制和分布式触发嵌入策略的新型水印方法，解决了现有技术在泛化性和隐蔽性上的不足。


<details>
  <summary>Details</summary>
Motivation: 生成代码模型（GCMs）需要有效的数字版权保护，但现有水印技术存在泛化性差和隐蔽性不足的问题。

Method: CodeGuard利用注意力机制确定水印嵌入位置，并通过同态字符替换和分布式触发嵌入策略提高隐蔽性。

Result: 实验显示，CodeGuard在代码摘要和生成任务中水印验证率达100%，且不影响主任务性能，隐蔽性显著优于基线方法。

Conclusion: CodeGuard为生成代码模型的版权保护提供了一种高效且隐蔽的解决方案。

Abstract: Generative code models (GCMs) significantly enhance development efficiency
through automated code generation and code summarization. However, building and
training these models require computational resources and time, necessitating
effective digital copyright protection to prevent unauthorized leaks and
misuse. Backdoor watermarking, by embedding hidden identifiers, simplifies
copyright verification by breaking the model's black-box nature. Current
backdoor watermarking techniques face two main challenges: first, limited
generalization across different tasks and datasets, causing fluctuating
verification rates; second, insufficient stealthiness, as watermarks are easily
detected and removed by automated methods. To address these issues, we propose
CodeGuard, a novel watermarking method combining attention mechanisms with
distributed trigger embedding strategies. Specifically, CodeGuard employs
attention mechanisms to identify watermark embedding positions, ensuring
verifiability. Moreover, by using homomorphic character replacement, it avoids
manual detection, while distributed trigger embedding reduces the likelihood of
automated detection. Experimental results demonstrate that CodeGuard achieves
up to 100% watermark verification rates in both code summarization and code
generation tasks, with no impact on the primary task performance. In terms of
stealthiness, CodeGuard performs exceptionally, with a maximum detection rate
of only 0.078 against ONION detection methods, significantly lower than
baseline methods.

</details>


### [18] [SPA: Towards More Stealth and Persistent Backdoor Attacks in Federated Learning](https://arxiv.org/abs/2506.20931)
*Chengcheng Zhu,Ye Li,Bosen Rao,Jiale Zhang,Yunlong Mao,Sheng Zhong*

Main category: cs.CR

TL;DR: 提出了一种名为SPA的新型隐蔽后门攻击框架，通过特征空间对齐而非直接触发标签关联，提高了攻击的隐蔽性和持久性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中的后门攻击通常依赖端到端标签监督，导致特征解耦和持久性有限。SPA旨在解决这些问题。

Method: 利用特征空间对齐减少后门触发特征与目标类特征之间的表示距离，并通过自适应对抗触发优化机制增强攻击效果。

Result: SPA在多种联邦学习基准测试中表现出高攻击成功率、低模型效用影响，并在非IID数据分布下保持鲁棒性。

Conclusion: SPA展示了后门攻击在联邦学习中的高度隐蔽性和持久性，呼吁开发更先进的特征级防御技术。

Abstract: Federated Learning (FL) has emerged as a leading paradigm for
privacy-preserving distributed machine learning, yet the distributed nature of
FL introduces unique security challenges, notably the threat of backdoor
attacks. Existing backdoor strategies predominantly rely on end-to-end label
supervision, which, despite their efficacy, often results in detectable feature
disentanglement and limited persistence. In this work, we propose a novel and
stealthy backdoor attack framework, named SPA, which fundamentally departs from
traditional approaches by leveraging feature-space alignment rather than direct
trigger-label association. Specifically, SPA reduces representational distances
between backdoor trigger features and target class features, enabling the
global model to misclassify trigger-embedded inputs with high stealth and
persistence. We further introduce an adaptive, adversarial trigger optimization
mechanism, utilizing boundary-search in the feature space to enhance attack
longevity and effectiveness, even against defensive FL scenarios and non-IID
data distributions. Extensive experiments on various FL benchmarks demonstrate
that SPA consistently achieves high attack success rates with minimal impact on
model utility, maintains robustness under challenging participation and data
heterogeneity conditions, and exhibits persistent backdoor effects far
exceeding those of conventional techniques. Our results call urgent attention
to the evolving sophistication of backdoor threats in FL and emphasize the
pressing need for advanced, feature-level defense techniques.

</details>


### [19] [PrivacyGo: Privacy-Preserving Ad Measurement with Multidimensional Intersection](https://arxiv.org/abs/2506.20981)
*Jian Du,Haohao Qian,Shikun Zhang,Wen-jie Lu,Donghang Lu,Yongchuan Niu,Bo Jiang,Yongjun Zhao,Qiang Yan*

Main category: cs.CR

TL;DR: 本文提出了一种基于反向OPRF和盲密钥旋转技术的隐私保护广告测量框架，支持多标识符安全匹配，防止跨标识符关联，并引入差分隐私机制。


<details>
  <summary>Details</summary>
Motivation: 解决多标识符隐私用户画像匹配问题，满足现代广告分析中对隐私保护的需求。

Method: 采用反向OPRF和盲密钥旋转技术，结合差分隐私机制，设计高效且安全的协议。

Result: 协议具有强隐私保证和高效率，适用于大规模数据集，为广告行业提供了实用的隐私保护解决方案。

Conclusion: 本文为隐私保护广告测量框架设定了新标准，结合密码学与差分隐私，满足行业关键需求。

Abstract: This paper tackles the challenging and practical problem of multi-identifier
private user profile matching for privacy-preserving ad measurement, a
cornerstone of modern advertising analytics. We introduce a comprehensive
cryptographic framework leveraging reversed Oblivious Pseudorandom Functions
(OPRF) and novel blind key rotation techniques to support secure matching
across multiple identifiers. Our design prevents cross-identifier linkages and
includes a differentially private mechanism to obfuscate intersection sizes,
mitigating risks such as membership inference attacks.
  We present a concrete construction of our protocol that achieves both strong
privacy guarantees and high efficiency. It scales to large datasets, offering a
practical and scalable solution for privacy-centric applications like secure ad
conversion tracking. By combining rigorous cryptographic principles with
differential privacy, our work addresses a critical need in the advertising
industry, setting a new standard for privacy-preserving ad measurement
frameworks.

</details>


### [20] [TEMPEST-LoRa: Cross-Technology Covert Communication](https://arxiv.org/abs/2506.21069)
*Xieyang Sun,Yuanqing Zheng,Wei Xi,Zuhao Chen,Zhizhen Chen,Han Hao,Zhiping Jiang,Sheng Zhong*

Main category: cs.CR

TL;DR: TEMPEST-LoRa是一种新型电磁隐蔽信道，利用视频电缆的电磁泄漏，通过LoRa接收器远距离传输敏感数据，最大距离87.5米，速率21.6 kbps。


<details>
  <summary>Details</summary>
Motivation: 电磁隐蔽信道对隔离网络的安全构成威胁，现有方法需要近距离部署专用接收器，限制了实际影响。本文旨在探索一种更隐蔽、远距离的传输方式。

Method: 利用视频电缆的电磁泄漏，通过Cross-Technology Covert Communication (CTCC)技术，将数据调制为LoRa可接收的信号。

Result: 实验表明，攻击者可在87.5米距离内以21.6 kbps速率可靠解码数据，且显示器关闭时仍可传输。

Conclusion: TEMPEST-LoRa展示了电磁隐蔽信道的潜在风险，需引起安全领域的重视。

Abstract: Electromagnetic (EM) covert channels pose significant threats to computer and
communications security in air-gapped networks. Previous works exploit EM
radiation from various components (e.g., video cables, memory buses, CPUs) to
secretly send sensitive information. These approaches typically require the
attacker to deploy highly specialized receivers near the victim, which limits
their real-world impact. This paper reports a new EM covert channel,
TEMPEST-LoRa, that builds on Cross-Technology Covert Communication (CTCC),
which could allow attackers to covertly transmit EM-modulated secret data from
air-gapped networks to widely deployed operational LoRa receivers from afar. We
reveal the potential risk and demonstrate the feasibility of CTCC by tackling
practical challenges involved in manipulating video cables to precisely
generate the EM leakage that could readily be received by third-party
commercial LoRa nodes/gateways. Experiment results show that attackers can
reliably decode secret data modulated by the EM leakage from a video cable at a
maximum distance of 87.5m or a rate of 21.6 kbps. We note that the secret data
transmission can be performed with monitors turned off (therefore covertly).

</details>


### [21] [PhishKey: A Novel Centroid-Based Approach for Enhanced Phishing Detection Using Adaptive HTML Component Extraction](https://arxiv.org/abs/2506.21106)
*Felipe Castaño,Eduardo Fidalgo,Enrique Alegre,Rocio Alaiz-Rodríguez,Raul Orduna,Francesco Zola*

Main category: cs.CR

TL;DR: PhishKey是一种新型钓鱼检测方法，结合字符级URL分类和HTML内容提取，通过软投票集成提高分类准确性。


<details>
  <summary>Details</summary>
Motivation: 钓鱼攻击快速演变，绕过检测机制并利用人类弱点，需要适应性、鲁棒性和高效的解决方案。

Method: PhishKey结合CNN进行URL分类和CAPE提取HTML内容，通过软投票集成结果。

Result: 在四个数据集上达到98.70% F1分数，对抗性攻击下性能下降最小。

Conclusion: PhishKey在钓鱼检测中表现出高效性和鲁棒性，适用于实际应用。

Abstract: Phishing attacks pose a significant cybersecurity threat, evolving rapidly to
bypass detection mechanisms and exploit human vulnerabilities. This paper
introduces PhishKey to address the challenges of adaptability, robustness, and
efficiency. PhishKey is a novel phishing detection method using automatic
feature extraction from hybrid sources. PhishKey combines character-level
processing with Convolutional Neural Networks (CNN) for URL classification, and
a Centroid-Based Key Component Phishing Extractor (CAPE) for HTML content at
the word level. CAPE reduces noise and ensures complete sample processing
avoiding crop operations on the input data. The predictions from both modules
are integrated using a soft-voting ensemble to achieve more accurate and
reliable classifications. Experimental evaluations on four state-of-the-art
datasets demonstrate the effectiveness of PhishKey. It achieves up to 98.70% F1
Score and shows strong resistance to adversarial manipulations such as
injection attacks with minimal performance degradation.

</details>


### [22] [Inside Job: Defending Kubernetes Clusters Against Network Misconfigurations](https://arxiv.org/abs/2506.21134)
*Jacopo Bufalino,Jose Luis Martin-Navarro,Mario Di Francesco,Tuomas Aura*

Main category: cs.CR

TL;DR: 本文分析了Kubernetes集群中网络配置对安全的影响，重点关注横向移动问题。通过评估287个开源应用，发现634个配置错误，远超现有解决方案的能力。部分问题已通过提出的缓解措施修复。


<details>
  <summary>Details</summary>
Motivation: Kubernetes作为容器编排标准，其网络配置对安全的影响尚未得到充分研究，尤其是横向移动问题。

Method: 对287个开源应用进行网络配置分析，重点关注横向移动。

Result: 发现634个配置错误，部分问题已通过缓解措施修复。

Conclusion: 网络配置对Kubernetes安全至关重要，现有解决方案需改进。

Abstract: Kubernetes has emerged as the de facto standard for container orchestration.
Unfortunately, its increasing popularity has also made it an attractive target
for malicious actors. Despite extensive research on securing Kubernetes, little
attention has been paid to the impact of network configuration on the security
of application deployments. This paper addresses this gap by conducting a
comprehensive analysis of network misconfigurations in a Kubernetes cluster
with specific reference to lateral movement. Accordingly, we carried out an
extensive evaluation of 287 open-source applications belonging to six different
organizations, ranging from IT companies and public entities to non-profits. As
a result, we identified 634 misconfigurations, well beyond what could be found
by solutions in the state of the art. We responsibly disclosed our findings to
the concerned organizations and engaged in a discussion to assess their
severity. As of now, misconfigurations affecting more than thirty applications
have been fixed with the mitigations we proposed.

</details>


### [23] [Balancing Privacy and Utility in Correlated Data: A Study of Bayesian Differential Privacy](https://arxiv.org/abs/2506.21308)
*Martin Lange,Patricia Guerra-Balboa,Javier Parra-Arnau,Thorsten Strufe*

Main category: cs.CR

TL;DR: 论文探讨了贝叶斯差分隐私（BDP）在相关数据中的实用性，提出了一种新方法以保持竞争力。


<details>
  <summary>Details</summary>
Motivation: 标准差分隐私（DP）在数据相关时低估隐私泄漏风险，BDP虽能解决此问题但现有机制实用性不足。

Method: 通过分析高斯多元分布和马尔可夫链等结构，提出理论框架并设计适应BDP的DP机制。

Result: 在真实数据库上验证，新方法能保持实用性，为相关数据隐私保护提供可行方案。

Conclusion: BDP在相关数据中可实现实用性，为隐私保护实践开辟新途径。

Abstract: Privacy risks in differentially private (DP) systems increase significantly
when data is correlated, as standard DP metrics often underestimate the
resulting privacy leakage, leaving sensitive information vulnerable. Given the
ubiquity of dependencies in real-world databases, this oversight poses a
critical challenge for privacy protections. Bayesian differential privacy (BDP)
extends DP to account for these correlations, yet current BDP mechanisms
indicate notable utility loss, limiting its adoption.
  In this work, we address whether BDP can be realistically implemented in
common data structures without sacrificing utility -- a key factor for its
applicability. By analyzing arbitrary and structured correlation models,
including Gaussian multivariate distributions and Markov chains, we derive
practical utility guarantees for BDP. Our contributions include theoretical
links between DP and BDP and a novel methodology for adapting DP mechanisms to
meet the BDP requirements. Through evaluations on real-world databases, we
demonstrate that our novel theorems enable the design of BDP mechanisms that
maintain competitive utility, paving the way for practical privacy-preserving
data practices in correlated settings.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [24] [The Singapore Consensus on Global AI Safety Research Priorities](https://arxiv.org/abs/2506.20702)
*Yoshua Bengio,Tegan Maharaj,Luke Ong,Stuart Russell,Dawn Song,Max Tegmark,Lan Xue,Ya-Qin Zhang,Stephen Casper,Wan Sie Lee,Sören Mindermann,Vanessa Wilfred,Vidhisha Balachandran,Fazl Barez,Michael Belinsky,Imane Bello,Malo Bourgon,Mark Brakel,Siméon Campos,Duncan Cass-Beggs,Jiahao Chen,Rumman Chowdhury,Kuan Chua Seah,Jeff Clune,Juntao Dai,Agnes Delaborde,Nouha Dziri,Francisco Eiras,Joshua Engels,Jinyu Fan,Adam Gleave,Noah Goodman,Fynn Heide,Dan Hendrycks,Cyrus Hodes,Bryan Low Kian Hsiang,Minlie Huang,Sami Jawhar,Wang Jingyu,Adam Tauman Kalai,Meindert Kamphuis,Mohan Kankanhalli,Subhash Kantamneni,Mathias Bonde Kirk,Thomas Kwa,Jeffrey Ladish,Kwok-Yan Lam,Wan Lee Sie,Taewhi Lee,Xiaojian Li,Jiajun Liu,Chaochao Lu,Yifan Mai,Richard Mallah,Julian Michael,Nick Moës,Simon Möller,Kihyuk Nam,Kwan Yee Ng,Mark Nitzberg,Besmira Nushi,Seán O hÉigeartaigh,Alejandro Ortega,Pierre Peigné,James Petrie,Benjamin Prud'Homme,Reihaneh Rabbany,Nayat Sanchez-Pi,Sarah Schwettmann,Buck Shlegeris,Saad Siddiqui,Aradhana Sinha,Martín Soto,Cheston Tan,Dong Ting,Robert Trager,Brian Tse,Anthony Tung K. H.,Vanessa Wilfred,John Willes,Denise Wong,Wei Xu,Rongwu Xu,Yi Zeng,HongJiang Zhang,Djordje Žikelić*

Main category: cs.AI

TL;DR: 本文讨论了AI安全的重要性，提出了构建可信生态系统的必要性，并通过2025年新加坡AI安全会议总结了AI安全研究的三个关键领域。


<details>
  <summary>Details</summary>
Motivation: 随着AI能力的快速提升，确保其安全性（可信、可靠、安全）成为迫切需求，以避免潜在风险并促进创新。

Method: 通过国际AI安全会议（SCAI）汇集全球AI科学家，采用深度防御模型，将AI安全研究分为开发、评估和控制三大领域。

Result: 报告总结了AI安全研究的三大挑战：开发可信AI系统、评估其风险以及部署后的监控与干预。

Conclusion: 构建可信的AI生态系统是确保AI安全的关键，需要全球合作和多层次的研究框架。

Abstract: Rapidly improving AI capabilities and autonomy hold significant promise of
transformation, but are also driving vigorous debate on how to ensure that AI
is safe, i.e., trustworthy, reliable, and secure. Building a trusted ecosystem
is therefore essential -- it helps people embrace AI with confidence and gives
maximal space for innovation while avoiding backlash.
  The "2025 Singapore Conference on AI (SCAI): International Scientific
Exchange on AI Safety" aimed to support research in this space by bringing
together AI scientists across geographies to identify and synthesise research
priorities in AI safety. This resulting report builds on the International AI
Safety Report chaired by Yoshua Bengio and backed by 33 governments. By
adopting a defence-in-depth model, this report organises AI safety research
domains into three types: challenges with creating trustworthy AI systems
(Development), challenges with evaluating their risks (Assessment), and
challenges with monitoring and intervening after deployment (Control).

</details>


### [25] [MAGPIE: A dataset for Multi-AGent contextual PrIvacy Evaluation](https://arxiv.org/abs/2506.20737)
*Gurusha Juneja,Alon Albalak,Wenyue Hua,William Yang Wang*

Main category: cs.AI

TL;DR: 论文探讨了基于LLM的代理在多轮对话中是否理解上下文隐私，并评估了其在协作任务中保护隐私的能力。研究发现当前模型（如GPT-4o和Claude-2.7-Sonnet）在隐私分类和多轮对话中表现不佳，隐私泄露率高。


<details>
  <summary>Details</summary>
Motivation: 随着LLM代理的普及，隐私保护在多代理协作任务（如调度、谈判等）中变得至关重要。现有基准测试仅评估单轮简单任务，无法反映真实场景中隐私保护的复杂性。

Method: 提出了一个名为MAGPIE的基准测试，包含158个高风险场景，评估LLM代理对上下文隐私的理解及其在协作任务中的隐私保护能力。

Result: 当前模型对隐私数据的分类错误率高（25.2%和43.6%），多轮对话中隐私泄露率高达59.9%和50.5%，且71%的场景中多代理系统无法完成任务。

Conclusion: 当前模型在上下文隐私保护和协作任务解决方面表现不足，亟需改进。

Abstract: The proliferation of LLM-based agents has led to increasing deployment of
inter-agent collaboration for tasks like scheduling, negotiation, resource
allocation etc. In such systems, privacy is critical, as agents often access
proprietary tools and domain-specific databases requiring strict
confidentiality. This paper examines whether LLM-based agents demonstrate an
understanding of contextual privacy. And, if instructed, do these systems
preserve inference time user privacy in non-adversarial multi-turn
conversation. Existing benchmarks to evaluate contextual privacy in LLM-agents
primarily assess single-turn, low-complexity tasks where private information
can be easily excluded. We first present a benchmark - MAGPIE comprising 158
real-life high-stakes scenarios across 15 domains. These scenarios are designed
such that complete exclusion of private data impedes task completion yet
unrestricted information sharing could lead to substantial losses. We then
evaluate the current state-of-the-art LLMs on (a) their understanding of
contextually private data and (b) their ability to collaborate without
violating user privacy. Empirical experiments demonstrate that current models,
including GPT-4o and Claude-2.7-Sonnet, lack robust understanding of contextual
privacy, misclassifying private data as shareable 25.2\% and 43.6\% of the
time. In multi-turn conversations, these models disclose private information in
59.9\% and 50.5\% of cases even under explicit privacy instructions.
Furthermore, multi-agent systems fail to complete tasks in 71\% of scenarios.
These results underscore that current models are not aligned towards both
contextual privacy preservation and collaborative task-solving.

</details>


### [26] [Dynamic Context-Aware Prompt Recommendation for Domain-Specific AI Applications](https://arxiv.org/abs/2506.20815)
*Xinye Tang,Haijun Zhai,Chaitanya Belwal,Vineeth Thayanithi,Philip Baumann,Yogesh K Roy*

Main category: cs.AI

TL;DR: 提出了一种动态上下文感知的提示推荐系统，用于领域特定的AI应用，通过多阶段推理和模板生成高质量提示。


<details>
  <summary>Details</summary>
Motivation: LLM应用对用户提示质量敏感，而领域特定应用中高质量提示的生成具有挑战性。

Method: 结合上下文查询分析、检索增强知识基础、分层技能组织和自适应技能排名，利用行为遥测和两阶段分层推理生成提示。

Result: 在真实数据集上验证了系统的高实用性和相关性，得到自动化和专家评估的认可。

Conclusion: 该系统能有效提升领域特定应用中提示的质量和实用性。

Abstract: LLM-powered applications are highly susceptible to the quality of user
prompts, and crafting high-quality prompts can often be challenging especially
for domain-specific applications. This paper presents a novel dynamic
context-aware prompt recommendation system for domain-specific AI applications.
Our solution combines contextual query analysis, retrieval-augmented knowledge
grounding, hierarchical skill organization, and adaptive skill ranking to
generate relevant and actionable prompt suggestions.
  The system leverages behavioral telemetry and a two-stage hierarchical
reasoning process to dynamically select and rank relevant skills, and
synthesizes prompts using both predefined and adaptive templates enhanced with
few-shot learning. Experiments on real-world datasets demonstrate that our
approach achieves high usefulness and relevance, as validated by both automated
and expert evaluations.

</details>


### [27] [Beyond Reactive Safety: Risk-Aware LLM Alignment via Long-Horizon Simulation](https://arxiv.org/abs/2506.20949)
*Chenkai Sun,Denghui Zhang,ChengXiang Zhai,Heng Ji*

Main category: cs.AI

TL;DR: 论文提出了一种框架，用于评估语言模型建议的宏观社会影响，并引入了一个间接危害场景数据集，以测试模型对潜在不良后果的预见能力。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型在社会决策中的影响力增加，确保其建议的积极影响需要理解其宏观社会影响。

Method: 提出了一个概念验证框架，用于模拟模型建议在宏观社会系统中的传播，并引入了一个包含100个间接危害场景的数据集。

Result: 新数据集上性能提升超过20%，在现有安全基准测试中平均胜率超过70%。

Conclusion: 该方法为构建更安全的语言模型提供了有前景的方向。

Abstract: Given the growing influence of language model-based agents on high-stakes
societal decisions, from public policy to healthcare, ensuring their beneficial
impact requires understanding the far-reaching implications of their
suggestions. We propose a proof-of-concept framework that projects how
model-generated advice could propagate through societal systems on a
macroscopic scale over time, enabling more robust alignment. To assess the
long-term safety awareness of language models, we also introduce a dataset of
100 indirect harm scenarios, testing models' ability to foresee adverse,
non-obvious outcomes from seemingly harmless user prompts. Our approach
achieves not only over 20% improvement on the new dataset but also an average
win rate exceeding 70% against strong baselines on existing safety benchmarks
(AdvBench, SafeRLHF, WildGuardMix), suggesting a promising direction for safer
agents.

</details>


### [28] [Unveiling Causal Reasoning in Large Language Models: Reality or Mirage?](https://arxiv.org/abs/2506.21215)
*Haoang Chi,He Li,Wenjing Yang,Feng Liu,Long Lan,Xiaoguang Ren,Tongliang Liu,Bo Han*

Main category: cs.AI

TL;DR: 论文探讨了大型语言模型（LLMs）的因果推理能力，指出其仅能进行浅层（level-1）推理，缺乏人类式深层（level-2）推理。通过新基准CausalProbe-2024验证，并提出G^2-Reasoner方法提升LLMs的因果推理能力。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs是否具备类似人类的真实因果推理能力，发现其仅能进行浅层推理，缺乏深层推理能力。

Method: 通过分析LLMs的自回归机制，提出新基准CausalProbe-2024，并设计G^2-Reasoner方法，结合通用知识和目标导向提示。

Result: LLMs在CausalProbe-2024上表现显著下降，G^2-Reasoner显著提升了其在新鲜和反事实情境中的推理能力。

Conclusion: G^2-Reasoner为LLMs迈向深层因果推理提供了新路径，但仍需进一步研究。

Abstract: Causal reasoning capability is critical in advancing large language models
(LLMs) toward strong artificial intelligence. While versatile LLMs appear to
have demonstrated capabilities in understanding contextual causality and
providing responses that obey the laws of causality, it remains unclear whether
they perform genuine causal reasoning akin to humans. However, current evidence
indicates the contrary. Specifically, LLMs are only capable of performing
shallow (level-1) causal reasoning, primarily attributed to the causal
knowledge embedded in their parameters, but they lack the capacity for genuine
human-like (level-2) causal reasoning. To support this hypothesis,
methodologically, we delve into the autoregression mechanism of
transformer-based LLMs, revealing that it is not inherently causal.
Empirically, we introduce a new causal Q&A benchmark called CausalProbe-2024,
whose corpora are fresh and nearly unseen for the studied LLMs. The LLMs
exhibit a significant performance drop on CausalProbe-2024 compared to earlier
benchmarks, indicating the fact that they primarily engage in level-1 causal
reasoning. To bridge the gap towards level-2 causal reasoning, we draw
inspiration from the fact that human reasoning is usually facilitated by
general knowledge and intended goals. We propose G^2-Reasoner, a method that
incorporates general knowledge and goal-oriented prompts into LLMs' causal
reasoning processes. Experiments demonstrate that G^2-Reasoner significantly
enhances LLMs' causal reasoning capability, particularly in fresh and
counterfactual contexts. This work sheds light on a new path for LLMs to
advance towards genuine causal reasoning, going beyond level-1 and making
strides towards level-2.

</details>


### [29] [World-aware Planning Narratives Enhance Large Vision-Language Model Planner](https://arxiv.org/abs/2506.21230)
*Junhao Shi,Zhaoye Fei,Siyin Wang,Qipeng Guo,Jingjing Gong,Xipeng QIu*

Main category: cs.AI

TL;DR: 论文提出WAP框架，通过四种认知能力增强LVLMs的环境理解，显著提升了任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂场景中表现不佳，缺乏环境感知能力，导致模型依赖额外提示而非视觉推理。

Method: WAP框架通过视觉外观建模、空间推理、功能抽象和语法接地四种能力，结合课程学习，仅使用原始视觉观察进行训练。

Result: 在EB-ALFRED基准测试中，任务成功率提升60.7，常识推理和长时规划分别提升60.0和70.0。开源模型优于GPT-4o和Claude-3.5-Sonnet。

Conclusion: WAP框架显著提升了LVLMs在复杂场景中的表现，证明了环境理解的重要性。

Abstract: Large Vision-Language Models (LVLMs) show promise for embodied planning tasks
but struggle with complex scenarios involving unfamiliar environments and
multi-step goals. Current approaches rely on environment-agnostic imitation
learning that disconnects instructions from environmental contexts, causing
models to struggle with context-sensitive instructions and rely on
supplementary cues rather than visual reasoning during long-horizon
interactions. In this work, we propose World-Aware Planning Narrative
Enhancement (WAP), a framework that infuses LVLMs with comprehensive
environmental understanding through four cognitive capabilities (visual
appearance modeling, spatial reasoning, functional abstraction, and syntactic
grounding) while developing and evaluating models using only raw visual
observations through curriculum learning. Evaluations on the EB-ALFRED
benchmark demonstrate substantial improvements, with Qwen2.5-VL achieving a
60.7 absolute improvement in task success rates, particularly in commonsense
reasoning (+60.0) and long-horizon planning (+70.0). Notably, our enhanced
open-source models outperform proprietary systems like GPT-4o and
Claude-3.5-Sonnet by a large margin.

</details>


### [30] [IXAII: An Interactive Explainable Artificial Intelligence Interface for Decision Support Systems](https://arxiv.org/abs/2506.21310)
*Pauline Speckmann,Mario Nadj,Christian Janiesch*

Main category: cs.AI

TL;DR: IXAII是一个交互式可解释AI系统，整合了LIME、SHAP、Anchors和DiCE四种方法，针对不同用户群体提供定制化解释，并通过专家和普通用户访谈验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的事后可解释AI方法多为静态且忽视用户视角，限制了其实际效果。

Method: 开发了交互式系统IXAII，整合四种可解释AI方法，提供定制化解释和可视化选项。

Result: 用户访谈表明IXAII能有效提升透明度，被认为是实用的。

Conclusion: IXAII通过结合可解释性、交互性和实际应用，为人机交互提供了新视角。

Abstract: Although several post-hoc methods for explainable AI have been developed,
most are static and neglect the user perspective, limiting their effectiveness
for the target audience. In response, we developed the interactive explainable
intelligent system called IXAII that offers explanations from four explainable
AI methods: LIME, SHAP, Anchors, and DiCE. Our prototype provides tailored
views for five user groups and gives users agency over the explanations'
content and their format. We evaluated IXAII through interviews with experts
and lay users. Our results indicate that IXAII, which provides different
explanations with multiple visualization options, is perceived as helpful to
increase transparency. By bridging the gaps between explainable AI methods,
interactivity, and practical implementation, we provide a novel perspective on
AI explanation practices and human-AI interaction.

</details>


### [31] [Active Inference AI Systems for Scientific Discovery](https://arxiv.org/abs/2506.21329)
*Karthik Duraisamy*

Main category: cs.AI

TL;DR: 论文提出当前AI系统在科学发现中的局限性，并强调需要填补抽象、推理和现实三个关键差距，而非依赖模型规模或计算资源。作者提出了一种主动推理AI系统架构，结合因果自监督模型、贝叶斯规划器和闭环实验验证，以促进科学发现。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统在科学发现中存在架构和推理机制的局限性，无法有效模拟因果关系或与现实实验互动。作者旨在通过填补抽象、推理和现实差距，推动AI驱动的科学进步。

Method: 提出主动推理AI系统，包括：1）基于因果自监督的长期研究记忆；2）符号或神经符号规划器；3）持久知识图谱；4）通过闭环实验验证优化内部表征。

Result: 该系统通过结合内部模型和外部验证，支持反事实推理和假设验证，促进科学发现。同时强调人类判断在不确定性和模糊反馈中的必要性。

Conclusion: 论文提出了一种新型AI系统架构，通过填补关键差距和结合人类判断，为AI驱动的科学发现提供了可行路径。

Abstract: The rapid evolution of artificial intelligence has led to expectations of
transformative scientific discovery, yet current systems remain fundamentally
limited by their operational architectures, brittle reasoning mechanisms, and
their separation from experimental reality. Building on earlier work, we
contend that progress in AI-driven science now depends on closing three
fundamental gaps -- the abstraction gap, the reasoning gap, and the reality gap
-- rather than on model size/data/test time compute. Scientific reasoning
demands internal representations that support simulation of actions and
response, causal structures that distinguish correlation from mechanism, and
continuous calibration. We define active inference AI systems for scientific
discovery as those that (i) maintain long-lived research memories grounded in
causal self-supervised foundation models, (ii) symbolic or neuro-symbolic
planners equipped with Bayesian guardrails, (iii) grow persistent knowledge
graphs where thinking generates novel conceptual nodes, reasoning establishes
causal edges, and real-world interaction prunes false connections while
strengthening verified pathways, and (iv) refine their internal representations
through closed-loop interaction with both high-fidelity simulators and
automated laboratories - an operational loop where mental simulation guides
action and empirical surprise reshapes understanding. In essence, we outline an
architecture where discovery arises from the interplay between internal models
that enable counterfactual reasoning and external validation that grounds
hypotheses in reality. It is also argued that the inherent ambiguity in
feedback from simulations and experiments, and underlying uncertainties makes
human judgment indispensable, not as a temporary scaffold but as a permanent
architectural component.

</details>


### [32] [TableMoE: Neuro-Symbolic Routing for Structured Expert Reasoning in Multimodal Table Understanding](https://arxiv.org/abs/2506.21393)
*Junwen Zhang,Pu Chen,Yin Zhang*

Main category: cs.AI

TL;DR: TableMoE是一种神经符号混合专家架构，专为多模态表格数据的鲁棒结构化推理设计，显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 解决现有多模态大语言模型在复杂表格结构、符号密度和视觉退化条件下的性能不足和泛化能力差的问题。

Method: 提出Neuro-Symbolic Routing机制，动态路由表格元素至专用专家（如Table-to-HTML），并引入TableMoE-Align数据集进行预训练。

Result: 在WildStruct基准测试中表现优异，验证了神经符号路由和结构化专家对齐的核心作用。

Conclusion: TableMoE通过神经符号推理有效提升了多模态表格理解的鲁棒性和可解释性。

Abstract: Multimodal understanding of tables in real-world contexts is challenging due
to the complexity of structure, symbolic density, and visual degradation (blur,
skew, watermarking, incomplete structures or fonts, multi-span or
hierarchically nested layouts). Existing multimodal large language models
(MLLMs) struggle with such WildStruct conditions, resulting in limited
performance and poor generalization. To address these challenges, we propose
TableMoE, a neuro-symbolic Mixture-of-Connector-Experts (MoCE) architecture
specifically designed for robust, structured reasoning over multimodal table
data. TableMoE features an innovative Neuro-Symbolic Routing mechanism, which
predicts latent semantic token roles (e.g., header, data cell, axis, formula)
and dynamically routes table elements to specialized experts (Table-to-HTML,
Table-to-JSON, Table-to-Code) using a confidence-aware gating strategy informed
by symbolic reasoning graphs. To facilitate effective alignment-driven
pretraining, we introduce the large-scale TableMoE-Align dataset, consisting of
1.2M table-HTML-JSON-code quadruples across finance, science, biomedicine and
industry, utilized exclusively for model pretraining. For evaluation, we curate
and release four challenging WildStruct benchmarks: WMMFinQA, WMMTatQA,
WMMTabDialog, and WMMFinanceMath, designed specifically to stress-test models
under real-world multimodal degradation and structural complexity. Experimental
results demonstrate that TableMoE significantly surpasses existing
state-of-the-art models. Extensive ablation studies validate each core
component, emphasizing the critical role of Neuro-Symbolic Routing and
structured expert alignment. Through qualitative analyses, we further showcase
TableMoE's interpretability and enhanced robustness, underscoring the
effectiveness of integrating neuro-symbolic reasoning for multimodal table
understanding.

</details>


### [33] [Spatial Mental Modeling from Limited Views](https://arxiv.org/abs/2506.21458)
*Baiqiao Yin,Qineng Wang,Pingyue Zhang,Jianshu Zhang,Kangrui Wang,Zihan Wang,Jieyu Zhang,Keshigeyan Chandrasegaran,Han Liu,Ranjay Krishna,Saining Xie,Manling Li,Jiajun Wu,Li Fei-Fei*

Main category: cs.AI

TL;DR: 论文探讨了视觉语言模型（VLMs）是否能像人类一样通过少量视角想象完整场景，提出了MindCube基准测试，并通过三种方法提升VLMs的空间心理模型能力，最终通过‘先映射后推理’方法显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 研究VLMs是否具备人类的空间心理建模能力，以解决现有模型在空间推理任务中表现接近随机的问题。

Method: 使用MindCube基准测试评估VLMs的空间心理建模能力，并提出三种方法（中间视角生成、自然语言推理链、认知地图）来提升性能。最佳方法为‘先映射后推理’结合强化学习。

Result: 通过‘先映射后推理’方法，准确率从37.8%提升至60.8%（+23.0%），结合强化学习后进一步提升至70.7%（+32.9%）。

Conclusion: 通过构建和利用结构化空间表征，VLMs的空间推理能力显著提升，为理解不可观测空间提供了新思路。

Abstract: Can Vision Language Models (VLMs) imagine the full scene from just a few
views, like humans do? Humans form spatial mental models, internal
representations of unseen space, to reason about layout, perspective, and
motion. Our new MindCube benchmark with 21,154 questions across 3,268 images
exposes this critical gap, where existing VLMs exhibit near-random performance.
Using MindCube, we systematically evaluate how well VLMs build robust spatial
mental models through representing positions (cognitive mapping), orientations
(perspective-taking), and dynamics (mental simulation for "what-if" movements).
We then explore three approaches to help VLMs approximate spatial mental
models, including unseen intermediate views, natural language reasoning chains,
and cognitive maps. The significant improvement comes from a synergistic
approach, "map-then-reason", that jointly trains the model to first generate a
cognitive map and then reason upon it. By training models to reason over these
internal maps, we boosted accuracy from 37.8% to 60.8% (+23.0%). Adding
reinforcement learning pushed performance even further to 70.7% (+32.9%). Our
key insight is that such scaffolding of spatial mental models, actively
constructing and utilizing internal structured spatial representations with
flexible reasoning processes, significantly improves understanding of
unobservable space.

</details>


### [34] [Ad-Hoc Human-AI Coordination Challenge](https://arxiv.org/abs/2506.21490)
*Tin Dizdarević,Ravi Hammond,Tobias Gessler,Anisoara Calinescu,Jonathan Cook,Matteo Gallici,Andrei Lupu,Jakob Nicolaus Foerster*

Main category: cs.AI

TL;DR: 论文提出了一种名为AH2AC2的挑战，旨在解决人类与AI协调中的评估难题，通过开发人类代理代理实现低成本、可复现的评估。


<details>
  <summary>Details</summary>
Motivation: 解决人类与AI协调中的评估难题，尤其是Hanabi游戏中人类评估的高成本和难以复现问题。

Method: 开发人类代理代理，基于大规模人类游戏数据集，并开源有限的人类游戏数据以促进数据高效方法的发展。

Result: 提出了AH2AC2挑战，并提供了两玩家和三玩家Hanabi场景的基线结果。

Conclusion: 通过人类代理代理和开源数据集，为人类与AI协调研究提供了低成本、可复现的评估方法。

Abstract: Achieving seamless coordination between AI agents and humans is crucial for
real-world applications, yet it remains a significant open challenge. Hanabi is
a cooperative card game featuring imperfect information, constrained
communication, theory of mind requirements, and coordinated action -- making it
an ideal testbed for human-AI coordination. However, its use for human-AI
interaction has been limited by the challenges of human evaluation. In this
work, we introduce the Ad-Hoc Human-AI Coordination Challenge (AH2AC2) to
overcome the constraints of costly and difficult-to-reproduce human
evaluations. We develop \textit{human proxy agents} on a large-scale human
dataset that serve as robust, cheap, and reproducible human-like evaluation
partners in AH2AC2. To encourage the development of data-efficient methods, we
open-source a dataset of 3,079 games, deliberately limiting the amount of
available human gameplay data. We present baseline results for both two- and
three- player Hanabi scenarios. To ensure fair evaluation, we host the proxy
agents through a controlled evaluation system rather than releasing them
publicly. The code is available at
\href{https://github.com/FLAIROx/ah2ac2}{https://github.com/FLAIROx/ah2ac2}.

</details>


### [35] [Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge](https://arxiv.org/abs/2506.21506)
*Boyu Gou,Zanming Huang,Yuting Ning,Yu Gu,Michael Lin,Weijian Qi,Andrei Kopanev,Botao Yu,Bernal Jiménez Gutiérrez,Yiheng Shu,Chan Hee Song,Jiaman Wu,Shijie Chen,Hanane Nour Moussa,Tianshu Zhang,Jian Xie,Yifei Li,Tianci Xue,Zeyi Liao,Kai Zhang,Boyuan Zheng,Zhaowei Cai,Viktor Rozgic,Morteza Ziyadi,Huan Sun,Yu Su*

Main category: cs.AI

TL;DR: 论文介绍了Mind2Web 2，一个包含130个高质量、长周期任务的基准测试，用于评估自主网络搜索系统。提出了Agent-as-a-Judge框架，通过任务特定的评判代理自动评估答案正确性和来源归属。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法无法应对自主网络搜索系统的复杂性和开放性，需要新的基准和方法。

Method: 构建Mind2Web 2基准，提出基于树状评分设计的Agent-as-a-Judge框架。

Result: OpenAI Deep Research系统达到人类性能的50-70%，耗时减半。

Conclusion: Mind2Web 2为下一代自主搜索系统的开发和评估提供了严格基础。

Abstract: Agentic search such as Deep Research systems, where large language models
autonomously browse the web, synthesize information, and return comprehensive
citation-backed answers, represents a major shift in how users interact with
web-scale information. While promising greater efficiency and cognitive
offloading, the growing complexity and open-endedness of agentic search have
outpaced existing evaluation benchmarks and methodologies, which largely assume
short search horizons and static answers. In this paper, we introduce Mind2Web
2, a benchmark of 130 realistic, high-quality, and long-horizon tasks that
require real-time web browsing and extensive information synthesis, constructed
with over 1,000 hours of human labor. To address the challenge of evaluating
time-varying and complex answers, we propose a novel Agent-as-a-Judge
framework. Our method constructs task-specific judge agents based on a
tree-structured rubric design to automatically assess both answer correctness
and source attribution. We conduct a comprehensive evaluation of nine frontier
agentic search systems and human performance, along with a detailed error
analysis to draw insights for future development. The best-performing system,
OpenAI Deep Research, can already achieve 50-70% of human performance while
spending half the time, showing a great potential. Altogether, Mind2Web 2
provides a rigorous foundation for developing and benchmarking the next
generation of agentic search systems.

</details>


### [36] [PsyLite Technical Report](https://arxiv.org/abs/2506.21536)
*Fangjun Ding,Renyu Zhang,Xinyu Feng,Chengye Xie,Zheng Zhang,Yanting Zhang*

Main category: cs.AI

TL;DR: PsyLite是一个基于InternLM2.5-7B-chat的轻量级心理咨询大语言模型，通过两阶段训练策略提升推理能力、心理咨询能力和对话安全性，并在资源受限环境中实现低硬件部署。


<details>
  <summary>Details</summary>
Motivation: 现有AI心理咨询模型在对话安全、场景处理和轻量部署方面存在不足，需要改进。

Method: 采用混合蒸馏数据微调和ORPO偏好优化的两阶段训练策略，结合条件RAG引入幽默元素和增强安全性。

Result: 在CEval、CPsyCounE和SafeDialBench评估中表现优异，心理咨询专业性提升47.6%，对话安全性提升2.4%。

Conclusion: PsyLite为资源受限环境中的心理咨询应用提供了可行解决方案。

Abstract: With the rapid development of digital technology, AI-driven psychological
counseling has gradually become an important research direction in the field of
mental health. However, existing models still have deficiencies in dialogue
safety, detailed scenario handling, and lightweight deployment. To address
these issues, this study proposes PsyLite, a lightweight psychological
counseling large language model agent developed based on the base model
InternLM2.5-7B-chat. Through a two-stage training strategy (hybrid distillation
data fine-tuning and ORPO preference optimization), PsyLite enhances the
model's deep-reasoning ability, psychological counseling ability, and safe
dialogue ability. After deployment using Ollama and Open WebUI, a custom
workflow is created with Pipelines. An innovative conditional RAG is designed
to introduce crosstalk humor elements at appropriate times during psychological
counseling to enhance user experience and decline dangerous requests to
strengthen dialogue safety. Evaluations show that PsyLite outperforms the
baseline models in the Chinese general evaluation (CEval), psychological
counseling professional evaluation (CPsyCounE), and dialogue safety evaluation
(SafeDialBench), particularly in psychological counseling professionalism
(CPsyCounE score improvement of 47.6\%) and dialogue safety (\safe{} score
improvement of 2.4\%). Additionally, the model uses quantization technology
(GGUF q4\_k\_m) to achieve low hardware deployment (5GB memory is sufficient
for operation), providing a feasible solution for psychological counseling
applications in resource-constrained environments.

</details>
