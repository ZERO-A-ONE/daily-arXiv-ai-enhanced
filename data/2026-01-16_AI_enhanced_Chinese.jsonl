{"id": "2601.08959", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.08959", "abs": "https://arxiv.org/abs/2601.08959", "authors": ["Md Mashrur Arifin", "Maqsudur Rahman", "Nasir U. Eisty"], "title": "Integrating APK Image and Text Data for Enhanced Threat Detection: A Multimodal Deep Learning Approach to Android Malware", "comment": null, "summary": "As zero-day Android malware attacks grow more sophisticated, recent research highlights the effectiveness of using image-based representations of malware bytecode to detect previously unseen threats. However, existing studies often overlook how image type and resolution affect detection and ignore valuable textual data in Android Application Packages (APKs), such as permissions and metadata, limiting their ability to fully capture malicious behavior. The integration of multimodality, which combines image and text data, has gained momentum as a promising approach to address these limitations. This paper proposes a multimodal deep learning framework integrating APK images and textual features to enhance Android malware detection. We systematically evaluate various image types and resolutions across different Convolutional Neural Networks (CNN) architectures, including VGG, ResNet-152, MobileNet, DenseNet, EfficientNet-B4, and use LLaMA-2, a large language model, to extract and annotate textual features for improved analysis. The findings demonstrate that RGB images at higher resolutions (e.g., 256x256, 512x512) achieve superior classification performance, while the multimodal integration of image and text using the CLIP model reveals limited potential. Overall, this research highlights the importance of systematically evaluating image attributes and integrating multimodal data to develop effective malware detection for Android systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408APK\u56fe\u50cf\u548c\u6587\u672c\u7279\u5f81\u6765\u589e\u5f3aAndroid\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u3002\u7814\u7a76\u53d1\u73b0\u9ad8\u5206\u8fa8\u7387RGB\u56fe\u50cf\u6027\u80fd\u6700\u4f73\uff0c\u4f46\u56fe\u50cf\u4e0e\u6587\u672c\u7684\u591a\u6a21\u6001\u96c6\u6210\u6548\u679c\u6709\u9650\u3002", "motivation": "\u968f\u7740\u96f6\u65e5Android\u6076\u610f\u8f6f\u4ef6\u653b\u51fb\u65e5\u76ca\u590d\u6742\uff0c\u73b0\u6709\u7814\u7a76\u5e38\u5ffd\u7565\u56fe\u50cf\u7c7b\u578b\u548c\u5206\u8fa8\u7387\u5bf9\u68c0\u6d4b\u7684\u5f71\u54cd\uff0c\u5e76\u5ffd\u89c6APK\u4e2d\u7684\u6587\u672c\u6570\u636e\uff08\u5982\u6743\u9650\u548c\u5143\u6570\u636e\uff09\uff0c\u9650\u5236\u4e86\u5168\u9762\u6355\u6349\u6076\u610f\u884c\u4e3a\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u591a\u6a21\u6001\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u540c\u56fe\u50cf\u7c7b\u578b\u548c\u5206\u8fa8\u7387\u5728\u591a\u79cdCNN\u67b6\u6784\uff08VGG\u3001ResNet-152\u3001MobileNet\u3001DenseNet\u3001EfficientNet-B4\uff09\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u4f7f\u7528LLaMA-2\u63d0\u53d6\u548c\u6807\u6ce8\u6587\u672c\u7279\u5f81\uff0c\u901a\u8fc7CLIP\u6a21\u578b\u96c6\u6210\u56fe\u50cf\u548c\u6587\u672c\u6570\u636e\u3002", "result": "\u9ad8\u5206\u8fa8\u7387RGB\u56fe\u50cf\uff08\u5982256x256\u3001512x512\uff09\u5728\u5206\u7c7b\u6027\u80fd\u4e0a\u8868\u73b0\u6700\u4f73\uff1b\u4f46\u4f7f\u7528CLIP\u6a21\u578b\u8fdb\u884c\u56fe\u50cf\u548c\u6587\u672c\u591a\u6a21\u6001\u96c6\u6210\u663e\u793a\u51fa\u6709\u9650\u7684\u6f5c\u529b\u3002", "conclusion": "\u7cfb\u7edf\u8bc4\u4f30\u56fe\u50cf\u5c5e\u6027\u548c\u96c6\u6210\u591a\u6a21\u6001\u6570\u636e\u5bf9\u4e8e\u5f00\u53d1\u6709\u6548\u7684Android\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5f53\u524d\u56fe\u50cf-\u6587\u672c\u591a\u6a21\u6001\u96c6\u6210\u65b9\u6cd5\u6548\u679c\u6709\u9650\u3002"}}
{"id": "2601.08987", "categories": ["cs.CR", "cs.MM", "cs.NI", "eess.IV"], "pdf": "https://arxiv.org/pdf/2601.08987", "abs": "https://arxiv.org/abs/2601.08987", "authors": ["Mohammad Waquas Usmani", "Susmit Shannigrahi", "Michael Zink"], "title": "ABE-VVS: Attribute-Based Encrypted Volumetric Video Streaming", "comment": "10 pages + 1 references and 9 figures with some sub-figures", "summary": "This work introduces ABE-VVS, a framework that performs attribute based selective coordinate encryption for point cloud based volumetric video streaming, enabling lightweight yet effective digital rights management (DRM). Rather than encrypting entire point cloud frames, our approach encrypts only selected subsets of coordinates ($X, Y, Z$, or combinations), lowering computational overhead and latency while still producing strong visual distortion that prevents meaningful unauthorized viewing. Our experiments show that encrypting only the $X$ coordinates achieves effective obfuscation while reducing encryption and decryption times by up to 50% and 80%, respectively, compared to full-frame encryption.\n  To our knowledge, this is the first work to provide a novel end-to-end evaluation of a DRM-enabled secure point cloud streaming system. We deployed a point cloud video streaming setup on the CloudLab testbed and evaluated three HTTP-based Attribute-Based Encryption (ABE) granularities - ABE-XYZ (encrypting all $X,Y,Z$ coordinates), ABE-XY, and ABE-X against conventional HTTPS/TLS secure streaming as well as an HTTP-only baseline without any security. Our streaming evaluation demonstrates that ABE-based schemes reduce server-side CPU load by up to 80% and cache CPU load by up to 63%, comparable to HTTP-only, while maintaining similar cache hit rates. Moreover, ABE-XYZ and ABE-XY exhibit lower client-side rebuffering than HTTPS, and ABE-X achieves zero rebuffering comparable to HTTP-only. Although ABE-VVS increases client-side CPU usage, the overhead is not large enough to affect streaming quality and is offset by its broader benefits, including simplified key revocation, elimination of per-client encryption, and reduced server and cache load.", "AI": {"tldr": "ABE-VVS\u6846\u67b6\u901a\u8fc7\u57fa\u4e8e\u5c5e\u6027\u7684\u9009\u62e9\u6027\u5750\u6807\u52a0\u5bc6\u5b9e\u73b0\u70b9\u4e91\u4f53\u89c6\u9891\u6d41\u5a92\u4f53\u8f7b\u91cf\u7ea7DRM\uff0c\u4ec5\u52a0\u5bc6\u90e8\u5206\u5750\u6807\uff08X\u3001Y\u3001Z\u6216\u5176\u7ec4\u5408\uff09\u800c\u975e\u6574\u4e2a\u70b9\u4e91\u5e27\uff0c\u5728\u4fdd\u6301\u6709\u6548\u89c6\u89c9\u6df7\u6dc6\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u548c\u5ef6\u8fdf\u3002", "motivation": "\u4f20\u7edf\u70b9\u4e91\u89c6\u9891\u6d41\u5a92\u4f53DRM\u65b9\u6848\u901a\u5e38\u9700\u8981\u52a0\u5bc6\u6574\u4e2a\u70b9\u4e91\u5e27\uff0c\u5bfc\u81f4\u9ad8\u8ba1\u7b97\u5f00\u9500\u548c\u5ef6\u8fdf\u3002\u9700\u8981\u4e00\u79cd\u8f7b\u91cf\u7ea7\u4f46\u6709\u6548\u7684DRM\u65b9\u6848\uff0c\u65e2\u80fd\u4fdd\u62a4\u5185\u5bb9\u4e0d\u88ab\u672a\u6388\u6743\u89c2\u770b\uff0c\u53c8\u80fd\u964d\u4f4e\u7cfb\u7edf\u8d1f\u8f7d\u5e76\u4fdd\u6301\u6d41\u5a92\u4f53\u8d28\u91cf\u3002", "method": "\u63d0\u51faABE-VVS\u6846\u67b6\uff0c\u91c7\u7528\u57fa\u4e8e\u5c5e\u6027\u7684\u9009\u62e9\u6027\u5750\u6807\u52a0\u5bc6\u65b9\u6cd5\u3002\u5728CloudLab\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u90e8\u7f72\u70b9\u4e91\u89c6\u9891\u6d41\u5a92\u4f53\u7cfb\u7edf\uff0c\u8bc4\u4f30\u4e09\u79cdHTTP-based ABE\u7c92\u5ea6\uff1aABE-XYZ\uff08\u52a0\u5bc6\u6240\u6709XYZ\u5750\u6807\uff09\u3001ABE-XY\u548cABE-X\u3002\u4e0e\u4f20\u7edfHTTPS/TLS\u5b89\u5168\u6d41\u5a92\u4f53\u4ee5\u53ca\u65e0\u5b89\u5168\u63aa\u65bd\u7684HTTP\u57fa\u7ebf\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u4ec5\u52a0\u5bc6X\u5750\u6807\u5373\u53ef\u5b9e\u73b0\u6709\u6548\u6df7\u6dc6\uff0c\u540c\u65f6\u5c06\u52a0\u5bc6\u548c\u89e3\u5bc6\u65f6\u95f4\u5206\u522b\u964d\u4f4e50%\u548c80%\u3002ABE\u65b9\u6848\u5c06\u670d\u52a1\u5668\u7aefCPU\u8d1f\u8f7d\u964d\u4f4e\u9ad8\u8fbe80%\uff0c\u7f13\u5b58CPU\u8d1f\u8f7d\u964d\u4f4e\u9ad8\u8fbe63%\uff0c\u4e0e\u7eafHTTP\u76f8\u5f53\u3002ABE-XYZ\u548cABE-XY\u5ba2\u6237\u7aef\u91cd\u65b0\u7f13\u51b2\u4f4e\u4e8eHTTPS\uff0cABE-X\u5b9e\u73b0\u96f6\u91cd\u65b0\u7f13\u51b2\u3002\u867d\u7136\u5ba2\u6237\u7aefCPU\u4f7f\u7528\u589e\u52a0\uff0c\u4f46\u5f00\u9500\u4e0d\u5f71\u54cd\u6d41\u5a92\u4f53\u8d28\u91cf\u3002", "conclusion": "ABE-VVS\u662f\u9996\u4e2a\u63d0\u4f9b\u7aef\u5230\u7aef\u8bc4\u4f30\u7684DRM\u5b89\u5168\u70b9\u4e91\u6d41\u5a92\u4f53\u7cfb\u7edf\u3002\u9009\u62e9\u6027\u5750\u6807\u52a0\u5bc6\u5728\u4fdd\u6301\u6709\u6548DRM\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\uff0c\u7b80\u5316\u5bc6\u94a5\u64a4\u9500\uff0c\u6d88\u9664\u6bcf\u5ba2\u6237\u7aef\u52a0\u5bc6\u9700\u6c42\uff0c\u5e76\u51cf\u5c11\u670d\u52a1\u5668\u548c\u7f13\u5b58\u8d1f\u8f7d\uff0c\u4e3a\u70b9\u4e91\u4f53\u89c6\u9891\u6d41\u5a92\u4f53\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u9ad8\u6548\u7684DRM\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.08856", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.08856", "abs": "https://arxiv.org/abs/2601.08856", "authors": ["Deeksha Nandal", "Riccardo Revalor", "Soham Dan", "Debjit Pal"], "title": "LAUDE: LLM-Assisted Unit Test Generation and Debugging of Hardware DEsigns", "comment": "18 Pages, 21 Figures, Submitted to ARR Review", "summary": "Unit tests are critical in the hardware design lifecycle to ensure that component design modules are functionally correct and conform to the specification before they are integrated at the system level. Thus developing unit tests targeting various design features requires deep understanding of the design functionality and creativity. When one or more unit tests expose a design failure, the debugging engineer needs to diagnose, localize, and debug the failure to ensure design correctness, which is often a painstaking and intense process. In this work, we introduce LAUDE, a unified unit-test generation and debugging framework for hardware designs that cross-pollinates the semantic understanding of the design source code with the Chain-of-Thought (CoT) reasoning capabilities of foundational Large-Language Models (LLMs). LAUDE integrates prompt engineering and design execution information to enhance its unit test generation accuracy and code debuggability. We apply LAUDE with closed- and open-source LLMs to a large corpus of buggy hardware design codes derived from the VerilogEval dataset, where generated unit tests detected bugs in up to 100% and 93% of combinational and sequential designs and debugged up to 93% and 84% of combinational and sequential designs, respectively.", "AI": {"tldr": "LAUDE\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u786c\u4ef6\u8bbe\u8ba1\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u4e0e\u8c03\u8bd5\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u8bbe\u8ba1\u6e90\u4ee3\u7801\u8bed\u4e49\u7406\u89e3\u548c\u601d\u7ef4\u94fe\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86\u786c\u4ef6\u8bbe\u8ba1\u7684\u6d4b\u8bd5\u8986\u76d6\u7387\u548c\u8c03\u8bd5\u6548\u7387\u3002", "motivation": "\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u7684\u5355\u5143\u6d4b\u8bd5\u5bf9\u4e8e\u786e\u4fdd\u6a21\u5757\u529f\u80fd\u6b63\u786e\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u5de5\u7a0b\u5e08\u6df1\u5165\u7406\u89e3\u8bbe\u8ba1\u529f\u80fd\u5e76\u5177\u5907\u521b\u9020\u6027\u601d\u7ef4\uff0c\u4e14\u8c03\u8bd5\u8fc7\u7a0b\u8017\u65f6\u8d39\u529b\u3002\u9700\u8981\u4e00\u79cd\u81ea\u52a8\u5316\u65b9\u6cd5\u6765\u63d0\u9ad8\u6d4b\u8bd5\u751f\u6210\u548c\u8c03\u8bd5\u7684\u6548\u7387\u3002", "method": "LAUDE\u6846\u67b6\u7ed3\u5408\u4e86\u8bbe\u8ba1\u6e90\u4ee3\u7801\u7684\u8bed\u4e49\u7406\u89e3\u548c\u57fa\u7840\u5927\u8bed\u8a00\u6a21\u578b\u7684\u601d\u7ef4\u94fe\u63a8\u7406\u80fd\u529b\uff0c\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u548c\u8bbe\u8ba1\u6267\u884c\u4fe1\u606f\u7684\u96c6\u6210\uff0c\u589e\u5f3a\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u51c6\u786e\u6027\u548c\u4ee3\u7801\u53ef\u8c03\u8bd5\u6027\u3002", "result": "\u5728VerilogEval\u6570\u636e\u96c6\u4e2d\u7684buggy\u786c\u4ef6\u8bbe\u8ba1\u4ee3\u7801\u4e0a\u6d4b\u8bd5\uff0cLAUDE\u751f\u6210\u7684\u5355\u5143\u6d4b\u8bd5\u5728\u7ec4\u5408\u8bbe\u8ba1\u4e2d\u68c0\u6d4b\u5230\u9ad8\u8fbe100%\u7684bug\uff0c\u5728\u65f6\u5e8f\u8bbe\u8ba1\u4e2d\u68c0\u6d4b\u523093%\u7684bug\uff1b\u8c03\u8bd5\u6210\u529f\u7387\u5206\u522b\u4e3a93%\u548c84%\u3002", "conclusion": "LAUDE\u901a\u8fc7\u7edf\u4e00\u7684\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u548c\u8c03\u8bd5\u7684\u6311\u6218\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u786c\u4ef6\u9a8c\u8bc1\u7684\u81ea\u52a8\u5316\u6c34\u5e73\u548c\u6548\u7387\u3002"}}
{"id": "2601.08950", "categories": ["cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.08950", "abs": "https://arxiv.org/abs/2601.08950", "authors": ["Mayank Sharma", "Roy Pea", "Hari Subramonyam"], "title": "ConvoLearn: A Dataset of Constructivist Tutor-Student Dialogue", "comment": null, "summary": "In educational applications, LLMs exhibit several fundamental pedagogical limitations, such as their tendency to reveal solutions rather than support dialogic learning. We introduce ConvoLearn (https://huggingface.co/datasets/masharma/convolearn ), a dataset grounded in knowledge building theory that operationalizes six core pedagogical dimensions: cognitive engagement, formative assessment, accountability, cultural responsiveness, metacognition, and power dynamics. We construct a semi-synthetic dataset of 1250 tutor-student dialogues (20 turns each) in middle school Earth Science through controlled interactions between human teachers and a simulated student. Using QLoRA, we demonstrate that training on this dataset meaningfully shifts LLM behavior toward knowledge-building strategies. Human evaluation by 31 teachers shows our fine-tuned Mistral 7B (M = 4.10, SD = 1.03) significantly outperforms both its base version (M = 2.59, SD = 1.11) and Claude Sonnet 4.5 (M = 2.87, SD = 1.29) overall. This work establishes a potential framework to guide future development and evaluation of constructivist AI tutors.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9488\u5bf9\u6559\u80b2\u5e94\u7528\u4e2dLLM\u7684\u6559\u5b66\u5c40\u9650\u6027\uff0c\u5f00\u53d1\u4e86ConvoLearn\u6570\u636e\u96c6\u6765\u8bad\u7ec3AI\u5bfc\u5e08\uff0c\u4f7f\u5176\u66f4\u652f\u6301\u5bf9\u8bdd\u5f0f\u77e5\u8bc6\u5efa\u6784\u5b66\u4e60\u800c\u975e\u76f4\u63a5\u63d0\u4f9b\u7b54\u6848\u3002", "motivation": "\u5f53\u524d\u6559\u80b2\u5e94\u7528\u4e2d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u6839\u672c\u6027\u6559\u5b66\u5c40\u9650\u6027\uff0c\u503e\u5411\u4e8e\u76f4\u63a5\u63ed\u793a\u89e3\u51b3\u65b9\u6848\u800c\u975e\u652f\u6301\u5bf9\u8bdd\u5f0f\u5b66\u4e60\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u4fc3\u8fdb\u77e5\u8bc6\u5efa\u6784\u7684AI\u5bfc\u5e08\uff0c\u8fd9\u9700\u8981\u57fa\u4e8e\u6559\u80b2\u5b66\u7406\u8bba\u7684\u6570\u636e\u96c6\u6765\u8bad\u7ec3\u6a21\u578b\u3002", "method": "\u57fa\u4e8e\u77e5\u8bc6\u5efa\u6784\u7406\u8bba\u521b\u5efaConvoLearn\u6570\u636e\u96c6\uff0c\u5305\u542b\u516d\u4e2a\u6838\u5fc3\u6559\u5b66\u7ef4\u5ea6\u3002\u901a\u8fc7\u4eba\u7c7b\u6559\u5e08\u4e0e\u6a21\u62df\u5b66\u751f\u7684\u53d7\u63a7\u4ea4\u4e92\uff0c\u6784\u5efa\u4e861250\u4e2a\u4e2d\u5b66\u5730\u7403\u79d1\u5b66\u9886\u57df\u7684\u5e08\u751f\u5bf9\u8bdd\u3002\u4f7f\u7528QLoRA\u65b9\u6cd5\u5bf9Mistral 7B\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u5fae\u8c03\u540e\u7684Mistral 7B\u6a21\u578b\u5728\u6559\u5b66\u884c\u4e3a\u4e0a\u663e\u8457\u8f6c\u5411\u77e5\u8bc6\u5efa\u6784\u7b56\u7565\u300231\u540d\u6559\u5e08\u7684\u4eba\u5de5\u8bc4\u4f30\u663e\u793a\uff0c\u5fae\u8c03\u6a21\u578b\uff08M=4.10\uff09\u663e\u8457\u4f18\u4e8e\u57fa\u7840\u7248\u672c\uff08M=2.59\uff09\u548cClaude Sonnet 4.5\uff08M=2.87\uff09\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u672a\u6765\u5efa\u6784\u4e3b\u4e49AI\u5bfc\u5e08\u7684\u5f00\u53d1\u548c\u8bc4\u4f30\u5efa\u7acb\u4e86\u4e00\u4e2a\u6f5c\u5728\u6846\u67b6\uff0c\u8bc1\u660e\u4e86\u57fa\u4e8e\u6559\u80b2\u5b66\u7406\u8bba\u7684\u6570\u636e\u96c6\u80fd\u591f\u6709\u6548\u6539\u5584LLM\u7684\u6559\u5b66\u884c\u4e3a\u3002"}}
{"id": "2601.09056", "categories": ["cs.CR", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.09056", "abs": "https://arxiv.org/abs/2601.09056", "authors": ["Robert Dilworth"], "title": "StegoStylo: Squelching Stylometric Scrutiny through Steganographic Stitching", "comment": "16 pages, 6 figures, 1 table", "summary": "Stylometry--the identification of an author through analysis of a text's style (i.e., authorship attribution)--serves many constructive purposes: it supports copyright and plagiarism investigations, aids detection of harmful content, offers exploratory cues for certain medical conditions (e.g., early signs of dementia or depression), provides historical context for literary works, and helps uncover misinformation and disinformation. In contrast, when stylometry is employed as a tool for authorship verification--confirming whether a text truly originates from a claimed author--it can also be weaponized for malicious purposes. Techniques such as de-anonymization, re-identification, tracking, profiling, and downstream effects like censorship illustrate the privacy threats that stylometric analysis can enable. Building on these concerns, this paper further explores how adversarial stylometry combined with steganography can counteract stylometric analysis. We first present enhancements to our adversarial attack, $\\textit{TraceTarnish}$, providing stronger evidence of its capacity to confound stylometric systems and reduce their attribution and verification accuracy. Next, we examine how steganographic embedding can be fine-tuned to mask an author's stylistic fingerprint, quantifying the level of authorship obfuscation achievable as a function of the proportion of words altered with zero-width Unicode characters. Based on our findings, steganographic coverage of 33% or higher seemingly ensures authorship obfuscation. Finally, we reflect on the ways stylometry can be used to undermine privacy and argue for the necessity of defensive tools like $\\textit{TraceTarnish}$.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u6587\u672c\u98ce\u683c\u5206\u6790\uff08\u6587\u4f53\u5b66\uff09\u7684\u53cc\u91cd\u7528\u9014\uff1a\u4e00\u65b9\u9762\u53ef\u7528\u4e8e\u4f5c\u8005\u8bc6\u522b\u3001\u7248\u6743\u4fdd\u62a4\u7b49\u6709\u76ca\u76ee\u7684\uff0c\u53e6\u4e00\u65b9\u9762\u4e5f\u53ef\u7528\u4e8e\u53bb\u533f\u540d\u5316\u3001\u8ffd\u8e2a\u7b49\u9690\u79c1\u5a01\u80c1\u3002\u7814\u7a76\u63d0\u51fa\u901a\u8fc7\u5bf9\u6297\u6027\u6587\u4f53\u5b66\u548c\u9690\u5199\u672f\u6765\u5bf9\u6297\u6587\u4f53\u5206\u6790\uff0c\u4fdd\u62a4\u4f5c\u8005\u9690\u79c1\u3002", "motivation": "\u6587\u4f53\u5b66\u4f5c\u4e3a\u4f5c\u8005\u8bc6\u522b\u5de5\u5177\u65e2\u6709\u5efa\u8bbe\u6027\u7528\u9014\uff08\u5982\u7248\u6743\u4fdd\u62a4\u3001\u6709\u5bb3\u5185\u5bb9\u68c0\u6d4b\u3001\u533b\u7597\u8bca\u65ad\u8f85\u52a9\uff09\uff0c\u4e5f\u53ef\u80fd\u88ab\u6076\u610f\u7528\u4e8e\u53bb\u533f\u540d\u5316\u3001\u8ffd\u8e2a\u3001\u5ba1\u67e5\u7b49\u9690\u79c1\u4fb5\u72af\u884c\u4e3a\u3002\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u9632\u5fa1\u6027\u5de5\u5177\u6765\u4fdd\u62a4\u4f5c\u8005\u7684\u9690\u79c1\u548c\u533f\u540d\u6027\u3002", "method": "1. \u589e\u5f3a\u5bf9\u6297\u6027\u653b\u51fb\u65b9\u6cd5TraceTarnish\uff0c\u8bc1\u660e\u5176\u80fd\u6709\u6548\u6df7\u6dc6\u6587\u4f53\u5206\u6790\u7cfb\u7edf\uff1b2. \u7814\u7a76\u9690\u5199\u672f\u5d4c\u5165\u6280\u672f\uff0c\u901a\u8fc7\u96f6\u5bbd\u5ea6Unicode\u5b57\u7b26\u4fee\u6539\u6587\u672c\uff0c\u91cf\u5316\u4e0d\u540c\u4fee\u6539\u6bd4\u4f8b\u4e0b\u7684\u4f5c\u8005\u6df7\u6dc6\u6548\u679c\u3002", "result": "1. TraceTarnish\u80fd\u663e\u8457\u964d\u4f4e\u6587\u4f53\u5206\u6790\u7cfb\u7edf\u7684\u4f5c\u8005\u5f52\u5c5e\u548c\u9a8c\u8bc1\u51c6\u786e\u7387\uff1b2. \u5f53\u9690\u5199\u672f\u8986\u76d6\u7387\u8fbe\u523033%\u6216\u66f4\u9ad8\u65f6\uff0c\u80fd\u6709\u6548\u5b9e\u73b0\u4f5c\u8005\u6df7\u6dc6\uff0c\u9690\u85cf\u4f5c\u8005\u7684\u6587\u4f53\u6307\u7eb9\u3002", "conclusion": "\u6587\u4f53\u5b66\u53ef\u80fd\u88ab\u7528\u4e8e\u4fb5\u72af\u9690\u79c1\uff0c\u56e0\u6b64\u9700\u8981\u50cfTraceTarnish\u8fd9\u6837\u7684\u9632\u5fa1\u5de5\u5177\u3002\u901a\u8fc7\u5bf9\u6297\u6027\u6587\u4f53\u5b66\u548c\u9690\u5199\u672f\u6280\u672f\uff0c\u53ef\u4ee5\u6709\u6548\u4fdd\u62a4\u4f5c\u8005\u7684\u533f\u540d\u6027\uff0c\u7279\u522b\u662f\u5f53\u9690\u5199\u672f\u8986\u76d6\u7387\u8fbe\u523033%\u4ee5\u4e0a\u65f6\u80fd\u786e\u4fdd\u4f5c\u8005\u6df7\u6dc6\u3002"}}
{"id": "2601.08857", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.08857", "abs": "https://arxiv.org/abs/2601.08857", "authors": ["Mustafa Degerli"], "title": "Revisiting Software Engineering Education in the Era of Large Language Models: A Curriculum Adaptation and Academic Integrity Framework", "comment": null, "summary": "The integration of Large Language Models (LLMs), such as ChatGPT and GitHub Copilot, into professional workflows is increasingly reshaping software engineering practices. These tools have lowered the cost of code generation, explanation, and testing, while introducing new forms of automation into routine development tasks. In contrast, most of the software engineering and computer engineering curricula remain closely aligned with pedagogical models that equate manual syntax production with technical competence. This growing misalignment raises concerns regarding assessment validity, learning outcomes, and the development of foundational skills. Adopting a conceptual research approach, this paper proposes a theoretical framework for analyzing how generative AI alters core software engineering competencies and introduces a pedagogical design model for LLM-integrated education. Attention is given to computer engineering programs in Turkey, where centralized regulation, large class sizes, and exam-oriented assessment practices amplify these challenges. The framework delineates how problem analysis, design, implementation, and testing increasingly shift from construction toward critique, validation, and human-AI stewardship. In addition, the paper argues that traditional plagiarism-centric integrity mechanisms are becoming insufficient, motivating a transition toward a process transparency model. While this work provides a structured proposal for curriculum adaptation, it remains a theoretical contribution; the paper concludes by outlining the need for longitudinal empirical studies to evaluate these interventions and their long-term impacts on learning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u7406\u8bba\u6846\u67b6\u5206\u6790\u751f\u6210\u5f0fAI\u5982\u4f55\u6539\u53d8\u8f6f\u4ef6\u5de5\u7a0b\u6838\u5fc3\u80fd\u529b\uff0c\u5e76\u8bbe\u8ba1LLM\u96c6\u6210\u6559\u80b2\u6a21\u578b\uff0c\u7279\u522b\u5173\u6ce8\u571f\u8033\u5176\u8ba1\u7b97\u673a\u5de5\u7a0b\u6559\u80b2\u9762\u4e34\u7684\u6311\u6218\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982ChatGPT\u3001GitHub Copilot\uff09\u6b63\u5728\u91cd\u5851\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\uff0c\u964d\u4f4e\u4e86\u4ee3\u7801\u751f\u6210\u3001\u89e3\u91ca\u548c\u6d4b\u8bd5\u7684\u6210\u672c\uff0c\u4f46\u5f53\u524d\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u4ecd\u4ee5\u624b\u52a8\u8bed\u6cd5\u751f\u4ea7\u4e3a\u6838\u5fc3\uff0c\u5bfc\u81f4\u8bc4\u4f30\u6709\u6548\u6027\u3001\u5b66\u4e60\u6210\u679c\u548c\u57fa\u7840\u6280\u80fd\u53d1\u5c55\u65b9\u9762\u5b58\u5728\u65e5\u76ca\u4e25\u91cd\u7684\u9519\u4f4d\u3002", "method": "\u91c7\u7528\u6982\u5ff5\u7814\u7a76\u65b9\u6cd5\uff0c\u63d0\u51fa\u7406\u8bba\u6846\u67b6\u5206\u6790\u751f\u6210\u5f0fAI\u5982\u4f55\u6539\u53d8\u8f6f\u4ef6\u5de5\u7a0b\u6838\u5fc3\u80fd\u529b\uff0c\u5e76\u8bbe\u8ba1LLM\u96c6\u6210\u6559\u80b2\u6a21\u578b\uff0c\u7279\u522b\u5173\u6ce8\u571f\u8033\u5176\u8ba1\u7b97\u673a\u5de5\u7a0b\u6559\u80b2\u4e2d\u96c6\u4e2d\u76d1\u7ba1\u3001\u5927\u73ed\u6559\u5b66\u548c\u8003\u8bd5\u5bfc\u5411\u8bc4\u4f30\u7b49\u6311\u6218\u3002", "result": "\u6846\u67b6\u663e\u793a\u95ee\u9898\u5206\u6790\u3001\u8bbe\u8ba1\u3001\u5b9e\u73b0\u548c\u6d4b\u8bd5\u6b63\u4ece\u6784\u5efa\u8f6c\u5411\u6279\u5224\u3001\u9a8c\u8bc1\u548c\u4eba\u673a\u534f\u540c\u7ba1\u7406\uff1b\u4f20\u7edf\u6284\u88ad\u68c0\u6d4b\u673a\u5236\u5df2\u4e0d\u8db3\uff0c\u9700\u8981\u5411\u8fc7\u7a0b\u900f\u660e\u5ea6\u6a21\u578b\u8fc7\u6e21\u3002", "conclusion": "\u672c\u6587\u4e3a\u8bfe\u7a0b\u9002\u5e94\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u5efa\u8bae\uff0c\u4f46\u4ecd\u5c5e\u7406\u8bba\u8d21\u732e\uff0c\u9700\u8981\u7eb5\u5411\u5b9e\u8bc1\u7814\u7a76\u6765\u8bc4\u4f30\u8fd9\u4e9b\u5e72\u9884\u63aa\u65bd\u53ca\u5176\u5bf9\u5b66\u4e60\u7684\u957f\u671f\u5f71\u54cd\u3002"}}
{"id": "2601.09082", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.09082", "abs": "https://arxiv.org/abs/2601.09082", "authors": ["Christopher Blake", "Chen Feng", "Xuechao Wang", "Qianyu Yu"], "title": "Rigorous and Generalized Proof of Security of Bitcoin Protocol with Bounded Network Delay", "comment": null, "summary": "A proof of the security of the Bitcoin protocol is made rigorous, and simplified in certain parts. A computational model in which an adversary can delay transmission of blocks by time $\u0394$ is considered. The protocol is generalized to allow blocks of different scores and a proof within this more general model is presented. An approach used in a previous paper that used random walk theory is shown through a counterexample to be incorrect; an approach involving a punctured block arrival process is shown to remedy this error. Thus, it is proven that with probability one, the Bitcoin protocol will have infinitely many honest blocks so long as the fully-delayed honest mining rate exceeds the adversary mining rate.", "AI": {"tldr": "\u672c\u6587\u5bf9\u6bd4\u7279\u5e01\u534f\u8bae\u7684\u5b89\u5168\u6027\u8bc1\u660e\u8fdb\u884c\u4e86\u4e25\u8c28\u5316\u548c\u7b80\u5316\uff0c\u8003\u8651\u4e86\u5bf9\u624b\u53ef\u4ee5\u5ef6\u8fdf\u533a\u5757\u4f20\u8f93\u7684\u8ba1\u7b97\u6a21\u578b\uff0c\u5e76\u8bc1\u660e\u4e86\u53ea\u8981\u5b8c\u5168\u5ef6\u8fdf\u540e\u7684\u8bda\u5b9e\u6316\u77ff\u7387\u8d85\u8fc7\u5bf9\u624b\u6316\u77ff\u7387\uff0c\u6bd4\u7279\u5e01\u534f\u8bae\u5c31\u4f1a\u4ee5\u6982\u73871\u4ea7\u751f\u65e0\u9650\u591a\u4e2a\u8bda\u5b9e\u533a\u5757\u3002", "motivation": "\u6bd4\u7279\u5e01\u534f\u8bae\u7684\u5b89\u5168\u6027\u8bc1\u660e\u9700\u8981\u66f4\u52a0\u4e25\u8c28\u548c\u7b80\u5316\uff0c\u7279\u522b\u662f\u8981\u7ea0\u6b63\u5148\u524d\u8bba\u6587\u4e2d\u57fa\u4e8e\u968f\u673a\u6e38\u8d70\u7406\u8bba\u7684\u9519\u8bef\u65b9\u6cd5\uff0c\u5e76\u5728\u66f4\u4e00\u822c\u7684\u6a21\u578b\u4e0b\u63d0\u4f9b\u6b63\u786e\u7684\u8bc1\u660e\u3002", "method": "1. \u5efa\u7acb\u8ba1\u7b97\u6a21\u578b\uff0c\u5141\u8bb8\u5bf9\u624b\u5ef6\u8fdf\u533a\u5757\u4f20\u8f93\u65f6\u95f4\u0394\uff1b2. \u5c06\u534f\u8bae\u63a8\u5e7f\u5230\u5141\u8bb8\u4e0d\u540c\u5206\u6570\u7684\u533a\u5757\uff1b3. \u4f7f\u7528\u7a7f\u5b54\u533a\u5757\u5230\u8fbe\u8fc7\u7a0b\u7684\u65b9\u6cd5\u6765\u7ea0\u6b63\u5148\u524d\u968f\u673a\u6e38\u8d70\u7406\u8bba\u7684\u9519\u8bef\uff1b4. \u5728\u66f4\u4e00\u822c\u7684\u6a21\u578b\u4e0b\u8fdb\u884c\u8bc1\u660e\u3002", "result": "\u8bc1\u660e\u4e86\u53ea\u8981\u5b8c\u5168\u5ef6\u8fdf\u540e\u7684\u8bda\u5b9e\u6316\u77ff\u7387\u8d85\u8fc7\u5bf9\u624b\u6316\u77ff\u7387\uff0c\u6bd4\u7279\u5e01\u534f\u8bae\u5c31\u4f1a\u4ee5\u6982\u73871\u4ea7\u751f\u65e0\u9650\u591a\u4e2a\u8bda\u5b9e\u533a\u5757\uff0c\u4ece\u800c\u786e\u4fdd\u4e86\u534f\u8bae\u7684\u5b89\u5168\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u4f9b\u4e86\u6bd4\u7279\u5e01\u534f\u8bae\u5b89\u5168\u6027\u7684\u4e25\u8c28\u8bc1\u660e\uff0c\u7ea0\u6b63\u4e86\u5148\u524d\u7814\u7a76\u4e2d\u7684\u9519\u8bef\uff0c\u5e76\u5728\u66f4\u4e00\u822c\u7684\u6a21\u578b\u4e0b\u5efa\u7acb\u4e86\u534f\u8bae\u5b89\u5168\u6027\u7684\u5145\u5206\u6761\u4ef6\uff0c\u4e3a\u6bd4\u7279\u5e01\u534f\u8bae\u7684\u7406\u8bba\u57fa\u7840\u63d0\u4f9b\u4e86\u91cd\u8981\u652f\u6491\u3002"}}
{"id": "2601.08858", "categories": ["cs.SE", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.08858", "abs": "https://arxiv.org/abs/2601.08858", "authors": ["Tejaswini Bollikonda"], "title": "Adaptive Trust Metrics for Multi-LLM Systems: Enhancing Reliability in Regulated Industries", "comment": "8 pages, 8 figures", "summary": "Large Language Models (LLMs) are increasingly deployed in sensitive domains such as healthcare, finance, and law, yet their integration raises pressing concerns around trust, accountability, and reliability. This paper explores adaptive trust metrics for multi LLM ecosystems, proposing a framework for quantifying and improving model reliability under regulated constraints. By analyzing system behaviors, evaluating uncertainty across multiple LLMs, and implementing dynamic monitoring pipelines, the study demonstrates practical pathways for operational trustworthiness. Case studies from financial compliance and healthcare diagnostics illustrate the applicability of adaptive trust metrics in real world settings. The findings position adaptive trust measurement as a foundational enabler for safe and scalable AI adoption in regulated industries.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u591aLLM\u751f\u6001\u7cfb\u7edf\u7684\u81ea\u9002\u5e94\u4fe1\u4efb\u5ea6\u91cf\u6846\u67b6\uff0c\u65e8\u5728\u91cf\u5316\u5e76\u63d0\u5347\u5728\u76d1\u7ba1\u7ea6\u675f\u4e0b\u7684\u6a21\u578b\u53ef\u9760\u6027\uff0c\u901a\u8fc7\u7cfb\u7edf\u884c\u4e3a\u5206\u6790\u3001\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u548c\u52a8\u6001\u76d1\u63a7\u7ba1\u9053\u6765\u5b9e\u73b0\u64cd\u4f5c\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u3001\u91d1\u878d\u3001\u6cd5\u5f8b\u7b49\u654f\u611f\u9886\u57df\u7684\u90e8\u7f72\u65e5\u76ca\u589e\u591a\uff0c\u56f4\u7ed5\u4fe1\u4efb\u3001\u95ee\u8d23\u548c\u53ef\u9760\u6027\u7684\u95ee\u9898\u53d8\u5f97\u65e5\u76ca\u7d27\u8feb\u3002\u9700\u8981\u5efa\u7acb\u80fd\u591f\u9002\u5e94\u76d1\u7ba1\u7ea6\u675f\u7684\u4fe1\u4efb\u5ea6\u91cf\u673a\u5236\u6765\u786e\u4fddAI\u7cfb\u7edf\u7684\u5b89\u5168\u91c7\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u81ea\u9002\u5e94\u4fe1\u4efb\u5ea6\u91cf\u6846\u67b6\uff0c\u5305\u62ec\uff1a1\uff09\u5206\u6790\u7cfb\u7edf\u884c\u4e3a\uff1b2\uff09\u8bc4\u4f30\u591a\u4e2aLLM\u4e4b\u95f4\u7684\u4e0d\u786e\u5b9a\u6027\uff1b3\uff09\u5b9e\u65bd\u52a8\u6001\u76d1\u63a7\u7ba1\u9053\u3002\u901a\u8fc7\u91d1\u878d\u5408\u89c4\u548c\u533b\u7597\u8bca\u65ad\u7684\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u6846\u67b6\u7684\u5b9e\u7528\u6027\u3002", "result": "\u7814\u7a76\u5c55\u793a\u4e86\u81ea\u9002\u5e94\u4fe1\u4efb\u5ea6\u91cf\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u9002\u7528\u6027\uff0c\u7279\u522b\u662f\u5728\u91d1\u878d\u5408\u89c4\u548c\u533b\u7597\u8bca\u65ad\u9886\u57df\u3002\u8be5\u6846\u67b6\u4e3a\u5728\u76d1\u7ba1\u884c\u4e1a\u4e2d\u5b9e\u73b0\u5b89\u5168\u548c\u53ef\u6269\u5c55\u7684AI\u91c7\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u8def\u5f84\u3002", "conclusion": "\u81ea\u9002\u5e94\u4fe1\u4efb\u5ea6\u91cf\u662f\u76d1\u7ba1\u884c\u4e1a\u4e2d\u5b9e\u73b0\u5b89\u5168\u3001\u53ef\u6269\u5c55AI\u91c7\u7528\u7684\u57fa\u7840\u6027\u63a8\u52a8\u56e0\u7d20\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u591aLLM\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u4fe1\u4efb\u3001\u95ee\u8d23\u548c\u53ef\u9760\u6027\u95ee\u9898\u3002"}}
{"id": "2601.09032", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09032", "abs": "https://arxiv.org/abs/2601.09032", "authors": ["Logan Ritchie", "Sushant Mehta", "Nick Heiner", "Mason Yu", "Edwin Chen"], "title": "The Hierarchy of Agentic Capabilities: Evaluating Frontier Models on Realistic RL Environments", "comment": null, "summary": "The advancement of large language model (LLM) based agents has shifted AI evaluation from single-turn response assessment to multi-step task completion in interactive environments. We present an empirical study evaluating frontier AI models on 150 workplace tasks within a realistic e-commerce RL environment from Surge. Our analysis reveals an empirically-derived \\emph{hierarchy of agentic capabilities} that models must master for real-world deployment: (1) tool use, (2) planning and goal formation, (3) adaptability, (4) groundedness, and (5) common-sense reasoning. Even the best-performing models fail approximately 40\\% of the tasks, with failures clustering predictably along this hierarchy. Weaker models struggle with fundamental tool use and planning, whereas stronger models primarily fail on tasks requiring contextual inference beyond explicit instructions. We introduce a task-centric design methodology for RL environments that emphasizes diversity and domain expert contributions, provide detailed failure analysis, and discuss implications for agent development. Our findings suggest that while current frontier models can demonstrate coherent multi-step behavior, substantial capability gaps remain before achieving human-level task completion in realistic workplace settings.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7535\u5546\u73af\u5883\u4e2d\u7684150\u4e2a\u804c\u573a\u4efb\u52a1\u8868\u73b0\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u9700\u8981\u638c\u63e1\u7684\u4e94\u4e2a\u5c42\u6b21\u80fd\u529b\uff0c\u5373\u4f7f\u6700\u4f73\u6a21\u578b\u4ecd\u670940%\u4efb\u52a1\u5931\u8d25\u7387\u3002", "motivation": "\u968f\u7740\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u53d1\u5c55\uff0cAI\u8bc4\u4f30\u9700\u8981\u4ece\u5355\u8f6e\u54cd\u5e94\u8bc4\u4f30\u8f6c\u5411\u4ea4\u4e92\u73af\u5883\u4e2d\u7684\u591a\u6b65\u9aa4\u4efb\u52a1\u5b8c\u6210\u8bc4\u4f30\u3002\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u524d\u6cbfAI\u6a21\u578b\u5728\u771f\u5b9e\u7535\u5546\u5de5\u4f5c\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u8868\u73b0\uff0c\u8bc6\u522b\u6a21\u578b\u5728\u73b0\u5b9e\u90e8\u7f72\u4e2d\u7684\u80fd\u529b\u5dee\u8ddd\u3002", "method": "\u91c7\u7528\u5b9e\u8bc1\u7814\u7a76\u65b9\u6cd5\uff0c\u5728Surge\u63d0\u4f9b\u7684\u771f\u5b9e\u7535\u5546\u5f3a\u5316\u5b66\u4e60\u73af\u5883\u4e2d\u8bc4\u4f30\u524d\u6cbfAI\u6a21\u578b\u5728150\u4e2a\u804c\u573a\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002\u5f15\u5165\u4efb\u52a1\u4e2d\u5fc3\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u5f3a\u8c03\u4efb\u52a1\u591a\u6837\u6027\u548c\u9886\u57df\u4e13\u5bb6\u8d21\u732e\uff0c\u5e76\u8fdb\u884c\u8be6\u7ec6\u7684\u5931\u8d25\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e86\u4e00\u4e2a\u7ecf\u9a8c\u63a8\u5bfc\u7684\"\u667a\u80fd\u4f53\u80fd\u529b\u5c42\u6b21\u7ed3\u6784\"\uff1a\u5de5\u5177\u4f7f\u7528\u3001\u89c4\u5212\u4e0e\u76ee\u6807\u5f62\u6210\u3001\u9002\u5e94\u6027\u3001\u63a5\u5730\u6027\u3001\u5e38\u8bc6\u63a8\u7406\u3002\u5373\u4f7f\u8868\u73b0\u6700\u4f73\u7684\u6a21\u578b\u4ecd\u6709\u7ea640%\u7684\u4efb\u52a1\u5931\u8d25\u7387\uff0c\u5931\u8d25\u6a21\u5f0f\u6cbf\u80fd\u529b\u5c42\u6b21\u53ef\u9884\u6d4b\u5206\u5e03\uff1a\u8f83\u5f31\u6a21\u578b\u5728\u57fa\u7840\u5de5\u5177\u4f7f\u7528\u548c\u89c4\u5212\u4e0a\u6323\u624e\uff0c\u8f83\u5f3a\u6a21\u578b\u4e3b\u8981\u5728\u9700\u8981\u8d85\u8d8a\u660e\u786e\u6307\u4ee4\u7684\u4e0a\u4e0b\u6587\u63a8\u7406\u4efb\u52a1\u4e0a\u5931\u8d25\u3002", "conclusion": "\u5f53\u524d\u524d\u6cbf\u6a21\u578b\u867d\u7136\u80fd\u5c55\u793a\u8fde\u8d2f\u7684\u591a\u6b65\u9aa4\u884c\u4e3a\uff0c\u4f46\u5728\u5b9e\u73b0\u771f\u5b9e\u804c\u573a\u73af\u5883\u4e2d\u4eba\u7c7b\u6c34\u5e73\u4efb\u52a1\u5b8c\u6210\u65b9\u9762\u4ecd\u5b58\u5728\u663e\u8457\u80fd\u529b\u5dee\u8ddd\u3002\u7814\u7a76\u4e3a\u667a\u80fd\u4f53\u5f00\u53d1\u63d0\u4f9b\u4e86\u91cd\u8981\u542f\u793a\uff0c\u5f3a\u8c03\u4e86\u9700\u8981\u9488\u5bf9\u4e0d\u540c\u80fd\u529b\u5c42\u6b21\u8fdb\u884c\u9488\u5bf9\u6027\u6539\u8fdb\u3002"}}
{"id": "2601.08859", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.08859", "abs": "https://arxiv.org/abs/2601.08859", "authors": ["Bruno M. Saraiva", "Iv\u00e1n Hidalgo-Cenalmor", "Ant\u00f3nio D. Brito", "Dami\u00e1n Mart\u00ednez", "Tayla Shakespeare", "Guillaume Jacquemet", "Ricardo Henriques"], "title": "EZInput: A Cross-Environment Python Library for Easy UI Generation in Scientific Computing", "comment": null, "summary": "Researchers face a persistent barrier when applying computational algorithms with parameter configuration typically demanding programming skills, interfaces differing across environments, and settings rarely persisting between sessions. This fragmentation forces repetitive input, slows iterative exploration, and undermines reproducibility because parameter choices are difficult to record, share, and reuse. We present EZInput, a cross-runtime environment Python library enabling algorithm developers to automatically generate graphical user interfaces that make their computational tools accessible to end-users without programming expertise. EZInput employs a declarative specification system where developers define input requirements and validation constraints once; the library then handles environment detection, interface rendering, parameter validation, and session persistence across Jupyter notebooks, Google Colab, and terminal environments. This \"write once, run anywhere\" architecture enables researchers to prototype in notebooks and deploy identical parameter configurations for batch execution on remote systems without code changes or manual transcription. Parameter persistence, inspired by ImageJ/FIJI and adapted to Python workflows, saves and restores user configurations via lightweight YAML files, eliminating redundant input and producing shareable records that enhance reproducibility. EZInput supports diverse input types essential for scientific computing and it also includes built-in validation that ensures data integrity and clear feedback that reduces user friction.", "AI": {"tldr": "EZInput\u662f\u4e00\u4e2a\u8de8\u8fd0\u884c\u65f6\u73af\u5883\u7684Python\u5e93\uff0c\u5141\u8bb8\u7b97\u6cd5\u5f00\u53d1\u8005\u81ea\u52a8\u751f\u6210\u56fe\u5f62\u7528\u6237\u754c\u9762\uff0c\u4f7f\u975e\u7f16\u7a0b\u4e13\u5bb6\u4e5f\u80fd\u4f7f\u7528\u8ba1\u7b97\u5de5\u5177\uff0c\u89e3\u51b3\u53c2\u6570\u914d\u7f6e\u788e\u7247\u5316\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u4eba\u5458\u5728\u5e94\u7528\u8ba1\u7b97\u7b97\u6cd5\u65f6\u9762\u4e34\u53c2\u6570\u914d\u7f6e\u7684\u6301\u7eed\u969c\u788d\uff1a\u9700\u8981\u7f16\u7a0b\u6280\u80fd\u3001\u4e0d\u540c\u73af\u5883\u7684\u63a5\u53e3\u5dee\u5f02\u3001\u4f1a\u8bdd\u95f4\u8bbe\u7f6e\u96be\u4ee5\u6301\u4e45\u4fdd\u5b58\u3002\u8fd9\u79cd\u788e\u7247\u5316\u5bfc\u81f4\u91cd\u590d\u8f93\u5165\u3001\u8fed\u4ee3\u63a2\u7d22\u7f13\u6162\uff0c\u4e14\u7531\u4e8e\u53c2\u6570\u9009\u62e9\u96be\u4ee5\u8bb0\u5f55\u3001\u5171\u4eab\u548c\u91cd\u7528\uff0c\u7834\u574f\u4e86\u7814\u7a76\u7684\u53ef\u91cd\u590d\u6027\u3002", "method": "EZInput\u91c7\u7528\u58f0\u660e\u5f0f\u89c4\u8303\u7cfb\u7edf\uff0c\u5f00\u53d1\u8005\u53ea\u9700\u5b9a\u4e49\u4e00\u6b21\u8f93\u5165\u9700\u6c42\u548c\u9a8c\u8bc1\u7ea6\u675f\uff1b\u5e93\u81ea\u52a8\u5904\u7406\u73af\u5883\u68c0\u6d4b\u3001\u754c\u9762\u6e32\u67d3\u3001\u53c2\u6570\u9a8c\u8bc1\u548c\u4f1a\u8bdd\u6301\u4e45\u5316\uff0c\u652f\u6301Jupyter notebooks\u3001Google Colab\u548c\u7ec8\u7aef\u73af\u5883\u3002\u53c2\u6570\u6301\u4e45\u5316\u673a\u5236\u901a\u8fc7\u8f7b\u91cf\u7ea7YAML\u6587\u4ef6\u4fdd\u5b58\u548c\u6062\u590d\u7528\u6237\u914d\u7f6e\u3002", "result": "\u5b9e\u73b0\u4e86\"\u4e00\u6b21\u7f16\u5199\uff0c\u968f\u5904\u8fd0\u884c\"\u7684\u67b6\u6784\uff0c\u4f7f\u7814\u7a76\u4eba\u5458\u80fd\u5728notebook\u4e2d\u539f\u578b\u8bbe\u8ba1\uff0c\u5e76\u5728\u8fdc\u7a0b\u7cfb\u7edf\u4e0a\u90e8\u7f72\u5b8c\u5168\u76f8\u540c\u7684\u53c2\u6570\u914d\u7f6e\u8fdb\u884c\u6279\u91cf\u6267\u884c\uff0c\u65e0\u9700\u4ee3\u7801\u66f4\u6539\u6216\u624b\u52a8\u8f6c\u5f55\u3002\u5185\u7f6e\u9a8c\u8bc1\u786e\u4fdd\u6570\u636e\u5b8c\u6574\u6027\uff0c\u6e05\u6670\u7684\u53cd\u9988\u51cf\u5c11\u7528\u6237\u6469\u64e6\u3002", "conclusion": "EZInput\u901a\u8fc7\u81ea\u52a8\u751f\u6210GUI\u3001\u8de8\u73af\u5883\u517c\u5bb9\u6027\u548c\u53c2\u6570\u6301\u4e45\u5316\uff0c\u89e3\u51b3\u4e86\u8ba1\u7b97\u5de5\u5177\u53c2\u6570\u914d\u7f6e\u7684\u788e\u7247\u5316\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u53ef\u8bbf\u95ee\u6027\u3001\u6548\u7387\u548c\u53ef\u91cd\u590d\u6027\uff0c\u7279\u522b\u9002\u5408\u79d1\u5b66\u8ba1\u7b97\u5de5\u4f5c\u6d41\u7a0b\u3002"}}
{"id": "2601.09129", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.09129", "abs": "https://arxiv.org/abs/2601.09129", "authors": ["Xiaonan Liu", "Zhihao Li", "Xiao Lan", "Hao Ren", "Haizhou Wang", "Xingshu Chen"], "title": "KryptoPilot: An Open-World Knowledge-Augmented LLM Agent for Automated Cryptographic Exploitation", "comment": "14 Pages,4 figures", "summary": "Capture-the-Flag (CTF) competitions play a central role in modern cybersecurity as a platform for training practitioners and evaluating offensive and defensive techniques derived from real-world vulnerabilities. Despite recent advances in large language models (LLMs), existing LLM-based agents remain ineffective on high-difficulty cryptographic CTF challenges, which require precise cryptanalytic knowledge, stable long-horizon reasoning, and disciplined interaction with specialized toolchains. Through a systematic exploratory study, we show that insufficient knowledge granularity, rather than model reasoning capacity, is a primary factor limiting successful cryptographic exploitation: coarse or abstracted external knowledge often fails to support correct attack modeling and implementation. Motivated by this observation, we propose KryptoPilot, an open-world knowledge-augmented LLM agent for automated cryptographic exploitation. KryptoPilot integrates dynamic open-world knowledge acquisition via a Deep Research pipeline, a persistent workspace for structured knowledge reuse, and a governance subsystem that stabilizes reasoning through behavioral constraints and cost-aware model routing. This design enables precise knowledge alignment while maintaining efficient reasoning across heterogeneous subtasks. We evaluate KryptoPilot on two established CTF benchmarks and in six real-world CTF competitions. KryptoPilot achieves a complete solve rate on InterCode-CTF, solves between 56 and 60 percent of cryptographic challenges on the NYU-CTF benchmark, and successfully solves 26 out of 33 cryptographic challenges in live competitions, including multiple earliest-solved and uniquely-solved instances. These results demonstrate the necessity of open-world, fine-grained knowledge augmentation and governed reasoning for scaling LLM-based agents to real-world cryptographic exploitation.", "AI": {"tldr": "KryptoPilot\u662f\u4e00\u4e2a\u9762\u5411\u52a0\u5bc6CTF\u6311\u6218\u7684\u5f00\u653e\u4e16\u754c\u77e5\u8bc6\u589e\u5f3aLLM\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u52a8\u6001\u77e5\u8bc6\u83b7\u53d6\u548c\u6cbb\u7406\u63a8\u7406\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5728\u590d\u6742\u52a0\u5bc6\u653b\u51fb\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u5728\u5904\u7406\u9ad8\u96be\u5ea6\u52a0\u5bc6CTF\u6311\u6218\u65f6\u6548\u679c\u4e0d\u4f73\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u77e5\u8bc6\u7c92\u5ea6\u4e0d\u8db3\uff0c\u800c\u975e\u6a21\u578b\u63a8\u7406\u80fd\u529b\u95ee\u9898\u3002\u7c97\u7c92\u5ea6\u6216\u62bd\u8c61\u7684\u5916\u90e8\u77e5\u8bc6\u65e0\u6cd5\u652f\u6301\u6b63\u786e\u7684\u653b\u51fb\u5efa\u6a21\u548c\u5b9e\u65bd\u3002", "method": "\u63d0\u51faKryptoPilot\u7cfb\u7edf\uff0c\u5305\u542b\uff1a1) \u901a\u8fc7\u6df1\u5ea6\u7814\u7a76\u7ba1\u9053\u5b9e\u73b0\u52a8\u6001\u5f00\u653e\u4e16\u754c\u77e5\u8bc6\u83b7\u53d6\uff1b2) \u7528\u4e8e\u7ed3\u6784\u5316\u77e5\u8bc6\u91cd\u7528\u7684\u6301\u4e45\u5de5\u4f5c\u7a7a\u95f4\uff1b3) \u901a\u8fc7\u884c\u4e3a\u7ea6\u675f\u548c\u6210\u672c\u611f\u77e5\u6a21\u578b\u8def\u7531\u7a33\u5b9a\u63a8\u7406\u7684\u6cbb\u7406\u5b50\u7cfb\u7edf\u3002", "result": "\u5728InterCode-CTF\u4e0a\u5b9e\u73b0\u5b8c\u5168\u89e3\u51b3\u7387\uff1b\u5728NYU-CTF\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u89e3\u51b356-60%\u7684\u52a0\u5bc6\u6311\u6218\uff1b\u57286\u4e2a\u771f\u5b9eCTF\u6bd4\u8d5b\u4e2d\u6210\u529f\u89e3\u51b326/33\u4e2a\u52a0\u5bc6\u6311\u6218\uff0c\u5305\u62ec\u591a\u4e2a\u6700\u65e9\u89e3\u51b3\u548c\u552f\u4e00\u89e3\u51b3\u7684\u5b9e\u4f8b\u3002", "conclusion": "\u5f00\u653e\u4e16\u754c\u3001\u7ec6\u7c92\u5ea6\u77e5\u8bc6\u589e\u5f3a\u548c\u6cbb\u7406\u63a8\u7406\u5bf9\u4e8e\u5c06\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u6269\u5c55\u5230\u771f\u5b9e\u4e16\u754c\u52a0\u5bc6\u653b\u51fb\u4efb\u52a1\u662f\u5fc5\u8981\u7684\u3002KryptoPilot\u5c55\u793a\u4e86\u8fd9\u79cd\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2601.08884", "categories": ["cs.SE", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.08884", "abs": "https://arxiv.org/abs/2601.08884", "authors": ["Samyak Jhaveri", "Cristina V. Lopes"], "title": "Bridging the Gap: Empowering Small Models in Reliable OpenACC-based Parallelization via GEPA-Optimized Prompting", "comment": null, "summary": "OpenACC lowers the barrier to GPU offloading, but writing high-performing pragma remains complex, requiring deep domain expertise in memory hierarchies, data movement, and parallelization strategies. Large Language Models (LLMs) present a promising potential solution for automated parallel code generation, but naive prompting often results in syntactically incorrect directives, uncompilable code, or performance that fails to exceed CPU baselines. We present a systematic prompt optimization approach to enhance OpenACC pragma generation without the prohibitive computational costs associated with model post-training. Leveraging the GEPA (GEnetic-PAreto) framework, we iteratively evolve prompts through a reflective feedback loop. This process utilizes crossover and mutation of instructions, guided by expert-curated gold examples and structured feedback based on clause- and clause parameter-level mismatches between the gold and predicted pragma. In our evaluation on the PolyBench suite, we observe an increase in compilation success rates for programs annotated with OpenACC pragma generated using the optimized prompts compared to those annotated using the simpler initial prompt, particularly for the \"nano\"-scale models. Specifically, with optimized prompts, the compilation success rate for GPT-4.1 Nano surged from 66.7% to 93.3%, and for GPT-5 Nano improved from 86.7% to 100%, matching or surpassing the capabilities of their significantly larger, more expensive versions. Beyond compilation, the optimized prompts resulted in a 21% increase in the number of programs that achieve functional GPU speedups over CPU baselines. These results demonstrate that prompt optimization effectively unlocks the potential of smaller, cheaper LLMs in writing stable and effective GPU-offloading directives, establishing a cost-effective pathway to automated directive-based parallelization in HPC workflows.", "AI": {"tldr": "\u4f7f\u7528\u9057\u4f20-\u5e15\u7d2f\u6258\u6846\u67b6\u4f18\u5316\u63d0\u793a\uff0c\u663e\u8457\u63d0\u5347\u5c0f\u578bLLM\u751f\u6210OpenACC\u5e76\u884c\u4ee3\u7801\u7684\u8d28\u91cf\u548c\u7f16\u8bd1\u6210\u529f\u7387", "motivation": "OpenACC\u964d\u4f4e\u4e86GPU\u5378\u8f7d\u7684\u95e8\u69db\uff0c\u4f46\u7f16\u5199\u9ad8\u6027\u80fd\u7684pragma\u4ecd\u7136\u590d\u6742\uff0c\u9700\u8981\u6df1\u539a\u7684\u5185\u5b58\u5c42\u6b21\u3001\u6570\u636e\u79fb\u52a8\u548c\u5e76\u884c\u5316\u7b56\u7565\u4e13\u4e1a\u77e5\u8bc6\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e3a\u81ea\u52a8\u5316\u5e76\u884c\u4ee3\u7801\u751f\u6210\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u7b80\u5355\u7684\u63d0\u793a\u901a\u5e38\u4f1a\u5bfc\u81f4\u8bed\u6cd5\u9519\u8bef\u7684\u6307\u4ee4\u3001\u65e0\u6cd5\u7f16\u8bd1\u7684\u4ee3\u7801\u6216\u6027\u80fd\u65e0\u6cd5\u8d85\u8fc7CPU\u57fa\u51c6\u3002", "method": "\u63d0\u51fa\u7cfb\u7edf\u6027\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\uff0c\u5229\u7528GEPA\uff08\u9057\u4f20-\u5e15\u7d2f\u6258\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u53cd\u5c04\u53cd\u9988\u5faa\u73af\u8fed\u4ee3\u6f14\u5316\u63d0\u793a\u3002\u8be5\u8fc7\u7a0b\u5229\u7528\u6307\u4ee4\u7684\u4ea4\u53c9\u548c\u53d8\u5f02\uff0c\u4ee5\u4e13\u5bb6\u7b56\u5212\u7684\u9ec4\u91d1\u793a\u4f8b\u4e3a\u6307\u5bfc\uff0c\u5e76\u57fa\u4e8e\u9ec4\u91d1\u548c\u9884\u6d4bpragma\u4e4b\u95f4\u7684\u5b50\u53e5\u548c\u5b50\u53e5\u53c2\u6570\u7ea7\u4e0d\u5339\u914d\u63d0\u4f9b\u7ed3\u6784\u5316\u53cd\u9988\u3002", "result": "\u5728PolyBench\u5957\u4ef6\u8bc4\u4f30\u4e2d\uff0c\u4f7f\u7528\u4f18\u5316\u63d0\u793a\u751f\u6210\u7684OpenACC pragma\u7684\u7f16\u8bd1\u6210\u529f\u7387\u663e\u8457\u63d0\u9ad8\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\"nano\"\u89c4\u6a21\u6a21\u578b\u3002GPT-4.1 Nano\u7684\u7f16\u8bd1\u6210\u529f\u7387\u4ece66.7%\u63d0\u5347\u523093.3%\uff0cGPT-5 Nano\u4ece86.7%\u63d0\u5347\u5230100%\uff0c\u5339\u914d\u6216\u8d85\u8d8a\u4e86\u66f4\u5927\u3001\u66f4\u6602\u8d35\u7248\u672c\u7684\u80fd\u529b\u3002\u4f18\u5316\u63d0\u793a\u8fd8\u4f7f\u5b9e\u73b0GPU\u52a0\u901f\u8d85\u8fc7CPU\u57fa\u51c6\u7684\u7a0b\u5e8f\u6570\u91cf\u589e\u52a0\u4e8621%\u3002", "conclusion": "\u63d0\u793a\u4f18\u5316\u6709\u6548\u91ca\u653e\u4e86\u66f4\u5c0f\u3001\u66f4\u4fbf\u5b9c\u7684LLM\u5728\u7f16\u5199\u7a33\u5b9a\u6709\u6548\u7684GPU\u5378\u8f7d\u6307\u4ee4\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u4e3aHPC\u5de5\u4f5c\u6d41\u4e2d\u57fa\u4e8e\u6307\u4ee4\u7684\u81ea\u52a8\u5316\u5e76\u884c\u5316\u5efa\u7acb\u4e86\u7ecf\u6d4e\u9ad8\u6548\u7684\u9014\u5f84\u3002"}}
{"id": "2601.09097", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09097", "abs": "https://arxiv.org/abs/2601.09097", "authors": ["Derrick Goh Xin Deik", "Quanyu Long", "Zhengyuan Liu", "Nancy F. Chen", "Wenya Wang"], "title": "Programming over Thinking: Efficient and Robust Multi-Constraint Planning", "comment": "8 pages of main text, 2 pages of references and and limitations, 37 pages of appendices", "summary": "Multi-constraint planning involves identifying, evaluating, and refining candidate plans while satisfying multiple, potentially conflicting constraints. Existing large language model (LLM) approaches face fundamental limitations in this domain. Pure reasoning paradigms, which rely on long natural language chains, are prone to inconsistency, error accumulation, and prohibitive cost as constraints compound. Conversely, LLMs combined with coding- or solver-based strategies lack flexibility: they often generate problem-specific code from scratch or depend on fixed solvers, failing to capture generalizable logic across diverse problems. To address these challenges, we introduce the Scalable COde Planning Engine (SCOPE), a framework that disentangles query-specific reasoning from generic code execution. By separating reasoning from execution, SCOPE produces solver functions that are consistent, deterministic, and reusable across queries while requiring only minimal changes to input parameters. SCOPE achieves state-of-the-art performance while lowering cost and latency. For example, with GPT-4o, it reaches 93.1% success on TravelPlanner, a 61.6% gain over the best baseline (CoT) while cutting inference cost by 1.4x and time by ~4.67x. Code is available at https://github.com/DerrickGXD/SCOPE.", "AI": {"tldr": "SCOPE\u6846\u67b6\u901a\u8fc7\u5206\u79bb\u63a8\u7406\u4e0e\u4ee3\u7801\u6267\u884c\uff0c\u89e3\u51b3\u4e86\u591a\u7ea6\u675f\u89c4\u5212\u4e2dLLM\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u53ef\u590d\u7528\u4e14\u6210\u672c\u66f4\u4f4e\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u73b0\u6709LLM\u65b9\u6cd5\u5728\u591a\u7ea6\u675f\u89c4\u5212\u4e2d\u5b58\u5728\u6839\u672c\u6027\u5c40\u9650\uff1a\u7eaf\u63a8\u7406\u65b9\u6cd5\u5bb9\u6613\u4ea7\u751f\u4e0d\u4e00\u81f4\u6027\u3001\u9519\u8bef\u7d2f\u79ef\u548c\u9ad8\u6210\u672c\uff1b\u800c\u7ed3\u5408\u7f16\u7801\u6216\u6c42\u89e3\u5668\u7684\u65b9\u6cd5\u7f3a\u4e4f\u7075\u6d3b\u6027\uff0c\u65e0\u6cd5\u6355\u6349\u8de8\u95ee\u9898\u7684\u901a\u7528\u903b\u8f91\u3002", "method": "\u63d0\u51faSCOPE\u6846\u67b6\uff0c\u5c06\u67e5\u8be2\u7279\u5b9a\u63a8\u7406\u4e0e\u901a\u7528\u4ee3\u7801\u6267\u884c\u89e3\u8026\uff0c\u751f\u6210\u4e00\u81f4\u3001\u786e\u5b9a\u4e14\u53ef\u8de8\u67e5\u8be2\u590d\u7528\u7684\u6c42\u89e3\u5668\u51fd\u6570\uff0c\u4ec5\u9700\u5bf9\u8f93\u5165\u53c2\u6570\u8fdb\u884c\u6700\u5c0f\u6539\u52a8\u3002", "result": "SCOPE\u5728TravelPlanner\u4e0a\u8fbe\u523093.1%\u7684\u6210\u529f\u7387\uff0c\u6bd4\u6700\u4f73\u57fa\u7ebf\uff08CoT\uff09\u63d0\u534761.6%\uff0c\u540c\u65f6\u5c06\u63a8\u7406\u6210\u672c\u964d\u4f4e1.4\u500d\uff0c\u65f6\u95f4\u51cf\u5c11\u7ea64.67\u500d\u3002", "conclusion": "SCOPE\u901a\u8fc7\u5206\u79bb\u63a8\u7406\u4e0e\u6267\u884c\uff0c\u89e3\u51b3\u4e86\u591a\u7ea6\u675f\u89c4\u5212\u4e2dLLM\u65b9\u6cd5\u7684\u6839\u672c\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u3001\u4f4e\u6210\u672c\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.09157", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09157", "abs": "https://arxiv.org/abs/2601.09157", "authors": ["Mitchell Petingola"], "title": "Deep Learning-based Binary Analysis for Vulnerability Detection in x86-64 Machine Code", "comment": null, "summary": "While much of the current research in deep learning-based vulnerability detection relies on disassembled binaries, this paper explores the feasibility of extracting features directly from raw x86-64 machine code. Although assembly language is more interpretable for humans, it requires more complex models to capture token-level context. In contrast, machine code may enable more efficient, lightweight models and preserve all information that might be lost in disassembly. This paper approaches the task of vulnerability detection through an exploratory study on two specific deep learning model architectures and aims to systematically evaluate their performance across three vulnerability types. The results demonstrate that graph-based models consistently outperform sequential models, emphasizing the importance of control flow relationships, and that machine code contains sufficient information for effective vulnerability discovery.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u76f4\u63a5\u4ece\u539f\u59cbx86-64\u673a\u5668\u4ee3\u7801\u8fdb\u884c\u6f0f\u6d1e\u68c0\u6d4b\u7684\u53ef\u884c\u6027\uff0c\u53d1\u73b0\u57fa\u4e8e\u56fe\u7ed3\u6784\u7684\u6a21\u578b\u4f18\u4e8e\u5e8f\u5217\u6a21\u578b\uff0c\u4e14\u673a\u5668\u4ee3\u7801\u5305\u542b\u8db3\u591f\u4fe1\u606f\u7528\u4e8e\u6709\u6548\u6f0f\u6d1e\u53d1\u73b0\u3002", "motivation": "\u5f53\u524d\u6df1\u5ea6\u5b66\u4e60\u6f0f\u6d1e\u68c0\u6d4b\u7814\u7a76\u591a\u4f9d\u8d56\u53cd\u6c47\u7f16\u4e8c\u8fdb\u5236\u6587\u4ef6\uff0c\u4f46\u53cd\u6c47\u7f16\u9700\u8981\u66f4\u590d\u6742\u6a21\u578b\u6765\u6355\u83b7\u6807\u8bb0\u7ea7\u4e0a\u4e0b\u6587\uff0c\u800c\u673a\u5668\u4ee3\u7801\u53ef\u80fd\u652f\u6301\u66f4\u9ad8\u6548\u3001\u8f7b\u91cf\u7ea7\u7684\u6a21\u578b\uff0c\u5e76\u4fdd\u7559\u53cd\u6c47\u7f16\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u4e22\u5931\u7684\u6240\u6709\u4fe1\u606f\u3002", "method": "\u901a\u8fc7\u63a2\u7d22\u6027\u7814\u7a76\uff0c\u91c7\u7528\u4e24\u79cd\u7279\u5b9a\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u67b6\u6784\uff08\u56fe\u6a21\u578b\u548c\u5e8f\u5217\u6a21\u578b\uff09\uff0c\u5728\u4e09\u79cd\u6f0f\u6d1e\u7c7b\u578b\u4e0a\u7cfb\u7edf\u8bc4\u4f30\u5176\u6027\u80fd\uff0c\u76f4\u63a5\u4ece\u539f\u59cbx86-64\u673a\u5668\u4ee3\u7801\u63d0\u53d6\u7279\u5f81\u3002", "result": "\u57fa\u4e8e\u56fe\u7684\u6a21\u578b\u59cb\u7ec8\u4f18\u4e8e\u5e8f\u5217\u6a21\u578b\uff0c\u5f3a\u8c03\u4e86\u63a7\u5236\u6d41\u5173\u7cfb\u7684\u91cd\u8981\u6027\uff1b\u673a\u5668\u4ee3\u7801\u5305\u542b\u8db3\u591f\u4fe1\u606f\u7528\u4e8e\u6709\u6548\u7684\u6f0f\u6d1e\u53d1\u73b0\u3002", "conclusion": "\u76f4\u63a5\u4ece\u673a\u5668\u4ee3\u7801\u8fdb\u884c\u6f0f\u6d1e\u68c0\u6d4b\u662f\u53ef\u884c\u7684\uff0c\u56fe\u6a21\u578b\u56e0\u5176\u80fd\u6355\u83b7\u63a7\u5236\u6d41\u5173\u7cfb\u800c\u8868\u73b0\u66f4\u4f18\uff0c\u673a\u5668\u4ee3\u7801\u4fdd\u7559\u4e86\u8db3\u591f\u7684\u4fe1\u606f\u7528\u4e8e\u6f0f\u6d1e\u53d1\u73b0\uff0c\u4e3a\u66f4\u9ad8\u6548\u7684\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u6cd5\u63d0\u4f9b\u4e86\u53ef\u80fd\u6027\u3002"}}
{"id": "2601.08995", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.08995", "abs": "https://arxiv.org/abs/2601.08995", "authors": ["Brent Pappas", "Paul Gazzillo"], "title": "Build Code is Still Code: Finding the Antidote for Pipeline Poisoning", "comment": "2026 IEEE/ACM 48th International Conference on Software Engineering. April 12--18, 2026. Rio de Janeiro, Brazil. 5 pages. 3 figures. 2 code listings. 1 table", "summary": "Open source C code underpins society's computing infrastructure. Decades of work has helped harden C code against attackers, but C projects do not consist of only C code. C projects also contain build system code for automating development tasks like compilation, testing, and packaging. These build systems are critcal to software supply chain security and vulnerable to being poisoned, with the XZ Utils and SolarWinds attacks being recent examples. Existing techniques try to harden software supply chains by verifying software dependencies, but such methods ignore the build system itself. Similarly, classic software security checkers only analyze and monitor program code, not build system code. Moreover, poisoned build systems can easily circumvent tools for detecting program code vulnerabilities by disabling such checks. We present development phase isolation, a novel strategy for hardening build systems against poisoning by modeling the information and behavior permissions of build automation as if it were program code. We have prototyped this approach as a tool called Foreman, which successfully detects and warns about the poisoned test files involved in the XZ Utils attack. We outline our future plans to protect against pipeline poisoning by automatically checking development phase isolation. We envision a future where build system security checkers are as prevalent as program code checkers.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\"\u5f00\u53d1\u9636\u6bb5\u9694\u79bb\"\u7684\u65b0\u7b56\u7565\uff0c\u901a\u8fc7\u5c06\u6784\u5efa\u81ea\u52a8\u5316\u89c6\u4e3a\u7a0b\u5e8f\u4ee3\u7801\u6765\u5efa\u6a21\u5176\u4fe1\u606f\u548c\u884c\u4e3a\u6743\u9650\uff0c\u4ece\u800c\u4fdd\u62a4\u6784\u5efa\u7cfb\u7edf\u514d\u53d7\u6295\u6bd2\u653b\u51fb\u3002\u539f\u578b\u5de5\u5177Foreman\u6210\u529f\u68c0\u6d4b\u4e86XZ Utils\u653b\u51fb\u4e2d\u7684\u6295\u6bd2\u6d4b\u8bd5\u6587\u4ef6\u3002", "motivation": "C\u9879\u76ee\u4e0d\u4ec5\u5305\u542bC\u4ee3\u7801\uff0c\u8fd8\u5305\u542b\u7528\u4e8e\u81ea\u52a8\u5316\u5f00\u53d1\u4efb\u52a1\u7684\u6784\u5efa\u7cfb\u7edf\u4ee3\u7801\u3002\u8fd9\u4e9b\u6784\u5efa\u7cfb\u7edf\u5bf9\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5bb9\u6613\u53d7\u5230\u6295\u6bd2\u653b\u51fb\uff08\u5982XZ Utils\u548cSolarWinds\u653b\u51fb\uff09\u3002\u73b0\u6709\u6280\u672f\u8981\u4e48\u53ea\u9a8c\u8bc1\u8f6f\u4ef6\u4f9d\u8d56\u9879\u800c\u5ffd\u7565\u6784\u5efa\u7cfb\u7edf\u672c\u8eab\uff0c\u8981\u4e48\u53ea\u5206\u6790\u7a0b\u5e8f\u4ee3\u7801\u800c\u4e0d\u5206\u6790\u6784\u5efa\u7cfb\u7edf\u4ee3\u7801\u3002\u6295\u6bd2\u7684\u6784\u5efa\u7cfb\u7edf\u53ef\u4ee5\u8f7b\u677e\u7ed5\u8fc7\u7a0b\u5e8f\u4ee3\u7801\u6f0f\u6d1e\u68c0\u6d4b\u5de5\u5177\u3002", "method": "\u63d0\u51fa\u4e86\"\u5f00\u53d1\u9636\u6bb5\u9694\u79bb\"\u7b56\u7565\uff0c\u5c06\u6784\u5efa\u81ea\u52a8\u5316\u7684\u4fe1\u606f\u548c\u884c\u4e3a\u6743\u9650\u5efa\u6a21\u4e3a\u7a0b\u5e8f\u4ee3\u7801\u3002\u5f00\u53d1\u4e86\u539f\u578b\u5de5\u5177Foreman\u6765\u5b9e\u73b0\u8fd9\u79cd\u65b9\u6cd5\uff0c\u901a\u8fc7\u68c0\u67e5\u6784\u5efa\u7cfb\u7edf\u7684\u6743\u9650\u548c\u9694\u79bb\u6765\u68c0\u6d4b\u6f5c\u5728\u7684\u6295\u6bd2\u653b\u51fb\u3002", "result": "Foreman\u6210\u529f\u68c0\u6d4b\u5e76\u8b66\u544a\u4e86XZ Utils\u653b\u51fb\u4e2d\u6d89\u53ca\u7684\u6295\u6bd2\u6d4b\u8bd5\u6587\u4ef6\u3002\u8be5\u5de5\u5177\u80fd\u591f\u8bc6\u522b\u6784\u5efa\u7cfb\u7edf\u4e2d\u7684\u5b89\u5168\u5a01\u80c1\uff0c\u800c\u4f20\u7edf\u65b9\u6cd5\u65e0\u6cd5\u68c0\u6d4b\u8fd9\u4e9b\u5a01\u80c1\u3002", "conclusion": "\u6784\u5efa\u7cfb\u7edf\u5b89\u5168\u68c0\u67e5\u5668\u5e94\u8be5\u50cf\u7a0b\u5e8f\u4ee3\u7801\u68c0\u67e5\u5668\u4e00\u6837\u666e\u53ca\u3002\u672a\u6765\u8ba1\u5212\u901a\u8fc7\u81ea\u52a8\u68c0\u67e5\u5f00\u53d1\u9636\u6bb5\u9694\u79bb\u6765\u9632\u6b62\u6d41\u6c34\u7ebf\u6295\u6bd2\uff0c\u4e3a\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\u63d0\u4f9b\u66f4\u5168\u9762\u7684\u4fdd\u62a4\u3002"}}
{"id": "2601.09100", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09100", "abs": "https://arxiv.org/abs/2601.09100", "authors": ["Lixiang Zhang", "Chenggong Zhao", "Qing Gao", "Xiaoke Zhao", "Gengyi Bai", "Jinhu Lv"], "title": "DScheLLM: Enabling Dynamic Scheduling through a Fine-Tuned Dual-System Large language Model", "comment": "14 pages, 6 figures", "summary": "Production scheduling is highly susceptible to dynamic disruptions, such as variations in processing times, machine availability, and unexpected task insertions. Conventional approaches typically rely on event-specific models and explicit analytical formulations, which limits their adaptability and generalization across previously unseen disturbances. To overcome these limitations, this paper proposes DScheLLM, a dynamic scheduling approach that leverages fine-tuned large language models within a dual-system (fast-slow) reasoning architecture to address disturbances of different scales. A unified large language model-based framework is constructed to handle dynamic events, where training datasets for both fast and slow reasoning modes are generated using exact schedules obtained from an operations research solver. The Huawei OpenPangu Embedded-7B model is subsequently fine-tuned under the hybrid reasoning paradigms using LoRA. Experimental evaluations on standard job shop scheduling benchmarks demonstrate that the fast-thinking mode can efficiently generate high-quality schedules and the slow-thinking mode can produce solver-compatible and well-formatted decision inputs. To the best of our knowledge, this work represents one of the earliest studies applying large language models to job shop scheduling in dynamic environments, highlighting their considerable potential for intelligent and adaptive scheduling optimization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDScheLLM\u65b9\u6cd5\uff0c\u5229\u7528\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u5728\u53cc\u7cfb\u7edf\uff08\u5feb\u6162\uff09\u63a8\u7406\u67b6\u6784\u4e2d\u5904\u7406\u751f\u4ea7\u8c03\u5ea6\u4e2d\u7684\u52a8\u6001\u6270\u52a8\uff0c\u901a\u8fc7\u534e\u4e3aOpenPangu\u6a21\u578b\u5728\u6807\u51c6\u4f5c\u4e1a\u8f66\u95f4\u8c03\u5ea6\u57fa\u51c6\u4e0a\u5b9e\u73b0\u9ad8\u6548\u8c03\u5ea6\u3002", "motivation": "\u4f20\u7edf\u751f\u4ea7\u8c03\u5ea6\u65b9\u6cd5\u5bf9\u52a8\u6001\u6270\u52a8\uff08\u5982\u5904\u7406\u65f6\u95f4\u53d8\u5316\u3001\u673a\u5668\u53ef\u7528\u6027\u3001\u610f\u5916\u4efb\u52a1\u63d2\u5165\uff09\u7684\u9002\u5e94\u6027\u6709\u9650\uff0c\u901a\u5e38\u4f9d\u8d56\u7279\u5b9a\u4e8b\u4ef6\u6a21\u578b\u548c\u663e\u5f0f\u5206\u6790\u516c\u5f0f\uff0c\u96be\u4ee5\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684\u6270\u52a8\u60c5\u51b5\u3002", "method": "\u6784\u5efa\u7edf\u4e00\u7684\u5927\u8bed\u8a00\u6a21\u578b\u6846\u67b6\u5904\u7406\u52a8\u6001\u4e8b\u4ef6\uff0c\u4f7f\u7528\u8fd0\u7b79\u5b66\u6c42\u89e3\u5668\u83b7\u5f97\u7684\u7cbe\u786e\u8c03\u5ea6\u751f\u6210\u5feb\u6162\u63a8\u7406\u6a21\u5f0f\u7684\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u57fa\u4e8e\u534e\u4e3aOpenPangu Embedded-7B\u6a21\u578b\u91c7\u7528LoRA\u8fdb\u884c\u5fae\u8c03\uff0c\u5b9e\u73b0\u53cc\u7cfb\u7edf\u63a8\u7406\u67b6\u6784\u3002", "result": "\u5728\u6807\u51c6\u4f5c\u4e1a\u8f66\u95f4\u8c03\u5ea6\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0c\u5feb\u601d\u8003\u6a21\u5f0f\u80fd\u9ad8\u6548\u751f\u6210\u9ad8\u8d28\u91cf\u8c03\u5ea6\u65b9\u6848\uff0c\u6162\u601d\u8003\u6a21\u5f0f\u80fd\u4ea7\u751f\u4e0e\u6c42\u89e3\u5668\u517c\u5bb9\u4e14\u683c\u5f0f\u826f\u597d\u7684\u51b3\u7b56\u8f93\u5165\u3002", "conclusion": "\u8fd9\u662f\u6700\u65e9\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u52a8\u6001\u73af\u5883\u4f5c\u4e1a\u8f66\u95f4\u8c03\u5ea6\u7684\u7814\u7a76\u4e4b\u4e00\uff0c\u5c55\u793a\u4e86LLM\u5728\u667a\u80fd\u81ea\u9002\u5e94\u8c03\u5ea6\u4f18\u5316\u4e2d\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2601.08998", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.08998", "abs": "https://arxiv.org/abs/2601.08998", "authors": ["Alexander Berndt", "Thomas Bach", "Rainer Gemulla", "Marcus Kessel", "Sebastian Baltes"], "title": "On the Flakiness of LLM-Generated Tests for Industrial and Open-Source Database Management Systems", "comment": "12 pages, 5 tables, 3 figures, accepted at the 48th International Conference on Software Engineering: Software Engineering in Practice (ICSE SEIP 2026)", "summary": "Flaky tests are a common problem in software testing. They produce inconsistent results when executed multiple times on the same code, invalidating the assumption that a test failure indicates a software defect. Recent work on LLM-based test generation has identified flakiness as a potential problem with generated tests. However, its prevalence and underlying causes are unclear. We examined the flakiness of LLM-generated tests in the context of four relational database management systems: SAP HANA, DuckDB, MySQL, and SQLite. We amplified test suites with two LLMs, GPT-4o and Mistral-Large-Instruct-2407, to assess the flakiness of the generated test cases. Our results suggest that generated tests have a slightly higher proportion of flaky tests compared to existing tests. Based on a manual inspection, we found that the most common root cause of flakiness was the reliance of a test on a certain order that is not guaranteed (\"unordered collection\"), which was present in 72 of 115 flaky tests (63%). Furthermore, both LLMs transferred the flakiness from the existing tests to the newly generated tests via the provided prompt context. Our experiments suggest that flakiness transfer is more prevalent in closed-source systems such as SAP HANA than in open-source systems. Our study informs developers on what types of flakiness to expect from LLM-generated tests. It also highlights the importance of providing LLMs with tailored context when employing LLMs for test generation.", "AI": {"tldr": "LLM\u751f\u6210\u7684\u6570\u636e\u5e93\u6d4b\u8bd5\u4e2d\u5b58\u5728\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u5176\u4e2d63%\u7684\u4e0d\u7a33\u5b9a\u6d4b\u8bd5\u6e90\u4e8e\u5bf9\u65e0\u5e8f\u96c6\u5408\u7684\u987a\u5e8f\u4f9d\u8d56\uff0c\u4e14\u95ed\u6e90\u7cfb\u7edf\u66f4\u5bb9\u6613\u51fa\u73b0\u4e0d\u7a33\u5b9a\u6027\u4f20\u9012\u3002", "motivation": "\u7814\u7a76LLM\u751f\u6210\u7684\u6d4b\u8bd5\u4e2d\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\u7684\u666e\u904d\u6027\u548c\u6839\u672c\u539f\u56e0\uff0c\u7279\u522b\u662f\u5728\u5173\u7cfb\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\u6d4b\u8bd5\u4e2d\uff0c\u56e0\u4e3a\u73b0\u6709\u7814\u7a76\u5df2\u8bc6\u522b\u4e0d\u7a33\u5b9a\u6027\u662fLLM\u751f\u6210\u6d4b\u8bd5\u7684\u6f5c\u5728\u95ee\u9898\uff0c\u4f46\u5176\u666e\u904d\u6027\u548c\u539f\u56e0\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u4f7f\u7528GPT-4o\u548cMistral-Large-Instruct-2407\u4e24\u4e2aLLM\u5bf9\u56db\u4e2a\u5173\u7cfb\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\uff08SAP HANA\u3001DuckDB\u3001MySQL\u3001SQLite\uff09\u7684\u6d4b\u8bd5\u5957\u4ef6\u8fdb\u884c\u6269\u589e\uff0c\u8bc4\u4f30\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u7684\u4e0d\u7a33\u5b9a\u6027\uff0c\u5e76\u901a\u8fc7\u624b\u52a8\u68c0\u67e5\u5206\u6790\u6839\u672c\u539f\u56e0\u3002", "result": "\u751f\u6210\u6d4b\u8bd5\u7684\u4e0d\u7a33\u5b9a\u6d4b\u8bd5\u6bd4\u4f8b\u7565\u9ad8\u4e8e\u73b0\u6709\u6d4b\u8bd5\uff1b63%\u7684\u4e0d\u7a33\u5b9a\u6d4b\u8bd5\uff0872/115\uff09\u7684\u6839\u672c\u539f\u56e0\u662f\u6d4b\u8bd5\u4f9d\u8d56\u672a\u4fdd\u8bc1\u7684\u987a\u5e8f\uff08\"\u65e0\u5e8f\u96c6\u5408\"\uff09\uff1bLLM\u901a\u8fc7\u63d0\u793a\u4e0a\u4e0b\u6587\u5c06\u73b0\u6709\u6d4b\u8bd5\u7684\u4e0d\u7a33\u5b9a\u6027\u4f20\u9012\u5230\u65b0\u751f\u6210\u7684\u6d4b\u8bd5\u4e2d\uff1b\u95ed\u6e90\u7cfb\u7edf\uff08\u5982SAP HANA\uff09\u6bd4\u5f00\u6e90\u7cfb\u7edf\u66f4\u5bb9\u6613\u51fa\u73b0\u4e0d\u7a33\u5b9a\u6027\u4f20\u9012\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86LLM\u751f\u6210\u6d4b\u8bd5\u4e2d\u53ef\u80fd\u9047\u5230\u7684\u4e0d\u7a33\u5b9a\u6027\u7c7b\u578b\u4fe1\u606f\uff0c\u5e76\u5f3a\u8c03\u4e86\u5728\u4f7f\u7528LLM\u8fdb\u884c\u6d4b\u8bd5\u751f\u6210\u65f6\u63d0\u4f9b\u5b9a\u5236\u5316\u4e0a\u4e0b\u6587\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.09105", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09105", "abs": "https://arxiv.org/abs/2601.09105", "authors": ["Wenbin Li", "Jingling Wu", "Xiaoyong Lin. Jing Chen", "Cong Chen"], "title": "AviationLMM: A Large Multimodal Foundation Model for Civil Aviation", "comment": "Accepted by 2025 7th International Conference on Interdisciplinary Computer Science and Engineering (ICICSE 2025) conference, Chongqing, China; 9 pages,1 figure,5 tables", "summary": "Civil aviation is a cornerstone of global transportation and commerce, and ensuring its safety, efficiency and customer satisfaction is paramount. Yet conventional Artificial Intelligence (AI) solutions in aviation remain siloed and narrow, focusing on isolated tasks or single modalities. They struggle to integrate heterogeneous data such as voice communications, radar tracks, sensor streams and textual reports, which limits situational awareness, adaptability, and real-time decision support. This paper introduces the vision of AviationLMM, a Large Multimodal foundation Model for civil aviation, designed to unify the heterogeneous data streams of civil aviation and enable understanding, reasoning, generation and agentic applications. We firstly identify the gaps between existing AI solutions and requirements. Secondly, we describe the model architecture that ingests multimodal inputs such as air-ground voice, surveillance, on-board telemetry, video and structured texts, and performs cross-modal alignment and fusion, and produces flexible outputs ranging from situation summaries and risk alerts to predictive diagnostics and multimodal incident reconstructions. In order to fully realize this vision, we identify key research opportunities to address, including data acquisition, alignment and fusion, pretraining, reasoning, trustworthiness, privacy, robustness to missing modalities, and synthetic scenario generation. By articulating the design and challenges of AviationLMM, we aim to boost the civil aviation foundation model progress and catalyze coordinated research efforts toward an integrated, trustworthy and privacy-preserving aviation AI ecosystem.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86AviationLMM\u2014\u2014\u4e00\u4e2a\u9762\u5411\u6c11\u822a\u7684\u5927\u578b\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\uff0c\u65e8\u5728\u7edf\u4e00\u6c11\u822a\u5f02\u6784\u6570\u636e\u6d41\uff0c\u5b9e\u73b0\u7406\u89e3\u3001\u63a8\u7406\u3001\u751f\u6210\u548c\u667a\u80fd\u4f53\u5e94\u7528\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709AI\u89e3\u51b3\u65b9\u6848\u5728\u6c11\u822a\u9886\u57df\u7684\u5b64\u7acb\u6027\u548c\u5c40\u9650\u6027\u95ee\u9898\u3002", "motivation": "\u6c11\u822a\u662f\u5168\u7403\u4ea4\u901a\u548c\u5546\u4e1a\u7684\u57fa\u77f3\uff0c\u786e\u4fdd\u5176\u5b89\u5168\u3001\u6548\u7387\u548c\u5ba2\u6237\u6ee1\u610f\u5ea6\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u6c11\u822a\u9886\u57df\u7684\u4f20\u7edfAI\u89e3\u51b3\u65b9\u6848\u5b58\u5728\u5b64\u7acb\u6027\u548c\u5c40\u9650\u6027\uff0c\u4e13\u6ce8\u4e8e\u5355\u4e00\u4efb\u52a1\u6216\u6a21\u6001\uff0c\u96be\u4ee5\u6574\u5408\u8bed\u97f3\u901a\u4fe1\u3001\u96f7\u8fbe\u8f68\u8ff9\u3001\u4f20\u611f\u5668\u6d41\u548c\u6587\u672c\u62a5\u544a\u7b49\u5f02\u6784\u6570\u636e\uff0c\u9650\u5236\u4e86\u6001\u52bf\u611f\u77e5\u3001\u9002\u5e94\u6027\u548c\u5b9e\u65f6\u51b3\u7b56\u652f\u6301\u80fd\u529b\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86AviationLMM\u6a21\u578b\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u80fd\u591f\u5904\u7406\u591a\u6a21\u6001\u8f93\u5165\uff08\u5305\u62ec\u7a7a\u5730\u8bed\u97f3\u3001\u76d1\u89c6\u6570\u636e\u3001\u673a\u8f7d\u9065\u6d4b\u3001\u89c6\u9891\u548c\u7ed3\u6784\u5316\u6587\u672c\uff09\uff0c\u6267\u884c\u8de8\u6a21\u6001\u5bf9\u9f50\u548c\u878d\u5408\uff0c\u5e76\u4ea7\u751f\u7075\u6d3b\u7684\u8f93\u51fa\uff08\u4ece\u6001\u52bf\u6458\u8981\u548c\u98ce\u9669\u8b66\u62a5\u5230\u9884\u6d4b\u6027\u8bca\u65ad\u548c\u591a\u6a21\u6001\u4e8b\u4ef6\u91cd\u5efa\uff09\u3002\u540c\u65f6\u8bc6\u522b\u4e86\u5b9e\u73b0\u8be5\u613f\u666f\u9700\u8981\u89e3\u51b3\u7684\u5173\u952e\u7814\u7a76\u673a\u4f1a\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86AviationLMM\u7684\u8bbe\u8ba1\u613f\u666f\u548c\u67b6\u6784\u6846\u67b6\uff0c\u8bc6\u522b\u4e86\u6570\u636e\u83b7\u53d6\u3001\u5bf9\u9f50\u878d\u5408\u3001\u9884\u8bad\u7ec3\u3001\u63a8\u7406\u3001\u53ef\u4fe1\u6027\u3001\u9690\u79c1\u3001\u6a21\u6001\u7f3a\u5931\u9c81\u68d2\u6027\u548c\u5408\u6210\u573a\u666f\u751f\u6210\u7b49\u5173\u952e\u7814\u7a76\u6311\u6218\uff0c\u4e3a\u63a8\u8fdb\u6c11\u822a\u57fa\u7840\u6a21\u578b\u7814\u7a76\u548c\u6784\u5efa\u96c6\u6210\u3001\u53ef\u4fe1\u3001\u9690\u79c1\u4fdd\u62a4\u7684\u822a\u7a7aAI\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u8def\u7ebf\u56fe\u3002", "conclusion": "\u901a\u8fc7\u9610\u8ff0AviationLMM\u7684\u8bbe\u8ba1\u548c\u6311\u6218\uff0c\u65e8\u5728\u63a8\u52a8\u6c11\u822a\u57fa\u7840\u6a21\u578b\u7684\u8fdb\u5c55\uff0c\u5e76\u4fc3\u8fdb\u534f\u8c03\u7684\u7814\u7a76\u52aa\u529b\uff0c\u671d\u7740\u6784\u5efa\u96c6\u6210\u3001\u53ef\u4fe1\u548c\u9690\u79c1\u4fdd\u62a4\u7684\u822a\u7a7aAI\u751f\u6001\u7cfb\u7edf\u65b9\u5411\u53d1\u5c55\u3002"}}
{"id": "2601.09273", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.09273", "abs": "https://arxiv.org/abs/2601.09273", "authors": ["Annika Wilde", "Samira Briongos", "Claudio Soriente", "Ghassan Karame"], "title": "The Real Menace of Cloning Attacks on SGX Applications", "comment": "These results were presented at the Learning from Authoritative Security Experiment Results (LASER) Workshop 2023 and extend the paper \"No Forking Way: Detecting Cloning Attacks on Intel SGX Applications\", published in the Proceedings of the 39th Annual Computer Security Applications Conference (ACSAC) 2023", "summary": "Trusted Execution Environments (TEEs) are gaining popularity as an effective means to provide confidentiality in the cloud. TEEs, such as Intel SGX, suffer from so-called rollback and cloning attacks (often referred to as forking attacks). Rollback attacks are enabled by the lack of freshness guarantees for sealed data; cloning attacks stem from the inability to determine if other instances of an enclave are running on the same platform. While rollback attacks have been extensively studied by the community, cloning attacks have been, unfortunately, less investigated. To address this gap, we extensively study and thoroughly analyze the susceptibility of 72 SGX-based proposals to cloning attacks. Our results show that roughly 20% of the analyzed proposals are insecure against cloning attacks-including those applications that rely on monotonic counters and are, therefore, secure against rollback attacks.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u7ea620%\u7684SGX\u63d0\u6848\u6613\u53d7\u514b\u9686\u653b\u51fb\uff0c\u5305\u62ec\u4f9d\u8d56\u5355\u8c03\u8ba1\u6570\u5668\u7684\u5e94\u7528", "motivation": "\u53ef\u4fe1\u6267\u884c\u73af\u5883\uff08TEEs\uff09\u5982Intel SGX\u5b58\u5728\u56de\u6eda\u548c\u514b\u9686\u653b\u51fb\u6f0f\u6d1e\u3002\u867d\u7136\u56de\u6eda\u653b\u51fb\u5df2\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u514b\u9686\u653b\u51fb\u7814\u7a76\u8f83\u5c11\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7a7a\u767d", "method": "\u5bf972\u4e2a\u57fa\u4e8eSGX\u7684\u63d0\u6848\u8fdb\u884c\u5e7f\u6cdb\u7814\u7a76\u548c\u6df1\u5165\u5206\u6790\uff0c\u8bc4\u4f30\u5176\u5bf9\u514b\u9686\u653b\u51fb\u7684\u8106\u5f31\u6027", "result": "\u7ea620%\u7684\u5206\u6790\u63d0\u6848\u5bf9\u514b\u9686\u653b\u51fb\u4e0d\u5b89\u5168\uff0c\u5305\u62ec\u90a3\u4e9b\u4f9d\u8d56\u5355\u8c03\u8ba1\u6570\u5668\u4e14\u5bf9\u56de\u6eda\u653b\u51fb\u5b89\u5168\u7684\u5e94\u7528\u7a0b\u5e8f", "conclusion": "\u514b\u9686\u653b\u51fb\u662fSGX\u5b89\u5168\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u5a01\u80c1\uff0c\u9700\u8981\u66f4\u591a\u5173\u6ce8\u548c\u7814\u7a76\uff0c\u5373\u4f7f\u4f7f\u7528\u5355\u8c03\u8ba1\u6570\u5668\u4e5f\u4e0d\u80fd\u5b8c\u5168\u9632\u6b62\u514b\u9686\u653b\u51fb"}}
{"id": "2601.09171", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.09171", "abs": "https://arxiv.org/abs/2601.09171", "authors": ["Dohyun Kim", "Sanggu Han", "Sangmin Woo", "Joonha Jang", "Jaehoon Kim", "Changhun Song", "Yongdae Kim"], "title": "SafePlanner: Testing Safety of the Automated Driving System Plan Model", "comment": null, "summary": "In this work, we present SafePlanner, a systematic testing framework for identifying safety-critical flaws in the Plan model of Automated Driving Systems (ADS). SafePlanner targets two core challenges: generating structurally meaningful test scenarios and detecting hazardous planning behaviors. To maximize coverage, SafePlanner performs a structural analysis of the Plan model implementation - specifically, its scene-transition logic and hierarchical control flow - and uses this insight to extract feasible scene transitions from code. It then composes test scenarios by combining these transitions with non-player vehicle (NPC) behaviors. Guided fuzzing is applied to explore the behavioral space of the Plan model under these scenarios. We evaluate SafePlanner on Baidu Apollo, a production-grade level 4 ADS. It generates 20635 test cases and detects 520 hazardous behaviors, grouped into 15 root causes through manual analysis. For four of these, we applied patches based on our analysis; the issues disappeared, and no apparent side effects were observed. SafePlanner achieves 83.63 percent function and 63.22 percent decision coverage on the Plan model, outperforming baselines in both bug discovery and efficiency.", "AI": {"tldr": "SafePlanner\u662f\u4e00\u4e2a\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u89c4\u5212\u6a21\u578b\u5b89\u5168\u6d4b\u8bd5\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5206\u6790\u548c\u5f15\u5bfc\u5f0f\u6a21\u7cca\u6d4b\u8bd5\u53d1\u73b0\u5b89\u5168\u5173\u952e\u7f3a\u9677\uff0c\u5728\u767e\u5ea6Apollo\u4e0a\u68c0\u6d4b\u5230520\u4e2a\u5371\u9669\u884c\u4e3a", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u89c4\u5212\u6a21\u578b\u7684\u5b89\u5168\u5173\u952e\u7f3a\u9677\u8bc6\u522b\u9700\u8981\u7cfb\u7edf\u5316\u7684\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u4f20\u7edf\u6d4b\u8bd5\u65b9\u6cd5\u5728\u751f\u6210\u6709\u610f\u4e49\u6d4b\u8bd5\u573a\u666f\u548c\u68c0\u6d4b\u5371\u9669\u89c4\u5212\u884c\u4e3a\u65b9\u9762\u5b58\u5728\u4e0d\u8db3", "method": "\u5bf9\u89c4\u5212\u6a21\u578b\u5b9e\u73b0\u8fdb\u884c\u7ed3\u6784\u5206\u6790\uff0c\u63d0\u53d6\u53ef\u884c\u7684\u573a\u666f\u8f6c\u6362\uff0c\u7ed3\u5408NPC\u884c\u4e3a\u7ec4\u5408\u6d4b\u8bd5\u573a\u666f\uff0c\u5e94\u7528\u5f15\u5bfc\u5f0f\u6a21\u7cca\u6d4b\u8bd5\u63a2\u7d22\u89c4\u5212\u6a21\u578b\u7684\u884c\u4e3a\u7a7a\u95f4", "result": "\u5728\u767e\u5ea6Apollo\u4e0a\u751f\u621020635\u4e2a\u6d4b\u8bd5\u7528\u4f8b\uff0c\u68c0\u6d4b\u5230520\u4e2a\u5371\u9669\u884c\u4e3a\uff0c\u5f52\u4e3a15\u4e2a\u6839\u672c\u539f\u56e0\uff0c\u4fee\u590d4\u4e2a\u95ee\u9898\u540e\u65e0\u526f\u4f5c\u7528\uff0c\u8fbe\u523083.63%\u51fd\u6570\u8986\u76d6\u7387\u548c63.22%\u51b3\u7b56\u8986\u76d6\u7387", "conclusion": "SafePlanner\u80fd\u6709\u6548\u8bc6\u522b\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u89c4\u5212\u6a21\u578b\u7684\u5b89\u5168\u7f3a\u9677\uff0c\u5728\u9519\u8bef\u53d1\u73b0\u548c\u6d4b\u8bd5\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e3aADS\u5b89\u5168\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u6846\u67b6"}}
{"id": "2601.09113", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09113", "abs": "https://arxiv.org/abs/2601.09113", "authors": ["Zixia Jia", "Jiaqi Li", "Yipeng Kang", "Yuxuan Wang", "Tong Wu", "Quansen Wang", "Xiaobo Wang", "Shuyi Zhang", "Junzhe Shen", "Qing Li", "Siyuan Qi", "Yitao Liang", "Di He", "Zilong Zheng", "Song-Chun Zhu"], "title": "The AI Hippocampus: How Far are We From Human Memory?", "comment": null, "summary": "Memory plays a foundational role in augmenting the reasoning, adaptability, and contextual fidelity of modern Large Language Models and Multi-Modal LLMs. As these models transition from static predictors to interactive systems capable of continual learning and personalized inference, the incorporation of memory mechanisms has emerged as a central theme in their architectural and functional evolution. This survey presents a comprehensive and structured synthesis of memory in LLMs and MLLMs, organizing the literature into a cohesive taxonomy comprising implicit, explicit, and agentic memory paradigms. Specifically, the survey delineates three primary memory frameworks. Implicit memory refers to the knowledge embedded within the internal parameters of pre-trained transformers, encompassing their capacity for memorization, associative retrieval, and contextual reasoning. Recent work has explored methods to interpret, manipulate, and reconfigure this latent memory. Explicit memory involves external storage and retrieval components designed to augment model outputs with dynamic, queryable knowledge representations, such as textual corpora, dense vectors, and graph-based structures, thereby enabling scalable and updatable interaction with information sources. Agentic memory introduces persistent, temporally extended memory structures within autonomous agents, facilitating long-term planning, self-consistency, and collaborative behavior in multi-agent systems, with relevance to embodied and interactive AI. Extending beyond text, the survey examines the integration of memory within multi-modal settings, where coherence across vision, language, audio, and action modalities is essential. Key architectural advances, benchmark tasks, and open challenges are discussed, including issues related to memory capacity, alignment, factual consistency, and cross-system interoperability.", "AI": {"tldr": "\u8be5\u7efc\u8ff0\u7cfb\u7edf\u6027\u5730\u56de\u987e\u4e86LLMs\u548cMLLMs\u4e2d\u7684\u8bb0\u5fc6\u673a\u5236\uff0c\u5c06\u5176\u5206\u4e3a\u9690\u5f0f\u3001\u663e\u5f0f\u548c\u667a\u80fd\u4f53\u8bb0\u5fc6\u4e09\u5927\u8303\u5f0f\uff0c\u5e76\u63a2\u8ba8\u4e86\u591a\u6a21\u6001\u73af\u5883\u4e0b\u7684\u8bb0\u5fc6\u6574\u5408\u53ca\u5f53\u524d\u6311\u6218\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u9759\u6001\u9884\u6d4b\u5668\u5411\u80fd\u591f\u6301\u7eed\u5b66\u4e60\u548c\u4e2a\u6027\u5316\u63a8\u7406\u7684\u4ea4\u4e92\u7cfb\u7edf\u8f6c\u53d8\uff0c\u8bb0\u5fc6\u673a\u5236\u5df2\u6210\u4e3a\u5176\u67b6\u6784\u548c\u529f\u80fd\u6f14\u8fdb\u7684\u6838\u5fc3\u4e3b\u9898\u3002\u9700\u8981\u5168\u9762\u68b3\u7406\u8bb0\u5fc6\u5728LLMs\u548cMLLMs\u4e2d\u7684\u4f5c\u7528\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u7ed3\u6784\u5316\u6846\u67b6\u3002", "method": "\u91c7\u7528\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5c06\u73b0\u6709\u7814\u7a76\u7ec4\u7ec7\u6210\u7edf\u4e00\u7684\u5206\u7c7b\u4f53\u7cfb\uff1a1) \u9690\u5f0f\u8bb0\u5fc6\uff08\u9884\u8bad\u7ec3transformer\u5185\u90e8\u53c2\u6570\u4e2d\u7684\u77e5\u8bc6\uff09\uff1b2) \u663e\u5f0f\u8bb0\u5fc6\uff08\u5916\u90e8\u5b58\u50a8\u548c\u68c0\u7d22\u7ec4\u4ef6\uff09\uff1b3) \u667a\u80fd\u4f53\u8bb0\u5fc6\uff08\u81ea\u4e3b\u667a\u80fd\u4f53\u4e2d\u7684\u6301\u4e45\u6027\u8bb0\u5fc6\u7ed3\u6784\uff09\u3002\u540c\u65f6\u6269\u5c55\u5230\u591a\u6a21\u6001\u73af\u5883\u4e0b\u7684\u8bb0\u5fc6\u6574\u5408\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b\u4e09\u5927\u8bb0\u5fc6\u8303\u5f0f\u7684\u5b8c\u6574\u5206\u7c7b\u4f53\u7cfb\uff1a\u9690\u5f0f\u8bb0\u5fc6\u6db5\u76d6\u6a21\u578b\u5185\u90e8\u7684\u77e5\u8bc6\u5d4c\u5165\u548c\u5173\u8054\u68c0\u7d22\u80fd\u529b\uff1b\u663e\u5f0f\u8bb0\u5fc6\u901a\u8fc7\u5916\u90e8\u5b58\u50a8\u5b9e\u73b0\u52a8\u6001\u77e5\u8bc6\u66f4\u65b0\uff1b\u667a\u80fd\u4f53\u8bb0\u5fc6\u652f\u6301\u957f\u671f\u89c4\u5212\u548c\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u3002\u8bc6\u522b\u4e86\u591a\u6a21\u6001\u8bb0\u5fc6\u6574\u5408\u7684\u5173\u952e\u9700\u6c42\u3002", "conclusion": "\u8bb0\u5fc6\u673a\u5236\u5bf9\u4e8e\u589e\u5f3aLLMs\u548cMLLMs\u7684\u63a8\u7406\u80fd\u529b\u3001\u9002\u5e94\u6027\u548c\u4e0a\u4e0b\u6587\u4fdd\u771f\u5ea6\u81f3\u5173\u91cd\u8981\u3002\u672a\u6765\u7814\u7a76\u9700\u8981\u89e3\u51b3\u8bb0\u5fc6\u5bb9\u91cf\u3001\u5bf9\u9f50\u3001\u4e8b\u5b9e\u4e00\u81f4\u6027\u3001\u8de8\u7cfb\u7edf\u4e92\u64cd\u4f5c\u6027\u7b49\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u591a\u6a21\u6001\u548c\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2601.09393", "categories": ["cs.SE", "cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.09393", "abs": "https://arxiv.org/abs/2601.09393", "authors": ["Zirui Wang", "Guangba Yu", "Michael R. Lyu"], "title": "AI-NativeBench: An Open-Source White-Box Agentic Benchmark Suite for AI-Native Systems", "comment": null, "summary": "The transition from Cloud-Native to AI-Native architectures is fundamentally reshaping software engineering, replacing deterministic microservices with probabilistic agentic services. However, this shift renders traditional black-box evaluation paradigms insufficient: existing benchmarks measure raw model capabilities while remaining blind to system-level execution dynamics. To bridge this gap, we introduce AI-NativeBench, the first application-centric and white-box AI-Native benchmark suite grounded in Model Context Protocol (MCP) and Agent-to-Agent (A2A) standards. By treating agentic spans as first-class citizens within distributed traces, our methodology enables granular analysis of engineering characteristics beyond simple capabilities. Leveraging this benchmark across 21 system variants, we uncover critical engineering realities invisible to traditional metrics: a parameter paradox where lightweight models often surpass flagships in protocol adherence, a pervasive inference dominance that renders protocol overhead secondary, and an expensive failure pattern where self-healing mechanisms paradoxically act as cost multipliers on unviable workflows. This work provides the first systematic evidence to guide the transition from measuring model capability to engineering reliable AI-Native systems. To facilitate reproducibility and further research, we have open-sourced the benchmark and dataset.", "AI": {"tldr": "AI-NativeBench\uff1a\u9996\u4e2a\u57fa\u4e8eMCP\u548cA2A\u6807\u51c6\u7684\u5e94\u7528\u4e2d\u5fc3\u5316\u767d\u76d2AI\u539f\u751f\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u63ed\u793a\u4f20\u7edf\u9ed1\u76d2\u8bc4\u4f30\u65e0\u6cd5\u53d1\u73b0\u7684\u7cfb\u7edf\u7ea7\u5de5\u7a0b\u7279\u6027", "motivation": "\u4ece\u4e91\u539f\u751f\u5230AI\u539f\u751f\u67b6\u6784\u7684\u8f6c\u578b\u6b63\u5728\u91cd\u5851\u8f6f\u4ef6\u5de5\u7a0b\uff0c\u4f46\u4f20\u7edf\u9ed1\u76d2\u8bc4\u4f30\u8303\u5f0f\u5df2\u4e0d\u8db3\u4ee5\u8bc4\u4f30\u6982\u7387\u6027\u667a\u80fd\u4f53\u670d\u52a1\uff0c\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4ec5\u8861\u91cf\u539f\u59cb\u6a21\u578b\u80fd\u529b\u800c\u5ffd\u89c6\u7cfb\u7edf\u7ea7\u6267\u884c\u52a8\u6001", "method": "\u5f15\u5165AI-NativeBench\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u57fa\u4e8e\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u548c\u667a\u80fd\u4f53\u5230\u667a\u80fd\u4f53\uff08A2A\uff09\u6807\u51c6\uff0c\u5c06\u667a\u80fd\u4f53\u8de8\u5ea6\u4f5c\u4e3a\u5206\u5e03\u5f0f\u8ffd\u8e2a\u4e2d\u7684\u4e00\u7b49\u516c\u6c11\uff0c\u5b9e\u73b0\u8d85\u8d8a\u7b80\u5355\u80fd\u529b\u7684\u7ec6\u7c92\u5ea6\u5de5\u7a0b\u7279\u6027\u5206\u6790", "result": "\u572821\u4e2a\u7cfb\u7edf\u53d8\u4f53\u4e0a\u53d1\u73b0\u4f20\u7edf\u6307\u6807\u65e0\u6cd5\u63ed\u793a\u7684\u5173\u952e\u5de5\u7a0b\u73b0\u5b9e\uff1a\u53c2\u6570\u6096\u8bba\uff08\u8f7b\u91cf\u6a21\u578b\u5728\u534f\u8bae\u9075\u5faa\u4e0a\u5e38\u4f18\u4e8e\u65d7\u8230\u6a21\u578b\uff09\u3001\u666e\u904d\u5b58\u5728\u7684\u63a8\u7406\u4e3b\u5bfc\uff08\u534f\u8bae\u5f00\u9500\u6b21\u8981\uff09\u3001\u6602\u8d35\u5931\u8d25\u6a21\u5f0f\uff08\u81ea\u6108\u673a\u5236\u5728\u4e0d\u53ef\u884c\u5de5\u4f5c\u6d41\u4e0a\u6210\u4e3a\u6210\u672c\u500d\u589e\u5668\uff09", "conclusion": "\u8be5\u5de5\u4f5c\u9996\u6b21\u63d0\u4f9b\u7cfb\u7edf\u5316\u8bc1\u636e\uff0c\u6307\u5bfc\u4ece\u8861\u91cf\u6a21\u578b\u80fd\u529b\u8f6c\u5411\u5de5\u7a0b\u5316\u53ef\u9760AI\u539f\u751f\u7cfb\u7edf\u7684\u8f6c\u578b\uff0c\u5e76\u5f00\u6e90\u57fa\u51c6\u6d4b\u8bd5\u548c\u6570\u636e\u96c6\u4ee5\u4fc3\u8fdb\u53ef\u590d\u73b0\u6027\u548c\u8fdb\u4e00\u6b65\u7814\u7a76"}}
{"id": "2601.09292", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09292", "abs": "https://arxiv.org/abs/2601.09292", "authors": ["Greta Dolcetti", "Giulio Zizzo", "Sergio Maffeis"], "title": "Blue Teaming Function-Calling Agents", "comment": "This work has been accepted to appear at the AAAI 2026 Workshop on Trust and Control in Agentic AI (TrustAgent)", "summary": "We present an experimental evaluation that assesses the robustness of four open source LLMs claiming function-calling capabilities against three different attacks, and we measure the effectiveness of eight different defences. Our results show how these models are not safe by default, and how the defences are not yet employable in real-world scenarios.", "AI": {"tldr": "\u8bc4\u4f30\u56db\u4e2a\u58f0\u79f0\u5177\u5907\u51fd\u6570\u8c03\u7528\u80fd\u529b\u7684\u5f00\u6e90LLM\u5bf9\u4e09\u79cd\u653b\u51fb\u7684\u9c81\u68d2\u6027\uff0c\u6d4b\u8bd5\u516b\u79cd\u9632\u5fa1\u63aa\u65bd\u7684\u6709\u6548\u6027\uff0c\u53d1\u73b0\u6a21\u578b\u9ed8\u8ba4\u4e0d\u5b89\u5168\u4e14\u9632\u5fa1\u63aa\u65bd\u5c1a\u4e0d\u9002\u7528\u4e8e\u5b9e\u9645\u573a\u666f", "motivation": "\u8bc4\u4f30\u58f0\u79f0\u5177\u5907\u51fd\u6570\u8c03\u7528\u80fd\u529b\u7684\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5b89\u5168\u6027\uff0c\u6d4b\u8bd5\u5b83\u4eec\u5bf9\u6076\u610f\u653b\u51fb\u7684\u9c81\u68d2\u6027\uff0c\u4ee5\u53ca\u73b0\u6709\u9632\u5fa1\u63aa\u65bd\u7684\u6709\u6548\u6027", "method": "\u5bf9\u56db\u4e2a\u5f00\u6e90LLM\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u4f7f\u7528\u4e09\u79cd\u4e0d\u540c\u7684\u653b\u51fb\u65b9\u6cd5\u6d4b\u8bd5\u5176\u51fd\u6570\u8c03\u7528\u80fd\u529b\u7684\u5b89\u5168\u6027\uff0c\u5e76\u8bc4\u4f30\u516b\u79cd\u4e0d\u540c\u9632\u5fa1\u63aa\u65bd\u7684\u6709\u6548\u6027", "result": "\u7ed3\u679c\u663e\u793a\u8fd9\u4e9b\u6a21\u578b\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u5e76\u4e0d\u5b89\u5168\uff0c\u73b0\u6709\u7684\u9632\u5fa1\u63aa\u65bd\u5728\u5b9e\u9645\u5e94\u7528\u573a\u666f\u4e2d\u5c1a\u4e0d\u53ef\u7528", "conclusion": "\u5f53\u524d\u58f0\u79f0\u5177\u5907\u51fd\u6570\u8c03\u7528\u80fd\u529b\u7684\u5f00\u6e90LLM\u5b58\u5728\u5b89\u5168\u9690\u60a3\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u5b89\u5168\u673a\u5236\uff0c\u73b0\u6709\u9632\u5fa1\u63aa\u65bd\u9700\u8981\u66f4\u591a\u5f00\u53d1\u624d\u80fd\u9002\u7528\u4e8e\u5b9e\u9645\u90e8\u7f72"}}
{"id": "2601.09182", "categories": ["cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.09182", "abs": "https://arxiv.org/abs/2601.09182", "authors": ["JungMin Yun", "JuneHyoung Kwon", "MiHyeon Kim", "YoungBin Kim"], "title": "Position on LLM-Assisted Peer Review: Addressing Reviewer Gap through Mentoring and Feedback", "comment": "Accepted to AAAI 2026 Workshop on AI for Scientific Research (AI4Research)", "summary": "The rapid expansion of AI research has intensified the Reviewer Gap, threatening the peer-review sustainability and perpetuating a cycle of low-quality evaluations. This position paper critiques existing LLM approaches that automatically generate reviews and argues for a paradigm shift that positions LLMs as tools for assisting and educating human reviewers. We define the core principles of high-quality peer review and propose two complementary systems grounded in these foundations: (i) an LLM-assisted mentoring system that cultivates reviewers' long-term competencies, and (ii) an LLM-assisted feedback system that helps reviewers refine the quality of their reviews. This human-centered approach aims to strengthen reviewer expertise and contribute to building a more sustainable scholarly ecosystem.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4ee5LLM\u8f85\u52a9\u4eba\u7c7b\u5ba1\u7a3f\u4eba\u7684\u65b0\u8303\u5f0f\uff0c\u800c\u975e\u81ea\u52a8\u751f\u6210\u5ba1\u7a3f\u610f\u89c1\uff0c\u65e8\u5728\u89e3\u51b3AI\u7814\u7a76\u5feb\u901f\u53d1\u5c55\u5bfc\u81f4\u7684\"\u5ba1\u7a3f\u4eba\u7f3a\u53e3\"\u95ee\u9898\uff0c\u63d0\u5347\u540c\u884c\u8bc4\u5ba1\u7684\u53ef\u6301\u7eed\u6027\u3002", "motivation": "AI\u7814\u7a76\u7684\u5feb\u901f\u6269\u5f20\u52a0\u5267\u4e86\"\u5ba1\u7a3f\u4eba\u7f3a\u53e3\"\uff0c\u5a01\u80c1\u540c\u884c\u8bc4\u5ba1\u7684\u53ef\u6301\u7eed\u6027\uff0c\u5e76\u5bfc\u81f4\u4f4e\u8d28\u91cf\u8bc4\u5ba1\u7684\u6076\u6027\u5faa\u73af\u3002\u73b0\u6709LLM\u81ea\u52a8\u751f\u6210\u5ba1\u7a3f\u610f\u89c1\u7684\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u5c06LLM\u5b9a\u4f4d\u4e3a\u8f85\u52a9\u548c\u6559\u80b2\u4eba\u7c7b\u5ba1\u7a3f\u4eba\u7684\u5de5\u5177\u3002\u57fa\u4e8e\u9ad8\u8d28\u91cf\u540c\u884c\u8bc4\u5ba1\u7684\u6838\u5fc3\u539f\u5219\uff0c\u8bbe\u8ba1\u4e86\u4e24\u4e2a\u4e92\u8865\u7cfb\u7edf\uff1aLLM\u8f85\u52a9\u7684\u5bfc\u5e08\u7cfb\u7edf\uff08\u57f9\u517b\u5ba1\u7a3f\u4eba\u957f\u671f\u80fd\u529b\uff09\u548cLLM\u8f85\u52a9\u7684\u53cd\u9988\u7cfb\u7edf\uff08\u5e2e\u52a9\u5ba1\u7a3f\u4eba\u6539\u8fdb\u8bc4\u5ba1\u8d28\u91cf\uff09\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\u548c\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u6848\uff0c\u4f46\u672a\u63d0\u4f9b\u5177\u4f53\u7684\u5b9e\u9a8c\u7ed3\u679c\u3002\u8be5\u65b9\u6848\u65e8\u5728\u901a\u8fc7\u589e\u5f3a\u5ba1\u7a3f\u4eba\u4e13\u4e1a\u80fd\u529b\u6765\u6784\u5efa\u66f4\u53ef\u6301\u7eed\u7684\u5b66\u672f\u751f\u6001\u7cfb\u7edf\u3002", "conclusion": "\u9700\u8981\u4eceLLM\u81ea\u52a8\u751f\u6210\u8bc4\u5ba1\u5411LLM\u8f85\u52a9\u4eba\u7c7b\u5ba1\u7a3f\u4eba\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u901a\u8fc7\u57f9\u517b\u5ba1\u7a3f\u4eba\u80fd\u529b\u548c\u6539\u8fdb\u8bc4\u5ba1\u8d28\u91cf\u6765\u5e94\u5bf9\u5ba1\u7a3f\u4eba\u7f3a\u53e3\uff0c\u5efa\u7acb\u66f4\u53ef\u6301\u7eed\u7684\u5b66\u672f\u8bc4\u5ba1\u4f53\u7cfb\u3002"}}
{"id": "2601.09321", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.09321", "abs": "https://arxiv.org/abs/2601.09321", "authors": ["Zhiyi Mou", "Jingyuan Yang", "Zeheng Qian", "Wangze Ni", "Tianfang Xiao", "Ning Liu", "Chen Zhang", "Zhan Qin", "Kui Ren"], "title": "SpatialJB: How Text Distribution Art Becomes the \"Jailbreak Key\" for LLM Guardrails", "comment": null, "summary": "While Large Language Models (LLMs) have powerful capabilities, they remain vulnerable to jailbreak attacks, which is a critical barrier to their safe web real-time application. Current commercial LLM providers deploy output guardrails to filter harmful outputs, yet these defenses are not impenetrable. Due to LLMs' reliance on autoregressive, token-by-token inference, their semantic representations lack robustness to spatially structured perturbations, such as redistributing tokens across different rows, columns, or diagonals. Exploiting the Transformer's spatial weakness, we propose SpatialJB to disrupt the model's output generation process, allowing harmful content to bypass guardrails without detection. Comprehensive experiments conducted on leading LLMs get nearly 100% ASR, demonstrating the high effectiveness of SpatialJB. Even after adding advanced output guardrails, like the OpenAI Moderation API, SpatialJB consistently maintains a success rate exceeding 75%, outperforming current jailbreak techniques by a significant margin. The proposal of SpatialJB exposes a key weakness in current guardrails and emphasizes the importance of spatial semantics, offering new insights to advance LLM safety research. To prevent potential misuse, we also present baseline defense strategies against SpatialJB and evaluate their effectiveness in mitigating such attacks. The code for the attack, baseline defenses, and a demo are available at https://anonymous.4open.science/r/SpatialJailbreak-8E63.", "AI": {"tldr": "SpatialJB\u662f\u4e00\u79cd\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b0\u578b\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528Transformer\u67b6\u6784\u5bf9\u7a7a\u95f4\u7ed3\u6784\u6270\u52a8\u7684\u8106\u5f31\u6027\uff0c\u91cd\u65b0\u5206\u914dtoken\u5728\u4e0d\u540c\u884c\u3001\u5217\u6216\u5bf9\u89d2\u7ebf\u4e0a\u7684\u4f4d\u7f6e\uff0c\u6210\u529f\u7ed5\u8fc7\u8f93\u51fa\u9632\u62a4\u673a\u5236\uff0c\u5b9e\u73b0\u63a5\u8fd1100%\u7684\u653b\u51fb\u6210\u529f\u7387\u3002", "motivation": "\u5f53\u524d\u5546\u4e1aLLM\u63d0\u4f9b\u5546\u90e8\u7f72\u7684\u8f93\u51fa\u9632\u62a4\u673a\u5236\u5e76\u975e\u4e0d\u53ef\u7a7f\u900f\uff0cLLM\u7531\u4e8e\u4f9d\u8d56\u81ea\u56de\u5f52\u7684token-by-token\u63a8\u7406\uff0c\u5176\u8bed\u4e49\u8868\u793a\u5bf9\u7a7a\u95f4\u7ed3\u6784\u6270\u52a8\u7f3a\u4e4f\u9c81\u68d2\u6027\u3002\u7814\u7a76\u8005\u5e0c\u671b\u5229\u7528Transformer\u7684\u7a7a\u95f4\u5f31\u70b9\u6765\u7834\u574f\u6a21\u578b\u7684\u8f93\u51fa\u751f\u6210\u8fc7\u7a0b\uff0c\u8ba9\u6709\u5bb3\u5185\u5bb9\u7ed5\u8fc7\u9632\u62a4\u673a\u5236\u800c\u4e0d\u88ab\u68c0\u6d4b\u3002", "method": "\u63d0\u51faSpatialJB\u653b\u51fb\u65b9\u6cd5\uff0c\u5229\u7528Transformer\u67b6\u6784\u5bf9\u7a7a\u95f4\u7ed3\u6784\u6270\u52a8\u7684\u8106\u5f31\u6027\uff0c\u901a\u8fc7\u91cd\u65b0\u5206\u914dtoken\u5728\u4e0d\u540c\u884c\u3001\u5217\u6216\u5bf9\u89d2\u7ebf\u4e0a\u7684\u4f4d\u7f6e\u6765\u7834\u574f\u6a21\u578b\u7684\u8f93\u51fa\u751f\u6210\u8fc7\u7a0b\uff0c\u4ece\u800c\u7ed5\u8fc7\u8f93\u51fa\u9632\u62a4\u673a\u5236\u3002", "result": "\u5728\u4e3b\u6d41LLM\u4e0a\u7684\u7efc\u5408\u5b9e\u9a8c\u83b7\u5f97\u4e86\u63a5\u8fd1100%\u7684\u653b\u51fb\u6210\u529f\u7387\uff08ASR\uff09\u3002\u5373\u4f7f\u5728\u6dfb\u52a0\u4e86OpenAI Moderation API\u7b49\u9ad8\u7ea7\u8f93\u51fa\u9632\u62a4\u673a\u5236\u540e\uff0cSpatialJB\u4ecd\u80fd\u4fdd\u6301\u8d85\u8fc775%\u7684\u6210\u529f\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u5f53\u524d\u7684\u8d8a\u72f1\u6280\u672f\u3002", "conclusion": "SpatialJB\u66b4\u9732\u4e86\u5f53\u524d\u9632\u62a4\u673a\u5236\u7684\u5173\u952e\u5f31\u70b9\uff0c\u5f3a\u8c03\u4e86\u7a7a\u95f4\u8bed\u4e49\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u63a8\u8fdbLLM\u5b89\u5168\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002\u4e3a\u9632\u6b62\u6f5c\u5728\u6ee5\u7528\uff0c\u7814\u7a76\u8005\u8fd8\u63d0\u51fa\u4e86\u9488\u5bf9SpatialJB\u7684\u57fa\u7ebf\u9632\u5fa1\u7b56\u7565\u5e76\u8bc4\u4f30\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2601.09456", "categories": ["cs.SE", "cs.DL"], "pdf": "https://arxiv.org/pdf/2601.09456", "abs": "https://arxiv.org/abs/2601.09456", "authors": ["Stephan Ferenz", "Oliver Werth", "Astrid Nie\u00dfe"], "title": "Towards a Metadata Schema for Energy Research Software", "comment": null, "summary": "Domain-specific metadata schemas are essential to improve the findability and reusability of research software and to follow the FAIR4RS principles. However, many domains, including energy research, lack established metadata schemas. To address this gap, we developed a metadata schema for energy research software based on a requirement analysis and evaluated it through user testing. Our results show that the schema balances the need for formalization and interoperability, while also meeting the specific needs of energy researchers. Meanwhile, the testing showed that a good presentation of the required information is key to enable researchers to create the required metadata. This paper provides insights into the challenges and opportunities of designing a metadata schema for energy research software.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u80fd\u6e90\u7814\u7a76\u8f6f\u4ef6\u7684\u5143\u6570\u636e\u6a21\u5f0f\uff0c\u901a\u8fc7\u9700\u6c42\u5206\u6790\u548c\u7528\u6237\u6d4b\u8bd5\u9a8c\u8bc1\uff0c\u8be5\u6a21\u5f0f\u5728\u5f62\u5f0f\u5316\u3001\u4e92\u64cd\u4f5c\u6027\u548c\u9886\u57df\u7279\u5b9a\u9700\u6c42\u4e4b\u95f4\u53d6\u5f97\u4e86\u5e73\u8861\u3002", "motivation": "\u8bb8\u591a\u9886\u57df\uff08\u5305\u62ec\u80fd\u6e90\u7814\u7a76\uff09\u7f3a\u4e4f\u6210\u719f\u7684\u5143\u6570\u636e\u6a21\u5f0f\uff0c\u8fd9\u5f71\u54cd\u4e86\u7814\u7a76\u8f6f\u4ef6\u7684\u53ef\u53d1\u73b0\u6027\u548c\u53ef\u91cd\u7528\u6027\uff0c\u4e5f\u4e0d\u7b26\u5408FAIR4RS\u539f\u5219\u3002\u9700\u8981\u4e3a\u80fd\u6e90\u7814\u7a76\u8f6f\u4ef6\u5f00\u53d1\u4e13\u95e8\u7684\u5143\u6570\u636e\u6a21\u5f0f\u6765\u89e3\u51b3\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u57fa\u4e8e\u9700\u6c42\u5206\u6790\u5f00\u53d1\u4e86\u80fd\u6e90\u7814\u7a76\u8f6f\u4ef6\u7684\u5143\u6570\u636e\u6a21\u5f0f\uff0c\u5e76\u901a\u8fc7\u7528\u6237\u6d4b\u8bd5\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5f00\u53d1\u7684\u5143\u6570\u636e\u6a21\u5f0f\u5728\u5f62\u5f0f\u5316\u3001\u4e92\u64cd\u4f5c\u6027\u548c\u80fd\u6e90\u7814\u7a76\u4eba\u5458\u7684\u7279\u5b9a\u9700\u6c42\u4e4b\u95f4\u53d6\u5f97\u4e86\u5e73\u8861\u3002\u6d4b\u8bd5\u8868\u660e\uff0c\u826f\u597d\u7684\u4fe1\u606f\u5448\u73b0\u65b9\u5f0f\u662f\u7814\u7a76\u4eba\u5458\u521b\u5efa\u6240\u9700\u5143\u6570\u636e\u7684\u5173\u952e\u3002", "conclusion": "\u672c\u6587\u4e3a\u8bbe\u8ba1\u80fd\u6e90\u7814\u7a76\u8f6f\u4ef6\u5143\u6570\u636e\u6a21\u5f0f\u63d0\u4f9b\u4e86\u6311\u6218\u548c\u673a\u9047\u7684\u89c1\u89e3\uff0c\u5f3a\u8c03\u4e86\u5728\u5f62\u5f0f\u5316\u9700\u6c42\u548c\u7528\u6237\u53cb\u597d\u6027\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.09259", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09259", "abs": "https://arxiv.org/abs/2601.09259", "authors": ["Jian Zhang", "Zhiyuan Wang", "Zhangqi Wang", "Yu He", "Haoran Luo", "li yuan", "Lingling Zhang", "Rui Mao", "Qika Lin", "Jun Liu"], "title": "MAXS: Meta-Adaptive Exploration with LLM Agents", "comment": null, "summary": "Large Language Model (LLM) Agents exhibit inherent reasoning abilities through the collaboration of multiple tools. However, during agent inference, existing methods often suffer from (i) locally myopic generation, due to the absence of lookahead, and (ii) trajectory instability, where minor early errors can escalate into divergent reasoning paths. These issues make it difficult to balance global effectiveness and computational efficiency. To address these two issues, we propose meta-adaptive exploration with LLM agents https://github.com/exoskeletonzj/MAXS, a meta-adaptive reasoning framework based on LLM Agents that flexibly integrates tool execution and reasoning planning. MAXS employs a lookahead strategy to extend reasoning paths a few steps ahead, estimating the advantage value of tool usage, and combines step consistency variance and inter-step trend slopes to jointly select stable, consistent, and high-value reasoning steps. Additionally, we introduce a trajectory convergence mechanism that controls computational cost by halting further rollouts once path consistency is achieved, enabling a balance between resource efficiency and global effectiveness in multi-tool reasoning. We conduct extensive empirical studies across three base models (MiMo-VL-7B, Qwen2.5-VL-7B, Qwen2.5-VL-32B) and five datasets, demonstrating that MAXS consistently outperforms existing methods in both performance and inference efficiency. Further analysis confirms the effectiveness of our lookahead strategy and tool usage.", "AI": {"tldr": "MAXS\u662f\u4e00\u4e2a\u57fa\u4e8eLLM Agent\u7684\u5143\u81ea\u9002\u5e94\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u524d\u77bb\u7b56\u7565\u548c\u8f68\u8ff9\u6536\u655b\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2d\u5c40\u90e8\u77ed\u89c6\u548c\u8f68\u8ff9\u4e0d\u7a33\u5b9a\u7684\u95ee\u9898\uff0c\u5728\u6027\u80fd\u548c\u63a8\u7406\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709LLM Agent\u63a8\u7406\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u7531\u4e8e\u7f3a\u4e4f\u524d\u77bb\u6027\u5bfc\u81f4\u5c40\u90e8\u77ed\u89c6\u751f\u6210\uff1b2\uff09\u8f68\u8ff9\u4e0d\u7a33\u5b9a\uff0c\u65e9\u671f\u5fae\u5c0f\u9519\u8bef\u4f1a\u6f14\u53d8\u6210\u53d1\u6563\u63a8\u7406\u8def\u5f84\u3002\u8fd9\u4e9b\u95ee\u9898\u4f7f\u5f97\u96be\u4ee5\u5e73\u8861\u5168\u5c40\u6709\u6548\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u63d0\u51faMAXS\u6846\u67b6\uff0c\u91c7\u7528\u524d\u77bb\u7b56\u7565\u5411\u524d\u6269\u5c55\u63a8\u7406\u8def\u5f84\u51e0\u6b65\uff0c\u4f30\u8ba1\u5de5\u5177\u4f7f\u7528\u7684\u4f18\u52bf\u503c\uff0c\u7ed3\u5408\u6b65\u9aa4\u4e00\u81f4\u6027\u65b9\u5dee\u548c\u6b65\u9aa4\u95f4\u8d8b\u52bf\u659c\u7387\u8054\u5408\u9009\u62e9\u7a33\u5b9a\u3001\u4e00\u81f4\u4e14\u9ad8\u4ef7\u503c\u7684\u63a8\u7406\u6b65\u9aa4\u3002\u5f15\u5165\u8f68\u8ff9\u6536\u655b\u673a\u5236\uff0c\u5728\u8def\u5f84\u4e00\u81f4\u6027\u8fbe\u5230\u65f6\u505c\u6b62\u8fdb\u4e00\u6b65\u5c55\u5f00\uff0c\u5e73\u8861\u8d44\u6e90\u6548\u7387\u548c\u5168\u5c40\u6709\u6548\u6027\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u7840\u6a21\u578b\uff08MiMo-VL-7B\u3001Qwen2.5-VL-7B\u3001Qwen2.5-VL-32B\uff09\u548c\u4e94\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0cMAXS\u5728\u6027\u80fd\u548c\u63a8\u7406\u6548\u7387\u65b9\u9762\u5747\u4e00\u81f4\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u8bc1\u5b9e\u4e86\u524d\u77bb\u7b56\u7565\u548c\u5de5\u5177\u4f7f\u7528\u7684\u6709\u6548\u6027\u3002", "conclusion": "MAXS\u901a\u8fc7\u5143\u81ea\u9002\u5e94\u63a8\u7406\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86LLM Agent\u63a8\u7406\u4e2d\u7684\u5c40\u90e8\u77ed\u89c6\u548c\u8f68\u8ff9\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u5168\u5c40\u6709\u6548\u6027\u548c\u8ba1\u7b97\u6548\u7387\u7684\u826f\u597d\u5e73\u8861\uff0c\u4e3a\u591a\u5de5\u5177\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.09612", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.09612", "abs": "https://arxiv.org/abs/2601.09612", "authors": ["Khairul Alam", "Banani Roy"], "title": "Analyzing GitHub Issues and Pull Requests in nf-core Pipelines: Insights into nf-core Pipeline Repositories", "comment": "12 pages", "summary": "Scientific Workflow Management Systems (SWfMSs) such as Nextflow have become essential software frameworks for conducting reproducible, scalable, and portable computational analyses in data-intensive fields like genomics, transcriptomics, and proteomics. Building on Nextflow, the nf-core community curates standardized, peer-reviewed pipelines that follow strict testing, documentation, and governance guidelines. Despite its broad adoption, little is known about the challenges users face during the development and maintenance of these pipelines. This paper presents an empirical study of 25,173 issues and pull requests from these pipelines to uncover recurring challenges, management practices, and perceived difficulties. Using BERTopic modeling, we identify 13 key challenges, including pipeline development and integration, bug fixing, integrating genomic data, managing CI configurations, and handling version updates. We then examine issue resolution dynamics, showing that 89.38\\% of issues and pull requests are eventually closed, with half resolved within three days. Statistical analysis reveals that the presence of labels (large effect, $\u03b4$ = 0.94) and code snippets (medium effect, $\u03b4$ = 0.50) significantly improve resolution likelihood. Further analysis reveals that tool development and repository maintenance poses the most significant challenges, followed by testing pipelines and CI configurations, and debugging containerized pipelines. Overall, this study provides actionable insights into the collaborative development and maintenance of nf-core pipelines, highlighting opportunities to enhance their usability, sustainability, and reproducibility.", "AI": {"tldr": "\u5bf9nf-core\u79d1\u5b66\u5de5\u4f5c\u6d41\u7ba1\u9053\u768425,173\u4e2a\u95ee\u9898\u548c\u62c9\u53d6\u8bf7\u6c42\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u8bc6\u522b\u51fa13\u4e2a\u5173\u952e\u6311\u6218\uff0c\u5206\u6790\u89e3\u51b3\u52a8\u6001\uff0c\u53d1\u73b0\u6807\u7b7e\u548c\u4ee3\u7801\u7247\u6bb5\u80fd\u663e\u8457\u63d0\u9ad8\u89e3\u51b3\u6982\u7387\u3002", "motivation": "\u5c3d\u7ba1Nextflow\u548cnf-core\u5728\u6570\u636e\u5bc6\u96c6\u578b\u79d1\u5b66\u9886\u57df\u5e7f\u6cdb\u91c7\u7528\uff0c\u4f46\u7528\u6237\u5728\u8fd9\u4e9b\u7ba1\u9053\u7684\u5f00\u53d1\u548c\u7ef4\u62a4\u8fc7\u7a0b\u4e2d\u9762\u4e34\u7684\u5177\u4f53\u6311\u6218\u5c1a\u4e0d\u6e05\u695a\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u63ed\u793a\u8fd9\u4e9b\u6311\u6218\u3001\u7ba1\u7406\u5b9e\u8df5\u548c\u611f\u77e5\u56f0\u96be\u3002", "method": "\u4f7f\u7528BERTopic\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5\u5206\u679025,173\u4e2a\u95ee\u9898\u548c\u62c9\u53d6\u8bf7\u6c42\uff0c\u8bc6\u522b\u5173\u952e\u6311\u6218\u7c7b\u522b\u3002\u901a\u8fc7\u7edf\u8ba1\u5206\u6790\u95ee\u9898\u89e3\u51b3\u52a8\u6001\uff0c\u5305\u62ec\u89e3\u51b3\u7387\u3001\u89e3\u51b3\u65f6\u95f4\uff0c\u4ee5\u53ca\u6807\u7b7e\u3001\u4ee3\u7801\u7247\u6bb5\u7b49\u56e0\u7d20\u5bf9\u89e3\u51b3\u6982\u7387\u7684\u5f71\u54cd\u3002", "result": "\u8bc6\u522b\u51fa13\u4e2a\u5173\u952e\u6311\u6218\uff0c\u5305\u62ec\u7ba1\u9053\u5f00\u53d1\u4e0e\u96c6\u6210\u3001\u9519\u8bef\u4fee\u590d\u3001\u57fa\u56e0\u7ec4\u6570\u636e\u96c6\u6210\u3001CI\u914d\u7f6e\u7ba1\u7406\u548c\u7248\u672c\u66f4\u65b0\u7b49\u300289.38%\u7684\u95ee\u9898\u548c\u62c9\u53d6\u8bf7\u6c42\u6700\u7ec8\u88ab\u5173\u95ed\uff0c\u534a\u6570\u57283\u5929\u5185\u89e3\u51b3\u3002\u6807\u7b7e\uff08\u5927\u6548\u5e94\uff0c\u03b4=0.94\uff09\u548c\u4ee3\u7801\u7247\u6bb5\uff08\u4e2d\u6548\u5e94\uff0c\u03b4=0.50\uff09\u663e\u8457\u63d0\u9ad8\u89e3\u51b3\u6982\u7387\u3002\u5de5\u5177\u5f00\u53d1\u548c\u4ed3\u5e93\u7ef4\u62a4\u662f\u6700\u5177\u6311\u6218\u6027\u7684\u9886\u57df\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3anf-core\u7ba1\u9053\u7684\u534f\u4f5c\u5f00\u53d1\u548c\u7ef4\u62a4\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\uff0c\u5f3a\u8c03\u4e86\u589e\u5f3a\u5176\u53ef\u7528\u6027\u3001\u53ef\u6301\u7eed\u6027\u548c\u53ef\u91cd\u590d\u6027\u7684\u673a\u4f1a\u3002\u7814\u7a76\u7ed3\u679c\u6709\u52a9\u4e8e\u6539\u8fdb\u79d1\u5b66\u5de5\u4f5c\u6d41\u7ba1\u7406\u7cfb\u7edf\u7684\u5f00\u53d1\u5b9e\u8df5\u3002"}}
{"id": "2601.09260", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09260", "abs": "https://arxiv.org/abs/2601.09260", "authors": ["Yan Liu", "Feng Zhang", "Zhanyu Ma", "Jun Xu", "Jiuchong Gao", "Jinghua Hao", "Renqing He", "Han Liu", "Yangdong Deng"], "title": "Efficient Paths and Dense Rewards: Probabilistic Flow Reasoning for Large Language Models", "comment": null, "summary": "High-quality chain-of-thought has demonstrated strong potential for unlocking the reasoning capabilities of large language models. However, current paradigms typically treat the reasoning process as an indivisible sequence, lacking an intrinsic mechanism to quantify step-wise information gain. This granularity gap manifests in two limitations: inference inefficiency from redundant exploration without explicit guidance, and optimization difficulty due to sparse outcome supervision or costly external verifiers. In this work, we propose CoT-Flow, a framework that reconceptualizes discrete reasoning steps as a continuous probabilistic flow, quantifying the contribution of each step toward the ground-truth answer. Built on this formulation, CoT-Flow enables two complementary methodologies: flow-guided decoding, which employs a greedy flow-based decoding strategy to extract information-efficient reasoning paths, and flow-based reinforcement learning, which constructs a verifier-free dense reward function. Experiments on challenging benchmarks demonstrate that CoT-Flow achieves a superior balance between inference efficiency and reasoning performance.", "AI": {"tldr": "CoT-Flow\uff1a\u5c06\u601d\u7ef4\u94fe\u63a8\u7406\u6b65\u9aa4\u91cd\u65b0\u6982\u5ff5\u5316\u4e3a\u8fde\u7eed\u6982\u7387\u6d41\uff0c\u91cf\u5316\u6bcf\u4e2a\u6b65\u9aa4\u5bf9\u6700\u7ec8\u7b54\u6848\u7684\u8d21\u732e\uff0c\u5b9e\u73b0\u63a8\u7406\u6548\u7387\u4e0e\u6027\u80fd\u7684\u5e73\u8861", "motivation": "\u5f53\u524d\u601d\u7ef4\u94fe\u65b9\u6cd5\u5c06\u63a8\u7406\u8fc7\u7a0b\u89c6\u4e3a\u4e0d\u53ef\u5206\u5272\u7684\u5e8f\u5217\uff0c\u7f3a\u4e4f\u91cf\u5316\u9010\u6b65\u4fe1\u606f\u589e\u76ca\u7684\u5185\u5728\u673a\u5236\uff0c\u5bfc\u81f4\u63a8\u7406\u6548\u7387\u4f4e\u4e0b\uff08\u5197\u4f59\u63a2\u7d22\uff09\u548c\u4f18\u5316\u56f0\u96be\uff08\u7a00\u758f\u76d1\u7763\u6216\u6602\u8d35\u9a8c\u8bc1\u5668\uff09", "method": "\u63d0\u51faCoT-Framework\uff0c\u5c06\u79bb\u6563\u63a8\u7406\u6b65\u9aa4\u91cd\u65b0\u6982\u5ff5\u5316\u4e3a\u8fde\u7eed\u6982\u7387\u6d41\uff0c\u91cf\u5316\u6bcf\u4e2a\u6b65\u9aa4\u5bf9\u771f\u5b9e\u7b54\u6848\u7684\u8d21\u732e\u3002\u57fa\u4e8e\u6b64\u5b9e\u73b0\u4e24\u79cd\u65b9\u6cd5\uff1a\u6d41\u5f15\u5bfc\u89e3\u7801\uff08\u8d2a\u5a6a\u6d41\u89e3\u7801\u7b56\u7565\u63d0\u53d6\u4fe1\u606f\u9ad8\u6548\u63a8\u7406\u8def\u5f84\uff09\u548c\u57fa\u4e8e\u6d41\u7684\u5f3a\u5316\u5b66\u4e60\uff08\u6784\u5efa\u65e0\u9700\u9a8c\u8bc1\u5668\u7684\u5bc6\u96c6\u5956\u52b1\u51fd\u6570\uff09", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCoT-Flow\u5728\u63a8\u7406\u6548\u7387\u548c\u63a8\u7406\u6027\u80fd\u4e4b\u95f4\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u5e73\u8861", "conclusion": "\u901a\u8fc7\u5c06\u63a8\u7406\u6b65\u9aa4\u91cf\u5316\u4e3a\u8fde\u7eed\u6982\u7387\u6d41\uff0cCoT-Flow\u80fd\u591f\u6709\u6548\u6307\u5bfc\u63a8\u7406\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u6548\u7387\u540c\u65f6\u4fdd\u6301\u6027\u80fd\uff0c\u4e3a\u601d\u7ef4\u94fe\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u4f18\u5316\u6846\u67b6"}}
{"id": "2601.09616", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.09616", "abs": "https://arxiv.org/abs/2601.09616", "authors": ["Tarannum Shaila Zaman", "Zhihui Yan", "Chen Wang", "Chadni Islam", "Jiangfan Shi", "Tingting Yu"], "title": "SysPro: Reproducing System-level Concurrency Bugs from Bug Reports", "comment": "Accepted in JSS", "summary": "Reproducing system-level concurrency bugs requires both input data and the precise interleaving order of system calls. This process is challenging because such bugs are non-deterministic, and bug reports often lack the detailed information needed. Additionally, the unstructured nature of reports written in natural language makes it difficult to extract necessary details. Existing tools are inadequate to reproduce these bugs due to their inability to manage the specific interleaving at the system call level. To address these challenges, we propose SysPro, a novel approach that automatically extracts relevant system call names from bug reports and identifies their locations in the source code. It generates input data by utilizing information retrieval, regular expression matching, and the category-partition method. This extracted input and interleaving data are then used to reproduce bugs through dynamic source code instrumentation. Our empirical study on real-world benchmarks demonstrates that SysPro is both effective and efficient at localizing and reproducing system-level concurrency bugs from bug reports.", "AI": {"tldr": "SysPro\uff1a\u4e00\u79cd\u4ecebug\u62a5\u544a\u4e2d\u81ea\u52a8\u63d0\u53d6\u7cfb\u7edf\u8c03\u7528\u4fe1\u606f\u5e76\u751f\u6210\u8f93\u5165\u6570\u636e\u6765\u590d\u73b0\u7cfb\u7edf\u7ea7\u5e76\u53d1bug\u7684\u65b0\u65b9\u6cd5", "motivation": "\u590d\u73b0\u7cfb\u7edf\u7ea7\u5e76\u53d1bug\u9700\u8981\u8f93\u5165\u6570\u636e\u548c\u7cbe\u786e\u7684\u7cfb\u7edf\u8c03\u7528\u4ea4\u9519\u987a\u5e8f\uff0c\u4f46\u7531\u4e8ebug\u7684\u975e\u786e\u5b9a\u6027\u548cbug\u62a5\u544a\u7f3a\u4e4f\u8be6\u7ec6\u4fe1\u606f\uff0c\u8fd9\u4e00\u8fc7\u7a0b\u5177\u6709\u6311\u6218\u6027\u3002\u73b0\u6709\u5de5\u5177\u65e0\u6cd5\u6709\u6548\u5904\u7406\u7cfb\u7edf\u8c03\u7528\u7ea7\u522b\u7684\u7279\u5b9a\u4ea4\u9519\u3002", "method": "SysPro\u901a\u8fc7\u4fe1\u606f\u68c0\u7d22\u3001\u6b63\u5219\u8868\u8fbe\u5f0f\u5339\u914d\u548c\u7c7b\u522b\u5212\u5206\u65b9\u6cd5\uff0c\u81ea\u52a8\u4ecebug\u62a5\u544a\u4e2d\u63d0\u53d6\u76f8\u5173\u7cfb\u7edf\u8c03\u7528\u540d\u79f0\u5e76\u5728\u6e90\u4ee3\u7801\u4e2d\u5b9a\u4f4d\uff0c\u751f\u6210\u8f93\u5165\u6570\u636e\uff0c\u7136\u540e\u901a\u8fc7\u52a8\u6001\u6e90\u4ee3\u7801\u63d2\u6869\u6765\u590d\u73b0bug\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0cSysPro\u5728\u4ecebug\u62a5\u544a\u4e2d\u5b9a\u4f4d\u548c\u590d\u73b0\u7cfb\u7edf\u7ea7\u5e76\u53d1bug\u65b9\u9762\u65e2\u6709\u6548\u53c8\u9ad8\u6548\u3002", "conclusion": "SysPro\u4e3a\u89e3\u51b3\u4ece\u81ea\u7136\u8bed\u8a00bug\u62a5\u544a\u4e2d\u590d\u73b0\u7cfb\u7edf\u7ea7\u5e76\u53d1bug\u7684\u6311\u6218\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u65b9\u6cd5\uff0c\u80fd\u591f\u81ea\u52a8\u63d0\u53d6\u5173\u952e\u4fe1\u606f\u5e76\u6210\u529f\u590d\u73b0\u8fd9\u4e9b\u96be\u4ee5\u5904\u7406\u7684bug\u3002"}}
{"id": "2601.09264", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09264", "abs": "https://arxiv.org/abs/2601.09264", "authors": ["Ziyi Shi", "Xusen Guo", "Hongliang Lu", "Mingxing Peng", "Haotian Wang", "Zheng Zhu", "Zhenning Li", "Yuxuan Liang", "Xinhu Zheng", "Hai Yang"], "title": "Coordinated Pandemic Control with Large Language Model Agents as Policymaking Assistants", "comment": "20pages, 6 figures, a 60-page supporting material pdf file", "summary": "Effective pandemic control requires timely and coordinated policymaking across administrative regions that are intrinsically interdependent. However, human-driven responses are often fragmented and reactive, with policies formulated in isolation and adjusted only after outbreaks escalate, undermining proactive intervention and global pandemic mitigation. To address this challenge, here we propose a large language model (LLM) multi-agent policymaking framework that supports coordinated and proactive pandemic control across regions. Within our framework, each administrative region is assigned an LLM agent as an AI policymaking assistant. The agent reasons over region-specific epidemiological dynamics while communicating with other agents to account for cross-regional interdependencies. By integrating real-world data, a pandemic evolution simulator, and structured inter-agent communication, our framework enables agents to jointly explore counterfactual intervention scenarios and synthesize coordinated policy decisions through a closed-loop simulation process. We validate the proposed framework using state-level COVID-19 data from the United States between April and December 2020, together with real-world mobility records and observed policy interventions. Compared with real-world pandemic outcomes, our approach reduces cumulative infections and deaths by up to 63.7% and 40.1%, respectively, at the individual state level, and by 39.0% and 27.0%, respectively, when aggregated across states. These results demonstrate that LLM multi-agent systems can enable more effective pandemic control with coordinated policymaking...", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u653f\u7b56\u5236\u5b9a\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u8de8\u533a\u57df\u534f\u8c03\u51b3\u7b56\uff0c\u663e\u8457\u964d\u4f4e\u75ab\u60c5\u611f\u67d3\u548c\u6b7b\u4ea1\u4eba\u6570", "motivation": "\u4f20\u7edf\u75ab\u60c5\u63a7\u5236\u653f\u7b56\u5f80\u5f80\u5206\u6563\u3001\u88ab\u52a8\uff0c\u5404\u5730\u533a\u5404\u81ea\u4e3a\u653f\uff0c\u53ea\u5728\u75ab\u60c5\u5347\u7ea7\u540e\u624d\u8c03\u6574\uff0c\u7f3a\u4e4f\u524d\u77bb\u6027\u548c\u534f\u8c03\u6027\uff0c\u5f71\u54cd\u5168\u7403\u75ab\u60c5\u9632\u63a7\u6548\u679c", "method": "\u4e3a\u6bcf\u4e2a\u884c\u653f\u533a\u57df\u5206\u914d\u4e00\u4e2aLLM\u667a\u80fd\u4f53\u4f5c\u4e3aAI\u653f\u7b56\u52a9\u624b\uff0c\u667a\u80fd\u4f53\u57fa\u4e8e\u533a\u57df\u7279\u5b9a\u6d41\u884c\u75c5\u5b66\u52a8\u6001\u8fdb\u884c\u63a8\u7406\uff0c\u540c\u65f6\u4e0e\u5176\u4ed6\u667a\u80fd\u4f53\u901a\u4fe1\u8003\u8651\u8de8\u533a\u57df\u76f8\u4e92\u4f9d\u8d56\uff0c\u6574\u5408\u771f\u5b9e\u4e16\u754c\u6570\u636e\u3001\u75ab\u60c5\u6f14\u5316\u6a21\u62df\u5668\u548c\u7ed3\u6784\u5316\u667a\u80fd\u4f53\u95f4\u901a\u4fe1", "result": "\u4f7f\u7528\u7f8e\u56fd2020\u5e744-12\u6708\u5dde\u7ea7COVID-19\u6570\u636e\u3001\u771f\u5b9e\u79fb\u52a8\u8bb0\u5f55\u548c\u89c2\u5bdf\u5230\u7684\u653f\u7b56\u5e72\u9884\u8fdb\u884c\u9a8c\u8bc1\uff0c\u5728\u5355\u4e2a\u5dde\u5c42\u9762\u5206\u522b\u51cf\u5c11\u7d2f\u8ba1\u611f\u67d3\u548c\u6b7b\u4ea163.7%\u548c40.1%\uff0c\u5728\u8de8\u5dde\u805a\u5408\u5c42\u9762\u5206\u522b\u51cf\u5c1139.0%\u548c27.0%", "conclusion": "LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u80fd\u591f\u901a\u8fc7\u534f\u8c03\u653f\u7b56\u5236\u5b9a\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u75ab\u60c5\u63a7\u5236\uff0c\u4e3a\u8de8\u533a\u57df\u534f\u540c\u51b3\u7b56\u63d0\u4f9b\u65b0\u65b9\u6cd5"}}
{"id": "2601.09407", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.09407", "abs": "https://arxiv.org/abs/2601.09407", "authors": ["Fokke Heikamp", "Lei Pan", "Robin Doss", "Rolando Trujillo-Rasua", "Sushmita Ruj"], "title": "A Systematic Security Analysis for Path-based Traceability Systems in RFID-Enabled Supply Chains", "comment": "28 pages, 6 figures", "summary": "Traceability systems have become prevalent in supply chains because of the rapid development of RFID and IoT technologies. These systems facilitate product recall and mitigate problems such as counterfeiting, tampering, and theft by tracking the manufacturing and distribution life-cycle of a product. Therefore, traceability systems are a defense mechanism against supply chain attacks and, consequently, have become a target for attackers to circumvent. For example, a counterfeiter may change the trace of a fake product for the trace of an authentic product, fooling the system into accepting a counterfeit product as legit and thereby giving a false sense of security.\n  This systematic analysis starts with the observation that security requirements in existing traceability solutions are often unstructured or incomplete, leaving critical vulnerabilities unaddressed. We synthesized the properties of current state-of-the-art traceability solutions within a single security framework that allows us to analyze and compare their security claims. Using this framework, we objectively compared the security of $17$ traceability solutions and identified several weaknesses and vulnerabilities. This article reports on these flaws, the methodology we used to identify them, and the first security evaluation of traceability solutions on a large scale.", "AI": {"tldr": "\u672c\u6587\u5bf9\u4f9b\u5e94\u94fe\u8ffd\u6eaf\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u5206\u6790\uff0c\u53d1\u73b0\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u7684\u5b89\u5168\u9700\u6c42\u5f80\u5f80\u4e0d\u5b8c\u6574\u6216\u7f3a\u4e4f\u7ed3\u6784\u5316\uff0c\u5bfc\u81f4\u5173\u952e\u6f0f\u6d1e\u672a\u88ab\u89e3\u51b3\u3002\u4f5c\u8005\u5efa\u7acb\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u5b89\u5168\u6846\u67b6\u6765\u5206\u6790\u548c\u6bd4\u8f8317\u79cd\u8ffd\u6eaf\u89e3\u51b3\u65b9\u6848\uff0c\u8bc6\u522b\u51fa\u591a\u79cd\u5f31\u70b9\u548c\u6f0f\u6d1e\u3002", "motivation": "\u968f\u7740RFID\u548c\u7269\u8054\u7f51\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u8ffd\u6eaf\u7cfb\u7edf\u5728\u4f9b\u5e94\u94fe\u4e2d\u65e5\u76ca\u666e\u53ca\uff0c\u7528\u4e8e\u4ea7\u54c1\u53ec\u56de\u548c\u9632\u6b62\u5047\u5192\u3001\u7be1\u6539\u3001\u76d7\u7a83\u7b49\u95ee\u9898\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u672c\u8eab\u4e5f\u6210\u4e3a\u653b\u51fb\u8005\u7684\u76ee\u6807\uff0c\u653b\u51fb\u8005\u53ef\u80fd\u901a\u8fc7\u4fee\u6539\u4ea7\u54c1\u8ffd\u6eaf\u4fe1\u606f\u6765\u6b3a\u9a97\u7cfb\u7edf\u3002\u73b0\u6709\u8ffd\u6eaf\u89e3\u51b3\u65b9\u6848\u7684\u5b89\u5168\u9700\u6c42\u5f80\u5f80\u4e0d\u5b8c\u6574\u6216\u7f3a\u4e4f\u7ed3\u6784\u5316\uff0c\u5bfc\u81f4\u5173\u952e\u5b89\u5168\u6f0f\u6d1e\u672a\u88ab\u89e3\u51b3\u3002", "method": "\u4f5c\u8005\u9996\u5148\u89c2\u5bdf\u5230\u73b0\u6709\u8ffd\u6eaf\u89e3\u51b3\u65b9\u6848\u7684\u5b89\u5168\u9700\u6c42\u5f80\u5f80\u4e0d\u5b8c\u6574\u6216\u7f3a\u4e4f\u7ed3\u6784\u5316\u3002\u7136\u540e\uff0c\u4ed6\u4eec\u7efc\u5408\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u8ffd\u6eaf\u89e3\u51b3\u65b9\u6848\u7684\u7279\u6027\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u5b89\u5168\u6846\u67b6\u3002\u4f7f\u7528\u8fd9\u4e2a\u6846\u67b6\uff0c\u4f5c\u8005\u5bf917\u79cd\u8ffd\u6eaf\u89e3\u51b3\u65b9\u6848\u8fdb\u884c\u4e86\u5ba2\u89c2\u6bd4\u8f83\u548c\u5b89\u5168\u5206\u6790\uff0c\u8bc6\u522b\u51fa\u5176\u4e2d\u7684\u5f31\u70b9\u548c\u6f0f\u6d1e\u3002", "result": "\u7814\u7a76\u8bc6\u522b\u4e86\u591a\u79cd\u5b89\u5168\u5f31\u70b9\u548c\u6f0f\u6d1e\uff0c\u8fd9\u662f\u9996\u6b21\u5bf9\u8ffd\u6eaf\u89e3\u51b3\u65b9\u6848\u8fdb\u884c\u5927\u89c4\u6a21\u5b89\u5168\u8bc4\u4f30\u3002\u901a\u8fc7\u7edf\u4e00\u7684\u5b89\u5168\u6846\u67b6\uff0c\u4f5c\u8005\u80fd\u591f\u5ba2\u89c2\u6bd4\u8f83\u4e0d\u540c\u89e3\u51b3\u65b9\u6848\u7684\u5b89\u5168\u6027\uff0c\u5e76\u53d1\u73b0\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u4e2d\u666e\u904d\u5b58\u5728\u7684\u5b89\u5168\u7f3a\u9677\u3002", "conclusion": "\u672c\u6587\u63d0\u4f9b\u4e86\u5bf9\u8ffd\u6eaf\u7cfb\u7edf\u5b89\u5168\u6027\u7684\u7cfb\u7edf\u6027\u5206\u6790\uff0c\u5efa\u7acb\u4e86\u8bc4\u4f30\u6846\u67b6\uff0c\u5e76\u63ed\u793a\u4e86\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u4e2d\u7684\u5b89\u5168\u7f3a\u9677\u3002\u8fd9\u9879\u5de5\u4f5c\u4e3a\u6539\u8fdb\u8ffd\u6eaf\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u5e76\u9996\u6b21\u5728\u5927\u89c4\u6a21\u4e0a\u8bc4\u4f30\u4e86\u8fd9\u4e9b\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2601.09695", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.09695", "abs": "https://arxiv.org/abs/2601.09695", "authors": ["Michael Konstantinou", "Renzo Degiovanni", "Mike Papadakis"], "title": "How well LLM-based test generation techniques perform with newer LLM versions?", "comment": null, "summary": "The rapid evolution of Large Language Models (LLMs) has strongly impacted software engineering, leading to a growing number of studies on automated unit test generation. However, the standalone use of LLMs without post-processing has proven insufficient, often producing tests that fail to compile or achieve high coverage. Several techniques have been proposed to address these issues, reporting improvements in test compilation and coverage. While important, LLM-based test generation techniques have been evaluated against relatively weak baselines (for todays' standards), i.e., old LLM versions and relatively weak prompts, which may exacerbate the performance contribution of the approaches. In other words, stronger (newer) LLMs may obviate any advantage these techniques bring. We investigate this issue by replicating four state-of-the-art LLM-based test generation tools, HITS, SymPrompt, TestSpark, and CoverUp that include engineering components aimed at guiding the test generation process through compilation and execution feedback, and evaluate their relative effectiveness and efficiency over a plain LLM test generation method. We integrate current LLM versions in all approaches and run an experiment on 393 classes and 3,657 methods. Our results show that the plain LLM approach can outperform previous state-of-the-art approaches in all test effectiveness metrics we used: line coverage (by 17.72%), branch coverage (by 19.80%) and mutation score (by 20.92%), and it does so at a comparable cost (LLM queries). We also observe that the granularity at which the plain LLM is applied has a significant impact on the cost. We therefore propose targeting first the program classes, where test generation is more efficient, and then the uncovered methods to reduce the number of LLM requests. This strategy achieves comparable (slightly higher) effectiveness while requiring about 20% fewer LLM requests.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u4efb\u52a1\u4e2d\uff0c\u4f7f\u7528\u6700\u65b0\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u7b80\u5355\u65b9\u6cd5\uff0c\u5728\u6d4b\u8bd5\u8986\u76d6\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u7684\u590d\u6742\u6280\u672f\uff0c\u4e14\u6210\u672c\u76f8\u5f53\u3002", "motivation": "\u5f53\u524dLLM\u9a71\u52a8\u7684\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u6280\u672f\u901a\u5e38\u5305\u542b\u590d\u6742\u7684\u540e\u5904\u7406\u7ec4\u4ef6\uff0c\u4f46\u8fd9\u4e9b\u6280\u672f\u5927\u591a\u57fa\u4e8e\u8f83\u65e7\u7684LLM\u7248\u672c\u8fdb\u884c\u8bc4\u4f30\u3002\u968f\u7740LLM\u80fd\u529b\u7684\u5feb\u901f\u63d0\u5347\uff0c\u8fd9\u4e9b\u590d\u6742\u6280\u672f\u53ef\u80fd\u5df2\u4e0d\u518d\u5fc5\u8981\uff0c\u7b80\u5355\u7684LLM\u65b9\u6cd5\u53ef\u80fd\u5df2\u7ecf\u8db3\u591f\u6709\u6548\u3002", "method": "\u590d\u5236\u4e86\u56db\u79cd\u6700\u5148\u8fdb\u7684LLM\u6d4b\u8bd5\u751f\u6210\u5de5\u5177\uff08HITS\u3001SymPrompt\u3001TestSpark\u3001CoverUp\uff09\uff0c\u5e76\u5c06\u5b83\u4eec\u4e0e\u7b80\u5355\u7684LLM\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\u3002\u5728\u6240\u6709\u65b9\u6cd5\u4e2d\u96c6\u6210\u4e86\u5f53\u524d\u6700\u65b0\u7684LLM\u7248\u672c\uff0c\u5e76\u5728393\u4e2a\u7c7b\u548c3,657\u4e2a\u65b9\u6cd5\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u7b80\u5355\u7684LLM\u65b9\u6cd5\u5728\u6240\u6709\u6d4b\u8bd5\u6709\u6548\u6027\u6307\u6807\u4e0a\u90fd\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff1a\u884c\u8986\u76d6\u7387\u63d0\u9ad817.72%\uff0c\u5206\u652f\u8986\u76d6\u7387\u63d0\u9ad819.80%\uff0c\u53d8\u5f02\u5f97\u5206\u63d0\u9ad820.92%\uff0c\u4e14LLM\u67e5\u8be2\u6210\u672c\u76f8\u5f53\u3002\u7814\u7a76\u8fd8\u53d1\u73b0\uff0c\u5e94\u7528LLM\u7684\u7c92\u5ea6\u5bf9\u6210\u672c\u6709\u663e\u8457\u5f71\u54cd\u3002", "conclusion": "\u968f\u7740LLM\u80fd\u529b\u7684\u63d0\u5347\uff0c\u590d\u6742\u7684\u6d4b\u8bd5\u751f\u6210\u6280\u672f\u53ef\u80fd\u5df2\u4e0d\u518d\u5fc5\u8981\u3002\u5efa\u8bae\u91c7\u7528\u4e24\u9636\u6bb5\u7b56\u7565\uff1a\u9996\u5148\u9488\u5bf9\u7a0b\u5e8f\u7c7b\u751f\u6210\u6d4b\u8bd5\uff08\u6548\u7387\u66f4\u9ad8\uff09\uff0c\u7136\u540e\u9488\u5bf9\u672a\u8986\u76d6\u7684\u65b9\u6cd5\uff0c\u8fd9\u6837\u53ef\u4ee5\u51cf\u5c11\u7ea620%\u7684LLM\u8bf7\u6c42\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u5f53\u7684\u6d4b\u8bd5\u6548\u679c\u3002"}}
{"id": "2601.09269", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09269", "abs": "https://arxiv.org/abs/2601.09269", "authors": ["Wencheng Ye", "Liang Peng", "Xiaoyang Yuan", "Yi Bin", "Pengpeng Zeng", "Hengyu Jin", "Heng Tao Shen"], "title": "RISER: Orchestrating Latent Reasoning Skills for Adaptive Activation Steering", "comment": null, "summary": "Recent work on domain-specific reasoning with large language models (LLMs) often relies on training-intensive approaches that require parameter updates. While activation steering has emerged as a parameter efficient alternative, existing methods apply static, manual interventions that fail to adapt to the dynamic nature of complex reasoning. To address this limitation, we propose RISER (Router-based Intervention for Steerable Enhancement of Reasoning), a plug-and-play intervention framework that adaptively steers LLM reasoning in activation space. RISER constructs a library of reusable reasoning vectors and employs a lightweight Router to dynamically compose them for each input. The Router is optimized via reinforcement learning under task-level rewards, activating latent cognitive primitives in an emergent and compositional manner. Across seven diverse benchmarks, RISER yields 3.4-6.5% average zero-shot accuracy improvements over the base model while surpassing CoT-style reasoning with 2-3x higher token efficiency and robust accuracy gains. Further analysis shows that RISER autonomously combines multiple vectors into interpretable, precise control strategies, pointing toward more controllable and efficient LLM reasoning.", "AI": {"tldr": "RISER\u662f\u4e00\u4e2a\u57fa\u4e8e\u8def\u7531\u5668\u7684\u81ea\u9002\u5e94\u6fc0\u6d3b\u5e72\u9884\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u52a8\u6001\u7ec4\u5408\u53ef\u91cd\u7528\u63a8\u7406\u5411\u91cf\uff0c\u5728\u96f6\u6837\u672c\u573a\u666f\u4e0b\u663e\u8457\u63d0\u5347LLM\u63a8\u7406\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8token\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6fc0\u6d3b\u5e72\u9884\u7684\u65b9\u6cd5\u91c7\u7528\u9759\u6001\u3001\u624b\u52a8\u5e72\u9884\uff0c\u65e0\u6cd5\u9002\u5e94\u590d\u6742\u63a8\u7406\u7684\u52a8\u6001\u7279\u6027\uff0c\u800c\u8bad\u7ec3\u5bc6\u96c6\u578b\u65b9\u6cd5\u9700\u8981\u53c2\u6570\u66f4\u65b0\uff0c\u4e0d\u591f\u9ad8\u6548\u3002\u9700\u8981\u4e00\u79cd\u53c2\u6570\u9ad8\u6548\u4e14\u80fd\u81ea\u9002\u5e94\u52a8\u6001\u63a8\u7406\u7684\u5e72\u9884\u65b9\u6cd5\u3002", "method": "\u63d0\u51faRISER\u6846\u67b6\uff1a1)\u6784\u5efa\u53ef\u91cd\u7528\u63a8\u7406\u5411\u91cf\u5e93\uff1b2)\u4f7f\u7528\u8f7b\u91cf\u7ea7\u8def\u7531\u5668\u52a8\u6001\u7ec4\u5408\u8fd9\u4e9b\u5411\u91cf\uff1b3)\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5728\u4efb\u52a1\u7ea7\u5956\u52b1\u4e0b\u4f18\u5316\u8def\u7531\u5668\uff0c\u4ee5\u6d8c\u73b0\u548c\u7ec4\u5408\u65b9\u5f0f\u6fc0\u6d3b\u6f5c\u5728\u8ba4\u77e5\u57fa\u5143\u3002", "result": "\u57287\u4e2a\u591a\u6837\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRISER\u76f8\u6bd4\u57fa\u7840\u6a21\u578b\u5e73\u5747\u63d0\u53473.4-6.5%\u7684\u96f6\u6837\u672c\u51c6\u786e\u7387\uff0c\u8d85\u8d8aCoT\u98ce\u683c\u63a8\u7406\uff0ctoken\u6548\u7387\u9ad82-3\u500d\uff0c\u4e14\u4fdd\u6301\u7a33\u5065\u7684\u51c6\u786e\u7387\u63d0\u5347\u3002", "conclusion": "RISER\u80fd\u591f\u81ea\u4e3b\u7ec4\u5408\u591a\u4e2a\u5411\u91cf\u5f62\u6210\u53ef\u89e3\u91ca\u7684\u7cbe\u786e\u63a7\u5236\u7b56\u7565\uff0c\u6307\u5411\u66f4\u53ef\u63a7\u548c\u9ad8\u6548\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\uff0c\u5c55\u793a\u4e86\u81ea\u9002\u5e94\u6fc0\u6d3b\u5e72\u9884\u5728\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.09703", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.09703", "abs": "https://arxiv.org/abs/2601.09703", "authors": ["Sicong Liu", "Yanxian Huang", "Mingwei Liu", "Jiachi Chen", "Ensheng Shi", "Yuchi Ma", "Hongyu Zhang", "Yin Zhang", "Yanlin Wang"], "title": "ShortCoder: Knowledge-Augmented Syntax Optimization for Token-Efficient Code Generation", "comment": null, "summary": "Code generation tasks aim to automate the conversion of user requirements into executable code, significantly reducing manual development efforts and enhancing software productivity. The emergence of large language models (LLMs) has significantly advanced code generation, though their efficiency is still impacted by certain inherent architectural constraints. Each token generation necessitates a complete inference pass, requiring persistent retention of contextual information in memory and escalating resource consumption. While existing research prioritizes inference-phase optimizations such as prompt compression and model quantization, the generation phase remains underexplored. To tackle these challenges, we propose a knowledge-infused framework named ShortCoder, which optimizes code generation efficiency while preserving semantic equivalence and readability. In particular, we introduce: (1) ten syntax-level simplification rules for Python, derived from AST-preserving transformations, achieving 18.1% token reduction without functional compromise; (2) a hybrid data synthesis pipeline integrating rule-based rewriting with LLM-guided refinement, producing ShorterCodeBench, a corpus of validated tuples of original code and simplified code with semantic consistency; (3) a fine-tuning strategy that injects conciseness awareness into the base LLMs. Extensive experimental results demonstrate that ShortCoder consistently outperforms state-of-the-art methods on HumanEval, achieving an improvement of 18.1%-37.8% in generation efficiency over previous methods while ensuring the performance of code generation.", "AI": {"tldr": "ShortCoder\u662f\u4e00\u4e2a\u77e5\u8bc6\u6ce8\u5165\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u6cd5\u7ea7\u7b80\u5316\u89c4\u5219\u3001\u6df7\u5408\u6570\u636e\u5408\u6210\u548c\u5fae\u8c03\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u8bed\u4e49\u7b49\u4ef7\u548c\u53ef\u8bfb\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u663e\u8457\u63d0\u5347\u4ee3\u7801\u751f\u6210\u6548\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5176\u6548\u7387\u53d7\u5230\u67b6\u6784\u9650\u5236\u7684\u5f71\u54cd\u3002\u6bcf\u4e2atoken\u751f\u6210\u90fd\u9700\u8981\u5b8c\u6574\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u9700\u8981\u6301\u7eed\u4fdd\u7559\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u589e\u52a0\u4e86\u8d44\u6e90\u6d88\u8017\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u63a8\u7406\u9636\u6bb5\u7684\u4f18\u5316\uff08\u5982\u63d0\u793a\u538b\u7f29\u548c\u6a21\u578b\u91cf\u5316\uff09\uff0c\u800c\u751f\u6210\u9636\u6bb5\u7684\u7814\u7a76\u76f8\u5bf9\u4e0d\u8db3\u3002", "method": "1. \u63d0\u51fa\u4e8610\u4e2a\u57fa\u4e8eAST\u4fdd\u6301\u8f6c\u6362\u7684Python\u8bed\u6cd5\u7ea7\u7b80\u5316\u89c4\u5219\uff0c\u5b9e\u73b018.1%\u7684token\u51cf\u5c11\u800c\u4e0d\u5f71\u54cd\u529f\u80fd\uff1b2. \u8bbe\u8ba1\u4e86\u6df7\u5408\u6570\u636e\u5408\u6210\u7ba1\u9053\uff0c\u7ed3\u5408\u57fa\u4e8e\u89c4\u5219\u7684\u6539\u5199\u548cLLM\u5f15\u5bfc\u7684\u7ec6\u5316\uff0c\u521b\u5efa\u4e86ShorterCodeBench\u8bed\u6599\u5e93\uff1b3. \u5f00\u53d1\u4e86\u5c06\u7b80\u6d01\u6027\u610f\u8bc6\u6ce8\u5165\u57fa\u7840LLM\u7684\u5fae\u8c03\u7b56\u7565\u3002", "result": "ShortCoder\u5728HumanEval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5728\u786e\u4fdd\u4ee3\u7801\u751f\u6210\u6027\u80fd\u7684\u540c\u65f6\uff0c\u76f8\u6bd4\u5148\u524d\u65b9\u6cd5\u5b9e\u73b0\u4e8618.1%-37.8%\u7684\u751f\u6210\u6548\u7387\u63d0\u5347\u3002", "conclusion": "ShortCoder\u6846\u67b6\u901a\u8fc7\u8bed\u6cd5\u7b80\u5316\u3001\u6570\u636e\u5408\u6210\u548c\u6a21\u578b\u5fae\u8c03\u7684\u6709\u6548\u7ed3\u5408\uff0c\u5728\u4fdd\u6301\u8bed\u4e49\u7b49\u4ef7\u548c\u53ef\u8bfb\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u751f\u6210\u7684\u6548\u7387\uff0c\u4e3a\u89e3\u51b3LLM\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u8d44\u6e90\u6d88\u8017\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2601.09274", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09274", "abs": "https://arxiv.org/abs/2601.09274", "authors": ["Jian Zhang", "Yu He", "Zhiyuan Wang", "Zhangqi Wang", "Kai He", "Fangzhi Xu", "Qika Lin", "Jun Liu"], "title": "$A^3$-Bench: Benchmarking Memory-Driven Scientific Reasoning via Anchor and Attractor Activation", "comment": null, "summary": "Scientific reasoning relies not only on logical inference but also on activating prior knowledge and experiential structures. Memory can efficiently reuse knowledge and enhance reasoning consistency and stability. However, existing benchmarks mainly evaluate final answers or step-by-step coherence, overlooking the \\textit{memory-driven} mechanisms that underlie human reasoning, which involves activating anchors and attractors, then integrating them into multi-step inference. To address this gap, we propose $A^3$-Bench~ https://a3-bench.github.io, a benchmark designed to evaluate scientific reasoning through dual-scale memory-driven activation, grounded in Anchor and Attractor Activation. First, we annotate 2,198 science reasoning problems across domains using the SAPM process(subject, anchor & attractor, problem, and memory developing). Second, we introduce a dual-scale memory evaluation framework utilizing anchors and attractors, along with the AAUI(Anchor--Attractor Utilization Index) metric to measure memory activation rates. Finally, through experiments with various base models and paradigms, we validate $A^3$-Bench and analyze how memory activation impacts reasoning performance, providing insights into memory-driven scientific reasoning.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86A\u00b3-Bench\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u79d1\u5b66\u63a8\u7406\u4e2d\u7684\u8bb0\u5fc6\u9a71\u52a8\u673a\u5236\uff0c\u91cd\u70b9\u5173\u6ce8\u951a\u70b9\u548c\u5438\u5f15\u5b50\u7684\u6fc0\u6d3b\u4e0e\u5229\u7528\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u8bc4\u4f30\u6700\u7ec8\u7b54\u6848\u6216\u9010\u6b65\u63a8\u7406\u7684\u8fde\u8d2f\u6027\uff0c\u4f46\u5ffd\u89c6\u4e86\u4eba\u7c7b\u63a8\u7406\u4e2d\u57fa\u4e8e\u8bb0\u5fc6\u9a71\u52a8\u7684\u673a\u5236\uff0c\u5373\u6fc0\u6d3b\u951a\u70b9\u548c\u5438\u5f15\u5b50\u5e76\u5c06\u5176\u6574\u5408\u5230\u591a\u6b65\u63a8\u7406\u4e2d\u7684\u8fc7\u7a0b\u3002", "method": "1) \u4f7f\u7528SAPM\u8fc7\u7a0b\uff08\u4e3b\u9898\u3001\u951a\u70b9\u4e0e\u5438\u5f15\u5b50\u3001\u95ee\u9898\u3001\u8bb0\u5fc6\u53d1\u5c55\uff09\u6807\u6ce8\u4e862,198\u4e2a\u8de8\u9886\u57df\u7684\u79d1\u5b66\u63a8\u7406\u95ee\u9898\uff1b2) \u5f15\u5165\u57fa\u4e8e\u951a\u70b9\u548c\u5438\u5f15\u5b50\u7684\u53cc\u5c3a\u5ea6\u8bb0\u5fc6\u8bc4\u4f30\u6846\u67b6\uff1b3) \u63d0\u51faAAUI\uff08\u951a\u70b9-\u5438\u5f15\u5b50\u5229\u7528\u6307\u6570\uff09\u6307\u6807\u6765\u8861\u91cf\u8bb0\u5fc6\u6fc0\u6d3b\u7387\u3002", "result": "\u901a\u8fc7\u591a\u79cd\u57fa\u7840\u6a21\u578b\u548c\u8303\u5f0f\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86A\u00b3-Bench\u7684\u6709\u6548\u6027\uff0c\u5e76\u5206\u6790\u4e86\u8bb0\u5fc6\u6fc0\u6d3b\u5982\u4f55\u5f71\u54cd\u63a8\u7406\u6027\u80fd\uff0c\u4e3a\u8bb0\u5fc6\u9a71\u52a8\u7684\u79d1\u5b66\u63a8\u7406\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u79d1\u5b66\u63a8\u7406\u8bc4\u4f30\u4e2d\u8bb0\u5fc6\u9a71\u52a8\u673a\u5236\u7684\u7a7a\u767d\uff0c\u63d0\u51fa\u7684A\u00b3-Bench\u57fa\u51c6\u548c\u8bc4\u4f30\u6846\u67b6\u80fd\u591f\u6709\u6548\u8861\u91cf\u6a21\u578b\u5728\u79d1\u5b66\u63a8\u7406\u4e2d\u6fc0\u6d3b\u548c\u5229\u7528\u5148\u9a8c\u77e5\u8bc6\u7684\u80fd\u529b\u3002"}}
{"id": "2601.09282", "categories": ["cs.AI", "cs.DC", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.09282", "abs": "https://arxiv.org/abs/2601.09282", "authors": ["Leszek Sliwko", "Jolanta Mizeria-Pietraszko"], "title": "Cluster Workload Allocation: Semantic Soft Affinity Using Natural Language Processing", "comment": null, "summary": "Cluster workload allocation often requires complex configurations, creating a usability gap. This paper introduces a semantic, intent-driven scheduling paradigm for cluster systems using Natural Language Processing. The system employs a Large Language Model (LLM) integrated via a Kubernetes scheduler extender to interpret natural language allocation hint annotations for soft affinity preferences. A prototype featuring a cluster state cache and an intent analyzer (using AWS Bedrock) was developed. Empirical evaluation demonstrated high LLM parsing accuracy (>95% Subset Accuracy on an evaluation ground-truth dataset) for top-tier models like Amazon Nova Pro/Premier and Mistral Pixtral Large, significantly outperforming a baseline engine. Scheduling quality tests across six scenarios showed the prototype achieved superior or equivalent placement compared to standard Kubernetes configurations, particularly excelling in complex and quantitative scenarios and handling conflicting soft preferences. The results validate using LLMs for accessible scheduling but highlight limitations like synchronous LLM latency, suggesting asynchronous processing for production readiness. This work confirms the viability of semantic soft affinity for simplifying workload orchestration.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7684\u8bed\u4e49\u5316\u3001\u610f\u56fe\u9a71\u52a8\u7684\u96c6\u7fa4\u8c03\u5ea6\u8303\u5f0f\uff0c\u901a\u8fc7LLM\u89e3\u6790\u81ea\u7136\u8bed\u8a00\u5206\u914d\u63d0\u793a\uff0c\u5b9e\u73b0\u7b80\u5316\u7684Kubernetes\u5de5\u4f5c\u8d1f\u8f7d\u7f16\u6392\u3002", "motivation": "\u96c6\u7fa4\u5de5\u4f5c\u8d1f\u8f7d\u5206\u914d\u901a\u5e38\u9700\u8981\u590d\u6742\u7684\u914d\u7f6e\uff0c\u5b58\u5728\u53ef\u7528\u6027\u5dee\u8ddd\u3002\u4f20\u7edf\u8c03\u5ea6\u914d\u7f6e\u5bf9\u7528\u6237\u4e0d\u53cb\u597d\uff0c\u9700\u8981\u7b80\u5316\u96c6\u7fa4\u7cfb\u7edf\u7684\u914d\u7f6e\u548c\u4f7f\u7528\u3002", "method": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u901a\u8fc7Kubernetes\u8c03\u5ea6\u5668\u6269\u5c55\u5668\u96c6\u6210\uff0c\u89e3\u91ca\u81ea\u7136\u8bed\u8a00\u5206\u914d\u63d0\u793a\u6ce8\u91ca\u4ee5\u5b9e\u73b0\u8f6f\u4eb2\u548c\u6027\u504f\u597d\u3002\u5f00\u53d1\u4e86\u539f\u578b\u7cfb\u7edf\uff0c\u5305\u62ec\u96c6\u7fa4\u72b6\u6001\u7f13\u5b58\u548c\u610f\u56fe\u5206\u6790\u5668\uff08\u4f7f\u7528AWS Bedrock\uff09\u3002", "result": "LLM\u89e3\u6790\u51c6\u786e\u7387\u9ad8\uff08\u5728\u8bc4\u4f30\u6570\u636e\u96c6\u4e0a>95%\u5b50\u96c6\u51c6\u786e\u7387\uff09\uff0cAmazon Nova Pro/Premier\u548cMistral Pixtral Large\u7b49\u9876\u7ea7\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u5f15\u64ce\u3002\u5728\u516d\u4e2a\u573a\u666f\u7684\u8c03\u5ea6\u8d28\u91cf\u6d4b\u8bd5\u4e2d\uff0c\u539f\u578b\u7cfb\u7edf\u5b9e\u73b0\u4e86\u4f18\u4e8e\u6216\u7b49\u540c\u4e8e\u6807\u51c6Kubernetes\u914d\u7f6e\u7684\u653e\u7f6e\u6548\u679c\uff0c\u5728\u590d\u6742\u548c\u5b9a\u91cf\u573a\u666f\u4ee5\u53ca\u5904\u7406\u51b2\u7a81\u8f6f\u504f\u597d\u65b9\u9762\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u7ed3\u679c\u9a8c\u8bc1\u4e86\u4f7f\u7528LLM\u8fdb\u884c\u53ef\u8bbf\u95ee\u8c03\u5ea6\u7684\u53ef\u884c\u6027\uff0c\u4f46\u6307\u51fa\u4e86\u540c\u6b65LLM\u5ef6\u8fdf\u7b49\u9650\u5236\uff0c\u5efa\u8bae\u91c7\u7528\u5f02\u6b65\u5904\u7406\u4ee5\u5b9e\u73b0\u751f\u4ea7\u5c31\u7eea\u3002\u8fd9\u9879\u5de5\u4f5c\u786e\u8ba4\u4e86\u8bed\u4e49\u8f6f\u4eb2\u548c\u6027\u5728\u7b80\u5316\u5de5\u4f5c\u8d1f\u8f7d\u7f16\u6392\u65b9\u9762\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2601.09281", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09281", "abs": "https://arxiv.org/abs/2601.09281", "authors": ["Jingjing Zhou", "Gaoxiang Cong", "Li Su", "Liang Li"], "title": "STaR: Sensitive Trajectory Regulation for Unlearning in Large Reasoning Models", "comment": null, "summary": "Large Reasoning Models (LRMs) have advanced automated multi-step reasoning, but their ability to generate complex Chain-of-Thought (CoT) trajectories introduces severe privacy risks, as sensitive information may be deeply embedded throughout the reasoning process. Existing Large Language Models (LLMs) unlearning approaches that typically focus on modifying only final answers are insufficient for LRMs, as they fail to remove sensitive content from intermediate steps, leading to persistent privacy leakage and degraded security. To address these challenges, we propose Sensitive Trajectory Regulation (STaR), a parameter-free, inference-time unlearning framework that achieves robust privacy protection throughout the reasoning process. Specifically, we first identify sensitive content via semantic-aware detection. Then, we inject global safety constraints through secure prompt prefix. Next, we perform trajectory-aware suppression to dynamically block sensitive content across the entire reasoning chain. Finally, we apply token-level adaptive filtering to prevent both exact and paraphrased sensitive tokens during generation. Furthermore, to overcome the inadequacies of existing evaluation protocols, we introduce two metrics: Multi-Decoding Consistency Assessment (MCS), which measures the consistency of unlearning across diverse decoding strategies, and Multi-Granularity Membership Inference Attack (MIA) Evaluation, which quantifies privacy protection at both answer and reasoning-chain levels. Experiments on the R-TOFU benchmark demonstrate that STaR achieves comprehensive and stable unlearning with minimal utility loss, setting a new standard for privacy-preserving reasoning in LRMs.", "AI": {"tldr": "STaR\u662f\u4e00\u4e2a\u9488\u5bf9\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u53c2\u6570\u65e0\u5173\u3001\u63a8\u7406\u65f6\u9057\u5fd8\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u68c0\u6d4b\u3001\u5b89\u5168\u63d0\u793a\u524d\u7f00\u3001\u8f68\u8ff9\u611f\u77e5\u6291\u5236\u548c\u81ea\u9002\u5e94\u8fc7\u6ee4\uff0c\u5728\u63a8\u7406\u94fe\u4e2d\u5168\u9762\u4fdd\u62a4\u9690\u79c1\uff0c\u540c\u65f6\u5f15\u5165\u65b0\u7684\u8bc4\u4f30\u6307\u6807MCS\u548cMIA\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u80fd\u591f\u751f\u6210\u590d\u6742\u7684\u601d\u7ef4\u94fe\u8f68\u8ff9\uff0c\u4f46\u8fd9\u5f15\u5165\u4e86\u4e25\u91cd\u7684\u9690\u79c1\u98ce\u9669\uff0c\u654f\u611f\u4fe1\u606f\u53ef\u80fd\u6df1\u5d4c\u4e8e\u63a8\u7406\u8fc7\u7a0b\u4e2d\u3002\u73b0\u6709\u7684LLM\u9057\u5fd8\u65b9\u6cd5\u901a\u5e38\u53ea\u4fee\u6539\u6700\u7ec8\u7b54\u6848\uff0c\u65e0\u6cd5\u4ece\u4e2d\u95f4\u6b65\u9aa4\u4e2d\u79fb\u9664\u654f\u611f\u5185\u5bb9\uff0c\u5bfc\u81f4\u6301\u7eed\u7684\u9690\u79c1\u6cc4\u9732\u548c\u5b89\u5168\u964d\u7ea7\u3002", "method": "STaR\u6846\u67b6\u5305\u542b\u56db\u4e2a\u6b65\u9aa4\uff1a1\uff09\u901a\u8fc7\u8bed\u4e49\u611f\u77e5\u68c0\u6d4b\u8bc6\u522b\u654f\u611f\u5185\u5bb9\uff1b2\uff09\u901a\u8fc7\u5b89\u5168\u63d0\u793a\u524d\u7f00\u6ce8\u5165\u5168\u5c40\u5b89\u5168\u7ea6\u675f\uff1b3\uff09\u6267\u884c\u8f68\u8ff9\u611f\u77e5\u6291\u5236\uff0c\u52a8\u6001\u963b\u6b62\u6574\u4e2a\u63a8\u7406\u94fe\u4e2d\u7684\u654f\u611f\u5185\u5bb9\uff1b4\uff09\u5e94\u7528\u4ee4\u724c\u7ea7\u81ea\u9002\u5e94\u8fc7\u6ee4\uff0c\u9632\u6b62\u751f\u6210\u7cbe\u786e\u548c\u8f6c\u8ff0\u7684\u654f\u611f\u4ee4\u724c\u3002", "result": "\u5728R-TOFU\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSTaR\u5b9e\u73b0\u4e86\u5168\u9762\u4e14\u7a33\u5b9a\u7684\u9057\u5fd8\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6700\u5c0f\u7684\u6548\u7528\u635f\u5931\uff0c\u4e3aLRMs\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u63a8\u7406\u8bbe\u7acb\u4e86\u65b0\u6807\u51c6\u3002", "conclusion": "STaR\u662f\u4e00\u4e2a\u6709\u6548\u7684\u63a8\u7406\u65f6\u9057\u5fd8\u6846\u67b6\uff0c\u80fd\u591f\u5728\u5927\u89c4\u6a21\u63a8\u7406\u6a21\u578b\u4e2d\u63d0\u4f9b\u5168\u9762\u7684\u9690\u79c1\u4fdd\u62a4\uff0c\u540c\u65f6\u5f15\u5165\u4e86\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6307\u6807\u6765\u91cf\u5316\u9690\u79c1\u4fdd\u62a4\u6548\u679c\u3002"}}
{"id": "2601.09503", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09503", "abs": "https://arxiv.org/abs/2601.09503", "authors": ["Siyuan Liu", "Hongbang Yuan", "Xinze Li", "Ziyue Zhu", "Yixin Cao", "Yu-Gang Jiang"], "title": "What Do LLM Agents Know About Their World? Task2Quiz: A Paradigm for Studying Environment Understanding", "comment": null, "summary": "Large language model (LLM) agents have demonstrated remarkable capabilities in complex decision-making and tool-use tasks, yet their ability to generalize across varying environments remains a under-examined concern. Current evaluation paradigms predominantly rely on trajectory-based metrics that measure task success, while failing to assess whether agents possess a grounded, transferable model of the environment. To address this gap, we propose Task-to-Quiz (T2Q), a deterministic and automated evaluation paradigm designed to decouple task execution from world-state understanding. We instantiate this paradigm in T2QBench, a suite comprising 30 environments and 1,967 grounded QA pairs across multiple difficulty levels. Our extensive experiments reveal that task success is often a poor proxy for environment understanding, and that current memory machanism can not effectively help agents acquire a grounded model of the environment. These findings identify proactive exploration and fine-grained state representation as primary bottlenecks, offering a robust foundation for developing more generalizable autonomous agents.", "AI": {"tldr": "\u63d0\u51faT2Q\u8bc4\u4f30\u8303\u5f0f\uff0c\u5c06\u4efb\u52a1\u6267\u884c\u4e0e\u73af\u5883\u7406\u89e3\u89e3\u8026\uff0c\u53d1\u73b0\u4efb\u52a1\u6210\u529f\u4e0d\u80fd\u6709\u6548\u53cd\u6620\u73af\u5883\u7406\u89e3\u80fd\u529b", "motivation": "\u5f53\u524dLLM\u667a\u80fd\u4f53\u8bc4\u4f30\u4e3b\u8981\u4f9d\u8d56\u57fa\u4e8e\u8f68\u8ff9\u7684\u4efb\u52a1\u6210\u529f\u7387\u6307\u6807\uff0c\u4f46\u65e0\u6cd5\u8bc4\u4f30\u667a\u80fd\u4f53\u662f\u5426\u771f\u6b63\u7406\u89e3\u73af\u5883\u6a21\u578b\uff0c\u5b58\u5728\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898", "method": "\u63d0\u51faTask-to-Quiz\uff08T2Q\uff09\u8bc4\u4f30\u8303\u5f0f\uff0c\u521b\u5efaT2QBench\u57fa\u51c6\uff0c\u5305\u542b30\u4e2a\u73af\u5883\u548c1,967\u4e2a\u57fa\u4e8e\u73af\u5883\u7684\u95ee\u7b54\u5bf9\uff0c\u5c06\u4efb\u52a1\u6267\u884c\u4e0e\u73af\u5883\u7406\u89e3\u5206\u79bb\u8bc4\u4f30", "result": "\u5b9e\u9a8c\u8868\u660e\u4efb\u52a1\u6210\u529f\u4e0e\u73af\u5883\u7406\u89e3\u76f8\u5173\u6027\u5f31\uff0c\u5f53\u524d\u8bb0\u5fc6\u673a\u5236\u65e0\u6cd5\u6709\u6548\u5e2e\u52a9\u667a\u80fd\u4f53\u83b7\u5f97\u73af\u5883\u7684\u57fa\u7840\u6a21\u578b\uff0c\u4e3b\u52a8\u63a2\u7d22\u548c\u7ec6\u7c92\u5ea6\u72b6\u6001\u8868\u793a\u662f\u4e3b\u8981\u74f6\u9888", "conclusion": "T2Q\u4e3a\u8bc4\u4f30\u667a\u80fd\u4f53\u73af\u5883\u7406\u89e3\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\uff0c\u63ed\u793a\u4e86\u5f53\u524dLLM\u667a\u80fd\u4f53\u5728\u6cdb\u5316\u80fd\u529b\u4e0a\u7684\u5173\u952e\u74f6\u9888\uff0c\u4e3a\u5f00\u53d1\u66f4\u901a\u7528\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\u5960\u5b9a\u4e86\u57fa\u7840"}}
{"id": "2601.09536", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09536", "abs": "https://arxiv.org/abs/2601.09536", "authors": ["Dongjie Cheng", "Yongqi Li", "Zhixin Ma", "Hongru Cai", "Yupeng Hu", "Wenjie Wang", "Liqiang Nie", "Wenjie Li"], "title": "Omni-R1: Towards the Unified Generative Paradigm for Multimodal Reasoning", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) are making significant progress in multimodal reasoning. Early approaches focus on pure text-based reasoning. More recent studies have incorporated multimodal information into the reasoning steps; however, they often follow a single task-specific reasoning pattern, which limits their generalizability across various multimodal tasks. In fact, there are numerous multimodal tasks requiring diverse reasoning skills, such as zooming in on a specific region or marking an object within an image. To address this, we propose unified generative multimodal reasoning, which unifies diverse multimodal reasoning skills by generating intermediate images during the reasoning process. We instantiate this paradigm with Omni-R1, a two-stage SFT+RL framework featuring perception alignment loss and perception reward, thereby enabling functional image generation. Additionally, we introduce Omni-R1-Zero, which eliminates the need for multimodal annotations by bootstrapping step-wise visualizations from text-only reasoning data. Empirical results show that Omni-R1 achieves unified generative reasoning across a wide range of multimodal tasks, and Omni-R1-Zero can match or even surpass Omni-R1 on average, suggesting a promising direction for generative multimodal reasoning.", "AI": {"tldr": "Omni-R1\u63d0\u51fa\u7edf\u4e00\u751f\u6210\u5f0f\u591a\u6a21\u6001\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u4e2d\u95f4\u56fe\u50cf\u7edf\u4e00\u591a\u79cd\u591a\u6a21\u6001\u63a8\u7406\u6280\u80fd\uff0c\u5305\u542b\u6709\u76d1\u7763\u548c\u65e0\u76d1\u7763\u4e24\u79cd\u5b9e\u73b0\u65b9\u5f0f\u3002", "motivation": "\u73b0\u6709MLLMs\u8981\u4e48\u4e13\u6ce8\u4e8e\u7eaf\u6587\u672c\u63a8\u7406\uff0c\u8981\u4e48\u91c7\u7528\u5355\u4e00\u4efb\u52a1\u7279\u5b9a\u7684\u63a8\u7406\u6a21\u5f0f\uff0c\u9650\u5236\u4e86\u5728\u4e0d\u540c\u591a\u6a21\u6001\u4efb\u52a1\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u3002\u9700\u8981\u7edf\u4e00\u6846\u67b6\u6765\u5904\u7406\u9700\u8981\u591a\u6837\u5316\u63a8\u7406\u6280\u80fd\u7684\u591a\u6a21\u6001\u4efb\u52a1\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u751f\u6210\u5f0f\u591a\u6a21\u6001\u63a8\u7406\u8303\u5f0f\uff0c\u901a\u8fc7\u751f\u6210\u4e2d\u95f4\u56fe\u50cf\u6765\u7edf\u4e00\u591a\u6837\u5316\u63a8\u7406\u6280\u80fd\u3002\u5177\u4f53\u5b9e\u73b0\u5305\u62ec\uff1a1) Omni-R1\uff1a\u4e24\u9636\u6bb5SFT+RL\u6846\u67b6\uff0c\u5305\u542b\u611f\u77e5\u5bf9\u9f50\u635f\u5931\u548c\u611f\u77e5\u5956\u52b1\uff1b2) Omni-R1-Zero\uff1a\u4ece\u7eaf\u6587\u672c\u63a8\u7406\u6570\u636e\u4e2d\u5f15\u5bfc\u751f\u6210\u9010\u6b65\u53ef\u89c6\u5316\uff0c\u65e0\u9700\u591a\u6a21\u6001\u6807\u6ce8\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cOmni-R1\u80fd\u5728\u5e7f\u6cdb\u7684\u591a\u6a21\u6001\u4efb\u52a1\u4e0a\u5b9e\u73b0\u7edf\u4e00\u751f\u6210\u5f0f\u63a8\u7406\uff0c\u800cOmni-R1-Zero\u5728\u5e73\u5747\u6027\u80fd\u4e0a\u80fd\u591f\u5339\u914d\u751a\u81f3\u8d85\u8d8aOmni-R1\u3002", "conclusion": "\u63d0\u51fa\u7684\u7edf\u4e00\u751f\u6210\u5f0f\u591a\u6a21\u6001\u63a8\u7406\u6846\u67b6\u4e3a\u591a\u6a21\u6001\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u7279\u522b\u662f\u65e0\u76d1\u7763\u7684Omni-R1-Zero\u65b9\u6cd5\u5c55\u793a\u4e86\u4ece\u7eaf\u6587\u672c\u6570\u636e\u4e2d\u5b66\u4e60\u591a\u6a21\u6001\u63a8\u7406\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.09667", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.09667", "abs": "https://arxiv.org/abs/2601.09667", "authors": ["Zhiyuan Hu", "Yunhai Hu", "Juncheng Liu", "Shuyue Stella Li", "Yucheng Wang", "Zhen Xu", "See-Kiong Ng", "Anh Tuan Luu", "Xinxing Xu", "Bryan Hooi", "Cynthia Breazeal", "Hae Won Park"], "title": "Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning", "comment": "Work in Progress", "summary": "Multi-agent systems have evolved into practical LLM-driven collaborators for many applications, gaining robustness from diversity and cross-checking. However, multi-agent RL (MARL) training is resource-intensive and unstable: co-adapting teammates induce non-stationarity, and rewards are often sparse and high-variance. Therefore, we introduce \\textbf{Multi-Agent Test-Time Reinforcement Learning (MATTRL)}, a framework that injects structured textual experience into multi-agent deliberation at inference time. MATTRL forms a multi-expert team of specialists for multi-turn discussions, retrieves and integrates test-time experiences, and reaches consensus for final decision-making. We also study credit assignment for constructing a turn-level experience pool, then reinjecting it into the dialogue. Across challenging benchmarks in medicine, math, and education, MATTRL improves accuracy by an average of 3.67\\% over a multi-agent baseline, and by 8.67\\% over comparable single-agent baselines. Ablation studies examine different credit-assignment schemes and provide a detailed comparison of how they affect training outcomes. MATTRL offers a stable, effective and efficient path to distribution-shift-robust multi-agent reasoning without tuning.", "AI": {"tldr": "MATTRL\u6846\u67b6\u901a\u8fc7\u6d4b\u8bd5\u65f6\u5f3a\u5316\u5b66\u4e60\uff0c\u5728\u591a\u667a\u80fd\u4f53\u63a8\u7406\u8fc7\u7a0b\u4e2d\u6ce8\u5165\u7ed3\u6784\u5316\u6587\u672c\u7ecf\u9a8c\uff0c\u63d0\u5347\u51b3\u7b56\u51c6\u786e\u6027\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u867d\u7136\u901a\u8fc7\u591a\u6837\u6027\u548c\u4ea4\u53c9\u9a8c\u8bc1\u83b7\u5f97\u9c81\u68d2\u6027\uff0c\u4f46\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u8d44\u6e90\u5bc6\u96c6\u4e14\u4e0d\u7a33\u5b9a\uff0c\u5b58\u5728\u975e\u5e73\u7a33\u6027\u548c\u7a00\u758f\u9ad8\u65b9\u5dee\u5956\u52b1\u95ee\u9898\u3002", "method": "MATTRL\u6846\u67b6\uff1a1) \u7ec4\u5efa\u591a\u4e13\u5bb6\u56e2\u961f\u8fdb\u884c\u591a\u8f6e\u8ba8\u8bba\uff1b2) \u68c0\u7d22\u5e76\u6574\u5408\u6d4b\u8bd5\u65f6\u7ecf\u9a8c\uff1b3) \u8fbe\u6210\u5171\u8bc6\u8fdb\u884c\u6700\u7ec8\u51b3\u7b56\uff1b\u540c\u65f6\u7814\u7a76\u4fe1\u7528\u5206\u914d\u673a\u5236\u6784\u5efa\u56de\u5408\u7ea7\u7ecf\u9a8c\u6c60\u5e76\u91cd\u65b0\u6ce8\u5165\u5bf9\u8bdd\u3002", "result": "\u5728\u533b\u5b66\u3001\u6570\u5b66\u548c\u6559\u80b2\u7b49\u6311\u6218\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMATTRL\u6bd4\u591a\u667a\u80fd\u4f53\u57fa\u7ebf\u5e73\u5747\u63d0\u53473.67%\u51c6\u786e\u7387\uff0c\u6bd4\u5355\u667a\u80fd\u4f53\u57fa\u7ebf\u63d0\u53478.67%\uff1b\u6d88\u878d\u7814\u7a76\u5206\u6790\u4e86\u4e0d\u540c\u4fe1\u7528\u5206\u914d\u65b9\u6848\u5bf9\u8bad\u7ec3\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "conclusion": "MATTRL\u63d0\u4f9b\u4e86\u4e00\u79cd\u7a33\u5b9a\u3001\u6709\u6548\u4e14\u9ad8\u6548\u7684\u8def\u5f84\uff0c\u65e0\u9700\u8c03\u4f18\u5373\u53ef\u5b9e\u73b0\u5206\u5e03\u504f\u79fb\u9c81\u68d2\u7684\u591a\u667a\u80fd\u4f53\u63a8\u7406\u3002"}}
