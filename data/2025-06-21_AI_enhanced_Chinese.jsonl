{"id": "2506.14913", "categories": ["cs.CR", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.14913", "abs": "https://arxiv.org/abs/2506.14913", "authors": ["Wassim Bouaziz", "Mathurin Videau", "Nicolas Usunier", "El-Mahdi El-Mhamdi"], "title": "Winter Soldier: Backdooring Language Models at Pre-Training with Indirect Data Poisoning", "comment": "18 pages, 12 figures", "summary": "The pre-training of large language models (LLMs) relies on massive text\ndatasets sourced from diverse and difficult-to-curate origins. Although\nmembership inference attacks and hidden canaries have been explored to trace\ndata usage, such methods rely on memorization of training data, which LM\nproviders try to limit. In this work, we demonstrate that indirect data\npoisoning (where the targeted behavior is absent from training data) is not\nonly feasible but also allow to effectively protect a dataset and trace its\nuse. Using gradient-based optimization prompt-tuning, we make a model learn\narbitrary secret sequences: secret responses to secret prompts that are absent\nfrom the training corpus. We validate our approach on language models\npre-trained from scratch and show that less than 0.005% of poisoned tokens are\nsufficient to covertly make a LM learn a secret and detect it with extremely\nhigh confidence ($p < 10^{-55}$) with a theoretically certifiable scheme.\nCrucially, this occurs without performance degradation (on LM benchmarks) and\ndespite secrets never appearing in the training set.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u95f4\u63a5\u6570\u636e\u6295\u6bd2\u65b9\u6cd5\uff0c\u901a\u8fc7\u68af\u5ea6\u4f18\u5316\u7684\u63d0\u793a\u8c03\u4f18\uff0c\u4f7f\u8bed\u8a00\u6a21\u578b\u5b66\u4e60\u79d8\u5bc6\u5e8f\u5217\uff0c\u4ece\u800c\u4fdd\u62a4\u6570\u636e\u96c6\u5e76\u8ffd\u8e2a\u5176\u4f7f\u7528\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u9884\u8bad\u7ec3\u4f9d\u8d56\u4e8e\u96be\u4ee5\u7ba1\u7406\u7684\u5927\u89c4\u6a21\u6587\u672c\u6570\u636e\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u8bad\u7ec3\u6570\u636e\u7684\u8bb0\u5fc6\uff0c\u800c\u6a21\u578b\u63d0\u4f9b\u8005\u8bd5\u56fe\u9650\u5236\u8fd9\u79cd\u8bb0\u5fc6\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u4e00\u79cd\u4e0d\u4f9d\u8d56\u8bb0\u5fc6\u7684\u95f4\u63a5\u6570\u636e\u6295\u6bd2\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u68af\u5ea6\u4f18\u5316\u7684\u63d0\u793a\u8c03\u4f18\u6280\u672f\uff0c\u4f7f\u6a21\u578b\u5b66\u4e60\u8bad\u7ec3\u6570\u636e\u4e2d\u4e0d\u5b58\u5728\u7684\u79d8\u5bc6\u5e8f\u5217\uff08\u79d8\u5bc6\u63d0\u793a\u548c\u79d8\u5bc6\u54cd\u5e94\uff09\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4ec5\u9700\u5c11\u4e8e0.005%\u7684\u6295\u6bd2\u6807\u8bb0\u5373\u53ef\u8ba9\u6a21\u578b\u5b66\u4e60\u79d8\u5bc6\uff0c\u5e76\u4ee5\u6781\u9ad8\u7f6e\u4fe1\u5ea6\uff08p < 10^-55\uff09\u68c0\u6d4b\u5230\u79d8\u5bc6\uff0c\u4e14\u4e0d\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "\u95f4\u63a5\u6570\u636e\u6295\u6bd2\u662f\u4e00\u79cd\u53ef\u884c\u4e14\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u53ef\u7528\u4e8e\u4fdd\u62a4\u6570\u636e\u96c6\u5e76\u8ffd\u8e2a\u5176\u4f7f\u7528\uff0c\u4e14\u4e0d\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2506.14944", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.14944", "abs": "https://arxiv.org/abs/2506.14944", "authors": ["Majid Khabbazian"], "title": "Fair Data Exchange with Constant-Time Proofs", "comment": "13 pages, 0 figures", "summary": "The Fair Data Exchange (FDE) protocol introduced at CCS 2024 offers atomic\npay-per-file transfers with constant-size proofs, but its prover and verifier\nruntimes still scale linearly with the file length n. We collapse these costs\nto essentially constant by viewing the file as a rate-1 Reed-Solomon (RS)\ncodeword, extending it to a lower-rate RS code with constant redundancy,\nencrypting this extended vector, and then proving correctness for only a small\nrandom subset of the resulting ciphertexts; RS decoding repairs any corrupted\nsymbols with negligible failure probability. Our protocol preserves full\nclient- and server-fairness, and adds only a tunable communication redundancy\noverhead.\n  Finally, we patch the elliptic-curve mismatch in the Bitcoin instantiation of\nFDE with a compact zk-SNARK, enabling the entire exchange to run off-chain and\nfalling back to just two on-chain transactions when channels are unavailable.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684Fair Data Exchange\uff08FDE\uff09\u534f\u8bae\uff0c\u901a\u8fc7\u5c06\u6587\u4ef6\u89c6\u4e3aReed-Solomon\uff08RS\uff09\u7801\u5b57\u5e76\u6269\u5c55\u4e3a\u4f4e\u901f\u7387RS\u7801\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8bc1\u660e\u8005\u548c\u9a8c\u8bc1\u8005\u7684\u8fd0\u884c\u65f6\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u516c\u5e73\u6027\u3002", "motivation": "\u73b0\u6709FDE\u534f\u8bae\u7684\u8bc1\u660e\u8005\u548c\u9a8c\u8bc1\u8005\u8fd0\u884c\u65f6\u95f4\u4e0e\u6587\u4ef6\u957f\u5ea6\u7ebf\u6027\u76f8\u5173\uff0c\u6548\u7387\u8f83\u4f4e\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7RS\u7f16\u7801\u548c\u52a0\u5bc6\u6280\u672f\uff0c\u5c06\u8fd0\u884c\u65f6\u95f4\u964d\u81f3\u63a5\u8fd1\u5e38\u6570\u3002", "method": "\u5c06\u6587\u4ef6\u89c6\u4e3a\u901f\u73871\u7684RS\u7801\u5b57\uff0c\u6269\u5c55\u4e3a\u4f4e\u901f\u7387RS\u7801\uff0c\u52a0\u5bc6\u540e\u4ec5\u5bf9\u5c11\u91cf\u968f\u673a\u5bc6\u6587\u5b50\u96c6\u8fdb\u884c\u6b63\u786e\u6027\u8bc1\u660e\uff0c\u5229\u7528RS\u89e3\u7801\u4fee\u590d\u635f\u574f\u7b26\u53f7\u3002", "result": "\u534f\u8bae\u663e\u8457\u964d\u4f4e\u4e86\u8fd0\u884c\u65f6\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5ba2\u6237\u7aef\u548c\u670d\u52a1\u5668\u7684\u516c\u5e73\u6027\uff0c\u4ec5\u589e\u52a0\u4e86\u53ef\u8c03\u7684\u901a\u4fe1\u5197\u4f59\u5f00\u9500\u3002", "conclusion": "\u6539\u8fdb\u540e\u7684FDE\u534f\u8bae\u5728\u6548\u7387\u548c\u516c\u5e73\u6027\u4e0a\u5747\u6709\u663e\u8457\u63d0\u5347\uff0c\u5e76\u901a\u8fc7zk-SNARK\u6280\u672f\u89e3\u51b3\u4e86\u6bd4\u7279\u5e01\u5b9e\u73b0\u4e2d\u7684\u692d\u5706\u66f2\u7ebf\u4e0d\u5339\u914d\u95ee\u9898\u3002"}}
{"id": "2506.14964", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.14964", "abs": "https://arxiv.org/abs/2506.14964", "authors": ["Filip Rezabek", "Jonathan Passerat-Palmbach", "Moe Mahhouk", "Frieder Erdmann", "Andrew Miller"], "title": "Narrowing the Gap between TEEs Threat Model and Deployment Strategies", "comment": null, "summary": "Confidential Virtual Machines (CVMs) provide isolation guarantees for data in\nuse, but their threat model does not include physical level protection and\nside-channel attacks. Therefore, current deployments rely on trusted cloud\nproviders to host the CVMs' underlying infrastructure. However, TEE\nattestations do not provide information about the operator hosting a CVM.\nWithout knowing whether a Trusted Execution Environment (TEE) runs within a\nprovider's infrastructure, a user cannot accurately assess the risks of\nphysical attacks. We observe a misalignment in the threat model where the\nworkloads are protected against other tenants but do not offer end-to-end\nsecurity assurances to external users without relying on cloud providers. The\nattestation should be extended to bind the CVM with the provider. A possible\nsolution can rely on the Protected Platform Identifier (PPID), a unique CPU\nidentifier. However, the implementation details of various TEE manufacturers,\nattestation flows, and providers vary. This makes verification of attestations,\nease of migration, and building applications without relying on a trusted party\nchallenging, highlighting a key limitation that must be addressed for the\nadoption of CVMs. We discuss two points focusing on hardening and extensions of\nTEEs' attestation.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u673a\u5bc6\u865a\u62df\u673a\uff08CVMs\uff09\u5728\u7269\u7406\u4fdd\u62a4\u548c\u4fa7\u4fe1\u9053\u653b\u51fb\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u63d0\u51fa\u9700\u8981\u6269\u5c55TEE\u8ba4\u8bc1\u4ee5\u7ed1\u5b9aCVM\u4e0e\u4e91\u63d0\u4f9b\u5546\uff0c\u5e76\u8ba8\u8bba\u4e86\u89e3\u51b3\u65b9\u6848\u7684\u6311\u6218\u3002", "motivation": "\u5f53\u524dCVMs\u7684\u5a01\u80c1\u6a21\u578b\u672a\u6db5\u76d6\u7269\u7406\u5c42\u4fdd\u62a4\u548c\u4fa7\u4fe1\u9053\u653b\u51fb\uff0c\u7528\u6237\u65e0\u6cd5\u51c6\u786e\u8bc4\u4f30\u7269\u7406\u653b\u51fb\u98ce\u9669\uff0c\u9700\u6539\u8fdb\u8ba4\u8bc1\u673a\u5236\u4ee5\u63d0\u4f9b\u7aef\u5230\u7aef\u5b89\u5168\u4fdd\u969c\u3002", "method": "\u63d0\u51fa\u5229\u7528\u53d7\u4fdd\u62a4\u5e73\u53f0\u6807\u8bc6\u7b26\uff08PPID\uff09\u7ed1\u5b9aCVM\u4e0e\u63d0\u4f9b\u5546\uff0c\u5e76\u8ba8\u8bbaTEE\u8ba4\u8bc1\u7684\u6269\u5c55\u4e0e\u5f3a\u5316\u3002", "result": "\u73b0\u6709TEE\u8ba4\u8bc1\u5b9e\u73b0\u5dee\u5f02\u5927\uff0c\u9a8c\u8bc1\u548c\u8fc1\u79fb\u56f0\u96be\uff0c\u9700\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u4ee5\u63a8\u52a8CVMs\u7684\u91c7\u7528\u3002", "conclusion": "\u9700\u6269\u5c55TEE\u8ba4\u8bc1\u673a\u5236\u4ee5\u7ed1\u5b9aCVM\u4e0e\u63d0\u4f9b\u5546\uff0c\u89e3\u51b3\u5b9e\u73b0\u5dee\u5f02\u5e26\u6765\u7684\u6311\u6218\uff0c\u63d0\u5347CVMs\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2506.15018", "categories": ["cs.CR", "cs.DS", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15018", "abs": "https://arxiv.org/abs/2506.15018", "authors": ["Ben Jacobsen", "Kassem Fawaz"], "title": "Private Continual Counting of Unbounded Streams", "comment": "12 pages, 2 figures", "summary": "We study the problem of differentially private continual counting in the\nunbounded setting where the input size $n$ is not known in advance. Current\nstate-of-the-art algorithms based on optimal instantiations of the matrix\nmechanism cannot be directly applied here because their privacy guarantees only\nhold when key parameters are tuned to $n$. Using the common `doubling trick'\navoids knowledge of $n$ but leads to suboptimal and non-smooth error. We solve\nthis problem by introducing novel matrix factorizations based on logarithmic\nperturbations of the function $\\frac{1}{\\sqrt{1-z}}$ studied in prior works,\nwhich may be of independent interest. The resulting algorithm has smooth error,\nand for any $\\alpha > 0$ and $t\\leq n$ it is able to privately estimate the sum\nof the first $t$ data points with $O(\\log^{2+2\\alpha}(t))$ variance. It\nrequires $O(t)$ space and amortized $O(\\log t)$ time per round, compared to\n$O(\\log(n)\\log(t))$ variance, $O(n)$ space and $O(n \\log n)$ pre-processing\ntime for the nearly-optimal bounded-input algorithm of Henzinger et al. (SODA\n2023). Empirically, we find that our algorithm's performance is also comparable\nto theirs in absolute terms: our variance is less than $1.5\\times$ theirs for\n$t$ as large as $2^{24}$.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u65e0\u754c\u8bbe\u7f6e\u4e0b\u7684\u5dee\u5206\u9690\u79c1\u8fde\u7eed\u8ba1\u6570\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5bf9\u6570\u6270\u52a8\u7684\u65b0\u578b\u77e9\u9635\u5206\u89e3\u65b9\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8bef\u5dee\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u77e9\u9635\u673a\u5236\u7684\u6700\u4f18\u7b97\u6cd5\u5728\u65e0\u754c\u8bbe\u7f6e\u4e0b\u65e0\u6cd5\u76f4\u63a5\u5e94\u7528\uff0c\u56e0\u4e3a\u5176\u9690\u79c1\u4fdd\u8bc1\u4f9d\u8d56\u4e8e\u9884\u5148\u77e5\u9053\u8f93\u5165\u89c4\u6a21\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u5bf9\u6570\u6270\u52a8\u7684\u65b0\u578b\u77e9\u9635\u5206\u89e3\u65b9\u6cd5\uff0c\u4f18\u5316\u4e86\u8bef\u5dee\u548c\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u7b97\u6cd5\u5728\u65e0\u754c\u8bbe\u7f6e\u4e0b\u5b9e\u73b0\u4e86\u5e73\u6ed1\u8bef\u5dee\uff0c\u65b9\u5dee\u4e3aO(log^{2+2\u03b1}(t))\uff0c\u7a7a\u95f4\u548c\u65f6\u95f4\u590d\u6742\u5ea6\u5206\u522b\u4e3aO(t)\u548cO(log t)\u3002", "conclusion": "\u65b0\u7b97\u6cd5\u5728\u8bef\u5dee\u548c\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u63a5\u8fd1\u6700\u4f18\u3002"}}
{"id": "2506.15207", "categories": ["cs.AI", "cs.MA", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.15207", "abs": "https://arxiv.org/abs/2506.15207", "authors": ["Mohamad A. Hady", "Siyi Hu", "Mahardhika Pratama", "Jimmy Cao", "Ryszard Kowalczyk"], "title": "Multi-Agent Reinforcement Learning for Autonomous Multi-Satellite Earth Observation: A Realistic Case Study", "comment": null, "summary": "The exponential growth of Low Earth Orbit (LEO) satellites has revolutionised\nEarth Observation (EO) missions, addressing challenges in climate monitoring,\ndisaster management, and more. However, autonomous coordination in\nmulti-satellite systems remains a fundamental challenge. Traditional\noptimisation approaches struggle to handle the real-time decision-making\ndemands of dynamic EO missions, necessitating the use of Reinforcement Learning\n(RL) and Multi-Agent Reinforcement Learning (MARL). In this paper, we\ninvestigate RL-based autonomous EO mission planning by modelling\nsingle-satellite operations and extending to multi-satellite constellations\nusing MARL frameworks. We address key challenges, including energy and data\nstorage limitations, uncertainties in satellite observations, and the\ncomplexities of decentralised coordination under partial observability. By\nleveraging a near-realistic satellite simulation environment, we evaluate the\ntraining stability and performance of state-of-the-art MARL algorithms,\nincluding PPO, IPPO, MAPPO, and HAPPO. Our results demonstrate that MARL can\neffectively balance imaging and resource management while addressing\nnon-stationarity and reward interdependency in multi-satellite coordination.\nThe insights gained from this study provide a foundation for autonomous\nsatellite operations, offering practical guidelines for improving policy\nlearning in decentralised EO missions.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u4e3b\u5730\u7403\u89c2\u6d4b\u4efb\u52a1\u89c4\u5212\uff0c\u4ece\u5355\u536b\u661f\u6269\u5c55\u5230\u591a\u536b\u661f\u661f\u5ea7\uff0c\u89e3\u51b3\u4e86\u80fd\u6e90\u3001\u6570\u636e\u5b58\u50a8\u548c\u4e0d\u786e\u5b9a\u6027\u7b49\u6311\u6218\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u4e86\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u4f4e\u5730\u7403\u8f68\u9053\u536b\u661f\u7684\u6fc0\u589e\u63a8\u52a8\u4e86\u5730\u7403\u89c2\u6d4b\u4efb\u52a1\u7684\u53d1\u5c55\uff0c\u4f46\u591a\u536b\u661f\u7cfb\u7edf\u7684\u81ea\u4e3b\u534f\u8c03\u4ecd\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\uff0c\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u96be\u4ee5\u6ee1\u8db3\u5b9e\u65f6\u51b3\u7b56\u9700\u6c42\u3002", "method": "\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u548c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u6a21\u62df\u5355\u536b\u661f\u548c\u591a\u536b\u661f\u64cd\u4f5c\uff0c\u89e3\u51b3\u80fd\u6e90\u3001\u6570\u636e\u5b58\u50a8\u548c\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u95ee\u9898\uff0c\u5e76\u8bc4\u4f30\u4e86\u591a\u79cdMARL\u7b97\u6cd5\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0cMARL\u80fd\u6709\u6548\u5e73\u8861\u6210\u50cf\u548c\u8d44\u6e90\u7ba1\u7406\uff0c\u89e3\u51b3\u591a\u536b\u661f\u534f\u8c03\u4e2d\u7684\u975e\u5e73\u7a33\u6027\u548c\u5956\u52b1\u4f9d\u8d56\u6027\u95ee\u9898\u3002", "conclusion": "\u7814\u7a76\u4e3a\u81ea\u4e3b\u536b\u661f\u64cd\u4f5c\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u5e76\u4e3a\u5206\u6563\u5f0f\u5730\u7403\u89c2\u6d4b\u4efb\u52a1\u7684\u653f\u7b56\u5b66\u4e60\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5357\u3002"}}
{"id": "2506.14866", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14866", "abs": "https://arxiv.org/abs/2506.14866", "authors": ["Thomas Kuntz", "Agatha Duzan", "Hao Zhao", "Francesco Croce", "Zico Kolter", "Nicolas Flammarion", "Maksym Andriushchenko"], "title": "OS-Harm: A Benchmark for Measuring Safety of Computer Use Agents", "comment": null, "summary": "Computer use agents are LLM-based agents that can directly interact with a\ngraphical user interface, by processing screenshots or accessibility trees.\nWhile these systems are gaining popularity, their safety has been largely\noverlooked, despite the fact that evaluating and understanding their potential\nfor harmful behavior is essential for widespread adoption. To address this gap,\nwe introduce OS-Harm, a new benchmark for measuring safety of computer use\nagents. OS-Harm is built on top of the OSWorld environment and aims to test\nmodels across three categories of harm: deliberate user misuse, prompt\ninjection attacks, and model misbehavior. To cover these cases, we create 150\ntasks that span several types of safety violations (harassment, copyright\ninfringement, disinformation, data exfiltration, etc.) and require the agent to\ninteract with a variety of OS applications (email client, code editor, browser,\netc.). Moreover, we propose an automated judge to evaluate both accuracy and\nsafety of agents that achieves high agreement with human annotations (0.76 and\n0.79 F1 score). We evaluate computer use agents based on a range of frontier\nmodels - such as o4-mini, Claude 3.7 Sonnet, Gemini 2.5 Pro - and provide\ninsights into their safety. In particular, all models tend to directly comply\nwith many deliberate misuse queries, are relatively vulnerable to static prompt\ninjections, and occasionally perform unsafe actions. The OS-Harm benchmark is\navailable at https://github.com/tml-epfl/os-harm.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86OS-Harm\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u57fa\u4e8eLLM\u7684\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u7684\u5b89\u5168\u6027\uff0c\u8986\u76d6\u6545\u610f\u6ee5\u7528\u3001\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u548c\u6a21\u578b\u4e0d\u5f53\u884c\u4e3a\u4e09\u7c7b\u5371\u5bb3\u3002", "motivation": "\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u7684\u5b89\u5168\u6027\u88ab\u5ffd\u89c6\uff0c\u4f46\u5176\u6f5c\u5728\u5371\u5bb3\u8bc4\u4f30\u5bf9\u5e7f\u6cdb\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002", "method": "\u6784\u5efaOS-Harm\u57fa\u51c6\uff0c\u5305\u542b150\u4e2a\u4efb\u52a1\u6d4b\u8bd5\u4e09\u7c7b\u5371\u5bb3\uff0c\u5e76\u63d0\u51fa\u81ea\u52a8\u5316\u8bc4\u4f30\u65b9\u6cd5\u3002", "result": "\u6d4b\u8bd5\u663e\u793a\u524d\u6cbf\u6a21\u578b\u6613\u53d7\u6545\u610f\u6ee5\u7528\u548c\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u4e14\u5076\u5c14\u6267\u884c\u4e0d\u5b89\u5168\u884c\u4e3a\u3002", "conclusion": "OS-Harm\u4e3a\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u7684\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u8bc4\u4f30\u5de5\u5177\uff0c\u63ed\u793a\u5176\u6f5c\u5728\u98ce\u9669\u3002"}}
{"id": "2506.14936", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14936", "abs": "https://arxiv.org/abs/2506.14936", "authors": ["Maxwell J. Jacobson", "Corey J. Maley", "Yexiang Xue"], "title": "CALM: Contextual Analog Logic with Multimodality", "comment": null, "summary": "In this work, we introduce Contextual Analog Logic with Multimodality (CALM).\nCALM unites symbolic reasoning with neural generation, enabling systems to make\ncontext-sensitive decisions grounded in real-world multi-modal data.\n  Background: Classic bivalent logic systems cannot capture the nuance of human\ndecision-making. They also require human grounding in multi-modal environments,\nwhich can be ad-hoc, rigid, and brittle. Neural networks are good at extracting\nrich contextual information from multi-modal data, but lack interpretable\nstructures for reasoning.\n  Objectives: CALM aims to bridge the gap between logic and neural perception,\ncreating an analog logic that can reason over multi-modal inputs. Without this\nintegration, AI systems remain either brittle or unstructured, unable to\ngeneralize robustly to real-world tasks. In CALM, symbolic predicates evaluate\nto analog truth values computed by neural networks and constrained search.\n  Methods: CALM represents each predicate using a domain tree, which\niteratively refines its analog truth value when the contextual groundings of\nits entities are determined. The iterative refinement is predicted by neural\nnetworks capable of capturing multi-modal information and is filtered through a\nsymbolic reasoning module to ensure constraint satisfaction.\n  Results: In fill-in-the-blank object placement tasks, CALM achieved 92.2%\naccuracy, outperforming classical logic (86.3%) and LLM (59.4%) baselines. It\nalso demonstrated spatial heatmap generation aligned with logical constraints\nand delicate human preferences, as shown by a human study.\n  Conclusions: CALM demonstrates the potential to reason with logic structure\nwhile aligning with preferences in multi-modal environments. It lays the\nfoundation for next-gen AI systems that require the precision and\ninterpretation of logic and the multimodal information processing of neural\nnetworks.", "AI": {"tldr": "CALM\u7ed3\u5408\u7b26\u53f7\u63a8\u7406\u4e0e\u795e\u7ecf\u751f\u6210\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u6570\u636e\u5b9e\u73b0\u4e0a\u4e0b\u6587\u654f\u611f\u51b3\u7b56\uff0c\u586b\u8865\u903b\u8f91\u4e0e\u795e\u7ecf\u611f\u77e5\u4e4b\u95f4\u7684\u9e3f\u6c9f\u3002", "motivation": "\u7ecf\u5178\u4e8c\u503c\u903b\u8f91\u7cfb\u7edf\u65e0\u6cd5\u6355\u6349\u4eba\u7c7b\u51b3\u7b56\u7684\u7ec6\u5fae\u5dee\u522b\uff0c\u4e14\u5728\u591a\u6a21\u6001\u73af\u5883\u4e2d\u9700\u8981\u4eba\u5de5\u6807\u6ce8\uff0c\u800c\u795e\u7ecf\u7f51\u7edc\u867d\u80fd\u63d0\u53d6\u591a\u6a21\u6001\u6570\u636e\u7684\u4e30\u5bcc\u4fe1\u606f\uff0c\u4f46\u7f3a\u4e4f\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u7ed3\u6784\u3002", "method": "CALM\u901a\u8fc7\u9886\u57df\u6811\u8868\u793a\u8c13\u8bcd\uff0c\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u8fed\u4ee3\u4f18\u5316\u5176\u6a21\u62df\u771f\u503c\uff0c\u5e76\u901a\u8fc7\u7b26\u53f7\u63a8\u7406\u6a21\u5757\u786e\u4fdd\u7ea6\u675f\u6ee1\u8db3\u3002", "result": "\u5728\u586b\u7a7a\u7269\u4f53\u653e\u7f6e\u4efb\u52a1\u4e2d\uff0cCALM\u51c6\u786e\u7387\u8fbe92.2%\uff0c\u4f18\u4e8e\u7ecf\u5178\u903b\u8f91\uff0886.3%\uff09\u548cLLM\u57fa\u7ebf\uff0859.4%\uff09\uff0c\u5e76\u751f\u6210\u7b26\u5408\u903b\u8f91\u7ea6\u675f\u548c\u4eba\u7c7b\u504f\u597d\u7684\u7a7a\u95f4\u70ed\u56fe\u3002", "conclusion": "CALM\u5c55\u793a\u4e86\u5728\u591a\u6a21\u6001\u73af\u5883\u4e2d\u7ed3\u5408\u903b\u8f91\u7ed3\u6784\u4e0e\u504f\u597d\u7684\u6f5c\u529b\uff0c\u4e3a\u4e0b\u4e00\u4ee3AI\u7cfb\u7edf\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2506.15028", "categories": ["cs.CR", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15028", "abs": "https://arxiv.org/abs/2506.15028", "authors": ["Gargi Mitra", "Mohammadreza Hallajiyan", "Inji Kim", "Athish Pranav Dharmalingam", "Mohammed Elnawawy", "Shahrear Iqbal", "Karthik Pattabiraman", "Homa Alemzadeh"], "title": "Systems-Theoretic and Data-Driven Security Analysis in ML-enabled Medical Devices", "comment": "32 pages, 6 figures, 6 tables", "summary": "The integration of AI/ML into medical devices is rapidly transforming\nhealthcare by enhancing diagnostic and treatment facilities. However, this\nadvancement also introduces serious cybersecurity risks due to the use of\ncomplex and often opaque models, extensive interconnectivity, interoperability\nwith third-party peripheral devices, Internet connectivity, and vulnerabilities\nin the underlying technologies. These factors contribute to a broad attack\nsurface and make threat prevention, detection, and mitigation challenging.\nGiven the highly safety-critical nature of these devices, a cyberattack on\nthese devices can cause the ML models to mispredict, thereby posing significant\nsafety risks to patients. Therefore, ensuring the security of these devices\nfrom the time of design is essential. This paper underscores the urgency of\naddressing the cybersecurity challenges in ML-enabled medical devices at the\npre-market phase. We begin by analyzing publicly available data on device\nrecalls and adverse events, and known vulnerabilities, to understand the threat\nlandscape of AI/ML-enabled medical devices and their repercussions on patient\nsafety. Building on this analysis, we introduce a suite of tools and techniques\ndesigned by us to assist security analysts in conducting comprehensive\npremarket risk assessments. Our work aims to empower manufacturers to embed\ncybersecurity as a core design principle in AI/ML-enabled medical devices,\nthereby making them safe for patients.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86AI/ML\u533b\u7597\u8bbe\u5907\u4e2d\u7684\u7f51\u7edc\u5b89\u5168\u98ce\u9669\uff0c\u63d0\u51fa\u4e86\u4e00\u5957\u5de5\u5177\u548c\u65b9\u6cd5\uff0c\u4ee5\u5728\u8bbe\u5907\u4e0a\u5e02\u524d\u8fdb\u884c\u98ce\u9669\u8bc4\u4f30\uff0c\u786e\u4fdd\u60a3\u8005\u5b89\u5168\u3002", "motivation": "AI/ML\u533b\u7597\u8bbe\u5907\u7684\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u4e86\u663e\u8457\u7684\u7f51\u7edc\u5b89\u5168\u98ce\u9669\uff0c\u53ef\u80fd\u5371\u53ca\u60a3\u8005\u5b89\u5168\uff0c\u56e0\u6b64\u9700\u8981\u5728\u8bbe\u8ba1\u9636\u6bb5\u5c31\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5206\u6790\u8bbe\u5907\u53ec\u56de\u3001\u4e0d\u826f\u4e8b\u4ef6\u548c\u5df2\u77e5\u6f0f\u6d1e\u6570\u636e\uff0c\u8bbe\u8ba1\u4e86\u4e00\u5957\u5de5\u5177\u548c\u6280\u672f\uff0c\u7528\u4e8e\u4e0a\u5e02\u524d\u98ce\u9669\u8bc4\u4f30\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u5957\u5e2e\u52a9\u5236\u9020\u5546\u5c06\u7f51\u7edc\u5b89\u5168\u4f5c\u4e3a\u6838\u5fc3\u8bbe\u8ba1\u539f\u5219\u7684\u5de5\u5177\uff0c\u4ee5\u63d0\u5347\u8bbe\u5907\u5b89\u5168\u6027\u3002", "conclusion": "\u5f3a\u8c03\u5728AI/ML\u533b\u7597\u8bbe\u5907\u8bbe\u8ba1\u9636\u6bb5\u89e3\u51b3\u7f51\u7edc\u5b89\u5168\u95ee\u9898\u7684\u7d27\u8feb\u6027\uff0c\u4ee5\u786e\u4fdd\u60a3\u8005\u5b89\u5168\u3002"}}
{"id": "2506.15672", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2506.15672", "abs": "https://arxiv.org/abs/2506.15672", "authors": ["Yao Zhang", "Chenyang Lin", "Shijie Tang", "Haokun Chen", "Shijie Zhou", "Yunpu Ma", "Volker Tresp"], "title": "SwarmAgentic: Towards Fully Automated Agentic System Generation via Swarm Intelligence", "comment": "41 pages", "summary": "The rapid progress of Large Language Models has advanced agentic systems in\ndecision-making, coordination, and task execution. Yet, existing agentic system\ngeneration frameworks lack full autonomy, missing from-scratch agent\ngeneration, self-optimizing agent functionality, and collaboration, limiting\nadaptability and scalability. We propose SwarmAgentic, a framework for fully\nautomated agentic system generation that constructs agentic systems from\nscratch and jointly optimizes agent functionality and collaboration as\ninterdependent components through language-driven exploration. To enable\nefficient search over system-level structures, SwarmAgentic maintains a\npopulation of candidate systems and evolves them via feedback-guided updates,\ndrawing inspiration from Particle Swarm Optimization (PSO). We evaluate our\nmethod on six real-world, open-ended, and exploratory tasks involving\nhigh-level planning, system-level coordination, and creative reasoning. Given\nonly a task description and an objective function, SwarmAgentic outperforms all\nbaselines, achieving a +261.8% relative improvement over ADAS on the\nTravelPlanner benchmark, highlighting the effectiveness of full automation in\nstructurally unconstrained tasks. This framework marks a significant step\ntoward scalable and autonomous agentic system design, bridging swarm\nintelligence with fully automated system multi-agent generation. Our code is\npublicly released at https://yaoz720.github.io/SwarmAgentic/.", "AI": {"tldr": "SwarmAgentic\u63d0\u51fa\u4e86\u4e00\u79cd\u5168\u81ea\u52a8\u4ee3\u7406\u7cfb\u7edf\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u8a00\u9a71\u52a8\u63a2\u7d22\u548c\u7fa4\u4f53\u667a\u80fd\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7406\u7cfb\u7edf\u7684\u81ea\u4e3b\u6027\u548c\u534f\u4f5c\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u4ee3\u7406\u7cfb\u7edf\u751f\u6210\u6846\u67b6\u7f3a\u4e4f\u5b8c\u5168\u81ea\u4e3b\u6027\uff0c\u9650\u5236\u4e86\u9002\u5e94\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002SwarmAgentic\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u8bed\u8a00\u9a71\u52a8\u63a2\u7d22\u548c\u57fa\u4e8e\u7c92\u5b50\u7fa4\u4f18\u5316\u7684\u53cd\u9988\u5f15\u5bfc\u66f4\u65b0\uff0c\u4ece\u96f6\u6784\u5efa\u4ee3\u7406\u7cfb\u7edf\u5e76\u8054\u5408\u4f18\u5316\u529f\u80fd\u4e0e\u534f\u4f5c\u3002", "result": "\u5728\u516d\u4e2a\u771f\u5b9e\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5c24\u5176\u5728TravelPlanner\u57fa\u51c6\u4e0a\u76f8\u5bf9ADAS\u63d0\u5347\u4e86261.8%\u3002", "conclusion": "SwarmAgentic\u4e3a\u53ef\u6269\u5c55\u548c\u81ea\u4e3b\u7684\u4ee3\u7406\u7cfb\u7edf\u8bbe\u8ba1\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\uff0c\u7ed3\u5408\u4e86\u7fa4\u4f53\u667a\u80fd\u4e0e\u5168\u81ea\u52a8\u591a\u4ee3\u7406\u751f\u6210\u3002"}}
{"id": "2506.15084", "categories": ["cs.SE", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.15084", "abs": "https://arxiv.org/abs/2506.15084", "authors": ["Weiqi Lu", "Yongqiang Tian", "Xiaohan Zhong", "Haoyang Ma", "Zhenyang Xu", "Shing-Chi Cheung", "Chengnian Sun"], "title": "An Empirical Study of Bugs in Data Visualization Libraries", "comment": "Proc. ACM Softw. Eng. 2, FSE", "summary": "Data visualization (DataViz) libraries play a crucial role in presentation,\ndata analysis, and application development, underscoring the importance of\ntheir accuracy in transforming data into visual representations. Incorrect\nvisualizations can adversely impact user experience, distort information\nconveyance, and influence user perception and decision-making processes. Visual\nbugs in these libraries can be particularly insidious as they may not cause\nobvious errors like crashes, but instead mislead users of the underlying data\ngraphically, resulting in wrong decision making. Consequently, a good\nunderstanding of the unique characteristics of bugs in DataViz libraries is\nessential for researchers and developers to detect and fix bugs in DataViz\nlibraries.\n  This study presents the first comprehensive analysis of bugs in DataViz\nlibraries, examining 564 bugs collected from five widely-used libraries. Our\nstudy systematically analyzes their symptoms and root causes, and provides a\ndetailed taxonomy. We found that incorrect/inaccurate plots are pervasive in\nDataViz libraries and incorrect graphic computation is the major root cause,\nwhich necessitates further automated testing methods for DataViz libraries.\nMoreover, we identified eight key steps to trigger such bugs and two test\noracles specific to DataViz libraries, which may inspire future research in\ndesigning effective automated testing techniques. Furthermore, with the recent\nadvancements in Vision Language Models (VLMs), we explored the feasibility of\napplying these models to detect incorrect/inaccurate plots. The results show\nthat the effectiveness of VLMs in bug detection varies from 29% to 57%,\ndepending on the prompts, and adding more information in prompts does not\nnecessarily increase the effectiveness. More findings can be found in our\nmanuscript.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u5168\u9762\u5206\u6790\u4e86\u6570\u636e\u53ef\u89c6\u5316\u5e93\u4e2d\u7684\u9519\u8bef\uff0c\u7814\u7a76\u4e86564\u4e2a\u9519\u8bef\uff0c\u53d1\u73b0\u4e0d\u51c6\u786e\u7ed8\u56fe\u666e\u904d\u5b58\u5728\uff0c\u5e76\u63a2\u7d22\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u6d4b\u9519\u8bef\u4e2d\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u6570\u636e\u53ef\u89c6\u5316\u5e93\u7684\u51c6\u786e\u6027\u5bf9\u7528\u6237\u4f53\u9a8c\u548c\u51b3\u7b56\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u89c6\u89c9\u9519\u8bef\u53ef\u80fd\u8bef\u5bfc\u7528\u6237\uff0c\u56e0\u6b64\u9700\u8981\u6df1\u5165\u7406\u89e3\u8fd9\u4e9b\u9519\u8bef\u7684\u7279\u6027\u3002", "method": "\u7814\u7a76\u6536\u96c6\u4e86\u4e94\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u6570\u636e\u53ef\u89c6\u5316\u5e93\u4e2d\u7684564\u4e2a\u9519\u8bef\uff0c\u7cfb\u7edf\u5206\u6790\u4e86\u5176\u75c7\u72b6\u548c\u6839\u672c\u539f\u56e0\uff0c\u5e76\u63d0\u51fa\u4e86\u8be6\u7ec6\u7684\u5206\u7c7b\u6cd5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e0d\u51c6\u786e\u7ed8\u56fe\u666e\u904d\u5b58\u5728\uff0c\u56fe\u5f62\u8ba1\u7b97\u9519\u8bef\u662f\u4e3b\u8981\u539f\u56e0\uff0c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u6d4b\u9519\u8bef\u4e2d\u7684\u6548\u679c\u56e0\u63d0\u793a\u800c\u5f02\uff0829%-57%\uff09\u3002", "conclusion": "\u7814\u7a76\u4e3a\u6570\u636e\u53ef\u89c6\u5316\u5e93\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u5e76\u6307\u51fa\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u9519\u8bef\u68c0\u6d4b\u4e2d\u7684\u6f5c\u529b\u4e0e\u5c40\u9650\u6027\u3002"}}
{"id": "2506.14990", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14990", "abs": "https://arxiv.org/abs/2506.14990", "authors": ["Tristan Tomilin", "Luka van den Boogaard", "Samuel Garcin", "Bram Grooten", "Meng Fang", "Mykola Pechenizkiy"], "title": "MEAL: A Benchmark for Continual Multi-Agent Reinforcement Learning", "comment": null, "summary": "Benchmarks play a crucial role in the development and analysis of\nreinforcement learning (RL) algorithms, with environment availability strongly\nimpacting research. One particularly underexplored intersection is continual\nlearning (CL) in cooperative multi-agent settings. To remedy this, we introduce\nMEAL (Multi-agent Environments for Adaptive Learning), the first benchmark\ntailored for continual multi-agent reinforcement learning (CMARL). Existing CL\nbenchmarks run environments on the CPU, leading to computational bottlenecks\nand limiting the length of task sequences. MEAL leverages JAX for GPU\nacceleration, enabling continual learning across sequences of 100 tasks on a\nstandard desktop PC in a few hours. We show that naively combining popular CL\nand MARL methods yields strong performance on simple environments, but fails to\nscale to more complex settings requiring sustained coordination and adaptation.\nOur ablation study identifies architectural and algorithmic features critical\nfor CMARL on MEAL.", "AI": {"tldr": "MEAL\u662f\u9996\u4e2a\u9488\u5bf9\u6301\u7eed\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08CMARL\uff09\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5229\u7528JAX\u5b9e\u73b0GPU\u52a0\u901f\uff0c\u652f\u6301\u5728\u666e\u901aPC\u4e0a\u5feb\u901f\u8fd0\u884c100\u4e2a\u4efb\u52a1\u7684\u5e8f\u5217\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u7b80\u5355\u7ed3\u5408\u73b0\u6709CL\u548cMARL\u65b9\u6cd5\u5728\u590d\u6742\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u6539\u8fdb\u67b6\u6784\u548c\u7b97\u6cd5\u3002", "motivation": "\u73b0\u6709\u6301\u7eed\u5b66\u4e60\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5728CPU\u4e0a\u8fd0\u884c\uff0c\u5bfc\u81f4\u8ba1\u7b97\u74f6\u9888\u548c\u4efb\u52a1\u5e8f\u5217\u957f\u5ea6\u53d7\u9650\uff0c\u4e14\u7f3a\u4e4f\u9488\u5bf9\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u73af\u5883\u7684\u6301\u7eed\u5b66\u4e60\u57fa\u51c6\u3002", "method": "\u63d0\u51faMEAL\u57fa\u51c6\uff0c\u5229\u7528JAX\u5b9e\u73b0GPU\u52a0\u901f\uff0c\u652f\u6301\u5728\u666e\u901aPC\u4e0a\u5feb\u901f\u8fd0\u884c100\u4e2a\u4efb\u52a1\u7684\u5e8f\u5217\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u7b80\u5355\u7ed3\u5408\u73b0\u6709CL\u548cMARL\u65b9\u6cd5\u5728\u7b80\u5355\u73af\u5883\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u590d\u6742\u73af\u5883\u4e2d\u65e0\u6cd5\u6301\u7eed\u534f\u8c03\u548c\u9002\u5e94\u3002", "conclusion": "MEAL\u4e3aCMARL\u7814\u7a76\u63d0\u4f9b\u4e86\u9ad8\u6548\u57fa\u51c6\uff0c\u5e76\u63ed\u793a\u4e86\u6539\u8fdb\u67b6\u6784\u548c\u7b97\u6cd5\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.15034", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.15034", "abs": "https://arxiv.org/abs/2506.15034", "authors": ["Pratama Derry", "Laksmono Agus Mahardika Ari", "Iqbal Muhammad", "Howon Kim"], "title": "MECHA: Multithreaded and Efficient Cryptographic Hardware Access", "comment": "4 Page", "summary": "This paper presents a multithread and efficient cryptographic hardware access\n(MECHA) for efficient and fast cryptographic operations that eliminates the\nneed for context switching. Utilizing a UNIX domain socket, MECHA manages\nmultiple requests from multiple applications simultaneously, resulting in\nfaster processing and improved efficiency. We comprise several key components,\nincluding the Server thread, Client thread, Transceiver thread, and a pair of\nSender and Receiver queues. MECHA design is portable and can be used with any\ncommunication protocol, with experimental results demonstrating a 83% increase\nin the speed of concurrent cryptographic requests compared to conventional\ninterface design. MECHA architecture has significant potential in the field of\nsecure communication applications ranging from cloud computing to the IoT,\noffering a faster and more efficient solution for managing multiple\ncryptographic operation requests concurrently.", "AI": {"tldr": "MECHA\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u591a\u7ebf\u7a0b\u52a0\u5bc6\u786c\u4ef6\u8bbf\u95ee\u65b9\u6848\uff0c\u901a\u8fc7UNIX\u57df\u5957\u63a5\u5b57\u7ba1\u7406\u591a\u5e94\u7528\u8bf7\u6c42\uff0c\u63d0\u5347\u52a0\u5bc6\u64cd\u4f5c\u901f\u5ea6\u4e0e\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u52a0\u5bc6\u63a5\u53e3\u8bbe\u8ba1\u9700\u8981\u4e0a\u4e0b\u6587\u5207\u6362\uff0c\u6548\u7387\u4f4e\u4e0b\uff0cMECHA\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u91c7\u7528\u591a\u7ebf\u7a0b\u67b6\u6784\uff08Server\u3001Client\u3001Transceiver\u7ebf\u7a0b\u53caSender/Receiver\u961f\u5217\uff09\uff0c\u901a\u8fc7UNIX\u57df\u5957\u63a5\u5b57\u5b9e\u73b0\u591a\u8bf7\u6c42\u5e76\u53d1\u5904\u7406\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cMECHA\u6bd4\u4f20\u7edf\u63a5\u53e3\u8bbe\u8ba1\u5feb83%\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u901a\u4fe1\u534f\u8bae\u3002", "conclusion": "MECHA\u5728\u5b89\u5168\u901a\u4fe1\u9886\u57df\uff08\u5982\u4e91\u8ba1\u7b97\u548c\u7269\u8054\u7f51\uff09\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\uff0c\u63d0\u4f9b\u66f4\u9ad8\u6548\u7684\u5e76\u53d1\u52a0\u5bc6\u64cd\u4f5c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.15088", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.15088", "abs": "https://arxiv.org/abs/2506.15088", "authors": ["Miao Miao"], "title": "Program Feature-based Fuzzing Benchmarking", "comment": null, "summary": "Fuzzing is a powerful software testing technique renowned for its\neffectiveness in identifying software vulnerabilities. Traditional fuzzing\nevaluations typically focus on overall fuzzer performance across a set of\ntarget programs, yet few benchmarks consider how fine-grained program features\ninfluence fuzzing effectiveness. To bridge this gap, we introduce a novel\nbenchmark designed to generate programs with configurable, fine-grained program\nfeatures to enhance fuzzing evaluations. We reviewed 25 recent grey-box fuzzing\nstudies, extracting 7 program features related to control-flow and data-flow\nthat can impact fuzzer performance. Using these features, we generated a\nbenchmark consisting of 153 programs controlled by 10 fine-grained configurable\nparameters. We evaluated 11 popular fuzzers using this benchmark. The results\nindicate that fuzzer performance varies significantly based on the program\nfeatures and their strengths, highlighting the importance of incorporating\nprogram characteristics into fuzzing evaluations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ef\u914d\u7f6e\u7684\u7ec6\u7c92\u5ea6\u7a0b\u5e8f\u7279\u5f81\u6765\u8bc4\u4f30\u6a21\u7cca\u6d4b\u8bd5\u7684\u6548\u679c\uff0c\u586b\u8865\u4e86\u4f20\u7edf\u8bc4\u4f30\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002", "motivation": "\u4f20\u7edf\u6a21\u7cca\u6d4b\u8bd5\u8bc4\u4f30\u901a\u5e38\u5173\u6ce8\u6574\u4f53\u6027\u80fd\uff0c\u800c\u5ffd\u7565\u4e86\u7ec6\u7c92\u5ea6\u7a0b\u5e8f\u7279\u5f81\u5bf9\u6d4b\u8bd5\u6548\u679c\u7684\u5f71\u54cd\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5206\u679025\u9879\u7070\u76d2\u6a21\u7cca\u6d4b\u8bd5\u7814\u7a76\uff0c\u63d0\u53d6\u4e867\u4e2a\u4e0e\u63a7\u5236\u548c\u6570\u636e\u6d41\u76f8\u5173\u7684\u7a0b\u5e8f\u7279\u5f81\uff0c\u5e76\u751f\u6210\u4e86\u4e00\u4e2a\u5305\u542b153\u4e2a\u7a0b\u5e8f\u7684\u57fa\u51c6\u6d4b\u8bd5\u96c6\u3002", "result": "\u8bc4\u4f30\u4e8611\u79cd\u6d41\u884c\u7684\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\uff0c\u7ed3\u679c\u663e\u793a\u5176\u6027\u80fd\u53d7\u7a0b\u5e8f\u7279\u5f81\u53ca\u5176\u5f3a\u5ea6\u663e\u8457\u5f71\u54cd\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5c06\u7a0b\u5e8f\u7279\u5f81\u7eb3\u5165\u6a21\u7cca\u6d4b\u8bd5\u8bc4\u4f30\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2506.15050", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15050", "abs": "https://arxiv.org/abs/2506.15050", "authors": ["Tiantian Fan", "Lingjun Liu", "Yu Yue", "Jiaze Chen", "Chengyi Wang", "Qiying Yu", "Chi Zhang", "Zhiqi Lin", "Ruofei Zhu", "Yufeng Yuan", "Xiaochen Zuo", "Bole Ma", "Mofan Zhang", "Gaohong Liu", "Ru Zhang", "Haotian Zhou", "Cong Xie", "Ruidong Zhu", "Zhi Zhang", "Xin Liu", "Mingxuan Wang", "Lin Yan", "Yonghui Wu"], "title": "Truncated Proximal Policy Optimization", "comment": null, "summary": "Recently, test-time scaling Large Language Models (LLMs) have demonstrated\nexceptional reasoning capabilities across scientific and professional tasks by\ngenerating long chains-of-thought (CoT). As a crucial component for developing\nthese reasoning models, reinforcement learning (RL), exemplified by Proximal\nPolicy Optimization (PPO) and its variants, allows models to learn through\ntrial and error. However, PPO can be time-consuming due to its inherent\non-policy nature, which is further exacerbated by increasing response lengths.\nIn this work, we propose Truncated Proximal Policy Optimization (T-PPO), a\nnovel extension to PPO that improves training efficiency by streamlining policy\nupdate and length-restricted response generation. T-PPO mitigates the issue of\nlow hardware utilization, an inherent drawback of fully synchronized\nlong-generation procedures, where resources often sit idle during the waiting\nperiods for complete rollouts. Our contributions are two-folds. First, we\npropose Extended Generalized Advantage Estimation (EGAE) for advantage\nestimation derived from incomplete responses while maintaining the integrity of\npolicy learning. Second, we devise a computationally optimized mechanism that\nallows for the independent optimization of the policy and value models. By\nselectively filtering prompt and truncated tokens, this mechanism reduces\nredundant computations and accelerates the training process without sacrificing\nconvergence performance. We demonstrate the effectiveness and efficacy of T-PPO\non AIME 2024 with a 32B base model. The experimental results show that T-PPO\nimproves the training efficiency of reasoning LLMs by up to 2.5x and\noutperforms its existing competitors.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684PPO\u65b9\u6cd5T-PPO\uff0c\u901a\u8fc7\u4f18\u5316\u7b56\u7565\u66f4\u65b0\u548c\u9650\u5236\u751f\u6210\u957f\u5ea6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "PPO\u5728\u957f\u5e8f\u5217\u751f\u6210\u4efb\u52a1\u4e2d\u6548\u7387\u4f4e\u4e0b\uff0c\u786c\u4ef6\u5229\u7528\u7387\u4e0d\u8db3\uff0c\u5f71\u54cd\u4e86LLMs\u7684\u8bad\u7ec3\u6548\u7387\u3002", "method": "\u63d0\u51faT-PPO\uff0c\u5305\u62ecEGAE\u4f18\u52bf\u4f30\u8ba1\u548c\u72ec\u7acb\u4f18\u5316\u7b56\u7565\u4e0e\u4ef7\u503c\u6a21\u578b\u7684\u673a\u5236\uff0c\u51cf\u5c11\u5197\u4f59\u8ba1\u7b97\u3002", "result": "\u5728AIME 2024\u4e0a\u9a8c\u8bc1\uff0cT-PPO\u8bad\u7ec3\u6548\u7387\u63d0\u53472.5\u500d\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "T-PPO\u901a\u8fc7\u4f18\u5316\u8bad\u7ec3\u6d41\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u4e86LLMs\u7684\u8bad\u7ec3\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2506.15043", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15043", "abs": "https://arxiv.org/abs/2506.15043", "authors": ["Amir Hossein Baradaran"], "title": "Advanced Prediction of Hypersonic Missile Trajectories with CNN-LSTM-GRU Architectures", "comment": null, "summary": "Advancements in the defense industry are paramount for ensuring the safety\nand security of nations, providing robust protection against emerging threats.\nAmong these threats, hypersonic missiles pose a significant challenge due to\ntheir extreme speeds and maneuverability, making accurate trajectory prediction\na critical necessity for effective countermeasures. This paper addresses this\nchallenge by employing a novel hybrid deep learning approach, integrating\nConvolutional Neural Networks (CNNs), Long Short-Term Memory (LSTM) networks,\nand Gated Recurrent Units (GRUs). By leveraging the strengths of these\narchitectures, the proposed method successfully predicts the complex\ntrajectories of hypersonic missiles with high accuracy, offering a significant\ncontribution to defense strategies and missile interception technologies. This\nresearch demonstrates the potential of advanced machine learning techniques in\nenhancing the predictive capabilities of defense systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408CNN\u3001LSTM\u548cGRU\u7684\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u4e8e\u9ad8\u7cbe\u5ea6\u9884\u6d4b\u9ad8\u8d85\u97f3\u901f\u5bfc\u5f39\u7684\u590d\u6742\u8f68\u8ff9\uff0c\u4e3a\u9632\u5fa1\u7b56\u7565\u548c\u62e6\u622a\u6280\u672f\u63d0\u4f9b\u4e86\u91cd\u8981\u652f\u6301\u3002", "motivation": "\u9ad8\u8d85\u97f3\u901f\u5bfc\u5f39\u56e0\u5176\u9ad8\u901f\u548c\u9ad8\u673a\u52a8\u6027\u5bf9\u9632\u5fa1\u7cfb\u7edf\u6784\u6210\u91cd\u5927\u6311\u6218\uff0c\u51c6\u786e\u9884\u6d4b\u5176\u8f68\u8ff9\u662f\u6709\u6548\u62e6\u622a\u7684\u5173\u952e\u3002", "method": "\u91c7\u7528CNN\u3001LSTM\u548cGRU\u76f8\u7ed3\u5408\u7684\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u5145\u5206\u5229\u7528\u5404\u67b6\u6784\u7684\u4f18\u52bf\u3002", "result": "\u6a21\u578b\u6210\u529f\u5b9e\u73b0\u4e86\u9ad8\u8d85\u97f3\u901f\u5bfc\u5f39\u8f68\u8ff9\u7684\u9ad8\u7cbe\u5ea6\u9884\u6d4b\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5148\u8fdb\u673a\u5668\u5b66\u4e60\u6280\u672f\u80fd\u663e\u8457\u63d0\u5347\u9632\u5fa1\u7cfb\u7edf\u7684\u9884\u6d4b\u80fd\u529b\u3002"}}
{"id": "2506.15098", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.15098", "abs": "https://arxiv.org/abs/2506.15098", "authors": ["Haosheng Zuo", "Feifei Niu", "Chuanyi Li"], "title": "Enhancement Report Approval Prediction: A Comparative Study of Large Language Models", "comment": null, "summary": "Enhancement reports (ERs) serve as a critical communication channel between\nusers and developers, capturing valuable suggestions for software improvement.\nHowever, manually processing these reports is resource-intensive, leading to\ndelays and potential loss of valuable insights. To address this challenge,\nenhancement report approval prediction (ERAP) has emerged as a research focus,\nleveraging machine learning techniques to automate decision-making. While\ntraditional approaches have employed feature-based classifiers and deep\nlearning models, recent advancements in large language models (LLM) present new\nopportunities for enhancing prediction accuracy. This study systematically\nevaluates 18 LLM variants (including BERT, RoBERTa, DeBERTa-v3, ELECTRA, and\nXLNet for encoder models; GPT-3.5-turbo, GPT-4o-mini, Llama 3.1 8B, Llama 3.1\n8B Instruct and DeepSeek-V3 for decoder models) against traditional methods\n(CNN/LSTM-BERT/GloVe). Our experiments reveal two key insights: (1)\nIncorporating creator profiles increases unfine-tuned decoder-only models'\noverall accuracy by 10.8 percent though it may introduce bias; (2) LoRA\nfine-tuned Llama 3.1 8B Instruct further improve performance, reaching 79\npercent accuracy and significantly enhancing recall for approved reports (76.1\npercent vs. LSTM-GLOVE's 64.1 percent), outperforming traditional methods by 5\npercent under strict chronological evaluation and effectively addressing class\nimbalance issues. These findings establish LLM as a superior solution for ERAP,\ndemonstrating their potential to streamline software maintenance workflows and\nimprove decision-making in real-world development environments. We also\ninvestigated and summarized the ER cases where the large models underperformed,\nproviding valuable directions for future research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u81ea\u52a8\u9884\u6d4b\u589e\u5f3a\u62a5\u544a\uff08ER\uff09\u7684\u6279\u51c6\u60c5\u51b5\uff0c\u53d1\u73b0LLM\u5728\u51c6\u786e\u6027\u548c\u53ec\u56de\u7387\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u65b9\u5411\u3002", "motivation": "\u624b\u52a8\u5904\u7406\u589e\u5f3a\u62a5\u544a\u8017\u65f6\u4e14\u6613\u9057\u6f0f\u6709\u4ef7\u503c\u5efa\u8bae\uff0c\u56e0\u6b64\u9700\u8981\u81ea\u52a8\u5316\u5de5\u5177\u63d0\u5347\u6548\u7387\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30\u4e8618\u79cdLLM\u53d8\u4f53\uff08\u5305\u62ec\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u6a21\u578b\uff09\uff0c\u5e76\u4e0e\u4f20\u7edf\u65b9\u6cd5\uff08\u5982CNN/LSTM-BERT/GloVe\uff09\u5bf9\u6bd4\u3002", "result": "LLM\u5728\u51c6\u786e\u6027\u548c\u53ec\u56de\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5c24\u5176\u662fLoRA\u5fae\u8c03\u7684Llama 3.1 8B Instruct\u6a21\u578b\u8fbe\u523079%\u51c6\u786e\u7387\u3002", "conclusion": "LLM\u662f\u589e\u5f3a\u62a5\u544a\u9884\u6d4b\u7684\u4f18\u8d8a\u89e3\u51b3\u65b9\u6848\uff0c\u672a\u6765\u7814\u7a76\u53ef\u9488\u5bf9\u5176\u4e0d\u8db3\u8fdb\u4e00\u6b65\u4f18\u5316\u3002"}}
{"id": "2506.15196", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15196", "abs": "https://arxiv.org/abs/2506.15196", "authors": ["Xianliang Yang", "Ling Zhang", "Haolong Qian", "Lei Song", "Jiang Bian"], "title": "HeurAgenix: Leveraging LLMs for Solving Complex Combinatorial Optimization Challenges", "comment": "27 pages,9 figures", "summary": "Heuristic algorithms play a vital role in solving combinatorial optimization\n(CO) problems, yet traditional designs depend heavily on manual expertise and\nstruggle to generalize across diverse instances. We introduce\n\\textbf{HeurAgenix}, a two-stage hyper-heuristic framework powered by large\nlanguage models (LLMs) that first evolves heuristics and then selects among\nthem automatically. In the heuristic evolution phase, HeurAgenix leverages an\nLLM to compare seed heuristic solutions with higher-quality solutions and\nextract reusable evolution strategies. During problem solving, it dynamically\npicks the most promising heuristic for each problem state, guided by the LLM's\nperception ability. For flexibility, this selector can be either a\nstate-of-the-art LLM or a fine-tuned lightweight model with lower inference\ncost. To mitigate the scarcity of reliable supervision caused by CO complexity,\nwe fine-tune the lightweight heuristic selector with a dual-reward mechanism\nthat jointly exploits singals from selection preferences and state perception,\nenabling robust selection under noisy annotations. Extensive experiments on\ncanonical benchmarks show that HeurAgenix not only outperforms existing\nLLM-based hyper-heuristics but also matches or exceeds specialized solvers.\nCode is available at https://github.com/microsoft/HeurAgenix.", "AI": {"tldr": "HeurAgenix\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4e24\u9636\u6bb5\u8d85\u542f\u53d1\u5f0f\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u3002\u5b83\u901a\u8fc7\u8fdb\u5316\u542f\u53d1\u5f0f\u7b56\u7565\u5e76\u52a8\u6001\u9009\u62e9\u6700\u4f18\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u542f\u53d1\u5f0f\u7b97\u6cd5\u4f9d\u8d56\u4eba\u5de5\u8bbe\u8ba1\u4e14\u96be\u4ee5\u6cdb\u5316\uff0cHeurAgenix\u65e8\u5728\u901a\u8fc7LLM\u81ea\u52a8\u5316\u548c\u4f18\u5316\u542f\u53d1\u5f0f\u7b56\u7565\u3002", "method": "HeurAgenix\u5206\u4e3a\u542f\u53d1\u5f0f\u8fdb\u5316\u548c\u52a8\u6001\u9009\u62e9\u4e24\u9636\u6bb5\uff0c\u5229\u7528LLM\u63d0\u53d6\u7b56\u7565\u5e76\u9009\u62e9\u6700\u4f18\u89e3\uff0c\u652f\u6301\u8f7b\u91cf\u7ea7\u6a21\u578b\u4ee5\u964d\u4f4e\u6210\u672c\u3002", "result": "\u5728\u6807\u51c6\u6d4b\u8bd5\u4e2d\uff0cHeurAgenix\u4f18\u4e8e\u73b0\u6709LLM\u8d85\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u751a\u81f3\u5ab2\u7f8e\u4e13\u7528\u6c42\u89e3\u5668\u3002", "conclusion": "HeurAgenix\u5c55\u793a\u4e86LLM\u5728\u7ec4\u5408\u4f18\u5316\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u81ea\u52a8\u5316\u542f\u53d1\u5f0f\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.15070", "categories": ["cs.CR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2506.15070", "abs": "https://arxiv.org/abs/2506.15070", "authors": ["Rasha Karakchi", "Rye Stahle-Smith", "Nishant Chinnasami", "Tiffany Yu"], "title": "Toward a Lightweight, Scalable, and Parallel Secure Encryption Engine", "comment": "This is submitted to the ACM/IEEE Symposium on Edge Computing (SEC\n  2025)", "summary": "The exponential growth of Internet of Things (IoT) applications has\nintensified the demand for efficient, high-throughput, and energy-efficient\ndata processing at the edge. Conventional CPU-centric encryption methods suffer\nfrom performance bottlenecks and excessive data movement, especially in\nlatency-sensitive and resource-constrained environments. In this paper, we\npresent SPiME, a lightweight, scalable, and FPGA-compatible Secure\nProcessor-in-Memory Encryption architecture that integrates the Advanced\nEncryption Standard (AES-128) directly into a Processing-in-Memory (PiM)\nframework. SPiME is designed as a modular array of parallel PiM units, each\ncombining an AES core with a minimal control unit to enable distributed\nin-place encryption with minimal overhead. The architecture is fully\nimplemented in Verilog and tested on multiple AMD UltraScale and UltraScale+\nFPGAs. Evaluation results show that SPiME can scale beyond 4,000 parallel units\nwhile maintaining less than 5\\% utilization of key FPGA resources on high-end\ndevices. It delivers over 25~Gbps in sustained encryption throughput with\npredictable, low-latency performance. The design's portability,\nconfigurability, and resource efficiency make it a compelling solution for\nsecure edge computing, embedded cryptographic systems, and customizable\nhardware accelerators.", "AI": {"tldr": "SPiME\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u53ef\u6269\u5c55\u4e14\u517c\u5bb9FPGA\u7684\u5b89\u5168\u5185\u5b58\u5904\u7406\u5668\u52a0\u5bc6\u67b6\u6784\uff0c\u96c6\u6210\u4e86AES-128\uff0c\u9002\u7528\u4e8e\u8fb9\u7f18\u8ba1\u7b97\u548c\u5d4c\u5165\u5f0f\u52a0\u5bc6\u7cfb\u7edf\u3002", "motivation": "\u7269\u8054\u7f51\u5e94\u7528\u7684\u5feb\u901f\u589e\u957f\u5bf9\u8fb9\u7f18\u8ba1\u7b97\u7684\u9ad8\u6548\u3001\u9ad8\u541e\u5410\u548c\u8282\u80fd\u6570\u636e\u5904\u7406\u63d0\u51fa\u4e86\u66f4\u9ad8\u8981\u6c42\uff0c\u4f20\u7edfCPU\u52a0\u5bc6\u65b9\u6cd5\u5728\u5ef6\u8fdf\u654f\u611f\u548c\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u5b58\u5728\u6027\u80fd\u74f6\u9888\u3002", "method": "SPiME\u91c7\u7528\u6a21\u5757\u5316\u5e76\u884c\u5185\u5b58\u5904\u7406\u5355\u5143\u9635\u5217\uff0c\u6bcf\u4e2a\u5355\u5143\u7ed3\u5408AES\u6838\u5fc3\u548c\u6700\u5c0f\u63a7\u5236\u5355\u5143\uff0c\u5b9e\u73b0\u5206\u5e03\u5f0f\u5c31\u5730\u52a0\u5bc6\u3002", "result": "\u5728\u9ad8\u7aefFPGA\u4e0a\uff0cSPiME\u53ef\u6269\u5c55\u81f34000\u591a\u4e2a\u5e76\u884c\u5355\u5143\uff0c\u8d44\u6e90\u5229\u7528\u7387\u4f4e\u4e8e5%\uff0c\u6301\u7eed\u52a0\u5bc6\u541e\u5410\u91cf\u8d85\u8fc725Gbps\uff0c\u5ef6\u8fdf\u4f4e\u4e14\u53ef\u9884\u6d4b\u3002", "conclusion": "SPiME\u7684\u8bbe\u8ba1\u5177\u6709\u4fbf\u643a\u6027\u3001\u53ef\u914d\u7f6e\u6027\u548c\u8d44\u6e90\u9ad8\u6548\u6027\uff0c\u662f\u5b89\u5168\u8fb9\u7f18\u8ba1\u7b97\u548c\u786c\u4ef6\u52a0\u901f\u5668\u7684\u7406\u60f3\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.15135", "categories": ["cs.SE", "cs.LO", "cs.PL", "F.3.1; F.1.2"], "pdf": "https://arxiv.org/pdf/2506.15135", "abs": "https://arxiv.org/abs/2506.15135", "authors": ["Zhengqun Koo"], "title": "Towards Bug-Free Distributed Go Programs", "comment": "Version 1. B.Comp. Dissertation", "summary": "Programmers of distributed systems need to reason about concurrency to avoid\nraces. However, reasoning about concurrency is difficult, and unexpected races\nshow up as bugs. Data race detection in shared memory systems is well-studied\n(dynamic data race detection [13], behavioral types [15], dynamic race\ndetection [31]). Similar to how a data race consists of reads and writes not\nrelated by happens-before at a shared memory location, a communication race\nconsists of receives and sends not related by happens-before on a shared\nchannel. Communication races are problematic: a receiver expects a specific\nmessage from a specific sender, but with a communication race, the receiver can\nreceive a message meant for another receiver, or not receive anything at all.\nIn this work, we describe a verification framework that can prove the absence\nof communication races for distributed programs that use a subset of the Go\nprogramming language, where synchronization is mainly achieved via message\npassing. We statically reason about how a distributed program executes, using a\nhappens-before order, extended to buffered and unbuffered channels.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9759\u6001\u9a8c\u8bc1\u6846\u67b6\uff0c\u7528\u4e8e\u8bc1\u660e\u4f7f\u7528Go\u8bed\u8a00\u5b50\u96c6\u7684\u5206\u5e03\u5f0f\u7a0b\u5e8f\u4e2d\u901a\u4fe1\u7ade\u4e89\u7684\u7f3a\u5931\u3002", "motivation": "\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u7684\u7a0b\u5e8f\u5458\u9700\u8981\u5904\u7406\u5e76\u53d1\u95ee\u9898\u4ee5\u907f\u514d\u7ade\u4e89\uff0c\u4f46\u5e76\u53d1\u63a8\u7406\u56f0\u96be\uff0c\u901a\u4fe1\u7ade\u4e89\u4f1a\u5bfc\u81f4\u63a5\u6536\u9519\u8bef\u6d88\u606f\u6216\u65e0\u6d88\u606f\u7684\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u6269\u5c55happens-before\u987a\u5e8f\u5230\u7f13\u51b2\u548c\u975e\u7f13\u51b2\u901a\u9053\uff0c\u9759\u6001\u5206\u6790\u5206\u5e03\u5f0f\u7a0b\u5e8f\u7684\u6267\u884c\u3002", "result": "\u6846\u67b6\u80fd\u591f\u8bc1\u660e\u7a0b\u5e8f\u4e2d\u6ca1\u6709\u901a\u4fe1\u7ade\u4e89\u3002", "conclusion": "\u8be5\u9a8c\u8bc1\u6846\u67b6\u4e3a\u5206\u5e03\u5f0f\u7a0b\u5e8f\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u9759\u6001\u5206\u6790\u65b9\u6cd5\uff0c\u786e\u4fdd\u901a\u4fe1\u7ade\u4e89\u7684\u4e0d\u5b58\u5728\u3002"}}
{"id": "2506.15075", "categories": ["cs.CR", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2506.15075", "abs": "https://arxiv.org/abs/2506.15075", "authors": ["Samhita Kuili", "Mohammadreza Amini", "Burak Kantarci"], "title": "CWGAN-GP Augmented CAE for Jamming Detection in 5G-NR in Non-IID Datasets", "comment": "6 pages, 5 figures, Accepted to IEEE International Symposium on\n  Personal, Indoor and Mobile Radio Communications (PIMRC) 2025", "summary": "In the ever-expanding domain of 5G-NR wireless cellular networks,\nover-the-air jamming attacks are prevalent as security attacks, compromising\nthe quality of the received signal. We simulate a jamming environment by\nincorporating additive white Gaussian noise (AWGN) into the real-world In-phase\nand Quadrature (I/Q) OFDM datasets. A Convolutional Autoencoder (CAE) is\nexploited to implement a jamming detection over various characteristics such as\nheterogenous I/Q datasets; extracting relevant information on Synchronization\nSignal Blocks (SSBs), and fewer SSB observations with notable class imbalance.\nGiven the characteristics of datasets, balanced datasets are acquired by\nemploying a Conv1D conditional Wasserstein Generative Adversarial\nNetwork-Gradient Penalty(CWGAN-GP) on both majority and minority SSB\nobservations. Additionally, we compare the performance and detection ability of\nthe proposed CAE model on augmented datasets with benchmark models:\nConvolutional Denoising Autoencoder (CDAE) and Convolutional Sparse Autoencoder\n(CSAE). Despite the complexity of data heterogeneity involved across all\ndatasets, CAE depicts the robustness in detection performance of jammed signal\nby achieving average values of 97.33% precision, 91.33% recall, 94.08%\nF1-score, and 94.35% accuracy over CDAE and CSAE.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5377\u79ef\u81ea\u7f16\u7801\u5668\uff08CAE\uff09\u76845G-NR\u65e0\u7ebf\u8702\u7a9d\u7f51\u7edc\u4e2d\u7684\u5e72\u6270\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08CWGAN-GP\uff09\u5e73\u8861\u6570\u636e\u96c6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "5G-NR\u7f51\u7edc\u4e2d\u666e\u904d\u5b58\u5728\u7684\u7a7a\u4e2d\u5e72\u6270\u653b\u51fb\u5f71\u54cd\u4e86\u4fe1\u53f7\u63a5\u6536\u8d28\u91cf\uff0c\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u5377\u79ef\u81ea\u7f16\u7801\u5668\uff08CAE\uff09\u68c0\u6d4b\u5e72\u6270\uff0c\u5e76\u901a\u8fc7CWGAN-GP\u751f\u6210\u5e73\u8861\u6570\u636e\u96c6\u4ee5\u89e3\u51b3\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "result": "CAE\u5728\u5e72\u6270\u68c0\u6d4b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5e73\u5747\u7cbe\u786e\u5ea6\u4e3a97.33%\uff0c\u53ec\u56de\u7387\u4e3a91.33%\uff0cF1\u5206\u6570\u4e3a94.08%\uff0c\u51c6\u786e\u7387\u4e3a94.35%\u3002", "conclusion": "CAE\u5728\u590d\u6742\u6570\u636e\u73af\u5883\u4e0b\u8868\u73b0\u51fa\u9c81\u68d2\u6027\uff0c\u4f18\u4e8e\u5176\u4ed6\u57fa\u51c6\u6a21\u578b\uff08CDAE\u548cCSAE\uff09\u3002"}}
{"id": "2506.15172", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.15172", "abs": "https://arxiv.org/abs/2506.15172", "authors": ["Maria Spichkova", "Kevin Iwan", "Madeleine Zwart", "Hina Lee", "Yuwon Yoon", "Xiaohan Qin"], "title": "Advanced approach for Agile/Scrum Process: RetroAI++", "comment": "Preprint. Accepted to the 29th International Conference on\n  Knowledge-Based and Intelligent Information & Engineering Systems (KES 2025).\n  Final version to be published by Elsevier (In Press)", "summary": "In Agile/Scrum software development, sprint planning and retrospective\nanalysis are the key elements of project management. The aim of our work is to\nsupport software developers in these activities. In this paper, we present our\nprototype tool RetroAI++, based on emerging intelligent technologies. In our\nRetroAI++ prototype, we aim to automate and refine the practical application of\nAgile/Scrum processes within Sprint Planning and Retrospectives. Leveraging AI\ninsights, our prototype aims to automate and refine the many processes involved\nin the Sprint Planning, Development and Retrospective stages of Agile/Scrum\ndevelopment projects, offering intelligent suggestions for sprint organisation\nas well as meaningful insights for retrospective reflection.", "AI": {"tldr": "RetroAI++\u662f\u4e00\u4e2a\u57fa\u4e8e\u667a\u80fd\u6280\u672f\u7684\u539f\u578b\u5de5\u5177\uff0c\u65e8\u5728\u81ea\u52a8\u5316\u5e76\u4f18\u5316\u654f\u6377/Scrum\u5f00\u53d1\u4e2d\u7684\u51b2\u523a\u8ba1\u5212\u548c\u56de\u987e\u5206\u6790\u3002", "motivation": "\u652f\u6301\u8f6f\u4ef6\u5f00\u53d1\u8005\u5728\u654f\u6377/Scrum\u5f00\u53d1\u4e2d\u7684\u51b2\u523a\u8ba1\u5212\u548c\u56de\u987e\u6d3b\u52a8\uff0c\u63d0\u5347\u9879\u76ee\u7ba1\u7406\u7684\u6548\u7387\u548c\u6548\u679c\u3002", "method": "\u5229\u7528AI\u6280\u672f\uff0c\u81ea\u52a8\u5316\u51b2\u523a\u8ba1\u5212\u3001\u5f00\u53d1\u548c\u56de\u987e\u9636\u6bb5\u7684\u591a\u9879\u6d41\u7a0b\uff0c\u5e76\u63d0\u4f9b\u667a\u80fd\u5efa\u8bae\u548c\u6df1\u5165\u6d1e\u5bdf\u3002", "result": "\u5f00\u53d1\u4e86RetroAI++\u539f\u578b\u5de5\u5177\uff0c\u80fd\u591f\u4e3a\u51b2\u523a\u7ec4\u7ec7\u548c\u56de\u987e\u53cd\u601d\u63d0\u4f9b\u667a\u80fd\u652f\u6301\u3002", "conclusion": "RetroAI++\u901a\u8fc7AI\u6280\u672f\u4f18\u5316\u4e86\u654f\u6377/Scrum\u5f00\u53d1\u7684\u5173\u952e\u73af\u8282\uff0c\u4e3a\u56e2\u961f\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.15225", "categories": ["cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2506.15225", "abs": "https://arxiv.org/abs/2506.15225", "authors": ["Jiahao You", "Ziye Jia", "Chao Dong", "Qihui Wu", "Zhu Han"], "title": "Joint Computation Offloading and Resource Allocation for Uncertain Maritime MEC via Cooperation of UAVs and Vessels", "comment": null, "summary": "The computation demands from the maritime Internet of Things (MIoT) increase\nrapidly in recent years, and the unmanned aerial vehicles (UAVs) and vessels\nbased multi-access edge computing (MEC) can fulfill these MIoT requirements.\nHowever, the uncertain maritime tasks present significant challenges of\ninefficient computation offloading and resource allocation. In this paper, we\nfocus on the maritime computation offloading and resource allocation through\nthe cooperation of UAVs and vessels, with consideration of uncertain tasks.\nSpecifically, we propose a cooperative MEC framework for computation offloading\nand resource allocation, including MIoT devices, UAVs and vessels. Then, we\nformulate the optimization problem to minimize the total execution time. As for\nthe uncertain MIoT tasks, we leverage Lyapunov optimization to tackle the\nunpredictable task arrivals and varying computational resource availability. By\nconverting the long-term constraints into short-term constraints, we obtain a\nset of small-scale optimization problems. Further, considering the\nheterogeneity of actions and resources of UAVs and vessels, we reformulate the\nsmall-scale optimization problem into a Markov game (MG). Moreover, a\nheterogeneous-agent soft actor-critic is proposed to sequentially update\nvarious neural networks and effectively solve the MG problem. Finally,\nsimulations are conducted to verify the effectiveness in addressing\ncomputational offloading and resource allocation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65e0\u4eba\u673a\u548c\u8239\u8236\u534f\u4f5c\u7684\u6d77\u4e0a\u8ba1\u7b97\u5378\u8f7d\u4e0e\u8d44\u6e90\u5206\u914d\u6846\u67b6\uff0c\u5229\u7528Lyapunov\u4f18\u5316\u548c\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\u89e3\u51b3\u4efb\u52a1\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u6d77\u4e0a\u7269\u8054\u7f51\uff08MIoT\uff09\u7684\u8ba1\u7b97\u9700\u6c42\u5feb\u901f\u589e\u957f\uff0c\u4f46\u4efb\u52a1\u4e0d\u786e\u5b9a\u6027\u5bfc\u81f4\u8ba1\u7b97\u5378\u8f7d\u548c\u8d44\u6e90\u5206\u914d\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u8981\u65e0\u4eba\u673a\u548c\u8239\u8236\u534f\u4f5c\u89e3\u51b3\u3002", "method": "\u63d0\u51fa\u534f\u4f5cMEC\u6846\u67b6\uff0c\u5229\u7528Lyapunov\u4f18\u5316\u5904\u7406\u4efb\u52a1\u4e0d\u786e\u5b9a\u6027\uff0c\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\uff0c\u5e76\u8bbe\u8ba1\u5f02\u6784\u667a\u80fd\u4f53\u8f6f\u6f14\u5458-\u8bc4\u8bba\u5bb6\u7b97\u6cd5\u6c42\u89e3\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u8ba1\u7b97\u5378\u8f7d\u548c\u8d44\u6e90\u5206\u914d\u95ee\u9898\u3002", "conclusion": "\u901a\u8fc7\u65e0\u4eba\u673a\u548c\u8239\u8236\u534f\u4f5c\u53ca\u4f18\u5316\u7b97\u6cd5\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u6d77\u4e0a\u7269\u8054\u7f51\u4efb\u52a1\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2506.15093", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.15093", "abs": "https://arxiv.org/abs/2506.15093", "authors": ["James Petrie", "Onni Aarne", "Nora Ammann", "David Dalrymple"], "title": "Flexible Hardware-Enabled Guarantees for AI Compute", "comment": null, "summary": "As artificial intelligence systems become increasingly powerful, they pose\ngrowing risks to international security, creating urgent coordination\nchallenges that current governance approaches struggle to address without\ncompromising sensitive information or national security. We propose flexible\nhardware-enabled guarantees (flexHEGs), that could be integrated with AI\naccelerators to enable trustworthy, privacy-preserving verification and\nenforcement of claims about AI development. FlexHEGs consist of an auditable\nguarantee processor that monitors accelerator usage and a secure enclosure\nproviding physical tamper protection. The system would be fully open source\nwith flexible, updateable verification capabilities. FlexHEGs could enable\ndiverse governance mechanisms including privacy-preserving model evaluations,\ncontrolled deployment, compute limits for training, and automated safety\nprotocol enforcement. In this first part of a three part series, we provide a\ncomprehensive introduction of the flexHEG system, including an overview of the\ngovernance and security capabilities it offers, its potential development and\nadoption paths, and the remaining challenges and limitations it faces. While\ntechnically challenging, flexHEGs offer an approach to address emerging\nregulatory and international security challenges in frontier AI development.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aflexHEGs\u7684\u786c\u4ef6\u4fdd\u969c\u7cfb\u7edf\uff0c\u65e8\u5728\u89e3\u51b3AI\u53d1\u5c55\u4e2d\u7684\u56fd\u9645\u5b89\u5168\u98ce\u9669\uff0c\u901a\u8fc7\u53ef\u5ba1\u8ba1\u7684\u4fdd\u8bc1\u5904\u7406\u5668\u548c\u5b89\u5168\u5916\u58f3\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u7684\u9a8c\u8bc1\u4e0e\u6267\u884c\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u65e5\u76ca\u5f3a\u5927\uff0c\u5176\u5bf9\u56fd\u9645\u5b89\u5168\u7684\u5a01\u80c1\u589e\u52a0\uff0c\u73b0\u6709\u6cbb\u7406\u65b9\u6cd5\u96be\u4ee5\u5728\u4e0d\u6cc4\u9732\u654f\u611f\u4fe1\u606f\u6216\u56fd\u5bb6\u5b89\u5168\u7684\u60c5\u51b5\u4e0b\u89e3\u51b3\u95ee\u9898\u3002", "method": "\u63d0\u51faflexHEGs\u7cfb\u7edf\uff0c\u5305\u62ec\u53ef\u5ba1\u8ba1\u7684\u4fdd\u8bc1\u5904\u7406\u5668\u548c\u5b89\u5168\u5916\u58f3\uff0c\u652f\u6301\u5f00\u6e90\u3001\u7075\u6d3b\u4e14\u53ef\u66f4\u65b0\u7684\u9a8c\u8bc1\u529f\u80fd\u3002", "result": "flexHEGs\u652f\u6301\u591a\u79cd\u6cbb\u7406\u673a\u5236\uff0c\u5982\u9690\u79c1\u4fdd\u62a4\u6a21\u578b\u8bc4\u4f30\u3001\u53d7\u63a7\u90e8\u7f72\u3001\u8bad\u7ec3\u8ba1\u7b97\u9650\u5236\u548c\u81ea\u52a8\u5b89\u5168\u534f\u8bae\u6267\u884c\u3002", "conclusion": "\u5c3d\u7ba1\u6280\u672f\u6311\u6218\u5927\uff0cflexHEGs\u4e3a\u89e3\u51b3\u524d\u6cbfAI\u53d1\u5c55\u4e2d\u7684\u76d1\u7ba1\u548c\u56fd\u9645\u5b89\u5168\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2506.15227", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.15227", "abs": "https://arxiv.org/abs/2506.15227", "authors": ["Quanjun Zhang", "Chunrong Fang", "Siqi Gu", "Ye Shang", "Zhenyu Chen", "Liang Xiao"], "title": "Large Language Models for Unit Testing: A Systematic Literature Review", "comment": null, "summary": "Unit testing is a fundamental practice in modern software engineering, with\nthe aim of ensuring the correctness, maintainability, and reliability of\nindividual software components. Very recently, with the advances in Large\nLanguage Models (LLMs), a rapidly growing body of research has leveraged LLMs\nto automate various unit testing tasks, demonstrating remarkable performance\nand significantly reducing manual effort. However, due to ongoing explorations\nin the LLM-based unit testing field, it is challenging for researchers to\nunderstand existing achievements, open challenges, and future opportunities.\nThis paper presents the first systematic literature review on the application\nof LLMs in unit testing until March 2025. We analyze \\numpaper{} relevant\npapers from the perspectives of both unit testing and LLMs. We first categorize\nexisting unit testing tasks that benefit from LLMs, e.g., test generation and\noracle generation. We then discuss several critical aspects of integrating LLMs\ninto unit testing research, including model usage, adaptation strategies, and\nhybrid approaches. We further summarize key challenges that remain unresolved\nand outline promising directions to guide future research in this area.\nOverall, our paper provides a systematic overview of the research landscape to\nthe unit testing community, helping researchers gain a comprehensive\nunderstanding of achievements and promote future research. Our artifacts are\npublicly available at the GitHub repository:\nhttps://github.com/iSEngLab/AwesomeLLM4UT.", "AI": {"tldr": "\u672c\u6587\u662f\u7b2c\u4e00\u7bc7\u5173\u4e8eLLMs\u5728\u5355\u5143\u6d4b\u8bd5\u4e2d\u5e94\u7528\u7684\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff0c\u603b\u7ed3\u4e86\u73b0\u6709\u6210\u679c\u3001\u6311\u6218\u53ca\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u968f\u7740LLMs\u7684\u53d1\u5c55\uff0c\u5176\u5728\u5355\u5143\u6d4b\u8bd5\u81ea\u52a8\u5316\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u589e\u591a\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u6027\u603b\u7ed3\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5206\u6790\u76f8\u5173\u8bba\u6587\uff0c\u4ece\u5355\u5143\u6d4b\u8bd5\u548cLLMs\u7684\u89d2\u5ea6\u5206\u7c7b\u4efb\u52a1\uff0c\u8ba8\u8bba\u6a21\u578b\u4f7f\u7528\u3001\u9002\u5e94\u7b56\u7565\u548c\u6df7\u5408\u65b9\u6cd5\u3002", "result": "\u603b\u7ed3\u4e86LLMs\u5728\u5355\u5143\u6d4b\u8bd5\u4e2d\u7684\u5173\u952e\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u672c\u6587\u4e3a\u5355\u5143\u6d4b\u8bd5\u793e\u533a\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u6982\u8ff0\uff0c\u4fc3\u8fdb\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2506.15377", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15377", "abs": "https://arxiv.org/abs/2506.15377", "authors": ["Ruoyu Wang", "Xinshu Li", "Chen Wang", "Lina Yao"], "title": "Efficient and Generalizable Environmental Understanding for Visual Navigation", "comment": null, "summary": "Visual Navigation is a core task in Embodied AI, enabling agents to navigate\ncomplex environments toward given objectives. Across diverse settings within\nNavigation tasks, many necessitate the modelling of sequential data accumulated\nfrom preceding time steps. While existing methods perform well, they typically\nprocess all historical observations simultaneously, overlooking the internal\nassociation structure within the data, which may limit the potential for\nfurther improvements in task performance. We address this by examining the\nunique characteristics of Navigation tasks through the lens of causality,\nintroducing a causal framework to highlight the limitations of conventional\nsequential methods. Leveraging this insight, we propose Causality-Aware\nNavigation (CAN), which incorporates a Causal Understanding Module to enhance\nthe agent's environmental understanding capability. Empirical evaluations show\nthat our approach consistently outperforms baselines across various tasks and\nsimulation environments. Extensive ablations studies attribute these gains to\nthe Causal Understanding Module, which generalizes effectively in both\nReinforcement and Supervised Learning settings without computational overhead.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u5173\u7cfb\u7684\u5bfc\u822a\u65b9\u6cd5\uff08CAN\uff09\uff0c\u901a\u8fc7\u5f15\u5165\u56e0\u679c\u7406\u89e3\u6a21\u5757\u63d0\u5347\u5bfc\u822a\u6027\u80fd\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5bfc\u822a\u65b9\u6cd5\u901a\u5e38\u540c\u65f6\u5904\u7406\u6240\u6709\u5386\u53f2\u89c2\u6d4b\u6570\u636e\uff0c\u5ffd\u7565\u4e86\u6570\u636e\u5185\u90e8\u5173\u8054\u7ed3\u6784\uff0c\u9650\u5236\u4e86\u4efb\u52a1\u6027\u80fd\u7684\u8fdb\u4e00\u6b65\u63d0\u5347\u3002", "method": "\u901a\u8fc7\u56e0\u679c\u89c6\u89d2\u5206\u6790\u5bfc\u822a\u4efb\u52a1\uff0c\u63d0\u51faCAN\u65b9\u6cd5\uff0c\u5305\u542b\u56e0\u679c\u7406\u89e3\u6a21\u5757\u4ee5\u589e\u5f3a\u73af\u5883\u7406\u89e3\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cCAN\u5728\u591a\u79cd\u4efb\u52a1\u548c\u4eff\u771f\u73af\u5883\u4e2d\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e14\u65e0\u9700\u989d\u5916\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "\u56e0\u679c\u7406\u89e3\u6a21\u5757\u6709\u6548\u63d0\u5347\u4e86\u5bfc\u822a\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u548c\u76d1\u7763\u5b66\u4e60\u573a\u666f\u3002"}}
{"id": "2506.15100", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.15100", "abs": "https://arxiv.org/abs/2506.15100", "authors": ["Onni Aarne", "James Petrie"], "title": "International Security Applications of Flexible Hardware-Enabled Guarantees", "comment": null, "summary": "As AI capabilities advance rapidly, flexible hardware-enabled guarantees\n(flexHEGs) offer opportunities to address international security challenges\nthrough comprehensive governance frameworks. This report examines how flexHEGs\ncould enable internationally trustworthy AI governance by establishing\nstandardized designs, robust ecosystem defenses, and clear operational\nparameters for AI-relevant chips. We analyze four critical international\nsecurity applications: limiting proliferation to address malicious use,\nimplementing safety norms to prevent loss of control, managing risks from\nmilitary AI systems, and supporting strategic stability through\nbalance-of-power mechanisms while respecting national sovereignty. The report\nexplores both targeted deployments for specific high-risk facilities and\ncomprehensive deployments covering all AI-relevant compute. We examine two\nprimary governance models: verification-based agreements that enable\ntransparent compliance monitoring, and ruleset-based agreements that\nautomatically enforce international rules through cryptographically-signed\nupdates. Through game-theoretic analysis, we demonstrate that comprehensive\nflexHEG agreements could remain stable under reasonable assumptions about state\npreferences and catastrophic risks. The report addresses critical\nimplementation challenges including technical thresholds for AI-relevant chips,\nmanagement of existing non-flexHEG hardware, and safeguards against abuse of\ngovernance power. While requiring significant international coordination,\nflexHEGs could provide a technical foundation for managing AI risks at the\nscale and speed necessary to address emerging threats to international security\nand stability.", "AI": {"tldr": "flexHEGs\uff08\u7075\u6d3b\u786c\u4ef6\u4fdd\u969c\uff09\u901a\u8fc7\u6807\u51c6\u5316\u8bbe\u8ba1\u548c\u56fd\u9645\u6cbb\u7406\u6846\u67b6\uff0c\u4e3aAI\u5b89\u5168\u63d0\u4f9b\u6280\u672f\u57fa\u7840\uff0c\u89e3\u51b3\u6076\u610f\u4f7f\u7528\u3001\u5931\u63a7\u98ce\u9669\u7b49\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u535a\u5f08\u8bba\u5206\u6790\u9a8c\u8bc1\u5176\u7a33\u5b9a\u6027\u3002", "motivation": "\u968f\u7740AI\u80fd\u529b\u5feb\u901f\u53d1\u5c55\uff0c\u56fd\u9645\u5b89\u5168\u9762\u4e34\u65b0\u6311\u6218\uff0cflexHEGs\u901a\u8fc7\u786c\u4ef6\u4fdd\u969c\u63d0\u4f9b\u53ef\u4fe1\u7684AI\u6cbb\u7406\u65b9\u6848\u3002", "method": "\u7814\u7a76flexHEGs\u5728\u9650\u5236\u6269\u6563\u3001\u5b89\u5168\u89c4\u8303\u3001\u519b\u4e8bAI\u98ce\u9669\u7ba1\u7406\u53ca\u6218\u7565\u7a33\u5b9a\u4e2d\u7684\u5e94\u7528\uff0c\u5206\u6790\u9a8c\u8bc1\u578b\u548c\u89c4\u5219\u578b\u4e24\u79cd\u6cbb\u7406\u6a21\u578b\u3002", "result": "\u535a\u5f08\u8bba\u5206\u6790\u8868\u660e\uff0c\u5168\u9762\u7684flexHEG\u534f\u8bae\u5728\u5408\u7406\u5047\u8bbe\u4e0b\u5177\u6709\u7a33\u5b9a\u6027\uff0c\u80fd\u6709\u6548\u7ba1\u7406AI\u98ce\u9669\u3002", "conclusion": "flexHEGs\u4e3a\u56fd\u9645AI\u6cbb\u7406\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u57fa\u7840\uff0c\u4f46\u9700\u514b\u670d\u534f\u8c03\u548c\u6280\u672f\u95e8\u69db\u7b49\u6311\u6218\u3002"}}
{"id": "2506.15453", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15453", "abs": "https://arxiv.org/abs/2506.15453", "authors": ["Yusuf Sulistyo Nugroho", "Farah Danisha Salam", "Brittany Reid", "Raula Gaikovina Kula", "Kazumasa Shimari", "Kenichi Matsumoto"], "title": "Uncovering Intention through LLM-Driven Code Snippet Description Generation", "comment": "6 pages, 3 figures, 4 tables, conference paper", "summary": "Documenting code snippets is essential to pinpoint key areas where both\ndevelopers and users should pay attention. Examples include usage examples and\nother Application Programming Interfaces (APIs), which are especially important\nfor third-party libraries. With the rise of Large Language Models (LLMs), the\nkey goal is to investigate the kinds of description developers commonly use and\nevaluate how well an LLM, in this case Llama, can support description\ngeneration. We use NPM Code Snippets, consisting of 185,412 packages with\n1,024,579 code snippets. From there, we use 400 code snippets (and their\ndescriptions) as samples. First, our manual classification found that the\nmajority of original descriptions (55.5%) highlight example-based usage. This\nfinding emphasizes the importance of clear documentation, as some descriptions\nlacked sufficient detail to convey intent. Second, the LLM correctly identified\nthe majority of original descriptions as \"Example\" (79.75%), which is identical\nto our manual finding, showing a propensity for generalization. Third, compared\nto the originals, the produced description had an average similarity score of\n0.7173, suggesting relevance but room for improvement. Scores below 0.9\nindicate some irrelevance. Our results show that depending on the task of the\ncode snippet, the intention of the document may differ from being instructions\nfor usage, installations, or descriptive learning examples for any user of a\nlibrary.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5f00\u53d1\u8005\u5e38\u7528\u7684\u4ee3\u7801\u7247\u6bb5\u63cf\u8ff0\u7c7b\u578b\uff0c\u5e76\u8bc4\u4f30\u4e86Llama\u6a21\u578b\u5728\u63cf\u8ff0\u751f\u6210\u4e2d\u7684\u8868\u73b0\u3002\u4f7f\u7528NPM\u4ee3\u7801\u7247\u6bb5\u6570\u636e\u96c6\uff0c\u53d1\u73b0\u591a\u6570\u63cf\u8ff0\u57fa\u4e8e\u793a\u4f8b\uff0cLLM\u80fd\u51c6\u786e\u8bc6\u522b\u4f46\u751f\u6210\u63cf\u8ff0\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002", "motivation": "\u4ee3\u7801\u7247\u6bb5\u6587\u6863\u5316\u5bf9\u5f00\u53d1\u8005\u548c\u7528\u6237\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u662f\u7b2c\u4e09\u65b9\u5e93\u3002\u7814\u7a76\u65e8\u5728\u4e86\u89e3\u5f00\u53d1\u8005\u5e38\u7528\u7684\u63cf\u8ff0\u7c7b\u578b\uff0c\u5e76\u8bc4\u4f30LLM\uff08\u5982Llama\uff09\u5728\u751f\u6210\u63cf\u8ff0\u4e2d\u7684\u80fd\u529b\u3002", "method": "\u4f7f\u7528NPM\u4ee3\u7801\u7247\u6bb5\u6570\u636e\u96c6\uff08185,412\u4e2a\u5305\uff0c1,024,579\u4e2a\u7247\u6bb5\uff09\uff0c\u9009\u53d6400\u4e2a\u6837\u672c\u8fdb\u884c\u624b\u52a8\u5206\u7c7b\u548cLLM\u8bc4\u4f30\u3002", "result": "55.5%\u7684\u539f\u59cb\u63cf\u8ff0\u57fa\u4e8e\u793a\u4f8b\uff0cLLM\u51c6\u786e\u8bc6\u522b79.75%\u7684\u793a\u4f8b\u63cf\u8ff0\u3002\u751f\u6210\u63cf\u8ff0\u7684\u5e73\u5747\u76f8\u4f3c\u6027\u5f97\u5206\u4e3a0.7173\uff0c\u663e\u793a\u76f8\u5173\u6027\u4f46\u9700\u6539\u8fdb\u3002", "conclusion": "\u4ee3\u7801\u7247\u6bb5\u7684\u6587\u6863\u610f\u56fe\u56e0\u4efb\u52a1\u800c\u5f02\uff0cLLM\u5728\u751f\u6210\u63cf\u8ff0\u65b9\u9762\u8868\u73b0\u826f\u597d\u4f46\u4ecd\u6709\u63d0\u5347\u7a7a\u95f4\u3002"}}
{"id": "2506.15567", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15567", "abs": "https://arxiv.org/abs/2506.15567", "authors": ["Aline Dobrovsky", "Konstantin Schekotihin", "Christian Burmer"], "title": "Managing Complex Failure Analysis Workflows with LLM-based Reasoning and Acting Agents", "comment": null, "summary": "Failure Analysis (FA) is a highly intricate and knowledge-intensive process.\nThe integration of AI components within the computational infrastructure of FA\nlabs has the potential to automate a variety of tasks, including the detection\nof non-conformities in images, the retrieval of analogous cases from diverse\ndata sources, and the generation of reports from annotated images. However, as\nthe number of deployed AI models increases, the challenge lies in orchestrating\nthese components into cohesive and efficient workflows that seamlessly\nintegrate with the FA process.\n  This paper investigates the design and implementation of a Large Language\nModel (LLM)-based Planning Agent (LPA) to assist FA engineers in solving their\nanalysis cases. The LPA integrates LLMs with advanced planning capabilities and\nexternal tool utilization, enabling autonomous processing of complex queries,\nretrieval of relevant data from external systems, and generation of\nhuman-readable responses. Evaluation results demonstrate the agent's\noperational effectiveness and reliability in supporting FA tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u89c4\u5212\u4ee3\u7406\uff08LPA\uff09\uff0c\u7528\u4e8e\u8f85\u52a9\u6545\u969c\u5206\u6790\uff08FA\uff09\u5de5\u7a0b\u5e08\u5904\u7406\u590d\u6742\u4efb\u52a1\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u6545\u969c\u5206\u6790\uff08FA\uff09\u662f\u4e00\u4e2a\u590d\u6742\u4e14\u77e5\u8bc6\u5bc6\u96c6\u578b\u7684\u8fc7\u7a0b\uff0c\u968f\u7740AI\u6a21\u578b\u7684\u589e\u591a\uff0c\u5982\u4f55\u534f\u8c03\u8fd9\u4e9b\u7ec4\u4ef6\u4ee5\u9ad8\u6548\u96c6\u6210\u5230FA\u6d41\u7a0b\u4e2d\u6210\u4e3a\u6311\u6218\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u89c4\u5212\u4ee3\u7406\uff08LPA\uff09\uff0c\u7ed3\u5408\u9ad8\u7ea7\u89c4\u5212\u80fd\u529b\u548c\u5916\u90e8\u5de5\u5177\u4f7f\u7528\uff0c\u81ea\u4e3b\u5904\u7406\u590d\u6742\u67e5\u8be2\u3001\u68c0\u7d22\u6570\u636e\u5e76\u751f\u6210\u53ef\u8bfb\u54cd\u5e94\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u8868\u660e\uff0cLPA\u5728\u652f\u6301FA\u4efb\u52a1\u65b9\u9762\u5177\u6709\u64cd\u4f5c\u6709\u6548\u6027\u548c\u53ef\u9760\u6027\u3002", "conclusion": "LPA\u80fd\u591f\u6709\u6548\u8f85\u52a9FA\u5de5\u7a0b\u5e08\uff0c\u63d0\u5347\u6545\u969c\u5206\u6790\u7684\u6548\u7387\u548c\u81ea\u52a8\u5316\u6c34\u5e73\u3002"}}
{"id": "2506.15102", "categories": ["cs.CR", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2506.15102", "abs": "https://arxiv.org/abs/2506.15102", "authors": ["Shizhao Peng", "Shoumo Li", "Tianle Tao"], "title": "EVA-S2PMLP: Secure and Scalable Two-Party MLP via Spatial Transformation", "comment": null, "summary": "Privacy-preserving neural network training in vertically partitioned\nscenarios is vital for secure collaborative modeling across institutions. This\npaper presents \\textbf{EVA-S2PMLP}, an Efficient, Verifiable, and Accurate\nSecure Two-Party Multi-Layer Perceptron framework that introduces spatial-scale\noptimization for enhanced privacy and performance. To enable reliable\ncomputation under real-number domain, EVA-S2PMLP proposes a secure\ntransformation pipeline that maps scalar inputs to vector and matrix spaces\nwhile preserving correctness. The framework includes a suite of atomic\nprotocols for linear and non-linear secure computations, with modular support\nfor secure activation, matrix-vector operations, and loss evaluation.\nTheoretical analysis confirms the reliability, security, and asymptotic\ncomplexity of each protocol. Extensive experiments show that EVA-S2PMLP\nachieves high inference accuracy and significantly reduced communication\noverhead, with up to $12.3\\times$ improvement over baselines. Evaluation on\nbenchmark datasets demonstrates that the framework maintains model utility\nwhile ensuring strict data confidentiality, making it a practical solution for\nprivacy-preserving neural network training in finance, healthcare, and\ncross-organizational AI applications.", "AI": {"tldr": "EVA-S2PMLP\u662f\u4e00\u4e2a\u9ad8\u6548\u3001\u53ef\u9a8c\u8bc1\u4e14\u51c6\u786e\u7684\u9690\u79c1\u4fdd\u62a4\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u5782\u76f4\u5206\u533a\u573a\u666f\uff0c\u901a\u8fc7\u7a7a\u95f4\u5c3a\u5ea6\u4f18\u5316\u63d0\u5347\u9690\u79c1\u548c\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u8de8\u673a\u6784\u534f\u4f5c\u5efa\u6a21\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u95ee\u9898\uff0c\u786e\u4fdd\u6570\u636e\u673a\u5bc6\u6027\u3002", "method": "\u63d0\u51fa\u5b89\u5168\u7684\u8f6c\u6362\u7ba1\u9053\uff0c\u5c06\u6807\u91cf\u8f93\u5165\u6620\u5c04\u5230\u5411\u91cf\u548c\u77e9\u9635\u7a7a\u95f4\uff0c\u5e76\u63d0\u4f9b\u539f\u5b50\u534f\u8bae\u652f\u6301\u7ebf\u6027\u4e0e\u975e\u7ebf\u6027\u5b89\u5168\u8ba1\u7b97\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cEVA-S2PMLP\u5728\u4fdd\u6301\u9ad8\u63a8\u7406\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\uff0c\u6027\u80fd\u63d0\u5347\u8fbe12.3\u500d\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u91d1\u878d\u3001\u533b\u7597\u7b49\u9886\u57df\u5177\u6709\u5b9e\u7528\u6027\uff0c\u80fd\u540c\u65f6\u4fdd\u969c\u6570\u636e\u9690\u79c1\u548c\u6a21\u578b\u6548\u7528\u3002"}}
{"id": "2506.15655", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.15655", "abs": "https://arxiv.org/abs/2506.15655", "authors": ["Yilin Zhang", "Xinran Zhao", "Zora Zhiruo Wang", "Chenyang Yang", "Jiayi Wei", "Tongshuang Wu"], "title": "cAST: Enhancing Code Retrieval-Augmented Generation with Structural Chunking via Abstract Syntax Tree", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) has become essential for large-scale\ncode generation, grounding predictions in external code corpora to improve\nactuality. However, a critical yet underexplored aspect of RAG pipelines is\nchunking -- the process of dividing documents into retrievable units. Existing\nline-based chunking heuristics often break semantic structures, splitting\nfunctions or merging unrelated code, which can degrade generation quality. We\npropose chunking via Abstract Syntax Trees (\\ourwork), a structure-aware method\nthat recursively breaks large AST nodes into smaller chunks and merges sibling\nnodes while respecting size limits. This approach generates self-contained,\nsemantically coherent units across programming languages and tasks, improving\nperformance on diverse code generation tasks, e.g., boosting Recall@5 by 4.3\npoints on RepoEval retrieval and Pass@1 by 2.67 points on SWE-bench generation.\nOur work highlights the importance of structure-aware chunking for scaling\nretrieval-enhanced code intelligence.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u62bd\u8c61\u8bed\u6cd5\u6811\uff08AST\uff09\u7684\u4ee3\u7801\u5206\u5757\u65b9\u6cd5\uff08\\ourwork\uff09\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u57fa\u4e8e\u884c\u7684\u5206\u5757\u65b9\u6cd5\u7834\u574f\u8bed\u4e49\u7ed3\u6784\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u884c\u7684\u5206\u5757\u65b9\u6cd5\u5728\u4ee3\u7801\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u4e2d\u5e38\u7834\u574f\u8bed\u4e49\u7ed3\u6784\uff0c\u5f71\u54cd\u751f\u6210\u8d28\u91cf\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u7ed3\u6784\u611f\u77e5\u7684\u5206\u5757\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eAST\u7684\u5206\u5757\u65b9\u6cd5\uff0c\u9012\u5f52\u5730\u5c06\u5927AST\u8282\u70b9\u5206\u89e3\u4e3a\u5c0f\u5206\u5757\uff0c\u5e76\u5728\u5927\u5c0f\u9650\u5236\u5185\u5408\u5e76\u5144\u5f1f\u8282\u70b9\uff0c\u751f\u6210\u8bed\u4e49\u8fde\u8d2f\u7684\u5355\u5143\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5982\u5728RepoEval\u68c0\u7d22\u4e2dRecall@5\u63d0\u53474.3\u70b9\uff0c\u5728SWE-bench\u751f\u6210\u4e2dPass@1\u63d0\u53472.67\u70b9\u3002", "conclusion": "\u7ed3\u6784\u611f\u77e5\u7684\u5206\u5757\u65b9\u6cd5\u5bf9\u6269\u5c55\u68c0\u7d22\u589e\u5f3a\u7684\u4ee3\u7801\u667a\u80fd\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2506.15624", "categories": ["cs.AI", "I.2.11; I.6.4; F.1.2; F.2.2; G.3; J.7"], "pdf": "https://arxiv.org/pdf/2506.15624", "abs": "https://arxiv.org/abs/2506.15624", "authors": ["Lyle Goodyear", "Rachel Guo", "Ramesh Johari"], "title": "The Effect of State Representation on LLM Agent Behavior in Dynamic Routing Games", "comment": "27 pages, 20 figures", "summary": "Large Language Models (LLMs) have shown promise as decision-makers in dynamic\nsettings, but their stateless nature necessitates creating a natural language\nrepresentation of history. We present a unifying framework for systematically\nconstructing natural language \"state\" representations for prompting LLM agents\nin repeated multi-agent games. Previous work on games with LLM agents has taken\nan ad hoc approach to encoding game history, which not only obscures the impact\nof state representation on agents' behavior, but also limits comparability\nbetween studies. Our framework addresses these gaps by characterizing methods\nof state representation along three axes: action informativeness (i.e., the\nextent to which the state representation captures actions played); reward\ninformativeness (i.e., the extent to which the state representation describes\nrewards obtained); and prompting style (or natural language compression, i.e.,\nthe extent to which the full text history is summarized).\n  We apply this framework to a dynamic selfish routing game, chosen because it\nadmits a simple equilibrium both in theory and in human subject experiments\n\\cite{rapoport_choice_2009}. Despite the game's relative simplicity, we find\nthat there are key dependencies of LLM agent behavior on the natural language\nstate representation. In particular, we observe that representations which\nprovide agents with (1) summarized, rather than complete, natural language\nrepresentations of past history; (2) information about regrets, rather than raw\npayoffs; and (3) limited information about others' actions lead to behavior\nthat more closely matches game theoretic equilibrium predictions, and with more\nstable game play by the agents. By contrast, other representations can exhibit\neither large deviations from equilibrium, higher variation in dynamic game play\nover time, or both.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u6027\u6846\u67b6\uff0c\u7528\u4e8e\u4e3aLLM\u4ee3\u7406\u5728\u591a\u4ee3\u7406\u6e38\u620f\u4e2d\u6784\u5efa\u81ea\u7136\u8bed\u8a00\u72b6\u6001\u8868\u793a\uff0c\u89e3\u51b3\u4e86\u4ee5\u5f80\u7814\u7a76\u4e2d\u72b6\u6001\u8868\u793a\u5bf9\u884c\u4e3a\u5f71\u54cd\u4e0d\u660e\u786e\u548c\u53ef\u6bd4\u6027\u53d7\u9650\u7684\u95ee\u9898\u3002", "motivation": "LLM\u5728\u52a8\u6001\u73af\u5883\u4e2d\u4f5c\u4e3a\u51b3\u7b56\u8005\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5176\u65e0\u72b6\u6001\u7279\u6027\u9700\u8981\u81ea\u7136\u8bed\u8a00\u5386\u53f2\u8868\u793a\u3002\u4ee5\u5f80\u7814\u7a76\u5bf9\u6e38\u620f\u5386\u53f2\u7684\u7f16\u7801\u65b9\u5f0f\u7f3a\u4e4f\u7cfb\u7edf\u6027\uff0c\u5f71\u54cd\u4e86\u884c\u4e3a\u5206\u6790\u548c\u7814\u7a76\u95f4\u7684\u53ef\u6bd4\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u4ece\u4e09\u4e2a\u7ef4\u5ea6\uff08\u52a8\u4f5c\u4fe1\u606f\u6027\u3001\u5956\u52b1\u4fe1\u606f\u6027\u548c\u63d0\u793a\u98ce\u683c\uff09\u7cfb\u7edf\u5316\u6784\u5efa\u72b6\u6001\u8868\u793a\uff0c\u5e76\u5e94\u7528\u4e8e\u52a8\u6001\u81ea\u79c1\u8def\u7531\u6e38\u620f\u4e2d\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u63d0\u4f9b\u603b\u7ed3\u6027\u5386\u53f2\u8868\u793a\u3001\u540e\u6094\u4fe1\u606f\u800c\u975e\u539f\u59cb\u6536\u76ca\u3001\u4ee5\u53ca\u6709\u9650\u4ed6\u4eba\u52a8\u4f5c\u4fe1\u606f\u7684\u8868\u793a\uff0c\u80fd\u66f4\u63a5\u8fd1\u535a\u5f08\u8bba\u5747\u8861\u9884\u6d4b\uff0c\u884c\u4e3a\u66f4\u7a33\u5b9a\u3002", "conclusion": "\u81ea\u7136\u8bed\u8a00\u72b6\u6001\u8868\u793a\u5bf9LLM\u4ee3\u7406\u884c\u4e3a\u6709\u663e\u8457\u5f71\u54cd\uff0c\u7279\u5b9a\u8868\u793a\u65b9\u5f0f\u80fd\u4f18\u5316\u5176\u51b3\u7b56\u8868\u73b0\uff0c\u63a5\u8fd1\u7406\u8bba\u5747\u8861\u3002"}}
{"id": "2506.15112", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.15112", "abs": "https://arxiv.org/abs/2506.15112", "authors": ["Xiangman Li", "Xiaodong Wu", "Jianbing Ni", "Mohamed Mahmoud", "Maazen Alsabaan"], "title": "PDLRecover: Privacy-preserving Decentralized Model Recovery with Machine Unlearning", "comment": null, "summary": "Decentralized learning is vulnerable to poison attacks, where malicious\nclients manipulate local updates to degrade global model performance. Existing\ndefenses mainly detect and filter malicious models, aiming to prevent a limited\nnumber of attackers from corrupting the global model. However, restoring an\nalready compromised global model remains a challenge. A direct approach is to\nremove malicious clients and retrain the model using only the benign clients.\nYet, retraining is time-consuming, computationally expensive, and may\ncompromise model consistency and privacy.\n  We propose PDLRecover, a novel method to recover a poisoned global model\nefficiently by leveraging historical model information while preserving\nprivacy. The main challenge lies in protecting shared historical models while\nenabling parameter estimation for model recovery. By exploiting the linearity\nof approximate Hessian matrix computation, we apply secret sharing to protect\nhistorical updates, ensuring local models are not leaked during transmission or\nreconstruction. PDLRecover introduces client-side preparation, periodic\nrecovery updates, and a final exact update to ensure robustness and convergence\nof the recovered model. Periodic updates maintain accurate curvature\ninformation, and the final step ensures high-quality convergence. Experiments\nshow that the recovered global model achieves performance comparable to a fully\nretrained model but with significantly reduced computation and time cost.\nMoreover, PDLRecover effectively prevents leakage of local model parameters,\nensuring both accuracy and privacy in recovery.", "AI": {"tldr": "PDLRecover\u662f\u4e00\u79cd\u9ad8\u6548\u6062\u590d\u4e2d\u6bd2\u5168\u5c40\u6a21\u578b\u7684\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u5386\u53f2\u6a21\u578b\u4fe1\u606f\u5e76\u4fdd\u62a4\u9690\u79c1\uff0c\u907f\u514d\u5b8c\u5168\u91cd\u65b0\u8bad\u7ec3\u3002", "motivation": "\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u96be\u4ee5\u6062\u590d\u5df2\u4e2d\u6bd2\u7684\u5168\u5c40\u6a21\u578b\uff0c\u800c\u91cd\u65b0\u8bad\u7ec3\u6210\u672c\u9ad8\u4e14\u53ef\u80fd\u5f71\u54cd\u9690\u79c1\u548c\u4e00\u81f4\u6027\u3002", "method": "\u901a\u8fc7\u8fd1\u4f3cHessian\u77e9\u9635\u7684\u7ebf\u6027\u8ba1\u7b97\u548c\u79d8\u5bc6\u5171\u4eab\u6280\u672f\u4fdd\u62a4\u5386\u53f2\u66f4\u65b0\uff0c\u7ed3\u5408\u5ba2\u6237\u7aef\u51c6\u5907\u3001\u5468\u671f\u6027\u6062\u590d\u66f4\u65b0\u548c\u6700\u7ec8\u7cbe\u786e\u66f4\u65b0\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6062\u590d\u7684\u5168\u5c40\u6a21\u578b\u6027\u80fd\u63a5\u8fd1\u5b8c\u5168\u91cd\u65b0\u8bad\u7ec3\u7684\u6a21\u578b\uff0c\u4f46\u8ba1\u7b97\u548c\u65f6\u95f4\u6210\u672c\u663e\u8457\u964d\u4f4e\uff0c\u540c\u65f6\u4fdd\u62a4\u4e86\u672c\u5730\u6a21\u578b\u9690\u79c1\u3002", "conclusion": "PDLRecover\u5728\u6062\u590d\u4e2d\u6bd2\u6a21\u578b\u65f6\u517c\u987e\u6548\u7387\u548c\u9690\u79c1\uff0c\u4e3a\u53bb\u4e2d\u5fc3\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.15648", "categories": ["cs.CR", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2506.15648", "abs": "https://arxiv.org/abs/2506.15648", "authors": ["Georgios Androutsopoulos", "Antonio Bianchi"], "title": "deepSURF: Detecting Memory Safety Vulnerabilities in Rust Through Fuzzing LLM-Augmented Harnesses", "comment": null, "summary": "Although Rust ensures memory safety by default, it also permits the use of\nunsafe code, which can introduce memory safety vulnerabilities if misused.\nUnfortunately, existing tools for detecting memory bugs in Rust typically\nexhibit limited detection capabilities, inadequately handle Rust-specific\ntypes, or rely heavily on manual intervention.\n  To address these limitations, we present deepSURF, a tool that integrates\nstatic analysis with Large Language Model (LLM)-guided fuzzing harness\ngeneration to effectively identify memory safety vulnerabilities in Rust\nlibraries, specifically targeting unsafe code. deepSURF introduces a novel\napproach for handling generics by substituting them with custom types and\ngenerating tailored implementations for the required traits, enabling the\nfuzzer to simulate user-defined behaviors within the fuzzed library.\nAdditionally, deepSURF employs LLMs to augment fuzzing harnesses dynamically,\nfacilitating exploration of complex API interactions and significantly\nincreasing the likelihood of exposing memory safety vulnerabilities. We\nevaluated deepSURF on 27 real-world Rust crates, successfully rediscovering 20\nknown memory safety bugs and uncovering 6 previously unknown vulnerabilities,\ndemonstrating clear improvements over state-of-the-art tools.", "AI": {"tldr": "deepSURF\u662f\u4e00\u4e2a\u7ed3\u5408\u9759\u6001\u5206\u6790\u548cLLM\u5f15\u5bfc\u7684\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\uff0c\u7528\u4e8e\u68c0\u6d4bRust\u5e93\u4e2d\u7684\u5185\u5b58\u5b89\u5168\u6f0f\u6d1e\uff0c\u7279\u522b\u662f\u5728\u4e0d\u5b89\u5168\u4ee3\u7801\u4e2d\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u5728\u68c0\u6d4bRust\u5185\u5b58\u6f0f\u6d1e\u65f6\u80fd\u529b\u6709\u9650\uff0c\u65e0\u6cd5\u5145\u5206\u5904\u7406Rust\u7279\u6709\u7c7b\u578b\u6216\u4f9d\u8d56\u4eba\u5de5\u5e72\u9884\u3002", "method": "deepSURF\u901a\u8fc7\u66ff\u6362\u6cdb\u578b\u4e3a\u81ea\u5b9a\u4e49\u7c7b\u578b\u5e76\u751f\u6210\u7279\u8d28\u5b9e\u73b0\uff0c\u7ed3\u5408LLM\u52a8\u6001\u589e\u5f3a\u6a21\u7cca\u6d4b\u8bd5\u7528\u4f8b\uff0c\u63a2\u7d22\u590d\u6742API\u4ea4\u4e92\u3002", "result": "\u572827\u4e2a\u771f\u5b9eRust\u5e93\u4e2d\uff0cdeepSURF\u91cd\u65b0\u53d1\u73b0\u4e8620\u4e2a\u5df2\u77e5\u6f0f\u6d1e\u548c6\u4e2a\u65b0\u6f0f\u6d1e\u3002", "conclusion": "deepSURF\u5728\u68c0\u6d4b\u80fd\u529b\u4e0a\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6f0f\u6d1e\u53d1\u73b0\u7684\u6548\u7387\u3002"}}
{"id": "2506.15639", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15639", "abs": "https://arxiv.org/abs/2506.15639", "authors": ["James Weichert", "Daniel Dunlap", "Mohammed Farghally", "Hoda Eldardiry"], "title": "The AI Policy Module: Developing Computer Science Student Competency in AI Ethics and Policy", "comment": "Accepted at IEEE Frontiers in Education (FIE) 2025", "summary": "As artificial intelligence (AI) further embeds itself into many settings\nacross personal and professional contexts, increasing attention must be paid\nnot only to AI ethics, but also to the governance and regulation of AI\ntechnologies through AI policy. However, the prevailing post-secondary\ncomputing curriculum is currently ill-equipped to prepare future AI\npractitioners to confront increasing demands to implement abstract ethical\nprinciples and normative policy preferences into the design and development of\nAI systems. We believe that familiarity with the 'AI policy landscape' and the\nability to translate ethical principles to practices will in the future\nconstitute an important responsibility for even the most technically-focused AI\nengineers.\n  Toward preparing current computer science (CS) students for these new\nexpectations, we developed an AI Policy Module to introduce discussions of AI\npolicy into the CS curriculum. Building on a successful pilot in fall 2024, in\nthis innovative practice full paper we present an updated and expanded version\nof the module, including a technical assignment on \"AI regulation\". We present\nthe findings from our pilot of the AI Policy Module 2.0, evaluating student\nattitudes towards AI ethics and policy through pre- and post-module surveys.\nFollowing the module, students reported increased concern about the ethical\nimpacts of AI technologies while also expressing greater confidence in their\nabilities to engage in discussions about AI regulation. Finally, we highlight\nthe AI Regulation Assignment as an effective and engaging tool for exploring\nthe limits of AI alignment and emphasizing the role of 'policy' in addressing\nethical challenges.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5c06AI\u653f\u7b56\u6a21\u5757\u5f15\u5165\u8ba1\u7b97\u673a\u79d1\u5b66\u8bfe\u7a0b\uff0c\u5e2e\u52a9\u5b66\u751f\u5c06\u4f26\u7406\u539f\u5219\u8f6c\u5316\u4e3a\u5b9e\u8df5\uff0c\u5e76\u901a\u8fc7\u8bd5\u70b9\u8c03\u67e5\u9a8c\u8bc1\u5176\u6548\u679c\u3002", "motivation": "\u5f53\u524d\u8ba1\u7b97\u673a\u79d1\u5b66\u8bfe\u7a0b\u672a\u80fd\u5145\u5206\u57f9\u517b\u5b66\u751f\u5e94\u5bf9AI\u4f26\u7406\u548c\u653f\u7b56\u7684\u80fd\u529b\uff0c\u9700\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u5f00\u53d1\u5e76\u8bd5\u70b9AI\u653f\u7b56\u6a21\u57572.0\uff0c\u5305\u62ec\u6280\u672f\u4f5c\u4e1a\u548c\u524d\u540e\u8c03\u67e5\u8bc4\u4f30\u5b66\u751f\u6001\u5ea6\u53d8\u5316\u3002", "result": "\u5b66\u751f\u8868\u73b0\u51fa\u5bf9AI\u4f26\u7406\u5f71\u54cd\u7684\u66f4\u591a\u5173\u6ce8\uff0c\u5e76\u589e\u5f3a\u4e86\u53c2\u4e0eAI\u653f\u7b56\u8ba8\u8bba\u7684\u4fe1\u5fc3\u3002", "conclusion": "AI\u653f\u7b56\u6a21\u5757\u662f\u6709\u6548\u7684\u6559\u5b66\u5de5\u5177\uff0c\u80fd\u63d0\u5347\u5b66\u751f\u5bf9AI\u4f26\u7406\u548c\u653f\u7b56\u7684\u7406\u89e3\u4e0e\u5b9e\u8df5\u80fd\u529b\u3002"}}
{"id": "2506.15117", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.15117", "abs": "https://arxiv.org/abs/2506.15117", "authors": ["Ming Nie", "Zhixiong Yang", "Bingsheng Wei"], "title": "CipherMind: The Longest Codebook in the World", "comment": null, "summary": "In recent years, the widespread application of large language models has\ninspired us to consider using inference for communication encryption. We\ntherefore propose CipherMind, which utilizes intermediate results from\ndeterministic fine-tuning of large model inferences as transmission content.\nThe semantic parameters of large models exhibit characteristics like opaque\nunderlying implementations and weak interpretability, thus enabling their use\nas an encryption method for data transmission. This communication paradigm can\nbe applied in scenarios like intra-gateway transmission, and theoretically, it\ncan be implemented using any large model as its foundation.", "AI": {"tldr": "CipherMind\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u786e\u5b9a\u6027\u5fae\u8c03\u4e2d\u95f4\u7ed3\u679c\u4f5c\u4e3a\u4f20\u8f93\u5185\u5bb9\uff0c\u5b9e\u73b0\u901a\u4fe1\u52a0\u5bc6\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u53c2\u6570\u5177\u6709\u4e0d\u900f\u660e\u6027\u548c\u5f31\u53ef\u89e3\u91ca\u6027\uff0c\u9002\u5408\u7528\u4e8e\u6570\u636e\u52a0\u5bc6\u4f20\u8f93\u3002", "method": "\u901a\u8fc7\u5927\u6a21\u578b\u7684\u786e\u5b9a\u6027\u5fae\u8c03\u4e2d\u95f4\u7ed3\u679c\u4f5c\u4e3a\u4f20\u8f93\u5185\u5bb9\uff0c\u9002\u7528\u4e8e\u5982\u7f51\u5173\u5185\u4f20\u8f93\u7b49\u573a\u666f\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u6a21\u578b\u7684\u901a\u4fe1\u52a0\u5bc6\u65b9\u6cd5\uff0c\u7406\u8bba\u4e0a\u53ef\u9002\u7528\u4e8e\u4efb\u4f55\u5927\u6a21\u578b\u3002", "conclusion": "CipherMind\u4e3a\u901a\u4fe1\u52a0\u5bc6\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u8303\u5f0f\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.15647", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15647", "abs": "https://arxiv.org/abs/2506.15647", "authors": ["Weixiang Zhao", "Jiahe Guo", "Yang Deng", "Xingyu Sui", "Yulin Hu", "Yanyan Zhao", "Wanxiang Che", "Bing Qin", "Tat-Seng Chua", "Ting Liu"], "title": "Exploring and Exploiting the Inherent Efficiency within Large Reasoning Models for Self-Guided Efficiency Enhancement", "comment": null, "summary": "Recent advancements in large reasoning models (LRMs) have significantly\nenhanced language models' capabilities in complex problem-solving by emulating\nhuman-like deliberative thinking. However, these models often exhibit\noverthinking (i.e., the generation of unnecessarily verbose and redundant\ncontent), which hinders efficiency and inflates inference cost. In this work,\nwe explore the representational and behavioral origins of this inefficiency,\nrevealing that LRMs inherently possess the capacity for more concise reasoning.\nEmpirical analyses show that correct reasoning paths vary significantly in\nlength, and the shortest correct responses often suffice, indicating untapped\nefficiency potential. Exploiting these findings, we propose two lightweight\nmethods to enhance LRM efficiency. First, we introduce Efficiency Steering, a\ntraining-free activation steering technique that modulates reasoning behavior\nvia a single direction in the model's representation space. Second, we develop\nSelf-Rewarded Efficiency RL, a reinforcement learning framework that\ndynamically balances task accuracy and brevity by rewarding concise correct\nsolutions. Extensive experiments on seven LRM backbones across multiple\nmathematical reasoning benchmarks demonstrate that our methods significantly\nreduce reasoning length while preserving or improving task performance. Our\nresults highlight that reasoning efficiency can be improved by leveraging and\nguiding the intrinsic capabilities of existing models in a self-guided manner.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u5728\u590d\u6742\u95ee\u9898\u89e3\u51b3\u4e2d\u7684\u6548\u7387\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u8f7b\u91cf\u7ea7\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u63a8\u7406\u6548\u7387\u3002", "motivation": "LRMs\u5728\u6a21\u62df\u4eba\u7c7b\u601d\u8003\u65f6\u5b58\u5728\u8fc7\u5ea6\u63a8\u7406\uff08\u751f\u6210\u5197\u4f59\u5185\u5bb9\uff09\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u548c\u63a8\u7406\u6210\u672c\u589e\u52a0\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u65b9\u6cd5\uff1a1\uff09Efficiency Steering\uff08\u65e0\u9700\u8bad\u7ec3\u7684\u6fc0\u6d3b\u5bfc\u5411\u6280\u672f\uff09\uff1b2\uff09Self-Rewarded Efficiency RL\uff08\u52a8\u6001\u5e73\u8861\u4efb\u52a1\u51c6\u786e\u6027\u548c\u7b80\u6d01\u6027\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff09\u3002", "result": "\u5728\u591a\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u63a8\u7406\u957f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u5347\u4e86\u4efb\u52a1\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5bfc\u6a21\u578b\u5185\u5728\u80fd\u529b\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u63a8\u7406\u6548\u7387\u3002"}}
{"id": "2506.15170", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.15170", "abs": "https://arxiv.org/abs/2506.15170", "authors": ["Yanxu Mao", "Tiehan Cui", "Peipei Liu", "Datao You", "Hongsong Zhu"], "title": "From LLMs to MLLMs to Agents: A Survey of Emerging Paradigms in Jailbreak Attacks and Defenses within LLM Ecosystem", "comment": null, "summary": "Large language models (LLMs) are rapidly evolving from single-modal systems\nto multimodal LLMs and intelligent agents, significantly expanding their\ncapabilities while introducing increasingly severe security risks. This paper\npresents a systematic survey of the growing complexity of jailbreak attacks and\ncorresponding defense mechanisms within the expanding LLM ecosystem. We first\ntrace the developmental trajectory from LLMs to MLLMs and Agents, highlighting\nthe core security challenges emerging at each stage. Next, we categorize\nmainstream jailbreak techniques from both the attack impact and visibility\nperspectives, and provide a comprehensive analysis of representative attack\nmethods, related datasets, and evaluation metrics. On the defense side, we\norganize existing strategies based on response timing and technical approach,\noffering a structured understanding of their applicability and implementation.\nFurthermore, we identify key limitations in existing surveys, such as\ninsufficient attention to agent-specific security issues, the absence of a\nclear taxonomy for hybrid jailbreak methods, a lack of detailed analysis of\nexperimental setups, and outdated coverage of recent advancements. To address\nthese limitations, we provide an updated synthesis of recent work and outline\nfuture research directions in areas such as dataset construction, evaluation\nframework optimization, and strategy generalization. Our study seeks to enhance\nthe understanding of jailbreak mechanisms and facilitate the advancement of\nmore resilient and adaptive defense strategies in the context of ever more\ncapable LLMs.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6001\u7cfb\u7edf\u4e2d\u8d8a\u72f1\u653b\u51fb\u7684\u590d\u6742\u6027\u548c\u9632\u5fa1\u673a\u5236\uff0c\u5f3a\u8c03\u4e86\u4eceLLM\u5230\u591a\u6a21\u6001LLM\u548c\u667a\u80fd\u4ee3\u7406\u7684\u53d1\u5c55\u8fc7\u7a0b\u4e2d\u7684\u5b89\u5168\u6311\u6218\u3002", "motivation": "\u968f\u7740LLM\u80fd\u529b\u7684\u6269\u5c55\uff0c\u5176\u5b89\u5168\u98ce\u9669\u65e5\u76ca\u4e25\u91cd\uff0c\u9700\u8981\u7cfb\u7edf\u68b3\u7406\u8d8a\u72f1\u653b\u51fb\u548c\u9632\u5fa1\u673a\u5236\u7684\u7814\u7a76\u73b0\u72b6\u3002", "method": "\u901a\u8fc7\u5206\u7c7b\u4e3b\u6d41\u8d8a\u72f1\u6280\u672f\u3001\u5206\u6790\u653b\u51fb\u65b9\u6cd5\u548c\u9632\u5fa1\u7b56\u7565\uff0c\u5e76\u7ed3\u5408\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6307\u6807\uff0c\u63d0\u4f9b\u7ed3\u6784\u5316\u7406\u89e3\u3002", "result": "\u603b\u7ed3\u4e86\u73b0\u6709\u7814\u7a76\u7684\u5c40\u9650\u6027\uff0c\u5982\u5bf9\u4ee3\u7406\u7279\u5b9a\u5b89\u5168\u95ee\u9898\u7684\u5173\u6ce8\u4e0d\u8db3\u3001\u6df7\u5408\u8d8a\u72f1\u65b9\u6cd5\u5206\u7c7b\u4e0d\u6e05\u6670\u7b49\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u7814\u7a76\u65e8\u5728\u589e\u5f3a\u5bf9\u8d8a\u72f1\u673a\u5236\u7684\u7406\u89e3\uff0c\u63a8\u52a8\u66f4\u5f3a\u5927\u548c\u9002\u5e94\u6027\u5f3a\u7684\u9632\u5fa1\u7b56\u7565\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.15212", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.15212", "abs": "https://arxiv.org/abs/2506.15212", "authors": ["Madjid G. Tehrani", "Eldar Sultanow", "William J. Buchanan", "Mahkame Houmani", "Christel H. Djaha Fodja"], "title": "LLM vs. SAST: A Technical Analysis on Detecting Coding Bugs of GPT4-Advanced Data Analysis", "comment": null, "summary": "With the rapid advancements in Natural Language Processing (NLP), large\nlanguage models (LLMs) like GPT-4 have gained significant traction in diverse\napplications, including security vulnerability scanning. This paper\ninvestigates the efficacy of GPT-4 in identifying software vulnerabilities\ncompared to traditional Static Application Security Testing (SAST) tools.\nDrawing from an array of security mistakes, our analysis underscores the potent\ncapabilities of GPT-4 in LLM-enhanced vulnerability scanning. We unveiled that\nGPT-4 (Advanced Data Analysis) outperforms SAST by an accuracy of 94% in\ndetecting 32 types of exploitable vulnerabilities. This study also addresses\nthe potential security concerns surrounding LLMs, emphasising the imperative of\nsecurity by design/default and other security best practices for AI.", "AI": {"tldr": "GPT-4\u5728\u6f0f\u6d1e\u626b\u63cf\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edfSAST\u5de5\u5177\uff0c\u51c6\u786e\u7387\u8fbe94%\uff0c\u4f46\u4e5f\u9700\u5173\u6ce8LLM\u7684\u5b89\u5168\u95ee\u9898\u3002", "motivation": "\u7814\u7a76GPT-4\u5728\u8bc6\u522b\u8f6f\u4ef6\u6f0f\u6d1e\u65b9\u9762\u7684\u6548\u679c\uff0c\u5e76\u4e0e\u4f20\u7edfSAST\u5de5\u5177\u5bf9\u6bd4\u3002", "method": "\u901a\u8fc7\u5206\u6790\u591a\u79cd\u5b89\u5168\u9519\u8bef\uff0c\u8bc4\u4f30GPT-4\u5728\u6f0f\u6d1e\u626b\u63cf\u4e2d\u7684\u8868\u73b0\u3002", "result": "GPT-4\uff08\u9ad8\u7ea7\u6570\u636e\u5206\u6790\uff09\u5728\u68c0\u6d4b32\u79cd\u53ef\u5229\u7528\u6f0f\u6d1e\u65f6\u51c6\u786e\u7387\u8fbe94%\uff0c\u4f18\u4e8eSAST\u5de5\u5177\u3002", "conclusion": "GPT-4\u5728\u6f0f\u6d1e\u626b\u63cf\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u9700\u7ed3\u5408\u5b89\u5168\u8bbe\u8ba1\u548c\u5176\u4ed6AI\u5b89\u5168\u6700\u4f73\u5b9e\u8df5\u3002"}}
{"id": "2506.15677", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.MM", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.15677", "abs": "https://arxiv.org/abs/2506.15677", "authors": ["Yining Hong", "Rui Sun", "Bingxuan Li", "Xingcheng Yao", "Maxine Wu", "Alexander Chien", "Da Yin", "Ying Nian Wu", "Zhecan James Wang", "Kai-Wei Chang"], "title": "Embodied Web Agents: Bridging Physical-Digital Realms for Integrated Agent Intelligence", "comment": null, "summary": "AI agents today are mostly siloed - they either retrieve and reason over vast\namount of digital information and knowledge obtained online; or interact with\nthe physical world through embodied perception, planning and action - but\nrarely both. This separation limits their ability to solve tasks that require\nintegrated physical and digital intelligence, such as cooking from online\nrecipes, navigating with dynamic map data, or interpreting real-world landmarks\nusing web knowledge. We introduce Embodied Web Agents, a novel paradigm for AI\nagents that fluidly bridge embodiment and web-scale reasoning. To\noperationalize this concept, we first develop the Embodied Web Agents task\nenvironments, a unified simulation platform that tightly integrates realistic\n3D indoor and outdoor environments with functional web interfaces. Building\nupon this platform, we construct and release the Embodied Web Agents Benchmark,\nwhich encompasses a diverse suite of tasks including cooking, navigation,\nshopping, tourism, and geolocation - all requiring coordinated reasoning across\nphysical and digital realms for systematic assessment of cross-domain\nintelligence. Experimental results reveal significant performance gaps between\nstate-of-the-art AI systems and human capabilities, establishing both\nchallenges and opportunities at the intersection of embodied cognition and\nweb-scale knowledge access. All datasets, codes and websites are publicly\navailable at our project page https://embodied-web-agent.github.io/.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578bAI\u4ee3\u7406\u8303\u5f0f\u2014\u2014Embodied Web Agents\uff0c\u65e8\u5728\u7ed3\u5408\u7269\u7406\u4e16\u754c\u4ea4\u4e92\u4e0e\u7f51\u7edc\u63a8\u7406\u80fd\u529b\uff0c\u89e3\u51b3\u8de8\u9886\u57df\u4efb\u52a1\u3002", "motivation": "\u5f53\u524dAI\u4ee3\u7406\u591a\u4e3a\u5b64\u7acb\u7cfb\u7edf\uff0c\u65e0\u6cd5\u540c\u65f6\u5904\u7406\u7269\u7406\u4e16\u754c\u4ea4\u4e92\u4e0e\u7f51\u7edc\u4fe1\u606f\u63a8\u7406\uff0c\u9650\u5236\u4e86\u5176\u89e3\u51b3\u8de8\u9886\u57df\u4efb\u52a1\u7684\u80fd\u529b\u3002", "method": "\u5f00\u53d1\u4e86\u7edf\u4e00\u7684\u4eff\u771f\u5e73\u53f0\uff08Embodied Web Agents task environments\uff09\u548c\u57fa\u51c6\u6d4b\u8bd5\uff08Embodied Web Agents Benchmark\uff09\uff0c\u6db5\u76d6\u591a\u79cd\u8de8\u9886\u57df\u4efb\u52a1\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u73b0\u6709AI\u7cfb\u7edf\u4e0e\u4eba\u7c7b\u80fd\u529b\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u63ed\u793a\u4e86\u7ed3\u5408\u7269\u7406\u8ba4\u77e5\u4e0e\u7f51\u7edc\u77e5\u8bc6\u8bbf\u95ee\u7684\u6311\u6218\u4e0e\u673a\u9047\u3002", "conclusion": "\u8bba\u6587\u4e3aAI\u4ee3\u7406\u7684\u8de8\u9886\u57df\u667a\u80fd\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\uff0c\u5e76\u516c\u5f00\u4e86\u6570\u636e\u96c6\u3001\u4ee3\u7801\u548c\u5e73\u53f0\u3002"}}
{"id": "2506.15224", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.15224", "abs": "https://arxiv.org/abs/2506.15224", "authors": ["Kevin Pfisterer", "Quentin Hillebrand", "Vorapong Suppakitpaisarn"], "title": "Facility Location Problem under Local Differential Privacy without Super-set Assumption", "comment": "accepted at DBSec 2025", "summary": "In this paper, we introduce an adaptation of the facility location problem\nand analyze it within the framework of local differential privacy (LDP). Under\nthis model, we ensure the privacy of client presence at specific locations.\nWhen n is the number of points, Gupta et al. established a lower bound of\n$\\Omega(\\sqrt{n})$ on the approximation ratio for any differentially private\nalgorithm applied to the original facility location problem. As a result,\nsubsequent works have adopted the super-set assumption, which may, however,\ncompromise user privacy. We show that this lower bound does not apply to our\nadaptation by presenting an LDP algorithm that achieves a constant\napproximation ratio with a relatively small additive factor. Additionally, we\nprovide experimental results demonstrating that our algorithm outperforms the\nstraightforward approach on both synthetically generated and real-world\ndatasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bbe\u65bd\u4f4d\u7f6e\u95ee\u9898\u7684\u6539\u8fdb\u7248\u672c\uff0c\u5e76\u5728\u672c\u5730\u5dee\u5206\u9690\u79c1\uff08LDP\uff09\u6846\u67b6\u4e0b\u8fdb\u884c\u4e86\u5206\u6790\u3002\u901a\u8fc7LDP\u7b97\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5e38\u6570\u8fd1\u4f3c\u6bd4\u548c\u5c0f\u9644\u52a0\u56e0\u5b50\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5728\u539f\u59cb\u8bbe\u65bd\u4f4d\u7f6e\u95ee\u9898\u4e2d\uff0c\u5dee\u5206\u9690\u79c1\u7b97\u6cd5\u7684\u8fd1\u4f3c\u6bd4\u4e0b\u754c\u4e3a\u03a9(\u221an)\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u91c7\u7528\u8d85\u96c6\u5047\u8bbe\u53ef\u80fd\u635f\u5bb3\u7528\u6237\u9690\u79c1\u3002\u672c\u6587\u65e8\u5728\u8bc1\u660e\u8fd9\u4e00\u4e0b\u754c\u4e0d\u9002\u7528\u4e8e\u6539\u8fdb\u7248\u672c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLDP\u7684\u7b97\u6cd5\uff0c\u786e\u4fdd\u7528\u6237\u5728\u7279\u5b9a\u4f4d\u7f6e\u7684\u5b58\u5728\u9690\u79c1\uff0c\u5e76\u5b9e\u73b0\u4e86\u5e38\u6570\u8fd1\u4f3c\u6bd4\u548c\u5c0f\u9644\u52a0\u56e0\u5b50\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7b97\u6cd5\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5747\u4f18\u4e8e\u76f4\u63a5\u65b9\u6cd5\u3002", "conclusion": "\u6539\u8fdb\u7684\u8bbe\u65bd\u4f4d\u7f6e\u95ee\u9898\u5728LDP\u6846\u67b6\u4e0b\u53ef\u4ee5\u5b9e\u73b0\u9ad8\u6548\u4e14\u9690\u79c1\u4fdd\u62a4\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7a81\u7834\u4e86\u539f\u59cb\u95ee\u9898\u7684\u9650\u5236\u3002"}}
{"id": "2506.15253", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15253", "abs": "https://arxiv.org/abs/2506.15253", "authors": ["Yuchuan Fu", "Xiaohan Yuan", "Dongxia Wang"], "title": "RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments", "comment": "12 pages, 8 figures", "summary": "The rapid deployment of Large language model (LLM) agents in critical domains\nlike healthcare and finance necessitates robust security frameworks. To address\nthe absence of standardized evaluation benchmarks for these agents in dynamic\nenvironments, we introduce RAS-Eval, a comprehensive security benchmark\nsupporting both simulated and real-world tool execution. RAS-Eval comprises 80\ntest cases and 3,802 attack tasks mapped to 11 Common Weakness Enumeration\n(CWE) categories, with tools implemented in JSON, LangGraph, and Model Context\nProtocol (MCP) formats. We evaluate 6 state-of-the-art LLMs across diverse\nscenarios, revealing significant vulnerabilities: attacks reduced agent task\ncompletion rates (TCR) by 36.78% on average and achieved an 85.65% success rate\nin academic settings. Notably, scaling laws held for security capabilities,\nwith larger models outperforming smaller counterparts. Our findings expose\ncritical risks in real-world agent deployments and provide a foundational\nframework for future security research. Code and data are available at\nhttps://github.com/lanzer-tree/RAS-Eval.", "AI": {"tldr": "RAS-Eval\u662f\u4e00\u4e2a\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u7684\u5b89\u5168\u8bc4\u4f30\u57fa\u51c6\uff0c\u5305\u542b80\u4e2a\u6d4b\u8bd5\u7528\u4f8b\u548c3,802\u4e2a\u653b\u51fb\u4efb\u52a1\uff0c\u8986\u76d611\u4e2aCWE\u7c7b\u522b\u3002\u8bc4\u4f30\u663e\u793a\uff0c\u653b\u51fb\u5e73\u5747\u964d\u4f4e\u4efb\u52a1\u5b8c\u6210\u738736.78%\uff0c\u5b66\u672f\u73af\u5883\u4e2d\u6210\u529f\u7387\u9ad8\u8fbe85.65%\u3002", "motivation": "\u7531\u4e8eLLM\u4ee3\u7406\u5728\u533b\u7597\u548c\u91d1\u878d\u7b49\u5173\u952e\u9886\u57df\u7684\u5feb\u901f\u90e8\u7f72\uff0c\u7f3a\u4e4f\u6807\u51c6\u5316\u5b89\u5168\u8bc4\u4f30\u57fa\u51c6\uff0c\u4e9f\u9700\u52a8\u6001\u73af\u5883\u4e0b\u7684\u5b89\u5168\u6846\u67b6\u3002", "method": "\u63d0\u51faRAS-Eval\u57fa\u51c6\uff0c\u652f\u6301\u6a21\u62df\u548c\u771f\u5b9e\u5de5\u5177\u6267\u884c\uff0c\u4f7f\u7528JSON\u3001LangGraph\u548cMCP\u683c\u5f0f\u5b9e\u73b0\u5de5\u5177\uff0c\u8bc4\u4f306\u79cd\u5148\u8fdbLLM\u3002", "result": "\u653b\u51fb\u663e\u8457\u964d\u4f4e\u4efb\u52a1\u5b8c\u6210\u7387\uff0c\u5b66\u672f\u73af\u5883\u4e2d\u653b\u51fb\u6210\u529f\u7387\u6781\u9ad8\uff0c\u4e14\u6a21\u578b\u89c4\u6a21\u4e0e\u5b89\u5168\u80fd\u529b\u6b63\u76f8\u5173\u3002", "conclusion": "RAS-Eval\u63ed\u793a\u4e86LLM\u4ee3\u7406\u90e8\u7f72\u4e2d\u7684\u5173\u952e\u98ce\u9669\uff0c\u4e3a\u672a\u6765\u5b89\u5168\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\u6846\u67b6\u3002"}}
{"id": "2506.15388", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15388", "abs": "https://arxiv.org/abs/2506.15388", "authors": ["Florian Rokohl", "Alexander Lehnert", "Marc Reichenbach"], "title": "Evaluation Pipeline for systematically searching for Anomaly Detection Systems", "comment": "Submitted to 18th HiPEAC Workshop on Reconfigurable Computing\n  (WRC'2024)", "summary": "Digitalization in the medical world provides major benefits while making it a\ntarget for attackers and thus hard to secure. To deal with network intruders we\npropose an anomaly detection system on hardware to detect malicious clients in\nreal-time. We meet real-time and power restrictions using FPGAs. Overall system\nperformance is achieved via the presented holistic system evaluation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eFPGA\u7684\u786c\u4ef6\u5f02\u5e38\u68c0\u6d4b\u7cfb\u7edf\uff0c\u7528\u4e8e\u5b9e\u65f6\u68c0\u6d4b\u533b\u7597\u6570\u5b57\u5316\u73af\u5883\u4e2d\u7684\u6076\u610f\u5ba2\u6237\u7aef\u3002", "motivation": "\u533b\u7597\u6570\u5b57\u5316\u5e26\u6765\u4e86\u5de8\u5927\u597d\u5904\uff0c\u4f46\u4e5f\u6210\u4e3a\u653b\u51fb\u76ee\u6807\uff0c\u96be\u4ee5\u4fdd\u969c\u5b89\u5168\u3002", "method": "\u4f7f\u7528FPGA\u6ee1\u8db3\u5b9e\u65f6\u6027\u548c\u529f\u8017\u9650\u5236\uff0c\u901a\u8fc7\u6574\u4f53\u7cfb\u7edf\u8bc4\u4f30\u5b9e\u73b0\u6027\u80fd\u3002", "result": "\u7cfb\u7edf\u80fd\u591f\u5b9e\u65f6\u68c0\u6d4b\u6076\u610f\u5ba2\u6237\u7aef\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u533b\u7597\u6570\u5b57\u5316\u73af\u5883\u4e2d\u6709\u6548\u63d0\u5347\u4e86\u5b89\u5168\u6027\u3002"}}
{"id": "2506.15417", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.15417", "abs": "https://arxiv.org/abs/2506.15417", "authors": ["Alessandro Palumbo", "Ruben Salvador"], "title": "Detecting Hardware Trojans in Microprocessors via Hardware Error Correction Code-based Modules", "comment": "To appear at the 31st IEEE International Symposium on On-Line Testing\n  and Robust System Design (IOLTS) 2025, 7 pages, 5 figures,", "summary": "Software-exploitable Hardware Trojans (HTs) enable attackers to execute\nunauthorized software or gain illicit access to privileged operations. This\nmanuscript introduces a hardware-based methodology for detecting runtime HT\nactivations using Error Correction Codes (ECCs) on a RISC-V microprocessor.\nSpecifically, it focuses on HTs that inject malicious instructions, disrupting\nthe normal execution flow by triggering unauthorized programs. To counter this\nthreat, the manuscript introduces a Hardware Security Checker (HSC) leveraging\nHamming Single Error Correction (HSEC) architectures for effective HT\ndetection. Experimental results demonstrate that the proposed solution achieves\na 100% detection rate for potential HT activations, with no false positives or\nundetected attacks. The implementation incurs minimal overhead, requiring only\n72 #LUTs, 24 #FFs, and 0.5 #BRAM while maintaining the microprocessor's\noriginal operating frequency and introducing no additional time delay.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u786c\u4ef6\u7684\u65b9\u6cd5\uff0c\u5229\u7528RISC-V\u5fae\u5904\u7406\u5668\u4e0a\u7684\u7ea0\u9519\u7801\uff08ECC\uff09\u68c0\u6d4b\u8fd0\u884c\u65f6\u786c\u4ef6\u6728\u9a6c\uff08HT\uff09\u6fc0\u6d3b\uff0c\u91cd\u70b9\u5173\u6ce8\u6ce8\u5165\u6076\u610f\u6307\u4ee4\u7684HT\u3002", "motivation": "\u786c\u4ef6\u6728\u9a6c\uff08HT\uff09\u53ef\u80fd\u5bfc\u81f4\u672a\u7ecf\u6388\u6743\u7684\u8f6f\u4ef6\u6267\u884c\u6216\u7279\u6743\u64cd\u4f5c\u8bbf\u95ee\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u6c49\u660e\u5355\u7ea0\u9519\uff08HSEC\uff09\u67b6\u6784\u7684\u786c\u4ef6\u5b89\u5168\u68c0\u67e5\u5668\uff08HSC\uff09\u6765\u68c0\u6d4bHT\u6fc0\u6d3b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5bf9\u6f5c\u5728HT\u6fc0\u6d3b\u7684\u68c0\u6d4b\u7387\u8fbe\u5230100%\uff0c\u65e0\u5047\u9633\u6027\u6216\u6f0f\u68c0\uff0c\u4e14\u786c\u4ef6\u5f00\u9500\u6781\u4f4e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9ad8\u6548\u4e14\u4f4e\u5f00\u9500\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u68c0\u6d4b\u786c\u4ef6\u6728\u9a6c\uff0c\u4fdd\u969c\u5fae\u5904\u7406\u5668\u5b89\u5168\u3002"}}
{"id": "2506.15432", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.15432", "abs": "https://arxiv.org/abs/2506.15432", "authors": ["Guillaume Lomet", "Ruben Salvador", "Brice Colombier", "Vincent Grosso", "Olivier Sentieys", "Cedric Killian"], "title": "Side-Channel Extraction of Dataflow AI Accelerator Hardware Parameters", "comment": "To appear at the 31st IEEE International Symposium on On-Line Testing\n  and Robust System Design (IOLTS) 2025, 7 pages, 4 figures, 1 algorithm", "summary": "Dataflow neural network accelerators efficiently process AI tasks on FPGAs,\nwith deployment simplified by ready-to-use frameworks and pre-trained models.\nHowever, this convenience makes them vulnerable to malicious actors seeking to\nreverse engineer valuable Intellectual Property (IP) through Side-Channel\nAttacks (SCA). This paper proposes a methodology to recover the hardware\nconfiguration of dataflow accelerators generated with the FINN framework.\nThrough unsupervised dimensionality reduction, we reduce the computational\noverhead compared to the state-of-the-art, enabling lightweight classifiers to\nrecover both folding and quantization parameters. We demonstrate an attack\nphase requiring only 337 ms to recover the hardware parameters with an accuracy\nof more than 95% and 421 ms to fully recover these parameters with an averaging\nof 4 traces for a FINN-based accelerator running a CNN, both using a random\nforest classifier on side-channel traces, even with the accelerator dataflow\nfully loaded. This approach offers a more realistic attack scenario than\nexisting methods, and compared to SoA attacks based on tsfresh, our method\nrequires 940x and 110x less time for preparation and attack phases,\nrespectively, and gives better results even without averaging traces.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u4fa7\u4fe1\u9053\u653b\u51fb\uff08SCA\uff09\u6062\u590dFINN\u6846\u67b6\u751f\u6210\u7684\u6570\u636e\u6d41\u52a0\u901f\u5668\u786c\u4ef6\u914d\u7f6e\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u5f00\u9500\uff0c\u5e76\u5728\u77ed\u65f6\u95f4\u5185\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u7684\u53c2\u6570\u6062\u590d\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u6d41\u795e\u7ecf\u7f51\u7edc\u52a0\u901f\u5668\u6613\u53d7\u6076\u610f\u653b\u51fb\u8005\u901a\u8fc7\u4fa7\u4fe1\u9053\u653b\u51fb\u9006\u5411\u5de5\u7a0b\uff0c\u5a01\u80c1\u77e5\u8bc6\u4ea7\u6743\u5b89\u5168\u3002", "method": "\u91c7\u7528\u65e0\u76d1\u7763\u964d\u7ef4\u6280\u672f\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\uff0c\u7ed3\u5408\u8f7b\u91cf\u7ea7\u5206\u7c7b\u5668\u6062\u590d\u6298\u53e0\u548c\u91cf\u5316\u53c2\u6570\u3002", "result": "\u653b\u51fb\u9636\u6bb5\u4ec5\u9700337\u6beb\u79d2\u6062\u590d\u786c\u4ef6\u53c2\u6570\uff08\u7cbe\u5ea6>95%\uff09\uff0c421\u6beb\u79d2\u5b8c\u5168\u6062\u590d\u53c2\u6570\uff08\u5e73\u57474\u6761\u8f68\u8ff9\uff09\uff0c\u8ba1\u7b97\u6548\u7387\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u66f4\u73b0\u5b9e\u7684\u653b\u51fb\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8ba1\u7b97\u6548\u7387\u63d0\u5347\u663e\u8457\uff0c\u4e14\u65e0\u9700\u8f68\u8ff9\u5e73\u5747\u5373\u53ef\u83b7\u5f97\u66f4\u597d\u7ed3\u679c\u3002"}}
{"id": "2506.15547", "categories": ["cs.CR", "cs.CC", "quant-ph"], "pdf": "https://arxiv.org/pdf/2506.15547", "abs": "https://arxiv.org/abs/2506.15547", "authors": ["Cameron Foreman", "Lewis Wooltorton", "Kevin Milner", "Florian J. Curchod"], "title": "An efficient construction of Raz's two-source randomness extractor with improved parameters", "comment": "12 + 11 pages. Comments welcome!", "summary": "Randomness extractors are algorithms that distill weak random sources into\nnear-perfect random numbers. Two-source extractors enable this distillation\nprocess by combining two independent weak random sources. Raz's extractor (STOC\n'05) was the first to achieve this in a setting where one source has linear\nmin-entropy (i.e., proportional to its length), while the other has only\nlogarithmic min-entropy in its length. However, Raz's original construction is\nimpractical due to a polynomial computation time of at least degree 4. Our work\nsolves this problem by presenting an improved version of Raz's extractor with\nquasi-linear computation time, as well as a new analytic theorem with reduced\nentropy requirements. We provide comprehensive analytical and numerical\ncomparisons of our construction with others in the literature, and we derive\nstrong and quantum-proof versions of our efficient Raz extractor. Additionally,\nwe offer an easy-to-use, open-source code implementation of the extractor and a\nnumerical parameter calculation module.", "AI": {"tldr": "\u6539\u8fdb\u4e86Raz\u7684\u63d0\u53d6\u5668\uff0c\u5b9e\u73b0\u4e86\u51c6\u7ebf\u6027\u8ba1\u7b97\u65f6\u95f4\uff0c\u5e76\u964d\u4f4e\u4e86\u71b5\u9700\u6c42\uff0c\u63d0\u4f9b\u4e86\u5206\u6790\u548c\u6570\u503c\u6bd4\u8f83\uff0c\u4ee5\u53ca\u5f3a\u548c\u91cf\u5b50\u8bc1\u660e\u7248\u672c\u3002", "motivation": "\u89e3\u51b3Raz\u63d0\u53d6\u5668\u56e0\u8ba1\u7b97\u65f6\u95f4\u8fc7\u957f\u800c\u4e0d\u5b9e\u7528\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u6539\u8fdb\u7248\u672c\u7684Raz\u63d0\u53d6\u5668\uff0c\u964d\u4f4e\u71b5\u9700\u6c42\u5e76\u4f18\u5316\u8ba1\u7b97\u65f6\u95f4\u3002", "result": "\u5b9e\u73b0\u4e86\u51c6\u7ebf\u6027\u8ba1\u7b97\u65f6\u95f4\uff0c\u63d0\u4f9b\u5f3a\u548c\u91cf\u5b50\u8bc1\u660e\u7248\u672c\uff0c\u5e76\u5f00\u6e90\u4ee3\u7801\u5b9e\u73b0\u3002", "conclusion": "\u6539\u8fdb\u540e\u7684\u63d0\u53d6\u5668\u66f4\u9ad8\u6548\u5b9e\u7528\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2506.15656", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2506.15656", "abs": "https://arxiv.org/abs/2506.15656", "authors": ["Wenhao Li", "Selvakumar Manickam", "Yung-wey Chong", "Shankar Karuppayah"], "title": "PhishDebate: An LLM-Based Multi-Agent Framework for Phishing Website Detection", "comment": null, "summary": "Phishing websites continue to pose a significant cybersecurity threat, often\nleveraging deceptive structures, brand impersonation, and social engineering\ntactics to evade detection. While recent advances in large language models\n(LLMs) have enabled improved phishing detection through contextual\nunderstanding, most existing approaches rely on single-agent classification\nfacing the risks of hallucination and lack interpretability or robustness. To\naddress these limitations, we propose PhishDebate, a modular multi-agent\nLLM-based debate framework for phishing website detection. PhishDebate employs\nfour specialized agents to independently analyze different textual aspects of a\nwebpage--URL structure, HTML composition, semantic content, and brand\nimpersonation--under the coordination of a Moderator and a final Judge. Through\nstructured debate and divergent thinking, the framework delivers more accurate\nand interpretable decisions. Extensive evaluations on commercial LLMs\ndemonstrate that PhishDebate achieves 98.2% recall and 98.2% True Positive Rate\n(TPR) on a real-world phishing dataset, and outperforms single-agent and Chain\nof Thought (CoT) baselines. Additionally, its modular design allows agent-level\nconfigurability, enabling adaptation to varying resource and application\nrequirements.", "AI": {"tldr": "PhishDebate\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u4ee3\u7406LLM\u7684\u9493\u9c7c\u7f51\u7ad9\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\u548c\u7ed3\u6784\u5316\u8fa9\u8bba\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u9493\u9c7c\u7f51\u7ad9\u901a\u8fc7\u6b3a\u9a97\u6027\u7ed3\u6784\u548c\u793e\u4ea4\u5de5\u7a0b\u9003\u907f\u68c0\u6d4b\uff0c\u73b0\u6709\u5355\u4ee3\u7406\u5206\u7c7b\u65b9\u6cd5\u5b58\u5728\u5e7b\u89c9\u548c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u95ee\u9898\u3002", "method": "PhishDebate\u91c7\u7528\u56db\u4e2a\u4e13\u95e8\u4ee3\u7406\u5206\u6790\u7f51\u9875\u7684\u4e0d\u540c\u6587\u672c\u65b9\u9762\uff08URL\u7ed3\u6784\u3001HTML\u7ec4\u6210\u3001\u8bed\u4e49\u5185\u5bb9\u548c\u54c1\u724c\u5192\u5145\uff09\uff0c\u7531\u534f\u8c03\u5458\u548c\u6cd5\u5b98\u8fdb\u884c\u7ed3\u6784\u5316\u8fa9\u8bba\u3002", "result": "\u5728\u771f\u5b9e\u9493\u9c7c\u6570\u636e\u96c6\u4e0a\uff0cPhishDebate\u53ec\u56de\u7387\u548c\u771f\u9633\u6027\u7387\u5747\u8fbe98.2%\uff0c\u4f18\u4e8e\u5355\u4ee3\u7406\u548cCoT\u57fa\u7ebf\u3002", "conclusion": "PhishDebate\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\u548c\u591a\u4ee3\u7406\u8fa9\u8bba\u663e\u8457\u63d0\u5347\u4e86\u9493\u9c7c\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u9002\u5e94\u6027\u3002"}}
