{"id": "2512.00106", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.00106", "abs": "https://arxiv.org/abs/2512.00106", "authors": ["Markus Funke", "Patricia Lago"], "title": "Injecting Sustainability in Software Architecture: A Rapid Review", "comment": "(Accepted/In press) 10th IEEE/ACM International Workshop on Green and Sustainable Software (GREENS '26): GREENS@ICSE 2026", "summary": "Sustainability has evolved from an emerging concern into a fundamental responsibility in software design, development, and operation. Research increasingly explores how sustainability can be systematically integrated into existing software engineering practices. Building on an industry-academia collaboration, we contribute to this discourse by conducting a mixed-method empirical study. We combine a rapid review of secondary studies with a focus group of practitioners. The review identifies challenges and opportunities in embedding sustainability in software architecture, while the focus group enriches and compares these findings. Based on the literature and industry synthesis, we derive five tangible takeaways to inform architects working in the field, and to guide our industry partners in the integration of sustainability concerns in architecture practices.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u6df7\u5408\u65b9\u6cd5\u5b9e\u8bc1\u7814\u7a76\uff0c\u7ed3\u5408\u6587\u732e\u7efc\u8ff0\u548c\u7126\u70b9\u5c0f\u7ec4\uff0c\u63a2\u8ba8\u5982\u4f55\u5728\u8f6f\u4ef6\u67b6\u6784\u4e2d\u7cfb\u7edf\u6027\u5730\u6574\u5408\u53ef\u6301\u7eed\u6027\u8003\u91cf\uff0c\u4e3a\u4ece\u4e1a\u8005\u63d0\u4f9b\u5b9e\u7528\u6307\u5bfc\u3002", "motivation": "\u53ef\u6301\u7eed\u6027\u5df2\u4ece\u65b0\u5174\u5173\u6ce8\u70b9\u53d1\u5c55\u4e3a\u8f6f\u4ef6\u8bbe\u8ba1\u3001\u5f00\u53d1\u548c\u8fd0\u7ef4\u7684\u57fa\u672c\u8d23\u4efb\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u5c06\u53ef\u6301\u7eed\u6027\u7cfb\u7edf\u6027\u5730\u6574\u5408\u5230\u73b0\u6709\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\u4e2d\uff0c\u7279\u522b\u662f\u8f6f\u4ef6\u67b6\u6784\u5c42\u9762\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u5b9e\u8bc1\u7814\u7a76\uff1a1\uff09\u5bf9\u4e8c\u624b\u7814\u7a76\u8fdb\u884c\u5feb\u901f\u6587\u732e\u7efc\u8ff0\uff0c\u8bc6\u522b\u8f6f\u4ef6\u67b6\u6784\u4e2d\u5d4c\u5165\u53ef\u6301\u7eed\u6027\u7684\u6311\u6218\u548c\u673a\u9047\uff1b2\uff09\u4e0e\u4ece\u4e1a\u8005\u8fdb\u884c\u7126\u70b9\u5c0f\u7ec4\u8ba8\u8bba\uff0c\u4e30\u5bcc\u5e76\u9a8c\u8bc1\u6587\u732e\u53d1\u73b0\u3002", "result": "\u57fa\u4e8e\u6587\u732e\u548c\u884c\u4e1a\u7efc\u5408\uff0c\u7814\u7a76\u5f97\u51fa\u4e86\u4e94\u4e2a\u5207\u5b9e\u53ef\u884c\u7684\u8981\u70b9\uff0c\u7528\u4e8e\u6307\u5bfc\u8f6f\u4ef6\u67b6\u6784\u5e08\u5728\u5b9e\u9645\u5de5\u4f5c\u4e2d\u6574\u5408\u53ef\u6301\u7eed\u6027\u8003\u91cf\uff0c\u5e76\u4e3a\u884c\u4e1a\u5408\u4f5c\u4f19\u4f34\u63d0\u4f9b\u5b9e\u8df5\u6307\u5bfc\u3002", "conclusion": "\u901a\u8fc7\u4ea7\u5b66\u5408\u4f5c\uff0c\u8be5\u7814\u7a76\u4e3a\u8f6f\u4ef6\u67b6\u6784\u4e2d\u53ef\u6301\u7eed\u6027\u7684\u7cfb\u7edf\u6027\u6574\u5408\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\u548c\u5b9e\u8df5\u6307\u5bfc\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u53ef\u6301\u7eed\u6027\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2512.00127", "categories": ["cs.SE", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2512.00127", "abs": "https://arxiv.org/abs/2512.00127", "authors": ["Shailja Thakur", "Vaibhav Saxena", "Rohan Kulkarni", "Shivdeep Singh", "Parameswaran Selvam", "Hima Patel", "Hiroshi Kanayama"], "title": "Generating Verifiable CoT from Execution-Traces", "comment": null, "summary": "Teaching language models to reason about code execution remains a fundamental challenge. While Chain-of-Thought (CoT) prompting has shown promise, current synthetic training data suffers from a critical weakness: the reasoning steps are often plausible-sounding explanations generated by teacher models, not verifiable accounts of what the code actually does. This creates a troubling failure mode where models learn to mimic superficially convincing but logically flawed reasoning patterns.\n  We address this by grounding CoT generation directly in program execution traces. Our pipeline instruments code to capture its dynamic behavior, then narrates these verified execution traces into natural language rationales that are correct by construction. This execution-grounded approach ensures every reasoning step reflects what the program genuinely computes, eliminating logical hallucinations at the source. We evaluate our method on code reasoning tasks (forward reasoning on CruxEval and LiveCodeBench-Exec, backward reasoning on CruxEval-Input), as well as code generation and explanation tasks from HumanEval. Models trained on our bi-directional trace-grounded data achieve substantial improvements, with gains of up to 30 points on output prediction and 28 points on input prediction over base models, alongside improved explanation and code generation, demonstrating that verifiable reasoning fundamentally enhances model capabilities. https://github.ibm.com/IBM-Research-AI/Verified-Code-CoT", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7a0b\u5e8f\u6267\u884c\u8f68\u8ff9\u7684\u4ee3\u7801\u63a8\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u4ee3\u7801\u6267\u884c\u8fc7\u7a0b\u8f6c\u5316\u4e3a\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff0c\u786e\u4fdd\u63a8\u7406\u6b65\u9aa4\u7684\u6b63\u786e\u6027\uff0c\u4ece\u800c\u89e3\u51b3\u4f20\u7edfCoT\u63d0\u793a\u4e2d\u5b58\u5728\u7684\u903b\u8f91\u5e7b\u89c9\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u63a8\u7406\u4efb\u52a1\u4e2d\u5b58\u5728\u5173\u952e\u7f3a\u9677\uff1a\u73b0\u6709\u7684\u5408\u6210\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u63a8\u7406\u6b65\u9aa4\u901a\u5e38\u662f\u6559\u5e08\u6a21\u578b\u751f\u6210\u7684\u770b\u4f3c\u5408\u7406\u4f46\u672a\u7ecf\u9a8c\u8bc1\u7684\u89e3\u91ca\uff0c\u800c\u975e\u4ee3\u7801\u5b9e\u9645\u6267\u884c\u8fc7\u7a0b\u7684\u771f\u5b9e\u63cf\u8ff0\uff0c\u8fd9\u5bfc\u81f4\u6a21\u578b\u5b66\u4e60\u5230\u8868\u9762\u4e0a\u5408\u7406\u4f46\u903b\u8f91\u6709\u7f3a\u9677\u7684\u63a8\u7406\u6a21\u5f0f\u3002", "method": "\u901a\u8fc7\u4ee3\u7801\u63d2\u6869\u6280\u672f\u6355\u83b7\u7a0b\u5e8f\u7684\u52a8\u6001\u6267\u884c\u8f68\u8ff9\uff0c\u7136\u540e\u5c06\u8fd9\u4e9b\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u6267\u884c\u8f68\u8ff9\u8f6c\u5316\u4e3a\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u6b65\u9aa4\uff0c\u6784\u5efa\u57fa\u4e8e\u6267\u884c\u8f68\u8ff9\u7684\u53cc\u5411\u63a8\u7406\u6570\u636e\u3002\u8fd9\u79cd\u65b9\u6cd5\u786e\u4fdd\u6bcf\u4e2a\u63a8\u7406\u6b65\u9aa4\u90fd\u53cd\u6620\u7a0b\u5e8f\u5b9e\u9645\u8ba1\u7b97\u8fc7\u7a0b\uff0c\u4ece\u6e90\u5934\u4e0a\u6d88\u9664\u903b\u8f91\u5e7b\u89c9\u3002", "result": "\u5728\u4ee3\u7801\u63a8\u7406\u4efb\u52a1\uff08CruxEval\u548cLiveCodeBench-Exec\u7684\u524d\u5411\u63a8\u7406\uff0cCruxEval-Input\u7684\u540e\u5411\u63a8\u7406\uff09\u4ee5\u53caHumanEval\u7684\u4ee3\u7801\u751f\u6210\u548c\u89e3\u91ca\u4efb\u52a1\u4e0a\uff0c\u4f7f\u7528\u8be5\u65b9\u6cd5\u8bad\u7ec3\u7684\u6a21\u578b\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\uff1a\u8f93\u51fa\u9884\u6d4b\u63d0\u5347\u9ad8\u8fbe30\u5206\uff0c\u8f93\u5165\u9884\u6d4b\u63d0\u534728\u5206\uff0c\u540c\u65f6\u4ee3\u7801\u751f\u6210\u548c\u89e3\u91ca\u80fd\u529b\u4e5f\u5f97\u5230\u6539\u5584\u3002", "conclusion": "\u57fa\u4e8e\u53ef\u9a8c\u8bc1\u6267\u884c\u8f68\u8ff9\u7684\u63a8\u7406\u65b9\u6cd5\u80fd\u591f\u4ece\u6839\u672c\u4e0a\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u76f8\u5173\u4efb\u52a1\u4e0a\u7684\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u53ef\u9a8c\u8bc1\u63a8\u7406\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u91cd\u8981\u589e\u5f3a\u4f5c\u7528\u3002"}}
{"id": "2512.00215", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.00215", "abs": "https://arxiv.org/abs/2512.00215", "authors": ["Mohammad Abdollahi", "Khandaker Rifah Tasnia", "Soumit Kanti Saha", "Jinqiu Yang", "Song Wang", "Hadi Hemmati"], "title": "Demystifying Errors in LLM Reasoning Traces: An Empirical Study of Code Execution Simulation", "comment": null, "summary": "Understanding a program's runtime reasoning behavior, meaning how intermediate states and control flows lead to final execution results, is essential for reliable code generation, debugging, and automated reasoning. Although large language models (LLMs) can accurately predict program outputs, most prior work has focused on output accuracy and performance, treating reasoning as a black box. As a result, little is known about the structure or failure modes of their reasoning traces. To address this gap, we conduct the first empirical study on runtime behavior inference with reasoning LLMs, aiming to uncover and characterize errors in their reasoning traces. We curate a benchmark from HumanEval Plus and LiveCodeBench, containing 427 code snippets. For each snippet, we test three input types: regular, edge, and invalid. Twelve input values are selected per snippet, each paired with its ground-truth execution result. We evaluate four state-of-the-art reasoning LLMs. Our results show that these models reach accuracies between 85 percent and 98 percent across input types. We also analyze the produced reasoning traces and develop a taxonomy with nine categories of inference errors. Finally, we explore tool-augmented reasoning. Using failures in the Computation Errors category as a case study, our experiments show that this approach corrects 58 percent of such errors, demonstrating the potential of tool support for improving LLM reasoning.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u5bf9\u63a8\u7406\u578b\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8fd0\u884c\u65f6\u884c\u4e3a\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\uff0c\u901a\u8fc7\u6784\u5efa\u5305\u542b427\u4e2a\u4ee3\u7801\u7247\u6bb5\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u4e864\u4e2a\u5148\u8fdb\u63a8\u7406LLM\u5728\u5e38\u89c4\u3001\u8fb9\u754c\u548c\u65e0\u6548\u8f93\u5165\u4e0b\u7684\u8868\u73b0\uff0c\u63ed\u793a\u4e86\u63a8\u7406\u8f68\u8ff9\u4e2d\u7684\u9519\u8bef\u7c7b\u578b\uff0c\u5e76\u63a2\u7d22\u4e86\u5de5\u5177\u589e\u5f3a\u63a8\u7406\u7684\u6539\u8fdb\u6f5c\u529b\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u51c6\u786e\u9884\u6d4b\u7a0b\u5e8f\u8f93\u51fa\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u8f93\u51fa\u51c6\u786e\u6027\uff0c\u5c06\u63a8\u7406\u8fc7\u7a0b\u89c6\u4e3a\u9ed1\u7bb1\u3002\u5bf9LLM\u63a8\u7406\u8f68\u8ff9\u7684\u7ed3\u6784\u548c\u5931\u8d25\u6a21\u5f0f\u4e86\u89e3\u751a\u5c11\uff0c\u8fd9\u9650\u5236\u4e86\u4ee3\u7801\u751f\u6210\u3001\u8c03\u8bd5\u548c\u81ea\u52a8\u63a8\u7406\u7684\u53ef\u9760\u6027\u3002", "method": "\u4eceHumanEval Plus\u548cLiveCodeBench\u4e2d\u7b5b\u9009427\u4e2a\u4ee3\u7801\u7247\u6bb5\uff0c\u4e3a\u6bcf\u4e2a\u7247\u6bb5\u6d4b\u8bd5\u4e09\u79cd\u8f93\u5165\u7c7b\u578b\uff08\u5e38\u89c4\u3001\u8fb9\u754c\u3001\u65e0\u6548\uff09\uff0c\u6bcf\u4e2a\u7247\u6bb5\u9009\u62e912\u4e2a\u8f93\u5165\u503c\u5e76\u914d\u5bf9\u5176\u771f\u5b9e\u6267\u884c\u7ed3\u679c\u3002\u8bc4\u4f304\u4e2a\u6700\u5148\u8fdb\u7684\u63a8\u7406LLM\uff0c\u5206\u6790\u751f\u6210\u7684\u63a8\u7406\u8f68\u8ff9\uff0c\u5efa\u7acb\u5305\u542b9\u4e2a\u7c7b\u522b\u7684\u63a8\u7406\u9519\u8bef\u5206\u7c7b\u6cd5\uff0c\u5e76\u63a2\u7d22\u5de5\u5177\u589e\u5f3a\u63a8\u7406\u65b9\u6cd5\u3002", "result": "\u6a21\u578b\u5728\u4e0d\u540c\u8f93\u5165\u7c7b\u578b\u4e0b\u7684\u51c6\u786e\u7387\u572885%\u523098%\u4e4b\u95f4\u3002\u7814\u7a76\u8bc6\u522b\u51fa9\u7c7b\u63a8\u7406\u9519\u8bef\uff0c\u5176\u4e2d\u8ba1\u7b97\u9519\u8bef\u7c7b\u522b\u7684\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u5de5\u5177\u589e\u5f3a\u63a8\u7406\u65b9\u6cd5\u80fd\u4fee\u6b6358%\u7684\u6b64\u7c7b\u9519\u8bef\uff0c\u663e\u793a\u4e86\u5de5\u5177\u652f\u6301\u5bf9\u6539\u8fdbLLM\u63a8\u7406\u7684\u6f5c\u529b\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5bf9\u63a8\u7406\u578bLLM\u8fd0\u884c\u65f6\u884c\u4e3a\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\u7684\u7814\u7a76\uff0c\u63ed\u793a\u4e86\u63a8\u7406\u8f68\u8ff9\u4e2d\u7684\u9519\u8bef\u6a21\u5f0f\uff0c\u5e76\u8bc1\u660e\u4e86\u5de5\u5177\u589e\u5f3a\u63a8\u7406\u80fd\u6709\u6548\u4fee\u6b63\u7279\u5b9a\u7c7b\u578b\u7684\u63a8\u7406\u9519\u8bef\uff0c\u4e3a\u63d0\u5347LLM\u5728\u4ee3\u7801\u76f8\u5173\u4efb\u52a1\u4e2d\u7684\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2512.00094", "categories": ["cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.00094", "abs": "https://arxiv.org/abs/2512.00094", "authors": ["Kexin Li", "Guozhen Ding", "Ilya Grishchenko", "David Lie"], "title": "HMARK: Radioactive Multi-Bit Semantic-Latent Watermarking for Diffusion Models", "comment": null, "summary": "Modern generative diffusion models rely on vast training datasets, often including images with uncertain ownership or usage rights. Radioactive watermarks -- marks that transfer to a model's outputs -- can help detect when such unauthorized data has been used for training. Moreover, aside from being radioactive, an effective watermark for protecting images from unauthorized training also needs to meet other existing requirements, such as imperceptibility, robustness, and multi-bit capacity. To overcome these challenges, we propose HMARK, a novel multi-bit watermarking scheme, which encodes ownership information as secret bits in the semantic-latent space (h-space) for image diffusion models. By leveraging the interpretability and semantic significance of h-space, ensuring that watermark signals correspond to meaningful semantic attributes, the watermarks embedded by HMARK exhibit radioactivity, robustness to distortions, and minimal impact on perceptual quality. Experimental results demonstrate that HMARK achieves 98.57% watermark detection accuracy, 95.07% bit-level recovery accuracy, 100% recall rate, and 1.0 AUC on images produced by the downstream adversarial model finetuned with LoRA on watermarked data across various types of distortions.", "AI": {"tldr": "HMARK\u662f\u4e00\u79cd\u7528\u4e8e\u56fe\u50cf\u6269\u6563\u6a21\u578b\u7684\u591a\u4f4d\u6c34\u5370\u65b9\u6848\uff0c\u901a\u8fc7\u5728\u8bed\u4e49\u6f5c\u5728\u7a7a\u95f4\uff08h-space\uff09\u5d4c\u5165\u6240\u6709\u6743\u4fe1\u606f\uff0c\u5b9e\u73b0\u4e86\u653e\u5c04\u6027\u3001\u9c81\u68d2\u6027\u548c\u4e0d\u53ef\u611f\u77e5\u6027\uff0c\u80fd\u6709\u6548\u68c0\u6d4b\u672a\u7ecf\u6388\u6743\u7684\u8bad\u7ec3\u6570\u636e\u4f7f\u7528\u3002", "motivation": "\u73b0\u4ee3\u751f\u6210\u6269\u6563\u6a21\u578b\u4f9d\u8d56\u5927\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u5176\u4e2d\u53ef\u80fd\u5305\u542b\u6240\u6709\u6743\u4e0d\u660e\u786e\u6216\u4f7f\u7528\u6743\u9650\u4e0d\u786e\u5b9a\u7684\u56fe\u50cf\u3002\u653e\u5c04\u6027\u6c34\u5370\u53ef\u4ee5\u5e2e\u52a9\u68c0\u6d4b\u672a\u7ecf\u6388\u6743\u7684\u6570\u636e\u662f\u5426\u88ab\u7528\u4e8e\u8bad\u7ec3\uff0c\u4f46\u73b0\u6709\u6c34\u5370\u65b9\u6848\u9700\u8981\u540c\u65f6\u6ee1\u8db3\u4e0d\u53ef\u611f\u77e5\u6027\u3001\u9c81\u68d2\u6027\u548c\u591a\u4f4d\u5bb9\u91cf\u7b49\u591a\u91cd\u9700\u6c42\u3002", "method": "HMARK\u901a\u8fc7\u5728\u56fe\u50cf\u6269\u6563\u6a21\u578b\u7684\u8bed\u4e49\u6f5c\u5728\u7a7a\u95f4\uff08h-space\uff09\u4e2d\u7f16\u7801\u79d8\u5bc6\u6bd4\u7279\u4f5c\u4e3a\u6240\u6709\u6743\u4fe1\u606f\u3002\u5229\u7528h-space\u7684\u53ef\u89e3\u91ca\u6027\u548c\u8bed\u4e49\u91cd\u8981\u6027\uff0c\u786e\u4fdd\u6c34\u5370\u4fe1\u53f7\u5bf9\u5e94\u6709\u610f\u4e49\u7684\u8bed\u4e49\u5c5e\u6027\uff0c\u4ece\u800c\u5b9e\u73b0\u653e\u5c04\u6027\u3001\u9c81\u68d2\u6027\u548c\u5bf9\u611f\u77e5\u8d28\u91cf\u7684\u6700\u5c0f\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cHMARK\u5728\u7ecfLoRA\u5fae\u8c03\u7684\u4e0b\u6e38\u5bf9\u6297\u6a21\u578b\u751f\u6210\u7684\u6c34\u5370\u56fe\u50cf\u4e0a\uff0c\u5728\u5404\u79cd\u5931\u771f\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e8698.57%\u7684\u6c34\u5370\u68c0\u6d4b\u51c6\u786e\u7387\u300195.07%\u7684\u6bd4\u7279\u7ea7\u6062\u590d\u51c6\u786e\u7387\u3001100%\u7684\u53ec\u56de\u7387\u548c1.0\u7684AUC\u503c\u3002", "conclusion": "HMARK\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u591a\u6bd4\u7279\u6c34\u5370\u65b9\u6848\uff0c\u901a\u8fc7\u5728\u6269\u6563\u6a21\u578b\u7684\u8bed\u4e49\u6f5c\u5728\u7a7a\u95f4\u5d4c\u5165\u6c34\u5370\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u653e\u5c04\u6027\u3001\u9c81\u68d2\u6027\u548c\u4e0d\u53ef\u611f\u77e5\u6027\u7684\u5e73\u8861\uff0c\u4e3a\u4fdd\u62a4\u56fe\u50cf\u514d\u53d7\u672a\u7ecf\u6388\u6743\u7684\u8bad\u7ec3\u4f7f\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.00231", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00231", "abs": "https://arxiv.org/abs/2512.00231", "authors": ["Monique Louise Monteiro", "George G. Cabral", "Adriano L. I. OLiveira"], "title": "CodeFlowLM: Incremental Just-In-Time Defect Prediction with Pretrained Language Models and Exploratory Insights into Defect Localization", "comment": null, "summary": "This work introduces CodeFlowLM, an incremental learning framework for Just-In-Time Software Defect Prediction (JIT-SDP) that leverages pre-trained language models (PLMs). Unlike traditional online learners, CodeFlowLM employs continual fine-tuning to address concept drift, class imbalance, and verification latency without retraining from scratch. We evaluated encoder-only and encoder-decoder PLMs (notably CodeT5+ and UniXCoder) in JIT-SDP scenarios within and between projects, comparing them with the incremental baseline BORB. The results show that CodeFlowLM achieves up to 68% G-Mean gains, confirming its superior adaptability and robustness in evolving software environments. We further extend the analysis to Just-in-Time Defect Localization (JIT-DL), benchmarking Large Language Models (LLMs) such as GPT-5, Claude Sonnet 4.5, and Gemini 2.5 Pro against attention-based models. GPT-5 delivers comparable performance for Recall@20% and Effort@20% with higher stability, although attention-based methods retain an advantage in fine-grained ranking metrics (Top-k, IFA). A qualitative error analysis reveals that most false positives arise from (1) human-like conservative bias, (2) insufficient contextual information in diff-based prompts, and (3) potential dataset mislabeling in JIT-Defects4J. These findings highlight both the promise and the current limitations of LLM reasoning in defect localization. False negatives occur in smaller proportions. Overall, CodeFlowLM significantly advances the state of the art in incremental JIT-SDP, demonstrating superior adaptability and robustness in evolving software environments. Furthermore, our exploratory analysis of LLMs in JIT-DL not only benchmarks their performance against established attention-based models but also provides critical insights into the current limitations of prompt-based defect reasoning.", "AI": {"tldr": "CodeFlowLM\u662f\u4e00\u4e2a\u7528\u4e8e\u5373\u65f6\u8f6f\u4ef6\u7f3a\u9677\u9884\u6d4b\u7684\u589e\u91cf\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u89e3\u51b3\u6982\u5ff5\u6f02\u79fb\u3001\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u9a8c\u8bc1\u5ef6\u8fdf\u95ee\u9898\uff0c\u5728\u8de8\u9879\u76ee\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u540c\u65f6\u63a2\u7d22\u4e86LLM\u5728\u7f3a\u9677\u5b9a\u4f4d\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u4f20\u7edf\u5728\u7ebf\u5b66\u4e60\u5668\u5728\u5373\u65f6\u8f6f\u4ef6\u7f3a\u9677\u9884\u6d4b\u4e2d\u9762\u4e34\u6982\u5ff5\u6f02\u79fb\u3001\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u9a8c\u8bc1\u5ef6\u8fdf\u7b49\u6311\u6218\uff0c\u9700\u8981\u66f4\u9002\u5e94\u8f6f\u4ef6\u73af\u5883\u6f14\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faCodeFlowLM\u589e\u91cf\u5b66\u4e60\u6846\u67b6\uff0c\u91c7\u7528\u6301\u7eed\u5fae\u8c03\u7b56\u7565\u800c\u975e\u4ece\u5934\u8bad\u7ec3\uff0c\u8bc4\u4f30\u4e86CodeT5+\u548cUniXCoder\u7b49\u7f16\u7801\u5668-\u89e3\u7801\u5668PLM\uff0c\u5e76\u4e0eBORB\u57fa\u7ebf\u6bd4\u8f83\uff0c\u540c\u65f6\u5c06\u5206\u6790\u6269\u5c55\u5230LLM\u5728\u7f3a\u9677\u5b9a\u4f4d\u4e2d\u7684\u5e94\u7528\u3002", "result": "CodeFlowLM\u5728\u5373\u65f6\u7f3a\u9677\u9884\u6d4b\u4e2d\u5b9e\u73b0\u9ad8\u8fbe68%\u7684G-Mean\u589e\u76ca\uff0c\u5728\u8de8\u9879\u76ee\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\uff1b\u5728\u7f3a\u9677\u5b9a\u4f4d\u4e2d\uff0cGPT-5\u5728Recall@20%\u548cEffort@20%\u6307\u6807\u4e0a\u4e0e\u6ce8\u610f\u529b\u6a21\u578b\u76f8\u5f53\u4e14\u66f4\u7a33\u5b9a\uff0c\u4f46\u6ce8\u610f\u529b\u6a21\u578b\u5728\u7ec6\u7c92\u5ea6\u6392\u540d\u6307\u6807\u4e0a\u4ecd\u6709\u4f18\u52bf\u3002", "conclusion": "CodeFlowLM\u663e\u8457\u63d0\u5347\u4e86\u589e\u91cf\u5373\u65f6\u7f3a\u9677\u9884\u6d4b\u7684\u6280\u672f\u6c34\u5e73\uff0c\u5c55\u793a\u4e86\u5728\u6f14\u5316\u8f6f\u4ef6\u73af\u5883\u4e2d\u7684\u4f18\u8d8a\u9002\u5e94\u6027\u548c\u9c81\u68d2\u6027\uff1bLLM\u5728\u7f3a\u9677\u5b9a\u4f4d\u4e2d\u867d\u6709\u6f5c\u529b\uff0c\u4f46\u5b58\u5728\u4fdd\u5b88\u504f\u5dee\u3001\u4e0a\u4e0b\u6587\u4fe1\u606f\u4e0d\u8db3\u548c\u6570\u636e\u6807\u6ce8\u95ee\u9898\u7b49\u9650\u5236\u3002"}}
{"id": "2512.00185", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.00185", "abs": "https://arxiv.org/abs/2512.00185", "authors": ["Shashanka B R", "Mohith Charan R", "Seema Banu F"], "title": "Chunking Strategies for Multimodal AI Systems", "comment": "45 pages, 5 figure", "summary": "Our goal is to consolidate the landscape of multimodal chunking strategies, providing researchers and practitioners with a technical foundation and design space for developing more effective and efficient multimodal AI systems. This survey paves the way for innovations in robust chunking pipelines that scale with modality complexity, enhance processing accuracy, and improve generative coherence in real-world applications. This survey provides a comprehensive taxonomy and technical analysis of chunking strategies tailored for each modality: text, images, audio, video, and cross-modal data. We examine classical and modern approaches such as fixed-size token windowing, recursive text splitting, object-centric visual chunking, silence-based audio segmentation, and scene detection in videos. Each approach is analyzed in terms of its underlying methodology, supporting tools (e.g., LangChain, Detectron2, PySceneDetect), benefits, and challenges, particularly those related to granularity-context trade-offs and multimodal alignment. Furthermore, we explore emerging cross-modal chunking strategies that aim to preserve alignment and semantic consistency across disparate data types [4]. We also include comparative insights, highlight open problems such as asynchronous information density and noisy alignment signals, and identify opportunities for future research in adaptive, learning-based, and task-specific chunking.", "AI": {"tldr": "\u672c\u6587\u662f\u4e00\u7bc7\u5173\u4e8e\u591a\u6a21\u6001\u5206\u5757\u7b56\u7565\u7684\u7efc\u8ff0\u6027\u8bba\u6587\uff0c\u7cfb\u7edf\u68b3\u7406\u4e86\u6587\u672c\u3001\u56fe\u50cf\u3001\u97f3\u9891\u3001\u89c6\u9891\u548c\u8de8\u6a21\u6001\u6570\u636e\u7684\u5206\u5757\u65b9\u6cd5\uff0c\u5206\u6790\u4e86\u5404\u79cd\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u6574\u5408\u591a\u6a21\u6001\u5206\u5757\u7b56\u7565\u7684\u7814\u7a76\u73b0\u72b6\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u6280\u672f\u57fa\u7840\u548c\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u4ee5\u5f00\u53d1\u66f4\u6709\u6548\u548c\u9ad8\u6548\u7684\u591a\u6a21\u6001AI\u7cfb\u7edf\u3002\u5f53\u524d\u591a\u6a21\u6001\u6570\u636e\u5904\u7406\u9762\u4e34\u6a21\u6001\u590d\u6742\u6027\u3001\u5904\u7406\u51c6\u786e\u6027\u548c\u751f\u6210\u4e00\u81f4\u6027\u7b49\u6311\u6218\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u5206\u5757\u7b56\u7565\u6307\u5bfc\u3002", "method": "\u91c7\u7528\u7efc\u8ff0\u7814\u7a76\u65b9\u6cd5\uff0c\u9996\u5148\u5efa\u7acb\u5168\u9762\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u7136\u540e\u9488\u5bf9\u6bcf\u79cd\u6a21\u6001\uff08\u6587\u672c\u3001\u56fe\u50cf\u3001\u97f3\u9891\u3001\u89c6\u9891\u3001\u8de8\u6a21\u6001\u6570\u636e\uff09\u5206\u6790\u7ecf\u5178\u548c\u73b0\u4ee3\u7684\u5206\u5757\u65b9\u6cd5\u3002\u5177\u4f53\u5305\u62ec\u56fa\u5b9a\u5927\u5c0f\u4ee4\u724c\u7a97\u53e3\u3001\u9012\u5f52\u6587\u672c\u5206\u5272\u3001\u5bf9\u8c61\u4e2d\u5fc3\u89c6\u89c9\u5206\u5757\u3001\u57fa\u4e8e\u9759\u97f3\u7684\u97f3\u9891\u5206\u5272\u3001\u89c6\u9891\u573a\u666f\u68c0\u6d4b\u7b49\u65b9\u6cd5\u3002\u6bcf\u79cd\u65b9\u6cd5\u90fd\u4ece\u5e95\u5c42\u65b9\u6cd5\u8bba\u3001\u652f\u6301\u5de5\u5177\u3001\u4f18\u52bf\u548c\u6311\u6218\u7b49\u65b9\u9762\u8fdb\u884c\u5206\u6790\u3002", "result": "\u63d0\u4f9b\u4e86\u591a\u6a21\u6001\u5206\u5757\u7b56\u7565\u7684\u5168\u9762\u6280\u672f\u5206\u6790\uff0c\u5305\u62ec\uff1a1\uff09\u5efa\u7acb\u4e86\u9488\u5bf9\u4e0d\u540c\u6a21\u6001\u7684\u5206\u5757\u7b56\u7565\u5206\u7c7b\u4f53\u7cfb\uff1b2\uff09\u5206\u6790\u4e86\u5404\u79cd\u65b9\u6cd5\u7684\u7c92\u5ea6-\u4e0a\u4e0b\u6587\u6743\u8861\u548c\u591a\u6a21\u6001\u5bf9\u9f50\u7b49\u5173\u952e\u6311\u6218\uff1b3\uff09\u63a2\u7d22\u4e86\u65b0\u5174\u7684\u8de8\u6a21\u6001\u5206\u5757\u7b56\u7565\uff1b4\uff09\u63d0\u4f9b\u4e86\u6bd4\u8f83\u6027\u89c1\u89e3\uff0c\u7a81\u51fa\u4e86\u5f00\u653e\u6027\u95ee\u9898\u5982\u5f02\u6b65\u4fe1\u606f\u5bc6\u5ea6\u548c\u566a\u58f0\u5bf9\u9f50\u4fe1\u53f7\u3002", "conclusion": "\u672c\u6587\u4e3a\u5f00\u53d1\u66f4\u6709\u6548\u7684\u591a\u6a21\u6001AI\u7cfb\u7edf\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u5305\u62ec\u81ea\u9002\u5e94\u5206\u5757\u3001\u57fa\u4e8e\u5b66\u4e60\u7684\u5206\u5757\u548c\u4efb\u52a1\u7279\u5b9a\u5206\u5757\u7b49\u3002\u8be5\u7efc\u8ff0\u6709\u52a9\u4e8e\u63a8\u52a8\u521b\u65b0\uff0c\u4f7f\u5206\u5757\u7ba1\u9053\u80fd\u591f\u968f\u6a21\u6001\u590d\u6742\u6027\u6269\u5c55\uff0c\u63d0\u9ad8\u5904\u7406\u51c6\u786e\u6027\uff0c\u5e76\u6539\u5584\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u751f\u6210\u4e00\u81f4\u6027\u3002"}}
{"id": "2512.00193", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00193", "abs": "https://arxiv.org/abs/2512.00193", "authors": ["Anson Ho", "Jean-Stanislas Denain", "David Atanasov", "Samuel Albanie", "Rohin Shah"], "title": "A Rosetta Stone for AI Benchmarks", "comment": null, "summary": "Most AI benchmarks saturate within years or even months after they are introduced, making it hard to study long-run trends in AI capabilities. To address this challenge, we build a statistical framework that stitches benchmarks together, putting model capabilities and benchmark difficulties on a single numerical scale. This acts as a \"Rosetta Stone\", allowing us to compare models across a wide range of abilities and time, even if they are not evaluated on the same benchmarks. Moreover, this works without assuming how capabilities evolve across time or with training compute. We demonstrate three applications of this framework. First, we use it to measure the speed of AI progress over time, and to forecast future AI capabilities. Second, we estimate the rate of improvements in algorithmic efficiency, finding estimates that are higher, but broadly consistent with prior work. Finally, we find that our approach can be used to detect rapid accelerations in AI progress.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u8ba1\u6846\u67b6\u5c06\u4e0d\u540cAI\u57fa\u51c6\u6d4b\u8bd5\"\u7f1d\u5408\"\u5728\u4e00\u8d77\uff0c\u5728\u7edf\u4e00\u5c3a\u5ea6\u4e0a\u8861\u91cf\u6a21\u578b\u80fd\u529b\u548c\u57fa\u51c6\u96be\u5ea6\uff0c\u7528\u4e8e\u7814\u7a76AI\u957f\u671f\u8d8b\u52bf", "motivation": "\u5927\u591a\u6570AI\u57fa\u51c6\u6d4b\u8bd5\u5728\u63a8\u51fa\u540e\u51e0\u5e74\u751a\u81f3\u51e0\u4e2a\u6708\u5185\u5c31\u4f1a\u9971\u548c\uff0c\u96be\u4ee5\u7814\u7a76AI\u80fd\u529b\u7684\u957f\u671f\u8d8b\u52bf", "method": "\u6784\u5efa\u7edf\u8ba1\u6846\u67b6\uff0c\u5c06\u6a21\u578b\u80fd\u529b\u548c\u57fa\u51c6\u6d4b\u8bd5\u96be\u5ea6\u653e\u5728\u5355\u4e00\u6570\u503c\u5c3a\u5ea6\u4e0a\uff0c\u65e0\u9700\u5047\u8bbe\u80fd\u529b\u5982\u4f55\u968f\u65f6\u95f4\u6216\u8bad\u7ec3\u8ba1\u7b97\u91cf\u6f14\u53d8", "result": "\u6846\u67b6\u53ef\u7528\u4e8e\uff1a1)\u6d4b\u91cfAI\u8fdb\u5c55\u901f\u5ea6\u5e76\u9884\u6d4b\u672a\u6765\u80fd\u529b\uff1b2)\u4f30\u7b97\u7b97\u6cd5\u6548\u7387\u6539\u8fdb\u7387\uff1b3)\u68c0\u6d4bAI\u8fdb\u5c55\u7684\u5feb\u901f\u52a0\u901f", "conclusion": "\u8be5\u6846\u67b6\u4f5c\u4e3a\"\u7f57\u585e\u5854\u77f3\u7891\"\uff0c\u80fd\u591f\u8de8\u4e0d\u540c\u57fa\u51c6\u6d4b\u8bd5\u548c\u65f6\u95f4\u6bd4\u8f83\u6a21\u578b\uff0c\u4e3a\u7814\u7a76AI\u957f\u671f\u8d8b\u52bf\u63d0\u4f9b\u6709\u6548\u5de5\u5177"}}
{"id": "2512.00110", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2512.00110", "abs": "https://arxiv.org/abs/2512.00110", "authors": ["Leo Kao"], "title": "Quantum-Adversary-Resilient Evidence Structures and Migration Strategies for Regulated AI Audit Trails", "comment": "15 pages, 1 table. Technical report for regulated AI audit trails with quantum-adversary security definitions and migration patterns", "summary": "Constant-size cryptographic evidence records are increasingly used to build audit trails for regulated AI workloads in clinical, pharmaceutical, and financial settings, where each execution is summarized by a compact, verifiable record of code identity, model version, data digests, and platform measurements. Existing instantiations, however, typically rely on classical signature schemes whose long-term security is threatened by quantum-capable adversaries. In this paper we formalize security notions for evidence structures in the presence of quantum adversaries and study post-quantum (PQ) instantiations and migration strategies for deployed audit logs. We recall an abstraction of constant-size evidence structures and introduce game-based definitions of Q-Audit Integrity, Q-Non-Equivocation, and Q-Binding, capturing the inability of a quantum adversary to forge, equivocate, or rebind evidence items. We then analyze a hash-and-sign instantiation in the quantum random-oracle model (QROM), assuming an existentially unforgeable PQ signature scheme against quantum adversaries, and show that the resulting evidence structure satisfies these notions under standard assumptions. Building on this, we present three migration patterns for existing evidence logs: hybrid signatures, re-signing of legacy evidence, and Merkle-root anchoring, and analyze their security, storage, and computational trade-offs. A case study based on an industrial constant-size evidence platform for regulated AI at Codebat Technologies Inc. suggests that quantum-safe audit trails are achievable with moderate overhead and that systematic migration can significantly extend the evidentiary lifetime of existing deployments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u9762\u5411\u91cf\u5b50\u8ba1\u7b97\u5a01\u80c1\u7684\u6052\u5b9a\u5927\u5c0f\u52a0\u5bc6\u8bc1\u636e\u8bb0\u5f55\u7cfb\u7edf\uff0c\u63d0\u51fa\u4e86\u91cf\u5b50\u5b89\u5168\u7684\u5f62\u5f0f\u5316\u5b9a\u4e49\u548c\u8fc1\u79fb\u7b56\u7565\uff0c\u786e\u4fdd\u53d7\u76d1\u7ba1AI\u5de5\u4f5c\u8d1f\u8f7d\u5ba1\u8ba1\u65e5\u5fd7\u7684\u957f\u671f\u5b89\u5168\u6027\u3002", "motivation": "\u5f53\u524d\u7528\u4e8e\u4e34\u5e8a\u3001\u5236\u836f\u548c\u91d1\u878d\u7b49\u53d7\u76d1\u7ba1AI\u5de5\u4f5c\u8d1f\u8f7d\u7684\u6052\u5b9a\u5927\u5c0f\u52a0\u5bc6\u8bc1\u636e\u8bb0\u5f55\u7cfb\u7edf\u4e3b\u8981\u4f9d\u8d56\u7ecf\u5178\u7b7e\u540d\u65b9\u6848\uff0c\u8fd9\u4e9b\u65b9\u6848\u9762\u4e34\u91cf\u5b50\u8ba1\u7b97\u80fd\u529b\u7684\u5bf9\u624b\u7684\u957f\u671f\u5b89\u5168\u5a01\u80c1\uff0c\u9700\u8981\u7814\u7a76\u540e\u91cf\u5b50\u5b89\u5168\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "1. \u5f62\u5f0f\u5316\u91cf\u5b50\u5bf9\u624b\u4e0b\u7684\u8bc1\u636e\u7ed3\u6784\u5b89\u5168\u6982\u5ff5\uff08Q-Audit Integrity\u3001Q-Non-Equivocation\u3001Q-Binding\uff09\uff1b2. \u5728\u91cf\u5b50\u968f\u673a\u9884\u8a00\u673a\u6a21\u578b(QROM)\u4e2d\u5206\u6790\u54c8\u5e0c-\u7b7e\u540d\u5b9e\u4f8b\u5316\uff1b3. \u63d0\u51fa\u4e09\u79cd\u8fc1\u79fb\u6a21\u5f0f\uff1a\u6df7\u5408\u7b7e\u540d\u3001\u91cd\u65b0\u7b7e\u540d\u9057\u7559\u8bc1\u636e\u3001Merkle\u6839\u951a\u5b9a\uff1b4. \u57fa\u4e8e\u5de5\u4e1a\u6848\u4f8b\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\u3002", "result": "\u5728\u6807\u51c6\u5047\u8bbe\u4e0b\uff0c\u57fa\u4e8e\u5b58\u5728\u6027\u4e0d\u53ef\u4f2a\u9020\u7684\u540e\u91cf\u5b50\u7b7e\u540d\u65b9\u6848\u6784\u5efa\u7684\u8bc1\u636e\u7ed3\u6784\u80fd\u591f\u6ee1\u8db3\u91cf\u5b50\u5b89\u5168\u6982\u5ff5\uff1b\u4e09\u79cd\u8fc1\u79fb\u7b56\u7565\u5728\u5b89\u5168\u6027\u3001\u5b58\u50a8\u548c\u8ba1\u7b97\u5f00\u9500\u65b9\u9762\u5404\u6709\u6743\u8861\uff1b\u5de5\u4e1a\u6848\u4f8b\u7814\u7a76\u8868\u660e\u91cf\u5b50\u5b89\u5168\u5ba1\u8ba1\u8ddf\u8e2a\u53ef\u5b9e\u73b0\u9002\u5ea6\u5f00\u9500\uff0c\u7cfb\u7edf\u8fc1\u79fb\u80fd\u663e\u8457\u5ef6\u957f\u73b0\u6709\u90e8\u7f72\u7684\u8bc1\u636e\u5bff\u547d\u3002", "conclusion": "\u91cf\u5b50\u5b89\u5168\u7684\u5ba1\u8ba1\u8ddf\u8e2a\u662f\u53ef\u5b9e\u73b0\u7684\uff0c\u901a\u8fc7\u5f62\u5f0f\u5316\u5b89\u5168\u5b9a\u4e49\u3001\u540e\u91cf\u5b50\u7b7e\u540d\u65b9\u6848\u548c\u7cfb\u7edf\u8fc1\u79fb\u7b56\u7565\uff0c\u80fd\u591f\u4fdd\u62a4\u53d7\u76d1\u7ba1AI\u5de5\u4f5c\u8d1f\u8f7d\u7684\u52a0\u5bc6\u8bc1\u636e\u8bb0\u5f55\u514d\u53d7\u91cf\u5b50\u8ba1\u7b97\u5a01\u80c1\uff0c\u5ef6\u957f\u73b0\u6709\u7cfb\u7edf\u7684\u4f7f\u7528\u5bff\u547d\u3002"}}
{"id": "2512.00325", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.00325", "abs": "https://arxiv.org/abs/2512.00325", "authors": ["Shaira Sadia Karim", "Abrar Mahmud Rahim", "Lamia Alam", "Ishmam Tashdeed", "Lutfun Nahar Lota", "Md. Abu Raihan M. Kamal", "Md. Azam Hossain"], "title": "Progressive Code Integration for Abstractive Bug Report Summarization", "comment": null, "summary": "Bug reports are often unstructured and verbose, making it challenging for developers to efficiently comprehend software issues. Existing summarization approaches typically rely on surface-level textual cues, resulting in incomplete or redundant summaries, and they frequently ignore associated code snippets, which are essential for accurate defect diagnosis. To address these limitations, we propose a progressive code-integration framework for LLM-based abstractive bug report summarization. Our approach incrementally incorporates long code snippets alongside textual content, overcoming standard LLM context window constraints and producing semantically rich summaries. Evaluated on four benchmark datasets using eight LLMs, our pipeline outperforms extractive baselines by 7.5%-58.2% and achieves performance comparable to state-of-the-art abstractive methods, highlighting the benefits of jointly leveraging textual and code information for enhanced bug comprehension.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6e10\u8fdb\u5f0f\u4ee3\u7801\u96c6\u6210\u6846\u67b6\uff0c\u7528\u4e8e\u57fa\u4e8eLLM\u7684\u7f3a\u9677\u62a5\u544a\u6458\u8981\u751f\u6210\uff0c\u901a\u8fc7\u9010\u6b65\u6574\u5408\u957f\u4ee3\u7801\u7247\u6bb5\u548c\u6587\u672c\u5185\u5bb9\u6765\u514b\u670dLLM\u4e0a\u4e0b\u6587\u7a97\u53e3\u9650\u5236\uff0c\u751f\u6210\u8bed\u4e49\u4e30\u5bcc\u7684\u6458\u8981\u3002", "motivation": "\u7f3a\u9677\u62a5\u544a\u901a\u5e38\u662f\u975e\u7ed3\u6784\u5316\u548c\u5197\u957f\u7684\uff0c\u4f7f\u5f97\u5f00\u53d1\u4eba\u5458\u96be\u4ee5\u6709\u6548\u7406\u89e3\u8f6f\u4ef6\u95ee\u9898\u3002\u73b0\u6709\u6458\u8981\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u8868\u9762\u6587\u672c\u7ebf\u7d22\uff0c\u5bfc\u81f4\u6458\u8981\u4e0d\u5b8c\u6574\u6216\u5197\u4f59\uff0c\u4e14\u7ecf\u5e38\u5ffd\u7565\u76f8\u5173\u7684\u4ee3\u7801\u7247\u6bb5\uff0c\u800c\u8fd9\u4e9b\u4ee3\u7801\u7247\u6bb5\u5bf9\u4e8e\u51c6\u786e\u7f3a\u9677\u8bca\u65ad\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u6e10\u8fdb\u5f0f\u4ee3\u7801\u96c6\u6210\u6846\u67b6\uff0c\u9010\u6b65\u5c06\u957f\u4ee3\u7801\u7247\u6bb5\u4e0e\u6587\u672c\u5185\u5bb9\u7ed3\u5408\uff0c\u514b\u670d\u6807\u51c6LLM\u4e0a\u4e0b\u6587\u7a97\u53e3\u9650\u5236\u3002\u8be5\u65b9\u6cd5\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u4f7f\u7528\u516b\u4e2aLLM\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u76f8\u6bd4\u62bd\u53d6\u5f0f\u57fa\u7ebf\u65b9\u6cd5\u6027\u80fd\u63d0\u53477.5%-58.2%\uff0c\u4e14\u4e0e\u6700\u5148\u8fdb\u7684\u62bd\u8c61\u5f0f\u65b9\u6cd5\u6027\u80fd\u76f8\u5f53\uff0c\u7a81\u663e\u4e86\u8054\u5408\u5229\u7528\u6587\u672c\u548c\u4ee3\u7801\u4fe1\u606f\u5bf9\u589e\u5f3a\u7f3a\u9677\u7406\u89e3\u7684\u597d\u5904\u3002", "conclusion": "\u63d0\u51fa\u7684\u6e10\u8fdb\u5f0f\u4ee3\u7801\u96c6\u6210\u6846\u67b6\u901a\u8fc7\u8054\u5408\u5229\u7528\u6587\u672c\u548c\u4ee3\u7801\u4fe1\u606f\uff0c\u80fd\u591f\u751f\u6210\u8bed\u4e49\u4e30\u5bcc\u7684\u7f3a\u9677\u62a5\u544a\u6458\u8981\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4e3a\u7f3a\u9677\u7406\u89e3\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.00218", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.00218", "abs": "https://arxiv.org/abs/2512.00218", "authors": ["Matt MacDermott", "Qiyao Wei", "Rada Djoneva", "Francis Rhys Ward"], "title": "Reasoning Under Pressure: How do Training Incentives Influence Chain-of-Thought Monitorability?", "comment": null, "summary": "AI systems that output their reasoning in natural language offer an opportunity for safety -- we can \\emph{monitor} their chain of thought (CoT) for undesirable reasoning, such as the pursuit of harmful objectives. However, the extent to which CoT faithfully reflects the underlying reasoning process, and hence the extent to which it can be usefully monitored, may be influenced by certain aspects of training. We investigate how different \\emph{training incentives}, applied to a reasoning model, affect its monitorability. We introduce a novel methodology for measuring monitorability according to whether a monitor can predict a key latent variable using the model's reasoning. When controlling for accuracy, we do not find evidence for consistent effects from commonly used incentives (length penalties and KL regularisation), but we find that adversarial optimisation (penalising monitor accuracy) degrades monitor performance, while direct optimisation for monitorability does not reliably lead to improvements. Our code is available at https://github.com/QiyaoWei/reasoning-under-pressure.", "AI": {"tldr": "\u7814\u7a76\u4e0d\u540c\u8bad\u7ec3\u6fc0\u52b1\u5bf9AI\u63a8\u7406\u6a21\u578b\u53ef\u76d1\u63a7\u6027\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5bf9\u6297\u6027\u4f18\u5316\u4f1a\u964d\u4f4e\u76d1\u63a7\u6027\u80fd\uff0c\u800c\u76f4\u63a5\u4f18\u5316\u53ef\u76d1\u63a7\u6027\u5e76\u4e0d\u603b\u80fd\u5e26\u6765\u6539\u8fdb", "motivation": "AI\u7cfb\u7edf\u8f93\u51fa\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u8fc7\u7a0b\u4e3a\u5b89\u5168\u76d1\u63a7\u63d0\u4f9b\u4e86\u673a\u4f1a\uff0c\u4f46\u63a8\u7406\u8fc7\u7a0b\u662f\u5426\u771f\u5b9e\u53cd\u6620\u5e95\u5c42\u601d\u7ef4\u8fc7\u7a0b\u4ee5\u53ca\u53ef\u76d1\u63a7\u7a0b\u5ea6\u53ef\u80fd\u53d7\u8bad\u7ec3\u65b9\u5f0f\u5f71\u54cd\uff0c\u9700\u8981\u7814\u7a76\u4e0d\u540c\u8bad\u7ec3\u6fc0\u52b1\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u7684\u53ef\u76d1\u63a7\u6027", "method": "\u5f15\u5165\u65b0\u7684\u65b9\u6cd5\u8bba\u6765\u8861\u91cf\u53ef\u76d1\u63a7\u6027\uff1a\u6839\u636e\u76d1\u63a7\u5668\u80fd\u5426\u4f7f\u7528\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\u9884\u6d4b\u5173\u952e\u6f5c\u5728\u53d8\u91cf\uff1b\u5728\u63a7\u5236\u51c6\u786e\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u6d4b\u8bd5\u5e38\u89c1\u8bad\u7ec3\u6fc0\u52b1\uff08\u957f\u5ea6\u60e9\u7f5a\u3001KL\u6b63\u5219\u5316\uff09\u3001\u5bf9\u6297\u6027\u4f18\u5316\uff08\u60e9\u7f5a\u76d1\u63a7\u51c6\u786e\u6027\uff09\u548c\u76f4\u63a5\u4f18\u5316\u53ef\u76d1\u63a7\u6027\u7684\u6548\u679c", "result": "\u5e38\u89c1\u8bad\u7ec3\u6fc0\u52b1\uff08\u957f\u5ea6\u60e9\u7f5a\u548cKL\u6b63\u5219\u5316\uff09\u5bf9\u53ef\u76d1\u63a7\u6027\u6ca1\u6709\u4e00\u81f4\u5f71\u54cd\uff1b\u5bf9\u6297\u6027\u4f18\u5316\u4f1a\u964d\u4f4e\u76d1\u63a7\u6027\u80fd\uff1b\u76f4\u63a5\u4f18\u5316\u53ef\u76d1\u63a7\u6027\u5e76\u4e0d\u80fd\u53ef\u9760\u5730\u5e26\u6765\u6539\u8fdb", "conclusion": "\u8bad\u7ec3\u6fc0\u52b1\u786e\u5b9e\u4f1a\u5f71\u54cdAI\u63a8\u7406\u6a21\u578b\u7684\u53ef\u76d1\u63a7\u6027\uff0c\u7279\u522b\u662f\u5bf9\u6297\u6027\u4f18\u5316\u4f1a\u635f\u5bb3\u76d1\u63a7\u80fd\u529b\uff0c\u8fd9\u4e3a\u8bbe\u8ba1\u66f4\u5b89\u5168\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u542f\u793a"}}
{"id": "2512.00380", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.00380", "abs": "https://arxiv.org/abs/2512.00380", "authors": ["Mingwei Liu", "Zheng Pei", "Yanlin Wang", "Zihao Wang", "Zikang Li", "Enci Lin", "Xin Peng", "Zibin Zheng"], "title": "Framework-Aware Code Generation with API Knowledge Graph-Constructed Data: A Study on HarmonyOS", "comment": null, "summary": "In the context of software frameworks with limited resources (such as HarmonyOS), large language models (LLMs) often exhibit poor code generation performance because they lack sufficient exposure to such environments during pre-training. Although LLMs can usually maintain correct logical structures across programming languages, they frequently struggle when dealing with framework-specific APIs or syntax, resulting in errors. This indicates that while pre-training equips LLMs with general algorithmic capabilities, they remain unfamiliar with the distinctive syntax and API usage of underrepresented frameworks. As a result, even advanced commercial models like GPT-4o cannot reliably generate correct code without prior adaptation. To address this issue, we propose APIKG4SYN, a framework designed to exploit API knowledge graphs for the construction of API-oriented question-code pairs, specifically tailored for low-resource frameworks without requiring executable code. APIKG4SYN integrates both single-API and multi-API knowledge, where the latter is derived through uncertainty estimation (UE)-driven Monte Carlo Tree Search (MCTS), enabling the creation of a diverse and informative dataset for fine-tuning LLMs. Using HarmonyOS as a case study, we build the first benchmark for HarmonyOS code generation. Experimental results show that fine-tuning Qwen with APIKG4SYN raises pass@1 accuracy to 25.00%, compared with 17.59% for the baseline GPT model. These results confirm that API-oriented data significantly enhance LLM performance in low-resource software development scenarios.", "AI": {"tldr": "\u9488\u5bf9\u8d44\u6e90\u53d7\u9650\u6846\u67b6\uff08\u5982HarmonyOS\uff09\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u56e0\u7f3a\u4e4f\u76f8\u5173\u9884\u8bad\u7ec3\u6570\u636e\u800c\u4ee3\u7801\u751f\u6210\u6027\u80fd\u5dee\u3002\u4f5c\u8005\u63d0\u51faAPIKG4SYN\u6846\u67b6\uff0c\u5229\u7528API\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u9762\u5411API\u7684\u95ee\u7b54\u5bf9\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u9a71\u52a8\u7684\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u6574\u5408\u5355API\u548c\u591aAPI\u77e5\u8bc6\uff0c\u663e\u8457\u63d0\u5347LLM\u5728\u4f4e\u8d44\u6e90\u6846\u67b6\u4e0b\u7684\u4ee3\u7801\u751f\u6210\u80fd\u529b\u3002", "motivation": "\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8f6f\u4ef6\u6846\u67b6\uff08\u5982HarmonyOS\uff09\u4e2d\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u7531\u4e8e\u9884\u8bad\u7ec3\u9636\u6bb5\u7f3a\u4e4f\u5bf9\u8fd9\u4e9b\u73af\u5883\u7684\u5145\u5206\u63a5\u89e6\uff0c\u5bfc\u81f4\u4ee3\u7801\u751f\u6210\u6027\u80fd\u4e0d\u4f73\u3002\u867d\u7136LLM\u901a\u5e38\u80fd\u5728\u4e0d\u540c\u7f16\u7a0b\u8bed\u8a00\u4e2d\u4fdd\u6301\u6b63\u786e\u7684\u903b\u8f91\u7ed3\u6784\uff0c\u4f46\u5728\u5904\u7406\u6846\u67b6\u7279\u5b9a\u7684API\u6216\u8bed\u6cd5\u65f6\u7ecf\u5e38\u51fa\u9519\u3002\u8fd9\u8868\u660e\u9884\u8bad\u7ec3\u867d\u7136\u8d4b\u4e88\u4e86LLM\u901a\u7528\u7684\u7b97\u6cd5\u80fd\u529b\uff0c\u4f46\u5bf9\u5c11\u6570\u6846\u67b6\u7279\u6709\u7684\u8bed\u6cd5\u548cAPI\u4f7f\u7528\u4ecd\u4e0d\u719f\u6089\uff0c\u5373\u4f7f\u662fGPT-4o\u8fd9\u6837\u7684\u5148\u8fdb\u5546\u4e1a\u6a21\u578b\u4e5f\u65e0\u6cd5\u53ef\u9760\u751f\u6210\u6b63\u786e\u4ee3\u7801\u3002", "method": "\u63d0\u51faAPIKG4SYN\u6846\u67b6\uff0c\u5229\u7528API\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u9762\u5411API\u7684\u95ee\u7b54\u5bf9\u6570\u636e\u96c6\uff0c\u4e13\u95e8\u9488\u5bf9\u4f4e\u8d44\u6e90\u6846\u67b6\u4e14\u65e0\u9700\u53ef\u6267\u884c\u4ee3\u7801\u3002\u8be5\u6846\u67b6\u6574\u5408\u5355API\u548c\u591aAPI\u77e5\u8bc6\uff0c\u5176\u4e2d\u591aAPI\u77e5\u8bc6\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u9a71\u52a8\u7684\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u83b7\u5f97\uff0c\u4ece\u800c\u521b\u5efa\u591a\u6837\u4e14\u4fe1\u606f\u4e30\u5bcc\u7684\u6570\u636e\u96c6\u7528\u4e8e\u5fae\u8c03LLM\u3002\u4ee5HarmonyOS\u4e3a\u6848\u4f8b\u7814\u7a76\uff0c\u6784\u5efa\u4e86\u9996\u4e2aHarmonyOS\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4f7f\u7528APIKG4SYN\u5fae\u8c03\u7684Qwen\u6a21\u578b\u5c06pass@1\u51c6\u786e\u7387\u63d0\u5347\u81f325.00%\uff0c\u800c\u57fa\u7ebfGPT\u6a21\u578b\u4ec5\u4e3a17.59%\u3002\u8fd9\u8bc1\u5b9e\u4e86\u9762\u5411API\u7684\u6570\u636e\u80fd\u663e\u8457\u63d0\u5347LLM\u5728\u4f4e\u8d44\u6e90\u8f6f\u4ef6\u5f00\u53d1\u573a\u666f\u4e2d\u7684\u6027\u80fd\u3002", "conclusion": "APIKG4SYN\u6846\u67b6\u901a\u8fc7\u5229\u7528API\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u4e13\u95e8\u7684\u6570\u636e\u96c6\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u5728\u4f4e\u8d44\u6e90\u8f6f\u4ef6\u6846\u67b6\u4e2d\u4ee3\u7801\u751f\u6210\u6027\u80fd\u5dee\u7684\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u8fd8\u4e3aHarmonyOS\u7b49\u4f4e\u8d44\u6e90\u6846\u67b6\u63d0\u4f9b\u4e86\u9996\u4e2a\u4ee3\u7801\u751f\u6210\u57fa\u51c6\uff0c\u8bc1\u660e\u4e86\u9762\u5411API\u7684\u6570\u636e\u5728\u589e\u5f3aLLM\u5bf9\u7279\u5b9a\u6846\u67b6\u9002\u5e94\u80fd\u529b\u65b9\u9762\u7684\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2512.00556", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.00556", "abs": "https://arxiv.org/abs/2512.00556", "authors": ["Sina Salimian", "Gias Uddin", "Sumon Biswas", "Henry Leung"], "title": "Bias Testing and Mitigation in Black Box LLMs using Metamorphic Relations", "comment": null, "summary": "The widespread deployment of Large Language Models (LLMs) has intensified concerns about subtle social biases embedded in their outputs. Existing guardrails often fail when faced with indirect or contextually complex bias-inducing prompts. To address these limitations, we propose a unified framework for both systematic bias evaluation and targeted mitigation. Our approach introduces six novel Metamorphic Relations (MRs) that, based on metamorphic testing principles, transform direct bias-inducing inputs into semantically equivalent yet adversarially challenging variants. These transformations enable an automated method for exposing hidden model biases: when an LLM responds inconsistently or unfairly across MR-generated variants, the underlying bias becomes detectable. We further show that the same MRs can be used to generate diverse bias-inducing samples for fine-tuning, directly linking the testing process to mitigation. Using six state-of-the-art LLMs - spanning open-source and proprietary models - and a representative subset of 385 questions from the 8,978-item BiasAsker benchmark covering seven protected groups, our MRs reveal up to 14% more hidden biases compared to existing tools. Moreover, fine-tuning with both original and MR-mutated samples significantly enhances bias resiliency, increasing safe response rates from 54.7% to over 88.9% across models. These results highlight metamorphic relations as a practical mechanism for improving fairness in conversational AI.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u57fa\u4e8e\u8715\u53d8\u6d4b\u8bd5\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u516d\u79cd\u65b0\u9896\u7684\u8715\u53d8\u5173\u7cfb\u5c06\u76f4\u63a5\u504f\u89c1\u8bf1\u5bfc\u8f93\u5165\u8f6c\u6362\u4e3a\u8bed\u4e49\u7b49\u6548\u4f46\u5bf9\u6297\u6027\u66f4\u5f3a\u7684\u53d8\u4f53\uff0c\u7528\u4e8e\u7cfb\u7edf\u6027\u504f\u89c1\u68c0\u6d4b\u548c\u7f13\u89e3\uff0c\u5728\u516d\u4e2aLLM\u4e0a\u53d1\u73b0\u6bd4\u73b0\u6709\u5de5\u5177\u591a14%\u7684\u9690\u85cf\u504f\u89c1\uff0c\u5e76\u901a\u8fc7\u5fae\u8c03\u5c06\u5b89\u5168\u54cd\u5e94\u7387\u4ece54.7%\u63d0\u5347\u81f388.9%\u4ee5\u4e0a\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5e7f\u6cdb\u90e8\u7f72\u5f15\u53d1\u4e86\u5bf9\u8f93\u51fa\u4e2d\u5fae\u5999\u793e\u4f1a\u504f\u89c1\u7684\u62c5\u5fe7\uff0c\u73b0\u6709\u9632\u62a4\u63aa\u65bd\u5728\u5904\u7406\u95f4\u63a5\u6216\u4e0a\u4e0b\u6587\u590d\u6742\u7684\u504f\u89c1\u8bf1\u5bfc\u63d0\u793a\u65f6\u5f80\u5f80\u5931\u6548\uff0c\u9700\u8981\u66f4\u7cfb\u7edf\u5316\u7684\u504f\u89c1\u8bc4\u4f30\u548c\u7f13\u89e3\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u8715\u53d8\u6d4b\u8bd5\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u5f15\u5165\u516d\u79cd\u65b0\u9896\u7684\u8715\u53d8\u5173\u7cfb\uff0c\u5c06\u76f4\u63a5\u504f\u89c1\u8bf1\u5bfc\u8f93\u5165\u8f6c\u6362\u4e3a\u8bed\u4e49\u7b49\u6548\u4f46\u5bf9\u6297\u6027\u66f4\u5f3a\u7684\u53d8\u4f53\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u504f\u89c1\u68c0\u6d4b\uff1b\u540c\u65f6\u5229\u7528\u8fd9\u4e9b\u53d8\u4f53\u751f\u6210\u591a\u6837\u5316\u7684\u504f\u89c1\u8bf1\u5bfc\u6837\u672c\u8fdb\u884c\u5fae\u8c03\uff0c\u5c06\u6d4b\u8bd5\u8fc7\u7a0b\u4e0e\u7f13\u89e3\u76f4\u63a5\u5173\u8054\u3002", "result": "\u5728\u516d\u4e2a\u6700\u5148\u8fdb\u7684LLM\uff08\u5305\u62ec\u5f00\u6e90\u548c\u4e13\u6709\u6a21\u578b\uff09\u4e0a\uff0c\u4f7f\u7528BiasAsker\u57fa\u51c6\u7684385\u4e2a\u95ee\u9898\u5b50\u96c6\uff08\u6db5\u76d6\u4e03\u4e2a\u53d7\u4fdd\u62a4\u7fa4\u4f53\uff09\uff0c\u8715\u53d8\u5173\u7cfb\u6bd4\u73b0\u6709\u5de5\u5177\u591a\u53d1\u73b014%\u7684\u9690\u85cf\u504f\u89c1\uff1b\u901a\u8fc7\u5fae\u8c03\u539f\u59cb\u548cMR\u7a81\u53d8\u6837\u672c\uff0c\u5b89\u5168\u54cd\u5e94\u7387\u4ece54.7%\u663e\u8457\u63d0\u5347\u81f388.9%\u4ee5\u4e0a\u3002", "conclusion": "\u8715\u53d8\u5173\u7cfb\u662f\u63d0\u9ad8\u5bf9\u8bddAI\u516c\u5e73\u6027\u7684\u5b9e\u7528\u673a\u5236\uff0c\u80fd\u591f\u7cfb\u7edf\u6027\u66b4\u9732\u9690\u85cf\u504f\u89c1\u5e76\u6709\u6548\u589e\u5f3a\u6a21\u578b\u7684\u504f\u89c1\u5f39\u6027\uff0c\u4e3aLLM\u504f\u89c1\u8bc4\u4f30\u548c\u7f13\u89e3\u63d0\u4f9b\u4e86\u7edf\u4e00\u6846\u67b6\u3002"}}
{"id": "2512.00305", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00305", "abs": "https://arxiv.org/abs/2512.00305", "authors": ["Zhengzhuo Xu", "SiNan Du", "Yiyan Qi", "SiwenLu", "Chengjin Xu", "Chun Yuan", "Jian Guo"], "title": "ChartPoint: Guiding MLLMs with Grounding Reflection for Chart Reasoning", "comment": "Accepted by ICCV 2025", "summary": "Multimodal Large Language Models (MLLMs) have emerged as powerful tools for chart comprehension. However, they heavily rely on extracted content via OCR, which leads to numerical hallucinations when chart textual annotations are sparse. While existing methods focus on scaling instructions, they fail to address the fundamental challenge, i.e., reasoning with visual perception. In this paper, we identify a critical observation: MLLMs exhibit weak grounding in chart elements and proportional relationships, as evidenced by their inability to localize key positions to match their reasoning. To bridge this gap, we propose PointCoT, which integrates reflective interaction into chain-of-thought reasoning in charts. By prompting MLLMs to generate bounding boxes and re-render charts based on location annotations, we establish connections between textual reasoning steps and visual grounding regions. We further introduce an automated pipeline to construct ChartPoint-SFT-62k, a dataset featuring 19.2K high-quality chart samples with step-by-step CoT, bounding box, and re-rendered visualizations. Leveraging this data, we develop two instruction-tuned models, ChartPointQ2 and ChartPointQ2.5, which outperform state-of-the-art across several chart benchmarks, e.g., +5.04\\% on ChartBench.", "AI": {"tldr": "PointCoT\u901a\u8fc7\u5c06\u53cd\u5c04\u5f0f\u4ea4\u4e92\u878d\u5165\u56fe\u8868\u601d\u7ef4\u94fe\u63a8\u7406\uff0c\u89e3\u51b3MLLMs\u5728\u56fe\u8868\u7406\u89e3\u4e2d\u7684\u89c6\u89c9\u611f\u77e5\u548c\u5b9a\u4f4d\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u56fe\u8868\u7406\u89e3\u6027\u80fd", "motivation": "\u73b0\u6709MLLMs\u5728\u56fe\u8868\u7406\u89e3\u4e2d\u8fc7\u5ea6\u4f9d\u8d56OCR\u63d0\u53d6\u5185\u5bb9\uff0c\u5f53\u56fe\u8868\u6587\u672c\u6807\u6ce8\u7a00\u758f\u65f6\u4f1a\u4ea7\u751f\u6570\u503c\u5e7b\u89c9\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6269\u5c55\u6307\u4ee4\uff0c\u4f46\u672a\u80fd\u89e3\u51b3\u6838\u5fc3\u6311\u6218\u2014\u2014\u57fa\u4e8e\u89c6\u89c9\u611f\u77e5\u7684\u63a8\u7406\u3002\u7814\u7a76\u53d1\u73b0MLLMs\u5728\u56fe\u8868\u5143\u7d20\u548c\u6bd4\u4f8b\u5173\u7cfb\u4e0a\u7684\u5b9a\u4f4d\u80fd\u529b\u8f83\u5f31\uff0c\u65e0\u6cd5\u5c06\u5173\u952e\u4f4d\u7f6e\u4e0e\u5176\u63a8\u7406\u76f8\u5339\u914d\u3002", "method": "\u63d0\u51faPointCoT\u65b9\u6cd5\uff0c\u5c06\u53cd\u5c04\u5f0f\u4ea4\u4e92\u878d\u5165\u56fe\u8868\u601d\u7ef4\u94fe\u63a8\u7406\u3002\u901a\u8fc7\u63d0\u793aMLLMs\u751f\u6210\u8fb9\u754c\u6846\u548c\u57fa\u4e8e\u4f4d\u7f6e\u6807\u6ce8\u91cd\u65b0\u6e32\u67d3\u56fe\u8868\uff0c\u5efa\u7acb\u6587\u672c\u63a8\u7406\u6b65\u9aa4\u4e0e\u89c6\u89c9\u5b9a\u4f4d\u533a\u57df\u4e4b\u95f4\u7684\u8fde\u63a5\u3002\u6784\u5efa\u4e86ChartPoint-SFT-62k\u6570\u636e\u96c6\uff0c\u5305\u542b19.2K\u9ad8\u8d28\u91cf\u56fe\u8868\u6837\u672c\uff0c\u5e26\u6709\u9010\u6b65\u601d\u7ef4\u94fe\u3001\u8fb9\u754c\u6846\u548c\u91cd\u65b0\u6e32\u67d3\u7684\u53ef\u89c6\u5316\u3002\u57fa\u4e8e\u6b64\u6570\u636e\u5f00\u53d1\u4e86\u4e24\u4e2a\u6307\u4ee4\u8c03\u4f18\u6a21\u578bChartPointQ2\u548cChartPointQ2.5\u3002", "result": "\u63d0\u51fa\u7684\u6a21\u578b\u5728\u591a\u4e2a\u56fe\u8868\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u4f8b\u5982\u5728ChartBench\u4e0a\u63d0\u5347+5.04%\u3002", "conclusion": "PointCoT\u901a\u8fc7\u5c06\u89c6\u89c9\u5b9a\u4f4d\u4e0e\u6587\u672c\u63a8\u7406\u76f8\u7ed3\u5408\uff0c\u6709\u6548\u89e3\u51b3\u4e86MLLMs\u5728\u56fe\u8868\u7406\u89e3\u4e2d\u7684\u6570\u503c\u5e7b\u89c9\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u56fe\u8868\u7406\u89e3\u80fd\u529b\u3002"}}
{"id": "2512.00142", "categories": ["cs.CR", "cs.AI", "q-fin.CP", "q-fin.GN"], "pdf": "https://arxiv.org/pdf/2512.00142", "abs": "https://arxiv.org/abs/2512.00142", "authors": ["Swati Sachan", "Dale S. Fickett"], "title": "DeFi TrustBoost: Blockchain and AI for Trustworthy Decentralized Financial Decisions", "comment": "19 pages", "summary": "This research introduces the Decentralized Finance (DeFi) TrustBoost Framework, which combines blockchain technology and Explainable AI to address challenges faced by lenders underwriting small business loan applications from low-wealth households. The framework is designed with a strong emphasis on fulfilling four crucial requirements of blockchain and AI systems: confidentiality, compliance with data protection laws, resistance to adversarial attacks, and compliance with regulatory audits. It presents a technique for tamper-proof auditing of automated AI decisions and a strategy for on-chain (inside-blockchain) and off-chain data storage to facilitate collaboration within and across financial organizations.", "AI": {"tldr": "DeFi TrustBoost Framework\u7ed3\u5408\u533a\u5757\u94fe\u548c\u53ef\u89e3\u91caAI\uff0c\u89e3\u51b3\u4f4e\u6536\u5165\u5bb6\u5ead\u5c0f\u4f01\u4e1a\u8d37\u6b3e\u5ba1\u6279\u4e2d\u7684\u4fe1\u4efb\u95ee\u9898\uff0c\u5f3a\u8c03\u4fdd\u5bc6\u6027\u3001\u5408\u89c4\u6027\u3001\u6297\u653b\u51fb\u6027\u548c\u53ef\u5ba1\u8ba1\u6027\u3002", "motivation": "\u89e3\u51b3\u91d1\u878d\u673a\u6784\u5728\u5ba1\u6279\u4f4e\u6536\u5165\u5bb6\u5ead\u5c0f\u4f01\u4e1a\u8d37\u6b3e\u7533\u8bf7\u65f6\u9762\u4e34\u7684\u4fe1\u4efb\u6311\u6218\uff0c\u7279\u522b\u662f\u5982\u4f55\u786e\u4fdd\u8d37\u6b3e\u51b3\u7b56\u8fc7\u7a0b\u7684\u900f\u660e\u5ea6\u3001\u5b89\u5168\u6027\u548c\u5408\u89c4\u6027\u3002", "method": "\u7ed3\u5408\u533a\u5757\u94fe\u6280\u672f\u548c\u53ef\u89e3\u91caAI\uff0c\u8bbe\u8ba1\u6ee1\u8db3\u4fdd\u5bc6\u6027\u3001\u6570\u636e\u4fdd\u62a4\u5408\u89c4\u3001\u6297\u5bf9\u6297\u653b\u51fb\u548c\u76d1\u7ba1\u5ba1\u8ba1\u8981\u6c42\u7684\u6846\u67b6\uff0c\u5305\u62ec\u9632\u7be1\u6539\u5ba1\u8ba1\u6280\u672f\u548c\u94fe\u4e0a\u94fe\u4e0b\u6570\u636e\u5b58\u50a8\u7b56\u7565\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684DeFi TrustBoost\u6846\u67b6\uff0c\u80fd\u591f\u5b9e\u73b0\u81ea\u52a8\u5316AI\u51b3\u7b56\u7684\u9632\u7be1\u6539\u5ba1\u8ba1\uff0c\u5e76\u652f\u6301\u91d1\u878d\u673a\u6784\u5185\u5916\u7684\u534f\u4f5c\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aDeFi\u9886\u57df\u7684\u5c0f\u4f01\u4e1a\u8d37\u6b3e\u5ba1\u6279\u63d0\u4f9b\u4e86\u53ef\u4fe1\u3001\u900f\u660e\u4e14\u5408\u89c4\u7684\u6280\u672f\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u4fc3\u8fdb\u91d1\u878d\u5305\u5bb9\u6027\u3002"}}
{"id": "2512.00560", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.00560", "abs": "https://arxiv.org/abs/2512.00560", "authors": ["Jinyu Cai", "Jialong Li", "Nianyu Li", "Zhenyu Mao", "Mingyue Zhang", "Kenji Tei"], "title": "SAGE: Semantic-Aware Gray-Box Game Regression Testing with Large Language Models", "comment": "This paper has been submitted to the Automated Software Engineering journal", "summary": "The rapid iteration cycles of modern live-service games make regression testing indispensable for maintaining quality and stability. However, existing regression testing approaches face critical limitations, especially in common gray-box settings where full source code access is unavailable: they heavily rely on manual effort for test case construction, struggle to maintain growing suites plagued by redundancy, and lack efficient mechanisms for prioritizing relevant tests. These challenges result in excessive testing costs, limited automation, and insufficient bug detection. To address these issues, we propose SAGE, a semanticaware regression testing framework for gray-box game environments. SAGE systematically addresses the core challenges of test generation, maintenance, and selection. It employs LLM-guided reinforcement learning for efficient, goal-oriented exploration to automatically generate a diverse foundational test suite. Subsequently, it applies a semantic-based multi-objective optimization to refine this suite into a compact, high-value subset by balancing cost, coverage, and rarity. Finally, it leverages LLM-based semantic analysis of update logs to prioritize test cases most relevant to version changes, enabling efficient adaptation across iterations. We evaluate SAGE on two representative environments, Overcooked Plus and Minecraft, comparing against both automated baselines and human-recorded test cases. Across all environments, SAGE achieves superior bug detection with significantly lower execution cost, while demonstrating strong adaptability to version updates.", "AI": {"tldr": "SAGE\u662f\u4e00\u4e2a\u9762\u5411\u7070\u76d2\u6e38\u620f\u73af\u5883\u7684\u8bed\u4e49\u611f\u77e5\u56de\u5f52\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7LLM\u5f15\u5bfc\u7684\u5f3a\u5316\u5b66\u4e60\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\uff0c\u591a\u76ee\u6807\u4f18\u5316\u538b\u7f29\u6d4b\u8bd5\u5957\u4ef6\uff0c\u5e76\u57fa\u4e8e\u66f4\u65b0\u65e5\u5fd7\u8bed\u4e49\u5206\u6790\u4f18\u5148\u9009\u62e9\u76f8\u5173\u6d4b\u8bd5\uff0c\u663e\u8457\u964d\u4f4e\u6d4b\u8bd5\u6210\u672c\u5e76\u63d0\u9ad8\u7f3a\u9677\u68c0\u6d4b\u80fd\u529b\u3002", "motivation": "\u73b0\u4ee3\u5b9e\u65f6\u670d\u52a1\u6e38\u620f\u7684\u5feb\u901f\u8fed\u4ee3\u5468\u671f\u9700\u8981\u6709\u6548\u7684\u56de\u5f52\u6d4b\u8bd5\u6765\u4fdd\u8bc1\u8d28\u91cf\u548c\u7a33\u5b9a\u6027\u3002\u73b0\u6709\u56de\u5f52\u6d4b\u8bd5\u65b9\u6cd5\u5728\u7070\u76d2\u73af\u5883\u4e0b\u5b58\u5728\u5173\u952e\u9650\u5236\uff1a\u6d4b\u8bd5\u7528\u4f8b\u6784\u5efa\u4f9d\u8d56\u4eba\u5de5\u3001\u6d4b\u8bd5\u5957\u4ef6\u5197\u4f59\u589e\u957f\u3001\u7f3a\u4e4f\u6709\u6548\u7684\u6d4b\u8bd5\u4f18\u5148\u7ea7\u6392\u5e8f\u673a\u5236\uff0c\u5bfc\u81f4\u6d4b\u8bd5\u6210\u672c\u8fc7\u9ad8\u3001\u81ea\u52a8\u5316\u7a0b\u5ea6\u4f4e\u3001\u7f3a\u9677\u68c0\u6d4b\u4e0d\u8db3\u3002", "method": "SAGE\u91c7\u7528\u4e09\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u4f7f\u7528LLM\u5f15\u5bfc\u7684\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u76ee\u6807\u5bfc\u5411\u63a2\u7d22\uff0c\u81ea\u52a8\u751f\u6210\u591a\u6837\u5316\u7684\u57fa\u7840\u6d4b\u8bd5\u5957\u4ef6\uff1b2) \u5e94\u7528\u57fa\u4e8e\u8bed\u4e49\u7684\u591a\u76ee\u6807\u4f18\u5316\uff0c\u5e73\u8861\u6210\u672c\u3001\u8986\u76d6\u7387\u548c\u7a00\u6709\u6027\uff0c\u5c06\u6d4b\u8bd5\u5957\u4ef6\u7cbe\u70bc\u4e3a\u7d27\u51d1\u7684\u9ad8\u4ef7\u503c\u5b50\u96c6\uff1b3) \u5229\u7528\u57fa\u4e8eLLM\u7684\u66f4\u65b0\u65e5\u5fd7\u8bed\u4e49\u5206\u6790\uff0c\u4f18\u5148\u9009\u62e9\u4e0e\u7248\u672c\u53d8\u66f4\u6700\u76f8\u5173\u7684\u6d4b\u8bd5\u7528\u4f8b\u3002", "result": "\u5728Overcooked Plus\u548cMinecraft\u4e24\u4e2a\u4ee3\u8868\u6027\u73af\u5883\u4e2d\u8bc4\u4f30\uff0c\u4e0e\u81ea\u52a8\u5316\u57fa\u51c6\u548c\u4eba\u5de5\u8bb0\u5f55\u7684\u6d4b\u8bd5\u7528\u4f8b\u76f8\u6bd4\uff0cSAGE\u5728\u6240\u6709\u73af\u5883\u4e2d\u90fd\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u7f3a\u9677\u68c0\u6d4b\u80fd\u529b\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u6267\u884c\u6210\u672c\uff0c\u5e76\u5c55\u73b0\u51fa\u5bf9\u7248\u672c\u66f4\u65b0\u7684\u5f3a\u5927\u9002\u5e94\u6027\u3002", "conclusion": "SAGE\u6709\u6548\u89e3\u51b3\u4e86\u7070\u76d2\u6e38\u620f\u73af\u5883\u4e2d\u56de\u5f52\u6d4b\u8bd5\u7684\u5173\u952e\u6311\u6218\uff0c\u901a\u8fc7\u81ea\u52a8\u751f\u6210\u3001\u4f18\u5316\u548c\u9009\u62e9\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u81ea\u9002\u5e94\u7684\u56de\u5f52\u6d4b\u8bd5\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u6d4b\u8bd5\u6210\u672c\u5e76\u63d0\u9ad8\u4e86\u7f3a\u9677\u68c0\u6d4b\u80fd\u529b\u3002"}}
{"id": "2512.00377", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.00377", "abs": "https://arxiv.org/abs/2512.00377", "authors": ["Yuexin Xiang", "SM Mahir Shazeed Rish", "Qishuang Fu", "Yuquan Li", "Qin Wang", "Tsz Hon Yuen", "Jiangshan Yu"], "title": "Measuring Memecoin Fragility", "comment": null, "summary": "Memecoins, emerging from internet culture and community-driven narratives, have rapidly evolved into a unique class of crypto assets. Unlike technology-driven cryptocurrencies, their market dynamics are primarily shaped by viral social media diffusion, celebrity influence, and speculative capital inflows.\n  To capture the distinctive vulnerabilities of these ecosystems, we present the first Memecoin Ecosystem Fragility Framework (ME2F). ME2F formalizes memecoin risks in three dimensions: i) Volatility Dynamics Score capturing persistent and extreme price swings together with spillover from base chains; ii) Whale Dominance Score quantifying ownership concentration among top holders; and iii) Sentiment Amplification Score measuring the impact of attention-driven shocks on market stability.\n  We apply ME2F to representative tokens (over 65\\% market share) and show that fragility is not evenly distributed across the ecosystem. Politically themed tokens such as TRUMP, MELANIA, and LIBRA concentrate the highest risks, combining volatility, ownership concentration, and sensitivity to sentiment shocks. Established memecoins such as DOGE, SHIB, and PEPE fall into an intermediate range. Benchmark tokens ETH and SOL remain consistently resilient due to deeper liquidity and institutional participation. Our findings provide the first ecosystem-level evidence of memecoin fragility and highlight governance implications for enhancing market resilience in the Web3 era.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u6a21\u56e0\u5e01\u751f\u6001\u7cfb\u7edf\u8106\u5f31\u6027\u6846\u67b6(ME2F)\uff0c\u7528\u4e8e\u91cf\u5316\u6a21\u56e0\u5e01\u5728\u6ce2\u52a8\u6027\u3001\u6240\u6709\u6743\u96c6\u4e2d\u5ea6\u548c\u60c5\u7eea\u653e\u5927\u4e09\u4e2a\u7ef4\u5ea6\u7684\u98ce\u9669\uff0c\u53d1\u73b0\u653f\u6cbb\u4e3b\u9898\u6a21\u56e0\u5e01\u98ce\u9669\u6700\u9ad8\uff0c\u800c\u4ee5\u592a\u574a\u7b49\u4e3b\u6d41\u4ee3\u5e01\u6700\u4e3a\u7a33\u5065\u3002", "motivation": "\u6a21\u56e0\u5e01\u4f5c\u4e3a\u4ece\u4e92\u8054\u7f51\u6587\u5316\u548c\u793e\u533a\u53d9\u4e8b\u4e2d\u8bde\u751f\u7684\u72ec\u7279\u52a0\u5bc6\u8d44\u4ea7\u7c7b\u522b\uff0c\u5176\u5e02\u573a\u52a8\u6001\u4e3b\u8981\u7531\u793e\u4ea4\u5a92\u4f53\u4f20\u64ad\u3001\u540d\u4eba\u5f71\u54cd\u548c\u6295\u673a\u8d44\u672c\u9a71\u52a8\uff0c\u4e0e\u4f20\u7edf\u6280\u672f\u9a71\u52a8\u7684\u52a0\u5bc6\u8d27\u5e01\u4e0d\u540c\u3002\u76ee\u524d\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u6846\u67b6\u6765\u8bc4\u4f30\u8fd9\u7c7b\u8d44\u4ea7\u7684\u8106\u5f31\u6027\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u4e86\u6a21\u56e0\u5e01\u751f\u6001\u7cfb\u7edf\u8106\u5f31\u6027\u6846\u67b6(ME2F)\uff0c\u8be5\u6846\u67b6\u4ece\u4e09\u4e2a\u7ef4\u5ea6\u5f62\u5f0f\u5316\u6a21\u56e0\u5e01\u98ce\u9669\uff1a1)\u6ce2\u52a8\u52a8\u6001\u8bc4\u5206\uff1a\u6355\u6349\u6301\u7eed\u548c\u6781\u7aef\u7684\u4ef7\u683c\u6ce2\u52a8\u4ee5\u53ca\u57fa\u7840\u94fe\u7684\u6ea2\u51fa\u6548\u5e94\uff1b2)\u9cb8\u9c7c\u4e3b\u5bfc\u8bc4\u5206\uff1a\u91cf\u5316\u9876\u7ea7\u6301\u6709\u8005\u7684\u6240\u6709\u6743\u96c6\u4e2d\u5ea6\uff1b3)\u60c5\u7eea\u653e\u5927\u8bc4\u5206\uff1a\u8861\u91cf\u6ce8\u610f\u529b\u9a71\u52a8\u51b2\u51fb\u5bf9\u5e02\u573a\u7a33\u5b9a\u6027\u7684\u5f71\u54cd\u3002", "result": "\u5e94\u7528ME2F\u5206\u6790\u4ee3\u8868\u6027\u4ee3\u5e01(\u8986\u76d6\u8d85\u8fc765%\u5e02\u573a\u4efd\u989d)\u53d1\u73b0\uff1a1)\u653f\u6cbb\u4e3b\u9898\u4ee3\u5e01(\u5982TRUMP\u3001MELANIA\u3001LIBRA)\u98ce\u9669\u6700\u9ad8\uff0c\u7ed3\u5408\u4e86\u6ce2\u52a8\u6027\u3001\u6240\u6709\u6743\u96c6\u4e2d\u5ea6\u548c\u60c5\u7eea\u51b2\u51fb\u654f\u611f\u6027\uff1b2)\u6210\u719f\u6a21\u56e0\u5e01(\u5982DOGE\u3001SHIB\u3001PEPE)\u5904\u4e8e\u4e2d\u7b49\u98ce\u9669\u8303\u56f4\uff1b3)\u57fa\u51c6\u4ee3\u5e01(ETH\u548cSOL)\u7531\u4e8e\u66f4\u6df1\u7684\u6d41\u52a8\u6027\u548c\u673a\u6784\u53c2\u4e0e\u800c\u4fdd\u6301\u7a33\u5b9a\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u63d0\u4f9b\u6a21\u56e0\u5e01\u751f\u6001\u7cfb\u7edf\u8106\u5f31\u6027\u8bc1\u636e\u7684\u7814\u7a76\uff0c\u63ed\u793a\u4e86\u6a21\u56e0\u5e01\u98ce\u9669\u7684\u5f02\u8d28\u6027\u5206\u5e03\uff0c\u4e3aWeb3\u65f6\u4ee3\u589e\u5f3a\u5e02\u573a\u97e7\u6027\u7684\u6cbb\u7406\u63d0\u4f9b\u4e86\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2512.00571", "categories": ["cs.SE", "cs.AI", "cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2512.00571", "abs": "https://arxiv.org/abs/2512.00571", "authors": ["Tarun Chintada", "Uday Kiran Cheera"], "title": "Enhancing Analogy-Based Software Effort Estimation with Firefly Algorithm Optimization", "comment": "12 pages, 3 figures, 2 tables. Research conducted in June 2024", "summary": "Analogy-Based Estimation (ABE) is a popular method for non-algorithmic estimation due to its simplicity and effectiveness. The Analogy-Based Estimation (ABE) model was proposed by researchers, however, no optimal approach for reliable estimation was developed. Achieving high accuracy in the ABE might be challenging for new software projects that differ from previous initiatives. This study (conducted in June 2024) proposes a Firefly Algorithm-guided Analogy-Based Estimation (FAABE) model that combines FA with ABE to improve estimation accuracy. The FAABE model was tested on five publicly accessible datasets: Cocomo81, Desharnais, China, Albrecht, Kemerer and Maxwell. To improve prediction efficiency, feature selection was used. The results were measured using a variety of evaluation metrics; various error measures include MMRE, MAE, MSE, and RMSE. Compared to conventional models, the experimental results show notable increases in prediction precision, demonstrating the efficacy of the Firefly-Analogy ensemble.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u8424\u706b\u866b\u7b97\u6cd5\u5f15\u5bfc\u7684\u7c7b\u6bd4\u4f30\u7b97\u6a21\u578b\uff08FAABE\uff09\uff0c\u5c06\u8424\u706b\u866b\u7b97\u6cd5\u4e0e\u7c7b\u6bd4\u4f30\u7b97\u76f8\u7ed3\u5408\uff0c\u4ee5\u63d0\u9ad8\u8f6f\u4ef6\u9879\u76ee\u4f30\u7b97\u7cbe\u5ea6\uff0c\u5e76\u5728\u591a\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u7c7b\u6bd4\u4f30\u7b97\u65b9\u6cd5\u867d\u7136\u7b80\u5355\u6709\u6548\uff0c\u4f46\u5bf9\u4e8e\u4e0e\u4ee5\u5f80\u9879\u76ee\u5dee\u5f02\u8f83\u5927\u7684\u65b0\u8f6f\u4ef6\u9879\u76ee\uff0c\u96be\u4ee5\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u4f30\u7b97\u3002\u73b0\u6709\u7814\u7a76\u5c1a\u672a\u5f00\u53d1\u51fa\u53ef\u9760\u7684\u4f18\u5316\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51faFAABE\u6a21\u578b\uff0c\u5c06\u8424\u706b\u866b\u7b97\u6cd5\u4e0e\u7c7b\u6bd4\u4f30\u7b97\u76f8\u7ed3\u5408\uff0c\u5e76\u4f7f\u7528\u7279\u5f81\u9009\u62e9\u6280\u672f\u6765\u63d0\u9ad8\u9884\u6d4b\u6548\u7387\u3002\u5728Cocomo81\u3001Desharnais\u3001China\u3001Albrecht\u3001Kemerer\u548cMaxwell\u4e94\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u4f7f\u7528MMRE\u3001MAE\u3001MSE\u548cRMSE\u7b49\u591a\u79cd\u8bc4\u4f30\u6307\u6807\u8fdb\u884c\u6d4b\u91cf\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u4f20\u7edf\u6a21\u578b\u76f8\u6bd4\uff0cFAABE\u6a21\u578b\u5728\u9884\u6d4b\u7cbe\u5ea6\u4e0a\u6709\u663e\u8457\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u8424\u706b\u866b-\u7c7b\u6bd4\u96c6\u6210\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "FAABE\u6a21\u578b\u901a\u8fc7\u96c6\u6210\u8424\u706b\u866b\u7b97\u6cd5\u548c\u7c7b\u6bd4\u4f30\u7b97\uff0c\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u8f6f\u4ef6\u9879\u76ee\u4f30\u7b97\u7684\u51c6\u786e\u6027\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u4e0e\u5386\u53f2\u9879\u76ee\u5dee\u5f02\u8f83\u5927\u7684\u65b0\u9879\u76ee\u65f6\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2512.00331", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.00331", "abs": "https://arxiv.org/abs/2512.00331", "authors": ["Yefeng Wu", "Yuchen Song", "Yecheng Zhao", "Ling Wu", "Shan Wan"], "title": "CogEvo-Edu: Cognitive Evolution Educational Multi-Agent Collaborative System", "comment": null, "summary": "Large language models (LLMs) are increasingly deployed as conversational tutors in STEM education, yet most systems still rely on a single LLM with a static retrieval-augmented generation (RAG) pipeline over course materials. This design struggles in complex domains such as digital signal processing (DSP), where tutors must maintain coherent long-term student models, manage heterogeneous knowledge bases, and adapt teaching strategies over extended interactions. We argue that retrieval, memory, and control should be treated as a coupled cognitive evolution process. We instantiate this view in CogEvo-Edu, a hierarchical educational multi-agent system comprising a Cognitive Perception Layer (CPL), a Knowledge Evolution Layer (KEL), and a Meta-Control Layer (MCL). CPL maintains dual memories and performs confidence-weighted consolidation to build structured, self-correcting student profiles under limited context. KEL assigns each knowledge chunk a spatiotemporal value that drives activation, semantic compression, and forgetting. MCL formulates tutoring as hierarchical sequential decision making, orchestrating specialized agents and jointly adapting CPL/KEL hyperparameters via a dual inner--outer loop. To evaluate CogEvo-Edu, we construct DSP-EduBench, a vertical benchmark for DSP tutoring with heterogeneous resources, simulated student profiles, and long-horizon interaction scripts. Using a three-model LLM-as-a-Judge ensemble, CogEvo-Edu raises the overall score from 5.32 to 9.23 and improves all six indicators over static RAG, simple memory, and a single-agent variant, demonstrating the value of jointly evolving student profiles, knowledge bases, and teaching policies.", "AI": {"tldr": "CogEvo-Edu\uff1a\u4e00\u4e2a\u7528\u4e8eSTEM\u6559\u80b2\uff08\u7279\u522b\u662f\u6570\u5b57\u4fe1\u53f7\u5904\u7406\uff09\u7684\u5206\u5c42\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u8026\u5408\u7684\u8ba4\u77e5\u6f14\u5316\u8fc7\u7a0b\uff08\u68c0\u7d22\u3001\u8bb0\u5fc6\u548c\u63a7\u5236\uff09\u6765\u63d0\u5347LLM\u4f5c\u4e3a\u5bf9\u8bdd\u5bfc\u5e08\u7684\u6548\u679c\u3002", "motivation": "\u5f53\u524dLLM\u5728STEM\u6559\u80b2\u4e2d\u4e3b\u8981\u4f9d\u8d56\u5355\u4e00\u6a21\u578b\u548c\u9759\u6001RAG\u7ba1\u9053\uff0c\u96be\u4ee5\u5904\u7406\u590d\u6742\u9886\u57df\uff08\u5982\u6570\u5b57\u4fe1\u53f7\u5904\u7406\uff09\u4e2d\u9700\u8981\u957f\u671f\u5b66\u751f\u5efa\u6a21\u3001\u5f02\u6784\u77e5\u8bc6\u5e93\u7ba1\u7406\u548c\u81ea\u9002\u5e94\u6559\u5b66\u7b56\u7565\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faCogEvo-Edu\u7cfb\u7edf\uff0c\u5305\u542b\u4e09\u4e2a\u5c42\u6b21\uff1a\u8ba4\u77e5\u611f\u77e5\u5c42\uff08\u7ef4\u62a4\u53cc\u91cd\u8bb0\u5fc6\u548c\u7f6e\u4fe1\u5ea6\u52a0\u6743\u6574\u5408\uff09\u3001\u77e5\u8bc6\u6f14\u5316\u5c42\uff08\u4e3a\u77e5\u8bc6\u5757\u5206\u914d\u65f6\u7a7a\u4ef7\u503c\u9a71\u52a8\u6fc0\u6d3b\u548c\u9057\u5fd8\uff09\u3001\u5143\u63a7\u5236\u5c42\uff08\u5c06\u6559\u5b66\u5efa\u6a21\u4e3a\u5206\u5c42\u5e8f\u5217\u51b3\u7b56\uff0c\u534f\u8c03\u4e13\u4e1a\u667a\u80fd\u4f53\uff09\u3002", "result": "\u5728DSP-EduBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528\u4e09\u6a21\u578bLLM-as-a-Judge\u8bc4\u4f30\uff0cCogEvo-Edu\u5c06\u603b\u4f53\u5f97\u5206\u4ece5.32\u63d0\u5347\u52309.23\uff0c\u5728\u516d\u4e2a\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u9759\u6001RAG\u3001\u7b80\u5355\u8bb0\u5fc6\u548c\u5355\u667a\u80fd\u4f53\u53d8\u4f53\u3002", "conclusion": "\u5c06\u5b66\u751f\u6863\u6848\u3001\u77e5\u8bc6\u5e93\u548c\u6559\u5b66\u7b56\u7565\u8054\u5408\u6f14\u5316\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86LLM\u4f5c\u4e3aSTEM\u6559\u80b2\u5bfc\u5e08\u7684\u6548\u679c\uff0c\u9a8c\u8bc1\u4e86\u5c06\u68c0\u7d22\u3001\u8bb0\u5fc6\u548c\u63a7\u5236\u4f5c\u4e3a\u8026\u5408\u8ba4\u77e5\u6f14\u5316\u8fc7\u7a0b\u7684\u4ef7\u503c\u3002"}}
{"id": "2512.00412", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00412", "abs": "https://arxiv.org/abs/2512.00412", "authors": ["Jiawei Chen", "Yang Yang", "Chao Yu", "Yu Tian", "Zhi Cao", "Linghao Li", "Hang Su", "Zhaoxia Yin"], "title": "Red Teaming Large Reasoning Models", "comment": "30 pages, 9 figures", "summary": "Large Reasoning Models (LRMs) have emerged as a powerful advancement in multi-step reasoning tasks, offering enhanced transparency and logical consistency through explicit chains of thought (CoT). However, these models introduce novel safety and reliability risks, such as CoT-hijacking and prompt-induced inefficiencies, which are not fully captured by existing evaluation methods. To address this gap, we propose RT-LRM, a unified benchmark designed to assess the trustworthiness of LRMs. RT-LRM evaluates three core dimensions: truthfulness, safety and efficiency. Beyond metric-based evaluation, we further introduce the training paradigm as a key analytical perspective to investigate the systematic impact of different training strategies on model trustworthiness. We achieve this by designing a curated suite of 30 reasoning tasks from an observational standpoint. We conduct extensive experiments on 26 models and identify several valuable insights into the trustworthiness of LRMs. For example, LRMs generally face trustworthiness challenges and tend to be more fragile than Large Language Models (LLMs) when encountering reasoning-induced risks. These findings uncover previously underexplored vulnerabilities and highlight the need for more targeted evaluations. In addition, we release a scalable toolbox for standardized trustworthiness research to support future advancements in this important field. Our code and datasets will be open-sourced.", "AI": {"tldr": "RT-LRM\u662f\u4e00\u4e2a\u8bc4\u4f30\u5927\u578b\u63a8\u7406\u6a21\u578b\u53ef\u4fe1\u5ea6\u7684\u7edf\u4e00\u57fa\u51c6\uff0c\u6db5\u76d6\u771f\u5b9e\u6027\u3001\u5b89\u5168\u6027\u548c\u6548\u7387\u4e09\u4e2a\u7ef4\u5ea6\uff0c\u901a\u8fc730\u4e2a\u63a8\u7406\u4efb\u52a1\u5bf926\u4e2a\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\uff0c\u53d1\u73b0LRM\u5b58\u5728\u53ef\u4fe1\u5ea6\u6311\u6218\u4e14\u6bd4LLM\u66f4\u8106\u5f31\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5f15\u5165\u4e86\u65b0\u7684\u5b89\u5168\u548c\u53ef\u9760\u6027\u98ce\u9669\uff08\u5982\u601d\u7ef4\u94fe\u52ab\u6301\u548c\u63d0\u793a\u8bf1\u5bfc\u4f4e\u6548\uff09\uff0c\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u65e0\u6cd5\u5145\u5206\u6355\u6349\u8fd9\u4e9b\u98ce\u9669\uff0c\u9700\u8981\u4e13\u95e8\u7684\u53ef\u4fe1\u5ea6\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "\u63d0\u51faRT-LRM\u7edf\u4e00\u57fa\u51c6\uff0c\u4ece\u771f\u5b9e\u6027\u3001\u5b89\u5168\u6027\u548c\u6548\u7387\u4e09\u4e2a\u7ef4\u5ea6\u8bc4\u4f30LRM\u53ef\u4fe1\u5ea6\uff1b\u5f15\u5165\u8bad\u7ec3\u8303\u5f0f\u4f5c\u4e3a\u5206\u6790\u89c6\u89d2\uff0c\u8bbe\u8ba130\u4e2a\u63a8\u7406\u4efb\u52a1\u5957\u4ef6\uff0c\u5bf926\u4e2a\u6a21\u578b\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0LRM\u666e\u904d\u9762\u4e34\u53ef\u4fe1\u5ea6\u6311\u6218\uff0c\u5728\u9047\u5230\u63a8\u7406\u8bf1\u5bfc\u98ce\u9669\u65f6\u6bd4\u5927\u578b\u8bed\u8a00\u6a21\u578b\u66f4\u8106\u5f31\uff1b\u63ed\u793a\u4e86\u5148\u524d\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u8106\u5f31\u6027\uff0c\u5f3a\u8c03\u4e86\u9488\u5bf9\u6027\u8bc4\u4f30\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "RT-LRM\u57fa\u51c6\u586b\u8865\u4e86LRM\u53ef\u4fe1\u5ea6\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u63ed\u793a\u4e86LRM\u7684\u8106\u5f31\u6027\uff0c\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u7814\u7a76\u5de5\u5177\u7bb1\uff0c\u5c06\u4fc3\u8fdb\u8be5\u9886\u57df\u672a\u6765\u53d1\u5c55\uff0c\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5c06\u5f00\u6e90\u3002"}}
{"id": "2512.00651", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.00651", "abs": "https://arxiv.org/abs/2512.00651", "authors": ["Mohammed Latif Siddiq", "Arvin Islam-Gomes", "Natalie Sekerak", "Joanna C. S. Santos"], "title": "Large Language Models for Software Engineering: A Reproducibility Crisis", "comment": "Submitted to Empirical Software Engineering (EMSE) journal; 112 pages (81 pages of references)", "summary": "Reproducibility is a cornerstone of scientific progress, yet its state in large language model (LLM)-based software engineering (SE) research remains poorly understood. This paper presents the first large-scale, empirical study of reproducibility practices in LLM-for-SE research. We systematically mined and analyzed 640 papers published between 2017 and 2025 across premier software engineering, machine learning, and natural language processing venues, extracting structured metadata from publications, repositories, and documentation. Guided by four research questions, we examine (i) the prevalence of reproducibility smells, (ii) how reproducibility has evolved over time, (iii) whether artifact evaluation badges reliably reflect reproducibility quality, and (iv) how publication venues influence transparency practices. Using a taxonomy of seven smell categories: Code and Execution, Data, Documentation, Environment and Tooling, Versioning, Model, and Access and Legal, we manually annotated all papers and associated artifacts. Our analysis reveals persistent gaps in artifact availability, environment specification, versioning rigor, and documentation clarity, despite modest improvements in recent years and increased adoption of artifact evaluation processes at top SE venues. Notably, we find that badges often signal artifact presence but do not consistently guarantee execution fidelity or long-term reproducibility. Motivated by these findings, we provide actionable recommendations to mitigate reproducibility smells and introduce a Reproducibility Maturity Model (RMM) to move beyond binary artifact certification toward multi-dimensional, progressive evaluation of reproducibility rigor.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u5bf9\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u4e2d\u7684\u53ef\u590d\u73b0\u6027\u5b9e\u8df5\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u5b9e\u8bc1\u5206\u6790\uff0c\u63ed\u793a\u4e86\u53ef\u590d\u73b0\u6027\u6c14\u5473\u666e\u904d\u5b58\u5728\u3001\u8bc4\u4f30\u5fbd\u7ae0\u53ef\u9760\u6027\u6709\u9650\u7b49\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u53ef\u590d\u73b0\u6027\u6210\u719f\u5ea6\u6a21\u578b\u548c\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u53ef\u590d\u73b0\u6027\u662f\u79d1\u5b66\u8fdb\u6b65\u7684\u57fa\u77f3\uff0c\u4f46\u5f53\u524d\u5bf9\u4e8e\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u4e2d\u53ef\u590d\u73b0\u6027\u5b9e\u8df5\u7684\u72b6\u51b5\u4e86\u89e3\u4e0d\u8db3\u3002\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u901a\u8fc7\u7cfb\u7edf\u5206\u6790\u4e86\u89e3\u8be5\u9886\u57df\u53ef\u590d\u73b0\u6027\u5b9e\u8df5\u7684\u771f\u5b9e\u72b6\u51b5\u3002", "method": "\u7814\u7a76\u7cfb\u7edf\u6316\u6398\u5e76\u5206\u6790\u4e862017-2025\u5e74\u95f4\u5728\u9876\u7ea7\u8f6f\u4ef6\u5de5\u7a0b\u3001\u673a\u5668\u5b66\u4e60\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4f1a\u8bae\u4e0a\u53d1\u8868\u7684640\u7bc7\u8bba\u6587\u3002\u901a\u8fc7\u4ece\u51fa\u7248\u7269\u3001\u4ee3\u7801\u5e93\u548c\u6587\u6863\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u5143\u6570\u636e\uff0c\u4f7f\u7528\u4e03\u4e2a\u6c14\u5473\u7c7b\u522b\uff08\u4ee3\u7801\u4e0e\u6267\u884c\u3001\u6570\u636e\u3001\u6587\u6863\u3001\u73af\u5883\u4e0e\u5de5\u5177\u3001\u7248\u672c\u63a7\u5236\u3001\u6a21\u578b\u3001\u8bbf\u95ee\u4e0e\u6cd5\u5f8b\uff09\u7684\u5206\u7c7b\u6cd5\uff0c\u5bf9\u6240\u6709\u8bba\u6587\u548c\u76f8\u5173\u6784\u4ef6\u8fdb\u884c\u4e86\u624b\u52a8\u6807\u6ce8\u3002", "result": "\u5206\u6790\u63ed\u793a\u4e86\u6784\u4ef6\u53ef\u7528\u6027\u3001\u73af\u5883\u89c4\u8303\u3001\u7248\u672c\u63a7\u5236\u4e25\u8c28\u6027\u548c\u6587\u6863\u6e05\u6670\u5ea6\u65b9\u9762\u5b58\u5728\u6301\u7eed\u5dee\u8ddd\u3002\u5c3d\u7ba1\u8fd1\u5e74\u6765\u6709\u6240\u6539\u5584\u4e14\u9876\u7ea7\u8f6f\u4ef6\u5de5\u7a0b\u4f1a\u8bae\u589e\u52a0\u4e86\u6784\u4ef6\u8bc4\u4f30\u6d41\u7a0b\u7684\u91c7\u7528\uff0c\u4f46\u8bc4\u4f30\u5fbd\u7ae0\u901a\u5e38\u4ec5\u8868\u793a\u6784\u4ef6\u5b58\u5728\uff0c\u5e76\u4e0d\u80fd\u4e00\u81f4\u4fdd\u8bc1\u6267\u884c\u4fdd\u771f\u5ea6\u6216\u957f\u671f\u53ef\u590d\u73b0\u6027\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u4e86\u53ef\u64cd\u4f5c\u7684\u5efa\u8bae\u6765\u51cf\u8f7b\u53ef\u590d\u73b0\u6027\u6c14\u5473\uff0c\u5e76\u5f15\u5165\u4e86\u53ef\u590d\u73b0\u6027\u6210\u719f\u5ea6\u6a21\u578b\uff0c\u65e8\u5728\u8d85\u8d8a\u4e8c\u5143\u6784\u4ef6\u8ba4\u8bc1\uff0c\u5b9e\u73b0\u591a\u7ef4\u5ea6\u3001\u6e10\u8fdb\u5f0f\u7684\u53ef\u590d\u73b0\u6027\u4e25\u8c28\u5ea6\u8bc4\u4f30\u3002"}}
{"id": "2512.00344", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00344", "abs": "https://arxiv.org/abs/2512.00344", "authors": ["Naifan Zhang", "Ruihan Sun", "Ruixi Su", "Shiqi Ma", "Shiya Zhang", "Xianna Weng", "Xiaofan Zhang", "Yuhan Zhan", "Yuyang Xu", "Zhaohan Chen", "Zhengyuan Pan", "Ziyi Song"], "title": "Echo-N1: Affective RL Frontier", "comment": null, "summary": "The LLM field has spent a year perfecting RL for tasks machines already excel at, math, code, and deterministic reasoning, while completely sidestepping the domain that actually defines human intelligence: subjective, emotionally grounded, personality sensitive conversation. This space has often been regarded as inherently subjective and challenging to formalize, making it appear unsuitable for conventional RL pipelines. We show that it is not only possible and it is a solvable and transformative RL problem. We propose the first framework that infers user personality on the fly and optimizes model behavior toward personalized conversational preferences. Contrary to the widespread belief that RL collapses in non-verifiable settings, our method produces consistent, robust, and dramatic improvements in humanlike interaction quality. We also introduce the first dynamic emotional intelligence evaluation suite to quantify these gains. Our model, which is introduced as Echo-N1, behaves far above its base version and outperforming the proprietary Doubao 1.5 Character. This work establishes a new frontier for RL: optimizing models for the deeply subjective, deeply human dimensions of conversation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u9996\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u4e2a\u6027\u5316\u5bf9\u8bdd\u6846\u67b6\uff0c\u901a\u8fc7\u5b9e\u65f6\u63a8\u65ad\u7528\u6237\u6027\u683c\u6765\u4f18\u5316\u5bf9\u8bdd\u884c\u4e3a\uff0c\u5728\u4e3b\u89c2\u60c5\u611f\u5bf9\u8bdd\u9886\u57df\u53d6\u5f97\u7a81\u7834\u6027\u8fdb\u5c55", "motivation": "\u5f53\u524dLLM\u9886\u57df\u8fc7\u5ea6\u5173\u6ce8\u6570\u5b66\u3001\u4ee3\u7801\u7b49\u786e\u5b9a\u6027\u63a8\u7406\u4efb\u52a1\uff0c\u5ffd\u89c6\u4e86\u771f\u6b63\u5b9a\u4e49\u4eba\u7c7b\u667a\u80fd\u7684\u4e3b\u89c2\u3001\u60c5\u611f\u5316\u3001\u4e2a\u6027\u5316\u7684\u5bf9\u8bdd\u9886\u57df\u3002\u8be5\u9886\u57df\u5e38\u88ab\u8ba4\u4e3a\u8fc7\u4e8e\u4e3b\u89c2\u96be\u4ee5\u5f62\u5f0f\u5316\uff0c\u4e0d\u9002\u5408\u4f20\u7edfRL\u65b9\u6cd5\uff0c\u4f46\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u662f\u4e00\u4e2a\u53ef\u89e3\u51b3\u4e14\u5177\u6709\u53d8\u9769\u6027\u7684RL\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u9996\u4e2a\u80fd\u591f\u5b9e\u65f6\u63a8\u65ad\u7528\u6237\u6027\u683c\u5e76\u9488\u5bf9\u4e2a\u6027\u5316\u5bf9\u8bdd\u504f\u597d\u4f18\u5316\u6a21\u578b\u884c\u4e3a\u7684\u6846\u67b6\u3002\u5f15\u5165\u52a8\u6001\u60c5\u611f\u667a\u80fd\u8bc4\u4f30\u5957\u4ef6\u6765\u91cf\u5316\u6539\u8fdb\u6548\u679c\u3002\u6a21\u578bEcho-N1\u5728\u4e3b\u89c2\u5bf9\u8bdd\u8d28\u91cf\u4e0a\u5b9e\u73b0\u663e\u8457\u63d0\u5347\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u975e\u53ef\u9a8c\u8bc1\u6027\u8bbe\u7f6e\u4e0b\u4ea7\u751f\u4e00\u81f4\u3001\u7a33\u5065\u4e14\u663e\u8457\u7684\u6539\u8fdb\uff0cEcho-N1\u6a21\u578b\u8868\u73b0\u8fdc\u8d85\u5176\u57fa\u7840\u7248\u672c\uff0c\u5e76\u4f18\u4e8e\u4e13\u6709\u7684Doubao 1.5 Character\u6a21\u578b\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3aRL\u5f00\u8f9f\u4e86\u65b0\u524d\u6cbf\uff1a\u9488\u5bf9\u5bf9\u8bdd\u4e2d\u6df1\u5ea6\u4e3b\u89c2\u3001\u6df1\u5ea6\u4eba\u6027\u5316\u7684\u7ef4\u5ea6\u4f18\u5316\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u5728\u4f20\u7edf\u8ba4\u4e3a\u4e0d\u9002\u5408RL\u7684\u4e3b\u89c2\u60c5\u611f\u5bf9\u8bdd\u9886\u57df\u5b9e\u73b0\u4f18\u5316\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2512.00414", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.00414", "abs": "https://arxiv.org/abs/2512.00414", "authors": ["Haney Kang", "Eduard Marin", "Myoungsung You", "Diego Perino", "Seungwon Shin", "Jinwoo Kim"], "title": "BEACON: Automatic Container Policy Generation using Environment-aware Dynamic Analysis", "comment": null, "summary": "This paper introduces BeaCon, a novel tool for the automated generation of adjustable container security policies. Unlike prior approaches, BeaCon leverages dynamic analysis to simulate realistic environments, uncovering container execution paths that may remain hidden during the profiling phase. To address the challenge of exploring vast profiling spaces, we employ efficient heuristics to reveal additional system events with minimal effort. In addition, BeaCon incorporates a security and functionality scoring mechanism to prioritize system calls and capabilities based on their impact on the host OS kernel's security and the functionality of containerized applications. By integrating these scores, BeaCon achieves a customized balance between security and functionality, enabling cloud providers to enforce security measures while maintaining tenant availability. We implemented a prototype of BeaCon using eBPF kernel technology and conducted extensive evaluations. Results from the top 15 containers, which revealed significant improvements, demonstrate that BeaCon identifies an average of 16.5% additional syscalls by applying diverse environments. Furthermore, we evaluated its effectiveness in mitigating risks associated with 45 known vulnerabilities (e.g., CVEs), showcasing its potential to significantly enhance container security. Additionally, we performed proof-of-concept demonstrations for two well-known security vulnerabilities, showing that BeaCon successfully reduces attack surface by blocking these exploits.", "AI": {"tldr": "BeaCon\u662f\u4e00\u4e2a\u57fa\u4e8e\u52a8\u6001\u5206\u6790\u7684\u81ea\u52a8\u5316\u5bb9\u5668\u5b89\u5168\u7b56\u7565\u751f\u6210\u5de5\u5177\uff0c\u901a\u8fc7\u6a21\u62df\u771f\u5b9e\u73af\u5883\u53d1\u73b0\u9690\u85cf\u7684\u6267\u884c\u8def\u5f84\uff0c\u4f7f\u7528\u542f\u53d1\u5f0f\u65b9\u6cd5\u63a2\u7d22\u914d\u7f6e\u7a7a\u95f4\uff0c\u7ed3\u5408\u5b89\u5168\u6027\u548c\u529f\u80fd\u6027\u8bc4\u5206\u673a\u5236\uff0c\u5728\u4fdd\u6301\u5bb9\u5668\u529f\u80fd\u6027\u7684\u540c\u65f6\u589e\u5f3a\u5b89\u5168\u6027\u3002", "motivation": "\u73b0\u6709\u5bb9\u5668\u5b89\u5168\u7b56\u7565\u751f\u6210\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u53d1\u73b0\u5bb9\u5668\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u53ef\u80fd\u66b4\u9732\u7684\u9690\u85cf\u6267\u884c\u8def\u5f84\uff0c\u5bfc\u81f4\u5b89\u5168\u7b56\u7565\u4e0d\u5b8c\u6574\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5e73\u8861\u5b89\u5168\u6027\u548c\u529f\u80fd\u6027\u7684\u81ea\u52a8\u5316\u5de5\u5177\uff0c\u5e2e\u52a9\u4e91\u670d\u52a1\u63d0\u4f9b\u5546\u5728\u4fdd\u969c\u79df\u6237\u53ef\u7528\u6027\u7684\u540c\u65f6\u589e\u5f3a\u5bb9\u5668\u5b89\u5168\u3002", "method": "1. \u4f7f\u7528\u52a8\u6001\u5206\u6790\u6a21\u62df\u771f\u5b9e\u73af\u5883\uff0c\u53d1\u73b0\u5bb9\u5668\u9690\u85cf\u7684\u6267\u884c\u8def\u5f84\uff1b2. \u91c7\u7528\u9ad8\u6548\u542f\u53d1\u5f0f\u65b9\u6cd5\u63a2\u7d22\u5e9e\u5927\u7684\u914d\u7f6e\u7a7a\u95f4\uff0c\u4ee5\u6700\u5c0f\u4ee3\u4ef7\u63ed\u793a\u989d\u5916\u7cfb\u7edf\u4e8b\u4ef6\uff1b3. \u5f15\u5165\u5b89\u5168\u6027\u548c\u529f\u80fd\u6027\u8bc4\u5206\u673a\u5236\uff0c\u6839\u636e\u7cfb\u7edf\u8c03\u7528\u548ccapabilities\u5bf9\u4e3b\u673a\u5185\u6838\u5b89\u5168\u6027\u548c\u5bb9\u5668\u5e94\u7528\u529f\u80fd\u7684\u5f71\u54cd\u8fdb\u884c\u4f18\u5148\u7ea7\u6392\u5e8f\uff1b4. \u57fa\u4e8eeBPF\u5185\u6838\u6280\u672f\u5b9e\u73b0\u539f\u578b\u7cfb\u7edf\u3002", "result": "1. \u5728Top 15\u5bb9\u5668\u8bc4\u4f30\u4e2d\uff0c\u901a\u8fc7\u5e94\u7528\u591a\u6837\u5316\u73af\u5883\uff0cBeaCon\u5e73\u5747\u8bc6\u522b\u51fa16.5%\u7684\u989d\u5916\u7cfb\u7edf\u8c03\u7528\uff1b2. \u5bf945\u4e2a\u5df2\u77e5\u6f0f\u6d1e\uff08\u5982CVEs\uff09\u7684\u8bc4\u4f30\u663e\u793a\uff0cBeaCon\u80fd\u6709\u6548\u7f13\u89e3\u76f8\u5173\u98ce\u9669\uff1b3. \u9488\u5bf9\u4e24\u4e2a\u77e5\u540d\u5b89\u5168\u6f0f\u6d1e\u7684\u6982\u5ff5\u9a8c\u8bc1\u6f14\u793a\u8868\u660e\uff0cBeaCon\u6210\u529f\u901a\u8fc7\u963b\u6b62\u8fd9\u4e9b\u653b\u51fb\u6765\u51cf\u5c11\u653b\u51fb\u9762\u3002", "conclusion": "BeaCon\u901a\u8fc7\u52a8\u6001\u5206\u6790\u548c\u667a\u80fd\u8bc4\u5206\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u5b89\u5168\u6027\u4e0e\u529f\u80fd\u6027\u7684\u5b9a\u5236\u5316\u5e73\u8861\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u5bb9\u5668\u5b89\u5168\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5e94\u7528\u53ef\u7528\u6027\uff0c\u4e3a\u4e91\u670d\u52a1\u63d0\u4f9b\u5546\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5bb9\u5668\u5b89\u5168\u7b56\u7565\u81ea\u52a8\u5316\u751f\u6210\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.00766", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.00766", "abs": "https://arxiv.org/abs/2512.00766", "authors": ["Zenghui Zhou", "Yuechen Li", "Yi Cai", "Jinlong Wen", "Xiaohan Yu", "Zheng Zheng", "Beibei Yin"], "title": "Code Comments for Quantum Software Development Kits: An Empirical Study on Qiskit", "comment": "Zenghui Zhou and Yuechen Li contributed equally to this work. Corresponding author is Zheng Zheng", "summary": "Quantum computing is gaining attention from academia and industry. With the quantum Software Development Kits (SDKs), programmers can develop quantum software to explore the power of quantum computing. However, programmers may face challenges in understanding quantum software due to the non-intuitive quantum mechanics. To facilitate software development and maintenance, code comments offered in quantum SDKs serve as a natural language explanation of program functionalities and logical flows. Despite their importance, scarce research systematically reports their value and provides constructive guidelines for programmers. To address this gap, our paper focuses on Qiskit, one of the most popular quantum SDKs, and presents CC4Q, the first dataset of code comments for quantum computing. CC4Q incorporates 9677 code comment pairs and 21970 sentence-level code comment units, the latter of which involve heavy human annotation. Regarding the annotation, we validate the applicability of the developer-intent taxonomy used in classical programs, and also propose a new taxonomy considering quantum-specific knowledge. We conduct an empirical study comprehensively interpreting code comments from three perspectives: comment structure and coverage, developers' intentions, and associated quantum topics. Our findings uncover key differences in code comments between classical and quantum software, and also outline quantum-specific knowledge relevant to quantum software development.", "AI": {"tldr": "\u672c\u6587\u521b\u5efa\u4e86\u9996\u4e2a\u91cf\u5b50\u8ba1\u7b97\u4ee3\u7801\u6ce8\u91ca\u6570\u636e\u96c6CC4Q\uff0c\u5305\u542b9677\u4e2a\u4ee3\u7801\u6ce8\u91ca\u5bf9\u548c21970\u4e2a\u53e5\u5b50\u7ea7\u6ce8\u91ca\u5355\u5143\uff0c\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u5206\u6790\u4e86\u91cf\u5b50\u8f6f\u4ef6\u6ce8\u91ca\u7684\u7279\u70b9\u3001\u5f00\u53d1\u8005\u610f\u56fe\u548c\u91cf\u5b50\u76f8\u5173\u4e3b\u9898\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u65e5\u76ca\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u7a0b\u5e8f\u5458\u5728\u7406\u89e3\u91cf\u5b50\u8f6f\u4ef6\u65f6\u9762\u4e34\u91cf\u5b50\u529b\u5b66\u4e0d\u76f4\u89c2\u7684\u6311\u6218\u3002\u867d\u7136\u91cf\u5b50SDK\u4e2d\u7684\u4ee3\u7801\u6ce8\u91ca\u80fd\u5e2e\u52a9\u89e3\u91ca\u7a0b\u5e8f\u529f\u80fd\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u7814\u7a76\u6765\u8bc4\u4f30\u5176\u4ef7\u503c\u5e76\u63d0\u4f9b\u6307\u5bfc\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u4ee5\u6700\u6d41\u884c\u7684\u91cf\u5b50SDK Qiskit\u4e3a\u7814\u7a76\u5bf9\u8c61\uff0c\u521b\u5efa\u4e86CC4Q\u6570\u636e\u96c6\uff0c\u5305\u542b\u5927\u91cf\u4ee3\u7801\u6ce8\u91ca\u5bf9\u548c\u53e5\u5b50\u7ea7\u6ce8\u91ca\u5355\u5143\u3002\u9a8c\u8bc1\u4e86\u7ecf\u5178\u7a0b\u5e8f\u4e2d\u4f7f\u7528\u7684\u5f00\u53d1\u8005\u610f\u56fe\u5206\u7c7b\u6cd5\u5728\u91cf\u5b50\u9886\u57df\u7684\u9002\u7528\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u8003\u8651\u91cf\u5b50\u7279\u5b9a\u77e5\u8bc6\u7684\u65b0\u5206\u7c7b\u6cd5\u3002\u4ece\u6ce8\u91ca\u7ed3\u6784\u4e0e\u8986\u76d6\u7387\u3001\u5f00\u53d1\u8005\u610f\u56fe\u548c\u91cf\u5b50\u76f8\u5173\u4e3b\u9898\u4e09\u4e2a\u89d2\u5ea6\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u91cf\u5b50\u8f6f\u4ef6\u4e0e\u7ecf\u5178\u8f6f\u4ef6\u5728\u4ee3\u7801\u6ce8\u91ca\u65b9\u9762\u5b58\u5728\u5173\u952e\u5dee\u5f02\uff0c\u5e76\u8bc6\u522b\u4e86\u4e0e\u91cf\u5b50\u8f6f\u4ef6\u5f00\u53d1\u76f8\u5173\u7684\u91cf\u5b50\u7279\u5b9a\u77e5\u8bc6\u3002CC4Q\u6570\u636e\u96c6\u4e3a\u91cf\u5b50\u8f6f\u4ef6\u6ce8\u91ca\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\u8d44\u6e90\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86\u91cf\u5b50\u8f6f\u4ef6\u4ee3\u7801\u6ce8\u91ca\uff0c\u521b\u5efa\u4e86CC4Q\u6570\u636e\u96c6\u5e76\u8fdb\u884c\u4e86\u5168\u9762\u5206\u6790\u3002\u7814\u7a76\u63ed\u793a\u4e86\u91cf\u5b50\u8f6f\u4ef6\u6ce8\u91ca\u7684\u72ec\u7279\u6027\uff0c\u4e3a\u91cf\u5b50\u8f6f\u4ef6\u5f00\u53d1\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u6307\u5bfc\uff0c\u6709\u52a9\u4e8e\u7a0b\u5e8f\u5458\u66f4\u597d\u5730\u7406\u89e3\u548c\u7ef4\u62a4\u91cf\u5b50\u8f6f\u4ef6\u3002"}}
{"id": "2512.00349", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00349", "abs": "https://arxiv.org/abs/2512.00349", "authors": ["Sitong Fang", "Shiyi Hou", "Kaile Wang", "Boyuan Chen", "Donghai Hong", "Jiayi Zhou", "Josef Dai", "Yaodong Yang", "Jiaming Ji"], "title": "Debate with Images: Detecting Deceptive Behaviors in Multimodal Large Language Models", "comment": null, "summary": "Are frontier AI systems becoming more capable? Certainly. Yet such progress is not an unalloyed blessing but rather a Trojan horse: behind their performance leaps lie more insidious and destructive safety risks, namely deception. Unlike hallucination, which arises from insufficient capability and leads to mistakes, deception represents a deeper threat in which models deliberately mislead users through complex reasoning and insincere responses. As system capabilities advance, deceptive behaviours have spread from textual to multimodal settings, amplifying their potential harm. First and foremost, how can we monitor these covert multimodal deceptive behaviors? Nevertheless, current research remains almost entirely confined to text, leaving the deceptive risks of multimodal large language models unexplored. In this work, we systematically reveal and quantify multimodal deception risks, introducing MM-DeceptionBench, the first benchmark explicitly designed to evaluate multimodal deception. Covering six categories of deception, MM-DeceptionBench characterizes how models strategically manipulate and mislead through combined visual and textual modalities. On the other hand, multimodal deception evaluation is almost a blind spot in existing methods. Its stealth, compounded by visual-semantic ambiguity and the complexity of cross-modal reasoning, renders action monitoring and chain-of-thought monitoring largely ineffective. To tackle this challenge, we propose debate with images, a novel multi-agent debate monitor framework. By compelling models to ground their claims in visual evidence, this method substantially improves the detectability of deceptive strategies. Experiments show that it consistently increases agreement with human judgements across all tested models, boosting Cohen's kappa by 1.5x and accuracy by 1.25x on GPT-4o.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u9996\u4e2a\u591a\u6a21\u6001\u6b3a\u9a97\u57fa\u51c6MM-DeceptionBench\uff0c\u5e76\u5f00\u53d1\u57fa\u4e8e\u56fe\u50cf\u8fa9\u8bba\u7684\u591a\u667a\u80fd\u4f53\u76d1\u63a7\u6846\u67b6\uff0c\u4ee5\u68c0\u6d4b\u548c\u91cf\u5316\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6b3a\u9a97\u98ce\u9669\u3002", "motivation": "\u968f\u7740\u524d\u6cbfAI\u7cfb\u7edf\u80fd\u529b\u63d0\u5347\uff0c\u6b3a\u9a97\u6027\u884c\u4e3a\u4ece\u6587\u672c\u6269\u5c55\u5230\u591a\u6a21\u6001\u573a\u666f\uff0c\u5e26\u6765\u66f4\u9690\u853d\u548c\u7834\u574f\u6027\u7684\u5b89\u5168\u98ce\u9669\u3002\u5f53\u524d\u7814\u7a76\u4e3b\u8981\u5c40\u9650\u4e8e\u6587\u672c\u9886\u57df\uff0c\u5bf9\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6b3a\u9a97\u98ce\u9669\u7f3a\u4e4f\u7cfb\u7edf\u8bc4\u4f30\u548c\u76d1\u63a7\u65b9\u6cd5\u3002", "method": "1. \u6784\u5efaMM-DeceptionBench\u57fa\u51c6\uff0c\u6db5\u76d6\u516d\u7c7b\u6b3a\u9a97\u884c\u4e3a\uff0c\u8bc4\u4f30\u6a21\u578b\u901a\u8fc7\u89c6\u89c9\u548c\u6587\u672c\u6a21\u6001\u8fdb\u884c\u7b56\u7565\u6027\u64cd\u7eb5\u548c\u8bef\u5bfc\u7684\u80fd\u529b\uff1b2. \u63d0\u51fa\"\u57fa\u4e8e\u56fe\u50cf\u7684\u8fa9\u8bba\"\u591a\u667a\u80fd\u4f53\u76d1\u63a7\u6846\u67b6\uff0c\u5f3a\u5236\u6a21\u578b\u57fa\u4e8e\u89c6\u89c9\u8bc1\u636e\u8fdb\u884c\u8fa9\u8bba\uff0c\u63d0\u9ad8\u6b3a\u9a97\u7b56\u7565\u7684\u53ef\u68c0\u6d4b\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u63d0\u51fa\u7684\u76d1\u63a7\u65b9\u6cd5\u5728\u6240\u6709\u6d4b\u8bd5\u6a21\u578b\u4e0a\u663e\u8457\u63d0\u9ad8\u4e86\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u4e00\u81f4\u6027\uff0c\u5728GPT-4o\u4e0aCohen's kappa\u7cfb\u6570\u63d0\u53471.5\u500d\uff0c\u51c6\u786e\u7387\u63d0\u53471.25\u500d\uff0c\u6709\u6548\u589e\u5f3a\u4e86\u591a\u6a21\u6001\u6b3a\u9a97\u884c\u4e3a\u7684\u68c0\u6d4b\u80fd\u529b\u3002", "conclusion": "\u591a\u6a21\u6001\u6b3a\u9a97\u662f\u524d\u6cbfAI\u7cfb\u7edf\u7684\u91cd\u8981\u5b89\u5168\u98ce\u9669\uff0c\u9700\u8981\u4e13\u95e8\u7684\u8bc4\u4f30\u57fa\u51c6\u548c\u76d1\u63a7\u65b9\u6cd5\u3002MM-DeceptionBench\u548c\u57fa\u4e8e\u56fe\u50cf\u7684\u8fa9\u8bba\u6846\u67b6\u4e3a\u7cfb\u7edf\u63ed\u793a\u548c\u91cf\u5316\u8fd9\u79cd\u98ce\u9669\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u5e94\u5bf9AI\u80fd\u529b\u63d0\u5347\u5e26\u6765\u7684\u5b89\u5168\u6311\u6218\u3002"}}
{"id": "2512.00844", "categories": ["cs.SE", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.00844", "abs": "https://arxiv.org/abs/2512.00844", "authors": ["Giles Winchester", "George Parisis", "Luc Berthouze"], "title": "FC-ADL: Efficient Microservice Anomaly Detection and Localisation Through Functional Connectivity", "comment": "13 pages, 6 figures, 2 tables", "summary": "Microservices have transformed software architecture through the creation of modular and independent services. However, they introduce operational complexities in service integration and system management that makes swift and accurate anomaly detection and localisation challenging. Despite the complex, dynamic, and interconnected nature of microservice architectures, prior works that investigate metrics for anomaly detection rarely include explicit information about time-varying interdependencies. And whilst prior works on fault localisation typically do incorporate information about dependencies between microservices, they scale poorly to real world large-scale deployments due to their reliance on computationally expensive causal inference. To address these challenges we propose FC-ADL, an end-to-end scalable approach for detecting and localising anomalous changes from microservice metrics based on the neuroscientific concept of functional connectivity. We show that by efficiently characterising time-varying changes in dependencies between microservice metrics we can both detect anomalies and provide root cause candidates without incurring the significant overheads of causal and multivariate approaches. We demonstrate that our approach can achieve top detection and localisation performance across a wide degree of different fault scenarios when compared to state-of-the-art approaches. Furthermore, we illustrate the scalability of our approach by applying it to Alibaba's extremely large real-world microservice deployment.", "AI": {"tldr": "FC-ADL\uff1a\u57fa\u4e8e\u529f\u80fd\u8fde\u63a5\u6027\u7684\u5fae\u670d\u52a1\u5f02\u5e38\u68c0\u6d4b\u4e0e\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u901a\u8fc7\u9ad8\u6548\u8868\u5f81\u5fae\u670d\u52a1\u6307\u6807\u95f4\u65f6\u53d8\u4f9d\u8d56\u5173\u7cfb\uff0c\u907f\u514d\u4f20\u7edf\u56e0\u679c\u63a8\u65ad\u7684\u9ad8\u8ba1\u7b97\u5f00\u9500\uff0c\u5b9e\u73b0\u5927\u89c4\u6a21\u90e8\u7f72\u4e0b\u7684\u53ef\u6269\u5c55\u5f02\u5e38\u7ba1\u7406", "motivation": "\u5fae\u670d\u52a1\u67b6\u6784\u867d\u7136\u63d0\u4f9b\u4e86\u6a21\u5757\u5316\u548c\u72ec\u7acb\u6027\uff0c\u4f46\u5e26\u6765\u4e86\u670d\u52a1\u96c6\u6210\u548c\u7cfb\u7edf\u7ba1\u7406\u7684\u64cd\u4f5c\u590d\u6742\u6027\uff0c\u4f7f\u5f97\u5feb\u901f\u51c6\u786e\u7684\u5f02\u5e38\u68c0\u6d4b\u548c\u5b9a\u4f4d\u53d8\u5f97\u56f0\u96be\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u7f3a\u4e4f\u5bf9\u65f6\u53d8\u4f9d\u8d56\u5173\u7cfb\u7684\u663e\u5f0f\u5efa\u6a21\uff0c\u8981\u4e48\u56e0\u4f9d\u8d56\u8ba1\u7b97\u6602\u8d35\u7684\u56e0\u679c\u63a8\u65ad\u800c\u96be\u4ee5\u6269\u5c55\u5230\u5b9e\u9645\u5927\u89c4\u6a21\u90e8\u7f72", "method": "\u63d0\u51faFC-ADL\u65b9\u6cd5\uff0c\u57fa\u4e8e\u795e\u7ecf\u79d1\u5b66\u4e2d\u7684\u529f\u80fd\u8fde\u63a5\u6027\u6982\u5ff5\uff0c\u901a\u8fc7\u9ad8\u6548\u8868\u5f81\u5fae\u670d\u52a1\u6307\u6807\u95f4\u65f6\u53d8\u4f9d\u8d56\u5173\u7cfb\u7684\u53d8\u5316\u6765\u68c0\u6d4b\u5f02\u5e38\u5e76\u63d0\u4f9b\u6839\u56e0\u5019\u9009\uff0c\u907f\u514d\u4e86\u56e0\u679c\u63a8\u65ad\u548c\u591a\u53d8\u91cf\u65b9\u6cd5\u7684\u9ad8\u8ba1\u7b97\u5f00\u9500", "result": "\u5728\u591a\u79cd\u6545\u969c\u573a\u666f\u4e0b\u5b9e\u73b0\u4e86\u9876\u5c16\u7684\u68c0\u6d4b\u548c\u5b9a\u4f4d\u6027\u80fd\uff0c\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff1b\u5728\u963f\u91cc\u5df4\u5df4\u6781\u5927\u89c4\u6a21\u7684\u771f\u5b9e\u5fae\u670d\u52a1\u90e8\u7f72\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u53ef\u6269\u5c55\u6027", "conclusion": "FC-ADL\u901a\u8fc7\u529f\u80fd\u8fde\u63a5\u6027\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5fae\u670d\u52a1\u67b6\u6784\u4e2d\u5f02\u5e38\u68c0\u6d4b\u548c\u5b9a\u4f4d\u7684\u6311\u6218\uff0c\u65e2\u4fdd\u6301\u4e86\u9ad8\u6027\u80fd\u53c8\u5177\u5907\u5927\u89c4\u6a21\u90e8\u7f72\u7684\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848"}}
{"id": "2512.00406", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.00406", "abs": "https://arxiv.org/abs/2512.00406", "authors": ["Pengyu Zeng", "Yuqin Dai", "Jun Yin", "Jing Zhong", "Ziyang Han", "Chaoyang Shi", "ZhanXiang Jin", "Maowei Jiang", "Yuxing Han", "Shuai Lu"], "title": "GreenPlanner: Practical Floorplan Layout Generation via an Energy-Aware and Function-Feasible Generative Framework", "comment": "11 pages, 6 figures", "summary": "Building design directly affects human well-being and carbon emissions, yet generating spatial-functional and energy-compliant floorplans remains manual, costly, and non-scalable. Existing methods produce visually plausible layouts but frequently violate key constraints, yielding invalid results due to the absence of automated evaluation. We present GreenPlanner, an energy- and functionality-aware generative framework that unifies design evaluation and generation. It consists of a labeled Design Feasibility Dataset for learning constraint priors; a fast Practical Design Evaluator (PDE) for predicting energy performance and spatial-functional validity; a Green Plan Dataset (GreenPD) derived from PDE-guided filtering to pair user requirements with regulation-compliant layouts; and a GreenFlow generator trained on GreenPD with PDE feedback for controllable, regulation-aware generation. Experiments show that GreenPlanner accelerates evaluation by over $10^{5}\\times$ with $>$99% accuracy, eliminates invalid samples, and boosts design efficiency by 87% over professional architects.", "AI": {"tldr": "GreenPlanner\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u80fd\u6e90\u4e0e\u529f\u80fd\u611f\u77e5\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u8bc4\u4f30\u548c\u751f\u6210\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3\u5efa\u7b51\u8bbe\u8ba1\u4e2d\u7a7a\u95f4\u529f\u80fd\u4e0e\u80fd\u6e90\u5408\u89c4\u6027\u89c4\u5212\u7684\u624b\u52a8\u3001\u4f4e\u6548\u95ee\u9898\u3002", "motivation": "\u5efa\u7b51\u8bbe\u8ba1\u76f4\u63a5\u5f71\u54cd\u4eba\u7c7b\u798f\u7949\u548c\u78b3\u6392\u653e\uff0c\u4f46\u76ee\u524d\u751f\u6210\u7a7a\u95f4\u529f\u80fd\u4e0e\u80fd\u6e90\u5408\u89c4\u7684\u5e73\u9762\u56fe\u4ecd\u7136\u662f\u624b\u52a8\u3001\u6602\u8d35\u4e14\u4e0d\u53ef\u6269\u5c55\u7684\u3002\u73b0\u6709\u65b9\u6cd5\u867d\u7136\u80fd\u4ea7\u751f\u89c6\u89c9\u4e0a\u5408\u7406\u7684\u5e03\u5c40\uff0c\u4f46\u7ecf\u5e38\u8fdd\u53cd\u5173\u952e\u7ea6\u675f\uff0c\u7531\u4e8e\u7f3a\u4e4f\u81ea\u52a8\u8bc4\u4f30\u800c\u5bfc\u81f4\u65e0\u6548\u7ed3\u679c\u3002", "method": "GreenPlanner\u5305\u542b\u56db\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u7528\u4e8e\u5b66\u4e60\u7ea6\u675f\u5148\u9a8c\u7684\u6807\u8bb0\u8bbe\u8ba1\u53ef\u884c\u6027\u6570\u636e\u96c6\uff1b2) \u7528\u4e8e\u9884\u6d4b\u80fd\u6e90\u6027\u80fd\u548c\u7a7a\u95f4\u529f\u80fd\u6709\u6548\u6027\u7684\u5feb\u901f\u5b9e\u7528\u8bbe\u8ba1\u8bc4\u4f30\u5668(PDE)\uff1b3) \u901a\u8fc7PDE\u5f15\u5bfc\u8fc7\u6ee4\u5f97\u5230\u7684\u7eff\u8272\u5e73\u9762\u6570\u636e\u96c6(GreenPD)\uff0c\u5c06\u7528\u6237\u9700\u6c42\u4e0e\u6cd5\u89c4\u5408\u89c4\u5e03\u5c40\u914d\u5bf9\uff1b4) \u5728GreenPD\u4e0a\u8bad\u7ec3\u5e76\u4f7f\u7528PDE\u53cd\u9988\u7684GreenFlow\u751f\u6210\u5668\uff0c\u5b9e\u73b0\u53ef\u63a7\u3001\u6cd5\u89c4\u611f\u77e5\u7684\u751f\u6210\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cGreenPlanner\u5c06\u8bc4\u4f30\u901f\u5ea6\u63d0\u9ad8\u4e86\u8d85\u8fc710^5\u500d\uff0c\u51c6\u786e\u7387\u8d85\u8fc799%\uff0c\u6d88\u9664\u4e86\u65e0\u6548\u6837\u672c\uff0c\u5e76\u5c06\u8bbe\u8ba1\u6548\u7387\u6bd4\u4e13\u4e1a\u5efa\u7b51\u5e08\u63d0\u9ad8\u4e8687%\u3002", "conclusion": "GreenPlanner\u901a\u8fc7\u7edf\u4e00\u8bbe\u8ba1\u8bc4\u4f30\u548c\u751f\u6210\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u5408\u89c4\u7684\u5efa\u7b51\u5e73\u9762\u56fe\u81ea\u52a8\u751f\u6210\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bbe\u8ba1\u8d28\u91cf\u548c\u6548\u7387\u3002"}}
{"id": "2512.00480", "categories": ["cs.CR", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.00480", "abs": "https://arxiv.org/abs/2512.00480", "authors": ["Liang Feng Zhang"], "title": "A Unified Framework for Constructing Information-Theoretic Private Information Retrieval", "comment": "22 pages", "summary": "Retrieving up-to-date information from a publicly accessible database poses significant threats to the user's privacy. {\\em Private information retrieval} (PIR) protocols allow a user to retrieve any entry from a database, without revealing the identity of the entry being retrieved to the server(s). Such protocols have found numerous applications in both theoretical studies and real-life scenarios. The existing PIR constructions mainly give multi-server {\\em information-theoretic} PIR (IT-PIR) protocols or single-server computational PIR (CPIR) protocols. Compared with CPIR, IT-PIR protocols are computationally more efficient and secure in the presence of unbounded servers. The most classical and challenging problem in the realm of IT-PIR is constructing protocols with lower {\\em communication complexity}. In this review, we introduce a new discrete structure called {\\em families of orthogonal arrays with span capability} (FOASC) and propose a unified framework for constructing IT-PIR protocols. We show how the most influential IT-PIR protocols in the literature can be captured by the framework. We also put forward several interesting open problems concerning FOASC, whose solutions may result in innovative IT-PIR protocols.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u79bb\u6563\u7ed3\u6784FOASC\uff0c\u5e76\u5efa\u7acb\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\u6765\u6784\u5efa\u4fe1\u606f\u8bba\u79c1\u6709\u4fe1\u606f\u68c0\u7d22\u534f\u8bae\uff0c\u80fd\u591f\u6db5\u76d6\u6587\u732e\u4e2d\u6700\u6709\u5f71\u54cd\u529b\u7684IT-PIR\u534f\u8bae\uff0c\u540c\u65f6\u63d0\u51fa\u4e86\u82e5\u5e72\u5f00\u653e\u6027\u95ee\u9898\u3002", "motivation": "\u79c1\u6709\u4fe1\u606f\u68c0\u7d22\u534f\u8bae\u5728\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u65b9\u9762\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4f46\u73b0\u6709\u6784\u9020\u4e3b\u8981\u5206\u4e3a\u591a\u670d\u52a1\u5668\u4fe1\u606f\u8bbaPIR\u548c\u5355\u670d\u52a1\u5668\u8ba1\u7b97PIR\u3002\u4fe1\u606f\u8bbaPIR\u5728\u8ba1\u7b97\u6548\u7387\u548c\u5b89\u5168\u6027\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u5176\u901a\u4fe1\u590d\u6742\u5ea6\u4e00\u76f4\u662f\u8be5\u9886\u57df\u6700\u7ecf\u5178\u548c\u6700\u5177\u6311\u6218\u6027\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165\u4e00\u79cd\u65b0\u7684\u79bb\u6563\u7ed3\u6784\u2014\u2014\u5177\u6709\u8de8\u5ea6\u80fd\u529b\u7684\u6b63\u4ea4\u9635\u5217\u65cf\uff08FOASC\uff09\uff0c\u5e76\u57fa\u4e8e\u6b64\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\u6765\u6784\u9020\u4fe1\u606f\u8bba\u79c1\u6709\u4fe1\u606f\u68c0\u7d22\u534f\u8bae\u3002\u8be5\u6846\u67b6\u80fd\u591f\u6db5\u76d6\u6587\u732e\u4e2d\u6700\u6709\u5f71\u54cd\u529b\u7684IT-PIR\u534f\u8bae\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684IT-PIR\u534f\u8bae\u6784\u9020\u6846\u67b6\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u5c06\u6587\u732e\u4e2d\u6700\u6709\u5f71\u54cd\u529b\u7684IT-PIR\u534f\u8bae\u7eb3\u5165\u8be5\u6846\u67b6\u3002\u540c\u65f6\u63d0\u51fa\u4e86\u5173\u4e8eFOASC\u7684\u82e5\u5e72\u6709\u8da3\u5f00\u653e\u6027\u95ee\u9898\u3002", "conclusion": "FOASC\u4e3aIT-PIR\u534f\u8bae\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6784\u9020\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u8be5\u9886\u57df\u7684\u6838\u5fc3\u901a\u4fe1\u590d\u6742\u5ea6\u95ee\u9898\u3002\u63d0\u51fa\u7684\u5f00\u653e\u6027\u95ee\u9898\u53ef\u80fd\u50ac\u751f\u521b\u65b0\u7684IT-PIR\u534f\u8bae\u3002"}}
{"id": "2512.00855", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.00855", "abs": "https://arxiv.org/abs/2512.00855", "authors": ["Miikka Kuutila", "Paul Ralph", "Huilian Sophie Qiu", "Ronnie de Souza Santos", "Morakot Choetkiertikul", "Amin Milani Fard", "Rana Alkadhi", "Xavier Devroey", "Gregorio Robles", "Hideaki Hata", "Sebastian Baltes", "Vladimir Kovalenko", "Shalini Chakraborty", "Eray Tuzun", "Hera Arif", "Gianisa Adisaputri", "Kelly Garc\u00e9s", "Anielle S. L. Andrade", "Eyram Amedzor", "Bimpe Ayoola", "Keisha Gaspard-Chickoree", "Arazoo Hoseyni"], "title": "The Software Infrastructure Attitude Scale (SIAS): A Questionnaire Instrument for Measuring Professionals' Attitudes Toward Technical and Sociotechnical Infrastructure", "comment": "Accepted to ICSE 2026, 11 pages + 2 for references, 1 figure, 7 tables", "summary": "Context: Recent software engineering (SE) research has highlighted the need for sociotechnical research, implying a demand for customized psychometric scales. Objective: We define the concepts of technical and sociotechnical infrastructure in software engineering, and develop and validate a psychometric scale that measures attitudes toward them. Method: Grounded in theories of infrastructure, attitudes, and prior work on psychometric measurement, we defined the target constructs and generated scale items. The scale was administered to 225 software professionals and evaluated using a split sample. We conducted an exploratory factor analysis (EFA) on one half of the sample to uncover the underlying factor structure and performed a confirmatory factor analysis (CFA) on the other half to validate the structure. Further analyses with the whole sample assessed face, criterion-related, and discriminant validity. Results: EFA supported a two-factor structure (technical and sociotechnical infrastructure), accounting for 65% of the total variance with strong loadings. CFA confirmed excellent model fit. Face and content validity were supported by the item content reflecting cognitive, affective, and behavioral components. Both subscales were correlated with job satisfaction, perceived autonomy, and feedback from the job itself, supporting convergent validity. Regression analysis supported criterion-related validity, while the Heterotrait-Monotrait ratio of correlations (HTMT), the Fornell-Larcker criterion, and model comparison all supported discriminant validity. Discussion: The resulting scale is a valid instrument for measuring attitudes toward technical and sociotechnical infrastructure in software engineering research. Our work contributes to ongoing efforts to integrate psychological measurement rigor into empirical and behavioral software engineering research.", "AI": {"tldr": "\u5f00\u53d1\u5e76\u9a8c\u8bc1\u4e86\u6d4b\u91cf\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u6280\u672f\u548c\u793e\u4f1a\u6280\u672f\u57fa\u7840\u8bbe\u65bd\u6001\u5ea6\u7684\u5fc3\u7406\u6d4b\u91cf\u91cf\u8868\uff0c\u5305\u542b\u4e24\u4e2a\u56e0\u5b50\u7ed3\u6784\uff0c\u5177\u6709\u826f\u597d\u7684\u4fe1\u6548\u5ea6\u3002", "motivation": "\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u9700\u8981\u793e\u4f1a\u6280\u672f\u7814\u7a76\uff0c\u56e0\u6b64\u9700\u8981\u5b9a\u5236\u5316\u7684\u5fc3\u7406\u6d4b\u91cf\u91cf\u8868\u6765\u6d4b\u91cf\u5bf9\u6280\u672f\u548c\u793e\u4f1a\u6280\u672f\u57fa\u7840\u8bbe\u65bd\u7684\u6001\u5ea6\u3002", "method": "\u57fa\u4e8e\u57fa\u7840\u8bbe\u65bd\u7406\u8bba\u3001\u6001\u5ea6\u7406\u8bba\u548c\u5fc3\u7406\u6d4b\u91cf\u7814\u7a76\uff0c\u5b9a\u4e49\u76ee\u6807\u6784\u5ff5\u5e76\u751f\u6210\u91cf\u8868\u9879\u76ee\u3002\u5bf9225\u540d\u8f6f\u4ef6\u4e13\u4e1a\u4eba\u5458\u65bd\u6d4b\uff0c\u4f7f\u7528\u5206\u534a\u6837\u672c\u8fdb\u884c\u63a2\u7d22\u6027\u56e0\u5b50\u5206\u6790\u548c\u9a8c\u8bc1\u6027\u56e0\u5b50\u5206\u6790\uff0c\u8bc4\u4f30\u8868\u9762\u6548\u5ea6\u3001\u6807\u51c6\u5173\u8054\u6548\u5ea6\u548c\u533a\u5206\u6548\u5ea6\u3002", "result": "\u63a2\u7d22\u6027\u56e0\u5b50\u5206\u6790\u652f\u6301\u53cc\u56e0\u5b50\u7ed3\u6784\uff08\u6280\u672f\u548c\u793e\u4f1a\u6280\u672f\u57fa\u7840\u8bbe\u65bd\uff09\uff0c\u89e3\u91ca65%\u603b\u65b9\u5dee\uff1b\u9a8c\u8bc1\u6027\u56e0\u5b50\u5206\u6790\u786e\u8ba4\u6a21\u578b\u62df\u5408\u4f18\u5ea6\u826f\u597d\uff1b\u91cf\u8868\u5177\u6709\u826f\u597d\u7684\u8868\u9762\u6548\u5ea6\u3001\u5185\u5bb9\u6548\u5ea6\u3001\u6536\u655b\u6548\u5ea6\u3001\u6807\u51c6\u5173\u8054\u6548\u5ea6\u548c\u533a\u5206\u6548\u5ea6\u3002", "conclusion": "\u5f00\u53d1\u7684\u91cf\u8868\u662f\u6d4b\u91cf\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u6280\u672f\u548c\u793e\u4f1a\u6280\u672f\u57fa\u7840\u8bbe\u65bd\u6001\u5ea6\u7684\u6709\u6548\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u5c06\u5fc3\u7406\u6d4b\u91cf\u4e25\u8c28\u6027\u6574\u5408\u5230\u5b9e\u8bc1\u548c\u884c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u4e2d\u3002"}}
{"id": "2512.00479", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00479", "abs": "https://arxiv.org/abs/2512.00479", "authors": ["Yuta Kobayashi", "Vincent Jeanselme", "Shalmali Joshi"], "title": "Mind the data gap: Missingness Still Shapes Large Language Model Prognoses", "comment": "Presented at ML4H 2025 - Findings Track", "summary": "Data collection often reflects human decisions. In healthcare, for instance, a referral for a diagnostic test is influenced by the patient's health, their preferences, available resources, and the practitioner's recommendations. Despite the extensive literature on the informativeness of missingness, its implications on the performance of Large Language Models (LLMs) have not been studied. Through a series of experiments on data from Columbia University Medical Center, a large urban academic medical center, and MIMIC-IV, we demonstrate that patterns of missingness significantly impact zero-shot predictive performance. Notably, the explicit inclusion of missingness indicators at prompting benefits some while hurting other LLMs' zero-shot predictive performance and calibration, suggesting an inconsistent impact. The proposed aggregated analysis and theoretical insights suggest that larger models benefit from these interventions, while smaller models can be negatively impacted. The LLM paradigm risks obscuring the impact of missingness, often neglected even in conventional ML, even further. We conclude that there is a need for more transparent accounting and systematic evaluation of the impact of representing (informative) missingness on downstream performance.", "AI": {"tldr": "LLM\u5728\u533b\u7597\u9884\u6d4b\u4efb\u52a1\u4e2d\u53d7\u6570\u636e\u7f3a\u5931\u6a21\u5f0f\u663e\u8457\u5f71\u54cd\uff0c\u7f3a\u5931\u6307\u793a\u7b26\u7684\u52a0\u5165\u5bf9\u4e0d\u540c\u6a21\u578b\u6548\u679c\u4e0d\u4e00\u81f4\uff0c\u5927\u6a21\u578b\u53d7\u76ca\u800c\u5c0f\u6a21\u578b\u53ef\u80fd\u53d7\u635f", "motivation": "\u7814\u7a76\u7f3a\u5931\u6570\u636e\u6a21\u5f0f\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5728\u533b\u7597\u9886\u57df\uff0c\u6570\u636e\u6536\u96c6\u5f80\u5f80\u53cd\u6620\u4eba\u7c7b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u800c\u73b0\u6709\u6587\u732e\u5c1a\u672a\u7cfb\u7edf\u7814\u7a76\u7f3a\u5931\u6570\u636e\u5bf9LLM\u9884\u6d4b\u6027\u80fd\u7684\u5f71\u54cd", "method": "\u4f7f\u7528\u54e5\u4f26\u6bd4\u4e9a\u5927\u5b66\u533b\u5b66\u4e2d\u5fc3\u548cMIMIC-IV\u6570\u636e\u96c6\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5206\u6790\u7f3a\u5931\u6a21\u5f0f\u5bf9\u96f6\u6837\u672c\u9884\u6d4b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u7279\u522b\u6d4b\u8bd5\u4e86\u5728\u63d0\u793a\u4e2d\u663e\u5f0f\u5305\u542b\u7f3a\u5931\u6307\u793a\u7b26\u7684\u6548\u679c", "result": "\u7f3a\u5931\u6a21\u5f0f\u663e\u8457\u5f71\u54cdLLM\u7684\u96f6\u6837\u672c\u9884\u6d4b\u6027\u80fd\uff1b\u663e\u5f0f\u5305\u542b\u7f3a\u5931\u6307\u793a\u7b26\u5bf9\u67d0\u4e9bLLM\u6709\u76ca\uff0c\u4f46\u5bf9\u5176\u4ed6\u6a21\u578b\u6709\u5bb3\uff0c\u5f71\u54cd\u4e0d\u4e00\u81f4\uff1b\u5927\u6a21\u578b\u4ece\u8fd9\u79cd\u5e72\u9884\u4e2d\u53d7\u76ca\uff0c\u800c\u5c0f\u6a21\u578b\u53ef\u80fd\u53d7\u5230\u8d1f\u9762\u5f71\u54cd", "conclusion": "\u9700\u8981\u66f4\u900f\u660e\u7684\u8bc4\u4f30\u548c\u7cfb\u7edf\u5316\u7814\u7a76\u7f3a\u5931\u6570\u636e\u8868\u793a\u5bf9\u4e0b\u6e38\u6027\u80fd\u7684\u5f71\u54cd\uff0cLLM\u8303\u5f0f\u53ef\u80fd\u8fdb\u4e00\u6b65\u63a9\u76d6\u7f3a\u5931\u6570\u636e\u7684\u5f71\u54cd\uff0c\u8fd9\u4e00\u95ee\u9898\u5728\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u4e2d\u4e5f\u5e38\u88ab\u5ffd\u89c6"}}
{"id": "2512.00601", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00601", "abs": "https://arxiv.org/abs/2512.00601", "authors": ["Boyang Gu", "Hongjian Zhou", "Bradley Max Segal", "Jinge Wu", "Zeyu Cao", "Hantao Zhong", "Lei Clifton", "Fenglin Liu", "David A. Clifton"], "title": "Clinical-R1: Empowering Large Language Models for Faithful and Comprehensive Reasoning with Clinical Objective Relative Policy Optimization", "comment": null, "summary": "Recent advances in large language models (LLMs) have shown strong reasoning capabilities through large-scale pretraining and post-training reinforcement learning, demonstrated by DeepSeek-R1. However, current post-training methods, such as Grouped Relative Policy Optimization (GRPO), mainly reward correctness, which is not aligned with the multi-dimensional objectives required in high-stakes fields such as medicine, where reasoning must also be faithful and comprehensive. We introduce Clinical-Objective Relative Policy Optimization (CRPO), a scalable, multi-objective, verifiable reinforcement learning method designed to align LLM post-training with clinical reasoning principles. CRPO integrates rule-based and verifiable reward signals that jointly optimize accuracy, faithfulness, and comprehensiveness without relying on human annotation. To demonstrate its effectiveness, we train Clinical-R1-3B, a 3B-parameter model for clinical reasoning. The experiments on three benchmarks demonstrate that our CRPO substantially improves reasoning on truthfulness and completeness over standard GRPO while maintaining comfortable accuracy enhancements. This framework provides a scalable pathway to align LLM reasoning with clinical objectives, enabling safer and more collaborative AI systems for healthcare while also highlighting the potential of multi-objective, verifiable RL methods in post-training scaling of LLMs for medical domains.", "AI": {"tldr": "CRPO\u662f\u4e00\u79cd\u7528\u4e8e\u4e34\u5e8a\u63a8\u7406\u7684\u591a\u76ee\u6807\u53ef\u9a8c\u8bc1\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u57fa\u4e8e\u89c4\u5219\u548c\u53ef\u9a8c\u8bc1\u7684\u5956\u52b1\u4fe1\u53f7\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u63d0\u5347\u771f\u5b9e\u6027\u548c\u5b8c\u6574\u6027\u3002", "motivation": "\u5f53\u524d\u7684\u540e\u8bad\u7ec3\u65b9\u6cd5\uff08\u5982GRPO\uff09\u4e3b\u8981\u5956\u52b1\u6b63\u786e\u6027\uff0c\u8fd9\u4e0e\u533b\u5b66\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u9700\u8981\u591a\u7ef4\u5ea6\u76ee\u6807\uff08\u5305\u62ec\u771f\u5b9e\u6027\u548c\u5168\u9762\u6027\uff09\u7684\u8981\u6c42\u4e0d\u4e00\u81f4\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5c06LLM\u540e\u8bad\u7ec3\u4e0e\u4e34\u5e8a\u63a8\u7406\u539f\u5219\u5bf9\u9f50\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e34\u5e8a\u76ee\u6807\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08CRPO\uff09\uff0c\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u591a\u76ee\u6807\u3001\u53ef\u9a8c\u8bc1\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u6574\u5408\u57fa\u4e8e\u89c4\u5219\u548c\u53ef\u9a8c\u8bc1\u7684\u5956\u52b1\u4fe1\u53f7\uff0c\u5171\u540c\u4f18\u5316\u51c6\u786e\u6027\u3001\u771f\u5b9e\u6027\u548c\u5168\u9762\u6027\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u3002", "result": "\u8bad\u7ec3\u4e86Clinical-R1-3B\uff0830\u4ebf\u53c2\u6570\u6a21\u578b\uff09\uff0c\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCRPO\u76f8\u6bd4\u6807\u51c6GRPO\u5728\u771f\u5b9e\u6027\u548c\u5b8c\u6574\u6027\u65b9\u9762\u663e\u8457\u6539\u5584\u63a8\u7406\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u89c2\u7684\u51c6\u786e\u6027\u63d0\u5347\u3002", "conclusion": "CRPO\u4e3a\u5c06LLM\u63a8\u7406\u4e0e\u4e34\u5e8a\u76ee\u6807\u5bf9\u9f50\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u9014\u5f84\uff0c\u4f7f\u533b\u7597AI\u7cfb\u7edf\u66f4\u5b89\u5168\u3001\u66f4\u5177\u534f\u4f5c\u6027\uff0c\u540c\u65f6\u7a81\u663e\u4e86\u591a\u76ee\u6807\u53ef\u9a8c\u8bc1RL\u65b9\u6cd5\u5728\u533b\u5b66\u9886\u57dfLLM\u540e\u8bad\u7ec3\u6269\u5c55\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2512.00635", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.00635", "abs": "https://arxiv.org/abs/2512.00635", "authors": ["Archisman Ghosh"], "title": "Extended Abstract: Synthesizable Low-overhead Circuit-level Countermeasures and Pro-Active Detection Techniques for Power and EM SCA", "comment": "This extended abstract is archived for educational purposes as an example for different PhD forum competitions. Total page is 3", "summary": "The gamut of todays internet-connected embedded devices has led to increased concerns regarding the security and confidentiality of data. Most internet-connected embedded devices employ mathematically secure cryptographic algorithms to address security vulnerabilities. Despite such mathematical guarantees, as these algorithms are often implemented in silicon, they leak critical information in terms of power consumption, electromagnetic (EM) radiation, timing, cache hits and misses, photonic emission and so on, leading to side-channel analysis (SCA) attacks. This thesis focuses on low overhead generic circuit-level yet synthesizable countermeasures against power and EM SCA. Existing countermeasures (including proposed) still have relatively high overhead which bars them from being used in energy-constraint IoT devices. We propose a zero-overhead integrated inductive sensor which is able to detect i)EM SCA ii) Clock glitch-based Fault Injection Attack (FIA), and iii) Voltage-glitch based Fault Injection Attack by using a simple ML algorithm. Advent of quantum computer research will open new possibilities for theoretical attacks against existing cryptographic protocols. National Institute of Standard & Technology (NIST) has standardized post-quantum cryptographic algorithms to secure crypto-systems against quantum adversary. I contribute to the standardization procedure by introducing the first silicon-verified Saber (a NIST finalist modulo Learning with Rounding scheme) which consumes lowest energy and area till date amongst all the candidates.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u9488\u5bf9\u7269\u8054\u7f51\u8bbe\u5907\u4fa7\u4fe1\u9053\u653b\u51fb\u7684\u96f6\u5f00\u9500\u9632\u62a4\u65b9\u6848\uff0c\u5305\u62ec\u96c6\u6210\u7535\u611f\u4f20\u611f\u5668\u68c0\u6d4b\u7535\u78c1\u4fa7\u4fe1\u9053\u653b\u51fb\u548c\u6545\u969c\u6ce8\u5165\u653b\u51fb\uff0c\u5e76\u8d21\u732e\u4e86\u9996\u4e2a\u7845\u9a8c\u8bc1\u7684Saber\u540e\u91cf\u5b50\u5bc6\u7801\u7b97\u6cd5\u5b9e\u73b0\u3002", "motivation": "\u7269\u8054\u7f51\u8bbe\u5907\u867d\u7136\u91c7\u7528\u6570\u5b66\u5b89\u5168\u7684\u52a0\u5bc6\u7b97\u6cd5\uff0c\u4f46\u786c\u4ef6\u5b9e\u73b0\u4f1a\u901a\u8fc7\u529f\u8017\u3001\u7535\u78c1\u8f90\u5c04\u7b49\u4fa7\u4fe1\u9053\u6cc4\u9732\u4fe1\u606f\uff0c\u73b0\u6709\u9632\u62a4\u65b9\u6848\u5f00\u9500\u8fc7\u9ad8\uff0c\u4e0d\u9002\u5408\u80fd\u6e90\u53d7\u9650\u7684\u7269\u8054\u7f51\u8bbe\u5907\u3002\u540c\u65f6\u91cf\u5b50\u8ba1\u7b97\u673a\u7684\u53d1\u5c55\u5a01\u80c1\u73b0\u6709\u52a0\u5bc6\u534f\u8bae\uff0c\u9700\u8981\u540e\u91cf\u5b50\u5bc6\u7801\u7b97\u6cd5\u3002", "method": "\u63d0\u51fa\u96f6\u5f00\u9500\u96c6\u6210\u7535\u611f\u4f20\u611f\u5668\uff0c\u4f7f\u7528\u7b80\u5355\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u68c0\u6d4b\u7535\u78c1\u4fa7\u4fe1\u9053\u653b\u51fb\u3001\u65f6\u949f\u6bdb\u523a\u6545\u969c\u6ce8\u5165\u653b\u51fb\u548c\u7535\u538b\u6bdb\u523a\u6545\u969c\u6ce8\u5165\u653b\u51fb\u3002\u540c\u65f6\u5b9e\u73b0\u5e76\u7845\u9a8c\u8bc1\u4e86NIST\u540e\u91cf\u5b50\u5bc6\u7801\u6807\u51c6\u5019\u9009\u7b97\u6cd5Saber\uff08\u57fa\u4e8e\u6a21\u53d6\u6574\u5b66\u4e60\u65b9\u6848\uff09\u3002", "result": "\u96c6\u6210\u7535\u611f\u4f20\u611f\u5668\u80fd\u6709\u6548\u68c0\u6d4b\u4e09\u79cd\u653b\u51fb\u7c7b\u578b\u3002Saber\u5b9e\u73b0\u8fbe\u5230\u4e86\u8fc4\u4eca\u4e3a\u6b62\u6240\u6709\u5019\u9009\u7b97\u6cd5\u4e2d\u6700\u4f4e\u7684\u80fd\u8017\u548c\u9762\u79ef\uff0c\u5e76\u6210\u4e3a\u9996\u4e2a\u7845\u9a8c\u8bc1\u7684Saber\u5b9e\u73b0\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7269\u8054\u7f51\u8bbe\u5907\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u4f4e\u5f00\u9500\u4fa7\u4fe1\u9053\u653b\u51fb\u9632\u62a4\u65b9\u6848\uff0c\u5e76\u4e3a\u540e\u91cf\u5b50\u5bc6\u7801\u6807\u51c6\u5316\u8fdb\u7a0b\u505a\u51fa\u4e86\u5b9e\u8d28\u6027\u8d21\u732e\uff0c\u63a8\u52a8\u4e86\u5b89\u5168\u786c\u4ef6\u8bbe\u8ba1\u7684\u53d1\u5c55\u3002"}}
{"id": "2512.00670", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00670", "abs": "https://arxiv.org/abs/2512.00670", "authors": ["He-Yen Hsieh", "Hong Wang", "H. T. Kung"], "title": "EDIT: Early Diffusion Inference Termination for dLLMs Based on Dynamics of Training Gradients", "comment": "22 pages, 11 figures", "summary": "Diffusion-based large language models (dLLMs) refine token generations through iterative denoising, but answers often stabilize before all steps complete. We propose EDIT (Early Diffusion Inference Termination), an inference-time criterion that adaptively stops denoising once sufficient reasoning stability relative to training-time reasoning is detected. EDIT monitors the alignment between token activations and a reasoning map derived from AdamW-aggregated LoRA updates captured during supervised fine-tuning (SFT). During training, optimization dynamics generate rich metadata about parameter importance that in prior methods is typically discarded upon model release. We preserve this information as a compact representation of learned reasoning pathways. During inference, alignment scores are converted to a distribution over the tokens already unmasked at the current denoising step, and convergence is detected when KL divergence between consecutive steps falls below a threshold on the matched unmasked (visible) tokens. Across reasoning benchmarks, EDIT reduces diffusion steps by 11.8% to 68.3% while preserving or improving accuracy in most settings, with approximately 0.02% storage overhead (about 1.5-2 MB for all QKV modules across 32 blocks in an 8 GB model). By utilizing training-gradient dynamics, our work opens a new research direction for reducing dLLM inference time and cost.", "AI": {"tldr": "EDIT\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bad\u7ec3\u68af\u5ea6\u52a8\u6001\u7684\u65e9\u671f\u6269\u6563\u63a8\u7406\u7ec8\u6b62\u65b9\u6cd5\uff0c\u901a\u8fc7\u76d1\u6d4btoken\u6fc0\u6d3b\u4e0e\u63a8\u7406\u56fe\u7684\u5339\u914d\u5ea6\u6765\u81ea\u9002\u5e94\u505c\u6b62\u53bb\u566a\u8fc7\u7a0b\uff0c\u663e\u8457\u51cf\u5c11\u63a8\u7406\u6b65\u9aa4\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u5347\u51c6\u786e\u6027\u3002", "motivation": "\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u8fed\u4ee3\u53bb\u566a\u751f\u6210token\uff0c\u4f46\u7b54\u6848\u901a\u5e38\u5728\u5b8c\u6210\u6240\u6709\u6b65\u9aa4\u524d\u5c31\u5df2\u7a33\u5b9a\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u6a21\u578b\u53d1\u5e03\u65f6\u4e22\u5f03\u4e86\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u4f18\u5316\u52a8\u6001\u4fe1\u606f\uff0c\u800c\u8fd9\u4e9b\u4fe1\u606f\u5305\u542b\u4e86\u53c2\u6570\u91cd\u8981\u6027\u7684\u4e30\u5bcc\u5143\u6570\u636e\u3002", "method": "EDIT\u5728\u76d1\u7763\u5fae\u8c03\u671f\u95f4\u6355\u83b7AdamW\u805a\u5408\u7684LoRA\u66f4\u65b0\uff0c\u6784\u5efa\u63a8\u7406\u56fe\u4f5c\u4e3a\u5b66\u4e60\u63a8\u7406\u8def\u5f84\u7684\u7d27\u51d1\u8868\u793a\u3002\u63a8\u7406\u65f6\u76d1\u6d4btoken\u6fc0\u6d3b\u4e0e\u63a8\u7406\u56fe\u7684\u5339\u914d\u5ea6\uff0c\u5c06\u5339\u914d\u5206\u6570\u8f6c\u6362\u4e3a\u5df2\u53bb\u566atoken\u7684\u5206\u5e03\uff0c\u5f53\u8fde\u7eed\u6b65\u9aa4\u95f4KL\u6563\u5ea6\u4f4e\u4e8e\u9608\u503c\u65f6\u68c0\u6d4b\u6536\u655b\u3002", "result": "\u5728\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cEDIT\u5c06\u6269\u6563\u6b65\u9aa4\u51cf\u5c11\u4e8611.8%\u523068.3%\uff0c\u5728\u5927\u591a\u6570\u8bbe\u7f6e\u4e2d\u4fdd\u6301\u6216\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\uff0c\u5b58\u50a8\u5f00\u9500\u4ec5\u7ea60.02%\uff08\u7ea61.5-2MB\uff09\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528\u8bad\u7ec3\u68af\u5ea6\u52a8\u6001\uff0cEDIT\u4e3a\u51cf\u5c11\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u65f6\u95f4\u548c\u6210\u672c\u5f00\u8f9f\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u65e9\u671f\u63a8\u7406\u7ec8\u6b62\u3002"}}
{"id": "2512.00645", "categories": ["cs.CR", "cs.DB"], "pdf": "https://arxiv.org/pdf/2512.00645", "abs": "https://arxiv.org/abs/2512.00645", "authors": ["Boyd Franken", "Hong-Hanh Nguyen-Le", "Nhien-An Le-Khac"], "title": "Blockchain-based vs. SQL Database Systems for Digital Twin Evidence Management: A Comparative Forensic Analysis", "comment": "Accepted at EAI International Conference on Digital Forensics & Cyber Crime 2025", "summary": "Digital forensics faces unprecedented challenges with the emergence of digital twins and metaverse technologies. This paper presents the first comparative analysis between blockchain-based and traditional database systems for managing digital twin evidence in forensic investigations. We conducted controlled experiments comparing the Ethereum blockchain with IPFS storage against traditional SQL databases for digital twin evidence management. Our findings reveal that while blockchain provides superior data integrity and immutability, crucial for forensic applications, traditional databases offer better performance consistency. The blockchain implementation showed faster average storage times but higher variability in retrieval operations. Both systems maintained forensic integrity through hash verification, though blockchain's immutable nature provides additional security guarantees essential for legal proceedings. This research contributes to the development of robust digital forensic methodologies for emerging technologies in the metaverse era.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u6bd4\u8f83\u4e86\u533a\u5757\u94fe\u4e0e\u4f20\u7edf\u6570\u636e\u5e93\u5728\u6570\u5b57\u5b6a\u751f\u8bc1\u636e\u7ba1\u7406\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u533a\u5757\u94fe\u5728\u6570\u636e\u5b8c\u6574\u6027\u548c\u4e0d\u53ef\u7be1\u6539\u6027\u65b9\u9762\u66f4\u4f18\uff0c\u800c\u4f20\u7edf\u6570\u636e\u5e93\u5728\u6027\u80fd\u4e00\u81f4\u6027\u65b9\u9762\u66f4\u597d\u3002", "motivation": "\u968f\u7740\u6570\u5b57\u5b6a\u751f\u548c\u5143\u5b87\u5b99\u6280\u672f\u7684\u51fa\u73b0\uff0c\u6570\u5b57\u53d6\u8bc1\u9762\u4e34\u524d\u6240\u672a\u6709\u7684\u6311\u6218\u3002\u9700\u8981\u7814\u7a76\u5982\u4f55\u6709\u6548\u7ba1\u7406\u6570\u5b57\u5b6a\u751f\u8bc1\u636e\uff0c\u4e3a\u65b0\u5174\u6280\u672f\u5f00\u53d1\u7a33\u5065\u7684\u6570\u5b57\u53d6\u8bc1\u65b9\u6cd5\u3002", "method": "\u8fdb\u884c\u4e86\u53d7\u63a7\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u4ee5\u592a\u574a\u533a\u5757\u94fe\u4e0eIPFS\u5b58\u50a8\u7cfb\u7edf\u4e0e\u4f20\u7edfSQL\u6570\u636e\u5e93\u5728\u6570\u5b57\u5b6a\u751f\u8bc1\u636e\u7ba1\u7406\u65b9\u9762\u7684\u6027\u80fd\u3002\u901a\u8fc7\u54c8\u5e0c\u9a8c\u8bc1\u786e\u4fdd\u53d6\u8bc1\u5b8c\u6574\u6027\u3002", "result": "\u533a\u5757\u94fe\u5728\u6570\u636e\u5b8c\u6574\u6027\u548c\u4e0d\u53ef\u7be1\u6539\u6027\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u5bf9\u6cd5\u5f8b\u7a0b\u5e8f\u81f3\u5173\u91cd\u8981\uff1b\u4f20\u7edf\u6570\u636e\u5e93\u5728\u6027\u80fd\u4e00\u81f4\u6027\u65b9\u9762\u66f4\u597d\u3002\u533a\u5757\u94fe\u5b58\u50a8\u65f6\u95f4\u66f4\u5feb\u4f46\u68c0\u7d22\u64cd\u4f5c\u53d8\u5f02\u6027\u66f4\u9ad8\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u4e3a\u5143\u5b87\u5b99\u65f6\u4ee3\u65b0\u5174\u6280\u672f\u7684\u6570\u5b57\u53d6\u8bc1\u65b9\u6cd5\u5b66\u53d1\u5c55\u505a\u51fa\u4e86\u8d21\u732e\uff0c\u8868\u660e\u533a\u5757\u94fe\u7684\u4e0d\u53ef\u7be1\u6539\u7279\u6027\u4e3a\u6cd5\u5f8b\u7a0b\u5e8f\u63d0\u4f9b\u4e86\u989d\u5916\u7684\u5b89\u5168\u4fdd\u969c\u3002"}}
{"id": "2512.01141", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.01141", "abs": "https://arxiv.org/abs/2512.01141", "authors": ["Muhammad Yousuf", "Akshat Bagade", "Chhittebbayi Penugonda", "Maanas Baraya"], "title": "Neural Variable Name Repair: Learning to Rename Identifiers for Readability", "comment": null, "summary": "Developers routinely work with source files whose variable names are generic or misleading, and with teams moving quickly, many functions are left undocumented. This slows comprehension, increases the risk of subtle bugs, and makes it harder for both humans and large language models (LLMs) to reason about code. We study variable name repair: given a real C++ function where all occurrences of one local or parameter name have been replaced by a placeholder (e.g. ID 1), the goal is to generate a natural, descriptive replacement name. We automatically construct this task from the C++ portion of BigCode's The Stack by parsing functions with Tree-sitter, masking a single identifier, and treating the original name as supervision. On top of Llama 3.1-8B, we build a pipeline with (i) warmup and dropout schedules for more stable fine-tuning, (ii) LoRA adapters for efficient specialization on identifier repair, and (iii) a dual-encoder reranker over top-k generator candidates. We evaluate using exact match, Top-5 Hit, and an embedding-based partial similarity score (0-100) that gives credit for near synonyms and format variants (e.g., jsonValue vs. json). On a held-out set of 200 C++ functions, a zero-shot Llama 3.1 baseline reaches 6.1 percent exact match. Our best LoRA-tuned model (with warmup and dropout) achieves 43.1 percent exact match, 50.2 percent Top-5 Hit, and an 82.03 partial-match score. A dual encoder reranker further improves selection quality without modifying the underlying generator, suggesting that task-specific fine-tuning plus reranking is a promising approach for practical identifier repair tools.", "AI": {"tldr": "\u7814\u7a76\u53d8\u91cf\u540d\u4fee\u590d\u4efb\u52a1\uff1a\u5f53C++\u51fd\u6570\u4e2d\u67d0\u4e2a\u53d8\u91cf\u540d\u88ab\u5360\u4f4d\u7b26\u66ff\u6362\u65f6\uff0c\u81ea\u52a8\u751f\u6210\u81ea\u7136\u3001\u63cf\u8ff0\u6027\u7684\u53d8\u91cf\u540d\u3002\u57fa\u4e8eLlama 3.1-8B\u6784\u5efa\u5305\u542b\u5fae\u8c03\u4f18\u5316\u3001LoRA\u9002\u914d\u5668\u548c\u91cd\u6392\u5e8f\u5668\u7684pipeline\uff0c\u5728\u771f\u5b9eC++\u4ee3\u7801\u4e0a\u663e\u8457\u63d0\u5347\u53d8\u91cf\u540d\u4fee\u590d\u6548\u679c\u3002", "motivation": "\u5f00\u53d1\u8005\u7ecf\u5e38\u9047\u5230\u53d8\u91cf\u540d\u8fc7\u4e8e\u901a\u7528\u6216\u8bef\u5bfc\u6027\u7684\u6e90\u4ee3\u7801\uff0c\u8bb8\u591a\u51fd\u6570\u7f3a\u4e4f\u6587\u6863\uff0c\u8fd9\u964d\u4f4e\u4e86\u4ee3\u7801\u7406\u89e3\u6548\u7387\uff0c\u589e\u52a0\u4e86bug\u98ce\u9669\uff0c\u4e5f\u5f71\u54cd\u4e86\u4eba\u7c7b\u548cLLM\u5bf9\u4ee3\u7801\u7684\u63a8\u7406\u80fd\u529b\u3002\u9700\u8981\u81ea\u52a8\u4fee\u590d\u53d8\u91cf\u540d\u6765\u6539\u5584\u4ee3\u7801\u53ef\u8bfb\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u3002", "method": "\u4eceBigCode\u7684The Stack\u6570\u636e\u96c6\u4e2d\u81ea\u52a8\u6784\u5efa\u4efb\u52a1\uff1a\u4f7f\u7528Tree-sitter\u89e3\u6790C++\u51fd\u6570\uff0c\u63a9\u7801\u5355\u4e2a\u6807\u8bc6\u7b26\uff0c\u5c06\u539f\u59cb\u540d\u79f0\u4f5c\u4e3a\u76d1\u7763\u4fe1\u53f7\u3002\u57fa\u4e8eLlama 3.1-8B\u6784\u5efapipeline\uff1a1\uff09\u4f7f\u7528\u9884\u70ed\u548cdropout\u8c03\u5ea6\u5b9e\u73b0\u66f4\u7a33\u5b9a\u7684\u5fae\u8c03\uff1b2\uff09LoRA\u9002\u914d\u5668\u9ad8\u6548\u4e13\u95e8\u5316\u6807\u8bc6\u7b26\u4fee\u590d\uff1b3\uff09\u53cc\u7f16\u7801\u5668\u91cd\u6392\u5e8f\u5668\u5bf9top-k\u5019\u9009\u8fdb\u884c\u91cd\u6392\u5e8f\u3002", "result": "\u5728200\u4e2aC++\u51fd\u6570\u7684\u6d4b\u8bd5\u96c6\u4e0a\uff1a\u96f6\u6837\u672cLlama 3.1\u57fa\u7ebf\u8fbe\u52306.1%\u7cbe\u786e\u5339\u914d\u3002\u6700\u4f73LoRA\u5fae\u8c03\u6a21\u578b\uff08\u5e26\u9884\u70ed\u548cdropout\uff09\u8fbe\u523043.1%\u7cbe\u786e\u5339\u914d\u300150.2% Top-5\u547d\u4e2d\u7387\u548c82.03\u90e8\u5206\u5339\u914d\u5206\u6570\u3002\u53cc\u7f16\u7801\u5668\u91cd\u6392\u5e8f\u5668\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u9009\u62e9\u8d28\u91cf\u3002", "conclusion": "\u4efb\u52a1\u7279\u5b9a\u7684\u5fae\u8c03\u52a0\u4e0a\u91cd\u6392\u5e8f\u662f\u5b9e\u7528\u6807\u8bc6\u7b26\u4fee\u590d\u5de5\u5177\u7684\u6709\u524d\u666f\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u53d8\u91cf\u540d\u4fee\u590d\u7684\u51c6\u786e\u6027\uff0c\u4e3a\u6539\u5584\u4ee3\u7801\u53ef\u8bfb\u6027\u548c\u5f00\u53d1\u6548\u7387\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.00683", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00683", "abs": "https://arxiv.org/abs/2512.00683", "authors": ["Wu Yonggang"], "title": "Model of human cognition", "comment": null, "summary": "The development of large language models (LLMs) is limited by a lack of explainability, the absence of a unifying theory, and prohibitive operational costs. We propose a neuro-theoretical framework for the emergence of intelligence in systems that is both functionally robust and biologically plausible. The model provides theoretical insights into cognitive processes such as decision-making and problem solving, and a computationally efficient approach for the creation of explainable and generalizable artificial intelligence.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u795e\u7ecf\u7406\u8bba\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u91ca\u667a\u80fd\u5728\u7cfb\u7edf\u4e2d\u7684\u6d8c\u73b0\uff0c\u8be5\u6846\u67b6\u65e2\u529f\u80fd\u7a33\u5065\u53c8\u5177\u6709\u751f\u7269\u5b66\u5408\u7406\u6027\uff0c\u65e8\u5728\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u3001\u7f3a\u4e4f\u7edf\u4e00\u7406\u8bba\u548c\u8fd0\u8425\u6210\u672c\u8fc7\u9ad8\u7684\u95ee\u9898\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u53d7\u5230\u4e09\u4e2a\u4e3b\u8981\u9650\u5236\uff1a\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u3001\u7f3a\u4e4f\u7edf\u4e00\u7406\u8bba\u4ee5\u53ca\u9ad8\u6602\u7684\u8fd0\u8425\u6210\u672c\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u9700\u8981\u4e00\u4e2a\u65e2\u529f\u80fd\u7a33\u5065\u53c8\u5177\u6709\u751f\u7269\u5b66\u5408\u7406\u6027\u7684\u7406\u8bba\u6846\u67b6\u6765\u89e3\u91ca\u667a\u80fd\u7684\u6d8c\u73b0\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u795e\u7ecf\u7406\u8bba\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u57fa\u4e8e\u751f\u7269\u5b66\u5408\u7406\u6027\uff0c\u65e8\u5728\u89e3\u91ca\u667a\u80fd\u5728\u7cfb\u7edf\u4e2d\u7684\u6d8c\u73b0\u8fc7\u7a0b\u3002\u8be5\u6a21\u578b\u4e3a\u51b3\u7b56\u5236\u5b9a\u548c\u95ee\u9898\u89e3\u51b3\u7b49\u8ba4\u77e5\u8fc7\u7a0b\u63d0\u4f9b\u7406\u8bba\u89c1\u89e3\uff0c\u5e76\u63d0\u4f9b\u4e86\u8ba1\u7b97\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u521b\u5efa\u53ef\u89e3\u91ca\u548c\u53ef\u6cdb\u5316\u7684\u4eba\u5de5\u667a\u80fd\u3002", "result": "\u8be5\u6846\u67b6\u63d0\u4f9b\u4e86\u5bf9\u8ba4\u77e5\u8fc7\u7a0b\u7684\u7406\u8bba\u7406\u89e3\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u8ba1\u7b97\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u6784\u5efa\u53ef\u89e3\u91ca\u548c\u53ef\u6cdb\u5316\u7684\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u3002\u867d\u7136\u8bba\u6587\u6458\u8981\u6ca1\u6709\u63d0\u4f9b\u5177\u4f53\u7684\u5b9e\u9a8c\u7ed3\u679c\uff0c\u4f46\u5f3a\u8c03\u4e86\u8be5\u6846\u67b6\u7684\u7406\u8bba\u8d21\u732e\u548c\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684\u795e\u7ecf\u7406\u8bba\u6846\u67b6\u4e3a\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3001\u7406\u8bba\u7edf\u4e00\u6027\u548c\u6210\u672c\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\uff0c\u4e3a\u521b\u5efa\u65e2\u5177\u6709\u751f\u7269\u5b66\u5408\u7406\u6027\u53c8\u8ba1\u7b97\u9ad8\u6548\u7684\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2512.00713", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00713", "abs": "https://arxiv.org/abs/2512.00713", "authors": ["Haoyu Shen", "Weimin Lyu", "Haotian Xu", "Tengfei Ma"], "title": "Concept-Guided Backdoor Attack on Vision Language Models", "comment": null, "summary": "Vision-Language Models (VLMs) have achieved impressive progress in multimodal text generation, yet their rapid adoption raises increasing concerns about security vulnerabilities. Existing backdoor attacks against VLMs primarily rely on explicit pixel-level triggers or imperceptible perturbations injected into images. While effective, these approaches reduce stealthiness and remain vulnerable to image-based defenses. We introduce concept-guided backdoor attacks, a new paradigm that operates at the semantic concept level rather than on raw pixels. We propose two different attacks. The first, Concept-Thresholding Poisoning (CTP), uses explicit concepts in natural images as triggers: only samples containing the target concept are poisoned, causing the model to behave normally in all other cases but consistently inject malicious outputs whenever the concept appears. The second, CBL-Guided Unseen Backdoor (CGUB), leverages a Concept Bottleneck Model (CBM) during training to intervene on internal concept activations, while discarding the CBM branch at inference time to keep the VLM unchanged. This design enables systematic replacement of a targeted label in generated text (for example, replacing \"cat\" with \"dog\"), even when the replacement behavior never appears in the training data. Experiments across multiple VLM architectures and datasets show that both CTP and CGUB achieve high attack success rates while maintaining moderate impact on clean-task performance. These findings highlight concept-level vulnerabilities as a critical new attack surface for VLMs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u6982\u5ff5\u5f15\u5bfc\u7684\u540e\u95e8\u653b\u51fb\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u8bed\u4e49\u6982\u5ff5\u800c\u975e\u50cf\u7d20\u7ea7\u89e6\u53d1\u5668\u6765\u653b\u51fb\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u5305\u62ecCTP\u548cCGUB\u4e24\u79cd\u653b\u51fb\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8bc1\u660e\u653b\u51fb\u6210\u529f\u7387\u9ad8\u4e14\u5bf9\u6b63\u5e38\u4efb\u52a1\u5f71\u54cd\u5c0f\u3002", "motivation": "\u73b0\u6709\u9488\u5bf9\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u540e\u95e8\u653b\u51fb\u4e3b\u8981\u4f9d\u8d56\u50cf\u7d20\u7ea7\u89e6\u53d1\u5668\u6216\u4e0d\u53ef\u5bdf\u89c9\u7684\u56fe\u50cf\u6270\u52a8\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u9690\u853d\u6027\u5dee\u4e14\u5bb9\u6613\u88ab\u57fa\u4e8e\u56fe\u50cf\u7684\u9632\u5fa1\u673a\u5236\u68c0\u6d4b\u3002\u9700\u8981\u63a2\u7d22\u66f4\u9690\u853d\u3001\u57fa\u4e8e\u8bed\u4e49\u6982\u5ff5\u5c42\u9762\u7684\u653b\u51fb\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u6982\u5ff5\u5f15\u5bfc\u7684\u540e\u95e8\u653b\u51fb\uff1a1) CTP\u653b\u51fb\u4f7f\u7528\u81ea\u7136\u56fe\u50cf\u4e2d\u7684\u663e\u5f0f\u6982\u5ff5\u4f5c\u4e3a\u89e6\u53d1\u5668\uff0c\u4ec5\u5bf9\u5305\u542b\u76ee\u6807\u6982\u5ff5\u7684\u6837\u672c\u8fdb\u884c\u6295\u6bd2\uff1b2) CGUB\u653b\u51fb\u5728\u8bad\u7ec3\u65f6\u5229\u7528\u6982\u5ff5\u74f6\u9888\u6a21\u578b\u5e72\u9884\u5185\u90e8\u6982\u5ff5\u6fc0\u6d3b\uff0c\u5728\u63a8\u7406\u65f6\u4e22\u5f03CBM\u5206\u652f\u4ee5\u4fdd\u6301\u6a21\u578b\u4e0d\u53d8\uff0c\u5b9e\u73b0\u7cfb\u7edf\u6027\u7684\u6807\u7b7e\u66ff\u6362\u3002", "result": "\u5728\u591a\u79cd\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u67b6\u6784\u548c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCTP\u548cCGUB\u90fd\u80fd\u5b9e\u73b0\u9ad8\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u5bf9\u5e72\u51c0\u4efb\u52a1\u7684\u6027\u80fd\u5f71\u54cd\u9002\u4e2d\uff0c\u8bc1\u660e\u4e86\u6982\u5ff5\u7ea7\u6f0f\u6d1e\u662f\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u91cd\u8981\u65b0\u653b\u51fb\u9762\u3002", "conclusion": "\u6982\u5ff5\u5f15\u5bfc\u7684\u540e\u95e8\u653b\u51fb\u4e3a\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u63d0\u51fa\u4e86\u65b0\u7684\u6311\u6218\uff0c\u6982\u5ff5\u7ea7\u6f0f\u6d1e\u6210\u4e3a\u5173\u952e\u7684\u65b0\u653b\u51fb\u9762\uff0c\u9700\u8981\u5f00\u53d1\u76f8\u5e94\u7684\u9632\u5fa1\u673a\u5236\u6765\u5e94\u5bf9\u8fd9\u79cd\u8bed\u4e49\u5c42\u9762\u7684\u5a01\u80c1\u3002"}}
{"id": "2512.00741", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00741", "abs": "https://arxiv.org/abs/2512.00741", "authors": ["Bojing Li", "Duo Zhong", "Dharani Nadendla", "Gabriel Terceros", "Prajna Bhandar", "Raguvir S", "Charles Nicholas"], "title": "MASCOT: Analyzing Malware Evolution Through A Well-Curated Source Code Dataset", "comment": "11 pages, 6 figures, conference paper; submitted to IEEE BigData 2025 CyberHunt workshop", "summary": "In recent years, the explosion of malware and extensive code reuse have formed complex evolutionary connections among malware specimens. The rapid pace of development makes it challenging for existing studies to characterize recent evolutionary trends. In addition, intuitive tools to untangle these intricate connections between malware specimens or categories are urgently needed. This paper introduces a manually-reviewed malware source code dataset containing 6032 specimens. Building on and extending current research from a software engineering perspective, we systematically evaluate the scale, development costs, code quality, as well as security and dependencies of modern malware. We further introduce a multi-view genealogy analysis to clarify malware connections: at an overall view, this analysis quantifies the strength and direction of connections among specimens and categories; at a detailed view, it traces the evolutionary histories of individual specimens. Experimental results indicate that, despite persistent shortcomings in code quality, malware specimens exhibit an increasing complexity and standardization, in step with the development of mainstream software engineering practices. Meanwhile, our genealogy analysis intuitively reveals lineage expansion and evolution driven by code reuse, providing new evidence and tools for understanding the formation and evolution of the malware ecosystem.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b6032\u4e2a\u6837\u672c\u7684\u624b\u52a8\u5ba1\u67e5\u6076\u610f\u8f6f\u4ef6\u6e90\u4ee3\u7801\u6570\u636e\u96c6\uff0c\u4ece\u8f6f\u4ef6\u5de5\u7a0b\u89d2\u5ea6\u7cfb\u7edf\u8bc4\u4f30\u73b0\u4ee3\u6076\u610f\u8f6f\u4ef6\u7684\u89c4\u6a21\u3001\u5f00\u53d1\u6210\u672c\u3001\u4ee3\u7801\u8d28\u91cf\u3001\u5b89\u5168\u6027\u548c\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u5f15\u5165\u591a\u89c6\u89d2\u8c31\u7cfb\u5206\u6790\u6765\u63ed\u793a\u6076\u610f\u8f6f\u4ef6\u4e4b\u95f4\u7684\u6f14\u5316\u5173\u7cfb\u3002", "motivation": "\u8fd1\u5e74\u6765\u6076\u610f\u8f6f\u4ef6\u7206\u70b8\u5f0f\u589e\u957f\u548c\u4ee3\u7801\u91cd\u7528\u5f62\u6210\u4e86\u590d\u6742\u7684\u6f14\u5316\u5173\u7cfb\uff0c\u73b0\u6709\u7814\u7a76\u96be\u4ee5\u63cf\u8ff0\u6700\u8fd1\u7684\u6f14\u5316\u8d8b\u52bf\uff0c\u8feb\u5207\u9700\u8981\u76f4\u89c2\u5de5\u5177\u6765\u7406\u6e05\u6076\u610f\u8f6f\u4ef6\u6837\u672c\u6216\u7c7b\u522b\u4e4b\u95f4\u7684\u590d\u6742\u8054\u7cfb\u3002", "method": "\u6784\u5efa\u624b\u52a8\u5ba1\u67e5\u7684\u6076\u610f\u8f6f\u4ef6\u6e90\u4ee3\u7801\u6570\u636e\u96c6\uff086032\u4e2a\u6837\u672c\uff09\uff0c\u4ece\u8f6f\u4ef6\u5de5\u7a0b\u89d2\u5ea6\u7cfb\u7edf\u8bc4\u4f30\u6076\u610f\u8f6f\u4ef6\u7684\u591a\u4e2a\u7ef4\u5ea6\uff0c\u5e76\u5f15\u5165\u591a\u89c6\u89d2\u8c31\u7cfb\u5206\u6790\u65b9\u6cd5\uff1a\u6574\u4f53\u89c6\u89d2\u91cf\u5316\u6837\u672c\u548c\u7c7b\u522b\u4e4b\u95f4\u7684\u8fde\u63a5\u5f3a\u5ea6\u548c\u65b9\u5411\uff0c\u8be6\u7ec6\u89c6\u89d2\u8ffd\u8e2a\u5355\u4e2a\u6837\u672c\u7684\u6f14\u5316\u5386\u53f2\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5c3d\u7ba1\u4ee3\u7801\u8d28\u91cf\u4ecd\u5b58\u5728\u6301\u7eed\u7f3a\u9677\uff0c\u4f46\u6076\u610f\u8f6f\u4ef6\u6837\u672c\u8868\u73b0\u51fa\u65e5\u76ca\u589e\u52a0\u7684\u590d\u6742\u6027\u548c\u6807\u51c6\u5316\uff0c\u4e0e\u4e3b\u6d41\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\u53d1\u5c55\u540c\u6b65\u3002\u8c31\u7cfb\u5206\u6790\u76f4\u89c2\u63ed\u793a\u4e86\u7531\u4ee3\u7801\u91cd\u7528\u9a71\u52a8\u7684\u8c31\u7cfb\u6269\u5c55\u548c\u6f14\u5316\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7406\u89e3\u6076\u610f\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\u7684\u5f62\u6210\u548c\u6f14\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u8bc1\u636e\u548c\u5de5\u5177\uff0c\u591a\u89c6\u89d2\u8c31\u7cfb\u5206\u6790\u80fd\u591f\u63ed\u793a\u6076\u610f\u8f6f\u4ef6\u4e4b\u95f4\u7684\u6f14\u5316\u5173\u7cfb\uff0c\u6709\u52a9\u4e8e\u66f4\u597d\u5730\u7406\u89e3\u6076\u610f\u8f6f\u4ef6\u7684\u6f14\u5316\u8d8b\u52bf\u3002"}}
{"id": "2512.00722", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00722", "abs": "https://arxiv.org/abs/2512.00722", "authors": ["Jiaming Xu", "Jiayi Pan", "Hanzhen Wang", "Yongkang Zhou", "Jiancai Ye", "Yu Wang", "Guohao Dai"], "title": "SpeContext: Enabling Efficient Long-context Reasoning with Speculative Context Sparsity in LLMs", "comment": "Accepted by ASPLOS 2026", "summary": "In this paper, we point out that the objective of the retrieval algorithms is to align with the LLM, which is similar to the objective of knowledge distillation in LLMs. We analyze the similarity in information focus between the distilled language model(DLM) and the original LLM from the perspective of information theory, and thus propose a novel paradigm that leverages a DLM as the retrieval algorithm. Based on the insight, we present SpeContext, an algorithm and system co-design for long-context reasoning. (1) At the algorithm level, SpeContext proposes lightweight retrieval head based on the head-level attention weights of DLM, achieving > 90% parameters reduction by pruning the redundancy. (2) At the system level, SpeContext designs an asynchronous prefetch dataflow via the elastic loading strategy, effectively overlapping KV cache retrieval with the LLM computation. (3) At the compilation level, SpeContext constructs the theoretical memory model and implements an adaptive memory management system to achieve acceleration by maximizing GPU memory utilization. We deploy and evaluate SpeContext in two resourceconstrained environments, cloud and edge. Extensive experiments show that, compared with the Huggingface framework, SpeContext achieves up to 24.89x throughput improvement in cloud and 10.06x speedup in edge with negligible accuracy loss, pushing the Pareto frontier of accuracy and throughput.", "AI": {"tldr": "SpeContext\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u84b8\u998f\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u68c0\u7d22\u7b97\u6cd5\u7684\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u7b97\u6cd5\u3001\u7cfb\u7edf\u548c\u7f16\u8bd1\u4e09\u4e2a\u5c42\u9762\u7684\u534f\u540c\u8bbe\u8ba1\uff0c\u5728\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u672c\u6587\u7684\u52a8\u673a\u662f\u89c2\u5bdf\u5230\u68c0\u7d22\u7b97\u6cd5\u7684\u76ee\u6807\u4e0eLLM\u5bf9\u9f50\uff0c\u8fd9\u4e0eLLM\u4e2d\u7684\u77e5\u8bc6\u84b8\u998f\u76ee\u6807\u76f8\u4f3c\u3002\u4f5c\u8005\u4ece\u4fe1\u606f\u8bba\u89d2\u5ea6\u5206\u6790\u4e86\u84b8\u998f\u8bed\u8a00\u6a21\u578b\u4e0e\u539f\u59cbLLM\u5728\u4fe1\u606f\u5173\u6ce8\u4e0a\u7684\u76f8\u4f3c\u6027\uff0c\u4ece\u800c\u63d0\u51fa\u5229\u7528DLM\u4f5c\u4e3a\u68c0\u7d22\u7b97\u6cd5\u7684\u65b0\u601d\u8def\u3002", "method": "SpeContext\u91c7\u7528\u4e09\u5c42\u534f\u540c\u8bbe\u8ba1\uff1a1) \u7b97\u6cd5\u5c42\u9762\uff1a\u57fa\u4e8eDLM\u7684\u6ce8\u610f\u529b\u5934\u6743\u91cd\u8bbe\u8ba1\u8f7b\u91cf\u7ea7\u68c0\u7d22\u5934\uff0c\u901a\u8fc7\u526a\u679d\u5197\u4f59\u5b9e\u73b0>90%\u53c2\u6570\u51cf\u5c11\uff1b2) \u7cfb\u7edf\u5c42\u9762\uff1a\u901a\u8fc7\u5f39\u6027\u52a0\u8f7d\u7b56\u7565\u8bbe\u8ba1\u5f02\u6b65\u9884\u53d6\u6570\u636e\u6d41\uff0c\u6709\u6548\u91cd\u53e0KV\u7f13\u5b58\u68c0\u7d22\u4e0eLLM\u8ba1\u7b97\uff1b3) \u7f16\u8bd1\u5c42\u9762\uff1a\u6784\u5efa\u7406\u8bba\u5185\u5b58\u6a21\u578b\u5e76\u5b9e\u73b0\u81ea\u9002\u5e94\u5185\u5b58\u7ba1\u7406\u7cfb\u7edf\uff0c\u6700\u5927\u5316GPU\u5185\u5b58\u5229\u7528\u7387\u3002", "result": "\u5728\u4e91\u548c\u8fb9\u7f18\u4e24\u79cd\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u90e8\u7f72\u8bc4\u4f30\uff0c\u4e0eHuggingface\u6846\u67b6\u76f8\u6bd4\uff0cSpeContext\u5728\u4e91\u7aef\u5b9e\u73b0\u4e86\u6700\u9ad824.89\u500d\u7684\u541e\u5410\u91cf\u63d0\u5347\uff0c\u5728\u8fb9\u7f18\u7aef\u5b9e\u73b0\u4e8610.06\u500d\u52a0\u901f\uff0c\u4e14\u7cbe\u5ea6\u635f\u5931\u53ef\u5ffd\u7565\u4e0d\u8ba1\uff0c\u63a8\u52a8\u4e86\u7cbe\u5ea6\u4e0e\u541e\u5410\u91cf\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\u3002", "conclusion": "SpeContext\u901a\u8fc7\u5c06DLM\u4f5c\u4e3a\u68c0\u7d22\u7b97\u6cd5\u7684\u521b\u65b0\u8303\u5f0f\uff0c\u7ed3\u5408\u7b97\u6cd5\u3001\u7cfb\u7edf\u548c\u7f16\u8bd1\u7684\u534f\u540c\u4f18\u5316\uff0c\u4e3a\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u6539\u8fdb\u3002"}}
{"id": "2512.00804", "categories": ["cs.CR", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2512.00804", "abs": "https://arxiv.org/abs/2512.00804", "authors": ["Hao Wu", "Prateek Saxena"], "title": "Bias Injection Attacks on RAG Databases and Sanitization Defenses", "comment": null, "summary": "This paper explores attacks and defenses on vector databases in retrieval-augmented generation (RAG) systems. Prior work on knowledge poisoning attacks primarily inject false or toxic content, which fact-checking or linguistic analysis easily detects. We reveal a new and subtle threat: bias injection attacks, which insert factually correct yet semantically biased passages into the knowledge base to covertly influence the ideological framing of answers generated by large language models (LLMs). We demonstrate that these adversarial passages, though linguistically coherent and truthful, can systematically crowd out opposing views from the retrieved context and steer LLM answers toward the attacker's intended perspective.\n  We precisely characterize this class of attacks and then develop a post-retrieval filtering defense, BiasDef. We construct a comprehensive benchmark based on public question answering datasets to evaluate them. Our results show that: (1) the proposed attack induces significant perspective shifts in LLM answers, effectively evading existing retrieval-based sanitization defenses; and (2) BiasDef outperforms existing methods by reducing adversarial passages retrieved by 15\\% which mitigates perspective shift by 6.2\\times in answers, while enabling the retrieval of 62\\% more benign passages.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76RAG\u7cfb\u7edf\u4e2d\u5411\u91cf\u6570\u636e\u5e93\u7684\u653b\u51fb\u4e0e\u9632\u5fa1\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u504f\u89c1\u6ce8\u5165\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d2\u5165\u4e8b\u5b9e\u6b63\u786e\u4f46\u8bed\u4e49\u504f\u89c1\u7684\u6587\u672c\u6765\u5f71\u54cdLLM\u7b54\u6848\u7684\u610f\u8bc6\u5f62\u6001\u6846\u67b6\uff0c\u5e76\u5f00\u53d1\u4e86\u540e\u68c0\u7d22\u8fc7\u6ee4\u9632\u5fa1\u65b9\u6cd5BiasDef\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u6295\u6bd2\u653b\u51fb\u4e3b\u8981\u6ce8\u5165\u865a\u5047\u6216\u6709\u6bd2\u5185\u5bb9\uff0c\u5bb9\u6613\u88ab\u4e8b\u5b9e\u6838\u67e5\u6216\u8bed\u8a00\u5206\u6790\u68c0\u6d4b\u3002\u672c\u6587\u63ed\u793a\u4e86\u4e00\u79cd\u66f4\u9690\u853d\u7684\u5a01\u80c1\uff1a\u504f\u89c1\u6ce8\u5165\u653b\u51fb\uff0c\u901a\u8fc7\u63d2\u5165\u4e8b\u5b9e\u6b63\u786e\u4f46\u8bed\u4e49\u504f\u89c1\u7684\u6587\u672c\u6765\u5f71\u54cdLLM\u7b54\u6848\u7684\u610f\u8bc6\u5f62\u6001\u6846\u67b6\u3002", "method": "1. \u7cbe\u786e\u63cf\u8ff0\u504f\u89c1\u6ce8\u5165\u653b\u51fb\u7c7b\u522b\uff1b2. \u5f00\u53d1\u540e\u68c0\u7d22\u8fc7\u6ee4\u9632\u5fa1\u65b9\u6cd5BiasDef\uff1b3. \u57fa\u4e8e\u516c\u5f00\u95ee\u7b54\u6570\u636e\u96c6\u6784\u5efa\u7efc\u5408\u57fa\u51c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "1. \u63d0\u51fa\u7684\u653b\u51fb\u80fd\u663e\u8457\u8bf1\u5bfcLLM\u7b54\u6848\u7684\u89c6\u89d2\u504f\u79fb\uff0c\u6709\u6548\u89c4\u907f\u73b0\u6709\u57fa\u4e8e\u68c0\u7d22\u7684\u51c0\u5316\u9632\u5fa1\uff1b2. BiasDef\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u51cf\u5c1115%\u7684\u5bf9\u6297\u6027\u6bb5\u843d\u68c0\u7d22\uff0c\u5c06\u7b54\u6848\u4e2d\u7684\u89c6\u89d2\u504f\u79fb\u964d\u4f4e6.2\u500d\uff0c\u540c\u65f6\u4f7f\u826f\u6027\u6bb5\u843d\u68c0\u7d22\u589e\u52a062%\u3002", "conclusion": "\u504f\u89c1\u6ce8\u5165\u653b\u51fb\u662fRAG\u7cfb\u7edf\u4e2d\u4e00\u79cd\u9690\u853d\u4e14\u6709\u6548\u7684\u5a01\u80c1\uff0c\u800cBiasDef\u4f5c\u4e3a\u540e\u68c0\u7d22\u8fc7\u6ee4\u9632\u5fa1\u65b9\u6cd5\u80fd\u6709\u6548\u7f13\u89e3\u8fd9\u79cd\u653b\u51fb\uff0c\u5728\u4fdd\u6301\u826f\u6027\u5185\u5bb9\u68c0\u7d22\u7684\u540c\u65f6\u51cf\u5c11\u5bf9\u6297\u6027\u504f\u89c1\u5185\u5bb9\u7684\u5f71\u54cd\u3002"}}
{"id": "2512.01356", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.01356", "abs": "https://arxiv.org/abs/2512.01356", "authors": ["Yuxin Zhang", "Yuxia Zhang", "Zeyu Sun", "Yanjie Jiang", "Hui Liu"], "title": "LAURA: Enhancing Code Review Generation with Context-Enriched Retrieval-Augmented LLM", "comment": "Accepted by the 2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE). Copyright 2025 IEEE. This is the author's accepted manuscript. The final published version may differ and will be available from IEEE Xplore", "summary": "Code review is critical for ensuring software quality and maintainability. With the rapid growth in software scale and complexity, code review has become a bottleneck in the development process because of its time-consuming and knowledge-intensive nature and the shortage of experienced developers willing to review code. Several approaches have been proposed for automatically generating code reviews based on retrieval, neural machine translation, pre-trained models, or large language models (LLMs). These approaches mainly leverage historical code changes and review comments. However, a large amount of crucial information for code review, such as the context of code changes and prior review knowledge, has been overlooked. This paper proposes an LLM-based review knowledge-augmented, context-aware framework for code review generation, named LAURA. The framework integrates review exemplar retrieval, context augmentation, and systematic guidance to enhance the performance of ChatGPT-4o and DeepSeek v3 in generating code review comments. Besides, given the extensive low-quality reviews in existing datasets, we also constructed a high-quality dataset. Experimental results show that for both models, LAURA generates review comments that are either completely correct or at least helpful to developers in 42.2% and 40.4% of cases, respectively, significantly outperforming SOTA baselines. Furthermore, our ablation studies demonstrate that all components of LAURA contribute positively to improving comment quality.", "AI": {"tldr": "LAURA\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u4ee3\u7801\u5ba1\u67e5\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u5ba1\u67e5\u793a\u4f8b\u68c0\u7d22\u3001\u4e0a\u4e0b\u6587\u589e\u5f3a\u548c\u7cfb\u7edf\u6307\u5bfc\uff0c\u663e\u8457\u63d0\u5347\u4e86ChatGPT-4o\u548cDeepSeek v3\u751f\u6210\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u7684\u8d28\u91cf\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u89c4\u6a21\u548c\u590d\u6742\u6027\u7684\u5feb\u901f\u589e\u957f\uff0c\u4ee3\u7801\u5ba1\u67e5\u5df2\u6210\u4e3a\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u7684\u74f6\u9888\uff0c\u56e0\u4e3a\u5176\u8017\u65f6\u3001\u77e5\u8bc6\u5bc6\u96c6\u4e14\u7f3a\u4e4f\u7ecf\u9a8c\u4e30\u5bcc\u7684\u5f00\u53d1\u8005\u3002\u73b0\u6709\u81ea\u52a8\u751f\u6210\u4ee3\u7801\u5ba1\u67e5\u7684\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u5386\u53f2\u4ee3\u7801\u53d8\u66f4\u548c\u5ba1\u67e5\u8bc4\u8bba\uff0c\u4f46\u5ffd\u7565\u4e86\u4ee3\u7801\u53d8\u66f4\u4e0a\u4e0b\u6587\u548c\u5148\u524d\u5ba1\u67e5\u77e5\u8bc6\u7b49\u5173\u952e\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\u4e86LAURA\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u5ba1\u67e5\u77e5\u8bc6\u589e\u5f3a\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u4ee3\u7801\u5ba1\u67e5\u751f\u6210\u6846\u67b6\u3002\u8be5\u6846\u67b6\u6574\u5408\u4e86\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u5ba1\u67e5\u793a\u4f8b\u68c0\u7d22\u3001\u4e0a\u4e0b\u6587\u589e\u5f3a\u548c\u7cfb\u7edf\u6307\u5bfc\uff0c\u4ee5\u63d0\u5347LLM\u751f\u6210\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0c\u9488\u5bf9\u73b0\u6709\u6570\u636e\u96c6\u4e2d\u5927\u91cf\u4f4e\u8d28\u91cf\u5ba1\u67e5\u7684\u95ee\u9898\uff0c\u8fd8\u6784\u5efa\u4e86\u4e00\u4e2a\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5bf9\u4e8eChatGPT-4o\u548cDeepSeek v3\u6a21\u578b\uff0cLAURA\u5206\u522b\u80fd\u572842.2%\u548c40.4%\u7684\u60c5\u51b5\u4e0b\u751f\u6210\u5b8c\u5168\u6b63\u786e\u6216\u81f3\u5c11\u5bf9\u5f00\u53d1\u8005\u6709\u5e2e\u52a9\u7684\u5ba1\u67e5\u8bc4\u8bba\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002\u6d88\u878d\u7814\u7a76\u8fdb\u4e00\u6b65\u8bc1\u660eLAURA\u7684\u6240\u6709\u7ec4\u4ef6\u90fd\u5bf9\u63d0\u5347\u8bc4\u8bba\u8d28\u91cf\u6709\u79ef\u6781\u8d21\u732e\u3002", "conclusion": "LAURA\u6846\u67b6\u901a\u8fc7\u6574\u5408\u5ba1\u67e5\u77e5\u8bc6\u589e\u5f3a\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u673a\u5236\uff0c\u6709\u6548\u63d0\u5347\u4e86LLM\u751f\u6210\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u7684\u8d28\u91cf\uff0c\u4e3a\u89e3\u51b3\u4ee3\u7801\u5ba1\u67e5\u74f6\u9888\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.00729", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.00729", "abs": "https://arxiv.org/abs/2512.00729", "authors": ["Yuxiang Chen", "Zuohan Wu", "Ziwei Wang", "Xiangning Yu", "Xujia Li", "Linyi Yang", "Mengyue Yang", "Jun Wang", "Lei Chen"], "title": "Probing the \"Psyche'' of Large Reasoning Models: Understanding Through a Human Lens", "comment": "13 pages", "summary": "Large reasoning models (LRMs) have garnered significant attention from researchers owing to their exceptional capability in addressing complex tasks. Motivated by the observed human-like behaviors in their reasoning processes, this paper introduces a comprehensive taxonomy to characterize atomic reasoning steps and probe the ``psyche'' of LRM intelligence. Specifically, it comprises five groups and seventeen categories derived from human mental processes, thereby grounding the understanding of LRMs in an interdisciplinary perspective. The taxonomy is then applied for an in-depth understanding of current LRMs, resulting in a distinct labeled dataset that comprises 277,534 atomic reasoning steps. Using this resource, we analyze contemporary LRMs and distill several actionable takeaways for improving training and post-training of reasoning models. Notably, our analysis reveals that prevailing post-answer ``double-checks'' (self-monitoring evaluations) are largely superficial and rarely yield substantive revisions. Thus, incentivizing comprehensive multi-step reflection, rather than simple self-monitoring, may offer a more effective path forward. To complement the taxonomy, an automatic annotation framework, named CAPO, is proposed to leverage large language models (LLMs) for generating the taxonomy-based annotations. Experimental results demonstrate that CAPO achieves higher consistency with human experts compared to baselines, facilitating a scalable and comprehensive analysis of LRMs from a human cognitive perspective. Together, the taxonomy, CAPO, and the derived insights provide a principled, scalable path toward understanding and advancing LRM reasoning.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4eba\u7c7b\u5fc3\u7406\u8fc7\u7a0b\u7684\u4e94\u7ec4\u5341\u4e03\u7c7b\u63a8\u7406\u6b65\u9aa4\u5206\u7c7b\u6cd5\uff0c\u7528\u4e8e\u5206\u6790\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\"\u5fc3\u7406\"\uff0c\u5e76\u5f00\u53d1\u4e86\u81ea\u52a8\u6807\u6ce8\u6846\u67b6CAPO\u548c\u5305\u542b277,534\u4e2a\u539f\u5b50\u63a8\u7406\u6b65\u9aa4\u7684\u6570\u636e\u96c6\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u81ea\u6211\u76d1\u63a7\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5c55\u73b0\u51fa\u7c7b\u4f3c\u4eba\u7c7b\u7684\u63a8\u7406\u884c\u4e3a\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u5206\u6790\u6846\u67b6\u3002\u7814\u7a76\u8005\u5e0c\u671b\u4ece\u8de8\u5b66\u79d1\u7684\u4eba\u7c7b\u8ba4\u77e5\u89c6\u89d2\uff0c\u6df1\u5165\u7406\u89e3\u8fd9\u4e9b\u6a21\u578b\u7684\"\u5fc3\u7406\"\u673a\u5236\uff0c\u4e3a\u6539\u8fdb\u8bad\u7ec3\u548c\u540e\u8bad\u7ec3\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "method": "1. \u63d0\u51fa\u57fa\u4e8e\u4eba\u7c7b\u5fc3\u7406\u8fc7\u7a0b\u7684\u4e94\u7ec4\u5341\u4e03\u7c7b\u539f\u5b50\u63a8\u7406\u6b65\u9aa4\u5206\u7c7b\u6cd5\uff1b2. \u5f00\u53d1\u81ea\u52a8\u6807\u6ce8\u6846\u67b6CAPO\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5206\u7c7b\u6cd5\u6807\u6ce8\uff1b3. \u6784\u5efa\u5305\u542b277,534\u4e2a\u539f\u5b50\u63a8\u7406\u6b65\u9aa4\u7684\u6807\u6ce8\u6570\u636e\u96c6\uff1b4. \u5e94\u7528\u8be5\u6846\u67b6\u5206\u6790\u5f53\u4ee3\u5927\u578b\u63a8\u7406\u6a21\u578b\u3002", "result": "1. CAPO\u6846\u67b6\u5728\u6807\u6ce8\u4e00\u81f4\u6027\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u66f4\u4e00\u81f4\uff1b2. \u5206\u6790\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u7684\u7b54\u6848\u540e\"\u53cc\u91cd\u68c0\u67e5\"\uff08\u81ea\u6211\u76d1\u63a7\u8bc4\u4f30\uff09\u5927\u591a\u6d41\u4e8e\u8868\u9762\uff0c\u5f88\u5c11\u4ea7\u751f\u5b9e\u8d28\u6027\u4fee\u6b63\uff1b3. \u6fc0\u52b1\u5168\u9762\u7684\u591a\u6b65\u53cd\u601d\u6bd4\u7b80\u5355\u7684\u81ea\u6211\u76d1\u63a7\u66f4\u6709\u6548\uff1b4. \u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u5927\u578b\u63a8\u7406\u6a21\u578b\u5206\u6790\u8def\u5f84\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u5206\u7c7b\u6cd5\u3001CAPO\u6846\u67b6\u548c\u6d1e\u5bdf\u4e3a\u7406\u89e3\u548c\u63a8\u8fdb\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u3001\u53ef\u6269\u5c55\u7684\u8def\u5f84\uff0c\u5f3a\u8c03\u9700\u8981\u4ece\u4eba\u7c7b\u8ba4\u77e5\u89c6\u89d2\u6df1\u5165\u5206\u6790\u6a21\u578b\u5fc3\u7406\uff0c\u5e76\u8f6c\u5411\u66f4\u5168\u9762\u7684\u591a\u6b65\u53cd\u601d\u673a\u5236\u3002"}}
{"id": "2512.01523", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.01523", "abs": "https://arxiv.org/abs/2512.01523", "authors": ["Pankaj Jalote", "Y. Raghu Reddy", "Vasudeva Varma"], "title": "Teaching an Online Multi-Institutional Research Level Software Engineering Course with Industry - an Experience Report", "comment": "7 pages", "summary": "Covid has made online teaching and learning acceptable and students, faculty, and industry professionals are all comfortable with this mode. This comfort can be leveraged to offer an online multi-institutional research-level course in an area where individual institutions may not have the requisite faculty to teach and/or research students to enroll. If the subject is of interest to industry, online offering also allows industry experts to contribute and participate with ease. Advanced topics in Software Engineering are ideally suited for experimenting with this approach as industry, which is often looking to incorporate advances in software engineering in their practices, is likely to agree to contribute and participate. In this paper we describe an experiment in teaching a course titled \"AI in Software Engineering\" jointly between two institutions with active industry participation, and share our and student's experience. We believe this collaborative teaching approach can be used for offering research level courses in any applied area of computer science by institutions who are small and find it difficult to offer research level courses on their own.", "AI": {"tldr": "\u5728\u7ebf\u591a\u673a\u6784\u7814\u7a76\u7ea7\u8bfe\u7a0b\u5b9e\u9a8c\uff0c\u5229\u7528\u75ab\u60c5\u540e\u5728\u7ebf\u6559\u5b66\u666e\u53ca\u7684\u4f18\u52bf\uff0c\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9ad8\u7ea7\u4e3b\u9898\u9886\u57df\u8fdb\u884c\u8de8\u673a\u6784\u5408\u4f5c\u6559\u5b66\uff0c\u5e76\u5f15\u5165\u884c\u4e1a\u4e13\u5bb6\u53c2\u4e0e", "motivation": "\u65b0\u51a0\u75ab\u60c5\u4f7f\u5728\u7ebf\u6559\u5b66\u6210\u4e3a\u5e38\u6001\uff0c\u5b66\u751f\u3001\u6559\u5e08\u548c\u884c\u4e1a\u4e13\u4e1a\u4eba\u58eb\u90fd\u9002\u5e94\u4e86\u8fd9\u79cd\u6a21\u5f0f\u3002\u8fd9\u79cd\u8212\u9002\u5ea6\u53ef\u4ee5\u88ab\u7528\u6765\u63d0\u4f9b\u5728\u7ebf\u591a\u673a\u6784\u7814\u7a76\u7ea7\u8bfe\u7a0b\uff0c\u7279\u522b\u662f\u5728\u5355\u4e2a\u673a\u6784\u53ef\u80fd\u7f3a\u4e4f\u8db3\u591f\u5e08\u8d44\u6216\u7814\u7a76\u751f\u7684\u9886\u57df\u3002\u5982\u679c\u4e3b\u9898\u5bf9\u884c\u4e1a\u6709\u5438\u5f15\u529b\uff0c\u5728\u7ebf\u5f62\u5f0f\u8fd8\u80fd\u8ba9\u884c\u4e1a\u4e13\u5bb6\u8f7b\u677e\u53c2\u4e0e", "method": "\u5728\u4e24\u4e2a\u673a\u6784\u4e4b\u95f4\u8054\u5408\u5f00\u8bbe\"AI in Software Engineering\"\u8bfe\u7a0b\uff0c\u5e76\u79ef\u6781\u9080\u8bf7\u884c\u4e1a\u4e13\u5bb6\u53c2\u4e0e\u3002\u91c7\u7528\u5728\u7ebf\u534f\u4f5c\u6559\u5b66\u6a21\u5f0f\uff0c\u8ba9\u4e0d\u540c\u673a\u6784\u7684\u5b66\u751f\u548c\u884c\u4e1a\u4e13\u4e1a\u4eba\u58eb\u5171\u540c\u53c2\u4e0e\u8bfe\u7a0b", "result": "\u6210\u529f\u5b9e\u65bd\u4e86\u8de8\u673a\u6784\u5728\u7ebf\u7814\u7a76\u7ea7\u8bfe\u7a0b\uff0c\u5206\u4eab\u4e86\u6559\u5e08\u548c\u5b66\u751f\u7684\u7ecf\u9a8c\u3002\u8bc1\u660e\u4e86\u8fd9\u79cd\u6a21\u5f0f\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9ad8\u7ea7\u4e3b\u9898\u9886\u57df\u7684\u53ef\u884c\u6027", "conclusion": "\u8fd9\u79cd\u534f\u4f5c\u6559\u5b66\u65b9\u6cd5\u53ef\u4ee5\u5e94\u7528\u4e8e\u8ba1\u7b97\u673a\u79d1\u5b66\u4efb\u4f55\u5e94\u7528\u9886\u57df\u7684\u7814\u7a76\u7ea7\u8bfe\u7a0b\uff0c\u7279\u522b\u9002\u5408\u89c4\u6a21\u8f83\u5c0f\u3001\u96be\u4ee5\u72ec\u7acb\u63d0\u4f9b\u7814\u7a76\u7ea7\u8bfe\u7a0b\u7684\u673a\u6784\u3002\u8f6f\u4ef6\u5de5\u7a0b\u9ad8\u7ea7\u4e3b\u9898\u7279\u522b\u9002\u5408\u8fd9\u79cd\u6a21\u5f0f\uff0c\u56e0\u4e3a\u884c\u4e1a\u901a\u5e38\u613f\u610f\u53c2\u4e0e\u5e76\u8d21\u732e\u4e13\u4e1a\u77e5\u8bc6"}}
{"id": "2512.00807", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00807", "abs": "https://arxiv.org/abs/2512.00807", "authors": ["Yujie Lin", "Jiayao Ma", "Qingguo Hu", "Derek F. Wong", "Jinsong Su"], "title": "BioPro: On Difference-Aware Gender Fairness for Vision-Language Models", "comment": null, "summary": "Vision-Language Models (VLMs) inherit significant social biases from their training data, notably in gender representation. Current fairness interventions often adopt a difference-unaware perspective that enforces uniform treatment across demographic groups. These approaches, however, fail to distinguish between contexts where neutrality is required and those where group-specific attributes are legitimate and must be preserved. Building upon recent advances in difference-aware fairness for text-only models, we extend this concept to the multimodal domain and formalize the problem of difference-aware gender fairness for image captioning and text-to-image generation. We advocate for selective debiasing, which aims to mitigate unwanted bias in neutral contexts while preserving valid distinctions in explicit ones. To achieve this, we propose BioPro (Bias Orthogonal Projection), an entirely training-free framework. BioPro identifies a low-dimensional gender-variation subspace through counterfactual embeddings and applies projection to selectively neutralize gender-related information. Experiments show that BioPro effectively reduces gender bias in neutral cases while maintaining gender faithfulness in explicit ones, thus providing a promising direction toward achieving selective fairness in VLMs. Beyond gender bias, we further demonstrate that BioPro can effectively generalize to continuous bias variables, such as scene brightness, highlighting its broader applicability.", "AI": {"tldr": "BioPro\uff1a\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u9009\u62e9\u6027\u53bb\u504f\u6846\u67b6\uff0c\u901a\u8fc7\u8bc6\u522b\u6027\u522b\u53d8\u5316\u5b50\u7a7a\u95f4\u5e76\u5e94\u7528\u6295\u5f71\uff0c\u5728\u4e2d\u6027\u573a\u666f\u4e2d\u51cf\u5c11\u6027\u522b\u504f\u89c1\uff0c\u5728\u660e\u786e\u573a\u666f\u4e2d\u4fdd\u6301\u6027\u522b\u5fe0\u5b9e\u5ea6", "motivation": "\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u663e\u8457\u7684\u6027\u522b\u504f\u89c1\uff0c\u73b0\u6709\u516c\u5e73\u6027\u5e72\u9884\u65b9\u6cd5\u91c7\u7528\u5dee\u5f02\u65e0\u611f\u77e5\u89c6\u89d2\uff0c\u5bf9\u6240\u6709\u4eba\u53e3\u7fa4\u4f53\u5b9e\u65bd\u7edf\u4e00\u5904\u7406\u3002\u8fd9\u79cd\u65b9\u6cd5\u65e0\u6cd5\u533a\u5206\u9700\u8981\u4e2d\u7acb\u6027\u7684\u573a\u666f\u548c\u9700\u8981\u4fdd\u7559\u7fa4\u4f53\u7279\u5b9a\u5c5e\u6027\u7684\u573a\u666f", "method": "\u63d0\u51faBioPro\uff08Bias Orthogonal Projection\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u53cd\u4e8b\u5b9e\u5d4c\u5165\u8bc6\u522b\u4f4e\u7ef4\u6027\u522b\u53d8\u5316\u5b50\u7a7a\u95f4\uff0c\u5e94\u7528\u6295\u5f71\u9009\u62e9\u6027\u5730\u4e2d\u548c\u6027\u522b\u76f8\u5173\u4fe1\u606f\u3002\u8be5\u65b9\u6cd5\u5b8c\u5168\u65e0\u9700\u8bad\u7ec3", "result": "BioPro\u5728\u4e2d\u6027\u60c5\u51b5\u4e0b\u6709\u6548\u51cf\u5c11\u6027\u522b\u504f\u89c1\uff0c\u5728\u660e\u786e\u60c5\u51b5\u4e0b\u4fdd\u6301\u6027\u522b\u5fe0\u5b9e\u5ea6\u3002\u6b64\u5916\uff0cBioPro\u8fd8\u80fd\u63a8\u5e7f\u5230\u8fde\u7eed\u504f\u89c1\u53d8\u91cf\uff08\u5982\u573a\u666f\u4eae\u5ea6\uff09\uff0c\u5c55\u793a\u4e86\u66f4\u5e7f\u6cdb\u7684\u9002\u7528\u6027", "conclusion": "BioPro\u4e3a\u5b9e\u73b0\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u9009\u62e9\u6027\u516c\u5e73\u6027\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u80fd\u591f\u533a\u5206\u4e2d\u6027\u573a\u666f\u548c\u660e\u786e\u573a\u666f\uff0c\u5728\u51cf\u5c11\u4e0d\u5fc5\u8981\u504f\u89c1\u7684\u540c\u65f6\u4fdd\u7559\u6709\u6548\u533a\u522b"}}
{"id": "2512.00818", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.00818", "abs": "https://arxiv.org/abs/2512.00818", "authors": ["Haozhen Gong", "Xiaozhong Ji", "Yuansen Liu", "Wenbin Wu", "Xiaoxiao Yan", "Jingjing Liu", "Kai Wu", "Jiazhen Pan", "Bailiang Jian", "Jiangning Zhang", "Xiaobin Hu", "Hongwei Bran Li"], "title": "Med-CMR: A Fine-Grained Benchmark Integrating Visual Evidence and Clinical Logic for Medical Complex Multimodal Reasoning", "comment": null, "summary": "MLLMs MLLMs are beginning to appear in clinical workflows, but their ability to perform complex medical reasoning remains unclear. We present Med-CMR, a fine-grained Medical Complex Multimodal Reasoning benchmark. Med-CMR distinguishes from existing counterparts by three core features: 1) Systematic capability decomposition, splitting medical multimodal reasoning into fine-grained visual understanding and multi-step reasoning to enable targeted evaluation; 2) Challenging task design, with visual understanding across three key dimensions (small-object detection, fine-detail discrimination, spatial understanding) and reasoning covering four clinically relevant scenarios (temporal prediction, causal reasoning, long-tail generalization, multi-source integration); 3) Broad, high-quality data coverage, comprising 20,653 Visual Question Answering (VQA) pairs spanning 11 organ systems and 12 imaging modalities, validated via a rigorous two-stage (human expert + model-assisted) review to ensure clinical authenticity. We evaluate 18 state-of-the-art MLLMs with Med-CMR, revealing GPT-5 as the top-performing commercial model: 57.81 accuracy on multiple-choice questions (MCQs) and a 48.70 open-ended score, outperforming Gemini 2.5 Pro (49.87 MCQ accuracy, 45.98 open-ended score) and leading open-source model Qwen3-VL-235B-A22B (49.34 MCQ accuracy, 42.62 open-ended score). However, specialized medical MLLMs do not reliably outperform strong general models, and long-tail generalization emerges as the dominant failure mode. Med-CMR thus provides a stress test for visual-reasoning integration and rare-case robustness in medical MLLMs, and a rigorous yardstick for future clinical systems.", "AI": {"tldr": "Med-CMR\u662f\u4e00\u4e2a\u7ec6\u7c92\u5ea6\u7684\u533b\u5b66\u590d\u6742\u591a\u6a21\u6001\u63a8\u7406\u57fa\u51c6\uff0c\u901a\u8fc7\u7cfb\u7edf\u80fd\u529b\u5206\u89e3\u3001\u6311\u6218\u6027\u4efb\u52a1\u8bbe\u8ba1\u548c\u9ad8\u8d28\u91cf\u6570\u636e\u8986\u76d6\u6765\u8bc4\u4f30\u533b\u7597MLLMs\u7684\u590d\u6742\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0GPT-5\u8868\u73b0\u6700\u4f73\u4f46\u4e13\u4e1a\u533b\u7597\u6a21\u578b\u672a\u660e\u663e\u4f18\u4e8e\u901a\u7528\u6a21\u578b\u3002", "motivation": "MLLMs\u5f00\u59cb\u5e94\u7528\u4e8e\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\uff0c\u4f46\u5176\u6267\u884c\u590d\u6742\u533b\u5b66\u63a8\u7406\u7684\u80fd\u529b\u5c1a\u4e0d\u6e05\u695a\u3002\u73b0\u6709\u57fa\u51c6\u7f3a\u4e4f\u5bf9\u533b\u5b66\u591a\u6a21\u6001\u63a8\u7406\u7684\u7ec6\u7c92\u5ea6\u8bc4\u4f30\uff0c\u9700\u8981\u66f4\u7cfb\u7edf\u7684\u80fd\u529b\u5206\u89e3\u548c\u66f4\u5177\u6311\u6218\u6027\u7684\u4efb\u52a1\u8bbe\u8ba1\u6765\u51c6\u786e\u8bc4\u4f30\u533b\u7597MLLMs\u7684\u5b9e\u9645\u6027\u80fd\u3002", "method": "1) \u7cfb\u7edf\u80fd\u529b\u5206\u89e3\uff1a\u5c06\u533b\u5b66\u591a\u6a21\u6001\u63a8\u7406\u7ec6\u5206\u4e3a\u89c6\u89c9\u7406\u89e3\u548c\u591a\u6b65\u63a8\u7406\uff1b2) \u6311\u6218\u6027\u4efb\u52a1\u8bbe\u8ba1\uff1a\u89c6\u89c9\u7406\u89e3\u6db5\u76d6\u4e09\u4e2a\u5173\u952e\u7ef4\u5ea6\uff08\u5c0f\u76ee\u6807\u68c0\u6d4b\u3001\u7ec6\u8282\u8fa8\u522b\u3001\u7a7a\u95f4\u7406\u89e3\uff09\uff0c\u63a8\u7406\u6db5\u76d6\u56db\u4e2a\u4e34\u5e8a\u76f8\u5173\u573a\u666f\uff08\u65f6\u95f4\u9884\u6d4b\u3001\u56e0\u679c\u63a8\u7406\u3001\u957f\u5c3e\u6cdb\u5316\u3001\u591a\u6e90\u6574\u5408\uff09\uff1b3) \u9ad8\u8d28\u91cf\u6570\u636e\u8986\u76d6\uff1a\u5305\u542b20,653\u4e2aVQA\u5bf9\uff0c\u6db5\u76d611\u4e2a\u5668\u5b98\u7cfb\u7edf\u548c12\u79cd\u6210\u50cf\u6a21\u6001\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\uff08\u4eba\u7c7b\u4e13\u5bb6+\u6a21\u578b\u8f85\u52a9\uff09\u5ba1\u67e5\u786e\u4fdd\u4e34\u5e8a\u771f\u5b9e\u6027\u3002", "result": "\u8bc4\u4f30\u4e8618\u4e2a\u6700\u5148\u8fdb\u7684MLLMs\uff0cGPT-5\u8868\u73b0\u6700\u4f73\uff1a\u591a\u9879\u9009\u62e9\u9898\u51c6\u786e\u738757.81%\uff0c\u5f00\u653e\u5f0f\u95ee\u9898\u5f97\u520648.70\uff0c\u4f18\u4e8eGemini 2.5 Pro\uff0849.87%\u51c6\u786e\u7387\uff0c45.98\u5206\uff09\u548c\u9886\u5148\u7684\u5f00\u6e90\u6a21\u578bQwen3-VL-235B-A22B\uff0849.34%\u51c6\u786e\u7387\uff0c42.62\u5206\uff09\u3002\u4e13\u4e1a\u533b\u7597MLLMs\u5e76\u672a\u53ef\u9760\u5730\u4f18\u4e8e\u5f3a\u5927\u7684\u901a\u7528\u6a21\u578b\uff0c\u957f\u5c3e\u6cdb\u5316\u6210\u4e3a\u4e3b\u8981\u5931\u8d25\u6a21\u5f0f\u3002", "conclusion": "Med-CMR\u4e3a\u533b\u5b66MLLMs\u7684\u89c6\u89c9-\u63a8\u7406\u6574\u5408\u548c\u7f55\u89c1\u75c5\u4f8b\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u538b\u529b\u6d4b\u8bd5\uff0c\u5e76\u4e3a\u672a\u6765\u4e34\u5e8a\u7cfb\u7edf\u5efa\u7acb\u4e86\u4e25\u683c\u7684\u8bc4\u4f30\u6807\u51c6\u3002\u7814\u7a76\u663e\u793a\u5f53\u524d\u533b\u7597MLLMs\u5728\u590d\u6742\u63a8\u7406\u65b9\u9762\u4ecd\u6709\u5c40\u9650\uff0c\u7279\u522b\u662f\u957f\u5c3e\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u3002"}}
{"id": "2512.01115", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.01115", "abs": "https://arxiv.org/abs/2512.01115", "authors": ["Tao Zhang", "Yevgeniy Vorobeychik"], "title": "Sliced R\u00e9nyi Pufferfish Privacy: Directional Additive Noise Mechanism and Private Learning with Gradient Clipping", "comment": null, "summary": "We study privatization mechanism design and privacy accounting in the Pufferfish family, addressing two practical gaps of Renyi Pufferfish Privacy (RPP): high-dimensional optimal transport (OT) calibration and the absence of a general, mechanism-agnostic composition rule for iterative learning. We introduce Sliced Renyi Pufferfish Privacy (SRPP), which replaces high-dimensional comparisons by directional ones over a set of unit vectors, enabling geometry-aware and tractable guarantees. To calibrate noise without high-dimensional OT, we propose sliced Wasserstein mechanisms that compute per-direction (1-D) sensitivities, yielding closed-form, statistically stable, and anisotropic calibrations. We further define SRPP Envelope (SRPE) as computable upper bounds that are tightly implementable by these sliced Wasserstein mechanisms. For iterative deep learning algorithms, we develop a decompose-then-compose SRPP-SGD scheme with gradient clipping based on a History-Uniform Cap (HUC), a pathwise bound on one-step directional changes that is uniform over optimization history, and a mean-square variant (ms-HUC) that leverages subsampling randomness to obtain on-average SRPP guarantees with improved utility. The resulting HUC and ms-HUC accountants aggregate per-iteration, per-direction Renyi costs and integrate naturally with moments-accountant style analyses. Finally, when multiple mechanisms are trained and privatized independently under a common slicing geometry, our analysis yields graceful additive composition in both worst-case and mean-square regimes. Our experiments indicate that the proposed SRPP-based methods achieve favorable privacy-utility trade-offs in both static and iterative settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5207\u7247Renyi Pufferfish\u9690\u79c1\u6846\u67b6\uff0c\u89e3\u51b3\u9ad8\u7ef4\u6700\u4f18\u4f20\u8f93\u6821\u51c6\u548c\u8fed\u4ee3\u5b66\u4e60\u673a\u5236\u65e0\u5173\u7ec4\u5408\u89c4\u5219\u7f3a\u5931\u95ee\u9898\uff0c\u901a\u8fc7\u5207\u7247Wasserstein\u673a\u5236\u548c\u8def\u5f84\u754c\u5b9e\u73b0\u51e0\u4f55\u611f\u77e5\u7684\u9690\u79c1\u4fdd\u62a4\u3002", "motivation": "\u9488\u5bf9Renyi Pufferfish\u9690\u79c1\u7684\u4e24\u4e2a\u5b9e\u9645\u7f3a\u9677\uff1a\u9ad8\u7ef4\u6700\u4f18\u4f20\u8f93\u6821\u51c6\u7684\u56f0\u96be\u6027\uff0c\u4ee5\u53ca\u7f3a\u4e4f\u901a\u7528\u7684\u673a\u5236\u65e0\u5173\u8fed\u4ee3\u5b66\u4e60\u7ec4\u5408\u89c4\u5219\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u5b9e\u7528\u3001\u53ef\u8ba1\u7b97\u7684\u9690\u79c1\u4fdd\u62a4\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u5207\u7247Renyi Pufferfish\u9690\u79c1\uff0c\u7528\u65b9\u5411\u6027\u6bd4\u8f83\u66ff\u4ee3\u9ad8\u7ef4\u6bd4\u8f83\uff1b\u8bbe\u8ba1\u5207\u7247Wasserstein\u673a\u5236\u8fdb\u884c\u566a\u58f0\u6821\u51c6\uff1b\u5f00\u53d1\u57fa\u4e8e\u5386\u53f2\u5747\u5300\u754c\u7684\u5206\u89e3-\u7ec4\u5408SRPP-SGD\u65b9\u6848\uff0c\u5229\u7528\u68af\u5ea6\u88c1\u526a\u548c\u5b50\u91c7\u6837\u968f\u673a\u6027\u3002", "result": "SRPP\u6846\u67b6\u5b9e\u73b0\u4e86\u51e0\u4f55\u611f\u77e5\u4e14\u53ef\u8ba1\u7b97\u7684\u9690\u79c1\u4fdd\u8bc1\uff1b\u5207\u7247Wasserstein\u673a\u5236\u63d0\u4f9b\u5c01\u95ed\u5f62\u5f0f\u3001\u7edf\u8ba1\u7a33\u5b9a\u548c\u5404\u5411\u5f02\u6027\u6821\u51c6\uff1bHUC\u548cms-HUC\u4f1a\u8ba1\u5e08\u80fd\u805a\u5408\u6bcf\u8fed\u4ee3\u3001\u6bcf\u65b9\u5411\u7684Renyi\u6210\u672c\uff1b\u5728\u9759\u6001\u548c\u8fed\u4ee3\u8bbe\u7f6e\u4e2d\u90fd\u83b7\u5f97\u4f18\u8d8a\u7684\u9690\u79c1-\u6548\u7528\u6743\u8861\u3002", "conclusion": "SRPP\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86RPP\u7684\u5b9e\u9645\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u4e86\u53ef\u8ba1\u7b97\u7684\u9690\u79c1\u4fdd\u8bc1\u548c\u4f18\u96c5\u7684\u7ec4\u5408\u6027\u8d28\uff0c\u5728\u6df1\u5ea6\u5b66\u4e60\u7684\u9690\u79c1\u4fdd\u62a4\u4e2d\u5c55\u73b0\u51fa\u4f18\u8d8a\u7684\u5b9e\u7528\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2512.01609", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.01609", "abs": "https://arxiv.org/abs/2512.01609", "authors": ["Patrick Herter", "Vincent Ahlrichs", "Ridvan A\u00e7ilan", "Julian Horsch"], "title": "GPTrace: Effective Crash Deduplication Using LLM Embeddings", "comment": "Original publication in 2026 IEEE/ACM 48th International Conference on Software Engineering (ICSE '26), April 12-18, 2026, Rio de Janeiro, Brazil. ACM, New York, NY, USA, 12 pages", "summary": "Fuzzing is a highly effective method for uncovering software vulnerabilities, but analyzing the resulting data typically requires substantial manual effort. This is amplified by the fact that fuzzing campaigns often find a large number of crashing inputs, many of which share the same underlying bug. Crash deduplication is the task of finding such duplicate crashing inputs and thereby reducing the data that needs to be examined. Many existing deduplication approaches rely on comparing stack traces or other information that is collected when a program crashes. Although various metrics for measuring the similarity of such pieces of information have been proposed, many do not yield satisfactory deduplication results. In this work, we present GPTrace, a deduplication workflow that leverages a large language model to evaluate the similarity of various data sources associated with crashes by computing embedding vectors and supplying those as input to a clustering algorithm. We evaluate our approach on over 300 000 crashing inputs belonging to 50 ground truth labels from 14 different targets. The deduplication results produced by GPTrace show a noticeable improvement over hand-crafted stack trace comparison methods and even more complex state-of-the-art approaches that are less flexible.", "AI": {"tldr": "GPTrace\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8ba1\u7b97\u5d29\u6e83\u6570\u636e\u5d4c\u5165\u5411\u91cf\uff0c\u901a\u8fc7\u805a\u7c7b\u7b97\u6cd5\u5b9e\u73b0\u5d29\u6e83\u53bb\u91cd\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u6709\u660e\u663e\u6539\u8fdb", "motivation": "\u6a21\u7cca\u6d4b\u8bd5\u53d1\u73b0\u5927\u91cf\u5d29\u6e83\u8f93\u5165\uff0c\u5176\u4e2d\u8bb8\u591a\u5171\u4eab\u76f8\u540c\u5e95\u5c42\u6f0f\u6d1e\uff0c\u4f46\u73b0\u6709\u53bb\u91cd\u65b9\u6cd5\u4f9d\u8d56\u6808\u8ffd\u8e2a\u7b49\u4fe1\u606f\u7684\u76f8\u4f3c\u6027\u6bd4\u8f83\uff0c\u6548\u679c\u4e0d\u7406\u60f3\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u81ea\u52a8\u5316\u53bb\u91cd\u65b9\u6848", "method": "\u63d0\u51faGPTrace\u53bb\u91cd\u5de5\u4f5c\u6d41\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u5404\u79cd\u5d29\u6e83\u6570\u636e\u6e90\u7684\u76f8\u4f3c\u6027\uff0c\u8ba1\u7b97\u5d4c\u5165\u5411\u91cf\uff0c\u5e76\u5c06\u8fd9\u4e9b\u5411\u91cf\u4f5c\u4e3a\u805a\u7c7b\u7b97\u6cd5\u7684\u8f93\u5165", "result": "\u572814\u4e2a\u4e0d\u540c\u76ee\u6807\u768450\u4e2a\u771f\u5b9e\u6807\u7b7e\u3001\u8d85\u8fc730\u4e07\u4e2a\u5d29\u6e83\u8f93\u5165\u4e0a\u8bc4\u4f30\uff0cGPTrace\u7684\u53bb\u91cd\u7ed3\u679c\u660e\u663e\u4f18\u4e8e\u624b\u5de5\u6808\u8ffd\u8e2a\u6bd4\u8f83\u65b9\u6cd5\u548c\u66f4\u590d\u6742\u4f46\u7075\u6d3b\u6027\u8f83\u5dee\u7684\u6700\u65b0\u65b9\u6cd5", "conclusion": "GPTrace\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u548c\u805a\u7c7b\u7b97\u6cd5\u7684\u7ed3\u5408\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5d29\u6e83\u53bb\u91cd\u7684\u6548\u679c\uff0c\u4e3a\u6a21\u7cca\u6d4b\u8bd5\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848"}}
{"id": "2512.00834", "categories": ["cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2512.00834", "abs": "https://arxiv.org/abs/2512.00834", "authors": ["Lin Zhu", "Kezhi Wang", "Luping Xiang", "Kun Yang"], "title": "SemAgent: Semantic-Driven Agentic AI Empowered Trajectory Prediction in Vehicular Networks", "comment": "Submitted for possible journal publication", "summary": "Efficient information exchange and reliable contextual reasoning are essential for vehicle-to-everything (V2X) networks. Conventional communication schemes often incur significant transmission overhead and latency, while existing trajectory prediction models generally lack environmental perception and logical inference capabilities. This paper presents a trajectory prediction framework that integrates semantic communication with Agentic AI to enhance predictive performance in vehicular environments. In vehicle-to-infrastructure (V2I) communication, a feature-extraction agent at the Roadside Unit (RSU) derives compact representations from historical vehicle trajectories, followed by semantic reasoning performed by a semantic-analysis agent. The RSU then transmits both feature representations and semantic insights to the target vehicle via semantic communication, enabling the vehicle to predict future trajectories by combining received semantics with its own historical data. In vehicle-to-vehicle (V2V) communication, each vehicle performs local feature extraction and semantic analysis while receiving predicted trajectories from neighboring vehicles, and jointly utilizes this information for its own trajectory prediction. Extensive experiments across diverse communication conditions demonstrate that the proposed method significantly outperforms baseline schemes, achieving up to a 47.5% improvement in prediction accuracy under low signal-to-noise ratio (SNR) conditions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u8bed\u4e49\u901a\u4fe1\u4e0e\u667a\u80fd\u4f53AI\u7684\u8f68\u8ff9\u9884\u6d4b\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347\u8f66\u8054\u7f51\u73af\u5883\u4e0b\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u5728\u4f4e\u4fe1\u566a\u6bd4\u6761\u4ef6\u4e0b\u9884\u6d4b\u7cbe\u5ea6\u63d0\u5347\u8fbe47.5%\u3002", "motivation": "\u4f20\u7edf\u901a\u4fe1\u65b9\u6848\u5b58\u5728\u4f20\u8f93\u5f00\u9500\u5927\u3001\u5ef6\u8fdf\u9ad8\u7684\u95ee\u9898\uff0c\u73b0\u6709\u8f68\u8ff9\u9884\u6d4b\u6a21\u578b\u7f3a\u4e4f\u73af\u5883\u611f\u77e5\u548c\u903b\u8f91\u63a8\u7406\u80fd\u529b\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u667a\u80fd\u7684\u8f66\u8054\u7f51\u901a\u4fe1\u4e0e\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u8bed\u4e49\u901a\u4fe1\u4e0e\u667a\u80fd\u4f53AI\u7ed3\u5408\u7684\u8f68\u8ff9\u9884\u6d4b\u6846\u67b6\uff1a\u5728V2I\u901a\u4fe1\u4e2d\uff0cRSU\u901a\u8fc7\u7279\u5f81\u63d0\u53d6\u667a\u80fd\u4f53\u4ece\u5386\u53f2\u8f68\u8ff9\u4e2d\u63d0\u53d6\u7d27\u51d1\u8868\u793a\uff0c\u8bed\u4e49\u5206\u6790\u667a\u80fd\u4f53\u8fdb\u884c\u8bed\u4e49\u63a8\u7406\uff0c\u7136\u540e\u5c06\u7279\u5f81\u8868\u793a\u548c\u8bed\u4e49\u6d1e\u5bdf\u4f20\u8f93\u7ed9\u76ee\u6807\u8f66\u8f86\uff1b\u5728V2V\u901a\u4fe1\u4e2d\uff0c\u6bcf\u8f86\u8f66\u8fdb\u884c\u672c\u5730\u7279\u5f81\u63d0\u53d6\u548c\u8bed\u4e49\u5206\u6790\uff0c\u540c\u65f6\u63a5\u6536\u90bb\u8fd1\u8f66\u8f86\u7684\u9884\u6d4b\u8f68\u8ff9\uff0c\u7efc\u5408\u5229\u7528\u8fd9\u4e9b\u4fe1\u606f\u8fdb\u884c\u81ea\u8eab\u8f68\u8ff9\u9884\u6d4b\u3002", "result": "\u5728\u5404\u79cd\u901a\u4fe1\u6761\u4ef6\u4e0b\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6848\uff0c\u5728\u4f4e\u4fe1\u566a\u6bd4\u6761\u4ef6\u4e0b\u9884\u6d4b\u7cbe\u5ea6\u63d0\u5347\u9ad8\u8fbe47.5%\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u901a\u8fc7\u8bed\u4e49\u901a\u4fe1\u4e0e\u667a\u80fd\u4f53AI\u7684\u6709\u6548\u7ed3\u5408\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8f66\u8054\u7f51\u73af\u5883\u4e0b\u7684\u8f68\u8ff9\u9884\u6d4b\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u6076\u52a3\u901a\u4fe1\u6761\u4ef6\u4e0b\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2512.01164", "categories": ["cs.CR", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.01164", "abs": "https://arxiv.org/abs/2512.01164", "authors": ["Yasaswini Konapalli", "Lotfi Ben Othmane", "Cihan Tunc", "Feras Benchellal", "Likhita Mudagere"], "title": "Reverse Engineering and Control-Aware Security Analysis of the ArduPilot UAV Framework", "comment": null, "summary": "Unmanned Aerial Vehicle (UAV) technologies are gaining high interest for many domains, which makes UAV security of utmost importance. ArduPilot is among the most widely used open-source autopilot UAV frameworks; yet, many studies demonstrate the vulnerabilities affecting such systems. Vulnerabilities within its communication subsystems (including WiFi, telemetry, or GPS) expose critical entry points, and vulnerabilities in Ardupilot can affect the control procedure. In this paper, we reconstruct the software architecture and the control models implemented by ArduPilot and then examine how these control models could potentially misused to induce malicious behaviors while relying on legitimate inputs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86ArduPilot\u5f00\u6e90\u65e0\u4eba\u673a\u81ea\u52a8\u9a7e\u9a76\u6846\u67b6\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u91cd\u70b9\u5173\u6ce8\u5176\u63a7\u5236\u6a21\u578b\u5982\u4f55\u88ab\u6076\u610f\u5229\u7528\u6765\u8bf1\u5bfc\u65e0\u4eba\u673a\u5f02\u5e38\u884c\u4e3a\u3002", "motivation": "\u968f\u7740\u65e0\u4eba\u673a\u6280\u672f\u5728\u591a\u4e2a\u9886\u57df\u83b7\u5f97\u9ad8\u5ea6\u5173\u6ce8\uff0c\u65e0\u4eba\u673a\u5b89\u5168\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002ArduPilot\u4f5c\u4e3a\u6700\u5e7f\u6cdb\u4f7f\u7528\u7684\u5f00\u6e90\u81ea\u52a8\u9a7e\u9a76\u6846\u67b6\uff0c\u5b58\u5728\u591a\u79cd\u5df2\u77e5\u6f0f\u6d1e\uff0c\u7279\u522b\u662f\u5728\u901a\u4fe1\u5b50\u7cfb\u7edf\uff08WiFi\u3001\u9065\u6d4b\u3001GPS\uff09\u548c\u63a7\u5236\u7a0b\u5e8f\u65b9\u9762\uff0c\u8fd9\u4e9b\u6f0f\u6d1e\u53ef\u80fd\u6210\u4e3a\u653b\u51fb\u5165\u53e3\u3002", "method": "\u9996\u5148\u91cd\u6784ArduPilot\u7684\u8f6f\u4ef6\u67b6\u6784\u548c\u63a7\u5236\u6a21\u578b\uff0c\u7136\u540e\u5206\u6790\u8fd9\u4e9b\u63a7\u5236\u6a21\u578b\u5982\u4f55\u53ef\u80fd\u88ab\u6ee5\u7528\uff0c\u901a\u8fc7\u5408\u6cd5\u8f93\u5165\u8bf1\u5bfc\u6076\u610f\u884c\u4e3a\u3002", "result": "\u8bba\u6587\u8bc6\u522b\u4e86ArduPilot\u63a7\u5236\u6a21\u578b\u4e2d\u53ef\u80fd\u88ab\u6076\u610f\u5229\u7528\u7684\u6f0f\u6d1e\uff0c\u5c55\u793a\u4e86\u653b\u51fb\u8005\u5982\u4f55\u901a\u8fc7\u770b\u4f3c\u5408\u6cd5\u7684\u8f93\u5165\u64cd\u7eb5\u65e0\u4eba\u673a\u6267\u884c\u5f02\u5e38\u884c\u4e3a\u3002", "conclusion": "ArduPilot\u7684\u63a7\u5236\u6a21\u578b\u5b58\u5728\u5b89\u5168\u98ce\u9669\uff0c\u653b\u51fb\u8005\u53ef\u4ee5\u5229\u7528\u8fd9\u4e9b\u6f0f\u6d1e\u901a\u8fc7\u5408\u6cd5\u8f93\u5165\u8bf1\u5bfc\u6076\u610f\u884c\u4e3a\uff0c\u8fd9\u5f3a\u8c03\u4e86\u65e0\u4eba\u673a\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5b89\u5168\u52a0\u56fa\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2512.01617", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.01617", "abs": "https://arxiv.org/abs/2512.01617", "authors": ["Pierciro Caliandro", "Matteo Ciccaglione", "Alessandro Pellegrini"], "title": "When High-Performance Computing Meets Software Testing: Distributed Fuzzing using MPI", "comment": null, "summary": "This paper explores the integration of MPI-based synchronization techniques into distributed fuzzing frameworks, highlighting possible substantial performance improvements compared to traditional filesystem-based synchronization methods. By employing lightweight MPI primitives, reductions in communication latency are achieved, facilitating more efficient data exchanges across distributed fuzzing nodes. Experimental results obtained over standard benchmarks demonstrate enhanced coverage progression from the early stages of the fuzzing process, which could be beneficial if fuzzing is employed in CI/CD pipelines at any stage of software development. Furthermore, the coordinated exchange of input corpora among clusters of fuzzers effectively addresses coverage stagnation, enabling a sustained exploration of complex and deep execution paths. Overall, the adoption of MPI-based synchronization approaches shows promising potential for significantly enhancing the scalability and efficacy of distributed fuzz testing.", "AI": {"tldr": "\u5c06MPI\u540c\u6b65\u6280\u672f\u96c6\u6210\u5230\u5206\u5e03\u5f0f\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6\u4e2d\uff0c\u76f8\u6bd4\u4f20\u7edf\u6587\u4ef6\u7cfb\u7edf\u540c\u6b65\u65b9\u6cd5\u53ef\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7MPI\u539f\u8bed\u51cf\u5c11\u901a\u4fe1\u5ef6\u8fdf\uff0c\u63d0\u9ad8\u5206\u5e03\u5f0f\u8282\u70b9\u95f4\u7684\u6570\u636e\u4ea4\u6362\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u6587\u4ef6\u7cfb\u7edf\u7684\u5206\u5e03\u5f0f\u6a21\u7cca\u6d4b\u8bd5\u540c\u6b65\u65b9\u6cd5\u5b58\u5728\u901a\u4fe1\u5ef6\u8fdf\u9ad8\u3001\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u6a21\u7cca\u6d4b\u8bd5\u7684\u6269\u5c55\u6027\u548c\u6027\u80fd\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u540c\u6b65\u673a\u5236\u6765\u63d0\u5347\u5206\u5e03\u5f0f\u6a21\u7cca\u6d4b\u8bd5\u7684\u6548\u679c\u3002", "method": "\u91c7\u7528\u57fa\u4e8eMPI\uff08\u6d88\u606f\u4f20\u9012\u63a5\u53e3\uff09\u7684\u540c\u6b65\u6280\u672f\uff0c\u5229\u7528\u8f7b\u91cf\u7ea7MPI\u539f\u8bed\u5b9e\u73b0\u5206\u5e03\u5f0f\u6a21\u7cca\u6d4b\u8bd5\u8282\u70b9\u4e4b\u95f4\u7684\u9ad8\u6548\u6570\u636e\u4ea4\u6362\u548c\u534f\u8c03\uff0c\u66ff\u4ee3\u4f20\u7edf\u7684\u6587\u4ef6\u7cfb\u7edf\u540c\u6b65\u65b9\u6cd5\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMPI\u540c\u6b65\u65b9\u6cd5\u4ece\u6a21\u7cca\u6d4b\u8bd5\u65e9\u671f\u9636\u6bb5\u5c31\u663e\u793a\u51fa\u66f4\u597d\u7684\u8986\u76d6\u7387\u8fdb\u5c55\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8986\u76d6\u7387\u505c\u6ede\u95ee\u9898\uff0c\u80fd\u591f\u6301\u7eed\u63a2\u7d22\u590d\u6742\u548c\u6df1\u5c42\u7684\u6267\u884c\u8def\u5f84\u3002", "conclusion": "MPI\u540c\u6b65\u65b9\u6cd5\u5728\u5206\u5e03\u5f0f\u6a21\u7cca\u6d4b\u8bd5\u4e2d\u5c55\u73b0\u51fa\u663e\u8457\u63d0\u5347\u6269\u5c55\u6027\u548c\u6548\u80fd\u7684\u6f5c\u529b\uff0c\u7279\u522b\u9002\u7528\u4e8eCI/CD\u6d41\u6c34\u7ebf\u4e2d\u7684\u6a21\u7cca\u6d4b\u8bd5\u5e94\u7528\u3002"}}
{"id": "2512.00836", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00836", "abs": "https://arxiv.org/abs/2512.00836", "authors": ["Emily Howerton", "Justin Lessler"], "title": "Assessing model error in counterfactual worlds", "comment": null, "summary": "Counterfactual scenario modeling exercises that ask \"what would happen if?\" are one of the most common ways we plan for the future. Despite their ubiquity in planning and decision making, scenario projections are rarely evaluated retrospectively. Differences between projections and observations come from two sources: scenario deviation and model miscalibration. We argue the latter is most important for assessing the value of models in decision making, but requires estimating model error in counterfactual worlds. Here we present and contrast three approaches for estimating this error, and demonstrate the benefits and limitations of each in a simulation experiment. We provide recommendations for the estimation of counterfactual error and discuss the components of scenario design that are required to make scenario projections evaluable.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e09\u79cd\u8bc4\u4f30\u53cd\u4e8b\u5b9e\u573a\u666f\u5efa\u6a21\u4e2d\u6a21\u578b\u8bef\u5dee\u7684\u65b9\u6cd5\uff0c\u5f3a\u8c03\u6a21\u578b\u6821\u51c6\u8bef\u5dee\u6bd4\u573a\u666f\u504f\u5dee\u5bf9\u51b3\u7b56\u66f4\u91cd\u8981\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u5b9e\u9a8c\u9a8c\u8bc1\u5404\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\u3002", "motivation": "\u53cd\u4e8b\u5b9e\u573a\u666f\u5efa\u6a21\u662f\u672a\u6765\u89c4\u5212\u4e2d\u5e38\u7528\u7684\u65b9\u6cd5\uff0c\u4f46\u5f88\u5c11\u8fdb\u884c\u56de\u987e\u6027\u8bc4\u4f30\u3002\u89c2\u6d4b\u503c\u4e0e\u9884\u6d4b\u503c\u4e4b\u95f4\u7684\u5dee\u5f02\u6765\u81ea\u573a\u666f\u504f\u5dee\u548c\u6a21\u578b\u6821\u51c6\u8bef\u5dee\uff0c\u4f5c\u8005\u8ba4\u4e3a\u540e\u8005\u5bf9\u8bc4\u4f30\u6a21\u578b\u5728\u51b3\u7b56\u4e2d\u7684\u4ef7\u503c\u66f4\u4e3a\u91cd\u8981\uff0c\u4f46\u9700\u8981\u5728\u53cd\u4e8b\u5b9e\u4e16\u754c\u4e2d\u4f30\u8ba1\u6a21\u578b\u8bef\u5dee\u3002", "method": "\u63d0\u51fa\u5e76\u5bf9\u6bd4\u4e09\u79cd\u4f30\u8ba1\u53cd\u4e8b\u5b9e\u8bef\u5dee\u7684\u65b9\u6cd5\uff1a1\uff09\u4f7f\u7528\u5386\u53f2\u6570\u636e\u8fdb\u884c\u6a21\u578b\u6821\u51c6\uff1b2\uff09\u5229\u7528\u7c7b\u4f3c\u573a\u666f\u7684\u89c2\u6d4b\u6570\u636e\uff1b3\uff09\u57fa\u4e8e\u6a21\u578b\u7ed3\u6784\u5047\u8bbe\u8fdb\u884c\u63a8\u65ad\u3002\u901a\u8fc7\u6a21\u62df\u5b9e\u9a8c\u5c55\u793a\u6bcf\u79cd\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\u3002", "result": "\u6a21\u62df\u5b9e\u9a8c\u8868\u660e\uff0c\u4e09\u79cd\u65b9\u6cd5\u5404\u6709\u4f18\u52bf\u548c\u5c40\u9650\u6027\u3002\u7b2c\u4e00\u79cd\u65b9\u6cd5\u5728\u5386\u53f2\u6570\u636e\u5145\u8db3\u65f6\u6548\u679c\u6700\u597d\uff0c\u7b2c\u4e8c\u79cd\u65b9\u6cd5\u9700\u8981\u7c7b\u4f3c\u573a\u666f\u6570\u636e\uff0c\u7b2c\u4e09\u79cd\u65b9\u6cd5\u5bf9\u6a21\u578b\u5047\u8bbe\u654f\u611f\u3002\u7814\u7a76\u63d0\u4f9b\u4e86\u53cd\u4e8b\u5b9e\u8bef\u5dee\u4f30\u8ba1\u7684\u5177\u4f53\u5efa\u8bae\u3002", "conclusion": "\u4e3a\u4e86\u8bc4\u4f30\u573a\u666f\u9884\u6d4b\uff0c\u9700\u8981\u8bbe\u8ba1\u53ef\u8bc4\u4f30\u7684\u573a\u666f\uff0c\u5e76\u533a\u5206\u573a\u666f\u504f\u5dee\u548c\u6a21\u578b\u6821\u51c6\u8bef\u5dee\u3002\u8bba\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u6846\u67b6\u6709\u52a9\u4e8e\u63d0\u9ad8\u53cd\u4e8b\u5b9e\u5efa\u6a21\u5728\u51b3\u7b56\u4e2d\u7684\u5b9e\u7528\u4ef7\u503c\uff0c\u4e3a\u672a\u6765\u573a\u666f\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6307\u5bfc\u539f\u5219\u3002"}}
{"id": "2512.01185", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.01185", "abs": "https://arxiv.org/abs/2512.01185", "authors": ["Zihao Wang", "Kar Wai Fok", "Vrizlynn L. L. Thing"], "title": "DefenSee: Dissecting Threat from Sight and Text - A Multi-View Defensive Pipeline for Multi-modal Jailbreaks", "comment": null, "summary": "Multi-modal large language models (MLLMs), capable of processing text, images, and audio, have been widely adopted in various AI applications. However, recent MLLMs integrating images and text remain highly vulnerable to coordinated jailbreaks. Existing defenses primarily focus on the text, lacking robust multi-modal protection. As a result, studies indicate that MLLMs are more susceptible to malicious or unsafe instructions, unlike their text-only counterparts. In this paper, we proposed DefenSee, a robust and lightweight multi-modal black-box defense technique that leverages image variants transcription and cross-modal consistency checks, mimicking human judgment. Experiments on popular multi-modal jailbreak and benign datasets show that DefenSee consistently enhances MLLM robustness while better preserving performance on benign tasks compared to SOTA defenses. It reduces the ASR of jailbreak attacks to below 1.70% on MiniGPT4 using the MM-SafetyBench benchmark, significantly outperforming prior methods under the same conditions.", "AI": {"tldr": "DefenSee\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u591a\u6a21\u6001\u9ed1\u76d2\u9632\u5fa1\u6280\u672f\uff0c\u901a\u8fc7\u56fe\u50cf\u53d8\u4f53\u8f6c\u5f55\u548c\u8de8\u6a21\u6001\u4e00\u81f4\u6027\u68c0\u67e5\u6765\u589e\u5f3a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u534f\u540c\u8d8a\u72f1\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u867d\u7136\u80fd\u5904\u7406\u6587\u672c\u3001\u56fe\u50cf\u548c\u97f3\u9891\uff0c\u4f46\u5728\u96c6\u6210\u56fe\u50cf\u548c\u6587\u672c\u65f6\u5bf9\u534f\u540c\u8d8a\u72f1\u653b\u51fb\u9ad8\u5ea6\u8106\u5f31\u3002\u73b0\u6709\u9632\u5fa1\u4e3b\u8981\u5173\u6ce8\u6587\u672c\u6a21\u6001\uff0c\u7f3a\u4e4f\u6709\u6548\u7684\u591a\u6a21\u6001\u4fdd\u62a4\u673a\u5236\uff0c\u5bfc\u81f4MLLMs\u6bd4\u7eaf\u6587\u672c\u6a21\u578b\u66f4\u5bb9\u6613\u53d7\u5230\u6076\u610f\u6216\u4e0d\u5b89\u5168\u6307\u4ee4\u7684\u653b\u51fb\u3002", "method": "\u63d0\u51faDefenSee\u9632\u5fa1\u6280\u672f\uff0c\u91c7\u7528\u56fe\u50cf\u53d8\u4f53\u8f6c\u5f55\u548c\u8de8\u6a21\u6001\u4e00\u81f4\u6027\u68c0\u67e5\u7684\u65b9\u6cd5\u3002\u901a\u8fc7\u751f\u6210\u56fe\u50cf\u7684\u4e0d\u540c\u53d8\u4f53\u5e76\u8fdb\u884c\u8f6c\u5f55\uff0c\u7136\u540e\u68c0\u67e5\u4e0d\u540c\u6a21\u6001\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\uff0c\u6a21\u62df\u4eba\u7c7b\u5224\u65ad\u8fc7\u7a0b\u6765\u68c0\u6d4b\u6076\u610f\u5185\u5bb9\u3002", "result": "\u5728\u6d41\u884c\u7684\u591a\u6a21\u6001\u8d8a\u72f1\u548c\u826f\u6027\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDefenSee\u80fd\u6301\u7eed\u589e\u5f3aMLLM\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u5728\u826f\u6027\u4efb\u52a1\u4e0a\u6bd4\u6700\u5148\u8fdb\u9632\u5fa1\u65b9\u6cd5\u66f4\u597d\u5730\u4fdd\u6301\u6027\u80fd\u3002\u5728MM-SafetyBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5c06MiniGPT4\u7684\u8d8a\u72f1\u653b\u51fb\u6210\u529f\u7387\u964d\u81f31.70%\u4ee5\u4e0b\uff0c\u663e\u8457\u4f18\u4e8e\u540c\u7c7b\u65b9\u6cd5\u3002", "conclusion": "DefenSee\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u8f7b\u91cf\u7ea7\u7684\u591a\u6a21\u6001\u9632\u5fa1\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u8de8\u6a21\u6001\u4e00\u81f4\u6027\u68c0\u67e5\u673a\u5236\u663e\u8457\u63d0\u9ad8\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u534f\u540c\u8d8a\u72f1\u653b\u51fb\u7684\u62b5\u6297\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u826f\u6027\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2512.01630", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.01630", "abs": "https://arxiv.org/abs/2512.01630", "authors": ["Ziheng Liu", "Runzhi He", "Minghui Zhou"], "title": "Package Dashboard: A Cross-Ecosystem Framework for Dual-Perspective Analysis of Software Packages", "comment": null, "summary": "Software supply chain attacks have revealed blind spots in existing SCA tools, which are often limited to a single ecosystem and assess either software artifacts or community activity in isolation. This fragmentation across tools and ecosystems forces developers to manually reconcile scattered data, undermining risk assessments. We present Package Dashboard, a cross-ecosystem framework that provides a unified platform for supply chain analysis, enabling a holistic, dual-perspective risk assessment by integrating package metadata, vulnerability information, and upstream community health metrics. By combining dependency resolution with repository analysis, it reduces cognitive load and improves traceability. Demonstrating the framework's versatility, a large-scale study of 374,000 packages across five Linux distributions shows its ability to uncover not only conventional vulnerabilities and license conflicts but also overlooked risks such as archived or inaccessible repositories. Ultimately, Package Dashboard provides a unified view of risk, equipping developers and DevSecOps engineers with actionable insights to strengthen the transparency, trustworthiness, and traceability of open-source ecosystems. Package Dashboard is publicly available at https://github.com/n19htfall/PackageDashboard, and a demonstration video can be found at https://youtu.be/y9ncftP8KPQ. Besides, the online version is available at https://pkgdash.osslab-pku.org.", "AI": {"tldr": "Package Dashboard\u662f\u4e00\u4e2a\u8de8\u751f\u6001\u7cfb\u7edf\u7684\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u5305\u5143\u6570\u636e\u3001\u6f0f\u6d1e\u4fe1\u606f\u548c\u4e0a\u6e38\u793e\u533a\u5065\u5eb7\u6307\u6807\uff0c\u63d0\u4f9b\u7edf\u4e00\u7684\u98ce\u9669\u8bc4\u4f30\u5e73\u53f0\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u53d1\u73b0\u4f20\u7edf\u5de5\u5177\u5ffd\u89c6\u7684\u98ce\u9669\u3002", "motivation": "\u73b0\u6709\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5206\u6790\u5de5\u5177\u5b58\u5728\u5c40\u9650\u6027\uff1a\u901a\u5e38\u5c40\u9650\u4e8e\u5355\u4e00\u751f\u6001\u7cfb\u7edf\uff0c\u4e14\u5b64\u7acb\u5730\u8bc4\u4f30\u8f6f\u4ef6\u5236\u54c1\u6216\u793e\u533a\u6d3b\u52a8\u3002\u8fd9\u79cd\u788e\u7247\u5316\u8feb\u4f7f\u5f00\u53d1\u8005\u624b\u52a8\u6574\u5408\u5206\u6563\u7684\u6570\u636e\uff0c\u5f71\u54cd\u4e86\u98ce\u9669\u8bc4\u4f30\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51faPackage Dashboard\u6846\u67b6\uff0c\u6574\u5408\u5305\u5143\u6570\u636e\u3001\u6f0f\u6d1e\u4fe1\u606f\u548c\u4e0a\u6e38\u793e\u533a\u5065\u5eb7\u6307\u6807\uff0c\u7ed3\u5408\u4f9d\u8d56\u89e3\u6790\u548c\u4ed3\u5e93\u5206\u6790\uff0c\u63d0\u4f9b\u7edf\u4e00\u7684\u53cc\u89c6\u89d2\u98ce\u9669\u8bc4\u4f30\u5e73\u53f0\u3002", "result": "\u901a\u8fc7\u5bf95\u4e2aLinux\u53d1\u884c\u7248\u4e2d374,000\u4e2a\u5305\u7684\u5927\u89c4\u6a21\u7814\u7a76\uff0c\u8bc1\u660e\u4e86\u6846\u67b6\u7684\u5b9e\u7528\u6027\uff0c\u4e0d\u4ec5\u80fd\u53d1\u73b0\u4f20\u7edf\u6f0f\u6d1e\u548c\u8bb8\u53ef\u8bc1\u51b2\u7a81\uff0c\u8fd8\u80fd\u8bc6\u522b\u5f52\u6863\u6216\u4e0d\u53ef\u8bbf\u95ee\u4ed3\u5e93\u7b49\u88ab\u5ffd\u89c6\u7684\u98ce\u9669\u3002", "conclusion": "Package Dashboard\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u98ce\u9669\u89c6\u56fe\uff0c\u4e3a\u5f00\u53d1\u8005\u548cDevSecOps\u5de5\u7a0b\u5e08\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\uff0c\u589e\u5f3a\u4e86\u5f00\u6e90\u751f\u6001\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u3001\u53ef\u4fe1\u5ea6\u548c\u53ef\u8ffd\u6eaf\u6027\u3002"}}
{"id": "2512.00839", "categories": ["cs.AI", "stat.CO", "stat.ME"], "pdf": "https://arxiv.org/pdf/2512.00839", "abs": "https://arxiv.org/abs/2512.00839", "authors": ["Fabrizio Maturo", "Donato Riccio", "Andrea Mazzitelli", "Giuseppe Bifulco", "Francesco Paolone", "Iulia Brezeanu"], "title": "ARCADIA: Scalable Causal Discovery for Corporate Bankruptcy Analysis Using Agentic AI", "comment": "35 pages, 9 figures, 4 tables", "summary": "This paper introduces ARCADIA, an agentic AI framework for causal discovery that integrates large-language-model reasoning with statistical diagnostics to construct valid, temporally coherent causal structures. Unlike traditional algorithms, ARCADIA iteratively refines candidate DAGs through constraint-guided prompting and causal-validity feedback, leading to stable and interpretable models for real-world high-stakes domains. Experiments on corporate bankruptcy data show that ARCADIA produces more reliable causal graphs than NOTEARS, GOLEM, and DirectLiNGAM while offering a fully explainable, intervention-ready pipeline. The framework advances AI by demonstrating how agentic LLMs can participate in autonomous scientific modeling and structured causal inference.", "AI": {"tldr": "ARCADIA\u662f\u4e00\u4e2a\u7528\u4e8e\u56e0\u679c\u53d1\u73b0\u7684\u667a\u80fdAI\u6846\u67b6\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4e0e\u7edf\u8ba1\u8bca\u65ad\uff0c\u901a\u8fc7\u8fed\u4ee3\u4f18\u5316\u6784\u5efa\u6709\u6548\u3001\u65f6\u5e8f\u4e00\u81f4\u7684\u56e0\u679c\u7ed3\u6784\uff0c\u5728\u771f\u5b9e\u9ad8\u98ce\u9669\u9886\u57df\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u7b97\u6cd5\u3002", "motivation": "\u4f20\u7edf\u56e0\u679c\u53d1\u73b0\u7b97\u6cd5\u5728\u9ad8\u98ce\u9669\u73b0\u5b9e\u9886\u57df\u5e94\u7528\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u53ef\u9760\u3001\u53ef\u89e3\u91ca\u4e14\u80fd\u5904\u7406\u590d\u6742\u65f6\u5e8f\u5173\u7cfb\u7684\u56e0\u679c\u5efa\u6a21\u65b9\u6cd5\u3002ARCADIA\u65e8\u5728\u901a\u8fc7\u667a\u80fdAI\u6846\u67b6\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u53c2\u4e0e\u81ea\u4e3b\u79d1\u5b66\u5efa\u6a21\u548c\u7ed3\u6784\u5316\u56e0\u679c\u63a8\u7406\u3002", "method": "ARCADIA\u91c7\u7528\u667a\u80fdAI\u6846\u67b6\uff0c\u6574\u5408\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4e0e\u7edf\u8ba1\u8bca\u65ad\uff0c\u901a\u8fc7\u7ea6\u675f\u5f15\u5bfc\u63d0\u793a\u548c\u56e0\u679c\u6709\u6548\u6027\u53cd\u9988\u8fed\u4ee3\u4f18\u5316\u5019\u9009\u6709\u5411\u65e0\u73af\u56fe\uff0c\u6784\u5efa\u7a33\u5b9a\u4e14\u53ef\u89e3\u91ca\u7684\u56e0\u679c\u6a21\u578b\u3002", "result": "\u5728\u4f01\u4e1a\u7834\u4ea7\u6570\u636e\u5b9e\u9a8c\u4e2d\uff0cARCADIA\u6bd4NOTEARS\u3001GOLEM\u548cDirectLiNGAM\u4ea7\u751f\u66f4\u53ef\u9760\u7684\u56e0\u679c\u56fe\uff0c\u540c\u65f6\u63d0\u4f9b\u5b8c\u5168\u53ef\u89e3\u91ca\u3001\u652f\u6301\u5e72\u9884\u7684\u5b8c\u6574\u6d41\u7a0b\u3002", "conclusion": "ARCADIA\u6846\u67b6\u5c55\u793a\u4e86\u667a\u80fd\u5927\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u53c2\u4e0e\u81ea\u4e3b\u79d1\u5b66\u5efa\u6a21\u548c\u7ed3\u6784\u5316\u56e0\u679c\u63a8\u7406\uff0c\u63a8\u52a8\u4e86AI\u5728\u56e0\u679c\u53d1\u73b0\u9886\u57df\u7684\u53d1\u5c55\uff0c\u4e3a\u9ad8\u98ce\u9669\u73b0\u5b9e\u9886\u57df\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u3001\u53ef\u89e3\u91ca\u7684\u56e0\u679c\u5efa\u6a21\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.01649", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.01649", "abs": "https://arxiv.org/abs/2512.01649", "authors": ["Daniel Strassler", "Gabe Elkin", "Curran Schiefelbein", "Daniel Herring", "Ian Jessen", "David Johnson", "Santiago A. Paredes", "Tod Shannon", "Jim Flavin"], "title": "MIT Lincoln Laboratory: A Case Study on Improving Software Support for Research Projects", "comment": "Strassler, D., et al. MIT Lincoln Laboratory: A Case Study on Improving Software Support for Research Projects. Zenodo, 2025, https://doi.org/10.5281/zenodo.16878161", "summary": "Software plays an ever increasing role in complex system development and prototyping, and in recent years, MIT Lincoln Laboratory has sought to improve both the effectiveness and culture surrounding software engineering in execution of its mission. The Homeland Protection and Air Traffic Control Division conducted an internal study to examine challenges to effective and efficient research software development, and to identify ways to strengthen both the culture and execution for greater impact on our mission. Key findings of this study fell into three main categories: project attributes that influence how software development activities must be conducted and managed, potential efficiencies from centralization, opportunities to improve staffing and culture with respect to software practitioners. The study delivered actionable recommendations, including centralizing and standardizing software support tooling, developing a common database to help match the right software talent and needs to projects, and creating a software stakeholder panel to assist with continued improvement.", "AI": {"tldr": "\u6797\u80af\u5b9e\u9a8c\u5ba4\u7814\u7a76\u8f6f\u4ef6\u5de5\u7a0b\u6311\u6218\uff0c\u63d0\u51fa\u6539\u8fdb\u8f6f\u4ef6\u5f00\u53d1\u548c\u6587\u5316\u7684\u5efa\u8bae", "motivation": "\u8f6f\u4ef6\u5728\u590d\u6742\u7cfb\u7edf\u5f00\u53d1\u548c\u539f\u578b\u8bbe\u8ba1\u4e2d\u4f5c\u7528\u65e5\u76ca\u91cd\u8981\uff0c\u6797\u80af\u5b9e\u9a8c\u5ba4\u5e0c\u671b\u6539\u8fdb\u8f6f\u4ef6\u5de5\u7a0b\u7684\u6709\u6548\u6027\u548c\u6587\u5316\uff0c\u4ee5\u66f4\u597d\u5730\u6267\u884c\u5176\u4f7f\u547d", "method": "\u56fd\u571f\u4fdd\u62a4\u4e0e\u7a7a\u4e2d\u4ea4\u901a\u7ba1\u5236\u90e8\u95e8\u8fdb\u884c\u5185\u90e8\u7814\u7a76\uff0c\u5206\u6790\u7814\u7a76\u8f6f\u4ef6\u5f00\u53d1\u9762\u4e34\u7684\u6311\u6218\uff0c\u8bc6\u522b\u52a0\u5f3a\u6587\u5316\u548c\u6267\u884c\u7684\u65b9\u6cd5", "result": "\u7814\u7a76\u53d1\u73b0\u5206\u4e3a\u4e09\u7c7b\uff1a\u5f71\u54cd\u8f6f\u4ef6\u5f00\u53d1\u6d3b\u52a8\u7684\u9879\u76ee\u5c5e\u6027\u3001\u96c6\u4e2d\u5316\u5e26\u6765\u7684\u6f5c\u5728\u6548\u7387\u3001\u6539\u8fdb\u8f6f\u4ef6\u4ece\u4e1a\u8005\u4eba\u5458\u914d\u7f6e\u548c\u6587\u5316\u7684\u673a\u4f1a", "conclusion": "\u7814\u7a76\u63d0\u51fa\u53ef\u64cd\u4f5c\u5efa\u8bae\uff1a\u96c6\u4e2d\u5316\u548c\u6807\u51c6\u5316\u8f6f\u4ef6\u652f\u6301\u5de5\u5177\u3001\u5f00\u53d1\u901a\u7528\u6570\u636e\u5e93\u5339\u914d\u8f6f\u4ef6\u4eba\u624d\u4e0e\u9879\u76ee\u9700\u6c42\u3001\u521b\u5efa\u8f6f\u4ef6\u5229\u76ca\u76f8\u5173\u8005\u5c0f\u7ec4\u4ee5\u6301\u7eed\u6539\u8fdb"}}
{"id": "2512.00852", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.00852", "abs": "https://arxiv.org/abs/2512.00852", "authors": ["Yandong Sun", "Qiang Huang", "Ziwei Xu", "Yiqun Sun", "Yixuan Tang", "Anthony K. H. Tung"], "title": "One Swallow Does Not Make a Summer: Understanding Semantic Structures in Embedding Spaces", "comment": null, "summary": "Embedding spaces are fundamental to modern AI, translating raw data into high-dimensional vectors that encode rich semantic relationships. Yet, their internal structures remain opaque, with existing approaches often sacrificing semantic coherence for structural regularity or incurring high computational overhead to improve interpretability. To address these challenges, we introduce the Semantic Field Subspace (SFS), a geometry-preserving, context-aware representation that captures local semantic neighborhoods within the embedding space. We also propose SAFARI (SemAntic Field subspAce deteRmInation), an unsupervised, modality-agnostic algorithm that uncovers hierarchical semantic structures using a novel metric called Semantic Shift, which quantifies how semantics evolve as SFSes evolve. To ensure scalability, we develop an efficient approximation of Semantic Shift that replaces costly SVD computations, achieving a 15~30x speedup with average errors below 0.01. Extensive evaluations across six real-world text and image datasets show that SFSes outperform standard classifiers not only in classification but also in nuanced tasks such as political bias detection, while SAFARI consistently reveals interpretable and generalizable semantic hierarchies. This work presents a unified framework for structuring, analyzing, and scaling semantic understanding in embedding spaces.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u8bed\u4e49\u573a\u5b50\u7a7a\u95f4(SFS)\u548cSAFARI\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u6355\u6349\u5c40\u90e8\u8bed\u4e49\u90bb\u57df\u5e76\u53d1\u73b0\u5c42\u6b21\u5316\u8bed\u4e49\u7ed3\u6784\uff0c\u540c\u65f6\u901a\u8fc7\u9ad8\u6548\u8fd1\u4f3c\u5b9e\u73b015~30\u500d\u52a0\u901f\u3002", "motivation": "\u5d4c\u5165\u7a7a\u95f4\u662f\u73b0\u4ee3AI\u7684\u57fa\u7840\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u727a\u7272\u8bed\u4e49\u8fde\u8d2f\u6027\u6765\u83b7\u5f97\u7ed3\u6784\u89c4\u5f8b\u6027\uff0c\u6216\u8005\u4e3a\u63d0\u5347\u53ef\u89e3\u91ca\u6027\u800c\u5e26\u6765\u9ad8\u8ba1\u7b97\u5f00\u9500\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u51e0\u4f55\u7ed3\u6784\u53c8\u80fd\u6355\u6349\u8bed\u4e49\u5173\u7cfb\u7684\u8868\u793a\u65b9\u6cd5\u3002", "method": "1. \u5f15\u5165\u8bed\u4e49\u573a\u5b50\u7a7a\u95f4(SFS)\uff1a\u4e00\u79cd\u4fdd\u6301\u51e0\u4f55\u7ed3\u6784\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u8868\u793a\uff0c\u6355\u6349\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u5c40\u90e8\u8bed\u4e49\u90bb\u57df\n2. \u63d0\u51faSAFARI\u7b97\u6cd5\uff1a\u65e0\u76d1\u7763\u3001\u6a21\u6001\u65e0\u5173\u7684\u7b97\u6cd5\uff0c\u4f7f\u7528\u65b0\u9896\u7684\"\u8bed\u4e49\u504f\u79fb\"\u5ea6\u91cf\u6765\u53d1\u73b0\u5c42\u6b21\u5316\u8bed\u4e49\u7ed3\u6784\n3. \u5f00\u53d1\u9ad8\u6548\u8fd1\u4f3c\u65b9\u6cd5\uff1a\u66ff\u4ee3\u6602\u8d35\u7684SVD\u8ba1\u7b97\uff0c\u5b9e\u73b015~30\u500d\u52a0\u901f\uff0c\u5e73\u5747\u8bef\u5dee\u4f4e\u4e8e0.01", "result": "\u57286\u4e2a\u771f\u5b9e\u4e16\u754c\u7684\u6587\u672c\u548c\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u663e\u793a\uff1aSFS\u5728\u5206\u7c7b\u4efb\u52a1\u4e0a\u4f18\u4e8e\u6807\u51c6\u5206\u7c7b\u5668\uff0c\u5728\u653f\u6cbb\u504f\u89c1\u68c0\u6d4b\u7b49\u7ec6\u5fae\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u597d\uff1bSAFARI\u59cb\u7ec8\u80fd\u63ed\u793a\u53ef\u89e3\u91ca\u4e14\u53ef\u6cdb\u5316\u7684\u8bed\u4e49\u5c42\u6b21\u7ed3\u6784\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u7ed3\u6784\u5316\u3001\u5206\u6790\u548c\u6269\u5c55\u8bed\u4e49\u7406\u89e3\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u8bed\u4e49\u8fde\u8d2f\u6027\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2512.01247", "categories": ["cs.CR", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2512.01247", "abs": "https://arxiv.org/abs/2512.01247", "authors": ["Yiluo Wei", "Peixian Zhang", "Gareth Tyson"], "title": "Benchmarking and Understanding Safety Risks in AI Character Platforms", "comment": "Accepted to NDSS '26: The Network and Distributed System Security Symposium 2026", "summary": "AI character platforms, which allow users to engage in conversations with AI personas, are a rapidly growing application domain. However, their immersive and personalized nature, combined with technical vulnerabilities, raises significant safety concerns. Despite their popularity, a systematic evaluation of their safety has been notably absent. To address this gap, we conduct the first large-scale safety study of AI character platforms, evaluating 16 popular platforms using a benchmark set of 5,000 questions across 16 safety categories. Our findings reveal a critical safety deficit: AI character platforms exhibit an average unsafe response rate of 65.1%, substantially higher than the 17.7% average rate of the baselines. We further discover that safety performance varies significantly across different characters and is strongly correlated with character features such as demographics and personality. Leveraging these insights, we demonstrate that our machine learning model is able identify less safe characters with an F1-score of 0.81. This predictive capability can be beneficial for platforms, enabling improved mechanisms for safer interactions, character search/recommendations, and character creation. Overall, the results and findings offer valuable insights for enhancing platform governance and content moderation for safer AI character platforms.", "AI": {"tldr": "\u5bf916\u4e2aAI\u89d2\u8272\u5e73\u53f0\u7684\u5927\u89c4\u6a21\u5b89\u5168\u8bc4\u4f30\u663e\u793a\uff0c\u8fd9\u4e9b\u5e73\u53f0\u5e73\u5747\u4e0d\u5b89\u5168\u56de\u590d\u7387\u9ad8\u8fbe65.1%\uff0c\u8fdc\u8d85\u57fa\u7ebf\u7cfb\u7edf\u768417.7%\uff0c\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u9690\u60a3\u3002", "motivation": "AI\u89d2\u8272\u5e73\u53f0\u5141\u8bb8\u7528\u6237\u4e0eAI\u89d2\u8272\u5bf9\u8bdd\uff0c\u5e94\u7528\u5feb\u901f\u589e\u957f\uff0c\u4f46\u5176\u6c89\u6d78\u5f0f\u3001\u4e2a\u6027\u5316\u7684\u7279\u6027\u7ed3\u5408\u6280\u672f\u6f0f\u6d1e\u5f15\u53d1\u4e86\u4e25\u91cd\u7684\u5b89\u5168\u62c5\u5fe7\u3002\u5c3d\u7ba1\u8fd9\u4e9b\u5e73\u53f0\u5f88\u53d7\u6b22\u8fce\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u5b89\u5168\u8bc4\u4f30\u3002", "method": "\u5bf916\u4e2a\u6d41\u884c\u7684AI\u89d2\u8272\u5e73\u53f0\u8fdb\u884c\u4e86\u9996\u6b21\u5927\u89c4\u6a21\u5b89\u5168\u7814\u7a76\uff0c\u4f7f\u7528\u5305\u542b16\u4e2a\u5b89\u5168\u7c7b\u522b\u76845,000\u4e2a\u95ee\u9898\u57fa\u51c6\u96c6\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u5206\u6790\u4e86\u89d2\u8272\u7279\u5f81\uff08\u5982\u4eba\u53e3\u7edf\u8ba1\u5b66\u548c\u4e2a\u6027\uff09\u4e0e\u5b89\u5168\u6027\u80fd\u7684\u76f8\u5173\u6027\u3002", "result": "AI\u89d2\u8272\u5e73\u53f0\u5e73\u5747\u4e0d\u5b89\u5168\u56de\u590d\u7387\u4e3a65.1%\uff0c\u663e\u8457\u9ad8\u4e8e\u57fa\u7ebf\u7cfb\u7edf\u768417.7%\uff1b\u5b89\u5168\u6027\u80fd\u5728\u4e0d\u540c\u89d2\u8272\u95f4\u5dee\u5f02\u5f88\u5927\uff0c\u4e14\u4e0e\u89d2\u8272\u7279\u5f81\uff08\u5982\u4eba\u53e3\u7edf\u8ba1\u5b66\u548c\u4e2a\u6027\uff09\u5f3a\u76f8\u5173\uff1b\u673a\u5668\u5b66\u4e60\u6a21\u578b\u80fd\u4ee50.81\u7684F1\u5206\u6570\u8bc6\u522b\u8f83\u4e0d\u5b89\u5168\u7684\u89d2\u8272\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86AI\u89d2\u8272\u5e73\u53f0\u5b58\u5728\u4e25\u91cd\u7684\u5b89\u5168\u7f3a\u9677\uff0c\u4f46\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u4e0d\u5b89\u5168\u89d2\u8272\u7684\u80fd\u529b\u53ef\u4e3a\u5e73\u53f0\u63d0\u4f9b\u6539\u8fdb\u673a\u5236\uff0c\u5305\u62ec\u66f4\u5b89\u5168\u7684\u4ea4\u4e92\u3001\u89d2\u8272\u641c\u7d22/\u63a8\u8350\u548c\u89d2\u8272\u521b\u5efa\uff0c\u4e3a\u5e73\u53f0\u6cbb\u7406\u548c\u5185\u5bb9\u5ba1\u6838\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2512.01690", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.01690", "abs": "https://arxiv.org/abs/2512.01690", "authors": ["Philip Garrett", "Juan P. Galeotti", "Andrea Arcuri", "Alexander Poth", "Olsi Rrjolli"], "title": "Generating REST API Tests With Descriptive Names", "comment": null, "summary": "Automated test generation has become a key technique for ensuring software quality, particularly in modern API-based architectures. However, automatically generated test cases are typically assigned non-descriptive names (e.g., test0, test1), which reduces their readability and hinders their usefulness during comprehension and maintenance. In this work, we present three novel deterministic techniques to generate REST API test names. We then compare eight techniques in total for generating descriptive names for REST API tests automatically produced by the fuzzer EvoMaster, using 10 test cases generated for 9 different open-source APIs. The eight techniques include rule-based heuristics and large language model (LLM)-based approaches. Their effectiveness was empirically evaluated through two surveys (involving up to 39 people recruited via LinkedIn). Our results show that a rule-based approach achieves the highest clarity ratings among deterministic methods, performs on par with state-of-the-art LLM-based models such as Gemini and GPT-4o, and significantly outperforms GPT-3.5.\n  To further evaluate the practical impact of our results, an industrial case study was carried out with practitioners who actively use EvoMaster at Volkswagen AG. A developer questionnaire was then carried out based on the use of EvoMaster on four different APIs by four different users, for a total of 74 evaluated test cases. Feedback from practitioners further confirms that descriptive names produced by this approach improve test suite readability.\n  These findings highlight that lightweight, deterministic techniques can serve as effective alternatives to computationally expensive and security-sensitive LLM-based approaches for automated system-level test naming, providing a practical step toward more developer-friendly API test generation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e09\u79cd\u786e\u5b9a\u6027\u6280\u672f\u4e3aREST API\u6d4b\u8bd5\u751f\u6210\u63cf\u8ff0\u6027\u540d\u79f0\uff0c\u5e76\u4e0eLLM\u65b9\u6cd5\u6bd4\u8f83\uff0c\u53d1\u73b0\u89c4\u5219\u65b9\u6cd5\u5728\u6e05\u6670\u5ea6\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u4e0e\u5148\u8fdbLLM\u76f8\u5f53\uff0c\u663e\u8457\u4f18\u4e8eGPT-3.5\uff0c\u4e14\u5de5\u4e1a\u6848\u4f8b\u8bc1\u5b9e\u80fd\u63d0\u5347\u6d4b\u8bd5\u53ef\u8bfb\u6027\u3002", "motivation": "\u81ea\u52a8\u5316\u751f\u6210\u7684API\u6d4b\u8bd5\u7528\u4f8b\u901a\u5e38\u4f7f\u7528\u975e\u63cf\u8ff0\u6027\u540d\u79f0\uff08\u5982test0\u3001test1\uff09\uff0c\u8fd9\u964d\u4f4e\u4e86\u6d4b\u8bd5\u7684\u53ef\u8bfb\u6027\uff0c\u963b\u788d\u4e86\u5728\u7406\u89e3\u548c\u7ef4\u62a4\u8fc7\u7a0b\u4e2d\u7684\u5b9e\u7528\u6027\u3002\u9700\u8981\u4e3aREST API\u6d4b\u8bd5\u751f\u6210\u63cf\u8ff0\u6027\u540d\u79f0\u4ee5\u6539\u5584\u5f00\u53d1\u4f53\u9a8c\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u79cd\u786e\u5b9a\u6027\u6280\u672f\u751f\u6210REST API\u6d4b\u8bd5\u540d\u79f0\uff0c\u5e76\u4e0eLLM\u65b9\u6cd5\uff08\u5305\u62ecGemini\u3001GPT-4o\u3001GPT-3.5\uff09\u5171\u516b\u79cd\u6280\u672f\u8fdb\u884c\u6bd4\u8f83\u3002\u4f7f\u7528EvoMaster\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u4e3a9\u4e2a\u5f00\u6e90API\u751f\u621010\u4e2a\u6d4b\u8bd5\u7528\u4f8b\u3002\u901a\u8fc7\u4e24\u9879\u8c03\u67e5\uff08\u6d89\u53ca39\u4eba\uff09\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u5e76\u5728\u5927\u4f17\u6c7d\u8f66\u516c\u53f8\u8fdb\u884c\u5de5\u4e1a\u6848\u4f8b\u7814\u7a76\uff0c\u8bc4\u4f3074\u4e2a\u6d4b\u8bd5\u7528\u4f8b\u3002", "result": "\u89c4\u5219\u65b9\u6cd5\u5728\u786e\u5b9a\u6027\u65b9\u6cd5\u4e2d\u83b7\u5f97\u6700\u9ad8\u6e05\u6670\u5ea6\u8bc4\u5206\uff0c\u4e0eGemini\u548cGPT-4o\u7b49\u5148\u8fdbLLM\u6a21\u578b\u8868\u73b0\u76f8\u5f53\uff0c\u663e\u8457\u4f18\u4e8eGPT-3.5\u3002\u5de5\u4e1a\u6848\u4f8b\u7814\u7a76\u8bc1\u5b9e\u63cf\u8ff0\u6027\u540d\u79f0\u80fd\u63d0\u9ad8\u6d4b\u8bd5\u5957\u4ef6\u7684\u53ef\u8bfb\u6027\u3002", "conclusion": "\u8f7b\u91cf\u7ea7\u786e\u5b9a\u6027\u6280\u672f\u53ef\u4ee5\u4f5c\u4e3a\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u5b58\u5728\u5b89\u5168\u98ce\u9669\u7684LLM\u65b9\u6cd5\u7684\u6709\u6548\u66ff\u4ee3\u65b9\u6848\uff0c\u4e3a\u81ea\u52a8\u5316\u7cfb\u7edf\u7ea7\u6d4b\u8bd5\u547d\u540d\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u4f7fAPI\u6d4b\u8bd5\u751f\u6210\u66f4\u52a0\u5f00\u53d1\u8005\u53cb\u597d\u3002"}}
{"id": "2512.00881", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00881", "abs": "https://arxiv.org/abs/2512.00881", "authors": ["Li Yuan", "Qingfei Huang", "Bingshan Zhu", "Yi Cai", "Qingbao Huang", "Changmeng Zheng", "Zikun Deng", "Tao Wang"], "title": "Hybrid-DMKG: A Hybrid Reasoning Framework over Dynamic Multimodal Knowledge Graphs for Multimodal Multihop QA with Knowledge Editing", "comment": "Accepted by AAAI 2026", "summary": "Multimodal Knowledge Editing (MKE) extends traditional knowledge editing to settings involving both textual and visual modalities. However, existing MKE benchmarks primarily assess final answer correctness while neglecting the quality of intermediate reasoning and robustness to visually rephrased inputs. To address this limitation, we introduce MMQAKE, the first benchmark for multimodal multihop question answering with knowledge editing. MMQAKE evaluates (1) a model's ability to reason over 2-5-hop factual chains that span both text and images, including performance at each intermediate step, and (2) robustness to visually rephrased inputs in multihop questions. Our evaluation shows that current MKE methods often struggle to consistently update and reason over multimodal reasoning chains after knowledge edits. To overcome these challenges, we propose Hybrid-DMKG, a hybrid reasoning framework built on a dynamic multimodal knowledge graph (DMKG) to enable accurate multihop reasoning over updated multimodal knowledge. Hybrid-DMKG first uses a large language model to decompose multimodal multihop questions into sequential sub-questions, then applies a multimodal retrieval model to locate updated facts by jointly encoding each sub-question with candidate entities and their associated images. For answer inference, a hybrid reasoning module operates over the DMKG via two parallel paths: (1) relation linking prediction, and (2) RAG reasoning with large vision-language models. A decision module aggregates evidence from both paths to select the most credible answer. Experimental results on MMQAKE show that Hybrid-DMKG significantly outperforms existing MKE approaches, achieving higher accuracy and improved robustness to knowledge updates.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86MMQAKE\u57fa\u51c6\u6d4b\u8bd5\u548cHybrid-DMKG\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u6539\u8fdb\u591a\u6a21\u6001\u77e5\u8bc6\u7f16\u8f91\u4e2d\u7684\u591a\u8df3\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u77e5\u8bc6\u7f16\u8f91\uff08MKE\uff09\u57fa\u51c6\u4e3b\u8981\u8bc4\u4f30\u6700\u7ec8\u7b54\u6848\u6b63\u786e\u6027\uff0c\u4f46\u5ffd\u7565\u4e86\u4e2d\u95f4\u63a8\u7406\u8d28\u91cf\u548c\u89c6\u89c9\u91cd\u8ff0\u8f93\u5165\u7684\u9c81\u68d2\u6027\u3002\u9700\u8981\u89e3\u51b3\u591a\u6a21\u6001\u591a\u8df3\u63a8\u7406\u4e2d\u7684\u77e5\u8bc6\u7f16\u8f91\u6311\u6218\u3002", "method": "\u63d0\u51faHybrid-DMKG\u6df7\u5408\u63a8\u7406\u6846\u67b6\uff1a1\uff09\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5206\u89e3\u591a\u6a21\u6001\u591a\u8df3\u95ee\u9898\u4e3a\u5b50\u95ee\u9898\uff1b2\uff09\u591a\u6a21\u6001\u68c0\u7d22\u6a21\u578b\u5b9a\u4f4d\u66f4\u65b0\u4e8b\u5b9e\uff1b3\uff09\u6df7\u5408\u63a8\u7406\u6a21\u5757\u901a\u8fc7\u5173\u7cfb\u94fe\u63a5\u9884\u6d4b\u548cRAG\u63a8\u7406\u4e24\u6761\u8def\u5f84\u5728\u52a8\u6001\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u4e0a\u63a8\u7406\uff1b4\uff09\u51b3\u7b56\u6a21\u5757\u805a\u5408\u8bc1\u636e\u9009\u62e9\u6700\u53ef\u4fe1\u7b54\u6848\u3002", "result": "\u5728MMQAKE\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHybrid-DMKG\u663e\u8457\u4f18\u4e8e\u73b0\u6709MKE\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u5bf9\u77e5\u8bc6\u66f4\u65b0\u7684\u66f4\u597d\u9c81\u68d2\u6027\u3002", "conclusion": "MMQAKE\u57fa\u51c6\u63ed\u793a\u4e86\u5f53\u524dMKE\u65b9\u6cd5\u5728\u591a\u6a21\u6001\u591a\u8df3\u63a8\u7406\u4e2d\u7684\u5c40\u9650\u6027\uff0cHybrid-DMKG\u901a\u8fc7\u52a8\u6001\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u548c\u6df7\u5408\u63a8\u7406\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u8fd9\u4e9b\u95ee\u9898\uff0c\u4e3a\u591a\u6a21\u6001\u77e5\u8bc6\u7f16\u8f91\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2512.01939", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01939", "abs": "https://arxiv.org/abs/2512.01939", "authors": ["Yanlin Wang", "Xinyi Xu", "Jiachi Chen", "Tingting Bi", "Wenchao Gu", "Zibin Zheng"], "title": "An Empirical Study of Agent Developer Practices in AI Agent Frameworks", "comment": null, "summary": "The rise of large language models (LLMs) has sparked a surge of interest in agents, leading to the rapid growth of agent frameworks. Agent frameworks are software toolkits and libraries that provide standardized components, abstractions, and orchestration mechanisms to simplify agent development. Despite widespread use of agent frameworks, their practical applications and how they influence the agent development process remain underexplored. Different agent frameworks encounter similar problems during use, indicating that these recurring issues deserve greater attention and call for further improvements in agent framework design. Meanwhile, as the number of agent frameworks continues to grow and evolve, more than 80% of developers report difficulties in identifying the frameworks that best meet their specific development requirements. In this paper, we conduct the first empirical study of LLM-based agent frameworks, exploring real-world experiences of developers in building AI agents. To compare how well the agent frameworks meet developer needs, we further collect developer discussions for the ten previously identified agent frameworks, resulting in a total of 11,910 discussions. Finally, by analyzing these discussions, we compare the frameworks across five dimensions: development efficiency, functional abstraction, learning cost, performance optimization, and maintainability, which refers to how easily developers can update and extend both the framework itself and the agents built upon it over time. Our comparative analysis reveals significant differences among frameworks in how they meet the needs of agent developers. Overall, we provide a set of findings and implications for the LLM-driven AI agent framework ecosystem and offer insights for the design of future LLM-based agent frameworks and agent developers.", "AI": {"tldr": "\u672c\u6587\u5bf9LLM\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u6846\u67b6\u8fdb\u884c\u4e86\u9996\u6b21\u5b9e\u8bc1\u7814\u7a76\uff0c\u901a\u8fc7\u5206\u679011,910\u4e2a\u5f00\u53d1\u8005\u8ba8\u8bba\uff0c\u4ece\u4e94\u4e2a\u7ef4\u5ea6\u6bd4\u8f83\u4e86\u5341\u4e2a\u4e3b\u6d41\u6846\u67b6\u7684\u4f18\u52a3\uff0c\u63ed\u793a\u4e86\u6846\u67b6\u8bbe\u8ba1\u4e2d\u7684\u5171\u6027\u95ee\u9898\uff0c\u5e76\u4e3a\u672a\u6765\u6846\u67b6\u5f00\u53d1\u548c\u5f00\u53d1\u8005\u9009\u62e9\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5174\u8d77\uff0c\u667a\u80fd\u4f53\u6846\u67b6\u5feb\u901f\u53d1\u5c55\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u6548\u679c\u548c\u5f00\u53d1\u8fc7\u7a0b\u5f71\u54cd\u7f3a\u4e4f\u6df1\u5165\u7814\u7a76\u3002\u5f00\u53d1\u8005\u9762\u4e34\u9009\u62e9\u56f0\u96be\uff0c\u4e0d\u540c\u6846\u67b6\u5b58\u5728\u76f8\u4f3c\u95ee\u9898\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u5b9e\u8bc1\u5206\u6790\u6765\u6307\u5bfc\u6846\u67b6\u6539\u8fdb\u548c\u5f00\u53d1\u5b9e\u8df5\u3002", "method": "\u6536\u96c6\u5341\u4e2a\u4e3b\u6d41\u667a\u80fd\u4f53\u6846\u67b6\u768411,910\u4e2a\u5f00\u53d1\u8005\u8ba8\u8bba\uff0c\u901a\u8fc7\u5b9a\u6027\u5206\u6790\u6bd4\u8f83\u6846\u67b6\u5728\u4e94\u4e2a\u5173\u952e\u7ef4\u5ea6\u4e0a\u7684\u8868\u73b0\uff1a\u5f00\u53d1\u6548\u7387\u3001\u529f\u80fd\u62bd\u8c61\u3001\u5b66\u4e60\u6210\u672c\u3001\u6027\u80fd\u4f18\u5316\u548c\u53ef\u7ef4\u62a4\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e0d\u540c\u6846\u67b6\u5728\u6ee1\u8db3\u5f00\u53d1\u8005\u9700\u6c42\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u63ed\u793a\u4e86\u6846\u67b6\u8bbe\u8ba1\u4e2d\u7684\u5171\u6027\u95ee\u9898\u3002\u8d85\u8fc780%\u7684\u5f00\u53d1\u8005\u96be\u4ee5\u9009\u62e9\u6700\u9002\u5408\u5176\u9700\u6c42\u7684\u6846\u67b6\uff0c\u5404\u6846\u67b6\u5728\u4e94\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u8868\u73b0\u5404\u6709\u4f18\u52a3\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3aLLM\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u6846\u67b6\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\uff0c\u6307\u51fa\u4e86\u6846\u67b6\u8bbe\u8ba1\u6539\u8fdb\u65b9\u5411\uff0c\u5e76\u4e3a\u5f00\u53d1\u8005\u9009\u62e9\u6846\u67b6\u548c\u672a\u6765\u6846\u67b6\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u3002"}}
{"id": "2512.00969", "categories": ["cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.00969", "abs": "https://arxiv.org/abs/2512.00969", "authors": ["Felix Saretzky", "Lucas Andersen", "Thomas Engel", "Fazel Ansari"], "title": "Integrating Causal Foundation Model in Prescriptive Maintenance Framework for Optimizing Production Line OEE", "comment": "9 pages, 3 images, 1 table, conference paper", "summary": "The transition to prescriptive maintenance in manufacturing is critically constrained by a dependence on predictive models. These models tend to rely on spurious correlations rather than identifying the true causal drivers of failures, often leading to costly misdiagnoses and ineffective interventions. This fundamental limitation results in a key-challenge: while we can predict that a failure may occur, we lack a systematic method to understand why a failure occurs, thereby providing the basis for identifying the most effective intervention. This paper proposes a model based on causal machine learning to bridge this gap. Our objective is to move beyond diagnosis to active prescription by simulating and evaluating potential fixes toward optimizing KPIs such as Overall Equipment Effectiveness (OEE). For this purpose a pre-trained causal foundation model is used as a \"what-if\" model to estimate the effects of potential fixes. By measuring the causal effect of each intervention on system-level KPIs, it provides a data-driven ranking of actions to recommend at the production line. This process not only identifies root causes but also quantifies their operational impact. The model is evaluated using semi-synthetic manufacturing data and compared with a baseline machine learning model. This paper sets the technical basis for a robust prescriptive maintenance framework, allowing engineers to test potential solutions in a causal environment to make more effective operational decisions and reduce costly downtimes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5236\u9020\u4e1a\u4ece\u9884\u6d4b\u6027\u7ef4\u62a4\u5411\u89c4\u8303\u6027\u7ef4\u62a4\u7684\u8f6c\u53d8\uff0c\u901a\u8fc7\u56e0\u679c\u57fa\u7840\u6a21\u578b\u6a21\u62df\u6f5c\u5728\u4fee\u590d\u63aa\u65bd\u5bf9\u7cfb\u7edfKPI\u7684\u5f71\u54cd\uff0c\u4ece\u800c\u63a8\u8350\u6700\u4f18\u5e72\u9884\u65b9\u6848\u3002", "motivation": "\u5236\u9020\u4e1a\u5411\u89c4\u8303\u6027\u7ef4\u62a4\u8f6c\u578b\u53d7\u5230\u9884\u6d4b\u6a21\u578b\u7684\u9650\u5236\uff0c\u8fd9\u4e9b\u6a21\u578b\u5f80\u5f80\u4f9d\u8d56\u865a\u5047\u76f8\u5173\u6027\u800c\u975e\u771f\u6b63\u7684\u6545\u969c\u56e0\u679c\u9a71\u52a8\u56e0\u7d20\uff0c\u5bfc\u81f4\u8bef\u8bca\u548c\u65e0\u6548\u5e72\u9884\u3002\u6838\u5fc3\u6311\u6218\u5728\u4e8e\uff1a\u867d\u7136\u80fd\u9884\u6d4b\u6545\u969c\u53d1\u751f\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u65b9\u6cd5\u6765\u7406\u89e3\u6545\u969c\u539f\u56e0\uff0c\u4ece\u800c\u65e0\u6cd5\u786e\u5b9a\u6700\u6709\u6548\u7684\u5e72\u9884\u63aa\u65bd\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u56e0\u679c\u673a\u5668\u5b66\u4e60\u7684\u6a21\u578b\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u56e0\u679c\u57fa\u7840\u6a21\u578b\u4f5c\u4e3a\"\u5047\u8bbe\u5206\u6790\"\u6a21\u578b\u6765\u4f30\u8ba1\u6f5c\u5728\u4fee\u590d\u63aa\u65bd\u7684\u6548\u679c\u3002\u901a\u8fc7\u6d4b\u91cf\u6bcf\u4e2a\u5e72\u9884\u5bf9\u7cfb\u7edf\u7ea7KPI\uff08\u5982\u6574\u4f53\u8bbe\u5907\u6548\u7387OEE\uff09\u7684\u56e0\u679c\u6548\u5e94\uff0c\u4e3a\u751f\u4ea7\u7ebf\u63d0\u4f9b\u6570\u636e\u9a71\u52a8\u7684\u884c\u52a8\u6392\u5e8f\u63a8\u8350\u3002", "result": "\u4f7f\u7528\u534a\u5408\u6210\u5236\u9020\u6570\u636e\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u4e0e\u57fa\u7ebf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\u3002\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u80fd\u8bc6\u522b\u6839\u672c\u539f\u56e0\uff0c\u8fd8\u80fd\u91cf\u5316\u5176\u64cd\u4f5c\u5f71\u54cd\uff0c\u4e3a\u5de5\u7a0b\u5e08\u5728\u56e0\u679c\u73af\u5883\u4e2d\u6d4b\u8bd5\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u6280\u672f\u57fa\u7840\u3002", "conclusion": "\u8be5\u8bba\u6587\u4e3a\u7a33\u5065\u7684\u89c4\u8303\u6027\u7ef4\u62a4\u6846\u67b6\u5960\u5b9a\u4e86\u6280\u672f\u57fa\u7840\uff0c\u4f7f\u5de5\u7a0b\u5e08\u80fd\u591f\u5728\u56e0\u679c\u73af\u5883\u4e2d\u6d4b\u8bd5\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\uff0c\u505a\u51fa\u66f4\u6709\u6548\u7684\u64cd\u4f5c\u51b3\u7b56\uff0c\u51cf\u5c11\u6602\u8d35\u7684\u505c\u673a\u65f6\u95f4\uff0c\u5b9e\u73b0\u4ece\u8bca\u65ad\u5230\u4e3b\u52a8\u5904\u65b9\u7684\u8f6c\u53d8\u3002"}}
{"id": "2512.01326", "categories": ["cs.CR", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.01326", "abs": "https://arxiv.org/abs/2512.01326", "authors": ["Omar Farooq Khan Suri", "John McCrae"], "title": "Securing Large Language Models (LLMs) from Prompt Injection Attacks", "comment": "10 pages, 1 figure, 1 table", "summary": "Large Language Models (LLMs) are increasingly being deployed in real-world applications, but their flexibility exposes them to prompt injection attacks. These attacks leverage the model's instruction-following ability to make it perform malicious tasks. Recent work has proposed JATMO, a task-specific fine-tuning approach that trains non-instruction-tuned base models to perform a single function, thereby reducing susceptibility to adversarial instructions. In this study, we evaluate the robustness of JATMO against HOUYI, a genetic attack framework that systematically mutates and optimizes adversarial prompts. We adapt HOUYI by introducing custom fitness scoring, modified mutation logic, and a new harness for local model testing, enabling a more accurate assessment of defense effectiveness. We fine-tuned LLaMA 2-7B, Qwen1.5-4B, and Qwen1.5-0.5B models under the JATMO methodology and compared them with a fine-tuned GPT-3.5-Turbo baseline. Results show that while JATMO reduces attack success rates relative to instruction-tuned models, it does not fully prevent injections; adversaries exploiting multilingual cues or code-related disruptors still bypass defenses. We also observe a trade-off between generation quality and injection vulnerability, suggesting that better task performance often correlates with increased susceptibility. Our results highlight both the promise and limitations of fine-tuning-based defenses and point toward the need for layered, adversarially informed mitigation strategies.", "AI": {"tldr": "JATMO\u9632\u5fa1\u65b9\u6cd5\u901a\u8fc7\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\u51cf\u5c11LLM\u7684\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u4f46HOUYI\u9057\u4f20\u653b\u51fb\u6846\u67b6\u4ecd\u80fd\u7ed5\u8fc7\u9632\u5fa1\uff0c\u663e\u793a\u5fae\u8c03\u9632\u5fa1\u5b58\u5728\u5c40\u9650\u6027", "motivation": "\u968f\u7740LLM\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u7684\u90e8\u7f72\u589e\u52a0\uff0c\u5176\u7075\u6d3b\u6027\u4f7f\u5176\u5bb9\u6613\u53d7\u5230\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u3002JATMO\u65b9\u6cd5\u901a\u8fc7\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\u6765\u51cf\u5c11\u5bf9\u6076\u610f\u6307\u4ee4\u7684\u654f\u611f\u6027\uff0c\u4f46\u9700\u8981\u8bc4\u4f30\u5176\u5b9e\u9645\u9632\u5fa1\u6548\u679c", "method": "\u7814\u7a76\u91c7\u7528HOUYI\u9057\u4f20\u653b\u51fb\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u81ea\u5b9a\u4e49\u9002\u5e94\u5ea6\u8bc4\u5206\u3001\u4fee\u6539\u7a81\u53d8\u903b\u8f91\u548c\u672c\u5730\u6a21\u578b\u6d4b\u8bd5\u7684\u65b0\u6846\u67b6\u6765\u8bc4\u4f30JATMO\u9632\u5fa1\u3002\u5bf9LLaMA 2-7B\u3001Qwen1.5-4B\u548cQwen1.5-0.5B\u6a21\u578b\u8fdb\u884cJATMO\u5fae\u8c03\uff0c\u5e76\u4e0e\u5fae\u8c03\u7684GPT-3.5-Turbo\u57fa\u7ebf\u8fdb\u884c\u6bd4\u8f83", "result": "JATMO\u76f8\u5bf9\u4e8e\u6307\u4ee4\u5fae\u8c03\u6a21\u578b\u964d\u4f4e\u4e86\u653b\u51fb\u6210\u529f\u7387\uff0c\u4f46\u672a\u80fd\u5b8c\u5168\u9632\u6b62\u6ce8\u5165\u653b\u51fb\uff1b\u5229\u7528\u591a\u8bed\u8a00\u7ebf\u7d22\u6216\u4ee3\u7801\u76f8\u5173\u5e72\u6270\u5668\u7684\u653b\u51fb\u8005\u4ecd\u80fd\u7ed5\u8fc7\u9632\u5fa1\u3002\u540c\u65f6\u89c2\u5bdf\u5230\u751f\u6210\u8d28\u91cf\u4e0e\u6ce8\u5165\u6f0f\u6d1e\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff0c\u66f4\u597d\u7684\u4efb\u52a1\u6027\u80fd\u901a\u5e38\u4e0e\u589e\u52a0\u7684\u6613\u611f\u6027\u76f8\u5173", "conclusion": "\u57fa\u4e8e\u5fae\u8c03\u7684\u9632\u5fa1\u65b9\u6cd5\u65e2\u6709\u524d\u666f\u4e5f\u6709\u5c40\u9650\u6027\uff0c\u9700\u8981\u91c7\u7528\u5206\u5c42\u3001\u5bf9\u6297\u6027\u611f\u77e5\u7684\u7f13\u89e3\u7b56\u7565\u6765\u5e94\u5bf9\u63d0\u793a\u6ce8\u5165\u653b\u51fb"}}
{"id": "2512.00997", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.00997", "abs": "https://arxiv.org/abs/2512.00997", "authors": ["Param Biyani", "Shashank Kirtania", "Yasharth Bajpai", "Sumit Gulwani", "Ashish Tiwari"], "title": "IndiMathBench: Autoformalizing Mathematical Reasoning Problems with a Human Touch", "comment": null, "summary": "We introduce IndiMathBench, a human-verified benchmark designed to evaluate mathematical theorem proving, curated using an AI-powered human-assisted pipeline for formalizing natural language problems in Lean. IndiMathBench is composed of 312 formal Lean 4 theorems paired with their corresponding informal problem statements, sourced from Indian Mathematics Olympiads. Through category-based retrieval, iterative compiler feedback, and multi-model ensembles, our pipeline generates candidate formalizations that experts efficiently validate via an interactive dashboard with automated quality summaries. Evaluation across multiple frontier models demonstrates that autoformalization remains challenging, with substantial gaps between syntactic validity and semantic correctness, while theorem proving success rates remain low even with iterative refinement, demonstrating that \\benchmark~presents a challenging testbed for mathematical reasoning. IndiMathBench is available at https://github.com/prmbiy/IndiMathBench.", "AI": {"tldr": "IndiMathBench\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u6570\u5b66\u5b9a\u7406\u8bc1\u660e\u7684\u4eba\u7c7b\u9a8c\u8bc1\u57fa\u51c6\uff0c\u5305\u542b312\u4e2a\u6765\u81ea\u5370\u5ea6\u6570\u5b66\u5965\u6797\u5339\u514b\u7ade\u8d5b\u7684Lean 4\u5f62\u5f0f\u5316\u5b9a\u7406\u53ca\u5176\u5bf9\u5e94\u7684\u975e\u6b63\u5f0f\u95ee\u9898\u9648\u8ff0\uff0c\u901a\u8fc7AI\u8f85\u52a9\u6d41\u7a0b\u6784\u5efa\u3002", "motivation": "\u5f53\u524d\u6570\u5b66\u5b9a\u7406\u8bc1\u660e\u7684\u81ea\u52a8\u5f62\u5f0f\u5316\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u9ad8\u8d28\u91cf\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u548c\u5f62\u5f0f\u5316\u65b9\u9762\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u9488\u5bf9\u771f\u5b9e\u4e16\u754c\u7684\u6570\u5b66\u7ade\u8d5b\u95ee\u9898\u3002", "method": "\u91c7\u7528AI\u9a71\u52a8\u7684\u4eba\u7c7b\u8f85\u52a9\u6d41\u7a0b\uff0c\u901a\u8fc7\u7c7b\u522b\u68c0\u7d22\u3001\u8fed\u4ee3\u7f16\u8bd1\u5668\u53cd\u9988\u548c\u591a\u6a21\u578b\u96c6\u6210\u751f\u6210\u5019\u9009\u5f62\u5f0f\u5316\uff0c\u4e13\u5bb6\u901a\u8fc7\u4ea4\u4e92\u5f0f\u4eea\u8868\u677f\u8fdb\u884c\u9ad8\u6548\u9a8c\u8bc1\uff0c\u5e76\u5229\u7528\u81ea\u52a8\u5316\u8d28\u91cf\u6458\u8981\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u81ea\u52a8\u5f62\u5f0f\u5316\u4ecd\u7136\u56f0\u96be\uff0c\u8bed\u6cd5\u6709\u6548\u6027\u548c\u8bed\u4e49\u6b63\u786e\u6027\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u5373\u4f7f\u7ecf\u8fc7\u8fed\u4ee3\u4f18\u5316\uff0c\u5b9a\u7406\u8bc1\u660e\u6210\u529f\u7387\u4ecd\u7136\u8f83\u4f4e\uff0c\u8868\u660e\u8be5\u57fa\u51c6\u5bf9\u6570\u5b66\u63a8\u7406\u5177\u6709\u6311\u6218\u6027\u3002", "conclusion": "IndiMathBench\u4e3a\u6570\u5b66\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u5c55\u793a\u4e86\u5f53\u524dAI\u5728\u6570\u5b66\u5b9a\u7406\u8bc1\u660e\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u57fa\u51c6\u8d44\u6e90\u3002"}}
{"id": "2512.01335", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.01335", "abs": "https://arxiv.org/abs/2512.01335", "authors": ["Xinyun Zhou", "Xinfeng Li", "Yinan Peng", "Ming Xu", "Xuanwang Zhang", "Miao Yu", "Yidong Wang", "Xiaojun Jia", "Kun Wang", "Qingsong Wen", "XiaoFeng Wang", "Wei Dong"], "title": "EmoRAG: Evaluating RAG Robustness to Symbolic Perturbations", "comment": "Accepted to ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD) 2026", "summary": "Retrieval-Augmented Generation (RAG) systems are increasingly central to robust AI, enhancing large language model (LLM) faithfulness by incorporating external knowledge. However, our study unveils a critical, overlooked vulnerability: their profound susceptibility to subtle symbolic perturbations, particularly through near-imperceptible emoticon tokens such as \"(@_@)\" that can catastrophically mislead retrieval, termed EmoRAG. We demonstrate that injecting a single emoticon into a query makes it nearly 100% likely to retrieve semantically unrelated texts that contain a matching emoticon. Our extensive experiment across general question-answering and code domains, using a range of state-of-the-art retrievers and generators, reveals three key findings: (I) Single-Emoticon Disaster: Minimal emoticon injections cause maximal disruptions, with a single emoticon almost 100% dominating RAG output. (II) Positional Sensitivity: Placing an emoticon at the beginning of a query can cause severe perturbation, with F1-Scores exceeding 0.92 across all datasets. (III) Parameter-Scale Vulnerability: Counterintuitively, models with larger parameters exhibit greater vulnerability to the interference. We provide an in-depth analysis to uncover the underlying mechanisms of these phenomena. Furthermore, we raise a critical concern regarding the robustness assumption of current RAG systems, envisioning a threat scenario where an adversary exploits this vulnerability to manipulate the RAG system. We evaluate standard defenses and find them insufficient against EmoRAG. To address this, we propose targeted defenses, analyzing their strengths and limitations in mitigating emoticon-based perturbations. Finally, we outline future directions for building robust RAG systems.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0RAG\u7cfb\u7edf\u5bf9\u8868\u60c5\u7b26\u53f7\u7b49\u5fae\u5c0f\u7b26\u53f7\u6270\u52a8\u5b58\u5728\u4e25\u91cd\u8106\u5f31\u6027\uff0c\u5355\u4e2a\u8868\u60c5\u7b26\u53f7\u5c31\u80fd\u51e0\u4e4e100%\u8bef\u5bfc\u68c0\u7d22\u7ed3\u679c\uff0c\u79f0\u4e3aEmoRAG\u6f0f\u6d1e\u3002", "motivation": "\u5c3d\u7ba1\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7cfb\u7edf\u901a\u8fc7\u6574\u5408\u5916\u90e8\u77e5\u8bc6\u63d0\u9ad8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u9760\u6027\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\u8fd9\u4e9b\u7cfb\u7edf\u5b58\u5728\u4e00\u4e2a\u88ab\u5ffd\u89c6\u7684\u5173\u952e\u6f0f\u6d1e\uff1a\u5bf9\u5fae\u5c0f\u7b26\u53f7\u6270\u52a8\uff08\u7279\u522b\u662f\u96be\u4ee5\u5bdf\u89c9\u7684\u8868\u60c5\u7b26\u53f7\uff09\u7684\u6781\u7aef\u654f\u611f\u6027\uff0c\u8fd9\u53ef\u80fd\u88ab\u653b\u51fb\u8005\u5229\u7528\u6765\u64cd\u7eb5\u7cfb\u7edf\u3002", "method": "\u901a\u8fc7\u5728\u67e5\u8be2\u4e2d\u6ce8\u5165\u5355\u4e2a\u8868\u60c5\u7b26\u53f7\uff08\u5982\"(@_@)\"\uff09\uff0c\u5728\u901a\u7528\u95ee\u7b54\u548c\u4ee3\u7801\u9886\u57df\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u4f7f\u7528\u591a\u79cd\u6700\u5148\u8fdb\u7684\u68c0\u7d22\u5668\u548c\u751f\u6210\u5668\uff0c\u5206\u6790\u8868\u60c5\u7b26\u53f7\u5bf9RAG\u7cfb\u7edf\u7684\u5f71\u54cd\u673a\u5236\u3002", "result": "\u53d1\u73b0\u4e09\u4e2a\u5173\u952e\u7ed3\u679c\uff1a(1)\u5355\u4e2a\u8868\u60c5\u7b26\u53f7\u6ce8\u5165\u5c31\u80fd\u9020\u6210\u6700\u5927\u7834\u574f\uff0c\u51e0\u4e4e100%\u4e3b\u5bfcRAG\u8f93\u51fa\uff1b(2)\u8868\u60c5\u7b26\u53f7\u5728\u67e5\u8be2\u5f00\u5934\u4f4d\u7f6e\u65f6\u6270\u52a8\u6700\u4e25\u91cd\uff0cF1\u5206\u6570\u8d85\u8fc70.92\uff1b(3)\u53c2\u6570\u66f4\u5927\u7684\u6a21\u578b\u53cd\u800c\u66f4\u8106\u5f31\u3002\u73b0\u6709\u9632\u5fa1\u63aa\u65bd\u5bf9\u6b64\u6f0f\u6d1e\u65e0\u6548\u3002", "conclusion": "\u5f53\u524dRAG\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u5047\u8bbe\u5b58\u5728\u4e25\u91cd\u95ee\u9898\uff0cEmoRAG\u6f0f\u6d1e\u53ef\u80fd\u88ab\u6076\u610f\u5229\u7528\u3002\u9700\u8981\u5f00\u53d1\u9488\u5bf9\u6027\u9632\u5fa1\u63aa\u65bd\uff0c\u5e76\u4e3a\u6784\u5efa\u66f4\u9c81\u68d2\u7684RAG\u7cfb\u7edf\u6307\u660e\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2512.01017", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01017", "abs": "https://arxiv.org/abs/2512.01017", "authors": ["Xinhang Li", "Jingbo Zhou", "Pengfei Luo", "Yixiong Xiao", "Tong Xu"], "title": "ChartAnchor: Chart Grounding with Structural-Semantic Fidelity", "comment": null, "summary": "Recent advances in multimodal large language models (MLLMs) highlight the need for benchmarks that rigorously evaluate structured chart comprehension.Chart grounding refers to the bidirectional alignment between a chart's visual appearance and the structured semantics. This task requires models to produce a symbolic specification that faithfully captures the chart's visual and structural intent, while also recovering the underlying tabular data with precise values and relationships. Chart grounding directly reflects a model's capabilities in numerical reasoning, multimodal alignment, and structural reconstruction, and has several important applications in real-world scenarios.Existing benchmarks, constrained by narrow chart diversity, isolated tasks, and incomplete evaluation frameworks, fail to holistically assess grounding. To address this, we propose ChartAnchor, a comprehensive benchmark of 8k+ chart-table-code triples spanning 30 chart types drawn from diverse real-world and augmented sources. ChartAnchor introduces two complementary tasks: chart-to-code generation (synthesizing executable code to replicate charts) and controlled chart-to-table reconstruction (extracting exact data with predefined headers), enabling cross-validation of visual and numerical fidelity. A multi-level evaluation framework integrates semantic validation, stylistic analysis, and perceptual metrics to assess both structural and content-level correctness. Extensive experiments on MLLMs reveal critical limitations in numerical precision and code synthesis, emphasizing the need for structured reasoning beyond surface-level perception. By unifying symbolic and data-driven grounding, ChartAnchor establishes a rigorous foundation for chart grounding, offering meaningful insights for advancing MLLMs in scientific, financial, and industrial domains.", "AI": {"tldr": "ChartAnchor\u662f\u4e00\u4e2a\u5305\u542b8k+\u56fe\u8868-\u8868\u683c-\u4ee3\u7801\u4e09\u5143\u7ec4\u7684\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d630\u79cd\u56fe\u8868\u7c7b\u578b\uff0c\u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u56fe\u8868\u7406\u89e3\u65b9\u9762\u7684\u7ed3\u6784\u5316\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5728\u56fe\u8868\u591a\u6837\u6027\u3001\u4efb\u52a1\u5b64\u7acb\u6027\u548c\u8bc4\u4f30\u6846\u67b6\u4e0d\u5b8c\u6574\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u56fe\u8868\u63a5\u5730\uff08chart grounding\uff09\u80fd\u529b\u3002\u56fe\u8868\u63a5\u5730\u9700\u8981\u6a21\u578b\u5728\u89c6\u89c9\u5916\u89c2\u548c\u7ed3\u6784\u5316\u8bed\u4e49\u4e4b\u95f4\u5efa\u7acb\u53cc\u5411\u5bf9\u9f50\uff0c\u8fd9\u5bf9\u6570\u503c\u63a8\u7406\u3001\u591a\u6a21\u6001\u5bf9\u9f50\u548c\u7ed3\u6784\u91cd\u5efa\u80fd\u529b\u63d0\u51fa\u4e86\u6311\u6218\u3002", "method": "\u63d0\u51faChartAnchor\u57fa\u51c6\uff0c\u5305\u542b\u4e24\u4e2a\u4e92\u8865\u4efb\u52a1\uff1a1\uff09\u56fe\u8868\u5230\u4ee3\u7801\u751f\u6210\uff08\u5408\u6210\u53ef\u6267\u884c\u4ee3\u7801\u4ee5\u590d\u5236\u56fe\u8868\uff09\uff1b2\uff09\u53d7\u63a7\u56fe\u8868\u5230\u8868\u683c\u91cd\u5efa\uff08\u4f7f\u7528\u9884\u5b9a\u4e49\u6807\u9898\u63d0\u53d6\u7cbe\u786e\u6570\u636e\uff09\u3002\u91c7\u7528\u591a\u7ea7\u8bc4\u4f30\u6846\u67b6\uff0c\u6574\u5408\u8bed\u4e49\u9a8c\u8bc1\u3001\u98ce\u683c\u5206\u6790\u548c\u611f\u77e5\u5ea6\u91cf\uff0c\u8bc4\u4f30\u7ed3\u6784\u548c\u5185\u5bb9\u5c42\u9762\u7684\u6b63\u786e\u6027\u3002", "result": "\u5728MLLMs\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u63ed\u793a\u4e86\u6570\u503c\u7cbe\u5ea6\u548c\u4ee3\u7801\u5408\u6210\u65b9\u9762\u7684\u5173\u952e\u9650\u5236\uff0c\u5f3a\u8c03\u9700\u8981\u8d85\u8d8a\u8868\u9762\u611f\u77e5\u7684\u7ed3\u6784\u5316\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "ChartAnchor\u901a\u8fc7\u7edf\u4e00\u7b26\u53f7\u548c\u6570\u636e\u9a71\u52a8\u7684\u63a5\u5730\u65b9\u6cd5\uff0c\u4e3a\u56fe\u8868\u63a5\u5730\u5efa\u7acb\u4e86\u4e25\u683c\u7684\u57fa\u7840\uff0c\u4e3a\u5728\u79d1\u5b66\u3001\u91d1\u878d\u548c\u5de5\u4e1a\u9886\u57df\u63a8\u8fdbMLLMs\u63d0\u4f9b\u4e86\u6709\u610f\u4e49\u7684\u89c1\u89e3\u3002"}}
{"id": "2512.01020", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.01020", "abs": "https://arxiv.org/abs/2512.01020", "authors": ["Jinu Lee", "Kyoung-Woon On", "Simeng Han", "Arman Cohan", "Julia Hockenmaier"], "title": "Evaluating Legal Reasoning Traces with Legal Issue Tree Rubrics", "comment": null, "summary": "Evaluating the quality of LLM-generated reasoning traces in expert domains (e.g., law) is essential for ensuring credibility and explainability, yet remains challenging due to the inherent complexity of such reasoning tasks. We introduce LEGIT (LEGal Issue Trees), a novel large-scale (24K instances) expert-level legal reasoning dataset with an emphasis on reasoning trace evaluation. We convert court judgments into hierarchical trees of opposing parties' arguments and the court's conclusions, which serve as rubrics for evaluating the issue coverage and correctness of the reasoning traces. We verify the reliability of these rubrics via human expert annotations and comparison with coarse, less informative rubrics. Using the LEGIT dataset, we show that (1) LLMs' legal reasoning ability is seriously affected by both legal issue coverage and correctness, and that (2) retrieval-augmented generation (RAG) and RL with rubrics bring complementary benefits for legal reasoning abilities, where RAG improves overall reasoning capability, whereas RL improves correctness albeit with reduced coverage.", "AI": {"tldr": "LEGIT\u6570\u636e\u96c6\uff1a\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u6cd5\u5f8b\u9886\u57df\u63a8\u7406\u8f68\u8ff9\u8d28\u91cf\u7684\u5927\u89c4\u6a21\u4e13\u5bb6\u7ea7\u6cd5\u5f8b\u63a8\u7406\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u5c06\u6cd5\u9662\u5224\u51b3\u8f6c\u6362\u4e3a\u5c42\u6b21\u5316\u8bba\u8bc1\u6811\u6765\u8bc4\u4f30\u63a8\u7406\u8986\u76d6\u7387\u548c\u6b63\u786e\u6027", "motivation": "\u5728\u4e13\u5bb6\u9886\u57df\uff08\u5982\u6cd5\u5f8b\uff09\u8bc4\u4f30LLM\u751f\u6210\u7684\u63a8\u7406\u8f68\u8ff9\u8d28\u91cf\u5bf9\u4e8e\u786e\u4fdd\u53ef\u4fe1\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u6b64\u7c7b\u63a8\u7406\u4efb\u52a1\u7684\u56fa\u6709\u590d\u6742\u6027\uff0c\u8fd9\u4e00\u8bc4\u4f30\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027", "method": "\u5f15\u5165LEGIT\u6570\u636e\u96c6\uff0824K\u5b9e\u4f8b\uff09\uff0c\u5c06\u6cd5\u9662\u5224\u51b3\u8f6c\u6362\u4e3a\u5bf9\u7acb\u53cc\u65b9\u8bba\u8bc1\u548c\u6cd5\u9662\u7ed3\u8bba\u7684\u5c42\u6b21\u5316\u6811\u7ed3\u6784\uff0c\u4f5c\u4e3a\u8bc4\u4f30\u63a8\u7406\u8f68\u8ff9\u95ee\u9898\u8986\u76d6\u7387\u548c\u6b63\u786e\u6027\u7684\u8bc4\u5206\u6807\u51c6\uff0c\u5e76\u901a\u8fc7\u4e13\u5bb6\u6807\u6ce8\u9a8c\u8bc1\u53ef\u9760\u6027", "result": "1. LLM\u7684\u6cd5\u5f8b\u63a8\u7406\u80fd\u529b\u53d7\u5230\u6cd5\u5f8b\u95ee\u9898\u8986\u76d6\u7387\u548c\u6b63\u786e\u6027\u7684\u4e25\u91cd\u5f71\u54cd\uff1b2. \u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u548c\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u5bf9\u6cd5\u5f8b\u63a8\u7406\u80fd\u529b\u5e26\u6765\u4e92\u8865\u6027\u76ca\u5904\uff1aRAG\u63d0\u9ad8\u6574\u4f53\u63a8\u7406\u80fd\u529b\uff0cRL\u63d0\u9ad8\u6b63\u786e\u6027\u4f46\u4f1a\u964d\u4f4e\u8986\u76d6\u7387", "conclusion": "LEGIT\u6570\u636e\u96c6\u4e3a\u8bc4\u4f30LLM\u5728\u6cd5\u5f8b\u9886\u57df\u7684\u63a8\u7406\u8f68\u8ff9\u8d28\u91cf\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u63ed\u793a\u4e86RAG\u548cRL\u5728\u63d0\u5347\u6cd5\u5f8b\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u4e92\u8865\u4f5c\u7528\uff0c\u4e3a\u4e13\u5bb6\u9886\u57df\u7684\u53ef\u4fe1AI\u7cfb\u7edf\u5f00\u53d1\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3"}}
{"id": "2512.01045", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01045", "abs": "https://arxiv.org/abs/2512.01045", "authors": ["Shenxi Liu", "Kan Li", "Mingyang Zhao", "Yuhang Tian", "Shoujun Zhou", "Bin Li"], "title": "Med-CRAFT: Automated Construction of Interpretable and Multi-Hop Video Workloads via Knowledge Graph Traversal", "comment": "8 pages, 7 figures", "summary": "The scarcity of high-quality, logically annotated video datasets remains a primary bottleneck in advancing Multi-Modal Large Language Models (MLLMs) for the medical domain. Traditional manual annotation is prohibitively expensive and non-scalable, while existing synthetic methods often suffer from stochastic hallucinations and a lack of logical interpretability. To address these challenges, we introduce \\textbf{\\PipelineName}, a novel neuro-symbolic data engineering framework that formalizes benchmark synthesis as a deterministic graph traversal process. Unlike black-box generative approaches, Med-CRAFT extracts structured visual primitives (e.g., surgical instruments, anatomical boundaries) from raw video streams and instantiates them into a dynamic Spatiotemporal Knowledge Graph. By anchoring query generation to valid paths within this graph, we enforce a rigorous Chain-of-Thought (CoT) provenance for every synthesized benchmark item. We instantiate this pipeline to produce M3-Med-Auto, a large-scale medical video reasoning benchmark exhibiting fine-grained temporal selectivity and multi-hop logical complexity. Comprehensive evaluations demonstrate that our automated pipeline generates query workloads with complexity comparable to expert-curated datasets. Furthermore, a logic alignment analysis reveals a high correlation between the prescribed graph topology and the reasoning steps of state-of-the-art MLLMs, validating the system's capability to encode verifiable logic into visual-linguistic benchmarks. This work paves the way for scalable, low-cost construction of robust evaluation protocols in critical domains.", "AI": {"tldr": "Med-CRAFT\u662f\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7\u6570\u636e\u5de5\u7a0b\u6846\u67b6\uff0c\u901a\u8fc7\u786e\u5b9a\u6027\u56fe\u904d\u5386\u8fc7\u7a0b\u5408\u6210\u533b\u7597\u89c6\u9891\u63a8\u7406\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u89e3\u51b3\u4e86\u533b\u7597\u9886\u57df\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u9ad8\u8d28\u91cf\u903b\u8f91\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\u3002", "motivation": "\u533b\u7597\u9886\u57df\u9ad8\u8d28\u91cf\u903b\u8f91\u6807\u6ce8\u89c6\u9891\u6570\u636e\u96c6\u7a00\u7f3a\uff0c\u4f20\u7edf\u4eba\u5de5\u6807\u6ce8\u6210\u672c\u9ad8\u6602\u4e14\u4e0d\u53ef\u6269\u5c55\uff0c\u73b0\u6709\u5408\u6210\u65b9\u6cd5\u5b58\u5728\u968f\u673a\u5e7b\u89c9\u548c\u7f3a\u4e4f\u903b\u8f91\u53ef\u89e3\u91ca\u6027\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faMed-CRAFT\u795e\u7ecf\u7b26\u53f7\u6570\u636e\u5de5\u7a0b\u6846\u67b6\uff0c\u4ece\u539f\u59cb\u89c6\u9891\u6d41\u63d0\u53d6\u7ed3\u6784\u5316\u89c6\u89c9\u57fa\u5143\uff0c\u5b9e\u4f8b\u5316\u4e3a\u52a8\u6001\u65f6\u7a7a\u77e5\u8bc6\u56fe\u8c31\uff0c\u901a\u8fc7\u56fe\u5185\u6709\u6548\u8def\u5f84\u951a\u5b9a\u67e5\u8be2\u751f\u6210\uff0c\u4e3a\u6bcf\u4e2a\u5408\u6210\u57fa\u51c6\u9879\u5f3a\u5236\u6267\u884c\u4e25\u683c\u7684\u601d\u7ef4\u94fe\u6eaf\u6e90\u3002", "result": "\u6784\u5efa\u4e86M3-Med-Auto\u5927\u89c4\u6a21\u533b\u7597\u89c6\u9891\u63a8\u7406\u57fa\u51c6\uff0c\u5177\u6709\u7ec6\u7c92\u5ea6\u65f6\u95f4\u9009\u62e9\u6027\u548c\u591a\u8df3\u903b\u8f91\u590d\u6742\u6027\u3002\u8bc4\u4f30\u8868\u660e\u81ea\u52a8\u6d41\u6c34\u7ebf\u751f\u6210\u7684\u67e5\u8be2\u590d\u6742\u5ea6\u53ef\u4e0e\u4e13\u5bb6\u7b56\u5212\u6570\u636e\u96c6\u76f8\u5ab2\u7f8e\uff0c\u903b\u8f91\u5bf9\u9f50\u5206\u6790\u663e\u793a\u56fe\u62d3\u6251\u4e0e\u6700\u5148\u8fdbMLLM\u63a8\u7406\u6b65\u9aa4\u9ad8\u5ea6\u76f8\u5173\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5173\u952e\u9886\u57df\u53ef\u6269\u5c55\u3001\u4f4e\u6210\u672c\u6784\u5efa\u9c81\u68d2\u8bc4\u4f30\u534f\u8bae\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u5c06\u53ef\u9a8c\u8bc1\u903b\u8f91\u7f16\u7801\u5230\u89c6\u89c9\u8bed\u8a00\u57fa\u51c6\u4e2d\u7684\u80fd\u529b\u3002"}}
{"id": "2512.01574", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2512.01574", "abs": "https://arxiv.org/abs/2512.01574", "authors": ["Sangpyo Kim", "Hyesung Ji", "Jongmin Kim", "Wonseok Choi", "Jaiyoung Park", "Jung Ho Ahn"], "title": "IVE: An Accelerator for Single-Server Private Information Retrieval Using Versatile Processing Elements", "comment": "15 pages, 14 figures, accepted at HPCA 2026", "summary": "Private information retrieval (PIR) is an essential cryptographic protocol for privacy-preserving applications, enabling a client to retrieve a record from a server's database without revealing which record was requested. Single-server PIR based on homomorphic encryption has particularly gained immense attention for its ease of deployment and reduced trust assumptions. However, single-server PIR remains impractical due to its high computational and memory bandwidth demands. Specifically, reading the entirety of large databases from storage, such as SSDs, severely limits its performance. To address this, we propose IVE, an accelerator for single-server PIR with a systematic extension that enables practical retrieval from large databases using DRAM. Recent advances in DRAM capacity allow PIR for large databases to be served entirely from DRAM, removing its dependence on storage bandwidth. Although the memory bandwidth bottleneck still remains, multi-client batching effectively amortizes database access costs across concurrent requests to improve throughput. However, client-specific data remains a bottleneck, whose bandwidth requirements ultimately limits performance. IVE overcomes this by employing a large on-chip scratchpad with an operation scheduling algorithm that maximizes data reuse, further boosting throughput. Additionally, we introduce sysNTTU, a versatile functional unit that enhances area efficiency without sacrificing performance. We also propose a heterogeneous memory system architecture, which enables a linear scaling of database sizes without a throughput degradation. Consequently, IVE achieves up to 1,275x higher throughput compared to prior PIR hardware solutions.", "AI": {"tldr": "IVE\u662f\u4e00\u4e2a\u9488\u5bf9\u5355\u670d\u52a1\u5668\u79c1\u6709\u4fe1\u606f\u68c0\u7d22\u7684\u52a0\u901f\u5668\uff0c\u901a\u8fc7DRAM\u5b58\u50a8\u3001\u591a\u5ba2\u6237\u7aef\u6279\u5904\u7406\u3001\u7247\u4e0a\u6682\u5b58\u5668\u548c\u4e13\u7528\u529f\u80fd\u5355\u5143\uff0c\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u786c\u4ef6\u65b9\u6848\u9ad8\u8fbe1275\u500d\u7684\u541e\u5410\u91cf\u63d0\u5347\u3002", "motivation": "\u5355\u670d\u52a1\u5668\u57fa\u4e8e\u540c\u6001\u52a0\u5bc6\u7684\u79c1\u6709\u4fe1\u606f\u68c0\u7d22\u867d\u7136\u90e8\u7f72\u7b80\u5355\u4e14\u4fe1\u4efb\u5047\u8bbe\u8f83\u5c11\uff0c\u4f46\u7531\u4e8e\u9700\u8981\u8bfb\u53d6\u6574\u4e2a\u6570\u636e\u5e93\uff0c\u5b58\u5728\u9ad8\u8ba1\u7b97\u548c\u5185\u5b58\u5e26\u5bbd\u9700\u6c42\uff0c\u5bfc\u81f4\u6027\u80fd\u53d7\u9650\uff0c\u7279\u522b\u662f\u4eceSSD\u7b49\u5b58\u50a8\u8bbe\u5907\u8bfb\u53d6\u5927\u578b\u6570\u636e\u5e93\u65f6\u6027\u80fd\u4e25\u91cd\u53d7\u9650\u3002", "method": "\u63d0\u51faIVE\u52a0\u901f\u5668\uff0c\u91c7\u7528DRAM\u5b58\u50a8\u5927\u578b\u6570\u636e\u5e93\u4ee5\u6d88\u9664\u5b58\u50a8\u5e26\u5bbd\u9650\u5236\uff1b\u901a\u8fc7\u591a\u5ba2\u6237\u7aef\u6279\u5904\u7406\u5206\u644a\u6570\u636e\u5e93\u8bbf\u95ee\u6210\u672c\uff1b\u4f7f\u7528\u5927\u578b\u7247\u4e0a\u6682\u5b58\u5668\u548c\u64cd\u4f5c\u8c03\u5ea6\u7b97\u6cd5\u6700\u5927\u5316\u6570\u636e\u91cd\u7528\uff1b\u5f15\u5165sysNTTU\u591a\u529f\u80fd\u5355\u5143\u63d0\u9ad8\u9762\u79ef\u6548\u7387\uff1b\u8bbe\u8ba1\u5f02\u6784\u5185\u5b58\u7cfb\u7edf\u67b6\u6784\u5b9e\u73b0\u6570\u636e\u5e93\u89c4\u6a21\u7ebf\u6027\u6269\u5c55\u800c\u4e0d\u964d\u4f4e\u541e\u5410\u91cf\u3002", "result": "IVE\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709PIR\u786c\u4ef6\u89e3\u51b3\u65b9\u6848\u9ad8\u8fbe1275\u500d\u7684\u541e\u5410\u91cf\u63d0\u5347\uff0c\u80fd\u591f\u652f\u6301\u5927\u89c4\u6a21\u6570\u636e\u5e93\u7684\u5b9e\u7528\u5316\u79c1\u6709\u4fe1\u606f\u68c0\u7d22\u3002", "conclusion": "IVE\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u786c\u4ef6\u67b6\u6784\u521b\u65b0\uff0c\u89e3\u51b3\u4e86\u5355\u670d\u52a1\u5668\u79c1\u6709\u4fe1\u606f\u68c0\u7d22\u7684\u6027\u80fd\u74f6\u9888\uff0c\u4f7f\u5176\u4ece\u7406\u8bba\u53ef\u884c\u53d8\u4e3a\u5b9e\u9645\u53ef\u7528\uff0c\u4e3a\u9690\u79c1\u4fdd\u62a4\u5e94\u7528\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.01078", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01078", "abs": "https://arxiv.org/abs/2512.01078", "authors": ["Jiawei Ren", "Yan Zhuang", "Xiaokang Ye", "Lingjun Mao", "Xuhong He", "Jianzhi Shen", "Mrinaal Dogra", "Yiming Liang", "Ruixuan Zhang", "Tianai Yue", "Yiqing Yang", "Eric Liu", "Ryan Wu", "Kevin Benavente", "Rajiv Mandya Nagaraju", "Muhammad Faayez", "Xiyan Zhang", "Dhruv Vivek Sharma", "Xianrui Zhong", "Ziqiao Ma", "Tianmin Shu", "Zhiting Hu", "Lianhui Qin"], "title": "SimWorld: An Open-ended Realistic Simulator for Autonomous Agents in Physical and Social Worlds", "comment": null, "summary": "While LLM/VLM-powered AI agents have advanced rapidly in math, coding, and computer use, their applications in complex physical and social environments remain challenging. Building agents that can survive and thrive in the real world (for example, by autonomously earning income or running a business) requires massive-scale interaction, reasoning, training, and evaluation across diverse embodied scenarios. However, existing world simulators for such development fall short: they often rely on limited hand-crafted environments, simulate simplified game-like physics and social rules, and lack native support for LLM/VLM agents. We introduce SimWorld, a new simulator built on Unreal Engine 5, designed for developing and evaluating LLM/VLM agents in rich, real-world-like settings. SimWorld offers three core capabilities: (1) realistic, open-ended world simulation, including accurate physical and social dynamics and language-driven procedural environment generation; (2) a rich interface for LLM/VLM agents, with multimodal world inputs and open-vocabulary actions at varying levels of abstraction; and (3) diverse and extensible physical and social reasoning scenarios that are easily customizable by users. We demonstrate SimWorld by deploying frontier LLM agents (e.g., GPT-4o, Gemini-2.5-Flash, Claude-3.5, and DeepSeek-Prover-V2) on long-horizon multi-agent delivery tasks involving strategic cooperation and competition. The results reveal distinct reasoning patterns and limitations across models. We open-source SimWorld and hope it becomes a foundational platform for advancing real-world agent intelligence across disciplines: https://simworld.org.", "AI": {"tldr": "SimWorld\u662f\u4e00\u4e2a\u57fa\u4e8e\u865a\u5e7b\u5f15\u64ce5\u6784\u5efa\u7684\u65b0\u578b\u6a21\u62df\u5668\uff0c\u65e8\u5728\u4e3aLLM/VLM\u667a\u80fd\u4f53\u5728\u4e30\u5bcc\u3001\u771f\u5b9e\u4e16\u754c\u822c\u7684\u73af\u5883\u4e2d\u63d0\u4f9b\u5f00\u53d1\u548c\u8bc4\u4f30\u5e73\u53f0\uff0c\u652f\u6301\u7269\u7406\u548c\u793e\u4f1a\u52a8\u6001\u6a21\u62df\u3001\u591a\u6a21\u6001\u63a5\u53e3\u4ee5\u53ca\u53ef\u6269\u5c55\u7684\u573a\u666f\u5b9a\u5236\u3002", "motivation": "\u5f53\u524dLLM/VLM\u667a\u80fd\u4f53\u5728\u590d\u6742\u7269\u7406\u548c\u793e\u4f1a\u73af\u5883\u4e2d\u7684\u5e94\u7528\u4ecd\u7136\u9762\u4e34\u6311\u6218\uff0c\u73b0\u6709\u4e16\u754c\u6a21\u62df\u5668\u5b58\u5728\u73af\u5883\u6709\u9650\u3001\u7269\u7406\u7b80\u5316\u3001\u7f3a\u4e4f\u5bf9LLM/VLM\u667a\u80fd\u4f53\u539f\u751f\u652f\u6301\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u771f\u5b9e\u3001\u5f00\u653e\u7684\u4e16\u754c\u6a21\u62df\u5e73\u53f0\u6765\u5f00\u53d1\u80fd\u591f\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u751f\u5b58\u548c\u53d1\u5c55\u7684\u667a\u80fd\u4f53\u3002", "method": "\u57fa\u4e8e\u865a\u5e7b\u5f15\u64ce5\u6784\u5efaSimWorld\u6a21\u62df\u5668\uff0c\u63d0\u4f9b\u4e09\u4e2a\u6838\u5fc3\u80fd\u529b\uff1a1\uff09\u771f\u5b9e\u3001\u5f00\u653e\u5f0f\u7684\u4e16\u754c\u6a21\u62df\uff0c\u5305\u62ec\u51c6\u786e\u7684\u7269\u7406\u548c\u793e\u4f1a\u52a8\u6001\u4ee5\u53ca\u8bed\u8a00\u9a71\u52a8\u7684\u7a0b\u5e8f\u5316\u73af\u5883\u751f\u6210\uff1b2\uff09\u4e3aLLM/VLM\u667a\u80fd\u4f53\u63d0\u4f9b\u4e30\u5bcc\u7684\u591a\u6a21\u6001\u63a5\u53e3\uff0c\u652f\u6301\u4e0d\u540c\u62bd\u8c61\u7ea7\u522b\u7684\u5f00\u653e\u8bcd\u6c47\u52a8\u4f5c\uff1b3\uff09\u591a\u6837\u4e14\u53ef\u6269\u5c55\u7684\u7269\u7406\u548c\u793e\u4f1a\u63a8\u7406\u573a\u666f\uff0c\u7528\u6237\u53ef\u8f7b\u677e\u5b9a\u5236\u3002", "result": "\u901a\u8fc7\u5728\u6d89\u53ca\u6218\u7565\u5408\u4f5c\u4e0e\u7ade\u4e89\u7684\u957f\u671f\u591a\u667a\u80fd\u4f53\u914d\u9001\u4efb\u52a1\u4e2d\u90e8\u7f72\u524d\u6cbfLLM\u667a\u80fd\u4f53\uff08\u5982GPT-4o\u3001Gemini-2.5-Flash\u7b49\uff09\uff0c\u5c55\u793a\u4e86SimWorld\u7684\u80fd\u529b\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u6a21\u578b\u4e4b\u95f4\u7684\u63a8\u7406\u6a21\u5f0f\u548c\u5c40\u9650\u6027\u5dee\u5f02\u3002", "conclusion": "SimWorld\u4f5c\u4e3a\u4e00\u4e2a\u5f00\u6e90\u5e73\u53f0\uff0c\u6709\u671b\u6210\u4e3a\u8de8\u5b66\u79d1\u63a8\u8fdb\u73b0\u5b9e\u4e16\u754c\u667a\u80fd\u4f53\u667a\u80fd\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u4e3a\u5f00\u53d1\u80fd\u591f\u5728\u590d\u6742\u7269\u7406\u548c\u793e\u4f1a\u73af\u5883\u4e2d\u6709\u6548\u8fd0\u4f5c\u7684AI\u667a\u80fd\u4f53\u63d0\u4f9b\u91cd\u8981\u652f\u6301\u3002"}}
{"id": "2512.01595", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.01595", "abs": "https://arxiv.org/abs/2512.01595", "authors": ["Harish Yadav", "Vikas Maurya", "Abhilash Jindal", "Vireshwar Kumar"], "title": "WhiteLie: A Robust System for Spoofing User Data in Android Platforms", "comment": null, "summary": "Android employs a permission framework that empowers users to either accept or deny sharing their private data (for example, location) with an app. However, many apps tend to crash when they are denied permission, leaving users no choice but to allow access to their data in order to use the app. In this paper, we introduce a comprehensive and robust user data spoofing system, WhiteLie, that can spoof a variety of user data and feed it to target apps. Additionally, it detects privacy-violating behaviours, automatically responding by supplying spoofed data instead of the user's real data, without crashing or disrupting the apps. Unlike prior approaches, WhiteLie requires neither device rooting nor altering the app's binary, making it deployable on stock Android devices. Through experiments on more than 70 popular Android apps, we demonstrate that WhiteLie is able to deceive apps into accepting spoofed data without getting detected. Our evaluation further demonstrates that WhiteLie introduces negligible overhead in terms of battery usage, CPU consumption, and app execution latency. Our findings underscore the feasibility of implementing user-centric privacy-enhancing mechanisms within the existing Android ecosystem.", "AI": {"tldr": "WhiteLie\u662f\u4e00\u4e2aAndroid\u7528\u6237\u6570\u636e\u6b3a\u9a97\u7cfb\u7edf\uff0c\u80fd\u5728\u4e0droot\u8bbe\u5907\u6216\u4fee\u6539\u5e94\u7528\u7684\u60c5\u51b5\u4e0b\uff0c\u5411\u5e94\u7528\u63d0\u4f9b\u865a\u5047\u6570\u636e\u4ee5\u4fdd\u62a4\u7528\u6237\u9690\u79c1\uff0c\u540c\u65f6\u907f\u514d\u5e94\u7528\u5d29\u6e83\u3002", "motivation": "Android\u6743\u9650\u6846\u67b6\u5141\u8bb8\u7528\u6237\u62d2\u7edd\u5e94\u7528\u8bbf\u95ee\u9690\u79c1\u6570\u636e\uff0c\u4f46\u8bb8\u591a\u5e94\u7528\u5728\u88ab\u62d2\u7edd\u6743\u9650\u65f6\u4f1a\u5d29\u6e83\uff0c\u8feb\u4f7f\u7528\u6237\u5fc5\u987b\u5141\u8bb8\u8bbf\u95ee\u624d\u80fd\u4f7f\u7528\u5e94\u7528\u3002", "method": "\u5f00\u53d1\u4e86WhiteLie\u7cfb\u7edf\uff0c\u80fd\u591f\u6b3a\u9a97\u591a\u79cd\u7528\u6237\u6570\u636e\u5e76\u68c0\u6d4b\u9690\u79c1\u8fdd\u89c4\u884c\u4e3a\uff0c\u81ea\u52a8\u5411\u76ee\u6807\u5e94\u7528\u63d0\u4f9b\u865a\u5047\u6570\u636e\u800c\u975e\u771f\u5b9e\u6570\u636e\uff0c\u65e0\u9700\u8bbe\u5907root\u6216\u4fee\u6539\u5e94\u7528\u4e8c\u8fdb\u5236\u6587\u4ef6\u3002", "result": "\u572870\u591a\u4e2a\u6d41\u884cAndroid\u5e94\u7528\u4e0a\u6d4b\u8bd5\uff0cWhiteLie\u80fd\u591f\u6210\u529f\u6b3a\u9a97\u5e94\u7528\u63a5\u53d7\u865a\u5047\u6570\u636e\u800c\u4e0d\u88ab\u68c0\u6d4b\uff0c\u4e14\u5728\u7535\u6c60\u4f7f\u7528\u3001CPU\u6d88\u8017\u548c\u5e94\u7528\u6267\u884c\u5ef6\u8fdf\u65b9\u9762\u5f15\u5165\u7684\u5f00\u9500\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86\u5728\u73b0\u6709Android\u751f\u6001\u7cfb\u7edf\u4e2d\u5b9e\u65bd\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u9690\u79c1\u589e\u5f3a\u673a\u5236\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2512.01099", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01099", "abs": "https://arxiv.org/abs/2512.01099", "authors": ["Daria Smirnova", "Hamid Nasiri", "Marta Adamska", "Zhengxin Yu", "Peter Garraghan"], "title": "Energy-Aware Data-Driven Model Selection in LLM-Orchestrated AI Systems", "comment": null, "summary": "As modern artificial intelligence (AI) systems become more advanced and capable, they can leverage a wide range of tools and models to perform complex tasks. Today, the task of orchestrating these models is often performed by Large Language Models (LLMs) that rely on qualitative descriptions of models for decision-making. However, the descriptions provided to these LLM-based orchestrators do not reflect true model capabilities and performance characteristics, leading to suboptimal model selection, reduced accuracy, and increased energy costs. In this paper, we conduct an empirical analysis of LLM-based orchestration limitations and propose GUIDE, a new energy-aware model selection framework that accounts for performance-energy trade-offs by incorporating quantitative model performance characteristics in decision-making. Experimental results demonstrate that GUIDE increases accuracy by 0.90%-11.92% across various evaluated tasks, and achieves up to 54% energy efficiency improvement, while reducing orchestrator model selection latency from 4.51 s to 7.2 ms.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faGUIDE\u6846\u67b6\uff0c\u901a\u8fc7\u91cf\u5316\u6a21\u578b\u6027\u80fd\u7279\u5f81\u8fdb\u884c\u80fd\u6e90\u611f\u77e5\u7684\u6a21\u578b\u9009\u62e9\uff0c\u89e3\u51b3LLM\u7f16\u6392\u5668\u56e0\u4f9d\u8d56\u5b9a\u6027\u63cf\u8ff0\u5bfc\u81f4\u7684\u6a21\u578b\u9009\u62e9\u6b21\u4f18\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u7f16\u6392\u5668\u4f9d\u8d56\u5b9a\u6027\u6a21\u578b\u63cf\u8ff0\u8fdb\u884c\u51b3\u7b56\uff0c\u8fd9\u4e9b\u63cf\u8ff0\u4e0d\u80fd\u53cd\u6620\u771f\u5b9e\u7684\u6a21\u578b\u80fd\u529b\u548c\u6027\u80fd\u7279\u5f81\uff0c\u5bfc\u81f4\u6a21\u578b\u9009\u62e9\u6b21\u4f18\u3001\u51c6\u786e\u6027\u964d\u4f4e\u548c\u80fd\u8017\u589e\u52a0\u3002", "method": "\u63d0\u51faGUIDE\u6846\u67b6\uff0c\u5728\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u7eb3\u5165\u91cf\u5316\u6a21\u578b\u6027\u80fd\u7279\u5f81\uff0c\u8003\u8651\u6027\u80fd-\u80fd\u8017\u6743\u8861\uff0c\u5b9e\u73b0\u80fd\u6e90\u611f\u77e5\u7684\u6a21\u578b\u9009\u62e9\u3002", "result": "GUIDE\u5728\u5404\u79cd\u8bc4\u4f30\u4efb\u52a1\u4e2d\u5c06\u51c6\u786e\u6027\u63d0\u9ad80.90%-11.92%\uff0c\u5b9e\u73b0\u9ad8\u8fbe54%\u7684\u80fd\u6548\u63d0\u5347\uff0c\u5e76\u5c06\u7f16\u6392\u5668\u6a21\u578b\u9009\u62e9\u5ef6\u8fdf\u4ece4.51\u79d2\u964d\u4f4e\u52307.2\u6beb\u79d2\u3002", "conclusion": "\u901a\u8fc7\u7eb3\u5165\u91cf\u5316\u6a21\u578b\u6027\u80fd\u7279\u5f81\uff0cGUIDE\u6846\u67b6\u663e\u8457\u6539\u5584\u4e86LLM\u7f16\u6392\u5668\u7684\u6a21\u578b\u9009\u62e9\u6548\u679c\uff0c\u5728\u63d0\u9ad8\u51c6\u786e\u6027\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u80fd\u8017\u548c\u5ef6\u8fdf\u3002"}}
{"id": "2512.01604", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.01604", "abs": "https://arxiv.org/abs/2512.01604", "authors": ["Shuai Feng", "Liang Feng Zhang"], "title": "On the Context-Hiding Property of Shamir-Based Homomorphic Secret Sharing", "comment": "2025 IEEE International Symposium on Information Theory", "summary": "Homomorphic secret sharing (HSS) allows multiple input clients to secretly share their private inputs to a function among several servers such that each server can homomorphically compute the function over its share to produce a share of the function's output. In HSS-enabled applications such as secure multi-party computation (MPC), security requires that the output shares leak no more information about the inputs than the function output. Such security is ensured by the context-hiding property of HSS. The typical rerandomization technique achieves context hiding but increases the share size. To address this, we formalize the context-hiding property of HSS for individual functions, examine the context-hiding property of Shamir-based HSS for monomials, and extend the study to polynomials.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u540c\u6001\u79d8\u5bc6\u5171\u4eab\uff08HSS\uff09\u7684\u4e0a\u4e0b\u6587\u9690\u85cf\u5c5e\u6027\uff0c\u91cd\u70b9\u5173\u6ce8\u5355\u9879\u5f0f\u548c\u591a\u9879\u5f0f\u7684Shamir-based HSS\uff0c\u65e8\u5728\u89e3\u51b3\u4f20\u7edf\u91cd\u968f\u673a\u5316\u6280\u672f\u589e\u52a0\u4efd\u989d\u5927\u5c0f\u7684\u95ee\u9898\u3002", "motivation": "\u5728HSS\u652f\u6301\u7684\u5e94\u7528\u5982\u5b89\u5168\u591a\u65b9\u8ba1\u7b97\u4e2d\uff0c\u5b89\u5168\u6027\u8981\u6c42\u8f93\u51fa\u4efd\u989d\u4e0d\u6cc4\u9732\u8d85\u51fa\u51fd\u6570\u8f93\u51fa\u4e4b\u5916\u7684\u8f93\u5165\u4fe1\u606f\u3002\u4f20\u7edf\u91cd\u968f\u673a\u5316\u6280\u672f\u867d\u7136\u80fd\u5b9e\u73b0\u4e0a\u4e0b\u6587\u9690\u85cf\uff0c\u4f46\u4f1a\u589e\u52a0\u4efd\u989d\u5927\u5c0f\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f62\u5f0f\u5316\u4e86\u5355\u4e2a\u51fd\u6570\u7684HSS\u4e0a\u4e0b\u6587\u9690\u85cf\u5c5e\u6027\uff0c\u7814\u7a76\u4e86\u5355\u9879\u5f0f\u7684Shamir-based HSS\u7684\u4e0a\u4e0b\u6587\u9690\u85cf\u7279\u6027\uff0c\u5e76\u5c06\u7814\u7a76\u6269\u5c55\u5230\u591a\u9879\u5f0f\u7684\u60c5\u51b5\u3002", "result": "\u8bba\u6587\u5206\u6790\u4e86Shamir-based HSS\u5728\u5355\u9879\u5f0f\u548c\u591a\u9879\u5f0f\u4e0a\u7684\u4e0a\u4e0b\u6587\u9690\u85cf\u5c5e\u6027\uff0c\u4e3a\u8bbe\u8ba1\u66f4\u9ad8\u6548\u7684HSS\u65b9\u6848\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u91cd\u968f\u673a\u5316\u6280\u672f\u5e26\u6765\u7684\u4efd\u989d\u5927\u5c0f\u589e\u52a0\u95ee\u9898\u3002", "conclusion": "\u901a\u8fc7\u5f62\u5f0f\u5316HSS\u7684\u4e0a\u4e0b\u6587\u9690\u85cf\u5c5e\u6027\u5e76\u5206\u6790Shamir-based\u65b9\u6848\u5728\u5355\u9879\u5f0f\u548c\u591a\u9879\u5f0f\u4e0a\u7684\u8868\u73b0\uff0c\u4e3a\u6784\u5efa\u66f4\u9ad8\u6548\u3001\u5b89\u5168\u7684HSS\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u4f18\u5316\u5b89\u5168\u591a\u65b9\u8ba1\u7b97\u7b49\u5e94\u7528\u3002"}}
{"id": "2512.01107", "categories": ["cs.AI", "econ.EM", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.01107", "abs": "https://arxiv.org/abs/2512.01107", "authors": ["Sanjog Misra"], "title": "Foundation Priors", "comment": null, "summary": "Foundation models, and in particular large language models, can generate highly informative responses, prompting growing interest in using these ''synthetic'' outputs as data in empirical research and decision-making. This paper introduces the idea of a foundation prior, which shows that model-generated outputs are not as real observations, but draws from the foundation prior induced prior predictive distribution. As such synthetic data reflects both the model's learned patterns and the user's subjective priors, expectations, and biases. We model the subjectivity of the generative process by making explicit the dependence of synthetic outputs on the user's anticipated data distribution, the prompt-engineering process, and the trust placed in the foundation model.\n  We derive the foundation prior as an exponential-tilted, generalized Bayesian update of the user's primitive prior, where a trust parameter governs the weight assigned to synthetic data. We then show how synthetic data and the associated foundation prior can be incorporated into standard statistical and econometric workflows, and discuss their use in applications such as refining complex models, informing latent constructs, guiding experimental design, and augmenting random-coefficient and partially linear specifications. By treating generative outputs as structured, explicitly subjective priors rather than as empirical observations, the framework offers a principled way to harness foundation models in empirical work while avoiding the conflation of synthetic ''facts'' with real data.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u57fa\u7840\u5148\u9a8c\"\u6982\u5ff5\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u5408\u6210\u6570\u636e\u89c6\u4e3a\u6765\u81ea\u5148\u9a8c\u9884\u6d4b\u5206\u5e03\u7684\u62bd\u6837\uff0c\u800c\u975e\u771f\u5b9e\u89c2\u6d4b\uff0c\u4e3a\u5728\u5b9e\u8bc1\u7814\u7a76\u4e2d\u4f7f\u7528\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u539f\u5219\u6027\u6846\u67b6\u3002", "motivation": "\u968f\u7740\u57fa\u7840\u6a21\u578b\uff08\u7279\u522b\u662f\u5927\u8bed\u8a00\u6a21\u578b\uff09\u751f\u6210\u9ad8\u8d28\u91cf\u54cd\u5e94\u7684\u80fd\u529b\u589e\u5f3a\uff0c\u7814\u7a76\u8005\u8d8a\u6765\u8d8a\u503e\u5411\u4e8e\u5728\u5b9e\u8bc1\u7814\u7a76\u548c\u51b3\u7b56\u4e2d\u4f7f\u7528\u8fd9\u4e9b\"\u5408\u6210\"\u8f93\u51fa\u4f5c\u4e3a\u6570\u636e\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u5408\u6210\u6570\u636e\u5e76\u975e\u771f\u5b9e\u89c2\u6d4b\uff0c\u800c\u662f\u53cd\u6620\u4e86\u6a21\u578b\u5b66\u4e60\u5230\u7684\u6a21\u5f0f\u4ee5\u53ca\u7528\u6237\u7684\u4e3b\u89c2\u5148\u9a8c\u3001\u671f\u671b\u548c\u504f\u89c1\uff0c\u9700\u8981\u5efa\u7acb\u7406\u8bba\u6846\u67b6\u6765\u907f\u514d\u5c06\u5408\u6210\"\u4e8b\u5b9e\"\u4e0e\u771f\u5b9e\u6570\u636e\u6df7\u6dc6\u3002", "method": "\u63d0\u51fa\"\u57fa\u7840\u5148\u9a8c\"\u6982\u5ff5\uff0c\u5c06\u751f\u6210\u8fc7\u7a0b\u7684\u4e3b\u89c2\u6027\u5efa\u6a21\u4e3a\u4f9d\u8d56\u4e8e\u7528\u6237\u9884\u671f\u6570\u636e\u5206\u5e03\u3001\u63d0\u793a\u5de5\u7a0b\u8fc7\u7a0b\u548c\u6a21\u578b\u4fe1\u4efb\u5ea6\u7684\u51fd\u6570\u3002\u901a\u8fc7\u6307\u6570\u503e\u659c\u7684\u5e7f\u4e49\u8d1d\u53f6\u65af\u66f4\u65b0\u63a8\u5bfc\u57fa\u7840\u5148\u9a8c\uff0c\u5176\u4e2d\u4fe1\u4efb\u53c2\u6570\u63a7\u5236\u5408\u6210\u6570\u636e\u7684\u6743\u91cd\u3002", "result": "\u5efa\u7acb\u4e86\u5c06\u5408\u6210\u6570\u636e\u548c\u76f8\u5173\u57fa\u7840\u5148\u9a8c\u7eb3\u5165\u6807\u51c6\u7edf\u8ba1\u548c\u8ba1\u91cf\u7ecf\u6d4e\u5b66\u5de5\u4f5c\u6d41\u7a0b\u7684\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5728\u7cbe\u70bc\u590d\u6742\u6a21\u578b\u3001\u6307\u5bfc\u6f5c\u5728\u6784\u5ff5\u3001\u6307\u5bfc\u5b9e\u9a8c\u8bbe\u8ba1\u4ee5\u53ca\u589e\u5f3a\u968f\u673a\u7cfb\u6570\u548c\u90e8\u5206\u7ebf\u6027\u89c4\u8303\u7b49\u5e94\u7528\u4e2d\u7684\u4f7f\u7528\u65b9\u5f0f\u3002", "conclusion": "\u901a\u8fc7\u5c06\u751f\u6210\u8f93\u51fa\u89c6\u4e3a\u7ed3\u6784\u5316\u3001\u660e\u786e\u4e3b\u89c2\u7684\u5148\u9a8c\u800c\u975e\u7ecf\u9a8c\u89c2\u6d4b\uff0c\u8be5\u6846\u67b6\u4e3a\u5728\u5b9e\u8bc1\u5de5\u4f5c\u4e2d\u5229\u7528\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u907f\u514d\u4e86\u5408\u6210\"\u4e8b\u5b9e\"\u4e0e\u771f\u5b9e\u6570\u636e\u7684\u6df7\u6dc6\uff0c\u4e3a\u5408\u6210\u6570\u636e\u5728\u79d1\u5b66\u7814\u7a76\u4e2d\u7684\u5408\u7406\u4f7f\u7528\u5960\u5b9a\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2512.01149", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.01149", "abs": "https://arxiv.org/abs/2512.01149", "authors": ["Krishna Taduri", "Shaunak Dhande", "Giacinto Paolo", "Saggese", "Paul Smith"], "title": "A Benchmark of Causal vs Correlation AI for Predictive Maintenance", "comment": null, "summary": "Predictive maintenance in manufacturing environments presents a challenging optimization problem characterized by extreme cost asymmetry, where missed failures incur costs roughly fifty times higher than false alarms. Conventional machine learning approaches typically optimize statistical accuracy metrics that do not reflect this operational reality and cannot reliably distinguish causal relationships from spurious correlations. This study evaluates eight predictive models, ranging from baseline statistical approaches to formal causal inference methods, on a dataset of 10,000 CNC machines with a 3.3% failure prevalence. The formal causal inference model (L5) achieved estimated annual cost savings of 1.16 million USD (a 70.2 percent reduction), outperforming the best correlation-based decision tree model (L3) by approximately 80,000 USD per year. The causal model matched the highest observed recall (87.9 percent) while reducing false alarms by 97 percent (from 165 to 5) and attained a precision of 92.1 percent, with a train-test performance gap of only 2.6 percentage points. These results indicate that causal AI methods, when combined with domain knowledge, can yield superior financial outcomes and more interpretable predictions compared to correlation-based approaches in predictive maintenance applications.", "AI": {"tldr": "\u56e0\u679cAI\u65b9\u6cd5\u5728\u9884\u6d4b\u6027\u7ef4\u62a4\u4e2d\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u76f8\u5173\u65b9\u6cd5\uff0c\u5b9e\u73b0\u5e74\u8282\u7701116\u4e07\u7f8e\u5143\u6210\u672c\uff0c\u51cf\u5c1170.2%\u635f\u5931", "motivation": "\u5236\u9020\u4e1a\u9884\u6d4b\u6027\u7ef4\u62a4\u9762\u4e34\u6781\u7aef\u6210\u672c\u4e0d\u5bf9\u79f0\u95ee\u9898\uff08\u6f0f\u68c0\u6210\u672c\u662f\u8bef\u62a5\u768450\u500d\uff09\uff0c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4f18\u5316\u7edf\u8ba1\u51c6\u786e\u6027\u6307\u6807\u800c\u975e\u5b9e\u9645\u8fd0\u8425\u6210\u672c\uff0c\u4e14\u65e0\u6cd5\u533a\u5206\u56e0\u679c\u5173\u7cfb\u4e0e\u865a\u5047\u76f8\u5173", "method": "\u8bc4\u4f308\u79cd\u9884\u6d4b\u6a21\u578b\uff0c\u5305\u62ec\u57fa\u7ebf\u7edf\u8ba1\u65b9\u6cd5\u548c\u6b63\u5f0f\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\uff0c\u572810,000\u53f0CNC\u673a\u5e8a\u6570\u636e\u96c6\uff08\u6545\u969c\u73873.3%\uff09\u4e0a\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790", "result": "\u6b63\u5f0f\u56e0\u679c\u63a8\u65ad\u6a21\u578b\uff08L5\uff09\u5b9e\u73b0\u5e74\u8282\u7701116\u4e07\u7f8e\u5143\uff08\u51cf\u5c1170.2%\u635f\u5931\uff09\uff0c\u6bd4\u6700\u4f73\u76f8\u5173\u51b3\u7b56\u6811\u6a21\u578b\uff08L3\uff09\u6bcf\u5e74\u591a\u8282\u77018\u4e07\u7f8e\u5143\uff1b\u4fdd\u6301\u6700\u9ad8\u53ec\u56de\u738787.9%\u7684\u540c\u65f6\u51cf\u5c1197%\u8bef\u62a5\uff08\u4ece165\u964d\u81f35\uff09\uff0c\u7cbe\u5ea6\u8fbe92.1%\uff0c\u8bad\u7ec3\u6d4b\u8bd5\u6027\u80fd\u5dee\u8ddd\u4ec52.6\u4e2a\u767e\u5206\u70b9", "conclusion": "\u56e0\u679cAI\u65b9\u6cd5\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u5728\u9884\u6d4b\u6027\u7ef4\u62a4\u5e94\u7528\u4e2d\u80fd\u4ea7\u751f\u66f4\u4f18\u8d22\u52a1\u7ed3\u679c\u548c\u66f4\u53ef\u89e3\u91ca\u7684\u9884\u6d4b\uff0c\u76f8\u6bd4\u57fa\u4e8e\u76f8\u5173\u7684\u65b9\u6cd5\u5177\u6709\u663e\u8457\u4f18\u52bf"}}
{"id": "2512.01666", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.01666", "abs": "https://arxiv.org/abs/2512.01666", "authors": ["Tianheng Qu", "Hongsong Zhu", "Limin Sun", "Haining Wang", "Haiqiang Fei", "Zheng He", "Zhi Li"], "title": "Demystifying Feature Engineering in Malware Analysis of API Call Sequences", "comment": null, "summary": "Machine learning (ML) has been widely used to analyze API call sequences in malware analysis, which typically requires the expertise of domain specialists to extract relevant features from raw data. The extracted features play a critical role in malware analysis. Traditional feature extraction is based on human domain knowledge, while there is a trend of using natural language processing (NLP) for automatic feature extraction. This raises a question: how do we effectively select features for malware analysis based on API call sequences? To answer it, this paper presents a comprehensive study of investigating the impact of feature engineering upon malware classification.We first conducted a comparative performance evaluation under three models, Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), and Transformer, with respect to knowledge-based and NLP-based feature engineering methods. We observed that models with knowledge-based feature engineering inputs generally outperform those using NLP-based across all metrics, especially under smaller sample sizes. Then we analyzed a complete set of data features from API call sequences, our analysis reveals that models often focus on features such as handles and virtual addresses, which vary across executions and are difficult for human analysts to interpret.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u57fa\u4e8eAPI\u8c03\u7528\u5e8f\u5217\u7684\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u4e2d\u7279\u5f81\u5de5\u7a0b\u7684\u5f71\u54cd\uff0c\u6bd4\u8f83\u4e86\u57fa\u4e8e\u9886\u57df\u77e5\u8bc6\u7684\u7279\u5f81\u5de5\u7a0b\u548c\u57fa\u4e8eNLP\u7684\u81ea\u52a8\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\u5728\u4e0d\u540c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e0a\u7684\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u4f20\u7edf\u6076\u610f\u8f6f\u4ef6\u5206\u6790\u4f9d\u8d56\u9886\u57df\u4e13\u5bb6\u624b\u52a8\u63d0\u53d6API\u8c03\u7528\u5e8f\u5217\u7279\u5f81\uff0c\u800cNLP\u65b9\u6cd5\u53ef\u5b9e\u73b0\u81ea\u52a8\u7279\u5f81\u63d0\u53d6\u3002\u672c\u6587\u65e8\u5728\u63a2\u7a76\u5982\u4f55\u6709\u6548\u9009\u62e9\u57fa\u4e8eAPI\u8c03\u7528\u5e8f\u5217\u7684\u7279\u5f81\u8fdb\u884c\u6076\u610f\u8f6f\u4ef6\u5206\u6790\uff0c\u6bd4\u8f83\u4e0d\u540c\u7279\u5f81\u5de5\u7a0b\u65b9\u6cd5\u5bf9\u5206\u7c7b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "1. \u4f7f\u7528\u4e09\u79cd\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08CNN\u3001LSTM\u3001Transformer\uff09\u8fdb\u884c\u6027\u80fd\u6bd4\u8f83\uff1b2. \u5bf9\u6bd4\u57fa\u4e8e\u9886\u57df\u77e5\u8bc6\u7684\u7279\u5f81\u5de5\u7a0b\u65b9\u6cd5\u548c\u57fa\u4e8eNLP\u7684\u7279\u5f81\u5de5\u7a0b\u65b9\u6cd5\uff1b3. \u5206\u6790API\u8c03\u7528\u5e8f\u5217\u7684\u5b8c\u6574\u7279\u5f81\u96c6\uff0c\u8bc6\u522b\u6a21\u578b\u5173\u6ce8\u7684\u5173\u952e\u7279\u5f81\u3002", "result": "1. \u4f7f\u7528\u57fa\u4e8e\u9886\u57df\u77e5\u8bc6\u7279\u5f81\u5de5\u7a0b\u7684\u6a21\u578b\u5728\u6240\u6709\u6307\u6807\u4e0a\u666e\u904d\u4f18\u4e8e\u4f7f\u7528NLP\u65b9\u6cd5\u7684\u6a21\u578b\uff0c\u7279\u522b\u662f\u5728\u5c0f\u6837\u672c\u60c5\u51b5\u4e0b\u4f18\u52bf\u66f4\u660e\u663e\uff1b2. \u5206\u6790\u53d1\u73b0\u6a21\u578b\u5f80\u5f80\u5173\u6ce8\u53e5\u67c4\uff08handles\uff09\u548c\u865a\u62df\u5730\u5740\u7b49\u7279\u5f81\uff0c\u4f46\u8fd9\u4e9b\u7279\u5f81\u5728\u4e0d\u540c\u6267\u884c\u4e2d\u53d8\u5316\u8f83\u5927\u4e14\u96be\u4ee5\u88ab\u4eba\u7c7b\u5206\u6790\u5e08\u89e3\u91ca\u3002", "conclusion": "\u57fa\u4e8e\u9886\u57df\u77e5\u8bc6\u7684\u7279\u5f81\u5de5\u7a0b\u5728\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u4e2d\u4ecd\u7136\u4f18\u4e8e\u81ea\u52a8NLP\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u91cf\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u3002\u7136\u800c\uff0c\u6a21\u578b\u5173\u6ce8\u7684\u67d0\u4e9b\u7279\u5f81\uff08\u5982\u53e5\u67c4\u548c\u865a\u62df\u5730\u5740\uff09\u5b58\u5728\u8de8\u6267\u884c\u53d8\u5f02\u6027\u548c\u53ef\u89e3\u91ca\u6027\u5dee\u7684\u95ee\u9898\uff0c\u8fd9\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2512.01210", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01210", "abs": "https://arxiv.org/abs/2512.01210", "authors": ["Ruiyu Wang", "Tuan Vinh", "Ran Xu", "Yuyin Zhou", "Jiaying Lu", "Carl Yang", "Francisco Pasquel"], "title": "Knowledge Graph Augmented Large Language Models for Next-Visit Disease Prediction", "comment": null, "summary": "Electronic health records (EHRs) support powerful clinical prediction models, but existing methods typically provide coarse, post hoc explanations that offer limited value for patient-level decision making. We introduce a knowledge graph (KG)-guided chain-of-thought (CoT) framework that generates clinically grounded and temporally consistent reasoning for visit-level disease prediction in MIMIC-III. ICD-9 codes are mapped to PrimeKG, from which disease-relevant nodes and multi-hop reasoning paths are extracted and used as scaffolds for CoT generation; only explanations whose conclusions match observed outcomes are retained. Lightweight LLaMA-3.1-Instruct-8B and Gemma-7B models are then fine-tuned on this supervision corpus. Across ten PrimeKG-mapped diseases and limited training cohorts (400 and 1000 cases), KG-guided models outperform strong classical baselines, achieving AUROC values of 0.66 to 0.70 and macro-AUPR values of 0.40 to 0.47. The models also transfer zero-shot to the CRADLE cohort, improving accuracy from approximately 0.40 to 0.51 up to 0.72 to 0.77. A blinded clinician evaluation shows consistent preference for KG-guided CoT explanations in clarity, relevance, and clinical correctness.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u5f15\u5bfc\u7684\u601d\u7ef4\u94fe\u6846\u67b6\uff0c\u4e3a\u7535\u5b50\u75c5\u5386\u4e2d\u7684\u75be\u75c5\u9884\u6d4b\u751f\u6210\u4e34\u5e8a\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u5728MIMIC-III\u548cCRADLE\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u826f\u597d\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7535\u5b50\u75c5\u5386\u9884\u6d4b\u6a21\u578b\u901a\u5e38\u63d0\u4f9b\u7c97\u7cd9\u7684\u4e8b\u540e\u89e3\u91ca\uff0c\u5bf9\u60a3\u8005\u5c42\u9762\u7684\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u6709\u9650\u3002\u9700\u8981\u751f\u6210\u5177\u6709\u4e34\u5e8a\u57fa\u7840\u548c\u65f6\u95f4\u4e00\u81f4\u6027\u7684\u53ef\u89e3\u91ca\u63a8\u7406\u3002", "method": "\u5c06ICD-9\u4ee3\u7801\u6620\u5c04\u5230PrimeKG\u77e5\u8bc6\u56fe\u8c31\uff0c\u63d0\u53d6\u75be\u75c5\u76f8\u5173\u8282\u70b9\u548c\u591a\u8df3\u63a8\u7406\u8def\u5f84\u4f5c\u4e3a\u601d\u7ef4\u94fe\u7684\u652f\u67b6\u3002\u4ec5\u4fdd\u7559\u7ed3\u8bba\u4e0e\u89c2\u5bdf\u7ed3\u679c\u5339\u914d\u7684\u89e3\u91ca\uff0c\u7528\u8fd9\u4e9b\u76d1\u7763\u6570\u636e\u5fae\u8c03LLaMA-3.1-Instruct-8B\u548cGemma-7B\u6a21\u578b\u3002", "result": "\u572810\u79cdPrimeKG\u6620\u5c04\u75be\u75c5\u548c\u6709\u9650\u8bad\u7ec3\u6570\u636e\uff08400\u548c1000\u4f8b\uff09\u4e0b\uff0cKG\u5f15\u5bfc\u6a21\u578b\u4f18\u4e8e\u4f20\u7edf\u57fa\u7ebf\uff0cAUROC\u8fbe0.66-0.70\uff0cmacro-AUPR\u8fbe0.40-0.47\u3002\u5728CRADLE\u961f\u5217\u4e0a\u96f6\u6837\u672c\u8fc1\u79fb\uff0c\u51c6\u786e\u7387\u4ece0.40-0.51\u63d0\u5347\u81f30.72-0.77\u3002\u4e34\u5e8a\u533b\u751f\u8bc4\u4f30\u663e\u793aKG\u5f15\u5bfc\u89e3\u91ca\u5728\u6e05\u6670\u5ea6\u3001\u76f8\u5173\u6027\u548c\u4e34\u5e8a\u6b63\u786e\u6027\u4e0a\u66f4\u53d7\u9752\u7750\u3002", "conclusion": "KG\u5f15\u5bfc\u7684\u601d\u7ef4\u94fe\u6846\u67b6\u80fd\u751f\u6210\u4e34\u5e8a\u53ef\u89e3\u91ca\u7684\u63a8\u7406\uff0c\u63d0\u9ad8\u75be\u75c5\u9884\u6d4b\u6027\u80fd\uff0c\u5e76\u5728\u8de8\u961f\u5217\u8fc1\u79fb\u4e2d\u4fdd\u6301\u6709\u6548\u6027\uff0c\u4e3a\u4e34\u5e8a\u51b3\u7b56\u63d0\u4f9b\u66f4\u6709\u4ef7\u503c\u7684\u89e3\u91ca\u3002"}}
{"id": "2512.01832", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.01832", "abs": "https://arxiv.org/abs/2512.01832", "authors": ["Francesco Buccafurri", "Carmen Licciardi"], "title": "A Privacy-Preserving Information-Sharing Protocol for Federated Authentication", "comment": null, "summary": "This paper presents a privacy-preserving protocol for identity registration and information sharing in federated authentication systems. The goal is to enable Identity Providers (IdPs) to detect duplicate or fraudulent identity enrollments without revealing users personal data or enabling cross-domain correlation. The protocol relies on Oblivious Pseudorandom Functions (OPRFs) combined with domain-specific transformations, ensuring that each IdP generates independent pseudonymous identifiers derived from a shared cryptographic service while maintaining full input confidentiality. A central authority maintains a blind registry that records successful and failed identity verifications using only pseudonymous identifiers, allowing global consistency checks without exposing sensitive information or linking users across domains. The proposed construction provides a general and abstract framework suitable for a wide range of federated authentication systems, achieving strong privacy guarantees while supporting effective fraud-prevention mechanisms during identity registration.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eOPRF\u7684\u9690\u79c1\u4fdd\u62a4\u534f\u8bae\uff0c\u7528\u4e8e\u8054\u90a6\u8ba4\u8bc1\u7cfb\u7edf\u4e2d\u7684\u8eab\u4efd\u6ce8\u518c\u548c\u4fe1\u606f\u5171\u4eab\uff0c\u80fd\u5728\u4e0d\u6cc4\u9732\u7528\u6237\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u68c0\u6d4b\u91cd\u590d\u6216\u6b3a\u8bc8\u8eab\u4efd\u6ce8\u518c", "motivation": "\u89e3\u51b3\u8054\u90a6\u8ba4\u8bc1\u7cfb\u7edf\u4e2d\u8eab\u4efd\u63d0\u4f9b\u5546\u9700\u8981\u68c0\u6d4b\u91cd\u590d\u6216\u6b3a\u8bc8\u8eab\u4efd\u6ce8\u518c\uff0c\u540c\u65f6\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u3001\u9632\u6b62\u8de8\u57df\u5173\u8054\u7684\u95ee\u9898", "method": "\u4f7f\u7528\u4e0d\u7ecf\u610f\u4f2a\u968f\u673a\u51fd\u6570\uff08OPRF\uff09\u7ed3\u5408\u9886\u57df\u7279\u5b9a\u53d8\u6362\uff0c\u6bcf\u4e2a\u8eab\u4efd\u63d0\u4f9b\u5546\u751f\u6210\u72ec\u7acb\u7684\u4f2a\u533f\u540d\u6807\u8bc6\u7b26\uff0c\u4e2d\u592e\u673a\u6784\u7ef4\u62a4\u76f2\u6ce8\u518c\u8868\u8bb0\u5f55\u9a8c\u8bc1\u7ed3\u679c", "result": "\u534f\u8bae\u63d0\u4f9b\u4e86\u901a\u7528\u62bd\u8c61\u6846\u67b6\uff0c\u5728\u4fdd\u6301\u5f3a\u9690\u79c1\u4fdd\u8bc1\u7684\u540c\u65f6\u652f\u6301\u6709\u6548\u7684\u6b3a\u8bc8\u9884\u9632\u673a\u5236\uff0c\u5b9e\u73b0\u5168\u5c40\u4e00\u81f4\u6027\u68c0\u67e5\u800c\u4e0d\u66b4\u9732\u654f\u611f\u4fe1\u606f", "conclusion": "\u8be5\u534f\u8bae\u4e3a\u8054\u90a6\u8ba4\u8bc1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9690\u79c1\u4fdd\u62a4\u7684\u8eab\u4efd\u6ce8\u518c\u548c\u4fe1\u606f\u5171\u4eab\u89e3\u51b3\u65b9\u6848\uff0c\u5e73\u8861\u4e86\u9690\u79c1\u4fdd\u62a4\u548c\u6b3a\u8bc8\u68c0\u6d4b\u7684\u9700\u6c42"}}
{"id": "2512.01222", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01222", "abs": "https://arxiv.org/abs/2512.01222", "authors": ["Ching Fang", "Samuel Marks"], "title": "Unsupervised decoding of encoded reasoning using language model interpretability", "comment": null, "summary": "As large language models become increasingly capable, there is growing concern that they may develop reasoning processes that are encoded or hidden from human oversight. To investigate whether current interpretability techniques can penetrate such encoded reasoning, we construct a controlled testbed by fine-tuning a reasoning model (DeepSeek-R1-Distill-Llama-70B) to perform chain-of-thought reasoning in ROT-13 encryption while maintaining intelligible English outputs. We evaluate mechanistic interpretability methods--in particular, logit lens analysis--on their ability to decode the model's hidden reasoning process using only internal activations. We show that logit lens can effectively translate encoded reasoning, with accuracy peaking in intermediate-to-late layers. Finally, we develop a fully unsupervised decoding pipeline that combines logit lens with automated paraphrasing, achieving substantial accuracy in reconstructing complete reasoning transcripts from internal model representations. These findings suggest that current mechanistic interpretability techniques may be more robust to simple forms of encoded reasoning than previously understood. Our work provides an initial framework for evaluating interpretability methods against models that reason in non-human-readable formats, contributing to the broader challenge of maintaining oversight over increasingly capable AI systems.", "AI": {"tldr": "\u7814\u7a76\u4eba\u5458\u901a\u8fc7\u8ba9\u8bed\u8a00\u6a21\u578b\u5728ROT-13\u52a0\u5bc6\u4e0b\u8fdb\u884c\u63a8\u7406\uff0c\u6d4b\u8bd5\u4e86\u5f53\u524d\u53ef\u89e3\u91ca\u6027\u6280\u672f\u80fd\u5426\u89e3\u7801\u6a21\u578b\u7684\u9690\u85cf\u63a8\u7406\u8fc7\u7a0b\uff0c\u53d1\u73b0logit lens\u65b9\u6cd5\u80fd\u6709\u6548\u7ffb\u8bd1\u7f16\u7801\u63a8\u7406\uff0c\u5e76\u5f00\u53d1\u4e86\u5b8c\u5168\u65e0\u76d1\u7763\u7684\u89e3\u7801\u6d41\u7a0b\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u589e\u5f3a\uff0c\u4eba\u4eec\u62c5\u5fc3\u5b83\u4eec\u53ef\u80fd\u53d1\u5c55\u51fa\u4eba\u7c7b\u65e0\u6cd5\u76d1\u7763\u7684\u7f16\u7801\u63a8\u7406\u8fc7\u7a0b\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u5f53\u524d\u53ef\u89e3\u91ca\u6027\u6280\u672f\u80fd\u5426\u7a7f\u900f\u8fd9\u79cd\u7f16\u7801\u63a8\u7406\uff0c\u4e3a\u76d1\u7763\u65e5\u76ca\u5f3a\u5927\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u5fae\u8c03\u63a8\u7406\u6a21\u578b\uff08DeepSeek-R1-Distill-Llama-70B\uff09\uff0c\u4f7f\u5176\u5728ROT-13\u52a0\u5bc6\u4e0b\u8fdb\u884c\u94fe\u5f0f\u63a8\u7406\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u7406\u89e3\u7684\u82f1\u8bed\u8f93\u51fa\u3002\u7136\u540e\u4f7f\u7528\u673a\u5236\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff08\u7279\u522b\u662flogit lens\u5206\u6790\uff09\u8bc4\u4f30\u4ec5\u901a\u8fc7\u5185\u90e8\u6fc0\u6d3b\u89e3\u7801\u6a21\u578b\u9690\u85cf\u63a8\u7406\u8fc7\u7a0b\u7684\u80fd\u529b\u3002", "result": "logit lens\u80fd\u6709\u6548\u7ffb\u8bd1\u7f16\u7801\u63a8\u7406\uff0c\u51c6\u786e\u7387\u5728\u4e2d\u540e\u671f\u5c42\u8fbe\u5230\u5cf0\u503c\u3002\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86\u5b8c\u5168\u65e0\u76d1\u7763\u7684\u89e3\u7801\u6d41\u7a0b\uff0c\u7ed3\u5408logit lens\u548c\u81ea\u52a8\u8f6c\u8ff0\uff0c\u4ece\u5185\u90e8\u6a21\u578b\u8868\u793a\u4e2d\u91cd\u5efa\u5b8c\u6574\u63a8\u7406\u8bb0\u5f55\uff0c\u53d6\u5f97\u4e86\u663e\u8457\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u5f53\u524d\u673a\u5236\u53ef\u89e3\u91ca\u6027\u6280\u672f\u5bf9\u7b80\u5355\u5f62\u5f0f\u7684\u7f16\u7801\u63a8\u7406\u53ef\u80fd\u6bd4\u4e4b\u524d\u7406\u89e3\u7684\u66f4\u52a0\u9c81\u68d2\u3002\u8fd9\u9879\u5de5\u4f5c\u4e3a\u8bc4\u4f30\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u5bf9\u6297\u975e\u4eba\u7c7b\u53ef\u8bfb\u683c\u5f0f\u63a8\u7406\u6a21\u578b\u63d0\u4f9b\u4e86\u521d\u6b65\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u89e3\u51b3\u76d1\u7763\u65e5\u76ca\u5f3a\u5927AI\u7cfb\u7edf\u7684\u66f4\u5e7f\u6cdb\u6311\u6218\u3002"}}
{"id": "2512.01891", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.01891", "abs": "https://arxiv.org/abs/2512.01891", "authors": ["Giada Stivala", "Rafael Mrowczynski", "Maria Hellenthal", "Giancarlo Pellegrino"], "title": "Behind the Curtain: How Shared Hosting Providers Respond to Vulnerability Notifications", "comment": "Accepted at IEEE S&P 2026", "summary": "Large-scale vulnerability notifications (VNs) can help hosting provider organizations (HPOs) identify and remediate security vulnerabilities that attackers can exploit in data breaches or phishing campaigns. Previous VN studies have primarily focused on factors under the control of reporters, such as sender reputation, email formatting, and communication channels. Despite these efforts, remediation rates for vulnerability notifications continue to remain consistently low. This paper presents the first in-depth study of how HPOs process vulnerability notifications internally and what organizational and operational factors influence VN effectiveness. We examine the problem from a different perspective to provide the first detailed understanding of the reasons behind persistently low remediation rates. Instead of manipulating parameters of VN campaigns, we interview hosting providers directly, investigating how they handle vulnerability notifications and what factors may influence VN effectiveness, such as VN awareness and reachability, HPOs' service models, and perceived security risks.\n  We conducted semi-structured interviews with 24 HPOs across shared hosting and web development services, representing varied company sizes and operator roles. Our findings reveal practical insights on VN processing and abuse workflows. While some providers remain hard to reach due to complex infrastructures, most report routinely handling VNs. However, limited remediation often stems from strict responsibility boundaries, where web application issues are seen as the customer's domain. Low hosting fees and high volumes of daily compromises further discourage both proactive and reactive measures. Our findings show that HPOs blame negligent website owners, and prior works on website owners confirms they often undervalue their sites or lack security know-how.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u6df1\u5165\u7814\u7a76\u4e86\u6258\u7ba1\u670d\u52a1\u63d0\u4f9b\u5546\u5982\u4f55\u5904\u7406\u6f0f\u6d1e\u901a\u77e5\uff0c\u63ed\u793a\u4e86\u5bfc\u81f4\u4fee\u590d\u7387\u6301\u7eed\u4f4e\u4e0b\u7684\u7ec4\u7ec7\u4e0e\u8fd0\u8425\u56e0\u7d20\uff0c\u800c\u975e\u4ec5\u4ec5\u5173\u6ce8\u901a\u77e5\u53d1\u9001\u65b9\u7684\u53ef\u63a7\u56e0\u7d20\u3002", "motivation": "\u5c3d\u7ba1\u4e4b\u524d\u7684\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u901a\u77e5\u53d1\u9001\u65b9\u53ef\u63a7\u7684\u56e0\u7d20\uff08\u5982\u53d1\u4ef6\u4eba\u4fe1\u8a89\u3001\u90ae\u4ef6\u683c\u5f0f\u3001\u901a\u4fe1\u6e20\u9053\uff09\uff0c\u4f46\u6f0f\u6d1e\u901a\u77e5\u7684\u4fee\u590d\u7387\u4ecd\u7136\u6301\u7eed\u4f4e\u4e0b\u3002\u672c\u6587\u65e8\u5728\u4ece\u6258\u7ba1\u670d\u52a1\u63d0\u4f9b\u5546\u7684\u89d2\u5ea6\uff0c\u9996\u6b21\u6df1\u5165\u4e86\u89e3\u5bfc\u81f4\u4fee\u590d\u7387\u4f4e\u4e0b\u7684\u6839\u672c\u539f\u56e0\u3002", "method": "\u901a\u8fc7\u5bf924\u5bb6\u6258\u7ba1\u670d\u52a1\u63d0\u4f9b\u5546\uff08\u6db5\u76d6\u5171\u4eab\u6258\u7ba1\u548c\u7f51\u7ad9\u5f00\u53d1\u670d\u52a1\uff0c\u4e0d\u540c\u516c\u53f8\u89c4\u6a21\u548c\u64cd\u4f5c\u89d2\u8272\uff09\u8fdb\u884c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u76f4\u63a5\u8c03\u67e5\u4ed6\u4eec\u5982\u4f55\u5904\u7406\u6f0f\u6d1e\u901a\u77e5\u4ee5\u53ca\u5f71\u54cd\u901a\u77e5\u6709\u6548\u6027\u7684\u56e0\u7d20\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a\u867d\u7136\u590d\u6742\u57fa\u7840\u8bbe\u65bd\u5bfc\u81f4\u90e8\u5206\u63d0\u4f9b\u5546\u96be\u4ee5\u8054\u7cfb\uff0c\u4f46\u5927\u591a\u6570\u4f1a\u5e38\u89c4\u5904\u7406\u6f0f\u6d1e\u901a\u77e5\u3002\u4fee\u590d\u7387\u4f4e\u7684\u4e3b\u8981\u539f\u56e0\u662f\u4e25\u683c\u7684\u8d23\u4efb\u8fb9\u754c\uff08\u5c06Web\u5e94\u7528\u95ee\u9898\u89c6\u4e3a\u5ba2\u6237\u8d23\u4efb\uff09\u3001\u4f4e\u6258\u7ba1\u8d39\u7528\u548c\u6bcf\u65e5\u5927\u91cf\u5b89\u5168\u4e8b\u4ef6\u963b\u788d\u4e86\u4e3b\u52a8\u548c\u88ab\u52a8\u63aa\u65bd\u3002\u6258\u7ba1\u5546\u6307\u8d23\u7f51\u7ad9\u6240\u6709\u8005\u758f\u5ffd\uff0c\u800c\u7f51\u7ad9\u6240\u6709\u8005\u5219\u4f4e\u4f30\u7f51\u7ad9\u4ef7\u503c\u6216\u7f3a\u4e4f\u5b89\u5168\u77e5\u8bc6\u3002", "conclusion": "\u6f0f\u6d1e\u901a\u77e5\u4fee\u590d\u7387\u4f4e\u4e0b\u7684\u6839\u672c\u539f\u56e0\u5728\u4e8e\u6258\u7ba1\u670d\u52a1\u63d0\u4f9b\u5546\u7684\u7ec4\u7ec7\u548c\u8fd0\u8425\u56e0\u7d20\uff0c\u7279\u522b\u662f\u8d23\u4efb\u5212\u5206\u3001\u7ecf\u6d4e\u6fc0\u52b1\u548c\u5b89\u5168\u4e8b\u4ef6\u91cf\u7b49\u56e0\u7d20\uff0c\u800c\u975e\u4ec5\u4ec5\u901a\u77e5\u53d1\u9001\u65b9\u7684\u6280\u672f\u56e0\u7d20\u3002\u8fd9\u4e3a\u6539\u8fdb\u6f0f\u6d1e\u901a\u77e5\u6548\u679c\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2512.01300", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01300", "abs": "https://arxiv.org/abs/2512.01300", "authors": ["Dacheng Liao", "Mengshi Qi", "Peng Shu", "Zhining Zhang", "Yuxin Lin", "Liang Liu", "Huadong Ma"], "title": "RoboDriveVLM: A Novel Benchmark and Baseline towards Robust Vision-Language Models for Autonomous Driving", "comment": null, "summary": "Current Vision-Language Model (VLM)-based end-to-end autonomous driving systems often leverage large language models to generate driving decisions directly based on their understanding of the current scene. However, such systems introduce multiple risks in real-world driving scenarios. To evaluate whether VLMs are truly viable for autonomous driving, we introduce RoboDriveBench, the first robustness benchmark focused on end-to-end trajectory prediction tasks. This benchmark systematically evaluates two critical categories of real-world challenges for VLM-based end-to-end autonomous driving systems through 11 simulated scenarios encompassing various corruption types, including 6 scenarios of sensor corruption caused by environmental variations, along with 5 cases of prompt corruption resulting from human intervention and data transmission failures. Each corruption type includes 250 unique driving scenarios and 5,689 frames, resulting in 64,559 total trajectory prediction cases per evaluation. To overcome these real-world challenges, we propose a novel VLM-based autonomous driving framework called RoboDriveVLM, which enhances robustness by mapping more multimodal data-e.g., lidar and radar-into a unified latent space. Furthermore, we introduce a new Test-Time Adaptation (TTA) method based on cross-modal knowledge distillation to improve the robustness of VLM-based autonomous driving systems. Through extensive experiments, our work highlights the limitations of current VLM-based end-to-end autonomous driving systems and provides a more reliable solution for real-world deployment. Source code and datasets will be released.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86RoboDriveBench\u57fa\u51c6\u6d4b\u8bd5\u6765\u8bc4\u4f30\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u5f00\u53d1\u4e86RoboDriveVLM\u6846\u67b6\u548c\u6d4b\u8bd5\u65f6\u9002\u5e94\u65b9\u6cd5\u6765\u63d0\u5347\u7cfb\u7edf\u5728\u771f\u5b9e\u4e16\u754c\u6311\u6218\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u76f4\u63a5\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6839\u636e\u573a\u666f\u7406\u89e3\u751f\u6210\u9a7e\u9a76\u51b3\u7b56\uff0c\u4f46\u5728\u771f\u5b9e\u9a7e\u9a76\u573a\u666f\u4e2d\u5b58\u5728\u591a\u79cd\u98ce\u9669\u3002\u9700\u8981\u8bc4\u4f30\u8fd9\u4e9b\u7cfb\u7edf\u662f\u5426\u771f\u6b63\u9002\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\uff0c\u5e76\u89e3\u51b3\u5176\u9c81\u68d2\u6027\u95ee\u9898\u3002", "method": "1. \u63d0\u51faRoboDriveBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b11\u4e2a\u6a21\u62df\u573a\u666f\uff086\u4e2a\u4f20\u611f\u5668\u635f\u574f\u573a\u666f\u548c5\u4e2a\u63d0\u793a\u635f\u574f\u573a\u666f\uff09\uff0c\u6bcf\u4e2a\u573a\u666f250\u4e2a\u72ec\u7279\u9a7e\u9a76\u573a\u666f\u548c5,689\u5e27\u56fe\u50cf\uff0c\u517164,559\u4e2a\u8f68\u8ff9\u9884\u6d4b\u6848\u4f8b\u30022. \u63d0\u51faRoboDriveVLM\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u66f4\u591a\u6a21\u6001\u6570\u636e\uff08\u5982\u6fc0\u5149\u96f7\u8fbe\u548c\u96f7\u8fbe\uff09\u6620\u5c04\u5230\u7edf\u4e00\u6f5c\u5728\u7a7a\u95f4\u6765\u589e\u5f3a\u9c81\u68d2\u6027\u30023. \u63d0\u51fa\u57fa\u4e8e\u8de8\u6a21\u6001\u77e5\u8bc6\u84b8\u998f\u7684\u6d4b\u8bd5\u65f6\u9002\u5e94\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u5c40\u9650\u6027\uff0c\u5e76\u4e3a\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002\u6e90\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5c06\u53d1\u5e03\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f3a\u8c03\u4e86\u5f53\u524dVLM\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u8106\u5f31\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u7cfb\u7edf\u6027\u7684\u8bc4\u4f30\u57fa\u51c6\u548c\u6539\u8fdb\u65b9\u6cd5\uff0c\u4e3a\u6784\u5efa\u66f4\u9c81\u68d2\u7684\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2512.01311", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.01311", "abs": "https://arxiv.org/abs/2512.01311", "authors": ["Shinji Mai", "Yunpeng Zhai", "Ziqian Chen", "Cheng Chen", "Anni Zou", "Shuchang Tao", "Zhaoyang Liu", "Bolin Ding"], "title": "CuES: A Curiosity-driven and Environment-grounded Synthesis Framework for Agentic RL", "comment": null, "summary": "Large language model based agents are increasingly deployed in complex, tool augmented environments. While reinforcement learning provides a principled mechanism for such agents to improve through interaction, its effectiveness critically depends on the availability of structured training tasks. In many realistic settings, however, no such tasks exist a challenge we term task scarcity, which has become a key bottleneck for scaling agentic RL. Existing approaches typically assume predefined task collections, an assumption that fails in novel environments where tool semantics and affordances are initially unknown. To address this limitation, we formalize the problem of Task Generation for Agentic RL, where an agent must learn within a given environment that lacks predefined tasks. We propose CuES, a Curiosity driven and Environment grounded Synthesis framework that autonomously generates diverse, executable, and meaningful tasks directly from the environment structure and affordances, without relying on handcrafted seeds or external corpora. CuES drives exploration through intrinsic curiosity, abstracts interaction patterns into reusable task schemas, and refines them through lightweight top down guidance and memory based quality control. Across three representative environments, AppWorld, BFCL, and WebShop, CuES produces task distributions that match or surpass manually curated datasets in both diversity and executability, yielding substantial downstream policy improvements. These results demonstrate that curiosity driven, environment grounded task generation provides a scalable foundation for agents that not only learn how to act, but also learn what to learn. The code is available at https://github.com/modelscope/AgentEvolver/research/CuES.", "AI": {"tldr": "CuES\u662f\u4e00\u4e2a\u597d\u5947\u5fc3\u9a71\u52a8\u3001\u73af\u5883\u57fa\u7840\u7684\u4efb\u52a1\u751f\u6210\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u4efb\u52a1\u7a00\u7f3a\u95ee\u9898\uff0c\u80fd\u591f\u81ea\u4e3b\u4ece\u73af\u5883\u7ed3\u6784\u548c\u529f\u80fd\u4e2d\u751f\u6210\u591a\u6837\u3001\u53ef\u6267\u884c\u4e14\u6709\u610f\u4e49\u7684\u4efb\u52a1\u3002", "motivation": "\u5728\u590d\u6742\u5de5\u5177\u589e\u5f3a\u73af\u5883\u4e2d\u90e8\u7f72\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u65f6\uff0c\u5f3a\u5316\u5b66\u4e60\u9700\u8981\u7ed3\u6784\u5316\u8bad\u7ec3\u4efb\u52a1\u624d\u80fd\u6709\u6548\u6539\u8fdb\u3002\u7136\u800c\u5728\u8bb8\u591a\u73b0\u5b9e\u573a\u666f\u4e2d\uff0c\u7f3a\u4e4f\u9884\u5b9a\u4e49\u4efb\u52a1\uff08\u4efb\u52a1\u7a00\u7f3a\u95ee\u9898\uff09\uff0c\u8fd9\u6210\u4e3a\u6269\u5c55\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u5173\u952e\u74f6\u9888\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u5b58\u5728\u9884\u5b9a\u4e49\u4efb\u52a1\u96c6\u5408\uff0c\u4f46\u5728\u65b0\u73af\u5883\u4e2d\u5de5\u5177\u8bed\u4e49\u548c\u529f\u80fd\u6700\u521d\u672a\u77e5\u65f6\uff0c\u8fd9\u4e00\u5047\u8bbe\u4e0d\u6210\u7acb\u3002", "method": "\u63d0\u51faCuES\u6846\u67b6\uff1a\u901a\u8fc7\u5185\u5728\u597d\u5947\u5fc3\u9a71\u52a8\u63a2\u7d22\uff0c\u5c06\u4ea4\u4e92\u6a21\u5f0f\u62bd\u8c61\u4e3a\u53ef\u91cd\u7528\u7684\u4efb\u52a1\u6a21\u5f0f\uff0c\u5e76\u901a\u8fc7\u8f7b\u91cf\u7ea7\u81ea\u4e0a\u800c\u4e0b\u6307\u5bfc\u548c\u57fa\u4e8e\u8bb0\u5fc6\u7684\u8d28\u91cf\u63a7\u5236\u8fdb\u884c\u7ec6\u5316\u3002\u8be5\u6846\u67b6\u76f4\u63a5\u4ece\u73af\u5883\u7ed3\u6784\u548c\u529f\u80fd\u4e2d\u81ea\u4e3b\u751f\u6210\u4efb\u52a1\uff0c\u4e0d\u4f9d\u8d56\u4eba\u5de5\u79cd\u5b50\u6216\u5916\u90e8\u8bed\u6599\u5e93\u3002", "result": "\u5728\u4e09\u4e2a\u4ee3\u8868\u6027\u73af\u5883\uff08AppWorld\u3001BFCL\u548cWebShop\uff09\u4e2d\uff0cCuES\u751f\u6210\u7684\u4efb\u52a1\u5206\u5e03\u5728\u591a\u6837\u6027\u548c\u53ef\u6267\u884c\u6027\u65b9\u9762\u5339\u914d\u6216\u8d85\u8d8a\u4e86\u624b\u52a8\u7b56\u5212\u7684\u6570\u636e\u96c6\uff0c\u5e26\u6765\u4e86\u663e\u8457\u7684\u4e0b\u6e38\u7b56\u7565\u6539\u8fdb\u3002", "conclusion": "\u597d\u5947\u5fc3\u9a71\u52a8\u3001\u73af\u5883\u57fa\u7840\u7684\u4efb\u52a1\u751f\u6210\u4e3a\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u57fa\u7840\uff0c\u4f7f\u667a\u80fd\u4f53\u4e0d\u4ec5\u5b66\u4e60\u5982\u4f55\u884c\u52a8\uff0c\u8fd8\u5b66\u4e60\u5b66\u4e60\u4ec0\u4e48\u3002\u8fd9\u4e3a\u89e3\u51b3\u4efb\u52a1\u7a00\u7f3a\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2512.01321", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.01321", "abs": "https://arxiv.org/abs/2512.01321", "authors": ["Juan Hernandez", "Diego Fern\u00e1ndez", "Manuel Cifuentes", "Denis Parra", "Rodrigo Toro Icarte"], "title": "Extending NGU to Multi-Agent RL: A Preliminary Study", "comment": "9 pages, 4 figures, 1 table. Accepted at the LatinX in AI (LXAI) Workshop at NeurIPS 2025. Includes experimental results for Multi-NGU and Multi-DQN in the PettingZoo simple_tag environment", "summary": "The Never Give Up (NGU) algorithm has proven effective in reinforcement learning tasks with sparse rewards by combining episodic novelty and intrinsic motivation. In this work, we extend NGU to multi-agent environments and evaluate its performance in the simple_tag environment from the PettingZoo suite. Compared to a multi-agent DQN baseline, NGU achieves moderately higher returns and more stable learning dynamics. We investigate three design choices: (1) shared replay buffer versus individual replay buffers, (2) sharing episodic novelty among agents using different k thresholds, and (3) using heterogeneous values of the beta parameter. Our results show that NGU with a shared replay buffer yields the best performance and stability, highlighting that the gains come from combining NGU intrinsic exploration with experience sharing. Novelty sharing performs comparably when k = 1 but degrades learning for larger values. Finally, heterogeneous beta values do not improve over a small common value. These findings suggest that NGU can be effectively applied in multi-agent settings when experiences are shared and intrinsic exploration signals are carefully tuned.", "AI": {"tldr": "\u5c06NGU\u7b97\u6cd5\u6269\u5c55\u5230\u591a\u667a\u80fd\u4f53\u73af\u5883\uff0c\u5728PettingZoo\u7684simple_tag\u73af\u5883\u4e2d\u8bc4\u4f30\u6027\u80fd\uff0c\u53d1\u73b0\u5171\u4eab\u7ecf\u9a8c\u56de\u653e\u80fd\u63d0\u5347NGU\u5728\u591a\u667a\u80fd\u4f53\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "NGU\u7b97\u6cd5\u5728\u7a00\u758f\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u4e3b\u8981\u5e94\u7528\u4e8e\u5355\u667a\u80fd\u4f53\u73af\u5883\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22NGU\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684\u9002\u7528\u6027\u548c\u6548\u679c\uff0c\u7279\u522b\u662f\u5982\u4f55\u901a\u8fc7\u7ecf\u9a8c\u5171\u4eab\u548c\u5185\u5728\u63a2\u7d22\u4fe1\u53f7\u8c03\u6574\u6765\u63d0\u5347\u591a\u667a\u80fd\u4f53\u5b66\u4e60\u6027\u80fd\u3002", "method": "\u5c06NGU\u7b97\u6cd5\u6269\u5c55\u5230\u591a\u667a\u80fd\u4f53\u73af\u5883\uff0c\u5728PettingZoo\u7684simple_tag\u73af\u5883\u4e2d\u8fdb\u884c\u5b9e\u9a8c\u3002\u6bd4\u8f83\u4e86\u4e09\u79cd\u8bbe\u8ba1\u9009\u62e9\uff1a1) \u5171\u4eab\u56de\u653e\u7f13\u51b2\u533a vs \u72ec\u7acb\u56de\u653e\u7f13\u51b2\u533a\uff1b2) \u4f7f\u7528\u4e0d\u540ck\u9608\u503c\u5171\u4eab\u60c5\u8282\u65b0\u9896\u6027\uff1b3) \u4f7f\u7528\u5f02\u6784\u7684beta\u53c2\u6570\u503c\u3002\u4ee5\u591a\u667a\u80fd\u4f53DQN\u4f5c\u4e3a\u57fa\u7ebf\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "NGU\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u6bd4\u591a\u667a\u80fd\u4f53DQN\u57fa\u7ebf\u83b7\u5f97\u4e2d\u7b49\u66f4\u9ad8\u7684\u56de\u62a5\u548c\u66f4\u7a33\u5b9a\u7684\u5b66\u4e60\u52a8\u6001\u3002\u5171\u4eab\u56de\u653e\u7f13\u51b2\u533a\u7684NGU\u8868\u73b0\u6700\u4f73\u4e14\u6700\u7a33\u5b9a\uff0c\u8868\u660e\u6027\u80fd\u63d0\u5347\u6765\u81eaNGU\u5185\u5728\u63a2\u7d22\u4e0e\u7ecf\u9a8c\u5171\u4eab\u7684\u7ed3\u5408\u3002\u65b0\u9896\u6027\u5171\u4eab\u5728k=1\u65f6\u8868\u73b0\u76f8\u5f53\uff0c\u4f46k\u503c\u8f83\u5927\u65f6\u4f1a\u964d\u4f4e\u5b66\u4e60\u6548\u679c\u3002\u5f02\u6784beta\u503c\u76f8\u6bd4\u5c0f\u7684\u5171\u540c\u503c\u6ca1\u6709\u6539\u8fdb\u3002", "conclusion": "NGU\u53ef\u4ee5\u6709\u6548\u5730\u5e94\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u8bbe\u7f6e\uff0c\u524d\u63d0\u662f\u5171\u4eab\u7ecf\u9a8c\u5e76\u4ed4\u7ec6\u8c03\u6574\u5185\u5728\u63a2\u7d22\u4fe1\u53f7\u3002\u5171\u4eab\u56de\u653e\u7f13\u51b2\u533a\u662f\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u7684\u5173\u952e\u8bbe\u8ba1\u9009\u62e9\uff0c\u800c\u65b0\u9896\u6027\u5171\u4eab\u548c\u53c2\u6570\u5f02\u6784\u5316\u9700\u8981\u8c28\u614e\u5904\u7406\u3002"}}
{"id": "2512.01434", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01434", "abs": "https://arxiv.org/abs/2512.01434", "authors": ["Daull Xavier", "Patrice Bellot", "Emmanuel Bruno", "Vincent Martin", "Elisabeth Murisasco"], "title": "A Flexible Multi-Agent LLM-Human Framework for Fast Human Validated Tool Building", "comment": null, "summary": "We introduce CollabToolBuilder, a flexible multiagent LLM framework with expert-in-the-loop (HITL) guidance that iteratively learns to create tools for a target goal, aligning with human intent and process, while minimizing time for task/domain adaptation effort and human feedback capture. The architecture generates and validates tools via four specialized agents (Coach, Coder, Critic, Capitalizer) using a reinforced dynamic prompt and systematic human feedback integration to reinforce each agent's role toward goals and constraints. This work is best viewed as a system-level integration and methodology combining multi-agent in-context learning, HITL controls, and reusable tool capitalization for complex iterative problems such as scientific document generation. We illustrate it with preliminary experiments (e.g., generating state-of-the-art research papers or patents given an abstract) and discuss its applicability to other iterative problem-solving.", "AI": {"tldr": "CollabToolBuilder\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\uff0c\u901a\u8fc7\u4e13\u5bb6\u5728\u73af\u6307\u5bfc\u8fed\u4ee3\u5b66\u4e60\u4e3a\u76ee\u6807\u521b\u5efa\u5de5\u5177\uff0c\u6700\u5c0f\u5316\u4efb\u52a1/\u9886\u57df\u9002\u5e94\u548c\u4eba\u5de5\u53cd\u9988\u83b7\u53d6\u65f6\u95f4\u3002", "motivation": "\u89e3\u51b3\u590d\u6742\u8fed\u4ee3\u95ee\u9898\uff08\u5982\u79d1\u5b66\u6587\u6863\u751f\u6210\uff09\u4e2d\u5de5\u5177\u521b\u5efa\u4e0e\u4eba\u7c7b\u610f\u56fe\u5bf9\u9f50\u7684\u6311\u6218\uff0c\u51cf\u5c11\u9886\u57df\u9002\u5e94\u548c\u4eba\u5de5\u53cd\u9988\u83b7\u53d6\u7684\u65f6\u95f4\u6210\u672c\u3002", "method": "\u4f7f\u7528\u56db\u4e2a\u4e13\u95e8\u5316\u667a\u80fd\u4f53\uff08\u6559\u7ec3\u3001\u7f16\u7801\u5458\u3001\u6279\u8bc4\u8005\u3001\u8d44\u672c\u5316\u8005\uff09\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u52a8\u6001\u63d0\u793a\u548c\u7cfb\u7edf\u5316\u4eba\u5de5\u53cd\u9988\u96c6\u6210\u6765\u751f\u6210\u548c\u9a8c\u8bc1\u5de5\u5177\uff0c\u652f\u6301\u591a\u667a\u80fd\u4f53\u4e0a\u4e0b\u6587\u5b66\u4e60\u548c\u53ef\u91cd\u7528\u5de5\u5177\u8d44\u672c\u5316\u3002", "result": "\u521d\u6b65\u5b9e\u9a8c\u5c55\u793a\u4e86\u7cfb\u7edf\u5728\u751f\u6210\u524d\u6cbf\u7814\u7a76\u8bba\u6587\u6216\u4e13\u5229\u7b49\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\uff0c\u8bc1\u660e\u4e86\u6846\u67b6\u5728\u590d\u6742\u8fed\u4ee3\u95ee\u9898\u89e3\u51b3\u4e2d\u7684\u9002\u7528\u6027\u3002", "conclusion": "CollabToolBuilder\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7cfb\u7edf\u7ea7\u96c6\u6210\u548c\u65b9\u6cd5\u8bba\uff0c\u7ed3\u5408\u591a\u667a\u80fd\u4f53\u4e0a\u4e0b\u6587\u5b66\u4e60\u3001\u4e13\u5bb6\u5728\u73af\u63a7\u5236\u548c\u53ef\u91cd\u7528\u5de5\u5177\u8d44\u672c\u5316\uff0c\u9002\u7528\u4e8e\u79d1\u5b66\u6587\u6863\u751f\u6210\u7b49\u590d\u6742\u8fed\u4ee3\u95ee\u9898\u3002"}}
{"id": "2512.01440", "categories": ["cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.01440", "abs": "https://arxiv.org/abs/2512.01440", "authors": ["Sylvain Mari\u00e9", "Pablo Knecht"], "title": "A Selective Temporal Hamming distance to find patterns in state transition event timeseries, at scale", "comment": null, "summary": "Discrete event systems are present both in observations of nature, socio economical sciences, and industrial systems. Standard analysis approaches do not usually exploit their dual event / state nature: signals are either modeled as transition event sequences, emphasizing event order alignment, or as categorical or ordinal state timeseries, usually resampled a distorting and costly operation as the observation period and number of events grow. In this work we define state transition event timeseries (STE-ts) and propose a new Selective Temporal Hamming distance (STH) leveraging both transition time and duration-in-state, avoiding costly and distorting resampling on large databases. STH generalizes both resampled Hamming and Jaccard metrics with better precision and computation time, and an ability to focus on multiple states of interest. We validate these benefits on simulated and real-world datasets.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u72b6\u6001\u8f6c\u79fb\u4e8b\u4ef6\u65f6\u95f4\u5e8f\u5217\uff08STE-ts\uff09\u548c\u9009\u62e9\u6027\u65f6\u5e8f\u6c49\u660e\u8ddd\u79bb\uff08STH\uff09\uff0c\u907f\u514d\u4e86\u5bf9\u5927\u578b\u6570\u636e\u5e93\u8fdb\u884c\u4ee3\u4ef7\u9ad8\u6602\u4e14\u626d\u66f2\u7684\u91cd\u91c7\u6837\u64cd\u4f5c\u3002", "motivation": "\u79bb\u6563\u4e8b\u4ef6\u7cfb\u7edf\u5728\u81ea\u7136\u89c2\u6d4b\u3001\u793e\u4f1a\u7ecf\u6d4e\u79d1\u5b66\u548c\u5de5\u4e1a\u7cfb\u7edf\u4e2d\u666e\u904d\u5b58\u5728\u3002\u6807\u51c6\u5206\u6790\u65b9\u6cd5\u901a\u5e38\u672a\u80fd\u5145\u5206\u5229\u7528\u5176\u4e8b\u4ef6/\u72b6\u6001\u7684\u53cc\u91cd\u6027\u8d28\uff1a\u4fe1\u53f7\u8981\u4e48\u88ab\u5efa\u6a21\u4e3a\u5f3a\u8c03\u4e8b\u4ef6\u987a\u5e8f\u5bf9\u9f50\u7684\u8f6c\u79fb\u4e8b\u4ef6\u5e8f\u5217\uff0c\u8981\u4e48\u88ab\u5efa\u6a21\u4e3a\u5206\u7c7b\u6216\u6709\u5e8f\u72b6\u6001\u65f6\u95f4\u5e8f\u5217\uff0c\u901a\u5e38\u9700\u8981\u8fdb\u884c\u91cd\u91c7\u6837\uff0c\u968f\u7740\u89c2\u6d4b\u5468\u671f\u548c\u4e8b\u4ef6\u6570\u91cf\u7684\u589e\u52a0\uff0c\u8fd9\u79cd\u64cd\u4f5c\u65e2\u626d\u66f2\u53c8\u4ee3\u4ef7\u9ad8\u6602\u3002", "method": "\u5b9a\u4e49\u4e86\u72b6\u6001\u8f6c\u79fb\u4e8b\u4ef6\u65f6\u95f4\u5e8f\u5217\uff08STE-ts\uff09\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9009\u62e9\u6027\u65f6\u5e8f\u6c49\u660e\u8ddd\u79bb\uff08STH\uff09\uff0c\u8be5\u8ddd\u79bb\u540c\u65f6\u5229\u7528\u8f6c\u79fb\u65f6\u95f4\u548c\u72b6\u6001\u6301\u7eed\u65f6\u95f4\uff0c\u907f\u514d\u4e86\u5bf9\u5927\u578b\u6570\u636e\u5e93\u8fdb\u884c\u4ee3\u4ef7\u9ad8\u6602\u4e14\u626d\u66f2\u7684\u91cd\u91c7\u6837\u3002", "result": "STH\u63a8\u5e7f\u4e86\u91cd\u91c7\u6837\u6c49\u660e\u8ddd\u79bb\u548cJaccard\u5ea6\u91cf\uff0c\u5177\u6709\u66f4\u597d\u7684\u7cbe\u5ea6\u548c\u8ba1\u7b97\u65f6\u95f4\uff0c\u5e76\u4e14\u80fd\u591f\u5173\u6ce8\u591a\u4e2a\u611f\u5174\u8da3\u7684\u72b6\u6001\u3002\u5728\u6a21\u62df\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u4f18\u52bf\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u79bb\u6563\u4e8b\u4ef6\u7cfb\u7edf\u7684\u53cc\u91cd\u6027\u8d28\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u91cd\u91c7\u6837\u65b9\u6cd5\u7684\u7f3a\u70b9\uff0c\u5728\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u90fd\u6709\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2512.01452", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01452", "abs": "https://arxiv.org/abs/2512.01452", "authors": ["Lingbo Li", "Anuradha Mathrani", "Teo Susnjak"], "title": "Automated Risk-of-Bias Assessment of Randomized Controlled Trials: A First Look at a GEPA-trained Programmatic Prompting Framework", "comment": null, "summary": "Assessing risk of bias (RoB) in randomized controlled trials is essential for trustworthy evidence synthesis, but the process is resource-intensive and prone to variability across reviewers. Large language models (LLMs) offer a route to automation, but existing methods rely on manually engineered prompts that are difficult to reproduce, generalize, or evaluate. This study introduces a programmable RoB assessment pipeline that replaces ad-hoc prompt design with structured, code-based optimization using DSPy and its GEPA module. GEPA refines LLM reasoning through Pareto-guided search and produces inspectable execution traces, enabling transparent replication of every step in the optimization process. We evaluated the method on 100 RCTs from published meta-analyses across seven RoB domains. GEPA-generated prompts were applied to both open-weight models (Mistral Small 3.1 with GPT-oss-20b) and commercial models (GPT-5 Nano and GPT-5 Mini). In domains with clearer methodological reporting, such as Random Sequence Generation, GEPA-generated prompts performed best, with similar results for Allocation Concealment and Blinding of Participants, while the commercial model performed slightly better overall. We also compared GEPA with three manually designed prompts using Claude 3.5 Sonnet. GEPA achieved the highest overall accuracy and improved performance by 30%-40% in Random Sequence Generation and Selective Reporting, and showed generally comparable, competitively aligned performance in the other domains relative to manual prompts. These findings suggest that GEPA can produce consistent and reproducible prompts for RoB assessment, supporting the structured and principled use of LLMs in evidence synthesis.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eDSPy\u548cGEPA\u6a21\u5757\u7684\u53ef\u7f16\u7a0b\u98ce\u9669\u8bc4\u4f30\u7ba1\u9053\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\u7684\u504f\u501a\u98ce\u9669\u8bc4\u4f30\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u4ee3\u7801\u4f18\u5316\u66ff\u4ee3\u624b\u52a8\u63d0\u793a\u8bbe\u8ba1\uff0c\u63d0\u9ad8\u4e86\u8bc4\u4f30\u7684\u4e00\u81f4\u6027\u548c\u53ef\u91cd\u590d\u6027\u3002", "motivation": "\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\u7684\u504f\u501a\u98ce\u9669\u8bc4\u4f30\u5bf9\u8bc1\u636e\u5408\u6210\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u8d44\u6e90\u5bc6\u96c6\u4e14\u5b58\u5728\u8bc4\u4f30\u8005\u95f4\u5dee\u5f02\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u81ea\u52a8\u5316\u9014\u5f84\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u96be\u4ee5\u590d\u5236\u3001\u6cdb\u5316\u6216\u8bc4\u4f30\u7684\u624b\u52a8\u8bbe\u8ba1\u63d0\u793a\u3002", "method": "\u5f15\u5165\u53ef\u7f16\u7a0b\u7684\u504f\u501a\u98ce\u9669\u8bc4\u4f30\u7ba1\u9053\uff0c\u4f7f\u7528DSPy\u53ca\u5176GEPA\u6a21\u5757\u8fdb\u884c\u7ed3\u6784\u5316\u4ee3\u7801\u4f18\u5316\u3002GEPA\u901a\u8fc7\u5e15\u7d2f\u6258\u5f15\u5bfc\u641c\u7d22\u6539\u8fdbLLM\u63a8\u7406\uff0c\u5e76\u751f\u6210\u53ef\u68c0\u67e5\u7684\u6267\u884c\u8f68\u8ff9\uff0c\u4f7f\u4f18\u5316\u8fc7\u7a0b\u7684\u6bcf\u4e00\u6b65\u90fd\u80fd\u900f\u660e\u590d\u5236\u3002\u5728100\u4e2a\u5df2\u53d1\u8868\u835f\u8403\u5206\u6790\u7684\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\u4e0a\u8bc4\u4f30\u4e86\u8be5\u65b9\u6cd5\uff0c\u6db5\u76d6\u4e03\u4e2a\u504f\u501a\u98ce\u9669\u9886\u57df\u3002", "result": "\u5728\u65b9\u6cd5\u62a5\u544a\u66f4\u6e05\u6670\u7684\u9886\u57df\uff08\u5982\u968f\u673a\u5e8f\u5217\u751f\u6210\uff09\uff0cGEPA\u751f\u6210\u7684\u63d0\u793a\u8868\u73b0\u6700\u4f73\uff1b\u5728\u5206\u914d\u9690\u85cf\u548c\u53c2\u4e0e\u8005\u76f2\u6cd5\u65b9\u9762\u4e5f\u6709\u7c7b\u4f3c\u7ed3\u679c\u3002\u5546\u4e1a\u6a21\u578b\u6574\u4f53\u8868\u73b0\u7565\u597d\u3002\u4e0e\u4e09\u4e2a\u624b\u52a8\u8bbe\u8ba1\u7684Claude 3.5 Sonnet\u63d0\u793a\u76f8\u6bd4\uff0cGEPA\u5b9e\u73b0\u4e86\u6700\u9ad8\u6574\u4f53\u51c6\u786e\u7387\uff0c\u5728\u968f\u673a\u5e8f\u5217\u751f\u6210\u548c\u9009\u62e9\u6027\u62a5\u544a\u65b9\u9762\u6027\u80fd\u63d0\u534730%-40%\uff0c\u5728\u5176\u4ed6\u9886\u57df\u4e0e\u624b\u52a8\u63d0\u793a\u8868\u73b0\u76f8\u5f53\u3002", "conclusion": "GEPA\u80fd\u591f\u4e3a\u504f\u501a\u98ce\u9669\u8bc4\u4f30\u751f\u6210\u4e00\u81f4\u4e14\u53ef\u91cd\u590d\u7684\u63d0\u793a\uff0c\u652f\u6301\u5728\u8bc1\u636e\u5408\u6210\u4e2d\u7ed3\u6784\u5316\u3001\u539f\u5219\u6027\u5730\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u63d0\u9ad8\u4e86\u81ea\u52a8\u5316\u8bc4\u4f30\u7684\u900f\u660e\u5ea6\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2512.01507", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.01507", "abs": "https://arxiv.org/abs/2512.01507", "authors": ["Daniel Armstrong", "Zlatko Jon\u010dev", "Andres M Bran", "Philippe Schwaller"], "title": "SynthStrategy: Extracting and Formalizing Latent Strategic Insights from LLMs in Organic Chemistry", "comment": null, "summary": "Modern computer-assisted synthesis planning (CASP) systems show promises at generating chemically valid reaction steps but struggle to incorporate strategic considerations such as convergent assembly, protecting group minimization, and optimal ring-forming sequences. We introduce a methodology that leverages Large Language Models to distill synthetic knowledge into code. Our system analyzes synthesis routes and translates strategic principles into Python functions representing diverse strategic and tactical rules, such as strategic functional group interconversions and ring construction strategies. By formalizing this knowledge as verifiable code rather than simple heuristics, we create testable, interpretable representations of synthetic strategy. We release the complete codebase and the USPTO-ST dataset -- synthesis routes annotated with strategic tags. This framework unlocks a novel capability for CASP: natural language-based route retrieval, achieving 75\\% Top-3 accuracy on our benchmark. We further validate our library through temporal analysis of historical trends and chemically intuitive route clustering that offers more granular partitioning than common previous methods. This work bridges the tactical-strategic divide in CASP, enabling specification, search, and evaluation of routes by strategic criteria rather than structure alone.", "AI": {"tldr": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5c06\u5408\u6210\u77e5\u8bc6\u8f6c\u5316\u4e3a\u4ee3\u7801\uff0c\u5b9e\u73b0\u8ba1\u7b97\u673a\u8f85\u52a9\u5408\u6210\u89c4\u5212\u4e2d\u7684\u6218\u7565\u8003\u91cf\uff0c\u5982\u6536\u655b\u7ec4\u88c5\u3001\u4fdd\u62a4\u57fa\u6700\u5c0f\u5316\u548c\u6700\u4f18\u73af\u5f62\u6210\u5e8f\u5217\u3002", "motivation": "\u73b0\u6709\u8ba1\u7b97\u673a\u8f85\u52a9\u5408\u6210\u89c4\u5212\u7cfb\u7edf\u80fd\u751f\u6210\u5316\u5b66\u4e0a\u6709\u6548\u7684\u53cd\u5e94\u6b65\u9aa4\uff0c\u4f46\u96be\u4ee5\u878d\u5165\u6218\u7565\u8003\u91cf\uff0c\u5982\u6536\u655b\u7ec4\u88c5\u3001\u4fdd\u62a4\u57fa\u6700\u5c0f\u5316\u548c\u6700\u4f18\u73af\u5f62\u6210\u5e8f\u5217\u7b49\u3002\u9700\u8981\u5c06\u5408\u6210\u6218\u7565\u77e5\u8bc6\u7cfb\u7edf\u5316\u5730\u7f16\u7801\u5230\u89c4\u5212\u7cfb\u7edf\u4e2d\u3002", "method": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u53d6\u5408\u6210\u77e5\u8bc6\u5e76\u8f6c\u5316\u4e3aPython\u4ee3\u7801\uff0c\u5c06\u6218\u7565\u539f\u5219\uff08\u5982\u6218\u7565\u5b98\u80fd\u56e2\u4e92\u53d8\u548c\u73af\u6784\u5efa\u7b56\u7565\uff09\u8f6c\u5316\u4e3a\u53ef\u9a8c\u8bc1\u7684\u51fd\u6570\u3002\u521b\u5efaUSPTO-ST\u6570\u636e\u96c6\uff08\u5e26\u6709\u6218\u7565\u6807\u7b7e\u7684\u5408\u6210\u8def\u7ebf\uff09\uff0c\u5b9e\u73b0\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u7684\u8def\u7ebf\u68c0\u7d22\u3002", "result": "\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523075%\u7684Top-3\u51c6\u786e\u7387\uff1b\u901a\u8fc7\u5386\u53f2\u8d8b\u52bf\u65f6\u95f4\u5206\u6790\u548c\u5316\u5b66\u76f4\u89c2\u8def\u7ebf\u805a\u7c7b\u9a8c\u8bc1\u4e86\u5e93\u7684\u6709\u6548\u6027\uff0c\u63d0\u4f9b\u4e86\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u7ec6\u7c92\u5ea6\u7684\u5212\u5206\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5f25\u5408\u4e86\u8ba1\u7b97\u673a\u8f85\u52a9\u5408\u6210\u89c4\u5212\u4e2d\u6218\u672f\u4e0e\u6218\u7565\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u4f7f\u8def\u7ebf\u80fd\u591f\u57fa\u4e8e\u6218\u7565\u6807\u51c6\u800c\u975e\u4ec5\u7ed3\u6784\u8fdb\u884c\u89c4\u8303\u3001\u641c\u7d22\u548c\u8bc4\u4f30\uff0c\u4e3a\u5408\u6210\u89c4\u5212\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u6218\u7565\u80fd\u529b\u3002"}}
{"id": "2512.01556", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.01556", "abs": "https://arxiv.org/abs/2512.01556", "authors": ["Zhiyuan Wang", "Aniri", "Tianlong Chen", "Yue Zhang", "Heng Tao Shen", "Xiaoshuang Shi", "Kaidi Xu"], "title": "LEC: Linear Expectation Constraints for False-Discovery Control in Selective Prediction and Routing Systems", "comment": null, "summary": "Large language models (LLMs) often generate unreliable answers, while heuristic uncertainty methods fail to fully distinguish correct from incorrect predictions, causing users to accept erroneous answers without statistical guarantees. We address this issue through the lens of false discovery rate (FDR) control, ensuring that among all accepted predictions, the proportion of errors does not exceed a target risk level. To achieve this in a principled way, we propose LEC, which reinterprets selective prediction as a constrained decision problem by enforcing a Linear Expectation Constraint over selection and error indicators. Then, we establish a finite-sample sufficient condition, which relies only on a held-out set of exchangeable calibration samples, to compute an FDR-constrained, coverage-maximizing threshold. Furthermore, we extend LEC to a two-model routing mechanism: given a prompt, if the current model's uncertainty exceeds its calibrated threshold, we delegate it to a stronger model, while maintaining a unified FDR guarantee. Evaluations on closed-ended and open-ended question-answering (QA) datasets show that LEC achieves tighter FDR control and substantially improves sample retention over prior methods. Moreover, the two-model routing mechanism achieves lower risk levels while accepting more correct samples than each individual model.", "AI": {"tldr": "LEC\u65b9\u6cd5\u901a\u8fc7\u7ebf\u6027\u671f\u671b\u7ea6\u675f\u548cFDR\u63a7\u5236\uff0c\u4e3aLLM\u9884\u6d4b\u63d0\u4f9b\u7edf\u8ba1\u4fdd\u8bc1\uff0c\u5e76\u6269\u5c55\u5230\u53cc\u6a21\u578b\u8def\u7531\u673a\u5236\uff0c\u5728\u4fdd\u6301FDR\u63a7\u5236\u7684\u540c\u65f6\u63d0\u9ad8\u6837\u672c\u4fdd\u7559\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7ecf\u5e38\u751f\u6210\u4e0d\u53ef\u9760\u7684\u7b54\u6848\uff0c\u800c\u542f\u53d1\u5f0f\u4e0d\u786e\u5b9a\u6027\u65b9\u6cd5\u65e0\u6cd5\u5b8c\u5168\u533a\u5206\u6b63\u786e\u548c\u9519\u8bef\u7684\u9884\u6d4b\uff0c\u5bfc\u81f4\u7528\u6237\u5728\u6ca1\u6709\u7edf\u8ba1\u4fdd\u8bc1\u7684\u60c5\u51b5\u4e0b\u63a5\u53d7\u9519\u8bef\u7b54\u6848\u3002", "method": "\u63d0\u51faLEC\u65b9\u6cd5\uff0c\u5c06\u9009\u62e9\u6027\u9884\u6d4b\u91cd\u65b0\u89e3\u91ca\u4e3a\u7ea6\u675f\u51b3\u7b56\u95ee\u9898\uff0c\u901a\u8fc7\u5bf9\u9009\u62e9\u548c\u9519\u8bef\u6307\u6807\u65bd\u52a0\u7ebf\u6027\u671f\u671b\u7ea6\u675f\uff0c\u5efa\u7acb\u6709\u9650\u6837\u672c\u5145\u5206\u6761\u4ef6\uff0c\u8ba1\u7b97FDR\u7ea6\u675f\u4e0b\u7684\u8986\u76d6\u6700\u5927\u5316\u9608\u503c\u3002\u6269\u5c55\u5230\u53cc\u6a21\u578b\u8def\u7531\u673a\u5236\uff1a\u5f53\u5f53\u524d\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u8d85\u8fc7\u6821\u51c6\u9608\u503c\u65f6\uff0c\u5c06\u5176\u59d4\u6258\u7ed9\u66f4\u5f3a\u7684\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u6301\u7edf\u4e00\u7684FDR\u4fdd\u8bc1\u3002", "result": "\u5728\u5c01\u95ed\u5f0f\u548c\u5f00\u653e\u5f0f\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cLEC\u5b9e\u73b0\u4e86\u66f4\u4e25\u683c\u7684FDR\u63a7\u5236\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u4e86\u6837\u672c\u4fdd\u7559\u7387\u3002\u53cc\u6a21\u578b\u8def\u7531\u673a\u5236\u5728\u4fdd\u6301\u8f83\u4f4e\u98ce\u9669\u6c34\u5e73\u7684\u540c\u65f6\uff0c\u6bd4\u5355\u4e2a\u6a21\u578b\u63a5\u53d7\u4e86\u66f4\u591a\u6b63\u786e\u6837\u672c\u3002", "conclusion": "LEC\u4e3aLLM\u9884\u6d4b\u63d0\u4f9b\u4e86\u7edf\u8ba1\u4fdd\u8bc1\u7684FDR\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u7ebf\u6027\u671f\u671b\u7ea6\u675f\u548c\u53cc\u6a21\u578b\u8def\u7531\u673a\u5236\uff0c\u5728\u63a7\u5236\u9519\u8bef\u7387\u7684\u540c\u65f6\u6700\u5927\u5316\u6b63\u786e\u9884\u6d4b\u7684\u63a5\u53d7\uff0c\u89e3\u51b3\u4e86LLM\u53ef\u9760\u6027\u95ee\u9898\u3002"}}
{"id": "2512.01616", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01616", "abs": "https://arxiv.org/abs/2512.01616", "authors": ["Chainesh Gautam", "Raghuram Bharadwaj Diddigi"], "title": "CLIP-RL: Aligning Language and Policy Representations for Task Transfer in Reinforcement Learning", "comment": "4 pages, 2 figures, accepted as a extended abstract at RLDM 2025", "summary": "Recently, there has been an increasing need to develop agents capable of solving multiple tasks within the same environment, especially when these tasks are naturally associated with language. In this work, we propose a novel approach that leverages combinations of pre-trained (language, policy) pairs to establish an efficient transfer pipeline. Our algorithm is inspired by the principles of Contrastive Language-Image Pretraining (CLIP) in Computer Vision, which aligns representations across different modalities under the philosophy that ''two modalities representing the same concept should have similar representations.'' The central idea here is that the instruction and corresponding policy of a task represent the same concept, the task itself, in two different modalities. Therefore, by extending the idea of CLIP to RL, our method creates a unified representation space for natural language and policy embeddings. Experimental results demonstrate the utility of our algorithm in achieving faster transfer across tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eCLIP\u539f\u7406\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u8bed\u8a00\u6307\u4ee4\u4e0e\u5bf9\u5e94\u7b56\u7565\u5bf9\u9f50\u5230\u7edf\u4e00\u8868\u793a\u7a7a\u95f4\uff0c\u5b9e\u73b0\u8de8\u4efb\u52a1\u7684\u9ad8\u6548\u8fc1\u79fb\u5b66\u4e60\u3002", "motivation": "\u5f53\u524d\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5728\u540c\u4e00\u73af\u5883\u4e2d\u89e3\u51b3\u591a\u4e2a\u4efb\u52a1\u7684\u667a\u80fd\u4f53\uff0c\u7279\u522b\u662f\u5f53\u8fd9\u4e9b\u4efb\u52a1\u4e0e\u8bed\u8a00\u81ea\u7136\u5173\u8054\u65f6\u3002\u4f20\u7edf\u65b9\u6cd5\u5728\u8de8\u4efb\u52a1\u8fc1\u79fb\u65b9\u9762\u6548\u7387\u4e0d\u9ad8\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6709\u6548\u5229\u7528\u8bed\u8a00-\u7b56\u7565\u5bf9\u5e94\u5173\u7cfb\u7684\u65b9\u6cd5\u3002", "method": "\u53d7\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2dCLIP\u65b9\u6cd5\u7684\u542f\u53d1\uff0c\u5c06\u8bed\u8a00\u6307\u4ee4\u548c\u5bf9\u5e94\u7b56\u7565\u89c6\u4e3a\u540c\u4e00\u4efb\u52a1\u5728\u4e0d\u540c\u6a21\u6001\u4e0b\u7684\u8868\u793a\u3002\u901a\u8fc7\u9884\u8bad\u7ec3\u7684\u8bed\u8a00-\u7b56\u7565\u5bf9\u7ec4\u5408\uff0c\u5efa\u7acb\u7edf\u4e00\u7684\u8868\u793a\u7a7a\u95f4\uff0c\u4f7f\u76f8\u540c\u4efb\u52a1\u7684\u8bed\u8a00\u63cf\u8ff0\u548c\u7b56\u7565\u5d4c\u5165\u5177\u6709\u76f8\u4f3c\u7684\u8868\u793a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u8de8\u4efb\u52a1\u8fc1\u79fb\u5b66\u4e60\u4e2d\u80fd\u591f\u5b9e\u73b0\u66f4\u5feb\u7684\u6536\u655b\u548c\u66f4\u597d\u7684\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u7edf\u4e00\u8868\u793a\u7a7a\u95f4\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u5c06CLIP\u539f\u7406\u6269\u5c55\u5230\u5f3a\u5316\u5b66\u4e60\u9886\u57df\uff0c\u6210\u529f\u6784\u5efa\u4e86\u8bed\u8a00\u548c\u7b56\u7565\u7684\u7edf\u4e00\u8868\u793a\u7a7a\u95f4\uff0c\u4e3a\u591a\u4efb\u52a1\u5b66\u4e60\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u8fc1\u79fb\u7ba1\u9053\uff0c\u5728\u8bed\u8a00\u5173\u8054\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u8de8\u4efb\u52a1\u8fc1\u79fb\u80fd\u529b\u3002"}}
{"id": "2512.01786", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.01786", "abs": "https://arxiv.org/abs/2512.01786", "authors": ["Xiaochuan Li", "Ke Wang", "Girija Gouda", "Shubham Choudhary", "Yaqun Wang", "Linwei Hu", "Joel Vaughan", "Freddy Lecue"], "title": "Who Judges the Judge? LLM Jury-on-Demand: Building Trustworthy LLM Evaluation Systems", "comment": "66 pages, 22 figures, 37 tables", "summary": "As Large Language Models (LLMs) become integrated into high-stakes domains, there is a growing need for evaluation methods that are both scalable for real-time deployment and reliable for critical decision-making. While human evaluation is reliable, it is slow and costly. Single LLM judges are biased, and static juries lack adaptability. To overcome these limitations, we propose LLM Jury-on-Demand - a dynamic, learning-based framework for scalable and context-aware evaluation. Our method trains a set of reliability predictors to assess when LLM judges will agree with human experts, leveraging token distributions, embeddings, and structural input features. This enables a fully adaptive evaluation where, for each data point, an optimal jury of the most reliable judges is dynamically selected, and their scores are aggregated using their reliability as weights. Experiments on summarization and RAG benchmarks show that our dynamic jury system achieves significantly higher correlation with human judgment than both single-judge and static-jury baselines. These results highlight the promise of adaptive, learning-based juries for building scalable, more reliable and trustworthy evaluation systems for modern LLMs in high-stakes domains.", "AI": {"tldr": "LLM Jury-on-Demand\uff1a\u4e00\u4e2a\u52a8\u6001\u3001\u57fa\u4e8e\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8bad\u7ec3\u53ef\u9760\u6027\u9884\u6d4b\u5668\u6765\u8bc4\u4f30LLM\u8bc4\u59d4\u4f55\u65f6\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u4e00\u81f4\uff0c\u4e3a\u6bcf\u4e2a\u6570\u636e\u70b9\u52a8\u6001\u9009\u62e9\u6700\u53ef\u9760\u7684\u8bc4\u59d4\u7ec4\u6210\u966a\u5ba1\u56e2\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u4e14\u53ef\u9760\u7684\u8bc4\u4f30\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u88ab\u96c6\u6210\u5230\u9ad8\u98ce\u9669\u9886\u57df\uff0c\u9700\u8981\u65e2\u80fd\u5728\u5b9e\u65f6\u90e8\u7f72\u4e2d\u6269\u5c55\u53c8\u80fd\u5728\u5173\u952e\u51b3\u7b56\u4e2d\u53ef\u9760\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002\u4eba\u7c7b\u8bc4\u4f30\u53ef\u9760\u4f46\u7f13\u6162\u6602\u8d35\uff0c\u5355\u4e2aLLM\u8bc4\u59d4\u5b58\u5728\u504f\u89c1\uff0c\u9759\u6001\u966a\u5ba1\u56e2\u7f3a\u4e4f\u9002\u5e94\u6027\u3002", "method": "\u63d0\u51faLLM Jury-on-Demand\u6846\u67b6\uff0c\u8bad\u7ec3\u4e00\u7ec4\u53ef\u9760\u6027\u9884\u6d4b\u5668\u6765\u8bc4\u4f30LLM\u8bc4\u59d4\u4f55\u65f6\u4f1a\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u8fbe\u6210\u4e00\u81f4\u3002\u5229\u7528token\u5206\u5e03\u3001\u5d4c\u5165\u548c\u7ed3\u6784\u5316\u8f93\u5165\u7279\u5f81\uff0c\u4e3a\u6bcf\u4e2a\u6570\u636e\u70b9\u52a8\u6001\u9009\u62e9\u6700\u53ef\u9760\u7684\u8bc4\u59d4\u7ec4\u6210\u6700\u4f18\u966a\u5ba1\u56e2\uff0c\u5e76\u4f7f\u7528\u53ef\u9760\u6027\u4f5c\u4e3a\u6743\u91cd\u805a\u5408\u4ed6\u4eec\u7684\u8bc4\u5206\u3002", "result": "\u5728\u6458\u8981\u548cRAG\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u52a8\u6001\u966a\u5ba1\u56e2\u7cfb\u7edf\u6bd4\u5355\u8bc4\u59d4\u548c\u9759\u6001\u966a\u5ba1\u56e2\u57fa\u7ebf\u5b9e\u73b0\u4e86\u663e\u8457\u66f4\u9ad8\u7684\u4eba\u7c7b\u5224\u65ad\u76f8\u5173\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u81ea\u9002\u5e94\u3001\u57fa\u4e8e\u5b66\u4e60\u7684\u966a\u5ba1\u56e2\u5728\u6784\u5efa\u53ef\u6269\u5c55\u3001\u66f4\u53ef\u9760\u548c\u53ef\u4fe1\u8d56\u7684\u73b0\u4ee3LLM\u8bc4\u4f30\u7cfb\u7edf\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u7279\u522b\u9002\u7528\u4e8e\u9ad8\u98ce\u9669\u9886\u57df\u3002"}}
{"id": "2512.01797", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.01797", "abs": "https://arxiv.org/abs/2512.01797", "authors": ["Cheng Gao", "Huimin Chen", "Chaojun Xiao", "Zhiyi Chen", "Zhiyuan Liu", "Maosong Sun"], "title": "H-Neurons: On the Existence, Impact, and Origin of Hallucination-Associated Neurons in LLMs", "comment": "20 pages, 4 figures", "summary": "Large language models (LLMs) frequently generate hallucinations -- plausible but factually incorrect outputs -- undermining their reliability. While prior work has examined hallucinations from macroscopic perspectives such as training data and objectives, the underlying neuron-level mechanisms remain largely unexplored. In this paper, we conduct a systematic investigation into hallucination-associated neurons (H-Neurons) in LLMs from three perspectives: identification, behavioral impact, and origins. Regarding their identification, we demonstrate that a remarkably sparse subset of neurons (less than $0.1\\%$ of total neurons) can reliably predict hallucination occurrences, with strong generalization across diverse scenarios. In terms of behavioral impact, controlled interventions reveal that these neurons are causally linked to over-compliance behaviors. Concerning their origins, we trace these neurons back to the pre-trained base models and find that these neurons remain predictive for hallucination detection, indicating they emerge during pre-training. Our findings bridge macroscopic behavioral patterns with microscopic neural mechanisms, offering insights for developing more reliable LLMs.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e7b\u89c9\u73b0\u8c61\u4e0e\u6781\u5c11\u6570\u7279\u5b9a\u795e\u7ecf\u5143\uff08H-Neurons\uff09\u76f8\u5173\uff0c\u8fd9\u4e9b\u795e\u7ecf\u5143\u4ec5\u5360\u6a21\u578b\u603b\u795e\u7ecf\u5143\u7684\u4e0d\u52300.1%\uff0c\u4f46\u80fd\u53ef\u9760\u9884\u6d4b\u5e7b\u89c9\u53d1\u751f\uff0c\u5e76\u5728\u9884\u8bad\u7ec3\u9636\u6bb5\u5c31\u5df2\u5f62\u6210\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7ecf\u5e38\u4ea7\u751f\u5e7b\u89c9\uff08\u770b\u4f3c\u5408\u7406\u4f46\u4e8b\u5b9e\u9519\u8bef\u7684\u8f93\u51fa\uff09\uff0c\u8fd9\u524a\u5f31\u4e86\u5176\u53ef\u9760\u6027\u3002\u867d\u7136\u5148\u524d\u7814\u7a76\u4ece\u5b8f\u89c2\u89d2\u5ea6\uff08\u5982\u8bad\u7ec3\u6570\u636e\u548c\u76ee\u6807\uff09\u63a2\u8ba8\u4e86\u5e7b\u89c9\u95ee\u9898\uff0c\u4f46\u795e\u7ecf\u5143\u5c42\u9762\u7684\u673a\u5236\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u4ece\u4e09\u4e2a\u89d2\u5ea6\u7cfb\u7edf\u7814\u7a76\u5e7b\u89c9\u76f8\u5173\u795e\u7ecf\u5143\uff08H-Neurons\uff09\uff1a1\uff09\u8bc6\u522b\uff1a\u53d1\u73b0\u6781\u7a00\u758f\u7684\u795e\u7ecf\u5143\u5b50\u96c6\u80fd\u53ef\u9760\u9884\u6d4b\u5e7b\u89c9\u53d1\u751f\uff1b2\uff09\u884c\u4e3a\u5f71\u54cd\uff1a\u901a\u8fc7\u53d7\u63a7\u5e72\u9884\u8bc1\u660e\u8fd9\u4e9b\u795e\u7ecf\u5143\u4e0e\u8fc7\u5ea6\u987a\u4ece\u884c\u4e3a\u5b58\u5728\u56e0\u679c\u5173\u8054\uff1b3\uff09\u8d77\u6e90\uff1a\u8ffd\u6eaf\u8fd9\u4e9b\u795e\u7ecf\u5143\u5230\u9884\u8bad\u7ec3\u57fa\u7840\u6a21\u578b\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u9884\u8bad\u7ec3\u9636\u6bb5\u5c31\u5df2\u51fa\u73b0\u3002", "result": "\u8bc6\u522b\u51fa\u4ec5\u5360\u6a21\u578b\u603b\u795e\u7ecf\u5143\u4e0d\u52300.1%\u7684\u7a00\u758f\u795e\u7ecf\u5143\u5b50\u96c6\u80fd\u53ef\u9760\u9884\u6d4b\u5e7b\u89c9\u53d1\u751f\uff0c\u4e14\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u5177\u6709\u5f3a\u6cdb\u5316\u80fd\u529b\u3002\u8fd9\u4e9b\u795e\u7ecf\u5143\u4e0e\u8fc7\u5ea6\u987a\u4ece\u884c\u4e3a\u5b58\u5728\u56e0\u679c\u5173\u8054\uff0c\u4e14\u6e90\u4e8e\u9884\u8bad\u7ec3\u9636\u6bb5\u7684\u57fa\u7840\u6a21\u578b\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c06\u5b8f\u89c2\u884c\u4e3a\u6a21\u5f0f\u4e0e\u5fae\u89c2\u795e\u7ecf\u673a\u5236\u8054\u7cfb\u8d77\u6765\uff0c\u4e3a\u5f00\u53d1\u66f4\u53ef\u9760\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002\u5e7b\u89c9\u76f8\u5173\u795e\u7ecf\u5143\u5728\u9884\u8bad\u7ec3\u9636\u6bb5\u5c31\u5df2\u5f62\u6210\uff0c\u4e14\u4ec5\u9700\u6781\u5c11\u6570\u795e\u7ecf\u5143\u5c31\u80fd\u53ef\u9760\u9884\u6d4b\u5e7b\u89c9\u53d1\u751f\u3002"}}
{"id": "2512.01880", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01880", "abs": "https://arxiv.org/abs/2512.01880", "authors": ["Daren Zhong", "Dingcheng Huang", "Clayton Greenberg"], "title": "Predicting Human Chess Moves: An AI Assisted Analysis of Chess Games Using Skill-group Specific n-gram Language Models", "comment": null, "summary": "Chess, a deterministic game with perfect information, has long served as a benchmark for studying strategic decision-making and artificial intelligence. Traditional chess engines or tools for analysis primarily focus on calculating optimal moves, often neglecting the variability inherent in human chess playing, particularly across different skill levels.\n  To overcome this limitation, we propose a novel and computationally efficient move prediction framework that approaches chess move prediction as a behavioral analysis task. The framework employs n-gram language models to capture move patterns characteristic of specific player skill levels. By dividing players into seven distinct skill groups, from novice to expert, we trained separate models using data from the open-source chess platform Lichess. The framework dynamically selects the most suitable model for prediction tasks and generates player moves based on preceding sequences.\n  Evaluation on real-world game data demonstrates that the model selector module within the framework can classify skill levels with an accuracy of up to 31.7\\% when utilizing early game information (16 half-moves). The move prediction framework also shows substantial accuracy improvements, with our Selector Assisted Accuracy being up to 39.1\\% more accurate than our benchmark accuracy. The computational efficiency of the framework further enhances its suitability for real-time chess analysis.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8en-gram\u8bed\u8a00\u6a21\u578b\u7684\u56fd\u9645\u8c61\u68cb\u8d70\u6cd5\u9884\u6d4b\u6846\u67b6\uff0c\u5c06\u8d70\u6cd5\u9884\u6d4b\u89c6\u4e3a\u884c\u4e3a\u5206\u6790\u4efb\u52a1\uff0c\u80fd\u591f\u6839\u636e\u73a9\u5bb6\u6280\u80fd\u6c34\u5e73\u52a8\u6001\u9009\u62e9\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\u3002", "motivation": "\u4f20\u7edf\u56fd\u9645\u8c61\u68cb\u5f15\u64ce\u4e3b\u8981\u5173\u6ce8\u8ba1\u7b97\u6700\u4f18\u8d70\u6cd5\uff0c\u5ffd\u7565\u4e86\u4e0d\u540c\u6280\u80fd\u6c34\u5e73\u73a9\u5bb6\u8d70\u6cd5\u7684\u53d8\u5f02\u6027\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u5c40\u9650\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5206\u6790\u73a9\u5bb6\u884c\u4e3a\u6a21\u5f0f\u5e76\u8003\u8651\u6280\u80fd\u6c34\u5e73\u5dee\u5f02\u7684\u9884\u6d4b\u6846\u67b6\u3002", "method": "\u5c06\u73a9\u5bb6\u5206\u4e3a7\u4e2a\u6280\u80fd\u7b49\u7ea7\uff08\u4ece\u65b0\u624b\u5230\u4e13\u5bb6\uff09\uff0c\u4f7f\u7528Lichess\u5e73\u53f0\u7684\u5f00\u6e90\u6570\u636e\u8bad\u7ec3\u72ec\u7acb\u7684n-gram\u8bed\u8a00\u6a21\u578b\u6765\u6355\u6349\u5404\u6280\u80fd\u6c34\u5e73\u7684\u8d70\u6cd5\u6a21\u5f0f\u3002\u6846\u67b6\u5305\u542b\u6a21\u578b\u9009\u62e9\u5668\u6a21\u5757\uff0c\u80fd\u52a8\u6001\u9009\u62e9\u6700\u9002\u5408\u7684\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\uff0c\u57fa\u4e8e\u524d\u5e8f\u8d70\u6cd5\u5e8f\u5217\u751f\u6210\u73a9\u5bb6\u8d70\u6cd5\u3002", "result": "\u6a21\u578b\u9009\u62e9\u5668\u6a21\u5757\u5728\u5229\u7528\u65e9\u671f\u6e38\u620f\u4fe1\u606f\uff0816\u4e2a\u534a\u8d70\u6cd5\uff09\u65f6\uff0c\u6280\u80fd\u6c34\u5e73\u5206\u7c7b\u51c6\u786e\u7387\u6700\u9ad8\u8fbe31.7%\u3002\u8d70\u6cd5\u9884\u6d4b\u6846\u67b6\u7684Selector Assisted Accuracy\u6bd4\u57fa\u51c6\u51c6\u786e\u7387\u63d0\u9ad8\u4e8639.1%\u3002\u6846\u67b6\u5177\u6709\u8ba1\u7b97\u6548\u7387\uff0c\u9002\u5408\u5b9e\u65f6\u5206\u6790\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u5c06\u56fd\u9645\u8c61\u68cb\u8d70\u6cd5\u9884\u6d4b\u91cd\u65b0\u5b9a\u4e49\u4e3a\u884c\u4e3a\u5206\u6790\u4efb\u52a1\uff0c\u901a\u8fc7\u8003\u8651\u73a9\u5bb6\u6280\u80fd\u6c34\u5e73\u7684\u53d8\u5f02\u6027\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u5b9e\u65f6\u56fd\u9645\u8c61\u68cb\u5206\u6790\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2512.01958", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.01958", "abs": "https://arxiv.org/abs/2512.01958", "authors": ["Jie Meng", "Jin Mao"], "title": "Learned-Rule-Augmented Large Language Model Evaluators", "comment": null, "summary": "Large language models (LLMs) are predominantly used as evaluators for natural language generation (NLG) tasks, but their application to broader evaluation scenarios remains limited. In this work, we explore the potential of LLMs as general evaluators across diverse tasks. Although LLM-based evaluators have made progress in different areas, existing methods struggle to generalize due to their reliance on costly, human-designed evaluation principles, which are often misaligned with both annotated data and LLMs' understanding.To address these challenges, we propose a rule-augmented evaluation paradigm. First, we introduce a rule distillation method that automatically extracts scoring rules from data using an LLM-assisted Monte Carlo Tree Search (MCTS), alleviating scalability issues and improving alignment with data. Second, to enable LLMs to effectively apply the learned rules, we propose two strategies: (1) Chain-of-Rule (CoR), which guides LLM to follow distilled rules, and (2) training a rule-augmented LLM evaluator (RuAE) via reinforcement learning, further bridging the gap between rules and LLMs' reasoning. Extensive experiments on diverse tasks demonstrate the effectiveness and generalizability of our approach across various evaluation scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c4\u5219\u589e\u5f3a\u7684LLM\u8bc4\u4f30\u8303\u5f0f\uff0c\u901a\u8fc7\u81ea\u52a8\u4ece\u6570\u636e\u4e2d\u63d0\u53d6\u8bc4\u5206\u89c4\u5219\u5e76\u8ba9LLM\u6709\u6548\u5e94\u7528\u8fd9\u4e9b\u89c4\u5219\uff0c\u89e3\u51b3\u4e86\u73b0\u6709LLM\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u8bbe\u8ba1\u89c4\u5219\u4e14\u4e0e\u6570\u636e\u548cLLM\u7406\u89e3\u4e0d\u5339\u914d\u7684\u95ee\u9898\u3002", "motivation": "LLM\u4e3b\u8981\u88ab\u7528\u4e8e\u81ea\u7136\u8bed\u8a00\u751f\u6210\u4efb\u52a1\u7684\u8bc4\u4f30\uff0c\u4f46\u5728\u66f4\u5e7f\u6cdb\u7684\u8bc4\u4f30\u573a\u666f\u4e2d\u5e94\u7528\u6709\u9650\u3002\u73b0\u6709LLM\u8bc4\u4f30\u65b9\u6cd5\u96be\u4ee5\u6cdb\u5316\uff0c\u56e0\u4e3a\u5b83\u4eec\u4f9d\u8d56\u6210\u672c\u9ad8\u6602\u7684\u4eba\u5de5\u8bbe\u8ba1\u8bc4\u4f30\u539f\u5219\uff0c\u8fd9\u4e9b\u539f\u5219\u5f80\u5f80\u4e0e\u6807\u6ce8\u6570\u636e\u548cLLM\u7684\u7406\u89e3\u4e0d\u5339\u914d\u3002", "method": "\u63d0\u51fa\u89c4\u5219\u589e\u5f3a\u7684\u8bc4\u4f30\u8303\u5f0f\uff1a1) \u89c4\u5219\u84b8\u998f\u65b9\u6cd5\uff1a\u4f7f\u7528LLM\u8f85\u52a9\u7684\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u81ea\u52a8\u4ece\u6570\u636e\u4e2d\u63d0\u53d6\u8bc4\u5206\u89c4\u5219\uff0c\u89e3\u51b3\u53ef\u6269\u5c55\u6027\u95ee\u9898\u5e76\u63d0\u9ad8\u4e0e\u6570\u636e\u7684\u5bf9\u9f50\u5ea6\uff1b2) \u89c4\u5219\u5e94\u7528\u7b56\u7565\uff1a\u5305\u62ecChain-of-Rule\u6307\u5bfcLLM\u9075\u5faa\u84b8\u998f\u89c4\u5219\uff0c\u4ee5\u53ca\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u89c4\u5219\u589e\u5f3a\u7684LLM\u8bc4\u4f30\u5668\uff0c\u5f25\u5408\u89c4\u5219\u4e0eLLM\u63a8\u7406\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "result": "\u5728\u591a\u6837\u5316\u4efb\u52a1\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u8bc4\u4f30\u573a\u666f\u4e2d\u7684\u6709\u6548\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684\u89c4\u5219\u589e\u5f3a\u8bc4\u4f30\u8303\u5f0f\u80fd\u591f\u81ea\u52a8\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u8bc4\u4f30\u89c4\u5219\uff0c\u5e76\u901a\u8fc7\u6709\u6548\u7684\u89c4\u5219\u5e94\u7528\u7b56\u7565\u8ba9LLM\u66f4\u597d\u5730\u6267\u884c\u8bc4\u4f30\u4efb\u52a1\uff0c\u4e3aLLM\u4f5c\u4e3a\u901a\u7528\u8bc4\u4f30\u5668\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.01970", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.01970", "abs": "https://arxiv.org/abs/2512.01970", "authors": ["Sitao Cheng", "Xunjian Yin", "Ruiwen Zhou", "Yuxuan Li", "Xinyi Wang", "Liangming Pan", "William Yang Wang", "Victor Zhong"], "title": "From Atomic to Composite: Reinforcement Learning Enables Generalization in Complementary Reasoning", "comment": "Work in Progress. Code and data will be available at https://github.com/sitaocheng/from_atomic_to_composite", "summary": "The mechanism by which RL contributes to reasoning capabilities-whether it incentivizes the synthesis of new skills or merely amplifies existing behaviors-remains a subject of intense debate. In this work, we investigate this question through the lens of Complementary Reasoning, a complex task that requires integrating internal parametric knowledge with external contextual information. Using a controlled synthetic dataset of human biographies, we strictly decouple this ability into two atomic skills: Parametric Reasoning (relying on internal knowledge) and Contextual Reasoning (depending on external information). To rigorously assess capability boundaries, we evaluate generalization across three distinct levels of difficulty: I.I.D., Composition, and Zero-shot settings. We find that while SFT is sufficient for in-distribution performance, it struggles with O.O.D. generalization, particularly in Zero-shot settings where relational combinations are novel. Crucially, we identify the SFT Generalization Paradox: Models supervised solely on the composite task achieve near-perfect in-distribution accuracy but collapse on out-of-distribution generalization, indicating their reliance on rote memorization of path shortcuts. In contrast, we find that RL acts as a reasoning synthesizer rather than a probability amplifier. However, we uncover a strict atomic prerequisite: RL can only synthesize these complex strategies if the base model has first mastered the independent atomic skills (Parametric and Contextual) via SFT. These findings challenge the view of RL as a mere amplifier, suggesting that given sufficient atomic foundations, RL can actively synthesize complex reasoning strategies from learned primitives without explicit supervision on such complex strategies. This indicates that decoupled atomic training followed by RL offers a scalable path to generalization for complex reasoning tasks.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5f3a\u5316\u5b66\u4e60\u5982\u4f55\u63d0\u5347\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0RL\u4e0d\u662f\u7b80\u5355\u653e\u5927\u73b0\u6709\u884c\u4e3a\uff0c\u800c\u662f\u80fd\u591f\u5408\u6210\u65b0\u7684\u590d\u6742\u63a8\u7406\u7b56\u7565\uff0c\u4f46\u524d\u63d0\u662f\u57fa\u7840\u6a21\u578b\u9700\u5148\u901a\u8fc7\u76d1\u7763\u5b66\u4e60\u638c\u63e1\u539f\u5b50\u6280\u80fd\u3002", "motivation": "\u7814\u7a76\u5f3a\u5316\u5b66\u4e60\u5bf9\u63a8\u7406\u80fd\u529b\u7684\u8d21\u732e\u673a\u5236\u2014\u2014\u662f\u6fc0\u52b1\u65b0\u6280\u80fd\u7684\u5408\u6210\u8fd8\u662f\u4ec5\u4ec5\u653e\u5927\u73b0\u6709\u884c\u4e3a\uff0c\u8fd9\u662f\u4e00\u4e2a\u6fc0\u70c8\u4e89\u8bba\u7684\u8bdd\u9898\u3002\u901a\u8fc7\u4e92\u8865\u63a8\u7406\u4efb\u52a1\u6765\u63a2\u7a76\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u4eba\u7c7b\u4f20\u8bb0\u7684\u5408\u6210\u6570\u636e\u96c6\uff0c\u5c06\u4e92\u8865\u63a8\u7406\u80fd\u529b\u4e25\u683c\u89e3\u8026\u4e3a\u4e24\u4e2a\u539f\u5b50\u6280\u80fd\uff1a\u53c2\u6570\u63a8\u7406\uff08\u4f9d\u8d56\u5185\u90e8\u77e5\u8bc6\uff09\u548c\u4e0a\u4e0b\u6587\u63a8\u7406\uff08\u4f9d\u8d56\u5916\u90e8\u4fe1\u606f\uff09\u3002\u5728\u4e09\u4e2a\u96be\u5ea6\u7ea7\u522b\u8bc4\u4f30\u6cdb\u5316\u80fd\u529b\uff1aI.I.D.\u3001\u7ec4\u5408\u548c\u96f6\u6837\u672c\u8bbe\u7f6e\u3002", "result": "\u53d1\u73b0SFT\u5728\u5206\u5e03\u5185\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5206\u5e03\u5916\u6cdb\u5316\uff08\u7279\u522b\u662f\u96f6\u6837\u672c\u8bbe\u7f6e\uff09\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u5b58\u5728\"SFT\u6cdb\u5316\u6096\u8bba\"\uff1a\u6a21\u578b\u4ec5\u9760\u8bb0\u5fc6\u8def\u5f84\u6377\u5f84\u3002RL\u80fd\u591f\u4f5c\u4e3a\u63a8\u7406\u5408\u6210\u5668\u800c\u975e\u6982\u7387\u653e\u5927\u5668\uff0c\u4f46\u524d\u63d0\u662f\u57fa\u7840\u6a21\u578b\u9700\u5148\u901a\u8fc7SFT\u638c\u63e1\u72ec\u7acb\u7684\u539f\u5b50\u6280\u80fd\u3002", "conclusion": "RL\u4e0d\u4ec5\u4ec5\u662f\u653e\u5927\u5668\uff0c\u5728\u5177\u5907\u8db3\u591f\u539f\u5b50\u57fa\u7840\u7684\u60c5\u51b5\u4e0b\uff0c\u80fd\u591f\u4e3b\u52a8\u4ece\u5b66\u4e60\u5230\u7684\u539f\u8bed\u4e2d\u5408\u6210\u590d\u6742\u63a8\u7406\u7b56\u7565\uff0c\u65e0\u9700\u5bf9\u590d\u6742\u7b56\u7565\u8fdb\u884c\u663e\u5f0f\u76d1\u7763\u3002\u89e3\u8026\u539f\u5b50\u8bad\u7ec3\u540e\u63a5RL\u4e3a\u590d\u6742\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u6cdb\u5316\u8def\u5f84\u3002"}}
{"id": "2512.01979", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.01979", "abs": "https://arxiv.org/abs/2512.01979", "authors": ["Aiden Yiliu Li", "Bizhi Yu", "Daoan Lei", "Tianhe Ren", "Shilong Liu"], "title": "Chain-of-Ground: Improving GUI Grounding via Iterative Reasoning and Reference Feedback", "comment": null, "summary": "GUI grounding aims to align natural language instructions with precise regions in complex user interfaces. Advanced multimodal large language models show strong ability in visual GUI grounding but still struggle with small or visually similar targets and ambiguity in real world layouts. These limitations arise from limited grounding capacity and from underuse of existing reasoning potential. We present Chain of Ground CoG a training free multi step grounding framework that uses multimodal large language models for iterative visual reasoning and refinement. Instead of direct prediction the model progressively reflects and adjusts its hypotheses leading to more accurate and interpretable localization. Our approach achieves 68.4 accuracy on the ScreenSpot Pro benchmark an improvement of 4.8 points. To measure real world generalization we introduce TPanel UI a dataset of 420 labeled industrial control panels with visual distortions such as blur and masking. On TPanel UI Chain of Ground improves over the strong baseline Qwen3 VL 235B by 6.9 points showing the effectiveness of multi step training free grounding across real world and digital interfaces. These results highlight a direction for unlocking grounding potential through structured iterative refinement instead of additional training.", "AI": {"tldr": "\u63d0\u51faChain of Ground (CoG)\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6b65\u8fed\u4ee3\u63a8\u7406\u548c\u4f18\u5316\u63d0\u5347GUI\u89c6\u89c9\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u5728ScreenSpot Pro\u57fa\u51c6\u4e0a\u63d0\u53474.8\u4e2a\u767e\u5206\u70b9\uff0c\u5728\u5de5\u4e1a\u63a7\u5236\u9762\u677f\u6570\u636e\u96c6\u4e0a\u63d0\u53476.9\u4e2a\u767e\u5206\u70b9\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728GUI\u89c6\u89c9\u5b9a\u4f4d\u4e2d\u9762\u4e34\u5c0f\u76ee\u6807\u3001\u89c6\u89c9\u76f8\u4f3c\u76ee\u6807\u8bc6\u522b\u56f0\u96be\uff0c\u4ee5\u53ca\u771f\u5b9e\u4e16\u754c\u5e03\u5c40\u4e2d\u7684\u6b67\u4e49\u95ee\u9898\uff0c\u8fd9\u4e9b\u9650\u5236\u6e90\u4e8e\u6709\u9650\u7684\u5b9a\u4f4d\u80fd\u529b\u548c\u672a\u5145\u5206\u5229\u7528\u73b0\u6709\u63a8\u7406\u6f5c\u529b\u3002", "method": "\u63d0\u51faChain of Ground (CoG)\u6846\u67b6\uff0c\u91c7\u7528\u65e0\u9700\u8bad\u7ec3\u7684\u591a\u6b65\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8fed\u4ee3\u89c6\u89c9\u63a8\u7406\u548c\u4f18\u5316\uff0c\u9010\u6b65\u53cd\u601d\u548c\u8c03\u6574\u5047\u8bbe\uff0c\u800c\u4e0d\u662f\u76f4\u63a5\u9884\u6d4b\u3002", "result": "\u5728ScreenSpot Pro\u57fa\u51c6\u4e0a\u8fbe\u523068.4%\u51c6\u786e\u7387\uff0c\u63d0\u53474.8\u4e2a\u767e\u5206\u70b9\uff1b\u5728TPanel UI\u5de5\u4e1a\u63a7\u5236\u9762\u677f\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u6bd4Qwen3 VL 235B\u57fa\u7ebf\u63d0\u53476.9\u4e2a\u767e\u5206\u70b9\uff0c\u5c55\u793a\u4e86\u5bf9\u771f\u5b9e\u4e16\u754c\u548c\u6570\u5b57\u754c\u9762\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u6784\u5316\u8fed\u4ee3\u4f18\u5316\u800c\u975e\u989d\u5916\u8bad\u7ec3\uff0c\u80fd\u591f\u91ca\u653e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b9a\u4f4d\u6f5c\u529b\uff0c\u63d0\u4f9b\u66f4\u51c6\u786e\u548c\u53ef\u89e3\u91ca\u7684\u5b9a\u4f4d\u7ed3\u679c\uff0c\u4e3aGUI\u89c6\u89c9\u5b9a\u4f4d\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2512.01992", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.01992", "abs": "https://arxiv.org/abs/2512.01992", "authors": ["Sai Kolasani", "Maxim Saplin", "Nicholas Crispino", "Kyle Montgomery", "Jared Quincy Davis", "Matei Zaharia", "Chi Wang", "Chenguang Wang"], "title": "LLM CHESS: Benchmarking Reasoning and Instruction-Following in LLMs through Chess", "comment": null, "summary": "We introduce LLM CHESS, an evaluation framework designed to probe the generalization of reasoning and instruction-following abilities in large language models (LLMs) through extended agentic interaction in the domain of chess. We rank over 50 open and closed source models by playing against a random opponent using a range of behavioral metrics, including win and loss rates, move quality, move legality, hallucinated actions, and game duration. For a subset of top reasoning models, we derive an Elo estimate by playing against a chess engine with variably configured skill, which allows for comparisons between models in an easily understandable way. Despite the simplicity of the instruction-following task and the weakness of the opponent, many state-of-the-art models struggle to complete games or achieve consistent wins. Similar to other benchmarks on complex reasoning tasks, our experiments reveal a clear separation between reasoning and non-reasoning models. However, unlike existing static benchmarks, the stochastic and dynamic nature of LLM CHESS uniquely reduces overfitting and memorization while preventing benchmark saturation, proving difficult even for top reasoning models. To support future work on evaluating reasoning and instruction-following in LLMs, we release our experimental framework, a public leaderboard, and a dataset of associated games.", "AI": {"tldr": "LLM CHESS\u662f\u4e00\u4e2a\u901a\u8fc7\u56fd\u9645\u8c61\u68cb\u6e38\u620f\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u548c\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u7684\u6846\u67b6\uff0c\u6d4b\u8bd5\u4e8650\u591a\u4e2a\u6a21\u578b\uff0c\u53d1\u73b0\u5373\u4f7f\u662f\u9876\u7ea7\u6a21\u578b\u4e5f\u96be\u4ee5\u7a33\u5b9a\u5b8c\u6210\u6e38\u620f\uff0c\u8be5\u6846\u67b6\u80fd\u6709\u6548\u51cf\u5c11\u8fc7\u62df\u5408\u548c\u8bb0\u5fc6\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u57fa\u51c6\u5b58\u5728\u8fc7\u62df\u5408\u3001\u8bb0\u5fc6\u5316\u548c\u57fa\u51c6\u9971\u548c\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u771f\u5b9e\u6d4b\u8bd5\u6a21\u578b\u63a8\u7406\u548c\u6307\u4ee4\u9075\u5faa\u6cdb\u5316\u80fd\u529b\u7684\u52a8\u6001\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u56fd\u9645\u8c61\u68cb\u6e38\u620f\u73af\u5883\uff0c\u8ba9LLMs\u4e0e\u968f\u673a\u5bf9\u624b\u5bf9\u6218\uff0c\u4f7f\u7528\u80dc\u7387\u3001\u79fb\u52a8\u8d28\u91cf\u3001\u5408\u6cd5\u6027\u3001\u5e7b\u89c9\u52a8\u4f5c\u7b49\u884c\u4e3a\u6307\u6807\u8fdb\u884c\u8bc4\u4f30\uff1b\u5bf9\u9876\u7ea7\u63a8\u7406\u6a21\u578b\u8fd8\u4f7f\u7528\u53ef\u53d8\u6280\u80fd\u914d\u7f6e\u7684\u8c61\u68cb\u5f15\u64ce\u8fdb\u884cElo\u8bc4\u5206\u3002", "result": "\u6d4b\u8bd5\u4e8650\u591a\u4e2a\u5f00\u6e90\u548c\u95ed\u6e90\u6a21\u578b\uff0c\u53d1\u73b0\u8bb8\u591a\u6700\u5148\u8fdb\u7684\u6a21\u578b\u96be\u4ee5\u5b8c\u6210\u6e38\u620f\u6216\u53d6\u5f97\u7a33\u5b9a\u80dc\u5229\uff1b\u63a8\u7406\u6a21\u578b\u548c\u975e\u63a8\u7406\u6a21\u578b\u8868\u73b0\u6709\u660e\u663e\u5dee\u5f02\uff1b\u8be5\u6846\u67b6\u80fd\u6709\u6548\u51cf\u5c11\u8fc7\u62df\u5408\u548c\u8bb0\u5fc6\u95ee\u9898\u3002", "conclusion": "LLM CHESS\u63d0\u4f9b\u4e86\u4e00\u4e2a\u52a8\u6001\u3001\u968f\u673a\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u6709\u6548\u6d4b\u8bd5LLMs\u7684\u63a8\u7406\u548c\u6307\u4ee4\u9075\u5faa\u80fd\u529b\uff0c\u51cf\u5c11\u4e86\u73b0\u6709\u9759\u6001\u57fa\u51c6\u7684\u95ee\u9898\uff0c\u5e76\u53d1\u5e03\u4e86\u5b9e\u9a8c\u6846\u67b6\u3001\u516c\u5f00\u6392\u884c\u699c\u548c\u76f8\u5173\u6570\u636e\u96c6\u3002"}}
