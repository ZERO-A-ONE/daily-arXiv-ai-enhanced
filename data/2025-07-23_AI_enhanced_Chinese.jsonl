{"id": "2507.15859", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15859", "abs": "https://arxiv.org/abs/2507.15859", "authors": ["Harsha Sammangi", "Aditya Jagatha", "Giridhar Reddy Bojja", "Jun Liu"], "title": "Decentralized AI-driven IoT Architecture for Privacy-Preserving and Latency-Optimized Healthcare in Pandemic and Critical Care Scenarios", "comment": "10 Pages", "summary": "AI Innovations in the IoT for Real-Time Patient Monitoring On one hand, the\ncurrent traditional centralized healthcare architecture poses numerous issues,\nincluding data privacy, delay, and security. Here, we present an AI-enabled\ndecentralized IoT architecture that can address such challenges during a\npandemic and critical care settings. This work presents our architecture to\nenhance the effectiveness of the current available federated learning,\nblockchain, and edge computing approach, maximizing data privacy, minimizing\nlatency, and improving other general system metrics. Experimental results\ndemonstrate transaction latency, energy consumption, and data throughput orders\nof magnitude lower than competitive cloud solutions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eAI\u7684\u53bb\u4e2d\u5fc3\u5316\u7269\u8054\u7f51\u67b6\u6784\uff0c\u7528\u4e8e\u5b9e\u65f6\u60a3\u8005\u76d1\u6d4b\uff0c\u901a\u8fc7\u7ed3\u5408\u8054\u90a6\u5b66\u4e60\u3001\u533a\u5757\u94fe\u548c\u8fb9\u7f18\u8ba1\u7b97\u6280\u672f\u6765\u89e3\u51b3\u4f20\u7edf\u4e2d\u5fc3\u5316\u533b\u7597\u67b6\u6784\u5728\u6570\u636e\u9690\u79c1\u3001\u5ef6\u8fdf\u548c\u5b89\u5168\u6027\u65b9\u9762\u7684\u95ee\u9898", "motivation": "\u4f20\u7edf\u7684\u4e2d\u5fc3\u5316\u533b\u7597\u67b6\u6784\u5b58\u5728\u6570\u636e\u9690\u79c1\u6cc4\u9732\u3001\u5ef6\u8fdf\u9ad8\u548c\u5b89\u5168\u6027\u5dee\u7b49\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u75ab\u60c5\u548c\u91cd\u75c7\u76d1\u62a4\u73af\u5883\u4e2d\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u6765\u5b9e\u73b0\u5b9e\u65f6\u60a3\u8005\u76d1\u6d4b", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cdAI\u9a71\u52a8\u7684\u53bb\u4e2d\u5fc3\u5316\u7269\u8054\u7f51\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u6574\u5408\u5e76\u4f18\u5316\u4e86\u8054\u90a6\u5b66\u4e60\u3001\u533a\u5757\u94fe\u548c\u8fb9\u7f18\u8ba1\u7b97\u6280\u672f\uff0c\u65e8\u5728\u6700\u5927\u5316\u6570\u636e\u9690\u79c1\u4fdd\u62a4\u3001\u6700\u5c0f\u5316\u5ef6\u8fdf\u5e76\u6539\u5584\u6574\u4f53\u7cfb\u7edf\u6027\u80fd\u6307\u6807", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u7ade\u4e89\u6027\u4e91\u89e3\u51b3\u65b9\u6848\u76f8\u6bd4\uff0c\u8be5\u67b6\u6784\u5728\u4ea4\u6613\u5ef6\u8fdf\u3001\u80fd\u8017\u548c\u6570\u636e\u541e\u5410\u91cf\u65b9\u9762\u90fd\u6709\u6570\u4e2a\u6570\u91cf\u7ea7\u7684\u6539\u5584", "conclusion": "\u63d0\u51fa\u7684AI\u9a71\u52a8\u53bb\u4e2d\u5fc3\u5316\u7269\u8054\u7f51\u67b6\u6784\u80fd\u591f\u6709\u6548\u89e3\u51b3\u4f20\u7edf\u4e2d\u5fc3\u5316\u533b\u7597\u7cfb\u7edf\u7684\u5173\u952e\u95ee\u9898\uff0c\u5728\u4fdd\u969c\u6570\u636e\u9690\u79c1\u548c\u5b89\u5168\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\uff0c\u4e3a\u75ab\u60c5\u548c\u91cd\u75c7\u76d1\u62a4\u573a\u666f\u4e0b\u7684\u5b9e\u65f6\u60a3\u8005\u76d1\u6d4b\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u65b9\u6848"}}
{"id": "2507.15984", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.15984", "abs": "https://arxiv.org/abs/2507.15984", "authors": ["I Putu Arya Dharmaadi", "Mohannad Alhanahnah", "Van-Thuan Pham", "Fadi Mohsen", "Fatih Turkmen"], "title": "BACFuzz: Exposing the Silence on Broken Access Control Vulnerabilities in Web Applications", "comment": "Under peer-review", "summary": "Broken Access Control (BAC) remains one of the most critical and widespread\nvulnerabilities in web applications, allowing attackers to access unauthorized\nresources or perform privileged actions. Despite its severity, BAC is\nunderexplored in automated testing due to key challenges: the lack of reliable\noracles and the difficulty of generating semantically valid attack requests. We\nintroduce BACFuzz, the first gray-box fuzzing framework specifically designed\nto uncover BAC vulnerabilities, including Broken Object-Level Authorization\n(BOLA) and Broken Function-Level Authorization (BFLA) in PHP-based web\napplications. BACFuzz combines LLM-guided parameter selection with runtime\nfeedback and SQL-based oracle checking to detect silent authorization flaws. It\nemploys lightweight instrumentation to capture runtime information that guides\ntest generation, and analyzes backend SQL queries to verify whether\nunauthorized inputs flow into protected operations. Evaluated on 20 real-world\nweb applications, including 15 CVE cases and 2 known benchmarks, BACFuzz\ndetects 16 of 17 known issues and uncovers 26 previously unknown BAC\nvulnerabilities with low false positive rates. All identified issues have been\nresponsibly disclosed, and artifacts will be publicly released.", "AI": {"tldr": "BACFuzz\u662f\u9996\u4e2a\u4e13\u95e8\u9488\u5bf9\u7834\u574f\u8bbf\u95ee\u63a7\u5236(BAC)\u6f0f\u6d1e\u7684\u7070\u76d2\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6\uff0c\u7ed3\u5408LLM\u6307\u5bfc\u7684\u53c2\u6570\u9009\u62e9\u548cSQL\u67e5\u8be2\u5206\u6790\u6765\u68c0\u6d4bPHP Web\u5e94\u7528\u4e2d\u7684\u6388\u6743\u7f3a\u9677\uff0c\u572820\u4e2a\u771f\u5b9e\u5e94\u7528\u4e2d\u68c0\u6d4b\u51fa16\u4e2a\u5df2\u77e5\u95ee\u9898\u548c26\u4e2a\u65b0\u53d1\u73b0\u7684BAC\u6f0f\u6d1e\u3002", "motivation": "\u7834\u574f\u8bbf\u95ee\u63a7\u5236(BAC)\u662fWeb\u5e94\u7528\u4e2d\u6700\u5173\u952e\u548c\u5e7f\u6cdb\u7684\u6f0f\u6d1e\u4e4b\u4e00\uff0c\u5141\u8bb8\u653b\u51fb\u8005\u8bbf\u95ee\u672a\u6388\u6743\u8d44\u6e90\u6216\u6267\u884c\u7279\u6743\u64cd\u4f5c\u3002\u5c3d\u7ba1\u5176\u4e25\u91cd\u6027\u5f88\u9ad8\uff0c\u4f46\u7531\u4e8e\u7f3a\u4e4f\u53ef\u9760\u7684\u9884\u8a00\u673a\u548c\u96be\u4ee5\u751f\u6210\u8bed\u4e49\u6709\u6548\u7684\u653b\u51fb\u8bf7\u6c42\u7b49\u5173\u952e\u6311\u6218\uff0cBAC\u5728\u81ea\u52a8\u5316\u6d4b\u8bd5\u4e2d\u63a2\u7d22\u4e0d\u8db3\u3002", "method": "\u63d0\u51faBACFuzz\u6846\u67b6\uff0c\u7ed3\u5408LLM\u6307\u5bfc\u7684\u53c2\u6570\u9009\u62e9\u3001\u8fd0\u884c\u65f6\u53cd\u9988\u548c\u57fa\u4e8eSQL\u7684\u9884\u8a00\u673a\u68c0\u67e5\u6765\u68c0\u6d4b\u9759\u9ed8\u6388\u6743\u7f3a\u9677\u3002\u4f7f\u7528\u8f7b\u91cf\u7ea7\u63d2\u6869\u6355\u83b7\u8fd0\u884c\u65f6\u4fe1\u606f\u6307\u5bfc\u6d4b\u8bd5\u751f\u6210\uff0c\u5e76\u5206\u6790\u540e\u7aefSQL\u67e5\u8be2\u6765\u9a8c\u8bc1\u672a\u6388\u6743\u8f93\u5165\u662f\u5426\u6d41\u5165\u53d7\u4fdd\u62a4\u64cd\u4f5c\u3002", "result": "\u572820\u4e2a\u771f\u5b9eWeb\u5e94\u7528(\u5305\u62ec15\u4e2aCVE\u6848\u4f8b\u548c2\u4e2a\u5df2\u77e5\u57fa\u51c6)\u4e0a\u8bc4\u4f30\uff0cBACFuzz\u68c0\u6d4b\u51fa17\u4e2a\u5df2\u77e5\u95ee\u9898\u4e2d\u768416\u4e2a\uff0c\u5e76\u53d1\u73b0\u4e8626\u4e2a\u6b64\u524d\u672a\u77e5\u7684BAC\u6f0f\u6d1e\uff0c\u4e14\u8bef\u62a5\u7387\u8f83\u4f4e\u3002\u6240\u6709\u8bc6\u522b\u7684\u95ee\u9898\u90fd\u5df2\u8d1f\u8d23\u4efb\u5730\u62ab\u9732\u3002", "conclusion": "BACFuzz\u4f5c\u4e3a\u9996\u4e2a\u4e13\u95e8\u9488\u5bf9BAC\u6f0f\u6d1e\u7684\u7070\u76d2\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u7ed3\u5408LLM\u6307\u5bfc\u548cSQL\u67e5\u8be2\u5206\u6790\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684BAC\u6f0f\u6d1e\u68c0\u6d4b\uff0c\u4e3aWeb\u5e94\u7528\u5b89\u5168\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.15997", "categories": ["cs.CR", "cs.HC", "68-XX 68-XX 68-XX"], "pdf": "https://arxiv.org/pdf/2507.15997", "abs": "https://arxiv.org/abs/2507.15997", "authors": ["Onyinye Dibia", "Mengyi Lu", "Prianka Bhattacharjee", "Joseph P. Near", "Yuanyuan Feng"], "title": "\"We Need a Standard\": Toward an Expert-Informed Privacy Label for Differential Privacy", "comment": "13 pages, 5 figures", "summary": "The increasing adoption of differential privacy (DP) leads to public-facing\nDP deployments by both government agencies and companies. However, real-world\nDP deployments often do not fully disclose their privacy guarantees, which vary\ngreatly between deployments. Failure to disclose certain DP parameters can lead\nto misunderstandings about the strength of the privacy guarantee, undermining\nthe trust in DP. In this work, we seek to inform future standards for\ncommunicating the privacy guarantees of DP deployments. Based on\nsemi-structured interviews with 12 DP experts, we identify important DP\nparameters necessary to comprehensively communicate DP guarantees, and describe\nwhy and how they should be disclosed. Based on expert recommendations, we\ndesign an initial privacy label for DP to comprehensively communicate privacy\nguarantees in a standardized format.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u4e13\u5bb6\u8bbf\u8c08\u8bc6\u522b\u4e86\u5dee\u5206\u9690\u79c1\u90e8\u7f72\u4e2d\u9700\u8981\u62ab\u9732\u7684\u5173\u952e\u53c2\u6570\uff0c\u5e76\u8bbe\u8ba1\u4e86\u6807\u51c6\u5316\u7684\u9690\u79c1\u6807\u7b7e\u6765\u5168\u9762\u4f20\u8fbe\u9690\u79c1\u4fdd\u969c\u4fe1\u606f", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u5dee\u5206\u9690\u79c1\u90e8\u7f72\u5f80\u5f80\u4e0d\u5145\u5206\u62ab\u9732\u5176\u9690\u79c1\u4fdd\u969c\u53c2\u6570\uff0c\u8fd9\u79cd\u53c2\u6570\u62ab\u9732\u7684\u4e0d\u5b8c\u6574\u6027\u5bfc\u81f4\u5bf9\u9690\u79c1\u4fdd\u62a4\u5f3a\u5ea6\u7684\u8bef\u89e3\uff0c\u4ece\u800c\u524a\u5f31\u4e86\u5bf9\u5dee\u5206\u9690\u79c1\u7684\u4fe1\u4efb", "method": "\u5bf912\u540d\u5dee\u5206\u9690\u79c1\u4e13\u5bb6\u8fdb\u884c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u8bc6\u522b\u5168\u9762\u4f20\u8fbe\u5dee\u5206\u9690\u79c1\u4fdd\u969c\u6240\u9700\u7684\u91cd\u8981\u53c2\u6570\uff0c\u5e76\u63cf\u8ff0\u8fd9\u4e9b\u53c2\u6570\u5e94\u8be5\u5982\u4f55\u4ee5\u53ca\u4e3a\u4ec0\u4e48\u9700\u8981\u88ab\u62ab\u9732", "result": "\u8bc6\u522b\u51fa\u4e86\u5168\u9762\u4f20\u8fbe\u5dee\u5206\u9690\u79c1\u4fdd\u969c\u6240\u5fc5\u9700\u7684\u91cd\u8981\u5dee\u5206\u9690\u79c1\u53c2\u6570\uff0c\u5e76\u57fa\u4e8e\u4e13\u5bb6\u5efa\u8bae\u8bbe\u8ba1\u4e86\u521d\u59cb\u7684\u5dee\u5206\u9690\u79c1\u6807\u7b7e\u539f\u578b", "conclusion": "\u57fa\u4e8e\u4e13\u5bb6\u5efa\u8bae\u8bbe\u8ba1\u4e86\u6807\u51c6\u5316\u683c\u5f0f\u7684\u9690\u79c1\u6807\u7b7e\uff0c\u53ef\u4ee5\u5168\u9762\u4f20\u8fbe\u5dee\u5206\u9690\u79c1\u7684\u9690\u79c1\u4fdd\u969c\u4fe1\u606f\uff0c\u4e3a\u672a\u6765\u5236\u5b9a\u5dee\u5206\u9690\u79c1\u90e8\u7f72\u7684\u9690\u79c1\u4fdd\u969c\u4f20\u8fbe\u6807\u51c6\u63d0\u4f9b\u4e86\u6307\u5bfc"}}
{"id": "2507.16040", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.16040", "abs": "https://arxiv.org/abs/2507.16040", "authors": ["Xinyuan Zhang", "Anrin Chakraborti", "Michael Reiter"], "title": "Blocklisted Oblivious Pseudorandom Functions", "comment": null, "summary": "An oblivious pseudorandom function (OPRF) is a protocol by which a client and\nserver interact to evaluate a pseudorandom function on a key provided by the\nserver and an input provided by the client, without divulging the key or input\nto the other party. We extend this notion by enabling the server to specify a\nblocklist, such that OPRF evaluation succeeds only if the client's input is not\non the blocklist. More specifically, our design gains performance by embedding\nthe client input into a metric space, where evaluation continues only if this\nembedding does not cluster with blocklist elements. Our framework exploits this\nstructure to separate the embedding and blocklist check to enable efficient\nimplementations of each, but then must stitch these phases together through\ncryptographic means. Our framework also supports subsequent evaluation of the\nOPRF on the same input more efficiently. We demonstrate the use of our design\nfor password blocklisting in augmented password-authenticated key exchange, and\nto MAC only executables that are not similar to ones on a blocklist of known\nmalware.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u652f\u6301\u9ed1\u540d\u5355\u7684\u9057\u5fd8\u4f2a\u968f\u673a\u51fd\u6570(OPRF)\u534f\u8bae\uff0c\u901a\u8fc7\u5c06\u5ba2\u6237\u7aef\u8f93\u5165\u5d4c\u5165\u5ea6\u91cf\u7a7a\u95f4\u5e76\u68c0\u67e5\u662f\u5426\u4e0e\u9ed1\u540d\u5355\u5143\u7d20\u805a\u7c7b\u6765\u63d0\u9ad8\u6027\u80fd\uff0c\u53ef\u5e94\u7528\u4e8e\u5bc6\u7801\u9ed1\u540d\u5355\u548c\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u7b49\u573a\u666f\u3002", "motivation": "\u4f20\u7edf\u7684\u9057\u5fd8\u4f2a\u968f\u673a\u51fd\u6570\u65e0\u6cd5\u652f\u6301\u670d\u52a1\u5668\u6307\u5b9a\u9ed1\u540d\u5355\u7684\u529f\u80fd\uff0c\u800c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff08\u5982\u5bc6\u7801\u9a8c\u8bc1\u3001\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\uff09\uff0c\u9700\u8981\u5728\u4e0d\u6cc4\u9732\u5ba2\u6237\u7aef\u8f93\u5165\u548c\u670d\u52a1\u5668\u5bc6\u94a5\u7684\u524d\u63d0\u4e0b\uff0c\u68c0\u67e5\u5ba2\u6237\u7aef\u8f93\u5165\u662f\u5426\u5728\u670d\u52a1\u5668\u7684\u9ed1\u540d\u5355\u4e2d\u3002", "method": "\u5c06\u5ba2\u6237\u7aef\u8f93\u5165\u5d4c\u5165\u5230\u5ea6\u91cf\u7a7a\u95f4\u4e2d\uff0c\u901a\u8fc7\u68c0\u67e5\u5d4c\u5165\u5411\u91cf\u662f\u5426\u4e0e\u9ed1\u540d\u5355\u5143\u7d20\u805a\u7c7b\u6765\u5224\u65ad\u8f93\u5165\u662f\u5426\u5728\u9ed1\u540d\u5355\u4e0a\u3002\u6846\u67b6\u5c06\u5d4c\u5165\u8fc7\u7a0b\u548c\u9ed1\u540d\u5355\u68c0\u67e5\u5206\u79bb\u4ee5\u63d0\u9ad8\u6548\u7387\uff0c\u7136\u540e\u901a\u8fc7\u5bc6\u7801\u5b66\u65b9\u6cd5\u5c06\u8fd9\u4e24\u4e2a\u9636\u6bb5\u7ed3\u5408\u8d77\u6765\u3002\u540c\u65f6\u652f\u6301\u5bf9\u76f8\u540c\u8f93\u5165\u7684\u540e\u7eedOPRF\u8bc4\u4f30\u66f4\u9ad8\u6548\u5730\u8fdb\u884c\u3002", "result": "\u6210\u529f\u8bbe\u8ba1\u4e86\u652f\u6301\u9ed1\u540d\u5355\u7684OPRF\u534f\u8bae\uff0c\u5e76\u5728\u4e24\u4e2a\u5b9e\u9645\u5e94\u7528\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff1a1\uff09\u5728\u589e\u5f3a\u5bc6\u7801\u8ba4\u8bc1\u5bc6\u94a5\u4ea4\u6362\u4e2d\u5b9e\u73b0\u5bc6\u7801\u9ed1\u540d\u5355\u529f\u80fd\uff1b2\uff09\u5bf9\u4e0d\u5728\u5df2\u77e5\u6076\u610f\u8f6f\u4ef6\u9ed1\u540d\u5355\u4e2d\u7684\u53ef\u6267\u884c\u6587\u4ef6\u8fdb\u884cMAC\u9a8c\u8bc1\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u6210\u529f\u6269\u5c55\u4e86OPRF\u7684\u529f\u80fd\uff0c\u4f7f\u5176\u80fd\u591f\u652f\u6301\u9ed1\u540d\u5355\u68c0\u67e5\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9690\u79c1\u4fdd\u62a4\u7279\u6027\u3002\u901a\u8fc7\u5ea6\u91cf\u7a7a\u95f4\u5d4c\u5165\u548c\u805a\u7c7b\u68c0\u67e5\u7684\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u9ed1\u540d\u5355OPRF\u534f\u8bae\uff0c\u4e3a\u5bc6\u7801\u5b89\u5168\u548c\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u7b49\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.15865", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15865", "abs": "https://arxiv.org/abs/2507.15865", "authors": ["Shai Shalev-Shwartz", "Amnon Shashua"], "title": "From Reasoning to Super-Intelligence: A Search-Theoretic Perspective", "comment": null, "summary": "Chain-of-Thought (CoT) reasoning has emerged as a powerful tool for enhancing\nthe problem-solving capabilities of large language models (LLMs). However, the\ntheoretical foundations of learning from CoT data remain underdeveloped, and\nexisting approaches -- such as Supervised Fine-Tuning (SFT), Reinforcement\nLearning (RL), Tree-of-Thoughts (ToT), and Monte Carlo Tree Search (MCTS) --\noften fail on complex reasoning tasks. In this work, we identify core obstacles\nthat hinder effective CoT learning, including distribution drift, lack of\nembedded search, and exponential inference costs. We introduce the Diligent\nLearner, a new learning paradigm that explicitly models reasoning as a\ndepth-first search guided by a validator and supports backtracking upon\nfailure. Under two mild and realistic assumptions, we prove that the Diligent\nLearner can efficiently learn from CoT data while existing methods fail to do\nso. This framework offers a path toward building scalable and reliable\nreasoning systems trained on naturally occurring, incomplete data -- paving the\nway for the development of Large Reasoning Models (LRMs) with robust,\ninterpretable problem-solving abilities.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\"\u52e4\u594b\u5b66\u4e60\u8005\"(Diligent Learner)\u8fd9\u4e00\u65b0\u7684\u5b66\u4e60\u8303\u5f0f\uff0c\u901a\u8fc7\u5c06\u63a8\u7406\u5efa\u6a21\u4e3a\u7531\u9a8c\u8bc1\u5668\u5f15\u5bfc\u7684\u6df1\u5ea6\u4f18\u5148\u641c\u7d22\u5e76\u652f\u6301\u56de\u6eaf\u6765\u89e3\u51b3\u73b0\u6709\u601d\u7ef4\u94fe\u5b66\u4e60\u65b9\u6cd5\u7684\u6838\u5fc3\u969c\u788d\uff0c\u4e3a\u6784\u5efa\u5927\u89c4\u6a21\u63a8\u7406\u6a21\u578b\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u7684\u601d\u7ef4\u94fe(CoT)\u5b66\u4e60\u65b9\u6cd5\u5982\u76d1\u7763\u5fae\u8c03\u3001\u5f3a\u5316\u5b66\u4e60\u3001\u601d\u7ef4\u6811\u7b49\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u7ecf\u5e38\u5931\u8d25\uff0c\u7f3a\u4e4f\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840\uff0c\u4e14\u5b58\u5728\u5206\u5e03\u6f02\u79fb\u3001\u7f3a\u4e4f\u5d4c\u5165\u5f0f\u641c\u7d22\u548c\u6307\u6570\u7ea7\u63a8\u7406\u6210\u672c\u7b49\u6838\u5fc3\u969c\u788d\u3002", "method": "\u63d0\u51fa\"\u52e4\u594b\u5b66\u4e60\u8005\"\u5b66\u4e60\u8303\u5f0f\uff0c\u5c06\u63a8\u7406\u663e\u5f0f\u5efa\u6a21\u4e3a\u7531\u9a8c\u8bc1\u5668\u5f15\u5bfc\u7684\u6df1\u5ea6\u4f18\u5148\u641c\u7d22\u8fc7\u7a0b\uff0c\u652f\u6301\u5728\u5931\u8d25\u65f6\u8fdb\u884c\u56de\u6eaf\uff0c\u80fd\u591f\u4ece\u81ea\u7136\u51fa\u73b0\u7684\u4e0d\u5b8c\u6574CoT\u6570\u636e\u4e2d\u9ad8\u6548\u5b66\u4e60\u3002", "result": "\u5728\u4e24\u4e2a\u6e29\u548c\u4e14\u73b0\u5b9e\u7684\u5047\u8bbe\u6761\u4ef6\u4e0b\uff0c\u7406\u8bba\u8bc1\u660e\u4e86\u52e4\u594b\u5b66\u4e60\u8005\u80fd\u591f\u4eceCoT\u6570\u636e\u4e2d\u9ad8\u6548\u5b66\u4e60\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u505a\u5230\u8fd9\u4e00\u70b9\uff0c\u4e3a\u6784\u5efa\u53ef\u6269\u5c55\u4e14\u53ef\u9760\u7684\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u8def\u5f84\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5f00\u53d1\u5177\u6709\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u7684\u5927\u89c4\u6a21\u63a8\u7406\u6a21\u578b(LRMs)\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u80fd\u591f\u5728\u81ea\u7136\u51fa\u73b0\u7684\u4e0d\u5b8c\u6574\u6570\u636e\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u89e3\u51b3\u4e86\u73b0\u6709CoT\u5b66\u4e60\u65b9\u6cd5\u7684\u6839\u672c\u6027\u95ee\u9898\u3002"}}
{"id": "2507.16060", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.16060", "abs": "https://arxiv.org/abs/2507.16060", "authors": ["Eyasu Getahun Chekole", "Howard Halim", "Jianying Zhou"], "title": "MFAz: Historical Access Based Multi-Factor Authorization", "comment": null, "summary": "Unauthorized access remains one of the critical security challenges in the\nrealm of cybersecurity. With the increasing sophistication of attack\ntechniques, the threat of unauthorized access is no longer confined to the\nconventional ones, such as exploiting weak access control policies. Instead,\nadvanced exploitation strategies, such as session hijacking-based attacks, are\nbecoming increasingly prevalent, posing serious security concerns. Session\nhijacking enables attackers to take over an already established session between\nlegitimate peers in a stealthy manner, thereby gaining unauthorized access to\nprivate resources. Unfortunately, traditional access control mechanisms, such\nas static access control policies, are insufficient to prevent session\nhijacking or other advanced exploitation techniques. In this work, we propose a\nnew multi-factor authorization (MFAz) scheme that proactively mitigates\nunauthorized access attempts both conventional and advanced unauthorized access\nattacks. The proposed scheme employs fine-grained access control rules (ARs)\nand verification points (VPs) that are systematically generated from\nhistorically granted accesses as the first and second authorization factors,\nrespectively. As a proof-of-concept, we implement the scheme using different\ntechniques. We leverage bloom filter to achieve runtime and storage efficiency,\nand blockchain to make authorization decisions in a temper-proof and\ndecentralized manner. To the best of our knowledge, this is the first formal\nintroduction of a multi-factor authorization scheme, which is orthogonal to the\nmulti-factor authentication (MFA) schemes. The effectiveness of our proposed\nscheme is experimentally evaluated using a smart-city testbed involving\ndifferent devices with varying computational capacities. The experimental\nresults reveal high effectiveness of the scheme both in security and\nperformance guarantees.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u56e0\u7d20\u6388\u6743(MFAz)\u65b9\u6848\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u8bbf\u95ee\u63a7\u5236\u89c4\u5219\u548c\u9a8c\u8bc1\u70b9\u6765\u4e3b\u52a8\u9632\u5fa1\u4f20\u7edf\u548c\u9ad8\u7ea7\u672a\u6388\u6743\u8bbf\u95ee\u653b\u51fb\uff0c\u7279\u522b\u662f\u4f1a\u8bdd\u52ab\u6301\u653b\u51fb\u3002\u8be5\u65b9\u6848\u4f7f\u7528\u5e03\u9686\u8fc7\u6ee4\u5668\u63d0\u9ad8\u6548\u7387\uff0c\u91c7\u7528\u533a\u5757\u94fe\u786e\u4fdd\u6388\u6743\u51b3\u7b56\u7684\u9632\u7be1\u6539\u6027\u548c\u53bb\u4e2d\u5fc3\u5316\u3002", "motivation": "\u4f20\u7edf\u8bbf\u95ee\u63a7\u5236\u673a\u5236\uff08\u5982\u9759\u6001\u8bbf\u95ee\u63a7\u5236\u7b56\u7565\uff09\u65e0\u6cd5\u6709\u6548\u9632\u5fa1\u4f1a\u8bdd\u52ab\u6301\u7b49\u9ad8\u7ea7\u653b\u51fb\u6280\u672f\u3002\u968f\u7740\u653b\u51fb\u624b\u6bb5\u65e5\u76ca\u590d\u6742\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u6388\u6743\u673a\u5236\u6765\u4e3b\u52a8\u7f13\u89e3\u4f20\u7edf\u548c\u9ad8\u7ea7\u672a\u6388\u6743\u8bbf\u95ee\u5a01\u80c1\uff0c\u4fdd\u62a4\u79c1\u6709\u8d44\u6e90\u514d\u53d7\u9690\u853d\u7684\u4f1a\u8bdd\u63a5\u7ba1\u653b\u51fb\u3002", "method": "\u63d0\u51fa\u591a\u56e0\u7d20\u6388\u6743(MFAz)\u65b9\u6848\uff0c\u91c7\u7528\u4e24\u4e2a\u6388\u6743\u56e0\u5b50\uff1a1)\u4ece\u5386\u53f2\u6388\u6743\u8bbf\u95ee\u4e2d\u7cfb\u7edf\u751f\u6210\u7684\u7ec6\u7c92\u5ea6\u8bbf\u95ee\u63a7\u5236\u89c4\u5219(ARs)\u4f5c\u4e3a\u7b2c\u4e00\u56e0\u5b50\uff1b2)\u9a8c\u8bc1\u70b9(VPs)\u4f5c\u4e3a\u7b2c\u4e8c\u56e0\u5b50\u3002\u4f7f\u7528\u5e03\u9686\u8fc7\u6ee4\u5668\u63d0\u9ad8\u8fd0\u884c\u65f6\u548c\u5b58\u50a8\u6548\u7387\uff0c\u5229\u7528\u533a\u5757\u94fe\u6280\u672f\u5b9e\u73b0\u9632\u7be1\u6539\u548c\u53bb\u4e2d\u5fc3\u5316\u7684\u6388\u6743\u51b3\u7b56\u3002", "result": "\u5728\u667a\u6167\u57ce\u5e02\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u5bf9\u4e0d\u540c\u8ba1\u7b97\u80fd\u529b\u7684\u8bbe\u5907\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6848\u5728\u5b89\u5168\u6027\u548c\u6027\u80fd\u4fdd\u8bc1\u65b9\u9762\u90fd\u5177\u6709\u5f88\u9ad8\u7684\u6709\u6548\u6027\u3002\u8fd9\u662f\u9996\u6b21\u6b63\u5f0f\u5f15\u5165\u4e0e\u591a\u56e0\u7d20\u8ba4\u8bc1(MFA)\u6b63\u4ea4\u7684\u591a\u56e0\u7d20\u6388\u6743\u65b9\u6848\u3002", "conclusion": "\u591a\u56e0\u7d20\u6388\u6743\u65b9\u6848\u80fd\u591f\u6709\u6548\u9632\u5fa1\u4f20\u7edf\u548c\u9ad8\u7ea7\u672a\u6388\u6743\u8bbf\u95ee\u653b\u51fb\uff0c\u7279\u522b\u662f\u4f1a\u8bdd\u52ab\u6301\u653b\u51fb\u3002\u901a\u8fc7\u7ed3\u5408\u7ec6\u7c92\u5ea6\u8bbf\u95ee\u63a7\u5236\u89c4\u5219\u548c\u9a8c\u8bc1\u70b9\uff0c\u4ee5\u53ca\u5229\u7528\u5e03\u9686\u8fc7\u6ee4\u5668\u548c\u533a\u5757\u94fe\u6280\u672f\uff0c\u8be5\u65b9\u6848\u5728\u4fdd\u8bc1\u5b89\u5168\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u826f\u597d\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2507.15866", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15866", "abs": "https://arxiv.org/abs/2507.15866", "authors": ["Marek Vlk", "Premysl Sucha", "Jaroslaw Rudy", "Radoslaw Idzikowski"], "title": "Purchase and Production Optimization in a Meat Processing Plant", "comment": "25 pages, 5 figures", "summary": "The food production industry, especially the meat production sector, faces\nmany challenges that have even escalated due to the recent outbreak of the\nenergy crisis in the European Union. Therefore, efficient use of input\nmaterials is an essential aspect affecting the profit of such companies. This\npaper addresses an optimization problem concerning the purchase and subsequent\nmaterial processing we solved for a meat processing company. Unlike the\nmajority of existing papers, we do not concentrate on how this problem concerns\nsupply chain management, but we focus purely on the production stage. The\nproblem involves the concept of alternative ways of material processing, stock\nof material with different expiration dates, and extra constraints widely\nneglected in the current literature, namely, the minimum order quantity and the\nminimum percentage in alternatives. We prove that each of these two constraints\nmakes the problem \\mbox{$\\mathcal{NP}$-hard}, and hence we design a simple\niterative approach based on integer linear programming that allows us to solve\nreal-life instances even using an open-source integer linear programming\nsolver. Another advantage of this approach is that it mitigates numerical\nissues, caused by the extensive range of data values, we experienced with a\ncommercial solver. The results obtained using real data from the meat\nprocessing company showed that our algorithm can find the optimum solution in a\nfew seconds for all considered use cases.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u8089\u7c7b\u52a0\u5de5\u4f01\u4e1a\u7684\u539f\u6599\u91c7\u8d2d\u548c\u5904\u7406\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u6574\u6570\u7ebf\u6027\u89c4\u5212\u7684\u8fed\u4ee3\u7b97\u6cd5\uff0c\u80fd\u591f\u5728\u51e0\u79d2\u5185\u627e\u5230\u6700\u4f18\u89e3\u3002", "motivation": "\u98df\u54c1\u751f\u4ea7\u884c\u4e1a\uff0c\u7279\u522b\u662f\u8089\u7c7b\u751f\u4ea7\u90e8\u95e8\u9762\u4e34\u8bf8\u591a\u6311\u6218\uff0c\u6b27\u76df\u80fd\u6e90\u5371\u673a\u4f7f\u60c5\u51b5\u6076\u5316\u3002\u9ad8\u6548\u5229\u7528\u8f93\u5165\u6750\u6599\u5bf9\u4f01\u4e1a\u76c8\u5229\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u6587\u732e\u591a\u5173\u6ce8\u4f9b\u5e94\u94fe\u7ba1\u7406\uff0c\u7f3a\u4e4f\u5bf9\u751f\u4ea7\u9636\u6bb5\u7684\u6df1\u5165\u7814\u7a76\uff0c\u4e14\u5ffd\u7565\u4e86\u6700\u5c0f\u8ba2\u8d2d\u91cf\u548c\u66ff\u4ee3\u54c1\u6700\u5c0f\u767e\u5206\u6bd4\u7b49\u91cd\u8981\u7ea6\u675f\u6761\u4ef6\u3002", "method": "\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u6574\u6570\u7ebf\u6027\u89c4\u5212\u7684\u7b80\u5355\u8fed\u4ee3\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u8003\u8651\u4e86\u6750\u6599\u5904\u7406\u7684\u66ff\u4ee3\u65b9\u5f0f\u3001\u4e0d\u540c\u5230\u671f\u65e5\u7684\u5e93\u5b58\u6750\u6599\uff0c\u4ee5\u53ca\u6700\u5c0f\u8ba2\u8d2d\u91cf\u548c\u66ff\u4ee3\u54c1\u6700\u5c0f\u767e\u5206\u6bd4\u7b49\u7ea6\u675f\u6761\u4ef6\u3002\u8bc1\u660e\u4e86\u8fd9\u4e24\u4e2a\u7ea6\u675f\u4f7f\u95ee\u9898\u53d8\u4e3aNP\u96be\u95ee\u9898\uff0c\u5e76\u4f7f\u7528\u5f00\u6e90\u6574\u6570\u7ebf\u6027\u89c4\u5212\u6c42\u89e3\u5668\u6765\u89e3\u51b3\u5b9e\u9645\u95ee\u9898\u3002", "result": "\u4f7f\u7528\u8089\u7c7b\u52a0\u5de5\u516c\u53f8\u7684\u771f\u5b9e\u6570\u636e\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u6709\u6548\u6027\u3002\u7b97\u6cd5\u80fd\u591f\u5728\u51e0\u79d2\u949f\u5185\u4e3a\u6240\u6709\u8003\u8651\u7684\u7528\u4f8b\u627e\u5230\u6700\u4f18\u89e3\u3002\u8be5\u65b9\u6cd5\u8fd8\u7f13\u89e3\u4e86\u7531\u4e8e\u6570\u636e\u503c\u8303\u56f4\u5e7f\u6cdb\u800c\u5728\u5546\u4e1a\u6c42\u89e3\u5668\u4e2d\u9047\u5230\u7684\u6570\u503c\u95ee\u9898\u3002", "conclusion": "\u63d0\u51fa\u7684\u8fed\u4ee3\u6574\u6570\u7ebf\u6027\u89c4\u5212\u65b9\u6cd5\u80fd\u591f\u9ad8\u6548\u89e3\u51b3\u8089\u7c7b\u52a0\u5de5\u4f01\u4e1a\u7684\u539f\u6599\u91c7\u8d2d\u548c\u5904\u7406\u4f18\u5316\u95ee\u9898\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u4f01\u4e1a\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u4f18\u5316\u5de5\u5177\u3002"}}
{"id": "2507.16134", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2507.16134", "abs": "https://arxiv.org/abs/2507.16134", "authors": ["Baofu Han", "Bing Li", "Yining Qi", "Raja Jurdak", "Kaibin Huang", "Chau Yuen"], "title": "DP2Guard: A Lightweight and Byzantine-Robust Privacy-Preserving Federated Learning Scheme for Industrial IoT", "comment": null, "summary": "Privacy-Preserving Federated Learning (PPFL) has emerged as a secure\ndistributed Machine Learning (ML) paradigm that aggregates locally trained\ngradients without exposing raw data. To defend against model poisoning threats,\nseveral robustness-enhanced PPFL schemes have been proposed by integrating\nanomaly detection. Nevertheless, they still face two major challenges: (1) the\nreliance on heavyweight encryption techniques results in substantial\ncommunication and computation overhead; and (2) single-strategy defense\nmechanisms often fail to provide sufficient robustness against adaptive\nadversaries. To overcome these challenges, we propose DP2Guard, a lightweight\nPPFL framework that enhances both privacy and robustness. DP2Guard leverages a\nlightweight gradient masking mechanism to replace costly cryptographic\noperations while ensuring the privacy of local gradients. A hybrid defense\nstrategy is proposed, which extracts gradient features using singular value\ndecomposition and cosine similarity, and applies a clustering algorithm to\neffectively identify malicious gradients. Additionally, DP2Guard adopts a trust\nscore-based adaptive aggregation scheme that adjusts client weights according\nto historical behavior, while blockchain records aggregated results and trust\nscores to ensure tamper-proof and auditable training. Extensive experiments\nconducted on two public datasets demonstrate that DP2Guard effectively defends\nagainst four advanced poisoning attacks while ensuring privacy with reduced\ncommunication and computation costs.", "AI": {"tldr": "\u63d0\u51fa\u4e86DP2Guard\uff0c\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u9690\u79c1\u4fdd\u62a4\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u68af\u5ea6\u63a9\u7801\u673a\u5236\u66ff\u4ee3\u6602\u8d35\u7684\u52a0\u5bc6\u64cd\u4f5c\uff0c\u91c7\u7528\u6df7\u5408\u9632\u5fa1\u7b56\u7565\u8bc6\u522b\u6076\u610f\u68af\u5ea6\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8e\u4fe1\u4efb\u5206\u6570\u7684\u81ea\u9002\u5e94\u805a\u5408\u65b9\u6848\u548c\u533a\u5757\u94fe\u8bb0\u5f55\u6765\u589e\u5f3a\u9690\u79c1\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u9690\u79c1\u4fdd\u62a4\u8054\u90a6\u5b66\u4e60\u65b9\u6848\u9762\u4e34\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1a(1)\u4f9d\u8d56\u91cd\u91cf\u7ea7\u52a0\u5bc6\u6280\u672f\u5bfc\u81f4\u5927\u91cf\u901a\u4fe1\u548c\u8ba1\u7b97\u5f00\u9500\uff1b(2)\u5355\u4e00\u7b56\u7565\u9632\u5fa1\u673a\u5236\u5f80\u5f80\u65e0\u6cd5\u5bf9\u6297\u81ea\u9002\u5e94\u5bf9\u624b\uff0c\u63d0\u4f9b\u8db3\u591f\u7684\u9c81\u68d2\u6027\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u62a4\u9690\u79c1\u53c8\u80fd\u589e\u5f3a\u9c81\u68d2\u6027\u7684\u8f7b\u91cf\u7ea7\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faDP2Guard\u6846\u67b6\uff0c\u5305\u542b\uff1a(1)\u8f7b\u91cf\u7ea7\u68af\u5ea6\u63a9\u7801\u673a\u5236\u66ff\u4ee3\u6602\u8d35\u7684\u5bc6\u7801\u5b66\u64cd\u4f5c\uff1b(2)\u6df7\u5408\u9632\u5fa1\u7b56\u7565\uff0c\u4f7f\u7528\u5947\u5f02\u503c\u5206\u89e3\u548c\u4f59\u5f26\u76f8\u4f3c\u5ea6\u63d0\u53d6\u68af\u5ea6\u7279\u5f81\uff0c\u5e94\u7528\u805a\u7c7b\u7b97\u6cd5\u8bc6\u522b\u6076\u610f\u68af\u5ea6\uff1b(3)\u57fa\u4e8e\u4fe1\u4efb\u5206\u6570\u7684\u81ea\u9002\u5e94\u805a\u5408\u65b9\u6848\uff0c\u6839\u636e\u5386\u53f2\u884c\u4e3a\u8c03\u6574\u5ba2\u6237\u7aef\u6743\u91cd\uff1b(4)\u533a\u5757\u94fe\u8bb0\u5f55\u805a\u5408\u7ed3\u679c\u548c\u4fe1\u4efb\u5206\u6570\uff0c\u786e\u4fdd\u9632\u7be1\u6539\u548c\u53ef\u5ba1\u8ba1\u7684\u8bad\u7ec3\u3002", "result": "\u5728\u4e24\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cDP2Guard\u80fd\u591f\u6709\u6548\u9632\u5fa1\u56db\u79cd\u5148\u8fdb\u7684\u6295\u6bd2\u653b\u51fb\uff0c\u540c\u65f6\u5728\u964d\u4f4e\u901a\u4fe1\u548c\u8ba1\u7b97\u6210\u672c\u7684\u60c5\u51b5\u4e0b\u786e\u4fdd\u9690\u79c1\u4fdd\u62a4\u3002", "conclusion": "DP2Guard\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u9690\u79c1\u4fdd\u62a4\u8054\u90a6\u5b66\u4e60\u65b9\u6848\u7684\u4e3b\u8981\u6311\u6218\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u8bbe\u8ba1\u548c\u6df7\u5408\u9632\u5fa1\u7b56\u7565\uff0c\u5728\u4fdd\u8bc1\u9690\u79c1\u7684\u540c\u65f6\u63d0\u4f9b\u4e86\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u4e86\u7cfb\u7edf\u5f00\u9500\u3002"}}
{"id": "2507.15874", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.15874", "abs": "https://arxiv.org/abs/2507.15874", "authors": ["Yin Wu", "Daniel Slieter", "Vivek Subramanian", "Ahmed Abouelazm", "Robin Bohn", "J. Marius Z\u00f6llner"], "title": "Why Braking? Scenario Extraction and Reasoning Utilizing LLM", "comment": null, "summary": "The growing number of ADAS-equipped vehicles has led to a dramatic increase\nin driving data, yet most of them capture routine driving behavior. Identifying\nand understanding safety-critical corner cases within this vast dataset remains\na significant challenge. Braking events are particularly indicative of\npotentially hazardous situations, motivating the central question of our\nresearch: Why does a vehicle brake? Existing approaches primarily rely on\nrule-based heuristics to retrieve target scenarios using predefined condition\nfilters. While effective in simple environments such as highways, these methods\nlack generalization in complex urban settings. In this paper, we propose a\nnovel framework that leverages Large Language Model (LLM) for scenario\nunderstanding and reasoning. Our method bridges the gap between low-level\nnumerical signals and natural language descriptions, enabling LLM to interpret\nand classify driving scenarios. We propose a dual-path scenario retrieval that\nsupports both category-based search for known scenarios and embedding-based\nretrieval for unknown Out-of-Distribution (OOD) scenarios. To facilitate\nevaluation, we curate scenario annotations on the Argoverse 2 Sensor Dataset.\nExperimental results show that our method outperforms rule-based baselines and\ngeneralizes well to OOD scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u7684\u9a7e\u9a76\u573a\u666f\u7406\u89e3\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u8f66\u8f86\u5236\u52a8\u884c\u4e3a\u548c\u8bc6\u522b\u5b89\u5168\u5173\u952e\u573a\u666f\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u5728\u590d\u6742\u57ce\u5e02\u73af\u5883\u4e2d\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u968f\u7740ADAS\u8f66\u8f86\u6570\u91cf\u589e\u957f\uff0c\u9a7e\u9a76\u6570\u636e\u6025\u5267\u589e\u52a0\uff0c\u4f46\u5927\u591a\u6570\u6570\u636e\u53cd\u6620\u7684\u662f\u5e38\u89c4\u9a7e\u9a76\u884c\u4e3a\u3002\u5728\u8fd9\u4e9b\u6d77\u91cf\u6570\u636e\u4e2d\u8bc6\u522b\u548c\u7406\u89e3\u5b89\u5168\u5173\u952e\u7684\u6781\u7aef\u6848\u4f8b\u4ecd\u7136\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002\u5236\u52a8\u4e8b\u4ef6\u7279\u522b\u80fd\u591f\u6307\u793a\u6f5c\u5728\u7684\u5371\u9669\u60c5\u51b5\uff0c\u56e0\u6b64\u7814\u7a76\u7684\u6838\u5fc3\u95ee\u9898\u662f\uff1a\u8f66\u8f86\u4e3a\u4ec0\u4e48\u5236\u52a8\uff1f\u73b0\u6709\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u867d\u7136\u5728\u9ad8\u901f\u516c\u8def\u7b49\u7b80\u5355\u73af\u5883\u4e2d\u6709\u6548\uff0c\u4f46\u5728\u590d\u6742\u57ce\u5e02\u73af\u5883\u4e2d\u7f3a\u4e4f\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u573a\u666f\u7406\u89e3\u548c\u63a8\u7406\u3002\u8be5\u65b9\u6cd5\u5728\u4f4e\u7ea7\u6570\u503c\u4fe1\u53f7\u548c\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u4e4b\u95f4\u5efa\u7acb\u6865\u6881\uff0c\u4f7fLLM\u80fd\u591f\u89e3\u91ca\u548c\u5206\u7c7b\u9a7e\u9a76\u573a\u666f\u3002\u63d0\u51fa\u4e86\u53cc\u8def\u5f84\u573a\u666f\u68c0\u7d22\u673a\u5236\uff0c\u652f\u6301\u57fa\u4e8e\u7c7b\u522b\u7684\u5df2\u77e5\u573a\u666f\u641c\u7d22\u548c\u57fa\u4e8e\u5d4c\u5165\u7684\u672a\u77e5\u5206\u5e03\u5916(OOD)\u573a\u666f\u68c0\u7d22\u3002", "result": "\u5728Argoverse 2\u4f20\u611f\u5668\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u573a\u666f\u6807\u6ce8\u548c\u8bc4\u4f30\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u57fa\u4e8e\u89c4\u5219\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u4e14\u5728\u5206\u5e03\u5916\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u57fa\u4e8eLLM\u7684\u9a7e\u9a76\u573a\u666f\u7406\u89e3\u6846\u67b6\u80fd\u591f\u6709\u6548\u5206\u6790\u8f66\u8f86\u5236\u52a8\u884c\u4e3a\uff0c\u8bc6\u522b\u5b89\u5168\u5173\u952e\u573a\u666f\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u57ce\u5e02\u73af\u5883\u548c\u672a\u77e5\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2507.15887", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15887", "abs": "https://arxiv.org/abs/2507.15887", "authors": ["Ori Press", "Brandon Amos", "Haoyu Zhao", "Yikai Wu", "Samuel K. Ainsworth", "Dominik Krupke", "Patrick Kidger", "Touqir Sajed", "Bartolomeo Stellato", "Jisun Park", "Nathanael Bosch", "Eli Meril", "Albert Steppi", "Arman Zharmagambetov", "Fangzhao Zhang", "David Perez-Pineiro", "Alberto Mercurio", "Ni Zhan", "Talor Abramovich", "Kilian Lieret", "Hanlin Zhang", "Shirley Huang", "Matthias Bethge", "Ofir Press"], "title": "AlgoTune: Can Language Models Speed Up General-Purpose Numerical Programs?", "comment": null, "summary": "Despite progress in language model (LM) capabilities, evaluations have thus\nfar focused on models' performance on tasks that humans have previously solved,\nincluding in programming (Jimenez et al., 2024) and mathematics (Glazer et al.,\n2024). We therefore propose testing models' ability to design and implement\nalgorithms in an open-ended benchmark: We task LMs with writing code that\nefficiently solves computationally challenging problems in computer science,\nphysics, and mathematics. Our AlgoTune benchmark consists of 155 coding tasks\ncollected from domain experts and a framework for validating and timing\nLM-synthesized solution code, which is compared to reference implementations\nfrom popular open-source packages. In addition, we develop a baseline LM agent,\nAlgoTuner, and evaluate its performance across a suite of frontier models.\nAlgoTuner achieves an average 1.72x speedup against our reference solvers,\nwhich use libraries such as SciPy, sk-learn and CVXPY. However, we find that\ncurrent models fail to discover algorithmic innovations, instead preferring\nsurface-level optimizations. We hope that AlgoTune catalyzes the development of\nLM agents exhibiting creative problem solving beyond state-of-the-art human\nperformance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86AlgoTune\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u8bbe\u8ba1\u548c\u5b9e\u73b0\u7b97\u6cd5\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u867d\u80fd\u5b9e\u73b01.72\u500d\u52a0\u901f\u4f46\u7f3a\u4e4f\u7b97\u6cd5\u521b\u65b0\u80fd\u529b", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u4e3b\u8981\u96c6\u4e2d\u5728\u4eba\u7c7b\u5df2\u89e3\u51b3\u7684\u4efb\u52a1\u4e0a\uff0c\u7f3a\u4e4f\u5bf9\u6a21\u578b\u5728\u5f00\u653e\u6027\u7b97\u6cd5\u8bbe\u8ba1\u548c\u5b9e\u73b0\u65b9\u9762\u80fd\u529b\u7684\u6d4b\u8bd5\uff0c\u9700\u8981\u8bc4\u4f30\u6a21\u578b\u662f\u5426\u80fd\u591f\u8d85\u8d8a\u73b0\u6709\u4eba\u7c7b\u8868\u73b0\u5c55\u73b0\u521b\u9020\u6027\u95ee\u9898\u89e3\u51b3\u80fd\u529b", "method": "\u6784\u5efa\u5305\u542b155\u4e2a\u7f16\u7a0b\u4efb\u52a1\u7684AlgoTune\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4efb\u52a1\u6765\u81ea\u8ba1\u7b97\u673a\u79d1\u5b66\u3001\u7269\u7406\u5b66\u548c\u6570\u5b66\u9886\u57df\u7684\u4e13\u5bb6\uff1b\u5efa\u7acb\u9a8c\u8bc1\u548c\u8ba1\u65f6\u6846\u67b6\u6765\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u89e3\u51b3\u65b9\u6848\u4ee3\u7801\uff1b\u5f00\u53d1\u57fa\u7ebf\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53AlgoTuner\uff1b\u4e0e\u6d41\u884c\u5f00\u6e90\u5305\uff08\u5982SciPy\u3001sk-learn\u3001CVXPY\uff09\u7684\u53c2\u8003\u5b9e\u73b0\u8fdb\u884c\u6027\u80fd\u5bf9\u6bd4", "result": "AlgoTuner\u5728\u53c2\u8003\u6c42\u89e3\u5668\u4e0a\u5e73\u5747\u5b9e\u73b0\u4e861.72\u500d\u7684\u52a0\u901f\u6548\u679c\uff1b\u4f46\u7814\u7a76\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u65e0\u6cd5\u53d1\u73b0\u7b97\u6cd5\u521b\u65b0\uff0c\u66f4\u503e\u5411\u4e8e\u8fdb\u884c\u8868\u9762\u5c42\u6b21\u7684\u4f18\u5316", "conclusion": "\u867d\u7136\u8bed\u8a00\u6a21\u578b\u5728\u7b97\u6cd5\u5b9e\u73b0\u4e0a\u8868\u73b0\u51fa\u4e00\u5b9a\u7684\u4f18\u5316\u80fd\u529b\uff0c\u4f46\u5728\u7b97\u6cd5\u521b\u65b0\u65b9\u9762\u4ecd\u6709\u4e0d\u8db3\uff1b\u5e0c\u671bAlgoTune\u57fa\u51c6\u80fd\u591f\u63a8\u52a8\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u5728\u521b\u9020\u6027\u95ee\u9898\u89e3\u51b3\u65b9\u9762\u7684\u53d1\u5c55\uff0c\u4f7f\u5176\u8d85\u8d8a\u5f53\u524d\u4eba\u7c7b\u6700\u5148\u8fdb\u8868\u73b0"}}
{"id": "2507.16164", "categories": ["cs.CR", "cs.AI", "cs.LG", "I.2.7; I.2.6; I.2.3; D.4.6"], "pdf": "https://arxiv.org/pdf/2507.16164", "abs": "https://arxiv.org/abs/2507.16164", "authors": ["Eldor Abdukhamidov", "Tamer Abuhmed", "Joanna C. S. Santos", "Mohammed Abuhamad"], "title": "Attacking interpretable NLP systems", "comment": null, "summary": "Studies have shown that machine learning systems are vulnerable to\nadversarial examples in theory and practice. Where previous attacks have\nfocused mainly on visual models that exploit the difference between human and\nmachine perception, text-based models have also fallen victim to these attacks.\nHowever, these attacks often fail to maintain the semantic meaning of the text\nand similarity. This paper introduces AdvChar, a black-box attack on\nInterpretable Natural Language Processing Systems, designed to mislead the\nclassifier while keeping the interpretation similar to benign inputs, thus\nexploiting trust in system transparency. AdvChar achieves this by making less\nnoticeable modifications to text input, forcing the deep learning classifier to\nmake incorrect predictions and preserve the original interpretation. We use an\ninterpretation-focused scoring approach to determine the most critical tokens\nthat, when changed, can cause the classifier to misclassify the input. We apply\nsimple character-level modifications to measure the importance of tokens,\nminimizing the difference between the original and new text while generating\nadversarial interpretations similar to benign ones. We thoroughly evaluated\nAdvChar by testing it against seven NLP models and three interpretation models\nusing benchmark datasets for the classification task. Our experiments show that\nAdvChar can significantly reduce the prediction accuracy of current deep\nlearning models by altering just two characters on average in input samples.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86AdvChar\uff0c\u4e00\u79cd\u9488\u5bf9\u53ef\u89e3\u91ca\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7cfb\u7edf\u7684\u9ed1\u76d2\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5fae\u5c0f\u7684\u5b57\u7b26\u7ea7\u4fee\u6539\u6765\u8bef\u5bfc\u5206\u7c7b\u5668\uff0c\u540c\u65f6\u4fdd\u6301\u6587\u672c\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u548c\u89e3\u91ca\u6027", "motivation": "\u73b0\u6709\u7684\u6587\u672c\u5bf9\u6297\u653b\u51fb\u5f80\u5f80\u65e0\u6cd5\u4fdd\u6301\u6587\u672c\u7684\u8bed\u4e49\u542b\u4e49\u548c\u76f8\u4f3c\u6027\uff0c\u4e14\u9488\u5bf9\u53ef\u89e3\u91caNLP\u7cfb\u7edf\u7684\u653b\u51fb\u7814\u7a76\u4e0d\u8db3\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5728\u4fdd\u6301\u89e3\u91ca\u76f8\u4f3c\u6027\u7684\u540c\u65f6\u8bef\u5bfc\u5206\u7c7b\u5668\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u4ee5\u5229\u7528\u7cfb\u7edf\u900f\u660e\u6027\u4e2d\u7684\u4fe1\u4efb\u6f0f\u6d1e", "method": "\u63d0\u51faAdvChar\u9ed1\u76d2\u653b\u51fb\u65b9\u6cd5\uff1a1) \u4f7f\u7528\u57fa\u4e8e\u89e3\u91ca\u7684\u8bc4\u5206\u65b9\u6cd5\u786e\u5b9a\u6700\u5173\u952e\u7684\u6807\u8bb0\uff1b2) \u5bf9\u8fd9\u4e9b\u5173\u952e\u6807\u8bb0\u8fdb\u884c\u7b80\u5355\u7684\u5b57\u7b26\u7ea7\u4fee\u6539\uff1b3) \u6700\u5c0f\u5316\u539f\u59cb\u6587\u672c\u4e0e\u4fee\u6539\u540e\u6587\u672c\u7684\u5dee\u5f02\uff1b4) \u751f\u6210\u4e0e\u826f\u6027\u6837\u672c\u76f8\u4f3c\u7684\u5bf9\u6297\u6027\u89e3\u91ca", "result": "\u57287\u4e2aNLP\u6a21\u578b\u548c3\u4e2a\u89e3\u91ca\u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\uff0c\u5b9e\u9a8c\u8868\u660eAdvChar\u5e73\u5747\u53ea\u9700\u4fee\u6539\u8f93\u5165\u6837\u672c\u4e2d\u76842\u4e2a\u5b57\u7b26\u5c31\u80fd\u663e\u8457\u964d\u4f4e\u5f53\u524d\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u9884\u6d4b\u51c6\u786e\u7387", "conclusion": "AdvChar\u6210\u529f\u5b9e\u73b0\u4e86\u5bf9\u53ef\u89e3\u91caNLP\u7cfb\u7edf\u7684\u6709\u6548\u653b\u51fb\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u6587\u672c\u8bed\u4e49\u548c\u89e3\u91ca\u76f8\u4f3c\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u901a\u8fc7\u6781\u5c11\u7684\u5b57\u7b26\u4fee\u6539\u8bef\u5bfc\u5206\u7c7b\u5668\uff0c\u63ed\u793a\u4e86\u53ef\u89e3\u91ca\u7cfb\u7edf\u4e2d\u5b58\u5728\u7684\u5b89\u5168\u6f0f\u6d1e"}}
{"id": "2507.15875", "categories": ["cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2507.15875", "abs": "https://arxiv.org/abs/2507.15875", "authors": ["Jerry Li", "Timothy Oh", "Joseph Hoang", "Vardhit Veeramachaneni"], "title": "Differential Multimodal Transformers", "comment": null, "summary": "Small language models have gained significant popularity due to their\nefficiency and growing capabilities. However, incorporating additional\nmodalities, such as vision, can exacerbate the challenge of limited context\nwindows by introducing noise. Recent studies have highlighted that Transformer\nattention mechanisms often disproportionately focus on irrelevant contexts. In\nthis work, we extend the Differential Attention mechanism, originally designed\nfor text-only models, to the text-vision model PaliGemma. Our aim is to\nevaluate its ability to mitigate noisy information retrieval and reduce\nhallucinations. To this end, we fine-tuned the PaliGemma 3B model using LoRA,\nincorporating Differential Attention, and experimented with various parameter\nsettings and configurations. We demonstrate that Differential Attention can be\nadapted and integrated into the fine-tuning of existing models to enhance noisy\ninformation retrieval and question-answering capabilities.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5c06\u5dee\u5206\u6ce8\u610f\u529b\u673a\u5236\u4ece\u7eaf\u6587\u672c\u6a21\u578b\u6269\u5c55\u5230\u6587\u672c-\u89c6\u89c9\u6a21\u578bPaliGemma\uff0c\u901a\u8fc7LoRA\u5fae\u8c03\u51cf\u5c11\u566a\u58f0\u4fe1\u606f\u68c0\u7d22\u548c\u5e7b\u89c9\u95ee\u9898\uff0c\u63d0\u5347\u95ee\u7b54\u80fd\u529b\u3002", "motivation": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u878d\u5408\u89c6\u89c9\u7b49\u989d\u5916\u6a21\u6001\u65f6\u9762\u4e34\u4e0a\u4e0b\u6587\u7a97\u53e3\u6709\u9650\u7684\u6311\u6218\uff0c\u56e0\u4e3a\u4f1a\u5f15\u5165\u566a\u58f0\u3002Transformer\u6ce8\u610f\u529b\u673a\u5236\u7ecf\u5e38\u8fc7\u5ea6\u5173\u6ce8\u65e0\u5173\u4e0a\u4e0b\u6587\uff0c\u9700\u8981\u6539\u8fdb\u673a\u5236\u6765\u7f13\u89e3\u566a\u58f0\u4fe1\u606f\u68c0\u7d22\u548c\u51cf\u5c11\u5e7b\u89c9\u3002", "method": "\u5c06\u539f\u672c\u4e3a\u7eaf\u6587\u672c\u6a21\u578b\u8bbe\u8ba1\u7684\u5dee\u5206\u6ce8\u610f\u529b\u673a\u5236\u6269\u5c55\u5230\u6587\u672c-\u89c6\u89c9\u6a21\u578bPaliGemma\u3002\u4f7f\u7528LoRA\u5bf9PaliGemma 3B\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u878d\u5165\u5dee\u5206\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5e76\u5c1d\u8bd5\u5404\u79cd\u53c2\u6570\u8bbe\u7f6e\u548c\u914d\u7f6e\u3002", "result": "\u8bc1\u660e\u4e86\u5dee\u5206\u6ce8\u610f\u529b\u673a\u5236\u53ef\u4ee5\u6210\u529f\u9002\u914d\u5e76\u96c6\u6210\u5230\u73b0\u6709\u6a21\u578b\u7684\u5fae\u8c03\u8fc7\u7a0b\u4e2d\uff0c\u80fd\u591f\u589e\u5f3a\u566a\u58f0\u4fe1\u606f\u68c0\u7d22\u548c\u95ee\u7b54\u80fd\u529b\u3002", "conclusion": "\u5dee\u5206\u6ce8\u610f\u529b\u673a\u5236\u53ef\u4ee5\u6709\u6548\u5730\u4ece\u7eaf\u6587\u672c\u6a21\u578b\u6269\u5c55\u5230\u591a\u6a21\u6001\u6587\u672c-\u89c6\u89c9\u6a21\u578b\uff0c\u901a\u8fc7\u51cf\u5c11\u5bf9\u65e0\u5173\u4e0a\u4e0b\u6587\u7684\u5173\u6ce8\u6765\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u4e3a\u5c0f\u578b\u591a\u6a21\u6001\u6a21\u578b\u7684\u4f18\u5316\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.15889", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15889", "abs": "https://arxiv.org/abs/2507.15889", "authors": ["Noah van der Vleuten"], "title": "Dr. Boot: Bootstrapping Program Synthesis Language Models to Perform Repairing", "comment": "Master's thesis, University of Amsterdam, 2023\n  (https://scripties.uba.uva.nl/search?id=record_54126). Code and experiments\n  available at: https://github.com/NoahVl/Dr-Boot", "summary": "Language models for program synthesis are usually trained and evaluated on\nprogramming competition datasets (MBPP, APPS). However, these datasets are\nlimited in size and quality, while these language models are extremely data\nhungry. Additionally, the language models have a misaligned program synthesis\nprocess compared to humans. While humans iteratively develop code with the help\nof a compiler, most program synthesis models currently produce code in one go.\nTo solve these issues, we introduce a bootstrapping algorithm for program\nsynthesis, that supports teaching models how to repair. We show that\nbootstrapping consistently outperforms regular fine-tuning. Compared to other\nwork, our bootstrapped model performs on par with fine-tuned models that are\n68\\% larger. Notably, bootstrapping with repairing also improves non-repairing\nperformance compared to regular bootstrapping during inference. However, on our\nmodels, repairing during inference is likely inferior to simply sampling the\nsame number of solutions. Furthermore, we find that there are issues with the\nexample test cases in the training portion of the APPS dataset that are\nvaluable to the community, as many repairing and reinforcement learning methods\nrely on them.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u7a0b\u5e8f\u5408\u6210\u7684\u81ea\u4e3e\u7b97\u6cd5\uff0c\u901a\u8fc7\u6559\u6a21\u578b\u5982\u4f55\u4fee\u590d\u4ee3\u7801\u6765\u89e3\u51b3\u73b0\u6709\u6570\u636e\u96c6\u89c4\u6a21\u6709\u9650\u548c\u6a21\u578b\u5408\u6210\u8fc7\u7a0b\u4e0e\u4eba\u7c7b\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7a0b\u5e8f\u5408\u6210\u8bed\u8a00\u6a21\u578b\u9762\u4e34\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u8bad\u7ec3\u548c\u8bc4\u4f30\u6570\u636e\u96c6\uff08MBPP\u3001APPS\uff09\u89c4\u6a21\u6709\u9650\u4e14\u8d28\u91cf\u4e0d\u9ad8\uff0c\u800c\u8bed\u8a00\u6a21\u578b\u9700\u8981\u5927\u91cf\u6570\u636e\uff1b2\uff09\u6a21\u578b\u7684\u7a0b\u5e8f\u5408\u6210\u8fc7\u7a0b\u4e0e\u4eba\u7c7b\u4e0d\u5339\u914d\uff0c\u4eba\u7c7b\u4f1a\u501f\u52a9\u7f16\u8bd1\u5668\u8fed\u4ee3\u5f00\u53d1\u4ee3\u7801\uff0c\u800c\u5927\u591a\u6570\u6a21\u578b\u662f\u4e00\u6b21\u6027\u751f\u6210\u4ee3\u7801\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u652f\u6301\u6559\u6a21\u578b\u5982\u4f55\u4fee\u590d\u4ee3\u7801\u7684\u81ea\u4e3e\u7b97\u6cd5\uff08bootstrapping algorithm\uff09\u3002\u8be5\u7b97\u6cd5\u80fd\u591f\u8ba9\u6a21\u578b\u5b66\u4e60\u4fee\u590d\u8fc7\u7a0b\uff0c\u4f7f\u5176\u66f4\u63a5\u8fd1\u4eba\u7c7b\u7684\u8fed\u4ee3\u5f00\u53d1\u65b9\u5f0f\u3002", "result": "\u81ea\u4e3e\u65b9\u6cd5\u6301\u7eed\u4f18\u4e8e\u5e38\u89c4\u5fae\u8c03\uff1b\u4e0e\u5176\u4ed6\u5de5\u4f5c\u76f8\u6bd4\uff0c\u81ea\u4e3e\u6a21\u578b\u7684\u6027\u80fd\u4e0e\u592768%\u7684\u5fae\u8c03\u6a21\u578b\u76f8\u5f53\uff1b\u5e26\u4fee\u590d\u7684\u81ea\u4e3e\u65b9\u6cd5\u5728\u63a8\u7406\u65f6\u4e5f\u80fd\u6539\u5584\u975e\u4fee\u590d\u6027\u80fd\uff1b\u4f46\u5728\u8be5\u6a21\u578b\u4e0a\uff0c\u63a8\u7406\u65f6\u4fee\u590d\u53ef\u80fd\u4e0d\u5982\u7b80\u5355\u91c7\u6837\u76f8\u540c\u6570\u91cf\u7684\u89e3\u51b3\u65b9\u6848\uff1b\u53d1\u73b0APPS\u6570\u636e\u96c6\u8bad\u7ec3\u90e8\u5206\u7684\u793a\u4f8b\u6d4b\u8bd5\u7528\u4f8b\u5b58\u5728\u95ee\u9898\u3002", "conclusion": "\u81ea\u4e3e\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347\u7a0b\u5e8f\u5408\u6210\u6a21\u578b\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u6559\u6a21\u578b\u5b66\u4e60\u4fee\u590d\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002\u8be5\u65b9\u6cd5\u4e3a\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u548c\u6a21\u578b\u4e0e\u4eba\u7c7b\u5408\u6210\u8fc7\u7a0b\u4e0d\u5339\u914d\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\uff0c\u540c\u65f6\u4e5f\u63ed\u793a\u4e86\u73b0\u6709\u6570\u636e\u96c6\u7684\u8d28\u91cf\u95ee\u9898\u3002"}}
{"id": "2507.16203", "categories": ["cs.CR", "cs.AI", "cs.AR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.16203", "abs": "https://arxiv.org/abs/2507.16203", "authors": ["Rui Guo", "Avinash Ayalasomayajula", "Henian Li", "Jingbo Zhou", "Sujan Kumar Saha", "Farimah Farahmandi"], "title": "SVAgent: AI Agent for Hardware Security Verification Assertion", "comment": null, "summary": "Verification using SystemVerilog assertions (SVA) is one of the most popular\nmethods for detecting circuit design vulnerabilities. However, with the\nglobalization of integrated circuit design and the continuous upgrading of\nsecurity requirements, the SVA development model has exposed major limitations.\nIt is not only inefficient in development, but also unable to effectively deal\nwith the increasing number of security vulnerabilities in modern complex\nintegrated circuits. In response to these challenges, this paper proposes an\ninnovative SVA automatic generation framework SVAgent. SVAgent introduces a\nrequirement decomposition mechanism to transform the original complex\nrequirements into a structured, gradually solvable fine-grained problem-solving\nchain. Experiments have shown that SVAgent can effectively suppress the\ninfluence of hallucinations and random answers, and the key evaluation\nindicators such as the accuracy and consistency of the SVA are significantly\nbetter than existing frameworks. More importantly, we successfully integrated\nSVAgent into the most mainstream integrated circuit vulnerability assessment\nframework and verified its practicality and reliability in a real engineering\ndesign environment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86SVAgent\u6846\u67b6\uff0c\u901a\u8fc7\u9700\u6c42\u5206\u89e3\u673a\u5236\u81ea\u52a8\u751f\u6210SystemVerilog\u65ad\u8a00(SVA)\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfSVA\u5f00\u53d1\u6548\u7387\u4f4e\u4e0b\u548c\u96be\u4ee5\u5e94\u5bf9\u590d\u6742\u96c6\u6210\u7535\u8def\u5b89\u5168\u6f0f\u6d1e\u7684\u95ee\u9898\uff0c\u5728\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6846\u67b6\u3002", "motivation": "\u968f\u7740\u96c6\u6210\u7535\u8def\u8bbe\u8ba1\u5168\u7403\u5316\u548c\u5b89\u5168\u8981\u6c42\u4e0d\u65ad\u5347\u7ea7\uff0c\u4f20\u7edf\u7684SystemVerilog\u65ad\u8a00(SVA)\u5f00\u53d1\u6a21\u5f0f\u66b4\u9732\u51fa\u91cd\u5927\u5c40\u9650\u6027\uff1a\u5f00\u53d1\u6548\u7387\u4f4e\u4e0b\uff0c\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u73b0\u4ee3\u590d\u6742\u96c6\u6210\u7535\u8def\u4e2d\u65e5\u76ca\u589e\u591a\u7684\u5b89\u5168\u6f0f\u6d1e\u68c0\u6d4b\u9700\u6c42\u3002", "method": "\u63d0\u51faSVAgent\u81ea\u52a8\u751f\u6210\u6846\u67b6\uff0c\u5f15\u5165\u9700\u6c42\u5206\u89e3\u673a\u5236\uff0c\u5c06\u539f\u59cb\u590d\u6742\u9700\u6c42\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u7684\u3001\u9010\u6b65\u53ef\u89e3\u7684\u7ec6\u7c92\u5ea6\u95ee\u9898\u6c42\u89e3\u94fe\uff0c\u4ece\u800c\u5b9e\u73b0SVA\u7684\u81ea\u52a8\u5316\u751f\u6210\u3002", "result": "\u5b9e\u9a8c\u8868\u660eSVAgent\u80fd\u591f\u6709\u6548\u6291\u5236\u5e7b\u89c9\u548c\u968f\u673a\u7b54\u6848\u7684\u5f71\u54cd\uff0c\u5728SVA\u7684\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\u7b49\u5173\u952e\u8bc4\u4f30\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6846\u67b6\u3002\u6210\u529f\u5c06SVAgent\u96c6\u6210\u5230\u4e3b\u6d41\u96c6\u6210\u7535\u8def\u6f0f\u6d1e\u8bc4\u4f30\u6846\u67b6\u4e2d\u3002", "conclusion": "SVAgent\u6846\u67b6\u5728\u5b9e\u9645\u5de5\u7a0b\u8bbe\u8ba1\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u5176\u5b9e\u7528\u6027\u548c\u53ef\u9760\u6027\uff0c\u4e3a\u89e3\u51b3\u96c6\u6210\u7535\u8def\u5b89\u5168\u9a8c\u8bc1\u4e2d\u7684SVA\u5f00\u53d1\u6311\u6218\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.15876", "categories": ["cs.AI", "q-fin.PR", "q-fin.ST", "q-fin.TR"], "pdf": "https://arxiv.org/pdf/2507.15876", "abs": "https://arxiv.org/abs/2507.15876", "authors": ["Eric Benhamou", "Jean-Jacques Ohana", "Alban Etienne", "B\u00e9atrice Guez", "Ethan Setrouk", "Thomas Jacquot"], "title": "Re-evaluating Short- and Long-Term Trend Factors in CTA Replication: A Bayesian Graphical Approach", "comment": "13 pages", "summary": "Commodity Trading Advisors (CTAs) have historically relied on trend-following\nrules that operate on vastly different horizons from long-term breakouts that\ncapture major directional moves to short-term momentum signals that thrive in\nfast-moving markets. Despite a large body of work on trend following, the\nrelative merits and interactions of short-versus long-term trend systems remain\ncontroversial. This paper adds to the debate by (i) dynamically decomposing CTA\nreturns into short-term trend, long-term trend and market beta factors using a\nBayesian graphical model, and (ii) showing how the blend of horizons shapes the\nstrategy's risk-adjusted performance.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u8d1d\u53f6\u65af\u56fe\u5f62\u6a21\u578b\u52a8\u6001\u5206\u89e3CTA\u6536\u76ca\u4e3a\u77ed\u671f\u8d8b\u52bf\u3001\u957f\u671f\u8d8b\u52bf\u548c\u5e02\u573a\u8d1d\u5854\u56e0\u5b50\uff0c\u7814\u7a76\u4e0d\u540c\u65f6\u95f4\u5468\u671f\u8d8b\u52bf\u7cfb\u7edf\u7684\u76f8\u5bf9\u4f18\u52bf\u53ca\u5176\u5bf9\u98ce\u9669\u8c03\u6574\u6536\u76ca\u7684\u5f71\u54cd", "motivation": "\u5546\u54c1\u4ea4\u6613\u987e\u95ee(CTA)\u5386\u53f2\u4e0a\u4f9d\u8d56\u4e8e\u5728\u4e0d\u540c\u65f6\u95f4\u5468\u671f\u4e0a\u8fd0\u4f5c\u7684\u8d8b\u52bf\u8ddf\u8e2a\u89c4\u5219\uff0c\u4f46\u77ed\u671f\u4e0e\u957f\u671f\u8d8b\u52bf\u7cfb\u7edf\u7684\u76f8\u5bf9\u4f18\u52bf\u548c\u76f8\u4e92\u4f5c\u7528\u4ecd\u5b58\u5728\u4e89\u8bae\uff0c\u9700\u8981\u6df1\u5165\u7814\u7a76\u8fd9\u4e9b\u7cfb\u7edf\u5982\u4f55\u5f71\u54cd\u7b56\u7565\u7684\u98ce\u9669\u8c03\u6574\u8868\u73b0", "method": "\u4f7f\u7528\u8d1d\u53f6\u65af\u56fe\u5f62\u6a21\u578b\u52a8\u6001\u5206\u89e3CTA\u6536\u76ca\uff0c\u5c06\u6536\u76ca\u5206\u89e3\u4e3a\u77ed\u671f\u8d8b\u52bf\u56e0\u5b50\u3001\u957f\u671f\u8d8b\u52bf\u56e0\u5b50\u548c\u5e02\u573a\u8d1d\u5854\u56e0\u5b50\u4e09\u4e2a\u7ec4\u6210\u90e8\u5206", "result": "\u901a\u8fc7\u52a8\u6001\u5206\u89e3\u5206\u6790\uff0c\u5c55\u793a\u4e86\u4e0d\u540c\u65f6\u95f4\u5468\u671f\u8d8b\u52bf\u7cfb\u7edf\u7684\u6df7\u5408\u5982\u4f55\u5851\u9020\u7b56\u7565\u7684\u98ce\u9669\u8c03\u6574\u8868\u73b0\uff0c\u4e3a\u7406\u89e3\u77ed\u671f\u4e0e\u957f\u671f\u8d8b\u52bf\u7cfb\u7edf\u7684\u76f8\u5bf9\u4f18\u52bf\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2", "conclusion": "\u4e0d\u540c\u65f6\u95f4\u5468\u671f\u8d8b\u52bf\u7cfb\u7edf\u7684\u7ec4\u5408\u65b9\u5f0f\u5bf9CTA\u7b56\u7565\u7684\u98ce\u9669\u8c03\u6574\u6536\u76ca\u5177\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u56fe\u5f62\u6a21\u578b\u53ef\u4ee5\u6709\u6548\u8bc6\u522b\u548c\u91cf\u5316\u8fd9\u4e9b\u5f71\u54cd"}}
{"id": "2507.15892", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.15892", "abs": "https://arxiv.org/abs/2507.15892", "authors": ["Elijah Nnorom", "Md Basim Uddin Ahmed", "Jiho Shin", "Hung Viet Pham", "Song Wang"], "title": "StaAgent: An Agentic Framework for Testing Static Analyzers", "comment": null, "summary": "Static analyzers play a critical role in identifying bugs early in the\nsoftware development lifecycle, but their rule implementations are often\nunder-tested and prone to inconsistencies. To address this, we propose\nStaAgent, an agentic framework that harnesses the generative capabilities of\nLarge Language Models (LLMs) to systematically evaluate static analyzer rules.\nStaAgent comprises four specialized agents: a Seed Generation Agent that\ntranslates bug detection rules into concrete, bug-inducing seed programs; a\nCode Validation Agent that ensures the correctness of these seeds; a Mutation\nGeneration Agent that produces semantically equivalent mutants; and an Analyzer\nEvaluation Agent that performs metamorphic testing by comparing the static\nanalyzer's behavior on seeds and their corresponding mutants. By revealing\ninconsistent behaviors, StaAgent helps uncover flaws in rule implementations.\nThis LLM-driven, multi-agent framework offers a scalable and adaptable solution\nto improve the reliability of static analyzers. We evaluated StaAgent with five\nstate-of-the-art LLMs (CodeL-lama, DeepSeek, Codestral, Qwen, and GPT-4o)\nacross five widely used static analyzers (SpotBugs, SonarQube, ErrorProne,\nInfer, and PMD). The experimental results show that our approach can help\nreveal 64 problematic rules in the latest versions of these five static\nanalyzers (i.e., 28 in SpotBugs, 18 in SonarQube, 6 in ErrorProne, 4 in Infer,\nand 8 in PMD). In addition, 53 out of the 64 bugs cannot be detected by the\nSOTA baseline. We have reported all the bugs to developers, with two of them\nalready fixed. Three more have been confirmed by developers, while the rest are\nawaiting response. These results demonstrate the effectiveness of our approach\nand underscore the promise of agentic, LLM-driven data synthesis to advance\nsoftware engineering.", "AI": {"tldr": "\u63d0\u51fa\u4e86StaAgent\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6765\u7cfb\u7edf\u8bc4\u4f30\u9759\u6001\u5206\u6790\u5668\u89c4\u5219\u7684\u53ef\u9760\u6027\uff0c\u901a\u8fc7\u751f\u6210\u79cd\u5b50\u7a0b\u5e8f\u3001\u9a8c\u8bc1\u4ee3\u7801\u3001\u4ea7\u751f\u53d8\u5f02\u4f53\u548c\u6267\u884c\u53d8\u5f62\u6d4b\u8bd5\u6765\u53d1\u73b0\u89c4\u5219\u5b9e\u73b0\u4e2d\u7684\u7f3a\u9677", "motivation": "\u9759\u6001\u5206\u6790\u5668\u5728\u8f6f\u4ef6\u5f00\u53d1\u751f\u547d\u5468\u671f\u4e2d\u53d1\u6325\u5173\u952e\u4f5c\u7528\uff0c\u4f46\u5176\u89c4\u5219\u5b9e\u73b0\u5f80\u5f80\u6d4b\u8bd5\u4e0d\u8db3\u4e14\u5bb9\u6613\u51fa\u73b0\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u9700\u8981\u4e00\u4e2a\u7cfb\u7edf\u6027\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u548c\u6539\u8fdb\u9759\u6001\u5206\u6790\u5668\u89c4\u5219\u7684\u53ef\u9760\u6027", "method": "\u8bbe\u8ba1\u4e86StaAgent\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u542b\u56db\u4e2a\u4e13\u95e8\u7684\u667a\u80fd\u4f53\uff1a\u79cd\u5b50\u751f\u6210\u667a\u80fd\u4f53\uff08\u5c06\u9519\u8bef\u68c0\u6d4b\u89c4\u5219\u8f6c\u6362\u4e3a\u5177\u4f53\u7684\u9519\u8bef\u8bf1\u5bfc\u79cd\u5b50\u7a0b\u5e8f\uff09\u3001\u4ee3\u7801\u9a8c\u8bc1\u667a\u80fd\u4f53\uff08\u786e\u4fdd\u79cd\u5b50\u7a0b\u5e8f\u7684\u6b63\u786e\u6027\uff09\u3001\u53d8\u5f02\u751f\u6210\u667a\u80fd\u4f53\uff08\u4ea7\u751f\u8bed\u4e49\u7b49\u4ef7\u7684\u53d8\u5f02\u4f53\uff09\u548c\u5206\u6790\u5668\u8bc4\u4f30\u667a\u80fd\u4f53\uff08\u901a\u8fc7\u6bd4\u8f83\u9759\u6001\u5206\u6790\u5668\u5728\u79cd\u5b50\u548c\u5bf9\u5e94\u53d8\u5f02\u4f53\u4e0a\u7684\u884c\u4e3a\u8fdb\u884c\u53d8\u5f62\u6d4b\u8bd5\uff09", "result": "\u5728\u4e94\u4e2a\u4e3b\u6d41\u9759\u6001\u5206\u6790\u5668\uff08SpotBugs\u3001SonarQube\u3001ErrorProne\u3001Infer\u3001PMD\uff09\u4e0a\u4f7f\u7528\u4e94\u4e2a\u5148\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\uff0c\u53d1\u73b0\u4e8664\u4e2a\u95ee\u9898\u89c4\u5219\uff08SpotBugs 28\u4e2a\u3001SonarQube 18\u4e2a\u3001ErrorProne 6\u4e2a\u3001Infer 4\u4e2a\u3001PMD 8\u4e2a\uff09\uff0c\u5176\u4e2d53\u4e2a\u65e0\u6cd5\u88ab\u73b0\u6709\u57fa\u51c6\u65b9\u6cd5\u68c0\u6d4b\u5230\u3002\u5df2\u5411\u5f00\u53d1\u8005\u62a5\u544a\u6240\u6709\u9519\u8bef\uff0c2\u4e2a\u5df2\u4fee\u590d\uff0c3\u4e2a\u5df2\u786e\u8ba4", "conclusion": "StaAgent\u6846\u67b6\u6709\u6548\u5730\u63ed\u793a\u4e86\u9759\u6001\u5206\u6790\u5668\u89c4\u5219\u5b9e\u73b0\u4e2d\u7684\u7f3a\u9677\uff0c\u8bc1\u660e\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u9a71\u52a8\u6570\u636e\u5408\u6210\u65b9\u6cd5\u5728\u63a8\u8fdb\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u6f5c\u529b\uff0c\u4e3a\u63d0\u9ad8\u9759\u6001\u5206\u6790\u5668\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u548c\u9002\u5e94\u6027\u5f3a\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2507.16241", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16241", "abs": "https://arxiv.org/abs/2507.16241", "authors": ["Paul R. B. Houssel", "Siamak Layeghy", "Priyanka Singh", "Marius Portmann"], "title": "eX-NIDS: A Framework for Explainable Network Intrusion Detection Leveraging Large Language Models", "comment": null, "summary": "This paper introduces eX-NIDS, a framework designed to enhance\ninterpretability in flow-based Network Intrusion Detection Systems (NIDS) by\nleveraging Large Language Models (LLMs). In our proposed framework, flows\nlabelled as malicious by NIDS are initially processed through a module called\nthe Prompt Augmenter. This module extracts contextual information and Cyber\nThreat Intelligence (CTI)-related knowledge from these flows. This enriched,\ncontext-specific data is then integrated with an input prompt for an LLM,\nenabling it to generate detailed explanations and interpretations of why the\nflow was identified as malicious by NIDS. We compare the generated\ninterpretations against a Basic-Prompt Explainer baseline, which does not\nincorporate any contextual information into the LLM's input prompt. Our\nframework is quantitatively evaluated using the Llama 3 and GPT-4 models,\nemploying a novel evaluation method tailored for natural language explanations,\nfocusing on their correctness and consistency. The results demonstrate that\naugmented LLMs can produce accurate and consistent explanations, serving as\nvaluable complementary tools in NIDS to explain the classification of malicious\nflows. The use of augmented prompts enhances performance by over 20% compared\nto the Basic-Prompt Explainer.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86eX-NIDS\u6846\u67b6\uff0c\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u548c\u63d0\u793a\u589e\u5f3a\u6a21\u5757\u4e3a\u7f51\u7edc\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\uff0c\u80fd\u591f\u751f\u6210\u51c6\u786e\u4e00\u81f4\u7684\u6076\u610f\u6d41\u91cf\u5206\u7c7b\u89e3\u91ca\uff0c\u76f8\u6bd4\u57fa\u7840\u63d0\u793a\u65b9\u6cd5\u6027\u80fd\u63d0\u5347\u8d85\u8fc720%\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u6d41\u91cf\u7684\u7f51\u7edc\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u96be\u4ee5\u89e3\u91ca\u4e3a\u4ec0\u4e48\u67d0\u4e2a\u7f51\u7edc\u6d41\u88ab\u8bc6\u522b\u4e3a\u6076\u610f\u6d41\u91cf\uff0c\u9700\u8981\u4e00\u4e2a\u6846\u67b6\u6765\u589e\u5f3aNIDS\u7684\u53ef\u89e3\u91ca\u6027\u5e76\u63d0\u4f9b\u8be6\u7ec6\u7684\u89e3\u91ca\u8bf4\u660e\u3002", "method": "\u8bbe\u8ba1\u4e86eX-NIDS\u6846\u67b6\uff0c\u5305\u542b\u63d0\u793a\u589e\u5f3a\u6a21\u5757(Prompt Augmenter)\uff0c\u8be5\u6a21\u5757\u4ece\u6076\u610f\u6d41\u91cf\u4e2d\u63d0\u53d6\u4e0a\u4e0b\u6587\u4fe1\u606f\u548c\u7f51\u7edc\u5a01\u80c1\u60c5\u62a5\u76f8\u5173\u77e5\u8bc6\uff0c\u5c06\u8fd9\u4e9b\u4e30\u5bcc\u7684\u4e0a\u4e0b\u6587\u6570\u636e\u4e0e\u8f93\u5165\u63d0\u793a\u7ed3\u5408\uff0c\u8f93\u5165\u5230\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u751f\u6210\u8be6\u7ec6\u7684\u6076\u610f\u6d41\u91cf\u8bc6\u522b\u89e3\u91ca\u3002", "result": "\u4f7f\u7528Llama 3\u548cGPT-4\u6a21\u578b\u8fdb\u884c\u5b9a\u91cf\u8bc4\u4f30\uff0c\u91c7\u7528\u9488\u5bf9\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u7684\u65b0\u9896\u8bc4\u4f30\u65b9\u6cd5\uff0c\u91cd\u70b9\u5173\u6ce8\u89e3\u91ca\u7684\u6b63\u786e\u6027\u548c\u4e00\u81f4\u6027\u3002\u7ed3\u679c\u663e\u793a\u589e\u5f3a\u578b\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u4ea7\u751f\u51c6\u786e\u4e00\u81f4\u7684\u89e3\u91ca\uff0c\u76f8\u6bd4\u57fa\u7840\u63d0\u793a\u89e3\u91ca\u5668\u6027\u80fd\u63d0\u5347\u8d85\u8fc720%\u3002", "conclusion": "eX-NIDS\u6846\u67b6\u6210\u529f\u5730\u4e3a\u7f51\u7edc\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u6027\uff0c\u589e\u5f3a\u578b\u63d0\u793a\u7684\u4f7f\u7528\u663e\u8457\u63d0\u9ad8\u4e86\u89e3\u91ca\u8d28\u91cf\uff0c\u8bc1\u660e\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u4f5c\u4e3aNIDS\u4e2d\u89e3\u91ca\u6076\u610f\u6d41\u91cf\u5206\u7c7b\u7684\u6709\u4ef7\u503c\u8865\u5145\u5de5\u5177\u3002"}}
{"id": "2507.15877", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15877", "abs": "https://arxiv.org/abs/2507.15877", "authors": ["Simon Ouellette"], "title": "Out-of-Distribution Generalization in the ARC-AGI Domain: Comparing Execution-Guided Neural Program Synthesis and Test-Time Fine-Tuning", "comment": null, "summary": "We run a controlled compositional generalization experiment in the ARC-AGI\ndomain: an open-world problem domain in which the ability to generalize\nout-of-distribution is, by design, an essential characteristic for success. We\ncompare neural program synthesis and test-time fine-tuning approaches on this\nexperiment. We find that execution-guided neural program synthesis outperforms\nall reference algorithms in its ability to compose novel solutions. Our\nempirical findings also suggest that the success of TTFT on ARC-AGI lies mainly\nin eliciting in-distribution knowledge that the LLM otherwise fails to rely on\ndirectly.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u795e\u7ecf\u7a0b\u5e8f\u5408\u6210\u548c\u6d4b\u8bd5\u65f6\u5fae\u8c03\u65b9\u6cd5\u5728ARC-AGI\u9886\u57df\u7684\u7ec4\u5408\u6cdb\u5316\u80fd\u529b\uff0c\u53d1\u73b0\u6267\u884c\u5f15\u5bfc\u7684\u795e\u7ecf\u7a0b\u5e8f\u5408\u6210\u5728\u5408\u6210\u65b0\u9896\u89e3\u51b3\u65b9\u6848\u65b9\u9762\u8868\u73b0\u6700\u4f73", "motivation": "\u5728ARC-AGI\u8fd9\u4e2a\u5f00\u653e\u4e16\u754c\u95ee\u9898\u57df\u4e2d\u8bc4\u4f30\u4e0d\u540c\u65b9\u6cd5\u7684\u7ec4\u5408\u6cdb\u5316\u80fd\u529b\uff0c\u8be5\u57df\u8bbe\u8ba1\u4e0a\u9700\u8981\u5206\u5e03\u5916\u6cdb\u5316\u80fd\u529b\u624d\u80fd\u6210\u529f", "method": "\u5728ARC-AGI\u57df\u4e0a\u8fdb\u884c\u53d7\u63a7\u7ec4\u5408\u6cdb\u5316\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u795e\u7ecf\u7a0b\u5e8f\u5408\u6210\u65b9\u6cd5\u548c\u6d4b\u8bd5\u65f6\u5fae\u8c03(TTFT)\u65b9\u6cd5\u7684\u6027\u80fd\u8868\u73b0", "result": "\u6267\u884c\u5f15\u5bfc\u7684\u795e\u7ecf\u7a0b\u5e8f\u5408\u6210\u5728\u7ec4\u5408\u65b0\u9896\u89e3\u51b3\u65b9\u6848\u7684\u80fd\u529b\u4e0a\u8d85\u8d8a\u4e86\u6240\u6709\u53c2\u8003\u7b97\u6cd5\uff1bTTFT\u5728ARC-AGI\u4e0a\u7684\u6210\u529f\u4e3b\u8981\u5728\u4e8e\u6fc0\u53d1LLM\u539f\u672c\u65e0\u6cd5\u76f4\u63a5\u4f9d\u8d56\u7684\u5206\u5e03\u5185\u77e5\u8bc6", "conclusion": "\u795e\u7ecf\u7a0b\u5e8f\u5408\u6210\u65b9\u6cd5\u5728\u9700\u8981\u7ec4\u5408\u6cdb\u5316\u80fd\u529b\u7684\u5f00\u653e\u4e16\u754c\u95ee\u9898\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u800c\u6d4b\u8bd5\u65f6\u5fae\u8c03\u7684\u6548\u679c\u4e3b\u8981\u6765\u81ea\u4e8e\u66f4\u597d\u5730\u5229\u7528\u5df2\u6709\u7684\u5206\u5e03\u5185\u77e5\u8bc6"}}
{"id": "2507.16037", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.16037", "abs": "https://arxiv.org/abs/2507.16037", "authors": ["Zhili Zeng", "Kimya Khakzad Shahandashti", "Alvine Boaye Belle", "Song Wang", "Zhen Ming", "Jiang"], "title": "A Pilot Study on LLM-Based Agentic Translation from Android to iOS: Pitfalls and Insights", "comment": null, "summary": "The rapid advancement of mobile applications has led to a significant demand\nfor cross-platform compatibility, particularly between the Android and iOS\nplatforms. Traditional approaches to mobile application translation often rely\non manual intervention or rule-based systems, which are labor-intensive and\ntime-consuming. While recent advancements in machine learning have introduced\nautomated methods, they often lack contextual understanding and adaptability,\nresulting in suboptimal translations. Large Language Models (LLMs) were\nrecently leveraged to enhance code translation at different granularities,\nincluding the method, class, and repository levels. Researchers have\ninvestigated common errors, limitations, and potential strategies to improve\nthese tasks. However, LLM-based application translation across different\nplatforms, such as migrating mobile applications between Android and iOS or\nadapting software across diverse frameworks, remains underexplored.\nUnderstanding the performance, strengths, and limitations of LLMs in\ncross-platform application translation is critical for advancing software\nengineering automation. This study aims to fill this gap by evaluating\nLLM-based agentic approaches for mobile application translation, identifying\nkey failure points, and proposing guidelines to improve translation\nperformance. We developed a chain of agents that account for dependencies,\nspecifications, program structure, and program control flow when translating\napplications from Android to iOS. To evaluate the performance, we manually\nexamined the translated code for syntactic correctness, semantic accuracy, and\nfunctional completeness. For translation failures, we further conducted a\ndetailed root cause analysis to understand the underlying limitations of the\nagentic translation process and identify opportunities for improvement.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7406\u65b9\u6cd5\u5728\u79fb\u52a8\u5e94\u7528\u8de8\u5e73\u53f0\u7ffb\u8bd1(Android\u5230iOS)\u4e2d\u7684\u6027\u80fd\uff0c\u5f00\u53d1\u4e86\u8003\u8651\u4f9d\u8d56\u5173\u7cfb\u3001\u89c4\u8303\u3001\u7a0b\u5e8f\u7ed3\u6784\u548c\u63a7\u5236\u6d41\u7684\u4ee3\u7406\u94fe\uff0c\u5e76\u901a\u8fc7\u624b\u5de5\u68c0\u67e5\u548c\u6839\u56e0\u5206\u6790\u8bc6\u522b\u4e86\u5173\u952e\u5931\u8d25\u70b9\uff0c\u4e3a\u63d0\u5347\u7ffb\u8bd1\u6027\u80fd\u63d0\u51fa\u4e86\u6307\u5bfc\u539f\u5219\u3002", "motivation": "\u4f20\u7edf\u7684\u79fb\u52a8\u5e94\u7528\u7ffb\u8bd1\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u5e72\u9884\u6216\u57fa\u4e8e\u89c4\u5219\u7684\u7cfb\u7edf\uff0c\u52b3\u52a8\u5bc6\u96c6\u4e14\u8017\u65f6\uff1b\u867d\u7136\u673a\u5668\u5b66\u4e60\u5f15\u5165\u4e86\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u4f46\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u7406\u89e3\u548c\u9002\u5e94\u6027\uff0c\u5bfc\u81f4\u7ffb\u8bd1\u6548\u679c\u4e0d\u4f73\uff1b\u800c\u57fa\u4e8eLLM\u7684\u8de8\u5e73\u53f0\u5e94\u7528\u7ffb\u8bd1(\u5982Android\u548ciOS\u4e4b\u95f4\u7684\u8fc1\u79fb)\u4ecd\u672a\u5145\u5206\u63a2\u7d22\uff0c\u9700\u8981\u7406\u89e3LLM\u5728\u6b64\u7c7b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3001\u4f18\u52bf\u548c\u5c40\u9650\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u4ee3\u7406\u94fe(chain of agents)\uff0c\u5728\u5c06Android\u5e94\u7528\u7ffb\u8bd1\u4e3aiOS\u5e94\u7528\u65f6\u8003\u8651\u4f9d\u8d56\u5173\u7cfb\u3001\u89c4\u8303\u3001\u7a0b\u5e8f\u7ed3\u6784\u548c\u7a0b\u5e8f\u63a7\u5236\u6d41\uff1b\u901a\u8fc7\u624b\u5de5\u68c0\u67e5\u7ffb\u8bd1\u4ee3\u7801\u7684\u8bed\u6cd5\u6b63\u786e\u6027\u3001\u8bed\u4e49\u51c6\u786e\u6027\u548c\u529f\u80fd\u5b8c\u6574\u6027\u6765\u8bc4\u4f30\u6027\u80fd\uff1b\u5bf9\u7ffb\u8bd1\u5931\u8d25\u6848\u4f8b\u8fdb\u884c\u8be6\u7ec6\u7684\u6839\u56e0\u5206\u6790\u3002", "result": "\u901a\u8fc7\u624b\u5de5\u68c0\u67e5\u8bc4\u4f30\u4e86\u7ffb\u8bd1\u4ee3\u7801\u7684\u8bed\u6cd5\u6b63\u786e\u6027\u3001\u8bed\u4e49\u51c6\u786e\u6027\u548c\u529f\u80fd\u5b8c\u6574\u6027\uff1b\u8bc6\u522b\u4e86\u4ee3\u7406\u7ffb\u8bd1\u8fc7\u7a0b\u4e2d\u7684\u5173\u952e\u5931\u8d25\u70b9\uff1b\u901a\u8fc7\u6839\u56e0\u5206\u6790\u7406\u89e3\u4e86\u5e95\u5c42\u5c40\u9650\u6027\u5e76\u53d1\u73b0\u4e86\u6539\u8fdb\u673a\u4f1a\u3002", "conclusion": "\u586b\u8865\u4e86LLM\u5728\u8de8\u5e73\u53f0\u5e94\u7528\u7ffb\u8bd1\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u81ea\u52a8\u5316\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u6d1e\u5bdf\uff1b\u901a\u8fc7\u8bc6\u522b\u5173\u952e\u5931\u8d25\u70b9\u548c\u63d0\u51fa\u6539\u8fdb\u6307\u5bfc\u539f\u5219\uff0c\u4e3a\u63d0\u5347\u57fa\u4e8eLLM\u7684\u79fb\u52a8\u5e94\u7528\u7ffb\u8bd1\u6027\u80fd\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.16276", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.16276", "abs": "https://arxiv.org/abs/2507.16276", "authors": ["Lambard Maxence", "Bertelle Cyrille", "Duvallet Claude"], "title": "From Contracts to Code: Automating Smart Contract Generation with Multi-Level Finite State Machines", "comment": null, "summary": "In an increasingly complex contractual landscape, the demand for\ntransparency, security, and efficiency has intensified. Blockchain technology,\nwith its decentralized and immutable nature, addresses these challenges by\nreducing intermediary costs, minimizing fraud risks, and enhancing system\ncompatibility. Smart contracts, initially conceptualized by Nick Szabo and\nlater implemented on the Ethereum blockchain, automate and secure contractual\nclauses, offering a robust solution for various industries. However, their\ncomplexity and the requirement for advanced programming skills present\nsignificant barriers to widespread adoption. This study introduces a\nmulti-level finite state machine model designed to represent and track the\nexecution of smart contracts. Our model aims to simplify smart contract\ndevelopment by providing a formalized framework that abstracts underlying\ntechnical complexities, making it accessible to professionals without deep\ntechnical expertise. The hierarchical structure of the multi-level finite state\nmachine enhances contract modularity and traceability, facilitating detailed\nrepresentation and evaluation of functional properties. The paper explores the\npotential of this multi-level approach, reviewing existing methodologies and\ntools, and detailing the smart contract generation process with an emphasis on\nreusable components and modularity. We also conduct a security analysis to\nevaluate potential vulnerabilities in our model, ensuring the robustness and\nreliability of the generated smart contracts.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u7ea7\u6709\u9650\u72b6\u6001\u673a\u6a21\u578b\u6765\u7b80\u5316\u667a\u80fd\u5408\u7ea6\u5f00\u53d1\uff0c\u901a\u8fc7\u5f62\u5f0f\u5316\u6846\u67b6\u964d\u4f4e\u6280\u672f\u95e8\u69db\uff0c\u63d0\u9ad8\u5408\u7ea6\u7684\u6a21\u5757\u5316\u548c\u53ef\u8ffd\u6eaf\u6027\uff0c\u5e76\u8fdb\u884c\u4e86\u5b89\u5168\u6027\u5206\u6790\u4ee5\u786e\u4fdd\u751f\u6210\u5408\u7ea6\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u667a\u80fd\u5408\u7ea6\u867d\u7136\u80fd\u63d0\u4f9b\u900f\u660e\u3001\u5b89\u5168\u3001\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5176\u590d\u6742\u6027\u548c\u5bf9\u9ad8\u7ea7\u7f16\u7a0b\u6280\u80fd\u7684\u8981\u6c42\u6210\u4e3a\u5e7f\u6cdb\u5e94\u7528\u7684\u91cd\u5927\u969c\u788d\u3002\u9700\u8981\u4e00\u79cd\u7b80\u5316\u667a\u80fd\u5408\u7ea6\u5f00\u53d1\u7684\u65b9\u6cd5\uff0c\u8ba9\u6ca1\u6709\u6df1\u539a\u6280\u672f\u4e13\u4e1a\u77e5\u8bc6\u7684\u4e13\u4e1a\u4eba\u5458\u4e5f\u80fd\u4f7f\u7528\u3002", "method": "\u5f15\u5165\u591a\u7ea7\u6709\u9650\u72b6\u6001\u673a\u6a21\u578b\u6765\u8868\u793a\u548c\u8ddf\u8e2a\u667a\u80fd\u5408\u7ea6\u7684\u6267\u884c\u3002\u8be5\u6a21\u578b\u63d0\u4f9b\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u62bd\u8c61\u5e95\u5c42\u6280\u672f\u590d\u6742\u6027\uff0c\u91c7\u7528\u5206\u5c42\u7ed3\u6784\u589e\u5f3a\u5408\u7ea6\u6a21\u5757\u5316\u548c\u53ef\u8ffd\u6eaf\u6027\uff0c\u91cd\u70b9\u5173\u6ce8\u53ef\u91cd\u7528\u7ec4\u4ef6\u548c\u6a21\u5757\u5316\u7684\u667a\u80fd\u5408\u7ea6\u751f\u6210\u8fc7\u7a0b\u3002", "result": "\u5f00\u53d1\u51fa\u7684\u591a\u7ea7\u6709\u9650\u72b6\u6001\u673a\u6a21\u578b\u80fd\u591f\u7b80\u5316\u667a\u80fd\u5408\u7ea6\u5f00\u53d1\u6d41\u7a0b\uff0c\u63d0\u9ad8\u5408\u7ea6\u7684\u6a21\u5757\u5316\u7a0b\u5ea6\u548c\u53ef\u8ffd\u6eaf\u6027\uff0c\u4f7f\u975e\u6280\u672f\u4e13\u4e1a\u4eba\u5458\u4e5f\u80fd\u53c2\u4e0e\u667a\u80fd\u5408\u7ea6\u5f00\u53d1\u3002\u6a21\u578b\u652f\u6301\u8be6\u7ec6\u7684\u529f\u80fd\u5c5e\u6027\u8868\u793a\u548c\u8bc4\u4f30\u3002", "conclusion": "\u591a\u7ea7\u6709\u9650\u72b6\u6001\u673a\u6a21\u578b\u4e3a\u667a\u80fd\u5408\u7ea6\u5f00\u53d1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u62bd\u8c61\u6280\u672f\u590d\u6742\u6027\u548c\u63d0\u9ad8\u6a21\u5757\u5316\u7a0b\u5ea6\uff0c\u964d\u4f4e\u4e86\u667a\u80fd\u5408\u7ea6\u5f00\u53d1\u7684\u95e8\u69db\u3002\u5b89\u5168\u6027\u5206\u6790\u786e\u4fdd\u4e86\u751f\u6210\u7684\u667a\u80fd\u5408\u7ea6\u5177\u6709\u8db3\u591f\u7684\u9c81\u68d2\u6027\u548c\u53ef\u9760\u6027\uff0c\u4e3a\u667a\u80fd\u5408\u7ea6\u7684\u5e7f\u6cdb\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.15880", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15880", "abs": "https://arxiv.org/abs/2507.15880", "authors": ["Andy E. Williams"], "title": "The Recursive Coherence Principle: A Formal Constraint on Scalable Intelligence, Alignment, and Reasoning Architecture", "comment": null, "summary": "Intelligence-biological, artificial, or collective-requires structural\ncoherence across recursive reasoning processes to scale effectively. As complex\nsystems grow, coherence becomes fragile unless a higher-order structure ensures\nsemantic consistency. This paper introduces the Recursive Coherence Principle\n(RCP): a foundational constraint stating that for any reasoning system of order\nN, composed of systems operating over conceptual spaces of order N-1, semantic\ncoherence is preserved only by a recursively evaluable generalization operator\nthat spans and aligns those lower-order conceptual spaces. Crucially, this\ncoherence enables structural alignment. Without recursive coherence, no system\ncan reliably preserve goals, meanings, or reasoning consistency at scale. We\nformally define the Functional Model of Intelligence (FMI) as the only known\noperator capable of satisfying the RCP at any scale. The FMI is a minimal,\ncomposable architecture with internal functions (evaluation, modeling,\nadaptation, stability, decomposition, bridging) and external functions\n(storage, recall, System 1 and System 2 reasoning) vital for preserving\nsemantic structure across inference and coordination layers. We prove that any\nsystem lacking the FMI will experience recursive coherence breakdown as it\nscales, arguing that common AI issues like misalignment, hallucination, and\ninstability are symptoms of this structural coherence loss. Unlike other\nfoundational principles, RCP uniquely captures the internal, recursive dynamics\nneeded for coherent, alignable intelligence, modeling semantic coherence under\nrecursion. This work significantly impacts AI alignment, advocating a shift\nfrom behavioral constraints to structural coherence, and offers a pathway for\nsafely generalizable, robustly coherent AI at scale.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9012\u5f52\u4e00\u81f4\u6027\u539f\u7406(RCP)\uff0c\u8ba4\u4e3a\u667a\u80fd\u7cfb\u7edf\u8981\u6709\u6548\u6269\u5c55\u5fc5\u987b\u5728\u9012\u5f52\u63a8\u7406\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u7ed3\u6784\u4e00\u81f4\u6027\uff0c\u5e76\u5f15\u5165\u529f\u80fd\u667a\u80fd\u6a21\u578b(FMI)\u4f5c\u4e3a\u6ee1\u8db3RCP\u7684\u552f\u4e00\u5df2\u77e5\u64cd\u4f5c\u7b26\uff0c\u7528\u4e8e\u89e3\u51b3AI\u5bf9\u9f50\u3001\u5e7b\u89c9\u7b49\u95ee\u9898", "motivation": "\u590d\u6742\u7cfb\u7edf\u5728\u6269\u5c55\u65f6\u5bb9\u6613\u5931\u53bb\u4e00\u81f4\u6027\uff0c\u73b0\u6709AI\u7cfb\u7edf\u5b58\u5728\u9519\u4f4d\u3001\u5e7b\u89c9\u548c\u4e0d\u7a33\u5b9a\u7b49\u95ee\u9898\uff0c\u9700\u8981\u4e00\u4e2a\u57fa\u7840\u6027\u539f\u7406\u6765\u786e\u4fdd\u667a\u80fd\u7cfb\u7edf\u5728\u4efb\u4f55\u89c4\u6a21\u4e0b\u90fd\u80fd\u4fdd\u6301\u8bed\u4e49\u4e00\u81f4\u6027\u548c\u7ed3\u6784\u5bf9\u9f50", "method": "\u63d0\u51fa\u9012\u5f52\u4e00\u81f4\u6027\u539f\u7406(RCP)\u4f5c\u4e3a\u57fa\u7840\u7ea6\u675f\uff0c\u5b9a\u4e49\u529f\u80fd\u667a\u80fd\u6a21\u578b(FMI)\u4f5c\u4e3a\u6ee1\u8db3RCP\u7684\u6700\u5c0f\u53ef\u7ec4\u5408\u67b6\u6784\uff0c\u5305\u542b\u5185\u90e8\u529f\u80fd(\u8bc4\u4f30\u3001\u5efa\u6a21\u3001\u9002\u5e94\u3001\u7a33\u5b9a\u6027\u3001\u5206\u89e3\u3001\u6865\u63a5)\u548c\u5916\u90e8\u529f\u80fd(\u5b58\u50a8\u3001\u56de\u5fc6\u3001\u7cfb\u7edf1\u548c\u7cfb\u7edf2\u63a8\u7406)", "result": "\u8bc1\u660e\u4e86\u7f3a\u4e4fFMI\u7684\u7cfb\u7edf\u5728\u6269\u5c55\u65f6\u4f1a\u7ecf\u5386\u9012\u5f52\u4e00\u81f4\u6027\u5d29\u6e83\uff0c\u8bc1\u660eRCP\u80fd\u591f\u72ec\u7279\u5730\u6355\u83b7\u4e00\u81f4\u3001\u53ef\u5bf9\u9f50\u667a\u80fd\u6240\u9700\u7684\u5185\u90e8\u9012\u5f52\u52a8\u6001\uff0c\u4e3a\u8bed\u4e49\u4e00\u81f4\u6027\u5efa\u6a21\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840", "conclusion": "RCP\u4e3aAI\u5bf9\u9f50\u63d0\u4f9b\u4e86\u4ece\u884c\u4e3a\u7ea6\u675f\u8f6c\u5411\u7ed3\u6784\u4e00\u81f4\u6027\u7684\u65b0\u8def\u5f84\uff0cFMI\u67b6\u6784\u4e3a\u6784\u5efa\u5b89\u5168\u53ef\u6cdb\u5316\u3001\u9c81\u68d2\u4e00\u81f4\u7684\u5927\u89c4\u6a21AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\uff0c\u5bf9AI\u5bf9\u9f50\u9886\u57df\u5177\u6709\u91cd\u8981\u5f71\u54cd"}}
{"id": "2507.16044", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.16044", "abs": "https://arxiv.org/abs/2507.16044", "authors": ["Meriem Mastouri", "Emna Ksontini", "Wael Kessentini"], "title": "Making REST APIs Agent-Ready: From OpenAPI to Model Context Protocol Servers for Tool-Augmented LLMs", "comment": null, "summary": "Large Language Models (LLMs) are evolving from passive text generators into\nactive agents that invoke external tools. To support this shift, scalable\nprotocols for tool integration are essential. The Model Context Protocol (MCP),\nintroduced by Anthropic in 2024, offers a schema-driven standard for dynamic\ntool discovery and invocation. Yet, building MCP servers remains manual and\nrepetitive, requiring developers to write glue code, handle authentication, and\nconfigure schemas by hand-replicating much of the integration effort MCP aims\nto eliminate.\n  This paper investigates whether MCP server construction can be meaningfully\nautomated. We begin by analyzing adoption trends: among 22,000+ MCP-tagged\nGitHub repositories created within six months of release, fewer than 5% include\nservers, typically small, single-maintainer projects dominated by repetitive\nscaffolding. To address this gap, we present AutoMCP, a compiler that generates\nMCP servers from OpenAPI 2.0/3.0 specifications. AutoMCP parses REST API\ndefinitions and produces complete server implementations, including schema\nregistration and authentication handling.\n  We evaluate AutoMCP on 50 real-world APIs spanning 5,066 endpoints across\nover 10 domains. From a stratified sample of 1,023 tool calls, 76.5% succeeded\nout of the box. Manual failure analysis revealed five recurring issues, all\nattributable to inconsistencies or omissions in the OpenAPI contracts. After\nminor fixes, averaging 19 lines of spec changes per API, AutoMCP achieved 99.9%\nsuccess.\n  Our findings (i) analyze MCP adoption and quantify the cost of manual server\ndevelopment, (ii) demonstrate that OpenAPI specifications, despite quality\nissues, enable near-complete MCP server automation, and (iii) contribute a\ncorpus of 5,066 callable tools along with insights on repairing common\nspecification flaws.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86AutoMCP\uff0c\u4e00\u4e2a\u80fd\u591f\u4eceOpenAPI\u89c4\u8303\u81ea\u52a8\u751f\u6210MCP\u670d\u52a1\u5668\u7684\u7f16\u8bd1\u5668\uff0c\u89e3\u51b3\u4e86\u624b\u52a8\u6784\u5efaMCP\u670d\u52a1\u5668\u7684\u91cd\u590d\u6027\u5de5\u4f5c\u95ee\u9898\uff0c\u572850\u4e2a\u771f\u5b9eAPI\u4e0a\u5b9e\u73b0\u4e8699.9%\u7684\u6210\u529f\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6b63\u4ece\u88ab\u52a8\u6587\u672c\u751f\u6210\u5668\u6f14\u53d8\u4e3a\u4e3b\u52a8\u8c03\u7528\u5916\u90e8\u5de5\u5177\u7684\u667a\u80fd\u4f53\uff0c\u4f46\u6784\u5efaMCP\u670d\u52a1\u5668\u4ecd\u7136\u9700\u8981\u5927\u91cf\u624b\u52a8\u5de5\u4f5c\uff0c\u5305\u62ec\u7f16\u5199\u80f6\u6c34\u4ee3\u7801\u3001\u5904\u7406\u8eab\u4efd\u9a8c\u8bc1\u548c\u624b\u52a8\u914d\u7f6e\u6a21\u5f0f\uff0c\u8fd9\u4e0eMCP\u65e8\u5728\u6d88\u9664\u96c6\u6210\u5de5\u4f5c\u7684\u76ee\u6807\u76f8\u77db\u76fe\u3002\u5206\u6790\u663e\u793a\u572822,000+\u4e2aMCP\u6807\u7b7e\u7684GitHub\u4ed3\u5e93\u4e2d\uff0c\u53ea\u6709\u4e0d\u52305%\u5305\u542b\u670d\u52a1\u5668\uff0c\u4e14\u591a\u4e3a\u5c0f\u578b\u5355\u7ef4\u62a4\u8005\u9879\u76ee\u3002", "method": "\u5f00\u53d1\u4e86AutoMCP\u7f16\u8bd1\u5668\uff0c\u80fd\u591f\u4eceOpenAPI 2.0/3.0\u89c4\u8303\u81ea\u52a8\u751f\u6210\u5b8c\u6574\u7684MCP\u670d\u52a1\u5668\u5b9e\u73b0\u3002\u8be5\u7f16\u8bd1\u5668\u89e3\u6790REST API\u5b9a\u4e49\u5e76\u751f\u6210\u5305\u62ec\u6a21\u5f0f\u6ce8\u518c\u548c\u8eab\u4efd\u9a8c\u8bc1\u5904\u7406\u5728\u5185\u7684\u5b8c\u6574\u670d\u52a1\u5668\u5b9e\u73b0\u3002\u572850\u4e2a\u771f\u5b9e\u4e16\u754cAPI\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u6db5\u76d65,066\u4e2a\u7aef\u70b9\u548c\u8d85\u8fc710\u4e2a\u9886\u57df\u3002", "result": "\u57281,023\u4e2a\u5de5\u5177\u8c03\u7528\u7684\u5206\u5c42\u6837\u672c\u4e2d\uff0c76.5%\u5f00\u7bb1\u5373\u7528\u6210\u529f\u3002\u901a\u8fc7\u624b\u52a8\u6545\u969c\u5206\u6790\u53d1\u73b0\u4e86\u4e94\u4e2a\u91cd\u590d\u51fa\u73b0\u7684\u95ee\u9898\uff0c\u90fd\u5f52\u56e0\u4e8eOpenAPI\u5408\u7ea6\u4e2d\u7684\u4e0d\u4e00\u81f4\u6216\u9057\u6f0f\u3002\u7ecf\u8fc7\u5e73\u5747\u6bcf\u4e2aAPI 19\u884c\u89c4\u8303\u66f4\u6539\u7684\u8f7b\u5fae\u4fee\u590d\u540e\uff0cAutoMCP\u5b9e\u73b0\u4e8699.9%\u7684\u6210\u529f\u7387\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff1a(1)\u5206\u6790\u4e86MCP\u7684\u91c7\u7528\u60c5\u51b5\u5e76\u91cf\u5316\u4e86\u624b\u52a8\u670d\u52a1\u5668\u5f00\u53d1\u7684\u6210\u672c\uff1b(2)\u8bc1\u660e\u4e86\u5c3d\u7ba1OpenAPI\u89c4\u8303\u5b58\u5728\u8d28\u91cf\u95ee\u9898\uff0c\u4f46\u4ecd\u80fd\u5b9e\u73b0\u8fd1\u4e4e\u5b8c\u5168\u7684MCP\u670d\u52a1\u5668\u81ea\u52a8\u5316\uff1b(3)\u8d21\u732e\u4e86\u5305\u542b5,066\u4e2a\u53ef\u8c03\u7528\u5de5\u5177\u7684\u8bed\u6599\u5e93\u4ee5\u53ca\u4fee\u590d\u5e38\u89c1\u89c4\u8303\u7f3a\u9677\u7684\u89c1\u89e3\u3002"}}
{"id": "2507.16291", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.16291", "abs": "https://arxiv.org/abs/2507.16291", "authors": ["Wenhao Li", "Selvakumar Manickam", "Yung-wey Chong", "Shankar Karuppayah"], "title": "Talking Like a Phisher: LLM-Based Attacks on Voice Phishing Classifiers", "comment": "Accepted by EAI ICDF2C 2025", "summary": "Voice phishing (vishing) remains a persistent threat in cybersecurity,\nexploiting human trust through persuasive speech. While machine learning\n(ML)-based classifiers have shown promise in detecting malicious call\ntranscripts, they remain vulnerable to adversarial manipulations that preserve\nsemantic content. In this study, we explore a novel attack vector where large\nlanguage models (LLMs) are leveraged to generate adversarial vishing\ntranscripts that evade detection while maintaining deceptive intent. We\nconstruct a systematic attack pipeline that employs prompt engineering and\nsemantic obfuscation to transform real-world vishing scripts using four\ncommercial LLMs. The generated transcripts are evaluated against multiple ML\nclassifiers trained on a real-world Korean vishing dataset (KorCCViD) with\nstatistical testing. Our experiments reveal that LLM-generated transcripts are\nboth practically and statistically effective against ML-based classifiers. In\nparticular, transcripts crafted by GPT-4o significantly reduce classifier\naccuracy (by up to 30.96%) while maintaining high semantic similarity, as\nmeasured by BERTScore. Moreover, these attacks are both time-efficient and\ncost-effective, with average generation times under 9 seconds and negligible\nfinancial cost per query. The results underscore the pressing need for more\nresilient vishing detection frameworks and highlight the imperative for LLM\nproviders to enforce stronger safeguards against prompt misuse in adversarial\nsocial engineering contexts.", "AI": {"tldr": "\u7814\u7a76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5bf9\u6297\u6027\u8bed\u97f3\u9493\u9c7c\u8f6c\u5f55\u6587\u672c\uff0c\u53d1\u73b0LLM\u80fd\u591f\u6709\u6548\u7ed5\u8fc7\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u7684\u68c0\u6d4b\uff0cGPT-4o\u751f\u6210\u7684\u6587\u672c\u53ef\u5c06\u5206\u7c7b\u5668\u51c6\u786e\u7387\u964d\u4f4e30.96%\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u68c0\u6d4b\u7cfb\u7edf\u7684\u8106\u5f31\u6027\u3002", "motivation": "\u8bed\u97f3\u9493\u9c7c\u653b\u51fb\u6301\u7eed\u5a01\u80c1\u7f51\u7edc\u5b89\u5168\uff0c\u867d\u7136\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u5728\u68c0\u6d4b\u6076\u610f\u901a\u8bdd\u8f6c\u5f55\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u5b83\u4eec\u5bb9\u6613\u53d7\u5230\u4fdd\u6301\u8bed\u4e49\u5185\u5bb9\u7684\u5bf9\u6297\u6027\u64cd\u4f5c\u7684\u653b\u51fb\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u80fd\u591f\u9003\u907f\u68c0\u6d4b\u540c\u65f6\u4fdd\u6301\u6b3a\u9a97\u610f\u56fe\u7684\u5bf9\u6297\u6027\u8bed\u97f3\u9493\u9c7c\u8f6c\u5f55\u6587\u672c\u8fd9\u4e00\u65b0\u578b\u653b\u51fb\u5411\u91cf\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u6027\u653b\u51fb\u7ba1\u9053\uff0c\u91c7\u7528\u63d0\u793a\u5de5\u7a0b\u548c\u8bed\u4e49\u6df7\u6dc6\u6280\u672f\uff0c\u4f7f\u7528\u56db\u4e2a\u5546\u4e1a\u5927\u8bed\u8a00\u6a21\u578b\u6765\u8f6c\u6362\u771f\u5b9e\u4e16\u754c\u7684\u8bed\u97f3\u9493\u9c7c\u811a\u672c\u3002\u5bf9\u751f\u6210\u7684\u8f6c\u5f55\u6587\u672c\u8fdb\u884c\u8bc4\u4f30\uff0c\u6d4b\u8bd5\u5176\u5bf9\u5728\u771f\u5b9e\u4e16\u754c\u97e9\u56fd\u8bed\u97f3\u9493\u9c7c\u6570\u636e\u96c6(KorCCViD)\u4e0a\u8bad\u7ec3\u7684\u591a\u4e2a\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u7684\u653b\u51fb\u6548\u679c\uff0c\u5e76\u8fdb\u884c\u7edf\u8ba1\u6d4b\u8bd5\u3002", "result": "LLM\u751f\u6210\u7684\u8f6c\u5f55\u6587\u672c\u5728\u5b9e\u9645\u548c\u7edf\u8ba1\u4e0a\u90fd\u5bf9\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u5206\u7c7b\u5668\u6709\u6548\u3002\u7279\u522b\u662fGPT-4o\u5236\u4f5c\u7684\u8f6c\u5f55\u6587\u672c\u663e\u8457\u964d\u4f4e\u4e86\u5206\u7c7b\u5668\u51c6\u786e\u7387\uff08\u6700\u9ad8\u964d\u4f4e30.96%\uff09\uff0c\u540c\u65f6\u901a\u8fc7BERTScore\u6d4b\u91cf\u4fdd\u6301\u4e86\u9ad8\u8bed\u4e49\u76f8\u4f3c\u6027\u3002\u8fd9\u4e9b\u653b\u51fb\u65e2\u7701\u65f6\u53c8\u7ecf\u6d4e\uff0c\u5e73\u5747\u751f\u6210\u65f6\u95f4\u4e0d\u52309\u79d2\uff0c\u6bcf\u6b21\u67e5\u8be2\u7684\u8d22\u52a1\u6210\u672c\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002", "conclusion": "\u7ed3\u679c\u5f3a\u8c03\u4e86\u5f00\u53d1\u66f4\u5177\u5f39\u6027\u7684\u8bed\u97f3\u9493\u9c7c\u68c0\u6d4b\u6846\u67b6\u7684\u8feb\u5207\u9700\u8981\uff0c\u5e76\u7a81\u51fa\u4e86LLM\u63d0\u4f9b\u5546\u5728\u5bf9\u6297\u6027\u793e\u4f1a\u5de5\u7a0b\u73af\u5883\u4e2d\u9488\u5bf9\u63d0\u793a\u6ee5\u7528\u5b9e\u65bd\u66f4\u5f3a\u5b89\u5168\u4fdd\u969c\u63aa\u65bd\u7684\u5fc5\u8981\u6027\u3002\u5f53\u524d\u7684\u673a\u5668\u5b66\u4e60\u68c0\u6d4b\u7cfb\u7edf\u9762\u4e34\u4e25\u91cd\u7684\u5bf9\u6297\u6027\u653b\u51fb\u5a01\u80c1\uff0c\u9700\u8981\u66f4\u5f3a\u7684\u9632\u5fa1\u673a\u5236\u3002"}}
{"id": "2507.15885", "categories": ["cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15885", "abs": "https://arxiv.org/abs/2507.15885", "authors": ["Pierluca D'Oro", "Caley Drooff", "Joy Chen", "Joseph Tighe"], "title": "ADEPTS: A Capability Framework for Human-Centered Agent Design", "comment": null, "summary": "Large language models have paved the way to powerful and flexible AI agents,\nassisting humans by increasingly integrating into their daily life. This\nflexibility, potential, and growing adoption demands a holistic and\ncross-disciplinary approach to developing, monitoring and discussing the\ncapabilities required for agent-driven user experiences. However, current\nguidance on human-centered AI agent development is scattered: UX heuristics\nfocus on interface behaviors, engineering taxonomies describe internal\npipelines, and ethics checklists address high-level governance. There is no\nconcise, user-facing vocabulary that tells teams what an agent should\nfundamentally be able to do. We introduce ADEPTS, a capability framework\ndefining a set of core user-facing capabilities to provide unified guidance\naround the development of AI agents. ADEPTS is based on six principles for\nhuman-centered agent design, that express the minimal, user-facing capabilities\nan AI agent should demonstrate to be understandable, controllable and\ntrustworthy in everyday use. ADEPTS complements existing frameworks and\ntaxonomies; differently from them, it sits at the interface between technical\nand experience development. By presenting ADEPTS, we aim to condense complex\nAI-UX requirements into a compact framework that is actionable guidance for AI\nresearchers, designers, engineers, and policy reviewers alike. We believe\nADEPTS has the potential of accelerating the improvement of user-relevant agent\ncapabilities, of easing the design of experiences that take advantage of those\ncapabilities, and of providing a shared language to track and discuss progress\naround the development of AI agents.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86ADEPTS\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u9762\u5411\u7528\u6237\u7684AI\u667a\u80fd\u4f53\u80fd\u529b\u6846\u67b6\uff0c\u65e8\u5728\u4e3aAI\u667a\u80fd\u4f53\u5f00\u53d1\u63d0\u4f9b\u7edf\u4e00\u6307\u5bfc\uff0c\u5f25\u5408\u6280\u672f\u5f00\u53d1\u4e0e\u7528\u6237\u4f53\u9a8c\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "motivation": "\u5f53\u524dAI\u667a\u80fd\u4f53\u5f00\u53d1\u6307\u5bfc\u5206\u6563\u4e14\u7f3a\u4e4f\u7edf\u4e00\u6027\uff1aUX\u542f\u53d1\u5f0f\u65b9\u6cd5\u5173\u6ce8\u754c\u9762\u884c\u4e3a\uff0c\u5de5\u7a0b\u5206\u7c7b\u6cd5\u63cf\u8ff0\u5185\u90e8\u7ba1\u9053\uff0c\u4f26\u7406\u68c0\u67e5\u8868\u5904\u7406\u9ad8\u5c42\u6cbb\u7406\u95ee\u9898\u3002\u7f3a\u5c11\u4e00\u4e2a\u7b80\u6d01\u7684\u3001\u9762\u5411\u7528\u6237\u7684\u8bcd\u6c47\u8868\u6765\u6307\u5bfc\u56e2\u961f\u6784\u5efa\u667a\u80fd\u4f53\u7684\u57fa\u672c\u80fd\u529b\u3002\u9700\u8981\u4e00\u4e2a\u6574\u4f53\u6027\u548c\u8de8\u5b66\u79d1\u7684\u65b9\u6cd5\u6765\u5f00\u53d1\u53ef\u7406\u89e3\u3001\u53ef\u63a7\u5236\u548c\u53ef\u4fe1\u8d56\u7684AI\u667a\u80fd\u4f53\u3002", "method": "\u57fa\u4e8e\u516d\u4e2a\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u667a\u80fd\u4f53\u8bbe\u8ba1\u539f\u5219\uff0c\u5f00\u53d1\u4e86ADEPTS\u80fd\u529b\u6846\u67b6\u3002\u8be5\u6846\u67b6\u5b9a\u4e49\u4e86\u4e00\u7ec4\u6838\u5fc3\u7684\u9762\u5411\u7528\u6237\u7684\u80fd\u529b\uff0c\u4f4d\u4e8e\u6280\u672f\u5f00\u53d1\u548c\u4f53\u9a8c\u5f00\u53d1\u7684\u63a5\u53e3\u5904\uff0c\u4e3aAI\u7814\u7a76\u4eba\u5458\u3001\u8bbe\u8ba1\u5e08\u3001\u5de5\u7a0b\u5e08\u548c\u653f\u7b56\u5ba1\u67e5\u8005\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\u3002", "result": "ADEPTS\u6846\u67b6\u6210\u529f\u5c06\u590d\u6742\u7684AI-UX\u9700\u6c42\u6d53\u7f29\u4e3a\u4e00\u4e2a\u7d27\u51d1\u7684\u6846\u67b6\uff0c\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u6307\u5bfc\u8bed\u8a00\u3002\u8be5\u6846\u67b6\u8865\u5145\u4e86\u73b0\u6709\u7684\u6846\u67b6\u548c\u5206\u7c7b\u6cd5\uff0c\u4e13\u95e8\u9488\u5bf9\u7528\u6237\u9762\u5411\u7684\u667a\u80fd\u4f53\u80fd\u529b\u8fdb\u884c\u4e86\u5b9a\u4e49\u548c\u7ec4\u7ec7\u3002", "conclusion": "ADEPTS\u6846\u67b6\u6709\u6f5c\u529b\u52a0\u901f\u7528\u6237\u76f8\u5173\u667a\u80fd\u4f53\u80fd\u529b\u7684\u6539\u8fdb\uff0c\u7b80\u5316\u5229\u7528\u8fd9\u4e9b\u80fd\u529b\u7684\u4f53\u9a8c\u8bbe\u8ba1\uff0c\u5e76\u4e3a\u8ddf\u8e2a\u548c\u8ba8\u8bbaAI\u667a\u80fd\u4f53\u5f00\u53d1\u8fdb\u5c55\u63d0\u4f9b\u5171\u540c\u8bed\u8a00\u3002\u8be5\u6846\u67b6\u4e3aAI\u667a\u80fd\u4f53\u7684\u4eba\u673a\u4ea4\u4e92\u5f00\u53d1\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u8df5\u6307\u5bfc\u3002"}}
{"id": "2507.16063", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16063", "abs": "https://arxiv.org/abs/2507.16063", "authors": ["Yousab Grees", "Polina Iaremchuk", "Ramtin Ehsani", "Esteban Parra", "Preetha Chatterjee", "Sonia Haiduc"], "title": "AI-Powered Commit Explorer (APCE)", "comment": null, "summary": "Commit messages in a version control system provide valuable information for\ndevelopers regarding code changes in software systems. Commit messages can be\nthe only source of information left for future developers describing what was\nchanged and why. However, writing high-quality commit messages is often\nneglected in practice. Large Language Model (LLM) generated commit messages\nhave emerged as a way to mitigate this issue. We introduce the AI-Powered\nCommit Explorer (APCE), a tool to support developers and researchers in the use\nand study of LLM-generated commit messages. APCE gives researchers the option\nto store different prompts for LLMs and provides an additional evaluation\nprompt that can further enhance the commit message provided by LLMs. APCE also\nprovides researchers with a straightforward mechanism for automated and human\nevaluation of LLM-generated messages. Demo link https://youtu.be/zYrJ9s6sZvo", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86AI-Powered Commit Explorer (APCE)\u5de5\u5177\uff0c\u7528\u4e8e\u652f\u6301\u5f00\u53d1\u8005\u548c\u7814\u7a76\u4eba\u5458\u4f7f\u7528\u548c\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u63d0\u4ea4\u6d88\u606f\uff0c\u63d0\u4f9b\u4e86\u63d0\u793a\u5b58\u50a8\u3001\u6d88\u606f\u8bc4\u4f30\u548c\u81ea\u52a8\u5316\u8bc4\u4f30\u673a\u5236\u3002", "motivation": "\u5728\u7248\u672c\u63a7\u5236\u7cfb\u7edf\u4e2d\uff0c\u63d0\u4ea4\u6d88\u606f\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u5173\u4e8e\u4ee3\u7801\u53d8\u66f4\u7684\u5b9d\u8d35\u4fe1\u606f\uff0c\u4f46\u9ad8\u8d28\u91cf\u63d0\u4ea4\u6d88\u606f\u7684\u7f16\u5199\u5728\u5b9e\u8df5\u4e2d\u7ecf\u5e38\u88ab\u5ffd\u89c6\u3002\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u63d0\u4ea4\u6d88\u606f\u6210\u4e3a\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u4f46\u9700\u8981\u5de5\u5177\u6765\u652f\u6301\u5176\u4f7f\u7528\u548c\u7814\u7a76\u3002", "method": "\u5f00\u53d1\u4e86AI-Powered Commit Explorer (APCE)\u5de5\u5177\uff0c\u8be5\u5de5\u5177\u5141\u8bb8\u7814\u7a76\u4eba\u5458\u5b58\u50a8\u4e0d\u540c\u7684LLM\u63d0\u793a\uff0c\u63d0\u4f9b\u989d\u5916\u7684\u8bc4\u4f30\u63d0\u793a\u6765\u589e\u5f3aLLM\u751f\u6210\u7684\u63d0\u4ea4\u6d88\u606f\uff0c\u5e76\u4e3aLLM\u751f\u6210\u6d88\u606f\u7684\u81ea\u52a8\u5316\u548c\u4eba\u5de5\u8bc4\u4f30\u63d0\u4f9b\u76f4\u63a5\u7684\u673a\u5236\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86APCE\u5de5\u5177\uff0c\u8be5\u5de5\u5177\u80fd\u591f\u5b58\u50a8\u591a\u79cdLLM\u63d0\u793a\u3001\u63d0\u4f9b\u8bc4\u4f30\u63d0\u793a\u529f\u80fd\u3001\u652f\u6301\u81ea\u52a8\u5316\u548c\u4eba\u5de5\u8bc4\u4f30LLM\u751f\u6210\u7684\u63d0\u4ea4\u6d88\u606f\uff0c\u5e76\u63d0\u4f9b\u4e86\u6f14\u793a\u94fe\u63a5\u5c55\u793a\u5de5\u5177\u529f\u80fd\u3002", "conclusion": "APCE\u5de5\u5177\u4e3a\u5f00\u53d1\u8005\u548c\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u4e00\u4e2acomprehensive\u7684\u5e73\u53f0\u6765\u4f7f\u7528\u548c\u7814\u7a76LLM\u751f\u6210\u7684\u63d0\u4ea4\u6d88\u606f\uff0c\u901a\u8fc7\u63d0\u4f9b\u63d0\u793a\u7ba1\u7406\u3001\u6d88\u606f\u589e\u5f3a\u548c\u8bc4\u4f30\u673a\u5236\uff0c\u6709\u6548\u652f\u6301\u4e86\u9ad8\u8d28\u91cf\u63d0\u4ea4\u6d88\u606f\u7684\u751f\u6210\u548c\u8bc4\u4f30\u5de5\u4f5c\u3002"}}
{"id": "2507.16329", "categories": ["cs.CR", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.16329", "abs": "https://arxiv.org/abs/2507.16329", "authors": ["Boheng Li", "Junjie Wang", "Yiming Li", "Zhiyang Hu", "Leyi Qi", "Jianshuo Dong", "Run Wang", "Han Qiu", "Zhan Qin", "Tianwei Zhang"], "title": "DREAM: Scalable Red Teaming for Text-to-Image Generative Systems via Distribution Modeling", "comment": "Preprint version. Under review", "summary": "Despite the integration of safety alignment and external filters,\ntext-to-image (T2I) generative models are still susceptible to producing\nharmful content, such as sexual or violent imagery. This raises serious\nconcerns about unintended exposure and potential misuse. Red teaming, which\naims to proactively identify diverse prompts that can elicit unsafe outputs\nfrom the T2I system (including the core generative model as well as potential\nexternal safety filters and other processing components), is increasingly\nrecognized as an essential method for assessing and improving safety before\nreal-world deployment. Yet, existing automated red teaming approaches often\ntreat prompt discovery as an isolated, prompt-level optimization task, which\nlimits their scalability, diversity, and overall effectiveness. To bridge this\ngap, in this paper, we propose DREAM, a scalable red teaming framework to\nautomatically uncover diverse problematic prompts from a given T2I system.\nUnlike most prior works that optimize prompts individually, DREAM directly\nmodels the probabilistic distribution of the target system's problematic\nprompts, which enables explicit optimization over both effectiveness and\ndiversity, and allows efficient large-scale sampling after training. To achieve\nthis without direct access to representative training samples, we draw\ninspiration from energy-based models and reformulate the objective into simple\nand tractable objectives. We further introduce GC-SPSA, an efficient\noptimization algorithm that provide stable gradient estimates through the long\nand potentially non-differentiable T2I pipeline. The effectiveness of DREAM is\nvalidated through extensive experiments, demonstrating that it surpasses 9\nstate-of-the-art baselines by a notable margin across a broad range of T2I\nmodels and safety filters in terms of prompt success rate and diversity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDREAM\u6846\u67b6\uff0c\u901a\u8fc7\u5efa\u6a21\u95ee\u9898\u63d0\u793a\u8bcd\u7684\u6982\u7387\u5206\u5e03\u6765\u81ea\u52a8\u53d1\u73b0\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u6a21\u578b\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5728\u6210\u529f\u7387\u548c\u591a\u6837\u6027\u65b9\u9762\u90fd\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7684\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u6a21\u578b\u5c3d\u7ba1\u96c6\u6210\u4e86\u5b89\u5168\u5bf9\u9f50\u548c\u5916\u90e8\u8fc7\u6ee4\u5668\uff0c\u4ecd\u7136\u5bb9\u6613\u4ea7\u751f\u6709\u5bb3\u5185\u5bb9\uff08\u5982\u6027\u6216\u66b4\u529b\u56fe\u50cf\uff09\u3002\u73b0\u6709\u7684\u81ea\u52a8\u5316\u7ea2\u961f\u6d4b\u8bd5\u65b9\u6cd5\u5c06\u63d0\u793a\u8bcd\u53d1\u73b0\u89c6\u4e3a\u5b64\u7acb\u7684\u63d0\u793a\u8bcd\u7ea7\u4f18\u5316\u4efb\u52a1\uff0c\u9650\u5236\u4e86\u5176\u53ef\u6269\u5c55\u6027\u3001\u591a\u6837\u6027\u548c\u6574\u4f53\u6709\u6548\u6027\u3002", "method": "\u63d0\u51faDREAM\u6846\u67b6\uff0c\u76f4\u63a5\u5efa\u6a21\u76ee\u6807\u7cfb\u7edf\u95ee\u9898\u63d0\u793a\u8bcd\u7684\u6982\u7387\u5206\u5e03\uff0c\u800c\u975e\u5355\u72ec\u4f18\u5316\u63d0\u793a\u8bcd\u3002\u501f\u9274\u80fd\u91cf\u6a21\u578b\u601d\u60f3\uff0c\u5c06\u76ee\u6807\u91cd\u65b0\u8868\u8ff0\u4e3a\u7b80\u5355\u53ef\u5904\u7406\u7684\u76ee\u6807\u51fd\u6570\u3002\u5f15\u5165GC-SPSA\u4f18\u5316\u7b97\u6cd5\uff0c\u901a\u8fc7\u957f\u4e14\u53ef\u80fd\u4e0d\u53ef\u5fae\u7684T2I\u7ba1\u9053\u63d0\u4f9b\u7a33\u5b9a\u7684\u68af\u5ea6\u4f30\u8ba1\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\uff0cDREAM\u5728\u5404\u79cdT2I\u6a21\u578b\u548c\u5b89\u5168\u8fc7\u6ee4\u5668\u4e0a\uff0c\u5728\u63d0\u793a\u8bcd\u6210\u529f\u7387\u548c\u591a\u6837\u6027\u65b9\u9762\u663e\u8457\u8d85\u8d8a\u4e869\u4e2a\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "DREAM\u6846\u67b6\u901a\u8fc7\u76f4\u63a5\u5efa\u6a21\u95ee\u9898\u63d0\u793a\u8bcd\u7684\u6982\u7387\u5206\u5e03\uff0c\u5b9e\u73b0\u4e86\u5bf9\u6709\u6548\u6027\u548c\u591a\u6837\u6027\u7684\u663e\u5f0f\u4f18\u5316\uff0c\u5e76\u652f\u6301\u8bad\u7ec3\u540e\u7684\u9ad8\u6548\u5927\u89c4\u6a21\u91c7\u6837\uff0c\u4e3aT2I\u7cfb\u7edf\u7684\u5b89\u5168\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u7ea2\u961f\u6d4b\u8bd5\u65b9\u6cd5\u3002"}}
{"id": "2507.15895", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15895", "abs": "https://arxiv.org/abs/2507.15895", "authors": ["Lisa Dargasz"], "title": "Integrating Reason-Based Moral Decision-Making in the Reinforcement Learning Architecture", "comment": "Master's thesis, April 2025, 122 pages", "summary": "Reinforcement Learning is a machine learning methodology that has\ndemonstrated strong performance across a variety of tasks. In particular, it\nplays a central role in the development of artificial autonomous agents. As\nthese agents become increasingly capable, market readiness is rapidly\napproaching, which means those agents, for example taking the form of humanoid\nrobots or autonomous cars, are poised to transition from laboratory prototypes\nto autonomous operation in real-world environments. This transition raises\nconcerns leading to specific requirements for these systems - among them, the\nrequirement that they are designed to behave ethically. Crucially, research\ndirected toward building agents that fulfill the requirement to behave\nethically - referred to as artificial moral agents(AMAs) - has to address a\nrange of challenges at the intersection of computer science and philosophy.\nThis study explores the development of reason-based artificial moral agents\n(RBAMAs). RBAMAs are build on an extension of the reinforcement learning\narchitecture to enable moral decision-making based on sound normative\nreasoning, which is achieved by equipping the agent with the capacity to learn\na reason-theory - a theory which enables it to process morally relevant\npropositions to derive moral obligations - through case-based feedback. They\nare designed such that they adapt their behavior to ensure conformance to these\nobligations while they pursue their designated tasks. These features contribute\nto the moral justifiability of the their actions, their moral robustness, and\ntheir moral trustworthiness, which proposes the extended architecture as a\nconcrete and deployable framework for the development of AMAs that fulfills key\nethical desiderata. This study presents a first implementation of an RBAMA and\ndemonstrates the potential of RBAMAs in initial experiments.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u57fa\u4e8e\u63a8\u7406\u7684\u4eba\u5de5\u9053\u5fb7\u667a\u80fd\u4f53\uff08RBAMAs\uff09\uff0c\u901a\u8fc7\u6269\u5c55\u5f3a\u5316\u5b66\u4e60\u67b6\u6784\u6765\u5b9e\u73b0\u57fa\u4e8e\u89c4\u8303\u63a8\u7406\u7684\u9053\u5fb7\u51b3\u7b56\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u5b66\u4e60\u63a8\u7406\u7406\u8bba\u5e76\u5728\u6267\u884c\u4efb\u52a1\u65f6\u9075\u5b88\u9053\u5fb7\u4e49\u52a1\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u4f53\uff08\u5982\u4eba\u5f62\u673a\u5668\u4eba\u3001\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\uff09\u5373\u5c06\u4ece\u5b9e\u9a8c\u5ba4\u539f\u578b\u8f6c\u5411\u771f\u5b9e\u4e16\u754c\u7684\u81ea\u4e3b\u8fd0\u884c\uff0c\u8feb\u5207\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5728\u6267\u884c\u4efb\u52a1\u65f6\u8868\u73b0\u51fa\u9053\u5fb7\u884c\u4e3a\u7684\u4eba\u5de5\u9053\u5fb7\u667a\u80fd\u4f53\uff0c\u8fd9\u8981\u6c42\u89e3\u51b3\u8ba1\u7b97\u673a\u79d1\u5b66\u548c\u54f2\u5b66\u4ea4\u53c9\u9886\u57df\u7684\u4e00\u7cfb\u5217\u6311\u6218\u3002", "method": "\u901a\u8fc7\u6269\u5c55\u5f3a\u5316\u5b66\u4e60\u67b6\u6784\uff0c\u4e3a\u667a\u80fd\u4f53\u914d\u5907\u5b66\u4e60\u63a8\u7406\u7406\u8bba\u7684\u80fd\u529b\uff0c\u4f7f\u5176\u80fd\u591f\u5904\u7406\u9053\u5fb7\u76f8\u5173\u547d\u9898\u5e76\u63a8\u5bfc\u51fa\u9053\u5fb7\u4e49\u52a1\u3002\u667a\u80fd\u4f53\u901a\u8fc7\u57fa\u4e8e\u6848\u4f8b\u7684\u53cd\u9988\u5b66\u4e60\u63a8\u7406\u7406\u8bba\uff0c\u5e76\u8c03\u6574\u884c\u4e3a\u4ee5\u786e\u4fdd\u5728\u6267\u884c\u6307\u5b9a\u4efb\u52a1\u65f6\u7b26\u5408\u8fd9\u4e9b\u9053\u5fb7\u4e49\u52a1\u3002", "result": "\u7814\u7a76\u5c55\u793a\u4e86RBAMA\u7684\u9996\u6b21\u5b9e\u73b0\uff0c\u5e76\u901a\u8fc7\u521d\u6b65\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u6f5c\u529b\u3002\u8be5\u67b6\u6784\u80fd\u591f\u63d0\u9ad8\u667a\u80fd\u4f53\u884c\u4e3a\u7684\u9053\u5fb7\u53ef\u8fa9\u62a4\u6027\u3001\u9053\u5fb7\u9c81\u68d2\u6027\u548c\u9053\u5fb7\u53ef\u4fe1\u5ea6\u3002", "conclusion": "\u57fa\u4e8e\u63a8\u7406\u7684\u4eba\u5de5\u9053\u5fb7\u667a\u80fd\u4f53\uff08RBAMAs\uff09\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5177\u4f53\u4e14\u53ef\u90e8\u7f72\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5f00\u53d1\u6ee1\u8db3\u5173\u952e\u4f26\u7406\u8981\u6c42\u7684\u4eba\u5de5\u9053\u5fb7\u667a\u80fd\u4f53\uff0c\u4e3a\u4eba\u5de5\u667a\u80fd\u4f53\u7684\u9053\u5fb7\u51b3\u7b56\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.16166", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.16166", "abs": "https://arxiv.org/abs/2507.16166", "authors": ["Nasir U. Eisty", "David E. Bernholdt", "Alex Koufos", "David J. Luet", "Miranda Mundt"], "title": "Ten Essential Guidelines for Building High-Quality Research Software", "comment": null, "summary": "High-quality research software is a cornerstone of modern scientific\nprogress, enabling researchers to analyze complex data, simulate phenomena, and\nshare reproducible results. However, creating such software requires adherence\nto best practices that ensure robustness, usability, and sustainability. This\npaper presents ten guidelines for producing high-quality research software,\ncovering every stage of the development lifecycle. These guidelines emphasize\nthe importance of planning, writing clean and readable code, using version\ncontrol, and implementing thorough testing strategies. Additionally, they\naddress key principles such as modular design, reproducibility, performance\noptimization, and long-term maintenance. The paper also highlights the role of\ndocumentation and community engagement in enhancing software usability and\nimpact. By following these guidelines, researchers can create software that\nadvances their scientific objectives and contributes to a broader ecosystem of\nreliable and reusable research tools. This work serves as a practical resource\nfor researchers and developers aiming to elevate the quality and impact of\ntheir research software.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5341\u4e2a\u5f00\u53d1\u9ad8\u8d28\u91cf\u79d1\u7814\u8f6f\u4ef6\u7684\u6307\u5bfc\u539f\u5219\uff0c\u6db5\u76d6\u4ece\u89c4\u5212\u5230\u7ef4\u62a4\u7684\u5b8c\u6574\u5f00\u53d1\u751f\u547d\u5468\u671f\uff0c\u65e8\u5728\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u521b\u5efa\u66f4\u53ef\u9760\u3001\u53ef\u7528\u548c\u53ef\u6301\u7eed\u7684\u79d1\u7814\u5de5\u5177\u3002", "motivation": "\u73b0\u4ee3\u79d1\u5b66\u7814\u7a76\u4e25\u91cd\u4f9d\u8d56\u9ad8\u8d28\u91cf\u7684\u7814\u7a76\u8f6f\u4ef6\u6765\u5206\u6790\u590d\u6742\u6570\u636e\u3001\u6a21\u62df\u73b0\u8c61\u548c\u5206\u4eab\u53ef\u91cd\u73b0\u7684\u7ed3\u679c\uff0c\u4f46\u521b\u5efa\u6b64\u7c7b\u8f6f\u4ef6\u9700\u8981\u9075\u5faa\u786e\u4fdd\u9c81\u68d2\u6027\u3001\u53ef\u7528\u6027\u548c\u53ef\u6301\u7eed\u6027\u7684\u6700\u4f73\u5b9e\u8df5\uff0c\u56e0\u6b64\u9700\u8981\u7cfb\u7edf\u6027\u7684\u6307\u5bfc\u539f\u5219\u3002", "method": "\u63d0\u51fa\u6db5\u76d6\u8f6f\u4ef6\u5f00\u53d1\u751f\u547d\u5468\u671f\u5404\u4e2a\u9636\u6bb5\u7684\u5341\u4e2a\u6307\u5bfc\u539f\u5219\uff0c\u5305\u62ec\uff1a\u89c4\u5212\u3001\u7f16\u5199\u6e05\u6d01\u53ef\u8bfb\u7684\u4ee3\u7801\u3001\u4f7f\u7528\u7248\u672c\u63a7\u5236\u3001\u5b9e\u65bd\u5168\u9762\u7684\u6d4b\u8bd5\u7b56\u7565\u3001\u6a21\u5757\u5316\u8bbe\u8ba1\u3001\u53ef\u91cd\u73b0\u6027\u3001\u6027\u80fd\u4f18\u5316\u3001\u957f\u671f\u7ef4\u62a4\u3001\u6587\u6863\u7f16\u5199\u548c\u793e\u533a\u53c2\u4e0e\u7b49\u5173\u952e\u8981\u7d20\u3002", "result": "\u5f62\u6210\u4e86\u4e00\u5957\u5b8c\u6574\u7684\u79d1\u7814\u8f6f\u4ef6\u5f00\u53d1\u6700\u4f73\u5b9e\u8df5\u6846\u67b6\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8d44\u6e90\u6307\u5357\uff0c\u80fd\u591f\u5e2e\u52a9\u4ed6\u4eec\u521b\u5efa\u65e2\u63a8\u8fdb\u79d1\u5b66\u76ee\u6807\u53c8\u5bf9\u66f4\u5e7f\u6cdb\u7684\u53ef\u9760\u53ef\u91cd\u7528\u7814\u7a76\u5de5\u5177\u751f\u6001\u7cfb\u7edf\u6709\u8d21\u732e\u7684\u8f6f\u4ef6\u3002", "conclusion": "\u901a\u8fc7\u9075\u5faa\u8fd9\u4e9b\u6307\u5bfc\u539f\u5219\uff0c\u7814\u7a76\u4eba\u5458\u80fd\u591f\u521b\u5efa\u9ad8\u8d28\u91cf\u7684\u79d1\u7814\u8f6f\u4ef6\uff0c\u4e0d\u4ec5\u5b9e\u73b0\u5176\u79d1\u5b66\u76ee\u6807\uff0c\u8fd8\u80fd\u4e3a\u6784\u5efa\u53ef\u9760\u548c\u53ef\u91cd\u7528\u7684\u7814\u7a76\u5de5\u5177\u751f\u6001\u7cfb\u7edf\u505a\u51fa\u8d21\u732e\uff0c\u4ece\u800c\u63d0\u5347\u79d1\u7814\u8f6f\u4ef6\u7684\u8d28\u91cf\u548c\u5f71\u54cd\u529b\u3002"}}
{"id": "2507.16372", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16372", "abs": "https://arxiv.org/abs/2507.16372", "authors": ["Tian Dong", "Yan Meng", "Shaofeng Li", "Guoxing Chen", "Zhen Liu", "Haojin Zhu"], "title": "Depth Gives a False Sense of Privacy: LLM Internal States Inversion", "comment": "Accepted by USENIX Security 2025. Please cite this paper as \"Tian\n  Dong, Yan Meng, Shaofeng Li, Guoxing Chen, Zhen Liu, Haojin Zhu. Depth Gives\n  a False Sense of Privacy: LLM Internal States Inversion. In the 34th USENIX\n  Security Symposium (USENIX Security '25).\"", "summary": "Large Language Models (LLMs) are increasingly integrated into daily routines,\nyet they raise significant privacy and safety concerns. Recent research\nproposes collaborative inference, which outsources the early-layer inference to\nensure data locality, and introduces model safety auditing based on inner\nneuron patterns. Both techniques expose the LLM's Internal States (ISs), which\nare traditionally considered irreversible to inputs due to optimization\nchallenges and the highly abstract representations in deep layers. In this\nwork, we challenge this assumption by proposing four inversion attacks that\nsignificantly improve the semantic similarity and token matching rate of\ninverted inputs. Specifically, we first develop two white-box\noptimization-based attacks tailored for low-depth and high-depth ISs. These\nattacks avoid local minima convergence, a limitation observed in prior work,\nthrough a two-phase inversion process. Then, we extend our optimization attack\nunder more practical black-box weight access by leveraging the transferability\nbetween the source and the derived LLMs. Additionally, we introduce a\ngeneration-based attack that treats inversion as a translation task, employing\nan inversion model to reconstruct inputs. Extensive evaluation of short and\nlong prompts from medical consulting and coding assistance datasets and 6 LLMs\nvalidates the effectiveness of our inversion attacks. Notably, a 4,112-token\nlong medical consulting prompt can be nearly perfectly inverted with 86.88 F1\ntoken matching from the middle layer of Llama-3 model. Finally, we evaluate\nfour practical defenses that we found cannot perfectly prevent ISs inversion\nand draw conclusions for future mitigation design.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u56db\u79cd\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u72b6\u6001\u7684\u53cd\u6f14\u653b\u51fb\u65b9\u6cd5\uff0c\u6311\u6218\u4e86\u4f20\u7edf\u8ba4\u4e3a\u5185\u90e8\u72b6\u6001\u4e0d\u53ef\u9006\u7684\u5047\u8bbe\uff0c\u5e76\u8bc1\u660e\u4e86\u8fd9\u4e9b\u653b\u51fb\u80fd\u591f\u6709\u6548\u6062\u590d\u539f\u59cb\u8f93\u5165\uff0c\u5bf9\u73b0\u6709\u9690\u79c1\u4fdd\u62a4\u673a\u5236\u6784\u6210\u5a01\u80c1\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u534f\u4f5c\u63a8\u7406\u548c\u5b89\u5168\u5ba1\u8ba1\u4e2d\u4f1a\u66b4\u9732\u5185\u90e8\u72b6\u6001\uff0c\u4f20\u7edf\u89c2\u70b9\u8ba4\u4e3a\u8fd9\u4e9b\u5185\u90e8\u72b6\u6001\u7531\u4e8e\u4f18\u5316\u56f0\u96be\u548c\u6df1\u5c42\u62bd\u8c61\u8868\u793a\u800c\u65e0\u6cd5\u9006\u5411\u6062\u590d\u539f\u59cb\u8f93\u5165\u3002\u7136\u800c\uff0c\u8fd9\u4e00\u5047\u8bbe\u7684\u5b89\u5168\u6027\u9700\u8981\u88ab\u91cd\u65b0\u5ba1\u89c6\u548c\u9a8c\u8bc1\u3002", "method": "\u63d0\u51fa\u56db\u79cd\u53cd\u6f14\u653b\u51fb\u65b9\u6cd5\uff1a1\uff09\u9488\u5bf9\u6d45\u5c42\u548c\u6df1\u5c42\u5185\u90e8\u72b6\u6001\u7684\u4e24\u79cd\u767d\u76d2\u4f18\u5316\u653b\u51fb\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u53cd\u6f14\u8fc7\u7a0b\u907f\u514d\u5c40\u90e8\u6700\u5c0f\u503c\u6536\u655b\uff1b2\uff09\u5229\u7528\u6e90\u6a21\u578b\u548c\u884d\u751f\u6a21\u578b\u95f4\u53ef\u8fc1\u79fb\u6027\u7684\u9ed1\u76d2\u653b\u51fb\uff1b3\uff09\u5c06\u53cd\u6f14\u89c6\u4e3a\u7ffb\u8bd1\u4efb\u52a1\u7684\u751f\u6210\u5f0f\u653b\u51fb\uff0c\u4f7f\u7528\u53cd\u6f14\u6a21\u578b\u91cd\u6784\u8f93\u5165\u3002", "result": "\u5728\u533b\u7597\u54a8\u8be2\u548c\u7f16\u7a0b\u8f85\u52a9\u6570\u636e\u96c6\u4e0a\u5bf96\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5e7f\u6cdb\u8bc4\u4f30\uff0c\u8bc1\u660e\u4e86\u653b\u51fb\u7684\u6709\u6548\u6027\u3002\u7279\u522b\u5730\uff0c\u4e00\u4e2a4112\u4e2atoken\u7684\u957f\u533b\u7597\u54a8\u8be2\u63d0\u793a\u80fd\u591f\u4eceLlama-3\u6a21\u578b\u7684\u4e2d\u95f4\u5c42\u4ee586.88\u7684F1 token\u5339\u914d\u7387\u88ab\u8fd1\u4e4e\u5b8c\u7f8e\u5730\u53cd\u6f14\u3002", "conclusion": "\u73b0\u6709\u7684\u56db\u79cd\u5b9e\u7528\u9632\u5fa1\u63aa\u65bd\u65e0\u6cd5\u5b8c\u5168\u963b\u6b62\u5185\u90e8\u72b6\u6001\u53cd\u6f14\u653b\u51fb\uff0c\u8868\u660e\u5f53\u524d\u7684\u9690\u79c1\u4fdd\u62a4\u673a\u5236\u5b58\u5728\u91cd\u5927\u6f0f\u6d1e\u3002\u7814\u7a76\u4e3a\u672a\u6765\u7684\u7f13\u89e3\u63aa\u65bd\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\uff0c\u5f3a\u8c03\u4e86\u91cd\u65b0\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u72b6\u6001\u5b89\u5168\u6027\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2507.15901", "categories": ["cs.AI", "cs.CY", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.15901", "abs": "https://arxiv.org/abs/2507.15901", "authors": ["Joydeep Chandra", "Satyam Kumar Navneet"], "title": "Advancing Responsible Innovation in Agentic AI: A study of Ethical Frameworks for Household Automation", "comment": null, "summary": "The implementation of Artificial Intelligence (AI) in household environments,\nespecially in the form of proactive autonomous agents, brings about\npossibilities of comfort and attention as well as it comes with intra or\nextramural ethical challenges. This article analyzes agentic AI and its\napplications, focusing on its move from reactive to proactive autonomy,\nprivacy, fairness and user control. We review responsible innovation\nframeworks, human-centered design principles, and governance practices to\ndistill practical guidance for ethical smart home systems. Vulnerable user\ngroups such as elderly individuals, children, and neurodivergent who face\nhigher risks of surveillance, bias, and privacy risks were studied in detail in\ncontext of Agentic AI. Design imperatives are highlighted such as tailored\nexplainability, granular consent mechanisms, and robust override controls,\nsupported by participatory and inclusive methodologies. It was also explored\nhow data-driven insights, including social media analysis via Natural Language\nProcessing(NLP), can inform specific user needs and ethical concerns. This\nsurvey aims to provide both a conceptual foundation and suggestions for\ndeveloping transparent, inclusive, and trustworthy agentic AI in household\nautomation.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5206\u6790\u4e86\u5bb6\u5ead\u73af\u5883\u4e2d\u4e3b\u52a8\u578b\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\u7684\u4f26\u7406\u6311\u6218\uff0c\u91cd\u70b9\u5173\u6ce8\u9690\u79c1\u3001\u516c\u5e73\u6027\u548c\u7528\u6237\u63a7\u5236\uff0c\u5e76\u4e3a\u5f31\u52bf\u7fa4\u4f53\u63d0\u51fa\u4e86\u8bbe\u8ba1\u5efa\u8bae\uff0c\u65e8\u5728\u5f00\u53d1\u900f\u660e\u3001\u5305\u5bb9\u548c\u53ef\u4fe1\u7684\u667a\u80fd\u5bb6\u5c45\u7cfb\u7edf\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u5728\u5bb6\u5ead\u73af\u5883\u4e2d\u4ece\u88ab\u52a8\u54cd\u5e94\u8f6c\u5411\u4e3b\u52a8\u81ea\u4e3b\uff0c\u5e26\u6765\u4e86\u8212\u9002\u4fbf\u5229\u7684\u540c\u65f6\u4e5f\u4ea7\u751f\u4e86\u4e25\u91cd\u7684\u4f26\u7406\u6311\u6218\uff0c\u7279\u522b\u662f\u5bf9\u8001\u5e74\u4eba\u3001\u513f\u7ae5\u548c\u795e\u7ecf\u591a\u6837\u6027\u7fa4\u4f53\u7b49\u5f31\u52bf\u7528\u6237\u7684\u9690\u79c1\u3001\u504f\u89c1\u548c\u76d1\u63a7\u98ce\u9669\uff0c\u9700\u8981\u5efa\u7acb\u8d1f\u8d23\u4efb\u7684\u667a\u80fd\u5bb6\u5c45\u7cfb\u7edf\u8bbe\u8ba1\u6846\u67b6\u3002", "method": "\u91c7\u7528\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5206\u6790\u8d1f\u8d23\u4efb\u521b\u65b0\u6846\u67b6\u3001\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u8bbe\u8ba1\u539f\u5219\u548c\u6cbb\u7406\u5b9e\u8df5\uff1b\u6df1\u5165\u7814\u7a76\u5f31\u52bf\u7528\u6237\u7fa4\u4f53\u9762\u4e34\u7684\u7279\u6b8a\u98ce\u9669\uff1b\u63a2\u7d22\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u5904\u7406\u8fdb\u884c\u793e\u4ea4\u5a92\u4f53\u5206\u6790\u7b49\u6570\u636e\u9a71\u52a8\u6d1e\u5bdf\u65b9\u6cd5\u6765\u4e86\u89e3\u7528\u6237\u9700\u6c42\u548c\u4f26\u7406\u5173\u5207\u3002", "result": "\u8bc6\u522b\u51fa\u667a\u80fd\u5bb6\u5c45\u7cfb\u7edf\u8bbe\u8ba1\u7684\u5173\u952e\u8981\u7d20\uff1a\u5b9a\u5236\u5316\u53ef\u89e3\u91ca\u6027\u3001\u7ec6\u7c92\u5ea6\u540c\u610f\u673a\u5236\u3001\u5f3a\u5927\u7684\u8986\u76d6\u63a7\u5236\u529f\u80fd\uff1b\u63d0\u51fa\u53c2\u4e0e\u5f0f\u548c\u5305\u5bb9\u6027\u65b9\u6cd5\u8bba\uff1b\u901a\u8fc7NLP\u7b49\u6280\u672f\u5206\u6790\u7528\u6237\u7279\u5b9a\u9700\u6c42\u548c\u4f26\u7406\u5173\u5207\u7684\u6709\u6548\u9014\u5f84\u3002", "conclusion": "\u4e3a\u5f00\u53d1\u900f\u660e\u3001\u5305\u5bb9\u548c\u53ef\u4fe1\u7684\u5bb6\u5ead\u81ea\u52a8\u5316\u4ee3\u7406AI\u63d0\u4f9b\u4e86\u6982\u5ff5\u57fa\u7840\u548c\u5b9e\u7528\u5efa\u8bae\uff0c\u5f3a\u8c03\u9700\u8981\u901a\u8fc7\u8d1f\u8d23\u4efb\u7684\u8bbe\u8ba1\u5b9e\u8df5\u6765\u5e73\u8861\u6280\u672f\u4fbf\u5229\u6027\u4e0e\u4f26\u7406\u5b89\u5168\u6027\uff0c\u7279\u522b\u662f\u4fdd\u62a4\u5f31\u52bf\u7fa4\u4f53\u7684\u6743\u76ca\u3002"}}
{"id": "2507.16208", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16208", "abs": "https://arxiv.org/abs/2507.16208", "authors": ["Sohaib Muhammad", "Ashwati Vipin", "Karan Shetti", "Honey Mittal"], "title": "LOCOFY Large Design Models -- Design to code conversion solution", "comment": null, "summary": "Despite rapid advances in Large Language Models and Multimodal Large Language\nModels (LLMs), numerous challenges related to interpretability, scalability,\nresource requirements and repeatability remain, related to their application in\nthe design-to-code space. To address this, we introduce the Large Design Models\n(LDMs) paradigm specifically trained on designs and webpages to enable seamless\nconversion from design-to-code. We have developed a training and inference\npipeline by incorporating data engineering and appropriate model architecture\nmodification. The training pipeline consists of the following: 1)Design\nOptimiser: developed using a proprietary ground truth dataset and addresses\nsub-optimal designs; 2)Tagging and feature detection: using pre-trained and\nfine-tuned models, this enables the accurate detection and classification of UI\nelements; and 3)Auto Components: extracts repeated UI structures into reusable\ncomponents to enable creation of modular code, thus reducing redundancy while\nenhancing code reusability. In this manner, each model addresses distinct but\nkey issues for design-to-code conversion. Separately, our inference pipeline\nprocesses real-world designs to produce precise and interpretable instructions\nfor code generation and ensures reliability. Additionally, our models\nillustrated exceptional end-to-end design-to-code conversion accuracy using a\nnovel preview match score metric. Comparative experiments indicated superior\nperformance of LDMs against LLMs on accuracy of node positioning,\nresponsiveness and reproducibility. Moreover, our custom-trained tagging and\nfeature detection model demonstrated high precision and consistency in\nidentifying UI elements across a wide sample of test designs. Thus, our\nproposed LDMs are a reliable and superior solution to understanding designs\nthat subsequently enable the generation of efficient and reliable\nproduction-ready code.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5927\u578b\u8bbe\u8ba1\u6a21\u578b(LDMs)\u8303\u5f0f\uff0c\u4e13\u95e8\u9488\u5bf9\u8bbe\u8ba1\u5230\u4ee3\u7801\u8f6c\u6362\u8fdb\u884c\u8bad\u7ec3\uff0c\u901a\u8fc7\u8bbe\u8ba1\u4f18\u5316\u5668\u3001\u6807\u7b7e\u68c0\u6d4b\u548c\u81ea\u52a8\u7ec4\u4ef6\u63d0\u53d6\u7b49\u6a21\u5757\uff0c\u5728\u8bbe\u8ba1\u7406\u89e3\u548c\u4ee3\u7801\u751f\u6210\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u5927\u8bed\u8a00\u6a21\u578b\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u548c\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\u8fc5\u901f\uff0c\u4f46\u5728\u8bbe\u8ba1\u5230\u4ee3\u7801\u8f6c\u6362\u5e94\u7528\u4e2d\u4ecd\u9762\u4e34\u53ef\u89e3\u91ca\u6027\u3001\u53ef\u6269\u5c55\u6027\u3001\u8d44\u6e90\u9700\u6c42\u548c\u53ef\u91cd\u590d\u6027\u7b49\u6311\u6218\uff0c\u9700\u8981\u4e13\u95e8\u7684\u89e3\u51b3\u65b9\u6848\u6765\u5b9e\u73b0\u65e0\u7f1d\u7684\u8bbe\u8ba1\u5230\u4ee3\u7801\u8f6c\u6362\u3002", "method": "\u63d0\u51fa\u5927\u578b\u8bbe\u8ba1\u6a21\u578b(LDMs)\u8303\u5f0f\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1)\u8bbe\u8ba1\u4f18\u5316\u5668\uff1a\u4f7f\u7528\u4e13\u6709\u771f\u5b9e\u6570\u636e\u96c6\u5904\u7406\u6b21\u4f18\u8bbe\u8ba1\uff1b2)\u6807\u7b7e\u548c\u7279\u5f81\u68c0\u6d4b\uff1a\u4f7f\u7528\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u6a21\u578b\u51c6\u786e\u68c0\u6d4b\u548c\u5206\u7c7bUI\u5143\u7d20\uff1b3)\u81ea\u52a8\u7ec4\u4ef6\uff1a\u63d0\u53d6\u91cd\u590d\u7684UI\u7ed3\u6784\u4e3a\u53ef\u91cd\u7528\u7ec4\u4ef6\uff0c\u51cf\u5c11\u5197\u4f59\u5e76\u63d0\u9ad8\u4ee3\u7801\u53ef\u91cd\u7528\u6027\u3002\u540c\u65f6\u5f00\u53d1\u4e86\u63a8\u7406\u7ba1\u9053\u5904\u7406\u771f\u5b9e\u8bbe\u8ba1\u5e76\u751f\u6210\u7cbe\u786e\u7684\u4ee3\u7801\u751f\u6210\u6307\u4ee4\u3002", "result": "LDMs\u5728\u7aef\u5230\u7aef\u8bbe\u8ba1\u5230\u4ee3\u7801\u8f6c\u6362\u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f7f\u7528\u65b0\u9896\u7684\u9884\u89c8\u5339\u914d\u5206\u6570\u6307\u6807\u8fdb\u884c\u8bc4\u4f30\u3002\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u76f8\u6bd4\uff0cLDMs\u5728\u8282\u70b9\u5b9a\u4f4d\u51c6\u786e\u6027\u3001\u54cd\u5e94\u6027\u548c\u53ef\u91cd\u590d\u6027\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002\u5b9a\u5236\u8bad\u7ec3\u7684\u6807\u7b7e\u548c\u7279\u5f81\u68c0\u6d4b\u6a21\u578b\u5728\u8bc6\u522bUI\u5143\u7d20\u65b9\u9762\u5c55\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u548c\u4e00\u81f4\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684LDMs\u662f\u7406\u89e3\u8bbe\u8ba1\u5e76\u751f\u6210\u9ad8\u6548\u53ef\u9760\u7684\u751f\u4ea7\u5c31\u7eea\u4ee3\u7801\u7684\u53ef\u9760\u4e14\u4f18\u8d8a\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u8bbe\u8ba1\u5230\u4ee3\u7801\u8f6c\u6362\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7684\u5927\u8bed\u8a00\u6a21\u578b\u65b9\u6cd5\u3002"}}
{"id": "2507.16540", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.16540", "abs": "https://arxiv.org/abs/2507.16540", "authors": ["Radowanul Haque", "Aftab Ali", "Sally McClean", "Naveed Khan"], "title": "Explainable Vulnerability Detection in C/C++ Using Edge-Aware Graph Attention Networks", "comment": null, "summary": "Detecting security vulnerabilities in source code remains challenging,\nparticularly due to class imbalance in real-world datasets where vulnerable\nfunctions are under-represented. Existing learning-based methods often optimise\nfor recall, leading to high false positive rates and reduced usability in\ndevelopment workflows. Furthermore, many approaches lack explainability,\nlimiting their integration into security workflows. This paper presents\nExplainVulD, a graph-based framework for vulnerability detection in C/C++ code.\nThe method constructs Code Property Graphs and represents nodes using\ndual-channel embeddings that capture both semantic and structural information.\nThese are processed by an edge-aware attention mechanism that incorporates\nedge-type embeddings to distinguish among program relations. To address class\nimbalance, the model is trained using class-weighted cross-entropy loss.\nExplainVulD achieves a mean accuracy of 88.25 percent and an F1 score of 48.23\npercent across 30 independent runs on the ReVeal dataset. These results\nrepresent relative improvements of 4.6 percent in accuracy and 16.9 percent in\nF1 score compared to the ReVeal model, a prior learning-based method. The\nframework also outperforms static analysis tools, with relative gains of 14.0\nto 14.1 percent in accuracy and 132.2 to 201.2 percent in F1 score. Beyond\nimproved detection performance, ExplainVulD produces explainable outputs by\nidentifying the most influential code regions within each function, supporting\ntransparency and trust in security triage.", "AI": {"tldr": "ExplainVulD\u662f\u4e00\u4e2a\u57fa\u4e8e\u56fe\u7684C/C++\u4ee3\u7801\u6f0f\u6d1e\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u901a\u9053\u5d4c\u5165\u548c\u8fb9\u611f\u77e5\u6ce8\u610f\u529b\u673a\u5236\u5904\u7406\u4ee3\u7801\u5c5e\u6027\u56fe\uff0c\u89e3\u51b3\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5728ReVeal\u6570\u636e\u96c6\u4e0a\u8fbe\u523088.25%\u51c6\u786e\u7387\u548c48.23% F1\u5206\u6570\uff0c\u540c\u65f6\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u6f0f\u6d1e\u68c0\u6d4b\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u6cd5\u9762\u4e34\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u771f\u5b9e\u6570\u636e\u96c6\u4e2d\u5b58\u5728\u4e25\u91cd\u7684\u7c7b\u522b\u4e0d\u5e73\u8861\uff0c\u6f0f\u6d1e\u51fd\u6570\u6570\u91cf\u4e0d\u8db3\uff1b2\uff09\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u4f18\u5316\u53ec\u56de\u7387\uff0c\u5bfc\u81f4\u8bef\u62a5\u7387\u9ad8\uff0c\u5b9e\u7528\u6027\u5dee\uff1b3\uff09\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u9650\u5236\u4e86\u5728\u5b89\u5168\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u96c6\u6210\u5e94\u7528\u3002", "method": "\u6784\u5efa\u4ee3\u7801\u5c5e\u6027\u56fe\uff08Code Property Graphs\uff09\u5e76\u4f7f\u7528\u53cc\u901a\u9053\u5d4c\u5165\u8868\u793a\u8282\u70b9\uff0c\u540c\u65f6\u6355\u83b7\u8bed\u4e49\u548c\u7ed3\u6784\u4fe1\u606f\uff1b\u91c7\u7528\u8fb9\u611f\u77e5\u6ce8\u610f\u529b\u673a\u5236\uff0c\u7ed3\u5408\u8fb9\u7c7b\u578b\u5d4c\u5165\u6765\u533a\u5206\u7a0b\u5e8f\u5173\u7cfb\uff1b\u4f7f\u7528\u7c7b\u52a0\u6743\u4ea4\u53c9\u71b5\u635f\u5931\u6765\u89e3\u51b3\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff1b\u901a\u8fc7\u8bc6\u522b\u51fd\u6570\u5185\u6700\u6709\u5f71\u54cd\u529b\u7684\u4ee3\u7801\u533a\u57df\u6765\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u8f93\u51fa\u3002", "result": "\u5728ReVeal\u6570\u636e\u96c6\u4e0a\u7ecf\u8fc730\u6b21\u72ec\u7acb\u8fd0\u884c\uff0cExplainVulD\u8fbe\u5230\u5e73\u5747\u51c6\u786e\u738788.25%\u548cF1\u5206\u657048.23%\uff1b\u76f8\u6bd4ReVeal\u6a21\u578b\uff0c\u51c6\u786e\u7387\u76f8\u5bf9\u63d0\u53474.6%\uff0cF1\u5206\u6570\u76f8\u5bf9\u63d0\u534716.9%\uff1b\u76f8\u6bd4\u9759\u6001\u5206\u6790\u5de5\u5177\uff0c\u51c6\u786e\u7387\u76f8\u5bf9\u63d0\u534714.0-14.1%\uff0cF1\u5206\u6570\u76f8\u5bf9\u63d0\u5347132.2-201.2%\u3002", "conclusion": "ExplainVulD\u6210\u529f\u63d0\u5347\u4e86\u6f0f\u6d1e\u68c0\u6d4b\u6027\u80fd\uff0c\u4e0d\u4ec5\u5728\u51c6\u786e\u7387\u548cF1\u5206\u6570\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u548c\u9759\u6001\u5206\u6790\u5de5\u5177\uff0c\u8fd8\u901a\u8fc7\u8bc6\u522b\u6700\u5177\u5f71\u54cd\u529b\u7684\u4ee3\u7801\u533a\u57df\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u8f93\u51fa\uff0c\u652f\u6301\u5b89\u5168\u5206\u7c7b\u4e2d\u7684\u900f\u660e\u5ea6\u548c\u4fe1\u4efb\u5ea6\uff0c\u4e3a\u5b9e\u9645\u5b89\u5168\u5de5\u4f5c\u6d41\u7a0b\u7684\u96c6\u6210\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u652f\u6301\u3002"}}
{"id": "2507.15974", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15974", "abs": "https://arxiv.org/abs/2507.15974", "authors": ["Tong Wu", "Chong Xiang", "Jiachen T. Wang", "Weichen Yu", "Chawin Sitawarin", "Vikash Sehwag", "Prateek Mittal"], "title": "Does More Inference-Time Compute Really Help Robustness?", "comment": "Preprint", "summary": "Recently, Zaremba et al. demonstrated that increasing inference-time\ncomputation improves robustness in large proprietary reasoning LLMs. In this\npaper, we first show that smaller-scale, open-source models (e.g., DeepSeek R1,\nQwen3, Phi-reasoning) can also benefit from inference-time scaling using a\nsimple budget forcing strategy. More importantly, we reveal and critically\nexamine an implicit assumption in prior work: intermediate reasoning steps are\nhidden from adversaries. By relaxing this assumption, we identify an important\nsecurity risk, intuitively motivated and empirically verified as an inverse\nscaling law: if intermediate reasoning steps become explicitly accessible,\nincreased inference-time computation consistently reduces model robustness.\nFinally, we discuss practical scenarios where models with hidden reasoning\nchains are still vulnerable to attacks, such as models with tool-integrated\nreasoning and advanced reasoning extraction attacks. Our findings collectively\ndemonstrate that the robustness benefits of inference-time scaling depend\nheavily on the adversarial setting and deployment context. We urge\npractitioners to carefully weigh these subtle trade-offs before applying\ninference-time scaling in security-sensitive, real-world applications.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u63a8\u7406\u65f6\u8ba1\u7b97\u6269\u5c55\u867d\u80fd\u63d0\u5347\u5c0f\u578b\u5f00\u6e90\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff0c\u4f46\u5f53\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u5bf9\u653b\u51fb\u8005\u53ef\u89c1\u65f6\uff0c\u4f1a\u51fa\u73b0\u53cd\u5411\u6269\u5c55\u5b9a\u5f8b\uff0c\u5373\u66f4\u591a\u8ba1\u7b97\u53cd\u800c\u964d\u4f4e\u6a21\u578b\u9c81\u68d2\u6027\uff0c\u63d0\u9192\u5728\u5b89\u5168\u654f\u611f\u5e94\u7528\u4e2d\u9700\u8c28\u614e\u6743\u8861\u6b64\u7c7btrade-off\u3002", "motivation": "\u5148\u524d\u5de5\u4f5c\u5047\u8bbe\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u5bf9\u653b\u51fb\u8005\u9690\u85cf\uff0c\u4f46\u8fd9\u4e00\u5047\u8bbe\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u53ef\u80fd\u4e0d\u6210\u7acb\u3002\u4f5c\u8005\u5e0c\u671b\u63a2\u7d22\u5f53\u8fd9\u4e00\u5047\u8bbe\u88ab\u653e\u677e\u65f6\uff0c\u63a8\u7406\u65f6\u8ba1\u7b97\u6269\u5c55\u5bf9\u6a21\u578b\u9c81\u68d2\u6027\u7684\u771f\u5b9e\u5f71\u54cd\uff0c\u5e76\u8bc6\u522b\u6f5c\u5728\u7684\u5b89\u5168\u98ce\u9669\u3002", "method": "\u4f7f\u7528\u9884\u7b97\u5f3a\u5236\u7b56\u7565\u5728\u5c0f\u578b\u5f00\u6e90\u6a21\u578b\u4e0a\u9a8c\u8bc1\u63a8\u7406\u65f6\u6269\u5c55\u7684\u6548\u679c\uff1b\u901a\u8fc7\u653e\u677e\"\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u9690\u85cf\"\u7684\u5047\u8bbe\uff0c\u7814\u7a76\u5f53\u63a8\u7406\u6b65\u9aa4\u5bf9\u653b\u51fb\u8005\u53ef\u89c1\u65f6\u7684\u9c81\u68d2\u6027\u53d8\u5316\uff1b\u5206\u6790\u5de5\u5177\u96c6\u6210\u63a8\u7406\u548c\u9ad8\u7ea7\u63a8\u7406\u63d0\u53d6\u653b\u51fb\u7b49\u5b9e\u9645\u653b\u51fb\u573a\u666f\u3002", "result": "\u9a8c\u8bc1\u4e86\u5c0f\u578b\u5f00\u6e90\u6a21\u578b\uff08\u5982DeepSeek R1\u3001Qwen3\u3001Phi-reasoning\uff09\u4e5f\u80fd\u4ece\u63a8\u7406\u65f6\u6269\u5c55\u4e2d\u53d7\u76ca\uff1b\u53d1\u73b0\u4e86\u53cd\u5411\u6269\u5c55\u5b9a\u5f8b\uff1a\u5f53\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u53ef\u89c1\u65f6\uff0c\u589e\u52a0\u63a8\u7406\u65f6\u8ba1\u7b97\u4f1a\u6301\u7eed\u964d\u4f4e\u6a21\u578b\u9c81\u68d2\u6027\uff1b\u8bc6\u522b\u4e86\u9690\u85cf\u63a8\u7406\u94fe\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u4ecd\u5b58\u5728\u7684\u6f0f\u6d1e\u3002", "conclusion": "\u63a8\u7406\u65f6\u6269\u5c55\u7684\u9c81\u68d2\u6027\u6536\u76ca\u4e25\u91cd\u4f9d\u8d56\u4e8e\u5bf9\u6297\u8bbe\u7f6e\u548c\u90e8\u7f72\u73af\u5883\u3002\u5728\u5b89\u5168\u654f\u611f\u7684\u5b9e\u9645\u5e94\u7528\u4e2d\u90e8\u7f72\u63a8\u7406\u65f6\u6269\u5c55\u4e4b\u524d\uff0c\u4ece\u4e1a\u8005\u9700\u8981\u4ed4\u7ec6\u6743\u8861\u8fd9\u4e9b\u5fae\u5999\u7684trade-off\uff0c\u4e0d\u80fd\u76f2\u76ee\u5047\u8bbe\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u59cb\u7ec8\u5bf9\u653b\u51fb\u8005\u9690\u85cf\u3002"}}
{"id": "2507.16327", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.16327", "abs": "https://arxiv.org/abs/2507.16327", "authors": ["Karoline Nyl\u00e6nder", "Aitor Arrieta", "Shaukat Ali", "Paolo Arcaini"], "title": "Search-based Generation of Waypoints for Triggering Self-Adaptations in Maritime Autonomous Vessels", "comment": "9 pages, 3 figures. Accepted at GECCO 2025 (Genetic and Evolutionary\n  Computation Conference), July 14-18, 2025, Malaga, Spain", "summary": "Self-adaptation in maritime autonomous vessels (AVs) enables them to adapt\ntheir behaviors to address unexpected situations while maintaining\ndependability requirements. During the design of such AVs, it is crucial to\nunderstand and identify the settings that should trigger adaptations, enabling\nvalidation of their implementation. To this end, we focus on the navigation\nsoftware of AVs, which must adapt their behavior during operation through\nadaptations. AVs often rely on predefined waypoints to guide them along\ndesignated routes, ensuring safe navigation. We propose a multiobjective\nsearch-based approach, called WPgen, to generate minor modifications to the\npredefined set of waypoints, keeping them as close as possible to the original\nwaypoints, while causing the AV to navigate inappropriately when navigating\nwith the generated waypoints. WPgen uses NSGA-II as the multi-objective search\nalgorithm with three seeding strategies for its initial population, resulting\nin three variations of WPgen. We evaluated these variations on three AVs (one\noverwater tanker and two underwater). We compared the three variations of WPgen\nwith Random Search as the baseline and with each other. Experimental results\nshowed that the effectiveness of these variations varied depending on the AV.\nBased on the results, we present the research and practical implications of\nWPgen.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86WPgen\u65b9\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u6d77\u4e0a\u81ea\u4e3b\u8239\u8236\u5bfc\u822a\u6d4b\u8bd5\u7528\u4f8b\uff0c\u901a\u8fc7\u5bf9\u9884\u5b9a\u4e49\u822a\u70b9\u8fdb\u884c\u5fae\u5c0f\u4fee\u6539\u6765\u89e6\u53d1\u4e0d\u5f53\u5bfc\u822a\u884c\u4e3a\uff0c\u4ee5\u9a8c\u8bc1\u81ea\u9002\u5e94\u7cfb\u7edf\u7684\u5b9e\u73b0", "motivation": "\u6d77\u4e0a\u81ea\u4e3b\u8239\u8236\u9700\u8981\u81ea\u9002\u5e94\u80fd\u529b\u6765\u5e94\u5bf9\u610f\u5916\u60c5\u51b5\u5e76\u4fdd\u6301\u53ef\u9760\u6027\u8981\u6c42\u3002\u5728\u8bbe\u8ba1\u6b64\u7c7b\u8239\u8236\u65f6\uff0c\u7406\u89e3\u548c\u8bc6\u522b\u5e94\u8be5\u89e6\u53d1\u81ea\u9002\u5e94\u7684\u573a\u666f\u8bbe\u7f6e\u81f3\u5173\u91cd\u8981\uff0c\u8fd9\u9700\u8981\u5bf9\u81ea\u9002\u5e94\u5b9e\u73b0\u8fdb\u884c\u9a8c\u8bc1", "method": "\u63d0\u51fa\u57fa\u4e8e\u591a\u76ee\u6807\u641c\u7d22\u7684WPgen\u65b9\u6cd5\uff0c\u4f7f\u7528NSGA-II\u7b97\u6cd5\u5bf9\u9884\u5b9a\u4e49\u822a\u70b9\u96c6\u5408\u8fdb\u884c\u5fae\u5c0f\u4fee\u6539\u3002\u8be5\u65b9\u6cd5\u91c7\u7528\u4e09\u79cd\u4e0d\u540c\u7684\u79cd\u5b50\u7b56\u7565\u6765\u521d\u59cb\u5316\u79cd\u7fa4\uff0c\u5f62\u6210WPgen\u7684\u4e09\u4e2a\u53d8\u4f53\uff0c\u76ee\u6807\u662f\u751f\u6210\u5c3d\u53ef\u80fd\u63a5\u8fd1\u539f\u59cb\u822a\u70b9\u4f46\u4f1a\u5bfc\u81f4\u4e0d\u5f53\u5bfc\u822a\u7684\u822a\u70b9", "result": "\u5728\u4e09\u8258\u81ea\u4e3b\u8239\u8236\uff08\u4e00\u8258\u6c34\u9762\u6cb9\u8f6e\u548c\u4e24\u8258\u6c34\u4e0b\u8239\u8236\uff09\u4e0a\u8bc4\u4f30\u4e86WPgen\u7684\u4e09\u4e2a\u53d8\u4f53\u3002\u4e0e\u968f\u673a\u641c\u7d22\u57fa\u7ebf\u65b9\u6cd5\u4ee5\u53ca\u5404\u53d8\u4f53\u4e4b\u95f4\u7684\u6bd4\u8f83\u8868\u660e\uff0c\u4e0d\u540c\u53d8\u4f53\u7684\u6709\u6548\u6027\u56e0\u8239\u8236\u7c7b\u578b\u800c\u5f02", "conclusion": "WPgen\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u751f\u6210\u7528\u4e8e\u6d4b\u8bd5\u6d77\u4e0a\u81ea\u4e3b\u8239\u8236\u5bfc\u822a\u7cfb\u7edf\u7684\u6d4b\u8bd5\u7528\u4f8b\uff0c\u4e0d\u540c\u7684\u79cd\u5b50\u7b56\u7565\u9002\u7528\u4e8e\u4e0d\u540c\u7c7b\u578b\u7684\u8239\u8236\u3002\u7814\u7a76\u4e3a\u6d77\u4e0a\u81ea\u4e3b\u8239\u8236\u81ea\u9002\u5e94\u7cfb\u7edf\u7684\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u5de5\u5177\u548c\u65b9\u6cd5\u6307\u5bfc"}}
{"id": "2507.16576", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.16576", "abs": "https://arxiv.org/abs/2507.16576", "authors": ["Ahmed Lekssays", "Husrev Taha Sencar", "Ting Yu"], "title": "From Text to Actionable Intelligence: Automating STIX Entity and Relationship Extraction", "comment": "This paper is accepted at RAID 2025", "summary": "Sharing methods of attack and their effectiveness is a cornerstone of\nbuilding robust defensive systems. Threat analysis reports, produced by various\nindividuals and organizations, play a critical role in supporting security\noperations and combating emerging threats. To enhance the timeliness and\nautomation of threat intelligence sharing, several standards have been\nestablished, with the Structured Threat Information Expression (STIX) framework\nemerging as one of the most widely adopted. However, generating STIX-compatible\ndata from unstructured security text remains a largely manual, expert-driven\nprocess. To address this challenge, we introduce AZERG, a tool designed to\nassist security analysts in automatically generating structured STIX\nrepresentations. To achieve this, we adapt general-purpose large language\nmodels for the specific task of extracting STIX-formatted threat data. To\nmanage the complexity, the task is divided into four subtasks: entity detection\n(T1), entity type identification (T2), related pair detection (T3), and\nrelationship type identification (T4). We apply task-specific fine-tuning to\naccurately extract relevant entities and infer their relationships in\naccordance with the STIX specification. To address the lack of training data,\nwe compiled a comprehensive dataset with 4,011 entities and 2,075 relationships\nextracted from 141 full threat analysis reports, all annotated in alignment\nwith the STIX standard. Our models achieved F1-scores of 84.43% for T1, 88.49%\nfor T2, 95.47% for T3, and 84.60% for T4 in real-world scenarios. We validated\ntheir performance against a range of open- and closed-parameter models, as well\nas state-of-the-art methods, demonstrating improvements of 2-25% across tasks.", "AI": {"tldr": "\u7814\u7a76\u8005\u5f00\u53d1\u4e86AZERG\u5de5\u5177\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u4ece\u975e\u7ed3\u6784\u5316\u5b89\u5168\u6587\u672c\u4e2d\u751f\u6210STIX\u683c\u5f0f\u7684\u5a01\u80c1\u60c5\u62a5\u6570\u636e\uff0c\u901a\u8fc7\u5c06\u4efb\u52a1\u5206\u89e3\u4e3a\u56db\u4e2a\u5b50\u4efb\u52a1\u5e76\u8fdb\u884c\u9488\u5bf9\u6027\u5fae\u8c03\uff0c\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u53d6\u5f97\u4e8684-95%\u7684F1\u5206\u6570\u8868\u73b0\u3002", "motivation": "\u5a01\u80c1\u5206\u6790\u62a5\u544a\u5bf9\u5b89\u5168\u8fd0\u8425\u81f3\u5173\u91cd\u8981\uff0cSTIX\u6846\u67b6\u5df2\u6210\u4e3a\u5a01\u80c1\u60c5\u62a5\u5171\u4eab\u7684\u5e7f\u6cdb\u91c7\u7528\u6807\u51c6\uff0c\u4f46\u4ece\u975e\u7ed3\u6784\u5316\u5b89\u5168\u6587\u672c\u751f\u6210STIX\u517c\u5bb9\u6570\u636e\u4ecd\u7136\u662f\u4e00\u4e2a\u4e3b\u8981\u4f9d\u8d56\u4e13\u5bb6\u7684\u624b\u5de5\u8fc7\u7a0b\uff0c\u7f3a\u4e4f\u81ea\u52a8\u5316\u548c\u53ca\u65f6\u6027\u3002", "method": "\u5f00\u53d1AZERG\u5de5\u5177\uff0c\u9002\u914d\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7528\u4e8e\u63d0\u53d6STIX\u683c\u5f0f\u5a01\u80c1\u6570\u636e\u3002\u5c06\u590d\u6742\u4efb\u52a1\u5206\u89e3\u4e3a\u56db\u4e2a\u5b50\u4efb\u52a1\uff1a\u5b9e\u4f53\u68c0\u6d4b(T1)\u3001\u5b9e\u4f53\u7c7b\u578b\u8bc6\u522b(T2)\u3001\u76f8\u5173\u5bf9\u68c0\u6d4b(T3)\u548c\u5173\u7cfb\u7c7b\u578b\u8bc6\u522b(T4)\u3002\u5e94\u7528\u4efb\u52a1\u7279\u5b9a\u7684\u5fae\u8c03\u6765\u51c6\u786e\u63d0\u53d6\u76f8\u5173\u5b9e\u4f53\u5e76\u63a8\u65ad\u5176\u5173\u7cfb\u3002\u6784\u5efa\u5305\u542b4,011\u4e2a\u5b9e\u4f53\u548c2,075\u4e2a\u5173\u7cfb\u7684\u7efc\u5408\u6570\u636e\u96c6\uff0c\u6765\u81ea141\u4efd\u5b8c\u6574\u5a01\u80c1\u5206\u6790\u62a5\u544a\u3002", "result": "\u6a21\u578b\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u53d6\u5f97\u4f18\u5f02\u8868\u73b0\uff1aT1\u4efb\u52a1F1\u5206\u657084.43%\uff0cT2\u4efb\u52a188.49%\uff0cT3\u4efb\u52a195.47%\uff0cT4\u4efb\u52a184.60%\u3002\u4e0e\u5f00\u653e\u548c\u5c01\u95ed\u53c2\u6570\u6a21\u578b\u4ee5\u53ca\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5404\u9879\u4efb\u52a1\u5747\u67092-25%\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "AZERG\u5de5\u5177\u6210\u529f\u5b9e\u73b0\u4e86\u4ece\u975e\u7ed3\u6784\u5316\u5b89\u5168\u6587\u672c\u81ea\u52a8\u751f\u6210STIX\u683c\u5f0f\u5a01\u80c1\u60c5\u62a5\u7684\u76ee\u6807\uff0c\u901a\u8fc7\u4efb\u52a1\u5206\u89e3\u548c\u9488\u5bf9\u6027\u5fae\u8c03\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u5a01\u80c1\u60c5\u62a5\u5904\u7406\u7684\u81ea\u52a8\u5316\u6c34\u5e73\u548c\u51c6\u786e\u6027\uff0c\u4e3a\u5b89\u5168\u5206\u6790\u5e08\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8f85\u52a9\u5de5\u5177\u3002"}}
{"id": "2507.16020", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16020", "abs": "https://arxiv.org/abs/2507.16020", "authors": ["Xi Yang", "Jiachen Wang", "Song Han", "Suining He"], "title": "Micromobility Flow Prediction: A Bike Sharing Station-level Study via Multi-level Spatial-Temporal Attention Neural Network", "comment": "6 pages, UrbComp 2024", "summary": "Efficient use of urban micromobility resources such as bike sharing is\nchallenging due to the unbalanced station-level demand and supply, which causes\nthe maintenance of the bike sharing systems painstaking. Prior efforts have\nbeen made on accurate prediction of bike traffics, i.e., demand/pick-up and\nreturn/drop-off, to achieve system efficiency. However, bike station-level\ntraffic prediction is difficult because of the spatial-temporal complexity of\nbike sharing systems. Moreover, such level of prediction over entire bike\nsharing systems is also challenging due to the large number of bike stations.\nTo fill this gap, we propose BikeMAN, a multi-level spatio-temporal attention\nneural network to predict station-level bike traffic for entire bike sharing\nsystems. The proposed network consists of an encoder and a decoder with an\nattention mechanism representing the spatial correlation between features of\nbike stations in the system and another attention mechanism describing the\ntemporal characteristic of bike station traffic. Through experimental study on\nover 10 millions trips of bike sharing systems (> 700 stations) of New York\nCity, our network showed high accuracy in predicting the bike station traffic\nof all stations in the city.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faBikeMAN\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u901a\u8fc7\u591a\u7ea7\u65f6\u7a7a\u6ce8\u610f\u529b\u673a\u5236\u9884\u6d4b\u6574\u4e2a\u5171\u4eab\u5355\u8f66\u7cfb\u7edf\u4e2d\u6240\u6709\u7ad9\u70b9\u7684\u4ea4\u901a\u6d41\u91cf\uff0c\u5728\u7ebd\u7ea6\u5e02\u8d85\u8fc7700\u4e2a\u7ad9\u70b9\u7684\u5b9e\u9a8c\u4e2d\u5c55\u73b0\u4e86\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u57ce\u5e02\u5fae\u51fa\u884c\u8d44\u6e90\u5982\u5171\u4eab\u5355\u8f66\u7cfb\u7edf\u9762\u4e34\u7ad9\u70b9\u7ea7\u9700\u6c42\u4f9b\u7ed9\u4e0d\u5e73\u8861\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u7cfb\u7edf\u7ef4\u62a4\u56f0\u96be\u3002\u73b0\u6709\u7684\u5355\u8f66\u4ea4\u901a\u9884\u6d4b\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u5171\u4eab\u5355\u8f66\u7cfb\u7edf\u7684\u65f6\u7a7a\u590d\u6742\u6027\uff0c\u4e14\u96be\u4ee5\u5bf9\u6574\u4e2a\u7cfb\u7edf\u7684\u5927\u91cf\u7ad9\u70b9\u8fdb\u884c\u7ad9\u70b9\u7ea7\u9884\u6d4b\u3002", "method": "\u63d0\u51faBikeMAN\u591a\u7ea7\u65f6\u7a7a\u6ce8\u610f\u529b\u795e\u7ecf\u7f51\u7edc\uff0c\u5305\u542b\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u7ed3\u6784\u3002\u91c7\u7528\u4e24\u79cd\u6ce8\u610f\u529b\u673a\u5236\uff1a\u4e00\u79cd\u8868\u793a\u7cfb\u7edf\u4e2d\u5355\u8f66\u7ad9\u70b9\u7279\u5f81\u4e4b\u95f4\u7684\u7a7a\u95f4\u76f8\u5173\u6027\uff0c\u53e6\u4e00\u79cd\u63cf\u8ff0\u5355\u8f66\u7ad9\u70b9\u4ea4\u901a\u7684\u65f6\u95f4\u7279\u5f81\u3002", "result": "\u5728\u7ebd\u7ea6\u5e02\u5171\u4eab\u5355\u8f66\u7cfb\u7edf\uff08\u8d85\u8fc7700\u4e2a\u7ad9\u70b9\uff0c1000\u4e07\u6b21\u51fa\u884c\u6570\u636e\uff09\u4e0a\u7684\u5b9e\u9a8c\u7814\u7a76\u8868\u660e\uff0c\u8be5\u7f51\u7edc\u5728\u9884\u6d4b\u57ce\u5e02\u4e2d\u6240\u6709\u7ad9\u70b9\u7684\u5355\u8f66\u7ad9\u70b9\u4ea4\u901a\u65b9\u9762\u663e\u793a\u51fa\u9ad8\u51c6\u786e\u6027\u3002", "conclusion": "BikeMAN\u7f51\u7edc\u6210\u529f\u89e3\u51b3\u4e86\u6574\u4e2a\u5171\u4eab\u5355\u8f66\u7cfb\u7edf\u7ad9\u70b9\u7ea7\u4ea4\u901a\u9884\u6d4b\u7684\u6311\u6218\uff0c\u901a\u8fc7\u591a\u7ea7\u65f6\u7a7a\u6ce8\u610f\u529b\u673a\u5236\u6709\u6548\u6355\u83b7\u4e86\u7cfb\u7edf\u7684\u7a7a\u95f4\u548c\u65f6\u95f4\u590d\u6742\u6027\uff0c\u4e3a\u5171\u4eab\u5355\u8f66\u7cfb\u7edf\u7684\u9ad8\u6548\u7ba1\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u9884\u6d4b\u5de5\u5177\u3002"}}
{"id": "2507.16407", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.16407", "abs": "https://arxiv.org/abs/2507.16407", "authors": ["Shuhan Liu", "Xing Hu", "Kerui Huang", "Xiaohu Yang", "David Lo", "Xin Xia"], "title": "Improving Code LLM Robustness to Prompt Perturbations via Layer-Aware Model Editing", "comment": null, "summary": "Large language models (LLMs) have demonstrated impressive capabilities in\ncode generation, where the natural language prompt plays a crucial role in\nconveying user intent to the model. However, prior studies have shown that LLMs\nare highly sensitive to prompt perturbations. Minor modifications in wording,\nsyntax, or formatting can significantly reduce the functional correctness of\ngenerated code. As perturbations frequently occur in real-world scenarios,\nimproving the robustness of LLMs to prompt perturbations is essential for\nensuring reliable performance in practical code generation. In this paper, we\nintroduce CREME (Code Robustness Enhancement via Model Editing), a novel\napproach that enhances LLM robustness through targeted parameter updates. CREME\nfirst identifies robustness-sensitive layers by comparing hidden states between\nan original prompt and its perturbed variant. Then, it performs lightweight\nparameter editing at the identified layer to reduce performance degradation. We\nevaluate CREME on two widely used code generation benchmarks (HumanEval and\nMBPP) along with their perturbed counterparts. Experimental results show that\nCREME improves Pass@1 accuracy by 63% on perturbed prompts while maintaining\nstable performance on clean inputs, with accuracy deviations within 1%. Further\nanalysis reveals that robustness-sensitive layers are primarily concentrated in\nthe middle and deeper layers of the network, and their locations vary across\ndifferent model architectures. These insights provide a valuable foundation for\ndeveloping future robustness-oriented editing strategies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCREME\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522b\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u5bf9\u63d0\u793a\u6270\u52a8\u654f\u611f\u7684\u7f51\u7edc\u5c42\u5e76\u8fdb\u884c\u9488\u5bf9\u6027\u53c2\u6570\u7f16\u8f91\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u6a21\u578b\u5bf9\u63d0\u793a\u53d8\u5316\u7684\u9c81\u68d2\u6027\uff0c\u5728\u6270\u52a8\u63d0\u793a\u4e0aPass@1\u51c6\u786e\u7387\u63d0\u534763%\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u5bf9\u63d0\u793a\u6270\u52a8\u9ad8\u5ea6\u654f\u611f\uff0c\u5fae\u5c0f\u7684\u63aa\u8f9e\u3001\u8bed\u6cd5\u6216\u683c\u5f0f\u53d8\u5316\u90fd\u4f1a\u663e\u8457\u964d\u4f4e\u751f\u6210\u4ee3\u7801\u7684\u529f\u80fd\u6b63\u786e\u6027\u3002\u7531\u4e8e\u6270\u52a8\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u9891\u7e41\u53d1\u751f\uff0c\u63d0\u5347LLM\u5bf9\u63d0\u793a\u6270\u52a8\u7684\u9c81\u68d2\u6027\u5bf9\u786e\u4fdd\u5b9e\u9645\u4ee3\u7801\u751f\u6210\u7684\u53ef\u9760\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002", "method": "CREME\uff08\u901a\u8fc7\u6a21\u578b\u7f16\u8f91\u589e\u5f3a\u4ee3\u7801\u9c81\u68d2\u6027\uff09\u65b9\u6cd5\u5206\u4e24\u6b65\uff1a1\uff09\u901a\u8fc7\u6bd4\u8f83\u539f\u59cb\u63d0\u793a\u548c\u6270\u52a8\u63d0\u793a\u4e4b\u95f4\u7684\u9690\u85cf\u72b6\u6001\u6765\u8bc6\u522b\u9c81\u68d2\u6027\u654f\u611f\u5c42\uff1b2\uff09\u5728\u8bc6\u522b\u51fa\u7684\u5c42\u4e0a\u6267\u884c\u8f7b\u91cf\u7ea7\u53c2\u6570\u7f16\u8f91\u4ee5\u51cf\u5c11\u6027\u80fd\u9000\u5316\u3002", "result": "\u5728HumanEval\u548cMBPP\u4e24\u4e2a\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u53ca\u5176\u6270\u52a8\u7248\u672c\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCREME\u5728\u6270\u52a8\u63d0\u793a\u4e0a\u5c06Pass@1\u51c6\u786e\u7387\u63d0\u5347\u4e8663%\uff0c\u540c\u65f6\u5728\u5e72\u51c0\u8f93\u5165\u4e0a\u4fdd\u6301\u7a33\u5b9a\u6027\u80fd\uff0c\u51c6\u786e\u7387\u504f\u5dee\u57281%\u4ee5\u5185\u3002", "conclusion": "\u9c81\u68d2\u6027\u654f\u611f\u5c42\u4e3b\u8981\u96c6\u4e2d\u5728\u7f51\u7edc\u7684\u4e2d\u5c42\u548c\u6df1\u5c42\uff0c\u4e14\u5176\u4f4d\u7f6e\u56e0\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u800c\u5f02\u3002\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u5f00\u53d1\u672a\u6765\u9762\u5411\u9c81\u68d2\u6027\u7684\u7f16\u8f91\u7b56\u7565\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7684\u57fa\u7840\u3002CREME\u6709\u6548\u63d0\u5347\u4e86LLM\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u63d0\u793a\u9c81\u68d2\u6027\u3002"}}
{"id": "2507.16585", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.16585", "abs": "https://arxiv.org/abs/2507.16585", "authors": ["Ahmed Lekssays", "Hamza Mouhcine", "Khang Tran", "Ting Yu", "Issa Khalil"], "title": "LLMxCPG: Context-Aware Vulnerability Detection Through Code Property Graph-Guided Large Language Models", "comment": "This paper is accepted at USENIX 2025", "summary": "Software vulnerabilities present a persistent security challenge, with over\n25,000 new vulnerabilities reported in the Common Vulnerabilities and Exposures\n(CVE) database in 2024 alone. While deep learning based approaches show promise\nfor vulnerability detection, recent studies reveal critical limitations in\nterms of accuracy and robustness: accuracy drops by up to 45% on rigorously\nverified datasets, and performance degrades significantly under simple code\nmodifications. This paper presents LLMxCPG, a novel framework integrating Code\nProperty Graphs (CPG) with Large Language Models (LLM) for robust vulnerability\ndetection. Our CPG-based slice construction technique reduces code size by\n67.84 to 90.93% while preserving vulnerability-relevant context. Our approach's\nability to provide a more concise and accurate representation of code snippets\nenables the analysis of larger code segments, including entire projects. This\nconcise representation is a key factor behind the improved detection\ncapabilities of our method, as it can now identify vulnerabilities that span\nmultiple functions. Empirical evaluation demonstrates LLMxCPG's effectiveness\nacross verified datasets, achieving 15-40% improvements in F1-score over\nstate-of-the-art baselines. Moreover, LLMxCPG maintains high performance across\nfunction-level and multi-function codebases while exhibiting robust detection\nefficacy under various syntactic code modifications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86LLMxCPG\u6846\u67b6\uff0c\u7ed3\u5408\u4ee3\u7801\u5c5e\u6027\u56fe(CPG)\u548c\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u8fdb\u884c\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\uff0c\u901a\u8fc7CPG\u5207\u7247\u6280\u672f\u5c06\u4ee3\u7801\u5927\u5c0f\u51cf\u5c1167.84-90.93%\uff0c\u540c\u65f6\u4fdd\u6301\u6f0f\u6d1e\u76f8\u5173\u4e0a\u4e0b\u6587\uff0c\u5728\u9a8c\u8bc1\u6570\u636e\u96c6\u4e0aF1\u5206\u6570\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u534715-40%\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u95ee\u9898\uff1a\u5728\u4e25\u683c\u9a8c\u8bc1\u7684\u6570\u636e\u96c6\u4e0a\u51c6\u786e\u7387\u4e0b\u964d\u9ad8\u8fbe45%\uff0c\u5728\u7b80\u5355\u4ee3\u7801\u4fee\u6539\u4e0b\u6027\u80fd\u663e\u8457\u9000\u5316\u3002\u540c\u65f6\uff0c2024\u5e74\u4ec5CVE\u6570\u636e\u5e93\u5c31\u62a5\u544a\u4e86\u8d85\u8fc725,000\u4e2a\u65b0\u6f0f\u6d1e\uff0c\u4e9f\u9700\u66f4\u6709\u6548\u7684\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51faLLMxCPG\u6846\u67b6\uff0c\u96c6\u6210\u4ee3\u7801\u5c5e\u6027\u56fe(CPG)\u548c\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u3002\u91c7\u7528\u57fa\u4e8eCPG\u7684\u5207\u7247\u6784\u5efa\u6280\u672f\uff0c\u5728\u4fdd\u6301\u6f0f\u6d1e\u76f8\u5173\u4e0a\u4e0b\u6587\u7684\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u4ee3\u7801\u5927\u5c0f\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u5206\u6790\u66f4\u5927\u7684\u4ee3\u7801\u6bb5\uff0c\u5305\u62ec\u6574\u4e2a\u9879\u76ee\uff0c\u5e76\u8bc6\u522b\u8de8\u591a\u4e2a\u51fd\u6570\u7684\u6f0f\u6d1e\u3002", "result": "\u5728\u9a8c\u8bc1\u6570\u636e\u96c6\u4e0a\uff0cLLMxCPG\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u5728F1\u5206\u6570\u4e0a\u5b9e\u73b0\u4e8615-40%\u7684\u63d0\u5347\u3002CPG\u5207\u7247\u6280\u672f\u5c06\u4ee3\u7801\u5927\u5c0f\u51cf\u5c11\u4e8667.84%\u523090.93%\u3002\u8be5\u65b9\u6cd5\u5728\u51fd\u6570\u7ea7\u548c\u591a\u51fd\u6570\u4ee3\u7801\u5e93\u4e2d\u90fd\u4fdd\u6301\u4e86\u9ad8\u6027\u80fd\uff0c\u5e76\u5728\u5404\u79cd\u8bed\u6cd5\u4ee3\u7801\u4fee\u6539\u4e0b\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u68c0\u6d4b\u6548\u529b\u3002", "conclusion": "LLMxCPG\u6846\u67b6\u901a\u8fc7\u7ed3\u5408CPG\u548cLLM\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u6cd5\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u63d0\u4f9b\u66f4\u7b80\u6d01\u51c6\u786e\u7684\u4ee3\u7801\u8868\u793a\uff0c\u652f\u6301\u5927\u89c4\u6a21\u4ee3\u7801\u5206\u6790\u548c\u8de8\u51fd\u6570\u6f0f\u6d1e\u68c0\u6d4b\uff0c\u5728\u591a\u4e2a\u8bc4\u4f30\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002"}}
{"id": "2507.16028", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16028", "abs": "https://arxiv.org/abs/2507.16028", "authors": ["Tehseen Rug", "Felix B\u00f6hmer", "Tessa Pfattheicher"], "title": "From Logic to Language: A Trust Index for Problem Solving with LLMs", "comment": "17 pages, 2 figures", "summary": "Classical computation, grounded in formal, logical systems, has been the\nengine of technological progress for decades, excelling at problems that can be\ndescribed with unambiguous rules. This paradigm, however, leaves a vast ocean\nof human problems -- those characterized by ambiguity, dynamic environments,\nand subjective context -- largely untouched. The advent of Large Language\nModels (LLMs) represents a fundamental shift, enabling computational systems to\nengage with this previously inaccessible domain using natural language. This\npaper introduces a unified framework to understand and contrast these\nproblem-solving paradigms. We define and delineate the problem spaces\naddressable by formal languages versus natural language. While solutions to the\nformer problem class can be evaluated using binary quality measures, the latter\nrequires a much more nuanced definition of approximate solution space taking\ninto account the vagueness, subjectivity and ambiguity inherent to natural\nlanguage. We therefore introduce a vector-valued trust index Q, which reflects\nsolution quality and distinguishes the binary correctness of formal solutions\nfrom the continuous adequacy spectrum characteristic of natural language\nsolutions. Within this framework, we propose two statistical quality\ndimensions. Normalized bi-semantic entropy measures robustness and conceptual\ndiversity of LLM answers given semantic variation in problem formulations.\nEmotional valence maps subjective valuation of a solution to a quantifiable\nmetric that can be maximized by invoking statistical measures. The concepts\nintroduced in this work will provide a more rigorous understanding of the\ncapabilities, limitations, and inherent nature of problem-solving in the age of\nLLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\u6765\u7406\u89e3\u548c\u5bf9\u6bd4\u4f20\u7edf\u8ba1\u7b97\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u95ee\u9898\u6c42\u89e3\u8303\u5f0f\uff0c\u5f15\u5165\u5411\u91cf\u503c\u4fe1\u4efb\u6307\u6570Q\u6765\u8bc4\u4f30\u81ea\u7136\u8bed\u8a00\u89e3\u51b3\u65b9\u6848\u7684\u8d28\u91cf\uff0c\u5e76\u63d0\u51fa\u4e86\u53cc\u8bed\u4e49\u71b5\u548c\u60c5\u611f\u6548\u4ef7\u4e24\u4e2a\u7edf\u8ba1\u8d28\u91cf\u7ef4\u5ea6\u3002", "motivation": "\u4f20\u7edf\u8ba1\u7b97\u57fa\u4e8e\u5f62\u5f0f\u903b\u8f91\u7cfb\u7edf\uff0c\u64c5\u957f\u5904\u7406\u660e\u786e\u89c4\u5219\u7684\u95ee\u9898\uff0c\u4f46\u5bf9\u4e8e\u5177\u6709\u6a21\u7cca\u6027\u3001\u52a8\u6001\u73af\u5883\u548c\u4e3b\u89c2\u8bed\u5883\u7684\u4eba\u7c7b\u95ee\u9898\u5374\u65e0\u80fd\u4e3a\u529b\u3002\u5927\u8bed\u8a00\u6a21\u578b\u7684\u51fa\u73b0\u4f7f\u8ba1\u7b97\u7cfb\u7edf\u80fd\u591f\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u5904\u7406\u8fd9\u4e9b\u4ee5\u524d\u65e0\u6cd5\u89e6\u53ca\u7684\u9886\u57df\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\u6765\u7406\u89e3\u8fd9\u4e24\u79cd\u95ee\u9898\u6c42\u89e3\u8303\u5f0f\u7684\u5dee\u5f02\u3002", "method": "\u4f5c\u8005\u5b9a\u4e49\u5e76\u5212\u5206\u4e86\u5f62\u5f0f\u8bed\u8a00\u4e0e\u81ea\u7136\u8bed\u8a00\u53ef\u89e3\u51b3\u7684\u95ee\u9898\u7a7a\u95f4\uff0c\u5f15\u5165\u5411\u91cf\u503c\u4fe1\u4efb\u6307\u6570Q\u6765\u53cd\u6620\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\uff0c\u533a\u5206\u5f62\u5f0f\u89e3\u51b3\u65b9\u6848\u7684\u4e8c\u5143\u6b63\u786e\u6027\u548c\u81ea\u7136\u8bed\u8a00\u89e3\u51b3\u65b9\u6848\u7684\u8fde\u7eed\u9002\u5f53\u6027\u8c31\u3002\u63d0\u51fa\u4e24\u4e2a\u7edf\u8ba1\u8d28\u91cf\u7ef4\u5ea6\uff1a\u6807\u51c6\u5316\u53cc\u8bed\u4e49\u71b5\uff08\u8861\u91cfLLM\u7b54\u6848\u7684\u9c81\u68d2\u6027\u548c\u6982\u5ff5\u591a\u6837\u6027\uff09\u548c\u60c5\u611f\u6548\u4ef7\uff08\u5c06\u4e3b\u89c2\u8bc4\u4ef7\u6620\u5c04\u4e3a\u53ef\u91cf\u5316\u6307\u6807\uff09\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u80fd\u591f\u533a\u5206\u4f20\u7edf\u8ba1\u7b97\u548cLLM\u95ee\u9898\u6c42\u89e3\u80fd\u529b\u7684\u7406\u8bba\u6846\u67b6\uff0c\u63d0\u4f9b\u4e86\u8bc4\u4f30\u81ea\u7136\u8bed\u8a00\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u7684\u91cf\u5316\u65b9\u6cd5\uff0c\u5305\u62ec\u5904\u7406\u6a21\u7cca\u6027\u3001\u4e3b\u89c2\u6027\u548c\u6b67\u4e49\u6027\u7684\u8bc4\u4f30\u6307\u6807\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u7406\u89e3LLM\u65f6\u4ee3\u95ee\u9898\u6c42\u89e3\u7684\u80fd\u529b\u3001\u5c40\u9650\u6027\u548c\u56fa\u6709\u7279\u6027\u63d0\u4f9b\u4e86\u66f4\u4e25\u683c\u7684\u7406\u8bba\u57fa\u7840\uff0c\u4e3a\u8bc4\u4f30\u548c\u4f18\u5316\u81ea\u7136\u8bed\u8a00\u8ba1\u7b97\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u5206\u6790\u5de5\u5177\u548c\u8d28\u91cf\u5ea6\u91cf\u6807\u51c6\u3002"}}
{"id": "2507.16439", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.16439", "abs": "https://arxiv.org/abs/2507.16439", "authors": ["Gunnar Larsen", "Carol Wong", "Anthony Peruma"], "title": "Exploring Large Language Models for Analyzing and Improving Method Names in Scientific Code", "comment": "The 19th ACM/IEEE International Symposium on Empirical Software\n  Engineering and Measurement - Emerging Results and Vision Track", "summary": "Research scientists increasingly rely on implementing software to support\ntheir research. While previous research has examined the impact of identifier\nnames on program comprehension in traditional programming environments, limited\nwork has explored this area in scientific software, especially regarding the\nquality of method names in the code. The recent advances in Large Language\nModels (LLMs) present new opportunities for automating code analysis tasks,\nsuch as identifier name appraisals and recommendations. Our study evaluates\nfour popular LLMs on their ability to analyze grammatical patterns and suggest\nimprovements for 496 method names extracted from Python-based Jupyter\nNotebooks. Our findings show that the LLMs are somewhat effective in analyzing\nthese method names and generally follow good naming practices, like starting\nmethod names with verbs. However, their inconsistent handling of\ndomain-specific terminology and only moderate agreement with human annotations\nindicate that automated suggestions require human evaluation. This work\nprovides foundational insights for improving the quality of scientific code\nthrough AI automation.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u56db\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u5728\u5206\u6790\u548c\u6539\u8fdb\u79d1\u5b66\u8f6f\u4ef6\u4e2d\u65b9\u6cd5\u540d\u8d28\u91cf\u65b9\u9762\u7684\u80fd\u529b\uff0c\u53d1\u73b0LLMs\u5728\u5206\u6790\u65b9\u6cd5\u540d\u65b9\u9762\u6709\u4e00\u5b9a\u6548\u679c\u4f46\u4ecd\u9700\u4eba\u5de5\u8bc4\u4f30", "motivation": "\u79d1\u5b66\u7814\u7a76\u4eba\u5458\u8d8a\u6765\u8d8a\u4f9d\u8d56\u8f6f\u4ef6\u652f\u6301\u7814\u7a76\u5de5\u4f5c\uff0c\u4f46\u5173\u4e8e\u79d1\u5b66\u8f6f\u4ef6\u4e2d\u6807\u8bc6\u7b26\u547d\u540d\u8d28\u91cf\uff08\u7279\u522b\u662f\u65b9\u6cd5\u540d\u8d28\u91cf\uff09\u7684\u7814\u7a76\u6709\u9650\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u4e3a\u81ea\u52a8\u5316\u4ee3\u7801\u5206\u6790\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u673a\u4f1a", "method": "\u8bc4\u4f30\u56db\u4e2a\u6d41\u884c\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5206\u6790\u8bed\u6cd5\u6a21\u5f0f\u548c\u4e3a496\u4e2a\u4ece\u57fa\u4e8ePython\u7684Jupyter Notebooks\u4e2d\u63d0\u53d6\u7684\u65b9\u6cd5\u540d\u63d0\u4f9b\u6539\u8fdb\u5efa\u8bae\u7684\u80fd\u529b", "result": "LLMs\u5728\u5206\u6790\u65b9\u6cd5\u540d\u65b9\u9762\u8868\u73b0\u51fa\u4e00\u5b9a\u6548\u679c\uff0c\u901a\u5e38\u9075\u5faa\u826f\u597d\u7684\u547d\u540d\u5b9e\u8df5\uff08\u5982\u65b9\u6cd5\u540d\u4ee5\u52a8\u8bcd\u5f00\u5934\uff09\uff0c\u4f46\u5728\u5904\u7406\u9886\u57df\u7279\u5b9a\u672f\u8bed\u65b9\u9762\u4e0d\u4e00\u81f4\uff0c\u4e0e\u4eba\u5de5\u6807\u6ce8\u7684\u4e00\u81f4\u6027\u4ec5\u4e3a\u4e2d\u7b49\u6c34\u5e73", "conclusion": "\u81ea\u52a8\u5316\u5efa\u8bae\u9700\u8981\u4eba\u5de5\u8bc4\u4f30\uff0c\u8be5\u5de5\u4f5c\u4e3a\u901a\u8fc7AI\u81ea\u52a8\u5316\u6539\u8fdb\u79d1\u5b66\u4ee3\u7801\u8d28\u91cf\u63d0\u4f9b\u4e86\u57fa\u7840\u89c1\u89e3"}}
{"id": "2507.16773", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.16773", "abs": "https://arxiv.org/abs/2507.16773", "authors": ["Yue Li", "Xiao Li", "Hao Wu", "Yue Zhang", "Fengyuan Xu", "Xiuzhen Cheng", "Sheng Zhong"], "title": "When LLMs Copy to Think: Uncovering Copy-Guided Attacks in Reasoning LLMs", "comment": null, "summary": "Large Language Models (LLMs) have become integral to automated code analysis,\nenabling tasks such as vulnerability detection and code comprehension. However,\ntheir integration introduces novel attack surfaces. In this paper, we identify\nand investigate a new class of prompt-based attacks, termed Copy-Guided Attacks\n(CGA), which exploit the inherent copying tendencies of reasoning-capable LLMs.\nBy injecting carefully crafted triggers into external code snippets,\nadversaries can induce the model to replicate malicious content during\ninference. This behavior enables two classes of vulnerabilities: inference\nlength manipulation, where the model generates abnormally short or excessively\nlong reasoning traces; and inference result manipulation, where the model\nproduces misleading or incorrect conclusions. We formalize CGA as an\noptimization problem and propose a gradient-based approach to synthesize\neffective triggers. Empirical evaluation on state-of-the-art reasoning LLMs\nshows that CGA reliably induces infinite loops, premature termination, false\nrefusals, and semantic distortions in code analysis tasks. While highly\neffective in targeted settings, we observe challenges in generalizing CGA\nacross diverse prompts due to computational constraints, posing an open\nquestion for future research. Our findings expose a critical yet underexplored\nvulnerability in LLM-powered development pipelines and call for urgent advances\nin prompt-level defense mechanisms.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u4e86\u4e00\u79cd\u65b0\u7684\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u7684\u653b\u51fb\u65b9\u5f0f\u2014\u2014\u590d\u5236\u5f15\u5bfc\u653b\u51fb(CGA)\uff0c\u8be5\u653b\u51fb\u5229\u7528\u63a8\u7406\u578bLLM\u7684\u56fa\u6709\u590d\u5236\u503e\u5411\uff0c\u901a\u8fc7\u5728\u5916\u90e8\u4ee3\u7801\u4e2d\u6ce8\u5165\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u89e6\u53d1\u5668\u6765\u64cd\u7eb5\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\u548c\u7ed3\u679c\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5316\u4ee3\u7801\u5206\u6790\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5176\u96c6\u6210\u5f15\u5165\u4e86\u65b0\u7684\u653b\u51fb\u9762\u3002\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u57fa\u4e8e\u63d0\u793a\u7684\u653b\u51fb\u7684\u6df1\u5165\u63a2\u7d22\uff0c\u7279\u522b\u662f\u5229\u7528\u63a8\u7406\u578bLLM\u590d\u5236\u503e\u5411\u7684\u653b\u51fb\u65b9\u5f0f\uff0c\u8fd9\u4e3a\u6076\u610f\u653b\u51fb\u8005\u63d0\u4f9b\u4e86\u65b0\u7684\u653b\u51fb\u673a\u4f1a\u3002", "method": "\u5c06\u590d\u5236\u5f15\u5bfc\u653b\u51fb(CGA)\u5f62\u5f0f\u5316\u4e3a\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u57fa\u4e8e\u68af\u5ea6\u7684\u65b9\u6cd5\u6765\u5408\u6210\u6709\u6548\u7684\u89e6\u53d1\u5668\u3002\u901a\u8fc7\u5728\u5916\u90e8\u4ee3\u7801\u7247\u6bb5\u4e2d\u6ce8\u5165\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u89e6\u53d1\u5668\uff0c\u8bf1\u5bfc\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u590d\u5236\u6076\u610f\u5185\u5bb9\uff0c\u5b9e\u73b0\u5bf9\u63a8\u7406\u957f\u5ea6\u548c\u63a8\u7406\u7ed3\u679c\u7684\u64cd\u7eb5\u3002", "result": "\u5728\u6700\u5148\u8fdb\u7684\u63a8\u7406\u578bLLM\u4e0a\u7684\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793a\uff0cCGA\u80fd\u591f\u53ef\u9760\u5730\u8bf1\u5bfc\u65e0\u9650\u5faa\u73af\u3001\u8fc7\u65e9\u7ec8\u6b62\u3001\u865a\u5047\u62d2\u7edd\u4ee5\u53ca\u4ee3\u7801\u5206\u6790\u4efb\u52a1\u4e2d\u7684\u8bed\u4e49\u626d\u66f2\u3002\u653b\u51fb\u5728\u76ee\u6807\u8bbe\u7f6e\u4e0b\u9ad8\u5ea6\u6709\u6548\uff0c\u4f46\u5728\u8de8\u591a\u6837\u5316\u63d0\u793a\u7684\u6cdb\u5316\u65b9\u9762\u5b58\u5728\u6311\u6218\u3002", "conclusion": "\u7814\u7a76\u66b4\u9732\u4e86LLM\u9a71\u52a8\u7684\u5f00\u53d1\u6d41\u6c34\u7ebf\u4e2d\u4e00\u4e2a\u5173\u952e\u4f46\u672a\u5145\u5206\u63a2\u7d22\u7684\u6f0f\u6d1e\uff0c\u63ed\u793a\u4e86\u4e24\u7c7b\u4e3b\u8981\u653b\u51fb\uff1a\u63a8\u7406\u957f\u5ea6\u64cd\u7eb5\u548c\u63a8\u7406\u7ed3\u679c\u64cd\u7eb5\u3002\u8fd9\u4e9b\u53d1\u73b0\u547c\u5401\u5728\u63d0\u793a\u7ea7\u9632\u5fa1\u673a\u5236\u65b9\u9762\u53d6\u5f97\u7d27\u8feb\u8fdb\u5c55\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u51fa\u4e86\u5f00\u653e\u6027\u95ee\u9898\u3002"}}
{"id": "2507.16067", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.16067", "abs": "https://arxiv.org/abs/2507.16067", "authors": ["Jeroen Spaans", "Jesse Heyninck"], "title": "A Unifying Framework for Semiring-Based Constraint Logic Programming With Negation (full version)", "comment": "Full version, including proofs and appendices, of paper accepted at\n  IJCAI 2025", "summary": "Constraint Logic Programming (CLP) is a logic programming formalism used to\nsolve problems requiring the consideration of constraints, like resource\nallocation and automated planning and scheduling. It has previously been\nextended in various directions, for example to support fuzzy constraint\nsatisfaction, uncertainty, or negation, with different notions of semiring\nbeing used as a unifying abstraction for these generalizations. None of these\nextensions have studied clauses with negation allowed in the body. We\ninvestigate an extension of CLP which unifies many of these extensions and\nallows negation in the body. We provide semantics for such programs, using the\nframework of approximation fixpoint theory, and give a detailed overview of the\nimpacts of properties of the semirings on the resulting semantics. As such, we\nprovide a unifying framework that captures existing approaches and allows\nextending them with a more expressive language.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u7ea6\u675f\u903b\u8f91\u7f16\u7a0b\u6269\u5c55\u6846\u67b6\uff0c\u652f\u6301\u4f53\u90e8\u5426\u5b9a\uff0c\u5e76\u4f7f\u7528\u534a\u73af\u548c\u8fd1\u4f3c\u4e0d\u52a8\u70b9\u7406\u8bba\u63d0\u4f9b\u8bed\u4e49", "motivation": "\u73b0\u6709\u7684\u7ea6\u675f\u903b\u8f91\u7f16\u7a0b\u6269\u5c55\uff08\u5982\u6a21\u7cca\u7ea6\u675f\u6ee1\u8db3\u3001\u4e0d\u786e\u5b9a\u6027\u3001\u5426\u5b9a\u7b49\uff09\u90fd\u6ca1\u6709\u7814\u7a76\u5141\u8bb8\u4f53\u90e8\u5426\u5b9a\u7684\u5b50\u53e5\uff0c\u9700\u8981\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\u6765\u6574\u5408\u8fd9\u4e9b\u6269\u5c55\u5e76\u652f\u6301\u66f4\u5177\u8868\u8fbe\u529b\u7684\u8bed\u8a00", "method": "\u4f7f\u7528\u534a\u73af\u4f5c\u4e3a\u7edf\u4e00\u62bd\u8c61\u6765\u6cdb\u5316\u5404\u79cd\u6269\u5c55\uff0c\u91c7\u7528\u8fd1\u4f3c\u4e0d\u52a8\u70b9\u7406\u8bba\u6846\u67b6\u4e3a\u652f\u6301\u4f53\u90e8\u5426\u5b9a\u7684\u7ea6\u675f\u903b\u8f91\u7a0b\u5e8f\u63d0\u4f9b\u8bed\u4e49\uff0c\u5e76\u8be6\u7ec6\u5206\u6790\u534a\u73af\u6027\u8d28\u5bf9\u8bed\u4e49\u7684\u5f71\u54cd", "result": "\u6210\u529f\u6784\u5efa\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u6355\u83b7\u73b0\u6709\u65b9\u6cd5\u5e76\u5141\u8bb8\u4f7f\u7528\u66f4\u5177\u8868\u8fbe\u529b\u7684\u8bed\u8a00\u8fdb\u884c\u6269\u5c55\uff0c\u4e3a\u5e26\u6709\u4f53\u90e8\u5426\u5b9a\u7684\u7ea6\u675f\u903b\u8f91\u7a0b\u5e8f\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u8bed\u4e49\u5b9a\u4e49", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u7ea6\u675f\u903b\u8f91\u7f16\u7a0b\u6846\u67b6\uff0c\u4e0d\u4ec5\u6574\u5408\u4e86\u73b0\u6709\u7684\u5404\u79cd\u6269\u5c55\u65b9\u6cd5\uff0c\u8fd8\u652f\u6301\u4f53\u90e8\u5426\u5b9a\uff0c\u4ece\u800c\u5b9e\u73b0\u4e86\u66f4\u5f3a\u7684\u8868\u8fbe\u80fd\u529b\u548c\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f"}}
{"id": "2507.16587", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.16587", "abs": "https://arxiv.org/abs/2507.16587", "authors": ["Giuseppe Crupi", "Rosalia Tufano", "Alejandro Velasco", "Antonio Mastropaolo", "Denys Poshyvanyk", "Gabriele Bavota"], "title": "On the Effectiveness of LLM-as-a-judge for Code Generation and Summarization", "comment": "Accepted at TSE. IEEE Transactions on Software Engineering", "summary": "Large Language Models have been recently exploited as judges for complex\nnatural language processing tasks, such as Q&A. The basic idea is to delegate\nto an LLM the assessment of the \"quality\" of the output provided by an\nautomated technique for tasks for which: (i) quantitative metrics would only\ntell part of the story, and; (ii) a large-scale human-based evaluation would be\ntoo expensive. LLMs-as-a-judge, if proven effective for a specific task, can\nalso unlock new possibilities for automation, with several LLMs proposing a\nsolution for a given instance of the task and others judging and deciding what\nis the best output to show the user. We study the effectiveness of\nLLMs-as-a-judge for two code-related tasks, namely code generation and code\nsummarization. The rationale for choosing these tasks is two-fold. First,\nquantitative metrics are usually not enough for the assessment of code\nsummarizers/generators. For example, it is well documented that metrics such as\nBLEU are quite weak proxies for the quality of the generated summaries. Second,\neven state-of-the-art techniques still struggle with handling complex instances\nof these tasks, making them good candidates for benefiting from more advanced\nsolutions envisioning collaboration among LLMs. For code generation, we check\nwhether eight LLMs are able to judge the correctness of 1,405 Java methods and\n1,281 Python functions generated by the same LLMs or implemented by humans. For\ncode summarization, we compare the judgment of five LLMs to those provided by\nnine humans for ~1.2k summaries, related to both Java and Python functions. Our\nfindings show that GPT-4-turbo is the best LLM in terms of judging capabilities\nfor both tasks, with \"smaller\" LLMs featuring tens of billions parameters not\nbeing able to cope with judging tasks. However, even the best-performing LLM\nfrequently misjudges the correctness of the code and summary quality.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8bc4\u5224\u8005\u5728\u4ee3\u7801\u751f\u6210\u548c\u4ee3\u7801\u6458\u8981\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u53d1\u73b0GPT-4-turbo\u662f\u6700\u4f73\u8bc4\u5224\u6a21\u578b\uff0c\u4f46\u5373\u4f7f\u662f\u6700\u597d\u7684\u6a21\u578b\u4e5f\u7ecf\u5e38\u8bef\u5224\u4ee3\u7801\u6b63\u786e\u6027\u548c\u6458\u8981\u8d28\u91cf\u3002", "motivation": "\u4f20\u7edf\u5b9a\u91cf\u6307\u6807\uff08\u5982BLEU\uff09\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u4ee3\u7801\u751f\u6210\u548c\u6458\u8981\u8d28\u91cf\uff0c\u800c\u5927\u89c4\u6a21\u4eba\u5de5\u8bc4\u4f30\u6210\u672c\u8fc7\u9ad8\uff0c\u56e0\u6b64\u9700\u8981\u63a2\u7d22\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8bc4\u5224\u8005\u7684\u53ef\u884c\u6027\uff0c\u4ee5\u5b9e\u73b0\u81ea\u52a8\u5316\u8bc4\u4f30\u5e76\u652f\u6301\u591a\u6a21\u578b\u534f\u4f5c\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5bf98\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6d4b\u8bd5\uff0c\u8bc4\u52241,405\u4e2aJava\u65b9\u6cd5\u548c1,281\u4e2aPython\u51fd\u6570\u7684\u6b63\u786e\u6027\uff1b\u5bf95\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u4e0e9\u4e2a\u4eba\u7c7b\u8bc4\u5224\u8005\u8fdb\u884c\u6bd4\u8f83\uff0c\u8bc4\u4f30\u7ea61.2k\u4e2aJava\u548cPython\u51fd\u6570\u6458\u8981\u7684\u8d28\u91cf\uff1b\u901a\u8fc7\u5bf9\u6bd4\u5206\u6790\u6765\u8bc4\u4f30\u4e0d\u540c\u6a21\u578b\u7684\u8bc4\u5224\u80fd\u529b\u3002", "result": "GPT-4-turbo\u5728\u4e24\u4e2a\u4efb\u52a1\u4e2d\u90fd\u8868\u73b0\u51fa\u6700\u4f73\u7684\u8bc4\u5224\u80fd\u529b\uff1b\u53c2\u6570\u89c4\u6a21\u8f83\u5c0f\uff08\u6570\u767e\u4ebf\u53c2\u6570\uff09\u7684\u5927\u8bed\u8a00\u6a21\u578b\u65e0\u6cd5\u80dc\u4efb\u8bc4\u5224\u4efb\u52a1\uff1b\u5373\u4f7f\u662f\u8868\u73b0\u6700\u597d\u7684\u6a21\u578b\u4e5f\u7ecf\u5e38\u5728\u4ee3\u7801\u6b63\u786e\u6027\u548c\u6458\u8981\u8d28\u91cf\u5224\u65ad\u4e0a\u51fa\u73b0\u9519\u8bef\u3002", "conclusion": "\u867d\u7136GPT-4-turbo\u5728\u4ee3\u7801\u76f8\u5173\u4efb\u52a1\u7684\u8bc4\u5224\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u76ee\u524d\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8bc4\u5224\u8005\u4ecd\u5b58\u5728\u663e\u8457\u5c40\u9650\u6027\uff0c\u7ecf\u5e38\u51fa\u73b0\u8bef\u5224\uff0c\u8868\u660e\u8fd9\u4e00\u65b9\u6cd5\u5c1a\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u624d\u80fd\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u53ef\u9760\u4f7f\u7528\u3002"}}
{"id": "2507.16788", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2507.16788", "abs": "https://arxiv.org/abs/2507.16788", "authors": ["Sebastian Pape", "Anis Bkakria", "Maurice Heymann", "Badreddine Chah", "Abdeljalil Abbas-Turki", "Sarah Syed-Winkler", "Matthias Hiller", "Reda Yaich"], "title": "AUTOPSY: A Framework for Tackling Privacy Challenges in the Automotive Industry", "comment": "19 pages, 4 figures", "summary": "With the General Data Protection Regulation (GDPR) in place, all domains have\nto ensure compliance with privacy legislation. However, compliance does not\nnecessarily result in a privacy-friendly system as for example getting users'\nconsent to process their data does not improve the privacy-friendliness of the\nsystem. Therefore, the goal of the AUTOPSY project was to support the privacy\nengineering process in the automotive domain by providing several building\nblocks which technically improve the privacy-friendliness of modern, i.e.,\nconnected and (partially) automated vehicles. This paper presents the results\nof the AUTOPSY project: a system model to identify relevant entities and\nlocations to apply privacy enhancing technologies (PETs); the privacy manager\naiming at more control of the data flow from the vehicle, a PET selection\napproach based on GDPR principles, and an architectural framework for\nautomotive privacy. Furthermore, we built a demonstrator for location-based\nservices to evaluate the architectural framework.", "AI": {"tldr": "AUTOPSY\u9879\u76ee\u65e8\u5728\u901a\u8fc7\u63d0\u4f9b\u591a\u4e2a\u6280\u672f\u6784\u5efa\u6a21\u5757\u6765\u652f\u6301\u6c7d\u8f66\u9886\u57df\u7684\u9690\u79c1\u5de5\u7a0b\u8fc7\u7a0b\uff0c\u4ee5\u6280\u672f\u624b\u6bb5\u63d0\u5347\u73b0\u4ee3\u8054\u7f51\u548c(\u90e8\u5206)\u81ea\u52a8\u5316\u8f66\u8f86\u7684\u9690\u79c1\u53cb\u597d\u6027\u3002", "motivation": "\u5c3d\u7ba1GDPR\u5408\u89c4\u4e0d\u4e00\u5b9a\u80fd\u5e26\u6765\u9690\u79c1\u53cb\u597d\u7684\u7cfb\u7edf\uff08\u5982\u4ec5\u83b7\u5f97\u7528\u6237\u540c\u610f\u5904\u7406\u6570\u636e\u5e76\u4e0d\u80fd\u6539\u5584\u7cfb\u7edf\u7684\u9690\u79c1\u53cb\u597d\u6027\uff09\uff0c\u56e0\u6b64\u9700\u8981\u5728\u6c7d\u8f66\u9886\u57df\u5f00\u53d1\u6280\u672f\u624b\u6bb5\u6765\u771f\u6b63\u63d0\u5347\u9690\u79c1\u4fdd\u62a4\u6c34\u5e73\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7cfb\u7edf\u6a21\u578b\u6765\u8bc6\u522b\u76f8\u5173\u5b9e\u4f53\u548c\u4f4d\u7f6e\u4ee5\u5e94\u7528\u9690\u79c1\u589e\u5f3a\u6280\u672f(PETs)\uff1b\u8bbe\u8ba1\u4e86\u9690\u79c1\u7ba1\u7406\u5668\u4ee5\u66f4\u597d\u5730\u63a7\u5236\u8f66\u8f86\u6570\u636e\u6d41\uff1b\u57fa\u4e8eGDPR\u539f\u5219\u63d0\u51fa\u4e86PET\u9009\u62e9\u65b9\u6cd5\uff1b\u6784\u5efa\u4e86\u6c7d\u8f66\u9690\u79c1\u67b6\u6784\u6846\u67b6\uff1b\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8e\u4f4d\u7f6e\u670d\u52a1\u7684\u6f14\u793a\u5668\u6765\u8bc4\u4f30\u67b6\u6784\u6846\u67b6\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u5305\u542b\u7cfb\u7edf\u6a21\u578b\u3001\u9690\u79c1\u7ba1\u7406\u5668\u3001PET\u9009\u62e9\u65b9\u6cd5\u548c\u67b6\u6784\u6846\u67b6\u5728\u5185\u7684\u5b8c\u6574\u9690\u79c1\u5de5\u7a0b\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8e\u4f4d\u7f6e\u7684\u670d\u52a1\u6f14\u793a\u5668\u9a8c\u8bc1\u4e86\u67b6\u6784\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "AUTOPSY\u9879\u76ee\u6210\u529f\u63d0\u4f9b\u4e86\u652f\u6301\u6c7d\u8f66\u9886\u57df\u9690\u79c1\u5de5\u7a0b\u7684\u6280\u672f\u6784\u5efa\u6a21\u5757\uff0c\u80fd\u591f\u4ece\u6280\u672f\u5c42\u9762\u771f\u6b63\u6539\u5584\u73b0\u4ee3\u8054\u7f51\u548c\u81ea\u52a8\u5316\u8f66\u8f86\u7684\u9690\u79c1\u53cb\u597d\u6027\uff0c\u8d85\u8d8a\u4e86\u5355\u7eaf\u7684GDPR\u5408\u89c4\u8981\u6c42\u3002"}}
{"id": "2507.16110", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.16110", "abs": "https://arxiv.org/abs/2507.16110", "authors": ["Shengchao Liu", "Hannan Xu", "Yan Ai", "Huanxin Li", "Yoshua Bengio", "Harry Guo"], "title": "Expert-Guided LLM Reasoning for Battery Discovery: From AI-Driven Hypothesis to Synthesis and Characterization", "comment": null, "summary": "Large language models (LLMs) leverage chain-of-thought (CoT) techniques to\ntackle complex problems, representing a transformative breakthrough in\nartificial intelligence (AI). However, their reasoning capabilities have\nprimarily been demonstrated in solving math and coding problems, leaving their\npotential for domain-specific applications-such as battery discovery-largely\nunexplored. Inspired by the idea that reasoning mirrors a form of guided\nsearch, we introduce ChatBattery, a novel agentic framework that integrates\ndomain knowledge to steer LLMs toward more effective reasoning in materials\ndesign. Using ChatBattery, we successfully identify, synthesize, and\ncharacterize three novel lithium-ion battery cathode materials, which achieve\npractical capacity improvements of 28.8%, 25.2%, and 18.5%, respectively, over\nthe widely used cathode material, LiNi0.8Mn0.1Co0.1O2 (NMC811). Beyond this\ndiscovery, ChatBattery paves a new path by showing a successful LLM-driven and\nreasoning-based platform for battery materials invention. This complete\nAI-driven cycle-from design to synthesis to characterization-demonstrates the\ntransformative potential of AI-driven reasoning in revolutionizing materials\ndiscovery.", "AI": {"tldr": "\u7814\u7a76\u8005\u5f00\u53d1\u4e86ChatBattery\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u80fd\u529b\u8fdb\u884c\u7535\u6c60\u6750\u6599\u53d1\u73b0\uff0c\u6210\u529f\u8bbe\u8ba1\u3001\u5408\u6210\u5e76\u8868\u5f81\u4e86\u4e09\u79cd\u65b0\u578b\u9502\u79bb\u5b50\u7535\u6c60\u6b63\u6781\u6750\u6599\uff0c\u76f8\u6bd4\u73b0\u6709\u6750\u6599\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u5bb9\u91cf\u63d0\u5347\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u548c\u7f16\u7a0b\u95ee\u9898\u4e0a\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5728\u7279\u5b9a\u9886\u57df\u5e94\u7528\uff08\u5982\u7535\u6c60\u53d1\u73b0\uff09\u4e2d\u7684\u6f5c\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u7814\u7a76\u8005\u53d7\u5230\"\u63a8\u7406\u7c7b\u4f3c\u4e8e\u5f15\u5bfc\u641c\u7d22\"\u8fd9\u4e00\u7406\u5ff5\u542f\u53d1\uff0c\u5e0c\u671b\u5c06\u9886\u57df\u77e5\u8bc6\u6574\u5408\u5230LLM\u4e2d\u4ee5\u6307\u5bfc\u6750\u6599\u8bbe\u8ba1\u4e2d\u7684\u6709\u6548\u63a8\u7406\u3002", "method": "\u63d0\u51faChatBattery\u667a\u80fd\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u6574\u5408\u9886\u57df\u77e5\u8bc6\u6765\u5f15\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6750\u6599\u8bbe\u8ba1\u4e2d\u8fdb\u884c\u66f4\u6709\u6548\u7684\u63a8\u7406\u3002\u5229\u7528\u94fe\u5f0f\u601d\u7ef4\uff08CoT\uff09\u6280\u672f\u89e3\u51b3\u590d\u6742\u7684\u7535\u6c60\u6750\u6599\u53d1\u73b0\u95ee\u9898\uff0c\u5f62\u6210\u4ece\u8bbe\u8ba1\u5230\u5408\u6210\u518d\u5230\u8868\u5f81\u7684\u5b8c\u6574AI\u9a71\u52a8\u5faa\u73af\u3002", "result": "\u6210\u529f\u8bc6\u522b\u3001\u5408\u6210\u5e76\u8868\u5f81\u4e86\u4e09\u79cd\u65b0\u578b\u9502\u79bb\u5b50\u7535\u6c60\u6b63\u6781\u6750\u6599\uff0c\u76f8\u6bd4\u5e7f\u6cdb\u4f7f\u7528\u7684\u6b63\u6781\u6750\u6599LiNi0.8Mn0.1Co0.1O2 (NMC811)\uff0c\u5206\u522b\u5b9e\u73b0\u4e8628.8%\u300125.2%\u548c18.5%\u7684\u5b9e\u9645\u5bb9\u91cf\u6539\u5584\u3002", "conclusion": "ChatBattery\u4e3a\u57fa\u4e8eLLM\u9a71\u52a8\u548c\u63a8\u7406\u7684\u7535\u6c60\u6750\u6599\u53d1\u660e\u5f00\u8f9f\u4e86\u65b0\u8def\u5f84\uff0c\u5c55\u793a\u4e86AI\u9a71\u52a8\u63a8\u7406\u5728\u9769\u547d\u6027\u6750\u6599\u53d1\u73b0\u4e2d\u7684\u53d8\u9769\u6f5c\u529b\u3002\u8fd9\u4e2a\u5b8c\u6574\u7684AI\u9a71\u52a8\u5faa\u73af\u8bc1\u660e\u4e86\u4eba\u5de5\u667a\u80fd\u5728\u6750\u6599\u79d1\u5b66\u9886\u57df\u7684\u5de8\u5927\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2507.16661", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.16661", "abs": "https://arxiv.org/abs/2507.16661", "authors": ["Tan Bui", "Yan Naing Tun", "Thanh Phuc Nguyen", "Yindu Su", "Ferdian Thung", "Yikun Li", "Han Wei Ang", "Yide Yin", "Frank Liauw", "Lwin Khin Shar", "Eng Lieh Ouh", "Ting Zhang", "David Lo"], "title": "VulCoCo: A Simple Yet Effective Method for Detecting Vulnerable Code Clones", "comment": null, "summary": "Code reuse is common in modern software development, but it can also spread\nvulnerabilities when developers unknowingly copy risky code. The code fragments\nthat preserve the logic of known vulnerabilities are known as vulnerable code\nclones (VCCs). Detecting those VCCs is a critical but challenging task.\nExisting VCC detection tools often rely on syntactic similarity or produce\ncoarse vulnerability predictions without clear explanations, limiting their\npractical utility. In this paper, we propose VulCoCo, a lightweight and\nscalable approach that combines embedding-based retrieval with large language\nmodel (LLM) validation. Starting from a set of known vulnerable functions, we\nretrieve syntactically or semantically similar candidate functions from a large\ncorpus and use an LLM to assess whether the candidates retain the\nvulnerability. Given that there is a lack of reproducible vulnerable code clone\nbenchmarks, we first construct a synthetic benchmark that spans various clone\ntypes.\n  Our experiments on the benchmark show that VulCoCo outperforms prior\nstate-of-the-art methods in terms of Precision@k and mean average precision\n(MAP). In addition, we also demonstrate VulCoCo's effectiveness in real-world\nprojects by submitting 400 pull requests (PRs) to 284 open-source projects.\nAmong them, 75 PRs were merged, and 15 resulted in newly published CVEs. We\nalso provide insights to inspire future work to further improve the precision\nof vulnerable code clone detection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faVulCoCo\uff0c\u4e00\u79cd\u8f7b\u91cf\u7ea7\u4e14\u53ef\u6269\u5c55\u7684\u6f0f\u6d1e\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7ed3\u5408\u5d4c\u5165\u5f0f\u68c0\u7d22\u548c\u5927\u8bed\u8a00\u6a21\u578b\u9a8c\u8bc1\uff0c\u5728\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5728\u5b9e\u9645\u9879\u76ee\u4e2d\u6210\u529f\u53d1\u73b0\u6f0f\u6d1e\uff0c\u63d0\u4ea4\u7684400\u4e2a\u62c9\u53d6\u8bf7\u6c42\u4e2d\u670975\u4e2a\u88ab\u5408\u5e76\uff0c15\u4e2a\u5bfc\u81f4\u65b0\u7684CVE\u53d1\u5e03\u3002", "motivation": "\u73b0\u6709\u7684\u6f0f\u6d1e\u4ee3\u7801\u514b\u9686(VCC)\u68c0\u6d4b\u5de5\u5177\u5f80\u5f80\u4f9d\u8d56\u8bed\u6cd5\u76f8\u4f3c\u6027\u6216\u4ea7\u751f\u7c97\u7cd9\u7684\u6f0f\u6d1e\u9884\u6d4b\u4e14\u7f3a\u4e4f\u6e05\u6670\u89e3\u91ca\uff0c\u9650\u5236\u4e86\u5b9e\u7528\u6027\u3002\u540c\u65f6\u7f3a\u4e4f\u53ef\u91cd\u73b0\u7684\u6f0f\u6d1e\u4ee3\u7801\u514b\u9686\u57fa\u51c6\u6d4b\u8bd5\u3002\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u6765\u68c0\u6d4b\u4fdd\u7559\u5df2\u77e5\u6f0f\u6d1e\u903b\u8f91\u7684\u4ee3\u7801\u7247\u6bb5\u3002", "method": "\u63d0\u51faVulCoCo\u65b9\u6cd5\uff0c\u7ed3\u5408\u5d4c\u5165\u5f0f\u68c0\u7d22\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u9a8c\u8bc1\u3002\u4ece\u5df2\u77e5\u6f0f\u6d1e\u51fd\u6570\u96c6\u5408\u5f00\u59cb\uff0c\u4ece\u5927\u578b\u8bed\u6599\u5e93\u4e2d\u68c0\u7d22\u8bed\u6cd5\u6216\u8bed\u4e49\u76f8\u4f3c\u7684\u5019\u9009\u51fd\u6570\uff0c\u7136\u540e\u4f7f\u7528LLM\u8bc4\u4f30\u5019\u9009\u51fd\u6570\u662f\u5426\u4fdd\u7559\u6f0f\u6d1e\u3002\u6784\u5efa\u4e86\u6db5\u76d6\u5404\u79cd\u514b\u9686\u7c7b\u578b\u7684\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cVulCoCo\u5728Precision@k\u548c\u5e73\u5747\u7cbe\u5ea6(MAP)\u65b9\u9762\u8d85\u8d8a\u4e86\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002\u5728\u5b9e\u9645\u9879\u76ee\u4e2d\u5411284\u4e2a\u5f00\u6e90\u9879\u76ee\u63d0\u4ea4\u4e86400\u4e2a\u62c9\u53d6\u8bf7\u6c42\uff0c\u5176\u4e2d75\u4e2a\u88ab\u5408\u5e76\uff0c15\u4e2a\u5bfc\u81f4\u65b0\u53d1\u5e03\u7684CVE\u3002", "conclusion": "VulCoCo\u662f\u4e00\u79cd\u6709\u6548\u7684\u6f0f\u6d1e\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5728\u5408\u6210\u57fa\u51c6\u548c\u5b9e\u9645\u5e94\u7528\u4e2d\u90fd\u8868\u73b0\u51fa\u8272\u3002\u7814\u7a76\u8fd8\u4e3a\u672a\u6765\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6f0f\u6d1e\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u7cbe\u5ea6\u7684\u5de5\u4f5c\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2507.16226", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2507.16226", "abs": "https://arxiv.org/abs/2507.16226", "authors": ["Dong Ben", "Hui Feng", "Qian Wang"], "title": "Distilled Large Language Model in Confidential Computing Environment for System-on-Chip Design", "comment": "7 pages, 4 figures;", "summary": "Large Language Models (LLMs) are increasingly used in circuit design tasks\nand have typically undergone multiple rounds of training. Both the trained\nmodels and their associated training data are considered confidential\nintellectual property (IP) and must be protected from exposure. Confidential\nComputing offers a promising solution to protect data and models through\nTrusted Execution Environments (TEEs). However, existing TEE implementations\nare not designed to support the resource-intensive nature of LLMs efficiently.\nIn this work, we first present a comprehensive evaluation of the LLMs within a\nTEE-enabled confidential computing environment, specifically utilizing Intel\nTrust Domain Extensions (TDX). We constructed experiments on three\nenvironments: TEE-based, CPU-only, and CPU-GPU hybrid implementations, and\nevaluated their performance in terms of tokens per second.\n  Our first observation is that distilled models, i.e., DeepSeek, surpass other\nmodels in performance due to their smaller parameters, making them suitable for\nresource-constrained devices. Also, in the quantized models such as 4-bit\nquantization (Q4) and 8-bit quantization (Q8), we observed a performance gain\nof up to 3x compared to FP16 models. Our findings indicate that for fewer\nparameter sets, such as DeepSeek-r1-1.5B, the TDX implementation outperforms\nthe CPU version in executing computations within a secure environment. We\nfurther validate the results using a testbench designed for SoC design tasks.\nThese validations demonstrate the potential of efficiently deploying\nlightweight LLMs on resource-constrained systems for semiconductor CAD\napplications.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u53ef\u4fe1\u6267\u884c\u73af\u5883(TEE)\u4e2d\u90e8\u7f72\u5927\u8bed\u8a00\u6a21\u578b\u7528\u4e8e\u7535\u8def\u8bbe\u8ba1\u4efb\u52a1\u7684\u53ef\u884c\u6027\uff0c\u901a\u8fc7Intel TDX\u6280\u672f\u8bc4\u4f30\u4e86\u4e0d\u540c\u6a21\u578b\u914d\u7f6e\u7684\u6027\u80fd\u8868\u73b0", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7535\u8def\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u589e\u591a\uff0c\u4f46\u8bad\u7ec3\u6570\u636e\u548c\u6a21\u578b\u4f5c\u4e3a\u673a\u5bc6\u77e5\u8bc6\u4ea7\u6743\u9700\u8981\u4fdd\u62a4\u3002\u73b0\u6709TEE\u5b9e\u73b0\u65e0\u6cd5\u6709\u6548\u652f\u6301\u8d44\u6e90\u5bc6\u96c6\u578b\u7684LLM\uff0c\u56e0\u6b64\u9700\u8981\u8bc4\u4f30\u5728\u673a\u5bc6\u8ba1\u7b97\u73af\u5883\u4e2d\u90e8\u7f72LLM\u7684\u53ef\u884c\u6027\u548c\u6027\u80fd", "method": "\u6784\u5efa\u4e86\u4e09\u79cd\u5b9e\u9a8c\u73af\u5883(\u57fa\u4e8eTEE\u3001\u4ec5CPU\u3001CPU-GPU\u6df7\u5408)\uff0c\u4f7f\u7528Intel Trust Domain Extensions (TDX)\u6280\u672f\uff0c\u5728\u4e0d\u540c\u73af\u5883\u4e0b\u8bc4\u4f30\u591a\u79cdLLM\u6a21\u578b\u7684\u6027\u80fd\u8868\u73b0\uff0c\u4ee5\u6bcf\u79d2\u5904\u7406token\u6570\u4f5c\u4e3a\u8bc4\u4f30\u6307\u6807\uff0c\u5e76\u4f7f\u7528SoC\u8bbe\u8ba1\u4efb\u52a1\u6d4b\u8bd5\u53f0\u8fdb\u884c\u9a8c\u8bc1", "result": "\u84b8\u998f\u6a21\u578b(\u5982DeepSeek)\u7531\u4e8e\u53c2\u6570\u8f83\u5c11\u5728\u6027\u80fd\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u9002\u5408\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\uff1b\u91cf\u5316\u6a21\u578b(4\u4f4d\u548c8\u4f4d\u91cf\u5316)\u76f8\u6bd4FP16\u6a21\u578b\u6027\u80fd\u63d0\u5347\u8fbe3\u500d\uff1b\u5bf9\u4e8e\u53c2\u6570\u8f83\u5c11\u7684\u6a21\u578b\u5982DeepSeek-r1-1.5B\uff0cTDX\u5b9e\u73b0\u5728\u5b89\u5168\u73af\u5883\u4e2d\u7684\u8ba1\u7b97\u6027\u80fd\u8d85\u8fc7\u4e86CPU\u7248\u672c", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86\u5728\u8d44\u6e90\u53d7\u9650\u7cfb\u7edf\u4e0a\u4e3a\u534a\u5bfc\u4f53CAD\u5e94\u7528\u9ad8\u6548\u90e8\u7f72\u8f7b\u91cf\u7ea7LLM\u7684\u6f5c\u529b\uff0c\u4e3a\u5728\u4fdd\u62a4\u77e5\u8bc6\u4ea7\u6743\u7684\u540c\u65f6\u5b9e\u73b0LLM\u5728\u7535\u8def\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2507.16126", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16126", "abs": "https://arxiv.org/abs/2507.16126", "authors": ["Michael R. Bock", "Kara Molisee", "Zachary Ozer", "Sumit Shah"], "title": "TaxCalcBench: Evaluating Frontier Models on the Tax Calculation Task", "comment": null, "summary": "Can AI file your taxes? Not yet. Calculating US personal income taxes is a\ntask that requires building an understanding of vast amounts of English text\nand using that knowledge to carefully compute results. We propose TaxCalcBench,\na benchmark for determining models' abilities to calculate personal income tax\nreturns given all of the necessary information. Our experiment shows that\nstate-of-the-art models succeed in calculating less than a third of federal\nincome tax returns even on this simplified sample set. Our analysis concludes\nthat models consistently misuse tax tables, make errors in tax calculation, and\nincorrectly determine eligibility. Our findings point to the need for\nadditional infrastructure to apply LLMs to the personal income tax calculation\ntask.", "AI": {"tldr": "\u7814\u7a76\u8005\u63d0\u51fa\u4e86TaxCalcBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30AI\u6a21\u578b\u8ba1\u7b97\u4e2a\u4eba\u6240\u5f97\u7a0e\u7684\u80fd\u529b\u3002\u7ed3\u679c\u663e\u793a\u6700\u5148\u8fdb\u7684\u6a21\u578b\u5728\u7b80\u5316\u6837\u672c\u96c6\u4e0a\u7684\u6210\u529f\u7387\u4e0d\u5230\u4e09\u5206\u4e4b\u4e00\uff0c\u4e3b\u8981\u9519\u8bef\u5305\u62ec\u7a0e\u8868\u8bef\u7528\u3001\u8ba1\u7b97\u9519\u8bef\u548c\u8d44\u683c\u5224\u65ad\u5931\u8bef\u3002", "motivation": "\u76ee\u524d\u7f3a\u4e4f\u8bc4\u4f30AI\u6a21\u578b\u5904\u7406\u590d\u6742\u7a0e\u52a1\u8ba1\u7b97\u4efb\u52a1\u80fd\u529b\u7684\u57fa\u51c6\u3002\u7f8e\u56fd\u4e2a\u4eba\u6240\u5f97\u7a0e\u8ba1\u7b97\u9700\u8981\u7406\u89e3\u5927\u91cf\u82f1\u6587\u6587\u672c\u5e76\u8fdb\u884c\u7cbe\u786e\u8ba1\u7b97\uff0c\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u73b0\u5b9e\u5e94\u7528\u573a\u666f\uff0c\u9700\u8981\u4e13\u95e8\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u6d4b\u8bd5\u6a21\u578b\u5728\u8fd9\u4e00\u9886\u57df\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51faTaxCalcBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8be5\u57fa\u51c6\u4e3a\u6a21\u578b\u63d0\u4f9b\u8ba1\u7b97\u4e2a\u4eba\u6240\u5f97\u7a0e\u7533\u62a5\u8868\u6240\u9700\u7684\u5168\u90e8\u4fe1\u606f\uff0c\u7136\u540e\u8bc4\u4f30\u6a21\u578b\u8ba1\u7b97\u8054\u90a6\u6240\u5f97\u7a0e\u7684\u51c6\u786e\u6027\u3002\u901a\u8fc7\u5206\u6790\u6a21\u578b\u5728\u7a0e\u8868\u4f7f\u7528\u3001\u7a0e\u52a1\u8ba1\u7b97\u548c\u8d44\u683c\u786e\u5b9a\u65b9\u9762\u7684\u8868\u73b0\u6765\u8bc4\u4f30\u5176\u80fd\u529b\u3002", "result": "\u6700\u5148\u8fdb\u7684\u6a21\u578b\u5728\u7b80\u5316\u6837\u672c\u96c6\u4e0a\u8ba1\u7b97\u8054\u90a6\u6240\u5f97\u7a0e\u7533\u62a5\u8868\u7684\u6210\u529f\u7387\u4f4e\u4e8e\u4e09\u5206\u4e4b\u4e00\u3002\u6a21\u578b\u4e3b\u8981\u5b58\u5728\u4e09\u7c7b\u9519\u8bef\uff1a1) \u7a0e\u8868\u8bef\u7528\uff1b2) \u7a0e\u52a1\u8ba1\u7b97\u9519\u8bef\uff1b3) \u8d44\u683c\u786e\u5b9a\u9519\u8bef\u3002\u8fd9\u8868\u660e\u5f53\u524d\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u7a0e\u52a1\u8ba1\u7b97\u4efb\u52a1\u65b9\u9762\u5b58\u5728\u663e\u8457\u5c40\u9650\u6027\u3002", "conclusion": "\u5f53\u524d\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8fd8\u65e0\u6cd5\u80dc\u4efb\u4e2a\u4eba\u6240\u5f97\u7a0e\u8ba1\u7b97\u4efb\u52a1\u3002\u7814\u7a76\u53d1\u73b0\u6a21\u578b\u5728\u7a0e\u8868\u4f7f\u7528\u3001\u6570\u503c\u8ba1\u7b97\u548c\u8d44\u683c\u5224\u65ad\u7b49\u5173\u952e\u73af\u8282\u90fd\u5b58\u5728\u7cfb\u7edf\u6027\u9519\u8bef\uff0c\u8868\u660e\u9700\u8981\u989d\u5916\u7684\u57fa\u7840\u8bbe\u65bd\u548c\u6539\u8fdb\u624d\u80fd\u5c06LLMs\u6709\u6548\u5e94\u7528\u4e8e\u4e2a\u4eba\u6240\u5f97\u7a0e\u8ba1\u7b97\u9886\u57df\u3002"}}
{"id": "2507.16685", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.16685", "abs": "https://arxiv.org/abs/2507.16685", "authors": ["Duong Nguyen", "Manh Tran-Duc", "Thanh Le-Cong", "Triet Huynh Minh Le", "M. Ali Babar", "Quyet-Thang Huynh"], "title": "VulGuard: An Unified Tool for Evaluating Just-In-Time Vulnerability Prediction Models", "comment": null, "summary": "We present VulGuard, an automated tool designed to streamline the extraction,\nprocessing, and analysis of commits from GitHub repositories for Just-In-Time\nvulnerability prediction (JIT-VP) research. VulGuard automatically mines commit\nhistories, extracts fine-grained code changes, commit messages, and software\nengineering metrics, and formats them for downstream analysis. In addition, it\nintegrates several state-of-the-art vulnerability prediction models, allowing\nresearchers to train, evaluate, and compare models with minimal setup. By\nsupporting both repository-scale mining and model-level experimentation within\na unified framework, VulGuard addresses key challenges in reproducibility and\nscalability in software security research. VulGuard can also be easily\nintegrated into the CI/CD pipeline. We demonstrate the effectiveness of the\ntool in two influential open-source projects, FFmpeg and the Linux kernel,\nhighlighting its potential to accelerate real-world JIT-VP research and promote\nstandardized benchmarking. A demo video is available at:\nhttps://youtu.be/j96096-pxbs", "AI": {"tldr": "VulGuard\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u5de5\u5177\uff0c\u7528\u4e8e\u4eceGitHub\u4ed3\u5e93\u4e2d\u63d0\u53d6\u3001\u5904\u7406\u548c\u5206\u6790\u63d0\u4ea4\u8bb0\u5f55\uff0c\u4ee5\u652f\u6301\u5373\u65f6\u6f0f\u6d1e\u9884\u6d4b(JIT-VP)\u7814\u7a76\uff0c\u96c6\u6210\u4e86\u591a\u4e2a\u5148\u8fdb\u7684\u6f0f\u6d1e\u9884\u6d4b\u6a21\u578b\uff0c\u5e76\u53ef\u8f7b\u677e\u96c6\u6210\u5230CI/CD\u6d41\u6c34\u7ebf\u4e2d\u3002", "motivation": "\u89e3\u51b3\u8f6f\u4ef6\u5b89\u5168\u7814\u7a76\u4e2d\u5373\u65f6\u6f0f\u6d1e\u9884\u6d4b(JIT-VP)\u9762\u4e34\u7684\u53ef\u91cd\u73b0\u6027\u548c\u53ef\u6269\u5c55\u6027\u6311\u6218\uff0c\u7b80\u5316\u4eceGitHub\u4ed3\u5e93\u63d0\u53d6\u548c\u5206\u6790\u63d0\u4ea4\u8bb0\u5f55\u7684\u590d\u6742\u6d41\u7a0b\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u7edf\u4e00\u7684\u6846\u67b6\u6765\u8bad\u7ec3\u3001\u8bc4\u4f30\u548c\u6bd4\u8f83\u6f0f\u6d1e\u9884\u6d4b\u6a21\u578b\u3002", "method": "\u5f00\u53d1\u4e86VulGuard\u81ea\u52a8\u5316\u5de5\u5177\uff0c\u8be5\u5de5\u5177\u80fd\u591f\uff1a1)\u81ea\u52a8\u6316\u6398\u63d0\u4ea4\u5386\u53f2\u8bb0\u5f55\uff1b2)\u63d0\u53d6\u7ec6\u7c92\u5ea6\u4ee3\u7801\u53d8\u66f4\u3001\u63d0\u4ea4\u6d88\u606f\u548c\u8f6f\u4ef6\u5de5\u7a0b\u6307\u6807\uff1b3)\u5c06\u6570\u636e\u683c\u5f0f\u5316\u7528\u4e8e\u4e0b\u6e38\u5206\u6790\uff1b4)\u96c6\u6210\u591a\u4e2a\u6700\u5148\u8fdb\u7684\u6f0f\u6d1e\u9884\u6d4b\u6a21\u578b\uff1b5)\u652f\u6301\u4ed3\u5e93\u7ea7\u522b\u7684\u6316\u6398\u548c\u6a21\u578b\u7ea7\u522b\u7684\u5b9e\u9a8c\uff1b6)\u53ef\u96c6\u6210\u5230CI/CD\u6d41\u6c34\u7ebf\u4e2d\u3002", "result": "\u5728\u4e24\u4e2a\u6709\u5f71\u54cd\u529b\u7684\u5f00\u6e90\u9879\u76eeFFmpeg\u548cLinux\u5185\u6838\u4e0a\u6f14\u793a\u4e86\u5de5\u5177\u7684\u6709\u6548\u6027\uff0c\u8bc1\u660e\u4e86VulGuard\u5728\u5b9e\u9645JIT-VP\u7814\u7a76\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u5e76\u80fd\u591f\u4fc3\u8fdb\u6807\u51c6\u5316\u57fa\u51c6\u6d4b\u8bd5\u3002\u5de5\u5177\u652f\u6301\u6700\u5c0f\u5316\u8bbe\u7f6e\u7684\u6a21\u578b\u8bad\u7ec3\u3001\u8bc4\u4f30\u548c\u6bd4\u8f83\u3002", "conclusion": "VulGuard\u6210\u529f\u89e3\u51b3\u4e86\u8f6f\u4ef6\u5b89\u5168\u7814\u7a76\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u901a\u8fc7\u63d0\u4f9b\u7edf\u4e00\u7684\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5373\u65f6\u6f0f\u6d1e\u9884\u6d4b\u7814\u7a76\u7684\u53ef\u91cd\u73b0\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u6709\u671b\u52a0\u901f\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684JIT-VP\u7814\u7a76\u53d1\u5c55\u5e76\u63a8\u52a8\u6807\u51c6\u5316\u57fa\u51c6\u6d4b\u8bd5\u7684\u5efa\u7acb\u3002"}}
{"id": "2507.16145", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.16145", "abs": "https://arxiv.org/abs/2507.16145", "authors": ["Shuhao Mei", "Yongchao Long", "Shan Cao", "Xiaobo Han", "Shijia Geng", "Jinbo Sun", "Yuxi Zhou", "Shenda Hong"], "title": "SpiroLLM: Finetuning Pretrained LLMs to Understand Spirogram Time Series with Clinical Validation in COPD Reporting", "comment": null, "summary": "Chronic Obstructive Pulmonary Disease (COPD), a major chronic respiratory\ndisease with persistent airflow limitation, is a leading global cause of\ndisability and mortality. Respiratory spirogram time series, routinely\ncollected during pulmonary function tests (PFTs), play a critical role in the\nearly detection of repsiratory diseases and in monitoring lung function over\ntime. However, most current AI models for COPD diagnosis are limited to\noutputting classification results without providing a rationale for their\ndiagnostic process, while current Large Language Models (LLMs) cannot\nunderstand spirograms yet, which severely limits their clinical trust and\nadoption. To tackle this challenge, we leverage a cohort of 234,028 individuals\nfrom the UK Biobank (UKB) to propose SpiroLLM, the first multimodal large\nlanguage model that can understand spirogram. The model extracts morphological\nfeatures from respiratory curves via a SpiroEncoder and aligns them with PFT\nnumerical values in a unified latent space using a SpiroProjector, ultimately\nempowering a large language model to generate a comprehensive diagnostic\nreport. Experimental results confirm that SpiroLLM achieved a diagnostic AUROC\nof 0.8980 (95% CI: 0.8820-0.9132). In a robustness test with missing core data,\nit maintained a 100% valid response rate, far surpassing the 13.4% of a\ntext-only model and showcasing the superiority of its multimodal design. This\nwork demonstrates the substantial potential of deeply fusing physiological\nsignals with large language models, establishing a new paradigm for the next\ngeneration of interpretable and reliable clinical decision support tools.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86SpiroLLM\uff0c\u8fd9\u662f\u9996\u4e2a\u80fd\u591f\u7406\u89e3\u80ba\u529f\u80fd\u56fe\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u7528\u4e8e\u6162\u6027\u963b\u585e\u6027\u80ba\u75c5(COPD)\u8bca\u65ad\u3002\u6a21\u578b\u901a\u8fc7SpiroEncoder\u63d0\u53d6\u547c\u5438\u66f2\u7ebf\u7279\u5f81\uff0c\u4f7f\u7528SpiroProjector\u5c06\u5176\u4e0e\u6570\u503c\u6570\u636e\u5bf9\u9f50\uff0c\u6700\u7ec8\u751f\u6210\u7efc\u5408\u8bca\u65ad\u62a5\u544a\uff0c\u572823.4\u4e07\u4eba\u7684UK Biobank\u961f\u5217\u4e2d\u8fbe\u52300.8980\u7684AUROC\u3002", "motivation": "\u73b0\u6709\u7684COPD\u8bca\u65adAI\u6a21\u578b\u4ec5\u80fd\u8f93\u51fa\u5206\u7c7b\u7ed3\u679c\u800c\u65e0\u6cd5\u63d0\u4f9b\u8bca\u65ad\u4f9d\u636e\uff0c\u800c\u5f53\u524d\u7684\u5927\u8bed\u8a00\u6a21\u578b\u65e0\u6cd5\u7406\u89e3\u80ba\u529f\u80fd\u56fe\uff0c\u8fd9\u4e25\u91cd\u9650\u5236\u4e86\u4e34\u5e8a\u4fe1\u4efb\u5ea6\u548c\u5e94\u7528\u3002\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u65e2\u80fd\u7406\u89e3\u80ba\u529f\u80fd\u56fe\u53c8\u80fd\u63d0\u4f9b\u53ef\u89e3\u91ca\u8bca\u65ad\u7684\u6a21\u578b\u3002", "method": "\u63d0\u51faSpiroLLM\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) SpiroEncoder\u7528\u4e8e\u4ece\u547c\u5438\u66f2\u7ebf\u4e2d\u63d0\u53d6\u5f62\u6001\u5b66\u7279\u5f81\uff1b2) SpiroProjector\u5c06\u5f62\u6001\u5b66\u7279\u5f81\u4e0e\u80ba\u529f\u80fd\u6d4b\u8bd5\u6570\u503c\u5728\u7edf\u4e00\u6f5c\u5728\u7a7a\u95f4\u4e2d\u5bf9\u9f50\uff1b3) \u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7efc\u5408\u8bca\u65ad\u62a5\u544a\u3002\u4f7f\u7528UK Biobank\u7684234,028\u4e2a\u4e2a\u4f53\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u548c\u9a8c\u8bc1\u3002", "result": "SpiroLLM\u5728COPD\u8bca\u65ad\u4e2d\u8fbe\u52300.8980\u7684AUROC\uff0895% CI: 0.8820-0.9132\uff09\u3002\u5728\u7f3a\u5931\u6838\u5fc3\u6570\u636e\u7684\u9c81\u68d2\u6027\u6d4b\u8bd5\u4e2d\uff0c\u6a21\u578b\u4fdd\u6301100%\u7684\u6709\u6548\u54cd\u5e94\u7387\uff0c\u8fdc\u8d85\u4ec5\u6587\u672c\u6a21\u578b\u768413.4%\uff0c\u5c55\u73b0\u4e86\u591a\u6a21\u6001\u8bbe\u8ba1\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u751f\u7406\u4fe1\u53f7\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u6df1\u5ea6\u878d\u5408\u7684\u5de8\u5927\u6f5c\u529b\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u53ef\u89e3\u91ca\u4e14\u53ef\u9760\u7684\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u5de5\u5177\u5efa\u7acb\u4e86\u65b0\u7684\u8303\u5f0f\u3002SpiroLLM\u4f5c\u4e3a\u9996\u4e2a\u80fd\u7406\u89e3\u80ba\u529f\u80fd\u56fe\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5728COPD\u8bca\u65ad\u4e2d\u8868\u73b0\u51fa\u8272\u4e14\u5177\u6709\u826f\u597d\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2507.16754", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16754", "abs": "https://arxiv.org/abs/2507.16754", "authors": ["Fangjian Lei", "Mariam El Mezouar", "Shayan Noei", "Ying Zou"], "title": "Never Come Up Empty: Adaptive HyDE Retrieval for Improving LLM Developer Support", "comment": null, "summary": "Large Language Models (LLMs) have shown promise in assisting developers with\ncode-related questions; however, LLMs carry the risk of generating unreliable\nanswers. To address this, Retrieval-Augmented Generation (RAG) has been\nproposed to reduce the unreliability (i.e., hallucinations) of LLMs. However,\ndesigning effective pipelines remains challenging due to numerous design\nchoices. In this paper, we construct a retrieval corpus of over 3 million Java\nand Python related Stack Overflow posts with accepted answers, and explore\nvarious RAG pipeline designs to answer developer questions, evaluating their\neffectiveness in generating accurate and reliable responses. More specifically,\nwe (1) design and evaluate 7 different RAG pipelines and 63 pipeline variants\nto answer questions that have historically similar matches, and (2) address new\nquestions without any close prior matches by automatically lowering the\nsimilarity threshold during retrieval, thereby increasing the chance of finding\npartially relevant context and improving coverage for unseen cases. We find\nthat implementing a RAG pipeline combining hypothetical-documentation-embedding\n(HyDE) with the full-answer context performs best in retrieving and answering\nsimilarcontent for Stack Overflow questions. Finally, we apply our optimal RAG\npipeline to 4 open-source LLMs and compare the results to their zero-shot\nperformance. Our findings show that RAG with our optimal RAG pipeline\nconsistently outperforms zero-shot baselines across models, achieving higher\nscores for helpfulness, correctness, and detail with LLM-as-a-judge. These\nfindings demonstrate that our optimal RAG pipelines robustly enhance answer\nquality for a wide range of developer queries including both previously seen\nand novel questions across different LLMs", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u5305\u542b300\u4e07\u4e2aJava\u548cPython\u76f8\u5173Stack Overflow\u5e16\u5b50\u7684\u68c0\u7d22\u8bed\u6599\u5e93\uff0c\u8bbe\u8ba1\u5e76\u8bc4\u4f30\u4e867\u79cd\u4e0d\u540c\u7684RAG\u7ba1\u9053\u548c63\u4e2a\u7ba1\u9053\u53d8\u4f53\uff0c\u4ee5\u63d0\u9ad8\u5927\u8bed\u8a00\u6a21\u578b\u5728\u56de\u7b54\u5f00\u53d1\u8005\u95ee\u9898\u65f6\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u534f\u52a9\u5f00\u53d1\u8005\u89e3\u7b54\u4ee3\u7801\u76f8\u5173\u95ee\u9898\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u5b58\u5728\u751f\u6210\u4e0d\u53ef\u9760\u7b54\u6848\u7684\u98ce\u9669\u3002\u867d\u7136\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u88ab\u63d0\u51fa\u6765\u51cf\u5c11LLM\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u4f46\u8bbe\u8ba1\u6709\u6548\u7684RAG\u7ba1\u9053\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u6d89\u53ca\u4f17\u591a\u8bbe\u8ba1\u9009\u62e9\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b300\u4e07\u4e2aJava\u548cPython\u76f8\u5173Stack Overflow\u5e16\u5b50\u53ca\u5176\u88ab\u63a5\u53d7\u7b54\u6848\u7684\u68c0\u7d22\u8bed\u6599\u5e93\uff1b\u8bbe\u8ba1\u5e76\u8bc4\u4f30\u4e867\u79cd\u4e0d\u540c\u7684RAG\u7ba1\u9053\u548c63\u4e2a\u7ba1\u9053\u53d8\u4f53\uff1b\u9488\u5bf9\u5386\u53f2\u4e0a\u6709\u76f8\u4f3c\u5339\u914d\u7684\u95ee\u9898\u8fdb\u884c\u8bc4\u4f30\uff1b\u901a\u8fc7\u81ea\u52a8\u964d\u4f4e\u68c0\u7d22\u65f6\u7684\u76f8\u4f3c\u5ea6\u9608\u503c\u6765\u5904\u7406\u6ca1\u6709\u7d27\u5bc6\u5148\u9a8c\u5339\u914d\u7684\u65b0\u95ee\u9898\uff1b\u5c06\u6700\u4f18RAG\u7ba1\u9053\u5e94\u7528\u4e8e4\u4e2a\u5f00\u6e90LLM\u5e76\u4e0e\u96f6\u6837\u672c\u6027\u80fd\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u53d1\u73b0\u7ed3\u5408\u5047\u8bbe\u6587\u6863\u5d4c\u5165(HyDE)\u548c\u5b8c\u6574\u7b54\u6848\u4e0a\u4e0b\u6587\u7684RAG\u7ba1\u9053\u5728\u68c0\u7d22\u548c\u56de\u7b54Stack Overflow\u95ee\u9898\u7684\u76f8\u4f3c\u5185\u5bb9\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff1b\u6700\u4f18RAG\u7ba1\u9053\u5728\u6240\u6709\u6a21\u578b\u4e0a\u90fd\u6301\u7eed\u4f18\u4e8e\u96f6\u6837\u672c\u57fa\u51c6\uff0c\u5728LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u7684\u8bc4\u4f30\u4e2d\uff0c\u5728\u6709\u7528\u6027\u3001\u6b63\u786e\u6027\u548c\u8be6\u7ec6\u7a0b\u5ea6\u65b9\u9762\u83b7\u5f97\u66f4\u9ad8\u5206\u6570\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u6700\u4f18RAG\u7ba1\u9053\u80fd\u591f\u7a33\u5065\u5730\u63d0\u5347\u5e7f\u6cdb\u5f00\u53d1\u8005\u67e5\u8be2\u7684\u7b54\u6848\u8d28\u91cf\uff0c\u5305\u62ec\u5728\u4e0d\u540cLLM\u4e0a\u5904\u7406\u4e4b\u524d\u89c1\u8fc7\u7684\u548c\u65b0\u9896\u7684\u95ee\u9898\uff0c\u8bc1\u660e\u4e86RAG\u5728\u63d0\u9ad8\u4ee3\u7801\u76f8\u5173\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.16184", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.16184", "abs": "https://arxiv.org/abs/2507.16184", "authors": ["Myung Ho Kim"], "title": "Emergent Cognitive Convergence via Implementation: A Structured Loop Reflecting Four Theories of Mind (A Position Paper)", "comment": "21 pages", "summary": "We report the discovery of a structural convergence across four influential\ntheories of mind: Kahneman's dual-system theory, Friston's predictive\nprocessing, Minsky's society of mind, and Clark's extended mind-emerging\nunintentionally within a practical AI agent architecture called Agentic Flow.\nDesigned to address limitations in large language models (LLMs), Agentic Flow\ncomprises five interdependent modules such as Retrieval, Cognition, Control,\nMemory, and Action arranged in a recurrent cognitive loop. Although originally\ninspired only by Minsky and Clark, the system's structure retrospectively\naligns with computational motifs found in all four theories, including\npredictive modeling, associative recall, and error-sensitive control.\n  To assess this convergence, we conducted comparative experiments with\nbaseline LLM agents on multi-step reasoning tasks. The structured agent\nachieved 95.8% task success and exhibited strong constraint adherence, while\nthe baseline system succeeded 62.3% of the time. These results were not aimed\nat proving superiority, but at illustrating how theoretical structures may\nemerge through practical design choices rather than top-down theory.\n  We introduce PEACE as a descriptive meta-architecture that captures\ndesign-level regularities observed in Agentic Flow. Not intended as a new\ntheory, PEACE provides a shared vocabulary for understanding architectures\nshaped by real-world implementation demands. This paper should be read as a\nposition paper - an exploratory reflection on how implementation can surface\nlatent structural echoes of cognitive theory, without asserting theoretical\nunification.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u4e86\u4e00\u4e2a\u540d\u4e3aAgentic Flow\u7684AI\u667a\u80fd\u4f53\u67b6\u6784\u610f\u5916\u5730\u5728\u7ed3\u6784\u4e0a\u6536\u655b\u4e86\u56db\u4e2a\u91cd\u8981\u7684\u5fc3\u667a\u7406\u8bba\uff08Kahneman\u7684\u53cc\u7cfb\u7edf\u7406\u8bba\u3001Friston\u7684\u9884\u6d4b\u5904\u7406\u3001Minsky\u7684\u5fc3\u667a\u793e\u4f1a\u548cClark\u7684\u5ef6\u5c55\u5fc3\u667a\uff09\uff0c\u5e76\u63d0\u51fa\u4e86PEACE\u5143\u67b6\u6784\u6765\u63cf\u8ff0\u8fd9\u79cd\u8bbe\u8ba1\u5c42\u9762\u7684\u89c4\u5f8b\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5c40\u9650\u6027\uff0c\u8bbe\u8ba1\u5b9e\u7528\u7684AI\u667a\u80fd\u4f53\u67b6\u6784\u65f6\uff0c\u610f\u5916\u53d1\u73b0\u8be5\u67b6\u6784\u5728\u7ed3\u6784\u4e0a\u4e0e\u591a\u4e2a\u8ba4\u77e5\u7406\u8bba\u4ea7\u751f\u4e86\u6536\u655b\uff0c\u8fd9\u4fc3\u4f7f\u7814\u7a76\u8005\u63a2\u7d22\u5b9e\u73b0\u8fc7\u7a0b\u4e2d\u5982\u4f55\u81ea\u7136\u6d8c\u73b0\u51fa\u8ba4\u77e5\u7406\u8bba\u7684\u6f5c\u5728\u7ed3\u6784\u56de\u58f0\u3002", "method": "\u8bbe\u8ba1\u4e86\u5305\u542b\u68c0\u7d22\u3001\u8ba4\u77e5\u3001\u63a7\u5236\u3001\u8bb0\u5fc6\u548c\u884c\u52a8\u4e94\u4e2a\u76f8\u4e92\u4f9d\u8d56\u6a21\u5757\u7684Agentic Flow\u67b6\u6784\uff0c\u91c7\u7528\u5faa\u73af\u8ba4\u77e5\u56de\u8def\u3002\u901a\u8fc7\u4e0e\u57fa\u7ebfLLM\u667a\u80fd\u4f53\u5728\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u5bf9\u6bd4\u5b9e\u9a8c\u6765\u8bc4\u4f30\u6027\u80fd\uff0c\u5e76\u63d0\u51faPEACE\u5143\u67b6\u6784\u6765\u63cf\u8ff0\u89c2\u5bdf\u5230\u7684\u8bbe\u8ba1\u89c4\u5f8b\u6027\u3002", "result": "\u7ed3\u6784\u5316\u667a\u80fd\u4f53\u5728\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u4e2d\u8fbe\u523095.8%\u7684\u6210\u529f\u7387\u5e76\u8868\u73b0\u51fa\u5f3a\u7ea6\u675f\u9075\u5faa\u80fd\u529b\uff0c\u800c\u57fa\u7ebf\u7cfb\u7edf\u6210\u529f\u7387\u4ec5\u4e3a62.3%\u3002\u5b9e\u9a8c\u7ed3\u679c\u5c55\u793a\u4e86\u7406\u8bba\u7ed3\u6784\u5982\u4f55\u901a\u8fc7\u5b9e\u9645\u8bbe\u8ba1\u9009\u62e9\u800c\u975e\u81ea\u4e0a\u800c\u4e0b\u7684\u7406\u8bba\u6784\u5efa\u81ea\u7136\u6d8c\u73b0\u3002", "conclusion": "\u8fd9\u662f\u4e00\u7bc7\u7acb\u573a\u8bba\u6587\uff0c\u63a2\u7d22\u6027\u5730\u53cd\u601d\u4e86\u5b9e\u73b0\u8fc7\u7a0b\u5982\u4f55\u80fd\u591f\u663e\u73b0\u8ba4\u77e5\u7406\u8bba\u7684\u6f5c\u5728\u7ed3\u6784\u56de\u58f0\u3002PEACE\u63d0\u4f9b\u4e86\u7406\u89e3\u7531\u73b0\u5b9e\u4e16\u754c\u5b9e\u73b0\u9700\u6c42\u5851\u9020\u7684\u67b6\u6784\u7684\u5171\u4eab\u8bcd\u6c47\uff0c\u4f46\u5e76\u4e0d\u4e3b\u5f20\u7406\u8bba\u7edf\u4e00\uff0c\u800c\u662f\u8bf4\u660e\u4e86\u5b9e\u9645\u8bbe\u8ba1\u4e2d\u7406\u8bba\u7ed3\u6784\u7684\u81ea\u7136\u6d8c\u73b0\u3002"}}
{"id": "2507.16808", "categories": ["cs.SE", "cs.AI", "68N19, 68T05", "B.6.3; D.3.4; I.2.2; I.2.6"], "pdf": "https://arxiv.org/pdf/2507.16808", "abs": "https://arxiv.org/abs/2507.16808", "authors": ["Zhihao Xu", "Bixin Li", "Lulu Wang"], "title": "Rethinking LLM-Based RTL Code Optimization Via Timing Logic Metamorphosis", "comment": "13pages with 9 pictures and 2 tables", "summary": "Register Transfer Level(RTL) code optimization is crucial for achieving high\nperformance and low power consumption in digital circuit design. However,\ntraditional optimization methods often rely on manual tuning and heuristics,\nwhich can be time-consuming and error-prone. Recent studies proposed to\nleverage Large Language Models(LLMs) to assist in RTL code optimization. LLMs\ncan generate optimized code snippets based on natural language descriptions,\npotentially speeding up the optimization process. However, existing approaches\nhave not thoroughly evaluated the effectiveness of LLM-Based code optimization\nmethods for RTL code with complex timing logic. To address this gap, we\nconducted a comprehensive empirical investigation to assess the capability of\nLLM-Based RTL code optimization methods in handling RTL code with complex\ntiming logic. In this study, we first propose a new benchmark for RTL\noptimization evaluation. It comprises four subsets, each corresponding to a\nspecific area of RTL code optimization. Then we introduce a method based on\nmetamorphosis to systematically evaluate the effectiveness of LLM-Based RTL\ncode optimization methods.Our key insight is that the optimization\neffectiveness should remain consistent for semantically equivalent but more\ncomplex code. After intensive experiments, we revealed several key findings.\n(1) LLM-Based RTL optimization methods can effectively optimize logic\noperations and outperform existing compiler-based methods. (2) LLM-Based RTL\noptimization methods do not perform better than existing compiler-based methods\non RTL code with complex timing logic, particularly in timing control flow\noptimization and clock domain optimization. This is primarily attributed to the\nchallenges LLMs face in understanding timing logic in RTL code. Based on these\nfindings, we provide insights for further research in leveraging LLMs for RTL\ncode optimization.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u7684RTL\u4ee3\u7801\u4f18\u5316\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u65f6\u5e8f\u903b\u8f91\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u53d1\u73b0LLM\u5728\u903b\u8f91\u64cd\u4f5c\u4f18\u5316\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u590d\u6742\u65f6\u5e8f\u903b\u8f91\u4f18\u5316\u65b9\u9762\u4e0d\u5982\u4f20\u7edf\u7f16\u8bd1\u5668\u65b9\u6cd5", "motivation": "\u4f20\u7edfRTL\u4ee3\u7801\u4f18\u5316\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u8c03\u4f18\u548c\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u8017\u65f6\u4e14\u6613\u51fa\u9519\u3002\u867d\u7136\u6709\u7814\u7a76\u63d0\u51fa\u4f7f\u7528LLM\u8f85\u52a9RTL\u4ee3\u7801\u4f18\u5316\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u672a\u5145\u5206\u8bc4\u4f30LLM\u5728\u5904\u7406\u590d\u6742\u65f6\u5e8f\u903b\u8f91RTL\u4ee3\u7801\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u5b58\u5728\u8bc4\u4f30\u7a7a\u767d", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b\u56db\u4e2a\u5b50\u96c6\u7684\u65b0RTL\u4f18\u5316\u8bc4\u4f30\u57fa\u51c6\uff0c\u6bcf\u4e2a\u5b50\u96c6\u5bf9\u5e94RTL\u4ee3\u7801\u4f18\u5316\u7684\u7279\u5b9a\u9886\u57df\u3002\u5f15\u5165\u57fa\u4e8e\u53d8\u5f62\u6d4b\u8bd5\u7684\u65b9\u6cd5\u6765\u7cfb\u7edf\u8bc4\u4f30LLM-based RTL\u4ee3\u7801\u4f18\u5316\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u6838\u5fc3\u601d\u60f3\u662f\u4f18\u5316\u6548\u679c\u5728\u8bed\u4e49\u7b49\u4ef7\u4f46\u66f4\u590d\u6742\u7684\u4ee3\u7801\u4e0a\u5e94\u4fdd\u6301\u4e00\u81f4", "result": "\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u53d1\u73b0\uff1a(1) LLM-based RTL\u4f18\u5316\u65b9\u6cd5\u80fd\u6709\u6548\u4f18\u5316\u903b\u8f91\u64cd\u4f5c\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u7f16\u8bd1\u5668\u65b9\u6cd5\uff1b(2) \u5728\u590d\u6742\u65f6\u5e8f\u903b\u8f91\u7684RTL\u4ee3\u7801\u4e0a\uff0c\u7279\u522b\u662f\u65f6\u5e8f\u63a7\u5236\u6d41\u4f18\u5316\u548c\u65f6\u949f\u57df\u4f18\u5316\u65b9\u9762\uff0cLLM-based\u65b9\u6cd5\u8868\u73b0\u4e0d\u5982\u73b0\u6709\u7f16\u8bd1\u5668\u65b9\u6cd5", "conclusion": "LLM\u5728\u7406\u89e3RTL\u4ee3\u7801\u4e2d\u7684\u65f6\u5e8f\u903b\u8f91\u65b9\u9762\u9762\u4e34\u6311\u6218\uff0c\u8fd9\u662f\u5176\u5728\u590d\u6742\u65f6\u5e8f\u903b\u8f91\u4f18\u5316\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\u7684\u4e3b\u8981\u539f\u56e0\u3002\u7814\u7a76\u4e3a\u8fdb\u4e00\u6b65\u5229\u7528LLM\u8fdb\u884cRTL\u4ee3\u7801\u4f18\u5316\u63d0\u4f9b\u4e86\u89c1\u89e3\u548c\u6307\u5bfc"}}
{"id": "2507.16204", "categories": ["cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2507.16204", "abs": "https://arxiv.org/abs/2507.16204", "authors": ["Li-Hsiang Shen", "Jyun-Jhe Huang"], "title": "CHIMERA: Compressed Hybrid Intelligence for Twin-Model Enhanced Multi-Agent Deep Reinforcement Learning for Multi-Functional RIS-Assisted Space-Air-Ground Integrated Networks", "comment": null, "summary": "A space-air-ground integrated network (SAGIN) architecture is proposed,\nempowered by multi-functional reconfigurable intelligent surfaces (MF-RIS)\ncapable of simultaneously reflecting, amplifying, and harvesting wireless\nenergy. The MF-RIS plays a pivotal role in addressing the energy shortages of\nlow-Earth orbit (LEO) satellites operating in shadowed regions, while\nexplicitly accounting for both communication and computing energy consumption\nacross the SAGIN nodes. To maximize the long-term energy efficiency (EE), we\nformulate a joint optimization problem over the MF-RIS parameters, including\nsignal amplification, phase-shifts, energy harvesting ratio, and active element\nselection as well as the SAGIN parameters of beamforming vectors, high-altitude\nplatform station (HAPS) deployment, user association, and computing capability.\nThe formulated problem is highly non-convex and non-linear and contains mixed\ndiscrete-continuous parameters. To tackle this, we conceive a compressed hybrid\nintelligence for twin-model enhanced multi-agent deep reinforcement learning\n(CHIMERA) framework, which integrates semantic state-action compression and\nparametrized sharing under hybrid reinforcement learning to efficiently explore\nsuitable complex actions. The simulation results have demonstrated that the\nproposed CHIMERA scheme substantially outperforms the conventional benchmarks,\nincluding fixed-configuration or non-harvesting MF-RIS, traditional RIS, and\nno-RIS cases, as well as centralized and multi-agent deep reinforcement\nlearning baselines in terms of the highest EE. Moreover, the proposed\nSAGIN-MF-RIS architecture achieves superior EE performance due to its\ncomplementary coverage, offering notable advantages over either standalone\nsatellite, aerial, or ground-only deployments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7531\u591a\u529f\u80fd\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762(MF-RIS)\u589e\u5f3a\u7684\u7a7a-\u5929-\u5730\u4e00\u4f53\u5316\u7f51\u7edc\u67b6\u6784\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316MF-RIS\u53c2\u6570\u548c\u7f51\u7edc\u53c2\u6570\u6765\u6700\u5927\u5316\u957f\u671f\u80fd\u6548\uff0c\u5e76\u8bbe\u8ba1\u4e86CHIMERA\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u6765\u89e3\u51b3\u590d\u6742\u7684\u975e\u51f8\u4f18\u5316\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u4f4e\u8f68\u536b\u661f\u5728\u9634\u5f71\u533a\u57df\u7684\u80fd\u91cf\u77ed\u7f3a\u95ee\u9898\uff0c\u540c\u65f6\u8003\u8651\u7a7a-\u5929-\u5730\u4e00\u4f53\u5316\u7f51\u7edc\u4e2d\u901a\u4fe1\u548c\u8ba1\u7b97\u7684\u80fd\u8017\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u53cd\u5c04\u3001\u653e\u5927\u548c\u6536\u96c6\u65e0\u7ebf\u80fd\u91cf\u7684\u667a\u80fd\u8868\u9762\u6280\u672f\u6765\u63d0\u5347\u7f51\u7edc\u7684\u957f\u671f\u80fd\u6548\u3002", "method": "\u63d0\u51fa\u591a\u529f\u80fd\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762(MF-RIS)\u589e\u5f3a\u7684\u7a7a-\u5929-\u5730\u4e00\u4f53\u5316\u7f51\u7edc\u67b6\u6784\uff0c\u5efa\u7acb\u8054\u5408\u4f18\u5316\u95ee\u9898\u5305\u62ecMF-RIS\u53c2\u6570(\u4fe1\u53f7\u653e\u5927\u3001\u76f8\u79fb\u3001\u80fd\u91cf\u6536\u96c6\u6bd4\u4f8b\u3001\u6709\u6e90\u5143\u4ef6\u9009\u62e9)\u548c\u7f51\u7edc\u53c2\u6570(\u6ce2\u675f\u6210\u5f62\u3001\u9ad8\u7a7a\u5e73\u53f0\u90e8\u7f72\u3001\u7528\u6237\u5173\u8054\u3001\u8ba1\u7b97\u80fd\u529b)\uff1b\u8bbe\u8ba1CHIMERA\u6846\u67b6\uff0c\u96c6\u6210\u8bed\u4e49\u72b6\u6001-\u52a8\u4f5c\u538b\u7f29\u548c\u53c2\u6570\u5316\u5171\u4eab\u7684\u6df7\u5408\u5f3a\u5316\u5b66\u4e60\u6765\u9ad8\u6548\u63a2\u7d22\u590d\u6742\u52a8\u4f5c\u7a7a\u95f4\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cCHIMERA\u65b9\u6848\u5728\u80fd\u6548\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u57fa\u51c6\u65b9\u6cd5\uff0c\u5305\u62ec\u56fa\u5b9a\u914d\u7f6e\u6216\u975e\u6536\u96c6\u80fd\u91cf\u7684MF-RIS\u3001\u4f20\u7edfRIS\u3001\u65e0RIS\u60c5\u51b5\uff0c\u4ee5\u53ca\u96c6\u4e2d\u5f0f\u548c\u591a\u667a\u80fd\u4f53\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u57fa\u51c6\uff1b\u6240\u63d0\u51fa\u7684SAGIN-MF-RIS\u67b6\u6784\u901a\u8fc7\u4e92\u8865\u8986\u76d6\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u80fd\u6548\u6027\u80fd\uff0c\u76f8\u6bd4\u5355\u72ec\u7684\u536b\u661f\u3001\u7a7a\u4e2d\u6216\u5730\u9762\u90e8\u7f72\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002", "conclusion": "\u591a\u529f\u80fd\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\u589e\u5f3a\u7684\u7a7a-\u5929-\u5730\u4e00\u4f53\u5316\u7f51\u7edc\u67b6\u6784\u80fd\u591f\u6709\u6548\u89e3\u51b3\u80fd\u91cf\u77ed\u7f3a\u95ee\u9898\u5e76\u663e\u8457\u63d0\u5347\u7f51\u7edc\u80fd\u6548\uff0cCHIMERA\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u4e3a\u89e3\u51b3\u590d\u6742\u7684\u6df7\u5408\u79bb\u6563-\u8fde\u7eed\u975e\u51f8\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\uff0c\u8be5\u67b6\u6784\u7684\u4e92\u8865\u8986\u76d6\u7279\u6027\u4f7f\u5176\u5728\u80fd\u6548\u6027\u80fd\u65b9\u9762\u4f18\u4e8e\u5355\u4e00\u7f51\u7edc\u90e8\u7f72\u65b9\u6848\u3002"}}
{"id": "2507.16229", "categories": ["cs.AI", "cs.CY", "cs.HC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.16229", "abs": "https://arxiv.org/abs/2507.16229", "authors": ["Bo Wen", "Chen Wang", "Qiwei Han", "Raquel Norel", "Julia Liu", "Thaddeus Stappenbeck", "Jeffrey L. Rogers"], "title": "Voice-based AI Agents: Filling the Economic Gaps in Digital Health Delivery", "comment": "IEEE International Conference on Digital Health (ICDH) 2025", "summary": "The integration of voice-based AI agents in healthcare presents a\ntransformative opportunity to bridge economic and accessibility gaps in digital\nhealth delivery. This paper explores the role of large language model\n(LLM)-powered voice assistants in enhancing preventive care and continuous\npatient monitoring, particularly in underserved populations. Drawing insights\nfrom the development and pilot study of Agent PULSE (Patient Understanding and\nLiaison Support Engine) -- a collaborative initiative between IBM Research,\nCleveland Clinic Foundation, and Morehouse School of Medicine -- we present an\neconomic model demonstrating how AI agents can provide cost-effective\nhealthcare services where human intervention is economically unfeasible. Our\npilot study with 33 inflammatory bowel disease patients revealed that 70\\%\nexpressed acceptance of AI-driven monitoring, with 37\\% preferring it over\ntraditional modalities. Technical challenges, including real-time\nconversational AI processing, integration with healthcare systems, and privacy\ncompliance, are analyzed alongside policy considerations surrounding\nregulation, bias mitigation, and patient autonomy. Our findings suggest that\nAI-driven voice agents not only enhance healthcare scalability and efficiency\nbut also improve patient engagement and accessibility. For healthcare\nexecutives, our cost-utility analysis demonstrates huge potential savings for\nroutine monitoring tasks, while technologists can leverage our framework to\nprioritize improvements yielding the highest patient impact. By addressing\ncurrent limitations and aligning AI development with ethical and regulatory\nframeworks, voice-based AI agents can serve as a critical entry point for\nequitable, sustainable digital healthcare solutions.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u57fa\u4e8e\u8bed\u97f3\u7684AI\u667a\u80fd\u4f53\u5728\u533b\u7597\u4fdd\u5065\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7Agent PULSE\u7cfb\u7edf\u7684\u8bd5\u70b9\u7814\u7a76\uff0c\u8bc1\u660e\u4e86AI\u8bed\u97f3\u52a9\u624b\u5728\u9884\u9632\u62a4\u7406\u548c\u60a3\u8005\u76d1\u6d4b\u65b9\u9762\u7684\u5de8\u5927\u6f5c\u529b\uff0c\u80fd\u591f\u6709\u6548\u964d\u4f4e\u6210\u672c\u5e76\u63d0\u9ad8\u533b\u7597\u670d\u52a1\u7684\u53ef\u53ca\u6027\u3002", "motivation": "\u89e3\u51b3\u6570\u5b57\u533b\u7597\u670d\u52a1\u4e2d\u7684\u7ecf\u6d4e\u548c\u53ef\u53ca\u6027\u5dee\u8ddd\uff0c\u7279\u522b\u662f\u4e3a\u670d\u52a1\u4e0d\u8db3\u7684\u4eba\u7fa4\u63d0\u4f9b\u6210\u672c\u6709\u6548\u7684\u533b\u7597\u4fdd\u5065\u670d\u52a1\uff0c\u901a\u8fc7AI\u8bed\u97f3\u667a\u80fd\u4f53\u5f25\u8865\u4eba\u5de5\u5e72\u9884\u5728\u7ecf\u6d4e\u4e0a\u4e0d\u53ef\u884c\u7684\u9886\u57df\u3002", "method": "\u5f00\u53d1\u5e76\u8bd5\u70b9\u6d4b\u8bd5Agent PULSE\u7cfb\u7edf\uff08\u60a3\u8005\u7406\u89e3\u548c\u8054\u7edc\u652f\u6301\u5f15\u64ce\uff09\uff0c\u8fd9\u662fIBM\u7814\u7a76\u9662\u3001\u514b\u5229\u592b\u5170\u8bca\u6240\u57fa\u91d1\u4f1a\u548c\u83ab\u5c14\u8c6a\u65af\u533b\u5b66\u9662\u7684\u5408\u4f5c\u9879\u76ee\u3002\u5efa\u7acb\u7ecf\u6d4e\u6a21\u578b\u5206\u6790AI\u667a\u80fd\u4f53\u7684\u6210\u672c\u6548\u76ca\uff0c\u5e76\u5bf933\u540d\u708e\u75c7\u6027\u80a0\u75c5\u60a3\u8005\u8fdb\u884c\u8bd5\u70b9\u7814\u7a76\u3002", "result": "70%\u7684\u60a3\u8005\u63a5\u53d7AI\u9a71\u52a8\u7684\u76d1\u6d4b\uff0c37%\u7684\u60a3\u8005\u66f4\u504f\u597dAI\u76d1\u6d4b\u800c\u975e\u4f20\u7edf\u65b9\u5f0f\u3002\u6210\u672c\u6548\u7528\u5206\u6790\u663e\u793a\u5728\u5e38\u89c4\u76d1\u6d4b\u4efb\u52a1\u65b9\u9762\u5177\u6709\u5de8\u5927\u7684\u6f5c\u5728\u8282\u7ea6\u3002\u6280\u672f\u6311\u6218\u5305\u62ec\u5b9e\u65f6\u5bf9\u8bddAI\u5904\u7406\u3001\u4e0e\u533b\u7597\u7cfb\u7edf\u96c6\u6210\u548c\u9690\u79c1\u5408\u89c4\u7b49\u65b9\u9762\u3002", "conclusion": "\u57fa\u4e8e\u8bed\u97f3\u7684AI\u667a\u80fd\u4f53\u4e0d\u4ec5\u80fd\u63d0\u9ad8\u533b\u7597\u4fdd\u5065\u7684\u53ef\u6269\u5c55\u6027\u548c\u6548\u7387\uff0c\u8fd8\u80fd\u6539\u5584\u60a3\u8005\u53c2\u4e0e\u5ea6\u548c\u53ef\u53ca\u6027\u3002\u901a\u8fc7\u89e3\u51b3\u5f53\u524d\u9650\u5236\u5e76\u5c06AI\u5f00\u53d1\u4e0e\u4f26\u7406\u548c\u76d1\u7ba1\u6846\u67b6\u4fdd\u6301\u4e00\u81f4\uff0c\u8bed\u97f3AI\u667a\u80fd\u4f53\u53ef\u4ee5\u6210\u4e3a\u516c\u5e73\u3001\u53ef\u6301\u7eed\u6570\u5b57\u533b\u7597\u89e3\u51b3\u65b9\u6848\u7684\u5173\u952e\u5165\u53e3\u70b9\u3002"}}
{"id": "2507.16395", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.16395", "abs": "https://arxiv.org/abs/2507.16395", "authors": ["Bo Hou", "Xin Tan", "Kai Zheng", "Fang Liu", "Yinghao Zhu", "Li Zhang"], "title": "LLM-Driven Collaborative Model for Untangling Commits via Explicit and Implicit Dependency Reasoning", "comment": null, "summary": "Atomic commits, each of which addresses a single development concern, are a\nbest practice in software development. However, developers frequently produce\ntangled commits that mix unrelated changes due to practical constraints or\nunclear boundaries, negatively impacting code review and maintenance. Although\nprior commit untangling approaches: rule-based, feature-based, or graph-based,\nhave made progress, they often rely on shallow signals and fail to distinguish\nbetween explicit dependencies (e.g., control/data flow) and implicit ones\n(e.g., semantic or conceptual relationships). In this paper, we propose\nColaUntangle, a new collaborative consultation framework for commit untangling\nthat models both explicit and implicit dependencies among code changes.\nColaUntangle integrates Large Language Model (LLM)-driven agents in a\nmulti-agent architecture: one agent specializes in explicit dependencies,\nanother in implicit ones, and a reviewer agent synthesizes their perspectives\nthrough iterative consultation. To capture explicit and implicit contextual\ninformation, we construct multi-version Program Dependency Graphs (delta-PDG),\nenabling agents to reason over code relationships with both symbolic and\nsemantic depth. We evaluate ColaUntangle on two widely-used datasets (1,612 C#\nand 14k Java tangled commits). Experimental results show that ColaUntangle\noutperforms the best-performing baseline, achieving an improvement of 44% on\nthe C# dataset and 100% on the Java dataset. These findings highlight the\npotential of LLM-based collaborative frameworks for advancing automated commit\nuntangling tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faColaUntangle\uff0c\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7684\u4ee3\u7801\u63d0\u4ea4\u62c6\u5206\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u548c\u9690\u5f0f\u4f9d\u8d56\u5efa\u6a21\u663e\u8457\u63d0\u5347\u4e86\u6df7\u5408\u63d0\u4ea4\u7684\u81ea\u52a8\u62c6\u5206\u6027\u80fd\u3002", "motivation": "\u5f00\u53d1\u8005\u7ecf\u5e38\u4ea7\u751f\u6df7\u5408\u4e86\u65e0\u5173\u53d8\u66f4\u7684\u7ea0\u7f20\u63d0\u4ea4\uff0c\u8fd9\u4f1a\u8d1f\u9762\u5f71\u54cd\u4ee3\u7801\u5ba1\u67e5\u548c\u7ef4\u62a4\u3002\u73b0\u6709\u7684\u57fa\u4e8e\u89c4\u5219\u3001\u7279\u5f81\u6216\u56fe\u7684\u63d0\u4ea4\u62c6\u5206\u65b9\u6cd5\u4f9d\u8d56\u6d45\u5c42\u4fe1\u53f7\uff0c\u65e0\u6cd5\u6709\u6548\u533a\u5206\u663e\u5f0f\u4f9d\u8d56\uff08\u5982\u63a7\u5236/\u6570\u636e\u6d41\uff09\u548c\u9690\u5f0f\u4f9d\u8d56\uff08\u5982\u8bed\u4e49\u6216\u6982\u5ff5\u5173\u7cfb\uff09\u3002", "method": "\u63d0\u51faColaUntangle\u534f\u4f5c\u54a8\u8be2\u6846\u67b6\uff0c\u91c7\u7528\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff1a\u4e00\u4e2a\u667a\u80fd\u4f53\u4e13\u95e8\u5904\u7406\u663e\u5f0f\u4f9d\u8d56\uff0c\u53e6\u4e00\u4e2a\u5904\u7406\u9690\u5f0f\u4f9d\u8d56\uff0c\u5ba1\u67e5\u667a\u80fd\u4f53\u901a\u8fc7\u8fed\u4ee3\u54a8\u8be2\u7efc\u5408\u4e24\u8005\u89c2\u70b9\u3002\u6784\u5efa\u591a\u7248\u672c\u7a0b\u5e8f\u4f9d\u8d56\u56fe(delta-PDG)\u6765\u6355\u83b7\u663e\u5f0f\u548c\u9690\u5f0f\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u5728\u7b26\u53f7\u548c\u8bed\u4e49\u5c42\u9762\u63a8\u7406\u4ee3\u7801\u5173\u7cfb\u3002", "result": "\u5728\u4e24\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u6570\u636e\u96c6\uff081,612\u4e2aC#\u548c14k\u4e2aJava\u7ea0\u7f20\u63d0\u4ea4\uff09\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0cColaUntangle\u8d85\u8d8a\u4e86\u6700\u4f73\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728C#\u6570\u636e\u96c6\u4e0a\u63d0\u534744%\uff0c\u5728Java\u6570\u636e\u96c6\u4e0a\u63d0\u5347100%\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u7a81\u51fa\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u534f\u4f5c\u6846\u67b6\u5728\u63a8\u8fdb\u81ea\u52a8\u5316\u63d0\u4ea4\u62c6\u5206\u4efb\u52a1\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u8bc1\u660e\u4e86\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u548c\u663e\u5f0f/\u9690\u5f0f\u4f9d\u8d56\u5efa\u6a21\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.16280", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16280", "abs": "https://arxiv.org/abs/2507.16280", "authors": ["Tianze Xu", "Pengrui Lu", "Lyumanshan Ye", "Xiangkun Hu", "Pengfei Liu"], "title": "ResearcherBench: Evaluating Deep AI Research Systems on the Frontiers of Scientific Inquiry", "comment": "22 pages, 3 figures", "summary": "The emergence of deep research systems presents significant capabilities in\nproblem-solving, extending from basic queries to sophisticated research tasks.\nHowever, existing benchmarks primarily evaluate these systems as agents for web\nretrieval and report generation, overlooking their potential to discover novel\ninsights on the frontiers of scientific research. To address this gap, we\nintroduce ResearcherBench, the first benchmark focused on evaluating the\ncapabilities of these advanced, agentic systems - which we refer to as Deep AI\nResearch Systems (DARS) - on frontier AI scientific questions. We compiled a\ndataset of 65 research questions expertly selected from real-world scientific\nscenarios such as laboratory discussions and interviews, spanning 35 different\nAI subjects and categorized into three types: technical details, literature\nreview, and open consulting. Our dual evaluation framework combines rubric\nassessment, which uses expert-designed criteria to evaluate insight quality,\nwith factual assessment, which measures citation accuracy (faithfulness) and\ncoverage (groundedness). We evaluated several leading commercial DARS and\nbaseline systems. Results show that OpenAI Deep Research and Gemini Deep\nResearch significantly outperform other systems, with particular strength in\nopen-ended consulting questions. Such capabilities represent a meaningful step\ntoward AI self-improvement, aligning with the vision of ASI for AI. We\nopen-source ResearcherBench to provide a standardized platform for promoting\nthe development of next-generation AI research assistants, hoping to foster a\nnew perspective in AI research evaluation for a novel pattern of scientific\ncollaboration: https://github.com/GAIR-NLP/ResearcherBench.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86ResearcherBench\uff0c\u8fd9\u662f\u9996\u4e2a\u4e13\u95e8\u8bc4\u4f30\u6df1\u5ea6AI\u7814\u7a76\u7cfb\u7edf(DARS)\u5728\u524d\u6cbfAI\u79d1\u5b66\u95ee\u9898\u4e0a\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc765\u4e2a\u771f\u5b9e\u79d1\u7814\u573a\u666f\u95ee\u9898\u548c\u53cc\u91cd\u8bc4\u4f30\u6846\u67b6\uff0c\u53d1\u73b0OpenAI Deep Research\u548cGemini Deep Research\u5728\u5f00\u653e\u5f0f\u54a8\u8be2\u95ee\u9898\u4e0a\u8868\u73b0\u7a81\u51fa\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u8bc4\u4f30AI\u7cfb\u7edf\u4f5c\u4e3a\u7f51\u7edc\u68c0\u7d22\u548c\u62a5\u544a\u751f\u6210\u4ee3\u7406\u7684\u80fd\u529b\uff0c\u5ffd\u89c6\u4e86\u5176\u5728\u79d1\u5b66\u7814\u7a76\u524d\u6cbf\u53d1\u73b0\u65b0\u89c1\u89e3\u7684\u6f5c\u529b\u3002\u4e3a\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u9700\u8981\u4e00\u4e2a\u4e13\u95e8\u8bc4\u4f30\u6df1\u5ea6AI\u7814\u7a76\u7cfb\u7edf\u5728\u524d\u6cbfAI\u79d1\u5b66\u95ee\u9898\u4e0a\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "\u6784\u5efa\u5305\u542b65\u4e2a\u7814\u7a76\u95ee\u9898\u7684\u6570\u636e\u96c6\uff0c\u8fd9\u4e9b\u95ee\u9898\u6765\u81ea\u5b9e\u9a8c\u5ba4\u8ba8\u8bba\u548c\u8bbf\u8c08\u7b49\u771f\u5b9e\u79d1\u7814\u573a\u666f\uff0c\u6db5\u76d635\u4e2a\u4e0d\u540cAI\u4e3b\u9898\uff0c\u5206\u4e3a\u6280\u672f\u7ec6\u8282\u3001\u6587\u732e\u7efc\u8ff0\u548c\u5f00\u653e\u54a8\u8be2\u4e09\u7c7b\u3002\u91c7\u7528\u53cc\u91cd\u8bc4\u4f30\u6846\u67b6\uff1a\u8bc4\u5206\u6807\u51c6\u8bc4\u4f30\uff08\u4f7f\u7528\u4e13\u5bb6\u8bbe\u8ba1\u7684\u6807\u51c6\u8bc4\u4f30\u6d1e\u5bdf\u8d28\u91cf\uff09\u548c\u4e8b\u5b9e\u8bc4\u4f30\uff08\u6d4b\u91cf\u5f15\u7528\u51c6\u786e\u6027\u548c\u8986\u76d6\u5ea6\uff09\u3002", "result": "\u8bc4\u4f30\u4e86\u51e0\u4e2a\u9886\u5148\u7684\u5546\u4e1aDARS\u548c\u57fa\u7ebf\u7cfb\u7edf\uff0c\u7ed3\u679c\u663e\u793aOpenAI Deep Research\u548cGemini Deep Research\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u7cfb\u7edf\uff0c\u7279\u522b\u662f\u5728\u5f00\u653e\u5f0f\u54a8\u8be2\u95ee\u9898\u4e0a\u8868\u73b0\u7a81\u51fa\u3002\u8fd9\u4e9b\u80fd\u529b\u4ee3\u8868\u4e86\u5411AI\u81ea\u6211\u6539\u8fdb\u8fc8\u51fa\u7684\u91cd\u8981\u4e00\u6b65\u3002", "conclusion": "ResearcherBench\u4e3a\u4fc3\u8fdb\u4e0b\u4e00\u4ee3AI\u7814\u7a76\u52a9\u624b\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u5e73\u53f0\uff0c\u6709\u671b\u4e3aAI\u7814\u7a76\u8bc4\u4f30\u5e26\u6765\u65b0\u89c6\u89d2\uff0c\u4fc3\u8fdb\u79d1\u5b66\u5408\u4f5c\u7684\u65b0\u6a21\u5f0f\u3002\u8bba\u6587\u5f00\u6e90\u4e86\u8be5\u57fa\u51c6\u6d4b\u8bd5\u4ee5\u63a8\u52a8\u76f8\u5173\u7814\u7a76\u53d1\u5c55\u3002"}}
{"id": "2507.16478", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.16478", "abs": "https://arxiv.org/abs/2507.16478", "authors": ["Shreya Saxena", "Siva Prasad", "Zishan Ahmad", "Vishal Vaddina"], "title": "ACT: Bridging the Gap in Code Translation through Synthetic Data Generation & Adaptive Training", "comment": null, "summary": "Code translation is a crucial process in software development and migration\nprojects, enabling interoperability between different programming languages and\nenhancing software adaptability and thus longevity. Traditional automated\ntranslation methods rely heavily on handcrafted transformation rules, which\noften lack flexibility and scalability. Meanwhile, advanced language models\npresent promising alternatives but are often limited by proprietary, API-based\nimplementations that raise concerns over data security and reliance. In this\npaper, we present Auto-Train for Code Translation (ACT), an innovative\nframework that aims to improve code translation capabilities by enabling\nin-house finetuning of open-source Large Language Models (LLMs). ACT's\nautomated pipeline significantly boosts the performance of these models,\nnarrowing the gap between open-source accessibility and the high performance of\nclosed-source solutions. Central to ACT is its synthetic data generation\nmodule, which builds extensive, high-quality datasets from initial code\nsamples, incorporating unit tests to ensure functional accuracy and diversity.\nACT's evaluation framework incorporates execution-level checks, offering a\ncomprehensive assessment of translation quality. A key feature in ACT is its\ncontroller module, which manages the entire pipeline by dynamically adjusting\nhyperparameters, orchestrating iterative data generation, and finetuning based\non real-time evaluations. This enables ACT to intelligently optimize when to\ncontinue training, generate additional targeted training data, or stop the\nprocess. Our results demonstrate that ACT consistently enhances the\neffectiveness of open-source models, offering businesses and developers a\nsecure and reliable alternative. Additionally, applying our data generation\npipeline to industry-scale migration projects has led to a notable increase in\ndeveloper acceleration.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86ACT\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u6d41\u6c34\u7ebf\u5bf9\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u4ee5\u63d0\u5347\u4ee3\u7801\u7ffb\u8bd1\u80fd\u529b\uff0c\u7f29\u5c0f\u5f00\u6e90\u6a21\u578b\u4e0e\u95ed\u6e90\u89e3\u51b3\u65b9\u6848\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\u3002", "motivation": "\u4f20\u7edf\u7684\u81ea\u52a8\u5316\u4ee3\u7801\u7ffb\u8bd1\u65b9\u6cd5\u4f9d\u8d56\u624b\u5de5\u5236\u4f5c\u7684\u8f6c\u6362\u89c4\u5219\uff0c\u7f3a\u4e4f\u7075\u6d3b\u6027\u548c\u53ef\u6269\u5c55\u6027\uff1b\u800c\u5148\u8fdb\u7684\u8bed\u8a00\u6a21\u578b\u901a\u5e38\u57fa\u4e8e\u4e13\u6709API\u5b9e\u73b0\uff0c\u5b58\u5728\u6570\u636e\u5b89\u5168\u548c\u4f9d\u8d56\u6027\u95ee\u9898\u3002\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u63d0\u5347\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7801\u7ffb\u8bd1\u80fd\u529b\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51faACT\uff08Auto-Train for Code Translation\uff09\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a1\uff09\u5408\u6210\u6570\u636e\u751f\u6210\u6a21\u5757\uff0c\u4ece\u521d\u59cb\u4ee3\u7801\u6837\u672c\u6784\u5efa\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u5e76\u7ed3\u5408\u5355\u5143\u6d4b\u8bd5\uff1b2\uff09\u8bc4\u4f30\u6846\u67b6\uff0c\u91c7\u7528\u6267\u884c\u7ea7\u68c0\u67e5\u5168\u9762\u8bc4\u4f30\u7ffb\u8bd1\u8d28\u91cf\uff1b3\uff09\u63a7\u5236\u5668\u6a21\u5757\uff0c\u52a8\u6001\u8c03\u6574\u8d85\u53c2\u6570\uff0c\u534f\u8c03\u8fed\u4ee3\u6570\u636e\u751f\u6210\u548c\u5fae\u8c03\u8fc7\u7a0b\u3002", "result": "ACT\u80fd\u591f\u6301\u7eed\u63d0\u5347\u5f00\u6e90\u6a21\u578b\u7684\u6548\u679c\uff0c\u4e3a\u4f01\u4e1a\u548c\u5f00\u53d1\u8005\u63d0\u4f9b\u5b89\u5168\u53ef\u9760\u7684\u66ff\u4ee3\u65b9\u6848\u3002\u5c06\u6570\u636e\u751f\u6210\u6d41\u6c34\u7ebf\u5e94\u7528\u5230\u5de5\u4e1a\u89c4\u6a21\u7684\u8fc1\u79fb\u9879\u76ee\u4e2d\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5f00\u53d1\u8005\u7684\u5de5\u4f5c\u6548\u7387\u3002", "conclusion": "ACT\u6846\u67b6\u6210\u529f\u7f29\u5c0f\u4e86\u5f00\u6e90\u6a21\u578b\u4e0e\u95ed\u6e90\u89e3\u51b3\u65b9\u6848\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u901a\u8fc7\u667a\u80fd\u5316\u7684\u8bad\u7ec3\u6d41\u6c34\u7ebf\u7ba1\u7406\u548c\u9ad8\u8d28\u91cf\u7684\u5408\u6210\u6570\u636e\u751f\u6210\uff0c\u4e3a\u4ee3\u7801\u7ffb\u8bd1\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b89\u5168\u3001\u53ef\u9760\u4e14\u9ad8\u6548\u7684\u5f00\u6e90\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.16296", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16296", "abs": "https://arxiv.org/abs/2507.16296", "authors": ["Cairong Zhao", "Yufeng Jin", "Zifan Song", "Haonan Chen", "Duoqian Miao", "Guosheng Hu"], "title": "Cross-Modal Distillation For Widely Differing Modalities", "comment": "14 pages, 9 figures", "summary": "Deep learning achieved great progress recently, however, it is not easy or\nefficient to further improve its performance by increasing the size of the\nmodel. Multi-modal learning can mitigate this challenge by introducing richer\nand more discriminative information as input. To solve the problem of limited\naccess to multi-modal data at the time of use, we conduct multi-modal learning\nby introducing a teacher model to transfer discriminative knowledge to a\nstudent model during training. However, this knowledge transfer via\ndistillation is not trivial because the big domain gap between the widely\ndiffering modalities can easily lead to overfitting. In this work, we introduce\na cross-modal distillation framework. Specifically, we find hard constrained\nloss, e.g. l2 loss forcing the student being exact the same as the teacher, can\neasily lead to overfitting in cross-modality distillation. To address this, we\npropose two soft constrained knowledge distillation strategies at the feature\nlevel and classifier level respectively. In addition, we propose a\nquality-based adaptive weights module to weigh input samples via quantified\ndata quality, leading to robust model training. We conducted experiments on\nspeaker recognition and image classification tasks, and the results show that\nour approach is able to effectively achieve knowledge transfer between the\ncommonly used and widely differing modalities of image, text, and speech.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8de8\u6a21\u6001\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\uff0c\u901a\u8fc7\u6559\u5e08\u6a21\u578b\u5411\u5b66\u751f\u6a21\u578b\u8f6c\u79fb\u5224\u522b\u6027\u77e5\u8bc6\uff0c\u89e3\u51b3\u591a\u6a21\u6001\u6570\u636e\u5728\u4f7f\u7528\u65f6\u8bbf\u95ee\u53d7\u9650\u7684\u95ee\u9898\uff0c\u5e76\u5728\u8bf4\u8bdd\u4eba\u8bc6\u522b\u548c\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e0a\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u901a\u8fc7\u589e\u52a0\u6a21\u578b\u89c4\u6a21\u6765\u63d0\u5347\u6027\u80fd\u53d8\u5f97\u56f0\u96be\u4e14\u6548\u7387\u4f4e\u4e0b\uff0c\u591a\u6a21\u6001\u5b66\u4e60\u80fd\u591f\u901a\u8fc7\u5f15\u5165\u66f4\u4e30\u5bcc\u7684\u5224\u522b\u6027\u4fe1\u606f\u6765\u7f13\u89e3\u8fd9\u4e00\u6311\u6218\uff0c\u4f46\u5728\u5b9e\u9645\u4f7f\u7528\u65f6\u591a\u6a21\u6001\u6570\u636e\u7684\u83b7\u53d6\u5f80\u5f80\u53d7\u9650\uff0c\u4e14\u4e0d\u540c\u6a21\u6001\u95f4\u7684\u5de8\u5927\u9886\u57df\u5dee\u8ddd\u5bb9\u6613\u5bfc\u81f4\u77e5\u8bc6\u84b8\u998f\u8fc7\u7a0b\u4e2d\u7684\u8fc7\u62df\u5408\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u8de8\u6a21\u6001\u84b8\u998f\u6846\u67b6\uff0c\u5305\u62ec\uff1a(1)\u5728\u7279\u5f81\u5c42\u548c\u5206\u7c7b\u5668\u5c42\u5206\u522b\u8bbe\u8ba1\u4e24\u79cd\u8f6f\u7ea6\u675f\u77e5\u8bc6\u84b8\u998f\u7b56\u7565\uff0c\u907f\u514d\u786c\u7ea6\u675f\u635f\u5931(\u5982L2\u635f\u5931)\u5bfc\u81f4\u7684\u8fc7\u62df\u5408\uff1b(2)\u63d0\u51fa\u57fa\u4e8e\u8d28\u91cf\u7684\u81ea\u9002\u5e94\u6743\u91cd\u6a21\u5757\uff0c\u901a\u8fc7\u91cf\u5316\u6570\u636e\u8d28\u91cf\u4e3a\u8f93\u5165\u6837\u672c\u5206\u914d\u6743\u91cd\uff0c\u5b9e\u73b0\u9c81\u68d2\u7684\u6a21\u578b\u8bad\u7ec3\u3002", "result": "\u5728\u8bf4\u8bdd\u4eba\u8bc6\u522b\u548c\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5b9e\u73b0\u56fe\u50cf\u3001\u6587\u672c\u548c\u8bed\u97f3\u7b49\u5e7f\u6cdb\u5e94\u7528\u4e14\u5dee\u5f02\u8f83\u5927\u7684\u6a21\u6001\u4e4b\u95f4\u7684\u77e5\u8bc6\u8f6c\u79fb\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u8de8\u6a21\u6001\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\u901a\u8fc7\u8f6f\u7ea6\u675f\u7b56\u7565\u548c\u81ea\u9002\u5e94\u6743\u91cd\u6a21\u5757\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u8de8\u6a21\u6001\u77e5\u8bc6\u8f6c\u79fb\u4e2d\u7684\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u4e0d\u540c\u6a21\u6001\u95f4\u7684\u6709\u6548\u77e5\u8bc6\u84b8\u998f\uff0c\u4e3a\u591a\u6a21\u6001\u5b66\u4e60\u5728\u6570\u636e\u53d7\u9650\u573a\u666f\u4e0b\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.16322", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16322", "abs": "https://arxiv.org/abs/2507.16322", "authors": ["Fred Mutisya", "Shikoh Gitau", "Christine Syovata", "Diana Oigara", "Ibrahim Matende", "Muna Aden", "Munira Ali", "Ryan Nyotu", "Diana Marion", "Job Nyangena", "Nasubo Ongoma", "Keith Mbae", "Elizabeth Wamicha", "Eric Mibuari", "Jean Philbert Nsengemana", "Talkmore Chidede"], "title": "Mind the Gap: Evaluating the Representativeness of Quantitative Medical Language Reasoning LLM Benchmarks for African Disease Burdens", "comment": "Preprint. 26 pages, includes appendix and tables", "summary": "Introduction: Existing medical LLM benchmarks largely reflect examination\nsyllabi and disease profiles from high income settings, raising questions about\ntheir validity for African deployment where malaria, HIV, TB, sickle cell\ndisease and other neglected tropical diseases (NTDs) dominate burden and\nnational guidelines drive care. Methodology: We systematically reviewed 31\nquantitative LLM evaluation papers (Jan 2019 May 2025) identifying 19 English\nmedical QA benchmarks. Alama Health QA was developed using a retrieval\naugmented generation framework anchored on the Kenyan Clinical Practice\nGuidelines. Six widely used sets (AfriMedQA, MMLUMedical, PubMedQA, MedMCQA,\nMedQAUSMLE, and guideline grounded Alama Health QA) underwent harmonized\nsemantic profiling (NTD proportion, recency, readability, lexical diversity\nmetrics) and blinded expert rating across five dimensions: clinical relevance,\nguideline alignment, clarity, distractor plausibility, and language/cultural\nfit. Results: Alama Health QA captured >40% of all NTD mentions across corpora\nand the highest within set frequencies for malaria (7.7%), HIV (4.1%), and TB\n(5.2%); AfriMedQA ranked second but lacked formal guideline linkage. Global\nbenchmarks showed minimal representation (e.g., sickle cell disease absent in\nthree sets) despite large scale. Qualitatively, Alama scored highest for\nrelevance and guideline alignment; PubMedQA lowest for clinical utility.\nDiscussion: Quantitative medical LLM benchmarks widely used in the literature\nunderrepresent African disease burdens and regulatory contexts, risking\nmisleading performance claims. Guideline anchored, regionally curated resources\nsuch as Alama Health QA and expanded disease specific derivatives are essential\nfor safe, equitable model evaluation and deployment across African health\nsystems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u533b\u5b66\u5927\u8bed\u8a00\u6a21\u578b\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u53cd\u6620\u9ad8\u6536\u5165\u56fd\u5bb6\u7684\u75be\u75c5\u8c31\uff0c\u4e0d\u9002\u7528\u4e8e\u975e\u6d32\u5730\u533a\u3002\u7814\u7a76\u5f00\u53d1\u4e86\u57fa\u4e8e\u80af\u5c3c\u4e9a\u4e34\u5e8a\u5b9e\u8df5\u6307\u5357\u7684Alama Health QA\u57fa\u51c6\uff0c\u66f4\u597d\u5730\u4ee3\u8868\u4e86\u759f\u75be\u3001HIV\u3001\u7ed3\u6838\u75c5\u7b49\u975e\u6d32\u9ad8\u53d1\u75be\u75c5\uff0c\u4e3a\u975e\u6d32\u533b\u7597\u7cfb\u7edf\u7684\u6a21\u578b\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u5408\u9002\u7684\u5de5\u5177\u3002", "motivation": "\u73b0\u6709\u7684\u533b\u5b66\u5927\u8bed\u8a00\u6a21\u578b\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u57fa\u4e8e\u9ad8\u6536\u5165\u56fd\u5bb6\u7684\u8003\u8bd5\u5927\u7eb2\u548c\u75be\u75c5\u8c31\uff0c\u5728\u759f\u75be\u3001HIV\u3001\u7ed3\u6838\u75c5\u3001\u9570\u72b6\u7ec6\u80de\u75c5\u7b49\u88ab\u5ffd\u89c6\u70ed\u5e26\u75be\u75c5\u5360\u4e3b\u5bfc\u5730\u4f4d\u7684\u975e\u6d32\u5730\u533a\u90e8\u7f72\u65f6\uff0c\u5176\u6709\u6548\u6027\u5b58\u5728\u95ee\u9898\u3002\u9700\u8981\u5f00\u53d1\u66f4\u9002\u5408\u975e\u6d32\u75be\u75c5\u8d1f\u62c5\u548c\u76d1\u7ba1\u73af\u5883\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "\u7cfb\u7edf\u6027\u56de\u987e\u4e8631\u7bc7\u5b9a\u91cfLLM\u8bc4\u4f30\u8bba\u6587\uff0c\u8bc6\u522b\u51fa19\u4e2a\u82f1\u6587\u533b\u5b66\u95ee\u7b54\u57fa\u51c6\u3002\u4f7f\u7528\u57fa\u4e8e\u80af\u5c3c\u4e9a\u4e34\u5e8a\u5b9e\u8df5\u6307\u5357\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\u5f00\u53d1\u4e86Alama Health QA\u3002\u5bf96\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u57fa\u51c6\u8fdb\u884c\u4e86\u7edf\u4e00\u7684\u8bed\u4e49\u5206\u6790\uff08NTD\u6bd4\u4f8b\u3001\u65f6\u6548\u6027\u3001\u53ef\u8bfb\u6027\u3001\u8bcd\u6c47\u591a\u6837\u6027\u6307\u6807\uff09\u548c\u4e13\u5bb6\u76f2\u8bc4\uff08\u4e34\u5e8a\u76f8\u5173\u6027\u3001\u6307\u5357\u4e00\u81f4\u6027\u3001\u6e05\u6670\u5ea6\u3001\u5e72\u6270\u9879\u5408\u7406\u6027\u3001\u8bed\u8a00\u6587\u5316\u9002\u5e94\u6027\uff09\u3002", "result": "Alama Health QA\u6db5\u76d6\u4e86\u6240\u6709\u8bed\u6599\u5e93\u4e2d\u8d85\u8fc740%\u7684NTD\u63d0\u53ca\uff0c\u759f\u75be(7.7%)\u3001HIV(4.1%)\u548c\u7ed3\u6838\u75c5(5.2%)\u7684\u9891\u7387\u6700\u9ad8\uff1bAfriMedQA\u6392\u540d\u7b2c\u4e8c\u4f46\u7f3a\u4e4f\u6b63\u5f0f\u7684\u6307\u5357\u5173\u8054\u3002\u5168\u7403\u57fa\u51c6\u663e\u793a\u6700\u5c0f\u7684\u4ee3\u8868\u6027\uff08\u5982\u9570\u72b6\u7ec6\u80de\u75c5\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e2d\u5b8c\u5168\u7f3a\u5931\uff09\u3002\u5b9a\u6027\u8bc4\u4f30\u4e2d\uff0cAlama\u5728\u76f8\u5173\u6027\u548c\u6307\u5357\u4e00\u81f4\u6027\u65b9\u9762\u5f97\u5206\u6700\u9ad8\uff1bPubMedQA\u5728\u4e34\u5e8a\u5b9e\u7528\u6027\u65b9\u9762\u5f97\u5206\u6700\u4f4e\u3002", "conclusion": "\u6587\u732e\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u7684\u5b9a\u91cf\u533b\u5b66LLM\u57fa\u51c6\u6d4b\u8bd5\u672a\u80fd\u5145\u5206\u4ee3\u8868\u975e\u6d32\u75be\u75c5\u8d1f\u62c5\u548c\u76d1\u7ba1\u73af\u5883\uff0c\u5b58\u5728\u8bef\u5bfc\u6027\u80fd\u58f0\u660e\u7684\u98ce\u9669\u3002\u57fa\u4e8e\u6307\u5357\u951a\u5b9a\u3001\u533a\u57df\u7b56\u5212\u7684\u8d44\u6e90\u5982Alama Health QA\u53ca\u5176\u6269\u5c55\u7684\u75be\u75c5\u7279\u5f02\u6027\u884d\u751f\u54c1\uff0c\u5bf9\u4e8e\u975e\u6d32\u536b\u751f\u7cfb\u7edf\u7684\u5b89\u5168\u3001\u516c\u5e73\u6a21\u578b\u8bc4\u4f30\u548c\u90e8\u7f72\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2507.16334", "categories": ["cs.AI", "cs.LG", "math.DG"], "pdf": "https://arxiv.org/pdf/2507.16334", "abs": "https://arxiv.org/abs/2507.16334", "authors": ["Alexander Strunk", "Roland Assam"], "title": "Higher Gauge Flow Models", "comment": null, "summary": "This paper introduces Higher Gauge Flow Models, a novel class of Generative\nFlow Models. Building upon ordinary Gauge Flow Models (arXiv:2507.13414), these\nHigher Gauge Flow Models leverage an L$_{\\infty}$-algebra, effectively\nextending the Lie Algebra. This expansion allows for the integration of the\nhigher geometry and higher symmetries associated with higher groups into the\nframework of Generative Flow Models. Experimental evaluation on a Gaussian\nMixture Model dataset revealed substantial performance improvements compared to\ntraditional Flow Models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9ad8\u89c4\u8303\u6d41\u6a21\u578b\uff08Higher Gauge Flow Models\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u578b\u751f\u6210\u6d41\u6a21\u578b\uff0c\u901a\u8fc7\u5229\u7528L\u221e\u4ee3\u6570\u6269\u5c55\u674e\u4ee3\u6570\uff0c\u5c06\u9ad8\u7ef4\u51e0\u4f55\u548c\u9ad8\u5bf9\u79f0\u6027\u6574\u5408\u5230\u751f\u6210\u6d41\u6a21\u578b\u6846\u67b6\u4e2d\uff0c\u5728\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u6570\u636e\u96c6\u4e0a\u663e\u793a\u51fa\u76f8\u6bd4\u4f20\u7edf\u6d41\u6a21\u578b\u7684\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u4f20\u7edf\u7684\u89c4\u8303\u6d41\u6a21\u578b\u57fa\u4e8e\u674e\u4ee3\u6570\uff0c\u4f46\u5728\u5904\u7406\u590d\u6742\u7684\u9ad8\u7ef4\u51e0\u4f55\u7ed3\u6784\u548c\u9ad8\u5bf9\u79f0\u6027\u65f6\u5b58\u5728\u5c40\u9650\u6027\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u5e76\u63d0\u9ad8\u751f\u6210\u6a21\u578b\u7684\u8868\u73b0\u529b\uff0c\u9700\u8981\u5c06\u9ad8\u7ef4\u7fa4\u8bba\u548c\u9ad8\u51e0\u4f55\u7684\u6982\u5ff5\u5f15\u5165\u5230\u751f\u6210\u6d41\u6a21\u578b\u4e2d\u3002", "method": "\u57fa\u4e8e\u666e\u901a\u89c4\u8303\u6d41\u6a21\u578b\u7684\u57fa\u7840\u4e0a\uff0c\u5229\u7528L\u221e\u4ee3\u6570\u6709\u6548\u6269\u5c55\u674e\u4ee3\u6570\u7ed3\u6784\u3002\u901a\u8fc7\u8fd9\u79cd\u6269\u5c55\uff0c\u5c06\u4e0e\u9ad8\u7fa4\u76f8\u5173\u7684\u9ad8\u7ef4\u51e0\u4f55\u548c\u9ad8\u5bf9\u79f0\u6027\u6574\u5408\u5230\u751f\u6210\u6d41\u6a21\u578b\u7684\u6846\u67b6\u4e2d\uff0c\u4ece\u800c\u6784\u5efa\u9ad8\u89c4\u8303\u6d41\u6a21\u578b\u3002", "result": "\u5728\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\uff0c\u9ad8\u89c4\u8303\u6d41\u6a21\u578b\u76f8\u6bd4\u4f20\u7edf\u6d41\u6a21\u578b\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u6539\u8fdb\u3002", "conclusion": "\u9ad8\u89c4\u8303\u6d41\u6a21\u578b\u901a\u8fc7\u5f15\u5165L\u221e\u4ee3\u6570\u548c\u9ad8\u7ef4\u51e0\u4f55\u6982\u5ff5\uff0c\u6210\u529f\u6269\u5c55\u4e86\u4f20\u7edf\u6d41\u6a21\u578b\u7684\u80fd\u529b\uff0c\u4e3a\u751f\u6210\u5efa\u6a21\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u5f3a\u5927\u7684\u6570\u5b66\u6846\u67b6\uff0c\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.16356", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16356", "abs": "https://arxiv.org/abs/2507.16356", "authors": ["Arpan Dasgupta", "Mizhaan Maniyar", "Awadhesh Srivastava", "Sanat Kumar", "Amrita Mahale", "Aparna Hedge", "Arun Suggala", "Karthikeyan Shanmugam", "Aparna Taneja", "Milind Tambe"], "title": "Learning to Call: A Field Trial of a Collaborative Bandit Algorithm for Improved Message Delivery in Mobile Maternal Health", "comment": null, "summary": "Mobile health (mHealth) programs utilize automated voice messages to deliver\nhealth information, particularly targeting underserved communities,\ndemonstrating the effectiveness of using mobile technology to disseminate\ncrucial health information to these populations, improving health outcomes\nthrough increased awareness and behavioral change. India's Kilkari program\ndelivers vital maternal health information via weekly voice calls to millions\nof mothers. However, the current random call scheduling often results in missed\ncalls and reduced message delivery. This study presents a field trial of a\ncollaborative bandit algorithm designed to optimize call timing by learning\nindividual mothers' preferred call times. We deployed the algorithm with around\n$6500$ Kilkari participants as a pilot study, comparing its performance to the\nbaseline random calling approach. Our results demonstrate a statistically\nsignificant improvement in call pick-up rates with the bandit algorithm,\nindicating its potential to enhance message delivery and impact millions of\nmothers across India. This research highlights the efficacy of personalized\nscheduling in mobile health interventions and underscores the potential of\nmachine learning to improve maternal health outreach at scale.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9488\u5bf9\u5370\u5ea6Kilkari\u9879\u76ee\u5f00\u53d1\u4e86\u4e00\u79cd\u534f\u4f5c\u5f3a\u76d7\u7b97\u6cd5\uff0c\u901a\u8fc7\u5b66\u4e60\u4e2a\u4eba\u504f\u597d\u7684\u901a\u8bdd\u65f6\u95f4\u6765\u4f18\u5316\u8bed\u97f3\u5065\u5eb7\u4fe1\u606f\u7684\u6295\u9012\u65f6\u95f4\uff0c\u57286500\u540d\u53c2\u4e0e\u8005\u7684\u8bd5\u70b9\u7814\u7a76\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u7535\u8bdd\u63a5\u542c\u7387\uff0c\u5c55\u793a\u4e86\u4e2a\u6027\u5316\u8c03\u5ea6\u5728\u79fb\u52a8\u5065\u5eb7\u5e72\u9884\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5370\u5ea6Kilkari\u9879\u76ee\u901a\u8fc7\u8bed\u97f3\u7535\u8bdd\u5411\u6570\u767e\u4e07\u6bcd\u4eb2\u4f20\u9012\u91cd\u8981\u7684\u5b55\u4ea7\u5987\u5065\u5eb7\u4fe1\u606f\uff0c\u4f46\u5f53\u524d\u7684\u968f\u673a\u901a\u8bdd\u8c03\u5ea6\u7ecf\u5e38\u5bfc\u81f4\u672a\u63a5\u7535\u8bdd\u548c\u4fe1\u606f\u4f20\u9012\u6548\u679c\u964d\u4f4e\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5b66\u4e60\u4e2a\u4eba\u504f\u597d\u901a\u8bdd\u65f6\u95f4\u7684\u667a\u80fd\u8c03\u5ea6\u65b9\u6cd5\u6765\u63d0\u9ad8\u4fe1\u606f\u4f20\u9012\u6548\u7387\u3002", "method": "\u8bbe\u8ba1\u5e76\u90e8\u7f72\u4e86\u4e00\u79cd\u534f\u4f5c\u5f3a\u76d7\u7b97\u6cd5\uff08collaborative bandit algorithm\uff09\uff0c\u8be5\u7b97\u6cd5\u80fd\u591f\u5b66\u4e60\u6bcf\u4f4d\u6bcd\u4eb2\u7684\u4e2a\u4eba\u504f\u597d\u901a\u8bdd\u65f6\u95f4\uff0c\u4ece\u800c\u4f18\u5316\u7535\u8bdd\u62e8\u6253\u7684\u65f6\u95f4\u5b89\u6392\u3002\u5728\u7ea66500\u540dKilkari\u53c2\u4e0e\u8005\u4e2d\u8fdb\u884c\u4e86\u5b9e\u5730\u8bd5\u9a8c\uff0c\u5e76\u4e0e\u57fa\u7ebf\u7684\u968f\u673a\u901a\u8bdd\u65b9\u6cd5\u8fdb\u884c\u4e86\u6027\u80fd\u6bd4\u8f83\u3002", "result": "\u4f7f\u7528\u5f3a\u76d7\u7b97\u6cd5\u7684\u901a\u8bdd\u63a5\u542c\u7387\u76f8\u6bd4\u968f\u673a\u901a\u8bdd\u65b9\u6cd5\u6709\u7edf\u8ba1\u5b66\u610f\u4e49\u4e0a\u7684\u663e\u8457\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u8be5\u7b97\u6cd5\u5728\u63d0\u9ad8\u4fe1\u606f\u4f20\u9012\u6548\u679c\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u53ef\u80fd\u5f71\u54cd\u5370\u5ea6\u6570\u767e\u4e07\u6bcd\u4eb2\u7684\u5065\u5eb7\u4fe1\u606f\u83b7\u53d6\u3002", "conclusion": "\u4e2a\u6027\u5316\u8c03\u5ea6\u5728\u79fb\u52a8\u5065\u5eb7\u5e72\u9884\u4e2d\u5177\u6709\u663e\u8457\u6548\u679c\uff0c\u673a\u5668\u5b66\u4e60\u6280\u672f\u5728\u5927\u89c4\u6a21\u6539\u5584\u5b55\u4ea7\u5987\u5065\u5eb7\u63a8\u5e7f\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002\u8be5\u7814\u7a76\u4e3a\u79fb\u52a8\u5065\u5eb7\u9879\u76ee\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u6280\u672f\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u901a\u8fc7\u667a\u80fd\u5316\u7684\u65f6\u95f4\u8c03\u5ea6\u663e\u8457\u63d0\u9ad8\u5065\u5eb7\u4fe1\u606f\u7684\u4f20\u9012\u6548\u7387\u3002"}}
{"id": "2507.16370", "categories": ["cs.AI", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.16370", "abs": "https://arxiv.org/abs/2507.16370", "authors": ["Lucas de Lara"], "title": "Canonical Representations of Markovian Structural Causal Models: A Framework for Counterfactual Reasoning", "comment": null, "summary": "Counterfactual reasoning aims at answering contrary-to-fact questions like\n''Would have Alice recovered had she taken aspirin?'' and corresponds to the\nmost fine-grained layer of causation. Critically, while many counterfactual\nstatements cannot be falsified -- even by randomized experiments -- they\nunderpin fundamental concepts like individual-wise fairness. Therefore,\nproviding models to formalize and implement counterfactual beliefs remains a\nfundamental scientific problem. In the Markovian setting of Pearl's causal\nframework, we propose an alternative approach to structural causal models to\nrepresent counterfactuals compatible with a given causal graphical model. More\nprecisely, we introduce counterfactual models, also called canonical\nrepresentations of structural causal models. They enable analysts to choose a\ncounterfactual conception via random-process probability distributions with\npreassigned marginals and characterize the counterfactual equivalence class of\nstructural causal models. Then, we present a normalization procedure to\ndescribe and implement various counterfactual conceptions. Compared to\nstructural causal models, it allows to specify many counterfactual conceptions\nwithout altering the observational and interventional constraints. Moreover,\nthe content of the model corresponding to the counterfactual layer does not\nneed to be estimated; only to make a choice. Finally, we illustrate the\nspecific role of counterfactuals in causality and the benefits of our approach\non theoretical and numerical examples.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53cd\u4e8b\u5b9e\u6a21\u578b\u7684\u65b0\u65b9\u6cd5\u6765\u8868\u793a\u548c\u5b9e\u73b0\u53cd\u4e8b\u5b9e\u63a8\u7406\uff0c\u4f5c\u4e3a\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5141\u8bb8\u5206\u6790\u5e08\u5728\u4e0d\u6539\u53d8\u89c2\u5bdf\u548c\u5e72\u9884\u7ea6\u675f\u7684\u60c5\u51b5\u4e0b\u6307\u5b9a\u591a\u79cd\u53cd\u4e8b\u5b9e\u6982\u5ff5\u3002", "motivation": "\u53cd\u4e8b\u5b9e\u63a8\u7406\u5bf9\u5e94\u56e0\u679c\u5173\u7cfb\u7684\u6700\u7cbe\u7ec6\u5c42\u6b21\uff0c\u867d\u7136\u8bb8\u591a\u53cd\u4e8b\u5b9e\u9648\u8ff0\u65e0\u6cd5\u88ab\u8bc1\u4f2a\uff0c\u4f46\u5b83\u4eec\u652f\u6491\u7740\u4e2a\u4f53\u516c\u5e73\u6027\u7b49\u57fa\u672c\u6982\u5ff5\u3002\u56e0\u6b64\uff0c\u63d0\u4f9b\u5f62\u5f0f\u5316\u548c\u5b9e\u73b0\u53cd\u4e8b\u5b9e\u4fe1\u5ff5\u7684\u6a21\u578b\u4ecd\u7136\u662f\u4e00\u4e2a\u57fa\u7840\u79d1\u5b66\u95ee\u9898\u3002", "method": "\u5728Pearl\u56e0\u679c\u6846\u67b6\u7684\u9a6c\u5c14\u53ef\u592b\u8bbe\u7f6e\u4e2d\uff0c\u4f5c\u8005\u63d0\u51fa\u53cd\u4e8b\u5b9e\u6a21\u578b\uff08\u4e5f\u79f0\u4e3a\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u7684\u89c4\u8303\u8868\u793a\uff09\u4f5c\u4e3a\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002\u5f15\u5165\u4e86\u5177\u6709\u9884\u5206\u914d\u8fb9\u9645\u5206\u5e03\u7684\u968f\u673a\u8fc7\u7a0b\u6982\u7387\u5206\u5e03\u6765\u9009\u62e9\u53cd\u4e8b\u5b9e\u6982\u5ff5\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u6807\u51c6\u5316\u7a0b\u5e8f\u6765\u63cf\u8ff0\u548c\u5b9e\u73b0\u5404\u79cd\u53cd\u4e8b\u5b9e\u6982\u5ff5\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u8868\u5f81\u4e0e\u7ed9\u5b9a\u56e0\u679c\u56fe\u6a21\u578b\u517c\u5bb9\u7684\u53cd\u4e8b\u5b9e\u7b49\u4ef7\u7c7b\uff0c\u5141\u8bb8\u5728\u4e0d\u6539\u53d8\u89c2\u5bdf\u548c\u5e72\u9884\u7ea6\u675f\u7684\u60c5\u51b5\u4e0b\u6307\u5b9a\u591a\u79cd\u53cd\u4e8b\u5b9e\u6982\u5ff5\u3002\u5bf9\u5e94\u53cd\u4e8b\u5b9e\u5c42\u7684\u6a21\u578b\u5185\u5bb9\u4e0d\u9700\u8981\u88ab\u4f30\u8ba1\uff0c\u53ea\u9700\u8981\u505a\u51fa\u9009\u62e9\u3002", "conclusion": "\u901a\u8fc7\u7406\u8bba\u548c\u6570\u503c\u793a\u4f8b\uff0c\u4f5c\u8005\u5c55\u793a\u4e86\u53cd\u4e8b\u5b9e\u5728\u56e0\u679c\u5173\u7cfb\u4e2d\u7684\u7279\u5b9a\u4f5c\u7528\u4ee5\u53ca\u6240\u63d0\u65b9\u6cd5\u7684\u4f18\u52bf\u3002\u8be5\u65b9\u6cd5\u4e3a\u53cd\u4e8b\u5b9e\u63a8\u7406\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u548c\u5b9e\u7528\u7684\u6846\u67b6\u3002"}}
{"id": "2507.16405", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.16405", "abs": "https://arxiv.org/abs/2507.16405", "authors": ["Stassa Patsantzis"], "title": "Self-Supervised Inductive Logic Programming", "comment": null, "summary": "Inductive Logic Programming (ILP) approaches like Meta \\-/ Interpretive\nLearning (MIL) can learn, from few examples, recursive logic programs with\ninvented predicates that generalise well to unseen instances. This ability\nrelies on a background theory and negative examples, both carefully selected\nwith expert knowledge of a learning problem and its solutions. But what if such\na problem-specific background theory or negative examples are not available? We\nformalise this question as a new setting for Self-Supervised ILP and present a\nnew MIL algorithm that learns in the new setting from some positive labelled,\nand zero or more unlabelled examples, and automatically generates, and labels,\nnew positive and negative examples during learning. We implement this algorithm\nin Prolog in a new MIL system, called Poker. We compare Poker to\nstate-of-the-art MIL system Louise on experiments learning grammars for\nContext-Free and L-System languages from labelled, positive example strings, no\nnegative examples, and just the terminal vocabulary of a language, seen in\nexamples, as a first-order background theory. We introduce a new approach for\nthe principled selection of a second-order background theory as a Second Order\nDefinite Normal Form (SONF), sufficiently general to learn all programs in a\nclass, thus removing the need for a backgound theory tailored to a learning\ntask. We find that Poker's performance improves with increasing numbers of\nautomatically generated examples while Louise, bereft of negative examples,\nover-generalises.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u81ea\u76d1\u7763\u5f52\u7eb3\u903b\u8f91\u7f16\u7a0b(ILP)\u65b9\u6cd5Poker,\u80fd\u591f\u5728\u7f3a\u4e4f\u4e13\u5bb6\u77e5\u8bc6\u80cc\u666f\u7406\u8bba\u548c\u8d1f\u4f8b\u7684\u60c5\u51b5\u4e0b,\u4ec5\u4ece\u6b63\u4f8b\u548c\u65e0\u6807\u7b7e\u4f8b\u5b50\u4e2d\u5b66\u4e60\u9012\u5f52\u903b\u8f91\u7a0b\u5e8f\u3002", "motivation": "\u4f20\u7edf\u7684\u5f52\u7eb3\u903b\u8f91\u7f16\u7a0b\u65b9\u6cd5\u5982\u5143\u89e3\u91ca\u5b66\u4e60(MIL)\u9700\u8981\u4e13\u5bb6\u7cbe\u5fc3\u9009\u62e9\u7684\u80cc\u666f\u7406\u8bba\u548c\u8d1f\u4f8b\u624d\u80fd\u6709\u6548\u5b66\u4e60,\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8fd9\u4e9b\u5148\u9a8c\u77e5\u8bc6\u5f80\u5f80\u4e0d\u53ef\u7528\u3002\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5728\u7f3a\u4e4f\u4e13\u5bb6\u77e5\u8bc6\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u81ea\u76d1\u7763\u5b66\u4e60\u7684ILP\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u65b0\u7684\u81ea\u76d1\u7763ILP\u8bbe\u7f6e\u548cMIL\u7b97\u6cd5,\u5f00\u53d1\u4e86Poker\u7cfb\u7edf\u3002\u8be5\u65b9\u6cd5\u80fd\u4ece\u6b63\u6807\u7b7e\u4f8b\u5b50\u548c\u65e0\u6807\u7b7e\u4f8b\u5b50\u4e2d\u5b66\u4e60,\u5728\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u81ea\u52a8\u751f\u6210\u548c\u6807\u6ce8\u65b0\u7684\u6b63\u8d1f\u4f8b\u5b50\u3002\u8fd8\u5f15\u5165\u4e86\u4e8c\u9636\u786e\u5b9a\u8303\u5f0f(SONF)\u6765\u539f\u5219\u6027\u5730\u9009\u62e9\u4e8c\u9636\u80cc\u666f\u7406\u8bba,\u4f7f\u5176\u8db3\u591f\u901a\u7528\u4ee5\u5b66\u4e60\u67d0\u7c7b\u4e2d\u7684\u6240\u6709\u7a0b\u5e8f\u3002", "result": "\u5728\u4e0a\u4e0b\u6587\u65e0\u5173\u8bed\u6cd5\u548cL-\u7cfb\u7edf\u8bed\u8a00\u7684\u8bed\u6cd5\u5b66\u4e60\u5b9e\u9a8c\u4e2d,Poker\u7cfb\u7edf\u7684\u6027\u80fd\u968f\u7740\u81ea\u52a8\u751f\u6210\u4f8b\u5b50\u6570\u91cf\u7684\u589e\u52a0\u800c\u63d0\u5347,\u800c\u7f3a\u4e4f\u8d1f\u4f8b\u7684Louise\u7cfb\u7edf\u51fa\u73b0\u8fc7\u5ea6\u6cdb\u5316\u95ee\u9898\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86Poker\u5728\u4ec5\u6709\u6b63\u4f8b\u548c\u7ec8\u7aef\u8bcd\u6c47\u8868\u4f5c\u4e3a\u4e00\u9636\u80cc\u666f\u7406\u8bba\u7684\u60c5\u51b5\u4e0b\u80fd\u591f\u6709\u6548\u5b66\u4e60\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u89e3\u51b3\u4e86ILP\u4e2d\u5bf9\u4e13\u5bb6\u77e5\u8bc6\u4f9d\u8d56\u7684\u95ee\u9898,\u63d0\u51fa\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u80fd\u591f\u5728\u7f3a\u4e4f\u80cc\u666f\u7406\u8bba\u548c\u8d1f\u4f8b\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u5b66\u4e60\u9012\u5f52\u903b\u8f91\u7a0b\u5e8f,\u4e3aILP\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u63a8\u5e7f\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2507.16414", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16414", "abs": "https://arxiv.org/abs/2507.16414", "authors": ["Hongyi Tang", "Zhihao Zhu", "Yi Yang"], "title": "Identifying Pre-training Data in LLMs: A Neuron Activation-Based Detection Framework", "comment": null, "summary": "The performance of large language models (LLMs) is closely tied to their\ntraining data, which can include copyrighted material or private information,\nraising legal and ethical concerns. Additionally, LLMs face criticism for\ndataset contamination and internalizing biases. To address these issues, the\nPre-Training Data Detection (PDD) task was proposed to identify if specific\ndata was included in an LLM's pre-training corpus. However, existing PDD\nmethods often rely on superficial features like prediction confidence and loss,\nresulting in mediocre performance. To improve this, we introduce NA-PDD, a\nnovel algorithm analyzing differential neuron activation patterns between\ntraining and non-training data in LLMs. This is based on the observation that\nthese data types activate different neurons during LLM inference. We also\nintroduce CCNewsPDD, a temporally unbiased benchmark employing rigorous data\ntransformations to ensure consistent time distributions between training and\nnon-training data. Our experiments demonstrate that NA-PDD significantly\noutperforms existing methods across three benchmarks and multiple LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86NA-PDD\u7b97\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u8bad\u7ec3\u6570\u636e\u548c\u975e\u8bad\u7ec3\u6570\u636e\u7684\u795e\u7ecf\u5143\u6fc0\u6d3b\u6a21\u5f0f\u5dee\u5f02\u6765\u68c0\u6d4b\u9884\u8bad\u7ec3\u6570\u636e\uff0c\u5e76\u5728\u65b0\u57fa\u51c6CCNewsPDD\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bad\u7ec3\u6570\u636e\u53ef\u80fd\u5305\u542b\u7248\u6743\u6750\u6599\u6216\u9690\u79c1\u4fe1\u606f\uff0c\u5f15\u53d1\u6cd5\u5f8b\u548c\u4f26\u7406\u95ee\u9898\uff0c\u540c\u65f6\u5b58\u5728\u6570\u636e\u96c6\u6c61\u67d3\u548c\u504f\u89c1\u5185\u5316\u95ee\u9898\u3002\u73b0\u6709\u7684\u9884\u8bad\u7ec3\u6570\u636e\u68c0\u6d4b(PDD)\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u548c\u635f\u5931\u7b49\u8868\u9762\u7279\u5f81\uff0c\u6027\u80fd\u5e73\u5eb8\uff0c\u9700\u8981\u66f4\u597d\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51faNA-PDD\u7b97\u6cd5\uff0c\u57fa\u4e8e\u8bad\u7ec3\u6570\u636e\u548c\u975e\u8bad\u7ec3\u6570\u636e\u5728LLM\u63a8\u7406\u8fc7\u7a0b\u4e2d\u6fc0\u6d3b\u4e0d\u540c\u795e\u7ecf\u5143\u7684\u89c2\u5bdf\uff0c\u901a\u8fc7\u5206\u6790\u5dee\u5f02\u5316\u795e\u7ecf\u5143\u6fc0\u6d3b\u6a21\u5f0f\u6765\u68c0\u6d4b\u9884\u8bad\u7ec3\u6570\u636e\u3002\u540c\u65f6\u6784\u5efa\u4e86CCNewsPDD\u57fa\u51c6\uff0c\u91c7\u7528\u4e25\u683c\u7684\u6570\u636e\u53d8\u6362\u786e\u4fdd\u8bad\u7ec3\u548c\u975e\u8bad\u7ec3\u6570\u636e\u7684\u65f6\u95f4\u5206\u5e03\u4e00\u81f4\u3002", "result": "NA-PDD\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u901a\u8fc7\u795e\u7ecf\u5143\u6fc0\u6d3b\u6a21\u5f0f\u5206\u6790\u8fdb\u884c\u9884\u8bad\u7ec3\u6570\u636e\u68c0\u6d4b\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u5206\u6790\u795e\u7ecf\u5143\u6fc0\u6d3b\u6a21\u5f0f\u7684\u5dee\u5f02\uff0cNA-PDD\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u8bc6\u522b\u5927\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u8bed\u6599\u4e2d\u7684\u7279\u5b9a\u6570\u636e\uff0c\u4e3a\u89e3\u51b3LLM\u8bad\u7ec3\u6570\u636e\u7684\u6cd5\u5f8b\u4f26\u7406\u95ee\u9898\u548c\u6570\u636e\u6c61\u67d3\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u6280\u672f\u624b\u6bb5\u3002"}}
{"id": "2507.16434", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.16434", "abs": "https://arxiv.org/abs/2507.16434", "authors": ["Stassa Patsantzis"], "title": "From model-based learning to model-free behaviour with Meta-Interpretive Learning", "comment": null, "summary": "A \"model\" is a theory that describes the state of an environment and the\neffects of an agent's decisions on the environment. A model-based agent can use\nits model to predict the effects of its future actions and so plan ahead, but\nmust know the state of the environment. A model-free agent cannot plan, but can\nact without a model and without completely observing the environment. An\nautonomous agent capable of acting independently in novel environments must\ncombine both sets of capabilities. We show how to create such an agent with\nMeta-Interpretive Learning used to learn a model-based Solver used to train a\nmodel-free Controller that can solve the same planning problems as the Solver.\nWe demonstrate the equivalence in problem-solving ability of the two agents on\ngrid navigation problems in two kinds of environment: randomly generated mazes,\nand lake maps with wide open areas. We find that all navigation problems solved\nby the Solver are also solved by the Controller, indicating the two are\nequivalent.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6a21\u578b\u57fa\u548c\u65e0\u6a21\u578b\u65b9\u6cd5\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u4f7f\u7528\u5143\u89e3\u91ca\u5b66\u4e60\u8bad\u7ec3\u6a21\u578b\u57fa\u6c42\u89e3\u5668\uff0c\u518d\u7528\u5176\u8bad\u7ec3\u65e0\u6a21\u578b\u63a7\u5236\u5668\uff0c\u5728\u7f51\u683c\u5bfc\u822a\u95ee\u9898\u4e0a\u9a8c\u8bc1\u4e86\u4e24\u8005\u7684\u7b49\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u667a\u80fd\u4f53\u8981\u4e48\u662f\u6a21\u578b\u57fa\u7684\uff08\u9700\u8981\u5b8c\u5168\u89c2\u5bdf\u73af\u5883\u72b6\u6001\u4f46\u80fd\u89c4\u5212\uff09\uff0c\u8981\u4e48\u662f\u65e0\u6a21\u578b\u7684\uff08\u65e0\u9700\u6a21\u578b\u4f46\u4e0d\u80fd\u89c4\u5212\uff09\u3002\u5728\u65b0\u9896\u73af\u5883\u4e2d\u72ec\u7acb\u884c\u52a8\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\u9700\u8981\u540c\u65f6\u5177\u5907\u8fd9\u4e24\u79cd\u80fd\u529b\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u5143\u89e3\u91ca\u5b66\u4e60\uff08Meta-Interpretive Learning\uff09\u6765\u5b66\u4e60\u4e00\u4e2a\u6a21\u578b\u57fa\u7684\u6c42\u89e3\u5668\uff08Solver\uff09\uff0c\u7136\u540e\u7528\u8fd9\u4e2a\u6c42\u89e3\u5668\u6765\u8bad\u7ec3\u4e00\u4e2a\u65e0\u6a21\u578b\u7684\u63a7\u5236\u5668\uff08Controller\uff09\uff0c\u4f7f\u63a7\u5236\u5668\u80fd\u591f\u89e3\u51b3\u4e0e\u6c42\u89e3\u5668\u76f8\u540c\u7684\u89c4\u5212\u95ee\u9898\u3002", "result": "\u5728\u4e24\u79cd\u7f51\u683c\u5bfc\u822a\u73af\u5883\uff08\u968f\u673a\u751f\u6210\u7684\u8ff7\u5bab\u548c\u5177\u6709\u5927\u7247\u5f00\u9614\u533a\u57df\u7684\u6e56\u6cca\u5730\u56fe\uff09\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u53d1\u73b0\u6c42\u89e3\u5668\u80fd\u89e3\u51b3\u7684\u6240\u6709\u5bfc\u822a\u95ee\u9898\uff0c\u63a7\u5236\u5668\u4e5f\u90fd\u80fd\u89e3\u51b3\uff0c\u8868\u660e\u4e24\u8005\u5728\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u4e0a\u662f\u7b49\u6548\u7684\u3002", "conclusion": "\u6210\u529f\u521b\u5efa\u4e86\u4e00\u4e2a\u7ed3\u5408\u6a21\u578b\u57fa\u548c\u65e0\u6a21\u578b\u65b9\u6cd5\u4f18\u52bf\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u901a\u8fc7\u5143\u89e3\u91ca\u5b66\u4e60\u8bad\u7ec3\u7684\u6c42\u89e3\u5668\u4e0e\u5176\u8bad\u7ec3\u7684\u63a7\u5236\u5668\u5728\u5bfc\u822a\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u7b49\u6548\u7684\u95ee\u9898\u89e3\u51b3\u80fd\u529b\uff0c\u4e3a\u6784\u5efa\u80fd\u5728\u65b0\u9896\u73af\u5883\u4e2d\u72ec\u7acb\u884c\u52a8\u7684\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2507.16454", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.16454", "abs": "https://arxiv.org/abs/2507.16454", "authors": ["Pierangela Bruno", "Carmine Dodaro", "Giuseppe Galat\u00e0", "Marco Maratea", "Marco Mochi"], "title": "Improving ASP-based ORS Schedules through Machine Learning Predictions", "comment": "17 pages, International Conference on Logic Programming, Under\n  consideration in Theory and Practice of Logic Programming (TPLP)", "summary": "The Operating Room Scheduling (ORS) problem deals with the optimization of\ndaily operating room surgery schedules. It is a challenging problem subject to\nmany constraints, like to determine the starting time of different surgeries\nand allocating the required resources, including the availability of beds in\ndifferent department units. Recently, solutions to this problem based on Answer\nSet Programming (ASP) have been delivered. Such solutions are overall\nsatisfying but, when applied to real data, they can currently only verify\nwhether the encoding aligns with the actual data and, at most, suggest\nalternative schedules that could have been computed. As a consequence, it is\nnot currently possible to generate provisional schedules. Furthermore, the\nresulting schedules are not always robust.\n  In this paper, we integrate inductive and deductive techniques for solving\nthese issues. We first employ machine learning algorithms to predict the\nsurgery duration, from historical data, to compute provisional schedules. Then,\nwe consider the confidence of such predictions as an additional input to our\nproblem and update the encoding correspondingly in order to compute more robust\nschedules. Results on historical data from the ASL1 Liguria in Italy confirm\nthe viability of our integration.\n  Under consideration in Theory and Practice of Logic Programming (TPLP).", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6574\u5408\u673a\u5668\u5b66\u4e60\u548cAnswer Set Programming (ASP)\u6280\u672f\uff0c\u89e3\u51b3\u624b\u672f\u5ba4\u8c03\u5ea6\u95ee\u9898\u4e2d\u9884\u6d4b\u624b\u672f\u65f6\u957f\u548c\u751f\u6210\u9c81\u68d2\u8c03\u5ea6\u65b9\u6848\u7684\u6311\u6218\uff0c\u5728\u610f\u5927\u5229ASL1 Liguria\u7684\u5386\u53f2\u6570\u636e\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eASP\u7684\u624b\u672f\u5ba4\u8c03\u5ea6\u89e3\u51b3\u65b9\u6848\u53ea\u80fd\u9a8c\u8bc1\u7f16\u7801\u4e0e\u5b9e\u9645\u6570\u636e\u7684\u4e00\u81f4\u6027\uff0c\u6700\u591a\u5efa\u8bae\u66ff\u4ee3\u8c03\u5ea6\u65b9\u6848\uff0c\u65e0\u6cd5\u751f\u6210\u9884\u6d4b\u6027\u8c03\u5ea6\uff0c\u4e14\u751f\u6210\u7684\u8c03\u5ea6\u65b9\u6848\u9c81\u68d2\u6027\u4e0d\u8db3\u3002", "method": "\u6574\u5408\u5f52\u7eb3\u548c\u6f14\u7ece\u6280\u672f\uff1a\u9996\u5148\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u4ece\u5386\u53f2\u6570\u636e\u4e2d\u9884\u6d4b\u624b\u672f\u65f6\u957f\u6765\u8ba1\u7b97\u9884\u6d4b\u6027\u8c03\u5ea6\uff1b\u7136\u540e\u5c06\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u4f5c\u4e3a\u989d\u5916\u8f93\u5165\uff0c\u76f8\u5e94\u66f4\u65b0\u7f16\u7801\u4ee5\u8ba1\u7b97\u66f4\u9c81\u68d2\u7684\u8c03\u5ea6\u65b9\u6848\u3002", "result": "\u5728\u610f\u5927\u5229ASL1 Liguria\u7684\u5386\u53f2\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u5b9e\u4e86\u8be5\u6574\u5408\u65b9\u6cd5\u7684\u53ef\u884c\u6027\uff0c\u80fd\u591f\u751f\u6210\u9884\u6d4b\u6027\u7684\u9c81\u68d2\u624b\u672f\u5ba4\u8c03\u5ea6\u65b9\u6848\u3002", "conclusion": "\u901a\u8fc7\u5c06\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u4e0eASP\u63a8\u7406\u76f8\u7ed3\u5408\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u624b\u672f\u5ba4\u8c03\u5ea6\u4e2d\u7684\u9884\u6d4b\u6027\u548c\u9c81\u68d2\u6027\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u533b\u7597\u8d44\u6e90\u4f18\u5316\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.16473", "categories": ["cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2507.16473", "abs": "https://arxiv.org/abs/2507.16473", "authors": ["Chang Li", "Yaren Zhang", "Haoran Lv", "Qiong Cao", "Chao Xue", "Xiaodong He"], "title": "Learning Temporal Abstractions via Variational Homomorphisms in Option-Induced Abstract MDPs", "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable reasoning ability through\nexplicit Chain-of-Thought (CoT) prompting, but generating these step-by-step\ntextual explanations is computationally expensive and slow. To overcome this,\nwe aim to develop a framework for efficient, implicit reasoning, where the\nmodel \"thinks\" in a latent space without generating explicit text for every\nstep. We propose that these latent thoughts can be modeled as\ntemporally-extended abstract actions, or options, within a hierarchical\nreinforcement learning framework. To effectively learn a diverse library of\noptions as latent embeddings, we first introduce the Variational Markovian\nOption Critic (VMOC), an off-policy algorithm that uses variational inference\nwithin the HiT-MDP framework. To provide a rigorous foundation for using these\noptions as an abstract reasoning space, we extend the theory of continuous MDP\nhomomorphisms. This proves that learning a policy in the simplified, abstract\nlatent space, for which VMOC is suited, preserves the optimality of the\nsolution to the original, complex problem. Finally, we propose a cold-start\nprocedure that leverages supervised fine-tuning (SFT) data to distill human\nreasoning demonstrations into this latent option space, providing a rich\ninitialization for the model's reasoning capabilities. Extensive experiments\ndemonstrate that our approach achieves strong performance on complex logical\nreasoning benchmarks and challenging locomotion tasks, validating our framework\nas a principled method for learning abstract skills for both language and\ncontrol.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u7684\u9690\u5f0f\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8fdb\u884c\"\u601d\u8003\"\u800c\u975e\u751f\u6210\u663e\u5f0f\u6587\u672c\uff0c\u5b9e\u73b0\u4e86\u6bd4\u4f20\u7edf\u601d\u7ef4\u94fe\u63d0\u793a\u66f4\u9ad8\u6548\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u3002", "motivation": "\u4f20\u7edf\u7684\u601d\u7ef4\u94fe\uff08CoT\uff09\u63d0\u793a\u867d\u7136\u80fd\u591f\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u751f\u6210\u9010\u6b65\u7684\u6587\u672c\u89e3\u91ca\u5728\u8ba1\u7b97\u4e0a\u6602\u8d35\u4e14\u901f\u5ea6\u7f13\u6162\u3002\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u9ad8\u6548\u7684\u9690\u5f0f\u63a8\u7406\u6846\u67b6\uff0c\u8ba9\u6a21\u578b\u80fd\u591f\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\"\u601d\u8003\"\u800c\u65e0\u9700\u4e3a\u6bcf\u4e00\u6b65\u751f\u6210\u663e\u5f0f\u6587\u672c\u3002", "method": "\u63d0\u51fa\u5c06\u6f5c\u5728\u601d\u7ef4\u5efa\u6a21\u4e3a\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u4e2d\u7684\u65f6\u95f4\u6269\u5c55\u62bd\u8c61\u52a8\u4f5c\uff08\u9009\u9879\uff09\u3002\u5f15\u5165\u53d8\u5206\u9a6c\u5c14\u53ef\u592b\u9009\u9879\u8bc4\u5224\u5668\uff08VMOC\uff09\u8fd9\u4e00\u79bb\u7b56\u7565\u7b97\u6cd5\uff0c\u5728HiT-MDP\u6846\u67b6\u5185\u4f7f\u7528\u53d8\u5206\u63a8\u7406\u6765\u5b66\u4e60\u591a\u6837\u5316\u7684\u9009\u9879\u5e93\u3002\u6269\u5c55\u8fde\u7eedMDP\u540c\u6001\u7406\u8bba\u4e3a\u4f7f\u7528\u9009\u9879\u4f5c\u4e3a\u62bd\u8c61\u63a8\u7406\u7a7a\u95f4\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002\u8bbe\u8ba1\u51b7\u542f\u52a8\u7a0b\u5e8f\uff0c\u5229\u7528\u76d1\u7763\u5fae\u8c03\u6570\u636e\u5c06\u4eba\u7c7b\u63a8\u7406\u6f14\u793a\u84b8\u998f\u5230\u6f5c\u5728\u9009\u9879\u7a7a\u95f4\u4e2d\u3002", "result": "\u5728\u590d\u6742\u903b\u8f91\u63a8\u7406\u57fa\u51c6\u548c\u5177\u6709\u6311\u6218\u6027\u7684\u8fd0\u52a8\u63a7\u5236\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u5f3a\u52b2\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u4f5c\u4e3a\u5b66\u4e60\u8bed\u8a00\u548c\u63a7\u5236\u62bd\u8c61\u6280\u80fd\u7684\u539f\u5219\u6027\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u7684\u9690\u5f0f\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u5efa\u6a21\u62bd\u8c61\u63a8\u7406\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u4e86\u6bd4\u663e\u5f0f\u601d\u7ef4\u94fe\u66f4\u9ad8\u6548\u7684\u63a8\u7406\uff0c\u5e76\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.16507", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.16507", "abs": "https://arxiv.org/abs/2507.16507", "authors": ["Jean Lelong", "Adnane Errazine", "Annabelle Blangero"], "title": "Agentic RAG with Knowledge Graphs for Complex Multi-Hop Reasoning in Real-World Applications", "comment": "ECAI 2025 demo track, 4 pages", "summary": "Conventional Retrieval-Augmented Generation (RAG) systems enhance Large\nLanguage Models (LLMs) but often fall short on complex queries, delivering\nlimited, extractive answers and struggling with multiple targeted retrievals or\nnavigating intricate entity relationships. This is a critical gap in\nknowledge-intensive domains. We introduce INRAExplorer, an agentic RAG system\nfor exploring the scientific data of INRAE (France's National Research\nInstitute for Agriculture, Food and Environment). INRAExplorer employs an\nLLM-based agent with a multi-tool architecture to dynamically engage a rich\nknowledge base, through a comprehensive knowledge graph derived from open\naccess INRAE publications. This design empowers INRAExplorer to conduct\niterative, targeted queries, retrieve exhaustive datasets (e.g., all\npublications by an author), perform multi-hop reasoning, and deliver\nstructured, comprehensive answers. INRAExplorer serves as a concrete\nillustration of enhancing knowledge interaction in specialized fields.", "AI": {"tldr": "\u7814\u7a76\u8005\u5f00\u53d1\u4e86INRAExplorer\uff0c\u4e00\u4e2a\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\uff0c\u7528\u4e8e\u63a2\u7d22\u6cd5\u56fd\u56fd\u5bb6\u519c\u4e1a\u98df\u54c1\u73af\u5883\u7814\u7a76\u9662\uff08INRAE\uff09\u7684\u79d1\u5b66\u6570\u636e\uff0c\u901a\u8fc7\u591a\u5de5\u5177\u67b6\u6784\u548c\u77e5\u8bc6\u56fe\u8c31\u5b9e\u73b0\u590d\u6742\u67e5\u8be2\u5904\u7406\u548c\u591a\u8df3\u63a8\u7406\u3002", "motivation": "\u4f20\u7edf\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\u5728\u5904\u7406\u590d\u6742\u67e5\u8be2\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u53ea\u80fd\u63d0\u4f9b\u6709\u9650\u7684\u63d0\u53d6\u5f0f\u7b54\u6848\uff0c\u5728\u591a\u76ee\u6807\u68c0\u7d22\u548c\u590d\u6742\u5b9e\u4f53\u5173\u7cfb\u5bfc\u822a\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u8fd9\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u9886\u57df\u662f\u4e00\u4e2a\u5173\u952e\u7f3a\u9677\u3002", "method": "\u63d0\u51faINRAExplorer\u7cfb\u7edf\uff0c\u91c7\u7528\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u548c\u591a\u5de5\u5177\u67b6\u6784\uff0c\u901a\u8fc7\u4eceINRAE\u5f00\u653e\u83b7\u53d6\u51fa\u7248\u7269\u6784\u5efa\u7684\u7efc\u5408\u77e5\u8bc6\u56fe\u8c31\u52a8\u6001\u4ea4\u4e92\u4e30\u5bcc\u7684\u77e5\u8bc6\u5e93\uff0c\u5b9e\u73b0\u8fed\u4ee3\u5f0f\u76ee\u6807\u67e5\u8be2\u3001\u8be6\u5c3d\u6570\u636e\u96c6\u68c0\u7d22\u548c\u591a\u8df3\u63a8\u7406\u3002", "result": "INRAExplorer\u80fd\u591f\u8fdb\u884c\u8fed\u4ee3\u5f0f\u3001\u6709\u9488\u5bf9\u6027\u7684\u67e5\u8be2\uff0c\u68c0\u7d22\u8be6\u5c3d\u7684\u6570\u636e\u96c6\uff08\u5982\u67d0\u4f5c\u8005\u7684\u6240\u6709\u51fa\u7248\u7269\uff09\uff0c\u6267\u884c\u591a\u8df3\u63a8\u7406\uff0c\u5e76\u63d0\u4f9b\u7ed3\u6784\u5316\u3001\u5168\u9762\u7684\u7b54\u6848\u3002", "conclusion": "INRAExplorer\u4e3a\u4e13\u4e1a\u9886\u57df\u4e2d\u589e\u5f3a\u77e5\u8bc6\u4ea4\u4e92\u63d0\u4f9b\u4e86\u5177\u4f53\u7684\u89e3\u51b3\u65b9\u6848\u793a\u4f8b\uff0c\u5c55\u793a\u4e86\u667a\u80fd\u4f53RAG\u7cfb\u7edf\u5728\u5904\u7406\u590d\u6742\u79d1\u5b66\u6570\u636e\u67e5\u8be2\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.16534", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.16534", "abs": "https://arxiv.org/abs/2507.16534", "authors": ["Shanghai AI Lab", ":", "Xiaoyang Chen", "Yunhao Chen", "Zeren Chen", "Zhiyun Chen", "Hanyun Cui", "Yawen Duan", "Jiaxuan Guo", "Qi Guo", "Xuhao Hu", "Hong Huang", "Lige Huang", "Chunxiao Li", "Juncheng Li", "Qihao Lin", "Dongrui Liu", "Xinmin Liu", "Zicheng Liu", "Chaochao Lu", "Xiaoya Lu", "Jingjing Qu", "Qibing Ren", "Jing Shao", "Jingwei Shi", "Jingwei Sun", "Peng Wang", "Weibing Wang", "Jia Xu", "Lewen Yan", "Xiao Yu", "Yi Yu", "Boxuan Zhang", "Jie Zhang", "Weichen Zhang", "Zhijie Zheng", "Tianyi Zhou", "Bowen Zhou"], "title": "Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report", "comment": "97 pages, 37 figures", "summary": "To understand and identify the unprecedented risks posed by rapidly advancing\nartificial intelligence (AI) models, this report presents a comprehensive\nassessment of their frontier risks. Drawing on the E-T-C analysis (deployment\nenvironment, threat source, enabling capability) from the Frontier AI Risk\nManagement Framework (v1.0) (SafeWork-F1-Framework), we identify critical risks\nin seven areas: cyber offense, biological and chemical risks, persuasion and\nmanipulation, uncontrolled autonomous AI R\\&D, strategic deception and\nscheming, self-replication, and collusion. Guided by the \"AI-$45^\\circ$ Law,\"\nwe evaluate these risks using \"red lines\" (intolerable thresholds) and \"yellow\nlines\" (early warning indicators) to define risk zones: green (manageable risk\nfor routine deployment and continuous monitoring), yellow (requiring\nstrengthened mitigations and controlled deployment), and red (necessitating\nsuspension of development and/or deployment). Experimental results show that\nall recent frontier AI models reside in green and yellow zones, without\ncrossing red lines. Specifically, no evaluated models cross the yellow line for\ncyber offense or uncontrolled AI R\\&D risks. For self-replication, and\nstrategic deception and scheming, most models remain in the green zone, except\nfor certain reasoning models in the yellow zone. In persuasion and\nmanipulation, most models are in the yellow zone due to their effective\ninfluence on humans. For biological and chemical risks, we are unable to rule\nout the possibility of most models residing in the yellow zone, although\ndetailed threat modeling and in-depth assessment are required to make further\nclaims. This work reflects our current understanding of AI frontier risks and\nurges collective action to mitigate these challenges.", "AI": {"tldr": "\u672c\u7814\u7a76\u5bf9\u524d\u6cbfAI\u6a21\u578b\u7684\u98ce\u9669\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\uff0c\u8bc6\u522b\u4e86\u4e03\u4e2a\u5173\u952e\u98ce\u9669\u9886\u57df\uff0c\u5e76\u4f7f\u7528\u7ea2\u9ec4\u7eff\u4e09\u8272\u98ce\u9669\u533a\u57df\u5212\u5206\u6cd5\u5bf9\u5f53\u524dAI\u6a21\u578b\u8fdb\u884c\u5206\u7c7b\uff0c\u53d1\u73b0\u6240\u6709\u6a21\u578b\u90fd\u5904\u4e8e\u7eff\u8272\u548c\u9ec4\u8272\u533a\u57df\uff0c\u672a\u8de8\u8d8a\u7ea2\u7ebf\u3002", "motivation": "\u968f\u7740AI\u6280\u672f\u5feb\u901f\u53d1\u5c55\uff0c\u9700\u8981\u7406\u89e3\u548c\u8bc6\u522b\u524d\u6cbfAI\u6a21\u578b\u5e26\u6765\u7684\u524d\u6240\u672a\u6709\u7684\u98ce\u9669\uff0c\u4e3aAI\u5b89\u5168\u6cbb\u7406\u63d0\u4f9b\u79d1\u5b66\u4f9d\u636e\u3002", "method": "\u91c7\u7528E-T-C\u5206\u6790\u6846\u67b6\uff08\u90e8\u7f72\u73af\u5883\u3001\u5a01\u80c1\u6e90\u3001\u8d4b\u80fd\u80fd\u529b\uff09\uff0c\u7ed3\u5408\"AI-45\u00b0\u6cd5\u5219\"\uff0c\u901a\u8fc7\u8bbe\u7f6e\"\u7ea2\u7ebf\"\uff08\u4e0d\u53ef\u5bb9\u5fcd\u9608\u503c\uff09\u548c\"\u9ec4\u7ebf\"\uff08\u65e9\u671f\u9884\u8b66\u6307\u6807\uff09\u6765\u5b9a\u4e49\u7eff\u3001\u9ec4\u3001\u7ea2\u4e09\u4e2a\u98ce\u9669\u533a\u57df\uff0c\u5bf9\u4e03\u4e2a\u5173\u952e\u98ce\u9669\u9886\u57df\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u6240\u6709\u5f53\u524d\u524d\u6cbfAI\u6a21\u578b\u90fd\u5904\u4e8e\u7eff\u8272\u548c\u9ec4\u8272\u533a\u57df\uff0c\u672a\u8de8\u8d8a\u7ea2\u7ebf\u3002\u7f51\u7edc\u653b\u51fb\u548c\u4e0d\u53d7\u63a7AI\u7814\u53d1\u98ce\u9669\u672a\u8fbe\u5230\u9ec4\u7ebf\uff1b\u81ea\u6211\u590d\u5236\u548c\u6218\u7565\u6b3a\u9a97\u98ce\u9669\u5927\u591a\u5728\u7eff\u533a\uff0c\u90e8\u5206\u63a8\u7406\u6a21\u578b\u5728\u9ec4\u533a\uff1b\u8bf4\u670d\u64cd\u63a7\u98ce\u9669\u591a\u6570\u6a21\u578b\u5728\u9ec4\u533a\uff1b\u751f\u7269\u5316\u5b66\u98ce\u9669\u65e0\u6cd5\u6392\u9664\u591a\u6570\u6a21\u578b\u5904\u4e8e\u9ec4\u533a\u7684\u53ef\u80fd\u6027\u3002", "conclusion": "\u5f53\u524dAI\u6a21\u578b\u867d\u7136\u5b58\u5728\u591a\u79cd\u524d\u6cbf\u98ce\u9669\uff0c\u4f46\u5c1a\u672a\u8fbe\u5230\u9700\u8981\u6682\u505c\u5f00\u53d1\u6216\u90e8\u7f72\u7684\u7ea2\u7ebf\u6c34\u5e73\u3002\u7814\u7a76\u5f3a\u8c03\u9700\u8981\u96c6\u4f53\u884c\u52a8\u6765\u7f13\u89e3\u8fd9\u4e9b\u6311\u6218\uff0c\u5e76\u4e3aAI\u98ce\u9669\u7ba1\u7406\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2507.16635", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16635", "abs": "https://arxiv.org/abs/2507.16635", "authors": ["Ali Mohamed Ali", "Luca Tirel", "Hashim A. Hashim"], "title": "Novel Multi-Agent Action Masked Deep Reinforcement Learning for General Industrial Assembly Lines Balancing Problems", "comment": null, "summary": "Efficient planning of activities is essential for modern industrial assembly\nlines to uphold manufacturing standards, prevent project constraint violations,\nand achieve cost-effective operations. While exact solutions to such challenges\ncan be obtained through Integer Programming (IP), the dependence of the search\nspace on input parameters often makes IP computationally infeasible for\nlarge-scale scenarios. Heuristic methods, such as Genetic Algorithms, can also\nbe applied, but they frequently produce suboptimal solutions in extensive\ncases. This paper introduces a novel mathematical model of a generic industrial\nassembly line formulated as a Markov Decision Process (MDP), without imposing\nassumptions on the type of assembly line a notable distinction from most\nexisting models. The proposed model is employed to create a virtual environment\nfor training Deep Reinforcement Learning (DRL) agents to optimize task and\nresource scheduling. To enhance the efficiency of agent training, the paper\nproposes two innovative tools. The first is an action-masking technique, which\nensures the agent selects only feasible actions, thereby reducing training\ntime. The second is a multi-agent approach, where each workstation is managed\nby an individual agent, as a result, the state and action spaces were reduced.\nA centralized training framework with decentralized execution is adopted,\noffering a scalable learning architecture for optimizing industrial assembly\nlines. This framework allows the agents to learn offline and subsequently\nprovide real-time solutions during operations by leveraging a neural network\nthat maps the current factory state to the optimal action. The effectiveness of\nthe proposed scheme is validated through numerical simulations, demonstrating\nsignificantly faster convergence to the optimal solution compared to a\ncomparable model-based approach.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u5de5\u4e1a\u88c5\u914d\u7ebf\u4efb\u52a1\u548c\u8d44\u6e90\u8c03\u5ea6\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u5efa\u6a21\u3001\u52a8\u4f5c\u63a9\u7801\u6280\u672f\u548c\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u5b9e\u73b0\u4e86\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u548c\u66f4\u597d\u7684\u5b9e\u65f6\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7684\u6574\u6570\u89c4\u5212\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u573a\u666f\u4e0b\u8ba1\u7b97\u590d\u6742\u5ea6\u8fc7\u9ad8\uff0c\u800c\u9057\u4f20\u7b97\u6cd5\u7b49\u542f\u53d1\u5f0f\u65b9\u6cd5\u5f80\u5f80\u4ea7\u751f\u6b21\u4f18\u89e3\u3002\u73b0\u6709\u7684\u88c5\u914d\u7ebf\u6a21\u578b\u5927\u591a\u5bf9\u88c5\u914d\u7ebf\u7c7b\u578b\u6709\u7279\u5b9a\u5047\u8bbe\uff0c\u7f3a\u4e4f\u901a\u7528\u6027\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u8bc1\u89e3\u8d28\u91cf\u53c8\u80fd\u9002\u5e94\u5927\u89c4\u6a21\u5b9e\u65f6\u5e94\u7528\u7684\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u5c06\u901a\u7528\u5de5\u4e1a\u88c5\u914d\u7ebf\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b(MDP)\uff0c\u4f7f\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u667a\u80fd\u4f53\u8fdb\u884c\u4efb\u52a1\u548c\u8d44\u6e90\u8c03\u5ea6\u4f18\u5316\u3002\u63d0\u51fa\u4e24\u4e2a\u521b\u65b0\u5de5\u5177\uff1a1)\u52a8\u4f5c\u63a9\u7801\u6280\u672f\u786e\u4fdd\u667a\u80fd\u4f53\u53ea\u9009\u62e9\u53ef\u884c\u52a8\u4f5c\uff1b2)\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\uff0c\u6bcf\u4e2a\u5de5\u4f5c\u7ad9\u7531\u72ec\u7acb\u667a\u80fd\u4f53\u7ba1\u7406\u3002\u91c7\u7528\u96c6\u4e2d\u8bad\u7ec3\u5206\u6563\u6267\u884c\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u5c06\u5f53\u524d\u5de5\u5382\u72b6\u6001\u6620\u5c04\u5230\u6700\u4f18\u52a8\u4f5c\u3002", "result": "\u6570\u503c\u4eff\u771f\u9a8c\u8bc1\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6848\u76f8\u6bd4\u57fa\u4e8e\u6a21\u578b\u7684\u53ef\u6bd4\u8f83\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u66f4\u5feb\u5730\u6536\u655b\u5230\u6700\u4f18\u89e3\u3002\u591a\u667a\u80fd\u4f53\u67b6\u6784\u6709\u6548\u51cf\u5c11\u4e86\u72b6\u6001\u548c\u52a8\u4f5c\u7a7a\u95f4\uff0c\u63d0\u9ad8\u4e86\u8bad\u7ec3\u6548\u7387\u3002\u7cfb\u7edf\u80fd\u591f\u5728\u79bb\u7ebf\u5b66\u4e60\u540e\u63d0\u4f9b\u5b9e\u65f6\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u5f00\u53d1\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316\u5de5\u4e1a\u88c5\u914d\u7ebf\u7684\u4efb\u52a1\u548c\u8d44\u6e90\u8c03\u5ea6\u3002\u901a\u8fc7MDP\u5efa\u6a21\u3001\u52a8\u4f5c\u63a9\u7801\u548c\u591a\u667a\u80fd\u4f53\u67b6\u6784\u7684\u7ed3\u5408\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u8bc1\u89e3\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u5b9e\u65f6\u6027\u80fd\uff0c\u4e3a\u5927\u89c4\u6a21\u5de5\u4e1a\u88c5\u914d\u7ebf\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.16670", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16670", "abs": "https://arxiv.org/abs/2507.16670", "authors": ["Amandeep Kaur", "Gyan Prakash"], "title": "Adaptive Inventory Strategies using Deep Reinforcement Learning for Dynamic Agri-Food Supply Chains", "comment": null, "summary": "Agricultural products are often subject to seasonal fluctuations in\nproduction and demand. Predicting and managing inventory levels in response to\nthese variations can be challenging, leading to either excess inventory or\nstockouts. Additionally, the coordination among stakeholders at various level\nof food supply chain is not considered in the existing body of literature. To\nbridge these research gaps, this study focuses on inventory management of\nagri-food products under demand and lead time uncertainties. By implementing\neffective inventory replenishment policy results in maximize the overall profit\nthroughout the supply chain. However, the complexity of the problem increases\ndue to these uncertainties and shelf-life of the product, that makes\nchallenging to implement traditional approaches to generate optimal set of\nsolutions. Thus, the current study propose a novel Deep Reinforcement Learning\n(DRL) algorithm that combines the benefits of both value- and policy-based DRL\napproaches for inventory optimization under uncertainties. The proposed\nalgorithm can incentivize collaboration among stakeholders by aligning their\ninterests and objectives through shared optimization goal of maximizing\nprofitability along the agri-food supply chain while considering perishability,\nand uncertainty simultaneously. By selecting optimal order quantities with\ncontinuous action space, the proposed algorithm effectively addresses the\ninventory optimization challenges. To rigorously evaluate this algorithm, the\nempirical data from fresh agricultural products supply chain inventory is\nconsidered. Experimental results corroborate the improved performance of the\nproposed inventory replenishment policy under stochastic demand patterns and\nlead time scenarios. The research findings hold managerial implications for\npolicymakers to manage the inventory of agricultural products more effectively\nunder uncertainty.", "AI": {"tldr": "\u672c\u7814\u7a76\u9488\u5bf9\u519c\u4ea7\u54c1\u4f9b\u5e94\u94fe\u4e2d\u9700\u6c42\u548c\u63d0\u524d\u671f\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u5e93\u5b58\u7ba1\u7406\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4ef7\u503c\u548c\u7b56\u7565\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\u4f18\u5316\u8ba2\u8d27\u91cf\uff0c\u5b9e\u73b0\u4f9b\u5e94\u94fe\u6574\u4f53\u5229\u6da6\u6700\u5927\u5316\u5e76\u4fc3\u8fdb\u5229\u76ca\u76f8\u5173\u8005\u534f\u4f5c\u3002", "motivation": "\u519c\u4ea7\u54c1\u9762\u4e34\u5b63\u8282\u6027\u751f\u4ea7\u548c\u9700\u6c42\u6ce2\u52a8\uff0c\u5728\u9700\u6c42\u548c\u63d0\u524d\u671f\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u5e93\u5b58\u7ba1\u7406\u5177\u6709\u6311\u6218\u6027\uff0c\u5bb9\u6613\u5bfc\u81f4\u5e93\u5b58\u8fc7\u5269\u6216\u7f3a\u8d27\u3002\u73b0\u6709\u6587\u732e\u672a\u8003\u8651\u98df\u54c1\u4f9b\u5e94\u94fe\u5404\u5c42\u7ea7\u5229\u76ca\u76f8\u5173\u8005\u4e4b\u95f4\u7684\u534f\u8c03\u95ee\u9898\uff0c\u4e14\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u548c\u4ea7\u54c1\u4fdd\u8d28\u671f\u7b49\u590d\u6742\u56e0\u7d20\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60(DRL)\u7b97\u6cd5\uff0c\u7ed3\u5408\u57fa\u4e8e\u4ef7\u503c\u548c\u57fa\u4e8e\u7b56\u7565\u7684DRL\u65b9\u6cd5\u4f18\u52bf\uff0c\u901a\u8fc7\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\u9009\u62e9\u6700\u4f18\u8ba2\u8d27\u91cf\u3002\u8be5\u7b97\u6cd5\u901a\u8fc7\u5171\u4eab\u7684\u5229\u6da6\u6700\u5927\u5316\u76ee\u6807\u6fc0\u52b1\u5229\u76ca\u76f8\u5173\u8005\u534f\u4f5c\uff0c\u540c\u65f6\u8003\u8651\u4ea7\u54c1\u6613\u8150\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u4f7f\u7528\u65b0\u9c9c\u519c\u4ea7\u54c1\u4f9b\u5e94\u94fe\u5e93\u5b58\u7684\u5b9e\u8bc1\u6570\u636e\u8fdb\u884c\u8bc4\u4f30\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u5b9e\u4e86\u6240\u63d0\u51fa\u7684\u5e93\u5b58\u8865\u5145\u7b56\u7565\u5728\u968f\u673a\u9700\u6c42\u6a21\u5f0f\u548c\u63d0\u524d\u671f\u573a\u666f\u4e0b\u7684\u6027\u80fd\u6539\u8fdb\u3002\u7b97\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u4e0d\u786e\u5b9a\u6027\u73af\u5883\u4e0b\u7684\u5e93\u5b58\u4f18\u5316\u6311\u6218\u3002", "conclusion": "\u7814\u7a76\u4e3a\u653f\u7b56\u5236\u5b9a\u8005\u5728\u4e0d\u786e\u5b9a\u6027\u6761\u4ef6\u4e0b\u66f4\u6709\u6548\u5730\u7ba1\u7406\u519c\u4ea7\u54c1\u5e93\u5b58\u63d0\u4f9b\u4e86\u7ba1\u7406\u542f\u793a\u3002\u6240\u63d0\u51fa\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u4f9b\u5e94\u94fe\u6574\u4f53\u5229\u6da6\u6700\u5927\u5316\uff0c\u540c\u65f6\u4fc3\u8fdb\u5404\u5229\u76ca\u76f8\u5173\u8005\u4e4b\u95f4\u7684\u534f\u4f5c\u3002"}}
{"id": "2507.16727", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16727", "abs": "https://arxiv.org/abs/2507.16727", "authors": ["Zhenyun Yin", "Shujie Wang", "Xuhong Wang", "Xingjun Ma", "Yinchun Wang"], "title": "Deliberative Searcher: Improving LLM Reliability via Reinforcement Learning with constraints", "comment": null, "summary": "Improving the reliability of large language models (LLMs) is critical for\ndeploying them in real-world scenarios. In this paper, we propose\n\\textbf{Deliberative Searcher}, the first framework to integrate certainty\ncalibration with retrieval-based search for open-domain question answering. The\nagent performs multi-step reflection and verification over Wikipedia data and\nis trained with a reinforcement learning algorithm that optimizes for accuracy\nunder a soft reliability constraint. Empirical results show that proposed\nmethod improves alignment between model confidence and correctness, leading to\nmore trustworthy outputs. This paper will be continuously updated.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86Deliberative Searcher\u6846\u67b6\uff0c\u8fd9\u662f\u9996\u4e2a\u5c06\u786e\u5b9a\u6027\u6821\u51c6\u4e0e\u68c0\u7d22\u641c\u7d22\u76f8\u7ed3\u5408\u7684\u5f00\u653e\u57df\u95ee\u7b54\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u6b65\u53cd\u601d\u548c\u9a8c\u8bc1\u63d0\u9ad8\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u63d0\u9ad8\u5927\u8bed\u8a00\u6a21\u578b(LLMs)\u5728\u73b0\u5b9e\u573a\u666f\u90e8\u7f72\u4e2d\u7684\u53ef\u9760\u6027\u662f\u5173\u952e\u9700\u6c42\uff0c\u9700\u8981\u89e3\u51b3\u6a21\u578b\u7f6e\u4fe1\u5ea6\u4e0e\u6b63\u786e\u6027\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff0c\u4f7f\u8f93\u51fa\u66f4\u52a0\u53ef\u4fe1\u3002", "method": "\u63d0\u51faDeliberative Searcher\u6846\u67b6\uff0c\u96c6\u6210\u786e\u5b9a\u6027\u6821\u51c6\u4e0e\u57fa\u4e8e\u68c0\u7d22\u7684\u641c\u7d22\uff0c\u667a\u80fd\u4f53\u5728Wikipedia\u6570\u636e\u4e0a\u6267\u884c\u591a\u6b65\u53cd\u601d\u548c\u9a8c\u8bc1\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5728\u8f6f\u53ef\u9760\u6027\u7ea6\u675f\u4e0b\u4f18\u5316\u51c6\u786e\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u6539\u5584\u4e86\u6a21\u578b\u7f6e\u4fe1\u5ea6\u4e0e\u6b63\u786e\u6027\u4e4b\u95f4\u7684\u5bf9\u9f50\uff0c\u4ea7\u751f\u66f4\u53ef\u4fe1\u7684\u8f93\u51fa\u7ed3\u679c\u3002", "conclusion": "Deliberative Searcher\u6846\u67b6\u6210\u529f\u63d0\u9ad8\u4e86\u5f00\u653e\u57df\u95ee\u7b54\u4e2d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u9760\u6027\uff0c\u901a\u8fc7\u786e\u5b9a\u6027\u6821\u51c6\u548c\u68c0\u7d22\u9a8c\u8bc1\u7684\u7ed3\u5408\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u7f6e\u4fe1\u5ea6\u6821\u51c6\u3002"}}
{"id": "2507.16768", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16768", "abs": "https://arxiv.org/abs/2507.16768", "authors": ["Ran Wang", "Xiaoxuan Liu", "Hao Ren", "Gang Chen", "Fanchao Qi", "Maosong Sun"], "title": "WGRAMMAR: Leverage Prior Knowledge to Accelerate Structured Decoding", "comment": null, "summary": "Structured decoding enables large language models (LLMs) to generate outputs\nin formats required by downstream systems, such as HTML or JSON. However,\nexisting methods suffer from efficiency bottlenecks due to grammar compilation,\nstate tracking, and mask creation. We observe that many real-world tasks embed\nstrong prior knowledge about output structure. Leveraging this, we propose a\ndecomposition of constraints into static and dynamic components -- precompiling\nstatic structures offline and instantiating dynamic arguments at runtime using\ngrammar snippets. Instead of relying on pushdown automata, we employ a\ncompositional set of operators to model regular formats, achieving lower\ntransition latency. We introduce wgrammar, a lightweight decoding engine that\nintegrates domain-aware simplification, constraint decomposition, and mask\ncaching, achieving up to 250x speedup over existing systems. wgrammar's source\ncode is publicly available at https://github.com/wrran/wgrammar.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86wgrammar\uff0c\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u7ed3\u6784\u5316\u89e3\u7801\u5f15\u64ce\uff0c\u901a\u8fc7\u5c06\u7ea6\u675f\u5206\u89e3\u4e3a\u9759\u6001\u548c\u52a8\u6001\u7ec4\u4ef6\uff0c\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u7cfb\u7edf\u9ad8\u8fbe250\u500d\u7684\u52a0\u901f\u3002", "motivation": "\u73b0\u6709\u7684\u7ed3\u6784\u5316\u89e3\u7801\u65b9\u6cd5\u5728\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7279\u5b9a\u683c\u5f0f\u8f93\u51fa\uff08\u5982HTML\u6216JSON\uff09\u65f6\u5b58\u5728\u6548\u7387\u74f6\u9888\uff0c\u4e3b\u8981\u4f53\u73b0\u5728\u8bed\u6cd5\u7f16\u8bd1\u3001\u72b6\u6001\u8ddf\u8e2a\u548c\u63a9\u7801\u521b\u5efa\u7b49\u65b9\u9762\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u5c06\u7ea6\u675f\u5206\u89e3\u4e3a\u9759\u6001\u548c\u52a8\u6001\u7ec4\u4ef6\u7684\u65b9\u6cd5\uff1a\u79bb\u7ebf\u9884\u7f16\u8bd1\u9759\u6001\u7ed3\u6784\uff0c\u8fd0\u884c\u65f6\u4f7f\u7528\u8bed\u6cd5\u7247\u6bb5\u5b9e\u4f8b\u5316\u52a8\u6001\u53c2\u6570\uff1b\u91c7\u7528\u7ec4\u5408\u7b97\u5b50\u96c6\u5408\u6765\u5efa\u6a21\u6b63\u5219\u683c\u5f0f\uff0c\u66ff\u4ee3\u4e0b\u63a8\u81ea\u52a8\u673a\uff1b\u96c6\u6210\u9886\u57df\u611f\u77e5\u7b80\u5316\u3001\u7ea6\u675f\u5206\u89e3\u548c\u63a9\u7801\u7f13\u5b58\u6280\u672f\u3002", "result": "\u5f00\u53d1\u4e86wgrammar\u8f7b\u91cf\u7ea7\u89e3\u7801\u5f15\u64ce\uff0c\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u7cfb\u7edf\u9ad8\u8fbe250\u500d\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u8f6c\u6362\u5ef6\u8fdf\uff0c\u63d0\u9ad8\u4e86\u7ed3\u6784\u5316\u89e3\u7801\u7684\u6548\u7387\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\u7684\u5148\u9a8c\u77e5\u8bc6\u548c\u7ea6\u675f\u5206\u89e3\u7b56\u7565\uff0cwgrammar\u6210\u529f\u89e3\u51b3\u4e86\u7ed3\u6784\u5316\u89e3\u7801\u7684\u6548\u7387\u95ee\u9898\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u683c\u5f0f\u5316\u8f93\u51fa\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.16792", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16792", "abs": "https://arxiv.org/abs/2507.16792", "authors": ["Roman Mayr", "Michel Schimpf", "Thomas Bohn\u00e9"], "title": "ChatChecker: A Framework for Dialogue System Testing and Evaluation Through Non-cooperative User Simulation", "comment": null, "summary": "While modern dialogue systems heavily rely on large language models (LLMs),\ntheir implementation often goes beyond pure LLM interaction. Developers\nintegrate multiple LLMs, external tools, and databases. Therefore, assessment\nof the underlying LLM alone does not suffice, and the dialogue systems must be\ntested and evaluated as a whole. However, this remains a major challenge. With\nmost previous work focusing on turn-level analysis, less attention has been\npaid to integrated dialogue-level quality assurance. To address this, we\npresent ChatChecker, a framework for automated evaluation and testing of\ncomplex dialogue systems. ChatChecker uses LLMs to simulate diverse user\ninteractions, identify dialogue breakdowns, and evaluate quality. Compared to\nprevious approaches, our design reduces setup effort and is generalizable, as\nit does not require reference dialogues and is decoupled from the\nimplementation of the target dialogue system. We improve breakdown detection\nperformance over a prior LLM-based approach by including an error taxonomy in\nthe prompt. Additionally, we propose a novel non-cooperative user simulator\nbased on challenging personas that uncovers weaknesses in target dialogue\nsystems more effectively. Through this, ChatChecker contributes to thorough and\nscalable testing. This enables both researchers and practitioners to accelerate\nthe development of robust dialogue systems.", "AI": {"tldr": "ChatChecker\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u8bc4\u4f30\u548c\u6d4b\u8bd5\u590d\u6742\u5bf9\u8bdd\u7cfb\u7edf\u7684\u6846\u67b6\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6a21\u62df\u7528\u6237\u4ea4\u4e92\u3001\u8bc6\u522b\u5bf9\u8bdd\u6545\u969c\u5e76\u8bc4\u4f30\u8d28\u91cf\uff0c\u65e0\u9700\u53c2\u8003\u5bf9\u8bdd\u4e14\u4e0e\u76ee\u6807\u7cfb\u7edf\u5b9e\u73b0\u89e3\u8026\uff0c\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u5bf9\u8bdd\u7cfb\u7edf\u6d4b\u8bd5\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u73b0\u4ee3\u5bf9\u8bdd\u7cfb\u7edf\u901a\u5e38\u96c6\u6210\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u3001\u5916\u90e8\u5de5\u5177\u548c\u6570\u636e\u5e93\uff0c\u4ec5\u8bc4\u4f30\u5e95\u5c42LLM\u4e0d\u8db3\u4ee5\u5168\u9762\u8bc4\u4f30\u6574\u4e2a\u5bf9\u8bdd\u7cfb\u7edf\u3002\u4ee5\u5f80\u5de5\u4f5c\u4e3b\u8981\u5173\u6ce8\u8f6e\u6b21\u7ea7\u5206\u6790\uff0c\u7f3a\u4e4f\u5bf9\u96c6\u6210\u5bf9\u8bdd\u7ea7\u8d28\u91cf\u4fdd\u8bc1\u7684\u5173\u6ce8\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u6574\u4f53\u6d4b\u8bd5\u548c\u8bc4\u4f30\u590d\u6742\u5bf9\u8bdd\u7cfb\u7edf\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faChatChecker\u6846\u67b6\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6a21\u62df\u591a\u6837\u5316\u7528\u6237\u4ea4\u4e92\uff0c\u8bc6\u522b\u5bf9\u8bdd\u6545\u969c\u5e76\u8bc4\u4f30\u8d28\u91cf\u3002\u8bbe\u8ba1\u4e2d\u51cf\u5c11\u4e86\u8bbe\u7f6e\u5de5\u4f5c\u91cf\uff0c\u5177\u6709\u901a\u7528\u6027\uff0c\u4e0d\u9700\u8981\u53c2\u8003\u5bf9\u8bdd\u4e14\u4e0e\u76ee\u6807\u5bf9\u8bdd\u7cfb\u7edf\u7684\u5b9e\u73b0\u89e3\u8026\u3002\u901a\u8fc7\u5728\u63d0\u793a\u4e2d\u5305\u542b\u9519\u8bef\u5206\u7c7b\u6cd5\u6765\u6539\u8fdb\u6545\u969c\u68c0\u6d4b\u6027\u80fd\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u6311\u6218\u6027\u4eba\u8bbe\u7684\u975e\u534f\u4f5c\u7528\u6237\u6a21\u62df\u5668\u3002", "result": "\u76f8\u6bd4\u4e4b\u524d\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u63d0\u793a\u4e2d\u5305\u542b\u9519\u8bef\u5206\u7c7b\u6cd5\u63d0\u9ad8\u4e86\u6545\u969c\u68c0\u6d4b\u6027\u80fd\u3002\u57fa\u4e8e\u6311\u6218\u6027\u4eba\u8bbe\u7684\u975e\u534f\u4f5c\u7528\u6237\u6a21\u62df\u5668\u80fd\u591f\u66f4\u6709\u6548\u5730\u53d1\u73b0\u76ee\u6807\u5bf9\u8bdd\u7cfb\u7edf\u7684\u5f31\u70b9\uff0c\u5b9e\u73b0\u4e86\u5168\u9762\u4e14\u53ef\u6269\u5c55\u7684\u6d4b\u8bd5\u3002", "conclusion": "ChatChecker\u4e3a\u590d\u6742\u5bf9\u8bdd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u81ea\u52a8\u5316\u8bc4\u4f30\u548c\u6d4b\u8bd5\u7684\u6709\u6548\u6846\u67b6\uff0c\u80fd\u591f\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u52a0\u901f\u5f00\u53d1\u7a33\u5065\u7684\u5bf9\u8bdd\u7cfb\u7edf\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5bf9\u8bdd\u7cfb\u7edf\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2507.16796", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16796", "abs": "https://arxiv.org/abs/2507.16796", "authors": ["Mian Ibad Ali Shah", "Enda Barrett", "Karl Mason"], "title": "Uncertainty-Aware Knowledge Transformers for Peer-to-Peer Energy Trading with Multi-Agent Reinforcement Learning", "comment": "7 pages, 4 figures, 1 table, Proceedings of the Main Track of the\n  European Conference on Artificial Intelligence (ECAI 2025), October 25-30,\n  2025", "summary": "This paper presents a novel framework for Peer-to-Peer (P2P) energy trading\nthat integrates uncertainty-aware prediction with multi-agent reinforcement\nlearning (MARL), addressing a critical gap in current literature. In contrast\nto previous works relying on deterministic forecasts, the proposed approach\nemploys a heteroscedastic probabilistic transformer-based prediction model\ncalled Knowledge Transformer with Uncertainty (KTU) to explicitly quantify\nprediction uncertainty, which is essential for robust decision-making in the\nstochastic environment of P2P energy trading. The KTU model leverages\ndomain-specific features and is trained with a custom loss function that\nensures reliable probabilistic forecasts and confidence intervals for each\nprediction. Integrating these uncertainty-aware forecasts into the MARL\nframework enables agents to optimize trading strategies with a clear\nunderstanding of risk and variability. Experimental results show that the\nuncertainty-aware Deep Q-Network (DQN) reduces energy purchase costs by up to\n5.7% without P2P trading and 3.2% with P2P trading, while increasing\nelectricity sales revenue by 6.4% and 44.7%, respectively. Additionally, peak\nhour grid demand is reduced by 38.8% without P2P and 45.6% with P2P. These\nimprovements are even more pronounced when P2P trading is enabled, highlighting\nthe synergy between advanced forecasting and market mechanisms for resilient,\neconomically efficient energy communities.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u96c6\u6210\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u9884\u6d4b\u548c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684P2P\u80fd\u6e90\u4ea4\u6613\u6846\u67b6\uff0c\u901a\u8fc7Knowledge Transformer with Uncertainty (KTU)\u6a21\u578b\u91cf\u5316\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\uff0c\u5b9e\u73b0\u4e86\u66f4\u9c81\u68d2\u7684\u80fd\u6e90\u4ea4\u6613\u51b3\u7b56\u3002", "motivation": "\u73b0\u6709P2P\u80fd\u6e90\u4ea4\u6613\u7814\u7a76\u4f9d\u8d56\u786e\u5b9a\u6027\u9884\u6d4b\uff0c\u7f3a\u4e4f\u5bf9\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7684\u8003\u8651\uff0c\u800c\u8fd9\u5728\u968f\u673a\u6027\u7684P2P\u80fd\u6e90\u4ea4\u6613\u73af\u5883\u4e2d\u5bf9\u9c81\u68d2\u51b3\u7b56\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u96c6\u6210\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u9884\u6d4b\u4e0e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60(MARL)\u7684\u6846\u67b6\uff0c\u91c7\u7528\u5f02\u65b9\u5dee\u6982\u7387\u53d8\u6362\u5668KTU\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\uff0c\u5229\u7528\u7279\u5b9a\u9886\u57df\u7279\u5f81\u548c\u5b9a\u5236\u635f\u5931\u51fd\u6570\u8bad\u7ec3\uff0c\u751f\u6210\u53ef\u9760\u7684\u6982\u7387\u9884\u6d4b\u548c\u7f6e\u4fe1\u533a\u95f4\uff0c\u5e76\u5c06\u5176\u6574\u5408\u5230\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u6df1\u5ea6Q\u7f51\u7edc(DQN)\u4e2d\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4e0d\u786e\u5b9a\u6027\u611f\u77e5DQN\u5728\u65e0P2P\u4ea4\u6613\u65f6\u964d\u4f4e\u80fd\u6e90\u91c7\u8d2d\u6210\u672c5.7%\uff0c\u6709P2P\u4ea4\u6613\u65f6\u964d\u4f4e3.2%\uff1b\u7535\u529b\u9500\u552e\u6536\u5165\u5206\u522b\u589e\u52a06.4%\u548c44.7%\uff1b\u5cf0\u65f6\u7535\u7f51\u9700\u6c42\u5206\u522b\u51cf\u5c1138.8%\u548c45.6%\u3002", "conclusion": "\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u9884\u6d4b\u4e0eP2P\u4ea4\u6613\u673a\u5236\u7684\u534f\u540c\u4f5c\u7528\u663e\u8457\u63d0\u5347\u4e86\u80fd\u6e90\u793e\u533a\u7684\u7ecf\u6d4e\u6548\u7387\u548c\u97e7\u6027\uff0c\u8bc1\u660e\u4e86\u5148\u8fdb\u9884\u6d4b\u6280\u672f\u4e0e\u5e02\u573a\u673a\u5236\u7ed3\u5408\u7684\u6709\u6548\u6027\u3002"}}
